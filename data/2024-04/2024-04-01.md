## [UPDATED!] **2024-04-01** (Publish Time)

## 生成模型

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-04-01**|**DPMesh: Exploiting Diffusion Prior for Occluded Human Mesh Recovery**|DPMesh：利用扩散先验来恢复遮挡的人体网格|Yixuan Zhu, Ao Li, Yansong Tang, Wenliang Zhao, Jie Zhou, Jiwen Lu|<http://arxiv.org/pdf/2404.01424v1>|null
**2024-04-01**|**Bigger is not Always Better: Scaling Properties of Latent Diffusion Models**|越大并不总是越好：潜在扩散模型的缩放特性|Kangfu Mei, Zhengzhong Tu, Mauricio Delbracio, Hossein Talebi, Vishal M. Patel, Peyman Milanfar|<http://arxiv.org/pdf/2404.01367v1>|null
**2024-04-01**|**MagicMirror: Fast and High-Quality Avatar Generation with a Constrained Search Space**|MagicMirror：在有限的搜索空间下快速生成高质量头像|Armand Comas-Massagué, Di Qiu, Menglei Chai, Marcel Bühler, Amit Raj, Ruiqi Gao, Qiangeng Xu, Mark Matthews, Paulo Gotardo, Octavia Camps, et.al.|<http://arxiv.org/pdf/2404.01296v1>|null
**2024-04-01**|**CosmicMan: A Text-to-Image Foundation Model for Humans**|CosmicMan：人类的文本到图像基础模型|Shikai Li, Jianglin Fu, Kaiyuan Liu, Wentao Wang, Kwan-Yee Lin, Wayne Wu|<http://arxiv.org/pdf/2404.01294v1>|null
**2024-04-01**|**Measuring Style Similarity in Diffusion Models**|测量扩散模型中的风格相似度|Gowthami Somepalli, Anubhav Gupta, Kamal Gupta, Shramay Palta, Micah Goldblum, Jonas Geiping, Abhinav Shrivastava, Tom Goldstein|<http://arxiv.org/pdf/2404.01292v1>|null
**2024-04-01**|**An image speaks a thousand words, but can everyone listen? On translating images for cultural relevance**|一图胜千言，但每个人都能听懂吗？论翻译图像的文化相关性|Simran Khanuja, Sathyanarayanan Ramamoorthy, Yueqi Song, Graham Neubig|<http://arxiv.org/pdf/2404.01247v1>|null
**2024-04-01**|**A Unified and Interpretable Emotion Representation and Expression Generation**|统一且可解释的情感表示和表达生成|Reni Paskaleva, Mykyta Holubakha, Andela Ilic, Saman Motamed, Luc Van Gool, Danda Paudel|<http://arxiv.org/pdf/2404.01243v1>|null
**2024-04-02**|**StructLDM: Structured Latent Diffusion for 3D Human Generation**|StructLDM：用于 3D 人体生成的结构化潜在扩散|Tao Hu, Fangzhou Hong, Ziwei Liu|<http://arxiv.org/pdf/2404.01241v2>|null
**2024-04-01**|**Video Interpolation with Diffusion Models**|使用扩散模型的视频插值|Siddhant Jain, Daniel Watson, Eric Tabellion, Aleksander Hołyński, Ben Poole, Janne Kontkanen|<http://arxiv.org/pdf/2404.01203v1>|null
**2024-04-01**|**Uncovering the Text Embedding in Text-to-Image Diffusion Models**|揭示文本到图像扩散模型中的文本嵌入|Hu Yu, Hao Luo, Fan Wang, Feng Zhao|<http://arxiv.org/pdf/2404.01154v1>|null
**2024-04-01**|**Condition-Aware Neural Network for Controlled Image Generation**|用于受控图像生成的条件感知神经网络|Han Cai, Muyang Li, Zhuoyang Zhang, Qinsheng Zhang, Ming-Yu Liu, Song Han|<http://arxiv.org/pdf/2404.01143v1>|null
**2024-04-01**|**Diffusion based Zero-shot Medical Image-to-Image Translation for Cross Modality Segmentation**|用于跨模态分割的基于扩散的零样本医学图像到图像转换|Zihao Wang, Yingyu Yang, Yuzhou Chen, Tingting Yuan, Maxime Sermesant, Herve Delingette|<http://arxiv.org/pdf/2404.01102v1>|null
**2024-04-01**|**UFID: A Unified Framework for Input-level Backdoor Detection on Diffusion Models**|UFID：扩散模型输入级后门检测的统一框架|Zihan Guan, Mengxuan Hu, Sheng Li, Anil Vullikanti|<http://arxiv.org/pdf/2404.01101v1>|null
**2024-04-01**|**HairFastGAN: Realistic and Robust Hair Transfer with a Fast Encoder-Based Approach**|HairFastGAN：采用基于快速编码器的方法实现真实且稳健的毛发传输|Maxim Nikolaev, Mikhail Kuznetsov, Dmitry Vetrov, Aibek Alanov|<http://arxiv.org/pdf/2404.01094v1>|null
**2024-04-01**|**Texture-Preserving Diffusion Models for High-Fidelity Virtual Try-On**|用于高保真虚拟试戴的纹理保留扩散模型|Xu Yang, Changxing Ding, Zhibin Hong, Junhao Huang, Jin Tao, Xiangmin Xu|<http://arxiv.org/pdf/2404.01089v1>|null
**2024-04-01**|**PhysReaction: Physically Plausible Real-Time Humanoid Reaction Synthesis via Forward Dynamics Guided 4D Imitation**|PhysReaction：通过前向动力学引导 4D 模拟进行物理上合理的实时人形反应合成|Yunze Liu, Changxi Chen, Chenjing Ding, Li Yi|<http://arxiv.org/pdf/2404.01081v1>|null
**2024-04-01**|**Drag Your Noise: Interactive Point-based Editing via Diffusion Semantic Propagation**|拖动噪音：通过扩散语义传播进行交互式基于点的编辑|Haofeng Liu, Chenshu Xu, Yifei Yang, Lihua Zeng, Shengfeng He|<http://arxiv.org/pdf/2404.01050v1>|null
**2024-04-02**|**Survey of Bias In Text-to-Image Generation: Definition, Evaluation, and Mitigation**|文本到图像生成中的偏差调查：定义、评估和缓解|Yixin Wan, Arjun Subramonian, Anaelia Ovalle, Zongyu Lin, Ashima Suvarna, Christina Chance, Hritik Bansal, Rebecca Pattichis, Kai-Wei Chang|<http://arxiv.org/pdf/2404.01030v2>|null
**2024-04-02**|**PosterLlama: Bridging Design Ability of Langauge Model to Contents-Aware Layout Generation**|PosterLlama：将语言模型的设计能力与内容感知布局生成联系起来|Jaejung Seol, Seojun Kim, Jaejun Yoo|<http://arxiv.org/pdf/2404.00995v2>|null
**2024-04-01**|**Improving Visual Recognition with Hyperbolical Visual Hierarchy Mapping**|通过双曲视觉层次映射提高视觉识别能力|Hyeongjun Kwon, Jinhyun Jang, Jin Kim, Kwonyoung Kim, Kwanghoon Sohn|<http://arxiv.org/pdf/2404.00974v1>|null
**2024-04-01**|**Towards Memorization-Free Diffusion Models**|迈向无记忆扩散模型|Chen Chen, Daochang Liu, Chang Xu|<http://arxiv.org/pdf/2404.00922v1>|null
**2024-04-01**|**Model-Agnostic Human Preference Inversion in Diffusion Models**|扩散模型中与模型无关的人类偏好反转|Jeeyung Kim, Ze Wang, Qiang Qiu|<http://arxiv.org/pdf/2404.00879v1>|null
**2024-04-01**|**TryOn-Adapter: Efficient Fine-Grained Clothing Identity Adaptation for High-Fidelity Virtual Try-On**|TryOn-Adapter：高效细粒度服装身份适配，实现高保真虚拟试穿|Jiazheng Xing, Chao Xu, Yijie Qian, Yang Liu, Guang Dai, Baigui Sun, Yong Liu, Jingdong Wang|<http://arxiv.org/pdf/2404.00878v1>|null
**2024-04-01**|**DiSR-NeRF: Diffusion-Guided View-Consistent Super-Resolution NeRF**|DiSR-NeRF：扩散引导视图一致超分辨率 NeRF|Jie Long Lee, Chen Li, Gim Hee Lee|<http://arxiv.org/pdf/2404.00874v1>|null
**2024-04-01**|**Generating Content for HDR Deghosting from Frequency View**|从频率视图生成用于 HDR 去重影的内容|Tao Hu, Qingsen Yan, Yuankai Qi, Yanning Zhang|<http://arxiv.org/pdf/2404.00849v1>|null

## 多模态

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-04-01**|**TraveLER: A Multi-LMM Agent Framework for Video Question-Answering**|TraveLER：用于视频问答的多 LMM 代理框架|Chuyi Shang, Amos You, Sanjay Subramanian, Trevor Darrell, Roei Herzig|<http://arxiv.org/pdf/2404.01476v1>|null
**2024-04-01**|**Evaluating Text-to-Visual Generation with Image-to-Text Generation**|使用图像到文本生成评估文本到视觉生成|Zhiqiu Lin, Deepak Pathak, Baiqi Li, Jiayao Li, Xide Xia, Graham Neubig, Pengchuan Zhang, Deva Ramanan|<http://arxiv.org/pdf/2404.01291v1>|null
**2024-04-01**|**Large Motion Model for Unified Multi-Modal Motion Generation**|用于统一多模态运动生成的大运动模型|Mingyuan Zhang, Daisheng Jin, Chenyang Gu, Fangzhou Hong, Zhongang Cai, Jingfang Huang, Chongzhi Zhang, Xinying Guo, Lei Yang, Ying He, et.al.|<http://arxiv.org/pdf/2404.01284v1>|null
**2024-04-02**|**Direct Preference Optimization of Video Large Multimodal Models from Language Model Reward**|来自语言模型奖励的视频大型多模态模型的直接偏好优化|Ruohong Zhang, Liangke Gui, Zhiqing Sun, Yihao Feng, Keyang Xu, Yuanhan Zhang, Di Fu, Chunyuan Li, Alexander Hauptmann, Yonatan Bisk, et.al.|<http://arxiv.org/pdf/2404.01258v2>|null
**2024-04-01**|**AURORA: Navigating UI Tarpits via Automated Neural Screen Understanding**|AURORA：通过自动神经屏幕理解导航 UI Tarpit|Safwat Ali Khan, Wenyu Wang, Yiran Ren, Bin Zhu, Jiangfan Shi, Alyssa McGowan, Wing Lam, Kevin Moran|<http://arxiv.org/pdf/2404.01240v1>|null
**2024-04-02**|**Open-Vocabulary Federated Learning with Multimodal Prototyping**|具有多模态原型的开放词汇联合学习|Huimin Zeng, Zhenrui Yue, Dong Wang|<http://arxiv.org/pdf/2404.01232v2>|null
**2024-04-01**|**iMD4GC: Incomplete Multimodal Data Integration to Advance Precise Treatment Response Prediction and Survival Analysis for Gastric Cancer**|iMD4GC：不完整的多模式数据集成可推进胃癌的精确治疗反应预测和生存分析|Fengtao Zhou, Yingxue Xu, Yanfen Cui, Shenyan Zhang, Yun Zhu, Weiyang He, Jiguang Wang, Xin Wang, Ronald Chan, Louis Ho Shing Lau, et.al.|<http://arxiv.org/pdf/2404.01192v1>|null
**2024-04-01**|**SpikeMba: Multi-Modal Spiking Saliency Mamba for Temporal Video Grounding**|SpikeMba：用于时间视频接地的多模式尖峰显着曼巴|Wenrui Li, Xiaopeng Hong, Xiaopeng Fan|<http://arxiv.org/pdf/2404.01174v1>|null
**2024-04-01**|**Detect2Interact: Localizing Object Key Field in Visual Question Answering (VQA) with LLMs**|Detect2Interact：使用法学硕士本地化视觉问答 (VQA) 中的对象关键字段|Jialou Wang, Manli Zhu, Yulei Li, Honglei Li, Longzhi Yang, Wai Lok Woo|<http://arxiv.org/pdf/2404.01151v1>|null
**2024-04-01**|**Prompt Learning for Oriented Power Transmission Tower Detection in High-Resolution SAR Images**|快速学习高分辨率 SAR 图像中的定向输电塔检测|Tianyang Li, Chao Wang, Hong Zhang|<http://arxiv.org/pdf/2404.01074v1>|null
**2024-04-01**|**360+x: A Panoptic Multi-modal Scene Understanding Dataset**|360+x：全景多模态场景理解数据集|Hao Chen, Yuqi Hou, Chenyuan Qu, Irene Testini, Xiaohan Hong, Jianbo Jiao|<http://arxiv.org/pdf/2404.00989v1>|null
**2024-04-01**|**How Can Large Language Models Enable Better Socially Assistive Human-Robot Interaction: A Brief Survey**|大型语言模型如何实现更好的社交辅助人机交互：一项简短的调查|Zhonghao Shi, Ellen Landrum, Amy O' Connell, Mina Kian, Leticia Pinto-Alva, Kaleen Shrestha, Xiaoyuan Zhu, Maja J Matarić|<http://arxiv.org/pdf/2404.00938v1>|null
**2024-04-01**|**MM3DGS SLAM: Multi-modal 3D Gaussian Splatting for SLAM Using Vision, Depth, and Inertial Measurements**|MM3DGS SLAM：使用视觉、深度和惯性测量进行 SLAM 的多模态 3D 高斯分布|Lisong C. Sun, Neel P. Bhatt, Jonathan C. Liu, Zhiwen Fan, Zhangyang Wang, Todd E. Humphreys, Ufuk Topcu|<http://arxiv.org/pdf/2404.00923v1>|null
**2024-04-01**|**LLaMA-Excitor: General Instruction Tuning via Indirect Feature Interaction**|LLaMA-Excitor：通过间接特征交互进行通用指令调整|Bo Zou, Chao Yang, Yu Qiao, Chengbin Quan, Youjian Zhao|<http://arxiv.org/pdf/2404.00913v1>|null
**2024-04-01**|**3MOS: Multi-sources, Multi-resolutions, and Multi-scenes dataset for Optical-SAR image matching**|3MOS：用于光学SAR图像匹配的多源、多分辨率、多场景数据集|Yibin Ye, Xichao Teng, Shuo Chen, Yijie Bian, Tao Tan, Zhang Li|<http://arxiv.org/pdf/2404.00838v1>|null

## Nerf

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-04-01**|**NeRF-MAE : Masked AutoEncoders for Self Supervised 3D representation Learning for Neural Radiance Fields**|NeRF-MAE：用于神经辐射场自监督 3D 表示学习的掩码自动编码器|Muhammad Zubair Irshad, Sergey Zakahrov, Vitor Guizilini, Adrien Gaidon, Zsolt Kira, Rares Ambrus|<http://arxiv.org/pdf/2404.01300v1>|null
**2024-04-01**|**Mirror-3DGS: Incorporating Mirror Reflections into 3D Gaussian Splatting**|Mirror-3DGS：将镜面反射纳入 3D 高斯泼溅|Jiarui Meng, Haijie Li, Yanmin Wu, Qiankun Gao, Shuzhou Yang, Jian Zhang, Siwei Ma|<http://arxiv.org/pdf/2404.01168v1>|null
**2024-04-01**|**SGCNeRF: Few-Shot Neural Rendering via Sparse Geometric Consistency Guidance**|SGCNeRF：通过稀疏几何一致性指导进行少样本神经渲染|Yuru Xiao, Xianming Liu, Deming Zhai, Kui Jiang, Junjun Jiang, Xiangyang Ji|<http://arxiv.org/pdf/2404.00992v1>|null
**2024-04-01**|**FlexiDreamer: Single Image-to-3D Generation with FlexiCubes**|FlexiDreamer：使用 FlexiCube 生成单一图像到 3D|Ruowen Zhao, Zhengyi Wang, Yikai Wang, Zihan Zhou, Jun Zhu|<http://arxiv.org/pdf/2404.00987v1>|null
**2024-04-01**|**Marrying NeRF with Feature Matching for One-step Pose Estimation**|将 NeRF 与特征匹配相结合以实现一步姿势估计|Ronghan Chen, Yang Cong, Yu Ren|<http://arxiv.org/pdf/2404.00891v1>|null
**2024-04-02**|**DPA-Net: Structured 3D Abstraction from Sparse Views via Differentiable Primitive Assembly**|DPA-Net：通过可微分基元组装从稀疏视图中进行结构化 3D 抽象|Fenggen Yu, Yiming Qian, Xu Zhang, Francisca Gil-Ureta, Brian Jackson, Eric Bennett, Hao Zhang|<http://arxiv.org/pdf/2404.00875v2>|null

## 3DGS

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-04-01**|**CityGaussian: Real-time High-quality Large-Scale Scene Rendering with Gaussians**|CityGaussian：使用高斯进行实时高质量大规模场景渲染|Yang Liu, He Guan, Chuanchen Luo, Lue Fan, Junran Peng, Zhaoxiang Zhang|<http://arxiv.org/pdf/2404.01133v1>|null
**2024-04-01**|**HAHA: Highly Articulated Gaussian Human Avatars with Textured Mesh Prior**|哈哈：具有纹理网格先验的高度铰接的高斯人体头像|David Svitov, Pietro Morerio, Lourdes Agapito, Alessio Del Bue|<http://arxiv.org/pdf/2404.01053v1>|null

## 模型压缩/优化

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-04-01**|**SUGAR: Pre-training 3D Visual Representations for Robotics**|SUGAR：机器人的预训练 3D 视觉表示|Shizhe Chen, Ricardo Garcia, Ivan Laptev, Cordelia Schmid|<http://arxiv.org/pdf/2404.01491v1>|null
**2024-04-01**|**BiPer: Binary Neural Networks using a Periodic Function**|BiPer：使用周期函数的二元神经网络|Edwin Vargas, Claudia Correa, Carlos Hinojosa, Henry Arguello|<http://arxiv.org/pdf/2404.01278v1>|null
**2024-04-01**|**PDF: A Probability-Driven Framework for Open World 3D Point Cloud Semantic Segmentation**|PDF：开放世界 3D 点云语义分割的概率驱动框架|Jinfeng Xu, Siyuan Yang, Xianzhi Li, Yuan Tang, Yixue Hao, Long Hu, Min Chen|<http://arxiv.org/pdf/2404.00979v1>|null
**2024-04-01**|**VideoDistill: Language-aware Vision Distillation for Video Question Answering**|VideoDistill：用于视频问答的语言感知视觉蒸馏|Bo Zou, Chao Yang, Yu Qiao, Chengbin Quan, Youjian Zhao|<http://arxiv.org/pdf/2404.00973v1>|null
**2024-04-02**|**A Comprehensive Review of Knowledge Distillation in Computer Vision**|计算机视觉知识蒸馏的全面综述|Sheikh Musa Kaleem, Tufail Rouf, Gousia Habib, Tausifa jan Saleem, Brejesh Lall|<http://arxiv.org/pdf/2404.00936v2>|null
**2024-04-01**|**Instance-Aware Group Quantization for Vision Transformers**|视觉 Transformer 的实例感知组量化|Jaehyeon Moon, Dohyung Kim, Junyong Cheon, Bumsub Ham|<http://arxiv.org/pdf/2404.00928v1>|null
**2024-04-01**|**Collaborative Learning of Anomalies with Privacy (CLAP) for Unsupervised Video Anomaly Detection: A New Baseline**|用于无监督视频异常检测的隐私异常协作学习 (CLAP)：新基线|Anas Al-lahham, Muhammad Zaigham Zaheer, Nurbek Tastan, Karthik Nandakumar|<http://arxiv.org/pdf/2404.00847v1>|null

## 分类/检测/识别/分割/...

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-04-01**|**What is Point Supervision Worth in Video Instance Segmentation?**|视频实例分割中的点监督有何价值？|Shuaiyi Huang, De-An Huang, Zhiding Yu, Shiyi Lan, Subhashree Radhakrishnan, Jose M. Alvarez, Abhinav Shrivastava, Anima Anandkumar|<http://arxiv.org/pdf/2404.01990v1>|null
**2024-04-01**|**On Train-Test Class Overlap and Detection for Image Retrieval**|图像检索中的训练测试类重叠和检测|Chull Hwan Song, Jooyoung Yoon, Taebaek Hwang, Shunghyun Choi, Yeong Hyeon Gu, Yannis Avrithis|<http://arxiv.org/pdf/2404.01524v1>|null
**2024-04-01**|**Temporally Consistent Unbalanced Optimal Transport for Unsupervised Action Segmentation**|无监督动作分割的时间一致不平衡最优传输|Ming Xu, Stephen Gould|<http://arxiv.org/pdf/2404.01518v1>|null
**2024-04-01**|**Can Biases in ImageNet Models Explain Generalization?**|ImageNet 模型中的偏差可以解释泛化吗？|Paul Gavrikov, Janis Keuper|<http://arxiv.org/pdf/2404.01509v1>|null
**2024-04-01**|**MosquitoFusion: A Multiclass Dataset for Real-Time Detection of Mosquitoes, Swarms, and Breeding Sites Using Deep Learning**|MosquitoFusion：使用深度学习实时检测蚊子、群体和繁殖地的多类数据集|Md. Faiyaz Abdullah Sayeedi, Fahim Hafiz, Md Ashiqur Rahman|<http://arxiv.org/pdf/2404.01501v1>|null
**2024-04-01**|**Modality Translation for Object Detection Adaptation Without Forgetting Prior Knowledge**|在不忘记先验知识的情况下进行目标检测适应的模态转换|Heitor Rapela Medeiros, Masih Aminbeidokhti, Fidel Guerrero Pena, David Latortue, Eric Granger, Marco Pedersoli|<http://arxiv.org/pdf/2404.01492v1>|null
**2024-04-01**|**QuAD: Query-based Interpretable Neural Motion Planning for Autonomous Driving**|QuAD：用于自动驾驶的基于查询的可解释神经运动规划|Sourav Biswas, Sergio Casas, Quinlan Sykora, Ben Agro, Abbas Sadat, Raquel Urtasun|<http://arxiv.org/pdf/2404.01486v1>|null
**2024-04-01**|**Finding Regions of Interest in Whole Slide Images Using Multiple Instance Learning**|使用多实例学习在整个幻灯片图像中查找感兴趣区域|Martim Afonso, Praphulla M. S. Bhawsar, Monjoy Saha, Jonas S. Almeida, Arlindo L. Oliveira|<http://arxiv.org/pdf/2404.01446v1>|null
**2024-04-01**|**Neural Implicit Representation for Building Digital Twins of Unknown Articulated Objects**|用于构建未知铰接物体数字孪生的神经隐式表示|Yijia Weng, Bowen Wen, Jonathan Tremblay, Valts Blukis, Dieter Fox, Leonidas Guibas, Stan Birchfield|<http://arxiv.org/pdf/2404.01440v1>|null
**2024-04-01**|**Generation and Detection of Sign Language Deepfakes - A Linguistic and Visual Analysis**|手语 Deepfake 的生成和检测 - 语言和视觉分析|Shahzeb Naeem, Muhammad Riyyan Khan, Usman Tariq, Abhinav Dhall, Carlos Ivan Colon, Hasan Al-Nashash|<http://arxiv.org/pdf/2404.01438v1>|null
**2024-04-01**|**The Radar Ghost Dataset -- An Evaluation of Ghost Objects in Automotive Radar Data**|雷达幽灵数据集——汽车雷达数据中幽灵物体的评估|Florian Kraus, Nicolas Scheiner, Werner Ritter, Klaus Dietmayer|<http://arxiv.org/pdf/2404.01437v1>|null
**2024-04-01**|**OVFoodSeg: Elevating Open-Vocabulary Food Image Segmentation via Image-Informed Textual Representation**|OVFoodSeg：通过图像知情的文本表示提升开放词汇食品图像分割|Xiongwei Wu, Sicheng Yu, Ee-Peng Lim, Chong-Wah Ngo|<http://arxiv.org/pdf/2404.01409v1>|null
**2024-04-01**|**Object-conditioned Bag of Instances for Few-Shot Personalized Instance Recognition**|用于少样本个性化实例识别的对象条件实例包|Umberto Michieli, Jijoong Moon, Daehyun Kim, Mete Ozay|<http://arxiv.org/pdf/2404.01397v1>|null
**2024-04-01**|**Language Guided Domain Generalized Medical Image Segmentation**|语言引导领域广义医学图像分割|Shahina Kunhimon, Muzammal Naseer, Salman Khan, Fahad Shahbaz Khan|<http://arxiv.org/pdf/2404.01272v1>|null
**2024-04-01**|**Bridging Remote Sensors with Multisensor Geospatial Foundation Models**|将远程传感器与多传感器地理空间基础模型桥接|Boran Han, Shuai Zhang, Xingjian Shi, Markus Reichstein|<http://arxiv.org/pdf/2404.01260v1>|null
**2024-04-01**|**FireANTs: Adaptive Riemannian Optimization for Multi-Scale Diffeomorphic Registration**|FireANTs：用于多尺度微分同胚配准的自适应黎曼优化|Rohit Jena, Pratik Chaudhari, James C. Gee|<http://arxiv.org/pdf/2404.01249v1>|null
**2024-04-01**|**Vision-language models for decoding provider attention during neonatal resuscitation**|新生儿复苏期间解码提供者注意力的视觉语言模型|Felipe Parodi, Jordan Matelsky, Alejandra Regla-Vargas, Elizabeth Foglia, Charis Lim, Danielle Weinberg, Konrad Kording, Heidi Herrick, Michael Platt|<http://arxiv.org/pdf/2404.01207v1>|null
**2024-04-01**|**Adaptive Query Prompting for Multi-Domain Landmark Detection**|用于多域地标检测的自适应查询提示|Qiusen Wei, Guoheng Huang, Xiaochen Yuan, Xuhang Chen, Guo Zhong, Jianwen Huang, Jiajie Huang|<http://arxiv.org/pdf/2404.01194v1>|null
**2024-04-02**|**MonoBox: Tightness-free Box-supervised Polyp Segmentation using Monotonicity Constraint**|MonoBox：使用单调性约束的无紧度盒监督息肉分割|Qiang Hu, Zhenyu Yi, Ying Zhou, Ting Li, Fan Huang, Mei Liu, Qiang Li, Zhiwei Wang|<http://arxiv.org/pdf/2404.01188v2>|null
**2024-04-01**|**Diagnosis of Skin Cancer Using VGG16 and VGG19 Based Transfer Learning Models**|使用基于 VGG16 和 VGG19 的迁移学习模型诊断皮肤癌|Amir Faghihi, Mohammadreza Fathollahi, Roozbeh Rajabi|<http://arxiv.org/pdf/2404.01160v1>|null
**2024-04-01**|**Medical Visual Prompting (MVP): A Unified Framework for Versatile and High-Quality Medical Image Segmentation**|医学视觉提示（MVP）：多功能、高质量医学图像分割的统一框架|Yulin Chen, Guoheng Huang, Kai Huang, Zijin Lin, Guo Zhong, Shenghong Luo, Jie Deng, Jian Zhou|<http://arxiv.org/pdf/2404.01127v1>|null
**2024-04-01**|**T-Mamba: Frequency-Enhanced Gated Long-Range Dependency for Tooth 3D CBCT Segmentation**|T-Mamba：牙齿 3D CBCT 分割的频率增强门控远程依赖性|Jing Hao, Lei He, Kuo Feng Hung|<http://arxiv.org/pdf/2404.01065v1>|null
**2024-04-01**|**Roadside Monocular 3D Detection via 2D Detection Prompting**|通过 2D 检测提示进行路边单目 3D 检测|Yechi Ma, Shuoquan Wei, Churun Zhang, Wei Hua, Yanan Li, Shu Kong|<http://arxiv.org/pdf/2404.01064v1>|null
**2024-04-01**|**Action Detection via an Image Diffusion Process**|通过图像扩散过程进行动作检测|Lin Geng Foo, Tianjiao Li, Hossein Rahmani, Jun Liu|<http://arxiv.org/pdf/2404.01051v1>|null
**2024-04-01**|**Harnessing Large Language Models for Training-free Video Anomaly Detection**|利用大型语言模型进行免训练视频异常检测|Luca Zanella, Willi Menapace, Massimiliano Mancini, Yiming Wang, Elisa Ricci|<http://arxiv.org/pdf/2404.01014v1>|null
**2024-04-01**|**Teeth-SEG: An Efficient Instance Segmentation Framework for Orthodontic Treatment based on Anthropic Prior Knowledge**|Teeth-SEG：基于人为先验知识的正畸治疗的高效实例分割框架|Bo Zou, Shaofeng Wang, Hao Liu, Gaoyue Sun, Yajie Wang, FeiFei Zuo, Chengbin Quan, Youjian Zhao|<http://arxiv.org/pdf/2404.01013v1>|null
**2024-04-01**|**CAMO: Correlation-Aware Mask Optimization with Modulated Reinforcement Learning**|CAMO：具有调制强化学习的相关感知掩模优化|Xiaoxiao Liang, Haoyu Yang, Kang Liu, Bei Yu, Yuzhe Ma|<http://arxiv.org/pdf/2404.00980v1>|null
**2024-04-01**|**S2RC-GCN: A Spatial-Spectral Reliable Contrastive Graph Convolutional Network for Complex Land Cover Classification Using Hyperspectral Images**|S2RC-GCN：使用高光谱图像进行复杂土地覆盖分类的空间光谱可靠对比图卷积网络|Renxiang Guan, Zihao Li, Chujia Song, Guo Yu, Xianju Li, Ruyi Feng|<http://arxiv.org/pdf/2404.00964v1>|null
**2024-04-01**|**Harnessing The Power of Attention For Patch-Based Biomedical Image Classification**|利用注意力的力量进行基于补丁的生物医学图像分类|Gousia Habib, Shaima Qureshi, Malik ishfaq|<http://arxiv.org/pdf/2404.00949v1>|null
**2024-04-01**|**Exploring the Efficacy of Group-Normalization in Deep Learning Models for Alzheimer's Disease Classification**|探索阿尔茨海默氏病分类深度学习模型中分组标准化的功效|Gousia Habib, Ishfaq Ahmed Malik, Jameel Ahmad, Imtiaz Ahmed, Shaima Qureshi|<http://arxiv.org/pdf/2404.00946v1>|null
**2024-04-01**|**GOV-NeSF: Generalizable Open-Vocabulary Neural Semantic Fields**|GOV-NeSF：可推广的开放词汇神经语义场|Yunsong Wang, Hanlin Chen, Gim Hee Lee|<http://arxiv.org/pdf/2404.00931v1>|null
**2024-04-01**|**Towards Label-Efficient Human Matting: A Simple Baseline for Weakly Semi-Supervised Trimap-Free Human Matting**|迈向标签高效的人体抠图：弱半监督无 Trimap 人体抠图的简单基线|Beomyoung Kim, Myeong Yeon Yi, Joonsang Yu, Young Joon Yoo, Sung Ju Hwang|<http://arxiv.org/pdf/2404.00921v1>|null
**2024-04-02**|**Rethinking Saliency-Guided Weakly-Supervised Semantic Segmentation**|重新思考显着性引导的弱监督语义分割|Beomyoung Kim, Donghyun Kim, Sung Ju Hwang|<http://arxiv.org/pdf/2404.00918v2>|null
**2024-04-01**|**MGMap: Mask-Guided Learning for Online Vectorized HD Map Construction**|MGMap：用于在线矢量化高精地图构建的掩模引导学习|Xiaolu Liu, Song Wang, Wentong Li, Ruizi Yang, Junbo Chen, Jianke Zhu|<http://arxiv.org/pdf/2404.00876v1>|null
**2024-04-01**|**Lipsum-FT: Robust Fine-Tuning of Zero-Shot Models Using Random Text Guidance**|Lipsum-FT：使用随机文本引导对零样本模型进行鲁棒微调|Giung Nam, Byeongho Heo, Juho Lee|<http://arxiv.org/pdf/2404.00860v1>|null
**2024-04-01**|**Meta Episodic learning with Dynamic Task Sampling for CLIP-based Point Cloud Classification**|元情景学习与动态任务采样用于基于 CLIP 的点云分类|Shuvozit Ghose, Yang Wang|<http://arxiv.org/pdf/2404.00857v1>|null
**2024-04-01**|**TSOM: Small Object Motion Detection Neural Network Inspired by Avian Visual Circuit**|TSOM：受鸟类视觉电路启发的小物体运动检测神经网络|Pignge Hu, Xiaoteng Zhang, Mengmeng Li, Yingjie Zhu, Li Shi|<http://arxiv.org/pdf/2404.00855v1>|null
**2024-04-01**|**Ensemble Learning for Vietnamese Scene Text Spotting in Urban Environments**|城市环境中越南场景文本识别的集成学习|Hieu Nguyen, Cong-Hoang Ta, Phuong-Thuy Le-Nguyen, Minh-Triet Tran, Trung-Nghia Le|<http://arxiv.org/pdf/2404.00852v1>|null
**2024-04-01**|**Transfer Learning with Point Transformers**|使用点转换器进行迁移学习|Kartik Gupta, Rahul Vippala, Sahima Srivastava|<http://arxiv.org/pdf/2404.00846v1>|null
**2024-04-01**|**Automated HER2 Scoring in Breast Cancer Images Using Deep Learning and Pyramid Sampling**|使用深度学习和金字塔采样对乳腺癌图像进行自动 HER2 评分|Sahan Yoruc Selcuk, Xilin Yang, Bijie Bai, Yijie Zhang, Yuzhu Li, Musa Aydin, Aras Firat Unal, Aditya Gomatam, Zhen Guo, Darrow Morgan Angus, et.al.|<http://arxiv.org/pdf/2404.00837v1>|null

## GNN

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-04-01**|**Equivariant Local Reference Frames for Unsupervised Non-rigid Point Cloud Shape Correspondence**|无监督非刚性点云形状对应的等变局部参考系|Ling Wang, Runfa Chen, Yikai Wang, Fuchun Sun, Xinzhou Wang, Sun Kai, Guangyuan Fu, Jianwei Zhang, Wenbing Huang|<http://arxiv.org/pdf/2404.00959v1>|null

## 图像理解

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-04-01**|**Data-Efficient Unsupervised Interpolation Without Any Intermediate Frame for 4D Medical Images**|用于 4D 医学图像的数据高效无监督插值，无需任何中间帧|JungEun Kim, Hangyul Yoon, Geondo Park, Kyungsu Kim, Eunho Yang|<http://arxiv.org/pdf/2404.01464v1>|null
**2024-04-01**|**BadPart: Unified Black-box Adversarial Patch Attacks against Pixel-wise Regression Tasks**|BadPart：针对像素回归任务的统一黑盒对抗性补丁攻击|Zhiyuan Cheng, Zhaoyi Liu, Tengda Guo, Shiwei Feng, Dongfang Liu, Mingjie Tang, Xiangyu Zhang|<http://arxiv.org/pdf/2404.00924v1>|null

## LLM

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-04-01**|**Entity-Centric Reinforcement Learning for Object Manipulation from Pixels**|用于从像素操作对象的以实体为中心的强化学习|Dan Haramati, Tal Daniel, Aviv Tamar|<http://arxiv.org/pdf/2404.01220v1>|null
**2024-04-01**|**LLMs are Good Sign Language Translators**|法学硕士是优秀的手语翻译者|Jia Gong, Lin Geng Foo, Yixuan He, Hossein Rahmani, Jun Liu|<http://arxiv.org/pdf/2404.00925v1>|null

## Transformer

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-04-01**|**On the Faithfulness of Vision Transformer Explanations**|关于 Vision Transformer 解释的可信度|Junyi Wu, Weitai Kang, Hao Tang, Yuan Hong, Yan Yan|<http://arxiv.org/pdf/2404.01415v1>|null
**2024-04-01**|**SyncMask: Synchronized Attentional Masking for Fashion-centric Vision-Language Pretraining**|SyncMask：用于以时尚为中心的视觉语言预训练的同步注意掩蔽|Chull Hwan Song, Taebaek Hwang, Jooyoung Yoon, Shunghyun Choi, Yeong Hyeon Gu|<http://arxiv.org/pdf/2404.01156v1>|null
**2024-04-01**|**Structured Initialization for Attention in Vision Transformers**|视觉变压器中注意力的结构化初始化|Jianqiao Zheng, Xueqian Li, Simon Lucey|<http://arxiv.org/pdf/2404.01139v1>|null
**2024-04-01**|**CMT: Cross Modulation Transformer with Hybrid Loss for Pansharpening**|CMT：具有混合损耗的交叉调制变压器，用于全色锐化|Wen-Jie Shu, Hong-Xia Dou, Rui Wen, Xiao Wu, Liang-Jian Deng|<http://arxiv.org/pdf/2404.01121v1>|null
**2024-04-01**|**AIGCOIQA2024: Perceptual Quality Assessment of AI Generated Omnidirectional Images**|AIGCOIQA2024：人工智能生成的全向图像的感知质量评估|Liu Yang, Huiyu Duan, Long Teng, Yucheng Zhu, Xiaohong Liu, Menghan Hu, Xiongkuo Min, Guangtao Zhai, Patrick Le Callet|<http://arxiv.org/pdf/2404.01024v1>|null
**2024-04-01**|**Towards Robust Event-guided Low-Light Image Enhancement: A Large-Scale Real-World Event-Image Dataset and Novel Approach**|迈向鲁棒事件引导的低光图像增强：大规模现实世界事件图像数据集和新颖方法|Guoqiang Liang, Kanghao Chen, Hangyu Li, Yunfan Lu, Lin Wang|<http://arxiv.org/pdf/2404.00834v1>|null

## 3D/CG

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-04-01**|**ContactHandover: Contact-Guided Robot-to-Human Object Handover**|ContactHandover：接触引导的机器人到人类的物体移交|Zixi Wang, Zeyi Liu, Nicolas Ouporov, Shuran Song|<http://arxiv.org/pdf/2404.01402v1>|null
**2024-04-01**|**CausalChaos! Dataset for Comprehensive Causal Action Question Answering Over Longer Causal Chains Grounded in Dynamic Visual Scenes**|因果混沌！基于动态视觉场景的较长因果链的综合因果动作问答数据集|Ting En Lam, Yuhan Chen, Elston Tan, Eric Peh, Ruirui Chen, Paritosh Parmar, Basura Fernando|<http://arxiv.org/pdf/2404.01299v1>|null
**2024-04-01**|**Scalable Scene Modeling from Perspective Imaging: Physics-based Appearance and Geometry Inference**|来自透视成像的可扩展场景建模：基于物理的外观和几何推理|Shuang Song|<http://arxiv.org/pdf/2404.01248v1>|null
**2024-04-02**|**SurMo: Surface-based 4D Motion Modeling for Dynamic Human Rendering**|SurMo：用于动态人体渲染的基于表面的 4D 运动建模|Tao Hu, Fangzhou Hong, Ziwei Liu|<http://arxiv.org/pdf/2404.01225v2>|null
**2024-04-01**|**Feature Splatting: Language-Driven Physics-Based Scene Synthesis and Editing**|特征泼溅：语言驱动的基于物理的场景合成和编辑|Ri-Zhao Qiu, Ge Yang, Weijia Zeng, Xiaolong Wang|<http://arxiv.org/pdf/2404.01223v1>|null
**2024-04-02**|**Few-shot point cloud reconstruction and denoising via learned Guassian splats renderings and fine-tuned diffusion features**|通过学习的高斯splats渲染和微调扩散特征进行少镜头点云重建和去噪|Pietro Bonazzi|<http://arxiv.org/pdf/2404.01112v2>|null
**2024-04-01**|**Scalable 3D Registration via Truncated Entry-wise Absolute Residuals**|通过截断的条目绝对残差进行可扩展的 3D 配准|Tianyu Huang, Liangzu Peng, René Vidal, Yun-Hui Liu|<http://arxiv.org/pdf/2404.00915v1>|null
**2024-04-01**|**From Pixels to Graphs: Open-Vocabulary Scene Graph Generation with Vision-Language Models**|从像素到图形：使用视觉语言模型生成开放词汇场景图|Rongjie Li, Songyang Zhang, Dahua Lin, Kai Chen, Xuming He|<http://arxiv.org/pdf/2404.00906v1>|null

## 各类学习方式

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-04-01**|**BEM: Balanced and Entropy-based Mix for Long-Tailed Semi-Supervised Learning**|BEM：用于长尾半监督学习的平衡和基于熵的混合|Hongwei Zheng, Linyuan Zhou, Han Li, Jinming Su, Xiaoming Wei, Xiaoming Xu|<http://arxiv.org/pdf/2404.01179v1>|null
**2024-04-01**|**CLIPtone: Unsupervised Learning for Text-based Image Tone Adjustment**|CLIPtone：基于文本的图像色调调整的无监督学习|Hyeongmin Lee, Kyoungkook Kang, Jungseul Ok, Sunghyun Cho|<http://arxiv.org/pdf/2404.01123v1>|null
**2024-04-01**|**Make Continual Learning Stronger via C-Flat**|通过 C-Flat 加强持续学习|Ang Bian, Wei Li, Hangjie Yuan, Chengrong Yu, Zixiang Zhao, Mang Wang, Aojun Lu, Tao Feng|<http://arxiv.org/pdf/2404.00986v1>|null
**2024-04-01**|**Learning by Correction: Efficient Tuning Task for Zero-Shot Generative Vision-Language Reasoning**|通过修正学习：零样本生成视觉语言推理的高效调优任务|Rongjie Li, Yu Wu, Xuming He|<http://arxiv.org/pdf/2404.00909v1>|null
**2024-04-01**|**Slightly Shift New Classes to Remember Old Classes for Video Class-Incremental Learning**|微移新课记住旧课视频课-增量学习|Jian Jiao, Yu Dai, Hefei Mei, Heqian Qiu, Chuanyang Gong, Shiyuan Tang, Xinpeng Hao, Hongliang Li|<http://arxiv.org/pdf/2404.00901v1>|null
**2024-04-01**|**Prompt Learning via Meta-Regularization**|通过元正则化快速学习|Jinyoung Park, Juyeon Ko, Hyunwoo J. Kim|<http://arxiv.org/pdf/2404.00851v1>|null

## 其他

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-04-01**|**VortexViz: Finding Vortex Boundaries by Learning from Particle Trajectories**|VortexViz：通过学习粒子轨迹来寻找涡旋边界|Akila de Silva, Nicholas Tee, Omkar Ghanekar, Fahim Hasan Khan, Gregory Dusek, James Davis, Alex Pang|<http://arxiv.org/pdf/2404.01352v1>|null
**2024-04-01**|**AETTA: Label-Free Accuracy Estimation for Test-Time Adaptation**|AETTA：测试时间适应的无标签准确度估计|Taeckyung Lee, Sorn Chottananurak, Taesik Gong, Sung-Ju Lee|<http://arxiv.org/pdf/2404.01351v1>|null
**2024-04-01**|**Noise2Image: Noise-Enabled Static Scene Recovery for Event Cameras**|Noise2Image：事件摄像机的启用噪声的静态场景恢复|Ruiming Cao, Dekel Galor, Amit Kohli, Jacob L Yates, Laura Waller|<http://arxiv.org/pdf/2404.01298v1>|null
**2024-04-01**|**Streaming Dense Video Captioning**|流式传输密集视频字幕|Xingyi Zhou, Anurag Arnab, Shyamal Buch, Shen Yan, Austin Myers, Xuehan Xiong, Arsha Nagrani, Cordelia Schmid|<http://arxiv.org/pdf/2404.01297v1>|null
**2024-04-01**|**LoSA: Long-Short-range Adapter for Scaling End-to-End Temporal Action Localization**|LoSA：用于扩展端到端时间动作本地化的长短程适配器|Akshita Gupta, Gaurav Mittal, Ahmed Magooda, Ye Yu, Graham W. Taylor, Mei Chen|<http://arxiv.org/pdf/2404.01282v1>|null
**2024-04-01**|**Getting it Right: Improving Spatial Consistency in Text-to-Image Models**|正确做法：提高文本到图像模型的空间一致性|Agneet Chatterjee, Gabriela Ben Melech Stan, Estelle Aflalo, Sayak Paul, Dhruba Ghosh, Tejas Gokhale, Ludwig Schmidt, Hannaneh Hajishirzi, Vasudev Lal, Chitta Baral, et.al.|<http://arxiv.org/pdf/2404.01197v1>|null
**2024-04-01**|**Motion Blur Decomposition with Cross-shutter Guidance**|使用交叉快门引导进行运动模糊分解|Xiang Ji, Haiyang Jiang, Yinqiang Zheng|<http://arxiv.org/pdf/2404.01120v1>|null
**2024-04-01**|**Stale Diffusion: Hyper-realistic 5D Movie Generation Using Old-school Methods**|Stale Diffusion：使用老式方法生成超现实 5D 电影|Joao F. Henriques, Dylan Campbell, Tengda Han|<http://arxiv.org/pdf/2404.01079v1>|null
**2024-04-01**|**Higher education assessment practice in the era of generative AI tools**|生成式AI工具时代的高等教育评估实践|Bayode Ogunleye, Kudirat Ibilola Zakariyyah, Oluwaseun Ajao, Olakunle Olayinka, Hemlata Sharma|<http://arxiv.org/pdf/2404.01036v1>|null
**2024-04-01**|**AMOR: Ambiguous Authorship Order**|AMOR：不明确的作者顺序|Maximilian Weiherer, Andreea Dogaru, Shreya Kapoor, Hannah Schieber, Bernhard Egger|<http://arxiv.org/pdf/2404.00994v1>|null
**2024-04-01**|**Gyro-based Neural Single Image Deblurring**|基于陀螺仪的神经单图像去模糊|Heemin Yang, Jaesung Rim, Seung-Hwan Baek, Sunghyun Cho|<http://arxiv.org/pdf/2404.00916v1>|null
**2024-04-01**|**An N-Point Linear Solver for Line and Motion Estimation with Event Cameras**|用于使用事件相机进行直线和运动估计的 N 点线性求解器|Ling Gao, Daniel Gehrig, Hang Su, Davide Scaramuzza, Laurent Kneip|<http://arxiv.org/pdf/2404.00842v1>|null

