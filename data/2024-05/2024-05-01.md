## [UPDATED!] **2024-05-01** (Publish Time)

## 生成模型

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-01**|**SonicDiffusion: Audio-Driven Image Generation and Editing with Pretrained Diffusion Models**|SonicDiffusion：使用预训练扩散模型进行音频驱动图像生成和编辑|Burak Can Biner, Farrin Marouf Sofian, Umur Berkay Karakaş, Duygu Ceylan, Erkut Erdem, Aykut Erdem|<http://arxiv.org/pdf/2405.00878v1>|null
**2024-05-01**|**Guided Conditional Diffusion Classifier (ConDiff) for Enhanced Prediction of Infection in Diabetic Foot Ulcers**|引导条件扩散分类器 (ConDiff) 用于增强对糖尿病足部溃疡感染的预测|Palawat Busaranuvong, Emmanuel Agu, Deepak Kumar, Shefalika Gautam, Reza Saadati Fard, Bengisu Tulu, Diane Strong|<http://arxiv.org/pdf/2405.00858v1>|null
**2024-05-01**|**ADM: Accelerated Diffusion Model via Estimated Priors for Robust Motion Prediction under Uncertainties**|ADM：通过估计先验加速扩散模型，实现不确定性下的鲁棒运动预测|Jiahui Li, Tianle Shen, Zekai Gu, Jiawei Sun, Chengran Yuan, Yuhang Han, Shuo Sun, Marcelo H. Ang Jr|<http://arxiv.org/pdf/2405.00797v1>|null
**2024-05-01**|**Coherent 3D Portrait Video Reconstruction via Triplane Fusion**|通过 Triplane Fusion 进行连贯 3D 肖像视频重建|Shengze Wang, Xueting Li, Chao Liu, Matthew Chan, Michael Stengel, Josef Spjut, Henry Fuchs, Shalini De Mello, Koki Nagano|<http://arxiv.org/pdf/2405.00794v1>|null
**2024-05-01**|**Obtaining Favorable Layouts for Multiple Object Generation**|获得多对象生成的有利布局|Barak Battash, Amit Rozner, Lior Wolf, Ofir Lindenbaum|<http://arxiv.org/pdf/2405.00791v1>|null
**2024-05-01**|**Deep Reward Supervisions for Tuning Text-to-Image Diffusion Models**|用于调整文本到图像扩散模型的深度奖励监督|Xiaoshi Wu, Yiming Hao, Manyuan Zhang, Keqiang Sun, Zhaoyang Huang, Guanglu Song, Yu Liu, Hongsheng Li|<http://arxiv.org/pdf/2405.00760v1>|null
**2024-05-01**|**TexSliders: Diffusion-Based Texture Editing in CLIP Space**|TexSliders：CLIP 空间中基于扩散的纹理编辑|Julia Guerrero-Viu, Milos Hasan, Arthur Roullier, Midhun Harikumar, Yiwei Hu, Paul Guerrero, Diego Gutierrez, Belen Masia, Valentin Deschaintre|<http://arxiv.org/pdf/2405.00672v1>|null
**2024-05-01**|**RGB$\leftrightarrow$X: Image decomposition and synthesis using material- and lighting-aware diffusion models**|RGB$\leftrightarrow$X：使用材质和光照感知扩散模型进行图像分解和合成|Zheng Zeng, Valentin Deschaintre, Iliyan Georgiev, Yannick Hold-Geoffroy, Yiwei Hu, Fujun Luan, Ling-Qi Yan, Miloš Hašan|<http://arxiv.org/pdf/2405.00666v1>|null
**2024-05-01**|**Deep Metric Learning-Based Out-of-Distribution Detection with Synthetic Outlier Exposure**|基于深度度量学习的分布外检测与综合异常值暴露|Assefa Seyoum Wahd|<http://arxiv.org/pdf/2405.00631v1>|null
**2024-05-01**|**Lane Segmentation Refinement with Diffusion Models**|利用扩散模型改进车道分割|Antonio Ruiz, Andrew Melnik, Dong Wang, Helge Ritter|<http://arxiv.org/pdf/2405.00620v1>|null
**2024-05-01**|**UWAFA-GAN: Ultra-Wide-Angle Fluorescein Angiography Transformation via Multi-scale Generation and Registration Enhancement**|UWAFA-GAN：通过多尺度生成和配准增强实现超广角荧光血管造影转换|Ruiquan Ge, Zhaojie Fang, Pengxue Wei, Zhanghao Chen, Hongyang Jiang, Ahmed Elazab, Wangting Li, Xiang Wan, Shaochong Zhang, Changmiao Wang|<http://arxiv.org/pdf/2405.00542v1>|**[link](https://github.com/tinysqua/uwafa-gan)**
**2024-05-01**|**In Anticipation of Perfect Deepfake: Identity-anchored Artifact-agnostic Detection under Rebalanced Deepfake Detection Protocol**|期待完美的 Deepfake：重新平衡的 Deepfake 检测协议下身份锚定的与工件无关的检测|Wei-Han Wang, Chin-Yuan Yeh, Hsi-Wen Chen, De-Nian Yang, Ming-Syan Chen|<http://arxiv.org/pdf/2405.00483v1>|null
**2024-05-01**|**Lazy Layers to Make Fine-Tuned Diffusion Models More Traceable**|惰性层使微调的扩散模型更可追踪|Haozhe Liu, Wentian Zhang, Bing Li, Bernard Ghanem, Jürgen Schmidhuber|<http://arxiv.org/pdf/2405.00466v1>|null
**2024-05-01**|**Detail-Enhancing Framework for Reference-Based Image Super-Resolution**|基于参考的图像超分辨率的细节增强框架|Zihan Wang, Ziliang Xiong, Hongying Tang, Xiaobing Yuan|<http://arxiv.org/pdf/2405.00431v1>|null
**2024-05-01**|**Continuous sPatial-Temporal Deformable Image Registration (CPT-DIR) for motion modelling in radiotherapy: beyond classic voxel-based methods**|用于放射治疗运动建模的连续时空可变形图像配准（CPT-DIR）：超越经典的基于体素的方法|Xia Li, Muheng Li, Antony Lomax, Joachim Buhmann, Ye Zhang|<http://arxiv.org/pdf/2405.00430v1>|null
**2024-05-01**|**Self-supervised Pre-training of Text Recognizers**|文本识别器的自监督预训练|Martin Kišš, Michal Hradiš|<http://arxiv.org/pdf/2405.00420v1>|**[link](https://github.com/dcgm/pero-pretraining)**
**2024-05-01**|**Streamlining Image Editing with Layered Diffusion Brushes**|使用分层扩散画笔简化图像编辑|Peyman Gholami, Robert Xiao|<http://arxiv.org/pdf/2405.00313v1>|null
**2024-05-01**|**ASAM: Boosting Segment Anything Model with Adversarial Tuning**|ASAM：通过对抗性调整增强分段任何模型|Bo Li, Haoke Xiao, Lv Tang|<http://arxiv.org/pdf/2405.00256v1>|**[link](https://github.com/luckybird1994/ASAM)**

## 多模态

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-01**|**Transformer-Based Self-Supervised Learning for Histopathological Classification of Ischemic Stroke Clot Origin**|基于变压器的自我监督学习对缺血性中风血栓起源的组织病理学分类|K. Yeh, M. S. Jabal, V. Gupta, D. F. Kallmes, W. Brinjikji, B. S. Erdal|<http://arxiv.org/pdf/2405.00908v1>|null
**2024-05-01**|**Beyond Human Vision: The Role of Large Vision Language Models in Microscope Image Analysis**|超越人类视觉：大型视觉语言模型在显微镜图像分析中的作用|Prateek Verma, Minh-Hao Van, Xintao Wu|<http://arxiv.org/pdf/2405.00876v1>|null
**2024-05-01**|**EALD-MLLM: Emotion Analysis in Long-sequential and De-identity videos with Multi-modal Large Language Model**|EALD-MLLM：使用多模态大语言模型进行长序列和去身份视频中的情感分析|Deng Li, Xin Liu, Bohao Xing, Baiqiang Xia, Yuan Zong, Bihan Wen, Heikki Kälviäinen|<http://arxiv.org/pdf/2405.00574v1>|null
**2024-05-01**|**Enhanced Visual Question Answering: A Comparative Analysis and Textual Feature Extraction Via Convolutions**|增强型视觉问答：通过卷积进行比较分析和文本特征提取|Zhilin Zhang|<http://arxiv.org/pdf/2405.00479v1>|null
**2024-05-01**|**MMTryon: Multi-Modal Multi-Reference Control for High-Quality Fashion Generation**|MMTryon：用于高品质时尚生成的多模态多参考控制|Xujie Zhang, Ente Lin, Xiu Li, Yuxuan Luo, Michael Kampffmeyer, Xin Dong, Xiaodan Liang|<http://arxiv.org/pdf/2405.00448v1>|null

## Nerf

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-01**|**DiL-NeRF: Delving into Lidar for Neural Radiance Field on Street Scenes**|DiL-NeRF：深入研究激光雷达在街景上的神经辐射场|Shanlin Sun, Bingbing Zhuang, Ziyu Jiang, Buyu Liu, Xiaohui Xie, Manmohan Chandraker|<http://arxiv.org/pdf/2405.00900v1>|null
**2024-05-01**|**Spectrally Pruned Gaussian Fields with Neural Compensation**|具有神经补偿的光谱修剪高斯场|Runyi Yang, Zhenxin Zhu, Zhou Jiang, Baijun Ye, Xiaoxue Chen, Yifei Zhang, Yuantao Chen, Jian Zhao, Hao Zhao|<http://arxiv.org/pdf/2405.00676v1>|**[link](https://github.com/runyiyang/sundae)**
**2024-05-01**|**Depth Priors in Removal Neural Radiance Fields**|去除神经辐射场中的深度先验|Zhihao Guo, Peng Wang|<http://arxiv.org/pdf/2405.00630v1>|null
**2024-05-01**|**NeRF-Guided Unsupervised Learning of RGB-D Registration**|NeRF 引导的 RGB-D 配准无监督学习|Zhinan Yu, Zheng Qin, Yijie Tang, Yongjun Wang, Renjiao Yi, Chenyang Zhu, Kai Xu|<http://arxiv.org/pdf/2405.00507v1>|null

## 模型压缩/优化

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-01**|**LOTUS: Improving Transformer Efficiency with Sparsity Pruning and Data Lottery Tickets**|LOTUS：通过稀疏剪枝和数据彩票提高变压器效率|Ojasw Upadhyay|<http://arxiv.org/pdf/2405.00906v1>|null
**2024-05-01**|**Wake Vision: A Large-scale, Diverse Dataset and Benchmark Suite for TinyML Person Detection**|Wake Vision：用于 TinyML 人员检测的大规模、多样化数据集和基准套件|Colby Banbury, Emil Njor, Matthew Stewart, Pete Warden, Manjunath Kudlur, Nat Jeffries, Xenofon Fafoutis, Vijay Janapa Reddi|<http://arxiv.org/pdf/2405.00892v1>|null
**2024-05-01**|**CrossMatch: Enhance Semi-Supervised Medical Image Segmentation with Perturbation Strategies and Knowledge Distillation**|CrossMatch：通过扰动策略和知识蒸馏增强半监督医学图像分割|Bin Zhao, Chunshi Wang, Shuxue Ding|<http://arxiv.org/pdf/2405.00354v1>|**[link](https://github.com/aieson/crossmatch)**
**2024-05-01**|**Model Quantization and Hardware Acceleration for Vision Transformers: A Comprehensive Survey**|视觉转换器的模型量化和硬件加速：综合调查|Dayou Du, Gu Gong, Xiaowen Chu|<http://arxiv.org/pdf/2405.00314v1>|**[link](https://github.com/dd-duda/awesome-vit-quantization-acceleration)**

## 分类/检测/识别/分割/...

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-01**|**Brighteye: Glaucoma Screening with Color Fundus Photographs based on Vision Transformer**|Brighteye：基于 Vision Transformer 的彩色眼底照片筛查青光眼|Hui Lin, Charilaos Apostolidis, Aggelos K. Katsaggelos|<http://arxiv.org/pdf/2405.00857v1>|null
**2024-05-01**|**CLIPArTT: Light-weight Adaptation of CLIP to New Domains at Test Time**|CLIPArTT：CLIP 在测试时轻量级适应新领域|Gustavo Adolfo Vargas Hakim, David Osowiechi, Mehrdad Noori, Milad Cheraghalikhani, Ali Bahri, Moslem Yazdanpanah, Ismail Ben Ayed, Christian Desrosiers|<http://arxiv.org/pdf/2405.00754v1>|null
**2024-05-01**|**Grains of Saliency: Optimizing Saliency-based Training of Biometric Attack Detection Models**|显著性粒度：优化基于显著性的生物特征攻击检测模型训练|Colton R. Crum, Samuel Webster, Adam Czajka|<http://arxiv.org/pdf/2405.00650v1>|null
**2024-05-01**|**GraCo: Granularity-Controllable Interactive Segmentation**|GraCo：粒度可控的交互式分割|Yian Zhao, Kehan Li, Zesen Cheng, Pengchong Qiao, Xiawu Zheng, Rongrong Ji, Chang Liu, Li Yuan, Jie Chen|<http://arxiv.org/pdf/2405.00587v1>|null
**2024-05-01**|**DmADs-Net: Dense multiscale attention and depth-supervised network for medical image segmentation**|DmADs-Net：用于医学图像分割的密集多尺度注意力和深度监督网络|Zhaojin Fu, Zheng Chen, Jinjiang Li, Lu Ren|<http://arxiv.org/pdf/2405.00472v1>|null
**2024-05-01**|**Predictive Accuracy-Based Active Learning for Medical Image Segmentation**|基于预测精度的医学图像分割主动学习|Jun Shi, Shulan Ruan, Ziqi Zhu, Minfan Zhao, Hong An, Xudong Xue, Bing Yan|<http://arxiv.org/pdf/2405.00452v1>|**[link](https://github.com/shijun18/paal-medseg)**
**2024-05-01**|**Visual and audio scene classification for detecting discrepancies in video: a baseline method and experimental protocol**|用于检测视频差异的视觉和音频场景分类：基线方法和实验协议|Konstantinos Apostolidis, Jakob Abesser, Luca Cuccovillo, Vasileios Mezaris|<http://arxiv.org/pdf/2405.00384v1>|null
**2024-05-01**|**Adaptive Bidirectional Displacement for Semi-Supervised Medical Image Segmentation**|用于半监督医学图像分割的自适应双向位移|Hanyang Chi, Jian Pang, Bingfeng Zhang, Weifeng Liu|<http://arxiv.org/pdf/2405.00378v1>|**[link](https://github.com/chy-upc/abd)**
**2024-05-01**|**Exploring Self-Supervised Vision Transformers for Deepfake Detection: A Comparative Analysis**|探索用于 Deepfake 检测的自监督视觉变压器：比较分析|Huy H. Nguyen, Junichi Yamagishi, Isao Echizen|<http://arxiv.org/pdf/2405.00355v1>|null
**2024-05-01**|**Learning High-Quality Navigation and Zooming on Omnidirectional Images in Virtual Reality**|学习虚拟现实中全向图像的高质量导航和缩放|Zidong Cao, Zhan Wang, Yexin Liu, Yan-Pei Cao, Ying Shan, Wei Zeng, Lin Wang|<http://arxiv.org/pdf/2405.00351v1>|null
**2024-05-01**|**MoPEFT: A Mixture-of-PEFTs for the Segment Anything Model**|MoPEFT：用于分段任意模型的 PEFT 混合|Rajat Sahay, Andreas Savakis|<http://arxiv.org/pdf/2405.00293v1>|null
**2024-05-01**|**Using Texture to Classify Forests Separately from Vegetation**|使用纹理将森林与植被分开分类|David R. Treadwell IV, Derek Jacoby, Will Parkinson, Bruce Maxwell, Yvonne Coady|<http://arxiv.org/pdf/2405.00264v1>|null

## OCR

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-01**|**CREPE: Coordinate-Aware End-to-End Document Parser**|CREPE：坐标感知的端到端文档解析器|Yamato Okamoto, Youngmin Baek, Geewook Kim, Ryota Nakao, DongHyun Kim, Moon Bin Yim, Seunghyun Park, Bado Lee|<http://arxiv.org/pdf/2405.00260v1>|null

## 图像理解

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-01**|**Spherical Linear Interpolation and Text-Anchoring for Zero-shot Composed Image Retrieval**|用于零样本合成图像检索的球面线性插值和文本锚定|Young Kyun Jang, Dat Huynh, Ashish Shah, Wen-Kai Chen, Ser-Nam Lim|<http://arxiv.org/pdf/2405.00571v1>|null

## Transformer

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-01**|**Learning to Compose: Improving Object Centric Learning by Injecting Compositionality**|学习组合：通过注入组合性来改进以对象为中心的学习|Whie Jung, Jaehoon Yoo, Sungjin Ahn, Seunghoon Hong|<http://arxiv.org/pdf/2405.00646v1>|**[link](https://github.com/whieya/learning-to-compose)**
**2024-05-01**|**NC-SDF: Enhancing Indoor Scene Reconstruction Using Neural SDFs with View-Dependent Normal Compensation**|NC-SDF：使用具有视图相关法线补偿的神经 SDF 增强室内场景重建|Ziyi Chen, Xiaolong Wu, Yu Zhang|<http://arxiv.org/pdf/2405.00340v1>|null

## 各类学习方式

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-01**|**Feature-Aware Noise Contrastive Learning For Unsupervised Red Panda Re-Identification**|用于无监督小熊猫重新识别的特征感知噪声对比学习|Jincheng Zhang, Qijun Zhao, Tie Liu|<http://arxiv.org/pdf/2405.00468v1>|null

## 其他

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-01**|**More is Better: Deep Domain Adaptation with Multiple Sources**|多多益善：多源深度域自适应|Sicheng Zhao, Hui Chen, Hu Huang, Pengfei Xu, Guiguang Ding|<http://arxiv.org/pdf/2405.00749v1>|null
**2024-05-01**|**Adapting Pretrained Networks for Image Quality Assessment on High Dynamic Range Displays**|采用预训练网络进行高动态范围显示器的图像质量评估|Andrei Chubarau, Hyunjin Yoo, Tara Akhavan, James Clark|<http://arxiv.org/pdf/2405.00670v1>|null
**2024-05-01**|**A Preprocessing and Evaluation Toolbox for Trajectory Prediction Research on the Drone Datasets**|用于无人机数据集轨迹预测研究的预处理和评估工具箱|Theodor Westny, Björn Olofsson, Erik Frisk|<http://arxiv.org/pdf/2405.00604v1>|**[link](https://github.com/westny/dronalize)**
**2024-05-01**|**Are Models Biased on Text without Gender-related Language?**|模型是否对没有性别相关语言的文本存在偏见？|Catarina G Belém, Preethi Seshadri, Yasaman Razeghi, Sameer Singh|<http://arxiv.org/pdf/2405.00588v1>|**[link](https://github.com/ucinlp/unstereo-eval)**
**2024-05-01**|**GAD-Generative Learning for HD Map-Free Autonomous Driving**|GAD-无高清地图自动驾驶生成学习|Weijian Sun, Yanbo Jia, Qi Zeng, Zihao Liu, Jiang Liao, Yue Li, Xianfeng Li, Bolin Zhao|<http://arxiv.org/pdf/2405.00515v1>|null
**2024-05-01**|**Get Your Embedding Space in Order: Domain-Adaptive Regression for Forest Monitoring**|整理嵌入空间：用于森林监测的域自适应回归|Sizhuo Li, Dimitri Gominski, Martin Brandt, Xiaoye Tong, Philippe Ciais|<http://arxiv.org/pdf/2405.00514v1>|null
**2024-05-01**|**The Pyramid of Captions**|字幕金字塔|Delong Chen, Samuel Cahyawijaya, Etsuko Ishii, Ho Shu Chan, Yejin Bang, Pascale Fung|<http://arxiv.org/pdf/2405.00485v1>|null
**2024-05-01**|**Covariant spatio-temporal receptive fields for neuromorphic computing**|神经形态计算的协变时空感受野|Jens Egholm Pedersen, Jörg Conradt, Tony Lindeberg|<http://arxiv.org/pdf/2405.00318v1>|**[link](https://github.com/jegp/nrf)**

