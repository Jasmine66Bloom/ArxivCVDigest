## [UPDATED!] **2024-05-28** (Publish Time)

## 生成模型

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-28**|**DiG: Scalable and Efficient Diffusion Models with Gated Linear Attention**|DiG：具有门控线性注意的可扩展且高效的扩散模型|Lianghui Zhu, Zilong Huang, Bencheng Liao, Jun Hao Liew, Hanshu Yan, Jiashi Feng, Xinggang Wang|<http://arxiv.org/pdf/2405.18428v1>|**[link](https://github.com/hustvl/dig)**
**2024-05-28**|**Phased Consistency Model**|阶段一致性模型|Fu-Yun Wang, Zhaoyang Huang, Alexander William Bergman, Dazhong Shen, Peng Gao, Michael Lingelbach, Keqiang Sun, Weikang Bian, Guanglu Song, Yu Liu, et.al.|<http://arxiv.org/pdf/2405.18407v1>|null
**2024-05-28**|**RACCooN: Remove, Add, and Change Video Content with Auto-Generated Narratives**|RACCooN：使用自动生成的叙述删除、添加和更改视频内容|Jaehong Yoon, Shoubin Yu, Mohit Bansal|<http://arxiv.org/pdf/2405.18406v1>|null
**2024-05-28**|**Is a 3D-Tokenized LLM the Key to Reliable Autonomous Driving?**|3D 代币化的 LLM 是可靠自动驾驶的关键吗？|Yifan Bai, Dongming Wu, Yingfei Liu, Fan Jia, Weixin Mao, Ziheng Zhang, Yucheng Zhao, Jianbing Shen, Xing Wei, Tiancai Wang, et.al.|<http://arxiv.org/pdf/2405.18361v1>|null
**2024-05-28**|**Universal and Extensible Language-Vision Models for Organ Segmentation and Tumor Detection from Abdominal Computed Tomography**|用于腹部计算机断层扫描器官分割和肿瘤检测的通用且可扩展的语言视觉模型|Jie Liu, Yixiao Zhang, Kang Wang, Mehmet Can Yavuz, Xiaoxi Chen, Yixuan Yuan, Haoliang Li, Yang Yang, Alan Yuille, Yucheng Tang, et.al.|<http://arxiv.org/pdf/2405.18356v1>|**[link](https://github.com/ljwztc/clip-driven-universal-model)**
**2024-05-28**|**Self-Supervised Learning Based Handwriting Verification**|基于自监督学习的笔迹验证|Mihir Chauhan, Mohammad Abuzar Shaikh, Bina Ramamurthy, Mingchen Gao, Siwei Lyu, Sargur Srihari|<http://arxiv.org/pdf/2405.18320v1>|**[link](https://github.com/mihir2/ssl-hv)**
**2024-05-28**|**Multi-modal Generation via Cross-Modal In-Context Learning**|通过跨模态上下文学习实现多模态生成|Amandeep Kumar, Muzammal Naseer, Sanath Narayan, Rao Muhammad Anwer, Salman Khan, Hisham Cholakkal|<http://arxiv.org/pdf/2405.18304v1>|**[link](https://github.com/virobo-15/mgcc)**
**2024-05-28**|**CT-based brain ventricle segmentation via diffusion Schrödinger Bridge without target domain ground truths**|通过扩散薛定谔桥进行基于 CT 的脑室分割（无目标域基本事实）|Reihaneh Teimouri, Marta Kersten-Oertel, Yiming Xiao|<http://arxiv.org/pdf/2405.18267v1>|null
**2024-05-28**|**Confidence-aware multi-modality learning for eye disease screening**|用于眼病筛查的置信感知多模态学习|Ke Zou, Tian Lin, Zongbo Han, Meng Wang, Xuedong Yuan, Haoyu Chen, Changqing Zhang, Xiaojing Shen, Huazhu Fu|<http://arxiv.org/pdf/2405.18167v1>|**[link](https://github.com/cocofeat/eyemost)**
**2024-05-28**|**EG4D: Explicit Generation of 4D Object without Score Distillation**|EG4D：无需分数提炼即可显式生成 4D 对象|Qi Sun, Zhiyang Guo, Ziyu Wan, Jing Nathan Yan, Shengming Yin, Wengang Zhou, Jing Liao, Houqiang Li|<http://arxiv.org/pdf/2405.18132v1>|null
**2024-05-28**|**Are Image Distributions Indistinguishable to Humans Indistinguishable to Classifiers?**|图像分布对人类来说是否难以区分，对分类器来说是否也无法区分？|Zebin You, Xinyu Zhang, Hanzhong Guo, Jingdong Wang, Chongxuan Li|<http://arxiv.org/pdf/2405.18029v1>|null
**2024-05-28**|**Unveiling the Power of Diffusion Features For Personalized Segmentation and Retrieval**|揭示扩散特征在个性化分割和检索中的威力|Dvir Samuel, Rami Ben-Ari, Matan Levy, Nir Darshan, Gal Chechik|<http://arxiv.org/pdf/2405.18025v1>|null
**2024-05-28**|**MAVIN: Multi-Action Video Generation with Diffusion Models via Transition Video Infilling**|MAVIN：通过过渡视频填充实现具有扩散模型的多动作视频生成|Bowen Zhang, Xiaofei Xie, Haotian Lu, Na Ma, Tianlin Li, Qing Guo|<http://arxiv.org/pdf/2405.18003v1>|**[link](https://github.com/18445864529/mavin)**
**2024-05-28**|**AttenCraft: Attention-guided Disentanglement of Multiple Concepts for Text-to-Image Customization**|AttenCraft：通过注意力引导解开多个概念以实现文本到图像的定制|Junjie Shentu, Matthew Watson, Noura Al Moubayed|<http://arxiv.org/pdf/2405.17965v1>|null
**2024-05-28**|**SarcNet: A Novel AI-based Framework to Automatically Analyze and Score Sarcomere Organizations in Fluorescently Tagged hiPSC-CMs**|SarcNet：一种基于 AI 的新型框架，用于自动分析和评分荧光标记的 hiPSC-CM 中的肌节组织|Huyen Le, Khiet Dang, Tien Lai, Nhung Nguyen, Mai Tran, Hieu Pham|<http://arxiv.org/pdf/2405.17926v1>|**[link](https://github.com/vinuni-vishc/sarcnet)**
**2024-05-28**|**Cycle-YOLO: A Efficient and Robust Framework for Pavement Damage Detection**|Cycle-YOLO：一种高效且稳健的路面损坏检测框架|Zhengji Li, Xi Xiao, Jiacheng Xie, Yuxiao Fan, Wentao Wang, Gang Chen, Liqiang Zhang, Tianyang Wang|<http://arxiv.org/pdf/2405.17905v1>|null
**2024-05-28**|**MixDQ: Memory-Efficient Few-Step Text-to-Image Diffusion Models with Metric-Decoupled Mixed Precision Quantization**|MixDQ：具有度量解耦混合精度量化的内存高效型少步文本到图像扩散模型|Tianchen Zhao, Xuefei Ning, Tongcheng Fang, Enshu Liu, Guyue Huang, Zinan Lin, Shengen Yan, Guohao Dai, Yu Wang|<http://arxiv.org/pdf/2405.17873v1>|null
**2024-05-28**|**Discriminator-Guided Cooperative Diffusion for Joint Audio and Video Generation**|用于音频和视频联合生成的鉴别器引导的协同扩散|Akio Hayakawa, Masato Ishii, Takashi Shibuya, Yuki Mitsufuji|<http://arxiv.org/pdf/2405.17842v1>|null
**2024-05-28**|**Diffusion Model Patching via Mixture-of-Prompts**|通过混合提示进行扩散模型修补|Seokil Ham, Sangmin Woo, Jin-Young Kim, Hyojun Go, Byeongjun Park, Changick Kim|<http://arxiv.org/pdf/2405.17825v1>|null
**2024-05-28**|**MindFormer: A Transformer Architecture for Multi-Subject Brain Decoding via fMRI**|MindFormer：一种通过 fMRI 进行多受试者大脑解码的 Transformer 架构|Inhwa Han, Jaayeon Lee, Jong Chul Ye|<http://arxiv.org/pdf/2405.17720v1>|null

## 多模态

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-28**|**Empowering Source-Free Domain Adaptation with MLLM-driven Curriculum Learning**|通过 MLLM 驱动的课程学习实现无源域适应|Dongjie Chen, Kartik Patwari, Zhengfeng Lai, Sen-ching Cheung, Chen-Nee Chuah|<http://arxiv.org/pdf/2405.18376v1>|**[link](https://github.com/Dong-Jie-Chen/RCL)**
**2024-05-28**|**MMCTAgent: Multi-modal Critical Thinking Agent Framework for Complex Visual Reasoning**|MMCTAgent：用于复杂视觉推理的多模态批判性思维代理框架|Somnath Kumar, Yash Gadhia, Tanuja Ganu, Akshay Nambi|<http://arxiv.org/pdf/2405.18358v1>|null
**2024-05-28**|**SkinCAP: A Multi-modal Dermatology Dataset Annotated with Rich Medical Captions**|SkinCAP：带有丰富医学说明的多模态皮肤病学数据集|Juexiao Zhou, Liyuan Sun, Yan Xu, Wenbin Liu, Shawn Afvari, Zhongyi Han, Jiaoyan Song, Yongzhi Ji, Xiaonan He, Xin Gao|<http://arxiv.org/pdf/2405.18004v1>|null
**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|可转移多模态感知的自监督预训练|Xiaohao Xu, Tianyi Zhang, Jinrong Yang, Matthew Johnson-Roberson, Xiaonan Huang|<http://arxiv.org/pdf/2405.17942v1>|null
**2024-05-28**|**The Evolution of Multimodal Model Architectures**|多模态模型架构的演变|Shakti N. Wadekar, Abhishek Chaurasia, Aman Chadha, Eugenio Culurciello|<http://arxiv.org/pdf/2405.17927v1>|null
**2024-05-28**|**Reliable Object Tracking by Multimodal Hybrid Feature Extraction and Transformer-Based Fusion**|通过多模态混合特征提取和基于 Transformer 的融合实现可靠的对象跟踪|Hongze Sun, Rui Liu, Wuque Cai, Jun Wang, Yue Wang, Huajin Tang, Yan Cui, Dezhong Yao, Daqing Guo|<http://arxiv.org/pdf/2405.17903v1>|null
**2024-05-28**|**White-box Multimodal Jailbreaks Against Large Vision-Language Models**|针对大型视觉语言模型的白盒多模式越狱|Ruofan Wang, Xingjun Ma, Hanxu Zhou, Chuanjun Ji, Guangnan Ye, Yu-Gang Jiang|<http://arxiv.org/pdf/2405.17894v1>|null
**2024-05-28**|**Seeing the Image: Prioritizing Visual Correlation by Contrastive Alignment**|看图像：通过对比对齐优先考虑视觉相关性|Xin Xiao, Bohong Wu, Jiacong Wang, Chunyuan Li, Xun Zhou, Haoyuan Guo|<http://arxiv.org/pdf/2405.17871v1>|null
**2024-05-28**|**mTREE: Multi-Level Text-Guided Representation End-to-End Learning for Whole Slide Image Analysis**|mTREE：用于全幻灯片图像分析的多级文本引导表示端到端学习|Quan Liu, Ruining Deng, Can Cui, Tianyuan Yao, Vishwesh Nath, Yucheng Tang, Yuankai Huo|<http://arxiv.org/pdf/2405.17824v1>|null
**2024-05-28**|**Visual Anchors Are Strong Information Aggregators For Multimodal Large Language Model**|视觉锚点是多模态大型语言模型的强大信息聚合器|Haogeng Liu, Quanzeng You, Xiaotian Han, Yongfei Liu, Huaibo Huang, Ran He, Hongxia Yang|<http://arxiv.org/pdf/2405.17815v1>|null
**2024-05-28**|**PTM-VQA: Efficient Video Quality Assessment Leveraging Diverse PreTrained Models from the Wild**|PTM-VQA：利用来自外部的多种预训练模型进行高效的视频质量评估|Kun Yuan, Hongbo Liu, Mading Li, Muyi Sun, Ming Sun, Jiachao Gong, Jinhua Hao, Chao Zhou, Yansong Tang|<http://arxiv.org/pdf/2405.17765v1>|null
**2024-05-28**|**MMPareto: Boosting Multimodal Learning with Innocent Unimodal Assistance**|MMPreto：通过无害的单模式辅助促进多模式学习|Yake Wei, Di Hu|<http://arxiv.org/pdf/2405.17730v1>|**[link](https://github.com/gewu-lab/mmpareto_icml2024)**

## Nerf

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-28**|**NeRAF: 3D Scene Infused Neural Radiance and Acoustic Fields**|NeRAF：3D 场景融合神经辐射和声场|Amandine Brunetto, Sascha Hornauer, Fabien Moutarde|<http://arxiv.org/pdf/2405.18213v1>|null
**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|用于高质量动态场景重建的精细三维高斯表示|Bin Zhang, Bi Zeng, Zexin Peng|<http://arxiv.org/pdf/2405.17891v1>|null
**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|HFGS：4D 高斯溅射，重点关注内窥镜场景重建的空间和时间高频分量|Haoyu Zhao, Xingyue Zhao, Lingting Zhu, Weixi Zheng, Yongchao Xu|<http://arxiv.org/pdf/2405.17872v1>|null
**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Mani-GS：使用三角网格进行高斯溅射操作|Xiangjun Gao, Xiaoyu Li, Yiyu Zhuang, Qi Zhang, Wenbo Hu, Chaopeng Zhang, Yao Yao, Ying Shan, Long Quan|<http://arxiv.org/pdf/2405.17811v1>|null

## 3DGS

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-28**|**GFlow: Recovering 4D World from Monocular Video**|GFlow：从单目视频恢复 4D 世界|Shizun Wang, Xingyi Yang, Qiuhong Shen, Zhenxiang Jiang, Xinchao Wang|<http://arxiv.org/pdf/2405.18426v1>|null
**2024-05-28**|**3DitScene: Editing Any Scene via Language-guided Disentangled Gaussian Splatting**|3DitScene：通过语言引导的解缠高斯溅射编辑任何场景|Qihang Zhang, Yinghao Xu, Chaoyang Wang, Hsin-Ying Lee, Gordon Wetzstein, Bolei Zhou, Ceyuan Yang|<http://arxiv.org/pdf/2405.18424v1>|null
**2024-05-28**|**3D StreetUnveiler with Semantic-Aware 2DGS**|具有语义感知 2DGS 的 3D StreetUnveiler|Jingwei Xu, Yikai Wang, Yiqun Zhao, Yanwei Fu, Shenghua Gao|<http://arxiv.org/pdf/2405.18416v1>|null
**2024-05-28**|**RT-GS2: Real-Time Generalizable Semantic Segmentation for 3D Gaussian Representations of Radiance Fields**|RT-GS2：辐射场 3D 高斯表示的实时可泛化语义分割|Mihnea-Bogdan Jurca, Remco Royen, Ion Giosan, Adrian Munteanu|<http://arxiv.org/pdf/2405.18033v1>|null
**2024-05-28**|**FreeSplat: Generalizable 3D Gaussian Splatting Towards Free-View Synthesis of Indoor Scenes**|FreeSplat：面向室内场景自由视角合成的通用 3D 高斯分层|Yunsong Wang, Tianxin Huang, Hanlin Chen, Gim Hee Lee|<http://arxiv.org/pdf/2405.17958v1>|**[link](https://github.com/wangys16/freesplat)**
**2024-05-28**|**Deform3DGS: Flexible Deformation for Fast Surgical Scene Reconstruction with Gaussian Splatting**|Deform3DGS：利用高斯溅射实现快速手术场景重建的灵活变形|Shuojue Yang, Qian Li, Daiyun Shen, Bingchen Gong, Qi Dou, Yueming Jin|<http://arxiv.org/pdf/2405.17835v1>|**[link](https://github.com/jinlab-imvr/deform3dgs)**
**2024-05-28**|**SafeguardGS: 3D Gaussian Primitive Pruning While Avoiding Catastrophic Scene Destruction**|SafeguardGS：避免灾难性场景破坏的 3D 高斯基元剪枝|Yongjae Lee, Zhaoliang Zhang, Deliang Fan|<http://arxiv.org/pdf/2405.17793v1>|null

## 模型压缩/优化

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-28**|**Deep Network Pruning: A Comparative Study on CNNs in Face Recognition**|深度网络剪枝：CNN 在人脸识别中的比较研究|Fernando Alonso-Fernandez, Kevin Hernandez-Diaz, Jose Maria Buades Rubio, Prayag Tiwari, Josef Bigun|<http://arxiv.org/pdf/2405.18302v1>|null
**2024-05-28**|**Visualizing the loss landscape of Self-supervised Vision Transformer**|可视化自监督视觉变换器的损失情况|Youngwan Lee, Jeffrey Ryan Willette, Jonghee Kim, Sung Ju Hwang|<http://arxiv.org/pdf/2405.18042v1>|null
**2024-05-28**|**Relational Self-supervised Distillation with Compact Descriptors for Image Copy Detection**|具有紧凑描述符的关系自监督蒸馏用于图像复制检测|Juntae Kim, Sungwon Woo, Jongho Nang|<http://arxiv.org/pdf/2405.17928v1>|null
**2024-05-28**|**FAIntbench: A Holistic and Precise Benchmark for Bias Evaluation in Text-to-Image Models**|FAIntbench：文本到图像模型中偏差评估的整体而精确的基准|Hanjun Luo, Ziye Deng, Ruizhe Chen, Zuozhu Liu|<http://arxiv.org/pdf/2405.17814v1>|**[link](https://github.com/astarojth/faintbench-v1)**

## 分类/检测/识别/分割/...

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-28**|**Why are Visually-Grounded Language Models Bad at Image Classification?**|为什么基于视觉的语言模型不擅长图像分类？|Yuhui Zhang, Alyssa Unell, Xiaohan Wang, Dhruba Ghosh, Yuchang Su, Ludwig Schmidt, Serena Yeung-Levy|<http://arxiv.org/pdf/2405.18415v1>|**[link](https://github.com/yuhui-zh15/vlmclassifier)**
**2024-05-28**|**A Review and Implementation of Object Detection Models and Optimizations for Real-time Medical Mask Detection during the COVID-19 Pandemic**|COVID-19 疫情期间医用口罩实时检测的物体检测模型与优化综述与实现|Ioanna Gogou, Dimitrios Koutsomitropoulos|<http://arxiv.org/pdf/2405.18387v1>|**[link](https://github.com/joangog/object-detection)**
**2024-05-28**|**Brain Tumor Segmentation (BraTS) Challenge 2024: Meningioma Radiotherapy Planning Automated Segmentation**|脑肿瘤分割 (BraTS) 挑战赛 2024：脑膜瘤放射治疗计划自动分割|Dominic LaBella, Katherine Schumacher, Michael Mix, Kevin Leu, Shan McBurney-Lin, Pierre Nedelec, Javier Villanueva-Meyer, Jonathan Shapey, Tom Vercauteren, Kazumi Chia, et.al.|<http://arxiv.org/pdf/2405.18383v1>|null
**2024-05-28**|**The 2024 Brain Tumor Segmentation (BraTS) Challenge: Glioma Segmentation on Post-treatment MRI**|2024 年脑肿瘤分割 (BraTS) 挑战赛：治疗后 MRI 上的胶质瘤分割|Maria Correia de Verdier, Rachit Saluja, Louis Gagnon, Dominic LaBella, Ujjwall Baid, Nourel Hoda Tahon, Martha Foltyn-Dumitru, Jikai Zhang, Maram Alafif, Saif Baig, et.al.|<http://arxiv.org/pdf/2405.18368v1>|null
**2024-05-28**|**SCE-MAE: Selective Correspondence Enhancement with Masked Autoencoder for Self-Supervised Landmark Estimation**|SCE-MAE：使用蒙版自动编码器进行选择性对应增强，实现自监督地标估计|Kejia Yin, Varshanth R. Rao, Ruowei Jiang, Xudong Liu, Parham Aarabi, David B. Lindell|<http://arxiv.org/pdf/2405.18322v1>|null
**2024-05-28**|**Deep Learning Innovations for Underwater Waste Detection: An In-Depth Analysis**|水下废物检测的深度学习创新：深入分析|Jaskaran Singh Walia, Pavithra L K|<http://arxiv.org/pdf/2405.18299v1>|null
**2024-05-28**|**Intent3D: 3D Object Detection in RGB-D Scans Based on Human Intention**|Intent3D：基于人类意图的 RGB-D 扫描中的 3D 物体检测|Weitai Kang, Mengxue Qu, Jyoti Kini, Yunchao Wei, Mubarak Shah, Yan Yan|<http://arxiv.org/pdf/2405.18295v1>|null
**2024-05-28**|**MSPE: Multi-Scale Patch Embedding Prompts Vision Transformers to Any Resolution**|MSPE：多尺度补丁嵌入促使视觉转换器达到任意分辨率|Wenzhuo Liu, Fei Zhu, Shijie Ma, Cheng-Lin Liu|<http://arxiv.org/pdf/2405.18240v1>|null
**2024-05-28**|**Position Paper: Think Globally, React Locally -- Bringing Real-time Reference-based Website Phishing Detection on macOS**|立场文件：放眼全球，立足本地——在 macOS 上实现基于实时参考的网站钓鱼检测|Ivan Petrukha, Nataliia Stulova, Sergii Kryvoblotskyi|<http://arxiv.org/pdf/2405.18236v1>|null
**2024-05-28**|**SSLChange: A Self-supervised Change Detection Framework Based on Domain Adaptation**|SSLChange：基于领域自适应的自监督变化检测框架|Yitao Zhao, Turgay Celik, Nanqing Liu, Feng Gao, Heng-Chao Li|<http://arxiv.org/pdf/2405.18224v1>|null
**2024-05-28**|**Learning to Detour: Shortcut Mitigating Augmentation for Weakly Supervised Semantic Segmentation**|学习绕行：弱监督语义分割的捷径缓解增强|JuneHyoung Kwon, Eunju Lee, Yunsung Cho, YoungBin Kim|<http://arxiv.org/pdf/2405.18148v1>|null
**2024-05-28**|**Low-Resource Crop Classification from Multi-Spectral Time Series Using Lossless Compressors**|使用无损压缩器从多光谱时间序列进行低资源作物分类|Wei Cheng, Hongrui Ye, Xiao Wen, Jiachen Zhang, Jiping Xu, Feifan Zhang|<http://arxiv.org/pdf/2405.18119v1>|**[link](https://github.com/qinfengsama/compressor-based-crop-mapping)**
**2024-05-28**|**FlowSDF: Flow Matching for Medical Image Segmentation Using Distance Transforms**|FlowSDF：使用距离变换进行医学图像分割的流匹配|Lea Bogensperger, Dominik Narnhofer, Alexander Falk, Konrad Schindler, Thomas Pock|<http://arxiv.org/pdf/2405.18087v1>|null
**2024-05-28**|**Edge-guided and Class-balanced Active Learning for Semantic Segmentation of Aerial Images**|边缘引导和类别平衡主动学习用于航空图像语义分割|Lianlei Shan, Weiqiang Wang, Ke Lv, Bin Luo|<http://arxiv.org/pdf/2405.18078v1>|null
**2024-05-28**|**Text Modality Oriented Image Feature Extraction for Detecting Diffusion-based DeepFake**|面向文本模态的图像特征提取，用于检测基于扩散的 DeepFake|Di Yang, Yihao Huang, Qing Guo, Felix Juefei-Xu, Xiaojun Jia, Run Wang, Geguang Pu, Yang Liu|<http://arxiv.org/pdf/2405.18071v1>|null
**2024-05-28**|**EffoVPR: Effective Foundation Model Utilization for Visual Place Recognition**|EffoVPR：视觉位置识别的有效基础模型利用|Issar Tzachor, Boaz Lerner, Matan Levy, Michael Green, Tal Berkovitz Shalev, Gavriel Habib, Dvir Samuel, Noam Korngut Zailer, Or Shimshi, Nir Darshan, et.al.|<http://arxiv.org/pdf/2405.18065v1>|null
**2024-05-28**|**Flow-Assisted Motion Learning Network for Weakly-Supervised Group Activity Recognition**|用于弱监督群体活动识别的流辅助运动学习网络|Muhammad Adi Nugroho, Sangmin Woo, Sumin Lee, Jinyoung Park, Yooseung Wang, Donguk Kim, Changick Kim|<http://arxiv.org/pdf/2405.18012v1>|null
**2024-05-28**|**DMT-JEPA: Discriminative Masked Targets for Joint-Embedding Predictive Architecture**|DMT-JEPA：用于联合嵌入预测架构的判别掩蔽目标|Shentong Mo, Sukmin Yun|<http://arxiv.org/pdf/2405.17995v1>|null
**2024-05-28**|**Boosting General Trimap-free Matting in the Real-World Image**|增强现实世界图像中的通用无三元抠图|Leo Shan Wenzhang Zhou Grace Zhao|<http://arxiv.org/pdf/2405.17916v1>|null
**2024-05-28**|**OV-DQUO: Open-Vocabulary DETR with Denoising Text Query Training and Open-World Unknown Objects Supervision**|OV-DQUO：具有去噪文本查询训练和开放世界未知对象监督的开放词汇 DETR|Junjie Wang, Bin Chen, Bin Kang, Yulin Li, YiChi Chen, Weizhi Xian, Huifeng Chang|<http://arxiv.org/pdf/2405.17913v1>|**[link](https://github.com/xiaomoguhz/ov-dquo)**
**2024-05-28**|**Adapting Pre-Trained Vision Models for Novel Instance Detection and Segmentation**|调整预训练视觉模型以实现新实例检测和分割|Yangxiao Lu, Jishnu Jaykumar P, Yunhui Guo, Nicholas Ruozzi, Yu Xiang|<http://arxiv.org/pdf/2405.17859v1>|**[link](https://github.com/youngsean/nids-net)**
**2024-05-28**|**Pursuing Feature Separation based on Neural Collapse for Out-of-Distribution Detection**|基于神经折叠的特征分离实现分布外检测|Yingwen Wu, Ruiji Yu, Xinwen Cheng, Zhengbao He, Xiaolin Huang|<http://arxiv.org/pdf/2405.17816v1>|null
**2024-05-28**|**Enhancing Road Safety: Real-Time Detection of Driver Distraction through Convolutional Neural Networks**|提高道路安全：通过卷积神经网络实时检测驾驶员分心|Amaan Aijaz Sheikh, Imaad Zaffar Khan|<http://arxiv.org/pdf/2405.17788v1>|null
**2024-05-28**|**Towards a Generalist and Blind RGB-X Tracker**|面向通用且盲目的 RGB-X 追踪器|Yuedong Tan, Zongwei Wu, Yuqian Fu, Zhuyun Zhou, Guolei Sun, Chao Ma, Danda Pani Paudel, Luc Van Gool, Radu Timofte|<http://arxiv.org/pdf/2405.17773v1>|null
**2024-05-28**|**Motion-Informed Deep Learning for Brain MR Image Reconstruction Framework**|基于运动信息的深度学习脑磁共振图像重建框架|Zhifeng Chen, Kamlesh Pawar, Kh Tohidul Islam, Himashi Peiris, Gary Egan, Zhaolin Chen|<http://arxiv.org/pdf/2405.17756v1>|null
**2024-05-28**|**Hierarchical Action Recognition: A Contrastive Video-Language Approach with Hierarchical Interactions**|分层动作识别：具有分层交互的对比视频语言方法|Rui Zhang, Shuailong Li, Junxiao Xue, Feng Lin, Qing Zhang, Xiao Ma, Xiaoran Yan|<http://arxiv.org/pdf/2405.17729v1>|null
**2024-05-28**|**EgoNCE++: Do Egocentric Video-Language Models Really Understand Hand-Object Interactions?**|EgoNCE++：以自我为中心的视频语言模型真的能理解手与物体的交互吗？|Boshen Xu, Ziheng Wang, Yang Du, Sipeng Zheng, Zhinan Song, Qin Jin|<http://arxiv.org/pdf/2405.17719v1>|**[link](https://github.com/xuboshen/egoncepp)**

## LLM

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-28**|**VeLoRA: Memory Efficient Training using Rank-1 Sub-Token Projections**|VeLoRA：使用 Rank-1 子标记投影进行内存高效训练|Roy Miles, Pradyumna Reddy, Ismail Elezi, Jiankang Deng|<http://arxiv.org/pdf/2405.17991v1>|null

## Transformer

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-28**|**ViG: Linear-complexity Visual Sequence Learning with Gated Linear Attention**|ViG：具有门控线性注意的线性复杂度视觉序列学习|Bencheng Liao, Xinggang Wang, Lianghui Zhu, Qian Zhang, Chang Huang|<http://arxiv.org/pdf/2405.18425v1>|**[link](https://github.com/hustvl/vig)**
**2024-05-28**|**VITON-DiT: Learning In-the-Wild Video Try-On from Human Dance Videos via Diffusion Transformers**|VITON-DiT：通过扩散变压器从人类舞蹈视频中学习野外视频试穿|Jun Zheng, Fuwei Zhao, Youjiang Xu, Xin Dong, Xiaodan Liang|<http://arxiv.org/pdf/2405.18326v1>|null
**2024-05-28**|**In-Context Symmetries: Self-Supervised Learning through Contextual World Models**|上下文对称性：通过上下文世界模型进行自我监督学习|Sharut Gupta, Chenyu Wang, Yifei Wang, Tommi Jaakkola, Stefanie Jegelka|<http://arxiv.org/pdf/2405.18193v1>|null
**2024-05-28**|**AnyFit: Controllable Virtual Try-on for Any Combination of Attire Across Any Scenario**|AnyFit：可控虚拟试穿，适合任何场景的任意服装组合|Yuhan Li, Hao Zhou, Wenxiang Shang, Ran Lin, Xuanhong Chen, Bingbing Ni|<http://arxiv.org/pdf/2405.18172v1>|null
**2024-05-28**|**Dual-Path Multi-Scale Transformer for High-Quality Image Deraining**|用于高质量图像去雨的双路径多尺度变换器|Huiling Zhou, Xianhao Wu, Hongming Chen|<http://arxiv.org/pdf/2405.18124v1>|null
**2024-05-28**|**Knowledge Circuits in Pretrained Transformers**|预训练 Transformer 中的知识电路|Yunzhi Yao, Ningyu Zhang, Zekun Xi, Mengru Wang, Ziwen Xu, Shumin Deng, Huajun Chen|<http://arxiv.org/pdf/2405.17969v1>|**[link](https://github.com/zjunlp/knowledgecircuits)**
**2024-05-28**|**Near-Infrared and Low-Rank Adaptation of Vision Transformers in Remote Sensing**|遥感中视觉变换器的近红外和低秩自适应|Irem Ulku, O. Ozgur Tanriover, Erdem Akagündüz|<http://arxiv.org/pdf/2405.17901v1>|null
**2024-05-28**|**Don't Miss the Forest for the Trees: Attentional Vision Calibration for Large Vision Language Models**|不要只见树木不见森林：大视觉语言模型的注意力视觉校准|Sangmin Woo, Donguk Kim, Jaehyuk Jang, Yubin Choi, Changick Kim|<http://arxiv.org/pdf/2405.17820v1>|null

## 3D/CG

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-28**|**Render and Diffuse: Aligning Image and Action Spaces for Diffusion-based Behaviour Cloning**|渲染和扩散：对齐图像和动作空间以实现基于扩散的行为克隆|Vitalis Vosylius, Younggyo Seo, Jafar Uruç, Stephen James|<http://arxiv.org/pdf/2405.18196v1>|null
**2024-05-28**|**VividPose: Advancing Stable Video Diffusion for Realistic Human Image Animation**|VividPose：推进稳定的视频扩散，实现逼真的人体图像动画|Qilin Wang, Zhengkai Jiang, Chengming Xu, Jiangning Zhang, Yabiao Wang, Xinyi Zhang, Yun Cao, Weijian Cao, Chengjie Wang, Yanwei Fu|<http://arxiv.org/pdf/2405.18156v1>|null
**2024-05-28**|**A Calibration Tool for Refractive Underwater Vision**|折射水下视觉校准工具|Felix Seegräber, Mengkun She, Felix Woelk, Kevin Köser|<http://arxiv.org/pdf/2405.18018v1>|null
**2024-05-28**|**ToonCrafter: Generative Cartoon Interpolation**|ToonCrafter：生成卡通插值|Jinbo Xing, Hanyuan Liu, Menghan Xia, Yong Zhang, Xintao Wang, Ying Shan, Tien-Tsin Wong|<http://arxiv.org/pdf/2405.17933v1>|null
**2024-05-28**|**Color Shift Estimation-and-Correction for Image Enhancement**|用于图像增强的色彩偏移估计和校正|Yiyu Li, Ke Xu, Gerhard Petrus Hancke, Rynson W. H. Lau|<http://arxiv.org/pdf/2405.17725v1>|**[link](https://github.com/yiyulics/csec)**

## 各类学习方式

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-28**|**SketchQL Demonstration: Zero-shot Video Moment Querying with Sketches**|SketchQL 演示：使用 Sketches 进行零镜头视频时刻查询|Renzhi Wu, Pramod Chunduri, Dristi J Shah, Ashmitha Julius Aravind, Ali Payani, Xu Chu, Joy Arulraj, Kexin Rong|<http://arxiv.org/pdf/2405.18334v1>|null
**2024-05-28**|**Text-only Synthesis for Image Captioning**|用于图像字幕的纯文本合成|Qing Zhou, Junlin Huang, Qiang Li, Junyu Gao, Qi Wang|<http://arxiv.org/pdf/2405.18258v1>|null
**2024-05-28**|**Bridging Mini-Batch and Asymptotic Analysis in Contrastive Learning: From InfoNCE to Kernel-Based Losses**|对比学习中小批量和渐近分析的衔接：从 InfoNCE 到基于核的损失|Panagiotis Koromilas, Giorgos Bouritsas, Theodoros Giannakopoulos, Mihalis Nicolaou, Yannis Panagakis|<http://arxiv.org/pdf/2405.18045v1>|**[link](https://github.com/pakoromilas/dhel-kcl)**
**2024-05-28**|**Gradually Vanishing Gap in Prototypical Network for Unsupervised Domain Adaptation**|原型网络中无监督域适应的逐渐消失差距|Shanshan Wang, Hao Zhou, Xun Yang, Zhenwei He, Mengzhu Wang, Xingyi Zhang, Meng Wang|<http://arxiv.org/pdf/2405.17774v1>|null

## 其他

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-28**|**Hierarchical World Models as Visual Whole-Body Humanoid Controllers**|分层世界模型作为视觉全身人形控制器|Nicklas Hansen, Jyothir S V, Vlad Sobal, Yann LeCun, Xiaolong Wang, Hao Su|<http://arxiv.org/pdf/2405.18418v1>|null
**2024-05-28**|**Towards a Sampling Theory for Implicit Neural Representations**|隐性神经表征的采样理论|Mahrokh Najaf, Gregory Ongie|<http://arxiv.org/pdf/2405.18410v1>|null
**2024-05-28**|**WIDIn: Wording Image for Domain-Invariant Representation in Single-Source Domain Generalization**|WIDIn：单源域泛化中域不变表示的措辞图像|Jiawei Ma, Yulei Niu, Shiyuan Huang, Guangxing Han, Shih-Fu Chang|<http://arxiv.org/pdf/2405.18405v1>|null
**2024-05-28**|**Frustratingly Easy Test-Time Adaptation of Vision-Language Models**|视觉语言模型的测试时间适配令人沮丧地简单|Matteo Farina, Gianni Franchi, Giovanni Iacca, Massimiliano Mancini, Elisa Ricci|<http://arxiv.org/pdf/2405.18330v1>|**[link](https://github.com/farinamatteo/zero)**
**2024-05-28**|**Histopathology Based AI Model Predicts Anti-Angiogenic Therapy Response in Renal Cancer Clinical Trial**|基于组织病理学的 AI 模型可预测肾癌临床试验中的抗血管生成治疗反应|Jay Jasti, Hua Zhong, Vandana Panwar, Vipul Jarmale, Jeffrey Miyata, Deyssy Carrillo, Alana Christie, Dinesh Rakheja, Zora Modrusan, Edward Ernest Kadel III, et.al.|<http://arxiv.org/pdf/2405.18327v1>|null
**2024-05-28**|**Self-Supervised Dual Contouring**|自监督双重轮廓|Ramana Sundararaman, Roman Klokov, Maks Ovsjanikov|<http://arxiv.org/pdf/2405.18131v1>|null
**2024-05-28**|**Automated Real-World Sustainability Data Generation from Images of Buildings**|根据建筑物图像自动生成现实世界可持续性数据|Peter J Bentley, Soo Ling Lim, Rajat Mathur, Sid Narang|<http://arxiv.org/pdf/2405.18064v1>|null
**2024-05-28**|**MULi-Ev: Maintaining Unperturbed LiDAR-Event Calibration**|MULi-Ev：保持不受干扰的 LiDAR 事件校准|Mathieu Cocheteux, Julien Moreau, Franck Davoine|<http://arxiv.org/pdf/2405.18021v1>|null
**2024-05-28**|**Towards Unified Robustness Against Both Backdoor and Adversarial Attacks**|实现针对后门攻击和对抗攻击的统一稳健性|Zhenxing Niu, Yuyao Sun, Qiguang Miao, Rong Jin, Gang Hua|<http://arxiv.org/pdf/2405.17929v1>|**[link](https://github.com/john-niu-07/pud)**
**2024-05-28**|**Graphomotor and Handwriting Disabilities Rating Scale (GHDRS):towards complex and objective assessment**|书写运动和书写障碍评定量表 (GHDRS)：面向复杂和客观的评估|Jiri Mekyska, Katarina Safarova, Tomas Urbanek, Jirina Bednarova, Vojtech Zvoncak, Jana Marie Havigerova, Lukas Cunek, Zoltan Galaz, Jan Mucha, Christine Klauszova, et.al.|<http://arxiv.org/pdf/2405.17886v1>|null
**2024-05-28**|**Sparsity- and Hybridity-Inspired Visual Parameter-Efficient Fine-Tuning for Medical Diagnosis**|稀疏性和混合性启发的医学诊断视觉参数高效微调|Mingyuan Liu, Lu Xu, Shengnan Liu, Jicong Zhang|<http://arxiv.org/pdf/2405.17877v1>|null
**2024-05-28**|**A Deep Neural Network Approach to Fare Evasion**|深度神经网络方法解决逃票问题|Johannes van der Vyver|<http://arxiv.org/pdf/2405.17855v1>|null
**2024-05-28**|**RITUAL: Random Image Transformations as a Universal Anti-hallucination Lever in LVLMs**|RITUAL：随机图像变换作为 LVLM 中的通用抗幻觉杠杆|Sangmin Woo, Jaehyuk Jang, Donguk Kim, Yubin Choi, Changick Kim|<http://arxiv.org/pdf/2405.17821v1>|null
**2024-05-28**|**Hyperspectral and multispectral image fusion with arbitrary resolution through self-supervised representations**|通过自监督表征实现任意分辨率的高光谱和多光谱图像融合|Ting Wang, Zipei Yan, Jizhou Li, Xile Zhao, Chao Wang, Michael Ng|<http://arxiv.org/pdf/2405.17818v1>|null
**2024-05-28**|**Benchmarking Skeleton-based Motion Encoder Models for Clinical Applications: Estimating Parkinson's Disease Severity in Walking Sequences**|对基于骨架的运动编码器模型进行临床应用基准测试：根据步行序列评估帕金森病的严重程度|Vida Adeli, Soroush Mehraban, Yasamin Zarghami, Irene Ballester, Andrea Sabo, Andrea Iaboni, Babak Taati|<http://arxiv.org/pdf/2405.17817v1>|**[link](https://github.com/taatiteam/motionencoders_parkinsonism_benchmark)**
**2024-05-28**|**Instruct-ReID++: Towards Universal Purpose Instruction-Guided Person Re-identification**|Instruct-ReID++：面向通用目的的指导性人员重新识别|Weizhen He, Yiheng Deng, Yunfeng Yan, Feng Zhu, Yizhou Wang, Lei Bai, Qingsong Xie, Donglian Qi, Wanli Ouyang, Shixiang Tang|<http://arxiv.org/pdf/2405.17790v1>|**[link](https://github.com/hwz-zju/instruct-reid)**
**2024-05-28**|**Microsaccade-inspired Event Camera for Robotics**|受微扫视启发的机器人事件相机|Botao He, Ze Wang, Yuan Zhou, Jingxi Chen, Chahat Deep Singh, Haojia Li, Yuman Gao, Shaojie Shen, Kaiwei Wang, Yanjun Cao, et.al.|<http://arxiv.org/pdf/2405.17769v1>|null
**2024-05-28**|**AdapNet: Adaptive Noise-Based Network for Low-Quality Image Retrieval**|AdapNet：用于低质量图像检索的自适应噪声网络|Sihe Zhang, Qingdong He, Jinlong Peng, Yuxi Li, Zhengkai Jiang, Jiafu Wu, Mingmin Chi, Yabiao Wang, Chengjie Wang|<http://arxiv.org/pdf/2405.17718v1>|null

