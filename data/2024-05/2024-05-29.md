## [UPDATED!] **2024-05-29** (Publish Time)

## 生成模型

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-29**|**LLMs Meet Multimodal Generation and Editing: A Survey**|法学硕士 (LLM) 满足多模式生成和编辑要求：一项调查|Yingqing He, Zhaoyang Liu, Jingye Chen, Zeyue Tian, Hongyu Liu, Xiaowei Chi, Runtao Liu, Ruibin Yuan, Yazhou Xing, Wenhai Wang, et.al.|<http://arxiv.org/pdf/2405.19334v1>|null
**2024-05-29**|**Programmable Motion Generation for Open-Set Motion Control Tasks**|用于开放式运动控制任务的可编程运动生成|Hanchao Liu, Xiaohang Zhan, Shaoli Huang, Tai-Jiang Mu, Ying Shan|<http://arxiv.org/pdf/2405.19283v1>|null
**2024-05-29**|**ConceptPrune: Concept Editing in Diffusion Models via Skilled Neuron Pruning**|ConceptPrune：通过熟练的神经元修剪在扩散模型中进行概念编辑|Ruchika Chavhan, Da Li, Timothy Hospedales|<http://arxiv.org/pdf/2405.19237v1>|null
**2024-05-29**|**VideoTree: Adaptive Tree-based Video Representation for LLM Reasoning on Long Videos**|VideoTree：基于树的自适应视频表示，用于长视频的 LLM 推理|Ziyang Wang, Shoubin Yu, Elias Stengel-Eskin, Jaehong Yoon, Feng Cheng, Gedas Bertasius, Mohit Bansal|<http://arxiv.org/pdf/2405.19209v1>|null
**2024-05-29**|**$E^{3}$Gen: Efficient, Expressive and Editable Avatars Generation**|$E^{3}$Gen：高效、富有表现力且可编辑的头像生成|Weitian Zhang, Yichao Yan, Yunhui Liu, Xingdong Sheng, Xiaokang Yang|<http://arxiv.org/pdf/2405.19203v1>|null
**2024-05-29**|**Reconstructing Interpretable Features in Computational Super-Resolution microscopy via Regularized Latent Search**|通过正则化潜在搜索重建计算超分辨率显微镜中的可解释特征|Marzieh Gheisari, Auguste Genovesio|<http://arxiv.org/pdf/2405.19112v1>|null
**2024-05-29**|**EasyAnimate: A High-Performance Long Video Generation Method based on Transformer Architecture**|EasyAnimate：基于 Transformer 架构的高性能长视频生成方法|Jiaqi Xu, Xinyi Zou, Kunzhe Huang, Yunkuo Chen, Bo Liu, MengLi Cheng, Xing Shi, Jun Huang|<http://arxiv.org/pdf/2405.18991v1>|null
**2024-05-29**|**MEGA: Masked Generative Autoencoder for Human Mesh Recovery**|MEGA：用于人体网格恢复的蒙版生成自动编码器|Guénolé Fiche, Simon Leglaive, Xavier Alameda-Pineda, Francesc Moreno-Noguer|<http://arxiv.org/pdf/2405.18839v1>|null
**2024-05-29**|**Flow Priors for Linear Inverse Problems via Iterative Corrupted Trajectory Matching**|通过迭代损坏轨迹匹配实现线性逆问题的流先验|Yasi Zhang, Peiyu Yu, Yaxuan Zhu, Yingshan Chang, Feng Gao, Ying Nian Wu, Oscar Leong|<http://arxiv.org/pdf/2405.18816v1>|null
**2024-05-29**|**MindSemantix: Deciphering Brain Visual Experiences with a Brain-Language Model**|MindSemantix：利用脑语言模型解读大脑视觉体验|Ziqi Ren, Jie Li, Xuetong Xue, Xin Li, Fan Yang, Zhicheng Jiao, Xinbo Gao|<http://arxiv.org/pdf/2405.18812v1>|null
**2024-05-29**|**Principled Probabilistic Imaging using Diffusion Models as Plug-and-Play Priors**|使用扩散模型作为即插即用先验的原理概率成像|Zihui Wu, Yu Sun, Yifan Chen, Bingliang Zhang, Yisong Yue, Katherine L. Bouman|<http://arxiv.org/pdf/2405.18782v1>|null
**2024-05-29**|**Leveraging Many-To-Many Relationships for Defending Against Visual-Language Adversarial Attacks**|利用多对多关系防御视觉语言对抗攻击|Futa Waseda, Antonio Tejero-de-Pablos|<http://arxiv.org/pdf/2405.18770v1>|null
**2024-05-29**|**Reverse the auditory processing pathway: Coarse-to-fine audio reconstruction from fMRI**|逆转听觉处理路径：从 fMRI 进行由粗到细的音频重建|Che Liu, Changde Du, Xiaoyu Chen, Huiguang He|<http://arxiv.org/pdf/2405.18726v1>|null
**2024-05-29**|**Correctable Landmark Discovery via Large Models for Vision-Language Navigation**|通过大型模型进行可纠正的视觉语言导航地标发现|Bingqian Lin, Yunshuang Nie, Ziming Wei, Yi Zhu, Hang Xu, Shikui Ma, Jianzhuang Liu, Xiaodan Liang|<http://arxiv.org/pdf/2405.18721v1>|null
**2024-05-29**|**Learning Diffeomorphism for Image Registration with Time-Continuous Networks using Semigroup Regularization**|使用半群正则化学习时间连续网络的微分同胚以实现图像配准|Mohammadjavad Matinkia, Nilanjan Ray|<http://arxiv.org/pdf/2405.18684v1>|null
**2024-05-29**|**Zero-to-Hero: Enhancing Zero-Shot Novel View Synthesis via Attention Map Filtering**|从零到英雄：通过注意力图过滤增强零样本新视图合成|Ido Sobol, Chenfeng Xu, Or Litany|<http://arxiv.org/pdf/2405.18677v1>|null

## 多模态

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-29**|**Multi-Modal Generative Embedding Model**|多模态生成嵌入模型|Feipeng Ma, Hongwei Xue, Guangting Wang, Yizhou Zhou, Fengyun Rao, Shilin Yan, Yueyi Zhang, Siying Wu, Mike Zheng Shou, Xiaoyan Sun|<http://arxiv.org/pdf/2405.19333v1>|null
**2024-05-29**|**Adaptive Image Quality Assessment via Teaching Large Multimodal Model to Compare**|通过教授大型多模态模型进行比较的自适应图像质量评估|Hanwei Zhu, Haoning Wu, Yixuan Li, Zicheng Zhang, Baoliang Chen, Lingyu Zhu, Yuming Fang, Guangtao Zhai, Weisi Lin, Shiqi Wang|<http://arxiv.org/pdf/2405.19298v1>|null
**2024-05-29**|**MetaToken: Detecting Hallucination in Image Descriptions by Meta Classification**|MetaToken：通过元分类检测图像描述中的幻觉|Laura Fieback, Jakob Spiegelberg, Hanno Gottschalk|<http://arxiv.org/pdf/2405.19186v1>|null
**2024-05-29**|**Benchmarking and Improving Detail Image Caption**|基准测试和改进细节图像说明|Hongyuan Dong, Jiawen Li, Bohong Wu, Jiacong Wang, Yuan Zhang, Haoyuan Guo|<http://arxiv.org/pdf/2405.19092v1>|null
**2024-05-29**|**Cracking the Code of Juxtaposition: Can AI Models Understand the Humorous Contradictions**|破解并置的密码：人工智能模型能理解幽默的矛盾吗|Zhe Hu, Tuo Liang, Jing Li, Yiren Lu, Yunlai Zhou, Yiran Qiao, Jing Ma, Yu Yin|<http://arxiv.org/pdf/2405.19088v1>|null
**2024-05-29**|**Cephalo: Multi-Modal Vision-Language Models for Bio-Inspired Materials Analysis and Design**|Cephalo：用于仿生材料分析和设计的多模态视觉语言模型|Markus J. Buehler|<http://arxiv.org/pdf/2405.19076v1>|null
**2024-05-29**|**Enhancing Vision-Language Model with Unmasked Token Alignment**|使用无掩码标记对齐增强视觉语言模型|Jihao Liu, Jinliang Zheng, Boxiao Liu, Yu Liu, Hongsheng Li|<http://arxiv.org/pdf/2405.19009v1>|null
**2024-05-29**|**Transcending Fusion: A Multi-Scale Alignment Method for Remote Sensing Image-Text Retrieval**|超越融合：一种用于遥感图像-文本检索的多尺度对齐方法|Rui Yang, Shuang Wang, Yingping Han, Yuanheng Li, Dong Zhao, Dou Quan, Yanhe Guo, Licheng Jiao|<http://arxiv.org/pdf/2405.18959v1>|null
**2024-05-29**|**RGB-T Object Detection via Group Shuffled Multi-receptive Attention and Multi-modal Supervision**|通过组混洗多接收注意和多模态监督进行 RGB-T 物体检测|Jinzhong Wang, Xuetao Tian, Shun Dai, Tao Zhuo, Haorui Zeng, Hongjuan Liu, Jiaqi Liu, Xiuwei Zhang, Yanning Zhang|<http://arxiv.org/pdf/2405.18955v1>|null
**2024-05-29**|**WTTFNet: A Weather-Time-Trajectory Fusion Network for Pedestrian Trajectory Prediction in Urban Complex**|WTTFNet：用于城市综合体行人轨迹预测的天气-时间-轨迹融合网络|Ho Chun Wu, Esther Hoi Shan Lau, Paul Yuen, Kevin Hung, John Kwok Tai Chui, Andrew Kwok Fai Lui|<http://arxiv.org/pdf/2405.18945v1>|null
**2024-05-29**|**Kestrel: Point Grounding Multimodal LLM for Part-Aware 3D Vision-Language Understanding**|Kestrel：用于部分感知 3D 视觉语言理解的点接地多模态法学硕士|Junjie Fei, Mahmoud Ahmed, Jian Ding, Eslam Mohamed Bakr, Mohamed Elhoseiny|<http://arxiv.org/pdf/2405.18937v1>|null
**2024-05-29**|**Evaluating Zero-Shot GPT-4V Performance on 3D Visual Question Answering Benchmarks**|在 3D 视觉问答基准上评估零样本 GPT-4V 性能|Simranjit Singh, Georgios Pavlakos, Dimitrios Stamoulis|<http://arxiv.org/pdf/2405.18831v1>|null
**2024-05-29**|**SketchTriplet: Self-Supervised Scenarized Sketch-Text-Image Triplet Generation**|SketchTriplet：自监督场景化草图-文本-图像三元组生成|Zhenbei Wu, Qiang Wang, Jie Yang|<http://arxiv.org/pdf/2405.18801v1>|null
**2024-05-29**|**On the Limits of Multi-modal Meta-Learning with Auxiliary Task Modulation Using Conditional Batch Normalization**|使用条件批量标准化进行辅助任务调节的多模态元学习的局限性|Jordi Armengol-Estapé, Vincent Michalski, Ramnath Kumar, Pierre-Luc St-Charles, Doina Precup, Samira Ebrahimi Kahou|<http://arxiv.org/pdf/2405.18751v1>|null

## Nerf

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|单眼胃镜检查中用于新视图合成的神经辐射场|Zijie Jiang, Yusuke Monno, Masatoshi Okutomi, Sho Suzuki, Kenji Miki|<http://arxiv.org/pdf/2405.18863v1>|null
**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|NeRF On-the-go：利用不确定性在野外实现无干扰的 NeRF|Weining Ren, Zihan Zhu, Boyang Sun, Jiaqi Chen, Marc Pollefeys, Songyou Peng|<http://arxiv.org/pdf/2405.18715v1>|null

## 3DGS

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-29**|**NPGA: Neural Parametric Gaussian Avatars**|NPGA：神经参数高斯化身|Simon Giebenhain, Tobias Kirschstein, Martin Rünz, Lourdes Agapito, Matthias Nießner|<http://arxiv.org/pdf/2405.19331v1>|null
**2024-05-29**|**LP-3DGS: Learning to Prune 3D Gaussian Splatting**|LP-3DGS：学习修剪 3D 高斯溅射|Zhaoliang Zhang, Tianchen Song, Yongjae Lee, Li Yang, Cheng Peng, Rama Chellappa, Deliang Fan|<http://arxiv.org/pdf/2405.18784v1>|null

## 模型压缩/优化

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-29**|**DGD: Dynamic 3D Gaussians Distillation**|DGD：动态 3D 高斯蒸馏|Isaac Labe, Noam Issachar, Itai Lang, Sagie Benaim|<http://arxiv.org/pdf/2405.19321v1>|null
**2024-05-29**|**Forward-Backward Knowledge Distillation for Continual Clustering**|用于连续聚类的前向-后向知识提炼|Mohammadreza Sadeghi, Zihan Wang, Narges Armanfard|<http://arxiv.org/pdf/2405.19234v1>|null
**2024-05-29**|**UniPTS: A Unified Framework for Proficient Post-Training Sparsity**|UniPTS：高效训练后稀疏性的统一框架|Jingjing Xie, Yuxin Zhang, Mingbao Lin, Zhihang Lin, Liujuan Cao, Rongrong Ji|<http://arxiv.org/pdf/2405.18810v1>|null
**2024-05-29**|**Provable Contrastive Continual Learning**|可证明的对比持续学习|Yichen Wen, Zhiquan Tan, Kaipeng Zheng, Chuanlong Xie, Weiran Huang|<http://arxiv.org/pdf/2405.18756v1>|null
**2024-05-29**|**T2V-Turbo: Breaking the Quality Bottleneck of Video Consistency Model with Mixed Reward Feedback**|T2V-Turbo：利用混合奖励反馈突破视频一致性模型的质量瓶颈|Jiachen Li, Weixi Feng, Tsu-Jui Fu, Xinyi Wang, Sugato Basu, Wenhu Chen, William Yang Wang|<http://arxiv.org/pdf/2405.18750v1>|null
**2024-05-29**|**PillarHist: A Quantization-aware Pillar Feature Encoder based on Height-aware Histogram**|PillarHist：基于高度感知直方图的量化感知支柱特征编码器|Sifan Zhou, Zhihang Yuan, Dawei Yang, Xubin Wen, Xing Hu, Yuguang Shi, Ziyu Zhao, Xiaobo Lu|<http://arxiv.org/pdf/2405.18734v1>|null

## 分类/检测/识别/分割/...

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-29**|**Reasoning3D -- Grounding and Reasoning in 3D: Fine-Grained Zero-Shot Open-Vocabulary 3D Reasoning Part Segmentation via Large Vision-Language Models**|Reasoning3D——3D 基础与推理：通过大型视觉语言模型进行细粒度零样本开放词汇 3D 推理部分分割|Tianrun Chen, Chunan Yu, Jing Li, Jianqi Zhang, Lanyun Zhu, Deyi Ji, Yong Zhang, Ying Zang, Zejian Li, Lingyun Sun|<http://arxiv.org/pdf/2405.19326v1>|null
**2024-05-29**|**Real-Time Environment Condition Classification for Autonomous Vehicles**|自动驾驶汽车的实时环境状况分类|Marco Introvigne, Andrea Ramazzina, Stefanie Walz, Dominik Scheuble, Mario Bijelic|<http://arxiv.org/pdf/2405.19305v1>|null
**2024-05-29**|**Contrastive-Adversarial and Diffusion: Exploring pre-training and fine-tuning strategies for sulcal identification**|对比对抗和扩散：探索脑沟识别的预训练和微调策略|Michail Mamalakis, Héloïse de Vareilles, Shun-Chin Jim Wu, Ingrid Agartz, Lynn Egeland Mørch-Johnsen, Jane Garrison, Jon Simons, Pietro Lio, John Suckling, Graham Murray|<http://arxiv.org/pdf/2405.19204v1>|null
**2024-05-29**|**LOGO: Video Text Spotting with Language Collaboration and Glyph Perception Model**|LOGO：利用语言协作和字形感知模型进行视频文本识别|Hongen Liu, Yi Liu, Di Sun, Jiahao Wang, Gang Pan|<http://arxiv.org/pdf/2405.19194v1>|null
**2024-05-29**|**Model Agnostic Defense against Adversarial Patch Attacks on Object Detection in Unmanned Aerial Vehicles**|无人机物体检测中对抗性补丁攻击的模型不可知防御|Saurabh Pathak, Samridha Shrestha, Abdelrahman AlMahmoud|<http://arxiv.org/pdf/2405.19179v1>|null
**2024-05-29**|**Exploring AI-based Anonymization of Industrial Image and Video Data in the Context of Feature Preservation**|在特征保留的背景下探索基于人工智能的工业图像和视频数据匿名化|Sabrina Cynthia Triess, Timo Leitritz, Christian Jauch|<http://arxiv.org/pdf/2405.19173v1>|null
**2024-05-29**|**Enhancing Zero-Shot Facial Expression Recognition by LLM Knowledge Transfer**|通过 LLM 知识转移增强零样本面部表情识别|Zengqun Zhao, Yu Cao, Shaogang Gong, Ioannis Patras|<http://arxiv.org/pdf/2405.19100v1>|null
**2024-05-29**|**FUSU: A Multi-temporal-source Land Use Change Segmentation Dataset for Fine-grained Urban Semantic Understanding**|FUSU：用于细粒度城市语义理解的多时间源土地利用变化分割数据集|Shuai Yuan, Guancong Lin, Lixian Zhang, Runmin Dong, Jinxiao Zhang, Shuang Chen, Juepeng Zheng, Jie Wang, Haohuan Fu|<http://arxiv.org/pdf/2405.19055v1>|null
**2024-05-29**|**A Good Foundation is Worth Many Labels: Label-Efficient Panoptic Segmentation**|良好的基础胜过许多标签：标签高效的全景分割|Niclas Vödisch, Kürsat Petek, Markus Käppeler, Abhinav Valada, Wolfram Burgard|<http://arxiv.org/pdf/2405.19035v1>|null
**2024-05-29**|**MDIW-13: a New Multi-Lingual and Multi-Script Database and Benchmark for Script Identification**|MDIW-13：一种新的多语言和多文字数据库和文字识别基准|Miguel A. Ferrer, Abhijit Das, Moises Diaz, Aythami Morales, Cristina Carmona-Duarte, Umapada Pal|<http://arxiv.org/pdf/2405.18924v1>|null
**2024-05-29**|**SSGA-Net: Stepwise Spatial Global-local Aggregation Networks for for Autonomous Driving**|SSGA-Net：用于自动驾驶的分步空间全局-本地聚合网络|Yiming Cui, Cheng Han, Dongfang Liu|<http://arxiv.org/pdf/2405.18857v1>|null
**2024-05-29**|**Supervised Contrastive Learning for Snapshot Spectral Imaging Face Anti-Spoofing**|快照光谱成像人脸防欺骗的监督对比学习|Chuanbiao Song, Yan Hong, Jun Lan, Huijia Zhu, Weiqiang Wang, Jianfu Zhang|<http://arxiv.org/pdf/2405.18853v1>|null
**2024-05-29**|**Parameter-efficient Fine-tuning in Hyperspherical Space for Open-vocabulary Semantic Segmentation**|超球面空间中用于开放词汇语义分割的参数高效微调|Zelin Peng, Zhengqin Xu, Zhilin Zeng, Yaoming Wang, Lingxi Xie, Qi Tian, Wei Shen|<http://arxiv.org/pdf/2405.18840v1>|null
**2024-05-29**|**Face processing emerges from object-trained convolutional neural networks**|面部处理源自对象训练的卷积神经网络|Zhenhua Zhao, Ji Chen, Zhicheng Lin, Haojiang Ying|<http://arxiv.org/pdf/2405.18800v1>|null
**2024-05-29**|**MOKD: Cross-domain Finetuning for Few-shot Classification via Maximizing Optimized Kernel Dependence**|MOKD：通过最大化优化核依赖性实现小样本分类的跨域微调|Hongduan Tian, Feng Liu, Tongliang Liu, Bo Du, Yiu-ming Cheung, Bo Han|<http://arxiv.org/pdf/2405.18786v1>|null
**2024-05-29**|**OUS: Scene-Guided Dynamic Facial Expression Recognition**|OUS：场景引导的动态面部表情识别|Xinji Mai, Haoran Wang, Zeng Tao, Junxiong Lin, Shaoqi Yan, Yan Wang, Jing Liu, Jiawen Yu, Xuan Tong, Yating Li, et.al.|<http://arxiv.org/pdf/2405.18769v1>|null
**2024-05-29**|**WLC-Net: a robust and fast deep-learning wood-leaf classification method**|WLC-Net：一种稳健且快速的深度学习木叶分类方法|Hanlong Li, Pei Wang, Yuhan Wu, Jing Ren, Yuhang Gao, Lingyun Zhang, Mingtai Zhang, Wenxin Chen|<http://arxiv.org/pdf/2405.18737v1>|null
**2024-05-29**|**FocSAM: Delving Deeply into Focused Objects in Segmenting Anything**|FocSAM：深入研究任何事物的细分焦点对象|You Huang, Zongyu Lan, Liujuan Cao, Xianming Lin, Shengchuan Zhang, Guannan Jiang, Rongrong Ji|<http://arxiv.org/pdf/2405.18706v1>|null
**2024-05-29**|**LLM-based Hierarchical Concept Decomposition for Interpretable Fine-Grained Image Classification**|基于 LLM 的分层概念分解，用于可解释的细粒度图像分类|Renyi Qu, Mark Yatskar|<http://arxiv.org/pdf/2405.18672v1>|null

## 图像理解

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-29**|**ContextBLIP: Doubly Contextual Alignment for Contrastive Image Retrieval from Linguistically Complex Descriptions**|ContextBLIP：从语言复杂描述中进行对比图像检索的双重上下文对齐|Honglin Lin, Siyu Li, Guoshun Nan, Chaoyue Tang, Xueting Wang, Jingxin Xu, Rong Yankai, Zhili Zhou, Yutong Gao, Qimei Cui, et.al.|<http://arxiv.org/pdf/2405.19226v1>|null
**2024-05-29**|**PanoNormal: Monocular Indoor 360° Surface Normal Estimation**|PanoNormal：单目室内 360° 表面法线估计|Kun Huang, Fanglue Zhang, Neil Dodgson|<http://arxiv.org/pdf/2405.18745v1>|null

## LLM

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-29**|**X-VILA: Cross-Modality Alignment for Large Language Model**|X-VILA：大型语言模型的跨模态对齐|Hanrong Ye, De-An Huang, Yao Lu, Zhiding Yu, Wei Ping, Andrew Tao, Jan Kautz, Song Han, Dan Xu, Pavlo Molchanov, et.al.|<http://arxiv.org/pdf/2405.19335v1>|null

## Transformer

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-29**|**Matryoshka Query Transformer for Large Vision-Language Models**|用于大型视觉语言模型的 Matryoshka 查询转换器|Wenbo Hu, Zi-Yi Dou, Liunian Harold Li, Amita Kamath, Nanyun Peng, Kai-Wei Chang|<http://arxiv.org/pdf/2405.19315v1>|null
**2024-05-29**|**CaLa: Complementary Association Learning for Augmenting Composed Image Retrieval**|CaLa：增强合成图像检索的互补关联学习|Xintong Jiang, Yaxiong Wang, Mengjian Li, Yujiao Wu, Bingwen Hu, Xueming Qian|<http://arxiv.org/pdf/2405.19149v1>|null
**2024-05-29**|**Single image super-resolution based on trainable feature matching attention network**|基于可训练特征匹配注意网络的单幅图像超分辨率|Qizhou Chen, Qing Shao|<http://arxiv.org/pdf/2405.18872v1>|null
**2024-05-29**|**SFANet: Spatial-Frequency Attention Network for Weather Forecasting**|SFANet：用于天气预报的空间频率注意力网络|Jiaze Wang, Hao Chen, Hongcan Xu, Jinpeng Li, Bowen Wang, Kun Shao, Furui Liu, Huaxi Chen, Guangyong Chen, Pheng-Ann Heng|<http://arxiv.org/pdf/2405.18849v1>|null
**2024-05-29**|**BRACTIVE: A Brain Activation Approach to Human Visual Brain Learning**|BRACTIVE：一种激活人类视觉大脑学习的方法|Xuan-Bac Nguyen, Hojin Jang, Xin Li, Samee U. Khan, Pawan Sinha, Khoa Luu|<http://arxiv.org/pdf/2405.18808v1>|null
**2024-05-29**|**SketchDeco: Decorating B&W Sketches with Colour**|SketchDeco：用颜色装饰黑白素描|Chaitat Utintu, Pinaki Nath Chowdhury, Aneeshan Sain, Subhadeep Koley, Ayan Kumar Bhunia, Yi-Zhe Song|<http://arxiv.org/pdf/2405.18716v1>|null
**2024-05-29**|**Vim-F: Visual State Space Model Benefiting from Learning in the Frequency Domain**|Vim-F：受益于频域学习的视觉状态空间模型|Juntao Zhang, Kun Bian, Peng Cheng, Wenbo An, Jianning Liu, Jun Zhou|<http://arxiv.org/pdf/2405.18679v1>|null

## 3D/CG

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-29**|**Neural Isometries: Taming Transformations for Equivariant ML**|神经等距：驯服等变机器学习的变换|Thomas W. Mitchel, Michael Taylor, Vincent Sitzmann|<http://arxiv.org/pdf/2405.19296v1>|null
**2024-05-29**|**3D Neural Edge Reconstruction**|3D 神经边缘重建|Lei Li, Songyou Peng, Zehao Yu, Shaohui Liu, Rémi Pautrat, Xiaochuan Yin, Marc Pollefeys|<http://arxiv.org/pdf/2405.19295v1>|null
**2024-05-29**|**Inpaint Biases: A Pathway to Accurate and Unbiased Image Generation**|修复偏差：实现准确、无偏差图像生成的途径|Jiyoon Myung, Jihyeon Park|<http://arxiv.org/pdf/2405.18762v1>|null
**2024-05-29**|**Multi-Condition Latent Diffusion Network for Scene-Aware Neural Human Motion Prediction**|用于场景感知神经人体运动预测的多条件潜在扩散网络|Xuehao Gao, Yang Yang, Yang Wu, Shaoyi Du, Auo-Jun Qi|<http://arxiv.org/pdf/2405.18700v1>|null

## 各类学习方式

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-29**|**Going beyond compositional generalization, DDPMs can produce zero-shot interpolation**|除了组合泛化之外，DDPM 还可以产生零样本插值|Justin Deschenaux, Igor Krawczuk, Grigorios Chrysos, Volkan Cevher|<http://arxiv.org/pdf/2405.19201v1>|null
**2024-05-29**|**Resurrecting Old Classes with New Data for Exemplar-Free Continual Learning**|利用新数据复活旧课程，实现无样本持续学习|Dipam Goswami, Albin Soutif--Cormerais, Yuyang Liu, Sandesh Kamath, Bartłomiej Twardowski, Joost van de Weijer|<http://arxiv.org/pdf/2405.19074v1>|null
**2024-05-29**|**EventZoom: A Progressive Approach to Event-Based Data Augmentation for Enhanced Neuromorphic Vision**|EventZoom：一种基于事件的数据增强渐进方法，用于增强神经形态视觉|Yiting Dong, Xiang He, Guobin Shen, Dongcheng Zhao, Yang Li, Yi Zeng|<http://arxiv.org/pdf/2405.18880v1>|null
**2024-05-29**|**LetsMap: Unsupervised Representation Learning for Semantic BEV Mapping**|LetsMap：用于语义 BEV 映射的无监督表征学习|Nikhil Gosala, Kürsat Petek, B Ravi Kiran, Senthil Yogamani, Paulo Drews-Jr, Wolfram Burgard, Abhinav Valada|<http://arxiv.org/pdf/2405.18852v1>|null
**2024-05-29**|**LLaMA-Reg: Using LLaMA 2 for Unsupervised Medical Image Registration**|LLaMA-Reg：使用 LLaMA 2 进行无监督医学图像配准|Mingrui Ma, Yu Yang|<http://arxiv.org/pdf/2405.18774v1>|null

## 其他

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-05-29**|**A study on the adequacy of common IQA measures for medical images**|医学图像常用 IQA 指标的充分性研究|Anna Breger, Clemens Karner, Ian Selby, Janek Gröhl, Sören Dittmer, Edward Lilley, Judith Babar, Jake Beckford, Timothy J Sadler, Shahab Shahipasand, et.al.|<http://arxiv.org/pdf/2405.19224v1>|null
**2024-05-29**|**ACCSAMS: Automatic Conversion of Exam Documents to Accessible Learning Material for Blind and Visually Impaired**|ACCSAMS：将考试文件自动转换为盲人和视障人士可访问的学习材料|David Wilkening, Omar Moured, Thorsten Schwarz, Karin Muller, Rainer Stiefelhagen|<http://arxiv.org/pdf/2405.19124v1>|null
**2024-05-29**|**ChartFormer: A Large Vision Language Model for Converting Chart Images into Tactile Accessible SVGs**|ChartFormer：一种将图表图像转换为触觉可访问的 SVG 的大型视觉语言模型|Omar Moured, Sara Alzalabny, Anas Osman, Thorsten Schwarz, Karin Muller, Rainer Stiefelhagen|<http://arxiv.org/pdf/2405.19117v1>|null
**2024-05-29**|**Alt4Blind: A User Interface to Simplify Charts Alt-Text Creation**|Alt4Blind：简化图表 Alt-Text 创建的用户界面|Omar Moured, Shahid Ali Farooqui, Karin Muller, Sharifeh Fadaeijouybari, Thorsten Schwarz, Mohammed Javed, Rainer Stiefelhagen|<http://arxiv.org/pdf/2405.19111v1>|null
**2024-05-29**|**Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided by a Function Prior**|通过函数先验指导的贝叶斯优化进行有效的黑盒对抗攻击|Shuyu Cheng, Yibo Miao, Yinpeng Dong, Xiao Yang, Xiao-Shan Gao, Jun Zhu|<http://arxiv.org/pdf/2405.19098v1>|null
**2024-05-29**|**A study of why we need to reassess full reference image quality assessment with medical images**|为什么我们需要用医学图像重新评估完整参考图像质量评估的研究|Anna Breger, Ander Biguri, Malena Sabaté Landman, Ian Selby, Nicole Amberg, Elisabeth Brunner, Janek Gröhl, Sepideh Hatamikia, Clemens Karner, Lipeng Ning, et.al.|<http://arxiv.org/pdf/2405.19097v1>|null
**2024-05-29**|**Patch-enhanced Mask Encoder Prompt Image Generation**|补丁增强型 Mask Encoder 快速图像生成|Shusong Xu, Peiye Liu|<http://arxiv.org/pdf/2405.19085v1>|null
**2024-05-29**|**Uniform vs. Lognormal Kinematics in Robots: Perceptual Preferences for Robotic Movements**|机器人的均匀运动与对数正态运动：机器人运动的感知偏好|Jose J. Quintana, Miguel A. Ferrer, Moises Diaz, Jose J. Feo, Adam Wolniakowski, Konstantsin Miatliuk|<http://arxiv.org/pdf/2405.19081v1>|null
**2024-05-29**|**On the Influence of Smoothness Constraints in Computed Tomography Motion Compensation**|平滑度约束对计算机断层扫描运动补偿的影响|Mareike Thies, Fabian Wagner, Noah Maul, Siyuan Mei, Mingxuan Gu, Laura Pfaff, Nastassia Vysotskaya, Haijun Yu, Andreas Maier|<http://arxiv.org/pdf/2405.19079v1>|null
**2024-05-29**|**Auto-selected Knowledge Adapters for Lifelong Person Re-identification**|自动选择知识适配器，实现终身人员重新识别|Xuelin Qian, Ruiqi Wu, Gong Cheng, Junwei Han|<http://arxiv.org/pdf/2405.19005v1>|null
**2024-05-29**|**EntProp: High Entropy Propagation for Improving Accuracy and Robustness**|EntProp：高熵传播，提高准确性和稳健性|Shohei Enomoto|<http://arxiv.org/pdf/2405.18931v1>|null
**2024-05-29**|**Exploring Human-in-the-Loop Test-Time Adaptation by Synergizing Active Learning and Model Selection**|通过结合主动学习和模型选择探索人机交互测试时间适应性|Yushu Li, Yongyi Su, Xulei Yang, Kui Jia, Xun Xu|<http://arxiv.org/pdf/2405.18911v1>|null
**2024-05-29**|**Spectral Fidelity and Spatial Enhancement: An Assessment and Cascading of Pan-Sharpening Techniques for Satellite Imagery**|光谱保真度和空间增强：卫星图像全色锐化技术的评估与级联|Abdul Aziz A. B, A. B Abdul Rahim|<http://arxiv.org/pdf/2405.18900v1>|null
**2024-05-29**|**MLAE: Masked LoRA Experts for Parameter-Efficient Fine-Tuning**|MLAE：用于参数高效微调的蒙面 LoRA 专家|Junjie Wang, Guangjing Yang, Wentao Chen, Huahui Yi, Xiaohu Wu, Qicheng Lao|<http://arxiv.org/pdf/2405.18897v1>|null
**2024-05-29**|**DecomCAM: Advancing Beyond Saliency Maps through Decomposition and Integration**|DecomCAM：通过分解和集成超越显著性图|Yuguang Yang, Runtang Guo, Sheng Wu, Yimi Wang, Linlin Yang, Bo Fan, Jilong Zhong, Juan Zhang, Baochang Zhang|<http://arxiv.org/pdf/2405.18882v1>|null
**2024-05-29**|**Domain-Inspired Sharpness-Aware Minimization Under Domain Shifts**|领域转移下的领域启发式锐度感知最小化|Ruipeng Zhang, Ziqing Fan, Jiangchao Yao, Ya Zhang, Yanfeng Wang|<http://arxiv.org/pdf/2405.18861v1>|null
**2024-05-29**|**Descriptive Image Quality Assessment in the Wild**|野外图像质量描述评估|Zhiyuan You, Jinjin Gu, Zheyuan Li, Xin Cai, Kaiwen Zhu, Tianfan Xue, Chao Dong|<http://arxiv.org/pdf/2405.18842v1>|null
**2024-05-29**|**Opinion-Unaware Blind Image Quality Assessment using Multi-Scale Deep Feature Statistics**|使用多尺度深度特征统计进行观点不知情的盲图像质量评估|Zhangkai Ni, Yue Liu, Keyan Ding, Wenhan Yang, Hanli Wang, Shiqi Wang|<http://arxiv.org/pdf/2405.18790v1>|null

