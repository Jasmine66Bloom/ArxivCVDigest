## [UPDATED!] **2024-06-13** (Publish Time)

## 生成模型

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-06-13**|**Alleviating Distortion in Image Generation via Multi-Resolution Diffusion Models**|通过多分辨率扩散模型减轻图像生成中的失真|Qihao Liu, Zhanpeng Zeng, Ju He, Qihang Yu, Xiaohui Shen, Liang-Chieh Chen|<http://arxiv.org/pdf/2406.09416v1>|null
**2024-06-13**|**An Image is Worth More Than 16x16 Patches: Exploring Transformers on Individual Pixels**|图像的价值不只是 16x16 的补丁：探索单个像素上的 Transformer|Duy-Kien Nguyen, Mahmoud Assran, Unnat Jain, Martin R. Oswald, Cees G. M. Snoek, Xinlei Chen|<http://arxiv.org/pdf/2406.09415v1>|null
**2024-06-13**|**Interpreting the Weight Space of Customized Diffusion Models**|解释定制扩散模型的权重空间|Amil Dravid, Yossi Gandelsman, Kuan-Chieh Wang, Rameen Abdal, Gordon Wetzstein, Alexei A. Efros, Kfir Aberman|<http://arxiv.org/pdf/2406.09413v1>|null
**2024-06-13**|**ConsistDreamer: 3D-Consistent 2D Diffusion for High-Fidelity Scene Editing**|ConsistDreamer：用于高保真场景编辑的 3D 一致 2D 扩散|Jun-Kun Chen, Samuel Rota Bulò, Norman Müller, Lorenzo Porzi, Peter Kontschieder, Yu-Xiong Wang|<http://arxiv.org/pdf/2406.09404v1>|null
**2024-06-13**|**Instruct 4D-to-4D: Editing 4D Scenes as Pseudo-3D Scenes Using 2D Diffusion**|指导 4D 到 4D：使用 2D 扩散将 4D 场景编辑为伪 3D 场景|Linzhan Mou, Jun-Kun Chen, Yu-Xiong Wang|<http://arxiv.org/pdf/2406.09402v1>|null
**2024-06-13**|**OmniTokenizer: A Joint Image-Video Tokenizer for Visual Generation**|OmniTokenizer：用于视觉生成的联合图像视频标记器|Junke Wang, Yi Jiang, Zehuan Yuan, Binyue Peng, Zuxuan Wu, Yu-Gang Jiang|<http://arxiv.org/pdf/2406.09399v1>|null
**2024-06-13**|**SimGen: Simulator-conditioned Driving Scene Generation**|SimGen：模拟器条件下的驾驶场景生成|Yunsong Zhou, Michael Simon, Zhenghao Peng, Sicheng Mo, Hongzi Zhu, Minyi Guo, Bolei Zhou|<http://arxiv.org/pdf/2406.09386v1>|null
**2024-06-13**|**GGHead: Fast and Generalizable 3D Gaussian Heads**|GGHead：快速且可通用的 3D 高斯头|Tobias Kirschstein, Simon Giebenhain, Jiapeng Tang, Markos Georgopoulos, Matthias Nießner|<http://arxiv.org/pdf/2406.09377v1>|null
**2024-06-13**|**CLIPAway: Harmonizing Focused Embeddings for Removing Objects via Diffusion Models**|CLIPAway：通过扩散模型协调聚焦嵌入以移除对象|Yigit Ekin, Ahmet Burak Yildirim, Erdem Eren Caglar, Aykut Erdem, Erkut Erdem, Aysegul Dundar|<http://arxiv.org/pdf/2406.09368v1>|null
**2024-06-13**|**Toffee: Efficient Million-Scale Dataset Construction for Subject-Driven Text-to-Image Generation**|Toffee：用于主题驱动的文本到图像生成的高效百万级数据集构建|Yufan Zhou, Ruiyi Zhang, Kaizhi Zheng, Nanxuan Zhao, Jiuxiang Gu, Zichao Wang, Xin Eric Wang, Tong Sun|<http://arxiv.org/pdf/2406.09305v1>|null
**2024-06-13**|**StableMaterials: Enhancing Diversity in Material Generation via Semi-Supervised Learning**|StableMaterials：通过半监督学习增强材料生成的多样性|Giuseppe Vecchio|<http://arxiv.org/pdf/2406.09293v1>|null
**2024-06-13**|**Neural Assets: 3D-Aware Multi-Object Scene Synthesis with Image Diffusion Models**|神经资产：利用图像扩散模型实现 3D 感知多对象场景合成|Ziyi Wu, Yulia Rubanova, Rishabh Kabra, Drew A. Hudson, Igor Gilitschenski, Yusuf Aytar, Sjoerd van Steenkiste, Kelsey R. Allen, Thomas Kipf|<http://arxiv.org/pdf/2406.09292v1>|null
**2024-06-13**|**MirrorCheck: Efficient Adversarial Defense for Vision-Language Models**|MirrorCheck：视觉语言模型的有效对抗防御|Samar Fares, Klea Ziu, Toluwani Aremu, Nikita Durasov, Martin Takáč, Pascal Fua, Karthik Nandakumar, Ivan Laptev|<http://arxiv.org/pdf/2406.09250v1>|null
**2024-06-13**|**EMMA: Your Text-to-Image Diffusion Model Can Secretly Accept Multi-Modal Prompts**|EMMA：你的文本到图像传播模型可以秘密接受多模式提示|Yucheng Han, Rui Wang, Chi Zhang, Juntao Hu, Pei Cheng, Bin Fu, Hanwang Zhang|<http://arxiv.org/pdf/2406.09162v1>|null
**2024-06-13**|**Generative AI-based Prompt Evolution Engineering Design Optimization With Vision-Language Model**|基于生成式人工智能的视觉语言模型快速进化工程设计优化|Melvin Wong, Thiago Rios, Stefan Menzel, Yew Soon Ong|<http://arxiv.org/pdf/2406.09143v1>|null
**2024-06-13**|**EquiPrompt: Debiasing Diffusion Models via Iterative Bootstrapping in Chain of Thoughts**|EquiPrompt：通过思维链中的迭代引导消除扩散模型偏差|Zahraa Al Sahili, Ioannis Patras, Matthew Purver|<http://arxiv.org/pdf/2406.09070v1>|null
**2024-06-13**|**Steganalysis on Digital Watermarking: Is Your Defense Truly Impervious?**|数字水印隐写分析：你的防御真的牢不可破吗？|Pei Yang, Hai Ci, Yiren Song, Mike Zheng Shou|<http://arxiv.org/pdf/2406.09026v1>|null
**2024-06-13**|**Preserving Identity with Variational Score for General-purpose 3D Editing**|利用变分得分保留身份以实现通用 3D 编辑|Duong H. Le, Tuan Pham, Aniruddha Kembhavi, Stephan Mandt, Wei-Chiu Ma, Jiasen Lu|<http://arxiv.org/pdf/2406.08953v1>|null
**2024-06-13**|**Step-by-Step Diffusion: An Elementary Tutorial**|一步步扩散：基础教程|Preetum Nakkiran, Arwen Bradley, Hattie Zhou, Madhu Advani|<http://arxiv.org/pdf/2406.08929v1>|null
**2024-06-13**|**Learning Images Across Scales Using Adversarial Training**|使用对抗性训练跨尺度学习图像|Krzysztof Wolski, Adarsh Djeacoumar, Alireza Javanmardi, Hans-Peter Seidel, Christian Theobalt, Guillaume Cordonnier, Karol Myszkowski, George Drettakis, Xingang Pan, Thomas Leimkühler|<http://arxiv.org/pdf/2406.08924v1>|null
**2024-06-13**|**Blind Super-Resolution via Meta-learning and Markov Chain Monte Carlo Simulation**|通过元学习和马尔可夫链蒙特卡罗模拟实现盲超分辨率|Jingyuan Xia, Zhixiong Yang, Shengxi Li, Shuanghui Zhang, Yaowen Fu, Deniz Gündüz, Xiang Li|<http://arxiv.org/pdf/2406.08896v1>|null
**2024-06-13**|**COVE: Unleashing the Diffusion Feature Correspondence for Consistent Video Editing**|COVE：释放扩散功能对应功能，实现一致的视频编辑|Jiangshan Wang, Yue Ma, Jiayi Guo, Yicheng Xiao, Gao Huang, Xiu Li|<http://arxiv.org/pdf/2406.08850v1>|null
**2024-06-13**|**Hallo: Hierarchical Audio-Driven Visual Synthesis for Portrait Image Animation**|Hallo：用于肖像图像动画的分层音频驱动视觉合成|Mingwang Xu, Hui Li, Qingkun Su, Hanlin Shang, Liwei Zhang, Ce Liu, Jingdong Wang, Luc Van Gool, Yao Yao, Siyu Zhu|<http://arxiv.org/pdf/2406.08801v1>|null
**2024-06-13**|**FouRA: Fourier Low Rank Adaptation**|FouRA：傅里叶低秩自适应|Shubhankar Borse, Shreya Kadambi, Nilesh Prasad Pandey, Kartikeya Bhardwaj, Viswanath Ganapathy, Sweta Priyadarshi, Risheek Garrepalli, Rafael Esteves, Munawar Hayat, Fatih Porikli|<http://arxiv.org/pdf/2406.08798v1>|null
**2024-06-13**|**Batch-Instructed Gradient for Prompt Evolution:Systematic Prompt Optimization for Enhanced Text-to-Image Synthesis**|用于快速演化的批量指示梯度：用于增强文本到图像合成的系统快速优化|Xinrui Yang, Zhuohan Wang, Anthony Hu|<http://arxiv.org/pdf/2406.08713v1>|null

## 多模态

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-06-13**|**VideoGPT+: Integrating Image and Video Encoders for Enhanced Video Understanding**|VideoGPT+：集成图像和视频编码器以增强视频理解|Muhammad Maaz, Hanoona Rasheed, Salman Khan, Fahad Khan|<http://arxiv.org/pdf/2406.09418v1>|null
**2024-06-13**|**Explore the Limits of Omni-modal Pretraining at Scale**|探索大规模全模态预训练的极限|Yiyuan Zhang, Handong Li, Jing Liu, Xiangyu Yue|<http://arxiv.org/pdf/2406.09412v1>|**[link](https://github.com/invictus717/MiCo)**
**2024-06-13**|**MuirBench: A Comprehensive Benchmark for Robust Multi-image Understanding**|MuirBench：稳健多图像理解的综合基准|Fei Wang, Xingyu Fu, James Y. Huang, Zekun Li, Qin Liu, Xiaogeng Liu, Mingyu Derek Ma, Nan Xu, Wenxuan Zhou, Kai Zhang, et.al.|<http://arxiv.org/pdf/2406.09411v1>|null
**2024-06-13**|**4M-21: An Any-to-Any Vision Model for Tens of Tasks and Modalities**|4M-21：适用于数十种任务和模式的任意视觉模型|Roman Bachmann, Oğuzhan Fatih Kar, David Mizrahi, Ali Garjani, Mingfei Gao, David Griffiths, Jiaming Hu, Afshin Dehghan, Amir Zamir|<http://arxiv.org/pdf/2406.09406v1>|null
**2024-06-13**|**Visual Sketchpad: Sketching as a Visual Chain of Thought for Multimodal Language Models**|视觉草图板：将草图作为多模态语言模型的视觉思维链|Yushi Hu, Weijia Shi, Xingyu Fu, Dan Roth, Mari Ostendorf, Luke Zettlemoyer, Noah A Smith, Ranjay Krishna|<http://arxiv.org/pdf/2406.09403v1>|null
**2024-06-13**|**MMScan: A Multi-Modal 3D Scene Dataset with Hierarchical Grounded Language Annotations**|MMScan：具有分层基础语言注释的多模态 3D 场景数据集|Ruiyuan Lyu, Tai Wang, Jingli Lin, Shuai Yang, Xiaohan Mao, Yilun Chen, Runsen Xu, Haifeng Huang, Chenming Zhu, Dahua Lin, et.al.|<http://arxiv.org/pdf/2406.09401v1>|null
**2024-06-13**|**Yo'LLaVA: Your Personalized Language and Vision Assistant**|Yo'LLaVA：您的个性化语言和视觉助手|Thao Nguyen, Haotian Liu, Yuheng Li, Mu Cai, Utkarsh Ojha, Yong Jae Lee|<http://arxiv.org/pdf/2406.09400v1>|null
**2024-06-13**|**Aligning Vision Models with Human Aesthetics in Retrieval: Benchmarks and Algorithms**|在检索中将视觉模型与人类美学相结合：基准和算法|Miaosen Zhang, Yixuan Wei, Zhen Xing, Yifei Ma, Zuxuan Wu, Ji Li, Zheng Zhang, Qi Dai, Chong Luo, Xin Geng, et.al.|<http://arxiv.org/pdf/2406.09397v1>|null
**2024-06-13**|**Too Many Frames, not all Useful:Efficient Strategies for Long-Form Video QA**|帧数过多，并非全部有用：长视频 QA 的有效策略|Jongwoo Park, Kanchana Ranasinghe, Kumara Kahatapitiya, Wonjeong Ryoo, Donghyun Kim, Michael S. Ryoo|<http://arxiv.org/pdf/2406.09396v1>|null
**2024-06-13**|**Towards Vision-Language Geo-Foundation Model: A Survey**|视觉语言地理基础模型研究综述|Yue Zhou, Litong Feng, Yiping Ke, Xue Jiang, Junchi Yan, Xue Yang, Wayne Zhang|<http://arxiv.org/pdf/2406.09385v1>|null
**2024-06-13**|**Multiagent Multitraversal Multimodal Self-Driving: Open MARS Dataset**|多智能体多遍历多模式自动驾驶：开放 MARS 数据集|Yiming Li, Zhiheng Li, Nuo Chen, Moonjun Gong, Zonglin Lyu, Zehong Wang, Peili Jiang, Chen Feng|<http://arxiv.org/pdf/2406.09383v1>|null
**2024-06-13**|**Needle In A Video Haystack: A Scalable Synthetic Framework for Benchmarking Video MLLMs**|视频大海捞针：用于对视频 MLLM 进行基准测试的可扩展合成框架|Zijia Zhao, Haoyu Lu, Yuqi Huo, Yifan Du, Tongtian Yue, Longteng Guo, Bingning Wang, Weipeng Chen, Jing Liu|<http://arxiv.org/pdf/2406.09367v1>|null
**2024-06-13**|**Towards an Improved Understanding and Utilization of Maximum Manifold Capacity Representations**|更好地理解和利用最大流形容量表示|Rylan Schaeffer, Victor Lecomte, Dhruv Bhandarkar Pai, Andres Carranza, Berivan Isik, Alyssa Unell, Mikail Khona, Thomas Yerxa, Yann LeCun, SueYeon Chung, et.al.|<http://arxiv.org/pdf/2406.09366v1>|null
**2024-06-13**|**CMC-Bench: Towards a New Paradigm of Visual Signal Compression**|CMC-Bench：迈向视觉信号压缩的新范式|Chunyi Li, Xiele Wu, Haoning Wu, Donghui Feng, Zicheng Zhang, Guo Lu, Xiongkuo Min, Xiaohong Liu, Guangtao Zhai, Weisi Lin|<http://arxiv.org/pdf/2406.09356v1>|null
**2024-06-13**|**AlignMMBench: Evaluating Chinese Multimodal Alignment in Large Vision-Language Models**|AlignMMBench：评估大型视觉语言模型中的中文多模态对齐|Yuhang Wu, Wenmeng Yu, Yean Cheng, Yan Wang, Xiaohan Zhang, Jiazheng Xu, Ming Ding, Yuxiao Dong|<http://arxiv.org/pdf/2406.09295v1>|null
**2024-06-13**|**Comparison Visual Instruction Tuning**|比较视觉指令调整|Wei Lin, Muhammad Jehanzeb Mirza, Sivan Doveh, Rogerio Feris, Raja Giryes, Sepp Hochreiter, Leonid Karlinsky|<http://arxiv.org/pdf/2406.09240v1>|null
**2024-06-13**|**Optimizing Visual Question Answering Models for Driving: Bridging the Gap Between Human and Machine Attention Patterns**|优化驾驶视觉问答模型：弥合人类与机器注意力模式之间的差距|Kaavya Rekanar, Martin Hayes, Ganesh Sistu, Ciaran Eising|<http://arxiv.org/pdf/2406.09203v1>|null
**2024-06-13**|**Towards Multilingual Audio-Visual Question Answering**|面向多语言视听问答|Orchid Chetia Phukan, Priyabrata Mallick, Swarup Ranjan Behera, Aalekhya Satya Narayani, Arun Balaji Buduru, Rajesh Sharma|<http://arxiv.org/pdf/2406.09156v1>|null
**2024-06-13**|**MMRel: A Relation Understanding Dataset and Benchmark in the MLLM Era**|MMRel：MLLM 时代的关系理解数据集和基准|Jiahao Nie, Gongjie Zhang, Wenbin An, Yap-Peng Tan, Alex C. Kot, Shijian Lu|<http://arxiv.org/pdf/2406.09121v1>|null
**2024-06-13**|**INS-MMBench: A Comprehensive Benchmark for Evaluating LVLMs' Performance in Insurance**|INS-MMBench：评估 LVLM 在保险领域表现的综合基准|Chenwei Lin, Hanjia Lyu, Xian Xu, Jiebo Luo|<http://arxiv.org/pdf/2406.09105v1>|null
**2024-06-13**|**Zoom and Shift are All You Need**|缩放和移位就是你所需要的|Jiahao Qin|<http://arxiv.org/pdf/2406.08866v1>|null
**2024-06-13**|**MMFakeBench: A Mixed-Source Multimodal Misinformation Detection Benchmark for LVLMs**|MMFakeBench：LVLM 的混合源多模态错误信息检测基准|Xuannan Liu, Zekun Li, Peipei Li, Shuhan Xia, Xing Cui, Linzhi Huang, Huaibo Huang, Weihong Deng, Zhaofeng He|<http://arxiv.org/pdf/2406.08772v1>|null
**2024-06-13**|**mOSCAR: A Large-scale Multilingual and Multimodal Document-level Corpus**|mOSCAR：大规模多语言、多模态文档级语料库|Matthieu Futeral, Armel Zebaze, Pedro Ortiz Suarez, Julien Abadji, Rémi Lacroix, Cordelia Schmid, Rachel Bawden, Benoît Sagot|<http://arxiv.org/pdf/2406.08707v1>|null
**2024-06-13**|**VLind-Bench: Measuring Language Priors in Large Vision-Language Models**|VLind-Bench：在大型视觉语言模型中测量语言先验|Kang-il Lee, Minbeom Kim, Seunghyun Yoon, Minsung Kim, Dongryeol Lee, Hyukhun Koh, Kyomin Jung|<http://arxiv.org/pdf/2406.08702v1>|null

## Nerf

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-06-13**|**Rethinking Score Distillation as a Bridge Between Image Distributions**|重新思考分数蒸馏作为图像分布之间的桥梁|David McAllister, Songwei Ge, Jia-Bin Huang, David W. Jacobs, Alexei A. Efros, Aleksander Holynski, Angjoo Kanazawa|<http://arxiv.org/pdf/2406.09417v1>|null
**2024-06-13**|**Neural NeRF Compression**|神经 NeRF 压缩|Tuan Pham, Stephan Mandt|<http://arxiv.org/pdf/2406.08943v1>|null
**2024-06-13**|**OpenMaterial: A Comprehensive Dataset of Complex Materials for 3D Reconstruction**|OpenMaterial：用于 3D 重建的复杂材料综合数据集|Zheng Dang, Jialu Huang, Fei Wang, Mathieu Salzmann|<http://arxiv.org/pdf/2406.08894v1>|null
**2024-06-13**|**NeRF Director: Revisiting View Selection in Neural Volume Rendering**|NeRF Director：重新审视神经体积渲染中的视图选择|Wenhui Xiao, Rodrigo Santa Cruz, David Ahmedt-Aristizabal, Olivier Salvado, Clinton Fookes, Leo Lebrat|<http://arxiv.org/pdf/2406.08839v1>|null

## 3DGS

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-06-13**|**Modeling Ambient Scene Dynamics for Free-view Synthesis**|为自由视角合成建模环境场景动态|Meng-Li Shih, Jia-Bin Huang, Changil Kim, Rajvi Shah, Johannes Kopf, Chen Gao|<http://arxiv.org/pdf/2406.09395v1>|null
**2024-06-13**|**Gaussian-Forest: Hierarchical-Hybrid 3D Gaussian Splatting for Compressed Scene Modeling**|高斯森林：用于压缩场景建模的分层混合 3D 高斯分层|Fengyi Zhang, Tianjun Zhang, Lin Zhang, Helen Huang, Yadan Luo|<http://arxiv.org/pdf/2406.08759v1>|null

## 模型压缩/优化

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-06-13**|**Scene Graph Generation in Large-Size VHR Satellite Imagery: A Large-Scale Dataset and A Context-Aware Approach**|大型 VHR 卫星图像中的场景图生成：大规模数据集和上下文感知方法|Yansheng Li, Linlin Wang, Tingzhu Wang, Xue Yang, Junwei Luo, Qi Wang, Youming Deng, Wenbin Wang, Xian Sun, Haifeng Li, et.al.|<http://arxiv.org/pdf/2406.09410v1>|null
**2024-06-13**|**MGRQ: Post-Training Quantization For Vision Transformer With Mixed Granularity Reconstruction**|MGRQ：具有混合粒度重建的视觉变换器训练后量化|Lianwei Yang, Zhikai Li, Junrui Xiao, Haisong Gong, Qingyi Gu|<http://arxiv.org/pdf/2406.09229v1>|null
**2024-06-13**|**Thoracic Surgery Video Analysis for Surgical Phase Recognition**|胸外科手术视频分析以实现手术阶段识别|Syed Abdul Mateen, Niharika Malvia, Syed Abdul Khader, Danny Wang, Deepti Srinivasan, Chi-Fu Jeffrey Yang, Lana Schumacher, Sandeep Manjanna|<http://arxiv.org/pdf/2406.09185v1>|null
**2024-06-13**|**PC-LoRA: Low-Rank Adaptation for Progressive Model Compression with Knowledge Distillation**|PC-LoRA：通过知识提炼实现渐进模型压缩的低秩自适应|Injoon Hwang, Haewon Park, Youngwan Lee, Jooyoung Yang, SunJae Maeng|<http://arxiv.org/pdf/2406.09117v1>|null

## 分类/检测/识别/分割/...

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-06-13**|**Towards Evaluating the Robustness of Visual State Space Models**|评估视觉状态空间模型的稳健性|Hashmat Shadab Malik, Fahad Shamshad, Muzammal Naseer, Karthik Nandakumar, Fahad Shahbaz Khan, Salman Khan|<http://arxiv.org/pdf/2406.09407v1>|null
**2024-06-13**|**Real-Time Deepfake Detection in the Real-World**|现实世界中的实时 Deepfake 检测|Bar Cavia, Eliahu Horwitz, Tal Reiss, Yedid Hoshen|<http://arxiv.org/pdf/2406.09398v1>|null
**2024-06-13**|**Exploring the Spectrum of Visio-Linguistic Compositionality and Recognition**|探索视觉语言组合性和识别的频谱|Youngtaek Oh, Pyunghwan Ahn, Jinhyung Kim, Gwangmo Song, Soonyoung Lee, In So Kweon, Junmo Kim|<http://arxiv.org/pdf/2406.09388v1>|null
**2024-06-13**|**Instance-level quantitative saliency in multiple sclerosis lesion segmentation**|多发性硬化症病变分割中的实例级定量显著性|Federico Spagnolo, Nataliia Molchanova, Roger Schaer, Meritxell Bach Cuadra, Mario Ocampo Pineda, Lester Melie-Garcia, Cristina Granziera, Vincent Andrearczyk, Adrien Depeursinge|<http://arxiv.org/pdf/2406.09335v1>|null
**2024-06-13**|**Memory-Efficient Sparse Pyramid Attention Networks for Whole Slide Image Analysis**|用于全幻灯片图像分析的内存高效稀疏金字塔注意力网络|Weiyi Wu, Chongyang Gao, Xinwen Xu, Siting Li, Jiang Gui|<http://arxiv.org/pdf/2406.09333v1>|null
**2024-06-13**|**Towards AI Lesion Tracking in PET/CT Imaging: A Siamese-based CNN Pipeline applied on PSMA PET/CT Scans**|面向 PET/CT 成像中的 AI 病变追踪：应用于 PSMA PET/CT 扫描的基于 Siamese 的 CNN 管道|Stefan P. Hein, Manuel Schultheiss, Andrei Gafita, Raphael Zaum, Farid Yagubbayli, Isabel Rauscher, Matthias Eiber, Franz Pfeiffer, Wolfgang A. Weber|<http://arxiv.org/pdf/2406.09327v1>|null
**2024-06-13**|**Common and Rare Fundus Diseases Identification Using Vision-Language Foundation Model with Knowledge of Over 400 Diseases**|使用视觉语言基础模型识别常见和罕见眼底疾病，涵盖 400 多种疾病知识|Meng Wang, Tian Lin, Kai Yu, Aidi Lin, Yuanyuan Peng, Lianyu Wang, Cheng Chen, Ke Zou, Huiyu Liang, Man Chen, et.al.|<http://arxiv.org/pdf/2406.09317v1>|null
**2024-06-13**|**Parameter-Efficient Active Learning for Foundational models**|基础模型的参数高效主动学习|Athmanarayanan Lakshmi Narayanan, Ranganath Krishnan, Amrutha Machireddy, Mahesh Subedar|<http://arxiv.org/pdf/2406.09296v1>|null
**2024-06-13**|**Assessing Model Generalization in Vicinity**|评估邻近模型的泛化能力|Yuchi Liu, Yifan Sun, Jingdong Wang, Liang Zheng|<http://arxiv.org/pdf/2406.09257v1>|null
**2024-06-13**|**Enhanced Object Detection: A Study on Vast Vocabulary Object Detection Track for V3Det Challenge 2024**|增强型物体检测：针对 V3Det 挑战赛 2024 的海量词汇物体检测赛道的研究|Peixi Wu, Bosong Chai, Xuan Nie, Longquan Yan, Zeyu Wang, Qifan Zhou, Boning Wang|<http://arxiv.org/pdf/2406.09201v1>|null
**2024-06-13**|**A Large-scale Universal Evaluation Benchmark For Face Forgery Detection**|人脸伪造检测的大规模通用评估基准|Yijun Bei, Hengrui Lou, Jinsong Geng, Erteng Liu, Lechao Cheng, Jie Song, Mingli Song, Zunlei Feng|<http://arxiv.org/pdf/2406.09181v1>|null
**2024-06-13**|**Fine-Grained Domain Generalization with Feature Structuralization**|具有特征结构化的细粒度领域泛化|Wenlong Yu, Dongyue Chen, Qilong Wang, Qinghua Hu|<http://arxiv.org/pdf/2406.09166v1>|null
**2024-06-13**|**Beyond the Frontier: Predicting Unseen Walls from Occupancy Grids by Learning from Floor Plans**|超越边界：通过学习平面图，根据占用网格预测看不见的墙壁|Ludvig Ericson, Patric Jensfelt|<http://arxiv.org/pdf/2406.09160v1>|null
**2024-06-13**|**DefAn: Definitive Answer Dataset for LLMs Hallucination Evaluation**|DefAn：法学硕士幻觉评估的权威答案数据集|A B M Ashikur Rahman, Saeed Anwar, Muhammad Usman, Ajmal Mian|<http://arxiv.org/pdf/2406.09155v1>|null
**2024-06-13**|**Auto-Vocabulary Segmentation for LiDAR Points**|LiDAR 点的自动词汇分割|Weijie Wei, Osman Ülger, Fatemeh Karimi Najadasl, Theo Gevers, Martin R. Oswald|<http://arxiv.org/pdf/2406.09126v1>|null
**2024-06-13**|**Large-Scale Evaluation of Open-Set Image Classification Techniques**|开放集图像分类技术的大规模评估|Halil Bisgin, Andres Palechor, Mike Suter, Manuel Günther|<http://arxiv.org/pdf/2406.09112v1>|null
**2024-06-13**|**Suitability of KANs for Computer Vision: A preliminary investigation**|KAN 对计算机视觉的适用性：初步调查|Basim Azam, Naveed Akhtar|<http://arxiv.org/pdf/2406.09087v1>|null
**2024-06-13**|**Cross-Modal Learning for Anomaly Detection in Fused Magnesium Smelting Process: Methodology and Benchmark**|跨模态学习在熔镁冶炼过程中的异常检测：方法论与基准|Gaochang Wu, Yapeng Zhang, Lan Deng, Jingxin Zhang, Tianyou Chai|<http://arxiv.org/pdf/2406.09016v1>|null
**2024-06-13**|**Adaptive Temporal Motion Guided Graph Convolution Network for Micro-expression Recognition**|用于微表情识别的自适应时间运动引导图卷积网络|Fengyuan Zhang, Zhaopei Huang, Xinjie Zhang, Qin Jin|<http://arxiv.org/pdf/2406.08997v1>|null
**2024-06-13**|**The Penalized Inverse Probability Measure for Conformal Classification**|共形分类的惩罚逆概率测度|Paul Melki, Lionel Bombrun, Boubacar Diallo, Jérôme Dias, Jean-Pierre da Costa|<http://arxiv.org/pdf/2406.08884v1>|null
**2024-06-13**|**EgoExo-Fitness: Towards Egocentric and Exocentric Full-Body Action Understanding**|EgoExo-Fitness：走向自我中心和外向的全身动作理解|Yuan-Ming Li, Wei-Jin Huang, An-Lan Wang, Ling-An Zeng, Jing-Ke Meng, Wei-Shi Zheng|<http://arxiv.org/pdf/2406.08877v1>|null
**2024-06-13**|**Conceptual Learning via Embedding Approximations for Reinforcing Interpretability and Transparency**|通过嵌入近似进行概念学习以增强可解释性和透明度|Maor Dikter, Tsachi Blau, Chaim Baskin|<http://arxiv.org/pdf/2406.08840v1>|null
**2024-06-13**|**Research on Deep Learning Model of Feature Extraction Based on Convolutional Neural Network**|基于卷积神经网络的特征提取深度学习模型研究|Houze Liu, Iris Li, Yaxin Liang, Dan Sun, Yining Yang, Haowei Yang|<http://arxiv.org/pdf/2406.08837v1>|null
**2024-06-13**|**Computer vision-based model for detecting turning lane features on Florida's public roadways**|基于计算机视觉的模型，用于检测佛罗里达州公共道路上的转弯车道特征|Richard Boadu Antwi, Samuel Takyi, Kimollo Michael, Alican Karaer, Eren Erman Ozguven, Ren Moses, Maxim A. Dulebenets, Thobias Sando|<http://arxiv.org/pdf/2406.08822v1>|null
**2024-06-13**|**ToSA: Token Selective Attention for Efficient Vision Transformers**|ToSA：高效视觉变换器的标记选择性注意|Manish Kumar Singh, Rajeev Yasarla, Hong Cai, Mingu Lee, Fatih Porikli|<http://arxiv.org/pdf/2406.08816v1>|null
**2024-06-13**|**Few-Shot Anomaly Detection via Category-Agnostic Registration Learning**|通过类别无关注册学习进行小样本异常检测|Chaoqin Huang, Haoyan Guan, Aofan Jiang, Yanfeng Wang, Michael Spratling, Xinchao Wang, Ya Zhang|<http://arxiv.org/pdf/2406.08810v1>|null
**2024-06-13**|**BEVSpread: Spread Voxel Pooling for Bird's-Eye-View Representation in Vision-based Roadside 3D Object Detection**|BEVSpread：基于视觉的路边 3D 物体检测中用于鸟瞰视图表示的扩展体素池|Wenjie Wang, Yehao Lu, Guangcong Zheng, Shuigen Zhan, Xiaoqing Ye, Zichang Tan, Jingdong Wang, Gaoang Wang, Xi Li|<http://arxiv.org/pdf/2406.08785v1>|null
**2024-06-13**|**ALINA: Advanced Line Identification and Notation Algorithm**|ALINA：高级线条识别和标记算法|Mohammed Abdul Hafeez Khan, Parth Ganeriwala, Siddhartha Bhattacharyya, Natasha Neogi, Raja Muthalagu|<http://arxiv.org/pdf/2406.08775v1>|null
**2024-06-13**|**DenoiseReID: Denoising Model for Representation Learning of Person Re-Identification**|DenoiseReID：用于行人重新识别表征学习的去噪模型|Zhengrui Xu, Guan'an Wang, Xiaowen Huang, Jitao Sang|<http://arxiv.org/pdf/2406.08773v1>|null
**2024-06-13**|**AGFA-Net: Attention-Guided and Feature-Aggregated Network for Coronary Artery Segmentation using Computed Tomography Angiography**|AGFA-Net：使用计算机断层扫描血管造影进行冠状动脉分割的注意力引导和特征聚合网络|Xinyun Liu, Chen Zhao|<http://arxiv.org/pdf/2406.08724v1>|null

## GNN

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-06-13**|**Self-supervised Graph Neural Network for Mechanical CAD Retrieval**|用于机械 CAD 检索的自监督图神经网络|Yuhan Quan, Huan ZHao, Jinfeng Yi, Yuqiang Chen|<http://arxiv.org/pdf/2406.08863v1>|null

## 图像理解

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-06-13**|**Depth Anything V2**|深度万物 V2|Lihe Yang, Bingyi Kang, Zilong Huang, Zhen Zhao, Xiaogang Xu, Jiashi Feng, Hengshuang Zhao|<http://arxiv.org/pdf/2406.09414v1>|null
**2024-06-13**|**WonderWorld: Interactive 3D Scene Generation from a Single Image**|WonderWorld：通过单幅图像生成交互式 3D 场景|Hong-Xing Yu, Haoyi Duan, Charles Herrmann, William T. Freeman, Jiajun Wu|<http://arxiv.org/pdf/2406.09394v1>|null
**2024-06-13**|**Scale-Invariant Monocular Depth Estimation via SSI Depth**|通过 SSI Depth 进行尺度不变单目深度估计|S. Mahdi H. Miangoleh, Mahesh Reddy, Yağız Aksoy|<http://arxiv.org/pdf/2406.09374v1>|null
**2024-06-13**|**Deep Transformer Network for Monocular Pose Estimation of Ship-Based UAV**|用于舰载无人机单目姿态估计的深度 Transformer 网络|Maneesha Wickramasuriya, Taeyoung Lee, Murray Snyder|<http://arxiv.org/pdf/2406.09260v1>|null
**2024-06-13**|**Multiple Prior Representation Learning for Self-Supervised Monocular Depth Estimation via Hybrid Transformer**|通过混合变压器进行自监督单目深度估计的多重先验表征学习|Guodong Sun, Junjie Liu, Mingxuan Liu, Moyun Liu, Yang Zhang|<http://arxiv.org/pdf/2406.08928v1>|null

## LLM

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-06-13**|**ReMI: A Dataset for Reasoning with Multiple Images**|ReMI：用于多图像推理的数据集|Mehran Kazemi, Nishanth Dikkala, Ankit Anand, Petar Devic, Ishita Dasgupta, Fangyu Liu, Bahare Fatemi, Pranjal Awasthi, Dee Guo, Sreenivas Gollapudi, et.al.|<http://arxiv.org/pdf/2406.09175v1>|null
**2024-06-13**|**How structured are the representations in transformer-based vision encoders? An analysis of multi-object representations in vision-language models**|基于 Transformer 的视觉编码器中的表征结构如何？视觉语言模型中多对象表征的分析|Tarun Khajuria, Braian Olmiro Dias, Jaan Aru|<http://arxiv.org/pdf/2406.09067v1>|null

## Transformer

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-06-13**|**PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance**|PianoMotion10M：钢琴演奏中手部动作生成的数据集和基准|Qijun Gan, Song Wang, Shengtao Wu, Jianke Zhu|<http://arxiv.org/pdf/2406.09326v1>|null
**2024-06-13**|**Vertical LoRA: Dense Expectation-Maximization Interpretation of Transformers**|垂直 LoRA：Transformer 的密集期望最大化解释|Zhuolin Fu|<http://arxiv.org/pdf/2406.09315v1>|**[link](https://github.com/neverUseThisName/vlora)**
**2024-06-13**|**Adaptive Slot Attention: Object Discovery with Dynamic Slot Number**|自适应槽位注意：使用动态槽位号进行对象发现|Ke Fan, Zechen Bai, Tianjun Xiao, Tong He, Max Horn, Yanwei Fu, Francesco Locatello, Zheng Zhang|<http://arxiv.org/pdf/2406.09196v1>|null
**2024-06-13**|**AMSA-UNet: An Asymmetric Multiple Scales U-net Based on Self-attention for Deblurring**|AMSA-UNet：基于自注意力机制的非对称多尺度 U-net，用于去模糊|Yingying Wang|<http://arxiv.org/pdf/2406.09015v1>|null
**2024-06-13**|**Dual Attribute-Spatial Relation Alignment for 3D Visual Grounding**|3D 视觉基础的双重属性-空间关系对齐|Yue Xu, Kaizhi Yang, Jiebo Luo, Xuejin Chen|<http://arxiv.org/pdf/2406.08907v1>|null
**2024-06-13**|**Fusion of regional and sparse attention in Vision Transformers**|Vision Transformers 中区域注意力和稀疏注意力的融合|Nabil Ibtehaz, Ning Yan, Masood Mortazavi, Daisuke Kihara|<http://arxiv.org/pdf/2406.08859v1>|null
**2024-06-13**|**Hybrid Spatial-spectral Neural Network for Hyperspectral Image Denoising**|用于高光谱图像去噪的混合空间光谱神经网络|Hao Liang, Chengjie, Kun Li, Xin Tian|<http://arxiv.org/pdf/2406.08782v1>|null

## 3D/CG

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-06-13**|**CodedEvents: Optimal Point-Spread-Function Engineering for 3D-Tracking with Event Cameras**|CodedEvents：利用事件相机进行 3D 跟踪的最佳点扩展函数工程|Sachin Shah, Matthew Albert Chan, Haoming Cai, Jingxi Chen, Sakshum Kulshrestha, Chahat Deep Singh, Yiannis Aloimonos, Christopher Metzler|<http://arxiv.org/pdf/2406.09409v1>|null
**2024-06-13**|**LLAVIDAL: Benchmarking Large Language Vision Models for Daily Activities of Living**|LLAVIDAL：为日常生活活动制定大型语言视觉模型基准测试|Rajatsubhra Chakraborty, Arkaprava Sinha, Dominick Reilly, Manish Kumar Govind, Pu Wang, Francois Bremond, Srijan Das|<http://arxiv.org/pdf/2406.09390v1>|null
**2024-06-13**|**LRM-Zero: Training Large Reconstruction Models with Synthesized Data**|LRM-Zero：使用合成数据训练大型重建模型|Desai Xie, Sai Bi, Zhixin Shu, Kai Zhang, Zexiang Xu, Yi Zhou, Sören Pirk, Arie Kaufman, Xin Sun, Hao Tan|<http://arxiv.org/pdf/2406.09371v1>|null
**2024-06-13**|**Action2Sound: Ambient-Aware Generation of Action Sounds from Egocentric Videos**|Action2Sound：根据自我中心视频生成环境感知动作声音|Changan Chen, Puyuan Peng, Ami Baid, Zihui Xue, Wei-Ning Hsu, David Harwarth, Kristen Grauman|<http://arxiv.org/pdf/2406.09272v1>|null
**2024-06-13**|**SR-CACO-2: A Dataset for Confocal Fluorescence Microscopy Image Super-Resolution**|SR-CACO-2：共聚焦荧光显微镜图像超分辨率数据集|Soufiane Belharbi, Mara KM Whitford, Phuong Hoang, Shakeeb Murtaza, Luke McCaffrey, Eric Granger|<http://arxiv.org/pdf/2406.09168v1>|**[link](https://github.com/sbelharbi/sr-caco-2)**
**2024-06-13**|**AirPlanes: Accurate Plane Estimation via 3D-Consistent Embeddings**|AirPlanes：通过 3D 一致性嵌入实现精确的平面估计|Jamie Watson, Filippo Aleotti, Mohamed Sayed, Zawar Qureshi, Oisin Mac Aodha, Gabriel Brostow, Michael Firman, Sara Vicente|<http://arxiv.org/pdf/2406.08960v1>|null

## 各类学习方式

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-06-13**|**Reflecting on the State of Rehearsal-free Continual Learning with Pretrained Models**|反思使用预训练模型进行无排练持续学习的现状|Lukas Thede, Karsten Roth, Olivier J. Hénaff, Matthias Bethge, Zeynep Akata|<http://arxiv.org/pdf/2406.09384v1>|null
**2024-06-13**|**Enhancing Domain Adaptation through Prompt Gradient Alignment**|通过快速梯度对齐增强域适应性|Hoang Phan, Lam Tran, Quyen Tran, Trung Le|<http://arxiv.org/pdf/2406.09353v1>|null
**2024-06-13**|**Reducing Task Discrepancy of Text Encoders for Zero-Shot Composed Image Retrieval**|减少零样本合成图像检索文本编码器的任务差异|Jaeseok Byun, Seokhyeon Jeong, Wonjae Kim, Sanghyuk Chun, Taesup Moon|<http://arxiv.org/pdf/2406.09188v1>|null
**2024-06-13**|**A PCA based Keypoint Tracking Approach to Automated Facial Expressions Encoding**|基于 PCA 的关键点跟踪方法实现面部表情自动编码|Shivansh Chandra Tripathi, Rahul Garg|<http://arxiv.org/pdf/2406.09017v1>|null

## 其他

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-06-13**|**Data Attribution for Text-to-Image Models by Unlearning Synthesized Images**|通过取消学习合成图像实现文本转图像模型的数据归因|Sheng-Yu Wang, Aaron Hertzmann, Alexei A. Efros, Jun-Yan Zhu, Richard Zhang|<http://arxiv.org/pdf/2406.09408v1>|null
**2024-06-13**|**Sagiri: Low Dynamic Range Image Enhancement with Generative Diffusion Prior**|Sagiri：利用生成扩散先验进行低动态范围图像增强|Baiang Li, Sizhuo Ma, Yanhong Zeng, Xiaogang Xu, Youqing Fang, Zhao Zhang, Jian Wang, Kai Chen|<http://arxiv.org/pdf/2406.09389v1>|null
**2024-06-13**|**You Don't Need Data-Augmentation in Self-Supervised Learning**|自监督学习中不需要数据增强|Théo Moutakanni, Maxime Oquab, Marc Szafraniec, Maria Vakalopoulou, Piotr Bojanowski|<http://arxiv.org/pdf/2406.09294v1>|null
**2024-06-13**|**WildlifeReID-10k: Wildlife re-identification dataset with 10k individual animals**|WildlifeReID-10k：包含 10,000 只动物的野生动物重新识别数据集|Lukáš Adam, Vojtěch Čermák, Kostas Papafitsoros, Lukas Picek|<http://arxiv.org/pdf/2406.09211v1>|null
**2024-06-13**|**CLIP-Driven Cloth-Agnostic Feature Learning for Cloth-Changing Person Re-Identification**|CLIP 驱动的与衣服无关的特征学习，用于更换衣服后人员重新识别|Shuang Li, Jiaxu Leng, Guozhang Li, Ji Gan, Haosheng chen, Xinbo Gao|<http://arxiv.org/pdf/2406.09198v1>|null
**2024-06-13**|**AdaRevD: Adaptive Patch Exiting Reversible Decoder Pushes the Limit of Image Deblurring**|AdaRevD：自适应补丁退出可逆解码器，突破图像去模糊的极限|Xintian Mao, Qingli Li, Yan Wang|<http://arxiv.org/pdf/2406.09135v1>|null
**2024-06-13**|**FacEnhance: Facial Expression Enhancing with Recurrent DDPMs**|FacEnhance：使用重复性 DDPM 增强面部表情|Hamza Bouzid, Lahoucine Ballihi|<http://arxiv.org/pdf/2406.09040v1>|null
**2024-06-13**|**Enhancing Cross-Modal Fine-Tuning with Gradually Intermediate Modality Generation**|通过逐步生成中间模态来增强跨模态微调|Lincan Cai, Shuang Li, Wenxuan Ma, Jingxuan Kang, Binhui Xie, Zixun Sun, Chengwei Zhu|<http://arxiv.org/pdf/2406.09003v1>|null
**2024-06-13**|**A Label-Free and Non-Monotonic Metric for Evaluating Denoising in Event Cameras**|用于评估事件相机去噪效果的无标签非单调指标|Chenyang Shi, Shasha Guo, Boyi Wei, Hanxiao Liu, Yibo Zhang, Ningfang Song, Jing Jin|<http://arxiv.org/pdf/2406.08909v1>|null
**2024-06-13**|**Computer Vision Approaches for Automated Bee Counting Application**|自动蜜蜂计数应用的计算机视觉方法|Simon Bilik, Ilona Janakova, Adam Ligocki, Dominik Ficek, Karel Horak|<http://arxiv.org/pdf/2406.08898v1>|null
**2024-06-13**|**OmniH2O: Universal and Dexterous Human-to-Humanoid Whole-Body Teleoperation and Learning**|OmniH2O：通用灵巧的人机全身远程操作和学习|Tairan He, Zhengyi Luo, Xialin He, Wenli Xiao, Chong Zhang, Weinan Zhang, Kris Kitani, Changliu Liu, Guanya Shi|<http://arxiv.org/pdf/2406.08858v1>|null
**2024-06-13**|**Rethinking Human Evaluation Protocol for Text-to-Video Models: Enhancing Reliability,Reproducibility, and Practicality**|重新思考文本转视频模型的人工评估协议：提高可靠性、可重复性和实用性|Tianle Zhang, Langtian Ma, Yuchen Yan, Yuchen Zhang, Kai Wang, Yue Yang, Ziyao Guo, Wenqi Shao, Yang You, Yu Qiao, et.al.|<http://arxiv.org/pdf/2406.08845v1>|null
**2024-06-13**|**Improving Adversarial Robustness via Feature Pattern Consistency Constraint**|通过特征模式一致性约束提高对抗鲁棒性|Jiacong Hu, Jingwen Ye, Zunlei Feng, Jiazhen Yang, Shunyu Liu, Xiaotian Yu, Lingxiang Jia, Mingli Song|<http://arxiv.org/pdf/2406.08829v1>|null
**2024-06-13**|**Skim then Focus: Integrating Contextual and Fine-grained Views for Repetitive Action Counting**|浏览然后聚焦：集成上下文和细粒度视图以进行重复动作计数|Zhengqi Zhao, Xiaohu Huang, Hao Zhou, Kun Yao, Errui Ding, Jingdong Wang, Xinggang Wang, Wenyu Liu, Bin Feng|<http://arxiv.org/pdf/2406.08814v1>|null

