## [UPDATED!] **2024-10-01** (Publish Time)

## 生成模型

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-10-01**|**Enhancing GANs with Contrastive Learning-Based Multistage Progressive   Finetuning SNN and RL-Based External Optimization**|增强生成对抗网络：基于对比学习的多阶段渐进式微调SNN与基于RL的外部优化|Osama Mustafa|<http://arxiv.org/pdf/2409.20340v2>|null
**2024-10-01**|**Synthesizing beta-amyloid PET images from T1-weighted Structural MRI: A   Preliminary Study**|合成β-淀粉样蛋白PET图像自T1加权结构MRI：一项初步研究|Qing Lyu, Jin Young Kim, Jeongchul Kim, Christopher T Whitlow|<http://arxiv.org/pdf/2409.18282v2>|null
**2024-10-01**|**Physics-Informed Latent Diffusion for Multimodal Brain MRI Synthesis**|物理信息引导的潜在扩散模型用于多模态脑部MRI合成|Sven Lüpke, Yousef Yeganeh, Ehsan Adeli, Nassir Navab, Azade Farshad|<http://arxiv.org/pdf/2409.13532v2>|null
**2024-10-01**|**Enhancing Image Classification in Small and Unbalanced Datasets through   Synthetic Data Augmentation**|增强小样本与不平衡数据集中的图像分类：合成数据增强方法|Neil De La Fuente, Mireia Majó, Irina Luzko, Henry Córdova, Gloria Fernández-Esparrach, Jorge Bernal|<http://arxiv.org/pdf/2409.10286v2>|null
**2024-10-01**|**EZIGen: Enhancing zero-shot subject-driven image generation with precise   subject encoding and decoupled guidance**|EZIGen: 利用精确主体编码与解耦引导增强零样本主体驱动的图像生成|Zicheng Duan, Yuxuan Ding, Chenhui Gou, Ziqin Zhou, Ethan Smith, Lingqiao Liu|<http://arxiv.org/pdf/2409.08091v2>|null
**2024-10-01**|**Segment-Anything Models Achieve Zero-shot Robustness in Autonomous   Driving**|段元模型在自动驾驶中实现零样本鲁棒性|Jun Yan, Pengyu Wang, Danni Wang, Weiquan Huang, Daniel Watzenig, Huilin Yin|<http://arxiv.org/pdf/2408.09839v2>|**[link](https://github.com/momo1986/robust_sam_iv)**
**2024-10-01**|**Counterfactual Explanations for Medical Image Classification and   Regression using Diffusion Autoencoder**|反事实解释在基于扩散自编码器的医学图像分类与回归中的应用|Matan Atad, David Schinz, Hendrik Moeller, Robert Graf, Benedikt Wiestler, Daniel Rueckert, Nassir Navab, Jan S. Kirschke, Matthias Keicher|<http://arxiv.org/pdf/2408.01571v2>|**[link](https://github.com/matanat/dae_counterfactual)**
**2024-10-01**|**Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy   Curvature of Attention**|平滑能量引导：利用降低的注意力能量曲率指导扩散模型|Susung Hong|<http://arxiv.org/pdf/2408.00760v2>|**[link](https://github.com/susunghong/seg-sdxl)**
**2024-10-01**|**OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and   Understanding**|OMG-LLaVA：桥接图像级、对象级、像素级推理与理解|Tao Zhang, Xiangtai Li, Hao Fei, Haobo Yuan, Shengqiong Wu, Shunping Ji, Chen Change Loy, Shuicheng Yan|<http://arxiv.org/pdf/2406.19389v2>|null
**2024-10-01**|**Generative Expansion of Small Datasets: An Expansive Graph Approach**|生成式小样本数据集扩展：一种扩张图方法|Vahid Jebraeeli, Bo Jiang, Hamid Krim, Derya Cansever|<http://arxiv.org/pdf/2406.17238v2>|null
**2024-10-01**|**SPAMming Labels: Efficient Annotations for the Trackers of Tomorrow**|高效标注：面向未来的追踪器SPAM标签生成技术|Orcun Cetintas, Tim Meinhardt, Guillem Brasó, Laura Leal-Taixé|<http://arxiv.org/pdf/2404.11426v3>|null
**2024-10-01**|**FiTv2: Scalable and Improved Flexible Vision Transformer for Diffusion   Model**|FiTv2：面向扩散模型的可扩展与改进型柔性视觉Transformer|Zidong Wang, Zeyu Lu, Di Huang, Cai Zhou, Wanli Ouyang, Lei Bai|<http://arxiv.org/pdf/2402.12376v2>|**[link](https://github.com/whlzy/fit)**
**2024-10-01**|**Noise-NeRF: Hide Information in Neural Radiance Fields using Trainable   Noise**|噪声-NeRF：使用可训练噪声在神经辐射场中隐藏信息|Qinglong Huang, Haoran Li, Yong Liao, Yanbin Hao, Pengyuan Zhou|<http://arxiv.org/pdf/2401.01216v2>|null
**2024-10-01**|**SpeedUpNet: A Plug-and-Play Adapter Network for Accelerating   Text-to-Image Diffusion Models**|SpeedUpNet：加速文本到图像扩散模型的即插即用适配网络|Weilong Chai, DanDan Zheng, Jiajiong Cao, Zhiquan Chen, Changbao Wang, Chenguang Ma|<http://arxiv.org/pdf/2312.08887v4>|null
**2024-10-01**|**Ladder Bottom-up Convolutional Bidirectional Variational Autoencoder for   Image Translation of Dotted Arabic Expiration Dates**|基于梯底卷积双向变分自编码器的点状阿拉伯语有效期图像转换方法|Ahmed Zidane, Ghada Soliman|<http://arxiv.org/pdf/2310.14069v2>|null
**2024-10-01**|**From Text to Mask: Localizing Entities Using the Attention of   Text-to-Image Diffusion Models**|文本到掩码：使用文本到图像扩散模型的注意力定位实体|Changming Xiao, Qi Yang, Feng Zhou, Changshui Zhang|<http://arxiv.org/pdf/2309.04109v2>|**[link](https://github.com/Big-Brother-Pikachu/Text2Mask)**

## 多模态

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-10-01**|**Towards Unified Multimodal Editing with Enhanced Knowledge Collaboration**|统一多模态编辑的增强知识协同方法研究|Kaihang Pan, Zhaoyu Fan, Juncheng Li, Qifan Yu, Hao Fei, Siliang Tang, Richang Hong, Hanwang Zhang, Qianru Sun|<http://arxiv.org/pdf/2409.19872v2>|null
**2024-10-01**|**NeuroPath: A Neural Pathway Transformer for Joining the Dots of Human   Connectomes**|神经路径变换器NeuroPath：连接人类连接组点的神经网络通路研究|Ziquan Wei, Tingting Dan, Jiaqi Ding, Guorong Wu|<http://arxiv.org/pdf/2409.17510v2>|**[link](https://github.com/Chrisa142857/neuro_detour)**
**2024-10-01**|**Evaluating Image Hallucination in Text-to-Image Generation with   Question-Answering**|基于问答评估文本到图像生成中的图像幻觉问题|Youngsun Lim, Hojun Choi, Pin-Yu Chen, Hyunjung Shim|<http://arxiv.org/pdf/2409.12784v3>|null
**2024-10-01**|**Shaking Up VLMs: Comparing Transformers and Structured State Space   Models for Vision & Language Modeling**|shaking up VLMs：比较视觉与语言建模中的Transformer和结构化状态空间模型|Georgios Pantazopoulos, Malvina Nikandrou, Alessandro Suglia, Oliver Lemon, Arash Eshghi|<http://arxiv.org/pdf/2409.05395v2>|**[link](https://github.com/gpantaz/vl_mamba)**
**2024-10-01**|**GMAI-MMBench: A Comprehensive Multimodal Evaluation Benchmark Towards   General Medical AI**|GMAI-MMBench：面向通用医疗AI的全面多模态评估基准|Pengcheng Chen, Jin Ye, Guoan Wang, Yanjun Li, Zhongying Deng, Wei Li, Tianbin Li, Haodong Duan, Ziyan Huang, Yanzhou Su, et.al.|<http://arxiv.org/pdf/2408.03361v5>|**[link](https://github.com/open-compass/vlmevalkit)**
**2024-10-01**|**MapsTP: HD Map Images Based Multimodal Trajectory Prediction for   Automated Vehicles**|基于高精地图图像的多模态轨迹预测方法 MapsTP：面向自动驾驶车辆|Sushil Sharma, Arindam Das, Ganesh Sistu, Mark Halton, Ciarán Eising|<http://arxiv.org/pdf/2407.05811v3>|null
**2024-10-01**|**Visual Robustness Benchmark for Visual Question Answering (VQA)**|视觉问答（VQA）视觉鲁棒性基准测试|Md Farhan Ishmam, Ishmam Tashdeed, Talukder Asir Saadat, Md Hamjajul Ashmafee, Abu Raihan Mostofa Kamal, Md. Azam Hossain|<http://arxiv.org/pdf/2407.03386v3>|**[link](https://github.com/ishmamt/Visual-Robustness)**
**2024-10-01**|**MDA: An Interpretable Multi-Modal Fusion with Missing Modalities and   Intrinsic Noise**|MDA：一种具有缺失模态和固有噪声的可解释多模态融合方法|Lin Fan, Yafei Ou, Cenyang Zheng, Pengyu Dai, Tamotsu Kamishima, Masayuki Ikebe, Kenji Suzuki, Xun Gong|<http://arxiv.org/pdf/2406.10569v2>|null
**2024-10-01**|**LUMA: A Benchmark Dataset for Learning from Uncertain and Multimodal   Data**|LUMA：用于不确定性和多模态数据学习的基准数据集|Grigor Bezirganyan, Sana Sellami, Laure Berti-Équille, Sébastien Fournier|<http://arxiv.org/pdf/2406.09864v2>|**[link](https://github.com/bezirganyan/luma)**
**2024-10-01**|**Finding Shared Decodable Concepts and their Negations in the Brain**|寻找大脑中可共享解码的概念及其否定|Cory Efird, Alex Murphy, Joel Zylberberg, Alona Fyshe|<http://arxiv.org/pdf/2405.17663v2>|null
**2024-10-01**|**Design as Desired: Utilizing Visual Question Answering for Multimodal   Pre-training**|视觉问答在多模态预训练中的设计与应用：按需构建|Tongkun Su, Jun Li, Xi Zhang, Haibo Jin, Hao Chen, Qiong Wang, Faqin Lv, Baoliang Zhao, Yin Hu|<http://arxiv.org/pdf/2404.00226v3>|**[link](https://github.com/moramisu/qft-miccai2024)**
**2024-10-01**|**Towards Language-Driven Video Inpainting via Multimodal Large Language   Models**|面向语言驱动的视频修复：基于多模态大型语言模型的方法|Jianzong Wu, Xiangtai Li, Chenyang Si, Shangchen Zhou, Jingkang Yang, Jiangning Zhang, Yining Li, Kai Chen, Yunhai Tong, Ziwei Liu, et.al.|<http://arxiv.org/pdf/2401.10226v2>|**[link](https://github.com/jianzongwu/language-driven-video-inpainting)**
**2024-10-01**|**ViLA: Efficient Video-Language Alignment for Video Question Answering**|ViLA：面向视频问答的高效视频-语言对齐方法|Xijun Wang, Junbang Liang, Chun-Kai Wang, Kenan Deng, Yu Lou, Ming Lin, Shan Yang|<http://arxiv.org/pdf/2312.08367v4>|**[link](https://github.com/xijun-cs/vila)**
**2024-10-01**|**Video-LLaVA: Learning United Visual Representation by Alignment Before   Projection**|视频-LLaVA：通过对齐后再投影学习统一的视觉表示|Bin Lin, Yang Ye, Bin Zhu, Jiaxi Cui, Munan Ning, Peng Jin, Li Yuan|<http://arxiv.org/pdf/2311.10122v3>|**[link](https://github.com/PKU-YuanGroup/Video-LLaVA)**
**2024-10-01**|**Gait Recognition in Large-scale Free Environment via Single LiDAR**|大规模自由环境下基于单台LiDAR的步态识别研究|Xiao Han, Yiming Ren, Peishan Cong, Yujing Sun, Jingya Wang, Lan Xu, Yuexin Ma|<http://arxiv.org/pdf/2211.12371v3>|null

## Nerf

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-10-01**|**RNG: Relightable Neural Gaussians**|RNG：可重照明神经高斯模型|Jiahui Fan, Fujun Luan, Jian Yang, Miloš Hašan, Beibei Wang|<http://arxiv.org/pdf/2409.19702v2>|null
**2024-10-01**|**CD-NGP: A Fast Scalable Continual Representation for Dynamic Scenes**|CD-NGP：动态场景的一种快速可扩展持续表示方法|Zhenhuan Liu, Shuai Liu, Zhiwei Ning, Jie Yang, Wei Liu|<http://arxiv.org/pdf/2409.05166v2>|null

## 模型压缩/优化

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-10-01**|**Self-Adapting Large Visual-Language Models to Edge Devices across Visual   Modalities**|自适配的大规模视觉-语言模型在边缘设备上的跨视觉模态应用|Kaiwen Cai, Zhekai Duan, Gaowen Liu, Charles Fleming, Chris Xiaoxuan Lu|<http://arxiv.org/pdf/2403.04908v3>|**[link](https://github.com/ramdrop/edgevl)**

## 分类/检测/识别/分割/...

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-10-01**|**See Detail Say Clear: Towards Brain CT Report Generation via   Pathological Clue-driven Representation Learning**|"观察细节，清晰描述：基于病理线索驱动的表示学习脑部CT报告生成研究"|Chengxin Zheng, Junzhong Ji, Yanzhao Shi, Xiaodan Zhang, Liangqiong Qu|<http://arxiv.org/pdf/2409.19676v2>|**[link](https://github.com/chauncey-jheng/pcrl-mrg)**
**2024-10-01**|**Automated Segmentation and Analysis of Microscopy Images of Laser Powder   Bed Fusion Melt Tracks**|激光粉末床熔融熔迹显微图像的自动分割与分析|Aagam Shah, Reimar Weissbach, David A. Griggs, A. John Hart, Elif Ertekin, Sameh Tawfick|<http://arxiv.org/pdf/2409.18326v2>|null
**2024-10-01**|**RICAU-Net: Residual-block Inspired Coordinate Attention U-Net for   Segmentation of Small and Sparse Calcium Lesions in Cardiac CT**|RICAU-Net：基于残差块启发式坐标注意力U-Net的小而稀疏心脏CT钙化灶分割方法|Doyoung Park, Jinsoo Kim, Qi Chang, Shuang Leng, Liang Zhong, Lohendran Baskaran|<http://arxiv.org/pdf/2409.06993v2>|null
**2024-10-01**|**LITE: A Paradigm Shift in Multi-Object Tracking with Efficient ReID   Feature Integration**|LITE：一种在多目标跟踪中通过高效ReID特征整合实现范式转变的方法|Jumabek Alikhanov, Dilshod Obidov, Hakil Kim|<http://arxiv.org/pdf/2409.04187v2>|**[link](https://github.com/jumabek/lite)**
**2024-10-01**|**More precise edge detections**|更精确的边缘检测技术|Hao Shu|<http://arxiv.org/pdf/2407.19992v2>|**[link](https://github.com/hao-b-shu/sdped)**
**2024-10-01**|**Optimizing Synthetic Data for Enhanced Pancreatic Tumor Segmentation**|优化合成数据以提升胰腺肿瘤分割效果|Linkai Peng, Zheyuan Zhang, Gorkem Durak, Frank H. Miller, Alpay Medetalibeyoglu, Michael B. Wallace, Ulas Bagci|<http://arxiv.org/pdf/2407.19284v2>|**[link](https://github.com/lkpengcs/syntumoranalyzer)**
**2024-10-01**|**Deformable Convolution Based Road Scene Semantic Segmentation of Fisheye   Images in Autonomous Driving**|基于可变形卷积的自动驾驶鱼眼图像道路场景语义分割|Anam Manzoor, Aryan Singh, Ganesh Sistu, Reenu Mohandas, Eoin Grua, Anthony Scanlan, Ciarán Eising|<http://arxiv.org/pdf/2407.16647v2>|null
**2024-10-01**|**Velocity Driven Vision: Asynchronous Sensor Fusion Birds Eye View Models   for Autonomous Vehicles**|速度驱动的视觉：自动驾驶车辆异步传感器融合鸟瞰视图模型|Seamie Hayes, Sushil Sharma, Ciarán Eising|<http://arxiv.org/pdf/2407.16636v3>|null
**2024-10-01**|**SS-SFR: Synthetic Scenes Spatial Frequency Response on Virtual KITTI and   Degraded Automotive Simulations for Object Detection**|SS-SFR：基于虚拟KITTI和降质汽车模拟合成场景的空间频率响应目标检测研究|Daniel Jakab, Alexander Braun, Cathaoir Agnew, Reenu Mohandas, Brian Michael Deegan, Dara Molloy, Enda Ward, Tony Scanlan, Ciarán Eising|<http://arxiv.org/pdf/2407.15646v2>|null
**2024-10-01**|**AXIAL: Attention-based eXplainability for Interpretable Alzheimer's   Localized Diagnosis using 2D CNNs on 3D MRI brain scans**|轴向：基于注意力解释性的可解释性阿尔茨海默病局部诊断——使用3D MRI脑扫描上的2D CNNs|Gabriele Lozupone, Alessandro Bria, Francesco Fontanella, Frederick J. A. Meijer, Claudio De Stefano|<http://arxiv.org/pdf/2407.02418v2>|**[link](https://github.com/GabrieleLozupone/AXIAL)**
**2024-10-01**|**Continual Learning in Medical Imaging: A Survey and Practical Analysis**|持续学习在医学影像中的应用：综述与实用分析|Mohammad Areeb Qazi, Anees Ur Rehman Hashmi, Santosh Sanjeev, Ibrahim Almakky, Numan Saeed, Camila Gonzalez, Mohammad Yaqub|<http://arxiv.org/pdf/2405.13482v2>|**[link](https://github.com/biomedia-mbzuai/awesome-cl-in-medical)**
**2024-10-01**|**Automatic Quantification of Serial PET/CT Images for Pediatric Hodgkin   Lymphoma Patients Using a Longitudinally-Aware Segmentation Network**|基于纵向感知分割网络的儿童霍奇金淋巴瘤患者序贯PET/CT图像自动量化研究|Xin Tie, Muheon Shin, Changhee Lee, Scott B. Perlman, Zachary Huemann, Amy J. Weisman, Sharon M. Castellino, Kara M. Kelly, Kathleen M. McCarten, Adina L. Alazraki, et.al.|<http://arxiv.org/pdf/2404.08611v2>|**[link](https://github.com/xtie97/las-net)**
**2024-10-01**|**ParFormer: A Vision Transformer with Parallel Mixer and Sparse Channel   Attention Patch Embedding**|ParFormer：一种具有并行混合器和稀疏通道注意力的图像Transformer嵌入方法|Novendra Setyawan, Ghufron Wahyu Kurniawan, Chi-Chia Sun, Jun-Wei Hsieh, Jing-Ming Guo, Wen-Kai Kuo|<http://arxiv.org/pdf/2403.15004v2>|**[link](https://github.com/novendrastywn/parformer-cape-2024)**
**2024-10-01**|**Individual mapping of large polymorphic shrubs in high mountains using   satellite images and deep learning**|利用卫星影像与深度学习对高山大型多态灌木个体映射|Rohaifa Khaldi, Siham Tabik, Sergio Puertas-Ruiz, Julio Peñas de Giles, José Antonio Hódar Correa, Regino Zamora, Domingo Alcaraz Segura|<http://arxiv.org/pdf/2401.17985v2>|null
**2024-10-01**|**OMG-Seg: Is One Model Good Enough For All Segmentation?**|OMG-Seg：一个模型是否足够应对所有分割任务？|Xiangtai Li, Haobo Yuan, Wei Li, Henghui Ding, Size Wu, Wenwei Zhang, Yining Li, Kai Chen, Chen Change Loy|<http://arxiv.org/pdf/2401.10229v2>|**[link](https://github.com/lxtgh/omg-seg)**
**2024-10-01**|**S3Net: Innovating Stereo Matching and Semantic Segmentation with a   Single-Branch Semantic Stereo Network in Satellite Epipolar Imagery**|S3Net：单分支语义立体网络在卫星极线图像中的立体匹配与语义分割创新应用|Qingyuan Yang, Guanzhou Chen, Xiaoliang Tan, Tong Wang, Jiaqi Wang, Xiaodong Zhang|<http://arxiv.org/pdf/2401.01643v3>|**[link](https://github.com/cveo/s3net)**
**2024-10-01**|**SVFAP: Self-supervised Video Facial Affect Perceiver**|SVFAP：自监督视频面部情感感知器|Licai Sun, Zheng Lian, Kexin Wang, Yu He, Mingyu Xu, Haiyang Sun, Bin Liu, Jianhua Tao|<http://arxiv.org/pdf/2401.00416v2>|**[link](https://github.com/sunlicai/svfap)**
**2024-10-01**|**Whale Detection Enhancement through Synthetic Satellite Images**|通过合成卫星图像提升鲸鱼检测效果|Akshaj Gaur, Cheng Liu, Xiaomin Lin, Nare Karapetyan, Yiannis Aloimonos|<http://arxiv.org/pdf/2308.07766v2>|**[link](https://github.com/prgumd/seadronesim2)**

## OCR

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-10-01**|**Camera Height Doesn't Change: Unsupervised Training for Metric Monocular   Road-Scene Depth Estimation**|无监督训练下的单目道路场景度量深度估计：相机高度不变策略|Genki Kinoshita, Ko Nishino|<http://arxiv.org/pdf/2312.04530v3>|null

## 图像理解

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-10-01**|**MobileMEF: Fast and Efficient Method for Multi-Exposure Fusion**|MobileMEF：一种快速高效的多曝光融合方法|Lucas Nedel Kirsten, Zhicheng Fu, Nikhil Ambha Madhusudhana|<http://arxiv.org/pdf/2408.07932v2>|**[link](https://github.com/lucaskirsten/mobilemef)**

## LLM

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-10-01**|**How Far Are We from Intelligent Visual Deductive Reasoning?**|视觉演绎推理智能化的距离还有多远？|Yizhe Zhang, He Bai, Ruixiang Zhang, Jiatao Gu, Shuangfei Zhai, Josh Susskind, Navdeep Jaitly|<http://arxiv.org/pdf/2403.04732v3>|**[link](https://github.com/apple/ml-rpm-bench)**

## Transformer

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-10-01**|**Famba-V: Fast Vision Mamba with Cross-Layer Token Fusion**|Famba-V：基于跨层Token融合的快速视觉曼巴网络|Hui Shen, Zhongwei Wan, Xin Wang, Mi Zhang|<http://arxiv.org/pdf/2409.09808v2>|**[link](https://github.com/aiot-mlsys-lab/famba-v)**
**2024-10-01**|**OmniHands: Towards Robust 4D Hand Mesh Recovery via A Versatile   Transformer**|全向手部：通过多功能Transformer实现稳健的4D手部网格恢复|Dixuan Lin, Yuxiang Zhang, Mengcheng Li, Yebin Liu, Wei Jing, Qi Yan, Qianying Wang, Hongwen Zhang|<http://arxiv.org/pdf/2405.20330v3>|null
**2024-10-01**|**CoTracker: It is Better to Track Together**|CoTracker：协同追踪更高效|Nikita Karaev, Ignacio Rocco, Benjamin Graham, Natalia Neverova, Andrea Vedaldi, Christian Rupprecht|<http://arxiv.org/pdf/2307.07635v3>|**[link](https://github.com/facebookresearch/co-tracker)**

## 3D/CG

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-10-01**|**Multi-Robot Informative Path Planning for Efficient Target Mapping using   Deep Reinforcement Learning**|多机器人基于深度强化学习的有效目标建图信息路径规划|Apoorva Vashisth, Dipam Patel, Damon Conover, Aniket Bera|<http://arxiv.org/pdf/2409.16967v2>|**[link](https://github.com/accgen99/marl_ipp)**
**2024-10-01**|**Towards Practical Human Motion Prediction with LiDAR Point Clouds**|实用型激光雷达点云人体动作预测研究|Xiao Han, Yiming Ren, Yichen Yao, Yujing Sun, Yuexin Ma|<http://arxiv.org/pdf/2408.08202v2>|null
**2024-10-01**|**Multi-RoI Human Mesh Recovery with Camera Consistency and Contrastive   Losses**|多RoI人体网格恢复与相机一致性及对比损失研究|Yongwei Nie, Changzhen Liu, Chengjiang Long, Qing Zhang, Guiqing Li, Hongmin Cai|<http://arxiv.org/pdf/2402.02074v2>|**[link](https://github.com/cptdiaos/multi-roi)**

## 各类学习方式

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-10-01**|**Observe Then Act: Asynchronous Active Vision-Action Model for Robotic   Manipulation**|观而后行：用于机器人操作的非同步主动视觉-动作模型|Guokang Wang, Hang Li, Shuyuan Zhang, Yanhong Liu, Huaping Liu|<http://arxiv.org/pdf/2409.14891v2>|null

## 其他

|Publish Date|Title|Title_CN|Authors|PDF|Code|
|---|---|---|---|---|---|
**2024-10-01**|**FLeNS: Federated Learning with Enhanced Nesterov-Newton Sketch**|FLeNS：基于增强Nesterov-Newton Sketch的联邦学习算法|Sunny Gupta, Mohit Jindal, Pankhi Kashyap, Pranav Jeevan, Amit Sethi|<http://arxiv.org/pdf/2409.15216v2>|null
**2024-10-01**|**Toward General-Purpose Robots via Foundation Models: A Survey and   Meta-Analysis**|迈向通用型机器人：基础模型研究综述与元分析|Yafei Hu, Quanting Xie, Vidhi Jain, Jonathan Francis, Jay Patrikar, Nikhil Keetha, Seungchan Kim, Yaqi Xie, Tianyi Zhang, Hao-Shu Fang, et.al.|<http://arxiv.org/pdf/2312.08782v3>|null
**2024-10-01**|**Identifying Spurious Correlations using Counterfactual Alignment**|使用反事实对齐识别虚假相关性|Joseph Paul Cohen, Louis Blankemeier, Akshay Chaudhari|<http://arxiv.org/pdf/2312.02186v2>|**[link](https://github.com/ieee8023/latentshift)**
**2024-10-01**|**Mitigating Shortcut Learning with Diffusion Counterfactuals and Diverse   Ensembles**|缓解捷径学习：基于扩散反事实与多样化集成的策略|Luca Scimeca, Alexander Rubinstein, Damien Teney, Seong Joon Oh, Armand Mihai Nicolicioiu, Yoshua Bengio|<http://arxiv.org/pdf/2311.16176v4>|null

