## [UPDATED!] **2024-12-26** (Update Time)


## 3D感知

|发布日期|英文标题|中文标题|作者|PDF链接|代码链接|
|---|---|---|---|---|---|
|2024-12-26|Resolving the Ambiguity of Complete-to-Partial Point Cloud Registration for Image-Guided Liver Surgery with Patches-to-Partial Matching|解决基于图像引导的肝脏手术中完整到部分点云配准的歧义：使用补丁到部分匹配|Zixin Yang, Jon S. Heiselman, Cheng Han, Kelly Merrell, Richard Simon, Cristian. A. Linte|<http://arxiv.org/pdf/2412.19328v1>|None|
|2024-12-26|3D Learnable Supertoken Transformer for LiDAR Point Cloud Scene Segmentation|3D可学习超标记Transformer用于激光雷达点云场景分割|Dening Lu, Jun Zhou, Kyle Gao, Linlin Xu, Jonathan Li|<http://arxiv.org/pdf/2405.15826v2>|None|
|2024-12-26|SeaMo: A Multi-Seasonal and Multimodal Remote Sensing Foundation Model|SeaMo：一种多季节和多模态遥感基础模型|Xuyang Li, Danfeng Hong, Chenyu Li, Jocelyn Chanussot|<http://arxiv.org/pdf/2412.19237v1>|None|
|2024-12-26|EMWaveNet: Physically Explainable Neural Network Based on Electromagnetic Propagation for SAR Target Recognition|电磁传播基础上的物理可解释神经网络在SAR目标识别中的应用|Zhuoxuan Li, Xu Zhang, Shumeng Yu, Haipeng Wang|<http://arxiv.org/pdf/2410.09749v2>|None|
|2024-12-26|Generating Editable Head Avatars with 3D Gaussian GANs|使用3D高斯生成对抗网络生成可编辑的头像|Guohao Li, Hongyu Yang, Yifang Men, Di Huang, Weixin Li, Ruijie Yang, Yunhong Wang|<http://arxiv.org/pdf/2412.19149v1>|<https://github.com/liguohao96/EGG3D.>|
|2024-12-26|Impact of color and mixing proportion of synthetic point clouds on semantic segmentation|合成点云中颜色和混合比例对语义分割的影响|Shaojie Zhou, Jia-Rui Lin, Peng Pan, Yuandong Pan, Ioannis Brilakis|<http://arxiv.org/pdf/2412.19145v1>|None|
|2024-12-26|CLIP-GS: Unifying Vision-Language Representation with 3D Gaussian Splatting|CLIP-GS：利用3D高斯分层统一视觉-语言表示|Siyu Jiao, Haoye Dong, Yuyang Yin, Zequn Jie, Yinlong Qian, Yao Zhao, Humphrey Shi, Yunchao Wei|<http://arxiv.org/pdf/2412.19142v1>|None|
|2024-12-26|Learning Monocular Depth from Events via Egomotion Compensation|通过自运动补偿学习事件单目深度|Haitao Meng, Chonghao Zhong, Sheng Tang, Lian JunJia, Wenwei Lin, Zhenshan Bing, Yi Chang, Gang Chen|<http://arxiv.org/pdf/2412.19067v1>|None|
|2024-12-26|DAPoinTr: Domain Adaptive Point Transformer for Point Cloud Completion|DAPoinTr：领域自适应点云补全的点云转换器|Yinghui Li, Qianyu Zhou, Jingyu Gong, Ye Zhu, Richard Dazeley, Xinkui Zhao, Xuequan Lu|<http://arxiv.org/pdf/2412.19062v1>|<https://github.com/Yinghui-Li-New/DAPoinTr>|
|2024-12-26|Imperceptible Adversarial Attacks on Point Clouds Guided by Point-to-Surface Field|不可察觉的点云对抗攻击，由点至面场引导|Keke Tang, Weiyao Ke, Weilong Peng, Xiaofei Wang, Ziyong Du, Zhize Wu, Peican Zhu, Zhihong Tian|<http://arxiv.org/pdf/2412.19015v1>|None|
|2024-12-26|Predictive Pattern Recognition Techniques Towards Spatiotemporal Representation of Plant Growth in Simulated and Controlled Environments: A Comprehensive Review|面向模拟和控制环境中植物生长时空表示的预测模式识别技术：全面综述|Mohamed Debbagh, Shangpeng Sun, Mark Lefsrud|<http://arxiv.org/pdf/2412.10538v2>|None|


## 3D重建

|发布日期|英文标题|中文标题|作者|PDF链接|代码链接|
|---|---|---|---|---|---|
|2024-12-26|LiHi-GS: LiDAR-Supervised Gaussian Splatting for Highway Driving Scene Reconstruction|LiHi-GS：基于激光雷达监督的高斯分层渲染在高速公路驾驶场景重建中的应用|Pou-Chun Kung, Xianling Zhang, Katherine A. Skinner, Nikita Jaipuria|<http://arxiv.org/pdf/2412.15447v2>|None|
|2024-12-26|MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo|MVS-GS：基于在线多视图立体的高质量3D高斯分层映射|Byeonggwon Lee, Junkyu Park, Khang Truong Giang, Sungho Jo, Soohwan Song|<http://arxiv.org/pdf/2412.19130v1>|None|
|2024-12-26|Reconstruction Target Matters in Masked Image Modeling for Cross-Domain Few-Shot Learning|跨域小样本学习中的掩码图像建模：重建目标至关重要|Ran Ma, Yixiong Zou, Yuhua Li, Ruixuan Li|<http://arxiv.org/pdf/2412.19101v1>|None|
|2024-12-26|Humans as a Calibration Pattern: Dynamic 3D Scene Reconstruction from Unsynchronized and Uncalibrated Videos|人类作为校准图案：从未同步和未校准的视频中进行动态3D场景重建|Changwoon Choi, Jeongjun Kim, Geonho Cha, Minkwan Kim, Dongyoon Wee, Young Min Kim|<http://arxiv.org/pdf/2412.19089v1>|None|


## NeRF

|发布日期|英文标题|中文标题|作者|PDF链接|代码链接|
|---|---|---|---|---|---|
|2024-12-26|Reflective Gaussian Splatting|反射高斯分层|Yuxuan Yao, Zixuan Zeng, Chun Gu, Xiatian Zhu, Li Zhang|<http://arxiv.org/pdf/2412.19282v1>|None|
|2024-12-26|NADER: Neural Architecture Design via Multi-Agent Collaboration|NADER：通过多智能体协作进行神经网络架构设计|Zekang Yang, Wang Zeng, Sheng Jin, Chen Qian, Ping Luo, Wentao Liu|<http://arxiv.org/pdf/2412.19206v1>|None|
|2024-12-26|Brain Ageing Prediction using Isolation Forest Technique and Residual Neural Network (ResNet)|基于隔离森林技术和残差神经网络（ResNet）的脑龄预测|Saadat Behzadi, Danial Sharifrazi, Roohallah Alizadehsani, Mojtaba Lotfaliany, Mohammadreza Mohebbi|<http://arxiv.org/pdf/2412.19017v1>|None|
|2024-12-26|Concept Discovery in Deep Neural Networks for Explainable Face Anti-Spoofing|深度神经网络中的概念发现用于可解释的人脸反欺骗|Haoyuan Zhang, Xiangyu Zhu, Li Gao, Jiawei Pan, Kai Pang, Guoying Zhao, Stan Z. Li, Zhen Lei|<http://arxiv.org/pdf/2412.17541v2>|None|


## 人体解析

|发布日期|英文标题|中文标题|作者|PDF链接|代码链接|
|---|---|---|---|---|---|
|2024-12-26|Extended Cross-Modality United Learning for Unsupervised Visible-Infrared Person Re-identification|扩展跨模态联合学习用于无监督可见光-红外行人重识别|Ruixing Wu, Yiming Yang, Jiakai He, Haifeng Hu|<http://arxiv.org/pdf/2412.19134v1>|None|


## 人脸识别/处理

|发布日期|英文标题|中文标题|作者|PDF链接|代码链接|
|---|---|---|---|---|---|
|2024-12-26|Dual Channel Multi-Attention in ViT for Biometric Authentication using Forehead Subcutaneous Vein Pattern and Periocular Pattern|双通道多注意力机制在基于额头皮下静脉图案和眼周图案的生物识别认证中应用于ViT|Arun K. Sharma, Shubhobrata Bhattacharya, Motahar Reza|<http://arxiv.org/pdf/2412.19160v1>|None|


## 图像描述生成

|发布日期|英文标题|中文标题|作者|PDF链接|代码链接|
|---|---|---|---|---|---|
|2024-12-26|ViPCap: Retrieval Text-Based Visual Prompts for Lightweight Image Captioning|ViPCap：基于文本检索的轻量级图像描述生成|Taewhan Kim, Soeun Lee, Si-Woo Kim, Dong-Jin Kim|<http://arxiv.org/pdf/2412.19289v2>|None|
|2024-12-26|Mask Approximation Net: Merging Feature Extraction and Distribution Learning for Remote Sensing Change Captioning|掩码近似网络：融合特征提取和分布学习以实现遥感变化描述|Dongwei Sun, Xiangyong Cao|<http://arxiv.org/pdf/2412.19179v1>|None|
|2024-12-26|A Cross-Font Image Retrieval Network for Recognizing Undeciphered Oracle Bone Inscriptions|一种用于识别未解甲骨文的跨字体图像检索网络|Zhicong Wu, Qifeng Su, Ke Gu, Xiaodong Shi|<http://arxiv.org/pdf/2409.06381v2>|None|


## 图像生成/合成

|发布日期|英文标题|中文标题|作者|PDF链接|代码链接|
|---|---|---|---|---|---|
|2024-12-26|Federated Hybrid Training and Self-Adversarial Distillation: Towards Robust Edge Networks|联邦混合训练与自对抗蒸馏：迈向鲁棒的边缘网络|Yu Qiao, Apurba Adhikary, Kitae Kim, Eui-Nam Huh, Zhu Han, Choong Seon Hong|<http://arxiv.org/pdf/2412.19354v1>|None|
|2024-12-26|Progressive Compression with Universally Quantized Diffusion Models|渐进式压缩与通用量化扩散模型|Yibo Yang, Justus C. Will, Stephan Mandt|<http://arxiv.org/pdf/2412.10935v2>|None|
|2024-12-26|LMFusion: Adapting Pretrained Language Models for Multimodal Generation|LMFusion：自适应预训练语言模型的多模态生成|Weijia Shi, Xiaochuang Han, Chunting Zhou, Weixin Liang, Xi Victoria Lin, Luke Zettlemoyer, Lili Yu|<http://arxiv.org/pdf/2412.15188v2>|None|
|2024-12-26|Manga Generation via Layout-controllable Diffusion|漫画生成：通过布局可控的扩散|Siyu Chen, Dengjie Li, Zenghao Bao, Yao Zhou, Lingfeng Tan, Yujie Zhong, Zheng Zhao|<http://arxiv.org/pdf/2412.19303v1>|None|
|2024-12-26|VINEVI: A Virtualized Network Vision Architecture for Smart Monitoring of Heterogeneous Applications and Infrastructures|虚拟化网络视觉架构VINEVI：用于异构应用和基础设施智能监控|Rodrigo Moreira, Hugo G. V. O. da Cunha, Larissa F. Rodrigues Moreira, Flávio de Oliveira Silva|<http://arxiv.org/pdf/2412.19226v1>|None|
|2024-12-26|AutoMMLab: Automatically Generating Deployable Models from Language Instructions for Computer Vision Tasks|AutoMMLab：从语言指令自动生成适用于计算机视觉任务的部署模型|Zekang Yang, Wang Zeng, Sheng Jin, Chen Qian, Ping Luo, Wentao Liu|<http://arxiv.org/pdf/2402.15351v2>|<https://github.com/yang-ze-kang/AutoMMLab.>|
|2024-12-26|SubjectDrive: Scaling Generative Data in Autonomous Driving via Subject Control|主题驱动：通过主题控制扩展自动驾驶中的生成数据|Binyuan Huang, Yuqing Wen, Yucheng Zhao, Yaosi Hu, Yingfei Liu, Fan Jia, Weixin Mao, Tiancai Wang|<http://arxiv.org/pdf/2403.19438v2>|None|
|2024-12-26|AskChart: Universal Chart Understanding through Textual Enhancement|AskChart：通过文本增强实现通用图表理解|Xudong Yang, Yifan Wu, Yizhang Zhu, Nan Tang, Yuyu Luo|<http://arxiv.org/pdf/2412.19146v1>|None|
|2024-12-26|How Panel Layouts Define Manga: Insights from Visual Ablation Experiments|《面板布局如何定义漫画：视觉消融实验的见解》|Siyuan Feng, Teruya Yoshinaga, Katsuhiko Hayashi, Koki Washio, Hidetaka Kamigaito|<http://arxiv.org/pdf/2412.19141v1>|None|
|2024-12-26|VectorPainter: Advanced Stylized Vector Graphics Synthesis Using Stroke-Style Priors|向量画家：基于笔触风格先验的高级风格化矢量图形合成|Juncheng Hu, Ximing Xing, Jing Zhang, Qian Yu|<http://arxiv.org/pdf/2405.02962v2>|None|
|2024-12-26|Diffusion Model Based Visual Compensation Guidance and Visual Difference Analysis for No-Reference Image Quality Assessment|基于扩散模型的视觉补偿引导与视觉差异分析的无参考图像质量评估|Zhaoyang Wang, Bo Hu, Mingyang Zhang, Jie Li, Leida Li, Maoguo Gong, Xinbo Gao|<http://arxiv.org/pdf/2402.14401v2>|None|
|2024-12-26|Decomposed Prototype Learning for Few-Shot Scene Graph Generation|分解原型学习用于少样本场景图生成|Xingchen Li, Jun Xiao, Guikun Chen, Yinfu Feng, Yi Yang, An-an Liu, Long Chen|<http://arxiv.org/pdf/2303.10863v2>|None|
|2024-12-26|Improving Generative Pre-Training: An In-depth Study of Masked Image Modeling and Denoising Models|提升生成预训练：掩码图像建模与去噪模型深入研究|Hyesong Choi, Daeun Kim, Sungmin Cha, Kwang Moo Yi, Dongbo Min|<http://arxiv.org/pdf/2412.19104v1>|None|
|2024-12-26|UniAvatar: Taming Lifelike Audio-Driven Talking Head Generation with Comprehensive Motion and Lighting Control|UniAvatar：通过全面运动和光照控制驯服逼真音频驱动的说话人头生成|Wenzhang Sun, Xiang Li, Donglin Di, Zhuding Liang, Qiyuan Zhang, Hao Li, Wei Chen, Jianxun Cui|<http://arxiv.org/pdf/2412.19860v1>|None|
|2024-12-26|Phys4DGen: A Physics-Driven Framework for Controllable and Efficient 4D Content Generation from a Single Image|Phys4DGen：基于物理的框架，从单张图像生成可控且高效的4D内容|Jiajing Lin, Zhenzhong Wang, Shu Jiang, Yongjie Hou, Min Jiang|<http://arxiv.org/pdf/2411.16800v3>|None|
|2024-12-26|Mask Factory: Towards High-quality Synthetic Data Generation for Dichotomous Image Segmentation|掩码工厂：迈向高质量二值图像分割合成数据生成|Haotian Qian, YD Chen, Shengtao Lou, Fahad Shahbaz Khan, Xiaogang Jin, Deng-Ping Fan|<http://arxiv.org/pdf/2412.19080v1>|None|
|2024-12-26|DiffPatch: Generating Customizable Adversarial Patches using Diffusion Model|DiffPatch：利用扩散模型生成可定制对抗性补丁|Zhixiang Wang, Guangnan Ye, Xiaosen Wang, Siheng Chen, Zhibo Wang, Xingjun Ma, Yu-Gang Jiang|<http://arxiv.org/pdf/2412.01440v2>|None|
|2024-12-26|PhotoBot: Reference-Guided Interactive Photography via Natural Language|PhotoBot：通过自然语言引导的参考指导交互式摄影|Oliver Limoyo, Jimmy Li, Dmitriy Rivkin, Jonathan Kelly, Gregory Dudek|<http://arxiv.org/pdf/2401.11061v4>|None|
|2024-12-26|A Probabilistic Fluctuation based Membership Inference Attack for Diffusion Models|基于概率波动的扩散模型成员推理攻击|Wenjie Fu, Huandong Wang, Liyuan Zhang, Chen Gao, Yong Li, Tao Jiang|<http://arxiv.org/pdf/2308.12143v5>|None|
|2024-12-26|Improving GFlowNets for Text-to-Image Diffusion Alignment|提升GFlowNets在文本到图像扩散对齐中的应用|Dinghuai Zhang, Yizhe Zhang, Jiatao Gu, Ruixiang Zhang, Josh Susskind, Navdeep Jaitly, Shuangfei Zhai|<http://arxiv.org/pdf/2406.00633v3>|None|
|2024-12-26|Zero-shot Text-guided Infinite Image Synthesis with LLM guidance|零样本基于LLM引导的文本引导无限图像合成|Soyeong Kwon, Taegyeong Lee, Taehwan Kim|<http://arxiv.org/pdf/2407.12642v2>|None|


## 图像编辑/处理

|发布日期|英文标题|中文标题|作者|PDF链接|代码链接|
|---|---|---|---|---|---|
|2024-12-26|BeSplat -- Gaussian Splatting from a Single Blurry Image and Event Stream|贝斯普拉特——从单个模糊图像和事件流中进行高斯喷溅|Gopi Raju Matta, Reddypalli Trisha, Kaushik Mitra|<http://arxiv.org/pdf/2412.19370v1>|None|
|2024-12-26|Completion as Enhancement: A Degradation-Aware Selective Image Guided Network for Depth Completion|深度补全作为增强：一种降质感知的图像引导选择性网络|Zhiqiang Yan, Zhengxue Wang, Kun Wang, Jun Li, Jian Yang|<http://arxiv.org/pdf/2412.19225v1>|None|
|2024-12-26|An End-to-End Depth-Based Pipeline for Selfie Image Rectification|基于深度学习的自拍图像校正端到端流程|Ahmed Alhawwary, Phong Nguyen-Ha, Janne Mustaniemi, Janne Heikkilä|<http://arxiv.org/pdf/2412.19189v1>|None|
|2024-12-26|Multi-Head Attention Driven Dynamic Visual-Semantic Embedding for Enhanced Image-Text Matching|多头注意力驱动的动态视觉-语义嵌入以增强图像-文本匹配|Wenjing Chen|<http://arxiv.org/pdf/2412.19184v1>|None|
|2024-12-26|Object-Centric Open-Vocabulary Image-Retrieval with Aggregated Features|基于聚合特征的以对象为中心的开源词汇图像检索|Hila Levi, Guy Heller, Dan Levi, Ethan Fetaya|<http://arxiv.org/pdf/2309.14999v2>|None|
|2024-12-26|FACEMUG: A Multimodal Generative and Fusion Framework for Local Facial Editing|面部MUG：一种用于局部面部编辑的多模态生成与融合框架|Wanglong Lu, Jikai Wang, Xiaogang Jin, Xianta Jiang, Hanli Zhao|<http://arxiv.org/pdf/2412.19009v1>|None|


## 场景理解

|发布日期|英文标题|中文标题|作者|PDF链接|代码链接|
|---|---|---|---|---|---|
|2024-12-26|SpectralKD: Understanding and Optimizing Vision Transformer Distillation through Spectral Analysis|光谱KD：通过光谱分析理解和优化视觉Transformer蒸馏|Huiyuan Tian, Bonan Xu, Shijian Li, Gang Pan|<http://arxiv.org/pdf/2412.19055v1>|None|
|2024-12-26|Relation-aware Hierarchical Prompt for Open-vocabulary Scene Graph Generation|关系感知的开放词汇场景图生成分层提示|Tao Liu, Rongjie Li, Chongyu Wang, Xuming He|<http://arxiv.org/pdf/2412.19021v1>|None|


## 少样本学习

|发布日期|英文标题|中文标题|作者|PDF链接|代码链接|
|---|---|---|---|---|---|
|2024-12-26|Advanced Knowledge Transfer: Refined Feature Distillation for Zero-Shot Quantization in Edge Computing|高级知识迁移：边缘计算中零样本量化的精细特征蒸馏|Inpyo Hong, Youngwan Jo, Hyojeong Lee, Sunghyun Ahn, Sanghyun Park|<http://arxiv.org/pdf/2412.19125v1>|<https://github.com/Inpyo-Hong/AKT-Advanced-knowledge-Transfer.>|


## 模型压缩

|发布日期|英文标题|中文标题|作者|PDF链接|代码链接|
|---|---|---|---|---|---|
|2024-12-26|Task Preference Optimization: Improving Multimodal Large Language Models with Vision Task Alignment|任务偏好优化：通过视觉任务对齐提升多模态大型语言模型|Ziang Yan, Zhilin Li, Yinan He, Chenting Wang, Kunchang Li, Xinhao Li, Xiangyu Zeng, Zilei Wang|<http://arxiv.org/pdf/2412.19326v1>|<https://github.com/OpenGVLab/TPO>|


## 渲染

|发布日期|英文标题|中文标题|作者|PDF链接|代码链接|
|---|---|---|---|---|---|
|2024-12-26|Uni-Renderer: Unifying Rendering and Inverse Rendering Via Dual Stream Diffusion|统一渲染与逆渲染：通过双流扩散实现|Zhifei Chen, Tianshuo Xu, Wenhang Ge, Leyi Wu, Dongyu Yan, Jing He, Luozhou Wang, Lu Zeng|<http://arxiv.org/pdf/2412.15050v2>|None|


## 目标检测

|发布日期|英文标题|中文标题|作者|PDF链接|代码链接|
|---|---|---|---|---|---|
|2024-12-26|Improving the network traffic classification using the Packet Vision approach|基于Packet Vision方法的网络流量分类改进|Rodrigo Moreira, Larissa Ferreira Rodrigues, Pedro Frosi Rosa, Flávio de Oliveira Silva|<http://arxiv.org/pdf/2412.19360v1>|None|
|2024-12-26|Evaluating Convolutional Neural Networks for COVID-19 classification in chest X-ray images|评估卷积神经网络在胸部X光片中对COVID-19进行分类的性能|Leonardo Gabriel Ferreira Rodrigues, Danilo Ferreira da Silva, Larissa Ferreira Rodrigues, João Fernando Mari|<http://arxiv.org/pdf/2412.19362v1>|None|
|2024-12-26|Transformer-Based Wireless Capsule Endoscopy Bleeding Tissue Detection and Classification|基于Transformer的无线胶囊内窥镜出血组织检测与分类|Basit Alawode, Shibani Hamza, Adarsh Ghimire, Divya Velayudhan|<http://arxiv.org/pdf/2412.19218v1>|<https://github.com/BasitAlawode/WCEBleedGen.>|
|2024-12-26|A Comprehensive Augmentation Framework for Anomaly Detection|全面异常检测增强框架|Jiang Lin, Yaping Yan|<http://arxiv.org/pdf/2308.15068v5>|None|
|2024-12-26|Revisiting Monocular 3D Object Detection from Scene-Level Depth Retargeting to Instance-Level Spatial Refinement|重新审视从场景级深度重定向到实例级空间细化的单目3D目标检测|Qiude Zhang, Chunyu Lin, Zhijie Shen, Nie Lang, Yao Zhao|<http://arxiv.org/pdf/2412.19165v1>|None|
|2024-12-26|Referencing Where to Focus: Improving VisualGrounding with Referential Query|参考聚焦点：通过参考查询改进视觉定位|Yabing Wang, Zhuotao Tian, Qingpei Guo, Zheng Qin, Sanping Zhou, Ming Yang, Le Wang|<http://arxiv.org/pdf/2412.19155v1>|None|
|2024-12-26|SUTrack: Towards Simple and Unified Single Object Tracking|SUTrack：迈向简单且统一的单目标跟踪|Xin Chen, Ben Kang, Wanting Geng, Jiawen Zhu, Yi Liu, Dong Wang, Huchuan Lu|<http://arxiv.org/pdf/2412.19138v1>|<https://github.com/chenxin-dlut/SUTrack.>|
|2024-12-26|Task Success Prediction and Open-Vocabulary Object Manipulation|任务成功预测与开放词汇物体操作|Motonari Kambara, Komei Sugiura|<http://arxiv.org/pdf/2412.19112v1>|None|
|2024-12-26|Spectral Enhancement and Pseudo-Anchor Guidance for Infrared-Visible Person Re-Identification|光谱增强与伪锚引导的红外可见光人员重识别|Yiyuan Ge, Zhihao Chen, Ziyang Wang, Jiaju Kang, Mingya Zhang|<http://arxiv.org/pdf/2412.19111v1>|<https://github.com/1024AILab/ReID-SEPG.>|
|2024-12-26|CSCPR: Cross-Source-Context Indoor RGB-D Place Recognition|跨源上下文室内RGB-D场景识别|Jing Liang, Zhuo Deng, Zheming Zhou, Min Sun, Omid Ghasemalizadeh, Cheng-Hao Kuo, Arnie Sen, Dinesh Manocha|<http://arxiv.org/pdf/2407.17457v2>|None|
|2024-12-26|From Coin to Data: The Impact of Object Detection on Digital Numismatics|从硬币到数据：目标检测对数字钱币学的影响|Rafael Cabral, Maria De Iorio, Andrew Harris|<http://arxiv.org/pdf/2412.19091v1>|None|
|2024-12-26|Queryable Prototype Multiple Instance Learning with Vision-Language Models for Incremental Whole Slide Image Classification|可查询原型多实例学习：基于视觉-语言模型的增量全切片图像分类|Jiaxiang Gou, Luping Ji, Pei Liu, Mao Ye|<http://arxiv.org/pdf/2410.10573v3>|<https://github.com/can-can-ya/QPMIL-VL.>|


## 自监督学习

|发布日期|英文标题|中文标题|作者|PDF链接|代码链接|
|---|---|---|---|---|---|
|2024-12-26|Self-supervised visual learning in the low-data regime: a comparative evaluation|自监督视觉学习在低数据环境下的比较评估|Sotirios Konstantakos, Jorgen Cani, Ioannis Mademlis, Despina Ioanna Chalkiadaki, Yuki M. Asano, Efstratios Gavves, Georgios Th. Papadopoulos|<http://arxiv.org/pdf/2404.17202v2>|None|
|2024-12-26|Evaluating Self-Supervised Learning in Medical Imaging: A Benchmark for Robustness, Generalizability, and Multi-Domain Impact|评估医学影像中的自监督学习：鲁棒性、泛化性和多领域影响的基准|Valay Bundele, Oğuz Ata Çal, Bora Kargi, Karahan Sarıtaş, Kıvanç Tezören, Zohreh Ghaderi, Hendrik Lensch|<http://arxiv.org/pdf/2412.19124v1>|None|
|2024-12-26|Cohort-Individual Cooperative Learning for Multimodal Cancer Survival Analysis|队列-个体协同学习多模态癌症生存分析|Huajun Zhou, Fengtao Zhou, Hao Chen|<http://arxiv.org/pdf/2404.02394v2>|None|


## 视觉-语言理解

|发布日期|英文标题|中文标题|作者|PDF链接|代码链接|
|---|---|---|---|---|---|
|2024-12-26|World-to-Words: Grounded Open Vocabulary Acquisition through Fast Mapping in Vision-Language Models|世界到词汇：通过视觉-语言模型中的快速映射实现基于地标的开放词汇获取|Ziqiao Ma, Jiayi Pan, Joyce Chai|<http://arxiv.org/pdf/2306.08685v2>|<https://github.com/sled-group/world-to-words>|
|2024-12-26|MoPD: Mixture-of-Prompts Distillation for Vision-Language Models|MoPD：视觉-语言模型混合提示蒸馏|Yang Chen, Shuai Fu, Yu Zhang|<http://arxiv.org/pdf/2412.19087v1>|None|
|2024-12-26|Scratching Visual Transformer's Back with Uniform Attention|用统一注意力为视觉Transformer挠痒|Nam Hyeon-Woo, Kim Yu-Ji, Byeongho Heo, Dongyoon Han, Seong Joon Oh, Tae-Hyun Oh|<http://arxiv.org/pdf/2210.08457v2>|None|
|2024-12-26|Universal dimensions of visual representation|视觉表示的通用维度|Zirui Chen, Michael F. Bonner|<http://arxiv.org/pdf/2408.12804v2>|None|


## 视频分析

|发布日期|英文标题|中文标题|作者|PDF链接|代码链接|
|---|---|---|---|---|---|
|2024-12-26|FineVQ: Fine-Grained User Generated Content Video Quality Assessment|精细VQ：细粒度用户生成内容视频质量评估|Huiyu Duan, Qiang Hu, Jiarui Wang, Liu Yang, Zitong Xu, Lu Liu, Xiongkuo Min, Chunlei Cai|<http://arxiv.org/pdf/2412.19238v1>|None|


## 视频生成

|发布日期|英文标题|中文标题|作者|PDF链接|代码链接|
|---|---|---|---|---|---|
|2024-12-26|Deep Common Feature Mining for Efficient Video Semantic Segmentation|深度通用特征挖掘用于高效视频语义分割|Yaoyan Zheng, Hongyu Yang, Di Huang|<http://arxiv.org/pdf/2403.02689v2>|<https://github.com/BUAAHugeGun/DCFM.>|
|2024-12-26|When SAM2 Meets Video Shadow and Mirror Detection|当SAM2遇见视频阴影和镜像检测|Leiping Jie|<http://arxiv.org/pdf/2412.19293v1>|<https://github.com/LeipingJie/SAM2Video>|
|2024-12-26|Perceive, Query & Reason: Enhancing Video QA with Question-Guided Temporal Queries|感知、查询与推理：通过问题引导的时间查询增强视频问答|Roberto Amoroso, Gengyuan Zhang, Rajat Koner, Lorenzo Baraldi, Rita Cucchiara, Volker Tresp|<http://arxiv.org/pdf/2412.19304v1>|None|
|2024-12-26|Which Viewpoint Shows it Best? Language for Weakly Supervising View Selection in Multi-view Videos|哪种视角展示得最好？多视角视频中弱监督视角选择的语言|Sagnik Majumder, Tushar Nagarajan, Ziad Al-Halah, Reina Pradhan, Kristen Grauman|<http://arxiv.org/pdf/2411.08753v2>|None|
|2024-12-26|Read, Watch and Scream! Sound Generation from Text and Video|阅读、观看、尖叫！从文本和视频中生成声音|Yujin Jeong, Yunji Kim, Sanghyuk Chun, Jiyoung Lee|<http://arxiv.org/pdf/2407.05551v2>|None|
|2024-12-26|Reversed in Time: A Novel Temporal-Emphasized Benchmark for Cross-Modal Video-Text Retrieval|《逆时而行：一种新颖的跨模态视频-文本检索时间强调基准》|Yang Du, Yuqi Liu, Qin Jin|<http://arxiv.org/pdf/2412.19178v1>|<https://github.com/qyr0403/Reversed-in-Time>|
|2024-12-26|PlanLLM: Video Procedure Planning with Refinable Large Language Models|PlanLLM：可精炼大型语言模型的视频程序规划|Dejie Yang, Zijing Zhao, YangLiu|<http://arxiv.org/pdf/2412.19139v1>|None|
|2024-12-26|Benchmarking Multi-dimensional AIGC Video Quality Assessment: A Dataset and Unified Model|多维AIGC视频质量评估基准：一个数据集和统一模型|Zhichao Zhang, Wei Sun, Xinyue Li, Jun Jia, Xiongkuo Min, Zicheng Zhang, Chunyi Li, Zijian Chen|<http://arxiv.org/pdf/2407.21408v2>|<https://github.com/zczhang-sjtu/UGVQ.git.>|


## 语义分割

|发布日期|英文标题|中文标题|作者|PDF链接|代码链接|
|---|---|---|---|---|---|
|2024-12-26|CALICO: Part-Focused Semantic Co-Segmentation with Large Vision-Language Models|CALICO：基于大型视觉-语言模型的局部聚焦语义共分割|Kiet A. Nguyen, Adheesh Juvekar, Tianjiao Yu, Muntasir Wahed, Ismini Lourentzou|<http://arxiv.org/pdf/2412.19331v1>|None|
|2024-12-26|Promptable Anomaly Segmentation with SAM Through Self-Perception Tuning|可调自感知的SAM通过自感知调优的提示式异常分割|Hui-Yue Yang, Hui Chen, Ao Wang, Kai Chen, Zijia Lin, Yongliang Tang, Pengcheng Gao, Yuming Quan|<http://arxiv.org/pdf/2411.17217v4>|None|
|2024-12-26|Modality-Projection Universal Model for Comprehensive Full-Body Medical Imaging Segmentation|模态投影通用模型：全面全身体医学影像分割|Yixin Chen, Lin Gao, Yajuan Gao, Rui Wang, Jingge Lian, Xiangxi Meng, Yanhua Duan, Leiying Chai|<http://arxiv.org/pdf/2412.19026v1>|None|


## 跨模态检索

|发布日期|英文标题|中文标题|作者|PDF链接|代码链接|
|---|---|---|---|---|---|
|2024-12-26|Semantic Residual for Multimodal Unified Discrete Representation|语义残差用于多模态统一离散表示|Hai Huang, Shulei Wang, Yan Xia|<http://arxiv.org/pdf/2412.19128v1>|None|

