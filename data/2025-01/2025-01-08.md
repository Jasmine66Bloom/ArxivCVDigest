## [UPDATED!] **2025-01-08** (Update Time)


## 3DGS

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|FatesGS: Fast and Accurate Sparse-View Surface Reconstruction using Gaussian Splatting with Depth-Feature Consistency|FatesGSï¼šåŸºäºé«˜æ–¯æ•£å¸ƒä¸æ·±åº¦ç‰¹å¾ä¸€è‡´æ€§çš„å¿«é€Ÿç²¾ç¡®ç¨€ç–è§†å›¾è¡¨é¢é‡å»º|Han Huang, Yulun Wu, Chao Deng, Ge Gao, Ming Gu, Yu-Shen Liu|<http://arxiv.org/pdf/2501.04628v1>|None|
|ğŸ“ æ›´æ–°|Balanced 3DGS: Gaussian-wise Parallelism Rendering with Fine-Grained Tiling|å¹³è¡¡3DGSï¼šåŸºäºé«˜æ–¯å¹¶è¡ŒåŒ–ä¸ç»†ç²’åº¦åˆ†å—çš„æ¸²æŸ“|Hao Gui, Lin Hu, Rui Chen, Mingxiao Huang, Yuxin Yin, Jin Yang, Yong Wu, Chen Liu .etc.|<http://arxiv.org/pdf/2412.17378v3>|None|


## äººä½“åˆ†æ

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Enhancing Financial VQA in Vision Language Models using Intermediate Structured Representations|åˆ©ç”¨ä¸­é—´ç»“æ„è¡¨ç¤ºå¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„é‡‘èè§†è§‰é—®ç­”|Archita Srivastava, Abhas Kumar, Rajesh Kumar, Prabhakar Srinivasan|<http://arxiv.org/pdf/2501.04675v1>|None|
|ğŸ†• å‘å¸ƒ|HyFusion: Enhanced Reception Field Transformer for Hyperspectral Image Fusion|è¶…å…‰è°±å›¾åƒèåˆå¢å¼ºæ¥æ”¶åœºå˜æ¢å™¨ï¼šHyFusion|Chia-Ming Lee, Yu-Fan Lin, Yu-Hao Ho, Li-Wei Kang, Chih-Chung Hsu|<http://arxiv.org/pdf/2501.04665v1>|None|
|ğŸ†• å‘å¸ƒ|Learnable Scaled Gradient Descent for Guaranteed Robust Tensor PCA|å¯å­¦ä¹ ç¼©æ”¾æ¢¯åº¦ä¸‹é™ç¡®ä¿é²æ£’çš„å¼ é‡PCA|Lanlan Feng, Ce Zhu, Yipeng Liu, Saiprasad Ravishankar, Longxiu Huang|<http://arxiv.org/pdf/2501.04565v1>|None|
|ğŸ†• å‘å¸ƒ|Towards Fair Class-wise Robustness: Class Optimal Distribution Adversarial Training|æœå‘å…¬å¹³çš„ç±»åˆ«é²æ£’æ€§ï¼šç±»åˆ«æœ€ä¼˜åˆ†å¸ƒå¯¹æŠ—è®­ç»ƒ|Hongxin Zhi, Hongtao Yu, Shaome Li, Xiuming Zhao, Yiteng Wu|<http://arxiv.org/pdf/2501.04527v1>|None|
|ğŸ†• å‘å¸ƒ|A novel Facial Recognition technique with Focusing on Masked Faces|ä¸€ç§é’ˆå¯¹é®æŒ¡äººè„¸çš„æ–°å‹é¢éƒ¨è¯†åˆ«æŠ€æœ¯|Dana A Abdullah, Dana Rasul Hamad, Hakem Beitollahi, Ismail Y Maolood, Abdulhady Abas Abdullah, Aso Khaleel Ameen|<http://arxiv.org/pdf/2501.04444v1>|None|
|ğŸ†• å‘å¸ƒ|Online Gaussian Test-Time Adaptation of Vision-Language Models|åœ¨çº¿é«˜æ–¯è§†è§‰-è¯­è¨€æ¨¡å‹æµ‹è¯•æ—¶è‡ªé€‚åº”|ClÃ©ment Fuchs, Maxime Zanella, Christophe De Vleeschouwer|<http://arxiv.org/pdf/2501.04352v1>|<https://github.com/cfuchs2023/OGA>|
|ğŸ“ æ›´æ–°|Embedding Similarity Guided License Plate Super Resolution|åŸºäºåµŒå…¥ç›¸ä¼¼åº¦å¼•å¯¼çš„ç‰Œç…§è¶…åˆ†è¾¨ç‡|Abderrezzaq Sendjasni, Mohamed-Chaker Larabi|<http://arxiv.org/pdf/2501.01483v2>|None|
|ğŸ“ æ›´æ–°|Detailed Object Description with Controllable Dimensions|å…·æœ‰å¯æ§ç»´åº¦çš„è¯¦ç»†ç‰©ä½“æè¿°|Xinran Wang, Haiwen Zhang, Baoteng Li, Kongming Liang, Hao Sun, Zhongjiang He, Zhanyu Ma, Jun Guo|<http://arxiv.org/pdf/2411.19106v2>|<https://github.com/xin-ran-w/ControllableObjectDescription.>|
|ğŸ“ æ›´æ–°|ViG-Bias: Visually Grounded Bias Discovery and Mitigation|ViG-Biasï¼šåŸºäºè§†è§‰çš„åè§å‘ç°ä¸ç¼“è§£|Badr-Eddine Marani, Mohamed Hanini, Nihitha Malayarukil, Stergios Christodoulidis, Maria Vakalopoulou, Enzo Ferrante|<http://arxiv.org/pdf/2407.01996v4>|None|
|ğŸ“ æ›´æ–°|LeGrad: An Explainability Method for Vision Transformers via Feature Formation Sensitivity|LeGradï¼šé€šè¿‡ç‰¹å¾å½¢æˆæ•æ„Ÿæ€§å®ç°è§†è§‰Transformerçš„å¯è§£é‡Šæ€§æ–¹æ³•|Walid Bousselham, Angie Boggust, Sofian Chaybouti, Hendrik Strobelt, Hilde Kuehne|<http://arxiv.org/pdf/2404.03214v2>|<https://github.com/WalBouss/LeGrad.>|
|ğŸ“ æ›´æ–°|TSCM: A Teacher-Student Model for Vision Place Recognition Using Cross-Metric Knowledge Distillation|TSCMï¼šä¸€ç§åŸºäºè·¨åº¦é‡çŸ¥è¯†è’¸é¦çš„è§†è§‰ä½ç½®è¯†åˆ«æ•™å¸ˆ-å­¦ç”Ÿæ¨¡å‹|Yehui Shen, Mingmin Liu, Huimin Lu, Xieyuanli Chen|<http://arxiv.org/pdf/2404.01587v2>|<https://github.com/nubot-nudt/TSCM.>|
|ğŸ“ æ›´æ–°|Cobra: Extending Mamba to Multi-Modal Large Language Model for Efficient Inference|Cobraï¼šæ‰©å±•Mambaè‡³å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä»¥å®ç°é«˜æ•ˆæ¨ç†|Han Zhao, Min Zhang, Wei Zhao, Pengxiang Ding, Siteng Huang, Donglin Wang|<http://arxiv.org/pdf/2403.14520v4>|None|
|ğŸ“ æ›´æ–°|Deep Unfolding Network with Spatial Alignment for multi-modal MRI reconstruction|æ·±åº¦å±•å¼€ç½‘ç»œç»“åˆç©ºé—´å¯¹é½çš„å¤šæ¨¡æ€MRIé‡å»º|Hao Zhang, Qi Wang, Jun Shi, Shihui Ying, Zhijie Wen|<http://arxiv.org/pdf/2312.16998v2>|None|
|ğŸ“ æ›´æ–°|Explainable Severity ranking via pairwise n-hidden comparison: a case study of glaucoma|é€šè¿‡æˆå¯¹néšè—æ¯”è¾ƒçš„å¯è§£é‡Šä¸¥é‡ç¨‹åº¦æ’åï¼šé’å…‰çœ¼çš„æ¡ˆä¾‹ç ”ç©¶|Hong Nguyen, Cuong V. Nguyen, Shrikanth Narayanan, Benjamin Y. Xu, Michael Pazzani|<http://arxiv.org/pdf/2312.02541v2>|None|
|ğŸ“ æ›´æ–°|FreeZe: Training-free zero-shot 6D pose estimation with geometric and vision foundation models|FreeZeï¼šåŸºäºå‡ ä½•å’Œè§†è§‰åŸºç¡€æ¨¡å‹çš„å…è®­ç»ƒé›¶æ ·æœ¬6Då§¿æ€ä¼°è®¡|Andrea Caraffa, Davide Boscaini, Amir Hamza, Fabio Poiesi|<http://arxiv.org/pdf/2312.00947v3>|<https://andreacaraffa.github.io/freeze.>|
|ğŸ“ æ›´æ–°|AutoFuse: Automatic Fusion Networks for Deformable Medical Image Registration|è‡ªåŠ¨èåˆï¼šç”¨äºå¯å˜å½¢åŒ»å­¦å›¾åƒé…å‡†çš„è‡ªåŠ¨èåˆç½‘ç»œ|Mingyuan Meng, Michael Fulham, Dagan Feng, Lei Bi, Jinman Kim|<http://arxiv.org/pdf/2309.05271v2>|None|


## äººè„¸æŠ€æœ¯

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|EditAR: Unified Conditional Generation with Autoregressive Models|ç¼–è¾‘å¢å¼ºç°å®ï¼šåŸºäºè‡ªå›å½’æ¨¡å‹çš„ç»Ÿä¸€æ¡ä»¶ç”Ÿæˆ|Jiteng Mu, Nuno Vasconcelos, Xiaolong Wang|<http://arxiv.org/pdf/2501.04699v1>|<https://jitengmu.github.io/EditAR>|
|ğŸ†• å‘å¸ƒ|Re-ranking the Context for Multimodal Retrieval Augmented Generation|å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆä¸­çš„ä¸Šä¸‹æ–‡é‡æ–°æ’åº|Matin Mortaheb, Mohammad A. Amir Khojastepour, Srimat T. Chakradhar, Sennur Ulukus|<http://arxiv.org/pdf/2501.04695v1>|None|
|ğŸ†• å‘å¸ƒ|SPAR3D: Stable Point-Aware Reconstruction of 3D Objects from Single Images|SPAR3Dï¼šåŸºäºå•å¼ å›¾åƒçš„ç¨³å®šç‚¹æ„ŸçŸ¥ä¸‰ç»´ç‰©ä½“é‡å»º|Zixuan Huang, Mark Boss, Aaryaman Vasishta, James M. Rehg, Varun Jampani|<http://arxiv.org/pdf/2501.04689v1>|None|
|ğŸ†• å‘å¸ƒ|Disentangled Clothed Avatar Generation with Layered Representation|è§£è€¦åˆ†å±‚è¡¨ç¤ºçš„ç€è£…è™šæ‹Ÿäººç”Ÿæˆ|Weitian Zhang, Sijing Wu, Manwen Liao, Yichao Yan|<http://arxiv.org/pdf/2501.04631v1>|<https://olivia23333.github.io/LayerAvatar>|
|ğŸ†• å‘å¸ƒ|On Computational Limits and Provably Efficient Criteria of Visual Autoregressive Models: A Fine-Grained Complexity Analysis|å…³äºè§†è§‰è‡ªå›å½’æ¨¡å‹çš„è®¡ç®—æé™å’Œå¯è¯æ˜æœ‰æ•ˆæ ‡å‡†ï¼šç»†ç²’åº¦å¤æ‚åº¦åˆ†æ|Yekun Ke, Xiaoyu Li, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song|<http://arxiv.org/pdf/2501.04377v1>|None|
|ğŸ†• å‘å¸ƒ|Instructive3D: Editing Large Reconstruction Models with Text Instructions|Instructive3Dï¼šä½¿ç”¨æ–‡æœ¬æŒ‡ä»¤ç¼–è¾‘å¤§å‹é‡å»ºæ¨¡å‹|Kunal Kathare, Ankit Dhiman, K Vikas Gowda, Siddharth Aravindan, Shubham Monga, Basavaraja Shanthappa Vandrotti, Lokesh R Boregowda|<http://arxiv.org/pdf/2501.04374v1>|None|
|ğŸ“ æ›´æ–°|MADation: Face Morphing Attack Detection with Foundation Models|MADationï¼šåŸºäºåŸºç¡€æ¨¡å‹çš„è¡¨æƒ…åˆæˆæ”»å‡»æ£€æµ‹|Eduarda Caldeira, Guray Ozgur, Tahar Chettaoui, Marija Ivanovska, Peter Peer, Fadi Boutros, Vitomir Struc, Naser Damer|<http://arxiv.org/pdf/2501.03800v2>|<https://github.com/gurayozgur/MADation>|
|ğŸ“ æ›´æ–°|Evaluating Image Caption via Cycle-consistent Text-to-Image Generation|é€šè¿‡å¾ªç¯ä¸€è‡´æ€§æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆè¯„ä¼°å›¾åƒæè¿°|Tianyu Cui, Jinbin Bai, Guo-Hua Wang, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang, Ye Shi|<http://arxiv.org/pdf/2501.03567v2>|None|
|ğŸ“ æ›´æ–°|Click2Mask: Local Editing with Dynamic Mask Generation|ç‚¹å‡»ç”Ÿæˆæ©ç ï¼šåŠ¨æ€æ©ç ç”Ÿæˆä¸‹çš„å±€éƒ¨ç¼–è¾‘|Omer Regev, Omri Avrahami, Dani Lischinski|<http://arxiv.org/pdf/2409.08272v2>|None|


## å…·èº«æ™ºèƒ½

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Grokking at the Edge of Numerical Stability|æ¢ç´¢æ•°å€¼ç¨³å®šæ€§çš„è¾¹ç¼˜|Lucas Prieto, Melih Barsbey, Pedro A. M. Mediano, Tolga Birdal|<http://arxiv.org/pdf/2501.04697v1>|<https://github.com/LucasPrietoAl/grokking-at-the-edge-of-numerical-stability.>|
|ğŸ†• å‘å¸ƒ|FrontierNet: Learning Visual Cues to Explore|FrontierNetï¼šå­¦ä¹ è§†è§‰çº¿ç´¢ä»¥æ¢ç´¢|Boyang Sun, Hanzhi Chen, Stefan Leutenegger, Cesar Cadena, Marc Pollefeys, Hermann Blum|<http://arxiv.org/pdf/2501.04597v1>|None|
|ğŸ†• å‘å¸ƒ|SplineFormer: An Explainable Transformer-Based Approach for Autonomous Endovascular Navigation|SplineFormerï¼šä¸€ç§åŸºäºå¯è§£é‡ŠTransformerçš„è‡ªä¸»è¡€ç®¡å†…å¯¼èˆªæ–¹æ³•|Tudor Jianu, Shayan Doust, Mengyun Li, Baoru Huang, Tuong Do, Hoan Nguyen, Karl Bates, Tung D. Ta .etc.|<http://arxiv.org/pdf/2501.04515v1>|None|
|ğŸ†• å‘å¸ƒ|The Role of Machine Learning in Congenital Heart Disease Diagnosis: Datasets, Algorithms, and Insights|æœºå™¨å­¦ä¹ åœ¨å…ˆå¤©æ€§å¿ƒè„ç—…è¯Šæ–­ä¸­çš„ä½œç”¨ï¼šæ•°æ®é›†ã€ç®—æ³•å’Œè§è§£|Khalil Khan, Farhan Ullah, Ikram Syed, Irfan Ullah|<http://arxiv.org/pdf/2501.04493v1>|None|
|ğŸ†• å‘å¸ƒ|Rethinking High-speed Image Reconstruction Framework with Spike Camera|é‡æ–°æ€è€ƒåŸºäºè„‰å†²ç›¸æœºçš„è¶…é«˜é€Ÿå›¾åƒé‡å»ºæ¡†æ¶|Kang Chen, Yajing Zheng, Tiejun Huang, Zhaofei Yu|<http://arxiv.org/pdf/2501.04477v1>|None|
|ğŸ†• å‘å¸ƒ|A Unified Framework for Foreground and Anonymization Area Segmentation in CT and MRI Data|ç»Ÿä¸€æ¡†æ¶åœ¨CTå’ŒMRIæ•°æ®ä¸­çš„å‰æ™¯å’ŒåŒ¿ååŒºåŸŸåˆ†å‰²|Michal Nohel, Constantin Ulrich, Jonathan Suprijadi, Tassilo Wald, Klaus Maier-Hein|<http://arxiv.org/pdf/2501.04361v1>|<https://github.com/MIC-DKFZ/Foreground-and-Anonymization-Area-Segmentation.>|
|ğŸ†• å‘å¸ƒ|TADFormer : Task-Adaptive Dynamic Transformer for Efficient Multi-Task Learning|TADFormerï¼šé«˜æ•ˆå¤šä»»åŠ¡å­¦ä¹ çš„ä»»åŠ¡è‡ªé€‚åº”åŠ¨æ€Transformer|Seungmin Baek, Soyul Lee, Hayeon Jo, Hyesong Choi, Dongbo Min|<http://arxiv.org/pdf/2501.04293v1>|None|
|ğŸ†• å‘å¸ƒ|Open set label noise learning with robust sample selection and margin-guided module|å¼€æ”¾é›†æ ‡ç­¾å™ªå£°å­¦ä¹ ï¼šé²æ£’æ ·æœ¬é€‰æ‹©ä¸è¾¹ç¼˜å¼•å¯¼æ¨¡å—|Yuandi Zhao, Qianxi Xia, Yang Sun, Zhijie Wen, Liyan Ma, Shihui Ying|<http://arxiv.org/pdf/2501.04269v1>|None|
|ğŸ†• å‘å¸ƒ|Robotic Programmer: Video Instructed Policy Code Generation for Robotic Manipulation|æœºå™¨äººç¨‹åºå‘˜ï¼šæœºå™¨äººæ“ä½œçš„è§†é¢‘æŒ‡ä»¤ç­–ç•¥ä»£ç ç”Ÿæˆ|Senwei Xie, Hongyu Wang, Zhanqi Xiao, Ruiping Wang, Xilin Chen|<http://arxiv.org/pdf/2501.04268v1>|None|
|ğŸ†• å‘å¸ƒ|Continual Self-supervised Learning Considering Medical Domain Knowledge in Chest CT Images|æŒç»­è‡ªç›‘ç£å­¦ä¹ ï¼šè€ƒè™‘åŒ»å­¦é¢†åŸŸçŸ¥è¯†åœ¨èƒ¸éƒ¨CTå›¾åƒä¸­çš„åº”ç”¨|Ren Tasai, Guang Li, Ren Togo, Minghui Tang, Takaaki Yoshimura, Hiroyuki Sugimori, Kenji Hirata, Takahiro Ogawa .etc.|<http://arxiv.org/pdf/2501.04217v1>|None|
|ğŸ†• å‘å¸ƒ|GRAPHITE: Graph-Based Interpretable Tissue Examination for Enhanced Explainability in Breast Cancer Histopathology|çŸ³å¢¨çƒ¯ï¼šåŸºäºå›¾çš„å¯è§£é‡Šç»„ç»‡æ£€æŸ¥ï¼Œç”¨äºå¢å¼ºä¹³è…ºç™Œç»„ç»‡ç—…ç†å­¦çš„å¯è§£é‡Šæ€§|Raktim Kumar Mondol, Ewan K. A. Millar, Peter H. Graham, Lois Browne, Arcot Sowmya, Erik Meijering|<http://arxiv.org/pdf/2501.04206v1>|None|
|ğŸ“ æ›´æ–°|Graph Cut-guided Maximal Coding Rate Reduction for Learning Image Embedding and Clustering|å›¾å‰²å¼•å¯¼çš„æœ€å¤§ç¼–ç ç‡é™ä½ä»¥å­¦ä¹ å›¾åƒåµŒå…¥å’Œèšç±»|W. He, Z. Huang, X. Meng, X. Qi, R. Xiao, C. -G. Li|<http://arxiv.org/pdf/2412.18930v2>|None|
|ğŸ“ æ›´æ–°|FILP-3D: Enhancing 3D Few-shot Class-incremental Learning with Pre-trained Vision-Language Models|FILP-3Dï¼šåˆ©ç”¨é¢„è®­ç»ƒè§†è§‰-è¯­è¨€æ¨¡å‹å¢å¼º3Då°æ ·æœ¬ç±»å¢é‡å­¦ä¹ |Wan Xu, Tianyu Huang, Tianyu Qu, Guanglei Yang, Yiwen Guo, Wangmeng Zuo|<http://arxiv.org/pdf/2312.17051v2>|None|
|ğŸ“ æ›´æ–°|TinySAM: Pushing the Envelope for Efficient Segment Anything Model|TinySAMï¼šæ¨åŠ¨é«˜æ•ˆSegment Anythingæ¨¡å‹çš„æ–°è¾¹ç•Œ|Han Shu, Wenshuo Li, Yehui Tang, Yiman Zhang, Yihao Chen, Houqiang Li, Yunhe Wang, Xinghao Chen|<http://arxiv.org/pdf/2312.13789v3>|<https://github.com/xinghaochen/TinySAM>|
|ğŸ“ æ›´æ–°|How to Bridge the Gap between Modalities: Survey on Multimodal Large Language Model|å¦‚ä½•å¼¥åˆæ¨¡æ€å·®è·ï¼šå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ç»¼è¿°|Shezheng Song, Xiaopeng Li, Shasha Li, Shan Zhao, Jie Yu, Jun Ma, Xiaoguang Mao, Weimin Zhang|<http://arxiv.org/pdf/2311.07594v3>|None|


## å›¾åƒå¤„ç†

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MB-TaylorFormer V2: Improved Multi-branch Linear Transformer Expanded by Taylor Formula for Image Restoration|MB-TaylorFormer V2ï¼šåŸºäºæ³°å‹’å…¬å¼çš„æ”¹è¿›å¤šåˆ†æ”¯çº¿æ€§Transformerå›¾åƒä¿®å¤|Zhi Jin, Yuwei Qiu, Kaihao Zhang, Hongdong Li, Wenhan Luo|<http://arxiv.org/pdf/2501.04486v1>|<https://github.com/FVL2020/MB-TaylorFormerV2.>|
|ğŸ†• å‘å¸ƒ|Edit as You See: Image-guided Video Editing via Masked Motion Modeling|æ ¹æ®æ‰€è§è¿›è¡Œç¼–è¾‘ï¼šé€šè¿‡æ©ç è¿åŠ¨å»ºæ¨¡çš„å›¾åƒå¼•å¯¼è§†é¢‘ç¼–è¾‘|Zhi-Lin Huang, Yixuan Liu, Chujun Qin, Zhongdao Wang, Dong Zhou, Dong Li, Emad Barsoum|<http://arxiv.org/pdf/2501.04325v1>|None|
|ğŸ†• å‘å¸ƒ|Recognition-Oriented Low-Light Image Enhancement based on Global and Pixelwise Optimization|é¢å‘è¯†åˆ«çš„ä½å…‰å›¾åƒå¢å¼ºï¼šåŸºäºå…¨å±€å’Œåƒç´ çº§ä¼˜åŒ–|Seitaro Ono, Yuka Ogino, Takahiro Toizumi, Atsushi Ito, Masato Tsukada|<http://arxiv.org/pdf/2501.04210v1>|None|
|ğŸ“ æ›´æ–°|DEFormer: DCT-driven Enhancement Transformer for Low-light Image and Dark Vision|DEFormerï¼šåŸºäºDCTé©±åŠ¨çš„ä½å…‰å›¾åƒå’Œæš—è§†è§‰å¢å¼ºTransformer|Xiangchen Yin, Zhenda Yu, Xin Gao, Xiao Sun|<http://arxiv.org/pdf/2309.06941v3>|None|


## å›¾åƒç†è§£

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Planarian Neural Networks: Evolutionary Patterns from Basic Bilateria Shaping Modern Artificial Neural Network Architectures|æ‰å½¢åŠ¨ç‰©ç¥ç»ç½‘ç»œï¼šä»åŸºç¡€ä¸¤ä¾§å¯¹ç§°åŠ¨ç‰©è¿›åŒ–è€Œæ¥çš„ç°ä»£äººå·¥ç¥ç»ç½‘ç»œæ¶æ„|Ziyuan Huang, Mark Newman, Maria Vaida, Srikar Bellur, Roozbeh Sadeghian, Andrew Siu, Hui Wang, Kevin Huggins|<http://arxiv.org/pdf/2501.04700v1>|None|
|ğŸ†• å‘å¸ƒ|FlairGPT: Repurposing LLMs for Interior Designs|FlairGPTï¼šå°†å¤§å‹è¯­è¨€æ¨¡å‹é‡æ–°ç”¨äºå®¤å†…è®¾è®¡|Gabrielle Littlefair, Niladri Shekhar Dutt, Niloy J. Mitra|<http://arxiv.org/pdf/2501.04648v1>|None|
|ğŸ†• å‘å¸ƒ|Discrete Wavelet Transform-Based Capsule Network for Hyperspectral Image Classification|åŸºäºç¦»æ•£å°æ³¢å˜æ¢çš„èƒ¶å›Šç½‘ç»œç”¨äºé«˜å…‰è°±å›¾åƒåˆ†ç±»|Zhiqiang Gao, Jiaqi Wang, Hangchi Shen, Zhihao Dou, Xiangbo Zhang, Kaizhu Huang|<http://arxiv.org/pdf/2501.04643v1>|None|
|ğŸ†• å‘å¸ƒ|A Histologic Dataset of Normal and Atypical Mitotic Figures on Human Breast Cancer (AMi-Br)|äººç±»ä¹³è…ºç™Œæ­£å¸¸å’Œå¼‚å¸¸æœ‰ä¸åˆ†è£‚å›¾åƒçš„ç—…ç†æ•°æ®é›†ï¼ˆAMi-Brï¼‰|Christof A. Bertram, Viktoria Weiss, Taryn A. Donovan, Sweta Banerjee, Thomas Conrad, Jonas Ammeling, Robert Klopfleisch, Christopher Kaltenecker .etc.|<http://arxiv.org/pdf/2501.04467v1>|None|
|ğŸ†• å‘å¸ƒ|Enhancing Scene Classification in Cloudy Image Scenarios: A Collaborative Transfer Method with Information Regulation Mechanism using Optical Cloud-Covered and SAR Remote Sensing Images|å¢å¼ºå¤šäº‘åœºæ™¯åˆ†ç±»ï¼šåŸºäºå…‰å­¦äº‘è¦†ç›–å’Œåˆæˆå­”å¾„é›·è¾¾é¥æ„Ÿå›¾åƒçš„ä¿¡æ¯è°ƒèŠ‚æœºåˆ¶ååŒè¿ç§»æ–¹æ³•|Yuze Wang, Rong Xiao, Haifeng Li, Mariana Belgiu, Chao Tao|<http://arxiv.org/pdf/2501.04283v1>|<https://github.com/wangyuze-csu/ESCCS>|
|ğŸ†• å‘å¸ƒ|LipGen: Viseme-Guided Lip Video Generation for Enhancing Visual Speech Recognition|å”‡åŠ¨ç”Ÿæˆï¼šåŸºäºè§†è§‰è¯­éŸ³è¯†åˆ«å¢å¼ºçš„è§†è§‰è¯­éŸ³è§†é¢‘ç”Ÿæˆ|Bowen Hao, Dongliang Zhou, Xiaojie Li, Xingyu Zhang, Liang Xie, Jianlong Wu, Erwei Yin|<http://arxiv.org/pdf/2501.04204v1>|None|
|ğŸ“ æ›´æ–°|Forget Vectors at Play: Universal Input Perturbations Driving Machine Unlearning in Image Classification|å¿˜è®°å‘é‡åœ¨ç©è€ï¼šé€šç”¨è¾“å…¥æ‰°åŠ¨é©±åŠ¨å›¾åƒåˆ†ç±»ä¸­çš„æœºå™¨åå­¦ä¹ |Changchang Sun, Ren Wang, Yihua Zhang, Jinghan Jia, Jiancheng Liu, Gaowen Liu, Sijia Liu, Yan Yan|<http://arxiv.org/pdf/2412.16780v2>|<https://github.com/Changchangsun/Forget-Vector.>|
|ğŸ“ æ›´æ–°|SAG-ViT: A Scale-Aware, High-Fidelity Patching Approach with Graph Attention for Vision Transformers|SAG-ViTï¼šä¸€ç§å…·æœ‰å›¾æ³¨æ„åŠ›æœºåˆ¶çš„å°ºåº¦æ„ŸçŸ¥ã€é«˜ä¿çœŸè¡¥ä¸æ–¹æ³•ç”¨äºè§†è§‰Transformer|Shravan Venkatraman, Jaskaran Singh Walia, Joe Dhanith P R|<http://arxiv.org/pdf/2411.09420v3>|<https://github.com/shravan-18/SAG-ViT.>|
|ğŸ“ æ›´æ–°|Towards Revisiting Visual Place Recognition for Joining Submaps in Multimap SLAM|è¿ˆå‘å¤šå›¾SLAMä¸­å­å›¾èåˆçš„è§†è§‰ä½ç½®è¯†åˆ«å†å®¡è§†|Markus WeiÃŸflog, Stefan Schubert, Peter Protzel, Peer Neubert|<http://arxiv.org/pdf/2407.12408v2>|None|
|ğŸ“ æ›´æ–°|Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics|Rad4XCNNï¼šä¸€ç§åŸºäºæ”¾å°„ç»„å­¦çš„CNNè¡ç”Ÿç‰¹å¾åå¤„ç†å…¨å±€è§£é‡Šçš„æ–°æ— ç›‘ç£æ–¹æ³•|Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile|<http://arxiv.org/pdf/2405.02334v2>|None|
|ğŸ“ æ›´æ–°|Improving Low-Light Image Recognition Performance Based on Image-adaptive Learnable Module|åŸºäºå›¾åƒè‡ªé€‚åº”å¯å­¦ä¹ æ¨¡å—çš„å¼±å…‰å›¾åƒè¯†åˆ«æ€§èƒ½æå‡|Seitaro Ono, Yuka Ogino, Takahiro Toizumi, Atsushi Ito, Masato Tsukada|<http://arxiv.org/pdf/2401.06438v2>|None|


## å¤šæ¨¡æ€

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Supervision-free Vision-Language Alignment|æ— ç›‘ç£è§†è§‰-è¯­è¨€å¯¹é½|Giorgio Giannone, Ruoteng Li, Qianli Feng, Evgeny Perevodchikov, Rui Chen, Aleix Martinez|<http://arxiv.org/pdf/2501.04568v1>|None|
|ğŸ†• å‘å¸ƒ|OpenOmni: Large Language Models Pivot Zero-shot Omnimodal Alignment across Language with Real-time Self-Aware Emotional Speech Synthesis|OpenOmniï¼šå¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨é›¶æ ·æœ¬è·¨è¯­è¨€å…¨æ¨¡æ€å¯¹é½åŠå®æ—¶è‡ªæ„ŸçŸ¥æƒ…æ„Ÿè¯­éŸ³åˆæˆ|Run Luo, Ting-En Lin, Haonan Zhang, Yuchuan Wu, Xiong Liu, Min Yang, Yongbin Li, Longze Chen .etc.|<http://arxiv.org/pdf/2501.04561v1>|None|
|ğŸ†• å‘å¸ƒ|Improving Image Captioning by Mimicking Human Reformulation Feedback at Inference-time|é€šè¿‡æ¨¡ä»¿æ¨ç†æ—¶çš„äººç±»é‡æ„åé¦ˆæ¥æ”¹è¿›å›¾åƒæè¿°|Uri Berger, Omri Abend, Lea Frermann, Gabriel Stanovsky|<http://arxiv.org/pdf/2501.04513v1>|None|


## æ‰©æ•£æ¡¥

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|DRIVINGVQA: Analyzing Visual Chain-of-Thought Reasoning of Vision Language Models in Real-World Scenarios with Driving Theory Tests|é©¾é©¶è§†è§‰é—®ç­”ï¼šé€šè¿‡é©¾é©¶ç†è®ºæµ‹è¯•åœ¨ç°å®åœºæ™¯ä¸­åˆ†æè§†è§‰è¯­è¨€æ¨¡å‹çš„è§†è§‰æ€ç»´æ¨ç†|Charles CorbiÃ¨re, Simon Roburin, Syrielle Montariol, Antoine Bosselut, Alexandre Alahi|<http://arxiv.org/pdf/2501.04671v1>|None|
|ğŸ†• å‘å¸ƒ|ContextMRI: Enhancing Compressed Sensing MRI through Metadata Conditioning|åŸºäºå…ƒæ•°æ®æ¡ä»¶çš„å‹ç¼©æ„ŸçŸ¥MRIå¢å¼ºï¼šContextMRI|Hyungjin Chung, Dohun Lee, Zihui Wu, Byung-Hoon Kim, Katherine L. Bouman, Jong Chul Ye|<http://arxiv.org/pdf/2501.04284v1>|None|
|ğŸ“ æ›´æ–°|Label-Efficient Data Augmentation with Video Diffusion Models for Guidewire Segmentation in Cardiac Fluoroscopy|åŸºäºè§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ ‡ç­¾é«˜æ•ˆæ•°æ®å¢å¼ºåœ¨å¿ƒè„è§å…‰é€è§†å¯¼ä¸åˆ†å‰²ä¸­çš„åº”ç”¨|Shaoyan Pan, Yikang Liu, Lin Zhao, Eric Z. Chen, Xiao Chen, Terrence Chen, Shanhui Sun|<http://arxiv.org/pdf/2412.16050v3>|None|
|ğŸ“ æ›´æ–°|PointDreamer: Zero-shot 3D Textured Mesh Reconstruction from Colored Point Cloud|ç‚¹æ¢¦è€…ï¼šä»å½©è‰²ç‚¹äº‘è¿›è¡Œé›¶æ ·æœ¬3Dçº¹ç†ç½‘æ ¼é‡å»º|Qiao Yu, Xianzhi Li, Yuan Tang, Xu Han, Jinfeng Xu, Long Hu, Min Chen|<http://arxiv.org/pdf/2406.15811v2>|<https://github.com/YuQiao0303/PointDreamer.>|
|ğŸ“ æ›´æ–°|AnoFPDM: Anomaly Segmentation with Forward Process of Diffusion Models for Brain MRI|è„‘MRIå¼‚å¸¸åˆ†å‰²çš„æ‰©æ•£æ¨¡å‹å‰å‘è¿‡ç¨‹æ–¹æ³•|Yiming Che, Fazle Rafsani, Jay Shah, Md Mahfuzur Rahman Siddiquee, Teresa Wu|<http://arxiv.org/pdf/2404.15683v4>|None|
|ğŸ“ æ›´æ–°|NeuralDiffuser: Neuroscience-inspired Diffusion Guidance for fMRI Visual Reconstruction|ç¥ç»æ‰©æ•£å™¨ï¼šç¥ç»ç§‘å­¦å¯å‘ä¸‹çš„fMRIè§†è§‰é‡å»ºæ‰©æ•£å¼•å¯¼|Haoyu Li, Hao Wu, Badong Chen|<http://arxiv.org/pdf/2402.13809v3>|None|


## æ•°å­—äºº

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Enhancing Virtual Try-On with Synthetic Pairs and Error-Aware Noise Scheduling|å¢å¼ºè™šæ‹Ÿè¯•ç©¿ï¼šåˆæˆé…å¯¹ä¸é”™è¯¯æ„ŸçŸ¥å™ªå£°è°ƒåº¦|Nannan Li, Kevin J. Shih, Bryan A. Plummer|<http://arxiv.org/pdf/2501.04666v1>|None|


## æ£€æµ‹åˆ†å‰²

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|RadGPT: Constructing 3D Image-Text Tumor Datasets|RadGPTï¼šæ„å»º3Då›¾åƒ-æ–‡æœ¬è‚¿ç˜¤æ•°æ®é›†|Pedro R. A. S. Bassi, Mehmet Can Yavuz, Kang Wang, Xiaoxi Chen, Wenxuan Li, Sergio Decherchi, Andrea Cavalli, Yang Yang .etc.|<http://arxiv.org/pdf/2501.04678v1>|None|
|ğŸ†• å‘å¸ƒ|Boosting Salient Object Detection with Knowledge Distillated from Large Foundation Models|åŸºäºå¤§å‹åŸºç¡€æ¨¡å‹çŸ¥è¯†è’¸é¦çš„æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹æå‡|Miaoyang He, Shuyong Gao, Tsui Qin Mok, Weifeng Ge, Wengqiang Zhang|<http://arxiv.org/pdf/2501.04582v1>|None|
|ğŸ†• å‘å¸ƒ|Unified Coding for Both Human Perception and Generalized Machine Analytics with CLIP Supervision|ç»Ÿä¸€ç¼–ç ä»¥å®ç°äººç±»æ„ŸçŸ¥å’Œå¹¿ä¹‰æœºå™¨åˆ†æçš„CLIPç›‘ç£|Kangsheng Yin, Quan Liu, Xuelin Shen, Yulin He, Wenhan Yang, Shiqi Wang|<http://arxiv.org/pdf/2501.04579v1>|None|
|ğŸ†• å‘å¸ƒ|Rapid Automated Mapping of Clouds on Titan With Instance Segmentation|å¿«é€Ÿè‡ªåŠ¨åœ¨æ³°å¦ä¸Šå¯¹äº‘è¿›è¡Œå®ä¾‹åˆ†å‰²æ˜ å°„|Zachary Yahn, Douglas M Trent, Ethan Duncan, BenoÃ®t Seignovert, John Santerre, Conor Nixon|<http://arxiv.org/pdf/2501.04459v1>|None|
|ğŸ†• å‘å¸ƒ|RSAR: Restricted State Angle Resolver and Rotated SAR Benchmark|RSARï¼šå—é™çŠ¶æ€è§’åº¦è§£ç®—å™¨å’Œæ—‹è½¬åˆæˆå­”å¾„é›·è¾¾åŸºå‡†|Xin Zhang, Xue Yang, Yuxuan Li, Jian Yang, Ming-Ming Cheng, Xiang Li|<http://arxiv.org/pdf/2501.04440v1>|<https://github.com/zhasion/RSAR.>|
|ğŸ†• å‘å¸ƒ|Exploring Unbiased Deepfake Detection via Token-Level Shuffling and Mixing|æ¢ç´¢é€šè¿‡ä»¤ç‰Œçº§æ´—ç‰Œå’Œæ··åˆçš„æ— åæ·±ä¼ªæ£€æµ‹|Xinghe Fu, Zhiyuan Yan, Taiping Yao, Shen Chen, Xi Li|<http://arxiv.org/pdf/2501.04376v1>|None|
|ğŸ†• å‘å¸ƒ|FGU3R: Fine-Grained Fusion via Unified 3D Representation for Multimodal 3D Object Detection|FGU3Rï¼šåŸºäºç»Ÿä¸€3Dè¡¨ç¤ºçš„å¤šæ¨¡æ€3Dç›®æ ‡æ£€æµ‹çš„ç»†ç²’åº¦èåˆ|Guoxin Zhang, Ziying Song, Lin Liu, Zhonghong Ou|<http://arxiv.org/pdf/2501.04373v1>|None|
|ğŸ†• å‘å¸ƒ|UPAQ: A Framework for Real-Time and Energy-Efficient 3D Object Detection in Autonomous Vehicles|UPAQï¼šè‡ªåŠ¨é©¾é©¶è½¦è¾†ä¸­å®æ—¶ä¸”èŠ‚èƒ½çš„3Dç›®æ ‡æ£€æµ‹æ¡†æ¶|Abhishek Balasubramaniam, Febin P Sunny, Sudeep Pasricha|<http://arxiv.org/pdf/2501.04213v1>|None|
|ğŸ“ æ›´æ–°|Strip R-CNN: Large Strip Convolution for Remote Sensing Object Detection|æ¡å¸¦R-CNNï¼šç”¨äºé¥æ„Ÿç›®æ ‡æ£€æµ‹çš„å¤§æ¡å¸¦å·ç§¯|Xinbin Yuan, ZhaoHui Zheng, Yuxuan Li, Xialei Liu, Li Liu, Xiang Li, Qibin Hou, Ming-Ming Cheng|<http://arxiv.org/pdf/2501.03775v2>|<https://github.com/YXB-NKU/Strip-R-CNN.>|
|ğŸ“ æ›´æ–°|GLoG-CSUnet: Enhancing Vision Transformers with Adaptable Radiomic Features for Medical Image Segmentation|GLoG-CSUnetï¼šé€šè¿‡è‡ªé€‚åº”æ”¾å°„ç»„å­¦ç‰¹å¾å¢å¼ºè§†è§‰Transformerè¿›è¡ŒåŒ»å­¦å›¾åƒåˆ†å‰²|Niloufar Eghbali, Hassan Bagher-Ebadian, Tuka Alhanai, Mohammad M. Ghassemi|<http://arxiv.org/pdf/2501.02788v2>|<https://github.com/HAAIL/GLoG-CSUnet.>|
|ğŸ“ æ›´æ–°|LogicAD: Explainable Anomaly Detection via VLM-based Text Feature Extraction|é€»è¾‘ADï¼šåŸºäºVLMçš„æ–‡æœ¬ç‰¹å¾æå–çš„å¯è§£é‡Šå¼‚å¸¸æ£€æµ‹|Er Jin, Qihui Feng, Yongli Mou, Stefan Decker, Gerhard Lakemeyer, Oliver Simons, Johannes Stegmaier|<http://arxiv.org/pdf/2501.01767v2>|None|
|ğŸ“ æ›´æ–°|Empowering LLMs to Understand and Generate Complex Vector Graphics|èµ‹èƒ½å¤§å‹è¯­è¨€æ¨¡å‹ç†è§£å’Œç”Ÿæˆå¤æ‚çŸ¢é‡å›¾å½¢|Ximing Xing, Juncheng Hu, Guotao Liang, Jing Zhang, Dong Xu, Qian Yu|<http://arxiv.org/pdf/2412.11102v2>|None|
|ğŸ“ æ›´æ–°|YOLOv5-Based Object Detection for Emergency Response in Aerial Imagery|åŸºäºYOLOv5çš„èˆªç©ºå½±åƒç´§æ€¥å“åº”ç›®æ ‡æ£€æµ‹|Sindhu Boddu, Arindam Mukherjee|<http://arxiv.org/pdf/2412.05394v2>|None|
|ğŸ“ æ›´æ–°|3D Part Segmentation via Geometric Aggregation of 2D Visual Features|åŸºäºäºŒç»´è§†è§‰ç‰¹å¾çš„å‡ ä½•èšåˆçš„3Déƒ¨ä»¶åˆ†å‰²|Marco Garosi, Riccardo Tedoldi, Davide Boscaini, Massimiliano Mancini, Nicu Sebe, Fabio Poiesi|<http://arxiv.org/pdf/2412.04247v2>|None|
|ğŸ“ æ›´æ–°|One missing piece in Vision and Language: A Survey on Comics Understanding|è§†è§‰ä¸è¯­è¨€ä¸­çš„ä¸€å—ç¼ºå¤±æ‹¼å›¾ï¼šæ¼«ç”»ç†è§£ç»¼è¿°|Emanuele Vivoli, Mohamed Ali Souibgui, Andrey Barsky, Artemis LLabrÃ©s, Marco Bertini, Dimosthenis Karatzas|<http://arxiv.org/pdf/2409.09502v2>|<https://github.com/emanuelevivoli/awesome-comics-understanding.>|
|ğŸ“ æ›´æ–°|ReCLIP++: Learn to Rectify the Bias of CLIP for Unsupervised Semantic Segmentation|ReCLIP++ï¼šå­¦ä¹ çº æ­£CLIPåœ¨æ— ç›‘ç£è¯­ä¹‰åˆ†å‰²ä¸­çš„åå·®|Jingyun Wang, Guoliang Kang|<http://arxiv.org/pdf/2408.06747v2>|<https://github.com/dogehhh/ReCLIP.>|
|ğŸ“ æ›´æ–°|Energy-based Hopfield Boosting for Out-of-Distribution Detection|åŸºäºèƒ½é‡çš„Hopfieldå¢å¼ºç”¨äºåˆ†å¸ƒå¤–æ£€æµ‹|Claus Hofmann, Simon Schmid, Bernhard Lehner, Daniel Klotz, Sepp Hochreiter|<http://arxiv.org/pdf/2405.08766v2>|None|
|ğŸ“ æ›´æ–°|MSCoTDet: Language-driven Multi-modal Fusion for Improved Multispectral Pedestrian Detection|MSCoTDetï¼šåŸºäºè¯­è¨€çš„è·¨æ¨¡æ€èåˆä»¥æå‡å¤šå…‰è°±è¡Œäººæ£€æµ‹|Taeheon Kim, Sangyun Chung, Damin Yeom, Youngjoon Yu, Hak Gu Kim, Yong Man Ro|<http://arxiv.org/pdf/2403.15209v3>|None|


## æ¨¡å‹ä¼˜åŒ–

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Test-Time Optimization for Domain Adaptive Open Vocabulary Segmentation|åŸŸè‡ªé€‚åº”å¼€æ”¾è¯æ±‡åˆ†å‰²çš„æµ‹è¯•æ—¶ä¼˜åŒ–|Ulindu De Silva, Didula Samaraweera, Sasini Wanigathunga, Kavindu Kariyawasam, Kanchana Ranasinghe, Muzammal Naseer, Ranga Rodrigo|<http://arxiv.org/pdf/2501.04696v1>|<https://github.com/UlinduP/SegTTO.>|
|ğŸ†• å‘å¸ƒ|Comprehensive Examination of Unrolled Networks for Linear Inverse Problems|å…¨é¢å®¡è§†å±•å¼€ç½‘ç»œåœ¨çº¿æ€§é€†é—®é¢˜ä¸­çš„åº”ç”¨|Eric Chen, Xi Chen, Arian Maleki, Shirin Jalali|<http://arxiv.org/pdf/2501.04608v1>|None|
|ğŸ†• å‘å¸ƒ|An Efficient Adaptive Compression Method for Human Perception and Machine Vision Tasks|é«˜æ•ˆçš„äººçœ¼æ„ŸçŸ¥ä¸æœºå™¨è§†è§‰ä»»åŠ¡è‡ªé€‚åº”å‹ç¼©æ–¹æ³•|Lei Liu, Zhenghao Chen, Zhihao Hu, Dong Xu|<http://arxiv.org/pdf/2501.04329v1>|None|
|ğŸ“ æ›´æ–°|Conjugate-Gradient-like Based Adaptive Moment Estimation Optimization Algorithm for Deep Learning|åŸºäºå…±è½­æ¢¯åº¦ç±»ä¼¼çš„è‡ªé€‚åº”åŠ¨é‡ä¼°è®¡ä¼˜åŒ–ç®—æ³•ç”¨äºæ·±åº¦å­¦ä¹ |Jiawu Tian, Liwei Xu, Xiaowei Zhang, Yongqi Li|<http://arxiv.org/pdf/2404.01714v4>|None|


## æµæ¨¡å‹

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|iFADIT: Invertible Face Anonymization via Disentangled Identity Transform|iFADITï¼šåŸºäºè§£è€¦èº«ä»½å˜æ¢çš„å¯é€†äººè„¸åŒ¿ååŒ–|Lin Yuan, Kai Liang, Xiong Li, Tao Wu, Nannan Wang, Xinbo Gao|<http://arxiv.org/pdf/2501.04390v1>|None|
|ğŸ†• å‘å¸ƒ|Eve: Efficient Multimodal Vision Language Models with Elastic Visual Experts|Eveï¼šé«˜æ•ˆçš„å¤šæ¨¡æ€è§†è§‰è¯­è¨€æ¨¡å‹ä¸å¼¹æ€§è§†è§‰ä¸“å®¶|Miao Rang, Zhenni Bi, Chuanjian Liu, Yehui Tang, Kai Han, Yunhe Wang|<http://arxiv.org/pdf/2501.04322v1>|None|


## ç”Ÿæˆæ¨¡å‹

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|DGQ: Distribution-Aware Group Quantization for Text-to-Image Diffusion Models|DGQï¼šé’ˆå¯¹æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„åˆ†å¸ƒæ„ŸçŸ¥ç»„é‡åŒ–|Hyogon Ryu, NaHyeon Park, Hyunjung Shim|<http://arxiv.org/pdf/2501.04304v1>|None|
|ğŸ“ æ›´æ–°|Adapting Image-to-Video Diffusion Models for Large-Motion Frame Interpolation|é€‚åº”å¤§è¿åŠ¨å¸§æ’å€¼çš„å›¾åƒåˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹|Luoxu Jin, Hiroshi Watanabe|<http://arxiv.org/pdf/2412.17042v2>|None|
|ğŸ“ æ›´æ–°|Stylebreeder: Exploring and Democratizing Artistic Styles through Text-to-Image Models|é£æ ¼åŸ¹è‚²ï¼šé€šè¿‡æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹æ¢ç´¢å’Œæ°‘ä¸»åŒ–è‰ºæœ¯é£æ ¼|Matthew Zheng, Enis Simsar, Hidir Yesiltepe, Federico Tombari, Joel Simon, Pinar Yanardag|<http://arxiv.org/pdf/2406.14599v2>|None|
|ğŸ“ æ›´æ–°|Tutorial on Diffusion Models for Imaging and Vision|å›¾åƒä¸è§†è§‰ä¸­çš„æ‰©æ•£æ¨¡å‹æ•™ç¨‹|Stanley H. Chan|<http://arxiv.org/pdf/2403.18103v3>|None|


## è§†é¢‘ç†è§£

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ConceptMaster: Multi-Concept Video Customization on Diffusion Transformer Models Without Test-Time Tuning|æ¦‚å¿µå¤§å¸ˆï¼šæ— éœ€æµ‹è¯•æ—¶è°ƒæ•´çš„æ‰©æ•£Transformeræ¨¡å‹ä¸Šçš„å¤šæ¦‚å¿µè§†é¢‘å®šåˆ¶|Yuzhou Huang, Ziyang Yuan, Quande Liu, Qiulin Wang, Xintao Wang, Ruimao Zhang, Pengfei Wan, Di Zhang .etc.|<http://arxiv.org/pdf/2501.04698v1>|None|
|ğŸ†• å‘å¸ƒ|Are They the Same? Exploring Visual Correspondence Shortcomings of Multimodal LLMs|å®ƒä»¬æ˜¯å¦ç›¸åŒï¼Ÿæ¢ç´¢å¤šæ¨¡æ€LLMsçš„è§†è§‰å¯¹åº”ä¸è¶³|Yikang Zhou, Tao Zhang, Shilin Xu, Shihao Chen, Qianyu Zhou, Yunhai Tong, Shunping Ji, Jiangning Zhang .etc.|<http://arxiv.org/pdf/2501.04670v1>|<https://github.com/zhouyiks/CoLVA.>|
|ğŸ†• å‘å¸ƒ|Enhancing Low-Cost Video Editing with Lightweight Adaptors and Temporal-Aware Inversion|æå‡ä½æˆæœ¬è§†é¢‘ç¼–è¾‘æ€§èƒ½ï¼šè½»é‡çº§é€‚é…å™¨å’Œæ—¶é—´æ„ŸçŸ¥é€†å˜æ¢|Yangfan He, Sida Li, Kun Li, Jianhui Wang, Binxu Li, Tianyu Shi, Jun Yin, Miao Zhang .etc.|<http://arxiv.org/pdf/2501.04606v1>|None|
|ğŸ†• å‘å¸ƒ|Identity-Preserving Video Dubbing Using Motion Warping|èº«ä»½ä¿æŒçš„è§†é¢‘é…éŸ³ä½¿ç”¨è¿åŠ¨æ‰­æ›²|Runzhen Liu, Qinjie Lin, Yunfei Liu, Lijian Lin, Ye Zhu, Yu Li, Chuhua Xian, Fa-Ting Hong|<http://arxiv.org/pdf/2501.04586v1>|None|
|ğŸ†• å‘å¸ƒ|Combining YOLO and Visual Rhythm for Vehicle Counting|ç»“åˆYOLOå’Œè§†è§‰èŠ‚å¥è¿›è¡Œè½¦è¾†è®¡æ•°|Victor Nascimento Ribeiro, Nina S. T. Hirata|<http://arxiv.org/pdf/2501.04534v1>|None|
|ğŸ†• å‘å¸ƒ|DeFusion: An Effective Decoupling Fusion Network for Multi-Modal Pregnancy Prediction|DeFusionï¼šä¸€ç§æœ‰æ•ˆçš„è§£è€¦èåˆç½‘ç»œç”¨äºå¤šæ¨¡æ€å­•æœŸé¢„æµ‹|Xueqiang Ouyang, Jia Wei, Wenjie Huo, Xiaocong Wang, Rui Li, Jianlong Zhou|<http://arxiv.org/pdf/2501.04353v1>|<https://github.com/Ou-Young-1999/DFNet.>|
|ğŸ†• å‘å¸ƒ|Building a Mind Palace: Structuring Environment-Grounded Semantic Graphs for Effective Long Video Analysis with LLMs|æ„å»ºå¿ƒçµå®«æ®¿ï¼šåˆ©ç”¨LLMsæœ‰æ•ˆè¿›è¡Œé•¿è§†é¢‘åˆ†æçš„ç¯å¢ƒåŸºç¡€è¯­ä¹‰å›¾ç»“æ„|Zeyi Huang, Yuyang Ji, Xiaofang Wang, Nikhil Mehta, Tong Xiao, Donghyun Lee, Sigmund Vanvalkenburgh, Shengxin Zha .etc.|<http://arxiv.org/pdf/2501.04336v1>|None|
|ğŸ†• å‘å¸ƒ|H-MBA: Hierarchical MamBa Adaptation for Multi-Modal Video Understanding in Autonomous Driving|H-MBAï¼šç”¨äºè‡ªåŠ¨é©¾é©¶å¤šæ¨¡æ€è§†é¢‘ç†è§£çš„å±‚æ¬¡MamBaè‡ªé€‚åº”|Siran Chen, Yuxiao Luo, Yue Ma, Yu Qiao, Yali Wang|<http://arxiv.org/pdf/2501.04302v1>|None|
|ğŸ“ æ›´æ–°|Efficient Video-Based ALPR System Using YOLO and Visual Rhythm|åŸºäºYOLOå’Œè§†è§‰èŠ‚å¥çš„é«˜æ•ˆè§†é¢‘è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ|Victor Nascimento Ribeiro, Nina S. T. Hirata|<http://arxiv.org/pdf/2501.02270v2>|None|
|ğŸ“ æ›´æ–°|Bridging Simplicity and Sophistication using GLinear: A Novel Architecture for Enhanced Time Series Prediction|åˆ©ç”¨GLinearå®ç°ç®€ç¹å…¼é¡¾ï¼šä¸€ç§æå‡æ—¶é—´åºåˆ—é¢„æµ‹çš„æ–°æ¶æ„|Syed Tahir Hussain Rizvi, Neel Kanwal, Muddasar Naeem, Alfredo Cuzzocrea, Antonio Coronato|<http://arxiv.org/pdf/2501.01087v3>|None|
|ğŸ“ æ›´æ–°|VideoRefer Suite: Advancing Spatial-Temporal Object Understanding with Video LLM|è§†é¢‘å‚è€ƒå¥—ä»¶ï¼šåˆ©ç”¨è§†é¢‘å¤§å‹è¯­è¨€æ¨¡å‹æ¨è¿›æ—¶ç©ºç‰©ä½“ç†è§£|Yuqian Yuan, Hang Zhang, Wentong Li, Zesen Cheng, Boqiang Zhang, Long Li, Xin Li, Deli Zhao .etc.|<http://arxiv.org/pdf/2501.00599v2>|None|
|ğŸ“ æ›´æ–°|Future Success Prediction in Open-Vocabulary Object Manipulation Tasks Based on End-Effector Trajectories|åŸºäºæœ«ç«¯æ‰§è¡Œå™¨è½¨è¿¹çš„å¼€æ”¾è¯æ±‡ç‰©ä½“æ“ä½œä»»åŠ¡æœªæ¥æˆåŠŸé¢„æµ‹|Motonari Kambara, Komei Sugiura|<http://arxiv.org/pdf/2412.19112v2>|None|
|ğŸ“ æ›´æ–°|Motion Dreamer: Realizing Physically Coherent Video Generation through Scene-Aware Motion Reasoning|è¿åŠ¨æ¢¦æƒ³å®¶ï¼šé€šè¿‡åœºæ™¯æ„ŸçŸ¥è¿åŠ¨æ¨ç†å®ç°ç‰©ç†ä¸€è‡´çš„è§†é¢‘ç”Ÿæˆ|Tianshuo Xu, Zhifei Chen, Leyi Wu, Hao Lu, Yuying Chen, Lihui Jiang, Bingbing Liu, Yingcong Chen|<http://arxiv.org/pdf/2412.00547v2>|<https://envision-research.github.io/MotionDreamer>|
|ğŸ“ æ›´æ–°|ISR-DPO: Aligning Large Multimodal Models for Videos by Iterative Self-Retrospective DPO|ISR-DPOï¼šé€šè¿‡è¿­ä»£è‡ªåæ€DPOå¯¹è§†é¢‘è¿›è¡Œå¤§æ¨¡æ€æ¨¡å‹å¯¹é½|Daechul Ahn, Yura Choi, San Kim, Youngjae Yu, Dongyeop Kang, Jonghyun Choi|<http://arxiv.org/pdf/2406.11280v2>|None|
|ğŸ“ æ›´æ–°|Motion-Zero: Zero-Shot Moving Object Control Framework for Diffusion-Based Video Generation|è¿åŠ¨é›¶ç‚¹ï¼šåŸºäºæ‰©æ•£çš„è§†é¢‘ç”Ÿæˆä¸­é›¶æ ·æœ¬ç§»åŠ¨å¯¹è±¡æ§åˆ¶æ¡†æ¶|Changgu Chen, Junwei Shu, Gaoqi He, Changbo Wang, Yang Li|<http://arxiv.org/pdf/2401.10150v4>|<https://vpx-ecnu.github.io/MotionZero-website>|
|ğŸ“ æ›´æ–°|From Pixels to Titles: Video Game Identification by Screenshots using Convolutional Neural Networks|ä»åƒç´ åˆ°æ ‡é¢˜ï¼šä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œé€šè¿‡æˆªå›¾è¯†åˆ«ç”µå­æ¸¸æˆ|Fabricio Breve|<http://arxiv.org/pdf/2311.15963v3>|None|


## å…¶ä»–

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Generative Dataset Distillation Based on Self-knowledge Distillation|åŸºäºè‡ªçŸ¥è¯†è’¸é¦çš„ç”Ÿæˆæ•°æ®é›†è’¸é¦|Longzhen Li, Guang Li, Ren Togo, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama|<http://arxiv.org/pdf/2501.04202v1>|None|

