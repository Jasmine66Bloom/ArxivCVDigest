## [UPDATED!] **2025-01-16** (Update Time)


## å›¾åƒç†è§£

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Lost in Translation, Found in Context: Sign Language Translation with Contextual Cues|è¿·å¤±åœ¨ç¿»è¯‘ä¸­ï¼Œå‘ç°äºè¯­å¢ƒï¼šå€ŸåŠ©è¯­å¢ƒçº¿ç´¢çš„æ‰‹è¯­ç¿»è¯‘|Youngjoon Jang, Haran Raajesh, Liliane Momeni, GÃ¼l Varol, Andrew Zisserman|<http://arxiv.org/pdf/2501.09754v1>|None|
|ğŸ†• å‘å¸ƒ|AdaFV: Accelerating VLMs with Self-Adaptive Cross-Modality Attention Mixture|AdaFVï¼šåŸºäºè‡ªé€‚åº”è·¨æ¨¡æ€æ³¨æ„åŠ›æ··åˆåŠ é€ŸVLMs|Jiayi Han, Liang Du, Yiwen Wu, Xiangguo Zhou, Hongwei Du, Weibo Zheng|<http://arxiv.org/pdf/2501.09532v1>|None|
|ğŸ†• å‘å¸ƒ|HydraMix: Multi-Image Feature Mixing for Small Data Image Classification|HydraMixï¼šå°æ•°æ®å›¾åƒåˆ†ç±»çš„å¤šå›¾åƒç‰¹å¾æ··åˆ|Christoph Reinders, Frederik Schubert, Bodo Rosenhahn|<http://arxiv.org/pdf/2501.09504v1>|None|
|ğŸ†• å‘å¸ƒ|Double Visual Defense: Adversarial Pre-training and Instruction Tuning for Improving Vision-Language Model Robustness|åŒé‡è§†è§‰é˜²å¾¡ï¼šå¯¹æŠ—é¢„è®­ç»ƒå’ŒæŒ‡ä»¤è°ƒæ•´ä»¥æå‡è§†è§‰-è¯­è¨€æ¨¡å‹é²æ£’æ€§|Zeyu Wang, Cihang Xie, Brian Bartoldson, Bhavya Kailkhura|<http://arxiv.org/pdf/2501.09446v1>|<https://doublevisualdefense.github.io/.>|
|ğŸ†• å‘å¸ƒ|Strategic Base Representation Learning via Feature Augmentations for Few-Shot Class Incremental Learning|åŸºäºç‰¹å¾å¢å¼ºçš„å¢é‡å­¦ä¹ ç­–ç•¥æ€§åŸºè¡¨ç¤ºå­¦ä¹ |Parinita Nema, Vinod K Kurmi|<http://arxiv.org/pdf/2501.09361v1>|None|
|ğŸ†• å‘å¸ƒ|Text-guided Synthetic Geometric Augmentation for Zero-shot 3D Understanding|åŸºäºæ–‡æœ¬å¼•å¯¼çš„é›¶æ ·æœ¬3Dç†è§£åˆæˆå‡ ä½•å¢å¼º|Kohei Torimi, Ryosuke Yamada, Daichi Otsuka, Kensho Hara, Yuki M. Asano, Hirokatsu Kataoka, Yoshimitsu Aoki|<http://arxiv.org/pdf/2501.09278v1>|None|
|ğŸ†• å‘å¸ƒ|Adaptive Law-Based Transformation (ALT): A Lightweight Feature Representation for Time Series Classification|è‡ªé€‚åº”å¾‹å˜æ¢ï¼ˆALTï¼‰ï¼šç”¨äºæ—¶é—´åºåˆ—åˆ†ç±»çš„è½»é‡çº§ç‰¹å¾è¡¨ç¤º|Marcell T. Kurbucz, BalÃ¡zs HajÃ³s, BalÃ¡zs P. Halmos, Vince Ã. MolnÃ¡r, Antal JakovÃ¡c|<http://arxiv.org/pdf/2501.09217v1>|None|
|ğŸ†• å‘å¸ƒ|Surgical Visual Understanding (SurgVU) Dataset|æ‰‹æœ¯è§†è§‰ç†è§£ï¼ˆSurgVUï¼‰æ•°æ®é›†|Aneeq Zia, Max Berniker, Rogerio Nespolo, Conor Perreault, Ziheng Wang, Benjamin Mueller, Ryan Schmidt, Kiran Bhattacharyya .etc.|<http://arxiv.org/pdf/2501.09209v1>|None|
|ğŸ“ æ›´æ–°|Enhancing Few-Shot Image Classification through Learnable Multi-Scale Embedding and Attention Mechanisms|é€šè¿‡å¯å­¦ä¹ å¤šå°ºåº¦åµŒå…¥å’Œæ³¨æ„åŠ›æœºåˆ¶å¢å¼ºå°æ ·æœ¬å›¾åƒåˆ†ç±»|Fatemeh Askari, Amirreza Fateh, Mohammad Reza Mohammadi|<http://arxiv.org/pdf/2409.07989v2>|<https://github.com/FatemehAskari/MSENet>|
|ğŸ“ æ›´æ–°|Rethinking Pre-Trained Feature Extractor Selection in Multiple Instance Learning for Whole Slide Image Classification|é‡æ–°æ€è€ƒåœ¨å¤šå®ä¾‹å­¦ä¹ ä¸­çš„é¢„è®­ç»ƒç‰¹å¾æå–å™¨é€‰æ‹©ï¼Œç”¨äºå…¨åˆ‡ç‰‡å›¾åƒåˆ†ç±»|Bryan Wong, Mun Yong Yi|<http://arxiv.org/pdf/2408.01167v3>|<https://github.com/bryanwong17/MIL-Feature-Extractor-Selection>|
|ğŸ“ æ›´æ–°|MAMo: Leveraging Memory and Attention for Monocular Video Depth Estimation|MAMoï¼šåˆ©ç”¨è®°å¿†å’Œæ³¨æ„åŠ›è¿›è¡Œå•ç›®è§†é¢‘æ·±åº¦ä¼°è®¡|Rajeev Yasarla, Hong Cai, Jisoo Jeong, Yunxiao Shi, Risheek Garrepalli, Fatih Porikli|<http://arxiv.org/pdf/2307.14336v3>|None|


## æ£€æµ‹åˆ†å‰²

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ComplexVAD: Detecting Interaction Anomalies in Video|å¤æ‚VADï¼šè§†é¢‘ä¸­çš„äº¤äº’å¼‚å¸¸æ£€æµ‹|Furkan Mumcu, Michael J. Jones, Yasin Yilmaz, Anoop Cherian|<http://arxiv.org/pdf/2501.09733v1>|None|
|ğŸ†• å‘å¸ƒ|Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation|ç²¾ç»†ç²’åº¦å›¾åƒ-æ–‡æœ¬å¯¹åº”ä¸æˆæœ¬èšåˆç”¨äºå¼€æ”¾è¯æ±‡éƒ¨åˆ†åˆ†å‰²|Jiho Choi, Seonho Lee, Minhyun Lee, Seungho Lee, Hyunjung Shim|<http://arxiv.org/pdf/2501.09688v1>|None|
|ğŸ†• å‘å¸ƒ|Sequential PatchCore: Anomaly Detection for Surface Inspection using Synthetic Impurities|åºåˆ—PatchCoreï¼šåˆ©ç”¨åˆæˆæ‚è´¨è¿›è¡Œè¡¨é¢æ£€æµ‹çš„å¼‚å¸¸æ£€æµ‹|Runzhou Mao, Juraj Fulir, Christoph Garth, Petra GospodnetiÄ‡|<http://arxiv.org/pdf/2501.09579v1>|None|
|ğŸ†• å‘å¸ƒ|The Devil is in the Details: Simple Remedies for Image-to-LiDAR Representation Learning|ç»†èŠ‚å†³å®šæˆè´¥ï¼šå›¾åƒåˆ°æ¿€å…‰é›·è¾¾è¡¨ç¤ºå­¦ä¹ çš„ç®€å•è§£å†³æ–¹æ¡ˆ|Wonjun Jo, Kwon Byung-Ki, Kim Ji-Yeon, Hawook Jeong, Kyungdon Joo, Tae-Hyun Oh|<http://arxiv.org/pdf/2501.09485v1>|None|
|ğŸ†• å‘å¸ƒ|MonoSOWA: Scalable monocular 3D Object detector Without human Annotations|MonoSOWAï¼šæ— éœ€äººå·¥æ ‡æ³¨çš„ scalable å•ç›® 3D ç‰©ä½“æ£€æµ‹å™¨|Jan Skvrna, Lukas Neumann|<http://arxiv.org/pdf/2501.09481v1>|None|
|ğŸ†• å‘å¸ƒ|RE-POSE: Synergizing Reinforcement Learning-Based Partitioning and Offloading for Edge Object Detection|RE-POSEï¼šååŒåŸºäºå¼ºåŒ–å­¦ä¹ çš„åˆ†å‰²ä¸å¸è½½ä»¥ä¼˜åŒ–è¾¹ç¼˜ç›®æ ‡æ£€æµ‹|Jianrui Shi, Yong Zhao, Zeyang Cui, Xiaoming Shen, Minhang Zeng, Xiaojie Liu|<http://arxiv.org/pdf/2501.09465v1>|None|
|ğŸ†• å‘å¸ƒ|On the Relation between Optical Aperture and Automotive Object Detection|å…‰å­¦å­”å¾„ä¸æ±½è½¦ç›®æ ‡æ£€æµ‹ä¹‹é—´çš„å…³ç³»|Ofer Bar-Shalom, Tzvi Philipp, Eran Kishon|<http://arxiv.org/pdf/2501.09456v1>|None|
|ğŸ†• å‘å¸ƒ|Image Segmentation with transformers: An Overview, Challenges and Future|å›¾åƒåˆ†å‰²ä¸Transformerï¼šæ¦‚è¿°ã€æŒ‘æˆ˜ä¸æœªæ¥|Deepjyoti Chetia, Debasish Dutta, Sanjib Kr Kalita|<http://arxiv.org/pdf/2501.09372v1>|None|
|ğŸ†• å‘å¸ƒ|SE-BSFV: Online Subspace Learning based Shadow Enhancement and Background Suppression for ViSAR under Complex Background|SE-BSFVï¼šå¤æ‚èƒŒæ™¯ä¸‹ViSARçš„åœ¨çº¿å­ç©ºé—´å­¦ä¹ é˜´å½±å¢å¼ºå’ŒèƒŒæ™¯æŠ‘åˆ¶|Shangqu Yan, Chenyang Luo, Yaowen Fu, Wenpeng Zhang, Wei Yang, Ruofeng Yu|<http://arxiv.org/pdf/2501.09341v1>|None|
|ğŸ†• å‘å¸ƒ|SoccerSynth-Detection: A Synthetic Dataset for Soccer Player Detection|è¶³çƒåˆæˆæ£€æµ‹ï¼šç”¨äºè¶³çƒçƒå‘˜æ£€æµ‹çš„åˆæˆæ•°æ®é›†|Haobin Qin, Calvin Yeung, Rikuhei Umemoto, Keisuke Fujii|<http://arxiv.org/pdf/2501.09281v1>|None|
|ğŸ†• å‘å¸ƒ|Are Open-Vocabulary Models Ready for Detection of MEP Elements on Construction Sites|å¼€æ”¾è¯æ±‡æ¨¡å‹æ˜¯å¦å·²å‡†å¤‡å¥½åœ¨å»ºç­‘å·¥åœ°ä¸Šæ£€æµ‹MEPå…ƒç´ |Abdalwhab Abdalwhab, Ali Imran, Sina Heydarian, Ivanka Iordanova, David St-Onge|<http://arxiv.org/pdf/2501.09267v1>|None|
|ğŸ“ æ›´æ–°|Improving Zero-Shot Object-Level Change Detection by Incorporating Visual Correspondence|é€šè¿‡å¼•å…¥è§†è§‰å¯¹åº”æ€§æ”¹è¿›é›¶æ ·æœ¬å¯¹è±¡çº§å˜åŒ–æ£€æµ‹|Hung Huy Nguyen, Pooyan Rahmanzadehgervi, Long Mai, Anh Totti Nguyen|<http://arxiv.org/pdf/2501.05555v2>|None|
|ğŸ“ æ›´æ–°|VLG-CBM: Training Concept Bottleneck Models with Vision-Language Guidance|è§†è§‰-è¯­è¨€å¼•å¯¼ä¸‹è®­ç»ƒæ¦‚å¿µç“¶é¢ˆæ¨¡å‹|Divyansh Srivastava, Ge Yan, Tsui-Wei Weng|<http://arxiv.org/pdf/2408.01432v3>|None|
|ğŸ“ æ›´æ–°|IOR: Inversed Objects Replay for Incremental Object Detection|é€†å¯¹è±¡é‡æ”¾ï¼šç”¨äºå¢é‡ç›®æ ‡æ£€æµ‹çš„é€†å¯¹è±¡é‡æ”¾|Zijia An, Boyu Diao, Libo Huang, Ruiqi Liu, Zhulin An, Yongjun Xu|<http://arxiv.org/pdf/2406.04829v3>|None|
|ğŸ“ æ›´æ–°|A Comparative Study on Multi-task Uncertainty Quantification in Semantic Segmentation and Monocular Depth Estimation|å¤šä»»åŠ¡ä¸ç¡®å®šæ€§é‡åŒ–åœ¨è¯­ä¹‰åˆ†å‰²å’Œå•ç›®æ·±åº¦ä¼°è®¡ä¸­çš„æ¯”è¾ƒç ”ç©¶|Steven Landgraf, Markus Hillemann, Theodor Kapler, Markus Ulrich|<http://arxiv.org/pdf/2405.17097v2>|None|


## è§†é¢‘ç†è§£

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Finding the Trigger: Causal Abductive Reasoning on Video Events|å¯»æ‰¾è§¦å‘å› ç´ ï¼šè§†é¢‘äº‹ä»¶ä¸Šçš„å› æœæ¨è®º|Thao Minh Le, Vuong Le, Kien Do, Sunil Gupta, Svetha Venkatesh, Truyen Tran|<http://arxiv.org/pdf/2501.09304v1>|None|
|ğŸ“ æ›´æ–°|MECD+: Unlocking Event-Level Causal Graph Discovery for Video Reasoning|MECD+ï¼šè§£é”è§†é¢‘æ¨ç†ä¸­çš„äº‹ä»¶çº§å› æœå›¾å‘ç°|Tieyuan Chen, Huabin Liu, Yi Wang, Yihang Chen, Tianyao He, Chaofan Gan, Huanyu He, Weiyao Lin|<http://arxiv.org/pdf/2501.07227v2>|None|


## ç”Ÿæˆæ¨¡å‹

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps|æ‰©æ•£æ¨¡å‹æ¨ç†æ—¶é—´ç¼©æ”¾è¶…è¶Šç¼©æ”¾å»å™ªæ­¥éª¤|Nanye Ma, Shangyuan Tong, Haolin Jia, Hexiang Hu, Yu-Chuan Su, Mingda Zhang, Xuan Yang, Yandong Li .etc.|<http://arxiv.org/pdf/2501.09732v1>|None|
|ğŸ†• å‘å¸ƒ|AnyStory: Towards Unified Single and Multiple Subject Personalization in Text-to-Image Generation|AnyStoryï¼šè¿ˆå‘ç»Ÿä¸€å•ä¸»ä½“å’Œå¤šä¸»ä½“æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸ªæ€§åŒ–|Junjie He, Yuxiang Tuo, Binghui Chen, Chongyang Zhong, Yifeng Geng, Liefeng Bo|<http://arxiv.org/pdf/2501.09503v1>|<https://aigcdesigngroup.github.io/AnyStory>|
|ğŸ†• å‘å¸ƒ|CaPa: Carve-n-Paint Synthesis for Efficient 4K Textured Mesh Generation|CaPaï¼šé«˜æ•ˆ4Kçº¹ç†ç½‘æ ¼çš„Carve-n-Paintåˆæˆ|Hwan Heo, Jangyeong Kim, Seongyeong Lee, Jeong A Wi, Junyoung Choi, Sangjun Ahn|<http://arxiv.org/pdf/2501.09433v1>|None|
|ğŸ†• å‘å¸ƒ|Dynamic Neural Style Transfer for Artistic Image Generation using VGG19|åŠ¨æ€ç¥ç»é£æ ¼è¿ç§»ï¼šåŸºäºVGG19çš„è‰ºæœ¯å›¾åƒç”Ÿæˆ|Kapil Kashyap, Mehak Garg, Sean Fargose, Sindhu Nair|<http://arxiv.org/pdf/2501.09420v1>|None|
|ğŸ“ æ›´æ–°|A General Framework for Inference-time Scaling and Steering of Diffusion Models|é€šç”¨æ‰©æ•£æ¨¡å‹æ¨ç†æ—¶ç¼©æ”¾å’Œå¼•å¯¼æ¡†æ¶|Raghav Singhal, Zachary Horvitz, Ryan Teehan, Mengye Ren, Zhou Yu, Kathleen McKeown, Rajesh Ranganath|<http://arxiv.org/pdf/2501.06848v3>|<https://github.com/zacharyhorvitz/Fk-Diffusion-Steering>|
|ğŸ“ æ›´æ–°|Synthesizing Forestry Images Conditioned on Plant Phenotype Using a Generative Adversarial Network|åŸºäºæ¤ç‰©è¡¨å‹çš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œåˆæˆæ—ä¸šå›¾åƒ|Debasmita Pal, Arun Ross|<http://arxiv.org/pdf/2307.03789v3>|None|


## æ‰©æ•£æ¡¥

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|DiffMesh: A Motion-aware Diffusion Framework for Human Mesh Recovery from Videos|DiffMeshï¼šä¸€ç§ç”¨äºä»è§†é¢‘ä¸­æ¢å¤äººä½“ç½‘æ ¼çš„æ„ŸçŸ¥è¿åŠ¨æ‰©æ•£æ¡†æ¶|Ce Zheng, Xianpeng Liu, Qucheng Peng, Tianfu Wu, Pu Wang, Chen Chen|<http://arxiv.org/pdf/2303.13397v6>|None|


## æµæ¨¡å‹

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|DEFOM-Stereo: Depth Foundation Model Based Stereo Matching|DEFOM-Stereoï¼šåŸºäºæ·±åº¦åŸºç¡€æ¨¡å‹çš„ç«‹ä½“åŒ¹é…|Hualie Jiang, Zhiqiang Lou, Laiyan Ding, Rui Xu, Minglang Tan, Wenjie Jiang, Rui Huang|<http://arxiv.org/pdf/2501.09466v1>|None|


## å›¾åƒå¤„ç†

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|FLOL: Fast Baselines for Real-World Low-Light Enhancement|å¿«é€ŸçœŸå®ä¸–ç•Œä½å…‰å¢å¼ºçš„åŸºçº¿|Juan C. Benito, Daniel Feijoo, Alvaro Garcia, Marcos V. Conde|<http://arxiv.org/pdf/2501.09718v1>|<https://github.com/cidautai/FLOL>|
|ğŸ†• å‘å¸ƒ|Text-driven Adaptation of Foundation Models for Few-shot Surgical Workflow Analysis|åŸºäºæ–‡æœ¬é©±åŠ¨çš„åŸºåº§æ¨¡å‹åœ¨å°‘æ ·æœ¬æ‰‹æœ¯æµç¨‹åˆ†æä¸­çš„åº”ç”¨|Tingxuan Chen, Kun Yuan, Vinkle Srivastav, Nassir Navab, Nicolas Padoy|<http://arxiv.org/pdf/2501.09555v1>|<https://github.com/TingxuanSix/Surg-FTDA.>|
|ğŸ†• å‘å¸ƒ|Joint Transmission and Deblurring: A Semantic Communication Approach Using Events|è”åˆä¼ è¾“ä¸å»æ¨¡ç³Šï¼šåŸºäºäº‹ä»¶çš„è¯­ä¹‰é€šä¿¡æ–¹æ³•|Pujing Yang, Guangyi Zhang, Yunlong Cai, Lei Yu, Guanding Yu|<http://arxiv.org/pdf/2501.09396v1>|None|
|ğŸ†• å‘å¸ƒ|SVIA: A Street View Image Anonymization Framework for Self-Driving Applications|SVIAï¼šé¢å‘è‡ªåŠ¨é©¾é©¶åº”ç”¨çš„è¡—æ™¯å›¾åƒåŒ¿ååŒ–æ¡†æ¶|Dongyu Liu, Xuhong Wang, Cen Chen, Yanhao Wang, Shengyue Yao, Yilun Lin|<http://arxiv.org/pdf/2501.09393v1>|None|
|ğŸ†• å‘å¸ƒ|Prompt-CAM: A Simpler Interpretable Transformer for Fine-Grained Analysis|æç¤º-CAMï¼šä¸€ç§ç”¨äºç»†ç²’åº¦åˆ†æçš„æ›´ç®€å•çš„å¯è§£é‡ŠTransformer|Arpita Chowdhury, Dipanjyoti Paul, Zheda Mai, Jianyang Gu, Ziheng Zhang, Kazi Sajeed Mehrab, Elizabeth G. Campolongo, Daniel Rubenstein .etc.|<http://arxiv.org/pdf/2501.09333v1>|None|
|ğŸ†• å‘å¸ƒ|Soft Knowledge Distillation with Multi-Dimensional Cross-Net Attention for Image Restoration Models Compression|åŸºäºå¤šç»´åº¦äº¤å‰ç½‘ç»œæ³¨æ„åŠ›çš„è½¯çŸ¥è¯†è’¸é¦ç”¨äºå›¾åƒæ¢å¤æ¨¡å‹å‹ç¼©|Yongheng Zhang, Danfeng Yan|<http://arxiv.org/pdf/2501.09321v1>|None|
|ğŸ†• å‘å¸ƒ|Shape-Based Single Object Classification Using Ensemble Method Classifiers|åŸºäºå½¢çŠ¶çš„å•å¯¹è±¡åˆ†ç±»ä½¿ç”¨é›†æˆæ–¹æ³•åˆ†ç±»å™¨|Nur Shazwani Kamarudin, Mokhairi Makhtar, Syadiah Nor Wan Shamsuddin, Syed Abdullah Fadzli|<http://arxiv.org/pdf/2501.09311v1>|None|
|ğŸ“ æ›´æ–°|StructSR: Refuse Spurious Details in Real-World Image Super-Resolution|ç»“æ„è¶…åˆ†è¾¨ç‡ï¼šåœ¨çœŸå®ä¸–ç•Œå›¾åƒä¸­æ‹’ç»è™šå‡ç»†èŠ‚|Yachao Li, Dong Liang, Tianyu Ding, Sheng-Jun Huang|<http://arxiv.org/pdf/2501.05777v2>|None|
|ğŸ“ æ›´æ–°|Super-class guided Transformer for Zero-Shot Attribute Classification|è¶…çº§ç±»åˆ«å¼•å¯¼çš„Transformeråœ¨é›¶æ ·æœ¬å±æ€§åˆ†ç±»ä¸­çš„åº”ç”¨|Sehyung Kim, Chanhyeong Yang, Jihwan Park, Taehoon Song, Hyunwoo J. Kim|<http://arxiv.org/pdf/2501.05728v2>|<https://github.com/mlvlab/SugaFormer.>|
|ğŸ“ æ›´æ–°|TextureCrop: Enhancing Synthetic Image Detection through Texture-based Cropping|çº¹ç†è£å‰ªï¼šé€šè¿‡åŸºäºçº¹ç†çš„è£å‰ªå¢å¼ºåˆæˆå›¾åƒæ£€æµ‹|Despina Konstantinidou, Christos Koutlis, Symeon Papadopoulos|<http://arxiv.org/pdf/2407.15500v4>|<https://github.com/mever-team/texture-crop.>|
|ğŸ“ æ›´æ–°|Direct Unlearning Optimization for Robust and Safe Text-to-Image Models|ç›´æ¥åå­¦ä¹ ä¼˜åŒ–ä»¥å®ç°é²æ£’ä¸”å®‰å…¨çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹|Yong-Hyun Park, Sangdoo Yun, Jin-Hwa Kim, Junho Kim, Geonhui Jang, Yonghyun Jeong, Junghyo Jo, Gayoung Lee|<http://arxiv.org/pdf/2407.21035v2>|None|
|ğŸ“ æ›´æ–°|reBEN: Refined BigEarthNet Dataset for Remote Sensing Image Analysis|ç²¾ç‚¼å¤§åœ°çƒç½‘æ•°æ®é›†ï¼šç”¨äºé¥æ„Ÿå›¾åƒåˆ†æçš„reBEN|Kai Norman Clasen, Leonard Hackel, Tom Burgert, Gencer Sumbul, BegÃ¼m Demir, Volker Markl|<http://arxiv.org/pdf/2407.03653v3>|None|
|ğŸ“ æ›´æ–°|Geometric Distortion Guided Transformer for Omnidirectional Image Super-Resolution|å…¨å‘å›¾åƒè¶…åˆ†è¾¨ç‡ä¸­çš„å‡ ä½•ç•¸å˜å¼•å¯¼Transformer|Cuixin Yang, Rongkang Dong, Jun Xiao, Cong Zhang, Kin-Man Lam, Fei Zhou, Guoping Qiu|<http://arxiv.org/pdf/2406.10869v2>|None|


## 3Dåœºæ™¯

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Learnings from Scaling Visual Tokenizers for Reconstruction and Generation|ä»æ‰©å±•è§†è§‰æ ‡è®°å™¨ç”¨äºé‡å»ºå’Œç”Ÿæˆä¸­çš„å­¦ä¹ |Philippe Hansen-Estruch, David Yan, Ching-Yao Chung, Orr Zohar, Jialiang Wang, Tingbo Hou, Tao Xu, Sriram Vishwanath .etc.|<http://arxiv.org/pdf/2501.09755v1>|None|
|ğŸ†• å‘å¸ƒ|UVRM: A Scalable 3D Reconstruction Model from Unposed Videos|UVRMï¼šä»æœªæ‘†å§¿åŠ¿è§†é¢‘ä¸­å¯æ‰©å±•çš„3Dé‡å»ºæ¨¡å‹|Shiu-hong Kao, Xiao Li, Jinglu Wang, Chi-Keung Tang, Yu-Wing Tai, Yan Lu|<http://arxiv.org/pdf/2501.09347v1>|None|
|ğŸ“ æ›´æ–°|BRIGHT-VO: Brightness-Guided Hybrid Transformer for Visual Odometry with Multi-modality Refinement Module|æ˜äº®è§†è§‰é‡Œç¨‹è®¡ï¼šå…·æœ‰å¤šæ¨¡æ€ç»†åŒ–æ¨¡å—çš„äº®åº¦å¼•å¯¼æ··åˆTransformer|Dongzhihan Wang, Yang Yang, Liang Xu|<http://arxiv.org/pdf/2501.08659v2>|<https://github.com/Anastasiawd/BrightVO.>|
|ğŸ“ æ›´æ–°|Point-PRC: A Prompt Learning Based Regulation Framework for Generalizable Point Cloud Analysis|ç‚¹-PRCï¼šä¸€ç§åŸºäºæç¤ºå­¦ä¹ çš„é€šç”¨ç‚¹äº‘åˆ†æè°ƒèŠ‚æ¡†æ¶|Hongyu Sun, Qiuhong Ke, Yongcai Wang, Wang Chen, Kang Yang, Deying Li, Jianfei Cai|<http://arxiv.org/pdf/2410.20406v3>|<https://github.com/auniquesun/Point-PRC>|
|ğŸ“ æ›´æ–°|FutureDepth: Learning to Predict the Future Improves Video Depth Estimation|æœªæ¥æ·±åº¦ï¼šå­¦ä¹ é¢„æµ‹æœªæ¥ä»¥æå‡è§†é¢‘æ·±åº¦ä¼°è®¡|Rajeev Yasarla, Manish Kumar Singh, Hong Cai, Yunxiao Shi, Jisoo Jeong, Yinhao Zhu, Shizhong Han, Risheek Garrepalli .etc.|<http://arxiv.org/pdf/2403.12953v2>|None|


## ç¥ç»æ¸²æŸ“

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Normal-NeRF: Ambiguity-Robust Normal Estimation for Highly Reflective Scenes|æ­£å¸¸-NeRFï¼šé’ˆå¯¹é«˜åå°„åœºæ™¯çš„é²æ£’æ€§æ­£å¸¸ä¼°è®¡|Ji Shi, Xianghua Ying, Ruohao Guo, Bowei Xing, Wenzhen Yue|<http://arxiv.org/pdf/2501.09460v1>|None|
|ğŸ†• å‘å¸ƒ|PISCO: Self-Supervised k-Space Regularization for Improved Neural Implicit k-Space Representations of Dynamic MRI|PISCOï¼šç”¨äºæ”¹è¿›åŠ¨æ€MRIç¥ç»éšå¼kç©ºé—´è¡¨ç¤ºçš„è‡ªç›‘ç£kç©ºé—´æ­£åˆ™åŒ–|Veronika Spieker, Hannah Eichhorn, Wenqi Huang, Jonathan K. Stelter, Tabita Catalan, Rickmer F. Braren, Daniel Rueckert, Francisco Sahli Costabal .etc.|<http://arxiv.org/pdf/2501.09403v1>|<https://github.com/compai-lab/2025-pisco-spieker>|
|ğŸ†• å‘å¸ƒ|Bias for Action: Video Implicit Neural Representations with Bias Modulation|åå‘è¡ŒåŠ¨ï¼šå…·æœ‰åç½®è°ƒåˆ¶çš„è§†é¢‘éšå¼ç¥ç»ç½‘ç»œè¡¨ç¤º|Alper Kayabasi, Anil Kumar Vadathya, Guha Balakrishnan, Vishwanath Saragadam|<http://arxiv.org/pdf/2501.09277v1>|None|
|ğŸ†• å‘å¸ƒ|OpticFusion: Multi-Modal Neural Implicit 3D Reconstruction of Microstructures by Fusing White Light Interferometry and Optical Microscopy|å…‰å­¦èåˆï¼šé€šè¿‡èåˆç™½å…‰å¹²æ¶‰æµ‹é‡å’Œå…‰å­¦æ˜¾å¾®é•œçš„å¤šæ¨¡æ€ç¥ç»éšå¼3Dé‡å»ºå¾®ç»“æ„|Shuo Chen, Yijin Li, Guofeng Zhang|<http://arxiv.org/pdf/2501.09259v1>|<https://github.com/zju3dv/OpticFusion.>|
|ğŸ“ æ›´æ–°|CryoBench: Diverse and challenging datasets for the heterogeneity problem in cryo-EM|CryoBenchï¼šå†·å†»ç”µé•œå¼‚è´¨æ€§é—®é¢˜çš„å¤šæ ·æ€§å’ŒæŒ‘æˆ˜æ€§æ•°æ®é›†|Minkyu Jeon, Rishwanth Raghu, Miro Astore, Geoffrey Woollard, Ryan Feathers, Alkin Kaz, Sonya M. Hanson, Pilar Cossio .etc.|<http://arxiv.org/pdf/2408.05526v2>|None|


## 3DGS

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Creating Virtual Environments with 3D Gaussian Splatting: A Comparative Study|åˆ©ç”¨3Dé«˜æ–¯å–·æº…åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼šä¸€é¡¹æ¯”è¾ƒç ”ç©¶|Shi Qiu, Binzhu Xie, Qixuan Liu, Pheng-Ann Heng|<http://arxiv.org/pdf/2501.09302v1>|None|
|ğŸ“ æ›´æ–°|Diffusion Models in Vision: A Survey|è§†è§‰ä¸­çš„æ‰©æ•£æ¨¡å‹ï¼šç»¼è¿°|Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, Mubarak Shah|<http://arxiv.org/pdf/2209.04747v6>|None|


## å¤šæ¨¡æ€

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|A Simple Aerial Detection Baseline of Multimodal Language Models|å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹çš„ä¸€ç§ç®€å•ç©ºä¸­æ£€æµ‹åŸºçº¿|Qingyun Li, Yushi Chen, Xinya Shu, Dong Chen, Xin He, Yi Yu, Xue Yang|<http://arxiv.org/pdf/2501.09720v1>|<https://github.com/Li-Qingyun/mllm-mmrotate.>|
|ğŸ†• å‘å¸ƒ|Mitigating Hallucinations in Large Vision-Language Models via DPO: On-Policy Data Hold the Key|é€šè¿‡DPOå‡è½»å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰ï¼šæŒ‰ç­–ç•¥æ•°æ®æ˜¯å…³é”®|Zhihe Yang, Xufang Luo, Dongqi Han, Yunjian Xu, Dongsheng Li|<http://arxiv.org/pdf/2501.09695v1>|None|
|ğŸ†• å‘å¸ƒ|Metric Learning with Progressive Self-Distillation for Audio-Visual Embedding Learning|åŸºäºæ¸è¿›å¼è‡ªè’¸é¦çš„åº¦é‡å­¦ä¹ ç”¨äºéŸ³é¢‘-è§†è§‰åµŒå…¥å­¦ä¹ |Donghuo Zeng, Kazushi Ikeda|<http://arxiv.org/pdf/2501.09608v1>|None|
|ğŸ†• å‘å¸ƒ|VanGogh: A Unified Multimodal Diffusion-based Framework for Video Colorization|æ¢µé«˜ï¼šä¸€ç§ç»Ÿä¸€çš„åŸºäºæ‰©æ•£çš„å¤šæ¨¡æ€è§†é¢‘ç€è‰²æ¡†æ¶|Zixun Fang, Zhiheng Liu, Kai Zhu, Yu Liu, Ka Leong Cheng, Wei Zhai, Yang Cao, Zheng-Jun Zha|<http://arxiv.org/pdf/2501.09499v1>|<https://becauseimbatman0.github.io/VanGogh.>|
|ğŸ†• å‘å¸ƒ|AugRefer: Advancing 3D Visual Grounding via Cross-Modal Augmentation and Spatial Relation-based Referring|AugReferï¼šé€šè¿‡è·¨æ¨¡æ€å¢å¼ºå’ŒåŸºäºç©ºé—´å…³ç³»çš„ç›®æ ‡å®šä½æ¨è¿›3Dè§†è§‰å®šä½|Xinyi Wang, Na Zhao, Zhiyuan Han, Dan Guo, Xun Yang|<http://arxiv.org/pdf/2501.09428v1>|None|
|ğŸ†• å‘å¸ƒ|YETI (YET to Intervene) Proactive Interventions by Multimodal AI Agents in Augmented Reality Tasks|YETIï¼ˆå°šæœªå¹²é¢„ï¼‰â€”â€”åœ¨å¢å¼ºç°å®ä»»åŠ¡ä¸­ç”±å¤šæ¨¡æ€AIä»£ç†è¿›è¡Œçš„ä¸»åŠ¨å¹²é¢„|Saptarashmi Bandyopadhyay, Vikas Bahirwani, Lavisha Aggarwal, Bhanu Guda, Lin Li, Andrea Colaco|<http://arxiv.org/pdf/2501.09355v1>|None|
|ğŸ“ æ›´æ–°|VITA-1.5: Towards GPT-4o Level Real-Time Vision and Speech Interaction|VITA-1.5ï¼šè¿ˆå‘GPT-4oçº§å®æ—¶è§†è§‰ä¸è¯­éŸ³äº¤äº’|Chaoyou Fu, Haojia Lin, Xiong Wang, Yi-Fan Zhang, Yunhang Shen, Xiaoyu Liu, Yangze Li, Zuwei Long .etc.|<http://arxiv.org/pdf/2501.01957v2>|None|
|ğŸ“ æ›´æ–°|Instruction-Guided Fusion of Multi-Layer Visual Features in Large Vision-Language Models|æŒ‡å¯¼å‹å¤šå±‚çº§è§†è§‰ç‰¹å¾èåˆåœ¨å¤§è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­çš„åº”ç”¨|Xu Li, Yi Zheng, Haotian Chen, Xiaolei Chen, Yuxuan Liang, Chenghang Lai, Bin Li, Xiangyang Xue|<http://arxiv.org/pdf/2501.08443v2>|None|


## å…·èº«æ™ºèƒ½

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Distilling Multi-modal Large Language Models for Autonomous Driving|æç‚¼å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä»¥å®ç°è‡ªåŠ¨é©¾é©¶|Deepti Hegde, Rajeev Yasarla, Hong Cai, Shizhong Han, Apratim Bhattacharyya, Shweta Mahajan, Litian Liu, Risheek Garrepalli .etc.|<http://arxiv.org/pdf/2501.09757v1>|None|
|ğŸ†• å‘å¸ƒ|SynthLight: Portrait Relighting with Diffusion Model by Learning to Re-render Synthetic Faces|SynthLightï¼šé€šè¿‡å­¦ä¹ é‡æ–°æ¸²æŸ“åˆæˆé¢å­”è¿›è¡Œäººåƒé‡å…‰ç…§çš„æ‰©æ•£æ¨¡å‹|Sumit Chaturvedi, Mengwei Ren, Yannick Hold-Geoffroy, Jingyuan Liu, Julie Dorsey, Zhixin Shu|<http://arxiv.org/pdf/2501.09756v1>|<https://vrroom.github.io/synthlight>|
|ğŸ†• å‘å¸ƒ|Mesh2SLAM in VR: A Fast Geometry-Based SLAM Framework for Rapid Prototyping in Virtual Reality Applications|VRä¸­çš„Mesh2SLAMï¼šä¸€ç§å¿«é€ŸåŸå‹è®¾è®¡çš„åŸºäºå‡ ä½•çš„SLAMæ¡†æ¶|Carlos Augusto Pinheiro de Sousa, Heiko Hamann, Oliver Deussen|<http://arxiv.org/pdf/2501.09600v1>|None|
|ğŸ†• å‘å¸ƒ|Comparison of Various SLAM Systems for Mobile Robot in an Indoor Environment|å®¤å†…ç¯å¢ƒä¸­ç§»åŠ¨æœºå™¨äººçš„å„ç§SLAMç³»ç»Ÿæ¯”è¾ƒ|Maksim Filipenko, Ilya Afanasyev|<http://arxiv.org/pdf/2501.09490v1>|None|
|ğŸ“ æ›´æ–°|Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise|éšæµè€Œè¡Œï¼šä½¿ç”¨å®æ—¶æ‰­æ›²å™ªå£°çš„è¿åŠ¨å¯æ§è§†é¢‘æ‰©æ•£æ¨¡å‹|Ryan Burgert, Yuancheng Xu, Wenqi Xian, Oliver Pilarski, Pascal Clausen, Mingming He, Li Ma, Yitong Deng .etc.|<http://arxiv.org/pdf/2501.08331v2>|<https://github.com/VGenAI-Netflix-Eyeline-Research/Go-with-the-Flow.>|
|ğŸ“ æ›´æ–°|Towards an End-to-End (E2E) Adversarial Learning and Application in the Physical World|è¿ˆå‘ç«¯åˆ°ç«¯ï¼ˆE2Eï¼‰å¯¹æŠ—å­¦ä¹ åŠå…¶åœ¨ç‰©ç†ä¸–ç•Œä¸­çš„åº”ç”¨|Dudi Biton, Jacob Shams, Satoru Koda, Asaf Shabtai, Yuval Elovici, Ben Nassi|<http://arxiv.org/pdf/2501.08258v2>|None|
|ğŸ“ æ›´æ–°|Latent Space Characterization of Autoencoder Variants|è‡ªç¼–ç å™¨å˜ä½“çš„æ½œåœ¨ç©ºé—´è¡¨å¾|Anika Shrivastava, Renu Rameshan, Samar Agnihotri|<http://arxiv.org/pdf/2412.04755v2>|None|
|ğŸ“ æ›´æ–°|Skinned Motion Retargeting with Dense Geometric Interaction Perception|çš®è‚¤è¿åŠ¨é‡å®šå‘ä¸å¯†é›†å‡ ä½•äº¤äº’æ„ŸçŸ¥|Zijie Ye, Jia-Wei Liu, Jia Jia, Shikun Sun, Mike Zheng Shou|<http://arxiv.org/pdf/2410.20986v2>|<https://github.com/abcyzj/MeshRet.>|
|ğŸ“ æ›´æ–°|Bayesian Low-Rank LeArning (Bella): A Practical Approach to Bayesian Neural Networks|è´å¶æ–¯ä½ç§©å­¦ä¹ ï¼ˆBellaï¼‰ï¼šè´å¶æ–¯ç¥ç»ç½‘ç»œçš„å®é™…æ–¹æ³•|Bao Gia Doan, Afshar Shamsi, Xiao-Yu Guo, Arash Mohammadi, Hamid Alinejad-Rokny, Dino Sejdinovic, Damien Teney, Damith C. Ranasinghe .etc.|<http://arxiv.org/pdf/2407.20891v4>|None|
|ğŸ“ æ›´æ–°|DriveLM: Driving with Graph Visual Question Answering|é©¾é©¶å›¾è§†è§‰é—®ç­”ï¼šDriveLMï¼šé©¾é©¶ä¹‹æ—…|Chonghao Sima, Katrin Renz, Kashyap Chitta, Li Chen, Hanxue Zhang, Chengen Xie, Jens BeiÃŸwenger, Ping Luo .etc.|<http://arxiv.org/pdf/2312.14150v3>|None|
|ğŸ“ æ›´æ–°|Collaboration in Immersive Environments: Challenges and Solutions|æ²‰æµ¸å¼ç¯å¢ƒä¸­çš„åä½œï¼šæŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ|Shahin Doroudian|<http://arxiv.org/pdf/2311.00689v4>|None|


## äººä½“åˆ†æ

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Robin: a Suite of Multi-Scale Vision-Language Models and the CHIRP Evaluation Benchmark|Robinï¼šä¸€å¥—å¤šå°ºåº¦è§†è§‰-è¯­è¨€æ¨¡å‹å’ŒCHIRPè¯„ä¼°åŸºå‡†|Alexis Roger, Prateek Humane, Daniel Z. Kaplan, Kshitij Gupta, Qi Sun, George Adamopoulos, Jonathan Siu Chi Lim, Quentin Anthony .etc.|<http://arxiv.org/pdf/2501.09672v1>|None|
|ğŸ†• å‘å¸ƒ|A New Teacher-Reviewer-Student Framework for Semi-supervised 2D Human Pose Estimation|ä¸€ç§ç”¨äºåŠç›‘ç£2Däººä½“å§¿æ€ä¼°è®¡çš„æ–°å‹æ•™å¸ˆ-å®¡ç¨¿äºº-å­¦ç”Ÿæ¡†æ¶|Wulian Yun, Mengshi Qi, Fei Peng, Huadong Ma|<http://arxiv.org/pdf/2501.09565v1>|None|
|ğŸ†• å‘å¸ƒ|Towards Robust and Realistic Human Pose Estimation via WiFi Signals|é€šè¿‡WiFiä¿¡å·å®ç°é²æ£’ä¸”çœŸå®çš„äººä½“å§¿æ€ä¼°è®¡|Yang Chen, Jingcai Guo, Song Guo, Jingren Zhou, Dacheng Tao|<http://arxiv.org/pdf/2501.09411v1>|None|
|ğŸ“ æ›´æ–°|Towards Balanced Continual Multi-Modal Learning in Human Pose Estimation|æœç€å¹³è¡¡çš„æŒç»­å¤šæ¨¡æ€å­¦ä¹ åœ¨äººä½“å§¿æ€ä¼°è®¡ä¸­çš„ç ”ç©¶|Jiaxuan Peng, Mengshi Qi, Dong Zhao, Huadong Ma|<http://arxiv.org/pdf/2501.05264v3>|None|
|ğŸ“ æ›´æ–°|Evaluating alignment between humans and neural network representations in image-based learning tasks|è¯„ä¼°äººç±»ä¸ç¥ç»ç½‘ç»œåœ¨åŸºäºå›¾åƒçš„å­¦ä¹ ä»»åŠ¡ä¸­çš„è¡¨ç¤ºå¯¹é½|Can Demircan, Tankred Saanum, Leonardo Pettini, Marcel Binz, Blazej M Baczkowski, Christian F Doeller, Mona M Garvert, Eric Schulz|<http://arxiv.org/pdf/2306.09377v3>|None|


## äººè„¸æŠ€æœ¯

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Unified Face Matching and Physical-Digital Spoofing Attack Detection|ç»Ÿä¸€äººè„¸åŒ¹é…ä¸ç‰©ç†-æ•°å­—æ¬ºéª—æ”»å‡»æ£€æµ‹|Arun Kunwar, Ajita Rattani|<http://arxiv.org/pdf/2501.09635v1>|None|
|ğŸ†• å‘å¸ƒ|WMamba: Wavelet-based Mamba for Face Forgery Detection|WMambaï¼šåŸºäºå°æ³¢å˜æ¢çš„Mambaäººè„¸ä¼ªé€ æ£€æµ‹|Siran Peng, Tianshuo Zhang, Li Gao, Xiangyu Zhu, Haoyuan Zhang, Kai Pang, Zhen Lei|<http://arxiv.org/pdf/2501.09617v1>|None|
|ğŸ†• å‘å¸ƒ|Omni-Emotion: Extending Video MLLM with Detailed Face and Audio Modeling for Multimodal Emotion Analysis|å…¨æƒ…æ„Ÿï¼šé€šè¿‡è¯¦ç»†çš„é¢éƒ¨å’ŒéŸ³é¢‘å»ºæ¨¡æ‰©å±•è§†é¢‘å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æ|Qize Yang, Detao Bai, Yi-Xing Peng, Xihan Wei|<http://arxiv.org/pdf/2501.09502v1>|None|
|ğŸ“ æ›´æ–°|iFADIT: Invertible Face Anonymization via Disentangled Identity Transform|iFADITï¼šåŸºäºè§£è€¦èº«ä»½å˜æ¢çš„å¯é€†äººè„¸åŒ¿ååŒ–|Lin Yuan, Kai Liang, Xiong Li, Tao Wu, Nannan Wang, Xinbo Gao|<http://arxiv.org/pdf/2501.04390v2>|None|
|ğŸ“ æ›´æ–°|A Multi-Modal Approach for Face Anti-Spoofing in Non-Calibrated Systems using Disparity Maps|åŸºäºè§†å·®å›¾çš„éæ ‡å®šç³»ç»Ÿäººè„¸åæ¬ºéª—çš„å¤šæ¨¡æ€æ–¹æ³•|Ariel Larey, Eyal Rond, Omer Achrack|<http://arxiv.org/pdf/2410.24031v3>|None|


## æ¨¡å‹ä¼˜åŒ–

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Practical Continual Forgetting for Pre-trained Vision Models|å®ç”¨é¢„è®­ç»ƒè§†è§‰æ¨¡å‹çš„æŒç»­é—å¿˜|Hongbo Zhao, Fei Zhu, Bolin Ni, Feng Zhu, Gaofeng Meng, Zhaoxiang Zhang|<http://arxiv.org/pdf/2501.09705v1>|<https://github.com/bjzhb666/GS-LoRA.>|
|ğŸ†• å‘å¸ƒ|Knowledge Distillation for Image Restoration : Simultaneous Learning from Degraded and Clean Images|å›¾åƒä¿®å¤ä¸­çš„çŸ¥è¯†è’¸é¦ï¼šä»é€€åŒ–å›¾åƒå’Œæ¸…æ™°å›¾åƒä¸­åŒæ—¶å­¦ä¹ |Yongheng Zhang, Danfeng Yan|<http://arxiv.org/pdf/2501.09268v1>|None|
|ğŸ“ æ›´æ–°|DehazeGS: Seeing Through Fog with 3D Gaussian Splatting|DehazeGSï¼šåˆ©ç”¨3Dé«˜æ–¯åˆ†å±‚å®ç°é›¾å¤©å›¾åƒå»é›¾|Jinze Yu, Yiqun Wang, Zhengda Lu, Jianwei Guo, Yong Li, Hongxing Qin, Xiaopeng Zhang|<http://arxiv.org/pdf/2501.03659v3>|None|
|ğŸ“ æ›´æ–°|Vulnerability-Aware Spatio-Temporal Learning for Generalizable and Interpretable Deepfake Video Detection|å…·æœ‰å¯è§£é‡Šæ€§çš„æ³›åŒ–æ·±åº¦ä¼ªé€ è§†é¢‘æ£€æµ‹çš„æ¼æ´æ„ŸçŸ¥æ—¶ç©ºå­¦ä¹ |Dat Nguyen, Marcella Astrid, Anis Kacem, Enjie Ghorbel, Djamila Aouada|<http://arxiv.org/pdf/2501.01184v2>|<https://github.com/10Ring/FakeSTormer.>|
|ğŸ“ æ›´æ–°|STROOBnet Optimization via GPU-Accelerated Proximal Recurrence Strategies|STROOBneté€šè¿‡GPUåŠ é€Ÿçš„è¿‘ç«¯é€’å½’ç­–ç•¥ä¼˜åŒ–|Ted Edward Holmberg, Mahdi Abdelguerfi, Elias Ioup|<http://arxiv.org/pdf/2404.14388v3>|None|


## åŒ»å­¦åº”ç”¨

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SRE-Conv: Symmetric Rotation Equivariant Convolution for Biomedical Image Classification|SRE-Convï¼šå¯¹ç§°æ—‹è½¬ç­‰å˜å·ç§¯åœ¨ç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†ç±»ä¸­çš„åº”ç”¨|Yuexi Du, Jiazhen Zhang, Tal Zeevi, Nicha C. Dvornek, John A. Onofrey|<http://arxiv.org/pdf/2501.09753v1>|<https://github.com/XYPB/SRE-Conv.>|
|ğŸ†• å‘å¸ƒ|Exploring AI-based System Design for Pixel-level Protected Health Information Detection in Medical Images|æ¢ç´¢åŸºäºAIçš„ç³»ç»Ÿè®¾è®¡åœ¨åŒ»å­¦å›¾åƒä¸­æ£€æµ‹åƒç´ çº§å—ä¿æŠ¤å¥åº·ä¿¡æ¯çš„æ–¹æ³•|Tuan Truong, Ivo M. Baltruschat, Mark Klemens, Grit Werner, Matthias Lenga|<http://arxiv.org/pdf/2501.09552v1>|None|
|ğŸ†• å‘å¸ƒ|Scaling up self-supervised learning for improved surgical foundation models|æ‰©å¤§è‡ªç›‘ç£å­¦ä¹ ä»¥æå‡æ‰‹æœ¯åŸºç¡€æ¨¡å‹|Tim J. M. Jaspers, Ronald L. P. D. de Jong, Yiping Li, Carolus H. J. Kusters, Franciscus H. A. Bakker, Romy C. van Jaarsveld, Gino M. Kuiper, Richard van Hillegersberg .etc.|<http://arxiv.org/pdf/2501.09436v1>|<https://github.com/TimJaspers0801/SurgeNet.>|
|ğŸ†• å‘å¸ƒ|Vision-Language Models Do Not Understand Negation|è§†è§‰-è¯­è¨€æ¨¡å‹å¹¶ä¸ç†è§£å¦å®š|Kumail Alhamoud, Shaden Alshammari, Yonglong Tian, Guohao Li, Philip Torr, Yoon Kim, Marzyeh Ghassemi|<http://arxiv.org/pdf/2501.09425v1>|None|
|ğŸ†• å‘å¸ƒ|Identification of Traditional Medicinal Plant Leaves Using an effective Deep Learning model and Self-Curated Dataset|åŸºäºæœ‰æ•ˆæ·±åº¦å­¦ä¹ æ¨¡å‹å’Œè‡ªæ„å»ºæ•°æ®é›†çš„ä¼ ç»Ÿè¯ç”¨æ¤ç‰©å¶ç‰‡è¯†åˆ«|Deepjyoti Chetia, Sanjib Kr Kalita, Prof Partha Pratim Baruah, Debasish Dutta, Tanaz Akhter|<http://arxiv.org/pdf/2501.09363v1>|None|
|ğŸ†• å‘å¸ƒ|Making Your Dreams A Reality: Decoding the Dreams into a Coherent Video Story from fMRI Signals|å°†æ¢¦å¢ƒè§£ç ä¸ºè¿è´¯è§†é¢‘æ•…äº‹ï¼šä»fMRIä¿¡å·ä¸­å®ç°æ¢¦æƒ³|Yanwei Fu, Jianxiong Gao, Baofeng Yang, Jianfeng Feng|<http://arxiv.org/pdf/2501.09350v1>|None|
|ğŸ†• å‘å¸ƒ|Domain-conditioned and Temporal-guided Diffusion Modeling for Accelerated Dynamic MRI Reconstruction|åŸºäºåŸŸæ¡ä»¶å’Œæ—¶é—´å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹åŠ é€ŸåŠ¨æ€MRIé‡å»º|Liping Zhang, Iris Yuwen Zhou, Sydney B. Montesi, Li Feng, Fang Liu|<http://arxiv.org/pdf/2501.09305v1>|None|
|ğŸ†• å‘å¸ƒ|Efficient Few-Shot Medical Image Analysis via Hierarchical Contrastive Vision-Language Learning|é«˜æ•ˆåˆ†å±‚å¯¹æ¯”è§†è§‰-è¯­è¨€å­¦ä¹ åœ¨å°‘é‡æ ·æœ¬åŒ»å­¦å›¾åƒåˆ†æä¸­çš„åº”ç”¨|Harrison Fuller, Fernando Gabriela Garcia, Victor Flores|<http://arxiv.org/pdf/2501.09294v1>|None|
|ğŸ†• å‘å¸ƒ|Leveraging Scale-aware Representations for improved Concept-Representation Alignment in ViTs|åˆ©ç”¨å°ºåº¦æ„ŸçŸ¥è¡¨ç¤ºä»¥æå‡ViTsä¸­çš„æ¦‚å¿µ-è¡¨ç¤ºå¯¹é½|Sanchit Sinha, Guangzhi Xiong, Aidong Zhang|<http://arxiv.org/pdf/2501.09221v1>|None|
|ğŸ“ æ›´æ–°|PhysMamba: State Space Duality Model for Remote Physiological Measurement|PhysMambaï¼šè¿œç¨‹ç”Ÿç†æµ‹é‡çŠ¶æ€ç©ºé—´å¯¹å¶æ¨¡å‹|Zhixin Yan, Yan Zhong, Hongbin Xu, Wenjun Zhang, Shangru Yi, Lin Shu, Wenxiong Kang|<http://arxiv.org/pdf/2408.01077v3>|None|
|ğŸ“ æ›´æ–°|Enhanced Masked Image Modeling to Avoid Model Collapse on Multi-modal MRI Datasets|å¢å¼ºæ©ç å›¾åƒå»ºæ¨¡ä»¥é¿å…å¤šæ¨¡æ€MRIæ•°æ®é›†ä¸Šçš„æ¨¡å‹å´©æºƒ|Linxuan Han, Sa Xiao, Zimeng Li, Haidong Li, Xiuchao Zhao, Yeqing Han, Fumin Guo, Xin Zhou|<http://arxiv.org/pdf/2407.10377v4>|<https://github.com/LinxuanHan/E-MIM.>|
|ğŸ“ æ›´æ–°|CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting Universal Machine Learning for Accelerated Cardiac MRI|CMRxRecon2024ï¼šä¸€ç§å¤šæ¨¡æ€ã€å¤šè§†è§’Kç©ºé—´æ•°æ®é›†ï¼Œä»¥ä¿ƒè¿›åŠ é€Ÿå¿ƒè„MRIçš„é€šç”¨æœºå™¨å­¦ä¹ |Zi Wang, Fanwen Wang, Chen Qin, Jun Lyu, Cheng Ouyang, Shuo Wang, Yan Li, Mengyao Yu .etc.|<http://arxiv.org/pdf/2406.19043v2>|None|
|ğŸ“ æ›´æ–°|A Comprehensive Survey of Foundation Models in Medicine|åŒ»å­¦é¢†åŸŸåŸºç¡€æ¨¡å‹ç»¼è¿°|Wasif Khan, Seowung Leem, Kyle B. See, Joshua K. Wong, Shaoting Zhang, Ruogu Fang|<http://arxiv.org/pdf/2406.10729v3>|None|
|ğŸ“ æ›´æ–°|Swin transformers are robust to distribution and concept drift in endoscopy-based longitudinal rectal cancer assessment|æ–¯æ¸©å˜æ¢å™¨åœ¨åŸºäºå†…çª¥é•œçš„çºµå‘ç›´è‚ ç™Œè¯„ä¼°ä¸­å¯¹åˆ†å¸ƒå’Œæ¦‚å¿µæ¼‚ç§»å…·æœ‰é²æ£’æ€§|Jorge Tapias Gomez, Aneesh Rangnekar, Hannah Williams, Hannah Thompson, Julio Garcia-Aguilar, Joshua Jesse Smith, Harini Veeraraghavan|<http://arxiv.org/pdf/2405.03762v3>|None|
|ğŸ“ æ›´æ–°|VIS-MAE: An Efficient Self-supervised Learning Approach on Medical Image Segmentation and Classification|VIS-MAEï¼šä¸€ç§é«˜æ•ˆçš„åŒ»å­¦å›¾åƒåˆ†å‰²å’Œåˆ†ç±»çš„è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•|Zelong Liu, Andrew Tieu, Nikhil Patel, Georgios Soultanidis, Louisa Deyer, Ying Wang, Sean Huver, Alexander Zhou .etc.|<http://arxiv.org/pdf/2402.01034v2>|<https://github.com/lzl199704/VIS-MAE.>|

