## [UPDATED!] **2025-02-13** (Update Time)


## å›¾åƒç†è§£

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|EmoAssist: Emotional Assistant for Visual Impairment Community|æƒ…æ„ŸåŠ©æ‰‹ï¼šè§†è§‰éšœç¢ç¤¾åŒºçš„æƒ…æ„Ÿè¾…åŠ©|Xingyu Qi, He Li, Linjie Li, Zhenyu Wu|<http://arxiv.org/pdf/2502.09285v1>|None|
|ğŸ†• å‘å¸ƒ|Visual Graph Question Answering with ASP and LLMs for Language Parsing|åŸºäºASPå’ŒLLMsçš„è§†è§‰å›¾é—®ç­”ä¸è¯­è¨€è§£æ|Jakob Johannes Bauer, Thomas Eiter, Nelson Higuera Ruiz, Johannes Oetsch|<http://arxiv.org/pdf/2502.09211v1>|None|
|ğŸ†• å‘å¸ƒ|Feature-based Graph Attention Networks Improve Online Continual Learning|åŸºäºç‰¹å¾çš„å›¾æ³¨æ„åŠ›ç½‘ç»œæå‡åœ¨çº¿æŒç»­å­¦ä¹ |Adjovi Sim, Zhengkui Wang, Aik Beng Ng, Shalini De Mello, Simon See, Wonmin Byeon|<http://arxiv.org/pdf/2502.09143v1>|None|
|ğŸ†• å‘å¸ƒ|Improving Deep Regression with Tightness|æå‡æ·±åº¦å›å½’çš„ç´§å¯†åº¦|Shihao Zhang, Yuguang Yan, Angela Yao|<http://arxiv.org/pdf/2502.09122v1>|<https://github.com/needylove/Regression_tightness.>|
|ğŸ†• å‘å¸ƒ|EventSTR: A Benchmark Dataset and Baselines for Event Stream based Scene Text Recognition|äº‹ä»¶æµåœºæ™¯æ–‡æœ¬è¯†åˆ«åŸºå‡†æ•°æ®é›†å’ŒåŸºçº¿ï¼šEventSTR|Xiao Wang, Jingtao Jiang, Dong Li, Futian Wang, Lin Zhu, Yaowei Wang, Yongyong Tian, Jin Tang|<http://arxiv.org/pdf/2502.09020v1>|<https://github.com/Event-AHU/EventSTR>|
|ğŸ†• å‘å¸ƒ|Towards Understanding Why Data Augmentation Improves Generalization|è¿ˆå‘ç†è§£æ•°æ®å¢å¼ºå¦‚ä½•æå‡æ³›åŒ–èƒ½åŠ›|Jingyang Li, Jiachun Pan, Kim-Chuan Toh, Pan Zhou|<http://arxiv.org/pdf/2502.08940v1>|None|
|ğŸ†• å‘å¸ƒ|ShapeLib: designing a library of procedural 3D shape abstractions with Large Language Models|ShapeLibï¼šåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è®¾è®¡ç¨‹åºåŒ–3Då½¢çŠ¶æŠ½è±¡åº“|R. Kenny Jones, Paul Guerrero, Niloy J. Mitra, Daniel Ritchie|<http://arxiv.org/pdf/2502.08884v1>|None|
|ğŸ“ æ›´æ–°|PulseCheck457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models|è„‰ææ£€æŸ¥457ï¼šå¤§å‹å¤šæ¨¡æ€æ¨¡å‹6Dç©ºé—´æ¨ç†çš„è¯Šæ–­åŸºå‡†|Xingrui Wang, Wufei Ma, Tiezheng Zhang, Celso M de Melo, Jieneng Chen, Alan Yuille|<http://arxiv.org/pdf/2502.08636v2>|None|
|ğŸ“ æ›´æ–°|Enhance-A-Video: Better Generated Video for Free|å¢å¼ºè§†é¢‘ï¼šå…è´¹è·å¾—æ›´å¥½çš„ç”Ÿæˆè§†é¢‘|Yang Luo, Xuanlei Zhao, Mengzhao Chen, Kaipeng Zhang, Wenqi Shao, Kai Wang, Zhangyang Wang, Yang You|<http://arxiv.org/pdf/2502.07508v2>|None|
|ğŸ“ æ›´æ–°|ArthroPhase: A Novel Dataset and Method for Phase Recognition in Arthroscopic Video|å…³èŠ‚ç›¸è¯†åˆ«ï¼šä¸€ç§ç”¨äºå…³èŠ‚é•œè§†é¢‘ç›¸ä½è¯†åˆ«çš„æ–°æ•°æ®é›†ä¸æ–¹æ³•|Ali Bahari Malayeri, Matthias Seibold, Nicola Cavalcanti, Jonas Hein, Sascha Jecklin, Lazaros Vlachopoulos, Sandro Fucentese, Sandro Hodel .etc.|<http://arxiv.org/pdf/2502.07431v2>|None|
|ğŸ“ æ›´æ–°|LLMI3D: MLLM-based 3D Perception from a Single 2D Image|LLMI3Dï¼šåŸºäºå¤šè¯­è¨€è¯­è¨€æ¨¡å‹çš„å•å¼ 2Då›¾åƒ3Dæ„ŸçŸ¥|Fan Yang, Sicheng Zhao, Yanhao Zhang, Hui Chen, Haonan Lu, Jungong Han, Guiguang Ding|<http://arxiv.org/pdf/2408.07422v2>|None|
|ğŸ“ æ›´æ–°|OpenVid-1M: A Large-Scale High-Quality Dataset for Text-to-video Generation|OpenVid-1Mï¼šç”¨äºæ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆçš„è¶…å¤§è§„æ¨¡é«˜è´¨é‡æ•°æ®é›†|Kepan Nan, Rui Xie, Penghao Zhou, Tiehan Fan, Zhenheng Yang, Zhijie Chen, Xiang Li, Jian Yang .etc.|<http://arxiv.org/pdf/2407.02371v3>|None|
|ğŸ“ æ›´æ–°|Explaining Explainability: Recommendations for Effective Use of Concept Activation Vectors|è§£é‡Šå¯è§£é‡Šæ€§ï¼šæ¦‚å¿µæ¿€æ´»å‘é‡çš„æœ‰æ•ˆä½¿ç”¨å»ºè®®|Angus Nicolson, Lisa Schut, J. Alison Noble, Yarin Gal|<http://arxiv.org/pdf/2404.03713v2>|None|
|ğŸ“ æ›´æ–°|Image and Point-cloud Classification for Jet Analysis in High-Energy Physics: A survey|å›¾åƒå’Œç‚¹äº‘åˆ†ç±»åœ¨é«˜èƒ½ç‰©ç†ä¸­åˆ†æå–·æ³¨ï¼šç»¼è¿°|Hamza Kheddar, Yassine Himeur, Abbes Amira, Rachik Soualah|<http://arxiv.org/pdf/2403.11934v3>|None|
|ğŸ“ æ›´æ–°|Grid Jigsaw Representation with CLIP: A New Perspective on Image Clustering|åŸºäºCLIPçš„ç½‘æ ¼æ‹¼å›¾è¡¨ç¤ºï¼šå›¾åƒèšç±»çš„æ–°è§†è§’|Zijie Song, Zhenzhen Hu, Richang Hong|<http://arxiv.org/pdf/2310.17869v2>|None|
|ğŸ“ æ›´æ–°|ColorSense: A Study on Color Vision in Machine Visual Recognition|è‰²å½©æ„ŸçŸ¥ï¼šæœºå™¨è§†è§‰è¯†åˆ«ä¸­çš„è‰²å½©è§†è§‰ç ”ç©¶|Ming-Chang Chiu, Yingfei Wang, Derrick Eui Gyu Kim, Pin-Yu Chen, Xuezhe Ma|<http://arxiv.org/pdf/2212.08650v3>|None|


## æ£€æµ‹åˆ†å‰²

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Instance Segmentation of Scene Sketches Using Natural Image Priors|åŸºäºè‡ªç„¶å›¾åƒå…ˆéªŒçš„åœºæ™¯è‰å›¾å®ä¾‹åˆ†å‰²|Mia Tang, Yael Vinker, Chuan Yan, Lvmin Zhang, Maneesh Agrawala|<http://arxiv.org/pdf/2502.09608v1>|<https://sketchseg.github.io/sketch-seg>|
|ğŸ†• å‘å¸ƒ|SQ-GAN: Semantic Image Communications Using Masked Vector Quantization|SQ-GANï¼šåŸºäºæ©ç å‘é‡é‡åŒ–çš„è¯­ä¹‰å›¾åƒé€šä¿¡|Francesco Pezone, Sergio Barbarossa, Giuseppe Caire|<http://arxiv.org/pdf/2502.09520v1>|None|
|ğŸ†• å‘å¸ƒ|DiffRenderGAN: Addressing Training Data Scarcity in Deep Segmentation Networks for Quantitative Nanomaterial Analysis through Differentiable Rendering and Generative Modelling|DiffRenderGANï¼šé€šè¿‡å¯å¾®æ¸²æŸ“å’Œç”Ÿæˆå»ºæ¨¡è§£å†³æ·±åº¦åˆ†å‰²ç½‘ç»œåœ¨å®šé‡çº³ç±³ææ–™åˆ†æä¸­è®­ç»ƒæ•°æ®ç¨€ç¼ºé—®é¢˜|Dennis Possart, Leonid Mill, Florian Vollnhals, Tor Hildebrand, Peter Suter, Mathis Hoffmann, Jonas Utz, Daniel Augsburger .etc.|<http://arxiv.org/pdf/2502.09477v1>|None|
|ğŸ†• å‘å¸ƒ|Wholly-WOOD: Wholly Leveraging Diversified-quality Labels for Weakly-supervised Oriented Object Detection|å…¨æœ¨ï¼ˆWholly-WOODï¼‰ï¼šå…¨é¢åˆ©ç”¨å¤šæ ·åŒ–è´¨é‡æ ‡ç­¾è¿›è¡Œå¼±ç›‘ç£æ–¹å‘æ€§ç›®æ ‡æ£€æµ‹|Yi Yu, Xue Yang, Yansheng Li, Zhenjun Han, Feipeng Da, Junchi Yan|<http://arxiv.org/pdf/2502.09471v1>|<https://github.com/VisionXLab/whollywood>|
|ğŸ†• å‘å¸ƒ|Mitigating the Impact of Prominent Position Shift in Drone-based RGBT Object Detection|å‡è½»æ— äººæœºåŸºäºRGBTç›®æ ‡æ£€æµ‹ä¸­æ˜¾è‘—ä½ç½®åç§»çš„å½±å“|Yan Zhang, Wen Yang, Chang Xu, Qian Hu, Fang Xu, Gui-Song Xia|<http://arxiv.org/pdf/2502.09311v1>|None|
|ğŸ†• å‘å¸ƒ|FLARES: Fast and Accurate LiDAR Multi-Range Semantic Segmentation|FLARESï¼šå¿«é€Ÿä¸”ç²¾ç¡®çš„æ¿€å…‰é›·è¾¾å¤šè·ç¦»è¯­ä¹‰åˆ†å‰²|Bin Yang, Alexandru Paul Condurache|<http://arxiv.org/pdf/2502.09274v1>|None|
|ğŸ†• å‘å¸ƒ|Pulling Back the Curtain: Unsupervised Adversarial Detection via Contrastive Auxiliary Networks|æ­å¼€é¢çº±ï¼šé€šè¿‡å¯¹æ¯”è¾…åŠ©ç½‘ç»œçš„æ— ç›‘ç£å¯¹æŠ—æ£€æµ‹|Eylon Mizrahi, Raz Lapid, Moshe Sipper|<http://arxiv.org/pdf/2502.09110v1>|None|
|ğŸ†• å‘å¸ƒ|Billet Number Recognition Based on Test-Time Adaptation|åŸºäºæµ‹è¯•æ—¶è‡ªé€‚åº”çš„ç¥¨æ®ç¼–å·è¯†åˆ«|Yuan Wei, Xiuzhuang Zhou|<http://arxiv.org/pdf/2502.09026v1>|None|
|ğŸ“ æ›´æ–°|MultiFloodSynth: Multi-Annotated Flood Synthetic Dataset Generation|å¤šæ ‡æ³¨æ´ªæ°´åˆæˆæ•°æ®é›†ç”Ÿæˆï¼šMultiFloodSynth|YoonJe Kang, Yonghoon Jung, Wonseop Shin, Bumsoo Kim, Sanghyun Seo|<http://arxiv.org/pdf/2502.03966v3>|None|
|ğŸ“ æ›´æ–°|Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding of Images and Videos|Sa2VAï¼šå°†SAM2ä¸LLaVAç»“åˆä»¥å®ç°å›¾åƒå’Œè§†é¢‘çš„å¯†é›†åŒ–æœ‰æ ¹ç†è§£|Haobo Yuan, Xiangtai Li, Tao Zhang, Zilong Huang, Shilin Xu, Shunping Ji, Yunhai Tong, Lu Qi .etc.|<http://arxiv.org/pdf/2501.04001v2>|None|
|ğŸ“ æ›´æ–°|NBM: an Open Dataset for the Acoustic Monitoring of Nocturnal Migratory Birds in Europe|æ¬§æ´²å¤œé—´è¿å¾™é¸Ÿç±»å£°å­¦ç›‘æµ‹çš„å¼€æºæ•°æ®é›†ï¼šNBM|Louis Airale, Adrien Pajot, Juliette Linossier|<http://arxiv.org/pdf/2412.03633v3>|None|
|ğŸ“ æ›´æ–°|Heuristical Comparison of Vision Transformers Against Convolutional Neural Networks for Semantic Segmentation on Remote Sensing Imagery|åŸºäºé¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²çš„è§†è§‰Transformerä¸å·ç§¯ç¥ç»ç½‘ç»œçš„ç»éªŒæ€§æ¯”è¾ƒ|Ashim Dahal, Saydul Akbar Murad, Nick Rahimi|<http://arxiv.org/pdf/2411.09101v2>|<https://github.com/ashimdahal/ViT-vs-CNN-Image-Segmentation.>|
|ğŸ“ æ›´æ–°|Locate Anything on Earth: Advancing Open-Vocabulary Object Detection for Remote Sensing Community|åœ°çƒä¸Šä»»ä½•äº‹ç‰©çš„å®šä½ï¼šæ¨è¿›é¥æ„Ÿé¢†åŸŸçš„å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹|Jiancheng Pan, Yanxing Liu, Yuqian Fu, Muyuan Ma, Jiahao Li, Danda Pani Paudel, Luc Van Gool, Xiaomeng Huang|<http://arxiv.org/pdf/2408.09110v2>|None|
|ğŸ“ æ›´æ–°|Open-YOLO 3D: Towards Fast and Accurate Open-Vocabulary 3D Instance Segmentation|å¼€æ”¾YOLO 3Dï¼šè¿ˆå‘å¿«é€Ÿä¸”å‡†ç¡®çš„å¼€æ”¾è¯æ±‡3Då®ä¾‹åˆ†å‰²|Mohamed El Amine Boudjoghra, Angela Dai, Jean Lahoud, Hisham Cholakkal, Rao Muhammad Anwer, Salman Khan, Fahad Shahbaz Khan|<http://arxiv.org/pdf/2406.02548v3>|<https://github.com/aminebdj/OpenYOLO3D.>|
|ğŸ“ æ›´æ–°|On the Importance of Backbone to the Adversarial Robustness of Object Detectors|å…³äºéª¨å¹²ç½‘ç»œå¯¹ç›®æ ‡æ£€æµ‹å™¨å¯¹æŠ—é²æ£’æ€§çš„é‡è¦æ€§|Xiao Li, Hang Chen, Xiaolin Hu|<http://arxiv.org/pdf/2305.17438v2>|<https://github.com/thu-ml/oddefense.>|
|ğŸ“ æ›´æ–°|MonoDETR: Depth-guided Transformer for Monocular 3D Object Detection|å•ç›®3Dç›®æ ‡æ£€æµ‹çš„æ·±åº¦å¼•å¯¼Transformer|Renrui Zhang, Han Qiu, Tai Wang, Ziyu Guo, Yiwen Tang, Xuanzhuo Xu, Ziteng Cui, Yu Qiao .etc.|<http://arxiv.org/pdf/2203.13310v5>|<https://github.com/ZrrSkywalker/MonoDETR.>|


## è§†é¢‘ç†è§£

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|GAIA: A Global, Multi-modal, Multi-scale Vision-Language Dataset for Remote Sensing Image Analysis|GAIAï¼šä¸€ä¸ªç”¨äºé¥æ„Ÿå›¾åƒåˆ†æçš„å…¨çƒã€å¤šæ¨¡æ€ã€å¤šå°ºåº¦è§†è§‰-è¯­è¨€æ•°æ®é›†|Angelos Zavras, Dimitrios Michail, Xiao Xiang Zhu, BegÃ¼m Demir, Ioannis Papoutsis|<http://arxiv.org/pdf/2502.09598v1>|None|
|ğŸ†• å‘å¸ƒ|Optimizing GPT for Video Understanding: Zero-Shot Performance and Prompt Engineering|ä¼˜åŒ–GPTä»¥å®ç°è§†é¢‘ç†è§£ï¼šé›¶æ ·æœ¬æ€§èƒ½ä¸æç¤ºå·¥ç¨‹|Mark Beliaev, Victor Yang, Madhura Raju, Jiachen Sun, Xinghai Hu|<http://arxiv.org/pdf/2502.09573v1>|None|
|ğŸ†• å‘å¸ƒ|Faster than real-time detection of shot boundaries, sampling structure and dynamic keyframes in video|è§†é¢‘ä¸­çš„å®æ—¶å¿«äºå®æ—¶æ£€æµ‹é•œå¤´è¾¹ç•Œã€é‡‡æ ·ç»“æ„å’ŒåŠ¨æ€å…³é”®å¸§|Hannes Fassold|<http://arxiv.org/pdf/2502.09202v1>|None|
|ğŸ“ æ›´æ–°|Moment of Untruth: Dealing with Negative Queries in Video Moment Retrieval|ç¬é—´å¤±çœŸï¼šå¤„ç†è§†é¢‘ç¬é—´æ£€ç´¢ä¸­çš„è´Ÿé¢æŸ¥è¯¢|Kevin Flanagan, Dima Damen, Michael Wray|<http://arxiv.org/pdf/2502.08544v2>|<https://github.com/keflanagan/MomentofUntruth>|
|ğŸ“ æ›´æ–°|When do they StOP?: A First Step Towards Automatically Identifying Team Communication in the Operating Room|ä½•æ—¶åœæ­¢ï¼Ÿè¿ˆå‘è‡ªåŠ¨è¯†åˆ«æ‰‹æœ¯å®¤å›¢é˜Ÿæ²Ÿé€šçš„ç¬¬ä¸€æ­¥|Keqi Chen, Lilien Schewski, Vinkle Srivastav, JoÃ«l Lavanchy, Didier Mutter, Guido Beldi, Sandra Keller, Nicolas Padoy|<http://arxiv.org/pdf/2502.08299v2>|<https://github.com/CAMMA-public/Team-OR.>|


## ç”Ÿæˆæ¨¡å‹

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|RigAnything: Template-Free Autoregressive Rigging for Diverse 3D Assets|RigAnythingï¼šé’ˆå¯¹å¤šæ ·åŒ–3Dèµ„äº§çš„å…æ¨¡æ¿è‡ªå›å½’ç»‘å®š|Isabella Liu, Zhan Xu, Wang Yifan, Hao Tan, Zexiang Xu, Xiaolong Wang, Hao Su, Zifan Shi|<http://arxiv.org/pdf/2502.09615v1>|None|
|ğŸ†• å‘å¸ƒ|Designing a Conditional Prior Distribution for Flow-Based Generative Models|è®¾è®¡åŸºäºæµç”Ÿæˆæ¨¡å‹çš„æ¡ä»¶å…ˆéªŒåˆ†å¸ƒ|Noam Issachar, Mohammad Salama, Raanan Fattal, Sagie Benaim|<http://arxiv.org/pdf/2502.09611v1>|None|
|ğŸ†• å‘å¸ƒ|Long-Term TalkingFace Generation via Motion-Prior Conditional Diffusion Model|åŸºäºè¿åŠ¨å…ˆéªŒçš„æ¡ä»¶æ‰©æ•£æ¨¡å‹è¿›è¡Œé•¿æœŸ TalkingFace ç”Ÿæˆ|Fei Shen, Cong Wang, Junyao Gao, Qin Guo, Jisheng Dang, Jinhui Tang, Tat-Seng Chua|<http://arxiv.org/pdf/2502.09533v1>|None|
|ğŸ†• å‘å¸ƒ|Redistribute Ensemble Training for Mitigating Memorization in Diffusion Models|é‡æ–°åˆ†é…é›†æˆè®­ç»ƒä»¥å‡è½»æ‰©æ•£æ¨¡å‹ä¸­çš„è®°å¿†åŒ–|Xiaoliu Guan, Yu Wu, Huayang Huang, Xiao Liu, Jiaxu Miao, Yi Yang|<http://arxiv.org/pdf/2502.09434v1>|<https://github.com/liuxiao-guan/IET_AGC.>|
|ğŸ†• å‘å¸ƒ|ImageRAG: Dynamic Image Retrieval for Reference-Guided Image Generation|å›¾åƒRAGï¼šåŸºäºå‚è€ƒå¼•å¯¼çš„åŠ¨æ€å›¾åƒæ£€ç´¢|Rotem Shalev-Arkushin, Rinon Gal, Amit H. Bermano, Ohad Fried|<http://arxiv.org/pdf/2502.09411v1>|<https://rotem-shalev.github.io/ImageRAG>|
|ğŸ†• å‘å¸ƒ|E-MD3C: Taming Masked Diffusion Transformers for Efficient Zero-Shot Object Customization|E-MD3Cï¼šé©¯æœæ©ç æ‰©æ•£Transformerä»¥å®ç°é«˜æ•ˆçš„é›¶æ ·æœ¬å¯¹è±¡å®šåˆ¶|Trung X. Pham, Zhang Kang, Ji Woo Hong, Xuran Zheng, Chang D. Yoo|<http://arxiv.org/pdf/2502.09164v1>|None|
|ğŸ†• å‘å¸ƒ|StyleBlend: Enhancing Style-Specific Content Creation in Text-to-Image Diffusion Models|é£æ ¼èåˆï¼šæå‡æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­çš„é£æ ¼ç‰¹å®šå†…å®¹åˆ›ä½œ|Zichong Chen, Shijin Wang, Yang Zhou|<http://arxiv.org/pdf/2502.09064v1>|None|
|ğŸ†• å‘å¸ƒ|Detecting Malicious Concepts Without Image Generation in AIGC|åœ¨AIGCä¸­æ— éœ€å›¾åƒç”Ÿæˆæ£€æµ‹æ¶æ„æ¦‚å¿µ|Kun Xu, Yushu Zhang, Shuren Qi, Tao Wang, Wenying Wen, Yuming Fang|<http://arxiv.org/pdf/2502.08921v1>|None|
|ğŸ“ æ›´æ–°|OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models|å…¨äººç±»-1ï¼šé‡æ–°æ€è€ƒå•é˜¶æ®µæ¡ä»¶äººç±»åŠ¨ç”»æ¨¡å‹çš„æ‰©å±•|Gaojie Lin, Jianwen Jiang, Jiaqi Yang, Zerong Zheng, Chao Liang|<http://arxiv.org/pdf/2502.01061v2>|None|
|ğŸ“ æ›´æ–°|VIIS: Visible and Infrared Information Synthesis for Severe Low-light Image Enhancement|å¯è§å…‰ä¸çº¢å¤–ä¿¡æ¯èåˆç”¨äºæ¶åŠ£ä½å…‰ç…§å›¾åƒå¢å¼ºï¼šVIIS|Chen Zhao, Mengyuan Yu, Fan Yang, Peiguang Jing|<http://arxiv.org/pdf/2412.13655v2>|<https://github.com/Chenz418/VIIS.>|
|ğŸ“ æ›´æ–°|Vision-LLMs Can Fool Themselves with Self-Generated Typographic Attacks|è§†è§‰LLMså¯é€šè¿‡è‡ªç”Ÿæˆå°åˆ·æ”»å‡»æ¬ºéª—è‡ªå·±|Maan Qraitem, Nazia Tasnim, Piotr Teterwak, Kate Saenko, Bryan A. Plummer|<http://arxiv.org/pdf/2402.00626v3>|<https://github.com/mqraitem/Self-Gen-Typo-Attack>|


## æ‰©æ•£æ¡¥

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|MRS: A Fast Sampler for Mean Reverting Diffusion based on ODE and SDE Solvers|MRSï¼šåŸºäºå¸¸å¾®åˆ†æ–¹ç¨‹å’Œéšæœºå¾®åˆ†æ–¹ç¨‹æ±‚è§£å™¨çš„å¿«é€Ÿå‡å€¼å›å½’æ‰©æ•£é‡‡æ ·å™¨|Ao Li, Wei Fang, Hongbo Zhao, Le Lu, Ge Yang, Minfeng Xu|<http://arxiv.org/pdf/2502.07856v2>|None|
|ğŸ“ æ›´æ–°|ADBM: Adversarial diffusion bridge model for reliable adversarial purification|å¯¹æŠ—æ‰©æ•£æ¡¥æ¨¡å‹ï¼šç”¨äºå¯é å¯¹æŠ—å‡€åŒ–çš„å¯¹æŠ—æ‰©æ•£æ¡¥æ¨¡å‹|Xiao Li, Wenxuan Sun, Huanran Chen, Qiongxiu Li, Yining Liu, Yingzhe He, Jie Shi, Xiaolin Hu|<http://arxiv.org/pdf/2408.00315v3>|None|


## æµæ¨¡å‹

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Variational Rectified Flow Matching|å˜åˆ†ä¿®æ­£æµåŒ¹é…|Pengsheng Guo, Alexander G. Schwing|<http://arxiv.org/pdf/2502.09616v1>|None|


## å›¾åƒå¤„ç†

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SteROI-D: System Design and Mapping for Stereo Depth Inference on Regions of Interest|ç«‹ä½“ROI-Dï¼šç³»ç»Ÿè®¾è®¡ä¸åŒºåŸŸå…´è¶£ç‚¹ä¸Šçš„ç«‹ä½“æ·±åº¦æ¨ç†æ˜ å°„|Jack Erhardt, Ziang Li, Reid Pinkham, Andrew Berkovich, Zhengya Zhang|<http://arxiv.org/pdf/2502.09528v1>|None|
|ğŸ†• å‘å¸ƒ|Vision-Language In-Context Learning Driven Few-Shot Visual Inspection Model|åŸºäºä¸Šä¸‹æ–‡è§†è§‰-è¯­è¨€å­¦ä¹ çš„å°‘æ ·æœ¬è§†è§‰æ£€æµ‹æ¨¡å‹|Shiryu Ueno, Yoshikazu Hayashi, Shunsuke Nakatsuka, Yusei Yamada, Hiroaki Aizawa, Kunihito Kato|<http://arxiv.org/pdf/2502.09057v1>|<https://github.com/ia-gu/Vision-Language-In-Context-Learning-Driven-Few-Shot-Visual-Inspection-Model.>|
|ğŸ†• å‘å¸ƒ|Residual Transformer Fusion Network for Salt and Pepper Image Denoising|æ®‹å·®å˜æ¢èåˆç½‘ç»œç”¨äºæ¤’ç›å™ªå£°å›¾åƒå»å™ª|Bintang Pradana Erlangga Putra, Heri Prasetyo, Esti Suryani|<http://arxiv.org/pdf/2502.09000v1>|None|
|ğŸ†• å‘å¸ƒ|On the Promise for Assurance of Differentiable Neurosymbolic Reasoning Paradigms|å…³äºå¯å¾®åˆ†ç¥ç»ç¬¦å·æ¨ç†èŒƒå¼çš„ä¿è¯å‰æ™¯|Luke E. Richards, Jessie Yaros, Jasen Babcock, Coung Ly, Robin Cosbey, Timothy Doster, Cynthia Matuszek|<http://arxiv.org/pdf/2502.08932v1>|None|
|ğŸ†• å‘å¸ƒ|Dynamic watermarks in images generated by diffusion models|åŠ¨æ€æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„å›¾åƒä¸­çš„æ°´å°|Yunzhuo Chen, Naveed Akhtar, Nur Al Hasan Haldar, Ajmal Mian|<http://arxiv.org/pdf/2502.08927v1>|None|
|ğŸ“ æ›´æ–°|Enhanced Feature-based Image Stitching for Endoscopic Videos in Pediatric Eosinophilic Esophagitis|å¢å¼ºç‰¹å¾å›¾åƒæ‹¼æ¥æŠ€æœ¯åœ¨å„¿ç§‘å—œé…¸æ€§é£Ÿç®¡ç‚å†…çª¥é•œè§†é¢‘ä¸­çš„åº”ç”¨|Juming Xiong, Muyang Li, Ruining Deng, Tianyuan Yao, Shunxing Bao, Regina N Tyree, Girish Hiremath, Yuankai Huo|<http://arxiv.org/pdf/2502.04207v2>|None|
|ğŸ“ æ›´æ–°|DM-Mamba: Dual-domain Multi-scale Mamba for MRI reconstruction|DM-Mambaï¼šåŒåŸŸå¤šå°ºåº¦Mambaç”¨äºMRIé‡å»º|Yucong Meng, Zhiwei Yang, Zhijian Song, Yonghong Shi|<http://arxiv.org/pdf/2501.08163v2>|<https://github.com/XiaoMengLiLiLi/DM-Mamba.>|
|ğŸ“ æ›´æ–°|Fully Unsupervised Dynamic MRI Reconstruction via Diffeo-Temporal Equivariance|å®Œå…¨æ— ç›‘ç£çš„åŠ¨æ€MRIé‡å»ºï¼šåŸºäºå¾®åˆ†æ—¶æ€ç­‰å˜æ€§|Andrew Wang, Mike Davies|<http://arxiv.org/pdf/2410.08646v2>|<https://github.com/Andrewwango/ddei.>|
|ğŸ“ æ›´æ–°|Dream-in-Style: Text-to-3D Generation Using Stylized Score Distillation|æ¢¦ä¹‹é£æ ¼ï¼šä½¿ç”¨é£æ ¼åŒ–å¾—åˆ†è’¸é¦çš„æ–‡æœ¬åˆ°3Dç”Ÿæˆ|Hubert Kompanowski, Binh-Son Hua|<http://arxiv.org/pdf/2406.18581v2>|None|
|ğŸ“ æ›´æ–°|A Cognitive Evaluation Benchmark of Image Reasoning and Description for Large Vision-Language Models|å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹å›¾åƒæ¨ç†ä¸æè¿°çš„è®¤çŸ¥è¯„ä¼°åŸºå‡†|Xiujie Song, Mengyue Wu, Kenny Q. Zhu, Chunhao Zhang, Yanyi Chen|<http://arxiv.org/pdf/2402.18409v4>|None|
|ğŸ“ æ›´æ–°|For Better or For Worse? Learning Minimum Variance Features With Label Augmentation|å¥½åå‚åŠï¼Ÿé€šè¿‡æ ‡ç­¾å¢å¼ºå­¦ä¹ æœ€å°æ–¹å·®ç‰¹å¾|Muthu Chidambaram, Rong Ge|<http://arxiv.org/pdf/2402.06855v3>|None|


## ç¥ç»æ¸²æŸ“

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Embed Any NeRF: Graph Meta-Networks for Neural Tasks on Arbitrary NeRF Architectures|åµŒå…¥ä»»æ„NeRFï¼šä»»æ„NeRFæ¶æ„ä¸Šçš„å›¾å…ƒç½‘ç»œç”¨äºç¥ç»ä»»åŠ¡|Francesco Ballerini, Pierluigi Zama Ramirez, Samuele Salti, Luigi Di Stefano|<http://arxiv.org/pdf/2502.09623v1>|None|
|ğŸ†• å‘å¸ƒ|Latent Radiance Fields with 3D-aware 2D Representations|æ½œåœ¨è¾å°„åœºä¸3Dæ„ŸçŸ¥2Dè¡¨ç¤º|Chaoyi Zhou, Xi Liu, Feng Luo, Siyu Huang|<http://arxiv.org/pdf/2502.09613v1>|None|
|ğŸ†• å‘å¸ƒ|Wasserstein distributional adversarial training for deep neural networks|Wassersteinåˆ†å¸ƒå¯¹æŠ—è®­ç»ƒç”¨äºæ·±åº¦ç¥ç»ç½‘ç»œ|Xingjian Bai, Guangyi He, Yifan Jiang, Jan Obloj|<http://arxiv.org/pdf/2502.09352v1>|None|
|ğŸ†• å‘å¸ƒ|FE-LWS: Refined Image-Text Representations via Decoder Stacking and Fused Encodings for Remote Sensing Image Captioning|FE-LWSï¼šé€šè¿‡è§£ç å™¨å †å å’Œèåˆç¼–ç ä¼˜åŒ–é¥æ„Ÿå›¾åƒå­—å¹•çš„å›¾åƒ-æ–‡æœ¬è¡¨ç¤º|Swadhin Das, Raksha Sharma|<http://arxiv.org/pdf/2502.09282v1>|None|
|ğŸ†• å‘å¸ƒ|Shortcut Learning Susceptibility in Vision Classifiers|è§†è§‰åˆ†ç±»å™¨ä¸­çš„æ·å¾„å­¦ä¹ æ•æ„Ÿæ€§|Pirzada Suhail, Amit Sethi|<http://arxiv.org/pdf/2502.09150v1>|None|
|ğŸ†• å‘å¸ƒ|Unsupervised Anomaly Detection on Implicit Shape representations for Sarcopenia Detection|æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹åœ¨éšå¼å½¢çŠ¶è¡¨ç¤ºä¸­ç”¨äºè‚Œè‚‰å‡å°‘ç—‡æ£€æµ‹|Louise Piecuch, Jeremie Huet, Antoine Frouin, Antoine Nordez, Anne-Sophie Boureau, Diana Mateus|<http://arxiv.org/pdf/2502.09088v1>|None|
|ğŸ†• å‘å¸ƒ|Zero-shot Concept Bottleneck Models|é›¶æ ·æœ¬æ¦‚å¿µç“¶é¢ˆæ¨¡å‹|Shin'ya Yamaguchi, Kosuke Nishida, Daiki Chijiwa, Yasutoshi Ida|<http://arxiv.org/pdf/2502.09018v1>|<https://github.com/yshinya6/zcbm.>|
|ğŸ“ æ›´æ–°|CANeRV: Content Adaptive Neural Representation for Video Compression|CANeRVï¼šè§†é¢‘å‹ç¼©çš„å†…å®¹è‡ªé€‚åº”ç¥ç»ç½‘ç»œè¡¨ç¤º|Lv Tang, Jun Zhu, Xinfeng Zhang, Li Zhang, Siwei Ma, Qingming Huang|<http://arxiv.org/pdf/2502.06181v2>|None|
|ğŸ“ æ›´æ–°|Learning Naturally Aggregated Appearance for Efficient 3D Editing|è‡ªç„¶èšåˆå¤–è§‚å­¦ä¹ ä»¥å®ç°é«˜æ•ˆ3Dç¼–è¾‘|Ka Leong Cheng, Qiuyu Wang, Zifan Shi, Kecheng Zheng, Yinghao Xu, Hao Ouyang, Qifeng Chen, Yujun Shen|<http://arxiv.org/pdf/2312.06657v2>|<https://felixcheng97.github.io/AGAP>|


## 3DGS

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|LIFe-GoM: Generalizable Human Rendering with Learned Iterative Feedback Over Multi-Resolution Gaussians-on-Mesh|LIFe-GoMï¼šåŸºäºå¤šåˆ†è¾¨ç‡ç½‘æ ¼ä¸Šçš„å­¦ä¹ è¿­ä»£åé¦ˆçš„é€šç”¨äººç±»æ¸²æŸ“|Jing Wen, Alexander G. Schwing, Shenlong Wang|<http://arxiv.org/pdf/2502.09617v1>|None|
|ğŸ†• å‘å¸ƒ|Self-Calibrating Gaussian Splatting for Large Field of View Reconstruction|è‡ªæ ¡å‡†é«˜æ–¯å–·æº…çš„å¤§è§†åœºé‡å»º|Youming Deng, Wenqi Xian, Guandao Yang, Leonidas Guibas, Gordon Wetzstein, Steve Marschner, Paul Debevec|<http://arxiv.org/pdf/2502.09563v1>|None|
|ğŸ†• å‘å¸ƒ|ConsistentDreamer: View-Consistent Meshes Through Balanced Multi-View Gaussian Optimization|ä¸€è‡´æ¢¦æƒ³è€…ï¼šé€šè¿‡å¹³è¡¡å¤šè§†å›¾é«˜æ–¯ä¼˜åŒ–å®ç°è§†å›¾ä¸€è‡´ç½‘æ ¼|Onat Åahin, Mohammad Altillawi, George Eskandar, Carlos Carbone, Ziyuan Liu|<http://arxiv.org/pdf/2502.09278v1>|None|
|ğŸ†• å‘å¸ƒ|DenseSplat: Densifying Gaussian Splatting SLAM with Neural Radiance Prior|å¯†é›†Splatï¼šåˆ©ç”¨ç¥ç»è¾å°„å…ˆéªŒå¢å¼ºé«˜æ–¯Splatting SLAM|Mingrui Li, Shuhong Liu, Tianchen Deng, Hongyu Wang|<http://arxiv.org/pdf/2502.09111v1>|None|
|ğŸ†• å‘å¸ƒ|BevSplat: Resolving Height Ambiguity via Feature-Based Gaussian Primitives for Weakly-Supervised Cross-View Localization|BevSplatï¼šé€šè¿‡åŸºäºç‰¹å¾çš„GaussianåŸºå…ƒè§£å†³é«˜åº¦æ¨¡ç³Šæ€§ä»¥å®ç°å¼±ç›‘ç£è·¨è§†å›¾å®šä½|Qiwei Wang, Shaoxun Wu, Yujiao Shi|<http://arxiv.org/pdf/2502.09080v1>|None|
|ğŸ†• å‘å¸ƒ|Large Images are Gaussians: High-Quality Large Image Representation with Levels of 2D Gaussian Splatting|å¤§å›¾åƒæ˜¯é«˜æ–¯åˆ†å¸ƒï¼šåŸºäºäºŒç»´é«˜æ–¯æ•£å¸ƒå±‚çº§çš„ä¼˜è´¨å¤§å›¾åƒè¡¨ç¤º|Lingting Zhu, Guying Lin, Jinnan Chen, Xinjie Zhang, Zhenchao Jin, Zhao Wang, Lequan Yu|<http://arxiv.org/pdf/2502.09039v1>|<https://github.com/HKU-MedAI/LIG>|
|ğŸ“ æ›´æ–°|4-LEGS: 4D Language Embedded Gaussian Splatting|å››è…¿ï¼šå››ç»´è¯­è¨€åµŒå…¥é«˜æ–¯åˆ†å±‚|Gal Fiebelman, Tamir Cohen, Ayellet Morgenstern, Peter Hedman, Hadar Averbuch-Elor|<http://arxiv.org/pdf/2410.10719v3>|None|
|ğŸ“ æ›´æ–°|Gaussian-Det: Learning Closed-Surface Gaussians for 3D Object Detection|é«˜æ–¯-æ£€æµ‹ï¼šå­¦ä¹ å°é—­è¡¨é¢é«˜æ–¯ç”¨äº3Dç›®æ ‡æ£€æµ‹|Hongru Yan, Yu Zheng, Yueqi Duan|<http://arxiv.org/pdf/2410.01404v2>|None|
|ğŸ“ æ›´æ–°|RenderWorld: World Model with Self-Supervised 3D Label|RenderWorldï¼šåŸºäºè‡ªç›‘ç£3Dæ ‡ç­¾çš„ä¸–ç•Œæ¨¡å‹|Ziyang Yan, Wenzhen Dong, Yihua Shao, Yuhang Lu, Liu Haiyang, Jingwen Liu, Haozhe Wang, Zhe Wang .etc.|<http://arxiv.org/pdf/2409.11356v2>|None|


## å¤šæ¨¡æ€

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for Reasoning Quality, Robustness, and Efficiency|MME-CoTï¼šè¯„ä¼°å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ä¸­æ€ç»´é“¾åœ¨æ¨ç†è´¨é‡ã€é²æ£’æ€§å’Œæ•ˆç‡æ–¹é¢çš„åŸºå‡†|Dongzhi Jiang, Renrui Zhang, Ziyu Guo, Yanwei Li, Yu Qi, Xinyan Chen, Liuhui Wang, Jianhan Jin .etc.|<http://arxiv.org/pdf/2502.09621v1>|None|
|ğŸ†• å‘å¸ƒ|Exploring the Potential of Encoder-free Architectures in 3D LMMs|æ¢ç´¢æ— ç¼–ç å™¨æ¶æ„åœ¨3D LMMsä¸­çš„æ½œåŠ›|Yiwen Tang, Zoey Guo, Zhuhao Wang, Ray Zhang, Qizhi Chen, Junli Liu, Delin Qu, Zhigang Wang .etc.|<http://arxiv.org/pdf/2502.09620v1>|<https://github.com/Ivan-Tang-3D/ENEL>|
|ğŸ†• å‘å¸ƒ|Galileo: Learning Global and Local Features in Pretrained Remote Sensing Models|ä¼½åˆ©ç•¥ï¼šåœ¨é¢„è®­ç»ƒé¥æ„Ÿæ¨¡å‹ä¸­å­¦ä¹ å…¨å±€å’Œå±€éƒ¨ç‰¹å¾|Gabriel Tseng, Anthony Fuller, Marlena Reil, Henry Herzog, Patrick Beukema, Favyen Bastani, James R. Green, Evan Shelhamer .etc.|<http://arxiv.org/pdf/2502.09356v1>|None|
|ğŸ†• å‘å¸ƒ|A Benchmark for Crime Surveillance Video Analysis with Large Models|å¤§å‹æ¨¡å‹åœ¨çŠ¯ç½ªç›‘æ§è§†é¢‘åˆ†æä¸­çš„åŸºå‡†æµ‹è¯•|Haoran Chen, Dong Yi, Moyan Cao, Chensen Huang, Guibo Zhu, Jinqiao Wang|<http://arxiv.org/pdf/2502.09325v1>|None|
|ğŸ†• å‘å¸ƒ|From Visuals to Vocabulary: Establishing Equivalence Between Image and Text Token Through Autoregressive Pre-training in MLLMs|ä»è§†è§‰åˆ°è¯æ±‡ï¼šé€šè¿‡MLLMsçš„è‡ªå›å½’é¢„è®­ç»ƒå»ºç«‹å›¾åƒå’Œæ–‡æœ¬æ ‡è®°ä¹‹é—´çš„ç­‰ä»·æ€§|Mingxiao Li, Fang Qu, Zhanpeng Chen, Na Su, Zhizhou Zhong, Ziyang Chen, Nan Du, Xiaolong Li|<http://arxiv.org/pdf/2502.09093v1>|None|
|ğŸ†• å‘å¸ƒ|Evolution of Data-driven Single- and Multi-Hazard Susceptibility Mapping and Emergence of Deep Learning Methods|æ•°æ®é©±åŠ¨å•å’Œå¤šç¾å®³æ˜“æŸæ€§æ˜ å°„çš„æ¼”å˜ä¸æ·±åº¦å­¦ä¹ æ–¹æ³•çš„å…´èµ·|Jaya Sreevalsan-Nair, Aswathi Mundayatt|<http://arxiv.org/pdf/2502.09045v1>|None|
|ğŸ†• å‘å¸ƒ|Harnessing Vision Models for Time Series Analysis: A Survey|åˆ©ç”¨è§†è§‰æ¨¡å‹è¿›è¡Œæ—¶é—´åºåˆ—åˆ†æï¼šç»¼è¿°|Jingchao Ni, Ziming Zhao, ChengAo Shen, Hanghang Tong, Dongjin Song, Wei Cheng, Dongsheng Luo, Haifeng Chen|<http://arxiv.org/pdf/2502.08869v1>|None|
|ğŸ“ æ›´æ–°|NanoVLMs: How small can we go and still make coherent Vision Language Models?|çº³ç±³VLMsï¼šæˆ‘ä»¬è¿˜èƒ½ç¼©å°åˆ°å¤šå°ï¼ŒåŒæ—¶è¿˜èƒ½æ„å»ºå‡ºè¿è´¯çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Ÿ|Mukund Agarwalla, Himanshu Kumar, Raj Dandekar, Rajat Dandekar, Sreedath Panat|<http://arxiv.org/pdf/2502.07838v2>|None|
|ğŸ“ æ›´æ–°|Evolving Symbolic 3D Visual Grounder with Weakly Supervised Reflection|æ¼”åŒ–çš„å¼±ç›‘ç£åå°„3Dè§†è§‰åŸºç¡€ç¬¦å·åŒ–|Boyu Mi, Hanqing Wang, Tai Wang, Yilun Chen, Jiangmiao Pang|<http://arxiv.org/pdf/2502.01401v2>|<https://github.com/OpenRobotLab/EaSe.>|
|ğŸ“ æ›´æ–°|SSP-IR: Semantic and Structure Priors for Diffusion-based Realistic Image Restoration|SSP-IRï¼šåŸºäºæ‰©æ•£çš„é€¼çœŸå›¾åƒæ¢å¤çš„è¯­ä¹‰å’Œç»“æ„å…ˆéªŒ|Yuhong Zhang, Hengsheng Zhang, Zhengxue Cheng, Rong Xie, Li Song, Wenjun Zhang|<http://arxiv.org/pdf/2407.03635v2>|<https://zyhrainbow.github.io/projects>|


## å…·èº«æ™ºèƒ½

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References|DexTrackï¼šä»äººç±»å‚è€ƒä¸­å®ç°é€šç”¨ç¥ç»è·Ÿè¸ªæ§åˆ¶ä»¥å®ç°çµå·§æ“ä½œ|Xueyi Liu, Jianibieke Adalibieke, Qianwei Han, Yuzhe Qin, Li Yi|<http://arxiv.org/pdf/2502.09614v1>|<https://meowuu7.github.io/DexTrack>|
|ğŸ†• å‘å¸ƒ|Diffusing DeBias: a Recipe for Turning a Bug into a Feature|æ¶ˆè§£åå·®ï¼šå°†ç¼ºé™·è½¬åŒ–ä¸ºç‰¹æ€§çš„é…æ–¹|Massimiliano Ciranni, Vito Paolo Pastore, Roberto Di Via, Enzo Tartaglione, Francesca Odone, Vittorio Murino|<http://arxiv.org/pdf/2502.09564v1>|None|
|ğŸ†• å‘å¸ƒ|EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents|å…·èº«åŸºå‡†ï¼šå…¨é¢åŸºå‡†æµ‹è¯•è§†è§‰é©±åŠ¨å…·èº«æ™ºèƒ½ä½“çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹|Rui Yang, Hanyang Chen, Junyu Zhang, Mark Zhao, Cheng Qian, Kangrui Wang, Qineng Wang, Teja Venkat Koripella .etc.|<http://arxiv.org/pdf/2502.09560v1>|None|
|ğŸ†• å‘å¸ƒ|When and How Does CLIP Enable Domain and Compositional Generalization?|ä½•æ—¶ä»¥åŠå¦‚ä½•å®ç°CLIPçš„é¢†åŸŸå’Œç»„åˆæ³›åŒ–ï¼Ÿ|Elias Kempf, Simon Schrodi, Max Argus, Thomas Brox|<http://arxiv.org/pdf/2502.09507v1>|None|
|ğŸ†• å‘å¸ƒ|Pixel-Level Reasoning Segmentation via Multi-turn Conversations|åŸºäºå¤šè½®å¯¹è¯çš„åƒç´ çº§æ¨ç†åˆ†å‰²|Dexian Cai, Xiaocui Yang, Yongkang Liu, Daling Wang, Shi Feng, Yifei Zhang, Soujanya Poria|<http://arxiv.org/pdf/2502.09447v1>|<https://github.com/ccccai239/PixelRIST.>|
|ğŸ†• å‘å¸ƒ|PTZ-Calib: Robust Pan-Tilt-Zoom Camera Calibration|PTZ-Calibï¼šé²æ£’çš„å…¨æ–¹ä½-å€¾æ–œ-å˜ç„¦ç›¸æœºæ ‡å®š|Jinhui Guo, Lubin Fan, Bojian Wu, Jiaqi Gu, Shen Cao, Jieping Ye|<http://arxiv.org/pdf/2502.09075v1>|<https://github.com/gjgjh/PTZ-Calib>|
|ğŸ†• å‘å¸ƒ|Topo2Seq: Enhanced Topology Reasoning via Topology Sequence Learning|æ‹“æ‰‘2åºåˆ—ï¼šé€šè¿‡æ‹“æ‰‘åºåˆ—å­¦ä¹ å¢å¼ºæ‹“æ‰‘æ¨ç†|Yiming Yang, Yueru Luo, Bingkun He, Erlong Li, Zhipeng Cao, Chao Zheng, Shuqi Mei, Zhen Li|<http://arxiv.org/pdf/2502.08974v1>|None|
|ğŸ†• å‘å¸ƒ|The Stochastic Parrot on LLM's Shoulder: A Summative Assessment of Physical Concept Understanding|éšæœºé¹¦é¹‰åœ¨å¤§å‹è¯­è¨€æ¨¡å‹è‚©ä¸Šï¼šç‰©ç†æ¦‚å¿µç†è§£çš„ç»¼åˆè¯„ä¼°|Mo Yu, Lemao Liu, Junjie Wu, Tsz Ting Chung, Shunchi Zhang, Jiangnan Li, Dit-Yan Yeung, Jie Zhou|<http://arxiv.org/pdf/2502.08946v1>|None|
|ğŸ†• å‘å¸ƒ|CoL3D: Collaborative Learning of Single-view Depth and Camera Intrinsics for Metric 3D Shape Recovery|CoL3Dï¼šç”¨äºåº¦é‡3Då½¢çŠ¶æ¢å¤çš„å•è§†å›¾æ·±åº¦å’Œç›¸æœºå†…å‚çš„åä½œå­¦ä¹ |Chenghao Zhang, Lubin Fan, Shen Cao, Bojian Wu, Jieping Ye|<http://arxiv.org/pdf/2502.08902v1>|None|
|ğŸ“ æ›´æ–°|What if Eye...? Computationally Recreating Vision Evolution|å¦‚æœçœ¼ç›...ï¼Ÿè®¡ç®—é‡ç°è§†è§‰è¿›åŒ–|Kushagra Tiwary, Aaron Young, Zaid Tasneem, Tzofi Klinghoffer, Akshat Dave, Tomaso Poggio, Dan-Eric Nilsson, Brian Cheung .etc.|<http://arxiv.org/pdf/2501.15001v2>|None|
|ğŸ“ æ›´æ–°|Diffusion Transformer Policy: Scaling Diffusion Transformer for Generalist Vision-Language-Action Learning|æ‰©æ•£Transformerç­–ç•¥ï¼šæ‰©å±•æ‰©æ•£Transformerä»¥å®ç°é€šç”¨è§†è§‰-è¯­è¨€-åŠ¨ä½œå­¦ä¹ |Zhi Hou, Tianyi Zhang, Yuwen Xiong, Hengjun Pu, Chengyang Zhao, Ronglei Tong, Yu Qiao, Jifeng Dai .etc.|<http://arxiv.org/pdf/2410.15959v3>|<https://zhihou7.github.io/dit_policy_vla>|
|ğŸ“ æ›´æ–°|An Overview of Prototype Formulations for Interpretable Deep Learning|æ·±åº¦å­¦ä¹ å¯è§£é‡Šæ€§åŸå‹å…¬å¼çš„æ¦‚è¿°|Maximilian Xiling Li, Korbinian Franz Rudolf, Nils Blank, Rudolf Lioutikov|<http://arxiv.org/pdf/2410.08925v3>|None|
|ğŸ“ æ›´æ–°|EventZoom: A Progressive Approach to Event-Based Data Augmentation for Enhanced Neuromorphic Vision|äº‹ä»¶æ”¾å¤§ï¼šä¸€ç§ç”¨äºå¢å¼ºç¥ç»å½¢æ€è§†è§‰çš„äº‹ä»¶æ•°æ®å¢å¼ºçš„æ¸è¿›å¼æ–¹æ³•|Yiting Dong, Xiang He, Guobin Shen, Dongcheng Zhao, Yang Li, Yi Zeng|<http://arxiv.org/pdf/2405.18880v3>|None|
|ğŸ“ æ›´æ–°|Opening Articulated Objects in the Real World|åœ¨ç°å®ä¸–ç•Œä¸­æ‰“å¼€å¯åŠ¨å¼ç‰©ä½“|Arjun Gupta, Michelle Zhang, Rishik Sathua, Saurabh Gupta|<http://arxiv.org/pdf/2402.17767v2>|<https://arjung128.github.io/opening-articulated-objects>|


## äººä½“åˆ†æ

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Metamorphic Testing for Pose Estimation Systems|å½¢æ€æµ‹è¯•ç”¨äºå§¿æ€ä¼°è®¡ç³»ç»Ÿ|Matias Duran, Thomas Laurent, Ellen Rushe, Anthony Ventresque|<http://arxiv.org/pdf/2502.09460v1>|None|
|ğŸ“ æ›´æ–°|Illegal Waste Detection in Remote Sensing Images: A Case Study|é¥æ„Ÿå›¾åƒä¸­çš„éæ³•åƒåœ¾æ£€æµ‹ï¼šä¸€ä¸ªæ¡ˆä¾‹ç ”ç©¶|Federico Gibellini, Piero Fraternali, Giacomo Boracchi, Luca Morandini, Andrea Diecidue, Simona Malegori|<http://arxiv.org/pdf/2502.06607v2>|None|
|ğŸ“ æ›´æ–°|ImDy: Human Inverse Dynamics from Imitated Observations|ImDyï¼šä»æ¨¡ä»¿è§‚å¯Ÿä¸­å­¦ä¹ çš„äººä½“é€†åŠ¨åŠ›å­¦|Xinpeng Liu, Junxuan Liang, Zili Lin, Haowen Hou, Yong-Lu Li, Cewu Lu|<http://arxiv.org/pdf/2410.17610v3>|<https://foruck.github.io/ImDy>|
|ğŸ“ æ›´æ–°|Boosting Semi-Supervised 2D Human Pose Estimation by Revisiting Data Augmentation and Consistency Training|é€šè¿‡é‡æ–°å®¡è§†æ•°æ®å¢å¼ºå’Œä¸€è‡´æ€§è®­ç»ƒæ¥æå‡åŠç›‘ç£2Däººä½“å§¿æ€ä¼°è®¡|Huayi Zhou, Mukun Luo, Fei Jiang, Yue Ding, Hongtao Lu, Kui Jia|<http://arxiv.org/pdf/2402.11566v3>|<https://github.com/hnuzhy/MultiAugs.>|
|ğŸ“ æ›´æ–°|Boosting Segment Anything Model Towards Open-Vocabulary Learning|æå‡Segment Anythingæ¨¡å‹å®ç°å¼€æ”¾è¯æ±‡å­¦ä¹ |Xumeng Han, Longhui Wei, Xuehui Yu, Zhiyang Dou, Xin He, Kuiran Wang, Yingfei Sun, Zhenjun Han .etc.|<http://arxiv.org/pdf/2312.03628v2>|None|


## äººè„¸æŠ€æœ¯

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Automatic Pruning via Structured Lasso with Class-wise Information|åŸºäºç»“æ„åŒ–Lassoçš„ç±»ä¿¡æ¯è‡ªåŠ¨å‰ªæ|Xiang Liu, Mingchen Li, Xia Li, Leigang Qu, Zifan Peng, Yijun Song, Zemin Liu, Linshan Jiang .etc.|<http://arxiv.org/pdf/2502.09125v1>|None|
|ğŸ†• å‘å¸ƒ|Text-driven 3D Human Generation via Contrastive Preference Optimization|åŸºäºå¯¹æ¯”åå¥½ä¼˜åŒ–çš„æ–‡æœ¬é©±åŠ¨3Däººä½“ç”Ÿæˆ|Pengfei Zhou, Xukun Shen, Yong Hu|<http://arxiv.org/pdf/2502.08977v1>|None|
|ğŸ“ æ›´æ–°|UEMM-Air: Make Unmanned Aerial Vehicles Perform More Multi-modal Tasks|UEMM-Airï¼šè®©æ— äººæœºæ‰§è¡Œæ›´å¤šå¤šæ¨¡æ€ä»»åŠ¡|Liang Yao, Fan Liu, Shengxiang Xu, Chuanyi Zhang, Xing Ma, Jianyu Jiang, Zequan Wang, Shimin Di .etc.|<http://arxiv.org/pdf/2406.06230v3>|<https://github.com/1e12Leon/UEMM-Air>|


## æ•°å­—äºº

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Diffusion Models Through a Global Lens: Are They Culturally Inclusive?|é€šè¿‡å…¨çƒè§†è§’çš„æ‰©æ•£æ¨¡å‹ï¼šå®ƒä»¬æ˜¯å¦å…·æœ‰æ–‡åŒ–åŒ…å®¹æ€§ï¼Ÿ|Zahra Bayramli, Ayhan Suleymanzade, Na Min An, Huzama Ahmad, Eunsu Kim, Junyeong Park, James Thorne, Alice Oh|<http://arxiv.org/pdf/2502.08914v1>|None|
|ğŸ“ æ›´æ–°|Sitcom-Crafter: A Plot-Driven Human Motion Generation System in 3D Scenes|ã€Šæƒ…æ™¯å–œå‰§åˆ›ä½œè€…ï¼š3Dåœºæ™¯ä¸­åŸºäºå‰§æƒ…çš„äººç±»åŠ¨ä½œç”Ÿæˆç³»ç»Ÿã€‹|Jianqi Chen, Panwen Hu, Xiaojun Chang, Zhenwei Shi, Michael Kampffmeyer, Xiaodan Liang|<http://arxiv.org/pdf/2410.10790v2>|<https://windvchen.github.io/Sitcom-Crafter.>|


## æ¨¡å‹ä¼˜åŒ–

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Can this Model Also Recognize Dogs? Zero-Shot Model Search from Weights|è¿™ä¸ªæ¨¡å‹ä¹Ÿèƒ½è¯†åˆ«ç‹—å—ï¼ŸåŸºäºæƒé‡çš„é›¶æ ·æœ¬æ¨¡å‹æœç´¢|Jonathan Kahana, Or Nathan, Eliahu Horwitz, Yedid Hoshen|<http://arxiv.org/pdf/2502.09619v1>|None|
|ğŸ†• å‘å¸ƒ|Prior-Constrained Association Learning for Fine-Grained Generalized Category Discovery|å…ˆå‰çº¦æŸçš„ç»†ç²’åº¦å¹¿ä¹‰ç±»åˆ«å‘ç°å…³è”å­¦ä¹ |Menglin Wang, Zhun Zhong, Xiaojin Gong|<http://arxiv.org/pdf/2502.09501v1>|None|
|ğŸ†• å‘å¸ƒ|Replay-free Online Continual Learning with Self-Supervised MultiPatches|æ— é‡æ”¾åœ¨çº¿æŒç»­å­¦ä¹ ä¸è‡ªç›‘ç£å¤šå—æ‹¼æ¥|Giacomo Cignoni, Andrea Cossu, Alex Gomez-Villa, Joost van de Weijer, Antonio Carta|<http://arxiv.org/pdf/2502.09140v1>|None|
|ğŸ†• å‘å¸ƒ|AIDE: Agentically Improve Visual Language Model with Domain Experts|AIDEï¼šåˆ©ç”¨é¢†åŸŸä¸“å®¶é€šè¿‡æ™ºèƒ½ä½“æå‡è§†è§‰è¯­è¨€æ¨¡å‹|Ming-Chang Chiu, Fuxiao Liu, Karan Sapra, Andrew Tao, Yaser Jacoob, Xuezhe Ma, Zhiding Yu, Guilin Liu|<http://arxiv.org/pdf/2502.09051v1>|None|
|ğŸ†• å‘å¸ƒ|DiffoRA: Enabling Parameter-Efficient LLM Fine-Tuning via Differential Low-Rank Matrix Adaptation|DiffoRAï¼šé€šè¿‡å¾®åˆ†ä½ç§©çŸ©é˜µè‡ªé€‚åº”å®ç°å‚æ•°é«˜æ•ˆçš„å¤§å‹è¯­è¨€æ¨¡å‹å¾®è°ƒ|Tangyu Jiang, Haodi Wang, Chun Yuan|<http://arxiv.org/pdf/2502.08905v1>|None|
|ğŸ“ æ›´æ–°|Surface Vision Mamba: Leveraging Bidirectional State Space Model for Efficient Spherical Manifold Representation|è¡¨é¢è§†è§‰èŸ’è›‡ï¼šåˆ©ç”¨åŒå‘çŠ¶æ€ç©ºé—´æ¨¡å‹å®ç°é«˜æ•ˆçš„çƒå½¢æµå½¢è¡¨ç¤º|Rongzhao He, Weihao Zheng, Leilei Zhao, Ying Wang, Dalin Zhu, Dan Wu, Bin Hu|<http://arxiv.org/pdf/2501.14679v3>|<https://github.com/Rongzhao-He/surface-vision-mamba.>|
|ğŸ“ æ›´æ–°|Enhancing Video-LLM Reasoning via Agent-of-Thoughts Distillation|é€šè¿‡æ€ç»´ä»£ç†è’¸é¦å¢å¼ºè§†é¢‘-LLMæ¨ç†|Yudi Shi, Shangzhe Di, Qirui Chen, Weidi Xie|<http://arxiv.org/pdf/2412.01694v2>|None|
|ğŸ“ æ›´æ–°|Efficient 3D Perception on Multi-Sweep Point Cloud with Gumbel Spatial Pruning|åŸºäºGumbelç©ºé—´å‰ªæçš„å¤šæ‰«æç‚¹äº‘ä¸Šçš„é«˜æ•ˆ3Dæ„ŸçŸ¥|Tianyu Sun, Jianhao Li, Xueqian Zhang, Zhongdao Wang, Bailan Feng, Hengshuang Zhao|<http://arxiv.org/pdf/2411.07742v2>|None|
|ğŸ“ æ›´æ–°|MDSGen: Fast and Efficient Masked Diffusion Temporal-Aware Transformers for Open-Domain Sound Generation|MDSGenï¼šå¿«é€Ÿé«˜æ•ˆçš„å¼€æ”¾é¢†åŸŸå£°éŸ³ç”Ÿæˆæ©ç æ‰©æ•£æ—¶åºæ„ŸçŸ¥Transformer|Trung X. Pham, Tri Ton, Chang D. Yoo|<http://arxiv.org/pdf/2410.02130v2>|None|


## åŒ»å­¦åº”ç”¨

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Standardisation of Convex Ultrasound Data Through Geometric Analysis and Augmentation|é€šè¿‡å‡ ä½•åˆ†æå’Œå¢å¼ºæ ‡å‡†åŒ–å‡¸é¢è¶…å£°æ•°æ®|Alistair Weld, Giovanni Faoro, Luke Dixon, Sophie Camp, Arianna Menciassi, Stamatia Giannarou|<http://arxiv.org/pdf/2502.09482v1>|None|
|ğŸ†• å‘å¸ƒ|A 3D Facial Reconstruction Evaluation Methodology: Comparing Smartphone Scans with Deep Learning Based Methods Using Geometry and Morphometry Criteria|ä¸‰ç»´é¢éƒ¨é‡å»ºè¯„ä¼°æ–¹æ³•ï¼šåŸºäºå‡ ä½•å’Œå½¢æ€è®¡é‡æ ‡å‡†ï¼Œæ¯”è¾ƒæ™ºèƒ½æ‰‹æœºæ‰«æä¸æ·±åº¦å­¦ä¹ æ–¹æ³•|Ãlvaro Heredia-LidÃ³n, Alejandro MoÃ±ux-Bernal, Alejandro GonzÃ¡lez, Luis M. Echeverry-Quiceno, Max Rubert, Aroa Casado, MarÃ­a Esther Esteban, Mireia Andreu-Montoriol .etc.|<http://arxiv.org/pdf/2502.09425v1>|None|
|ğŸ†• å‘å¸ƒ|A Physics-Informed Deep Learning Model for MRI Brain Motion Correction|åŸºäºç‰©ç†ä¿¡æ¯çš„MRIè„‘éƒ¨è¿åŠ¨æ ¡æ­£æ·±åº¦å­¦ä¹ æ¨¡å‹|Mojtaba Safari, Shansong Wang, Zach Eidex, Richard Qiu, Chih-Wei Chang, David S. Yu, Xiaofeng Yang|<http://arxiv.org/pdf/2502.09296v1>|<https://github.com/mosaf/PI-MoCoNet.git.>|
|ğŸ†• å‘å¸ƒ|Memory-based Ensemble Learning in CMR Semantic Segmentation|åŸºäºè®°å¿†çš„CMRè¯­ä¹‰åˆ†å‰²é›†æˆå­¦ä¹ æ–¹æ³•|Yiwei Liu, Ziyi Wu, Liang Zhong, Linyi Wen, Yuankai Wu|<http://arxiv.org/pdf/2502.09269v1>|None|
|ğŸ†• å‘å¸ƒ|DynSegNet:Dynamic Architecture Adjustment for Adversarial Learning in Segmenting Hemorrhagic Lesions from Fundus Images|DynSegNetï¼šé’ˆå¯¹çœ¼åº•å›¾åƒä¸­å‡ºè¡€æ€§ç—…å˜åˆ†å‰²çš„å¯¹æŠ—å­¦ä¹ åŠ¨æ€æ¶æ„è°ƒæ•´|Zesheng Li, Minwen Liao, Haoran Chen, Yan Su, Chengchang Pan, Honggang Qi|<http://arxiv.org/pdf/2502.09256v1>|None|
|ğŸ†• å‘å¸ƒ|Multimodal HIE Lesion Segmentation in Neonates: A Comparative Study of Loss Functions|å¤šæ¨¡æ€æ–°ç”Ÿå„¿HIEç—…å˜åˆ†å‰²ï¼šæŸå¤±å‡½æ•°æ¯”è¾ƒç ”ç©¶|Annayah Usman, Abdul Haseeb, Tahir Syed|<http://arxiv.org/pdf/2502.09148v1>|None|
|ğŸ†• å‘å¸ƒ|Hierarchical Vision Transformer with Prototypes for Interpretable Medical Image Classification|åŸºäºåŸå‹çš„é«˜å±‚æ¬¡è§†è§‰Transformeråœ¨å¯è§£é‡ŠåŒ»å­¦å›¾åƒåˆ†ç±»ä¸­çš„åº”ç”¨|Luisa GallÃ©e, Catharina Silvia Lisson, Meinrad Beer, Michael GÃ¶tz|<http://arxiv.org/pdf/2502.08997v1>|None|
|ğŸ†• å‘å¸ƒ|Latents of latents to delineate pixels: hybrid Matryoshka autoencoder-to-U-Net pairing for segmenting large medical images in GPU-poor and low-data regimes|æ½œå±‚ä¸­çš„æ½œå±‚ï¼šç”¨äºåˆ†å‰²å¤§å‹åŒ»å­¦å›¾åƒçš„æ··åˆé©¬é›…å¯å¤«æ–¯åŸºè‡ªåŠ¨ç¼–ç å™¨åˆ°U-Neté…å¯¹ï¼Œé€‚ç”¨äºGPUèµ„æºåŒ®ä¹å’Œä½æ•°æ®ç¯å¢ƒ|Tahir Syed, Ariba Khan, Sawera Hanif|<http://arxiv.org/pdf/2502.08988v1>|None|
|ğŸ†• å‘å¸ƒ|PathFinder: A Multi-Modal Multi-Agent System for Medical Diagnostic Decision-Making Applied to Histopathology|è·¯å¾„æ¢ç´¢è€…ï¼šåº”ç”¨äºç—…ç†å­¦åŒ»å­¦è¯Šæ–­å†³ç­–çš„å¤šæ¨¡æ€å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ|Fatemeh Ghezloo, Mehmet Saygin Seyfioglu, Rustin Soraki, Wisdom O. Ikezogwo, Beibin Li, Tejoram Vivekanandan, Joann G. Elmore, Ranjay Krishna .etc.|<http://arxiv.org/pdf/2502.08916v1>|None|
|ğŸ“ æ›´æ–°|A Unified Model for Compressed Sensing MRI Across Undersampling Patterns|ç»Ÿä¸€è·¨æ¬ é‡‡æ ·æ¨¡å¼çš„å‹ç¼©æ„ŸçŸ¥MRIæ¨¡å‹|Armeet Singh Jatyani, Jiayun Wang, Aditi Chandrashekar, Zihui Wu, Miguel Liu-Schiaffini, Bahareh Tolooshams, Anima Anandkumar|<http://arxiv.org/pdf/2410.16290v3>|None|
|ğŸ“ æ›´æ–°|SkinGEN: an Explainable Dermatology Diagnosis-to-Generation Framework with Interactive Vision-Language Models|çš®è‚¤ç”Ÿæˆå™¨ï¼šä¸€ä¸ªå…·æœ‰äº¤äº’å¼è§†è§‰-è¯­è¨€æ¨¡å‹çš„å¯è§£é‡Šçš®è‚¤ç—…å­¦è¯Šæ–­åˆ°ç”Ÿæˆæ¡†æ¶|Bo Lin, Yingjing Xu, Xuanwen Bao, Zhou Zhao, Zhouyang Wang, Jianwei Yin|<http://arxiv.org/pdf/2404.14755v2>|None|
|ğŸ“ æ›´æ–°|Multi-level Asymmetric Contrastive Learning for Volumetric Medical Image Segmentation Pre-training|å¤šçº§éå¯¹ç§°å¯¹æ¯”å­¦ä¹ ç”¨äºä½“ç´ åŒ»å­¦å›¾åƒåˆ†å‰²é¢„è®­ç»ƒ|Shuang Zeng, Lei Zhu, Xinliang Zhang, Micky C Nnamdi, Wenqi Shi, J Ben Tamo, Qian Chen, Hangzhou He .etc.|<http://arxiv.org/pdf/2309.11876v3>|<https://github.com/stevezs315/MACL.>|

