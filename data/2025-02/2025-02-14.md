## [UPDATED!] **2025-02-14** (Update Time)


## å›¾åƒç†è§£

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Simplifying DINO via Coding Rate Regularization|é€šè¿‡ç ç‡æ­£åˆ™åŒ–ç®€åŒ–DINO|Ziyang Wu, Jingyuan Zhang, Druv Pai, XuDong Wang, Chandan Singh, Jianwei Yang, Jianfeng Gao, Yi Ma|<http://arxiv.org/pdf/2502.10385v1>|None|
|ğŸ†• å‘å¸ƒ|X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from Multi-Turn Jailbreaks without Compromising Usability|X-Boundaryï¼šå»ºç«‹ç²¾ç¡®å®‰å…¨è¾¹ç•Œä»¥ä¿æŠ¤LLMså…å—å¤šè½®è¶Šç‹±æ”»å‡»è€Œä¸æŸå®³å¯ç”¨æ€§|Xiaoya Lu, Dongrui Liu, Yi Yu, Luxin Xu, Jing Shao|<http://arxiv.org/pdf/2502.09990v1>|<https://github.com/AI45Lab/X-Boundary.>|
|ğŸ†• å‘å¸ƒ|VicKAM: Visual Conceptual Knowledge Guided Action Map for Weakly Supervised Group Activity Recognition|è§†è§‰æ¦‚å¿µçŸ¥è¯†å¼•å¯¼çš„åŠ¨ä½œå›¾ï¼šç”¨äºå¼±ç›‘ç£ç¾¤ä½“æ´»åŠ¨è¯†åˆ«|Zhuming Wang, Yihao Zheng, Jiarui Li, Yaofei Wu, Yan Huang, Zun Li, Lifang Wu, Liang Wang|<http://arxiv.org/pdf/2502.09967v1>|None|
|ğŸ†• å‘å¸ƒ|Granite Vision: a lightweight, open-source multimodal model for enterprise Intelligence|èŠ±å²—å²©è§†è§‰ï¼šä¸€ç§è½»é‡çº§ã€å¼€æºçš„å¤šæ¨¡æ€ä¼ä¸šæ™ºèƒ½æ¨¡å‹|Granite Vision Team, Leonid Karlinsky, Assaf Arbelle, Abraham Daniels, Ahmed Nassar, Amit Alfassi, Bo Wu, Eli Schwartz .etc.|<http://arxiv.org/pdf/2502.09927v1>|None|
|ğŸ“ æ›´æ–°|Domain-Invariant Per-Frame Feature Extraction for Cross-Domain Imitation Learning with Visual Observations|è·¨åŸŸæ¨¡ä»¿å­¦ä¹ ä¸­çš„åŸŸä¸å˜å¸§çº§ç‰¹å¾æå–|Minung Kim, Kawon Lee, Jungmo Kim, Sungho Choi, Seungyul Han|<http://arxiv.org/pdf/2502.02867v2>|None|
|ğŸ“ æ›´æ–°|Analyzing and Boosting the Power of Fine-Grained Visual Recognition for Multi-modal Large Language Models|åˆ†æå¹¶æå‡å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ç»†ç²’åº¦è§†è§‰è¯†åˆ«çš„æ•ˆèƒ½|Hulingxiao He, Geng Li, Zijun Geng, Jinglin Xu, Yuxin Peng|<http://arxiv.org/pdf/2501.15140v2>|<https://github.com/PKU-ICST-MIPL/Finedefics_ICLR2025.>|
|ğŸ“ æ›´æ–°|CrossFi: A Cross Domain Wi-Fi Sensing Framework Based on Siamese Network|è·¨åŸŸWi-Fiæ„ŸçŸ¥æ¡†æ¶ï¼šåŸºäºSiameseç½‘ç»œçš„CrossFi|Zijian Zhao, Tingwei Chen, Zhijie Cai, Xiaoyang Li, Hang Li, Qimei Chen, Guangxu Zhu|<http://arxiv.org/pdf/2408.10919v4>|<https://github.com/RS2002/CrossFi.>|
|ğŸ“ æ›´æ–°|HaSPeR: An Image Repository for Hand Shadow Puppet Recognition|HaSPeRï¼šæ‰‹å½±æœ¨å¶è¯†åˆ«å›¾åƒåº“|Syed Rifat Raiyan, Zibran Zarif Amio, Sabbir Ahmed|<http://arxiv.org/pdf/2408.10360v5>|None|


## æ£€æµ‹åˆ†å‰²

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ReStyle3D: Scene-Level Appearance Transfer with Semantic Correspondences|ReStyle3Dï¼šåŸºäºè¯­ä¹‰å¯¹åº”å…³ç³»çš„åœºæ™¯çº§å¤–è§‚è¿ç§»|Liyuan Zhu, Shengqu Cai, Shengyu Huang, Gordon Wetzstein, Naji Khosravan, Iro Armeni|<http://arxiv.org/pdf/2502.10377v1>|None|
|ğŸ†• å‘å¸ƒ|Object Detection and Tracking|ç›®æ ‡æ£€æµ‹ä¸è·Ÿè¸ª|Md Pranto, Omar Faruk|<http://arxiv.org/pdf/2502.10310v1>|None|
|ğŸ†• å‘å¸ƒ|Image Embedding Sampling Method for Diverse Captioning|å›¾åƒåµŒå…¥é‡‡æ ·æ–¹æ³•ç”¨äºå¤šæ ·åŒ–æè¿°|Sania Waheed, Na Min An|<http://arxiv.org/pdf/2502.10118v1>|None|
|ğŸ†• å‘å¸ƒ|Towards Polyp Counting In Full-Procedure Colonoscopy Videos|æœç€å…¨æµç¨‹ç»“è‚ é•œè§†é¢‘ä¸­çš„æ¯è‚‰è®¡æ•°æŠ€æœ¯|Luca Parolari, Andrea Cherubini, Lamberto Ballan, Carlo Biffi|<http://arxiv.org/pdf/2502.10054v1>|<https://github.com/lparolari/towards-polyp-counting.>|
|ğŸ†• å‘å¸ƒ|V2V-LLM: Vehicle-to-Vehicle Cooperative Autonomous Driving with Multi-Modal Large Language Models|V2V-LLMï¼šåŸºäºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„è½¦è¾†é—´ååŒè‡ªåŠ¨é©¾é©¶|Hsu-kuang Chiu, Ryo Hachiuma, Chien-Yi Wang, Stephen F. Smith, Yu-Chiang Frank Wang, Min-Hung Chen|<http://arxiv.org/pdf/2502.09980v1>|<https://eddyhkchiu.github.io/v2vllm.github.io>|
|ğŸ†• å‘å¸ƒ|FrGNet: A fourier-guided weakly-supervised framework for nuclear instance segmentation|FrGNetï¼šä¸€ç§åŸºäºå‚…é‡Œå¶å¼•å¯¼çš„å¼±ç›‘ç£æ ¸å®ä¾‹åˆ†å‰²æ¡†æ¶|Peng Ling|<http://arxiv.org/pdf/2502.09874v1>|<https://github.com/LQY404/FrGNet.>|
|ğŸ“ æ›´æ–°|Local-Prompt: Extensible Local Prompts for Few-Shot Out-of-Distribution Detection|å±€éƒ¨æç¤ºï¼šç”¨äºå°æ ·æœ¬åˆ†å¸ƒå¤–æ£€æµ‹çš„å¯æ‰©å±•å±€éƒ¨æç¤º|Fanhu Zeng, Zhen Cheng, Fei Zhu, Hongxin Wei, Xu-Yao Zhang|<http://arxiv.org/pdf/2409.04796v2>|<https://github.com/AuroraZengfh/Local-Prompt.>|
|ğŸ“ æ›´æ–°|Verbalized Machine Learning: Revisiting Machine Learning with Language Models|æœºå™¨å­¦ä¹ è¯­è¨€åŒ–ï¼šç”¨è¯­è¨€æ¨¡å‹é‡æ–°å®¡è§†æœºå™¨å­¦ä¹ |Tim Z. Xiao, Robert Bamler, Bernhard SchÃ¶lkopf, Weiyang Liu|<http://arxiv.org/pdf/2406.04344v3>|None|


## è§†é¢‘ç†è§£

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ManiTrend: Bridging Future Generation and Action Prediction with 3D Flow for Robotic Manipulation|æœºå™¨äººæ“ä½œä¸­çš„3Dæµï¼šè¿æ¥æœªæ¥ä¸–ä»£ä¸åŠ¨ä½œé¢„æµ‹çš„ManiTrend|Yuxin He, Qiang Nie|<http://arxiv.org/pdf/2502.10028v1>|None|
|ğŸ†• å‘å¸ƒ|Temporal Scale and Shift Invariant Automatic Event Recognition using the Mellin Transform|åŸºäºæ¢…æ—å˜æ¢çš„æ—¶é—´å°ºåº¦å’Œå¹³ç§»ä¸å˜è‡ªåŠ¨äº‹ä»¶è¯†åˆ«|Xi Shen, Julian Gamboa, Tabassom Hamidfar, Shamima A. Mitu, Selim M. Shahriar|<http://arxiv.org/pdf/2502.09939v1>|None|
|ğŸ“ æ›´æ–°|Optimizing GPT for Video Understanding: Zero-Shot Performance and Prompt Engineering|ä¼˜åŒ–GPTä»¥å®ç°è§†é¢‘ç†è§£ï¼šé›¶æ ·æœ¬æ€§èƒ½ä¸æç¤ºå·¥ç¨‹|Mark Beliaev, Victor Yang, Madhura Raju, Jiachen Sun, Xinghai Hu|<http://arxiv.org/pdf/2502.09573v2>|None|


## ç”Ÿæˆæ¨¡å‹

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Region-Adaptive Sampling for Diffusion Transformers|åŒºåŸŸè‡ªé€‚åº”é‡‡æ ·æ‰©æ•£å˜æ¢å™¨|Ziming Liu, Yifan Yang, Chengruidong Zhang, Yiqi Zhang, Lili Qiu, Yang You, Yuqing Yang|<http://arxiv.org/pdf/2502.10389v1>|None|
|ğŸ†• å‘å¸ƒ|Generating on Generated: An Approach Towards Self-Evolving Diffusion Models|ç”Ÿæˆäºç”Ÿæˆï¼šè‡ªè¿›åŒ–æ‰©æ•£æ¨¡å‹çš„ä¸€ç§æ–¹æ³•|Xulu Zhang, Xiaoyong Wei, Jinlin Wu, Jiaxin Wu, Zhaoxiang Zhang, Zhen Lei, Qing Li|<http://arxiv.org/pdf/2502.09963v1>|None|
|ğŸ†• å‘å¸ƒ|Precise Parameter Localization for Textual Generation in Diffusion Models|ç²¾ç¡®å‚æ•°å®šä½ï¼šæ‰©æ•£æ¨¡å‹ä¸­çš„æ–‡æœ¬ç”Ÿæˆ|Åukasz Staniszewski, Bartosz CywiÅ„ski, Franziska Boenisch, Kamil Deja, Adam Dziedzic|<http://arxiv.org/pdf/2502.09935v1>|<https://t2i-text-loc.github.io/.>|
|ğŸ“ æ›´æ–°|FreeBlend: Advancing Concept Blending with Staged Feedback-Driven Interpolation Diffusion|FreeBlendï¼šé€šè¿‡åˆ†é˜¶æ®µåé¦ˆé©±åŠ¨çš„æ’å€¼æ‰©æ•£æ¨è¿›æ¦‚å¿µèåˆ|Yufan Zhou, Haoyu Shen, Huan Wang|<http://arxiv.org/pdf/2502.05606v2>|None|


## æ‰©æ•£æ¡¥

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SPIRIT: Short-term Prediction of solar IRradIance for zero-shot Transfer learning using Foundation Models|SPIRITï¼šåŸºäºåŸºç¡€æ¨¡å‹çš„é›¶æ ·æœ¬è¿ç§»å­¦ä¹ çŸ­æœŸå¤ªé˜³çº¢å¤–è¾å°„é¢„æµ‹|Aditya Mishra, Ravindra T, Srinivasan Iyengar, Shivkumar Kalyanaraman, Ponnurangam Kumaraguru|<http://arxiv.org/pdf/2502.10307v1>|None|


## å›¾åƒå¤„ç†

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Exploring the Camera Bias of Person Re-identification|æ¢ç´¢è¡Œäººé‡è¯†åˆ«ä¸­çš„ç›¸æœºåå·®|Myungseo Song, Jin-Woo Park, Jong-Seok Lee|<http://arxiv.org/pdf/2502.10195v1>|None|
|ğŸ†• å‘å¸ƒ|Compress image to patches for Vision Transformer|å‹ç¼©å›¾åƒä¸ºè¡¥ä¸ä»¥ç”¨äºè§†è§‰Transformer|Xinfeng Zhao, Yaoru Sun|<http://arxiv.org/pdf/2502.10120v1>|None|
|ğŸ†• å‘å¸ƒ|Hands-off Image Editing: Language-guided Editing without any Task-specific Labeling, Masking or even Training|æ— éœ€åŠ¨æ‰‹çš„å›¾åƒç¼–è¾‘ï¼šæ— éœ€ä»»åŠ¡ç‰¹å®šæ ‡ç­¾ã€é®ç½©ç”šè‡³è®­ç»ƒçš„è¯­è¨€å¼•å¯¼ç¼–è¾‘|Rodrigo Santos, AntÃ³nio Branco, JoÃ£o Silva, JoÃ£o Rodrigues|<http://arxiv.org/pdf/2502.10064v1>|None|
|ğŸ†• å‘å¸ƒ|Conditional Latent Coding with Learnable Synthesized Reference for Deep Image Compression|æ¡ä»¶æ½œåœ¨ç¼–ç ä¸å¯å­¦ä¹ åˆæˆå‚è€ƒçš„æ·±åº¦å›¾åƒå‹ç¼©|Siqi Wu, Yinda Chen, Dong Liu, Zhihai He|<http://arxiv.org/pdf/2502.09971v1>|<https://github.com/ydchen0806/CLC.>|
|ğŸ†• å‘å¸ƒ|A Lightweight and Effective Image Tampering Localization Network with Vision Mamba|è½»é‡çº§ä¸”æœ‰æ•ˆçš„è§†è§‰Mambaå›¾åƒç¯¡æ”¹å®šä½ç½‘ç»œ|Kun Guo, Gang Cao, Zijie Lou, Xianglin Huang, Jiaoyun Liu|<http://arxiv.org/pdf/2502.09941v1>|<https://github.com/multimediaFor/ForMa.>|
|ğŸ†• å‘å¸ƒ|Deep Tree Tensor Networks for Image Recognition|æ·±åº¦æ ‘å¼ é‡ç½‘ç»œåœ¨å›¾åƒè¯†åˆ«ä¸­çš„åº”ç”¨|Chang Nie, Junfang Chen, Yajie Chen|<http://arxiv.org/pdf/2502.09928v1>|None|
|ğŸ†• å‘å¸ƒ|Compression-Aware One-Step Diffusion Model for JPEG Artifact Removal|JPEGä¼ªå½±å»é™¤çš„å‹ç¼©æ„ŸçŸ¥ä¸€æ­¥æ‰©æ•£æ¨¡å‹|Jinpei Guo, Zheng Chen, Wenbo Li, Yong Guo, Yulun Zhang|<http://arxiv.org/pdf/2502.09873v1>|<https://github.com/jp-guo/CODiff.>|
|ğŸ“ æ›´æ–°|$\textrm{A}^{\textrm{2}}$RNet: Adversarial Attack Resilient Network for Robust Infrared and Visible Image Fusion|AÂ²RNetï¼šç”¨äºé²æ£’çº¢å¤–å’Œå¯è§å…‰å›¾åƒèåˆçš„å¯¹æŠ—æ”»å‡»é²æ£’ç½‘ç»œ|Jiawei Li, Hongwei Yu, Jiansheng Chen, Xinlong Ding, Jinlong Wang, Jinyuan Liu, Bochao Zou, Huimin Ma|<http://arxiv.org/pdf/2412.09954v3>|<https://github.com/lok-18/A2RNet.>|
|ğŸ“ æ›´æ–°|Anti-Forgetting Adaptation for Unsupervised Person Re-identification|å¯¹æŠ—é—å¿˜çš„è‡ªç›‘ç£è¡Œäººé‡è¯†åˆ«é€‚åº”æ€§|Hao Chen, Francois Bremond, Nicu Sebe, Shiliang Zhang|<http://arxiv.org/pdf/2411.14695v2>|None|


## 3Dåœºæ™¯

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|RealCam-I2V: Real-World Image-to-Video Generation with Interactive Complex Camera Control|çœŸå®ç›¸æœº-I2Vï¼šå…·æœ‰äº¤äº’å¼å¤æ‚ç›¸æœºæ§åˆ¶çš„ç°å®ä¸–ç•Œå›¾åƒåˆ°è§†é¢‘ç”Ÿæˆ|Teng Li, Guangcong Zheng, Rui Jiang, Shuigenzhan, Tao Wu, Yehao Lu, Yining Lin, Xi Li|<http://arxiv.org/pdf/2502.10059v1>|<https://zgctroy.github.io/RealCam-I2V.>|
|ğŸ“ æ›´æ–°|When Video Coding Meets Multimodal Large Language Models: A Unified Paradigm for Video Coding|è§†é¢‘ç¼–ç é‡è§å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼šè§†é¢‘ç¼–ç çš„ç»Ÿä¸€èŒƒå¼|Pingping Zhang, Jinlong Li, Kecheng Chen, Meng Wang, Long Xu, Haoliang Li, Nicu Sebe, Sam Kwong .etc.|<http://arxiv.org/pdf/2408.08093v3>|None|


## ç¥ç»æ¸²æŸ“

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|DiSciPLE: Learning Interpretable Programs for Scientific Visual Discovery|DiSciPLEï¼šå­¦ä¹ ç”¨äºç§‘å­¦è§†è§‰å‘ç°çš„å¯è§£é‡Šç¨‹åº|Utkarsh Mall, Cheng Perng Phoo, Mia Chiquier, Bharath Hariharan, Kavita Bala, Carl Vondrick|<http://arxiv.org/pdf/2502.10060v1>|None|
|ğŸ†• å‘å¸ƒ|Using MRNet to Predict Lunar Rock Categories Detected by Chang'e 5 Probe|åˆ©ç”¨MRNeté¢„æµ‹å«¦å¨¥äº”å·æ¢æµ‹å™¨æ£€æµ‹åˆ°çš„æœˆçƒå²©çŸ³ç±»åˆ«|Jin Cui, Yifei Zou, Siyuan Zhang|<http://arxiv.org/pdf/2502.09952v1>|None|
|ğŸ“ æ›´æ–°|Supervised contrastive learning for cell stage classification of animal embryos|åŠ¨ç‰©èƒšèƒç»†èƒé˜¶æ®µåˆ†ç±»çš„ç›‘ç£å¯¹æ¯”å­¦ä¹ |Yasmine Hachani, Patrick Bouthemy, Elisa Fromont, Sylvie Ruffini, Ludivine Laffont, Alline de Paula Reis|<http://arxiv.org/pdf/2502.07360v2>|None|
|ğŸ“ æ›´æ–°|TractShapeNet: Efficient Multi-Shape Learning with 3D Tractography Point Clouds|è½¨è¿¹å½¢çŠ¶ç½‘ï¼šåŸºäº3Dè½¨è¿¹ç»˜å›¾ç‚¹äº‘çš„é«˜æ•ˆå¤šå½¢çŠ¶å­¦ä¹ |Yui Lo, Yuqian Chen, Dongnan Liu, Jon Haitz Legarreta, Leo Zekelman, Fan Zhang, Jarrett Rushmore, Yogesh Rathi .etc.|<http://arxiv.org/pdf/2410.22099v4>|<https://github.com/SlicerDMRI/TractShapeNet.>|
|ğŸ“ æ›´æ–°|Dynamic Scene Understanding through Object-Centric Voxelization and Neural Rendering|é€šè¿‡ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„ä½“ç´ åŒ–å’Œç¥ç»æ¸²æŸ“å®ç°åŠ¨æ€åœºæ™¯ç†è§£|Yanpeng Zhao, Yiwei Hao, Siyu Gao, Yunbo Wang, Xiaokang Yang|<http://arxiv.org/pdf/2407.20908v2>|None|
|ğŸ“ æ›´æ–°|Pavlok-Nudge: A Feedback Mechanism for Atomic Behaviour Modification with Snoring Usecase|Pavlok-Nudgeï¼šåŸºäºæ‰“é¼¾ç”¨ä¾‹çš„åŸå­è¡Œä¸ºä¿®æ”¹åé¦ˆæœºåˆ¶|Md Rakibul Hasan, Shreya Ghosh, Pradyumna Agrawal, Zhixi Cai, Abhinav Dhall, Tom Gedeon|<http://arxiv.org/pdf/2305.06110v4>|<https://github.com/hasan-rakibul/pavlok-nudge-snore.>|


## å¤šæ¨¡æ€

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MM-RLHF: The Next Step Forward in Multimodal LLM Alignment|MM-RLHFï¼šå¤šæ¨¡æ€LLMå¯¹é½çš„ä¸‹ä¸€æ­¥è¿›å±•|Yi-Fan Zhang, Tao Yu, Haochen Tian, Chaoyou Fu, Peiyan Li, Jianshu Zeng, Wulin Xie, Yang Shi .etc.|<http://arxiv.org/pdf/2502.10391v1>|None|
|ğŸ†• å‘å¸ƒ|Probing Perceptual Constancy in Large Vision Language Models|æ¢ç©¶å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„æ„ŸçŸ¥æ’å¸¸æ€§|Haoran Sun, Suyang Yu, Yijiang Li, Qingying Gao, Haiyun Lyu, Hokin Deng, Dezhi Luo|<http://arxiv.org/pdf/2502.10273v1>|None|
|ğŸ†• å‘å¸ƒ|VisCon-100K: Leveraging Contextual Web Data for Fine-tuning Vision Language Models|VisCon-100Kï¼šåˆ©ç”¨ä¸Šä¸‹æ–‡ç½‘ç»œæ•°æ®å¾®è°ƒè§†è§‰è¯­è¨€æ¨¡å‹|Gokul Karthik Kumar, Iheb Chaabane, Kebin Wu|<http://arxiv.org/pdf/2502.10250v1>|None|
|ğŸ†• å‘å¸ƒ|TaskGalaxy: Scaling Multi-modal Instruction Fine-tuning with Tens of Thousands Vision Task Types|ä»»åŠ¡é“¶æ²³ï¼šé€šè¿‡æ•°ä»¥åƒè®¡çš„è§†è§‰ä»»åŠ¡ç±»å‹æ‰©å±•å¤šæ¨¡æ€æŒ‡ä»¤å¾®è°ƒ|Jiankang Chen, Tianke Zhang, Changyi Liu, Haojie Ding, Yaya Shi, Feng Cheng, Huihui Xiao, Bin Wen .etc.|<http://arxiv.org/pdf/2502.09925v1>|<https://github.com/Kwai-YuanQi/TaskGalaxy.>|
|ğŸ†• å‘å¸ƒ|Insect-Foundation: A Foundation Model and Large Multimodal Dataset for Vision-Language Insect Understanding|æ˜†è™«åŸºç¡€ï¼šè§†è§‰-è¯­è¨€æ˜†è™«ç†è§£çš„åŸºåº§æ¨¡å‹å’Œå¤§å‹å¤šæ¨¡æ€æ•°æ®é›†|Thanh-Dat Truong, Hoang-Quan Nguyen, Xuan-Bac Nguyen, Ashley Dowling, Xin Li, Khoa Luu|<http://arxiv.org/pdf/2502.09906v1>|None|
|ğŸ“ æ›´æ–°|TRISHUL: Towards Region Identification and Screen Hierarchy Understanding for Large VLM based GUI Agents|TRISHULï¼šè¿ˆå‘å¤§å‹VLMåŸºäºGUIä»£ç†çš„åŒºåŸŸè¯†åˆ«å’Œå±å¹•å±‚æ¬¡ç»“æ„ç†è§£|Kunal Singh, Shreyas Singh, Mukund Khanna|<http://arxiv.org/pdf/2502.08226v2>|None|
|ğŸ“ æ›´æ–°|One Leaf Reveals the Season: Occlusion-Based Contrastive Learning with Semantic-Aware Views for Efficient Visual Representation|ä¸€ç‰‡å¶å­æ­ç¤ºå­£èŠ‚ï¼šåŸºäºé®æŒ¡çš„å¯¹æ¯”å­¦ä¹ ä¸è¯­ä¹‰æ„ŸçŸ¥è§†å›¾çš„æ•ˆç‡è§†è§‰è¡¨å¾|Xiaoyu Yang, Lijian Xu, Hongsheng Li, Shaoting Zhang|<http://arxiv.org/pdf/2411.09858v2>|None|
|ğŸ“ æ›´æ–°|Is What You Ask For What You Get? Investigating Concept Associations in Text-to-Image Models|ä½ æ‰€è¦æ±‚çš„ï¼Œå°±æ˜¯ä½ æ‰€å¾—åˆ°çš„å—ï¼Ÿæ¢ç©¶æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ä¸­çš„æ¦‚å¿µå…³è”|Salma Abdel Magid, Weiwei Pan, Simon Warchol, Grace Guo, Junsik Kim, Mahia Rahman, Hanspeter Pfister|<http://arxiv.org/pdf/2410.04634v2>|None|
|ğŸ“ æ›´æ–°|Towards Top-Down Reasoning: An Explainable Multi-Agent Approach for Visual Question Answering|æœå‘è‡ªä¸Šè€Œä¸‹çš„æ¨ç†ï¼šä¸€ç§å¯è§£é‡Šçš„å¤šæ™ºèƒ½ä½“è§†è§‰é—®ç­”æ–¹æ³•|Zeqing Wang, Wentao Wan, Qiqing Lao, Runmeng Chen, Minjie Lang, Xiao Wang, Keze Wang, Liang Lin|<http://arxiv.org/pdf/2311.17331v4>|None|


## å…·èº«æ™ºèƒ½

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MITO: Enabling Non-Line-of-Sight Perception using Millimeter-waves through Real-World Datasets and Simulation Tools|MITOï¼šé€šè¿‡çœŸå®ä¸–ç•Œæ•°æ®é›†å’Œä»¿çœŸå·¥å…·å®ç°æ¯«ç±³æ³¢éè§†è·æ„ŸçŸ¥|Laura Dodds, Tara Boroushaki, Fadel Adib|<http://arxiv.org/pdf/2502.10259v1>|None|
|ğŸ†• å‘å¸ƒ|PromptArtisan: Multi-instruction Image Editing in Single Pass with Complete Attention Control|PromptArtisanï¼šå•æ¬¡éå†ä¸­çš„å¤šæŒ‡ä»¤å›¾åƒç¼–è¾‘ä¸å®Œå…¨æ³¨æ„åŠ›æ§åˆ¶|Kunal Swami, Raghu Chittersu, Pranav Adlinge, Rajeev Irny, Shashavali Doodekula, Alok Shukla|<http://arxiv.org/pdf/2502.10258v1>|None|
|ğŸ†• å‘å¸ƒ|Mapping bathymetry of inland water bodies on the North Slope of Alaska with Landsat using Random Forest|åˆ©ç”¨éšæœºæ£®æ—åœ¨é˜¿æ‹‰æ–¯åŠ åŒ—å¡å†…é™†æ°´ä½“ä¸Šé€šè¿‡Landsatè¿›è¡Œæ°´æ·±æµ‹ç»˜|Mark L. Carroll, Margaret R. Wooten, Claire E. Simpson, Caleb S. Spradlin, Melanie J. Frost, Mariana Blanco-Rojas, Zachary W. Williams, Jordan A. Caraballo-Vega .etc.|<http://arxiv.org/pdf/2502.10214v1>|None|
|ğŸ†• å‘å¸ƒ|Revisiting Generalization Power of a DNN in Terms of Symbolic Interactions|é‡æ–°å®¡è§†åŸºäºç¬¦å·äº¤äº’çš„æ·±åº¦ç¥ç»ç½‘ç»œæ³›åŒ–èƒ½åŠ›|Lei Cheng, Junpeng Zhang, Qihan Ren, Quanshi Zhang|<http://arxiv.org/pdf/2502.10162v1>|None|
|ğŸ†• å‘å¸ƒ|MonoForce: Learnable Image-conditioned Physics Engine|MonoForceï¼šå¯å­¦ä¹ çš„å›¾åƒæ¡ä»¶ç‰©ç†å¼•æ“|Ruslan Agishev, Karel Zimmermann|<http://arxiv.org/pdf/2502.10156v1>|None|
|ğŸ†• å‘å¸ƒ|Leveraging V2X for Collaborative HD Maps Construction Using Scene Graph Generation|åˆ©ç”¨V2Xè¿›è¡ŒåŸºäºåœºæ™¯å›¾ç”Ÿæˆçš„ååŒé«˜ç²¾åº¦åœ°å›¾æ„å»º|Gamal Elghazaly, Raphael Frank|<http://arxiv.org/pdf/2502.10127v1>|None|
|ğŸ†• å‘å¸ƒ|Self-Consistent Model-based Adaptation for Visual Reinforcement Learning|è‡ªæ´½æ¨¡å‹åŸºç¡€è‡ªé€‚åº”è§†è§‰å¼ºåŒ–å­¦ä¹ |Xinning Zhou, Chengyang Ying, Yao Feng, Hang Su, Jun Zhu|<http://arxiv.org/pdf/2502.09923v1>|None|
|ğŸ“ æ›´æ–°|S2CFormer: Reorienting Learned Image Compression from Spatial Interaction to Channel Aggregation|S2CFormerï¼šå°†å­¦ä¹ å›¾åƒå‹ç¼©ä»ç©ºé—´äº¤äº’é‡æ–°å®šä½åˆ°é€šé“èšåˆ|Yunuo Chen, Qian Li, Bing He, Donghui Feng, Ronghua Wu, Qi Wang, Li Song, Guo Lu .etc.|<http://arxiv.org/pdf/2502.00700v2>|None|
|ğŸ“ æ›´æ–°|Image Forgery Localization with State Space Models|åŸºäºçŠ¶æ€ç©ºé—´æ¨¡å‹çš„å›¾åƒä¼ªé€ å®šä½|Zijie Lou, Gang Cao, Kun Guo, Shaowei Weng, Lifang Yu|<http://arxiv.org/pdf/2412.11214v2>|<https://github.com/multimediaFor/LoMa.>|
|ğŸ“ æ›´æ–°|Benchmarking Predictive Coding Networks -- Made Simple|åŸºå‡†æµ‹è¯•é¢„æµ‹ç¼–ç ç½‘ç»œâ€”â€”ç®€åŒ–ç‰ˆ|Luca Pinchetti, Chang Qi, Oleh Lokshyn, Gaspard Olivers, Cornelius Emde, Mufeng Tang, Amine M'Charrak, Simon Frieder .etc.|<http://arxiv.org/pdf/2407.01163v2>|<https://github.com/liukidar/pcx>|


## äººä½“åˆ†æ

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|City-Scale Multi-Camera Vehicle Tracking System with Improved Self-Supervised Camera Link Model|åŸå¸‚çº§å¤šæ‘„åƒå¤´è½¦è¾†è·Ÿè¸ªç³»ç»Ÿï¼šæ”¹è¿›çš„è‡ªç›‘ç£ç›¸æœºé“¾æ¥æ¨¡å‹|Yuqiang Lin, Sam Lockyer, Nic Zhang|<http://arxiv.org/pdf/2405.11345v3>|None|


## äººè„¸æŠ€æœ¯

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Interpretable Concept-based Deep Learning Framework for Multimodal Human Behavior Modeling|å¯è§£é‡Šçš„æ¦‚å¿µåŸºç¡€æ·±åº¦å­¦ä¹ æ¡†æ¶ç”¨äºå¤šæ¨¡æ€äººç±»è¡Œä¸ºå»ºæ¨¡|Xinyu Li, Marwa Mahmoud|<http://arxiv.org/pdf/2502.10145v1>|None|
|ğŸ†• å‘å¸ƒ|Navigating Label Ambiguity for Facial Expression Recognition in the Wild|åœ¨é‡å¤–é¢éƒ¨è¡¨æƒ…è¯†åˆ«ä¸­çš„æ ‡ç­¾æ¨¡ç³Šå¯¼èˆª|JunGyu Lee, Yeji Choi, Haksub Kim, Ig-Jae Kim, Gi Pyo Nam|<http://arxiv.org/pdf/2502.09993v1>|None|
|ğŸ†• å‘å¸ƒ|AffectSRNet : Facial Emotion-Aware Super-Resolution Network|æƒ…æ„Ÿæ„ŸçŸ¥è¶…åˆ†è¾¨ç‡ç½‘ç»œï¼šAffectSRNet|Syed Sameen Ahmad Rizvi, Soham Kumar, Aryan Seth, Pratik Narang|<http://arxiv.org/pdf/2502.09932v1>|None|
|ğŸ“ æ›´æ–°|A Survey on Personalized Content Synthesis with Diffusion Models|ä¸ªæ€§åŒ–å†…å®¹åˆæˆä¸­çš„æ‰©æ•£æ¨¡å‹ç»¼è¿°|Xulu Zhang, Xiaoyong Wei, Wengyu Zhang, Jinlin Wu, Zhaoxiang Zhang, Zhen Lei, Qing Li|<http://arxiv.org/pdf/2405.05538v2>|None|


## æ•°å­—äºº

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ViRAC: A Vision-Reasoning Agent Head Movement Control Framework in Arbitrary Virtual Environments|ViRACï¼šä»»æ„è™šæ‹Ÿç¯å¢ƒä¸­è§†è§‰-æ¨ç†æ™ºèƒ½ä½“å¤´éƒ¨è¿åŠ¨æ§åˆ¶æ¡†æ¶|Juyeong Hwang, Seong-Eun Hong, Hyeongyeop Kang|<http://arxiv.org/pdf/2502.10046v1>|None|
|ğŸ†• å‘å¸ƒ|Learning to Calibrate for Reliable Visual Fire Detection|å­¦ä¹ ä»¥æ ¡å‡†ç¡®ä¿å¯é è§†è§‰ç«ç¾æ£€æµ‹|Ziqi Zhang, Xiuzhuang Zhou, Xiangyang Gong|<http://arxiv.org/pdf/2502.09872v1>|None|


## æ¨¡å‹ä¼˜åŒ–

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Text-guided Sparse Voxel Pruning for Efficient 3D Visual Grounding|åŸºäºæ–‡æœ¬å¼•å¯¼çš„ç¨€ç–ä½“ç´ å‰ªæä»¥æé«˜3Dè§†è§‰å®šä½æ•ˆç‡|Wenxuan Guo, Xiuwei Xu, Ziwei Wang, Jianjiang Feng, Jie Zhou, Jiwen Lu|<http://arxiv.org/pdf/2502.10392v1>|<https://github.com/GWxuan/TSP3D>|
|ğŸ†• å‘å¸ƒ|Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model|ã€Šæ­¥è§†é¢‘-T2VæŠ€æœ¯æŠ¥å‘Šï¼šè§†é¢‘åŸºç¡€æ¨¡å‹çš„å®è·µã€æŒ‘æˆ˜ä¸æœªæ¥ã€‹|Guoqing Ma, Haoyang Huang, Kun Yan, Liangyu Chen, Nan Duan, Shengming Yin, Changyi Wan, Ranchen Ming .etc.|<http://arxiv.org/pdf/2502.10248v1>|<https://github.com/stepfun-ai/Step-Video-T2V.>|
|ğŸ“ æ›´æ–°|Magic 1-For-1: Generating One Minute Video Clips within One Minute|ã€Šé­”æ³•1-1ï¼šä¸€åˆ†é’Ÿå†…ç”Ÿæˆä¸€åˆ†é’Ÿè§†é¢‘ç‰‡æ®µã€‹|Hongwei Yi, Shitong Shao, Tian Ye, Jiantong Zhao, Qingyu Yin, Michael Lingelbach, Li Yuan, Yonghong Tian .etc.|<http://arxiv.org/pdf/2502.07701v2>|<https://github.com/DA-Group-PKU/Magic-1-For-1.>|
|ğŸ“ æ›´æ–°|Surface Vision Mamba: Leveraging Bidirectional State Space Model for Efficient Spherical Manifold Representation|è¡¨é¢è§†è§‰èŸ’è›‡ï¼šåˆ©ç”¨åŒå‘çŠ¶æ€ç©ºé—´æ¨¡å‹å®ç°é«˜æ•ˆçš„çƒå½¢æµå½¢è¡¨ç¤º|Rongzhao He, Weihao Zheng, Leilei Zhao, Ying Wang, Dalin Zhu, Dan Wu, Bin Hu|<http://arxiv.org/pdf/2501.14679v4>|<https://github.com/Rongzhao-He/surface-vision-mamba.>|
|ğŸ“ æ›´æ–°|Coevolution of Camouflage|ä¼ªè£…çš„ååŒè¿›åŒ–|Craig Reynolds|<http://arxiv.org/pdf/2304.11793v3>|None|


## åŒ»å­¦åº”ç”¨

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Ocular Disease Classification Using CNN with Deep Convolutional Generative Adversarial Network|åŸºäºæ·±åº¦å·ç§¯ç”Ÿæˆå¯¹æŠ—ç½‘ç»œçš„è§†ç½‘è†œç–¾ç—…åˆ†ç±»|Arun Kunwar, Dibakar Raj Pant, Jukka Heikkonen, Rajeev Kanth|<http://arxiv.org/pdf/2502.10334v1>|None|
|ğŸ†• å‘å¸ƒ|QMaxViT-Unet+: A Query-Based MaxViT-Unet with Edge Enhancement for Scribble-Supervised Segmentation of Medical Images|QMaxViT-Unet+ï¼šä¸€ç§åŸºäºæŸ¥è¯¢çš„è¾¹ç¼˜å¢å¼ºMaxViT-Unetï¼Œç”¨äºæ¶‚é¸¦ç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²|Thien B. Nguyen-Tat, Hoang-An Vo, Phuoc-Sang Dang|<http://arxiv.org/pdf/2502.10294v1>|<https://github.com/anpc849/QMaxViT-Unet>|
|ğŸ†• å‘å¸ƒ|Artificial Intelligence to Assess Dental Findings from Panoramic Radiographs -- A Multinational Study|äººå·¥æ™ºèƒ½è¯„ä¼°å…¨æ™¯Xå…‰ç‰‡ä¸­çš„ç‰™ç§‘å‘ç°â€”â€”ä¸€é¡¹å¤šå›½ç ”ç©¶|Yin-Chih Chelsea Wang, Tsao-Lun Chen, Shankeeth Vinayahalingam, Tai-Hsien Wu, Chu Wei Chang, Hsuan Hao Chang, Hung-Jen Wei, Mu-Hsiung Chen .etc.|<http://arxiv.org/pdf/2502.10277v1>|None|
|ğŸ†• å‘å¸ƒ|TransGUNet: Transformer Meets Graph-based Skip Connection for Medical Image Segmentation|TransGUNetï¼šTransformeré‡è§åŸºäºå›¾è·³è¿çš„åŒ»å­¦å›¾åƒåˆ†å‰²|Ju-Hyeon Nam, Nur Suriza Syazwany, Sang-Chul Lee|<http://arxiv.org/pdf/2502.09931v1>|None|
|ğŸ†• å‘å¸ƒ|Dynamic-Computed Tomography Angiography for Cerebral Vessel Templates and Segmentation|åŠ¨æ€è®¡ç®—æœºæ–­å±‚æ‰«æè¡€ç®¡é€ å½±ç”¨äºè„‘éƒ¨è¡€ç®¡æ¨¡æ¿å’Œåˆ†å‰²|Shrikanth Yadav, Jisoo Kim, Geoffrey Young, Lei Qin|<http://arxiv.org/pdf/2502.09893v1>|None|
|ğŸ†• å‘å¸ƒ|HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation|å¥åº·GPTï¼šä¸€ç§é€šè¿‡å¼‚æ„çŸ¥è¯†é€‚åº”ç»Ÿä¸€ç†è§£å’Œç”Ÿæˆçš„åŒ»ç–—å¤§è§†è§‰-è¯­è¨€æ¨¡å‹|Tianwei Lin, Wenqiao Zhang, Sijing Li, Yuqian Yuan, Binhe Yu, Haoyuan Li, Wanggui He, Hao Jiang .etc.|<http://arxiv.org/pdf/2502.09838v1>|<https://github.com/DCDmllm/HealthGPT.>|
|ğŸ“ æ›´æ–°|The Devil is in the Prompts: De-Identification Traces Enhance Memorization Risks in Synthetic Chest X-Ray Generation|æ¶é­”è—åœ¨æç¤ºä¸­ï¼šå»æ ‡è¯†åŒ–ç—•è¿¹å¢å¼ºåˆæˆèƒ¸éƒ¨Xå…‰ç‰‡ç”Ÿæˆä¸­çš„è®°å¿†é£é™©|Raman Dutt|<http://arxiv.org/pdf/2502.07516v2>|None|
|ğŸ“ æ›´æ–°|MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin|åŒ»æ„Ÿ mimicï¼šåŸºäºåŒ»ç”Ÿçµæ„Ÿçš„å¤šæ¨¡æ€èåˆï¼Œç”¨äºä¸æ˜åŸå› å‘çƒ­çš„æ—©æœŸè¯Šæ–­|Minrui Chen, Yi Zhou, Huidong Jiang, Yuhan Zhu, Guanjie Zou, Minqi Chen, Rong Tian, Hiroto Saigo|<http://arxiv.org/pdf/2502.04794v2>|None|
|ğŸ“ æ›´æ–°|QTSeg: A Query Token-Based Dual-Mix Attention Framework with Multi-Level Feature Distribution for Medical Image Segmentation|QTSegï¼šåŸºäºæŸ¥è¯¢ä»¤ç‰Œçš„äºŒçº§æ··åˆæ³¨æ„åŠ›æ¡†æ¶ï¼Œç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²çš„å¤šçº§ç‰¹å¾åˆ†å¸ƒ|Phuong-Nam Tran, Nhat Truong Pham, Duc Ngoc Minh Dang, Eui-Nam Huh, Choong Seon Hong|<http://arxiv.org/pdf/2412.17241v2>|<https://github.com/tpnam0901/QTSeg>|
|ğŸ“ æ›´æ–°|SEW: Self-calibration Enhanced Whole Slide Pathology Image Analysis|SEWï¼šè‡ªæ ¡å‡†å¢å¼ºçš„å…¨åˆ‡ç‰‡ç—…ç†å›¾åƒåˆ†æ|Haoming Luo, Xiaotian Yu, Shengxuming Zhang, Jiabin Xia, Yang Jian, Yuning Sun, Liang Xue, Mingli Song .etc.|<http://arxiv.org/pdf/2412.10853v2>|None|
|ğŸ“ æ›´æ–°|A Comprehensive Framework for Automated Segmentation of Perivascular Spaces in Brain MRI with the nnU-Net|åŸºäºnnU-Netçš„è„‘éƒ¨MRIè¡€ç®¡å‘¨å›´é—´éš™è‡ªåŠ¨åˆ†å‰²çš„å…¨é¢æ¡†æ¶|William Pham, Alexander Jarema, Donggyu Rim, Zhibin Chen, Mohamed S. H. Khlif, Vaughan G. Macefield, Luke A. Henderson, Amy Brodtmann|<http://arxiv.org/pdf/2411.19564v2>|None|
|ğŸ“ æ›´æ–°|Intensity-Spatial Dual Masked Autoencoder for Multi-Scale Feature Learning in Chest CT Segmentation|èƒ¸éƒ¨CTåˆ†å‰²ä¸­çš„å¤šå°ºåº¦ç‰¹å¾å­¦ä¹ ç”¨å¼ºåº¦-ç©ºé—´åŒé‡æ©ç è‡ªåŠ¨ç¼–ç å™¨|Yuexing Ding, Jun Wang, Hongbing Lyu|<http://arxiv.org/pdf/2411.13198v2>|<https://github.com/prowontheus/ISD-MAE.>|
|ğŸ“ æ›´æ–°|SAM-LAD: Segment Anything Model Meets Zero-Shot Logic Anomaly Detection|SAM-LADï¼šSegment Anything Model é‡è§é›¶æ ·æœ¬é€»è¾‘å¼‚å¸¸æ£€æµ‹|Yun Peng, Xiao Lin, Nachuan Ma, Jiayuan Du, Chuangwei Liu, Chengju Liu, Qijun Chen|<http://arxiv.org/pdf/2406.00625v4>|None|
|ğŸ“ æ›´æ–°|Solving the enigma: Enhancing faithfulness and comprehensibility in explanations of deep networks|ç ´è§£è°œå›¢ï¼šå¢å¼ºæ·±åº¦ç½‘ç»œè§£é‡Šçš„å¿ å®æ€§å’Œå¯ç†è§£æ€§|Michail Mamalakis, Antonios Mamalakis, Ingrid Agartz, Lynn Egeland MÃ¸rch-Johnsen, Graham Murray, John Suckling, Pietro Lio|<http://arxiv.org/pdf/2405.10008v2>|None|
|ğŸ“ æ›´æ–°|Why does my medical AI look at pictures of birds? Exploring the efficacy of transfer learning across domain boundaries|ä¸ºä»€ä¹ˆæˆ‘çš„åŒ»ç–—AIä¼šçœ‹é¸Ÿçš„å›¾ç‰‡ï¼Ÿæ¢ç´¢è·¨é¢†åŸŸè¾¹ç•Œè¿ç§»å­¦ä¹ çš„æœ‰æ•ˆæ€§|Frederic Jonske, Moon Kim, Enrico Nasca, Janis Evers, Johannes Haubold, RenÃ© Hosch, Felix Nensa, Michael Kamp .etc.|<http://arxiv.org/pdf/2306.17555v2>|None|

