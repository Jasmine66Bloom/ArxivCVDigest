## [UPDATED!] **2025-02-17** (Update Time)


## å›¾åƒç†è§£

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|NaturalL2S: End-to-End High-quality Multispeaker Lip-to-Speech Synthesis with Differential Digital Signal Processing|è‡ªç„¶L2Sï¼šåŸºäºå¾®åˆ†æ•°å­—ä¿¡å·å¤„ç†çš„ç«¯åˆ°ç«¯é«˜è´¨é‡å¤šè¯´è¯äººå”‡è¯­åˆæˆ|Yifan Liang, Fangkun Liu, Andong Li, Xiaodong Li, Chengshi Zheng|<http://arxiv.org/pdf/2502.12002v1>|<https://yifan-liang.github.io/NaturalL2S>|
|ğŸ†• å‘å¸ƒ|GeoDANO: Geometric VLM with Domain Agnostic Vision Encoder|GeoDANOï¼šåŸŸæ— å…³çš„å‡ ä½•è§†è§‰è¯­è¨€æ¨¡å‹|Seunghyuk Cho, Zhenyue Qin, Yang Liu, Youngbin Choi, Seungbeom Lee, Dongwoo Kim|<http://arxiv.org/pdf/2502.11360v1>|None|
|ğŸ“ æ›´æ–°|VidSketch: Hand-drawn Sketch-Driven Video Generation with Diffusion Control|VidSketchï¼šåŸºäºæ‰‹ç»˜è‰å›¾é©±åŠ¨çš„è§†é¢‘ç”Ÿæˆä¸æ‰©æ•£æ§åˆ¶|Lifan Jiang, Shuang Chen, Boxi Wu, Xiaotong Guan, Jiahui Zhang|<http://arxiv.org/pdf/2502.01101v2>|None|
|ğŸ“ æ›´æ–°|Evaluation of End-to-End Continuous Spanish Lipreading in Different Data Conditions|ä¸åŒæ•°æ®æ¡ä»¶ä¸‹ç«¯åˆ°ç«¯è¿ç»­è¥¿ç­ç‰™è¯­å”‡è¯»è¯„ä¼°|David Gimeno-GÃ³mez, Carlos-D. MartÃ­nez-Hinarejos|<http://arxiv.org/pdf/2502.00464v2>|<https://github.com/david-gimeno/evaluating-end2end-spanish-lipreading.>|
|ğŸ“ æ›´æ–°|CLEAR: Character Unlearning in Textual and Visual Modalities|æ¸…æ™°ï¼šæ–‡æœ¬å’Œè§†è§‰æ¨¡æ€ä¸­çš„å­—ç¬¦å»å­¦ä¹ |Alexey Dontsov, Dmitrii Korzh, Alexey Zhavoronkin, Boris Mikheev, Denis Bobkov, Aibek Alanov, Oleg Y. Rogov, Ivan Oseledets .etc.|<http://arxiv.org/pdf/2410.18057v3>|None|
|ğŸ“ æ›´æ–°|PrototypeFormer: Learning to Explore Prototype Relationships for Few-shot Image Classification|åŸå‹Formerï¼šå­¦ä¹ æ¢ç´¢åŸå‹å…³ç³»è¿›è¡Œå°æ ·æœ¬å›¾åƒåˆ†ç±»|Meijuan Su, Feihong He, Fanzhang Li|<http://arxiv.org/pdf/2310.03517v2>|None|


## æ£€æµ‹åˆ†å‰²

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Enhancing Transparent Object Pose Estimation: A Fusion of GDR-Net and Edge Detection|å¢å¼ºé€æ˜ç‰©ä½“å§¿æ€ä¼°è®¡ï¼šGDR-Netä¸è¾¹ç¼˜æ£€æµ‹çš„èåˆ|Tessa Pulli, Peter HÃ¶nig, Stefan Thalhammer, Matthias Hirschmanner, Markus Vincze|<http://arxiv.org/pdf/2502.12027v1>|None|
|ğŸ†• å‘å¸ƒ|Image Inversion: A Survey from GANs to Diffusion and Beyond|å›¾åƒåè½¬ï¼šä»GANåˆ°æ‰©æ•£æ¨¡å‹åŠæ›´è¿œçš„ç ”ç©¶ç»¼è¿°|Yinan Chen, Jiangning Zhang, Yali Bi, Xiaobin Hu, Teng Hu, Zhucun Xue, Ran Yi, Yong Liu .etc.|<http://arxiv.org/pdf/2502.11974v1>|<https://github.com/RyanChenYN/ImageInversion>|
|ğŸ†• å‘å¸ƒ|From Open-Vocabulary to Vocabulary-Free Semantic Segmentation|ä»å¼€æ”¾è¯æ±‡åˆ°æ— è¯æ±‡è¯­ä¹‰åˆ†å‰²|Klara Reichard, Giulia Rizzoli, Stefano Gasperini, Lukas Hoyer, Pietro Zanuttigh, Nassir Navab, Federico Tombari|<http://arxiv.org/pdf/2502.11891v1>|None|
|ğŸ†• å‘å¸ƒ|Lightweight Deepfake Detection Based on Multi-Feature Fusion|è½»é‡çº§å¤šç‰¹å¾èåˆæ·±åº¦ä¼ªé€ æ£€æµ‹|Siddiqui Muhammad Yasir, Hyun Kim|<http://arxiv.org/pdf/2502.11763v1>|None|
|ğŸ†• å‘å¸ƒ|Component-aware Unsupervised Logical Anomaly Generation for Industrial Anomaly Detection|ç»„ä»¶æ„ŸçŸ¥çš„æ— ç›‘ç£é€»è¾‘å¼‚å¸¸ç”Ÿæˆç”¨äºå·¥ä¸šå¼‚å¸¸æ£€æµ‹|Xuan Tong, Yang Chang, Qing Zhao, Jiawen Yu, Boyang Wang, Junxiong Lin, Yuxuan Lin, Xinji Mai .etc.|<http://arxiv.org/pdf/2502.11712v1>|None|
|ğŸ“ æ›´æ–°|Knowledge Swapping via Learning and Unlearning|é€šè¿‡å­¦ä¹ å’Œé—å¿˜è¿›è¡ŒçŸ¥è¯†äº¤æ¢|Mingyu Xing, Lechao Cheng, Shengeng Tang, Yaxiong Wang, Zhun Zhong, Meng Wang|<http://arxiv.org/pdf/2502.08075v2>|<https://github.com/xingmingyu123456/KnowledgeSwapping>|
|ğŸ“ æ›´æ–°|Demystifying Catastrophic Forgetting in Two-Stage Incremental Object Detector|æ­ç§˜ä¸¤é˜¶æ®µå¢é‡ç›®æ ‡æ£€æµ‹ä¸­çš„ç¾éš¾æ€§é—å¿˜|Qirui Wu, Shizhou Zhang, De Cheng, Yinghui Xing, Di Xu, Peng Wang, Yanning Zhang|<http://arxiv.org/pdf/2502.05540v2>|None|
|ğŸ“ æ›´æ–°|iFormer: Integrating ConvNet and Transformer for Mobile Application|iFormerï¼šèåˆå·ç§¯ç¥ç»ç½‘ç»œå’ŒTransformerç”¨äºç§»åŠ¨åº”ç”¨|Chuanyang Zheng|<http://arxiv.org/pdf/2501.15369v2>|None|
|ğŸ“ æ›´æ–°|SynCo: Synthetic Hard Negatives for Contrastive Visual Representation Learning|SynCoï¼šç”¨äºå¯¹æ¯”è§†è§‰è¡¨å¾å­¦ä¹ çš„åˆæˆç¡¬è´Ÿæ ·æœ¬|Nikolaos Giakoumoglou, Tania Stathaki|<http://arxiv.org/pdf/2410.02401v7>|None|
|ğŸ“ æ›´æ–°|High-quality Unknown Object Instance Segmentation via Quadruple Boundary Error Refinement|é«˜è´¨é‡æœªçŸ¥å®ä¾‹åˆ†å‰²é€šè¿‡å››é‡è¾¹ç•Œè¯¯å·®ç»†åŒ–|Seunghyeok Back, Sangbeom Lee, Kangmin Kim, Joosoon Lee, Sungho Shin, Jemo Maeng, Kyoobin Lee|<http://arxiv.org/pdf/2306.16132v4>|None|


## è§†é¢‘ç†è§£

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Unhackable Temporal Rewarding for Scalable Video MLLMs|ä¸å¯ç¯¡æ”¹çš„æ—¶é—´å¥–åŠ±ç”¨äºå¯æ‰©å±•çš„è§†é¢‘å¤šè¯­è¨€è¯­è¨€æ¨¡å‹|En Yu, Kangheng Lin, Liang Zhao, Yana Wei, Zining Zhu, Haoran Wei, Jianjian Sun, Zheng Ge .etc.|<http://arxiv.org/pdf/2502.12081v1>|None|
|ğŸ†• å‘å¸ƒ|iMOVE: Instance-Motion-Aware Video Understanding|iMOVEï¼šå®ä¾‹è¿åŠ¨æ„ŸçŸ¥è§†é¢‘ç†è§£|Jiaze Li, Yaya Shi, Zongyang Ma, Haoran Xu, Feng Cheng, Huihui Xiao, Ruiwen Kang, Fan Yang .etc.|<http://arxiv.org/pdf/2502.11594v1>|None|
|ğŸ“ æ›´æ–°|Advances in Multimodal Adaptation and Generalization: From Traditional Approaches to Foundation Models|å¤šæ¨¡æ€é€‚åº”ä¸æ³›åŒ–è¿›å±•ï¼šä»ä¼ ç»Ÿæ–¹æ³•åˆ°åŸºç¡€æ¨¡å‹|Hao Dong, Moru Liu, Kaiyang Zhou, Eleni Chatzi, Juho Kannala, Cyrill Stachniss, Olga Fink|<http://arxiv.org/pdf/2501.18592v3>|<https://github.com/donghao51/Awesome-Multimodal-Adaptation.>|
|ğŸ“ æ›´æ–°|Deep Learning and Hybrid Approaches for Dynamic Scene Analysis, Object Detection and Motion Tracking|æ·±åº¦å­¦ä¹ ä¸æ··åˆæ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯åˆ†æã€ç›®æ ‡æ£€æµ‹ä¸è¿åŠ¨è·Ÿè¸ªä¸­çš„åº”ç”¨|Shahran Rahman Alve|<http://arxiv.org/pdf/2412.05331v3>|None|


## ç”Ÿæˆæ¨¡å‹

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Diffusion-Sharpening: Fine-tuning Diffusion Models with Denoising Trajectory Sharpening|æ‰©æ•£é”åŒ–ï¼šä½¿ç”¨å»å™ªè½¨è¿¹é”åŒ–å¾®è°ƒæ‰©æ•£æ¨¡å‹|Ye Tian, Ling Yang, Xinchen Zhang, Yunhai Tong, Mengdi Wang, Bin Cui|<http://arxiv.org/pdf/2502.12146v1>|<https://github.com/Gen-Verse/Diffusion-Sharpening>|
|ğŸ†• å‘å¸ƒ|MagicArticulate: Make Your 3D Models Articulation-Ready|é­”å¹» articulateï¼šè®©ä½ çš„ 3D æ¨¡å‹å‡†å¤‡å¥½å…³èŠ‚æ´»åŠ¨|Chaoyue Song, Jianfeng Zhang, Xiu Li, Fan Yang, Yiwen Chen, Zhongcong Xu, Jun Hao Liew, Xiaoyang Guo .etc.|<http://arxiv.org/pdf/2502.12135v1>|<https://chaoyuesong.github.io/MagicArticulate.>|
|ğŸ†• å‘å¸ƒ|Descriminative-Generative Custom Tokens for Vision-Language Models|è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­çš„åˆ¤åˆ«-ç”Ÿæˆå®šåˆ¶æ ‡è®°|Pramuditha Perera, Matthew Trager, Luca Zancato, Alessandro Achille, Stefano Soatto|<http://arxiv.org/pdf/2502.12095v1>|None|
|ğŸ†• å‘å¸ƒ|DLFR-VAE: Dynamic Latent Frame Rate VAE for Video Generation|åŠ¨æ€æ½œåœ¨å¸§ç‡å˜åˆ†è‡ªç¼–ç å™¨ç”¨äºè§†é¢‘ç”Ÿæˆ|Zhihang Yuan, Siyuan Wang, Rui Xie, Hanling Zhang, Tongcheng Fang, Yuzhang Shang, Shengen Yan, Guohao Dai .etc.|<http://arxiv.org/pdf/2502.11897v1>|None|
|ğŸ†• å‘å¸ƒ|MVTokenFlow: High-quality 4D Content Generation using Multiview Token Flow|MVTokenFlowï¼šåŸºäºå¤šè§†å›¾Tokenæµçš„4Dé«˜è´¨é‡å†…å®¹ç”Ÿæˆ|Hanzhuo Huang, Yuan Liu, Ge Zheng, Jiepeng Wang, Zhiyang Dou, Sibei Yang|<http://arxiv.org/pdf/2502.11697v1>|None|
|ğŸ†• å‘å¸ƒ|Membership Inference Attacks for Face Images Against Fine-Tuned Latent Diffusion Models|é’ˆå¯¹å¾®è°ƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„å¯¹æŠ—äººè„¸å›¾åƒæˆå‘˜æ¨ç†æ”»å‡»|Lauritz Christian Holme, Anton Mosquera Storgaard, Siavash Arjomand Bigdeli|<http://arxiv.org/pdf/2502.11619v1>|None|
|ğŸ†• å‘å¸ƒ|Control-CLIP: Decoupling Category and Style Guidance in CLIP for Specific-Domain Generation|æ§åˆ¶-CLIPï¼šåœ¨CLIPä¸­è§£è€¦ç±»åˆ«å’Œé£æ ¼æŒ‡å¯¼ä»¥å®ç°ç‰¹å®šé¢†åŸŸç”Ÿæˆ|Zexi Jia, Chuanwei Huang, Hongyan Fei, Yeshuang Zhu, Zhiqiang Yuan, Jinchao Zhang, Jie Zhou|<http://arxiv.org/pdf/2502.11532v1>|None|
|ğŸ†• å‘å¸ƒ|SayAnything: Audio-Driven Lip Synchronization with Conditional Video Diffusion|ä»»ä½•è¯è¯­ï¼šæ¡ä»¶è§†é¢‘æ‰©æ•£é©±åŠ¨çš„éŸ³é¢‘å”‡åŒæ­¥|Junxian Ma, Shiwen Wang, Jian Yang, Junyi Hu, Jian Liang, Guosheng Lin, Jingbo chen, Kai Li .etc.|<http://arxiv.org/pdf/2502.11515v1>|None|
|ğŸ†• å‘å¸ƒ|Learning to Sample Effective and Diverse Prompts for Text-to-Image Generation|å­¦ä¹ ä¸ºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆé‡‡æ ·æœ‰æ•ˆä¸”å¤šæ ·åŒ–çš„æç¤º|Taeyoung Yun, Dinghuai Zhang, Jinkyoo Park, Ling Pan|<http://arxiv.org/pdf/2502.11477v1>|None|
|ğŸ“ æ›´æ–°|Efficient-vDiT: Efficient Video Diffusion Transformers With Attention Tile|é«˜æ•ˆ-vDiTï¼šå…·æœ‰æ³¨æ„åŠ›ç“¦ç‰‡çš„è§†é¢‘æ‰©æ•£Transformer|Hangliang Ding, Dacheng Li, Runlong Su, Peiyuan Zhang, Zhijie Deng, Ion Stoica, Hao Zhang|<http://arxiv.org/pdf/2502.06155v2>|None|
|ğŸ“ æ›´æ–°|SAT-LDM: Provably Generalizable Image Watermarking for Latent Diffusion Models with Self-Augmented Training|SAT-LDMï¼šåŸºäºè‡ªå¢å¼ºè®­ç»ƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹å›¾åƒæ°´å°çš„è¯æ˜æ³›åŒ–|Lu Zhang, Liang Zeng|<http://arxiv.org/pdf/2501.00463v2>|None|
|ğŸ“ æ›´æ–°|Adapting Image-to-Video Diffusion Models for Large-Motion Frame Interpolation|é€‚åº”å¤§è¿åŠ¨å¸§æ’å€¼çš„å›¾åƒåˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹|Luoxu Jin, Hiroshi Watanabe|<http://arxiv.org/pdf/2412.17042v3>|None|
|ğŸ“ æ›´æ–°|Growth Inhibitors for Suppressing Inappropriate Image Concepts in Diffusion Models|æŠ‘åˆ¶æ‰©æ•£æ¨¡å‹ä¸­ä¸é€‚å½“å›¾åƒæ¦‚å¿µçš„æŠ‘åˆ¶å‰‚ç ”ç©¶|Die Chen, Zhiwen Li, Mingyuan Fan, Cen Chen, Wenmeng Zhou, Yanhao Wang, Yaliang Li|<http://arxiv.org/pdf/2408.01014v2>|None|
|ğŸ“ æ›´æ–°|STAR: Scale-wise Text-conditioned AutoRegressive image generation|STARï¼šåŸºäºå°ºåº¦æ–‡æœ¬æ¡ä»¶çš„è‡ªå›å½’å›¾åƒç”Ÿæˆ|Xiaoxiao Ma, Mohan Zhou, Tao Liang, Yalong Bai, Tiejun Zhao, Biye Li, Huaian Chen, Yi Jin|<http://arxiv.org/pdf/2406.10797v2>|None|
|ğŸ“ æ›´æ–°|MoLA: Motion Generation and Editing with Latent Diffusion Enhanced by Adversarial Training|MoLAï¼šé€šè¿‡å¯¹æŠ—è®­ç»ƒå¢å¼ºçš„æ½œåœ¨æ‰©æ•£è¿åŠ¨ç”Ÿæˆä¸ç¼–è¾‘|Kengo Uchida, Takashi Shibuya, Yuhta Takida, Naoki Murata, Julian Tanke, Shusuke Takahashi, Yuki Mitsufuji|<http://arxiv.org/pdf/2406.01867v3>|None|
|ğŸ“ æ›´æ–°|Hiding and Recovering Knowledge in Text-to-Image Diffusion Models via Learnable Prompts|é€šè¿‡å¯å­¦ä¹ æç¤ºåœ¨æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­éšè—å’Œæ¢å¤çŸ¥è¯†|Anh Bui, Khanh Doan, Trung Le, Paul Montague, Tamas Abraham, Dinh Phung|<http://arxiv.org/pdf/2403.12326v3>|None|


## æ‰©æ•£æ¡¥

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Diffusion Models without Classifier-free Guidance|æ— åˆ†ç±»å™¨å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹|Zhicong Tang, Jianmin Bao, Dong Chen, Baining Guo|<http://arxiv.org/pdf/2502.12154v1>|<https://github.com/tzco/Diffusion-wo-CFG.>|


## å›¾åƒå¤„ç†

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|On the Logic Elements Associated with Round-Off Errors and Gaussian Blur in Image Registration: A Simple Case of Commingling|å…³äºå›¾åƒé…å‡†ä¸­ä¸èˆå…¥è¯¯å·®å’Œé«˜æ–¯æ¨¡ç³Šç›¸å…³çš„é€»è¾‘å…ƒç´ ï¼šæ··åˆçš„ç®€å•æ¡ˆä¾‹|Serap A. Savari|<http://arxiv.org/pdf/2502.11992v1>|None|
|ğŸ†• å‘å¸ƒ|ILIAS: Instance-Level Image retrieval At Scale|ILIASï¼šå¤§è§„æ¨¡å®ä¾‹çº§å›¾åƒæ£€ç´¢|Giorgos Kordopatis-Zilos, Vladan StojniÄ‡, Anna Manko, Pavel Å uma, Nikolaos-Antonios Ypsilantis, Nikos Efthymiadis, Zakaria Laskar, JiÅ™Ã­ Matas .etc.|<http://arxiv.org/pdf/2502.11748v1>|None|
|ğŸ†• å‘å¸ƒ|GraphMorph: Tubular Structure Extraction by Morphing Predicted Graphs|å›¾å½¢å½¢æ€ï¼šé€šè¿‡å½¢æ€é¢„æµ‹å›¾æå–ç®¡çŠ¶ç»“æ„|Zhao Zhang, Ziwei Zhao, Dong Wang, Liwei Wang|<http://arxiv.org/pdf/2502.11731v1>|None|
|ğŸ†• å‘å¸ƒ|The Worse The Better: Content-Aware Viewpoint Generation Network for Projection-related Point Cloud Quality Assessment|è¶Šå·®è¶Šå¥½ï¼šç”¨äºæŠ•å½±ç›¸å…³ç‚¹äº‘è´¨é‡è¯„ä¼°çš„å†…å®¹æ„ŸçŸ¥è§†è§’ç”Ÿæˆç½‘ç»œ|Zhiyong Su, Bingxu Xie, Zheng Li, Jincan Wu, Weiqing Li|<http://arxiv.org/pdf/2502.11710v1>|None|
|ğŸ†• å‘å¸ƒ|Object-Centric Image to Video Generation with Language Guidance|ä»¥è¯­è¨€å¼•å¯¼ä¸ºä¸­å¿ƒçš„å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆ|Angel Villar-Corrales, Gjergj Plepi, Sven Behnke|<http://arxiv.org/pdf/2502.11655v1>|<https://play-slot.github.io/TextOCVP>|
|ğŸ†• å‘å¸ƒ|Semantically Robust Unsupervised Image Translation for Paired Remote Sensing Images|è¯­ä¹‰é²æ£’çš„æˆå¯¹é¥æ„Ÿå›¾åƒæ— ç›‘ç£å›¾åƒç¿»è¯‘|Sheng Fang, Kaiyu Li, Zhe Li, Jianli Zhao, Xingli Zhang|<http://arxiv.org/pdf/2502.11468v1>|None|
|ğŸ†• å‘å¸ƒ|Precise GPS-Denied UAV Self-Positioning via Context-Enhanced Cross-View Geo-Localization|åŸºäºä¸Šä¸‹æ–‡å¢å¼ºçš„è·¨è§†å›¾åœ°ç†å®šä½å®ç°ç²¾ç¡®çš„GPSæ‹’ç»æ— äººæœºè‡ªå®šä½|Yuanze Xu, Ming Dai, Wenxiao Cai, Wankou Yang|<http://arxiv.org/pdf/2502.11408v1>|None|
|ğŸ†• å‘å¸ƒ|A Physics-Informed Blur Learning Framework for Imaging Systems|åŸºäºç‰©ç†ä¿¡æ¯çš„æˆåƒç³»ç»Ÿæ¨¡ç³Šå­¦ä¹ æ¡†æ¶|Liqun Chen, Yuxuan Li, Jun Dai, Jinwei Gu, Tianfan Xue|<http://arxiv.org/pdf/2502.11382v1>|None|
|ğŸ“ æ›´æ–°|Compress image to patches for Vision Transformer|å‹ç¼©å›¾åƒä¸ºè¡¥ä¸ä»¥ç”¨äºè§†è§‰Transformer|Xinfeng Zhao, Yaoru Sun|<http://arxiv.org/pdf/2502.10120v2>|None|
|ğŸ“ æ›´æ–°|Cluster and Predict Latent Patches for Improved Masked Image Modeling|èšç±»å’Œé¢„æµ‹æ½œåœ¨è¡¥ä¸ä»¥æ”¹è¿›æ©ç å›¾åƒå»ºæ¨¡|TimothÃ©e Darcet, Federico Baldassarre, Maxime Oquab, Julien Mairal, Piotr Bojanowski|<http://arxiv.org/pdf/2502.08769v2>|None|
|ğŸ“ æ›´æ–°|Vision CNNs trained to estimate spatial latents learned similar ventral-stream-aligned representations|è§†è§‰CNNsè®­ç»ƒä»¥ä¼°è®¡ç©ºé—´æ½œåœ¨å˜é‡ï¼Œå­¦ä¹ åˆ°ä¸è…¹ä¾§æµå¯¹é½çš„ç›¸ä¼¼è¡¨ç¤º|Yudi Xie, Weichen Huang, Esther Alter, Jeremy Schwartz, Joshua B. Tenenbaum, James J. DiCarlo|<http://arxiv.org/pdf/2412.09115v2>|None|
|ğŸ“ æ›´æ–°|Parametric PerceptNet: A bio-inspired deep-net trained for Image Quality Assessment|å‚æ•°æ„ŸçŸ¥ç½‘ç»œï¼šä¸€ç§ç”¨äºå›¾åƒè´¨é‡è¯„ä¼°çš„ç”Ÿç‰©å¯å‘æ·±åº¦ç½‘ç»œ|Jorge Vila-TomÃ¡s, Pablo HernÃ¡ndez-CÃ¡mara, Valero Laparra, JesÃºs Malo|<http://arxiv.org/pdf/2412.03210v2>|None|
|ğŸ“ æ›´æ–°|Towards Scalable Insect Monitoring: Ultra-Lightweight CNNs as On-Device Triggers for Insect Camera Traps|é¢å‘å¯æ‰©å±•çš„æ˜†è™«ç›‘æµ‹ï¼šè¶…è½»é‡çº§CNNä½œä¸ºè®¾å¤‡ç«¯æ˜†è™«ç›¸æœºé™·é˜±çš„è§¦å‘å™¨|Ross Gardiner, Sareh Rowands, Benno I. Simmons|<http://arxiv.org/pdf/2411.14467v2>|None|
|ğŸ“ æ›´æ–°|Object-Attribute-Relation Representation Based Video Semantic Communication|åŸºäºå¯¹è±¡-å±æ€§-å…³ç³»è¡¨ç¤ºçš„è§†é¢‘è¯­ä¹‰é€šä¿¡|Qiyuan Du, Yiping Duan, Qianqian Yang, Xiaoming Tao, MÃ©rouane Debbah|<http://arxiv.org/pdf/2406.10469v2>|None|
|ğŸ“ æ›´æ–°|REP: Resource-Efficient Prompting for Rehearsal-Free Continual Learning|èµ„æºé«˜æ•ˆçš„æ— é‡æ”¾æŒç»­å­¦ä¹ æç¤ºæ–¹æ³•|Sungho Jeon, Xinyue Ma, Kwang In Kim, Myeongjae Jeon|<http://arxiv.org/pdf/2406.04772v3>|None|
|ğŸ“ æ›´æ–°|IRSRMamba: Infrared Image Super-Resolution via Mamba-based Wavelet Transform Feature Modulation Model|çº¢å¤–å›¾åƒè¶…åˆ†è¾¨ç‡ï¼šåŸºäºMambaå°æ³¢å˜æ¢ç‰¹å¾è°ƒåˆ¶æ¨¡å‹|Yongsong Huang, Tomo Miyazaki, Xiaofeng Liu, Shinichiro Omachi|<http://arxiv.org/pdf/2405.09873v2>|<https://github.com/yongsongH/IRSRMamba.>|
|ğŸ“ æ›´æ–°|Understanding Figurative Meaning through Explainable Visual Entailment|é€šè¿‡å¯è§£é‡Šè§†è§‰è•´æ¶µç†è§£æ¯”å–»æ„ä¹‰|Arkadiy Saakyan, Shreyas Kulkarni, Tuhin Chakrabarty, Smaranda Muresan|<http://arxiv.org/pdf/2405.01474v3>|None|


## 3Dåœºæ™¯

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|FLARE: Feed-forward Geometry, Appearance and Camera Estimation from Uncalibrated Sparse Views|FLAREï¼šä»æœªæ ¡å‡†çš„ç¨€ç–è§†å›¾ä¸­è¿›è¡Œå‰é¦ˆå‡ ä½•ã€å¤–è§‚å’Œç›¸æœºä¼°è®¡|Shangzhan Zhang, Jianyuan Wang, Yinghao Xu, Nan Xue, Christian Rupprecht, Xiaowei Zhou, Yujun Shen, Gordon Wetzstein|<http://arxiv.org/pdf/2502.12138v1>|<https://zhanghe3z.github.io/FLARE>|
|ğŸ†• å‘å¸ƒ|pySLAM: An Open-Source, Modular, and Extensible Framework for SLAM|pySLAMï¼šä¸€ä¸ªå¼€æºã€æ¨¡å—åŒ–å’Œå¯æ‰©å±•çš„SLAMæ¡†æ¶|Luigi Freda|<http://arxiv.org/pdf/2502.11955v1>|None|
|ğŸ†• å‘å¸ƒ|Deep Neural Networks for Accurate Depth Estimation with Latent Space Features|æ·±åº¦ç¥ç»ç½‘ç»œç»“åˆæ½œåœ¨ç©ºé—´ç‰¹å¾è¿›è¡Œç²¾ç¡®æ·±åº¦ä¼°è®¡|Siddiqui Muhammad Yasir, Hyunsik Ahn|<http://arxiv.org/pdf/2502.11777v1>|None|
|ğŸ†• å‘å¸ƒ|Range and Bird's Eye View Fused Cross-Modal Visual Place Recognition|èŒƒå›´ä¸é¸Ÿç°è§†å›¾èåˆçš„è·¨æ¨¡æ€è§†è§‰åœ°ç‚¹è¯†åˆ«|Jianyi Peng, Fan Lu, Bin Li, Yuan Huang, Sanqing Qu, Guang Chen|<http://arxiv.org/pdf/2502.11742v1>|None|
|ğŸ†• å‘å¸ƒ|MaskGWM: A Generalizable Driving World Model with Video Mask Reconstruction|MaskGWMï¼šä¸€ç§å…·æœ‰è§†é¢‘æ©ç é‡å»ºçš„é€šç”¨é©¾é©¶ä¸–ç•Œæ¨¡å‹|Jingcheng Ni, Yuxin Guo, Yichen Liu, Rui Chen, Lewei Lu, Zehuan Wu|<http://arxiv.org/pdf/2502.11663v1>|None|
|ğŸ†• å‘å¸ƒ|SurgPose: a Dataset for Articulated Robotic Surgical Tool Pose Estimation and Tracking|SurgPoseï¼šç”¨äºå…³èŠ‚å¼æœºå™¨äººæ‰‹æœ¯å·¥å…·å§¿æ€ä¼°è®¡ä¸è·Ÿè¸ªçš„æ•°æ®é›†|Zijian Wu, Adam Schmidt, Randy Moore, Haoying Zhou, Alexandre Banks, Peter Kazanzides, Septimiu E. Salcudean|<http://arxiv.org/pdf/2502.11534v1>|None|
|ğŸ†• å‘å¸ƒ|MARS: Mesh AutoRegressive Model for 3D Shape Detailization|MARSï¼šç”¨äº3Då½¢çŠ¶ç»†èŠ‚åŒ–çš„ç½‘æ ¼è‡ªå›å½’æ¨¡å‹|Jingnan Gao, Weizhe Liu, Weixuan Sun, Senbo Wang, Xibin Song, Taizhang Shang, Shenzhou Chen, Hongdong Li .etc.|<http://arxiv.org/pdf/2502.11390v1>|None|
|ğŸ“ æ›´æ–°|DINeuro: Distilling Knowledge from 2D Natural Images via Deformable Tubular Transferring Strategy for 3D Neuron Reconstruction|DINeuroï¼šé€šè¿‡å¯å˜å½¢ç®¡çŠ¶è¿ç§»ç­–ç•¥ä»äºŒç»´è‡ªç„¶å›¾åƒä¸­æå–çŸ¥è¯†ä»¥è¿›è¡Œä¸‰ç»´ç¥ç»å…ƒé‡å»º|Yik San Cheng, Runkai Zhao, Heng Wang, Hanchuan Peng, Yui Lo, Yuqian Chen, Lauren J. O'Donnell, Weidong Cai|<http://arxiv.org/pdf/2410.22078v2>|None|
|ğŸ“ æ›´æ–°|Global-Local Distillation Network-Based Audio-Visual Speaker Tracking with Incomplete Modalities|åŸºäºå…¨å±€-å±€éƒ¨è’¸é¦ç½‘ç»œçš„éŸ³é¢‘-è§†è§‰è¯´è¯äººè·Ÿè¸ªåŠå…¶ä¸å®Œæ•´æ¨¡æ€|Yidi Li, Yihan Li, Yixin Guo, Bin Ren, Zhenhuan Xu, Hao Guo, Hong Liu, Nicu Sebe|<http://arxiv.org/pdf/2408.14585v2>|None|


## ç¥ç»æ¸²æŸ“

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|HumanGif: Single-View Human Diffusion with Generative Prior|HumanGifï¼šåŸºäºç”Ÿæˆå…ˆéªŒçš„å•è§†è§’äººä½“æ‰©æ•£|Shoukang Hu, Takuya Narihira, Kazumi Fukuda, Ryosuke Sawata, Takashi Shibuya, Yuki Mitsufuji|<http://arxiv.org/pdf/2502.12080v1>|None|
|ğŸ†• å‘å¸ƒ|Predicting Next-Day Wildfire Spread with Time Series and Attention|é¢„æµ‹æ¬¡æ—¥æ£®æ—ç«ç¾è”“å»¶ï¼šæ—¶é—´åºåˆ—ä¸æ³¨æ„åŠ›æœºåˆ¶|Saad Lahrichi, Jesse Johnson, Jordan Malof|<http://arxiv.org/pdf/2502.12003v1>|None|
|ğŸ†• å‘å¸ƒ|ChordFormer: A Conformer-Based Architecture for Large-Vocabulary Audio Chord Recognition|å’Œå¼¦å‰å¥æ›²ï¼šä¸€ç§åŸºäºConformerçš„å¤§è¯æ±‡é‡éŸ³é¢‘å’Œå¼¦è¯†åˆ«æ¶æ„|Muhammad Waseem Akram, Stefano Dettori, Valentina Colla, Giorgio Carlo Buttazzo|<http://arxiv.org/pdf/2502.11840v1>|None|
|ğŸ†• å‘å¸ƒ|Intuitive physics understanding emerges from self-supervised pretraining on natural videos|ä»è‡ªç„¶è§†é¢‘ä¸­è‡ªç›‘ç£é¢„è®­ç»ƒä¸­æ¶Œç°çš„ç›´è§‚ç‰©ç†ç†è§£|Quentin Garrido, Nicolas Ballas, Mahmoud Assran, Adrien Bardes, Laurent Najman, Michael Rabbat, Emmanuel Dupoux, Yann LeCun|<http://arxiv.org/pdf/2502.11831v1>|None|
|ğŸ†• å‘å¸ƒ|On the Computation of the Fisher Information in Continual Learning|å…³äºæŒç»­å­¦ä¹ ä¸­Fisherä¿¡æ¯çš„è®¡ç®—|Gido M. van de Ven|<http://arxiv.org/pdf/2502.11756v1>|None|
|ğŸ†• å‘å¸ƒ|Adversarially Robust CLIP Models Can Induce Better (Robust) Perceptual Metrics|å¯¹æŠ—é²æ£’çš„CLIPæ¨¡å‹å¯ä»¥è¯±å¯¼æ›´å¥½çš„ï¼ˆé²æ£’ï¼‰æ„ŸçŸ¥åº¦é‡|Francesco Croce, Christian Schlarmann, Naman Deep Singh, Matthias Hein|<http://arxiv.org/pdf/2502.11725v1>|None|
|ğŸ†• å‘å¸ƒ|Real-time Neural Rendering of LiDAR Point Clouds|å®æ—¶æ¿€å…‰é›·è¾¾ç‚¹äº‘ç¥ç»æ¸²æŸ“|Joni Vanherck, Brent Zoomers, Tom Mertens, Lode Jorissen, Nick Michiels|<http://arxiv.org/pdf/2502.11618v1>|None|
|ğŸ“ æ›´æ–°|BoxMAC -- A Boxing Dataset for Multi-label Action Classification|BoxMAC -- å¤šæ ‡ç­¾åŠ¨ä½œåˆ†ç±»çš„æ‹³å‡»æ•°æ®é›†|Shashikanta Sahoo|<http://arxiv.org/pdf/2412.18204v2>|None|
|ğŸ“ æ›´æ–°|IOVS4NeRF:Incremental Optimal View Selection for Large-Scale NeRFs|IOVS4NeRFï¼šå¤§è§„æ¨¡NeRFçš„å¢é‡æœ€ä¼˜è§†è§’é€‰æ‹©|Jingpeng Xie, Shiyu Tan, Yuanlei Wang, Tianle Du, Yifei Xue, Yizhen Lao|<http://arxiv.org/pdf/2407.18611v3>|None|
|ğŸ“ æ›´æ–°|Variable Radiance Field for Real-World Category-Specific Reconstruction from Single Image|å¯å˜è¾å°„åœºï¼šä»å•å¼ å›¾åƒå®ç°çœŸå®ä¸–ç•Œç±»åˆ«ç‰¹å®šé‡å»º|Kun Wang, Zhiqiang Yan, Zhenyu Zhang, Xiang Li, Jun Li, Jian Yang|<http://arxiv.org/pdf/2306.05145v2>|None|


## 3DGS

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|3D Gaussian Inpainting with Depth-Guided Cross-View Consistency|ä¸‰ç»´é«˜æ–¯å»å™ªä¸æ·±åº¦å¼•å¯¼çš„è·¨è§†å›¾ä¸€è‡´æ€§|Sheng-Yu Huang, Zi-Ting Chou, Yu-Chiang Frank Wang|<http://arxiv.org/pdf/2502.11801v1>|None|
|ğŸ“ æ›´æ–°|ConsistentDreamer: View-Consistent Meshes Through Balanced Multi-View Gaussian Optimization|ä¸€è‡´æ¢¦æƒ³è€…ï¼šé€šè¿‡å¹³è¡¡å¤šè§†å›¾é«˜æ–¯ä¼˜åŒ–å®ç°è§†å›¾ä¸€è‡´ç½‘æ ¼|Onat Åahin, Mohammad Altillawi, George Eskandar, Carlos Carbone, Ziyuan Liu|<http://arxiv.org/pdf/2502.09278v2>|None|
|ğŸ“ æ›´æ–°|3D Reconstruction of Shoes for Augmented Reality|é‹ç±»ä¸‰ç»´é‡å»ºç”¨äºå¢å¼ºç°å®|Pratik Shrestha, Sujan Kapali, Swikar Gautam, Vishal Pokharel, Santosh Giri|<http://arxiv.org/pdf/2501.18643v2>|None|


## å¤šæ¨¡æ€

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|HermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and Generation|èµ«å°”å¢¨æ–¯æµï¼šæ— ç¼ç¼©å°å¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆå·®è·|Ling Yang, Xinchen Zhang, Ye Tian, Chenming Shang, Minghao Xu, Wentao Zhang, Bin Cui|<http://arxiv.org/pdf/2502.12148v1>|<https://github.com/Gen-Verse/HermesFlow>|
|ğŸ†• å‘å¸ƒ|PRISM: Self-Pruning Intrinsic Selection Method for Training-Free Multimodal Data Selection|PRISMï¼šè®­ç»ƒè‡ªç”±çš„å¤šæ¨¡æ€æ•°æ®é€‰æ‹©çš„è‡ªå‰ªæå†…åœ¨é€‰æ‹©æ–¹æ³•|Jinhe Bi, Yifan Wang, Danqi Yan, Xun Xiao, Artur Hecker, Volker Tresp, Yunpu Ma|<http://arxiv.org/pdf/2502.12119v1>|None|
|ğŸ†• å‘å¸ƒ|Token Communications: A Unified Framework for Cross-modal Context-aware Semantic Communications|è·¨æ¨¡æ€ä¸Šä¸‹æ–‡æ„ŸçŸ¥è¯­ä¹‰é€šä¿¡çš„ç»Ÿä¸€æ¡†æ¶ï¼šToken Communications|Li Qiao, Mahdi Boloursaz Mashhadi, Zhen Gao, Rahim Tafazolli, Mehdi Bennis, Dusit Niyato|<http://arxiv.org/pdf/2502.12096v1>|None|
|ğŸ†• å‘å¸ƒ|Learning Generalizable Prompt for CLIP with Class Similarity Knowledge|å­¦ä¹ å…·æœ‰ç±»åˆ«ç›¸ä¼¼æ€§çŸ¥è¯†çš„CLIPé€šç”¨æç¤º|Sehun Jung, Hyang-won Lee|<http://arxiv.org/pdf/2502.11969v1>|None|
|ğŸ†• å‘å¸ƒ|video-SALMONN-o1: Reasoning-enhanced Audio-visual Large Language Model|è§†é¢‘-SALMONN-o1ï¼šæ¨ç†å¢å¼ºçš„è§†å¬å¤§å‹è¯­è¨€æ¨¡å‹|Guangzhi Sun, Yudong Yang, Jimin Zhuang, Changli Tang, Yixuan Li, Wei Li, Zejun MA, Chao Zhang|<http://arxiv.org/pdf/2502.11775v1>|None|
|ğŸ†• å‘å¸ƒ|Language Models Can See Better: Visual Contrastive Decoding For LLM Multimodal Reasoning|è¯­è¨€æ¨¡å‹çœ‹å¾—æ›´å¥½ï¼šç”¨äºLLMå¤šæ¨¡æ€æ¨ç†çš„è§†è§‰å¯¹æ¯”è§£ç |Yuqi Pang, Bowen Yang, Haoqin Tu, Yun Cao, Zeyu Zhang|<http://arxiv.org/pdf/2502.11751v1>|<https://github.com/Pbhgit/MVCD.>|
|ğŸ†• å‘å¸ƒ|Mitigating Visual Knowledge Forgetting in MLLM Instruction-tuning via Modality-decoupled Gradient Descent|ç¼“è§£å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹æŒ‡ä»¤å¾®è°ƒä¸­çš„è§†è§‰çŸ¥è¯†é—å¿˜ï¼šé€šè¿‡æ¨¡æ€è§£è€¦æ¢¯åº¦ä¸‹é™|Junda Wu, Yuxin Xiong, Xintong Li, Yu Xia, Ruoyu Wang, Yu Wang, Tong Yu, Sungchul Kim .etc.|<http://arxiv.org/pdf/2502.11740v1>|None|
|ğŸ†• å‘å¸ƒ|"See the World, Discover Knowledge": A Chinese Factuality Evaluation for Large Vision Language Models|ã€Šè§ä¸–ç•Œï¼Œè¯†çŸ¥è¯†ï¼šå¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹çš„ä¸­å›½äº‹å®æ€§è¯„ä¼°ã€‹|Jihao Gu, Yingyao Wang, Pi Bu, Chen Wang, Ziming Wang, Tengtao Song, Donglai Wei, Jiale Yuan .etc.|<http://arxiv.org/pdf/2502.11718v1>|None|
|ğŸ†• å‘å¸ƒ|Token Pruning in Multimodal Large Language Models: Are We Solving the Right Problem?|å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„Tokenå‰ªæï¼šæˆ‘ä»¬æ˜¯å¦è§£å†³äº†æ­£ç¡®çš„é—®é¢˜ï¼Ÿ|Zichen Wen, Yifeng Gao, Weijia Li, Conghui He, Linfeng Zhang|<http://arxiv.org/pdf/2502.11501v1>|None|
|ğŸ†• å‘å¸ƒ|Stop Looking for Important Tokens in Multimodal Language Models: Duplication Matters More|åœæ­¢åœ¨å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ä¸­å¯»æ‰¾é‡è¦æ ‡è®°ï¼šé‡å¤æ›´é‡è¦|Zichen Wen, Yifeng Gao, Shaobo Wang, Junyuan Zhang, Qintong Zhang, Weijia Li, Conghui He, Linfeng Zhang|<http://arxiv.org/pdf/2502.11494v1>|<https://github.com/ZichenWen1/DART.>|
|ğŸ†• å‘å¸ƒ|Why Vision Language Models Struggle with Visual Arithmetic? Towards Enhanced Chart and Geometry Understanding|è§†è§‰è¯­è¨€æ¨¡å‹ä¸ºä½•åœ¨è§†è§‰ç®—æœ¯ä¸­æŒ£æ‰ï¼Ÿè¿ˆå‘å¢å¼ºçš„å›¾è¡¨å’Œå‡ ä½•ç†è§£|Kung-Hsiang Huang, Can Qin, Haoyi Qiu, Philippe Laban, Shafiq Joty, Caiming Xiong, Chien-Sheng Wu|<http://arxiv.org/pdf/2502.11492v1>|None|
|ğŸ†• å‘å¸ƒ|Do we Really Need Visual Instructions? Towards Visual Instruction-Free Fine-tuning for Large Vision-Language Models|æˆ‘ä»¬çœŸçš„éœ€è¦è§†è§‰æŒ‡ä»¤å—ï¼Ÿè¿ˆå‘å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹çš„æ— è§†è§‰æŒ‡ä»¤å¾®è°ƒ|Zikang Liu, Kun Zhou, Wayne Xin Zhao, Dawei Gao, Yaliang Li, Ji-Rong Wen|<http://arxiv.org/pdf/2502.11427v1>|None|
|ğŸ“ æ›´æ–°|Do Large Multimodal Models Solve Caption Generation for Scientific Figures? Lessons Learned from SCICAP Challenge 2023|å¤§å‹å¤šæ¨¡æ€æ¨¡å‹èƒ½å¦è§£å†³ç§‘å­¦å›¾è±¡çš„æ ‡é¢˜ç”Ÿæˆï¼Ÿä»2023å¹´SCICAPæŒ‘æˆ˜èµ›ä¸­å­¦åˆ°çš„ç»éªŒ|Ting-Yao E. Hsu, Yi-Li Hsu, Shaurya Rohatgi, Chieh-Yang Huang, Ho Yin Sam Ng, Ryan Rossi, Sungchul Kim, Tong Yu .etc.|<http://arxiv.org/pdf/2501.19353v2>|None|
|ğŸ“ æ›´æ–°|Scalable Vision Language Model Training via High Quality Data Curation|é€šè¿‡é«˜è´¨é‡æ•°æ®æ•´ç†å®ç°å¯æ‰©å±•è§†è§‰è¯­è¨€æ¨¡å‹è®­ç»ƒ|Hongyuan Dong, Zijian Kang, Weijie Yin, Xiao Liang, Chao Feng, Jiao Ran|<http://arxiv.org/pdf/2501.05952v2>|None|
|ğŸ“ æ›´æ–°|MIRe: Enhancing Multimodal Queries Representation via Fusion-Free Modality Interaction for Multimodal Retrieval|MIReï¼šé€šè¿‡æ— èåˆæ¨¡æ€äº¤äº’å¢å¼ºå¤šæ¨¡æ€æŸ¥è¯¢è¡¨ç¤ºçš„å¤šæ¨¡æ€æ£€ç´¢|Yeong-Joon Ju, Ho-Joong Kim, Seong-Whan Lee|<http://arxiv.org/pdf/2411.08334v2>|<https://github.com/yeongjoonJu/MIRe.>|
|ğŸ“ æ›´æ–°|Both Text and Images Leaked! A Systematic Analysis of Multimodal LLM Data Contamination|æ–‡æœ¬ä¸å›¾åƒå‡æ³„éœ²ï¼å¤šæ¨¡æ€LLMæ•°æ®æ±¡æŸ“çš„ç³»ç»Ÿåˆ†æ|Dingjie Song, Sicheng Lai, Shunian Chen, Lichao Sun, Benyou Wang|<http://arxiv.org/pdf/2411.03823v2>|None|
|ğŸ“ æ›´æ–°|Better Language Models Exhibit Higher Visual Alignment|æ›´å¥½çš„è¯­è¨€æ¨¡å‹å±•ç°å‡ºæ›´é«˜çš„è§†è§‰å¯¹é½|Jona Ruthardt, Gertjan J. Burghouts, Serge Belongie, Yuki M. Asano|<http://arxiv.org/pdf/2410.07173v2>|None|
|ğŸ“ æ›´æ–°|Bridging Compressed Image Latents and Multimodal Large Language Models|è·¨è¶Šå‹ç¼©å›¾åƒæ½œå˜é‡å’Œå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹|Chia-Hao Kao, Cheng Chien, Yu-Jen Tseng, Yi-Hsin Chen, Alessandro Gnutti, Shao-Yuan Lo, Wen-Hsiao Peng, Riccardo Leonardi|<http://arxiv.org/pdf/2407.19651v2>|None|
|ğŸ“ æ›´æ–°|MFC-Bench: Benchmarking Multimodal Fact-Checking with Large Vision-Language Models|MFC-Benchï¼šåŸºäºå¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹çš„è·¨æ¨¡æ€äº‹å®æ ¸æŸ¥åŸºå‡†æµ‹è¯•|Shengkang Wang, Hongzhan Lin, Ziyang Luo, Zhen Ye, Guang Chen, Jing Ma|<http://arxiv.org/pdf/2406.11288v3>|<https://github.com/wskbest/MFC-Bench>|
|ğŸ“ æ›´æ–°|Understanding Long Videos with Multimodal Language Models|ç†è§£é•¿è§†é¢‘çš„å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹|Kanchana Ranasinghe, Xiang Li, Kumara Kahatapitiya, Michael S. Ryoo|<http://arxiv.org/pdf/2403.16998v3>|None|


## å…·èº«æ™ºèƒ½

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Does Knowledge About Perceptual Uncertainty Help an Agent in Automated Driving?|æ„ŸçŸ¥ä¸ç¡®å®šæ€§çŸ¥è¯†æ˜¯å¦æœ‰åŠ©äºè‡ªåŠ¨é©¾é©¶ä¸­çš„æ™ºèƒ½ä½“ï¼Ÿ|Natalie Grabowsky, Annika MÃ¼tze, Joshua Wendland, Nils Jansen, Matthias Rottmann|<http://arxiv.org/pdf/2502.11864v1>|None|
|ğŸ†• å‘å¸ƒ|FUNCTO: Function-Centric One-Shot Imitation Learning for Tool Manipulation|åŠŸèƒ½ä¸­å¿ƒçš„ä¸€æ­¥å¼å·¥å…·æ“ä½œæ¨¡ä»¿å­¦ä¹ ï¼šFUNCTO|Chao Tang, Anxing Xiao, Yuhong Deng, Tianrun Hu, Wenlong Dong, Hanbo Zhang, David Hsu, Hong Zhang|<http://arxiv.org/pdf/2502.11744v1>|None|
|ğŸ†• å‘å¸ƒ|No-reference geometry quality assessment for colorless point clouds via list-wise rank learning|æ— å‚è€ƒè‰²å½©ç‚¹äº‘å‡ ä½•è´¨é‡è¯„ä¼°çš„åˆ—è¡¨æ’åºå­¦ä¹ æ–¹æ³•|Zheng Li, Bingxu Xie, Chao Chu, Weiqing Li, Zhiyong Su|<http://arxiv.org/pdf/2502.11726v1>|None|
|ğŸ†• å‘å¸ƒ|Without Paired Labeled Data: An End-to-End Self-Supervised Paradigm for UAV-View Geo-Localization|æ— é…å¯¹æ ‡æ³¨æ•°æ®ï¼šæ— äººæœºè§†è§’åœ°ç†å®šä½çš„ç«¯åˆ°ç«¯è‡ªç›‘ç£èŒƒå¼|Zhongwei Chen, Zhao-Xu Yang, Hai-Jun Rong|<http://arxiv.org/pdf/2502.11381v1>|None|
|ğŸ“ æ›´æ–°|AI Guide Dog: Egocentric Path Prediction on Smartphone|äººå·¥æ™ºèƒ½å¯¼ç›²çŠ¬ï¼šæ™ºèƒ½æ‰‹æœºä¸Šçš„è‡ªä¸­å¿ƒè·¯å¾„é¢„æµ‹|Aishwarya Jadhav, Jeffery Cao, Abhishree Shetty, Urvashi Priyam Kumar, Aditi Sharma, Ben Sukboontip, Jayant Sravan Tamarapalli, Jingyi Zhang .etc.|<http://arxiv.org/pdf/2501.07957v2>|None|
|ğŸ“ æ›´æ–°|NaVILA: Legged Robot Vision-Language-Action Model for Navigation|NaVILAï¼šç”¨äºå¯¼èˆªçš„è…¿éƒ¨æœºå™¨äººè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹|An-Chieh Cheng, Yandong Ji, Zhaojing Yang, Zaitian Gongye, Xueyan Zou, Jan Kautz, Erdem BÄ±yÄ±k, Hongxu Yin .etc.|<http://arxiv.org/pdf/2412.04453v2>|None|
|ğŸ“ æ›´æ–°|Rethinking Meta-Learning from a Learning Lens|é‡æ–°ä»å­¦ä¹ è§†è§’å®¡è§†å…ƒå­¦ä¹ |Jingyao Wang, Wenwen Qiang, Chuxiong Sun, Changwen Zheng, Jiangmeng Li|<http://arxiv.org/pdf/2409.08474v2>|None|
|ğŸ“ æ›´æ–°|3D Whole-body Grasp Synthesis with Directional Controllability|ä¸‰ç»´å…¨èº«æŠ“å–åˆæˆä¸æ–¹å‘å¯æ§æ€§|Georgios Paschalidis, Romana Wilschut, Dimitrije AntiÄ‡, Omid Taheri, Dimitrios Tzionas|<http://arxiv.org/pdf/2408.16770v2>|<https://gpaschalidis.github.io/cwgrasp.>|


## äººä½“åˆ†æ

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|A Monocular Event-Camera Motion Capture System|å•ç›®äº‹ä»¶ç›¸æœºè¿åŠ¨æ•æ‰ç³»ç»Ÿ|Leonard Bauersfeld, Davide Scaramuzza|<http://arxiv.org/pdf/2502.12113v1>|None|
|ğŸ†• å‘å¸ƒ|Defining and Evaluating Visual Language Models' Basic Spatial Abilities: A Perspective from Psychometrics|å®šä¹‰å’Œè¯„ä¼°è§†è§‰è¯­è¨€æ¨¡å‹çš„åŸºæœ¬ç©ºé—´èƒ½åŠ›ï¼šå¿ƒç†æµ‹é‡å­¦è§†è§’|Wenrui Xu, Dalin Lyu, Weihang Wang, Jie Feng, Chen Gao, Yong Li|<http://arxiv.org/pdf/2502.11859v1>|None|
|ğŸ†• å‘å¸ƒ|Revealing Bias Formation in Deep Neural Networks Through the Geometric Mechanisms of Human Visual Decoupling|é€šè¿‡äººç±»è§†è§‰è§£è€¦çš„å‡ ä½•æœºåˆ¶æ­ç¤ºæ·±åº¦ç¥ç»ç½‘ç»œä¸­çš„åå·®å½¢æˆ|Yanbiao Ma, Bowei Liu, Wei Dai, Jiayi Chen, Shuo Li|<http://arxiv.org/pdf/2502.11809v1>|None|
|ğŸ“ æ›´æ–°|What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations|é‚£æ˜¯åœ¨è°ˆè®ºä»€ä¹ˆï¼Ÿç§‘å­¦æ¼”ç¤ºçš„è§†é¢‘åˆ°æ–‡æœ¬æ‘˜è¦æ•°æ®é›†|Dongqi Liu, Chenxi Whitehouse, Xi Yu, Louis Mahon, Rohit Saxena, Zheng Zhao, Yifu Qiu, Mirella Lapata .etc.|<http://arxiv.org/pdf/2502.08279v2>|None|
|ğŸ“ æ›´æ–°|T2VEval: T2V-generated Videos Benchmark Dataset and Objective Evaluation Method|T2VEvalï¼šT2Vç”Ÿæˆè§†é¢‘åŸºå‡†æ•°æ®é›†å’Œå®¢è§‚è¯„ä¼°æ–¹æ³•|Zelu Qi, Ping Shi, Shuqi Wang, Zhaoyang Zhang, Fei Zhao, Zefeng Ying, Da Pan|<http://arxiv.org/pdf/2501.08545v3>|None|
|ğŸ“ æ›´æ–°|X-Fi: A Modality-Invariant Foundation Model for Multimodal Human Sensing|X-Fiï¼šä¸€ç§ç”¨äºå¤šæ¨¡æ€äººä½“æ„ŸçŸ¥çš„æ¨¡æ€ä¸å˜åŸºç¡€æ¨¡å‹|Xinyan Chen, Jianfei Yang|<http://arxiv.org/pdf/2410.10167v3>|None|
|ğŸ“ æ›´æ–°|Bootstrapping Vision-language Models for Self-supervised Remote Physiological Measurement|è‡ªç›‘ç£è¿œç¨‹ç”Ÿç†æµ‹é‡ä¸­çš„è§†è§‰-è¯­è¨€æ¨¡å‹è‡ªä¸¾|Zijie Yue, Miaojing Shi, Hanli Wang, Shuai Ding, Qijun Chen, Shanlin Yang|<http://arxiv.org/pdf/2407.08507v2>|None|
|ğŸ“ æ›´æ–°|Neural Slot Interpreters: Grounding Object Semantics in Emergent Slot Representations|ç¥ç»æ§½ä½è§£é‡Šå™¨ï¼šåœ¨æ¶Œç°æ§½ä½è¡¨ç¤ºä¸­é”šå®šå¯¹è±¡è¯­ä¹‰|Bhishma Dedhia, Niraj K. Jha|<http://arxiv.org/pdf/2403.07887v3>|None|


## äººè„¸æŠ€æœ¯

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|A Comparison of Human and Machine Learning Errors in Face Recognition|äººè„¸è¯†åˆ«ä¸­äººç±»ä¸æœºå™¨å­¦ä¹ è¯¯å·®çš„æ¯”è¾ƒ|Marina EstÃ©vez-Almenzar, Ricardo Baeza-Yates, Carlos Castillo|<http://arxiv.org/pdf/2502.11337v1>|None|
|ğŸ“ æ›´æ–°|Nautilus: Locality-aware Autoencoder for Scalable Mesh Generation|æµ·èºï¼šç”¨äºå¯æ‰©å±•ç½‘æ ¼ç”Ÿæˆçš„å±€éƒ¨æ„ŸçŸ¥è‡ªåŠ¨ç¼–ç å™¨|Yuxuan Wang, Xuanyu Yi, Haohan Weng, Qingshan Xu, Xiaokang Wei, Xianghui Yang, Chunchao Guo, Long Chen .etc.|<http://arxiv.org/pdf/2501.14317v4>|None|
|ğŸ“ æ›´æ–°|Adapting Multi-modal Large Language Model to Concept Drift From Pre-training Onwards|é€‚åº”ä»é¢„è®­ç»ƒå¼€å§‹çš„è·¨æ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹å¯¹æ¦‚å¿µæ¼‚ç§»çš„è°ƒæ•´|Xiaoyu Yang, Jie Lu, En Yu|<http://arxiv.org/pdf/2405.13459v3>|<https://github.com/XiaoyuYoung/ConceptDriftMLLMs.>|


## æ•°å­—äºº

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|VoLUT: Efficient Volumetric streaming enhanced by LUT-based super-resolution|VoLUTï¼šåŸºäºæŸ¥æ‰¾è¡¨ï¼ˆLUTï¼‰è¶…åˆ†è¾¨ç‡ä¼˜åŒ–çš„é«˜æ•ˆä½“ç´ æµ|Chendong Wang, Anlan Zhang, Yifan Yang, Lili Qiu, Yuqing Yang, Xinyang Jiang, Feng Qian, Suman Banerjee|<http://arxiv.org/pdf/2502.12151v1>|None|
|ğŸ†• å‘å¸ƒ|Characterizing Photorealism and Artifacts in Diffusion Model-Generated Images|å¯¹æ‰©æ•£æ¨¡å‹ç”Ÿæˆå›¾åƒä¸­çš„é€¼çœŸåº¦å’Œä¼ªå½±è¿›è¡Œè¡¨å¾|Negar Kamali, Karyn Nakamura, Aakriti Kumar, Angelos Chatzimparmpas, Jessica Hullman, Matthew Groh|<http://arxiv.org/pdf/2502.11989v1>|None|
|ğŸ†• å‘å¸ƒ|GaussianMotion: End-to-End Learning of Animatable Gaussian Avatars with Pose Guidance from Text|é«˜æ–¯è¿åŠ¨ï¼šåŸºäºæ–‡æœ¬å§¿æ€å¼•å¯¼çš„åŠ¨ç”»é«˜æ–¯è™šæ‹Ÿå½¢è±¡çš„ç«¯åˆ°ç«¯å­¦ä¹ |Gyumin Shim, Sangmin Lee, Jaegul Choo|<http://arxiv.org/pdf/2502.11642v1>|None|
|ğŸ†• å‘å¸ƒ|Syllables to Scenes: Literary-Guided Free-Viewpoint 3D Scene Synthesis from Japanese Haiku|éŸ³èŠ‚è‡³åœºæ™¯ï¼šæ–‡å­¦å¼•å¯¼çš„æ—¥æœ¬ä¿³å¥è‡ªç”±è§†ç‚¹3Dåœºæ™¯åˆæˆ|Chunan Yu, Yidong Han, Chaotao Ding, Ying Zang, Lanyun Zhu, Xinhao Chen, Zejian Li, Renjun Xu .etc.|<http://arxiv.org/pdf/2502.11586v1>|None|
|ğŸ“ æ›´æ–°|SPHERE: Unveiling Spatial Blind Spots in Vision-Language Models Through Hierarchical Evaluation|SPHEREï¼šé€šè¿‡åˆ†å±‚è¯„ä¼°æ­ç¤ºè§†è§‰-è¯­è¨€æ¨¡å‹ä¸­çš„ç©ºé—´ç›²ç‚¹|Wenyu Zhang, Wei En Ng, Lixin Ma, Yuwen Wang, Jungqi Zhao, Allison Koenecke, Boyang Li, Lu Wang|<http://arxiv.org/pdf/2412.12693v2>|None|


## æ¨¡å‹ä¼˜åŒ–

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|GRAPHGPT-O: Synergistic Multimodal Comprehension and Generation on Graphs|å›¾GPT-Oï¼šå›¾ä¸Šçš„ååŒå¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆ|Yi Fang, Bowen Jin, Jiacheng Shen, Sirui Ding, Qiaoyu Tan, Jiawei Han|<http://arxiv.org/pdf/2502.11925v1>|None|
|ğŸ†• å‘å¸ƒ|Rethinking Audio-Visual Adversarial Vulnerability from Temporal and Modality Perspectives|é‡æ–°ä»æ—¶é—´å’Œæ¨¡æ€è§’åº¦æ€è€ƒéŸ³é¢‘-è§†è§‰å¯¹æŠ—è„†å¼±æ€§|Zeliang Zhang, Susan Liang, Daiki Shimada, Chenliang Xu|<http://arxiv.org/pdf/2502.11858v1>|None|
|ğŸ†• å‘å¸ƒ|Steering the LoCoMotif: Using Domain Knowledge in Time Series Motif Discovery|å¼•å¯¼LoCoMotifï¼šåœ¨æ—¶é—´åºåˆ—æ¨¡å¼å‘ç°ä¸­ä½¿ç”¨é¢†åŸŸçŸ¥è¯†|Aras Yurtman, Daan Van Wesenbeeck, Wannes Meert, Hendrik Blockeel|<http://arxiv.org/pdf/2502.11850v1>|None|
|ğŸ“ æ›´æ–°|Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model|ã€Šæ­¥è§†é¢‘-T2VæŠ€æœ¯æŠ¥å‘Šï¼šè§†é¢‘åŸºç¡€æ¨¡å‹çš„å®è·µã€æŒ‘æˆ˜ä¸æœªæ¥ã€‹|Guoqing Ma, Haoyang Huang, Kun Yan, Liangyu Chen, Nan Duan, Shengming Yin, Changyi Wan, Ranchen Ming .etc.|<http://arxiv.org/pdf/2502.10248v2>|<https://github.com/stepfun-ai/Step-Video-T2V.>|
|ğŸ“ æ›´æ–°|Magic 1-For-1: Generating One Minute Video Clips within One Minute|ã€Šé­”æ³•1-1ï¼šä¸€åˆ†é’Ÿå†…ç”Ÿæˆä¸€åˆ†é’Ÿè§†é¢‘ç‰‡æ®µã€‹|Hongwei Yi, Shitong Shao, Tian Ye, Jiantong Zhao, Qingyu Yin, Michael Lingelbach, Li Yuan, Yonghong Tian .etc.|<http://arxiv.org/pdf/2502.07701v3>|<https://github.com/DA-Group-PKU/Magic-1-For-1.>|
|ğŸ“ æ›´æ–°|Navigating Semantic Drift in Task-Agnostic Class-Incremental Learning|åœ¨ä»»åŠ¡æ— å…³ç±»å¢é‡å­¦ä¹ ä¸­çš„è¯­ä¹‰æ¼‚ç§»å¯¼èˆª|Fangwen Wu, Lechao Cheng, Shengeng Tang, Xiaofeng Zhu, Chaowei Fang, Dingwen Zhang, Meng Wang|<http://arxiv.org/pdf/2502.07560v2>|<https://github.com/fwu11/MACIL.git>|
|ğŸ“ æ›´æ–°|InfiFusion: A Unified Framework for Enhanced Cross-Model Reasoning via LLM Fusion|æ— é™èåˆï¼šé€šè¿‡LLMèåˆå¢å¼ºè·¨æ¨¡å‹æ¨ç†çš„ç»Ÿä¸€æ¡†æ¶|Zhaoyi Yan, Yiming Zhang, Baoyi He, Yuhao Fu, Qi Zhou, Zhijie Sang, Chunlin Ji, Shengyu Zhang .etc.|<http://arxiv.org/pdf/2501.02795v3>|None|
|ğŸ“ æ›´æ–°|FlexCAD: Unified and Versatile Controllable CAD Generation with Fine-tuned Large Language Models|FlexCADï¼šåŸºäºå¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹çš„ç»Ÿä¸€ä¸”å¤šåŠŸèƒ½çš„å¯æ§CADç”Ÿæˆ|Zhanwei Zhang, Shizhao Sun, Wenxiao Wang, Deng Cai, Jiang Bian|<http://arxiv.org/pdf/2411.05823v2>|<https://github.com/microsoft/FlexCAD.>|
|ğŸ“ æ›´æ–°|BitStack: Any-Size Compression of Large Language Models in Variable Memory Environments|æ¯”ç‰¹å †ï¼šå¯å˜å†…å­˜ç¯å¢ƒä¸­å¤§å‹è¯­è¨€æ¨¡å‹çš„ä»»æ„å¤§å°å‹ç¼©|Xinghao Wang, Pengyu Wang, Bo Wang, Dong Zhang, Yunhua Zhou, Xipeng Qiu|<http://arxiv.org/pdf/2410.23918v3>|<https://github.com/xinghaow99/BitStack.>|
|ğŸ“ æ›´æ–°|ExPLoRA: Parameter-Efficient Extended Pre-Training to Adapt Vision Transformers under Domain Shifts|ExPLoRAï¼šå‚æ•°é«˜æ•ˆçš„æ‰©å±•é¢„è®­ç»ƒä»¥é€‚åº”åŸŸåç§»ä¸‹çš„è§†è§‰Transformer|Samar Khanna, Medhanie Irgau, David B. Lobell, Stefano Ermon|<http://arxiv.org/pdf/2406.10973v3>|<https://samar-khanna.github.io/ExPLoRA>|
|ğŸ“ æ›´æ–°|TE-NeXt: A LiDAR-Based 3D Sparse Convolutional Network for Traversability Estimation|TE-NeXtï¼šä¸€ç§åŸºäºæ¿€å…‰é›·è¾¾çš„3Dç¨€ç–å·ç§¯ç½‘ç»œç”¨äºé€šè¡Œæ€§ä¼°è®¡|Antonio Santo, Juan J. Cabrera, David Valiente, Carlos Viegas, Arturo Gil|<http://arxiv.org/pdf/2406.01395v4>|None|


## åŒ»å­¦åº”ç”¨

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MultiFlow: A unified deep learning framework for multi-vessel classification, segmentation and clustering of phase-contrast MRI validated on a multi-site single ventricle patient cohort|å¤šæµï¼šä¸€ç§ç”¨äºå¤šè¡€ç®¡åˆ†ç±»ã€åˆ†å‰²å’Œèšç±»ç›¸ä½å¯¹æ¯”MRIçš„ç»Ÿä¸€æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œåœ¨å¤šä¸­å¿ƒå•å¿ƒå®¤æ‚£è€…é˜Ÿåˆ—ä¸­å¾—åˆ°éªŒè¯|Tina Yao, Nicole St. Clair, Gabriel F. Miller, FORCE Investigators, Jennifer A. Steeden, Rahul H. Rathod, Vivek Muthurangu|<http://arxiv.org/pdf/2502.11993v1>|None|
|ğŸ†• å‘å¸ƒ|Robust 6DoF Pose Tracking Considering Contour and Interior Correspondence Uncertainty for AR Assembly Guidance|é²æ£’6è‡ªç”±åº¦å§¿æ€è·Ÿè¸ªï¼šè€ƒè™‘è½®å»“å’Œå†…éƒ¨å¯¹åº”ä¸ç¡®å®šæ€§ä»¥å®ç°ARè£…é…å¼•å¯¼|Jixiang Chen, Jing Chen, Kai Liu, Haochen Chang, Shanfeng Fu, Jian Yang|<http://arxiv.org/pdf/2502.11971v1>|None|
|ğŸ†• å‘å¸ƒ|JotlasNet: Joint Tensor Low-Rank and Attention-based Sparse Unrolling Network for Accelerating Dynamic MRI|JotlasNetï¼šç”¨äºåŠ é€ŸåŠ¨æ€MRIçš„è”åˆå¼ é‡ä½ç§©å’ŒåŸºäºæ³¨æ„åŠ›çš„ç¨€ç–å±•å¼€ç½‘ç»œ|Yinghao Zhang, Haiyan Gui, Ningdi Yang, Yue Hu|<http://arxiv.org/pdf/2502.11749v1>|None|
|ğŸ†• å‘å¸ƒ|Incomplete Modality Disentangled Representation for Ophthalmic Disease Grading and Diagnosis|çœ¼ç§‘ç–¾ç—…åˆ†çº§ä¸è¯Šæ–­çš„ä¸å®Œæ•´æ¨¡æ€è§£è€¦è¡¨ç¤º|Chengzhi Liu, Zile Huang, Zhe Chen, Feilong Tang, Yu Tian, Zhongxing Xu, Zihong Luo, Yalin Zheng .etc.|<http://arxiv.org/pdf/2502.11724v1>|None|
|ğŸ†• å‘å¸ƒ|MMXU: A Multi-Modal and Multi-X-ray Understanding Dataset for Disease Progression|MMXUï¼šä¸€ç§ç”¨äºç–¾ç—…è¿›å±•çš„å¤šæ¨¡æ€å’Œå¤šXå°„çº¿ç†è§£æ•°æ®é›†|Linjie Mu, Zhongzhen Huang, Shengqian Qin, Yakun Zhu, Shaoting Zhang, Xiaofan Zhang|<http://arxiv.org/pdf/2502.11651v1>|<https://github.com/linjiemu/MMXU>|
|ğŸ†• å‘å¸ƒ|Enhancing Out-of-Distribution Detection in Medical Imaging with Normalizing Flows|åˆ©ç”¨æ­£æ€åŒ–æµå¢å¼ºåŒ»å­¦å›¾åƒä¸­çš„å¼‚å¸¸å€¼æ£€æµ‹|Dariush Lotfi, Mohammad-Ali Nikouei Mahani, Mohamad Koohi-Moghadam, Kyongtae Ty Bae|<http://arxiv.org/pdf/2502.11638v1>|<https://github.com/dlotfi/MedOODFlow.>|
|ğŸ†• å‘å¸ƒ|Towards a Trustworthy Anomaly Detection for Critical Applications through Approximated Partial AUC Loss|è¿ˆå‘å¯ä¿¡çš„è¿‘ä¼¼éƒ¨åˆ†AUCæŸå¤±å¼‚å¸¸æ£€æµ‹æ–¹æ³•|Arnaud Bougaham, BenoÃ®t FrÃ©nay|<http://arxiv.org/pdf/2502.11570v1>|<https://github.com/ArnaudBougaham/tapAUC.>|
|ğŸ†• å‘å¸ƒ|Variable-frame CNNLSTM for Breast Nodule Classification using Ultrasound Videos|å¯å˜å¸§CNNLSTMç”¨äºè¶…å£°è§†é¢‘ä¹³è…ºç»“èŠ‚åˆ†ç±»|Xiangxiang Cui, Zhongyu Li, Xiayue Fan, Peng Huang, Ying Wang, Meng Yang, Shi Chang, Jihua Zhu|<http://arxiv.org/pdf/2502.11481v1>|None|
|ğŸ†• å‘å¸ƒ|Leveraging Labelled Data Knowledge: A Cooperative Rectification Learning Network for Semi-supervised 3D Medical Image Segmentation|åˆ©ç”¨æ ‡æ³¨æ•°æ®çŸ¥è¯†ï¼šä¸€ç§ç”¨äºåŠç›‘ç£3DåŒ»å­¦å›¾åƒåˆ†å‰²çš„ååŒæ ¡æ­£å­¦ä¹ ç½‘ç»œ|Yanyan Wang, Kechen Song, Yuyuan Liu, Shuai Ma, Yunhui Yan, Gustavo Carneiro|<http://arxiv.org/pdf/2502.11456v1>|None|
|ğŸ†• å‘å¸ƒ|Medical Image Registration Meets Vision Foundation Model: Prototype Learning and Contour Awareness|åŒ»å­¦å›¾åƒé…å‡†é‡è§è§†è§‰åŸºç¡€æ¨¡å‹ï¼šåŸå‹å­¦ä¹ å’Œè½®å»“æ„ŸçŸ¥|Hao Xu, Tengfei Xue, Jianan Fan, Dongnan Liu, Yuqian Chen, Fan Zhang, Carl-Fredrik Westin, Ron Kikinis .etc.|<http://arxiv.org/pdf/2502.11440v1>|<https://github.com/HaoXu0507/IPMI25-SAM-Assisted-Registration.>|
|ğŸ†• å‘å¸ƒ|WRT-SAM: Foundation Model-Driven Segmentation for Generalized Weld Radiographic Testing|åŸºäºåŸºç¡€æ¨¡å‹çš„å¹¿ä¹‰ç„Šç¼å°„çº¿ç…§ç›¸æ£€æµ‹åˆ†å‰²æ–¹æ³•|Yunyi Zhou, Kun Shi, Gang Hao|<http://arxiv.org/pdf/2502.11338v1>|None|
|ğŸ†• å‘å¸ƒ|Differentially private fine-tuned NF-Net to predict GI cancer type|åŸºäºå·®åˆ†éšç§çš„å¾®è°ƒNF-Neté¢„æµ‹èƒƒè‚ é“ç™Œç±»å‹|Sai Venkatesh Chilukoti, Imran Hossen Md, Liqun Shan, Vijay Srinivas Tida, Xiali Hei|<http://arxiv.org/pdf/2502.11329v1>|None|
|ğŸ“ æ›´æ–°|HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation|å¥åº·GPTï¼šä¸€ç§é€šè¿‡å¼‚æ„çŸ¥è¯†é€‚åº”ç»Ÿä¸€ç†è§£å’Œç”Ÿæˆçš„åŒ»ç–—å¤§è§†è§‰-è¯­è¨€æ¨¡å‹|Tianwei Lin, Wenqiao Zhang, Sijing Li, Yuqian Yuan, Binhe Yu, Haoyuan Li, Wanggui He, Hao Jiang .etc.|<http://arxiv.org/pdf/2502.09838v2>|<https://github.com/DCDmllm/HealthGPT.>|
|ğŸ“ æ›´æ–°|Memory-based Ensemble Learning in CMR Semantic Segmentation|åŸºäºè®°å¿†çš„CMRè¯­ä¹‰åˆ†å‰²é›†æˆå­¦ä¹ æ–¹æ³•|Yiwei Liu, Ziyi Wu, Liang Zhong, Lingyi Wen, Yuankai Wu|<http://arxiv.org/pdf/2502.09269v2>|None|
|ğŸ“ æ›´æ–°|Novel computational workflows for natural and biomedical image processing based on hypercomplex algebras|æ–°å‹åŸºäºè¶…å¤æ•°ä»£æ•°çš„è‡ªç„¶å’Œç”Ÿç‰©åŒ»å­¦å›¾åƒå¤„ç†è®¡ç®—å·¥ä½œæµç¨‹|Nektarios A. Valous, Eckhard Hitzer, DragoÅŸ DuÅŸe, Rodrigo Rojas Moraleda, Ferdinand Popp, Meggy Suarez-Carmona, Anna Berthel, Ismini Papageorgiou .etc.|<http://arxiv.org/pdf/2502.07758v2>|None|
|ğŸ“ æ›´æ–°|Rethinking Text-Promptable Surgical Instrument Segmentation with Robust Framework|é‡æ–°æ€è€ƒåŸºäºæ–‡æœ¬æç¤ºçš„æ‰‹æœ¯å™¨æ¢°åˆ†å‰²çš„é²æ£’æ¡†æ¶|Tae-Min Choi, Juyoun Park|<http://arxiv.org/pdf/2411.12199v2>|None|
|ğŸ“ æ›´æ–°|Contrastive Language Prompting to Ease False Positives in Medical Anomaly Detection|å¯¹æ¯”è¯­è¨€æç¤ºä»¥å‡è½»åŒ»å­¦å¼‚å¸¸æ£€æµ‹ä¸­çš„å‡é˜³æ€§|YeongHyeon Park, Myung Jin Kim, Hyeong Seok Kim|<http://arxiv.org/pdf/2411.07546v2>|None|
|ğŸ“ æ›´æ–°|Grounded Knowledge-Enhanced Medical Vision-Language Pre-training for Chest X-Ray|åŸºäºåœ°é¢çŸ¥è¯†çš„èƒ¸éƒ¨Xå…‰åŒ»å­¦è§†è§‰-è¯­è¨€é¢„è®­ç»ƒ|Qiao Deng, Zhongzhen Huang, Yunqi Wang, Zhichuan Wang, Zhao Wang, Xiaofan Zhang, Qi Dou, Yeung Yu Hui .etc.|<http://arxiv.org/pdf/2404.14750v2>|None|


## å…¶ä»–

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Text4Seg: Reimagining Image Segmentation as Text Generation|æ–‡æœ¬4åˆ†å‰²ï¼šå°†å›¾åƒåˆ†å‰²é‡æ–°æ„æƒ³ä¸ºæ–‡æœ¬ç”Ÿæˆ|Mengcheng Lan, Chaofeng Chen, Yue Zhou, Jiaxing Xu, Yiping Ke, Xinjiang Wang, Litong Feng, Wayne Zhang|<http://arxiv.org/pdf/2410.09855v2>|None|

