## [UPDATED!] **2025-02-18** (Update Time)


## å›¾åƒç†è§£

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|myEye2Wheeler: A Two-Wheeler Indian Driver Real-World Eye-Tracking Dataset|æˆ‘çš„Eye2Wheelerï¼šä¸€ä¸ªä¸¤è½®å°åº¦é©¾é©¶å‘˜çœŸå®ä¸–ç•Œçœ¼åŠ¨æ•°æ®é›†|Bhaiya Vaibhaw Kumar, Deepti Rawat, Tanvi Kandalla, Aarnav Nagariya, Kavita Vemuri|<http://arxiv.org/pdf/2502.12723v1>|None|
|ğŸ†• å‘å¸ƒ|Spiking Vision Transformer with Saccadic Attention|è„‰å†²è§†è§‰Transformerä¸æ‰«è§†æ³¨æ„åŠ›|Shuai Wang, Malu Zhang, Dehao Zhang, Ammar Belatreche, Yichen Xiao, Yu Liang, Yimeng Shan, Qian Sun .etc.|<http://arxiv.org/pdf/2502.12677v1>|None|
|ğŸ“ æ›´æ–°|VarGes: Improving Variation in Co-Speech 3D Gesture Generation via StyleCLIPS|VarGesï¼šé€šè¿‡StyleCLIPSæå‡ååŒè¯­éŸ³3Dæ‰‹åŠ¿ç”Ÿæˆçš„å¤šæ ·æ€§|Ming Meng, Ke Mu, Yonggui Zhu, Zhe Zhu, Haoyu Sun, Heyang Yan, Zhaoxin Fan|<http://arxiv.org/pdf/2502.10729v2>|<https://github.com/mookerr/VarGES>|
|ğŸ“ æ›´æ–°|HeRCULES: Heterogeneous Radar Dataset in Complex Urban Environment for Multi-session Radar SLAM|èµ«æ‹‰å…‹å‹’æ–¯ï¼šå¤æ‚åŸå¸‚ç¯å¢ƒä¸­çš„å¼‚æ„é›·è¾¾æ•°æ®é›†ï¼Œç”¨äºå¤šä¼šè¯é›·è¾¾SLAM|Hanjun Kim, Minwoo Jung, Chiyun Noh, Sangwoo Jung, Hyunho Song, Wooseong Yang, Hyesu Jang, Ayoung Kim|<http://arxiv.org/pdf/2502.01946v2>|None|
|ğŸ“ æ›´æ–°|Benchmarking and Improving Large Vision-Language Models for Fundamental Visual Graph Understanding and Reasoning|åŸºå‡†æµ‹è¯•ä¸æå‡å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹çš„åŸºæœ¬è§†è§‰å›¾ç†è§£å’Œæ¨ç†|Yingjie Zhu, Xuefeng Bai, Kehai Chen, Yang Xiang, Jun Yu, Min Zhang|<http://arxiv.org/pdf/2412.13540v2>|None|
|ğŸ“ æ›´æ–°|Locality-aware Cross-modal Correspondence Learning for Dense Audio-Visual Events Localization|å±€éƒ¨æ„ŸçŸ¥è·¨æ¨¡æ€å¯¹åº”å­¦ä¹ ç”¨äºå¯†é›†éŸ³é¢‘-è§†è§‰äº‹ä»¶å®šä½|Ling Xing, Hongyu Qu, Rui Yan, Xiangbo Shu, Jinhui Tang|<http://arxiv.org/pdf/2409.07967v2>|None|
|ğŸ“ æ›´æ–°|A CNN Based Framework for Unistroke Numeral Recognition in Air-Writing|åŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„ç©ºä¸­ä¹¦å†™å•ç¬”æ•°å­—è¯†åˆ«æ¡†æ¶|Prasun Roy, Subhankar Ghosh, Umapada Pal|<http://arxiv.org/pdf/2303.07989v2>|None|


## æ£€æµ‹åˆ†å‰²

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|WeedsGalore: A Multispectral and Multitemporal UAV-based Dataset for Crop and Weed Segmentation in Agricultural Maize Fields|WeedsGaloreï¼šä¸€ç§ç”¨äºå†œä¸šç‰ç±³ç”°ä½œç‰©å’Œæ‚è‰åˆ†å‰²çš„å¤šå…‰è°±å’Œå¤šæ—¶ç›¸æ— äººæœºæ•°æ®é›†|Ekin Celikkan, Timo Kunzmann, Yertay Yeskaliyev, Sibylle Itzerott, Nadja Klein, Martin Herold|<http://arxiv.org/pdf/2502.13103v1>|<https://github.com/GFZ/weedsgalore>|
|ğŸ†• å‘å¸ƒ|RobuRCDet: Enhancing Robustness of Radar-Camera Fusion in Bird's Eye View for 3D Object Detection|RobuRCDetï¼šå¢å¼ºé¸Ÿç°è§†å›¾ä¸­é›·è¾¾-ç›¸æœºèåˆçš„é²æ£’æ€§ç”¨äº3Dç›®æ ‡æ£€æµ‹|Jingtong Yue, Zhiwei Lin, Xin Lin, Xiaoyu Zhou, Xiangtai Li, Lu Qi, Yongtao Wang, Ming-Hsuan Yang|<http://arxiv.org/pdf/2502.13071v1>|None|
|ğŸ†• å‘å¸ƒ|Enhancing Power Grid Inspections with Machine Learning|åˆ©ç”¨æœºå™¨å­¦ä¹ å¢å¼ºç”µç½‘å·¡æ£€|Diogo Lavado, Ricardo Santos, Andre Coelho, Joao Santos, Alessandra Micheletti, Claudia Soares|<http://arxiv.org/pdf/2502.13037v1>|None|
|ğŸ†• å‘å¸ƒ|Detection and Geographic Localization of Natural Objects in the Wild: A Case Study on Palms|é‡å¤–è‡ªç„¶ç‰©ä½“æ£€æµ‹ä¸åœ°ç†å®šä½ï¼šæ£•æ¦ˆæ ‘æ¡ˆä¾‹ç ”ç©¶|Kangning Cui, Rongkun Zhu, Manqi Wang, Wei Tang, Gregory D. Larsen, Victor P. Pauca, Sarra Alqahtani, Fan Yang .etc.|<http://arxiv.org/pdf/2502.13023v1>|None|
|ğŸ†• å‘å¸ƒ|An Experimental Study of SOTA LiDAR Segmentation Models|SOTAæ¿€å…‰é›·è¾¾åˆ†å‰²æ¨¡å‹çš„å®éªŒç ”ç©¶|Bike Chen, Antti TikanmÃ¤ki, Juha RÃ¶ning|<http://arxiv.org/pdf/2502.12860v1>|None|
|ğŸ†• å‘å¸ƒ|DAMamba: Vision State Space Model with Dynamic Adaptive Scan|DAMambaï¼šå…·æœ‰åŠ¨æ€è‡ªé€‚åº”æ‰«æçš„è§†è§‰çŠ¶æ€ç©ºé—´æ¨¡å‹|Tanzhe Li, Caoshuo Li, Jiayi Lyu, Hongjuan Pei, Baochang Zhang, Taisong Jin, Rongrong Ji|<http://arxiv.org/pdf/2502.12627v1>|<https://github.com/ltzovo/DAMamba.>|
|ğŸ†• å‘å¸ƒ|When Segmentation Meets Hyperspectral Image: New Paradigm for Hyperspectral Image Classification|å½“åˆ†å‰²é‡è§é«˜å…‰è°±å›¾åƒï¼šé«˜å…‰è°±å›¾åƒåˆ†ç±»çš„æ–°èŒƒå¼|Weilian Zhou, Weixuan Xie, Sei-ichiro Kamata, Man Sing Wong, Huiying, Hou, Haipeng Wang|<http://arxiv.org/pdf/2502.12541v1>|None|
|ğŸ†• å‘å¸ƒ|YOLOv12: Attention-Centric Real-Time Object Detectors|YOLOv12ï¼šä»¥æ³¨æ„åŠ›ä¸ºä¸­å¿ƒçš„å®æ—¶ç›®æ ‡æ£€æµ‹å™¨|Yunjie Tian, Qixiang Ye, David Doermann|<http://arxiv.org/pdf/2502.12524v1>|None|
|ğŸ†• å‘å¸ƒ|YUNet: Improved YOLOv11 Network for Skyline Detection|YUNetï¼šæ”¹è¿›çš„YOLOv11ç½‘ç»œç”¨äºå¤©é™…çº¿æ£€æµ‹|Gang Yang, Miao Wang, Quan Zhou, Jiangchuan Li|<http://arxiv.org/pdf/2502.12449v1>|<https://github.com/kuazhangxiaoai/SkylineDet-YOLOv11Seg.git.>|
|ğŸ†• å‘å¸ƒ|Gaseous Object Detection|æ°”ä½“ç›®æ ‡æ£€æµ‹|Kailai Zhou, Yibo Wang, Tao Lv, Qiu Shen, Xun Cao|<http://arxiv.org/pdf/2502.12415v1>|None|
|ğŸ“ æ›´æ–°|FrGNet: A fourier-guided weakly-supervised framework for nuclear instance segmentation|FrGNetï¼šä¸€ç§åŸºäºå‚…é‡Œå¶å¼•å¯¼çš„å¼±ç›‘ç£æ ¸å®ä¾‹åˆ†å‰²æ¡†æ¶|Peng Ling, Wenxiao Xiong|<http://arxiv.org/pdf/2502.09874v2>|<https://github.com/LQY404/FrGNet.>|
|ğŸ“ æ›´æ–°|SNAT-YOLO: Efficient Cross-Layer Aggregation Network for Edge-Oriented Gangue Detection|SNAT-YOLOï¼šé¢å‘è¾¹ç¼˜çš„çŸ¸çŸ³æ£€æµ‹çš„é«˜æ•ˆè·¨å±‚èšåˆç½‘ç»œ|Shang Li|<http://arxiv.org/pdf/2502.05988v2>|None|
|ğŸ“ æ›´æ–°|TS40K: a 3D Point Cloud Dataset of Rural Terrain and Electrical Transmission System|TS40Kï¼šå†œæ‘åœ°å½¢å’Œè¾“ç”µç³»ç»Ÿçš„3Dç‚¹äº‘æ•°æ®é›†|Diogo Lavado, ClÃ¡udia Soares, Alessandra Micheletti, Ricardo Santos, AndrÃ© Coelho, JoÃ£o Santos|<http://arxiv.org/pdf/2405.13989v2>|None|


## è§†é¢‘ç†è§£

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Instance-Level Moving Object Segmentation from a Single Image with Events|åŸºäºäº‹ä»¶çš„å•ä¸€å›¾åƒä¸­å®ä¾‹çº§ç§»åŠ¨ç›®æ ‡åˆ†å‰²|Zhexiong Wan, Bin Fan, Le Hui, Yuchao Dai, Gim Hee Lee|<http://arxiv.org/pdf/2502.12975v1>|<https://npucvr.github.io/EvInsMOS>|
|ğŸ†• å‘å¸ƒ|Adaptive Prototype Model for Attribute-based Multi-label Few-shot Action Recognition|è‡ªé€‚åº”åŸå‹æ¨¡å‹åœ¨åŸºäºå±æ€§çš„å°‘æ ·æœ¬åŠ¨ä½œè¯†åˆ«ä¸­çš„åº”ç”¨|Juefeng Xiao, Tianqi Xiang, Zhigang Tu|<http://arxiv.org/pdf/2502.12582v1>|<https://github.com/theAAPM/AAPM>|
|ğŸ“ æ›´æ–°|iMOVE: Instance-Motion-Aware Video Understanding|iMOVEï¼šå®ä¾‹è¿åŠ¨æ„ŸçŸ¥è§†é¢‘ç†è§£|Jiaze Li, Yaya Shi, Zongyang Ma, Haoran Xu, Feng Cheng, Huihui Xiao, Ruiwen Kang, Fan Yang .etc.|<http://arxiv.org/pdf/2502.11594v2>|None|
|ğŸ“ æ›´æ–°|PTQ4RIS: Post-Training Quantization for Referring Image Segmentation|PTQ4RISï¼šé’ˆå¯¹æŒ‡ç§°å›¾åƒåˆ†å‰²çš„æ¨¡å‹åè®­ç»ƒé‡åŒ–|Xiaoyan Jiang, Hang Yang, Kaiying Zhu, Xihe Qiu, Shibo Zhao, Sifan Zhou|<http://arxiv.org/pdf/2409.17020v2>|<https://github.com/gugu511yy/PTQ4RIS>|


## ç”Ÿæˆæ¨¡å‹

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|AV-Flow: Transforming Text to Audio-Visual Human-like Interactions|AV-Flowï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºç±»ä¼¼äººç±»éŸ³é¢‘-è§†è§‰äº¤äº’|Aggelina Chatziagapi, Louis-Philippe Morency, Hongyu Gong, Michael Zollhoefer, Dimitris Samaras, Alexander Richard|<http://arxiv.org/pdf/2502.13133v1>|<https://aggelinacha.github.io/AV-Flow>|
|ğŸ†• å‘å¸ƒ|Personalized Image Generation with Deep Generative Models: A Decade Survey|ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆï¼šåŸºäºæ·±åº¦ç”Ÿæˆæ¨¡å‹çš„åå¹´ç»¼è¿°|Yuxiang Wei, Yiheng Zheng, Yabo Zhang, Ming Liu, Zhilong Ji, Lei Zhang, Wangmeng Zuo|<http://arxiv.org/pdf/2502.13081v1>|<https://github.com/csyxwei/Awesome-Personalized-Image-Generation.>|
|ğŸ†• å‘å¸ƒ|Contrast-Unity for Partially-Supervised Temporal Sentence Grounding|å¯¹æ¯”ç»Ÿä¸€ï¼šéƒ¨åˆ†ç›‘ç£æ—¶é—´å¥å­å®šä½|Haicheng Wang, Chen Ju, Weixiong Lin, Chaofan Ma, Shuai Xiao, Ya Zhang, Yanfeng Wang|<http://arxiv.org/pdf/2502.12917v1>|None|
|ğŸ†• å‘å¸ƒ|3D Shape-to-Image Brownian Bridge Diffusion for Brain MRI Synthesis from Cortical Surfaces|ä¸‰ç»´å½¢çŠ¶åˆ°å›¾åƒå¸ƒæœ—è¿åŠ¨æ¡¥æ‰©æ•£ï¼šåŸºäºçš®è´¨è¡¨é¢çš„è„‘MRIåˆæˆ|Fabian Bongratz, Yitong Li, Sama Elbaroudy, Christian Wachinger|<http://arxiv.org/pdf/2502.12742v1>|<https://github.com/ai-med/Cor2Vox.>|
|ğŸ†• å‘å¸ƒ|MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation|MALTæ‰©æ•£ï¼šç”¨äºä»»æ„é•¿åº¦è§†é¢‘ç”Ÿæˆçš„è®°å¿†å¢å¼ºæ½œåœ¨å˜æ¢å™¨|Sihyun Yu, Meera Hahn, Dan Kondratyuk, Jinwoo Shin, Agrim Gupta, JosÃ© Lezama, Irfan Essa, David Ross .etc.|<http://arxiv.org/pdf/2502.12632v1>|None|
|ğŸ†• å‘å¸ƒ|DeltaDiff: A Residual-Guided Diffusion Model for Enhanced Image Super-Resolution|DeltaDiffï¼šä¸€ç§æ®‹å·®å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹ç”¨äºå¢å¼ºå›¾åƒè¶…åˆ†è¾¨ç‡|Chao Yang, Yong Fan, Cheng Lu, Zhijing Yang|<http://arxiv.org/pdf/2502.12567v1>|<https://github.com/continueyang/DeltaDiff>|
|ğŸ“ æ›´æ–°|MagicArticulate: Make Your 3D Models Articulation-Ready|é­”å¹» articulateï¼šè®©ä½ çš„ 3D æ¨¡å‹å‡†å¤‡å¥½å…³èŠ‚æ´»åŠ¨|Chaoyue Song, Jianfeng Zhang, Xiu Li, Fan Yang, Yiwen Chen, Zhongcong Xu, Jun Hao Liew, Xiaoyang Guo .etc.|<http://arxiv.org/pdf/2502.12135v2>|<https://chaoyuesong.github.io/MagicArticulate.>|
|ğŸ“ æ›´æ–°|AnyRefill: A Unified, Data-Efficient Framework for Left-Prompt-Guided Vision Tasks|AnyRefillï¼šä¸€ç§ç»Ÿä¸€ã€æ•°æ®é«˜æ•ˆçš„å·¦æç¤ºå¼•å¯¼è§†è§‰ä»»åŠ¡æ¡†æ¶|Ming Xie, Chenjie Cao, Yunuo Cai, Xiangyang Xue, Yu-Gang Jiang, Yanwei Fu|<http://arxiv.org/pdf/2502.11158v2>|None|
|ğŸ“ æ›´æ–°|Probing Visual Language Priors in VLMs|æ¢ç©¶è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„è§†è§‰å…ˆéªŒ|Tiange Luo, Ang Cao, Gunhee Lee, Justin Johnson, Honglak Lee|<http://arxiv.org/pdf/2501.00569v3>|None|
|ğŸ“ æ›´æ–°|STAR: Scale-wise Text-conditioned AutoRegressive image generation|STARï¼šåŸºäºå°ºåº¦æ–‡æœ¬æ¡ä»¶çš„è‡ªå›å½’å›¾åƒç”Ÿæˆ|Xiaoxiao Ma, Mohan Zhou, Tao Liang, Yalong Bai, Tiejun Zhao, Biye Li, Huaian Chen, Yi Jin|<http://arxiv.org/pdf/2406.10797v3>|None|
|ğŸ“ æ›´æ–°|AdvLoRA: Adversarial Low-Rank Adaptation of Vision-Language Models|AdvLoRAï¼šè§†è§‰-è¯­è¨€æ¨¡å‹çš„å¯¹æŠ—ä½ç§©è‡ªé€‚åº”|Yuheng Ji, Yue Liu, Zhicheng Zhang, Zhao Zhang, Yuting Zhao, Xiaoshuai Hao, Gang Zhou, Xingwei Zhang .etc.|<http://arxiv.org/pdf/2404.13425v2>|None|
|ğŸ“ æ›´æ–°|Semantically Consistent Person Image Generation|è¯­ä¹‰ä¸€è‡´çš„äººåƒç”Ÿæˆ|Prasun Roy, Saumik Bhattacharya, Subhankar Ghosh, Umapada Pal, Michael Blumenstein|<http://arxiv.org/pdf/2302.14728v2>|None|
|ğŸ“ æ›´æ–°|TIPS: Text-Induced Pose Synthesis|æ–‡æœ¬è¯±å¯¼å§¿æ€åˆæˆ|Prasun Roy, Subhankar Ghosh, Saumik Bhattacharya, Umapada Pal, Michael Blumenstein|<http://arxiv.org/pdf/2207.11718v2>|None|
|ğŸ“ æ›´æ–°|Scene Aware Person Image Generation through Global Contextual Conditioning|åœºæ™¯æ„ŸçŸ¥çš„äººåƒç”Ÿæˆé€šè¿‡å…¨å±€ä¸Šä¸‹æ–‡æ¡ä»¶åŒ–|Prasun Roy, Subhankar Ghosh, Saumik Bhattacharya, Umapada Pal, Michael Blumenstein|<http://arxiv.org/pdf/2206.02717v2>|None|


## æ‰©æ•£æ¡¥

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|RAPID: Retrieval Augmented Training of Differentially Private Diffusion Models|å¿«é€Ÿæ£€ç´¢å¢å¼ºçš„å·®åˆ†éšç§æ‰©æ•£æ¨¡å‹è®­ç»ƒ|Tanqiu Jiang, Changjiang Li, Fenglong Ma, Ting Wang|<http://arxiv.org/pdf/2502.12794v1>|<https://github.com/TanqiuJiang/RAPID>|
|ğŸ†• å‘å¸ƒ|High-Fidelity Novel View Synthesis via Splatting-Guided Diffusion|é«˜ä¿çœŸæ–°è§†è§’åˆæˆï¼šåŸºäºSplattingå¼•å¯¼çš„æ‰©æ•£|Xiang Zhang, Yang Zhang, Lukas Mehl, Markus Gross, Christopher Schroers|<http://arxiv.org/pdf/2502.12752v1>|None|
|ğŸ†• å‘å¸ƒ|RecDreamer: Consistent Text-to-3D Generation via Uniform Score Distillation|RecDreamerï¼šé€šè¿‡ç»Ÿä¸€åˆ†æ•°è’¸é¦å®ç°ä¸€è‡´çš„æ–‡æœ¬åˆ°3Dç”Ÿæˆ|Chenxi Zheng, Yihong Lin, Bangzhen Liu, Xuemiao Xu, Yongwei Nie, Shengfeng He|<http://arxiv.org/pdf/2502.12640v1>|None|


## æµæ¨¡å‹

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|L4P: Low-Level 4D Vision Perception Unified|L4Pï¼šä½çº§4Dè§†è§‰æ„ŸçŸ¥ç»Ÿä¸€|Abhishek Badki, Hang Su, Bowen Wen, Orazio Gallo|<http://arxiv.org/pdf/2502.13078v1>|None|
|ğŸ†• å‘å¸ƒ|Not-So-Optimal Transport Flows for 3D Point Cloud Generation|éæœ€ä¼˜ä¼ è¾“æµç”¨äº3Dç‚¹äº‘ç”Ÿæˆ|Ka-Hei Hui, Chao Liu, Xiaohui Zeng, Chi-Wing Fu, Arash Vahdat|<http://arxiv.org/pdf/2502.12456v1>|None|
|ğŸ“ æ›´æ–°|Post-processing of coronary and myocardial spatial data|å† çŠ¶åŠ¨è„‰å’Œå¿ƒè‚Œç©ºé—´æ•°æ®çš„åå¤„ç†|Jay Aodh Mackenzie, Megan Jeanne Miller, Nicholas Hill, Mette Olufsen|<http://arxiv.org/pdf/2207.14624v3>|None|


## å›¾åƒå¤„ç†

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Is Noise Conditioning Necessary for Denoising Generative Models?|å™ªå£°æ¡ä»¶å¯¹äºå»å™ªç”Ÿæˆæ¨¡å‹æ˜¯å¦å¿…è¦ï¼Ÿ|Qiao Sun, Zhicheng Jiang, Hanhong Zhao, Kaiming He|<http://arxiv.org/pdf/2502.13129v1>|None|
|ğŸ†• å‘å¸ƒ|Spherical Dense Text-to-Image Synthesis|çƒé¢å¯†é›†æ–‡æœ¬åˆ°å›¾åƒåˆæˆ|Timon Winter, Stanislav Frolov, Brian Bernhard Moser, Andreas Dengel|<http://arxiv.org/pdf/2502.12691v1>|None|
|ğŸ†• å‘å¸ƒ|Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining|é€šè¿‡å›¾åƒå»é›¨è§†è§’é‡æ–°å®¡è§†ä½çº§è§†è§‰æ¨¡å‹çš„æ³›åŒ–é—®é¢˜|Jinfan Hu, Zhiyuan You, Jinjin Gu, Kaiwen Zhu, Tianfan Xue, Chao Dong|<http://arxiv.org/pdf/2502.12600v1>|None|
|ğŸ†• å‘å¸ƒ|Learning Transformation-Isomorphic Latent Space for Accurate Hand Pose Estimation|å­¦ä¹ å˜æ¢åŒæ„æ½œåœ¨ç©ºé—´ä»¥å®ç°å‡†ç¡®çš„æ‰‹éƒ¨å§¿æ€ä¼°è®¡|Kaiwen Ren, Lei Hu, Zhiheng Zhang, Yongjing Ye, Shihong Xia|<http://arxiv.org/pdf/2502.12535v1>|None|
|ğŸ“ æ›´æ–°|VLMaterial: Procedural Material Generation with Large Vision-Language Models|VLMaterialï¼šåŸºäºå¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹çš„ç¨‹åºåŒ–æè´¨ç”Ÿæˆ|Beichen Li, Rundi Wu, Armando Solar-Lezama, Changxi Zheng, Liang Shi, Bernd Bickel, Wojciech Matusik|<http://arxiv.org/pdf/2501.18623v2>|None|
|ğŸ“ æ›´æ–°|LieRE: Generalizing Rotary Position Encodings|LieREï¼šæ—‹è½¬ä½ç½®ç¼–ç çš„æ³›åŒ–|Sophie Ostmeier, Brian Axelrod, Michael E. Moseley, Akshay Chaudhari, Curtis Langlotz|<http://arxiv.org/pdf/2406.10322v3>|None|
|ğŸ“ æ›´æ–°|BenthicNet: A global compilation of seafloor images for deep learning applications|æµ·åº•ç½‘ç»œï¼šç”¨äºæ·±åº¦å­¦ä¹ åº”ç”¨çš„å…¨çƒæµ·åº•å›¾åƒæ±‡ç¼–|Scott C. Lowe, Benjamin Misiuk, Isaac Xu, Shakhboz Abdulazizov, Amit R. Baroi, Alex C. Bastos, Merlin Best, Vicki Ferrini .etc.|<http://arxiv.org/pdf/2405.05241v3>|None|
|ğŸ“ æ›´æ–°|AttributionScanner: A Visual Analytics System for Model Validation with Metadata-Free Slice Finding|AttributionScannerï¼šä¸€ç§æ— å…ƒæ•°æ®åˆ‡ç‰‡æŸ¥æ‰¾çš„æ¨¡å‹éªŒè¯å¯è§†åŒ–åˆ†æç³»ç»Ÿ|Xiwei Xuan, Jorge Piazentin Ono, Liang Gou, Kwan-Liu Ma, Liu Ren|<http://arxiv.org/pdf/2401.06462v4>|None|
|ğŸ“ æ›´æ–°|A Unified Framework for Event-based Frame Interpolation with Ad-hoc Deblurring in the Wild|åŸºäºç°åœºäº‹ä»¶å¸§æ’å€¼ä¸é‡å¤–å³å…´å»æ¨¡ç³Šçš„ç»Ÿä¸€æ¡†æ¶|Lei Sun, Daniel Gehrig, Christos Sakaridis, Mathias Gehrig, Jingyun Liang, Peng Sun, Zhijie Xu, Kaiwei Wang .etc.|<http://arxiv.org/pdf/2301.05191v2>|<https://github.com/AHupuJR/REFID.>|
|ğŸ“ æ›´æ–°|Multi-scale Attention Guided Pose Transfer|å¤šå°ºåº¦æ³¨æ„åŠ›å¼•å¯¼çš„å§¿æ€è¿ç§»|Prasun Roy, Saumik Bhattacharya, Subhankar Ghosh, Umapada Pal|<http://arxiv.org/pdf/2202.06777v2>|None|


## 3Dåœºæ™¯

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SHADeS: Self-supervised Monocular Depth Estimation Through Non-Lambertian Image Decomposition|SHADeSï¼šé€šè¿‡éæœ—ä¼¯å›¾åƒåˆ†è§£è¿›è¡Œè‡ªç›‘ç£å•ç›®æ·±åº¦ä¼°è®¡|Rema Daher, Francisco Vasconcelos, Danail Stoyanov|<http://arxiv.org/pdf/2502.12994v1>|<https://github.com/RemaDaher/SHADeS.>|
|ğŸ†• å‘å¸ƒ|Archetypal SAE: Adaptive and Stable Dictionary Learning for Concept Extraction in Large Vision Models|å…¸å‹è‡ªç¼–ç å™¨ï¼šå¤§è§†è§‰æ¨¡å‹ä¸­æ¦‚å¿µæå–çš„è‡ªé€‚åº”å’Œç¨³å®šå­—å…¸å­¦ä¹ |Thomas Fel, Ekdeep Singh Lubana, Jacob S. Prince, Matthew Kowal, Victor Boutin, Isabel Papadimitriou, Binxu Wang, Martin Wattenberg .etc.|<http://arxiv.org/pdf/2502.12892v1>|None|
|ğŸ†• å‘å¸ƒ|NoKSR: Kernel-Free Neural Surface Reconstruction via Point Cloud Serialization|æ— æ ¸ç¥ç»ç½‘ç»œè¡¨é¢é‡å»ºï¼šé€šè¿‡ç‚¹äº‘åºåˆ—åŒ–|Zhen Li, Weiwei Sun, Shrisudhan Govindarajan, Shaobo Xia, Daniel Rebain, Kwang Moo Yi, Andrea Tagliasacchi|<http://arxiv.org/pdf/2502.12534v1>|None|
|ğŸ“ æ›´æ–°|A Causally Informed Pretraining Approach for Multimodal Foundation Models: Applications in Remote Sensing|å› æœä¿¡æ¯é©±åŠ¨çš„å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹é¢„è®­ç»ƒæ–¹æ³•ï¼šé¥æ„Ÿåº”ç”¨|Praveen Ravirathinam, Ankush Khandelwal, Rahul Ghosh, Vipin Kumar|<http://arxiv.org/pdf/2407.19660v3>|None|


## ç¥ç»æ¸²æŸ“

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|PartSDF: Part-Based Implicit Neural Representation for Composite 3D Shape Parametrization and Optimization|åŸºäºéƒ¨ä»¶çš„éšå¼ç¥ç»è¡¨ç¤ºç”¨äºå¤åˆææ–™3Då½¢çŠ¶å‚æ•°åŒ–å’Œä¼˜åŒ–|Nicolas Talabot, Olivier Clerc, Arda Cinar Demirtas, Doruk Oner, Pascal Fua|<http://arxiv.org/pdf/2502.12985v1>|<https://github.com/cvlab-epfl/PartSDF.>|
|ğŸ†• å‘å¸ƒ|Leveraging Intermediate Representations for Better Out-of-Distribution Detection|åˆ©ç”¨ä¸­é—´è¡¨ç¤ºè¿›è¡Œæ›´å¥½çš„åˆ†å¸ƒå¤–æ£€æµ‹|Gianluca Guglielmo, Marc Masana|<http://arxiv.org/pdf/2502.12849v1>|None|
|ğŸ†• å‘å¸ƒ|Beyond Timesteps: A Novel Activation-wise Membrane Potential Propagation Mechanism for Spiking Neural Networks in 3D cloud|è¶…è¶Šæ—¶é—´æ­¥ï¼šä¸€ç§ç”¨äº3Däº‘ä¸­è„‰å†²ç¥ç»ç½‘ç»œçš„æ–°å‹åŸºäºæ¿€æ´»çš„è†œç”µä½ä¼ æ’­æœºåˆ¶|Jian Song, Boxuan Zheng, Xiangfei Yang, Donglin Wang|<http://arxiv.org/pdf/2502.12791v1>|None|
|ğŸ†• å‘å¸ƒ|ROI-NeRFs: Hi-Fi Visualization of Objects of Interest within a Scene by NeRFs Composition|ROI-NeRFsï¼šåŸºäºNeRFç»„åˆçš„æ„Ÿå…´è¶£åŒºåŸŸé«˜ä¿çœŸå¯è§†åŒ–|Quoc-Anh Bui, Gilles Rougeron, GÃ©raldine Morin, Simone Gasparini|<http://arxiv.org/pdf/2502.12673v1>|None|
|ğŸ†• å‘å¸ƒ|S2C: Learning Noise-Resistant Differences for Unsupervised Change Detection in Multimodal Remote Sensing Images|S2Cï¼šå­¦ä¹ å¤šæ¨¡æ€é¥æ„Ÿå›¾åƒæ— ç›‘ç£å˜åŒ–æ£€æµ‹çš„æŠ—å™ªå£°å·®å¼‚|Lei Ding, Xibing Zuo, Danfeng Hong, Haitao Guo, Jun Lu, Zhihui Gong, Lorenzo Bruzzone|<http://arxiv.org/pdf/2502.12604v1>|<https://github.com/DingLei14/S2C.>|
|ğŸ†• å‘å¸ƒ|IM360: Textured Mesh Reconstruction for Large-scale Indoor Mapping with 360$^\circ$ Cameras|IM360ï¼šåŸºäº360Â°ç›¸æœºçš„å®¤å†…å¤§è§„æ¨¡åœ°å›¾çº¹ç†ç½‘æ ¼é‡å»º|Dongki Jung, Jaehoon Choi, Yonghan Lee, Dinesh Manocha|<http://arxiv.org/pdf/2502.12545v1>|None|
|ğŸ†• å‘å¸ƒ|Enhancing Audio-Visual Spiking Neural Networks through Semantic-Alignment and Cross-Modal Residual Learning|é€šè¿‡è¯­ä¹‰å¯¹é½å’Œè·¨æ¨¡æ€æ®‹å·®å­¦ä¹ å¢å¼ºéŸ³é¢‘-è§†è§‰è„‰å†²ç¥ç»ç½‘ç»œ|Xiang He, Dongcheng Zhao, Yiting Dong, Guobin Shen, Xin Yang, Yi Zeng|<http://arxiv.org/pdf/2502.12488v1>|<https://github.com/Brain-Cog-Lab/S-CMRL.>|
|ğŸ†• å‘å¸ƒ|Multi Image Super Resolution Modeling for Earth System Models|å¤šå›¾åƒè¶…åˆ†è¾¨ç‡å»ºæ¨¡ç”¨äºåœ°çƒç³»ç»Ÿæ¨¡å‹|Ehsan Zeraatkar, Salah A Faroughi, Jelena TeÅ¡iÄ‡|<http://arxiv.org/pdf/2502.12427v1>|None|
|ğŸ†• å‘å¸ƒ|Boosting Illuminant Estimation in Deep Color Constancy through Enhancing Brightness Robustness|é€šè¿‡å¢å¼ºäº®åº¦é²æ£’æ€§æå‡æ·±åº¦é¢œè‰²æ’å¸¸æ€§ä¸­çš„å…‰æºä¼°è®¡|Mengda Xie, Chengzhi Zhong, Yiling He, Zhan Qin, Meie Fang|<http://arxiv.org/pdf/2502.12418v1>|None|
|ğŸ“ æ›´æ–°|TEASER: Token Enhanced Spatial Modeling for Expressions Reconstruction|æ ‡é¢˜ç¿»è¯‘ï¼šåŸºäºæ ‡è®°å¢å¼ºçš„ç©ºé—´å»ºæ¨¡ç”¨äºè¡¨æƒ…é‡å»º|Yunfei Liu, Lei Zhu, Lijian Lin, Ye Zhu, Ailing Zhang, Yu Li|<http://arxiv.org/pdf/2502.10982v2>|None|
|ğŸ“ æ›´æ–°|Dreamweaver: Learning Compositional World Representations from Pixels|æ¢¦å¹»ç¼–ç»‡è€…ï¼šä»åƒç´ ä¸­å­¦ä¹ ç»„åˆä¸–ç•Œè¡¨ç¤º|Junyeob Baek, Yi-Fu Wu, Gautam Singh, Sungjin Ahn|<http://arxiv.org/pdf/2501.14174v2>|None|
|ğŸ“ æ›´æ–°|Where Do We Stand with Implicit Neural Representations? A Technical and Performance Survey|æˆ‘ä»¬ä¸éšå¼ç¥ç»ç½‘ç»œè¡¨ç¤ºå¤„äºä½•ç§å¢ƒåœ°ï¼Ÿä¸€é¡¹æŠ€æœ¯åŠæ€§èƒ½ç»¼è¿°|Amer Essakine, Yanqi Cheng, Chun-Wun Cheng, Lipei Zhang, Zhongying Deng, Lei Zhu, Carola-Bibiane SchÃ¶nlieb, Angelica I Aviles-Rivero|<http://arxiv.org/pdf/2411.03688v2>|None|
|ğŸ“ æ›´æ–°|Explanation Bottleneck Models|è§£é‡Šç“¶é¢ˆæ¨¡å‹|Shin'ya Yamaguchi, Kosuke Nishida|<http://arxiv.org/pdf/2409.17663v3>|<https://github.com/yshinya6/xbm>|
|ğŸ“ æ›´æ–°|Position and Rotation Invariant Sign Language Recognition from 3D Kinect Data with Recurrent Neural Networks|åŸºäºå¾ªç¯ç¥ç»ç½‘ç»œä»3D Kinectæ•°æ®ä¸­å®ç°ä½ç½®å’Œæ—‹è½¬ä¸å˜çš„æ‰‹è¯­è¯†åˆ«|Prasun Roy, Saumik Bhattacharya, Partha Pratim Roy, Umapada Pal|<http://arxiv.org/pdf/2010.12669v4>|None|


## 3DGS

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|GARAD-SLAM: 3D GAussian splatting for Real-time Anti Dynamic SLAM|GARAD-SLAMï¼šå®æ—¶æŠ—åŠ¨æ€SLAMçš„3Dé«˜æ–¯åˆ†å±‚|Mingrui Li, Weijian Chen, Na Cheng, Jingyuan Xu, Dong Li, Hongyu Wang|<http://arxiv.org/pdf/2502.03228v2>|None|


## å¤šæ¨¡æ€

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Re-Align: Aligning Vision Language Models via Retrieval-Augmented Direct Preference Optimization|é‡å¯¹é½ï¼šé€šè¿‡æ£€ç´¢å¢å¼ºçš„ç›´æ¥åå¥½ä¼˜åŒ–å¯¹é½è§†è§‰è¯­è¨€æ¨¡å‹|Shuo Xing, Yuping Wang, Peiran Li, Ruizheng Bai, Yueqi Wang, Chengxuan Qian, Huaxiu Yao, Zhengzhong Tu|<http://arxiv.org/pdf/2502.13146v1>|<https://github.com/taco-group/Re-Align.>|
|ğŸ†• å‘å¸ƒ|Understanding and Rectifying Safety Perception Distortion in VLMs|ç†è§£ä¸æ ¡æ­£VLMsä¸­çš„å®‰å…¨æ„ŸçŸ¥æ‰­æ›²|Xiaohan Zou, Jian Kang, George Kesidis, Lu Lin|<http://arxiv.org/pdf/2502.13095v1>|None|
|ğŸ†• å‘å¸ƒ|Improved Fine-Tuning of Large Multimodal Models for Hateful Meme Detection|æ”¹è¿›å¤§å‹å¤šæ¨¡æ€æ¨¡å‹åœ¨ä»‡æ¨è¡¨æƒ…åŒ…æ£€æµ‹ä¸­çš„å¾®è°ƒ|Jingbiao Mei, Jinghong Chen, Guangyu Yang, Weizhe Lin, Bill Byrne|<http://arxiv.org/pdf/2502.13061v1>|None|
|ğŸ†• å‘å¸ƒ|Towards Text-Image Interleaved Retrieval|è¿ˆå‘æ–‡æœ¬-å›¾åƒäº¤é”™æ£€ç´¢|Xin Zhang, Ziqi Dai, Yongqi Li, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, Jun Yu .etc.|<http://arxiv.org/pdf/2502.12799v1>|None|
|ğŸ†• å‘å¸ƒ|Corrupted but Not Broken: Rethinking the Impact of Corrupted Data in Visual Instruction Tuning|ã€ŠæŸåä½†æœªç ´ç¢ï¼šé‡æ–°æ€è€ƒæŸåæ•°æ®åœ¨è§†è§‰æŒ‡ä»¤å¾®è°ƒä¸­çš„å½±å“ã€‹|Yunhao Gou, Hansi Yang, Zhili Liu, Kai Chen, Yihan Zeng, Lanqing Hong, Zhenguo Li, Qun Liu .etc.|<http://arxiv.org/pdf/2502.12635v1>|None|
|ğŸ†• å‘å¸ƒ|CutPaste&Find: Efficient Multimodal Hallucination Detector with Visual-aid Knowledge Base|CutPaste&Findï¼šåŸºäºè§†è§‰çŸ¥è¯†åº“çš„é«˜æ•ˆå¤šæ¨¡æ€å¹»è§‰æ£€æµ‹å™¨|Cong-Duy Nguyen, Xiaobao Wu, Duc Anh Vu, Shuai Zhao, Thong Nguyen, Anh Tuan Luu|<http://arxiv.org/pdf/2502.12591v1>|None|
|ğŸ†• å‘å¸ƒ|Comprehensive Assessment and Analysis for NSFW Content Erasure in Text-to-Image Diffusion Models|å…¨é¢è¯„ä¼°ä¸åˆ†ææ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­NSFWå†…å®¹æ“¦é™¤|Die Chen, Zhiwen Li, Cen Chen, Xiaodan Li, Jinyan Ye|<http://arxiv.org/pdf/2502.12527v1>|None|
|ğŸ†• å‘å¸ƒ|SAFEERASER: Enhancing Safety in Multimodal Large Language Models through Multimodal Machine Unlearning|å®‰å…¨æ“¦é™¤å™¨ï¼šé€šè¿‡å¤šæ¨¡æ€æœºå™¨åå­¦ä¹ å¢å¼ºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§|Junkai Chen, Zhijie Deng, Kening Zheng, Yibo Yan, Shuliang Liu, PeiJun Wu, Peijie Jiang, Jia Liu .etc.|<http://arxiv.org/pdf/2502.12520v1>|None|
|ğŸ†• å‘å¸ƒ|RealSyn: An Effective and Scalable Multimodal Interleaved Document Transformation Paradigm|çœŸå®åˆæˆï¼šä¸€ç§æœ‰æ•ˆä¸”å¯æ‰©å±•çš„å¤šæ¨¡æ€äº¤é”™æ–‡æ¡£è½¬æ¢èŒƒå¼|Tiancheng Gu, Kaicheng Yang, Chaoyi Zhang, Yin Xie, Xiang An, Ziyong Feng, Dongnan Liu, Weidong Cai .etc.|<http://arxiv.org/pdf/2502.12513v1>|<https://github.com/deepglint/RealSyn.>|
|ğŸ†• å‘å¸ƒ|Robust Disentangled Counterfactual Learning for Physical Audiovisual Commonsense Reasoning|é²æ£’è§£è€¦åäº‹å®å­¦ä¹ ç”¨äºç‰©ç†è§†å¬å¸¸è¯†æ¨ç†|Mengshi Qi, Changsheng Lv, Huadong Ma|<http://arxiv.org/pdf/2502.12425v1>|None|
|ğŸ“ æ›´æ–°|Do Large Multimodal Models Solve Caption Generation for Scientific Figures? Lessons Learned from SciCap Challenge 2023|å¤§å‹å¤šæ¨¡æ€æ¨¡å‹èƒ½å¦è§£å†³ç§‘å­¦å›¾è±¡çš„æ ‡é¢˜ç”Ÿæˆï¼Ÿä»SciCapæŒ‘æˆ˜2023ä¸­æ±²å–çš„æ•™è®­|Ting-Yao E. Hsu, Yi-Li Hsu, Shaurya Rohatgi, Chieh-Yang Huang, Ho Yin Sam Ng, Ryan Rossi, Sungchul Kim, Tong Yu .etc.|<http://arxiv.org/pdf/2501.19353v3>|None|
|ğŸ“ æ›´æ–°|Can Multimodal LLMs do Visual Temporal Understanding and Reasoning? The answer is No!|å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹èƒ½å¦è¿›è¡Œè§†è§‰æ—¶ç©ºç†è§£å’Œæ¨ç†ï¼Ÿç­”æ¡ˆæ˜¯ï¼šä¸èƒ½ï¼|Mohamed Fazli Imam, Chenyang Lyu, Alham Fikri Aji|<http://arxiv.org/pdf/2501.10674v2>|None|
|ğŸ“ æ›´æ–°|Migician: Revealing the Magic of Free-Form Multi-Image Grounding in Multimodal Large Language Models|ç±³å‰å®‰ï¼šæ­ç¤ºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­è‡ªç”±å½¢å¼å¤šå›¾åƒå®šä½çš„é­”æ³•|You Li, Heyu Huang, Chi Chen, Kaiyu Huang, Chao Huang, Zonghao Guo, Zhiyuan Liu, Jinan Xu .etc.|<http://arxiv.org/pdf/2501.05767v3>|<https://migician-vg.github.io/.>|
|ğŸ“ æ›´æ–°|Mitigating Modality Prior-Induced Hallucinations in Multimodal Large Language Models via Deciphering Attention Causality|é€šè¿‡è§£ç æ³¨æ„åŠ›å› æœæ€§å‡è½»å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„æ¨¡æ€å…ˆéªŒè¯±å¯¼çš„å¹»è§‰|Guanyu Zhou, Yibo Yan, Xin Zou, Kun Wang, Aiwei Liu, Xuming Hu|<http://arxiv.org/pdf/2410.04780v2>|<https://github.com/The-Martyr/CausalMM>|
|ğŸ“ æ›´æ–°|SynthVLM: High-Efficiency and High-Quality Synthetic Data for Vision Language Models|SynthVLMï¼šç”¨äºè§†è§‰è¯­è¨€æ¨¡å‹çš„è¶…é«˜æ•ˆç‡å’Œé«˜è´¨é‡åˆæˆæ•°æ®|Zheng Liu, Hao Liang, Bozhou Li, Tianyi Bai, Wentao Xiong, Chong Chen, Conghui He, Wentao Zhang .etc.|<http://arxiv.org/pdf/2407.20756v4>|<https://github.com/starriver030515/SynthVLM.>|
|ğŸ“ æ›´æ–°|RU-AI: A Large Multimodal Dataset for Machine-Generated Content Detection|RU-AIï¼šç”¨äºæœºå™¨ç”Ÿæˆå†…å®¹æ£€æµ‹çš„å¤§å‹å¤šæ¨¡æ€æ•°æ®é›†|Liting Huang, Zhihao Zhang, Yiran Zhang, Xiyue Zhou, Shoujin Wang|<http://arxiv.org/pdf/2406.04906v3>|<https://github.com/ZhihaoZhang97/RU-AI.>|


## å…·èº«æ™ºèƒ½

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|RAD: Training an End-to-End Driving Policy via Large-Scale 3DGS-based Reinforcement Learning|åŸºäºå¤§è§„æ¨¡3DGSçš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒç«¯åˆ°ç«¯é©¾é©¶ç­–ç•¥ï¼šRAD|Hao Gao, Shaoyu Chen, Bo Jiang, Bencheng Liao, Yiang Shi, Xiaoyang Guo, Yuechuan Pu, Haoran Yin .etc.|<http://arxiv.org/pdf/2502.13144v1>|<https://hgao-cv.github.io/RAD.>|
|ğŸ†• å‘å¸ƒ|SoFar: Language-Grounded Orientation Bridges Spatial Reasoning and Object Manipulation|SoFarï¼šåŸºäºè¯­è¨€çš„å§¿æ€æ¡¥æ¢è¿æ¥ç©ºé—´æ¨ç†å’Œç‰©ä½“æ“ä½œ|Zekun Qi, Wenyao Zhang, Yufei Ding, Runpei Dong, Xinqiang Yu, Jingwen Li, Lingyun Xu, Baoyu Li .etc.|<http://arxiv.org/pdf/2502.13143v1>|None|
|ğŸ†• å‘å¸ƒ|Mean of Means: Human Localization with Calibration-free and Unconstrained Camera Settings (extended version)|å‡å€¼å‡å€¼ï¼šæ— éœ€æ ¡å‡†å’Œä¸å—é™åˆ¶ç›¸æœºè®¾ç½®çš„è§†è§‰å®šä½ï¼ˆæ‰©å±•ç‰ˆï¼‰|Tianyi Zhang, Wengyu Zhang, Xulu Zhang, Jiaxin Wu, Xiao-Yong Wei, Jiannong Cao, Qing Li|<http://arxiv.org/pdf/2502.13017v1>|None|
|ğŸ†• å‘å¸ƒ|Predicate Hierarchies Improve Few-Shot State Classification|è°“è¯å±‚æ¬¡ç»“æ„æå‡å°‘æ ·æœ¬çŠ¶æ€åˆ†ç±»|Emily Jin, Joy Hsu, Jiajun Wu|<http://arxiv.org/pdf/2502.12481v1>|None|
|ğŸ†• å‘å¸ƒ|Multi-vision-based Picking Point Localisation of Target Fruit for Harvesting Robots|åŸºäºå¤šè§†è§‰çš„ç›®æ ‡æ°´æœé‡‡æ‘˜æœºå™¨äººæ‹¾å–ç‚¹å®šä½|C. Beldek, A. Dunn, J. Cunningham, E. Sariyildiz, S. L. Phung, G. Alici|<http://arxiv.org/pdf/2502.12406v1>|None|
|ğŸ“ æ›´æ–°|A Real-to-Sim-to-Real Approach to Robotic Manipulation with VLM-Generated Iterative Keypoint Rewards|åŸºäºVLMç”Ÿæˆè¿­ä»£å…³é”®ç‚¹å¥–åŠ±çš„ä»çœŸå®åˆ°æ¨¡æ‹Ÿå†åˆ°çœŸå®æœºå™¨äººæ“ä½œæ–¹æ³•|Shivansh Patel, Xinchen Yin, Wenlong Huang, Shubham Garg, Hooshang Nayyeri, Li Fei-Fei, Svetlana Lazebnik, Yunzhu Li|<http://arxiv.org/pdf/2502.08643v2>|None|
|ğŸ“ æ›´æ–°|Bayesian Low-Rank LeArning (Bella): A Practical Approach to Bayesian Neural Networks|è´å¶æ–¯ä½ç§©å­¦ä¹ ï¼ˆBellaï¼‰ï¼šè´å¶æ–¯ç¥ç»ç½‘ç»œçš„å®é™…æ–¹æ³•|Bao Gia Doan, Afshar Shamsi, Xiao-Yu Guo, Arash Mohammadi, Hamid Alinejad-Rokny, Dino Sejdinovic, Damien Teney, Damith C. Ranasinghe .etc.|<http://arxiv.org/pdf/2407.20891v5>|None|
|ğŸ“ æ›´æ–°|DarSwin-Unet: Distortion Aware Encoder-Decoder Architecture|DarSwin-U-Netï¼šå¤±çœŸæ„ŸçŸ¥ç¼–ç å™¨-è§£ç å™¨æ¶æ„|Akshaya Athwale, Ichrak Shili, Ã‰mile Bergeron, Ola Ahmad, Jean-FranÃ§ois Lalonde|<http://arxiv.org/pdf/2407.17328v2>|None|
|ğŸ“ æ›´æ–°|R3L: Relative Representations for Reinforcement Learning|R3Lï¼šå¼ºåŒ–å­¦ä¹ ä¸­çš„ç›¸å¯¹è¡¨ç¤º|Antonio Pio Ricciardi, Valentino Maiorca, Luca Moschella, Riccardo Marin, Emanuele RodolÃ |<http://arxiv.org/pdf/2404.12917v3>|None|
|ğŸ“ æ›´æ–°|Deep Learning for Cross-Domain Few-Shot Visual Recognition: A Survey|æ·±åº¦å­¦ä¹ åœ¨è·¨åŸŸå°æ ·æœ¬è§†è§‰è¯†åˆ«ä¸­çš„åº”ç”¨ï¼šç»¼è¿°|Huali Xu, Shuaifeng Zhi, Shuzhou Sun, Vishal M. Patel, Li Liu|<http://arxiv.org/pdf/2303.08557v4>|None|


## äººä½“åˆ†æ

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Natural Language Generation from Visual Sequences: Challenges and Future Directions|ä»è§†è§‰åºåˆ—ç”Ÿæˆè‡ªç„¶è¯­è¨€ï¼šæŒ‘æˆ˜ä¸æœªæ¥æ–¹å‘|Aditya K Surikuchi, Raquel FernÃ¡ndez, Sandro Pezzelle|<http://arxiv.org/pdf/2502.13034v1>|None|
|ğŸ†• å‘å¸ƒ|CHATS: Combining Human-Aligned Optimization and Test-Time Sampling for Text-to-Image Generation|CHATSï¼šç»“åˆäººç±»å¯¹é½ä¼˜åŒ–å’Œæµ‹è¯•æ—¶é‡‡æ ·è¿›è¡Œæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ|Minghao Fu, Guo-Hua Wang, Liangfu Cao, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang|<http://arxiv.org/pdf/2502.12579v1>|None|
|ğŸ†• å‘å¸ƒ|Spatiotemporal Multi-Camera Calibration using Freely Moving People|æ—¶ç©ºå¤šæ‘„åƒå¤´æ ‡å®šï¼šåˆ©ç”¨è‡ªç”±ç§»åŠ¨çš„äºº|Sang-Eun Lee, Ko Nishino, Shohei Nobuhara|<http://arxiv.org/pdf/2502.12546v1>|None|
|ğŸ†• å‘å¸ƒ|Benchmarking Zero-Shot Facial Emotion Annotation with Large Language Models: A Multi-Class and Multi-Frame Approach in DailyLife|åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„é›¶æ ·æœ¬é¢éƒ¨æƒ…æ„Ÿæ ‡æ³¨åŸºå‡†æµ‹è¯•ï¼šæ—¥å¸¸ç”Ÿæ´»åœºæ™¯ä¸­çš„å¤šç±»åˆ«å’Œå¤šå¸§æ–¹æ³•|He Zhang, Xinyi Fu|<http://arxiv.org/pdf/2502.12454v1>|None|
|ğŸ“ æ›´æ–°|A Physical Coherence Benchmark for Evaluating Video Generation Models via Optical Flow-guided Frame Prediction|åŸºäºå…‰æµå¼•å¯¼çš„å¸§é¢„æµ‹è¯„ä¼°è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„ç‰©ç†ä¸€è‡´æ€§åŸºå‡†|Yongfan Chen, Xiuwen Zhu, Tianyu Li, Hao Chen, Chunhua Shen|<http://arxiv.org/pdf/2502.05503v2>|<https://github.com/Jeckinchen/PhyCoBench.>|
|ğŸ“ æ›´æ–°|T2VEval: T2V-generated Videos Benchmark Dataset and Objective Evaluation Method|T2VEvalï¼šT2Vç”Ÿæˆè§†é¢‘åŸºå‡†æ•°æ®é›†å’Œå®¢è§‚è¯„ä¼°æ–¹æ³•|Zelu Qi, Ping Shi, Shuqi Wang, Zhaoyang Zhang, Fei Zhao, Zefeng Ying, Da Pan|<http://arxiv.org/pdf/2501.08545v4>|None|
|ğŸ“ æ›´æ–°|HumanEval-V: Benchmarking High-Level Visual Reasoning with Complex Diagrams in Coding Tasks|äººç±»è¯„ä¼°-Vï¼šåœ¨ç¼–ç ä»»åŠ¡ä¸­ç”¨å¤æ‚å›¾è¡¨è¿›è¡Œé«˜çº§è§†è§‰æ¨ç†çš„åŸºå‡†æµ‹è¯•|Fengji Zhang, Linquan Wu, Huiyu Bai, Guancheng Lin, Xiao Li, Xiao Yu, Yue Wang, Bei Chen .etc.|<http://arxiv.org/pdf/2410.12381v3>|<https://github.com/HumanEval-V/HumanEval-V-Benchmark.>|
|ğŸ“ æ›´æ–°|Human and AI Perceptual Differences in Image Classification Errors|äººç±»ä¸AIåœ¨å›¾åƒåˆ†ç±»é”™è¯¯ä¸­çš„æ„ŸçŸ¥å·®å¼‚|Minghao Liu, Jiaheng Wei, Yang Liu, James Davis|<http://arxiv.org/pdf/2304.08733v2>|None|


## äººè„¸æŠ€æœ¯

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|GVTNet: Graph Vision Transformer For Face Super-Resolution|GVTNetï¼šé¢å‘äººè„¸è¶…åˆ†è¾¨ç‡çš„å›¾è§†è§‰Transformer|Chao Yang, Yong Fan, Cheng Lu, Minghao Yuan, Zhijing Yang|<http://arxiv.org/pdf/2502.12570v1>|<https://github.com/continueyang/GVTNet>|


## æ•°å­—äºº

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Magma: A Foundation Model for Multimodal AI Agents|å²©æµ†ï¼šå¤šæ¨¡æ€äººå·¥æ™ºèƒ½ä»£ç†çš„åŸºç¡€æ¨¡å‹|Jianwei Yang, Reuben Tan, Qianhui Wu, Ruijie Zheng, Baolin Peng, Yongyuan Liang, Yu Gu, Mu Cai .etc.|<http://arxiv.org/pdf/2502.13130v1>|<https://microsoft.github.io/Magma.>|
|ğŸ†• å‘å¸ƒ|MomentSeeker: A Comprehensive Benchmark and A Strong Baseline For Moment Retrieval Within Long Videos|MomentSeekerï¼šé•¿è§†é¢‘å†…ç¬é—´æ£€ç´¢çš„å…¨é¢åŸºå‡†ä¸å¼ºå¤§åŸºçº¿|Huaying Yuan, Jian Ni, Yueze Wang, Junjie Zhou, Zhengyang Liang, Zheng Liu, Zhao Cao, Zhicheng Dou .etc.|<http://arxiv.org/pdf/2502.12558v1>|None|
|ğŸ“ æ›´æ–°|Don't drop your samples! Coherence-aware training benefits Conditional diffusion|ä¸è¦ä¸¢å¼ƒä½ çš„æ ·æœ¬ï¼ä¸€è‡´æ€§æ„ŸçŸ¥è®­ç»ƒåŠ©åŠ›æ¡ä»¶æ‰©æ•£|Nicolas Dufour, Victor Besnier, Vicky Kalogeiton, David Picard|<http://arxiv.org/pdf/2405.20324v2>|None|


## æ¨¡å‹ä¼˜åŒ–

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Multimodal Mamba: Decoder-only Multimodal State Space Model via Quadratic to Linear Distillation|å¤šæ¨¡æ€Mambaï¼šé€šè¿‡äºŒæ¬¡åˆ°çº¿æ€§è’¸é¦çš„ä»…è§£ç å™¨å¤šæ¨¡æ€çŠ¶æ€ç©ºé—´æ¨¡å‹|Bencheng Liao, Hongyuan Tao, Qian Zhang, Tianheng Cheng, Yingyue Li, Haoran Yin, Wenyu Liu, Xinggang Wang|<http://arxiv.org/pdf/2502.13145v1>|<https://github.com/hustvl/mmMamba>|
|ğŸ†• å‘å¸ƒ|CAST: Component-Aligned 3D Scene Reconstruction from an RGB Image|CASTï¼šåŸºäºRGBå›¾åƒçš„ç»„ä»¶å¯¹é½3Dåœºæ™¯é‡å»º|Kaixin Yao, Longwen Zhang, Xinhao Yan, Yan Zeng, Qixuan Zhang, Lan Xu, Wei Yang, Jiayuan Gu .etc.|<http://arxiv.org/pdf/2502.12894v1>|None|
|ğŸ“ æ›´æ–°|Learning to Stop Overthinking at Test Time|å­¦ä¹ åœ¨æµ‹è¯•æ—¶åœæ­¢è¿‡åº¦æ€è€ƒ|Hieu Tran Bao, Nguyen Cong Dat, Nguyen Duc Anh, Hoang Thanh-Tung|<http://arxiv.org/pdf/2502.10954v2>|None|
|ğŸ“ æ›´æ–°|RedundancyLens: Revealing and Exploiting Visual Token Processing Redundancy for Efficient Decoder-Only MLLMs|å†—ä½™é•œå¤´ï¼šæ­ç¤ºå’Œåˆ©ç”¨è§†è§‰æ ‡è®°å¤„ç†å†—ä½™ä»¥å®ç°é«˜æ•ˆä»…è§£ç å™¨å¤šè¯­è¨€è¯­è¨€æ¨¡å‹|Hongliang Li, Jiaxin Zhang, Wenhui Liao, Dezhi Peng, Kai Ding, Lianwen Jin|<http://arxiv.org/pdf/2501.19036v2>|<https://github.com/L-Hugh/RedundancyLens.>|
|ğŸ“ æ›´æ–°|Ctrl-U: Robust Conditional Image Generation via Uncertainty-aware Reward Modeling|Ctrl-Uï¼šåŸºäºä¸ç¡®å®šæ€§æ„ŸçŸ¥å¥–åŠ±å»ºæ¨¡çš„é²æ£’æ¡ä»¶å›¾åƒç”Ÿæˆ|Guiyu Zhang, Huan-ang Gao, Zijian Jiang, Hao Zhao, Zhedong Zheng|<http://arxiv.org/pdf/2410.11236v2>|<https://grenoble-zhang.github.io/Ctrl-U-Page>|
|ğŸ“ æ›´æ–°|CSA: Data-efficient Mapping of Unimodal Features to Multimodal Features|CSAï¼šå•æ¨¡æ€ç‰¹å¾åˆ°å¤šæ¨¡æ€ç‰¹å¾çš„æ•°æ®é«˜æ•ˆæ˜ å°„|Po-han Li, Sandeep P. Chinchali, Ufuk Topcu|<http://arxiv.org/pdf/2410.07610v3>|None|


## åŒ»å­¦åº”ç”¨

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|A deep learning framework for efficient pathology image analysis|æ·±åº¦å­¦ä¹ æ¡†æ¶åœ¨ç—…ç†å›¾åƒåˆ†æä¸­çš„é«˜æ•ˆåº”ç”¨|Peter Neidlinger, Tim Lenz, Sebastian Foersch, Chiara M. L. Loeffler, Jan Clusmann, Marco Gustav, Lawrence A. Shaktah, Rupert Langer .etc.|<http://arxiv.org/pdf/2502.13027v1>|None|
|ğŸ†• å‘å¸ƒ|Fake It Till You Make It: Using Synthetic Data and Domain Knowledge for Improved Text-Based Learning for LGE Detection|ä¼ªé€ è‡³æˆåŠŸï¼šåˆ©ç”¨åˆæˆæ•°æ®å’Œé¢†åŸŸçŸ¥è¯†æå‡åŸºäºæ–‡æœ¬çš„LGEæ£€æµ‹å­¦ä¹ |Athira J Jacob, Puneet Sharma, Daniel Rueckert|<http://arxiv.org/pdf/2502.12948v1>|None|
|ğŸ†• å‘å¸ƒ|Carotid Artery Plaque Analysis in 3D Based on Distance Encoding in Mesh Representations|åŸºäºç½‘æ ¼è¡¨ç¤ºä¸­è·ç¦»ç¼–ç çš„3Dé¢ˆåŠ¨è„‰æ–‘å—åˆ†æ|Hinrich Rahlfs, Markus HÃ¼llebrand, Sebastian Schmitter, Christoph Strecker, Andreas Harloff, Anja Hennemuth|<http://arxiv.org/pdf/2502.12819v1>|None|
|ğŸ†• å‘å¸ƒ|Learning Wall Segmentation in 3D Vessel Trees using Sparse Annotations|åŸºäºç¨€ç–æ ‡æ³¨åœ¨3Dè¡€ç®¡æ ‘ä¸­è¿›è¡Œå­¦ä¹ å¢™åˆ†å‰²|Hinrich Rahlfs, Markus HÃ¼llebrand, Sebastian Schmitter, Christoph Strecker, Andreas Harloff, Anja Hennemuth|<http://arxiv.org/pdf/2502.12801v1>|None|
|ğŸ†• å‘å¸ƒ|Uncertainty Propagation for Echocardiography Clinical Metric Estimation via Contour Sampling|åŸºäºè½®å»“é‡‡æ ·çš„è¶…å£°å¿ƒåŠ¨å›¾ä¸´åºŠæŒ‡æ ‡ä¼°è®¡çš„ä¸ç¡®å®šæ€§ä¼ æ’­|Thierry Judge, Olivier Bernard, Woo-Jin Cho Kim, Alberto Gomez, Arian Beqiri, Agisilaos Chartsias, Pierre-Marc Jodoin|<http://arxiv.org/pdf/2502.12713v1>|<https://github.com/ThierryJudge/contouring-uncertainty.>|
|ğŸ†• å‘å¸ƒ|Fast Data Aware Neural Architecture Search via Supernet Accelerated Evaluation|å¿«é€Ÿæ•°æ®æ„ŸçŸ¥ç¥ç»æ¶æ„æœç´¢é€šè¿‡è¶…ç½‘ç»œåŠ é€Ÿè¯„ä¼°|Emil Njor, Colby Banbury, Xenofon Fafoutis|<http://arxiv.org/pdf/2502.12690v1>|None|
|ğŸ“ æ›´æ–°|VividMed: Vision Language Model with Versatile Visual Grounding for Medicine|VividMedï¼šé€‚ç”¨äºåŒ»å­¦çš„é€šç”¨è§†è§‰å®šä½è§†è§‰è¯­è¨€æ¨¡å‹|Lingxiao Luo, Bingda Tang, Xuanzhong Chen, Rong Han, Ting Chen|<http://arxiv.org/pdf/2410.12694v2>|<https://github.com/function2-llx/MMMM.>|
|ğŸ“ æ›´æ–°|LADDER: Language Driven Slice Discovery and Error Rectification|LADDERï¼šåŸºäºè¯­è¨€çš„åˆ‡ç‰‡å‘ç°ä¸é”™è¯¯çº æ­£|Shantanu Ghosh, Rayan Syed, Chenyu Wang, Clare B. Poynton, Shyam Visweswaran, Kayhan Batmanghelich|<http://arxiv.org/pdf/2408.07832v9>|None|


## å…¶ä»–

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|LLMPopcorn: An Empirical Study of LLMs as Assistants for Popular Micro-video Generation|LLMPopcornï¼šå…³äºå¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºæµè¡Œå¾®è§†é¢‘ç”ŸæˆåŠ©æ‰‹çš„å®è¯ç ”ç©¶|Junchen Fu, Xuri Ge, Kaiwen Zheng, Ioannis Arapakis, Xin Xin, Joemon M. Jose|<http://arxiv.org/pdf/2502.12945v1>|None|

