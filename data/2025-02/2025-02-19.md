## [UPDATED!] **2025-02-19** (Update Time)


## å›¾åƒç†è§£

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|A Chain-of-Thought Subspace Meta-Learning for Few-shot Image Captioning with Large Vision and Language Models|åŸºäºå¤§å‹è§†è§‰å’Œè¯­è¨€æ¨¡å‹çš„é“¾å¼æ€ç»´å­ç©ºé—´å…ƒå­¦ä¹ ç”¨äºå°‘æ ·æœ¬å›¾åƒæè¿°|Hao Huang, Shuaihang Yuan, Yu Hao, Congcong Wen, Yi Fang|<http://arxiv.org/pdf/2502.13942v1>|None|
|ğŸ†• å‘å¸ƒ|Qwen2.5-VL Technical Report|Qwen2.5-VL æŠ€æœ¯æŠ¥å‘Š|Shuai Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Sibo Song, Kai Dang, Peng Wang .etc.|<http://arxiv.org/pdf/2502.13923v1>|None|
|ğŸ†• å‘å¸ƒ|Toward Robust Non-Transferable Learning: A Survey and Benchmark|è¿ˆå‘é²æ£’çš„éè¿ç§»å­¦ä¹ ï¼šç»¼è¿°ä¸åŸºå‡†|Ziming Hong, Yongli Xiang, Tongliang Liu|<http://arxiv.org/pdf/2502.13593v1>|None|
|ğŸ“ æ›´æ–°|Why Sample Space Matters: Keyframe Sampling Optimization for LiDAR-based Place Recognition|ä¸ºä»€ä¹ˆæ ·æœ¬ç©ºé—´å¾ˆé‡è¦ï¼šåŸºäºLiDARçš„åœ°ç‚¹è¯†åˆ«çš„å…³é”®å¸§é‡‡æ ·ä¼˜åŒ–|Nikolaos Stathoulopoulos, Vidya Sumathy, Christoforos Kanellakis, George Nikolakopoulos|<http://arxiv.org/pdf/2410.02643v2>|None|


## æ£€æµ‹åˆ†å‰²

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Image compositing is all you need for data augmentation|å›¾åƒåˆæˆï¼šæ•°æ®å¢å¼ºçš„å…¨éƒ¨æ‰€éœ€|Ang Jia Ning Shermaine, Michalis Lazarou, Tania Stathaki|<http://arxiv.org/pdf/2502.13936v1>|None|
|ğŸ†• å‘å¸ƒ|An Overall Real-Time Mechanism for Classification and Quality Evaluation of Rice|å®æ—¶æ°´ç¨»åˆ†ç±»ä¸è´¨é‡è¯„ä¼°çš„æ•´ä½“æœºåˆ¶|Wanke Xia, Ruxin Peng, Haoqi Chu, Xinlei Zhu, Zhiyu Yang, Yaojun Wang|<http://arxiv.org/pdf/2502.13764v1>|None|
|ğŸ†• å‘å¸ƒ|CARE: Confidence-Aware Regression Estimation of building density fine-tuning EO Foundation Models|CAREï¼šåŸºäºç½®ä¿¡åº¦çš„å»ºç­‘å¯†åº¦å›å½’ä¼°è®¡ä¸EOåŸºç¡€æ¨¡å‹å¾®è°ƒ|Nikolaos Dionelis, Jente Bosmans, Nicolas LongÃ©pÃ©|<http://arxiv.org/pdf/2502.13734v1>|None|
|ğŸ†• å‘å¸ƒ|2.5D U-Net with Depth Reduction for 3D CryoET Object Identification|2.5D å¸¦æ·±åº¦ç¼©å‡çš„ U-Net ç”¨äº 3D å†·å†»ç”µå­æ–­å±‚æ‰«æç‰©ä½“è¯†åˆ«|Yusuke Uchida, Takaaki Fukui|<http://arxiv.org/pdf/2502.13484v1>|None|
|ğŸ†• å‘å¸ƒ|JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust Multi-Teacher Knowledge Distillation Framework|JL1-CDï¼šé¥æ„Ÿå˜åŒ–æ£€æµ‹çš„æ–°åŸºå‡†ä¸é²æ£’çš„å¤šæ•™å¸ˆçŸ¥è¯†è’¸é¦æ¡†æ¶|Ziyuan Liu, Ruifei Zhu, Long Gao, Yuanxiu Zhou, Jingyu Ma, Yuantao Gu|<http://arxiv.org/pdf/2502.13407v1>|<https://github.com/circleLZY/MTKD-CD.>|
|ğŸ“ æ›´æ–°|ME-CPT: Multi-Task Enhanced Cross-Temporal Point Transformer for Urban 3D Change Detection|å¤šä»»åŠ¡å¢å¼ºè·¨æ—¶åºç‚¹Transformerç”¨äºåŸå¸‚3Då˜åŒ–æ£€æµ‹|Luqi Zhang, Haiping Wang, Chong Liu, Zhen Dong, Bisheng Yang|<http://arxiv.org/pdf/2501.14004v2>|<https://github.com/zhangluqi0209/ME-CPT.>|
|ğŸ“ æ›´æ–°|FuzzRisk: Online Collision Risk Estimation for Autonomous Vehicles based on Depth-Aware Object Detection via Fuzzy Inference|æ¨¡ç³Šé£é™©ï¼šåŸºäºæ¨¡ç³Šæ¨ç†çš„æ·±åº¦æ„ŸçŸ¥ç›®æ ‡æ£€æµ‹åœ¨è‡ªåŠ¨é©¾é©¶è½¦è¾†ä¸­åœ¨çº¿ç¢°æ’é£é™©è¯„ä¼°|Brian Hsuan-Cheng Liao, Yingjie Xu, Chih-Hong Cheng, Hasan Esen, Alois Knoll|<http://arxiv.org/pdf/2411.08060v2>|None|
|ğŸ“ æ›´æ–°|RSNet: A Light Framework for The Detection of Multi-scale Remote Sensing Targets|RSNetï¼šä¸€ç§ç”¨äºå¤šå°ºåº¦é¥æ„Ÿç›®æ ‡æ£€æµ‹çš„è½»é‡çº§æ¡†æ¶|Hongyu Chen, Chengcheng Chen, Fei Wang, Yuhu Shi, Weiming Zeng|<http://arxiv.org/pdf/2410.23073v5>|None|
|ğŸ“ æ›´æ–°|UNION: Unsupervised 3D Object Detection using Object Appearance-based Pseudo-Classes|UNIONï¼šåŸºäºå¯¹è±¡å¤–è§‚çš„ä¼ªç±»è¿›è¡Œæ— ç›‘ç£3Dç›®æ ‡æ£€æµ‹|Ted Lentsch, Holger Caesar, Dariu M. Gavrila|<http://arxiv.org/pdf/2405.15688v3>|<https://github.com/TedLentsch/UNION.>|
|ğŸ“ æ›´æ–°|A Framework for Building Point Cloud Cleaning, Plane Detection and Semantic Segmentation|æ„å»ºç‚¹äº‘æ¸…ç†ã€å¹³é¢æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²æ¡†æ¶|Ilyass Abouelaziz, Youssef Mourchid|<http://arxiv.org/pdf/2402.00692v2>|None|
|ğŸ“ æ›´æ–°|Generalized Robot 3D Vision-Language Model with Fast Rendering and Pre-Training Vision-Language Alignment|å¹¿ä¹‰æœºå™¨äºº3Dè§†è§‰-è¯­è¨€æ¨¡å‹ï¼šå¿«é€Ÿæ¸²æŸ“ä¸é¢„è®­ç»ƒè§†è§‰-è¯­è¨€å¯¹é½|Kangcheng Liu, Yong-Jin Liu, Baoquan Chen|<http://arxiv.org/pdf/2312.00663v2>|None|


## è§†é¢‘ç†è§£

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Capturing Rich Behavior Representations: A Dynamic Action Semantic-Aware Graph Transformer for Video Captioning|æ•æ‰ä¸°å¯Œçš„è¡Œä¸ºè¡¨å¾ï¼šä¸€ç§ç”¨äºè§†é¢‘å­—å¹•çš„åŠ¨æ€åŠ¨ä½œè¯­ä¹‰æ„ŸçŸ¥å›¾å˜æ¢å™¨|Caihua Liu, Xu Li, Wenjing Xue, Wei Tang, Xia Feng|<http://arxiv.org/pdf/2502.13754v1>|None|
|ğŸ†• å‘å¸ƒ|Event-Based Video Frame Interpolation With Cross-Modal Asymmetric Bidirectional Motion Fields|åŸºäºäº‹ä»¶çš„è§†é¢‘å¸§æ’å€¼ä¸è·¨æ¨¡æ€éå¯¹ç§°åŒå‘è¿åŠ¨åœº|Taewoo Kim, Yujeong Chae, Hyun-Kurl Jang, Kuk-Jin Yoon|<http://arxiv.org/pdf/2502.13716v1>|<https://github.com/intelpro/CBMNet>|


## ç”Ÿæˆæ¨¡å‹

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|FlexTok: Resampling Images into 1D Token Sequences of Flexible Length|FlexTokï¼šå°†å›¾åƒé‡é‡‡æ ·ä¸ºçµæ´»é•¿åº¦çš„1Dæ ‡è®°åºåˆ—|Roman Bachmann, Jesse Allardice, David Mizrahi, Enrico Fini, OÄŸuzhan Fatih Kar, Elmira Amirloo, Alaaeldin El-Nouby, Amir Zamir .etc.|<http://arxiv.org/pdf/2502.13967v1>|None|
|ğŸ†• å‘å¸ƒ|IP-Composer: Semantic Composition of Visual Concepts|IP-Composerï¼šè§†è§‰æ¦‚å¿µçš„è¯­ä¹‰ç»„åˆ|Sara Dorfman, Dana Cohen-Bar, Rinon Gal, Daniel Cohen-Or|<http://arxiv.org/pdf/2502.13951v1>|None|
|ğŸ“ æ›´æ–°|PoGDiff: Product-of-Gaussians Diffusion Models for Imbalanced Text-to-Image Generation|PoGDiffï¼šç”¨äºä¸å¹³è¡¡æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„é«˜æ–¯ä¹˜ç§¯æ‰©æ•£æ¨¡å‹|Ziyan Wang, Sizhe Wei, Xiaoming Huo, Hao Wang|<http://arxiv.org/pdf/2502.08106v2>|None|
|ğŸ“ æ›´æ–°|DiffGuard: Text-Based Safety Checker for Diffusion Models|DiffGuardï¼šåŸºäºæ–‡æœ¬çš„æ‰©æ•£æ¨¡å‹å®‰å…¨æ£€æŸ¥å™¨|Massine El Khader, Elias Al Bouzidi, Abdellah Oumida, Mohammed Sbaihi, Eliott Binard, Jean-Philippe Poli, Wassila Ouerdane, Boussad Addad .etc.|<http://arxiv.org/pdf/2412.00064v2>|None|
|ğŸ“ æ›´æ–°|SMITE: Segment Me In TimE|SMITEï¼šæ—¶é—´åˆ†å‰²|Amirhossein Alimohammadi, Sauradip Nag, Saeid Asgari Taghanaki, Andrea Tagliasacchi, Ghassan Hamarneh, Ali Mahdavi Amiri|<http://arxiv.org/pdf/2410.18538v2>|None|
|ğŸ“ æ›´æ–°|Many Heads Are Better Than One: Improved Scientific Idea Generation by A LLM-Based Multi-Agent System|å¤šå¤´èƒœè¿‡å•å¤´ï¼šåŸºäºLLMçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæå‡ç§‘å­¦åˆ›æ„ç”Ÿæˆ|Haoyang Su, Renqi Chen, Shixiang Tang, Zhenfei Yin, Xinzhe Zheng, Jinzhe Li, Biqing Qi, Qi Wu .etc.|<http://arxiv.org/pdf/2410.09403v2>|<https://github.com/open-sciencelab/Virtual-Scientists.>|
|ğŸ“ æ›´æ–°|Accelerating Diffusion Transformers with Token-wise Feature Caching|åŠ é€Ÿæ‰©æ•£Transformerçš„Tokençº§ç‰¹å¾ç¼“å­˜|Chang Zou, Xuyang Liu, Ting Liu, Siteng Huang, Linfeng Zhang|<http://arxiv.org/pdf/2410.05317v4>|None|
|ğŸ“ æ›´æ–°|EC-DIT: Scaling Diffusion Transformers with Adaptive Expert-Choice Routing|EC-DITï¼šé€šè¿‡è‡ªé€‚åº”ä¸“å®¶é€‰æ‹©è·¯ç”±æ‰©å±•æ‰©æ•£Transformer|Haotian Sun, Tao Lei, Bowen Zhang, Yanghao Li, Haoshuo Huang, Ruoming Pang, Bo Dai, Nan Du|<http://arxiv.org/pdf/2410.02098v4>|None|
|ğŸ“ æ›´æ–°|STAR: Scale-wise Text-conditioned AutoRegressive image generation|STARï¼šåŸºäºå°ºåº¦æ–‡æœ¬æ¡ä»¶çš„è‡ªå›å½’å›¾åƒç”Ÿæˆ|Xiaoxiao Ma, Mohan Zhou, Tao Liang, Yalong Bai, Tiejun Zhao, Biye Li, Huaian Chen, Yi Jin|<http://arxiv.org/pdf/2406.10797v4>|None|


## æ‰©æ•£æ¡¥

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|MRS: A Fast Sampler for Mean Reverting Diffusion based on ODE and SDE Solvers|MRSï¼šåŸºäºå¸¸å¾®åˆ†æ–¹ç¨‹å’Œéšæœºå¾®åˆ†æ–¹ç¨‹æ±‚è§£å™¨çš„å¿«é€Ÿå‡å€¼å›å½’æ‰©æ•£é‡‡æ ·å™¨|Ao Li, Wei Fang, Hongbo Zhao, Le Lu, Ge Yang, Minfeng Xu|<http://arxiv.org/pdf/2502.07856v3>|None|


## å›¾åƒå¤„ç†

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|GPU-Friendly Laplacian Texture Blending|GPUå‹å¥½çš„æ‹‰æ™®æ‹‰æ–¯çº¹ç†èåˆ|Bartlomiej Wronski|<http://arxiv.org/pdf/2502.13945v1>|None|
|ğŸ†• å‘å¸ƒ|Symmetrical Visual Contrastive Optimization: Aligning Vision-Language Models with Minimal Contrastive Images|å¯¹ç§°è§†è§‰å¯¹æ¯”ä¼˜åŒ–ï¼šç”¨æœ€å°å¯¹æ¯”å›¾åƒå¯¹é½è§†è§‰-è¯­è¨€æ¨¡å‹|Shengguang Wu, Fan-Yun Sun, Kaiyue Wen, Nick Haber|<http://arxiv.org/pdf/2502.13928v1>|None|
|ğŸ†• å‘å¸ƒ|Benchmarking of Different YOLO Models for CAPTCHAs Detection and Classification|ä¸åŒYOLOæ¨¡å‹åœ¨éªŒè¯ç æ£€æµ‹ä¸åˆ†ç±»ä¸­çš„åŸºå‡†æµ‹è¯•|MikoÅ‚aj Wysocki, Henryk Gierszal, Piotr Tyczka, Sophia Karagiorgou, George Pantelis|<http://arxiv.org/pdf/2502.13740v1>|None|
|ğŸ†• å‘å¸ƒ|MaizeEar-SAM: Zero-Shot Maize Ear Phenotyping|ç‰ç±³ç©—-SAMï¼šé›¶æ ·æœ¬ç‰ç±³ç©—è¡¨å‹åˆ†æ|Hossein Zaremehrjerdi, Lisa Coffey, Talukder Jubery, Huyu Liu, Jon Turkus, Kyle Linders, James C. Schnable, Patrick S. Schnable .etc.|<http://arxiv.org/pdf/2502.13399v1>|None|
|ğŸ†• å‘å¸ƒ|Pretrained Image-Text Models are Secretly Video Captioners|é¢„è®­ç»ƒçš„å›¾åƒ-æ–‡æœ¬æ¨¡å‹å®é™…ä¸Šæ˜¯ç§˜å¯†çš„è§†é¢‘æè¿°ç”Ÿæˆå™¨|Chunhui Zhang, Yiren Jian, Zhongyu Ouyang, Soroush Vosoughi|<http://arxiv.org/pdf/2502.13363v1>|None|
|ğŸ“ æ›´æ–°|Spherical Dense Text-to-Image Synthesis|çƒé¢å¯†é›†æ–‡æœ¬åˆ°å›¾åƒåˆæˆ|Timon Winter, Stanislav Frolov, Brian Bernhard Moser, Andreas Dengel|<http://arxiv.org/pdf/2502.12691v2>|None|
|ğŸ“ æ›´æ–°|Data-Efficient Limited-Angle CT Using Deep Priors and Regularization|åŸºäºæ·±åº¦å…ˆéªŒå’Œæ­£åˆ™åŒ–çš„æ•°æ®é«˜æ•ˆæœ‰é™è§’CT|Ilmari Vahteristo, Zhi-Song Liu, Andreas Rupp|<http://arxiv.org/pdf/2502.12293v2>|None|
|ğŸ“ æ›´æ–°|SemiHMER: Semi-supervised Handwritten Mathematical Expression Recognition using pseudo-labels|åŠç›‘ç£ä¼ªæ ‡ç­¾æ‰‹å†™æ•°å­¦è¡¨è¾¾å¼è¯†åˆ«ï¼šSemiHMER|Kehua Chen, Haoyang Shen|<http://arxiv.org/pdf/2502.07172v2>|None|
|ğŸ“ æ›´æ–°|HDCompression: Hybrid-Diffusion Image Compression for Ultra-Low Bitrates|æ··åˆæ‰©æ•£è¶…ä½æ¯”ç‰¹ç‡å›¾åƒå‹ç¼©ï¼šHDCompression|Lei Lu, Yize Li, Yanzhi Wang, Wei Wang, Wei Jiang|<http://arxiv.org/pdf/2502.07160v2>|None|
|ğŸ“ æ›´æ–°|Towards Hard and Soft Shadow Removal via Dual-Branch Separation Network and Vision Transformer|é€šè¿‡åŒåˆ†æ”¯åˆ†ç¦»ç½‘ç»œå’Œè§†è§‰Transformerå®ç°ç¡¬é˜´å½±å’Œè½¯é˜´å½±çš„å»é™¤|Jiajia Liang|<http://arxiv.org/pdf/2501.01864v2>|None|
|ğŸ“ æ›´æ–°|Explaining the Impact of Training on Vision Models via Activation Clustering|é€šè¿‡æ¿€æ´»èšç±»è§£é‡Šè®­ç»ƒå¯¹è§†è§‰æ¨¡å‹çš„å½±å“|AhcÃ¨ne Boubekki, Samuel G. Fadel, Sebastian Mair|<http://arxiv.org/pdf/2411.19700v2>|None|
|ğŸ“ æ›´æ–°|Multiview Equivariance Improves 3D Correspondence Understanding with Minimal Feature Finetuning|å¤šè§†è§’ç­‰å˜æ€§é€šè¿‡æœ€å°ç‰¹å¾å¾®è°ƒæå‡3Då¯¹åº”ç†è§£|Yang You, Yixin Li, Congyue Deng, Yue Wang, Leonidas Guibas|<http://arxiv.org/pdf/2411.19458v2>|<https://github.com/qq456cvb/3DCorrEnhance.>|
|ğŸ“ æ›´æ–°|Mitigating Hallucinations in Large Vision-Language Models via Summary-Guided Decoding|é€šè¿‡æ‘˜è¦å¼•å¯¼è§£ç å‡è½»å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰|Kyungmin Min, Minbeom Kim, Kang-il Lee, Dongryeol Lee, Kyomin Jung|<http://arxiv.org/pdf/2410.13321v3>|None|
|ğŸ“ æ›´æ–°|Denoising as Adaptation: Noise-Space Domain Adaptation for Image Restoration|å»å™ªä½œä¸ºé€‚åº”ï¼šå™ªå£°ç©ºé—´åŸŸé€‚åº”ç”¨äºå›¾åƒæ¢å¤|Kang Liao, Zongsheng Yue, Zhouxia Wang, Chen Change Loy|<http://arxiv.org/pdf/2406.18516v3>|None|
|ğŸ“ æ›´æ–°|High-Quality 3D Creation from A Single Image Using Subject-Specific Knowledge Prior|ä»å•å¼ å›¾åƒåˆ©ç”¨ç‰¹å®šä¸»é¢˜å…ˆéªŒçŸ¥è¯†åˆ›å»ºé«˜è´¨é‡3Dæ¨¡å‹|Nan Huang, Ting Zhang, Yuhui Yuan, Dong Chen, Shanghang Zhang|<http://arxiv.org/pdf/2312.11535v3>|None|
|ğŸ“ æ›´æ–°|Carefully Blending Adversarial Training, Purification, and Aggregation Improves Adversarial Robustness|ç²¾å¿ƒèåˆå¯¹æŠ—è®­ç»ƒã€å‡€åŒ–å’Œèšåˆä»¥æå‡å¯¹æŠ—é²æ£’æ€§|Emanuele Ballarin, Alessio Ansuini, Luca Bortolussi|<http://arxiv.org/pdf/2306.06081v5>|<https://github.com/emaballarin/CARSO>|
|ğŸ“ æ›´æ–°|GMValuator: Similarity-based Data Valuation for Generative Models|GMValuatorï¼šåŸºäºç›¸ä¼¼æ€§çš„ç”Ÿæˆæ¨¡å‹æ•°æ®ä¼°å€¼|Jiaxi Yang, Wenglong Deng, Benlin Liu, Yangsibo Huang, James Zou, Xiaoxiao Li|<http://arxiv.org/pdf/2304.10701v8>|None|


## 3Dåœºæ™¯

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Betsu-Betsu: Multi-View Separable 3D Reconstruction of Two Interacting Objects|è´è‹è´è‹ï¼šä¸¤ä¸ªäº¤äº’ç‰©ä½“å¤šè§†å›¾å¯åˆ†ç¦»3Dé‡å»º|Suhas Gopal, Rishabh Dabral, Vladislav Golyanik, Christian Theobalt|<http://arxiv.org/pdf/2502.13968v1>|None|
|ğŸ“ æ›´æ–°|NoKSR: Kernel-Free Neural Surface Reconstruction via Point Cloud Serialization|æ— æ ¸ç¥ç»ç½‘ç»œè¡¨é¢é‡å»ºï¼šé€šè¿‡ç‚¹äº‘åºåˆ—åŒ–|Zhen Li, Weiwei Sun, Shrisudhan Govindarajan, Shaobo Xia, Daniel Rebain, Kwang Moo Yi, Andrea Tagliasacchi|<http://arxiv.org/pdf/2502.12534v2>|None|
|ğŸ“ æ›´æ–°|pySLAM: An Open-Source, Modular, and Extensible Framework for SLAM|pySLAMï¼šä¸€ä¸ªå¼€æºã€æ¨¡å—åŒ–å’Œå¯æ‰©å±•çš„SLAMæ¡†æ¶|Luigi Freda|<http://arxiv.org/pdf/2502.11955v2>|None|


## ç¥ç»æ¸²æŸ“

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Continually Learning Structured Visual Representations via Network Refinement with Rerelation|é€šè¿‡ç½‘ç»œç²¾ç‚¼ä¸é‡å…³è”å®ç°ç»“æ„åŒ–è§†è§‰è¡¨ç¤ºçš„æŒç»­å­¦ä¹ |Zeki Doruk Erden, Boi Faltings|<http://arxiv.org/pdf/2502.13935v1>|None|
|ğŸ“ æ›´æ–°|IM360: Textured Mesh Reconstruction for Large-scale Indoor Mapping with 360$^\circ$ Cameras|IM360ï¼šåŸºäº360Â°ç›¸æœºçš„å®¤å†…å¤§è§„æ¨¡åœ°å›¾çº¹ç†ç½‘æ ¼é‡å»º|Dongki Jung, Jaehoon Choi, Yonghan Lee, Dinesh Manocha|<http://arxiv.org/pdf/2502.12545v2>|None|
|ğŸ“ æ›´æ–°|Regularization by Neural Style Transfer for MRI Field-Transfer Reconstruction with Limited Data|åŸºäºç¥ç»é£æ ¼è¿ç§»çš„æœ‰é™æ•°æ®MRIåœºè¿ç§»é‡å»ºæ­£åˆ™åŒ–|Guoyao Shen, Yancheng Zhu, Mengyu Li, Ryan McNaughton, Hernan Jara, Sean B. Andersson, Chad W. Farris, Stephan Anderson .etc.|<http://arxiv.org/pdf/2308.10968v3>|None|


## 3DGS

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|3D Gaussian Splatting aided Localization for Large and Complex Indoor-Environments|ä¸‰ç»´é«˜æ–¯åˆ†å±‚è¾…åŠ©å¤§å‹å¤æ‚å®¤å†…ç¯å¢ƒçš„å®šä½|Vincent Ress, Jonas Meyer, Wei Zhang, David Skuddis, Uwe Soergel, Norbert Haala|<http://arxiv.org/pdf/2502.13803v1>|None|
|ğŸ“ æ›´æ–°|Hybrid Explicit Representation for Ultra-Realistic Head Avatars|æ··åˆæ˜¾å¼è¡¨ç¤ºçš„è¶…é€¼çœŸå¤´åƒ|Hongrui Cai, Yuting Xiao, Xuan Wang, Jiafei Li, Yudong Guo, Yanbo Fan, Shenghua Gao, Juyong Zhang|<http://arxiv.org/pdf/2403.11453v2>|None|


## å¤šæ¨¡æ€

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|CardiacMamba: A Multimodal RGB-RF Fusion Framework with State Space Models for Remote Physiological Measurement|CardiacMambaï¼šä¸€ç§ç”¨äºè¿œç¨‹ç”Ÿç†æµ‹é‡çš„å¤šæ¨¡æ€RGB-RFèåˆæ¡†æ¶ä¸çŠ¶æ€ç©ºé—´æ¨¡å‹|Zheng Wu, Yiping Xie, Bo Zhao, Jiguang He, Fei Luo, Ning Deng, Zitong Yu|<http://arxiv.org/pdf/2502.13624v1>|<https://github.com/WuZheng42/CardiacMamba.>|
|ğŸ“ æ›´æ–°|ChineseSimpleVQA -- "See the World, Discover Knowledge": A Chinese Factuality Evaluation for Large Vision Language Models|ChineseSimpleVQA â€”â€” â€œçœ‹ä¸–ç•Œï¼Œå‘ç°çŸ¥è¯†â€ï¼šå¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹çš„ä¸­å›½äº‹å®æ€§è¯„ä¼°|Jihao Gu, Yingyao Wang, Pi Bu, Chen Wang, Ziming Wang, Tengtao Song, Donglai Wei, Jiale Yuan .etc.|<http://arxiv.org/pdf/2502.11718v2>|None|
|ğŸ“ æ›´æ–°|Template-Based Visual Program Distillation|åŸºäºæ¨¡æ¿çš„è§†è§‰ç¨‹åºè’¸é¦|Michal Shlapentokh-Rothman, Yu-Xiong Wang, Derek Hoiem|<http://arxiv.org/pdf/2412.08564v2>|None|
|ğŸ“ æ›´æ–°|Contrastive Localized Language-Image Pre-Training|å¯¹æ¯”å±€éƒ¨åŒ–è¯­è¨€-å›¾åƒé¢„è®­ç»ƒ|Hong-You Chen, Zhengfeng Lai, Haotian Zhang, Xinze Wang, Marcin Eichner, Keen You, Meng Cao, Bowen Zhang .etc.|<http://arxiv.org/pdf/2410.02746v2>|None|
|ğŸ“ æ›´æ–°|Multimodal Emotion Recognition using Audio-Video Transformer Fusion with Cross Attention|å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«ï¼šåŸºäºéŸ³é¢‘-è§†é¢‘Transformerèåˆä¸äº¤å‰æ³¨æ„åŠ›çš„æ–¹æ³•|Joe Dhanith P R, Shravan Venkatraman, Vigya Sharma, Santhosh Malarvannan, Modigari Narendra|<http://arxiv.org/pdf/2407.18552v3>|None|
|ğŸ“ æ›´æ–°|Interpreting Neurons in Deep Vision Networks with Language Models|æ·±åº¦è§†è§‰ç½‘ç»œä¸­ç¥ç»å…ƒçš„è¯­è¨€æ¨¡å‹è§£é‡Š|Nicholas Bai, Rahul A. Iyer, Tuomas Oikarinen, Akshay Kulkarni, Tsui-Wei Weng|<http://arxiv.org/pdf/2403.13771v2>|<https://github.com/Trustworthy-ML-Lab/Describe-and-Dissect.>|
|ğŸ“ æ›´æ–°|MVAM: Multi-View Attention Method for Fine-grained Image-Text Matching|å¤šè§†è§’æ³¨æ„åŠ›æ–¹æ³•ç”¨äºç»†ç²’åº¦å›¾åƒ-æ–‡æœ¬åŒ¹é…|Wanqing Cui, Rui Cheng, Jiafeng Guo, Xueqi Cheng|<http://arxiv.org/pdf/2402.17237v2>|None|


## å…·èº«æ™ºèƒ½

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|A Training-Free Framework for Precise Mobile Manipulation of Small Everyday Objects|æ— è®­ç»ƒæ¡†æ¶å®ç°å°æ—¥å¸¸ç‰©ä½“çš„ç²¾ç¡®ç§»åŠ¨æ“ä½œ|Arjun Gupta, Rishik Sathua, Saurabh Gupta|<http://arxiv.org/pdf/2502.13964v1>|None|
|ğŸ†• å‘å¸ƒ|NavigateDiff: Visual Predictors are Zero-Shot Navigation Assistants|NavigateDiffï¼šè§†è§‰é¢„æµ‹å™¨ä½œä¸ºé›¶æ ·æœ¬å¯¼èˆªåŠ©æ‰‹|Yiran Qin, Ao Sun, Yuze Hong, Benyou Wang, Ruimao Zhang|<http://arxiv.org/pdf/2502.13894v1>|None|
|ğŸ†• å‘å¸ƒ|Building Age Estimation: A New Multi-Modal Benchmark Dataset and Community Challenge|æ„å»ºå¹´é¾„ä¼°è®¡ï¼šä¸€ä¸ªæ–°çš„å¤šæ¨¡æ€åŸºå‡†æ•°æ®é›†å’Œç¤¾åŒºæŒ‘æˆ˜|Nikolaos Dionelis, Nicolas LongÃ©pÃ©, Alessandra Feliciotti, Mattia Marconcini, Devis Peressutti, Nika Oman Kadunc, JaeWan Park, Hagai Raja Sinulingga .etc.|<http://arxiv.org/pdf/2502.13818v1>|None|
|ğŸ†• å‘å¸ƒ|Improving Collision-Free Success Rate For Object Goal Visual Navigation Via Two-Stage Training With Collision Prediction|é€šè¿‡å…·æœ‰ç¢°æ’é¢„æµ‹çš„ä¸¤é˜¶æ®µè®­ç»ƒæé«˜æ— ç¢°æ’æˆåŠŸç‡çš„ç‰©ä½“ç›®æ ‡è§†è§‰å¯¼èˆª|Shiwei Lian, Feitian Zhang|<http://arxiv.org/pdf/2502.13498v1>|None|
|ğŸ“ æ›´æ–°|Towards Fusing Point Cloud and Visual Representations for Imitation Learning|è¿ˆå‘èåˆç‚¹äº‘å’Œè§†è§‰è¡¨ç¤ºçš„æ¨¡ä»¿å­¦ä¹ |Atalay Donat, Xiaogang Jia, Xi Huang, Aleksandar Taranovic, Denis Blessing, Ge Li, Hongyi Zhou, Hanyi Zhang .etc.|<http://arxiv.org/pdf/2502.12320v2>|None|
|ğŸ“ æ›´æ–°|BFA: Best-Feature-Aware Fusion for Multi-View Fine-grained Manipulation|BFAï¼šå¤šè§†è§’ç²¾ç»†æ“ä½œçš„æœ€ä½³ç‰¹å¾æ„ŸçŸ¥èåˆ|Zihan Lan, Weixin Mao, Haosheng Li, Le Wang, Tiancai Wang, Haoqiang Fan, Osamu Yoshie|<http://arxiv.org/pdf/2502.11161v2>|None|
|ğŸ“ æ›´æ–°|MonoForce: Learnable Image-conditioned Physics Engine|MonoForceï¼šå¯å­¦ä¹ çš„å›¾åƒæ¡ä»¶ç‰©ç†å¼•æ“|Ruslan Agishev, Karel Zimmermann|<http://arxiv.org/pdf/2502.10156v2>|None|
|ğŸ“ æ›´æ–°|Utility Engineering: Analyzing and Controlling Emergent Value Systems in AIs|äººå·¥æ™ºèƒ½ä¸­çš„æ•ˆç”¨å·¥ç¨‹ï¼šåˆ†æå’Œæ§åˆ¶æ¶Œç°çš„ä»·å€¼ç³»ç»Ÿ|Mantas Mazeika, Xuwang Yin, Rishub Tamirisa, Jaehyuk Lim, Bruce W. Lee, Richard Ren, Long Phan, Norman Mu .etc.|<http://arxiv.org/pdf/2502.08640v2>|None|
|ğŸ“ æ›´æ–°|MetaSSC: Enhancing 3D Semantic Scene Completion for Autonomous Driving through Meta-Learning and Long-sequence Modeling|å…ƒSSCï¼šé€šè¿‡å…ƒå­¦ä¹ å’Œé•¿åºåˆ—å»ºæ¨¡å¢å¼ºè‡ªåŠ¨é©¾é©¶çš„3Dè¯­ä¹‰åœºæ™¯è¡¥å…¨|Yansong Qu, Zixuan Xu, Zilin Huang, Zihao Sheng, Tiantian Chen, Sikai Chen|<http://arxiv.org/pdf/2411.03672v2>|None|
|ğŸ“ æ›´æ–°|Personalized Instance-based Navigation Toward User-Specific Objects in Realistic Environments|ä¸ªæ€§åŒ–åŸºäºå®ä¾‹çš„å¯¼èˆªï¼ŒæŒ‡å‘ç°å®ç¯å¢ƒä¸­çš„ç”¨æˆ·ç‰¹å®šå¯¹è±¡|Luca Barsellotti, Roberto Bigazzi, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara|<http://arxiv.org/pdf/2410.18195v2>|None|
|ğŸ“ æ›´æ–°|Generalizable Humanoid Manipulation with 3D Diffusion Policies|å…·æœ‰3Dæ‰©æ•£ç­–ç•¥çš„é€šç”¨ç±»äººæœºå™¨äººæ“ä½œ|Yanjie Ze, Zixuan Chen, Wenhao Wang, Tianyi Chen, Xialin He, Ying Yuan, Xue Bin Peng, Jiajun Wu|<http://arxiv.org/pdf/2410.10803v2>|None|
|ğŸ“ æ›´æ–°|Controllable Unlearning for Image-to-Image Generative Models via $\varepsilon$-Constrained Optimization|å¯æ§æ€§é—å¿˜ï¼šé€šè¿‡Îµçº¦æŸä¼˜åŒ–å®ç°å›¾åƒåˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„å›¾åƒå­¦ä¹ |Xiaohua Feng, Yuyuan Li, Chaochao Chen, Li Zhang, Longfei Li, Jun Zhou, Xiaolin Zheng|<http://arxiv.org/pdf/2408.01689v3>|None|
|ğŸ“ æ›´æ–°|Hands-on STEM Learning Experiences using Digital Technologies|ä½¿ç”¨æ•°å­—æŠ€æœ¯çš„åŠ¨æ‰‹STEMå­¦ä¹ ä½“éªŒ|Gaia Fior, Carlo Fonda, Enrique Canessa|<http://arxiv.org/pdf/2408.00781v2>|None|
|ğŸ“ æ›´æ–°|PILOT: A Pre-Trained Model-Based Continual Learning Toolbox|PILOTï¼šåŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„æŒç»­å­¦ä¹ å·¥å…·ç®±|Hai-Long Sun, Da-Wei Zhou, Han-Jia Ye, De-Chuan Zhan|<http://arxiv.org/pdf/2309.07117v2>|None|


## äººä½“åˆ†æ

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|GroundCap: A Visually Grounded Image Captioning Dataset|GroundCapï¼šä¸€ä¸ªè§†è§‰åŸºç¡€å›¾åƒæè¿°æ•°æ®é›†|Daniel A. P. Oliveira, LourenÃ§o Teodoro, David Martins de Matos|<http://arxiv.org/pdf/2502.13898v1>|None|
|ğŸ†• å‘å¸ƒ|Multi-view Video-Pose Pretraining for Operating Room Surgical Activity Recognition|å¤šè§†è§’è§†é¢‘å§¿æ€é¢„è®­ç»ƒç”¨äºæ‰‹æœ¯å®¤æ‰‹æœ¯æ´»åŠ¨è¯†åˆ«|Idris Hamoud, Vinkle Srivastav, Muhammad Abdullah Jamal, Didier Mutter, Omid Mohareri, Nicolas Padoy|<http://arxiv.org/pdf/2502.13883v1>|<https://github.com/CAMMA-public/PreViPS.>|
|ğŸ†• å‘å¸ƒ|Generative Video Semantic Communication via Multimodal Semantic Fusion with Large Model|åŸºäºå¤§æ¨¡å‹çš„å¤šæ¨¡æ€è¯­ä¹‰èåˆç”Ÿæˆè§†é¢‘è¯­ä¹‰é€šä¿¡|Hang Yin, Li Qiao, Yu Ma, Shuo Sun, Kan Li, Zhen Gao, Dusit Niyato|<http://arxiv.org/pdf/2502.13838v1>|None|
|ğŸ†• å‘å¸ƒ|Exploring Mutual Cross-Modal Attention for Context-Aware Human Affordance Generation|æ¢ç´¢äº’æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶ä»¥å®ç°æƒ…å¢ƒæ„ŸçŸ¥äººç±»èƒ½åŠ›ç”Ÿæˆ|Prasun Roy, Saumik Bhattacharya, Subhankar Ghosh, Umapada Pal, Michael Blumenstein|<http://arxiv.org/pdf/2502.13637v1>|None|
|ğŸ†• å‘å¸ƒ|LaVCa: LLM-assisted Visual Cortex Captioning|LaVCaï¼šåŸºäºLLMçš„è§†è§‰çš®å±‚å­—å¹•ç”Ÿæˆ|Takuya Matsuyama, Shinji Nishimoto, Yu Takagi|<http://arxiv.org/pdf/2502.13606v1>|None|
|ğŸ†• å‘å¸ƒ|Semi-supervised classification of bird vocalizations|åŠç›‘ç£é¸Ÿç±»é¸£å«åˆ†ç±»|Simen Hexeberg, Mandar Chitre, Matthias Hoffmann-Kuhnt, Bing Wen Low|<http://arxiv.org/pdf/2502.13440v1>|None|
|ğŸ†• å‘å¸ƒ|SNN-Driven Multimodal Human Action Recognition via Event Camera and Skeleton Data Fusion|åŸºäºäº‹ä»¶ç›¸æœºå’Œéª¨éª¼æ•°æ®èåˆçš„SNNé©±åŠ¨çš„å¤šæ¨¡æ€äººä½“åŠ¨ä½œè¯†åˆ«|Naichuan Zheng, Hailun Xia|<http://arxiv.org/pdf/2502.13385v1>|None|
|ğŸ“ æ›´æ–°|Animate Your Thoughts: Decoupled Reconstruction of Dynamic Natural Vision from Slow Brain Activity|ã€ŠåŠ¨ç”»ä½ çš„æ€ç»´ï¼šä»ç¼“æ…¢çš„è„‘æ´»åŠ¨ä¸­è§£è€¦é‡å»ºåŠ¨æ€è‡ªç„¶è§†è§‰ã€‹|Yizhuo Lu, Changde Du, Chong Wang, Xuanliu Zhu, Liuyun Jiang, Xujin Li, Huiguang He|<http://arxiv.org/pdf/2405.03280v2>|<https://mind-animator-design.github.io/.>|


## æ•°å­—äºº

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Geolocation with Real Human Gameplay Data: A Large-Scale Dataset and Human-Like Reasoning Framework|åŸºäºçœŸå®äººç±»æ¸¸æˆæ•°æ®çš„åœ°ç†å®šä½ï¼šä¸€ä¸ªå¤§è§„æ¨¡æ•°æ®é›†å’Œç±»ä¼¼äººç±»æ¨ç†æ¡†æ¶|Zirui Song, Jingpu Yang, Yuan Huang, Jonathan Tonglet, Zeyu Zhang, Tao Cheng, Meng Fang, Iryna Gurevych .etc.|<http://arxiv.org/pdf/2502.13759v1>|None|
|ğŸ†• å‘å¸ƒ|MoVer: Motion Verification for Motion Graphics Animations|MoVerï¼šè¿åŠ¨å›¾å½¢åŠ¨ç”»çš„è¿åŠ¨éªŒè¯|Jiaju Ma, Maneesh Agrawala|<http://arxiv.org/pdf/2502.13372v1>|None|
|ğŸ“ æ›´æ–°|Multimodal Fake News Video Explanation Generation: Dataset, Model, and Evaluation|å¤šæ¨¡æ€è™šå‡æ–°é—»è§†é¢‘è§£é‡Šç”Ÿæˆï¼šæ•°æ®é›†ã€æ¨¡å‹å’Œè¯„ä¼°|Lizhi Chen, Zhong Qian, Peifeng Li, Qiaoming Zhu|<http://arxiv.org/pdf/2501.08514v2>|None|


## æ¨¡å‹ä¼˜åŒ–

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MEX: Memory-efficient Approach to Referring Multi-Object Tracking|MEXï¼šé«˜æ•ˆå†…å­˜çš„æŒ‡ä»£å¤šç›®æ ‡è·Ÿè¸ªæ–¹æ³•|Huu-Thien Tran, Phuoc-Sang Pham, Thai-Son Tran, Khoa Luu|<http://arxiv.org/pdf/2502.13875v1>|None|
|ğŸ†• å‘å¸ƒ|Transferring Textual Preferences to Vision-Language Understanding through Model Merging|é€šè¿‡æ¨¡å‹èåˆå°†æ–‡æœ¬åå¥½è¿ç§»åˆ°è§†è§‰-è¯­è¨€ç†è§£|Chen-An Li, Tzu-Han Lin, Yun-Nung Chen, Hung-yi Lee|<http://arxiv.org/pdf/2502.13487v1>|None|
|ğŸ†• å‘å¸ƒ|MM-Verify: Enhancing Multimodal Reasoning with Chain-of-Thought Verification|MM-Verifyï¼šé€šè¿‡æ€ç»´é“¾éªŒè¯å¢å¼ºå¤šæ¨¡æ€æ¨ç†|Linzhuang Sun, Hao Liang, Jingxuan Wei, Bihui Yu, Tianpeng Li, Fan Yang, Zenan Zhou, Wentao Zhang|<http://arxiv.org/pdf/2502.13383v1>|None|
|ğŸ“ æ›´æ–°|Rethinking Audio-Visual Adversarial Vulnerability from Temporal and Modality Perspectives|é‡æ–°ä»æ—¶é—´å’Œæ¨¡æ€è§’åº¦æ€è€ƒéŸ³é¢‘-è§†è§‰å¯¹æŠ—è„†å¼±æ€§|Zeliang Zhang, Susan Liang, Daiki Shimada, Chenliang Xu|<http://arxiv.org/pdf/2502.11858v2>|None|
|ğŸ“ æ›´æ–°|Long-VITA: Scaling Large Multi-modal Models to 1 Million Tokens with Leading Short-Context Accuracy|é•¿-VITAï¼šé€šè¿‡é¢†å…ˆçš„çŸ­ä¸Šä¸‹æ–‡ç²¾åº¦æ‰©å±•å¤§å‹å¤šæ¨¡æ€æ¨¡å‹è‡³ä¸€ç™¾ä¸‡ä¸ªæ ‡è®°|Yunhang Shen, Chaoyou Fu, Shaoqi Dong, Xiong Wang, Yi-Fan Zhang, Peixian Chen, Mengdan Zhang, Haoyu Cao .etc.|<http://arxiv.org/pdf/2502.05177v2>|None|
|ğŸ“ æ›´æ–°|PolyhedronNet: Representation Learning for Polyhedra with Surface-attributed Graph|å¤šé¢ä½“ç½‘ç»œï¼šåŸºäºè¡¨é¢å±æ€§å›¾çš„å‡¸å¤šé¢ä½“è¡¨ç¤ºå­¦ä¹ |Dazhou Yu, Genpei Zhang, Liang Zhao|<http://arxiv.org/pdf/2502.01814v2>|<https://github.com/dyu62/3D_polyhedron>|
|ğŸ“ æ›´æ–°|Efficient Dataset Distillation via Diffusion-Driven Patch Selection for Improved Generalization|é«˜æ•ˆé€šè¿‡æ‰©æ•£é©±åŠ¨å—é€‰æ‹©è¿›è¡Œæ•°æ®é›†è’¸é¦ä»¥æå‡æ³›åŒ–èƒ½åŠ›|Xinhao Zhong, Shuoyang Sun, Xulin Gu, Zhaoyang Xu, Yaowei Wang, Jianlong Wu, Bin Chen|<http://arxiv.org/pdf/2412.09959v2>|None|
|ğŸ“ æ›´æ–°|Cross-View Graph Consistency Learning for Invariant Graph Representations|è·¨è§†è§’å›¾ä¸€è‡´æ€§å­¦ä¹ ä»¥å®ç°ä¸å˜å›¾è¡¨ç¤º|Jie Chen, Hua Mao, Wai Lok Woo, Chuanbin Liu, Xi Peng|<http://arxiv.org/pdf/2311.11821v2>|None|


## åŒ»å­¦åº”ç”¨

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MSVCOD:A Large-Scale Multi-Scene Dataset for Video Camouflage Object Detection|MSVCODï¼šå¤§è§„æ¨¡å¤šåœºæ™¯è§†é¢‘ä¼ªè£…ç›®æ ‡æ£€æµ‹æ•°æ®é›†|Shuyong Gao, Yu'ang Feng, Qishan Wang, Lingyi Hong, Xinyu Zhou, Liu Fei, Yan Wang, Wenqiang Zhang|<http://arxiv.org/pdf/2502.13859v1>|None|
|ğŸ†• å‘å¸ƒ|MGFI-Net: A Multi-Grained Feature Integration Network for Enhanced Medical Image Segmentation|MGFI-Netï¼šä¸€ç§ç”¨äºå¢å¼ºåŒ»å­¦å›¾åƒåˆ†å‰²çš„å¤šç²’åº¦ç‰¹å¾é›†æˆç½‘ç»œ|Yucheng Zeng|<http://arxiv.org/pdf/2502.13808v1>|None|
|ğŸ†• å‘å¸ƒ|From Correctness to Comprehension: AI Agents for Personalized Error Diagnosis in Education|ä»æ­£ç¡®æ€§åˆ°ç†è§£ï¼šä¸ªæ€§åŒ–æ•™è‚²é”™è¯¯è¯Šæ–­çš„AIä»£ç†|Yi-Fan Zhang, Hang Li, Dingjie Song, Lichao Sun, Tianlong Xu, Qingsong Wen|<http://arxiv.org/pdf/2502.13789v1>|None|
|ğŸ†• å‘å¸ƒ|Medical Image Classification with KAN-Integrated Transformers and Dilated Neighborhood Attention|åŸºäºKANé›†æˆTransformerå’Œæ‰©å¼ é‚»åŸŸæ³¨æ„åŠ›çš„åŒ»å­¦å›¾åƒåˆ†ç±»|Omid Nejati Manzari, Hojat Asgariandehkordi, Taha Koleilat, Yiming Xiao, Hassan Rivaz|<http://arxiv.org/pdf/2502.13693v1>|None|
|ğŸ†• å‘å¸ƒ|MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D Medical Image Analysis|ç§»åŠ¨ViMï¼šä¸€ç§è½»é‡çº§ä¸”ç»´åº¦æ— å…³çš„3DåŒ»å­¦å›¾åƒåˆ†æè§†è§‰é©¬amba|Wei Dai, Steven Wang, Jun Liu|<http://arxiv.org/pdf/2502.13524v1>|None|
|ğŸ†• å‘å¸ƒ|Enhancing Chest X-ray Classification through Knowledge Injection in Cross-Modality Learning|é€šè¿‡è·¨æ¨¡æ€å­¦ä¹ ä¸­çš„çŸ¥è¯†æ³¨å…¥å¢å¼ºèƒ¸éƒ¨Xå…‰ç‰‡åˆ†ç±»|Yang Yan, Bingqing Yue, Qiaxuan Li, Man Huang, Jingyu Chen, Zhenzhong Lan|<http://arxiv.org/pdf/2502.13447v1>|None|
|ğŸ“ æ›´æ–°|Are generative models fair? A study of racial bias in dermatological image generation|ç”Ÿæˆæ¨¡å‹å…¬å¹³å—ï¼Ÿçš®è‚¤ç§‘å›¾åƒç”Ÿæˆä¸­çš„ç§æ—åè§ç ”ç©¶|Miguel LÃ³pez-PÃ©rez, SÃ¸ren Hauberg, Aasa Feragen|<http://arxiv.org/pdf/2501.11752v2>|None|
|ğŸ“ æ›´æ–°|MedIAnomaly: A comparative study of anomaly detection in medical images|åŒ»å­¦å›¾åƒå¼‚å¸¸æ£€æµ‹çš„æ¯”è¾ƒç ”ç©¶ï¼šMedIAnomaly|Yu Cai, Weiwen Zhang, Hao Chen, Kwang-Ting Cheng|<http://arxiv.org/pdf/2404.04518v4>|<https://github.com/caiyu6666/MedIAnomaly.>|
|ğŸ“ æ›´æ–°|V2C-Long: Longitudinal Cortex Reconstruction with Spatiotemporal Correspondence|V2C-Longï¼šåŸºäºæ—¶ç©ºå¯¹åº”çš„é•¿çºµéš”çš®è´¨é‡å»º|Fabian Bongratz, Jan Fecht, Anne-Marie Rickmann, Christian Wachinger|<http://arxiv.org/pdf/2402.17438v2>|None|
|ğŸ“ æ›´æ–°|E2ENet: Dynamic Sparse Feature Fusion for Accurate and Efficient 3D Medical Image Segmentation|E2ENetï¼šç”¨äºç²¾ç¡®é«˜æ•ˆ3DåŒ»å­¦å›¾åƒåˆ†å‰²çš„åŠ¨æ€ç¨€ç–ç‰¹å¾èåˆ|Boqian Wu, Qiao Xiao, Shiwei Liu, Lu Yin, Mykola Pechenizkiy, Decebal Constantin Mocanu, Maurice Van Keulen, Elena Mocanu|<http://arxiv.org/pdf/2312.04727v2>|<https://github.com/boqian333/E2ENet-Medical.>|


## å…¶ä»–

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç é“¾æ¥|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MagicGeo: Training-Free Text-Guided Geometric Diagram Generation|é­”å¹»å‡ ä½•ï¼šæ— éœ€è®­ç»ƒçš„æ–‡æœ¬å¼•å¯¼å‡ ä½•å›¾å½¢ç”Ÿæˆ|Junxiao Wang, Ting Zhang, Heng Yu, Jingdong Wang, Hua Huang|<http://arxiv.org/pdf/2502.13855v1>|None|
|ğŸ“ æ›´æ–°|LLMPopcorn: An Empirical Study of LLMs as Assistants for Popular Micro-video Generation|LLMPopcornï¼šå…³äºå¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºæµè¡Œå¾®è§†é¢‘ç”ŸæˆåŠ©æ‰‹çš„å®è¯ç ”ç©¶|Junchen Fu, Xuri Ge, Kaiwen Zheng, Ioannis Arapakis, Xin Xin, Joemon M. Jose|<http://arxiv.org/pdf/2502.12945v2>|None|

