## [UPDATED!] **2025-03-08** (Update Time)


## 表示学习 (Representation Learning)


### 视觉Transformer (Vision Transformers)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Designing Concise ConvNets with Columnar Stages|设计具有列阶段的高效卷积神经网络|Ashish Kumar, Jaesik Park|<http://arxiv.org/pdf/2410.04089v2>|[[代码]](<https://github.com/ashishkumar822/CoSNet>)<br />- 问题：简洁ConvNet，资源受限，性能优化<br />- 方法：Columnar Stages，并行卷积，1x1卷积最小化<br />- 效果：低FLOPs，低参数，性能优异|
|📝 更新|Back to the Future Cyclopean Stereo: a human perception approach combining deep and geometric constraints|回到未来：巨眼立体视觉：结合深度和几何约束的人眼感知方法|Sherlon Almeida da Silva, Davi Geiger, Luiz Velho, Moacir Antonelli Ponti|<http://arxiv.org/pdf/2502.21280v2>|- 问题：立体视觉，深度信息，几何约束<br />- 方法：深度模型，几何模型，先验模型<br />- 效果：性能提升，视觉质量改善|
|📝 更新|ShadowMamba: State-Space Model with Boundary-Region Selective Scan for Shadow Removal|影子曼巴：具有边界区域选择性扫描的状态空间模型用于阴影去除|Xiujin Zhu, Chee-Onn Chow, Joon Huang Chuah|<http://arxiv.org/pdf/2411.03260v2>|- 问题：阴影去除，低效，长距离依赖<br />- 方法：边界区域选择扫描，Mamba模型，U-Net结构<br />- 效果：性能提升，参数减少，计算成本低|
|📝 更新|ComFe: An Interpretable Head for Vision Transformers|ComFe：视觉Transformer的可解释头部|Evelyn J. Mannix, Liam Hodgkinson, Howard Bondell|<http://arxiv.org/pdf/2403.04125v5>|[[代码]](<https://github.com/emannix/comfe-component-features.>)<br />- 问题：可解释性，超参数，可扩展性，计算效率<br />- 方法：Component Features (ComFe)，预训练ViT，原型距离<br />- 效果：高性能，鲁棒性，基准数据集表现|


### 基础模型 (Foundation Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Mixture of Exemplars Approach for Efficient Out-of-Distribution Detection with Foundation Models|基于基础模型的混合示例方法，用于高效检测分布外数据|Evelyn Mannix, Howard Bondell|<http://arxiv.org/pdf/2311.17093v5>|[[代码]](<https://github.com/emannix/molar-mixture-of-exemplars.>)<br />- 问题：OOD检测，低置信度，长训练时间<br />- 方法：MoLAR，预训练基础模型，相似性比较<br />- 效果：高效，性能提升，速度提升|


## 生成建模 (Generative Modeling)


### 扩散模型 (Diffusion Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Tiled Diffusion|瓦片扩散|Or Madar, Ohad Fried|<http://arxiv.org/pdf/2412.15185v2>|- 问题：图像拼接，手动构建，局限性<br />- 方法：Tiled Diffusion，扩散模型，多域生成<br />- 效果：自动化，无缝集成，创意增强|
|📝 更新|Baking Gaussian Splatting into Diffusion Denoiser for Fast and Scalable Single-stage Image-to-3D Generation and Reconstruction|将高斯散布烘焙到扩散去噪器中，实现快速且可扩展的单阶段图像到3D生成与重建|Yuanhao Cai, He Zhang, Kai Zhang, Yixun Liang, Mengwei Ren, Fujun Luan, Qing Liu, Soo Ye Kim .etc.|<http://arxiv.org/pdf/2411.14384v3>|[[代码]](<https://caiyuanhao1998.github.io/project>)<br />- 问题：3D一致性，单视图生成，场景重建<br />- 方法：DiffusionGS模型，场景-对象混合训练<br />- 效果：PSNR/FID提升，速度提升|
|📝 更新|MotionPCM: Real-Time Motion Synthesis with Phased Consistency Model|运动PCM：基于相位一致性模型的实时运动合成|Lei Jiang, Ye Wei, Hao Ni|<http://arxiv.org/pdf/2501.19083v2>|- 问题：高复杂度，低效率，生成结果差<br />- 方法：MotionPCM，相位一致性模型，实时合成<br />- 效果：实时，FID提升38.9%|
|📝 更新|Rethinking Video Tokenization: A Conditioned Diffusion-based Approach|重新思考视频分词：基于条件扩散的方法|Nianzu Yang, Pandeng Li, Liming Zhao, Yang Li, Chen-Wei Xie, Yehui Tang, Xudong Lu, Zhihang Liu .etc.|<http://arxiv.org/pdf/2503.03708v2>|- 问题：视频压缩，重建，训练难度，稳定性<br />- 方法：条件扩散模型，视频编码器，解码器<br />- 效果：性能提升，效率高|
|📝 更新|The Best of Both Worlds: Integrating Language Models and Diffusion Models for Video Generation|最佳融合：语言模型与扩散模型在视频生成中的应用|Aoxiong Yin, Kai Shen, Yichong Leng, Xu Tan, Xinyu Zhou, Juncheng Li, Siliang Tang|<http://arxiv.org/pdf/2503.04606v2>|[[代码]](<https://landiff.github.io/.>)<br />- 问题：T2V生成，视觉质量，语义理解<br />- 方法：LanDiff，语义压缩，语义token，流扩散模型<br />- 效果：VBench高分，长视频生成|
|📝 更新|Self-Guidance: Boosting Flow and Diffusion Generation on Their Own|自我引导：提升自身在光流和扩散生成上的性能|Tiancheng Li, Weijian Luo, Zhiyang Chen, Liyuan Ma, Guo-Jun Qi|<http://arxiv.org/pdf/2412.05827v2>|- 问题：指导策略，模型重训练，应用限制<br />- 方法：Self-Guidance，噪声密度检测，灵活应用<br />- 效果：性能提升，生理结构生成|
|🆕 发布|Explainable Synthetic Image Detection through Diffusion Timestep Ensembling|可解释的合成图像检测：通过扩散时间步长集成|Yixin Wu, Feiran Zhang, Tianyuan Shi, Ruicheng Yin, Zhenghua Wang, Zhenliang Gan, Xiaohua Wang, Changze Lv .etc.|<http://arxiv.org/pdf/2503.06201v1>|- 问题：合成图像检测，安全风险，Fourier功率谱<br />- 方法：扩散时间步长集成，噪声增强，解释生成<br />- 效果：高检测精度，泛化能力强|
|🆕 发布|FORESCENE: FOREcasting human activity via latent SCENE graphs diffusion|FORESCENE：通过潜在场景图扩散预测人类活动|Antonio Alliegro, Francesca Pistilli, Tatiana Tommasi, Giuseppe Averta|<http://arxiv.org/pdf/2503.06182v1>|- 问题：行为预测，场景图，交互动态，长期活动<br />- 方法：图自动编码器，潜在扩散模型，场景图预测<br />- 效果：性能提升，复杂任务解决|
|🆕 发布|PTDiffusion: Free Lunch for Generating Optical Illusion Hidden Pictures with Phase-Transferred Diffusion Model|PTDiffusion：相位迁移扩散模型生成光学错觉隐藏图片的免费午餐|Xiang Gao, Shuai Yang, Jiaying Liu|<http://arxiv.org/pdf/2503.06186v1>|- 问题：光学错觉，图像融合，文本引导，无监督<br />- 方法：PTDiffusion模型，相位迁移，异步控制<br />- 效果：无监督，高质量，自然|
|🆕 发布|BioMoDiffuse: Physics-Guided Biomechanical Diffusion for Controllable and Authentic Human Motion Synthesis|生物机械扩散：基于物理的、可控且逼真的运动合成|Zixi Kang, Xinghan Wang, Yadong Mu|<http://arxiv.org/pdf/2503.06151v1>|- 问题：生物力学，运动合成，物理真实性，控制性<br />- 方法：生物力学网络，物理引导扩散，解耦控制<br />- 效果：物理准确，可控制|
|📝 更新|ZeroStereo: Zero-shot Stereo Matching from Single Images|零Stereo：从单张图像中进行零样本立体匹配|Xianqi Wang, Hao Yang, Gangwei Xu, Junda Cheng, Min Lin, Yong Deng, Jinliang Zang, Yurui Chen .etc.|<http://arxiv.org/pdf/2501.08654v2>|[[代码]](<https://github.com/Windsrain/ZeroStereo.>)<br />- 问题：零样本立体匹配，数据稀缺，泛化困难<br />- 方法：单图生成右图，伪视差，扩散修复，无监督置信度生成，自适应视差选择<br />- 效果：零样本泛化，性能最优|
|🆕 发布|VLForgery Face Triad: Detection, Localization and Attribution via Multimodal Large Language Models|低频伪造人脸三元组：通过多模态大型语言模型进行检测、定位和归因|Xinan He, Yue Zhou, Bing Fan, Bin Li, Guopu Zhu, Feng Ding|<http://arxiv.org/pdf/2503.06142v1>|- 问题：Deepfake检测，定位，归因<br />- 方法：MLLMs，VLF，EkCot，低级视觉比较<br />- 效果：检测精度高，定位准确，归因有效|
|📝 更新|Fast LiDAR Data Generation with Rectified Flows|快速校正流下的激光雷达数据生成|Kazuto Nakashima, Xiaowen Liu, Tomoya Miyawaki, Yumi Iwashita, Ryo Kurazume|<http://arxiv.org/pdf/2412.02241v2>|- 问题：LiDAR数据生成，计算成本高<br />- 方法：R2Flow，rectified flows，Transformer架构<br />- 效果：效率高，质量好|
|🆕 发布|USP: Unified Self-Supervised Pretraining for Image Generation and Understanding|统一自监督预训练：用于图像生成与理解|Xiangxiang Chu, Renda Li, Yong Wang|<http://arxiv.org/pdf/2503.06132v1>|[[代码]](<https://github.com/cxxgtxy/USP.>)<br />- 问题：预训练迁移，输入不匹配，收敛速度慢<br />- 方法：统一自监督预训练，掩码潜在建模，VAE<br />- 效果：性能相当，收敛快，生成质量高|
|📝 更新|DiffVSR: Revealing an Effective Recipe for Taming Robust Video Super-Resolution Against Complex Degradations|DiffVSR：揭示对抗复杂退化进行鲁棒视频超分辨率的有效配方|Xiaohui Li, Yihao Liu, Shuo Cao, Ziyan Chen, Shaobin Zhuang, Xiangyu Chen, Yinan He, Yi Wang .etc.|<http://arxiv.org/pdf/2501.10110v3>|- 问题：视频超分辨率，复杂退化，学习负担<br />- 方法：渐进学习策略，交织潜在转换<br />- 效果：性能优越，时间一致性|
|🆕 发布|PointDiffuse: A Dual-Conditional Diffusion Model for Enhanced Point Cloud Semantic Segmentation|点云语义分割的二元条件扩散模型：PointDiffuse|Yong He, Hongshan Yu, Mingtao Feng, Tongjia Chen, Zechuan Li, Anwaar Ulhaq, Saeed Anwar, Ajmal Saeed Mian|<http://arxiv.org/pdf/2503.06094v1>|- 问题：点云语义分割，效率低，细节丢失<br />- 方法：扩散模型，噪声标签嵌入，点频率转换器<br />- 效果：mIoU提升，性能优越|
|📝 更新|Detecting Human Artifacts from Text-to-Image Models|从文本到图像模型中检测人类人工制品|Kaihong Wang, Lingzhi Zhang, Jianming Zhang|<http://arxiv.org/pdf/2411.13842v2>|[[代码]](<https://github.com/wangkaihong/HADM.>)<br />- 问题：文本到图像模型，人工伪影，人体结构<br />- 方法：人工伪影数据集，检测模型，扩散模型微调<br />- 效果：伪影减少，图像质量提升|
|📝 更新|DEEM: Diffusion Models Serve as the Eyes of Large Language Models for Image Perception|DEEM：扩散模型作为大型语言模型图像感知的眼睛|Run Luo, Yunshui Li, Longze Chen, Wanwei He, Ting-En Lin, Ziqiang Liu, Lei Zhang, Zikai Song .etc.|<http://arxiv.org/pdf/2405.15232v4>|- 问题：多模态模型，视觉感知，分布外数据，图像编码器<br />- 方法：扩散模型，生成反馈，语义分布对齐<br />- 效果：鲁棒性提升，幻觉减少，性能增强|
|📝 更新|Diffusion Model with Perceptual Loss|扩散模型与感知损失|Shanchuan Lin, Xiao Yang|<http://arxiv.org/pdf/2401.00110v7>|- 问题：扩散模型，生成样本不真实，指导方法效果<br />- 方法：感知损失，自感知损失，无指导生成<br />- 效果：样本真实，无需指导|
|📝 更新|Mind the Time: Temporally-Controlled Multi-Event Video Generation|注意时间：时间控制的多事件视频生成|Ziyi Wu, Aliaksandr Siarohin, Willi Menapace, Ivan Skorokhodov, Yuwei Fang, Varnith Chordia, Igor Gilitschenski, Sergey Tulyakov|<http://arxiv.org/pdf/2412.05263v2>|- 问题：视频生成，时间控制，多事件<br />- 方法：MinT，时间编码，预训练模型<br />- 效果：控制时间，生成连贯|
|📝 更新|Concept Corrector: Erase concepts on the fly for text-to-image diffusion models|概念纠正器：实时擦除文本到图像扩散模型中的概念|Zheling Meng, Bo Peng, Xiaochuan Jin, Yueming Lyu, Wei Wang, Jing Dong|<http://arxiv.org/pdf/2502.16368v2>|- 问题：文本到图像生成，不期望内容，概念擦除<br />- 方法：中间图像，视觉特征，概念去除注意力<br />- 效果：实时擦除，效果显著|
|📝 更新|Just Leaf It: Accelerating Diffusion Classifiers with Hierarchical Class Pruning|仅叶：通过分层类剪枝加速扩散分类器|Arundhati S. Shanbhag, Brian B. Moser, Tobias C. Nauen, Stanislav Frolov, Federico Raue, Andreas Dengel|<http://arxiv.org/pdf/2411.12073v2>|- 问题：高计算成本，低效率<br />- 方法：分层分类，类别剪枝，子树预测<br />- 效果：推理速度提升60%，精度保持|
|📝 更新|Improving Tropical Cyclone Forecasting With Video Diffusion Models|利用视频扩散模型提升热带气旋预报|Zhibo Ren, Pritthijit Nath, Pancham Shukla|<http://arxiv.org/pdf/2501.16003v2>|[[代码]](<https://github.com/Ren-creater/forecast-video-diffmodels.>)<br />- 问题：热带气旋预测，长期动态，独立帧预测<br />- 方法：视频扩散模型，时间层，多帧生成<br />- 效果：MAE降低，PSNR提升，SSIM提升|


### 自回归模型 (Autoregressive Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Signs as Tokens: A Retrieval-Enhanced Multilingual Sign Language Generator|符号作为标记：一种检索增强的多语言手语生成器|Ronglai Zuo, Rolandos Alexandros Potamias, Evangelos Ververas, Jiankang Deng, Stefanos Zafeiriou|<http://arxiv.org/pdf/2411.17799v2>|- 问题：手语生成，文本到手语，多语言<br />- 方法：分词器，多头解码，检索增强<br />- 效果：效率提升，精度提高|


### 生成对抗网络 (GANs)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MMGenBench: Fully Automatically Evaluating LMMs from the Text-to-Image Generation Perspective|MMGenBench：从文本到图像生成视角全自动评估LMMs|Hailang Huang, Yong Wang, Zixuan Huang, Huaqiu Li, Tongwen Huang, Xiangxiang Chu, Richong Zhang|<http://arxiv.org/pdf/2411.14062v2>|- 问题：LMMs评估，领域特定，劳动密集，描述能力<br />- 方法：MMGenBench-Pipeline，文本描述，图像生成，比较<br />- 效果：全面评估，性能提升，优化方向|
|🆕 发布|HealthiVert-GAN: A Novel Framework of Pseudo-Healthy Vertebral Image Synthesis for Interpretable Compression Fracture Grading|健康伪影生成器-GAN：一种用于可解释压缩骨折分级的新型伪健康椎骨图像合成框架|Qi Zhang, Shunan Zhang, Ziqi Zhao, Kun Wang, Jun Xu, Jianqi Sun|<http://arxiv.org/pdf/2503.05990v1>|[[代码]](<https://github.com/zhibaishouheilab/HealthiVert-GAN.>)<br />- 问题：VCFs诊断，深度学习，可解释性，灵敏度<br />- 方法：HealthiVert-GAN，伪健康图像合成，RHLV量化，SVM分类<br />- 效果：分类性能，诊断灵敏度|


## 多模态学习 (Multimodal Learning)


### 视觉语言模型 (Vision-Language Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|WildLMa: Long Horizon Loco-Manipulation in the Wild|野地长时域本地操作：WildLMa|Ri-Zhao Qiu, Yuchen Song, Xuanbin Peng, Sai Aneesh Suryadevara, Ge Yang, Minghuan Liu, Mazeyu Ji, Chengzhe Jia .etc.|<http://arxiv.org/pdf/2411.15131v2>|- 问题：多环境，长时程，复杂操作<br />- 方法：低级控制器适应，技能库，规划器接口<br />- 效果：高抓取成功率，泛化能力|
|🆕 发布|GeoLangBind: Unifying Earth Observation with Agglomerative Vision-Language Foundation Models|GeoLangBind：统一地球观测与聚合视觉-语言基础模型|Zhitong Xiong, Yi Wang, Weikang Yu, Adam J Stewart, Jie Zhao, Nils Lehmann, Thomas Dujardin, Zhenghang Yuan .etc.|<http://arxiv.org/pdf/2503.06312v1>|- 问题：地球观测数据，异构，分析框架<br />- 方法：语言统一，多模态数据集，零样本模型<br />- 效果：性能优越，应用广泛|
|📝 更新|What Do You See? Enhancing Zero-Shot Image Classification with Multimodal Large Language Models|你所看到的？利用多模态大型语言模型增强零样本图像分类|Abdelrahman Abdelhamed, Mahmoud Afifi, Alec Go|<http://arxiv.org/pdf/2405.15668v3>|- 问题：零样本图像分类，LLMs，多模态<br />- 方法：文本表示，跨模态嵌入，线性分类器<br />- 效果：准确率提升，超越基准|
|🆕 发布|Your Large Vision-Language Model Only Needs A Few Attention Heads For Visual Grounding|您的视觉-语言大模型仅需少量注意力头即可实现视觉定位|Seil Kang, Jinyeong Kim, Junhyeok Kim, Seong Jae Hwang|<http://arxiv.org/pdf/2503.06287v1>|- 问题：视觉定位，LVLM，注意力头<br />- 方法：定位头，文本到图像注意力，无监督<br />- 效果：高精度，无需微调|
|📝 更新|VoCoT: Unleashing Visually Grounded Multi-Step Reasoning in Large Multi-Modal Models|VoCoT：在大型多模态模型中释放基于视觉的多步推理|Zejun Li, Ruipu Luo, Jiwen Zhang, Minghui Qiu, Xuanjing Huang, Zhongyu Wei|<http://arxiv.org/pdf/2405.16919v3>|[[代码]](<https://github.com/RupertLuo/VoCoT.>)<br />- 问题：单步推理，模态差距，复杂任务<br />- 方法：多步推理，视觉 grounding，对象中心路径<br />- 效果：性能提升，超越SOTA|
|🆕 发布|Can Atomic Step Decomposition Enhance the Self-structured Reasoning of Multimodal Large Models?|原子步分解能否增强多模态大型模型的自我结构化推理？|Kun Xiang, Zhili Liu, Zihao Jiang, Yunshuang Nie, Kaixin Cai, Yiyang Yin, Runhui Huang, Haoxiang Fan .etc.|<http://arxiv.org/pdf/2503.06252v1>|[[代码]](<https://github.com/Quinn777/AtomThink.>)<br />- 问题：多模态推理，慢思考，复杂性问题<br />- 方法：SCoT，AtomThink，多模块设计<br />- 效果：性能提升，效率提高|
|🆕 发布|SplatTalk: 3D VQA with Gaussian Splatting|SplatTalk：基于高斯喷溅的3D视觉问答|Anh Thai, Songyou Peng, Kyle Genova, Leonidas Guibas, Thomas Funkhouser|<http://arxiv.org/pdf/2503.06271v1>|- 问题：3D VQA，数据复杂，标注成本高<br />- 方法：3D Gaussian Splatting，零样本学习<br />- 效果：性能优于3D模型，与3D LMM相当|
|🆕 发布|From Captions to Rewards (CAREVL): Leveraging Large Language Model Experts for Enhanced Reward Modeling in Large Vision-Language Models|从描述到奖励（CAREVL）：利用大型语言模型专家增强大型视觉-语言模型中的奖励建模|Muzhi Dai, Jiashuo Sun, Zhiyuan Zhao, Shixuan Liu, Rui Li, Junyu Gao, Xuelong Li|<http://arxiv.org/pdf/2503.06260v1>|- 问题：LVLM偏好建模，数据稀缺，低置信度数据<br />- 方法：专家模型，弱监督，奖励建模<br />- 效果：性能提升，基准测试|
|📝 更新|ClinKD: Cross-Modal Clinical Knowledge Distiller For Multi-Task Medical Images|跨模态临床知识蒸馏的多任务医学图像处理|Hongyu Ge, Longkun Hao, Zihui Xu, Zhenxin Lin, Bin Li, Shoujun Zhou, Hongjin Zhao, Yihang Liu|<http://arxiv.org/pdf/2502.05928v2>|[[代码]](<https://github.com/overloadedHenry/ClinKD.>)<br />- 问题：多任务VQA，图像-文本对齐，医学知识<br />- 方法：ClinKD框架，知识蒸馏，医学知识适应<br />- 效果：性能提升，适应医学知识|
|📝 更新|T2I-CompBench++: An Enhanced and Comprehensive Benchmark for Compositional Text-to-image Generation|T2I-CompBench++：用于组合文本到图像生成的增强型全面基准|Kaiyi Huang, Chengqi Duan, Kaiyue Sun, Enze Xie, Zhenguo Li, Xihui Liu|<http://arxiv.org/pdf/2307.06350v3>|- 问题：复杂场景生成，多对象，属性，关系<br />- 方法：T2I-CompBench++，3D-spatial，MLLMs评估<br />- 效果：模型评估，挑战探索|
|🆕 发布|Reinforced Diffuser for Red Teaming Large Vision-Language Models|强化扩散器用于对抗大型视觉-语言模型|Ruofan Wang, Xiang Zheng, Xiaosen Wang, Cong Wang, Xingjun Ma|<http://arxiv.org/pdf/2503.06223v1>|- 问题：VLMs安全性，毒化文本，黑盒攻击<br />- 方法：Red Team Diffuser，强化学习，扩散模型<br />- 效果：毒性提升，跨模型迁移|
|📝 更新|Bridging Information Asymmetry in Text-video Retrieval: A Data-centric Approach|弥合文本-视频检索中的信息不对称：一种以数据为中心的方法|Zechen Bai, Tianjun Xiao, Tong He, Pichao Wang, Zheng Zhang, Thomas Brox, Mike Zheng Shou|<http://arxiv.org/pdf/2408.07249v2>|- 问题：信息不对称，文本视频检索<br />- 方法：数据驱动框架，事件级剪辑，LLM查询生成<br />- 效果：性能提升，跨模态检索|
|📝 更新|GazeCLIP: Enhancing Gaze Estimation Through Text-Guided Multimodal Learning|视觉注视增强：通过文本引导的多模态学习提升注视估计|Jun Wang, Hao Ruan, Liangjian Wen, Yong Dai, Mingjie Wang|<http://arxiv.org/pdf/2401.00260v4>|- 问题：gaze estimation, linguistic cues, multimodal learning<br />- 方法：text-face collaboration, CLIP-based backbone, multimodal fusion<br />- 效果：state-of-the-art accuracy, visual-language collaboration|
|📝 更新|FedMLLM: Federated Fine-tuning MLLM on Multimodal Heterogeneity Data|联邦多模态异构数据上的多语言语言模型微调：FedMLLM|Binqian Xu, Xiangbo Shu, Haiyang Mei, Guosen Xie, Basura Fernando, Jinhui Tang|<http://arxiv.org/pdf/2411.14717v2>|- 问题：MLLMs，多模态异质性，联邦学习，隐私<br />- 方法：FedMLLM框架，模态无关策略，基准测试<br />- 效果：性能提升，数据范围扩大|
|📝 更新|Multi-GraspLLM: A Multimodal LLM for Multi-Hand Semantic Guided Grasp Generation|多手语义引导抓取的多模态LLM：Multi-GraspLLM|Haosheng Li, Weixin Mao, Weipeng Deng, Chenyu Meng, Haoqiang Fan, Tiancai Wang, Ping Tan, Hongan Wang .etc.|<http://arxiv.org/pdf/2412.08468v2>|- 问题：多手语义抓取，数据集，语言指导<br />- 方法：多模态LLM，语义空间对齐，手感知线性映射<br />- 效果：性能提升，仿真实验|
|📝 更新|MUNBa: Machine Unlearning via Nash Bargaining|MUNBa：基于纳什讨价还价的机器反学习|Jing Wu, Mehrtash Harandi|<http://arxiv.org/pdf/2411.15537v2>|- 问题：机器去学习，梯度冲突，多任务学习<br />- 方法：Nash协商理论，合作博弈，Pareto最优<br />- 效果：性能提升，遗忘精确，鲁棒性增强|
|🆕 发布|Treble Counterfactual VLMs: A Causal Approach to Hallucination|三重反事实视觉语言模型：幻觉的因果方法|Li Li, Jiashu Qu, Yuxiao Zhou, Yuehan Qin, Tiankai Yang, Yue Zhao|<http://arxiv.org/pdf/2503.06169v1>|[[代码]](<https://github.com/TREE985/Treble-Counterfactual-VLMs.>)<br />- 问题：VLM幻觉，统计偏差，语言先验，特征学习<br />- 方法：因果图，反事实分析，干预模块<br />- 效果：幻觉减少，性能保持|
|🆕 发布|UrbanVideo-Bench: Benchmarking Vision-Language Models on Embodied Intelligence with Video Data in Urban Spaces|城市视频基准：在都市空间中利用视频数据对具身智能视觉-语言模型进行基准测试|Baining Zhao, Jianjie Fang, Zichao Dai, Ziyou Wang, Jirong Zha, Weichen Zhang, Chen Gao, Yue Wang .etc.|<http://arxiv.org/pdf/2503.06157v1>|- 问题：视频-语言模型，城市空间，认知能力<br />- 方法：基准测试，数据收集，问题生成<br />- 效果：认知能力评估，任务相关性分析|
|🆕 发布|Next Token Is Enough: Realistic Image Quality and Aesthetic Scoring with Multimodal Large Language Model|下一个标记就足够了：多模态大型语言模型在真实图像质量和美学评分中的应用|Mingxing Li, Rui Wang, Lei Sun, Yancheng Bai, Xiangxiang Chu|<http://arxiv.org/pdf/2503.06141v1>|- 问题：图像质量评估，美学评分，UGC图像<br />- 方法：RealQA数据集，MLLMs，预测数值分数<br />- 效果：SOTA性能，强泛化能力|
|🆕 发布|OpenRSD: Towards Open-prompts for Object Detection in Remote Sensing Images|开放RSD：面向遥感图像目标检测的开放提示|Ziyue Huang, Yongchao Feng, Shuai Yang, Ziqi Liu, Qingjie Liu, Yunhong Wang|<http://arxiv.org/pdf/2503.06146v1>|- 问题：封闭集检测，数据集规模小，遥感图像解释挑战<br />- 方法：开放提示，多任务检测头，多阶段训练<br />- 效果：精度高，实时性，适用于大规模|
|📝 更新|Detecting Offensive Memes with Social Biases in Singapore Context Using Multimodal Large Language Models|在新加坡语境下利用多模态大型语言模型检测具有社会偏见的冒犯性迷因|Cao Yuxuan, Wu Jiayang, Alistair Cheong Liang Chuen, Bryan Shan Guanrong, Theodore Lee Chong Jen, Sherman Chann Zhi Shen|<http://arxiv.org/pdf/2502.18101v2>|[[代码]](<https://github.com/aliencaocao/vlm-for-memes-aisg.>)<br />- 问题：多模态内容分类，文化多样性，低资源语言<br />- 方法：GPT-4V标注，VLM微调，OCR翻译<br />- 效果：高精度，高AUROC|
|📝 更新|TSCLIP: Robust CLIP Fine-Tuning for Worldwide Cross-Regional Traffic Sign Recognition|TSCLIP：面向全球跨区域交通标志识别的鲁棒CLIP微调|Guoyang Zhao, Fulong Ma, Weiqing Qi, Chenguang Zhang, Yuxuan Liu, Ming Liu, Jun Ma|<http://arxiv.org/pdf/2409.15077v2>|[[代码]](<https://github.com/guoyangzhao/TSCLIP.>)<br />- 问题：区域数据分布，交通标志识别，性能退化<br />- 方法：CLIP微调，跨区域数据集，提示工程<br />- 效果：鲁棒性，泛化能力|
|🆕 发布|GEM: Empowering MLLM for Grounded ECG Understanding with Time Series and Images|GEM：利用时间序列和图像赋能MLLM进行基于地面的ECG理解|Xiang Lan, Feng Wu, Kai He, Qinghao Zhao, Shenda Hong, Mengling Feng|<http://arxiv.org/pdf/2503.06073v1>|[[代码]](<https://github.com/lanxiang1017/GEM.git>)<br />- 问题：多模态协同，可解释性，波形证据<br />- 方法：双编码器，跨模态对齐，知识引导指令生成<br />- 效果：性能提升，可解释性增强|
|📝 更新|GRAPHGPT-O: Synergistic Multimodal Comprehension and Generation on Graphs|图GPT-O：图上的协同多模态理解和生成|Yi Fang, Bowen Jin, Jiacheng Shen, Sirui Ding, Qiaoyu Tan, Jiawei Han|<http://arxiv.org/pdf/2502.11925v2>|- 问题：多模态理解，图结构，语义信息<br />- 方法：GraphGPT-o，线性化，层次对齐器<br />- 效果：有效，多领域验证|
|🆕 发布|Towards Universal Text-driven CT Image Segmentation|迈向通用文本驱动CT图像分割|Yuheng Li, Yuxiang Lai, Maria Thor, Deborah Marshall, Zachary Buchwald, David S. Yu, Xiaofeng Yang|<http://arxiv.org/pdf/2503.06030v1>|[[代码]](<https://github.com/ricklisz/OpenVocabCT.>)<br />- 问题：CT图像分割，深度学习性能下降，标注困难<br />- 方法：OpenVocabCT，视觉语言模型，多粒度对比学习<br />- 效果：性能优越，公开数据|
|🆕 发布|Zero-Shot Peg Insertion: Identifying Mating Holes and Estimating SE(2) Poses with Vision-Language Models|零样本销钉插入：利用视觉-语言模型识别配对孔和估计SE(2)位姿|Masaru Yajima, Kei Ota, Asako Kanezaki, Rei Kawakami|<http://arxiv.org/pdf/2503.06026v1>|- 问题：零样本，插入，识别，定位，不确定性<br />- 方法：视觉语言模型，匹配，估计，SE(2)姿态<br />- 效果：高精度，泛化，实际应用|
|📝 更新|Task-oriented Sequential Grounding and Navigation in 3D Scenes|面向任务的3D场景中的顺序定位与导航|Zhuofan Zhang, Ziyu Zhu, Junhao Li, Pengxiang Li, Tianxu Wang, Tengyu Liu, Xiaojian Ma, Yixin Chen .etc.|<http://arxiv.org/pdf/2408.04034v2>|- 问题：3D视觉语言对齐，任务导向，动态场景<br />- 方法：SG3D数据集，SG-LLM模型，逐步定位导航<br />- 效果：挑战揭示，能力提升|
|🆕 发布|Integrating Frequency-Domain Representations with Low-Rank Adaptation in Vision-Language Models|视觉-语言模型中融合频域表示与低秩自适应|Md Azim Khan, Aryya Gangopadhyay, Jianwu Wang, Robert F. Erbacher|<http://arxiv.org/pdf/2503.06003v1>|- 问题：VLM计算挑战，效率低，性能差<br />- 方法：频率域，低秩自适应，DFT，空间权重<br />- 效果：性能相当，细节丰富，响应相关|


### 多模态融合 (Multimodal Fusion)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Advancing Autonomous Vehicle Intelligence: Deep Learning and Multimodal LLM for Traffic Sign Recognition and Robust Lane Detection|推进自动驾驶车辆智能：深度学习与多模态LLM在交通标志识别和鲁棒车道检测中的应用|Chandan Kumar Sah, Ankit Kumar Shaw, Xiaoli Lian, Arsalan Shahid Baig, Tuopu Wen, Kun Jiang, Mengmeng Yang, Diange Yang|<http://arxiv.org/pdf/2503.06313v1>|- 问题：自动驾驶，交通标志识别，车道检测，复杂环境<br />- 方法：深度学习，多模态LLM，CNN，曲线拟合<br />- 效果：高精度，鲁棒性，安全性提升|
|🆕 发布|Removing Multiple Hybrid Adverse Weather in Video via a Unified Model|通过统一模型去除视频中的多种混合恶劣天气|Yecong Wan, Mingwen Shao, Yuanshuo Cheng, Jun Shu, Shuigen Wang|<http://arxiv.org/pdf/2503.06200v1>|- 问题：多混合天气，降解分布，模型适应性，数据缺乏<br />- 方法：统一模型，空间特征引导，动态路由聚合<br />- 效果：鲁棒性，泛化能力|
|🆕 发布|Viewport-Unaware Blind Omnidirectional Image Quality Assessment: A Flexible and Effective Paradigm|视口无关的全向图像质量评估：一种灵活有效的范式|Jiebin Yan, Kangcheng Wu, Junjie Chen, Ziwen Tan, Yuming Fang|<http://arxiv.org/pdf/2503.06129v1>|- 问题：BOIQA模型，计算成本高，可扩展性差<br />- 方法：自适应采样，变形免疫特征融合，局部到全局聚合<br />- 效果：性能竞争，低复杂度|
|🆕 发布|Multi-Layer Visual Feature Fusion in Multimodal LLMs: Methods, Analysis, and Best Practices|多层视觉特征融合在多模态大型语言模型中的方法、分析和最佳实践|Junyan Lin, Haoran Chen, Yue Fan, Yingqi Fan, Xin Jin, Hui Su, Jinlan Fu, Xiaoyu Shen|<http://arxiv.org/pdf/2503.06063v1>|[[代码]](<https://github.com/EIT-NLP/Layer_Select_Fuse_for_MLLM.>)<br />- 问题：多模态LLMs，视觉特征融合，层选择，融合策略<br />- 方法：系统研究，层选择，最佳融合方法<br />- 效果：性能提升，稳定性增强|
|🆕 发布|GenieBlue: Integrating both Linguistic and Multimodal Capabilities for Large Language Models on Mobile Devices|GenieBlue：为移动设备上的大型语言模型整合语言和多模态能力|Xudong Lu, Yinghao Chen, Renshou Wu, Haohao Gao, Xi Chen, Xue Yang, Xiangyu Zhao, Aojun Zhou .etc.|<http://arxiv.org/pdf/2503.06019v1>|- 问题：MLLMs性能退化，硬件兼容性差，语言能力维护，MoE架构支持<br />- 方法：参数冻结，Transformer块复制，LoRA模块集成<br />- 效果：效率高，实用性强|


### 跨模态对齐 (Cross-modal Alignment)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Zero-AVSR: Zero-Shot Audio-Visual Speech Recognition with LLMs by Learning Language-Agnostic Speech Representations|零AVSR：通过学习语言无关的语音表示，利用LLMs实现零样本视听语音识别|Jeong Hun Yeo, Minsu Kim, Chae Won Kim, Stavros Petridis, Yong Man Ro|<http://arxiv.org/pdf/2503.06273v1>|- 问题：零样本语音识别，语言无关，多语言支持<br />- 方法：语言无关语音表示，LLM，多任务学习<br />- 效果：跨语言识别，数据集丰富|
|🆕 发布|Integrating Chain-of-Thought for Multimodal Alignment: A Study on 3D Vision-Language Learning|整合思维链的多模态对齐：3D视觉-语言学习研究|Yanjun Chen, Yirong Sun, Xinghao Chen, Jian Wang, Xiaoyu Shen, Wenjie Li, Wei Zhang|<http://arxiv.org/pdf/2503.06232v1>|- 问题：多模态对齐，3D视觉语言学习<br />- 方法：CoT嵌入，3D-CoT基准，双层评估框架<br />- 效果：语义对齐提升，LRM优于LLM|
|📝 更新|AI, Entrepreneurs, and Privacy: Deep Learning Outperforms Humans in Detecting Entrepreneurs from Image Data|人工智能、企业家与隐私：深度学习在从图像数据中检测企业家方面优于人类|Martin Obschonka, Christian Fisch, Tharindu Fernando, Clinton Fookes|<http://arxiv.org/pdf/2409.03765v3>|- 问题：AI，隐私，职业识别，人脸图像<br />- 方法：CNN，对比学习，人脸图像对<br />- 效果：高准确率，隐私风险|
|📝 更新|Gotta Hear Them All: Sound Source Aware Vision to Audio Generation|必须全部听到：基于声源感知的视觉到音频生成|Wei Guo, Heng Wang, Jianbo Ma, Weidong Cai|<http://arxiv.org/pdf/2411.15447v3>|[[代码]](<https://ssv2a.github.io/SSV2A-demo>)<br />- 问题：V2A生成，沉浸感，表达性，局部声音，细节忽略<br />- 方法：SSV2A，视觉检测，跨模态翻译，CMSS流形，注意力混合<br />- 效果：生成质量高，相关性强，控制直观|
|📝 更新|Driving-Video Dehazing with Non-Aligned Regularization for Safety Assistance|驾驶视频去雾的非对齐正则化安全辅助|Junkai Fan, Jiangwei Weng, Kun Wang, Yijun Yang, Jianjun Qian, Jun Li, Jian Yang|<http://arxiv.org/pdf/2405.09996v2>|- 问题：去雾，视频，动态场景，非对齐，训练困难<br />- 方法：非对齐正则化，参考匹配，视频去雾<br />- 效果：性能优越，状态艺术|
|📝 更新|LES-Talker: Fine-Grained Emotion Editing for Talking Head Generation in Linear Emotion Space|LES-Talker：线性情感空间中人脸视频生成中的细粒度情感编辑|Guanwen Feng, Zhihao Qian, Yunan Li, Siyu Jin, Qiguang Miao, Chi-Man Pun|<http://arxiv.org/pdf/2411.09268v2>|- 问题：细粒度情感编辑，高可解释性，线性情感空间<br />- 方法：线性情感空间定义，跨维度注意力网络，网络设计<br />- 效果：高视觉质量，多级编辑，性能优越|
|🆕 发布|Vision-aware Multimodal Prompt Tuning for Uploadable Multi-source Few-shot Domain Adaptation|视觉感知的多模态提示调整用于可上传的多源少样本领域自适应|Kuanghong Liu, Jin Wang, Kangjian He, Dan Xu, Xuejie Zhang|<http://arxiv.org/pdf/2503.06106v1>|- 问题：MFDA，低资源，边缘设备，少样本，域适应<br />- 方法：UMFDA，VAMP，视觉感知，多模态提示调整<br />- 效果：性能提升，协作学习|
|📝 更新|LaMP: Language-Motion Pretraining for Motion Generation, Retrieval, and Captioning|LaMP：用于运动生成、检索和字幕的语言-运动预训练|Zhe Li, Weihao Yuan, Yisheng He, Lingteng Qiu, Shenhao Zhu, Xiaodong Gu, Weichao Shen, Yuan Dong .etc.|<http://arxiv.org/pdf/2410.07093v2>|- 问题：语言-动作对齐，CLIP局限性，动作生成，检索，描述<br />- 方法：LaMP模型，语言-动作预训练，自回归掩码预测<br />- 效果：性能提升，多任务，LaMP-BertScore|


## 目标检测识别 (Object Detection & Recognition)


### 二维检测 (2D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Accurate and Efficient Two-Stage Gun Detection in Video|准确高效的视频两阶段枪支检测|Badhan Chandra Das, M. Hadi Amini, Yanzhao Wu|<http://arxiv.org/pdf/2503.06317v1>|- 问题：视频枪检测，小目标，复杂场景，数据集限制<br />- 方法：两阶段检测，图像增强，目标定位<br />- 效果：性能提升，效率增强|
|🆕 发布|Get In Video: Add Anything You Want to the Video|视频随心所欲：将任何你想要的内容添加到视频中|Shaobin Zhuang, Zhipeng Huang, Binxin Yang, Ying Zhang, Fangyikang Wang, Canmiao Fu, Chong Sun, Zheng-Jun Zha .etc.|<http://arxiv.org/pdf/2503.06268v1>|- 问题：视频编辑，视觉特征，实例交互<br />- 方法：GetIn-1M数据集，扩散Transformer，3D全注意力<br />- 效果：高质量编辑，自然交互|
|🆕 发布|MSConv: Multiplicative and Subtractive Convolution for Face Recognition|MSConv：用于人脸识别的乘法和减法卷积|Si Zhou, Yain-Whar Si, Xiaochen Yuan, Xiaofan Li, Xiaoxiang Liu, Xinyuan Zhang, Cong Lin, Xueyuan Gong|<http://arxiv.org/pdf/2503.06187v1>|- 问题：特征融合，特征提取，人脸识别<br />- 方法：MSConv，多尺度混合卷积，乘减操作<br />- 效果：性能提升，特征平衡|
|📝 更新|MolParser: End-to-end Visual Recognition of Molecule Structures in the Wild|MolParser：野外分子结构的端到端视觉识别|Xi Fang, Jiankun Wang, Xiaochen Cai, Shangqian Chen, Shuwen Yang, Haoyi Tao, Nan Wang, Lin Yao .etc.|<http://arxiv.org/pdf/2411.11098v2>|- 问题：分子结构识别，OCSR，Markush结构<br />- 方法：MolParser，SMILES编码，主动学习<br />- 效果：高效准确，超越经典方法|
|🆕 发布|Handwritten Digit Recognition: An Ensemble-Based Approach for Superior Performance|手写数字识别：一种基于集成方法的卓越性能提升|Syed Sajid Ullah, Li Gang, Mudassir Riaz, Ahsan Ashfaq, Salman Khan, Sajawal Khan|<http://arxiv.org/pdf/2503.06104v1>|- 问题：手写数字识别，准确率，鲁棒性<br />- 方法：CNN，SVM，数据增强，集成学习<br />- 效果：高准确率，泛化能力强|
|🆕 发布|A Novel Trustworthy Video Summarization Algorithm Through a Mixture of LoRA Experts|一种基于LoRA专家混合的新型可信视频摘要算法|Wenzhuo Du, Gerun Wang, Guancheng Chen, Hang Zhao, Xin Li, Jian Gao|<http://arxiv.org/pdf/2503.06064v1>|- 问题：视频搜索效率低，模型复杂，资源消耗大<br />- 方法：混合专家，LoRA，时空适应机制<br />- 效果：性能最优，成本降低|


### 三维检测 (3D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Rethinking Lanes and Points in Complex Scenarios for Monocular 3D Lane Detection|重新思考复杂场景中单目3D车道检测的车道和点|Yifan Chang, Junjie Huang, Xiaofeng Wang, Yun Ye, Zhujin Liang, Yi Shan, Dalong Du, Xingang Wang|<http://arxiv.org/pdf/2503.06237v1>|- 问题：单目3D车道检测，几何结构利用不足，误差大<br />- 方法：补丁策略，EP-head，PL-attention<br />- 效果：F1-score提升，模型更高效|
|📝 更新|T-3DGS: Removing Transient Objects for 3D Scene Reconstruction|T-3DGS：去除瞬态物体进行三维场景重建|Alexander Markin, Vadim Pryadilshchikov, Artem Komarichev, Ruslan Rakhimov, Peter Wonka, Evgeny Burnaev|<http://arxiv.org/pdf/2412.00155v2>|- 问题：3D场景重建，瞬态物体，质量退化<br />- 方法：Gaussian Splatting，分类网络，双向跟踪<br />- 效果：性能提升，高保真重建|
|🆕 发布|End-to-End HOI Reconstruction Transformer with Graph-based Encoding|端到端基于图编码的HOI重建Transformer|Zhenrong Wang, Qi Zheng, Sihan Ma, Maosheng Ye, Yibing Zhan, Dongjiang Li|<http://arxiv.org/pdf/2503.06012v1>|- 问题：HOI重建，全局结构，局部细节，建模冲突<br />- 方法：Transformer，图编码，自注意力机制，图残差块<br />- 效果：性能提升，结果改善|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Object-Centric World Model for Language-Guided Manipulation|以对象为中心的世界模型用于语言引导的操作|Youngjoon Jeong, Junha Chun, Soonwoo Cha, Taesup Kim|<http://arxiv.org/pdf/2503.06170v1>|- 问题：世界模型，计算资源，语言指导<br />- 方法：对象中心，槽位注意力，语言指令<br />- 效果：高效，灵活，任务优势|
|📝 更新|GestureLSM: Latent Shortcut based Co-Speech Gesture Generation with Spatial-Temporal Modeling|手势LSM：基于潜在捷径的协同语音手势生成与时空建模|Pinxin Liu, Luchuan Song, Junhua Huang, Haiyang Liu, Chenliang Xu|<http://arxiv.org/pdf/2501.18898v2>|[[代码]](<https://andypinxinliu.github.io/GestureLSM>)<br />- 问题：全身体势生成，空间交互，生成速度慢<br />- 方法：空间时间建模，流匹配，潜在捷径学习<br />- 效果：性能领先，推理时间减少|


## 三维重建 (3D Reconstruction)


### 多视图重建 (Multi-view Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Occam's LGS: An Efficient Approach for Language Gaussian Splatting|奥卡姆语言高斯分层：一种高效的语言高斯分层方法|Jiahuan Cheng, Jan-Nico Zaech, Luc Van Gool, Danda Pani Paudel|<http://arxiv.org/pdf/2412.01807v2>|[[代码]](<https://insait-institute.github.io/OccamLGS>)<br />- 问题：Gaussian Splatting，语义特征，计算成本高<br />- 方法：Occam's razor，加权多视图聚合<br />- 效果：效率高，速度提升|


### 神经隐式重建 (Neural Implicit Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Monge-Ampere Regularization for Learning Arbitrary Shapes from Point Clouds|从点云学习任意形状的Monge-Ampère正则化|Chuanxiang Yang, Yuanfeng Zhou, Guangshun Wei, Long Ma, Junhui Hou, Yuan Liu, Wenping Wang|<http://arxiv.org/pdf/2410.18477v2>|[[代码]](<https://github.com/chuanxiang-yang/S2DF.>)<br />- 问题：SDF局限性，UDF非光滑性，表面建模<br />- 方法：S$^{2}$DF，Monge-Ampere正则化，无监督学习<br />- 效果：性能优于现有方法，无需地面实值|


### 单目重建 (Monocular Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Realistic Clothed Human and Object Joint Reconstruction from a Single Image|从单张图像中实现逼真的着装人体和物体联合重建|Ayushi Dutta, Marco Pesavento, Marco Volino, Adrian Hilton, Armin Mustafa|<http://arxiv.org/pdf/2502.18150v2>|- 问题：3D重建，服装细节，遮挡，深度模糊<br />- 方法：隐式表示，注意力模型，扩散模型<br />- 效果：细节丰富，重建质量高|


## 神经渲染 (Neural Rendering)


### 神经辐射场 (Neural Radiance Fields)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Incremental Multi-Scene Modeling via Continual Neural Graphics Primitives|增量多场景建模通过持续神经图形原语|Prajwal Singh, Ashish Tiwari, Gautam Vashishtha, Shanmuganathan Raman|<http://arxiv.org/pdf/2411.19903v2>|- 问题：NeRF可扩展性，多场景建模，训练时间累积<br />- 方法：C-NGP，增量学习，生成重放<br />- 效果：高质量渲染，参数不变，PSNR提升|
|📝 更新|PlanarNeRF: Online Learning of Planar Primitives with Neural Radiance Fields|平面NeRF：基于神经辐射场的平面基元在线学习|Zheng Chen, Qingan Yan, Huangying Zhan, Changjiang Cai, Xiangyu Xu, Yuzhong Huang, Weihan Wang, Ziyue Feng .etc.|<http://arxiv.org/pdf/2401.00871v2>|- 问题：平面检测，3D结构简化，标注依赖<br />- 方法：神经场表示，平面拟合模块，全局记忆库<br />- 效果：在线学习，效率提升|
|🆕 发布|SecureGS: Boosting the Security and Fidelity of 3D Gaussian Splatting Steganography|SecureGS：提升3D高斯喷溅隐写术的安全性和保真度|Xuanyu Zhang, Jiarui Meng, Zhipei Xu, Shuzhou Yang, Yanmin Wu, Ronggang Wang, Jian Zhang|<http://arxiv.org/pdf/2503.06118v1>|- 问题：3DGS隐私保护，渲染质量，计算效率，安全性<br />- 方法：混合加密，神经解码，密度区域感知<br />- 效果：渲染质量提升，速度提升，安全性增强|
|🆕 发布|NeuraLoc: Visual Localization in Neural Implicit Map with Dual Complementary Features|NeuraLoc：基于神经隐式地图的双互补特征视觉定位|Hongjia Zhai, Boming Zhao, Hai Li, Xiaokun Pan, Yijia He, Zhaopeng Cui, Hujun Bao, Guofeng Zhang|<http://arxiv.org/pdf/2503.06117v1>|[[代码]](<https://zju3dv.github.io/neuraloc>)<br />- 问题：NeRF定位，几何约束，存储需求<br />- 方法：3D关键点描述符，语义上下文特征，匹配图构建<br />- 效果：训练速度提升，存储减少，性能优越|


### 可控渲染 (Controllable Rendering)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ForestSplats: Deformable transient field for Gaussian Splatting in the Wild|森林滴溅：野外的可变形瞬态场高斯滴溅|Wongi Park, Myeongseok Nam, Siwon Kim, Sangwoo Jo, Soomok Lee|<http://arxiv.org/pdf/2503.06179v1>|- 问题：3D-GS性能下降，计算成本高，内存需求大<br />- 方法：变形场，超像素掩码，不确定性感知稠密化<br />- 效果：无VFM，内存效率高|
|🆕 发布|Feature-EndoGaussian: Feature Distilled Gaussian Splatting in Surgical Deformable Scene Reconstruction|特征-端到端高斯：手术变形场景重建中的特征蒸馏高斯喷溅|Kai Li, Junhao Wang, William Han, Ding Zhao|<http://arxiv.org/pdf/2503.06161v1>|- 问题：手术场景重建，实时性，3DGS<br />- 方法：FEG，语义特征蒸馏，Gaussian变形<br />- 效果：性能提升，实时语义重建|


### 场景编辑 (Scene Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OpenFly: A Versatile Toolchain and Large-scale Benchmark for Aerial Vision-Language Navigation|OpenFly：一种通用的工具链和大规模空中视觉语言导航基准|Yunpeng Gao, Chenhui Li, Zhongrui You, Junli Liu, Zhen Li, Pengan Chen, Qizhi Chen, Zhonghan Tang .etc.|<http://arxiv.org/pdf/2502.18041v4>|- 问题：室外航空视觉语言导航，数据收集困难，缺乏基准<br />- 方法：自动化工具链，大规模数据集，OpenFly-Agent模型<br />- 效果：数据集，模型性能提升|


## 定位与映射 (Localization & Mapping)


### 语义建图 (Semantic Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EvidMTL: Evidential Multi-Task Learning for Uncertainty-Aware Semantic Surface Mapping from Monocular RGB Images|基于证据的多任务学习：从单目RGB图像中进行不确定性感知语义表面映射|Rohit Menon, Nils Dengler, Sicong Pan, Gokul Krishna Chenchani, Maren Bennewitz|<http://arxiv.org/pdf/2503.04441v2>|- 问题：语义映射，不确定性，深度估计，单目图像<br />- 方法：EvidMTL，证据头，深度损失函数<br />- 效果：不确定性估计，精度提升|


### 位姿估计 (Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LucidFusion: Reconstructing 3D Gaussians with Arbitrary Unposed Images|LucidFusion：使用任意未定位图像重建3D高斯分布|Hao He, Yixun Liang, Luozhou Wang, Yuanhao Cai, Xinli Xu, Hao-Xiang Guo, Xiang Wen, Yingcong Chen|<http://arxiv.org/pdf/2410.15636v3>|- 问题：3D重建，相机姿态，固定视角，灵活性<br />- 方法：图像到图像翻译，相对坐标图，相对坐标高斯<br />- 效果：快速，鲁棒，灵活|
|📝 更新|Humans as a Calibration Pattern: Dynamic 3D Scene Reconstruction from Unsynchronized and Uncalibrated Videos|人类作为校准图案：从未同步和未校准的视频中进行动态3D场景重建|Changwoon Choi, Jeongjun Kim, Geonho Cha, Minkwan Kim, Dongyoon Wee, Young Min Kim|<http://arxiv.org/pdf/2412.19089v2>|- 问题：动态3D场景重建，视频同步性，未校准<br />- 方法：人体运动，时间偏移计算，多分辨率网格<br />- 效果：准确校准，高质量重建|
|📝 更新|Motion-Aware Generative Frame Interpolation|感知运动生成帧插值|Guozhen Zhang, Yuhan Zhu, Yutao Cui, Xiaotong Zhao, Kai Ma, Limin Wang|<http://arxiv.org/pdf/2501.03699v2>|- 问题：运动稳定性，内容一致性，复杂运动区域，生成模型<br />- 方法：运动感知，双重引导，动态修正<br />- 效果：视频质量，视觉保真|
|🆕 发布|Fish2Mesh Transformer: 3D Human Mesh Recovery from Egocentric Vision|鱼2网格变换器：基于自视角视觉的3D人体网格恢复|David C. Jeong, Aditya Puranik, James Vong, Vrushabh Abhijit Deogirikar, Ryan Fell, Julianna Dietrich, Maria Kyrarini, Christopher Kitts|<http://arxiv.org/pdf/2503.06089v1>|- 问题：3D人体网格恢复，鱼眼图像，自遮挡<br />- 方法：Fish2Mesh模型，位置嵌入块，多任务头<br />- 效果：超越SOTA，3D HMR|
|📝 更新|FisheyeDepth: A Real Scale Self-Supervised Depth Estimation Model for Fisheye Camera|鱼眼深度：一种针对鱼眼相机的真实尺度自监督深度估计模型|Guoyang Zhao, Yuxuan Liu, Weiqing Qi, Fulong Ma, Ming Liu, Jun Ma|<http://arxiv.org/pdf/2409.15054v2>|[[代码]](<https://github.com/guoyangzhao/FisheyeDepth.>)<br />- 问题：深度估计，鱼眼相机，图像扭曲，真实尺度<br />- 方法：自监督学习，鱼眼模型，多通道输出<br />- 效果：精度提升，鲁棒性增强|


### 视觉SLAM (Visual SLAM)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Leveraging Consistent Spatio-Temporal Correspondence for Robust Visual Odometry|利用一致时空对应关系实现鲁棒视觉里程计|Zhaoxing Zhang, Junda Cheng, Gangwei Xu, Xiaoxiang Wang, Can Zhang, Xin Yang|<http://arxiv.org/pdf/2412.16923v4>|- 问题：视觉里程标，噪声，一致性，长序列<br />- 方法：时空视觉里程标，时间传播模块，空间激活模块<br />- 效果：精度提升，性能优越|
|🆕 发布|Towards Ambiguity-Free Spatial Foundation Model: Rethinking and Decoupling Depth Ambiguity|迈向无歧义的空间基础模型：深度模糊的重新思考与解耦|Xiaohao Xu, Feng Xue, Xiang Li, Haowei Li, Shusheng Yang, Tianyi Zhang, Matthew Johnson-Roberson, Xiaonan Huang|<http://arxiv.org/pdf/2503.06014v1>|[[代码]](<https://github.com/Xiaohao-Xu/Ambiguity-in-Space.>)<br />- 问题：深度模糊，空间理解，多层深度<br />- 方法：多假设模型，LVP技术，无监督学习<br />- 效果：零样本，深度估计，几何生成|


## 自监督学习 (Self-supervised Learning)


### 一致性学习 (Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FCDM: A Physics-Guided Bidirectional Frequency Aware Convolution and Diffusion-Based Model for Sinogram Inpainting|FCDM：一种基于物理引导的双向频率感知卷积和扩散模型用于正弦图修复|Jiaze E, Srutarshi Banerjee, Tekin Bicer, Guannan Wang, Yanfu Zhang, Bin Ren|<http://arxiv.org/pdf/2409.06714v3>|- 问题：CT稀疏扫描，特征纠缠，物理约束缺乏<br />- 方法：双向频率卷积，物理信息损失，扩散增强<br />- 效果：SSIM 0.95，PSNR 30 dB|
|🆕 发布|Text2Story: Advancing Video Storytelling with Text Guidance|文本引导下的视频叙事：推动视频故事讲述的发展|Taewon Kang, Divya Kothandaraman, Ming C. Lin|<http://arxiv.org/pdf/2503.06310v1>|- 问题：视频故事生成，文本指导，时序一致性，语义保持，动作连续性<br />- 方法：双向时间加权，Black-Scholes算法，语义动作表示<br />- 效果：时序一致，视觉吸引，无额外训练|
|🆕 发布|DropletVideo: A Dataset and Approach to Explore Integral Spatio-Temporal Consistent Video Generation|DropletVideo：探索积分时空一致视频生成的数据集与方法|Runze Zhang, Guoguang Du, Xiaochuan Li, Qi Jia, Liang Jin, Lu Liu, Jingjing Wang, Cong Xu .etc.|<http://arxiv.org/pdf/2503.06053v1>|- 问题：时空一致性，视频生成，情节连贯性<br />- 方法：DropletVideo数据集，模型训练，时空一致性<br />- 效果：时空连贯性，视频生成|


### 对比学习 (Contrastive Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|STiL: Semi-supervised Tabular-Image Learning for Comprehensive Task-Relevant Information Exploration in Multimodal Classification|STiL：多模态分类中全面任务相关信息探索的半监督表格-图像学习|Siyi Du, Xinzhe Luo, Declan P. O'Regan, Chen Qin|<http://arxiv.org/pdf/2503.06277v1>|- 问题：标签数据少，特征学习差，模态信息缺失<br />- 方法：半监督学习，对比学习，伪标签生成<br />- 效果：性能优于现有方法，信息探索全面|


## 迁移与适应 (Transfer & Adaptation)


### 增量学习 (Incremental Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning to Unlearn while Retaining: Combating Gradient Conflicts in Machine Unlearning|学习在保留的同时遗忘：对抗机器反学习的梯度冲突|Gaurav Patel, Qiang Qiu|<http://arxiv.org/pdf/2503.06339v1>|- 问题：梯度冲突，知识保留，模型性能<br />- 方法：学习未学习，梯度正则化，隐式机制<br />- 效果：有效未学习，性能保留|
|📝 更新|LightCL: Compact Continual Learning with Low Memory Footprint For Edge Device|标题翻译：LightCL：低内存占用下的紧凑型持续学习，适用于边缘设备|Zeqing Wang, Fei Cheng, Kangye Ji, Bohu Huang|<http://arxiv.org/pdf/2407.10545v3>|- 问题：边缘设备，持续学习，资源消耗，泛化能力<br />- 方法：LightCL，结构压缩，泛化性评估<br />- 效果：内存减少，泛化能力提升|
|📝 更新|PILOT: A Pre-Trained Model-Based Continual Learning Toolbox|PILOT：基于预训练模型的持续学习工具箱|Hai-Long Sun, Da-Wei Zhou, De-Chuan Zhan, Han-Jia Ye|<http://arxiv.org/pdf/2309.07117v3>|- 问题：增量学习，预训练模型，持续学习<br />- 方法：PILOT工具箱，预训练模型应用，算法集成<br />- 效果：性能提升，算法评估|
|🆕 发布|Pathological Prior-Guided Multiple Instance Learning For Mitigating Catastrophic Forgetting in Breast Cancer Whole Slide Image Classification|病理先验引导的多实例学习以减轻乳腺癌全切片图像分类中的灾难性遗忘|Weixi Zheng, Aoling Huang. Jingping Yuan, Haoyu Zhao, Zhou Zhao, Yongchao Xu, Thierry Géraud|<http://arxiv.org/pdf/2503.06056v1>|- 问题：遗忘，分类，WSI，病理，MIL<br />- 方法：病理先验，PaGMIL，分类头，提示引导<br />- 效果：性能平衡，持续学习|


### 域适应 (Domain Adaptation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Dataset to Real-world: General 3D Object Detection via Generalized Cross-domain Few-shot Learning|从数据集到现实世界：通用3D目标检测通过广义跨域小样本学习|Shuangzhi Li, Junlong Shen, Lei Ma, Xingyu Li|<http://arxiv.org/pdf/2503.06282v1>|- 问题：数据集限制，泛化能力差，少样本学习<br />- 方法：多模态融合，对比增强原型学习，物理感知搜索<br />- 效果：性能提升，泛化能力强|
|📝 更新|Dynamic Degradation Decomposition Network for All-in-One Image Restoration|动态退化分解网络用于一体化图像恢复|Huiqiang Wang, Mingchen Song, Guoqiang Zhong|<http://arxiv.org/pdf/2502.19068v2>|- 问题：单一模型，复杂退化，适应性<br />- 方法：动态分解网络，跨域分析，自适应策略<br />- 效果：性能提升，PSNR改善|
|📝 更新|Pretrained Reversible Generation as Unsupervised Visual Representation Learning|预训练可逆生成作为无监督视觉表征学习|Rongkun Xue, Jinouwen Zhang, Yazhe Niu, Dazhong Shen, Bingqi Ma, Yu Liu, Jing Yang|<http://arxiv.org/pdf/2412.01787v2>|- 问题：生成模型，判别任务，代表性学习<br />- 方法：预训练可逆生成，特征提取，下游任务<br />- 效果：性能提升，准确率，泛化性|
|📝 更新|Universal Actions for Enhanced Embodied Foundation Models|通用动作增强具身基础模型|Jinliang Zheng, Jianxiong Li, Dongxiu Liu, Yinan Zheng, Zhihao Wang, Zhonghong Ou, Yu Liu, Jingjing Liu .etc.|<http://arxiv.org/pdf/2501.10105v2>|[[代码]](<https://github.com/2toinf/UniAct>)<br />- 问题：异构动作空间，数据异质性，跨领域泛化困难<br />- 方法：通用动作空间，结构特征利用，动作翻译<br />- 效果：性能超越，跨机器人适应|
|🆕 发布|NeuroADDA: Active Discriminative Domain Adaptation in Connectomic|神经ADDA：连接组中的主动判别域适应|Shashata Sawmya, Thomas L. Athey, Gwyneth Liu, Nir Shavit|<http://arxiv.org/pdf/2503.06196v1>|- 问题：connectomics，domain adaptation，pretrained models<br />- 方法：NeuroADDA，active learning，MMD<br />- 效果：性能提升，效率提高|
|🆕 发布|Feature Fusion Attention Network with CycleGAN for Image Dehazing, De-Snowing and De-Raining|基于CycleGAN的图像去雾、除雪和去雨特征融合注意力网络|Akshat Jain|<http://arxiv.org/pdf/2503.06107v1>|- 问题：图像去雾，去雪，去雨<br />- 方法：FFA网络，CycleGAN，特征融合<br />- 效果：PSNR，SSIM提升|
|📝 更新|DODA: Adapting Object Detectors to Dynamic Agricultural Environments in Real-Time with Diffusion|DODA：利用扩散技术实时适应动态农业环境的对象检测器自适应|Shuai Xiang, Pieter M. Blok, James Burridge, Haozhou Wang, Wei Guo|<http://arxiv.org/pdf/2403.18334v2>|[[代码]](<https://github.com/UTokyo-FieldPhenomics-Lab/DODA.>)<br />- 问题：领域迁移，农业环境，实时适应<br />- 方法：扩散模型，域嵌入，布局到图像<br />- 效果：快速适应，性能提升|
|📝 更新|Learning Object Properties Using Robot Proprioception via Differentiable Robot-Object Interaction|通过可微机器人-物体交互学习物体属性|Peter Yichen Chen, Chao Liu, Pingchuan Ma, John Eastman, Daniela Rus, Dylan Randle, Yuri Ivanov, Wojciech Matusik|<http://arxiv.org/pdf/2410.03920v2>|- 问题：物体属性识别，机器人感知，数据依赖<br />- 方法：可微分模拟，机器人-物体交互，关节编码器<br />- 效果：属性估计，精度高，计算快|
|📝 更新|Rethinking Debiasing: Real-World Bias Analysis and Mitigation|重新思考去偏：现实世界中的偏差分析和缓解|Peng Kuang, Zhibo Wang, Zhixuan Chu, Jingyi Wang, Kui Ren|<http://arxiv.org/pdf/2405.15240v3>|- 问题：数据偏差，模型泛化，现实世界<br />- 方法：细粒度分析，新数据集，Debias in Destruction (DiD)<br />- 效果：性能提升，有效去偏|


## 鲁棒学习 (Robust Learning)


### 对抗防御 (Adversarial Defense)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Adversarial Robustness of Discriminative Self-Supervised Learning in Vision|视觉中判别自监督学习的对抗鲁棒性|Ömer Veysel Çağatan, Ömer Faruk Tal, M. Emre Gürsoy|<http://arxiv.org/pdf/2503.06361v1>|- 问题：对抗鲁棒性，自监督学习，视觉表征<br />- 方法：模型评估，对比分析，因素探究<br />- 效果：鲁棒性提升，优势明显|
|🆕 发布|Vision-based 3D Semantic Scene Completion via Capture Dynamic Representations|基于视觉的捕获动态表示的3D语义场景补全|Meng Wang, Fan Wu, Yunchuan Qin, Ruihui Li, Zhuo Tang, Kenli Li|<http://arxiv.org/pdf/2503.06222v1>|- 问题：动态物体，3D语义场景，多视图一致性<br />- 方法：CDScene，动态表示捕获，动态-静态融合<br />- 效果：鲁棒性，准确性|
|📝 更新|ControlNeXt: Powerful and Efficient Control for Image and Video Generation|ControlNeXt：强大的高效图像和视频生成控制|Bohao Peng, Jian Wang, Yuechen Zhang, Wenbo Li, Ming-Chang Yang, Jiaya Jia|<http://arxiv.org/pdf/2408.06070v3>|- 问题：控制生成，计算资源，训练挑战<br />- 方法：ControlNeXt架构，参数减少，Cross Normalization<br />- 效果：高效，鲁棒|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhanced Pediatric Dental Segmentation Using a Custom SegUNet with VGG19 Backbone on Panoramic Radiographs|基于VGG19骨干网络的定制SegUNet在全景X光片上增强儿童牙科分割|Md Ohiduzzaman Ovi, Maliha Sanjana, Fahad Fahad, Mahjabin Runa, Zarin Tasnim Rothy, Tanmoy Sarkar Pias, A. M. Tayeful Islam, Rumman Ahmed Prodhan|<http://arxiv.org/pdf/2503.06321v1>|- 问题：儿童牙科分割，结构变化大，数据少<br />- 方法：SegUNet，VGG19骨干，特征提取<br />- 效果：高精度，高Dice系数，高IOU|
|📝 更新|NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning|NAVER：一种用于视觉基座学习的神经符号组合自动机，具有显式逻辑推理|Zhixi Cai, Fucai Ke, Simindokht Jahangard, Maria Garcia de la Banda, Reza Haffari, Peter J. Stuckey, Hamid Rezatofighi|<http://arxiv.org/pdf/2502.00372v2>|[[代码]](<https://github.com/ControlNet/NAVER>)<br />- 问题：视觉 grounding，推理，语言逻辑<br />- 方法：神经符号组合，概率逻辑推理，有限状态自动机<br />- 效果：SoTA性能，鲁棒性，可解释性|


### 对抗攻击 (Adversarial Attack)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|IDEATOR: Jailbreaking and Benchmarking Large Vision-Language Models Using Themselves|IDEATOR：利用自身进行大型视觉-语言模型的越狱和基准测试|Ruofan Wang, Juncheng Li, Yixu Wang, Bo Wang, Xiaosen Wang, Yan Teng, Yingchun Wang, Xingjun Ma .etc.|<http://arxiv.org/pdf/2411.00827v3>|- 问题：VLM安全性，攻击，数据限制<br />- 方法：IDEATOR，VLM生成，扩散模型<br />- 效果：高攻击成功率，强可迁移性|
|🆕 发布|Exploring Adversarial Transferability between Kolmogorov-arnold Networks|探索Kolmogorov-Arnold网络之间的对抗迁移性|Songping Wang, Xinquan Yue, Yueming Lyu, Caifeng Shan|<http://arxiv.org/pdf/2503.06276v1>|- 问题：KANs对抗鲁棒性，过拟合，迁移性差<br />- 方法：AdvKAN，BDSM，GLI<br />- 效果：攻击能力强，揭示漏洞|
|🆕 发布|Boosting the Local Invariance for Better Adversarial Transferability|提升局部不变性以增强对抗性可迁移性|Bohan Liu, Xiaosen Wang|<http://arxiv.org/pdf/2503.06140v1>|- 问题：对抗迁移性，局部不变性，攻击威胁<br />- 方法：局部不变性提升，LI-Boost技术<br />- 效果：攻击增强，模型泛化|


### 对抗训练 (Adversarial Training)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Video2BEV: Transforming Drone Videos to BEVs for Video-based Geo-localization|视频2BEV：将无人机视频转换为BEV进行基于视频的地理定位|Hao Ju, Shaofei Huang, Si Liu, Zhedong Zheng|<http://arxiv.org/pdf/2411.13610v2>|- 问题：视觉地理定位，视频利用不足，遮挡敏感<br />- 方法：视频转BEV，Gaussian Splatting，扩散模块<br />- 效果：高召回率，低遮挡鲁棒性|


## 模型压缩加速 (Model Compression & Acceleration)


### 知识蒸馏 (Knowledge Distillation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ACAM-KD: Adaptive and Cooperative Attention Masking for Knowledge Distillation|自适应与合作注意力掩码的知识蒸馏|Qizhen Lan, Qing Tian|<http://arxiv.org/pdf/2503.06307v1>|- 问题：知识蒸馏，特征选择，效率挑战<br />- 方法：自适应注意力，特征融合，空间通道掩码<br />- 效果：性能提升，效率优化|
|📝 更新|UVRM: A Scalable 3D Reconstruction Model from Unposed Videos|UVRM：从未摆姿势视频中可扩展的3D重建模型|Shiu-hong Kao, Xiao Li, Jinglu Wang, Yang Li, Chi-Keung Tang, Yu-Wing Tai, Yan Lu|<http://arxiv.org/pdf/2501.09347v2>|- 问题：3D重建，无姿态数据，训练困难<br />- 方法：UVRM模型，Transformer，无姿态训练<br />- 效果：高效重建，无姿态数据|
|🆕 发布|VLScene: Vision-Language Guidance Distillation for Camera-Based 3D Semantic Scene Completion|VLScene：基于摄像头的3D语义场景补全的视觉-语言指导蒸馏|Meng Wang, Huilong Pi, Ruihui Li, Yunchuan Qin, Zhuo Tang, Kenli Li|<http://arxiv.org/pdf/2503.06219v1>|- 问题：3D语义场景理解，几何模糊，语义建模不足<br />- 方法：视觉语言模型，语义先验，几何-语义感知<br />- 效果：mIoU提升，性能领先|
|📝 更新|Multi-perspective Contrastive Logit Distillation|多视角对比对数似然蒸馏|Qi Wang, Jinjia Zhou|<http://arxiv.org/pdf/2411.10693v2>|- 问题：logit distillation，语义信息，KL divergence<br />- 方法：Multi-perspective Contrastive Logit Distillation (MCLD)<br />- 效果：state-of-the-art，训练效率，Vision Transformers|
|🆕 发布|GSV3D: Gaussian Splatting-based Geometric Distillation with Stable Video Diffusion for Single-Image 3D Object Generation|GSV3D：基于高斯喷溅的几何蒸馏与稳定视频扩散的单图像3D物体生成|Ye Tao, Jiawei Zhang, Yahao Shi, Dongqing Zou, Bin Zhou|<http://arxiv.org/pdf/2503.06136v1>|- 问题：3D生成，数据稀缺，几何一致性<br />- 方法：Gaussian Splatting，几何蒸馏，多视图一致性<br />- 效果：高质量，一致性|
|🆕 发布|X2I: Seamless Integration of Multimodal Understanding into Diffusion Transformer via Attention Distillation|X2I：通过注意力蒸馏将多模态理解无缝集成到扩散Transformer中|Jian Ma, Qirong Peng, Xu Guo, Chen Chen, Haonan Lu, Zhenyu Yang|<http://arxiv.org/pdf/2503.06134v1>|[[代码]](<https://github.com/OPPO-Mente-Lab/X2I.>)<br />- 问题：T2I模型，多模态理解，能力转移<br />- 方法：X2I框架，注意力蒸馏，AlignNet<br />- 效果：性能提升，多模态理解，应用广泛|
|🆕 发布|Improving SAM for Camouflaged Object Detection via Dual Stream Adapters|通过双流适配器提升伪装物体检测中SAM的性能|Jiaming Liu, Linghe Kong, Guihai Chen|<http://arxiv.org/pdf/2503.06042v1>|- 问题：SAM，COD，性能不足<br />- 方法：SAM-COD，双流适配器，知识蒸馏<br />- 效果：性能提升，最优结果|
|📝 更新|Preserving Angles Improves Feature Distillation of Foundation Models|保留角度提升基础模型特征蒸馏效果|Evelyn J. Mannix, Liam Hodgkinson, Howard Bondell|<http://arxiv.org/pdf/2411.15239v2>|[[代码]](<https://github.com/emannix/cospress.>)<br />- 问题：模型压缩，特征蒸馏，性能转移<br />- 方法：CosPress，角度保留，特征映射<br />- 效果：泛化性提升，鲁棒性增强|


## 泛化与鲁棒性 (Generalization & Robustness)


### 域泛化 (Domain Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MOB-GCN: A Novel Multiscale Object-Based Graph Neural Network for Hyperspectral Image Classification|MOB-GCN：一种用于高光谱图像分类的新型多尺度基于对象的图神经网络|Tuan-Anh Yang, Truong-Son Hy, Phuong D. Dao|<http://arxiv.org/pdf/2502.16289v2>|[[代码]](<https://github.com/HySonLab/MultiscaleHSI>)<br />- 问题：低精度，噪声，信息遗漏<br />- 方法：多尺度OBIA，MGN架构，动态图层次<br />- 效果：高精度，高效，噪声减少|
|📝 更新|Constraint-Aware Feature Learning for Parametric Point Cloud|标题翻译结果：  参数点云的约束感知特征学习|Xi Cheng, Ruiqi Lei, Di Huang, Zhichao Liao, Fengyuan Piao, Yan Chen, Pingfa Feng, Long Zeng|<http://arxiv.org/pdf/2411.07747v4>|- 问题：CAD形状约束，几何特征，相似外观，不同约束<br />- 方法：约束表示，CstNet，注意力层，Param20K<br />- 效果：分类精度提升，旋转鲁棒性增强|
|🆕 发布|RGB-Phase Speckle: Cross-Scene Stereo 3D Reconstruction via Wrapped Pre-Normalization|RGB-相位散斑：通过包裹预归一化实现跨场景立体3D重建|Kai Yang, Zijian Bai, Yang Xiao, Xinyu Li, Xiaohan Shi|<http://arxiv.org/pdf/2503.06125v1>|- 问题：3D重建，DSM，跨场景，鲁棒性<br />- 方法：RGB-Speckle，相位预归一化，编码解码<br />- 效果：稳定性提升，泛化能力强|


## 可解释性 (Interpretability)


### 归因分析 (Attribution Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VACT: A Video Automatic Causal Testing System and a Benchmark|视频自动因果测试系统及基准|Haotong Yang, Qingyuan Zheng, Yunjian Gao, Yongkun Yang, Yangbo He, Zhouchen Lin, Muhan Zhang|<http://arxiv.org/pdf/2503.06163v1>|- 问题：视频生成模型，事实错误，因果理解，自动化评估<br />- 方法：VACT框架，因果分析，语言模型辅助<br />- 效果：因果理解评估，基准测试，模型可靠性提升|


### 概念解释 (Concept Explanation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Exploring Interpretability for Visual Prompt Tuning with Hierarchical Concepts|探索基于层次概念的视觉提示调优的可解释性|Yubin Wang, Xinyang Jiang, De Cheng, Xiangqian Zhao, Zilong Wang, Dongsheng Li, Cairong Zhao|<http://arxiv.org/pdf/2503.06084v1>|- 问题：可解释性，视觉提示，AI可靠性<br />- 方法：IVPT框架，层次概念原型，区域特征聚合<br />- 效果：可解释性提升，性能优越|


## 医学影像分析 (Medical Image Analysis)


### 医学分割 (Medical Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|U-net based prediction of cerebrospinal fluid distribution and ventricular reflux grading|基于U-net的脑脊液分布预测和脑室反流分级|Melanie Rieff, Fabian Holzberger, Oksana Lapina, Geir Ringstad, Lars Magnus Valnes, Bogna Warsza, Kent-Andre Mardal, Per Kristian Eide .etc.|<http://arxiv.org/pdf/2410.04460v2>|- 问题：脑脊液分布预测，脑室反流分级<br />- 方法：U-net模型，深度学习，MRI数据分析<br />- 效果：预测准确，效率提升|
|📝 更新|VesselSAM: Leveraging SAM for Aortic Vessel Segmentation with LoRA and Atrous Attention|血管SAM：利用LoRA和扩张注意力机制通过SAM进行主动脉血管分割|Adnan Iltaf, Rayan Merghani Ahmed, Zhenxi Zhang, Bin Li, Shoujun Zhou|<http://arxiv.org/pdf/2502.18185v2>|[[代码]](<https://github.com/Adnan-CAS/AtrousLora.>)<br />- 问题：血管分割，噪声，边缘结构，计算效率<br />- 方法：VesselSAM，AtrousLoRA，LoRA，Atrous Attention<br />- 效果：高精度，低计算量|
|🆕 发布|End-to-End Action Segmentation Transformer|端到端动作分割Transformer|Tieqiao Wang, Sinisa Todorovic|<http://arxiv.org/pdf/2503.06316v1>|- 问题：预计算特征，缺乏建模，动作分割<br />- 方法：EAST，高效适配器，检测框架，数据增强<br />- 效果：SOTA性能，GTEA等基准|
|📝 更新|Hierarchical Uncertainty Estimation for Learning-based Registration in Neuroimaging|基于神经影像学习的层次化不确定性估计|Xiaoling Hu, Karthik Gopinath, Peirong Liu, Malte Hoffmann, Koen Van Leemput, Oula Puonti, Juan Eugenio Iglesias|<http://arxiv.org/pdf/2410.09299v2>|[[代码]](<https://github.com/HuXiaoling/Regre4Regis.>)<br />- 问题：深度学习，图像配准，不确定性估计，神经影像<br />- 方法：层次不确定性传播，高斯分布建模，蒙特卡洛采样<br />- 效果：配准精度提升，不确定性感知优化|
|🆕 发布|Segment Anything, Even Occluded|任意分割，即使遮挡|Wei-En Tai, Yu-Lin Shih, Cheng Sun, Yu-Chiang Frank Wang, Hwann-Tzong Chen|<http://arxiv.org/pdf/2503.06261v1>|- 问题：模态分割，灵活性，预训练检测器<br />- 方法：SAMEO框架，Amodal-LVIS数据集<br />- 效果：零样本性能，泛化能力|
|🆕 发布|Dynamically evolving segment anything model with continuous learning for medical image segmentation|动态演化的持续学习医学图像分割“任何东西”模型|Zhaori Liu, Mengyang Li, Hu Han, Enli Zhang, Shiguang Shan, Zhiming Zhao|<http://arxiv.org/pdf/2503.06236v1>|- 问题：医疗图像分割，场景多样性，动态演化<br />- 方法：EvoSAM模型，连续学习，知识积累<br />- 效果：分割精度提升，遗忘缓解|
|🆕 发布|Attention on the Wires (AttWire): A Foundation Model for Detecting Devices and Catheters in X-ray Fluoroscopic Images|注意力在导线上（AttWire）：一种用于检测X射线透视图像中设备和导管的基座模型|YingLiang Ma, Sandra Howell, Aldo Rinaldi, Tarv Dhanjal, Kawal S. Rhode|<http://arxiv.org/pdf/2503.06190v1>|[[代码]](<https://github.com/YingLiangMa/AttWire.>)<br />- 问题：设备检测，X光图像，实时性<br />- 方法：注意力机制，CNN，多尺度滤波<br />- 效果：高精度，实时检测|
|📝 更新|Test-Time Optimization for Domain Adaptive Open Vocabulary Segmentation|域自适应开放词汇分割的测试时优化|Ulindu De Silva, Didula Samaraweera, Sasini Wanigathunga, Kavindu Kariyawasam, Kanchana Ranasinghe, Muzammal Naseer, Ranga Rodrigo|<http://arxiv.org/pdf/2501.04696v2>|- 问题：开放词汇分割，领域适应性，测试时优化<br />- 方法：自监督目标，模型参数对齐，多模态嵌入<br />- 效果：性能提升，新SOTA|
|🆕 发布|Pathology-Guided AI System for Accurate Segmentation and Diagnosis of Cervical Spondylosis|病理引导的人工智能系统用于颈椎病的准确分割和诊断|Qi Zhang, Xiuyuan Chen, Ziyi He, Lianming Wu, Kun Wang, Jianqi Sun, Hongxing Shen|<http://arxiv.org/pdf/2503.06114v1>|- 问题：颈椎病诊断，MRI，人工解读，效率低，易出错<br />- 方法：病理引导，分割模型，专家诊断框架<br />- 效果：高精度，高准确率，超越现有方法|
|🆕 发布|ZO-DARTS++: An Efficient and Size-Variable Zeroth-Order Neural Architecture Search Algorithm|ZO-DARTS++：一种高效且可变大小的零阶神经架构搜索算法|Lunchen Xie, Eugenio Lomurno, Matteo Gambella, Danilo Ardagna, Manual Roveri, Matteo Matteucci, Qingjiang Shi|<http://arxiv.org/pdf/2503.06092v1>|- 问题：效率，操作选择，适应性，资源限制<br />- 方法：零阶近似，sparsemax，温度退火，大小可变搜索<br />- 效果：性能提升，时间缩短，参数减少|
|🆕 发布|Patch-Depth Fusion: Dichotomous Image Segmentation via Fine-Grained Patch Strategy and Depth Integrity-Prior|补丁-深度融合：通过细粒度补丁策略和深度完整性先验的二分图像分割|Xianjie Liu, Keren Fu, Qijun Zhao|<http://arxiv.org/pdf/2503.06100v1>|[[代码]](<https://github.com/Tennine2077/PDFNet.>)<br />- 问题：图像分割，细节建模，深度完整性<br />- 方法：Patch-Depth融合，多模态输入，深度完整性损失<br />- 效果：精度高，参数少|
|🆕 发布|GrInAdapt: Scaling Retinal Vessel Structural Map Segmentation Through Grounding, Integrating and Adapting Multi-device, Multi-site, and Multi-modal Fundus Domains|GrInAdapt：通过接地、整合和适应多设备、多地点和多模态眼底领域的视网膜血管结构图分割扩展规模|Zixuan Liu, Aaron Honjaya, Yuekai Xu, Yi Zhang, Hefu Pan, Xin Wang, Linda G Shapiro, Sheng Wang .etc.|<http://arxiv.org/pdf/2503.05991v1>|- 问题：深度学习，血管分割，模态特定，分布偏移<br />- 方法：GrInAdapt，多视图，域适应，多模态融合<br />- 效果：高精度，鲁棒性，临床决策|


### 影像重建 (Image Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|StreamGS: Online Generalizable Gaussian Splatting Reconstruction for Unposed Image Streams|StreamGS：面向未摆姿势图像流的在线可泛化高斯分层重建|Yang LI, Jinglu Wang, Lei Chu, Xiao Li, Shiu-hong Kao, Ying-Cong Chen, Yan Lu|<http://arxiv.org/pdf/2503.06235v1>|- 问题：实时3D重建，泛化能力，冗余减少<br />- 方法：StreamGS，内容自适应细化，特征聚合<br />- 效果：速度提升，泛化性好|
|🆕 发布|SRM-Hair: Single Image Head Mesh Reconstruction via 3D Morphable Hair|SRM-Hair：基于3D可变形头发的单图像头部网格重建|Zidu Wang, Jiankuo Zhao, Miao Xu, Xiangyu Zhu, Zhen Lei|<http://arxiv.org/pdf/2503.06154v1>|[[代码]](<https://github.com/wang-zidu/SRM-Hair>)<br />- 问题：3DMM扩展，语义一致性，头发建模<br />- 方法：SRM-Hair，语义一致射线建模，系数控制<br />- 效果：高保真，独立头发网格，性能领先|
|🆕 发布|A Label-Free High-Precision Residual Moveout Picking Method for Travel Time Tomography based on Deep Learning|基于深度学习的无标签高精度剩余时差拾取方法在旅行时间层析成像中的应用|Hongtao Wang, Jiandong Liang, Lei Wang, Shuaizhe Liang, Jinping Zhu, Chunxia Zhang, Jiangshe Zhang|<http://arxiv.org/pdf/2503.06038v1>|- 问题：RMO拟合精度低，迭代效率低，训练样本稀缺，后处理复杂<br />- 方法：深度学习，级联拾取，趋势回归，数据合成<br />- 效果：拾取密度高，精度高|


## 智能驾驶 (Intelligent Driving)


### 环境感知 (Environment Perception)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|StreamMind: Unlocking Full Frame Rate Streaming Video Dialogue through Event-Gated Cognition|StreamMind：通过事件门控认知解锁全帧率流媒体视频对话|Xin Ding, Hao Wu, Yifan Yang, Shiqi Jiang, Donglin Bai, Zhibo Chen, Ting Cao|<http://arxiv.org/pdf/2503.06220v1>|- 问题：视频对话，帧率限制，计算成本高<br />- 方法：事件门控认知，EPFE，感知-认知交织<br />- 效果：超高速处理，实时响应，性能优越|
|📝 更新|Dual Conditioned Motion Diffusion for Pose-Based Video Anomaly Detection|基于姿态的视频异常检测的双条件运动扩散|Hongsong Wang, Andi Xu, Pinle Ding, Jie Gui|<http://arxiv.org/pdf/2412.17210v2>|- 问题：视频异常检测，姿态识别，运动扩散<br />- 方法：DCMD框架，运动变换器，UAD正则化<br />- 效果：性能优越，泛化能力强|


### 轨迹预测 (Trajectory Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TransParking: A Dual-Decoder Transformer Framework with Soft Localization for End-to-End Automatic Parking|TransParking：一种具有软定位的端到端自动泊车双解码器Transformer框架|Hangyu Du, Chee-Meng Chew|<http://arxiv.org/pdf/2503.06071v1>|- 问题：自动泊车，复杂环境，轨迹预测<br />- 方法：Transformer，双解码器，软定位<br />- 效果：误差降低50%，端到端|


## 工业视觉 (Industrial Vision)


### 缺陷检测 (Defect Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|STAR: A Foundation Model-driven Framework for Robust Task Planning and Failure Recovery in Robotic Systems|STAR：基于基础模型的机器人系统鲁棒任务规划和故障恢复框架|Md Sadman Sakib, Yu Sun|<http://arxiv.org/pdf/2503.06060v1>|- 问题：动态环境，任务执行，适应性，故障恢复<br />- 方法：STAR框架，FMs与KGs结合，知识图谱嵌入<br />- 效果：高精度，高成功率|


## 其他 (Others)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Hierarchical Document Parsing via Large Margin Feature Matching and Heuristics|基于大间隔特征匹配和启发式算法的层次文档解析|Duong Anh Kiet|<http://arxiv.org/pdf/2502.07442v2>|[[代码]](<https://github.com/ffyyytt/VRUID-AAAI-DAKiet>)<br />- 问题：文档结构解析，特征匹配，层次关系<br />- 方法：大间隔损失，启发式规则，贪婪算法<br />- 效果：高精度，计算效率|

