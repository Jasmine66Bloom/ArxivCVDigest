## [UPDATED!] **2025-03-11** (Update Time)


## 表示学习 (Representation Learning)


### 视觉Transformer (Vision Transformers)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|KAN-Mixers: a new deep learning architecture for image classification|KAN-Mixers：一种新的图像分类深度学习架构|Jorge Luiz dos Santos Canuto, Linnyer Beatrys Ruiz Aylon, Rodrigo Clemente Thom de Souza|<http://arxiv.org/pdf/2503.08939v1>|- 问题：CNN，ViT，MLP-Mixer，特征提取<br />- 方法：KAN，KAN-Mixers，深度学习架构<br />- 效果：准确率提升，Fashion-MNIST，CIFAR-10|
|🆕 发布|Vision Transformer for Intracranial Hemorrhage Classification in CT Scans Using an Entropy-Aware Fuzzy Integral Strategy for Adaptive Scan-Level Decision Fusion|基于熵感知模糊积分策略的CT扫描颅内出血分类的视觉Transformer|Mehdi Hosseini Chagahi, Niloufar Delfan, Behzad Moshiri, Md. Jalil Piran, Jaber Hatam Parikhan|<http://arxiv.org/pdf/2503.08609v1>|- 问题：颅内出血分类，CT扫描，临床决策<br />- 方法：PVT模型，SHAP特征选择，熵感知融合<br />- 效果：准确率提升，鲁棒性增强|
|🆕 发布|ChromaFormer: A Scalable and Accurate Transformer Architecture for Land Cover Classification|色度former：一种用于土地覆盖分类的可扩展且准确的Transformer架构|Mingshi Li, Dusan Grujicic, Ben Somers, Stien Heremans, Steven De Saeger, Matthew B. Blaschko|<http://arxiv.org/pdf/2503.08534v1>|- 问题：多光谱图像分类，模型规模限制，精度不足<br />- 方法：ChromaFormer，多光谱注意力，大规模模型<br />- 效果：精度提升，性能提升|
|📝 更新|Unified CNNs and transformers underlying learning mechanism reveals multi-head attention modus vivendi|统一CNN和Transformer的底层学习机制揭示多头注意力共存模式|Ella Koresh, Ronit D. Gross, Yuval Meir, Yarden Tzach, Tal Halevi, Ido Kanter|<http://arxiv.org/pdf/2501.12900v2>|- 问题：CNNs, ViTs, 学习机制<br />- 方法：统一学习机制，SNP测量，ANDC剪枝<br />- 效果：MHA机制，网络行为揭示|
|🆕 发布|EnergyFormer: Energy Attention with Fourier Embedding for Hyperspectral Image Classification|能量前体：基于傅里叶嵌入的超光谱图像分类中的能量注意力|Saad Sohail, Muhammad Usama, Usman Ghous, Manuel Mazzara, Salvatore Distefano, Muhammad Ahmad|<http://arxiv.org/pdf/2503.08239v1>|- 问题：高光谱图像分类，特征提取，分类挑战<br />- 方法：多头能量注意力，傅里叶位置嵌入，增强卷积块注意力模块<br />- 效果：准确率提升，超越现有模型|
|📝 更新|Breaking the Low-Rank Dilemma of Linear Attention|打破线性注意力低秩困境|Qihang Fan, Huaibo Huang, Ran He|<http://arxiv.org/pdf/2411.07635v5>|[[代码]](<https://github.com/qhfan/RALA.>)<br />- 问题：线性注意力，性能退化，低秩困境<br />- 方法：Rank-Augmented Linear Attention (RALA)，RAVLT<br />- 效果：高精度，低参数，低计算量|


### 预训练模型 (Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Do computer vision foundation models learn the low-level characteristics of the human visual system?|标题翻译结果：  计算机视觉基础模型是否学习了人类视觉系统的低级特征？|Yancheng Cai, Fei Yin, Dounia Hammou, Rafal Mantiuk|<http://arxiv.org/pdf/2502.20256v2>|- 问题：基础模型，低级特征，人眼视觉<br />- 方法：测试协议，图像编码器评估<br />- 效果：部分模型相似，对比掩码表现佳|
|🆕 发布|Seeing What's Not There: Spurious Correlation in Multimodal LLMs|看到不存在的：多模态大型语言模型中的虚假相关性|Parsa Hosseini, Sumit Nawathe, Mazda Moayeri, Sriram Balasubramanian, Soheil Feizi|<http://arxiv.org/pdf/2503.08884v1>|- 问题：MLLMs，虚假相关性，视觉模型<br />- 方法：SpurLens，GPT-4，开放集检测器<br />- 效果：识别虚假视觉线索，降低准确性，放大幻觉|
|🆕 发布|TT-GaussOcc: Test-Time Compute for Self-Supervised Occupancy Prediction via Spatio-Temporal Gaussian Splatting|TT-GaussOcc：基于时空高斯喷溅的自监督占用预测的测试时计算|Fengyi Zhang, Huitong Yang, Zheng Zhang, Zi Huang, Yadan Luo|<http://arxiv.org/pdf/2503.08485v1>|- 问题：3D占用预测，训练成本高，适应性差<br />- 方法：TT-GaussOcc，时空高斯分层，动态优化<br />- 效果：mIoU提升46%，支持高分辨率，推理速度2.6 FPS|
|🆕 发布|CFNet: Optimizing Remote Sensing Change Detection through Content-Aware Enhancement|CFNet：通过内容感知增强优化遥感变化检测|Fan Wu, Sijun Dong, Xiaoliang Meng|<http://arxiv.org/pdf/2503.08505v1>|[[代码]](<https://github.com/wifiBlack/CFNet.>)<br />- 问题：遥感图像变化检测，风格差异，模型影响<br />- 方法：内容感知增强，EfficientNet-B5，内容优先约束<br />- 效果：F1提升，IoU提升|


## 生成建模 (Generative Modeling)


### 扩散模型 (Diffusion Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OmniPaint: Mastering Object-Oriented Editing via Disentangled Insertion-Removal Inpainting|全画：通过解耦插入-删除修复实现面向对象编辑的精通|Yongsheng Yu, Ziyun Zeng, Haitian Zheng, Jiebo Luo|<http://arxiv.org/pdf/2503.08677v2>|[[代码]](<https://yeates.github.io/OmniPaint-Page>)<br />- 问题：对象编辑，物理效果，训练数据<br />- 方法：统一框架，渐进式训练，CycleFlow<br />- 效果：精确编辑，场景保留|
|🆕 发布|Layton: Latent Consistency Tokenizer for 1024-pixel Image Reconstruction and Generation by 256 Tokens|Layton：基于256个标记的1024像素图像重建和生成的潜在一致性标记器|Qingsong Xie, Zhao Zhang, Zhe Huang, Yanhao Zhang, Haonan Lu, Zhenyu Yang|<http://arxiv.org/pdf/2503.08377v2>|[[代码]](<https://github.com/OPPO-Mente-Lab/Layton>)<br />- 问题：效率与保真度平衡，高分辨率图像重建<br />- 方法：Layton，Transformer编码器，量化代码簿，潜在一致性解码器<br />- 效果：高保真重建，256 token压缩|
|📝 更新|DAViD: Modeling Dynamic Affordance of 3D Objects using Pre-trained Video Diffusion Models|DAViD：利用预训练视频扩散模型建模3D物体的动态适应性|Hyeonwoo Kim, Sangwon Beak, Hanbyul Joo|<http://arxiv.org/pdf/2501.08333v2>|- 问题：动态交互，数据稀缺，3D对象<br />- 方法：视频扩散模型，合成数据，LoRA模块<br />- 效果：模型性能提升，交互运动合成|
|📝 更新|Efficient Fine-Tuning and Concept Suppression for Pruned Diffusion Models|高效剪枝扩散模型的微调和概念抑制|Reza Shirkavand, Peiran Yu, Shangqian Gao, Gowthami Somepalli, Tom Goldstein, Heng Huang|<http://arxiv.org/pdf/2412.15341v2>|- 问题：模型复杂度，计算负担，内容生成问题<br />- 方法：bilevel优化，模型剪枝，知识蒸馏<br />- 效果：效率提升，内容抑制|
|🆕 发布|"Principal Components" Enable A New Language of Images|主成分开启图像的新语言|Xin Wen, Bingchen Zhao, Ismail Elezi, Jiankang Deng, Xiaojuan Qi|<http://arxiv.org/pdf/2503.08685v1>|- 问题：视觉token化，结构忽视，可解释性差<br />- 方法：PCA-like结构，因果token序列，扩散解码<br />- 效果：重建性能，可解释性，模型性能|
|🆕 发布|MEAT: Multiview Diffusion Model for Human Generation on Megapixels with Mesh Attention|多视角扩散模型在百万像素级别上的人脸生成：网格注意力|Yuhan Wang, Fangzhou Hong, Shuai Yang, Liming Jiang, Wayne Wu, Chen Change Loy|<http://arxiv.org/pdf/2503.08664v1>|- 问题：多视角扩散模型，分辨率，人体数据<br />- 方法：网格注意力，关键点条件，多视角运动视频<br />- 效果：高分辨率，一致性，性能提升|
|🆕 发布|REGEN: Learning Compact Video Embedding with (Re-)Generative Decoder|REGEN：利用（再）生成解码器学习紧凑的视频嵌入|Yitian Zhang, Long Mai, Aniruddha Mahapatra, David Bourgin, Yicong Hong, Jonah Casebeer, Feng Liu, Yun Fu|<http://arxiv.org/pdf/2503.08665v1>|- 问题：视频嵌入，压缩比，生成模型<br />- 方法：生成解码器，扩散变换器，条件模块<br />- 效果：高压缩比，效率提升|
|📝 更新|TED-VITON: Transformer-Empowered Diffusion Models for Virtual Try-On|TED-VITON：基于Transformer的扩散模型在虚拟试穿中的应用|Zhenchen Wan, Yanwu Xu, Zhaoqing Wang, Feng Liu, Tongliang Liu, Mingming Gong|<http://arxiv.org/pdf/2411.17017v3>|[[代码]](<https://zhenchenwan.github.io/TED-VITON>)<br />- 问题：VTO模型过时，文本渲染挑战，细节保留困难<br />- 方法：GS Adapter，Text Preservation Loss，LLM优化<br />- 效果：SOTA性能，新基准|
|🆕 发布|MF-VITON: High-Fidelity Mask-Free Virtual Try-On with Minimal Input|MF-VITON：最小输入下的高保真无遮挡虚拟试穿|Zhenchen Wan, Yanwu xu, Dongting Hu, Weilun Cheng, Tianxi Chen, Zhaoqing Wang, Feng Liu, Tongliang Liu .etc.|<http://arxiv.org/pdf/2503.08650v1>|[[代码]](<https://zhenchenwan.github.io/MF-VITON>)<br />- 问题：VITON，依赖面具，输入复杂<br />- 方法：无面具VITON，两阶段流程，数据增强<br />- 效果：SOTA性能，超越现有方法|
|🆕 发布|Rethinking Diffusion Model in High Dimension|重新思考高维空间中的扩散模型|Zhenxin Zheng, Zhenjie Zheng|<http://arxiv.org/pdf/2503.08643v1>|- 问题：高维数据，扩散模型，统计性质<br />- 方法：目标函数分析，统一框架，高效推理<br />- 效果：性能提升，效率提高|
|📝 更新|RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth Diffusion|RealmDreamer：基于文本驱动的3D场景生成与修复及深度扩散|Jaidev Shriram, Alex Trevithick, Lingjie Liu, Ravi Ramamoorthi|<http://arxiv.org/pdf/2404.07199v2>|- 问题：文本描述生成3D场景，3D场景生成<br />- 方法：3D高斯分层，2D修复扩散模型，深度扩散模型<br />- 效果：高质量，多样化，单图生成|
|🆕 发布|Tuning-Free Multi-Event Long Video Generation via Synchronized Coupled Sampling|无调参多事件长视频生成通过同步耦合采样|Subin Kim, Seoung Wug Oh, Jui-Hsien Wang, Joon-Young Lee, Jinwoo Shin|<http://arxiv.org/pdf/2503.08605v1>|- 问题：长视频生成，内容漂移，语义连贯性<br />- 方法：同步耦合采样，反向采样，优化采样<br />- 效果：平滑过渡，长距离一致性|
|📝 更新|Curriculum Direct Preference Optimization for Diffusion and Consistency Models|课程直接偏好优化：扩散和一致性模型|Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, Nicu Sebe, Mubarak Shah|<http://arxiv.org/pdf/2405.13637v3>|[[代码]](<https://github.com/CroitoruAlin/Curriculum-DPO.>)<br />- 问题：DPO，RLHF，文本到图像生成<br />- 方法：课程学习，排名差异，难度分层<br />- 效果：文本对齐，美学，人类偏好|
|🆕 发布|Modular Customization of Diffusion Models via Blockwise-Parameterized Low-Rank Adaptation|模块化定制通过块状参数化低秩自适应的扩散模型|Mingkang Zhu, Xi Chen, Zhongdao Wang, Bei Yu, Hengshuang Zhao, Jiaya Jia|<http://arxiv.org/pdf/2503.08575v1>|- 问题：模块化定制，扩散模型，概念融合，身份保留<br />- 方法：BlockLoRA，随机输出擦除，Blockwise LoRA<br />- 效果：多概念融合，高保真|
|📝 更新|GraPE: A Generate-Plan-Edit Framework for Compositional T2I Synthesis|GraPE：一种用于组合式T2I合成的生成-规划-编辑框架|Ashish Goswami, Satyam Kumar Modi, Santhosh Rishi Deshineni, Harman Singh, Prathosh A. P, Parag Singla|<http://arxiv.org/pdf/2412.06089v2>|[[代码]](<https://dair-iitd.github.io/GraPE>)<br />- 问题：复杂文本指令，生成错误，属性建模<br />- 方法：生成-计划-编辑框架，多模态LLM，编辑模型<br />- 效果：性能提升，模型泛化|
|🆕 发布|Posterior-Mean Denoising Diffusion Model for Realistic PET Image Reconstruction|后验均值去噪扩散模型在真实PET图像重建中的应用|Yiran Sun, Osama Mawlawi|<http://arxiv.org/pdf/2503.08546v1>|- 问题：PET图像重建，细节丢失，过度平滑，伪影<br />- 方法：PMDM-PET，后验均值，扩散模型，感知-失真平衡<br />- 效果：真实感，最小失真，最优感知质量|
|🆕 发布|High-Quality 3D Head Reconstruction from Any Single Portrait Image|从任意单张肖像图像中重建高质量3D人头|Jianfu Zhang, yujie Gao, Jiahui Zhan, Wentao Wang, Yiyi Zhang, Haohua Zhao, Liqing Zhang|<http://arxiv.org/pdf/2503.08516v1>|- 问题：3D头像重建，信息缺失，视角多样<br />- 方法：多视角扩散，身份表情信息，高保真数据集<br />- 效果：高质量，一致性，鲁棒性|
|🆕 发布|SAS: Segment Any 3D Scene with Integrated 2D Priors|SAS：基于集成2D先验的任意3D场景分割|Zhuoyuan Li, Jiahao Lu, Jiacheng Deng, Hanzhi Chang, Lifan Wu, Yanzhe Liang, Tianzhu Zhang|<http://arxiv.org/pdf/2503.08512v1>|- 问题：3D场景分割，开放词汇，动态场景<br />- 方法：模型对齐，能力构建，特征蒸馏<br />- 效果：性能提升，泛化能力强|
|📝 更新|PointDiffuse: A Dual-Conditional Diffusion Model for Enhanced Point Cloud Semantic Segmentation|点云语义分割的二元条件扩散模型：PointDiffuse|Yong He, Hongshan Yu, Mingtao Feng, Tongjia Chen, Zechuan Li, Anwaar Ulhaq, Saeed Anwar, Ajmal Saeed Mian|<http://arxiv.org/pdf/2503.06094v2>|- 问题：点云语义分割，效率低，细节丢失<br />- 方法：扩散模型，噪声标签嵌入，点频率变换器<br />- 效果：mIoU提升，性能优越|
|📝 更新|Structure Preserving Diffusion Models|结构保持扩散模型|Haoye Lu, Spencer Szabados, Yaoliang Yu|<http://arxiv.org/pdf/2402.19369v2>|- 问题：结构保持，扩散模型，对称性，必要条件<br />- 方法：几何结构框架，桥模型，对称性保持<br />- 效果：对称分布学习，样本质量高|
|🆕 发布|NullFace: Training-Free Localized Face Anonymization|无脸：无需训练的局部人脸匿名化|Han-Wei Kung, Tuomas Varanka, Terence Sim, Nicu Sebe|<http://arxiv.org/pdf/2503.08478v1>|[[代码]](<https://github.com/hanweikung/nullface>)<br />- 问题：隐私保护，图像实用，人脸匿名<br />- 方法：预训练模型，无监督，局部匿名<br />- 效果：匿名度高，属性保留，图像质量好|
|🆕 发布|Using Powerful Prior Knowledge of Diffusion Model in Deep Unfolding Networks for Image Compressive Sensing|利用扩散模型在深度展开网络中进行图像压缩感知的强大先验知识|Chen Liao, Yan Shen, Dan Li, Zhongli Wang|<http://arxiv.org/pdf/2503.08429v1>|[[代码]](<https://github.com/FengodChen/DMP-DUN-CVPR2025.>)<br />- 问题：图像压缩感知，重建质量，迭代优化<br />- 方法：扩散模型，深度展开网络，迭代优化算法<br />- 效果：高质重建，效率提升|
|📝 更新|OmniEraser: Remove Objects and Their Effects in Images with Paired Video-Frame Data|全息擦除器：利用配对视频帧数据在图像中移除物体及其影响|Runpu Wei, Zijin Yin, Shuo Zhang, Lanxiang Zhou, Xueyi Wang, Chao Ban, Tianwei Cao, Hao Sun .etc.|<http://arxiv.org/pdf/2501.07397v3>|- 问题：图像去噪，阴影反射处理，形状伪影，内容生成<br />- 方法：视频数据集，背景引导，扩散过程<br />- 效果：性能提升，泛化能力强|
|🆕 发布|Bokeh Diffusion: Defocus Blur Control in Text-to-Image Diffusion Models|波库姆扩散：文本到图像扩散模型中的失焦模糊控制|Armando Fortes, Tianyi Wei, Shangchen Zhou, Xingang Pan|<http://arxiv.org/pdf/2503.08434v1>|- 问题：深度场控制，内容改变，模糊控制<br />- 方法：场景一致，物理参数，混合训练<br />- 效果：灵活控制，真实图像编辑|
|📝 更新|Coherent Video Inpainting Using Optical Flow-Guided Efficient Diffusion|基于光流引导的高效扩散的连贯视频修复|Bohai Gu, Hao Luo, Song Guo, Peiran Dong, Qihua Zhou|<http://arxiv.org/pdf/2412.00857v3>|- 问题：视频修复，时序一致性，计算效率<br />- 方法：光流引导，扩散模型，多尺度适配器<br />- 效果：性能提升，效率优化|
|🆕 发布|AnyMoLe: Any Character Motion In-betweening Leveraging Video Diffusion Models|任意MoLe：利用视频扩散模型进行任意角色运动插值|Kwan Yun, Seokhyeon Hong, Chaelin Kim, Junyong Noh|<http://arxiv.org/pdf/2503.08417v1>|- 问题：数据依赖，运动插帧，特定角色<br />- 方法：视频扩散模型，两阶段生成，ICAdapt，运动模仿优化<br />- 效果：数据减少，平滑过渡，适用广泛|
|📝 更新|DiffDoctor: Diagnosing Image Diffusion Models Before Treating|DiffDoctor：在治疗之前诊断图像扩散模型|Yiyang Wang, Xi Chen, Xiaogang Xu, Sihui Ji, Yu Liu, Yujun Shen, Hengshuang Zhao|<http://arxiv.org/pdf/2501.12382v2>|- 问题：图像扩散模型，伪影，质量评估<br />- 方法：DiffDoctor，两阶段流程，人工标注<br />- 效果：减少伪影，优化模型|
|🆕 发布|PromptLNet: Region-Adaptive Aesthetic Enhancement via Prompt Guidance in Low-Light Enhancement Net|PromptLNet：低光增强网络中的提示引导区域自适应美学提升|Jun Yin, Yangfan He, Miao Zhang, Pengyu Zeng, Tianyi Wang, Shuai Lu, Xueqian Wang|<http://arxiv.org/pdf/2503.08276v1>|- 问题：低光图像增强，美学质量，局部调整<br />- 方法：美学评价模型，提示驱动亮度调整，扩散模型优化<br />- 效果：视觉质量提升，灵活性增强|
|📝 更新|OminiControl: Minimal and Universal Control for Diffusion Transformer|全控奥米：扩散变换器的最小化与通用控制|Zhenxiong Tan, Songhua Liu, Xingyi Yang, Qiaochu Xue, Xinchao Wang|<http://arxiv.org/pdf/2411.15098v5>|- 问题：图像条件，参数开销，控制任务<br />- 方法：最小架构，序列处理，动态位置编码<br />- 效果：性能匹配，数据集Subjects200K|
|🆕 发布|OminiControl2: Efficient Conditioning for Diffusion Transformers|OminiControl2：扩散变换器的有效条件化|Zhenxiong Tan, Qiaochu Xue, Xingyi Yang, Songhua Liu, Xinchao Wang|<http://arxiv.org/pdf/2503.08280v1>|- 问题：控制信号生成，计算效率低<br />- 方法：动态压缩，特征重用，多条件生成<br />- 效果：效率提升，速度加快|
|🆕 发布|DexGrasp Anything: Towards Universal Robotic Dexterous Grasping with Physics Awareness|DexGrasp Anything：迈向具有物理感知的通用机器人灵巧抓取|Yiming Zhong, Qi Jiang, Jingyi Yu, Yuexin Ma|<http://arxiv.org/pdf/2503.08257v1>|- 问题：机器人抓取，物理约束，数据多样性<br />- 方法：扩散模型，物理感知，数据集<br />- 效果：性能领先，数据丰富|
|🆕 发布|Aligning Text to Image in Diffusion Models is Easier Than You Think|《在扩散模型中将文本对齐到图像比您想象的要简单》|Jaa-Yeon Lee, Byunghee Cha, Jeongsol Kim, Jong Chul Ye|<http://arxiv.org/pdf/2503.08250v1>|- 问题：文本图像对齐，表示对齐，残差误对齐<br />- 方法：对比学习，SoftREPA，软文本标记<br />- 效果：语义一致性增强，互信息增加|
|🆕 发布|SARA: Structural and Adversarial Representation Alignment for Training-efficient Diffusion Models|SARA：用于训练高效扩散模型的基于结构和对抗表示对齐|Hesen Chen, Junyan Wang, Zhiyu Tan, Hao Li|<http://arxiv.org/pdf/2503.08253v1>|- 问题：训练效率，生成质量，结构关系，全局分布<br />- 方法：SARA，多级约束，自相似矩阵，对抗对齐<br />- 效果：FID 1.36，收敛速度快|
|📝 更新|AnomalyPainter: Vision-Language-Diffusion Synergy for Zero-Shot Realistic and Diverse Industrial Anomaly Synthesis|异常画家：视觉-语言-扩散协同实现零样本真实且多样化的工业异常合成|Zhangyu Lai, Yilin Lu, Xinyang Li, Jianghang Lin, Yansong Qu, Liujuan Cao, Ming Li, Rongrong Ji|<http://arxiv.org/pdf/2503.07253v2>|- 问题：合成真实多样，零样本，工业异常<br />- 方法：VLLM，LDM，Tex-9K，ControlNet，Texture-Aware Latent Init<br />- 效果：真实，多样，下游性能|
|🆕 发布|TSCnet: A Text-driven Semantic-level Controllable Framework for Customized Low-Light Image Enhancement|TSCnet：一种基于文本驱动的语义级可控框架，用于定制低光图像增强|Miao Zhang, Jun Yin, Pengyu Zeng, Yiqing Shen, Shuai Lu, Xueqian Wang|<http://arxiv.org/pdf/2503.08168v1>|- 问题：低光图像增强，个性化，映射不灵活<br />- 方法：LLM，RRS，TBC，ACC，条件扩散模型<br />- 效果：可见性提升，色彩平衡，细节增强|
|📝 更新|Single Image Rolling Shutter Removal with Diffusion Models|单图像滚动快门消除与扩散模型|Zhanglei Yang, Haipeng Li, Mingbo Hong, Chen-Lin Zhang, Jiajun Li, Shuaicheng Liu|<http://arxiv.org/pdf/2407.02906v2>|- 问题：单帧滚动快门，图像质量，运动校正<br />- 方法：扩散模型，图像到运动，patch-attention模块<br />- 效果：超越，潜力，数据集|
|🆕 发布|Multimodal Generation of Animatable 3D Human Models with AvatarForge|多模态生成可动3D人模：AvatarForge|Xinhang Liu, Yu-Wing Tai, Chi-Keung Tang|<http://arxiv.org/pdf/2503.08165v1>|- 问题：3D人像生成，动画，数据稀缺<br />- 方法：LLM推理，3D生成器，迭代设计<br />- 效果：高精度，可定制|
|📝 更新|Regularization by Texts for Latent Diffusion Inverse Solvers|文本正则化在潜在扩散逆求解器中的应用|Jeongsol Kim, Geon Yeong Park, Hyungjin Chung, Jong Chul Ye|<http://arxiv.org/pdf/2311.15658v3>|- 问题：逆问题求解，测量模糊，系统对称性<br />- 方法：文本正则化，逆扩散采样，自适应否定<br />- 效果：降低模糊，提升精度效率|
|📝 更新|GeneMAN: Generalizable Single-Image 3D Human Reconstruction from Multi-Source Human Data|基因人：从多源人体数据中实现可泛化的单图像3D人体重建|Wentao Wang, Hang Ye, Fangzhou Hong, Xue Yang, Jianfu Zhang, Yizhou Wang, Ziwei Liu, Liang Pan|<http://arxiv.org/pdf/2411.18624v2>|- 问题：单图3D重建，比例变化，姿态模糊，纹理不一致，数据稀缺<br />- 方法：文本到图像扩散模型，几何初始化与雕塑，多空间纹理细化<br />- 效果：高保真，泛化能力强|
|🆕 发布|FlowDPS: Flow-Driven Posterior Sampling for Inverse Problems|FlowDPS：基于流的逆问题后验采样|Jeongsol Kim, Bryan Sangwoo Kim, Jong Chul Ye|<http://arxiv.org/pdf/2503.08136v1>|- 问题：逆问题求解，扩散模型，流模型<br />- 方法：后验采样，流驱动，Tweedie公式<br />- 效果：性能提升，无需额外训练|
|🆕 发布|MGHanD: Multi-modal Guidance for authentic Hand Diffusion|MGHanD：多模态引导的真实手部扩散|Taehyeon Eum, Jieun Choi, Tae-Kyun Kim|<http://arxiv.org/pdf/2503.08133v1>|- 问题：手部图像生成，手指错误，结构变形<br />- 方法：多模态引导，视觉与文本指导，LoRA适配器<br />- 效果：高质量，无特定条件，用户评价高|
|📝 更新|Attentive Eraser: Unleashing Diffusion Model's Object Removal Potential via Self-Attention Redirection Guidance|注意擦除器：通过自注意力重定向引导释放扩散模型的对象去除潜力|Wenhao Sun, Benlei Cui, Xue-Mei Dong, Jingqun Tang, Yi Liu|<http://arxiv.org/pdf/2412.12974v4>|[[代码]](<https://github.com/Anonym0u3/AttentiveEraser.>)<br />- 问题：随机伪影，重绘困难，稳定性差<br />- 方法：自注意力重定向，ASS机制，SARG引导<br />- 效果：效果优于训练方法，可扩展性强|
|🆕 发布|Uni$\textbf{F}^2$ace: Fine-grained Face Understanding and Generation with Unified Multimodal Models|统一多模态模型进行细粒度人脸理解和生成：UniFace|Junzhe Li, Xuerui Qiu, Linrui Xu, Liya Guo, Delin Qu, Tingting Long, Chun Fan, Ming Li|<http://arxiv.org/pdf/2503.08120v1>|- 问题：粗粒度面部属性理解，生成能力不足<br />- 方法：统一多模态模型，扩散技术，混合专家架构<br />- 效果：性能优越，理解与生成任务|
|🆕 发布|MegaSR: Mining Customized Semantics and Expressive Guidance for Image Super-Resolution|MegaSR：挖掘定制语义和表达性指导进行图像超分辨率|Xinrui Li, Jianlong Wu, Xinchuan Huang, Chong Chen, Weili Guan, Xian-Sheng Hua, Liqiang Nie|<http://arxiv.org/pdf/2503.08096v1>|- 问题：语义一致性，多粒度语义，图像语义，重建一致性<br />- 方法：定制语义挖掘，多阶段聚合，T2I模型<br />- 效果：语义丰富，结构一致|
|🆕 发布|ACE: Concept Editing in Diffusion Models without Performance Degradation|ACE：无需性能下降的扩散模型中的概念编辑|Ruipeng Wang, Junfeng Fang, Jiaqi Li, Hao Chen, Jie Shi, Kun Wang, Xiang Wang|<http://arxiv.org/pdf/2503.08116v1>|[[代码]](<https://github.com/littlelittlenine/ACE-zero.git>)<br />- 问题：概念编辑，模型性能，安全内容<br />- 方法：交叉空间投影，概念擦除，语义一致性<br />- 效果：性能提升，风险缓解|
|🆕 发布|Representing 3D Shapes With 64 Latent Vectors for 3D Diffusion Models|使用64个潜在向量表示3D形状的3D扩散模型|In Cho, Youngbeom Yoo, Subin Jeon, Seon Joo Kim|<http://arxiv.org/pdf/2503.08737v1>|- 问题：3D形状表示，压缩，扩散模型<br />- 方法：COD-VAE，两阶段编码器，三平面解码器<br />- 效果：压缩16倍，生成速度20.8倍提升|
|🆕 发布|Seeing Beyond Haze: Generative Nighttime Image Dehazing|超越雾霾：生成式夜间图像去雾|Beibei Lin, Stephen Lin, Robby Tan|<http://arxiv.org/pdf/2503.08073v1>|- 问题：夜间图像去雾，背景信息缺失，生成能力有限<br />- 方法：图像扩散模型，背景先验，引导训练<br />- 效果：去雾效果显著，背景信息恢复|
|📝 更新|Boosting Diffusion-Based Text Image Super-Resolution Model Towards Generalized Real-World Scenarios|基于扩散的文本图像超分辨率模型在通用真实世界场景中的提升|Chenglu Pan, Xiaogang Xu, Ganggui Ding, Yunke Zhang, Wenbo Li, Jiarong Xu, Qingbiao Wu|<http://arxiv.org/pdf/2503.07232v2>|- 问题：低分辨率文本图像恢复，保真度，风格真实性<br />- 方法：数据采样策略，预训练SR模型，交叉注意力机制<br />- 效果：保真度提升，文本结构准确|
|🆕 发布|Partial differential equation system for binarization of degraded document images|退化文档图像的二值化部分微分方程系统|Youjin Liu, Yu Wang|<http://arxiv.org/pdf/2503.08017v1>|- 问题：图像退化，二值化，文本图像<br />- 方法：PDE系统，弱耦合，背景估计<br />- 效果：处理优势，实验验证|
|📝 更新|DMin: Scalable Training Data Influence Estimation for Diffusion Models|DMin：扩散模型的可扩展训练数据影响估计|Huawei Lin, Yingjie Lao, Weijie Zhao|<http://arxiv.org/pdf/2412.08637v3>|- 问题：扩散模型，训练数据影响，估计<br />- 方法：DMin框架，梯度压缩，高效检索<br />- 效果：可扩展，性能保持，效率高|
|📝 更新|Diffusion Model-Based Image Editing: A Survey|基于扩散模型的图像编辑：综述|Yi Huang, Jiancheng Huang, Yifan Liu, Mingfu Yan, Jiaxi Lv, Jianzhuang Liu, Wei Xiong, He Zhang .etc.|<http://arxiv.org/pdf/2402.17525v4>|[[代码]](<https://github.com/SiatMMLab/Awesome-Diffusion-Model-Based-Image-Editing-Methods.>)<br />- 问题：图像编辑，噪声去除，模型分析<br />- 方法：扩散模型，图像修复，基准测试<br />- 效果：高质量生成，性能评估|
|🆕 发布|Preserving Product Fidelity in Large Scale Image Recontextualization with Diffusion Models|在大规模图像重上下文中使用扩散模型保持产品保真度|Ishaan Malhi, Praneet Dutta, Ellie Talius, Sally Ma, Brendan Driscoll, Krista Holden, Garima Pruthi, Arunachalam Narayanaswamy|<http://arxiv.org/pdf/2503.08729v1>|- 问题：产品图像重置，数据收集限制，模型理解不足<br />- 方法：文本到图像扩散模型，数据增强，图像到视频扩散<br />- 效果：高保真，多样性，真实感|


### 生成对抗网络 (GANs)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PRISM: Privacy-Preserving Improved Stochastic Masking for Federated Generative Models|PRISM：联邦生成模型隐私保护改进随机掩码|Kyeongkook Seo, Dong-Jun Han, Jaejun Yoo|<http://arxiv.org/pdf/2503.08085v2>|- 问题：联邦学习，生成模型，通信成本，训练稳定性<br />- 方法：随机掩码，MMD损失，MADA聚合<br />- 效果：性能稳定，效率高，隐私保护|
|🆕 发布|Generalizable AI-Generated Image Detection Based on Fractal Self-Similarity in the Spectrum|基于频谱分形自相似性的通用人工智能图像检测|Shengpeng Xiao, Yuanfang Guo, Heqi Peng, Zeming Liu, Liang Yang, Yunhong Wang|<http://arxiv.org/pdf/2503.08484v1>|- 问题：泛化能力，AI图像检测，模型间差异<br />- 方法：光谱自相似性，周期扩展，低通滤波<br />- 效果：泛化性能提升，GANs和扩散模型|
|📝 更新|Dressing the Imagination: A Dataset for AI-Powered Translation of Text into Fashion Outfits and A Novel KAN Adapter for Enhanced Feature Adaptation|着装想象：一个用于AI驱动文本到时尚装扮翻译的数据集以及一种用于增强特征适应的新型KAN适配器|Gayatri Deshmukh, Somsubhra De, Chirag Sehgal, Jishu Sen Gupta, Sparsh Mittal|<http://arxiv.org/pdf/2411.13901v2>|- 问题：AI时尚设计，文本转服装，特征适应<br />- 方法：FLORA数据集，KAN Adapters，Kolmogorov-Arnold Networks<br />- 效果：模型增强，风格丰富，准确生成|
|📝 更新|HunyuanVideo: A Systematic Framework For Large Video Generative Models|HunyuanVideo：大型视频生成模型的整体框架|Weijie Kong, Qi Tian, Zijian Zhang, Rox Min, Zuozhuo Dai, Jin Zhou, Jiangfeng Xiong, Xin Li .etc.|<http://arxiv.org/pdf/2412.03603v6>|[[代码]](<https://github.com/Tencent/HunyuanVideo.>)<br />- 问题：封闭源模型，性能差距，视频生成<br />- 方法：开源框架，数据整理，模型扩展<br />- 效果：性能超越，代码开源|
|📝 更新|From Poses to Identity: Training-Free Person Re-Identification via Feature Centralization|从姿态到身份：通过特征集中化实现的无监督行人重识别|Chao Yuan, Guiwei Zhang, Changxiao Ma, Tianyi Zhang, Guanglin Niu|<http://arxiv.org/pdf/2503.00938v2>|- 问题：特征提取噪声，身份表示不稳定<br />- 方法：特征集中化，身份引导生成，邻域特征集中<br />- 效果：性能提升，泛化能力强|
|🆕 发布|ObjectMover: Generative Object Movement with Video Prior|对象移动器：利用视频先验进行生成性物体运动|Xin Yu, Tianyu Wang, Soo Ye Kim, Paul Guerrero, Xi Chen, Qing Liu, Zhe Lin, Xiaojuan Qi|<http://arxiv.org/pdf/2503.08037v1>|- 问题：物体移动，图像编辑，光照，视角，遮挡<br />- 方法：序列到序列，视频生成模型，数据生成，多任务学习<br />- 效果：模型泛化，结果优异|
|🆕 发布|Exploring Bias in over 100 Text-to-Image Generative Models|探索超过100个文本到图像生成模型中的偏差|Jordan Vice, Naveed Akhtar, Richard Hartley, Ajmal Mian|<http://arxiv.org/pdf/2503.08012v1>|- 问题：模型偏差，文本到图像，生成模型，开放平台<br />- 方法：多维度评估，模型分析，时间趋势研究<br />- 效果：揭示偏差模式，促进负责任AI|
|🆕 发布|STRMs: Spatial Temporal Reasoning Models for Vision-Based Localization Rivaling GPS Precision|时空推理模型：用于视觉定位的模型，与GPS精度相媲美|Hin Wai Lui, Jeffrey L. Krichmar|<http://arxiv.org/pdf/2503.07939v1>|- 问题：视觉定位，GPS精度，生物启发<br />- 方法：VAE-RNN，VAE-Transformer，生成模型<br />- 效果：精度高，资源少|
|🆕 发布|CAD-VAE: Leveraging Correlation-Aware Latents for Comprehensive Fair Disentanglement|CAD-VAE：利用相关性感知潜在变量实现全面公平解耦|Chenrui Ma, Rongchang Zhao, Xi Xiao, Hongyang Xie, Tianyang Wang, Xiao Wang, Hao Zhang, Yanning Shen|<http://arxiv.org/pdf/2503.07938v1>|- 问题：深度生成模型，偏见，公平性，解耦，相关性<br />- 方法：CAD-VAE，相关潜在码，条件互信息，相关性驱动优化<br />- 效果：公平性提升，反事实生成，图像编辑|


### 自回归模型 (Autoregressive Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|3D Point Cloud Generation via Autoregressive Up-sampling|基于自回归上采样的3D点云生成|Ziqiao Meng, Qichao Wang, Zhipeng Zhou, Irwin King, Peilin Zhao|<http://arxiv.org/pdf/2503.08594v1>|- 问题：3D点云生成，无序结构，生成质量<br />- 方法：自回归上采样，多尺度表示，点云上采样网络<br />- 效果：超越SoTA，参数效率高，形状补全|
|🆕 发布|HOFAR: High-Order Augmentation of Flow Autoregressive Transformers|HOFAR：流自回归变换器的高阶增强|Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song, Mingda Wan|<http://arxiv.org/pdf/2503.08032v1>|- 问题：FlowAR，第一阶轨迹，生成质量<br />- 方法：高阶监督，系统框架，轨迹动态分析<br />- 效果：质量提升，理解深化|


## 多模态学习 (Multimodal Learning)


### 视觉语言模型 (Vision-Language Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Modeling Variants of Prompts for Vision-Language Models|视觉-语言模型中提示变体的建模|Ao Li, Zongfang Liu, Xinhua Li, Jinghui Zhang, Pengwei Wang, Hu Wang|<http://arxiv.org/pdf/2503.08229v2>|[[代码]](<https://github.com/liaolea/MVP.>)<br />- 问题：VLMs性能敏感，prompt模板设计<br />- 方法：RobustPrompt Benchmark，MVP，VAE<br />- 效果：模型鲁棒性提升，性能无下降|
|🆕 发布|Prompt-OT: An Optimal Transport Regularization Paradigm for Knowledge Preservation in Vision-Language Model Adaptation|Prompt-OT：视觉-语言模型自适应中知识保持的最优传输正则化范式|Xiwen Chen, Wenhui Zhu, Peijie Qiu, Hao Wang, Huayu Li, Haiyu Wu, Aristeidis Sotiras, Yalin Wang .etc.|<http://arxiv.org/pdf/2503.08906v1>|[[代码]](<https://github.com/ChongQingNoSubway/Prompt-OT>)<br />- 问题：VLMs适应，过拟合，泛化差<br />- 方法：OT指导，prompt学习，特征分布一致性<br />- 效果：泛化提升，性能优于现有方法|
|🆕 发布|Filter Like You Test: Data-Driven Data Filtering for CLIP Pretraining|基于测试过滤数据的CLIP预训练数据驱动数据过滤|Mikey Shechter, Yair Carmon|<http://arxiv.org/pdf/2503.08805v1>|- 问题：数据筛选，预训练，视觉语言数据集<br />- 方法：FLYT，M-FLYT，Soft Cap Sampling<br />- 效果：零样本准确率提升，资源利用优化|
|🆕 发布|OmniMamba: Efficient and Unified Multimodal Understanding and Generation via State Space Models|全视界Mamba：通过状态空间模型实现高效且统一的多模态理解和生成|Jialv Zou, Bencheng Liao, Qian Zhang, Wenyu Liu, Xinggang Wang|<http://arxiv.org/pdf/2503.08686v1>|[[代码]](<https://github.com/hustvl/OmniMamba>)<br />- 问题：计算复杂度高，数据依赖大<br />- 方法：线性架构，词汇解耦，LoRA<br />- 效果：效率提升，性能优越|
|📝 更新|TIPO: Text to Image with Text Presampling for Prompt Optimization|文本预采样优化提示的文本到图像|Shih-Ying Yeh, Sang-Hyun Park, Yi Li, Giyeong Oh, Xuehai Wang, Min Song, Youngjae Yu|<http://arxiv.org/pdf/2411.08127v3>|- 问题：T2I生成，prompt优化，效率低<br />- 方法：预训练模型，prompt采样，语义空间<br />- 效果：质量提升，效率高|
|📝 更新|Mitigating Hallucination for Large Vision Language Model by Inter-Modality Correlation Calibration Decoding|通过跨模态相关性校准解码减轻大型视觉语言模型中的幻觉|Jiaming Li, Jiacheng Zhang, Zequn Jie, Lin Ma, Guanbin Li|<http://arxiv.org/pdf/2501.01926v2>|[[代码]](<https://github.com/lijm48/IMCCD.>)<br />- 问题：幻觉，视觉语言模型，多模态关联<br />- 方法：IMCCD，CMVED，CDAR<br />- 效果：幻觉减少，文本生成|
|📝 更新|Visual Haystacks: A Vision-Centric Needle-In-A-Haystack Benchmark|视觉 haystacks：一个以视觉为中心的“大海捞针”基准|Tsung-Han Wu, Giscard Biamby, Jerome Quenum, Ritwik Gupta, Joseph E. Gonzalez, Trevor Darrell, David M. Chan|<http://arxiv.org/pdf/2407.13766v4>|- 问题：MIQA，长上下文，推理，偏差<br />- 方法：视觉Haystacks，MIRAGE，视觉RAG<br />- 效果：性能提升，新基准，竞争力|
|📝 更新|Critic-V: VLM Critics Help Catch VLM Errors in Multimodal Reasoning|Critic-V：视觉语言模型批评家帮助捕捉多模态推理中的视觉语言模型错误|Di Zhang, Junxian Li, Jingdi Lei, Xunzhi Wang, Yujie Liu, Zonglin Yang, Jiatong Li, Weida Wang .etc.|<http://arxiv.org/pdf/2411.18203v4>|- 问题：VLM错误，推理不准确，幻觉理解<br />- 方法：Actor-Critic，Reasoner，Critic，DPO<br />- 效果：性能提升，推理准确|
|🆕 发布|ComicsPAP: understanding comic strips by picking the correct panel|ComicsPAP：通过选择正确的画格来理解漫画条|Emanuele Vivoli, Artemis Llabrés, Mohamed Ali Soubgui, Marco Bertini, Ernest Valveny Llobet, Dimosthenis Karatzas|<http://arxiv.org/pdf/2503.08561v1>|- 问题：漫画理解，时序空间，模型局限<br />- 方法：ComicsPAP基准，Pick-a-Panel，模型适配<br />- 效果：性能提升，资源驱动|
|📝 更新|Forgotten Polygons: Multimodal Large Language Models are Shape-Blind|遗忘的多边形：多模态大型语言模型对形状视而不见|William Rudman, Michal Golovanesky, Amir Bar, Vedant Palit, Yann LeCun, Carsten Eickhoff, Ritambhara Singh|<http://arxiv.org/pdf/2502.15969v2>|[[代码]](<https://github.com/rsinghlab/Shape-Blind.>)<br />- 问题：MLLMs 形状识别能力弱，数学问题解决差<br />- 方法：几何原理解析，多步推理测试，VC-CoT 提示<br />- 效果：准确率提升，视觉推理增强|
|🆕 发布|GTR: Guided Thought Reinforcement Prevents Thought Collapse in RL-based VLM Agent Training|GTR：引导思维强化防止基于RL的VLM代理训练中的思维崩溃|Tong Wei, Yijun Yang, Junliang Xing, Yuanchun Shi, Zongqing Lu, Deheng Ye|<http://arxiv.org/pdf/2503.08525v1>|- 问题：VLM代理训练，CoT推理，思考崩溃<br />- 方法：GTR框架，过程引导，自动校正器<br />- 效果：性能提升，泛化增强|
|🆕 发布|SignRep: Enhancing Self-Supervised Sign Representations|SignRep：增强自监督手势表示|Ryan Wong, Necati Cihan Camgoz, Richard Bowden|<http://arxiv.org/pdf/2503.08529v1>|- 问题：手语表示学习，数据稀缺，模型复杂<br />- 方法：自监督框架，骨骼线索，特征正则化<br />- 效果：SOTA性能，多任务表现，成本降低|
|🆕 发布|MMRL: Multi-Modal Representation Learning for Vision-Language Models|多模态表征学习：用于视觉-语言模型的MMRL|Yuncheng Guo, Xiaodong Gu|<http://arxiv.org/pdf/2503.08497v1>|[[代码]](<https://github.com/yunncheng/MMRL.>)<br />- 问题：VLMs过拟合，泛化能力差<br />- 方法：MMRL框架，共享表示空间，多模态交互<br />- 效果：性能提升，泛化与适应平衡|
|🆕 发布|Referring to Any Person|指向任何人物|Qing Jiang, Lin Wu, Zhaoyang Zeng, Tianhe Ren, Yuda Xiong, Yihao Chen, Qin Liu, Lei Zhang|<http://arxiv.org/pdf/2503.08507v1>|[[代码]](<https://github.com/IDEA-Research/RexSeek>)<br />- 问题：自然语言描述，个体检测，多个体识别<br />- 方法：HumanRef数据集，多模态大语言模型，RexSeek模型<br />- 效果：泛化能力强，适用广泛|
|🆕 发布|External Knowledge Injection for CLIP-Based Class-Incremental Learning|基于CLIP的类增量学习的外部知识注入|Da-Wei Zhou, Kai-Wen Li, Jingyi Ning, Han-Jia Ye, Lijun Zhang, De-Chuan Zhan|<http://arxiv.org/pdf/2503.08510v1>|[[代码]](<https://github.com/RenaissCode/ENGINE>)<br />- 问题：CIL，CLIP，知识遗忘，特征丢失<br />- 方法：ENGINE，双分支注入，数据增强，GPT-4重写<br />- 效果：性能提升，知识补偿|
|🆕 发布|SuperCap: Multi-resolution Superpixel-based Image Captioning|超级电容：基于多分辨率超像素的图像标题生成|Henry Senior, Luca Rossi, Gregory Slabaugh, Shanxin Yuan|<http://arxiv.org/pdf/2503.08496v1>|- 问题：图像描述，超像素，VLMs，跨领域，多分辨率<br />- 方法：超像素结合，VLMs，多尺度输入，注意力机制<br />- 效果：CIDEr 136.9，竞争力|
|🆕 发布|PhysVLM: Enabling Visual Language Models to Understand Robotic Physical Reachability|PhysVLM：使视觉语言模型理解机器人物理可达性|Weijie Zhou, Manli Tao, Chaoyang Zhao, Haiyun Guo, Honghui Dong, Ming Tang, Jinqiao Wang|<http://arxiv.org/pdf/2503.08481v1>|- 问题：VLM，物理可达性，不准确，环境感知<br />- 方法：S-P Map，特征编码器，多机器人数据集<br />- 效果：性能提升，泛化能力强|
|📝 更新|ChatRex: Taming Multimodal LLM for Joint Perception and Understanding|ChatRex：驯服多模态LLM以实现联合感知和理解|Qing Jiang, Gen Luo, Yuqin Yang, Yuda Xiong, Yihao Chen, Zhaoyang Zeng, Tianhe Ren, Lei Zhang|<http://arxiv.org/pdf/2411.18363v3>|[[代码]](<https://github.com/IDEA-Research/ChatRex.>)<br />- 问题：感知能力不足，多模态LLM<br />- 方法：ChatRex，感知设计，数据引擎<br />- 效果：性能提升，应用拓展|
|📝 更新|Silent Hazards of Token Reduction in Vision-Language Models: The Hidden Impact on Consistency|视觉-语言模型中标记减少的静默风险：对一致性的潜在影响|Yizheng Sun, Hao Li, Chang Xu, Chenghua Lin, Riza Batista-Navarro, Jingyuan Sun|<http://arxiv.org/pdf/2503.06794v2>|- 问题：Token reduction, VLMs, consistency issues<br />- 方法：SVD, lower-rank approximation, LoFi<br />- 效果：cost reduction, consistency improvement|
|📝 更新|QUART-Online: Latency-Free Large Multimodal Language Model for Quadruped Robot Learning|QUART-Online：用于四足机器人学习的零延迟大型多模态语言模型|Xinyang Tong, Pengxiang Ding, Yiguo Fan, Donglin Wang, Wenjie Zhang, Can Cui, Mingyang Sun, Han Zhao .etc.|<http://arxiv.org/pdf/2412.15576v3>|- 问题：推理延迟，性能下降，参数缩减<br />- 方法：ACD，压缩动作表示，语义空间融合<br />- 效果：实时推理，成功率提升65%|
|🆕 发布|Controlling Latent Diffusion Using Latent CLIP|控制潜在扩散的潜在CLIP|Jason Becker, Chris Wendler, Peter Baylies, Robert West, Christian Wressnegger|<http://arxiv.org/pdf/2503.08455v1>|- 问题：高成本VAE解码，CLIP模型在像素空间<br />- 方法：Latent-CLIP，零样本分类，ReNO<br />- 效果：性能匹配，成本降低，引导生成|
|📝 更新|VAGUE: Visual Contexts Clarify Ambiguous Expressions|模糊：视觉上下文澄清模糊表达|Heejeong Nam, Jinwoo Ahn, Keummin Ka, Jiwan Chung, Youngjae Yu|<http://arxiv.org/pdf/2411.14137v2>|[[代码]](<https://github.com/Hazel-Heejeong-Nam/VAGUE.git.>)<br />- 问题：多模态推理，意图歧义，视觉上下文<br />- 方法：VAGUE基准，图像-文本对，意图识别<br />- 效果：性能提升，差距明显|
|📝 更新|V-LoRA: An Efficient and Flexible System Boosts Vision Applications with LoRA LMM|V-LoRA：一种高效灵活的系统通过LoRA LMM提升视觉应用|Liang Mi, Weijun Wang, Wenming Tu, Qingfeng He, Rui Kong, Xinyu Fang, Yazhu Dong, Yikang Zhang .etc.|<http://arxiv.org/pdf/2411.00915v3>|- 问题：LoRA模型，计算成本高，延迟高<br />- 方法：LoRA LMM，自适应批处理，灵活编排<br />- 效果：精度提升，延迟降低|
|📝 更新|Are foundation models for computer vision good conformal predictors?|计算机视觉的基础模型是否是好的一致性预测器？|Leo Fillioux, Julio Silva-Rodríguez, Ismail Ben Ayed, Paul-Henry Cournède, Maria Vakalopoulou, Stergios Christodoulidis, Jose Dolz|<http://arxiv.org/pdf/2412.06082v2>|- 问题：基础模型，不确定性建模，安全部署<br />- 方法：Conformal Prediction，Vision Transformers，置信度校准<br />- 效果：适用性高，效率降低，性能提升|
|🆕 发布|Debiased Prompt Tuning in Vision-Language Model without Annotations|无标注视觉-语言模型中的去偏差提示调整|Chaoquan Jiang, Yunfan Yang, Rui Hu, Jitao Sang|<http://arxiv.org/pdf/2503.08368v1>|- 问题：Prompt Tuning, Spurious Correlations, Robustness, Annotations, Vision-Language Models<br />- 方法：Zero-shot Image Recognition, Pseudo-annotations, Weight Adjustment<br />- 效果：Robustness Gap, Accuracy Improvement|
|🆕 发布|Prompt2LVideos: Exploring Prompts for Understanding Long-Form Multimodal Videos|Prompt2LVideos：探索理解长格式多模态视频的提示|Soumya Shamarao Jahagirdar, Jayasree Saha, C V Jawahar|<http://arxiv.org/pdf/2503.08335v1>|- 问题：长视频理解，标注困难，LLMs<br />- 方法：Prompt工程，ASR，OCR<br />- 效果：全面理解，数据集|
|🆕 发布|DIV-FF: Dynamic Image-Video Feature Fields For Environment Understanding in Egocentric Videos|动态图像-视频特征域：用于自旋视频环境理解的动态图像-视频特征场|Lorenzo Mur-Labadia, Josechu Guerrero, Ruben Martinez-Cantin|<http://arxiv.org/pdf/2503.08344v1>|- 问题：环境理解，动态交互，语义几何信息，场景理解<br />- 方法：动态特征场，图像视频特征融合，组件分解<br />- 效果：长期时空理解，动态场景表现|
|📝 更新|Chrono: A Simple Blueprint for Representing Time in MLLMs|Chrono：在多模态语言模型中表示时间的简单蓝图|Boris Meinardus, Hector Rodriguez, Anil Batra, Anna Rohrbach, Marcus Rohrbach|<http://arxiv.org/pdf/2406.18113v5>|- 问题：视频语言模型，时间理解，时序定位<br />- 方法：Chrono蓝图，通用序列表示<br />- 效果：SOTA，时序检索|
|📝 更新|CNN-JEPA: Self-Supervised Pretraining Convolutional Neural Networks Using Joint Embedding Predictive Architecture|CNN-JEPA：基于联合嵌入预测架构的自监督预训练卷积神经网络|András Kalapos, Bálint Gyires-Tóth|<http://arxiv.org/pdf/2408.07514v2>|- 问题：CNN SSL，Vision Transformers，适应挑战<br />- 方法：CNN-JEPA，稀疏编码器，深度可分离卷积<br />- 效果：性能提升，效率高|
|🆕 发布|EgoBlind: Towards Egocentric Visual Assistance for the Blind People|自我盲视：迈向盲人自中心视觉辅助|Junbin Xiao, Nanxin Huang, Hao Qiu, Zhulin Tao, Xun Yang, Richang Hong, Meng Wang, Angela Yao|<http://arxiv.org/pdf/2503.08221v1>|- 问题：盲人视觉辅助，视频问答，多模态语言模型<br />- 方法：EgoBlind数据集，评估MLLM性能<br />- 效果：识别能力低，MLLM局限|
|🆕 发布|Attention Hijackers: Detect and Disentangle Attention Hijacking in LVLMs for Hallucination Mitigation|注意力劫持者：检测和分解LVLMs中的幻觉缓解中的注意力劫持|Beitao Chen, Xinyu Lyu, Lianli Gao, Jingkuan Song, Heng Tao Shen|<http://arxiv.org/pdf/2503.08216v1>|- 问题：幻觉，视觉注意力，指令干扰<br />- 方法：AID，注意力劫持检测，解耦机制<br />- 效果：幻觉减少，模型鲁棒|
|📝 更新|ROSE: Revolutionizing Open-Set Dense Segmentation with Patch-Wise Perceptual Large Multimodal Model|ROSE：通过Patch-Wise感知大型多模态模型革新开放式密集分割|Kunyang Han, Yibo Hu, Mengxue Qu, Hailin Shi, Yao Zhao, Yunchao Wei|<http://arxiv.org/pdf/2412.00153v3>|- 问题：开放集，密集分割，预定义类别限制，稀疏预测<br />- 方法：Patch-wise感知，开放类别生成，指令响应范式<br />- 效果：密集预测，类别精度提升|
|🆕 发布|Towards Large-scale Chemical Reaction Image Parsing via a Multimodal Large Language Model|面向大规模化学反应图像解析的多模态大型语言模型|Yufan Chen, Ching Ting Leung, Jianwei Sun, Yong Huang, Linyan Li, Hao Chen, Hanyu Gao|<http://arxiv.org/pdf/2503.08156v1>|- 问题：化学反应图像解析，数据质量，人工标注<br />- 方法：多模态大语言模型，RxnIM，大规模数据生成<br />- 效果：F1分数88%，超越现有方法|
|🆕 发布|Few-Shot Class-Incremental Model Attribution Using Learnable Representation From CLIP-ViT Features|基于CLIP-ViT特征的学可表示的少样本类别增量模型归因|Hanbyul Lee, Juneho Yi|<http://arxiv.org/pdf/2503.08148v1>|- 问题：模型可解释性，数据密集，新模型识别<br />- 方法：FSCIL，CLIP-ViT特征，自适应集成模块<br />- 效果：泛化能力强，识别效率高|
|📝 更新|GPT4Scene: Understand 3D Scenes from Videos with Vision-Language Models|GPT4Scene：利用视觉-语言模型理解视频中的3D场景|Zhangyang Qi, Zhixiong Zhang, Ye Fang, Jiaqi Wang, Hengshuang Zhao|<http://arxiv.org/pdf/2501.01428v4>|- 问题：3D空间理解，VLM局限性，全局-局部对应<br />- 方法：GPT4Scene，视觉提示，BEV图像<br />- 效果：性能提升，3D理解，预训练扩展|
|📝 更新|PromptHSI: Universal Hyperspectral Image Restoration with Vision-Language Modulated Frequency Adaptation|PromptHSI：基于视觉-语言调制频率自适应的通用高光谱图像恢复|Chia-Ming Lee, Ching-Heng Cheng, Yu-Fan Lin, Yi-Ching Cheng, Wo-Ting Liao, Fu-En Yang, Yu-Chiang Frank Wang, Chih-Chung Hsu|<http://arxiv.org/pdf/2411.15922v3>|[[代码]](<https://github.com/chingheng0808/PromptHSI.>)<br />- 问题：HSI恢复，域差距，信息损失，降解模式<br />- 方法：频率感知，VLM引导，文本提示分解<br />- 效果：恢复效果好，应用潜力大|
|📝 更新|OCR Hinders RAG: Evaluating the Cascading Impact of OCR on Retrieval-Augmented Generation|OCR阻碍RAG：评估OCR对检索增强生成的影响级联效应|Junyuan Zhang, Qintong Zhang, Bin Wang, Linke Ouyang, Zichen Wen, Ying Li, Ka-Ho Chow, Conghui He .etc.|<http://arxiv.org/pdf/2412.02592v2>|[[代码]](<https://github.com/opendatalab/OHR-Bench>)<br />- 问题：OCR噪声，RAG性能，知识库构建<br />- 方法：OHRBench基准，噪声类型识别，性能评估<br />- 效果：揭示OCR影响，评估噪声程度|
|🆕 发布|Unmasking the Unknown: Facial Deepfake Detection in the Open-Set Paradigm|揭开未知面纱：开放集范式下的面部深度伪造检测|Nadarasar Bahavan, Sanjay Saha, Ken Chen, Sachith Seneviratne, Sanka Rasnayaka, Saman Halgamuge|<http://arxiv.org/pdf/2503.08055v1>|- 问题：deepfake检测，闭集范式，未知方法<br />- 方法：开放集，对比学习，监督学习<br />- 效果：准确率提升，鲁棒性增强|
|📝 更新|LayoutVLM: Differentiable Optimization of 3D Layout via Vision-Language Models|布局VLM：通过视觉-语言模型的可微3D布局优化|Fan-Yun Sun, Weiyu Liu, Siyi Gu, Dylan Lim, Goutam Bhat, Federico Tombari, Manling Li, Nick Haber .etc.|<http://arxiv.org/pdf/2412.02193v3>|- 问题：3D推理，空间布局，语言指令，物理约束<br />- 方法：VLM语义知识，可微分优化，自洽解码<br />- 效果：物理合理，语义对齐，推理性能提升|
|📝 更新|Global Compression Commander: Plug-and-Play Inference Acceleration for High-Resolution Large Vision-Language Models|全球压缩指挥官：高分辨率大型视觉-语言模型即插即用推理加速|Xuyang Liu, Ziming Wang, Yuhang Han, Yingyao Wang, Jiale Yuan, Jun Song, Bo Zheng, Linfeng Zhang .etc.|<http://arxiv.org/pdf/2501.05179v4>|[[代码]](<https://github.com/xuyang-liu16/GlobalCom2.>)<br />- 问题：LVLMs效率低，多视图处理，压缩技术不足<br />- 方法：全局压缩指挥器，动态分块，信息评估<br />- 效果：性能维持，FLOPs减少，内存降低|
|🆕 发布|LongProLIP: A Probabilistic Vision-Language Model with Long Context Text|LongProLIP：一种具有长上下文文本的概率视觉-语言模型|Sanghyuk Chun, Sangdoo Yun|<http://arxiv.org/pdf/2503.08048v1>|- 问题：ProLIP，长文本处理，上下文信息<br />- 方法：LongProLIP，微调策略，长文本支持<br />- 效果：长文本理解，零样本能力|
|🆕 发布|Multi-Cue Adaptive Visual Token Pruning for Large Vision-Language Models|多线索自适应视觉标记剪枝用于大型视觉-语言模型|Bozhi Luan, Wengang Zhou, Hao Feng, Zhe Wang, Xiaosong Li, Houqiang Li|<http://arxiv.org/pdf/2503.08019v1>|[[代码]](<https://github.com/bzluan/AdaptPrune.>)<br />- 问题：视觉语言模型，剪枝，效率<br />- 方法：自适应剪枝，空间距离，相似度<br />- 效果：速度提升，鲁棒性|
|📝 更新|VASCAR: Content-Aware Layout Generation via Visual-Aware Self-Correction|VASCAR：通过视觉感知自校正的内容感知布局生成|Jiahao Zhang, Ryota Yoshihashi, Shunsuke Kitada, Atsuki Osanai, Yuta Nakashima|<http://arxiv.org/pdf/2412.04237v3>|- 问题：LLMs限制，内容感知布局，视觉感知<br />- 方法：视觉感知自校正，迭代优化，LVLMs应用<br />- 效果：SOTA布局生成，泛化性强|
|🆕 发布|SKALD: Learning-Based Shot Assembly for Coherent Multi-Shot Video Creation|SKALD：基于学习的连贯多镜头视频创建镜头组装|Chen Yi Lu, Md Mehrab Tanjim, Ishita Dasgupta, Somdeb Sarkhel, Gang Wu, Saayan Mitra, Somali Chaterji|<http://arxiv.org/pdf/2503.08010v1>|- 问题：多镜头视频拼接，叙事连贯性，文本依赖<br />- 方法：学习剪辑组装，对比学习，特征回归<br />- 效果：IoU提升，速度加快，用户偏好|
|📝 更新|LightMotion: A Light and Tuning-free Method for Simulating Camera Motion in Video Generation|光动：视频生成中模拟相机运动的轻量级和无调谐方法|Quanjian Song, Zhihang Lin, Zhanpeng Zeng, Ziyue Zhang, Liujuan Cao, Rongrong Ji|<http://arxiv.org/pdf/2503.06508v2>|- 问题：计算瓶颈，调优，深度估计<br />- 方法：潜在空间操作，背景感知采样，纠正噪声<br />- 效果：性能提升，质量增强|
|📝 更新|Image Super-Resolution with Text Prompt Diffusion|基于文本提示的图像超分辨率|Zheng Chen, Yulun Zhang, Jinjin Gu, Xin Yuan, Linghe Kong, Guihai Chen, Xiaokang Yang|<http://arxiv.org/pdf/2311.14282v5>|[[代码]](<https://github.com/zhengchen1999/PromptSR.>)<br />- 问题：图像超分辨率，退化信息提取，模型性能限制<br />- 方法：文本提示，多模态方法，PromptSR<br />- 效果：结果显著，合成与真实图像|
|📝 更新|Grounding-IQA: Multimodal Language Grounding Model for Image Quality Assessment|图像质量评估的多模态语言定位模型：Grounding-IQA|Zheng Chen, Xun Zhang, Wenbo Li, Renjing Pei, Fenglong Song, Xiongkuo Min, Xiaohong Liu, Xin Yuan .etc.|<http://arxiv.org/pdf/2411.17237v2>|[[代码]](<https://github.com/zhengchen1999/Grounding-IQA.>)<br />- 问题：IQA方法依赖泛化描述，细粒度评估受限<br />- 方法：grounding-IQA，GIQA-DES，GIQA-VQA，GIQA-160K，GIQA-Bench<br />- 效果：细粒度IQA应用，描述质量，VQA准确率|


### 多模态融合 (Multimodal Fusion)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MsaMIL-Net: An End-to-End Multi-Scale Aware Multiple Instance Learning Network for Efficient Whole Slide Image Classification|MsaMIL-Net：一种用于高效全切片图像分类的端到端多尺度感知多实例学习网络|Jiangping Wen, Jinyu Wen, Meie Fang|<http://arxiv.org/pdf/2503.08581v2>|- 问题：MIL, WSI分类，特征提取，多尺度，性能限制<br />- 方法：多尺度特征，语义过滤，融合MIL模块<br />- 效果：准确率提升，AUC提升|
|🆕 发布|Language-Depth Navigated Thermal and Visible Image Fusion|语言深度导航的热成像和可见光图像融合|Jinchang Zhang, Zijun Li, Guoyu Lu|<http://arxiv.org/pdf/2503.08676v1>|- 问题：深度信息融合，3D重建，机器人导航<br />- 方法：文本引导，深度驱动，扩散模型<br />- 效果：精度提升，场景理解|
|🆕 发布|A Multimodal Physics-Informed Neural Network Approach for Mean Radiant Temperature Modeling|多模态物理信息神经网络方法在平均辐射温度建模中的应用|Pouya Shaeri, Saud AlKhaled, Ariane Middel|<http://arxiv.org/pdf/2503.08482v1>|- 问题：室外热舒适度，平均辐射温度，资源密集，预测精度<br />- 方法：物理信息神经网络，多模态数据，辐射建模<br />- 效果：预测准确，物理一致性，性能优越|
|🆕 发布|FilmComposer: LLM-Driven Music Production for Silent Film Clips|电影作曲家：基于LLM的默片剪辑音乐制作|Zhifeng Xie, Qile He, Youjia Zhu, Qiwei He, Mengtian Li|<http://arxiv.org/pdf/2503.08147v1>|[[代码]](<https://apple-jun.github.io/FilmComposer.github.io>)<br />- 问题：无声电影配乐，音乐生成，多代理方法<br />- 方法：LLM驱动，波形与符号音乐，音乐元素控制<br />- 效果：高质量，一致性，多样性|
|📝 更新|Dynamic Analysis and Adaptive Discriminator for Fake News Detection|动态分析与自适应判别器在假新闻检测中的应用|Xinqi Su, Zitong Yu, Yawen Cui, Ajian Liu, Xun Lin, Yuhao Wang, Haochen Liang, Wenhui Li .etc.|<http://arxiv.org/pdf/2408.10883v2>|[[代码]](<https://github.com/SuXinqi/DAAD.>)<br />- 问题：假新闻检测，知识依赖，语义分析，灵活性<br />- 方法：蒙特卡洛树搜索，LLM优化，软路由机制<br />- 效果：检测模型，性能优越|
|📝 更新|Knowledge Bridger: Towards Training-free Missing Multi-modality Completion|知识桥接：迈向无训练缺失多模态补全|Guanzhou Ke, Shengfeng He, Xiao Li Wang, Bo Wang, Guoqing Chao, Yuanyang Zhang, Yi Xie, HeXing Su|<http://arxiv.org/pdf/2502.19834v3>|- 问题：缺失模态，预训练，泛化能力<br />- 方法：知识桥接，多模态模型，知识图谱<br />- 效果：高效，鲁棒，高质量|
|🆕 发布|Enhancing Sentiment Analysis through Multimodal Fusion: A BERT-DINOv2 Approach|通过多模态融合增强情感分析：一种BERT-DINOv2方法|Taoxu Zhao, Meisi Li, Kehao Chen, Liye Wang, Xucheng Zhou, Kunal Chaturvedi, Mukesh Prasad, Ali Anaissi .etc.|<http://arxiv.org/pdf/2503.07943v1>|- 问题：情感分析，单一模态，理解不全面<br />- 方法：BERT，DINOv2，融合模型<br />- 效果：综合性能提升|


### 跨模态对齐 (Cross-modal Alignment)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|$^R$FLAV: Rolling Flow matching for infinite Audio Video generation|FLAV：无限音频视频生成的滚动流匹配|Alex Ergasti, Giuseppe Gabriele Tarollo, Filippo Botti, Tomaso Fontanini, Claudio Ferrari, Massimo Bertozzi, Andrea Prati|<http://arxiv.org/pdf/2503.08307v2>|[[代码]](<https://github.com/ErgastiAlex/R-FLAV.>)<br />- 问题：AV生成，多模态同步，时间一致性，无限时长<br />- 方法：Transformer架构，交叉模态交互模块，轻量级时序融合<br />- 效果：超越现有模型，多模态AV生成|
|📝 更新|Video-to-Audio Generation with Hidden Alignment|基于隐藏对齐的视频生成音频|Manjie Xu, Chenxing Li, Xinyi Tu, Yong Ren, Rilin Chen, Yu Gu, Wei Liang, Dong Yu|<http://arxiv.org/pdf/2407.07464v3>|- 问题：视频音频同步，生成质量，数据增强<br />- 方法：视觉编码器，辅助嵌入，消融研究<br />- 效果：同步性，生成能力|
|🆕 发布|TLA: Tactile-Language-Action Model for Contact-Rich Manipulation|触觉-语言-动作模型：用于富含接触的操纵|Peng Hao, Chaofan Zhang, Dingzhe Li, Xiaoge Cao, Xiaoshuai Hao, Shaowei Cui, Shuo Wang|<http://arxiv.org/pdf/2503.08548v1>|- 问题：语言条件触觉操作，触觉感知，接触密集任务<br />- 方法：TLA模型，跨模态语言定位，数据集构建<br />- 效果：动作生成，动作准确率，泛化能力|
|📝 更新|KinMo: Kinematic-aware Human Motion Understanding and Generation|《KinMo：基于运动学感知的人体运动理解和生成》|Pengfei Zhang, Pinxin Liu, Hyeongwoo Kim, Pablo Garrido, Bindita Chaudhuri|<http://arxiv.org/pdf/2411.15472v2>|[[代码]](<https://andypinxinliu.github.io/KinMo>)<br />- 问题：动作描述，模态差距，运动理解，生成能力<br />- 方法：描述性运动表示，自动化标注，文本-运动对齐<br />- 效果：理解提升，生成编辑|
|📝 更新|Towards Improved Text-Aligned Codebook Learning: Multi-Hierarchical Codebook-Text Alignment with Long Text|迈向改进文本对齐代码本学习：多层级代码本-文本对齐与长文本|Guotao Liang, Baoquan Zhang, Zhiyuan Wen, Junteng Zhao, Yunming Ye, Kola Ye, Yao He|<http://arxiv.org/pdf/2503.01261v2>|- 问题：文本描述过简，文本-代码本对齐差<br />- 方法：文本增强，多层级编码，采样对齐<br />- 效果：性能提升，跨模态任务|
|📝 更新|Towards Open-Vocabulary Audio-Visual Event Localization|面向开放词汇的视听事件定位|Jinxing Zhou, Dan Guo, Ruohao Guo, Yuxin Mao, Jingjing Hu, Yiran Zhong, Xiaojun Chang, Meng Wang|<http://arxiv.org/pdf/2411.11278v3>|- 问题：开放词汇，音频-视觉事件定位，未见类别<br />- 方法：OV-AVEBench数据集，特征提取，模型微调<br />- 效果：未见类别识别，性能评估|
|📝 更新|OTTER: A Vision-Language-Action Model with Text-Aware Visual Feature Extraction|OTTER：一种具有文本感知视觉特征提取的视觉-语言-动作模型|Huang Huang, Fangchen Liu, Letian Fu, Tingfan Wu, Mustafa Mukadam, Jitendra Malik, Ken Goldberg, Pieter Abbeel|<http://arxiv.org/pdf/2503.03734v2>|[[代码]](<https://ottervla.github.io/.>)<br />- 问题：VLA模型，预训练语义对齐，微调<br />- 方法：文本感知视觉特征提取，任务相关特征选择<br />- 效果：零样本泛化，性能提升|
|🆕 发布|A Survey on Wi-Fi Sensing Generalizability: Taxonomy, Techniques, Datasets, and Future Research Prospects|Wi-Fi感知泛化性综述：分类、技术、数据集和未来研究方向|Fei Wang, Tingting Zhang, Bintong Zhao, Libao Xing, Tiantian Wang, Han Ding, Tony Xiao Han|<http://arxiv.org/pdf/2503.08008v1>|- 问题：Wi-Fi感知泛化，环境依赖，信号特征不一致<br />- 方法：分类，技术分析，数据集概述<br />- 效果：方法系统化，数据集全面，未来方向启发|
|🆕 发布|Text-RGBT Person Retrieval: Multilevel Global-Local Cross-Modal Alignment and A High-quality Benchmark|文本RGBT人物检索：多级全局-局部跨模态对齐与高质量基准|Yifei Deng, Zhengyu Chen, Ziheng Xu, Chenglong Li, Jin Tang|<http://arxiv.org/pdf/2503.07950v1>|- 问题：光照变化，跨模态对齐，异构性<br />- 方法：多级全局-局部对齐网络，高质量数据集<br />- 效果：性能提升，鲁棒性增强|
|📝 更新|X2CT-CLIP: Enable Multi-Abnormality Detection in Computed Tomography from Chest Radiography via Tri-Modal Contrastive Learning|X2CT-CLIP：通过三模态对比学习实现从胸部X光片到计算机断层扫描的多异常检测|Jianzhong You, Yuan Gao, Sangwook Kim, Chris Mcintosh|<http://arxiv.org/pdf/2503.02162v2>|- 问题：多异常检测，模态差距，知识迁移<br />- 方法：X2CT-CLIP，三模态对比学习，隐空间对齐<br />- 效果：超越基线，跨模态检索，少样本适应|


## 目标检测识别 (Object Detection & Recognition)


### 三维检测 (3D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Accelerate 3D Object Detection Models via Zero-Shot Attention Key Pruning|通过零样本注意力键剪枝加速3D目标检测模型|Lizhen Xu, Xiuxiu Bai, Xiaojun Jia, Jianwu Fang, Shanmin Pang|<http://arxiv.org/pdf/2503.08101v2>|[[代码]](<https://github.com/iseri27/tg_gbc.>)<br />- 问题：3D检测模型，计算需求高，迁移困难<br />- 方法：零样本剪枝，tgGBC，注意力权重<br />- 效果：速度提升1.99倍，性能损失小于1%|
|📝 更新|HO-Cap: A Capture System and Dataset for 3D Reconstruction and Pose Tracking of Hand-Object Interaction|HO-Cap：用于手-物体交互3D重建和姿态跟踪的捕获系统和数据集|Jikai Wang, Qifan Zhang, Yu-Wei Chao, Bowen Wen, Xiaohu Guo, Yu Xiang|<http://arxiv.org/pdf/2406.06843v4>|- 问题：3D重建，姿态跟踪，手-物体交互<br />- 方法：数据采集系统，半自动标注，视频数据集<br />- 效果：效率提升，应用潜力|
|📝 更新|Revisiting Point Cloud Completion: Are We Ready For The Real-World?|重新审视点云补全：我们准备好应对现实世界了吗？|Stuti Pathak, Prashant Kumar, Dheeraj Baiju, Nicholus Mboga, Gunther Steenackers, Rudi Penne|<http://arxiv.org/pdf/2411.17580v4>|- 问题：点云补全，真实场景，噪声，不完整<br />- 方法：拓扑特征，RealPC数据集，BOSHNet网络<br />- 效果：性能提升，拓扑一致性|
|📝 更新|TSP3D: Text-guided Sparse Voxel Pruning for Efficient 3D Visual Grounding|TSP3D：基于文本引导的稀疏体素剪枝以实现高效的3D视觉定位|Wenxuan Guo, Xiuwei Xu, Ziwei Wang, Jianjiang Feng, Jie Zhou, Jiwen Lu|<http://arxiv.org/pdf/2502.10392v2>|[[代码]](<https://github.com/GWxuan/TSP3D>)<br />- 问题：3D视觉定位，效率低，精度不足<br />- 方法：多级卷积，文本引导剪枝，补全<br />- 效果：速度提升，精度领先|
|🆕 发布|Learning to Detect Objects from Multi-Agent LiDAR Scans without Manual Labels|从多智能体激光雷达扫描中学习检测对象而不需要人工标签|Qiming Xia, Wenkai Lin, Haoen Xiang, Xun Huang, Siheng Chen, Zhen Dong, Cheng Wang, Chenglu Wen|<http://arxiv.org/pdf/2503.08421v1>|[[代码]](<https://github.com/xmuqimingxia/DOtA.>)<br />- 问题：无监督3D目标检测，数据稀疏，伪标签低质量<br />- 方法：DOtA，多代理协同，多尺度编码<br />- 效果：性能优于现有方法，验证有效|
|🆕 发布|WildSeg3D: Segment Any 3D Objects in the Wild from 2D Images|野地3D分割：从2D图像中分割任何野地中的3D物体|Yansong Guo, Jie Hu, Yansong Qu, Liujuan Cao|<http://arxiv.org/pdf/2503.08407v1>|- 问题：3D分割，场景特定训练，实时性<br />- 方法：动态全局对齐，多视图组映射，前馈机制<br />- 效果：泛化能力强，速度提升40倍|
|📝 更新|CogNav: Cognitive Process Modeling for Object Goal Navigation with LLMs|认知导航：基于大型语言模型的物体目标导航的认知过程建模|Yihan Cao, Jiazhao Zhang, Zhinan Yu, Shuzhen Liu, Zheng Qin, Qin Zou, Bo Du, Kai Xu|<http://arxiv.org/pdf/2412.10439v2>|- 问题：ObjectNav，认知过程，目标导航<br />- 方法：CogNav，认知状态建模，语言模型<br />- 效果：成功率提升，性能改善|
|🆕 发布|HERO: Human Reaction Generation from Videos|HERO：从视频中生成人类反应|Chengjun Yu, Wei Zhai, Yuhang Yang, Yang Cao, Zheng-Jun Zha|<http://arxiv.org/pdf/2503.08270v1>|[[代码]](<https://jackyu6.github.io/HERO.>)<br />- 问题：反应生成，交互AI，情感影响<br />- 方法：HERO框架，全局帧级表示，动态属性利用<br />- 效果：多类别交互，数据集支持|
|🆕 发布|A Framework for Reducing the Complexity of Geometric Vision Problems and its Application to Two-View Triangulation with Approximation Bounds|一个降低几何视觉问题复杂度的框架及其在具有近似界限的两视图三角测量中的应用|Felix Rydell, Georg Bökman, Fredrik Kahl, Kathlén Kohn|<http://arxiv.org/pdf/2503.08142v1>|- 问题：几何视觉问题，计算复杂度，三角测量<br />- 方法：成本函数重加权，近似解，优化策略<br />- 效果：简化计算，保持精度，实验验证|
|🆕 发布|SparseVoxFormer: Sparse Voxel-based Transformer for Multi-modal 3D Object Detection|稀疏VoxFormer：基于稀疏体素的Transformer用于多模态3D目标检测|Hyeongseok Son, Jia He, Seung-In Park, Ying Min, Yunhao Zhang, ByungIn Yoo|<http://arxiv.org/pdf/2503.08092v1>|- 问题：低分辨率特征，BEV空间，计算成本高<br />- 方法：稀疏Voxel，Transformer，模态融合<br />- 效果：计算成本低，性能提升|
|🆕 发布|Simulating Automotive Radar with Lidar and Camera Inputs|利用激光雷达和摄像头输入模拟汽车雷达|Peili Song, Dezhen Song, Yifan Yang, Enfan Lan, Jingtai Liu|<http://arxiv.org/pdf/2503.08068v1>|- 问题：低质量数据集，雷达信号模拟<br />- 方法：DIS-Net，RSS-Net，雷达信号生成<br />- 效果：高保真，数据增强|
|📝 更新|FreeGaussian: Annotation-free Controllable 3D Gaussian Splats with Flow Derivatives|标题翻译：无标注可控3D高斯块与流导数|Qizhi Chen, Delin Qu, Junli Liu, Yiwen Tang, Haoming Song, Dong Wang, Bin Zhao, Xuelong Li|<http://arxiv.org/pdf/2410.22070v2>|- 问题：单目视频，Gaussian splats，约束不足<br />- 方法：动态Gaussian约束，3D球形向量控制<br />- 效果：自监督优化，控制能力|
|🆕 发布|From Slices to Sequences: Autoregressive Tracking Transformer for Cohesive and Consistent 3D Lymph Node Detection in CT Scans|从切片到序列：用于CT扫描中连贯一致3D淋巴结检测的自回归跟踪Transformer|Qinji Yu, Yirui Wang, Ke Yan, Dandan Zheng, Dashan Ai, Dazhou Guo, Zhanghexuan Ji, Yanzhou Su .etc.|<http://arxiv.org/pdf/2503.07933v1>|- 问题：3D淋巴结检测，切片一致性，2.5D方法，跟踪任务<br />- 方法：LN-Tracker，Transformer，自回归跟踪，掩码注意力<br />- 效果：性能提升，泛化能力强|


### 多目标跟踪 (Multi-object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PromptGAR: Flexible Promptive Group Activity Recognition|PromptGAR：灵活的提示式群体活动识别|Zhangyu Jin, Andrew Feng, Ankur Chemburkar, Celso M. De Melo|<http://arxiv.org/pdf/2503.08933v1>|- 问题：GAR局限性，输入灵活性，长期一致性，多组场景<br />- 方法：多模态提示，点提示，相对实例注意力，区域提示<br />- 效果：高识别精度，输入灵活，泛化能力强|
|🆕 发布|Attention to Trajectory: Trajectory-Aware Open-Vocabulary Tracking|轨迹感知开放词汇跟踪：关注轨迹|Yunhao Li, Yifan Jiao, Dan Meng, Heng Fan, Libo Zhang|<http://arxiv.org/pdf/2503.08145v1>|- 问题：OV-MOT，轨迹信息，关联稳定性，分类精度<br />- 方法：TCR策略，TraCLIP模块，TFA，TSE<br />- 效果：性能提升，轨迹信息价值|


### 二维检测 (2D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|The Detection of Saccadic Eye Movements and Per-Eye Comparisons using Virtual Reality Eye Tracking Devices|基于虚拟现实眼动追踪设备的扫视眼动检测及每眼比较|Teran Bukenberger, Brent Davis|<http://arxiv.org/pdf/2503.08926v1>|- 问题：saccade detection, VR eye tracking, neuroscience<br />- 方法：prototype software, 60/90Hz eye tracker, per-eye comparisons<br />- 效果：saccade detection, neurological disorders|
|📝 更新|Efficient Event-Based Object Detection: A Hybrid Neural Network with Spatial and Temporal Attention|高效的事件驱动目标检测：一种具有空间和时序注意力的混合神经网络|Soikat Hasan Ahmed, Jan Finkbeiner, Emre Neftci|<http://arxiv.org/pdf/2403.10173v3>|- 问题：事件相机，对象检测，SNN，ANN，精度不足<br />- 方法：混合网络，注意力机制，时空关系，DWConvL-STMs<br />- 效果：性能提升，参数减少，功耗降低|
|🆕 发布|Recognition-Synergistic Scene Text Editing|识别协同场景文本编辑|Zhengyao Fang, Pengyuan Lyu, Jingjing Wu, Chengquan Zhang, Jun Yu, Guangming Lu, Wenjie Pei|<http://arxiv.org/pdf/2503.08387v1>|[[代码]](<https://github.com/ZhengyaoFang/RS-STE.>)<br />- 问题：场景文本编辑，风格内容分离，复杂场景性能<br />- 方法：RS-STE，多模态并行解码器，循环自监督微调<br />- 效果：SOTA性能，风格内容一致性，下游任务性能提升|
|📝 更新|Bringing the Context Back into Object Recognition, Robustly|将上下文重新引入物体识别，稳健地|Klara Janouskova, Cristian Gavrus, Jiri Matas|<http://arxiv.org/pdf/2411.15933v2>|- 问题：背景依赖，模型鲁棒性差<br />- 方法：L2R2，零样本检测，前景定位<br />- 效果：性能提升，鲁棒性强|
|🆕 发布|Embodied Crowd Counting|具身化人群计数|Runling Long, Yunlong Wang, Jia Wan, Xiang Deng, Xinting Zhu, Weili Guan, Antoni B. Chan, Liqiang Nie|<http://arxiv.org/pdf/2503.08367v1>|- 问题：遮挡，数据集限制，室内导航，复杂场景<br />- 方法：ECCD，ZECC，MLLM导航，正常线分析<br />- 效果：精度高，成本低|
|📝 更新|TransXNet: Learning Both Global and Local Dynamics with a Dual Dynamic Token Mixer for Visual Recognition|TransXNet：使用双重动态标记混合器学习全局和局部动态的视觉识别|Meng Lou, Shu Zhang, Hong-Yu Zhou, Chuan Wu, Sibei Yang, Yizhou Yu|<http://arxiv.org/pdf/2310.19380v3>|- 问题：动态适应，特征融合，表示能力<br />- 方法：D-Mixer，全局注意力，深度卷积<br />- 效果：性能提升，成本降低|
|🆕 发布|OLMD: Orientation-aware Long-term Motion Decoupling for Continuous Sign Language Recognition|OLMD：面向连续手语识别的感知方向长期运动解耦|Yiheng Yu, Sheng Liu, Yuan Feng, Min Xu, Zhelun Jin, Xuhua Yang|<http://arxiv.org/pdf/2503.08205v1>|- 问题：多方向运动，长期运动，识别精度低<br />- 方法：OLMD框架，LMA模块，运动解耦<br />- 效果：SOTA性能，WER降低|
|🆕 发布|Bring Remote Sensing Object Detect Into Nature Language Model: Using SFT Method|将遥感目标检测引入自然语言模型：使用SFT方法|Fei Wang, Chengcheng Chen, Hongyu Chen, Yugang Chang, Weiming Zeng|<http://arxiv.org/pdf/2503.08144v1>|- 问题：遥感图像检测，VLM理解挑战<br />- 方法：SFT，自然语言标注，指令微调<br />- 效果：有效检测，VQA能力|
|🆕 发布|SphOR: A Representation Learning Perspective on Open-set Recognition for Identifying Unknown Classes in Deep Learning Models|SphOR：深度学习模型中识别未知类别的开放集识别的表示学习视角|Nadarasar Bahavan, Sachith Seneviratne, Saman Halgamuge|<http://arxiv.org/pdf/2503.08049v1>|- 问题：开放集识别，未知类别识别，特征学习<br />- 方法：球形嵌入，von Mises-Fisher分布，语义模糊样本<br />- 效果：高效，性能提升，最先进结果|
|📝 更新|SweetTok: Semantic-Aware Spatial-Temporal Tokenizer for Compact Video Discretization|甜Tok：用于紧凑视频离散化的语义感知时空标记器|Zhentao Tan, Ben Xue, Jian Jia, Junhao Wang, Wencai Ye, Shaoyun Shi, Mingjie Sun, Wenjin Wu .etc.|<http://arxiv.org/pdf/2412.10443v3>|- 问题：视频离散化，压缩，语义信息<br />- 方法：SweetTok，DQAE，MLC<br />- 效果：压缩率提升，重建效果改善|
|🆕 发布|7ABAW-Compound Expression Recognition via Curriculum Learning|基于课程学习的复合表情识别|Chen Liu, Feng Qiu, Wei Zhang, Lincheng Li, Dadong Wang, Xin Yu|<http://arxiv.org/pdf/2503.07969v1>|[[代码]](<https://github.com/YenanLiu/ABAW7th.>)<br />- 问题：复合表情识别，数据稀缺，模型复杂<br />- 方法：课程学习，单表情预训练，动态生成<br />- 效果：最佳性能，F-score 0.6063|
|🆕 发布|STEAD: Spatio-Temporal Efficient Anomaly Detection for Time and Compute Sensitive Applications|时空高效异常检测：适用于时间和计算敏感应用的STEAD|Andrew Gao, Jun Liu|<http://arxiv.org/pdf/2503.07942v1>|[[代码]](<https://github.com/agao8/STEAD>)<br />- 问题：异常检测，时间敏感，计算敏感<br />- 方法：STEAD，(2+1)D卷积，Performer线性注意力<br />- 效果：高AUC，低参数，实时推理|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Frequency selection for the diagnostic characterization of human brain tumours|频率选择用于人类脑肿瘤的诊断特征化|Carlos Arizmendi, Alfredo Vellido, Enrique Romero|<http://arxiv.org/pdf/2503.08756v1>|- 问题：脑肿瘤诊断，磁共振，代谢信息，高维度<br />- 方法：频率选择，非线性分类，数据库分析<br />- 效果：诊断，肿瘤特征|
|🆕 发布|MINT-Demo: Membership Inference Test Demonstrator|MINT-Demo：成员身份推断测试演示器|Daniel DeAlcala, Aythami Morales, Julian Fierrez, Gonzalo Mancera, Ruben Tolosana, Ruben Vera-Rodriguez|<http://arxiv.org/pdf/2503.08332v1>|- 问题：透明度，机器学习训练，数据使用，识别<br />- 方法：MINT技术，实验验证，平台演示<br />- 效果：高准确率，透明度提升|


## 时序理解 (Temporal Understanding)


### 时序分析 (Temporal Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|QuoTA: Query-oriented Token Assignment via CoT Query Decouple for Long Video Comprehension|QuoTA：通过CoT查询解耦的面向查询的Token分配，用于长视频理解|Yongdong Luo, Wang Chen, Xiawu Zheng, Weizhong Huang, Shukang Yin, Haojia Lin, Chaoyou Fu, Jinfa Huang .etc.|<http://arxiv.org/pdf/2503.08689v1>|[[代码]](<https://github.com/MAC-AutoML/QuoTA.>)<br />- 问题：视觉冗余，语义关联，任务特定<br />- 方法：查询导向，CoT推理，模块化扩展<br />- 效果：性能提升，预算优化|
|📝 更新|ReTaKe: Reducing Temporal and Knowledge Redundancy for Long Video Understanding|ReTaKe：降低长视频理解中的时间和知识冗余|Xiao Wang, Qingyi Si, Jianlong Wu, Shiyu Zhu, Li Cao, Liqiang Nie|<http://arxiv.org/pdf/2412.20504v3>|[[代码]](<https://github.com/SCZwangxiao/video-ReTaKe>)<br />- 问题：长视频理解，时间冗余，知识冗余<br />- 方法：DPSelect，PivotKV，关键帧识别，知识缓存<br />- 效果：压缩率提升，性能损失小|


## 三维重建 (3D Reconstruction)


### 单目重建 (Monocular Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CDI3D: Cross-guided Dense-view Interpolation for 3D Reconstruction|CDI3D：用于3D重建的跨引导密集视图插值|Zhiyuan Wu, Xibin Song, Senbo Wang, Weizhe Liu, Jiayu Yang, Ziang Cheng, Shenzhou Chen, Taizhang Shang .etc.|<http://arxiv.org/pdf/2503.08005v2>|- 问题：3D重建，单视图，多视图一致性，模型不一致性<br />- 方法：CDI3D，密集视图插值，倾斜相机轨迹<br />- 效果：高质量，高效率，纹理几何|
|🆕 发布|GarmentCrafter: Progressive Novel View Synthesis for Single-View 3D Garment Reconstruction and Editing|服装工匠：单视图3D服装重建与编辑的渐进式新颖视图合成|Yuanhao Wang, Cheng Zhang, Gonçalo Frazão, Jinlong Yang, Alexandru-Eugen Ichim, Thabo Beeler, Fernando De la Torre|<http://arxiv.org/pdf/2503.08678v1>|- 问题：单视图3D服装重建，缺乏跨视图一致性<br />- 方法：渐进深度预测，图像扭曲，多视图扩散模型<br />- 效果：高视觉保真度，跨视图一致性|
|📝 更新|PanoDreamer: Optimization-Based Single Image to 360 3D Scene With Diffusion|PanoDreamer：基于优化的单张图像到360度3D场景的扩散|Avinash Paliwal, Xilong Zhou, Andrii Tsarov, Nima Khademi Kalantari|<http://arxiv.org/pdf/2412.04827v2>|- 问题：单图生成360°3D场景<br />- 方法：单图全景和深度估计，交替最小化策略<br />- 效果：一致性，整体质量|
|🆕 发布|MVD-HuGaS: Human Gaussians from a Single Image via 3D Human Multi-view Diffusion Prior|MVD-HuGaS：通过3D人体多视图扩散先验从单张图像中提取人类高斯分布|Kaiqiang Xiong, Ying Feng, Qi Zhang, Jianbo Jiao, Yang Zhao, Zhihao Liang, Huachen Gao, Ronggang Wang|<http://arxiv.org/pdf/2503.08218v1>|- 问题：单图3D重建，多视角扩散模型，不一致先验<br />- 方法：多视角扩散模型，对齐模块，深度人脸扭曲缓解<br />- 效果：高保真渲染，SOTA性能|


### 神经隐式重建 (Neural Implicit Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Acoustic Neural 3D Reconstruction Under Pose Drift|声学神经3D重建在姿态漂移下的应用|Tianxiang Lin, Mohamad Qadri, Kevin Zhang, Adithya Pediredla, Christopher A. Metzler, Michael Kaess|<http://arxiv.org/pdf/2503.08930v1>|- 问题：3D重建，姿态漂移，声学图像<br />- 方法：神经隐式表面，6DoF姿态参数化，梯度回传<br />- 效果：高保真，3D重建|
|🆕 发布|HessianForge: Scalable LiDAR reconstruction with Physics-Informed Neural Representation and Smoothness Energy Constraints|HessianForge：基于物理信息神经网络表示和平滑度能量约束的可扩展激光雷达重建|Hrishikesh Viswanath, Md Ashiqur Rahman, Chi Lin, Damon Conover, Aniket Bera|<http://arxiv.org/pdf/2503.08929v1>|[[代码]](<https://github.com/HrishikeshVish/HessianForge>)<br />- 问题：LiDAR重建，表面平滑性，噪声处理<br />- 方法：物理信息神经网络，平滑度能量约束，层次八叉树<br />- 效果：精度提升，平滑度改善|
|📝 更新|CAD-Recode: Reverse Engineering CAD Code from Point Clouds|CAD-Recode：从点云逆向工程CAD代码|Danila Rukhovich, Elona Dupont, Dimitrios Mallis, Kseniya Cherenkova, Anis Kacem, Djamila Aouada|<http://arxiv.org/pdf/2412.14042v2>|- 问题：3D CAD，点云，逆向工程<br />- 方法：Python代码表示，LLM解码，轻量投影<br />- 效果：性能提升，可解释性|
|📝 更新|Measuring the Discrepancy between 3D Geometric Models using Directional Distance Fields|测量3D几何模型之间的方向距离场差异|Siyu Ren, Junhui Hou, Xiaodong Chen, Hongkai Xiong, Wenping Wang|<http://arxiv.org/pdf/2401.09736v2>|[[代码]](<https://github.com/rsy6318/DirDist.>)<br />- 问题：3D模型差异度量，效率低，效果差<br />- 方法：方向距离场，DDF，模型对应<br />- 效果：高精度，泛化能力强|
|📝 更新|TROI: Cross-Subject Pretraining with Sparse Voxel Selection for Enhanced fMRI Visual Decoding|TROI：基于稀疏体素选择的跨主体预训练以增强fMRI视觉解码|Ziyu Wang, Tengyu Pan, Zhenyu Li, Ji Wu, Xiuxing Li, Jianyong Wang|<http://arxiv.org/pdf/2502.00412v2>|- 问题：fMRI视觉解码，ROI标注，冗余信息，噪声<br />- 方法：TROI，稀疏体素选择，预训练，学习率回溯<br />- 效果：性能超越MindEye2，效率提升|
|🆕 发布|Dynamic PET Image Reconstruction via Non-negative INR Factorization|动态正电子发射断层扫描（PET）图像重建通过非负INR分解|Chaozhi Zhang, Wenxiang Ding, Roy Y. He, Xiaoqun Zhang, Qiaoqiao Ding|<http://arxiv.org/pdf/2503.08025v1>|- 问题：动态PET图像重建，噪声投影数据<br />- 方法：非负隐式神经网络表示分解，低秩矩阵分解，神经网络表示<br />- 效果：连续表示，几何特征，浓度变化|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Deformable Linear Object Surface Placement Using Elastica Planning and Local Shape Control|可变形线性物体表面放置：基于Elastica规划和局部形状控制|I. Grinberg, A. Levin, E. D. Rimon|<http://arxiv.org/pdf/2503.08545v1>|- 问题：DLOs放置，约束环境，挑战<br />- 方法：Euler's elastica，ResNet，低级反馈<br />- 效果：恢复性，仿真实验|
|📝 更新|Associative Transformer|关联变换器|Yuwei Sun, Hideya Ochiai, Zhirong Wu, Stephen Lin, Ryota Kanai|<http://arxiv.org/pdf/2309.12862v4>|- 问题：稀疏注意力，参数效率，复杂关系推理<br />- 方法：关联Transformer，显式记忆，Hopfield能量函数<br />- 效果：参数减少，性能提升，超越SOTA|


### 多视图重建 (Multi-view Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Twinner: Shining Light on Digital Twins in a Few Snaps|Twinner：在几秒钟内照亮数字孪生的光芒|Jesus Zarzar, Tom Monnier, Roman Shapovalov, Andrea Vedaldi, David Novotny|<http://arxiv.org/pdf/2503.08382v1>|- 问题：数字孪生重建，光照恢复，几何与材质<br />- 方法：高效Transformer，全合成数据集，可微物理着色<br />- 效果：重建质量高，速度优|
|🆕 发布|Parametric Point Cloud Completion for Polygonal Surface Reconstruction|参数化点云补全用于多边形表面重建|Zhaiyu Chen, Yuqing Wang, Liangliang Nan, Xiao Xiang Zhu|<http://arxiv.org/pdf/2503.08363v1>|- 问题：点云补全，表面重建，数据不完整<br />- 方法：参数化补全，平面代理，高阶结构<br />- 效果：性能提升，新标准|
|🆕 发布|Explaining Human Preferences via Metrics for Structured 3D Reconstruction|通过结构化3D重建的指标解释人类偏好|Jack Langerman, Denys Rozumnyi, Yuzhong Huang, Dmytro Mishkin|<http://arxiv.org/pdf/2503.08208v1>|- 问题：3D重建评估，偏好度量，专家分析<br />- 方法：系统测试，上下文推荐，学习度量<br />- 效果：偏好解释，应用指导|
|🆕 发布|MVGSR: Multi-View Consistency Gaussian Splatting for Robust Surface Reconstruction|多视图一致性高斯分层用于鲁棒表面重建|Chenfeng Hou, Qi Xun Yeo, Mengqi Guo, Yongxin Su, Yanyan Li, Gim Hee Lee|<http://arxiv.org/pdf/2503.08093v1>|- 问题：3DGS，表面重建，动态物体，不一致性，伪影<br />- 方法：多视图一致性，Gaussian模型，干扰物掩码<br />- 效果：几何精度，渲染保真度|


## 神经渲染 (Neural Rendering)


### 神经辐射场 (Neural Radiance Fields)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|INPC: Implicit Neural Point Clouds for Radiance Field Rendering|隐式神经点云用于辐射场渲染|Florian Hahlbohm, Linus Franke, Moritz Kappel, Susana Castillo, Martin Eisemann, Marc Stamminger, Marcus Magnor|<http://arxiv.org/pdf/2403.16862v2>|- 问题：场景重建，视图合成，无边界场景<br />- 方法：隐式神经点云，八叉树概率场，多分辨率哈希网格<br />- 效果：图像质量高，交互式帧率|
|📝 更新|Enhancing Autonomous Navigation by Imaging Hidden Objects using Single-Photon LiDAR|利用单光子激光雷达成像隐藏物体以增强自主导航|Aaron Young, Nevindu M. Batagoda, Harry Zhang, Akshat Dave, Adithya Pediredla, Dan Negrut, Ramesh Raskar|<http://arxiv.org/pdf/2410.03555v2>|- 问题：自主导航，有限可见性，隐藏物体<br />- 方法：单光子LiDAR，NLOS成像，感知控制<br />- 效果：感知范围扩展，安全路径导航|
|🆕 发布|Mitigating Ambiguities in 3D Classification with Gaussian Splatting|利用高斯分层缓解3D分类中的歧义|Ruiqi Zhang, Hao Zhu, Jingyi Zhao, Qi Zhang, Xun Cao, Zhan Ma|<http://arxiv.org/pdf/2503.08352v1>|- 问题：3D分类，点云，表面类型，透明度，歧义<br />- 方法：高斯分层，特征表征，数据集构建<br />- 效果：歧义缓解，分类效果提升|
|🆕 发布|S3R-GS: Streamlining the Pipeline for Large-Scale Street Scene Reconstruction|S3R-GS：简化大规模街景重建的流程|Guangting Zheng, Jiajun Deng, Xiaomeng Chu, Yu Yuan, Houqiang Li, Yanyong Zhang|<http://arxiv.org/pdf/2503.08217v1>|- 问题：3DGS，大规模场景，重建成本高<br />- 方法：S3R-GS，简化流程，2D框替代3D框<br />- 效果：渲染质量提升，重建速度加快|
|🆕 发布|Dynamic Scene Reconstruction: Recent Advance in Real-time Rendering and Streaming|动态场景重建：实时渲染与流式传输的最新进展|Jiaxuan Zhu, Hao Tang|<http://arxiv.org/pdf/2503.08166v1>|- 问题：动态场景，2D图像，渲染，重建<br />- 方法：Neural Radiance Fields，3D Gaussian Splatting，数据集<br />- 效果：性能比较，挑战，未来方向|
|🆕 发布|ArticulatedGS: Self-supervised Digital Twin Modeling of Articulated Objects using 3D Gaussian Splatting|ArticulatedGS：基于3D高斯喷溅的自监督关节对象数字孪生建模|Junfu Guo, Yu Xin, Gaoyi Liu, Kai Xu, Ligang Liu, Ruizhen Hu|<http://arxiv.org/pdf/2503.08135v1>|- 问题：部分级重建，运动参数估计，数字孪生，3D-GS<br />- 方法：自监督学习，多视图，3D高斯分层<br />- 效果：高精度，高质量|
|🆕 发布|GigaSLAM: Large-Scale Monocular SLAM with Hierachical Gaussian Splats|吉加SLAM：大规模单目SLAM的分层高斯斑点|Kai Deng, Jian Yang, Shenlong Wang, Jin Xie|<http://arxiv.org/pdf/2503.08071v1>|- 问题：大规模单目SLAM，室内SLAM限制，无边界环境<br />- 方法：NeRF/3DGS，层次稀疏体素图，多级细节解码<br />- 效果：高精度跟踪，真实渲染|
|🆕 发布|NeRF-VIO: Map-Based Visual-Inertial Odometry with Initialization Leveraging Neural Radiance Fields|基于神经辐射场的初始化的地图视觉惯性里程计|Yanyu Zhang, Dongming Wang, Jie Xu, Mengyuan Liu, Pengxiang Zhu, Wei Ren|<http://arxiv.org/pdf/2503.07952v1>|- 问题：视觉惯性里程计，初始化，地图依赖<br />- 方法：NeRF初始化，多层感知器，损失函数重定义<br />- 效果：精度提升，效率提高|
|📝 更新|6DGS: Enhanced Direction-Aware Gaussian Splatting for Volumetric Rendering|6DGS：增强型方向感知高斯分层渲染用于体渲染|Zhongpai Gao, Benjamin Planche, Meng Zheng, Anwesa Choudhuri, Terrence Chen, Ziyan Wu|<http://arxiv.org/pdf/2410.04974v3>|[[代码]](<https://gaozhongpai.github.io/6dgs>)<br />- 问题：实时渲染，质量，方向感知，Gaussian Splatting<br />- 方法：6DGS，增强颜色，优化控制<br />- 效果：PSNR提升，点数减少|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CellStyle: Improved Zero-Shot Cell Segmentation via Style Transfer|单元格样式：通过风格迁移改进的无监督细胞分割|Rüveyda Yilmaz, Zhu Chen, Yuli Wu, Johannes Stegmaier|<http://arxiv.org/pdf/2503.08603v1>|- 问题：零样本细胞分割，数据域差异，标注稀缺<br />- 方法：风格迁移，零样本适应，属性转移<br />- 效果：性能提升，泛化能力强|


### 可控渲染 (Controllable Rendering)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PCGS: Progressive Compression of 3D Gaussian Splatting|PCGS：3D高斯分层渐进压缩|Yihang Chen, Mengyao Li, Qianyi Wu, Weiyao Lin, Mehrtash Harandi, Jianfei Cai|<http://arxiv.org/pdf/2503.08511v1>|[[代码]](<https://github.com/YihangChen-ee/PCGS.>)<br />- 问题：3DGS数据量大，压缩效率低<br />- 方法：渐进压缩，量化策略，概率预测<br />- 效果：渐进性，性能相当|
|🆕 发布|GAS-NeRF: Geometry-Aware Stylization of Dynamic Radiance Fields|GAS-NeRF：动态辐射场几何感知风格化|Nhat Phuong Anh Vu, Abhishek Saroha, Or Litany, Daniel Cremers|<http://arxiv.org/pdf/2503.08483v1>|- 问题：动态场景，风格化，几何特征，忽略<br />- 方法：GAS-NeRF，深度图，几何细节，外观转移<br />- 效果：风格化质量提升，时间一致性|
|🆕 发布|DyArtbank: Diverse Artistic Style Transfer via Pre-trained Stable Diffusion and Dynamic Style Prompt Artbank|DyArtbank：基于预训练的Stable Diffusion和动态风格提示的艺术银行实现多样化艺术风格迁移|Zhanjie Zhang, Quanwei Zhang, Guangyuan Li, Junsheng Luan, Mengyuan Yang, Yun Wang, Lei Zhao|<http://arxiv.org/pdf/2503.08392v1>|[[代码]](<https://github.com/Jamie-Cheung/DyArtbank>)<br />- 问题：风格迁移，一致性，多样性，数据不足<br />- 方法：DyArtbank，DSPA，KCFP<br />- 效果：多样化，高真实感|
|📝 更新|UniScene: Unified Occupancy-centric Driving Scene Generation|统一以占用为中心的驾驶场景生成：UniScene|Bohan Li, Jiazhe Guo, Hongsi Liu, Yingshuang Zou, Yikang Ding, Xiwu Chen, Hu Zhu, Feiyang Tan .etc.|<http://arxiv.org/pdf/2412.05435v2>|[[代码]](<https://arlo0o.github.io/uniscene>)<br />- 问题：数据生成，多样性，布局到数据，复杂场景<br />- 方法：统一框架，语义占用，渐进生成，联合渲染<br />- 效果：性能提升，下游任务受益|
|🆕 发布|HRAvatar: High-Quality and Relightable Gaussian Head Avatar|HRAvatar：高质量且可重光照的高斯头部头像|Dongbin Zhang, Yunfei Liu, Lijian Lin, Ye Zhu, Kangjie Chen, Minghan Qin, Yu Li, Haoqian Wang|<http://arxiv.org/pdf/2503.08224v1>|- 问题：单目视频，3D头像，实时性能，人脸跟踪，光照效果<br />- 方法：3DGS，端到端优化，学习变形模型，物理光照<br />- 效果：高保真，可重光照，真实感|
|🆕 发布|U-StyDiT: Ultra-high Quality Artistic Style Transfer Using Diffusion Transformers|U-StyDiT：基于扩散变换器的超高质量艺术风格迁移|Zhanjie Zhang, Ao Ma, Ke Cao, Jing Wang, Shanyuan Liu, Yuhang Ma, Bo Cheng, Dawei Leng .etc.|<http://arxiv.org/pdf/2503.08157v1>|- 问题：风格迁移，质量低，伪影，不和谐<br />- 方法：扩散模型，内容-风格解耦，MSM，StyDiT块<br />- 效果：高质量，艺术风格|
|📝 更新|Efficient Density Control for 3D Gaussian Splatting|高效三维高斯喷溅密度控制|Xiaobin Deng, Changyu Diao, Min Li, Ruohan Yu, Duanqing Xu|<http://arxiv.org/pdf/2411.10133v3>|[[代码]](<https://github.com/XiaoBin2001/EDC.>)<br />- 问题：3DGS效率低，优化慢，质量差<br />- 方法：长轴分割，恢复感知剪枝<br />- 效果：质量提升，泛化性能好|
|🆕 发布|7DGS: Unified Spatial-Temporal-Angular Gaussian Splatting|七维空间-时间-角度高斯分层渲染|Zhongpai Gao, Benjamin Planche, Meng Zheng, Anwesa Choudhuri, Terrence Chen, Ziyan Wu|<http://arxiv.org/pdf/2503.07946v1>|[[代码]](<https://gaozhongpai.github.io/7dgs>)<br />- 问题：动态场景实时渲染，视点依赖效果<br />- 方法：7D高斯分层，条件切片机制，联合优化<br />- 效果：PSNR提升，实时渲染|


### 场景编辑 (Scene Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AquaFuse: Waterbody Fusion for Physics Guided View Synthesis of Underwater Scenes|水体融合：水下场景物理引导视图合成的水体融合|Md Abu Bakr Siddique, Jiayi Wu, Ioannis Rekleitis, Md Jahidul Islam|<http://arxiv.org/pdf/2411.01119v2>|- 问题：水下场景合成，数据增强，几何一致性<br />- 方法：物理引导，水体融合，深度一致性<br />- 效果：深度一致性，结构相似性|


## 定位与映射 (Localization & Mapping)


### 视觉SLAM (Visual SLAM)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Keypoint Semantic Integration for Improved Feature Matching in Outdoor Agricultural Environments|室外农业环境中改进特征匹配的关键点语义集成|Rajitha de Silva, Jonathan Cox, Marija Popovic, Cesar Cadena, Cyrill Stachniss, Riccardo Polvara|<http://arxiv.org/pdf/2503.08843v1>|- 问题：视觉特征匹配，感知模糊，重复结构<br />- 方法：关键点语义集成，描述符增强，语义区域<br />- 效果：匹配精度提升，准确性改善|
|📝 更新|MITO: A Millimeter-Wave Dataset and Simulator for Non-Line-of-Sight Perception|MITO：用于非视距感知的毫米波数据集和模拟器|Laura Dodds, Tara Boroushaki, Cusuh Ham, Fadel Adib|<http://arxiv.org/pdf/2502.10259v3>|- 问题：非视距感知，毫米波，遮挡，分辨率低<br />- 方法：毫米波数据集，合成孔径，模拟工具<br />- 效果：高分辨率，NLOS感知，基准测试|
|🆕 发布|Keypoint Detection and Description for Raw Bayer Images|原始拜耳图像的关键点检测与描述|Jiakai Lin, Jinchang Zhang, Guoyu Lu|<http://arxiv.org/pdf/2503.08673v1>|- 问题：关键点检测，Bayer图像，SLAM，特征描述<br />- 方法：直接处理，原始图像，卷积核设计<br />- 效果：高精度，稳定性，资源高效|
|📝 更新|Bridge Frame and Event: Common Spatiotemporal Fusion for High-Dynamic Scene Optical Flow|桥梁框架与事件：高动态场景光流中的常见时空融合|Hanyu Zhou, Haonan Wang, Haoyue Liu, Yuxing Duan, Yi Chang, Luxin Yan|<http://arxiv.org/pdf/2503.06992v2>|- 问题：高动态场景光流，空间模糊，时间不连续<br />- 方法：共同潜在空间，视觉边界定位，运动相关性融合<br />- 效果：性能提升，可解释性|


### 语义建图 (Semantic Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Generating Robot Constitutions & Benchmarks for Semantic Safety|生成用于语义安全的机器人宪法与基准|Pierre Sermanet, Anirudha Majumdar, Alex Irpan, Dmitry Kalashnikov, Vikas Sindhwani|<http://arxiv.org/pdf/2503.08663v1>|- 问题：语义安全，机器人，VLMs风险<br />- 方法：ASIMOV Benchmark，宪法AI，自动修正<br />- 效果：高一致性，超越基线|
|🆕 发布|Talk2PC: Enhancing 3D Visual Grounding through LiDAR and Radar Point Clouds Fusion for Autonomous Driving|Talk2PC：通过激光雷达和雷达点云融合增强自动驾驶中的3D视觉定位|Runwei Guan, Jianan Liu, Ningwei Ouyang, Daizong Liu, Xiaolou Sun, Lianqing Zheng, Ming Xu, Yutao Yue .etc.|<http://arxiv.org/pdf/2503.08336v1>|- 问题：3D视觉定位，数据融合，自动驾驶<br />- 方法：TPCNet，多传感器融合，动态门控图融合<br />- 效果：性能领先，数据集表现|


### 位姿估计 (Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AthletePose3D: A Benchmark Dataset for 3D Human Pose Estimation and Kinematic Validation in Athletic Movements|运动员姿态3D：用于3D人体姿态估计和运动学验证的基准数据集|Calvin Yeung, Tomohiro Suzuki, Ryota Tanaka, Zhuoer Yin, Keisuke Fujii|<http://arxiv.org/pdf/2503.07499v2>|[[代码]](<https://github.com/calvinyeungck/AthletePose3D>)<br />- 问题：3D人体姿态估计，运动数据不足，速度加速度<br />- 方法：AthletePose3D数据集，模型微调，波形分析<br />- 效果：MPJPE降低，运动学验证|
|🆕 发布|Depth-Assisted Network for Indiscernible Marine Object Counting with Adaptive Motion-Differentiated Feature Encoding|深度辅助网络在自适应运动区分特征编码下实现不可辨认海洋目标计数|Chengzhi Ma, Kunqian Li, Shuaixin Liu, Han Mei|<http://arxiv.org/pdf/2503.08152v1>|[[代码]](<https://github.com/OUCVisionGroup/VIMOC-Net.>)<br />- 问题：水下物体计数，数据稀缺，可见度低，动态相似<br />- 方法：深度辅助网络，自适应运动区分特征编码<br />- 效果：性能提升，结果竞争|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visual Attention Graph|视觉注意力图|Kai-Fu Yang, Yong-Jie Li|<http://arxiv.org/pdf/2503.08531v1>|- 问题：视觉注意力编码，语义信息，注意力模式<br />- 方法：注意力图，语义扫描路径，注视密度计算<br />- 效果：注意力预测，认知状态评估|
|🆕 发布|Neural Network for Blind Unmixing: a novel MatrixConv Unmixing (MCU) Approach|神经网络在盲解混中的应用：一种新颖的MatrixConv解混（MCU）方法|Chao Zhou, Wei Pu, Miguel Rodrigues|<http://arxiv.org/pdf/2503.08745v1>|- 问题：HSI unmixing，物理意义，CNN不足<br />- 方法：MatrixConv Unmixing (MCU)，DIP技术，迭代求解<br />- 效果：物理意义，质量提升|
|🆕 发布|CQVPR: Landmark-aware Contextual Queries for Visual Place Recognition|CQVPR：视觉场景识别中的地标感知上下文查询|Dongyue Li, Daisuke Deguchi, Hiroshi Murase|<http://arxiv.org/pdf/2503.08170v1>|- 问题：地标识别，场景理解，视觉位置识别<br />- 方法：上下文查询，地标感知，查询匹配损失<br />- 效果：性能提升，场景理解增强|
|🆕 发布|HOTFormerLoc: Hierarchical Octree Transformer for Versatile Lidar Place Recognition Across Ground and Aerial Views|HOTFormerLoc：适用于地面和空中视图的多功能激光雷达位置识别的分层八叉树Transformer|Ethan Griffiths, Maryam Haghighat, Simon Denman, Clinton Fookes, Milad Ramezani|<http://arxiv.org/pdf/2503.08140v1>|[[代码]](<https://csiro-robotics.github.io/HOTFormerLoc>)<br />- 问题：3D地方识别，跨视角，点云数据<br />- 方法：层次八叉树，Transformer，多尺度注意力<br />- 效果：性能提升，数据集CS-Wild-Places|


## 自监督学习 (Self-supervised Learning)


### 对比学习 (Contrastive Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Attention Reallocation: Towards Zero-cost and Controllable Hallucination Mitigation of MLLMs|注意力重新分配：迈向零成本和可控的MLLM幻觉缓解|Chongjun Tu, Peng Ye, Dongzhan Zhou, Lei Bai, Gang Yu, Tao Chen, Wanli Ouyang|<http://arxiv.org/pdf/2503.08342v2>|- 问题：MLLMs幻觉，训练开销，注意力分配<br />- 方法：注意力重分配，视觉输入依赖，控制幻觉强度<br />- 效果：零成本，性能平衡|
|📝 更新|Polyhedra Encoding Transformers: Enhancing Diffusion MRI Analysis Beyond Voxel and Volumetric Embedding|多面体编码Transformer：超越体素和体积嵌入的扩散磁共振成像分析增强|Tianyuan Yao, Zhiyuan Li, Praitayini Kanakaraj, Derek B. Archer, Kurt Schilling, Lori Beason-Held, Susan Resnick, Bennett A. Landman .etc.|<http://arxiv.org/pdf/2501.13352v2>|- 问题：dMRI分析，深度学习，局限性<br />- 方法：PE-Transformer，球面信号处理，方向信息<br />- 效果：高精度，FOD，超越CNN和标准Transformer|
|📝 更新|STiL: Semi-supervised Tabular-Image Learning for Comprehensive Task-Relevant Information Exploration in Multimodal Classification|STiL：多模态分类中全面任务相关信息探索的半监督表格-图像学习|Siyi Du, Xinzhe Luo, Declan P. O'Regan, Chen Qin|<http://arxiv.org/pdf/2503.06277v2>|[[代码]](<https://github.com/siyi-wind/STiL.>)<br />- 问题：标签数据少，特征学习欠佳，模态信息缺失<br />- 方法：半监督学习，对比一致性，伪标签生成<br />- 效果：性能优于现有方法，信息探索全面|
|🆕 发布|RAG-Adapter: A Plug-and-Play RAG-enhanced Framework for Long Video Understanding|RAG-适配器：一种即插即用型RAG增强框架，用于长视频理解|Xichen Tan, Yunfan Ye, Yuanjing Luo, Qian Wan, Fang Liu, Zhiping Cai|<http://arxiv.org/pdf/2503.08576v1>|- 问题：长视频理解，信息损失，评估不准确<br />- 方法：RAG-Adapter，GCL，MMAT数据集<br />- 效果：准确度提升，性能优化|
|📝 更新|Reframing Dense Action Detection (RefDense): A Paradigm Shift in Problem Solving & a Novel Optimization Strategy|重新定义密集动作检测（RefDense）：问题解决范式转变与新型优化策略|Faegheh Sardari, Armin Mustafa, Philip J. B. Jackson, Adrian Hilton|<http://arxiv.org/pdf/2501.18509v2>|- 问题：密集动作检测，类别模糊，时间重叠<br />- 方法：子概念分解，子网络，对比学习损失<br />- 效果：性能提升，指标改善|
|🆕 发布|CL-MVSNet: Unsupervised Multi-view Stereo with Dual-level Contrastive Learning|CL-MVSNet：基于双级对比学习的无监督多视图立体视觉|Kaiqiang Xiong, Rui Peng, Zhe Zhang, Tianxing Feng, Jianbo Jiao, Feng Gao, Ronggang Wang|<http://arxiv.org/pdf/2503.08219v1>|- 问题：MVS，光测一致性，不可区分区域，视点依赖效应<br />- 方法：双级对比学习，图像级对比分支，场景级对比分支，L0.5光测一致性损失<br />- 效果：SOTA性能，超越监督方法|
|🆕 发布|Scale-Aware Pre-Training for Human-Centric Visual Perception: Enabling Lightweight and Generalizable Models|尺度感知的人中心视觉感知预训练：实现轻量化和泛化模型|Xuanhan Wang, Huimin Deng, Lianli Gao, Jingkuan Song|<http://arxiv.org/pdf/2503.08201v1>|- 问题：HVP模型泛化性差，模型尺寸大<br />- 方法：Scale-Aware Image Pretraining (SAIP)<br />- 效果：泛化能力强，性能提升|
|🆕 发布|A Theoretical Framework for Preventing Class Collapse in Supervised Contrastive Learning|监督对比学习中防止类别崩溃的理论框架|Chungpa Lee, Jeongheon Oh, Kibok Lee, Jy-yong Sohn|<http://arxiv.org/pdf/2503.08203v1>|- 问题：SupCL，类坍塌，损失平衡<br />- 方法：SSEM，嵌入模型，超参数分析<br />- 效果：预防坍塌，代表学习|
|🆕 发布|MaRI: Material Retrieval Integration across Domains|MaRI：跨领域材料检索集成|Jianhui Wang, Zhifei Yang, Yangfan He, Huixiong Zhang, Yuxuan Chen, Jingwei Huang|<http://arxiv.org/pdf/2503.08111v1>|- 问题：材料检索，数据稀缺，性能不足<br />- 方法：特征空间桥接，对比学习，多源数据集<br />- 效果：性能优越，泛化能力强|


### 一致性学习 (Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LiSu: A Dataset and Method for LiDAR Surface Normal Estimation|LiSu：激光雷达表面法线估计的数据集与方法|Dušan Malić, Christian Fruhwirth-Reisinger, Samuel Schulter, Horst Possegger|<http://arxiv.org/pdf/2503.08601v1>|- 问题：LiDAR表面正常估计，数据集，方法，鲁棒性<br />- 方法：LiSu数据集，时空特性，自训练，正则化<br />- 效果：性能提升，域适应|
|📝 更新|SemTalk: Holistic Co-speech Motion Generation with Frame-level Semantic Emphasis|SemTalk：基于帧级语义强调的全面共语音运动生成|Xiangyue Zhang, Jianfang Li, Jiaxu Zhang, Ziqiang Dang, Jianqiang Ren, Liefeng Bo, Zhigang Tu|<http://arxiv.org/pdf/2412.16563v3>|- 问题：Co-speech motion generation, semantic emphasis<br />- 方法：base motion learning, sparse motion learning, adaptive fusion<br />- 效果：state-of-the-art, high-quality, semantic richness|
|📝 更新|RealVVT: Towards Photorealistic Video Virtual Try-on via Spatio-Temporal Consistency|真实VVT：通过时空一致性实现逼真视频虚拟试穿|Siqi Li, Zhengkai Jiang, Jiawei Zhou, Zhihong Liu, Xiaowei Chi, Haoqian Wang|<http://arxiv.org/pdf/2501.08682v2>|- 问题：虚拟试穿，视频序列，服装一致性，动态人体姿态<br />- 方法：视频基础模型，时空一致性，注意力焦点损失，长视频处理<br />- 效果：超越现有模型，时尚电商，虚拟试衣|
|🆕 发布|Toward Stable World Models: Measuring and Addressing World Instability in Generative Environments|迈向稳定的全局模型：在生成环境中测量和解决全局不稳定性|Soonwoo Kwon, Jin-Young Kim, Hyojun Go, Kyungjune Baek|<http://arxiv.org/pdf/2503.08122v1>|- 问题：世界模型不稳定，内容丢失，学习噪声<br />- 方法：世界稳定性评估框架，逆操作检验<br />- 效果：揭示挑战，提升稳定性|
|📝 更新|F3D-Gaus: Feed-forward 3D-aware Generation on ImageNet with Cycle-Aggregative Gaussian Splatting|F3D-Gaus：基于ImageNet的循环聚合高斯喷溅的前馈3D感知生成|Yuxin Wang, Qianyi Wu, Dan Xu|<http://arxiv.org/pdf/2501.06714v3>|- 问题：3D感知生成，单目数据集，跨视角一致性<br />- 方法：F3D-Gaus，循环聚合高斯分层，视频模型先验<br />- 效果：高质量，多视角一致，效率提升|
|📝 更新|VACE: All-in-One Video Creation and Editing|VACE：一站式视频创作与编辑|Zeyinzi Jiang, Zhen Han, Chaojie Mao, Jingfeng Zhang, Yulin Pan, Yu Liu|<http://arxiv.org/pdf/2503.07598v2>|[[代码]](<https://ali-vilab.github.io/VACE-Page>)<br />- 问题：视频合成，编辑，一致性，挑战<br />- 方法：VACE，统一框架，视频条件单元，上下文适配器<br />- 效果：性能相当，多样化应用|


### 掩码自编码 (Masked Autoencoding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MotionAura: Generating High-Quality and Motion Consistent Videos using Discrete Diffusion|运动光环：利用离散扩散生成高质量且运动一致的视频|Onkar Susladkar, Jishu Sen Gupta, Chirag Sehgal, Sparsh Mittal, Rekha Singhal|<http://arxiv.org/pdf/2410.07659v2>|- 问题：视频处理，时空复杂度，压缩，生成，修复<br />- 方法：3D-MBQ-VAE，MotionAura，频域处理，Sketch Guided Inpainting<br />- 效果：SOTA性能，高质量视频|


## 迁移与适应 (Transfer & Adaptation)


### 元学习 (Meta Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|The JPEG Pleno Learning-based Point Cloud Coding Standard: Serving Man and Machine|JPEG Pleno学习基础点云编码标准：服务人与机器|André F. R. Guarda, Nuno M. M. Rodrigues, Fernando Pereira|<http://arxiv.org/pdf/2409.08130v2>|- 问题：点云编码效率，压缩，计算机视觉任务<br />- 方法：JPEG Pleno，深度学习，稀疏卷积神经网络<br />- 效果：效率提升，性能优于MPEG PCC，压缩率降低|
|🆕 发布|Zero-Shot Action Generalization with Limited Observations|基于有限观察的零样本动作泛化|Abdullah Alchihabi, Hanping Zhang, Yuhong Guo|<http://arxiv.org/pdf/2503.08867v1>|- 问题：零样本动作泛化，未见动作，数据限制<br />- 方法：动作表示学习，策略学习，合成动作表示<br />- 效果：超越现有方法，泛化能力强|
|📝 更新|Vision-R1: Incentivizing Reasoning Capability in Multimodal Large Language Models|视觉-R1：激励多模态大型语言模型中的推理能力|Wenxuan Huang, Bohan Jia, Zijie Zhai, Shaosheng Cao, Zheyu Ye, Fei Zhao, Zhe Xu, Yao Hu .etc.|<http://arxiv.org/pdf/2503.06749v2>|[[代码]](<https://github.com/Osilly/Vision-R1>)<br />- 问题：推理能力，多模态，数据稀缺<br />- 方法：CoT数据集，PTST，GRPO<br />- 效果：推理能力提升，准确率提高|
|🆕 发布|Towards Synthesized and Editable Motion In-Betweening Through Part-Wise Phase Representation|通过部分相位表示实现合成和可编辑的中间运动|Minyue Dai, Jingbo Wang, Ke Fan, Bin Ji, Haoyu Zhao, Junting Dong, Bo Dai|<http://arxiv.org/pdf/2503.08180v1>|- 问题：运动风格编码，肢体运动控制，风格多样性<br />- 方法：部分级相位表示，周期性自动编码器，运动流形学习<br />- 效果：动画连贯性，风格可控性，速度与泛化|
|📝 更新|Deep Clustering via Probabilistic Ratio-Cut Optimization|深度聚类通过概率比率割优化|Ayoub Ghriss, Claire Monteleoni|<http://arxiv.org/pdf/2502.03405v2>|- 问题：图割优化，聚类，在线学习<br />- 方法：概率建模，随机变量，PRCut<br />- 效果：性能提升，自监督学习|
|🆕 发布|Unifying Structure and Activation: A Comprehensive Approach of Parameter and Memory Efficient Transfer Learning|统一结构和激活：参数和内存高效迁移学习的全面方法|Tian Jin, Enjun Du, Changwei Wang, Wenhao Xu, Ding Luo|<http://arxiv.org/pdf/2503.08154v1>|- 问题：PETL，内存占用，参数规模<br />- 方法：S2A框架，激活模块，4-bit量化<br />- 效果：内存减少，参数减少，性能提升|
|🆕 发布|WISA: World Simulator Assistant for Physics-Aware Text-to-Video Generation|WISA：物理感知文本到视频生成的全球模拟助手|Jing Wang, Ao Ma, Ke Cao, Jun Zheng, Zhanjie Zhang, Jiasong Feng, Shanyuan Liu, Yuhang Ma .etc.|<http://arxiv.org/pdf/2503.08153v1>|[[代码]](<https://360cvgroup.github.io/WISA>)<br />- 问题：T2V模型物理理解，物理信息缺失，物理现象弱表示<br />- 方法：物理原理分解，MoPA注意力，物理分类器，WISA-32K数据集<br />- 效果：物理兼容性提升，VideoPhy基准改进|
|📝 更新|Deep Tensor Network|深度张量网络|Xuantao Li|<http://arxiv.org/pdf/2311.11091v2>|- 问题：神经网络，表达性，计算效率<br />- 方法：张量网络，注意力机制，张量操作<br />- 效果：效率提升，复杂交互建模|
|📝 更新|DaD: Distilled Reinforcement Learning for Diverse Keypoint Detection|DaD：用于多样化关键点检测的蒸馏强化学习|Johan Edstedt, Georg Bökman, Mårten Wadenbäck, Michael Felsberg|<http://arxiv.org/pdf/2503.07347v2>|[[代码]](<https://github.com/parskatt/dad>)<br />- 问题：关键点检测，SfM，非可微，依赖描述符<br />- 方法：自监督，无描述符，强化学习，平衡采样<br />- 效果：性能提升，SotA，公开代码|


### 域适应 (Domain Adaptation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Residual Learning and Filtering Networks for End-to-End Lossless Video Compression|残差学习和滤波网络用于端到端无损视频压缩|Md baharul Islam, Afsana Ahsan Jeny|<http://arxiv.org/pdf/2503.08819v1>|- 问题：运动估计误差，补偿结构不足，压缩误差<br />- 方法：残差学习，滤波网络，PReLU变换<br />- 效果：性能竞争，视频质量提升|
|🆕 发布|GBlobs: Explicit Local Structure via Gaussian Blobs for Improved Cross-Domain LiDAR-based 3D Object Detection|GBlobs：通过高斯Blob显式局部结构以改进跨域基于LiDAR的3D目标检测|Dušan Malić, Christian Fruhwirth-Reisinger, Samuel Schulter, Horst Possegger|<http://arxiv.org/pdf/2503.08639v1>|- 问题：跨域3D检测，领域泛化，全局特征依赖<br />- 方法：局部结构编码，高斯Blob，GBlobs<br />- 效果：性能提升，多源泛化|
|📝 更新|Going Beyond Conventional OOD Detection|超越传统异常检测|Sudarshan Regmi|<http://arxiv.org/pdf/2411.10794v3>|[[代码]](<https://github.com/sudarshanregmi/ASCOOD>)<br />- 问题：OOD检测，伪相关，细粒度分类<br />- 方法：虚拟异常合成，像素归因，标准化特征表示<br />- 效果：性能提升，泛化能力强|
|🆕 发布|Comparing Satellite Data for Next-Day Wildfire Predictability|比较卫星数据以提高次日野火预测能力|Justus Karlsson, Yonghao Xu, Amanda Berg, Leif Haglund|<http://arxiv.org/pdf/2503.08580v1>|[[代码]](<https://github.com/justuskarlsson/wildfire-mod14-vnp14>)<br />- 问题：卫星数据，火灾预测，MODIS，VIIRS，比较<br />- 方法：模型评估，火场掩码分析，机器学习<br />- 效果：VIIRS更优，MODIS改进|
|🆕 发布|1LoRA: Summation Compression for Very Low-Rank Adaptation|1LoRA：非常低秩自适应的求和压缩|Alessio Quercia, Zhuo Cao, Arya Bangun, Richard D. Paul, Abigail Morrison, Ira Assent, Hanno Scharr|<http://arxiv.org/pdf/2503.08333v1>|- 问题：低秩自适应，参数高效，内存高效<br />- 方法：1LoRA，特征求和，单可训练向量<br />- 效果：性能提升，参数减少，效率提高|
|🆕 发布|Feature Alignment with Equivariant Convolutions for Burst Image Super-Resolution|基于等变卷积的突发图像超分辨率特征对齐|Xinyi Liu, Feiyu Tan, Qi Xie, Qian Zhao, Deyu Meng|<http://arxiv.org/pdf/2503.08300v1>|- 问题：BISR对齐精度低，理论不足<br />- 方法：等变卷积，显式监督，特征域应用<br />- 效果：性能提升，视觉质量改善|
|📝 更新|A Bidirectional Long Short Term Memory Approach for Infrastructure Health Monitoring Using On-board Vibration Response|双向长短期记忆方法在利用车载振动响应进行基础设施健康监测中的应用|R. R. Samani, A. Nunez, B. De Schutter|<http://arxiv.org/pdf/2412.02643v2>|- 问题：基础设施健康监测，振动响应，参数估计<br />- 方法：LSTM特征提取，BiLSTM网络，帧分割<br />- 效果：精度高，自动识别，误差小|
|🆕 发布|Denoising via Repainting: an image denoising method using layer wise medical image repainting|基于层叠式医学图像重绘的降噪方法|Arghya Pal, Sailaja Rajanala, CheeMing Ting, Raphael Phan|<http://arxiv.org/pdf/2503.08094v1>|- 问题：医学图像去噪，诊断可靠性<br />- 方法：多尺度，贝塞尔路径重绘，结构保留<br />- 效果：PSNR提升，SSIM改善|
|🆕 发布|Trend-Aware Supervision: On Learning Invariance for Semi-Supervised Facial Action Unit Intensity Estimation|趋势感知监督：关于半监督面部动作单元强度估计的学习不变性|Yingjie Chen, Jiarui Zhang, Tao Wang, Yun Liang|<http://arxiv.org/pdf/2503.08078v1>|- 问题：半监督人脸动作单元强度估计，伪相关性，鲁棒性差<br />- 方法：趋势感知监督，Trend-Aware Supervision (TAS)<br />- 效果：性能提升，无额外成本|
|🆕 发布|AdaSCALE: Adaptive Scaling for OOD Detection|AdaSCALE：用于异常检测的自适应缩放|Sudarshan Regmi|<http://arxiv.org/pdf/2503.08023v1>|[[代码]](<https://github.com/sudarshanregmi/AdaSCALE>)<br />- 问题：OOD检测，激活塑造，样本特定缩放<br />- 方法：AdaSCALE，自适应缩放，OOD可能性估计<br />- 效果：性能提升，FPR@95降低|
|📝 更新|OccMamba: Semantic Occupancy Prediction with State Space Models|OccMamba：基于状态空间模型的语义占用预测|Heng Li, Yuenan Hou, Xiaohan Xing, Yuexin Ma, Xiao Sun, Yanyong Zhang|<http://arxiv.org/pdf/2408.09859v2>|[[代码]](<https://github.com/USTCLH/OccMamba.>)<br />- 问题：语义占用预测，Transformer，计算复杂度<br />- 方法：Mamba架构，层次模块，局部上下文处理器<br />- 效果：性能提升，开源|
|🆕 发布|Pre-trained Models Succeed in Medical Imaging with Representation Similarity Degradation|预训练模型在表示相似度退化的医学影像中取得成功|Wenqiang Zu, Shenghao Xie, Hao Chen, Lei Ma|<http://arxiv.org/pdf/2503.07958v1>|- 问题：跨域迁移学习，表示相似性，医学图像<br />- 方法：相似性空间框架，量化分析，线性相关性<br />- 效果：模型有效性，知识迁移，策略优化|
|🆕 发布|Learning Gentle Grasping Using Vision, Sound, and Touch|利用视觉、声音和触觉学习温和抓取|Ken Nakahara, Roberto Calandra|<http://arxiv.org/pdf/2503.07926v1>|- 问题：轻柔抓取，物体易损，视觉触觉听觉信号<br />- 方法：多模态输入，动作条件模型，预测稳定性<br />- 效果：准确率提升，抓取稳定|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|QUIET-SR: Quantum Image Enhancement Transformer for Single Image Super-Resolution|量子图像增强单图像超分辨率变换器：QUIET-SR|Siddhant Dutta, Nouhaila Innan, Khadijeh Najafi, Sadok Ben Yahia, Muhammad Shafique|<http://arxiv.org/pdf/2503.08759v1>|- 问题：SISR计算成本高，量子算法可扩展性差<br />- 方法：Swin Transformer，量子窗口注意力，变分量子神经网络<br />- 效果：PSNR和SSIM指标高，参数少|


### 增量学习 (Incremental Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Continual Learning for Multiple Modalities|持续学习多模态|Hyundong Jin, Eunwoo Kim|<http://arxiv.org/pdf/2503.08064v1>|- 问题：多模态，连续学习，知识遗忘<br />- 方法：模态聚合，自正则化，知识关联<br />- 效果：性能提升，泛化能力强|
|🆕 发布|Achieving More with Less: Additive Prompt Tuning for Rehearsal-Free Class-Incremental Learning|更少即更多：无需排练的类增量学习中的加性提示微调|Haoran Chen, Ping Wang, Zihan Zhou, Xu Zhang, Zuxuan Wu, Yu-Gang Jiang|<http://arxiv.org/pdf/2503.07979v1>|- 问题：CIL计算开销大，参数效率低<br />- 方法：共享提示，直接修改CLS token，添加提示<br />- 效果：计算复杂度降低，参数效率高|


## 鲁棒学习 (Robust Learning)


### 对抗攻击 (Adversarial Attack)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Birds look like cars: Adversarial analysis of intrinsically interpretable deep learning|鸟类看起来像汽车：内在可解释深度学习的对抗性分析|Hubert Baniecki, Przemyslaw Biecek|<http://arxiv.org/pdf/2503.08636v1>|- 问题：可解释性，对抗攻击，原型网络，视觉偏差<br />- 方法：对抗分析，原型操纵，后门攻击<br />- 效果：模型局限性，安全性质疑|
|🆕 发布|Adv-CPG: A Customized Portrait Generation Framework with Facial Adversarial Attacks|Adv-CPG：一种带有面部对抗攻击的定制肖像生成框架|Junying Wang, Hongyuan Zhang, Yuan Yuan|<http://arxiv.org/pdf/2503.08269v1>|- 问题：CPG，隐私保护，人脸识别<br />- 方法：Adv-CPG，面部对抗攻击，加密保护<br />- 效果：攻击成功率提升，隐私保护|
|📝 更新|MAGIC: Mastering Physical Adversarial Generation in Context through Collaborative LLM Agents|MAGIC：通过协作大型语言模型代理在上下文中掌握物理对抗生成|Yun Xing, Nhat Chung, Jie Zhang, Yue Cao, Ivor Tsang, Yang Liu, Lei Ma, Qing Guo|<http://arxiv.org/pdf/2412.08014v2>|- 问题：物理对抗攻击，视觉感知模型，场景多样性<br />- 方法：MAGIC框架，多模态LLM代理，协同生成<br />- 效果：有效攻击，场景适应|
|📝 更新|MIGA: Mutual Information-Guided Attack on Denoising Models for Semantic Manipulation|MIGA：基于互信息引导的语义操纵去噪模型攻击|Guanghao Li, Mingzhi Chen, Hao Yu, Shuting Dong, Wenhao Jiang, Ming Tang, Chun Yuan|<http://arxiv.org/pdf/2503.06966v2>|- 问题：对抗攻击，语义信息，去噪模型<br />- 方法：互信息引导攻击，语义相似度，对抗扰动<br />- 效果：语义篡改，鲁棒性评估|
|📝 更新|Towards Million-Scale Adversarial Robustness Evaluation With Stronger Individual Attacks|迈向百万规模对抗鲁棒性评估：更强的个体攻击|Yong Xie, Weijie Zheng, Hanxun Huang, Guangnan Ye, Xingjun Ma|<http://arxiv.org/pdf/2411.15210v4>|- 问题：大规模对抗鲁棒性评估，真实世界风险，白盒攻击<br />- 方法：概率间隔攻击（PMA），集成攻击，百万规模数据集<br />- 效果：性能提升，鲁棒性分析|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HierarQ: Task-Aware Hierarchical Q-Former for Enhanced Video Understanding|HierarQ：任务感知的分层Q-Former以增强视频理解|Shehreen Azad, Vibhav Vineet, Yogesh Singh Rawat|<http://arxiv.org/pdf/2503.08585v1>|- 问题：视频理解，帧采样，上下文长度限制<br />- 方法：任务感知，分层Q-Former，语言引导特征调制器<br />- 效果：性能提升，鲁棒高效|
|🆕 发布|Design and Implementation of FourCropNet: A CNN-Based System for Efficient Multi-Crop Disease Detection and Management|基于CNN的FourCropNet设计与实现：一种高效的多作物病害检测与管理系统|H. P. Khandagale, Sangram Patil, V. S. Gavali, S. V. Chavan, P. P. Halkarnikar, Prateek A. Meshram|<http://arxiv.org/pdf/2503.08348v1>|- 问题：多作物病害检测，效率，可扩展性<br />- 方法：残差块，注意力机制，轻量级层<br />- 效果：高准确率，泛化能力强|
|📝 更新|AtlasSeg: Atlas Prior Guided Dual-U-Net for Cortical Segmentation in Fetal Brain MRI|AtlasSeg：基于图谱先验的Dual-U-Net在胎儿脑MRI皮质分割中的应用|Haoan Xu, Tianshu Zheng, Xinyi Xu, Yao Shen, Jiwei Sun, Cong Sun, Guangbin Wang, Zhaopeng Cui .etc.|<http://arxiv.org/pdf/2411.02867v2>|- 问题：胎儿脑MRI分割，解剖变化，年龄特征<br />- 方法：AtlasSeg，双U-Net，图谱先验，多尺度注意力<br />- 效果：高Dice系数，早晚期改善，鲁棒性强|
|🆕 发布|BUFFER-X: Towards Zero-Shot Point Cloud Registration in Diverse Scenes|BUFFER-X：迈向多样化场景中的零样本点云配准|Minkyun Seo, Hyungtae Lim, Kanghee Lee, Luca Carlone, Jaesik Park|<http://arxiv.org/pdf/2503.07940v1>|[[代码]](<https://github.com/MIT-SPARK/BUFFER-X.>)<br />- 问题：点云注册泛化能力差，依赖特定环境参数，鲁棒性低<br />- 方法：自适应体素大小，远点采样，尺度归一化<br />- 效果：零样本泛化，无需参数调整|


### 对抗训练 (Adversarial Training)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Robust Latent Matters: Boosting Image Generation with Sampling Error|鲁棒潜在主题：通过采样误差提升图像生成|Kai Qiu, Xiang Li, Jason Kuen, Hao Chen, Xiaohao Xu, Jiuxiang Gu, Yinyi Luo, Bhiksha Raj .etc.|<http://arxiv.org/pdf/2503.08354v1>|[[代码]](<https://github.com/lxa9867/ImageFolder.>)<br />- 问题：图像生成质量，tokenizer性能评估<br />- 方法：采样误差模拟，tokenizer训练方案，pFID指标<br />- 效果：生成质量提升，收敛速度加快|
|🆕 发布|Generalized Kullback-Leibler Divergence Loss|广义Kullback-Leibler散度损失|Jiequan Cui, Beier Zhu, Qingshan Xu, Zhuotao Tian, Xiaojuan Qi, Bei Yu, Hanwang Zhang, Richang Hong|<http://arxiv.org/pdf/2503.08038v1>|[[代码]](<https://github.com/jiequancui/DKL.>)<br />- 问题：KL损失局限性，优化挑战，样本偏差<br />- 方法：DKL分解，权重函数优化，引入全局信息<br />- 效果：对抗鲁棒性提升，知识蒸馏性能增强|


### 对抗防御 (Adversarial Defense)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Adversarial Guided Diffusion Models for Adversarial Purification|对抗引导的扩散模型用于对抗净化|Guang Lin, Zerui Tao, Jianhai Zhang, Toshihisa Tanaka, Qibin Zhao|<http://arxiv.org/pdf/2403.16067v5>|- 问题：对抗净化，语义信息，误分类<br />- 方法：对抗引导，扩散模型，辅助神经网络<br />- 效果：鲁棒性增强，准确率提升|
|🆕 发布|AG-VPReID: A Challenging Large-Scale Benchmark for Aerial-Ground Video-based Person Re-Identification|AG-VPReID：基于空中-地面视频的人体重识别的挑战性大规模基准|Huy Nguyen, Kien Nguyen, Akila Pemasiri, Feng Liu, Sridha Sridharan, Clinton Fookes|<http://arxiv.org/pdf/2503.08121v1>|[[代码]](<https://github.com/agvpreid25/AG-VPReID-Net.>)<br />- 问题：跨平台视频ReID，视角不变性，大规模数据集<br />- 方法：AG-VPReID-Net，时空流，外观流，多尺度注意力<br />- 效果：性能提升，泛化能力强|
|🆕 发布|FairDeFace: Evaluating the Fairness and Adversarial Robustness of Face Obfuscation Methods|公平DeFace：评估人脸模糊方法的公平性和对抗鲁棒性|Seyyed Mohammad Sadegh Moosavi Khorzooghi, Poojitha Thota, Mohit Singhal, Abolfazl Asudeh, Gautam Das, Shirin Nilizadeh|<http://arxiv.org/pdf/2503.08731v1>|- 问题：公平性，鲁棒性，人脸模糊，评估框架<br />- 方法：FairDeFace，数据基准，对抗模型<br />- 效果：全面评估，发现偏差，可视化分析|


## 模型压缩加速 (Model Compression & Acceleration)


### 知识蒸馏 (Knowledge Distillation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Continual Distillation Learning: Knowledge Distillation in Prompt-based Continual Learning|持续蒸馏学习：基于提示的持续学习中的知识蒸馏|Qifan Zhang, Yunhui Guo, Yu Xiang|<http://arxiv.org/pdf/2407.13911v3>|- 问题：知识蒸馏，持续学习，性能提升<br />- 方法：知识蒸馏基于提示，插入提示<br />- 效果：效率提高，性能增强|
|🆕 发布|LightGen: Efficient Image Generation through Knowledge Distillation and Direct Preference Optimization|LightGen：通过知识蒸馏和直接偏好优化实现高效图像生成|Xianfeng Wu, Yajing Bai, Haoze Zheng, Harold Haodong Chen, Yexin Liu, Zihao Wang, Xuran Ma, Wen-Jie Shu .etc.|<http://arxiv.org/pdf/2503.08619v1>|[[代码]](<https://github.com/XianfengWu01/LightGen>)<br />- 问题：数据依赖，模型复杂，计算资源限制<br />- 方法：知识蒸馏，DPO优化，轻量级架构<br />- 效果：效率提升，质量相当|
|🆕 发布|Disentangled World Models: Learning to Transfer Semantic Knowledge from Distracting Videos for Reinforcement Learning|解耦世界模型：学习从干扰视频中迁移语义知识以用于强化学习|Qi Wang, Zhipeng Zhang, Baao Xie, Xin Jin, Yunbo Wang, Shiyu Wang, Liaomo Zheng, Xiaokang Yang .etc.|<http://arxiv.org/pdf/2503.08751v1>|- 问题：低样本效率，无先验知识，语义知识转移<br />- 方法：离线到在线潜热蒸馏，灵活解耦约束，可解释模型<br />- 效果：知识迁移，表现优越|
|📝 更新|Co-learning Single-Step Diffusion Upsampler and Downsampler with Two Discriminators and Distillation|协同学习带两个判别器和蒸馏的单步扩散上采样器和下采样器|Sohwi Kim, Tae-Kyun Kim|<http://arxiv.org/pdf/2410.07663v3>|- 问题：超分辨率，降采样，图像重建<br />- 方法：共学习框架，单步扩散，可学习降采样<br />- 效果：性能提升，效率提高|
|🆕 发布|Structural and Statistical Texture Knowledge Distillation and Learning for Segmentation|结构统计纹理知识蒸馏与学习用于分割|Deyi Ji, Feng Zhao, Hongtao Lu, Feng Wu, Jieping Ye|<http://arxiv.org/pdf/2503.08043v1>|- 问题：低级纹理信息，语义分割，知识蒸馏<br />- 方法：结构统计纹理知识蒸馏，CDM，TIEM，QDL<br />- 效果：性能提升，SOTA|
|📝 更新|T2VEval: Benchmark Dataset and Objective Evaluation Method for T2V-generated Videos|T2VEval：T2V生成视频的基准数据集和客观评估方法|Zelu Qi, Ping Shi, Shuqi Wang, Chaoyang Zhang, Fei Zhao, Zefeng Ying, Da Pan, Xi Yang .etc.|<http://arxiv.org/pdf/2501.08545v5>|- 问题：T2V视频质量评估，主观性，复杂扭曲<br />- 方法：T2VEval-Bench，多维度评估，多分支融合<br />- 效果：性能领先，综合评估|
|🆕 发布|Efficient Dataset Distillation through Low-Rank Space Sampling|通过低秩空间采样实现高效的数据库蒸馏|Hangyang Kong, Wenbo Zhou, Xuxiang He, Xiaotong Tu, Xinghao Ding|<http://arxiv.org/pdf/2503.07998v1>|- 问题：数据冗余，泛化能力差，计算负担重<br />- 方法：低秩空间采样，匹配训练轨迹<br />- 效果：信息冗余最小化，性能提升9.9%|


### 量化优化 (Quantization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SSVQ: Unleashing the Potential of Vector Quantization with Sign-Splitting|SSVQ：利用符号分割释放向量量化的潜力|Shuaiting Li, Juncan Deng, Chenxuan Wang, Kedong Xu, Rongtao Deng, Hong Gu, Haibin Shen, Kejie Huang|<http://arxiv.org/pdf/2503.08668v1>|- 问题：VQ压缩，微调限制，方向错误<br />- 方法：SSVQ，解耦符号位，联合优化<br />- 效果：压缩-精度提升，硬件加速|
|📝 更新|Q-PETR: Quant-aware Position Embedding Transformation for Multi-View 3D Object Detection|Q-PETR：多视角3D目标检测的量化感知位置嵌入变换|Jiangyong Yu, Changyong Shu, Dawei Yang, Sifan Zhou, Zichen Yu, Xing Hu, Yan Chen|<http://arxiv.org/pdf/2502.15488v2>|- 问题：3D检测精度下降，量化，多视图<br />- 方法：位置编码转换，自适应量化策略，跨注意力机制<br />- 效果：性能下降<1%，速度提升2倍，内存减少3倍|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Data Aggregation Visualization System supported by Processing-in-Memory|基于内存处理的数据聚合可视化系统|Junyoung Kim, Madhulika Balakumar, Kenneth Ross|<http://arxiv.org/pdf/2503.08463v1>|- 问题：数据可视化，聚合查询，频率归一化<br />- 方法：DIVAN系统，PIM架构，数据归一化<br />- 效果：可视化效率高，计算速度快|


### 网络剪枝 (Network Pruning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Faster Vision Mamba is Rebuilt in Minutes via Merged Token Re-training|更快视觉Mamba通过合并令牌再训练在几分钟内重建|Mingjia Shi, Yuhao Zhou, Ruiji Yu, Zekai Li, Zhiyuan Liang, Xuanlei Zhao, Xiaojiang Peng, Shanmukha Ramakrishna Vedantam .etc.|<http://arxiv.org/pdf/2412.12496v3>|- 问题：效率提升，信息保留，性能退化<br />- 方法：合并Token，快速重训练，R-MeeTo框架<br />- 效果：精度损失小，速度提升|


## 泛化与鲁棒性 (Generalization & Robustness)


### 不确定性建模 (Uncertainty Modeling)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Segmentation-Guided CT Synthesis with Pixel-Wise Conformal Uncertainty Bounds|基于像素级正则不确定性界限的CT合成引导分割|David Vallmanya Poch, Yorick Estievenart, Elnura Zhalieva, Sukanya Patra, Mohammad Yaqub, Souhaib Ben Taieb|<http://arxiv.org/pdf/2503.08515v1>|- 问题：CT图像质量，剂量计算，CBCT，不确定性<br />- 方法：STF-RUE，分割引导，像素级不确定性<br />- 效果：翻译精度提升，不确定性量化|


### 域泛化 (Domain Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Make-It-Animatable: An Efficient Framework for Authoring Animation-Ready 3D Characters|制作动画化：制作动画准备3D角色的有效框架|Zhiyang Guo, Jinxu Xiang, Kai Ma, Wengang Zhou, Houqiang Li, Ran Zhang|<http://arxiv.org/pdf/2411.18197v3>|[[代码]](<https://jasongzy.github.io/Make-It-Animatable>)<br />- 问题：手动动画制作，骨骼绑定，皮肤贴图，泛化能力差<br />- 方法：数据驱动，形状自动编码器，粗细表示，结构感知建模<br />- 效果：快速，高质量，泛化性强|


## 可解释性 (Interpretability)


### 归因分析 (Attribution Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Beyond Subspace Isolation: Many-to-Many Transformer for Light Field Image Super-resolution|超越子空间隔离：多对多Transformer用于光场图像超分辨率|Zeke Zexi Hu, Xiaoming Chen, Vera Yuk Ying Chung, Yiran Shen|<http://arxiv.org/pdf/2401.00740v2>|- 问题：LFSR，特征提取，子空间隔离<br />- 方法：Many-to-Many Transformer，空间-角信息聚合，自注意力机制<br />- 效果：性能提升，非局部上下文|
|🆕 发布|i-WiViG: Interpretable Window Vision GNN|i-WiViG：可解释窗口视觉图神经网络|Ivica Obadic, Dmitry Kangin, Dario Oliveira, Plamen P Angelov, Xiao Xiang Zhu|<http://arxiv.org/pdf/2503.08321v1>|- 问题：黑盒模型，解释性，远程感知<br />- 方法：窗口图处理，自解释瓶颈，子图识别<br />- 效果：性能竞争，解释忠实，解释稀疏|
|📝 更新|Gaussian Smoothing in Saliency Maps: The Stability-Fidelity Trade-Off in Neural Network Interpretability|高斯平滑在显著性图中的应用：神经网络可解释性中的稳定性-保真度权衡|Zhuorui Ye, Farzan Farnia|<http://arxiv.org/pdf/2411.05837v2>|- 问题：梯度图稳定性，随机性，解释性<br />- 方法：Gaussian smoothing，算法稳定性框架，理论界限<br />- 效果：稳定性提升，保真度降低|


### 概念解释 (Concept Explanation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Prototype-Based Multiple Instance Learning for Gigapixel Whole Slide Image Classification|基于原型的多实例学习在吉像素全切片图像分类中的应用|Susu Sun, Dominique van Midden, Geert Litjens, Christian F. Baumgartner|<http://arxiv.org/pdf/2503.08384v1>|[[代码]](<https://github.com/ss-sun/ProtoMIL.>)<br />- 问题：MIL模型可解释性差，缺乏人机交互<br />- 方法：原型MIL，稀疏自编码器，概念表示<br />- 效果：性能相当，解释直观|
|📝 更新|GRADE: Quantifying Sample Diversity in Text-to-Image Models|GRADE：量化文本到图像模型中的样本多样性|Royi Rassin, Aviv Slobodkin, Shauli Ravfogel, Yanai Elazar, Yoav Goldberg|<http://arxiv.org/pdf/2410.22592v2>|- 问题：样本多样性，文本到图像模型，同质性<br />- 方法：GRADE，世界知识，熵<br />- 效果：多样性量化，模型同质|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Cross-Modal Few-Shot Learning: a Generative Transfer Learning Framework|跨模态小样本学习：一种生成式迁移学习框架|Zhengwei Yang, Yuke Li, Qiang Sun, Basura Fernando, Heng Huang, Zheng Wang|<http://arxiv.org/pdf/2410.10663v2>|- 问题：多模态，少样本，识别<br />- 方法：生成式迁移学习，跨模态共享概念<br />- 效果：性能领先，多模态数据|


## 医学影像分析 (Medical Image Analysis)


### 医学分割 (Medical Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|On the status of current quantum machine learning software|当前量子机器学习软件的现状|Manish K. Gupta, Tomasz Rybotycki, Piotr Gawron|<http://arxiv.org/pdf/2503.08962v1>|- 问题：量子机器学习软件，软件限制，NISQ设备<br />- 方法：卫星图像分割，混合模型，成本分析<br />- 效果：模型质量变化，成本评估|
|📝 更新|Automated Retinal Layer and Fluid Segmentation and Cross-sectional Analysis using Spectral Domain Optical Coherence Tomography Images for Diabetic Retinopathy|基于光谱域光学相干断层扫描图像的糖尿病视网膜病变视网膜层和液体自动分割及横断面分析|S. Chen, D. Ma, M. Raviselvan, S. Sundaramoorthy, K. Popuri, M. J. Ju, M. V. Sarunic, D. Ratra .etc.|<http://arxiv.org/pdf/2503.01248v2>|- 问题：糖尿病视网膜病变，自动分割，厚度分析<br />- 方法：深度神经网络，SwinUNETR，VM-Unet<br />- 效果：准确率高，临床应用|
|🆕 发布|Integration of nested cross-validation, automated hyperparameter optimization, high-performance computing to reduce and quantify the variance of test performance estimation of deep learning models|深度学习模型测试性能估计方差降低与量化：嵌套交叉验证、自动超参数优化与高性能计算集成|Paul Calle, Averi Bates, Justin C. Reynolds, Yunlong Liu, Haoyang Cui, Sinaro Ly, Chen Wang, Qinghao Zhang .etc.|<http://arxiv.org/pdf/2503.08589v1>|- 问题：测试性能估计方差，模型可信度低<br />- 方法：NACHOS，NCV，AHPO，HPC<br />- 效果：方差降低，模型可信度提升|
|📝 更新|Deformable Mamba for Wide Field of View Segmentation|可变形Mamba用于宽视场分割|Jie Hu, Junwei Zheng, Jiale Wei, Jiaming Zhang, Rainer Stiefelhagen|<http://arxiv.org/pdf/2411.16481v2>|- 问题：Mamba解码器，宽场图像分割，性能退化<br />- 方法：可变形Mamba解码器，自适应扭曲感知<br />- 效果：性能提升，参数减少，FLOPs降低|
|📝 更新|Prediction of Frozen Region Growth in Kidney Cryoablation Intervention Using a 3D Flow-Matching Model|基于3D流匹配模型的肾脏冷冻消融干预中冷冻区生长预测|Siyeop Yoon, Yujin Oh, Matthew Tivnan, Sifan Song, Pengfei Jin, Sekeun Kim, Hyun Jin Cho, Dufan Wu .etc.|<http://arxiv.org/pdf/2503.04966v2>|- 问题：冷冻消融，冰球预测，手术指导<br />- 方法：3D流匹配模型，CT成像，变形场学习<br />- 效果：IoU 0.61，Dice 0.75，实时指导|
|🆕 发布|TrackOcc: Camera-based 4D Panoptic Occupancy Tracking|TrackOcc：基于相机的4D全景占用跟踪|Zhuoguang Chen, Kenan Li, Xiuyu Yang, Tao Jiang, Yiming Li, Hang Zhao|<http://arxiv.org/pdf/2503.08471v1>|[[代码]](<https://github.com/Tsinghua-MARS-Lab/TrackOcc.>)<br />- 问题：动态场景理解，3D跟踪，语义预测，时空一致性<br />- 方法：4D Panoptic Tracking，TrackOcc，流式处理<br />- 效果：Waymo数据集，SOTA性能|
|📝 更新|Surgical SAM 2: Real-time Segment Anything in Surgical Video by Efficient Frame Pruning|手术SAM 2：通过高效帧剪枝在手术视频中实现实时分割任何东西|Haofeng Liu, Erli Zhang, Junde Wu, Mingxuan Hong, Yueming Jin|<http://arxiv.org/pdf/2408.07931v2>|[[代码]](<https://github.com/jinlab-imvr/Surgical-SAM-2.>)<br />- 问题：手术视频分割，效率低，计算量大<br />- 方法：SAM2，帧剪枝，EFP机制<br />- 效果：实时分割，性能提升|
|📝 更新|CrackESS: A Self-Prompting Crack Segmentation System for Edge Devices|CrackESS：边缘设备自提示裂缝分割系统|Yingchu Wang, Ji He, Shijie Yu|<http://arxiv.org/pdf/2412.07205v3>|- 问题：裂缝检测，边缘设备，效率，精度<br />- 方法：YOLOv8，LoRA，CMRM<br />- 效果：性能提升，应用可行|
|🆕 发布|nnInteractive: Redefining 3D Promptable Segmentation|nnInteractive：重新定义3D可提示分割|Fabian Isensee, Maximilian Rokuss, Lars Krämer, Stefan Dinkelacker, Ashis Ravindran, Florian Stritzke, Benjamin Hamm, Tassilo Wald .etc.|<http://arxiv.org/pdf/2503.08373v1>|[[代码]](<https://github.com/MIC-DKFZ/napari-nninteractive>)<br />- 问题：3D分割，交互性，适应性，集成，可用性<br />- 方法：3D交互，多提示，2D交互，开放集<br />- 效果：精度新标准，集成，易用|
|🆕 发布|3D Medical Imaging Segmentation on Non-Contrast CT|非对比CT上的3D医学图像分割|Canxuan Gang, Yuhan Peng|<http://arxiv.org/pdf/2503.08361v1>|- 问题：非对比CT图像分割，语义标注，全局上下文建模<br />- 方法：CNN-Transformer混合，nnUNet，自监督/对比预训练<br />- 效果：性能领先，长尾问题解决|
|🆕 发布|Pathology-Aware Adaptive Watermarking for Text-Driven Medical Image Synthesis|病理感知自适应水印用于文本驱动医学图像合成|Chanyoung Kim, Dayun Ju, Jinyeong Kim, Woojung Han, Roberto Alcover-Couso, Seong Jae Hwang|<http://arxiv.org/pdf/2503.08346v1>|- 问题：医疗图像合成，水印，误用，诊断<br />- 方法：病理感知，自适应，水印强度调整<br />- 效果：诊断完整性，水印鲁棒性|
|📝 更新|To which reference class do you belong? Measuring racial fairness of reference classes with normative modeling|您属于哪个参考类别？使用规范性模型衡量参考类别的种族公平性|Saige Rutherford, Thomas Wolfers, Charlotte Fraza, Nathaniel G. Harnett, Christian F. Beckmann, Henricus G. Ruhe, Andre F. Marquand|<http://arxiv.org/pdf/2407.19114v2>|- 问题：种族公平性，参考类，临床解释，偏差，数据偏差<br />- 方法：规范建模，种族预测，多变量分析<br />- 效果：揭示种族差异，提高模型公平性|
|🆕 发布|SegDesicNet: Lightweight Semantic Segmentation in Remote Sensing with Geo-Coordinate Embeddings for Domain Adaptation|SegDesicNet：基于地理坐标嵌入的轻量级遥感语义分割与领域自适应|Sachin Verma, Frank Lindseth, Gabriel Kiss|<http://arxiv.org/pdf/2503.08290v1>|- 问题：语义分割，领域适应性，遥感图像<br />- 方法：地理坐标嵌入，球面编码，SegDesicNet模块<br />- 效果：MIoU提升，参数减少|
|🆕 发布|Towards All-in-One Medical Image Re-Identification|迈向一站式医学图像重识别|Yuan Tian, Kaiyuan Ji, Rongzhao Zhang, Yankai Jiang, Chunyi Li, Xiaosong Wang, Guangtao Zhai|<http://arxiv.org/pdf/2503.08173v1>|[[代码]](<https://github.com/tianyuan168326/All-in-One-MedReID-Pytorch>)<br />- 问题：MedReID，个性化医疗，隐私保护<br />- 方法：ComPA，模态适配，医学先验<br />- 效果：性能优越，应用广泛|
|📝 更新|PerSense: Personalized Instance Segmentation in Dense Images|个性化密集图像实例分割：PerSense|Muhammad Ibraheem Siddiqui, Muhammad Umer Sheikh, Hassan Abid, Muhammad Haris Khan|<http://arxiv.org/pdf/2405.13518v3>|- 问题：个性化实例分割，密集场景，遮挡，尺度变化，背景杂乱<br />- 方法：IDM，PPSM，模型无关，反馈机制，PerSense-D<br />- 效果：精度提升，适应性强|
|📝 更新|Enhancing Prohibited Item Detection through X-ray-Specific Augmentation and Contextual Feature Integration|通过X射线特定增强和上下文特征整合提升违禁物品检测|Renshuai Tao, Haoyu Wang, Wei Wang, Yunchao Wei, Yao Zhao|<http://arxiv.org/pdf/2411.18078v2>|- 问题：X射线检测，长尾分布，特征缺失<br />- 方法：X射线增强，上下文特征整合<br />- 效果：性能提升，SoTA超越|
|🆕 发布|Deep Perceptual Enhancement for Medical Image Analysis|深度感知增强用于医学图像分析|S M A Sharif, Rizwan Ali Naqvi, Mithun Biswas, Woong-Kee Loh|<http://arxiv.org/pdf/2503.08027v1>|[[代码]](<https://github.com/sharif-apu/DPE_JBHI>)<br />- 问题：低质量医学图像，诊断困难<br />- 方法：深度学习，感知增强，全卷积网络<br />- 效果：PSNR提升，DeltaE改善|
|📝 更新|End-to-End Action Segmentation Transformer|端到端动作分割Transformer|Tieqiao Wang, Sinisa Todorovic|<http://arxiv.org/pdf/2503.06316v2>|- 问题：预计算帧特征，缺乏动作建模，动作分割<br />- 方法：EAST，高效适配器，分割检测框架，动作提议数据增强<br />- 效果：SOTA性能，GTEA，50Salads|
|🆕 发布|DiffEGG: Diffusion-Driven Edge Generation as a Pixel-Annotation-Free Alternative for Instance Annotation|DiffEGG：基于扩散驱动的边缘生成，作为无像素标注的实例标注替代方案|Sanghyun Jo, Ziseok Lee, Wooyeol Lee, Kyungsu Kim|<http://arxiv.org/pdf/2503.07982v1>|[[代码]](<https://github.com/shjo-april/DiffEGG.>)<br />- 问题：精确分割，标注成本高，边界模糊<br />- 方法：DiffEGG，RIP，无标注<br />- 效果：AP提升，PQ提升|


### 疾病诊断 (Disease Diagnosis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Are ECGs enough? Deep learning classification of cardiac anomalies using only electrocardiograms|心电图是否足够？仅使用心电图进行心脏异常的深度学习分类|Joao D. S. Marques, Arlindo L. Oliveira|<http://arxiv.org/pdf/2503.08960v1>|[[代码]](<https://github.com/joaodsmarques/Are-ECGs-enough-Deep-Learning-Classifiers>)<br />- 问题：ECG分析，心脏异常诊断，数据集限制，模型泛化<br />- 方法：神经网络架构，迁移学习，学习策略优化<br />- 效果：学习效率提升，预测性能改善|
|🆕 发布|Generalizable and Explainable Deep Learning for Medical Image Computing: An Overview|通用且可解释的深度学习在医学图像计算中的应用：综述|Ahmad Chaddad, Yan Hu, Yihang Wu, Binbin Wen, Reem Kateb|<http://arxiv.org/pdf/2503.08420v1>|- 问题：可解释性，透明度，医疗图像<br />- 方法：CNN，ResNet50，XAI技术，t-test<br />- 效果：准确率，F1分数，置信度提升|
|📝 更新|OTCXR: Rethinking Self-supervised Alignment using Optimal Transport for Chest X-ray Analysis|OTCXR：利用最优传输重新思考胸部X光分析中的自监督对齐|Vandan Gorade, Azad Singh, Deepak Mishra|<http://arxiv.org/pdf/2404.11868v4>|- 问题：语义对齐，细节捕捉，病理特征<br />- 方法：最优传输，CV-SIM模块，方差协方差正则化<br />- 效果：语义丰富，诊断准确|
|📝 更新|Interactive Medical Image Analysis with Concept-based Similarity Reasoning|基于概念相似度推理的交互式医学图像分析|Ta Duc Huy, Sen Kim Tran, Phan Nguyen, Nguyen Hoang Tran, Tran Bao Sam, Anton van den Hengel, Zhibin Liao, Johan W. Verjans .etc.|<http://arxiv.org/pdf/2503.06873v2>|[[代码]](<https://github.com/tadeephuy/InteractCSR.>)<br />- 问题：模型可解释性，概念理解，交互性<br />- 方法：CSR网络，原型学习，空间交互<br />- 效果：性能提升，可解释性增强|


### 影像重建 (Image Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Reconstruct Anything Model: a lightweight foundation model for computational imaging|任意重建模型：计算成像的轻量级基础模型|Matthieu Terris, Samuel Hurault, Maxime Song, Julian Tachella|<http://arxiv.org/pdf/2503.08915v1>|- 问题：成像逆问题，迭代算法，训练成本高<br />- 方法：非迭代架构，轻量级，知识集成<br />- 效果：泛化能力强，性能优异|
|📝 更新|Lightweight Hypercomplex MRI Reconstruction: A Generalized Kronecker-Parameterized Approach|轻量级超复数MRI重建：一种广义克罗内克参数化方法|Haosen Zhang, Jiahao Huang, Yinzhe Wu, Congren Dai, Fanwen Wang, Zhenxuan Zhang, Guang Yang|<http://arxiv.org/pdf/2503.05063v2>|- 问题：MRI重建，内存密集，资源受限<br />- 方法：Kronecker-Parameterized Hypercomplex，Kronecker模块，Kronecker U-Net<br />- 效果：参数减少50%，性能稳定，泛化能力强|
|🆕 发布|X-Field: A Physically Grounded Representation for 3D X-ray Reconstruction|X-Field：3D X射线重建的物理基础表示|Feiran Wang, Jiachen Tao, Junyi Wu, Haoxuan Wang, Bin Duan, Kai Wang, Zongxin Yang, Yan Yan|<http://arxiv.org/pdf/2503.08596v1>|- 问题：X射线成像，3D重建，辐射暴露，材料特性<br />- 方法：X-Field，能量吸收率，路径分割算法<br />- 效果：视觉 fidelity，超越现有方法|
|🆕 发布|Diffusion Transformer Meets Random Masks: An Advanced PET Reconstruction Framework|扩散Transformer遇见随机掩码：先进的PET重建框架|Bin Huang, Binzhong He, Yanhan Chen, Zhili Liu, Xinyue Wang, Binxuan Li, Qiegen Liu|<http://arxiv.org/pdf/2503.08339v1>|[[代码]](<https://github.com/yqx7150/DREAM.>)<br />- 问题：PET图像重建，质量提升，效率<br />- 方法：Diffusion Transformer，随机掩码，高维堆叠<br />- 效果：重建质量提升，临床细节保留|
|📝 更新|LLM-HDR: Bridging LLM-based Perception and Self-Supervision for Unpaired LDR-to-HDR Image Reconstruction|LLM-HDR：基于LLM感知和自监督的无配对LDR到HDR图像重建的桥梁|Hrishav Bakul Barua, Kalin Stefanov, Lemuel Lai En Che, Abhinav Dhall, KokSheik Wong, Ganesh Krishnasamy|<http://arxiv.org/pdf/2410.15068v2>|[[代码]](<https://github.com/HrishavBakulBarua/LLM-HDR>)<br />- 问题：LDR-to-HDR，无配对数据集，视觉伪影<br />- 方法：LLM感知，语义循环一致性，自监督学习<br />- 效果：SOTA性能，高质量HDR图像|
|🆕 发布|DDO-IN: Dual Domains Optimization for Implicit Neural Network to Eliminate Motion Artifact in Magnetic Resonance Imaging|DDO-IN：用于消除磁共振成像中运动伪影的隐式神经网络的双重域优化|Zhongyu Mai, Zewei Zhan, Hanyu Guo, Yulang Huang, Weifeng Su|<http://arxiv.org/pdf/2503.08056v1>|- 问题：MRI运动伪影，细节丢失，图像质量差<br />- 方法：双域优化，隐式神经网络，互补掩码<br />- 效果：性能提升，细节保留|
|🆕 发布|A Bi-channel Aided Stitching of Atomic Force Microscopy Images|基于双通道辅助的原子力显微镜图像拼接|Huanhuan Zhao, Ruben Millan Solsona, Marti Checa, Spenser R. Brown, Jennifer L. Morrell-Falvey, Liam Collins, Arpan Biswas|<http://arxiv.org/pdf/2503.08735v1>|- 问题：图像拼接，特征稀疏，变换处理<br />- 方法：双通道辅助，特征匹配，位置估计<br />- 效果：性能提升，避免错误分析|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Lost & Found: Tracking Changes from Egocentric Observations in 3D Dynamic Scene Graphs|失而复得：在3D动态场景图中从自视角观察中追踪变化|Tjark Behrens, René Zurbrügg, Marc Pollefeys, Zuria Bauer, Hermann Blum|<http://arxiv.org/pdf/2411.19162v2>|[[代码]](<https://behretj.github.io/LostAndFound.>)<br />- 问题：动态场景，语义理解，交互追踪<br />- 方法：自旋记录，6DoF追踪，场景图变换<br />- 效果：精度提升，轨迹平滑|


## 智能驾驶 (Intelligent Driving)


### 轨迹预测 (Trajectory Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Conformal forecasting for surgical instrument trajectory|符合性预测用于手术器械轨迹|Sara Sangalli, Gary Sarwin, Ertunc Erdil, Alessandro Carretta, Victor Staartjes, Carlo Serra, Ender Konukoglu|<http://arxiv.org/pdf/2503.04191v2>|- 问题：手术器械轨迹预测，不确定性量化<br />- 方法：标准符合预测，符合化分位数回归<br />- 效果：不确定性评估，预测区间|
|📝 更新|Conformal Trajectory Prediction with Multi-View Data Integration in Cooperative Driving|基于多视角数据融合的协同驾驶中的共形轨迹预测|Xi Chen, Rahul Bhadani, Larry Head|<http://arxiv.org/pdf/2408.00374v3>|[[代码]](<https://github.com/xichennn/V2I_trajectory_prediction.>)<br />- 问题：单视角轨迹预测，数据融合，V2V/V2I<br />- 方法：V2INet，多视角数据建模，端到端训练<br />- 效果：FDE降低，MR降低|
|🆕 发布|Task-Oriented Co-Design of Communication, Computing, and Control for Edge-Enabled Industrial Cyber-Physical Systems|面向边缘赋能工业 cyber-physical 系统的通信、计算和控制协同设计|Yufeng Diao, Yichi Zhang, Daniele De Martini, Philip Guodong Zhao, Emma Liying Li|<http://arxiv.org/pdf/2503.08661v1>|- 问题：带宽限制，噪声干扰，延迟<br />- 方法：任务导向协同设计，JSCC，信息瓶颈，延迟感知控制预测<br />- 效果：驾驶评分提升，带宽使用降低|
|📝 更新|Collaborative Uncertainty Benefits Multi-Agent Multi-Modal Trajectory Forecasting|协同不确定性提升多智能体多模态轨迹预测|Bohan Tang, Yiqi Zhong, Chenxin Xu, Wei-Tao Wu, Ulrich Neumann, Yanfeng Wang, Ya Zhang, Siheng Chen|<http://arxiv.org/pdf/2207.05195v2>|- 问题：多模态轨迹预测，不确定性，预测排名<br />- 方法：协作不确定性，回归框架，不确定性估计<br />- 效果：性能提升，不确定性相关|
|🆕 发布|ICPR 2024 Competition on Rider Intention Prediction|2024年ICPR竞赛：骑行者意图预测|Shankar Gangisetty, Abdul Wasi, Shyam Nandan Rai, C. V. Jawahar, Sajay Raj, Manish Prajapati, Ayesha Choudhary, Aaryadev Chandra .etc.|<http://arxiv.org/pdf/2503.08437v1>|- 问题：道路安全，骑行者意图预测，事故预防<br />- 方法：RAAD数据集，多视角RIP，状态空间模型<br />- 效果：性能提升，SVM，CNN-LSTM|
|🆕 发布|SGNetPose+: Stepwise Goal-Driven Networks with Pose Information for Trajectory Prediction in Autonomous Driving|SGNetPose+：用于自动驾驶轨迹预测的逐步目标驱动网络与姿态信息|Akshat Ghiya, Ali K. AlShami, Jugal Kalita|<http://arxiv.org/pdf/2503.08016v1>|- 问题：自动驾驶，轨迹预测，行人安全<br />- 方法：SGNet架构，骨骼信息，时间增强<br />- 效果：JAAD，PIE，性能提升|


### 决策规划 (Decision Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CoLMDriver: LLM-based Negotiation Benefits Cooperative Autonomous Driving|CoLMDriver：基于LLM的协商对协同自动驾驶的益处|Changxing Liu, Genjia Liu, Zijun Wang, Jinchang Yang, Siheng Chen|<http://arxiv.org/pdf/2503.08683v1>|[[代码]](<https://github.com/cxliu0314/CoLMDriver.>)<br />- 问题：V2V合作驾驶，协议限制，泛化能力，LLM应用<br />- 方法：LLM谈判模块，actor-critic，意图引导生成器<br />- 效果：成功率高11%，交互场景|
|🆕 发布|HiP-AD: Hierarchical and Multi-Granularity Planning with Deformable Attention for Autonomous Driving in a Single Decoder|HiP-AD：单解码器中用于自动驾驶的层次化和多粒度规划与可变形注意力|Yingqi Tang, Zhuoran Xu, Zhaotie Meng, Erkang Cheng|<http://arxiv.org/pdf/2503.08612v1>|- 问题：E2E-AD性能，规划查询设计，交互性，轨迹预测<br />- 方法：多粒度规划，变形注意力，统一解码器<br />- 效果：Bench2Drive优于，nuScenes竞争|
|🆕 发布|Reasoning in visual navigation of end-to-end trained agents: a dynamical systems approach|视觉导航中端到端训练代理的推理：一种动力系统方法|Steeven Janny, Hervé Poirier, Leonid Antsfeld, Guillaume Bono, Gianluca Monaci, Boris Chidlovskii, Francesco Giuliari, Alessio Del Bue .etc.|<http://arxiv.org/pdf/2503.08306v1>|- 问题：视觉导航，推理，动态系统，机器人<br />- 方法：端到端训练，实验研究，记忆分析<br />- 效果：精确规划，长期规划|
|🆕 发布|A Cascading Cooperative Multi-agent Framework for On-ramp Merging Control Integrating Large Language Models|级联协同多智能体框架，融合大型语言模型的车道入口合并控制|Miao Zhang, Zhenlong Fang, Tianyi Wang, Qian Zhang, Shuai Lu, Junfeng Jiao, Tianyu Shi|<http://arxiv.org/pdf/2503.08199v1>|- 问题：传统RL，多智能体协调，可解释性<br />- 方法：CCMA框架，LLM增强，奖励函数，检索增强生成<br />- 效果：性能提升，微宏观优化|


### 环境感知 (Environment Perception)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SegAgent: Exploring Pixel Understanding Capabilities in MLLMs by Imitating Human Annotator Trajectories|SegAgent：通过模仿人类标注者轨迹探索MLLMs的像素理解能力|Muzhi Zhu, Yuzhuo Tian, Hao Chen, Chunluan Zhou, Qingpei Guo, Yang Liu, Ming Yang, Chunhua Shen|<http://arxiv.org/pdf/2503.08625v1>|- 问题：像素理解，MLLM，评估任务，分割方法<br />- 方法：HLMAT，Markov决策过程，交互式分割<br />- 效果：SOTA性能，多任务支持|
|🆕 发布|JiSAM: Alleviate Labeling Burden and Corner Case Problems in Autonomous Driving via Minimal Real-World Data|JiSAM：通过最小化真实世界数据减轻自动驾驶中的标注负担和边缘案例问题|Runjian Chen, Wenqi Shao, Bo Zhang, Shaoshuai Shi, Li Jiang, Ping Luo|<http://arxiv.org/pdf/2503.08422v1>|- 问题：标注负担，角案例问题，数据规模限制<br />- 方法：JiSAM，抖动增强，域感知骨干，记忆式分区对齐<br />- 效果：SOTA性能，15mAP提升|
|🆕 发布|HASARD: A Benchmark for Vision-Based Safe Reinforcement Learning in Embodied Agents|HASARD：具身智能体基于视觉的鲁棒强化学习基准|Tristan Tomilin, Meng Fang, Mykola Pechenizkiy|<http://arxiv.org/pdf/2503.08241v1>|- 问题：安全强化学习，视觉基准，导航任务<br />- 方法：HASARD基准，多难度级别，egocentric视觉<br />- 效果：评估方法，学习过程，探索潜力|
|📝 更新|Efficient Physics Simulation for 3D Scenes via MLLM-Guided Gaussian Splatting|基于MLLM引导的高斯分层渲染的3D场景高效物理模拟|Haoyu Zhao, Hao Wang, Xingyue Zhao, Hao Fei, Hongqiu Wang, Chengjiang Long, Hua Zou|<http://arxiv.org/pdf/2411.12789v2>|- 问题：3D场景模拟，物理属性预测，计算成本高<br />- 方法：MLLM-P3，MPDP，PGAS<br />- 效果：实时模拟，高保真运动|


## 工业视觉 (Industrial Vision)


### 工业测量 (Industrial Measurement)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Ev-Layout: A Large-scale Event-based Multi-modal Dataset for Indoor Layout Estimation and Tracking|Ev-Layout：大规模基于事件的室内布局估计与跟踪多模态数据集|Xucheng Guo, Yiran Shen, Xiaofang Xiao, Yuanfeng Zhou, Lin Wang|<http://arxiv.org/pdf/2503.08370v1>|- 问题：室内布局估计，跟踪，数据集<br />- 方法：混合数据采集，IMU，事件相机<br />- 效果：精度提升，事件时空信息聚合|
|🆕 发布|Physics-based AI methodology for Material Parameter Extraction from Optical Data|基于物理的AI方法从光学数据中提取材料参数|M. Koumans, J. L. M. van Mechelen|<http://arxiv.org/pdf/2503.08183v1>|- 问题：材料参数提取，光谱数据，物理模型<br />- 方法：物理神经网络，多尺度检测，优化框架<br />- 效果：自主性，鲁棒性，效率|


### 质量控制 (Quality Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FaceID-6M: A Large-Scale, Open-Source FaceID Customization Dataset|FaceID-6M：一个大规模、开源的FaceID定制数据集|Shuhe Wang, Xiaoya Li, Jiwei Li, Guoyin Wang, Xiaofei Sun, Bob Zhu, Han Qiu, Mo Yu .etc.|<http://arxiv.org/pdf/2503.07091v2>|[[代码]](<https://github.com/ShuheSH/FaceID-6M.>)<br />- 问题：数据封闭，模型透明度低，研究受限<br />- 方法：FaceID-6M数据集，图像文本过滤，开源<br />- 效果：性能提升，模型可用|
|🆕 发布|Oasis: One Image is All You Need for Multimodal Instruction Data Synthesis|绿洲：一张图片就足以用于多模态指令数据合成|Letian Zhang, Quan Cui, Bingchen Zhao, Cheng Yang|<http://arxiv.org/pdf/2503.08741v1>|- 问题：隐私，数据收集，数据多样性，质量保证<br />- 方法：图像提示，质量控制，数据合成<br />- 效果：性能提升，特定领域能力|


## 其他 (Others)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Deformable Registration Framework for Augmented Reality-based Surgical Guidance in Head and Neck Tumor Resection|可变形配准框架在基于增强现实的头颈肿瘤切除手术引导中的应用|Qingyun Yang, Fangjie Li, Jiayi Xu, Zixuan Liu, Sindhura Sridhar, Whitney Jin, Jennifer Du, Jon Heiselman .etc.|<http://arxiv.org/pdf/2503.08802v1>|- 问题：HNSCC复发，术中边缘定位，FSA准确性，3D解剖复杂<br />- 方法：变形配准，厚度信息，定制变形策略，AR辅助<br />- 效果：TRE降低，临床意义高，手术误差减少|
|📝 更新|MambaIRv2: Attentive State Space Restoration|MambaIRv2：注意力状态空间恢复|Hang Guo, Yong Guo, Yaohua Zha, Yulun Zhang, Wenbo Li, Tao Dai, Shu-Tao Xia, Yawei Li|<http://arxiv.org/pdf/2411.15269v2>|[[代码]](<https://github.com/csguoh/MambaIR.>)<br />- 问题：Mamba局限性，图像恢复挑战<br />- 方法：非因果建模，注意力状态空间，语义引导机制<br />- 效果：性能提升，参数减少|

