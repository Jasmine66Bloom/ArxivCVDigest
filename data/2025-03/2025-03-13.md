## [UPDATED!] **2025-03-13** (Update Time)


## 表示学习 (Representation Learning)


### 视觉Transformer (Vision Transformers)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Kolmogorov-Arnold Attention: Is Learnable Attention Better For Vision Transformers?|高斯-阿诺德注意力：可学习的注意力对视觉Transformer更好吗？|Subhajit Maity, Killian Hitsman, Xin Li, Aritra Dutta|<http://arxiv.org/pdf/2503.10632v1>|- 问题：可学习注意力，视觉Transformer，性能<br />- 方法：Kolmogorov-Arnold注意力，Fourier-KArAt，模块化设计<br />- 效果：性能提升，泛化能力强|
|📝 更新|$ShiftwiseConv:$ Small Convolutional Kernel with Large Kernel Effect|ShiftwiseConv：具有大核效果的微小卷积核|Dachong Li, Li Li, Zhuangzhuang Chen, Jianqiang Li|<http://arxiv.org/pdf/2401.12736v2>|[[代码]](<https://github.com/lidc54/shift-wiseConv.>)<br />- 问题：大卷积核，性能瓶颈，特征提取<br />- 方法：Shiftwise卷积，多路径依赖，纯CNN<br />- 效果：超越SOTA，3x3卷积等效|
|📝 更新|Spectral State Space Model for Rotation-Invariant Visual Representation Learning|光谱状态空间模型用于旋转不变视觉表示学习|Sahar Dastani, Ali Bahri, Moslem Yazdanpanah, Mehrdad Noori, David Osowiechi, Gustavo Adolfo Vargas Hakim, Farzad Beizaee, Milad Cheraghalikhani .etc.|<http://arxiv.org/pdf/2503.06369v2>|- 问题：SSMs局限性，旋转不变性，图像关系建模<br />- 方法：Spectral VMamba，图拉普拉斯谱，RFN模块<br />- 效果：旋转不变，性能提升|


### 预训练模型 (Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RoMA: Scaling up Mamba-based Foundation Models for Remote Sensing|RoMA：扩展Mamba基础模型以实现遥感规模化|Fengxiang Wang, Hongzhen Wang, Yulin Wang, Di Wang, Mingshuo Chen, Haiyan Zhao, Yangang Sun, Shuo Wang .etc.|<http://arxiv.org/pdf/2503.10392v1>|[[代码]](<https://github.com/MiliLab/RoMA.>)<br />- 问题：可扩展性，自监督学习，高分辨率图像<br />- 方法：Mamba架构，旋转感知预训练，多尺度预测<br />- 效果：性能提升，效率提高|
|📝 更新|Content and Salient Semantics Collaboration for Cloth-Changing Person Re-Identification|内容与显著语义协同的衣物更换人物重识别|Qizao Wang, Xuelin Qian, Bin Li, Lifeng Chen, Yanwei Fu, Xiangyang Xue|<http://arxiv.org/pdf/2405.16597v2>|[[代码]](<https://github.com/QizaoWang/CSSC-CCReID.>)<br />- 问题：衣物变化，行人重识别<br />- 方法：语义挖掘，SMR模块，CSSC框架<br />- 效果：性能优越，基准测试领先|


## 生成建模 (Generative Modeling)


### 扩散模型 (Diffusion Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Distilling Diversity and Control in Diffusion Models|扩散模型中的多样性蒸馏与控制|Rohit Gandikota, David Bau|<http://arxiv.org/pdf/2503.10637v1>|- 问题：多样性降低，控制蒸馏，代表性结构<br />- 方法：控制蒸馏，扩散目标可视化，多样性蒸馏<br />- 效果：多样性恢复，效率提升|
|🆕 发布|HybridVLA: Collaborative Diffusion and Autoregression in a Unified Vision-Language-Action Model|混合VLA：统一视觉-语言-动作模型中的协同扩散和自回归|Jiaming Liu, Hao Chen, Pengju An, Zhuoyang Liu, Renrui Zhang, Chenyang Gu, Xiaoqi Li, Ziyu Guo .etc.|<http://arxiv.org/pdf/2503.10631v1>|- 问题：VLA模型，动作连续性，推理能力，融合策略<br />- 方法：HybridVLA，协同训练，动作融合机制<br />- 效果：性能提升，稳定控制|
|🆕 发布|GoT: Unleashing Reasoning Capability of Multimodal Large Language Model for Visual Generation and Editing|GoT：释放多模态大型语言模型在视觉生成和编辑中的推理能力|Rongyao Fang, Chengqi Duan, Kun Wang, Linjiang Huang, Hao Li, Shilin Yan, Hao Tian, Xingyu Zeng .etc.|<http://arxiv.org/pdf/2503.10639v1>|[[代码]](<https://github.com/rongyaofang/GoT.>)<br />- 问题：视觉生成，编辑，推理能力，文本提示<br />- 方法：生成链式思维，语义空间引导模块，Qwen2.5-VL<br />- 效果：性能提升，交互式生成|
|🆕 发布|V2Edit: Versatile Video Diffusion Editor for Videos and 3D Scenes|V2Edit：适用于视频和3D场景的多功能视频扩散编辑器|Yanming Zhang, Jun-Kun Chen, Jipeng Lyu, Yu-Xiong Wang|<http://arxiv.org/pdf/2503.10634v1>|- 问题：视频编辑，内容保留，3D场景<br />- 方法：渐进策略，协同机制，渲染编辑重建<br />- 效果：高质量，高一致性|
|🆕 发布|Studying Classifier(-Free) Guidance From a Classifier-Centric Perspective|从分类器中心视角研究分类器（无）指导|Xiaoming Zhao, Alexander G. Schwing|<http://arxiv.org/pdf/2503.10638v1>|- 问题：Classifier-free guidance，理解，Classifier-centric<br />- 方法：Empirical study，Systematic study，Flow-matching<br />- 效果：Conditional generation，Gap shrink|
|🆕 发布|NIL: No-data Imitation Learning by Leveraging Pre-trained Video Diffusion Models|NIL：利用预训练视频扩散模型的无数据模仿学习|Mert Albaba, Chenhao Li, Markos Diomataris, Omid Taheri, Andreas Krause, Michael Black|<http://arxiv.org/pdf/2503.10626v1>|- 问题：技能学习，数据获取难，形态多样性<br />- 方法：视频扩散模型，视觉Transformer，模仿学习<br />- 效果：性能提升，泛化能力强|
|🆕 发布|DiT-Air: Revisiting the Efficiency of Diffusion Model Architecture Design in Text to Image Generation|DiT-Air：重新审视文本到图像生成中扩散模型架构设计的效率|Chen Chen, Rui Qian, Wenze Hu, Tsu-Jui Fu, Lezhi Li, Bowen Zhang, Alex Schwing, Wei Liu .etc.|<http://arxiv.org/pdf/2503.10618v1>|- 问题：Diffusion Transformers, 文本到图像生成，架构设计<br />- 方法：参数共享，DiT-Air，监督微调<br />- 效果：性能提升，参数效率高|
|🆕 发布|MuDG: Taming Multi-modal Diffusion with Gaussian Splatting for Urban Scene Reconstruction|MuDG：利用高斯喷溅驯服多模态扩散以实现城市场景重建|Yingshuang Zou, Yikang Ding, Chuanrui Zhang, Jiazhe Guo, Bohan Li, Xiaoyang Lyu, Feiyang Tan, Xiaojuan Qi .etc.|<http://arxiv.org/pdf/2503.10604v1>|- 问题：视角偏差，时序一致性，场景可控性<br />- 方法：多模态扩散模型，高斯分层，无优化NVS<br />- 效果：重建质量提升，合成效果优|
|🆕 发布|CoSTA$\ast$: Cost-Sensitive Toolpath Agent for Multi-turn Image Editing|CoSTA$\ast$：多轮图像编辑的成本敏感路径代理|Advait Gupta, NandaKiran Velaga, Dang Nguyen, Tianyi Zhou|<http://arxiv.org/pdf/2503.10613v1>|- 问题：多轮图像编辑，工具路径，成本敏感<br />- 方法：LLM，子任务树，A*搜索，成本-质量平衡<br />- 效果：成本优化，质量提升|
|🆕 发布|CameraCtrl II: Dynamic Scene Exploration via Camera-controlled Video Diffusion Models|CameraCtrl II：通过相机控制的视频扩散模型进行动态场景探索|Hao He, Ceyuan Yang, Shanchuan Lin, Yinghao Xu, Meng Wei, Liangke Gui, Qi Zhao, Gordon Wetzstein .etc.|<http://arxiv.org/pdf/2503.10592v1>|- 问题：动态场景探索，视频生成，视角范围限制<br />- 方法：视频扩散模型，动态场景生成，相机控制<br />- 效果：空间探索，连贯视频序列|
|🆕 发布|Long Context Tuning for Video Generation|长上下文调优用于视频生成|Yuwei Guo, Ceyuan Yang, Ziyan Yang, Zhibei Ma, Zhijie Lin, Zhenheng Yang, Dahua Lin, Lu Jiang|<http://arxiv.org/pdf/2503.10589v1>|[[代码]](<https://guoyww.github.io/projects>)<br />- 问题：视频生成，多场景一致性，单帧模型<br />- 方法：长上下文调整，全注意力机制，异步噪声策略<br />- 效果：连贯多场景，生成能力提升|
|📝 更新|Tiled Diffusion|瓦片扩散|Or Madar, Ohad Fried|<http://arxiv.org/pdf/2412.15185v3>|- 问题：图像拼接，手动构建，局限性<br />- 方法：Tiled Diffusion，扩散模型，自动生成<br />- 效果：无缝拼接，多场景应用|
|🆕 发布|AudioX: Diffusion Transformer for Anything-to-Audio Generation|音频X：任何到音频生成的扩散Transformer|Zeyue Tian, Yizhu Jin, Zhaoyang Liu, Ruibin Yuan, Xu Tan, Qifeng Chen, Wei Xue, Yike Guo|<http://arxiv.org/pdf/2503.10522v1>|[[代码]](<https://zeyuet.github.io/AudioX>)<br />- 问题：跨模态生成，数据稀缺，模型单一<br />- 方法：Diffusion Transformer，多模态掩码训练，数据集构建<br />- 效果：性能优异，泛化能力强|
|📝 更新|ACDiT: Interpolating Autoregressive Conditional Modeling and Diffusion Transformer|ACDiT：插值自回归条件建模与扩散变换器|Jinyi Hu, Shengding Hu, Yuxuan Song, Yufei Huang, Mingxuan Wang, Hao Zhou, Zhiyuan Liu, Wei-Ying Ma .etc.|<http://arxiv.org/pdf/2412.07720v2>|- 问题：连续视觉信息建模，离散化限制，视觉生成<br />- 方法：ACDiT，块状自回归，条件扩散过程<br />- 效果：性能最佳，模型迁移，长时视觉生成|
|🆕 发布|Streaming Generation of Co-Speech Gestures via Accelerated Rolling Diffusion|通过加速滚动扩散进行协同语音手势的流式生成|Evgeniia Vu, Andrei Boiarov, Dmitry Vetrov|<http://arxiv.org/pdf/2503.10488v1>|- 问题：实时生成，时序一致性，采样效率<br />- 方法：加速滚动扩散，RDLA，结构化噪声调度<br />- 效果：速度提升，高保真，一致性|
|📝 更新|Video Super-Resolution: All You Need is a Video Diffusion Model|视频超分辨率：你所需要的就是一个视频扩散模型|Zhihao Zhan, Wang Pang, Xiang Zhu, Yechao Bai|<http://arxiv.org/pdf/2503.03355v2>|- 问题：视频超分辨率，运动模式，光流估计<br />- 方法：扩散后验采样，视频生成模型，扩散变换器<br />- 效果：泛化能力强，适应性强|
|📝 更新|Meissonic: Revitalizing Masked Generative Transformers for Efficient High-Resolution Text-to-Image Synthesis|Meissonic：复兴掩码生成Transformer以实现高效的高分辨率文本到图像合成|Jinbin Bai, Tian Ye, Wei Chow, Enxin Song, Xiangtai Li, Zhen Dong, Lei Zhu, Shuicheng Yan|<http://arxiv.org/pdf/2410.08261v4>|- 问题：MIM效率低，分辨率不足<br />- 方法：架构创新，位置编码，采样优化<br />- 效果：性能提升，高分辨率|
|🆕 发布|CINEMA: Coherent Multi-Subject Video Generation via MLLM-Based Guidance|电影：基于MLLM引导的连贯多主体视频生成|Yufan Deng, Xun Guo, Yizhi Wang, Jacob Zhiyuan Fang, Angtian Wang, Shenghai Yuan, Yiding Yang, Bo Liu .etc.|<http://arxiv.org/pdf/2503.10391v1>|- 问题：多主体视频生成，一致性，关系建模<br />- 方法：MLLM指导，无显式对应，关系解释<br />- 效果：一致性提升，视频连贯性|
|📝 更新|Arbitrary-steps Image Super-resolution via Diffusion Inversion|任意步图像超分辨率通过扩散逆算|Zongsheng Yue, Kang Liao, Chen Change Loy|<http://arxiv.org/pdf/2412.09013v2>|[[代码]](<https://github.com/zsyOAOA/InvSR.>)<br />- 问题：图像超分辨率，扩散模型，噪声预测<br />- 方法：扩散逆，部分噪声预测，深度噪声预测<br />- 效果：任意步采样，性能优越|
|🆕 发布|ConceptGuard: Continual Personalized Text-to-Image Generation with Forgetting and Confusion Mitigation|概念守护：具有遗忘和混淆缓解的持续个性化文本到图像生成|Zirun Guo, Tao Jin|<http://arxiv.org/pdf/2503.10358v1>|- 问题：概念遗忘，混淆，连续定制<br />- 方法：shift embedding，概念绑定，记忆保持正则化，优先队列<br />- 效果：优于基线，定量定性分析|
|🆕 发布|DreamInsert: Zero-Shot Image-to-Video Object Insertion from A Single Image|DreamInsert：基于单图的零样本图像到视频物体插入|Qi Zhao, Zhan Ma, Pan Zhou|<http://arxiv.org/pdf/2503.10342v1>|- 问题：单图视频插入，运动信息缺乏<br />- 方法：轨迹考虑，预测运动，融合背景<br />- 效果：零样本，无缝生成|
|📝 更新|Prompt-SID: Learning Structural Representation Prompt via Latent Diffusion for Single-Image Denoising|Prompt-SID：通过潜在扩散学习结构表示提示的单图像去噪|Huaqiu Li, Wang Zhang, Xiaowan Hu, Tao Jiang, Zikang Chen, Haoqian Wang|<http://arxiv.org/pdf/2502.06432v2>|[[代码]](<https://github.com/huaqlili/Prompt-SID.>)<br />- 问题：图像去噪，结构信息损失，自监督学习<br />- 方法：Prompt学习，结构编码，结构注意力模块<br />- 效果：去噪效果显著，结构信息保留|
|📝 更新|LatentSync: Taming Audio-Conditioned Latent Diffusion Models for Lip Sync with SyncNet Supervision|潜同步：利用SyncNet监督驯服音频条件潜在扩散模型实现唇同步|Chunyu Li, Chao Zhang, Weikai Xu, Jingyu Lin, Jinghui Xie, Weiguo Feng, Bingyue Peng, Cunjian Chen .etc.|<http://arxiv.org/pdf/2412.09262v2>|- 问题：唇同步精度低，视觉-视觉捷径，音频-视觉关联<br />- 方法：SyncNet监督，StableSyncNet，TREPA机制<br />- 效果：精度提升，时间一致性增强|
|📝 更新|Bokeh Diffusion: Defocus Blur Control in Text-to-Image Diffusion Models|波库姆扩散：文本到图像扩散模型中的失焦模糊控制|Armando Fortes, Tianyi Wei, Shangchen Zhou, Xingang Pan|<http://arxiv.org/pdf/2503.08434v2>|- 问题：深度场控制，内容改变，模糊控制<br />- 方法：场景一致，物理参数，混合训练<br />- 效果：灵活控制，真实图像编辑|
|📝 更新|EmojiDiff: Advanced Facial Expression Control with High Identity Preservation in Portrait Generation|EmojiDiff：肖像生成中高身份保留的高级面部表情控制|Liangwei Jiang, Ruida Li, Zhifeng Zhang, Shuo Fang, Chenguang Ma|<http://arxiv.org/pdf/2412.01254v2>|- 问题：表情控制，身份保留，生成图像<br />- 方法：EmojiDiff，解耦训练，ID-ICA<br />- 效果：精确控制，高保真，泛化好|
|📝 更新|Hallo3: Highly Dynamic and Realistic Portrait Image Animation with Video Diffusion Transformer|Hallo3：基于视频扩散变换器的超动态和逼真人像动画|Jiahao Cui, Hui Li, Yun Zhan, Hanlin Shang, Kaihui Cheng, Yuqi Ma, Shan Mu, Hang Zhou .etc.|<http://arxiv.org/pdf/2412.00733v4>|[[代码]](<https://fudan-generative-vision.github.io/hallo3>)<br />- 问题：动态肖像动画，非正面视角，动态物体，沉浸式背景<br />- 方法：Transformer，视频生成模型，身份参考网络<br />- 效果：高动态，真实，改进|
|📝 更新|HERO: Human-Feedback Efficient Reinforcement Learning for Online Diffusion Model Finetuning|HERO：基于人类反馈的高效强化学习在线扩散模型微调|Ayano Hiranaka, Shang-Fu Chen, Chieh-Hsin Lai, Dongjun Kim, Naoki Murata, Takashi Shibuya, Wei-Hsiang Liao, Shao-Hua Sun .etc.|<http://arxiv.org/pdf/2410.05116v3>|[[代码]](<https://hero-dm.github.io/.>)<br />- 问题：人类反馈，强化学习，扩散模型，微调<br />- 方法：在线反馈，表示学习，图像生成<br />- 效果：效率提升，任务处理|
|🆕 发布|PlanGen: Towards Unified Layout Planning and Image Generation in Auto-Regressive Vision Language Models|PlanGen：迈向统一布局规划和图像生成在自回归视觉语言模型中|Runze He, Bo Cheng, Yuhang Ma, Qingxiang Jia, Shanyuan Liu, Ao Ma, Xiaoyu Wu, Liebucha Wu .etc.|<http://arxiv.org/pdf/2503.10127v1>|[[代码]](<https://360cvgroup.github.io/PlanGen.>)<br />- 问题：布局规划，图像生成，模型分离<br />- 方法：统一模型，自回归变换器，布局条件集成<br />- 效果：多任务训练，布局引导，性能提升|
|📝 更新|Optimizing for the Shortest Path in Denoising Diffusion Model|优化去噪扩散模型中的最短路径|Ping Chen, Xingpeng Zhang, Zhaoxiang Liu, Huan Hu, Xiang Liu, Kai Wang, Min Wang, Yanlin Qian .etc.|<http://arxiv.org/pdf/2503.03265v3>|[[代码]](<https://github.com/UnicomAI/ShortDF.>)<br />- 问题：去噪效率，质量，残差传播<br />- 方法：最短路径建模，DDIM，图论<br />- 效果：时间减少，视觉质量提升|
|🆕 发布|Improving Diffusion-based Inverse Algorithms under Few-Step Constraint via Learnable Linear Extrapolation|通过可学习线性外推改善受步数限制的扩散逆算法|Jiawei Zhang, Ziyuan Liu, Leon Yan, Gen Li, Yuantao Gu|<http://arxiv.org/pdf/2503.10103v1>|[[代码]](<https://github.com/weigerzan/LLE_inverse_problem>)<br />- 问题：扩散模型，逆算法，步骤限制，性能退化<br />- 方法：可学习线性外推，统一分析，高效采样<br />- 效果：性能提升，效率增强|
|📝 更新|DiffSensei: Bridging Multi-Modal LLMs and Diffusion Models for Customized Manga Generation|DiffSensei：连接多模态LLMs和扩散模型以实现定制漫画生成|Jianzong Wu, Chao Tang, Jingbo Wang, Yanhong Zeng, Xiangtai Li, Yunhai Tong|<http://arxiv.org/pdf/2412.07589v2>|[[代码]](<https://jianzongwu.github.io/projects>)<br />- 问题：多角色场景控制，人物外观交互，定制漫画生成<br />- 方法：扩散模型，多模态LLM，掩码交叉注意力<br />- 效果：文本可调，定制化，性能提升|
|🆕 发布|Investigating and Improving Counter-Stereotypical Action Relation in Text-to-Image Diffusion Models|探究与提升文本到图像扩散模型中的反典型动作关系|Sina Malakouti, Adriana Kovashka|<http://arxiv.org/pdf/2503.10037v1>|- 问题：反典型动作关系，生成失败，分布偏差<br />- 方法：角色桥接分解，ActionBench基准，中间组合<br />- 效果：生成改善，自动和人工评估提升|
|🆕 发布|Channel-wise Noise Scheduled Diffusion for Inverse Rendering in Indoor Scenes|室内场景逆渲染中的通道噪声调度扩散|JunYong Choi, Min-Cheol Sagong, SeokYeong Lee, Seung-Won Jung, Ig-Jae Kim, Junghyun Cho|<http://arxiv.org/pdf/2503.09993v1>|- 问题：逆渲染，单解预测，多样性<br />- 方法：通道噪声调度，扩散模型<br />- 效果：准确性，多样性|
|📝 更新|Preference Alignment for Diffusion Model via Explicit Denoised Distribution Estimation|通过显式去噪分布估计实现扩散模型的偏好对齐|Dingyuan Shi, Yong Wang, Hangyu Li, Xiangxiang Chu|<http://arxiv.org/pdf/2411.14871v3>|- 问题：偏好对齐，扩散模型，中间步骤优化<br />- 方法：DDE，逐步估计，单次估计<br />- 效果：性能提升，定量定性|
|📝 更新|There and Back Again: On the relation between Noise and Image Inversions in Diffusion Models|《去而复返：扩散模型中噪声与图像反转之间的关系》|Łukasz Staniszewski, Łukasz Kuciński, Kamil Deja|<http://arxiv.org/pdf/2410.23530v2>|[[代码]](<https://github.com/luk-st/taba.>)<br />- 问题：低维特征，图像逆过程，噪声预测<br />- 方法：DDIM逆过程分析，噪声预测误差，结构模式<br />- 效果：低多样性，映射不明确|
|🆕 发布|PanoGen++: Domain-Adapted Text-Guided Panoramic Environment Generation for Vision-and-Language Navigation|PanoGen++：面向视觉与语言导航的领域自适应文本引导全景环境生成|Sen Wang, Dongliang Zhou, Liang Xie, Chao Xu, Ye Yan, Erwei Yin|<http://arxiv.org/pdf/2503.09938v1>|- 问题：数据稀缺，导航任务，环境生成<br />- 方法：PanoGen++，扩散模型，低秩适应<br />- 效果：性能提升，泛化增强|


### 生成对抗网络 (GANs)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|The Curse of Conditions: Analyzing and Improving Optimal Transport for Conditional Flow-Based Generation|条件流生成中最优传输的诅咒：分析与改进|Ho Kei Cheng, Alexander Schwing|<http://arxiv.org/pdf/2503.10636v1>|[[代码]](<https://hkchengrex.github.io/C2OT>)<br />- 问题：条件生成，最优传输，性能差距<br />- 方法：条件最优传输，加权项，成本矩阵<br />- 效果：性能提升，效果优于基线|
|📝 更新|COMBO: Compositional World Models for Embodied Multi-Agent Cooperation|COMBO：用于具身多智能体合作的组合世界模型|Hongxin Zhang, Zeyuan Wang, Qiushi Lyu, Zheyuan Zhang, Sunli Chen, Tianmin Shu, Behzad Dariush, Kwonjoon Lee .etc.|<http://arxiv.org/pdf/2404.10775v2>|- 问题：多智能体合作，部分可观测，世界模型<br />- 方法：生成模型，组合世界模型，视觉语言模型<br />- 效果：高效合作，任务多样性|
|🆕 发布|Finetuning Generative Trajectory Model with Reinforcement Learning from Human Feedback|基于人类反馈的强化学习微调生成轨迹模型|Derun Li, Jianwei Ren, Yue Wang, Xin Wen, Pengxiang Li, Leimeng Xu, Kun Zhan, Zhongpu Xia .etc.|<http://arxiv.org/pdf/2503.10434v1>|- 问题：轨迹生成，风格多样性，数据偏差，分布偏移<br />- 方法：反馈驱动微调，多条件降噪，强化学习<br />- 效果：PDMS 93.95，个性化，适应性|
|📝 更新|PEMF-VTO: Point-Enhanced Video Virtual Try-on via Mask-free Paradigm|PEMF-VTO：基于无遮挡范式的点增强视频虚拟试穿|Tianyu Chang, Xiaohao Chen, Zhichao Wei, Xuanpu Zhang, Qing-Guo Chen, Weihua Luo, Peipei Song, Xun Yang|<http://arxiv.org/pdf/2412.03021v3>|- 问题：视频虚拟试穿，mask-free，时空信息破坏<br />- 方法：Point-Enhanced Transformer，PSA，PTA<br />- 效果：自然，连贯，视觉吸引力|
|🆕 发布|Piece it Together: Part-Based Concepting with IP-Priors|拼凑在一起：基于IP先验的部件概念化|Elad Richardson, Kfir Goldberg, Yuval Alaluf, Daniel Cohen-Or|<http://arxiv.org/pdf/2503.10365v1>|- 问题：文本条件，视觉元素，创意组合<br />- 方法：IP-Priors，轻量级模型，LoRA微调<br />- 效果：连贯合成，多样化生成|
|🆕 发布|Do I look like a `cat.n.01` to you? A Taxonomy Image Generation Benchmark|我看起来像“猫.n.01”吗？一个图像生成基准分类法|Viktor Moskvoretskii, Alina Lobanova, Ekaterina Neminova, Chris Biemann, Alexander Panchenko, Irina Nikishina|<http://arxiv.org/pdf/2503.10357v1>|- 问题：零样本图像生成，分类图像生成，基准测试<br />- 方法：文本到图像模型，基准评估，人类反馈<br />- 效果：模型性能差异显著，检索方法表现不佳|
|🆕 发布|MACS: Multi-source Audio-to-image Generation with Contextual Significance and Semantic Alignment|多源音频到图像生成：具有情境意义和语义对齐的MACS|Hao Zhou, Xiaobao Guo, Yuzhe Zhu, Adams Wai-Kin Kong|<http://arxiv.org/pdf/2503.10287v1>|- 问题：单源音频，视觉内容限制<br />- 方法：多源音频分离，语义对齐，排名损失<br />- 效果：性能提升，视觉质量优|
|📝 更新|From Easy to Hard: Progressive Active Learning Framework for Infrared Small Target Detection with Single Point Supervision|从易到难：基于单点监督的渐进式主动学习红外小目标检测框架|Chuang Yu, Jinmiao Zhao, Yunpeng Liu, Sicheng Zhao, Yimian Dai, Xiangyu Yue|<http://arxiv.org/pdf/2412.11154v2>|[[代码]](<https://github.com/YuChuang1205/PAL.>)<br />- 问题：红外小目标检测，单点监督，标签进化不稳定<br />- 方法：渐进式主动学习，模型预启动，双更新策略，衰减因子<br />- 效果：性能提升，SOTA结果，高效稳定|
|🆕 发布|Semantic Latent Motion for Portrait Video Generation|语义潜在运动的人像视频生成|Qiyuan Zhang, Chenyu Wu, Wenzhang Sun, Huaize Liu, Donglin Di, Wei Chen, Changqing Zou|<http://arxiv.org/pdf/2503.10096v1>|- 问题：运动生成，效率低，不真实<br />- 方法：语义潜在运动，抽象推理生成<br />- 效果：实时生成，高真实感|
|📝 更新|CAD-MLLM: Unifying Multimodality-Conditioned CAD Generation With MLLM|CAD-MLLM：统一多模态条件CAD生成与MLLM|Jingwei Xu, Zibo Zhao, Chenyu Wang, Wen Liu, Yi Ma, Shenghua Gao|<http://arxiv.org/pdf/2411.04954v2>|- 问题：CAD模型生成，多模态输入，参数化模型<br />- 方法：CAD命令序列，LLM特征空间对齐，数据构建与标注<br />- 效果：性能优越，鲁棒性强|
|📝 更新|DDIM-Driven Coverless Steganography Scheme with Real Key|基于DDIM的带真实密钥的无封面隐写术方案|Mingyu Yu, Haonan Miao, Zhengping Jin, Sujuan Qin|<http://arxiv.org/pdf/2411.06486v3>|- 问题：信息隐藏，密钥交换，安全风险<br />- 方法：DDIM，真实密钥，可逆数据隐藏，混沌加密<br />- 效果：减少密钥交换，增强安全性|


### 自回归模型 (Autoregressive Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Autoregressive Image Generation with Randomized Parallel Decoding|自回归图像生成与随机并行解码|Haopeng Li, Jinyue Yang, Guoqi Li, Huan Wang|<http://arxiv.org/pdf/2503.10568v1>|- 问题：效率低，泛化差，顺序生成<br />- 方法：随机并行解码，位置引导，因果注意力<br />- 效果：FID 1.94，吞吐量提升20倍，内存消耗降低75%|
|🆕 发布|Proxy-Tuning: Tailoring Multimodal Autoregressive Models for Subject-Driven Image Generation|代理调优：为驱动图像生成定制多模态自回归模型|Yi Wu, Lingting Zhu, Lei Liu, Wandi Qiao, Ziqiang Li, Lequan Yu, Bin Li|<http://arxiv.org/pdf/2503.10125v1>|- 问题：多模态AR模型，主题驱动图像生成，性能不足<br />- 方法：Proxy-Tuning，扩散模型增强，弱到强泛化<br />- 效果：AR模型超越扩散模型，主题忠实度，上下文理解|


## 多模态学习 (Multimodal Learning)


### 视觉语言模型 (Vision-Language Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UniGoal: Towards Universal Zero-shot Goal-oriented Navigation|UniGoal：迈向通用零样本目标导向导航|Hang Yin, Xiuwei Xu, Lingqing Zhao, Ziwei Wang, Jie Zhou, Jiwen Lu|<http://arxiv.org/pdf/2503.10630v1>|- 问题：零样本导航，目标多样化，泛化能力差<br />- 方法：统一图表示，场景图，图匹配，长期目标生成<br />- 效果：零样本性能，超越特定任务方法|
|🆕 发布|DriveLMM-o1: A Step-by-Step Reasoning Dataset and Large Multimodal Model for Driving Scenario Understanding|DriveLMM-o1：驾驶场景理解的一步一步推理数据集和大型多模态模型|Ayesha Ishaq, Jean Lahoud, Ketan More, Omkar Thawakar, Ritesh Thawkar, Dinura Dissanayake, Noor Ahsan, Yuhao Li .etc.|<http://arxiv.org/pdf/2503.10621v1>|[[代码]](<https://github.com/ayesha-ishaq/DriveLMM-o1.>)<br />- 问题：自动驾驶推理，视觉理解，多模态模型<br />- 方法：DriveLMM-o1，推理数据集，多模态模型<br />- 效果：准确率提升，推理能力增强|
|🆕 发布|R1-Onevision: Advancing Generalized Multimodal Reasoning through Cross-Modal Formalization|R1-Onevision：通过跨模态形式化推进泛化多模态推理|Yi Yang, Xiaoxuan He, Hongkun Pan, Xiyan Jiang, Yan Deng, Xingtao Yang, Haoyu Lu, Dacheng Yin .etc.|<http://arxiv.org/pdf/2503.10615v1>|- 问题：多模态推理，视觉语言模型，性能不足<br />- 方法：跨模态推理，形式化表示，R1-Onevision模型<br />- 效果：先进推理，鲁棒泛化，超越GPT-4o和Qwen2.5-VL|
|🆕 发布|GroundingSuite: Measuring Complex Multi-Granular Pixel Grounding|GroundingSuite：测量复杂多粒度像素定位|Rui Hu, Lianghui Zhu, Yuxuan Zhang, Tianheng Cheng, Lei Liu, Heng Liu, Longjin Ran, Xiaoxin Chen .etc.|<http://arxiv.org/pdf/2503.10596v1>|- 问题：数据集限制，标注效率低<br />- 方法：自动化标注框架，大规模数据集，精心评估基准<br />- 效果：性能提升，效率高|
|🆕 发布|TruthPrInt: Mitigating LVLM Object Hallucination Via Latent Truthful-Guided Pre-Intervention|TruthPrInt：通过潜在真实引导预干预减轻LVLM对象幻觉|Jinhao Duan, Fei Kong, Hao Cheng, James Diffenderfer, Bhavya Kailkhura, Lichao Sun, Xiaofeng Zhu, Xiaoshuang Shi .etc.|<http://arxiv.org/pdf/2503.10602v1>|[[代码]](<https://github.com/jinhaoduan/TruthPrInt.>)<br />- 问题：LVLM Object Hallucination, Internal States, Hallucination Indicators<br />- 方法：TruthPrInt, Latent Truthful-Guided, ComnHallu<br />- 效果：显著优于，OH Mitigation|
|🆕 发布|VisualWebInstruct: Scaling up Multimodal Instruction Data through Web Search|视觉WebInstruct：通过网络搜索扩展多模态指令数据|Yiming Jia, Jiachen Li, Xiang Yue, Bo Li, Ping Nie, Kai Zou, Wenhu Chen|<http://arxiv.org/pdf/2503.10582v1>|- 问题：数据稀缺，推理能力受限<br />- 方法：Web搜索，内容提取，数据合成<br />- 效果：性能提升，最佳模型领先|
|🆕 发布|TokenCarve: Information-Preserving Visual Token Compression in Multimodal Large Language Models|TokenCarve：多模态大型语言模型中的信息保留视觉标记压缩|Xudong Tan, Peng Ye, Chongjun Tu, Jianjian Cao, Yaoxin Yang, Lin Zhang, Dongzhan Zhou, Tao Chen|<http://arxiv.org/pdf/2503.10501v1>|[[代码]](<https://github.com/ShawnTan86/TokenCarve.>)<br />- 问题：MLLMs，视觉token，压缩，信息损失，性能退化<br />- 方法：TokenCarve，IPGS，信息保留，两阶段压缩<br />- 效果：速度提升，存储减少，精度下降小|
|🆕 发布|World Modeling Makes a Better Planner: Dual Preference Optimization for Embodied Task Planning|世界建模让规划更出色：具身任务规划的二元偏好优化|Siyin Wang, Zhaoye Fei, Qinyuan Cheng, Shiduo Zhang, Panpan Cai, Jinlan Fu, Xipeng Qiu|<http://arxiv.org/pdf/2503.10480v1>|- 问题：任务规划，依赖约束，效率，世界建模<br />- 方法：D$^2$PO，偏好学习，树搜索<br />- 效果：成功率高，路径高效|
|📝 更新|HecVL: Hierarchical Video-Language Pretraining for Zero-shot Surgical Phase Recognition|HecVL：基于层次视频-语言预训练的零样本手术阶段识别|Kun Yuan, Vinkle Srivastav, Nassir Navab, Nicolas Padoy|<http://arxiv.org/pdf/2405.10075v2>|[[代码]](<https://github.com/CAMMA-public/SurgVLP>)<br />- 问题：零样本手术阶段识别，视频语言预训练<br />- 方法：层次化视频语言预训练，对比学习，多级文本对齐<br />- 效果：零样本识别，跨数据集迁移，泛化能力强|
|🆕 发布|4D LangSplat: 4D Language Gaussian Splatting via Multimodal Large Language Models|四维LangSplat：基于多模态大型语言模型的四维语言高斯散布|Wanhua Li, Renping Zhou, Jiawei Zhou, Yingwei Song, Johannes Herter, Minghan Qin, Gao Huang, Hanspeter Pfister|<http://arxiv.org/pdf/2503.10437v1>|- 问题：动态场景，4D语言场，时间敏感查询<br />- 方法：4D LangSplat，MLLMs，视频提示<br />- 效果：精确，高效|
|📝 更新|Reasoning to Attend: Try to Understand How <SEG> Token Works|推理以关注：尝试理解<SEG>标记的工作原理|Rui Qian, Xin Yin, Dejing Dou|<http://arxiv.org/pdf/2412.17741v6>|[[代码]](<https://github.com/rui-qian/READ.>)<br />- 问题：<SEG> token工作原理，视觉 grounding<br />- 方法：可视化相似度图，READ模型，SasP模块<br />- 效果：语义相似度匹配，性能提升|
|🆕 发布|VisualPRM: An Effective Process Reward Model for Multimodal Reasoning|视觉PRM：一种有效的多模态推理过程奖励模型|Weiyun Wang, Zhangwei Gao, Lianjie Chen, Zhe Chen, Jinguo Zhu, Xiangyu Zhao, Yangzhou Liu, Yue Cao .etc.|<http://arxiv.org/pdf/2503.10291v1>|[[代码]](<https://internvl.github.io/blog>)<br />- 问题：多模态推理能力，模型性能，数据集构建<br />- 方法：过程奖励模型，多模态数据集，基准测试<br />- 效果：性能提升，推理准确|
|📝 更新|PhysVLM: Enabling Visual Language Models to Understand Robotic Physical Reachability|PhysVLM：使视觉语言模型理解机器人物理可达性|Weijie Zhou, Manli Tao, Chaoyang Zhao, Haiyun Guo, Honghui Dong, Ming Tang, Jinqiao Wang|<http://arxiv.org/pdf/2503.08481v2>|- 问题：VLM，物理可达性，不准确，环境感知<br />- 方法：S-P Map，特征编码器，多机器人数据集<br />- 效果：性能提升，兼容性强|
|📝 更新|Narrating the Video: Boosting Text-Video Retrieval via Comprehensive Utilization of Frame-Level Captions|视频叙事：通过全面利用帧级标题提升文本-视频检索|Chan Hur, Jeong-hun Hong, Dong-hun Lee, Dabin Kang, Semin Myeong, Sang-hyo Park, Hyeyoung Park|<http://arxiv.org/pdf/2503.05186v3>|- 问题：语义捕捉，信息错误，视频检索<br />- 方法：帧级字幕，多模态交互，自适应过滤，双模态匹配，硬负样本<br />- 效果：性能提升，最先进|
|📝 更新|FaVChat: Unlocking Fine-Grained Facial Video Understanding with Multimodal Large Language Models|FaVChat：利用多模态大型语言模型解锁细粒度面部视频理解|Fufangchen Zhao, Ming Li, Linrui Xu, Wenhao Jiang, Jian Gao, Danfeng Yan|<http://arxiv.org/pdf/2503.09158v2>|- 问题：细粒度面部理解，VMLLMs，面部视频<br />- 方法：FaVChat，混合模型架构，多粒度表示<br />- 效果：超越现有VMLLMs，零样本评估|
|🆕 发布|MouseGPT: A Large-scale Vision-Language Model for Mouse Behavior Analysis|MouseGPT：用于小鼠行为分析的大规模视觉-语言模型|Teng Xu, Taotao Zhou, Youjia Wang, Peng Yang, Simin Tang, Kuixiang Shao, Zifeng Tang, Yifei Liu .etc.|<http://arxiv.org/pdf/2503.10212v1>|- 问题：动物行为分析，机器视觉局限性，行为量化，行为解释<br />- 方法：视觉-语言模型，大规模数据集，行为标注<br />- 效果：行为分析，行为发现，模型性能提升|
|📝 更新|AnomalyDINO: Boosting Patch-based Few-shot Anomaly Detection with DINOv2|异常DINO：利用DINOv2增强基于补丁的少样本异常检测|Simon Damm, Mike Laszkiewicz, Johannes Lederer, Asja Fischer|<http://arxiv.org/pdf/2405.14529v3>|- 问题：Few-shot Anomaly Detection, Vision-Only, Industrial Applications<br />- 方法：DINOv2, Patch-based, AnomalyDINO<br />- 效果：State-of-the-art, AUROC, Fast Deployment|
|🆕 发布|Through the Magnifying Glass: Adaptive Perception Magnification for Hallucination-Free VLM Decoding|通过放大镜：无幻觉VLM解码的自适应感知放大|Shunqi Mao, Chaoyi Zhang, Weidong Cai|<http://arxiv.org/pdf/2503.10183v1>|[[代码]](<https://github.com/ShunqiM/PM>)<br />- 问题：视觉幻觉，VLM，解码偏差<br />- 方法：感知放大器，迭代隔离，区域放大<br />- 效果：幻觉减少，语言生成增强|
|🆕 发布|LVAgent: Long Video Understanding by Multi-Round Dynamical Collaboration of MLLM Agents|LVAgent：通过多轮动态协作的MLLM代理实现长视频理解|Boyu Chen, Zhengrong Yue, Siran Chen, Zikang Wang, Yang Liu, Peng Li, Yali Wang|<http://arxiv.org/pdf/2503.10200v1>|- 问题：长视频理解，MLLM，时间建模，性能有限<br />- 方法：多轮动态协作，检索方案，性能优化<br />- 效果：超越现有模型，准确率80%，提升14.3%|
|📝 更新|M2IST: Multi-Modal Interactive Side-Tuning for Efficient Referring Expression Comprehension|M2IST：多模态交互式旁调优高效指代表达理解|Xuyang Liu, Ting Liu, Siteng Huang, Yi Xin, Yue Hu, Quanjun Yin, Donglin Wang, Yuanyuan Wu .etc.|<http://arxiv.org/pdf/2407.01131v4>|[[代码]](<https://github.com/xuyang-liu16/M2IST.>)<br />- 问题：REC，PETL，多模态交互，GPU内存，参数效率<br />- 方法：M2IST，M3ISAs，侧调优，预训练模型<br />- 效果：性能效率，参数少，内存低|
|📝 更新|V-LoRA: An Efficient and Flexible System Boosts Vision Applications with LoRA LMM|V-LoRA：一种高效灵活的系统通过LoRA LMM提升视觉应用|Liang Mi, Weijun Wang, Wenming Tu, Qingfeng He, Rui Kong, Xinyu Fang, Yazhu Dong, Yikang Zhang .etc.|<http://arxiv.org/pdf/2411.00915v4>|- 问题：LoRA模型，计算成本高，延迟高<br />- 方法：LoRA LMM，自适应批处理，灵活编排<br />- 效果：精度提升，延迟降低|
|🆕 发布|A Hierarchical Semantic Distillation Framework for Open-Vocabulary Object Detection|开放词汇目标检测的分层语义蒸馏框架|Shenghao Fu, Junkai Yan, Qize Yang, Xihan Wei, Xiaohua Xie, Wei-Shi Zheng|<http://arxiv.org/pdf/2503.10152v1>|- 问题：开放词汇目标检测，语义知识学习，特征空间对齐<br />- 方法：层次语义蒸馏，CLIP模型知识利用，多级语义提取<br />- 效果：AP提升，性能优于其他|
|📝 更新|ECBench: Can Multi-modal Foundation Models Understand the Egocentric World? A Holistic Embodied Cognition Benchmark|ECBench：多模态基础模型能否理解以自我为中心的世界？一个整体具身认知基准|Ronghao Dang, Yuqian Yuan, Wenqi Zhang, Yifei Xin, Boqiang Zhang, Long Li, Liuyi Wang, Qinyang Zeng .etc.|<http://arxiv.org/pdf/2501.05031v2>|[[代码]](<https://github.com/Rh-Dang/ECBench.>)<br />- 问题：多模态基础模型，认知能力，评估框架<br />- 方法：ECBench，人类标注，ECEval<br />- 效果：认知能力提升，可靠模型|
|🆕 发布|Hybrid Agents for Image Restoration|混合代理用于图像恢复|Bingchen Li, Xin Li, Yiting Lu, Zhibo Chen|<http://arxiv.org/pdf/2503.10120v1>|- 问题：图像修复，模式选择，用户交互，效率限制<br />- 方法：混合代理，多模式集成，指令微调<br />- 效果：智能交互，效率提升|
|📝 更新|Deciphering Functions of Neurons in Vision-Language Models|解码视觉-语言模型中神经元的功能|Jiaqi Xu, Cuiling Lan, Xuejin Chen, Yan Lu|<http://arxiv.org/pdf/2502.18485v3>|- 问题：VLMs神经元功能，可解释性<br />- 方法：神经元激活观察，GPT-4o辅助解释，激活模拟器<br />- 效果：神经元分类，系统统计分析|
|📝 更新|Mono-InternVL: Pushing the Boundaries of Monolithic Multimodal Large Language Models with Endogenous Visual Pre-training|Mono-InternVL：通过内源视觉预训练推动单体多模态大型语言模型的边界|Gen Luo, Xue Yang, Wenhan Dou, Zhaokai Wang, Jiawen Liu, Jifeng Dai, Yu Qiao, Xizhou Zhu|<http://arxiv.org/pdf/2410.08202v3>|[[代码]](<https://github.com/OpenGVLab/Mono-InternVL.>)<br />- 问题：不稳定优化，灾难性遗忘，视觉预训练<br />- 方法：视觉参数空间嵌入，多模态混合专家结构，内源视觉预训练<br />- 效果：性能提升，延迟降低|
|🆕 发布|Bayesian Prompt Flow Learning for Zero-Shot Anomaly Detection|贝叶斯提示流学习用于零样本异常检测|Zhen Qu, Xian Tao, Xinyi Gong, Shichen Qu, Qiyu Chen, Zhengtao Zhang, Xingang Wang, Guiguang Ding|<http://arxiv.org/pdf/2503.10080v1>|- 问题：零样本异常检测，文本提示，泛化能力<br />- 方法：贝叶斯提示流学习，提示空间建模，残差交叉注意力<br />- 效果：性能提升，泛化增强|
|📝 更新|LongProLIP: A Probabilistic Vision-Language Model with Long Context Text|LongProLIP：一种具有长上下文文本的概率视觉-语言模型|Sanghyuk Chun, Sangdoo Yun|<http://arxiv.org/pdf/2503.08048v2>|[[代码]](<https://github.com/naver-ai/prolip>)<br />- 问题：ProLIP，长文本处理，上下文信息<br />- 方法：LongProLIP，微调策略，扩展文本长度<br />- 效果：长文本理解，零样本能力|
|🆕 发布|How Do Multimodal Large Language Models Handle Complex Multimodal Reasoning? Placing Them in An Extensible Escape Game|如何处理复杂的多模态推理：将多模态大型语言模型置于可扩展的逃脱游戏中|Ziyue Wang, Yurui Dong, Fuwen Luo, Minyuan Ruan, Zhili Cheng, Chi Chen, Peng Li, Yang Liu|<http://arxiv.org/pdf/2503.10042v1>|- 问题：复杂多模态推理，评估方法单一，模型行为分析不足<br />- 方法：MM-Escape基准，EscapeCraft环境，多模态推理评估<br />- 效果：揭示模型局限，发现改进潜力|
|📝 更新|Learning Visual Proxy for Compositional Zero-Shot Learning|学习视觉代理用于组合式零样本学习|Shiyu Zhang, Cheng Yan, Yang Liu, Chenchen Jing, Lei Zhou, Wenjun Wang|<http://arxiv.org/pdf/2501.13859v3>|- 问题：CZSL，模态差距，文本原型，视觉特征<br />- 方法：视觉代理学习，CMJL策略，初始化视觉代理<br />- 效果：性能提升，泛化能力强|
|🆕 发布|Style Evolving along Chain-of-Thought for Unknown-Domain Object Detection|基于思维链的未知领域目标检测风格演化|Zihao Zhang, Aming Wu, Yahong Han|<http://arxiv.org/pdf/2503.09968v1>|- 问题：Single-DGOD，跨域检测，风格组合，单步提示<br />- 方法：风格演化，思维链，多风格融合<br />- 效果：性能提升，泛化能力增强|
|🆕 发布|UVE: Are MLLMs Unified Evaluators for AI-Generated Videos?|UVE：MLLMs是AI生成视频的统一评估器吗？|Yuanxin Liu, Rui Zhu, Shuhuai Ren, Jiacong Wang, Haoyuan Guo, Xu Sun, Lu Jiang|<http://arxiv.org/pdf/2503.09949v1>|[[代码]](<https://github.com/bytedance/UVE.>)<br />- 问题：AI视频评估，MLLMs，统一评估<br />- 方法：UVE-Bench，多方面评估，MLLMs应用<br />- 效果：超越现有方法，性能提升|
|🆕 发布|Emotion Recognition with CLIP and Sequential Learning|基于CLIP和序列学习的情感识别|Weiwei Zhou, Chenkun Ling, Zefeng Cai|<http://arxiv.org/pdf/2503.09929v1>|- 问题：情感识别，连续性，挑战<br />- 方法：CLIP微调，TCN模块，Transformer<br />- 效果：性能提升，准确性高|
|📝 更新|Enhancing Vision-Language Pre-training with Rich Supervisions|增强视觉-语言预训练的丰富监督|Yuan Gao, Kunyu Shi, Pengkai Zhu, Edouard Belval, Oren Nuriel, Srikar Appalaraju, Shabnam Ghadar, Vijay Mahadevan .etc.|<http://arxiv.org/pdf/2403.03346v2>|- 问题：视觉语言预训练，数据限制，性能提升<br />- 方法：强监督预训练，屏幕截图，HTML结构<br />- 效果：性能提升，任务泛化|
|📝 更新|Non-autoregressive Sequence-to-Sequence Vision-Language Models|非自回归序列到序列视觉-语言模型|Kunyu Shi, Qi Dong, Luis Goncalves, Zhuowen Tu, Stefano Soatto|<http://arxiv.org/pdf/2403.02249v2>|- 问题：推理延迟，自回归生成，性能受限<br />- 方法：并行解码，Query-CTC损失，联合分布建模<br />- 效果：性能相当，推理加速|


### 多模态融合 (Multimodal Fusion)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OVTR: End-to-End Open-Vocabulary Multiple Object Tracking with Transformer|OVTR：基于Transformer的端到端开放词汇多目标跟踪|Jinyang Li, En Yu, Sijia Chen, Wenbing Tao|<http://arxiv.org/pdf/2503.10616v1>|[[代码]](<https://github.com/jinyanglii/OVTR.>)<br />- 问题：开放词汇，多目标跟踪，性能受限<br />- 方法：Transformer，类别信息传播，双分支结构<br />- 效果：性能提升，速度加快，适应性强|
|🆕 发布|Interactive Multimodal Fusion with Temporal Modeling|交互式多模态融合与时间建模|Jun Yu, Yongqi Wang, Lei Wang, Yang Zheng, Shengfan Xu|<http://arxiv.org/pdf/2503.10523v1>|- 问题：情感分析，多模态融合，时空建模<br />- 方法：ResNet，VGG模型，TCN，跨模态注意力<br />- 效果：性能竞争，Aff-Wild2|
|📝 更新|Exploring a Multimodal Fusion-based Deep Learning Network for Detecting Facial Palsy|探索基于多模态融合的深度学习网络检测面瘫|Heng Yim Nicole Oo, Min Hun Lee, Jeong Hoon Lim|<http://arxiv.org/pdf/2405.16496v2>|- 问题：面部麻痹检测，主观评估，数据模态<br />- 方法：多模态融合，深度学习，特征提取<br />- 效果：精度提升，召回率提升|
|🆕 发布|A Multimodal Fusion Model Leveraging MLP Mixer and Handcrafted Features-based Deep Learning Networks for Facial Palsy Detection|基于MLP混合器和手工特征深度学习网络的跨模态融合模型用于面瘫检测|Heng Yim Nicole Oo, Min Hun Lee, Jeong Hoon Lim|<http://arxiv.org/pdf/2503.10371v1>|- 问题：面部麻痹检测，主观评估，数据模态<br />- 方法：MLP mixer，手工艺特征，多模态融合<br />- 效果：F1值96.00，显著提升|
|📝 更新|Ultra-high resolution multimodal MRI dense labelled holistic brain atlas|超高清多模态MRI密集标注整体脑图谱|José V. Manjón, Sergio Morell-Ortega, Marina Ruiz-Perez, Boris Mansencal, Edern Le Bot, Marien Gadea, Enrique Lanuza, Gwenaelle Catheline .etc.|<http://arxiv.org/pdf/2501.16879v2>|- 问题：脑图谱，多模态，高分辨率，神经疾病检测<br />- 方法：融合协议，对称组群归一化，多尺度标签<br />- 效果：高分辨率，一致性，新方法开发|
|🆕 发布|A Multi-Modal Federated Learning Framework for Remote Sensing Image Classification|多模态联邦学习框架用于遥感图像分类|Barış Büyüktaş, Gencer Sumbul, Begüm Demir|<http://arxiv.org/pdf/2503.10262v1>|- 问题：多模态，遥感图像，分类，数据异构<br />- 方法：多模态融合，特征白化，互信息最大化<br />- 效果：性能提升，多标签，像素级|
|🆕 发布|Multi-Modal Mamba Modeling for Survival Prediction (M4Survive): Adapting Joint Foundation Model Representations|多模态Mamba建模用于生存预测（M4Survive）：联合基础模型表示的适应|Ho Hin Lee, Alberto Santamaria-Pang, Jameson Merkov, Matthew Lungren, Ivan Tarapov|<http://arxiv.org/pdf/2503.10057v1>|- 问题：生存预测，多模态，肿瘤生物学，互补洞察<br />- 方法：M4Survive，联合基础模型，高效适配器网络<br />- 效果：多模态学习，精度提升，预测分析|


### 跨模态对齐 (Cross-modal Alignment)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dual-Stage Cross-Modal Network with Dynamic Feature Fusion for Emotional Mimicry Intensity Estimation|双阶段跨模态网络与动态特征融合用于情感模仿强度估计|Jun Yu, Lingsi Zhu, Yanjun Chi, Yunxiang Zhang, Yang Zheng, Yongqi Wang, Xilong Lu|<http://arxiv.org/pdf/2503.10603v1>|- 问题：情感模仿强度，动态关联，多模态融合<br />- 方法：双阶段对齐，动态融合模块，质量引导融合<br />- 效果：性能提升，细粒度分析|
|🆕 发布|NeighborRetr: Balancing Hub Centrality in Cross-Modal Retrieval|邻域检索：跨模态检索中平衡中心性|Zengrong Lin, Zheng Wang, Tianwen Qian, Pan Mu, Sixian Chan, Cong Bai|<http://arxiv.org/pdf/2503.10526v1>|[[代码]](<https://github.com/zzezze/NeighborRetr>)<br />- 问题：跨模态检索，hubness问题，代表性偏差<br />- 方法：NeighborRetr，平衡学习，自适应调整<br />- 效果：性能提升，泛化能力强|
|🆕 发布|RealGeneral: Unifying Visual Generation via Temporal In-Context Learning with Video Models|RealGeneral：通过视频模型的时间内情境学习统一视觉生成|Yijing Lin, Mengqi Huang, Shuhan Zhuang, Zhendong Mao|<http://arxiv.org/pdf/2503.10406v1>|[[代码]](<https://lyne1.github.io/RealGeneral>)<br />- 问题：视觉生成任务统一，泛化性差<br />- 方法：视频模型，条件帧预测，统一嵌入模块<br />- 效果：生成质量提升，任务性能增强|
|📝 更新|EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotions|EMOVA：赋予语言模型看见、听见和表达生动情感的能力|Kai Chen, Yunhao Gou, Runhui Huang, Zhili Liu, Daxin Tan, Jing Xu, Chunwei Wang, Yi Zhu .etc.|<http://arxiv.org/pdf/2409.18042v3>|- 问题：多模态感知，生成，公开数据挑战<br />- 方法：EMOVA模型，语义声学解耦，风格模块<br />- 效果：SOTA性能，多模态对话|
|📝 更新|Audio-Visual Deepfake Detection With Local Temporal Inconsistencies|基于局部时间不一致性的音视频深度伪造检测|Marcella Astrid, Enjie Ghorbel, Djamila Aouada|<http://arxiv.org/pdf/2501.08137v4>|- 问题：深伪视频检测，时序不一致性<br />- 方法：时序距离图，注意力机制，伪假生成<br />- 效果：检测效果佳，数据集验证|
|📝 更新|Reliable Representation Learning for Incomplete Multi-View Missing Multi-Label Classification|可靠的缺失多视图多标签分类的表示学习|Chengliang Liu, Jie Wen, Yong Xu, Bob Zhang, Liqiang Nie, Min Zhang|<http://arxiv.org/pdf/2303.17117v3>|- 问题：多视图，多标签，缺失数据，分类<br />- 方法：对比学习，质量感知子网络，标签驱动<br />- 效果：性能提升，泛化能力强|
|📝 更新|Seeing is Understanding: Unlocking Causal Attention into Modality-Mutual Attention for Multimodal LLMs|视觉理解：解锁因果注意力以实现多模态LLMs的模态互注意力|Wei-Yao Wang, Zhao Wang, Helen Suzuki, Yoshiyuki Kobayashi|<http://arxiv.org/pdf/2503.02597v2>|[[代码]](<https://github.com/sony/aki>)<br />- 问题：视觉语言不匹配，因果注意力限制<br />- 方法：模态互注意力，MapleLeaf AKI<br />- 效果：性能提升，泛化能力强|
|🆕 发布|Cosh-DiT: Co-Speech Gesture Video Synthesis via Hybrid Audio-Visual Diffusion Transformers|Cosh-DiT：基于混合音频-视觉扩散变换器的共语音手势视频合成|Yasheng Sun, Zhiliang Xu, Hang Zhou, Jiazhi Guan, Quanwei Yang, Kaisiyuan Wang, Borong Liang, Yingying Li .etc.|<http://arxiv.org/pdf/2503.09942v1>|- 问题：Co-speech gesture video synthesis, rhythmic nuances, realistic images<br />- 方法：Hybrid Diffusion Transformers, audio-to-motion, motion-to-video<br />- 效果：lifelike videos, expressive gestures, seamless alignment|


## 目标检测识别 (Object Detection & Recognition)


### 二维检测 (2D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Transformers without Normalization|无归一化的Transformer|Jiachen Zhu, Xinlei Chen, Kaiming He, Yann LeCun, Zhuang Liu|<http://arxiv.org/pdf/2503.10622v1>|- 问题：Transformer，Normalization，性能<br />- 方法：Dynamic Tanh，DyT，替代<br />- 效果：匹配，超越，性能|
|🆕 发布|MASQUE: A Text-Guided Diffusion-Based Framework for Localized and Customized Adversarial Makeup|MASQUE：一种基于文本引导的扩散框架，用于局部化和定制对抗性化妆|Youngjin Kwon, Xiao Zhang|<http://arxiv.org/pdf/2503.10549v1>|- 问题：隐私保护，反人脸识别，生成对抗，视觉瑕疵，适应性差<br />- 方法：文本引导，扩散模型，局部化，对抗指导<br />- 效果：成功率提升，保真度高，适应性强|
|🆕 发布|Hoi2Anomaly: An Explainable Anomaly Detection Approach Guided by Human-Object Interaction|Hoi2Anomaly：基于人-物交互的可解释异常检测方法|Yuhan Wang, Cheng Liu, Daou Zhang, Weichao Wu|<http://arxiv.org/pdf/2503.10508v1>|- 问题：异常检测，语义信息缺乏，解释性不足<br />- 方法：多模态指令微调，HOI提取，VLP框架微调<br />- 效果：精度高，可解释|
|📝 更新|Making Every Frame Matter: Continuous Activity Recognition in Streaming Video via Adaptive Video Context Modeling|让每一帧都重要：通过自适应视频上下文建模在流媒体视频中的连续活动识别|Hao Wu, Donglin Bai, Shiqi Jiang, Qianxi Zhang, Yifan Yang, Xin Ding, Ting Cao, Yunxin Liu .etc.|<http://arxiv.org/pdf/2410.14993v2>|- 问题：视频活动识别，多尺度，未剪辑<br />- 方法：自适应视频上下文建模，活动空间特征提取，动态适应性<br />- 效果：速度30FPS，准确率提升，零样本性能|
|🆕 发布|HSEmotion Team at ABAW-8 Competition: Audiovisual Ambivalence/Hesitancy, Emotional Mimicry Intensity and Facial Expression Recognition|HSEmotion团队在ABAW-8竞赛中的表现：视听矛盾/犹豫、情感模仿强度与面部表情识别|Andrey V. Savchenko|<http://arxiv.org/pdf/2503.10399v1>|- 问题：情感行为分析，视频表情识别<br />- 方法：预训练模型，音频特征，文本嵌入，多层感知器<br />- 效果：性能提升，验证指标提高|
|🆕 发布|Enhancing Facial Privacy Protection via Weakening Diffusion Purification|通过弱化扩散净化增强面部隐私保护|Ali Salar, Qing Liu, Yingli Tian, Guoying Zhao|<http://arxiv.org/pdf/2503.10350v1>|- 问题：面部隐私，扩散模型，隐私保护<br />- 方法：无条件嵌入，身份保持结构，对抗性修改<br />- 效果：保护成功率提升，自然外观|
|📝 更新|Revealing Bias Formation in Deep Neural Networks Through the Geometric Mechanisms of Human Visual Decoupling|通过人类视觉解耦的几何机制揭示深度神经网络中的偏差形成|Yanbiao Ma, Bowei Liu, Boyuan Gao, Wei Dai, Jiayi Chen, Shuo Li|<http://arxiv.org/pdf/2502.11809v2>|- 问题：DNNs偏见，几何分析，感知流形<br />- 方法：人类视觉系统启发，几何复杂性，感知流形几何库<br />- 效果：揭示偏见，计算几何属性|
|🆕 发布|PS3C: An Ensemble-Based Two-Step Framework for Classification of Pep Smear Cell Images|PS3C：一种基于集成学习的两步分类法用于肽染色细胞图像分类|Theo Di Piazza, Loic Boussel|<http://arxiv.org/pdf/2503.10312v1>|- 问题：宫颈癌早期检测，细胞图像分类<br />- 方法：两阶段集成框架，神经网络，图像识别<br />- 效果：自动化工具，工作量减轻|
|📝 更新|ATRNet-STAR: A Large Dataset and Benchmark Towards Remote Sensing Object Recognition in the Wild|ATRNet-STAR：迈向野外遥感目标识别的大数据集和基准|Yongxiang Liu, Weijie Li, Li Liu, Jie Zhou, Bowen Peng, Yafei Song, Xuying Xiong, Wei Yang .etc.|<http://arxiv.org/pdf/2501.13354v4>|- 问题：SAR ATR数据集，深度学习应用，数据收集困难<br />- 方法：ATRNet-STAR数据集，大规模，多类别，标注样本<br />- 效果：性能提升，基准建立，研究推进|
|🆕 发布|Unveiling the Invisible: Reasoning Complex Occlusions Amodally with AURA|揭示无形：使用AURA模态无关地推理复杂遮挡|Zhixuan Li, Hyunse Yoon, Sanghoon Lee, Weisi Lin|<http://arxiv.org/pdf/2503.10225v1>|- 问题：amodal segmentation，复杂遮挡，用户交互<br />- 方法：AURA模型，全局设计，空间设计<br />- 效果：有效预测，数据集，公开|
|🆕 发布|CoStoDet-DDPM: Collaborative Training of Stochastic and Deterministic Models Improves Surgical Workflow Anticipation and Recognition|CoStoDet-DDPM：协作训练随机和确定性模型以提升手术流程预测与识别|Kaixiang Yang, Xin Li, Qiang Li, Zhiwei Wang|<http://arxiv.org/pdf/2503.10216v1>|[[代码]](<https://github.com/kk42yy/CoStoDet-DDPM.>)<br />- 问题：手术流程预测，不确定性，确定性模型<br />- 方法：DDPM，协同训练，不确定性捕捉<br />- 效果：eMAE降低16%，Jaccard提升1.0%|
|📝 更新|VIGFace: Virtual Identity Generation for Privacy-Free Face Recognition|VIGFace：隐私保护的人脸虚拟身份生成|Minsoo Kim, Min-Cheol Sagong, Gi Pyo Nam, Junghyun Cho, Ig-Jae Kim|<http://arxiv.org/pdf/2403.08277v3>|- 问题：隐私，数据获取，合成图像，人脸识别<br />- 方法：虚拟身份，特征空间，扩散模型<br />- 效果：隐私保护，性能提升|
|🆕 发布|Mamba-VA: A Mamba-based Approach for Continuous Emotion Recognition in Valence-Arousal Space|Mamba-VA：基于Mamba的连续情感识别在效价-唤醒空间中的方法|Yuheng Liang, Zheyu Wang, Feng Liu, Mingzhou Liu, Yu Yao|<http://arxiv.org/pdf/2503.10104v1>|[[代码]](<https://github.com/FreedomPuppy77/Charon.>)<br />- 问题：连续情绪识别，长期依赖，复杂时序<br />- 方法：Mamba架构，MAE，TCN，长序列建模<br />- 效果：性能提升，优于基线|
|📝 更新|Affective Behaviour Analysis via Progressive Learning|情感行为分析通过渐进式学习|Chen Liu, Wei Zhang, Feng Qiu, Lincheng Li, Xin Yu|<http://arxiv.org/pdf/2407.16945v3>|[[代码]](<https://github.com/YenanLiu/ABAW7th.>)<br />- 问题：情感行为分析，多任务学习，s-Aff-Wild2数据库<br />- 方法：渐进式学习，特征融合，时序建模<br />- 效果：多任务学习，性能提升|


### 三维检测 (3D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Semantic-Supervised Spatial-Temporal Fusion for LiDAR-based 3D Object Detection|基于激光雷达的3D目标检测的语义监督时空融合|Chaoqun Wang, Xiaobin Hong, Wenzhong Li, Ruimao Zhang|<http://arxiv.org/pdf/2503.10579v1>|- 问题：LiDAR点稀疏，时空信息利用，空间错位<br />- 方法：ST-Fusion，空间聚合，时间融合，语义注入<br />- 效果：NDS提升2.8%，nuScenes基准|
|🆕 发布|Lightweight Models for Emotional Analysis in Video|轻量级模型在视频情感分析中的应用|Quoc-Tien Nguyen, Hong-Hai Nguyen, Van-Thong Huynh|<http://arxiv.org/pdf/2503.10530v1>|- 问题：情感分析，视频，轻量级模型<br />- 方法：MobileNetV4，3D MLP-Mixer，多尺度特征<br />- 效果：效率高，准确性好|
|🆕 发布|PiSA: A Self-Augmented Data Engine and Training Strategy for 3D Understanding with Large Models|PiSA：用于大型模型3D理解的自我增强数据引擎和训练策略|Zilu Guo, Hongbin Lin, Zhihao Yuan, Chaoda Zheng, Pengshuo Qiu, Dongzhi Jiang, Renrui Zhang, Chun-Mei Feng .etc.|<http://arxiv.org/pdf/2503.10529v1>|- 问题：3D数据集，模态差距，领域差距<br />- 方法：PiSA-Engine，PointLLM-PiSA，PiSA-Bench<br />- 效果：性能提升，零样本能力|
|📝 更新|WonderVerse: Extendable 3D Scene Generation with Video Generative Models|奇境：基于视频生成模型的可扩展3D场景生成|Hao Feng, Zhi Zuo, Jia-Hui Pan, Ka-Hei Hui, Yihua Shao, Qi Dou, Wei Xie, Zhengzhe Liu|<http://arxiv.org/pdf/2503.09160v2>|- 问题：3D场景生成，几何失真，扩展性差<br />- 方法：视频生成模型，3D场景扩展，异常序列检测<br />- 效果：高沉浸感，几何一致性，扩展性|
|🆕 发布|Hyper3D: Efficient 3D Representation via Hybrid Triplane and Octree Feature for Enhanced 3D Shape Variational Auto-Encoders|Hyper3D：通过混合三平面和八叉树特征实现高效的3D表示以增强3D形状变分自编码器|Jingyu Guo, Sensen Gao, Jia-Wang Bian, Wanhu Sun, Heliang Zheng, Rongfei Jia, Mingming Gong|<http://arxiv.org/pdf/2503.10403v1>|- 问题：3D形状压缩，几何细节损失，3D表示效率低<br />- 方法：混合三平面，八叉树特征，高分辨率表示<br />- 效果：高保真度，细节丰富|
|🆕 发布|ROODI: Reconstructing Occluded Objects with Denoising Inpainters|ROODI：利用去噪修复器重建遮挡物体|Yeonjin Chang, Erqun Dong, Seunghyeon Seo, Nojun Kwak, Kwang Moo Yi|<http://arxiv.org/pdf/2503.10256v1>|- 问题：物体提取，遮挡处理，3D Gaussian Splatting<br />- 方法：对象中心，剪枝，生成式修复<br />- 效果：性能提升，超越现有方法|
|📝 更新|GraphBEV: Towards Robust BEV Feature Alignment for Multi-Modal 3D Object Detection|GraphBEV：迈向鲁棒的BEV特征对齐的多模态3D目标检测|Ziying Song, Lei Yang, Shaoqing Xu, Lin Liu, Dongyang Xu, Caiyan Jia, Feiyang Jia, Li Wang|<http://arxiv.org/pdf/2403.11848v4>|- 问题：BEV特征对齐，深度估计误差，传感器校准不准确<br />- 方法：Graph匹配，局部对齐，全局对齐<br />- 效果：性能提升，mAP 70.1%，超越BEV Fusion|
|📝 更新|Learning to Detect Objects from Multi-Agent LiDAR Scans without Manual Labels|从多智能体激光雷达扫描中学习检测对象而不需要人工标签|Qiming Xia, Wenkai Lin, Haoen Xiang, Xun Huang, Siheng Chen, Zhen Dong, Cheng Wang, Chenglu Wen|<http://arxiv.org/pdf/2503.08421v2>|[[代码]](<https://github.com/xmuqimingxia/DOtA.>)<br />- 问题：无监督3D目标检测，数据稀疏，伪标签低质量<br />- 方法：DOtA，多代理LiDAR扫描，多尺度编码<br />- 效果：性能优于现有方法，验证有效|
|📝 更新|From Slices to Sequences: Autoregressive Tracking Transformer for Cohesive and Consistent 3D Lymph Node Detection in CT Scans|从切片到序列：用于CT扫描中连贯一致3D淋巴结检测的自回归跟踪Transformer|Qinji Yu, Yirui Wang, Ke Yan, Dandan Zheng, Dashan Ai, Dazhou Guo, Zhanghexuan Ji, Yanzhou Su .etc.|<http://arxiv.org/pdf/2503.07933v2>|- 问题：3D淋巴结检测，切片一致性，2.5D方法，跟踪任务<br />- 方法：LN-Tracker，Transformer，自回归跟踪，掩码注意力<br />- 效果：性能提升，泛化能力强|


### 多目标跟踪 (Multi-object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OmniSTVG: Toward Spatio-Temporal Omni-Object Video Grounding|全时空全对象视频定位：迈向时空全对象视频定位|Jiali Yao, Xinran Deng, Xin Gu, Mengrui Dai, Bing Fan, Zhipeng Zhang, Yan Huang, Heng Fan .etc.|<http://arxiv.org/pdf/2503.10500v1>|[[代码]](<https://github.com/JellyYao3000/OmniSTVG.>)<br />- 问题：STVG，多目标定位，时空信息<br />- 方法：OmniSTVG，BOSTVG，OmniTube<br />- 效果：全面理解，基准数据集|


## 时序理解 (Temporal Understanding)


### 时序分析 (Temporal Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|BIMBA: Selective-Scan Compression for Long-Range Video Question Answering|BIMBA：长距离视频问答的选择性扫描压缩|Md Mohaiminul Islam, Tushar Nagarajan, Huiyu Wang, Gedas Bertasius, Lorenzo Torresani|<http://arxiv.org/pdf/2503.09590v2>|- 问题：长视频VQA，信息提取，长距离依赖，计算成本高<br />- 方法：选择性扫描，状态空间模型，高效信息选择<br />- 效果：准确率提升，性能优化|
|📝 更新|LaMMA-P: Generalizable Multi-Agent Long-Horizon Task Allocation and Planning with LM-Driven PDDL Planner|LaMMA-P：基于LM驱动的PDDL规划器的通用多智能体长时程任务分配与规划|Xiaopan Zhang, Hao Qin, Fuquan Wang, Yue Dong, Jiachen Li|<http://arxiv.org/pdf/2409.20560v2>|- 问题：长时任务分配，多机器人协作，自然语言理解<br />- 方法：语言模型驱动，PDDL规划，多智能体<br />- 效果：成功率提升，效率提高|
|🆕 发布|DTA: Dual Temporal-channel-wise Attention for Spiking Neural Networks|双时序通道注意力：用于脉冲神经网络|Minje Kim, Minjun Kim, Xu Yang|<http://arxiv.org/pdf/2503.10052v1>|[[代码]](<https://github.com/MnJnKIM/DTA-SNN.>)<br />- 问题：SNNs，时间信息利用，注意力机制<br />- 方法：DTA，双时序通道注意力，融合策略<br />- 效果：性能提升，复杂关系捕捉|
|🆕 发布|TIME: Temporal-sensitive Multi-dimensional Instruction Tuning and Benchmarking for Video-LLMs|时间敏感的多维度视频LLMs指令微调和基准测试：TIME|Yunxiao Wang, Meng Liu, Rui Shao, Haoyu Zhang, Bin Wen, Fan Yang, Tingting Gao, Di Zhang .etc.|<http://arxiv.org/pdf/2503.09994v1>|- 问题：视频LLMs时序理解，数据标注成本高<br />- 方法：多维度指令微调，多任务提示微调，新基准<br />- 效果：时序理解提升，避免捷径|


## 三维重建 (3D Reconstruction)


### 多视图重建 (Multi-view Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MVGSR: Multi-View Consistency Gaussian Splatting for Robust Surface Reconstruction|多视图一致性高斯分层用于鲁棒表面重建|Chenfeng Hou, Qi Xun Yeo, Mengqi Guo, Yongxin Su, Yanyan Li, Gim Hee Lee|<http://arxiv.org/pdf/2503.08093v2>|- 问题：3DGS，表面重建，动态物体，不一致性，伪影<br />- 方法：多视图一致性，Gaussian模型，干扰掩码，多视图贡献<br />- 效果：几何精度，渲染保真度|
|📝 更新|AdaptiveFusion: Adaptive Multi-Modal Multi-View Fusion for 3D Human Body Reconstruction|自适应融合：自适应多模态多视图融合用于3D人体重建|Anjun Chen, Xiangyu Wang, Zhi Xu, Kun Shi, Yan Qin, Yuchi Huo, Jiming Chen, Qi Ye|<http://arxiv.org/pdf/2409.04851v3>|- 问题：单一传感器依赖，融合方法定制化，噪声敏感<br />- 方法：自适应多模态融合，Transformer模型，模态采样模块<br />- 效果：高精度，泛化性强|
|🆕 发布|RSR-NF: Neural Field Regularization by Static Restoration Priors for Dynamic Imaging|RSR-NF：基于静态恢复先验的动态成像神经网络场正则化|Berk Iskender, Sushan Nakarmi, Nitin Daphalapurkar, Marc L. Klasky, Yoram Bresler|<http://arxiv.org/pdf/2503.10015v1>|- 问题：动态成像，dCT，逆问题，数据稀缺<br />- 方法：神经场，RED框架，静态深度空间先验<br />- 效果：重建改善，超越现有技术|
|🆕 发布|Reference-Free 3D Reconstruction of Brain Dissection Photographs with Machine Learning|基于机器学习的无参考脑部解剖照片的3D重建|Lin Tian, Sean I. Young, Jonathan Williams Ramirez, Dina Zemlyanker, Lucas Jacob Deden Binder, Rogeny Herisse, Theresa R. Connors, Derek H. Oakley .etc.|<http://arxiv.org/pdf/2503.09963v1>|[[代码]](<https://github.com/lintian-a/reffree.>)<br />- 问题：3D重建，脑切片，无参考，病理学<br />- 方法：机器学习，3D坐标估计，合成数据训练<br />- 效果：性能相当，部分堆叠重建|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Architecture-Aware Minimization (A$^2$M): How to Find Flat Minima in Neural Architecture Search|架构感知最小化（A$^2$M）：如何在神经架构搜索中找到平坦的最小值|Matteo Gambella, Fabrizio Pittorino, Manuel Roveri|<http://arxiv.org/pdf/2503.10404v1>|[[代码]](<https://github.com/AI-Tech-Research-Lab/AsquaredM.>)<br />- 问题：NAS，架构空间，几何性质，局部性<br />- 方法：A$^2$M，平缓最小值，梯度偏置<br />- 效果：准确率提升，泛化能力增强|
|🆕 发布|Geometric Parameter Estimations of Perovskite Solar Cells Based on Optical Simulations|基于光学模拟的钙钛矿太阳能电池几何参数估计|Junhao Wang|<http://arxiv.org/pdf/2503.10102v1>|- 问题：层厚估计，非侵入式，钙钛矿太阳能电池<br />- 方法：卷积神经网络，光量子效率，贝叶斯优化<br />- 效果：高精度，低误差|
|📝 更新|Accelerating Flood Warnings by 10 Hours: The Power of River Network Topology in AI-enhanced Flood Forecasting|加速洪水预警10小时：河流网络拓扑在人工智能增强洪水预报中的力量|Hongjun Wang, Jiyuan Chen, Yinqiang Zheng, Xuan Song|<http://arxiv.org/pdf/2410.05536v3>|- 问题：洪水预测，GNN，拓扑结构，预测精度<br />- 方法：图变换，拓扑连接，稀疏化<br />- 效果：预测提前，精度提升|


### 单目重建 (Monocular Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Diver Attention Estimation Framework for Effective Underwater Human-Robot Interaction|一种用于有效水下人机交互的差异化注意力估计框架|Sadman Sakib Enan, Junaed Sattar|<http://arxiv.org/pdf/2209.14447v2>|- 问题：水下人机交互，注意力估计，潜水员分心<br />- 方法：DATT-Net，金字塔结构，面部关键点<br />- 效果：自主导航，交互准备|


## 神经渲染 (Neural Rendering)


### 可控渲染 (Controllable Rendering)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GroomLight: Hybrid Inverse Rendering for Relightable Human Hair Appearance Modeling|GroomLight：可重光照的人发外观建模的混合逆渲染|Yang Zheng, Menglei Chai, Delio Vicini, Yuxiao Zhou, Yinghao Xu, Leonidas Guibas, Gordon Wetzstein, Thabo Beeler|<http://arxiv.org/pdf/2503.10597v1>|- 问题：头发渲染，光照平衡，细节捕捉，泛化能力<br />- 方法：混合逆渲染，BSDF模型，残差模型<br />- 效果：高保真，重光照，视图合成|
|🆕 发布|ConsisLoRA: Enhancing Content and Style Consistency for LoRA-based Style Transfer|ConsisLoRA：增强基于LoRA的风格迁移的内容和风格一致性|Bolin Chen, Baoquan Zhao, Haoran Xie, Yi Cai, Qing Li, Xudong Mao|<http://arxiv.org/pdf/2503.10614v1>|- 问题：内容不一致，风格错位，内容泄露<br />- 方法：ConsisLoRA，两步训练策略，逐步损失转换<br />- 效果：一致性提升，内容泄露减少|
|📝 更新|SpotLight: Shadow-Guided Object Relighting via Diffusion|SpotLight：基于扩散的阴影引导物体重光照|Frédéric Fortier-Chouinard, Zitian Zhang, Louis-Etienne Messier, Mathieu Garon, Anand Bhattad, Jean-François Lalonde|<http://arxiv.org/pdf/2411.18665v2>|- 问题：光照控制，图像重光照，阴影引导<br />- 方法：扩散模型，阴影注入，无额外训练<br />- 效果：高质量重光照，优越合成|
|🆕 发布|MaterialMVP: Illumination-Invariant Material Generation via Multi-view PBR Diffusion|材料MVP：通过多视角PBR扩散实现光照不变材料生成|Zebin He, Mingxin Yang, Shuhui Yang, Yixuan Tang, Tao Wang, Kaihao Zhang, Guanying Chen, Yuhong Liu .etc.|<http://arxiv.org/pdf/2503.10289v1>|- 问题：多视角材料合成，光照不变性，PBR纹理生成<br />- 方法：参考注意力，一致性正则化训练，双通道材料生成<br />- 效果：光照不变，几何一致性，3D资产创建|
|📝 更新|DoF-Gaussian: Controllable Depth-of-Field for 3D Gaussian Splatting|深度可控高斯分层渲染的DoF-Gaussian|Liao Shen, Tianqi Liu, Huiqiang Sun, Jiaqi Li, Zhiguo Cao, Wei Li, Chen Change Loy|<http://arxiv.org/pdf/2503.00746v3>|- 问题：3D-GS，深度不足，浅景深<br />- 方法：DoF-Gaussian，镜头模型，深度先验<br />- 效果：可控制，实时，高质量|


### 神经辐射场 (Neural Radiance Fields)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Flow-NeRF: Joint Learning of Geometry, Poses, and Dense Flow within Unified Neural Representations|Flow-NeRF：在统一神经网络表示中联合学习几何、姿态和密集流|Xunzhi Zheng, Dan Xu|<http://arxiv.org/pdf/2503.10464v1>|[[代码]](<https://zhengxunzhi.github.io/flownerf>)<br />- 问题：几何模糊，无姿态先验，场景重建<br />- 方法：Flow-NeRF，统一神经网络表示，流估计映射<br />- 效果：超越前人，新视角合成，深度估计|
|📝 更新|SplatAD: Real-Time Lidar and Camera Rendering with 3D Gaussian Splatting for Autonomous Driving|SplatAD：基于3D高斯喷溅的实时激光雷达和相机渲染，用于自动驾驶|Georg Hess, Carl Lindström, Maryam Fatemi, Christoffer Petersson, Lennart Svensson|<http://arxiv.org/pdf/2411.16816v3>|- 问题：低渲染速度，无法渲染Lidar数据，缺乏实时性<br />- 方法：3D Gaussian Splatting，优化算法，传感器现象建模<br />- 效果：实时渲染，高PSNR，速度提升|
|🆕 发布|GS-SDF: LiDAR-Augmented Gaussian Splatting and Neural SDF for Geometrically Consistent Rendering and Reconstruction|GS-SDF：基于LiDAR增强的高斯喷溅和神经SDF的几何一致渲染与重建|Jianheng Liu, Yunfei Wan, Bowen Wang, Chunran Zheng, Jiarong Lin, Fu Zhang|<http://arxiv.org/pdf/2503.10170v1>|[[代码]](<https://github.com/hku-mars/GS-SDF.>)<br />- 问题：高精度重建，几何一致性，渲染质量<br />- 方法：LiDAR-Augmented，Gaussian Splatting，Neural SDF<br />- 效果：重建精度高，渲染质量优|
|🆕 发布|3D Student Splatting and Scooping|三维学生喷溅和挖掘|Jialin Zhu, Jiangbei Yue, Feixiang He, He Wang|<http://arxiv.org/pdf/2503.10148v1>|- 问题：3DGS，表达性，学习挑战<br />- 方法：Student's t分布，Splatting & Scooping，优化采样<br />- 效果：质量提升，参数效率高|
|🆕 发布|GaussHDR: High Dynamic Range Gaussian Splatting via Learning Unified 3D and 2D Local Tone Mapping|高动态范围高斯分层渲染：通过学习统一3D和2D局部色调映射|Jinfeng Liu, Lingtong Kong, Bo Li, Dan Xu|<http://arxiv.org/pdf/2503.10143v1>|- 问题：HDR重建，3D/2D映射，稳定性，模型容量，全局映射<br />- 方法：3D高斯分层，残差映射，不确定性学习<br />- 效果：性能提升，合成/真实场景|
|🆕 发布|Fourier Decomposition for Explicit Representation of 3D Point Cloud Attributes|傅里叶分解用于3D点云属性的显式表示|Donghyun Kim, Hyunah Ko, Chanyoung Kim, Seong Jae Hwang|<http://arxiv.org/pdf/2503.10055v1>|- 问题：3D点云，属性表示，处理挑战<br />- 方法：3D傅里叶分解，特征解耦，谱域操作<br />- 效果：分类性能提升，数据增强|


### 场景编辑 (Scene Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RoCo-Sim: Enhancing Roadside Collaborative Perception through Foreground Simulation|RoCo-Sim：通过前景模拟增强路边协作感知|Yuwen Du, Anning Hu, Zichen Chao, Yifan Lu, Junhao Ge, Genjia Liu, Weitao Wu, Lanjun Wang .etc.|<http://arxiv.org/pdf/2503.10410v1>|[[代码]](<https://github.com/duyuwen-duen/RoCo-Sim>)<br />- 问题：路边感知，数据问题，性能差<br />- 方法：RoCo-Sim，多视图，前景模拟<br />- 效果：性能提升，SOTA超越|


## 定位与映射 (Localization & Mapping)


### 位姿估计 (Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Consistent multi-animal pose estimation in cattle using dynamic Kalman filter based tracking|基于动态卡尔曼滤波跟踪的牛群一致多动物位估计|Maarten Perneel, Ines Adriaens, Ben Aernouts, Jan Verwaeren|<http://arxiv.org/pdf/2503.10450v1>|- 问题：动物行为研究，数据收集成本高，算法定制化<br />- 方法：动态卡尔曼滤波，KeySORT，实时跟踪<br />- 效果：高精度，时空一致性，行为监测|
|🆕 发布|6D Object Pose Tracking in Internet Videos for Robotic Manipulation|互联网视频中用于机器人操作的6D物体姿态跟踪|Georgy Ponimatkin, Martin Cífka, Tomáš Souček, Médéric Fourmy, Yann Labbé, Vladimir Petrik, Josef Sivic|<http://arxiv.org/pdf/2503.10307v1>|- 问题：6D姿态跟踪，互联网视频，动态运动，未知模型<br />- 方法：CAD模型检索，6D对齐，轨迹优化<br />- 效果：性能提升，机器人操作，Embodied AI|
|🆕 发布|VicaSplat: A Single Run is All You Need for 3D Gaussian Splatting and Camera Estimation from Unposed Video Frames|VicaSplat：从未摆姿势的视频帧中进行3D高斯喷溅和相机估计，只需单次运行|Zhiqi Li, Chengrui Dong, Yiming Chen, Zhangchi Huang, Peidong Liu|<http://arxiv.org/pdf/2503.10286v1>|[[代码]](<https://lizhiqi49.github.io/VicaSplat.>)<br />- 问题：3D Gaussians重建，相机姿态估计，未摆姿势视频帧<br />- 方法：Transformer网络，视觉token，相机token<br />- 效果：超越基线，跨数据集泛化|
|🆕 发布|TARS: Traffic-Aware Radar Scene Flow Estimation|TARS：基于交通感知的雷达场景流估计|Jialong Wu, Marco Braun, Dominic Spata, Matthias Rottmann|<http://arxiv.org/pdf/2503.10210v1>|- 问题：稀疏雷达点云，场景流估计，刚性运动假设<br />- 方法：交通感知，联合检测与场景流，交通向量场<br />- 效果：性能提升，超越现有方法|
|🆕 发布|Unlocking Generalization Power in LiDAR Point Cloud Registration|解锁激光雷达点云配准的泛化能力|Zhenxuan Zeng, Qiao Wu, Xiyu Zhang, Lin Yuanbo Wu, Pei An, Jiaqi Yang, Ji Wang, Peng Wang|<http://arxiv.org/pdf/2503.10149v1>|[[代码]](<https://github.com/peakpang/UGP.>)<br />- 问题：LiDAR点云注册，泛化能力差<br />- 方法：剪枝框架，消除交叉注意力，渐进式自注意力，BEV特征<br />- 效果：泛化性能提升，注册召回率提高|
|📝 更新|Refinement Module based on Parse Graph of Feature Map for Human Pose Estimation|基于特征图解析图的精炼模块用于人体姿态估计|Shibang Liu, Xuemei Xie, Guangming Shi|<http://arxiv.org/pdf/2501.11069v4>|- 问题：人体姿态估计，解析图，特征图，结构限制<br />- 方法：RMPG模块，上下文信息，递归分解<br />- 效果：模型适应性强，参数少，结果优异|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Procedure-Aware Surgical Video-language Pretraining with Hierarchical Knowledge Augmentation|基于程序感知的手术视频语言预训练与分层知识增强|Kun Yuan, Vinkle Srivastav, Nassir Navab, Nicolas Padoy|<http://arxiv.org/pdf/2410.00263v2>|[[代码]](<https://github.com/CAMMA-public/SurgVLP>)<br />- 问题：知识域差距，数据稀缺，信息损失，时空挑战<br />- 方法：知识增强，PeskaVLP框架，语言监督，视觉自监督<br />- 效果：零样本迁移，泛化能力|


### 语义建图 (Semantic Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OSMa-Bench: Evaluating Open Semantic Mapping Under Varying Lighting Conditions|OSMa-Bench：评估在不同光照条件下开放语义映射|Maxim Popov, Regina Kurkova, Mikhail Iumanov, Jaafar Mahmoud, Sergey Kolyubin|<http://arxiv.org/pdf/2503.10331v1>|[[代码]](<https://be2rlab.github.io/OSMa-Bench>)<br />- 问题：OSM，语义映射，光照条件，性能评估<br />- 方法：OSMa-Bench，RGB-D数据集，语义图评估<br />- 效果：模型鲁棒性，未来研究方向|


## 自监督学习 (Self-supervised Learning)


### 一致性学习 (Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Towards Generalizable Scene Change Detection|面向可泛化的场景变化检测|Jaewoo Kim, Uehwan Kim|<http://arxiv.org/pdf/2409.06214v4>|- 问题：场景变化检测泛化能力差，时序一致性差<br />- 方法：预训练模型，伪掩码生成，几何语义匹配<br />- 效果：性能提升，泛化能力强|
|🆕 发布|VideoMerge: Towards Training-free Long Video Generation|视频融合：迈向无需训练的长视频生成|Siyang Zhang, Harry Yang, Ser-Nam Lim|<http://arxiv.org/pdf/2503.09926v1>|- 问题：长视频生成，训练成本高，适应性差，质量挑战<br />- 方法：VideoMerge，无监督，短视频合并<br />- 效果：高质量，可扩展，动态内容|


## 迁移与适应 (Transfer & Adaptation)


### 域适应 (Domain Adaptation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ETCH: Generalizing Body Fitting to Clothed Humans via Equivariant Tightness|ETCH：通过等变紧度将身体贴合推广到着装人类|Boqian Li, Haiwen Feng, Zeyu Cai, Michael J. Black, Yuliang Xiu|<http://arxiv.org/pdf/2503.10624v1>|[[代码]](<https://boqian-li.github.io/ETCH>)<br />- 问题：体态拟合，多阶段，泛化性差<br />- 方法：等变紧度拟合，局部SE(3)等变，姿态不变特征<br />- 效果：精度提升，泛化性强|
|🆕 发布|Unlock the Power of Unlabeled Data in Language Driving Model|解锁语言驱动模型中未标记数据的潜力|Chaoqun Wang, Jie Yang, Xiaobin Hong, Ruimao Zhang|<http://arxiv.org/pdf/2503.10586v1>|- 问题：标注数据成本高，依赖性强<br />- 方法：模板提示，伪标注，自洽优化<br />- 效果：半监督学习，性能提升|
|🆕 发布|OODD: Test-time Out-of-Distribution Detection with Dynamic Dictionary|OODD：基于动态字典的测试时域外分布检测|Yifeng Yang, Lin Zhu, Zewen Sun, Hengyu Liu, Qinying Gu, Nanyang Ye|<http://arxiv.org/pdf/2503.10468v1>|- 问题：OOD检测，测试时，训练异常<br />- 方法：动态字典，优先队列，信息采样<br />- 效果：FPR95提升26%，速度提升3倍|
|🆕 发布|Low Complexity Point Tracking of the Myocardium in 2D Echocardiography|心肌二维超声心动图中的低复杂度点跟踪|Artem Chernyshov, John Nyberg, Vegard Holmstrøm, Md Abulkalam Azad, Bjørnar Grenne, Håvard Dalen, Svein Arne Aase, Lasse Lovstakken .etc.|<http://arxiv.org/pdf/2503.10431v1>|- 问题：点跟踪，2D超声心动图，深度学习，效率低<br />- 方法：MyoTracker，低复杂度，CoTracker2简化<br />- 效果：误差低，准确，速度快|
|🆕 发布|Object detection characteristics in a learning factory environment using YOLOv8|基于YOLOv8在智能制造环境中的目标检测特性|Toni Schneidereit, Stefan Gohrenz, Michael Breuß|<http://arxiv.org/pdf/2503.10356v1>|- 问题：背景干扰，检测精度，数据集构建<br />- 方法：YOLOv8模型，多材料训练，特征分析<br />- 效果：检测行为分析，数据集贡献|
|📝 更新|SMIRK: 3D Facial Expressions through Analysis-by-Neural-Synthesis|SMIRK：通过神经合成分析的3D面部表情|George Retsinas, Panagiotis P. Filntisis, Radek Danecek, Victoria F. Abrevaya, Anastasios Roussos, Timo Bolkart, Petros Maragos|<http://arxiv.org/pdf/2404.04104v2>|[[代码]](<https://georgeretsi.github.io/smirk>)<br />- 问题：3D面部表情重建，表达多样性，自监督训练<br />- 方法：神经渲染模块，几何监督，数据增强<br />- 效果：表达重建，性能提升|
|📝 更新|2HandedAfforder: Learning Precise Actionable Bimanual Affordances from Human Videos|双手Afforder：从人类视频中学习精确的可操作双臂可及性|Marvin Heidinger, Snehal Jauhri, Vignesh Prasad, Georgia Chalvatzaki|<http://arxiv.org/pdf/2503.09320v2>|- 问题：affordance prediction, object segmentation, bimanual actions<br />- 方法：VLM-based model, 2HANDS dataset, affordance region segmentation<br />- 效果：superior performance, actionable affordance regions|
|🆕 发布|CPLOYO: A Pulmonary Nodule Detection Model with Multi-Scale Feature Fusion and Nonlinear Feature Learning|标题翻译结果：  CPLOYO：一种基于多尺度特征融合和非线性特征学习的肺结节检测模型|Meng Wang, Zi Yang, Ruifeng Zhao, Yaoting Jiang|<http://arxiv.org/pdf/2503.10045v1>|- 问题：肺结节检测，多类型，高灵敏度<br />- 方法：C2f_RepViTCAMF模块，MSCAF模块，KAN网络<br />- 效果：检测精度提升，泛化能力强|
|🆕 发布|Dual-domain Modulation Network for Lightweight Image Super-Resolution|双域调制轻量级图像超分辨率网络|Wenjie Li, Heng Guo, Yuefeng Hou, Guangwei Gao, Zhanyu Ma|<http://arxiv.org/pdf/2503.10047v1>|- 问题：轻量级图像超分辨率，频率特征，结构重建<br />- 方法：双域调制网络，WMT，Fourier监督<br />- 效果：PSNR相当，FLOPs降低，速度提升|
|🆕 发布|Post-disaster building indoor damage and survivor detection using autonomous path planning and deep learning with unmanned aerial vehicles|灾害后建筑室内损坏和幸存者检测：利用自主路径规划和无人机深度学习|Xiao Pan, Sina Tavasoli, T. Y. Yang, Sina Poorghasem|<http://arxiv.org/pdf/2503.10027v1>|- 问题：灾害后建筑室内检测，人工效率低，危险<br />- 方法：自主路径规划，深度学习，低成本MAV<br />- 效果：高精度，效率提升|
|🆕 发布|One-Shot Federated Unsupervised Domain Adaptation with Scaled Entropy Attention and Multi-Source Smoothed Pseudo Labeling|一次性联邦无监督领域自适应：基于缩放熵注意力和多源平滑伪标签|Ali Abedi, Q. M. Jonathan Wu, Ning Zhang, Farhad Pourpanah|<http://arxiv.org/pdf/2503.10020v1>|- 问题：联邦学习，域适应，隐私保护，通信开销<br />- 方法：Scaled Entropy Attention，Multi-Source Pseudo Labeling，SSCE<br />- 效果：性能提升，成本降低|


### 增量学习 (Incremental Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EFC++: Elastic Feature Consolidation with Prototype Re-balancing for Cold Start Exemplar-free Incremental Learning|EFC++：基于原型再平衡的弹性特征融合，用于无示例增量学习的冷启动|Simone Magistri, Tomaso Trinci, Albin Soutif-Cormerais, Joost van de Weijer, Andrew D. Bagdanov|<http://arxiv.org/pdf/2503.10439v1>|- 问题：EFCIL，冷启动，特征漂移，数据不足<br />- 方法：弹性特征巩固，原型重平衡，EFM，伪度量<br />- 效果：模型塑性，性能提升|
|🆕 发布|Generative Binary Memory: Pseudo-Replay Class-Incremental Learning on Binarized Embeddings|生成二进制记忆：基于二值嵌入的伪重放类增量学习|Yanis Basso-Bert, Anca Molnos, Romain Lemaire, William Guicquero, Antoine Dupret|<http://arxiv.org/pdf/2503.10333v1>|- 问题：动态环境，CIL，保留旧类别，学习新类别<br />- 方法：Generative Binary Memory，BMM，特征二值化<br />- 效果：高精度，低内存|
|🆕 发布|Singular Value Fine-tuning for Few-Shot Class-Incremental Learning|单值微调用于少样本类增量学习|Zhiwu Wang, Yichen Wu, Renzhen Wang, Haokun Lin, Quanziang Wang, Qian Zhao, Deyu Meng|<http://arxiv.org/pdf/2503.10214v1>|- 问题：CIL，FSCIL，过拟合，遗忘问题<br />- 方法：SVD，SVFCL，参数高效微调<br />- 效果：减少参数，降低过拟合，提升性能|
|🆕 发布|StableFusion: Continual Video Retrieval via Frame Adaptation|稳定融合：通过帧适应的持续视频检索|Zecheng Zhao, Zhi Chen, Zi Huang, Shazia Sadiq, Tong Chen|<http://arxiv.org/pdf/2503.10111v1>|[[代码]](<https://github.com/JasonCodeMaker/CTVR>)<br />- 问题：视频检索，持续学习，语义对齐<br />- 方法：帧融合适配器，任务感知混合专家<br />- 效果：性能优越，任务保持|


### 元学习 (Meta Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LUMOS: Language-Conditioned Imitation Learning with World Models|LUMOS：基于世界模型的语言条件模仿学习|Iman Nematollahi, Branton DeMoss, Akshay L Chandra, Nick Hawes, Wolfram Burgard, Ingmar Posner|<http://arxiv.org/pdf/2503.10370v1>|- 问题：多任务模仿学习，分布偏移，长时序学习<br />- 方法：世界模型，语言条件，潜在空间学习<br />- 效果：零样本迁移，长时序性能|
|🆕 发布|IDEA: Inverted Text with Cooperative Deformable Aggregation for Multi-modal Object Re-Identification|IDEA：基于协同可变形聚合的倒置文本多模态目标重识别|Yuhao Wang, Yongfeng Lv, Pingping Zhang, Huchuan Lu|<http://arxiv.org/pdf/2503.10324v1>|- 问题：多模态ReID，文本语义信息，特征融合，冗余<br />- 方法：IMFE，CDA，多模态标注，语义引导<br />- 效果：鲁棒性提升，性能增强|
|🆕 发布|SVIP: Semantically Contextualized Visual Patches for Zero-Shot Learning|SVIP：用于零样本学习的语义上下文视觉块|Zhi Chen, Zecheng Zhao, Jingcai Guo, Jingjing Li, Zi Huang|<http://arxiv.org/pdf/2503.10252v1>|- 问题：ZSL，语义错位，视觉语义交互<br />- 方法：SVIP，Transformer，自监督，语义上下文<br />- 效果：SOTA，可解释性，语义丰富|
|📝 更新|AgiBot World Colosseo: A Large-scale Manipulation Platform for Scalable and Intelligent Embodied Systems|AgiBot世界斗兽场：一个用于可扩展和智能具身系统的规模化操作平台|AgiBot-World-Contributors, Qingwen Bu, Jisong Cai, Li Chen, Xiuqi Cui, Yan Ding, Siyuan Feng, Shenyuan Gao .etc.|<http://arxiv.org/pdf/2503.06669v2>|- 问题：机器人操作，数据规模，智能系统<br />- 方法：大规模平台，数据收集，通用策略<br />- 效果：性能提升，成功率提高|
|🆕 发布|Enhancing Multi-Agent Systems via Reinforcement Learning with LLM-based Planner and Graph-based Policy|通过基于LLM的规划和基于图的策略的强化学习增强多智能体系统|Ziqi Jia, Junjie Li, Xiaoyang Qu, Jianzong Wang|<http://arxiv.org/pdf/2503.10049v1>|- 问题：MAS协调，安全，复杂任务，奖励函数设计<br />- 方法：LLM，图协作，元学习<br />- 效果：高效协作，性能优越|
|📝 更新|An Information-Theoretic Regularizer for Lossy Neural Image Compression|信息论正则化器在损失性神经图像压缩中的应用|Yingwen Zhang, Meng Wang, Xihua Sheng, Peilin Chen, Junru Li, Li Zhang, Shiqi Wang|<http://arxiv.org/pdf/2411.16727v3>|- 问题：图像压缩，熵最小化，优化挑战<br />- 方法：信息理论，结构正则化，负条件熵<br />- 效果：模型正则化，比特率提升|
|📝 更新|Towards Synthesized and Editable Motion In-Betweening Through Part-Wise Phase Representation|通过部分相位表示实现合成和可编辑的中间运动|Minyue Dai, Jingbo Wang, Ke Fan, Bin Ji, Haoyu Zhao, Junting Dong, Bo Dai|<http://arxiv.org/pdf/2503.08180v2>|- 问题：运动风格编码，肢体运动控制，风格多样性<br />- 方法：部分级相位表示，周期性自动编码器，运动流形学习<br />- 效果：动画连贯性，风格可控性，速度与泛化|
|🆕 发布|Modeling Thousands of Human Annotators for Generalizable Text-to-Image Person Re-identification|建模成千上万的人类标注者以实现可泛化的文本到图像的人脸重识别|Jiayu Jiang, Changxing Ding, Wentao Tan, Junhong Wang, Jin Tao, Xiangmin Xu|<http://arxiv.org/pdf/2503.09962v1>|- 问题：标注成本高，描述风格单一<br />- 方法：人类标注者建模，风格特征提取，聚类<br />- 效果：泛化能力提升|


## 鲁棒学习 (Robust Learning)


### 对抗攻击 (Adversarial Attack)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1|一个令人沮丧的简单但高度有效的攻击基线：对GPT-4.5/4o/o1强大黑盒模型的攻击成功率超过90%|Zhaoyi Li, Xiaohan Zhao, Dong-Dong Wu, Jiacheng Cui, Zhiqiang Shen|<http://arxiv.org/pdf/2503.10635v1>|[[代码]](<https://github.com/VILA-Lab/M-Attack.>)<br />- 问题：黑盒模型攻击失败，语义信息缺失<br />- 方法：语义清晰编码，局部区域调整，嵌入空间对齐<br />- 效果：90%成功率，超越现有方法|
|📝 更新|Prompt-Driven Contrastive Learning for Transferable Adversarial Attacks|驱动提示的迁移对抗攻击对比学习|Hunmin Yang, Jongoh Jeong, Kuk-Jin Yoon|<http://arxiv.org/pdf/2407.20657v2>|- 问题：对抗攻击，迁移性，视觉语言模型<br />- 方法：Prompt-Driven Contrastive Learning，CLIP模型，生成模型<br />- 效果：可迁移，性能优越|
|📝 更新|AnywhereDoor: Multi-Target Backdoor Attacks on Object Detection|任意门：目标检测的多目标后门攻击|Jialin Lu, Junjie Shan, Ziqi Zhao, Ka-Ho Chow|<http://arxiv.org/pdf/2503.06529v2>|- 问题：目标检测，后门攻击，单目标，控制<br />- 方法：多目标，解耦，触发拼贴，批量策略<br />- 效果：控制度提升，成功率提高|


### 对抗训练 (Adversarial Training)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hierarchical Self-Supervised Adversarial Training for Robust Vision Models in Histopathology|层次自监督对抗训练在病理学中构建鲁棒视觉模型|Hashmat Shadab Malik, Shahina Kunhimon, Muzammal Naseer, Fahad Shahbaz Khan, Salman Khan|<http://arxiv.org/pdf/2503.10629v1>|[[代码]](<https://github.com/HashmatShadab/HSAT.>)<br />- 问题：对抗攻击，医疗图像，鲁棒性，层次结构<br />- 方法：层次自监督，对抗训练，多级对比学习<br />- 效果：鲁棒性提升，性能增益|


### 对抗防御 (Adversarial Defense)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OCCUQ: Exploring Efficient Uncertainty Quantification for 3D Occupancy Prediction|OCCUQ：探索3D占用预测的高效不确定性量化|Severin Heidrich, Till Beemelmanns, Alexey Nekrasov, Bastian Leibe, Lutz Eckstein|<http://arxiv.org/pdf/2503.10605v1>|[[代码]](<https://github.com/ika-rwth-aachen/OCCUQ>)<br />- 问题：3D占用预测，不确定性，鲁棒性<br />- 方法：动态校准，区域特定干扰，OoD检测<br />- 效果：性能优越，可靠性高|
|📝 更新|Towards Class-wise Robustness Analysis|朝向类别鲁棒性分析|Tejaswini Medi, Julia Grabinski, Margret Keuper|<http://arxiv.org/pdf/2411.19853v2>|- 问题：模型鲁棒性，类别差异，对抗攻击，数据损坏<br />- 方法：类别级鲁棒性分析，对抗训练，潜在空间结构<br />- 效果：类别脆弱性识别，误分类敏感性评估|
|📝 更新|ReVLA: Reverting Visual Domain Limitation of Robotic Foundation Models|ReVLA：逆转机器人基础模型视觉领域局限性的方法|Sombit Dey, Jan-Nico Zaech, Nikolay Nikolov, Luc Van Gool, Danda Pani Paudel|<http://arxiv.org/pdf/2409.15250v2>|- 问题：视觉域限制，模型泛化能力弱<br />- 方法：模型融合，逐步反向，视觉基础模型<br />- 效果：泛化能力提升，任务性能改善|
|🆕 发布|Robustness Tokens: Towards Adversarial Robustness of Transformers|标题翻译：鲁棒性标记：迈向Transformer的对抗鲁棒性|Brian Pulfer, Yury Belousov, Slava Voloshynovskiy|<http://arxiv.org/pdf/2503.10191v1>|- 问题：对抗攻击，模型脆弱，预训练模型<br />- 方法：Robustness Tokens，微调私有token<br />- 效果：鲁棒性提升，性能保留|
|🆕 发布|ST-FlowNet: An Efficient Spiking Neural Network for Event-Based Optical Flow Estimation|ST-FlowNet：一种用于事件驱动光流估计的高效脉冲神经网络|Hongze Sun, Jun Wang, Wuque Cai, Duo Chen, Qianqian Liao, Jiayi He, Yan Cui, Dezhong Yao .etc.|<http://arxiv.org/pdf/2503.10195v1>|- 问题：SNN性能受限，训练复杂，动态场景估计<br />- 方法：ST-FlowNet架构，ConvGRU模块，ANN-to-SNN转换<br />- 效果：性能优越，能量高效|
|📝 更新|Can't Slow me Down: Learning Robust and Hardware-Adaptive Object Detectors against Latency Attacks for Edge Devices|无法阻止我：针对边缘设备对抗延迟攻击的鲁棒和硬件自适应目标检测器学习|Tianyi Wang, Zichen Wang, Cong Wang, Yuanchao Shu, Ruilong Deng, Peng Cheng, Jiming Chen|<http://arxiv.org/pdf/2412.02171v2>|- 问题：对象检测，延迟攻击，实时性，鲁棒性<br />- 方法：背景注意力，对抗训练，硬件适应性<br />- 效果：实时性提升，准确度平衡|
|🆕 发布|AdvPaint: Protecting Images from Inpainting Manipulation via Adversarial Attention Disruption|AdvPaint：通过对抗注意力破坏保护图像免受修复操纵|Joonsung Jeon, Woo Jae Kim, Suhyeon Ha, Sooel Son, Sung-eui Yoon|<http://arxiv.org/pdf/2503.10081v1>|- 问题：图像篡改，扩散模型， inpainting<br />- 方法：对抗注意力破坏，两阶段扰动策略<br />- 效果：FID提升，精度降低|
|🆕 发布|MetricGrids: Arbitrary Nonlinear Approximation with Elementary Metric Grids based Implicit Neural Representation|基于隐式神经网络表示的初等度量网格的任意非线性逼近：MetricGrids|Shu Wang, Yanbo Gao, Shuai Li, Chong Lv, Xun Cai, Chuankun Li, Hui Yuan, Jinglin Zhang|<http://arxiv.org/pdf/2503.10000v1>|[[代码]](<https://github.com/wangshu31/MetricGrids>)<br />- 问题：非线性信号近似，线性潜空间，复杂信号表示<br />- 方法：MetricGrids，Taylor展开，高阶外推解码<br />- 效果：拟合精度高，渲染准确，鲁棒性强|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DeepThalamus: A novel deep learning method for automatic segmentation of brain thalamic nuclei from multimodal ultra-high resolution MRI|深度丘脑：一种用于多模态超高分辨率MRI自动分割脑丘脑核的新型深度学习方法|Marina Ruiz-Perez, Sergio Morell-Ortega, Marien Gadea, Roberto Vivo-Hernando, Gregorio Rubio, Fernando Aparici, Mariam de la Iglesia-Vaya, Thomas Tourdias .etc.|<http://arxiv.org/pdf/2401.07751v2>|- 问题：脑室核分割，多模态，超分辨率<br />- 方法：深度学习，半监督学习，数据库构建<br />- 效果：精度高，效率高|
|🆕 发布|ES-Parkour: Advanced Robot Parkour with Bio-inspired Event Camera and Spiking Neural Network|ES-Parkour：基于生物启发事件相机和脉冲神经网络的高级机器人跑酷|Qiang Zhang, Jiahang Cao, Jingkai Sun, Gang Han, Wen Zhao, Yijie Guo, Renjing Xu|<http://arxiv.org/pdf/2503.09985v1>|- 问题：视觉传感器限制，计算需求高，室外部署难<br />- 方法：事件相机，脉冲神经网络，生物启发<br />- 效果：能耗降低88.3%，性能优异|
|🆕 发布|Target-aware Bidirectional Fusion Transformer for Aerial Object Tracking|目标感知双向融合Transformer用于空中目标跟踪|Xinglong Sun, Haijiang Sun, Shan Jiang, Jiacheng Wang, Jiasong Wang|<http://arxiv.org/pdf/2503.09951v1>|- 问题：跟踪质量低，特征融合单一，鲁棒性差<br />- 方法：双向融合网络，线性自交叉注意力，目标感知编码<br />- 效果：精度高，速度30.5 FPS|
|🆕 发布|Uncertainty-aware Long-tailed Weights Model the Utility of Pseudo-labels for Semi-supervised Learning|不确定性感知长尾权重模型：伪标签在半监督学习中的效用|Jiaqi Wu, Junbiao Pang, Qingming Huang|<http://arxiv.org/pdf/2503.09974v1>|- 问题：伪标签质量，置信度阈值，过自信现象<br />- 方法：不确定性感知，长尾权重，UES结构<br />- 效果：PCK提升，准确率提升|


## 模型压缩加速 (Model Compression & Acceleration)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Poly-MgNet: Polynomial Building Blocks in Multigrid-Inspired ResNets|多网格灵感ResNets中的多项式构建块：Poly-MgNet|Antonia van Betteray, Matthias Rottmann, Karsten Kahl|<http://arxiv.org/pdf/2503.10594v1>|- 问题：ResNet结构，多网格方法，权重数量<br />- 方法：多项式块，MgNet扩展，权重减少<br />- 效果：精度提升，权重减少|
|🆕 发布|EEdit : Rethinking the Spatial and Temporal Redundancy for Efficient Image Editing|EEdit：重新思考高效图像编辑中的空间和时间冗余|Zexuan Yan, Yue Ma, Chang Zou, Wenteng Chen, Qifeng Chen, Linfeng Zhang|<http://arxiv.org/pdf/2503.10270v1>|[[代码]](<https://github.com/yuriYanZeXuan/EEdit>)<br />- 问题：图像编辑计算开销大，实时性差<br />- 方法：空间局部缓存，时间步跳过，token索引预处理<br />- 效果：效率提升2.46倍，性能无损失|
|🆕 发布|FourierSR: A Fourier Token-based Plugin for Efficient Image Super-Resolution|傅里叶SR：基于傅里叶令牌的高效图像超分辨率插件|Wenjie Li, Heng Guo, Yuefeng Hou, Zhanyu Ma|<http://arxiv.org/pdf/2503.10043v1>|- 问题：图像超分辨率效率低，计算成本高<br />- 方法：傅里叶Token插件，全局感受野<br />- 效果：PSNR提升，参数和FLOPs增加少|


### 知识蒸馏 (Knowledge Distillation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RewardSDS: Aligning Score Distillation via Reward-Weighted Sampling|奖励加权采样对齐分数蒸馏|Itay Chachy, Guy Yariv, Sagie Benaim|<http://arxiv.org/pdf/2503.09601v2>|[[代码]](<https://itaychachy.github.io/reward-sds>)<br />问题：SDS对用户意图的细粒度对齐，方法：Reward-Weighted Sampling，效果：性能提升，SOTA|
|📝 更新|Uni-Sign: Toward Unified Sign Language Understanding at Scale|统一手语理解：迈向大规模统一|Zecheng Li, Wengang Zhou, Weichao Zhao, Kepeng Wu, Hezhen Hu, Houqiang Li|<http://arxiv.org/pdf/2501.15187v3>|[[代码]](<https://github.com/ZechengLi19/Uni-Sign.>)<br />- 问题：预训练与微调差距，SLU任务统一性，关键点精度<br />- 方法：大规模生成预训练，统一SLT任务，PGF模块，分数感知采样<br />- 效果：SOTA性能，知识迁移|
|🆕 发布|Towards Fast, Memory-based and Data-Efficient Vision-Language Policy|迈向快速、基于内存和数据高效的视觉-语言策略|Haoxuan Li, Sixu Yan, Yuhan Li, Xinggang Wang|<http://arxiv.org/pdf/2503.10322v1>|- 问题：推理成本高，数据域偏移，处理经验有限<br />- 方法：LiteVLP，预训练VLM，数据微调<br />- 效果：速度提升，精度高，记忆能力强|
|🆕 发布|MoFlow: One-Step Flow Matching for Human Trajectory Forecasting via Implicit Maximum Likelihood Estimation based Distillation|MoFlow：基于隐式最大似然估计蒸馏的单步流匹配用于人类轨迹预测|Yuxiang Fu, Qi Yan, Lele Wang, Ke Li, Renjie Liao|<http://arxiv.org/pdf/2503.09950v1>|- 问题：轨迹预测，多模态，未来运动<br />- 方法：MoFlow模型，流匹配，IMLE蒸馏<br />- 效果：性能最优，轨迹多样，采样速度快|
|📝 更新|Sensor-Invariant Tactile Representation|传感器不变触觉表示|Harsh Gupta, Yuchen Mo, Shengmiao Jin, Wenzhen Yuan|<http://arxiv.org/pdf/2502.19638v2>|- 问题：传感器可迁移性差，信号差异大<br />- 方法：Transformer架构，模拟传感器数据集，零样本迁移<br />- 效果：数据模型可迁移，应用广泛|


## 泛化与鲁棒性 (Generalization & Robustness)


### 域泛化 (Domain Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|UniGaze: Towards Universal Gaze Estimation via Large-scale Pre-Training|UniGaze：通过大规模预训练实现通用注视估计|Jiawei Qin, Xucong Zhang, Yusuke Sugano|<http://arxiv.org/pdf/2502.02307v2>|[[代码]](<https://github.com/ut-vision/UniGaze.>)<br />- 问题：泛化能力差，数据依赖高<br />- 方法：大规模预训练，自监督学习，预训练管道<br />- 效果：泛化提升，降低数据依赖|
|🆕 发布|Improving Medical Waste Classification with Hybrid Capsule Networks|利用混合胶囊网络提升医疗废物分类|Bennet van den Broek, Javad Pourmostafa Roshan Sharami|<http://arxiv.org/pdf/2503.10426v1>|- 问题：医疗废物分类，环境健康风险<br />- 方法：胶囊网络，DenseNet，混合模型<br />- 效果：F1分数提升，分类性能改善|
|🆕 发布|SmartWay: Enhanced Waypoint Prediction and Backtracking for Zero-Shot Vision-and-Language Navigation|智能路径：零样本视觉与语言导航中的增强航点预测与回溯|Xiangyu Shi, Zerui Li, Wenqi Lyu, Jiatong Xia, Feras Dayoub, Yanyuan Qiao, Qi Wu|<http://arxiv.org/pdf/2503.10069v1>|- 问题：VLN-CE，空间意识，历史推理，回溯能力<br />- 方法：增强预测器，MLLM导航，视觉编码，注意力融合，回溯规划<br />- 效果：SOTA性能，适应性|


### 分布鲁棒性 (Distribution Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Hidden in the Noise: Two-Stage Robust Watermarking for Images|隐藏于噪声中：图像两阶段鲁棒水印|Kasra Arabi, Benjamin Feuer, R. Teal Witter, Chinmay Hegde, Niv Cohen|<http://arxiv.org/pdf/2412.04653v4>|- 问题：图像水印易伪造，信息泄露<br />- 方法：噪声嵌入，两阶段检测，Fourier模式<br />- 效果：鲁棒性强，抗攻击|


## 可解释性 (Interpretability)


### 概念解释 (Concept Explanation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning Interpretable Logic Rules from Deep Vision Models|从深度视觉模型中学习可解释的逻辑规则|Chuqin Geng, Yuhe Jiang, Ziyu Zhao, Haolin Ye, Zhaoyue Wang, Xujie Si|<http://arxiv.org/pdf/2503.10547v1>|- 问题：可解释性，逻辑规则，视觉概念<br />- 方法：VisionLogic框架，神经元转换，因果验证<br />- 效果：局部解释，全局解释，保留判别力|


## 医学影像分析 (Medical Image Analysis)


### 影像重建 (Image Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LHM: Large Animatable Human Reconstruction Model from a Single Image in Seconds|LHM：秒级从单张图像中重建大型可动人类模型|Lingteng Qiu, Xiaodong Gu, Peihao Li, Qi Zuo, Weichao Shen, Junfei Zhang, Kejie Qiu, Weihao Yuan .etc.|<http://arxiv.org/pdf/2503.10625v1>|- 问题：单图3D人体重建，几何外观解耦，模型泛化能力<br />- 方法：多模态Transformer，注意力机制，头部特征金字塔<br />- 效果：秒级重建，高保真度，泛化能力强|
|🆕 发布|How Should We Evaluate Uncertainty in Accelerated MRI Reconstruction?|如何评估加速MRI重建中的不确定性？|Luca Trautmann, Peter Wijeratne, Itamar Ronen, Ivor Simpson|<http://arxiv.org/pdf/2503.10527v1>|- 问题：加速MRI重建，不确定性评估<br />- 方法：解剖变化评估，图像注册，分割<br />- 效果：相关性高，揭示模型偏差|
|📝 更新|Fast MRI for All: Bridging Equity Gaps via Training without Raw Data Access|快速MRI普及：通过无原始数据访问的训练弥合公平差距|Yaşar Utku Alçalar, Merve Gülle, Mehmet Akçakaya|<http://arxiv.org/pdf/2411.13022v2>|- 问题：MRI数据获取限制，PD-DL泛化能力差<br />- 方法：CUPID，压缩性评估，临床图像训练<br />- 效果：高质量重建，超越CS，零样本训练|
|📝 更新|Continuous K-space Recovery Network with Image Guidance for Fast MRI Reconstruction|基于图像引导的连续K空间恢复网络用于快速MRI重建|Yucong Meng, Zhiwei Yang, Minghong Duan, Yonghong Shi, Zhijian Song|<http://arxiv.org/pdf/2411.11282v2>|- 问题：MRI重建，扫描时间长，k-space特性，学习不足<br />- 方法：连续k-space网络，图像引导，多阶段训练<br />- 效果：性能提升，优于其他方法|
|📝 更新|The R2D2 Deep Neural Network Series for Scalable Non-Cartesian Magnetic Resonance Imaging|R2D2深度神经网络系列：可扩展的非笛卡尔磁共振成像|Yiwei Chen, Amir Aghabiglou, Shijie Chen, Motahare Torki, Chao Tang, Ruud B. van Heeswijk, Yves Wiaux|<http://arxiv.org/pdf/2503.09559v2>|- 问题：非笛卡尔MRI重建，可扩展性，迭代慢<br />- 方法：R2D2深度神经网络，残差图像，匹配追踪<br />- 效果：重建质量高，训练可扩展|
|🆕 发布|Speedy MASt3R|快速MASt3R|Jingxing Li, Yongjae Lee, Abhay Kumar Yadav, Cheng Peng, Rama Chellappa, Deliang Fan|<http://arxiv.org/pdf/2503.10017v1>|- 问题：图像匹配速度慢，精度瓶颈<br />- 方法：FlashMatch，GraphFusion，FastNN-Lite，HybridCast<br />- 效果：速度提升54%，实时3D理解|


### 疾病诊断 (Disease Diagnosis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning Disease State from Noisy Ordinal Disease Progression Labels|从噪声有序疾病进展标签中学习疾病状态|Gustav Schmidt, Holger Heidrich, Philipp Berens, Sarah Müller|<http://arxiv.org/pdf/2503.10440v1>|- 问题：噪声序数标签，疾病状态学习<br />- 方法：独立图像编码，对称性，不确定性估计<br />- 效果：可解释性，少样本学习|
|📝 更新|Histologic Dataset of Normal and Atypical Mitotic Figures on Human Breast Cancer (AMi-Br)|人类乳腺癌正常和异常有丝分裂图像的病理数据集（AMi-Br）|Christof A. Bertram, Viktoria Weiss, Taryn A. Donovan, Sweta Banerjee, Thomas Conrad, Jonas Ammeling, Robert Klopfleisch, Christopher Kaltenecker .etc.|<http://arxiv.org/pdf/2501.04467v2>|- 问题：乳腺癌，细胞周期，突变，基因，预后<br />- 方法：公开数据集，专家投票，分类实验<br />- 效果：高平衡准确率，蒙特卡洛验证|
|🆕 发布|Detecting Dataset Bias in Medical AI: A Generalized and Modality-Agnostic Auditing Framework|医学人工智能中数据集偏差的检测：一个通用且模态无关的审计框架|Nathan Drenkow, Mitchell Pavlak, Keith Harrigian, Ayah Zirikly, Adarsh Subbaswamy, Mathias Unberath|<http://arxiv.org/pdf/2503.09969v1>|- 问题：数据集偏差，机器学习，AI系统风险<br />- 方法：G-AUDIT框架，属性检测，数据模态无关<br />- 效果：识别偏差，提升AI可靠性|


### 医学分割 (Medical Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Category Prompt Mamba Network for Nuclei Segmentation and Classification|核分割与分类的Mamba网络分类提示|Ye Zhang, Zijie Fang, Yifeng Wang, Lingbo Zhang, Xianchao Guan, Yongbing Zhang|<http://arxiv.org/pdf/2503.10422v1>|- 问题：核分割，分类，图像分割，训练时间，内存消耗<br />- 方法：Mamba网络，类别概率排序，特征扫描<br />- 效果：性能提升，核分割，分类|
|📝 更新|Semi-supervised Semantic Segmentation for Remote Sensing Images via Multi-scale Uncertainty Consistency and Cross-Teacher-Student Attention|基于多尺度不确定性一致性和跨教师-学生注意力的遥感图像半监督语义分割|Shanwen Wang, Xin Sun, Changrui Chen, Danfeng Hong, Jungong Han|<http://arxiv.org/pdf/2501.10736v2>|- 问题：半监督学习，遥感图像，多尺度，相似度高<br />- 方法：不确定性一致性，跨教师-学生注意力，多尺度学习<br />- 效果：性能优越，区分力强|
|🆕 发布|Eye on the Target: Eye Tracking Meets Rodent Tracking|目标在眼前：眼动追踪遇见啮齿动物追踪|Emil Mededovic, Yuli Wu, Henning Konermann, Marcin Kopaczka, Mareike Schulz, Rene Tolba, Johannes Stegmaier|<http://arxiv.org/pdf/2503.10305v1>|- 问题：动物行为分析，手动标注，主观性强<br />- 方法：眼动追踪，零样本分割，智能提示优化<br />- 效果：分割精度提升，Jaccard指数提高|
|🆕 发布|Markerless Tracking-Based Registration for Medical Image Motion Correction|基于无标记跟踪的医学图像运动校正配准|Luisa Neubig, Deirdre Larsen, Takeshi Ikuma, Markus Kopp, Melda Kunduk, Andreas M. Kist|<http://arxiv.org/pdf/2503.10260v1>|- 问题：吞咽运动，患者运动，图像运动校正<br />- 方法：无标记跟踪，位移场，运动校正管道<br />- 效果：准确性高，吞咽动态保留|
|📝 更新|GeoPix: Multi-Modal Large Language Model for Pixel-level Image Understanding in Remote Sensing|GeoPix：遥感中像素级图像理解的跨模态大型语言模型|Ruizhe Ou, Yuan Hu, Fan Zhang, Jiaxin Chen, Yu Liu|<http://arxiv.org/pdf/2501.06828v2>|- 问题：像素级图像理解，缺乏对话能力<br />- 方法：掩码预测器，可学习记忆模块，两阶段训练<br />- 效果：像素级分割，性能优越|
|📝 更新|CADSpotting: Robust Panoptic Symbol Spotting on Large-Scale CAD Drawings|CADSpotting：大规模CAD图纸上的鲁棒全景符号检测|Jiazuo Mu, Fuyi Yang, Yanshun Zhang, Mingqian Zhang, Junxiong Zhang, Yongjian Luo, Lan Xu, Yujiao Shi .etc.|<http://arxiv.org/pdf/2412.07377v3>|- 问题：符号多样性，尺度变化，重叠元素<br />- 方法：密集点云模型，SWA技术，LS-CAD数据集<br />- 效果：显著超越，自动化重建|
|🆕 发布|Deep Learning-Based Direct Leaf Area Estimation using Two RGBD Datasets for Model Development|基于深度学习的直接叶面积估计：使用两个RGBD数据集进行模型开发|Namal Jayasuriya, Yi Guo, Wen Hu, Oula Ghannoum|<http://arxiv.org/pdf/2503.10129v1>|- 问题：叶面积直接估计，深度学习，RGBD图像<br />- 方法：Mask R-CNN，双数据集，双网络设计<br />- 效果：高F1分数，高R-squared|
|🆕 发布|MoEdit: On Learning Quantity Perception for Multi-object Image Editing|MoEdit：关于多对象图像编辑数量感知的学习|Yanfeng Li, Kahou Chan, Yue Sun, Chantong Lam, Tong Tong, Zitong Yu, Keren Fu, Xiaohong Liu .etc.|<http://arxiv.org/pdf/2503.10112v1>|[[代码]](<https://github.com/Tear-kitty/MoEdit.>)<br />- 问题：多对象图像编辑，感知一致性，数量感知<br />- 方法：FeCom模块，QTTN模块，Stable Diffusion<br />- 效果：SOTA性能，高质量编辑|
|🆕 发布|Image Quality Assessment: From Human to Machine Preference|图像质量评估：从人类到机器偏好|Chunyi Li, Yuan Tian, Xiaoyue Ling, Zicheng Zhang, Haodong Duan, Haoning Wu, Ziheng Jia, Xiaohong Liu .etc.|<http://arxiv.org/pdf/2503.10078v1>|[[代码]](<https://github.com/lcysyzxdxc/MPD.>)<br />- 问题：IQA，人机视觉差异，机器偏好<br />- 方法：机器偏好定义，MPD数据库，算法验证<br />- 效果：机器偏好识别，IQA进化|


## 智能驾驶 (Intelligent Driving)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SciVerse: Unveiling the Knowledge Comprehension and Visual Reasoning of LMMs on Multi-modal Scientific Problems|SciVerse：揭示LMMs在多模态科学问题上的知识理解和视觉推理|Ziyu Guo, Ray Zhang, Hao Chen, Jialin Gao, Dongzhi Jiang, Jiaze Wang, Pheng-Ann Heng|<http://arxiv.org/pdf/2503.10627v1>|- 问题：LMMs，科学问题解决，知识理解，视觉推理<br />- 方法：SciVerse，多版本评估，CoT推理策略<br />- 效果：评估限制，未来发展方向|
|📝 更新|Are you Struggling? Dataset and Baselines for Struggle Determination in Assembly Videos|您是否在挣扎？——用于装配视频挣扎识别的数据集和基线|Shijia Feng, Michael Wray, Brian Sullivan, Youngkyoon Jang, Casimir Ludwig, Iain Gilchrist, Walterio Mayol-Cuevas|<http://arxiv.org/pdf/2402.11057v4>|- 问题：视频，挣扎，识别，数据集，基准<br />- 方法：数据集构建，标注，深度学习<br />- 效果：基准，评估|
|📝 更新|Facial Attractiveness Prediction in Live Streaming: A New Benchmark and Multi-modal Method|实时直播中面部吸引力预测：一个新的基准和多模态方法|Hui Li, Xiaoyu Ren, Hongjiu Yu, Huiyu Duan, Kai Li, Ying Chen, Libo Wang, Xiongkuo Min .etc.|<http://arxiv.org/pdf/2501.02509v2>|- 问题：FAP数据集，模型泛化能力，直播场景<br />- 方法：LiveBeauty数据集，多模态特征提取，跨模态融合<br />- 效果：性能提升，开放数据集|
|🆕 发布|Exploring Mutual Empowerment Between Wireless Networks and RL-based LLMs: A Survey|无线网络与基于强化学习的大型语言模型之间相互赋能的探索：综述|Yu Qiao, Phuong-Nam Tran, Ji Su Yoon, Loc X. Nguyen, Choong Seon Hong|<http://arxiv.org/pdf/2503.09956v1>|- 问题：无线网络，RL-LLMs，互促，挑战，解决方案<br />- 方法：资源分配，网络优化，分布式推理<br />- 效果：创新，智能通信|


### 环境感知 (Environment Perception)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CODEI: Resource-Efficient Task-Driven Co-Design of Perception and Decision Making for Mobile Robots Applied to Autonomous Vehicles|CODEI：针对移动机器人的感知与决策任务驱动的资源高效协同设计，应用于自动驾驶车辆|Dejan Milojevic, Gioele Zardini, Miriam Elser, Andrea Censi, Emilio Frazzoli|<http://arxiv.org/pdf/2503.10296v1>|- 问题：资源高效，任务驱动，感知决策，移动机器人，自动驾驶<br />- 方法：任务驱动设计，感知需求量化，整数线性规划，协同设计<br />- 效果：资源优化，性能提升|
|🆕 发布|KVQ: Boosting Video Quality Assessment via Saliency-guided Local Perception|KVQ：通过显著性引导的局部感知提升视频质量评估|Yunpeng Qu, Kun Yuan, Qizhi Xie, Ming Sun, Chao Zhou, Jian Wang|<http://arxiv.org/pdf/2503.10259v1>|[[代码]](<https://github.com/qyp2000/KVQ.>)<br />- 问题：视频质量评估，局部感知，标注成本高<br />- 方法：Fusion-Window Attention，局部感知约束，LPVQ数据集<br />- 效果：性能提升，局部感知能力|
|🆕 发布|Interpretable Image Classification via Non-parametric Part Prototype Learning|通过非参数部分原型学习进行可解释图像分类|Zhijie Zhu, Lei Fan, Maurice Pagnucco, Yang Song|<http://arxiv.org/pdf/2503.10247v1>|[[代码]](<https://github.com/zijizhu/proto-non-param.>)<br />- 问题：可解释性图像分类，原型网络，冗余概念<br />- 方法：非参数原型学习，语义特征聚类，独特性评分<br />- 效果：解释性提升，性能优于现有方法|
|📝 更新|JiSAM: Alleviate Labeling Burden and Corner Case Problems in Autonomous Driving via Minimal Real-World Data|JiSAM：通过最小化真实世界数据减轻自动驾驶中的标注负担和边缘案例问题|Runjian Chen, Wenqi Shao, Bo Zhang, Shaoshuai Shi, Li Jiang, Ping Luo|<http://arxiv.org/pdf/2503.08422v2>|- 问题：标注负担，角案例问题，数据规模限制<br />- 方法：JiSAM，抖动增强，域感知骨干，记忆式分区对齐<br />- 效果：SOTA性能，15 mAPs提升|
|🆕 发布|VMBench: A Benchmark for Perception-Aligned Video Motion Generation|VMBench：感知对齐视频运动生成基准|Xinrang Ling, Chen Zhu, Meiqi Wu, Hangyu Li, Xiaokun Feng, Cundian Yang, Aiming Hao, Jiashu Zhu .etc.|<http://arxiv.org/pdf/2503.10076v1>|[[代码]](<https://github.com/GD-AIGC/VMBench>)<br />- 问题：运动评估，感知对齐，运动提示<br />- 方法：感知指标，元信息提取，多级提示库<br />- 效果：指标提升，感知对齐|
|🆕 发布|V2X-ReaLO: An Open Online Framework and Dataset for Cooperative Perception in Reality|V2X-ReaLO：一个用于现实场景协同感知的开源在线框架和数据集|Hao Xiang, Zhaoliang Zheng, Xin Xia, Seth Z. Zhao, Letian Gao, Zewei Zhou, Tianhui Cai, Yun Zhang .etc.|<http://arxiv.org/pdf/2503.10034v1>|- 问题：V2X合作感知，现实场景，中间融合<br />- 方法：开放框架，实时中间融合，动态数据集<br />- 效果：性能评估，基准提升|
|🆕 发布|TGP: Two-modal occupancy prediction with 3D Gaussian and sparse points for 3D Environment Awareness|TGP：基于3D高斯和稀疏点的双模态占用预测用于3D环境感知|Mu Chen, Wenyu Chen, Mingchuan Yang, Yuan Zhang, Tao Han, Xinchi Li, Yunlong Li, Huaici Zhao|<http://arxiv.org/pdf/2503.09941v1>|- 问题：3D语义占用预测，空间信息丢失，结构细节表示<br />- 方法：双模态预测，3D高斯集，稀疏点，Transformer架构<br />- 效果：高精度，IoU提升|


### 轨迹预测 (Trajectory Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GoalFlow: Goal-Driven Flow Matching for Multimodal Trajectories Generation in End-to-End Autonomous Driving|目标流：面向端到端自动驾驶的多模态轨迹生成中的目标驱动流匹配|Zebin Xing, Xingyu Zhang, Yang Hu, Bo Jiang, Tong He, Qian Zhang, Xiaoxiao Long, Wei Yin|<http://arxiv.org/pdf/2503.05689v3>|[[代码]](<https://github.com/YvanYin/GoalFlow.>)<br />- 问题：多模态轨迹生成，轨迹选择复杂，质量下降<br />- 方法：GoalFlow，目标点约束，Flow Matching<br />- 效果：PDMS 90.3，性能优异|
|📝 更新|DA-STGCN: 4D Trajectory Prediction Based on Spatiotemporal Feature Extraction|基于时空特征提取的4D轨迹预测：DA-STGCN|Yuheng Kuang, Zhengning Wang, Jianping Zhang, Zhenyu Shi, Yuding Zhang|<http://arxiv.org/pdf/2503.04823v2>|- 问题：4D轨迹预测，交互，动态优化<br />- 方法：DA-STGCN，自注意力，图注意力<br />- 效果：ADE/FDE降低，节点相关性增强|


## 工业视觉 (Industrial Vision)


### 质量控制 (Quality Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CountPath: Automating Fragment Counting in Digital Pathology|CountPath：自动化数字病理学中的片段计数|Ana Beatriz Vieira, Maria Valente, Diana Montezuma, Tomé Albuquerque, Liliana Ribeiro, Domingos Oliveira, João Monteiro, Sofia Gonçalves .etc.|<http://arxiv.org/pdf/2503.10520v1>|- 问题：病理图像质量控制，人工计数效率低，主观性强<br />- 方法：YOLOv9，Vision Transformer，自动化计数<br />- 效果：性能接近专家，准确率86%|
|🆕 发布|Automatic quality control in multi-centric fetal brain MRI super-resolution reconstruction|多中心胎儿脑MRI超分辨率重建中的自动质量控制|Thomas Sanchez, Vladyslav Zalevsky, Angeline Mihailo, Gerard Martí Juan, Elisenda Eixarch, Andras Jakab, Vincent Dunet, Mériam Koob .etc.|<http://arxiv.org/pdf/2503.10156v1>|- 问题：胎儿脑MRI，质量控制，超分辨率重建<br />- 方法：机器学习，图像质量指标，随机森林<br />- 效果：高准确率，可扩展性|
|📝 更新|Oasis: One Image is All You Need for Multimodal Instruction Data Synthesis|绿洲：一张图片就足以用于多模态指令数据合成|Letian Zhang, Quan Cui, Bingchen Zhao, Cheng Yang|<http://arxiv.org/pdf/2503.08741v2>|- 问题：隐私数据，多模态数据，数据收集，数据合成<br />- 方法：图像提示，质量控制，数据多样性<br />- 效果：性能提升，特定领域能力|


### 缺陷检测 (Defect Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AI-assisted Early Detection of Pancreatic Ductal Adenocarcinoma on Contrast-enhanced CT|人工智能辅助的对比增强CT上胰腺导管腺癌的早期检测|Han Liu, Riqiang Gao, Sasa Grbic|<http://arxiv.org/pdf/2503.10068v1>|[[代码]](<https://github.com/han-liu/PDAC_detection.>)<br />- 问题：胰腺癌早期检测，CT图像，PDAC<br />- 方法：粗到细方法，数据分割，后处理函数<br />- 效果：排名第一，AUROC 0.9263，AP 0.7243|


## 其他 (Others)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Charting and Navigating Hugging Face's Model Atlas|绘制并导航Hugging Face的模型图谱|Eliahu Horwitz, Nitzan Kurer, Jonathan Kahana, Liel Amar, Yedid Hoshen|<http://arxiv.org/pdf/2503.10633v1>|- 问题：模型库搜索，模型文档，模型地图<br />- 方法：模型地图构建，结构先验，未文档区域<br />- 效果：可视化，模型属性预测，趋势分析|
|📝 更新|Complexity Experts are Task-Discriminative Learners for Any Image Restoration|复杂度专家是任何图像恢复任务中的任务判别性学习者|Eduard Zamfir, Zongwei Wu, Nancy Mehta, Yuedong Tan, Danda Pani Paudel, Yulun Zhang, Radu Timofte|<http://arxiv.org/pdf/2411.18466v2>|[[代码]](<https://eduardzamfir.github.io/moceir>)<br />- 问题：MoE架构，任务泛化，专家无效<br />- 方法：复杂性专家，动态任务分配<br />- 效果：性能提升，效率高|
|🆕 发布|Dream-IF: Dynamic Relative EnhAnceMent for Image Fusion|梦-IF：动态相对增强图像融合|Xingxin Xu, Bing Cao, Yinan Xia, Pengfei Zhu, Qinghua Hu|<http://arxiv.org/pdf/2503.10109v1>|- 问题：图像融合，信息整合，传感器退化，融合质量<br />- 方法：动态相对增强，跨模态增强，prompt-based编码<br />- 效果：性能提升，效果优于对比方法|
|🆕 发布|Do We Always Need the Simplicity Bias? Looking for Optimal Inductive Biases in the Wild|我们是否总是需要简单性偏差？在野外寻找最优归纳偏差|Damien Teney, Liangze Jiang, Florin Gogianu, Ehsan Abbasnejad|<http://arxiv.org/pdf/2503.10065v1>|- 问题：Simplicity bias, ReLU, inductive biases<br />- 方法：meta-learning, new activation functions, complexity priors<br />- 效果：suboptimal ReLUs, tailored architectures|
|📝 更新|Forget Vectors at Play: Universal Input Perturbations Driving Machine Unlearning in Image Classification|忘记向量在玩耍：通用输入扰动驱动图像分类中的机器反学习|Changchang Sun, Ren Wang, Yihua Zhang, Jinghan Jia, Jiancheng Liu, Gaowen Liu, Sijia Liu, Yan Yan|<http://arxiv.org/pdf/2412.16780v3>|[[代码]](<https://github.com/Changchangsun/Forget-Vector.>)<br />- 问题：机器取消学习，数据影响消除<br />- 方法：输入扰动，忘却向量，向量运算<br />- 效果：模型无关，性能竞争|

