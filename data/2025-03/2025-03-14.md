## [UPDATED!] **2025-03-14** (Update Time)


## 表示学习 (Representation Learning)


### 视觉Transformer (Vision Transformers)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Similarity-Aware Token Pruning: Your VLM but Faster|相似度感知的Token剪枝：你的VLM但更快|Ahmadreza Jeddi, Negin Baghbanzadeh, Elham Dolatabadi, Babak Taati|<http://arxiv.org/pdf/2503.11549v1>|- 问题：ViT/VLM计算需求高，自注意力复杂度高<br />- 方法：SAINT，动态优化，图模型<br />- 效果：效率提升，性能损失小|
|🆕 发布|APLA: A Simple Adaptation Method for Vision Transformers|APLA：视觉Transformer的简单自适应方法|Moein Sorkhei, Emir Konuk, Kevin Smith, Christos Matsoukas|<http://arxiv.org/pdf/2503.11335v1>|[[代码]](<https://github.com/MoeinSorkhei/APLA.>)<br />- 问题：适应技术，计算成本，架构修改<br />- 方法：APLA，投影层更新，参数无增加<br />- 效果：性能最优，效率提升|
|📝 更新|PEMF-VTO: Point-Enhanced Video Virtual Try-on via Mask-free Paradigm|PEMF-VTO：基于无遮挡范式的点增强视频虚拟试穿|Tianyu Chang, Xiaohao Chen, Zhichao Wei, Xuanpu Zhang, Qing-Guo Chen, Weihua Luo, Peipei Song, Xun Yang|<http://arxiv.org/pdf/2412.03021v4>|[[代码]](<https://pemf-vto.github.io/.>)<br />- 问题：视频虚拟试穿，mask-free，时空信息，动态运动<br />- 方法：Point-Enhanced Transformer，PSA，PTA<br />- 效果：自然，连贯，视觉吸引力|


### 基础模型 (Foundation Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VideoTree: Adaptive Tree-based Video Representation for LLM Reasoning on Long Videos|视频树：用于长视频LLM推理的自适应树状视频表示|Ziyang Wang, Shoubin Yu, Elias Stengel-Eskin, Jaehong Yoon, Feng Cheng, Gedas Bertasius, Mohit Bansal|<http://arxiv.org/pdf/2405.19209v3>|- 问题：视频冗余，信息无关，长视频理解<br />- 方法：查询自适应，层次化表示，多粒度信息<br />- 效果：推理准确率提升，效率提高|


## 生成建模 (Generative Modeling)


### 自回归模型 (Autoregressive Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TreeMeshGPT: Artistic Mesh Generation with Autoregressive Tree Sequencing|树网格GPT：基于自回归树序列的艺术网格生成|Stefan Lionar, Jiabin Liang, Gim Hee Lee|<http://arxiv.org/pdf/2503.11629v1>|- 问题：艺术网格生成，点云对齐，训练难度，网格质量<br />- 方法：自回归树序列，三角形邻接，高效编码<br />- 效果：高保真，细节丰富，正常方向一致性|
|🆕 发布|Safe-VAR: Safe Visual Autoregressive Model for Text-to-Image Generative Watermarking|安全-VAR：用于文本到图像生成水印的安全视觉自回归模型|Ziyi Wang, Songbai Tan, Gang Xu, Xuerui Qiu, Hongbin Xu, Xin Meng, Ming Li, Fei Richard Yu|<http://arxiv.org/pdf/2503.11324v1>|- 问题：VAR模型水印，适应性问题<br />- 方法：自适应嵌入，跨尺度融合<br />- 效果：性能提升，鲁棒性强|
|🆕 发布|Direction-Aware Diagonal Autoregressive Image Generation|方向感知对角自回归图像生成|Yijia Xu, Jianzhong Ju, Jian Luan, Jinshi Cui|<http://arxiv.org/pdf/2503.11129v1>|- 问题：图像序列，欧几里得距离，自回归生成<br />- 方法：对角扫描，因果注意力，方向感知模块<br />- 效果：FID分数，最优|
|🆕 发布|Perceive, Understand and Restore: Real-World Image Super-Resolution with Autoregressive Multimodal Generative Models|感知、理解与恢复：基于自回归多模态生成模型的现实世界图像超分辨率|Hongyang Wei, Shuaizheng Liu, Chun Yuan, Lei Zhang|<http://arxiv.org/pdf/2503.11073v1>|[[代码]](<https://github.com/nonwhy/PURE.>)<br />- 问题：图像超分辨率，感知理解，重建不准确<br />- 方法：自回归模型，指令微调，语义描述<br />- 效果：内容保留，细节真实，场景复杂|


### 扩散模型 (Diffusion Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Pathology Image Compression with Pre-trained Autoencoders|病理图像压缩与预训练自动编码器|Srikar Yellapragada, Alexandros Graikos, Kostas Triaridis, Zilinghan Li, Tarak Nath Nandi, Ravi K Madduri, Prateek Prasanna, Joel Saltz .etc.|<http://arxiv.org/pdf/2503.11591v1>|- 问题：病理图像压缩，存储传输效率，细节保留<br />- 方法：预训练自动编码器，病理模型基准测试，K-means聚类<br />- 效果：性能提升，存储效率，质量保持|
|🆕 发布|TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation|TASTE-Rob：推动面向通用机器人操作的面向任务的手-物体交互视频生成|Hongxiang Zhao, Xingchen Liu, Mutian Xu, Yiming Hao, Weikai Chen, Xiaoguang Han|<http://arxiv.org/pdf/2503.11423v1>|- 问题：数据集，模型，交互，视频生成，机器人操作<br />- 方法：TASTE-Rob，VDM，姿态细化<br />- 效果：高质量，可泛化|
|📝 更新|RectifiedHR: Enable Efficient High-Resolution Image Generation via Energy Rectification|RectifiedHR：通过能量整流实现高效的高分辨率图像生成|Zhen Yang, Guibao Shen, Liang Hou, Mushui Liu, Luozhou Wang, Xin Tao, Pengfei Wan, Di Zhang .etc.|<http://arxiv.org/pdf/2503.02537v2>|- 问题：高分辨率图像生成效率低，性能下降<br />- 方法：噪声刷新策略，能量衰减分析，改进指导超参数<br />- 效果：高效，性能提升|
|🆕 发布|MTV-Inpaint: Multi-Task Long Video Inpainting|多任务长视频修复|Shiyuan Yang, Zheng Gu, Liang Hou, Xin Tao, Pengfei Wan, Xiaodong Chen, Jing Liao|<http://arxiv.org/pdf/2503.11412v1>|[[代码]](<https://mtv-inpaint.github.io/.>)<br />- 问题：视频修复，场景完成，物体插入，控制性，长视频<br />- 方法：多任务框架，双分支注意力，多模态控制，两阶段流程<br />- 效果：性能领先，应用广泛|
|🆕 发布|Towards A Correct Usage of Cryptography in Semantic Watermarks for Diffusion Models|迈向扩散模型语义水印中密码学正确使用的道路|Jonas Thietke, Andreas Müller, Denis Lukovnikov, Asja Fischer, Erwin Quiring|<http://arxiv.org/pdf/2503.11404v1>|- 问题：语义水印，加密技术，Gaussian Shading，性能证明，密钥管理<br />- 方法：IND-CPA安全，性能证明，配置讨论<br />- 效果：新型证明，安全性，效率|
|🆕 发布|BEVDiffLoc: End-to-End LiDAR Global Localization in BEV View based on Diffusion Model|BEVDiffLoc：基于扩散模型的BEV视图中端到端激光雷达全局定位|Ziyue Wang, Chenghao Shi, Neng Wang, Qinghua Yu, Xieyuanli Chen, Huimin Lu|<http://arxiv.org/pdf/2503.11372v1>|[[代码]](<https://github.com/nubot-nudt/BEVDiffLoc.>)<br />- 问题：LiDAR定位，BEV，端到端，鲁棒性，精度<br />- 方法：数据增强，特征学习，扩散模型<br />- 效果：性能提升，优于基线|
|📝 更新|Data Pruning in Generative Diffusion Models|数据剪枝在生成扩散模型中的应用|Rania Briq, Jiangtao Wang, Stefan Kesselheim|<http://arxiv.org/pdf/2411.12523v3>|- 问题：数据剪枝，生成模型，数据冗余<br />- 方法：聚类方法，数据平衡，无监督学习<br />- 效果：性能提升，公平采样|
|📝 更新|Distilling Diversity and Control in Diffusion Models|扩散模型中的多样性蒸馏与控制|Rohit Gandikota, David Bau|<http://arxiv.org/pdf/2503.10637v2>|- 问题：多样性降低，控制蒸馏，代表性结构<br />- 方法：控制蒸馏，扩散目标可视化，多样性蒸馏<br />- 效果：多样性恢复，效率提升|
|📝 更新|Continuous, Subject-Specific Attribute Control in T2I Models by Identifying Semantic Directions|基于识别语义方向的T2I模型中的连续、特定主题属性控制|Stefan Andreas Baumann, Felix Krause, Michael Neumayr, Nick Stracke, Melvin Sevi, Vincent Tao Hu, Björn Ommer|<http://arxiv.org/pdf/2403.17064v2>|[[代码]](<https://github.com/CompVis/attribute-control.>)<br />- 问题：T2I模型属性控制，连续性，特定主题<br />- 方法：语义方向识别，优化技术，学习模型<br />- 效果：细粒度控制，灵活性，精度|
|📝 更新|CreatiLayout: Siamese Multimodal Diffusion Transformer for Creative Layout-to-Image Generation|标题翻译：创意布局到图像生成：一种用于创意布局的多模态Siamese扩散变换器|Hui Zhang, Dexiang Hong, Yitong Wang, Jie Shao, Xinglong Wu, Zuxuan Wu, Yu-Gang Jiang|<http://arxiv.org/pdf/2412.03859v2>|- 问题：L2I生成，MM-DiT，布局引导，模态竞争<br />- 方法：SiamLayout，Siamese分支，LayoutSAM，Layout Designer<br />- 效果：高效生成，大规模数据集，布局优化|
|🆕 发布|Noise Synthesis for Low-Light Image Denoising with Diffusion Models|低光照图像去噪中的噪声合成与扩散模型|Liying Lu, Raphaël Achddou, Sabine Süsstrunk|<http://arxiv.org/pdf/2503.11262v1>|- 问题：低光图像降噪，噪声合成，数据集获取难<br />- 方法：扩散模型，噪声分布捕捉，模型适配<br />- 效果：性能提升，数据集生成|
|📝 更新|Decouple-Then-Merge: Finetune Diffusion Models as Multi-Task Learning|解耦后合并：作为多任务学习的微调扩散模型|Qianli Ma, Xuefei Ning, Dongrui Liu, Li Niu, Linfeng Zhang|<http://arxiv.org/pdf/2410.06664v2>|[[代码]](<https://github.com/MqLeet/DeMe>)<br />- 问题：梯度冲突，训练效率低<br />- 方法：DeMe框架，多任务学习，参数空间合并<br />- 效果：生成质量提升，效率高|
|🆕 发布|Towards Better Alignment: Training Diffusion Models with Reinforcement Learning Against Sparse Rewards|朝着更好的对齐：利用稀疏奖励的强化学习训练扩散模型|Zijing Hu, Fengda Zhang, Long Chen, Kun Kuang, Jiahui Li, Kaifeng Gao, Jun Xiao, Xin Wang .etc.|<http://arxiv.org/pdf/2503.11240v1>|- 问题：稀疏奖励，模型对齐，生成图像质量<br />- 方法：反向渐进训练，分支采样<br />- 效果：对齐提升，多样性保持|
|🆕 发布|Multi-Stage Generative Upscaler: Reconstructing Football Broadcast Images via Diffusion Models|多阶段生成式上采样器：通过扩散模型重建足球直播图像|Luca Martini, Daniele Zolezzi, Saverio Iacono, Gianni Viardo Vercelli|<http://arxiv.org/pdf/2503.11181v1>|- 问题：低分辨率图像，足球直播，视觉分析<br />- 方法：多阶段生成，扩散模型，图像到图像<br />- 效果：高保真输出，细节恢复|
|🆕 发布|Harnessing Frequency Spectrum Insights for Image Copyright Protection Against Diffusion Models|利用频谱洞察力对抗扩散模型进行图像版权保护|Zhenguang Liu, Chao Shuai, Shaojing Fan, Ziping Dong, Jinwu Hu, Zhongjie Ba, Kui Ren|<http://arxiv.org/pdf/2503.11071v1>|- 问题：版权保护，扩散模型，图像生成<br />- 方法：频率域水印，CoprGuard框架<br />- 效果：鲁棒性，泛化性|
|📝 更新|SAFREE: Training-Free and Adaptive Guard for Safe Text-to-Image And Video Generation|SAFREE：无需训练且自适应的安全文本到图像和视频生成守护者|Jaehong Yoon, Shoubin Yu, Vaidehi Patil, Huaxiu Yao, Mohit Bansal|<http://arxiv.org/pdf/2410.12761v2>|- 问题：不安全内容生成，模型权重改变，训练依赖<br />- 方法：文本嵌入子空间检测，自适应过滤机制，自适应重注意力<br />- 效果：SOTA性能，高保真度，安全生成|
|🆕 发布|Understanding Flatness in Generative Models: Its Role and Benefits|理解生成模型中的平面性：其作用与益处|Taehwan Lee, Kyeongkook Seo, Jaejun Yoo, Sung Whan Yoon|<http://arxiv.org/pdf/2503.11078v1>|- 问题：Flatness, Generative Models, Loss Surface<br />- 方法：Theoretical Analysis, Diffusion Models, Sharpness-Aware Minimization<br />- 效果：Robustness, Generalization, Performance|
|🆕 发布|Flow to the Mode: Mode-Seeking Diffusion Autoencoders for State-of-the-Art Image Tokenization|流向模式：用于最先进图像分词的寻模扩散自动编码器|Kyle Sargent, Kyle Hsu, Justin Johnson, Li Fei-Fei, Jiajun Wu|<http://arxiv.org/pdf/2503.11056v1>|[[代码]](<http://kylesargent.github.io/flowmo>)<br />- 问题：图像压缩，生成模型，性能提升<br />- 方法：FlowMo，扩散自编码器，Transformer<br />- 效果：新SOTA，无卷积，无对抗损失|
|📝 更新|Tora: Trajectory-oriented Diffusion Transformer for Video Generation|Tora：面向轨迹的扩散Transformer用于视频生成|Zhenghao Zhang, Junchao Liao, Menghao Li, Zuozhuo Dai, Bingxue Qiu, Siyu Zhu, Long Qin, Weizhi Wang|<http://arxiv.org/pdf/2407.21705v4>|[[代码]](<https://github.com/alibaba/Tora>)<br />- 问题：视频生成，运动控制，扩散模型<br />- 方法：轨迹提取，时空扩散，运动融合<br />- 效果：高运动保真，复杂运动模拟|
|🆕 发布|ACMo: Attribute Controllable Motion Generation|ACMo：属性可控的运动生成|Mingjie Wei, Xuemei Xie, Guangming Shi|<http://arxiv.org/pdf/2503.11038v1>|[[代码]](<https://mjwei3d.github.io/ACMo>)<br />- 问题：运动属性控制，泛化能力，文本到运动<br />- 方法：属性扩散模型，运动适配器，LLM规划器<br />- 效果：风格化生成，用户友好，性能相当|
|📝 更新|Layton: Latent Consistency Tokenizer for 1024-pixel Image Reconstruction and Generation by 256 Tokens|Layton：基于256个标记的1024像素图像重建和生成的潜在一致性标记器|Qingsong Xie, Zhao Zhang, Zhe Huang, Yanhao Zhang, Haonan Lu, Zhenyu Yang|<http://arxiv.org/pdf/2503.08377v3>|[[代码]](<https://github.com/OPPO-Mente-Lab/Layton>)<br />- 问题：效率与保真度平衡，高分辨率图像重建<br />- 方法：Layton，Transformer编码器，量化代码簿，潜在一致性解码器<br />- 效果：高保真重建，256 tokens生成1024x1024图像|
|📝 更新|PTDiffusion: Free Lunch for Generating Optical Illusion Hidden Pictures with Phase-Transferred Diffusion Model|PTDiffusion：相位迁移扩散模型生成光学错觉隐藏图片的免费午餐|Xiang Gao, Shuai Yang, Jiaying Liu|<http://arxiv.org/pdf/2503.06186v2>|- 问题：光学错觉，图像融合，文本引导，无监督<br />- 方法：相位迁移，扩散模型，异步控制<br />- 效果：无训练，质量高，自然|
|🆕 发布|PSF-4D: A Progressive Sampling Framework for View Consistent 4D Editing|PSF-4D：一种用于视图一致4D编辑的渐进式采样框架|Hasan Iqbal, Nazmul Karim, Umar Khalid, Azib Farooq, Zichun Zhong, Jing Hua, Chen Chen|<http://arxiv.org/pdf/2503.11044v1>|- 问题：4D编辑，时序一致性，多视角一致性<br />- 方法：渐进采样框架，相关高斯噪声，跨视角噪声模型<br />- 效果：高质量编辑，超越现有方法|
|🆕 发布|EmoDiffusion: Enhancing Emotional 3D Facial Animation with Latent Diffusion Models|情感扩散：利用潜在扩散模型增强情感3D面部动画|Yixuan Zhang, Qing Chang, Yuxi Wang, Guang Chen, Zhaoxiang Zhang, Junran Peng|<http://arxiv.org/pdf/2503.11028v1>|- 问题：情感分离，3D动画，语音同步<br />- 方法：VAEs，扩散模型，情感适配器<br />- 效果：真实感，情感丰富|
|📝 更新|FlashVideo: Flowing Fidelity to Detail for Efficient High-Resolution Video Generation|FlashVideo：高效高分辨率视频生成中的流动保真度至细节|Shilong Zhang, Wenbo Li, Shoufa Chen, Chongjian Ge, Peize Sun, Yida Zhang, Yi Jiang, Zehuan Yuan .etc.|<http://arxiv.org/pdf/2502.05179v3>|- 问题：高分辨率视频生成，计算需求高<br />- 方法：两阶段框架，低分辨率生成，流匹配<br />- 效果：高效，高分辨率|
|📝 更新|ClassDiffusion: More Aligned Personalization Tuning with Explicit Class Guidance|《ClassDiffusion：基于显式类别引导的更精确个性化调整》|Jiannan Huang, Jun Hao Liew, Hanshu Yan, Yuyang Yin, Yao Zhao, Humphrey Shi, Yunchao Wei|<http://arxiv.org/pdf/2405.17532v3>|- 问题：过拟合，概念偏差，采样困难<br />- 方法：语义保留损失，概念空间调节<br />- 效果：提升组合能力，扩展至视频生成|


### 生成对抗网络 (GANs)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|T2I-FineEval: Fine-Grained Compositional Metric for Text-to-Image Evaluation|T2I-FineEval：文本到图像评估的细粒度组合度量|Seyed Mohammad Hadi Hosseini, Amir Mohammad Izadi, Ali Abdollahi, Armin Saghafian, Mahdieh Soleymani Baghshah|<http://arxiv.org/pdf/2503.11481v1>|- 问题：文本到图像生成，组合复杂性，评价指标<br />- 方法：细粒度问题分解，图像成分分析<br />- 效果：超越现有指标，评价效果提升|
|📝 更新|Compositional Generative Model of Unbounded 4D Cities|无界四维城市的组合生成模型|Haozhe Xie, Zhaoxi Chen, Fangzhou Hong, Ziwei Liu|<http://arxiv.org/pdf/2501.08983v2>|- 问题：4D城市生成，动态对象，静态场景，城市环境<br />- 方法：CityDreamer4D，神经字段，BEV表示<br />- 效果：实例编辑，城市风格化，城市模拟|
|📝 更新|Structure-guided Deep Multi-View Clustering|结构引导的深度多视图聚类|Jinrong Cui, Xiaohuang Wu, Haitao Zhang, Chongjie Dong, Jie Wen|<http://arxiv.org/pdf/2501.10157v3>|- 问题：多视图聚类，结构信息，数据分布<br />- 方法：结构引导，正样本选择，损失函数<br />- 效果：性能提升，一致性增强|
|🆕 发布|CyclePose -- Leveraging Cycle-Consistency for Annotation-Free Nuclei Segmentation in Fluorescence Microscopy|CyclePose -- 利用循环一致性实现荧光显微镜中无标注的细胞核分割|Jonas Utz, Stefan Vocht, Anne Tjorven Buessen, Dennis Possart, Fabian Wagner, Mareike Thies, Mingxuan Gu, Stefan Uderhardt .etc.|<http://arxiv.org/pdf/2503.11266v1>|[[代码]](<https://github.com/jonasutz/CyclePose>)<br />- 问题：无标注数据，核分割，计算成本高<br />- 方法：CycleGAN，自监督，CyclePose框架<br />- 效果：性能优于，弱监督|
|🆕 发布|Step-Video-TI2V Technical Report: A State-of-the-Art Text-Driven Image-to-Video Generation Model|《步视频-TI2V 技术报告：一种先进的基于文本驱动的图像到视频生成模型》|Haoyang Huang, Guoqing Ma, Nan Duan, Xing Chen, Changyi Wan, Ranchen Ming, Tianyu Wang, Bo Wang .etc.|<http://arxiv.org/pdf/2503.11251v1>|[[代码]](<https://github.com/stepfun-ai/Step-Video-TI2V.>)<br />- 问题：文本驱动图像到视频生成，性能评估<br />- 方法：30B参数模型，多输入生成，新基准Step-Video-TI2V-Eval<br />- 效果：SOTA性能，视频生成|
|📝 更新|The Curse of Conditions: Analyzing and Improving Optimal Transport for Conditional Flow-Based Generation|条件流生成中最优传输的诅咒：分析与改进|Ho Kei Cheng, Alexander Schwing|<http://arxiv.org/pdf/2503.10636v2>|[[代码]](<https://hkchengrex.github.io/C2OT>)<br />- 问题：条件生成，最优传输，性能差距<br />- 方法：条件最优传输，加权项，成本矩阵<br />- 效果：性能提升，效果优于基线|


## 多模态学习 (Multimodal Learning)


### 视觉语言模型 (Vision-Language Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Filter, Correlate, Compress: Training-Free Token Reduction for MLLM Acceleration|滤波、相关、压缩：无训练令牌减少以加速多语言语言模型|Yuhang Han, Xuyang Liu, Zihan Zhang, Pengxiang Ding, Donglin Wang, Honggang Chen, Qingsen Yan, Siteng Huang|<http://arxiv.org/pdf/2411.17686v3>|[[代码]](<https://ficoco-accelerate.github.io/.>)<br />- 问题：MLLMs计算挑战，冗余视觉token，信息恢复<br />- 方法：filter-correlate-compress框架，FiCoCo，自适应策略<br />- 效果：FLOPs减少，性能保留，效果优于现有方法|
|🆕 发布|Rethinking Few-Shot Adaptation of Vision-Language Models in Two Stages|重新思考分阶段实现视觉-语言模型的少样本适应|Matteo Farina, Massimiliano Mancini, Giovanni Iacca, Elisa Ricci|<http://arxiv.org/pdf/2503.11609v1>|- 问题：Few-Shot Adaptation，VLMs，参数效率<br />- 方法：Two-Stage Few-Shot Adaptation，PEFT，选择性推理<br />- 效果：超越SOTA，分类器性能提升|
|🆕 发布|VERIFY: A Benchmark of Visual Explanation and Reasoning for Investigating Multimodal Reasoning Fidelity|验证：多模态推理保真度研究的视觉解释与推理基准|Jing Bi, Junjia Guo, Susan Liang, Guangyu Sun, Luchuan Song, Yunlong Tang, Jinxi He, Jiarui Wu .etc.|<http://arxiv.org/pdf/2503.11557v1>|- 问题：视觉推理能力评估，多模态大语言模型，基准测试<br />- 方法：VERIFY基准，视觉信息推理，决策路径分析<br />- 效果：揭示模型局限，平衡感知推理|
|🆕 发布|SmolDocling: An ultra-compact vision-language model for end-to-end multi-modal document conversion|超紧凑型端到端多模态文档转换视觉-语言模型：SmolDocling|Ahmed Nassar, Andres Marafioti, Matteo Omenetti, Maksym Lysak, Nikolaos Livathinos, Christoph Auer, Lucas Morin, Rafael Teixeira de Lima .etc.|<http://arxiv.org/pdf/2503.11576v1>|- 问题：多模态文档转换，模型紧凑，性能强<br />- 方法：DocTags，端到端，参数少<br />- 效果：泛化好，效率高|
|🆕 发布|Vamba: Understanding Hour-Long Videos with Hybrid Mamba-Transformers|Vamba：利用混合Mamba-Transformer理解长达一小时的视频|Weiming Ren, Wentao Ma, Huan Yang, Cong Wei, Ge Zhang, Wenhu Chen|<http://arxiv.org/pdf/2503.11579v1>|- 问题：长视频处理，计算成本高，信息损失<br />- 方法：Mamba-2块，线性复杂度编码<br />- 效果：效率提升，性能增强|
|🆕 发布|TikZero: Zero-Shot Text-Guided Graphics Program Synthesis|TikZero：零样本文本引导的图形程序合成|Jonas Belouadi, Eddy Ilg, Margret Keuper, Hideki Tanaka, Masao Utiyama, Raj Dabre, Steffen Eger, Simone Paolo Ponzetto|<http://arxiv.org/pdf/2503.11509v1>|- 问题：文本图像合成，数据稀缺，编辑性<br />- 方法：图像表示，解耦生成，零样本合成<br />- 效果：性能超越基线，匹配大型模型|
|📝 更新|Visual Adaptive Prompting for Compositional Zero-Shot Learning|视觉自适应提示用于组合式零样本学习|Kyle Stein, Arash Mahyari, Guillermo Francia, Eman El-Sheikh|<http://arxiv.org/pdf/2502.20292v2>|- 问题：CZSL，视觉上下文，语义-视觉特征桥接<br />- 方法：VAPS，动态视觉提示库，相似性检索<br />- 效果：SOTA结果，泛化能力强|
|🆕 发布|PARIC: Probabilistic Attention Regularization for Language Guided Image Classification from Pre-trained Vison Language Models|概率注意力正则化：基于预训练视觉语言模型的语言引导图像分类|Mayank Nautiyal, Stela Arranz Gheorghe, Kristiana Stefa, Li Ju, Ida-Maria Sintorn, Prashant Singh|<http://arxiv.org/pdf/2503.11360v1>|- 问题：语言引导，注意力，预训练模型，多值性，跨模态映射<br />- 方法：概率注意力，不确定性估计，参考注意力图<br />- 效果：预测精度提升，减少偏差，一致性，鲁棒性|
|🆕 发布|Road Rage Reasoning with Vision-language Models (VLMs): Task Definition and Evaluation Dataset|基于视觉-语言模型的道路愤怒推理：任务定义与评估数据集|Yibing Weng, Yu Gu, Fuji Ren|<http://arxiv.org/pdf/2503.11342v1>|- 问题：道路愤怒，视觉语言模型，场景理解，事件识别<br />- 方法：道路愤怒推理任务，标注数据集，评估指标<br />- 效果：VLMs缺陷，性能提升|
|📝 更新|Holmes-VAU: Towards Long-term Video Anomaly Understanding at Any Granularity|霍姆斯-VAU：迈向任何粒度的长期视频异常理解|Huaxin Zhang, Xiaohao Xu, Xiang Wang, Jialong Zuo, Xiaonan Huang, Changxin Gao, Shanjun Zhang, Li Yu .etc.|<http://arxiv.org/pdf/2412.06171v2>|[[代码]](<https://github.com/pipixin321/HolmesVAU.>)<br />- 问题：视频异常理解，多尺度，可解释性<br />- 方法：大规模基准，半自动化标注，ATS采样<br />- 效果：效率提升，准确度提高|
|🆕 发布|DynRsl-VLM: Enhancing Autonomous Driving Perception with Dynamic Resolution Vision-Language Models|动态分辨率视觉-语言模型：提升自动驾驶感知|Xirui Zhou, Lianlei Shan, Xiaolin Gui|<http://arxiv.org/pdf/2503.11265v1>|- 问题：感知能力不足，细节信息丢失，计算负担重<br />- 方法：动态分辨率，ViT，图像-文本对齐<br />- 效果：环境感知增强，计算效率高|
|🆕 发布|Compound Expression Recognition via Large Vision-Language Models|复合表情识别通过大型视觉-语言模型|Jun Yu, Xilong Lu|<http://arxiv.org/pdf/2503.11241v1>|- 问题：CER，表情复杂，情感捕捉难<br />- 方法：LVLMs，两阶段微调，视觉语言特征<br />- 效果：高精度，零样本泛化|
|🆕 发布|LLaVA-MLB: Mitigating and Leveraging Attention Bias for Training-Free Video LLMs|LLaVA-MLB：缓解和利用注意力偏差以训练无监督视频语言大模型|Leqi Shen, Tao He, Guoqiang Gong, Fan Yang, Yifeng Zhang, Pengzhang Liu, Sicheng Zhao, Guiguang Ding|<http://arxiv.org/pdf/2503.11205v1>|- 问题：视频LLMs，信息保留，注意力偏差<br />- 方法：Gridded Attention Pooling，Visual Summarization Tail<br />- 效果：性能提升，效率准确|
|📝 更新|Skip Tuning: Pre-trained Vision-Language Models are Effective and Efficient Adapters Themselves|跳过调优：预训练的视觉-语言模型本身就是有效的和高效的适配器|Shihan Wu, Ji Zhang, Pengpeng Zeng, Lianli Gao, Jingkuan Song, Heng Tao Shen|<http://arxiv.org/pdf/2412.11509v2>|[[代码]](<https://github.com/Koorye/SkipTuning.>)<br />- 问题：VLM迁移，效率低，知识转移差<br />- 方法：Skip Tuning，LSkip，CSkip<br />- 效果：高效，知识转移好|
|🆕 发布|Beyond the Destination: A Novel Benchmark for Exploration-Aware Embodied Question Answering|超越目的地：探索感知具身问答的新基准|Kaixuan Jiang, Yang Liu, Weixing Chen, Jingzhou Luo, Ziliang Chen, Ling Pan, Guanbin Li, Liang Lin|<http://arxiv.org/pdf/2503.11117v1>|- 问题：EQA探索效率低，数据集设计差，评估指标不足<br />- 方法：EXPRESS-Bench，Fine-EQA，EAC<br />- 效果：提升探索效率，改善推理能力|
|🆕 发布|Quantifying Interpretability in CLIP Models with Concept Consistency|CLIP模型中概念一致性的可解释性量化|Avinash Madasu, Vasudev Lal, Phillip Howard|<http://arxiv.org/pdf/2503.11103v1>|- 问题：CLIP模型可解释性，概念一致性，模型性能<br />- 方法：概念一致性分数（CCS），ChatGPT，LLM评估<br />- 效果：模型性能提升，概念捕捉，领域外检测|
|🆕 发布|Open3DVQA: A Benchmark for Comprehensive Spatial Reasoning with Multimodal Large Language Model in Open Space|开放3DVQA：开放空间中多模态大型语言模型全面空间推理基准|Weichen Zhan, Zile Zhou, Zhiheng Zheng, Chen Gao, Jinqiang Cui, Yong Li, Xinlei Chen, Xiao-Ping Zhang|<http://arxiv.org/pdf/2503.11094v1>|[[代码]](<https://github.com/WeichenZh/Open3DVQA.>)<br />- 问题：空间推理，多模态LLM，基准测试<br />- 方法：Open3DVQA，半自动化数据收集，多方面评估<br />- 效果：性能提升，视角一致性，模型微调|
|🆕 发布|OmniDiff: A Comprehensive Benchmark for Fine-grained Image Difference Captioning|全息差异：细粒度图像差异描述的全面基准|Yuan Liu, Saihui Hou, Saijie Hou, Jiabao Du, Shibei Meng, Yongzhen Huang|<http://arxiv.org/pdf/2503.11093v1>|- 问题：IDC，数据集，深度，宽度，描述简单<br />- 方法：OmniDiff，M$^3$Diff，MDP模块<br />- 效果：SOTA，跨场景，准确率提升|
|🆕 发布|EmbodiedVSR: Dynamic Scene Graph-Guided Chain-of-Thought Reasoning for Visual Spatial Tasks|具身VSR：动态场景图引导的视觉空间任务思维链推理|Yi Zhang, Qiang Zhang, Xiaozhu Ju, Zhaoyang Liu, Jilei Mao, Jingkai Sun, Jintao Wu, Shixiong Gao .etc.|<http://arxiv.org/pdf/2503.11089v1>|- 问题：空间推理，长时任务，多模态模型<br />- 方法：动态场景图，思维链推理，零样本学习<br />- 效果：性能提升，推理连贯|
|📝 更新|Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning|在婴儿学习中发现超越语言输入的隐藏视觉概念|Xueyi Ke, Satoshi Tsutsui, Yayun Zhang, Bihan Wen|<http://arxiv.org/pdf/2501.05205v3>|- 问题：婴儿视觉学习，概念发现，跨学科研究<br />- 方法：无监督学习，内部表示分析，视觉概念神经元<br />- 效果：扩展词汇，模型比较|
|📝 更新|Mitigating Object Hallucinations in Large Vision-Language Models with Assembly of Global and Local Attention|减轻大型视觉-语言模型中的对象幻觉：全局与局部注意力的组装|Wenbin An, Feng Tian, Sicong Leng, Jiahao Nie, Haonan Lin, QianYing Wang, Ping Chen, Xiaoqin Zhang .etc.|<http://arxiv.org/pdf/2406.12718v3>|[[代码]](<https://github.com/Lackel/AGLA.>)<br />- 问题：对象幻觉，视觉定位不足<br />- 方法：AGLA，全局与局部注意力组装<br />- 效果：幻觉缓解，任务适用性广|
|🆕 发布|Falcon: A Remote Sensing Vision-Language Foundation Model|猎鹰：一种遥感视觉-语言基础模型|Kelu Yao, Nuo Xu, Rong Yang, Yingying Xu, Zhuoyan Gao, Titinunt Kitrungrotsakul, Yi Ren, Pu Zhang .etc.|<http://arxiv.org/pdf/2503.11070v1>|[[代码]](<https://github.com/TianHuiLab/Falcon>)<br />- 问题：遥感视觉语言模型，任务复杂，数据稀缺<br />- 方法：Falcon模型，Falcon_SFT数据集，指令微调<br />- 效果：多任务，高精度，参数少|
|🆕 发布|BannerAgency: Advertising Banner Design with Multimodal LLM Agents|多模态大型语言模型代理的广告横幅设计|Heng Wang, Yotaro Shimose, Shingo Takamatsu|<http://arxiv.org/pdf/2503.11060v1>|- 问题：广告横幅设计挑战，多尺寸需求，主观性，可编辑性<br />- 方法：MLLMs，自动设计，组件化输出<br />- 效果：高效，高质量，易编辑|
|📝 更新|Attention Hijackers: Detect and Disentangle Attention Hijacking in LVLMs for Hallucination Mitigation|注意力劫持者：检测和分解LVLMs中的幻觉缓解中的注意力劫持|Beitao Chen, Xinyu Lyu, Lianli Gao, Jingkuan Song, Heng Tao Shen|<http://arxiv.org/pdf/2503.08216v2>|- 问题：幻觉，视觉注意力，指令干扰<br />- 方法：AID，注意力劫持检测，解耦机制<br />- 效果：幻觉减少，模型鲁棒|
|📝 更新|Through the Magnifying Glass: Adaptive Perception Magnification for Hallucination-Free VLM Decoding|通过放大镜：无幻觉VLM解码的自适应感知放大|Shunqi Mao, Chaoyi Zhang, Weidong Cai|<http://arxiv.org/pdf/2503.10183v2>|[[代码]](<https://github.com/ShunqiM/PM>)<br />- 问题：视觉幻觉，VLM，解码偏差<br />- 方法：感知放大器，迭代隔离，区域放大<br />- 效果：幻觉减少，语言生成增强|
|📝 更新|On the Limitations of Vision-Language Models in Understanding Image Transforms|关于视觉-语言模型在理解图像变换中的局限性|Ahmad Mustafa Anis, Hasnain Ali, Saquib Sarfraz|<http://arxiv.org/pdf/2503.09837v2>|- 问题：VLMs，图像变换，理解局限性<br />- 方法：Flickr8k数据集，图像描述，模型评估<br />- 效果：模型缺陷，下游任务影响|
|🆕 发布|RONA: Pragmatically Diverse Image Captioning with Coherence Relations|RONA：基于连贯关系的实用多样化图像描述|Aashish Anantha Ramakrishnan, Aadarsh Anantha Ramakrishnan, Dongwon Lee|<http://arxiv.org/pdf/2503.10997v1>|[[代码]](<https://github.com/aashish2000/RONA>)<br />- 问题：图像描述多样性，中心信息传达<br />- 方法：Coherence Relations，MLLM prompting<br />- 效果：多样性提升，真实性对齐|


### 跨模态对齐 (Cross-modal Alignment)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Anchors Aweigh! Sail for Optimal Unified Multi-Modal Representations|锚点启航！扬帆驶向最优化的统一多模态表示|Minoh Jeong, Min Namgung, Zae Myung Kim, Dongyeop Kang, Yao-Yi Chiang, Alfred Hero|<http://arxiv.org/pdf/2410.02086v2>|- 问题：多模态学习，固定锚点，信息不足，跨模态关联<br />- 方法：自适应锚点，CentroBind，多模态表示<br />- 效果：性能提升，效率增强|
|🆕 发布|RASA: Replace Anyone, Say Anything -- A Training-Free Framework for Audio-Driven and Universal Portrait Video Editing|RASA：替换任何人，说出任何话——一种无需训练的音频驱动和通用肖像视频编辑框架|Tianrui Pan, Lin Liu, Jie Liu, Xiaopeng Zhang, Jie Tang, Gangshan Wu, Qi Tian|<http://arxiv.org/pdf/2503.11571v1>|[[代码]](<https://alice01010101.github.io/RASA>)<br />- 问题：肖像视频编辑，唇部重演，运动转移，训练需求<br />- 方法：无训练框架，统一动画控制，源逆潜变<br />- 效果：精确唇部，灵活运动|
|📝 更新|Aligning First, Then Fusing: A Novel Weakly Supervised Multimodal Violence Detection Method|首先对齐，然后融合：一种新颖的弱监督多模态暴力检测方法|Wenping Jin, Li Zhu, Jing Sun|<http://arxiv.org/pdf/2501.07496v2>|[[代码]](<https://github.com/xjpp2016/MAVD.>)<br />- 问题：弱监督，暴力检测，多模态<br />- 方法：语义特征对齐，模态融合，多实例学习<br />- 效果：AP 86.07%，信息充分利用|
|📝 更新|M2LADS Demo: A System for Generating Multimodal Learning Analytics Dashboards|M2LADS演示：一个生成多模态学习分析仪表板的系统|Alvaro Becerra, Roberto Daza, Ruth Cobos, Aythami Morales, Julian Fierrez|<http://arxiv.org/pdf/2502.15363v2>|- 问题：多模态学习数据分析，数据整合，可视化<br />- 方法：M2LADS系统，生物传感器数据集成，同步<br />- 效果：生理和行为数据可视化，数据科学家辅助|
|📝 更新|Dual-Stage Cross-Modal Network with Dynamic Feature Fusion for Emotional Mimicry Intensity Estimation|双阶段跨模态网络与动态特征融合用于情感模仿强度估计|Jun Yu, Lingsi Zhu, Yanjun Chi, Yunxiang Zhang, Yang Zheng, Yongqi Wang, Xilong Lu|<http://arxiv.org/pdf/2503.10603v2>|- 问题：情感模仿强度估计，动态相关性，多模态融合<br />- 方法：双阶段跨模态，动态融合模块，质量引导融合<br />- 效果：性能提升，细粒度分析|
|📝 更新|ParGo: Bridging Vision-Language with Partial and Global Views|ParGo：通过局部和全局视图连接视觉-语言|An-Lan Wang, Bin Shan, Wei Shi, Kun-Yu Lin, Xiang Fei, Guozhi Tang, Lei Liao, Can Huang .etc.|<http://arxiv.org/pdf/2408.12928v3>|- 问题：视觉-语言模态连接，表示差距，局部-全局视图<br />- 方法：ParGo投影器，全局-局部集成，ParGoCap-1M-PT数据集<br />- 效果：MME基准提升，细节感知能力增强|
|📝 更新|ChartMoE: Mixture of Diversely Aligned Expert Connector for Chart Understanding|图MoE：用于图表理解的多样化对齐专家连接器混合模型|Zhengzhuo Xu, Bowen Qu, Yiyan Qi, Sinan Du, Chengjin Xu, Chun Yuan, Jian Guo|<http://arxiv.org/pdf/2409.03277v3>|- 问题：图表理解，数据可靠性，模态桥接<br />- 方法：MoE架构，专家连接器，初始化策略<br />- 效果：准确率提升，性能优化|
|🆕 发布|MAVFlow: Preserving Paralinguistic Elements with Conditional Flow Matching for Zero-Shot AV2AV Multilingual Translation|MAVFlow：利用条件流匹配保留副语言元素，实现零样本AV2AV多语言翻译|Sungwoo Cho, Jeongsoo Choi, Sungnyun Kim, Se-Young Yun|<http://arxiv.org/pdf/2503.11026v1>|- 问题：AV2AV翻译，语音面部一致性，零样本<br />- 方法：条件流匹配，多模态引导，x-vectors<br />- 效果：性能提升，零样本翻译|
|🆕 发布|Observation-Graph Interaction and Key-Detail Guidance for Vision and Language Navigation|视觉与语言导航中的观察图交互与关键细节引导|Yifan Xie, Binkai Ou, Fei Ma, Yaohua Liu|<http://arxiv.org/pdf/2503.11006v1>|- 问题：VLN，路径规划，指令理解，导航精度<br />- 方法：观察图交互，关键细节引导，跨模态对齐<br />- 效果：性能提升，最优结果|


### 多模态融合 (Multimodal Fusion)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MMS-LLaMA: Efficient LLM-based Audio-Visual Speech Recognition with Minimal Multimodal Speech Tokens|MMS-LLaMA：基于最小多模态语音标记的高效LLM音频-视觉语音识别|Jeong Hun Yeo, Hyeongseop Rha, Se Jin Park, Yong Man Ro|<http://arxiv.org/pdf/2503.11315v1>|- 问题：AVSR，LLM，计算成本高<br />- 方法：早期融合，Q-Former，动态分配<br />- 效果：性能提升，效率提升|
|🆕 发布|Towards General Multimodal Visual Tracking|迈向通用多模态视觉跟踪|Andong Lu, Mai Wen, Jinhu Wang, Yuanzhi Guo, Chenglong Li, Jin Tang, Bin Luo|<http://arxiv.org/pdf/2503.11218v1>|- 问题：多模态跟踪，复杂场景，模态融合<br />- 方法：QuadFusion，多尺度融合，QuadTrack600<br />- 效果：性能提升，挑战场景鲁棒|
|🆕 发布|Multimodal-Aware Fusion Network for Referring Remote Sensing Image Segmentation|多模态感知融合网络用于遥感图像分割|Leideng Shi, Juan Zhang|<http://arxiv.org/pdf/2503.11183v1>|[[代码]](<https://github.com/Roaxy/MAFN.>)<br />- 问题：RRSIS，多模态融合，特征提取<br />- 方法：MAFN，CFM，MSRC<br />- 效果：精度提升，性能优越|
|📝 更新|LLaVA-Octopus: Unlocking Instruction-Driven Adaptive Projector Fusion for Video Understanding|LLaVA-Octopus：解锁指令驱动的自适应投影融合以实现视频理解|Jiaxing Zhao, Boyuan Sun, Xiang Chen, Xihan Wei, Qibin Hou|<http://arxiv.org/pdf/2501.05067v2>|- 问题：视频理解，多模态，特征融合，指令驱动<br />- 方法：自适应权重，视觉投影器，动态调整<br />- 效果：性能提升，多任务表现佳|
|🆕 发布|Solution for 8th Competition on Affective & Behavior Analysis in-the-wild|野外情感与行为分析第八届竞赛的解决方案|Jun Yu, Yunxiang Zhang, Xilong Lu, Yang Zheng, Yongqi Wang, Lingsi Zhu|<http://arxiv.org/pdf/2503.11115v1>|- 问题：面部动作单元检测，环境鲁棒性，准确性<br />- 方法：ConvNeXt，Whisper，Transformer，特征融合<br />- 效果：高维特征，AU检测精度提升|


## 目标检测识别 (Object Detection & Recognition)


### 三维检测 (3D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Affinity-VAE: incorporating prior knowledge in representation learning from scientific images|亲和-VAE：从科学图像中学习表示时融入先验知识|Marjan Famili, Jola Mirecka, Camila Rangel Smith, Anna Kotańska, Nikolai Juraschko, Beatriz Costa-Gomes, Colin M. Palmer, Jeyan Thiyagalingam .etc.|<http://arxiv.org/pdf/2209.04517v2>|- 问题：科学图像，表示学习，相似性，低对比度<br />- 方法：Affinity-VAE，先验知识，蛋白质结构<br />- 效果：旋转不变性，形态一致性，性能竞争|
|🆕 发布|FLASHμ: Fast Localizing And Sizing of Holographic Microparticles|FLASHμ：快速定位和测量全息微粒子|Ayush Paliwal, Oliver Schlenczek, Birte Thiede, Manuel Santos Pereira, Katja Stieger, Eberhard Bodenschatz, Gholamhossein Bagheri, Alexander Ecker|<http://arxiv.org/pdf/2503.11538v1>|- 问题：3D重建，粒子定位，尺寸测量，计算效率低<br />- 方法：两阶段神经网络，非局部检测，合成数据训练<br />- 效果：速度提升，精度高|
|📝 更新|PersonaCraft: Personalized and Controllable Full-Body Multi-Human Scene Generation Using Occlusion-Aware 3D-Conditioned Diffusion|个性化可控全身体感多人场景生成：基于遮挡感知3D条件扩散|Gwanghyun Kim, Suh Yoon Jeon, Seunggyu Lee, Se Young Chun|<http://arxiv.org/pdf/2411.18068v2>|- 问题：复杂场景，遮挡，全身个性化，2D姿态，面部身份<br />- 方法：3D条件扩散，SMPLx-ControlNet，遮挡边界增强，无分类器引导<br />- 效果：高质量，多人体，个性化|
|🆕 发布|Enhanced Multi-View Pedestrian Detection Using Probabilistic Occupancy Volume|基于概率占用体积的增强多视角行人检测|Reef Alturki, Adrian Hilton, Jean-Yves Guillemaut|<http://arxiv.org/pdf/2503.10982v1>|- 问题：遮挡，单视图检测，多视图融合，3D特征<br />- 方法：3D重建，概率占用体积，视觉 hull<br />- 效果：MODA 97.3%，性能提升|


### 二维检测 (2D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Alzheimer's Disease Classification Using Retinal OCT: TransnetOCT and Swin Transformer Models|基于视网膜OCT的阿尔茨海默病分类：TransnetOCT和Swin Transformer模型|Siva Manohar Reddy Kesu, Neelam Sinha, Hariharan Ramasangu, Thomas Gregor Issac|<http://arxiv.org/pdf/2503.11511v1>|- 问题：阿尔茨海默病，视网膜OCT，早期检测<br />- 方法：TransNetOCT，Swin Transformer，深度学习<br />- 效果：高准确率，可靠分类|
|🆕 发布|AugGen: Synthetic Augmentation Can Improve Discriminative Models|AugGen：合成增强可提升判别模型|Parsa Rahimi, Damien Teney, Sebastien Marcel|<http://arxiv.org/pdf/2503.11544v1>|[[代码]](<https://parsa-ra.github.io/auggen>)<br />- 问题：隐私，资源，合成数据，模型性能<br />- 方法：自包含，条件生成模型，数据集训练<br />- 效果：性能提升，超越基准|
|🆕 发布|Remote Photoplethysmography in Real-World and Extreme Lighting Scenarios|远程光电容积脉搏波描记法在现实世界和极端光照场景中的应用|Hang Shao, Lei Luo, Jianjun Qian, Mengkai Yan, Shuo Chen, Jian Yang|<http://arxiv.org/pdf/2503.11465v1>|- 问题：rPPG，光照干扰，训练困难<br />- 方法：视频transformer，干扰消除，自监督学习<br />- 效果：鲁棒性，实时性|
|🆕 发布|Enhancing Hand Palm Motion Gesture Recognition by Eliminating Reference Frame Bias via Frame-Invariant Similarity Measures|通过消除参考帧偏差的帧不变相似度度量增强手掌运动手势识别|Arno Verduyn, Maxim Vochten, Joris De Schutter|<http://arxiv.org/pdf/2503.11352v1>|- 问题：手势识别，参考系依赖，环境变化<br />- 方法：不变轨迹描述符，HPM数据集，实时PoC<br />- 效果：高可靠性，92.3% F1分数|
|🆕 发布|Self-Supervised Pretraining for Fine-Grained Plankton Recognition|自监督预训练用于细粒度浮游生物识别|Joona Kareinen, Tuomas Eerola, Kaisa Kraft, Lasse Lensu, Sanna Suikkanen, Heikki Kälviäinen|<http://arxiv.org/pdf/2503.11341v1>|- 问题：细粒度识别，数据集变化，标注困难<br />- 方法：自监督预训练，掩码自动编码，微调<br />- 效果：识别精度高，标注需求低|
|🆕 发布|Colour Morphological Distance Ordering based on the Log-Exp-Supremum|基于对数-指数-上确界的彩色形态学距离排序|Marvin Kahra, Michael Breuß|<http://arxiv.org/pdf/2503.11329v1>|- 问题：色彩形态学，无序，距离度量<br />- 方法：对数-指数-上确界，预排序，字典序<br />- 效果：避免伪彩色，结构元素识别|
|🆕 发布|Open-Set Plankton Recognition|开放集浮游生物识别|Joona Kareinen, Annaliina Skyttä, Tuomas Eerola, Kaisa Kraft, Lasse Lensu, Sanna Suikkanen, Maiju Lehtiniemi, Heikki Kälviäinen|<http://arxiv.org/pdf/2503.11318v1>|- 问题：开放集识别，微细生物，数据集，分类挑战<br />- 方法：OSR实验，拒绝阈值分析，公开数据集<br />- 效果：高精度，应用潜力|
|📝 更新|S$^3$AD: Semi-supervised Small Apple Detection in Orchard Environments|S$^3$AD：果园环境中的半监督小苹果检测|Robert Johanson, Christian Wilms, Ole Johannsen, Simone Frintrop|<http://arxiv.org/pdf/2311.05029v2>|- 问题：苹果检测，小目标，半监督学习，数据集<br />- 方法：S$^3$AD，上下文注意力，选择性拼接<br />- 效果：性能提升，挑战分析|
|📝 更新|An Ensemble-Based Two-Step Framework for Classification of Pap Smear Cell Images|基于集成学习的两步框架用于宫颈涂片细胞图像分类|Theo Di Piazza, Loic Boussel|<http://arxiv.org/pdf/2503.10312v2>|- 问题：宫颈癌早期检测，细胞图像分类<br />- 方法：两阶段集成，神经网络，图像识别<br />- 效果：自动化，诊断辅助|
|🆕 发布|Augmenting Image Annotation: A Human-LMM Collaborative Framework for Efficient Object Selection and Label Generation|图像标注增强：一种高效对象选择和标签生成的人机协同框架|He Zhang, Xinyi Fu, John M. Carroll|<http://arxiv.org/pdf/2503.11096v1>|- 问题：人工标注效率低，易疲劳，泛化能力差<br />- 方法：LMM辅助标注，人机协作，自动生成标签<br />- 效果：效率提升，泛化能力强|
|🆕 发布|VA-AR: Learning Velocity-Aware Action Representations with Mixture of Window Attention|VA-AR：使用混合窗口注意力学习速度感知动作表示|Jiangning Wei, Lixiong Qin, Bo Yu, Tianjian Zou, Chuhan Yan, Dandan Xiao, Yang Yu, Lan Yang .etc.|<http://arxiv.org/pdf/2503.11004v1>|- 问题：动作识别性能下降，速度影响，鲁棒性不足<br />- 方法：速度感知，混合窗口注意力，动态调整<br />- 效果：性能提升，准确度增强|
|🆕 发布|Rethinking Rotation-Invariant Recognition of Fine-grained Shapes from the Perspective of Contour Points|重新思考基于轮廓点的细粒度形状旋转不变识别|Yanjie Xu, Handing Xu, Tianmu Wang, Yaguan Li, Yunzhi Chen, Zhenguo Nie|<http://arxiv.org/pdf/2503.10992v1>|[[代码]](<https://github.com/zhenguonie/ANRICN_CGA.>)<br />- 问题：旋转不变性，细粒度形状识别，信息冗余<br />- 方法：轮廓点，几何区域，旋转不变编码<br />- 效果：性能优异，鲁棒性强|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HiTVideo: Hierarchical Tokenizers for Enhancing Text-to-Video Generation with Autoregressive Large Language Models|HiTVideo：用于增强基于自回归大型语言模型的文本到视频生成的分层标记器|Ziqin Zhou, Yifan Yang, Yuqing Yang, Tianyu He, Houwen Peng, Kai Qiu, Qi Dai, Lili Qiu .etc.|<http://arxiv.org/pdf/2503.11513v1>|[[代码]](<https://ziqinzhou66.github.io/project>)<br />- 问题：视频生成，文本-视频，复杂度，语义，时空<br />- 方法：HiTVideo，层次化标记器，3D因果VAE<br />- 效果：压缩率提升，重建质量，文本指导|


### 多目标跟踪 (Multi-object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Cognitive Disentanglement for Referring Multi-Object Tracking|认知解耦用于多对象跟踪的指称|Shaofeng Liang, Runwei Guan, Wangwang Lian, Daizong Liu, Xiaolou Sun, Dongming Wu, Yutao Yue, Weiping Ding .etc.|<http://arxiv.org/pdf/2503.11496v1>|- 问题：RMOT，语义信息融合，复杂场景理解<br />- 方法：认知解耦，双向交互融合，语义解耦查询学习<br />- 效果：HOTA提升，性能改进|


## 场景理解 (Scene Understanding)


### 语义分割 (Semantic Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MEET: A Million-Scale Dataset for Fine-Grained Geospatial Scene Classification with Zoom-Free Remote Sensing Imagery|MEET：一个用于无缩放遥感影像精细粒度地理空间场景分类的百万规模数据集|Yansheng Li, Yuning Wu, Gong Cheng, Chao Tao, Bo Dang, Yu Wang, Jiahao Zhang, Chuge Zhang .etc.|<http://arxiv.org/pdf/2503.11219v1>|[[代码]](<https://jerrywyn.github.io/project>)<br />- 问题：遥感图像分类，尺度依赖，场景上下文<br />- 方法：MEET数据集，场景内场景分类，CAT模型<br />- 效果：性能提升，基准测试|


## 时序理解 (Temporal Understanding)


### 时序分析 (Temporal Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|V-STaR: Benchmarking Video-LLMs on Video Spatio-Temporal Reasoning|V-STaR：在视频时空推理上对视频LLMs进行基准测试|Zixu Cheng, Jian Hu, Ziquan Liu, Chenyang Si, Wei Li, Shaogang Gong|<http://arxiv.org/pdf/2503.11495v1>|- 问题：视频LLM，时空推理，关系推理，理解评估<br />- 方法：V-STaR基准，RSTR任务，CoT逻辑，GPT-4管道<br />- 效果：时空推理差距，模型评估|


## 三维重建 (3D Reconstruction)


### 多视图重建 (Multi-view Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VGGT: Visual Geometry Grounded Transformer|VGGT：视觉几何基础Transformer|Jianyuan Wang, Minghao Chen, Nikita Karaev, Andrea Vedaldi, Christian Rupprecht, David Novotny|<http://arxiv.org/pdf/2503.11651v1>|[[代码]](<https://github.com/facebookresearch/vggt.>)<br />- 问题：3D场景理解，单任务模型，效率低<br />- 方法：VGGT网络，直接推断3D属性，预训练特征骨干<br />- 效果：高效，多任务，性能优越|
|🆕 发布|Cloud2BIM: An open-source automatic pipeline for efficient conversion of large-scale point clouds into IFC format|云到BIM：一个开源的大规模点云到IFC格式高效转换的自动流程|Slávek Zbirovský, Václav Nežerka|<http://arxiv.org/pdf/2503.11498v1>|- 问题：点云数据转换，BIM模型创建，手动操作，效率低<br />- 方法：自动转换，开放源代码，算法集成<br />- 效果：速度快，准确性高|
|🆕 发布|PBR3DGen: A VLM-guided Mesh Generation with High-quality PBR Texture|PBR3DGen：基于VLM的高质量PBR纹理网格生成|Xiaokang Wei, Bowen Zhang, Xianghui Yang, Yuxuan Wang, Chunchao Guo, Xi Zhao, Yan Luximon|<http://arxiv.org/pdf/2503.11368v1>|[[代码]](<https://pbr3dgen1218.github.io/.>)<br />- 问题：PBR材料生成，光照影响，材质分解，空间属性<br />- 方法：VLM引导，多视图扩散，像素感知先验<br />- 效果：新SOTA，PBR估计，网格生成|
|📝 更新|GauSTAR: Gaussian Surface Tracking and Reconstruction|高斯表面跟踪与重建：GauSTAR|Chengwei Zheng, Lixin Xue, Juan Zarate, Jie Song|<http://arxiv.org/pdf/2501.10283v3>|[[代码]](<https://eth-ait.github.io/GauSTAR>)<br />- 问题：动态表面跟踪，拓扑变化，重建<br />- 方法：GauSTAR，Gaussian Splatting，场景流<br />- 效果：实时渲染，准确重建|
|🆕 发布|Deep Incomplete Multi-view Clustering with Distribution Dual-Consistency Recovery Guidance|深度不完整多视图聚类与分布双一致性恢复指导|Jiaqi Jin, Siwei Wang, Zhibin Dong, Xihong Yang, Xinwang Liu, En Zhu, Kunlun He|<http://arxiv.org/pdf/2503.11017v1>|- 问题：多视角聚类，数据不完整，分布差异<br />- 方法：分布双一致性，邻域感知一致性，原型一致性<br />- 效果：性能优越，效果显著|


### 神经隐式重建 (Neural Implicit Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Polyhedral Surface: Self-supervised Point Cloud Reconstruction Based on Polyhedral Surface|多面体表面：基于多面体表面的自监督点云重建|Hui Tian, Kai Xu|<http://arxiv.org/pdf/2310.14560v2>|- 问题：点云重建，局部几何，特征丢失，边界伪影<br />- 方法：多面体表面，自监督学习，神经网路<br />- 效果：最佳结果，ShapeNetCore，ABC，ScanNet|
|🆕 发布|NF-SLAM: Effective, Normalizing Flow-supported Neural Field representations for object-level visual SLAM in automotive applications|NF-SLAM：适用于汽车应用中物体级视觉SLAM的有效归一化流支持的神经网络场表示|Li Cui, Yang Ding, Richard Hartley, Zirui Xie, Laurent Kneip, Zhenghua Yu|<http://arxiv.org/pdf/2503.11199v1>|- 问题：视觉SLAM，3D形状表示，稀疏数据<br />- 方法：神经场，归一化流，16维隐码<br />- 效果：性能提升，准确可靠|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Leveraging Diffusion Knowledge for Generative Image Compression with Fractal Frequency-Aware Band Learning|利用扩散知识进行具有分形频率感知的带学习生成图像压缩|Lingyu Zhu, Xiangrui Zeng, Bolin Chen, Peilin Chen, Yung-Hui Li, Shiqi Wang|<http://arxiv.org/pdf/2503.11321v1>|- 问题：图像压缩，率失真，真实感<br />- 方法：扩散知识，FFAB-IC网络，频率感知<br />- 效果：压缩率提升，真实感增强|


### 单目重建 (Monocular Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Street Gaussians without 3D Object Tracker|《无需3D目标跟踪的街景高斯分布》|Ruida Zhang, Chengxi Li, Chenyangguang Zhang, Xingyu Liu, Haili Yuan, Yanyan Li, Xiangyang Ji, Gim Hee Lee|<http://arxiv.org/pdf/2412.05548v2>|- 问题：动态场景重建，3D追踪器局限性，手动标注<br />- 方法：2D深度追踪，3D对象融合，运动学习策略<br />- 效果：优于现有方法，公开代码|


## 神经渲染 (Neural Rendering)


### 场景编辑 (Scene Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Advancing 3D Gaussian Splatting Editing with Complementary and Consensus Information|推进基于互补和一致性信息的3D高斯分层编辑|Xuanqi Zhang, Jieun Lee, Chris Joslin, Wonsook Lee|<http://arxiv.org/pdf/2503.11601v1>|- 问题：3DGS编辑，几何不一致，深度信息利用<br />- 方法：互补信息学习，波let共识机制，深度条件编辑<br />- 效果：渲染质量提升，视图一致性|
|🆕 发布|EgoSplat: Open-Vocabulary Egocentric Scene Understanding with Language Embedded 3D Gaussian Splatting|自我散布：嵌入语言的三维高斯散布的开放词汇自中心场景理解|Di Li, Jie Feng, Jiahao Chen, Weisheng Dong, Guanbin Li, Guangming Shi, Licheng Jiao|<http://arxiv.org/pdf/2503.11345v1>|- 问题：遮挡，多视角，动态交互，语义不一致，语义重建<br />- 方法：语言嵌入，3D高斯分层，多视角特征聚合，时空预测模块<br />- 效果：性能提升，新基准|


### 可控渲染 (Controllable Rendering)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Prof. Robot: Differentiable Robot Rendering Without Static and Self-Collisions|机器人教授：无静态和自碰撞的可微分机器人渲染|Quanyuan Ruan, Jiabao Lei, Wenhao Yuan, Yanglin Zhang, Dekun Lu, Guiliang Liu, Kui Jia|<http://arxiv.org/pdf/2503.11269v1>|- 问题：不同步渲染，物理感知缺失，碰撞风险<br />- 方法：碰撞分类器，Eikonal正则化，物理感知<br />- 效果：避免碰撞，优化动作|
|🆕 发布|Uncertainty-Aware Normal-Guided Gaussian Splatting for Surface Reconstruction from Sparse Image Sequences|基于稀疏图像序列的表面重建的不确定性感知正则化高斯分层|Zhen Tan, Xieyuanli Chen, Jinpu Zhang, Lei Feng, Dewen Hu|<http://arxiv.org/pdf/2503.11172v1>|- 问题：3DGS，稀疏图像序列，几何不确定性，局部最小值，结构伪影<br />- 方法：UNG-GS，空间不确定性场，概率建模，深度渲染策略，正常细化<br />- 效果：高保真渲染，高精度重建，性能提升|
|📝 更新|StyleSSP: Sampling StartPoint Enhancement for Training-free Diffusion-based Method for Style Transfer|风格SSP：无训练扩散风格迁移方法的起始点采样增强|Ruojun Xu, Weijie Xi, Xiaodi Wang, Yongbo Mao, Zach Cheng|<http://arxiv.org/pdf/2501.11319v2>|[[代码]](<https://github.com/bytedance/StyleSSP.>)<br />- 问题：风格迁移，内容泄露，布局变化<br />- 方法：起点增强，频率操作，负向引导<br />- 效果：内容保留，风格迁移|


### 神经辐射场 (Neural Radiance Fields)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LiDAR-GS:Real-time LiDAR Re-Simulation using Gaussian Splatting|LiDAR-GS：基于高斯散布的实时激光雷达重模拟|Qifeng Chen, Sheng Yang, Sicong Du, Tao Tang, Peng Chen, Yuchi Huo|<http://arxiv.org/pdf/2410.05111v2>|[[代码]](<https://github.com/cqf7419/LiDAR-GS.>)<br />- 问题：实时，高保真，LiDAR重模拟<br />- 方法：Gaussian Splatting，激光束投射，Neural Gaussian Representation<br />- 效果：帧率，质量，LiDAR特性|
|📝 更新|GuardSplat: Efficient and Robust Watermarking for 3D Gaussian Splatting|GuardSplat：高效且鲁棒的3D高斯喷溅水印技术|Zixuan Chen, Guangcong Wang, Jiahao Zhu, Jianhuang Lai, Xiaohua Xie|<http://arxiv.org/pdf/2411.19895v4>|[[代码]](<https://github.com/NarcissusEx/GuardSplat.>)<br />- 问题：3DGS资产版权保护，水印，效率，鲁棒性<br />- 方法：CLIP指导，SH-aware消息嵌入，抗扭曲提取<br />- 效果：高效，鲁棒，高保真|


## 定位与映射 (Localization & Mapping)


### 位姿估计 (Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bring Your Rear Cameras for Egocentric 3D Human Pose Estimation|带来你的后置摄像头进行以自我为中心的3D人体姿态估计|Hiroyasu Akada, Jian Wang, Vladislav Golyanik, Christian Theobalt|<http://arxiv.org/pdf/2503.11652v1>|- 问题：3D人体姿态估计，HMD设计，后置摄像头，多视角融合<br />- 方法：Transformer，2D关节热图，多视角信息<br />- 效果：精度提升，MPJPE降低|
|🆕 发布|EMoTive: Event-guided Trajectory Modeling for 3D Motion Estimation|EMoTive：事件引导的轨迹建模用于3D运动估计|Zengyu Wan, Wei Zhai, Yang Cao, Zhengjun Zha|<http://arxiv.org/pdf/2503.11371v1>|- 问题：3D运动估计，深度变化，时空不一致性<br />- 方法：事件引导，非均匀参数曲线，密度感知融合<br />- 效果：有效建模，多动态数据集|
|🆕 发布|Online Test-time Adaptation for 3D Human Pose Estimation: A Practical Perspective with Estimated 2D Poses|在线测试时自适应3D人体姿态估计：基于估计的2D姿态的实用视角|Qiuxia Lin, Kerui Gu, Linlin Yang, Angela Yao|<http://arxiv.org/pdf/2503.11194v1>|- 问题：在线测试时自适应，3D人体姿态估计，估计2D姿态<br />- 方法：自适应聚合，两阶段优化，局部增强<br />- 效果：超越现有方法，提高实用性|
|📝 更新|Homogeneous Dynamics Space for Heterogeneous Humans|同质动力学空间用于异质人类|Xinpeng Liu, Junxuan Liang, Chenshuo Zhang, Zixuan Cai, Cewu Lu, Yong-Lu Li|<http://arxiv.org/pdf/2412.06146v2>|[[代码]](<https://foruck.github.io/HDyS.>)<br />- 问题：人类动力学，异质性，运动理解<br />- 方法：Homogeneous Dynamics Space (HDyS)，数据聚合，逆前向动力学<br />- 效果：动力学映射，实验验证|
|🆕 发布|Fast and Robust Localization for Humanoid Soccer Robot via Iterative Landmark Matching|快速且鲁棒的类人形足球机器人定位方法通过迭代地标匹配|Ruochen Hou, Mingzhang Zhu, Hyunwoo Nam, Gabriel I. Fernandez, Dennis W. Hong|<http://arxiv.org/pdf/2503.11020v1>|- 问题：机器人定位，计算成本高，传感器噪声，视野限制<br />- 方法：迭代地标匹配，异常值去除，数据融合<br />- 效果：快速，鲁棒，精度高|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Exploring Typographic Visual Prompts Injection Threats in Cross-Modality Generation Models|探索跨模态生成模型中的字体视觉提示注入威胁|Hao Cheng, Erjia Xiao, Yichi Wang, Kaidi Xu, Mengshu Sun, Jindong Gu, Renjing Xu|<http://arxiv.org/pdf/2503.11519v1>|- 问题：跨模态生成模型，视觉提示注入，安全风险<br />- 方法：TVPI数据集，性能影响研究<br />- 效果：深入理解，潜在原因|
|🆕 发布|Neurons: Emulating the Human Visual Cortex Improves Fidelity and Interpretability in fMRI-to-Video Reconstruction|神经元：模拟人类视觉皮层提高fMRI到视频重建的保真度和可解释性|Haonan Wang, Qixiang Zhang, Lehan Wang, Xuanqi Huang, Xiaomeng Li|<http://arxiv.org/pdf/2503.11167v1>|[[代码]](<https://github.com/xmed-lab/NEURONS.>)<br />- 问题：fMRI-to-video，动态捕捉，语义对齐，特征整合<br />- 方法：NEURONS，子任务解耦，视觉皮层模拟<br />- 效果：视频一致性提升，语义准确率提升|


### 视觉SLAM (Visual SLAM)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AQUA-SLAM: Tightly-Coupled Underwater Acoustic-Visual-Inertial SLAM with Sensor Calibration|AQUA-SLAM：紧密耦合的水下声学-视觉-惯性SLAM与传感器校准|Shida Xu, Kaicheng Zhang, Sen Wang|<http://arxiv.org/pdf/2503.11420v1>|- 问题：水下SLAM，视觉特征缺失，传感器校准<br />- 方法：声视觉惯性SLAM，传感器校准技术，线性近似<br />- 效果：定位精度高，鲁棒性强|


### 语义建图 (Semantic Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|L2RSI: Cross-view LiDAR-based Place Recognition for Large-scale Urban Scenes via Remote Sensing Imagery|L2RSI：基于激光雷达的跨视图大规模城市场景遥感图像定位识别|Ziwei Shi, Xiaoran Zhang, Yan Xia, Yu Zang, Siqi Shen, Cheng Wang|<http://arxiv.org/pdf/2503.11245v1>|[[代码]](<https://shizw695.github.io/L2RSI>)<br />- 问题：LiDAR place recognition，3D maps，costly，time-consuming<br />- 方法：XA-L&RSI，cross-view LiDAR，feature alignment，probability propagation<br />- 效果：large-scale，95.08%，30m radius|


## 自监督学习 (Self-supervised Learning)


### 对比学习 (Contrastive Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|V$^2$Dial: Unification of Video and Visual Dialog via Multimodal Experts|V$^2$Dial：通过多模态专家统一视频与视觉对话|Adnen Abdessaied, Anna Rohrbach, Marcus Rohrbach, Andreas Bulling|<http://arxiv.org/pdf/2503.02063v2>|- 问题：多模态对话，视频与视觉对话，任务分离<br />- 方法：专家模型，联合学习，特征对齐<br />- 效果：新SOTA，零样本与微调|
|📝 更新|SiMHand: Mining Similar Hands for Large-Scale 3D Hand Pose Pre-training|SiMHand：大规模3D手部姿态预训练中的相似手部挖掘|Nie Lin, Takehiko Ohkawa, Yifei Huang, Mingfang Zhang, Minjie Cai, Ming Li, Ryosuke Furuta, Yoichi Sato|<http://arxiv.org/pdf/2502.15251v2>|[[代码]](<https://github.com/ut-vision/SiMHand.>)<br />- 问题：3D手姿估计，大规模数据，相似性挖掘<br />- 方法：对比学习，相似手对嵌入，自适应权重<br />- 效果：性能提升，超越PeCLR|
|🆕 发布|A Survey on Self-supervised Contrastive Learning for Multimodal Text-Image Analysis|多模态文本-图像分析中自监督对比学习的综述|Asifullah Khan, Laiba Asmatullah, Anza Malik, Shahzaib Khan, Hamna Asif|<http://arxiv.org/pdf/2503.11101v1>|- 问题：自监督学习，对比学习，文本图像分析<br />- 方法：对比学习，模型结构，预训练任务<br />- 效果：性能提升，应用广泛|


### 一致性学习 (Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Zero-TIG: Temporal Consistency-Aware Zero-Shot Illumination-Guided Low-light Video Enhancement|零-TIG：基于时间一致性感知的无监督光照引导低光视频增强|Yini Li, Nantheera Anantrasirichai|<http://arxiv.org/pdf/2503.11175v1>|- 问题：低光视频增强，时间一致性，无标注数据<br />- 方法：Retinex理论，光流技术，时序反馈模块<br />- 效果：无标注数据，视觉效果提升|


### 掩码自编码 (Masked Autoencoding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Masked LoGoNet: Fast and Accurate 3D Image Analysis for Medical Domain|掩码LoGoNet：医疗领域快速准确的3D图像分析|Amin Karimi Monsefi, Payam Karisani, Mengxi Zhou, Stacey Choi, Nathan Doble, Heng Ji, Srinivasan Parthasarathy, Rajiv Ramnath|<http://arxiv.org/pdf/2402.06190v2>|- 问题：数据成本高，训练数据少，维护成本高<br />- 方法：LoGoNet架构，自监督学习，多任务学习<br />- 效果：准确率高，推理快|


## 迁移与适应 (Transfer & Adaptation)


### 域适应 (Domain Adaptation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Seeing and Seeing Through the Glass: Real and Synthetic Data for Multi-Layer Depth Estimation|透过玻璃看世界：多层深度估计的实时与合成数据|Hongyu Wen, Yiming Zuo, Venkat Subramanian, Patrick Chen, Jia Deng|<http://arxiv.org/pdf/2503.11633v1>|- 问题：透明物体深度估计，多层数据集<br />- 方法：LayeredDepth数据集，合成数据生成器<br />- 效果：性能提升，准确率提高|
|🆕 发布|Disentangled Object-Centric Image Representation for Robotic Manipulation|解耦以物体为中心的图像表示用于机器人操作|David Emukpere, Romain Deffayet, Bingbing Wu, Romain Brégier, Michael Niemaz, Jean-Luc Meunier, Denys Proux, Jean-Michel Renders .etc.|<http://arxiv.org/pdf/2503.11565v1>|- 问题：多对象环境，简单操作，泛化能力<br />- 方法：DOCIR，解耦表示，对象、障碍、机器人<br />- 效果：最佳性能，泛化，仿真与真实世界|
|🆕 发布|Watch and Learn: Leveraging Expert Knowledge and Language for Surgical Video Understanding|观看并学习：利用专家知识和语言进行手术视频理解|David Gastager, Ghazal Ghazaei, Constantin Patsch|<http://arxiv.org/pdf/2503.11392v1>|- 问题：手术视频理解，数据稀疏，标注困难<br />- 方法：视频语言模型，大规模预训练，参数高效微调<br />- 效果：性能提升，零样本能力，密集视频字幕|
|🆕 发布|Deepfake Detection of Face Images based on a Convolutional Neural Network|基于卷积神经网络的深度伪造人脸图像检测|Lukas Kroiß, Johannes Reschke|<http://arxiv.org/pdf/2503.11389v1>|- 问题：deepfake检测，图像真实性，人脸识别<br />- 方法：ResNet-50，迁移学习，微调<br />- 效果：高精度，高召回率|
|🆕 发布|Cardiomyopathy Diagnosis Model from Endomyocardial Biopsy Specimens: Appropriate Feature Space and Class Boundary in Small Sample Size Data|心肌病诊断模型：小样本量数据中的适当特征空间和类别边界|Masaya Mori, Yuto Omae, Yutaka Koyama, Kazuyuki Hara, Jun Toyotani, Yasuo Okumura, Hiroyuki Hao|<http://arxiv.org/pdf/2503.11331v1>|- 问题：小样本，特征提取，模型泛化<br />- 方法：特征选择，维度压缩，支持向量机<br />- 效果：诊断有效，泛化性能提升|
|🆕 发布|Simulating Dual-Pixel Images From Ray Tracing For Depth Estimation|从光线追踪模拟双像素图像进行深度估计|Fengchen He, Dayang Zhao, Hao Xu, Tingwei Quan, Shaoqun Zeng|<http://arxiv.org/pdf/2503.11213v1>|- 问题：DP图像，深度估计，数据稀缺，模拟误差<br />- 方法：Sdirt方案，光迹追踪，深度估计训练<br />- 效果：泛化性好，模型性能提升|
|🆕 发布|A Multi-Objective Evaluation Framework for Analyzing Utility-Fairness Trade-Offs in Machine Learning Systems|多目标评估框架：分析机器学习系统中效用-公平性权衡|Gökhan Özbulak, Oscar Jimenez-del-Toro, Maíra Fatoretto, Lilian Berton, André Anjos|<http://arxiv.org/pdf/2503.11120v1>|- 问题：公平性评估，多目标，挑战<br />- 方法：多目标优化，雷达图，模型无关<br />- 效果：性能分析，决策支持|
|🆕 发布|Active Learning from Scene Embeddings for End-to-End Autonomous Driving|从场景嵌入中进行主动学习以实现端到端自动驾驶|Wenhao Jiang, Duo Li, Menghan Hu, Chao Ma, Ke Wang, Zhipeng Zhang|<http://arxiv.org/pdf/2503.11062v1>|- 问题：自动驾驶，数据标注，场景识别<br />- 方法：场景嵌入，主动学习，BEV特征<br />- 效果：数据减少30%，性能提升|
|🆕 发布|Towards Privacy-preserved Pre-training of Remote Sensing Foundation Models with Federated Mutual-guidance Learning|面向隐私保护遥感基础模型联邦互导学习的预训练|Jieyi Tan, Chengwei Zhang, Bo Dang, Yansheng Li|<http://arxiv.org/pdf/2503.11051v1>|- 问题：隐私保护，数据异构，模型漂移，通信开销<br />- 方法：联邦学习，互指导学习，SCG机制，CSG机制<br />- 效果：通信效率高，性能提升|
|🆕 发布|FMNet: Frequency-Assisted Mamba-Like Linear Attention Network for Camouflaged Object Detection|FMNet：用于伪装目标检测的频率辅助Mamba-like线性注意力网络|Ming Deng, Sijin Sun, Zihao Li, Xiaochuan Hu, Xing Wu|<http://arxiv.org/pdf/2503.11030v1>|- 问题：伪装目标检测，特征提取，计算成本<br />- 方法：频率域学习，多尺度频率辅助，线性注意力网络<br />- 效果：性能提升，效率优化|


### 元学习 (Meta Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AdaptGCD: Multi-Expert Adapter Tuning for Generalized Category Discovery|自适应GCD：通用类别发现的多专家适配器调优|Yuxun Qu, Yongqiang Tang, Chenyang Zhang, Wensheng Zhang|<http://arxiv.org/pdf/2410.21705v2>|- 问题：GCD任务，泛化能力，适应性<br />- 方法：Adapter tuning，多专家结构，路由约束<br />- 效果：性能提升，新类别发现|
|📝 更新|Towards Sample-specific Backdoor Attack with Clean Labels via Attribute Trigger|面向基于属性触发的带清洁标签的样本特定后门攻击|Mingyan Zhu, Yiming Li, Junfeng Guo, Tao Wei, Shu-Tao Xia, Zhan Qin|<http://arxiv.org/pdf/2312.04584v3>|- 问题：SSBA，清洁标签，攻击检测<br />- 方法：属性触发，内容相关特征，BAAT<br />- 效果：有效攻击，抗防御|
|📝 更新|Rethinking Epistemic and Aleatoric Uncertainty for Active Open-Set Annotation: An Energy-Based Approach|重新思考主动开放集标注中的认识论和随机不确定性：一种基于能量的方法|Chen-Chen Zong, Sheng-Jun Huang|<http://arxiv.org/pdf/2502.19691v2>|[[代码]](<https://github.com/chenchenzong/EAOA.>)<br />- 问题：开放集标注，不确定性，性能优化<br />- 方法：能量模型，自适应采样，多类检测器<br />- 效果：性能提升，高查询精度|


### 增量学习 (Incremental Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RECAST: Reparameterized, Compact weight Adaptation for Sequential Tasks|RECAST：针对序列任务的重新参数化、紧凑权重自适应|Nazia Tasnim, Bryan A. Plummer|<http://arxiv.org/pdf/2411.16870v2>|- 问题：增量学习，参数冗余，资源受限<br />- 方法：软参数共享，神经模仿，架构无关<br />- 效果：参数减少，性能提升|


## 鲁棒学习 (Robust Learning)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ReCamMaster: Camera-Controlled Generative Rendering from A Single Video|ReCamMaster：从单视频进行相机控制生成渲染|Jianhong Bai, Menghan Xia, Xiao Fu, Xintao Wang, Lianrui Mu, Jinwen Cao, Zuozhu Liu, Haoji Hu .etc.|<http://arxiv.org/pdf/2503.11647v1>|[[代码]](<https://jianhongbai.github.io/ReCamMaster>)<br />- 问题：视频重渲染，相机轨迹，动态同步<br />- 方法：生成模型，视频条件，多相机数据集<br />- 效果：性能提升，应用广泛|
|📝 更新|Dita: Scaling Diffusion Transformer for Generalist Vision-Language-Action Policy|Dita：扩展扩散Transformer以实现通用视觉-语言-动作策略|Zhi Hou, Tianyi Zhang, Yuwen Xiong, Haonan Duan, Hengjun Pu, Ronglei Tong, Chengyang Zhao, Xizhou Zhu .etc.|<http://arxiv.org/pdf/2410.15959v4>|- 问题：泛化能力，动作空间适应性，多模态扩散<br />- 方法：Transformer架构，上下文条件，跨数据集集成<br />- 效果：泛化性强，适应性强，长时任务执行|
|🆕 发布|MoMa-Kitchen: A 100K+ Benchmark for Affordance-Grounded Last-Mile Navigation in Mobile Manipulation|MoMa-Kitchen：移动操作中基于功能定位的最后一公里导航的10万+基准测试|Pingrui Zhang, Xianqiang Gao, Yuhan Wu, Kehui Liu, Dong Wang, Zhigang Wang, Bin Zhao, Yan Ding .etc.|<http://arxiv.org/pdf/2503.11081v1>|- 问题：导航与操作分离，定位不足，数据集缺乏<br />- 方法：MoMa-Kitchen数据集，自动生成，NavAff模型<br />- 效果：学习定位，适应不同臂型和平台|


### 对抗攻击 (Adversarial Attack)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Hiding Local Manipulations on SAR Images: a Counter-Forensic Attack|隐藏SAR图像上的局部操作：一种反取证攻击|Sara Mandelli, Edoardo Daniele Cannas, Paolo Bestagini, Stefano Tebaldini, Stefano Tubaro|<http://arxiv.org/pdf/2407.07041v2>|- 问题：SAR图像篡改，检测难度高<br />- 方法：对抗性攻击，模拟重采集<br />- 效果：隐蔽性强，通用性高|
|📝 更新|AnywhereDoor: Multi-Target Backdoor Attacks on Object Detection|任意门：目标检测的多目标后门攻击|Jialin Lu, Junjie Shan, Ziqi Zhao, Ka-Ho Chow|<http://arxiv.org/pdf/2411.14243v2>|- 问题：目标检测，后门攻击，单目标，多目标<br />- 方法：客观解耦，触发拼贴，策略批处理<br />- 效果：控制度高，成功率提升26%|


### 对抗防御 (Adversarial Defense)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Provenance Detection for AI-Generated Images: Combining Perceptual Hashing, Homomorphic Encryption, and AI Detection Models|AI生成图像的溯源检测：结合感知哈希、同态加密和AI检测模型|Shree Singhi, Aayan Yadav, Aayush Gupta, Shariar Ebrahimi, Parisa Hassanizadeh|<http://arxiv.org/pdf/2503.11195v1>|- 问题：AI图像溯源，水印易篡改，隐私保护<br />- 方法：DinoHash，MP-FHE，AI检测模型<br />- 效果：精度提升，隐私保护|
|🆕 发布|DriveGEN: Generalized and Robust 3D Detection in Driving via Controllable Text-to-Image Diffusion Generation|驱动生成：通过可控文本到图像扩散生成在驾驶中的泛化和鲁棒的3D检测|Hongbin Lin, Zilu Guo, Yifan Zhang, Shuaicheng Niu, Yafeng Li, Ruimao Zhang, Shuguang Cui, Zhen Li|<http://arxiv.org/pdf/2503.11122v1>|[[代码]](<https://github.com/Hongbin98/DriveGEN.>)<br />- 问题：3D检测，数据集规模，分布偏移，OOD问题<br />- 方法：文本到图像扩散，自原型提取，原型引导扩散<br />- 效果：鲁棒性提升，性能改善|
|📝 更新|Lifelong Knowledge Editing for Vision Language Models with Low-Rank Mixture-of-Experts|终身知识编辑：低秩混合专家视觉语言模型|Qizhou Chen, Chengyu Wang, Dakan Wang, Taolin Zhang, Wangyue Li, Xiaofeng He|<http://arxiv.org/pdf/2411.15432v2>|- 问题：VLLM编辑，知识更新，低秩专家<br />- 方法：LiveEdit，低秩专家生成，视觉语义知识<br />- 效果：终身编辑，性能提升|
|📝 更新|CADRef: Robust Out-of-Distribution Detection via Class-Aware Decoupled Relative Feature Leveraging|CADRef：基于类感知解耦相对特征的鲁棒异常检测|Zhiwei Ling, Yachen Chang, Hailiang Zhao, Xinkui Zhao, Kingsum Chow, Shuiguang Deng|<http://arxiv.org/pdf/2503.00325v2>|- 问题：过分布检测，DNN，特征利用，信息忽视<br />- 方法：CARef，CADRef，特征解耦，模型权重<br />- 效果：AUROC提升，FPR95降低|


### 对抗训练 (Adversarial Training)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Benchmarking Study of Vision-based Robotic Grasping Algorithms|基于视觉的机器人抓取算法基准测试研究|Bharath K Rameshbabu, Sumukh S Balakrishna, Brian Flynn, Vinarak Kapoor, Adam Norton, Holly Yanco, Berk Calli|<http://arxiv.org/pdf/2503.11163v1>|- 问题：视觉机器人抓取算法，比较分析，实验条件<br />- 方法：机器学习，分析算法，基准测试，仿真实验<br />- 效果：算法性能评估，实验结果分析|
|🆕 发布|Weakly Supervised Contrastive Adversarial Training for Learning Robust Features from Semi-supervised Data|弱监督对比对抗训练从半监督数据中学习鲁棒特征|Lilin Zhang, Chengpei Wu, Ning Yang|<http://arxiv.org/pdf/2503.11032v1>|- 问题：对抗训练，特征鲁棒性，半监督学习<br />- 方法：弱监督，对比对抗训练，信息理论<br />- 效果：特征鲁棒性提升，学习效果优化|
|📝 更新|DICE: End-to-end Deformation Capture of Hand-Face Interactions from a Single Image|DICE：从单张图像中端到端捕捉手-脸交互变形|Qingxuan Wu, Zhiyang Dou, Sirui Xu, Soshi Shimada, Chen Wang, Zhengming Yu, Yuan Liu, Cheng Lin .etc.|<http://arxiv.org/pdf/2406.17988v2>|- 问题：单图3D重建，手脸交互，变形捕捉，自遮挡，单视图模糊<br />- 方法：Transformer架构，解耦变形，弱监督训练，对抗先验<br />- 效果：精度领先，交互式速度|


## 模型压缩加速 (Model Compression & Acceleration)


### 知识蒸馏 (Knowledge Distillation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Towards Few-Call Model Stealing via Active Self-Paced Knowledge Distillation and Diffusion-Based Image Generation|朝着通过主动自我调节知识蒸馏和基于扩散的图像生成实现少量调用模型窃取的研究|Vlad Hondru, Radu Tudor Ionescu|<http://arxiv.org/pdf/2310.00096v2>|[[代码]](<https://github.com/vladhondru25/model-stealing.>)<br />- 问题：模型窃取，黑盒模型，数据限制<br />- 方法：扩散模型，知识蒸馏，自定步长学习<br />- 效果：模型提取，性能优越|
|🆕 发布|Breaking Shallow Limits: Task-Driven Pixel Fusion for Gap-free RGBT Tracking|标题翻译：打破浅层限制：任务驱动无间隙RGBT跟踪的像素融合|Andong Lu, Yuanzhi Guo, Wanyu Wang, Chenglong Li, Jin Tang, Bin Luo|<http://arxiv.org/pdf/2503.11247v1>|- 问题：融合位置，浅层网络，信息区分，融合能力<br />- 方法：任务驱动融合，渐进学习框架，动态模板更新<br />- 效果：性能提升，实时低延迟|
|📝 更新|Learnable Cross-modal Knowledge Distillation for Multi-modal Learning with Missing Modality|可学习的跨模态知识蒸馏，用于缺失模态的多模态学习|Hu Wang, Congbo Ma, Jianpeng Zhang, Yuan Zhang, Jodie Avery, Louise Hull, Gustavo Carneiro|<http://arxiv.org/pdf/2310.01035v2>|- 问题：多模态学习，缺失模态，模型性能下降<br />- 方法：LCKD模型，知识蒸馏，教师选举<br />- 效果：性能提升，Dice分数提高|
|🆕 发布|GaussianIP: Identity-Preserving Realistic 3D Human Generation via Human-Centric Diffusion Prior|高斯IP：通过以人为中心的扩散先验实现身份保持的真实3D人体生成|Zichen Tang, Yuan Yao, Miaomiao Cui, Liefeng Bo, Hongyu Yang|<http://arxiv.org/pdf/2503.11143v1>|[[代码]](<https://github.com/silence-tang/GaussianIP.>)<br />- 问题：3D人脸生成，细节缺失，训练时间长<br />- 方法：AHDS，VCR，多视角迭代<br />- 效果：质量提升，效率提高|
|📝 更新|MoVE-KD: Knowledge Distillation for VLMs with Mixture of Visual Encoders|MoVE-KD：基于混合视觉编码器的视觉语言模型知识蒸馏|Jiajun Cao, Yuan Zhang, Tao Huang, Ming Lu, Qizhe Zhang, Ruichuan An, Ningning MA, Shanghang Zhang|<http://arxiv.org/pdf/2501.01709v2>|[[代码]](<https://github.com/hey-cjj/MoVE-KD.>)<br />- 问题：VLMs计算成本高，特征提取冲突<br />- 方法：MoVE-KD，LoRA，MoEs，注意力蒸馏<br />- 效果：效率提升，性能增强|
|🆕 发布|LUSD: Localized Update Score Distillation for Text-Guided Image Editing|局部更新分数蒸馏用于文本引导的图像编辑|Worameth Chinchuthakun, Tossaporn Saengja, Nontawat Tritrong, Pitchaporn Rewatbowornwong, Pramook Khungurn, Supasorn Suwajanakorn|<http://arxiv.org/pdf/2503.11054v1>|- 问题：prompt fidelity, background preservation, score distillation, object insertion, gradient variations<br />- 方法：attention-based regularization, gradient filtering-normalization, localized update<br />- 效果：prompt fidelity, background preservation, user preference|
|🆕 发布|Cyclic Contrastive Knowledge Transfer for Open-Vocabulary Object Detection|循环对比知识迁移用于开放词汇物体检测|Chuhan Zhang, Chaoyang Zhu, Pingcheng Dong, Long Chen, Dong Zhang|<http://arxiv.org/pdf/2503.11005v1>|[[代码]](<https://github.com/ZCHUHan/CCKT-Det.>)<br />- 问题：开放词汇检测，预训练模型，知识迁移，监督学习<br />- 方法：循环知识转移，语义先验，区域对比损失<br />- 效果：性能提升，AP50增加|
|🆕 发布|Image-Goal Navigation Using Refined Feature Guidance and Scene Graph Enhancement|基于精细特征引导和场景图增强的图像目标导航|Zhicheng Feng, Xieyuanli Chen, Chenghao Shi, Lun Luo, Zhichao Chen, Yun-Hui Liu, Huimin Lu|<http://arxiv.org/pdf/2503.10986v1>|[[代码]](<https://github.com/nubot-nudt/RFSG.>)<br />- 问题：图像导航，特征关联，场景信息<br />- 方法：空间通道注意力，自蒸馏机制，场景图增强<br />- 效果：性能领先，实时导航|


### 网络剪枝 (Network Pruning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Training Noise Token Pruning|训练噪声令牌剪枝|Mingxing Rao, Bohan Jiang, Daniel Moyer|<http://arxiv.org/pdf/2411.18092v2>|- 问题：视觉Transformer，剪枝，噪声<br />- 方法：连续噪声剪枝，理论连接，实证评估<br />- 效果：优化训练，保留计算收益|


### 量化优化 (Quantization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Stabilizing Quantization-Aware Training by Implicit-Regularization on Hessian Matrix|通过Hessian矩阵的隐式正则化稳定量化感知训练|Junbiao Pang, Tianyang Cai|<http://arxiv.org/pdf/2503.11159v1>|- 问题：QAT稳定性，性能下降，Hessian矩阵<br />- 方法：FPQ，特征扰动，特征蒸馏<br />- 效果：SOTA性能，FP模型超越|
|📝 更新|Standalone 16-bit Neural Network Training: Missing Study for Hardware-Limited Deep Learning Practitioners|独立16位神经网络训练：硬件限制深度学习实践者的缺失研究|Juyoung Yun, Sol Choi, Francois Rameau, Byungkon Kang, Zhoulai Fu|<http://arxiv.org/pdf/2305.10947v5>|- 问题：资源限制，16位精度，神经网络<br />- 方法：理论分析，实证评估，误差容忍<br />- 效果：精度匹配，速度提升|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MoLEx: Mixture of Layer Experts for Finetuning with Sparse Upcycling|MoLEx：用于稀疏升级微调的层专家混合|Rachel S. Y. Teo, Tan M. Nguyen|<http://arxiv.org/pdf/2503.11144v1>|[[代码]](<https://github.com/rachtsy/molex.>)<br />- 问题：参数高效微调，模型重训练成本高<br />- 方法：层专家混合，稀疏混合专家，信息交换<br />- 效果：微调结果提升，计算开销低|


## 泛化与鲁棒性 (Generalization & Robustness)


### 域泛化 (Domain Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Non Line-of-Sight Optical Wireless Communication using Neuromorphic Cameras|非视距光学无线通信利用神经形态相机|Abbaas Alif Mohamed Nishar, Alireza Marefat, Ashwin Ashok|<http://arxiv.org/pdf/2503.11226v1>|- 问题：非视距通信，光无线通信，事件相机<br />- 方法：神经形态相机，被动反射，自适应调制<br />- 效果：数据速率高，鲁棒性强|
|🆕 发布|SpaceSeg: A High-Precision Intelligent Perception Segmentation Method for Multi-Spacecraft On-Orbit Targets|空间分割：一种用于多航天器在轨目标的超高精度智能感知分割方法|Hao Liu, Pengyu Guo, Siyuan Yang, Zeqing Jiang, Qinglei Hu, Dongyu Li|<http://arxiv.org/pdf/2503.11133v1>|[[代码]](<https://github.com/Akibaru/SpaceSeg>)<br />- 问题：多目标分割，环境复杂，精度要求高<br />- 方法：MSHARD，MS-CCA，SDAT，定制损失函数<br />- 效果：高精度，mIoU 89.87%，mAcc 99.98%|


## 可解释性 (Interpretability)


### 归因分析 (Attribution Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FastVID: Dynamic Density Pruning for Fast Video Large Language Models|快速VID：动态密度剪枝用于快速视频大型语言模型|Leqi Shen, Guoqiang Gong, Tao He, Yifeng Zhang, Pengzhang Liu, Sicheng Zhao, Guiguang Ding|<http://arxiv.org/pdf/2503.11187v1>|[[代码]](<https://github.com/LunarShen/FastVID.>)<br />- 问题：视频LLM推理成本高，冗余token<br />- 方法：动态密度剪枝，时空冗余分析<br />- 效果：性能提升，效率高|


### 可视化解释 (Visual Explanation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Virtual Guidance as a Mid-level Representation for Navigation with Augmented Reality|虚拟引导作为增强现实导航的中级表示|Hsuan-Kung Yang, Tsung-Chih Chiang, Jou-Min Liu, Ting-Ru Liu, Chun-Wei Huang, Tsu-Ching Hsiao, Chun-Yi Lee|<http://arxiv.org/pdf/2303.02731v3>|- 问题：导航信息传达，多模态融合，动态环境<br />- 方法：虚拟引导，视觉表示，模拟-现实迁移<br />- 效果：性能优于基线，导航有效性|


### 概念解释 (Concept Explanation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unlocking Open-Set Language Accessibility in Vision Models|解锁视觉模型中的开放集语言可访问性|Fawaz Sammani, Jonas Fischer, Nikos Deligiannis|<http://arxiv.org/pdf/2503.10981v1>|- 问题：视觉模型可解释性，开放集文本查询<br />- 方法：无标签方法，高效，保留分布和推理<br />- 效果：文本可解释性，零样本解码|


## 医学影像分析 (Medical Image Analysis)


### 医学分割 (Medical Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|COIN: Confidence Score-Guided Distillation for Annotation-Free Cell Segmentation|COIN：基于置信度分数的无标注细胞分割蒸馏|Sanghyun Jo, Seo Jin Lee, Seungwoo Lee, Seohyung Hong, Hyungseok Seo, Kyungsu Kim|<http://arxiv.org/pdf/2503.11439v1>|[[代码]](<https://github.com/shjo-april/COIN.>)<br />- 问题：无标注细胞分割，误检，性能差<br />- 方法：置信度引导蒸馏，无监督语义分割，递归自蒸馏<br />- 效果：超越现有方法，性能提升|
|📝 更新|Multi-modal Vision Pre-training for Medical Image Analysis|多模态视觉预训练在医学图像分析中的应用|Shaohao Rui, Lingzhi Chen, Zhenyu Tang, Lilong Wang, Mianxin Liu, Shaoting Zhang, Xiaosong Wang|<http://arxiv.org/pdf/2410.10604v2>|- 问题：跨模态学习，数据需求高，忽略模态关联<br />- 方法：多模态预训练，代理任务，模态模板蒸馏<br />- 效果：Dice Score提升，准确率提高|
|🆕 发布|LuSeg: Efficient Negative and Positive Obstacles Segmentation via Contrast-Driven Multi-Modal Feature Fusion on the Lunar|LuSeg：基于对比驱动的多模态特征融合在月球上的高效正负障碍物分割|Shuaifeng Jiao, Zhiwen Zeng, Zhuoqun Su, Xieyuanli Chen, Zongtan Zhou, Huimin Lu|<http://arxiv.org/pdf/2503.11409v1>|[[代码]](<https://github.com/nubot-nudt/LuSeg.>)<br />- 问题：月球探索，障碍物分割，安全自主<br />- 方法：对比学习，多模态特征融合，两阶段网络<br />- 效果：性能最优，速度高|
|📝 更新|Category Prompt Mamba Network for Nuclei Segmentation and Classification|核分割与分类的Mamba网络分类提示|Ye Zhang, Zijie Fang, Yifeng Wang, Lingbo Zhang, Xianchao Guan, Yongbing Zhang|<http://arxiv.org/pdf/2503.10422v2>|- 问题：核分割，分类，图像分割，训练时间，内存消耗<br />- 方法：Mamba网络，类别概率排序，特征扫描<br />- 效果：性能提升，核分割，分类|
|📝 更新|A study of why we need to reassess full reference image quality assessment with medical images|《关于为何需要重新评估医学图像全参考图像质量评估的研究》|Anna Breger, Ander Biguri, Malena Sabaté Landman, Ian Selby, Nicole Amberg, Elisabeth Brunner, Janek Gröhl, Sepideh Hatamikia .etc.|<http://arxiv.org/pdf/2405.19097v4>|- 问题：全参考图像质量评估，医学图像，PSNR，SSIM，不适用<br />- 方法：案例分析，医学图像类型，评估方法<br />- 效果：改进需求，AI可靠性|
|📝 更新|COMMA: Coordinate-aware Modulated Mamba Network for 3D Dispersed Vessel Segmentation|COMMA：用于3D散乱血管分割的坐标感知调制Mamba网络|Gen Shi, Hui Zhang, Jie Tian|<http://arxiv.org/pdf/2503.02332v2>|[[代码]](<https://github.com/shigen-StoneRoot/COMMA.>)<br />- 问题：3D血管分割，空间不确定性，位置感知丢失<br />- 方法：COMMA网络，ccMamba块，CaM块<br />- 效果：性能优越，效率高|
|📝 更新|LIX: Implicitly Infusing Spatial Geometric Prior Knowledge into Visual Semantic Segmentation for Autonomous Driving|LIX：将空间几何先验知识隐式融合到自动驾驶视觉语义分割中|Sicen Guo, Ziwei Long, Zhiyuan Wu, Qijun Chen, Ioannis Pitas, Rui Fan|<http://arxiv.org/pdf/2403.08215v2>|- 问题：空间几何数据缺失，语义分割性能下降<br />- 方法：知识蒸馏，动态权重控制，特征重校准<br />- 效果：性能提升，优于现有方法|
|🆕 发布|Toward Generalized Image Quality Assessment: Relaxing the Perfect Reference Quality Assumption|迈向通用图像质量评估：放宽完美参考质量假设|Du Chen, Tianhe Wu, Kede Ma, Lei Zhang|<http://arxiv.org/pdf/2503.11221v1>|[[代码]](<https://tianhewu.github.io/A-FINE-page.github.io>)<br />- 问题：FR-IQA，参考质量假设，图像增强<br />- 方法：DiffIQA数据库，A-FINE模型，自适应评估<br />- 效果：超越标准模型，SRIQA-Bench验证|
|🆕 发布|Minding Fuzzy Regions: A Data-driven Alternating Learning Paradigm for Stable Lesion Segmentation|关注模糊区域：一种用于稳定病变分割的数据驱动交替学习范式|Lexin Fang, Yunyang Xu, Xiang Ma, Xuemei Li, Caiming Zhang|<http://arxiv.org/pdf/2503.11140v1>|- 问题：病变分割，边界模糊，噪声标签<br />- 方法：DALE范式，损失一致性，分布对齐<br />- 效果：性能提升，稳定性高|
|🆕 发布|A Novel Decomposed Feature-Oriented Framework for Open-Set Semantic Segmentation on LiDAR Data|一种基于激光雷达数据的开放集语义分割的新型分解特征导向框架|Wenbang Deng, Xieyuanli Chen, Qinghua Yu, Yunze He, Junhao Xiao, Huimin Lu|<http://arxiv.org/pdf/2503.11097v1>|[[代码]](<https://github.com/nubot-nudt/DOSS.>)<br />- 问题：开放集语义分割，未知物体识别<br />- 方法：分解双解码器网络，多目标损失函数，异常检测机制<br />- 效果：性能优于现有方法，特征驱动|


### 影像重建 (Image Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Enhanced Low-Dose CT Image Reconstruction by Domain and Task Shifting Gaussian Denoisers|基于域和任务迁移的高斯去噪器增强低剂量CT图像重建|Tim Selig, Thomas März, Martin Storath, Andreas Weinmann|<http://arxiv.org/pdf/2403.03551v4>|- 问题：低剂量CT图像重建，噪声高，计算复杂<br />- 方法：FBP-DTSGD，预训练，任务迁移<br />- 效果：质量高，效率高|
|🆕 发布|TransiT: Transient Transformer for Non-line-of-sight Videography|瞬变Transformer：非视距视频摄影的瞬变变换器|Ruiqian Li, Siyuan Shen, Suan Xia, Ziheng Wang, Xingyue Peng, Chengxuan Song, Yingsheng Zhu, Tao Wu .etc.|<http://arxiv.org/pdf/2503.11328v1>|- 问题：NLOS视频重建，帧率与质量平衡，信号噪声比低<br />- 方法：TransiT架构，特征融合，时空Transformer，迁移学习<br />- 效果：实时重建，高分辨率，高帧率|
|📝 更新|Multi-Knowledge-oriented Nighttime Haze Imaging Enhancer for Vision-driven Intelligent Transportation Systems|多知识导向的夜间雾霾图像增强器，用于视觉驱动的智能交通系统|Ai Chen, Yuxu Lu, Dong Yang, Junlin Zhou, Yan Fu, Duanbing Chen|<http://arxiv.org/pdf/2502.07351v3>|[[代码]](<https://github.com/Ai-Chen-Lab/MKoIE.>)<br />- 问题：夜间雾霾，低光，图像质量差<br />- 方法：任务导向学习，自注意力模块，多尺度特征提取<br />- 效果：检测准确，效率高|


## 智能驾驶 (Intelligent Driving)


### 决策规划 (Decision Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Centaur: Robust End-to-End Autonomous Driving with Test-Time Training|半人马：基于测试时训练的鲁棒端到端自动驾驶|Chonghao Sima, Kashyap Chitta, Zhiding Yu, Shiyi Lan, Ping Luo, Andreas Geiger, Hongyang Li, Jose M. Alvarez|<http://arxiv.org/pdf/2503.11650v1>|- 问题：自动驾驶决策系统可靠性，规则依赖，保守行为<br />- 方法：测试时训练，不确定性度量，Cluster Entropy<br />- 效果：安全指标提升，navtest排名第一|
|🆕 发布|A Framework for a Capability-driven Evaluation of Scenario Understanding for Multimodal Large Language Models in Autonomous Driving|自动驾驶中多模态大型语言模型场景理解能力驱动的评估框架|Tin Stribor Sohn, Philipp Reis, Maximilian Dillitzer, Johannes Bach, Jason J. Corso, Eric Sax|<http://arxiv.org/pdf/2503.11400v1>|- 问题：MLLMs评估，场景理解，自动驾驶<br />- 方法：能力驱动框架，四维能力评估，场景分析<br />- 效果：系统评估，框架应用|
|🆕 发布|Aerial Vision-and-Language Navigation with Grid-based View Selection and Map Construction|基于网格视图选择和地图构建的空中视觉与语言导航|Ganlong Zhao, Guanbin Li, Jia Pan, Yizhou Yu|<http://arxiv.org/pdf/2503.11091v1>|- 问题：Aerial VLN，导航，3D场景，垂直动作，水平动作<br />- 方法：网格视图选择，地图构建，跨模态Transformer<br />- 效果：导航效果提升，地图信息丰富|


### 环境感知 (Environment Perception)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FG-DFPN: Flow Guided Deformable Frame Prediction Network|FG-DFPN：流引导可变形帧预测网络|M. Akın Yılmaz, Ahmet Bilican, A. Murat Tekalp|<http://arxiv.org/pdf/2503.11343v1>|- 问题：视频帧预测，时空动态，运动模式<br />- 方法：光流引导，可变形卷积，多尺度设计<br />- 效果：性能提升，PSNR 1dB，推理速度竞争|
|🆕 发布|GMG: A Video Prediction Method Based on Global Focus and Motion Guided|GMG：基于全局焦点和运动引导的视频预测方法|Yuhao Du, Hui Liu, Haoxiang Peng, Xinyuan Chen, Chenrong Wu, Jiankai Zhang|<http://arxiv.org/pdf/2503.11297v1>|- 问题：气象数据预测，特征提取，非刚性运动<br />- 方法：全局关注模块，运动引导模块<br />- 效果：预测精度高，适应性强|
|🆕 发布|Deep Lossless Image Compression via Masked Sampling and Coarse-to-Fine Auto-Regression|深度无损图像压缩：基于掩码采样和自回归的粗到细方法|Tiantian Li, Qunbing Xia, Yue Li, Ruixiao Guo, Gaobo Yang|<http://arxiv.org/pdf/2503.11231v1>|- 问题：无损图像压缩，依赖性，方向性<br />- 方法：掩码采样，粗细自回归，迭代过程<br />- 效果：压缩性能，编码速度，灵活性|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Advancements in Real-Time Oncology Diagnosis: Harnessing AI and Image Fusion Techniques|实时肿瘤诊断的进展：利用人工智能和图像融合技术|Leila Bagheriye, Johan Kwisthout|<http://arxiv.org/pdf/2503.11332v1>|- 问题：实时诊断，癌症早期检测，图像融合<br />- 方法：AI分析，多模态成像，神经形态架构<br />- 效果：高精度，早期诊断|
|🆕 发布|EmoAgent: Multi-Agent Collaboration of Plan, Edit, and Critic, for Affective Image Manipulation|情感图像编辑的多智能体协作：计划、编辑和批评|Qi Mao, Haobo Hu, Yujie He, Difei Gao, Haokun Chen, Libiao Jin|<http://arxiv.org/pdf/2503.11290v1>|- 问题：情感图像处理，多元素调整，协作方法<br />- 方法：多智能体协作，规划编辑批评，情感因子检索<br />- 效果：情感表达合理，效果优于现有方法|
|📝 更新|A Two-Step Concept-Based Approach for Enhanced Interpretability and Trust in Skin Lesion Diagnosis|基于概念的两种步骤方法，以增强皮肤病变诊断的可解释性和可信度|Cristiano Patrício, Luís F. Teixeira, João C. Neves|<http://arxiv.org/pdf/2411.05609v2>|[[代码]](<https://github.com/CristianoPatricio/2-step-concept-based-skin-diagnosis.>)<br />- 问题：可解释性，信任度，标注数据稀缺<br />- 方法：两步法，预训练VLM，LLM生成诊断<br />- 效果：超越传统CBM，解释性增强|


## 工业视觉 (Industrial Vision)


### 缺陷检测 (Defect Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-View Industrial Anomaly Detection with Epipolar Constrained Cross-View Fusion|多视图工业异常检测与共线约束跨视图融合|Yifan Liu, Xun Xu, Shijie Li, Jingyi Liao, Xulei Yang|<http://arxiv.org/pdf/2503.11088v1>|- 问题：多视图独立处理，几何特性未利用<br />- 方法：视差约束注意力模块，预训练策略，多视图负样本合成<br />- 效果：性能优于现有方法|


### 质量控制 (Quality Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Comparative Analysis of Advanced AI-based Object Detection Models for Pavement Marking Quality Assessment during Daytime|基于先进人工智能的路面标记质量评估白天检测模型的比较分析|Gian Antariksa, Rohir Chakraborty, Shriyank Somvanshi, Subasish Das, Mohammad Jalayer, Deep Rameshkumar Patel, David Mills|<http://arxiv.org/pdf/2503.11008v1>|- 问题：路面标记检测，YOLO模型，质量评估<br />- 方法：YOLOv8变体，mAP评估，IoU阈值<br />- 效果：准确高效，提升安全性|


## 其他 (Others)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Foundation Cures Personalization: Improving Personalized Models' Prompt Consistency via Hidden Foundation Knowledge|基础治愈个性化：通过隐藏基础知识提高个性化模型的提示一致性|Yiyang Cai, Zhengkai Jiang, Yulong Liu, Chunyang Jiang, Wei Xue, Wenhan Luo, Yike Guo|<http://arxiv.org/pdf/2411.15277v2>|[[代码]](<https://github.com/YIYANGCAI/freecure-project-page>)<br />- 问题：个性化模型，prompt一致性，身份嵌入，控制面部属性<br />- 方法：FreeCure框架，双重推理范式，基础模型知识<br />- 效果：prompt一致性提升，非侵入式增强，模型兼容性|

