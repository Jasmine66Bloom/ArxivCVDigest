## [UPDATED!] **2025-03-20** (Update Time)


## 表示学习 (Representation Learning)


### 视觉Transformer (Vision Transformers)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Karyotype AI for Precision Oncology|精准肿瘤学中的核型人工智能|Zahra Shamsi, Drew Bryant, Jacob Wilson, Xiaoyu Qu, Avinava Dubey, Konik Kothari, Mostafa Dehghani, Mariya Chavarha .etc.|<http://arxiv.org/pdf/2211.14312v4>|- 问题：染色体异常检测，手动分析，数据稀缺<br />- 方法：Vision Transformers，预训练微调，零样本检测<br />- 效果：高精度，快速诊断，改善患者预后|
|🆕 发布|Binarized Mamba-Transformer for Lightweight Quad Bayer HybridEVS Demosaicing|二值化Mamba-Transformer用于轻量级四合一拜耳混合EVS去马赛克|Shiyang Zhou, Haijin Zeng, Yunfan Lu, Tong Shao, Ke Tang, Yongyong Chen, Jie Liu, Jingyong Su|<http://arxiv.org/pdf/2503.16134v1>|[[代码]](<https://github.com/Clausy9/BMTNet.>)<br />- 问题：Quad Bayer，HybridEVS，去马赛克，复杂度高<br />- 方法：Binarized Mamba-Transformer，Bi-Mamba，轻量级<br />- 效果：高效，高性能|
|📝 更新|A Retrospective Systematic Study on Hierarchical Sparse Query Transformer-assisted Ultrasound Screening for Early Hepatocellular Carcinoma|关于辅助超声筛查早期肝细胞癌的分层稀疏查询变换器系统回顾性系统研究|Chaoyin She, Ruifang Lu, Danni He, Jiayi Lv, Yadan Lin, Meiqing Cheng, Hui Huang, Fengyu Ye .etc.|<http://arxiv.org/pdf/2502.03772v2>|[[代码]](<https://github.com/Asunatan/HSQformer.>)<br />- 问题：HCC早期检测，超声筛查，诊断一致性<br />- 方法：HSQformer，CNN，Vision Transformer，MoE框架<br />- 效果：AUC提升，诊断准确率|


### 预训练模型 (Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CLIMB: Data Foundations for Large Scale Multimodal Clinical Foundation Models|CLIMB：大规模多模态临床基础模型的数据基础|Wei Dai, Peilin Chen, Malinda Lu, Daniel Li, Haowen Wei, Hejie Cui, Paul Pu Liang|<http://arxiv.org/pdf/2503.07667v2>|[[代码]](<https://github.com/DDVD233/climb.>)<br />- 问题：小规模数据，单一模态，限制发展<br />- 方法：CLIMB基准，多模态数据，多任务预训练<br />- 效果：性能提升，泛化能力，融合策略|
|📝 更新|A Survey of the Self Supervised Learning Mechanisms for Vision Transformers|视觉Transformer的自监督学习机制综述|Asifullah Khan, Anabia Sohail, Mustansar Fiaz, Mehdi Hassan, Tariq Habib Afridi, Sibghat Ullah Marwat, Farzeen Munir, Safdar Ali .etc.|<http://arxiv.org/pdf/2408.17059v4>|- 问题：数据标注成本高，SSL，ViTs，有限标注数据<br />- 方法：SSL机制分类，动机讨论，预训练任务，比较分析<br />- 效果：探索SSL，识别挑战，未来研究方向|


## 生成建模 (Generative Modeling)


### 自回归模型 (Autoregressive Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bridging Continuous and Discrete Tokens for Autoregressive Visual Generation|跨越连续和离散标记以实现自回归视觉生成|Yuqing Wang, Zhijie Lin, Yao Teng, Yuanzhi Zhu, Shuhuai Ren, Jiashi Feng, Xihui Liu|<http://arxiv.org/pdf/2503.16430v1>|[[代码]](<https://yuqingwang1029.github.io/TokenBridge.>)<br />- 问题：图像压缩，信息损失，模型不稳定<br />- 方法：TokenBridge，后训练量化，轻量级预测<br />- 效果：质量相当，简单建模|
|🆕 发布|Improving Autoregressive Image Generation through Coarse-to-Fine Token Prediction|通过粗到细标记预测改进自回归图像生成|Ziyao Guo, Kaipeng Zhang, Michael Qizhe Shieh|<http://arxiv.org/pdf/2503.16194v1>|- 问题：量化误差，代码簿大小，自回归建模<br />- 方法：粗到细预测，辅助模型，码字表示<br />- 效果：性能提升，采样速度|
|📝 更新|Switti: Designing Scale-Wise Transformers for Text-to-Image Synthesis|Switti：设计用于文本到图像合成的尺度感知Transformer|Anton Voronov, Denis Kuznedelev, Mikhail Khoroshikh, Valentin Khrulkov, Dmitry Baranchuk|<http://arxiv.org/pdf/2412.01819v4>|- 问题：T2I生成，训练稳定性，采样速度，内存使用<br />- 方法：scale-wise transformer，非因果架构，无指导分类器<br />- 效果：采样加速，性能提升，速度提升7倍|


### 扩散模型 (Diffusion Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Multi-subject Open-set Personalization in Video Generation|多主体开放集视频生成个性化|Tsai-Shien Chen, Aliaksandr Siarohin, Willi Menapace, Yuwei Fang, Kwot Sin Lee, Ivan Skorokhodov, Kfir Aberman, Jun-Yan Zhu .etc.|<http://arxiv.org/pdf/2501.06187v2>|- 问题：视频个性化，领域限制，优化耗时，单主体支持<br />- 方法：Diffusion Transformer，多主体开放集，自动数据构建<br />- 效果：性能超越，量化评估|
|🆕 发布|DreamTexture: Shape from Virtual Texture with Analysis by Augmentation|梦境纹理：通过增强分析实现虚拟纹理的形状重建|Ananta R. Bhattarai, Xingzhe He, Alla Sheffer, Helge Rhodin|<http://arxiv.org/pdf/2503.16412v1>|- 问题：3D重建，虚拟纹理，计算成本高<br />- 方法：单目深度，虚拟纹理，变形分析<br />- 效果：重建精度高，计算效率高|
|🆕 发布|InfiniteYou: Flexible Photo Recrafting While Preserving Your Identity|无限你：在保留您身份的同时灵活进行照片重塑|Liming Jiang, Qing Yan, Yumin Jia, Zichuan Liu, Hao Kang, Xin Lu|<http://arxiv.org/pdf/2503.16418v1>|- 问题：身份相似性低，文本图像对齐差，生成质量低<br />- 方法：InfuseNet，多阶段训练，SPMS数据<br />- 效果：性能领先，兼容性强|
|🆕 发布|VerbDiff: Text-Only Diffusion Models with Enhanced Interaction Awareness|VerbDiff：增强交互意识的纯文本扩散模型|SeungJu Cha, Kwanyoung Lee, Ye-Chan Kim, Hyunwoo Oh, Dong-Jin Kim|<http://arxiv.org/pdf/2503.16406v1>|- 问题：交互理解，文本到图像，扩散模型<br />- 方法：VerbDiff，交互词解耦，局部区域利用<br />- 效果：准确交互，高质量图像|
|🆕 发布|Scale-wise Distillation of Diffusion Models|尺度蒸馏的扩散模型|Nikita Starodubcev, Denis Kuznedelev, Artem Babenko, Dmitry Baranchuk|<http://arxiv.org/pdf/2503.16397v1>|- 问题：扩散模型，计算成本高，性能损失<br />- 方法：尺度蒸馏，分布匹配，Patch Loss<br />- 效果：推理时间缩短，性能提升|
|🆕 发布|Do Visual Imaginations Improve Vision-and-Language Navigation Agents?|视觉想象能否提升视觉-语言导航智能体的性能？|Akhil Perincherry, Jacob Krantz, Stefan Lee|<http://arxiv.org/pdf/2503.16394v1>|- 问题：视觉想象，导航性能，视觉理解<br />- 方法：文本到图像扩散模型，辅助损失函数<br />- 效果：成功率提升，路径长度优化|
|🆕 发布|NuiScene: Exploring Efficient Generation of Unbounded Outdoor Scenes|NuiScene：探索无限户外场景的高效生成|Han-Hung Lee, Qinghong Han, Angel X. Chang|<http://arxiv.org/pdf/2503.16375v1>|- 问题：户外场景生成，高度变化，快速生成<br />- 方法：场景块编码，显式外扩模型，NuiScene43<br />- 效果：压缩性能，生成速度，环境融合|
|🆕 发布|LaPIG: Cross-Modal Generation of Paired Thermal and Visible Facial Images|LaPIG：跨模态生成成对的热成像和可见光面部图像|Leyang Wang, Joice Lin|<http://arxiv.org/pdf/2503.16376v1>|- 问题：数据获取困难，数据质量，数据多样性<br />- 方法：LLM辅助，ArcFace嵌入，LDMs，LLMs生成描述<br />- 效果：高质量数据，身份信息保留，性能优越|
|🆕 发布|Ultra-Resolution Adaptation with Ease|轻松实现超分辨率自适应|Ruonan Yu, Songhua Liu, Zhenxiong Tan, Xinchao Wang|<http://arxiv.org/pdf/2503.16322v1>|[[代码]](<https://github.com/Huage001/URAE>)<br />- 问题：高分辨率图像生成，数据资源有限<br />- 方法：URAE，数据效率，参数效率<br />- 效果：性能提升，效率高|
|🆕 发布|SceneMI: Motion In-betweening for Modeling Human-Scene Interactions|场景MI：建模人景交互之间的运动插值|Inwoo Hwang, Bing Zhou, Young Min Kim, Jian Wang, Chuan Guo|<http://arxiv.org/pdf/2503.16289v1>|- 问题：HSI建模，控制性，灵活性<br />- 方法：Scene-aware Motion In-betweening，SceneMI，扩散模型<br />- 效果：场景感知，数据增强，应用广泛|
|🆕 发布|Unleashing Vecset Diffusion Model for Fast Shape Generation|释放Vecset扩散模型以实现快速形状生成|Zeqiang Lai, Yunfei Zhao, Zibo Zhao, Haolin Liu, Fuyun Wang, Huiwen Shi, Xianghui Yang, Qinxiang Lin .etc.|<http://arxiv.org/pdf/2503.16302v1>|[[代码]](<https://github.com/Tencent/FlashVDM.>)<br />- 问题：3D形状生成速度慢，解码困难<br />- 方法：FlashVDM，渐进式流动蒸馏，轻量级解码器<br />- 效果：速度提升，性能接近SOTA|
|🆕 发布|Temporal Score Analysis for Understanding and Correcting Diffusion Artifacts|时间分数分析：理解与纠正扩散伪影|Yu Cao, Zengqun Zhao, Ioannis Patras, Shaogang Gong|<http://arxiv.org/pdf/2503.16218v1>|- 问题：扩散模型，视觉伪影，理解，检测<br />- 方法：时间分数分析，ASCED，动态监测<br />- 效果：减少伪影，效果匹配，无需额外训练|
|📝 更新|Text2Earth: Unlocking Text-driven Remote Sensing Image Generation with a Global-Scale Dataset and a Foundation Model|Text2Earth：利用全球规模数据集和基础模型解锁文本驱动遥感图像生成|Chenyang Liu, Keyan Chen, Rui Zhao, Zhengxia Zou, Zhenwei Shi|<http://arxiv.org/pdf/2501.00895v2>|[[代码]](<https://chen-yang-liu.github.io/Text2Earth>)<br />- 问题：文本驱动遥感图像生成，数据规模小，生成能力有限<br />- 方法：Git-10M数据集，Text2Earth模型，分辨率引导机制<br />- 效果：FID提升26.23，Zero-shot Cls-OA提升20.95%|
|🆕 发布|Shining Yourself: High-Fidelity Ornaments Virtual Try-on with Diffusion Model|自我闪耀：基于扩散模型的超高保真饰品虚拟试穿|Yingmao Miao, Zhanpeng Huang, Rui Han, Zibin Wang, Chenhao Lin, Chao Shen|<http://arxiv.org/pdf/2503.16065v1>|- 问题：虚拟饰品试穿，几何和外观一致性，尺度与姿态变化<br />- 方法：扩散模型，迭代方案，注意力层正则化<br />- 效果：身份保留，真实视觉效果|
|🆕 发布|Expert Race: A Flexible Routing Strategy for Scaling Diffusion Transformer with Mixture of Experts|专家赛道：混合专家的扩散变换器可扩展性灵活路由策略|Yike Yuan, Ziyu Wang, Zihao Huang, Defa Zhu, Xun Zhou, Jingyi Yu, Qiyang Min|<http://arxiv.org/pdf/2503.16057v1>|- 问题：模型可扩展性，性能提升，浅层学习挑战<br />- 方法：MoE，Expert Race，层内正则化，路由相似度损失<br />- 效果：性能增益，可扩展性|
|🆕 发布|Animating the Uncaptured: Humanoid Mesh Animation with Video Diffusion Models|《捕捉之外：人形网格动画与视频扩散模型》|Marc Benedí San Millán, Angela Dai, Matthias Nießner|<http://arxiv.org/pdf/2503.15996v1>|- 问题：动画制作耗时，成本高，真实感不足<br />- 方法：视频扩散模型，SMPL表示，运动优化<br />- 效果：高效，低成本，多样化|
|🆕 发布|Acc3D: Accelerating Single Image to 3D Diffusion Models via Edge Consistency Guided Score Distillation|Acc3D：通过边缘一致性引导的分数蒸馏加速单图像到3D扩散模型|Kendong Liu, Zhiyu Zhu, Hui Liu, Junhui Hou|<http://arxiv.org/pdf/2503.15975v1>|- 问题：加速单图到3D模型，正则化学习，边缘一致性<br />- 方法：边缘一致性引导，分数蒸馏，对抗增强<br />- 效果：效率提升20倍，质量改善|
|📝 更新|I2AM: Interpreting Image-to-Image Latent Diffusion Models via Bi-Attribution Maps|图像到图像潜在扩散模型通过双属性图进行解释|Junseo Park, Hyeryung Jang|<http://arxiv.org/pdf/2407.12331v2>|- 问题：I2I模型可解释性，跨注意力机制，图像生成<br />- 方法：I2AM，双向归因图，IMACS<br />- 效果：模型调试，性能提升，可解释性增强|
|🆕 发布|BlockDance: Reuse Structurally Similar Spatio-Temporal Features to Accelerate Diffusion Transformers|块舞：重用结构相似的空间时间特征以加速扩散变换器|Hui Zhang, Tingwei Gao, Jie Shao, Zuxuan Wu|<http://arxiv.org/pdf/2503.15927v1>|- 问题：低推理速度，冗余计算<br />- 方法：BlockDance，STSS特征，资源动态分配<br />- 效果：加速25%-50%，保持质量|
|🆕 发布|Text-Driven Diffusion Model for Sign Language Production|基于文本驱动的手语生成扩散模型|Jiayi He, Xu Wang, Ruobei Zhang, Shengeng Tang, Yaxiong Wang, Lechao Cheng|<http://arxiv.org/pdf/2503.15914v1>|- 问题：手语生成，语义对齐，文本驱动<br />- 方法：扩散模型，编码器，损失函数<br />- 效果：BLEU-1 20.17，第二|
|📝 更新|Pathways on the Image Manifold: Image Editing via Video Generation|图像流形上的路径：通过视频生成进行图像编辑|Noam Rotstein, Gal Yona, Daniel Silver, Roy Velich, David Bensaïd, Ron Kimmel|<http://arxiv.org/pdf/2411.16819v4>|[[代码]](<https://rotsteinnoam.github.io/Frame2Frame.>)<br />- 问题：图像编辑准确性，保真度，复杂指令<br />- 方法：图像到视频模型，时间过程，平滑过渡<br />- 效果：编辑精度提升，图像保真度保持|
|🆕 发布|Jasmine: Harnessing Diffusion Prior for Self-supervised Depth Estimation|茉莉：利用扩散先验进行自监督深度估计|Jiyuan Wang, Chunyu Lin, Cheng Guan, Lang Nie, Jing He, Haodong Li, Kang Liao, Yao Zhao|<http://arxiv.org/pdf/2503.15905v1>|- 问题：单目深度估计，监督学习，自监督，模糊预测<br />- 方法：扩散模型，混合图像重建，Scale-Shift GRU<br />- 效果：SoTA性能，零样本泛化|
|📝 更新|Paint by Inpaint: Learning to Add Image Objects by Removing Them First|通过先去除来学习添加图像对象：Paint by Inpaint|Navve Wasserman, Noam Rotstein, Roy Ganz, Ron Kimmel|<http://arxiv.org/pdf/2404.18212v3>|[[代码]](<https://rotsteinnoam.github.io/Paint-by-Inpaint.>)<br />- 问题：图像编辑，添加对象，无输入掩码<br />- 方法：去除对象，训练模型，自然语言指令<br />- 效果：模型超越，编辑任务提升|
|📝 更新|Perturb-and-Revise: Flexible 3D Editing with Generative Trajectories|扰动与修正：具有生成轨迹的灵活3D编辑|Susung Hong, Johanna Karras, Ricardo Martin-Brualla, Ira Kemelmacher-Shlizerman|<http://arxiv.org/pdf/2412.05279v2>|[[代码]](<https://susunghong.github.io/Perturb-and-Revise.>)<br />- 问题：3D编辑，几何变化，外观修改<br />- 方法：Perturb-and-Revise，NeRF编辑，生成轨迹<br />- 效果：灵活编辑，一致性，效果显著|
|🆕 发布|Repurposing 2D Diffusion Models with Gaussian Atlas for 3D Generation|重新利用高斯图谱的二维扩散模型进行三维生成|Tiange Xiang, Kai Li, Chengjiang Long, Christian Häne, Peihong Guo, Scott Delp, Ehsan Adeli, Li Fei-Fei|<http://arxiv.org/pdf/2503.15877v1>|- 问题：3D数据稀缺，2D模型迁移，3D生成<br />- 方法：Gaussian Atlas，2D模型复用，3D数据集<br />- 效果：3D生成，跨模态迁移|
|📝 更新|Diffusion Model as a Noise-Aware Latent Reward Model for Step-Level Preference Optimization|扩散模型作为噪声感知的潜在奖励模型用于步级偏好优化|Tao Zhang, Cheng Da, Kun Ding, Kun Jin, Yan Li, Tingting Gao, Di Zhang, Shiming Xiang .etc.|<http://arxiv.org/pdf/2502.01051v2>|[[代码]](<https://github.com/Kwai-Kolors/LPO.>)<br />- 问题：偏好优化，噪声处理，扩散模型，像素级奖励<br />- 方法：潜在奖励模型，潜在偏好优化，直接在潜在空间<br />- 效果：性能提升，训练速度加快|
|🆕 发布|UniCoRN: Latent Diffusion-based Unified Controllable Image Restoration Network across Multiple Degradations|基于潜在扩散的跨多种退化统一可控图像恢复网络：UniCoRN|Debabrata Mandal, Soumitri Chattopadhyay, Guansen Tong, Praneeth Chakravarthula|<http://arxiv.org/pdf/2503.15868v1>|[[代码]](<https://codejaeger.github.io/unicorn-gh>)<br />- 问题：单一退化处理，多退化同时处理<br />- 方法：多头扩散模型，低级视觉线索，混合专家策略<br />- 效果：性能提升，鲁棒恢复|
|📝 更新|Style-Friendly SNR Sampler for Style-Driven Generation|风格友好型信噪比采样器用于风格驱动生成|Jooyoung Choi, Chaehun Shin, Yeongtak Oh, Heeseung Kim, Jungbeom Lee, Sungroh Yoon|<http://arxiv.org/pdf/2411.14793v3>|- 问题：风格学习，风格模板，风格驱动生成<br />- 方法：风格友好SNR采样器，噪声水平调整<br />- 效果：风格捕捉，风格模板创建|
|📝 更新|Causal Deciphering and Inpainting in Spatio-Temporal Dynamics via Diffusion Model|时空动态中的因果解码与修复通过扩散模型|Yifan Duan, Jian Zhao, pengcheng, Junyuan Mao, Hao Wu, Jingyu Xu, Shilong Wang, Caoyuan Ma .etc.|<http://arxiv.org/pdf/2409.19608v3>|- 问题：数据不平衡，模型泛化性差，可解释性低<br />- 方法：因果框架，图像修复，DDPM<br />- 效果：性能提升，泛化能力增强|
|📝 更新|Aligning Text to Image in Diffusion Models is Easier Than You Think|《在扩散模型中将文本对齐到图像比您想象的要简单》|Jaa-Yeon Lee, Byunghee Cha, Jeongsol Kim, Jong Chul Ye|<http://arxiv.org/pdf/2503.08250v2>|- 问题：文本图像对齐，表示对齐，残差误对齐<br />- 方法：对比学习，SoftREPA，软文本标记<br />- 效果：语义一致性提升，互信息增加|
|📝 更新|Image is All You Need to Empower Large-scale Diffusion Models for In-Domain Generation|图像即一切：赋能大规模扩散模型进行域内生成|Pu Cao, Feng Zhou, Lu Yang, Tianrui Huang, Qing Song|<http://arxiv.org/pdf/2312.08195v2>|- 问题：领域生成，数据标签，模型泛化<br />- 方法：指导解耦，先验保留，知识学习<br />- 效果：生成质量高，可控性强|
|🆕 发布|EDEN: Enhanced Diffusion for High-quality Large-motion Video Frame Interpolation|EDEN：用于高质量大运动视频帧插值的增强扩散|Zihao Zhang, Haoran Chen, Haoyu Zhao, Guansong Lu, Yanwei Fu, Hang Xu, Zuxuan Wu|<http://arxiv.org/pdf/2503.15831v1>|- 问题：视频帧插值，大运动，非线性运动<br />- 方法：扩散模型，transformer，时间注意力<br />- 效果：LPIPS降低，性能提升|
|📝 更新|V2X-R: Cooperative LiDAR-4D Radar Fusion for 3D Object Detection with Denoising Diffusion|V2X-R：用于3D目标检测的降噪扩散协同LiDAR-4D雷达融合|Xun Huang, Jinlong Wang, Qiming Xia, Siheng Chen, Bisheng Yang, Xin Li, Cheng Wang, Chenglu Wen|<http://arxiv.org/pdf/2411.08402v4>|[[代码]](<https://github.com/ylwhxht/V2X-R.>)<br />- 问题：V2X系统，3D检测，恶劣天气，性能退化<br />- 方法：LiDAR-4D雷达融合，MDD模块，扩散模型<br />- 效果：性能提升，天气鲁棒|
|🆕 发布|Controlling Avatar Diffusion with Learnable Gaussian Embedding|控制虚拟形象扩散的可学习高斯嵌入|Xuan Gao, Jingtao Zhou, Dongyu Liu, Yuqi Zhou, Juyong Zhang|<http://arxiv.org/pdf/2503.15809v1>|[[代码]](<https://ustc3dv.github.io/Learn2Control>)<br />- 问题：3D一致性，时间连贯性，运动准确性，控制信号，数据多样性<br />- 方法：可学习高斯嵌入，参数化头部表面，大规模数据集<br />- 效果：真实性，表达性，3D一致性|
|📝 更新|Label-efficient multi-organ segmentation with a diffusion model|基于扩散模型的标签高效多器官分割|Yongzhi Huang, Fengjun Xi, Liyun Tu, Jinxin Zhu, Haseeb Hassan, Liyilei Su, Yun Peng, Jingyu Li .etc.|<http://arxiv.org/pdf/2402.15216v2>|- 问题：多器官分割，标签数据稀缺<br />- 方法：扩散模型，知识迁移，少量标签微调<br />- 效果：高DSC，低标签需求|
|📝 更新|Multi-Reward as Condition for Instruction-based Image Editing|基于指令的图像编辑的多奖励条件|Xin Gu, Ming Li, Libo Zhang, Fan Chen, Longyin Wen, Tiejian Luo, Sijie Zhu|<http://arxiv.org/pdf/2411.04713v2>|[[代码]](<https://github.com/bytedance/Multi-Reward-Editing.>)<br />- 问题：训练数据质量，指令遵循，细节保留，生成伪影<br />- 方法：多视角奖励数据，LVLM评估，多奖励框架<br />- 效果：编辑质量提升，性能优于基线|


### 生成对抗网络 (GANs)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VP-NTK: Exploring the Benefits of Visual Prompting in Differentially Private Data Synthesis|VP-NTK：探索视觉提示在差分隐私数据合成中的优势|Chia-Yi Hsu, Jia-You Chen, Yu-Lin Tsai, Chih-Hsun Lin, Pin-Yu Chen, Chia-Mu Yu, Chun-Ying Huang|<http://arxiv.org/pdf/2503.16195v1>|- 问题：DP数据合成，低效用，高分辨率图像<br />- 方法：视觉提示，DP-NTK，PEFT<br />- 效果：性能提升，高分辨率图像|
|🆕 发布|SenseExpo: Efficient Autonomous Exploration with Prediction Information from Lightweight Neural Networks|感知展：利用轻量级神经网络预测信息的有效自主探索|Haojia Gao, Haohua Que, Hoiian Au, Weihao Shan, Mingkai Liu, Yusen Qin, Lei Mu, Rong Zhao .etc.|<http://arxiv.org/pdf/2503.16000v1>|- 问题：计算开销大，环境泛化能力差，探索效率低<br />- 方法：轻量级预测网络，GANs，Transformer，FFC<br />- 效果：性能提升，时间减少|
|🆕 发布|A Survey on fMRI-based Brain Decoding for Reconstructing Multimodal Stimuli|基于fMRI的脑解码重建多模态刺激综述|Pengyu Liu, Guohua Dong, Dan Guo, Kun Li, Fengling Li, Xun Yang, Meng Wang, Xiaomin Ying|<http://arxiv.org/pdf/2503.15978v1>|[[代码]](<https://github.com/LpyNow/BrainDecodingImage.>)<br />- 问题：fMRI脑解码，多模态刺激，神经机制<br />- 方法：GANs，VAEs，Diffusion Models，多模态预训练模型<br />- 效果：信号质量提升，认知过程理解|
|📝 更新|FreeCloth: Free-form Generation Enhances Challenging Clothed Human Modeling|自由布料：自由形式生成提升挑战性着装人体建模|Hang Ye, Xiaoxuan Ma, Hai Ci, Wentao Zhu, Yizhou Wang|<http://arxiv.org/pdf/2411.19942v2>|- 问题：服装变形建模，LBS局限性，服装分割困难<br />- 方法：FreeCloth框架，区域分类，自由形式生成<br />- 效果：最佳性能，高保真，高真实感|
|🆕 发布|MiLA: Multi-view Intensive-fidelity Long-term Video Generation World Model for Autonomous Driving|MiLA：多视角高保真长期视频生成自动驾驶世界模型|Haiguang Wang, Daqi Liu, Hongwei Xie, Haisong Liu, Enhui Ma, Kaicheng Yu, Limin Wang, Bing Wang|<http://arxiv.org/pdf/2503.15875v1>|[[代码]](<https://github.com/xiaomi-mlab/mila.github.io.>)<br />- 问题：数据稀缺，视频生成，动态场景，错误累积<br />- 方法：Coarse-to-Re(fine)，时序去噪调度，联合去噪校正<br />- 效果：高保真，长视频，性能领先|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Selective Complementary Feature Fusion and Modal Feature Compression Interaction for Brain Tumor Segmentation|选择性互补特征融合与模态特征压缩交互用于脑肿瘤分割|Dong Chen, Boyue Zhao, Yi Zhang, Meng Zhao|<http://arxiv.org/pdf/2503.16149v1>|[[代码]](<https://github.com/CDmm0/CFCI-Net>)<br />- 问题：脑肿瘤分割，模态特征融合，冗余交互<br />- 方法：SCFF模块，MFCI Transformer，多模态压缩交互<br />- 效果：准确率提升，优于现有模型|
|🆕 发布|SpiLiFormer: Enhancing Spiking Transformers with Lateral Inhibition|Spiking Transformers的侧抑制增强：SpiLiFormer|Zeqi Zheng, Yanchen Huang, Yingchao Yu, Zizheng Zhu, Junfeng Tang, Zhaofei Yu, Yaochu Jin|<http://arxiv.org/pdf/2503.15986v1>|- 问题：SNNs, Transformers, 过度关注，注意力分配<br />- 方法：Lateral Inhibition, SpiLiFormer, 侧抑制机制<br />- 效果：SOTA性能，参数效率，时间效率|


## 多模态学习 (Multimodal Learning)


### 视觉语言模型 (Vision-Language Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GAEA: A Geolocation Aware Conversational Model|GAEA：一种基于地理位置感知的对话模型|Ron Campos, Ashmal Vayani, Parth Parag Kulkarni, Rohit Gupta, Aritra Dutta, Mubarak Shah|<http://arxiv.org/pdf/2503.16423v1>|- 问题：图像地理定位，对话模型，LMMs，下游任务<br />- 方法：GAEA模型，地理上下文，问答对<br />- 效果：性能提升，LLaVA-OneVision，GPT-4o|
|📝 更新|Multi-Modal Foundation Models for Computational Pathology: A Survey|多模态基础模型在计算病理学中的应用：综述|Dong Li, Guihong Wan, Xintao Wu, Xinyu Wu, Xiaohui Chen, Yi He, Christine G. Lian, Peter K. Sorger .etc.|<http://arxiv.org/pdf/2503.09091v2>|- 问题：计算病理学，多模态，基础模型<br />- 方法：视觉语言，知识图谱，基因表达<br />- 效果：综合分析，数据集，任务分类|
|📝 更新|Unifying 2D and 3D Vision-Language Understanding|统一二维和三维视觉语言理解|Ayush Jain, Alexander Swerdlow, Yuzhou Wang, Sergio Arnaud, Ada Martin, Alexander Sax, Franziska Meier, Katerina Fragkiadaki|<http://arxiv.org/pdf/2503.10745v2>|- 问题：3D数据稀缺，2D-3D融合，视觉语言理解<br />- 方法：预训练初始化，语言条件解码器，2D到3D提升<br />- 效果：SOTA性能，跨模态增强，真实评估|
|🆕 发布|Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model|广义少样本3D点云分割与视觉-语言模型|Zhaochong An, Guolei Sun, Yun Liu, Runjia Li, Junlin Han, Ender Konukoglu, Serge Belongie|<http://arxiv.org/pdf/2503.16282v1>|[[代码]](<https://github.com/ZhaochongAn/GFS-VL>)<br />- 问题：3D点云分割，少样本，泛化能力<br />- 方法：3D VLM，伪标签选择，自适应填充，混合策略<br />- 效果：泛化能力提升，基准测试|
|📝 更新|Benchmarking Large Language Models for Handwritten Text Recognition|手写文本识别大型语言模型基准测试|Giorgia Crosilla, Lukas Klic, Giovanni Colavizza|<http://arxiv.org/pdf/2503.15195v2>|- 问题：HTR，监督训练，手动标注，布局分离<br />- 方法：MLLMs，零样本识别，自动纠错<br />- 效果：私有模型优于开源，现代手写识别佳|
|🆕 发布|Chain of Functions: A Programmatic Pipeline for Fine-Grained Chart Reasoning Data|链式函数：细粒度图表推理数据编程管道|Zijian Li, Jingjing Fu, Lei Song, Jiang Bian, Jun Zhang, Rui Wang|<http://arxiv.org/pdf/2503.16260v1>|- 问题：视觉推理，数据稀缺，生成质量低<br />- 方法：Chain of Functions (CoF)，自由探索，函数链<br />- 效果：精度高，多样性，可解释性|
|📝 更新|Vision-Language Models Generate More Homogeneous Stories for Phenotypically Black Individuals|视觉-语言模型为表型黑人个体生成更同质化的故事|Messi H. J. Lee, Soyeon Jeon|<http://arxiv.org/pdf/2412.09668v2>|- 问题：VLMs，种族偏见，同质性，黑人，故事生成<br />- 方法：计算机生成图像，文本相似度，VLMs输出<br />- 效果：同质性高，性别差异，交互影响|
|📝 更新|TWIST & SCOUT: Grounding Multimodal LLM-Experts by Forget-Free Tuning|TWIST & SCOUT：通过无遗忘调优将多模态LLM-专家进行扎根|Aritra Bhowmik, Mohammad Mahdi Derakhshani, Dennis Koelma, Yuki M. Asano, Martin R. Oswald, Cees G. M. Snoek|<http://arxiv.org/pdf/2410.10491v2>|- 问题：空间感知，MLLM，视觉理解，少监督<br />- 方法：TWIST，SCOUT，忘却自由微调<br />- 效果：强性能，保留能力|
|🆕 发布|FreeFlux: Understanding and Exploiting Layer-Specific Roles in RoPE-Based MMDiT for Versatile Image Editing|FreeFlux：理解并利用基于RoPE的MMDiT中层的特定角色以实现多功能的图像编辑|Tianyi Wei, Yifan Zhou, Dongdong Chen, Xingang Pan|<http://arxiv.org/pdf/2503.16153v1>|- 问题：RoPE角色，MMDiT，依赖模式<br />- 方法：自动探测，任务特定框架，关键值注入<br />- 效果：超越现有，语义保留，无缝修改|
|🆕 发布|CLS-RL: Image Classification with Rule-Based Reinforcement Learning|基于规则强化学习的图像分类：CLS-RL|Ming Li, Shitian Zhao, Jike Zhong, Yuxiang Lai, Kaipeng Zhang|<http://arxiv.org/pdf/2503.16188v1>|- 问题：少样本学习，过拟合，分类性能<br />- 方法：规则强化学习，可验证信号，无思考CLS-RL<br />- 效果：高平均精度，泛化能力强|
|📝 更新|Bring Remote Sensing Object Detect Into Nature Language Model: Using SFT Method|将遥感目标检测引入自然语言模型：使用SFT方法|Fei Wang, Chengcheng Chen, Hongyu Chen, Yugang Chang, Weiming Zeng|<http://arxiv.org/pdf/2503.08144v2>|- 问题：遥感图像检测，VLM理解挑战<br />- 方法：SFT，自然语言描述，VLM微调<br />- 效果：有效检测，VQA能力|
|📝 更新|Defending Multimodal Backdoored Models by Repulsive Visual Prompt Tuning|防御多模态后门模型：通过排斥性视觉提示调整|Zhifang Zhang, Shuo He, Haobo Wang, Bingquan Shen, Lei Feng|<http://arxiv.org/pdf/2412.20392v2>|- 问题：多模态模型，后门攻击，安全漏洞<br />- 方法：视觉提示调整，特征排斥损失，参数微调<br />- 效果：攻击成功率降低，泛化能力强|
|📝 更新|VideoGen-of-Thought: Step-by-step generating multi-shot video with minimal manual intervention|视频思维生成：最小人工干预下逐步生成多镜头视频|Mingzhe Zheng, Yongqi Xu, Haojian Huang, Xuran Ma, Yexin Liu, Wenjie Shu, Yatian Pang, Feilong Tang .etc.|<http://arxiv.org/pdf/2503.15138v2>|- 问题：视频生成，叙事碎片，视觉不一致，过渡瑕疵<br />- 方法：动态故事线，身份感知传播，相邻潜在过渡<br />- 效果：一致性提升，手动调整减少|
|🆕 发布|MarkushGrapher: Joint Visual and Textual Recognition of Markush Structures|马克舒斯图结构联合视觉和文本识别：MarkushGrapher|Lucas Morin, Valéry Weber, Ahmed Nassar, Gerhard Ingmar Meijer, Luc Van Gool, Yawei Li, Peter Staar|<http://arxiv.org/pdf/2503.16096v1>|- 问题：Markush结构识别，多模态，化学文献分析<br />- 方法：Vision-Text-Layout编码器，合成数据生成，M2S基准<br />- 效果：超越现有模型，自动生成|
|📝 更新|DongbaMIE: A Multimodal Information Extraction Dataset for Evaluating Semantic Understanding of Dongba Pictograms|东巴MIE：用于评估东巴象形文字语义理解的跨模态信息提取数据集|Xiaojun Bi, Shuo Li, Ziyue Wang, Fuwen Luo, Weizheng Qiao, Lu Han, Ziwei Sun, Peng Li .etc.|<http://arxiv.org/pdf/2503.03644v3>|- 问题：Dongba pictographs, semantic understanding, dataset lack<br />- 方法：DongbaMIE, multimodal, semantic annotations<br />- 效果：MLLMs, challenges, recognition|
|📝 更新|ROCKET-1: Mastering Open-World Interaction with Visual-Temporal Context Prompting|ROCKET-1：通过视觉-时间上下文提示掌握开放世界交互|Shaofei Cai, Zihao Wang, Kewei Lian, Zhancun Mu, Xiaojian Ma, Anji Liu, Yitao Liang|<http://arxiv.org/pdf/2410.17856v3>|[[代码]](<https://craftjarvis.github.io/ROCKET-1.>)<br />- 问题：开放世界交互，视觉-语言模型，抽象概念，空间信息<br />- 方法：视觉-时间上下文提示，ROCKET-1，实时跟踪<br />- 效果：任务完成，性能提升76%|
|📝 更新|Vision-Language Models for Acute Tuberculosis Diagnosis: A Multimodal Approach Combining Imaging and Clinical Data|急性肺结核诊断的视觉-语言模型：结合影像和临床数据的跨模态方法|Ananya Ganapthy, Praveen Shastry, Naveen Kumarasami, Anandakumar D, Keerthana R, Mounigasri M, Varshinipriya M, Kishore Prasath Venkatesh .etc.|<http://arxiv.org/pdf/2503.14538v2>|- 问题：急性结核病诊断，影像与临床数据，多模态<br />- 方法：SIGLIP，Gemma-3b，视觉编码，解码<br />- 效果：高精度，高召回率，空间定位|
|🆕 发布|STOP: Integrated Spatial-Temporal Dynamic Prompting for Video Understanding|停止：视频理解中的集成时空动态提示|Zichen Liu, Kunlun Xu, Bing Su, Xu Zou, Yuxin Peng, Jiahuan Zhou|<http://arxiv.org/pdf/2503.15973v1>|[[代码]](<https://github.com/zhoujiahuan1991/CVPR2025-STOP.>)<br />- 问题：视频理解，时空动态，提示学习，数据稀缺<br />- 方法：时空动态提示，帧内空间提示，帧间时间提示<br />- 效果：性能提升，关键帧优先|
|🆕 发布|Beyond the Visible: Multispectral Vision-Language Learning for Earth Observation|超越可见：地球观测的多光谱视觉-语言学习|Clive Tinashe Marimo, Benedikt Blumenstiel, Maximilian Nitsche, Johannes Jakubik, Thomas Brunschwiler|<http://arxiv.org/pdf/2503.15969v1>|- 问题：光谱信息利用不足，视觉语言模型，地球观测<br />- 方法：Llama3-MS-CLIP，对比学习，大规模多光谱数据集<br />- 效果：性能提升，分类准确率，检索性能|
|🆕 发布|Don't Fight Hallucinations, Use Them: Estimating Image Realism using NLI over Atomic Facts|不要与幻觉抗争，利用它们：使用原子事实上的NLI估计图像的真实性|Elisei Rykov, Kseniia Petrushina, Kseniia Titova, Alexander Panchenko, Vasily Konovalov|<http://arxiv.org/pdf/2503.15948v1>|- 问题：图像现实主义评估，常识违背，幻觉<br />- 方法：LVLM，NLI，原子事实，现实度评分<br />- 效果：零样本，新SOTA|
|📝 更新|Preserve or Modify? Context-Aware Evaluation for Balancing Preservation and Modification in Text-Guided Image Editing|保留还是修改？文本引导图像编辑中的上下文感知评估以平衡保留与修改|Yoonjeon Kim, Soohyun Ryu, Yeonsung Jung, Hyunkoo Lee, Joowon Kim, June Yong Yang, Jaeryong Hwang, Eunho Yang|<http://arxiv.org/pdf/2410.11374v3>|[[代码]](<https://github.com/augclip/augclip_eval.>)<br />- 问题：文本引导图像编辑，评价指标，语境盲点<br />- 方法：AugCLIP，上下文感知，CLIP表示，多模态语言模型<br />- 效果：人类评估标准，性能提升|
|🆕 发布|Enhancing Zero-Shot Image Recognition in Vision-Language Models through Human-like Concept Guidance|通过人类似概念引导增强视觉-语言模型中的零样本图像识别|Hui Liu, Wenya Wang, Kecheng Chen, Jie Liu, Yibing Liu, Tiexin Qin, Peisong He, Xinghao Jiang .etc.|<http://arxiv.org/pdf/2503.15886v1>|- 问题：零样本图像识别，VLM性能不足，prompt工程，适应性差<br />- 方法：CHBR框架，贝叶斯推理，重要性采样，LLM生成概念<br />- 效果：超越现有方法，泛化能力强|
|🆕 发布|What can Off-the-Shelves Large Multi-Modal Models do for Dynamic Scene Graph Generation?|《现成的大多模态模型能为动态场景图生成做些什么？》|Xuanming Cui, Jaiminkumar Ashokbhai Bhoi, Chionh Wei Peng, Adriel Kuek, Ser Nam Lim|<http://arxiv.org/pdf/2503.15846v1>|- 问题：DSGG，精度-召回率，重要性，评估协议<br />- 方法：LMMs，简单解码器，少量微调<br />- 效果：SOTA，有效克服问题|
|🆕 发布|A Vision Centric Remote Sensing Benchmark|视觉中心遥感基准|Abduljaleel Adejumo, Faegheh Yeganli, Clifford Broni-bediako, Aoran Xiao, Naoto Yokoya, Mennatullah Siam|<http://arxiv.org/pdf/2503.15816v1>|- 问题：视觉语言任务，遥感图像，视觉推理<br />- 方法：遥感多模态视觉模式（RSMMVP）基准，CLIP盲对识别<br />- 效果：性能分析，局限性揭示|
|📝 更新|MIA-Bench: Towards Better Instruction Following Evaluation of Multimodal LLMs|MIA-Bench：迈向更优的多模态LLMs指令遵循评估|Yusu Qian, Hanrong Ye, Jean-Philippe Fauconnier, Peter Grasch, Yinfei Yang, Zhe Gan|<http://arxiv.org/pdf/2407.01509v5>|- 问题：指令遵循，多模态LLMs，评估基准<br />- 方法：MIA-Bench，图像-提示对，指令挑战<br />- 效果：性能差异，改进空间，训练数据|
|📝 更新|VideoGen-of-Thought: Step-by-step generating multi-shot video with minimal manual intervention|视频思维生成：最小人工干预下逐步生成多镜头视频|Mingzhe Zheng, Yongqi Xu, Haojian Huang, Xuran Ma, Yexin Liu, Wenjie Shu, Yatian Pang, Feilong Tang .etc.|<http://arxiv.org/pdf/2412.02259v2>|- 问题：视频生成，叙事碎片，视觉不一致，过渡瑕疵<br />- 方法：动态故事线，身份感知跨帧传播，相邻潜在过渡<br />- 效果：一致性提升，手动调整减少|
|🆕 发布|AutoDrive-QA- Automated Generation of Multiple-Choice Questions for Autonomous Driving Datasets Using Large Vision-Language Models|自动生成自动驾驶数据集多选题的视觉-语言大模型AutoDrive-QA|Boshra Khalili, Andrew W. Smyth|<http://arxiv.org/pdf/2503.15778v1>|- 问题：自动驾驶数据集评估，主观性，可靠性<br />- 方法：自动生成多选题，LLMs，错误模式<br />- 效果：客观评估，模型泛化，GPT-4V领先|


### 多模态融合 (Multimodal Fusion)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|M3: 3D-Spatial MultiModal Memory|M3：三维空间多模态记忆|Xueyan Zou, Yuchen Song, Ri-Zhao Qiu, Xuanbin Peng, Jianglong Ye, Sifei Liu, Xiaolong Wang|<http://arxiv.org/pdf/2503.16413v1>|- 问题：特征压缩，信息丢失，计算限制<br />- 方法：3D Gaussian Splatting，多模态记忆，注意力机制<br />- 效果：效率提升，应用验证|
|📝 更新|EPAM-Net: An Efficient Pose-driven Attention-guided Multimodal Network for Video Action Recognition|EPAM-Net：一种高效的姿态驱动注意力引导的多模态视频动作识别网络|Ahmed Abdelkawy, Asem Ali, Aly Farag|<http://arxiv.org/pdf/2408.05421v2>|[[代码]](<https://github.com/ahmed-nady/Multimodal-Action-Recognition.>)<br />- 问题：计算密集，实时应用受限<br />- 方法：X-ShiftNet，TSM，注意力引导<br />- 效果：FLOPs减少，参数减少，性能提升|
|🆕 发布|Disentangled and Interpretable Multimodal Attention Fusion for Cancer Survival Prediction|解耦且可解释的多模态注意力融合用于癌症生存预测|Aniek Eijpe, Soufyan Lakbir, Melis Erdal Cesur, Sara P. Oliveira, Sanne Abeln, Wilson Silva|<http://arxiv.org/pdf/2503.16069v1>|- 问题：癌症生存预测，多模态融合，可解释性<br />- 方法：解耦注意力融合，距离相关性损失，Shapley值解释<br />- 效果：性能提升，解耦度提高|
|🆕 发布|V-NAW: Video-based Noise-aware Adaptive Weighting for Facial Expression Recognition|基于视频的噪声感知自适应加权面部表情识别|JunGyu Lee, Kunyoung Lee, Haesol Park, Ig-Jae Kim, Gi Pyo Nam|<http://arxiv.org/pdf/2503.15970v1>|- 问题：面部表情识别，标签模糊，类别不平衡<br />- 方法：视频噪声感知，自适应加权，帧间冗余减少<br />- 效果：性能提升，过拟合减少|
|📝 更新|CREMA: Generalizable and Efficient Video-Language Reasoning via Multimodal Modular Fusion|CREMA：通过多模态模块化融合实现通用且高效的视频-语言推理|Shoubin Yu, Jaehong Yoon, Mohit Bansal|<http://arxiv.org/pdf/2402.05889v4>|- 问题：灵活性，效率，模态融合，参数更新<br />- 方法：模态融合框架，传感器利用，参数高效模块<br />- 效果：性能提升，参数减少|


### 跨模态对齐 (Cross-modal Alignment)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UniSync: A Unified Framework for Audio-Visual Synchronization|统一音频-视觉同步框架：UniSync|Tao Feng, Yifan Xie, Xun Guan, Jiyuan Song, Zhou Liu, Fei Ma, Fei Yu|<http://arxiv.org/pdf/2503.16357v1>|- 问题：音频-视频同步，代表性不足，学习策略欠佳<br />- 方法：嵌入相似度，兼容性，对比学习，跨说话人<br />- 效果：性能提升，多样性，同步质量|
|🆕 发布|Do image and video quality metrics model low-level human vision?|图像和视频质量度量是否模拟了低级人类视觉？|Dounia Hammou, Yancheng Cai, Pavan Madhusudanarao, Christos G. Bampis, Rafał K. Mantiuk|<http://arxiv.org/pdf/2503.16264v1>|- 问题：质量指标，低级视觉，感知模型<br />- 方法：测试，对比敏感度，对比掩蔽<br />- 效果：性能分析，SSIM，MS-SSIM|
|🆕 发布|PromptHash: Affinity-Prompted Collaborative Cross-Modal Learning for Adaptive Hashing Retrieval|PromptHash：基于亲和提示的协同跨模态学习自适应哈希检索|Qiang Zou, Shuli Cheng, Jiayi Chen|<http://arxiv.org/pdf/2503.16064v1>|[[代码]](<https://github.com/ShiShuMo/PromptHash.>)<br />- 问题：语义保留，上下文完整性，信息冗余<br />- 方法：亲和提示学习，自适应门控融合，层次对比学习<br />- 效果：性能提升，检索准确率提高|
|📝 更新|EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotions|EMOVA：赋予语言模型看见、听见和表达生动情感的能力|Kai Chen, Yunhao Gou, Runhui Huang, Zhili Liu, Daxin Tan, Jing Xu, Chunwei Wang, Yi Zhu .etc.|<http://arxiv.org/pdf/2409.18042v4>|- 问题：多模态感知，生成，公开数据挑战<br />- 方法：EMOVA模型，语义声学解耦，风格模块<br />- 效果：SOTA性能，多模态对话|
|🆕 发布|CausalCLIPSeg: Unlocking CLIP's Potential in Referring Medical Image Segmentation with Causal Intervention|因果CLIPSeg：利用因果干预释放CLIP在医学图像分割中的潜力|Yaxiong Chen, Minghong Wei, Zixuan Zheng, Jingliang Hu, Yilei Shi, Shengwu Xiong, Xiao Xiang Zhu, Lichao Mou|<http://arxiv.org/pdf/2503.15949v1>|[[代码]](<https://github.com/WUTCM-Lab/CausalCLIPSeg.>)<br />- 问题：医学图像分割，视觉-文本对齐，因果干预<br />- 方法：CLIP，跨模态解码，因果干预模块<br />- 效果：性能领先，文本-像素对齐|
|🆕 发布|UniCrossAdapter: Multimodal Adaptation of CLIP for Radiology Report Generation|UniCrossAdapter：基于CLIP的放射报告生成多模态自适应|Yaxiong Chen, Chuang Du, Chunlei Li, Jingliang Hu, Yilei Shi, Shengwu Xiong, Xiao Xiang Zhu, Lichao Mou|<http://arxiv.org/pdf/2503.15940v1>|[[代码]](<https://github.com/chauncey-tow/MRG-CLIP.>)<br />- 问题：放射报告生成，数据稀缺，跨模态语义<br />- 方法：CLIP迁移，UniCrossAdapter，轻量适配模块<br />- 效果：状态艺术，语义知识利用|


## 目标检测识别 (Object Detection & Recognition)


### 三维检测 (3D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SynCity: Training-Free Generation of 3D Worlds|SynCity：无需训练的3D世界生成|Paul Engstler, Aleksandar Shtedritski, Iro Laina, Christian Rupprecht, Andrea Vedaldi|<http://arxiv.org/pdf/2503.16420v1>|- 问题：3D世界生成，文本描述，无监督<br />- 方法：3D生成模型，2D图像生成，拼接策略<br />- 效果：高质量，大场景，细节丰富|
|🆕 发布|SA-Occ: Satellite-Assisted 3D Occupancy Prediction in Real World|卫星辅助真实世界3D占用预测|Chen Chen, Zhirui Wang, Taowei Sheng, Yi Jiang, Yundu Li, Peirui Cheng, Luning Zhang, Kaiqiang Chen .etc.|<http://arxiv.org/pdf/2503.16399v1>|[[代码]](<https://github.com/chenchen235/SA-Occ.>)<br />- 问题：3D占用预测，街景图像，卫星图像，精度限制<br />- 方法：卫星辅助，动态解耦融合，3D投影引导，均匀采样对齐<br />- 效果：性能提升，低延迟|
|🆕 发布|Uncertainty Meets Diversity: A Comprehensive Active Learning Framework for Indoor 3D Object Detection|不确定性遇见多样性：室内3D目标检测的全面主动学习框架|Jiangyi Wang, Na Zhao|<http://arxiv.org/pdf/2503.16125v1>|- 问题：室内3D检测，标注负担重，数据挑战大<br />- 方法：不确定性，多样性，CAP bank，原型分配<br />- 效果：性能提升，标注减少|
|🆕 发布|PoseTraj: Pose-Aware Trajectory Control in Video Diffusion|姿态轨迹：视频扩散中的姿态感知轨迹控制|Longbin Ji, Lei Zhong, Pengfei Wei, Changjian Li|<http://arxiv.org/pdf/2503.16068v1>|- 问题：3D理解，运动生成，旋转轨迹<br />- 方法：PoseTraj，预训练框架，3D边界框<br />- 效果：3D对齐，轨迹精度，视频质量|
|📝 更新|Beyond Role-Based Surgical Domain Modeling: Generalizable Re-Identification in the Operating Room|超越基于角色的手术室领域建模：手术室中的可泛化重识别|Tony Danjun Wang, Lennart Bastian, Tobias Czempiel, Christian Heiliger, Nassir Navab|<http://arxiv.org/pdf/2503.13028v2>|- 问题：手术角色模型，团队熟悉度，个体差异，手术结果<br />- 方法：人员中心建模，3D点云编码，可迁移识别框架<br />- 效果：准确率提升，人员跟踪精度提高|
|🆕 发布|GraspCoT: Integrating Physical Property Reasoning for 6-DoF Grasping under Flexible Language Instructions|抓取CoT：在灵活语言指令下整合物理属性推理的6自由度抓取|Xiaomeng Chu, Jiajun Deng, Guoliang You, Wei Liu, Xingchen Li, Jianmin Ji, Yanyong Zhang|<http://arxiv.org/pdf/2503.16013v1>|- 问题：6-DoF抓取，物理属性，语言指令<br />- 方法：CoT推理，QA模板，多模态LLM架构<br />- 效果：性能优越，实用性验证|
|📝 更新|Odd-One-Out: Anomaly Detection by Comparing with Neighbors|异常检测：与邻居比较的“奇数”方法|Ankan Bhunia, Changjian Li, Hakan Bilen|<http://arxiv.org/pdf/2406.20099v3>|- 问题：异常检测，场景特定，邻居比较<br />- 方法：3D模型，部分感知，跨实例比较<br />- 效果：新基准，全面分析|
|📝 更新|Synthetic Prior for Few-Shot Drivable Head Avatar Inversion|合成先验用于少量样本可驾驶头部头像逆转换|Wojciech Zielonka, Stephan J. Garbin, Alexandros Lattas, George Kopanas, Paulo Gotardo, Thabo Beeler, Justus Thies, Timo Bolkart|<http://arxiv.org/pdf/2501.06903v2>|- 问题：少样本，可驱动，头像逆生成，数据限制，泛化能力<br />- 方法：合成先验，3D生成网络，Gaussian splatting，卷积编码器-解码器<br />- 效果：泛化提升，视图合成，表情合成|
|📝 更新|Multi-View Pose-Agnostic Change Localization with Zero Labels|多视角姿态无关变化定位，无需零标签|Chamuditha Jayanga Galappaththige, Jason Lai, Lloyd Windrim, Donald Dansereau, Niko Suenderhauf, Dimity Miller|<http://arxiv.org/pdf/2412.03911v2>|- 问题：多视角，变化检测，无标签<br />- 方法：3DGS表示，多视角信息整合，变化通道学习<br />- 效果：性能提升，F1分数改善|
|📝 更新|Generative Human Geometry Distribution|生成人类几何分布|Xiangjun Tang, Biao Zhang, Peter Wonka|<http://arxiv.org/pdf/2503.01448v2>|- 问题：真实人体几何生成，细节保留，交互建模<br />- 方法：3D人体生成框架，几何分布建模<br />- 效果：高保真，几何精度|
|🆕 发布|Computation-Efficient and Recognition-Friendly 3D Point Cloud Privacy Protection|计算高效且识别友好的3D点云隐私保护|Haotian Ma, Lin Gu, Siyi Wu, Yingying Zhu|<http://arxiv.org/pdf/2503.15818v1>|- 问题：3D点云隐私，几何结构，隐私保护<br />- 方法：PointFlowGMM，流模型，角度相似度损失<br />- 效果：隐私保护，模型小型化，识别性能保持|


### 二维检测 (2D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Closer to Ground Truth: Realistic Shape and Appearance Labeled Data Generation for Unsupervised Underwater Image Segmentation|更接近真实：用于无监督水下图像分割的逼真形状和外观标注数据生成|Andrei Jelea, Ahmed Nabil Belbachir, Marius Leordeanu|<http://arxiv.org/pdf/2503.16051v1>|- 问题：水下图像分割，标注数据，鱼分割<br />- 方法：无监督分割，合成数据生成，形状变换<br />- 效果：性能提升，DeepSalmon数据集|
|📝 更新|Information-Preserved Blending Method for Forward-Looking Sonar Mosaicing in Non-Ideal System Configuration|信息保留的前视声纳镶嵌方法在非理想系统配置中的应用|Jiayi Su, Xingbin Tu, Fengzhong Qu, Yan Wei|<http://arxiv.org/pdf/2212.05216v2>|- 问题：FLS mosaicing，信息丢失，非理想系统<br />- 方法：LST-SW，GVM，信息保留<br />- 效果：细节保留，质量提升|
|📝 更新|HS-FPN: High Frequency and Spatial Perception FPN for Tiny Object Detection|HS-FPN：用于微小目标检测的高频和空间感知FPN|Zican Shi, Jing Hu, Jie Ren, Hengkang Ye, Xuyang Yuan, Yan Ouyang, Jia He, Bo Ji .etc.|<http://arxiv.org/pdf/2412.10116v3>|- 问题：FPN，小物体检测，特征不足，空间感知<br />- 方法：HFP，SDP，高频感知，空间依赖<br />- 效果：AI-TOD，性能提升|
|🆕 发布|TruthLens: Explainable DeepFake Detection for Face Manipulated and Fully Synthetic Data|真实镜：针对人脸操纵和全合成数据的可解释深度伪造检测|Rohit Kundu, Athula Balachandran, Amit K. Roy-Chowdhury|<http://arxiv.org/pdf/2503.15867v1>|- 问题：DeepFake检测，可解释性，分类限制<br />- 方法：TruthLens框架，多模态LGM，视觉模型<br />- 效果：检测精度提升，解释性增强|
|📝 更新|D&M: Enriching E-commerce Videos with Sound Effects by Key Moment Detection and SFX Matching|D&M：通过关键时刻检测和音效匹配丰富电子商务视频|Jingyu Liu, Minquan Wang, Ye Ma, Bo Wang, Aozhu Chen, Quan Chen, Peng Jiang, Xirong Li|<http://arxiv.org/pdf/2408.13226v3>|- 问题：电商视频，关键帧检测，音效匹配，用户体验<br />- 方法：D&M模型，关键帧检测，音效匹配<br />- 效果：性能优越，用户体验提升|


## 时序理解 (Temporal Understanding)


### 视频预测 (Video Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Words in Motion: Extracting Interpretable Control Vectors for Motion Transformers|动态中的词语：提取运动变换器的可解释控制向量|Omer Sahin Tas, Royden Wagner|<http://arxiv.org/pdf/2406.11624v4>|- 问题：可解释性，隐藏状态，运动预测<br />- 方法：线性探测，控制向量，稀疏自编码器<br />- 效果：高准确性，可解释性，零样本泛化|


### 时序分析 (Temporal Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Advancing Time Series Wildfire Spread Prediction: Modeling Improvements and the WSTS+ Benchmark|推进时间序列野火蔓延预测：模型改进与WSTS+基准|Saad Lahrichi, Jake Bova, Jesse Johnson, Jordan Malof|<http://arxiv.org/pdf/2502.12003v2>|- 问题：wildfire spread prediction, time series data<br />- 方法：modeling improvements, WSTS+, benchmark<br />- 效果：SOTA accuracy, expanded data|


## 三维重建 (3D Reconstruction)


### 多视图重建 (Multi-view Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dynamic Point Maps: A Versatile Representation for Dynamic 3D Reconstruction|动态点图：动态3D重建的多用途表示|Edgar Sucar, Zihang Lai, Eldar Insafutdinov, Andrea Vedaldi|<http://arxiv.org/pdf/2503.16318v1>|- 问题：动态场景，3D重建，点云，运动分割<br />- 方法：动态点图，4D任务，网络回归<br />- 效果：SOTA性能，视频深度预测|
|📝 更新|MTGS: Multi-Traversal Gaussian Splatting|多遍历高斯分层渲染|Tianyu Li, Yihang Qiu, Zhenhua Wu, Carl Lindström, Peng Su, Matthias Nießner, Hongyang Li|<http://arxiv.org/pdf/2503.12552v2>|- 问题：多遍历数据，场景重建，动态物体，外观变化<br />- 方法：MTGS，动态场景图，颜色校正，球谐系数<br />- 效果：LPIPS提升，几何精度提升|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Revealing Key Details to See Differences: A Novel Prototypical Perspective for Skeleton-based Action Recognition|揭示关键细节以观察差异：基于骨架的动作识别的一种新颖原型视角|Hongda Liu, Yunfan Liu, Min Ren, Hao Wang, Yunlong Wang, Zhenan Sun|<http://arxiv.org/pdf/2411.18941v2>|[[代码]](<https://github.com/firework8/ProtoGCN.>)<br />- 问题：动作识别，相似动作区分，骨骼表示，细节缺乏<br />- 方法：ProtoGCN，图卷积网络，原型表示<br />- 效果：性能提升，基准数据集|
|📝 更新|How accurate is mechanobiology? A statistical test of cell force|机械生物学有多准确？细胞力的统计检验|Aleix Boquet-Pujadas|<http://arxiv.org/pdf/2412.18406v2>|- 问题：机械生物学，测量误差，统计测试<br />- 方法：重建框架，假设检验<br />- 效果：公开问题，提出解决方案|


### 单目重建 (Monocular Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Monocular Vision to Autonomous Action: Guiding Tumor Resection via 3D Reconstruction|从单目视觉到自主行动：通过3D重建引导肿瘤切除|Ayberk Acar, Mariana Smith, Lidia Al-Zogbi, Tanner Watts, Fangjie Li, Hao Li, Nural Yilmaz, Paul Maria Scheikl .etc.|<http://arxiv.org/pdf/2503.16263v1>|- 问题：手术导航，深度相机，单目相机，3D重建<br />- 方法：RGB图像，3D映射，结构光运动算法<br />- 效果：性能可比，超越RGB-D，手术机器人自主|
|🆕 发布|Reconstructing In-the-Wild Open-Vocabulary Human-Object Interactions|在野外重建开放词汇的人-物体交互|Boran Wen, Dingbang Huang, Zichen Zhang, Jiahong Zhou, Jianbin Deng, Jingyu Gong, Yulong Chen, Lizhuang Ma .etc.|<http://arxiv.org/pdf/2503.15898v1>|[[代码]](<https://wenboran2002.github.io/3dhoi.>)<br />- 问题：单图HOI重建，数据缺乏，泛化能力差<br />- 方法：Open3DHOI数据集，Gaussian-HOI优化器，新任务<br />- 效果：开放词汇，空间交互，理解能力提升|
|🆕 发布|Frequency Enhancement for Image Demosaicking|图像去马赛克频率增强|Jingyun Liu, Daiqin Yang, Zhenzhong Chen|<http://arxiv.org/pdf/2503.15800v1>|[[代码]](<https://github.com/VelvetReverie/DFENet-demosaicking.>)<br />- 问题：高频纹理恢复，性能有限<br />- 方法：DFENet，频率选择，多路径处理<br />- 效果：性能优越，新数据集|


### 神经隐式重建 (Neural Implicit Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Towards Lossless Implicit Neural Representation via Bit Plane Decomposition|向无损隐式神经网络表示通过位平面分解|Woo Kyoung Han, Byeonghun Lee, Hyunmin Cho, Sunghoon Im, Kyong Hwan Jin|<http://arxiv.org/pdf/2502.21001v2>|[[代码]](<https://github.com/WooKyoungHan/LosslessINR>)<br />- 问题：INR模型大小，位精度，收敛速度<br />- 方法：位平面分解，无损失表示，位偏置<br />- 效果：快速收敛，无损压缩|
|📝 更新|PC-Talk: Precise Facial Animation Control for Audio-Driven Talking Face Generation|PC-Talk：音频驱动说话人脸生成的精确面部动画控制|Baiqin Wang, Xiangyu Zhu, Fan Shen, Hao Xu, Zhen Lei|<http://arxiv.org/pdf/2503.14295v2>|- 问题：面部动画控制不足，唇音同步，情感表达<br />- 方法：PC-Talk框架，关键点变形，唇音对齐，情感控制<br />- 效果：精确控制，多样性，性能领先|
|📝 更新|SDF-TopoNet: A Two-Stage Framework for Tubular Structure Segmentation via SDF Pre-training and Topology-Aware Fine-Tuning|SDF-TopoNet：基于SDF预训练和拓扑感知微调的管状结构分割两阶段框架|Siyi Wu, Leyi Zhao, Haotian Ma, Xinyuan Song|<http://arxiv.org/pdf/2503.14523v2>|- 问题：拓扑一致性，计算成本高，像素精度低<br />- 方法：SDF预训练，拓扑感知微调，动态适配器<br />- 效果：拓扑精度高，训练效率高|
|🆕 发布|OffsetOPT: Explicit Surface Reconstruction without Normals|OffsetOPT：无需法线的显式表面重建|Huan Lei|<http://arxiv.org/pdf/2503.15763v1>|- 问题：表面重建，正常值需求，隐式表示<br />- 方法：OffsetOPT，神经网络，点云<br />- 效果：无正常值，表面精度高|


## 神经渲染 (Neural Rendering)


### 可控渲染 (Controllable Rendering)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bézier Splatting for Fast and Differentiable Vector Graphics|贝塞尔散点绘制：快速且可微分的矢量图形|Xi Liu, Chaoyi Zhou, Nanxuan Zhao, Siyu Huang|<http://arxiv.org/pdf/2503.16424v1>|- 问题：优化，渲染，计算成本，矢量图形<br />- 方法：贝塞尔曲线，贝塞尔撒点，可微分<br />- 效果：速度提升，质量改善|
|🆕 发布|Bokehlicious: Photorealistic Bokeh Rendering with Controllable Apertures|《博克丽奥：可控光圈下的逼真散景渲染》|Tim Seizinger, Florin-Alexandru Vasluianu, Marcos V. Conde, Radu Timofte|<http://arxiv.org/pdf/2503.16067v1>|[[代码]](<https://github.com/TimSeizinger/Bokehlicious>)<br />- 问题：Bokeh渲染，真实感，数据缺乏<br />- 方法：Aperture-Aware Attention，RealBokeh数据集<br />- 效果：SOTA超越，计算成本低，泛化能力强|
|📝 更新|Gaussian Eigen Models for Human Heads|高斯特征模型在人头识别中的应用|Wojciech Zielonka, Timo Bolkart, Thabo Beeler, Justus Thies|<http://arxiv.org/pdf/2407.04545v3>|- 问题：个性化头像，轻量化，高保真<br />- 方法：Gaussian Eigen Models，3D Gaussian primitives，CNN-based distillation<br />- 效果：高质量，低资源，泛化能力强|
|🆕 发布|SaMam: Style-aware State Space Model for Arbitrary Image Style Transfer|SaMam：任意图像风格迁移的感知风格状态空间模型|Hongda Liu, Longguang Wang, Ye Zhang, Ziru Yu, Yulan Guo|<http://arxiv.org/pdf/2503.15934v1>|- 问题：风格迁移，计算复杂度，局部遗忘，通道冗余，空间不连续<br />- 方法：Mamba模型，风格感知解码器，局部增强，之字形扫描<br />- 效果：性能优于，准确性，效率|


### 神经辐射场 (Neural Radiance Fields)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|1000+ FPS 4D Gaussian Splatting for Dynamic Scene Rendering|1000+ FPS 动态场景渲染的4D高斯分层|Yuheng Yuan, Qiuhong Shen, Xingyi Yang, Xinchao Wang|<http://arxiv.org/pdf/2503.16422v1>|- 问题：4DGS，存储，渲染速度，时间冗余<br />- 方法：4DGS-1K，时空变化分数，活动掩码<br />- 效果：存储减少，速度提升，质量相当|
|🆕 发布|Gaussian Graph Network: Learning Efficient and Generalizable Gaussian Representations from Multi-view Images|高斯图网络：从多视角图像中学习高效且可泛化的高斯表示|Shengjun Zhang, Xin Fei, Fangfu Liu, Haixu Song, Yueqi Duan|<http://arxiv.org/pdf/2503.16338v1>|- 问题：多视角图像，Gaussian Splatting，表示，关系，优化<br />- 方法：Gaussian Graph Network，Gaussian Graphs，消息传递，特征融合，Gaussian pooling<br />- 效果：效率高，泛化好，图像质量好|
|🆕 发布|OccluGaussian: Occlusion-Aware Gaussian Splatting for Large Scene Reconstruction and Rendering|遮挡感知高斯分层：用于大场景重建和渲染|Shiyong Liu, Xiao Tang, Zhihao Li, Yingfan He, Chongjie Ye, Jianzhuang Liu, Binxiao Huang, Shunbo Zhou .etc.|<http://arxiv.org/pdf/2503.16177v1>|- 问题：场景重建，遮挡，低相关性，渲染速度慢<br />- 方法：遮挡感知场景划分，区域渲染，高相关性<br />- 效果：重建结果优，渲染速度快|
|📝 更新|GSplatLoc: Grounding Keypoint Descriptors into 3D Gaussian Splatting for Improved Visual Localization|GSplatLoc：将关键点描述符嵌入到3D高斯散布中以改进视觉定位|Gennady Sidorov, Malik Mohrat, Denis Gridusov, Ruslan Rakhimov, Sergey Kolyubin|<http://arxiv.org/pdf/2409.16502v3>|- 问题：视觉定位，优化复杂，精度有限<br />- 方法：3D高斯分层，XFeat特征提取，两阶段流程<br />- 效果：性能提升，NeRFMatch，PNeRFLoc|
|🆕 发布|Automating 3D Dataset Generation with Neural Radiance Fields|标题翻译：利用神经辐射场自动化3D数据集生成|P. Schulz, T. Hempel, A. Al-Hamadi|<http://arxiv.org/pdf/2503.15997v1>|- 问题：3D数据集生成，标注困难，规模小<br />- 方法：神经辐射场，自动生成，3D模型<br />- 效果：高效，自动化，性能强|
|🆕 发布|Enhancing Close-up Novel View Synthesis via Pseudo-labeling|通过伪标签增强近距离新颖视图合成|Jiatong Xia, Libo Sun, Lingqiao Liu|<http://arxiv.org/pdf/2503.15908v1>|- 问题：近距视图合成，数据缺乏，伪标签<br />- 方法：伪标签学习，多视角监督，新数据集<br />- 效果：图像质量提升，合成效果佳|
|🆕 发布|VideoRFSplat: Direct Scene-Level Text-to-3D Gaussian Splatting Generation with Flexible Pose and Multi-View Joint Modeling|视频RFSplat：具有灵活姿态和多视图联合建模的直接场景级文本到3D高斯分层生成|Hyojun Go, Byeongjun Park, Hyelin Nam, Byung-Hoon Kim, Hyungjin Chung, Changick Kim|<http://arxiv.org/pdf/2503.15855v1>|- 问题：2D模型扩展，模态间隙，训练不稳定<br />- 方法：双流架构，异步采样，联合建模<br />- 效果：无后处理，结果优越|
|🆕 发布|BARD-GS: Blur-Aware Reconstruction of Dynamic Scenes via Gaussian Splatting|基于高斯碎片的模糊感知动态场景重建：BARD-GS|Yiren Lu, Yunlai Zhou, Disheng Liu, Tuo Liang, Yu Yin|<http://arxiv.org/pdf/2503.15835v1>|- 问题：动态场景重建，图像模糊，相机姿态不精确<br />- 方法：相机运动去模糊，物体运动去模糊，Gaussian Splatting<br />- 效果：高质量重建，性能优于现有方法|


## 定位与映射 (Localization & Mapping)


### 位姿估计 (Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Jointly Understand Your Command and Intention:Reciprocal Co-Evolution between Scene-Aware 3D Human Motion Synthesis and Analysis|共同理解您的指令和意图：场景感知3D人体运动合成与分析的相互协同进化|Xuehao Gao, Yang Yang, Shaoyi Du, Guo-Jun Qi, Junwei Han|<http://arxiv.org/pdf/2503.00371v3>|- 问题：场景感知，人运动合成，分析，多模态理解<br />- 方法：Co-Evolving Synthesis-Analysis，文本到人运动合成，级联生成策略<br />- 效果：多样性提升，鲁棒性增强|
|🆕 发布|Probabilistic Prompt Distribution Learning for Animal Pose Estimation|动物姿态估计的概率提示分布学习|Jiyong Rao, Brian Nlong Zhao, Yu Wang|<http://arxiv.org/pdf/2503.16120v1>|[[代码]](<https://github.com/Raojiyong/PPAP.>)<br />- 问题：动物姿态估计，视觉多样性，不确定性<br />- 方法：概率提示学习，跨模态适应，多样性损失<br />- 效果：性能提升，跨物种泛化|
|🆕 发布|Hybrid-Level Instruction Injection for Video Token Compression in Multi-modal Large Language Models|混合级指令注入用于多模态大型语言模型中的视频令牌压缩|Zhihang Liu, Chen-Wei Xie, Pandeng Li, Liming Zhao, Longxiang Tang, Yun Zheng, Chuanbin Liu, Hongtao Xie|<http://arxiv.org/pdf/2503.16036v1>|[[代码]](<https://github.com/lntzm/HICom.>)<br />- 问题：视频压缩，信息损失，计算负担<br />- 方法：指令注入，局部全局压缩，注意力机制<br />- 效果：性能提升，压缩率提高|
|📝 更新|GIVEPose: Gradual Intra-class Variation Elimination for RGB-based Category-Level Object Pose Estimation|GIVEPose：基于RGB的类别级目标姿态估计的渐进式类内变异消除|Zinqin Huang, Gu Wang, Chenyangguang Zhang, Ruida Zhang, Xiu Li, Xiangyang Ji|<http://arxiv.org/pdf/2503.15110v2>|[[代码]](<https://github.com/ziqin-h/GIVEPose.>)<br />- 问题：RGBD依赖，NOCS不足，类内变异性<br />- 方法：IVFC图，渐变消除，类别级模型<br />- 效果：性能提升，优于现有方法|
|📝 更新|STEP: Simultaneous Tracking and Estimation of Pose for Animals and Humans|动物和人类姿态的同步跟踪与估计：STEP|Shashikant Verma, Harish Katti, Soumyaratna Debnath, Yamuna Swamy, Shanmuganathan Raman|<http://arxiv.org/pdf/2503.13344v2>|- 问题：多物种姿态估计，跟踪，效率<br />- 方法：Transformer，GMSP，OMRA，无目标检测<br />- 效果：高效，准确|
|📝 更新|Distilling 3D distinctive local descriptors for 6D pose estimation|提炼用于6D姿态估计的3D独特局部描述符|Amir Hamza, Andrea Caraffa, Davide Boscaini, Fabio Poiesi|<http://arxiv.org/pdf/2503.15106v2>|[[代码]](<https://tev-fbk.github.io/dGeDi>)<br />- 问题：3D描述符，6D姿态估计，效率低<br />- 方法：知识蒸馏，学生模型，损失函数<br />- 效果：效率提升，性能竞争|
|📝 更新|CMMLoc: Advancing Text-to-PointCloud Localization with Cauchy-Mixture-Model Based Framework|CMMLoc：基于柯西混合模型框架推进文本到点云定位|Yanlong Xu, Haoxuan Qu, Jun Liu, Wenxiao Zhang, Xun Yang|<http://arxiv.org/pdf/2503.02593v3>|[[代码]](<https://github.com/kevin301342/CMMLoc.>)<br />- 问题：文本描述，点云定位，部分相关，不确定性<br />- 方法：Cauchy-Mixture-Model，空间融合，方向集成<br />- 效果：KITTI360Pose，最先进|


### 语义建图 (Semantic Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding|ARKit LabelMaker：室内3D场景理解的新尺度|Guangda Ji, Silvan Weder, Francis Engelmann, Marc Pollefeys, Hermann Blum|<http://arxiv.org/pdf/2410.13924v2>|- 问题：3D视觉，数据量，模型规模<br />- 方法：ARKit LabelMaker，大规模数据集，自动标注<br />- 效果：精度提升，状态艺术|
|🆕 发布|Learning 3D Scene Analogies with Neural Contextual Scene Maps|利用神经上下文场景图学习3D场景类比|Junho Kim, Gwangtak Bae, Eun Sun Lee, Young Min Kim|<http://arxiv.org/pdf/2503.15897v1>|- 问题：场景理解，3D环境，知识迁移<br />- 方法：3D场景类比，神经上下文场景图<br />- 效果：场景类比识别，轨迹转移|
|📝 更新|AirRoom: Objects Matter in Room Reidentification|AirRoom：在室内重识别中，物体很重要|Runmao Yao, Yi Du, Zhuoqun Chen, Haoze Zheng, Chen Wang|<http://arxiv.org/pdf/2503.01130v2>|- 问题：室内场景识别，物体信息忽视，复杂环境<br />- 方法：对象感知，多级信息整合，粗细粒度检索<br />- 效果：性能提升，灵活可替代，鲁棒性|
|🆕 发布|GraPLUS: Graph-based Placement Using Semantics for Image Composition|基于语义的图结构图像合成放置方法：GraPLUS|Mir Mohammad Khaleghi, Mehran Safayani, Abdolreza Mirzaei|<http://arxiv.org/pdf/2503.15761v1>|- 问题：图像合成，物体放置，语义理解<br />- 方法：场景图，GPT-2，图神经网络<br />- 效果：准确率92.1%，FID 28.83|


### 视觉SLAM (Visual SLAM)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MG-SLAM: Structure Gaussian Splatting SLAM with Manhattan World Hypothesis|MG-SLAM：基于曼哈顿世界假设的结构高斯喷溅SLAM|Shuhong Liu, Tianchen Deng, Heng Zhou, Liuzhuozheng Li, Hongyu Wang, Danwei Wang, Mingrui Li|<http://arxiv.org/pdf/2405.20031v3>|- 问题：SLAM重建，室内环境，几何不完整<br />- 方法：Manhattan World假设，结构线融合，几何插值<br />- 效果：效率提升，精度提高|
|📝 更新|Spatiotemporal Multi-Camera Calibration using Freely Moving People|时空多摄像头标定：利用自由移动的人|Sang-Eun Lee, Ko Nishino, Shohei Nobuhara|<http://arxiv.org/pdf/2502.12546v2>|- 问题：多相机标定，匹配，统一框架<br />- 方法：3D人体姿态，单位球面，软分配，非线性优化<br />- 效果：无标记标定，准确性高|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MASH-VLM: Mitigating Action-Scene Hallucination in Video-LLMs through Disentangled Spatial-Temporal Representations|MASH-VLM：通过解耦时空表示减轻视频LLMs中的动作场景幻觉|Kyungho Bae, Jinhyung Kim, Sihaeng Lee, Soonyoung Lee, Gunhee Lee, Jinwoo Choi|<http://arxiv.org/pdf/2503.15871v1>|- 问题：动作场景幻觉，视频LLMs，空间时间特征混合<br />- 方法：DST-attention，Harmonic-RoPE，解耦表示<br />- 效果：UNSCENE基准，最先进结果|


## 自监督学习 (Self-supervised Learning)


### 一致性学习 (Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SV4D 2.0: Enhancing Spatio-Temporal Consistency in Multi-View Video Diffusion for High-Quality 4D Generation|SV4D 2.0：提升多视图视频扩散中的时空一致性以实现高质量4D生成|Chun-Han Yao, Yiming Xie, Vikram Voleti, Huaizu Jiang, Varun Jampani|<http://arxiv.org/pdf/2503.16396v1>|- 问题：多视图视频扩散，时空一致性，高质4D生成<br />- 方法：网络架构改进，数据增强，渐进式训练，4D优化<br />- 效果：质量提升，时空一致性增强|
|🆕 发布|Zero-1-to-A: Zero-Shot One Image to Animatable Head Avatars Using Video Diffusion|零到一至A：基于视频扩散的零样本单图到可动头像|Zhou Zhenglin, Ma Fan, Fan Hehe, Chua Tat-Seng|<http://arxiv.org/pdf/2503.15851v1>|[[代码]](<https://github.com/ZhenglinZhou/Zero-1-to-A.>)<br />- 问题：数据需求高，视频扩散平滑，不一致性<br />- 方法：视频扩散模型，空间时间一致性，迭代构建<br />- 效果：动画质量提升，渲染速度提高|


### 对比学习 (Contrastive Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Conjuring Positive Pairs for Efficient Unification of Representation Learning and Image Synthesis|召唤正对以高效统一表征学习和图像合成|Imanol G. Estepa, Jesús M. Rodríguez-de-Vera, Ignacio Sarasúa, Bhalaji Nagarajan, Petia Radeva|<http://arxiv.org/pdf/2503.15060v2>|- 问题：统一表示学习与图像合成，语义标记重建，计算开销大<br />- 方法：Sorcen框架，Echo Contrast，预计算标记<br />- 效果：性能提升，效率提高|
|📝 更新|LiMoE: Mixture of LiDAR Representation Learners from Automotive Scenes|LiMoE：来自汽车场景的激光雷达表示学习器混合体|Xiang Xu, Lingdong Kong, Hui Shuai, Liang Pan, Ziwei Liu, Qingshan Liu|<http://arxiv.org/pdf/2501.04004v2>|- 问题：LiDAR数据表示，互补属性，数据利用<br />- 方法：MoE，多表示结合，CML，SMS<br />- 效果：性能提升，大规模数据集|
|🆕 发布|DocVideoQA: Towards Comprehensive Understanding of Document-Centric Videos through Question Answering|文档视频问答：通过问答实现以文档为中心的视频的全面理解|Haochen Wang, Kai Hu, Liangcai Gao|<http://arxiv.org/pdf/2503.15887v1>|- 问题：文档视频理解，数据集，模态理解<br />- 方法：DocVideoQA，DV-LLaMA，对比学习<br />- 效果：性能提升，数据发布|
|📝 更新|Zero-Shot Head Swapping in Real-World Scenarios|零样本现实场景中的人头替换|Sohyun Jeong, Taewoong Kang, Hyojin Jang, Jaegul Choo|<http://arxiv.org/pdf/2503.00861v2>|- 问题：传统头换脸，局限性，复杂场景<br />- 方法：HID，IOMask，头发注入模块<br />- 效果：最佳性能，视觉一致，真实|


## 迁移与适应 (Transfer & Adaptation)


### 域适应 (Domain Adaptation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DynamicVis: An Efficient and General Visual Foundation Model for Remote Sensing Image Understanding|动态视：一种高效且通用的遥感图像理解视觉基础模型|Keyan Chen, Chenyang Liu, Bowen Chen, Wenyuan Li, Zhengxia Zou, Zhenwei Shi|<http://arxiv.org/pdf/2503.16426v1>|- 问题：遥感图像理解，泛化能力，高分辨率数据<br />- 方法：动态视觉感知，动态区域感知，多实例学习<br />- 效果：高效，多任务，低延迟|
|📝 更新|SSHNet: Unsupervised Cross-modal Homography Estimation via Problem Reformulation and Split Optimization|SSHNet：通过问题重构和分割优化进行无监督跨模态单应性估计|Junchen Yu, Si-Yuan Cao, Runmin Zhang, Chenghao Zhang, Zhu Yu, Shujie Chen, Bailin Yang, Hui-liang Shen|<http://arxiv.org/pdf/2409.17993v4>|- 问题：无监督跨模态单应性估计<br />- 方法：问题重构，分割优化，特征空间监督，知识蒸馏<br />- 效果：性能提升，MACEs降低|
|📝 更新|The Devil is in the Spurious Correlations: Boosting Moment Retrieval with Dynamic Learning|虚假相关性的魔鬼：通过动态学习提升时刻检索|Xinyang Zhou, Fanyue Wei, Lixin Duan, Angela Yao, Wen Li|<http://arxiv.org/pdf/2501.07305v2>|- 问题：时间定位挑战，虚假相关性，背景关联<br />- 方法：动态学习，视频合成，文本动态交互<br />- 效果：性能提升，新SOTA|
|🆕 发布|Coupling deep and handcrafted features to assess smile genuineness|将深度特征与手工特征耦合以评估微笑真实性|Benedykt Pawlus, Bogdan Smolka, Jolanta Kawulok, Michal Kawulok|<http://arxiv.org/pdf/2503.16128v1>|- 问题：微笑真实性评估，视频序列，面部表情<br />- 方法：LSTM网络，手工特征，结合<br />- 效果：实时，有效性|
|🆕 发布|OSLoPrompt: Bridging Low-Supervision Challenges and Open-Set Domain Generalization in CLIP|OSLoPrompt：在CLIP中弥合低监督挑战与开放集域泛化|Mohamad Hassan N C, Divyam Gupta, Mainak Singha, Sai Bhargav Rongali, Ankit Jha, Muhammad Haris Khan, Biplab Banerjee|<http://arxiv.org/pdf/2503.16106v1>|- 问题：低监督，开放集，领域泛化，CLIP<br />- 方法：prompt学习，跨注意力模块，伪开放样本<br />- 效果：新SOTA，显著超越|
|🆕 发布|Learning to Efficiently Adapt Foundation Models for Self-Supervised Endoscopic 3D Scene Reconstruction from Any Cameras|学习高效适应基础模型以从任何相机进行自监督内窥镜3D场景重建|Beilei Cui, Long Bai, Mobarakol Islam, An Wang, Zhiqi Ma, Yiming Huang, Feng Li, Zhen Chen .etc.|<http://arxiv.org/pdf/2503.15917v1>|- 问题：3D场景重建，自监督学习，基础模型，医学应用<br />- 方法：Endo3DAC框架，GDV-LoRA，深度图优化<br />- 效果：性能优越，参数少，效率高|
|📝 更新|On Domain-Specific Post-Training for Multimodal Large Language Models|特定领域后训练的多模态大型语言模型|Daixuan Cheng, Shaohan Huang, Ziyu Zhu, Xintong Zhang, Wayne Xin Zhao, Zhongzhi Luan, Bo Dai, Zhenliang Zhang|<http://arxiv.org/pdf/2411.19930v2>|- 问题：领域适应，MLLMs，数据合成，训练流程，任务评估<br />- 方法：生成-过滤流程，单阶段训练，开源模型<br />- 效果：性能提升，任务多样性，开源贡献|
|📝 更新|UDA4Inst: Unsupervised Domain Adaptation for Instance Segmentation|UDA4Inst：实例分割的无监督领域自适应|Yachan Guo, Yi Xiao, Danna Xue, Jose Luis Gomez Zurita, Antonio M. Lopez|<http://arxiv.org/pdf/2405.09682v5>|- 问题：实例分割，标注数据缺乏，领域适应<br />- 方法：语义类别训练，双向混合训练，伪标签生成<br />- 效果：性能提升，新基准，多数据集|
|📝 更新|Mapping Global Floods with 10 Years of Satellite Radar Data|利用10年卫星雷达数据绘制全球洪水图|Amit Misra, Kevin White, Simone Fobi Nsutezo, William Straka, Juan Lavista|<http://arxiv.org/pdf/2411.01411v2>|- 问题：全球洪水监测，数据稀缺，云覆盖影响<br />- 方法：深度学习，SAR卫星数据，云穿透能力<br />- 效果：长期数据集，实时响应，趋势分析|


### 元学习 (Meta Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ReLearn: Unlearning via Learning for Large Language Models|ReLearn：通过学习进行去学习的大语言模型|Haoming Xu, Ningyuan Zhao, Liming Yang, Sendong Zhao, Shumin Deng, Mengru Wang, Bryan Hooi, Nay Oo .etc.|<http://arxiv.org/pdf/2502.11190v2>|[[代码]](<https://github.com/zjunlp/unlearn.>)<br />- 问题：大语言模型，遗忘，性能下降，评估指标不足<br />- 方法：数据增强，微调，KFR，KRR，LS<br />- 效果：有效遗忘，高质量输出|
|📝 更新|Fine-Grained Open-Vocabulary Object Detection with Fined-Grained Prompts: Task, Dataset and Benchmark|精细粒度开放词汇目标检测：任务、数据集和基准|Ying Liu, Yijing Hua, Haojiang Chai, Yanbo Wang, TengQi Ye|<http://arxiv.org/pdf/2503.14862v2>|- 问题：开放词汇检测，数据评估，细粒度识别<br />- 方法：3F-OVD任务，NEU-171K数据集，后处理技术<br />- 效果：基准测试，性能提升|
|🆕 发布|UAS Visual Navigation in Large and Unseen Environments via a Meta Agent|通过元智能体在大规模未知环境中的UAS视觉导航|Yuci Han, Charles Toth, Alper Yilmaz|<http://arxiv.org/pdf/2503.15781v1>|- 问题：UAS导航，大规模环境，迁移学习<br />- 方法：元课程训练，ISAR算法，元强化学习<br />- 效果：收敛速度提升，适应能力增强|


## 鲁棒学习 (Robust Learning)


### 对抗防御 (Adversarial Defense)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RESFL: An Uncertainty-Aware Framework for Responsible Federated Learning by Balancing Privacy, Fairness and Utility in Autonomous Vehicles|责任联邦学习的隐私、公平与效用平衡的不确定性感知框架：RESFL|Dawood Wasif, Terrence J. Moore, Jin-Hee Cho|<http://arxiv.org/pdf/2503.16251v1>|- 问题：隐私，公平性，鲁棒性，性能差异<br />- 方法：对抗隐私解耦，不确定性引导，公平性感知聚合<br />- 效果：检测精度提升，公平性降低，隐私攻击成功率降低|
|📝 更新|2DSig-Detect: a semi-supervised framework for anomaly detection on image data using 2D-signatures|2DSig-Detect：基于2D签名的图像数据异常检测半监督框架|Xinheng Xie, Kureha Yamaguchi, Margaux Leblanc, Simon Malzard, Varun Chhabra, Victoria Nockles, Yue Wu|<http://arxiv.org/pdf/2409.04982v2>|- 问题：异常检测，对抗攻击，图像数据<br />- 方法：2D-signature，半监督框架，粗糙路径理论<br />- 效果：性能优越，计算时间减少|
|📝 更新|Project-Probe-Aggregate: Efficient Fine-Tuning for Group Robustness|项目-探测-聚合：针对组鲁棒的高效微调|Beier Zhu, Jiequan Cui, Hanwang Zhang, Chi Zhang|<http://arxiv.org/pdf/2503.09487v2>|- 问题：图像-文本模型，伪相关性，鲁棒性<br />- 方法：Project-Probe-Aggregate，失败反偏，少数样本识别<br />- 效果：参数高效，性能提升|
|📝 更新|SAUCE: Selective Concept Unlearning in Vision-Language Models with Sparse Autoencoders|SAUCE：基于稀疏自编码器的视觉-语言模型中的选择性概念遗忘|Qing Li, Jiahui Geng, Derui Zhu, Fengyu Cai, Chenyang Lyu, Fakhri Karray|<http://arxiv.org/pdf/2503.14530v2>|- 问题：VLMs遗忘集，粗粒度，模型效用低<br />- 方法：稀疏自编码器，细粒度，选择性遗忘<br />- 效果：遗忘质量高，模型效用保持|


### 对抗训练 (Adversarial Training)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Narrowing Class-Wise Robustness Gaps in Adversarial Training|缩小对抗训练中类间鲁棒性差距|Fatemeh Amerehi, Patrick Healy|<http://arxiv.org/pdf/2503.16179v1>|- 问题：数据偏移，鲁棒性下降，泛化能力差，性能不平衡<br />- 方法：增强标注，对抗训练，缓解不平衡<br />- 效果：鲁棒性提升，精度改善|
|🆕 发布|3-D Image-to-Image Fusion in Lightsheet Microscopy by Two-Step Adversarial Network: Contribution to the FuseMyCells Challenge|基于两步对抗网络的激光共聚焦显微镜三维图像到图像融合：对FuseMyCells挑战赛的贡献|Marek Wodzinski, Henning Müller|<http://arxiv.org/pdf/2503.16075v1>|- 问题：3D图像融合，低分辨率，多视图<br />- 方法：两步对抗网络，下采样，高分辨率推理<br />- 效果：高SSIM，提升融合质量|
|📝 更新|Weakly Supervised Contrastive Adversarial Training for Learning Robust Features from Semi-supervised Data|弱监督对比对抗训练从半监督数据中学习鲁棒特征|Lilin Zhang, Chengpei Wu, Ning Yang|<http://arxiv.org/pdf/2503.11032v2>|[[代码]](<https://github.com/zhang-lilin/WSCAT.>)<br />- 问题：对抗训练，特征鲁棒性，半监督学习<br />- 方法：弱监督，对比对抗训练，信息理论<br />- 效果：特征学习，性能提升|


## 模型压缩加速 (Model Compression & Acceleration)


### 知识蒸馏 (Knowledge Distillation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Sonata: Self-Supervised Learning of Reliable Point Representations|奏鸣曲：可靠点表示的自监督学习|Xiaoyang Wu, Daniel DeTone, Duncan Frost, Tianwei Shen, Chris Xie, Nan Yang, Jakob Engel, Richard Newcombe .etc.|<http://arxiv.org/pdf/2503.16429v1>|- 问题：3D点云，自监督学习，可靠性，线性探测<br />- 方法：遮挡信息，增强输入依赖，自蒸馏<br />- 效果：参数效率高，数据效率高，性能提升|
|🆕 发布|Accurate Scene Text Recognition with Efficient Model Scaling and Cloze Self-Distillation|准确场景文本识别：高效模型缩放与闭卷自蒸馏|Andrea Maracani, Savas Ozkan, Sijun Cho, Hyowon Kim, Eunchung Noh, Jeongwon Min, Cho Jung Min, Dookun Park .etc.|<http://arxiv.org/pdf/2503.16184v1>|- 问题：STR性能，解码器扩展，标签噪声<br />- 方法：Cloze Self-Distillation，交叉注意力，软预测<br />- 效果：SOTA性能，参数减少，计算成本低|
|📝 更新|Tiny models from tiny data: Textual and null-text inversion for few-shot distillation|微型模型从微型数据：文本和空文本逆变换的少样本蒸馏|Erik Landolsi, Fredrik Kahl|<http://arxiv.org/pdf/2406.03146v2>|[[代码]](<https://github.com/pixwse/tiny2.>)<br />- 问题：少样本学习，数据缺乏，模型效率低<br />- 方法：TINT模型，文本和空文本反转，合成数据<br />- 效果：精度高，速度快|
|🆕 发布|DnLUT: Ultra-Efficient Color Image Denoising via Channel-Aware Lookup Tables|DnLUT：基于通道感知查找表的超高效彩色图像去噪|Sidi Yang, Binxiao Huang, Yulun Zhang, Dahai Yu, Yujiu Yang, Ngai Wong|<http://arxiv.org/pdf/2503.15931v1>|[[代码]](<https://github.com/Stephen0808/DnLUT.>)<br />- 问题：图像降噪，计算资源，内存需求<br />- 方法：通道混合器，L形卷积，查找表<br />- 效果：效率高，PSNR提升|
|📝 更新|Multimodal Industrial Anomaly Detection by Crossmodal Reverse Distillation|跨模态反向蒸馏的多模态工业异常检测|Xinyue Liu, Jianyuan Wang, Biao Leng, Shuo Zhang|<http://arxiv.org/pdf/2412.08949v2>|- 问题：多模态异常检测，知识蒸馏，特征融合，信息利用不足<br />- 方法：跨模态反向蒸馏，多分支设计，跨模态滤波器<br />- 效果：性能领先，检测准确|


### 网络剪枝 (Network Pruning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|XAttention: Block Sparse Attention with Antidiagonal Scoring|XAttention：带反斜对角评分的块稀疏注意力|Ruyi Xu, Guangxuan Xiao, Haofeng Huang, Junxian Guo, Song Han|<http://arxiv.org/pdf/2503.16428v1>|[[代码]](<https://github.com/mit-han-lab/x-attention.>)<br />- 问题：高计算成本，精度与效率平衡，块稀疏注意力<br />- 方法：XAttention框架，抗对角评分，块重要性测量<br />- 效果：加速推理，高精度，13.5倍加速|


### 量化优化 (Quantization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Plug-and-Play 1.x-Bit KV Cache Quantization for Video Large Language Models|《视频大型语言模型用1.x位KV缓存量化的即插即用技术》|Keda Tao, Haoxuan You, Yang Sui, Can Qin, Huan Wang|<http://arxiv.org/pdf/2503.16257v1>|- 问题：视频LLMs，KV缓存，内存瓶颈<br />- 方法：VidKV，混合精度量化，通道量化<br />- 效果：低比特量化，性能无损|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MambaIC: State Space Models for High-Performance Learned Image Compression|MambaIC：高性能学习图像压缩的状态空间模型|Fanhu Zeng, Hao Tang, Yihua Shao, Siyu Chen, Ling Shao, Yan Wang|<http://arxiv.org/pdf/2503.12461v2>|[[代码]](<https://github.com/AuroraZengfh/MambaIC.>)<br />- 问题：图像压缩，计算效率，冗余建模<br />- 方法：状态空间模型，自适应上下文建模，窗口局部注意力<br />- 效果：效率提升，高分辨率压缩|


## 泛化与鲁棒性 (Generalization & Robustness)


### 分布鲁棒性 (Distribution Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Tokenize Image as a Set|图像作为集合的标记化|Zigang Geng, Mengde Xu, Han Hu, Shuyang Gu|<http://arxiv.org/pdf/2503.16425v1>|[[代码]](<https://github.com/Gengzigang/TokenSet.>)<br />- 问题：图像序列化，局部扰动，离散集建模<br />- 方法：TokenSet，双变换机制，Fixed-Sum离散扩散<br />- 效果：语义感知，生成质量提升|


### 不确定性建模 (Uncertainty Modeling)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Efficient Bayesian Computation Using Plug-and-Play Priors for Poisson Inverse Problems|高效使用即插即用先验的泊松逆问题贝叶斯计算|Teresa Klatzer, Savvas Melidonis, Marcelo Pereyra, Konstantinos C. Zygalakis|<http://arxiv.org/pdf/2503.16222v1>|- 问题：低光子Poisson成像，不确定性，不稳定性<br />- 方法：PnP Langevin采样，加速方法，镜像采样<br />- 效果：准确估计，不确定性量化，模型参数调优|


### 域泛化 (Domain Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MapGlue: Multimodal Remote Sensing Image Matching|地图粘合：多模态遥感图像配准|Peihao Wu, Yongxiang Yao, Wenfei Zhang, Dong Wei, Yi Wan, Yansheng Li, Yongjun Zhang|<http://arxiv.org/pdf/2503.16185v1>|[[代码]](<https://github.com/PeihaoWu/MapGlue.>)<br />- 问题：多模态图像匹配，数据稀缺，几何差异<br />- 方法：MapData，图引导机制，语义上下文<br />- 效果：匹配精度高，泛化能力强|


## 可解释性 (Interpretability)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RoboFactory: Exploring Embodied Agent Collaboration with Compositional Constraints|机器人工厂：探索具有组合约束的具身智能体协作|Yiran Qin, Li Kang, Xiufeng Song, Zhenfei Yin, Xiaohong Liu, Xihui Liu, Ruimao Zhang, Lei Bai|<http://arxiv.org/pdf/2503.16408v1>|- 问题：多智能体协作，数据生成，安全性，效率<br />- 方法：组合约束，定制接口，自动化数据收集<br />- 效果：基准测试，模仿学习，安全高效|
|🆕 发布|Single Image Iterative Subject-driven Generation and Editing|单图像迭代主题驱动生成与编辑|Yair Shpitzer, Gal Chechik, Idan Schwartz|<http://arxiv.org/pdf/2503.16025v1>|- 问题：个性化图像生成，单图学习，质量退化<br />- 方法：SISO，相似度优化，迭代生成<br />- 效果：质量提升，主体保真，背景保留|


### 概念解释 (Concept Explanation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Local Compositional Complexity: How to Detect a Human-readable Messsage|局部组合复杂性：如何检测可读的乱码|Louis Mahon|<http://arxiv.org/pdf/2501.03664v2>|- 问题：数据复杂性，信息传递，局部组合复杂性<br />- 方法：局部组合性，结构化描述，复杂度评分<br />- 效果：信号区分，通信识别|


## 医学影像分析 (Medical Image Analysis)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Panoptic-CUDAL Technical Report: Rural Australia Point Cloud Dataset in Rainy Conditions|《全景-CUDAL 技术报告：雨天条件下澳大利亚乡村点云数据集》|Tzu-Yun Tseng, Alexey Nekrasov, Malcolm Burdorf, Bastian Leibe, Julie Stephany Berrio, Mao Shan, Stewart Worrall|<http://arxiv.org/pdf/2503.16378v1>|- 问题：农村环境，恶劣天气，感知导航<br />- 方法：Panoptic-CUDAL数据集，高分辨率数据<br />- 效果：数据丰富，基线结果|
|🆕 发布|No Thing, Nothing: Highlighting Safety-Critical Classes for Robust LiDAR Semantic Segmentation in Adverse Weather|无物，无物：突出恶劣天气下鲁棒激光雷达语义分割的关键安全类别|Junsung Park, Hwijeong Lee, Inha Kang, Hyunjung Shim|<http://arxiv.org/pdf/2503.15910v1>|- 问题：LiDAR语义分割，天气影响，动态物体识别<br />- 方法：NTN，特征绑定，局部区域正则化<br />- 效果：mIoU提升，事物类别识别改善|


### 医学分割 (Medical Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Attentional Triple-Encoder Network in Spatiospectral Domains for Medical Image Segmentation|基于空间光谱域的注意力三重编码网络在医学图像分割中的应用|Kristin Qi, Xinhan Di|<http://arxiv.org/pdf/2503.16389v1>|- 问题：OCT图像分割，空间-光谱依赖，分割精度低<br />- 方法：三编码器网络，CNN，FFC，注意力机制，融合模块<br />- 效果：Dice分数提升，性能优于前人|
|🆕 发布|Rapid patient-specific neural networks for intraoperative X-ray to volume registration|快速患者特异性神经网络的术中X射线到体积配准|Vivek Gopalakrishnan, Neel Dey, David-Dimitris Chlorogiannis, Andrew Abumoussa, Anna M. Larson, Darren B. Orbach, Sarah Frisken, Polina Golland|<http://arxiv.org/pdf/2503.16309v1>|[[代码]](<https://github.com/eigenvivek/xvr.>)<br />- 问题：2D/3D配准，数据泛化，参数调整<br />- 方法：xvr框架，物理模拟，自动训练<br />- 效果：亚毫米级精度，快速训练|
|📝 更新|Repurposing Stable Diffusion Attention for Training-Free Unsupervised Interactive Segmentation|重新利用稳定扩散注意力进行无监督交互式分割训练|Markus Karmann, Onay Urfalioglu|<http://arxiv.org/pdf/2411.10411v2>|[[代码]](<https://github.com/mkarmann/m2n2.>)<br />- 问题：无监督分割，训练免费，交互式<br />- 方法：Stable Diffusion注意力，Markov链，Markov-map<br />- 效果：结果优异，NoC低|
|🆕 发布|M2N2V2: Multi-Modal Unsupervised and Training-free Interactive Segmentation|M2N2V2：多模态无监督和无训练交互式分割|Markus Karmann, Peng-Tao Jiang, Bo Li, Onay Urfalioglu|<http://arxiv.org/pdf/2503.16254v1>|- 问题：无监督，交互式分割，深度引导，注意力图<br />- 方法：M2N2V2，深度模态，自适应评分函数<br />- 效果：NoC降低，mIoU提升，竞争性结果|
|📝 更新|UNIP: Rethinking Pre-trained Attention Patterns for Infrared Semantic Segmentation|统一预训练注意力模式：红外语义分割的再思考|Tao Zhang, Jinyong Wen, Zhen Chen, Kun Ding, Shiming Xiang, Chunhong Pan|<http://arxiv.org/pdf/2502.02257v2>|[[代码]](<https://github.com/casiatao/UNIP.>)<br />- 问题：预训练，红外语义分割，域差距<br />- 方法：UNIP框架，混合数据集，特征金字塔网络<br />- 效果：性能提升，成本降低|
|📝 更新|Transformation trees -- documentation of multimodal image registration|变换树——多模态图像配准的文档|Agnieszka Anna Tomaka, Dariusz Pojda, Michał Tarnawski, Leszek Luchowski|<http://arxiv.org/pdf/2501.19140v2>|- 问题：多模态图像配准，透明性，可重复性<br />- 方法：变换树，结构化记录，.dpw格式<br />- 效果：数据组织，分析效率，信息重用|
|🆕 发布|Landmarks Are Alike Yet Distinct: Harnessing Similarity and Individuality for One-Shot Medical Landmark Detection|地标相似却独特：利用相似性和个体性进行一次性医学地标检测|Xu He, Zhen Huang, Qingsong Yao, Xiaoqian Zhou, S. Kevin Zhou|<http://arxiv.org/pdf/2503.16058v1>|- 问题：多地标检测，内存计算，见锯现象<br />- 方法：伪标签，模板数据，模型融合<br />- 效果：精度提升，资源效率|
|🆕 发布|SALT: Singular Value Adaptation with Low-Rank Transformation|SALT：低秩变换下的奇异值自适应|Abdelrahman Elsayed, Sarim Hashmi, Mohammed Elseiagy, Hu Wang, Mohammad Yaqub, Ibrahim Almakky|<http://arxiv.org/pdf/2503.16055v1>|[[代码]](<https://github.com/BioMedIA-MBZUAI/SALT>)<br />- 问题：医疗图像分割，模型微调成本高，欠拟合<br />- 方法：SALT，低秩变换，SVD，参数高效微调<br />- 效果：Dice系数提升，参数少|
|🆕 发布|Nano-3D: Metasurface-Based Neural Depth Imaging|纳米-3D：基于超表面的人工神经网络深度成像|Bingxuan Li, Jiahao Wu, Yuan Xu, Yunxiang Zhang, Zezheng Zhu, Nanfang Yu, Qi Sun|<http://arxiv.org/pdf/2503.15770v1>|- 问题：深度成像，体积大，精度低<br />- 方法：超紧凑，元表面，深度学习<br />- 效果：精确，纳米技术|


### 疾病诊断 (Disease Diagnosis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PSA-MIL: A Probabilistic Spatial Attention-Based Multiple Instance Learning for Whole Slide Image Classification|PSA-MIL：一种基于概率空间注意力的多实例学习用于全切片图像分类|Sharon Peled, Yosef E. Maruvka, Moti Freiman|<http://arxiv.org/pdf/2503.16284v1>|- 问题：WSI分类，MIL，空间关系，诊断准确性<br />- 方法：PSA-MIL，空间注意力，概率解释，距离衰减<br />- 效果：性能提升，计算成本降低|
|🆕 发布|OpenMIBOOD: Open Medical Imaging Benchmarks for Out-Of-Distribution Detection|开放MIBOOD：用于分布外检测的开源医学图像基准|Max Gutbrod, David Rauber, Danilo Weber Nunes, Christoph Palm|<http://arxiv.org/pdf/2503.16247v1>|[[代码]](<https://github.com/remic-othr/OpenMIBOOD.>)<br />- 问题：AI系统可靠性，OOD检测，医疗影像<br />- 方法：OpenMIBOOD框架，多领域基准，后处理方法评估<br />- 效果：跨领域适用性，风险降低，系统可靠性提升|
|📝 更新|FOCUS: Knowledge-enhanced Adaptive Visual Compression for Few-shot Whole Slide Image Classification|聚焦：基于知识的自适应视觉压缩在少样本全切片图像分类中的应用|Zhengrui Guo, Conghao Xiong, Jiabo Ma, Qichen Sun, Lishuang Feng, Jinzhuo Wang, Hao Chen|<http://arxiv.org/pdf/2411.14743v2>|[[代码]](<https://github.com/dddavid4real/FOCUS.>)<br />- 问题：少样本学习，WSI分类，数据稀缺<br />- 方法：知识增强，自适应视觉压缩，语言先验<br />- 效果：诊断性能提升，语义信息利用|
|🆕 发布|UMIT: Unifying Medical Imaging Tasks via Vision-Language Models|UMIT：通过视觉-语言模型统一医学影像任务|Haiyang Yu, Siyang Yi, Ke Niu, Minghan Zhuo, Bin Li|<http://arxiv.org/pdf/2503.15892v1>|- 问题：多任务，单一模态，应用局限<br />- 方法：统一多模态，多任务VLM，两阶段训练<br />- 效果：性能提升，诊断准确，效率提高|
|🆕 发布|RL4Med-DDPO: Reinforcement Learning for Controlled Guidance Towards Diverse Medical Image Generation using Vision-Language Foundation Models|基于视觉-语言基础模型的多样化医学图像生成控制引导的强化学习：RL4Med-DDPO|Parham Saremi, Amar Kumar, Mohammed Mohammed, Zahra TehraniNasab, Tal Arbel|<http://arxiv.org/pdf/2503.15784v1>|- 问题：VLFM，医学图像，精细对齐，语义理解<br />- 方法：多阶段架构，RL算法，语义对齐<br />- 效果：生成质量提升，疾病分类性能改善|


### 影像重建 (Image Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Iterative Optimal Attention and Local Model for Single Image Rain Streak Removal|迭代最优注意力与局部模型用于单图像雨迹去除|Xiangyu Li, Wanshu Fan, Yue Shen, Cong Wang, Wei Wang, Xin Yang, Qiang Zhang, Dongsheng Zhou|<http://arxiv.org/pdf/2503.16165v1>|- 问题：雨 streak 消除，图像质量，VBMS<br />- 方法：EMResformer，期望最大化，局部模型<br />- 效果：性能提升，准确性提高|
|📝 更新|Segmentation Guided Sparse Transformer for Under-Display Camera Image Restoration|基于分割引导的稀疏Transformer用于屏幕下摄像头图像恢复|Jingyun Xue, Tao Wang, Pengwen Dai, Kaihao Zhang|<http://arxiv.org/pdf/2403.05906v2>|- 问题：UDC图像退化，Transformer冗余，稀疏注意力<br />- 方法：SGSFormer，稀疏自注意力，实例分割引导<br />- 效果：图像质量提升，恢复效果佳|
|🆕 发布|DIPLI: Deep Image Prior Lucky Imaging for Blind Astronomical Image Restoration|DIPLI：深度图像先验幸运成像盲天文图像恢复|Suraj Singh, Anastasia Batsheva, Oleg Y. Rogov, Ahmed Bouridane|<http://arxiv.org/pdf/2503.15984v1>|- 问题：天文图像恢复，深度学习，训练数据有限<br />- 方法：DIP模型改进，多帧处理，Markov方法<br />- 效果：性能提升，超越Lucky Imaging|
|📝 更新|SemHiTok: A Unified Image Tokenizer via Semantic-Guided Hierarchical Codebook for Multimodal Understanding and Generation|语义引导的分层码本统一图像标记器，用于多模态理解和生成|Zisheng Chen, Chunwei Wang, Xiuwei Chen, Hang Xu, Jianhua Han, Xiaodan Liang|<http://arxiv.org/pdf/2503.06764v3>|- 问题：统一图像分词器，多模态理解，生成任务，特征平衡<br />- 方法：语义引导，分层代码簿，纹理子代码簿<br />- 效果：rFID分数高，多模态任务表现佳|
|📝 更新|Cooperative Hardware-Prompt Learning for Snapshot Compressive Imaging|协同硬件提示学习用于快照压缩成像|Jiamian Wang, Zongliang Wu, Yulun Zhang, Xin Yuan, Tao Lin, Zhiqiang Tao|<http://arxiv.org/pdf/2306.01176v2>|[[代码]](<https://github.com/Jiamian-Wang/FedHP-Snapshot-Compressive-Imaging>)<br />- 问题：硬件依赖，隐私问题，异构性，数据不一致<br />- 方法：联邦学习，硬件条件提示器，数据对齐<br />- 效果：性能提升，数据隐私保护|


## 智能驾驶 (Intelligent Driving)


### 决策规划 (Decision Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|JARVIS-VLA: Post-Training Large-Scale Vision Language Models to Play Visual Games with Keyboards and Mouse|JARVIS-VLA：基于键盘和鼠标的视觉游戏后训练大规模视觉语言模型|Muyao Li, Zihao Wang, Kaichen He, Xiaojian Ma, Yitao Liang|<http://arxiv.org/pdf/2503.16365v1>|[[代码]](<https://craftjarvis.github.io/JarvisVLA.>)<br />- 问题：VLA模型，训练，开放世界决策<br />- 方法：视觉语言后训练，自监督学习，VLM优化<br />- 效果：性能提升，Minecraft任务，超越模仿学习|


### 环境感知 (Environment Perception)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Complexity in Complexity: Understanding Visual Complexity Through Structure, Color, and Surprise|复杂性中的复杂性：通过结构、色彩和惊喜理解视觉复杂性|Karahan Sarıtaş, Peter Dayan, Tingke Shen, Surabhi S Nath|<http://arxiv.org/pdf/2501.15890v3>|[[代码]](<https://github.com/Complexity-Project/Complexity-in-Complexity.>)<br />- 问题：视觉复杂性理解，模型可解释性，数据偏差<br />- 方法：Multi-Scale Sobel Gradient，Multi-Scale Unique Color，Large Language Model<br />- 效果：预测性能提升，可解释性保持|
|📝 更新|LongVALE: Vision-Audio-Language-Event Benchmark Towards Time-Aware Omni-Modal Perception of Long Videos|LongVALE：面向时间感知长视频的视觉-音频-语言-事件基准|Tiantian Geng, Jinrui Zhang, Qingni Wang, Teng Wang, Jinming Duan, Feng Zheng|<http://arxiv.org/pdf/2411.19772v3>|- 问题：多模态视频理解，数据标注困难，视频理解局限<br />- 方法：自动管道，事件边界检测，跨模态关联<br />- 效果：基准数据集，LLM应用|
|📝 更新|Moto: Latent Motion Token as the Bridging Language for Learning Robot Manipulation from Videos|Moto：作为从视频中学习机器人操作的桥梁语言的潜在运动标记|Yi Chen, Yuying Ge, Weiliang Tang, Yizhuo Li, Yixiao Ge, Mingyu Ding, Ying Shan, Xihui Liu|<http://arxiv.org/pdf/2412.04445v2>|- 问题：机器人学习，视频数据，动作标签，成本高<br />- 方法：Moto，运动标记，自回归预训练<br />- 效果：知识迁移，机器人操作，效率提升|
|📝 更新|U-Motion: Learned Point Cloud Video Compression with U-Structured Temporal Context Generation|U-Motion：基于U结构化时间上下文生成的学习点云视频压缩|Tingyu Fan, Yueyu Hu, Ran Gong, Yao Wang|<http://arxiv.org/pdf/2411.14501v4>|- 问题：PCV压缩，运动估计，时空冗余<br />- 方法：U-Structured预测，多尺度补偿，时空预测编码<br />- 效果：性能提升，效率提高|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UniHDSA: A Unified Relation Prediction Approach for Hierarchical Document Structure Analysis|统一层次文档结构分析的关系预测方法：UniHDSA|Jiawei Wang, Kai Hu, Qiang Huo|<http://arxiv.org/pdf/2503.15893v1>|- 问题：HDSA，文档结构分析，关系预测<br />- 方法：UniHDSA，统一框架，Transformer<br />- 效果：SOTA性能，竞争结果|


### 轨迹预测 (Trajectory Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SSTP: Efficient Sample Selection for Trajectory Prediction|SSTP：轨迹预测中的高效样本选择|Ruining Yang, Yi Xu, Yun Fu, Lili Su|<http://arxiv.org/pdf/2409.17385v2>|- 问题：轨迹预测，数据量大，场景不平衡<br />- 方法：SSTP框架，梯度向量，子模块函数<br />- 效果：数据量减半，性能提升，时间减少|


## 工业视觉 (Industrial Vision)


### 质量控制 (Quality Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MagicMotion: Controllable Video Generation with Dense-to-Sparse Trajectory Guidance|魔动：基于密集到稀疏轨迹引导的可控视频生成|Quanhao Li, Zhen Xing, Rui Wang, Hui Zhang, Qi Dai, Zuxuan Wu|<http://arxiv.org/pdf/2503.16421v1>|[[代码]](<https://quanhaol.github.io/magicmotion-site.>)<br />- 问题：复杂运动控制，对象一致性，视觉质量，单一格式，无基准数据集<br />- 方法：密集到稀疏轨迹引导，MagicMotion框架，MagicData数据集，MagicBench基准<br />- 效果：精确轨迹控制，对象一致性，视觉质量提升|
|📝 更新|Wolf: Dense Video Captioning with a World Summarization Framework|狼：基于世界摘要框架的密集视频字幕|Boyi Li, Ligeng Zhu, Ran Tian, Shuhan Tan, Yuxiao Chen, Yao Lu, Yin Cui, Sushant Veer .etc.|<http://arxiv.org/pdf/2407.18908v2>|[[代码]](<https://wolfv0.github.io/.>)<br />- 问题：视频描述准确性，信息捕捉效率<br />- 方法：混合专家模型，VLMs，CapScore<br />- 效果：性能超越，基准建立|


### 缺陷检测 (Defect Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hyperspectral Imaging for Identifying Foreign Objects on Pork Belly|猪肉腹部异物识别的超光谱成像|Gabriela Ghimpeteanu, Hayat Rajani, Josep Quintana, Rafael Garcia|<http://arxiv.org/pdf/2503.16086v1>|- 问题：食品安全，异物检测，猪肉，光谱成像<br />- 方法：预处理，ViT分割，光谱分析<br />- 效果：高精度，效率高|
|📝 更新|ISP-AD: A Large-Scale Real-World Dataset for Advancing Industrial Anomaly Detection with Synthetic and Real Defects|ISP-AD：用于推进工业异常检测的大规模真实世界数据集，包含合成和真实缺陷|Paul J. Krassnig, Dieter P. Gruber|<http://arxiv.org/pdf/2503.04997v2>|- 问题：工业缺陷检测，数据集，成像条件<br />- 方法：ISP-AD数据集，合成与真实缺陷，混合监督训练<br />- 效果：模型泛化，低误报率，高召回率|


### 工业测量 (Industrial Measurement)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Semantic-Guided Global-Local Collaborative Networks for Lightweight Image Super-Resolution|语义引导的全局-局部协同网络用于轻量级图像超分辨率|Wanshu Fan, Yue Wang, Cong Wang, Yunzhe Zhang, Wei Wang, Dongsheng Zhou|<http://arxiv.org/pdf/2503.16056v1>|[[代码]](<https://github.com/fanamber831/SGGLC-Net.>)<br />- 问题：图像退化，超分辨率，测量精度<br />- 方法：语义引导，全局-局部协作，混合注意力<br />- 效果：性能提升，轻量化|
|🆕 发布|Sequential Spatial-Temporal Network for Interpretable Automatic Ultrasonic Assessment of Fetal Head during labor|序列时空网络在分娩过程中对胎儿头部进行可解释的自动超声评估|Jie Gan, Zhuonan Liang, Jianan Fan, Lisa Mcguire, Caterina Watson, Jacqueline Spurway, Jillian Clarke, Weidong Cai|<http://arxiv.org/pdf/2503.15861v1>|- 问题：胎儿头评估，超声分析，测量精度<br />- 方法：SSTN，时空网络，可解释性<br />- 效果：误差降低，性能提升|


## 其他 (Others)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CaKE: Circuit-aware Editing Enables Generalizable Knowledge Learners|CaKE：电路感知编辑实现可泛化知识学习|Yunzhi Yao, Jizhan Fang, Jia-Chen Gu, Ningyu Zhang, Shumin Deng, Huajun Chen, Nanyun Peng|<http://arxiv.org/pdf/2503.16356v1>|[[代码]](<https://github.com/zjunlp/CaKE.>)<br />- 问题：知识编辑，多跳推理，知识泛化<br />- 方法：电路感知，知识编辑，数据引导<br />- 效果：推理精度提升，知识利用|
|🆕 发布|Agentic Keyframe Search for Video Question Answering|基于代理的关键帧搜索用于视频问答|Sunqi Fan, Meng-Hao Guo, Shuojin Yang|<http://arxiv.org/pdf/2503.16032v1>|[[代码]](<https://github.com/fansunqi/AKeyS.>)<br />- 问题：视频理解，计算成本高，效率低<br />- 方法：语言代理，动态搜索，关键帧识别<br />- 效果：效率高，精度高|
|🆕 发布|GazeSCRNN: Event-based Near-eye Gaze Tracking using a Spiking Neural Network|基于脉冲神经网络的基于事件的近眼注视跟踪：GazeSCRNN|Stijn Groenen, Marzieh Hassanshahi Varposhti, Mahyar Shahsavari|<http://arxiv.org/pdf/2503.16012v1>|- 问题：动态眼动跟踪，传统系统局限性，高时间分辨率<br />- 方法：事件相机，脉冲神经网络，ALIF神经元<br />- 效果：高精度，低误差|
|📝 更新|A General Adaptive Dual-level Weighting Mechanism for Remote Sensing Pansharpening|通用自适应双层加权机制在遥感全色融合中的应用|Jie Huang, Haorui Chen, Jiaxuan Ren, Siran Peng, Liangjian Deng|<http://arxiv.org/pdf/2503.13214v2>|[[代码]](<https://github.com/Jie-1203/ADWM.>)<br />- 问题：特征异质性，冗余，深度学习方法<br />- 方法：协方差矩阵，CACW，ADWM<br />- 效果：性能提升，泛化性，可视化|

