## [UPDATED!] **2025-03-21** (Update Time)


## 表示学习 (Representation Learning)


### 视觉Transformer (Vision Transformers)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Karyotype AI for Precision Oncology|精准肿瘤学中的核型人工智能|Zahra Shamsi, Isaac Reid, Drew Bryant, Jacob Wilson, Xiaoyu Qu, Avinava Dubey, Konik Kothari, Mostafa Dehghani .etc.|<http://arxiv.org/pdf/2211.14312v5>|- 问题：染色体异常检测，手动分析，数据稀缺<br />- 方法：Vision Transformers，预训练微调，零样本检测<br />- 效果：高精度，快速诊断，改善患者预后|
|📝 更新|DLEN: Dual Branch of Transformer for Low-Light Image Enhancement in Dual Domains|DLEN：双域低光图像增强的Transformer双分支|Junyu Xia, Jiesong Bai, Yihang Dong|<http://arxiv.org/pdf/2501.12235v3>|[[代码]](<https://github.com/LaLaLoXX/DLEN>)<br />- 问题：低光图像增强，细节丢失，自然性差<br />- 方法：Transformer，双分支结构，波let变换<br />- 效果：性能优于，基准测试|
|📝 更新|Spectral State Space Model for Rotation-Invariant Visual Representation Learning|光谱状态空间模型用于旋转不变视觉表示学习|Sahar Dastani, Ali Bahri, Moslem Yazdanpanah, Mehrdad Noori, David Osowiechi, Gustavo Adolfo Vargas Hakim, Farzad Beizaee, Milad Cheraghalikhani .etc.|<http://arxiv.org/pdf/2503.06369v3>|- 问题：SSMs局限性，旋转不变性，图像关系建模<br />- 方法：Spectral VMamba，图拉普拉斯谱，RFN模块<br />- 效果：旋转不变，性能提升|
|📝 更新|Sparse autoencoders reveal selective remapping of visual concepts during adaptation|稀疏自编码器揭示适应过程中的视觉概念选择性重映射|Hyesu Lim, Jinho Choi, Jaegul Choo, Steffen Schneider|<http://arxiv.org/pdf/2412.05276v2>|- 问题：模型适应机制，视觉概念重映射<br />- 方法：PatchSAE，概念提取，空间属性<br />- 效果：解释性，适应效果|
|🆕 发布|Token Dynamics: Towards Efficient and Dynamic Video Token Representation for Video Large Language Models|视频大语言模型中高效且动态的视频标记表示：标记动力学|Haichao Zhang, Zhuowei Li, Dimitris Metaxas, Yun Fu|<http://arxiv.org/pdf/2503.16980v1>|- 问题：视频表示，效率低，压缩不足<br />- 方法：Token Dynamics，动态减少，跨动态注意力<br />- 效果：压缩率0.07%，性能下降1.13%|


### 基础模型 (Foundation Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Specialized Foundation Models Struggle to Beat Supervised Baselines|专用基础模型难以击败监督基线|Zongzhe Xu, Ritvik Gupta, Wenduo Cheng, Alexander Shen, Junhong Shen, Ameet Talwalkar, Mikhail Khodak|<http://arxiv.org/pdf/2411.02796v2>|- 问题：基础模型，监督学习，领域特定，性能比较<br />- 方法：专用领域，简单监督模型，基准对比<br />- 效果：基础模型挑战，监督模型优势|


## 生成建模 (Generative Modeling)


### 扩散模型 (Diffusion Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Decouple and Track: Benchmarking and Improving Video Diffusion Transformers for Motion Transfer|解耦与追踪：视频扩散变换器的运动传递基准测试与改进|Qingyu Shi, Jianzong Wu, Jinbin Bai, Jiangning Zhang, Lu Qi, Xiangtai Li, Yunhai Tong|<http://arxiv.org/pdf/2503.17350v1>|- 问题：运动迁移，模型解耦，时空交互<br />- 方法：DeT模型，时间核，显式监督<br />- 效果：运动保真度，编辑保真度|
|📝 更新|TopoDiffusionNet: A Topology-aware Diffusion Model|拓扑扩散网络：一种拓扑感知扩散模型|Saumya Gupta, Dimitris Samaras, Chao Chen|<http://arxiv.org/pdf/2410.16646v2>|[[代码]](<https://github.com/Saumya-Gupta-26/TopoDiffusionNet>)<br />- 问题：拓扑控制，图像生成，拓扑保真<br />- 方法：拓扑数据，持久同伦，拓扑目标函数<br />- 效果：拓扑精度提升，拓扑结构保持|
|🆕 发布|Dereflection Any Image with Diffusion Priors and Diversified Data|任何图像的扩散先验和多样化数据去反照|Jichen Hu, Chen Yang, Zanwei Zhou, Jiemin Fang, Xiaokang Yang, Qi Tian, Wei Shen|<http://arxiv.org/pdf/2503.17347v1>|- 问题：反射去除，数据稀缺，泛化能力差<br />- 方法：数据集DRR，扩散先验，渐进训练<br />- 效果：SOTA性能，泛化能力强|
|📝 更新|MANTA: Diffusion Mamba for Efficient and Effective Stochastic Long-Term Dense Anticipation|MANTA：高效且有效的随机长期密集预测的扩散曼巴|Olga Zatsarynna, Emad Bahrami, Yazan Abu Farha, Gianpiero Francesca, Juergen Gall|<http://arxiv.org/pdf/2501.08837v2>|[[代码]](<https://github.com/olga-zats/DIFF_MANTA>)<br />- 问题：长期密集动作预测，不确定性建模，长距离时间建模<br />- 方法：MANTA网络，统一预测，线性复杂度<br />- 效果：SOTA结果，效率提升|
|📝 更新|SuperPC: A Single Diffusion Model for Point Cloud Completion, Upsampling, Denoising, and Colorization|超级PC：一个用于点云补全、上采样、去噪和着色的单一扩散模型|Yi Du, Zhipeng Zhao, Shaoshu Su, Sharath Golluri, Haoze Zheng, Runmao Yao, Chen Wang|<http://arxiv.org/pdf/2503.14558v2>|- 问题：点云处理，任务独立，缺陷共存<br />- 方法：统一扩散模型，条件扩散框架，空间混合融合<br />- 效果：多任务处理，性能超越，效率提升|
|🆕 发布|Leveraging Text-to-Image Generation for Handling Spurious Correlation|利用文本到图像生成处理虚假相关性|Aryan Yazdan Parast, Basim Azam, Naveed Akhtar|<http://arxiv.org/pdf/2503.17226v1>|- 问题：泛化能力差，伪相关性，图像分类<br />- 方法：文本到图像生成，因果成分，语言分割<br />- 效果：准确率提升，泛化能力增强|
|🆕 发布|Deep End-to-End Posterior ENergy (DEEPEN) for image recovery|深度端到端后验能量（DEEPEN）用于图像恢复|Jyothi Rikhab Chand, Mathews Jacob|<http://arxiv.org/pdf/2503.17244v1>|- 问题：E2E图像重建，采样困难，训练复杂<br />- 方法：DEEPEN框架，MAP估计，采样<br />- 效果：性能提升，采样速度快|
|🆕 发布|UniCon: Unidirectional Information Flow for Effective Control of Large-Scale Diffusion Models|UniCon：大规模扩散模型有效控制的单向信息流|Fanghua Yu, Jinjin Gu, Jinfan Hu, Zheyuan Li, Chao Dong|<http://arxiv.org/pdf/2503.17221v1>|- 问题：控制，效率，大规模扩散模型，训练<br />- 方法：单向信息流，减少计算需求，参数体积加倍<br />- 效果：内存减少，速度提升，生成能力增强|
|📝 更新|UniCoRN: Latent Diffusion-based Unified Controllable Image Restoration Network across Multiple Degradations|基于潜在扩散的跨多种退化统一可控图像恢复网络：UniCoRN|Debabrata Mandal, Soumitri Chattopadhyay, Guansen Tong, Praneeth Chakravarthula|<http://arxiv.org/pdf/2503.15868v2>|[[代码]](<https://codejaeger.github.io/unicorn-gh>)<br />- 问题：单一退化处理，多退化同时处理<br />- 方法：多头扩散模型，低级视觉线索，混合专家策略<br />- 效果：性能提升，鲁棒恢复|
|🆕 发布|FreeUV: Ground-Truth-Free Realistic Facial UV Texture Recovery via Cross-Assembly Inference Strategy|FreeUV：基于跨组装推理策略的无真实UV纹理人脸恢复|Xingchao Yang, Takafumi Taketomi, Yuki Endo, Yoshihiro Kanamori|<http://arxiv.org/pdf/2503.17197v1>|- 问题：3D面部纹理恢复，数据限制，复杂细节<br />- 方法：无标注数据，跨组装推理，独立网络<br />- 效果：高保真，鲁棒性，新应用|
|🆕 发布|D2C: Unlocking the Potential of Continuous Autoregressive Image Generation with Discrete Tokens|D2C：利用离散标记解锁连续自回归图像生成的潜力|Panpan Wang, Liqiang Niu, Fandong Meng, Jinan Xu, Yufeng Chen, Jie Zhou|<http://arxiv.org/pdf/2503.17155v1>|- 问题：图像生成质量，效率，复杂性<br />- 方法：D2C模型，离散连续融合，两阶段生成<br />- 效果：性能优越，图像质量高|
|📝 更新|Self-supervised Monocular Depth Estimation Based on Hierarchical Feature-Guided Diffusion|基于分层特征引导扩散的单目深度估计|Runze Liu, Dongchen Zhu, Guanghui Zhang, Lei Wang, Jiamao Li|<http://arxiv.org/pdf/2406.09782v2>|- 问题：自监督单目深度估计，鲁棒性，图像噪声<br />- 方法：扩散模型，特征引导去噪，隐式深度一致性损失<br />- 效果：性能优异，鲁棒性强|
|🆕 发布|R2LDM: An Efficient 4D Radar Super-Resolution Framework Leveraging Diffusion Model|R2LDM：利用扩散模型的高效4D雷达超分辨率框架|Boyuan Zheng, Shouyi Lu, Renbo Huang, Minqing Huang, Fan Lu, Wei Tian, Guirong Zhuo, Lu Xiong|<http://arxiv.org/pdf/2503.17097v1>|- 问题：4D雷达超分辨率，点云生成，信息捕捉<br />- 方法：Voxel特征，LVDM，LPCR模块<br />- 效果：点云密度提升，任务性能改善|
|🆕 发布|DIDiffGes: Decoupled Semi-Implicit Diffusion Models for Real-time Gesture Generation from Speech|DIDiffGes：解耦半隐式扩散模型用于从语音中实时生成手势|Yongkang Cheng, Shaoli Huang, Xuelin Chen, Jifeng Ning, Mingming Gong|<http://arxiv.org/pdf/2503.17059v1>|[[代码]](<https://cyk990422.github.io/DIDiffGes.>)<br />- 问题：扩散模型采样复杂，实时性差<br />- 方法：解耦半隐式扩散模型，GANs，分解分布<br />- 效果：采样步骤减少，生成质量高|
|📝 更新|Diffusion Beats Autoregressive: An Evaluation of Compositional Generation in Text-to-Image Models|扩散模型胜过自回归：文本到图像模型中组合生成的评估|Arash Marioriyad, Parham Rezaei, Mahdieh Soleymani Baghshah, Mohammad Hossein Rohban|<http://arxiv.org/pdf/2410.22775v2>|- 问题：T2I模型，生成失败，细节捕捉<br />- 方法：FLUX模型，T2I-CompBench，对比评估<br />- 效果：LlamaGen不足，FLUX与DALL-E3相当|
|🆕 发布|Enabling Versatile Controls for Video Diffusion Models|视频扩散模型的多功能控制赋能|Xu Zhang, Hao Zhou, Haoming Qin, Xiaobin Lu, Jiaxing Yan, Guanzhong Wang, Zeyu Chen, Yi Liu|<http://arxiv.org/pdf/2503.16983v1>|[[代码]](<http://github.com/PaddlePaddle/PaddleMIX>)<br />- 问题：视频生成控制，时空属性，控制挑战<br />- 方法：VCtrl框架，条件模块，控制信号集成<br />- 效果：控制增强，生成质量提升|
|🆕 发布|ARFlow: Human Action-Reaction Flow Matching with Physical Guidance|ARFlow：基于物理引导的人体动作-反应流匹配|Wentao Jiang, Jingya Wang, Haotao Lu, Kaiyang Ji, Baoxiong Jia, Siyuan Huang, Ye Shi|<http://arxiv.org/pdf/2503.16973v1>|- 问题：动作-反应合成，模型复杂，物理违规<br />- 方法：ARFlow框架，x1预测，物理引导<br />- 效果：性能提升，碰撞减少|
|🆕 发布|MagicColor: Multi-Instance Sketch Colorization|魔彩：多实例草图着色|Yinhan Zhang, Yue Ma, Bingyuan Wang, Qifeng Chen, Zeyu Wang|<http://arxiv.org/pdf/2503.16948v1>|[[代码]](<https://yinhan-zhang.github.io/color>)<br />- 问题：多实例草图着色，数据收集困难，效率低<br />- 方法：自博弈训练，实例引导，细粒度颜色匹配<br />- 效果：自动化，一致性，精度高|
|📝 更新|Free-Lunch Color-Texture Disentanglement for Stylized Image Generation|免费午餐色彩纹理解耦用于风格化图像生成|Jiang Qin, Senmao Li, Alexandra Gomez-Villa, Shiqi Yang, Yaxing Wang, Kai Wang, Joost van de Weijer|<http://arxiv.org/pdf/2503.14275v2>|[[代码]](<https://deepffff.github.io/sadis.github.io>)<br />- 问题：风格定制，颜色纹理控制，风格元素独立<br />- 方法：CLIP图像嵌入，颜色纹理分离，RegWCT<br />- 效果：风格定制，纹理保真|
|🆕 发布|Re-HOLD: Video Hand Object Interaction Reenactment via adaptive Layout-instructed Diffusion Model|Re-HOLD：通过自适应布局指令扩散模型进行视频手部物体交互重演|Yingying Fan, Quanwei Yang, Kaisiyuan Wang, Hang Zhou, Yingying Li, Haocheng Feng, Yu Wu, Jingdong Wang|<http://arxiv.org/pdf/2503.16942v1>|[[代码]](<https://fyycs.github.io/Re-HOLD.>)<br />- 问题：手-物体交互，视频重演，布局指导，扩散模型<br />- 方法：自适应布局，交互纹理增强，记忆银行，布局调整<br />- 效果：性能提升，效果优于现有方法|
|📝 更新|You See it, You Got it: Learning 3D Creation on Pose-Free Videos at Scale|你看到它，你就得到了它：大规模学习无姿态视频上的3D创作|Baorui Ma, Huachen Gao, Haoge Deng, Zhengxiong Luo, Tiejun Huang, Lulu Tang, Xinlong Wang|<http://arxiv.org/pdf/2412.06699v3>|- 问题：3D生成，数据规模，标注成本，视觉条件<br />- 方法：数据清洗，时间依赖噪声，视觉条件生成<br />- 效果：零样本，开放世界，性能提升|
|📝 更新|Aligning Text to Image in Diffusion Models is Easier Than You Think|《在扩散模型中将文本对齐到图像比您想象的要简单》|Jaa-Yeon Lee, Byunghee Cha, Jeongsol Kim, Jong Chul Ye|<http://arxiv.org/pdf/2503.08250v3>|- 问题：文本图像对齐，表示对齐，残差误对齐<br />- 方法：对比学习，SoftREPA，软文本标记<br />- 效果：语义一致性增强，互信息增加|
|🆕 发布|When Preferences Diverge: Aligning Diffusion Models with Minority-Aware Adaptive DPO|当偏好分歧时：与少数族裔感知自适应DPO对齐扩散模型|Lingfan Zhang, Chen Liu, Chengming Xu, Kai Hu, Donghao Luo, Chengjie Wang, Yanwei Fu, Yuan Yao|<http://arxiv.org/pdf/2503.16921v1>|- 问题：偏好数据，模型性能，少数样本，主观性，挑战<br />- 方法：Adaptive-DPO，少数实例感知，DPO目标，损失函数<br />- 效果：模型改进，数据适应性，训练方法|
|📝 更新|OmniFlow: Any-to-Any Generation with Multi-Modal Rectified Flows|全流：多模态校正流的任意到任意生成|Shufan Li, Konstantinos Kallidromitis, Akash Gokul, Zichun Liao, Yusuke Kato, Kazuki Kozuka, Aditya Grover|<http://arxiv.org/pdf/2412.01169v2>|[[代码]](<https://github.com/jacklishufan/OmniFlows.>)<br />- 问题：多模态生成，模态对齐，性能优化<br />- 方法：多模态RF，指导机制，扩展MMDiT架构<br />- 效果：性能提升，灵活控制|
|📝 更新|Kiss3DGen: Repurposing Image Diffusion Models for 3D Asset Generation|Kiss3DGen：重用图像扩散模型进行3D资产生成|Jiantao Lin, Xin Yang, Meixi Chen, Yingjie Xu, Dongyu Yan, Leyi Wu, Xinli Xu, Lie XU .etc.|<http://arxiv.org/pdf/2503.01370v2>|- 问题：3D内容生成，质量有限，泛化性差，数据收集难<br />- 方法：2D扩散模型，3D Bundle Image，多视图图像，纹理映射<br />- 效果：高效生成，高质量，3D编辑|
|📝 更新|PersonaBooth: Personalized Text-to-Motion Generation|个性化文本到动作生成：PersonaBooth|Boeun Kim, Hea In Jeong, JungHoon Sung, Yihua Cheng, Jeongmin Lee, Ju Yong Chang, Sang-Il Choi, Younggeun Choi .etc.|<http://arxiv.org/pdf/2503.07390v3>|- 问题：个性化动作生成，数据分布，一致性捕捉<br />- 方法：PerMo数据集，PersonaBooth模型，对比学习，上下文融合<br />- 效果：超越现有方法，新基准|
|🆕 发布|Safe and Reliable Diffusion Models via Subspace Projection|通过子空间投影实现的安全可靠扩散模型|Huiqiang Chen, Tianqing Zhu, Linlin Wang, Xin Yu, Longxiang Gao, Wanlei Zhou|<http://arxiv.org/pdf/2503.16835v1>|- 问题：不适当内容生成，概念残留，文本到图像模型<br />- 方法：子空间投影，文本逆变换，子空间扩展<br />- 效果：概念移除，生成质量保留|
|🆕 发布|Auto-Regressive Diffusion for Generating 3D Human-Object Interactions|自回归扩散生成3D人-物交互|Zichen Geng, Zeeshan Hayder, Wei Liu, Ajmal Saeed Mian|<http://arxiv.org/pdf/2503.16801v1>|- 问题：HOI生成，一致性，长序列<br />- 方法：自回归扩散模型，cVAE，Mamba编码器<br />- 效果：性能提升，速度优化|


### 生成对抗网络 (GANs)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Position: Interactive Generative Video as Next-Generation Game Engine|交互式生成视频：下一代游戏引擎的位置|Jiwen Yu, Yiran Qin, Haoxuan Che, Quande Liu, Xintao Wang, Pengfei Wan, Di Zhang, Xihui Liu|<http://arxiv.org/pdf/2503.17359v1>|- 问题：传统游戏引擎内容限制，成本高<br />- 方法：交互式生成视频，生成游戏引擎<br />- 效果：内容无限，交互性强|
|🆕 发布|Vision Transformer Based Semantic Communications for Next Generation Wireless Networks|基于视觉Transformer的下一代无线网络语义通信|Muhammad Ahmed Mohsin, Muhammad Jazib, Zeeshan Alam, Muhmmad Farhan Khan, Muhammad Saad, Muhammad Ali Jamshed|<http://arxiv.org/pdf/2503.17275v1>|- 问题：语义通信，带宽需求，图像传输<br />- 方法：ViT架构，编码器-解码器，注意力机制<br />- 效果：高PSNR，语义相似性，突破|
|🆕 发布|Neuro-Symbolic Scene Graph Conditioning for Synthetic Image Dataset Generation|神经符号场景图条件化用于合成图像数据集生成|Giacomo Savazzi, Eugenio Lomurno, Cristian Sbrolli, Agnese Chiatti, Matteo Matteucci|<http://arxiv.org/pdf/2503.17224v1>|- 问题：数据稀缺，合成数据质量差，神经符号方法<br />- 方法：神经符号条件化，场景图表示，关系约束编码<br />- 效果：性能提升，结构信息增强|
|📝 更新|Data-driven Camera and Lidar Simulation Models for Autonomous Driving: A Review from Generative Models to Volume Renderers|基于数据驱动的自动驾驶汽车摄像头和激光雷达仿真模型：从生成模型到体渲染器的综述|Hamed Haghighi, Xiaomeng Wang, Hao Jing, Mehrdad Dianati|<http://arxiv.org/pdf/2402.10079v2>|- 问题：传感器模拟，自动驾驶，数据驱动，生成模型，体积渲染<br />- 方法：深度学习，数据驱动，生成模型，体积渲染<br />- 效果：模型性能提升，数据集合成|
|🆕 发布|Enhancing Steering Estimation with Semantic-Aware GNNs|基于语义感知图神经网络增强转向估计|Fouad Makiyeh, Huy-Dung Nguyen, Patrick Chareyre, Ramin Hasani, Marc Blanchon, Daniela Rus|<http://arxiv.org/pdf/2503.17153v1>|- 问题：转向估计，2D模型，3D空间信息<br />- 方法：语义感知GNN，RNN，伪3D点云，语义标签，高效连接策略<br />- 效果：性能提升，成本效益|
|🆕 发布|Missing Target-Relevant Information Prediction with World Model for Accurate Zero-Shot Composed Image Retrieval|基于世界模型的缺失目标相关信息预测，以实现准确的零样本组合图像检索|Yuanmin Tang, Jing Yu, Keke Gai, Jiamin Zhuang, Gang Xiong, Gaopeng Gou, Qi Wu|<http://arxiv.org/pdf/2503.17109v1>|[[代码]](<https://github.com/Pter61/predicir.>)<br />- 问题：ZS-CIR，参考图像，目标内容，缺失信息<br />- 方法：PrediCIR，世界模型，预测网络<br />- 效果：性能提升，新SOTA|
|📝 更新|WAIT: Feature Warping for Animation to Illustration video Translation using GANs|等待：基于GAN的动画到插画视频翻译的特征扭曲|Samet Hicsonmez, Nermin Samet, Fidan Samet, Oguz Bakir, Emre Akbas, Pinar Duygulu|<http://arxiv.org/pdf/2310.04901v2>|[[代码]](<https://github.com/giddyyupp/wait.>)<br />- 问题：视频风格迁移，无序图像，风格一致性<br />- 方法：特征扭曲，生成网络，GANs<br />- 效果：风格一致，效果显著|
|🆕 发布|AnimatePainter: A Self-Supervised Rendering Framework for Reconstructing Painting Process|AnimatePainter：一种用于重建绘画过程的自我监督渲染框架|Junjie Hu, Shuyong Gao, Qianyu Guo, Yan Wang, Qishan Wang, Yuang Feng, Wenqiang Zhang|<http://arxiv.org/pdf/2503.17029v1>|- 问题：绘画过程重建，数据依赖，深度学习<br />- 方法：自监督框架，深度融合，视频生成<br />- 效果：无数据，真实感强|
|🆕 发布|HyperLoRA: Parameter-Efficient Adaptive Generation for Portrait Synthesis|超低参数自适应生成用于人像合成|Mengtian Li, Jinshu Chen, Wanquan Feng, Bingchuan Li, Fei Dai, Songtao Zhao, Qian He|<http://arxiv.org/pdf/2503.16944v1>|- 问题：个性化肖像合成，资源消耗，自然性不足<br />- 方法：HyperLoRA，自适应插件网络，LoRA权重生成<br />- 效果：零样本生成，高保真，可编辑|
|🆕 发布|Generative Compositor for Few-Shot Visual Information Extraction|生成式少样本视觉信息提取合成器|Zhibo Yang, Wei Hua, Sibo Song, Cong Yao, Yingying Zhu, Wenqing Cheng, Xiang Bai|<http://arxiv.org/pdf/2503.16854v1>|- 问题：少样本，视觉信息提取，数据缺乏<br />- 方法：Generative Compositor，指针生成网络，预训练策略<br />- 效果：高性能，超越基线|


### 自回归模型 (Autoregressive Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Zero-Shot Styled Text Image Generation, but Make It Autoregressive|零样本风格化文本图像生成，但让它自回归|Vittorio Pippi, Fabio Quattrini, Silvia Cascianelli, Alessio Tonioni, Rita Cucchiara|<http://arxiv.org/pdf/2503.17074v1>|- 问题：风格泛化，技术限制，输出长度，训练效率<br />- 方法：Emuru框架，变分自编码器，自回归Transformer<br />- 效果：零样本泛化，无背景噪声，效果显著|


## 多模态学习 (Multimodal Learning)


### 视觉语言模型 (Vision-Language Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Beyond Semantics: Rediscovering Spatial Awareness in Vision-Language Models|超越语义：在视觉-语言模型中重新发现空间感知|Jianing Qi, Jiawei Liu, Hao Tang, Zhigang Zhu|<http://arxiv.org/pdf/2503.17349v1>|- 问题：VLMs，空间推理，语义，位置信息<br />- 方法：双路径模型，可解释性分析，干预措施<br />- 效果：空间推理能力提升，可解释性设计|
|🆕 发布|OpenVLThinker: An Early Exploration to Complex Vision-Language Reasoning via Iterative Self-Improvement|开放VLThinker：通过迭代自我改进对复杂视觉-语言推理的早期探索|Yihe Deng, Hritik Bansal, Fan Yin, Nanyun Peng, Wei Wang, Kai-Wei Chang|<http://arxiv.org/pdf/2503.17352v1>|[[代码]](<https://github.com/yihedeng9/OpenVLThinker.>)<br />- 问题：复杂视觉语言推理，模型性能提升<br />- 方法：迭代自改进，监督微调，强化学习<br />- 效果：推理性能提升，鲁棒性增强|
|📝 更新|TruthPrInt: Mitigating LVLM Object Hallucination Via Latent Truthful-Guided Pre-Intervention|TruthPrInt：通过潜在真实引导预干预减轻LVLM对象幻觉|Jinhao Duan, Fei Kong, Hao Cheng, James Diffenderfer, Bhavya Kailkhura, Lichao Sun, Xiaofeng Zhu, Xiaoshuang Shi .etc.|<http://arxiv.org/pdf/2503.10602v2>|[[代码]](<https://github.com/jinhaoduan/TruthPrInt.>)<br />- 问题：LVLM对象幻觉，内部状态，幻觉指标<br />- 方法：TruthPrInt，真实引导预干预，ComnHallu<br />- 效果：显著优于，幻觉检测|
|🆕 发布|Slide-Level Prompt Learning with Vision Language Models for Few-Shot Multiple Instance Learning in Histopathology|基于视觉语言模型的病理学少样本多实例学习中的幻灯片级提示学习|Devavrat Tomar, Guillaume Vray, Dwarikanath Mahapatra, Sudipta Roy, Jean-Philippe Thiran, Behzad Bozorgtabar|<http://arxiv.org/pdf/2503.17238v1>|[[代码]](<https://github.com/LTS5/SLIP.>)<br />- 问题：少样本分类，病理图像，多实例学习<br />- 方法：视觉语言模型，提示学习，病理先验知识<br />- 效果：性能优越，少样本学习|
|📝 更新|Code-as-Monitor: Constraint-aware Visual Programming for Reactive and Proactive Robotic Failure Detection|代码即监控：用于反应性和主动式机器人故障检测的约束感知视觉编程|Enshen Zhou, Qi Su, Cheng Chi, Zhizheng Zhang, Zhongyuan Wang, Tiejun Huang, Lu Sheng, He Wang|<http://arxiv.org/pdf/2412.04455v3>|- 问题：机器人故障检测，反应性，预防性<br />- 方法：Code-as-Monitor，VLM，时空约束<br />- 效果：成功率提升，执行时间减少|
|🆕 发布|PP-DocLayout: A Unified Document Layout Detection Model to Accelerate Large-Scale Data Construction|PP-DocLayout：一种用于加速大规模数据构建的统一文档布局检测模型|Ting Sun, Cheng Cui, Yuning Du, Yi Liu|<http://arxiv.org/pdf/2503.17213v1>|[[代码]](<https://github.com/PaddlePaddle/PaddleX>)<br />- 问题：文档布局检测，泛化能力，复杂布局，实时性能<br />- 方法：PP-DocLayout模型，多尺度模型，高效推理<br />- 效果：高精度，低延迟，数据构建|
|📝 更新|GiVE: Guiding Visual Encoder to Perceive Overlooked Information|GiVE：引导视觉编码器感知被忽视的信息|Junjie Li, Jianghong Ma, Xiaofeng Zhang, Yuhang Li, Jianyang Shi|<http://arxiv.org/pdf/2410.20109v2>|- 问题：语义对齐，非显著物体，视觉编码器<br />- 方法：AG-Adapter，视觉语义学习，OITC，OIIC，OID<br />- 效果：性能提升，状态艺术|
|📝 更新|VASparse: Towards Efficient Visual Hallucination Mitigation via Visual-Aware Token Sparsification|VASparse：通过视觉感知的Token稀疏化实现高效视觉幻觉缓解|Xianwei Zhuang, Zhihong Zhu, Yuxin Xie, Liming Liang, Yuexian Zou|<http://arxiv.org/pdf/2501.06553v2>|[[代码]](<https://github.com/mengchuang123/VASparse-github.>)<br />- 问题：视觉幻觉，解码速度慢，效率低<br />- 方法：视觉感知稀疏化，对比学习，注意力调整<br />- 效果：性能提升，速度优化|
|📝 更新|EgoTextVQA: Towards Egocentric Scene-Text Aware Video Question Answering|自我视角场景文本感知视频问答|Sheng Zhou, Junbin Xiao, Qingyun Li, Yicong Li, Xun Yang, Dan Guo, Meng Wang, Tat-Seng Chua .etc.|<http://arxiv.org/pdf/2502.07411v2>|[[代码]](<https://github.com/zhousheng97/EgoTextVQA.>)<br />- 问题：egocentric QA，scene text，动态环境<br />- 方法：EgoTextVQA，multimodal LLM，时序推理<br />- 效果：性能评估，准确率33%，关键因素|
|🆕 发布|Not Only Text: Exploring Compositionality of Visual Representations in Vision-Language Models|不仅仅是文本：探索视觉语言模型中视觉表示的组合性|Davide Berasi, Matteo Farina, Massimiliano Mancini, Elisa Ricci, Nicola Strisciuglio|<http://arxiv.org/pdf/2503.17142v1>|[[代码]](<https://github.com/BerasiDavide/vlm_image_compositionality.>)<br />- 问题：VLMs，视觉表示，组合性，噪声，稀疏性<br />- 方法：GDE，几何感知，组合结构<br />- 效果：组合分类，组鲁棒性，性能提升|
|📝 更新|UVE: Are MLLMs Unified Evaluators for AI-Generated Videos?|UVE：MLLMs是AI生成视频的统一评估器吗？|Yuanxin Liu, Rui Zhu, Shuhuai Ren, Jiacong Wang, Haoyuan Guo, Xu Sun, Lu Jiang|<http://arxiv.org/pdf/2503.09949v2>|[[代码]](<https://github.com/bytedance/UVE.>)<br />- 问题：AI视频评估，MLLMs，统一评估<br />- 方法：UVE-Bench，多方面评估，MLLMs应用<br />- 效果：超越现有方法，性能提升|
|📝 更新|Dynamic-LLaVA: Efficient Multimodal Large Language Models via Dynamic Vision-language Context Sparsification|动态-LLaVA：通过动态视觉-语言上下文稀疏化的高效多模态大型语言模型|Wenxuan Huang, Zijie Zhai, Yunhang Shen, Shaosheng Cao, Fei Zhao, Xiangfeng Xu, Zheyu Ye, Yao Hu .etc.|<http://arxiv.org/pdf/2412.00876v4>|[[代码]](<https://github.com/Osilly/dynamic_llava>)<br />- 问题：MLLMs效率低，冗余高<br />- 方法：动态视觉语言上下文稀疏化，定制化稀疏推理<br />- 效果：计算消耗降低，性能提升|
|🆕 发布|Beyond Accuracy: What Matters in Designing Well-Behaved Models?|超越准确性：设计良好行为模型的关键因素是什么？|Robin Hesse, Doğukan Bağcı, Bernt Schiele, Simone Schaub-Meyer, Stefan Roth|<http://arxiv.org/pdf/2503.17110v1>|- 问题：模型行为，质量维度，DNN<br />- 方法：多维度研究，大规模分析，QUBA评分<br />- 效果：新见解，模型排名，定制推荐|
|🆕 发布|Seeing What Matters: Empowering CLIP with Patch Generation-to-Selection|看见重要的事物：通过Patch生成到选择的增强CLIP|Gensheng Pei, Tao Chen, Yujia Wang, Xinhao Cai, Xiangbo Shu, Tianfei Zhou, Yazhou Yao|<http://arxiv.org/pdf/2503.17080v1>|- 问题：CLIP训练效率低，语义信息丢失<br />- 方法：Patch Generation-to-Selection，Sobel边缘检测，相似度计算<br />- 效果：零样本分类，检索性能提升|
|📝 更新|SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models|SPHINX-X：扩展多模态大型语言模型家族的数据和参数|Dongyang Liu, Renrui Zhang, Longtian Qiu, Siyuan Huang, Weifeng Lin, Shitian Zhao, Shijie Geng, Ziyi Lin .etc.|<http://arxiv.org/pdf/2402.05935v3>|[[代码]](<https://github.com/Alpha-VLLM/LLaMA2-Accessory>)<br />- 问题：多模态大语言模型，数据与参数扩展<br />- 方法：SPHINX框架改进，多模态数据集，多语言能力<br />- 效果：性能提升，数据与参数规模相关|
|📝 更新|Surgical Text-to-Image Generation|手术文本到图像生成|Chinedu Innocent Nwoye, Rupak Bose, Kareem Elgohary, Lorenzo Arboit, Giorgio Carlino, Joël L. Lavanchy, Pietro Mascagni, Nicolas Padoy|<http://arxiv.org/pdf/2407.09230v3>|- 问题：高成本，伦理限制，数据获取难<br />- 方法：T5模型，文本嵌入，类平衡技术<br />- 效果：高保真，强对齐|
|📝 更新|Morphing Tokens Draw Strong Masked Image Models|形态化令牌绘制强大的掩码图像模型|Taekyung Kim, Byeongho Heo, Dongyoon Han|<http://arxiv.org/pdf/2401.00254v4>|- 问题：MIM，空间不一致，监督信号，表示学习<br />- 方法：动态Token Morphing，DTM，上下文生成<br />- 效果：MIM结果提升，迁移学习，实验证明|
|🆕 发布|PE-CLIP: A Parameter-Efficient Fine-Tuning of Vision Language Models for Dynamic Facial Expression Recognition|PE-CLIP：一种用于动态面部表情识别的参数高效视觉语言模型微调|Ibtissam Saadi, Abdenour Hadid, Douglas W. Cunningham, Abdelmalik Taleb-Ahmed, Yassin El Hillali|<http://arxiv.org/pdf/2503.16945v1>|[[代码]](<https://github.com/Ibtissam-SAADI/PE-CLIP>)<br />- 问题：DFER，VLMs，全微调，复杂度，时序建模<br />- 方法：PEFT，TDA，ShA，MaPLe，可学习提示<br />- 效果：参数高效，高精度，资源高效|
|🆕 发布|TEMPO: Temporal Preference Optimization of Video LLMs via Difficulty Scheduling and Pre-SFT Alignment|TEMPO：通过难度调度和预SFT对齐优化视频LLMs的时间偏好|Shicheng Li, Lei Li, Kun Ouyang, Shuhuai Ren, Yuanxin Liu, Yuanxing Zhang, Fuzheng Zhang, Lingpeng Kong .etc.|<http://arxiv.org/pdf/2503.16929v1>|- 问题：时间推理，数据对应弱，预测范式<br />- 方法：DPO，偏好数据生成，课程学习，Pre-SFT对齐<br />- 效果：性能提升，可扩展|
|🆕 发布|Vision-Language Gradient Descent-driven All-in-One Deep Unfolding Networks|视觉-语言梯度下降驱动的全融合深度展开网络|Haijin Zeng, Xiangming Wang, Yongyong Chen, Jingyong Su, Jie Liu|<http://arxiv.org/pdf/2503.16930v1>|- 问题：图像退化，DUNs局限性，手动选择退化矩阵<br />- 方法：VLM，自动梯度估计，多退化处理<br />- 效果：性能提升，SOTS 3.74 dB，Rain100L 1.70 dB|
|📝 更新|Activating Distributed Visual Region within LLMs for Efficient and Effective Vision-Language Training and Inference|激活LLMs中的分布式视觉区域以实现高效且有效的视觉-语言训练和推理|Siyuan Wang, Dianyi Wang, Chengxing Zhou, Zejun Li, Zhihao Fan, Xuanjing Huang, Zhongyu Wei|<http://arxiv.org/pdf/2412.12785v2>|- 问题：LVLMs训练，视觉能力，效率，效果<br />- 方法：视觉区域，选择性层调优，层剪枝<br />- 效果：性能保持，训练时间减少|
|📝 更新|OpenRSD: Towards Open-prompts for Object Detection in Remote Sensing Images|开放RSD：面向遥感图像目标检测的开放提示|Ziyue Huang, Yongchao Feng, Shuai Yang, Ziqi Liu, Qingjie Liu, Yunhong Wang|<http://arxiv.org/pdf/2503.06146v2>|- 问题：封闭集检测，数据集规模小，遥感图像解释挑战<br />- 方法：开放提示，多任务检测头，多阶段训练<br />- 效果：精度高，实时性强|
|🆕 发布|Classifier-guided CLIP Distillation for Unsupervised Multi-label Classification|基于分类器的CLIP蒸馏用于无监督多标签分类|Dongseob Kim, Hyunjung Shim|<http://arxiv.org/pdf/2503.16873v1>|[[代码]](<https://github.com/k0u-id/CCD.>)<br />- 问题：多标签分类，标注困难，CLIP偏差<br />- 方法：分类器引导，多视角，去偏伪标签<br />- 效果：性能提升，效果验证|
|📝 更新|MBQ: Modality-Balanced Quantization for Large Vision-Language Models|模态平衡量化：大型视觉-语言模型的量化方法|Shiyao Li, Yingchun Hu, Xuefei Ning, Xihui Liu, Ke Hong, Xiaotao Jia, Xiuhong Li, Yaqi Yan .etc.|<http://arxiv.org/pdf/2412.19509v2>|[[代码]](<https://github.com/thu-nics/MBQ.>)<br />- 问题：VLMs部署，PTQ，模态差异<br />- 方法：MBQ，模态平衡，敏感度校正<br />- 效果：精度提升，速度提升|
|🆕 发布|Joint Extraction Matters: Prompt-Based Visual Question Answering for Multi-Field Document Information Extraction|联合提取至关重要：基于提示的多字段文档信息提取的视觉问答|Mengsay Loem, Taiju Hosaka|<http://arxiv.org/pdf/2503.16868v1>|- 问题：独立提取，忽略依赖，信息提取<br />- 方法：联合提取，回归度量，多字段提示<br />- 效果：精度提升，减少混淆|
|🆕 发布|LoRASculpt: Sculpting LoRA for Harmonizing General and Specialized Knowledge in Multimodal Large Language Models|LoRASculpt：在多模态大型语言模型中调和通用与专业知识之LoRA的雕塑|Jian Liang, Wenke Huang, Guancheng Wan, Qu Yang, Mang Ye|<http://arxiv.org/pdf/2503.16843v1>|- 问题：MLLMs，知识融合，遗忘问题，LoRA<br />- 方法：LoRASculpt，稀疏更新，冲突缓解正则化<br />- 效果：知识和谐，泛化增强，性能提升|
|📝 更新|SeqAfford: Sequential 3D Affordance Reasoning via Multimodal Large Language Model|SeqAfford：基于多模态大型语言模型的序列3D可及性推理|Chunlin Yu, Hanqing Wang, Ye Shi, Haoyang Luo, Sibei Yang, Jingyi Yu, Jingya Wang|<http://arxiv.org/pdf/2412.01550v3>|- 问题：3D affordance segmentation，单对象，长时任务，复杂意图<br />- 方法：Sequential 3D Affordance Reasoning，多模态LGM，多粒度语言点集成<br />- 效果：超越现有方法，开放世界泛化|
|📝 更新|Mitigating Hallucinations in Multimodal Spatial Relations through Constraint-Aware Prompting|通过约束感知提示减轻多模态空间关系中的幻觉|Jiarui Wu, Zhuo Liu, Hangfeng He|<http://arxiv.org/pdf/2502.08317v2>|- 问题：空间关系幻觉，预测错误，模型挑战<br />- 方法：约束感知提示，双向约束，传递性约束<br />- 效果：性能提升，输出一致|
|📝 更新|Too Many Frames, Not All Useful: Efficient Strategies for Long-Form Video QA|太多帧，并非全部有用：长视频问答中的高效策略|Jongwoo Park, Kanchana Ranasinghe, Kumara Kahatapitiya, Wonjeong Ryu, Donghyun Kim, Michael S. Ryoo|<http://arxiv.org/pdf/2406.09396v5>|[[代码]](<https://github.com/jongwoopark7978/LVNet.>)<br />- 问题：长视频问答，信息冗余，帧选择<br />- 方法：关键帧选择，Hierarchical Keyframe Selector，LVNet<br />- 效果：性能提升，效率提高|
|📝 更新|Enhancing Zero-Shot Image Recognition in Vision-Language Models through Human-like Concept Guidance|通过人类似概念引导增强视觉-语言模型中的零样本图像识别|Hui Liu, Wenya Wang, Kecheng Chen, Jie Liu, Yibing Liu, Tiexin Qin, Peisong He, Xinghao Jiang .etc.|<http://arxiv.org/pdf/2503.15886v2>|- 问题：零样本图像识别，VLM性能不足，prompt工程，适应性差<br />- 方法：CHBR框架，贝叶斯推理，重要性采样，LLM生成概念<br />- 效果：超越现有方法，泛化能力强|
|📝 更新|Towards Self-Improving Systematic Cognition for Next-Generation Foundation MLLMs|迈向下一代基础多语言LLMs的自改进系统性认知|Xiaoying Zhang, Da Peng, Yipeng Zhang, Zonghao Guo, Chengyue Wu, Chi Chen, Wei Ke, Helen Meng .etc.|<http://arxiv.org/pdf/2503.12303v4>|- 问题：MLLMs感知与推理，预训练方法，输出准确性<br />- 方法：Self-Improving cognition，Chain-of-Description，CoT reasoning<br />- 效果：认知能力提升，基准性能领先|
|🆕 发布|A-IDE : Agent-Integrated Denoising Experts|A-IDE：集成智能体的去噪专家|Uihyun Cho, Namhun Kim|<http://arxiv.org/pdf/2503.16780v1>|- 问题：低剂量CT图像去噪，模型泛化能力差<br />- 方法：A-IDE框架，区域专用模型，决策型代理<br />- 效果：性能提升，RMSE，PSNR，SSIM|
|📝 更新|GET: Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery|GET：解锁CLIP在泛化类别发现中的多模态潜力|Enguang Wang, Zhimao Peng, Zhengyuan Xie, Fei Yang, Xialei Liu, Ming-Ming Cheng|<http://arxiv.org/pdf/2403.09974v3>|[[代码]](<https://github.com/enguangW/GET.>)<br />- 问题：GCD，多模态，分类，文本信息，无标签数据<br />- 方法：TES，CLIP，视觉-文本特征，双分支框架<br />- 效果：多模态潜力，SOTA，性能提升|
|🆕 发布|OpenCity3D: What do Vision-Language Models know about Urban Environments?|OpenCity3D：视觉-语言模型了解多少关于城市环境的信息？|Valentin Bieri, Marco Zamboni, Nicolas S. Blumer, Qingxuan Chen, Francis Engelmann|<http://arxiv.org/pdf/2503.16776v1>|- 问题：VLMs应用局限，3D场景理解，城市环境<br />- 方法：OpenCity3D，多视角重建，高级任务<br />- 效果：零样本，少样本，适应性强|
|📝 更新|ChatBEV: A Visual Language Model that Understands BEV Maps|ChatBEV：一种理解BEV地图的可视语言模型|Qingyao Xu, Siheng Chen, Guang Chen, Yanfeng Wang, Ya Zhang|<http://arxiv.org/pdf/2503.13938v2>|- 问题：交通场景理解，BEV地图应用，数据量不足<br />- 方法：ChatBEV-QA基准，数据收集管道，语言驱动场景生成<br />- 效果：场景理解，导航指导|


### 多模态融合 (Multimodal Fusion)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Adapting to the Unknown: Training-Free Audio-Visual Event Perception with Dynamic Thresholds|适应未知：无需训练的动态阈值音频-视觉事件感知|Eitan Shaar, Ariel Shaulov, Gal Chechik, Lior Wolf|<http://arxiv.org/pdf/2503.13693v2>|- 问题：泛化能力差，标注困难，动态变化忽略，融合损失<br />- 方法：无监督学习，动态阈值，自适应分析<br />- 效果：性能提升，泛化能力强|
|📝 更新|United we stand, Divided we fall: Handling Weak Complementary Relationships for Audio-Visual Emotion Recognition in Valence-Arousal Space|团结则立，分裂则亡：处理在效价-唤醒空间中音频-视觉情感识别的弱互补关系|R. Gnana Praveen, Jahangir Alam, Eric Charton|<http://arxiv.org/pdf/2503.12261v2>|- 问题：弱互补关系，音频-视觉情感识别，特征表示<br />- 方法：GRJCA，门控机制，迭代控制<br />- 效果：CCC提升，鲁棒性增强|
|🆕 发布|Depth-Aided Color Image Inpainting in Quaternion Domain|四元数域中的深度辅助彩色图像修复|Shunki Tatsumi, Ryo Hayakawa, Youji Iiguni|<http://arxiv.org/pdf/2503.16818v1>|- 问题：图像修复，深度信息，四元数域<br />- 方法：深度辅助，低秩四元数矩阵补全<br />- 效果：修复精度提升，视觉效果改善|


### 跨模态对齐 (Cross-modal Alignment)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Align Your Rhythm: Generating Highly Aligned Dance Poses with Gating-Enhanced Rhythm-Aware Feature Representation|对齐你的节奏：通过门控增强的节奏感知特征表示生成高度对齐的舞蹈姿态|Congyi Fan, Jian Guan, Xuanjia Zhao, Dongli Xu, Youtian Lin, Tong Ye, Pengming Feng, Haiwei Pan|<http://arxiv.org/pdf/2503.17340v1>|- 问题：音乐驱动舞蹈生成，节奏对齐，运动自然性<br />- 方法：相位节奏提取，时序门控注意力，并行运动建模<br />- 效果：节奏对齐，运动多样性|
|🆕 发布|The CASTLE 2024 Dataset: Advancing the Art of Multimodal Understanding|《CASTLE 2024 数据集：推动多模态理解艺术的进步》|Luca Rossetto, Werner Bailer, Duc-Tien Dang-Nguyen, Graham Healy, Björn Þór Jónsson, Onanong Kongmeesub, Hoang-Bao Le, Stevan Rudinac .etc.|<http://arxiv.org/pdf/2503.17116v1>|[[代码]](<https://castle-dataset.github.io/.>)<br />- 问题：单一视角，数据有限，视角受限<br />- 方法：多模态数据，多视角视频，无遮挡<br />- 效果：数据丰富，视角全面|
|📝 更新|T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting|T2ICount：提升零样本计数中的跨模态理解|Yifei Qian, Zhongliang Guo, Bowen Deng, Chun Tong Lei, Shuai Zhao, Chun Pong Lau, Xiaopeng Hong, Michael P. Pound|<http://arxiv.org/pdf/2502.20625v2>|[[代码]](<https://github.com/cha15yq/T2ICount.>)<br />- 问题：零样本计数，文本敏感性，跨模态理解<br />- 方法：扩散模型，语义校正模块，区域一致性损失<br />- 效果：性能提升，基准测试|
|📝 更新|Exploring Part-Informed Visual-Language Learning for Person Re-Identification|探索基于部分信息视觉-语言学习的人脸重识别|Yin Lin, Yehansen Chen, Baocai Yin, Jinshui Hu, Bing Yin, Cong Liu, Zengfu Wang|<http://arxiv.org/pdf/2308.02738v2>|- 问题：VLL ReID，特征一致性，局部特征<br />- 方法：Part-Informed VLL，prompt tuning，视觉语言对齐<br />- 效果：性能提升，高Rank-1，高mAP|
|🆕 发布|A Tale of Two Classes: Adapting Supervised Contrastive Learning to Binary Imbalanced Datasets|两个类别的故事：将监督对比学习适应二分类不平衡数据集|David Mildenberger, Paul Hager, Daniel Rueckert, Martin J Menten|<http://arxiv.org/pdf/2503.17024v1>|- 问题：SupCon，不平衡数据集，表示空间缺陷<br />- 方法：新指标，定制策略<br />- 效果：性能提升，准确率提高|
|🆕 发布|City2Scene: Improving Acoustic Scene Classification with City Features|城市2场景：利用城市特征提升声景分类|Yiqiang Cai, Yizhou Tan, Peihong Zhang, Yuxuan Liu, Shengchen Li, Xi Shao, Mark D. Plumbley|<http://arxiv.org/pdf/2503.16862v1>|- 问题：声景分类，城市特征，泛化能力<br />- 方法：知识蒸馏，城市分类模型，声景模型<br />- 效果：精度提升，CNN，Transformer|
|🆕 发布|ETVA: Evaluation of Text-to-Video Alignment via Fine-grained Question Generation and Answering|ETVA：通过细粒度问题生成和回答评估文本到视频对齐|Kaisi Guan, Zhengfeng Lai, Yuchong Sun, Peng Zhang, Wei Liu, Kieran Liu, Meng Cao, Ruihua Song|<http://arxiv.org/pdf/2503.16867v1>|- 问题：T2V对齐评估，粗粒度，人类偏好<br />- 方法：多代理系统，语义场景图，知识增强推理<br />- 效果：高相关性，基准数据集|
|🆕 发布|Joint Self-Supervised Video Alignment and Action Segmentation|联合自监督视频对齐和动作分割|Ali Shah Ali, Syed Ahmed Mahmood, Mubin Saeed, Andrey Konin, M. Zeeshan Zia, Quoc-Huy Tran|<http://arxiv.org/pdf/2503.16832v1>|- 问题：视频对齐，动作分割<br />- 方法：统一最优传输框架，融合Gromov-Wasserstein<br />- 效果：性能提升，时间内存节省|


## 目标检测识别 (Object Detection & Recognition)


### 二维检测 (2D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|An Iterative Feedback Mechanism for Improving Natural Language Class Descriptions in Open-Vocabulary Object Detection|开放词汇目标检测中改进自然语言类别描述的迭代反馈机制|Louis Y. Kim, Michelle Karker, Victoria Valledor, Seiyoung C. Lee, Karl F. Brzoska, Margaret Duff, Anthony Palladino|<http://arxiv.org/pdf/2503.17285v1>|- 问题：自然语言描述，目标检测，开放词汇，非技术用户<br />- 方法：文本嵌入分析，对比示例，迭代反馈<br />- 效果：性能提升，模型适用性|
|🆕 发布|MSCA-Net:Multi-Scale Context Aggregation Network for Infrared Small Target Detection|多尺度上下文聚合网络用于红外小目标检测（MSCA-Net）|Xiaojin Lu, Taoran yue, Jiaxi cai, Shibing Chu|<http://arxiv.org/pdf/2503.17193v1>|- 问题：红外小目标检测，低对比度，高噪声<br />- 方法：多尺度特征融合，PCBAM，通道聚合<br />- 效果：高mIoU，复杂背景检测|
|🆕 发布|D2Fusion: Dual-domain Fusion with Feature Superposition for Deepfake Detection|D2Fusion：基于特征叠加的双域融合深度伪造检测|Xueqi Qiu, Xingyu Miao, Fan Wan, Haoran Duan, Tejal Shah, Varun Ojhab, Yang Longa, Rajiv Ranjan|<http://arxiv.org/pdf/2503.17184v1>|- 问题：Deepfake检测，领域信息，融合不足<br />- 方法：双向注意力，频率注意力，特征叠加<br />- 效果：性能提升，异常捕捉|
|🆕 发布|Exploring Few-Shot Object Detection on Blood Smear Images: A Case Study of Leukocytes and Schistocytes|探索血涂片图像上的少样本目标检测：白细胞和裂体细胞案例分析|Davide Antonio Mura, Michela Pinna, Lorenzo Putzu, Andrea Loddo, Alessandra Perniciano, Olga Mulas, Cecilia Di Ruberto|<http://arxiv.org/pdf/2503.17107v1>|- 问题：血细胞检测，少量样本，自动计数<br />- 方法：DE-ViT模型，Few-Shot学习，数据集<br />- 效果：性能提升，域偏移|
|🆕 发布|Superpowering Open-Vocabulary Object Detectors for X-ray Vision|超级赋能开放词汇X射线视觉目标检测器|Pablo Garcia-Fernandez, Lorenzo Vaquero, Mingxuan Liu, Feng Xue, Daniel Cores, Nicu Sebe, Manuel Mucientes, Elisa Ricci|<http://arxiv.org/pdf/2503.17071v1>|[[代码]](<https://github.com/PAGF188/RAXO.>)<br />- 问题：OvOD，X射线，数据稀缺，模态差距<br />- 方法：RAXO，双源检索，X射线材料迁移<br />- 效果：性能提升，mAP增加|
|📝 更新|Explaining Human Activity Recognition with SHAP: Validating Insights with Perturbation and Quantitative Measures|用SHAP解释人类活动识别：通过扰动和定量度量验证洞察力|Felix Tempel, Espen Alexander F. Ihlen, Lars Adde, Inga Strümke|<http://arxiv.org/pdf/2411.03714v2>|- 问题：活动识别，模型可解释性，高风险应用<br />- 方法：SHAP解释，扰动方法，定量评估<br />- 效果：关键点影响，模型可信度提升|
|🆕 发布|Scoring, Remember, and Reference: Catching Camouflaged Objects in Videos|评分、记忆与参考：捕捉视频中的伪装物体|Yuang Feng, Shuyong Gao, Fuzhen Yan, Yicheng Song, Lingyi Hong, Junjie Hu, Wenqiang Zhang|<http://arxiv.org/pdf/2503.17050v1>|- 问题：VCOD，伪装目标检测，动态信息利用不足<br />- 方法：记忆参考帧，双解码器，参考引导注意力机制<br />- 效果：性能提升10%，参数减少，单次视频处理|
|🆕 发布|Exploring the Efficacy of Partial Denoising Using Bit Plane Slicing for Enhanced Fracture Identification: A Comparative Study of Deep Learning-Based Approaches and Handcrafted Feature Extraction Techniques|基于深度学习方法和手工特征提取技术的部分去噪使用位平面切片增强裂缝识别有效性的比较研究|Snigdha Paul, Sambit Mallick, Anindya Sen|<http://arxiv.org/pdf/2503.17030v1>|- 问题：骨折识别，图像噪声，深度学习<br />- 方法：部分去噪，位平面切片，特征提取<br />- 效果：准确率提升，诊断精度提高|
|📝 更新|AutArch: An AI-assisted workflow for object detection and automated recording in archaeological catalogues|AI辅助的考古目录中物体检测与自动记录工作流程：AutArch|Kevin Klein, Antoine Muller, Alyssa Wohde, Alexander V. Gorelik, Volker Heyd, Ralf Lämmel, Yoan Diekmann, Maxime Brami|<http://arxiv.org/pdf/2311.17978v3>|- 问题：考古数据一致性，自动化记录，数据质量差异<br />- 方法：AI辅助工作流程，图像处理，对象检测<br />- 效果：数据收集加速，自动化，标准化|
|📝 更新|Design of an Expression Recognition Solution Based on the Global Channel-Spatial Attention Mechanism and Proportional Criterion Fusion|基于全局通道-空间注意力机制和比例准则融合的表情识别解决方案设计|Jun Yu, Yang Zheng, Lei Wang, Yongqi Wang, Shengfan Xu|<http://arxiv.org/pdf/2503.11935v3>|- 问题：表情识别，挑战，应用<br />- 方法：全局通道-空间注意力，比例准则融合，特征提取<br />- 效果：准确率提升，竞争力强|
|🆕 发布|Temporal Action Detection Model Compression by Progressive Block Drop|基于渐进式块丢弃的时间动作检测模型压缩|Xiaoyong Chen, Yong Guo, Jiaming Liang, Sitong Zhuang, Runhao Zeng, Xiping Hu|<http://arxiv.org/pdf/2503.16916v1>|- 问题：模型压缩，计算需求高，并行化效率低<br />- 方法：渐进式块丢弃，参数高效对齐<br />- 效果：计算量减少25%，无损压缩|
|🆕 发布|Stack Transformer Based Spatial-Temporal Attention Model for Dynamic Multi-Culture Sign Language Recognition|基于堆叠变换器的动态多文化手语识别时空注意力模型|Koki Hirooka, Abu Saleh Musa Miah, Tatsuya Murakami, Yuto Akiba, Yong Seok Hwang, Jungpil Shin|<http://arxiv.org/pdf/2503.16855v1>|- 问题：多文化手语识别，SLR性能，空间时序依赖<br />- 方法：Stack Transformer，多头注意力，Stack Transfer<br />- 效果：McSL性能提升，准确率提高|
|🆕 发布|Region Masking to Accelerate Video Processing on Neuromorphic Hardware|区域掩码加速神经形态硬件上的视频处理|Sreetama Sarkar, Sumit Bam Shrestha, Yue Che, Leobardo Campos-Macias, Gourav Datta, Peter A. Beerel|<http://arxiv.org/pdf/2503.16775v1>|- 问题：视频处理能耗高，延迟大<br />- 方法：区域掩码，SNN，事件处理<br />- 效果：能耗降低，延迟减少|
|🆕 发布|elaTCSF: A Temporal Contrast Sensitivity Function for Flicker Detection and Modeling Variable Refresh Rate Flicker|elaTCSF：用于闪烁检测和建模可变刷新率闪烁的时间对比敏感度函数|Yancheng Cai, Ali Bozorgian, Maliha Ashraf, Robert Wanat, Rafał K. Mantiuk|<http://arxiv.org/pdf/2503.16759v1>|- 问题：传统CFF，TCSF_IDMS，参数不足，低频检测<br />- 方法：elaTCSF，空间概率求和，多参数结合<br />- 效果：模型验证，VRR检测，视觉感知|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ZeroHSI: Zero-Shot 4D Human-Scene Interaction by Video Generation|零HSI：通过视频生成实现零样本4D人景交互|Hongjie Li, Hong-Xing Yu, Jiaman Li, Jiajun Wu|<http://arxiv.org/pdf/2412.18600v2>|- 问题：HSI生成，未见环境，MoCap数据<br />- 方法：视频生成模型，可微分渲染，零样本学习<br />- 效果：真实运动，动态场景，无真实数据|


### 多目标跟踪 (Multi-object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Strong Baseline: Multi-UAV Tracking via YOLOv12 with BoT-SORT-ReID|强基线：基于YOLOv12和BoT-SORT-ReID的多无人机跟踪|Yu-Hsi Chen|<http://arxiv.org/pdf/2503.17237v1>|[[代码]](<https://github.com/wish44165/YOLOv12-BoT-SORT-ReID>)<br />- 问题：多UAV跟踪，红外视频，低对比度，小目标<br />- 方法：YOLOv12，BoT-SORT，ReID，定制训练<br />- 效果：强基线，无对比增强，性能竞争|
|🆕 发布|Multi-modal Multi-platform Person Re-Identification: Benchmark and Method|多模态多平台行人重识别：基准与方法|Ruiyang Ha, Songyi Jiang, Bin Li, Bikang Pan, Yihang Zhu, Junjie Zhang, Xiatian Zhu, Shaogang Gong .etc.|<http://arxiv.org/pdf/2503.17096v1>|[[代码]](<https://mp-reid.github.io/.>)<br />- 问题：多模态，多平台，ReID，挑战<br />- 方法：MP-ReID基准，Uni-Prompt ReID<br />- 效果：超越，鲁棒|
|📝 更新|Babel: A Scalable Pre-trained Model for Multi-Modal Sensing via Expandable Modality Alignment|巴别：一种通过可扩展模态对齐的多模态感知可扩展预训练模型|Shenghong Dai, Shiqi Jiang, Yifan Yang, Ting Cao, Mo Li, Suman Banerjee, Lili Qiu|<http://arxiv.org/pdf/2407.17777v2>|- 问题：多模态感知，数据稀缺，模态融合<br />- 方法：可扩展模态对齐，二元模态对齐，数据平衡<br />- 效果：性能提升，模态融合|


### 三维检测 (3D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Which2comm: An Efficient Collaborative Perception Framework for 3D Object Detection|Which2comm：一种高效的3D目标检测协同感知框架|Duanrui Yu, Jing You, Xin Pei, Anqi Qu, Dingyu Wang, Shaocheng Jia|<http://arxiv.org/pdf/2503.17175v1>|- 问题：通信带宽限制，感知性能下降，性能与成本权衡<br />- 方法：语义检测框，稀疏特征，时间融合<br />- 效果：性能提升，成本降低|
|🆕 发布|Temporal-Guided Spiking Neural Networks for Event-Based Human Action Recognition|基于时间引导的基于事件的人体动作识别脉冲神经网络|Siyuan Yang, Shilin Lu, Shizheng Wang, Meng Hwa Er, Zengwei Zheng, Alex C. Kot|<http://arxiv.org/pdf/2503.17132v1>|- 问题：SNN处理长期时间信息，事件相机HAR<br />- 方法：TS-SNN，3D-SNN，FallingDetection-CeleX<br />- 效果：超越SNN方法，处理长期时间信息|
|🆕 发布|GAA-TSO: Geometry-Aware Assisted Depth Completion for Transparent and Specular Objects|GAA-TSO：针对透明和镜面物体的几何感知辅助深度补全|Yizhe Liu, Tong Jia, Da Cai, Hao Wang, Dongyue Chen|<http://arxiv.org/pdf/2503.17106v1>|- 问题：透明物体，深度信息，不准确，3D结构<br />- 方法：几何感知，跨模态融合，特征聚合<br />- 效果：性能提升，机器人抓取|
|🆕 发布|HSM: Hierarchical Scene Motifs for Multi-Scale Indoor Scene Generation|HSM：多尺度室内场景生成的分层场景模式|Hou In Derek Pun, Hou In Ivan Tam, Austin T. Wang, Xiaoliang Huo, Angel X. Chang, Manolis Savva|<http://arxiv.org/pdf/2503.16848v1>|- 问题：室内场景生成，物体布局，空间尺度<br />- 方法：层次场景模式，跨尺度空间模式，统一生成<br />- 效果：真实感，符合用户输入|
|📝 更新|An Integrated Approach to Robotic Object Grasping and Manipulation|机器人抓取与操作的综合方法|Owais Ahmed, M Huzaifa, M Areeb, Hamza Ali Khan|<http://arxiv.org/pdf/2411.13205v2>|- 问题：机器人抓取，货架拣选，不确定位置，自主适应<br />- 方法：创新系统，自主导航，高效检索<br />- 效果：自动化，效率提升|
|🆕 发布|Seg2Box: 3D Object Detection by Point-Wise Semantics Supervision|Seg2Box：基于点语义监督的3D目标检测|Maoji Zheng, Ziyu Xu, Qiming Xia, Hai Wu, Chenglu Wen, Cheng Wang|<http://arxiv.org/pdf/2503.16811v1>|- 问题：3D目标检测，语义分割，冗余，伪标签<br />- 方法：MFMS-C模块，SGIM-ST模块，自训练<br />- 效果：mAP提升，性能优越|
|🆕 发布|RigGS: Rigging of 3D Gaussians for Modeling Articulated Objects in Videos|RigGS：用于视频中建模关节对象的三维高斯建模|Yuxin Yao, Zhi Deng, Junhui Hou|<http://arxiv.org/pdf/2503.16822v1>|- 问题：视频2D物体建模，可编辑性，驱动性，可复现性<br />- 方法：3D高斯表示，骨架运动表示，节点控制变形<br />- 效果：真实动作生成，高质量渲染|


## 场景理解 (Scene Understanding)


### 语义分割 (Semantic Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Center-guided Classifier for Semantic Segmentation of Remote Sensing Images|中心引导的遥感图像语义分割分类器|Wei Zhang, Mengting Ma, Yizhen Jiang, Rongrong Lian, Zhenkai Wu, Kangning Cui, Xiaowen Ma|<http://arxiv.org/pdf/2503.16963v1>|[[代码]](<https://github.com/xwmaxwma/rssegmentation.>)<br />- 问题：遥感图像分割，类内方差大，分类器缺陷<br />- 方法：CenterSeg，原型生成，Grassmann流形约束<br />- 效果：性能优越，简单轻量，可解释性|


## 三维重建 (3D Reconstruction)


### 神经隐式重建 (Neural Implicit Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HyperNVD: Accelerating Neural Video Decomposition via Hypernetworks|超网络加速神经视频分解：HyperNVD|Maria Pilligua, Danna Xue, Javier Vazquez-Corral|<http://arxiv.org/pdf/2503.17276v1>|- 问题：视频分解，时间消耗，单视频过拟合<br />- 方法：元学习，超网络，INR模型<br />- 效果：加速训练，缩短收敛|
|📝 更新|Uncertainty modeling for fine-tuned implicit functions|细粒度隐函数微调的不确定性建模|Anna Susmelj, Mael Macuglia, Nataša Tagasovska, Reto Sutter, Sebastiano Caprara, Jean-Philippe Thiran, Ender Konukoglu|<http://arxiv.org/pdf/2406.12082v2>|- 问题：模型不确定性，数据稀疏，分布偏移<br />- 方法：Dropsembles，不确定性估计<br />- 效果：准确度高，计算成本低|


### 多视图重建 (Multi-view Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ColabSfM: Collaborative Structure-from-Motion by Point Cloud Registration|协同结构从运动：基于点云配准的协同结构从运动|Johan Edstedt, André Mateus, Alberto Jaenal|<http://arxiv.org/pdf/2503.17093v1>|[[代码]](<https://github.com/EricssonResearch/ColabSfM>)<br />- 问题：SfM重建，注册，可扩展性，训练数据集<br />- 方法：SfM注册数据集，点云注册，RefineRoITr<br />- 效果：ColabSfM，显著改进|
|🆕 发布|Instant Gaussian Stream: Fast and Generalizable Streaming of Dynamic Scene Reconstruction via Gaussian Splatting|即时高斯流：通过高斯分层实现快速且可泛化的动态场景重建流|Jinbo Yan, Rui Peng, Zhiyan Wang, Luyang Tang, Jiayu Yang, Jie Liang, Jiahao Wu, Ronggang Wang|<http://arxiv.org/pdf/2503.16979v1>|- 问题：高重建时间，误差累积，应用受限<br />- 方法：Gaussian Splatting，Anchor-driven Network，Key-frame Streaming<br />- 效果：快速重建，高可扩展性|


### 单目重建 (Monocular Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FATE: Full-head Gaussian Avatar with Textural Editing from Monocular Video|FATE：基于单目视频的纹理编辑全头高斯虚拟形象|Jiawei Zhang, Zijian Wu, Zhiyang Liang, Yicheng Gong, Dongfang Hu, Yao Yao, Xun Cao, Hao Zhu|<http://arxiv.org/pdf/2411.15604v2>|- 问题：单目视频，3D头像，重建，编辑<br />- 方法：采样密集化，神经烘焙，通用补全<br />- 效果：全头，可动，360°|


## 神经渲染 (Neural Rendering)


### 可控渲染 (Controllable Rendering)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FFaceNeRF: Few-shot Face Editing in Neural Radiance Fields|FFaceNeRF：神经辐射场中的少样本人脸编辑|Kwan Yun, Chaelin Kim, Hangyeul Shin, Junyong Noh|<http://arxiv.org/pdf/2503.17095v1>|[[代码]](<https://kwanyun.github.io/FFaceNeRF_page>)<br />- 问题：用户控制有限，数据集获取困难<br />- 方法：几何适配器，特征注入，潜在混合<br />- 效果：灵活度高，控制性强，图像质量高|
|🆕 发布|TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting|TaoAvatar：通过3D高斯喷溅实现增强现实中的实时逼真全身对话头像|Jianchuan Chen, Jingchuan Hu, Gaige Wang, Zhonghua Jiang, Tiansong Zhou, Zhiwen Chen, Chengfei Lv|<http://arxiv.org/pdf/2503.17032v1>|- 问题：全身动作，表情控制，实时性，3DGS<br />- 方法：个性化模板，StyleUnet，轻量级网络，细节补偿<br />- 效果：高保真，实时渲染，90FPS|
|📝 更新|Aquatic-GS: A Hybrid 3D Representation for Underwater Scenes|水生-GS：水下场景的混合3D表示|Shaohua Liu, Junzhe Lu, Zuoya Gu, Jiajun Li, Yue Deng|<http://arxiv.org/pdf/2411.00239v2>|- 问题：水下场景表示，信息耦合，3D场景<br />- 方法：混合3D表示，神经水场，3D高斯分层<br />- 效果：渲染质量提升，速度提升|


### 场景编辑 (Scene Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|UrbanGS: Semantic-Guided Gaussian Splatting for Urban Scene Reconstruction|城市场景重建的语义引导高斯分层|Ziwen Li, Jiaxin Huang, Runnan Chen, Yunlong Che, Yandong Guo, Tongliang Liu, Fakhri Karray, Mingming Gong|<http://arxiv.org/pdf/2412.03473v2>|- 问题：城市场景重建，动态对象建模，3DGS，4DGS，标注成本高<br />- 方法：语义引导，Gaussian Splatting，静态动态区分，时间嵌入<br />- 效果：重建质量高，效率高|


### 神经辐射场 (Neural Radiance Fields)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DroneSplat: 3D Gaussian Splatting for Robust 3D Reconstruction from In-the-Wild Drone Imagery|DroneSplat：从野外无人机图像中进行鲁棒3D重建的3D高斯Splatting|Jiadong Tang, Yu Gao, Dianyi Yang, Liqi Yan, Yufeng Yue, Yi Yang|<http://arxiv.org/pdf/2503.16964v1>|- 问题：动态干扰，视角限制，3D重建<br />- 方法：自适应掩膜，Gaussian Splatting，多视角预测<br />- 效果：鲁棒性提升，高质量渲染|
|🆕 发布|Optimized Minimal 3D Gaussian Splatting|优化最小3D高斯分层|Joo Chan Lee, Jong Hwan Ko, Eunbyung Park|<http://arxiv.org/pdf/2503.16924v1>|[[代码]](<https://maincold2.github.io/omg>)<br />- 问题：3DGS存储，内存开销，质量退化<br />- 方法：OMG，最小化Gaussian，属性表示<br />- 效果：存储减少50%，渲染质量高|
|📝 更新|3D Student Splatting and Scooping|三维学生喷溅和挖掘|Jialin Zhu, Jiangbei Yue, Feixiang He, He Wang|<http://arxiv.org/pdf/2503.10148v3>|- 问题：3DGS，表达性，学习挑战<br />- 方法：Student's t分布，SSS模型，优化采样<br />- 效果：质量提升，参数效率高|


## 定位与映射 (Localization & Mapping)


### 位姿估计 (Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Image as an IMU: Estimating Camera Motion from a Single Motion-Blurred Image|图像作为IMU：从单张运动模糊图像估计相机运动|Jerred Chen, Ronald Clark|<http://arxiv.org/pdf/2503.17358v1>|- 问题：运动模糊，相机姿态估计，速度估计<br />- 方法：运动流场预测，深度图估计，线性最小二乘<br />- 效果：IMU-like测量，速度估计，性能领先|
|🆕 发布|Pow3R: Empowering Unconstrained 3D Reconstruction with Camera and Scene Priors|Pow3R：利用相机和场景先验增强无约束3D重建|Wonbong Jang, Philippe Weinzaepfel, Vincent Leroy, Lourdes Agapito, Jerome Revaud|<http://arxiv.org/pdf/2503.17316v1>|- 问题：3D重建，相机和场景先验，信息利用<br />- 方法：Pow3R模型，Transformer架构，条件化<br />- 效果：最佳结果，信息利用|
|📝 更新|Matrix3D: Large Photogrammetry Model All-in-One|Matrix3D：一体化大型摄影测量模型|Yuanxun Lu, Jingyang Zhang, Tian Fang, Jean-Daniel Nahmias, Yanghai Tsin, Long Quan, Xun Cao, Yao Yao .etc.|<http://arxiv.org/pdf/2502.07685v2>|[[代码]](<https://nju-3dv.github.io/projects>)<br />- 问题：多模态，摄影测量，任务，统一模型<br />- 方法：扩散Transformer，多模态集成，掩码学习<br />- 效果：性能领先，数据扩展，3D内容|
|📝 更新|Automatic infant 2D pose estimation from videos: comparing seven deep neural network methods|自动从视频中估计婴儿2D姿态：比较七种深度神经网络方法|Filipe Gama, Matej Misar, Lukas Navara, Sergiu T. Popescu, Matej Hoffmann|<http://arxiv.org/pdf/2406.17382v3>|- 问题：婴儿姿态估计，视频分析，运动研究<br />- 方法：七种深度学习方法，性能比较，误差分析<br />- 效果：ViTPose最佳，实时性高|
|📝 更新|Reloc3r: Large-Scale Training of Relative Camera Pose Regression for Generalizable, Fast, and Accurate Visual Localization|Reloc3r：大规模训练相对相机位姿回归以实现可泛化、快速和精确的视觉定位|Siyan Dong, Shuzhe Wang, Shaohui Liu, Lulu Cai, Qingnan Fan, Juho Kannala, Yanchao Yang|<http://arxiv.org/pdf/2412.08376v2>|[[代码]](<https://github.com/ffrivera0/reloc3r.>)<br />- 问题：视觉定位，泛化能力，精度<br />- 方法：相对位姿回归，运动平均模块<br />- 效果：实时，泛化|
|📝 更新|Omni6D: Large-Vocabulary 3D Object Dataset for Category-Level 6D Object Pose Estimation|全视6D：用于类别级6D物体姿态估计的大词汇量3D物体数据集|Mengchen Zhang, Tong Wu, Tai Wang, Tengfei Wang, Ziwei Liu, Dahua Lin|<http://arxiv.org/pdf/2409.18261v3>|- 问题：6D物体姿态估计，类别级别，数据集范围窄<br />- 方法：Omni6D数据集，对称性度量，模型微调<br />- 效果：类别覆盖广，基准测试，模型适应性强|


### 语义建图 (Semantic Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FALCON: Fairness Learning via Contrastive Attention Approach to Continual Semantic Scene Understanding|FALCON：通过对比注意力方法实现公平学习的持续语义场景理解|Thanh-Dat Truong, Utsav Prabhu, Bhiksha Raj, Jackson Cothren, Khoa Luu|<http://arxiv.org/pdf/2311.15965v3>|- 问题：持续学习，语义场景理解，公平性，灾难性遗忘，背景偏移<br />- 方法：公平对比聚类损失，注意力视觉语法，特征表示<br />- 效果：SoTA性能，公平性提升|
|🆕 发布|ExCap3D: Expressive 3D Scene Understanding via Object Captioning with Varying Detail|ExCap3D：通过具有不同细节的对象标题进行富有表现力的3D场景理解|Chandan Yeshwanth, David Rozenberszki, Angela Dai|<http://arxiv.org/pdf/2503.17044v1>|- 问题：3D场景理解，细节描述，对象描述<br />- 方法：多级细节描述，语义一致性，VLM生成数据集<br />- 效果：Cider评分提升，质量提高|
|🆕 发布|SGFormer: Satellite-Ground Fusion for 3D Semantic Scene Completion|卫星-地面融合用于3D语义场景补全：SGFormer|Xiyue Guo, Jiarui Hu, Junjie Hu, Hujun Bao, Guofeng Zhang|<http://arxiv.org/pdf/2503.16825v1>|[[代码]](<https://github.com/gxytcrc/SGFormer.>)<br />- 问题：语义完成，视觉遮挡，卫星-地面融合<br />- 方法：双分支架构，地面视图引导，自适应权重<br />- 效果：性能提升，优于现有方法|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Radar-Guided Polynomial Fitting for Metric Depth Estimation|雷达引导的多项式拟合用于度量深度估计|Patrick Rim, Hyoungseob Park, Vadim Ezhov, Jeffrey Moon, Alex Wong|<http://arxiv.org/pdf/2503.17182v1>|- 问题：深度估计，尺度转换，区域对齐<br />- 方法：雷达引导，多项式拟合，结构一致性<br />- 效果：性能提升，MAE 30.3%，RMSE 37.2%|
|📝 更新|SALOVA: Segment-Augmented Long Video Assistant for Targeted Retrieval and Routing in Long-Form Video Analysis|SALOVA：用于长视频分析中目标检索和路由的段增强长视频助手|Junho Kim, Hyunjun Kim, Hosu Lee, Yong Man Ro|<http://arxiv.org/pdf/2411.16173v2>|- 问题：长视频分析，信息损失，模型响应<br />- 方法：Segment-Augmented，动态路由，时空投影<br />- 效果：精确检索，上下文完整性|
|📝 更新|HOTFormerLoc: Hierarchical Octree Transformer for Versatile Lidar Place Recognition Across Ground and Aerial Views|HOTFormerLoc：适用于地面和空中视图的多功能激光雷达位置识别的分层八叉树Transformer|Ethan Griffiths, Maryam Haghighat, Simon Denman, Clinton Fookes, Milad Ramezani|<http://arxiv.org/pdf/2503.08140v2>|[[代码]](<https://csiro-robotics.github.io/HOTFormerLoc.>)<br />- 问题：3D地方识别，跨视图，点云数据<br />- 方法：层次八叉树，Transformer，多尺度注意力<br />- 效果：性能提升，数据集CS-Wild-Places|


## 自监督学习 (Self-supervised Learning)


### 掩码自编码 (Masked Autoencoding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|URLOST: Unsupervised Representation Learning without Stationarity or Topology|URLOST：无需平稳性或拓扑结构的无监督表示学习|Zeyu Yun, Juexiao Zhang, Yann LeCun, Yubei Chen|<http://arxiv.org/pdf/2310.04496v2>|- 问题：无监督学习，依赖稳定性，拓扑结构<br />- 方法：自组织层，谱聚类，掩码自编码器<br />- 效果：跨模态学习，超越现有方法|
|🆕 发布|Halton Scheduler For Masked Generative Image Transformer|哈顿调度器在掩码生成图像变换器中的应用|Victor Besnier, Mickael Chen, David Hurych, Eduardo Valle, Matthieu Cord|<http://arxiv.org/pdf/2503.17076v1>|[[代码]](<https://github.com/valeoai/Halton-MaskGIT.>)<br />- 问题：MaskGIT采样调度，采样误差，超参数调整<br />- 方法：Halton调度器，低偏差序列，非恢复性错误减少<br />- 效果：FID降低，图像质量提升，多样性增加|


### 对比学习 (Contrastive Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|End-to-end Adaptive Dynamic Subsampling and Reconstruction for Cardiac MRI|端到端自适应动态子采样与心脏MRI重建|George Yiasemis, Jan-Jakob Sonke, Jonas Teuwen|<http://arxiv.org/pdf/2403.10346v2>|- 问题：动态MRI加速，非自适应，重建质量<br />- 方法：自适应动态采样，vSHARP网络，定制采样模式<br />- 效果：重建质量提升，高加速效果|
|🆕 发布|CoRLD: Contrastive Representation Learning Of Deformable Shapes In Images|CoRLD：图像中可变形形状的对比表征学习|Tonmoy Hossain ana Miaomiao Zhang|<http://arxiv.org/pdf/2503.17162v1>|- 问题：模板依赖，细粒度区分困难<br />- 方法：对比学习，变形空间，无参考图像<br />- 效果：分类精度提升，泛化能力强|
|📝 更新|PUGS: Zero-shot Physical Understanding with Gaussian Splatting|PUGS：基于高斯喷溅的零样本物理理解|Yinghao Shuai, Ran Yu, Yuantao Chen, Zijian Jiang, Xiaowei Song, Nan Wang, Jv Zheng, Jianzhu Ma .etc.|<http://arxiv.org/pdf/2502.12231v2>|[[代码]](<https://github.com/EverNorif/PUGS>)<br />- 问题：物理属性理解，3D重建，零样本预测<br />- 方法：高斯分层，几何正则化，区域对比损失<br />- 效果：性能提升，真实场景应用|
|🆕 发布|Semi-supervised Cervical Segmentation on Ultrasound by A Dual Framework for Neural Networks|基于双框架神经网络的超声图像半监督宫颈分割|Fangyijie Wang, Kathleen M. Curran, Guénolé Silvestre|<http://arxiv.org/pdf/2503.17057v1>|[[代码]](<https://github.com/13204942/SSL>)<br />- 问题：超声图像，颈肌分割，数据稀缺<br />- 方法：半监督学习，双网络框架，伪标签，对比学习<br />- 效果：性能竞争，公开代码|
|📝 更新|Cross-Modal Consistency Learning for Sign Language Recognition|跨模态一致性学习用于手语识别|Kepeng Wu, Zecheng Li, Hezhen Hu, Wengang Zhou, Houqiang Li|<http://arxiv.org/pdf/2503.12485v2>|- 问题：ISLR性能，语义线索不足，视觉特征干扰<br />- 方法：CCL-SLR，对比学习，数据增强<br />- 效果：性能提升，效果显著|
|📝 更新|From Open Vocabulary to Open World: Teaching Vision Language Models to Detect Novel Objects|从开放词汇到开放世界：训练视觉语言模型检测新物体|Zizhao Li, Zhengkang Xiang, Joseph West, Kourosh Khoshelham|<http://arxiv.org/pdf/2411.18207v3>|- 问题：封闭集假设，OVD局限性，NOOD误分类，FOOD忽略<br />- 方法：OWEL，Pseudo Unknown Embedding，MSCAL<br />- 效果：SOTA性能，开放词汇检测|
|🆕 发布|Learning Part Knowledge to Facilitate Category Understanding for Fine-Grained Generalized Category Discovery|学习部分知识以促进细粒度泛化类别发现中的类别理解|Enguang Wang, Zhimao Peng, Zhengyuan Xie, Haori Lu, Fei Yang, Xialei Liu|<http://arxiv.org/pdf/2503.16782v1>|- 问题：细粒度分类，全局特征，局部差异<br />- 方法：部分知识，自适应分解，差异正则化<br />- 效果：性能提升，鲁棒性|


### 一致性学习 (Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SV4D 2.0: Enhancing Spatio-Temporal Consistency in Multi-View Video Diffusion for High-Quality 4D Generation|SV4D 2.0：提升多视图视频扩散中的时空一致性以实现高质量4D生成|Chun-Han Yao, Yiming Xie, Vikram Voleti, Huaizu Jiang, Varun Jampani|<http://arxiv.org/pdf/2503.16396v2>|- 问题：多视图视频扩散，时空一致性，高质4D生成<br />- 方法：网络架构改进，数据增强，渐进式训练，4D优化<br />- 效果：质量提升，时空一致性增强|


## 迁移与适应 (Transfer & Adaptation)


### 元学习 (Meta Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Exploring a Principled Framework for Deep Subspace Clustering|探索深度子空间聚类的原则性框架|Xianghan Meng, Zhiyuan Huang, Wei He, Xianbiao Qi, Rong Xiao, Chun-Guang Li|<http://arxiv.org/pdf/2503.17288v1>|[[代码]](<https://github.com/mengxianghan123/PRO-DSC.>)<br />- 问题：子空间聚类，特征折叠，理论保证<br />- 方法：PRO-DSC，正则化，正交子空间<br />- 效果：性能优越，可扩展|
|🆕 发布|HAPI: A Model for Learning Robot Facial Expressions from Human Preferences|HAPI：一种从人类偏好中学习机器人面部表情的模型|Dongsheng Yang, Qianying Liu, Wataru Sato, Takashi Minato, Chaoran Liu, Shin'ya Nishida|<http://arxiv.org/pdf/2503.17046v1>|- 问题：机器人表情生成，人类偏好，模型预测，表达自然度<br />- 方法：学习到排序框架，Siamese RankNet，人类反馈<br />- 效果：表情真实，社会共鸣，效果显著|


### 域适应 (Domain Adaptation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Mono2D: A Trainable Monogenic Layer for Robust Knee Cartilage Segmentation on Out-of-Distribution 2D Ultrasound Data|Mono2D：一种用于在分布外2D超声数据上实现鲁棒性膝关节软骨分割的可训练单基因层|Alvin Kimbowa, Arjun Parmar, Maziar Badii, David Liu, Matthew Harkey, Ilker Hacihaliloglu|<http://arxiv.org/pdf/2503.09050v2>|- 问题：领域偏移，泛化能力差<br />- 方法：Monogenic层，可训练带通滤波器，联合训练<br />- 效果：Dice分数提升，平均表面距离减小|
|🆕 发布|Jailbreaking the Non-Transferable Barrier via Test-Time Data Disguising|破解不可迁移性障碍：测试时数据伪装|Yongli Xiang, Ziming Hong, Lina Yao, Dadong Wang, Tongliang Liu|<http://arxiv.org/pdf/2503.17198v1>|- 问题：非迁移学习，安全风险，黑盒攻击<br />- 方法：测试时数据伪装，JailNTL攻击<br />- 效果：绕过障碍，提升准确率|
|📝 更新|When Domain Generalization meets Generalized Category Discovery: An Adaptive Task-Arithmetic Driven Approach|当领域泛化遇见泛化类别发现：一种自适应任务-算术驱动方法|Vaibhav Rathore, Shubhranil B, Saikat Dutta, Sarthak Mehrotra, Zsolt Kira, Biplab Banerjee|<http://arxiv.org/pdf/2503.14897v2>|- 问题：分布偏移，训练数据限制，GCD性能<br />- 方法：DG-GCD，DG2CD-Net，任务驱动训练<br />- 效果：性能提升，泛化能力强|
|📝 更新|SoMA: Singular Value Decomposed Minor Components Adaptation for Domain Generalizable Representation Learning|SoMA：基于奇异值分解的次级成分自适应域泛化表示学习|Seokju Yun, Seunghye Chae, Dongheon Lee, Youngmin Ro|<http://arxiv.org/pdf/2412.04077v2>|- 问题：领域泛化，PEFT，模型泛化能力<br />- 方法：SVD分解，次要成分调整，冻结块<br />- 效果：SOTA结果，无额外开销|
|🆕 发布|From Faces to Voices: Learning Hierarchical Representations for High-quality Video-to-Speech|从面部到语音：学习高质量视频到语音的层次化表示|Ji-Hoon Kim, Jeongsoo Choi, Jaehun Kim, Chaeyoung Jung, Joon Son Chung|<http://arxiv.org/pdf/2503.16956v1>|- 问题：视频到语音，模态差距，语音质量<br />- 方法：层次表示学习，特征空间转换，流匹配模型<br />- 效果：高质量语音，超越现有方法|
|🆕 发布|Casual Inference via Style Bias Deconfounding for Domain Generalization|通过风格偏差去混淆进行领域泛化的因果推理|Jiaxi Li, Di Lin, Hao Chen, Hongying Liu, Liang Wan, Wei Feng|<http://arxiv.org/pdf/2503.16852v1>|- 问题：领域泛化，风格频率，视觉相关性，因果推理<br />- 方法：风格去混淆，结构因果模型，风格引导专家模块<br />- 效果：性能提升，多领域泛化|


### 增量学习 (Incremental Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Specifying What You Know or Not for Multi-Label Class-Incremental Learning|《为多标签类增量学习指定已知或未知的内容》|Aoting Zhang, Dongbao Yang, Chang Liu, Xiaopeng Hong, Yu Zhou|<http://arxiv.org/pdf/2503.17017v1>|- 问题：多标签增量学习，知识区分，遗忘问题<br />- 方法：HCP框架，特征净化，前瞻性知识挖掘<br />- 效果：缓解遗忘，精度提升|
|📝 更新|Enhanced Continual Learning of Vision-Language Models with Model Fusion|增强型视觉-语言模型融合的持续学习|Haoyuan Gao, Zicong Zhang, Yuqi Wei, Linglan Zhao, Guilin Li, Yexin Li, Linghe Kong, Weiran Huang|<http://arxiv.org/pdf/2503.10705v2>|- 问题：灾难性遗忘，零样本性能下降，参数效率低<br />- 方法：模型融合，任务解耦-统一，多模型聚合<br />- 效果：性能提升，零样本能力增强|
|🆕 发布|Restoring Forgotten Knowledge in Non-Exemplar Class Incremental Learning through Test-Time Semantic Evolution|通过测试时语义演化在非示例类增量学习中恢复遗忘的知识|Haori Lu, Xusheng Cao, Linlan Huang, Enguang Wang, Fei Yang, Xialei Liu|<http://arxiv.org/pdf/2503.16793v1>|- 问题：NECIL，遗忘，知识恢复，测试时优化<br />- 方法：RoSE，语义演化，自监督，梯度下降替代<br />- 效果：SOTA，性能提升，可行性验证|


## 鲁棒学习 (Robust Learning)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Time-Series U-Net with Recurrence for Noise-Robust Imaging Photoplethysmography|时间序列U-Net循环用于噪声鲁棒成像光电容积脉搏波描记法|Vineet R. Shenoy, Shaoju Wu, Armand Comas, Tim K. Marks, Suhas Lohit, Hassan Mansour|<http://arxiv.org/pdf/2503.17351v1>|- 问题：噪声鲁棒性，iPPG，非接触式生理信号<br />- 方法：模块化，TURNIP，时间序列U-Net<br />- 效果：心率估计，性能提升|
|🆕 发布|Dynamic Attention Mechanism in Spatiotemporal Memory Networks for Object Tracking|动态注意力机制在时空记忆网络中的目标跟踪|Meng Zhou, Jiadong Xie, Mingsheng Xu|<http://arxiv.org/pdf/2503.16768v1>|- 问题：模板匹配，特征选择，融合，复杂场景<br />- 方法：动态注意力机制，轻量级门控网络，时空相关性分析<br />- 效果：性能优越，实时高效|


### 对抗训练 (Adversarial Training)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SOUS VIDE: Cooking Visual Drone Navigation Policies in a Gaussian Splatting Vacuum|SOUS VIDE：高斯喷溅真空中的视觉无人机导航策略烹饪|JunEn Low, Maximilian Adang, Javier Yu, Keiko Nagami, Mac Schwager|<http://arxiv.org/pdf/2412.16346v2>|[[代码]](<https://stanfordmsl.github.io/SousVide>)<br />- 问题：视觉无人机导航，模拟器，训练方法<br />- 方法：FiGS模拟器，SV-Net神经网络，低级控制模块<br />- 效果：零样本迁移，鲁棒性，实时性|
|📝 更新|Inverting Transformer-based Vision Models|基于Transformer的视觉模型反演|Jan Rathjens, Shirin Reyhanian, David Kappel, Laurenz Wiskott|<http://arxiv.org/pdf/2412.06534v2>|[[代码]](<https://github.com/wiskott-lab/inverse-detection-transformer.>)<br />- 问题：视觉模型机制理解，Transformer模型，中间层可视化<br />- 方法：模块化逆模型训练，图像重建<br />- 效果：机制洞察，架构比较|
|📝 更新|LaDTalk: Latent Denoising for Synthesizing Talking Head Videos with High Frequency Details|LaDTalk：用于合成具有高频细节的说话人头视频的潜在去噪|Jian Yang, Xukun Wang, Wentao Wang, Guoming Li, Qihang Fang, Ruihong Yuan, Tianyang Wang, Xiaomei Zhang .etc.|<http://arxiv.org/pdf/2410.00990v2>|- 问题：高频细节，表达有限，视频质量<br />- 方法：Wav2Lip，Lipschitz Continuity，SOVQAE<br />- 效果：视频质量提升，同步性能提升|


### 对抗防御 (Adversarial Defense)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hi-ALPS -- An Experimental Robustness Quantification of Six LiDAR-based Object Detection Systems for Autonomous Driving|Hi-ALPS -- 六种基于激光雷达的自动驾驶目标检测系统的实验鲁棒性量化|Alexandra Arzberger, Ramin Tavakoli Kolagari|<http://arxiv.org/pdf/2503.17168v1>|- 问题：LiDAR OD鲁棒性，对抗样本，测试<br />- 方法：Hi-ALPS，层次化，对抗扰动<br />- 效果：鲁棒性量化，方法适用性|
|📝 更新|Instant Adversarial Purification with Adversarial Consistency Distillation|即时对抗净化：基于对抗一致性蒸馏|Chun Tong Lei, Hon Ming Yam, Zhongliang Guo, Yifei Qian, Chun Pong Lau|<http://arxiv.org/pdf/2408.17064v3>|- 问题：对抗攻击，计算开销，扩散模型<br />- 方法：一步控制净化，GAND，CAP<br />- 效果：高效，防御成功率高|
|🆕 发布|EasyRobust: A Comprehensive and Easy-to-use Toolkit for Robust and Generalized Vision|EasyRobust：一个全面且易于使用的鲁棒和泛化视觉工具包|Xiaofeng Mao, Yuefeng Chen, Rong Zhang, Hui Xue, Zhao Li, Hang Su|<http://arxiv.org/pdf/2503.16975v1>|[[代码]](<https://github.com/alibaba/easyrobust.>)<br />- 问题：机器视觉鲁棒性差，对抗攻击，数据分布偏移<br />- 方法：EasyRobust工具包，对抗鲁棒性，非对抗鲁棒性<br />- 效果：准确评估，模型鲁棒|
|🆕 发布|Lie Detector: Unified Backdoor Detection via Cross-Examination Framework|《测谎仪：通过交叉审问框架实现统一的后门检测》|Xuan Wang, Siyuan Liang, Dongping Liao, Han Fang, Aishan Liu, Xiaochun Cao, Yu-liang Lu, Ee-Chien Chang .etc.|<http://arxiv.org/pdf/2503.16872v1>|- 问题：数据安全，模型后门，检测准确率<br />- 方法：交叉检验，模型不一致性，特征相似度<br />- 效果：检测性能提升，多模态模型适用|
|🆕 发布|Rethinking the Role of Spatial Mixing|重新思考空间混合的作用|George Cazenavette, Joel Julin, Simon Lucey|<http://arxiv.org/pdf/2503.16760v1>|- 问题：2D卷积，空间混合，模型性能<br />- 方法：分离空间混合，随机初始化，对抗鲁棒性<br />- 效果：性能相当，鲁棒性增强|


### 对抗攻击 (Adversarial Attack)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|When Lighting Deceives: Exposing Vision-Language Models' Illumination Vulnerability Through Illumination Transformation Attack|当光线欺骗：通过光照变换攻击揭露视觉-语言模型的照明脆弱性|Hanqing Liu, Shouwei Ruan, Yao Huang, Shiji Zhao, Xingxing Wei|<http://arxiv.org/pdf/2503.06903v2>|- 问题：VLMs照明脆弱性，照明变化鲁棒性<br />- 方法：照明变换攻击，参数化点光源，物理照明重建<br />- 效果：性能降低，自然性高|


## 模型压缩加速 (Model Compression & Acceleration)


### 知识蒸馏 (Knowledge Distillation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Distilling Monocular Foundation Model for Fine-grained Depth Completion|单目基础模型用于精细深度补全蒸馏|Yingping Liang, Yutao Hu, Wenqi Shao, Ying Fu|<http://arxiv.org/pdf/2503.16970v1>|[[代码]](<https://github.com/Sharpiless/DMD3C>)<br />- 问题：深度完成，稀疏标注，监督学习<br />- 方法：知识蒸馏，预训练，SSI Loss<br />- 效果：性能提升，KITTI第一|
|📝 更新|Efficient Training of Generalizable Visuomotor Policies via Control-Aware Augmentation|通过控制感知增强的高效训练通用的视觉运动策略|Yinuo Zhao, Kun Wu, Tianjiao Yi, Zhiyuan Xu, Xiaozhu Ju, Zhengping Che, Chi Harold Liu, Jian Tang|<http://arxiv.org/pdf/2401.09258v2>|- 问题：泛化能力差，数据增强不足，信息破坏<br />- 方法：控制感知增强，知识蒸馏，专家-学生策略<br />- 效果：泛化提升，训练稳定高效|


## 泛化与鲁棒性 (Generalization & Robustness)


### 域泛化 (Domain Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Language Anchor-Guided Method for Robust Noisy Domain Generalization|一种基于语言锚点的鲁棒噪声领域泛化方法|Zilin Dai, Lehong Wang, Fangzhou Lin, Yidong Wang, Zhigang Li, Kazunori D Yamada, Ziming Zhang, Wang Lu|<http://arxiv.org/pdf/2503.17211v1>|- 问题：分布偏移，标签噪声，过拟合，特征冗余<br />- 方法：语言锚点，样本重加权，自适应加权<br />- 效果：准确率提升，鲁棒性增强|
|📝 更新|Cross-Modality Perturbation Synergy Attack for Person Re-identification|跨模态扰动协同攻击的人体重识别|Yunpeng Gong, Zhun Zhong, Yansong Qu, Zhiming Luo, Rongrong Ji, Min Jiang|<http://arxiv.org/pdf/2401.10090v6>|[[代码]](<https://github.com/finger-monkey/cmps__attack.>)<br />- 问题：跨模态ReID安全，模态差异处理<br />- 方法：多模态梯度优化，通用扰动攻击<br />- 效果：攻击有效，系统鲁棒性提升|
|🆕 发布|ST-Prompt Guided Histological Hypergraph Learning for Spatial Gene Expression Prediction|基于ST-Prompt引导的病理学超图学习进行空间基因表达预测|Yi Niu, Jiashuai Liu, Yingkang Zhan, Jiangbo Shi, Di Zhang, Ines Machado, Mireia Crispin-Ortuzar, Chen Li .etc.|<http://arxiv.org/pdf/2503.16816v1>|- 问题：基因表达预测，异质关系，空间转录组学<br />- 方法：ST-prompt，超图学习，多尺度融合<br />- 效果：超越现有方法，接近真实值|


## 可解释性 (Interpretability)


### 归因分析 (Attribution Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Deep Learning Framework for Visual Attention Prediction and Analysis of News Interfaces|深度学习框架在新闻界面视觉注意力预测与分析中的应用|Matthew Kenely, Dylan Seychell, Carl James Debono, Chris Porter|<http://arxiv.org/pdf/2503.17212v1>|- 问题：注意力预测，新闻界面，数据集限制，年龄差异<br />- 方法：SaRa模型，DeepGaze IIE，注意力模式分析<br />- 效果：性能提升，年龄差异分析|
|📝 更新|Number it: Temporal Grounding Videos like Flipping Manga|编号：像翻页漫画一样的时间定位视频|Yongliang Wu, Xinting Hu, Yuyang Sun, Yizhou Zhou, Wenbo Zhu, Fengyun Rao, Bernt Schiele, Xu Yang|<http://arxiv.org/pdf/2411.10332v3>|[[代码]](<https://github.com/yongliang-wu/NumPro.>)<br />- 问题：视频时序定位，视觉理解，精确性<br />- 方法：Number-Prompt，时序编号，视觉-时序关联<br />- 效果：性能提升，mIoU，mAP|


## 医学影像分析 (Medical Image Analysis)


### 医学分割 (Medical Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DINO-LG: A Task-Specific DINO Model for Coronary Calcium Scoring|DINO-LG：一种针对冠状动脉钙评分的任务特定DINO模型|Mahmut S. Gokmen, Caner Ozcan, Moneera N. Haque, Steve W. Leung, C. Seth Parker, W. Brent Seales, Cody Bumgardner|<http://arxiv.org/pdf/2411.07976v7>|- 问题：CAC评分，数据稀缺，模型性能低<br />- 方法：DINO模型，自监督学习，标签引导<br />- 效果：敏感度提升，特异性提升，成本降低|
|🆕 发布|Cross-Modal Interactive Perception Network with Mamba for Lung Tumor Segmentation in PET-CT Images|基于Mamba的跨模态交互感知网络在PET-CT图像中用于肺肿瘤分割|Jie Mei, Chenyu Lin, Yu Qiu, Yaonan Wang, Hui Zhang, Ziyang Wang, Dong Dai|<http://arxiv.org/pdf/2503.17261v1>|[[代码]](<https://github.com/mj129/CIPA.>)<br />- 问题：肺肿瘤分割，PET-CT图像，数据集限制<br />- 方法：CIPA网络，CRM模块，DCIM模块<br />- 效果：性能提升，跨模态交互|
|📝 更新|RadioActive: 3D Radiological Interactive Segmentation Benchmark|放射性：3D放射学交互式分割基准|Constantin Ulrich, Tassilo Wald, Emily Tempus, Maximilian Rokuss, Paul F. Jaeger, Klaus Maier-Hein|<http://arxiv.org/pdf/2411.07885v3>|- 问题：3D放射学分割，交互性，评估协议，性能评估<br />- 方法：RadioActive基准，多样化数据集，提示技术<br />- 效果：性能提升，通用模型优于专业模型|
|📝 更新|SUM Parts: Benchmarking Part-Level Semantic Segmentation of Urban Meshes|SUM Parts：城市网格部分级语义分割基准测试|Weixiao Gao, Liangliang Nan, Hugo Ledoux|<http://arxiv.org/pdf/2503.15300v2>|[[代码]](<https://tudelft3d.github.io/SUMParts>)<br />- 问题：城市场景语义分割，纹理网格，部分级标签<br />- 方法：大规模数据集，交互式标注工具，3D语义分割评估<br />- 效果：丰富空间表示，高效标注|
|🆕 发布|Does a Rising Tide Lift All Boats? Bias Mitigation for AI-based CMR Segmentation|《涨潮是否都能扬帆？基于AI的CMR分割的偏差缓解》|Tiarna Lee, Esther Puyol-Antón, Bram Ruijsink, Miaojing Shi, Andrew P. King|<http://arxiv.org/pdf/2503.17089v1>|- 问题：AI CMR分割，模型偏差，种族偏见<br />- 方法：过采样，重要性重新加权，Group DRO，裁剪图像<br />- 效果：性能提升，偏差减少|
|🆕 发布|An Attentive Representative Sample Selection Strategy Combined with Balanced Batch Training for Skin Lesion Segmentation|基于注意力机制的代表性样本选择策略与平衡批量训练相结合的皮肤病变分割|Stephen Lloyd-Brown, Susan Francis, Caroline Hoad, Penny Gowland, Karen Mullinger, Andrew French, Xin Chen|<http://arxiv.org/pdf/2503.17034v1>|- 问题：训练集选择，模型性能，低标注数据<br />- 方法：代表性样本选择，平衡批量训练，无监督学习<br />- 效果：性能提升，低标注数据有效利用|
|🆕 发布|High Accuracy Pulmonary Vessel Segmentation for Contrast and Non-contrast CT Images and Its Clinical Evaluation|高精度肺血管分割对比与非对比CT图像及其临床评估|Ying Ming, Shaoze Luo, Longfei Zhao, Qiqi Xu, Wei Song|<http://arxiv.org/pdf/2503.16988v1>|- 问题：肺血管分割，CTPA，NCCT，精度低<br />- 方法：VLSOM，Cl-Dice-Loss，CTPA到NCCT转换<br />- 效果：高精度，临床评估好|
|🆕 发布|Steady Progress Beats Stagnation: Mutual Aid of Foundation and Conventional Models in Mixed Domain Semi-Supervised Medical Image Segmentation|稳步进步胜于停滞：基础模型与常规模型在混合域半监督医学图像分割中的互助|Qinghe Ma, Jian Zhang, Zekun Li, Lei Qi, Qian Yu, Yinghuan Shi|<http://arxiv.org/pdf/2503.16997v1>|[[代码]](<https://github.com/MQinghe/SynFoC>)<br />- 问题：领域偏移，过自信预测，错误累积<br />- 方法：SynFoC框架，伪标签，一致性正则化<br />- 效果：Dice分数提升，性能优越|
|🆕 发布|GeoT: Geometry-guided Instance-dependent Transition Matrix for Semi-supervised Tooth Point Cloud Segmentation|GeoT：基于几何引导的实例依赖转换矩阵用于半监督牙齿点云分割|Weihao Yu, Xiaoqing Guo, Chenxin Li, Yifan Liu, Yixuan Yuan|<http://arxiv.org/pdf/2503.16976v1>|- 问题：半监督，牙齿点云，伪标签噪声<br />- 方法：实例依赖转换矩阵，几何先验，点级正则化，类级平滑<br />- 效果：性能提升，数据利用率高|
|📝 更新|Weakly Supervised Segmentation of Hyper-Reflective Foci with Compact Convolutional Transformers and SAM2|弱监督下超反光焦点分割：紧凑卷积变换器和SAM2的应用|Olivier Morelle, Justus Bisten, Maximilian W. M. Wintergerst, Robert P. Finger, Thomas Schultz|<http://arxiv.org/pdf/2501.05933v2>|- 问题：弱监督分割，超反射焦点，空间分辨率低<br />- 方法：LRP提示，SAM2，紧凑卷积Transformer<br />- 效果：分割精度高，召回率提升|
|📝 更新|IMDPrompter: Adapting SAM to Image Manipulation Detection by Cross-View Automated Prompt Learning|IMDPrompter：通过跨视图自动提示学习将SAM应用于图像操纵检测的适应性调整|Quan Zhang, Yuxin Qi, Xi Tang, Jinwei Fang, Xi Lin, Ke Zhang, Chun Yuan|<http://arxiv.org/pdf/2502.02454v3>|- 问题：SAM，图像操作检测，手动提示，单视图信息<br />- 方法：IMDPrompter，跨视图提示学习，自动检测<br />- 效果：自动化，准确掩码|
|📝 更新|Cross-Species Data Integration for Enhanced Layer Segmentation in Kidney Pathology|跨物种数据集成以增强肾脏病理学层段分割|Junchao Zhu, Mengmeng Yin, Ruining Deng, Yitian Long, Yu Wang, Yaohong Wang, Shilin Zhao, Haichun Yang .etc.|<http://arxiv.org/pdf/2408.09278v2>|[[代码]](<https://github.com/hrlblab/layer_segmentation.>)<br />- 问题：肾脏病理，层分割，数据稀缺<br />- 方法：跨物种数据整合，CNN，Transformer<br />- 效果：mIoU提升，Dice提升|
|🆕 发布|Downstream Analysis of Foundational Medical Vision Models for Disease Progression|基础医学视觉模型在疾病进展中的下游分析|Basar Demir, Soumitri Chattopadhyay, Thomas Hastings Greer, Boqi Chen, Marc Niethammer|<http://arxiv.org/pdf/2503.16842v1>|- 问题：疾病进展预测，医学图像，特征提取<br />- 方法：线性探针，模型评估，特征分析<br />- 效果：预测准确，空间对齐，注册模型|


### 影像重建 (Image Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Recovering Pulse Waves from Video Using Deep Unrolling and Deep Equilibrium Models|从视频中恢复脉搏波：深度展开和深度平衡模型|Vineet R Shenoy, Suhas Lohit, Hassan Mansour, Rama Chellappa, Tim K. Marks|<http://arxiv.org/pdf/2503.17269v1>|- 问题：iPPG，脉搏信号恢复，心率估计<br />- 方法：信号处理，深度学习，逆问题框架<br />- 效果：心率估计，参数少|
|🆕 发布|Unsupervised Joint Learning of Optical Flow and Intensity with Event Cameras|无监督联合学习光流和强度的事件相机|Shuang Guo, Friedhelm Hamann, Guillermo Gallego|<http://arxiv.org/pdf/2503.17262v1>|[[代码]](<https://github.com/tub-rip/e2fai>)<br />- 问题：事件相机，光流，强度，联合学习<br />- 方法：事件生成模型，光流与强度联合估计，综合损失函数<br />- 效果：性能提升，动态范围，推理时间短|
|📝 更新|Deep End-to-end Adaptive k-Space Sampling, Reconstruction, and Registration for Dynamic MRI|深度端到端自适应k空间采样、重建和配准的动态MRI|George Yiasemis, Jan-Jakob Sonke, Jonas Teuwen|<http://arxiv.org/pdf/2411.18249v2>|- 问题：动态MRI， undersampling，图像质量，运动估计<br />- 方法：深度学习，自适应采样，联合训练<br />- 效果：性能提升，运动估计准确|
|🆕 发布|RAW-Adapter: Adapting Pre-trained Visual Model to Camera RAW Images and A Benchmark|RAW-Adapter：将预训练视觉模型适配到相机RAW图像及一个基准|Ziteng Cui, Jianfei Yang, Tatsuya Harada|<http://arxiv.org/pdf/2503.17027v1>|- 问题：RAW图像处理，ISP与网络融合，模型级协同<br />- 方法：RAW-Adapter，ISP模块，模型级适配器<br />- 效果：性能提升，泛化能力强|


### 疾病诊断 (Disease Diagnosis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Embedded Visual Prompt Tuning|嵌入式视觉提示微调|Wenqiang Zu, Shenghao Xie, Qing Zhao, Guoqi Li, Lei Ma|<http://arxiv.org/pdf/2407.01003v5>|[[代码]](<https://github.com/zuwenqiang/EPT.>)<br />- 问题：PEFT，跨域，少样本，医学图像<br />- 方法：嵌入式提示，特征空间，分布校准<br />- 效果：性能提升，时间高效|
|🆕 发布|A Comparative Analysis of Image Descriptors for Histopathological Classification of Gastric Cancer|胃癌组织病理学分类中图像描述符的比较分析|Marco Usai, Andrea Loddo, Alessandra Perniciano, Maurizio Atzori, Cecilia Di Ruberto|<http://arxiv.org/pdf/2503.17105v1>|- 问题：胃癌病理图像分类，诊断工具，预测准确性<br />- 方法：机器学习，深度学习，特征描述符比较<br />- 效果：高F1分数，高准确率|
|🆕 发布|PVChat: Personalized Video Chat with One-Shot Learning|PVChat：基于单次学习的个性化视频聊天|Yufei Shi, Weilong Yan, Gang Xu, Yumeng Li, Yuchen Li, Zhenxi Li, Fei Richard Yu, Ming Li .etc.|<http://arxiv.org/pdf/2503.17069v1>|- 问题：视频理解，身份感知，个性化，问答<br />- 方法：MoH ViLLM，自动增强，ReLU Routing MoH<br />- 效果：单视频问答，个性化特征理解|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|R-LiViT: A LiDAR-Visual-Thermal Dataset Enabling Vulnerable Road User Focused Roadside Perception|R-LiViT：一个面向易受伤害道路使用者道路侧感知的激光雷达-视觉-热成像数据集|Jonas Mirlach, Lei Wan, Andreas Wiedholz, Hannan Ejaz Keen, Andreas Eich|<http://arxiv.org/pdf/2503.17122v1>|- 问题：路边感知，VRU检测，数据集，极端光照<br />- 方法：LiDAR-RGB-thermal融合，多场景，多标注<br />- 效果：数据丰富，公开可用|
|🆕 发布|A New Statistical Model of Star Speckles for Learning to Detect and Characterize Exoplanets in Direct Imaging Observations|一种用于直接成像观测中检测和表征系外行星的星斑统计模型|Théo Bodrito, Olivier Flasseur, Julien Mairal, Jean Ponce, Maud Langlois, Anne-Marie Lagrange|<http://arxiv.org/pdf/2503.17117v1>|- 问题：星斑噪声，系外行星检测，图像处理<br />- 方法：多尺度模型，物理原理，联合通道表示<br />- 效果：精度提升，鲁棒性增强|


## 智能驾驶 (Intelligent Driving)


### 环境感知 (Environment Perception)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Leveraging V2X for Collaborative HD Maps Construction Using Scene Graph Generation|利用V2X进行基于场景图生成的协同高精度地图构建|Gamal Elghazaly, Raphael Frank|<http://arxiv.org/pdf/2502.10127v2>|- 问题：HD地图生成，成本高，变化捕捉差<br />- 方法：V2X通信，场景图生成，全局聚合<br />- 效果：预测性能优，实时性高|
|🆕 发布|Salient Object Detection in Traffic Scene through the TSOD10K Dataset|基于TSOD10K数据集的交通场景显著目标检测|Yu Qiu, Yuhang Sun, Jie Mei, Lin Xiao, Jing Xu|<http://arxiv.org/pdf/2503.16910v1>|- 问题：交通场景，显著性检测，安全驾驶<br />- 方法：TSOD10K数据集，Mamba模型，Dual-Frequency模块<br />- 效果：性能提升，基准建立|
|📝 更新|Moto: Latent Motion Token as the Bridging Language for Learning Robot Manipulation from Videos|Moto：作为从视频中学习机器人操作的桥梁语言的潜在运动标记|Yi Chen, Yuying Ge, Weiliang Tang, Yizhuo Li, Yixiao Ge, Mingyu Ding, Ying Shan, Xihui Liu|<http://arxiv.org/pdf/2412.04445v3>|- 问题：机器人学习，视频数据，动作标签，低成本<br />- 方法：Moto，运动标记，自回归预训练<br />- 效果：高效，鲁棒，知识迁移|


### 轨迹预测 (Trajectory Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Physical Plausibility-aware Trajectory Prediction via Locomotion Embodiment|基于运动具身感知的物理合理性轨迹预测|Hiromu Taketsugu, Takeru Oba, Takahiro Maeda, Shohei Nobuhara, Norimichi Ukita|<http://arxiv.org/pdf/2503.17267v1>|[[代码]](<https://github.com/ImIntheMiddle/EmLoco.>)<br />- 问题：HTP预测不真实，物理不合理<br />- 方法：Locomotion Embodiment，可微分运动值函数，Embodied Locomotion loss<br />- 效果：性能提升，数据驱动|


### 决策规划 (Decision Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|When Words Outperform Vision: VLMs Can Self-Improve Via Text-Only Training For Human-Centered Decision Making|当文字胜过视觉：VLMs可通过仅用文本训练实现自我改进以支持以人为中心的决策制定|Zhe Hu, Jing Li, Yu Yin|<http://arxiv.org/pdf/2503.16965v1>|- 问题：VLMs，复杂决策，人类中心，视觉限制<br />- 方法：文本仅训练，合成数据，自改进<br />- 效果：性能提升，效率增强|


## 工业视觉 (Industrial Vision)


### 缺陷检测 (Defect Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Survey on RGB, 3D, and Multimodal Approaches for Unsupervised Industrial Image Anomaly Detection|RGB、3D和多模态方法在无监督工业图像异常检测中的应用综述|Yuxuan Lin, Yang Chang, Xuan Tong, Jiawen Yu, Antonio Liotta, Guofan Huang, Wei Song, Deyu Zeng .etc.|<http://arxiv.org/pdf/2410.21982v2>|[[代码]](<https://github.com/Sunny5250/Awesome-Multi-Setting-UIAD.>)<br />- 问题：工业图像异常检测，RGB，3D，多模态<br />- 方法：综合综述，特征融合策略，挑战与方向<br />- 效果：性能提升，自动化，可靠性增强|


## 其他 (Others)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Topological Data Analysis Framework for Quantifying Necrosis in Glioblastomas|一种用于量化胶质母细胞瘤坏死的拓扑数据分析框架|Francisco Tellez, Enrique Torres-Giese|<http://arxiv.org/pdf/2503.17331v1>|- 问题：肿瘤坏死量化，结构分析，MRI研究<br />- 方法：拓扑数据分析，形状描述符，子复形空隙度<br />- 效果：坏死形态分析，肿瘤亚型识别|
|📝 更新|A General Adaptive Dual-level Weighting Mechanism for Remote Sensing Pansharpening|通用自适应双级加权机制在遥感全色融合中的应用|Jie Huang, Haorui Chen, Jiaxuan Ren, Siran Peng, Liangjian Deng|<http://arxiv.org/pdf/2503.13214v3>|[[代码]](<https://github.com/Jie-1203/ADWM.>)<br />- 问题：特征异质性，冗余，深度学习方法<br />- 方法：协方差矩阵，CACW，ADWM<br />- 效果：性能提升，泛化性，可视化|
|📝 更新|Training Neural Networks on RAW and HDR Images for Restoration Tasks|基于RAW和HDR图像的神经网络训练用于修复任务|Andrew Yanzhe Ke, Lei Luo, Alexandre Chapiro, Xiaoyu Xiang, Yuchen Fan, Rakesh Ranjan, Rafal Mantiuk|<http://arxiv.org/pdf/2312.03640v2>|- 问题：RAW/HDR图像训练，色彩空间，神经网络<br />- 方法：色彩空间转换，感知损失函数，图像恢复任务<br />- 效果：性能提升，感知均匀性|
|🆕 发布|DCEdit: Dual-Level Controlled Image Editing via Precisely Localized Semantics|DCEdit：基于精确定位语义的双层控制图像编辑|Yihan Hu, Jianing Peng, Yiheng Lin, Ting Liu, Xiaochao Qu, Luoqi Liu, Yao Zhao, Yunchao Wei|<http://arxiv.org/pdf/2503.16795v1>|- 问题：文本引导，图像编辑，语义定位，编辑精度<br />- 方法：语义定位策略，双重控制机制，自注意力<br />- 效果：背景保留，编辑准确|

