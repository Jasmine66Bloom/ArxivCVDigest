## [UPDATED!] **2025-03-22** (Update Time)


## 表示学习 (Representation Learning)


### 预训练模型 (Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|IceBench: A Benchmark for Deep Learning based Sea Ice Type Classification|冰基准：基于深度学习的海冰类型分类基准|Samira Alkaee Taleghan, Andrew P. Barrett, Walter N. Meier, Farnoush Banaei-Kashani|<http://arxiv.org/pdf/2503.17877v1>|- 问题：海冰分类，传统方法，效率低，偏差大<br />- 方法：IceBench基准，数据集，模型评估<br />- 效果：标准化，比较研究，模型迁移|
|🆕 发布|EMPLACE: Self-Supervised Urban Scene Change Detection|EMPLACE：自监督城市场景变化检测|Tim Alpherts, Sennay Ghebreab, Nanne van Noord|<http://arxiv.org/pdf/2503.17716v1>|- 问题：城市场景变化检测，数据标注，监督学习<br />- 方法：AC-1M数据集，自监督学习，Vision Transformer<br />- 效果：性能提升，零样本设置|


### 视觉Transformer (Vision Transformers)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Fractal-IR: A Unified Framework for Efficient and Scalable Image Restoration|分形-红外：一种高效且可扩展的图像恢复统一框架|Yawei Li, Bin Ren, Jingyun Liang, Rakesh Ranjan, Mengyuan Liu, Nicu Sebe, Ming-Hsuan Yang, Luca Benini|<http://arxiv.org/pdf/2503.17825v1>|- 问题：图像恢复，可扩展性，计算效率<br />- 方法：分形架构，局部信息扩展，模型缩放策略<br />- 效果：性能提升，PSNR增益|
|🆕 发布|Serial Low-rank Adaptation of Vision Transformer|序列低秩自适应视觉Transformer|Houqiang Zhong, Shaocheng Shen, Ke Cai, Zhenglong Wu, Jiangchao Yao, Yuan Cheng, Xuefei Li, Xiaoyun Zhang .etc.|<http://arxiv.org/pdf/2503.17750v1>|- 问题：参数高效，低秩适应，视觉Transformer<br />- 方法：Serial LoRA，低秩矩阵，注意力机制<br />- 效果：参数减少，性能相当|
|📝 更新|ShadowMaskFormer: Mask Augmented Patch Embeddings for Shadow Removal|阴影去除的掩码增强补丁嵌入：ShadowMaskFormer|Zhuohao Li, Guoyang Xie, Guannan Jiang, Zhichao Lu|<http://arxiv.org/pdf/2404.18433v3>|[[代码]](<https://github.com/lizhh268/ShadowMaskFormer.>)<br />- 问题：阴影去除，Transformer，注意力机制，计算资源<br />- 方法：ShadowMaskFormer，mask-augmented patch embedding，阴影信息整合<br />- 效果：模型参数少，性能优越|
|📝 更新|Enhancing Layer Attention Efficiency through Pruning Redundant Retrievals|通过剪枝冗余检索增强层注意力效率|Hanze Li, Xiande Huang|<http://arxiv.org/pdf/2503.06473v3>|- 问题：层注意力机制，冗余，特征提取<br />- 方法：KL散度，EBQM，跳过冗余层<br />- 效果：训练时间减少30%，性能提升|


## 生成建模 (Generative Modeling)


### 扩散模型 (Diffusion Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Simpler Diffusion (SiD2): 1.5 FID on ImageNet512 with pixel-space diffusion|简化扩散（SiD2）：在ImageNet512上实现1.5 FID的像素空间扩散|Emiel Hoogeboom, Thomas Mensink, Jonathan Heek, Kay Lamerigts, Ruiqi Gao, Tim Salimans|<http://arxiv.org/pdf/2410.19324v2>|- 问题：高分辨率图像合成，效率，质量<br />- 方法：像素空间扩散模型，简化架构，超参数优化<br />- 效果：1.5 FID，SOTA结果|
|📝 更新|DiffusionRenderer: Neural Inverse and Forward Rendering with Video Diffusion Models|扩散渲染器：基于视频扩散模型的神经逆渲染和正向渲染|Ruofan Liang, Zan Gojcic, Huan Ling, Jacob Munkberg, Jon Hasselgren, Zhi-Hao Lin, Jun Gao, Alexander Keller .etc.|<http://arxiv.org/pdf/2501.18590v2>|- 问题：逆渲染，正向渲染，光照模拟，场景表示<br />- 方法：视频扩散模型，G缓冲估计，神经渲染<br />- 效果：性能优越，应用广泛|
|📝 更新|GenDeg: Diffusion-based Degradation Synthesis for Generalizable All-In-One Image Restoration|GenDeg：基于扩散的通用一体化图像退化合成|Sudarshan Rajagopalan, Nithin Gopalakrishnan Nair, Jay N. Paranjape, Vishal M. Patel|<http://arxiv.org/pdf/2411.17687v2>|- 问题：泛化能力差，数据多样性不足，数据获取困难<br />- 方法：生成模型，条件扩散模型，合成退化图像<br />- 效果：性能提升，泛化能力增强|
|📝 更新|VD3D: Taming Large Video Diffusion Transformers for 3D Camera Control|VD3D：驯服大型视频扩散变换器以控制3D摄像机|Sherwin Bahmani, Ivan Skorokhodov, Aliaksandr Siarohin, Willi Menapace, Guocheng Qian, Michael Vasilkovsky, Hsin-Ying Lee, Chaoyang Wang .etc.|<http://arxiv.org/pdf/2407.12781v3>|- 问题：视频生成，相机控制，3D视觉<br />- 方法：Transformer，控制Net，时空嵌入<br />- 效果：可控生成，性能领先|
|🆕 发布|Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models|渐进式提示细化以提高文本到图像生成模型的对齐|Ketan Suhaas Saichandran, Xavier Thomas, Prakhar Kaushik, Deepti Ghadiyaram|<http://arxiv.org/pdf/2503.17794v1>|- 问题：文本到图像生成，对齐困难，复杂场景<br />- 方法：SCoPE，粗到细提示嵌入，插值<br />- 效果：VQA分数提升，性能增强|
|📝 更新|AC3D: Analyzing and Improving 3D Camera Control in Video Diffusion Transformers|AC3D：分析并改进视频扩散变换器中的3D相机控制|Sherwin Bahmani, Ivan Skorokhodov, Guocheng Qian, Aliaksandr Siarohin, Willi Menapace, Andrea Tagliasacchi, David B. Lindell, Sergey Tulyakov|<http://arxiv.org/pdf/2411.18673v3>|- 问题：3D相机控制，视频生成质量，训练参数<br />- 方法：低频运动分析，架构优化，定制数据集<br />- 效果：训练速度提升，视觉质量提高|
|🆕 发布|DVG-Diffusion: Dual-View Guided Diffusion Model for CT Reconstruction from X-Rays|DVG-Diffusion：基于双视图引导的X射线CT重建扩散模型|Xing Xie, Jiawei Liu, Huijie Fan, Zhi Han, Yandong Tang, Liangqiong Qu|<http://arxiv.org/pdf/2503.17804v1>|- 问题：CT重建，X射线，少视图，深度学习<br />- 方法：DVG-Diffusion，视图引导，特征对齐<br />- 效果：高保真，感知质量|
|📝 更新|Beyond Flat Text: Dual Self-inherited Guidance for Visual Text Generation|超越平面文本：视觉文本生成的双重自继承指导|Minxing Luo, Zixun Xia, Liaojun Chen, Zhenhang Li, Weichao Zeng, Jianye Wang, Wentao Cheng, Yaxing Wang .etc.|<http://arxiv.org/pdf/2501.05892v2>|- 问题：视觉文本生成，文本扭曲，背景不和谐<br />- 方法：语义校正，结构注入，先验融合<br />- 效果：高精度，高质量|
|📝 更新|MOVIS: Enhancing Multi-Object Novel View Synthesis for Indoor Scenes|MOVIS：增强室内场景多对象新颖视图合成|Ruijie Lu, Yixin Chen, Junfeng Ni, Baoxiong Jia, Yu Liu, Diwen Wan, Gang Zeng, Siyuan Huang|<http://arxiv.org/pdf/2412.11457v2>|[[代码]](<https://jason-aplp.github.io/MOVIS>)<br />- 问题：多对象新视角合成，结构一致性，模型局限性<br />- 方法：结构感知特征，辅助任务，结构引导采样<br />- 效果：一致性提升，泛化能力强|
|🆕 发布|Towards Invisible Backdoor Attack on Text-to-Image Diffusion Model|向文本到图像扩散模型的无形后门攻击|Jie Zhang, Zhongqi Wang, Shiguang Shan, Xilin Chen|<http://arxiv.org/pdf/2503.17724v1>|[[代码]](<https://github.com/Robin-WZQ/IBA.>)<br />- 问题：文本到图像模型，后门攻击，可检测性<br />- 方法：IBA，语义一致性，注意力一致性<br />- 效果：攻击成功率97.5%，防御绕过率98%|
|🆕 发布|DynASyn: Multi-Subject Personalization Enabling Dynamic Action Synthesis|动态动作合成多主体个性化：DynASyn|Yongjin Choi, Chanhun Park, Seung Jun Baek|<http://arxiv.org/pdf/2503.17728v1>|- 问题：个性化，动态行为，过拟合，单一参考图<br />- 方法：概念先验，注意力图正则化，SDE编辑<br />- 效果：高真实感，超越基线|
|📝 更新|MagicQuill: An Intelligent Interactive Image Editing System|魔笔：一个智能交互式图像编辑系统|Zichen Liu, Yue Yu, Hao Ouyang, Qiuyu Wang, Ka Leong Cheng, Wen Wang, Zhiheng Liu, Qifeng Chen .etc.|<http://arxiv.org/pdf/2411.09703v2>|- 问题：图像编辑，操作复杂，效率低<br />- 方法：智能交互，MLLM实时预测，扩散先验<br />- 效果：高效编辑，高质量结果|
|📝 更新|Video Diffusion Transformers are In-Context Learners|视频扩散Transformer是上下文学习者|Zhengcong Fei, Di Qiu, Debang Li, Changqian Yu, Mingyuan Fan|<http://arxiv.org/pdf/2412.10783v3>|[[代码]](<https://github.com/feizc/Video-In-Context.>)<br />- 问题：视频扩散模型，上下文学习，微调<br />- 方法：视频拼接，多场景联合描述，小数据集微调<br />- 效果：长视频生成，无额外计算，高保真|
|🆕 发布|Towards Transformer-Based Aligned Generation with Self-Coherence Guidance|基于Transformer的对齐生成与自协调引导|Shulei Wang, Wang Lin, Hai Huang, Hanting Wang, Sihang Cai, WenKang Han, Tao Jin, Jingyuan Chen .etc.|<http://arxiv.org/pdf/2503.17675v1>|[[代码]](<https://scg-diffusion.github.io/scg-diffusion.>)<br />- 问题：语义对齐，复杂文本，属性绑定<br />- 方法：Self-Coherence Guidance，跨注意力优化<br />- 效果：性能优越，超越现有方法|
|🆕 发布|MotionDiff: Training-free Zero-shot Interactive Motion Editing via Flow-assisted Multi-view Diffusion|运动差异：基于流辅助多视角扩散的无训练零样本交互式运动编辑|Yikun Ma, Yiqing Li, Jiawei Wu, Zhi Jin|<http://arxiv.org/pdf/2503.17695v1>|- 问题：运动编辑，生成模型不确定性，多视图一致性<br />- 方法：无监督，光流，多视图扩散<br />- 效果：高质量，无需重训练|
|🆕 发布|OMR-Diffusion:Optimizing Multi-Round Enhanced Training in Diffusion Models for Improved Intent Understanding|OMR-Diffusion：优化扩散模型中的多轮增强训练以提升意图理解|Kun Li, Jianhui Wang, Miao Zhang, Xueqian Wang|<http://arxiv.org/pdf/2503.17660v1>|- 问题：多轮对话，意图理解，图像生成，用户偏好<br />- 方法：视觉共适应，奖励模型，多轮对话数据集<br />- 效果：意图理解提升，对话效率高|
|🆕 发布|Efficient Diffusion Training through Parallelization with Truncated Karhunen-Loève Expansion|高效通过截断Karhunen-Loève展开并行化的扩散训练|Yumeng Ren, Yaofang Liu, Aitor Artola, Laurent Mertz, Raymond H. Chan, Jean-michel Morel|<http://arxiv.org/pdf/2503.17657v1>|- 问题：训练速度慢，收敛慢，布朗运动复杂<br />- 方法：KL扩散，截断KL展开，并行化<br />- 效果：速度提升，FID分数降低|
|📝 更新|Implicit Image-to-Image Schrodinger Bridge for Image Restoration|隐式图像到图像薛定谔桥用于图像恢复|Yuang Wang, Siyeop Yoon, Pengfei Jin, Matthew Tivnan, Sifan Song, Zhennong Chen, Rui Hu, Li Zhang .etc.|<http://arxiv.org/pdf/2403.06069v3>|- 问题：图像恢复速度慢，I2SB迭代过程<br />- 方法：I3SB，非马尔可夫框架，信息利用<br />- 效果：加速，质量相同，步骤减少|
|📝 更新|Deciphering Oracle Bone Language with Diffusion Models|《利用扩散模型解读甲骨文语言》|Haisu Guan, Huanxin Yang, Xinyu Wang, Shengwei Han, Yongge Liu, Lianwen Jin, Xiang Bai, Yuliang Liu|<http://arxiv.org/pdf/2406.00684v3>|[[代码]](<https://github.com/guanhaisu/OBSD.>)<br />- 问题：甲骨文，未解之谜，古语言，AI decipherment<br />- 方法：扩散模型，图像生成，条件策略<br />- 效果：有效性，甲骨文数据集|
|📝 更新|PTDiffusion: Free Lunch for Generating Optical Illusion Hidden Pictures with Phase-Transferred Diffusion Model|PTDiffusion：相位迁移扩散模型生成光学错觉隐藏图片的免费午餐|Xiang Gao, Shuai Yang, Jiaying Liu|<http://arxiv.org/pdf/2503.06186v3>|- 问题：光学错觉，图像融合，文本引导<br />- 方法：PTDiffusion模型，相位迁移，无监督训练<br />- 效果：高质量，高保真，自然性|
|🆕 发布|Guidance Free Image Editing via Explicit Conditioning|无指导图像编辑：显式条件化|Mehdi Noroozi, Alberto Gil Ramos, Luca Morreale, Ruchika Chavhan, Malcolm Chadwick, Abhinav Mehrotra, Sourav Bhattacharya|<http://arxiv.org/pdf/2503.17593v1>|- 问题：CFG计算成本高，图像编辑效率低<br />- 方法：显式条件化，噪声分布建模<br />- 效果：效率提升，图像质量高|
|📝 更新|Diffusion-Aided Joint Source Channel Coding For High Realism Wireless Image Transmission|扩散辅助的高保真无线图像传输联合源信道编码|Mingyu Yang, Bowen Liu, Boyang Wang, Hun-Seok Kim|<http://arxiv.org/pdf/2404.17736v3>|- 问题：感知质量，带宽限制，SNR低<br />- 方法：Diffusion-Aided JSCC，多模态特征，控制模块<br />- 效果：高保真，低比特率|
|📝 更新|DreamRelation: Bridging Customization and Relation Generation|梦关系：连接定制与关系生成|Qingyu Shi, Lu Qi, Jianzong Wu, Jinbin Bai, Jingbo Wang, Yunhai Tong, Xiangtai Li|<http://arxiv.org/pdf/2410.23280v3>|- 问题：定制化图像生成，关系忽视，身份保留<br />- 方法：DreamRelation框架，关键点匹配损失，局部特征<br />- 效果：关系精确，身份保留|


### 生成对抗网络 (GANs)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FundusGAN: A Hierarchical Feature-Aware Generative Framework for High-Fidelity Fundus Image Generation|FundusGAN：一种用于高保真眼底图像生成的分层特征感知生成框架|Qingshan Hou, Meng Wang, Peng Cao, Zou Ke, Xiaoli Liu, Huazhu Fu, Osmar R. Zaiane|<http://arxiv.org/pdf/2503.17831v1>|- 问题：数据稀缺，诊断模型，预训练挑战<br />- 方法：FundusGAN，特征金字塔，StyleGAN<br />- 效果：高保真，诊断准确，性能提升|
|📝 更新|Linear Attention Modeling for Learned Image Compression|线性注意力建模用于学习图像压缩|Donghui Feng, Zhengxue Cheng, Shen Wang, Ronghua Wu, Hongwei Hu, Guo Lu, Li Song|<http://arxiv.org/pdf/2502.05741v2>|[[代码]](<https://github.com/sjtu-medialab/RwkvCompress>)<br />- 问题：图像压缩效率，低复杂度设计<br />- 方法：线性注意力模型，Bi-RWKV块，Omni-Shift模块<br />- 效果：RD性能提升，超越VTM-9.1|


### 自回归模型 (Autoregressive Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Bridging Continuous and Discrete Tokens for Autoregressive Visual Generation|跨越连续和离散标记以实现自回归视觉生成|Yuqing Wang, Zhijie Lin, Yao Teng, Yuanzhi Zhu, Shuhuai Ren, Jiashi Feng, Xihui Liu|<http://arxiv.org/pdf/2503.16430v2>|[[代码]](<https://yuqingwang1029.github.io/TokenBridge.>)<br />- 问题：图像压缩，信息损失，模型复杂度<br />- 方法：TokenBridge，后训练量化，轻量级预测<br />- 效果：质量相当，简单建模|


## 多模态学习 (Multimodal Learning)


### 视觉语言模型 (Vision-Language Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|good4cir: Generating Detailed Synthetic Captions for Composed Image Retrieval|Good4cir：为合成图像检索生成详细合成字幕|Pranavi Kolouju, Eric Xing, Robert Pless, Nathan Jacobs, Abby Stylianou|<http://arxiv.org/pdf/2503.17871v1>|- 问题：CIR数据集，标注不足，检索精度低<br />- 方法：视觉语言模型，细粒度描述，文本指令合成<br />- 效果：检索精度提升，数据集扩展|
|🆕 发布|4D-Bench: Benchmarking Multi-modal Large Language Models for 4D Object Understanding|4D-Bench：用于4D物体理解的跨模态大型语言模型基准测试|Wenxuan Zhu, Bing Li, Cheng Zheng, Jinjie Mai, Jun Chen, Letian Jiang, Abdullah Hamdi, Sara Rojas Martinez .etc.|<http://arxiv.org/pdf/2503.17827v1>|- 问题：MLLMs 4D理解能力评估，缺乏标准化基准<br />- 方法：4D-Bench，4D物体问答，4D物体描述<br />- 效果：揭示时间理解差距，需进一步研究|
|🆕 发布|GOAL: Global-local Object Alignment Learning|目标：全局-局部目标对齐学习|Hyungyu Choi, Young Kyun Jang, Chanho Eom|<http://arxiv.org/pdf/2503.17782v1>|- 问题：长文本描述，CLIP，语义对齐<br />- 方法：LISM，TSL，局部语义对齐<br />- 效果：性能提升，适应详细描述|
|🆕 发布|V2P-Bench: Evaluating Video-Language Understanding with Visual Prompts for Better Human-Model Interaction|V2P-Bench：利用视觉提示评估视频语言理解以优化人机交互|Yiming Zhao, Yu Zeng, Yukun Qi, YaoYang Liu, Lin Chen, Zehui Chen, Xikun Bao, Jie Zhao .etc.|<http://arxiv.org/pdf/2503.17736v1>|[[代码]](<https://github.com/gaotiexinqu/V2P-Bench.>)<br />- 问题：视频理解，文本提示，交互效率低<br />- 方法：V2P-Bench，多模态交互，视觉提示<br />- 效果：模型性能低，认知对齐|
|📝 更新|ChatReID: Open-ended Interactive Person Retrieval via Hierarchical Progressive Tuning for Vision Language Models|ChatReID：基于分层渐进调优的视觉语言模型的开端交互式人物检索|Ke Niu, Haiyang Yu, Mengyang Zhao, Teng Fu, Siyang Yi, Wei Lu, Bin Li, Xuelin Qian .etc.|<http://arxiv.org/pdf/2502.19958v2>|- 问题：Re-ID，VLM应用，匹配精度<br />- 方法：ChatReID，指令数据集，分层渐进调优<br />- 效果：SOTA性能，细粒度识别|
|📝 更新|Omni-RGPT: Unifying Image and Video Region-level Understanding via Token Marks|全视域RGPT：通过标记统一图像和视频区域级理解|Miran Heo, Min-Hung Chen, De-An Huang, Sifei Liu, Subhashree Radhakrishnan, Seon Joo Kim, Yu-Chiang Frank Wang, Ryo Hachiuma|<http://arxiv.org/pdf/2501.08326v2>|- 问题：区域理解，多模态，视频理解<br />- 方法：Token Mark，区域提示，辅助任务<br />- 效果：SOTA结果，强性能|
|🆕 发布|CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model|CountLLM：通过大型语言模型实现可泛化的重复动作计数|Ziyu Yao, Xuxin Cheng, Zhiqi Huang, Lei Li|<http://arxiv.org/pdf/2503.17690v1>|- 问题：重复动作计数，回归网络，泛化能力，过拟合<br />- 方法：CountLLM，LLM，周期性模板，多模态训练<br />- 效果：性能优越，泛化性强|
|🆕 发布|TDRI: Two-Phase Dialogue Refinement and Co-Adaptation for Interactive Image Generation|双阶段交互式图像生成对话精炼与协同适应|Yuheng Feng, Jianhui Wang, Kun Li, Sida Li, Tianyu Shi, Haoyue Han, Miao Zhang, Xueqian Wang|<http://arxiv.org/pdf/2503.17669v1>|- 问题：模糊提示，用户意图对齐，生成质量<br />- 方法：两阶段对话，D2P模块，FR模块，AO模块<br />- 效果：用户满意度提升，迭代反馈，个性化|


### 跨模态对齐 (Cross-modal Alignment)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Eye Gaze as a Signal for Conveying User Attention in Contextual AI Systems|眼动作为传递用户注意力的信号在情境人工智能系统中的应用|Ethan Wilson, Naveen Sendhilnathan, Charlie S. Burlingham, Yusuf Mansour, Robert Cavin, Sai Deep Tetali, Ajoy Savio Fernandes, Michael J. Proulx|<http://arxiv.org/pdf/2501.13878v2>|- 问题：用户意图，系统交互，眼动追踪<br />- 方法：眼动信号，任务上下文，多模态代理<br />- 效果：用户体验，信息传递|
|🆕 发布|Aligning Foundation Model Priors and Diffusion-Based Hand Interactions for Occlusion-Resistant Two-Hand Reconstruction|对齐基础模型先验和基于扩散的手部交互以实现抗遮挡双手重建|Gaoge Han, Yongkang Cheng, Zhe Chen, Shaoli Huang, Tongliang Liu|<http://arxiv.org/pdf/2503.17788v1>|- 问题：手部重建，遮挡，交互对齐<br />- 方法：融合对齐编码器，扩散模型，梯度降噪<br />- 效果：性能提升，遮挡处理，交互鲁棒|
|📝 更新|RankByGene: Gene-Guided Histopathology Representation Learning Through Cross-Modal Ranking Consistency|RankByGene：通过跨模态排名一致性引导的病理学图像基因指导表示学习|Wentao Huang, Meilong Xu, Xiaoling Hu, Shahira Abousamra, Aniruddha Ganguly, Saarthak Kapse, Alisa Yurovsky, Prateek Prasanna .etc.|<http://arxiv.org/pdf/2411.15076v2>|- 问题：基因表达与组织图像对齐，跨模态关系，空间扭曲<br />- 方法：排名一致性，知识蒸馏，教师-学生网络<br />- 效果：对齐改善，预测性能提升|
|🆕 发布|Leveraging Audio Representations for Vibration-Based Crowd Monitoring in Stadiums|利用音频表示进行体育场振动式人群监控|Yen Cheng Chang, Jesse Codling, Yiwen Dong, Jiale Zhang, Jiasi Chen, Hae Young Noh, Pei Zhang|<http://arxiv.org/pdf/2503.17646v1>|- 问题：隐私，监控，振动，数据缺乏，行为预测<br />- 方法：ViLA，音频预训练，跨模态学习<br />- 效果：误差降低，性能提升|


## 目标检测识别 (Object Detection & Recognition)


### 二维检测 (2D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SynMorph: Generating Synthetic Face Morphing Dataset with Mated Samples|SynMorph：使用配对样本生成合成人脸变形数据集|Haoyu Zhang, Raghavendra Ramachandra, Kiran Raja, Christoph Busch|<http://arxiv.org/pdf/2409.05595v2>|- 问题：数据缺乏，隐私限制，MAD算法<br />- 方法：合成数据集，2450身份，100k形态<br />- 效果：质量评估，性能提升，算法训练|
|📝 更新|Referring Camouflaged Object Detection|参考伪装物体检测|Xuying Zhang, Bowen Yin, Zheng Lin, Qibin Hou, Deng-Ping Fan, Ming-Ming Cheng|<http://arxiv.org/pdf/2306.07532v3>|[[代码]](<https://github.com/zhangxuying1004/RefCOD.>)<br />- 问题：Ref-COD, 隐蔽目标检测<br />- 方法：R2CNet, 引用分支，分割分支<br />- 效果：性能优越，公开数据集|
|📝 更新|SwinTextSpotter v2: Towards Better Synergy for Scene Text Spotting|SwinTextSpotter v2：迈向场景文本检测的更好协同|Mingxin Huang, Dezhi Peng, Hongliang Li, Zhenghao Peng, Chongyu Liu, Dahua Lin, Yuliang Liu, Xiang Bai .etc.|<http://arxiv.org/pdf/2401.07641v2>|[[代码]](<https://github.com/mxin262/SwinTextSpotterv2>)<br />- 问题：文本检测识别，特征交互，任务协同<br />- 方法：识别转换模块，识别对齐模块，Box Selection Schedule<br />- 效果：性能提升，多语言支持|
|🆕 发布|BackMix: Regularizing Open Set Recognition by Removing Underlying Fore-Background Priors|BackMix：通过去除底层前景-背景先验来正则化开放集识别|Yu Wang, Junxian Mu, Hongzhi Huang, Qilong Wang, Pengfei Zhu, Qinghua Hu|<http://arxiv.org/pdf/2503.17717v1>|[[代码]](<https://github.com/Vanixxz/BackMix.>)<br />- 问题：OSR模型，背景干扰，选择困难<br />- 方法：BackMix，前景背景分离，全局平均池化<br />- 效果：性能提升，简单易用|


### 三维检测 (3D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Breaking the SSL-AL Barrier: A Synergistic Semi-Supervised Active Learning Framework for 3D Object Detection|打破SSL-AL壁垒：一种用于3D目标检测的协同半监督主动学习框架|Zengran Wang, Yanan Zhang, Jiaxin Chen, Di Huang|<http://arxiv.org/pdf/2501.15449v2>|[[代码]](<https://github.com/LandDreamer/S_SSAL.>)<br />- 问题：标注负担，SSL-AL冲突，性能不足<br />- 方法：CPSP预训练，CAL方法，模型级联<br />- 效果：少量标注，性能接近全数据集|
|📝 更新|Odd-One-Out: Anomaly Detection by Comparing with Neighbors|异常检测：与邻居比较的“奇数”方法|Ankan Bhunia, Changjian Li, Hakan Bilen|<http://arxiv.org/pdf/2406.20099v4>|- 问题：异常检测，场景特定，邻居比较<br />- 方法：3D模型，几何一致性，部分感知表示<br />- 效果：新基准，全面分析|
|🆕 发布|MAMAT: 3D Mamba-Based Atmospheric Turbulence Removal and its Object Detection Capability|MAMAT：基于3D Mamba的湍流去除及其目标检测能力|Paul Hill, Zhiming Liu, Nantheera Anantrasirichai|<http://arxiv.org/pdf/2503.17700v1>|- 问题：大气湍流，视频质量，对象检测<br />- 方法：3D Mamba，双模块策略，3D卷积<br />- 效果：质量提升，检测准确|
|📝 更新|Occlusion-aware Text-Image-Point Cloud Pretraining for Open-World 3D Object Recognition|开放世界3D物体识别的遮挡感知文本-图像-点云预训练|Khanh Nguyen, Ghulam Mubashar Hassan, Ajmal Mian|<http://arxiv.org/pdf/2502.10674v2>|[[代码]](<https://ndkhanh360.github.io/project-occtip.>)<br />- 问题：3D物体识别，遮挡，预训练，Transformer<br />- 方法：遮挡感知预训练，DuoMamba模型，空间依赖建模<br />- 效果：性能提升，降低延迟，减少计算量|


### 多目标跟踪 (Multi-object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MUST: The First Dataset and Unified Framework for Multispectral UAV Single Object Tracking|MUST：首个多光谱无人机单目标跟踪数据集和统一框架|Haolin Qin, Tingfa Xu, Tianhao Li, Zhenxiang Chen, Tao Feng, Jianan Li|<http://arxiv.org/pdf/2503.17699v1>|[[代码]](<https://github.com/q2479036243/MUST-Multispectral-UAV-Single-Object-Tracking.>)<br />- 问题：UAV跟踪，小目标，遮挡，RGB限制<br />- 方法：MUST数据集，UNTrack框架，光谱背景消除<br />- 效果：性能提升，效率提高|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SeedVR: Seeding Infinity in Diffusion Transformer Towards Generic Video Restoration|SeedVR：在扩散Transformer中播种无限，实现通用视频恢复|Jianyi Wang, Zhijie Lin, Meng Wei, Yang Zhao, Ceyuan Yang, Fei Xiao, Chen Change Loy, Lu Jiang|<http://arxiv.org/pdf/2501.01320v4>|- 问题：视频修复，保真度，时间一致性，生成能力，采样效率<br />- 方法：扩散Transformer，shifted window attention，变量窗口<br />- 效果：高性能，合成/真实基准，AI视频|


## 场景理解 (Scene Understanding)


### 语义分割 (Semantic Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Causal Adjustment Module for Debiasing Scene Graph Generation|因果调整模块用于场景图生成去偏|Li Liu, Shuzhou Sun, Shuaifeng Zhi, Fan Shi, Zhen Liu, Janne Heikkilä, Yongxiang Liu|<http://arxiv.org/pdf/2503.17862v1>|- 问题：模型偏差，长尾分布，对象分布，关系生成<br />- 方法：因果推理，MCCM模型，因果调整模块<br />- 效果：零样本关系，性能提升|


## 三维重建 (3D Reconstruction)


### 多视图重建 (Multi-view Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ReCap: Better Gaussian Relighting with Cross-Environment Captures|ReCap：基于跨环境捕获的更优高斯重光照|Jingzhi Li, Zongwei Wu, Eduard Zamfir, Radu Timofte|<http://arxiv.org/pdf/2412.07534v2>|- 问题：3D物体重光照，光照-材质模糊，物理对应缺失<br />- 方法：多任务学习，光照表示优化，材质属性共享<br />- 效果：准确重光照，鲁棒材质估计|
|📝 更新|PI-HMR: Towards Robust In-bed Temporal Human Shape Reconstruction with Contact Pressure Sensing|PI-HMR：基于接触压力传感的鲁棒床铺内人体形状重建方法|Ziyu Wu, Yufan Xiong, Mengting Niu, Fangting Xie, Quan Wan, Qijun Ying, Boyan Liu, Xiaohui Cai|<http://arxiv.org/pdf/2503.00068v2>|- 问题：非视距场景，隐私敏感，深度模糊，数据标注，模型设计<br />- 方法：SMPLify-IB，多尺度特征融合，压力序列回归<br />- 效果：性能提升，误差降低|
|📝 更新|MTGS: Multi-Traversal Gaussian Splatting|多遍历高斯分层渲染|Tianyu Li, Yihang Qiu, Zhenhua Wu, Carl Lindström, Peng Su, Matthias Nießner, Hongyang Li|<http://arxiv.org/pdf/2503.12552v3>|- 问题：多遍历数据，场景重建，动态物体，外观变化<br />- 方法：MTGS，动态场景图，颜色校正，球谐系数<br />- 效果：LPIPS提升，几何精度提升|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CODA: Repurposing Continuous VAEs for Discrete Tokenization|CODA：将连续变分自编码器重新用于离散标记化|Zeyu Liu, Zanlin Ni, Yeguo Hua, Xin Deng, Xiao Ma, Cheng Zhong, Gao Huang|<http://arxiv.org/pdf/2503.17760v1>|- 问题：离散视觉标记，训练不稳定，低代码簿利用率，重建质量有限<br />- 方法：CODA框架，连续到离散适配，离散化过程<br />- 效果：高代码簿利用率，低FID，高重建质量|


## 神经渲染 (Neural Rendering)


### 可控渲染 (Controllable Rendering)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GaussianFocus: Constrained Attention Focus for 3D Gaussian Splatting|高斯聚焦：3D高斯分层约束注意力聚焦|Zexu Huang, Min Xu, Stuart Perry|<http://arxiv.org/pdf/2503.17798v1>|- 问题：冗余噪声，渲染质量，大场景限制<br />- 方法：注意力焦点，约束策略，细分重建<br />- 效果：质量提升，大场景渲染|
|📝 更新|LAYOUTDREAMER: Physics-guided Layout for Text-to-3D Compositional Scene Generation|布局梦想家：基于物理的布局用于文本到3D组合场景生成|Yang Zhou, Zongjin He, Qixuan Li, Chao Wang|<http://arxiv.org/pdf/2502.01949v2>|- 问题：文本引导3D场景生成，物理真实性，可控制性<br />- 方法：3D高斯分层，场景图，动态相机调整<br />- 效果：SOTA性能，多物体生成|


### 神经辐射场 (Neural Radiance Fields)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Gaussian Splatting for Efficient Satellite Image Photogrammetry|高斯喷溅技术在卫星影像摄影测量中的应用|Luca Savant Aira, Gabriele Facciolo, Thibaud Ehret|<http://arxiv.org/pdf/2412.13047v2>|- 问题：卫星图像，3D建模，效率低<br />- 方法：Gaussian splatting，EO-NeRF，稀疏性，一致性<br />- 效果：效率高，性能优|


### 场景编辑 (Scene Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GS-LTS: 3D Gaussian Splatting-Based Adaptive Modeling for Long-Term Service Robots|GS-LTS：基于3D高斯分层散布的长期服务机器人自适应建模|Bin Fu, Jialin Li, Bin Zhang, Ruiping Wang, Xilin Chen|<http://arxiv.org/pdf/2503.17733v1>|[[代码]](<https://vipl-vsu.github.io/3DGS-LTS.>)<br />- 问题：3DGS，动态场景，长期服务，场景更新<br />- 方法：3DGS，单图变化检测，多视角观察，高斯编辑<br />- 效果：场景更新，重建，导航|


## 定位与映射 (Localization & Mapping)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LightLoc: Learning Outdoor LiDAR Localization at Light Speed|光速定位：以光速学习户外激光雷达定位|Wen Li, Chen Liu, Shangshu Yu, Dunqiang Liu, Yin Zhou, Siqi Shen, Chenglu Wen, Cheng Wang|<http://arxiv.org/pdf/2503.17814v1>|[[代码]](<https://github.com/liw95/LightLoc.>)<br />- 问题：训练时间长，场景覆盖广，数据量大<br />- 方法：样本分类指导，冗余样本下采样<br />- 效果：训练时间缩短50倍，性能最优|


### 位姿估计 (Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Co-op: Correspondence-based Novel Object Pose Estimation|基于对应关系的创新物体姿态估计|Sungphill Moon, Hyeontae Son, Dongcheol Hur, Sangwook Kim|<http://arxiv.org/pdf/2503.17731v1>|- 问题：单图新物体姿态估计，效率低，泛化差<br />- 方法：对应关系，半密集匹配，混合表示<br />- 效果：快速准确，BOP挑战赛最佳|
|🆕 发布|3D Modeling: Camera Movement Estimation and path Correction for SFM Model using the Combination of Modified A-SIFT and Stereo System|三维建模：基于改进A-SIFT与立体系统的相机运动估计及路径校正用于SFM模型|Usha Kumari, Shuvendu Rana|<http://arxiv.org/pdf/2503.17668v1>|- 问题：3D建模，视角变化，计算复杂，对齐误差<br />- 方法：ASIFT改进，旋转校正，立体视觉<br />- 效果：高精度，超越现有方法|


### 语义建图 (Semantic Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhancing Martian Terrain Recognition with Deep Constrained Clustering|增强火星地形识别的深度约束聚类|Tejas Panambur, Mario Parente|<http://arxiv.org/pdf/2503.17633v1>|- 问题：火星地形识别，深度聚类，特征嵌入，自然变化<br />- 方法：DCCML，约束聚类，软硬约束，度量学习<br />- 效果：聚类精度提升，检索准确率提高|


### 视觉SLAM (Visual SLAM)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Learning-based 3D Reconstruction in Autonomous Driving: A Comprehensive Survey|基于学习的自动驾驶3D重建：全面综述|Liewen Liao, Weihao Yan, Ming Yang, Songan Zhang|<http://arxiv.org/pdf/2503.14537v2>|- 问题：3D重建，自动驾驶，场景理解<br />- 方法：学习模型，数据增强，多视角分析<br />- 效果：技术参考，趋势总结|


## 自监督学习 (Self-supervised Learning)


### 掩码自编码 (Masked Autoencoding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Efficient Self-supervised Vision Pretraining with Local Masked Reconstruction|高效的自监督视觉预训练：局部掩码重建|Jun Chen, Ming Hu, Boyang Li, Mohamed Elhoseiny|<http://arxiv.org/pdf/2206.00790v3>|[[代码]](<https://github.com/junchen14/LoMaR.>)<br />- 问题：计算复杂度高，效率低<br />- 方法：局部掩码重建，Transformer编码器<br />- 效果：精度提升，效率高|


### 对比学习 (Contrastive Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Unsupervised Foundation Model-Agnostic Slide-Level Representation Learning|无监督基础模型无关的幻灯片级表示学习|Tim Lenz, Peter Neidlinger, Marta Ligero, Georg Wölflein, Marko van Treeck, Jakob Nikolas Kather|<http://arxiv.org/pdf/2411.13623v3>|[[代码]](<https://github.com/KatherLab/COBRA.>)<br />- 问题：病理图像表示学习，弱监督，MIL<br />- 方法：单模态SSL，FM集成，COBRA预训练<br />- 效果：AUC提升，性能优越|
|🆕 发布|Normalized Matching Transformer|归一化匹配转换器|Abtin Pourhadi, Paul Swoboda|<http://arxiv.org/pdf/2503.17715v1>|- 问题：稀疏关键点匹配，图像配对<br />- 方法：视觉骨干，SplineCNN，Transformer，Sinkhorn算法<br />- 效果：性能提升，数据增强|
|📝 更新|Neural-MCRL: Neural Multimodal Contrastive Representation Learning for EEG-based Visual Decoding|神经-多模态对比表征学习用于基于EEG的视觉解码|Yueyang Li, Zijian Kang, Shengyu Gong, Wenhao Dong, Weiming Zeng, Hongjie Yan, Wai Ting Siok, Nizhuan Wang|<http://arxiv.org/pdf/2412.17337v2>|[[代码]](<https://github.com/NZWANG/Neural-MCRL.>)<br />- 问题：EEG视觉解码，多模态，语义一致性<br />- 方法：语义桥接，跨模态对齐，NESTA编码器<br />- 效果：解码精度提升，模型泛化性增强|


### 一致性学习 (Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Collaborative Temporal Consistency Learning for Point-supervised Natural Language Video Localization|协同时间一致性学习用于点监督的自然语言视频定位|Zhuo Tao, Liang Li, Qi Chen, Yunbin Tu, Zheng-Jun Zha, Ming-Hsuan Yang, Yuankai Qi, Qingming Huang|<http://arxiv.org/pdf/2503.17651v1>|- 问题：NLVL，点监督，时间一致性，标注成本<br />- 方法：COTEL框架，TCL模块，交叉一致性指导，HCAL损失<br />- 效果：性能优越，SoTA，代码开源|
|🆕 发布|InstructVEdit: A Holistic Approach for Instructional Video Editing|指令视频编辑：一种全面的方法|Chi Zhang, Chengjian Feng, Feng Yan, Qiming Zhang, Mingjin Zhang, Yujie Zhong, Jing Zhang, Lin Ma|<http://arxiv.org/pdf/2503.17641v1>|[[代码]](<https://o937-blip.github.io/InstructVEdit.>)<br />- 问题：视频编辑，数据稀缺，模型架构，训练策略<br />- 方法：数据集构建，模型改进，迭代优化<br />- 效果：性能提升，泛化能力强|


## 迁移与适应 (Transfer & Adaptation)


### 域适应 (Domain Adaptation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VectorPainter: Advanced Stylized Vector Graphics Synthesis Using Stroke-Style Priors|向量画家：基于笔触风格先验的高级风格化矢量图形合成|Juncheng Hu, Ximing Xing, Jing Zhang, Qian Yu|<http://arxiv.org/pdf/2405.02962v3>|- 问题：文本到矢量图形，风格化，参考图像<br />- 方法：矢量化，模仿学习，风格保持<br />- 效果：风格化，矢量图形|
|📝 更新|Do ImageNet-trained models learn shortcuts? The impact of frequency shortcuts on generalization|图像网训练的模型是否学会了捷径？频率捷径对泛化能力的影响|Shunxin Wang, Raymond Veldhuis, Nicola Strisciuglio|<http://arxiv.org/pdf/2503.03519v2>|- 问题：频率捷径，泛化性能，计算成本<br />- 方法：大规模分析，CNN，Transformer<br />- 效果：识别捷径，影响评估|
|📝 更新|NavCoT: Boosting LLM-Based Vision-and-Language Navigation via Learning Disentangled Reasoning|NavCoT：通过学习解耦推理提升基于LLM的视觉-语言导航|Bingqian Lin, Yunshuang Nie, Ziming Wei, Jiaqi Chen, Shikui Ma, Jianhua Han, Hang Xu, Xiaojun Chang .etc.|<http://arxiv.org/pdf/2403.07376v2>|[[代码]](<https://github.com/expectorlin/NavCoT.>)<br />- 问题：VLN，LLM，领域差距<br />- 方法：NavCoT，参数高效，推理链<br />- 效果：性能提升，R2R数据集7%相对改进|
|🆕 发布|GUI-Xplore: Empowering Generalizable GUI Agents with One Exploration|GUI-Xplore：通过一次探索赋予通用GUI代理能力|Yuchen Sun, Shanhui Zhao, Tao Yu, Hao Wen, Samith Va, Mengwei Xu, Yuanchun Li, Chongyang Zhang|<http://arxiv.org/pdf/2503.17709v1>|- 问题：泛化能力，数据集限制，GUI应用，任务多样性<br />- 方法：GUI-Xplore，探索-推理框架，Xplore-Agent<br />- 效果：泛化提升，性能改善|
|🆕 发布|DCEvo: Discriminative Cross-Dimensional Evolutionary Learning for Infrared and Visible Image Fusion|DCEvo：用于红外和可见光图像融合的判别性跨维度进化学习|Jinyuan Liu, Bowei Zhang, Qingyun Mei, Xingyuan Li, Yang Zou, Zhiying Jiang, Long Ma, Risheng Liu .etc.|<http://arxiv.org/pdf/2503.17673v1>|[[代码]](<https://github.com/Beate-Suy-Zhang/DCEvo.>)<br />- 问题：红外可见光融合，任务性能提升，优化反馈<br />- 方法：判别性跨维度进化学习，多目标优化，判别增强器<br />- 效果：视觉质量提升，任务性能增强|
|📝 更新|RSNet: A Light Framework for The Detection of Multi-scale Remote Sensing Targets|RSNet：一种用于多尺度遥感目标检测的轻量级框架|Hongyu Chen, Chengcheng Chen, Fei Wang, Yugang Chang, Yuhu Shi, Weiming Zeng|<http://arxiv.org/pdf/2410.23073v6>|- 问题：小目标检测，参数少，背景复杂<br />- 方法：WCG骨干，WSF连接，LS检测组件<br />- 效果：mAP高，参数少|


### 元学习 (Meta Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Multimodal 3D Reasoning Segmentation with Complex Scenes|多模态复杂场景3D推理分割|Xueying Jiang, Lewei Lu, Ling Shao, Shijian Lu|<http://arxiv.org/pdf/2411.13927v2>|- 问题：3D场景理解，多模态学习，交互解释，单类别对象，空间关系<br />- 方法：ReasonSeg3D，MORE3D，3D推理，文本解释<br />- 效果：复杂场景分割，3D关系学习|
|🆕 发布|Visual Variational Autoencoder Prompt Tuning|视觉变分自编码器提示调整|Xi Xiao, Yunbei Zhang, Yanshuh Li, Xingjian Li, Tianyang Wang, Jihun Hamm, Xiao Wang, Min Xu|<http://arxiv.org/pdf/2503.17650v1>|- 问题：PEFT，视觉多样性，静态提示<br />- 方法：V$^2$APT，变分自编码器，动态提示<br />- 效果：性能提升，超越VPT-Deep|


## 鲁棒学习 (Robust Learning)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Topology preserving Image segmentation using the iterative convolution-thresholding method|拓扑保持图像分割的迭代卷积-阈值方法|Lingyun Deng, Litong Liu, Dong Wang, Xiao-Ping Wang|<http://arxiv.org/pdf/2503.17792v1>|- 问题：图像分割，拓扑属性，精度低<br />- 方法：拓扑保持，迭代卷积阈值法，TP-ICTM<br />- 效果：精度提升，鲁棒性增强|


## 模型压缩加速 (Model Compression & Acceleration)


### 知识蒸馏 (Knowledge Distillation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RDTF: Resource-efficient Dual-mask Training Framework for Multi-frame Animated Sticker Generation|资源高效的多帧动画贴纸生成双掩码训练框架：RDTF|Zhiqiang Yuan, Ting Zhang, Ying Deng, Jiapei Zhang, Yeshuang Zhu, Zexi Jia, Jie Zhou, Jinchao Zhang|<http://arxiv.org/pdf/2503.17735v1>|- 问题：资源受限，模型拟合能力差，知识迁移偏差<br />- 方法：自训练，双掩码数据利用，难度自适应课程学习<br />- 效果：性能优于参数高效调优，资源高效|
|📝 更新|X2I: Seamless Integration of Multimodal Understanding into Diffusion Transformer via Attention Distillation|X2I：通过注意力蒸馏将多模态理解无缝集成到扩散Transformer中|Jian Ma, Qirong Peng, Xu Guo, Chen Chen, Haonan Lu, Zhenyu Yang|<http://arxiv.org/pdf/2503.06134v2>|[[代码]](<https://github.com/OPPO-Mente-Lab/X2I.>)<br />- 问题：T2I模型，多模态理解，能力转移<br />- 方法：X2I框架，注意力蒸馏，AlignNet<br />- 效果：性能提升，多模态理解，适用LoRA|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EfficientViM: Efficient Vision Mamba with Hidden State Mixer based State Space Duality|EfficientViM：基于隐藏状态混合器的状态空间二重性高效视觉Mamba|Sanghyeok Lee, Joonmyung Choi, Hyunwoo J. Kim|<http://arxiv.org/pdf/2411.15241v2>|[[代码]](<https://github.com/mlvlab/EfficientViM.>)<br />- 问题：资源受限环境，神经网络部署，全局交互<br />- 方法：HSM-SSD，通道混合，多阶段融合<br />- 效果：速度-精度提升，性能改进|


## 医学影像分析 (Medical Image Analysis)


### 医学分割 (Medical Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ULTra: Unveiling Latent Token Interpretability in Transformer-Based Understanding and Segmentation|ULTra：揭示基于Transformer的理解和分割中潜在标记的可解释性|Hesam Hosseini, Ghazal Hosseini Mighan, Amirabbas Afzali, Sajjad Amini, Amir Houmansadr|<http://arxiv.org/pdf/2411.12589v2>|- 问题：Transformer可解释性，语义分割，模型复杂<br />- 方法：ULTra框架，自监督训练，外部变换矩阵<br />- 效果：无监督分割，性能领先，模型解释|
|🆕 发布|RefCut: Interactive Segmentation with Reference Guidance|RefCut：参考引导的交互式分割|Zheng Lin, Nan Zhou, Chen-Xi Du, Deng-Ping Fan, Shi-Min Hu|<http://arxiv.org/pdf/2503.17820v1>|- 问题：交互式分割，模糊性，标注负担<br />- 方法：参考图像，优化模型，目标分解数据集<br />- 效果：性能提升，效率提高|
|📝 更新|MaskSAM: Towards Auto-prompt SAM with Mask Classification for Volumetric Medical Image Segmentation|MaskSAM：面向具有掩码分类的自动提示SAM的体素医学图像分割|Bin Xie, Hao Tang, Bin Duan, Dawen Cai, Yan Yan, Gady Agam|<http://arxiv.org/pdf/2403.14103v2>|- 问题：SAM，医学图像分割，语义标签预测<br />- 方法：MaskSAM，prompt-free，3D深度卷积<br />- 效果：AMOS2022 90.52% Dice，超越nnUNet|
|🆕 发布|HiLoTs: High-Low Temporal Sensitive Representation Learning for Semi-Supervised LiDAR Segmentation in Autonomous Driving|高-低时序敏感表示学习在自动驾驶中的半监督激光雷达分割|R. D. Lin, Pengcheng Weng, Yinqiao Wang, Han Ding, Jinsong Han, Fei Wang|<http://arxiv.org/pdf/2503.17752v1>|[[代码]](<https://github.com/rdlin118/HiLoTs>)<br />- 问题：半监督LiDAR分割，时空敏感度，标注成本高<br />- 方法：HiLoTs，高低时敏表示学习，交叉注意力机制<br />- 效果：性能提升，接近LiDAR+Camera|
|📝 更新|Promoting Segment Anything Model towards Highly Accurate Dichotomous Image Segmentation|推动Segment Anything模型实现高度精确的二值图像分割|Xianjie Liu, Keren Fu, Yao Jiang, Qijun Zhao|<http://arxiv.org/pdf/2401.00248v3>|- 问题：SAM分割精度低，边界模糊<br />- 方法：DIS-SAM框架，两阶段方法，修改网络<br />- 效果：高精度分割，细节丰富|
|🆕 发布|Multi-modality Anomaly Segmentation on the Road|多模态道路异常分割|Heng Gao, Zhuolin He, Shoumeng Qiu, Xiangyang Xue, Jian Pu|<http://arxiv.org/pdf/2503.17712v1>|[[代码]](<https://github.com/HengGao12/MMRAS_plus.>)<br />- 问题：异常检测，语义分割，自动驾驶<br />- 方法：多模态，不确定性，CLIP编码器<br />- 效果：性能提升，数据集验证|
|🆕 发布|A Temporal Modeling Framework for Video Pre-Training on Video Instance Segmentation|视频实例分割的视频预训练时间建模框架|Qing Zhong, Peng-Tao Jiang, Wen Wang, Guodong Ding, Lin Wu, Kaiqi Huang|<http://arxiv.org/pdf/2503.17672v1>|- 问题：预训练模型，时序知识，域差距，视频实例分割<br />- 方法：伪视频增强，多尺度时序模块，自交叉注意力<br />- 效果：性能提升，平均精度提高|


### 影像重建 (Image Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ClaraVid: A Holistic Scene Reconstruction Benchmark From Aerial Perspective With Delentropy-Based Complexity Profiling|ClaraVid：基于熵减复杂性分析的空中视角整体场景重建基准|Radu Beche, Sergiu Nedevschi|<http://arxiv.org/pdf/2503.17856v1>|[[代码]](<https://rdbch.github.io/claravid>)<br />- 问题：数据稀缺，场景重建，渲染缺陷<br />- 方法：合成数据集，Delentropic Scene Profile，复杂度评估<br />- 效果：基准测试，复杂度与精度关联|
|🆕 发布|Hierarchy-Aware and Channel-Adaptive Semantic Communication for Bandwidth-Limited Data Fusion|带宽受限数据融合的层次感知和通道自适应语义通信|Lei Guo, Wei Chen, Yuxuan Sun, Bo Ai, Nikolaos Pappas, Tony Quek|<http://arxiv.org/pdf/2503.17777v1>|- 问题：高分辨率融合，带宽限制，数据密集<br />- 方法：层次感知，通道自适应，语义通信<br />- 效果：PSNR提升，带宽降低|
|📝 更新|StreamGS: Online Generalizable Gaussian Splatting Reconstruction for Unposed Image Streams|StreamGS：面向未摆姿势图像流的在线可泛化高斯分层重建|Yang LI, Jinglu Wang, Lei Chu, Xiao Li, Shiu-hong Kao, Ying-Cong Chen, Yan Lu|<http://arxiv.org/pdf/2503.06235v2>|- 问题：实时3DGS，未定位图像流，泛化能力，冗余减少<br />- 方法：内容自适应细化，跨帧特征聚合，在线重建<br />- 效果：速度提升，泛化性强|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LayerAnimate: Layer-level Control for Animation|层动画：层级动画控制|Yuxue Yang, Lue Fan, Zuzeng Lin, Feng Wang, Zhaoxiang Zhang|<http://arxiv.org/pdf/2501.08295v3>|- 问题：动画层控制，数据稀缺，层级控制<br />- 方法：层感知架构，数据整理流程，自动元素分割<br />- 效果：动画质量提升，控制精度高，易用性增强|


### 疾病诊断 (Disease Diagnosis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Assessing workflow impact and clinical utility of AI-assisted brain aneurysm detection: a multi-reader study|评估人工智能辅助脑动脉瘤检测的工作流程影响和临床效用：一项多读者研究|Tommaso Di Noto, Sofyan Jankowski, Francesco Puccinelli, Guillaume Marie, Sebastien Tourbier, Yasser Aleman-Gomez, Oscar Esteban, Ricardo Corredor-Jerez .etc.|<http://arxiv.org/pdf/2503.17786v1>|- 问题：AI脑动脉瘤检测，临床应用，多读者研究<br />- 方法：AI模型，多读者比较，临床验证<br />- 效果：AI辅助，性能无显著提升，阅读时间增加|
|📝 更新|MIRAM: Masked Image Reconstruction Across Multiple Scales for Breast Lesion Risk Prediction|MIRAM：多尺度掩码图像重建以预测乳腺病变风险|Hung Q. Vo, Pengyu Yuan, Zheng Yin, Kelvin K. Wong, Chika F. Ezeana, Son T. Ly, Stephen T. C. Wong, Hien V. Nguyen|<http://arxiv.org/pdf/2503.07157v2>|- 问题：乳腺癌风险预测，图像重建，自监督学习<br />- 方法：多尺度图像重建，掩码图像建模，SSL<br />- 效果：AP提升，AUC提升|
|🆕 发布|AI-Based Screening for Depression and Social Anxiety Through Eye Tracking: An Exploratory Study|基于人工智能的抑郁症和社会焦虑眼动筛查：一项探索性研究|Karol Chlasta, Katarzyna Wisiecka, Krzysztof Krejtz, Izabela Krejtz|<http://arxiv.org/pdf/2503.17625v1>|- 问题：抑郁症，焦虑症，视觉注意力，眼动追踪<br />- 方法：CNN，残差网络，眼动数据<br />- 效果：准确率48%，62%|


## 智能驾驶 (Intelligent Driving)


### 环境感知 (Environment Perception)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|mmCooper: A Multi-agent Multi-stage Communication-efficient and Collaboration-robust Cooperative Perception Framework|mmCooper：一种多智能体多阶段通信高效且协作鲁棒的协同感知框架|Bingyi Liu, Jian Teng, Hongfei Xue, Enshu Wang, Chuanhui Zhu, Pu Wang, Libing Wu|<http://arxiv.org/pdf/2501.12263v2>|- 问题：带宽限制，信息交换误差，感知性能<br />- 方法：多阶段协作，信息平衡，误信过滤<br />- 效果：感知性能提升，通信效率高|


## 其他 (Others)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MaIR: A Locality- and Continuity-Preserving Mamba for Image Restoration|MaIR：一种保留局部性和连续性的Mamba图像恢复方法|Boyun Li, Haiyu Zhao, Wenxin Wang, Peng Hu, Yuanbiao Gou, Xi Peng|<http://arxiv.org/pdf/2412.20066v2>|[[代码]](<https://github.com/XLearning-SCU/2025-CVPR-MaIR.>)<br />- 问题：局部关系，空间连续性，序列差异<br />- 方法：Nested S-shaped Scanning，Sequence Shuffle Attention<br />- 效果：超越40基线，SOTA性能|

