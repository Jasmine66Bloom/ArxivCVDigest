## [UPDATED!] **2025-03-25** (Update Time)


## 表示学习 (Representation Learning)


### 视觉Transformer (Vision Transformers)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FIPER: Generalizable Factorized Features for Robust Low-Level Vision Models|FIPER：用于鲁棒低级视觉模型的通用分解特征|Yang-Che Sun, Cheng Yu Yeo, Ernie Chu, Jun-Cheng Chen, Yu-Lun Liu|<http://arxiv.org/pdf/2410.18083v3>|- 问题：低级视觉任务，细节恢复，网络架构<br />- 方法：因子化特征，频率显式表达，基础系数分解<br />- 效果：性能提升，泛化能力强|
|📝 更新|CSCO: Connectivity Search of Convolutional Operators|卷积算子连接搜索：CSCO|Tunhou Zhang, Shiyu Li, Hsin-Pai Cheng, Feng Yan, Hai Li, Yiran Chen|<http://arxiv.org/pdf/2404.17152v2>|- 问题：连接性搜索，卷积算子，设计空间，搜索效率<br />- 方法：CSCO，神经预测器，图同构，MH-ES<br />- 效果：性能提升，样本效率|
|📝 更新|Aberration Correcting Vision Transformers for High-Fidelity Metalens Imaging|高保真金属透镜成像的像差校正视觉Transformer|Byeonghyeon Lee, Youbin Kim, Yongjae Jo, Hyunsu Kim, Hyemi Park, Yangkyu Kim, Debabrata Mandal, Praneeth Chakravarthula .etc.|<http://arxiv.org/pdf/2412.04591v2>|[[代码]](<https://benhenryl.github.io/Metalens-Transformer.>)<br />- 问题：金属透镜图像质量差，畸变校正<br />- 方法：ViT，MAFG，STAF模块<br />- 效果：图像质量提升，性能优于前人|
|🆕 发布|ChA-MAEViT: Unifying Channel-Aware Masked Autoencoders and Multi-Channel Vision Transformers for Improved Cross-Channel Learning|ChA-MAEViT：统一通道感知掩码自编码器和多通道视觉Transformer以提升跨通道学习|Chau Pham, Juan C. Caicedo, Bryan A. Plummer|<http://arxiv.org/pdf/2503.19331v1>|- 问题：跨通道学习，MAE局限性，MCI特征互补<br />- 方法：动态掩码，记忆token，融合模块，Channel-Aware解码器<br />- 效果：性能提升，MCI效果增强|


### 基础模型 (Foundation Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Multimodal Knowledge-enhanced Whole-slide Pathology Foundation Model|多模态知识增强的全切片病理基础模型|Yingxue Xu, Yihui Wang, Fengtao Zhou, Jiabo Ma, Cheng Jin, Shu Yang, Jinbang Li, Zhengyu Zhang .etc.|<http://arxiv.org/pdf/2407.15362v3>|- 问题：病理图像，知识融合，上下文捕获，多模态<br />- 方法：mSTAR，全切片预训练，模态整合<br />- 效果：性能提升，多任务应用|


### 预训练模型 (Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CCUP: A Controllable Synthetic Data Generation Pipeline for Pretraining Cloth-Changing Person Re-Identification Models|CCUP：一种用于预训练服装变化人物重识别模型的可控合成数据生成管道|Yujian Zhao, Chengru Wu, Yinong Xu, Xuanzheng Du, Ruiyu Li, Guanglin Niu|<http://arxiv.org/pdf/2410.13567v2>|[[代码]](<https://github.com/yjzhao1019/CCUP.>)<br />- 问题：CC-ReID数据成本高，模型泛化能力差<br />- 方法：可控合成数据生成，大规模CCUP数据集，预训练-微调框架<br />- 效果：模型性能提升，泛化能力增强|
|📝 更新|Parameter-Efficient Fine-Tuning for Pre-Trained Vision Models: A Survey|参数高效的预训练视觉模型微调：综述|Yi Xin, Jianjiang Yang, Siqi Luo, Haodi Zhou, Junlong Du, Xiaohong Liu, Yue Fan, Qing Li .etc.|<http://arxiv.org/pdf/2402.02242v3>|[[代码]](<https://github.com/synbol/Awesome-Parameter-Efficient-Transfer-Learning.>)<br />- 问题：参数效率，预训练模型，全微调，计算存储需求<br />- 方法：参数高效微调，分类方法，数据集应用<br />- 效果：性能提升，资源节省|


## 生成建模 (Generative Modeling)


### 扩散模型 (Diffusion Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning 3D Object Spatial Relationships from Pre-trained 2D Diffusion Models|从预训练的2D扩散模型中学习3D物体空间关系|Sangwon Beak, Hyeonwoo Kim, Hanbyul Joo|<http://arxiv.org/pdf/2503.19914v1>|- 问题：3D空间关系学习，2D扩散模型，OOR<br />- 方法：合成3D样本，OOR扩散模型，多对象OOR<br />- 效果：鲁棒性，适用性|
|📝 更新|Reanimating Images using Neural Representations of Dynamic Stimuli|利用动态刺激的神经表征重动画像|Jacob Yeung, Andrew F. Luo, Gabriel Sarch, Margaret M. Henderson, Deva Ramanan, Michael J. Tarr|<http://arxiv.org/pdf/2406.02659v3>|[[代码]](<https://brain-nrds.github.io/.>)<br />- 问题：动态视觉理解，运动解码，脑活动，视频重动画<br />- 方法：视频扩散模型，脑活动解码，运动信号，视频重动画<br />- 效果：脑活动解码，视频重动画|
|📝 更新|Repurposing Pre-trained Video Diffusion Models for Event-based Video Interpolation|重新利用预训练的视频扩散模型进行基于事件的视频插值|Jingxi Chen, Brandon Y. Feng, Haoming Cai, Tianfu Wang, Levi Burner, Dehao Yuan, Cornelia Fermuller, Christopher A. Metzler .etc.|<http://arxiv.org/pdf/2412.07761v2>|- 问题：视频插帧，数据限制，运动估计<br />- 方法：预训练模型，事件视频插帧<br />- 效果：性能提升，泛化能力强|
|🆕 发布|Scaling Down Text Encoders of Text-to-Image Diffusion Models|文本到图像扩散模型的文本编码器缩小规模|Lifu Wang, Daqing Liu, Xinchen Liu, Xiaodong He|<http://arxiv.org/pdf/2503.19897v1>|- 问题：参数冗余，模型过大，非视觉响应<br />- 方法：视觉知识蒸馏，T5编码器训练，数据集构建<br />- 效果：模型缩小50倍，GPU需求降低，生成图像质量高|
|🆕 发布|ICE: Intrinsic Concept Extraction from a Single Image via Diffusion Models|ICE：基于扩散模型的单图像内在概念提取|Fernando Julio Cendra, Kai Han|<http://arxiv.org/pdf/2503.19902v1>|[[代码]](<https://visual-ai.github.io/ice>)<br />- 问题：视觉概念定义模糊，T2I模型学习困难，概念提取缺乏系统方法<br />- 方法：自动概念定位，分解对象概念，提取内在概念<br />- 效果：单图无监督提取，性能优越|
|📝 更新|Aesthetic Post-Training Diffusion Models from Generic Preferences with Step-by-step Preference Optimization|从通用偏好中通过逐步偏好优化构建美学后训练扩散模型|Zhanhao Liang, Yuhui Yuan, Shuyang Gu, Bohan Chen, Tiankai Hang, Mingxi Cheng, Ji Li, Liang Zheng|<http://arxiv.org/pdf/2406.04314v3>|- 问题：美学，偏好优化，扩散模型，图像质量<br />- 方法：逐步偏好优化，候选池，步感知模型<br />- 效果：美学提升，收敛速度快|
|🆕 发布|FireEdit: Fine-grained Instruction-based Image Editing via Region-aware Vision Language Model|FireEdit：基于区域感知视觉语言模型的细粒度指令图像编辑|Jun Zhou, Jiahao Li, Zunnan Xu, Hanhui Li, Yiji Cheng, Fa-Ting Hong, Qin Lin, Qinglin Lu .etc.|<http://arxiv.org/pdf/2503.19839v1>|[[代码]](<https://zjgans.github.io/fireedit.github.io.>)<br />- 问题：复杂场景，语义一致性，细粒度编辑<br />- 方法：区域感知VLM，时间感知目标注入，混合视觉交叉注意力<br />- 效果：语义一致性，超越现有方法|
|📝 更新|GCC: Generative Color Constancy via Diffusing a Color Checker|GCC：通过扩散颜色检查器实现生成式颜色恒常性|Chen-Wei Chang, Cheng-De Fan, Chia-Che Chang, Yi-Chen Lo, Yu-Chee Tseng, Jiun-Long Huang, Yu-Lun Liu|<http://arxiv.org/pdf/2502.17435v2>|- 问题：颜色恒常性，泛化能力，传感器差异<br />- 方法：扩散模型，单步推理，Laplacian分解<br />- 效果：鲁棒性，泛化能力|
|📝 更新|EmoAttack: Emotion-to-Image Diffusion Models for Emotional Backdoor Generation|情感攻击：用于情感后门生成的情感到图像扩散模型|Tianyu Wei, Shanmin Pang, Qi Guo, Yizhuo Ma, Xiaofeng Cao, Ming-Ming Cheng, Qing Guo|<http://arxiv.org/pdf/2406.15863v2>|- 问题：情感后门攻击，扩散模型，恶意内容<br />- 方法：情感感知后门攻击，EmoBooth，情感词映射<br />- 效果：有效生成，威胁揭露|
|🆕 发布|Unpaired Object-Level SAR-to-Optical Image Translation for Aircraft with Keypoints-Guided Diffusion Models|无配对飞机级SAR到光学图像翻译：基于关键点引导的扩散模型|Ruixi You, Hecheng Jia, Feng Xu|<http://arxiv.org/pdf/2503.19798v1>|- 问题：SAR图像翻译，对象级，对齐困难<br />- 方法：关键点引导，扩散模型，无监督学习<br />- 效果：性能提升，泛化能力强|
|🆕 发布|Fine-Grained Erasure in Text-to-Image Diffusion-based Foundation Models|精细粒度文本到图像扩散基础模型中的擦除|Kartik Thakral, Tamar Glaser, Tal Hassner, Mayank Vatsa, Richa Singh|<http://arxiv.org/pdf/2503.19783v1>|- 问题：文本到图像生成，知识保留，相邻问题<br />- 方法：FADE，概念邻域，网格模块<br />- 效果：保留率提升，性能改善|
|📝 更新|DiffIR2VR-Zero: Zero-Shot Video Restoration with Diffusion-based Image Restoration Models|DiffIR2VR-Zero：基于扩散图像恢复模型的零样本视频恢复|Chang-Han Yeh, Chin-Yang Lin, Zhixiang Wang, Chi-Wei Hsiao, Ting-Hsuan Chen, Hau-Shiang Shiu, Yu-Lun Liu|<http://arxiv.org/pdf/2407.01519v4>|- 问题：视频修复，时序不一致，重训练需求<br />- 方法：层次化潜在变形，混合令牌合并<br />- 效果：高质量修复，时序一致性|
|📝 更新|Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation|基于无监督门控低秩自适应的文本到图像扩散模型局部化概念擦除|Byung Hyun Lee, Sungjin Lim, Se Young Chun|<http://arxiv.org/pdf/2503.12356v2>|- 问题：有害内容生成，概念删除，图像质量<br />- 方法：局部概念擦除，GLoCE，低秩矩阵<br />- 效果：图像保真度，性能提升|
|🆕 发布|PCM : Picard Consistency Model for Fast Parallel Sampling of Diffusion Models|PCM：用于快速并行采样扩散模型的Picard一致性模型|Junhyuk So, Jiwoong Shin, Chaeyeon Jang, Eunhyeok Park|<http://arxiv.org/pdf/2503.19731v1>|- 问题：生成速度慢，收敛慢<br />- 方法：PCM，模型切换，一致性模型<br />- 效果：速度提升，收敛精确|
|🆕 发布|CoSimGen: Controllable Diffusion Model for Simultaneous Image and Mask Generation|CoSimGen：可控图像和掩码同时生成扩散模型|Rupak Bose, Chinedu Innocent Nwoye, Aditya Bhat, Nicolas Padoy|<http://arxiv.org/pdf/2503.19661v1>|- 问题：数据标注困难，单模态生成，控制性不足<br />- 方法：文本提示，空间嵌入，谱嵌入，对比损失<br />- 效果：高保真，控制性强|
|🆕 发布|GIViC: Generative Implicit Video Compression|GIViC：生成式隐式视频压缩|Ge Gao, Siyue Teng, Tianhao Peng, Fan Zhang, David Bull|<http://arxiv.org/pdf/2503.19604v1>|- 问题：视频压缩性能，INR，SOTA<br />- 方法：GIViC，扩散过程，HGLA<br />- 效果：BD-rate降低，性能提升|
|🆕 发布|Dance Like a Chicken: Low-Rank Stylization for Human Motion Diffusion|《鸡舞飞扬：人类动作扩散的低秩风格化》|Haim Sawdayee, Chuan Guo, Guy Tevet, Bing Zhou, Jian Wang, Amit H. Bermano|<http://arxiv.org/pdf/2503.19557v1>|- 问题：风格化运动生成，数据稀缺，低质量生成<br />- 方法：低秩适应，风格迁移，分布结构保持<br />- 效果：风格一致性，文本保真度|
|📝 更新|StarGen: A Spatiotemporal Autoregression Framework with Video Diffusion Model for Scalable and Controllable Scene Generation|星生：一种用于可扩展和可控场景生成的时空自回归框架与视频扩散模型|Shangjin Zhai, Zhichao Ye, Jialin Liu, Weijian Xie, Jiaqi Hu, Zhen Peng, Hua Xue, Danpeng Chen .etc.|<http://arxiv.org/pdf/2501.05763v2>|[[代码]](<https://zju3dv.github.io/StarGen.>)<br />- 问题：长距离场景生成，计算限制，一致性挑战<br />- 方法：视频扩散模型，自回归框架，时空条件<br />- 效果：可扩展性，精确控制，性能优越|
|🆕 发布|Single-Step Latent Consistency Model for Remote Sensing Image Super-Resolution|单步遥感图像超分辨率潜在一致性模型|Xiaohui Sun, Jiangwei Mo, Hanlin Wu, Jie Ma|<http://arxiv.org/pdf/2503.19505v1>|- 问题：超分辨率速度慢，效率低<br />- 方法：单步扩散模型，残差自编码器，一致性扩散学习<br />- 效果：效率高，质量好|
|📝 更新|PCDreamer: Point Cloud Completion Through Multi-view Diffusion Priors|PCDreamer：通过多视图扩散先验的点云补全|Guangshun Wei, Yuan Feng, Long Ma, Chen Wang, Yuanfeng Zhou, Changjian Li|<http://arxiv.org/pdf/2411.19036v3>|- 问题：点云补全，特征提取，数据配对困难<br />- 方法：多视图扩散先验，形状融合模块，形状巩固模块<br />- 效果：细节数据恢复，性能优越|
|📝 更新|DiffusionAct: Controllable Diffusion Autoencoder for One-shot Face Reenactment|扩散激活：可控扩散自编码器用于单次人脸重演|Stella Bounareli, Christos Tzelepis, Vasileios Argyriou, Ioannis Patras, Georgios Tzimiropoulos|<http://arxiv.org/pdf/2403.17217v2>|- 问题：人脸重演，GAN缺陷，背景失真<br />- 方法：DiffusionAct，DiffAE语义空间控制<br />- 效果：高保真，无特定训练|
|📝 更新|AIM2PC: Aerial Image to 3D Building Point Cloud Reconstruction|AIM2PC：航拍图像到3D建筑点云重建|Soulaimene Turki, Daniel Panangian, Houda Chaabouni-Chouayakh, Ksenia Bittner|<http://arxiv.org/pdf/2503.18527v2>|[[代码]](<https://github.com/Soulaimene/AIM2PCDataset>)<br />- 问题：单视图重建，几何细节，3D点云，相机姿态<br />- 方法：AIM2PC，特征融合，CDPM模型<br />- 效果：完整重建，性能优越|
|📝 更新|Expert Race: A Flexible Routing Strategy for Scaling Diffusion Transformer with Mixture of Experts|专家赛道：混合专家的扩散Transformer的可扩展路由策略|Yike Yuan, Ziyu Wang, Zihao Huang, Defa Zhu, Xun Zhou, Jingyi Yu, Qiyang Min|<http://arxiv.org/pdf/2503.16057v2>|- 问题：模型可扩展性，性能提升，浅层学习挑战<br />- 方法：MoE，Expert Race，层内正则化，路由相似度损失<br />- 效果：性能增益，可扩展性|
|🆕 发布|AccVideo: Accelerating Video Diffusion Model with Synthetic Dataset|AccVideo：利用合成数据集加速视频扩散模型|Haiyu Zhang, Xinyuan Chen, Yaohui Wang, Xihui Liu, Yunhong Wang, Yu Qiao|<http://arxiv.org/pdf/2503.19462v1>|- 问题：视频生成速度慢，计算量大<br />- 方法：AccVideo，合成数据集，轨迹指导，对抗训练<br />- 效果：速度提升8.5倍，视频质量高|
|📝 更新|DyMO: Training-Free Diffusion Model Alignment with Dynamic Multi-Objective Scheduling|DyMO：基于动态多目标调度的免训练扩散模型对齐|Xin Xie, Dong Gong|<http://arxiv.org/pdf/2412.00759v3>|- 问题：文本图像对齐，计算成本高，数据需求大<br />- 方法：无训练对齐，动态多目标调度，语义对齐<br />- 效果：效果显著，鲁棒性强|
|📝 更新|Extreme Precipitation Nowcasting using Multi-Task Latent Diffusion Models|极端降水预报的多任务潜在扩散模型|Li Chaorong, Ling Xudong, Yang Qiang, Qin Fengqing, Huang Yuanyuan|<http://arxiv.org/pdf/2410.14103v3>|- 问题：雷达图像空间细节，预测精度，降水强度<br />- 方法：多任务潜扩散模型，分解雷达图像，子图像建模<br />- 效果：CSI提升13-26%|
|🆕 发布|Towards Robust Time-of-Flight Depth Denoising with Confidence-Aware Diffusion Model|面向鲁棒的时间飞行深度去噪：基于置信度感知的扩散模型|Changyong He, Jin Zeng, Jiawei Zhang, Jiajie Guo|<http://arxiv.org/pdf/2503.19448v1>|- 问题：ToF深度去噪，噪声，深度分布<br />- 方法：DepthCAD，Stable Diffusion，置信度引导<br />- 效果：鲁棒性，性能领先|
|🆕 发布|Quantifying the Ease of Reproducing Training Data in Unconditional Diffusion Models|无条件扩散模型中训练数据复现难度的量化|Masaya Hasegawa, Koji Yasuda|<http://arxiv.org/pdf/2503.19429v1>|- 问题：扩散模型，数据复现，版权问题<br />- 方法：Langevin方程，ODE，概率量化<br />- 效果：低复杂度，数据质量提升|
|📝 更新|Re-HOLD: Video Hand Object Interaction Reenactment via adaptive Layout-instructed Diffusion Model|Re-HOLD：通过自适应布局指令扩散模型进行视频手部物体交互重演|Yingying Fan, Quanwei Yang, Kaisiyuan Wang, Hang Zhou, Yingying Li, Haocheng Feng, Errui Ding, Yu Wu .etc.|<http://arxiv.org/pdf/2503.16942v3>|[[代码]](<https://fyycs.github.io/Re-HOLD.>)<br />- 问题：手-物体交互，视频重演，布局指导，扩散模型<br />- 方法：自适应布局，交互纹理增强，记忆银行，布局调整<br />- 效果：性能提升，效果优于现有方法|
|📝 更新|Unveil Inversion and Invariance in Flow Transformer for Versatile Image Editing|揭示流变换器中的逆变换和不变性，实现多功能的图像编辑|Pengcheng Xu, Boyuan Jiang, Xiaobin Hu, Donghao Luo, Qingdong He, Jiangning Zhang, Chengjie Wang, Yunsheng Wu .etc.|<http://arxiv.org/pdf/2411.15843v4>|- 问题：图像编辑，逆变换，不变性控制，扩散模型<br />- 方法：两阶段逆变换，自适应层归一化，文本特征操作<br />- 效果：灵活编辑，准确度高|
|🆕 发布|Inference-Time Scaling for Flow Models via Stochastic Generation and Rollover Budget Forcing|基于随机生成和翻滚预算强制的流模型推理时间缩放|Jaihoon Kim, Taehoon Yoon, Jisung Hwang, Minhyuk Sung|<http://arxiv.org/pdf/2503.19385v1>|- 问题：流模型推理时间缩放，效率低<br />- 方法：SDE生成，插值转换，Rollover Budget Forcing<br />- 效果：性能提升，优于前人方法|
|📝 更新|Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise|随流而行：使用实时扭曲噪声的运动可控视频扩散模型|Ryan Burgert, Yuancheng Xu, Wenqi Xian, Oliver Pilarski, Pascal Clausen, Mingming He, Li Ma, Yitong Deng .etc.|<http://arxiv.org/pdf/2501.08331v4>|[[代码]](<https://github.com/Eyeline-Research/Go-with-the-Flow.>)<br />- 问题：视频扩散模型，运动控制，噪声采样<br />- 方法：实时噪声扭曲，光学流场，空间高斯性<br />- 效果：实时性，运动控制，像素质量|
|📝 更新|RayFlow: Instance-Aware Diffusion Acceleration via Adaptive Flow Trajectories|RayFlow：通过自适应流轨迹的实例感知扩散加速|Huiyang Shao, Xin Xia, Yuhong Yang, Yuxi Ren, Xing Wang, Xuefeng Xiao|<http://arxiv.org/pdf/2503.07699v2>|- 问题：扩散模型速度慢，质量受损，可控性差<br />- 方法：实例感知，自适应轨迹，时间采样<br />- 效果：速度提升，质量改善，效率提高|
|🆕 发布|EfficientMT: Efficient Temporal Adaptation for Motion Transfer in Text-to-Video Diffusion Models|EfficientMT：文本到视频扩散模型中运动传递的效率时序自适应|Yufei Cai, Hu Han, Yuxiang Wei, Shiguang Shan, Xilin Chen|<http://arxiv.org/pdf/2503.19369v1>|[[代码]](<https://github.com/PrototypeNx/EfficientMT.>)<br />- 问题：运动可控性，计算负担，运动迁移<br />- 方法：EfficientMT，时间信息提取，时间集成机制<br />- 效果：效率高，运动可控|
|🆕 发布|MVPortrait: Text-Guided Motion and Emotion Control for Multi-view Vivid Portrait Animation|MVPortrait：多视角生动肖像动画的文本引导运动和情感控制|Yukang Lin, Hokit Fung, Jianjin Xu, Zeping Ren, Adela S. M. Lau, Guosheng Yin, Xiu Li|<http://arxiv.org/pdf/2503.19383v1>|- 问题：控制不足，多视角，文本引导<br />- 方法：FLAME中间表示，两阶段框架，多视角生成<br />- 效果：情感控制，视角一致性|
|🆕 发布|DeClotH: Decomposable 3D Cloth and Human Body Reconstruction from a Single Image|DeClotH：从单张图像中分解3D衣物和人体重建|Hyeongjin Nam, Donghwan Kim, Jeongtaek Oh, Kyoung Mu Lee|<http://arxiv.org/pdf/2503.19373v1>|[[代码]](<https://hygenie1228.github.io/DeClotH>)<br />- 问题：单图3D人体服装重建，遮挡，几何纹理<br />- 方法：3D模板模型，布料扩散模型<br />- 效果：准确，有效|
|🆕 发布|Interpretable Generative Models through Post-hoc Concept Bottlenecks|通过后处理概念瓶颈的可解释生成模型|Akshay Kulkarni, Ge Yan, Chung-En Sun, Tuomas Oikarinen, Tsui-Wei Weng|<http://arxiv.org/pdf/2503.19377v1>|- 问题：可解释性，生成模型，效率，可扩展性<br />- 方法：概念瓶颈，后处理技术，CB-AE，CC<br />- 效果：可解释性，可操控性，性能提升|
|🆕 发布|Correcting Deviations from Normality: A Reformulated Diffusion Model for Multi-Class Unsupervised Anomaly Detection|纠正正常性偏差：一种用于多类无监督异常检测的重构扩散模型|Farzad Beizaee, Gregory A. Lodygensky, Christian Desrosiers, Jose Dolz|<http://arxiv.org/pdf/2503.19357v1>|[[代码]](<https://github.com/farzad-bz/DeCo-Diff>)<br />- 问题：异常检测，结构完整性，内容恢复，多类别，噪声<br />- 方法：扩散模型，区域选择性，偏差校正<br />- 效果：AUPRC提升，准确识别|
|📝 更新|Latent Space Super-Resolution for Higher-Resolution Image Generation with Diffusion Models|潜空间超分辨率：使用扩散模型生成更高分辨率的图像|Jinho Jeong, Sangmin Han, Jinwoo Kim, Seon Joo Kim|<http://arxiv.org/pdf/2503.18446v2>|[[代码]](<https://github.com/3587jjh/LSRNA.>)<br />- 问题：扩散模型，分辨率扩展，结构扭曲，内容重复<br />- 方法：LSRNA，潜在空间超分辨率，区域噪声添加<br />- 效果：超越1K分辨率，细节保留，性能优越|
|🆕 发布|BADGR: Bundle Adjustment Diffusion Conditioned by GRadients for Wide-Baseline Floor Plan Reconstruction|BADGR：基于梯度的捆绑调整扩散条件学习宽基线平面图重建|Yuguang Li, Ivaylo Boyadzhiev, Zixuan Liu, Linda Shapiro, Alex Colburn|<http://arxiv.org/pdf/2503.19340v1>|- 问题：宽基线全景图，相机位姿，楼层布局，重建<br />- 方法：扩散模型，梯度条件，BA优化，LM优化器<br />- 效果：精度提升，性能优越|
|📝 更新|SyncDiff: Synchronized Motion Diffusion for Multi-Body Human-Object Interaction Synthesis|同步运动扩散：多人体与人-物体交互合成的同步运动|Wenkun He, Yun Liu, Ruitao Liu, Li Yi|<http://arxiv.org/pdf/2412.20104v3>|- 问题：多体交互，运动同步，复杂度<br />- 方法：同步扩散，频率域分解，对齐分数<br />- 效果：运动合成，效果优越|
|📝 更新|Generative Photography: Scene-Consistent Camera Control for Realistic Text-to-Image Synthesis|生成摄影：实现逼真文本到图像合成的场景一致性相机控制|Yu Yuan, Xijun Wang, Yichen Sheng, Prateek Chennuri, Xingguang Zhang, Stanley Chan|<http://arxiv.org/pdf/2412.02168v3>|[[代码]](<https://generative-photography.github.io/project.>)<br />- 问题：场景一致性，相机控制，文本到图像，物理设置<br />- 方法：维度提升，相机内参学习，场景一致性<br />- 效果：图像生成，真实感，性能提升|
|📝 更新|Improved Training Technique for Latent Consistency Models|改进的潜在一致性模型训练技术|Quan Dao, Khanh Doan, Di Liu, Trung Le, Dimitris Metaxas|<http://arxiv.org/pdf/2502.01441v2>|[[代码]](<https://github.com/quandao10/sLCT>)<br />- 问题：一致性模型，大规模数据集，潜在空间性能<br />- 方法：Cauchy损失，扩散损失，最优传输耦合，自适应调度器<br />- 效果：性能提升，缩小差距|
|📝 更新|GameFactory: Creating New Games with Generative Interactive Videos|游戏工坊：通过生成交互式视频创造新游戏|Jiwen Yu, Yiran Qin, Xintao Wang, Pengfei Wan, Di Zhang, Xihui Liu|<http://arxiv.org/pdf/2501.08325v2>|[[代码]](<https://yujiwen.github.io/gamefactory>)<br />- 问题：游戏内容生成，动作控制，场景通用性<br />- 方法：GF-Minecraft，动作控制模块，多阶段训练策略<br />- 效果：开放域，可控制，AI驱动|
|📝 更新|TopoCellGen: Generating Histopathology Cell Topology with a Diffusion Model|TopoCellGen：利用扩散模型生成组织病理学细胞拓扑结构|Meilong Xu, Saumya Gupta, Xiaoling Hu, Chen Li, Shahira Abousamra, Dimitris Samaras, Prateek Prasanna, Chao Chen|<http://arxiv.org/pdf/2412.06011v2>|[[代码]](<https://github.com/Melon-Xu/TopoCellGen.>)<br />- 问题：细胞拓扑建模，数据增强，病理学<br />- 方法：拓扑约束，扩散模型，TopoFD<br />- 效果：拓扑关系捕捉，结果精度|
|🆕 发布|ISPDiffuser: Learning RAW-to-sRGB Mappings with Texture-Aware Diffusion Models and Histogram-Guided Color Consistency|ISPDiffuser：利用纹理感知扩散模型和直方图引导的色彩一致性学习RAW到sRGB映射|Yang Ren, Hai Jiang, Menglong Yang, Wei Li, Shuaicheng Liu|<http://arxiv.org/pdf/2503.19283v1>|[[代码]](<https://github.com/RenYangSCU/ISPDiffuser.>)<br />- 问题：RAW-to-sRGB映射，细节差异，颜色失真<br />- 方法：纹理感知扩散模型，直方图引导颜色一致性<br />- 效果：超越现有方法，视觉效果提升|
|📝 更新|Zeroth-order Informed Fine-Tuning for Diffusion Model: A Recursive Likelihood Ratio Optimizer|零阶信息驱动的扩散模型微调：递归似然比优化器|Tao Ren, Zishi Zhang, Zehao Li, Jingyang Jiang, Shentao Qin, Guanghao Li, Yan Li, Yi Zheng .etc.|<http://arxiv.org/pdf/2502.00639v2>|- 问题：扩散模型微调，样本效率低，梯度估计偏差<br />- 方法：零阶梯度，递归似然比优化器，计算图重排<br />- 效果：性能保证，实验验证，协同效应|
|🆕 发布|Learning Hazing to Dehazing: Towards Realistic Haze Generation for Real-World Image Dehazing|学习去雾化以去雾：迈向现实世界图像去雾的真实雾生成|Ruiyi Wang, Yushuo Zheng, Zicheng Zhang, Chunyi Li, Shuaicheng Liu, Guangtao Zhai, Xiaohong Liu|<http://arxiv.org/pdf/2503.19262v1>|[[代码]](<https://github.com/ruiyi-w/Learning-Hazing-to-Dehazing.>)<br />- 问题：去雾，预训练模型依赖，扩散模型效率低<br />- 方法：HazeGen，DiffDehaze，AccSamp，AlignOp<br />- 效果：去雾性能优，视觉效果好|
|📝 更新|WonderWorld: Interactive 3D Scene Generation from a Single Image|奇境：从单张图像生成交互式3D场景|Hong-Xing Yu, Haoyi Duan, Charles Herrmann, William T. Freeman, Jiajun Wu|<http://arxiv.org/pdf/2406.09394v4>|- 问题：3D场景生成，低延迟，几何优化<br />- 方法：FLAGS，单视图生成，深度扩散<br />- 效果：实时交互，场景连接|
|📝 更新|FloVD: Optical Flow Meets Video Diffusion Model for Enhanced Camera-Controlled Video Synthesis|FloVD：光流与视频扩散模型结合以增强相机控制视频合成|Wonjoon Jin, Qi Dai, Chong Luo, Seung-Hwan Baek, Sunghyun Cho|<http://arxiv.org/pdf/2502.08244v2>|- 问题：视频合成，相机控制，运动捕捉<br />- 方法：光流，视频扩散模型，两阶段合成<br />- 效果：精确控制，自然运动|


### 生成对抗网络 (GANs)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FullDiT: Multi-Task Video Generative Foundation Model with Full Attention|全视点视频生成多任务基础模型：全注意力机制|Xuan Ju, Weicai Ye, Quande Liu, Qiulin Wang, Xintao Wang, Pengfei Wan, Di Zhang, Kun Gai .etc.|<http://arxiv.org/pdf/2503.19907v1>|- 问题：视频生成控制，参数冗余，性能局限<br />- 方法：全注意力机制，多任务融合，统一序列表示<br />- 效果：最优结果，全注意力效率|
|🆕 发布|In the Blink of an Eye: Instant Game Map Editing using a Generative-AI Smart Brush|眨眼之间：利用生成式AI智能笔进行即时游戏地图编辑|Vitaly Gnatyuk, Valeriia Koriukina Ilya Levoshevich, Pavel Nurminskiy, Guenter Wallner|<http://arxiv.org/pdf/2503.19793v1>|- 问题：3D游戏地图艺术创作，自动化生成，高分辨率纹理<br />- 方法：生成对抗网络，扩散模型，智能画笔<br />- 效果：高效生成，细节丰富，上下文一致性|
|📝 更新|Aether: Geometric-Aware Unified World Modeling|以太：几何感知统一世界建模|Aether Team, Haoyi Zhu, Yifan Wang, Jianjun Zhou, Wenzheng Chang, Yang Zhou, Zizun Li, Junyi Chen .etc.|<http://arxiv.org/pdf/2503.18945v2>|- 问题：空间推理，几何重建，生成建模<br />- 方法：统一框架，特征学习，几何建模<br />- 效果：泛化能力强，零样本泛化|
|🆕 发布|Exploring Disentangled and Controllable Human Image Synthesis: From End-to-End to Stage-by-Stage|探索解耦和可控的人脸图像合成：从端到端到分阶段|Zhengwentai Sun, Heyuan Li, Xihe Yang, Keru Zheng, Shuliang Ning, Yihao Zhi, Hongjie Liao, Chenghong Li .etc.|<http://arxiv.org/pdf/2503.19486v1>|[[代码]](<https://taited.github.io/discohuman-project>)<br />- 问题：细粒度可控性，因素解耦，数据不一致<br />- 方法：阶段化框架，虚拟试穿数据，MVHumanNet<br />- 效果：可控性提升，泛化能力增强|
|🆕 发布|G-DexGrasp: Generalizable Dexterous Grasping Synthesis Via Part-Aware Prior Retrieval and Prior-Assisted Generation|G-DexGrasp：通过部件感知先验检索和先验辅助生成实现可泛化的灵巧抓取合成|Juntao Jian, Xiuping Liu, Zixuan Chen, Manyi Li, Jian Liu, Ruizhen Hu|<http://arxiv.org/pdf/2503.19457v1>|- 问题：泛化能力，未见类别，任务指令<br />- 方法：检索增强，先验检索，先验辅助生成<br />- 效果：高质量，合理配置|
|📝 更新|IDOL: Instant Photorealistic 3D Human Creation from a Single Image|IDOL：从单张图像即时创建逼真的3D人像|Yiyu Zhuang, Jiaxi Lv, Hao Wen, Qing Shuai, Ailing Zeng, Hao Zhu, Shifeng Chen, Yujiu Yang .etc.|<http://arxiv.org/pdf/2412.14963v2>|[[代码]](<https://yiyuzhuang.github.io/IDOL>)<br />- 问题：单图3D人像创建，数据稀缺，模型复杂<br />- 方法：HuGe100K数据集，可解释性模型，动画支持<br />- 效果：高保真，快速，应用广泛|
|🆕 发布|Exploring Semantic Feature Discrimination for Perceptual Image Super-Resolution and Opinion-Unaware No-Reference Image Quality Assessment|探索语义特征区分在感知图像超分辨率和不知情意见无参考图像质量评估中的应用|Guanglu Dong, Xiangyu Liao, Mingyang Li, Guihuan Guo, Chao Ren|<http://arxiv.org/pdf/2503.19295v1>|- 问题：GAN，图像超分辨率，语义信息，质量评估<br />- 方法：语义特征区分，特征判别器，文本引导<br />- 效果：质量提升，性能改善|
|📝 更新|AMD-Hummingbird: Towards an Efficient Text-to-Video Model|AMD-Hummingbird：迈向高效的文本到视频模型|Takashi Isobe, He Cui, Dong Zhou, Mengmeng Ge, Dong Li, Emad Barsoum|<http://arxiv.org/pdf/2503.18559v2>|- 问题：效率与质量平衡，模型轻量化，视觉反馈学习<br />- 方法：模型剪枝，数据预处理，LLMs与VQA<br />- 效果：效率提升，质量优化，长视频生成|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Using deep neural networks to detect non-analytically defined expert event labels in canoe sprint force sensor signals|利用深度神经网络检测皮划艇冲刺力传感器信号中的非解析定义专家事件标签|Sarah Rockstroh, Patrick Frenzel, Daniel Matthes, Kay Schubert, David Wollburg, Mirco Fuchs|<http://arxiv.org/pdf/2407.08395v3>|- 问题：运动参数检测，人工交互，模型预测<br />- 方法：CNN，RNN，BGRU，SoftED扩展<br />- 效果：模型适用，性能评估|


### 自回归模型 (Autoregressive Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Practical Fine-Tuning of Autoregressive Models on Limited Handwritten Texts|实际在有限手写文本上对自回归模型的微调|Jan Kohút, Michal Hradiš|<http://arxiv.org/pdf/2503.19546v1>|- 问题：OCR模型适应，标注工作量，稳定性<br />- 方法：Transformer微调，模型组件分析，置信度选择<br />- 效果：CER降低，标注成本减半|
|🆕 发布|Long-Context Autoregressive Video Modeling with Next-Frame Prediction|长上下文自回归视频建模与下一帧预测|Yuchao Gu, Weijia Mao, Mike Zheng Shou|<http://arxiv.org/pdf/2503.19325v1>|- 问题：视频生成，长时序，视觉冗余<br />- 方法：FAR模型，FlexRoPE，长短期建模<br />- 效果：性能提升，长视频生成|


## 多模态学习 (Multimodal Learning)


### 视觉语言模型 (Vision-Language Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CoLLM: A Large Language Model for Composed Image Retrieval|CoLLM：用于组合图像检索的大型语言模型|Chuong Huynh, Jinyu Yang, Ashish Tawari, Mubarak Shah, Son Tran, Raffay Hamid, Trishul Chilimbi, Abhinav Shrivastava|<http://arxiv.org/pdf/2503.19910v1>|- 问题：CIR数据稀缺，模型性能受限<br />- 方法：CoLLM框架，LLMs生成三元组，MTCIR数据集<br />- 效果：性能提升，基准优化|
|🆕 发布|CAFe: Unifying Representation and Generation with Contrastive-Autoregressive Finetuning|CAFe：通过对比自回归微调统一表示和生成|Hao Yu, Zhuokai Zhao, Shen Yan, Lukasz Korycki, Jianyu Wang, Baosheng He, Jiayi Liu, Lizhu Zhang .etc.|<http://arxiv.org/pdf/2503.19900v1>|- 问题：LVLMs，表示学习，生成能力，平衡<br />- 方法：对比自回归微调，统一表示与生成<br />- 效果：SOTA，多模态检索，生成|
|🆕 发布|FALCONEye: Finding Answers and Localizing Content in ONE-hour-long videos with multi-modal LLMs|FALCONEye：使用多模态大型语言模型在长达一小时的视频中寻找答案和定位内容|Carlos Plou, Cesar Borja, Ruben Martinez-Cantin, Ana C. Murillo|<http://arxiv.org/pdf/2503.19850v1>|- 问题：视频信息检索，长视频处理，答案定位<br />- 方法：元架构，探索算法，VLM校准<br />- 效果：性能优越，基准测试|
|🆕 发布|Towards Online Multi-Modal Social Interaction Understanding|迈向在线多模态社交交互理解|Xinpeng Li, Shijian Deng, Bolin Lai, Weiguo Pian, James M. Rehg, Yapeng Tian|<http://arxiv.org/pdf/2503.19851v1>|[[代码]](<https://github.com/Sampson-Lee/OnlineMMSI.>)<br />- 问题：MMSI，实时反馈，历史信息依赖<br />- 方法：Online-MMSI-VLM，多党对话预测，社会感知视觉提示<br />- 效果：SOTA性能，显著超越基线|
|📝 更新|CLIP-EBC: CLIP Can Count Accurately through Enhanced Blockwise Classification|CLIP-EBC：通过增强块级分类，CLIP能够准确计数|Yiming Ma, Victor Sanchez, Tanaya Guha|<http://arxiv.org/pdf/2403.09281v3>|[[代码]](<https://github.com/Yiming-M/CLIP-EBC.>)<br />- 问题：准确计数，CLIP，回归问题，分类误差<br />- 方法：EBC框架，整数值区间，回归损失<br />- 效果：性能提升，MAE降低，RMSE降低|
|🆕 发布|SeLIP: Similarity Enhanced Contrastive Language Image Pretraining for Multi-modal Head MRI|SeLIP：基于相似性增强的对比语言图像预训练用于多模态头部MRI|Zhiyang Liu, Dong Yang, Minghao Zhang, Hanyu Sun, Hong Wu, Huiying Wang, Wen Shen, Chao Chai .etc.|<http://arxiv.org/pdf/2503.19801v1>|- 问题：数据样本不足，医学图像分析<br />- 方法：对比学习，混合相似度匹配，SeLIP预训练<br />- 效果：多模态MRI，下游任务表现佳|
|🆕 发布|PAVE: Patching and Adapting Video Large Language Models|PAVE：视频大语言模型的修补和适应|Zhuoming Liu, Yiquan Li, Khoi Duc Nguyen, Yiwu Zhong, Yin Li|<http://arxiv.org/pdf/2503.19794v1>|[[代码]](<https://github.com/dragonlzm/PAVE.>)<br />- 问题：视频LLM适应新任务，多模态数据<br />- 方法：轻量级适配器，多任务学习<br />- 效果：性能提升，泛化能力强|
|📝 更新|Decorum: A Language-Based Approach For Style-Conditioned Synthesis of Indoor 3D Scenes|礼仪：基于语言的室内3D场景风格条件合成方法|Kelly O. Marshall, Omid Poursaeed, Sergiu Oprea, Amit Kumar, Anushrut Jignasu, Chinmay Hegde, Yilei Li, Rakesh Ranjan|<http://arxiv.org/pdf/2503.18155v2>|- 问题：3D场景生成，风格控制，自然语言<br />- 方法：语言表示，LLMs，多模态检索<br />- 效果：性能提升，效果改善|
|📝 更新|SPA-VL: A Comprehensive Safety Preference Alignment Dataset for Vision Language Model|SPA-VL：视觉语言模型的综合安全偏好对齐数据集|Yongting Zhang, Lu Chen, Guodong Zheng, Yifeng Gao, Rui Zheng, Jinlan Fu, Zhenfei Yin, Senjie Jin .etc.|<http://arxiv.org/pdf/2406.12030v3>|- 问题：VLMs安全对齐，数据集缺乏<br />- 方法：SPA-VL数据集，多源VLMs，自动化构建<br />- 效果：模型改进，无害性与帮助性|
|📝 更新|Interpreting Object-level Foundation Models via Visual Precision Search|通过视觉精度搜索解释对象级基础模型|Ruoyu Chen, Siyuan Liang, Jingzhi Li, Shiming Liu, Maosen Li, Zhen Huang, Hua Zhang, Xiaochun Cao|<http://arxiv.org/pdf/2411.16198v3>|[[代码]](<https://github.com/RuoyuChen10/VPS.>)<br />- 问题：模型可解释性，定位精度，噪声干扰<br />- 方法：视觉精度搜索，稀疏子区域，一致性评分<br />- 效果：解释性提升，性能超越SOTA|
|📝 更新|When Large Vision-Language Model Meets Large Remote Sensing Imagery: Coarse-to-Fine Text-Guided Token Pruning|当大型视觉-语言模型遇见大型遥感影像：由粗到细的文本引导的token剪枝|Junwei Luo, Yingying Zhang, Xue Yang, Kang Wu, Qi Zhu, Lei Liang, Jingdong Chen, Yansheng Li|<http://arxiv.org/pdf/2503.07588v2>|[[代码]](<https://github.com/VisionXLab/LRS-VQA.>)<br />- 问题：大遥感图像，信息损失，计算复杂<br />- 方法：文本引导，区域聚焦，动态图像金字塔<br />- 效果：效率高，效果优|
|📝 更新|Interpretable Bilingual Multimodal Large Language Model for Diverse Biomedical Tasks|可解释的双语多模态大型语言模型用于多样化的生物医学任务|Lehan Wang, Haonan Wang, Honglong Yang, Jiaji Mao, Zehong Yang, Jun Shen, Xiaomeng Li|<http://arxiv.org/pdf/2410.18387v3>|- 问题：区域识别，模型可解释性，多模态任务<br />- 方法：区域感知模型，双语训练，大规模数据集<br />- 效果：最佳性能，多任务处理，可解释性提升|
|🆕 发布|Mind the Gap: Benchmarking Spatial Reasoning in Vision-Language Models|注意差距：评估视觉-语言模型中的空间推理|Ilias Stogiannidis, Steven McDonagh, Sotirios A. Tsaftaris|<http://arxiv.org/pdf/2503.19707v1>|[[代码]](<https://github.com/stogiannidis/srbench>)<br />- 问题：VLMs 空间推理，基准不足，任务混淆<br />- 方法：空间推理分析，模型性能评估，合成与真实图像<br />- 效果：发现缺陷，揭示需求，建立平台|
|📝 更新|CLIP-Adapter: Better Vision-Language Models with Feature Adapters|CLIP-Adapter：通过特征适配器提升视觉-语言模型|Peng Gao, Shijie Geng, Renrui Zhang, Teli Ma, Rongyao Fang, Yongfeng Zhang, Hongsheng Li, Yu Qiao|<http://arxiv.org/pdf/2110.04544v2>|[[代码]](<https://github.com/gaopengcuhk/CLIP-Adapter.>)<br />- 问题：视觉语言模型，prompt工程，特征适配<br />- 方法：CLIP-Adapter，特征适配器，残差融合<br />- 效果：超越prompt优化，简单设计|
|📝 更新|MC-LLaVA: Multi-Concept Personalized Vision-Language Model|MC-LLaVA：多概念个性化视觉-语言模型|Ruichuan An, Sihan Yang, Ming Lu, Renrui Zhang, Kai Zeng, Yulin Luo, Jiajun Cao, Hao Liang .etc.|<http://arxiv.org/pdf/2503.18854v2>|[[代码]](<https://github.com/arctanxarc/MC-LLaVA>)<br />- 问题：单概念个性化，多概念交互，现实应用限制<br />- 方法：多概念指令调整，个性化文本提示，个性化视觉提示<br />- 效果：多概念个性化响应，用户特定助手|
|🆕 发布|Unlocking the Hidden Potential of CLIP in Generalizable Deepfake Detection|解锁CLIP在泛化深度伪造检测中的潜在能力|Andrii Yermakov, Jan Cech, Jiri Matas|<http://arxiv.org/pdf/2503.19683v1>|[[代码]](<https://github.com/yermandy/deepfake-detection>)<br />- 问题：部分人脸deepfake检测，CLIP模型，参数高效微调<br />- 方法：CLIP ViT-L/14，PEFT，预处理，正则化<br />- 效果：高检测精度，泛化能力强|
|🆕 发布|fine-CLIP: Enhancing Zero-Shot Fine-Grained Surgical Action Recognition with Vision-Language Models|精细CLIP：利用视觉-语言模型增强零样本精细粒度手术动作识别|Saurav Sharma, Didier Mutter, Nicolas Padoy|<http://arxiv.org/pdf/2503.19670v1>|- 问题：零样本细粒度手术动作识别，语义细节忽视，泛化能力弱<br />- 方法：fine-CLIP，层次化提示建模，LoRA视觉骨干，图基聚类<br />- 效果：F1和mAP提升|
|🆕 发布|Exploring Hallucination of Large Multimodal Models in Video Understanding: Benchmark, Analysis and Mitigation|探索大型多模态模型在视频理解中的幻觉：基准、分析和缓解|Hongcheng Gao, Jiashu Qu, Jingyi Tang, Baolong Bi, Yue Liu, Hongyu Chen, Li Liang, Li Su .etc.|<http://arxiv.org/pdf/2503.19622v1>|[[代码]](<https://github.com/Hongcheng-Gao/HAVEN.>)<br />- 问题：LMMs幻觉，视频理解，可靠性<br />- 方法：HAVEN基准，视频思考模型，SRFT，TDPO<br />- 效果：准确率提升，偏差降低|
|📝 更新|MetaToken: Detecting Hallucination in Image Descriptions by Meta Classification|MetaToken：通过元分类检测图像描述中的幻觉|Laura Fieback, Jakob Spiegelberg, Hanno Gottschalk|<http://arxiv.org/pdf/2405.19186v2>|- 问题：LVLMs幻觉检测，可信度，计算成本<br />- 方法：MetaToken，轻量级分类器，token级检测<br />- 效果：低成本，无数据依赖，有效性|
|🆕 发布|OpenSDI: Spotting Diffusion-Generated Images in the Open World|开放世界中的扩散生成图像检测：OpenSDI|Yabin Wang, Zhiwu Huang, Xiaopeng Hong|<http://arxiv.org/pdf/2503.19653v1>|[[代码]](<https://github.com/iamwangyabin/OpenSDI.>)<br />- 问题：扩散生成图像识别，开放世界，数据集<br />- 方法：Synergizing Pretrained Models (SPM)，MaskCLIP<br />- 效果：性能提升，IoU/F1，准确率|
|📝 更新|VideoGLaMM: A Large Multimodal Model for Pixel-Level Visual Grounding in Videos|视频GLaMM：一种用于视频像素级视觉定位的大型多模态模型|Shehan Munasinghe, Hanan Gani, Wenqi Zhu, Jiale Cao, Eric Xing, Fahad Shahbaz Khan, Salman Khan|<http://arxiv.org/pdf/2411.04923v3>|- 问题：视频文本对齐，像素级定位，视频理解<br />- 方法：多模态模型，视觉编码器，时空解码器<br />- 效果：性能提升，任务表现佳|
|📝 更新|Dissecting CLIP: Decomposition with a Schur Complement-based Approach|剖析CLIP：基于Schur补的分解方法|Azim Ospanov, Mohammad Jalali, Farzan Farnia|<http://arxiv.org/pdf/2412.18645v2>|[[代码]](<https://github.com/aziksh-ospanov/CLIP-DISSECTION>)<br />- 问题：CLIPScore，图像多样性，文本到图像模型<br />- 方法：Schur补分解，SCE分数，CLIP嵌入修改<br />- 效果：量化多样性，聚焦/去聚焦，模型评估|
|🆕 发布|GenHancer: Imperfect Generative Models are Secretly Strong Vision-Centric Enhancers|GenHancer：不完美的生成模型实际上是秘密强大的视觉增强器|Shijie Ma, Yuying Ge, Teng Wang, Yuxin Guo, Yixiao Ge, Ying Shan|<http://arxiv.org/pdf/2503.19480v1>|- 问题：CLIP视觉细节感知弱，生成模型增强效果未探<br />- 方法：条件机制，去噪配置，生成范式<br />- 效果：MMVP-VLM基准提升，多模态大语言模型|
|📝 更新|RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics|机器人空间理解：为机器人二维和三维视觉语言模型教授空间理解|Chan Hee Song, Valts Blukis, Jonathan Tremblay, Stephen Tyree, Yu Su, Stan Birchfield|<http://arxiv.org/pdf/2411.16537v2>|- 问题：空间理解，视觉语言模型，训练数据，空间推理<br />- 方法：RoboSpatial，3D扫描，egocentric图像，空间关系标注<br />- 效果：模型性能提升，下游任务表现佳|
|📝 更新|GFlowVLM: Enhancing Multi-step Reasoning in Vision-Language Models with Generative Flow Networks|GFlowVLM：利用生成流网络增强视觉-语言模型的多步推理|Haoqiang Kang, Enna Sachdeva, Piyush Gupta, Sangjae Bae, Kwonjoon Lee|<http://arxiv.org/pdf/2503.06514v2>|- 问题：VLM多步推理，SFT，PPO，限制，多样性<br />- 方法：GFlowVLM，GFlowNets，非马尔可夫决策，CoT推理<br />- 效果：效率提升，多样性增强，泛化能力强|
|🆕 发布|LangBridge: Interpreting Image as a Combination of Language Embeddings|LangBridge：将图像解释为语言嵌入的组合|Jiaqi Liao, Yuwei Niu, Fanqing Meng, Hao Li, Changyao Tian, Yinuo Du, Yuwen Xiong, Dianqi Li .etc.|<http://arxiv.org/pdf/2503.19404v1>|- 问题：LVLMs，视觉-语言对齐，MLP机制，LLM重训练<br />- 方法：LangBridge，视觉嵌入投影，线性组合映射<br />- 效果：预训练迁移，性能维持，可解释性|
|📝 更新|Think Before You Segment: High-Quality Reasoning Segmentation with GPT Chain of Thoughts|在分割前思考：基于GPT思维链的高质量推理分割|Shiu-hong Kao, Yu-Wing Tai, Chi-Keung Tang|<http://arxiv.org/pdf/2503.07503v3>|- 问题：推理分割，复杂查询，低质量分割<br />- 方法：GPT链式思维，训练免费框架，多模态交互<br />- 效果：质量提升，零样本，用户友好|
|📝 更新|Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning|在婴儿学习中发现超越语言输入的隐藏视觉概念|Xueyi Ke, Satoshi Tsutsui, Yayun Zhang, Bihan Wen|<http://arxiv.org/pdf/2501.05205v4>|[[代码]](<https://github.com/Kexueyi/discover_infant_vis.>)<br />- 问题：婴儿视觉学习，概念发现，语言输入<br />- 方法：模型分析，神经元标注，比较研究<br />- 效果：跨词汇识别，认知科学融合|
|📝 更新|GOAL: Global-local Object Alignment Learning|目标：全局-局部目标对齐学习|Hyungyu Choi, Young Kyun Jang, Chanho Eom|<http://arxiv.org/pdf/2503.17782v2>|- 问题：长文本描述，CLIP，语义对齐<br />- 方法：LISM，TSL，局部语义对齐<br />- 效果：性能提升，细粒度理解|
|📝 更新|AIpparel: A Multimodal Foundation Model for Digital Garments|AIpparel：数字服装的多模态基础模型|Kiyohiro Nakayama, Jan Ackermann, Timur Levent Kesdogan, Yang Zheng, Maria Korosteleva, Olga Sorkine-Hornung, Leonidas J. Guibas, Guandao Yang .etc.|<http://arxiv.org/pdf/2412.03937v4>|[[代码]](<https://georgenakayama.github.io/AIpparel>)<br />- 问题：服装设计耗时，手工设计，模式生成<br />- 方法：多模态基础模型，大规模数据集，创新标记方案<br />- 效果：SOTA性能，交互式编辑|
|📝 更新|A Benchmark for Cycling Close Pass Detection from Video Streams|自行车视频流中近距离接触检测的基准|Mingjie Li, Ben Beck, Tharindu Rathnayake, Lingheng Meng, Zijue Chen, Akansel Cosgun, Xiaojun Chang, Dana Kulić|<http://arxiv.org/pdf/2304.11868v2>|[[代码]](<https://github.com/SustainableMobility/cyc-cp>)<br />- 问题：自行车近车检测，视频流，安全交互<br />- 方法：Cyc-CP基准，场景级检测，实例级检测，深度学习模型<br />- 效果：高精度，加速检测，促进研究|
|📝 更新|OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations|全文档基准：全面注释下多样化PDF文档解析的基准测试|Linke Ouyang, Yuan Qu, Hongbin Zhou, Jiawei Zhu, Rui Zhang, Qunshu Lin, Bin Wang, Zhiyuan Zhao .etc.|<http://arxiv.org/pdf/2412.07626v2>|[[代码]](<https://github.com/opendatalab/OmniDocBench.>)<br />- 问题：文档解析评估不全面，类型单一，方法评价不公平<br />- 方法：OmniDocBench，多源标注，多级评估<br />- 效果：新标准，公平评估|
|🆕 发布|ImageSet2Text: Describing Sets of Images through Text|图像集2文本：通过文本描述图像集|Piera Riccio, Francesco Galati, Kajetan Schweighofer, Noa Garcia, Nuria Oliver|<http://arxiv.org/pdf/2503.19361v1>|- 问题：图像集描述，自然语言生成，视觉语言模型<br />- 方法：概念瓶颈模型，视觉问答链，知识图谱<br />- 效果：准确性，可读性，质量提升|
|📝 更新|Instruct-CLIP: Improving Instruction-Guided Image Editing with Automated Data Refinement Using Contrastive Learning|指令CLIP：利用对比学习自动数据精炼提升指令引导的图像编辑|Sherry X. Chen, Misha Sra, Pradeep Sen|<http://arxiv.org/pdf/2503.18406v2>|[[代码]](<https://github.com/SherryXTChen/Instruct-CLIP.git.>)<br />- 问题：指令引导图像编辑，数据集质量，T2I模型限制<br />- 方法：Instruct-CLIP，自监督学习，数据精炼<br />- 效果：模型改进，指令对齐，编辑质量提升|
|🆕 发布|Can Vision-Language Models Answer Face to Face Questions in the Real-World?|《视觉-语言模型能否在现实世界中面对面提问？》|Reza Pourreza, Rishit Dagli, Apratim Bhattacharyya, Sunny Panchal, Guillaume Berger, Roland Memisevic|<http://arxiv.org/pdf/2503.19356v1>|- 问题：视觉语言模型，实时问答，人脸识别<br />- 方法：新数据集，IVD，模型微调<br />- 效果：性能提升，能力增强|
|📝 更新|Historic Scripts to Modern Vision: A Novel Dataset and A VLM Framework for Transliteration of Modi Script to Devanagari|从历史手稿到现代视觉：一种新型数据集和用于莫迪文转写为德文尼格里的VLM框架|Harshal Kausadikar, Tanvi Kale, Onkar Susladkar, Sparsh Mittal|<http://arxiv.org/pdf/2503.13060v2>|- 问题：Modi script to Devanagari transliteration, expert scarcity, document preservation<br />- 方法：MoDeTrans dataset, MoScNet VLM, knowledge distillation<br />- 效果：高性能，低参数，OCR任务竞争力|
|🆕 发布|ST-VLM: Kinematic Instruction Tuning for Spatio-Temporal Reasoning in Vision-Language Models|ST-VLM：视觉-语言模型中的运动学指令调优用于时空推理|Dohwan Ko, Sihyeon Kim, Yumin Suh, Vijay Kumar B. G, Minseo Yoon, Manmohan Chandraker, Hyunwoo J. Kim|<http://arxiv.org/pdf/2503.19355v1>|[[代码]](<https://ikodoh.github.io/ST-VLM.>)<br />- 问题：时空推理，VLM，运动分析<br />- 方法：STKit，伪标签生成，ST-VLM<br />- 效果：性能提升，泛化能力强|
|📝 更新|Commonsense Video Question Answering through Video-Grounded Entailment Tree Reasoning|基于视频 grounded 推理的常识视频问答|Huabin Liu, Filip Ilievski, Cees G. M. Snoek|<http://arxiv.org/pdf/2501.05069v2>|- 问题：视频问答，模型偏差，推理能力<br />- 方法：视频片段 grounding，推理树构建，动态扩展<br />- 效果：泛化性强，推理准确|
|🆕 发布|ImageGen-CoT: Enhancing Text-to-Image In-context Learning with Chain-of-Thought Reasoning|ImageGen-CoT：利用思维链推理增强文本到图像的情境学习|Jiaqi Liao, Zhengyuan Yang, Linjie Li, Dianqi Li, Kevin Lin, Yu Cheng, Lijuan Wang|<http://arxiv.org/pdf/2503.19312v1>|[[代码]](<https://ImageGen-CoT.github.io/.>)<br />- 问题：T2I-ICL，语境推理，LLMs<br />- 方法：ImageGen-CoT，数据集，混合缩放<br />- 效果：性能提升，80%增益|
|🆕 发布|LRSCLIP: A Vision-Language Foundation Model for Aligning Remote Sensing Image with Longer Text|LRSCLIP：一种用于对齐遥感图像与长文本的视觉-语言基础模型|Weizhi Chen, Jingbo Chen, Yupeng Deng, Jiansheng Chen, Yuman Feng, Zhihao Xi, Diyou Liu, Kai Li .etc.|<http://arxiv.org/pdf/2503.19311v1>|[[代码]](<https://github.com/MitsuiChen14/LRSCLIP.>)<br />- 问题：长文本处理，幻觉问题，语义粒度限制<br />- 方法：LRSCLIP模型，LRS2M数据集，KPS模块，双文本损失<br />- 效果：检索精度提升，性能最优|
|📝 更新|STOP: Integrated Spatial-Temporal Dynamic Prompting for Video Understanding|停止：视频理解中的集成时空动态提示|Zichen Liu, Kunlun Xu, Bing Su, Xu Zou, Yuxin Peng, Jiahuan Zhou|<http://arxiv.org/pdf/2503.15973v2>|[[代码]](<https://github.com/zhoujiahuan1991/CVPR2025-STOP.>)<br />- 问题：视频理解，时空动态，提示学习，数据稀缺<br />- 方法：时空动态提示，帧内空间提示，帧间时间提示<br />- 效果：性能提升，关键帧优先|
|🆕 发布|Fine-grained Textual Inversion Network for Zero-Shot Composed Image Retrieval|精细粒度文本逆变换网络用于零样本组合图像检索|Haoqiang Lin, Haokun Wen, Xuemeng Song, Meng Liu, Yupeng Hu, Liqiang Nie|<http://arxiv.org/pdf/2503.19296v1>|- 问题：零样本图像检索，文本逆转换，数据标注成本高<br />- 方法：细粒度文本逆转换，语义正则化，BLIP图像描述<br />- 效果：性能优越，实验验证|
|📝 更新|VTD-CLIP: Video-to-Text Discretization via Prompting CLIP|VTD-CLIP：通过提示CLIP的视频到文本离散化|Wencheng Zhu, Yuexin Wang, Hongxuan Li, Pengfei Zhu, Qinghua Hu|<http://arxiv.org/pdf/2503.18407v2>|[[代码]](<https://github.com/isxinxin/VTD-CLIP.>)<br />- 问题：视频识别，可解释性，泛化能力<br />- 方法：视频到文本离散化，视觉代码簿，置信度融合<br />- 效果：性能提升，可解释性增强|
|📝 更新|Global-Local Tree Search in VLMs for 3D Indoor Scene Generation|全局-局部树搜索在VLMs中用于3D室内场景生成|Wei Deng, Mengshi Qi, Huadong Ma|<http://arxiv.org/pdf/2503.18476v2>|[[代码]](<https://github.com/dw-dengwei/TreeSearchGen>)<br />- 问题：3D室内场景生成，VLMs，空间布局约束<br />- 方法：全局-局部树搜索，场景结构分解，VLM位置预测<br />- 效果：生成更合理，优于现有方法|
|📝 更新|Lessons and Insights from a Unifying Study of Parameter-Efficient Fine-Tuning (PEFT) in Visual Recognition|从视觉识别中参数高效微调（PEFT）统一研究中的教训与洞见|Zheda Mai, Ping Zhang, Cheng-Hao Tu, Hong-You Chen, Li Zhang, Wei-Lun Chao|<http://arxiv.org/pdf/2409.16434v5>|- 问题：PEFT性能，应用场景，方法选择<br />- 方法：统一研究，超参数调优，下游任务评估<br />- 效果：相似精度，不同错误，多任务适用|


### 多模态融合 (Multimodal Fusion)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FUSE: Label-Free Image-Event Joint Monocular Depth Estimation via Frequency-Decoupled Alignment and Degradation-Robust Fusion|FUSE：通过频率解耦对齐和退化鲁棒融合的无标签图像-事件联合单目深度估计|Pihai Sun, Junjun Jiang, Yuanqi Yao, Youyu Chen, Wenbo Zhao, Kui Jiang, Xianming Liu|<http://arxiv.org/pdf/2503.19739v1>|[[代码]](<https://github.com/sunpihai-up/FUSE>)<br />- 问题：泛化性，数据稀缺，频率不匹配<br />- 方法：PST，FreDFuse，联合编码<br />- 效果：性能提升，零样本适应|
|🆕 发布|RoboFlamingo-Plus: Fusion of Depth and RGB Perception with Vision-Language Models for Enhanced Robotic Manipulation|机器人火烈鸟增强版：融合深度和RGB感知与视觉-语言模型以增强机器人操作|Sheng Wang|<http://arxiv.org/pdf/2503.19510v1>|- 问题：融合深度与RGB，VLM，机器人操作<br />- 方法：ViT，resampling，交叉注意力<br />- 效果：性能提升10-20%，多模态理解|
|🆕 发布|Adaptive Weighted Parameter Fusion with CLIP for Class-Incremental Learning|自适应加权参数融合结合CLIP进行类别增量学习|Juncen Guo, Xiaoguang Zhu, Liangyu Teng, Hao Yang, Jing Liu, Yang Liu, Liang Song|<http://arxiv.org/pdf/2503.19503v1>|- 问题：CIL，遗忘，知识保留，信息损失<br />- 方法：自适应融合，CLIP，平衡因子<br />- 效果：性能提升，验证有效|
|🆕 发布|A-MESS: Anchor based Multimodal Embedding with Semantic Synchronization for Multimodal Intent Recognition|A-MESS：基于锚点的多模态嵌入与语义同步的多模态意图识别|Yaomin Shen, Xiaojian Lin, Wei Fan|<http://arxiv.org/pdf/2503.19474v1>|- 问题：多模态意图识别，模态连接，语义表示<br />- 方法：锚点嵌入，语义同步，三元组对比学习<br />- 效果：最先进性能，深入理解|
|📝 更新|CLIP-SR: Collaborative Linguistic and Image Processing for Super-Resolution|CLIP-SR：协同语言与图像处理用于超分辨率|Bingwen Hu, Heng Liu, Zhedong Zheng, Ping Liu|<http://arxiv.org/pdf/2412.11609v2>|- 问题：CNN超分辨率，文本引导，语义不一致，细节损失<br />- 方法：多模态语义增强，TIFBlock，迭代优化<br />- 效果：高质量SR，语义一致性，可编辑性|


### 跨模态对齐 (Cross-modal Alignment)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Improved Alignment of Modalities in Large Vision Language Models|大视觉语言模型中模态对齐的改进|Kartik Jangra, Aman Kumar Singh, Yashwani Mann, Geetanjali Rathee|<http://arxiv.org/pdf/2503.19508v1>|- 问题：多模态对齐，大模型，数据效率<br />- 方法：自回归训练，注意力掩码，预训练阶段<br />- 效果：性能提升，小模型大效果|
|📝 更新|TrafficLoc: Localizing Traffic Surveillance Cameras in 3D Scenes|交通定位：在3D场景中定位交通监控摄像头|Yan Xia, Yunxiang Lu, Rui Song, Oussema Dhaouadi, João F. Henriques, Daniel Cremers|<http://arxiv.org/pdf/2412.10308v2>|[[代码]](<https://tum-luk.github.io/projects>)<br />- 问题：交通摄像头定位，3D场景，图像到点云注册<br />- 方法：TrafficLoc，几何引导注意力损失，对比学习，密集训练对齐<br />- 效果：性能提升，泛化能力强|
|📝 更新|Technical Approach for the EMI Challenge in the 8th Affective Behavior Analysis in-the-Wild Competition|第八届情感行为分析在野挑战赛中的EMI技术方法|Jun Yu, Lingsi Zhu, Yanjun Chi, Yunxiang Zhang, Yang Zheng, Yongqi Wang, Xilong Lu|<http://arxiv.org/pdf/2503.10603v3>|- 问题：EMI估计，动态关联，多模态融合<br />- 方法：双阶段对齐，CLIP架构，时序感知融合<br />- 效果：高相关系数，竞赛亚军|
|🆕 发布|VGAT: A Cancer Survival Analysis Framework Transitioning from Generative Visual Question Answering to Genomic Reconstruction|VGAT：从生成式视觉问答到基因组重建的癌症生存分析框架|Zizhi Chen, Minghao Han, Xukun Zhang, Shuwei Ma, Tao Liu, Xing Wei, Lihua Zhang|<http://arxiv.org/pdf/2503.19367v1>|[[代码]](<https://github.com/CZZZZZZZZZZZZZZZZZ/VGAT.>)<br />- 问题：癌症生存分析，基因组测序限制，VQA技术，基因组重建<br />- 方法：VGAT框架，文本特征提取，视觉提示模块<br />- 效果：WSI预测，性能提升，临床可行性|


## 目标检测识别 (Object Detection & Recognition)


### 多目标跟踪 (Multi-object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SAMWISE: Infusing Wisdom in SAM2 for Text-Driven Video Segmentation|SAMWISE：将智慧融入SAM2以实现文本驱动视频分割|Claudia Cuttano, Gabriele Trivigno, Gabriele Rosi, Carlo Masone, Giuseppe Averta|<http://arxiv.org/pdf/2411.17646v2>|[[代码]](<https://github.com/ClaudiaCuttano/SAMWISE>)<br />- 问题：RVOS局限性，全局上下文丢失，流式处理困难<br />- 方法：SAM2，自然语言理解，时间建模，适配器模块<br />- 效果：SOTA，参数增量小|
|📝 更新|Is a Pure Transformer Effective for Separated and Online Multi-Object Tracking?|纯Transformer对分离和在线多目标跟踪有效吗？|Chongwei Liu, Haojie Li, Zhihui Wang, Rui Xu|<http://arxiv.org/pdf/2405.14119v2>|[[代码]](<https://github.com/chongweiliu/PuTR>)<br />- 问题：多目标跟踪，长期跟踪，实时性<br />- 方法：Transformer，轨迹图，在线学习<br />- 效果：性能提升，适应性强|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AudCast: Audio-Driven Human Video Generation by Cascaded Diffusion Transformers|音频驱动的级联扩散变换器生成人类视频|Jiazhi Guan, Kaisiyuan Wang, Zhiliang Xu, Quanwei Yang, Yasheng Sun, Shengyi He, Borong Liang, Yukang Cao .etc.|<http://arxiv.org/pdf/2503.19824v1>|[[代码]](<https://guanjz20.github.io/projects>)<br />- 问题：音频驱动视频生成，非连贯动态，细节处理难<br />- 方法：级联扩散Transformer，区域细化，3D拟合<br />- 效果：高保真，时序一致性，细节丰富|


### 三维检测 (3D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AuraFusion360: Augmented Unseen Region Alignment for Reference-based 360° Unbounded Scene Inpainting|AuraFusion360：基于参考的360°无界场景修复中的未见区域增强对齐|Chung-Ho Wu, Yang-Jung Chen, Ying-Huan Chen, Jie-Ying Lee, Bo-Hsu Ke, Chun-Wei Tuan Mu, Yi-Chuan Huang, Chin-Yang Lin .etc.|<http://arxiv.org/pdf/2502.05176v2>|- 问题：360°无界场景，视域一致性，几何精度<br />- 方法：深度感知，自适应引导，SDEdit增强<br />- 效果：高质量，几何准确|
|🆕 发布|GRN+: A Simplified Generative Reinforcement Network for Tissue Layer Analysis in 3D Ultrasound Images for Chronic Low-back Pain|GRN+：一种用于慢性腰痛3D超声图像组织层分析的简化生成式强化网络|Zixue Zeng, Xiaoyan Zhao, Matthew Cartier, Xin Meng, Jiantao Pu|<http://arxiv.org/pdf/2503.19736v1>|- 问题：3D超声图像，组织层分析，手动标注，劳动密集<br />- 方法：GRN+，多模型框架，自动层分割，SGE，两阶段反向传播<br />- 效果：Dice系数高，计算成本低，标注依赖低|
|📝 更新|SG-GAN: Fine Stereoscopic-Aware Generation for 3D Brain Point Cloud Up-sampling from a Single Image|SG-GAN：从单张图像到3D脑点云上采样的精细立体感知生成|Bowen Hu, Weiheng Yao, Sibo Qiao, Hieu Pham, Shuqiang Wang, Michael Kwok-Po Ng|<http://arxiv.org/pdf/2305.12646v2>|- 问题：3D脑点云上采样，精度不足，数据稀缺<br />- 方法：SG-GAN，双阶段生成，自注意力模块<br />- 效果：高密度，细节恢复，性能优越|
|📝 更新|Which2comm: An Efficient Collaborative Perception Framework for 3D Object Detection|Which2comm：一种高效的3D目标检测协同感知框架|Duanrui Yu, Jing You, Xin Pei, Anqi Qu, Dingyu Wang, Shaocheng Jia|<http://arxiv.org/pdf/2503.17175v2>|- 问题：通信带宽限制，感知性能下降<br />- 方法：语义检测框，稀疏特征传输，时间融合<br />- 效果：性能提升，通信成本降低|
|📝 更新|BimArt: A Unified Approach for the Synthesis of 3D Bimanual Interaction with Articulated Objects|双艺：3D可动对象双臂交互的统一方法|Wanyue Zhang, Rishabh Dabral, Vladislav Golyanik, Vasileios Choutas, Eduardo Alvarado, Thabo Beeler, Marc Habermann, Christian Theobalt|<http://arxiv.org/pdf/2412.05066v2>|- 问题：3D双臂交互，关节物体，合成<br />- 方法：距离图，特征表示，接触先验<br />- 效果：高质量，多样化|
|📝 更新|HD-EPIC: A Highly-Detailed Egocentric Video Dataset|HD-EPIC：一个高细节自视角视频数据集|Toby Perrett, Ahmad Darkhalil, Saptarshi Sinha, Omar Emara, Sam Pollard, Kranti Parida, Kaiting Liu, Prajwal Gatti .etc.|<http://arxiv.org/pdf/2502.04144v2>|- 问题：厨房视频标注，细节，真实环境<br />- 方法：详细标注，数字孪生，无脚本采集<br />- 效果：挑战性基准，识别能力，动作识别|
|📝 更新|Lightweight Models for Emotional Analysis in Video|轻量级模型在视频情感分析中的应用|Quoc-Tien Nguyen, Hong-Hai Nguyen, Van-Thong Huynh|<http://arxiv.org/pdf/2503.10530v2>|- 问题：情感分析，视频，轻量级模型<br />- 方法：MobileNetV4，3D MLP-Mixer，多尺度特征<br />- 效果：效率高，准确性好|
|🆕 发布|MATT-GS: Masked Attention-based 3DGS for Robot Perception and Object Detection|MATT-GS：基于掩码注意力的3DGS在机器人感知和目标检测中的应用|Jee Won Lee, Hansol Lim, SooYeun Yang, Jongseong Brad Choi|<http://arxiv.org/pdf/2503.19330v1>|- 问题：机器人感知，物体检测，工业环境<br />- 方法：掩码注意力，3D高斯分层，背景去除<br />- 效果：视觉保真度提升，细节保留|


### 二维检测 (2D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DeNVeR: Deformable Neural Vessel Representations for Unsupervised Video Vessel Segmentation|DeNVeR：用于无监督视频血管分割的可变形神经网络血管表示|Chun-Hung Wu, Shih-Hong Chen, Chih-Yao Hu, Hsin-Yu Wu, Kai-Hsin Chen, Yu-You Chen, Chih-Hai Su, Chih-Kuo Lee .etc.|<http://arxiv.org/pdf/2406.01591v4>|- 问题：无监督血管分割，X射线血管造影视频<br />- 方法：层分离，光流，Eulerian运动场<br />- 效果：精度高，泛化能力强|
|🆕 发布|Surg-3M: A Dataset and Foundation Model for Perception in Surgical Settings|Surg-3M：手术场景感知的数据集和基础模型|Chengan Che, Chao Wang, Tom Vercauteren, Sophia Tsoka, Luis C. Garcia-Peraza-Herrera|<http://arxiv.org/pdf/2503.19740v1>|- 问题：数据集规模小，视觉数据解释不准确<br />- 方法：Surg-3M数据集，SurgFM基础模型，自监督预训练<br />- 效果：性能提升，Jaccard指数，mAP|
|🆕 发布|BiblioPage: A Dataset of Scanned Title Pages for Bibliographic Metadata Extraction|《BiblioPage：用于书目元数据提取的扫描标题页数据集》|Jan Kohút, Martin Dočekal, Michal Hradiš, Marek Vaško|<http://arxiv.org/pdf/2503.19658v1>|[[代码]](<https://github.com/DCGM/biblio-dataset>)<br />- 问题：手动数字化，数据集缺乏，自动化困难<br />- 方法：BiblioPage数据集，标注，模型评估<br />- 效果：高mAP，高F1分数|
|📝 更新|RL-RC-DoT: A Block-level RL agent for Task-Aware Video Compression|RL-RC-DoT：一种基于块级的任务感知视频压缩强化学习代理|Uri Gadot, Assaf Shocher, Shie Mannor, Gal Chechik, Assaf Hallak|<http://arxiv.org/pdf/2501.12216v2>|- 问题：视频压缩，任务优化，编码器效率<br />- 方法：块级RL，QPs控制，任务感知<br />- 效果：性能提升，效率优化|
|🆕 发布|Video Anomaly Detection with Contours - A Study|基于轮廓的视频异常检测研究|Mia Siemon, Ivan Nikolov, Thomas B. Moeslund, Kamal Nasrollahi|<http://arxiv.org/pdf/2503.19588v1>|- 问题：异常检测，行为模式，轮廓学习<br />- 方法：回归分类，轮廓表示，浅层神经网络<br />- 效果：计算复杂度低，数据覆盖广|
|🆕 发布|TFIC: End-to-End Text-Focused Image Compression for Coding for Machines|TFIC：面向机器编码的端到端文本聚焦图像压缩|Stefano Della Fiore, Alessandro Gnutti, Marco Dalai, Pierangelo Migliorati, Riccardo Leonardi|<http://arxiv.org/pdf/2503.19495v1>|- 问题：图像压缩，OCR，低比特率，计算效率<br />- 方法：文本聚焦压缩，端到端设计，优化编码过程<br />- 效果：OCR精度提升，压缩效率高|
|📝 更新|CQ-DINO: Mitigating Gradient Dilution via Category Queries for Vast Vocabulary Object Detection|CQ-DINO：通过类别查询缓解梯度稀释的大词汇量目标检测|Zhichao Sun, Huazhang Hu, Yidong Ma, Gang Liu, Nemo Chen, Xu Tang, Yao Hu, Yongchao Xu|<http://arxiv.org/pdf/2503.18430v2>|[[代码]](<https://github.com/RedAIGC/CQ-DINO.>)<br />- 问题：梯度稀释，类别查询，大规模检测<br />- 方法：对比学习，查询选择，类别关联<br />- 效果：性能提升，AP超越前人|
|📝 更新|LVFace: Progressive Cluster Optimization for Large Vision Models in Face Recognition|LVFace：面向人脸识别的大视觉模型的渐进式聚类优化|Jinghan You, Shanglin Li, Yuanrui Sun, Jiangchuan Wei, Mingyu Guo, Chao Feng, Jiao Ran|<http://arxiv.org/pdf/2501.13420v2>|- 问题：CNN训练，ViT潜力，性能不足<br />- 方法：PCO，NCS，特征期望惩罚<br />- 效果：SOTA，性能提升|
|📝 更新|Frequency Dynamic Convolution for Dense Image Prediction|频率动态卷积用于密集图像预测|Linwei Chen, Lin Gu, Liang Li, Chenggang Yan, Ying Fu|<http://arxiv.org/pdf/2503.18783v2>|[[代码]](<https://github.com/Linwei-Chen/FDConv.>)<br />- 问题：DY-Conv，参数成本高，适应能力有限<br />- 方法：FDConv，频率动态卷积，KSM，FBM<br />- 效果：性能提升，参数增加少|
|🆕 发布|Face Spoofing Detection using Deep Learning|深度学习在人脸欺骗检测中的应用|Najeebullah, Maaz Salman, Zar Nawab Khan Swati|<http://arxiv.org/pdf/2503.19223v1>|- 问题：人脸伪造检测，生物识别安全<br />- 方法：MobileNetV2，ResNET50，ViT，图像分类<br />- 效果：准确率91.59%，泛化能力强|


## 场景理解 (Scene Understanding)


### 语义分割 (Semantic Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MambaVision: A Hybrid Mamba-Transformer Vision Backbone|曼巴视觉：一种混合曼巴-Transformer视觉骨干|Ali Hatamizadeh, Jan Kautz|<http://arxiv.org/pdf/2407.08083v2>|[[代码]](<https://github.com/NVlabs/MambaVision>)<br />- 问题：视觉特征建模，长距离依赖，模型效率<br />- 方法：Mamba-Transformer融合，自注意力块，分层架构<br />- 效果：SOTA性能，下游任务表现佳|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DWIM: Towards Tool-aware Visual Reasoning via Discrepancy-aware Workflow Generation & Instruct-Masking Tuning|DWIM：通过差异感知工作流程生成与指令掩码调优实现工具感知视觉推理|Fucai Ke, Vijay Kumar B G, Xingjian Leng, Zhixi Cai, Zaid Khan, Weiqing Wang, Pari Delir Haghighi, Hamid Rezatofighi .etc.|<http://arxiv.org/pdf/2503.19263v1>|- 问题：视觉推理，工具意识，训练数据，工具错误，微调困难<br />- 方法：差异感知工作流生成，指令掩码微调<br />- 效果：最佳性能，强泛化|


## 时序理解 (Temporal Understanding)


### 时序分析 (Temporal Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Lost in Time: A New Temporal Benchmark for VideoLLMs|迷失在时间中：视频LLMs的新时间基准|Daniel Cores, Michael Dorkenwald, Manuel Mucientes, Cees G. M. Snoek, Yuki M. Asano|<http://arxiv.org/pdf/2410.07752v3>|- 问题：视频模型评估，时间推理，信息过载，知识复制<br />- 方法：TVBench，开放性问答，时间理解<br />- 效果：挑战现有模型，揭示时间推理重要性|


## 三维重建 (3D Reconstruction)


### 多视图重建 (Multi-view Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PartRM: Modeling Part-Level Dynamics with Large Cross-State Reconstruction Model|PartRM：利用大型跨状态重建模型建模部件级动态|Mingju Gao, Yike Pan, Huan-ang Gao, Zongzheng Zhang, Wenyi Li, Hao Dong, Hao Tang, Li Yi .etc.|<http://arxiv.org/pdf/2503.19913v1>|- 问题：部分级动态建模，视频扩散模型，数据稀缺<br />- 方法：4D重建框架，多尺度拖拽嵌入，两阶段训练<br />- 效果：新SOTA，机器人操作|
|📝 更新|DepthSplat: Connecting Gaussian Splatting and Depth|深度融合：连接高斯融合与深度|Haofei Xu, Songyou Peng, Fangjinhua Wang, Hermann Blum, Daniel Barath, Andreas Geiger, Marc Pollefeys|<http://arxiv.org/pdf/2410.13862v3>|- 问题：深度估计，单视图，Gaussian splatting<br />- 方法：多视图深度模型，预训练特征，无监督预训练<br />- 效果：性能提升，实时重建|
|🆕 发布|SparseGS-W: Sparse-View 3D Gaussian Splatting in the Wild with Generative Priors|稀疏视图野外生成先验下的3D高斯分层|Yiqing Li, Xuan Wang, Jiawei Wu, Yikun Ma, Zhi Jin|<http://arxiv.org/pdf/2503.19452v1>|- 问题：稀疏视图，3D重建，场景合成<br />- 方法：3D高斯分层，生成先验，约束扩散<br />- 效果：性能提升，FID，ClipIQA，MUSIQ|


### 单目重建 (Monocular Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EventMamba: Enhancing Spatio-Temporal Locality with State Space Models for Event-Based Video Reconstruction|事件Mamba：利用状态空间模型增强时空局部性以实现基于事件的视频重建|Chengjie Ge, Xueyang Fu, Peng He, Kunyu Wang, Chengzhi Cao, Zheng-Jun Zha|<http://arxiv.org/pdf/2503.19721v1>|- 问题：EBVR，空间时序局部性，Mamba局限性<br />- 方法：随机窗口偏移，一致遍历序列化<br />- 效果：视频重建提升，速度提升，质量提升|


### 神经隐式重建 (Neural Implicit Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GaussianUDF: Inferring Unsigned Distance Functions through 3D Gaussian Splatting|高斯UDF：通过3D高斯喷溅推断无符号距离函数|Shujuan Li, Yu-Shen Liu, Zhizhong Han|<http://arxiv.org/pdf/2503.19458v1>|[[代码]](<https://lisj575.github.io/GaussianUDF>)<br />- 问题：UDF学习，3DGS，连续性，自监督<br />- 方法：2D高斯平面，约束学习，梯度推断<br />- 效果：精度高，效率高，表面完整|
|📝 更新|BF-STVSR: B-Splines and Fourier-Best Friends for High Fidelity Spatial-Temporal Video Super-Resolution|BF-STVSR：B样条与傅里叶最佳拍档实现高保真时空视频超分辨率|Eunjin Kim, Hyeonjin Kim, Kyong Hwan Jin, Jaejun Yoo|<http://arxiv.org/pdf/2501.11043v2>|[[代码]](<https://github.com/Eunjnnn/bfstvsr.>)<br />- 问题：C-STVSR，数据复杂性，运动表示，性能限制<br />- 方法：B-spline Mapper，Fourier Mapper，时空特性<br />- 效果：PSNR，SSIM，细节增强|
|📝 更新|IncEventGS: Pose-Free Gaussian Splatting from a Single Event Camera|IncEventGS：单事件相机中的无姿态高斯喷溅|Jian Huang, Chengrui Dong, Xuanhua Chen, Peidong Liu|<http://arxiv.org/pdf/2410.08107v4>|[[代码]](<https://github.com/wu-cvgl/IncEventGS.>)<br />- 问题：事件相机，3D重建，NeRF，SLAM<br />- 方法：增量3D高斯分层，跟踪映射，场景表示<br />- 效果：性能优越，运动估计准确|


## 神经渲染 (Neural Rendering)


### 神经辐射场 (Neural Radiance Fields)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SpectroMotion: Dynamic 3D Reconstruction of Specular Scenes|光谱运动：镜面场景的动态3D重建|Cheng-De Fan, Chen-Wei Chang, Yi-Ruei Liu, Jie-Ying Lee, Jiun-Long Huang, Yu-Chee Tseng, Yu-Lun Liu|<http://arxiv.org/pdf/2410.17249v3>|- 问题：动态镜面场景重建，表面正常计算，光照条件适应<br />- 方法：3DGS，PBR，变形场，残差校正，可变形环境图<br />- 效果：真实感，性能提升|
|📝 更新|FrugalNeRF: Fast Convergence for Few-shot Novel View Synthesis without Learned Priors|FrugalNeRF：无需学习先验的少样本新视角合成快速收敛|Chin-Yang Lin, Chung-Ho Wu, Chang-Han Yeh, Shih-Han Yen, Cheng Sun, Yu-Lun Liu|<http://arxiv.org/pdf/2410.16271v2>|- 问题：NeRF，少样本，过拟合，训练时间长<br />- 方法：跨尺度几何适应，伪真实深度，权重共享<br />- 效果：性能提升，训练时间缩短|
|🆕 发布|A Survey on Event-driven 3D Reconstruction: Development under Different Categories|事件驱动3D重建综述：不同类别下的进展|Chuanzhi Xu, Haoxian Zhou, Haodong Chen, Vera Chung, Qiang Qu|<http://arxiv.org/pdf/2503.19753v1>|- 问题：事件相机，3D重建，高动态范围，异步捕获<br />- 方法：立体，单目，多模态系统，几何，学习，混合方法<br />- 效果：准确重建，动态运动，挑战性光照|
|🆕 发布|MultimodalStudio: A Heterogeneous Sensor Dataset and Framework for Neural Rendering across Multiple Imaging Modalities|多模态工作室：跨多种成像模态的神经渲染异构传感器数据集和框架|Federico Lincetto, Gianluca Agresti, Mattia Rossi, Pietro Zanuttigh|<http://arxiv.org/pdf/2503.19673v1>|- 问题：异构模态学习，数据稀缺，渲染质量<br />- 方法：多模态数据集，NeRF框架，跨模态信息传递<br />- 效果：高质量渲染，信息跨模态迁移|
|📝 更新|ProtoGS: Efficient and High-Quality Rendering with 3D Gaussian Prototypes|ProtoGS：基于3D高斯原型的有效且高质量的渲染|Zhengqing Gao, Dongting Hu, Jia-Wang Bian, Huan Fu, Yan Li, Tongliang Liu, Mingming Gong, Kun Zhang|<http://arxiv.org/pdf/2503.17486v2>|- 问题：3DGS渲染效率低，质量受限<br />- 方法：学习原型，K-means聚类，SfM锚点<br />- 效果：效率提升，质量保持|
|📝 更新|ProbeSDF: Light Field Probes for Neural Surface Reconstruction|探SDF：用于神经表面重建的光场探针|Briac Toussaint, Diego Thomas, Jean-Sébastien Franco|<http://arxiv.org/pdf/2412.10084v2>|- 问题：SDF，多视图3D重建，性能提升<br />- 方法：最小辐射度参数化，特征编码，MLP<br />- 效果：速度提升，性能增强|
|🆕 发布|SINR: Sparsity Driven Compressed Implicit Neural Representations|稀疏驱动压缩隐式神经网络表示：SINR|Dhananjaya Jayasundara, Sudarshan Rajagopalan, Yasiru Ranasinghe, Trac D. Tran, Vishal M. Patel|<http://arxiv.org/pdf/2503.19576v1>|- 问题：INR压缩，量化依赖，存储需求高<br />- 方法：稀疏编码，字典学习，无需传输原子<br />- 效果：存储减少，质量高|
|📝 更新|LookCloser: Frequency-aware Radiance Field for Tiny-Detail Scene|LookCloser：针对微小细节场景的频率感知辐射场|Xiaoyu Zhang, Weihong Pan, Chong Bao, Xiyu Zhang, Xiaojun Xiang, Hanqing Jiang, Hujun Bao|<http://arxiv.org/pdf/2503.18513v2>|[[代码]](<https://coscatter.github.io/LookCloser>)<br />- 问题：NeRF，频率建模，细节捕捉，场景结构<br />- 方法：FA-NeRF，频率量化，频率网格，特征重加权<br />- 效果：细节保留，性能提升|
|📝 更新|MS-NeRF: Multi-Space Neural Radiance Fields|MS-NeRF：多空间神经辐射场|Ze-Xin Yin, Peng-Yi Jiao, Jiaxiong Qiu, Ming-Ming Cheng, Bo Ren|<http://arxiv.org/pdf/2305.04268v2>|[[代码]](<https://zx-yin.github.io/msnerf>)<br />- 问题：反射物体渲染模糊，计算量大<br />- 方法：多空间神经网络，特征场并行，增强NeRF<br />- 效果：PSNR提升，参数增加少|
|📝 更新|SelfSplat: Pose-Free and 3D Prior-Free Generalizable 3D Gaussian Splatting|自Splat：无需姿态和3D先验的通用3D高斯Splatting|Gyeongjin Kang, Jisang Yoo, Jihyeon Park, Seungtae Nam, Sangpil Kim, Hyeonsoo Im, Sangheon Shin, Eunbyung Park|<http://arxiv.org/pdf/2411.17190v4>|[[代码]](<https://gynjn.github.io/selfsplat>)<br />- 问题：3D重建，无姿态，无先验<br />- 方法：自监督深度，姿态估计，匹配感知网络<br />- 效果：高质量，泛化能力强|
|📝 更新|StableGS: A Floater-Free Framework for 3D Gaussian Splatting|稳定GS：一个无漂移的3D高斯分层框架|Luchao Wang, Qian Ren, Kaimin Liao, Hua Wang, Zhi Chen, Yaohua Tang|<http://arxiv.org/pdf/2503.18458v2>|- 问题：3DGS训练不稳定，floaters，视觉质量下降<br />- 方法：StableGS框架，深度一致性约束，双透明度GS模型<br />- 效果：稳定性提升，质量改善|
|🆕 发布|HoGS: Unified Near and Far Object Reconstruction via Homogeneous Gaussian Splatting|HoGS：通过同质高斯喷溅实现近远物体统一重建|Xinpeng Liu, Zeyi Huang, Fumio Okura, Yasuyuki Matsushita|<http://arxiv.org/pdf/2503.19232v1>|[[代码]](<https://kh129.github.io/hogs>)<br />- 问题：3DGS性能，远物重建，坐标限制<br />- 方法：HoGS，同质坐标，投影几何<br />- 效果：精度提升，渲染质量，实时性|


### 可控渲染 (Controllable Rendering)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Bokehlicious: Photorealistic Bokeh Rendering with Controllable Apertures|《博克丽奥：可控光圈下的逼真散景渲染》|Tim Seizinger, Florin-Alexandru Vasluianu, Marcos V. Conde, Zongwei Wu, Radu Timofte|<http://arxiv.org/pdf/2503.16067v2>|[[代码]](<https://github.com/TimSeizinger/Bokehlicious>)<br />- 问题：Bokeh渲染，真实感，数据缺乏<br />- 方法：Aperture-Aware Attention，RealBokeh数据集<br />- 效果：SOTA超越，计算成本低，泛化能力强|
|🆕 发布|EmoHead: Emotional Talking Head via Manipulating Semantic Expression Parameters|情感头部：通过操纵语义表情参数实现的情感说话头|Xuli Shen, Hua Cai, Dingding Yu, Weilin Shen, Qing Xu, Xiangyang Xue|<http://arxiv.org/pdf/2503.19416v1>|- 问题：情感表达，视频生成，抽象概念，参数化<br />- 方法：音频-表情模块，预训练超平面，神经辐射场<br />- 效果：高质量，可控性|
|📝 更新|CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting|CompMarkGS：压缩3D高斯分层鲁棒水印|Sumin In, Youngdong Jang, Utae Jeong, MinHyuk Jang, Hyeongcheol Park, Eunbyung Park, Sangpil Kim|<http://arxiv.org/pdf/2503.12836v3>|- 问题：3DGS水印，压缩，鲁棒性，质量<br />- 方法：量化模拟，可学习嵌入，频率感知锚点<br />- 效果：水印保留，高质量|


## 定位与映射 (Localization & Mapping)


### 位姿估计 (Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visuo-Tactile Object Pose Estimation for a Multi-Finger Robot Hand with Low-Resolution In-Hand Tactile Sensing|视觉触觉多指机器人手低分辨率在手触觉感知中的物体姿态估计|Lukas Mack, Felix Grüninger, Benjamin A. Richardson, Regine Lendway, Katherine J. Kuchenbecker, Joerg Stueckler|<http://arxiv.org/pdf/2503.19893v1>|- 问题：3D姿态估计，遮挡，视觉噪声，触觉感知<br />- 方法：视觉触觉融合，概率图模型，鲁棒优化<br />- 效果：精度提升，高遮挡下性能好|
|🆕 发布|Semi-SD: Semi-Supervised Metric Depth Estimation via Surrounding Cameras for Autonomous Driving|半监督度量深度估计：通过周围摄像头实现自动驾驶|Yusen Xie, Zhengmin Huang, Shaojie Shen, Jun Ma|<http://arxiv.org/pdf/2503.19713v1>|[[代码]](<https://github.com/xieyuser/Semi-SD.>)<br />- 问题：深度估计，尺度模糊，自动驾驶<br />- 方法：时空语义融合，交叉注意力，位姿估计<br />- 效果：性能领先，深度质量高|
|🆕 发布|DynOPETs: A Versatile Benchmark for Dynamic Object Pose Estimation and Tracking in Moving Camera Scenarios|动态物体姿态估计与跟踪在移动相机场景下的通用基准：DynOPETs|Xiangting Meng, Jiaqi Yang, Mingshu Chen, Chenxin Yan, Yujiao Shi, Wenchao Ding, Laurent Kneip|<http://arxiv.org/pdf/2503.19625v1>|- 问题：动态物体，移动相机，姿态估计，数据集稀缺<br />- 方法：数据集DynOPETs，伪标签，姿态图优化<br />- 效果：加速研究，公开可用|
|🆕 发布|Scene-agnostic Pose Regression for Visual Localization|场景无关的人体姿态回归用于视觉定位|Junwei Zheng, Ruiping Liu, Yufan Chen, Zhenfang Chen, Kailun Yang, Jiaming Zhang, Rainer Stiefelhagen|<http://arxiv.org/pdf/2503.19543v1>|[[代码]](<https://junweizheng93.github.io/publications>)<br />- 问题：APR适应性差，RPR需数据库，VO误差累积<br />- 方法：场景无关姿态回归（SPR），360SPR数据集，SPR-Mamba模型<br />- 效果：超越APR，RPR，VO|
|📝 更新|Synergizing Motion and Appearance: Multi-Scale Compensatory Codebooks for Talking Head Video Generation|协同运动与外观：用于说话人头视频生成的多尺度补偿代码簿|Shuling Zhao, Fa-Ting Hong, Xiaoshui Huang, Dan Xu|<http://arxiv.org/pdf/2412.00719v2>|- 问题：视频生成，身份保留，运动建模，外观指导<br />- 方法：多尺度代码本，联合学习，补偿模块<br />- 效果：高质量，灵活运动，低失真|
|🆕 发布|Pose-Based Fall Detection System: Efficient Monitoring on Standard CPUs|基于姿态的跌倒检测系统：在标准CPU上的高效监控|Vinayak Mali, Saurabh Jaiswal|<http://arxiv.org/pdf/2503.19501v1>|- 问题：跌倒检测，传感器依赖，计算资源高<br />- 方法：姿态估计，MediaPipe，投票机制<br />- 效果：实时处理，低误报率|
|🆕 发布|Multi-modal 3D Pose and Shape Estimation with Computed Tomography|多模态3D姿态和形状估计与计算机断层扫描|Mingxiao Tu, Hoijoon Jung, Alireza Moghadam, Jineel Raythatha, Lachlan Allan, Jeremy Hsu, Andre Kyme, Jinman Kim|<http://arxiv.org/pdf/2503.19405v1>|- 问题：3D PSE，床位，遮挡，精度低<br />- 方法：多模态融合，CT扫描，形状估计<br />- 效果：性能提升，临床应用|
|📝 更新|Any6D: Model-free 6D Pose Estimation of Novel Objects|Any6D：新型物体免模型6D姿态估计|Taeyeop Lee, Bowen Wen, Minjun Kang, Gyuree Kang, In So Kweon, Kuk-Jin Yoon|<http://arxiv.org/pdf/2503.18673v2>|- 问题：6D姿态估计，新物体，单图像<br />- 方法：模型无关，联合对齐，渲染比较<br />- 效果：精度高，鲁棒性强|
|🆕 发布|From Sparse to Dense: Camera Relocalization with Scene-Specific Detector from Feature Gaussian Splatting|从稀疏到密集：基于特征高斯喷绘的特定场景检测器的相机重定位|Zhiwei Huang, Hailin Yu, Yichun Shentu, Jin Yuan, Guofeng Zhang|<http://arxiv.org/pdf/2503.19358v1>|- 问题：相机重定位，稀疏到密集，定位精度<br />- 方法：特征高斯，匹配采样，场景检测器<br />- 效果：准确度高，召回率高|
|📝 更新|AutoURDF: Unsupervised Robot Modeling from Point Cloud Frames Using Cluster Registration|自动URDF：基于聚类配准的无监督点云帧机器人建模|Jiong Lin, Lechen Zhang, Kwansoo Lee, Jialong Ning, Judah Goldfeder, Hod Lipson|<http://arxiv.org/pdf/2412.05507v2>|- 问题：机器人建模，手动，点云帧<br />- 方法：聚类注册，6-DoF变换，层次处理<br />- 效果：自动化，准确性高|
|🆕 发布|Analyzing the Synthetic-to-Real Domain Gap in 3D Hand Pose Estimation|分析3D手部姿态估计中的合成到真实域差距|Zhuoran Zhao, Linlin Yang, Pengzhan Sun, Pan Hui, Angela Yao|<http://arxiv.org/pdf/2503.19307v1>|[[代码]](<https://github.com/delaprada/HandSynthesis.git.>)<br />- 问题：3D手部姿态估计，合成-真实差距<br />- 方法：数据合成管道，组件分析，系统研究<br />- 效果：合成数据精度，手部姿态估计|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DynFocus: Dynamic Cooperative Network Empowers LLMs with Video Understanding|DynFocus：动态协作网络赋能LLMs的视频理解|Yudong Han, Qingpei Guo, Liyuan Pan, Liu Liu, Yu Guan, Ming Yang|<http://arxiv.org/pdf/2411.12355v2>|- 问题：视频理解，信息保留，内存效率<br />- 方法：动态编码，DPE模块，CCE模块<br />- 效果：性能竞争，高效编码|
|🆕 发布|Beyond Object Categories: Multi-Attribute Reference Understanding for Visual Grounding|超越对象类别：多属性参考理解用于视觉定位|Hao Guo, Jianfei Zhu, Wei Fan, Chunzhi Yi, Feng Jiang|<http://arxiv.org/pdf/2503.19240v1>|- 问题：REC限制，对象描述，属性描述<br />- 方法：Multi-ref EC，SIGAR数据集，多属性参考<br />- 效果：定位性能提升，自然交互|


### 语义建图 (Semantic Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Divide-and-Conquer: Dual-Hierarchical Optimization for Semantic 4D Gaussian Spatting|分割与征服：语义4D高斯空间分割的双重分层优化|Zhiying Yan, Yiyuan Liang, Shilv Cai, Tao Zhang, Sheng Zhong, Luxin Yan, Xu Zou|<http://arxiv.org/pdf/2503.19332v1>|[[代码]](<https://sweety-yan.github.io/DHO.>)<br />- 问题：动态场景理解，Gaussian Splatting，更新策略，噪声，伪影<br />- 方法：Dual-Hierarchical Optimization，Gaussian Flow，Gaussian Guidance<br />- 效果：性能优于基线，支持下游任务|


## 自监督学习 (Self-supervised Learning)


### 对比学习 (Contrastive Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SuperFlow++: Enhanced Spatiotemporal Consistency for Cross-Modal Data Pretraining|超级流++：跨模态数据预训练的增强时空一致性|Xiang Xu, Lingdong Kong, Hui Shuai, Wenwei Zhang, Liang Pan, Kai Chen, Ziwei Liu, Qingshan Liu|<http://arxiv.org/pdf/2503.19912v1>|[[代码]](<https://github.com/Xiangxu-0103/SuperFlow>)<br />- 问题：时空一致性，跨模态数据预训练，运动捕捉<br />- 方法：视图一致性，稠密到稀疏正则化，对比学习，时间投票<br />- 效果：性能提升，可扩展性|
|🆕 发布|Scaling Vision Pre-Training to 4K Resolution|将视觉预训练扩展到4K分辨率|Baifeng Shi, Boyi Li, Han Cai, Yao Lu, Sifei Liu, Marco Pavone, Jan Kautz, Song Han .etc.|<http://arxiv.org/pdf/2503.19903v1>|- 问题：低分辨率视觉预训练，计算成本高<br />- 方法：PS3，局部区域处理，对比学习<br />- 效果：高分辨率感知，效率提升|
|🆕 发布|Single Shot AI-assisted quantification of KI-67 proliferation index in breast cancer|单次AI辅助测定乳腺癌中KI-67增殖指数|Deepti Madurai Muthu, Priyanka S, Lalitha Rani N, P. G. Kubendran Amos|<http://arxiv.org/pdf/2503.19606v1>|- 问题：Ki-67定量，主观性，可重复性差<br />- 方法：YOLOv8，对象检测，AI辅助<br />- 效果：高mAP50，客观性，一致性|
|📝 更新|Few-Shot Segmentation with Global and Local Contrastive Learning|少量样本分割：全局与局部对比学习|Weide Liu, Zhonghua Wu, Henghui Ding, Fayao Liu, Jie Lin, Guosheng Lin, Wei Zhou|<http://arxiv.org/pdf/2108.05293v2>|- 问题：少样本分割，信息提取，依赖支持图像<br />- 方法：全局-局部对比学习，先验提取器，独立信息提取<br />- 效果：新SOTA，PASCAL-5i，COCO|


### 一致性学习 (Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Tracktention: Leveraging Point Tracking to Attend Videos Faster and Better|追踪注意力：利用点跟踪加速并提升视频处理|Zihang Lai, Andrea Vedaldi|<http://arxiv.org/pdf/2503.19904v1>|- 问题：视频预测，时间一致性，运动处理，长距离依赖<br />- 方法：Tracktention层，点跟踪，运动信息整合<br />- 效果：时间一致性提升，性能改善|
|🆕 发布|GyralNet Subnetwork Partitioning via Differentiable Spectral Modularity Optimization|基于可微谱模体优化的GyralNet子网络划分|Yan Zhuang, Minheng Chen, Chao Cao, Tong Chen, Jing Zhang, Xiaowei Yu, Yanjun Lyu, Lu Zhang .etc.|<http://arxiv.org/pdf/2503.19823v1>|- 问题：3HG分析，分辨率限制，计算复杂度，社区关系<br />- 方法：可微分谱模度优化，拓扑相似性，DTI连接<br />- 效果：个体级分区，社区一致性，理解脑连接|
|📝 更新|HunyuanPortrait: Implicit Condition Control for Enhanced Portrait Animation|HunyuanPortrait：增强肖像动画的隐式条件控制|Zunnan Xu, Zhentao Yu, Zixiang Zhou, Jun Zhou, Xiaoyu Jin, Fa-Ting Hong, Xiaozhong Ji, Junwei Zhu .etc.|<http://arxiv.org/pdf/2503.18860v2>|[[代码]](<https://kkakkkka.github.io/HunyuanPortrait.>)<br />- 问题：肖像动画，条件控制，表情，姿态<br />- 方法：隐式表示，扩散模型，注意力机制<br />- 效果：可控性，真实性，泛化性|
|📝 更新|Zero-1-to-A: Zero-Shot One Image to Animatable Head Avatars Using Video Diffusion|零到一至A：使用视频扩散从零样本单张图像到可动头部头像|Zhenglin Zhou, Fan Ma, Hehe Fan, Tat-Seng Chua|<http://arxiv.org/pdf/2503.15851v2>|[[代码]](<https://github.com/ZhenglinZhou/Zero-1-to-A.>)<br />- 问题：数据需求高，结果平滑，时空不一致<br />- 方法：视频扩散，时空一致性数据集，渐进式学习<br />- 效果：动画质量提升，渲染速度提高|
|📝 更新|SV4D 2.0: Enhancing Spatio-Temporal Consistency in Multi-View Video Diffusion for High-Quality 4D Generation|SV4D 2.0：提升多视图视频扩散中的时空一致性以实现高质量4D生成|Chun-Han Yao, Yiming Xie, Vikram Voleti, Huaizu Jiang, Varun Jampani|<http://arxiv.org/pdf/2503.16396v3>|- 问题：多视图视频扩散，时空一致性，高质4D生成<br />- 方法：网络架构改进，数据增强，渐进式训练，4D优化<br />- 效果：质量提升，一致性增强|


### 掩码自编码 (Masked Autoencoding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mask$^2$DiT: Dual Mask-based Diffusion Transformer for Multi-Scene Long Video Generation|Mask$^2$DiT：基于双掩码的扩散Transformer用于多场景长视频生成|Tianhao Qi, Jianlong Yuan, Wanquan Feng, Shancheng Fang, Jiawei Liu, SiYu Zhou, Qian He, Hongtao Xie .etc.|<http://arxiv.org/pdf/2503.19881v1>|[[代码]](<https://tianhao-qi.github.io/Mask2DiTProject.>)<br />- 问题：多场景视频生成，文本-视觉对齐<br />- 方法：Mask$^2$DiT，对称二进制掩码，条件掩码<br />- 效果：视觉一致性，语义对齐|
|🆕 发布|Bootstrap Your Own Views: Masked Ego-Exo Modeling for Fine-grained View-invariant Video Representations|自举您的视图：掩码自我-外部建模用于细粒度视图不变视频表示|Jungin Park, Jiyoung Lee, Kwanghoon Sohn|<http://arxiv.org/pdf/2503.19706v1>|[[代码]](<https://github.com/park-jungin/byov.>)<br />- 问题：视角不变性，视频理解，视角差异<br />- 方法：掩码建模，因果时间动态，跨视角对齐<br />- 效果：性能提升，多任务表现|


## 迁移与适应 (Transfer & Adaptation)


### 元学习 (Meta Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HyperFLINT: Hypernetwork-based Flow Estimation and Temporal Interpolation for Scientific Ensemble Visualization|超FLINT：基于超网络的流估计和科学集成可视化中的时间插值|Hamid Gadirov, Qi Wu, David Bauer, Kwan-Liu Ma, Jos Roerdink, Steffen Frey|<http://arxiv.org/pdf/2412.04095v2>|- 问题：流场估计，时间插值，参数空间探索<br />- 方法：超网络，模块化神经网络，动态适应<br />- 效果：性能提升，参数空间探索|
|🆕 发布|One Framework to Rule Them All: Unifying RL-Based and RL-Free Methods in RLHF|统一强化学习与无强化学习方法在强化学习与人类反馈（RLHF）中的框架：一统天下|Xin Cai|<http://arxiv.org/pdf/2503.19523v1>|- 问题：RLHF，LRMs，方法统一<br />- 方法：神经结构化带预测，GRO框架<br />- 效果：方法整合，实证验证|
|📝 更新|On-Device Self-Supervised Learning of Low-Latency Monocular Depth from Only Events|设备端仅从事件中自监督学习低延迟单目深度|Jesse Hagenaars, Yilun Wu, Federico Paredes-Vallés, Stein Stroobants, Guido de Croon|<http://arxiv.org/pdf/2412.06359v2>|- 问题：低延迟，单目深度估计，在线学习，计算效率<br />- 方法：对比最大化，时间内存优化，事件相机<br />- 效果：实时学习，性能提升|


### 域适应 (Domain Adaptation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Domain-incremental White Blood Cell Classification with Privacy-aware Continual Learning|基于领域增量与隐私感知的持续学习白细胞分类|Pratibha Kumari, Afshin Bozorgpour, Daniel Reisenbüchler, Edgar Jost, Martina Crysandt, Christian Matek, Dorit Merhof|<http://arxiv.org/pdf/2503.19819v1>|- 问题：WBC分类，领域偏移，遗忘，性能退化<br />- 方法：生成式重放，隐私保护，轻量级生成器<br />- 效果：遗忘缓解，性能保持|
|📝 更新|FREE-Merging: Fourier Transform for Efficient Model Merging|自由合并：高效模型合并的傅里叶变换|Shenghe Zheng, Hongzhi Wang|<http://arxiv.org/pdf/2411.16815v2>|- 问题：模型合并，性能与成本，任务干扰<br />- 方法：Fourier变换，专家模块，动态补偿<br />- 效果：平衡，多任务，灵活适应|
|🆕 发布|Burst Image Super-Resolution with Mamba|爆裂图像超分辨率：Mamba方法|Ozan Unal, Steven Marty, Dengxin Dai|<http://arxiv.org/pdf/2503.19634v1>|- 问题：BISR，分辨率提升，计算复杂度<br />- 方法：Mamba架构，空间-时间模块，信息路由<br />- 效果：SOTA性能，合成-真实数据集|
|📝 更新|Learning to segment anatomy and lesions from disparately labeled sources in brain MRI|从不同标注来源学习从脑MRI中分割解剖结构和病变|Meva Himmetoglu, Ilja Ciernik, Ender Konukoglu|<http://arxiv.org/pdf/2503.18840v2>|- 问题：脑MRI分割，解剖结构，病变，标签不匹配<br />- 方法：解耦路径，多序列，注意力机制，图像自适应，元学习，共训练<br />- 效果：性能提升，解剖结构，病变|
|🆕 发布|Wavelet-based Global-Local Interaction Network with Cross-Attention for Multi-View Diabetic Retinopathy Detection|基于小波的全局-局部交互网络结合跨注意力机制的多视角糖尿病视网膜病变检测|Yongting Hu, Yuxin Lin, Chengliang Liu, Xiaoling Luo, Xiaoyan Dou, Qihao Xu, Yong Xu|<http://arxiv.org/pdf/2503.19329v1>|[[代码]](<https://github.com/HuYongting/WGLIN.>)<br />- 问题：多视角DR检测，病变信息学习，多视角融合<br />- 方法：波分网络，全局-局部交互，跨视角融合<br />- 效果：性能提升，公开数据集验证|
|📝 更新|Hard-aware Instance Adaptive Self-training for Unsupervised Cross-domain Semantic Segmentation|硬感知实例自适应自训练的无监督跨域语义分割|Chuang Zhu, Kebin Liu, Wenqi Tang, Ke Mei, Jiaqi Zou, Tiejun Huang|<http://arxiv.org/pdf/2302.06992v2>|[[代码]](<https://github.com/bupt-ai-cz/HIAST.>)<br />- 问题：跨域语义分割，数据偏差，自训练<br />- 方法：实例自适应，伪标签生成，区域自适应正则化<br />- 效果：性能提升，泛化能力强|
|🆕 发布|Adaptive Wavelet Filters as Practical Texture Feature Amplifiers for Parkinson's Disease Screening in OCT|自适应小波滤波器作为OCT中帕金森病筛查的实用纹理特征放大器|Xiaoqing Zhang, Hanfeng Shi, Xiangyu Li, Haili Ye, Tao Xu, Na Li, Yan Hu, Fan Lv .etc.|<http://arxiv.org/pdf/2503.19292v1>|- 问题：帕金森病筛查，OCT图像，纹理特征<br />- 方法：自适应小波滤波器，频率域学习，平衡置信度损失<br />- 效果：性能提升，可信度增强|


### 增量学习 (Incremental Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Feature Calibration enhanced Parameter Synthesis for CLIP-based Class-incremental Learning|基于CLIP的类增量学习中的特征校准增强参数合成|Juncen Guo, Xiaoguang Zhu, Lianlong Sun, Liangyu Teng, Di Li, Yang Liu, Liang Song|<http://arxiv.org/pdf/2503.18672v2>|- 问题：CIL，视觉特征，VLMs，灾难性遗忘，泛化能力<br />- 方法：FCPS，参数调整，特征校准，参数合成<br />- 效果：平衡学习，泛化能力，实验验证|
|📝 更新|Pathological Prior-Guided Multiple Instance Learning For Mitigating Catastrophic Forgetting in Breast Cancer Whole Slide Image Classification|病理先验引导的多实例学习以减轻乳腺癌全切片图像分类中的灾难性遗忘|Weixi Zheng, Aoling Huang, Jingping Yuan, Haoyu Zhao, Zhou Zhao, Yongchao Xu, Thierry Géraud|<http://arxiv.org/pdf/2503.06056v2>|- 问题：灾难性遗忘，WSI分类，病理学<br />- 方法：PaGMIL框架，病理先验，多实例学习<br />- 效果：持续学习，性能平衡|


## 鲁棒学习 (Robust Learning)


### 对抗训练 (Adversarial Training)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AvatarArtist: Open-Domain 4D Avatarization|AvatarArtist：开放域4D虚拟化身|Hongyu Liu, Xuan Wang, Ziyu Wan, Yue Ma, Jingye Chen, Yanbo Fan, Yujun Shen, Yibing Song .etc.|<http://arxiv.org/pdf/2503.19906v1>|- 问题：开放域4D头像，风格任意，无监督<br />- 方法：参数三平面，GANs，扩散模型，多域数据集<br />- 效果：高质量4D头像，强鲁棒性|
|📝 更新|Inverting Transformer-based Vision Models|基于Transformer的视觉模型反演|Jan Rathjens, Shirin Reyhanian, David Kappel, Laurenz Wiskott|<http://arxiv.org/pdf/2412.06534v3>|[[代码]](<https://github.com/wiskott-lab/inverse-tvm.>)<br />- 问题：视觉模型机制理解，Transformer，图像重建<br />- 方法：模块化逆模型训练，中间层图像重建<br />- 效果：机制洞察，架构比较|
|🆕 发布|TeLL Me what you cant see|告诉我你无法看到的|Saverio Cavasin, Pietro Biasetton, Mattia Tamiazzo, Mauro Conti, Simone Milani|<http://arxiv.org/pdf/2503.19478v1>|- 问题：图像质量，识别准确性，数据稀缺<br />- 方法：数据增强，特征提取，视觉语言模型<br />- 效果：识别准确率提升，鲁棒性增强|
|📝 更新|Self-Corrected Flow Distillation for Consistent One-Step and Few-Step Text-to-Image Generation|自校正流蒸馏以实现一致的一步和少步文本到图像生成|Quan Dao, Hao Phung, Trung Dao, Dimitris Metaxas, Anh Tran|<http://arxiv.org/pdf/2412.16906v2>|[[代码]](<https://github.com/VinAIResearch/SCFlow>)<br />- 问题：Flow matching, 函数评估, 采样过程<br />- 方法：Self-corrected flow distillation, 一致性模型, 对抗训练<br />- 效果：一致生成，优越结果|


### 对抗攻击 (Adversarial Attack)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SITA: Structurally Imperceptible and Transferable Adversarial Attacks for Stylized Image Generation|SITA：用于风格化图像生成的结构不可感知且可迁移的对抗攻击|Jingdan Kang, Haoxin Yang, Yan Cai, Huaidong Zhang, Xuemiao Xu, Yong Du, Shengfeng He|<http://arxiv.org/pdf/2503.19791v1>|[[代码]](<https://github.com/A-raniy-day/SITA.>)<br />- 问题：数据滥用，风格迁移，计算成本，噪声<br />- 方法：CLIP-based destylization loss，结构破坏，噪声嵌入<br />- 效果：高可迁移性，低计算成本，视觉质量保护|
|📝 更新|NoPain: No-box Point Cloud Attack via Optimal Transport Singular Boundary|无痛：基于最优传输奇异边界的无框点云攻击|Zezeng Li, Xiaoyu Du, Na Lei, Liming Chen, Weimin Wang|<http://arxiv.org/pdf/2503.00063v3>|[[代码]](<https://github.com/cognaclee/nopain>)<br />- 问题：点云攻击，过拟合，可迁移性差<br />- 方法：最优传输，数据分布，非光滑边界<br />- 效果：高效，可迁移，防御策略有效|
|📝 更新|Improving Transferable Targeted Attacks with Feature Tuning Mixup|提升特征调优混合的迁移性目标攻击|Kaisheng Liang, Xuelong Dai, Yanjie Li, Dong Wang, Bin Xiao|<http://arxiv.org/pdf/2411.15553v2>|- 问题：可迁移攻击，特征空间，计算成本<br />- 方法：特征调整，Mixup，学习扰动<br />- 效果：攻击性能提升，低计算成本|
|🆕 发布|Stop Walking in Circles! Bailing Out Early in Projected Gradient Descent|停止在圈中徘徊！投影梯度下降中的早期退出策略|Philip Doldo, Derek Everett, Amol Khanna, Andre T Nguyen, Edward Raff|<http://arxiv.org/pdf/2503.19347v1>|- 问题：PGD计算量大，效率低<br />- 方法：基于循环检测的早期终止<br />- 效果：速度提升，攻击强度不变|


### 对抗防御 (Adversarial Defense)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Resilient Sensor Fusion under Adverse Sensor Failures via Multi-Modal Expert Fusion|基于多模态专家融合的鲁棒传感器融合在恶劣传感器故障下|Konyul Park, Yecheol Kim, Daehun Kim, Jun Won Choi|<http://arxiv.org/pdf/2503.19776v1>|- 问题：传感器融合，性能下降，模态依赖<br />- 方法：MoME，混合专家，多专家解码<br />- 效果：鲁棒性，性能提升|
|🆕 发布|RGB-Th-Bench: A Dense benchmark for Visual-Thermal Understanding of Vision Language Models|RGB-Th-Bench：视觉语言模型视觉-热理解的高密度基准|Mehdi Moshtaghi, Siavash H. Khajavi, Joni Pajarinen|<http://arxiv.org/pdf/2503.19654v1>|- 问题：VLMs RGB-Th理解能力，数据集缺乏，评估框架不足<br />- 方法：RGB-Th-Bench，多维度评估，严格指标<br />- 效果：性能差距，多模态学习需求|
|📝 更新|Understanding and Reducing the Class-Dependent Effects of Data Augmentation with A Two-Player Game Approach|理解并减少数据增强的类别依赖效应：一种双玩家游戏方法|Yunpeng Jiang, Paul Weng, Yutong Ban|<http://arxiv.org/pdf/2407.03146v3>|- 问题：数据增强，类别依赖，不公平效应<br />- 方法：CLAM，对抗游戏，乘性权重<br />- 效果：公平性提升，平均精度影响小|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dita: Scaling Diffusion Transformer for Generalist Vision-Language-Action Policy|Dita：扩展扩散Transformer以实现通用视觉-语言-动作策略|Zhi Hou, Tianyi Zhang, Yuwen Xiong, Haonan Duan, Hengjun Pu, Ronglei Tong, Chengyang Zhao, Xizhou Zhu .etc.|<http://arxiv.org/pdf/2503.19757v1>|- 问题：泛化能力，动作空间适应性，异构动作空间<br />- 方法：Transformer，统一多模态扩散过程，上下文条件<br />- 效果：跨数据集集成，长时任务执行，开源基准|
|🆕 发布|On What Depends the Robustness of Multi-source Models to Missing Data in Earth Observation?|多源模型在地球观测中面对缺失数据鲁棒性的影响因素是什么？|Francisco Mena, Diego Arenas, Miro Miranda, Andreas Dengel|<http://arxiv.org/pdf/2503.19719v1>|- 问题：多源模型，缺失数据，地球观测<br />- 方法：模型评估，任务性质，数据互补性<br />- 效果：模型性能，预测准确性|
|📝 更新|Spectral Informed Mamba for Robust Point Cloud Processing|光谱信息驱动的Mamba鲁棒点云处理|Ali Bahri, Moslem Yazdanpanah, Mehrdad Noori, Sahar Dastani, Milad Cheraghalikhani, David Osowiechi, Gustavo Adolfo Vargas Hakim, Farzad Beizaee .etc.|<http://arxiv.org/pdf/2503.04953v2>|- 问题：点云处理，鲁棒性，复杂结构<br />- 方法：Mamba，Masked Autoencoder，谱图，递归分割<br />- 效果：分类，分割，少样本学习|
|📝 更新|HeatFormer: A Neural Optimizer for Multiview Human Mesh Recovery|热前形器：一种用于多视角人体网格恢复的神经网络优化器|Yuto Matsubara, Ko Nishino|<http://arxiv.org/pdf/2412.04456v3>|- 问题：多视角人体姿态恢复，固定多视角监控<br />- 方法：神经优化，SMPL参数估计，Transformer<br />- 效果：准确性，鲁棒性，泛化性|
|🆕 发布|Adaptive Multi-Order Graph Regularized NMF with Dual Sparsity for Hyperspectral Unmixing|自适应多阶图正则化NMF与双稀疏性用于高光谱解混|Hui Chen, Liangyu Liu, Xianchao Xiu, Wanquan Liu|<http://arxiv.org/pdf/2503.19258v1>|- 问题：Hyperspectral unmixing, NMF, graph learning, parameter tuning<br />- 方法：multi-order graph regularization, adaptive learning, dual sparsity<br />- 效果：unmixing results, better robustness|
|🆕 发布|Limited-angle x-ray nano-tomography with machine-learning enabled iterative reconstruction engine|有限角度X射线纳米断层扫描与机器学习驱动的迭代重建引擎|Chonghang Zhao, Mingyuan Ge, Xiaogang Yang, Yong S. Chu, Hanfei Yan|<http://arxiv.org/pdf/2503.19248v1>|- 问题：有限角X射线断层扫描，缺失楔形，重建图像质量差<br />- 方法：感知融合迭代重建，CNN，交替方向乘子法<br />- 效果：重建质量提升，适用性广|


## 模型压缩加速 (Model Compression & Acceleration)


### 知识蒸馏 (Knowledge Distillation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|From My View to Yours: Ego-Augmented Learning in Large Vision Language Models for Understanding Exocentric Daily Living Activities|从我之视角到你的视角：大视觉语言模型中的自我增强学习以理解外心日常活动|Dominick Reilly, Manish Kumar Govind, Le Xue, Srijan Das|<http://arxiv.org/pdf/2501.05711v2>|[[代码]](<https://github.com/dominickrei/EgoExo4ADL.>)<br />- 问题：LVLMs ADL理解，细粒度交互，空间关系<br />- 方法：ego2exo知识蒸馏，SK-EGO，domain-agnostic bootstrapping<br />- 效果：egocentric理解，ADL基准评估|
|📝 更新|Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation|指令-4DGS：基于4D高斯静态-动态分离的高效动态场景编辑|Joohyun Kwon, Hanbyel Cho, Junmo Kim|<http://arxiv.org/pdf/2502.02091v2>|- 问题：动态场景编辑，效率低，时间消耗大<br />- 方法：4D高斯表示，静态-动态分离，分数蒸馏<br />- 效果：效率高，时间缩短，质量高|
|📝 更新|Text-driven 3D Human Generation via Contrastive Preference Optimization|基于对比偏好优化的文本驱动3D人体生成|Pengfei Zhou, Xukun Shen, Yong Hu|<http://arxiv.org/pdf/2502.08977v3>|- 问题：3D模型与文本对齐，SDS优化<br />- 方法：对比偏好优化，偏好优化模块，否定偏好模块<br />- 效果：纹理真实感，视觉对齐|
|📝 更新|Lightweight Embedded FPGA Deployment of Learned Image Compression with Knowledge Distillation and Hybrid Quantization|轻量级嵌入式FPGA部署：基于知识蒸馏和混合量化的学习图像压缩|Alaa Mazouz, Sumanta Chaudhuri, Marco Cagnanzzo, Mihai Mitrea, Enzo Tartaglione, Attilio Fiandrotti|<http://arxiv.org/pdf/2503.04832v5>|- 问题：LIC硬件实现，效率，平台适应性<br />- 方法：知识蒸馏，混合量化，GDN激活，FPGA配置<br />- 效果：效率高，平台适应，性能优异|
|📝 更新|Masking meets Supervision: A Strong Learning Alliance|遮蔽与监督相遇：强大的学习联盟|Byeongho Heo, Taekyung Kim, Sangdoo Yun, Dongyoon Han|<http://arxiv.org/pdf/2306.11339v3>|[[代码]](<https://github.com/naver-ai/augsub>)<br />- 问题：masking, supervised learning, 不稳定训练<br />- 方法：Masked Sub-branch, 松弛损失函数<br />- 效果：性能提升，训练稳定|
|📝 更新|Every SAM Drop Counts: Embracing Semantic Priors for Multi-Modality Image Fusion and Beyond|每个SAM都至关重要：拥抱语义先验的多模态图像融合及其应用|Guanyao Wu, Haoyu Liu, Hongming Fu, Yichuan Peng, Jinyuan Liu, Xin Fan, Risheng Liu|<http://arxiv.org/pdf/2503.01210v2>|[[代码]](<https://github.com/RollingPlain/SAGE_IVIF.>)<br />- 问题：多模态融合，细节保留，任务适应性<br />- 方法：SAM语义先验，SPA模块，知识蒸馏<br />- 效果：质量提升，效率高|
|🆕 发布|M$^2$CD: A Unified MultiModal Framework for Optical-SAR Change Detection with Mixture of Experts and Self-Distillation|M$^2$CD：基于专家混合与自蒸馏的统一多模态光学SAR变化检测框架|Ziyuan Liu, Jiawei Zhang, Wenyu Wang, Yuantao Gu|<http://arxiv.org/pdf/2503.19406v1>|- 问题：跨模态学习，SAR图像，CD方法，Siamese网络<br />- 方法：MoE模块，O2SP路径，自蒸馏，CNN，Transformer<br />- 效果：SOTA，光学-SAR CD|
|📝 更新|CKD: Contrastive Knowledge Distillation from A Sample-wise Perspective|对比知识蒸馏：从样本视角的蒸馏方法|Wencheng Zhu, Xin Zhou, Pengfei Zhu, Yu Wang, Qinghua Hu|<http://arxiv.org/pdf/2404.14109v2>|- 问题：过拟合，语义关系，计算复杂度<br />- 方法：样本级对比，内样本对齐，InfoNCE损失<br />- 效果：样本对齐，语义一致性|
|🆕 发布|Multi-Object Sketch Animation by Scene Decomposition and Motion Planning|多对象场景分解与运动规划下的草图动画|Jingyu Liu, Zijie Xin, Yuhan Fu, Ruixiang Zhao, Bangxiang Lan, Xirong Li|<http://arxiv.org/pdf/2503.19351v1>|- 问题：多对象动画，单对象动画，运动建模，优化<br />- 方法：MoSketch，迭代优化，场景分解，运动规划<br />- 效果：性能优越，新途径|
|📝 更新|Identity-preserving Distillation Sampling by Fixed-Point Iterator|基于不动点迭代器的身份保持蒸馏采样|SeonHwa Kim, Jiwon Kim, Soobin Park, Donghoon Ahn, Jiwon Kang, Seungryong Kim, Kyong Hwan Jin, Eunju Cha|<http://arxiv.org/pdf/2502.19930v2>|- 问题：SDS模糊，梯度噪声，图像编辑退化<br />- 方法：IDS，FPR，固定点迭代正则化<br />- 效果：清晰，结构一致性|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TokenHSI: Unified Synthesis of Physical Human-Scene Interactions through Task Tokenization|TokenHSI：通过任务标记化统一合成物理人-场景交互|Liang Pan, Zeshi Yang, Zhiyang Dou, Wenjia Wang, Buzhen Huang, Bo Dai, Taku Komura, Jingbo Wang|<http://arxiv.org/pdf/2503.19901v1>|[[代码]](<https://liangpan99.github.io/TokenHSI>)<br />- 问题：HSI合成，多技能整合，适应性<br />- 方法：TokenHSI，任务标记，共享token<br />- 效果：多任务训练，灵活适应，技能协调|
|📝 更新|Empowering LLMs to Understand and Generate Complex Vector Graphics|赋能大型语言模型理解和生成复杂矢量图形|Ximing Xing, Juncheng Hu, Guotao Liang, Jing Zhang, Dong Xu, Qian Yu|<http://arxiv.org/pdf/2412.11102v3>|- 问题：LLM SVG理解，生成，渲染问题<br />- 方法：LLM4SVG，语义标记，数据生成<br />- 效果：语义对齐，数据丰富|
|🆕 发布|$L^2$FMamba: Lightweight Light Field Image Super-Resolution with State Space Model|$L^2$FMamba：基于状态空间模型的轻量级光场图像超分辨率|Zeqiang Wei, Kai Jin, Zeyi Hou, Kuan Song, Xiuzhuang Zhou|<http://arxiv.org/pdf/2503.19253v1>|- 问题：Transformer，计算复杂度，超分辨率<br />- 方法：LF-VSSM模块，轻量级网络，L^2FMamba<br />- 效果：参数减少，性能提升，速度加快|


### 量化优化 (Quantization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GENIUS: A Generative Framework for Universal Multimodal Search|通用多模态搜索的生成框架：GENIUS|Sungyeon Kim, Xinliang Zhu, Xiaofan Lin, Muhammet Bastan, Douglas Gray, Suha Kwak|<http://arxiv.org/pdf/2503.19868v1>|- 问题：任务特定，性能不足，传统方法<br />- 方法：模态解耦，语义量化，查询增强<br />- 效果：超越前人，高效检索|
|📝 更新|Hardware-Friendly Static Quantization Method for Video Diffusion Transformers|硬件友好的视频扩散Transformer静态量化方法|Sanghyun Yi, Qingfeng Liu, Mostafa El-Khamy|<http://arxiv.org/pdf/2502.15077v2>|- 问题：动态量化，资源受限，视频扩散Transformer<br />- 方法：静态量化，逐步校准，通道量化，张量量化<br />- 效果：视频质量，FP16，ViDiT-Q|


## 泛化与鲁棒性 (Generalization & Robustness)


### 域泛化 (Domain Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Improved tissue sodium concentration quantification in breast cancer by reducing partial volume effects: a preliminary study|通过减少部分体积效应提高乳腺癌组织钠浓度定量：一项初步研究|Olgica Zaric, Carmen Leser, Vladimir Juras, Alex Farr, Malina Gologan, Stanislas Rapacchi, Laura Villazan Garcia, Christian Singer .etc.|<http://arxiv.org/pdf/2503.19570v1>|- 问题：PVE, TSC量化误差<br />- 方法：压缩感知，wTV, dTV, AG-TV, ADC<br />- 效果：TSC准确度提升，图像质量改善|
|🆕 发布|COB-GS: Clear Object Boundaries in 3DGS Segmentation Based on Boundary-Adaptive Gaussian Splitting|COB-GS：基于边界自适应高斯分割的3DGS分割中清晰物体边界|Jiaxin Zhang, Junjun Jiang, Youyu Chen, Kui Jiang, Xianming Liu|<http://arxiv.org/pdf/2503.19443v1>|[[代码]](<https://github.com/ZestfulJX/COB-GS.>)<br />- 问题：3DGS分割，边界模糊，语义指导缺失<br />- 方法：边界自适应高斯分割，语义梯度统计，视觉优化<br />- 效果：精度提升，边界清晰，视觉质量高|
|📝 更新|Superpixel Tokenization for Vision Transformers: Preserving Semantic Integrity in Visual Tokens|视觉Transformer中的超像素标记化：在视觉标记中保持语义完整性|Jaihyun Lew, Soohyuk Jang, Jaehoon Lee, Seungryong Yoo, Eunji Kim, Saehyung Lee, Jisoo Mok, Siwon Kim .etc.|<http://arxiv.org/pdf/2412.04680v3>|- 问题：ViT tokenization，语义混合，视觉概念<br />- 方法：superpixel tokenization，pre-aggregate extraction，superpixel-aware aggregation<br />- 效果：准确性提升，鲁棒性增强|


### 分布鲁棒性 (Distribution Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Towards Unbiased and Robust Spatio-Temporal Scene Graph Generation and Anticipation|朝向无偏和鲁棒的时空场景图生成与预测|Rohith Peddi, Saurabh, Ayush Abhay Shrivastava, Parag Singla, Vibhav Gogate|<http://arxiv.org/pdf/2411.13059v2>|- 问题：STSG生成，场景图偏见，长尾分布<br />- 方法：ImparTail，损失掩码，课程学习<br />- 效果：无偏，鲁棒|


## 可解释性 (Interpretability)


### 归因分析 (Attribution Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Attention IoU: Examining Biases in CelebA using Attention Maps|注意力IoU：使用注意力图检验CelebA中的偏差|Aaron Serianni, Tyler Zhu, Vikram V. Ramaswamy, Olga Russakovsky|<http://arxiv.org/pdf/2503.19846v1>|- 问题：模型偏差，内部工作，特征识别<br />- 方法：Attention-IoU，注意力图，内部表示<br />- 效果：揭示偏差，识别特征，发现变量|
|📝 更新|Shot Sequence Ordering for Video Editing: Benchmarks, Metrics, and Cinematology-Inspired Computing Methods|视频剪辑中的镜头序列排序：基准、指标和电影学启发计算方法|Yuzhi Li, Haojun Xu, Feng Tian|<http://arxiv.org/pdf/2503.17975v2>|[[代码]](<https://github.com/litchiar/ShotSeqBench.>)<br />- 问题：视频编辑，AI辅助，镜头排序<br />- 方法：基准数据集，Kendall Tau距离，Cinematology Embedding<br />- 效果：准确度提升，公开数据集|
|📝 更新|Explaining Deep Convolutional Neural Networks for Image Classification by Evolving Local Interpretable Model-agnostic Explanations|通过进化局部可解释模型无关解释来解释用于图像分类的深度卷积神经网络|Bin Wang, Wenbin Pei, Bing Xue, Mengjie Zhang|<http://arxiv.org/pdf/2211.15143v2>|- 问题：可解释性，深度学习，图像分类<br />- 方法：遗传算法，模型无关，进化解释<br />- 效果：快速解释，提高置信度|


## 医学影像分析 (Medical Image Analysis)


### 医学分割 (Medical Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unpaired Translation of Chest X-ray Images for Lung Opacity Diagnosis via Adaptive Activation Masks and Cross-Domain Alignment|胸部X光片的无监督翻译用于肺不透明度诊断：自适应激活掩码与跨域对齐|Junzhi Ning, Dominic Marshall, Yijian Gao, Xiaodan Xing Yang Nan, Yingying Fang, Sheng Zhang, Matthieu Komorowski, Guang Yang|<http://arxiv.org/pdf/2503.19860v1>|- 问题：肺透明度，诊断困难，分割精度低<br />- 方法：自适应激活掩码，跨域对齐，无监督翻译<br />- 效果：FID降低，KID降低，分割精度提升|
|🆕 发布|LPOSS: Label Propagation Over Patches and Pixels for Open-vocabulary Semantic Segmentation|LPOSS：基于块和像素的开放词汇语义分割的标签传播|Vladan Stojnić, Yannis Kalantidis, Jiří Matas, Giorgos Tolias|<http://arxiv.org/pdf/2503.19777v1>|[[代码]](<https://github.com/vladan-stojnic/LPOSS>)<br />- 问题：开放词汇语义分割，无监督，分辨率限制<br />- 方法：标签传播，像素级优化，全局推理<br />- 效果：精度提升，性能领先|
|🆕 发布|BiPrompt-SAM: Enhancing Image Segmentation via Explicit Selection between Point and Text Prompts|BiPrompt-SAM：通过显式选择点和文本提示增强图像分割|Suzhe Xu, Jialin Peng, Chengyuan Zhang|<http://arxiv.org/pdf/2503.19769v1>|- 问题：图像分割，点文本提示，融合<br />- 方法：BiPrompt-SAM，显式选择，MoE<br />- 效果：mDice提升，IoU提升|
|🆕 发布|OpenLex3D: A New Evaluation Benchmark for Open-Vocabulary 3D Scene Representations|OpenLex3D：开放词汇3D场景表示的新评估基准|Christina Kassab, Sacha Morin, Martin Büchner, Matías Mattamala, Kumaraditya Gupta, Abhinav Valada, Liam Paull, Maurice Fallon|<http://arxiv.org/pdf/2503.19764v1>|[[代码]](<https://openlex3d.github.io/.>)<br />- 问题：3D场景理解，开放词汇，语义评估<br />- 方法：OpenLex3D，语义分割，对象检索<br />- 效果：新标注，性能评估，改进方向|
|🆕 发布|InterSliceBoost: Identifying Tissue Layers in Three-dimensional Ultrasound Images for Chronic Lower Back Pain (cLBP) Assessment|InterSliceBoost：用于慢性下背痛（cLBP）评估的三维超声图像中识别组织层的方法|Zixue Zeng, Matthew Cartier, Xiaoyan Zhao, Pengyu Chen, Xin Meng, Zhiyu Sheng, Maryam Satarpour, John M Cormack .etc.|<http://arxiv.org/pdf/2503.19735v1>|- 问题：cLBP评估，组织层分析，3D超声图像，手动标注<br />- 方法：InterSliceBoost，特征提取，部分标注数据集<br />- 效果：Dice系数高，性能显著|
|🆕 发布|CamSAM2: Segment Anything Accurately in Camouflaged Videos|CamSAM2：在伪装视频中准确分割任何事物|Yuli Zhou, Guolei Sun, Yawei Li, Yuqian Fu, Luca Benini, Ender Konukoglu|<http://arxiv.org/pdf/2503.19730v1>|[[代码]](<https://github.com/zhoustan/CamSAM2>)<br />- 问题：VCOS，camouflaged videos，segmentation<br />- 方法：CamSAM2，decamouflaged token，IOF，EOF，OPG<br />- 效果：mDice gains，MoCA-Mask，SUN-SEG-Hard|
|🆕 发布|Optimization of MedSAM model based on bounding box adaptive perturbation algorithm|基于边界框自适应扰动算法的MedSAM模型优化|Boyi Li, Ye Yuan, Wenjun Tan|<http://arxiv.org/pdf/2503.19700v1>|- 问题：MedSAM模型，分割错误，边界框限制<br />- 方法：自适应扰动算法，优化训练过程<br />- 效果：减少错误，提高精度|
|📝 更新|Helvipad: A Real-World Dataset for Omnidirectional Stereo Depth Estimation|赫尔维帕德：全向立体深度估计的真实世界数据集|Mehdi Zayene, Jannik Endres, Albias Havolli, Charles Corbière, Salim Cherkaoui, Alexandre Kontouli, Alexandre Alahi|<http://arxiv.org/pdf/2411.18335v2>|- 问题：Omnidirectional stereo depth estimation, data lack<br />- 方法：Real-world dataset, 360° cameras, LiDAR, depth completion<br />- 效果：Benchmark, improved performance|
|🆕 发布|Show or Tell? Effectively prompting Vision-Language Models for semantic segmentation|展示还是讲述？有效提示视觉-语言模型进行语义分割|Niccolo Avogaro, Thomas Frick, Mattia Rigotti, Andrea Bartezzaghi, Filip Janicki, Cristiano Malossi, Konrad Schindler, Roy Assaf|<http://arxiv.org/pdf/2503.19647v1>|- 问题：VLMs语义分割，prompting，性能提升<br />- 方法：prompting方案，few-shot learning，PromptMatcher<br />- 效果：性能提升，超越现有模型|
|📝 更新|PG-SAM: Prior-Guided SAM with Medical for Multi-organ Segmentation|标题翻译结果：  PG-SAM：基于医学先验的SAM多器官分割|Yiheng Zhong, Zihong Luo, Chengzhi Liu, Feilong Tang, Zelin Peng, Ming Hu, Yingzhen Hu, Jionglong Su .etc.|<http://arxiv.org/pdf/2503.18227v2>|[[代码]](<https://github.com/logan-0623/PG-SAM.>)<br />- 问题：SAM精度低，模态融合，语义噪声<br />- 方法：细粒度模态对齐，医学LLM，多级特征融合<br />- 效果：性能提升，最佳表现|
|📝 更新|RobustEMD: Domain Robust Matching for Cross-domain Few-shot Medical Image Segmentation|鲁棒EMD：跨域小样本医学图像分割的领域鲁棒匹配|Yazhou Zhu, Minxian Li, Qiaolin Ye, Shidong Wang, Tong Xin, Haofeng Zhang|<http://arxiv.org/pdf/2410.01110v4>|- 问题：跨域，少样本，医学图像分割<br />- 方法：EMD匹配，纹理结构权重，点集距离度量<br />- 效果：SoTA性能，泛化能力强|
|📝 更新|Patch-Depth Fusion: Dichotomous Image Segmentation via Fine-Grained Patch Strategy and Depth Integrity-Prior|补丁-深度融合：通过细粒度补丁策略和深度完整性先验的二分图像分割|Xianjie Liu, Keren Fu, Qijun Zhao|<http://arxiv.org/pdf/2503.06100v2>|[[代码]](<https://github.com/Tennine2077/PDFNet>)<br />- 问题：图像分割，细节建模，深度完整性<br />- 方法：Patch-Depth融合，多模态输入，深度完整性损失<br />- 效果：精度高，参数少|
|🆕 发布|SACB-Net: Spatial-awareness Convolutions for Medical Image Registration|空间感知卷积在医学图像配准中的应用|Xinxing Cheng, Tianyang Zhang, Wenqi Lu, Qingjie Meng, Alejandro F. Frangi, Jinming Duan|<http://arxiv.org/pdf/2503.19592v1>|[[代码]](<https://github.com/x-xc/SACB_Net>)<br />- 问题：空间信息捕获不足，变形场估计欠佳<br />- 方法：SACB，自适应卷积核，多尺度流估计<br />- 效果：性能优越，效果显著|
|📝 更新|Promoting Segment Anything Model towards Highly Accurate Dichotomous Image Segmentation|推动Segment Anything模型实现高度精确的二值图像分割|Xianjie Liu, Keren Fu, Yao Jiang, Qijun Zhao|<http://arxiv.org/pdf/2401.00248v4>|[[代码]](<https://github.com/Tennine2077/DIS-SAM>)<br />- 问题：SAM分割精度低，边界模糊<br />- 方法：DIS-SAM框架，两阶段方法，修改网络<br />- 效果：F-measure提升，细节准确|
|🆕 发布|Prompt-Guided Dual-Path UNet with Mamba for Medical Image Segmentation|基于Mamba的提示引导双路径UNet在医学图像分割中的应用|Shaolei Zhang, Jinyan Liu, Tianyi Qian, Xuesong Li|<http://arxiv.org/pdf/2503.19589v1>|- 问题：CNN局限性，Transformer计算复杂，局部细节忽视<br />- 方法：Prompt-Guided Mamba模块，局部-全局信息融合，多尺度信息提取<br />- 效果：性能优于现有方法，全局信息捕获|
|🆕 发布|Tiling artifacts and trade-offs of feature normalization in the segmentation of large biological images|大生物图像分割中特征归一化的拼接伪影及其权衡|Elena Buglakova, Anwai Archit, Edoardo D'Imprima, Julia Mahamid, Constantin Pape, Anna Kreshuk|<http://arxiv.org/pdf/2503.19545v1>|- 问题：大图像分割，拼接误差，特征归一化<br />- 方法：BatchRenorm，检测指标，数据集分析<br />- 效果：消除拼接，提升迁移性能|
|📝 更新|RelationField: Relate Anything in Radiance Fields|关系域：关联辐射场中的任何事物|Sebastian Koch, Johanna Wald, Mirco Colosi, Narunas Vaskevicius, Pedro Hermosilla, Federico Tombari, Timo Ropinski|<http://arxiv.org/pdf/2412.13652v2>|- 问题：对象关系理解，场景图生成<br />- 方法：RelationField，射线路径表示，知识蒸馏<br />- 效果：SOTA性能，多模态LLM|
|🆕 发布|ASP-VMUNet: Atrous Shifted Parallel Vision Mamba U-Net for Skin Lesion Segmentation|ASP-VMUNet：用于皮肤病变分割的孔径可调并行视觉Mamba U-Net|Muyi Bao, Shuchang Lyu, Zhaoyang Xu, Qi Zhao, Changyu Zeng, Wenpei Bai, Guangliang Cheng|<http://arxiv.org/pdf/2503.19427v1>|[[代码]](<https://github.com/BaoBao0926/ASP-VMUNet>)<br />- 问题：皮肤病变分割，CNN局限性，Transformer计算负担<br />- 方法：Mamba架构，空洞扫描，并行视觉Mamba层<br />- 效果：性能提升，医学图像分割|
|🆕 发布|A Prototype-Guided Coarse Annotations Refining Approach for Whole Slide Images|基于原型引导的整张切片图像粗略标注细化方法|Bingjian Yao, Weiping Lin, Yan He, Zheng Wang, Liangsheng Wang|<http://arxiv.org/pdf/2503.19407v1>|- 问题：粗标注，语义模式，精度限制<br />- 方法：原型引导，局部-全局建模，伪标签模块<br />- 效果：性能提升，SOTA超越|
|📝 更新|MatAnyone: Stable Video Matting with Consistent Memory Propagation|MatAnyone：具有一致记忆传播的稳定视频抠图|Peiqing Yang, Shangchen Zhou, Jixin Zhao, Qingyi Tao, Chen Change Loy|<http://arxiv.org/pdf/2501.14677v2>|- 问题：视频抠图，背景复杂，语义不稳定<br />- 方法：记忆传播，区域自适应融合，大规模数据集<br />- 效果：鲁棒性，准确性|
|📝 更新|Accuracy Improvement of Cell Image Segmentation Using Feedback Former|细胞图像分割中反馈前馈器提高准确率|Hinako Mitsuoka, Kazuhiro Hotta|<http://arxiv.org/pdf/2408.12974v2>|- 问题：细胞图像分割，Transformer，细节信息缺失<br />- 方法：Feedback Former，反馈处理，Transformer编码器<br />- 效果：精度提升，计算成本低|
|🆕 发布|Show and Segment: Universal Medical Image Segmentation via In-Context Learning|展示与分割：基于上下文学习的通用医学图像分割|Yunhe Gao, Di Liu, Zhuowei Li, Yunsheng Li, Dongdong Chen, Mu Zhou, Dimitris N. Metaxas|<http://arxiv.org/pdf/2503.19359v1>|- 问题：医学图像分割，泛化能力差，任务特定<br />- 方法：In-context学习，轻量级编码模块，上下文引导<br />- 效果：泛化性强，自动发现解剖关系|
|🆕 发布|BIMII-Net: Brain-Inspired Multi-Iterative Interactive Network for RGB-T Road Scene Semantic Segmentation|脑启发的多迭代交互网络用于RGB-T道路场景语义分割：BIMII-Net|Hanshuo Qiu, Jie Jiang, Ruoli Yang, Lixin Zhan, Jizhao Liu|<http://arxiv.org/pdf/2503.19303v1>|- 问题：RGB-T语义分割，信息融合，层次差异<br />- 方法：DCCNN，CEAEF-Module，多模块迭代<br />- 效果：SOTA性能，泛化能力强|
|🆕 发布|A Comprehensive Analysis of Mamba for 3D Volumetric Medical Image Segmentation|对Mamba在3D体素医学图像分割中的全面分析|Chaohan Wang, Yutong Xie, Qi Chen, Yuyin Zhou, Qi Wu|<http://arxiv.org/pdf/2503.19308v1>|- 问题：Mamba，3D图像分割，Transformer，多尺度，复杂扫描<br />- 方法：UlikeMamba，3D深度卷积，多尺度Mamba块，Tri-scan<br />- 效果：超越nnUNet，CoTr，U-Mamba，精度提升|
|🆕 发布|Multiscale Feature Importance-based Bit Allocation for End-to-End Feature Coding for Machines|基于多尺度特征重要性的一端到端特征编码比特分配|Junle Liu, Yun Zhang, Zixi Guo|<http://arxiv.org/pdf/2503.19278v1>|- 问题：特征编码，远程智能分析，机器视觉<br />- 方法：多尺度特征重要性，比特分配，任务损失率模型<br />- 效果：比特率节省，性能提升|
|📝 更新|Multi-Disease-Aware Training Strategy for Cardiac MR Image Segmentation|多疾病感知训练策略用于心脏磁共振图像分割|Hong Zheng, Yucheng Chen, Nan Mu, Xiaoning Li|<http://arxiv.org/pdf/2503.17896v2>|- 问题：心脏MR图像分割，形状不规则，泛化能力差<br />- 方法：多疾病感知训练策略，数据预处理，多疾病数据集<br />- 效果：分割性能提升，鲁棒性增强|
|🆕 发布|Context-Aware Semantic Segmentation: Enhancing Pixel-Level Understanding with Large Language Models for Advanced Vision Applications|情境感知语义分割：利用大型语言模型增强像素级理解以推动高级视觉应用|Ben Rahman|<http://arxiv.org/pdf/2503.19276v1>|- 问题：语义分割，上下文理解，对象关系<br />- 方法：LLMs，Swin Transformer，GPT-4，交叉注意力，图神经网络<br />- 效果：mIoU提升，mAP提升|


### 疾病诊断 (Disease Diagnosis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Pfungst and Clever Hans: Identifying the unintended cues in a widely used Alzheimer's disease MRI dataset using explainable deep learning|《普芬施和聪明的汉斯：利用可解释深度学习识别广泛使用的阿尔茨海默病MRI数据集中未预期的提示》|Christian Tinauer, Maximilian Sackl, Rudolf Stollberger, Stefan Ropele, Christian Langkammer|<http://arxiv.org/pdf/2501.15831v2>|- 问题：AD MRI分类，黑盒模型，特征贡献<br />- 方法：T1w MRI数据，预处理，深度学习，特征分析<br />- 效果：体积特征重要，纹理影响小|


### 影像重建 (Image Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Noisier2Inverse: Self-Supervised Learning for Image Reconstruction with Correlated Noise|噪声2逆：相关噪声图像重建的自监督学习|Nadja Gruber, Johannes Schwab, Markus Haltmeier, Ander Biguri, Clemens Dlaska, Gyeongha Hwang|<http://arxiv.org/pdf/2503.19468v1>|- 问题：逆问题，相关噪声，无监督学习<br />- 方法：Noisier2Inverse，测量空间损失函数，无外推步骤<br />- 效果：性能优于，自监督|
|🆕 发布|Exploring Textual Semantics Diversity for Image Transmission in Semantic Communication Systems using Visual Language Model|探索语义通信系统中基于视觉语言模型的图像传输文本语义多样性|Peishan Huang, Dong Li|<http://arxiv.org/pdf/2503.19386v1>|- 问题：语义特征不足，重建精度低<br />- 方法：多文本传输，VLM辅助，LLaVA提取<br />- 效果：重建精度提升|


## 智能驾驶 (Intelligent Driving)


### 环境感知 (Environment Perception)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EventFly: Event Camera Perception from Ground to the Sky|事件飞：从地面到天空的事件相机感知|Lingdong Kong, Dongyue Lu, Xiang Xu, Lai Xing Ng, Wei Tsang Ooi, Benoit R. Cottereau|<http://arxiv.org/pdf/2503.19916v1>|- 问题：跨平台适应，事件相机感知，运动动态，视角，类别分布<br />- 方法：事件激活优先，EventBlend，EventMatch，EXPo基准<br />- 效果：性能提升，领域自适应|
|📝 更新|UrbanCAD: Towards Highly Controllable and Photorealistic 3D Vehicles for Urban Scene Simulation|城市CAD：迈向高度可控和逼真的城市场景3D车辆模拟|Yichong Lu, Yichi Cai, Shangzhan Zhang, Hongyu Zhou, Haoji Hu, Huimin Yu, Andreas Geiger, Yiyi Liao|<http://arxiv.org/pdf/2411.19292v2>|- 问题：3D车辆模型，控制性，真实感<br />- 方法：UrbanCAD框架，检索-优化流程，背景插入<br />- 效果：高真实感，感知模型准确|
|🆕 发布|High-Quality Spatial Reconstruction and Orthoimage Generation Using Efficient 2D Gaussian Splatting|高效二维高斯分层技术实现高质量空间重建和正射影像生成|Qian Wang, Zhihao Zhan, Jialei He, Zhituo Tu, Xiang Zhu, Jie Yuan|<http://arxiv.org/pdf/2503.19703v1>|- 问题：TDOM生成，计算成本高，精度要求高<br />- 方法：2D Gaussian Splatting，深度图生成，分治策略<br />- 效果：高精度，低资源成本，效率高|
|📝 更新|VideoRefer Suite: Advancing Spatial-Temporal Object Understanding with Video LLM|视频参考套件：利用视频大型语言模型推进时空物体理解|Yuqian Yuan, Hang Zhang, Wentong Li, Zesen Cheng, Boqiang Zhang, Long Li, Xin Li, Deli Zhao .etc.|<http://arxiv.org/pdf/2501.00599v3>|- 问题：视频理解，时空细节，数据缺乏，基准不足<br />- 方法：VideoRefer Suite，多代理数据引擎，时空对象编码器<br />- 效果：性能提升，泛化能力增强|
|🆕 发布|TraF-Align: Trajectory-aware Feature Alignment for Asynchronous Multi-agent Perception|轨迹感知特征对齐：异步多智能体感知中的轨迹感知特征对齐|Zhiying Song, Lei Yang, Fuxi Wen, Jun Li|<http://arxiv.org/pdf/2503.19391v1>|- 问题：异步多智能体感知，特征对齐，时空延迟<br />- 方法：轨迹感知特征对齐，预测特征轨迹，时空采样<br />- 效果：特征融合，语义一致性，感知性能提升|


### 决策规划 (Decision Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ORION: A Holistic End-to-End Autonomous Driving Framework by Vision-Language Instructed Action Generation|ORION：基于视觉-语言指令生成动作的全面端到端自动驾驶框架|Haoyu Fu, Diankun Zhang, Zongchuang Zhao, Jianfeng Cui, Dingkang Liang, Chong Zhang, Dingyuan Zhang, Hongwei Xie .etc.|<http://arxiv.org/pdf/2503.19755v1>|- 问题：E2E自动驾驶，因果推理，VLMs性能，语义-数值差距<br />- 方法：QT-Former，LLM，生成规划器，统一优化<br />- 效果：高封闭环性能，超越SOTA|
|📝 更新|RoboBrain: A Unified Brain Model for Robotic Manipulation from Abstract to Concrete|机器人脑：从抽象到具体的机器人操作统一脑模型|Yuheng Ji, Huajie Tan, Jiayu Shi, Xiaoshuai Hao, Yuan Zhang, Hengyuan Zhang, Pengwei Wang, Mengdi Zhao .etc.|<http://arxiv.org/pdf/2502.21257v2>|- 问题：MLLMs局限性，机器人操作能力<br />- 方法：ShareRobot数据集，RoboBrain模型，多阶段训练<br />- 效果：先进性能，机器人操作能力提升|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MARS: Memory-Enhanced Agents with Reflective Self-improvement|MARS：具有反思自我改进功能的内存增强智能体|Xuechen Liang, Meiling Tao, Yinghui Xia, Jianhui Wang, Kun Li, Yijin Wang, Jingsong Yang, Tianyu Shi .etc.|<http://arxiv.org/pdf/2503.19271v1>|- 问题：LLMs，决策，记忆，动态环境，挑战<br />- 方法：MARS框架，迭代反馈，反思机制，Ebbinghaus遗忘曲线<br />- 效果：多任务处理，长跨度信息|


## 工业视觉 (Industrial Vision)


### 质量控制 (Quality Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LENVIZ: A High-Resolution Low-Exposure Night Vision Benchmark Dataset|LENVIZ：高分辨率低曝光夜景视觉基准数据集|Manjushree Aithal, Rosaura G. VidalMata, Manikandtan Kartha, Gong Chen, Eashan Adhikarla, Lucas N. Kirsten, Zhicheng Fu, Nikhil A. Madhusudhana .etc.|<http://arxiv.org/pdf/2503.19804v1>|- 问题：低光照图像增强，挑战，数据集<br />- 方法：LENVIZ数据集，多曝光，真实场景<br />- 效果：高分辨率，高质量，基准|


## 其他 (Others)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Scale generalisation properties of extended scale-covariant and scale-invariant Gaussian derivative networks on image datasets with spatial scaling variations|扩展尺度协变和尺度不变高斯导数网络在具有空间尺度变化的图像数据集上的尺度泛化特性|Andrzej Perzanowski, Tony Lindeberg|<http://arxiv.org/pdf/2409.11140v2>|- 问题：尺度泛化，GaussDerNets，尺度不变性<br />- 方法：空间缩放，平均池化，尺度通道dropout<br />- 效果：尺度泛化提升，性能改善|
|📝 更新|RoboMatrix: A Skill-centric Hierarchical Framework for Scalable Robot Task Planning and Execution in Open-World|机器人矩阵：一个以技能为中心的分层框架，用于开放世界中的可扩展机器人任务规划和执行|Weixin Mao, Weiheng Zhong, Zhou Jiang, Dong Fang, Zhongyue Zhang, Zihan Lan, Haosheng Li, Fan Jia .etc.|<http://arxiv.org/pdf/2412.00171v3>|[[代码]](<https://github.com/WayneMao/RoboMatrix.>)<br />- 问题：任务数据收集，泛化能力，错误定位，开放世界<br />- 方法：技能中心，分层架构，VLA模型<br />- 效果：成功率提升，开放世界应用|
|📝 更新|PRIMEdit: Probability Redistribution for Instance-aware Multi-object Video Editing with Benchmark Dataset|PRIMEdit：基于概率重分配的实例感知多目标视频编辑及基准数据集|Samuel Teodoro, Agus Gunawan, Soo Ye Kim, Jihyong Oh, Munchurl Kim|<http://arxiv.org/pdf/2412.12877v2>|- 问题：多对象视频编辑，编辑泄漏，缺乏评估<br />- 方法：概率重分配，实例感知，多实例采样<br />- 效果：编辑忠实，准确，泄漏预防|

