## [UPDATED!] **2025-03-26** (Update Time)


## 表示学习 (Representation Learning)


### 预训练模型 (Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Feature4X: Bridging Any Monocular Video to 4D Agentic AI with Versatile Gaussian Feature Fields|特征4X：通过多用途高斯特征场将任何单目视频连接到4D代理人工智能|Shijie Zhou, Hui Ren, Yijia Weng, Shuwang Zhang, Zhen Wang, Dejia Xu, Zhiwen Fan, Suya You .etc.|<http://arxiv.org/pdf/2503.20776v1>|- 问题：2D到4D扩展，数据稀缺，语义操作挑战<br />- 方法：Feature4X框架，4D特征场蒸馏，动态优化策略<br />- 效果：多任务，沉浸式交互，可扩展系统|
|🆕 发布|UniSTD: Towards Unified Spatio-Temporal Learning across Diverse Disciplines|统一时空学习：跨越不同学科的通用方法|Chen Tang, Xinzhu Ma, Encheng Su, Xiufeng Song, Xiaohong Liu, Wei-Hong Li, Lei Bai, Wanli Ouyang .etc.|<http://arxiv.org/pdf/2503.20748v1>|[[代码]](<https://github.com/1hunters/UniSTD.>)<br />- 问题：任务特定架构，泛化性差，可扩展性低<br />- 方法：统一Transformer框架，两阶段预训练，混合专家适应<br />- 效果：跨任务学习，多任务支持，降低训练成本|
|📝 更新|MozzaVID: Mozzarella Volumetric Image Dataset|莫扎拉体积图像数据集|Pawel Tomasz Pieta, Peter Winkel Rasmussen, Anders Bjorholm Dahl, Jeppe Revall Frisvad, Siavash Arjomand Bigdeli, Carsten Gundlach, Anders Nymark Christensen|<http://arxiv.org/pdf/2412.04880v2>|- 问题：数据集短缺，模型可比性低，结构分析困难<br />- 方法：MozzaVID数据集，多分辨率，食品结构研究<br />- 效果：结构分析，模型优化|
|📝 更新|Parameter-Efficient Fine-Tuning for Pre-Trained Vision Models: A Survey|参数高效的预训练视觉模型微调：综述|Yi Xin, Jianjiang Yang, Siqi Luo, Haodi Zhou, Junlong Du, Xiaohong Liu, Yue Fan, Qing Li .etc.|<http://arxiv.org/pdf/2402.02242v4>|[[代码]](<https://github.com/synbol/Awesome-Parameter-Efficient-Transfer-Learning.>)<br />- 问题：参数效率，预训练模型，全微调，计算存储需求<br />- 方法：参数高效微调，分类方法，资源集合<br />- 效果：性能超越，最小参数修改|


### 基础模型 (Foundation Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Towards Scalable Foundation Model for Multi-modal and Hyperspectral Geospatial Data|面向多模态和高光谱地理空间数据的可扩展基础模型|Haozhe Si, Yuxuan Wan, Minh Do, Deepak Vasisht, Han Zhao, Hendrik F. Hamann|<http://arxiv.org/pdf/2503.12843v3>|- 问题：可扩展性，计算效率，模型灵活性<br />- 方法：LESS注意力块，连续位置通道嵌入层，感知场掩码<br />- 效果：性能竞争，泛化能力强|
|📝 更新|Perception of Visual Content: Differences Between Humans and Foundation Models|视觉内容感知：人类与基础模型之间的差异|Nardiena A. Pratama, Shaoyang Fan, Gianluca Demartini|<http://arxiv.org/pdf/2411.18968v2>|- 问题：人类与基础模型感知差异，内容解释偏差<br />- 方法：比较人类与ML标注，语义评估，区域分类<br />- 效果：ML标注相似性高，ML模型性能佳|


### 视觉Transformer (Vision Transformers)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Imitating Radiological Scrolling: A Global-Local Attention Model for 3D Chest CT Volumes Multi-Label Anomaly Classification|模仿放射学滚动：一种用于3D胸部CT体积多标签异常分类的全局-局部注意力模型|Theo Di Piazza, Carole Lazarus, Olivier Nempont, Loic Boussel|<http://arxiv.org/pdf/2503.20652v1>|- 问题：3D CT多标签异常分类，长距离依赖，导航行为，全局-局部注意力<br />- 方法：CT-Scroll模型，模仿放射学滚动，全局-局部注意力机制<br />- 效果：高效，有效性，实验验证|
|🆕 发布|RSRWKV: A Linear-Complexity 2D Attention Mechanism for Efficient Remote Sensing Vision Task|RSRWKV：一种用于高效遥感视觉任务的线性复杂度2D注意力机制|Chunshan Li, Rong Wang, Xiaofei Yang, Dianhui Chu|<http://arxiv.org/pdf/2503.20382v1>|- 问题：高分辨率遥感，CNN局限性，Transformer效率低，RWKV限制<br />- 方法：2D-WKV扫描，MVC-Shift，ECA模块<br />- 效果：性能优越，效率高|
|🆕 发布|AI-Driven MRI Spine Pathology Detection: A Comprehensive Deep Learning Approach for Automated Diagnosis in Diverse Clinical Settings|人工智能驱动的MRI脊柱病理检测：一种适用于多样化临床环境的全面深度学习方法|Bargava Subramanian, Naveen Kumarasami, Praveen Shastry, Raghotham Sripadraj, Kalyan Sivasailam, Anandakumar D, Abinaya Ramachandran, Sudhir MP .etc.|<http://arxiv.org/pdf/2503.20316v1>|- 问题：MRI脊柱病理检测，自动化诊断<br />- 方法：Vision Transformers，U-Net，MedSAM，Cascade R-CNN<br />- 效果：高精度，高召回率|


## 生成建模 (Generative Modeling)


### 扩散模型 (Diffusion Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FB-4D: Spatial-Temporal Coherent Dynamic 3D Content Generation with Feature Banks|FB-4D：基于特征库的空间-时间一致动态3D内容生成|Jinwei Li, Huan-ang Gao, Wenyi Li, Haohan Chi, Chenyu Liu, Chenxi Du, Yiqian Liu, Mingju Gao .etc.|<http://arxiv.org/pdf/2503.20784v1>|- 问题：4D生成，时空一致性，挑战<br />- 方法：特征库，动态融合，预训练特征<br />- 效果：性能提升，质量高|
|📝 更新|PhysAnimator: Physics-Guided Generative Cartoon Animation|物理引导的生成卡通动画：PhysAnimator|Tianyi Xie, Yiwei Zhao, Ying Jiang, Chenfanfu Jiang|<http://arxiv.org/pdf/2501.16550v2>|[[代码]](<https://xpandora.github.io/PhysAnimator>)<br />- 问题：手绘动画，物理模拟，数据驱动<br />- 方法：物理引导，变形体模拟，能量笔触，视频扩散模型<br />- 效果：动态动画，视觉真实|
|🆕 发布|Dynamic Motion Blending for Versatile Motion Editing|动态运动混合：多用途运动编辑|Nan Jiang, Hongjie Li, Ziye Yuan, Zimo He, Yixin Chen, Tengyu Liu, Yixin Zhu, Siyuan Huang|<http://arxiv.org/pdf/2503.20724v1>|- 问题：语义控制，编辑场景，训练数据限制<br />- 方法：MotionCutMix，MotionReFit，扩散模型<br />- 效果：性能提升，文本引导|
|🆕 发布|A weakly-supervised deep learning model for fast localisation and delineation of the skeleton, internal organs, and spinal canal on Whole-Body Diffusion-Weighted MRI (WB-DWI)|弱监督深度学习模型在全身扩散加权磁共振成像（WB-DWI）中快速定位和描绘骨骼、内脏和脊髓通道|A. Candito, A. Dragan, R. Holbrey, A. Ribeiro, R. Donners, C. Messiou, N. Tunariu, D. -M. Koh .etc.|<http://arxiv.org/pdf/2503.20722v1>|- 问题：自动分割，ADC测量，TDV量化，临床应用<br />- 方法：弱监督学习，Residual U-Net，软标签<br />- 效果：快速，高精度，可重复|
|📝 更新|Data Augmentation in Earth Observation: A Diffusion Model Approach|地球观测中的数据增强：扩散模型方法|Tiago Sousa, Benoît Ries, Nicolas Guelfi|<http://arxiv.org/pdf/2406.06218v2>|- 问题：数据稀缺，语义多样性不足，AI模型精度受限<br />- 方法：扩散模型，元提示，视觉语言模型，迭代数据增强<br />- 效果：语义多样性提升，AI模型性能改善|
|🆕 发布|MMGen: Unified Multi-modal Image Generation and Understanding in One Go|MMGen：一步到位的统一多模态图像生成与理解|Jiepeng Wang, Zhaoqing Wang, Hao Pan, Yuan Liu, Dongdong Yu, Changhu Wang, Wenping Wang|<http://arxiv.org/pdf/2503.20644v1>|- 问题：多模态生成与理解，任务统一<br />- 方法：扩散模型，多模态输出，模态解耦<br />- 效果：任务统一，效果优越|
|📝 更新|Black-Box Forgery Attacks on Semantic Watermarks for Diffusion Models|黑盒伪造攻击针对扩散模型语义水印|Andreas Müller, Denis Lukovnikov, Jonas Thietke, Asja Fischer, Erwin Quiring|<http://arxiv.org/pdf/2412.03283v2>|- 问题：语义水印，伪造攻击，安全性<br />- 方法：无关模型，伪造攻击设计，水印移除<br />- 效果：攻击成功，安全性质疑|
|📝 更新|Unleashing Vecset Diffusion Model for Fast Shape Generation|释放Vecset扩散模型以实现快速形状生成|Zeqiang Lai, Yunfei Zhao, Zibo Zhao, Haolin Liu, Fuyun Wang, Huiwen Shi, Xianghui Yang, Qingxiang Lin .etc.|<http://arxiv.org/pdf/2503.16302v2>|[[代码]](<https://github.com/Tencent/FlashVDM.>)<br />- 问题：3D形状生成速度慢，解码困难<br />- 方法：FlashVDM，渐进式流动蒸馏，自适应KV选择<br />- 效果：速度提升，性能接近SOTA|
|🆕 发布|Diffusion Counterfactuals for Image Regressors|扩散反事实图像回归器|Trung Duc Ha, Sidney Bender|<http://arxiv.org/pdf/2503.20595v1>|- 问题：回归任务，反事实解释，生成模型<br />- 方法：扩散模型，去噪扩散模型，扩散自动编码器<br />- 效果：可解释性，语义变化，质量提升|
|🆕 发布|TD-BFR: Truncated Diffusion Model for Efficient Blind Face Restoration|TD-BFR：高效的盲人脸恢复截断扩散模型|Ziying Zhang, Xiang Gao, Zhixin Wang, Qiang hu, Xiaoyun Zhang|<http://arxiv.org/pdf/2503.20537v1>|- 问题：训练慢，细节恢复差<br />- 方法：截断扩散模型，自适应去降质，细节恢复<br />- 效果：速度快，质量优|
|🆕 发布|Exploring Robustness of Cortical Morphometry in the presence of white matter lesions, using Diffusion Models for Lesion Filling|探索白质病变存在下皮质形态学鲁棒性的研究，利用扩散模型进行病变填充|Vinzenz Uhr, Ivan Diaz, Christian Rummel, Richard McKinley|<http://arxiv.org/pdf/2503.20571v1>|- 问题：白质病变，皮质厚度测量，深度学习，脑分割<br />- 方法：U-Net，扩散模型，伪3D结构<br />- 效果：鲁棒性提升，皮质厚度测量准确|
|🆕 发布|GAIA-2: A Controllable Multi-View Generative World Model for Autonomous Driving|GAIA-2：一种可控制的用于自动驾驶的多视图生成世界模型|Lloyd Russell, Anthony Hu, Lorenzo Bertoni, George Fedoseev, Jamie Shotton, Elahe Arani, Gianluca Corrado|<http://arxiv.org/pdf/2503.20523v1>|- 问题：自动驾驶，多视图，生成模型，控制，一致性<br />- 方法：GAIA-2，世界模型，结构化输入，多相机视频<br />- 效果：高分辨率，时空一致性，场景合成|
|🆕 发布|Dissecting and Mitigating Diffusion Bias via Mechanistic Interpretability|剖析与缓解扩散偏差：通过机制可解释性|Yingdong Shi, Changming Li, Yifan Wang, Yongxiang Zhao, Anqi Pang, Sibei Yang, Jingyi Yu, Kan Ren|<http://arxiv.org/pdf/2503.20483v1>|- 问题：扩散模型，社会偏见，机制可解释性<br />- 方法：机制解释，偏差特征，直接操作<br />- 效果：有效管理，保持图像质量|
|🆕 发布|Contrastive Learning Guided Latent Diffusion Model for Image-to-Image Translation|对比学习引导的潜在扩散模型在图像到图像翻译中的应用|Qi Si, Bo Wang, Zhao Zhang|<http://arxiv.org/pdf/2503.20484v1>|- 问题：文本提示，内容保留，图像质量<br />- 方法：零样本扩散，对比损失，交叉注意力<br />- 效果：图像翻译，性能提升|
|📝 更新|Inference-Time Scaling for Flow Models via Stochastic Generation and Rollover Budget Forcing|基于随机生成和回滚预算强制的流模型推理时间缩放|Jaihoon Kim, Taehoon Yoon, Jisung Hwang, Minhyuk Sung|<http://arxiv.org/pdf/2503.19385v2>|- 问题：流模型推理时间缩放，效率低<br />- 方法：SDE生成，插值转换，Rollover Budget Forcing<br />- 效果：性能提升，优于前人方法|
|📝 更新|MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor Scene Generation|MMGDreamer：混合模态图用于几何可控的3D室内场景生成|Zhifei Yang, Keyang Lu, Chao Zhang, Jiaxing Qi, Hanqi Jiang, Ruifei Ma, Shenglin Yin, Yifan Xu .etc.|<http://arxiv.org/pdf/2502.05874v3>|[[代码]](<https://yangzhifeio.github.io/project>)<br />- 问题：3D场景生成，几何控制，图表示，用户输入<br />- 方法：混合模态图，扩散模型，关系预测<br />- 效果：几何控制，性能领先|
|🆕 发布|Latent Beam Diffusion Models for Decoding Image Sequences|潜在光束扩散模型用于解码图像序列|Guilherme Fernandes, Vasco Ramos, Regev Cohen, Idan Szpektor, João Magalhães|<http://arxiv.org/pdf/2503.20429v1>|- 问题：视觉一致性，序列生成，非线性故事<br />- 方法：beam search，动态搜索，跨注意力机制<br />- 效果：连贯性，连续性，文本对齐|
|🆕 发布|ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On|基于图像的虚拟试穿图像-时间步自适应掩码扩散Transformer框架：ITA-MDT|Ji Woo Hong, Tri Ton, Trung X. Pham, Gwanhyeong Koo, Sunjae Yoon, Chang D. Yoo|<http://arxiv.org/pdf/2503.20418v1>|- 问题：虚拟试穿，细节处理，全局上下文<br />- 方法：MDT，ITAFA，SRE模块<br />- 效果：效率提升，性能优化|
|🆕 发布|Consistency Trajectory Matching for One-Step Generative Super-Resolution|一致性轨迹匹配的单步生成式超分辨率|Weiyi You, Mingyang Zhang, Leheng Zhang, Kexuan Shi, Xingyu Zhou, Shuhang Gu|<http://arxiv.org/pdf/2503.20349v1>|- 问题：超分辨率，训练成本高，推理开销大<br />- 方法：一致性轨迹匹配，PF-ODE，一致性训练<br />- 效果：性能提升，低延迟|
|📝 更新|DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation|DiTCtrl：探索多模态扩散Transformer中的注意力控制以实现免调参的多提示长视频生成|Minghong Cai, Xiaodong Cun, Xiaoyu Li, Wenze Liu, Zhaoyang Zhang, Yong Zhang, Ying Shan, Xiangyu Yue|<http://arxiv.org/pdf/2412.18597v2>|- 问题：多提示视频生成，训练数据要求高，过渡不自然<br />- 方法：MM-DiT架构，注意力控制，无监督学习<br />- 效果：无监督生成，平滑过渡，性能优异|
|📝 更新|CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer|CogVideoX：基于专家Transformer的文本到视频扩散模型|Zhuoyi Yang, Jiayan Teng, Wendi Zheng, Ming Ding, Shiyu Huang, Jiazheng Xu, Yuanming Yang, Wenyi Hong .etc.|<http://arxiv.org/pdf/2408.06072v3>|[[代码]](<https://github.com/THUDM/CogVideo.>)<br />- 问题：视频生成，叙事连贯性，运动限制<br />- 方法：3D VAE，专家Transformer，多分辨率帧打包<br />- 效果：高保真，长视频，语义对齐|
|🆕 发布|Wan: Open and Advanced Large-Scale Video Generative Models|万：开放和高级大规模视频生成模型|WanTeam, :, Ang Wang, Baole Ai, Bin Wen, Chaojie Mao, Chen-Wei Xie, Di Chen .etc.|<http://arxiv.org/pdf/2503.20314v1>|[[代码]](<https://github.com/Wan-Video/Wan2.1.>)<br />- 问题：视频生成，性能提升，模型可扩展性<br />- 方法：扩散模型，VAE，大规模数据，自动评估<br />- 效果：领先性能，高效，开源|
|📝 更新|ARFlow: Human Action-Reaction Flow Matching with Physical Guidance|ARFlow：基于物理引导的人体动作-反应流匹配|Wentao Jiang, Jingya Wang, Haotao Lu, Kaiyang Ji, Baoxiong Jia, Siyuan Huang, Ye Shi|<http://arxiv.org/pdf/2503.16973v2>|- 问题：动作反应合成，物理违例，复杂机制<br />- 方法：ARFlow框架，x1预测，物理引导<br />- 效果：性能提升，碰撞减少|
|🆕 发布|Traversing Distortion-Perception Tradeoff using a Single Score-Based Generative Model|穿越失真-感知权衡：基于单一评分的生成模型|Yuhan Wang, Suzhi Bi, Ying-Jun Angela Zhang, Xiaojun Yuan|<http://arxiv.org/pdf/2503.20297v1>|- 问题：DP tradeoff，感知质量，MSE，模型适应性<br />- 方法：score-based generative model，方差缩放，反向扩散<br />- 效果：灵活穿越，优化，有效|
|🆕 发布|RelTriple: Learning Plausible Indoor Layouts by Integrating Relationship Triples into the Diffusion Process|RelTriple：通过整合关系三元组到扩散过程中学习合理的室内布局|Kaifan Sun, Bingchen Yang, Peter Wonka, Jun Xiao, Haiyong Jiang|<http://arxiv.org/pdf/2503.20289v1>|- 问题：室内布局生成，关系不完整，布局不现实<br />- 方法：关系三元组，扩散过程，空间关系学习<br />- 效果：结果提升，空间关系，实用性|
|📝 更新|DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking Head Video Generation|动态帧头像：基于非自回归扩散框架的说话人头视频生成|Hanbo Cheng, Limin Lin, Chenyu Liu, Pengcheng Xia, Pengfei Hu, Jiefeng Ma, Jun Du, Jia Pan|<http://arxiv.org/pdf/2410.13726v3>|[[代码]](<https://github.com/Hanbo-Cheng/DAWN-pytorch.>)<br />- 问题：talking head生成，自回归策略，速度慢，误差积累<br />- 方法：非自回归扩散，动态视频生成，音频驱动<br />- 效果：高速度，高质量，自然动作|
|🆕 发布|EGVD: Event-Guided Video Diffusion Model for Physically Realistic Large-Motion Frame Interpolation|EGVD：基于事件引导的物理真实感大运动帧插值视频扩散模型|Ziran Zhang, Xiaohui Li, Yihao Liu, Yujin Wang, Yueting Chen, Tianfan Xue, Shi Guo|<http://arxiv.org/pdf/2503.20268v1>|[[代码]](<https://github.com/OpenImagingLab/EGVD.>)<br />- 问题：大运动视频插帧，运动模糊，训练数据有限<br />- 方法：事件引导，多模态运动条件生成，选择性微调<br />- 效果：感知质量提升，LPIPS指标改善|
|🆕 发布|Unconditional Priors Matter! Improving Conditional Generation of Fine-Tuned Diffusion Models|无条件先验很重要！提升微调扩散模型的条件生成|Prin Phunyaphibarn, Phillip Y. Lee, Jaihoon Kim, Minhyuk Sung|<http://arxiv.org/pdf/2503.20240v1>|- 问题：CFG训练，无条件噪声预测，条件生成质量<br />- 方法：基模型预测，无条件噪声替换，跨模型应用<br />- 效果：条件生成质量提升，泛化能力增强|
|🆕 发布|Video Motion Graphs|视频运动图|Haiyang Liu, Zhan Xu, Fa-Ting Hong, Hsin-Ping Huang, Yi Zhou, Yang Zhou|<http://arxiv.org/pdf/2503.20218v1>|[[代码]](<https://h-liu1997.github.io/Video-Motion-Graphs>)<br />- 问题：真实运动视频生成，多模态条件，视频帧插值<br />- 方法：HMInterp，双分支插值，条件渐进训练<br />- 效果：高质量纹理，准确轨迹|
|📝 更新|EfficientMT: Efficient Temporal Adaptation for Motion Transfer in Text-to-Video Diffusion Models|EfficientMT：文本到视频扩散模型中运动传递的效率时序自适应|Yufei Cai, Hu Han, Yuxiang Wei, Shiguang Shan, Xilin Chen|<http://arxiv.org/pdf/2503.19369v2>|[[代码]](<https://github.com/PrototypeNx/EfficientMT.>)<br />- 问题：运动可控性，计算负担，运动迁移<br />- 方法：T2V模型，时间信息提取，缩放模块，时间集成机制<br />- 效果：效率高，可控性强|
|📝 更新|Uni$\textbf{F}^2$ace: Fine-grained Face Understanding and Generation with Unified Multimodal Models|统一多模态模型进行细粒度人脸理解和生成：UniFace|Junzhe Li, Xuerui Qiu, Linrui Xu, Liya Guo, Delin Qu, Tingting Long, Chun Fan, Ming Li|<http://arxiv.org/pdf/2503.08120v2>|- 问题：粗粒度面部属性理解，生成能力不足<br />- 方法：统一多模态模型，扩散技术，混合专家架构<br />- 效果：性能优越，理解与生成任务提升|


### 自回归模型 (Autoregressive Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ARMO: Autoregressive Rigging for Multi-Category Objects|ARMO：多类别对象的自回归绑定|Mingze Sun, Shiwei Mao, Keyi Chen, Yurun Chen, Shunlin Lu, Jingbo Wang, Junting Dong, Ruqi Huang|<http://arxiv.org/pdf/2503.20663v1>|- 问题：3D模型动态性，骨骼结构，皮肤绑定<br />- 方法：OmniRig数据集，自回归模型，条件生成<br />- 效果：性能提升，泛化能力强|
|🆕 发布|MAR-3D: Progressive Masked Auto-regressor for High-Resolution 3D Generation|MAR-3D：用于高分辨率3D生成的渐进式掩码自回归生成器|Jinnan Chen, Lingting Zhu, Zeyu Hu, Shengju Qian, Yugang Chen, Xin Wang, Gim Hee Lee|<http://arxiv.org/pdf/2503.20519v1>|- 问题：3D数据无序性，压缩损失，高分辨率预测<br />- 方法：金字塔VAE，级联掩码自回归，条件增强<br />- 效果：性能优越，泛化能力强|
|🆕 发布|Beyond Words: Advancing Long-Text Image Generation via Multimodal Autoregressive Models|超越文字：通过多模态自回归模型推进长文本图像生成|Alex Jinpeng Wang, Linjie Li, Zhengyuan Yang, Lijuan Wang, Min Li|<http://arxiv.org/pdf/2503.20198v1>|- 问题：长文本图像生成，文本生成质量，模型瓶颈<br />- 方法：新型二元分词器，多模态自回归模型<br />- 效果：高保真，可控性，性能优越|


### 生成对抗网络 (GANs)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation|BizGen：推进信息图表生成中的文章级别视觉文本渲染|Yuyang Peng, Shishi Xiao, Keming Wu, Qisheng Liao, Bohan Chen, Kevin Lin, Danqing Huang, Ji Li .etc.|<http://arxiv.org/pdf/2503.20672v1>|- 问题：文章级视觉文本渲染，长文本，高质量数据稀缺<br />- 方法：Infographics-650K数据集，布局引导交叉注意力<br />- 效果：BizEval结果优于SOTA，组件有效性验证|
|📝 更新|TechCoach: Towards Technical-Point-Aware Descriptive Action Coaching|技术点感知描述性动作指导：TechCoach|Yuan-Ming Li, An-Lan Wang, Kun-Yu Lin, Yu-Ming Tang, Ling-An Zeng, Jian-Fang Hu, Wei-Shi Zheng|<http://arxiv.org/pdf/2411.17130v2>|- 问题：动作技能指导，技术点反馈，评估方法<br />- 方法：描述性动作指导，TechPoint推理，数据集构建<br />- 效果：TechPoint感知，评估基准，公开数据|
|📝 更新|In the Blink of an Eye: Instant Game Map Editing using a Generative-AI Smart Brush|眨眼之间：利用生成式AI智能笔实现即时游戏地图编辑|Vitaly Gnatyuk, Valeriia Koriukina, Ilya Levoshevich, Pavel Nurminskiy, Guenter Wallner|<http://arxiv.org/pdf/2503.19793v2>|- 问题：3D游戏地图艺术创作，AI应用，高分辨率纹理<br />- 方法：生成对抗网络，扩散模型，智能画笔<br />- 效果：高效，细节丰富，上下文一致性|
|🆕 发布|Qwen2.5-Omni Technical Report|Qwen2.5-全视场技术报告|Jin Xu, Zhifang Guo, Jinzheng He, Hangrui Hu, Ting He, Shuai Bai, Keqin Chen, Jialin Wang .etc.|<http://arxiv.org/pdf/2503.20215v1>|- 问题：多模态感知，文本生成，语音合成，时间同步<br />- 方法：块状处理，TMRoPE，Thinker-Talker架构，滑动窗口DiT<br />- 效果：性能提升，端到端，自然流畅|
|📝 更新|Any2AnyTryon: Leveraging Adaptive Position Embeddings for Versatile Virtual Clothing Tasks|任意到任意Tryon：利用自适应位置嵌入实现多功能的虚拟服装任务|Hailong Guo, Bohan Zeng, Yiren Song, Wentao Zhang, Chuang Zhang, Jiaming Liu|<http://arxiv.org/pdf/2501.15891v2>|[[代码]](<https://logn-2024.github.io/Any2anyTryonProjectPage>)<br />- 问题：数据稀缺，任务特定，缺乏可控性<br />- 方法：自适应位置嵌入，LAION-Garment，合成数据<br />- 效果：泛化性强，可控度高|


## 多模态学习 (Multimodal Learning)


### 跨模态对齐 (Cross-modal Alignment)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Zero-Shot Audio-Visual Editing via Cross-Modal Delta Denoising|零样本跨模态差分去噪音频-视觉编辑|Yan-Bo Lin, Kevin Lin, Zhengyuan Yang, Linjie Li, Jianfeng Wang, Chung-Ching Lin, Xiaofei Wang, Gedas Bertasius .etc.|<http://arxiv.org/pdf/2503.20782v1>|[[代码]](<https://genjib.github.io/project_page>)<br />- 问题：零样本音频视频编辑，同步，一致性<br />- 方法：跨模态Delta去噪，音频视频交互<br />- 效果：性能提升，泛化能力强|
|📝 更新|OTTER: A Vision-Language-Action Model with Text-Aware Visual Feature Extraction|OTTER：一种具有文本感知视觉特征提取的视觉-语言-动作模型|Huang Huang, Fangchen Liu, Letian Fu, Tingfan Wu, Mustafa Mukadam, Jitendra Malik, Ken Goldberg, Pieter Abbeel|<http://arxiv.org/pdf/2503.03734v3>|[[代码]](<https://ottervla.github.io/.>)<br />- 问题：VLA模型，预训练语义对齐，零样本泛化<br />- 方法：文本感知视觉特征提取，选择性特征传递<br />- 效果：零样本泛化，性能提升|
|📝 更新|Generating Multimodal Driving Scenes via Next-Scene Prediction|通过下一场景预测生成多模态驾驶场景|Yanhao Wu, Haoyang Zhang, Tianwei Lin, Lichao Huang, Shujie Luo, Rui Wu, Congpei Qiu, Wei Ke .etc.|<http://arxiv.org/pdf/2503.14945v2>|[[代码]](<https://yanhaowu.github.io/UMGen>)<br />- 问题：模态限制，场景可控性，计算需求<br />- 方法：多模态生成，TAR，OAR，AMA模块<br />- 效果：复杂场景生成，多模态一致性|
|🆕 发布|VPO: Aligning Text-to-Video Generation Models with Prompt Optimization|VPO：通过提示优化对齐文本到视频生成模型|Jiale Cheng, Ruiliang Lyu, Xiaotao Gu, Xiao Liu, Jiazheng Xu, Yida Lu, Jiayan Teng, Zhuoyi Yang .etc.|<http://arxiv.org/pdf/2503.20491v1>|[[代码]](<https://github.com/thu-coai/VPO.>)<br />- 问题：文本视频生成，prompt优化，LLM局限性<br />- 方法：VPO框架，安全对齐，两阶段优化<br />- 效果：安全提升，视频质量改善|
|📝 更新|Referring Video Object Segmentation via Language-aligned Track Selection|基于语言对齐的轨迹选择进行视频目标分割|Seongchan Kim, Woojeong Jin, Sangbeom Lim, Heeji Yoon, Hyunwook Choi, Seungryong Kim|<http://arxiv.org/pdf/2412.01136v2>|[[代码]](<https://cvlab-kaist.github.io/SOLA.>)<br />- 问题：视频对象分割，语言对齐，运动理解<br />- 方法：SAM2，轻量级跟踪选择，IoU伪标签<br />- 效果：SOTA性能，MeViS数据集|
|🆕 发布|Instruction-Oriented Preference Alignment for Enhancing Multi-Modal Comprehension Capability of MLLMs|指令导向的偏好对齐以增强多模态理解能力|Zitian Wang, Yue Liao, Kang Rong, Fengyun Rao, Yibo Yang, Si Liu|<http://arxiv.org/pdf/2503.20309v1>|- 问题：MLLMs多模态理解能力，幻觉因素，偏好对齐<br />- 方法：指令导向偏好对齐，自动偏好构建，验证过程<br />- 效果：幻觉减少，理解能力提升|
|🆕 发布|Cross-Modal Prototype Allocation: Unsupervised Slide Representation Learning via Patch-Text Contrast in Computational Pathology|跨模态原型分配：通过计算病理学中的补丁-文本对比进行无监督幻灯片表示学习|Yuxuan Chen, Jiawen Li, Jiali Hu, Xitong Ling, Tian Guan, Anjia Han, Yonghong He|<http://arxiv.org/pdf/2503.20190v1>|- 问题：弱监督学习，泛化性差，语义信息忽略<br />- 方法：跨模态原型分配，LLM生成文本，无参数注意力聚合<br />- 效果：性能优于现有框架，可比弱监督模型|


### 视觉语言模型 (Vision-Language Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ADS-Edit: A Multimodal Knowledge Editing Dataset for Autonomous Driving Systems|ADS-Edit：自动驾驶系统多模态知识编辑数据集|Chenxi Wang, Jizhan Fang, Xiang Chen, Bozhong Tian, Ziwen Xu, Huajun Chen, Ningyu Zhang|<http://arxiv.org/pdf/2503.20756v1>|[[代码]](<https://github.com/zjunlp/EasyEdit.>)<br />- 问题：交通知识理解，复杂路况，车辆状态多样<br />- 方法：知识编辑，ADS-Edit数据集，多模态<br />- 效果：模型行为改进，应用推广|
|🆕 发布|Reason-RFT: Reinforcement Fine-Tuning for Visual Reasoning|原因-RFT：视觉推理的强化微调|Huajie Tan, Yuheng Ji, Xiaoshuai Hao, Minglan Lin, Pengwei Wang, Zhongyuan Wang, Shanghang Zhang|<http://arxiv.org/pdf/2503.20752v1>|- 问题：视觉推理泛化能力差，过拟合，认知僵化<br />- 方法：强化微调，CoT数据，GRPO<br />- 效果：性能提升，泛化能力强，数据效率高|
|🆕 发布|MATHGLANCE: Multimodal Large Language Models Do Not Know Where to Look in Mathematical Diagrams|MATHGLANCE：多模态大型语言模型在数学图表中不知如何定位|Yanpeng Sun, Shan Zhang, Wei Tang, Aotian Chen, Piotr Koniusz, Kai Zou, Yuan Xue, Anton van den Hengel|<http://arxiv.org/pdf/2503.20745v1>|- 问题：MLLMs，数学图理解，感知评估<br />- 方法：MATHGLANCE，GeoPeP，几何标注<br />- 效果：感知准确度提升，推理能力增强|
|📝 更新|Harmony: A Joint Self-Supervised and Weakly-Supervised Framework for Learning General Purpose Visual Representations|和谐：一种联合自监督和弱监督学习通用视觉表示的框架|Mohammed Baharoon, Jonathan Klein, Dominik L. Michels|<http://arxiv.org/pdf/2405.14239v2>|[[代码]](<https://github.com/MohammedSB/Harmony>)<br />- 问题：视觉表示学习，局部特征，密集预测任务<br />- 方法：联合自监督，弱监督，软CLIP目标<br />- 效果：性能提升，多任务，优于CLIP，MaskCLIP，SLIP|
|🆕 发布|Mitigating Low-Level Visual Hallucinations Requires Self-Awareness: Database, Model and Training Strategy|减轻低级视觉幻觉需要自我意识：数据库、模型和训练策略|Yinan Sun, Xiongkuo Min, Zicheng Zhang, Yixuan Gao, Yuqin Cao, Guangtao Zhai|<http://arxiv.org/pdf/2503.20673v1>|- 问题：视觉幻觉，低级视觉理解，模型可靠性<br />- 方法：HALPU数据库，SAFEQA模型，ESA-PO框架<br />- 效果：降低幻觉，提升模型自意识|
|📝 更新|COSMOS: Cross-Modality Self-Distillation for Vision Language Pre-training|宇宙：跨模态自蒸馏用于视觉语言预训练|Sanghwan Kim, Rui Xiao, Mariana-Iuliana Georgescu, Stephan Alaniz, Zeynep Akata|<http://arxiv.org/pdf/2412.01814v2>|[[代码]](<https://github.com/ExplainableML/cosmos.>)<br />- 问题：对比损失局限性，信息忽视，下游任务效果受限<br />- 方法：文本裁剪，跨模态自蒸馏，交叉注意力模块<br />- 效果：零样本任务表现优异，超越CLIP模型|
|🆕 发布|AutoRad-Lung: A Radiomic-Guided Prompting Autoregressive Vision-Language Model for Lung Nodule Malignancy Prediction|AutoRad-Lung：一种基于放射组学引导的提示自回归视觉-语言模型用于肺结节恶性预测|Sadaf Khademi, Mehran Shabanpour, Reza Taleei, Anastasia Oikonomou, Arash Mohammadi|<http://arxiv.org/pdf/2503.20662v1>|- 问题：肺癌诊断，视觉特征，主观性，文本信息，视觉编码器<br />- 方法：自回归VLM，Radiomics提示，条件上下文优化<br />- 效果：像素级差异，跨模态对齐|
|📝 更新|MC-LLaVA: Multi-Concept Personalized Vision-Language Model|MC-LLaVA：多概念个性化视觉-语言模型|Ruichuan An, Sihan Yang, Ming Lu, Renrui Zhang, Kai Zeng, Yulin Luo, Jiajun Cao, Hao Liang .etc.|<http://arxiv.org/pdf/2411.11706v3>|[[代码]](<https://github.com/arctanxarc/MC-LLaVA.>)<br />- 问题：单概念个性化，多概念交互，现实应用限制<br />- 方法：多概念指令调整，个性化文本提示，个性化视觉提示<br />- 效果：多概念个性化响应，用户特定助手|
|📝 更新|CLIP in Medical Imaging: A Survey|医学影像中的CLIP：综述|Zihao Zhao, Yuxiao Liu, Han Wu, Mei Wang, Yonghao Li, Sheng Wang, Lin Teng, Disheng Liu .etc.|<http://arxiv.org/pdf/2312.07353v6>|[[代码]](<https://github.com/zhaozh10/Awesome-CLIP-in-Medical-Imaging.>)<br />- 问题：CLIP，医学图像，预训练，应用<br />- 方法：CLIP预训练，优化，多任务<br />- 效果：泛化性，可解释性|
|🆕 发布|Beyond Intermediate States: Explaining Visual Redundancy through Language|超越中间状态：通过语言解释视觉冗余|Dingchen Yang, Bowen Cao, Anran Zhang, Weibo Gu, Winston Hu, Guang Chen|<http://arxiv.org/pdf/2503.20540v1>|- 问题：视觉冗余，MLLMs，中间状态，视觉理解<br />- 方法：视觉输入操纵，文本输出分析，冗余原型识别<br />- 效果：性能提升，视觉token剪枝|
|🆕 发布|Towards Efficient and General-Purpose Few-Shot Misclassification Detection for Vision-Language Models|面向高效和通用型视觉-语言模型少量样本误分类检测|Fanhu Zeng, Zhen Cheng, Fei Zhu, Xu-Yao Zhang|<http://arxiv.org/pdf/2503.20492v1>|- 问题：误分类检测，VLM，小样本，效率，泛化<br />- 方法：FSMisD，prompt learning，伪样本生成，负损失<br />- 效果：效率提升，泛化能力强|
|🆕 发布|MLLM-Selector: Necessity and Diversity-driven High-Value Data Selection for Enhanced Visual Instruction Tuning|MLLM-Selector：基于必要性和多样性驱动的增值数据选择以增强视觉指令微调|Yiwei Ma, Guohai Xu, Xiaoshuai Sun, Jiayi Ji, Jie Lou, Debing Zhang, Rongrong Ji|<http://arxiv.org/pdf/2503.20502v1>|- 问题：VIT数据选择，高价值数据，自动化<br />- 方法：MLLM-Selector，必要性，多样性<br />- 效果：性能提升，数据效率高|
|📝 更新|Bayesian Modeling of Zero-Shot Classifications for Urban Flood Detection|基于贝叶斯模型的零样本分类在城市洪水检测中的应用|Matt Franchi, Nikhil Garg, Wendy Ju, Emma Pierson|<http://arxiv.org/pdf/2503.14754v2>|- 问题：城市洪水检测，标签缺乏，零样本分类<br />- 方法：预训练视觉语言模型，空间贝叶斯模型<br />- 效果：风险预测，识别高风险人群|
|📝 更新|Aligning Visual Contrastive learning models via Preference Optimization|通过偏好优化对齐视觉对比学习模型|Amirabbas Afzali, Borna Khodabandeh, Ali Rasekh, Mahyar JafariNodeh, Sepehr kazemi, Simon Gottschalk|<http://arxiv.org/pdf/2411.08923v3>|- 问题：对比学习，数据质量，偏好优化，鲁棒性<br />- 方法：偏好优化，视觉对比学习，模型行为对齐<br />- 效果：性能提升，对抗攻击处理，下游任务准确|
|📝 更新|Unlocking the Hidden Potential of CLIP in Generalizable Deepfake Detection|解锁CLIP在泛化深度伪造检测中的潜在能力|Andrii Yermakov, Jan Cech, Jiri Matas|<http://arxiv.org/pdf/2503.19683v2>|[[代码]](<https://github.com/yermandy/deepfake-detection>)<br />- 问题：部分人脸deepfake检测，CLIP模型，ViT-L/14<br />- 方法：PEFT，LN-tuning，预处理，正则化<br />- 效果：高检测精度，泛化能力强|
|🆕 发布|Self-ReS: Self-Reflection in Large Vision-Language Models for Long Video Understanding|自我反思：用于长视频理解的超大视觉-语言模型中的自我反思|Joao Pereira, Vasco Lopes, David Semedo, Joao Neves|<http://arxiv.org/pdf/2503.20362v1>|- 问题：长视频理解，线性采样，信息冗余<br />- 方法：非线性采样，自我反思，注意力图<br />- 效果：任务精度提升，推理速度加快|
|📝 更新|PHT-CAD: Efficient CAD Parametric Primitive Analysis with Progressive Hierarchical Tuning|PHT-CAD：基于渐进式分层调优的高效CAD参数化原语分析|Ke Niu, Yuwen Chen, Haiyang Yu, Zhuofan Chen, Xianghui Que, Bin Li, Xiangyang Xue|<http://arxiv.org/pdf/2503.18147v2>|- 问题：CAD PPA，结构约束，语义理解<br />- 方法：EHP，PHT-CAD，VLMs，回归头<br />- 效果：效率提升，精度提高|
|🆕 发布|VideoGEM: Training-free Action Grounding in Videos|视频GEM：无需训练的视频动作定位|Felix Vogel, Walid Bousselham, Anna Kukleva, Nina Shvetsova, Hilde Kuehne|<http://arxiv.org/pdf/2503.20348v1>|- 问题：视频动作定位，语义概念提取，训练需求高<br />- 方法：预训练模型，层加权，动态权重调整，提示分解<br />- 效果：训练免费，性能优于现有方法|
|📝 更新|NLPrompt: Noise-Label Prompt Learning for Vision-Language Models|NLPrompt：视觉-语言模型中的噪声标签提示学习|Bikang Pan, Qun Li, Xiaoying Tang, Wei Huang, Zhen Fang, Feng Liu, Jingya Wang, Jingyi Yu .etc.|<http://arxiv.org/pdf/2412.01256v2>|- 问题：噪声标签，prompt学习，性能退化<br />- 方法：PromptMAE，PromptOT，数据净化<br />- 效果：鲁棒性增强，性能提升|
|🆕 发布|Dynamic Pyramid Network for Efficient Multimodal Large Language Model|动态金字塔网络：高效的多模态大型语言模型|Hao Ai, Kunyi Wang, Zezhou Wang, Hao Lu, Jin Tian, Yaxin Luo, Peng Xing, Jen-Yuan Huang .etc.|<http://arxiv.org/pdf/2503.20322v1>|[[代码]](<https://github.com/aihao2000/DPN-LLaVA.>)<br />- 问题：MLLM计算成本高，视觉语义破坏<br />- 方法：动态金字塔网络，动态池化专家<br />- 效果：FLOPs减少56%，性能提升0.74%|
|🆕 发布|EditCLIP: Representation Learning for Image Editing|编辑CLIP：图像编辑的表示学习|Qian Wang, Aleksandar Cvejic, Abdelrahman Eldesokey, Peter Wonka|<http://arxiv.org/pdf/2503.20318v1>|- 问题：图像编辑，表示学习，编辑评估<br />- 方法：EditCLIP，联合编码，嵌入计算<br />- 效果：超越现有，效率高，质量可靠|
|📝 更新|MMRL: Multi-Modal Representation Learning for Vision-Language Models|多模态表征学习：用于视觉-语言模型的MMRL|Yuncheng Guo, Xiaodong Gu|<http://arxiv.org/pdf/2503.08497v2>|[[代码]](<https://github.com/yunncheng/MMRL.>)<br />- 问题：VLMs过拟合，泛化能力差<br />- 方法：MMRL框架，共享表示空间，多模态交互<br />- 效果：性能提升，泛化与适应平衡|
|📝 更新|RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics|机器人空间理解：为机器人二维和三维视觉语言模型教授空间理解|Chan Hee Song, Valts Blukis, Jonathan Tremblay, Stephen Tyree, Yu Su, Stan Birchfield|<http://arxiv.org/pdf/2411.16537v3>|- 问题：空间理解，视觉语言模型，训练数据，空间推理<br />- 方法：RoboSpatial，3D扫描，egocentric图像，空间关系标注<br />- 效果：模型表现提升，空间推理任务，机器人操作|
|🆕 发布|ViLBench: A Suite for Vision-Language Process Reward Modeling|ViLBench：视觉-语言处理奖励模型套件|Haoqin Tu, Weitao Feng, Hardy Chen, Hui Liu, Xianfeng Tang, Cihang Xie|<http://arxiv.org/pdf/2503.20271v1>|[[代码]](<https://ucsc-vlaa.github.io/ViLBench>)<br />- 问题：PRM评估，VLLM性能，奖励模型<br />- 方法：ViLBench基准，过程奖励信号，数据收集<br />- 效果：性能提升，挑战VLLM|
|📝 更新|Benchmarking Large Vision-Language Models via Directed Scene Graph for Comprehensive Image Captioning|通过定向场景图进行基准测试，以实现全面图像描述|Fan Lu, Wei Wu, Kecheng Zheng, Shuailei Ma, Biao Gong, Jiawei Liu, Wei Zhai, Yang Cao .etc.|<http://arxiv.org/pdf/2412.08614v3>|- 问题：详细图像描述，基准测试，视觉语言模型<br />- 方法：语义分割，属性标注，场景图构建<br />- 效果：评估准确，人类评分一致|
|📝 更新|ST-VLM: Kinematic Instruction Tuning for Spatio-Temporal Reasoning in Vision-Language Models|ST-VLM：视觉-语言模型中的运动学指令调优用于时空推理|Dohwan Ko, Sihyeon Kim, Yumin Suh, Vijay Kumar B. G, Minseo Yoon, Manmohan Chandraker, Hyunwoo J. Kim|<http://arxiv.org/pdf/2503.19355v2>|[[代码]](<https://ikodoh.github.io/ST-VLM.>)<br />- 问题：时空推理，运动元素分析，VLM性能<br />- 方法：STKit，伪标签生成，ST-VLM<br />- 效果：性能提升，泛化能力强|
|📝 更新|LangBridge: Interpreting Image as a Combination of Language Embeddings|LangBridge：将图像解释为语言嵌入的组合|Jiaqi Liao, Yuwei Niu, Fanqing Meng, Hao Li, Changyao Tian, Yinuo Du, Yuwen Xiong, Dianqi Li .etc.|<http://arxiv.org/pdf/2503.19404v2>|[[代码]](<https://jiaqiliao77.github.io/LangBridge.github.io>)<br />- 问题：LVLMs，视觉-语言对齐，MLP机制，重训练<br />- 方法：LangBridge，线性映射，预训练迁移<br />- 效果：性能维持，可解释性|
|🆕 发布|Rethinking Vision-Language Model in Face Forensics: Multi-Modal Interpretable Forged Face Detector|重新思考人脸取证中的视觉-语言模型：多模态可解释伪造人脸检测器|Xiao Guo, Xiufeng Song, Yue Zhang, Xiaohong Liu, Xiaoming Liu|<http://arxiv.org/pdf/2503.20188v1>|- 问题：深度伪造检测，可解释性，多模态学习<br />- 方法：CLIP，LLM，M2F2-Det，prompt learning<br />- 效果：性能提升，可解释性增强|
|📝 更新|Narrating the Video: Boosting Text-Video Retrieval via Comprehensive Utilization of Frame-Level Captions|视频叙事：通过全面利用帧级标题提升文本-视频检索|Chan Hur, Jeong-hun Hong, Dong-hun Lee, Dabin Kang, Semin Myeong, Sang-hyo Park, Hyeyoung Park|<http://arxiv.org/pdf/2503.05186v4>|- 问题：语义理解，视频检索，信息错误<br />- 方法：帧级字幕，多模态交互，自适应过滤<br />- 效果：性能提升，基准数据集|
|📝 更新|HLV-1K: A Large-scale Hour-Long Video Benchmark for Time-Specific Long Video Understanding|HLV-1K：一个大规模的时长一小时视频基准，用于特定时间点长视频理解|Heqing Zou, Tianze Luo, Guiyang Xie, Victor, Zhang, Fengmao Lv, Guangcong Wang, Junyang Chen .etc.|<http://arxiv.org/pdf/2501.01645v2>|- 问题：长视频理解，挑战，效率，数据集<br />- 方法：大规模视频基准，时间感知，多任务<br />- 效果：评估，能力测试，任务促进|
|📝 更新|Progress-Aware Video Frame Captioning|感知进度的视频帧字幕生成|Zihui Xue, Joungbin An, Xitong Yang, Kristen Grauman|<http://arxiv.org/pdf/2412.02071v2>|- 问题：视频帧级，动作捕捉，时间动态<br />- 方法：ProgressCaptioner，FrameCap数据集，FrameCapEval基准<br />- 效果：超越领先模型，精确捕捉动作进展|
|📝 更新|PAINT: Paying Attention to INformed Tokens to Mitigate Hallucination in Large Vision-Language Model|PAINT：通过关注信息化的令牌减轻大型视觉-语言模型中的幻觉|Kazi Hasan Ibn Arif, Sajib Acharjee Dip, Khizar Hussain, Lang Zhang, Chris Thomas|<http://arxiv.org/pdf/2501.12206v3>|[[代码]](<https://github.com/hasanar1f/PAINT>)<br />- 问题：幻觉，视觉语言模型，注意力权重<br />- 方法：PAINT框架，局部和总结标记，权重增强<br />- 效果：幻觉率降低，准确率保持|


### 多模态融合 (Multimodal Fusion)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MMMORRF: Multimodal Multilingual Modularized Reciprocal Rank Fusion|多模态多语言模块化互信息排序融合|Saron Samuel, Dan DeGenaro, Jimena Guallar-Blasco, Kate Sanders, Oluwaseun Eisape, Arun Reddy, Alexander Martin, Andrew Yates .etc.|<http://arxiv.org/pdf/2503.20698v1>|- 问题：多模态检索，视觉优先，信息需求<br />- 方法：模态感知，加权互信息融合，模块化<br />- 效果：nDCG提升，效率高|
|📝 更新|Point-Cache: Test-time Dynamic and Hierarchical Cache for Robust and Generalizable Point Cloud Analysis|点缓存：用于鲁棒和泛化点云分析的测试时动态和分层缓存|Hongyu Sun, Qiuhong Ke, Ming Cheng, Yongcai Wang, Deying Li, Chenhui Gou, Jianfei Cai|<http://arxiv.org/pdf/2503.12150v2>|[[代码]](<https://github.com/auniquesun/Point-Cache.>)<br />- 问题：测试时分布偏移，模型适应性，开放词汇识别<br />- 方法：Point-Cache，层次缓存，动态管理<br />- 效果：高效，无训练，性能提升|
|🆕 发布|CryoSAMU: Enhancing 3D Cryo-EM Density Maps of Protein Structures at Intermediate Resolution with Structure-Aware Multimodal U-Nets|CryoSAMU：利用结构感知多模态U-Nets增强中等分辨率蛋白质结构3D冷冻电镜密度图|Chenwei Zhang, Anne Condon, Khanh Dao Duc|<http://arxiv.org/pdf/2503.20291v1>|[[代码]](<https://github.com/chenwei-zhang/CryoSAMU.>)<br />- 问题：3D Cryo-EM密度图，中间分辨率，增强<br />- 方法：结构感知，多模态U-Nets，训练<br />- 效果：性能提升，速度加快|
|📝 更新|FUSE: Label-Free Image-Event Joint Monocular Depth Estimation via Frequency-Decoupled Alignment and Degradation-Robust Fusion|FUSE：通过频率解耦对齐和退化鲁棒融合的无标签图像-事件联合单目深度估计|Pihai Sun, Junjun Jiang, Yuanqi Yao, Youyu Chen, Wenbo Zhao, Kui Jiang, Xianming Liu|<http://arxiv.org/pdf/2503.19739v2>|[[代码]](<https://github.com/sunpihai-up/FUSE>)<br />- 问题：泛化性，数据稀缺，频率不匹配，特征融合<br />- 方法：PST，FreDFuse，联合编码，物理融合<br />- 效果：性能提升，零样本适应|


## 目标检测识别 (Object Detection & Recognition)


### 二维检测 (2D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BASKET: A Large-Scale Video Dataset for Fine-Grained Skill Estimation|BASKET：用于精细粒度技能估计的大规模视频数据集|Yulu Pan, Ce Zhang, Gedas Bertasius|<http://arxiv.org/pdf/2503.20781v1>|[[代码]](<https://github.com/yulupan00/BASKET.>)<br />- 问题：技能估计，视频数据集，细粒度<br />- 方法：大规模数据集，细粒度技能，长视频分析<br />- 效果：挑战模型，资源开发|
|🆕 发布|Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data|解耦无源个性化中性目标数据面部表情识别|Masoumeh Sharafi, Emma Ollivier, Muhammad Osama Zeeshan, Soufiane Belharbi, Marco Pedersoli, Alessandro Lameiras Koerich, Simon Bacon, Eric~Granger|<http://arxiv.org/pdf/2503.20771v1>|- 问题：面部表情识别，数据隐私，源域适应，中性数据<br />- 方法：解耦源域适应，自监督学习，特征解耦<br />- 效果：模型精度提升，数据隐私保护|
|🆕 发布|Emotion Detection and Music Recommendation System|情感检测与音乐推荐系统|Swetha Kambham, Hubert Jhonson, Sai Prathap Reddy Kambham|<http://arxiv.org/pdf/2503.20739v1>|- 问题：情感识别，音乐推荐，实时分析<br />- 方法：深度学习，面部识别，DeepFace框架<br />- 效果：个性化体验，音乐疗法|
|🆕 发布|SChanger: Change Detection from a Semantic Change and Spatial Consistency Perspective|SChanger：从语义变化和空间一致性角度进行变化检测|Ziyu Zhou, Keyan Hu, Yutian Fang, Xiaoping Rui|<http://arxiv.org/pdf/2503.20734v1>|- 问题：数据稀缺，深度学习，变化检测<br />- 方法：语义变化网络，Siamese架构，时空融合模块<br />- 效果：F1分数提升，模型性能优越|
|🆕 发布|Benchmarking Machine Learning Methods for Distributed Acoustic Sensing|机器学习在分布式声学传感中的应用方法基准测试|Shuaikai Shi, Qijun Zong|<http://arxiv.org/pdf/2503.20681v1>|- 问题：DAS数据识别，机器学习，性能比较<br />- 方法：机器学习算法，深度学习模型，数据预处理<br />- 效果：智能监测，应用领域拓展|
|🆕 发布|Evaluating Facial Expression Recognition Datasets for Deep Learning: A Benchmark Study with Novel Similarity Metrics|评估深度学习用面部表情识别数据集：一种带有新颖相似度指标的基准研究|F. Xavier Gaya-Morey, Cristina Manresa-Yee, Célia Martinie, Jose M. Buades-Rubio|<http://arxiv.org/pdf/2503.20428v1>|- 问题：FER数据集，深度学习，性能，质量，多样性<br />- 方法：相似性指标，数据集分析，自动标注<br />- 效果：泛化能力，标注质量，系统发展|
|📝 更新|DEIM: DETR with Improved Matching for Fast Convergence|DEIM：用于快速收敛的改进匹配 DETR|Shihua Huang, Zhichao Lu, Xiaodong Cun, Yongjun Yu, Xiao Zhou, Xi Shen|<http://arxiv.org/pdf/2412.04234v3>|[[代码]](<https://github.com/ShihuaHuang95/DEIM.>)<br />- 问题：DETR收敛慢，匹配质量低<br />- 方法：Dense O2O匹配，Matchability-Aware Loss<br />- 效果：性能提升，训练时间缩短|
|📝 更新|TopoBDA: Towards Bezier Deformable Attention for Road Topology Understanding|TopoBDA：迈向贝塞尔变形注意力以实现道路拓扑理解|Muhammet Esat Kalfaoglu, Halil Ibrahim Ozturk, Ozsel Kilinc, Alptekin Temizel|<http://arxiv.org/pdf/2412.18951v2>|- 问题：道路拓扑理解，多摄像头图像，车道线检测<br />- 方法：Bezier变形注意力，Transformer解码器，多模态数据融合<br />- 效果：中心线检测，拓扑推理，3D车道线检测|
|🆕 发布|Attribute-formed Class-specific Concept Space: Endowing Language Bottleneck Model with Better Interpretability and Scalability|属性形成的类特定概念空间：赋予语言瓶颈模型更好的可解释性和可扩展性|Jianyang Zhang, Qianli Luo, Guowu Yang, Wenjing Yang, Weide Liu, Guosheng Lin, Fengmao Lv|<http://arxiv.org/pdf/2503.20301v1>|[[代码]](<https://github.com/tiggers23/ALBM.>)<br />- 问题：可解释性，可扩展性，伪线索，未见类别<br />- 方法：属性形成，类特定空间，VAPL，DSS策略<br />- 效果：可解释性，迁移性，性能提升|
|🆕 发布|Context-Aware Weakly Supervised Image Manipulation Localization with SAM Refinement|基于SAM精炼的上下文感知弱监督图像操纵定位|Xinghao Wang, Changtao Miao, Dianmo Sheng, Tao Gong, Qi Chu, Bin Liu, Nenghai Yu|<http://arxiv.org/pdf/2503.20294v1>|- 问题：弱监督图像篡改定位，边缘信息，定位性能<br />- 方法：CABL模块，CAM-Guided SAM Refinement，Transformer-CNN<br />- 效果：定位性能提升，多数据集表现优异|
|🆕 发布|BEAR: A Video Dataset For Fine-grained Behaviors Recognition Oriented with Action and Environment Factors|BEAR：面向动作和环境因素的细粒度行为识别视频数据集|Chengyang Hu, Yuduo Chen, Lizhuang Ma|<http://arxiv.org/pdf/2503.20209v1>|- 问题：行为识别，特征学习，细粒度行为<br />- 方法：BEAR数据集，环境与动作因素，细粒度行为协议<br />- 效果：模型探索，输入模态影响|


### 三维检测 (3D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PhysGen3D: Crafting a Miniature Interactive World from a Single Image|PhysGen3D：从单张图像构建微型交互式世界|Boyuan Chen, Hanxiao Jiang, Shaowei Liu, Saurabh Gupta, Yunzhu Li, Hao Zhao, Shenlong Wang|<http://arxiv.org/pdf/2503.20746v1>|- 问题：单图生成，物理交互，3D场景<br />- 方法：图像理解，物理模拟，交互式生成<br />- 效果：物理真实，交互灵活|
|🆕 发布|GLRD: Global-Local Collaborative Reason and Debate with PSL for 3D Open-Vocabulary Detection|GLRD：基于PSL的3D开放词汇检测中的全局-局部协同推理与辩论|Xingyu Peng, Si Liu, Chen Gao, Yan Bai, Beipeng Mu, Xiaofei Wang, Huaxia Xia|<http://arxiv.org/pdf/2503.20682v1>|- 问题：3D OVD，物体识别，场景信息，标签缺失<br />- 方法：GLRD框架，LLM推理，OV-PSL求解，辩论机制<br />- 效果：精度提升，性能优越|
|🆕 发布|Flip Learning: Weakly Supervised Erase to Segment Nodules in Breast Ultrasound|翻转学习：弱监督擦除分割乳腺超声结节|Yuhao Huang, Ao Chang, Haoran Dou, Xing Tao, Xinrui Zhou, Yan Cao, Ruobing Huang, Alejandro F Frangi .etc.|<http://arxiv.org/pdf/2503.20685v1>|- 问题：弱监督分割，结节分割，超声图像<br />- 方法：多智能体强化学习，翻转学习，奖励设计<br />- 效果：性能提升，可比全监督学习|
|📝 更新|Unleashing HyDRa: Hybrid Fusion, Depth Consistency and Radar for Unified 3D Perception|释放HyDRa：混合融合、深度一致性及雷达的统一3D感知|Philipp Wolters, Johannes Gilg, Torben Teepe, Fabian Herzog, Anouar Laouichi, Martin Hofmann, Gerhard Rigoll|<http://arxiv.org/pdf/2403.07746v4>|[[代码]](<https://github.com/phi-wol/hydra.>)<br />- 问题：深度预测，融合，3D感知<br />- 方法：HyDRa架构，混合融合，雷达特征<br />- 效果：NDS+1.8，AMOTA+1.5|
|🆕 发布|Perceptually Accurate 3D Talking Head Generation: New Definitions, Speech-Mesh Representation, and Evaluation Metrics|感知准确的3D说话人头生成：新定义、语音-网格表示和评估指标|Lee Chae-Yeon, Oh Hyun-Bin, Han EunGi, Kim Sung-Bin, Suekyeong Nam, Tae-Hyun Oh|<http://arxiv.org/pdf/2503.20308v1>|[[代码]](<https://perceptual-3d-talking-head.github.io/.>)<br />- 问题：唇同步，感知对齐，语音特征<br />- 方法：语音-网格表示，感知损失，评估指标<br />- 效果：唇同步提升，感知准确|
|🆕 发布|Leveraging 3D Geometric Priors in 2D Rotation Symmetry Detection|利用3D几何先验在2D旋转对称性检测中的应用|Ahyun Seo, Minsu Cho|<http://arxiv.org/pdf/2503.20235v1>|- 问题：旋转对称检测，3D几何一致性，视角扭曲<br />- 方法：3D预测，投影回2D，3D几何先验<br />- 效果：旋转轴检测，3D先验影响|
|📝 更新|EVT: Efficient View Transformation for Multi-Modal 3D Object Detection|高效多模态3D目标检测中的视图变换（EVT）|Yongjin Lee, Hyeon-Mun Jeong, Yurim Jeon, Sanghyun Kim|<http://arxiv.org/pdf/2411.10715v3>|- 问题：多模态3D检测，深度估计，计算开销，几何指导不足<br />- 方法：EVT框架，ASAP，查询检测框架<br />- 效果：精度提升，实时速度|
|📝 更新|MamBEV: Enabling State Space Models to Learn Birds-Eye-View Representations|MamBEV：使状态空间模型学习鸟瞰视图表示|Hongyu Ke, Jack Morris, Kentaro Oguchi, Xiaofei Cao, Yongkang Liu, Haoxin Wang, Yi Ding|<http://arxiv.org/pdf/2503.13858v2>|- 问题：3D视觉，计算效率，BEV表示<br />- 方法：MamBEV框架，线性SSM，跨注意力<br />- 效果：效率提升，性能优越|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spectrum from Defocus: Fast Spectral Imaging with Chromatic Focal Stack|从失焦中提取光谱：快速彩色焦距堆叠光谱成像|M. Kerem Aydin, Yi-Chun Hung, Jaclyn Pytlarz, Qi Guo, Emma Alexander|<http://arxiv.org/pdf/2503.20184v1>|- 问题：光谱成像，分辨率，计算复杂度<br />- 方法：色散焦距，迭代算法，物理建模<br />- 效果：快速，紧凑，高光谱|


## 三维重建 (3D Reconstruction)


### 多视图重建 (Multi-view Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Cutting Voxel Projector a New Approach to Construct 3D Cone Beam CT Operator|切割体素投影仪：构建3D锥束CT算子的新方法|Vojtěch Kulvait, Julian Moosmann, Georg Rose|<http://arxiv.org/pdf/2110.09841v3>|[[代码]](<https://github.com/kulvait/KCT_cbct.>)<br />- 问题：3D锥束CT重建，投影器，非均匀体素网格<br />- 方法：切割体素投影器，近精确投影，自适应分辨率<br />- 效果：高精度，速度提升|
|📝 更新|MARVEL-40M+: Multi-Level Visual Elaboration for High-Fidelity Text-to-3D Content Creation|MARVEL-40M+：用于高保真文本到3D内容创建的多级视觉细化|Sankalp Sinha, Mohammad Sadil Khan, Muhammad Usama, Shino Sam, Didier Stricker, Sk Aziz Ali, Muhammad Zeshan Afzal|<http://arxiv.org/pdf/2411.17945v2>|[[代码]](<https://sankalpsinha-cmos.github.io/MARVEL>)<br />- 问题：3D内容生成，数据集限制，标注深度不足<br />- 方法：多级视觉细化，多视图VLMs，LLMs，人类元数据<br />- 效果：标注质量高，语言多样性，生成速度快|


### 单目重建 (Monocular Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Towards End-to-End Neuromorphic Voxel-based 3D Object Reconstruction Without Physical Priors|迈向无物理先验的端到端神经形态体素化3D物体重建|Chuanzhi Xu, Langyi Chen, Haodong Chen, Vera Chung, Qiang Qu|<http://arxiv.org/pdf/2501.00741v2>|- 问题：3D重建，神经形态相机，物理先验，单目，复杂流程<br />- 方法：端到端，事件表示，特征增强，阈值优化<br />- 效果：精度提升，基准优化|
|📝 更新|Decoupling Fine Detail and Global Geometry for Compressed Depth Map Super-Resolution|解耦精细细节与全局几何的压缩深度图超分辨率|Huan Zheng, Wencheng Han, Jianbing Shen|<http://arxiv.org/pdf/2411.03239v3>|[[代码]](<https://github.com/Ian0926/GDNet.>)<br />- 问题：压缩深度图，细节丢失，几何结构误差<br />- 方法：GDNet，FGDE，GGE，低秩空间<br />- 效果：几何一致性，细节恢复|
|🆕 发布|Progressive Focused Transformer for Single Image Super-Resolution|渐进式聚焦Transformer用于单图像超分辨率|Wei Long, Xingyu Zhou, Leheng Zhang, Shuhang Gu|<http://arxiv.org/pdf/2503.20337v1>|- 问题：计算开销大，特征无关计算，性能下降<br />- 方法：渐进式聚焦注意力，PFA，特征筛选<br />- 效果：性能提升，计算效率高|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Euclidean Distance to Convex Polyhedra and Application to Class Representation in Spectral Images|欧几里得距离到凸多面体及其在光谱图像类表示中的应用|Antoine Bottenmuller, Florent Magaud, Arnaud Demortière, Etienne Decencière, Petr Dokladal|<http://arxiv.org/pdf/2503.20328v1>|- 问题：线性分解，光谱图像，数据相关性<br />- 方法：空间密度函数，欧几里得距离，算法优化<br />- 效果：超越现有方法，泛化能力强|
|🆕 发布|TraNCE: Transformative Non-linear Concept Explainer for CNNs|TraNCE：CNN的变革性非线性概念解释器|Ugochukwu Ejike Akpudo, Yongsheng Gao, Jun Zhou, Andrew Lewis|<http://arxiv.org/pdf/2503.20230v1>|- 问题：CNN可解释性，线性假设，激活关系<br />- 方法：VAE概念发现，Bessel函数可视化，Faith分数<br />- 效果：概念识别，避免重复，评估一致性|


### 神经隐式重建 (Neural Implicit Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Guiding Human-Object Interactions with Rich Geometry and Relations|引导人类-物体交互的丰富几何和关系|Mengqing Xue, Yifei Liu, Ling Guo, Shaoli Huang, Changxing Ding|<http://arxiv.org/pdf/2503.20172v1>|- 问题：HOI合成，几何复杂性，交互精度<br />- 方法：ROG框架，边界关键点，扩散关系模型<br />- 效果：性能提升，语义准确性|


## 神经渲染 (Neural Rendering)


### 神经辐射场 (Neural Radiance Fields)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AccidentSim: Generating Physically Realistic Vehicle Collision Videos from Real-World Accident Reports|事故模拟：从现实世界事故报告中生成物理逼真的车辆碰撞视频|Xiangwen Zhang, Qian Zhang, Longfei Han, Qiang Qu, Xiaoming Chen|<http://arxiv.org/pdf/2503.20654v1>|- 问题：车辆事故视频收集困难，物理模拟不准确<br />- 方法：物理线索提取，语言模型预测，NeRF渲染<br />- 效果：物理真实性，视觉真实性|
|📝 更新|DeSplat: Decomposed Gaussian Splatting for Distractor-Free Rendering|DeSplat：用于无干扰渲染的分解高斯喷溅|Yihao Wang, Marcus Klasson, Matias Turkulainen, Shuzhe Wang, Juho Kannala, Arno Solin|<http://arxiv.org/pdf/2411.19756v2>|[[代码]](<https://aaltoml.github.io/desplat>)<br />- 问题：多视图一致性，语义信息，渲染速度<br />- 方法：分解高斯，场景分离，alpha合成<br />- 效果：无干扰渲染，结果可比|
|📝 更新|4DRGS: 4D Radiative Gaussian Splatting for Efficient 3D Vessel Reconstruction from Sparse-View Dynamic DSA Images|四维辐射高斯分层：从稀疏视图动态DSA图像中高效重建3D血管的4DRGS|Zhentao Liu, Ruyi Zha, Huangxuan Zhao, Hongdong Li, Zhiming Cui|<http://arxiv.org/pdf/2412.12919v2>|- 问题：3D血管重建，稀疏视图，DSA图像<br />- 方法：4D辐射高斯分层，神经网络预测，X射线光栅化<br />- 效果：高效，高质量，速度快|
|📝 更新|DashGaussian: Optimizing 3D Gaussian Splatting in 200 Seconds|DashGaussian：200秒内优化3D高斯分层|Youyu Chen, Junjun Jiang, Kui Jiang, Xiao Tang, Zhihao Li, Xianming Liu, Yinyu Nie|<http://arxiv.org/pdf/2503.18402v2>|- 问题：3DGS优化复杂度高，渲染时间长<br />- 方法：DashGaussian，动态渲染分辨率，优化复杂性<br />- 效果：优化速度提升45.7%，保持渲染质量|
|📝 更新|A Survey on Event-driven 3D Reconstruction: Development under Different Categories|事件驱动3D重建综述：不同类别下的进展|Chuanzhi Xu, Haoxian Zhou, Haodong Chen, Vera Chung, Qiang Qu|<http://arxiv.org/pdf/2503.19753v2>|- 问题：事件相机，3D重建，高动态范围，异步捕获<br />- 方法：几何方法，学习型方法，混合方法，神经辐射场，3D高斯分层<br />- 效果：准确重建，快速运动，挑战性光照|
|🆕 发布|TC-GS: Tri-plane based compression for 3D Gaussian Splatting|TC-GS：基于三平面压缩的3D高斯分层渲染|Taorui Wang, Zitong Yu, Yong Xu|<http://arxiv.org/pdf/2503.20221v1>|[[代码]](<https://github.com/timwang2001/TC-GS.>)<br />- 问题：3DGS压缩，数据量大，压缩困难<br />- 方法：三平面编码，KNN解码，位置信息，自适应波let损失<br />- 效果：SOTA结果，多数据集验证|
|🆕 发布|EVolSplat: Efficient Volume-based Gaussian Splatting for Urban View Synthesis|EVolSplat：高效基于体积的高斯分层渲染用于城市视图合成|Sheng Miao, Jiaxin Huang, Dongfeng Bai, Xu Yan, Hongyu Zhou, Yue Wang, Bingbing Liu, Andreas Geiger .etc.|<http://arxiv.org/pdf/2503.20168v1>|- 问题：城市场景，实时渲染，多视图不一致<br />- 方法：3D卷积网络，3D高斯混合，灵活背景模型<br />- 效果：高效，真实感，实时|


### 可控渲染 (Controllable Rendering)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Pluggable Style Representation Learning for Multi-Style Transfer|可插拔风格表示学习用于多风格迁移|Hongda Liu, Longguang Wang, Weijun Guan, Ye Zhang, Yulan Guo|<http://arxiv.org/pdf/2503.20368v1>|[[代码]](<https://github.com/The-Learning-And-Vision-Atelier-LAVA/SaMST.>)<br />- 问题：风格多样性，模型规模，计算成本<br />- 方法：风格表示学习，SaMST网络，可插拔风格表示<br />- 效果：高效，准确性高|


## 定位与映射 (Localization & Mapping)


### 视觉SLAM (Visual SLAM)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Robust Flower Cluster Matching Using The Unscented Transform|鲁棒的花簇匹配：基于无迹变换|Andy Chu, Rashik Shrestha, Yu Gu, Jason N. Gross|<http://arxiv.org/pdf/2503.20631v1>|- 问题：花簇匹配，图像注册，植物生长变化<br />- 方法：Unscented Transform，RGB-D数据，不确定性估计<br />- 效果：鲁棒性，动态环境，机器人授粉|
|🆕 发布|Synthetic-to-Real Self-supervised Robust Depth Estimation via Learning with Motion and Structure Priors|基于运动和结构先验的合成到真实自监督鲁棒深度估计|Weilong Yan, Ming Li, Haipeng Li, Shuwei Shao, Robby T. Tan|<http://arxiv.org/pdf/2503.20211v1>|- 问题：深度估计，合成到真实，鲁棒性<br />- 方法：运动结构先验，一致性重加权，深度分布约束<br />- 效果：性能提升，泛化能力强|


### 位姿估计 (Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Comparison of marker-less 2D image-based methods for infant pose estimation|无标记二维图像婴儿姿态估计方法比较|Lennart Jahn, Sarah Flügge, Dajie Zhang, Luise Poustka, Sven Bölte, Florentin Wörgötter, Peter B Marschik, Tomas Kulvicius|<http://arxiv.org/pdf/2410.04980v3>|- 问题：婴儿姿态估计，2D图像，方法比较<br />- 方法：ViTPose模型，数据重训练，视角比较<br />- 效果：模型适用，视角提升|
|📝 更新|HumanDiT: Pose-Guided Diffusion Transformer for Long-form Human Motion Video Generation|人类DiT：姿态引导的扩散变换器用于长格式人体运动视频生成|Qijun Gan, Yi Ren, Chen Zhang, Zhenhui Ye, Pan Xie, Xiang Yin, Zehuan Yuan, Bingyue Peng .etc.|<http://arxiv.org/pdf/2502.04847v3>|- 问题：人体动作视频生成，细节渲染，视觉一致性<br />- 方法：姿态引导，扩散Transformer，多分辨率，前缀潜在参考<br />- 效果：高保真，长序列，姿态准确|
|🆕 发布|DINeMo: Learning Neural Mesh Models with no 3D Annotations|DINeMo：无需3D标注学习神经网格模型|Weijie Guo, Guofeng Zhang, Wufei Ma, Alan Yuille|<http://arxiv.org/pdf/2503.20220v1>|[[代码]](<https://analysis-by-synthesis.github.io/DINeMo>)<br />- 问题：3D标注依赖，类别限制，扩展性差<br />- 方法：无标注训练，伪对应生成，双向方法<br />- 效果：性能提升，效率高|
|🆕 发布|Reasoning and Learning a Perceptual Metric for Self-Training of Reflective Objects in Bin-Picking with a Low-cost Camera|推理与学习感知度量以实现低成本相机在分拣反射物体中的自训练|Peiyuan Ni, Chee Meng Chew, Marcelo H. Ang Jr., Gregory S. Chirikjian|<http://arxiv.org/pdf/2503.20207v1>|- 问题：低成本相机，反射物体，稀疏深度，手动标注<br />- 方法：MoPR算法，SaL-BGMM，WR-InfoNCE损失<br />- 效果：性能提升，自训练|


## 自监督学习 (Self-supervised Learning)


### 一致性学习 (Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Free4D: Tuning-free 4D Scene Generation with Spatial-Temporal Consistency|Free4D：无需调优的基于时空一致性的4D场景生成|Tianqi Liu, Zihao Huang, Zhaoxi Chen, Guangcong Wang, Shoukang Hu, Liao Shen, Huiqiang Sun, Zhiguo Cao .etc.|<http://arxiv.org/pdf/2503.20785v1>|- 问题：单图4D场景生成，效率低，泛化能力差<br />- 方法：预训练模型，图像到视频扩散，自适应引导机制<br />- 效果：实时渲染，空间时间一致性|


## 迁移与适应 (Transfer & Adaptation)


### 域适应 (Domain Adaptation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Networking Systems for Video Anomaly Detection: A Tutorial and Survey|视频异常检测的网络安全系统：教程与综述|Jing Liu, Yang Liu, Jieyu Lin, Jielin Li, Liang Cao, Peng Sun, Bo Hu, Liang Song .etc.|<http://arxiv.org/pdf/2405.10347v3>|[[代码]](<https://github.com/fdjingliu/NSVAD.>)<br />- 问题：视频异常检测，网络安全，隐私保护<br />- 方法：深度学习，边缘计算，网络系统<br />- 效果：进展显著，应用广泛|
|🆕 发布|Demand Estimation with Text and Image Data|基于文本和图像数据的需求数量估计|Giovanni Compiani, Ilya Morozov, Stephan Seiler|<http://arxiv.org/pdf/2503.20711v1>|- 问题：需求估计，文本图像数据，替代模式<br />- 方法：深度学习模型，嵌入，随机系数对数模型<br />- 效果：超越标准模型，准确预测|
|🆕 发布|TerraTorch: The Geospatial Foundation Models Toolkit|地球火炬：地理空间基础模型工具包|Carlos Gomes, Benedikt Blumenstiel, Joao Lucas de Sousa Almeida, Pedro Henrique de Oliveira, Paolo Fraccaro, Francesc Marti Escofet, Daniela Szwarcman, Naomi Simumba .etc.|<http://arxiv.org/pdf/2503.20563v1>|[[代码]](<https://github.com/IBM/terratorch>)<br />- 问题：地学模型，微调，基准测试<br />- 方法：PyTorch Lightning，数据模块，模型工厂<br />- 效果：降低时间，提高效率|
|📝 更新|Towards Real-World Test-Time Adaptation: Tri-Net Self-Training with Balanced Normalization|迈向真实世界测试时自适应：平衡归一化的Tri-Net自训练|Yongyi Su, Xun Xu, Kui Jia|<http://arxiv.org/pdf/2309.14949v2>|[[代码]](<https://github.com/Gorilla-Lab-SCUT/TRIBE.>)<br />- 问题：真实场景测试时自适应，数据不平衡，持续领域偏移<br />- 方法：平衡归一化，自训练，锚定损失<br />- 效果：性能提升，SOTA|
|📝 更新|Fine-Grained Domain Generalization with Feature Structuralization|精细粒度领域泛化与特征结构化|Wenlong Yu, Dongyue Chen, Qilong Wang, Qinghua Hu|<http://arxiv.org/pdf/2406.09166v3>|- 问题：FGDG，特征易受干扰，模型性能下降<br />- 方法：特征结构化，多粒度知识，联合优化<br />- 效果：性能提升6.2%，鲁棒性增强|


### 增量学习 (Incremental Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|IAP: Improving Continual Learning of Vision-Language Models via Instance-Aware Prompting|IAP：通过实例感知提示改进视觉-语言模型的持续学习|Hao Fu, Hanbin Zhao, Jiahua Dong, Chao Zhang, Hui Qian|<http://arxiv.org/pdf/2503.20612v1>|[[代码]](<https://github.com/FerdinandZJU/IAP.>)<br />- 问题：MCIL，遗忘，PEFT，prompt tuning<br />- 方法：Instance-Aware Prompting，IA-GP，IA-CDDP<br />- 效果：有效适应，降低遗忘|


### 元学习 (Meta Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Socratic Planner: Self-QA-Based Zero-Shot Planning for Embodied Instruction Following|苏格拉底计划者：基于自我问答的零样本具身指令遵循规划|Suyeon Shin, Sujin jeon, Junghyun Kim, Gi-Cheon Kang, Byoung-Tak Zhang|<http://arxiv.org/pdf/2404.15190v2>|- 问题：EIF，任务规划，零样本学习，自然语言指令<br />- 方法：Socratic Planner，自问自答，视觉反馈，重规划机制<br />- 效果：超越SOTA，长时任务，机器人应用|
|📝 更新|One Framework to Rule Them All: Unifying RL-Based and RL-Free Methods in RLHF|统一强化学习与无强化学习方法在强化学习与人类反馈（RLHF）中的框架：一统天下|Xin Cai|<http://arxiv.org/pdf/2503.19523v2>|- 问题：RLHF，LRMs，方法统一<br />- 方法：神经结构化赌博机预测，GRO框架<br />- 效果：方法整合，实证验证|
|🆕 发布|Faster Parameter-Efficient Tuning with Token Redundancy Reduction|更快的参数高效调优：通过标记冗余减少|Kwonyoung Kim, Jungin Park, Jin Kim, Hyeongjun Kwon, Kwanghoon Sohn|<http://arxiv.org/pdf/2503.20282v1>|- 问题：PET效率低，延迟高，计算开销大<br />- 方法：FPET，token冗余减少，适配器，直通估计<br />- 效果：推理快，内存高效，性能优|
|🆕 发布|InsViE-1M: Effective Instruction-based Video Editing with Elaborate Dataset Construction|InsViE-1M：基于有效指令的视频编辑与精心构建的数据集|Yuhui Wu, Liyi Chen, Ruibin Li, Shihao Wang, Chenxi Xie, Lei Zhang|<http://arxiv.org/pdf/2503.20287v1>|- 问题：视频编辑，数据集，低质量，训练困难<br />- 方法：高质量数据集，编辑过滤，多阶段学习<br />- 效果：性能提升，模型训练|
|📝 更新|Stealthy Backdoor Attack in Self-Supervised Learning Vision Encoders for Large Vision Language Models|隐蔽后门攻击在大视觉语言模型的自监督学习视觉编码器中|Zhaoyi Liu, Huan Zhang|<http://arxiv.org/pdf/2502.18290v3>|- 问题：视觉编码器，后门攻击，视觉语言模型，安全漏洞<br />- 方法：BadVision，触发优化，后门学习<br />- 效果：高成功率，视觉理解误差，隐蔽性|


## 鲁棒学习 (Robust Learning)


### 对抗训练 (Adversarial Training)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DexHandDiff: Interaction-aware Diffusion Planning for Adaptive Dexterous Manipulation|DexHandDiff：感知交互的扩散规划以实现自适应灵巧操作|Zhixuan Liang, Yao Mu, Yixiao Wang, Tianxing Chen, Wenqi Shao, Wei Zhan, Masayoshi Tomizuka, Ping Luo .etc.|<http://arxiv.org/pdf/2411.18562v5>|- 问题：复杂交互，扩散规划，适应性，鬼状态<br />- 方法：交互感知，双阶段扩散，动态模型，语言模型<br />- 效果：成功率提升，泛化能力强|
|📝 更新|MuseTalk: Real-Time High-Fidelity Video Dubbing via Spatio-Temporal Sampling|MuseTalk：基于时空采样的实时高保真视频配音|Yue Zhang, Zhizhou Zhong, Minhao Liu, Zhaokang Chen, Bin Wu, Yubin Zeng, Chao Zhan, Yingjie He .etc.|<http://arxiv.org/pdf/2410.10122v3>|[[代码]](<https://github.com/TMElyralab/MuseTalk>)<br />- 问题：实时视频配音，身份一致性，唇同步<br />- 方法：两阶段训练，信息帧采样，动态边缘采样<br />- 效果：高视觉保真度，唇同步精度|
|📝 更新|AvatarArtist: Open-Domain 4D Avatarization|AvatarArtist：开放域4D虚拟化身|Hongyu Liu, Xuan Wang, Ziyu Wan, Yue Ma, Jingye Chen, Yanbo Fan, Yujun Shen, Yibing Song .etc.|<http://arxiv.org/pdf/2503.19906v2>|- 问题：开放域4D头像，风格任意，数据分布多样<br />- 方法：参数三平面，GANs与扩散模型，多域数据集<br />- 效果：高质量4D头像，强鲁棒性|


### 对抗防御 (Adversarial Defense)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UWarp: A Whole Slide Image Registration Pipeline to Characterize Scanner-Induced Local Domain Shift|UWarp：一种用于表征扫描仪诱导的局部域移位的全切片图像配准管道|Antoine Schieb, Bilal Hadjadji, Daniel Tshokola Mweze, Natalia Fernanda Valderrama, Valentin Derangère, Laurent Arnould, Sylvain Ladoire, Alain Lalande .etc.|<http://arxiv.org/pdf/2503.20653v1>|- 问题：扫描域偏移，局部域偏移分析，深度学习模型影响<br />- 方法：UWarp，层次注册，局部校正<br />- 效果：精度提升，时间减少|
|🆕 发布|Lipschitz Constant Meets Condition Number: Learning Robust and Compact Deep Neural Networks|李普希茨常数与条件数相遇：学习鲁棒且紧凑的深度神经网络|Yangqi Feng, Shing-Ho J. Lin, Baoyuan Gao, Xian Wei|<http://arxiv.org/pdf/2503.20454v1>|- 问题：压缩DNN，精度下降，对抗攻击<br />- 方法：TSCNC约束，条件数降低，Lipschitz常数<br />- 效果：鲁棒性提升，高压缩率|
|🆕 发布|Siformer: Feature-isolated Transformer for Efficient Skeleton-based Sign Language Recognition|Siformer：基于骨架的体态语言识别的高效特征隔离Transformer|Muxin Pu, Mei Kuan Lim, Chun Yong Chong|<http://arxiv.org/pdf/2503.20436v1>|- 问题：手部姿态，数据缺失，复杂度差异<br />- 方法：手部姿态校正，特征隔离机制，输入自适应推理<br />- 效果：SOTA性能，精度提升|
|📝 更新|Hi-ALPS -- An Experimental Robustness Quantification of Six LiDAR-based Object Detection Systems for Autonomous Driving|Hi-ALPS -- 六种基于激光雷达的自动驾驶目标检测系统的实验鲁棒性量化|Alexandra Arzberger, Ramin Tavakoli Kolagari|<http://arxiv.org/pdf/2503.17168v2>|- 问题：LiDAR OD鲁棒性，对抗样本，测试<br />- 方法：Hi-ALPS，层次化，对抗扰动<br />- 效果：鲁棒性量化，方法适用性|


### 对抗攻击 (Adversarial Attack)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|The mathematics of adversarial attacks in AI -- Why deep learning is unstable despite the existence of stable neural networks|人工智能中对抗攻击的数学——为什么深度学习尽管存在稳定的神经网络仍然是不稳定的|Alexander Bastounis, Anders C Hansen, Verner Vlačić|<http://arxiv.org/pdf/2109.06098v2>|- 问题：深度学习不稳定，对抗攻击，神经网络<br />- 方法：数学悖论，变量维度，存在性证明<br />- 效果：揭示悖论，算法挑战|
|🆕 发布|Enabling Heterogeneous Adversarial Transferability via Feature Permutation Attacks|通过特征置换攻击实现异构对抗迁移性|Tao Wu, Tie Luo|<http://arxiv.org/pdf/2503.20310v1>|- 问题：异构架构，对抗迁移性差<br />- 方法：特征重排，无参数，零FLOP<br />- 效果：攻击成功率提升，泛化能力强|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Trial to Triumph: Advancing Long Video Understanding via Visual Context Sample Scaling and Self-reward Alignment|从试错到胜利：通过视觉上下文样本缩放和自奖励对齐推进长视频理解|Yucheng Suo, Fan Ma, Linchao Zhu, Tianyi Wang, Fengyun Rao, Yi Yang|<http://arxiv.org/pdf/2503.20472v1>|- 问题：长视频理解，信息遗漏，模型限制<br />- 方法：视觉上下文采样，自奖励对齐，多模态模型<br />- 效果：性能提升，正确率提高|
|🆕 发布|SpikeDerain: Unveiling Clear Videos from Rainy Sequences Using Color Spike Streams|SpikeDerain：利用颜色尖峰流揭示雨景序列中的清晰视频|Hanwen Liang, Xian Zhong, Wenxuan Liu, Yajing Zheng, Wenxin Huang, Zhaofei Yu, Tiejun Huang|<http://arxiv.org/pdf/2503.20315v1>|- 问题：雨景视频去雨，动态场景感知，数据稀缺<br />- 方法：色脉冲流去雨网络，雨迹合成模型<br />- 效果：鲁棒性，效果显著|


## 模型压缩加速 (Model Compression & Acceleration)


### 知识蒸馏 (Knowledge Distillation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|High Quality Diffusion Distillation on a Single GPU with Relative and Absolute Position Matching|高质量单GPU扩散蒸馏：基于相对和绝对位置匹配|Guoqiang Zhang, Kenta Niwa, J. P. Lewis, Cedric Mesnage, W. Bastiaan Kleijn|<http://arxiv.org/pdf/2503.20744v1>|- 问题：GPU资源限制，高分辨率生成，训练效率<br />- 方法：RAPM，相对绝对位置匹配，单GPU训练<br />- 效果：高效，高FID分数|
|🆕 发布|Vision as LoRA|视觉作为LoRA|Han Wang, Yongjie Ye, Bingru Li, Yuxiang Nie, Jinghui Lu, Jingqun Tang, Yanjie Wang, Can Huang|<http://arxiv.org/pdf/2503.20680v1>|[[代码]](<https://github.com/Hon-Wong/VoRA.>)<br />- 问题：LLM视觉能力，外部模块，结构复杂<br />- 方法：LoRA层，内部视觉能力，块级蒸馏<br />- 效果：性能相当，训练加速|
|🆕 发布|Small Object Detection: A Comprehensive Survey on Challenges, Techniques and Real-World Applications|小目标检测：挑战、技术和实际应用综述|Mahya Nikouei, Bita Baroutian, Shahabedin Nabavi, Fateme Taraghi, Atefe Aghaei, Ayoob Sajedi, Mohsen Ebrahimi Moghaddam|<http://arxiv.org/pdf/2503.20516v1>|- 问题：小目标检测，挑战，低分辨率，遮挡，背景干扰<br />- 方法：多尺度特征，超分辨率，注意力机制，Transformer架构<br />- 效果：效率提升，应用广泛|
|🆕 发布|Incremental Object Keypoint Learning|增量目标关键点学习|Mingfu Liang, Jiahuan Zhou, Xu Zou, Ying Wu|<http://arxiv.org/pdf/2503.20248v1>|- 问题：关键点检测，泛化能力，迁移学习<br />- 方法：增量学习，知识关联，空间蒸馏<br />- 效果：遗忘缓解，性能提升|
|📝 更新|MonoTAKD: Teaching Assistant Knowledge Distillation for Monocular 3D Object Detection|MonoTAKD：单目3D目标检测的知识蒸馏教学助手|Hou-I Liu, Christine Wu, Jen-Hao Cheng, Wenhao Chai, Shian-Yun Wang, Gaowen Liu, Hugo Latapie, Jhih-Ciang Wu .etc.|<http://arxiv.org/pdf/2404.04910v3>|[[代码]](<https://github.com/hoiliu-0801/MonoTAKD.>)<br />- 问题：深度模糊，知识迁移，3D检测<br />- 方法：教学助手模型，3D空间线索，特征差异<br />- 效果：性能提升，泛化能力强|
|📝 更新|Joint Learning for Scattered Point Cloud Understanding with Hierarchical Self-Distillation|联合学习用于分层自蒸馏的散乱点云理解|Kaiyue Zhou, Ming Dong, Peiyuan Zhi, Shengjin Wang|<http://arxiv.org/pdf/2312.16902v3>|- 问题：点云理解，稀疏性，完整性<br />- 方法：级联架构，自蒸馏，层次化<br />- 效果：性能提升，信息瓶颈|


### 网络剪枝 (Network Pruning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SURGEON: Memory-Adaptive Fully Test-Time Adaptation via Dynamic Activation Sparsity|SURGEON：通过动态激活稀疏性的记忆自适应全测试时自适应|Ke Ma, Jiaqi Tang, Bin Guo, Fan Dang, Sicong Liu, Zhui Zhu, Lei Wu, Cheng Fang .etc.|<http://arxiv.org/pdf/2503.20354v1>|- 问题：测试时适应性，内存限制，模型精度<br />- 方法：动态激活稀疏，梯度重要性，层激活内存<br />- 效果：内存减少，精度提升|


## 泛化与鲁棒性 (Generalization & Robustness)


### 不确定性建模 (Uncertainty Modeling)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Recovering Dynamic 3D Sketches from Videos|从视频中恢复动态3D草图|Jaeah Lee, Changwoon Choi, Young Min Kim, Jaesik Park|<http://arxiv.org/pdf/2503.20321v1>|- 问题：3D运动理解，视频，动态草图<br />- 方法：Liv3Stroke，3D曲线，运动抽象<br />- 效果：鲁棒性，直接分析|


### 域泛化 (Domain Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|COB-GS: Clear Object Boundaries in 3DGS Segmentation Based on Boundary-Adaptive Gaussian Splitting|COB-GS：基于边界自适应高斯分割的3DGS分割中清晰物体边界|Jiaxin Zhang, Junjun Jiang, Youyu Chen, Kui Jiang, Xianming Liu|<http://arxiv.org/pdf/2503.19443v2>|[[代码]](<https://github.com/ZestfulJX/COB-GS.>)<br />- 问题：3DGS分割，边界模糊，语义指导缺失<br />- 方法：边界自适应高斯分割，语义梯度统计，视觉优化<br />- 效果：精度提升，边界清晰，视觉质量高|


## 可解释性 (Interpretability)


### 归因分析 (Attribution Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|TopV-Nav: Unlocking the Top-View Spatial Reasoning Potential of MLLM for Zero-shot Object Navigation|TopV-Nav：解锁多语言语言模型（MLLM）在零样本物体导航中的俯视图空间推理潜力|Linqing Zhong, Chen Gao, Zihan Ding, Yue Liao, Huimin Ma, Shifeng Zhang, Xu Zhou, Si Liu|<http://arxiv.org/pdf/2411.16425v2>|- 问题：ZSON，空间信息，LLM，导航<br />- 方法：TopV-Nav，AVPG，DMS，PTD<br />- 效果：优越性，MP3D，HM3D|
|📝 更新|Towards Visual Discrimination and Reasoning of Real-World Physical Dynamics: Physics-Grounded Anomaly Detection|面向真实世界物理动态的可视区分与推理：基于物理的异常检测|Wenqiao Li, Yao Gu, Xintao Chen, Xiaohao Xu, Ming Hu, Xiaonan Huang, Yingna Wu|<http://arxiv.org/pdf/2503.03562v3>|[[代码]](<https://guyao2023.github.io/Phys-AD>)<br />- 问题：工业异常检测，物理理解，视觉推理<br />- 方法：Physics-AD数据集，物理异常检测，PAEval指标<br />- 效果：基准测试，物理异常解释|
|📝 更新|Attention IoU: Examining Biases in CelebA using Attention Maps|注意力IoU：使用注意力图检验CelebA中的偏差|Aaron Serianni, Tyler Zhu, Olga Russakovsky, Vikram V. Ramaswamy|<http://arxiv.org/pdf/2503.19846v2>|- 问题：模型偏差，内部工作，特征识别<br />- 方法：Attention-IoU，注意力图，内部表示<br />- 效果：揭示偏差，识别特征，发现变量|
|📝 更新|Explaining Deep Convolutional Neural Networks for Image Classification by Evolving Local Interpretable Model-agnostic Explanations|通过进化局部可解释模型无关解释来解释用于图像分类的深度卷积神经网络|Bin Wang, Wenbin Pei, Bing Xue, Mengjie Zhang|<http://arxiv.org/pdf/2211.15143v3>|- 问题：可解释性，深度学习，图像分类<br />- 方法：遗传算法，模型无关，进化解释<br />- 效果：快速解释，提高置信度|


## 医学影像分析 (Medical Image Analysis)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|R-LiViT: A LiDAR-Visual-Thermal Dataset Enabling Vulnerable Road User Focused Roadside Perception|R-LiViT：一个面向易受伤害道路使用者道路侧感知的激光雷达-视觉-热成像数据集|Jonas Mirlach, Lei Wan, Andreas Wiedholz, Hannan Ejaz Keen, Andreas Eich|<http://arxiv.org/pdf/2503.17122v2>|- 问题：路边感知，VRU检测，数据集，极端光照<br />- 方法：LiDAR-RGB-thermal融合，多场景，多时间<br />- 效果：全面资源，公开数据|


### 医学分割 (Medical Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation|基于极坐标正弦函数的片段扭曲直观轴向增强用于医学切片分割|Yiqin Zhang, Qingkui Chen, Chen Huang, Zhengjie Zhang, Meiling Chen, Zhibing Fu|<http://arxiv.org/pdf/2412.03352v2>|[[代码]](<https://github.com/MGAMZ/PSBPD.>)<br />- 问题：医学图像分割，数据增强，机制不明确<br />- 方法：极坐标，正弦扭曲，分段仿射<br />- 效果：精度提升，临床应用|
|📝 更新|PG-SAM: Prior-Guided SAM with Medical for Multi-organ Segmentation|PG-SAM：基于医学先验的SAM多器官分割|Yiheng Zhong, Zihong Luo, Chengzhi Liu, Feilong Tang, Zelin Peng, Ming Hu, Yingzhen Hu, Jionglong Su .etc.|<http://arxiv.org/pdf/2503.18227v3>|[[代码]](<https://github.com/logan-0623/PG-SAM.>)<br />- 问题：医学图像分割，精度低，模态融合<br />- 方法：细粒度模态对齐，多级特征融合，迭代优化<br />- 效果：性能提升，最佳表现|
|🆕 发布|Attention Xception UNet (AXUNet): A Novel Combination of CNN and Self-Attention for Brain Tumor Segmentation|注意力Xception UNet（AXUNet）：一种用于脑肿瘤分割的CNN与自注意力新组合|Farzan Moodi, Fereshteh Khodadadi Shoushtari, Gelareh Valizadeh, Dornaz Mazinani, Hanieh Mobarak Salari, Hamidreza Saligheh Rad|<http://arxiv.org/pdf/2503.20446v1>|- 问题：脑肿瘤分割，诊断，治疗<br />- 方法：Xception，自注意力，UNet<br />- 效果：Dice分数提升，肿瘤分割准确|
|📝 更新|OverLoCK: An Overview-first-Look-Closely-next ConvNet with Context-Mixing Dynamic Kernels|OverLoCK：一种以概述-先看-再仔细看的卷积神经网络及其上下文混合动态核|Meng Lou, Yizhou Yu|<http://arxiv.org/pdf/2502.20087v2>|- 问题：卷积神经网络，生物视觉，上下文建模<br />- 方法：自上而下注意力，动态卷积，上下文混合<br />- 效果：性能提升，效率高|
|📝 更新|VesselSAM: Leveraging SAM for Aortic Vessel Segmentation with LoRA and Atrous Attention|血管SAM：利用SAM进行升主动脉血管分割的LoRA和扩张注意力|Adnan Iltaf, Rayan Merghani Ahmed, Zhenxi Zhang, Bin Li, Shoujun Zhou|<http://arxiv.org/pdf/2502.18185v3>|[[代码]](<https://github.com/Adnan-CAS/AtrousLora.>)<br />- 问题：血管分割，小尺寸，复杂边缘，噪声<br />- 方法：VesselSAM，AtrousLoRA，LoRA，Atrous Attention<br />- 效果：高精度，低计算量|
|🆕 发布|Mamba-3D as Masked Autoencoders for Accurate and Data-Efficient Analysis of Medical Ultrasound Videos|Mamba-3D：用于准确且数据高效分析医学超声视频的掩码自编码器|Jiaheng Zhou, Yanfeng Zhou, Wei Fang, Yuxing Tang, Le Lu, Ge Yang|<http://arxiv.org/pdf/2503.20258v1>|- 问题：超声视频分析，数据稀缺，视频分析挑战<br />- 方法：E-ViM$^3$，3D结构，Enclosure Global Tokens，masked video modeling<br />- 效果：数据高效，性能领先，少样本学习|
|🆕 发布|Assessing SAM for Tree Crown Instance Segmentation from Drone Imagery|评估无人机影像中树冠实例分割的SAM|Mélisande Teng, Arthur Ouaknine, Etienne Laliberté, Yoshua Bengio, David Rolnick, Hugo Larochelle|<http://arxiv.org/pdf/2503.20199v1>|- 问题：树种植监测，自动分割，无人机图像<br />- 方法：SAM，Mask R-CNN，DSM信息<br />- 效果：性能提升，预测改进|
|📝 更新|CamSAM2: Segment Anything Accurately in Camouflaged Videos|CamSAM2：在伪装视频中准确分割任何事物|Yuli Zhou, Guolei Sun, Yawei Li, Yuqian Fu, Luca Benini, Ender Konukoglu|<http://arxiv.org/pdf/2503.19730v2>|[[代码]](<https://github.com/zhoustan/CamSAM2.>)<br />- 问题：VCOS，camouflaged videos，segmentation<br />- 方法：CamSAM2，decamouflaged token，IOF，EOF，OPG<br />- 效果：mDice gains，MoCA-Mask，SUN-SEG-Hard|


### 影像重建 (Image Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Scale-Equivariant Imaging: Self-Supervised Learning for Image Super-Resolution and Deblurring|尺度等变成像：图像超分辨率和去模糊的自监督学习|Jérémy Scanvic, Mike Davies, Patrice Abry, Julián Tachella|<http://arxiv.org/pdf/2312.11232v3>|- 问题：图像超分辨率，去模糊，自监督学习<br />- 方法：尺度等变成像，低频信息利用<br />- 效果：性能提升，与监督学习相当|
|🆕 发布|Devil is in the Uniformity: Exploring Diverse Learners within Transformer for Image Restoration|恶魔隐藏在统一性：探索Transformer图像修复中的多样性学习者|Shihao Zhou, Dayu Li, Jinshan Pan, Juncheng Zhou, Jinglei Shi, Jufeng Yang|<http://arxiv.org/pdf/2503.20174v1>|- 问题：Transformer, 图像恢复, 多头注意力, 红冗余<br />- 方法：HINT模型，HMHA，QKCU模块<br />- 效果：性能提升，图像质量高|


### 疾病诊断 (Disease Diagnosis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vision-Amplified Semantic Entropy for Hallucination Detection in Medical Visual Question Answering|医学视觉问答中的幻觉检测：视觉增强语义熵|Zehui Liao, Shishuai Hu, Ke Zou, Huazhu Fu, Liangli Zhen, Yong Xia|<http://arxiv.org/pdf/2503.20504v1>|- 问题：幻觉检测，医疗VQA，语义熵<br />- 方法：视觉增强，弱扰动，对比分布<br />- 效果：优于现有方法|
|🆕 发布|3D Convolutional Neural Networks for Improved Detection of Intracranial bleeding in CT Imaging|3D卷积神经网络在CT影像中提高颅内出血检测的准确性|Bargava Subramanian, Naveen Kumarasami, Praveen Shastry, Kalyan Sivasailam, Anandakumar D, Elakkiya R, Harsha KG, Rithanya V .etc.|<http://arxiv.org/pdf/2503.20306v1>|- 问题：颅内出血检测，诊断速度慢，准确性低<br />- 方法：3D CNN，图像预处理，U型网络架构<br />- 效果：高精度，高召回率，临床可靠性|
|📝 更新|CATD: Unified Representation Learning for EEG-to-fMRI Cross-Modal Generation|CATD：EEG-to-fMRI跨模态生成的统一表示学习|Weiheng Yao, Zhihan Lyu, Mufti Mahmud, Ning Zhong, Baiying Lei, Shuqiang Wang|<http://arxiv.org/pdf/2408.00777v3>|- 问题：多模态神经影像，成本高，可用性低<br />- 方法：CATD框架，条件对齐，时间频率分割<br />- 效果：预测精度提升，诊断准确度增强|
|📝 更新|A Multimodal Vision Foundation Model for Clinical Dermatology|多模态视觉基础模型在临床皮肤病学中的应用|Siyuan Yan, Zhen Yu, Clare Primiero, Cristina Vico-Alonso, Zhonghua Wang, Litao Yang, Philipp Tschandl, Ming Hu .etc.|<http://arxiv.org/pdf/2410.15038v2>|- 问题：皮肤疾病诊断，多模态信息，深度学习模型<br />- 方法：PanDerm，自监督学习，多机构数据<br />- 效果：性能领先，临床应用潜力|


## 智能驾驶 (Intelligent Driving)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Cherry Yield Forecast: Harvest Prediction for Individual Sweet Cherry Trees|樱桃产量预测：单株甜樱桃树收获预测|Andreas Gilson, Peter Pietrzyk, Chiara Paglia, Annika Killer, Fabian Keil, Lukas Meyer, Dominikus Kittemann, Patrick Noack .etc.|<http://arxiv.org/pdf/2503.20419v1>|- 问题：可靠产量预测，早期季节，图像计数，果实状态<br />- 方法：线性回归，时间点选择，图像数据自动化<br />- 效果：手动计数，预测准确性|
|📝 更新|Human Motion Instruction Tuning|人类运动指令微调|Lei Li, Sen Jia, Jianhao Wang, Zhongyu Jiang, Feng Zhou, Ju Dai, Tianfang Zhang, Zongkai Wu .etc.|<http://arxiv.org/pdf/2411.16805v4>|[[代码]](<https://github.com/ILGLJ/LLaMo.>)<br />- 问题：运动指令调整，行为理解，预测<br />- 方法：保留运动数据，多模态分析，领域知识捕获<br />- 效果：提升理解，增强预测|
|📝 更新|UniHDSA: A Unified Relation Prediction Approach for Hierarchical Document Structure Analysis|统一层次文档结构分析的关系预测方法：UniHDSA|Jiawei Wang, Kai Hu, Qiang Huo|<http://arxiv.org/pdf/2503.15893v2>|[[代码]](<https://github.com/microsoft/CompHRDoc.>)<br />- 问题：文档结构分析，层次结构恢复<br />- 方法：统一关系预测，Transformer架构<br />- 效果：性能领先，多任务处理|


### 轨迹预测 (Trajectory Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Vision-based Multi-future Trajectory Prediction: A Survey|基于视觉的多未来轨迹预测：综述|Renhao Huang, Hao Xue, Maurice Pagnucco, Flora Salim, Yang Song|<http://arxiv.org/pdf/2302.10463v2>|- 问题：多未来轨迹预测，行为多样性，不确定性<br />- 方法：独特分类法，框架分析，数据集评估<br />- 效果：模型比较，实验验证|


### 环境感知 (Environment Perception)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GM-MoE: Low-Light Enhancement with Gated-Mechanism Mixture-of-Experts|GM-MoE：基于门控机制的专家混合增强低光照图像|Minwen Liao, Hao Bo Dong, Xinyi Wang, Ziyang Yan, Yihua Shao|<http://arxiv.org/pdf/2503.07417v2>|- 问题：低光增强，泛化能力，任务特定<br />- 方法：混合专家网络，门控机制，特征融合<br />- 效果：性能提升，PSNR，SSIM|
|🆕 发布|Network Inversion for Generating Confidently Classified Counterfeits|网络反演生成自信分类的假币|Pirzada Suhail, Amit Sethi|<http://arxiv.org/pdf/2503.20187v1>|- 问题：生成自信分类样本，决策边界理解，模型安全<br />- 方法：网络反演，one-hot向量，KLD<br />- 效果：生成自信分类样本，挑战高置信度假设|
|📝 更新|Three Cars Approaching within 100m! Enhancing Distant Geometry by Tri-Axis Voxel Scanning for Camera-based Semantic Scene Completion|三车逼近！基于三轴体素扫描增强远程几何的相机语义场景补全|Jongseong Bae, Junwoo Ha, Ha Young Kim|<http://arxiv.org/pdf/2411.16129v2>|- 问题：远距离几何估计，视角，遮挡，语义场景补全<br />- 方法：Tri-Axis Voxel Scanning，Scan Module，Scan Loss<br />- 效果：性能提升，IoU，mIoU|


## 工业视觉 (Industrial Vision)


### 质量控制 (Quality Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Oasis: One Image is All You Need for Multimodal Instruction Data Synthesis|绿洲：一张图片就足以用于多模态指令数据合成|Letian Zhang, Quan Cui, Bingchen Zhao, Cheng Yang|<http://arxiv.org/pdf/2503.08741v3>|[[代码]](<https://github.com/Letian2003/MM_INF.>)<br />- 问题：隐私数据，多模态数据，合成，质量，多样性<br />- 方法：图像提示，MLLMs，质量控制<br />- 效果：性能提升，特定领域能力|


### 缺陷检测 (Defect Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ONER: Online Experience Replay for Incremental Anomaly Detection|ONER：增量异常检测的在线经验回放|Yizhou Jin, Jiahui Zhu, Guodong Wang, Shiwei Li, Jinjin Zhang, Xinyue Liu, Qingjie Liu, Yunhong Wang|<http://arxiv.org/pdf/2412.03907v3>|- 问题：增量异常检测，灾难性遗忘，知识覆盖，特征冲突<br />- 方法：在线经验回放，动态提示，语义原型<br />- 效果：性能提升，参数少，效率高|
|🆕 发布|LogicQA: Logical Anomaly Detection with Vision Language Model Generated Questions|逻辑QA：基于视觉语言模型生成问题的逻辑异常检测|Yejin Kwon, Daeun Moon, Youngje Oh, Hyunsoo Yoon|<http://arxiv.org/pdf/2503.20252v1>|- 问题：异常检测，逻辑异常，可解释性<br />- 方法：视觉语言模型，自动生成问题，无监督学习<br />- 效果：SOTA性能，高AUROC，高F1-max|


## 其他 (Others)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Fantastic Copyrighted Beasts and How (Not) to Generate Them|神奇版权兽及其（如何）生成（或不生成）|Luxi He, Yangsibo Huang, Weijia Shi, Tinghao Xie, Haotian Liu, Yue Wang, Luke Zettlemoyer, Chiyuan Zhang .etc.|<http://arxiv.org/pdf/2406.14526v2>|- 问题：版权侵权，模型生成，版权人物，法律问题<br />- 方法：评估框架，关键词识别，半自动技术<br />- 效果：识别有效性，策略不足，负提示|

