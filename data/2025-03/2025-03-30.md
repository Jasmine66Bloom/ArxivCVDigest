## [UPDATED!] **2025-03-30** (Update Time)


## 表示学习 (Representation Learning)


### 视觉Transformer (Vision Transformers)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Reinforcement Learning-based Token Pruning in Vision Transformers: A Markov Game Approach|基于强化学习的视觉Transformer中Token剪枝：马尔可夫博弈方法|Chenglong Lu, Shen Liang, Xuewei Wang, Wei Wang|<http://arxiv.org/pdf/2503.23459v1>|[[代码]](<https://github.com/daashuai/rl4evit.>)<br />- 问题：ViT计算成本高，token剪枝策略缺乏适应性<br />- 方法：RL，Markov Game，MAPPO，奖励函数<br />- 效果：速度提升44%，精度下降0.4%|
|🆕 发布|Efficient Token Compression for Vision Transformer with Spatial Information Preserved|高效保留空间信息的视觉Transformer的Token压缩|Junzhu Mao, Yang Shen, Jinyang Guo, Yazhou Yao, Xiansheng Hua|<http://arxiv.org/pdf/2503.23455v1>|[[代码]](<https://github.com/NUST-Machine-Intelligence-Laboratory/prune_and_merge.>)<br />- 问题：Token压缩，Transformer，计算内存需求<br />- 方法：Prune and Merge，梯度加权注意力，训练恢复<br />- 效果：速度提升，精度下降小|
|📝 更新|Token Dynamics: Towards Efficient and Dynamic Video Token Representation for Video Large Language Models|视频大语言模型中高效且动态的视频标记表示：标记动力学|Haichao Zhang, Yun Fu|<http://arxiv.org/pdf/2503.16980v2>|- 问题：视频表示，LLM，效率，时空，压缩<br />- 方法：Token Dynamics，动态减少，跨动态注意力<br />- 效果：低压缩率，性能损失小|
|🆕 发布|Improved Ear Verification with Vision Transformers and Overlapping Patches|基于视觉Transformer和重叠补丁的改进耳部验证|Deeksha Arun, Kagan Ozturk, Kevin W. Bowyer, Patrick Flynn|<http://arxiv.org/pdf/2503.23275v1>|- 问题：耳识别效率低，特征捕捉不足<br />- 方法：ViT，重叠补丁策略，模型对比<br />- 效果：性能提升，准确率提高|
|🆕 发布|A Lightweight Image Super-Resolution Transformer Trained on Low-Resolution Images Only|仅基于低分辨率图像训练的轻量级图像超分辨率Transformer|Björn Möller, Lucas Görnhardt, Tim Fingscheidt|<http://arxiv.org/pdf/2503.23265v1>|[[代码]](<https://github.com/ifnspaml/SuperResolutionMultiscaleTraining.>)<br />- 问题：低分辨率图像，超分辨率，训练数据<br />- 方法：轻量级Transformer，LR-only训练，多尺度训练<br />- 效果：性能优越，CNN，Transformer|


### 预训练模型 (Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CCUP: A Controllable Synthetic Data Generation Pipeline for Pretraining Cloth-Changing Person Re-Identification Models|CCUP：一种可控合成数据生成管道，用于预训练服装变化人物重识别模型|Yujian Zhao, Chengru Wu, Yinong Xu, Xuanzheng Du, Ruiyu Li, Guanglin Niu|<http://arxiv.org/pdf/2410.13567v3>|[[代码]](<https://github.com/yjzhao1019/CCUP.>)<br />- 问题：CC-ReID数据成本高，模型泛化能力差<br />- 方法：可控合成数据生成，大规模CCUP数据集，预训练-微调框架<br />- 效果：模型性能提升，泛化能力增强|


## 生成建模 (Generative Modeling)


### 扩散模型 (Diffusion Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DiT4SR: Taming Diffusion Transformer for Real-World Image Super-Resolution|DiT4SR：驯服扩散Transformer以实现真实世界图像超分辨率|Zheng-Peng Duan, Jiawei Zhang, Xin Jin, Ziheng Zhang, Zheng Xiong, Dongqing Zou, Jimmy Ren, Chun-Le Guo .etc.|<http://arxiv.org/pdf/2503.23580v1>|[[代码]](<https://adam-duan.github.io/projects>)<br />- 问题：Real-ISR，扩散模型，图像超分辨率<br />- 方法：DiT，LR嵌入，注意力机制，交叉流卷积<br />- 效果：性能提升，实验验证|
|📝 更新|SINE: SINgle Image Editing with Text-to-Image Diffusion Models|SINE：基于文本到图像扩散模型的单图像编辑|Zhixing Zhang, Ligong Han, Arnab Ghosh, Dimitris Metaxas, Jian Ren|<http://arxiv.org/pdf/2212.04489v2>|[[代码]](<https://github.com/zhang-zx/SINE.git>)<br />- 问题：单图编辑，信息泄漏，过拟合<br />- 方法：模型指导，单图微调，基于补丁<br />- 效果：编辑能力，风格变化，内容添加|
|🆕 发布|Language-Guided Trajectory Traversal in Disentangled Stable Diffusion Latent Space for Factorized Medical Image Generation|基于解耦稳定扩散潜在空间的因子化医学图像生成中的语言引导轨迹遍历|Zahra TehraniNasab, Amar Kumar, Tal Arbel|<http://arxiv.org/pdf/2503.23623v1>|- 问题：医学图像生成，可解释性，因素解耦<br />- 方法：视觉语言模型，预训练，轨迹遍历<br />- 效果：属性因子化，精确控制|
|🆕 发布|Enhancing Creative Generation on Stable Diffusion-based Models|基于稳定扩散模型的创意生成增强|Jiyeon Han, Dahee Kwon, Gayoung Lee, Junho Kim, Jaesik Choi|<http://arxiv.org/pdf/2503.23538v1>|- 问题：创意生成能力受限，文本-图像对齐强<br />- 方法：C3，特征增强，无训练<br />- 效果：创意提升，无额外计算成本|
|📝 更新|Precise, Fast, and Low-cost Concept Erasure in Value Space: Orthogonal Complement Matters|精确、快速且低成本的值空间概念擦除：正交补很重要|Yuan Wang, Ouxiang Li, Tingting Mu, Yanbin Hao, Kuien Liu, Xiang Wang, Xiangnan He|<http://arxiv.org/pdf/2412.06143v2>|[[代码]](<https://github.com/WYuan1001/AdaVD.>)<br />- 问题：概念消除，模型预训练，低成本<br />- 方法：自适应值分解，正交补，预训练无<br />- 效果：高效，低成本，效果佳|
|📝 更新|SleeperMark: Towards Robust Watermark against Fine-Tuning Text-to-image Diffusion Models|睡眠者标记：迈向针对微调文本到图像扩散模型的鲁棒水印|Zilan Wang, Junfeng Guo, Jiacheng Zhu, Yiming Li, Heng Huang, Muhao Chen, Zhengzhong Tu|<http://arxiv.org/pdf/2412.04852v2>|[[代码]](<https://github.com/taco-group/SleeperMark.>)<br />- 问题：T2I模型，知识产权保护，模型微调，黑盒攻击<br />- 方法：SleeperMark，鲁棒水印，解耦信息<br />- 效果：抗微调，抗攻击，影响小|
|📝 更新|PlanGen: Towards Unified Layout Planning and Image Generation in Auto-Regressive Vision Language Models|PlanGen：迈向统一布局规划和图像生成在自回归视觉语言模型中|Runze He, Bo Cheng, Yuhang Ma, Qingxiang Jia, Shanyuan Liu, Ao Ma, Xiaoyu Wu, Liebucha Wu .etc.|<http://arxiv.org/pdf/2503.10127v2>|[[代码]](<https://360cvgroup.github.io/PlanGen.>)<br />- 问题：布局规划，图像生成，模型分离<br />- 方法：统一模型，自回归，布局条件集成<br />- 效果：多任务训练，布局引导|
|🆕 发布|Towards Physically Plausible Video Generation via VLM Planning|通过VLM规划实现物理合理的视频生成|Xindi Yang, Baolu Li, Yiming Zhang, Zhenfei Yin, Lei Bai, Liqian Ma, Zhiyong Wang, Jianfei Cai .etc.|<http://arxiv.org/pdf/2503.23368v1>|[[代码]](<https://madaoer.github.io/projects>)<br />- 问题：VDM物理合理性，动力学错误，事件序列不正确<br />- 方法：VLM规划，物理感知推理，运动轨迹预测<br />- 效果：物理合理运动，方法优越|
|🆕 发布|DSPFusion: Image Fusion via Degradation and Semantic Dual-Prior Guidance|DSPFusion：基于降质和语义双优先级引导的图像融合|Linfeng Tang, Chunyu Li, Guoqing Wang, Yixuan Yuan, Jiayi Ma|<http://arxiv.org/pdf/2503.23355v1>|- 问题：退化图像融合，应用受限<br />- 方法：降解先验，语义先验，扩散模型<br />- 效果：速度提升，效果优化|
|🆕 发布|Object Isolated Attention for Consistent Story Visualization|孤立对象一致性故事可视化|Xiangyang Luo, Junhao Cheng, Yifan Xie, Xin Zhang, Tao Feng, Zhou Liu, Fei Ma, Fei Yu|<http://arxiv.org/pdf/2503.23353v1>|- 问题：故事可视化，人物一致性，场景自然性<br />- 方法：Transformer模块，隔离注意力机制，预训练扩散模型<br />- 效果：训练免费，效果优于现有方法|
|🆕 发布|TraceMark-LDM: Authenticatable Watermarking for Latent Diffusion Models via Binary-Guided Rearrangement|TraceMark-LDM：基于二进制引导重排的潜在扩散模型可验证水印|Wenhao Luo, Zhangyi Shen, Ye Yao, Feng Ding, Guopu Zhu, Weizhi Meng|<http://arxiv.org/pdf/2503.23332v1>|- 问题：LDM水印，质量，鲁棒性<br />- 方法：二进制引导，变量重排，编码器微调<br />- 效果：质量提升，准确度高，攻击鲁棒|


### 生成对抗网络 (GANs)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Internal Organ Localization Using Depth Images|基于深度图像的内部器官定位|Eytan Kats, Kai Geißler, Jochen G. Hirsch, Stefan Heldman, Mattias P. Heinrich|<http://arxiv.org/pdf/2503.23468v1>|- 问题：患者定位，深度图像，内部器官<br />- 方法：学习框架，深度学习模型，MRI数据集<br />- 效果：定位准确，流程优化|
|🆕 发布|TextCrafter: Accurately Rendering Multiple Texts in Complex Visual Scenes|文本工匠：在复杂视觉场景中准确渲染多个文本|Nikai Du, Zhennan Chen, Zhizhou Chen, Shan Gao, Xi Chen, Zhengkai Jiang, Jian Yang, Ying Tai|<http://arxiv.org/pdf/2503.23461v1>|- 问题：CVTG，文本生成，图像文本，渲染挑战<br />- 方法：TextCrafter，渐进策略，文本对齐<br />- 效果：准确渲染，性能超越|
|📝 更新|Missing Target-Relevant Information Prediction with World Model for Accurate Zero-Shot Composed Image Retrieval|基于世界模型的缺失目标相关信息预测，以实现准确的零样本组合图像检索|Yuanmin Tang, Jing Yu, Keke Gai, Jiamin Zhuang, Gang Xiong, Gaopeng Gou, Qi Wu|<http://arxiv.org/pdf/2503.17109v2>|[[代码]](<https://github.com/Pter61/predicir.>)<br />- 问题：ZS-CIR，信息缺失，图像检索<br />- 方法：PrediCIR，世界模型，预测网络<br />- 效果：性能提升，新SOTA|
|🆕 发布|A Large Scale Analysis of Gender Biases in Text-to-Image Generative Models|大规模分析文本到图像生成模型中的性别偏见|Leander Girrbach, Stephan Alaniz, Genevieve Smith, Zeynep Akata|<http://arxiv.org/pdf/2503.23398v1>|- 问题：性别偏见，T2I模型，日常场景<br />- 方法：大规模数据集，自动检测，语义分组<br />- 效果：揭示性别角色，性别刻板印象|
|🆕 发布|Map Feature Perception Metric for Map Generation Quality Assessment and Loss Optimization|地图生成质量评估与损失优化的地图特征感知度量|Chenxing Sun, Jing Bai|<http://arxiv.org/pdf/2503.23370v1>|- 问题：地图生成，真实性评估，视觉相似度，语义结构<br />- 方法：地图特征感知，深度特征提取，全局属性<br />- 效果：性能提升，地理可信度|
|🆕 发布|Beyond Unimodal Boundaries: Generative Recommendation with Multimodal Semantics|超越单模态边界：基于多模态语义的生成式推荐|Jing Zhu, Mingxuan Ju, Yozen Liu, Danai Koutra, Neil Shah, Tong Zhao|<http://arxiv.org/pdf/2503.23333v1>|- 问题：多模态，生成推荐，模态选择，MGR<br />- 方法：MGR-LF++，对比模态对齐，特殊标记<br />- 效果：性能提升20%，单模态替代|
|📝 更新|Progressive Human Motion Generation Based on Text and Few Motion Frames|基于文本和少量运动帧的渐进式人类运动生成|Ling-An Zeng, Gaojie Wu, Ancong Wu, Jian-Fang Hu, Wei-Shi Zheng|<http://arxiv.org/pdf/2503.13300v2>|[[代码]](<https://github.com/qinghuannn/PMG.>)<br />- 问题：T2M方法，姿态描述，生成控制<br />- 方法：TF2M任务，PMG方法，伪帧替换<br />- 效果：效果优于T2M，生成精度高|
|🆕 发布|MoCha: Towards Movie-Grade Talking Character Synthesis|MoCha：迈向电影级对话角色合成|Cong Wei, Bo Sun, Haoyu Ma, Ji Hou, Felix Juefei-Xu, Zecheng He, Xiaoliang Dai, Luxin Zhang .etc.|<http://arxiv.org/pdf/2503.23307v1>|- 问题：电影级对话角色合成，故事叙述，动画生成<br />- 方法：MoCha，语音-视频对齐，联合训练，结构化提示模板<br />- 效果：高真实感，高表现力，高可控性|
|📝 更新|Representational Similarity via Interpretable Visual Concepts|通过可解释视觉概念实现表征相似性|Neehar Kondapaneni, Oisin Mac Aodha, Pietro Perona|<http://arxiv.org/pdf/2503.15699v2>|- 问题：网络相似度测量，可解释性，视觉概念<br />- 方法：RSVC，比较模型，发现概念<br />- 效果：模型差异分析，概念识别|
|📝 更新|D-Judge: How Far Are We? Evaluating the Discrepancies Between AI-synthesized Images and Natural Images through Multimodal Guidance|D-Judge：我们距离多远？通过多模态引导评估AI合成图像与自然图像之间的差异|Renyang Liu, Ziyu Lyu, Wei Zhou, See-Kiong Ng|<http://arxiv.org/pdf/2412.17632v2>|- 问题：AI图像差异，自然图像，生成模型<br />- 方法：D-Judge基准，多模态引导，五维度评估<br />- 效果：差距显著，人机一致性|
|🆕 发布|SketchVideo: Sketch-based Video Generation and Editing|SketchVideo：基于草图的视频生成与编辑|Feng-Lin Liu, Hongbo Fu, Xintao Wang, Weicai Ye, Pengfei Wan, Di Zhang, Lin Gao|<http://arxiv.org/pdf/2503.23284v1>|- 问题：视频生成，布局控制，运动控制，编辑<br />- 方法：DiT模型，sketch控制块，帧间注意力机制<br />- 效果：可控生成，精细编辑|


### 自回归模型 (Autoregressive Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FastVAR: Linear Visual Autoregressive Modeling via Cached Token Pruning|快速VAR：通过缓存令牌剪枝的线性视觉自回归建模|Hang Guo, Yawei Li, Taolin Zhang, Jiangshan Wang, Tao Dai, Shu-Tao Xia, Luca Benini|<http://arxiv.org/pdf/2503.23367v1>|[[代码]](<https://github.com/csguoh/FastVAR.>)<br />- 问题：VAR模型，计算复杂度高，分辨率扩展<br />- 方法：缓存token剪枝，尺度特定建模<br />- 效果：加速2.7倍，性能下降<1%，零样本生成|


## 多模态学习 (Multimodal Learning)


### 视觉语言模型 (Vision-Language Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DASH: Detection and Assessment of Systematic Hallucinations of VLMs|DASH：视觉语言模型系统性幻觉的检测与评估|Maximilian Augustin, Yannic Neuhaus, Matthias Hein|<http://arxiv.org/pdf/2503.23573v1>|[[代码]](<https://YanNeu.github.io/DASH.>)<br />- 问题：VLMs幻觉检测，开放世界，系统性错误<br />- 方法：DASH，DASH-OPT，图像检索<br />- 效果：大规模检测，幻觉缓解|
|🆕 发布|OpenDriveVLA: Towards End-to-end Autonomous Driving with Large Vision Language Action Model|OpenDriveVLA：迈向端到端自动驾驶的大视觉语言动作模型|Xingcheng Zhou, Xuyuan Han, Feng Yang, Yunpu Ma, Alois C. Knoll|<http://arxiv.org/pdf/2503.23463v1>|- 问题：自动驾驶，视觉语言模型，驾驶动作<br />- 方法：视觉语言对齐，动态关系建模，轨迹规划<br />- 效果：最先进结果，高命令遵循，稳健轨迹|
|🆕 发布|Semantic-Spatial Feature Fusion with Dynamic Graph Refinement for Remote Sensing Image Captioning|语义-空间特征融合与动态图细化用于遥感图像标题生成|Maofu Liu, Jiahui Liu, Xiaokang Zhang|<http://arxiv.org/pdf/2503.23453v1>|- 问题：语义描述，视觉特征，文本信息，对象定位<br />- 方法：语义-空间特征融合，动态图细化，图注意力网络<br />- 效果：描述质量提升，实验结果有效|
|📝 更新|OpenSDI: Spotting Diffusion-Generated Images in the Open World|开放世界中的扩散生成图像检测：OpenSDI|Yabin Wang, Zhiwu Huang, Xiaopeng Hong|<http://arxiv.org/pdf/2503.19653v2>|[[代码]](<https://github.com/iamwangyabin/OpenSDI.>)<br />- 问题：扩散生成图像识别，开放世界，数据集<br />- 方法：Synergizing Pretrained Models (SPM)，MaskCLIP<br />- 效果：性能提升，IoU，F1|
|📝 更新|F$^3$OCUS -- Federated Finetuning of Vision-Language Foundation Models with Optimal Client Layer Updating Strategy via Multi-objective Meta-Heuristics|F$^3$OCUS -- 基于多目标元启发式的最优客户端层更新策略的联邦视觉-语言基础模型微调|Pramit Saha, Felix Wagner, Divyanshu Mishra, Can Peng, Anshul Thakur, David Clifton, Konstantinos Kamnitsas, J. Alison Noble|<http://arxiv.org/pdf/2411.11912v2>|- 问题：联邦学习，视觉语言模型，参数高效微调<br />- 方法：F3OCUS，元启发式优化，多目标<br />- 效果：性能提升，数据集，实验验证|
|📝 更新|Pretrain like Your Inference: Masked Tuning Improves Zero-Shot Composed Image Retrieval|像您的推理一样预训练：掩码微调提升零样本组合图像检索|Junyang Chen, Hanjiang Lai|<http://arxiv.org/pdf/2311.07622v3>|[[代码]](<https://github.com/Chen-Junyang-cn/PLI>)<br />- 问题：ZS-CIR，预训练模型，差异，图像修改<br />- 方法：掩码调整，对比学习，文本引导<br />- 效果：性能提升，数据集验证|
|📝 更新|OpenING: A Comprehensive Benchmark for Judging Open-ended Interleaved Image-Text Generation|开放ING：用于评估开放式交错图像-文本生成的全面基准|Pengfei Zhou, Xiaopeng Peng, Jiajun Song, Chuanhao Li, Zhaopan Xu, Yue Yang, Ziyao Guo, Hao Zhang .etc.|<http://arxiv.org/pdf/2411.18499v3>|- 问题：图像-文本生成，评估基准，数据多样性<br />- 方法：OpenING基准，IntJudge模型，数据管道<br />- 效果：高一致性，性能提升|
|🆕 发布|From Panels to Prose: Generating Literary Narratives from Comics|从画板到散文：从漫画生成文学叙事|Ragav Sachdeva, Andrew Zisserman|<http://arxiv.org/pdf/2503.23344v1>|- 问题：漫画可访问性，视觉障碍，叙事生成<br />- 方法：Magiv3模型，OCR，人物定位<br />- 效果：文本叙事，深度理解|
|📝 更新|StreamChat: Chatting with Streaming Video|StreamChat：与流媒体视频聊天|Jihao Liu, Zhiding Yu, Shiyi Lan, Shihao Wang, Rongyao Fang, Jan Kautz, Hongsheng Li, Jose M. Alvare|<http://arxiv.org/pdf/2412.08646v2>|- 问题：延迟，信息滞后，交互效率低<br />- 方法：动态更新，交叉注意力，3D-RoPE机制<br />- 效果：性能提升，交互能力增强|
|🆕 发布|EagleVision: Object-level Attribute Multimodal LLM for Remote Sensing|鹰眼视觉：遥感对象级属性多模态大型语言模型|Hongxiang Jiang, Jihao Yin, Qixiong Wang, Jiaqi Feng, Guo Chen|<http://arxiv.org/pdf/2503.23330v1>|[[代码]](<https://github.com/XiangTodayEatsWhat/EagleVision.>)<br />- 问题：远程感知，对象定位，属性描述，模型性能<br />- 方法：MLLM，属性解耦，EVAttrs-95K，EVBench<br />- 效果：性能提升，对象检测，属性理解|
|🆕 发布|LaViC: Adapting Large Vision-Language Models to Visually-Aware Conversational Recommendation|LaViC：将大型视觉-语言模型适应于视觉感知对话推荐|Hyunsik Jeon, Satoshi Koide, Yu Wang, Zhankui He, Julian McAuley|<http://arxiv.org/pdf/2503.23312v1>|[[代码]](<https://github.com/jeon185/LaViC.>)<br />- 问题：视觉信息，对话推荐，个性化<br />- 方法：视觉知识自蒸馏，推荐提示调整，视觉语言模型<br />- 效果：性能提升，准确性高|
|📝 更新|MLLM-Selector: Necessity and Diversity-driven High-Value Data Selection for Enhanced Visual Instruction Tuning|MLLM-Selector：基于必要性和多样性驱动的增值数据选择以增强视觉指令微调|Yiwei Ma, Guohai Xu, Xiaoshuai Sun, Jiayi Ji, Jie Lou, Debing Zhang, Rongrong Ji|<http://arxiv.org/pdf/2503.20502v2>|- 问题：VIT数据选择，高价值数据，自动化<br />- 方法：MLLM-Selector，必要性，多样性<br />- 效果：性能提升，数据减少|
|🆕 发布|ReasonGrounder: LVLM-Guided Hierarchical Feature Splatting for Open-Vocabulary 3D Visual Grounding and Reasoning|ReasonGrounder：基于LVLM引导的分层特征散布用于开放词汇3D视觉定位与推理|Zhenyang Liu, Yikai Wang, Sixiao Zheng, Tongying Pan, Longfei Liang, Yanwei Fu, Xiangyang Xue|<http://arxiv.org/pdf/2503.23297v1>|- 问题：开放词汇，3D视觉定位，推理，遮挡<br />- 方法：LVLM引导，层次特征，Gaussian splatting<br />- 效果：精度提升，场景理解|
|📝 更新|debiaSAE: Benchmarking and Mitigating Vision-Language Model Bias|debiaSAE：视觉-语言模型偏差的基准测试与缓解|Kuleen Sasse, Shan Chen, Jackson Pond, Danielle Bitterman, John Osborne|<http://arxiv.org/pdf/2410.13146v2>|- 问题：VLMs 偏见，基准不足，公平性<br />- 方法：严格评估数据集，稀疏自编码器<br />- 效果：性能提升，公平性改善|
|📝 更新|VideoSAVi: Self-Aligned Video Language Models without Human Supervision|视频SAVi：无需人工监督的自对齐视频语言模型|Yogesh Kulkarni, Pooyan Fazli|<http://arxiv.org/pdf/2412.00624v2>|- 问题：视频语言模型，监督成本高，效率低<br />- 方法：自训练，自我批评，直接偏好优化<br />- 效果：性能提升，效率高|


### 多模态融合 (Multimodal Fusion)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OVTR: End-to-End Open-Vocabulary Multiple Object Tracking with Transformer|OVTR：基于Transformer的端到端开放词汇多目标跟踪|Jinyang Li, En Yu, Sijia Chen, Wenbing Tao|<http://arxiv.org/pdf/2503.10616v3>|[[代码]](<https://github.com/jinyanglii/OVTR.>)<br />- 问题：开放词汇，多目标跟踪，性能受限<br />- 方法：Transformer，类别信息传播，双分支结构<br />- 效果：性能提升，速度加快，适应性强|
|🆕 发布|CA^2ST: Cross-Attention in Audio, Space, and Time for Holistic Video Recognition|CA^2ST：音频、空间和时间中的交叉注意力，用于整体视频识别|Jongseo Lee, Joohyun Chang, Dongho Lee, Jinwoo Choi|<http://arxiv.org/pdf/2503.23447v1>|- 问题：视频识别，时空理解，模型不足<br />- 方法：两流架构，瓶颈交叉注意力，音频专家集成<br />- 效果：平衡性能，有效信息交换|
|📝 更新|Multimodal Feature-Driven Deep Learning for the Prediction of Duck Body Dimensions and Weight|多模态特征驱动深度学习预测鸭体尺寸和体重|Wenbo Xiao, Qiannan Han, Gang Shu, Guiping Liang, Hongyan Zhang, Song Wang, Zhihao Xu, Weican Wan .etc.|<http://arxiv.org/pdf/2503.14001v4>|- 问题：体形尺寸预测，深度学习，多模态数据<br />- 方法：PointNet++，Transformer编码器，特征融合<br />- 效果：高精度，非侵入式|
|📝 更新|MVREC: A General Few-shot Defect Classification Model Using Multi-View Region-Context|MVREC：一种基于多视角区域-上下文的通用小样本缺陷分类模型|Shuai Lyu, Rongchen Zhang, Zeqi Ma, Fangjian Liao, Dongmei Mo, Waikeung Wong|<http://arxiv.org/pdf/2412.16897v2>|[[代码]](<https://github.com/ShuaiLYU/MVREC>)<br />- 问题：FSDMC泛化性差，特征提取不足<br />- 方法：AlphaCLIP，区域-上下文框架，Zip-Adapter<br />- 效果：泛化性强，分类性能提升|


### 跨模态对齐 (Cross-modal Alignment)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Re-Aligning Language to Visual Objects with an Agentic Workflow|重新对齐语言与视觉对象：一种具有代理工作流程的方法|Yuming Chen, Jiangyan Feng, Haodong Zhang, Lijun Gong, Feng Zhu, Rui Zhao, Qibin Hou, Ming-Ming Cheng .etc.|<http://arxiv.org/pdf/2503.23508v1>|- 问题：LOD模型泛化能力，VLM幻觉，VL对齐质量<br />- 方法：Agentic workflow，LLM控制，自适应调整<br />- 效果：性能提升50%，数据质量保持|
|🆕 发布|CADFormer: Fine-Grained Cross-modal Alignment and Decoding Transformer for Referring Remote Sensing Image Segmentation|CADFormer：用于遥感图像细粒度跨模态对齐和解码的Transformer|Maofu Liu, Xin Jiang, Xiaokang Zhang|<http://arxiv.org/pdf/2503.23456v1>|- 问题：RRSIS，多模态，特征对齐，解码，语义信息<br />- 方法：SMGAM，TCMD，细粒度，跨模态<br />- 效果：性能提升，RRSIS-HR|
|🆕 发布|JavisDiT: Joint Audio-Video Diffusion Transformer with Hierarchical Spatio-Temporal Prior Synchronization|贾维斯DiT：具有分层时空先验同步的联合音频-视频扩散Transformer|Kai Liu, Wei Li, Lai Chen, Shengqiong Wu, Yanhao Zheng, Jiayi Ji, Fan Zhou, Rongxin Jiang .etc.|<http://arxiv.org/pdf/2503.23377v1>|[[代码]](<https://javisdit.github.io/.>)<br />- 问题：同步音频视频生成，同步性，质量<br />- 方法：扩散Transformer，HiST-Sypo Estimator，同步先验<br />- 效果：高质量生成，精确同步|
|🆕 发布|Physically Ground Commonsense Knowledge for Articulated Object Manipulation with Analytic Concepts|物理基础常识知识在解析概念下用于关节对象操作|Jianhua Sun, Jiude Wei, Yuxuan Li, Cewu Lu|<http://arxiv.org/pdf/2503.23348v1>|- 问题：LLM语义知识，物理世界，机器人操作，知识 grounding<br />- 方法：分析概念，机器计算，物理信息表示<br />- 效果：可解释性，准确性|
|📝 更新|SOAF: Scene Occlusion-aware Neural Acoustic Field|场景遮挡感知神经声场|Huiyu Gao, Jiahao Ma, David Ahmedt-Aristizabal, Chuong Nguyen, Miaomiao Liu|<http://arxiv.org/pdf/2407.02264v3>|- 问题：音频合成，场景遮挡，声场建模<br />- 方法：距离感知，场景结构学习，方向感知注意力<br />- 效果：音频生成，性能提升|


## 目标检测识别 (Object Detection & Recognition)


### 三维检测 (3D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|3D-AVS: LiDAR-based 3D Auto-Vocabulary Segmentation|3D-AVS：基于激光雷达的3D自动词汇分割|Weijie Wei, Osman Ülger, Fatemeh Karimi Nejadasl, Theo Gevers, Martin R. Oswald|<http://arxiv.org/pdf/2406.09126v3>|[[代码]](<https://github.com/ozzyou/3D-AVS>)<br />- 问题：OVS可扩展性，自动词汇，LiDAR语义识别<br />- 方法：3D-AVS，SMAP模块，TPSS评估<br />- 效果：自动生成词汇，语义分割准确|
|📝 更新|Self-Supervised Masked Mesh Learning for Unsupervised Anomaly Detection on 3D Cortical Surfaces|自监督掩码网格学习用于3D皮质表面的无监督异常检测|Hao-Chun Yang, Sicheng Dai, Saige Rutherford, Christian Gaser, Andre F Marquand, Christian F Beckmann, Thomas Wolfers|<http://arxiv.org/pdf/2412.05580v3>|- 问题：脑成像，无监督异常检测，3D皮质表面<br />- 方法：自监督，掩码网格学习，MMN<br />- 效果：异常检测，阿尔茨海默病，生物标志物|
|🆕 发布|Efficient Dynamic Attention 3D Convolution for Hyperspectral Image Classification|高效动态注意力3D卷积在高光谱图像分类中的应用|Guandong Li, Mengxia Ye|<http://arxiv.org/pdf/2503.23472v1>|- 问题：超光谱图像分类，信息利用不足，梯度消失，过拟合<br />- 方法：动态注意力3D卷积，3D-DenseNet，多并行卷积核<br />- 效果：效率提升，精度提高|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VELOCITI: Benchmarking Video-Language Compositional Reasoning with Strict Entailment|VELOCITI：使用严格蕴涵基准测试视频-语言组合推理|Darshana Saravanan, Varun Gupta, Darshan Singh, Zeeshan Khan, Vineet Gandhi, Makarand Tapaswi|<http://arxiv.org/pdf/2406.10889v2>|- 问题：视频语言推理，基准测试，严格蕴含<br />- 方法：VELOCITI基准，严格VLE，多帧视觉输入<br />- 效果：模型评估，理解差距，挑战与验证|


### 二维检测 (2D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Analyzing and Boosting the Power of Fine-Grained Visual Recognition for Multi-modal Large Language Models|分析并提升多模态大型语言模型中细粒度视觉识别的效能|Hulingxiao He, Geng Li, Zijun Geng, Jinglin Xu, Yuxin Peng|<http://arxiv.org/pdf/2501.15140v3>|[[代码]](<https://github.com/PKU-ICST-MIPL/Finedefics_ICLR2025.>)<br />- 问题：FGVR，MLLMs，视觉理解，能力不足<br />- 方法：Finedefics，属性描述，对比学习<br />- 效果：性能提升，参数规模相当|
|📝 更新|YOLO-LLTS: Real-Time Low-Light Traffic Sign Detection via Prior-Guided Enhancement and Multi-Branch Feature Interaction|YOLO-LLTS：基于先验引导增强和多分支特征交互的实时低光照交通标志检测|Ziyu Lin, Yunfan Wu, Yuhang Ma, Junzhou Chen, Ronghui Zhang, Jiaming Wu, Guodong Yin, Liang Lin|<http://arxiv.org/pdf/2503.13883v2>|- 问题：低光交通标志检测，特征稀释，信息提取<br />- 方法：HRFM-TOD，MFIA，PGFE，低光图像增强<br />- 效果：性能提升，实时检测|
|📝 更新|MMAD: Multi-label Micro-Action Detection in Videos|多标签微动作视频检测：MMAD|Kun Li, Pengyu Liu, Dan Guo, Fei Wang, Zhiliang Wu, Hehe Fan, Meng Wang|<http://arxiv.org/pdf/2407.05311v2>|[[代码]](<https://github.com/VUT-HFUT/Micro-Action.>)<br />- 问题：微动作识别，时间重叠，情感分析<br />- 方法：MMAD任务，MMA-52数据集，双路径时空适配器<br />- 效果：多标签检测，时空建模|
|🆕 发布|OwlSight: A Robust Illumination Adaptation Framework for Dark Video Human Action Recognition|猫眼视界：一种用于暗光视频人体动作识别的鲁棒性光照适应框架|Shihao Cheng, Jinlu Zhang, Yue Liu, Zhigang Tu|<http://arxiv.org/pdf/2503.23266v1>|- 问题：低光环境，动作识别，亮度信息，性能不足<br />- 方法：生物启发，全阶段增强，时间一致性，亮度调整，反射增强<br />- 效果：性能提升，数据集规模大|


### 多目标跟踪 (Multi-object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VideoFusion: A Spatio-Temporal Collaborative Network for Mutli-modal Video Fusion and Restoration|视频融合：一种用于多模态视频融合与恢复的空间-时间协作网络|Linfeng Tang, Yeda Wang, Meiqi Gong, Zizhuo Li, Yuxin Deng, Xunpeng Yi, Chunyu Li, Han Xu .etc.|<http://arxiv.org/pdf/2503.23359v1>|- 问题：视频融合，时空依赖，数据稀缺<br />- 方法：M3SVD，跨模态交互，时空协同<br />- 效果：性能提升，时空一致性|
|📝 更新|Analysis of Unstructured High-Density Crowded Scenes for Crowd Monitoring|非结构化高密度拥挤场景的监控分析|Alexandre Matov|<http://arxiv.org/pdf/2408.11836v9>|- 问题：人群监控，异常行为检测，运动轨迹分析<br />- 方法：自动检测，实时跟踪，数据驱动软件<br />- 效果：实时性，高精度|


## 三维重建 (3D Reconstruction)


### 单目重建 (Monocular Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Blurry-Edges: Photon-Limited Depth Estimation from Defocused Boundaries|模糊边缘：从失焦边界进行光子限制深度估计|Wei Xu, Charles James Wagner, Junjie Luo, Qi Guo|<http://arxiv.org/pdf/2503.23606v1>|- 问题：深度估计，噪声敏感，光子限制<br />- 方法：模糊边缘表示，深度神经网络，DfD关系<br />- 效果：高精度，光子限制|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Optimal Invariant Bases for Atomistic Machine Learning|原子机器学习的最优不变基|Alice E. A. Allen, Emily Shinkle, Roxana Bujack, Nicholas Lubbers|<http://arxiv.org/pdf/2503.23515v1>|- 问题：原子配置描述符，不完整，功能依赖<br />- 方法：模式识别技术，去除冗余描述符，优化基<br />- 效果：效率提升，准确度高，成本低|
|🆕 发布|KernelDNA: Dynamic Kernel Sharing via Decoupled Naive Adapters|KernelDNA：通过解耦朴素适配器的动态核共享|Haiduo Huang, Yadong Zhang, Pengju Ren|<http://arxiv.org/pdf/2503.23379v1>|[[代码]](<https://github.com/haiduo/KernelDNA.>)<br />- 问题：动态卷积，参数开销，推理速度，优化困难<br />- 方法：KernelDNA，解耦适配器，跨层权重共享<br />- 效果：精度效率平衡，性能提升|


### 神经隐式重建 (Neural Implicit Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SpINR: Neural Volumetric Reconstruction for FMCW Radars|SpINR：基于FMCW雷达的神经体素重建|Harshvardhan Takawale, Nirupam Roy|<http://arxiv.org/pdf/2503.23313v1>|- 问题：雷达成像，分辨率限制，泛化能力<br />- 方法：频率域，隐式神经网络，高效学习<br />- 效果：高分辨率，准确重建|


### 多视图重建 (Multi-view Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MonoInstance: Enhancing Monocular Priors via Multi-view Instance Alignment for Neural Rendering and Reconstruction|MonoInstance：通过多视角实例对齐增强单目先验以用于神经渲染和重建|Wenyuan Zhang, Yixiao Yang, Han Huang, Liang Han, Kanle Shi, Yu-Shen Liu, Zhizhong Han|<http://arxiv.org/pdf/2503.18363v2>|- 问题：单目深度先验，多视角不一致，不确定性<br />- 方法：多视角实例对齐，密度度量，约束项<br />- 效果：性能提升，重建，新视角合成|


## 神经渲染 (Neural Rendering)


### 可控渲染 (Controllable Rendering)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visual Acuity Consistent Foveated Rendering towards Retinal Resolution|视觉清晰度一致的视网膜分辨率微视场渲染|Zhi Zhang, Meng Gai, Sheng Li|<http://arxiv.org/pdf/2503.23410v1>|- 问题：渲染效率低，视觉质量下降<br />- 方法：视觉精度一致渲染，对数极坐标映射<br />- 效果：速度提升，视觉质量保持|


### 神经辐射场 (Neural Radiance Fields)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhancing 3D Gaussian Splatting Compression via Spatial Condition-based Prediction|基于空间条件预测增强3D高斯分层压缩|Jingui Ma, Yang Hu, Luyang Tang, Jiayu Yang, Yongqi Zhai, Ronggang Wang|<http://arxiv.org/pdf/2503.23337v1>|- 问题：3DGS压缩，存储传输成本高<br />- 方法：空间条件预测，残差补偿，实例感知超先验<br />- 效果：比特率降低，性能优于SOTA|
|📝 更新|NeRFPrior: Learning Neural Radiance Field as a Prior for Indoor Scene Reconstruction|NeRFPrior：学习神经辐射场作为室内场景重建的先验|Wenyuan Zhang, Emily Yue-ting Jia, Junsheng Zhou, Baorui Ma, Kanle Shi, Yu-Shen Liu, Zhizhong Han|<http://arxiv.org/pdf/2503.18361v2>|- 问题：高质表面重建，预训练需求大，色彩忽略<br />- 方法：NeRF prior，体积渲染，多视角一致性<br />- 效果：性能提升，优于现有方法|


## 定位与映射 (Localization & Mapping)


### 位姿估计 (Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PhysPose: Refining 6D Object Poses with Physical Constraints|物理约束下的6D物体姿态精炼：PhysPose|Martin Malenický, Martin Cífka, Médéric Fourmy, Louis Montaut, Justin Carpentier, Josef Sivic, Vladimir Petrik|<http://arxiv.org/pdf/2503.23587v1>|- 问题：6D物体姿态估计，物理不一致性<br />- 方法：物理约束优化，后处理，场景几何<br />- 效果：精度提升，机器人任务成功率提高|
|🆕 发布|Multiview Image-Based Localization|多视角图像基于定位|Cameron Fiore, Hongyi Fan, Benjamin Kimia|<http://arxiv.org/pdf/2503.23577v1>|- 问题：图像定位精度低，隐私问题，计算效率<br />- 方法：混合方法，相对平移估计，多视图对应<br />- 效果：性能提升，效率优化|
|🆕 发布|HiPART: Hierarchical Pose AutoRegressive Transformer for Occluded 3D Human Pose Estimation|HiPART：用于遮挡3D人体姿态估计的层次化自回归Transformer|Hongwei Zheng, Han Li, Wenrui Dai, Ziyang Zheng, Chenglin Li, Junni Zou, Hongkai Xiong|<http://arxiv.org/pdf/2503.23331v1>|- 问题：遮挡，2D输入限制，3D姿态估计<br />- 方法：多尺度标记，骨架感知对齐，层次自回归模型<br />- 效果：鲁棒性，性能提升，复杂度降低|


### 视觉SLAM (Visual SLAM)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ROVER: A Multi-Season Dataset for Visual SLAM|ROVER：一个适用于视觉SLAM的多季节数据集|Fabian Schmidt, Julian Daubermann, Marcel Mitschke, Constantin Blessing, Stefan Meyer, Markus Enzweiler, Abhinav Valada|<http://arxiv.org/pdf/2412.02506v2>|[[代码]](<https://iis-esslingen.github.io/rover.>)<br />- 问题：视觉SLAM，季节变化，光照条件，植被影响<br />- 方法：多季节数据集，多传感器融合，环境适应性<br />- 效果：性能评估，挑战识别，系统改进|
|🆕 发布|Boosting Omnidirectional Stereo Matching with a Pre-trained Depth Foundation Model|基于预训练深度基础模型的全方位立体匹配增强|Jannik Endres, Oliver Hahn, Charles Corbière, Simone Schaub-Meyer, Stefan Roth, Alexandre Alahi|<http://arxiv.org/pdf/2503.23502v1>|- 问题：深度感知，立体匹配，数据稀缺，精度有限<br />- 方法：预训练模型，迭代优化，两阶段训练<br />- 效果：MAE降低16%，性能领先|
|📝 更新|STEP: Enhancing Video-LLMs' Compositional Reasoning by Spatio-Temporal Graph-guided Self-Training|视频-LLMs通过时空图引导的自训练增强组合推理：STEP|Haiyi Qiu, Minghe Gao, Long Qian, Kaihang Pan, Qifan Yu, Juncheng Li, Wenjie Wang, Siliang Tang .etc.|<http://arxiv.org/pdf/2412.00161v2>|- 问题：视频理解，组合推理，时空推理<br />- 方法：时空图引导，自训练，问答数据<br />- 效果：性能提升，样本少|


### 语义建图 (Semantic Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|StructVPR++: Distill Structural and Semantic Knowledge with Weighting Samples for Visual Place Recognition|结构视觉识别++：通过加权样本蒸馏结构和语义知识|Yanqing Shen, Sanping Zhou, Jingwen Fu, Ruotong Wang, Shitao Chen, Nanning Zheng|<http://arxiv.org/pdf/2503.06601v2>|- 问题：视觉场景识别，语义信息提取，效率与精度平衡<br />- 方法：结构语义知识蒸馏，样本加权蒸馏，解耦特征<br />- 效果：精度提升，实时效率|


## 自监督学习 (Self-supervised Learning)


### 对比学习 (Contrastive Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Mask-informed Deep Contrastive Incomplete Multi-view Clustering|基于掩码信息的深度对比不完全多视角聚类|Zhenglai Li, Yuqi Shi, Xiao He, Chang Tang|<http://arxiv.org/pdf/2502.02234v2>|- 问题：多视角聚类，缺失样本，知识整合<br />- 方法：掩码融合网络，对比学习，先验知识<br />- 效果：性能优越，数据集验证|


## 迁移与适应 (Transfer & Adaptation)


### 元学习 (Meta Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GenVP: Generating Visual Puzzles with Contrastive Hierarchical VAEs|生成视觉谜题的对比分层变分自编码器：GenVP|Kalliopi Basioti, Pritish Sahu, Qingze Tony Liu, Zihao Xu, Hao Wang, Vladimir Pavlovic|<http://arxiv.org/pdf/2503.23598v1>|- 问题：抽象视觉推理，RPMs，生成新谜题<br />- 方法：对比级联VAEs，生成视觉谜题<br />- 效果：SOTA性能，OOD泛化|
|📝 更新|Configurable Holography: Towards Display and Scene Adaptation|可配置全息：迈向显示和场景自适应|Yicheng Zhan, Liang Shi, Wojciech Matusik, Qi Sun, Kaan Akşit|<http://arxiv.org/pdf/2405.01558v3>|- 问题：模型配置，训练效率，场景适应性<br />- 方法：可配置模型结构，连续条件化，深度估计与合成关联<br />- 效果：高质3D全息，速度提升|
|📝 更新|Visual Self-paced Iterative Learning for Unsupervised Temporal Action Localization|视觉自定步速迭代学习用于无监督时序动作定位|Yupeng Hu, Han Jiang, Hao Liu, Kun Wang, Haoyu Tang, Liqiang Nie|<http://arxiv.org/pdf/2312.07384v2>|- 问题：TAL，标签依赖，聚类置信度低，伪标签不可靠<br />- 方法：自-paced迭代学习，上下文特征，增量实例学习<br />- 效果：性能优越，效果提升|
|🆕 发布|VideoGen-Eval: Agent-based System for Video Generation Evaluation|视频生成评估的基于代理的系统：VideoGen-Eval|Yuhang Yang, Ke Fan, Shangkun Sun, Hongxiang Li, Ailing Zeng, FeiLin Han, Wei Zhai, Wei Liu .etc.|<http://arxiv.org/pdf/2503.23452v1>|- 问题：评估系统不足，模型能力展示，OOD问题，指标与偏好不匹配<br />- 方法：LLM内容结构，MLLM内容判断，时序密集维度工具<br />- 效果：与人类偏好强一致，可靠评估，基准多样性丰富|
|🆕 发布|Learning Predictive Visuomotor Coordination|学习预测性视觉运动协调|Wenqi Jia, Bolin Lai, Miao Liu, Danfei Xu, James M. Rehg|<http://arxiv.org/pdf/2503.23300v1>|- 问题：视动协调预测，多模态信号，行为建模<br />- 方法：VCR，扩散模型，时序依赖学习<br />- 效果：泛化能力强，准确预测|


### 域适应 (Domain Adaptation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ViLAaD: Enhancing "Attracting and Dispersing'' Source-Free Domain Adaptation with Vision-and-Language Model|ViLAaD：通过视觉和语言模型增强“吸引和分散”无源域适应|Shuhei Tarashima, Xinqi Shu, Norio Tagawa|<http://arxiv.org/pdf/2503.23529v1>|- 问题：源域自适应，信息编码，辅助资源<br />- 方法：ViL模型，AaD框架，ViLAaD<br />- 效果：性能提升，泛化能力强|
|🆕 发布|AU-TTT: Vision Test-Time Training model for Facial Action Unit Detection|AU-TTT：面部动作单元检测的视觉测试时训练模型|Bohao Xing, Kaishen Yuan, Zitong Yu, Xin Liu, Heikki Kälviäinen|<http://arxiv.org/pdf/2503.23450v1>|- 问题：AU检测，数据标注成本高，泛化能力差<br />- 方法：TTT，视觉骨干网络，RoI扫描机制<br />- 效果：性能提升，跨域泛化|
|🆕 发布|GMapLatent: Geometric Mapping in Latent Space|GMapLatent：潜在空间中的几何映射|Wei Zeng, Xuebin Chang, Jianghao Su, Xiang Gu, Jian Sun, Zongben Xu|<http://arxiv.org/pdf/2503.23407v1>|- 问题：跨域生成，模式崩溃，混合问题<br />- 方法：几何映射，规范潜在空间，严格约束<br />- 效果：避免崩溃，精确对齐，性能优越|
|📝 更新|FM2S: Towards Spatially-Correlated Noise Modeling in Zero-Shot Fluorescence Microscopy Image Denoising|FM2S：迈向零样本荧光显微镜图像去噪中的空间相关噪声建模|Jizhihui Liu, Qixun Teng, Qing Ma, Junjun Jiang|<http://arxiv.org/pdf/2412.10031v2>|- 问题：噪声建模，零样本，荧光显微镜<br />- 方法：噪声注入，渐进学习，轻量网络<br />- 效果：性能优越，参数少|
|📝 更新|TouchUp-G: Improving Feature Representation through Graph-Centric Finetuning|TouchUp-G：通过图中心微调提升特征表示|Jing Zhu, Xiang Song, Vassilis N. Ioannidis, Danai Koutra, Christos Faloutsos|<http://arxiv.org/pdf/2309.13885v2>|- 问题：特征表示，图学习，GNN，节点特征，性能下降<br />- 方法：Graph-Centric Finetuning，特征同质化，TOUCHUP-G<br />- 效果：多模态，通用，SOTA|
|📝 更新|EgoMe: A New Dataset and Challenge for Following Me via Egocentric View in Real World|自我跟随：一个基于第一人称视角在现实世界中跟随我的新数据集和挑战|Heqian Qiu, Zhaofeng Shi, Lanxiao Wang, Huiyu Xiong, Xiang Li, Hongliang Li|<http://arxiv.org/pdf/2501.19061v2>|- 问题：模仿学习，数据不一致，认知过程<br />- 方法：EgoMe数据集，多模态数据，标注<br />- 效果：数据丰富，挑战性基准，优势显著|
|🆕 发布|AnyCam: Learning to Recover Camera Poses and Intrinsics from Casual Videos|AnyCam：从日常视频中学习恢复相机姿态和内参|Felix Wimbauer, Weirong Chen, Dominik Muhle, Christian Rupprecht, Daniel Cremers|<http://arxiv.org/pdf/2503.23282v1>|- 问题：相机运动和内参估计，动态视频，SfM，SLAM<br />- 方法：Transformer模型，不确定性损失，预训练网络<br />- 效果：准确度高，速度快，4D点云|


### 增量学习 (Incremental Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Diffusion Meets Few-shot Class Incremental Learning|扩散与少样本类别增量学习相遇|Junsu Kim, Yunhoe Ku, Dongyoon Han, Seungryul Baek|<http://arxiv.org/pdf/2503.23402v1>|- 问题：FSCIL，数据有限，遗忘问题<br />- 方法：Diffusion-FSCIL，预训练模型，多尺度特征<br />- 效果：性能提升，适应新类别|
|🆕 发布|Language Guided Concept Bottleneck Models for Interpretable Continual Learning|语言引导的概念瓶颈模型用于可解释的持续学习|Lu Yu, Haoyu Han, Zhe Tao, Hantao Yao, Changsheng Xu|<http://arxiv.org/pdf/2503.23283v1>|- 问题：灾难性遗忘，可解释性，持续学习<br />- 方法：语言引导，概念瓶颈模型，语义一致性<br />- 效果：性能提升，可解释性增强|


## 鲁棒学习 (Robust Learning)


### 对抗防御 (Adversarial Defense)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Embedding Shift Dissection on CLIP: Effects of Augmentations on VLM's Representation Learning|CLIP上的嵌入位移分解：增强对视觉语言模型表示学习的影响|Ashim Dahal, Saydul Akbar Murad, Nick Rahimi|<http://arxiv.org/pdf/2503.23495v1>|- 问题：CLIP表示学习，不同增强，机制可解释性<br />- 方法：9种增强技术，嵌入位移分析，注意力图，定性分析<br />- 效果：显著位移，鲁棒性，对抗数据防御|
|📝 更新|RGB-Th-Bench: A Dense benchmark for Visual-Thermal Understanding of Vision Language Models|RGB-Th-Bench：视觉语言模型视觉-热理解的高密度基准|Mehdi Moshtaghi, Siavash H. Khajavi, Joni Pajarinen|<http://arxiv.org/pdf/2503.19654v3>|- 问题：VLMs RGB-Th理解能力，数据集缺乏，评估框架不足<br />- 方法：RGB-Th-Bench，多维度评估，严格指标<br />- 效果：性能差距，需多模态学习|


### 对抗攻击 (Adversarial Attack)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Enhancing Adversarial Transferability via Component-Wise Transformation|通过组件级变换增强对抗迁移性|Hangyu Liu, Bo Peng, Can Cui, Pengxiang Ding, Donglin Wang|<http://arxiv.org/pdf/2501.11901v2>|- 问题：对抗样本，迁移性差，架构差异<br />- 方法：组件式变换，插值，旋转<br />- 效果：攻击成功率，稳定性|


## 模型压缩加速 (Model Compression & Acceleration)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EEdit: Rethinking the Spatial and Temporal Redundancy for Efficient Image Editing|EEdit：重新思考高效图像编辑中的空间和时间冗余|Zexuan Yan, Yue Ma, Chang Zou, Wenteng Chen, Qifeng Chen, Linfeng Zhang|<http://arxiv.org/pdf/2503.10270v2>|[[代码]](<https://github.com/yuriYanZeXuan/EEdit>)<br />- 问题：计算开销大，实时性差<br />- 方法：空间局部缓存，时间步跳过，token索引<br />- 效果：效率提升，性能无损|


## 泛化与鲁棒性 (Generalization & Robustness)


### 域泛化 (Domain Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Any-Resolution AI-Generated Image Detection by Spectral Learning|任意分辨率AI生成图像检测通过光谱学习|Dimitrios Karageorgiou, Symeon Papadopoulos, Ioannis Kompatsiaris, Efstratios Gavves|<http://arxiv.org/pdf/2411.19417v2>|[[代码]](<https://mever-team.github.io/spai.>)<br />- 问题：AI生成图像检测，光谱伪影，泛化能力差<br />- 方法：光谱学习，掩码学习，光谱重建相似度，光谱上下文注意力<br />- 效果：AUC提升5.5%，鲁棒性强|
|🆕 发布|COSMIC: Clique-Oriented Semantic Multi-space Integration for Robust CLIP Test-Time Adaptation|COSMIC：针对鲁棒CLIP测试时自适应的基于图论的语义多空间集成|Fanding Huang, Jingyan Jiang, Qinting Jiang, Hebei Li, Faisal Nadeem Khan, Zhi Wang|<http://arxiv.org/pdf/2503.23388v1>|[[代码]](<https://github.com/hf618/COSMIC.>)<br />- 问题：测试时适应，缓存可靠性，单类信息使用<br />- 方法：多粒度语义缓存，图查询，DSG，CGH<br />- 效果：性能提升，跨域生成|


## 医学影像分析 (Medical Image Analysis)


### 医学分割 (Medical Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Leveraging Vision-Language Foundation Models to Reveal Hidden Image-Attribute Relationships in Medical Imaging|利用视觉-语言基础模型揭示医学影像中隐藏的图像-属性关系|Amar Kumar, Anita Kriz, Barak Pertzov, Tal Arbel|<http://arxiv.org/pdf/2503.23618v1>|- 问题：VLMs，数据属性，图像生成<br />- 方法：微调，高分辨率图像，数据关系揭示<br />- 效果：性能提升，数据关系，局限性|
|🆕 发布|BiPVL-Seg: Bidirectional Progressive Vision-Language Fusion with Global-Local Alignment for Medical Image Segmentation|双向渐进视觉-语言融合及全局-局部对齐的医学图像分割|Rafi Ibn Sultan, Hui Zhu, Chengyin Li, Dongxiao Zhu|<http://arxiv.org/pdf/2503.23534v1>|- 问题：医学图像分割，视觉-语言融合，特征对齐，术语差异<br />- 方法：双向渐进融合，全局-局部对齐，端到端框架<br />- 效果：性能提升，多类分割|
|🆕 发布|BoundMatch: Boundary detection applied to semi-supervised segmentation for urban-driving scenes|BoundMatch：应用于城市驾驶场景半监督分割的边界检测|Haruya Ishikawa, Yoshimitsu Aoki|<http://arxiv.org/pdf/2503.23519v1>|- 问题：边界检测，半监督分割，标注负担<br />- 方法：多任务学习，边界一致性正则化，融合模块<br />- 效果：性能提升，边界清晰|
|🆕 发布|ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025|ReferDINO-Plus：2025年CVPR第4届PVUW MeViS挑战赛的第二个解决方案|Tianming Liang, Haichao Jiang, Wei-Shi Zheng, Jian-Fang Hu|<http://arxiv.org/pdf/2503.23509v1>|[[代码]](<https://github.com/iSEE-Laboratory/ReferDINO-Plus.>)<br />- 问题：RVOS，视频对象分割，文本描述<br />- 方法：ReferDINO，SAM2，条件融合<br />- 效果：60.43 \(\mathcal{J}\&\mathcal{F}\)，第二名|
|🆕 发布|Federated Self-Supervised Learning for One-Shot Cross-Modal and Cross-Imaging Technique Segmentation|联邦自监督学习在单样本跨模态和跨图像技术分割中的应用|Siladittya Manna, Suresh Das, Sayantari Ghosh, Saumik Bhattacharya|<http://arxiv.org/pdf/2503.23507v1>|- 问题：隐私保护，数据稀缺，跨模态，跨成像，分割<br />- 方法：联邦自监督学习，CoWPro，融合dice损失<br />- 效果：性能提升，未见数据集验证|
|📝 更新|Local Concept Embeddings for Analysis of Concept Distributions in Vision DNN Feature Spaces|局部概念嵌入：用于分析视觉深度神经网络特征空间中概念分布的方法|Georgii Mikriukov, Gesina Schwalbe, Korinna Bade|<http://arxiv.org/pdf/2311.14435v3>|- 问题：概念分割，隐式子概念，概念分布<br />- 方法：局部概念嵌入，GMM，层次聚类<br />- 效果：性能竞争，理解深度学习|
|🆕 发布|Improving underwater semantic segmentation with underwater image quality attention and muti-scale aggregation attention|水下语义分割：基于水下图像质量注意力和多尺度聚合注意力的改进|Xin Zuo, Jiaran Jiang, Jifeng Shen, Wankou Yang|<http://arxiv.org/pdf/2503.23422v1>|[[代码]](<https://github.com/SAWRJJ/UWSegFormer.>)<br />- 问题：水下图像质量差，语义分割困难<br />- 方法：UIQA模块，MAA模块，Edge Learning Loss<br />- 效果：mIoU提升，边界清晰|
|📝 更新|Effective SAM Combination for Open-Vocabulary Semantic Segmentation|有效的开放词汇语义分割中的SAM组合|Minhyeok Lee, Suhwan Cho, Jungho Lee, Sunghun Yang, Heeseung Choi, Ig-Jae Kim, Sangyoun Lee|<http://arxiv.org/pdf/2411.14723v2>|- 问题：开放词汇，语义分割，计算成本高<br />- 方法：ESC-Net，SAM解码块，伪提示嵌入<br />- 效果：性能提升，效率高|
|📝 更新|OnlineAnySeg: Online Zero-Shot 3D Segmentation by Visual Foundation Model Guided 2D Mask Merging|在线AnySeg：基于视觉基础模型的在线零样本3D分割通过2D掩码合并|Yijie Tang, Jiazhao Zhang, Yuqing Lan, Yulan Guo, Dezun Dong, Chenyang Zhu, Kai Xu|<http://arxiv.org/pdf/2503.01309v3>|- 问题：在线零样本3D分割，2D先验，空间一致性<br />- 方法：视觉基础模型，2D掩码合并，哈希技术<br />- 效果：实时效率，零样本，性能领先|


### 影像重建 (Image Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ControlFusion: A Controllable Image Fusion Framework with Language-Vision Degradation Prompts|控制融合：一种带有语言-视觉退化提示的可控图像融合框架|Linfeng Tang, Yeda Wang, Zhanchuan Cai, Junjun Jiang, Jiayi Ma|<http://arxiv.org/pdf/2503.23356v1>|- 问题：图像融合，复合退化，用户需求<br />- 方法：语言视觉提示，退化成像模型，自适应处理<br />- 效果：融合质量提升，退化处理强|


## 智能驾驶 (Intelligent Driving)


### 轨迹预测 (Trajectory Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Language Prompt for Autonomous Driving|自动驾驶的语言提示|Dongming Wu, Wencheng Han, Yingfei Liu, Tiancai Wang, Cheng-zhong Xu, Xiangyu Zhang, Jianbing Shen|<http://arxiv.org/pdf/2309.04379v2>|[[代码]](<https://github.com/wudongming97/Prompt4Driving.>)<br />- 问题：语言提示，自动驾驶，数据稀缺<br />- 方法：NuPrompt，Transformer，PromptTrack<br />- 效果：性能提升，新见解|
|🆕 发布|Enhancing Human Motion Prediction via Multi-range Decoupling Decoding with Gating-adjusting Aggregation|通过门控调整聚合的多范围解耦解码增强人类运动预测|Jiexin Wang, Wenwen Qiang, Zhao Yang, Bing Su|<http://arxiv.org/pdf/2503.23381v1>|- 问题：运动预测准确性，信息相关性，学习限制<br />- 方法：多范围解耦解码，门控调整聚合<br />- 效果：预测性能提升，易集成|


### 环境感知 (Environment Perception)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Video Prediction Transformers without Recurrence or Convolution|无循环或卷积的视频预测Transformer|Yujin Tang, Lu Qi, Fei Xie, Xiangtai Li, Chao Ma, Ming-Hsuan Yang|<http://arxiv.org/pdf/2410.04733v3>|[[代码]](<https://github.com/yyyujintang/PredFormer.>)<br />- 问题：RNN计算成本高，CNN泛化能力差<br />- 方法：PredFormer，3D注意力机制，纯Transformer<br />- 效果：性能提升，效率高|
|🆕 发布|OnSiteVRU: A High-Resolution Trajectory Dataset for High-Density Vulnerable Road Users|OnSiteVRU：高分辨率轨迹数据集，用于高密度易受伤害道路使用者|Zhangcun Yan, Jianqing Li, Peng Hang, Jian Sun|<http://arxiv.org/pdf/2503.23365v1>|- 问题：VRU行为多样性，数据集不足，交通流安全<br />- 方法：OnSiteVRU数据集，多场景覆盖，高精度轨迹<br />- 效果：VRU密度高，场景丰富，支持自动驾驶|


## 工业视觉 (Industrial Vision)


### 缺陷检测 (Defect Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Beyond Academic Benchmarks: Critical Analysis and Best Practices for Visual Industrial Anomaly Detection|超越学术基准：视觉工业异常检测的关键分析和最佳实践|Aimira Baitieva, Yacine Bouaouni, Alexandre Briot, Dick Ameln, Souhaiel Khalfaoui, Samet Akcay|<http://arxiv.org/pdf/2503.23451v1>|[[代码]](<https://github.com/abc-125/viad-benchmark>)<br />- 问题：工业异常检测，数据集局限性，方法实用性<br />- 方法：真实数据集，公平比较，综合分析<br />- 效果：性能评估，跨领域应用|

