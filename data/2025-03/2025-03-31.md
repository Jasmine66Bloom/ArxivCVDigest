## [UPDATED!] **2025-03-31** (Update Time)


## 表示学习 (Representation Learning)


### 基础模型 (Foundation Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Adapting Vision Foundation Models for Real-time Ultrasound Image Segmentation|适应视觉基础模型进行实时超声图像分割|Xiaoran Zhang, Eric Z. Chen, Lin Zhao, Xiao Chen, Yikang Liu, Boris Maihe, James S. Duncan, Terrence Chen .etc.|<http://arxiv.org/pdf/2503.24368v1>|- 问题：超声图像分割，适应性强，实时性<br />- 方法：Hiera模型，多尺度特征，DINOv2表示<br />- 效果：性能提升，实时应用|
|🆕 发布|ORAL: Prompting Your Large-Scale LoRAs via Conditional Recurrent Diffusion|ORAL：通过条件循环扩散提示您的超大规模LoRAs|Rana Muhammad Shahroz Khan, Dongwen Tang, Pingzhi Li, Kai Wang, Tianlong Chen|<http://arxiv.org/pdf/2503.24354v1>|- 问题：LoRA可扩展性，可控性，参数生成<br />- 方法：条件循环扩散，模型架构集成，文本任务指定<br />- 效果：高质LoRA参数，性能可比或优于传统训练|
|🆕 发布|PolypSegTrack: Unified Foundation Model for Colonoscopy Video Analysis|结肠镜视频分析的统一基础模型：PolypSegTrack|Anwesa Choudhuri, Zhongpai Gao, Meng Zheng, Benjamin Planche, Terrence Chen, Ziyan Wu|<http://arxiv.org/pdf/2503.24108v1>|- 问题：结肠镜视频分析，息肉检测，分割，分类，跟踪<br />- 方法：PolypSegTrack，条件掩码损失，无监督跟踪，预训练模型<br />- 效果：性能提升，超越现有方法|
|🆕 发布|HumanAesExpert: Advancing a Multi-Modality Foundation Model for Human Image Aesthetic Assessment|人类美学专家：推进多模态基础模型用于人类图像美学评估|Zhichao Liao, Xiaokun Liu, Wenyu Qin, Qingyu Li, Qiulin Wang, Pengfei Wan, Di Zhang, Long Zeng .etc.|<http://arxiv.org/pdf/2503.23907v1>|[[代码]](<https://humanaesexpert.github.io/HumanAesExpert>)<br />- 问题：HIAA，数据集，评估框架<br />- 方法：HumanBeauty，多模态模型，MetaVoter<br />- 效果：性能提升，公开数据|
|🆕 发布|MGD-SAM2: Multi-view Guided Detail-enhanced Segment Anything Model 2 for High-Resolution Class-agnostic Segmentation|MGD-SAM2：多视角引导细节增强Segment Anything Model 2用于高分辨率无类别分割|Haoran Shen, Peixian Zhuang, Jiahao Kou, Yuxin Zeng, Haoying Xu, Jiangyun Li|<http://arxiv.org/pdf/2503.23786v1>|[[代码]](<https://github.com/sevenshr/MGD-SAM2.>)<br />- 问题：HRCS，细节分割，低分辨率，手动提示<br />- 方法：SAM2，MPAdapter，MCEM，HMIM，DRM<br />- 效果：性能提升，泛化能力强|


### 预训练模型 (Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Can Test-Time Scaling Improve World Foundation Model?|测试时缩放能否提升世界基础模型？|Wenyan Cong, Hanqing Zhu, Peihao Wang, Bangya Liu, Dejia Xu, Kevin Wang, David Z. Pan, Yan Wang .etc.|<http://arxiv.org/pdf/2503.24320v1>|[[代码]](<https://github.com/Mia-Cong/SWIFT.git.>)<br />- 问题：World Foundation Model，测试时缩放，计算资源<br />- 方法：SWIFT框架，WFM评估工具，过程级推理<br />- 效果：可扩展性，效率提升|
|📝 更新|Reversible Decoupling Network for Single Image Reflection Removal|可逆解耦网络用于单图反射消除|Hao Zhao, Mingjia Li, Qiming Hu, Xiaojie Guo|<http://arxiv.org/pdf/2410.08063v2>|[[代码]](<https://github.com/lime-j/RDNet>)<br />- 问题：反射去除，信息瓶颈，双流网络<br />- 方法：可逆编码器，特征解耦，动态特征校准<br />- 效果：性能提升，SOTA，NTIRE 2025冠军|
|🆕 发布|It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data|《盲配！迈向无需并行数据的视觉-语言对应》|Dominik Schnaus, Nikita Araslanov, Daniel Cremers|<http://arxiv.org/pdf/2503.24129v1>|- 问题：无监督视觉语言对应，平行数据，成熟模型<br />- 方法：无监督匹配，二次分配问题，新型启发式算法<br />- 效果：无监督匹配，语义知识嵌入|
|🆕 发布|SALT: A Flexible Semi-Automatic Labeling Tool for General LiDAR Point Clouds with Cross-Scene Adaptability and 4D Consistency|SALT：一种具有跨场景适应性和4D一致性的通用激光雷达点云半自动标注工具|Yanbo Wang, Yongtao Chen, Chuan Cao, Tianchen Deng, Wentao Zhao, Jingchuan Wang, Weidong Chen|<http://arxiv.org/pdf/2503.23980v1>|[[代码]](<https://github.com/Cavendish518/SALT.>)<br />- 问题：LiDAR点云标注，跨场景适应性，4D一致性<br />- 方法：零样本学习，数据对齐，4D一致性提示，4D NMS<br />- 效果：效率提升，性能接近人工标注|


### 视觉Transformer (Vision Transformers)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Double Deep Learning-based Solution for Efficient Event Data Coding and Classification|基于双深度学习的有效事件数据编码与分类解决方案|Abdelrahman Seleem, André F. R. Guarda, Nuno M. M. Rodrigues, Fernando Pereira|<http://arxiv.org/pdf/2407.15531v2>|- 问题：事件数据编码，分类，压缩<br />- 方法：双深度学习架构，点云表示，JPEG Pleno Point Cloud Coding<br />- 效果：分类性能高，压缩比高|
|📝 更新|Vision-RWKV: Efficient and Scalable Visual Perception with RWKV-Like Architectures|视觉-RWKV：类似RWKV架构的高效且可扩展的视觉感知|Yuchen Duan, Weiyun Wang, Zhe Chen, Xizhou Zhu, Lewei Lu, Tong Lu, Yu Qiao, Hongsheng Li .etc.|<http://arxiv.org/pdf/2403.02308v3>|[[代码]](<https://github.com/OpenGVLab/Vision-RWKV.>)<br />- 问题：高分辨率图像处理，长上下文分析，计算复杂度<br />- 方法：RWKV架构，稀疏输入处理，无窗口操作<br />- 效果：性能超越ViT，速度更快，内存更低|
|🆕 发布|Introducing the Short-Time Fourier Kolmogorov Arnold Network: A Dynamic Graph CNN Approach for Tree Species Classification in 3D Point Clouds|引入短时傅里叶柯尔莫哥洛夫阿诺德网络：一种用于3D点云中树种分类的动态图卷积神经网络方法|Said Ohamouddoua, Mohamed Ohamouddoub, Rafik Lasrib, Hanaa El Afiaa, Raddouane Chiheba, Abdellatif El Afiaa|<http://arxiv.org/pdf/2503.23647v1>|- 问题：树种分类，3D点云，深度学习，效率<br />- 方法：STFT-KAN，动态图CNN，轻量级DGCNN<br />- 效果：性能提升，参数减少，效率高|
|📝 更新|An interpretable approach to automating the assessment of biofouling in video footage|一种用于自动评估视频素材中生物污损的可解释方法|Evelyn J. Mannix, Bartholomew A. Woodham|<http://arxiv.org/pdf/2503.12875v2>|- 问题：生物污损评估，自动化，计算机视觉<br />- 方法：ComFe，DINOv2 ViT，可解释性<br />- 效果：性能提升，透明度增强|


## 生成建模 (Generative Modeling)


### 生成对抗网络 (GANs)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Consistent Subject Generation via Contrastive Instantiated Concepts|通过对比实例概念实现一致的主体生成|Lee Hsin-Ying, Kelvin C. K. Chan, Ming-Hsuan Yang|<http://arxiv.org/pdf/2503.24387v1>|- 问题：文本到图像生成，主题一致性，生成模型<br />- 方法：对比学习，概念实例化，映射网络<br />- 效果：一致性，灵活性|
|🆕 发布|PathOrchestra: A Comprehensive Foundation Model for Computational Pathology with Over 100 Diverse Clinical-Grade Tasks|PathOrchestra：一个包含超过100个多样化临床级任务的计算病理学全面基础模型|Fang Yan, Jianfeng Wu, Jiawen Li, Wei Wang, Jiaxuan Lu, Wen Chen, Zizhao Gao, Jianan Li .etc.|<http://arxiv.org/pdf/2503.24345v1>|- 问题：病理图像复杂性，数据需求高，临床验证难<br />- 方法：大规模自监督学习，多任务训练，结构化报告生成<br />- 效果：高精度，泛癌分类，临床应用潜力|
|🆕 发布|Beyond a Single Mode: GAN Ensembles for Diverse Medical Data Generation|超越单一模式：用于多样化医学数据生成的GAN集成|Lorenzo Tronchin, Tommy Löfstedt, Paolo Soda, Valerio Guarrasi|<http://arxiv.org/pdf/2503.24258v1>|- 问题：GANs，模式崩溃，数据分布覆盖不足<br />- 方法：GAN ensembles，多目标优化，模型选择<br />- 效果：多样性，效率，下游任务效能提升|
|📝 更新|Singular Value Scaling: Efficient Generative Model Compression via Pruned Weights Refinement|奇异值缩放：通过剪枝权重细化实现高效的生成模型压缩|Hyeonjin Kim, Jaejun Yoo|<http://arxiv.org/pdf/2412.17387v3>|[[代码]](<https://github.com/LAIT-CVLab/Singular-Value-Scaling.>)<br />- 问题：模型压缩，性能维持，泛化性差<br />- 方法：Singular Value Scaling，权重优化，泛化模型<br />- 效果：压缩性能提升，训练效率高|
|📝 更新|Interpreting Low-level Vision Models with Causal Effect Maps|利用因果效应图解释低级视觉模型|Jinfan Hu, Jinjin Gu, Shiyao Yu, Fanghua Yu, Zheyuan Li, Zhiyuan You, Chaochao Lu, Chao Dong|<http://arxiv.org/pdf/2407.19789v3>|[[代码]](<https://github.com/J-FHu/CEM.>)<br />- 问题：可解释性，低级视觉模型，因果效应<br />- 方法：因果效应图（CEM），模型/任务无关<br />- 效果：可视化，量化，深入理解|
|📝 更新|Mitigating Covariate Shift in Imitation Learning for Autonomous Vehicles Using Latent Space Generative World Models|缓解自动驾驶车辆模仿学习中的协变量偏移：使用潜在空间生成世界模型|Alexander Popov, Alperen Degirmenci, David Wehr, Shashank Hegde, Ryan Oldja, Alexey Kamenev, Bertrand Douillard, David Nistér .etc.|<http://arxiv.org/pdf/2409.16663v3>|- 问题：Covariate shift, Imitation learning, Autonomous vehicles<br />- 方法：Latent space generative world models, Transformer-based encoder, Multi-view cross-attention<br />- 效果：CARLA simulator, Perturbation handling|
|📝 更新|Enhancing Intent Understanding for Ambiguous prompt: A Human-Machine Co-Adaption Strategy|提升模糊提示意图理解：人机协同自适应策略|Yangfan He, Jianhui Wang, Yijin Wang, Kun Li, Yan Zhong, Xinyuan Song, Li Sun, Jingyuan Lu .etc.|<http://arxiv.org/pdf/2501.15167v4>|- 问题：意图理解，模糊提示，用户需求<br />- 方法：人机共适应，互信息优化，参数调整<br />- 效果：减少调整，数据集，开源|


### 扩散模型 (Diffusion Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|InstructRestore: Region-Customized Image Restoration with Human Instructions|指令恢复：基于人类指令的区域定制图像恢复|Shuaizheng Liu, Jianqi Ma, Lingchen Sun, Xiangtao Kong, Lei Zhang|<http://arxiv.org/pdf/2503.24357v1>|[[代码]](<https://github.com/shuaizhengliu/InstructRestore.git.>)<br />- 问题：统一处理，缺乏区域定制，用户指令<br />- 方法：数据生成，ControlNet架构，区域定制<br />- 效果：用户指令，图像修复|
|🆕 发布|Visual Acoustic Fields|视觉声场|Yuelei Li, Hyunjin Kim, Fangneng Zhan, Ri-Zhao Qiu, Mazeyu Ji, Xiaojun Shan, Xueyan Zou, Paul Liang .etc.|<http://arxiv.org/pdf/2503.24270v1>|[[代码]](<https://yuelei0428.github.io/projects>)<br />- 问题：物体声音，视觉信号，3D空间<br />- 方法：3D Gaussian Splatting，条件扩散模型，声音定位<br />- 效果：真实声音，准确定位|
|📝 更新|DICE: Discrete Inversion Enabling Controllable Editing for Multinomial Diffusion and Masked Generative Models|DICE：离散反演实现多项式扩散和掩码生成模型的可控编辑|Xiaoxiao He, Ligong Han, Quan Dao, Song Wen, Minhao Bai, Di Liu, Han Zhang, Martin Renqiang Min .etc.|<http://arxiv.org/pdf/2410.08207v2>|- 问题：控制编辑，离散扩散模型，内容编辑<br />- 方法：离散反演，记录噪声序列，灵活编辑<br />- 效果：高数据保真，增强编辑能力|
|🆕 发布|DenseFormer: Learning Dense Depth Map from Sparse Depth and Image via Conditional Diffusion Model|密集前体：通过条件扩散模型从稀疏深度和图像学习密集深度图|Ming Yuan, Sichao Wang, Chuang Zhang, Lei He, Qing Xu, Jianqiang Wang|<http://arxiv.org/pdf/2503.23993v1>|- 问题：深度补全，稀疏深度，图像<br />- 方法：扩散模型，特征金字塔，变形注意力<br />- 效果：精度提升，性能优越|
|🆕 发布|DiffScale: Continuous Downscaling and Bias Correction of Subseasonal Wind Speed Forecasts using Diffusion Models|DiffScale：利用扩散模型进行季节内风速预报的连续降尺度和偏差校正|Maximilian Springenberg, Noelia Otero, Yuxin Xue, Jackie Ma|<http://arxiv.org/pdf/2503.23893v1>|- 问题：S2S风速预测，降尺度，偏差校正<br />- 方法：Diffusion模型，超分辨率，无分类器指导<br />- 效果：预测质量提升，泛化能力强|
|🆕 发布|MuseFace: Text-driven Face Editing via Diffusion-based Mask Generation Approach|MuseFace：基于扩散模型掩码生成技术的文本驱动人脸编辑|Xin Zhang, Siting Huang, Xiangyang Luo, Yifan Xie, Weijiang Yu, Heng Chang, Fei Ma, Fei Yu|<http://arxiv.org/pdf/2503.23888v1>|- 问题：文本驱动人脸编辑，多样性，可控性，灵活性<br />- 方法：文本到掩码扩散模型，语义感知人脸编辑<br />- 效果：高保真，精细掩码|
|🆕 发布|Training-Free Text-Guided Image Editing with Visual Autoregressive Model|无训练文本引导的视觉自回归模型图像编辑|Yufei Wang, Lanqing Guo, Zhihao Li, Jiaxing Huang, Pichao Wang, Bihan Wen, Jian Wang|<http://arxiv.org/pdf/2503.23897v1>|- 问题：文本引导图像编辑，逆变换误差，全局修改<br />- 方法：VAR模型，缓存机制，自适应掩码策略<br />- 效果：高保真，快速推理|
|🆕 发布|ExScene: Free-View 3D Scene Reconstruction with Gaussian Splatting from a Single Image|ExScene：基于高斯喷溅的单图像自由视点3D场景重建|Tianyi Gong, Boyan Li, Yifei Zhong, Fangxin Wang|<http://arxiv.org/pdf/2503.23881v1>|- 问题：单视图重建，低一致性，窄视角<br />- 方法：多模态扩散模型，全景深度估计，3D高斯分层<br />- 效果：沉浸式，超越基准|
|📝 更新|Drag Your Gaussian: Effective Drag-Based Editing with Score Distillation for 3D Gaussian Splatting|拖动你的高斯：基于拖动的高效编辑与分数蒸馏用于3D高斯喷溅|Yansong Qu, Dian Chen, Xinyang Li, Xiaofan Li, Shengchuan Zhang, Liujuan Cao, Rongrong Ji|<http://arxiv.org/pdf/2501.18672v5>|[[代码]](<https://quyans.github.io/Drag-Your-Gaussian.>)<br />- 问题：3D编辑，控制不足，几何变化<br />- 方法：拖拽编辑，隐式三平面，Drag-SDS损失<br />- 效果：精确控制，效果提升|
|📝 更新|Controllable Human Image Generation with Personalized Multi-Garments|可控个性化多服装的人类图像生成|Yisol Choi, Sangkyung Kwak, Sihyun Yu, Hyungwon Choi, Jinwoo Shin|<http://arxiv.org/pdf/2411.16801v2>|- 问题：可控人像生成，数据获取困难，多服装<br />- 方法：数据生成，过滤策略，多路径扩散模型<br />- 效果：高质量生成，泛化能力强|
|📝 更新|On-device Sora: Enabling Training-Free Diffusion-based Text-to-Video Generation for Mobile Devices|设备端Sora：为移动设备实现无需训练的基于扩散的文本到视频生成|Bosung Kim, Kyuhwan Lee, Isu Jeong, Jungmin Cheon, Yeojin Lee, Seulki Lee|<http://arxiv.org/pdf/2502.04363v2>|[[代码]](<https://github.com/eai-lab/On-device-Sora>)<br />- 问题：移动设备，扩散模型，训练，视频生成<br />- 方法：LPL，TDTM，CI-DL<br />- 效果：高效，高质量|
|🆕 发布|On-device Sora: Enabling Training-Free Diffusion-based Text-to-Video Generation for Mobile Devices|设备端Sora：为移动设备实现无需训练的基于扩散的文本到视频生成|Bosung Kim, Kyuhwan Lee, Isu Jeong, Jungmin Cheon, Yeojin Lee, Seulki Lee|<http://arxiv.org/pdf/2503.23796v1>|[[代码]](<https://github.com/eai-lab/On-device-Sora>)<br />- 问题：移动设备，扩散模型，文本到视频生成，计算限制<br />- 方法：LPL，TDTM，CI-DL，模型优化<br />- 效果：高效生成，高质量视频|
|📝 更新|MultiBooth: Towards Generating All Your Concepts in an Image from Text|多视角：从文本生成图像中所有概念的方法|Chenyang Zhu, Kai Li, Yue Ma, Chunming He, Xiu Li|<http://arxiv.org/pdf/2404.14239v3>|- 问题：多概念定制，低概念保真度，高推理成本<br />- 方法：单概念学习，多概念集成，概念编码<br />- 效果：概念保真度提升，推理成本降低|
|🆕 发布|StrokeFusion: Vector Sketch Generation via Joint Stroke-UDF Encoding and Latent Sequence Diffusion|中风融合：通过联合中风-UDF 编码和潜在序列扩散生成矢量草图|Jin Zhou, Yi Zhou, Pengfei Xu, Hui Huang|<http://arxiv.org/pdf/2503.23752v1>|- 问题：非矢量草图，特征提取困难，结构完整性受损<br />- 方法：双模态特征学习，UDF编码，潜在序列扩散<br />- 效果：高保真，编辑支持|
|🆕 发布|Expanding-and-Shrinking Binary Neural Networks|扩展与收缩二值神经网络|Xulong Shi, Caiyi Sun, Zhi Qi, Liu Hao, Xiaodong Yang|<http://arxiv.org/pdf/2503.23709v1>|- 问题：BNN精度低，特征表示受限<br />- 方法：扩展-收缩操作，增强特征表示<br />- 效果：泛化好，性能提升|
|🆕 发布|Effective Cloud Removal for Remote Sensing Images by an Improved Mean-Reverting Denoising Model with Elucidated Design Space|基于阐明设计空间的改进均值回归去噪模型的有效云去除遥感图像|Yi Liu, Wengen Li, Jihong Guan, Shuigeng Zhou, Yichao Zhang|<http://arxiv.org/pdf/2503.23717v1>|[[代码]](<https://github.com/Ly403/EMRDM.>)<br />- 问题：云去除，遥感图像，扩散模型，信息丢失<br />- 方法：改进均值回归扩散模型，模块化框架，预条件技术<br />- 效果：性能提升，多时相处理|
|📝 更新|Enhancing Object Coherence in Layout-to-Image Synthesis|增强布局到图像合成中的物体连贯性|Yibin Wang, Changhai Zhou, Honghui Xu|<http://arxiv.org/pdf/2311.10522v7>|- 问题：对象连贯性，语义连贯性，物理连贯性<br />- 方法：扩散模型，GSF，SCA模块<br />- 效果：效果优越|
|📝 更新|Hi3DGen: High-fidelity 3D Geometry Generation from Images via Normal Bridging|Hi3DGen：通过法线桥接从图像中生成高保真3D几何形状|Chongjie Ye, Yushuang Wu, Ziteng Lu, Jiahao Chang, Xiaoyang Guo, Jiaqing Zhou, Hao Zhao, Xiaoguang Han|<http://arxiv.org/pdf/2503.22236v2>|- 问题：高保真3D模型，几何细节，图像模糊<br />- 方法：正常桥接，图像到法线，法线到几何<br />- 效果：高保真，几何细节丰富|
|📝 更新|MovieBench: A Hierarchical Movie Level Dataset for Long Video Generation|电影基准：用于长视频生成的分层电影级别数据集|Weijia Wu, Mingyu Liu, Zeyu Zhu, Xi Xia, Haoen Feng, Wen Wang, Kevin Qinghong Lin, Chunhua Shen .etc.|<http://arxiv.org/pdf/2411.15262v2>|[[代码]](<https://weijiawu.github.io/MovieBench>)<br />- 问题：长视频生成，多场景，连贯叙事<br />- 方法：MovieBench数据集，层次结构，角色一致性<br />- 效果：新视角，挑战，公开数据|
|📝 更新|Diffusion-driven lensless fiber endomicroscopic quantitative phase imaging towards digital pathology|扩散驱动无镜头光纤内窥镜定量相位成像用于数字病理学|Zhaoqing Chen, Jiawei Sun, Xibin Yang, Xinyi Ye, Bin Zhao, Xuelong Li, Juergen Czarske|<http://arxiv.org/pdf/2407.18456v4>|- 问题：单次相位重建，复杂结构，计算挑战<br />- 方法：SpecDiffusion，迭代相位去噪，多步骤重建<br />- 效果：高保真重建，泛化能力强，误差降低|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Optimization of Layer Skipping and Frequency Scaling for Convolutional Neural Networks under Latency Constraint|卷积神经网络在延迟约束下的层跳过和频率缩放优化|Minh David Thao Chan, Ruoyu Zhao, Yukuan Jia, Ruiqing Mao, Sheng Zhou|<http://arxiv.org/pdf/2503.24014v1>|- 问题：CNN能耗，延迟约束，计算复杂度<br />- 方法：层跳过，频率缩放，比例层跳过<br />- 效果：能耗降低，精度损失小|


## 多模态学习 (Multimodal Learning)


### 视觉语言模型 (Vision-Language Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Any2Caption:Interpreting Any Condition to Caption for Controllable Video Generation|任意条件到字幕：将任意条件解释为可控视频生成的字幕|Shengqiong Wu, Weicai Ye, Jiahao Wang, Quande Liu, Xintao Wang, Pengfei Wan, Di Zhang, Kun Gai .etc.|<http://arxiv.org/pdf/2503.24379v1>|- 问题：视频生成，意图理解，条件控制<br />- 方法：条件解耦，多模态模型，指令微调<br />- 效果：可控性提升，视频质量改善|
|🆕 发布|FakeScope: Large Multimodal Expert Model for Transparent AI-Generated Image Forensics|伪造范围：大型多模态专家模型用于透明的人工智能生成图像取证|Yixuan Li, Yu Tian, Yipo Huang, Wei Lu, Shiqi Wang, Weisi Lin, Anderson Rocha|<http://arxiv.org/pdf/2503.24267v1>|- 问题：AI生成图像检测，透明度，可解释性<br />- 方法：专家模型，多模态，FakeChain，FakeInstruct<br />- 效果：高精度，可解释性，零样本能力|
|📝 更新|CASA: Class-Agnostic Shared Attributes in Vision-Language Models for Efficient Incremental Object Detection|CASA：视觉-语言模型中的类无关共享属性，用于高效增量目标检测|Mingyi Guo, Yuyang Liu, Zhiyuan Yan, Zongying Lin, Peixi Peng, Yonghong Tian|<http://arxiv.org/pdf/2410.05804v3>|- 问题：灾难性遗忘，背景偏移，类别遗忘<br />- 方法：CASA，LLM生成属性，属性矩阵<br />- 效果：增量检测，性能领先|
|🆕 发布|Navi-plus: Managing Ambiguous GUI Navigation Tasks with Follow-up|Navi-plus：通过后续操作管理模糊的GUI导航任务|Ziming Cheng, Zhiyuan Huang, Junting Pan, Zhaohui Hou, Mingjie Zhan|<http://arxiv.org/pdf/2503.24180v1>|- 问题：GUI导航任务，信息遗漏，性能受限<br />- 方法：自纠正导航，交互式信息补全，Navi-plus数据集<br />- 效果：性能恢复，任务完成|
|🆕 发布|DANTE-AD: Dual-Vision Attention Network for Long-Term Audio Description|DANTE-AD：用于长期音频描述的双视觉注意力网络|Adrienne Deganutti, Simon Hadfield, Andrew Gilbert|<http://arxiv.org/pdf/2503.24096v1>|- 问题：长视频描述，场景理解，缺乏上下文<br />- 方法：双视觉Transformer，帧级与场景级融合，序列交叉注意力<br />- 效果：NLP指标提升，LLM评价优异|
|🆕 发布|COSMO: Combination of Selective Memorization for Low-cost Vision-and-Language Navigation|COSMO：低成本视觉-语言导航的选优记忆组合|Siqi Zhang, Yanyuan Qiao, Qunbo Wang, Zike Yan, Qi Wu, Zhihua Wei, Jing Liu|<http://arxiv.org/pdf/2503.24065v1>|- 问题：VLN性能，计算成本<br />- 方法：COSMO架构，选择性记忆，RSS，CS3模块<br />- 效果：高性能，低计算成本|
|🆕 发布|H2VU-Benchmark: A Comprehensive Benchmark for Hierarchical Holistic Video Understanding|H2VU-Benchmark：一个用于分层整体视频理解的全面基准|Qi Wu, Quanlong Zheng, Yanhao Zhang, Junlin Xie, Jinguo Luo, Kuo Wang, Peng Liu, Qingsong Xie .etc.|<http://arxiv.org/pdf/2503.24008v1>|- 问题：评估视频理解能力，覆盖范围，任务多样性，场景适应性<br />- 方法：H2VU基准，扩展视频时长，综合评估任务，丰富视频数据<br />- 效果：模型潜力，综合分析|
|📝 更新|InPK: Infusing Prior Knowledge into Prompt for Vision-Language Models|InPK：将先验知识融入视觉-语言模型的提示|Shuchang Zhou, Jiwei Wei, Shiyuan He, Yuyang Zhou, Chaoning Zhang, Jie Zou, Ning Xie, Yang Yang|<http://arxiv.org/pdf/2502.19777v2>|- 问题：Prompt tuning, prior knowledge, overfitting, domain shifts<br />- 方法：InPK model, class-specific prior knowledge, progressive interaction<br />- 效果：zero/few-shot, image classification, outperform|
|📝 更新|Cropper: Vision-Language Model for Image Cropping through In-Context Learning|Cropper：基于上下文学习的图像裁剪视觉-语言模型|Seung Hyun Lee, Jijun Jiang, Yiran Xu, Zhuofang Li, Junjie Ke, Yinxiao Li, Junfeng He, Steven Hickson .etc.|<http://arxiv.org/pdf/2408.07790v2>|- 问题：图像裁剪，适应新需求，VLMs应用<br />- 方法：prompt检索，迭代优化，多任务裁剪<br />- 效果：性能提升，泛化能力强|
|🆕 发布|AirCache: Activating Inter-modal Relevancy KV Cache Compression for Efficient Large Vision-Language Model Inference|AirCache：激活跨模态相关性KV缓存压缩以高效进行大型视觉-语言模型推理|Kai Huang, Hao Zou, Bochen Wang, Ye Xi, Zhen Xie, Hao Wang|<http://arxiv.org/pdf/2503.23956v1>|- 问题：LVLMs推理，KV缓存，计算开销<br />- 方法：AirCache，相关性分析，精英观察窗口<br />- 效果：性能相当，缓存减少，速度提升|
|📝 更新|Mitigating Cache Noise in Test-Time Adaptation for Large Vision-Language Models|减轻大型视觉语言模型测试时自适应中的缓存噪声|Haotian Zhai, Xinyu Chen, Can Zhang, Tianming Sha, Ruirui Li|<http://arxiv.org/pdf/2503.18334v2>|- 问题：缓存噪声，TTA，分布偏移，特征偏差<br />- 方法：CRG，残差参数，GDA<br />- 效果：性能提升，鲁棒性，适应性|
|📝 更新|Beyond Walking: A Large-Scale Image-Text Benchmark for Text-based Person Anomaly Search|超越行走：基于文本的人体异常搜索大规模图像-文本基准|Shuyu Yang, Yaxiong Wang, Li Zhu, Zhedong Zheng|<http://arxiv.org/pdf/2411.17776v2>|[[代码]](<https://github.com/Shuyu-XJTU/CMP.>)<br />- 问题：文本搜索，异常行为，行为识别<br />- 方法：大规模数据集，姿态感知框架，负样本采样<br />- 效果：高召回率，行为检索|
|🆕 发布|Boosting MLLM Reasoning with Text-Debiased Hint-GRPO|提升基于文本偏差的提示-GRPO的MLLM推理|Qihan Huang, Long Chan, Jinlong Liu, Wanggui He, Hao Jiang, Mingli Song, Jingyuan Chen, Chang Yao .etc.|<http://arxiv.org/pdf/2503.23905v1>|[[代码]](<https://github.com/hqhQAQ/Hint-GRPO.>)<br />- 问题：低数据利用，文本偏差，复杂推理任务<br />- 方法：Hint-GRPO，文本偏差校准<br />- 效果：推理能力提升，性能优越|
|📝 更新|HyperGLM: HyperGraph for Video Scene Graph Generation and Anticipation|超图GLM：用于视频场景图生成与预测的超图|Trong-Thuan Nguyen, Pha Nguyen, Jackson Cothren, Alper Yilmaz, Khoa Luu|<http://arxiv.org/pdf/2411.18042v2>|- 问题：视频场景理解，多对象关系，推理能力<br />- 方法：场景超图，实体场景图，因果图，LLM注入<br />- 效果：多任务，性能提升，复杂关系建模|
|📝 更新|Know "No'' Better: A Data-Driven Approach for Enhancing Negation Awareness in CLIP|《知其不可：提升CLIP中否定意识的数据驱动方法》|Junsung Park, Jungbeom Lee, Jongyoon Song, Sangwon Yu, Dahuin Jung, Sungroh Yoon|<http://arxiv.org/pdf/2501.10913v2>|- 问题：CLIP，否定理解，数据不足<br />- 方法：数据生成，LLM，NegationCLIP<br />- 效果：性能提升，多模态任务|
|🆕 发布|Texture or Semantics? Vision-Language Models Get Lost in Font Recognition|纹理还是语义？视觉-语言模型在字体识别中迷失方向|Zhecheng Li, Guoxian Song, Yujun Cai, Zhen Xiong, Junsong Yuan, Yiwei Wang|<http://arxiv.org/pdf/2503.23768v1>|- 问题：VLMs，字体识别，能力，限制<br />- 方法：Font Recognition Benchmark， stroop effect，注意力分析<br />- 效果：性能有限，CoT提示，语义特征|
|🆕 发布|STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World Understanding?|STI-Bench：多模态语言模型是否已准备好精确理解时空世界？|Yun Li, Yiming Zhang, Tao Lin, XiangRui Liu, Wenxiao Cai, Zheng Liu, Bo Zhao|<http://arxiv.org/pdf/2503.23765v1>|- 问题：MLLMs，时空理解，评估，不确定性<br />- 方法：STI-Bench，挑战任务，机器人操作<br />- 效果：MLLMs，时空理解，挑战|
|🆕 发布|KOFFVQA: An Objectively Evaluated Free-form VQA Benchmark for Large Vision-Language Models in the Korean Language|KOFFVQA：针对韩语大型视觉语言模型的客观评估自由形式视觉问答基准|Yoonshik Kim, Jaeyoon Jung|<http://arxiv.org/pdf/2503.23730v1>|[[代码]](<https://github.com/maum-ai/KOFFVQA>)<br />- 问题：主观评估，缺乏韩语基准，开放性问题<br />- 方法：客观评估，预定义规则，韩语VQA基准<br />- 效果：可靠性高，模型评估|
|🆕 发布|HOIGen-1M: A Large-scale Dataset for Human-Object Interaction Video Generation|HOIGen-1M：用于人类-物体交互视频生成的大规模数据集|Kun Liu, Qi Liu, Xinchen Liu, Jie Li, Yongdong Zhang, Jiebo Luo, Xiaodong He, Wu Liu|<http://arxiv.org/pdf/2503.23715v1>|[[代码]](<https://liuqi-creat.github.io/HOIGen.github.io.>)<br />- 问题：HOI视频生成，数据缺乏，模型精度低<br />- 方法：大规模数据集，多模态语言模型，MoME策略<br />- 效果：数据集提升，模型改进|
|🆕 发布|LATex: Leveraging Attribute-based Text Knowledge for Aerial-Ground Person Re-Identification|基于属性文本知识的空中-地面人员重识别|Xiang Hu, Yuhao Wang, Pingping Zhang, Huchuan Lu|<http://arxiv.org/pdf/2503.23722v1>|- 问题：AG-ReID，语义信息，训练成本高<br />- 方法：prompt-tuning，CLIP模型，AIE，PACG，CPT<br />- 效果：性能提升，效率提高|
|📝 更新|MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models|大规模多模态交错理解基准：用于大型视觉-语言模型|Peng Xia, Siwei Han, Shi Qiu, Yiyang Zhou, Zhaoyang Wang, Wenhao Zheng, Zhaorun Chen, Chenhang Cui .etc.|<http://arxiv.org/pdf/2410.10139v2>|[[代码]](<https://mmie-bench.github.io/.>)<br />- 问题：多模态理解评估不足，数据规模小，指标偏差<br />- 方法：大规模知识密集型基准，自动评估指标<br />- 效果：全面评估，揭示模型潜力|
|🆕 发布|The Devil is in the Distributions: Explicit Modeling of Scene Content is Key in Zero-Shot Video Captioning|魔鬼在于分布：在零样本视频字幕生成中，显式建模场景内容至关重要|Mingkai Tian, Guorong Li, Yuankai Qi, Amin Beheshti, Javen Qinfeng Shi, Anton van den Hengel, Qingming Huang|<http://arxiv.org/pdf/2503.23679v1>|- 问题：零样本视频字幕，场景内容建模<br />- 方法：多粒度文本提示，记忆银行，类别感知检索<br />- 效果：CIDEr指标提升|
|📝 更新|Interpretable Few-shot Learning with Online Attribute Selection|可解释的在线属性选择小样本学习|Mohammad Reza Zarei, Majid Komeili|<http://arxiv.org/pdf/2211.09107v3>|- 问题：FSL，决策解释，黑盒模型<br />- 方法：可解释模型，在线属性选择，属性增强<br />- 效果：准确性高，可解释性强|
|🆕 发布|Context-Independent OCR with Multimodal LLMs: Effects of Image Resolution and Visual Complexity|基于多模态大型语言模型的上下文无关OCR：图像分辨率和视觉复杂性的影响|Kotaro Inoue|<http://arxiv.org/pdf/2503.23667v1>|- 问题：OCR性能，图像分辨率，视觉复杂性<br />- 方法：多模态LLMs，单字符图像，视觉复杂度<br />- 效果：识别准确率，分辨率影响|
|📝 更新|Skip-Vision: Efficient and Scalable Acceleration of Vision-Language Models via Adaptive Token Skipping|跳视：通过自适应标记跳过高效且可扩展地加速视觉-语言模型|Weili Zeng, Ziyuan Huang, Kaixiang Ji, Yichao Yan|<http://arxiv.org/pdf/2503.21817v2>|- 问题：计算成本高，视觉token过多<br />- 方法：Skip-FFN，KV-cache移除<br />- 效果：训练时间减少，推理FLOPs降低，延迟减少|
|📝 更新|Will Pre-Training Ever End? A First Step Toward Next-Generation Foundation MLLMs via Self-Improving Systematic Cognition|《预训练何时会结束？通过自我改进的系统认知迈向下一代基础多语言机器学习模型的第一步》|Xiaoying Zhang, Da Peng, Yipeng Zhang, Zonghao Guo, Chengyue Wu, Chi Chen, Wei Ke, Helen Meng .etc.|<http://arxiv.org/pdf/2503.12303v5>|- 问题：模型能力提升，数据限制，预训练，推理时计算，后训练优化<br />- 方法：自改进认知，多模态预训练，自生成数据，链式描述，结构化思维链<br />- 效果：认知能力提升，超越现有方法|
|🆕 发布|DeepDubber-V1: Towards High Quality and Dialogue, Narration, Monologue Adaptive Movie Dubbing Via Multi-Modal Chain-of-Thoughts Reasoning Guidance|DeepDubber-V1：通过多模态思维链推理指导实现高质量、对话、旁白、独白自适应电影配音|Junjie Zheng, Zihao Chen, Chaofan Ding, Xinhan Di|<http://arxiv.org/pdf/2503.23660v1>|- 问题：电影配音，风格适应，情感传达，细节理解<br />- 方法：多模态CoT推理，大语言模型，数据集<br />- 效果：性能提升，SPK-SIM，EMO-SIM，LSE-D，MCD-SL|


### 跨模态对齐 (Cross-modal Alignment)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CIBR: Cross-modal Information Bottleneck Regularization for Robust CLIP Generalization|CIBR：用于鲁棒CLIP泛化的跨模态信息瓶颈正则化|Yingrui Ji, Xi Xiao, Gaofei Chen, Hao Xu, Chenrui Ma, Lijing Zhu, Aokun Liang, Jiansheng Chen|<http://arxiv.org/pdf/2503.24182v1>|- 问题：CLIP泛化能力，信息瓶颈，语义对齐<br />- 方法：CIB框架，CIBR正则化，惩罚项<br />- 效果：性能提升，理论理解|
|🆕 发布|FlexiMo: A Flexible Remote Sensing Foundation Model|FlexiMo：一种灵活的遥感基础模型|Xuyang Li, Chenyu Li, Pedram Ghamisi, Danfeng Hong|<http://arxiv.org/pdf/2503.23844v1>|- 问题：固定分辨率，空间特征限制，模型适应性差<br />- 方法：空间分辨率感知模块，参数自由对齐嵌入，通道自适应<br />- 效果：泛化增强，鲁棒性提升，多任务性能优异|


### 多模态融合 (Multimodal Fusion)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MoMuSE: Momentum Multi-modal Target Speaker Extraction for Real-time Scenarios with Impaired Visual Cues|MoMuSE：基于动量的多模态目标说话人提取，适用于视觉线索受损的实时场景|Junjie Li, Ke Zhang, Shuai Wang, Kong Aik Lee, Man-Wai Mak, Haizhou Li|<http://arxiv.org/pdf/2412.08247v2>|- 问题：AV-TSE稳定性，视觉线索缺失，注意力动量<br />- 方法：MoMuSE，记忆身份动量，实时推理<br />- 效果：显著改进，严重视觉线索缺失场景|
|🆕 发布|AMB-FHE: Adaptive Multi-biometric Fusion with Fully Homomorphic Encryption|自适应多生物特征融合与全同态加密|Florian Bayer, Christian Rathgeb|<http://arxiv.org/pdf/2503.23949v1>|- 问题：隐私保护，多模态融合，同态加密，生物识别<br />- 方法：自适应融合，模板加密，深度学习<br />- 效果：隐私增强，灵活性提升|
|🆕 发布|AdaMMS: Model Merging for Heterogeneous Multimodal Large Language Models with Unsupervised Coefficient Optimization|AdaMMS：异构多模态大型语言模型的模型融合与无监督系数优化|Yiyang Du, Xiaochen Wang, Chi Chen, Jiabo Ye, Yiru Wang, Peng Li, Ming Yan, Ji Zhang .etc.|<http://arxiv.org/pdf/2503.23733v1>|- 问题：异构MLLMs，模型融合，参数空间不对称<br />- 方法：映射函数，线性插值，无监督超参数优化<br />- 效果：超越前人，视觉语言基准|


## 目标检测识别 (Object Detection & Recognition)


### 三维检测 (3D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Point Tracking in Surgery--The 2024 Surgical Tattoos in Infrared (STIR) Challenge|手术中的点跟踪——2024年红外（STIR）手术纹身挑战|Adam Schmidt, Mert Asim Karaoglu, Soham Sinha, Mingang Jang, Ho-Gun Ha, Kyungmin Jung, Kyeongmo Gu, Ihsan Ullah .etc.|<http://arxiv.org/pdf/2503.24306v1>|[[代码]](<https://github.com/athaddius/STIRMetrics>)<br />- 问题：手术中组织运动理解，算法量化，数据集<br />- 方法：红外手术纹身(STIR)挑战，准确性，效率<br />- 效果：算法评估，准确性，效率|
|📝 更新|Perceptually Accurate 3D Talking Head Generation: New Definitions, Speech-Mesh Representation, and Evaluation Metrics|感知准确的3D说话人头生成：新定义、语音-网格表示和评估指标|Lee Chae-Yeon, Oh Hyun-Bin, Han EunGi, Kim Sung-Bin, Suekyeong Nam, Tae-Hyun Oh|<http://arxiv.org/pdf/2503.20308v3>|[[代码]](<https://perceptual-3d-talking-head.github.io/.>)<br />- 问题：唇同步，感知对齐，语音特征<br />- 方法：语音-网格表示，感知损失，评估指标<br />- 效果：唇同步提升，感知准确|
|🆕 发布|GLane3D : Detecting Lanes with Graph of 3D Keypoints|GLane3D：基于3D关键点图的车道检测|Halil İbrahim Öztürk, Muhammet Esat Kalfaoğlu, Ozsel Kilinc|<http://arxiv.org/pdf/2503.23882v1>|- 问题：3D车道检测，泛化能力，车道结构变异性<br />- 方法：3D关键点检测，图结构预测，PointNMS<br />- 效果：F1分数提升，泛化能力强|
|📝 更新|Synthetic Prior for Few-Shot Drivable Head Avatar Inversion|合成先验用于少量样本可驾驶头部头像逆转换|Wojciech Zielonka, Stephan J. Garbin, Alexandros Lattas, George Kopanas, Paulo Gotardo, Thabo Beeler, Justus Thies, Timo Bolkart|<http://arxiv.org/pdf/2501.06903v3>|- 问题：少样本，可驱动，头像逆生成，数据限制，泛化能力<br />- 方法：合成先验，3D生成网络，Gaussian splatting，卷积编码器-解码器<br />- 效果：泛化提升，视图合成，表情合成|
|🆕 发布|WaveFormer: A 3D Transformer with Wavelet-Driven Feature Representation for Efficient Medical Image Segmentation|波前器：一种用于高效医学图像分割的3D Transformer和基于小波驱动的特征表示|Md Mahfuz Al Hasan, Mahdi Zaman, Abdul Jawad, Alberto Santamaria-Pang, Ho Hin Lee, Ivan Tarapov, Kyle See, Md Shah Imran .etc.|<http://arxiv.org/pdf/2503.23764v1>|- 问题：3D图像分割，长距离依赖，局部特征，计算资源<br />- 方法：3D Transformer，小波变换，上下文表示<br />- 效果：性能相当，计算复杂度低|


### 二维检测 (2D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Order Matters: On Parameter-Efficient Image-to-Video Probing for Recognizing Nearly Symmetric Actions|参数高效近对称动作识别的图像到视频探针：顺序很重要|Thinesh Thiyakesan Ponbagavathi, Alina Roitberg|<http://arxiv.org/pdf/2503.24298v1>|- 问题：近对称动作识别，参数高效，时间建模<br />- 方法：Self-attentive Temporal Embedding Probing (STEP)，位置编码，CLS token<br />- 效果：性能提升，参数减少|
|🆕 发布|MB-ORES: A Multi-Branch Object Reasoner for Visual Grounding in Remote Sensing|MB-ORES：一种用于遥感视觉定位的多分支物体推理器|Karim Radouane, Hanane Azzag, Mustapha lebbah|<http://arxiv.org/pdf/2503.24219v1>|[[代码]](<https://github.com/rd20karim/MB-ORES>)<br />- 问题：视觉定位，目标检测，遥感图像<br />- 方法：多分支网络，对象推理，图表示<br />- 效果：性能提升，优于现有方法|
|🆕 发布|Video-based Traffic Light Recognition by Rockchip RV1126 for Autonomous Driving|基于Rockchip RV1126的视频交通灯识别技术用于自动驾驶|Miao Fan, Xuxu Kong, Shengtong Xu, Haoyi Xiong, Xiangzeng Liu|<http://arxiv.org/pdf/2503.23965v1>|- 问题：交通灯识别，复杂场景，实时性<br />- 方法：视频分析，Transformer，嵌入式平台<br />- 效果：性能领先，实时处理|
|📝 更新|TransXNet: Learning Both Global and Local Dynamics with a Dual Dynamic Token Mixer for Visual Recognition|TransXNet：使用双重动态标记混合器学习全局和局部动态的视觉识别|Meng Lou, Shu Zhang, Hong-Yu Zhou, Sibei Yang, Chuan Wu, Yizhou Yu|<http://arxiv.org/pdf/2310.19380v4>|[[代码]](<https://github.com/LMMMEng/TransXNet.>)<br />- 问题：动态适应，特征融合，表示能力<br />- 方法：D-Mixer，全局/局部动态学习，CNN-Transformer<br />- 效果：性能提升，成本降低|
|📝 更新|Context-Aware Weakly Supervised Image Manipulation Localization with SAM Refinement|基于SAM精炼的上下文感知弱监督图像操纵定位|Xinghao Wang, Tao Gong, Qi Chu, Bin Liu, Nenghai Yu|<http://arxiv.org/pdf/2503.20294v2>|- 问题：弱监督图像篡改定位，边缘信息，定位性能<br />- 方法：CABL模块，CAM-Guided SAM Refinement，Transformer-CNN<br />- 效果：定位性能提升，多数据集表现优异|


### 多目标跟踪 (Multi-object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Exploring Temporal Dynamics in Event-based Eye Tracker|探索基于事件的眼睛追踪器中的时间动态|Hongwei Ren, Xiaopeng Lin, Hongxiang Huang, Yue Zhou, Bojun Cheng|<http://arxiv.org/pdf/2503.23725v1>|[[代码]](<https://github.com/rhwxmx/TDTracker.>)<br />- 问题：眼动追踪，时间分辨率，快速眼动<br />- 方法：TDTracker，3D卷积，GRU，Mamba<br />- 效果：SOTA性能，CVPR挑战赛第三|


## 三维重建 (3D Reconstruction)


### 神经隐式重建 (Neural Implicit Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DH-Mamba: Exploring Dual-domain Hierarchical State Space Models for MRI Reconstruction|DH-Mamba：探索用于MRI重建的双域分层状态空间模型|Yucong Meng, Zhiwei Yang, Zhijian Song, Yonghong Shi|<http://arxiv.org/pdf/2501.08163v3>|- 问题：MRI重建，欠采样，长距离依赖，空间变化<br />- 方法：k空间学习，层次Mamba，局部多样性增强<br />- 效果：性能提升，计算成本低|
|🆕 发布|Learning Bijective Surface Parameterization for Inferring Signed Distance Functions from Sparse Point Clouds with Grid Deformation|学习具有网格变形的从稀疏点云推断符号距离函数的双射表面参数化|Takeshi Noda, Chao Chen, Junsheng Zhou, Weiqi Zhang, Yu-Shen Liu, Zhizhong Han|<http://arxiv.org/pdf/2503.23670v1>|[[代码]](<https://takeshie.github.io/Bijective-SDF>)<br />- 问题：SDF推断，稀疏点云，几何信息缺乏<br />- 方法：动态变形网络，BSP参数化，网格变形优化<br />- 效果：性能优于现有方法|


### 单目重建 (Monocular Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Gen3DSR: Generalizable 3D Scene Reconstruction via Divide and Conquer from a Single View|Gen3DSR：基于单视图的划分与征服的通用3D场景重建|Andreea Ardelean, Mert Özer, Bernhard Egger|<http://arxiv.org/pdf/2404.03421v2>|[[代码]](<https://andreeadogaru.github.io/Gen3DSR>)<br />- 问题：单视图3D重建，场景多样性，3D数据监督，图像先验<br />- 方法：混合方法，分而治之，模块化设计<br />- 效果：泛化能力强，无需重训练|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Exploring Reliable PPG Authentication on Smartwatches in Daily Scenarios|探索日常场景中智能手表上可靠的PPG身份验证|Jiankai Tang, Jiacheng Liu, Renling Tong, Kai Zhu, Zhe Li, Xin Yi, Junliang Xing, Yuanchun Shi .etc.|<http://arxiv.org/pdf/2503.23930v1>|- 问题：PPG认证可靠性，运动伪影，生理变化<br />- 方法：MTL-RAPID，多任务联合训练，信号质量评估<br />- 效果：AUC 99.2%，EER 3.5%，性能提升|


### 多视图重建 (Multi-view Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|3D Dental Model Segmentation with Geometrical Boundary Preserving|三维牙科模型几何边界保持分割|Shufan Xi, Zexian Liu, Junlin Chang, Hongyu Wu, Xiaogang Wang, Aimin Hao|<http://arxiv.org/pdf/2503.23702v1>|- 问题：3D牙模分割，精度低，几何细节丢失<br />- 方法：3D mesh downsampling，多视角特征提取，点网络<br />- 效果：精度提升，几何边界保留|
|🆕 发布|Detail-aware multi-view stereo network for depth estimation|深度估计的细节感知多视图立体网络|Haitao Tian, Junyang Li, Chenxing Wang, Helong Jiang|<http://arxiv.org/pdf/2503.23684v1>|[[代码]](<https://github.com/wsmtht520-/DAMVSNet.>)<br />- 问题：边界深度恢复，细节区域，几何结构<br />- 方法：DA-MVSNet，粗细框架，图像合成损失<br />- 效果：精度提升，结果竞争|


## 神经渲染 (Neural Rendering)


### 神经辐射场 (Neural Radiance Fields)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Free360: Layered Gaussian Splatting for Unbounded 360-Degree View Synthesis from Extremely Sparse and Unposed Views|Free360：从极稀疏和无定位视角的无限360度视图合成中的分层高斯喷溅|Chong Bao, Xiyu Zhang, Zehao Yu, Jiale Shi, Guofeng Zhang, Songyou Peng, Zhaopeng Cui|<http://arxiv.org/pdf/2503.24382v1>|[[代码]](<https://zju3dv.github.io/free360>)<br />- 问题：稀疏视角，无姿态，360度场景<br />- 方法：分层高斯，密集立体重建，迭代融合<br />- 效果：渲染质量高，表面重建准确|
|🆕 发布|ERUPT: Efficient Rendering with Unposed Patch Transformer|ERUPT：基于未定位补丁变换器的有效渲染|Maxim V. Shugaev, Vincent Chen, Maxim Karrenbach, Kyle Ashley, Bridget Kennedy, Naresh P. Cuntoor|<http://arxiv.org/pdf/2503.24374v1>|- 问题：新型视图合成，小集合RGB图像，无姿态图像<br />- 方法：patch-based querying，学习潜在相机姿态，MSVS-1M数据集<br />- 效果：渲染效率高，图像质量好，数据需求低|
|🆕 发布|DiET-GS: Diffusion Prior and Event Stream-Assisted Motion Deblurring 3D Gaussian Splatting|DiET-GS：扩散先验和事件流辅助的运动去模糊3D高斯分层|Seungjun Lee, Gim Hee Lee|<http://arxiv.org/pdf/2503.24210v1>|- 问题：3D图像去模糊，色彩恢复，细节保留<br />- 方法：扩散先验，事件流辅助，3D高斯分层<br />- 效果：高质量视图，优于基线|
|📝 更新|RadSplat: Radiance Field-Informed Gaussian Splatting for Robust Real-Time Rendering with 900+ FPS|RadSplat：基于辐射场信息的高斯分层渲染，实现超过900 FPS的鲁棒实时渲染|Michael Niemeyer, Fabian Manhardt, Marie-Julie Rakotosaona, Michael Oechsle, Daniel Duckworth, Rama Gosula, Keisuke Tateno, John Bates .etc.|<http://arxiv.org/pdf/2403.13806v2>|- 问题：实时渲染，高计算需求，优化困难<br />- 方法：辐射场，Gaussian Splatting，优化<br />- 效果：高帧率，高质量|
|📝 更新|Disentangled 4D Gaussian Splatting: Towards Faster and More Efficient Dynamic Scene Rendering|解耦四维高斯分层：迈向更快、更高效的动态场景渲染|Hao Feng, Hao Sun, Wei Xie|<http://arxiv.org/pdf/2503.22159v2>|- 问题：动态场景渲染，计算复杂，冗余计算<br />- 方法：解耦4D高斯，4D到3D投影，高效表示<br />- 效果：渲染速度提升，存储需求降低|
|🆕 发布|Uni-Render: A Unified Accelerator for Real-Time Rendering Across Diverse Neural Renderers|统一渲染器：跨多种神经渲染器的实时渲染统一加速器|Chaojian Li, Sixu Li, Linrui Jiang, Jingqun Zhang, Yingyan Celine Lin|<http://arxiv.org/pdf/2503.23644v1>|- 问题：实时渲染，算法通用性，设备兼容性<br />- 方法：统一加速器，可重构硬件，动态调整<br />- 效果：实时渲染，效率兼容|


### 可控渲染 (Controllable Rendering)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|StochasticSplats: Stochastic Rasterization for Sorting-Free 3D Gaussian Splatting|标题翻译：随机喷溅：无排序3D高斯喷溅的随机光栅化|Shakiba Kheradmand, Delio Vicini, George Kopanas, Dmitry Lagun, Kwang Moo Yi, Mark Matthews, Andrea Tagliasacchi|<http://arxiv.org/pdf/2503.24366v1>|- 问题：3DGS，深度排序，渲染伪影，成本控制，视觉保真<br />- 方法：随机光栅化，蒙特卡洛估计，无排序<br />- 效果：渲染速度提升，质量可控|
|🆕 发布|Learning 3D-Gaussian Simulators from RGB Videos|从RGB视频中学习3D高斯模拟器|Mikel Zhobro, Andreas René Geist, Georg Martius|<http://arxiv.org/pdf/2503.24009v1>|- 问题：视频数据，物理模拟，空间时间一致性<br />- 方法：3D高斯粒子，Transformer，逆渲染<br />- 效果：物理行为，光照效果|
|📝 更新|Gaussian Eigen Models for Human Heads|高斯特征模型在人头识别中的应用|Wojciech Zielonka, Timo Bolkart, Thabo Beeler, Justus Thies|<http://arxiv.org/pdf/2407.04545v4>|- 问题：个性化头像，轻量级，高质量<br />- 方法：Gaussian Eigen Models，3D Gaussian primitives，Gaussian splatting<br />- 效果：高视觉质量，泛化能力强|
|📝 更新|3D-GSW: 3D Gaussian Splatting for Robust Watermarking|3D高斯分层渲染：用于鲁棒水印的3D高斯分层|Youngdong Jang, Hyunje Park, Feng Yang, Heeju Ko, Euijin Choo, Sangpil Kim|<http://arxiv.org/pdf/2409.13222v4>|[[代码]](<https://kuai-lab.github.io/cvpr20253dgsw>)<br />- 问题：3D-GS水印，版权保护，模型攻击<br />- 方法：Frequency-Guided Densification，FGD，梯度掩码<br />- 效果：鲁棒性，渲染质量|


## 定位与映射 (Localization & Mapping)


### 位姿估计 (Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Easi3R: Estimating Disentangled Motion from DUSt3R Without Training|Easi3R：无需训练从DUSt3R中估计解耦运动|Xingyu Chen, Yue Chen, Yuliang Xiu, Andreas Geiger, Anpei Chen|<http://arxiv.org/pdf/2503.24391v1>|- 问题：4D数据集规模小，模型泛化能力差<br />- 方法：无监督训练，注意力适应，解耦运动估计<br />- 效果：超越现有方法，轻量级，准确度高|
|📝 更新|Image as an IMU: Estimating Camera Motion from a Single Motion-Blurred Image|图像作为IMU：从单个运动模糊图像估计相机运动|Jerred Chen, Ronald Clark|<http://arxiv.org/pdf/2503.17358v2>|- 问题：运动模糊，相机姿态估计，机器人，VR/AR<br />- 方法：运动流场，深度图，线性最小二乘<br />- 效果：IMU-like测量，速度估计|
|📝 更新|YOLO11 and Vision Transformers based 3D Pose Estimation of Immature Green Fruits in Commercial Apple Orchards for Robotic Thinning|基于YOLO11和视觉Transformer的商业苹果园中未成熟绿色水果的3D姿态估计与机器人疏花|Ranjan Sapkota, Manoj Karkee|<http://arxiv.org/pdf/2410.19846v3>|- 问题：3D姿态估计，果实识别，机器人疏花<br />- 方法：YOLO11检测，ViT深度估计，Depth Anything V2<br />- 效果：精度高，速度快|
|🆕 发布|LiM-Loc: Visual Localization with Dense and Accurate 3D Reference Maps Directly Corresponding 2D Keypoints to 3D LiDAR Point Clouds|LiM-Loc：与密集且精确的3D参考地图直接对应2D关键点的3D激光雷达点云视觉定位|Masahiko Tsuji, Hitoshi Niigaki, Ryuichi Tanida|<http://arxiv.org/pdf/2503.23664v1>|- 问题：视觉定位，3D参考图，稀疏，不准确<br />- 方法：3D LiDAR，直接对应，稀疏映射<br />- 效果：高精度，宽域定位|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Comparative Study of Scanpath Models in Graph-Based Visualization|基于图可视化的扫描路径模型比较研究|Angela Lopez-Cardona, Parvin Emami, Sebastian Idesis, Saravanakumar Duraisamy, Luis A. Leiva, Ioannis Arapakis|<http://arxiv.org/pdf/2503.24160v1>|- 问题：眼动追踪，信息可视化，模型预测<br />- 方法：眼动实验，模型比较，复杂度分析<br />- 效果：模型评估，设计优化|
|🆕 发布|PixelCAM: Pixel Class Activation Mapping for Histology Image Classification and ROI Localization|像素CAM：用于组织学图像分类和ROI定位的像素级激活映射|Alexis Guichemerre, Soufiane Belharbi, Mohammadhadi Shateri, Luke McCaffrey, Eric Granger|<http://arxiv.org/pdf/2503.24135v1>|- 问题：WSOL局限性，异步收敛，定位精度低<br />- 方法：PixelCAM，多任务学习，像素级分类<br />- 效果：ROI定位准确，分类性能提升|
|🆕 发布|AMMSM: Adaptive Motion Magnification and Sparse Mamba for Micro-Expression Recognition|自适应运动放大与稀疏Mamba用于微表情识别|Xuxiong Liu, Tengteng Dong, Fei Wang, Weijie Feng, Xiao Sun|<http://arxiv.org/pdf/2503.24057v1>|- 问题：微表情识别，短时，信号微弱<br />- 方法：多任务学习，自监督，Mamba架构<br />- 效果：SOTA精度，鲁棒性|
|🆕 发布|ZeroMimic: Distilling Robotic Manipulation Skills from Web Videos|ZeroMimic：从网络视频中提炼机器人操作技能|Junyao Shi, Zhuolun Zhao, Tianyou Wang, Ian Pedroza, Amy Luo, Jie Wang, Jason Ma, Dinesh Jayaraman|<http://arxiv.org/pdf/2503.23877v1>|- 问题：模仿学习，数据限制，技能蒸馏<br />- 方法：视频理解，抓取检测，策略生成<br />- 效果：多任务，泛化强，可重用|


### 语义建图 (Semantic Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Benchmark for Vision-Centric HD Mapping by V2I Systems|基于V2I系统的视觉中心高清地图基准测试|Miao Fan, Shanshan Yu, Shengtong Xu, Kun Jiang, Haoyi Xiong, Xiangzeng Liu|<http://arxiv.org/pdf/2503.23963v1>|- 问题：安全挑战，缺乏全局视角，语义信息，地图向量化，V2I通信<br />- 方法：真实世界数据集，V2I-HD框架，方向性解耦自注意力机制<br />- 效果：实时推理，稳定鲁棒，低成本|


### 视觉SLAM (Visual SLAM)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CoMatch: Dynamic Covisibility-Aware Transformer for Bilateral Subpixel-Level Semi-Dense Image Matching|CoMatch：动态共视性感知Transformer在双边亚像素级半密集图像匹配中的应用|Zizhuo Li, Yifan Lu, Linfeng Tang, Shihua Zhang, Jiayi Ma|<http://arxiv.org/pdf/2503.23925v1>|- 问题：图像匹配精度，计算效率，泛化能力<br />- 方法：动态可见性，注意力机制，细粒度匹配<br />- 效果：精度提升，效率提高|


## 自监督学习 (Self-supervised Learning)


### 对比学习 (Contrastive Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RingMo-Aerial: An Aerial Remote Sensing Foundation Model With A Affine Transformation Contrastive Learning|环视-空中：一种具有仿射变换对比学习的空中遥感基础模型|Wenhui Diao, Haichen Yu, Kaiyue Kang, Tong Ling, Di Liu, Yingchao Feng, Hanbo Bi, Libo Ren .etc.|<http://arxiv.org/pdf/2409.13366v2>|- 问题：ARS视觉任务，视角特性，算法局限性<br />- 方法：FE-MSA机制，对比学习，ARS-Adapter<br />- 效果：SOTA性能，适应性，有效性|
|🆕 发布|Every Painting Awakened: A Training-free Framework for Painting-to-Animation Generation|每一幅画作都被唤醒：一种无需训练的绘画到动画生成框架|Lingyu Liu, Yaxiong Wang, Li Zhu, Zhedong Zheng|<http://arxiv.org/pdf/2503.23736v1>|- 问题：静态绘画动画，文本指导，视觉一致性<br />- 方法：预训练模型，合成代理图像，双路径架构<br />- 效果：语义对齐，动态效果|


### 掩码自编码 (Masked Autoencoding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Bootstrap Your Own Views: Masked Ego-Exo Modeling for Fine-grained View-invariant Video Representations|自举您的视图：掩码自我-外部建模用于细粒度视图不变视频表示|Jungin Park, Jiyoung Lee, Kwanghoon Sohn|<http://arxiv.org/pdf/2503.19706v2>|[[代码]](<https://github.com/park-jungin/byov.>)<br />- 问题：视角不变性，视频理解，视角差异<br />- 方法：掩码建模，因果时间动态，跨视角对齐<br />- 效果：性能提升，多任务表现|


### 一致性学习 (Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Consistency-aware Self-Training for Iterative-based Stereo Matching|基于迭代立体匹配的一致性感知自训练|Jingyi Zhou, Peng Ye, Haoyu Zhang, Jiakang Yuan, Rao Qiang, Liu YangChenXu, Wu Cailin, Feng Xu .etc.|<http://arxiv.org/pdf/2503.23747v1>|- 问题：迭代立体匹配，依赖标签数据，性能退化<br />- 方法：一致性感知自训练，软滤波模块，软加权损失<br />- 效果：性能提升，SOTA方法改进|
|📝 更新|Towards Geometric-Photometric Joint Alignment for Facial Mesh Registration|面向几何-光度联合对齐的人脸网格配准|Xizhi Wang, Yaxiong Wang, Mengjian Li|<http://arxiv.org/pdf/2403.02629v2>|- 问题：面部网格注册，纹理不一致，拓扑不一致<br />- 方法：GPJA，可微分渲染，多尺度优化<br />- 效果：像素级精度，纹理一致性|


## 迁移与适应 (Transfer & Adaptation)


### 域适应 (Domain Adaptation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|The impact of internal variability on benchmarking deep learning climate emulators|内部变异性对深度学习气候模拟器基准测试的影响|Björn Lütjens, Raffaele Ferrari, Duncan Watson-Parris, Noelle Selin|<http://arxiv.org/pdf/2408.05288v2>|[[代码]](<https://github.com/blutjens/climate-emulator.>)<br />- 问题：气候模拟，深度学习，内部变异性，基准测试<br />- 方法：线性回归，气候模拟增加，基准更新<br />- 效果：线性模拟优于深度学习，降水模拟改进|
|🆕 发布|Foundation Models For Seismic Data Processing: An Extensive Review|地震数据处理的基础模型：全面综述|Fabian Fuchs, Mario Ruben Fernandez, Norman Ettrich, Janis Keuper|<http://arxiv.org/pdf/2503.24166v1>|- 问题：地震数据处理，深度学习，数据依赖，模型性能<br />- 方法：基础模型应用，模型特性评估，自然图像模型<br />- 效果：性能提升，效率优化|
|🆕 发布|From Colors to Classes: Emergence of Concepts in Vision Transformers|从颜色到类别：视觉Transformer中概念的涌现|Teresa Dorszewski, Lenka Tětková, Robert Jenssen, Lars Kai Hansen, Kristoffer Knutsen Wickstrøm|<http://arxiv.org/pdf/2503.24071v1>|- 问题：ViT信息处理，层间理解，概念编码<br />- 方法：层间分析，神经元标注，预训练策略<br />- 效果：概念复杂性，特征多样性，任务相关性|
|📝 更新|DSU-Net:An Improved U-Net Model Based on DINOv2 and SAM2 with Multi-scale Cross-model Feature Enhancement|DSU-Net：基于DINOv2和SAM2的多尺度跨模型特征增强的改进U-Net模型|Yimin Xu, Fan Yang, Bin Xu|<http://arxiv.org/pdf/2503.21187v2>|[[代码]](<https://github.com/CheneyXuYiMin/SAM2DINO-Seg>)<br />- 问题：训练成本高，特征表示不足<br />- 方法：特征协作框架，轻量级适配器，跨模态融合<br />- 效果：性能提升，高效部署|
|🆕 发布|Evaluation of (Un-)Supervised Machine Learning Methods for GNSS Interference Classification with Real-World Data Discrepancies|基于真实世界数据差异的GNSS干扰分类（无）监督机器学习方法评估|Lucas Heublein, Nisha L. Raichur, Tobias Feigl, Tobias Brieger, Fin Heuer, Lennart Asbach, Alexander Rügamer, Felix Ott|<http://arxiv.org/pdf/2503.23775v1>|- 问题：GNSS干扰分类，数据集，现实差异<br />- 方法：大规模测量，伪标签，数据集融合<br />- 效果：性能评估，模型适应|
|🆕 发布|Investigation of intelligent barbell squat coaching system based on computer vision and machine learning|基于计算机视觉和机器学习的智能哑铃深蹲训练系统研究|Yinq-Rong Chern, Yuhao Lee, Hsiao-Ching Lin, Guan-Ting Chen, Ying-Hsien Chen, Fu-Sung Lin, Chih-Yao Chuang, Jenn-Jier James Lien .etc.|<http://arxiv.org/pdf/2503.23731v1>|- 问题：运动诊断，训练反馈，技术改进<br />- 方法：计算机视觉，机器学习，SHAP方法<br />- 效果：高准确率，实时反馈|
|🆕 发布|ElimPCL: Eliminating Noise Accumulation with Progressive Curriculum Labeling for Source-Free Domain Adaptation|消除噪声累积：基于渐进式课程标注的源域自适应去噪|Jie Cheng, Hao Zheng, Meiguang Zheng, Lei Wang, Hao Wu, Jian Zhang|<http://arxiv.org/pdf/2503.23712v1>|- 问题：噪声累积，伪标签不确定性，领域偏移<br />- 方法：ElimPCL，原型一致性，Dual MixUP<br />- 效果：性能提升，3.4%改进|


### 增量学习 (Incremental Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Plasticity-Aware Method for Continual Self-Supervised Learning in Remote Sensing|一种针对遥感领域持续自监督学习的可塑性感知方法|Lars Möllenbrok, Behnood Rasti, Begüm Demir|<http://arxiv.org/pdf/2503.24088v1>|- 问题：CSSL，遗忘，适应性，性能下降<br />- 方法：知识蒸馏，解耦机制，特征划分<br />- 效果：精度提升，遗忘减少|
|📝 更新|Bayesian Learning-driven Prototypical Contrastive Loss for Class-Incremental Learning|基于贝叶斯学习的类增量学习原型对比损失|Nisha L. Raichur, Lucas Heublein, Tobias Feigl, Alexander Rügamer, Christopher Mutschler, Felix Ott|<http://arxiv.org/pdf/2405.11067v3>|- 问题：灾难性遗忘，类增量学习<br />- 方法：贝叶斯学习，对比损失，原型网络<br />- 效果：性能优越，验证有效|
|📝 更新|LoRA Subtraction for Drift-Resistant Space in Exemplar-Free Continual Learning|无示例持续学习中的漂移抵抗空间LoRA减法|Xuan Liu, Xiaobin Chang|<http://arxiv.org/pdf/2503.18985v2>|- 问题：特征漂移，灾难性遗忘，EFCL，知识保留<br />- 方法：DRS，LoRA-，参数高效微调<br />- 效果：稳定性提升，效率提高，性能优异|


### 元学习 (Meta Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Convolutional Kolmogorov-Arnold Networks|卷积高斯-阿诺德网络|Alexander Dylan Bodner, Antonio Santiago Tepsich, Jack Natan Spolski, Santiago Pourteau|<http://arxiv.org/pdf/2406.13155v3>|- 问题：CNN参数效率低，表达能力不足<br />- 方法：Kolmogorov-Arnold Networks，可学习激活函数，卷积层集成<br />- 效果：参数效率高，精度高，资源少|


## 鲁棒学习 (Robust Learning)


### 对抗训练 (Adversarial Training)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Exploring the Effect of Reinforcement Learning on Video Understanding: Insights from SEED-Bench-R1|探索强化学习对视频理解的影响：SEED-Bench-R1的见解|Yi Chen, Yuying Ge, Rui Wang, Yixiao Ge, Lu Qiu, Ying Shan, Xihui Liu|<http://arxiv.org/pdf/2503.24376v1>|- 问题：视频理解，多模态LLMs，推理能力<br />- 方法：SEED-Bench-R1，RL，SFT<br />- 效果：数据效率，性能提升|
|🆕 发布|BBoxCut: A Targeted Data Augmentation Technique for Enhancing Wheat Head Detection Under Occlusions|BBoxCut：一种针对遮挡下小麦穗检测增强的定向数据增强技术|Yasashwini Sai Gowri P, Karthik Seemakurthy, Andrews Agyemang Opoku, Sita Devi Bharatula|<http://arxiv.org/pdf/2503.24032v1>|- 问题：小麦头检测，遮挡，自动化，数据增强<br />- 方法：BBoxCut，随机局部遮挡，模拟遮挡<br />- 效果：mAP提升，鲁棒性增强|
|📝 更新|Adaptive Multi-step Refinement Network for Robust Point Cloud Registration|自适应多步细化网络用于鲁棒点云配准|Zhi Chen, Yufan Ren, Tong Zhang, Zheng Dang, Wenbing Tao, Sabine Süsstrunk, Mathieu Salzmann|<http://arxiv.org/pdf/2312.03053v2>|- 问题：点云配准，重叠区域小，学习算法<br />- 方法：自适应多步细化网络，注意力机制，训练过程<br />- 效果：性能提升，3DLoMatch 80.4%召回率|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Self-Supervised Pretraining for Aerial Road Extraction|自监督预训练用于航空道路提取|Rupert Polley, Sai Vignesh Abishek Deenadayalan, J. Marius Zöllner|<http://arxiv.org/pdf/2503.24326v1>|- 问题：数据稀缺，标注昂贵，分割精度低<br />- 方法：自监督预训练，图像修复，结构学习<br />- 效果：精度提升，泛化增强|


### 对抗防御 (Adversarial Defense)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|4D mmWave Radar in Adverse Environments for Autonomous Driving: A Survey|4D 毫米波雷达在恶劣环境下的自动驾驶：综述|Xiangyuan Peng, Miao Tang, Huawei Sun, Lorenzo Servadei, Robert Wille|<http://arxiv.org/pdf/2503.24091v1>|- 问题：自动驾驶感知，恶劣环境，雷达性能<br />- 方法：4D mmWave雷达，数据集，方法分析<br />- 效果：感知准确，鲁棒性强|
|📝 更新|Resilient Sensor Fusion under Adverse Sensor Failures via Multi-Modal Expert Fusion|基于多模态专家融合的鲁棒传感器融合在恶劣传感器故障下|Konyul Park, Yecheol Kim, Daehun Kim, Jun Won Choi|<http://arxiv.org/pdf/2503.19776v2>|- 问题：传感器融合，性能下降，模态依赖<br />- 方法：多模态专家融合，混合专家方法，自适应查询路由<br />- 效果：鲁棒性能，极端条件，性能领先|


### 对抗攻击 (Adversarial Attack)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Data-free Universal Adversarial Perturbation with Pseudo-semantic Prior|无数据通用对抗扰动与伪语义先验|Chanhui Lee, Yeonghwan Song, Jeany Son|<http://arxiv.org/pdf/2502.21048v2>|[[代码]](<https://github.com/ChnanChan/PSP-UAP.>)<br />- 问题：数据无关，泛化攻击，语义内容，迁移性差<br />- 方法：伪语义先验，区域采样，样本重加权<br />- 效果：攻击成功率，迁移性，超越数据依赖|


## 模型压缩加速 (Model Compression & Acceleration)


### 量化优化 (Quantization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Style Quantization for Data-Efficient GAN Training|数据高效GAN训练的风格量化|Jian Wang, Xin Lan, Jizhe Zhou, Yuxin Tian, Jiancheng Lv|<http://arxiv.org/pdf/2503.24282v1>|- 问题：数据有限，GAN训练困难，CR效果差<br />- 方法：风格量化，CR优化，代码簿学习<br />- 效果：生成质量提升，判别器鲁棒性增强|


### 知识蒸馏 (Knowledge Distillation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Crossmodal Knowledge Distillation with WordNet-Relaxed Text Embeddings for Robust Image Classification|跨模态知识蒸馏：利用WordNet-Relaxed文本嵌入实现鲁棒图像分类|Chenqi Guo, Mengshuo Rong, Qianli Feng, Rongfan Feng, Yinglong Ma|<http://arxiv.org/pdf/2503.24017v1>|- 问题：知识蒸馏，标签泄漏，语义结构<br />- 方法：WordNet-Relaxed，多教师框架，CLIP嵌入<br />- 效果：性能提升，最佳结果|
|📝 更新|MagicDistillation: Weak-to-Strong Video Distillation for Large-Scale Few-Step Synthesis|魔幻蒸馏：大规模少步合成中的弱到强视频蒸馏|Shitong Shao, Hongwei Yi, Hanzhong Guo, Tian Ye, Daquan Zhou, Michael Lingelbach, Zhiqiang Xu, Zeke Xie|<http://arxiv.org/pdf/2503.13319v2>|[[代码]](<https://magicdistillation.github.io/MagicDistillation>)<br />- 问题：推理开销大，表情不自然，合成视频质量差<br />- 方法：MagicDistillation，LoRA，W2S分布匹配<br />- 效果：效率高，效果优|
|🆕 发布|Decoupled Distillation to Erase: A General Unlearning Method for Any Class-centric Tasks|解耦蒸馏以消除：任何以类别为中心任务的通用反学习方法|Yu Zhou, Dian Zheng, Qijie Mo, Renjie Lu, Kun-Yu Lin, Wei-Shi Zheng|<http://arxiv.org/pdf/2503.23751v1>|- 问题：类中心任务，知识遗忘，模型干扰<br />- 方法：理论框架，暗知识，掩码蒸馏<br />- 效果：性能提升，泛化能力强|
|📝 更新|Emphasizing Discriminative Features for Dataset Distillation in Complex Scenarios|强调复杂场景中数据蒸馏的判别特征|Kai Wang, Zekai Li, Zhi-Qi Cheng, Samir Khaki, Ahmad Sajedi, Ramakrishna Vedantam, Konstantinos N Plataniotis, Alexander Hauptmann .etc.|<http://arxiv.org/pdf/2410.17193v2>|[[代码]](<https://github.com/NUS-HPC-AI-Lab/EDF.>)<br />- 问题：复杂场景，数据蒸馏，性能差<br />- 方法：EDF，Grad-CAM，特征增强<br />- 效果：SOTA，复杂场景，性能提升|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Pan-LUT: Efficient Pan-sharpening via Learnable Look-Up Tables|全图查表：通过可学习查找表实现高效的全景锐化|Zhongnan Cai, Yingying Wang, Yunlong Lin, Hui Zheng, Ge Meng, Zixu Lin, Jiaxin Xie, Junbin Lu .etc.|<http://arxiv.org/pdf/2503.23793v1>|- 问题：深度学习，计算开销，高分辨率，实时性<br />- 方法：可学习查找表，PAN引导，自适应聚合<br />- 效果：效率高，性能优|


## 泛化与鲁棒性 (Generalization & Robustness)


### 不确定性建模 (Uncertainty Modeling)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Conformal uncertainty quantification to evaluate predictive fairness of foundation AI model for skin lesion classes across patient demographics|基于患者人口统计学评估基础AI模型皮肤病变类别预测公平性的共形不确定性量化|Swarnava Bhattacharyya, Umapada Pal, Tapabrata Chakraborti|<http://arxiv.org/pdf/2503.23819v1>|- 问题：模型透明度，公平性，不确定性<br />- 方法：符合性分析，动态F1分数采样<br />- 效果：公平性评估，信任度提升|


## 可解释性 (Interpretability)


### 可视化解释 (Visual Explanation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Finer-CAM: Spotting the Difference Reveals Finer Details for Visual Explanation|更细粒度的CAM：揭示差异以获得更精细的视觉解释|Ziheng Zhang, Jianyang Gu, Arpita Chowdhury, Zheda Mai, David Carlyn, Tanya Berger-Wolf, Yu Su, Wei-Lun Chao|<http://arxiv.org/pdf/2501.11309v2>|[[代码]](<https://github.com/Imageomics/Finer-CAM.>)<br />- 问题：CAM，细粒度分类，解释性，相似类<br />- 方法：Finer-CAM，对比相似类，抑制共享特征<br />- 效果：精确定位，可调对比度，置信度下降|


### 归因分析 (Attribution Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|An Explainable Neural Radiomic Sequence Model with Spatiotemporal Continuity for Quantifying 4DCT-based Pulmonary Ventilation|可解释的基于时空连续性的神经放射组学序列模型，用于量化基于4DCT的肺通气|Rihui Zhang, Haiming Zhu, Jingtong Zhao, Lei Zhang, Fang-Fang Yin, Chunhao Wang, Zhenyu Yang|<http://arxiv.org/pdf/2503.23898v1>|- 问题：肺通气评估，核医学，4DCT<br />- 方法：神经放射组学，LSTM，时空连续性<br />- 效果：Dice系数高，可解释性|
|🆕 发布|FineCausal: A Causal-Based Framework for Interpretable Fine-Grained Action Quality Assessment|精细因果：基于因果的细粒度动作质量评估框架|Ruisheng Han, Kanglei Zhou, Amir Atapour-Abarghouei, Xiaohui Liang, Hubert P. H. Shum|<http://arxiv.org/pdf/2503.23911v1>|[[代码]](<https://github.com/Harrison21/FineCausal.>)<br />- 问题：AQA可靠性，可解释性，黑盒问题<br />- 方法：因果干预模块，图注意力网络，时间因果注意力<br />- 效果：最佳性能，可解释反馈|
|📝 更新|Boost Your Human Image Generation Model via Direct Preference Optimization|通过直接偏好优化提升人像生成模型|Sanghyeon Na, Yonggyu Kim, Hyunjoon Lee|<http://arxiv.org/pdf/2405.20216v2>|- 问题：图像生成，解剖，姿态，细节，现实主义<br />- 方法：直接偏好优化，高质量真实图像，课程学习框架<br />- 效果：高保真，个性化|


## 医学影像分析 (Medical Image Analysis)


### 医学分割 (Medical Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Pre-training with 3D Synthetic Data: Learning 3D Point Cloud Instance Segmentation from 3D Synthetic Scenes|基于3D合成数据的预训练：从3D合成场景中学习3D点云实例分割|Daichi Otsuka, Shinichi Mae, Ryosuke Yamada, Hirokatsu Kataoka|<http://arxiv.org/pdf/2503.24229v1>|- 问题：3D点云数据标注成本高，实例分割性能需提升<br />- 方法：3D合成数据预训练，Point-E生成模型<br />- 效果：性能提升，3D点云实例分割|
|🆕 发布|AI-Assisted Colonoscopy: Polyp Detection and Segmentation using Foundation Models|人工智能辅助结肠镜检查：使用基础模型进行息肉检测与分割|Uxue Delaquintana-Aramendi, Leire Benito-del-Valle, Aitor Alvarez-Gila, Javier Pascau, Luisa F Sánchez-Peralta, Artzai Picón, J Blas Pagador, Cristina L Saratxaga|<http://arxiv.org/pdf/2503.24138v1>|- 问题：结肠镜检查，息肉检测，数据稀缺<br />- 方法：基础模型，零样本学习，多数据集评估<br />- 效果：性能提升，泛化能力强|
|🆕 发布|IMPACT: A Generic Semantic Loss for Multimodal Medical Image Registration|IMPACT：一种通用的多模态医学图像配准语义损失|Valentin Boussot, Cédric Hémon, Jean-Claude Nunes, Jason Downling, Simon Rouzé, Caroline Lafond, Anaïs Barateau, Jean-Louis Dillenseger|<http://arxiv.org/pdf/2503.24121v1>|- 问题：医学图像配准，多模态，语义相似度<br />- 方法：IMPACT损失函数，预训练模型，SAM集成<br />- 效果：性能提升，鲁棒性增强|
|🆕 发布|Local Information Matters: Inference Acceleration For Grounded Conversation Generation Models Through Adaptive Local-Aware Token Pruning|局部信息至关重要：通过自适应局部感知令牌剪枝加速基于地面对话生成模型的推理|Bizhe Bai, Jianjian Cao, Yadan Luo, Tao Che|<http://arxiv.org/pdf/2503.23959v1>|- 问题：GCG模型计算成本高，特征丢失，性能下降<br />- 方法：自适应局部感知剪枝，细节密度捕获，动态密度形成<br />- 效果：加速，性能提升|
|🆕 发布|A Multi-Stage Auto-Context Deep Learning Framework for Tissue and Nuclei Segmentation and Classification in H&E-Stained Histological Images of Advanced Melanoma|多阶段自上下文深度学习框架在高级黑色素瘤H&E染色组织学图像中的组织和细胞核分割与分类|Nima Torbati, Anastasia Meshcheryakova, Diana Mechtcheriakova, Amirreza Mahbod|<http://arxiv.org/pdf/2503.23958v1>|[[代码]](<https://github.com/NimaTorbati/PumaSubmit>)<br />- 问题：黑色素瘤，组织分割，细胞核分类，H&E染色图像<br />- 方法：多阶段，深度学习，统一框架，自动上下文<br />- 效果：PUMA挑战赛，排名第一，微Dice分数，F1分数|
|🆕 发布|Spectral-Adaptive Modulation Networks for Visual Perception|光谱自适应调制网络用于视觉感知|Guhnoo Yun, Juhan Yoo, Kijung Kim, Jeongho Lee, Paul Hongsuck Seo, Dong Hwan Kim|<http://arxiv.org/pdf/2503.23947v1>|- 问题：光谱行为，2D卷积，自注意力，频率响应<br />- 方法：图谱分析，光谱自适应调制，多尺度卷积<br />- 效果：性能提升，超越SOTA|
|🆕 发布|Bridge the Gap Between Visual and Linguistic Comprehension for Generalized Zero-shot Semantic Segmentation|弥合视觉与语言理解之间的差距以实现泛化零样本语义分割|Xiaoqing Guo, Wuyang Li, Yixuan Yuan|<http://arxiv.org/pdf/2503.23806v1>|- 问题：GZS3，语义表示，知识迁移<br />- 方法：Decoupled Vision-Language Matching，SPMatch，CSMatch<br />- 效果：超越基准，PASCAL VOC，COCO-Stuff|


### 影像重建 (Image Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learned Image Compression and Restoration for Digital Pathology|学习图像压缩与数字病理学图像恢复|SeonYeong Lee, EonSeung Seong, DongEon Lee, SiYeoul Lee, Yubin Cho, Chunsu Park, Seonho Kim, MinKyoung Seo .etc.|<http://arxiv.org/pdf/2503.23862v1>|[[代码]](<https://github.com/pnu-amilab/CLERIC.>)<br />- 问题：数字病理图像，存储，传输，可视化<br />- 方法：CLERIC，深度学习，图像压缩，恢复<br />- 效果：压缩效率，诊断质量|


## 智能驾驶 (Intelligent Driving)


### 环境感知 (Environment Perception)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving|UniOcc：自动驾驶中占用预测与预测的统一基准|Yuping Wang, Xiangyu Huang, Xiaokang Sun, Mingxuan Yan, Shuo Xing, Zhengzhong Tu, Jiachen Li|<http://arxiv.org/pdf/2503.24381v1>|- 问题：自动驾驶，占用预测，数据集，性能评估<br />- 方法：统一基准，真实数据，流信息<br />- 效果：性能提升，鲁棒评估|
|🆕 发布|JointTuner: Appearance-Motion Adaptive Joint Training for Customized Video Generation|联合调谐器：针对定制视频生成的外观-运动自适应联合训练|Fangda Chen, Shanshan Zhao, Chuanfu Xu, Long Lan|<http://arxiv.org/pdf/2503.23951v1>|- 问题：概念干扰，外观污染，特征域不匹配，空间特征泄漏<br />- 方法：自适应联合训练，Adaptive LoRA，时空Transformer，外观独立时间损失<br />- 效果：性能优越，定制化生成|
|🆕 发布|XLRS-Bench: Could Your Multimodal LLMs Understand Extremely Large Ultra-High-Resolution Remote Sensing Imagery?|XLRS-Bench：你的多模态LLM能理解极端大尺寸超高分辨率遥感影像吗？|Fengxiang Wang, Hongzhen Wang, Mingshuo Chen, Di Wang, Yulin Wang, Zonghao Guo, Qiang Ma, Long Lan .etc.|<http://arxiv.org/pdf/2503.23771v1>|- 问题：多模态LLM，遥感图像，评估基准，语义关系<br />- 方法：XLRS-Bench，超高清图像，半自动标注，子任务<br />- 效果：感知推理，认知过程，开源|


### 轨迹预测 (Trajectory Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning Velocity and Acceleration: Self-Supervised Motion Consistency for Pedestrian Trajectory Prediction|学习速度和加速度：用于行人轨迹预测的自监督运动一致性|Yizhou Huang, Yihua Cheng, Kezhi Wang|<http://arxiv.org/pdf/2503.24272v1>|- 问题：行人轨迹预测，数据分布，异常行为<br />- 方法：自监督学习，运动一致性，特征注入<br />- 效果：性能提升，状态-of-the-art|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HumanDreamer: Generating Controllable Human-Motion Videos via Decoupled Generation|人类梦想者：通过解耦生成可控的人类运动视频|Boyuan Wang, Xiaofeng Wang, Chaojun Ni, Guosheng Zhao, Zhiqin Yang, Zheng Zhu, Muyang Zhang, Yukun Zhou .etc.|<http://arxiv.org/pdf/2503.24026v1>|- 问题：人体运动视频生成，姿态控制，灵活性<br />- 方法：HumanDreamer，MotionVid，MotionDiT，LAMA loss<br />- 效果：FID提升，R-precision增强，多样性和高质量|


### 决策规划 (Decision Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Exploring Cognitive Paradoxes in Video Games: A Quantum Mechanical Perspective|探索视频游戏中的认知悖论：量子力学视角|Ivan S. Maksymov, Ganna Pogrebna|<http://arxiv.org/pdf/2307.08758v2>|- 问题：认知悖论，决策理论，感知反转<br />- 方法：量子力学模型，视频游戏实验，感知反转类比<br />- 效果：认知行为阐明，决策理解提升|


## 工业视觉 (Industrial Vision)


### 工业测量 (Industrial Measurement)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SU-YOLO: Spiking Neural Network for Efficient Underwater Object Detection|SU-YOLO：高效水下目标检测的脉冲神经网络|Chenyang Li, Wenxuan Liu, Guoqiang Gong, Xiaobo Ding, Xian Zhong|<http://arxiv.org/pdf/2503.24389v1>|[[代码]](<https://github.com/lwxfight/snn-underwater.>)<br />- 问题：水下目标检测，低功耗，高精度<br />- 方法：SNN模型，水下图像去噪，SeBN，spiking residual blocks<br />- 效果：mAP 78.8%，参数6.97M，能耗2.98 mJ|


## 其他 (Others)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Short-video Propagation Influence Rating: A New Real-world Dataset and A New Large Graph Model|短视频传播影响力评估：一个新真实世界数据集和一个新的大图模型|Dizhan Xue, Jing Cui, Shengsheng Qian, Chuanrui Hu, Changsheng Xu|<http://arxiv.org/pdf/2503.23746v1>|- 问题：短视频传播，影响力评估，跨平台数据<br />- 方法：XS-Video数据集，NetGPT模型，LLMs结合<br />- 效果：预测精度高，跨平台分析|
|📝 更新|Head and Neck Tumor Segmentation of MRI from Pre- and Mid-radiotherapy with Pre-training, Data Augmentation and Dual Flow UNet|基于预训练、数据增强和双流UNet的放疗前后MRI头颈肿瘤分割|Litingyu Wang, Wenjun Liao, Shichuan Zhang, Guotai Wang|<http://arxiv.org/pdf/2412.14846v2>|[[代码]](<https://github.com/WltyBY/HNTS-MRG2024_train_code.>)<br />- 问题：肿瘤分割，MRI，放疗前后，自动化<br />- 方法：预训练，数据增强，双流UNet<br />- 效果：高精度，Dice系数|

