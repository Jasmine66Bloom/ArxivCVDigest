## [UPDATED!] **2025-04-02** (Update Time)


## 表示学习 (Representation Learning)


### 基础模型 (Foundation Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ILLUME+: Illuminating Unified MLLM with Dual Visual Tokenization and Diffusion Refinement|ILLUME+：基于双重视觉标记和扩散精炼的统一多模态语言模型照明|Runhui Huang, Chunwei Wang, Junwei Yang, Guansong Lu, Yunlong Yuan, Jianhua Han, Lu Hou, Wei Zhang .etc.|<http://arxiv.org/pdf/2504.01934v1>|[[代码]](<https://illume-unified-mllm.github.io/.>)<br />- 问题：统一模型理解、生成、编辑能力不足<br />- 方法：双视觉标记化，扩散模型，连续输入离散输出<br />- 效果：性能提升，多模态应用|


### 视觉Transformer (Vision Transformers)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UniViTAR: Unified Vision Transformer with Native Resolution|统一分辨率原生视觉Transformer：UniViTAR|Limeng Qiao, Yiyang Gan, Bairui Wang, Jie Qin, Shuang Xu, Siqi Yang, Lin Ma|<http://arxiv.org/pdf/2504.01792v1>|- 问题：视觉建模，分辨率标准化，空间-上下文保真度<br />- 方法：架构升级，渐进式训练，模态适应<br />- 效果：模型有效性，多尺度|
|🆕 发布|Understanding Cross-Model Perceptual Invariances Through Ensemble Metamers|通过集成元模型理解跨模型感知不变性|Lukas Boehm, Jonas Leo Mueller, Christoffer Loeffler, Leo Schwinn, Bjoern Eskofier, Dario Zanca|<http://arxiv.org/pdf/2504.01739v1>|- 问题：感知不变性，神经网络，可解释性<br />- 方法：集成元模型，神经网络集成，图像指标<br />- 效果：认知相似，架构影响|
|🆕 发布|Detecting Lip-Syncing Deepfakes: Vision Temporal Transformer for Analyzing Mouth Inconsistencies|检测同步深度伪造：用于分析嘴部不一致性的视觉时序转换器|Soumyya Kanti Datta, Shan Jia, Siwei Lyu|<http://arxiv.org/pdf/2504.01470v1>|[[代码]](<https://github.com/skrantidatta/LIPINC-V2>)<br />- 问题：唇同步深伪检测，嘴部不一致<br />- 方法：视觉时序转换器，多头交叉注意力<br />- 效果：性能领先，数据集LipSyncTIMIT|
|📝 更新|Autonomous AI for Multi-Pathology Detection in Chest X-Rays: A Multi-Site Study in the Indian Healthcare System|自主人工智能在胸部X光片多病理检测中的应用：印度医疗体系中的多中心研究|Bargava Subramanian, Shajeev Jaikumar, Praveen Shastry, Naveen Kumarasami, Kalyan Sivasailam, Anandakumar D, Keerthana R, Mounigasri M .etc.|<http://arxiv.org/pdf/2504.00022v2>|- 问题：多病理检测，CXR，AI系统<br />- 方法：Vision Transformers，Faster R-CNN，U-Net模型<br />- 效果：高精度，高召回率，优化诊断|
|🆕 发布|Prompt-Guided Attention Head Selection for Focus-Oriented Image Retrieval|提示引导的焦点图像检索注意力头选择|Yuji Nozawa, Yu-Chieh Lin, Kazumoto Nakamura, Youyang Ng|<http://arxiv.org/pdf/2504.01348v1>|- 问题：FOIR任务，多对象，复杂背景<br />- 方法：Prompt-Guided，PHS，注意力头选择<br />- 效果：性能提升，训练免费|


## 生成建模 (Generative Modeling)


### 扩散模型 (Diffusion Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VideoScene: Distilling Video Diffusion Model to Generate 3D Scenes in One Step|视频场景：将视频扩散模型提炼为一步生成3D场景|Hanyang Wang, Fangfu Liu, Jiawei Chi, Yueqi Duan|<http://arxiv.org/pdf/2504.01956v1>|[[代码]](<https://hanyang-21.github.io/VideoScene>)<br />- 问题：3D场景恢复，稀疏视图，性能退化<br />- 方法：视频扩散模型蒸馏，3D感知跳跃流，动态降噪策略<br />- 效果：高效，3D生成|
|🆕 发布|A Diffusion-Based Framework for Occluded Object Movement|基于扩散的遮挡物体运动框架|Zheng-Peng Duan, Jiawei Zhang, Siyu Liu, Zheng Lin, Chun-Le Guo, Dongqing Zou, Jimmy Ren, Chongyi Li|<http://arxiv.org/pdf/2504.01873v1>|- 问题：遮挡物体运动，图像编辑，背景填充，运动引导<br />- 方法：DiffOOM框架，并行分支，去遮挡，运动优化<br />- 效果：性能优越，用户满意度高|
|🆕 发布|Implicit Bias Injection Attacks against Text-to-Image Diffusion Models|针对文本到图像扩散模型的隐式偏差注入攻击|Huayang Huang, Xiangye Jin, Jiaxu Miao, Yu Wu|<http://arxiv.org/pdf/2504.01819v1>|[[代码]](<https://github.com/Hannah1102/IBI-attacks.>)<br />- 问题：T2I模型偏差，隐式偏见，误导信息<br />- 方法：隐式偏差注入，IBI-Attacks框架，自适应调整<br />- 效果：隐蔽性，可迁移性，语义保留|
|📝 更新|Denoising Functional Maps: Diffusion Models for Shape Correspondence|去噪功能图：形状对应中的扩散模型|Aleksei Zhuravlev, Zorah Lähner, Vladislav Golyanik|<http://arxiv.org/pdf/2503.01845v2>|- 问题：形状对应，泛化能力，训练数据<br />- 方法：扩散模型，功能图，无监督选择基<br />- 效果：性能竞争，数据集广泛|
|📝 更新|SaRA: High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation|SaRA：基于渐进稀疏低秩适应的高效扩散模型微调|Teng Hu, Jiangning Zhang, Ran Yi, Hongrui Huang, Yabiao Wang, Lizhuang Ma|<http://arxiv.org/pdf/2409.06633v2>|- 问题：扩散模型微调，参数冗余，过拟合<br />- 方法：渐进稀疏低秩适应，核范数训练，非结构化反向传播<br />- 效果：性能提升，泛化能力强|
|📝 更新|Target-Aware Video Diffusion Models|目标感知视频扩散模型|Taeksoo Kim, Hanbyul Joo|<http://arxiv.org/pdf/2503.18950v2>|- 问题：视频生成，目标交互，动作控制<br />- 方法：目标感知模型，文本提示，交叉注意力损失<br />- 效果：准确交互，高效生成|
|🆕 发布|InvFussion: Bridging Supervised and Zero-shot Diffusion for Inverse Problems|逆问题中的监督和无监督扩散的桥梁：InvFussion|Noam Elata, Hyungjin Chung, Jong Chul Ye, Tomer Michaeli, Michael Elad|<http://arxiv.org/pdf/2504.01689v1>|- 问题：逆问题，扩散模型，监督学习，零样本学习，性能-灵活性权衡<br />- 方法：融合架构，降解操作，注意力机制，多模态估计<br />- 效果：高性能，灵活，超越现有方法|
|📝 更新|Towards Physically Plausible Video Generation via VLM Planning|通过VLM规划实现物理上合理的视频生成|Xindi Yang, Baolu Li, Yiming Zhang, Zhenfei Yin, Lei Bai, Liqian Ma, Zhiyong Wang, Jianfei Cai .etc.|<http://arxiv.org/pdf/2503.23368v2>|[[代码]](<https://madaoer.github.io/projects>)<br />- 问题：VDM物理合理性，动力学错误，事件序列不正确<br />- 方法：VLM规划，物理感知推理，两阶段框架<br />- 效果：物理合理运动，方法优越|
|🆕 发布|Pro-DG: Procedural Diffusion Guidance for Architectural Facade Generation|程序扩散引导：用于建筑立面生成的过程式指导|Aleksander Plocharski, Jan Swidzinski, Przemyslaw Musialski|<http://arxiv.org/pdf/2504.01571v1>|- 问题：建筑立面生成，控制性，真实感<br />- 方法：形状语法，扩散模型，层次匹配<br />- 效果：精确性，真实性|
|🆕 发布|Domain Guidance: A Simple Transfer Approach for a Pre-trained Diffusion Model|领域引导：一种用于预训练扩散模型的简单迁移方法|Jincheng Zhong, Xiangcheng Zhang, Jianmin Wang, Mingsheng Long|<http://arxiv.org/pdf/2504.01521v1>|- 问题：模型扩展，计算需求，个性化模型<br />- 方法：Domain Guidance，预训练知识，采样过程引导<br />- 效果：FID改善，FD_DINOv2改善|
|📝 更新|Adapting Video Diffusion Models for Time-Lapse Microscopy|适应视频扩散模型于时间序列显微镜|Alexander Holmberg, Nils Mechtel, Wei Ouyang|<http://arxiv.org/pdf/2503.18583v2>|- 问题：视频扩散模型，显微镜视频，细胞行为<br />- 方法：领域自适应，条件生成，数值嵌入<br />- 效果：真实性提升，行为捕捉|
|📝 更新|NVS-Solver: Video Diffusion Model as Zero-Shot Novel View Synthesizer|NVS-Solver：视频扩散模型作为零样本新视角合成器|Meng You, Zhiyu Zhu, Hui Liu, Junhui Hou|<http://arxiv.org/pdf/2405.15364v2>|[[代码]](<https://github.com/ZHU-Zhiyu/NVS_Solver>)<br />- 问题：无监督视频扩散，新视角合成，无需训练<br />- 方法：预训练模型，自适应采样，理论建模<br />- 效果：性能优越，视觉效果佳|
|📝 更新|Distilling Multi-view Diffusion Models into 3D Generators|从多视角扩散模型中提炼出3D生成器|Hao Qin, Luyuan Chen, Ming Kong, Mengxu Lu, Qiang Zhu|<http://arxiv.org/pdf/2504.00457v2>|[[代码]](<https://qinbaigao.github.io/DD3G_project>)<br />- 问题：多视图扩散模型，3D生成，知识蒸馏<br />- 方法：高斯散点，概率流，PEPD生成器<br />- 效果：泛化能力强，生成质量高|
|📝 更新|Lux Post Facto: Learning Portrait Performance Relighting with Conditional Video Diffusion and a Hybrid Dataset|事后奢华：利用条件视频扩散和混合数据集学习人像性能重光照|Yiqun Mei, Mingming He, Li Ma, Julien Philip, Wenqi Xian, David M George, Xueming Yu, Gabriel Dedic .etc.|<http://arxiv.org/pdf/2503.14485v2>|- 问题：视频人像重光照，真实感，时间一致性<br />- 方法：条件视频扩散模型，混合数据集，光照注入<br />- 效果：最佳结果，真实感，时间一致性|


### 生成对抗网络 (GANs)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DLFR-VAE: Dynamic Latent Frame Rate VAE for Video Generation|动态潜在帧率变分自编码器用于视频生成|Zhihang Yuan, Siyuan Wang, Rui Xie, Hanling Zhang, Tongcheng Fang, Yuzhang Shang, Shengen Yan, Guohao Dai .etc.|<http://arxiv.org/pdf/2502.11897v2>|- 问题：视频生成，时间非均匀性，信息理论<br />- 方法：动态潜在帧率，无监督适应，可插拔模块<br />- 效果：加速生成，内容复杂度适应|
|🆕 发布|A$^\text{T}$A: Adaptive Transformation Agent for Text-Guided Subject-Position Variable Background Inpainting|自适应变换代理：用于文本引导的变主体位置背景修复|Yizhe Tang, Zhimin Sun, Yuzhen Du, Ran Yi, Guangben Lu, Teng Hu, Luying Li, Lizhuang Ma .etc.|<http://arxiv.org/pdf/2504.01603v1>|- 问题：背景修复，位置不一致，文本引导<br />- 方法：自适应变换，逆位移变换，位置切换嵌入<br />- 效果：修复效果好，性能优异|
|📝 更新|Modeling Visual Memorability Assessment with Autoencoders Reveals Characteristics of Memorable Images|使用自编码器建模视觉记忆度评估揭示难忘图像的特征|Elham Bagheri, Yalda Mohsenzadeh|<http://arxiv.org/pdf/2410.15235v2>|- 问题：图像记忆度，特征贡献，视觉感知<br />- 方法：自动编码器，VGG16，记忆度预测<br />- 效果：相关性显著，预测性能强|


### 自回归模型 (Autoregressive Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Parallelized Autoregressive Visual Generation|并行自回归视觉生成|Yuqing Wang, Shuhuai Ren, Zhijie Lin, Yujin Han, Haoyuan Guo, Zhenheng Yang, Difan Zou, Jiashi Feng .etc.|<http://arxiv.org/pdf/2412.15119v2>|[[代码]](<https://yuqingwang1029.github.io/PAR-project.>)<br />- 问题：慢推理速度，序列预测，效率低<br />- 方法：并行化，弱依赖并行，强依赖顺序<br />- 效果：速度提升，质量相当|
|📝 更新|Loong: Generating Minute-level Long Videos with Autoregressive Language Models|龙：使用自回归语言模型生成分钟级长视频|Yuqing Wang, Tianwei Xiong, Daquan Zhou, Zhijie Lin, Yang Zhao, Bingyi Kang, Jiashi Feng, Xihui Liu|<http://arxiv.org/pdf/2410.02757v2>|[[代码]](<https://yuqingwang1029.github.io/Loong-video.>)<br />- 问题：长视频生成，LLM，视频生成挑战<br />- 方法：统一序列建模，渐进式训练，损失重加权<br />- 效果：分钟级长视频，文本提示生成|


## 多模态学习 (Multimodal Learning)


### 视觉语言模型 (Vision-Language Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Image Difference Grounding with Natural Language|基于自然语言的图像差异定位|Wenxuan Wang, Zijia Zhao, Yisi Zhang, Yepeng Tang, Erdong Hu, Xinlong Wang, Jing Liu|<http://arxiv.org/pdf/2504.01952v1>|- 问题：视觉定位，单图限制，差异理解<br />- 方法：图像差异定位，DiffGround数据集，DiffTracker模型<br />- 效果：细粒度理解，公开数据集|
|🆕 发布|Towards Unified Referring Expression Segmentation Across Omni-Level Visual Target Granularities|面向跨全级视觉目标粒度的统一指代表达式分割|Jing Liu, Wenxuan Wang, Yisi Zhang, Yepeng Tang, Xingjian He, Longteng Guo, Tongtian Yue, Xinlong Wang|<http://arxiv.org/pdf/2504.01954v1>|[[代码]](<https://github.com/Rubics-Xuan/MRES.>)<br />- 问题：多粒度视觉目标定位，数据稀缺，模型局限性<br />- 方法：MRES任务，MRES-32M数据集，UniRES++模型<br />- 效果：多粒度性能提升，基准测试领先|
|🆕 发布|Is Temporal Prompting All We Need For Limited Labeled Action Recognition?|我们需要时间提示就足够用于有限标注的动作识别了吗？|Shreyank N Gowda, Boyan Gao, Xiao Gu, Xiaobo Jin|<http://arxiv.org/pdf/2504.01890v1>|- 问题：动作识别，数据依赖，时序建模<br />- 方法：时序提示，CLIP架构，预训练能力<br />- 效果：参数少，效率高，性能优|
|🆕 发布|FineLIP: Extending CLIP's Reach via Fine-Grained Alignment with Longer Text Inputs|精细LIP：通过与更长文本输入的精细对齐扩展CLIP的覆盖范围|Mothilal Asokan, Kebin Wu, Fatima Albreiki|<http://arxiv.org/pdf/2504.01916v1>|- 问题：CLIP文本编码器限制，细节信息捕捉困难<br />- 方法：Fine-grained alignment，长文本处理，动态聚合<br />- 效果：性能提升，超越现有方法|
|📝 更新|Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning|宇宙-Reason1：从物理常识到具身推理|NVIDIA, :, Alisson Azzolini, Hannah Brandon, Prithvijit Chattopadhyay, Huayu Chen, Jinju Chu, Yin Cui .etc.|<http://arxiv.org/pdf/2503.15558v2>|[[代码]](<https://github.com/nvidia-cosmos/cosmos-reason1.>)<br />- 问题：物理AI，感知，理解，行动<br />- 方法：物理常识，具身推理，多模态模型<br />- 效果：性能提升，模型可用|
|🆕 发布|Prompting Medical Vision-Language Models to Mitigate Diagnosis Bias by Generating Realistic Dermoscopic Images|通过生成逼真的皮肤镜图像来提示医学视觉-语言模型以减轻诊断偏差|Nusrat Munia, Abdullah-Al-Zubaer Imran|<http://arxiv.org/pdf/2504.01838v1>|[[代码]](<https://github.com/Munia03/DermDiT>)<br />- 问题：诊断偏差，皮肤疾病，数据不平衡<br />- 方法：DermDiT框架，文本提示，多模态学习<br />- 效果：高质量图像，减少偏差|
|📝 更新|CoMM: A Coherent Interleaved Image-Text Dataset for Multimodal Understanding and Generation|CoMM：一个用于多模态理解和生成的连贯交错图像-文本数据集|Wei Chen, Lin Li, Yongqi Yang, Bin Wen, Fan Yang, Tingting Gao, Yu Wu, Long Chen|<http://arxiv.org/pdf/2406.10462v3>|- 问题：数据质量差，生成序列不连贯<br />- 方法：多视角过滤，预训练模型，质量评估<br />- 效果：提升MLLMs，新任务评估|
|🆕 发布|CLIP-SLA: Parameter-Efficient CLIP Adaptation for Continuous Sign Language Recognition|CLIP-SLA：用于连续手语识别的参数高效CLIP自适应方法|Sarah Alyami, Hamzah Luqman|<http://arxiv.org/pdf/2504.01666v1>|- 问题：连续手语识别，参数高效，预训练模型<br />- 方法：CLIP-SLA，PEFT，SLA-Adapter，SLA-LoRA<br />- 效果：性能提升，参数少|
|🆕 发布|BioAtt: Anatomical Prior Driven Low-Dose CT Denoising|生物先验驱动的低剂量CT去噪|Namhun Kim, UiHyun Cho|<http://arxiv.org/pdf/2504.01662v1>|- 问题：LDCT去噪，细节丢失，数据驱动<br />- 方法：解剖先验，视觉语言模型，空间注意力<br />- 效果：性能提升，解剖指导|
|🆕 发布|Text Speaks Louder than Vision: ASCII Art Reveals Textual Biases in Vision-Language Models|文字胜于视觉：ASCII艺术揭示视觉-语言模型中的文本偏见|Zhaochen Wang, Yujun Cai, Zi Huang, Bryan Hooi, Yiwei Wang, Ming-Hsuan Yang|<http://arxiv.org/pdf/2504.01589v1>|- 问题：VLMs，文本优先，语义-视觉冲突<br />- 方法：ASCII艺术，对抗性攻击，评估框架<br />- 效果：文本优先，模型缺陷，内容审核|
|📝 更新|Underwater Camouflaged Object Tracking Meets Vision-Language SAM2|水下伪装目标跟踪与视觉-语言SAM2相遇|Chunhui Zhang, Li Liu, Guanjie Huang, Zhipeng Zhang, Hao Wen, Xi Zhou, Shiming Ge, Yanfeng Wang|<http://arxiv.org/pdf/2409.16902v3>|[[代码]](<https://github.com/983632847/Awesome-Multimodal-Object-Tracking>)<br />- 问题：水下动物跟踪，伪装物体，数据集，视觉语言<br />- 方法：UW-COT220，SAM2，VL-SAM2<br />- 效果：性能提升，最先进|
|🆕 发布|ANNEXE: Unified Analyzing, Answering, and Pixel Grounding for Egocentric Interaction|附件：基于自回归神经网络的统一分析、回答和像素定位用于自视角交互|Yuejiao Su, Yi Wang, Qiongyang Hu, Chuang Yang, Lap-Pui Chau|<http://arxiv.org/pdf/2504.01472v1>|- 问题：Egocentric interaction understanding, lack of flexibility, coherent responses<br />- 方法：Ego-IRG, ANNEXE model, multimodal large language models<br />- 效果：comprehensive interpretation, effective performance|
|📝 更新|Can DeepSeek Reason Like a Surgeon? An Empirical Evaluation for Vision-Language Understanding in Robotic-Assisted Surgery|标题翻译：  深度Seek能否像外科医生一样推理？机器人辅助手术中视觉-语言理解的实证评估|Boyi Ma, Yanguang Zhao, Jie Wang, Guankun Wang, Kun Yuan, Tong Chen, Long Bai, Hongliang Ren|<http://arxiv.org/pdf/2503.23130v2>|- 问题：视觉语言理解，机器人辅助手术，DeepSeek模型<br />- 方法：对话能力评估，手术场景任务，空间位置分析<br />- 效果：手术工具识别，组织识别，局限|
|📝 更新|VGRP-Bench: Visual Grid Reasoning Puzzle Benchmark for Large Vision-Language Models|VGRP-Bench：大型视觉-语言模型的可视化网格推理基准测试|Yufan Ren, Konstantinos Tertikas, Shalini Maiti, Junlin Han, Tong Zhang, Sabine Süsstrunk, Filippos Kokkinos|<http://arxiv.org/pdf/2503.23064v2>|- 问题：视觉语言模型，推理难题，评估框架<br />- 方法：VGRP-Bench，多难度，SFT策略<br />- 效果：性能提升，局限性分析|
|🆕 发布|All Patches Matter, More Patches Better: Enhance AI-Generated Image Detection via Panoptic Patch Learning|所有补丁都重要，更多补丁更佳：通过全景补丁学习增强人工智能图像检测|Zheng Yang, Ruoxin Chen, Zhiyuan Yan, Ke-Yue Zhang, Xinghe Fu, Shuang Wu, Xiujun Shu, Taiping Yao .etc.|<http://arxiv.org/pdf/2504.01396v1>|- 问题：AI生成图像检测，特征集中，检测鲁棒性<br />- 方法：泛化补丁学习，随机补丁替换，补丁对比学习<br />- 效果：鲁棒性增强，泛化能力提升|
|📝 更新|Augmenting Multimodal LLMs with Self-Reflective Tokens for Knowledge-based Visual Question Answering|增强多模态LLMs的自反标记以实现基于知识的视觉问答|Federico Cocchi, Nicholas Moratelli, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara|<http://arxiv.org/pdf/2411.16863v2>|[[代码]](<https://aimagelab.github.io/ReflectiVA.>)<br />- 问题：MLLMs，知识限制，适应性差<br />- 方法：Reflective LLaVA，自我反思标记，外部知识集成<br />- 效果：知识问答，性能提升|
|🆕 发布|On Data Synthesis and Post-training for Visual Abstract Reasoning|关于视觉抽象推理的数据合成和后训练|Ke Zhu, Yu Wang, Jiangjiang Liu, Qunyi Xie, Shanshan Liu, Gang Zhang|<http://arxiv.org/pdf/2504.01324v1>|- 问题：抽象视觉推理，视觉语言模型，数据合成，后训练<br />- 方法：创新数据合成，后训练过程<br />- 效果：模型性能超越，多模态理解能力|
|🆕 发布|COST: Contrastive One-Stage Transformer for Vision-Language Small Object Tracking|对比单阶段Transformer用于视觉-语言小目标跟踪|Chunhui Zhang, Li Liu, Jialin Gao, Xin Sun, Hao Wen, Xi Zhou, Shiming Ge, Yanfeng Wang|<http://arxiv.org/pdf/2504.01321v1>|- 问题：视觉语言跟踪，多模态融合，特征空间分布差异<br />- 方法：对比对齐，Transformer，多模态融合机制<br />- 效果：性能提升，SOTA|
|🆕 发布|Safeguarding Vision-Language Models: Mitigating Vulnerabilities to Gaussian Noise in Perturbation-based Attacks|保障视觉-语言模型安全：减轻基于扰动攻击中对高斯噪声的脆弱性|Jiawei Wang, Yushen Zuo, Yuanjun Chai, Zhendong Liu, Yichen Fu, Yichun Feng, Kin-man Lam|<http://arxiv.org/pdf/2504.01308v1>|[[代码]](<https://github.com/JarvisUSTC/DiffPure-RobustVLM.>)<br />- 问题：VLM易受攻击，噪声训练不足<br />- 方法：Robust-VLGuard，DiffPure-VLM，噪声增强微调<br />- 效果：攻击成功率降低，功能保持|


### 多模态融合 (Multimodal Fusion)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Leveraging Embedding Techniques in Multimodal Machine Learning for Mental Illness Assessment|利用嵌入技术在多模态机器学习中用于精神疾病评估|Abdelrahaman A. Hassan, Abdelrahman A. Ali, Aya E. Fouda, Radwa J. Hanafy, Mohammed E. Fouda|<http://arxiv.org/pdf/2504.01767v1>|- 问题：精神疾病诊断，多模态学习，客观评估<br />- 方法：数据预处理，嵌入模型，CNN-BiLSTM，决策融合<br />- 效果：高准确率，个性化工具|
|📝 更新|SAV-SE: Scene-aware Audio-Visual Speech Enhancement with Selective State Space Model|场景感知音频-视觉语音增强与选择性状态空间模型|Xinyuan Qian, Jiaran Gao, Yaodan Zhang, Qiquan Zhang, Hexin Liu, Leibny Paola Garcia, Haizhou Li|<http://arxiv.org/pdf/2411.07751v2>|- 问题：语音增强，视觉信息，环境噪声，场景感知<br />- 方法：VC-S²E，Conformer，Mamba模块<br />- 效果：性能提升，公开数据集验证|
|📝 更新|AnySat: One Earth Observation Model for Many Resolutions, Scales, and Modalities|AnySat：一种适用于多种分辨率、尺度和模态的地球观测模型|Guillaume Astruc, Nicolas Gonthier, Clement Mallet, Loic Landrieu|<http://arxiv.org/pdf/2412.14123v2>|[[代码]](<https://github.com/gastruc/AnySat.>)<br />- 问题：多分辨率，尺度，模态，地球观测<br />- 方法：JEPA，自适应空间编码器，自监督学习<br />- 效果：多模态，多任务，SOTA|
|📝 更新|A-MESS: Anchor based Multimodal Embedding with Semantic Synchronization for Multimodal Intent Recognition|A-MESS：基于锚点的多模态嵌入与语义同步的多模态意图识别|Yaomin Shen, Xiaojian Lin, Wei Fan|<http://arxiv.org/pdf/2503.19474v2>|- 问题：多模态意图识别，模态连接，语义表示<br />- 方法：锚点嵌入，语义同步，三元组对比学习<br />- 效果：最先进，多模态表示，下游任务洞察|
|📝 更新|VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video Generation|视频工艺3：图像到视频生成中的相机、物体和光照控制|Sixiao Zheng, Zimian Peng, Yanpeng Zhou, Yi Zhu, Hang Xu, Xiangru Huang, Yanwei Fu|<http://arxiv.org/pdf/2502.07531v3>|- 问题：多元素控制，数据限制，网络效能<br />- 方法：Image2Cloud，ObjMotionNet，Spatial Triple-Attention Transformer<br />- 效果：高质量视频，控制精度高|


### 跨模态对齐 (Cross-modal Alignment)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Leveraging Modality Tags for Enhanced Cross-Modal Video Retrieval|利用模态标签增强跨模态视频检索|Adriano Fragomeni, Dima Damen, Michael Wray|<http://arxiv.org/pdf/2504.01591v1>|- 问题：视频检索，模态对齐，跨模态检索<br />- 方法：MAC-VR，模态标签，辅助概念<br />- 效果：性能提升，超越现有方法|
|🆕 发布|Training-free Dense-Aligned Diffusion Guidance for Modular Conditional Image Synthesis|无训练密集对齐扩散引导的模块化条件图像合成|Zixuan Wang, Duo Peng, Feng Chen, Yuwei Yang, Yinjie Lei|<http://arxiv.org/pdf/2504.01515v1>|[[代码]](<https://github.com/ZixuanWang0525/DADG.>)<br />- 问题：条件图像合成，应用范围窄<br />- 方法：模块化条件，DCA，DGA，DMA<br />- 效果：适应性增强，性能优越|
|🆕 发布|Enhanced Cross-modal 3D Retrieval via Tri-modal Reconstruction|标题翻译：基于三模态重建的增强跨模态3D检索|Junlong Ren, Hao Wang|<http://arxiv.org/pdf/2504.01476v1>|- 问题：跨模态3D检索，2D-3D一致性，性能受限<br />- 方法：多视图图像，点云联合表示，三模态重建<br />- 效果：性能提升，鲁棒性增强|


## 目标检测识别 (Object Detection & Recognition)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TransientTables: Evaluating LLMs' Reasoning on Temporally Evolving Semi-structured Tables|瞬态表格：评估大型语言模型在时间演变半结构化表格上的推理能力|Abhilash Shankarampeta, Harsh Mahajan, Tushar Kataria, Dan Roth, Vivek Gupta|<http://arxiv.org/pdf/2504.01879v1>|- 问题：LLMs时序推理能力，数据集，模板生成<br />- 方法：数据集构建，模板生成，任务分解<br />- 效果：基准测试，性能提升|


### 三维检测 (3D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Efficient 3D Recognition with Event-driven Spike Sparse Convolution|高效的事件驱动脉冲稀疏卷积3D识别|Xuerui Qiu, Man Yao, Jieyuan Zhang, Yuhong Chou, Ning Qiao, Shibo Zhou, Bo Xu, Guoqi Li|<http://arxiv.org/pdf/2412.07360v3>|[[代码]](<https://github.com/bollossom/E-3DSNN>)<br />- 问题：3D识别，SNN性能，预处理，特征提取<br />- 方法：Spike Voxel Coding，Spike Sparse Convolution，E-3DSNN<br />- 效果：SOTA结果，效率高，多任务|
|🆕 发布|GarmageNet: A Dataset and Scalable Representation for Generic Garment Modeling|GarmageNet：通用服装建模的数据集和可扩展表示|Siran Li, Ruiyang Liu, Chen Liu, Zhendong Wang, Gaofeng He, Yong-Lu Li, Xiaogang Jin, Huamin Wang|<http://arxiv.org/pdf/2504.01483v1>|- 问题：高保真服装建模，数据集，高效表示<br />- 方法：Garmage表示，2D-3D集成，GarmageNet生成框架<br />- 效果：高保真，多层级，工业级模拟|


### 多目标跟踪 (Multi-object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Deep LG-Track: An Enhanced Localization-Confidence-Guided Multi-Object Tracker|深度LG-Track：一种增强定位-置信度引导的多目标跟踪器|Ting Meng, Chunyun Fu, Xiangyan Yan, Zheng Liang, Pan Ji, Jianwen Wang, Tao Huang|<http://arxiv.org/pdf/2504.01457v1>|- 问题：多目标跟踪，精度，鲁棒性<br />- 方法：自适应卡尔曼滤波，成本矩阵融合，动态特征更新<br />- 效果：性能优于，指标提升|


### 二维检测 (2D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Modeling Multiple Normal Action Representations for Error Detection in Procedural Tasks|建模多个正常动作表示以检测程序任务中的错误|Wei-Jin Huang, Yuan-Ming Li, Zhi-Wei Xia, Yu-Ming Tang, Kun-Yu Lin, Jian-Fang Hu, Wei-Shi Zheng|<http://arxiv.org/pdf/2503.22405v2>|[[代码]](<https://github.com/iSEE-Laboratory/AMNAR.>)<br />- 问题：错误检测，动作表示，动态环境，原型错误<br />- 方法：AMNAR框架，预测动作，重构表示<br />- 效果：性能提升，状态艺术|
|📝 更新|Mr. DETR: Instructive Multi-Route Training for Detection Transformers|Mr. DETR：检测Transformer的指导性多路径训练|Chang-Bin Zhang, Yujie Zhong, Kai Han|<http://arxiv.org/pdf/2412.10028v3>|[[代码]](<https://visual-ai.github.io/mrdetr>)<br />- 问题：检测Transformer训练，多任务预测<br />- 方法：多路由训练，辅助路径，指令式自注意力<br />- 效果：性能提升，推理无影响|
|📝 更新|Repurposing SAM for User-Defined Semantics Aware Segmentation|重新利用SAM进行用户定义语义感知分割|Rohit Kundu, Sudipta Paul, Arindam Dutta, Amit K. Roy-Chowdhury|<http://arxiv.org/pdf/2312.02420v2>|- 问题：SAM语义感知不足，缺乏类别关联<br />- 方法：U-SAM，语义信息积累，映射函数学习<br />- 效果：mIoU提升，语义分割|


## 时序理解 (Temporal Understanding)


### 时序分析 (Temporal Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TimeSearch: Hierarchical Video Search with Spotlight and Reflection for Human-like Long Video Understanding|时间搜索：具有焦点和反射的人性化长视频分层搜索|Junwen Pan, Rui Zhang, Xin Wan, Yuan Zhang, Ming Lu, Qi She|<http://arxiv.org/pdf/2504.01407v1>|- 问题：长视频理解，视觉幻觉，时间处理挑战<br />- 方法：TimeSearch框架，Spotlight，Reflection，TAFR<br />- 效果：性能提升，LVBench准确率51.5%，Charades-STA mIoU提升11.8%|


## 三维重建 (3D Reconstruction)


### 多视图重建 (Multi-view Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Ross3D: Reconstructive Visual Instruction Tuning with 3D-Awareness|罗斯3D：具有3D意识的重建视觉指令微调|Haochen Wang, Yucheng Zhao, Tiancai Wang, Haoqiang Fan, Xiangyu Zhang, Zhaoxiang Zhang|<http://arxiv.org/pdf/2504.01901v1>|- 问题：3D场景理解，数据集缺乏，2D模型扩展<br />- 方法：3D感知，重建视觉指令调整，跨视图重建<br />- 效果：SOTA性能，半监督学习潜力|


### 神经隐式重建 (Neural Implicit Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EVOS: Efficient Implicit Neural Training via EVOlutionary Selector|EVOS：通过进化选择器的有效隐式神经网络训练|Weixiang Zhang, Shuzhao Xie, Chengwei Ren, Siyi Xie, Chen Tang, Shijia Ge, Mingzi Wang, Zhi Wang|<http://arxiv.org/pdf/2412.10153v2>|- 问题：INR训练效率低，计算开销大<br />- 方法：EVOlutionary Selector，稀疏评估，频率引导交叉<br />- 效果：训练时间减少，收敛性好|
|🆕 发布|A topology-preserving three-stage framework for fully-connected coronary artery extraction|拓扑保持的三阶段全连接冠状动脉提取框架|Yuehui Qiu, Dandan Shan, Yining Wang, Pei Dong, Dijia Wu, Xinnian Yang, Qingqi Hong, Dinggang Shen|<http://arxiv.org/pdf/2504.01597v1>|[[代码]](<https://github.com/YH-Qiu/CorSegRec.>)<br />- 问题：冠状动脉提取，拓扑结构，分割误差<br />- 方法：拓扑保持，三阶段框架，中心线增强<br />- 效果：Dice分数高，Hausdorff距离小|
|📝 更新|Pairwise-Constrained Implicit Functions for 3D Human Heart Modelling|成对约束的隐函数用于3D人心建模|Hieu Le, Jingyi Xu, Nicolas Talabot, Jiancheng Yang, Pascal Fua|<http://arxiv.org/pdf/2307.08716v3>|- 问题：3D心脏建模，多层结构，表面间隙<br />- 方法：对偶约束SDF，独立SDF，内部结构<br />- 效果：精度提升，结构准确|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Dinomaly: The Less Is More Philosophy in Multi-Class Unsupervised Anomaly Detection|多类无监督异常检测中的“少即是多”哲学：Dinomaly|Jia Guo, Shuai Lu, Weihang Zhang, Fang Chen, Huiqi Li, Hongen Liao|<http://arxiv.org/pdf/2405.14325v5>|- 问题：多类图像异常检测，性能差距大<br />- 方法：Dinomaly框架，Transformer架构，简单组件<br />- 效果：AUROC高，超越现有方法|


### 单目重建 (Monocular Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|High-fidelity 3D Object Generation from Single Image with RGBN-Volume Gaussian Reconstruction Model|基于RGBN-体积高斯重建模型的单图像高保真3D物体生成|Yiyang Shen, Kun Zhou, He Wang, Yin Yang, Tianjia Shao|<http://arxiv.org/pdf/2504.01512v1>|- 问题：2D图像几何模糊，3D高斯结构缺失<br />- 方法：RGBN-Volume Gaussian，Voxel-Gaussian表示，融合模块<br />- 效果：高保真，高质量，鲁棒|


## 神经渲染 (Neural Rendering)


### 神经辐射场 (Neural Radiance Fields)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Diffusion-Guided Gaussian Splatting for Large-Scale Unconstrained 3D Reconstruction and Novel View Synthesis|扩散引导的高斯分层用于大规模无约束3D重建和新视角合成|Niluthpol Chowdhury Mithun, Tuan Pham, Qiao Wang, Ben Southall, Kshitij Minhas, Bogdan Matei, Stephan Mandt, Supun Samarasekera .etc.|<http://arxiv.org/pdf/2504.01960v1>|- 问题：大规模，非约束，3D重建，稀疏数据，质量退化<br />- 方法：GS-Diff，多视图扩散模型，伪观测生成<br />- 效果：性能优越，超越现有基准|
|🆕 发布|FIORD: A Fisheye Indoor-Outdoor Dataset with LIDAR Ground Truth for 3D Scene Reconstruction and Benchmarking|FIORD：一个带有激光雷达地面真实值的鱼眼室内-室外数据集，用于3D场景重建和基准测试|Ulas Gunes, Matias Turkulainen, Xuqian Ren, Arno Solin, Juho Kannala, Esa Rahtu|<http://arxiv.org/pdf/2504.01732v1>|- 问题：视角受限，数据集规模，SfM处理，场景重建<br />- 方法：鱼眼图像，360度覆盖，LIDAR点云<br />- 效果：鲁棒基准，多样方法支持|
|🆕 发布|RealityAvatar: Towards Realistic Loose Clothing Modeling in Animatable 3D Gaussian Avatars|现实化身：迈向可动3D高斯化身中的逼真宽松服装建模|Yahui Li, Zhi Zeng, Liming Pang, Guixuan Zhang, Shuwu Zhang|<http://arxiv.org/pdf/2504.01559v1>|- 问题：服装动态建模，非刚性区域，时间不一致<br />- 方法：3D Gaussian Splatting，运动趋势模块，潜在骨骼编码器<br />- 效果：高保真，结构 fidelity，感知质量提升|
|🆕 发布|Luminance-GS: Adapting 3D Gaussian Splatting to Challenging Lighting Conditions with View-Adaptive Curve Adjustment|亮度-全局分割：通过视点自适应曲线调整将3D高斯分层应用于具有挑战性光照条件|Ziteng Cui, Xuangeng Chu, Tatsuya Harada|<http://arxiv.org/pdf/2504.01503v1>|- 问题：多视角，光照变化，NVS，3DGS<br />- 方法：Luminance-GS，曲线调整，颜色矩阵映射<br />- 效果：SOTA，实时渲染，质量提升|


### 可控渲染 (Controllable Rendering)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BOGausS: Better Optimized Gaussian Splatting|BOGausS：更优化的高斯散布|Stéphane Pateux, Matthieu Gendrin, Luce Morin, Théo Ladune, Xiaoran Jiang|<http://arxiv.org/pdf/2504.01844v1>|- 问题：3DGS训练，模型复杂度高，质量损失<br />- 方法：优化方法，BOGausS<br />- 效果：模型轻量化，质量无损|
|📝 更新|DreamScape: 3D Scene Creation via Gaussian Splatting joint Correlation Modeling|梦境场景：通过高斯分层联合相关性建模的3D场景生成|Yueming Zhao, Xuening Yuan, Hongyu Yang, Di Huang|<http://arxiv.org/pdf/2404.09227v3>|- 问题：3D场景生成，多物体，训练不稳定<br />- 方法：Gaussian Splatting，3D Gaussian Guide，LLMs<br />- 效果：高保真，可控|
|🆕 发布|3DBonsai: Structure-Aware Bonsai Modeling Using Conditioned 3D Gaussian Splatting|3DBonsai：基于条件3D高斯散布的结构感知盆景建模|Hao Wu, Hao Wang, Ruochong Li, Xuran Ma, Hui Xiong|<http://arxiv.org/pdf/2504.01619v1>|- 问题：3D生成，结构信息，复杂结构， bonsai<br />- 方法：3D空间殖民算法，3D高斯先验，结构一致性模块<br />- 效果：结构感知，生成效果，新基准|
|📝 更新|EmoHead: Emotional Talking Head via Manipulating Semantic Expression Parameters|情感头部：通过操纵语义表情参数实现的情感说话头|Xuli Shen, Hua Cai, Dingding Yu, Weilin Shen, Qing Xu, Xiangyang Xue|<http://arxiv.org/pdf/2503.19416v2>|- 问题：情感表达，视频生成，抽象概念<br />- 方法：语义参数，音频-表情模块，预训练超平面<br />- 效果：质量提升，可控性增强|
|🆕 发布|3D Gaussian Inverse Rendering with Approximated Global Illumination|3D高斯逆渲染与近似全局照明|Zirui Wu, Jianteng Chen, Laijian Li, Shaoteng Wu, Zhikai Zhu, Kang Xu, Martin R. Oswald, Jie Song|<http://arxiv.org/pdf/2504.01358v1>|[[代码]](<https://wuzirui.github.io/gs-ssr.>)<br />- 问题：3D场景重建，光照限制，编辑困难<br />- 方法：3D Gaussian Splatting，屏幕空间光线追踪，蒙特卡洛方法<br />- 效果：真实感，实时渲染，编辑性|


## 定位与映射 (Localization & Mapping)


### 视觉SLAM (Visual SLAM)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CoMatcher: Multi-View Collaborative Feature Matching|CoMatcher：多视角协同特征匹配|Jintao Zhang, Zimin Xia, Mingyue Dong, Shuhan Shen, Linwei Yue, Xianwei Zheng|<http://arxiv.org/pdf/2504.01872v1>|- 问题：多视角匹配，场景复杂，不确定性<br />- 方法：CoMatcher，全局理解，跨视图一致性<br />- 效果：可靠跟踪，性能优越|


### 位姿估计 (Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dual-stream Transformer-GCN Model with Contextualized Representations Learning for Monocular 3D Human Pose Estimation|双流Transformer-GCN模型，用于单目3D人体姿态估计的上下文表示学习|Mingrui Ye, Lianping Yang, Hegui Zhu, Zenghao Zheng, Xin Wang, Yantao Lo|<http://arxiv.org/pdf/2504.01764v1>|- 问题：单目3D人体姿态估计，深度模糊，数据限制，模型泛化<br />- 方法：Transformer-GCN双流模型，上下文表示学习，运动预训练<br />- 效果：性能提升，泛化能力强|
|🆕 发布|DEPTHOR: Depth Enhancement from a Practical Light-Weight dToF Sensor and RGB Image|深度增强：基于实用轻量级dToF传感器和RGB图像的深度增强|Jijun Xiang, Xuan Zhu, Xianqi Wang, Yu Wang, Hong Zhang, Fei Guo, Xin Yang|<http://arxiv.org/pdf/2504.01596v1>|[[代码]](<https://github.com/ShadowBbBb/Depthor>)<br />- 问题：深度增强，dToF，超分辨率，校准误差，噪声<br />- 方法：模拟数据，MDE，全局深度关系<br />- 效果：精度提升，RMSE降低|
|🆕 发布|Direction-Aware Hybrid Representation Learning for 3D Hand Pose and Shape Estimation|方向感知混合表示学习用于3D手部姿态和形状估计|Shiyong Liu, Zhihao Li, Xiao Tang, Jianzhuang Liu|<http://arxiv.org/pdf/2504.01298v1>|- 问题：3D手部姿态和形状估计，优化问题，训练困难<br />- 方法：方向感知混合特征，像素方向信息，对比学习<br />- 效果：准确率提升33%，实时运动捕捉|


## 自监督学习 (Self-supervised Learning)


### 对比学习 (Contrastive Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Sparse Dictionary Learning for Image Recovery by Iterative Shrinkage|稀疏字典学习迭代收缩图像恢复|Shima Shabani, Mohammadsadegh Khoshghiaferezaee, Michael Breuß|<http://arxiv.org/pdf/2503.10732v2>|- 问题：稀疏编码，图像恢复，优化方法<br />- 方法：迭代收缩，在线学习，字典学习<br />- 效果：重建质量提升，计算效率高|


## 迁移与适应 (Transfer & Adaptation)


### 域适应 (Domain Adaptation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Deep Representation Learning for Unsupervised Clustering of Myocardial Fiber Trajectories in Cardiac Diffusion Tensor Imaging|深度表示学习在心脏扩散张量成像中无监督聚类心肌纤维轨迹|Mohini Anand, Xavier Tricoche|<http://arxiv.org/pdf/2504.01953v1>|- 问题：心肌纤维轨迹聚类，DTI数据，无监督学习<br />- 方法：双向LSTM，Transformer自编码器，密度聚类<br />- 效果：纤维轨迹识别，结构分析|
|🆕 发布|Memory-efficient Low-latency Remote Photoplethysmography through Temporal-Spatial State Space Duality|基于时空状态空间偶合的高效内存低延迟远程光电容积脉搏波描记法|Kegang Wang, Jiankai Tang, Yuxuan Fan, Jiatong Ji, Yuanchun Shi, Yuntao Wang|<http://arxiv.org/pdf/2504.01774v1>|[[代码]](<https://github.com/Health-HCI-Group/ME-rPPG-demo.>)<br />- 问题：rPPG计算瓶颈，资源需求高<br />- 方法：ME-rPPG，时空状态空间对偶性<br />- 效果：低延迟，高准确率|
|📝 更新|FriendNet: Detection-Friendly Dehazing Network|友网：面向检测的去雾网络|Yihua Fan, Yongzhen Wang, Mingqiang Wei, Fu Lee Wang, Haoran Xie|<http://arxiv.org/pdf/2403.04443v2>|[[代码]](<https://github.com/fanyihua0309/FriendNet.>)<br />- 问题：图像去雾，目标检测，性能提升<br />- 方法：FriendNet架构，GFB，GAB，PFEB<br />- 效果：图像质量高，检测精度高|
|📝 更新|Efficient Alignment of Unconditioned Action Prior for Language-conditioned Pick and Place in Clutter|高效对齐无条件动作先验以实现语言条件下的杂乱环境中的抓取和放置|Kechun Xu, Xunlong Xia, Kaixuan Wang, Yifei Yang, Yunxuan Mao, Bing Deng, Rong Xiong, Yue Wang|<http://arxiv.org/pdf/2503.09423v2>|[[代码]](<https://xukechun.github.io/papers>)<br />- 问题：语言条件拣放，复杂环境，数据需求高<br />- 方法：A2，动作先验对齐，注意力层<br />- 效果：成功率提升，步骤减少|
|🆕 发布|MuTri: Multi-view Tri-alignment for OCT to OCTA 3D Image Translation|MuTri：基于多视角三重对齐的OCT到OCTA 3D图像转换|Zhuangzhuang Chen, Hualiang Wang, Chubin Ou, Xiaomeng Li|<http://arxiv.org/pdf/2504.01428v1>|- 问题：OCT到OCTA图像转换，单视图指导，结果次优<br />- 方法：多视图Tri-alignment，VQ-VAE，语义对齐，结构对齐<br />- 效果：大规模数据集，性能提升|
|📝 更新|Dynamic Proxy Domain Generalizes the Crowd Localization by Better Binary Segmentation|动态代理域通过更好的二值分割泛化人群定位|Junyu Gao, Da Zhang, Qiyu Wang, Zhiyuan Zhao, Xuelong Li|<http://arxiv.org/pdf/2404.13992v2>|[[代码]](<https://github.com/zhangda1018/DPD.>)<br />- 问题：领域迁移，置信度阈值，泛化能力<br />- 方法：动态代理域，生成代理域，DPD算法<br />- 效果：泛化提升，定位准确|


### 元学习 (Meta Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Meta ControlNet: Enhancing Task Adaptation via Meta Learning|元控制网：通过元学习增强任务适应性|Junjie Yang, Jinze Zhao, Peihao Wang, Zhangyang Wang, Yingbin Liang|<http://arxiv.org/pdf/2312.01255v2>|[[代码]](<https://github.com/JunjieYang97/Meta-ControlNet.>)<br />- 问题：任务适应，训练步骤长，零样本控制，非边缘任务<br />- 方法：元学习，层冻结设计，快速适应<br />- 效果：学习步骤减少，零样本适应，性能提升|


### 增量学习 (Incremental Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ProtoGuard-guided PROPEL: Class-Aware Prototype Enhancement and Progressive Labeling for Incremental 3D Point Cloud Segmentation|原型守护引导的PROPEL：增量3D点云分割的类感知原型增强和渐进式标注|Haosheng Li, Yuecong Xu, Junjie Chen, Kemi Ding|<http://arxiv.org/pdf/2504.01648v1>|- 问题：灾难性遗忘，类别相似，不平衡分布，误分类<br />- 方法：ProtoGuard，PROPEL，原型增强，渐进式标注<br />- 效果：mIoU提升，CIL性能|


## 鲁棒学习 (Robust Learning)


### 对抗训练 (Adversarial Training)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Enhancing Implicit Neural Representations via Symmetric Power Transformation|通过对称幂变换增强隐式神经网络表示|Weixiang Zhang, Shuzhao Xie, Chengwei Ren, Shijia Ge, Mingzi Wang, Zhi Wang|<http://arxiv.org/pdf/2412.09213v2>|- 问题：INR能力，数据变换，对称性<br />- 方法：对称幂变换，范围定义，非线性<br />- 效果：性能提升，鲁棒性增强|
|🆕 发布|DreamActor-M1: Holistic, Expressive and Robust Human Image Animation with Hybrid Guidance|DreamActor-M1：基于混合引导的全面、富有表现力和鲁棒的人像动画|Yuxuan Luo, Zhengkun Rong, Lizhen Wang, Longhao Zhang, Tianshu Hu, Yongming Zhu|<http://arxiv.org/pdf/2504.01724v1>|[[代码]](<https://grisoon.github.io/DreamActor-M1>)<br />- 问题：细粒度控制，多尺度适应，时间一致性<br />- 方法：扩散变换器，混合引导，渐进式训练<br />- 效果：表达性强，鲁棒性好|
|🆕 发布|Bridge 2D-3D: Uncertainty-aware Hierarchical Registration Network with Domain Alignment|桥接2D-3D：具有域对齐的不确定性感知分层配准网络|Zhixin Cheng, Jiacheng Deng, Xinjun Li, Baoqun Yin, Tianzhu Zhang|<http://arxiv.org/pdf/2504.01641v1>|- 问题：图像-点云配准，噪声匹配，域差距<br />- 方法：UHMM，AMAM，不确定性建模，域对齐<br />- 效果：优越性能，最先进方法|


### 对抗防御 (Adversarial Defense)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AdPO: Enhancing the Adversarial Robustness of Large Vision-Language Models with Preference Optimization|AdPO：通过偏好优化增强大型视觉-语言模型的对抗鲁棒性|Chaohu Liu, Tianyi Gui, Yu Liu, Linli Xu|<http://arxiv.org/pdf/2504.01735v1>|- 问题：LVLMs，对抗攻击，鲁棒性，性能退化<br />- 方法：偏好优化，对抗训练，图像编码器修改<br />- 效果：性能提升，效率高|
|🆕 发布|Overlap-Aware Feature Learning for Robust Unsupervised Domain Adaptation for 3D Semantic Segmentation|基于重叠感知的特征学习，用于鲁棒的3D语义分割无监督域适应|Junjie Chen, Yuecong Xu, Haosheng Li, Kemi Ding|<http://arxiv.org/pdf/2504.01668v1>|- 问题：3D语义分割，域适应，鲁棒性，对抗攻击<br />- 方法：重叠感知，可逆注意力，对比学习<br />- 效果：mIoU提升，对抗攻击下性能稳定|
|🆕 发布|Robust Unsupervised Domain Adaptation for 3D Point Cloud Segmentation Under Source Adversarial Attacks|鲁棒的无监督领域自适应：在源对抗攻击下的3D点云分割|Haosheng Li, Yuecong Xu, Junjie Chen, Kemi Ding|<http://arxiv.org/pdf/2504.01659v1>|- 问题：无监督领域自适应，对抗攻击，3D点云分割<br />- 方法：对抗点云生成，Robust Long-Tail loss，解码器分支<br />- 效果：性能下降减轻，鲁棒性提升|
|🆕 发布|Benchmarking the Spatial Robustness of DNNs via Natural and Adversarial Localized Corruptions|通过自然和对抗性局部扰动评估DNN的空间鲁棒性|Giulia Marchiori Pietrosanti, Giulio Rossolini, Alessandro Biondi, Giorgio Buttazzo|<http://arxiv.org/pdf/2504.01632v1>|- 问题：DNNs空间鲁棒性，局部扰动，语义分割<br />- 方法：区域感知多攻击，专用指标，评估框架<br />- 效果：模型鲁棒性，威胁覆盖，可靠性提升|
|🆕 发布|Leveraging Generalizability of Image-to-Image Translation for Enhanced Adversarial Defense|利用图像到图像翻译的泛化能力以增强对抗性防御|Haibo Zhang, Zhihua Yao, Kouichi Sakurai, Takeshi Saitoh|<http://arxiv.org/pdf/2504.01399v1>|- 问题：对抗攻击，模型稳定性，泛化能力<br />- 方法：图像到图像翻译，残差块，单模型训练<br />- 效果：分类精度提升，性能竞争|
|📝 更新|STEREO: A Two-Stage Framework for Adversarially Robust Concept Erasing from Text-to-Image Diffusion Models|立体：一种针对文本到图像扩散模型的对抗鲁棒概念擦除两阶段框架|Koushik Srivatsan, Fahad Shamshad, Muzammal Naseer, Vishal M. Patel, Karthik Nandakumar|<http://arxiv.org/pdf/2408.16807v2>|- 问题：概念擦除，对抗攻击，模型滥用<br />- 方法：两阶段框架，对抗训练，锚定概念<br />- 效果：鲁棒性提升，效用保留|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Scale-adaptive UAV Geo-localization via Height-aware Partition Learning|基于高度感知分区学习的尺度自适应无人机地理定位|Quan Chen, Tingyu Wang, Rongfeng Lu, Yu Liu, Bolun Zheng, Zhedong Zheng|<http://arxiv.org/pdf/2412.11535v3>|- 问题：尺度差异，定位精度低<br />- 方法：高度感知，自适应分区学习，特征提取<br />- 效果：定位精度高，鲁棒性强|
|🆕 发布|A Conic Transformation Approach for Solving the Perspective-Three-Point Problem|圆锥变换法解决透视三点问题的方法|Haidong Wu, Snehal Bhayani, Janne Heikkilä|<http://arxiv.org/pdf/2504.01620v1>|- 问题：P3P问题，圆锥曲线，求解<br />- 方法：圆锥变换，坐标系统，简化公式<br />- 效果：速度提升，鲁棒性，稳定性|
|📝 更新|Towards Calibrated Deep Clustering Network|朝向校准的深度聚类网络|Yuheng Jia, Jianhong Cheng, Hui Liu, Junhui Hou|<http://arxiv.org/pdf/2403.02998v3>|[[代码]](<https://github.com/ChengJianH/CDC.>)<br />- 问题：过自信问题，深度聚类，置信度误差<br />- 方法：双头模型，置信度调整，伪标签自训练<br />- 效果：性能提升，准确度提高|
|📝 更新|ArchCAD-400K: An Open Large-Scale Architectural CAD Dataset and New Baseline for Panoptic Symbol Spotting|ArchCAD-400K：一个开放的大规模建筑CAD数据集和全景符号检测的新基准|Ruifeng Luo, Zhengjie Liu, Tianxiao Cheng, Jie Wang, Tongjie Wang, Xingguang Wei, Haomin Wang, YanPeng Li .etc.|<http://arxiv.org/pdf/2503.22346v2>|- 问题：CAD符号识别，数据标注，大规模数据集<br />- 方法：CAD数据标注引擎，DPSS模型，自适应融合模块<br />- 效果：性能提升，鲁棒性增强|
|🆕 发布|ForestVO: Enhancing Visual Odometry in Forest Environments through ForestGlue|ForestVO：通过ForestGlue增强森林环境中的视觉里程计|Thomas Pritchard, Saifullah Ijaz, Ronald Clark, Basaran Bahadir Kocer|<http://arxiv.org/pdf/2504.01261v1>|- 问题：森林环境，视觉里程计，特征匹配，计算开销<br />- 方法：ForestGlue，SuperPoint，LightGlue/SuperGlue，Transformer<br />- 效果：精度高，计算低，实时部署|


### 对抗攻击 (Adversarial Attack)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Adversarial Example Soups: Improving Transferability and Stealthiness for Free|对抗样本汤：免费提升迁移性和隐蔽性|Bo Yang, Hengwei Zhang, Jindong Wang, Yulong Yang, Chenhao Lin, Chao Shen, Zhengyu Zhao|<http://arxiv.org/pdf/2402.18370v3>|- 问题：可迁移性，对抗样本，安全性风险<br />- 方法：对抗样本汤，模型汤启发，平均丢弃样本<br />- 效果：攻击成功率提升，隐蔽性增强|


## 模型压缩加速 (Model Compression & Acceleration)


### 知识蒸馏 (Knowledge Distillation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bridge the Gap between SNN and ANN for Image Restoration|弥合SNN与ANN在图像恢复中的差距|Xin Su, Chen Wu, Zhuoran Zheng|<http://arxiv.org/pdf/2504.01755v1>|- 问题：SNN训练慢，效率低，能耗高<br />- 方法：ANN-SNN蒸馏，中间特征引导<br />- 效果：效率提升，性能改善|
|🆕 发布|FlowR: Flowing from Sparse to Dense 3D Reconstructions|FlowR：从稀疏到密集的3D重建流动|Tobias Fischer, Samuel Rota Bulò, Yung-Hsu Yang, Nikhil Varma Keetha, Lorenzo Porzi, Norman Müller, Katja Schwarz, Jonathon Luiten .etc.|<http://arxiv.org/pdf/2504.01647v1>|- 问题：3D重建，稀疏数据，质量下降<br />- 方法：多视图，流匹配模型，生成新视图<br />- 效果：质量提升，基准测试领先|
|🆕 发布|Q-Adapt: Adapting LMM for Visual Quality Assessment with Progressive Instruction Tuning|Q-Adapt：通过渐进式指令调整适应LMM进行视觉质量评估|Yiting Lu, Xin Li, Haoning Wu, Bingchen Li, Weisi Lin, Zhibo Chen|<http://arxiv.org/pdf/2504.01655v1>|[[代码]](<https://github.com/yeppp27/Q-Adapt.>)<br />- 问题：EIQA感知解释冲突，理解不足<br />- 方法：Q-Adapt，渐进式指令调整，LoRA，视觉提示调整<br />- 效果：多方面解释，性能提升|
|📝 更新|Cyclic Contrastive Knowledge Transfer for Open-Vocabulary Object Detection|循环对比知识迁移用于开放词汇目标检测|Chuhan Zhang, Chaoyang Zhu, Pingcheng Dong, Long Chen, Dong Zhang|<http://arxiv.org/pdf/2503.11005v2>|- 问题：开放词汇检测，预训练模型，知识迁移，监督学习<br />- 方法：循环知识转移，语义先验，区域对比损失<br />- 效果：性能提升，AP50，COCO基准|


## 泛化与鲁棒性 (Generalization & Robustness)


### 不确定性建模 (Uncertainty Modeling)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GaussianLSS -- Toward Real-world BEV Perception: Depth Uncertainty Estimation via Gaussian Splatting|高斯LSS -- 面向真实世界BEV感知：通过高斯喷溅进行深度不确定性估计|Shu-Wei Lu, Yi-Hsuan Tsai, Yi-Ting Chen|<http://arxiv.org/pdf/2504.01957v1>|- 问题：BEV感知，不确定性建模，计算成本高<br />- 方法：Gaussian Splatting，深度不确定性估计，LSS范式<br />- 效果：性能提升，速度提升，内存效率高|


### 分布鲁棒性 (Distribution Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FortisAVQA and MAVEN: a Benchmark Dataset and Debiasing Framework for Robust Multimodal Reasoning|FortisAVQA和MAVEN：一个用于鲁棒多模态推理的基准数据集和去偏框架|Jie Ma, Zhitao Gao, Qi Chai, Jun Liu, Pinghui Wang, Jing Tao, Zhou Su|<http://arxiv.org/pdf/2504.00487v2>|[[代码]](<https://github.com/reml-group/fortisavqa.>)<br />- 问题：AVQA偏差，鲁棒性差<br />- 方法：FortisAVQA数据集，MAVEN框架，循环协作去偏<br />- 效果：性能提升，去偏有效|


### 域泛化 (Domain Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mesh Mamba: A Unified State Space Model for Saliency Prediction in Non-Textured and Textured Meshes|标题翻译：网格蟒：用于非纹理和纹理网格显著性预测的统一状态空间模型|Kaiwei Zhang, Dandan Zhu, Xiongkuo Min, Guangtao Zhai|<http://arxiv.org/pdf/2504.01466v1>|- 问题：视觉注意力，几何结构，纹理，显著性，数据集<br />- 方法：状态空间模型，拓扑框架，全局上下文建模<br />- 效果：性能提升，可扩展性，多类型适应|


## 医学影像分析 (Medical Image Analysis)


### 医学分割 (Medical Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Scene-Centric Unsupervised Panoptic Segmentation|场景中心的无监督全景分割|Oliver Hahn, Christoph Reich, Nikita Araslanov, Daniel Cremers, Christian Rupprecht, Stefan Roth|<http://arxiv.org/pdf/2504.01955v1>|- 问题：无监督，全景分割，场景理解<br />- 方法：场景中心，伪标签，深度运动线索<br />- 效果：泛化能力强，PQ提升9.4%|
|🆕 发布|Equivariant Spherical CNNs for Accurate Fiber Orientation Distribution Estimation in Neonatal Diffusion MRI with Reduced Acquisition Time|等变球面CNN在新生儿扩散磁共振成像中准确估计纤维方向分布并减少采集时间|Haykel Snoussi, Davood Karimi|<http://arxiv.org/pdf/2504.01925v1>|- 问题：脑微结构评估，低信噪比，运动伪影，髓鞘化<br />- 方法：旋转等变sCNN，减少梯度方向，FOD预测<br />- 效果：低MSE，高ACC，解剖合理性提升|
|🆕 发布|Instance Migration Diffusion for Nuclear Instance Segmentation in Pathology|核病理学中的实例迁移扩散用于核实例分割|Lirui Qi, Hongliang He, Tong Wang, Siwei Feng, Guohong Fu|<http://arxiv.org/pdf/2504.01577v1>|- 问题：核实例分割，数据稀缺，性能受限<br />- 方法：实例迁移扩散模型，核迁移模块，结构感知修复<br />- 效果：性能提升，数据增强|
|🆕 发布|STPNet: Scale-aware Text Prompt Network for Medical Image Segmentation|STPNet：用于医学图像分割的尺度感知文本提示网络|Dandan Shan, Zihan Li, Yunxiang Li, Qingde Li, Jie Tian, Qingqi Hong|<http://arxiv.org/pdf/2504.01561v1>|[[代码]](<https://github.com/HUANGLIZI/STPNet.>)<br />- 问题：医学图像分割，不确定性，语义差距<br />- 方法：文本提示网络，多尺度描述，检索-分割联合学习<br />- 效果：超越现有方法，语义知识整合|
|🆕 发布|Beyond Nearest Neighbor Interpolation in Data Augmentation|超越最近邻插值在数据增强中的应用|Olivier Rukundo|<http://arxiv.org/pdf/2504.01527v1>|- 问题：数据增强，标签风险，像素错误<br />- 方法：几何变换，替代插值，类别过滤<br />- 效果：质量提升，性能改善|
|🆕 发布|Semi-Supervised Biomedical Image Segmentation via Diffusion Models and Teacher-Student Co-Training|基于扩散模型和师生协同训练的半监督生物医学图像分割|Luca Ciampi, Gabriele Lagani, Giuseppe Amato, Fabrizio Falchi|<http://arxiv.org/pdf/2504.01547v1>|[[代码]](<https://github.com/ciampluca/diffusion_semi_supervised_biomedical_image_segmentation>)<br />- 问题：半监督学习，生物医学图像分割，数据标注限制<br />- 方法：DDPMs，教师-学生共训练，伪标签生成<br />- 效果：性能优于现有技术，有限标注数据|
|🆕 发布|BiSeg-SAM: Weakly-Supervised Post-Processing Framework for Boosting Binary Segmentation in Segment Anything Models|BiSeg-SAM：Segment Anything Models中提升二值分割的弱监督后处理框架|Encheng Su, Hu Cao, Alois Knoll|<http://arxiv.org/pdf/2504.01452v1>|- 问题：弱监督，医学图像分割，标注成本高<br />- 方法：BiSeg-SAM，WeakBox，MM2B，DetailRefine<br />- 效果：性能提升，SOTA|
|🆕 发布|Multimodal Point Cloud Semantic Segmentation With Virtual Point Enhancement|多模态点云语义分割与虚拟点增强|Zaipeng Duan, Xuzhong Hu, Pei An, Jie Ma|<http://arxiv.org/pdf/2504.01449v1>|- 问题：点云稀疏，细节捕捉困难<br />- 方法：虚拟点增强，自适应滤波，噪声鲁棒特征提取<br />- 效果：mIoU提升，性能改善|
|📝 更新|SAM-REF: Introducing Image-Prompt Synergy during Interaction for Detail Enhancement in the Segment Anything Model|SAM-REF：在Segment Anything模型中引入图像提示协同作用以增强细节|Chongkai Yu, Ting Liu, Anqi Li, Xiaochao Qu, Chengjing Wu, Luoqi Liu, Xiaolin Hu|<http://arxiv.org/pdf/2408.11535v3>|- 问题：交互式分割，细节提取，效率低<br />- 方法：两阶段精炼框架，图像-提示协同，轻量级精炼器<br />- 效果：精度提升，效率保持|
|🆕 发布|v-CLR: View-Consistent Learning for Open-World Instance Segmentation|v-CLR：面向开放世界实例分割的视图一致性学习|Chang-Bin Zhang, Jinhong Ni, Yujie Zhong, Kai Han|<http://arxiv.org/pdf/2504.01383v1>|[[代码]](<https://visual-ai.github.io/vclr>)<br />- 问题：开放世界实例分割，视觉网络偏差，未见纹理<br />- 方法：v-CLR框架，多视角学习，无监督模型<br />- 效果：性能最优，鲁棒性强|
|🆕 发布|DALIP: Distribution Alignment-based Language-Image Pre-Training for Domain-Specific Data|DALIP：基于分布对齐的领域特定数据语言-图像预训练|Junjie Wu, Jiangtao Xie, Zhaolin Zhang, Qilong Wang, Qinghua Hu, Peihua Li, Sen Xu|<http://arxiv.org/pdf/2504.01386v1>|- 问题：CLIP模型，领域特定数据，性能限制<br />- 方法：DALIP，特征分布匹配，MBDC模块<br />- 效果：性能提升，泛化能力强|
|🆕 发布|CFMD: Dynamic Cross-layer Feature Fusion for Salient Object Detection|CFMD：用于显著目标检测的动态跨层特征融合|Jin Lian, Zhongyu Wan, Ming Gao, JunFeng Chen|<http://arxiv.org/pdf/2504.01326v1>|- 问题：CFPNs，计算瓶颈，边界模糊<br />- 方法：CFLMA，动态权重，自适应上采样<br />- 效果：精度提升，边界分割质量|
|🆕 发布|BOLDSimNet: Examining Brain Network Similarity between Task and Resting-State fMRI|BOLDSimNet：探讨任务态和静息态fMRI脑网络相似性|Boseong Kim, Debashis Das Chakladar, Haejun Chung, Ikbeom Jang|<http://arxiv.org/pdf/2504.01274v1>|- 问题：fMRI，脑网络相似性，噪声敏感，多变量依赖<br />- 方法：BOLDSimNet，MTE，功能ROI分组<br />- 效果：网络相似性量化，注意力波动识别|


### 影像重建 (Image Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Muographic Image Upsampling with Machine Learning for Built Infrastructure Applications|基于机器学习的建筑基础设施应用中的穆奥图像超分辨率|William O'Donnell, David Mahon, Guangliang Yang, Simon Gardner|<http://arxiv.org/pdf/2502.02624v2>|- 问题：非破坏性评估，muography，图像重建，时间延长，噪声<br />- 方法：cWGAN-GP，upsampling，语义分割，Geant4模拟<br />- 效果：速度提升，质量改善，特征量化|


## 智能驾驶 (Intelligent Driving)


### 环境感知 (Environment Perception)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning from Streaming Video with Orthogonal Gradients|从正交梯度中学习流媒体视频|Tengda Han, Dilara Gokay, Joseph Heyward, Chuhan Zhang, Daniel Zoran, Viorica Pătrăucean, João Carreira, Dima Damen .etc.|<http://arxiv.org/pdf/2504.01961v1>|- 问题：视频流学习，非独立同分布，性能下降<br />- 方法：正交梯度，优化器修改，AdamW<br />- 效果：性能提升，优于AdamW|
|🆕 发布|{GSR4B}: Biomass Map Super-Resolution with Sentinel-1/2 Guidance|{GSR4B}: 基于Sentinel-1/2引导的生物量地图超分辨率|Kaan Karaman, Yuchang Jiang, Damien Robert, Vivien Sainte Fare Garnot, Maria João Santos, Jan Dirk Wegner|<http://arxiv.org/pdf/2504.01722v1>|[[代码]](<https://github.com/kaankaramanofficial/GSR4B>)<br />- 问题：高分辨率生物质地图，低分辨率产品，卫星观测<br />- 方法：GSR，多尺度引导，纹理保留<br />- 效果：精度提升，计算效率高|
|📝 更新|Divide and Merge: Motion and Semantic Learning in End-to-End Autonomous Driving|分割与合并：端到端自动驾驶中的运动和语义学习|Yinzhe Shen, Omer Sahin Tas, Kaiwen Wang, Royden Wagner, Christoph Stiller|<http://arxiv.org/pdf/2502.07631v2>|[[代码]](<https://github.com/shenyinzhe/DMAD.>)<br />- 问题：多任务学习，负迁移，感知性能<br />- 方法：神经贝叶斯解码，语义解码，并行学习<br />- 效果：性能提升，感知预测规划|


### 轨迹预测 (Trajectory Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|End-to-End Driving with Online Trajectory Evaluation via BEV World Model|端到端驾驶：通过BEV世界模型进行在线轨迹评估|Yingyan Li, Yuqi Wang, Yang Liu, Jiawei He, Lue Fan, Zhaoxiang Zhang|<http://arxiv.org/pdf/2504.01941v1>|[[代码]](<https://github.com/liyingyanUCAS/WoTE.>)<br />- 问题：自动驾驶，轨迹评估，安全性<br />- 方法：BEV世界模型，在线预测，轨迹评估<br />- 效果：性能领先，效率高|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GMAI-VL-R1: Harnessing Reinforcement Learning for Multimodal Medical Reasoning|GMAI-VL-R1：利用强化学习进行多模态医学推理|Yanzhou Su, Tianbin Li, Jiyao Liu, Chenglong Ma, Junzhi Ning, Cheng Tang, Sibo Ju, Jin Ye .etc.|<http://arxiv.org/pdf/2504.01886v1>|[[代码]](<https://github.com/uni-medical/GMAI-VL-R1>)<br />- 问题：医疗推理能力不足，诊断精度低<br />- 方法：多模态推理，强化学习，数据合成<br />- 效果：诊断准确率提升，泛化能力增强|


### 决策规划 (Decision Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Why Autonomous Vehicles Are Not Ready Yet: A Multi-Disciplinary Review of Problems, Attempted Solutions, and Future Directions|自动驾驶汽车为何尚未准备好：问题、尝试的解决方案和未来方向的跨学科综述|Xingshuai Dong, Max Cappuccio, Hamad Al Jassmi, Fady Alnajjar, Essam Debie, Milad Ghasrikhouzani, Alessandro Lanteri, Ali Luqman .etc.|<http://arxiv.org/pdf/2311.09093v4>|- 问题：自动驾驶，技术挑战，商业化延迟<br />- 方法：多学科审查，风险评估，跨领域分析<br />- 效果：问题识别，解决方案，未来方向|


## 其他 (Others)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spatial-R1: Enhancing MLLMs in Video Spatial Reasoning|空间-R1：提升视频空间推理中的多语言大模型|Kun Ouyang|<http://arxiv.org/pdf/2504.01805v1>|- 问题：视频空间推理，MLLMs，挑战<br />- 方法：SR数据集，GRPO优化，Qwen2.5-VL-7B-Instruct<br />- 效果：性能提升，VSI-Bench基准，超越模型|
|🆕 发布|Slow-Fast Architecture for Video Multi-Modal Large Language Models|慢-快架构用于视频多模态大型语言模型|Min Shi, Shihao Wang, Chieh-Yun Chen, Jitesh Jain, Kai Wang, Junjun Xiong, Guilin Liu, Zhiding Yu .etc.|<http://arxiv.org/pdf/2504.01328v1>|- 问题：视频MLLMs，时间分辨率，空间细节，计算预算<br />- 方法：慢-快架构，双token策略，混合解码器<br />- 效果：性能提升，效率提高|

