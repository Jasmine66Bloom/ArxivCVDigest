## [UPDATED!] **2025-04-07** (Update Time)


## 表示学习 (Representation Learning)


### 基础模型 (Foundation Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Training state-of-the-art pathology foundation models with orders of magnitude less data|用数量级更少的数据训练最先进的病理学基础模型|Mikhail Karasikov, Joost van Doorn, Nicolas Känzig, Melis Erdal Cesur, Hugo Mark Horlings, Robert Berke, Fei Tang, Sebastian Otálora|<http://arxiv.org/pdf/2504.05186v1>|- 问题：数据量，模型性能，病理图像<br />- 方法：DINOv2框架，后训练微调，高分辨率图像<br />- 效果：模型性能，数据量减少|


### 视觉Transformer (Vision Transformers)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CloSE: A Compact Shape- and Orientation-Agnostic Cloth State Representation|CloSE：一种紧凑的形状和方向无关的布料状态表示|Jay Kamat, Júlia Borràs, Carme Torras|<http://arxiv.org/pdf/2504.05033v1>|[[代码]](<https://jaykamat99.github.io/close-representation>)<br />- 问题：非刚性布料，变形表示，形状无关<br />- 方法：dGLI盘表示，CloSE表示<br />- 效果：紧凑，连续，应用广泛|
|🆕 发布|Lumina-OmniLV: A Unified Multimodal Framework for General Low-Level Vision|Lumina-OmniLV：一种用于通用低级视觉的统一多模态框架|Yuandong Pu, Le Zhuo, Kaiwen Zhu, Liangbin Xie, Wenlong Zhang, Xiangyu Chen, Pneg Gao, Yu Qiao .etc.|<http://arxiv.org/pdf/2504.04903v1>|- 问题：低级视觉任务，多模态，多任务<br />- 方法：Diffusion Transformer，文本视觉提示，浅层特征控制<br />- 效果：性能优化，泛化能力强|
|🆕 发布|Vision Transformers with Autoencoders and Explainable AI for Cancer Patient Risk Stratification Using Whole Slide Imaging|基于全切片成像的癌症患者风险分层：结合自编码器和可解释人工智能的视觉Transformer|Ahmad Hussein, Mukesh Prasad, Ali Braytee|<http://arxiv.org/pdf/2504.04749v1>|- 问题：癌症诊断，WSI，特征提取，可解释性<br />- 方法：ViT，Autoencoders，SHAP，风险分层<br />- 效果：性能强，可解释性高|


## 生成建模 (Generative Modeling)


### 扩散模型 (Diffusion Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Gaussian Mixture Flow Matching Models|高斯混合流匹配模型|Hansheng Chen, Kai Zhang, Hao Tan, Zexiang Xu, Fujun Luan, Leonidas Guibas, Gordon Wetzstein, Sai Bi|<http://arxiv.org/pdf/2504.05304v1>|- 问题：采样误差，颜色过饱和，生成质量低<br />- 方法：GMFlow模型，动态GM参数，GM-SDE/ODE求解器<br />- 效果：生成质量高，精度高|
|🆕 发布|CREA: A Collaborative Multi-Agent Framework for Creative Content Generation with Diffusion Models|协同多智能体扩散模型创意内容生成框架：CREA|Kavana Venkatesh, Connor Dunlop, Pinar Yanardag|<http://arxiv.org/pdf/2504.05306v1>|- 问题：AI图像创造力，编辑自主性，艺术性<br />- 方法：多智能体协作，创意编辑任务，扩散模型<br />- 效果：性能提升，艺术探索|
|📝 更新|DiffPatch: Generating Customizable Adversarial Patches using Diffusion Models|DiffPatch：利用扩散模型生成可定制对抗性补丁|Zhixiang Wang, Xiaosen Wang, Bo Wang, Siheng Chen, Zhibo Wang, Xingjun Ma, Yu-Gang Jiang|<http://arxiv.org/pdf/2412.01440v3>|- 问题：对抗样本，美观性，定制化<br />- 方法：扩散模型，参考图像，形状可变<br />- 效果：自然外观，攻击性能|
|🆕 发布|DA2Diff: Exploring Degradation-aware Adaptive Diffusion Priors for All-in-One Weather Restoration|DA2Diff：探索适用于一站式天气修复的降级感知自适应扩散先验|Jiamei Xiong, Xuefeng Yan, Yongzhen Wang, Wei Zhao, Xiao-Ping Zhang, Mingqiang Wei|<http://arxiv.org/pdf/2504.05135v1>|- 问题：多天气退化，复杂真实退化<br />- 方法：CLIP感知，降解自适应先验，动态专家选择<br />- 效果：性能优越，适应性强|
|📝 更新|CleanDIFT: Diffusion Features without Noise|CleanDIFT：无噪声的扩散特征|Nick Stracke, Stefan Andreas Baumann, Kolja Bauer, Frank Fundel, Björn Ommer|<http://arxiv.org/pdf/2412.03439v2>|- 问题：噪声影响，特征质量，模型性能<br />- 方法：轻量级微调，无监督，噪声消除<br />- 效果：性能提升，成本降低|
|📝 更新|No Re-Train, More Gain: Upgrading Backbones with Diffusion model for Pixel-Wise and Weakly-Supervised Few-Shot Segmentation|无需重新训练，更多收益：使用扩散模型升级骨干网络以实现像素级和弱监督小样本分割|Shuai Chen, Fanman Meng, Chenhao Wu, Haoran Wei, Runtong Zhang, Qingbo Wu, Linfeng Xu, Hongliang Li|<http://arxiv.org/pdf/2407.16182v2>|- 问题：FSS方法，灵活性，多类型标注，不同标注量<br />- 方法：DiffUp框架，特征转换模块，多粒度先验<br />- 效果：性能提升，准确度提高|
|🆕 发布|REWIND: Real-Time Egocentric Whole-Body Motion Diffusion with Exemplar-Based Identity Conditioning|REWIND：基于示例身份条件的实时自中心全身运动扩散|Jihyun Lee, Weipeng Xu, Alexander Richard, Shih-En Wei, Shunsuke Saito, Shaojie Bai, Te-Li Wang, Minhyuk Sung .etc.|<http://arxiv.org/pdf/2504.04956v1>|- 问题：实时，高保真，自运动估计<br />- 方法：级联去噪扩散，扩散蒸馏，Transformer架构<br />- 效果：实时，高精度|
|📝 更新|Track4Gen: Teaching Video Diffusion Models to Track Points Improves Video Generation|Track4Gen：通过跟踪点训练视频扩散模型以提升视频生成|Hyeonho Jeong, Chun-Hao Paul Huang, Jong Chul Ye, Niloy Mitra, Duygu Ceylan|<http://arxiv.org/pdf/2412.06016v3>|- 问题：视觉连贯性，外观漂移，空间跟踪，特征级监督<br />- 方法：Track4Gen，视频扩散，点跟踪，单网络融合<br />- 效果：减少漂移，稳定生成|
|📝 更新|A Survey on Personalized Content Synthesis with Diffusion Models|个性化内容合成中的扩散模型综述|Xulu Zhang, Xiaoyong Wei, Wentao Hu, Jinlin Wu, Jiaxin Wu, Wengyu Zhang, Zhaoxiang Zhang, Zhen Lei .etc.|<http://arxiv.org/pdf/2405.05538v3>|- 问题：个性化内容合成，扩散模型，内容创作<br />- 方法：TTF，PTA，任务个性化<br />- 效果：综述，挑战分析，未来方向|
|🆕 发布|Disentangling Instruction Influence in Diffusion Transformers for Parallel Multi-Instruction-Guided Image Editing|解耦扩散变换器中并行多指令引导图像编辑的指令影响|Hui Liu, Bin Zou, Suiyun Zhang, Kecheng Chen, Rui Liu, Haoliang Li|<http://arxiv.org/pdf/2504.04784v1>|- 问题：多指令并行编辑，指令冲突，质量下降<br />- 方法：指令影响解耦，注意力掩码，局部修改<br />- 效果：步骤减少，保真度提升，编辑完成|
|🆕 发布|Continuous Locomotive Crowd Behavior Generation|连续机车人群行为生成|Inhwan Bae, Junoh Lee, Hae-Gon Jeon|<http://arxiv.org/pdf/2504.04756v1>|[[代码]](<https://github.com/InhwanBae/CrowdES>)<br />- 问题：连续人群行为生成，真实感，动态模拟<br />- 方法：人群发射器模型，扩散模型，行为特征分配<br />- 效果：多样化行为，场景动态|
|📝 更新|Parametric Shadow Control for Portrait Generation in Text-to-Image Diffusion Models|参数化阴影控制用于文本到图像扩散模型中的肖像生成|Haoming Cai, Tsung-Wei Huang, Shiv Gehlot, Brandon Y. Feng, Sachin Shah, Guan-Ming Su, Christopher Metzler|<http://arxiv.org/pdf/2503.21943v2>|- 问题：阴影控制，风格多样性，资源消耗<br />- 方法：Shadow Director，参数化阴影，合成数据训练<br />- 效果：直觉控制，风格一致性，资源友好|
|🆕 发布|TactileNet: Bridging the Accessibility Gap with AI-Generated Tactile Graphics for Individuals with Vision Impairment|air 触觉网：利用人工智能生成的触觉图形弥合视障人士的可用性差距|Adnan Khan, Alireza Choubineh, Mai A. Shaaban, Abbas Akkasi, Majid Komeili|<http://arxiv.org/pdf/2504.04722v1>|- 问题：视力障碍者，触觉图形，需求，传统方法<br />- 方法：TactileNet，Stable Diffusion，LoRA，DreamBooth<br />- 效果：高保真，标准合规，可扩展|
|📝 更新|AR-1-to-3: Single Image to Consistent 3D Object Generation via Next-View Prediction|AR-1-to-3：通过下一视角预测实现单图到一致3D物体生成|Xuying Zhang, Yupeng Zhou, Kai Wang, Yikai Wang, Zhen Li, Xiuli Shao, Daquan Zhou, Qibin Hou .etc.|<http://arxiv.org/pdf/2503.12929v2>|- 问题：视图一致性，3D几何，纹理质量<br />- 方法：扩散模型，次视图预测，Stacked-LE，LSTM-GE<br />- 效果：一致性提升，高保真3D|
|📝 更新|Adversarially Domain-adaptive Latent Diffusion for Unsupervised Semantic Segmentation|对抗性领域自适应潜在扩散用于无监督语义分割|Jongmin Yu, Zhongtian Sun, Chen Bene Chi, Jinhong Yang, Shan Luo|<http://arxiv.org/pdf/2412.16859v2>|- 问题：无监督语义分割，领域自适应，虚拟-真实差异<br />- 方法：潜在扩散模型，对抗学习，跨域特征对齐<br />- 效果：mIoU提升，优于现有方法|


### 自回归模型 (Autoregressive Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|One-Minute Video Generation with Test-Time Training|一分钟视频生成：测试时训练|Karan Dalal, Daniel Koceja, Gashon Hussein, Jiarui Xu, Yue Zhao, Youjin Song, Shihao Han, Ka Chun Cheung .etc.|<http://arxiv.org/pdf/2504.05298v1>|[[代码]](<https://test-time-training.github.io/video-dit>)<br />- 问题：视频生成，长上下文，复杂故事<br />- 方法：Test-Time Training，Mamba层，Transformer<br />- 效果：视频连贯性，复杂故事，性能提升|
|📝 更新|FastVAR: Linear Visual Autoregressive Modeling via Cached Token Pruning|快速VAR：通过缓存令牌剪枝的线性视觉自回归建模|Hang Guo, Yawei Li, Taolin Zhang, Jiangshan Wang, Tao Dai, Shu-Tao Xia, Luca Benini|<http://arxiv.org/pdf/2503.23367v2>|[[代码]](<https://github.com/csguoh/FastVAR.>)<br />- 问题：VAR模型，计算复杂度高，分辨率扩展<br />- 方法：缓存token剪枝，线性模型，零样本生成<br />- 效果：加速2.7倍，性能下降<1%，高分辨率生成|


### 生成对抗网络 (GANs)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Video-Bench: Human-Aligned Video Generation Benchmark|视频基准：人机协同视频生成基准|Hui Han, Siyuan Li, Jiaqi Chen, Yiwen Yuan, Yuling Wu, Chak Tou Leong, Hanwen Du, Junchen Fu .etc.|<http://arxiv.org/pdf/2504.04907v1>|- 问题：视频生成评估，人类期望，质量指标<br />- 方法：Video-Bench，MLLM，few-shot scoring<br />- 效果：人类偏好，客观准确|
|📝 更新|Leveraging GANs For Active Appearance Models Optimized Model Fitting|利用生成对抗网络优化主动外观模型模型拟合|Anurag Awasthi|<http://arxiv.org/pdf/2501.11218v3>|- 问题：AAM线性假设，复杂变化，拟合困难<br />- 方法：GAN-augmented AAM，U-Net，PatchGAN<br />- 效果：高精度，快收敛|
|🆕 发布|3DM-WeConvene: Learned Image Compression with 3D Multi-Level Wavelet-Domain Convolution and Entropy Model|3DM-WeConvene：基于3D多级小波域卷积和熵模型的图像压缩学习|Haisheng Fu, Jie Liang, Feng Liang, Zhenman Fang, Guohe Zhang, Jingning Han|<http://arxiv.org/pdf/2504.04658v1>|- 问题：图像压缩，频率域相关性，空间域相关性<br />- 方法：3D多级小波变换，3DM-WeConv层，3DWeChARM模型<br />- 效果：R-D性能提升，计算复杂度降低|


## 多模态学习 (Multimodal Learning)


### 视觉语言模型 (Vision-Language Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|URECA: Unique Region Caption Anything|独特区域描述任何事物：URECA|Sangbeom Lim, Junwan Kim, Heeji Yoon, Jaewoo Jung, Seungryong Kim|<http://arxiv.org/pdf/2504.05305v1>|- 问题：区域描述独特性，多粒度，数据集<br />- 方法：URECA数据集，MLLMs，动态掩码建模<br />- 效果：最佳性能，泛化能力强|
|🆕 发布|SmolVLM: Redefining small and efficient multimodal models|SmolVLM：重新定义小型高效的多模态模型|Andrés Marafioti, Orr Zohar, Miquel Farré, Merve Noyan, Elie Bakouch, Pedro Cuenca, Cyril Zakka, Loubna Ben Allal .etc.|<http://arxiv.org/pdf/2504.05299v1>|- 问题：大VLM资源消耗大，效率低<br />- 方法：紧凑模型，优化架构，高效分词<br />- 效果：性能提升，内存降低|
|🆕 发布|InteractVLM: 3D Interaction Reasoning from 2D Foundational Models|交互VLM：从2D基础模型进行3D交互推理|Sai Kumar Dwivedi, Dimitrije Antić, Shashank Tripathi, Omid Taheri, Cordelia Schmid, Michael J. Black, Dimitrios Tzionas|<http://arxiv.org/pdf/2504.05303v1>|- 问题：3D接触点估计，遮挡，深度模糊，形状变化<br />- 方法：Render-Localize-Lift模块，MV-Loc模型，语义联系<br />- 效果：准确估计，3D重建|
|🆕 发布|LiveVQA: Live Visual Knowledge Seeking|实时视觉知识搜索|Mingyang Fu, Yuyang Peng, Benlin Liu, Yao Wan, Dongping Chen|<http://arxiv.org/pdf/2504.05288v1>|- 问题：实时视觉知识获取，视觉问答，知识库更新<br />- 方法：自动收集数据集，合成问题，多跳问答<br />- 效果：模型性能提升，视觉推理关键|
|📝 更新|FetalCLIP: A Visual-Language Foundation Model for Fetal Ultrasound Image Analysis|胎儿CLIP：胎儿超声图像分析的可视-语言基础模型|Fadillah Maani, Numan Saeed, Tausifa Saleem, Zaid Farooq, Hussain Alasmawi, Werner Diehl, Ameera Mohammad, Gareth Waring .etc.|<http://arxiv.org/pdf/2502.14807v2>|- 问题：胎儿超声图像分析，数据稀缺，模型泛化能力差<br />- 方法：视觉语言基础模型，多模态学习，大规模数据集<br />- 效果：性能提升，泛化能力强|
|🆕 发布|Explaining Low Perception Model Competency with High-Competency Counterfactuals|用高能力反事实解释低感知模型能力|Sara Pohland, Claire Tomlin|<http://arxiv.org/pdf/2504.05254v1>|- 问题：模型不确定性，低模型竞争力，解释性<br />- 方法：高竞争力反事实图像，IGD，FGD，Reco，LGD，LNN<br />- 效果：准确解释，语言模型，解释能力增强|
|🆕 发布|Mapping biodiversity at very-high resolution in Europe|欧洲高分辨率生物多样性映射|César Leblanc, Lukas Picek, Benjamin Deneu, Pierre Bonnet, Maximilien Servajean, Rémi Palard, Alexis Joly|<http://arxiv.org/pdf/2504.05231v1>|- 问题：高分辨率，生物多样性，欧洲，物种分布<br />- 方法：深度SDM，多模态模型，Pl@ntBERT<br />- 效果：精细生态洞察，大陆尺度地图|
|📝 更新|Spider: Any-to-Many Multimodal LLM|蜘蛛：任意到多模态的多模态大型语言模型|Jinxiang Lai, Jie Zhang, Jun Liu, Jian Li, Xiaocheng Lu, Song Guo|<http://arxiv.org/pdf/2411.09439v2>|[[代码]](<https://github.com/Layjins/Spider>)<br />- 问题：Any-to-Any MLLM，模态生成限制<br />- 方法：Spider框架，X-to-Xs能力，TMM数据集<br />- 效果：高效AMMG，多模态内容生成|
|📝 更新|MME-Unify: A Comprehensive Benchmark for Unified Multimodal Understanding and Generation Models|MME-Unify：统一多模态理解和生成模型的全面基准|Wulin Xie, Yi-Fan Zhang, Chaoyou Fu, Yang Shi, Bingyan Nie, Hongkai Chen, Zhang Zhang, Liang Wang .etc.|<http://arxiv.org/pdf/2504.03641v2>|[[代码]](<https://mme-unify.github.io/.>)<br />- 问题：U-MLLMs 评估，标准化，混合模态<br />- 方法：综合评估框架，新任务，模型基准<br />- 效果：性能差距，模型能力|
|🆕 发布|The 1st Solution for 4th PVUW MeViS Challenge: Unleashing the Potential of Large Multimodal Models for Referring Video Segmentation|第一版第四届PVUW MeViS挑战解决方案：释放大型多模态模型在指视频段分割中的潜力|Hao Fang, Runmin Cong, Xiankai Lu, Zhiyang Chen, Wei Zhang|<http://arxiv.org/pdf/2504.05178v1>|- 问题：运动表达视频分割，多模态模型，Referring Video Segmentation<br />- 方法：Sa2VA，均匀采样，多模型集成<br />- 效果：61.98% J&F，CVPR 2025 第一名|
|🆕 发布|Towards Visual Text Grounding of Multimodal Large Language Model|迈向多模态大型语言模型的视觉文本定位|Ming Li, Ruiyi Zhang, Jian Chen, Jiuxiang Gu, Yufan Zhou, Franck Dernoncourt, Wanrong Zhu, Tianyi Zhou .etc.|<http://arxiv.org/pdf/2504.04974v1>|- 问题：视觉文本定位，文档图像，MLLMs，基准测试<br />- 方法：TRIG任务，OCR-LLM交互，合成数据集<br />- 效果：能力提升，空间推理增强|
|🆕 发布|RS-RAG: Bridging Remote Sensing Imagery and Comprehensive Knowledge with a Multi-Modal Dataset and Retrieval-Augmented Generation Model|RS-RAG：通过多模态数据集和检索增强生成模型连接遥感影像与综合知识|Congcong Wen, Yiting Lin, Xiaokang Qu, Nan Li, Yong Liao, Hui Lin, Xiang Li|<http://arxiv.org/pdf/2504.04988v1>|- 问题：远程感知VLM，缺乏外部知识，语义推理受限<br />- 方法：多模态知识库，RS-RAG框架，知识检索与生成<br />- 效果：语义理解提升，性能超越基线|
|📝 更新|SpaceVLLM: Endowing Multimodal Large Language Model with Spatio-Temporal Video Grounding Capability|空间VLLM：赋予多模态大型语言模型时空视频定位能力|Jiankang Wang, Zhihan zhang, Zhihang Liu, Yang Li, Jiannan Ge, Hongtao Xie, Yongdong Zhang|<http://arxiv.org/pdf/2503.13983v2>|- 问题：时空视频定位，信息提取，视觉映射<br />- 方法：时空感知查询，空间解码器，Uni-STG数据集<br />- 效果：SOTA性能，多任务覆盖|
|🆕 发布|A Taxonomy of Self-Handover|自我切换的分类法|Naoki Wake, Atsushi Kanehira, Kazuhiro Sasabuchi, Jun Takamatsu, Katsushi Ikeuchi|<http://arxiv.org/pdf/2504.04939v1>|- 问题：自我交接，双手协调，动作策略<br />- 方法：系统分类，手动标注，视觉语言模型<br />- 效果：协调性，任务过渡|
|📝 更新|VidCtx: Context-aware Video Question Answering with Image Models|视频上下文感知图像模型辅助视频问答|Andreas Goulas, Vasileios Mezaris, Ioannis Patras|<http://arxiv.org/pdf/2412.17415v2>|[[代码]](<https://github.com/IDT-ITI/VidCtx.>)<br />- 问题：视频问答，计算限制，视觉信息缺失<br />- 方法：VidCtx框架，多模态模型，上下文描述<br />- 效果：性能提升，可扩展性|
|📝 更新|Towards Understanding How Knowledge Evolves in Large Vision-Language Models|迈向理解大型视觉-语言模型中知识演化的路径|Sudong Wang, Yunjian Zhang, Yao Zhu, Jianing Li, Zizhe Wang, Yanwei Liu, Xiangyang Ji|<http://arxiv.org/pdf/2504.02862v2>|[[代码]](<https://github.com/XIAO4579/Vlm-interpretability.>)<br />- 问题：LVLMs知识演化，内部机制，能力提升<br />- 方法：知识分析策略，多模态知识演化，关键节点识别<br />- 效果：演化轨迹揭示，机制理解|
|📝 更新|Open-Vocabulary Action Localization with Iterative Visual Prompting|开放词汇动作定位与迭代视觉提示|Naoki Wake, Atsushi Kanehira, Kazuhiro Sasabuchi, Jun Takamatsu, Katsushi Ikeuchi|<http://arxiv.org/pdf/2408.17422v5>|[[代码]](<https://microsoft.github.io/VLM-Video-Action-Localization>)<br />- 问题：视频动作定位，标注成本高，VLMs适用性<br />- 方法：迭代视觉提示，VLMs，采样窗口<br />- 效果：零样本定位，性能相当|
|🆕 发布|SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models|SCAM：多模态基础模型的真实世界印刷鲁棒性评估|Justus Westerhoff, Erblina Purellku, Jakob Hackstein, Leo Pinetzki, Lorenz Hufe|<http://arxiv.org/pdf/2504.04893v1>|[[代码]](<https://github.com/Bliss-e-V/SCAM.>)<br />- 问题：字体攻击，多模态模型，数据集限制<br />- 方法：SCAM数据集，基准测试，VLMs评估<br />- 效果：性能下降，模型易受攻击|
|📝 更新|MSCPT: Few-shot Whole Slide Image Classification with Multi-scale and Context-focused Prompt Tuning|MSCPT：基于多尺度与上下文聚焦提示调优的少样本全切片图像分类|Minghao Han, Linhao Qu, Dingkang Yang, Xukun Zhang, Xiaoying Wang, Lihua Zhang|<http://arxiv.org/pdf/2408.11505v2>|[[代码]](<https://github.com/Hanminghao/MSCPT.>)<br />- 问题：弱监督，WSI分类，数据稀缺，多尺度，上下文<br />- 方法：多尺度提示调整，图提示调整，非参数实例聚合<br />- 效果：性能强，公开代码|
|📝 更新|Enhancing the Reasoning Ability of Multimodal Large Language Models via Mixed Preference Optimization|通过混合偏好优化增强多模态大型语言模型的推理能力|Weiyun Wang, Zhe Chen, Wenhai Wang, Yue Cao, Yangzhou Liu, Zhangwei Gao, Jinguo Zhu, Xizhou Zhu .etc.|<http://arxiv.org/pdf/2411.10442v2>|- 问题：分布偏移，多模态推理，CoT性能<br />- 方法：偏好优化，MMPR数据集，MPO方法<br />- 效果：性能提升，InternVL2-8B-MPO|
|📝 更新|Is Temporal Prompting All We Need For Limited Labeled Action Recognition?|我们需要时间提示就足够用于有限标注的动作识别了吗？|Shreyank N Gowda, Boyan Gao, Xiao Gu, Xiaobo Jin|<http://arxiv.org/pdf/2504.01890v2>|- 问题：视频理解，数据依赖，时序建模<br />- 方法：TP-CLIP，时序提示，CLIP架构<br />- 效果：参数少，效率高，性能优|
|📝 更新|Interpretable Bilingual Multimodal Large Language Model for Diverse Biomedical Tasks|可解释的双语多模态大型语言模型用于多样化的生物医学任务|Lehan Wang, Haonan Wang, Honglong Yang, Jiaji Mao, Zehong Yang, Jun Shen, Xiaomeng Li|<http://arxiv.org/pdf/2410.18387v4>|- 问题：区域识别，模型可解释性，多模态任务<br />- 方法：区域感知，双语模型，大规模数据集<br />- 效果：最佳性能，多任务处理，可解释性提升|
|🆕 发布|OrderChain: A General Prompting Paradigm to Improve Ordinal Understanding Ability of MLLM|OrderChain：一种提升多模态语言模型序数理解能力的通用提示范式|Jinhong Wang, Shuo Tong, Jian liu, Dongqi Tang, Weiqiang Wang, Wentong Li, Hongxia Xu, Danny Chen .etc.|<http://arxiv.org/pdf/2504.04801v1>|- 问题：MLLMs，Ordinal Regression，性能挑战<br />- 方法：OrderChain，prompting paradigm，specificity modeling<br />- 效果：准确率提升，超越SOTA|
|🆕 发布|OCC-MLLM-CoT-Alpha: Towards Multi-stage Occlusion Recognition Based on Large Language Models via 3D-Aware Supervision and Chain-of-Thoughts Guidance|OCC-MLLM-CoT-Alpha：基于3D感知监督和思维链引导的面向多阶段遮挡识别的大型语言模型|Chaoyi Wang, Baoqing Li, Xinhan Di|<http://arxiv.org/pdf/2504.04781v1>|- 问题：遮挡物体识别，视觉语言模型，多模态<br />- 方法：3D感知监督，思维链引导，多模态大模型<br />- 效果：决策分数提升，性能改善|
|📝 更新|EarthDial: Turning Multi-sensory Earth Observations to Interactive Dialogues|地球指南针：将多感官地球观测转化为交互式对话|Sagar Soni, Akshay Dudhane, Hiyam Debary, Mustansar Fiaz, Muhammad Akhtar Munir, Muhammad Sohail Danish, Paolo Fraccaro, Campbell D Watson .etc.|<http://arxiv.org/pdf/2412.15190v2>|[[代码]](<https://github.com/hiyamdebary/EarthDial.>)<br />- 问题：遥感数据，VLMs性能差，固定分辨率，传感器模态少<br />- 方法：EarthDial，多模态数据，指令微调，双时相分析<br />- 效果：超越现有模型，泛化能力强|
|🆕 发布|AnyArtisticGlyph: Multilingual Controllable Artistic Glyph Generation|任意艺术符号：多语言可控艺术符号生成|Xiongbo Lu, Yaxiong Chen, Shengwu Xiong|<http://arxiv.org/pdf/2504.04743v1>|[[代码]](<https://github.com/jiean001/AnyArtisticGlyph>)<br />- 问题：AGIG，可控生成，细节缺陷<br />- 方法：扩散模型，多语言，CLIP模型<br />- 效果：自然图像，最佳性能|
|🆕 发布|Enhancing Compositional Reasoning in Vision-Language Models with Synthetic Preference Data|利用合成偏好数据增强视觉-语言模型中的组合推理|Samarth Mishra, Kate Saenko, Venkatesh Saligrama|<http://arxiv.org/pdf/2504.04740v1>|[[代码]](<https://github.com/samarth4149/SCRAMBLe.>)<br />- 问题：多模态大语言模型，组合推理困难<br />- 方法：合成偏好数据，偏好学习，SCRAMBLe<br />- 效果：性能提升，Winoground指标改善|
|📝 更新|Do LLMs Understand Visual Anomalies? Uncovering LLM's Capabilities in Zero-shot Anomaly Detection|LLMs 是否理解视觉异常？揭示LLM在零样本异常检测中的能力|Jiaqi Zhu, Shaofeng Cai, Fang Deng, Beng Chin Ooi, Junran Wu|<http://arxiv.org/pdf/2404.09654v3>|- 问题：零样本异常检测，语义模糊，局部定位<br />- 方法：运行时提示自适应，上下文评分，细粒度对齐<br />- 效果：性能提升，MVTec 12.1%，VisA 8.9%|
|📝 更新|NuScenes-SpatialQA: A Spatial Understanding and Reasoning Benchmark for Vision-Language Models in Autonomous Driving|NuScenes-SpatialQA：自动驾驶中视觉-语言模型的时空理解和推理基准|Kexin Tian, Jingrui Mao, Yunlong Zhang, Jiwan Jiang, Yang Zhou, Zhengzhong Tu|<http://arxiv.org/pdf/2504.03164v2>|- 问题：VLMs 空间理解，推理能力，驾驶场景<br />- 方法：NuScenes-SpatialQA，3D 场景图，QA 生成<br />- 效果：空间能力评估，实验验证|
|📝 更新|Safeguarding Vision-Language Models: Mitigating Vulnerabilities to Gaussian Noise in Perturbation-based Attacks|保障视觉-语言模型安全：减轻基于扰动攻击中对高斯噪声的脆弱性|Jiawei Wang, Yushen Zuo, Yuanjun Chai, Zhendong Liu, Yicheng Fu, Yichun Feng, Kin-Man Lam|<http://arxiv.org/pdf/2504.01308v2>|[[代码]](<https://github.com/JarvisUSTC/DiffPure-RobustVLM.>)<br />- 问题：VLM易受攻击，噪声处理不足<br />- 方法：Robust-VLGuard，DiffPure-VLM，噪声增强微调<br />- 效果：攻击成功率降低，功能保持|
|🆕 发布|LEO-MINI: An Efficient Multimodal Large Language Model using Conditional Token Reduction and Mixture of Multi-Modal Experts|LEO-MINI：一种高效的基于条件标记减少和多模态专家混合的多模态大型语言模型|Yimu Wang, Mozhgan Nasr Azadani, Sean Sedwards, Krzysztof Czarnecki|<http://arxiv.org/pdf/2504.04653v1>|- 问题：MLLMs视觉token冗余，效率低<br />- 方法：CoTR，MMoE，LoRA专家<br />- 效果：效率提升，推理能力增强|


### 多模态融合 (Multimodal Fusion)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SSLFusion: Scale & Space Aligned Latent Fusion Model for Multimodal 3D Object Detection|SSLFusion：用于多模态3D目标检测的尺度与空间对齐潜在融合模型|Bonan Ding, Jin Xie, Jing Nie, Jiale Cao|<http://arxiv.org/pdf/2504.05170v1>|- 问题：尺度空间信息错位，多模态特征融合，计算复杂度高<br />- 方法：尺度对齐融合，空间对齐模块，潜在跨模态融合<br />- 效果：3D AP提升，性能优于现有方法|
|🆕 发布|AsyReC: A Multimodal Graph-based Framework for Spatio-Temporal Asymmetric Dyadic Relationship Classification|AsyReC：一种基于多模态图的空间时间非对称二元关系分类框架|Wang Tang, Fethiye Irmak Dogan, Linbo Qing, Hatice Gunes|<http://arxiv.org/pdf/2504.05030v1>|[[代码]](<https://github.com/tw-repository/AsyReC.>)<br />- 问题：不对称关系，连续性，周期性，行为模式<br />- 方法：图神经网络，节点-边注意力，关系学习架构，周期时间编码<br />- 效果：性能提升，鲁棒性增强|
|📝 更新|SPIDER: A Comprehensive Multi-Organ Supervised Pathology Dataset and Baseline Models|SPIDER：一个全面的器官级监督病理学数据集和基线模型|Dmitry Nechaev, Alexey Pchelnikov, Ekaterina Ivanova|<http://arxiv.org/pdf/2503.02876v2>|[[代码]](<https://github.com/HistAI/SPIDER>)<br />- 问题：数据集，多样性，质量，标注<br />- 方法：SPIDER数据集，Hibou-L模型，注意力机制<br />- 效果：多器官，高精度，基准|
|📝 更新|Audio-visual Controlled Video Diffusion with Masked Selective State Spaces Modeling for Natural Talking Head Generation|基于掩码选择状态空间建模的视听控制视频扩散，用于自然谈话头像生成|Fa-Ting Hong, Zunnan Xu, Zixiang Zhou, Jun Zhou, Xiu Li, Qin Lin, Qinglin Lu, Dan Xu|<http://arxiv.org/pdf/2504.02542v3>|[[代码]](<https://harlanhong.github.io/publications>)<br />- 问题：多模态控制，自然生成，视频扩散<br />- 方法：多分支结构，门控机制，掩码策略<br />- 效果：自然协调，无缝集成|
|🆕 发布|SUEDE:Shared Unified Experts for Physical-Digital Face Attack Detection Enhancement|SUEDE：用于物理-数字面部攻击检测增强的共享统一专家|Zuying Xie, Changtao Miao, Ajian Liu, Jiabao Guo, Feng Li, Dan Guo, Yunfeng Diao|<http://arxiv.org/pdf/2504.04818v1>|- 问题：物理-数字人脸攻击检测，特征空间，统一框架<br />- 方法：混合专家，共享专家，路由专家，CLIP集成<br />- 效果：性能提升，优于现有方法|
|🆕 发布|Grounding 3D Object Affordance with Language Instructions, Visual Observations and Interactions|基于语言指令、视觉观察和交互的3D物体功能定位|He Zhu, Quyu Kong, Kechun Xu, Xunlong Xia, Bing Deng, Jieping Ye, Rong Xiong, Yue Wang|<http://arxiv.org/pdf/2504.04744v1>|- 问题：3D物体操作，语言指令，视觉交互<br />- 方法：LMAffordance3D，多模态融合，语义特征<br />- 效果：数据集，实验验证，效果优越|


### 跨模态对齐 (Cross-modal Alignment)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FantasyTalking: Realistic Talking Portrait Generation via Coherent Motion Synthesis|幻想对话：通过连贯运动合成实现逼真的对话肖像生成|Mengchao Wang, Qiang Wang, Fan Jiang, Yaqi Fan, Yunpeng Zhang, Yonggang Qi, Kun Zhao, Mu Xu|<http://arxiv.org/pdf/2504.04842v1>|[[代码]](<https://fantasy-amap.github.io/fantasy-talking>)<br />- 问题：静态肖像，表情，动作，背景<br />- 方法：视频扩散模型，音频视觉对齐，面部一致性<br />- 效果：高保真，连贯，可控|
|📝 更新|Autism Spectrum Disorder Classification with Interpretability in Children based on Structural MRI Features Extracted using Contrastive Variational Autoencoder|基于对比变分自编码器提取的结构MRI特征在儿童自闭症谱系障碍分类中的可解释性研究|Ruimin Ma, Ruitao Xie, Yanlin Wang, Jintao Meng, Yanjie Wei, Wenhui Xi, Yi Pan|<http://arxiv.org/pdf/2307.00976v2>|- 问题：ASD儿童早期筛查，s-MRI，数据量小，可解释性<br />- 方法：CVAE，对比学习，迁移学习<br />- 效果：分类准确，神经解剖学解释|


## 目标检测识别 (Object Detection & Recognition)


### 二维检测 (2D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AnomalousNet: A Hybrid Approach with Attention U-Nets and Change Point Detection for Accurate Characterization of Anomalous Diffusion in Video Data|异常扩散视频数据中准确表征的注意力U-Nets与变化点检测的混合方法：AnomalousNet|Yusef Ahsini, Marc Escoto, J. Alberto Conejero|<http://arxiv.org/pdf/2504.05271v1>|- 问题：异常扩散，视频数据分析，轨迹估计，噪声，变化点检测<br />- 方法：粒子跟踪，注意力U-Net，变化点检测<br />- 效果：高精度，状态识别|
|🆕 发布|Contour Integration Underlies Human-Like Vision|人类视觉背后的轮廓整合|Ben Lonnqvist, Elsa Scialom, Abdulkadir Gokce, Zehra Merchant, Michael H. Herzog, Martin Schrimpf|<http://arxiv.org/pdf/2504.05253v1>|- 问题：深度学习模型，泛化能力，轮廓整合<br />- 方法：实验设计，对象识别，碎片化水平<br />- 效果：人类表现，模型性能，集成偏差|
|🆕 发布|LDGNet: A Lightweight Difference Guiding Network for Remote Sensing Change Detection|LDGNet：一种用于遥感变化检测的轻量级差异引导网络|Chenfeng Xu|<http://arxiv.org/pdf/2504.05062v1>|- 问题：轻量级，遥感变化检测，计算成本<br />- 方法：差异引导模块，差异感知动态融合，视觉状态空间模型<br />- 效果：性能提升，参数少，计算量低|
|📝 更新|MultiTSF: Transformer-based Sensor Fusion for Human-Centric Multi-view and Multi-modal Action Recognition|多视角多模态动作识别的人中心传感器融合的Transformer模型：MultiTSF|Trung Thanh Nguyen, Yasutomo Kawanishi, Vijay John, Takahiro Komamizu, Ichiro Ide|<http://arxiv.org/pdf/2504.02279v2>|- 问题：多模态多视角，动作识别，环境条件，传感器同步，细粒度标注<br />- 方法：Transformer，动态建模，时空依赖，人类检测模块<br />- 效果：超越，视频序列，帧级|
|📝 更新|MultiEYE: Dataset and Benchmark for OCT-Enhanced Retinal Disease Recognition from Fundus Images|多眼：基于OCT增强的视网膜疾病从眼底图像识别的数据集和基准|Lehan Wang, Chongchong Qi, Chubin Ou, Lin An, Mei Jin, Xiangbin Kong, Xiaomeng Li|<http://arxiv.org/pdf/2412.09402v2>|[[代码]](<https://github.com/xmed-lab/MultiEYE.>)<br />- 问题：多模态学习，临床应用，数据配对<br />- 方法：OCT增强，多类疾病诊断，OCT-CoDA<br />- 效果：性能提升，可解释性|
|📝 更新|Prompting the Unseen: Detecting Hidden Backdoors in Black-Box Models|提示未见：检测黑盒模型中的隐藏后门|Zi-Xuan Huang, Jia-Wei Chen, Zhi-Peng Zhang, Chia-Mu Yu|<http://arxiv.org/pdf/2411.09540v2>|- 问题：黑盒模型，后门检测，视觉提示<br />- 方法：BProm，分类子空间不一致性，低分类精度<br />- 效果：有效性，黑盒检测|
|🆕 发布|From Specificity to Generality: Revisiting Generalizable Artifacts in Detecting Face Deepfakes|从特异性到泛化：重新审视检测人脸深度伪造的泛化性成果|Long Ma, Zhiyuan Yan, Yize Chen, Jin Xu, Qinglang Guo, Hu Huang, Yong Liao, Hui Lin|<http://arxiv.org/pdf/2504.04827v1>|- 问题：深伪检测，通用框架，伪造痕迹<br />- 方法：伪假样本，人脸不一致，上采样<br />- 效果：泛化能力强，分类器表现好|
|🆕 发布|Enhancing Leaf Disease Classification Using GAT-GCN Hybrid Model|利用GAT-GCN混合模型增强叶片病害分类|Shyam Sundhar, Riya Sharma, Priyansh Maheshwari, Suvidha Rupesh Kumar, T. Sunil Kumar|<http://arxiv.org/pdf/2504.04764v1>|- 问题：叶病分类，农业病害，精准识别<br />- 方法：GAT-GCN混合模型，超像素分割，边缘增强<br />- 效果：高精度，高召回率，F1-score高|
|🆕 发布|Bottom-Up Scattering Information Perception Network for SAR target recognition|自下而上散射信息感知网络用于合成孔径雷达目标识别|Chenxi Zhao, Daochang Wang, Siqian Zhang, Gangyao Kuang|<http://arxiv.org/pdf/2504.04780v1>|- 问题：SAR图像识别，散射信息感知不足<br />- 方法：局部散射感知器，无监督散射特征提取，知识聚合<br />- 效果：可解释性提升，识别性能增强|
|🆕 发布|SapiensID: Foundation for Human Recognition|人类识别的基础：SapiensID|Minchul Kim, Dingqiang Ye, Yiyang Su, Feng Liu, Xiaoming Liu|<http://arxiv.org/pdf/2504.04708v1>|- 问题：多模态识别，模型分离，场景多样性<br />- 方法：Retina Patch，MRM，SAH，WebBody4M<br />- 效果：性能提升，跨场景泛化|
|📝 更新|Detecting AI-Generated Video via Frame Consistency|通过帧一致性检测AI生成视频|Long Ma, Zhiyuan Yan, Qinglang Guo, Yong Liao, Haiyang Yu, Pengyuan Zhou|<http://arxiv.org/pdf/2402.02085v7>|[[代码]](<https://github.com/wuwuwuyue/DeCoF.>)<br />- 问题：AI生成视频检测，开源数据集，检测方法<br />- 方法：开源数据集，DeCoF模型，帧一致性<br />- 效果：通用性，检测效果|


### 三维检测 (3D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|3D Universal Lesion Detection and Tagging in CT with Self-Training|3D基于自训练的CT图像中通用病变检测与标注|Jared Frazier, Tejas Sudharshan Mathai, Jianfei Liu, Angshuman Paul, Ronald M. Summers|<http://arxiv.org/pdf/2504.05201v1>|- 问题：3D病变检测，标签，数据不平衡<br />- 方法：自训练，VFNet，3D扩展<br />- 效果：高灵敏度，3D检测|
|🆕 发布|Correcting Class Imbalances with Self-Training for Improved Universal Lesion Detection and Tagging|利用自训练纠正类别不平衡以提高通用病变检测和标记|Alexander Shieh, Tejas Sudharshan Mathai, Jianfei Liu, Angshuman Paul, Ronald M. Summers|<http://arxiv.org/pdf/2504.05207v1>|- 问题：数据不平衡，标注不足，ULDT<br />- 方法：自训练，阈值策略，数据增强<br />- 效果：敏感度提升，泛化能力增强|
|🆕 发布|PvNeXt: Rethinking Network Design and Temporal Motion for Point Cloud Video Recognition|PvNeXt：重新思考网络设计和点云视频识别中的时间运动|Jie Wang, Tingfa Xu, Lihe Ding, Xinjie Zhang, Long Bai, Jianan Li|<http://arxiv.org/pdf/2504.05075v1>|- 问题：点云视频识别，计算冗余，时间动态<br />- 方法：PvNeXt，个性化查询，运动模仿器<br />- 效果：效率提升，效果显著|
|📝 更新|ZFusion: An Effective Fuser of Camera and 4D Radar for 3D Object Perception in Autonomous Driving|ZFusion：自动驾驶中用于3D物体感知的相机与4D雷达的有效融合器|Sheng Yang, Tong Zhan, Shichen Qiao, Jicheng Gong, Qing Yang, Jian Wang, Yanfeng Lu|<http://arxiv.org/pdf/2504.03438v2>|- 问题：3D物体感知，雷达点云稀疏，融合<br />- 方法：FP-DDCA fuser，特征金字塔，Transformer<br />- 效果：mAP提升，性能接近LiDAR|
|🆕 发布|Inverse++: Vision-Centric 3D Semantic Occupancy Prediction Assisted with 3D Object Detection|Inverse++：基于视觉的3D语义占用预测及其辅助3D物体检测|Zhenxing Ming, Julie Stephany Berrio, Mao Shan, Stewart Worrall|<http://arxiv.org/pdf/2504.04732v1>|[[代码]](<https://github.com/DanielMing123/Inverse>)<br />- 问题：3D语义占用预测，自动驾驶，3D物体检测<br />- 方法：多任务学习，3D监督信号，辅助分支<br />- 效果：IoU 31.73%，mIoU 20.91%，VRU检测|


### 多目标跟踪 (Multi-object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Strong Baseline: Multi-UAV Tracking via YOLOv12 with BoT-SORT-ReID|强基线：基于YOLOv12和BoT-SORT-ReID的多无人机跟踪|Yu-Hsi Chen|<http://arxiv.org/pdf/2503.17237v2>|[[代码]](<https://github.com/wish44165/YOLOv12-BoT-SORT-ReID>)<br />- 问题：多UAV跟踪，红外视频，低对比度，小目标<br />- 方法：YOLOv12，BoT-SORT，ReID，定制训练<br />- 效果：强基线，竞争性能|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Classification of ADHD and Healthy Children Using EEG Based Multi-Band Spatial Features Enhancement|基于多频带空间特征增强的ADHD儿童与健康儿童分类|Md Bayazid Hossain, Md Anwarul Islam Himel, Md Abdur Rahim, Shabbir Mahmood, Abu Saleh Musa Miah, Jungpil Shin|<http://arxiv.org/pdf/2504.04664v1>|- 问题：ADHD儿童分类，EEG信号，诊断工具<br />- 方法：多频带特征提取，SVM分类，RBF核<br />- 效果：高准确率，高鲁棒性|


## 三维重建 (3D Reconstruction)


### 多视图重建 (Multi-view Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Texture2LoD3: Enabling LoD3 Building Reconstruction With Panoramic Images|纹理到LoD3：利用全景图像实现LoD3建筑重建|Wenzhao Tang, Weihang Li, Xiucheng Liang, Olaf Wysocki, Filip Biljecki, Christoph Holst, Boris Jutzi|<http://arxiv.org/pdf/2504.05249v1>|[[代码]](<https://wenzhaotang.github.io/Texture2LoD3>)<br />- 问题：LoD3建筑重建，对象建模，纹理，低多边形<br />- 方法：3D模型先验，全景图像，分割，ReLoD3数据集<br />- 效果：精度提升，成本降低|
|📝 更新|Factored-NeuS: Reconstructing Surfaces, Illumination, and Materials of Possibly Glossy Objects|因子NeuS：重建可能具有光泽物体的表面、光照和材质|Yue Fan, Ningjing Fan, Ivan Skorokhodov, Oleg Voynov, Savva Ignatyev, Evgeny Burnaev, Peter Wonka, Yiqun Wang|<http://arxiv.org/pdf/2305.17929v2>|- 问题：表面，材质，光照，多视角，图像重建<br />- 方法：逆渲染，SDF，辐射场，可学习映射<br />- 效果：无额外数据，超越现有技术|
|🆕 发布|CADCrafter: Generating Computer-Aided Design Models from Unconstrained Images|CADCrafter：从非约束图像生成计算机辅助设计模型|Cheng Chen, Jiacheng Wei, Tianrun Chen, Chi Zhang, Xiaofeng Yang, Shangzhan Zhang, Bingchen Yang, Chuan-Sheng Foo .etc.|<http://arxiv.org/pdf/2504.04753v1>|- 问题：CAD模型生成，3D扫描，后处理，用户友好<br />- 方法：CADCrafter，几何编码器，DPO优化<br />- 效果：泛化能力强，处理真实图像|


### 神经隐式重建 (Neural Implicit Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Climplicit: Climatic Implicit Embeddings for Global Ecological Tasks|Climplicit：用于全球生态任务的气候隐式嵌入|Johannes Dollinger, Damien Robert, Elena Plekhanova, Lukas Drees, Jan Dirk Wegner|<http://arxiv.org/pdf/2504.05089v1>|- 问题：气候数据，深度学习，存储，计算，技术<br />- 方法：Climplicit，时空编码，隐式表示<br />- 效果：效率提升，性能优越|
|🆕 发布|Exploring Kernel Transformations for Implicit Neural Representations|探索隐式神经网络表示的核变换|Sheng Zheng, Chaoning Zhang, Dongshen Han, Fachrina Dewi Puspitasari, Xinhong Hao, Yang Yang, Heng Tao Shen|<http://arxiv.org/pdf/2504.04728v1>|- 问题：INR，输入/输出核变换，模型内部组件<br />- 方法：不变模型，尺度与平移组合，深度与归一化视角<br />- 效果：性能提升，计算开销低|


## 神经渲染 (Neural Rendering)


### 可控渲染 (Controllable Rendering)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Let it Snow! Animating Static Gaussian Scenes With Dynamic Weather Effects|让它下雪！使用动态天气效果动画静态高斯场景|Gal Fiebelman, Hadar Averbuch-Elor, Sagie Benaim|<http://arxiv.org/pdf/2504.05296v1>|- 问题：静态场景动态元素，物理交互，渲染挑战<br />- 方法：Gaussian Splatting，粒子模拟，MPM<br />- 效果：视觉质量，物理 realism|
|🆕 发布|PanoDreamer: Consistent Text to 360-Degree Scene Generation|PanoDreamer：一致性的文本到360度场景生成|Zhexiao Xiong, Zhang Chen, Zhong Li, Yi Xu, Nathan Jacobs|<http://arxiv.org/pdf/2504.05152v1>|- 问题：低质量纹理，不一致3D结构，超视场生成<br />- 方法：大语言模型，warp-refine流程，3D高斯分层<br />- 效果：高质量，几何一致|
|📝 更新|RNG: Relightable Neural Gaussians|RNG：可重光照的神经网络高斯分布|Jiahui Fan, Fujun Luan, Jian Yang, Miloš Hašan, Beibei Wang|<http://arxiv.org/pdf/2409.19702v5>|- 问题：3DGS，光照固定，重光照，形状模糊<br />- 方法：RNG，条件辐射，阴影提示，深度细化网络<br />- 效果：训练快，渲染快，阴影质量高|


### 神经辐射场 (Neural Radiance Fields)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Embracing Dynamics: Dynamics-aware 4D Gaussian Splatting SLAM|拥抱动态：动态感知4D高斯分层SLAM|Zhicong Sun, Jacqueline Lo, Jinxing Hu|<http://arxiv.org/pdf/2504.04844v1>|- 问题：动态场景，SLAM，位姿漂移，地图重建<br />- 方法：4D Gaussian Splatting，动态感知，InfoModule<br />- 效果：高精度，高可靠性|
|📝 更新|LeanGaussian: Breaking Pixel or Point Cloud Correspondence in Modeling 3D Gaussians|LeanGaussian：在建模3D高斯时打破像素或点云对应|Jiamin Wu, Kenkun Liu, Han Gao, Xiaoke Jiang, Lei Zhang|<http://arxiv.org/pdf/2404.16323v3>|[[代码]](<https://github.com/jwubz123/LeanGaussian.>)<br />- 问题：Gaussian splatting，对应冗余，资源浪费<br />- 方法：LeanGaussian，3D Gaussian ellipsoid，变形Transformer<br />- 效果：PSNR提升，速度提升|
|📝 更新|ARC-NeRF: Area Ray Casting for Broader Unseen View Coverage in Few-shot Object Rendering|ARC-NeRF：基于区域光线追踪的少样本对象渲染中更广泛的未见视图覆盖|Seunghyeon Seo, Yeonjin Chang, Jayeon Yoo, Seungwoo Lee, Hojun Lee, Nojun Kwak|<http://arxiv.org/pdf/2403.10906v2>|- 问题：NeRF渲染，多视角，细节丢失<br />- 方法：Area Ray Casting，自适应正则化，亮度一致性<br />- 效果：细节丰富，渲染准确|
|🆕 发布|DeclutterNeRF: Generative-Free 3D Scene Recovery for Occlusion Removal|去杂NeRF：无生成式3D场景恢复以消除遮挡|Wanzhou Liu, Zhexiao Xiong, Xinyu Li, Nathan Jacobs|<http://arxiv.org/pdf/2504.04679v1>|- 问题：遮挡去除，场景细节，生成先验，数据集，3D场景<br />- 方法：DeclutterSet，DeclutterNeRF，多视图优化，遮挡退火正则化，结构相似度损失<br />- 效果：无生成先验，高质量，无伪影|


## 定位与映射 (Localization & Mapping)


### 位姿估计 (Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction|双PM：用于3D形状和姿态重建的双重姿态-规范点图|Ben Kaye, Tomas Jakab, Shangzhe Wu, Christian Rupprecht, Andrea Vedaldi|<http://arxiv.org/pdf/2412.04464v4>|- 问题：3D形状和姿态重建，变形物体<br />- 方法：DualPM，点图，模态重建<br />- 效果：性能提升，泛化能力强|
|🆕 发布|MotionPRO: Exploring the Role of Pressure in Human MoCap and Beyond|运动PRO：探索压力在人体动作捕捉及其应用中的作用|Shenghao Ren, Yi Lu, Jiayi Huang, Jiayi Zhao, He Zhang, Tao Yu, Qiu Shen, Xun Cao|<http://arxiv.org/pdf/2504.05046v1>|[[代码]](<https://nju-cite-mocaphumanoid.github.io/MotionPRO>)<br />- 问题：MoCap，物理合理性，轨迹精度<br />- 方法：压力信号，数据集，网络架构<br />- 效果：性能提升，虚拟人驱动|
|📝 更新|Less Biased Noise Scale Estimation for Threshold-Robust RANSAC|更少偏差的噪声尺度估计用于阈值鲁棒的RANSAC|Johan Edstedt|<http://arxiv.org/pdf/2503.13433v2>|[[代码]](<https://github.com/Parskatt/simfitpp>)<br />- 问题：RANSAC阈值估计，噪声尺度估计，偏差<br />- 方法：SIMFIT改进，多对扩展，阈值过滤<br />- 效果：鲁棒性，性能提升|


### 视觉SLAM (Visual SLAM)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Stereo-LiDAR Fusion by Semi-Global Matching With Discrete Disparity-Matching Cost and Semidensification|基于离散视差匹配成本和半密化的半全局匹配立体激光雷达融合|Yasuhiro Yao, Ryoichi Ishikawa, Takeshi Oishi|<http://arxiv.org/pdf/2504.05148v1>|- 问题：实时深度估计，LiDAR与立体相机融合<br />- 方法：SGM，DDC，半密度化，一致性检查<br />- 效果：实时，非学习，误差率低|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AGBD: A Global-scale Biomass Dataset|全球尺度生物质数据集|Ghjulia Sialelli, Torben Peters, Jan D. Wegner, Konrad Schindler|<http://arxiv.org/pdf/2406.04928v3>|[[代码]](<https://github.com/ghjuliasialelli/AGBD>)<br />- 问题：AGB估计，数据集，分辨率，全球覆盖<br />- 方法：GEDI，Sentinel-2，PALSAR-2，高分辨率地图<br />- 效果：高精度，多样性，公开可用|
|🆕 发布|Inland Waterway Object Detection in Multi-environment: Dataset and Approach|内陆航道多环境下的目标检测：数据集与方法|Shanshan Wang, Haixiang Xu, Hui Feng, Xiaoqian Wang, Pei Song, Sijie Liu, Jianhua He|<http://arxiv.org/pdf/2504.04835v1>|- 问题：内陆航道，数据稀缺，环境复杂<br />- 方法：MEIWVD数据集，场景引导增强，多尺度融合<br />- 效果：性能提升，复杂环境适应|


## 自监督学习 (Self-supervised Learning)


### 对比学习 (Contrastive Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MSA-UNet3+: Multi-Scale Attention UNet3+ with New Supervised Prototypical Contrastive Loss for Coronary DSA Image Segmentation|MSA-UNet3+：基于新监督原型对比损失的冠脉DSA图像分割的多尺度注意力UNet3+|Rayan Merghani Ahmed, Adnan Iltaf, Bin Li, Shoujun Zhou|<http://arxiv.org/pdf/2504.05184v1>|[[代码]](<https://github.com/rayanmerghani/MSA-UNet3plus.>)<br />- 问题：冠脉DSA图像分割，低对比度，噪声，结构重叠，类不平衡<br />- 方法：MSA-UNet3+，多尺度注意力，监督原型对比损失<br />- 效果：Dice系数87.73%，F1分数87.78%，ASD和ACD降低|
|🆕 发布|Dual Consistent Constraint via Disentangled Consistency and Complementarity for Multi-view Clustering|基于解耦一致性和互补性的多视角聚类双重一致性约束|Bo Li, Jing Yun|<http://arxiv.org/pdf/2504.04676v1>|- 问题：多视角聚类，代表性学习，互补性忽视<br />- 方法：解耦变分自编码器，对比学习，一致性推断<br />- 效果：表现优于基线，扩展性强|


### 掩码自编码 (Masked Autoencoding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Uni4D: A Unified Self-Supervised Learning Framework for Point Cloud Videos|Uni4D：一种统一的点云视频自监督学习框架|Zhi Zuo, Chenyi Zhuang, Zhiqiang Shen, Pan Gao, Jie Qin|<http://arxiv.org/pdf/2504.04837v1>|- 问题：点云视频学习，运动学习，表示差距<br />- 方法：自解耦MAE，潜在空间建模，高级低级特征解耦<br />- 效果：性能提升，长视频处理，准确率提高|
|📝 更新|MIMRS: A Survey on Masked Image Modeling in Remote Sensing|MIMRS：遥感中掩码图像建模综述|Shabnam Choudhury, Akhil Vasim, Michael Schmitt, Biplab Banerjee|<http://arxiv.org/pdf/2504.03181v2>|- 问题：遥感图像建模，数据不完整，云遮挡<br />- 方法：掩码图像建模，自监督学习，预训练<br />- 效果：云去除，数据融合，超分辨率|


## 迁移与适应 (Transfer & Adaptation)


### 域适应 (Domain Adaptation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Reality Check of Vision-Language Pre-training in Radiology: Have We Progressed Using Text?|放射学中视觉-语言预训练的现实检验：我们是否通过文本取得了进展？|Julio Silva-Rodríguez, Jose Dolz, Ismail Ben Ayed|<http://arxiv.org/pdf/2504.05227v1>|- 问题：医学图像，视觉语言预训练，数据稀缺，概念细粒度<br />- 方法：单模态预训练，细粒度标签，异构数据整合<br />- 效果：竞争力强，开放词汇泛化质疑|
|🆕 发布|DiCoTTA: Domain-invariant Learning for Continual Test-time Adaptation|DiCoTTA：针对持续测试时自适应的领域不变学习|Sohyun Lee, Nayeong Kim, Juwon Kang, Seong Joon Oh, Suha Kwak|<http://arxiv.org/pdf/2504.04981v1>|- 问题：CTTA，域不变性，知识保留<br />- 方法：DiCoTTA，域不变学习，特征表示<br />- 效果：SOTA性能，泛化能力强|
|📝 更新|Seeing is Believing? Enhancing Vision-Language Navigation using Visual Perturbations|视觉扰动增强视觉-语言导航：可信的视觉|Xuesong Zhang, Jia Li, Yunbo Xu, Zhenzhen Hu, Richang Hong|<http://arxiv.org/pdf/2409.05552v2>|- 问题：视觉语言导航，模型理解，视觉扰动<br />- 方法：多分支架构，视觉质量影响，分支数量<br />- 效果：性能提升，超越现有方法|
|🆕 发布|Content-Aware Transformer for All-in-one Image Restoration|内容感知全能图像修复Transformer|Gang Wu, Junjun Jiang, Kui Jiang, Xianming Liu|<http://arxiv.org/pdf/2504.04869v1>|[[代码]](<https://github.com/Aitical/DSwinIR.>)<br />- 问题：Transformer，图像修复，感受野限制<br />- 方法：DSwinIR，可变形滑动窗口，中央集成模式<br />- 效果：性能提升，PSNR改善|
|📝 更新|Exploring Semi-Supervised Learning for Online Mapping|探索在线制图中的半监督学习方法|Adam Lilja, Erik Wallin, Junsheng Fu, Lars Hammarstrand|<http://arxiv.org/pdf/2410.10279v2>|- 问题：在线地图生成，数据标注成本高，半监督学习<br />- 方法：融合伪标签，增强自监督训练<br />- 效果：性能提升，泛化能力强|
|📝 更新|Memory-efficient Low-latency Remote Photoplethysmography through Temporal-Spatial State Space Duality|基于时空状态空间偶合的高效内存低延迟远程光电容积脉搏波描记法|Kegang Wang, Jiankai Tang, Yuxuan Fan, Jiatong Ji, Yuanchun Shi, Yuntao Wang|<http://arxiv.org/pdf/2504.01774v2>|[[代码]](<https://health-hci-group.github.io/ME-rPPG-demo>)<br />- 问题：rPPG计算瓶颈，资源需求高<br />- 方法：ME-rPPG，时空状态空间对偶性<br />- 效果：低延迟，高精度|


## 鲁棒学习 (Robust Learning)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|TflosYOLO+TFSC: An Accurate and Robust Model for Estimating Flower Count and Flowering Period|TflosYOLO+TFSC：一种用于估算花朵数量和开花期的准确且鲁棒模型|Qianxi Mi, Pengcheng Yuan, Chunlei Ma, Jiedan Chen, Mingzhe Yao|<http://arxiv.org/pdf/2501.15262v3>|- 问题：茶花计数，开花期预测，传统方法低效<br />- 方法：TflosYOLO，TFSC模型，SE网络<br />- 效果：高精度，高鲁棒性，R^2 0.974|
|📝 更新|MambaVO: Deep Visual Odometry Based on Sequential Matching Refinement and Training Smoothing|MambaVO：基于序列匹配优化和训练平滑的深度视觉里程计|Shuo Wang, Wanting Li, Yongcai Wang, Zhaoxin Fan, Zhe Huang, Xudong Cai, Jian Zhao, Deying Li|<http://arxiv.org/pdf/2412.20082v2>|- 问题：视觉里程标，匹配误差，几何建模，鲁棒性<br />- 方法：Mamba匹配，PFG优化，TAP平滑<br />- 效果：SOTA性能，实时运行|
|🆕 发布|Content-Distortion High-Order Interaction for Blind Image Quality Assessment|内容失真高阶交互用于盲图像质量评估|Shuai Liu, Qingyu Mao, Chao Li, Jiacong Chen, Fanyang Meng, Yonghong Tian, Yongsheng Liang|<http://arxiv.org/pdf/2504.05076v1>|- 问题：NR-IQA，内容-失真交互，质量感知<br />- 方法：CoDI-IQA，PPIM，多级特征融合<br />- 效果：预测准确，数据效率，泛化能力强|
|🆕 发布|Learning Affine Correspondences by Integrating Geometric Constraints|通过整合几何约束学习仿射对应|Pengju Sun, Banglei Guan, Zhenbao Yu, Yang Shang, Qifeng Yu, Daniel Barath|<http://arxiv.org/pdf/2504.04834v1>|[[代码]](<https://github.com/stilcrad/DenseAffine.>)<br />- 问题：Affine correspondence，性能局限<br />- 方法：密集匹配，几何约束，损失函数<br />- 效果：精度提升，鲁棒性增强|


### 对抗训练 (Adversarial Training)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Universal Lymph Node Detection in Multiparametric MRI with Selective Augmentation|多参数MRI中的通用淋巴结检测与选择性增强|Tejas Sudharshan Mathai, Sungwon Lee, Thomas C. Shen, Zhiyong Lu, Ronald M. Summers|<http://arxiv.org/pdf/2504.05196v1>|- 问题：淋巴结检测，mpMRI，测量困难，漏检<br />- 方法：VFNet，选择性增强，Intra-Label LISA<br />- 效果：灵敏度提升，检测准确|
|📝 更新|Latent Intrinsics Emerge from Training to Relight|从训练中涌现的潜在内参用于重光照|Xiao Zhang, William Gao, Seemandhar Jain, Michael Maire, David A. Forsyth, Anand Bhattad|<http://arxiv.org/pdf/2405.21074v2>|- 问题：图像重光照，逆图形，误差控制难<br />- 方法：数据驱动，潜在变量，无监督学习<br />- 效果：SOTA重光照，恢复反照率|
|📝 更新|Unsupervised 3D Point Cloud Completion via Multi-view Adversarial Learning|无监督多视角对抗学习实现3D点云补全|Lintai Wu, Xianjing Cheng, Yong Xu, Huanqiang Zeng, Junhui Hou|<http://arxiv.org/pdf/2407.09786v3>|[[代码]](<https://github.com/ltwu6/malspc>)<br />- 问题：3D点云补全，遮挡，自监督，弱监督<br />- 方法：多视角对抗学习，几何相似性，Pattern Retrieval Network<br />- 效果：无监督，效果优于现有方法|


### 对抗防御 (Adversarial Defense)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Adversarial Robustness for Deep Learning-based Wildfire Prediction Models|基于深度学习的野火预测模型的对抗鲁棒性|Ryo Ide, Lei Yang|<http://arxiv.org/pdf/2412.20006v3>|- 问题：火灾预测，数据稀缺，模型鲁棒性差<br />- 方法：WARP框架，对抗样本生成，数据增强<br />- 效果：模型鲁棒性提升，预测精度提高|
|🆕 发布|Balancing Robustness and Efficiency in Embedded DNNs Through Activation Function Selection|通过激活函数选择在嵌入式深度神经网络中平衡鲁棒性和效率|Jon Gutiérrez Zaballa, Koldo Basterretxea, Javier Echanobe|<http://arxiv.org/pdf/2504.05119v1>|- 问题：软错误鲁棒性，模型压缩，激活函数选择<br />- 方法：bounded AFs，模型评估，技术无关<br />- 效果：鲁棒性增强，模型压缩，效率提升|
|🆕 发布|ABCDWaveNet: Advancing Robust Road Ponding Detection in Fog through Dynamic Frequency-Spatial Synergy|ABCDWaveNet：通过动态频空协同提升雾天道路积水检测的鲁棒性|Ronghui Zhang, Dakang Lyu, Tengfei Li, Yunfan Wu, Ujjal Manandhar, Benfei Wang, Junzhou Chen, Bolin Gao .etc.|<http://arxiv.org/pdf/2504.05112v1>|- 问题：道路积水检测，ADAS，雾天，鲁棒性<br />- 方法：动态卷积，小波模块，自适应注意力<br />- 效果：性能提升，IoU增益，实时性|
|🆕 发布|RCCFormer: A Robust Crowd Counting Network Based on Transformer|RCCFormer：基于Transformer的鲁棒人群计数网络|Peng Liu, Heng-Chao Li, Sen Lei, Nanqing Liu, Bin Feng, Xiao Wu|<http://arxiv.org/pdf/2504.04935v1>|- 问题：背景干扰，尺度变化，计数精度<br />- 方法：Transformer，特征融合，自适应尺度感知<br />- 效果：性能提升，最佳结果|
|🆕 发布|Two is Better than One: Efficient Ensemble Defense for Robust and Compact Models|两个胜过一个：高效集成防御以实现鲁棒和紧凑模型|Yoojin Jung, Byung Cheol Song|<http://arxiv.org/pdf/2504.04747v1>|- 问题：模型压缩，对抗攻击，资源受限<br />- 方法：高效集成防御，动态子模型，多样化压缩<br />- 效果：高鲁棒性，推理速度提升|
|🆕 发布|On the Robustness of GUI Grounding Models Against Image Attacks|关于GUI定位模型对图像攻击的鲁棒性|Haoren Zhao, Tianyi Chen, Zhen Wang|<http://arxiv.org/pdf/2504.04716v1>|[[代码]](<https://github.com/ZZZhr-1/Robust_GUI_Grounding.>)<br />- 问题：GUI grounding模型鲁棒性，自然噪声，对抗攻击<br />- 方法：系统评估，多环境测试，对抗攻击条件<br />- 效果：敏感度评估，鲁棒性基准|
|📝 更新|Reliable-loc: Robust sequential LiDAR global localization in large-scale street scenes based on verifiable cues|可靠的定位：基于可验证线索的大规模街景中鲁棒的序列式激光雷达全局定位|Xianghong Zou, Jianping Li, Weitong Wu, Fuxun Liang, Bisheng Yang, Zhen Dong|<http://arxiv.org/pdf/2411.07815v2>|[[代码]](<https://github.com/zouxianghong/Reliable-loc.>)<br />- 问题：LiDAR全局定位，鲁棒性，大规模场景<br />- 方法：可验证线索，MCL，状态监控<br />- 效果：高精度，实时性能|


### 对抗攻击 (Adversarial Attack)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Latent Feature and Attention Dual Erasure Attack against Multi-View Diffusion Models for 3D Assets Protection|潜特征与注意力双重擦除攻击针对多视图扩散模型的三维资产保护|Jingwei Sun, Xuchong Zhang, Changfeng Sun, Qicheng Bai, Hongbin Sun|<http://arxiv.org/pdf/2408.11408v2>|- 问题：知识产权侵权，MVDMs，3D资产保护<br />- 方法：潜在特征，注意力，双重擦除攻击<br />- 效果：攻击有效性，迁移性，鲁棒性|
|📝 更新|A Survey and Evaluation of Adversarial Attacks for Object Detection|对抗攻击在目标检测中的调查与评估|Khoi Nguyen Tiet Nguyen, Wenyu Zhang, Kangkang Lu, Yuhuan Wu, Xingjian Zheng, Hui Li Tan, Liangli Zhen|<http://arxiv.org/pdf/2408.01934v4>|- 问题：对抗攻击，目标检测，鲁棒性，安全风险<br />- 方法：分类框架，攻击方法评估，开源实现分析<br />- 效果：关键洞察，研究缺口，标准化评估|


## 模型压缩加速 (Model Compression & Acceleration)


### 知识蒸馏 (Knowledge Distillation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Reinforced Multi-teacher Knowledge Distillation for Efficient General Image Forgery Detection and Localization|强化多教师知识蒸馏用于高效通用图像伪造检测与定位|Zeqin Yu, Jiangqun Ni, Jian Zhang, Haoyi Deng, Yuzhen Lin|<http://arxiv.org/pdf/2504.05224v1>|- 问题：图像伪造检测与定位，多样性伪造操作<br />- 方法：多教师知识蒸馏，动态教师选择，Cue-Net<br />- 效果：性能优越，知识迁移|
|🆕 发布|EffOWT: Transfer Visual Language Models to Open-World Tracking Efficiently and Effectively|EffOWT：高效且有效地将视觉语言模型迁移到开放世界跟踪|Bingyang Wang, Kaer Huang, Bin Li, Yiqiang Yan, Lihe Zhang, Huchuan Lu, You He|<http://arxiv.org/pdf/2504.05141v1>|- 问题：OWT泛化能力，VLM迁移，参数成本，性能优化<br />- 方法：独立侧网络，Transformer+CNN，MLP稀疏交互<br />- 效果：OWTA提升5.5%，参数更新1.3%，内存节省36.4%|
|🆕 发布|DebGCD: Debiased Learning with Distribution Guidance for Generalized Category Discovery|去偏学习中的分布引导广义类别发现|Yuanpei Liu, Kai Han|<http://arxiv.org/pdf/2504.04804v1>|[[代码]](<https://visual-ai.github.io/debgcd>)<br />- 问题：GCD，标签偏差，分布引导，语义分布<br />- 方法：DebGCD，辅助分类器，语义分布检测，课程学习<br />- 效果：SOTA性能，优化学习|
|🆕 发布|Bridging Knowledge Gap Between Image Inpainting and Large-Area Visible Watermark Removal|弥合图像修复与大面积可见水印去除之间的知识差距|Yicheng Leng, Chaowei Fang, Junye Chen, Yixiang Fang, Sheng Li, Guanbin Li|<http://arxiv.org/pdf/2504.04687v1>|- 问题：水印去除，模型依赖，大区域水印<br />- 方法：特征适应框架，知识迁移，双分支系统<br />- 效果：性能提升，鲁棒性增强|


### 量化优化 (Quantization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PTQ4VM: Post-Training Quantization for Visual Mamba|PTQ4VM：视觉Mamba的模型后训练量化|Younghyun Cho, Changhun Lee, Seonggon Kim, Eunhyeok Park|<http://arxiv.org/pdf/2412.20386v2>|[[代码]](<https://github.com/YoungHyun197/ptq4vm.>)<br />- 问题：Visual Mamba，量化敏感，性能提升难<br />- 方法：PTQ4VM，PTS量化，JLSS学习<br />- 效果：速度提升，精度损失小|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SMF: Template-free and Rig-free Animation Transfer using Kinetic Codes|SMF：基于动力学代码的无模板和刚性动画传输|Sanjeev Muralikrishnan, Niladri Shekhar Dutt, Niloy J. Mitra|<http://arxiv.org/pdf/2504.04831v1>|- 问题：动画重定向，稀疏运动描述，模板，变形装置，泛化能力<br />- 方法：自监督运动场，动力量码，空间时间预测器<br />- 效果：泛化，SoTA|
|🆕 发布|LagKV: Lag-Relative Information of the KV Cache Tells Which Tokens Are Important|LagKV：KV缓存中的延迟相对信息揭示了哪些标记是重要的|Manlai Liang, JiaMing Zhang, Xiong Li, Jinlong Li|<http://arxiv.org/pdf/2504.04704v1>|[[代码]](<https://github.com/AI-Lab-China-Merchants-Bank/LagKV>)<br />- 问题：KV缓存大小，部署成本，任务精度<br />- 方法：LagKV，无注意力机制，KV比较<br />- 效果：性能相当，压缩比高|


### 网络剪枝 (Network Pruning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dynamic Vision Mamba|动态视觉猛犸|Mengxuan Wu, Zekai Li, Zhiyuan Liang, Moyang Li, Xuanlei Zhao, Samir Khaki, Zheng Zhu, Xiaojiang Peng .etc.|<http://arxiv.org/pdf/2504.04787v1>|- 问题：空间冗余，早期剪枝，计算效率<br />- 方法：定制剪枝，动态选择块，FLOPs减少<br />- 效果：性能下降小，泛化能力强|


## 泛化与鲁棒性 (Generalization & Robustness)


### 不确定性建模 (Uncertainty Modeling)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Explainability of AI Uncertainty: Application to Multiple Sclerosis Lesion Segmentation on MRI|人工智能不确定性的可解释性：应用于MRI上多发性硬化症病灶分割|Nataliia Molchanova, Pedro M. Gordaliza, Alessandro Cagol, Mario Ocampo--Pineda, Po--Jui Lu, Matthias Weigel, Xinjie Chen, Erin S. Beck .etc.|<http://arxiv.org/pdf/2504.04814v1>|- 问题：AI不确定性，医学图像分割，可解释性<br />- 方法：深度集成，不确定性来源分析，医学因素关联<br />- 效果：实例不确定性，专家反馈，场景适用|


### 分布鲁棒性 (Distribution Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Benchmarking Multi-modal Semantic Segmentation under Sensor Failures: Missing and Noisy Modality Robustness|多模态语义分割在传感器故障下的基准测试：缺失和噪声模态鲁棒性|Chenfei Liao, Kaiyu Lei, Xu Zheng, Junha Moon, Zhixiong Wang, Yixuan Wang, Danda Pani Paudel, Luc Van Gool .etc.|<http://arxiv.org/pdf/2503.18445v2>|[[代码]](<https://github.com/Chenfei-Liao/Multi-Modal-Semantic-Segmentation-Robustness-Benchmark.>)<br />- 问题：多模态语义分割，鲁棒性，基准测试<br />- 方法：鲁棒性基准，概率模型，评估指标<br />- 效果：首个基准，新工具|


## 可解释性 (Interpretability)


### 可视化解释 (Visual Explanation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Show and Tell: Visually Explainable Deep Neural Nets via Spatially-Aware Concept Bottleneck Models|展示与讲述：通过空间感知概念瓶颈模型实现视觉可解释的深度神经网络|Itay Benou, Tammy Riklin-Raviv|<http://arxiv.org/pdf/2502.20134v2>|- 问题：深度神经网络可解释性差，缺乏可视化<br />- 方法：空间感知概念瓶颈模型，无标签训练<br />- 效果：分类任务性能提升，高质量空间解释|


## 医学影像分析 (Medical Image Analysis)


### 医学分割 (Medical Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|S^4M: Boosting Semi-Supervised Instance Segmentation with SAM|S^4M：利用SAM提升半监督实例分割|Heeji Yoon, Heeseong Shin, Eunbeen Hong, Hyunwook Choi, Hansang Cho, Daun Jeong, Seungryong Kim|<http://arxiv.org/pdf/2504.05301v1>|- 问题：半监督实例分割，伪标签质量差，性能受限<br />- 方法：SAM集成，新型蒸馏方法，伪标签精炼，数据增强<br />- 效果：性能提升，SOTA|
|🆕 发布|An ensemble deep learning approach to detect tumors on Mohs micrographic surgery slides|基于集成深度学习的莫氏显微手术切片肿瘤检测方法|Abdurrahim Yilmaz, Serra Atilla Aydin, Deniz Temur, Furkan Yuceyalcin, Berkin Deniz Kahya, Rahmetullah Varol, Ozay Gokoz, Gulsum Gencoglan .etc.|<http://arxiv.org/pdf/2504.05219v1>|- 问题：肿瘤检测，MMS，时间效率，病理学<br />- 方法：深度学习，U-Net，WSI分割<br />- 效果：高成功，高AUC|
|🆕 发布|BoxSeg: Quality-Aware and Peer-Assisted Learning for Box-supervised Instance Segmentation|BoxSeg：基于框监督的实例分割中的质量感知与同伴辅助学习|Jinxiang Lai, Wenlong Wu, Jiawei Zhan, Jian Li, Bin-Bin Gao, Jun Liu, Jie Zhang, Song Guo|<http://arxiv.org/pdf/2504.05137v1>|- 问题：Box-supervised instance segmentation, noisy masks, quality-aware<br />- 方法：Quality-Aware Module (QAM), Peer-assisted Copy-paste (PC), pseudo masks<br />- 效果：state-of-the-art, mask quality|
|📝 更新|Less is More? Revisiting the Importance of Frame Rate in Real-Time Zero-Shot Surgical Video Segmentation|少即是多？重新审视实时零样本手术视频分割中帧率的重要性|Utku Ozbulak, Seyed Amir Mousavi, Francesca Tozzi, Niki Rashidian, Wouter Willaert, Wesley De Neve, Joris Vankerschaver|<http://arxiv.org/pdf/2502.20934v2>|- 问题：帧率，零样本分割，实时性，手术视频<br />- 方法：帧率影响研究，实时场景评估，人类感知调查<br />- 效果：帧率优化，性能提升，实时性强化|
|🆕 发布|CMaP-SAM: Contraction Mapping Prior for SAM-driven Few-shot Segmentation|CMaP-SAM：基于SAM驱动的少样本分割的收缩映射先验|Shuai Chen, Fanman Meng, Haoran Wei, Chenhao Wu, Qingbo Wu, Linfeng Xu, Hongliang Li|<http://arxiv.org/pdf/2504.05049v1>|- 问题：FSS，结构相关性，信息损失<br />- 方法：收缩映射，位置先验优化，自适应分布对齐<br />- 效果：mIoU提升，性能领先|
|🆕 发布|IterMask3D: Unsupervised Anomaly Detection and Segmentation with Test-Time Iterative Mask Refinement in 3D Brain MR|IterMask3D：基于3D脑部MR的测试时迭代掩码细化无监督异常检测与分割|Ziyun Liang, Xiaoqing Guo, Wentian Xu, Yasin Ibrahim, Natalie Voets, Pieter M Pretorius, J. Alison Noble, Konstantinos Kamnitsas|<http://arxiv.org/pdf/2504.04911v1>|- 问题：异常检测，图像重建，信息损失，假阳性<br />- 方法：迭代掩码，空间掩码，高频信息<br />- 效果：降低假阳性，提升重建性能|
|🆕 发布|Prior2Former -- Evidential Modeling of Mask Transformers for Assumption-Free Open-World Panoptic Segmentation|Prior2Former -- 针对无假设开放世界全景分割的掩码Transformer的证据建模|Sebastian Schmidt, Julius Körner, Dominik Fuchsgruber, Stefano Gasperini, Federico Tombari, Stephan Günnemann|<http://arxiv.org/pdf/2504.04841v1>|- 问题：开放世界分割，新类别，OOD数据<br />- 方法：Prior2Former，Beta prior，不确定性估计<br />- 效果：最佳性能，无OOD数据|
|📝 更新|Learning Spatial-Semantic Features for Robust Video Object Segmentation|学习用于鲁棒视频目标分割的空间语义特征|Xin Li, Deshui Miao, Zhenyu He, Yaowei Wang, Huchuan Lu, Ming-Hsuan Yang|<http://arxiv.org/pdf/2407.07760v2>|[[代码]](<https://github.com/yahooo-m/S3>)<br />- 问题：视频对象分割，目标识别，遮挡，背景干扰<br />- 方法：空间语义特征，判别性查询，交叉注意力<br />- 效果：性能提升，泛化能力强|
|📝 更新|Prompt Categories Cluster for Weakly Supervised Semantic Segmentation|弱监督语义分割的提示类别聚类|Wangyu Wu, Xianglin Qiu, Siqi Song, Xiaowei Huang, Fei Ma, Jimin Xiao|<http://arxiv.org/pdf/2412.13823v2>|- 问题：弱监督语义分割，语义模糊，共享信息<br />- 方法：Prompt Categories Clustering，LLMs，类别聚类<br />- 效果：性能提升，超越现有方法|
|📝 更新|Distilling Spectral Graph for Object-Context Aware Open-Vocabulary Semantic Segmentation|蒸馏光谱图用于对象-上下文感知开放词汇语义分割|Chanyoung Kim, Dayun Ju, Woojung Han, Ming-Hsuan Yang, Seong Jae Hwang|<http://arxiv.org/pdf/2411.17150v3>|- 问题：OVSS，对象上下文，语义分割，学习方案，模型能力<br />- 方法：光谱图，对象级上下文，特征蒸馏，注意力机制，文本嵌入<br />- 效果：性能提升，泛化能力强|
|🆕 发布|DFormerv2: Geometry Self-Attention for RGBD Semantic Segmentation|DFormerv2：用于RGBD语义分割的几何自注意力|Bo-Wen Yin, Jiao-Long Cao, Ming-Ming Cheng, Qibin Hou|<http://arxiv.org/pdf/2504.04701v1>|[[代码]](<https://github.com/VCIP-RGBD/DFormer.>)<br />- 问题：RGBD语义分割，深度信息编码，几何先验<br />- 方法：几何自注意力，深度图作为先验，注意力权重分配<br />- 效果：性能提升，鲁棒性增强|


### 疾病诊断 (Disease Diagnosis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Federated Learning for Medical Image Classification: A Comprehensive Benchmark|联邦学习在医学图像分类中的应用：一个全面的基准|Zhekai Zhou, Guibo Luo, Mingzhi Chen, Zhenyu Weng, Yuesheng Zhu|<http://arxiv.org/pdf/2504.05238v1>|- 问题：联邦学习，医疗图像，隐私保护，优化算法<br />- 方法：综合评估，比较实验，数据增强<br />- 效果：性能挑战，基准建立|


### 影像重建 (Image Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|6Img-to-3D: Few-Image Large-Scale Outdoor Driving Scene Reconstruction|6Img-to-3D：基于少量图像的大规模户外驾驶场景重建|Théo Gieruc, Marius Kästingschäfer, Sebastian Bernhard, Mathieu Salzmann|<http://arxiv.org/pdf/2404.12378v2>|[[代码]](<https://github.com/continental/6Img-to-3D>)<br />- 问题：3D重建，图像数量少，场景无限，遮挡区域<br />- 方法：Transformer，参数化三平面，可微分体积渲染<br />- 效果：高效，可扩展，360°场景|
|🆕 发布|Inter-event Interval Microscopy for Event Cameras|事件相机间的间隔显微镜|Changqing Su, Yanqin Chen, Zihan Lin, Zhen Cheng, You Zhou, Bo Xiong, Zhaofei Yu, Tiejun Huang|<http://arxiv.org/pdf/2504.04924v1>|- 问题：事件相机，强度重建，动态场景<br />- 方法：事件间隔，脉冲调制，IEIM<br />- 效果：高分辨率，高动态范围，低带宽|


## 智能驾驶 (Intelligent Driving)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Sparse Signal to Smooth Motion: Real-Time Motion Generation with Rolling Prediction Models|从稀疏信号到平滑运动：基于滚动预测模型的实时运动生成|German Barquero, Nadine Bertsch, Manojkumar Marramreddy, Carlos Chacón, Filippo Arcadu, Ferran Rigual, Nicky Sijia He, Cristina Palmero .etc.|<http://arxiv.org/pdf/2504.05265v1>|- 问题：手部追踪，运动生成，输入不稳定性<br />- 方法：滚动预测模型，实时处理，无缝切换<br />- 效果：平滑运动，真实数据集|
|🆕 发布|InstructionBench: An Instructional Video Understanding Benchmark|指令Bench：一个指令视频理解基准|Haiwan Wei, Yitian Yuan, Xiaohan Lan, Wei Ke, Lin Ma|<http://arxiv.org/pdf/2504.05040v1>|- 问题：视频理解，指令视频，时序推理<br />- 方法：InstructionBench，GPT-4，问答评估<br />- 效果：模型评估，性能差距，数据集|


### 环境感知 (Environment Perception)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CODEI: Resource-Efficient Task-Driven Co-Design of Perception and Decision Making for Mobile Robots Applied to Autonomous Vehicles|CODEI：针对移动机器人的感知与决策任务驱动的资源高效协同设计，应用于自动驾驶车辆|Dejan Milojevic, Gioele Zardini, Miriam Elser, Andrea Censi, Emilio Frazzoli|<http://arxiv.org/pdf/2503.10296v2>|- 问题：资源高效，任务驱动，感知决策，移动机器人<br />- 方法：任务驱动设计，感知需求量化，整数线性规划<br />- 效果：资源优化，性能提升|
|📝 更新|Agent Journey Beyond RGB: Unveiling Hybrid Semantic-Spatial Environmental Representations for Vision-and-Language Navigation|智能体超越RGB之旅：揭示视觉-语言导航的混合语义-空间环境表示|Xuesong Zhang, Yunbo Xu, Jia Li, Zhenzhen Hu, Richnag Hong|<http://arxiv.org/pdf/2412.06465v4>|- 问题：VLN导航，RGB图像，语义空间，模态差距<br />- 方法：SUSA架构，TSU模块，DSP模块<br />- 效果：新SOTA，REVERIE，R2R，SOON|


## 其他 (Others)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Joint multiband deconvolution for Euclid and Vera C. Rubin images|联合多波段去卷积算法用于Euclid和Vera C. Rubin图像|Utsav Akhaury, Pascale Jablonka, Frédéric Courbin, Jean-Luc Starck|<http://arxiv.org/pdf/2502.17177v2>|- 问题：多波段，图像去卷积，分辨率提升<br />- 方法：联合去卷积，多波段关联，DRUNet降噪<br />- 效果：分辨率提高，形态恢复，通用于不同噪声|
|🆕 发布|Balancing Task-invariant Interaction and Task-specific Adaptation for Unified Image Fusion|平衡任务不变交互和任务特定适应的统一图像融合|Xingyu Hu, Junjun Jiang, Chenyang Wang, Kui Jiang, Xianming Liu, Jiayi Ma|<http://arxiv.org/pdf/2504.05164v1>|- 问题：统一图像融合，任务不变性，特定适应性<br />- 方法：动态平衡，交互增强像素注意力，基于操作自适应融合，FAMO策略<br />- 效果：性能竞争，泛化能力强|
|📝 更新|Cognitive Science-Inspired Evaluation of Core Capabilities for Object Understanding in AI|人工智能中物体理解核心能力认知科学启发评估|Danaja Rutar, Alva Markelius, Konstantinos Voudouris, José Hernández-Orallo, Lucy Cheke|<http://arxiv.org/pdf/2503.21668v2>|- 问题：对象理解，认知科学，AI能力评估<br />- 方法：理论框架分析，AI范式评估，综合评价方法<br />- 效果：识别核心能力，提升AI理解|

