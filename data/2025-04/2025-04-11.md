## [UPDATED!] **2025-04-11** (Update Time)


## 表示学习 (Representation Learning)


### 视觉Transformer (Vision Transformers)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Steering CLIP's vision transformer with sparse autoencoders|引导稀疏自编码器优化CLIP的视觉Transformer|Sonia Joseph, Praneet Suresh, Ethan Goldfarb, Lorenz Hufe, Yossi Gandelsman, Robert Graham, Danilo Bzdok, Wojciech Samek .etc.|<http://arxiv.org/pdf/2504.08729v1>|- 问题：视觉模型机制理解，稀疏自编码器，视觉与语言处理差异<br />- 方法：CLIP视觉Transformer，稀疏自编码器训练，可操控性分析<br />- 效果：可操控性提升，性能改善，最优解|
|🆕 发布|Hypergraph Vision Transformers: Images are More than Nodes, More than Edges|超图视觉Transformer：图像不仅是节点，更是边缘|Joshua Fixelle|<http://arxiv.org/pdf/2504.08710v1>|- 问题：ViTs可扩展性，高阶关系建模，计算效率<br />- 方法：HgVT，超图结构，动态超图构建<br />- 效果：高效，语义提取，图像检索|
|🆕 发布|Efficient Mixture of Geographical Species for On Device Wildlife Monitoring|高效混合地理物种用于设备端野生动物监测|Emmanuel Azuh Mensah, Joban Mand, Yueheng Ou, Min Jang, Kurtis Heimerl|<http://arxiv.org/pdf/2504.08620v1>|- 问题：边缘设备，野生动物监测，计算效率<br />- 方法：地理物种混合，条件计算，子网络剪枝<br />- 效果：性能提升，数据集应用|
|🆕 发布|SARFormer -- An Acquisition Parameter Aware Vision Transformer for Synthetic Aperture Radar Data|SARFormer —— 一种合成孔径雷达数据感知参数的视觉Transformer|Jonathan Prexl, Michael Recla, Michael Schmitt|<http://arxiv.org/pdf/2504.08441v1>|- 问题：SAR图像处理，复杂几何，多图像学习<br />- 方法：参数编码模块，ViT架构，自监督预训练<br />- 效果：性能提升，RMSE降低|
|📝 更新|Breaking the Barriers: Video Vision Transformers for Word-Level Sign Language Recognition|打破壁垒：用于词级手语识别的视频视觉Transformer|Alexander Brettmann, Jakob Grävinghoff, Marlene Rüschoff, Marie Westhues|<http://arxiv.org/pdf/2504.07792v2>|- 问题：手语识别，动态词级，CNN局限性<br />- 方法：ViViT模型，自注意力机制，全局关系捕捉<br />- 效果：Top-1精度75.58%，超越CNN|


### 预训练模型 (Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|The Key of Parameter Skew in Federated Learning|联邦学习中参数偏斜的关键|Junfeng Liao, Sifan Wang, Ye Yuan, Riquan Zhang|<http://arxiv.org/pdf/2408.11278v2>|- 问题：FL统计异构性，参数偏斜，模型估计误差<br />- 方法：参数偏斜概念，FedSA聚合策略，参数分组<br />- 效果：测试精度提升4.7%，优于基线|


## 生成建模 (Generative Modeling)


### 扩散模型 (Diffusion Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Generating Fine Details of Entity Interactions|生成实体交互的精细细节|Xinyi Gu, Jiayuan Mao|<http://arxiv.org/pdf/2504.08714v1>|- 问题：实体交互生成，数据稀缺，图像质量低<br />- 方法：分解增强，细节描述，LLM，VLM<br />- 效果：图像质量提升，交互丰富|
|🆕 发布|Seaweed-7B: Cost-Effective Training of Video Generation Foundation Model|海藻-7B：视频生成基础模型的低成本训练|Team Seawead, Ceyuan Yang, Zhijie Lin, Yang Zhao, Shanchuan Lin, Zhibei Ma, Haoyuan Guo, Hao Chen .etc.|<http://arxiv.org/pdf/2504.08685v1>|- 问题：视频生成，资源受限，模型性能<br />- 方法：7B参数模型，高效训练，轻量级微调<br />- 效果：性能优异，泛化能力强|
|🆕 发布|ZipIR: Latent Pyramid Diffusion Transformer for High-Resolution Image Restoration|ZipIR：用于高分辨率图像恢复的潜在金字塔扩散Transformer|Yongsheng Yu, Haitian Zheng, Zhifei Zhang, Jianming Zhang, Yuqian Zhou, Connelly Barnes, Yuchen Liu, Wei Xiong .etc.|<http://arxiv.org/pdf/2504.08591v1>|- 问题：高分辨率图像恢复，效率低，计算量大<br />- 方法：压缩潜变量，扩散模型，Transformer<br />- 效果：速度提升，质量提升|
|🆕 发布|COP-GEN-Beta: Unified Generative Modelling of COPernicus Imagery Thumbnails|COP-GEN-Beta：Copernicus影像缩略图的统一生成建模|Miguel Espinosa, Valerio Marsocci, Yuru Jia, Elliot J. Crowley, Mikolaj Czerkawski|<http://arxiv.org/pdf/2504.08548v1>|- 问题：多模态数据统一表示，模态转换<br />- 方法：生成扩散模型，序列扩散变换器，模态时间步嵌入<br />- 效果：零样本模态翻译，高质量样本生成|
|🆕 发布|Discriminator-Free Direct Preference Optimization for Video Diffusion|无判别器直接偏好优化视频扩散|Haoran Cheng, Qide Dong, Liang Peng, Zhizhou Sha, Weiguo Feng, Jinghui Xie, Zhao Song, Shilei Wen .etc.|<http://arxiv.org/pdf/2504.08542v1>|- 问题：数据效率低，评价不确定性，人工标注偏差，自动判别器失败<br />- 方法：无判别器DPO，编辑视频作为案例，训练模型避免编辑引入的瑕疵<br />- 效果：数据效率高，评价明确，无限数据扩展|
|📝 更新|WF-VAE: Enhancing Video VAE by Wavelet-Driven Energy Flow for Latent Video Diffusion Model|WF-VAE：通过小波驱动的能量流增强视频变分自编码器以实现潜在视频扩散模型|Zongjian Li, Bin Lin, Yang Ye, Liuhan Chen, Xinhua Cheng, Shenghai Yuan, Li Yuan|<http://arxiv.org/pdf/2411.17459v3>|[[代码]](<https://github.com/PKU-YuanGroup/WF-VAE.>)<br />- 问题：视频VAE编码成本高，长视频处理不连续<br />- 方法：波分变换，低频能量流，因果缓存<br />- 效果：吞吐量提升2倍，内存消耗降低4倍|
|🆕 发布|Cut-and-Splat: Leveraging Gaussian Splatting for Synthetic Data Generation|切割与喷溅：利用高斯喷溅进行合成数据生成|Bram Vanherle, Brent Zoomers, Jeroen Put, Frank Van Reeth, Nick Michiels|<http://arxiv.org/pdf/2504.08473v1>|- 问题：合成数据生成，3D模型，光照效果，相机伪影<br />- 方法：Gaussian Splatting，实例分割，自动提取<br />- 效果：高质量，自动化，性能优越|
|📝 更新|Generative Object Insertion in Gaussian Splatting with a Multi-View Diffusion Model|高斯分层中的生成性物体插入和多视角扩散模型|Hongliang Zhong, Can Wang, Jingbo Zhang, Jing Liao|<http://arxiv.org/pdf/2409.16938v2>|- 问题：3D内容，物体插入，质量低，单视图<br />- 方法：多视图扩散模型，MVInpainter，ControlNet<br />- 效果：高质量，一致性，和谐|
|🆕 发布|MineWorld: a Real-Time and Open-Source Interactive World Model on Minecraft|MineWorld：基于Minecraft的实时开源交互式世界模型|Junliang Guo, Yang Ye, Tianyu He, Haoyu Wu, Yushu Jiang, Tim Pearce, Jiang Bian|<http://arxiv.org/pdf/2504.08388v1>|- 问题：世界建模，动态环境，智能交互<br />- 方法：Transformer，视觉-动作自回归，并行解码<br />- 效果：实时交互，性能超越SoTA|
|🆕 发布|EasyGenNet: An Efficient Framework for Audio-Driven Gesture Video Generation Based on Diffusion Model|EasyGenNet：基于扩散模型的音频驱动手势视频生成的高效框架|Renda Li, Xiaohua Qi, Qiang Ling, Jun Yu, Ziyi Chen, Peng Chang, Mei HanJing Xiao|<http://arxiv.org/pdf/2504.08344v1>|- 问题：语音驱动手势视频生成，手势到视频合成困难<br />- 方法：单阶段训练，扩散模型，时序推理<br />- 效果：自然连续，超越GAN和扩散方法|
|🆕 发布|Single View Garment Reconstruction Using Diffusion Mapping Via Pattern Coordinates|基于图案坐标的扩散映射单视图服装重建|Ren Li, Cong Cao, Corentin Dumery, Yingxuan You, Hao Li, Pascal Fua|<http://arxiv.org/pdf/2504.08353v1>|- 问题：3D服装重建，单图，宽松服装<br />- 方法：扩散映射，ISP，映射模型<br />- 效果：高保真，泛化好，几何细节|
|🆕 发布|Geometric Consistency Refinement for Single Image Novel View Synthesis via Test-Time Adaptation of Diffusion Models|通过扩散模型测试时自适应的几何一致性细化实现单图像新视角合成|Josef Bengtson, David Nilsson, Fredrik Kahl|<http://arxiv.org/pdf/2504.08348v1>|- 问题：几何一致性，单图像新视图合成，扩散模型<br />- 方法：损失函数，图像匹配，测试时自适应<br />- 效果：几何一致性提升，图像质量保持|
|🆕 发布|In-2-4D: Inbetweening from Two Single-View Images to 4D Generation|在-2-4D：从两张单视图图像到4D生成的插值|Sauradip Nag, Daniel Cohen-Or, Hao Zhang, Ali Mahdavi-Amiri|<http://arxiv.org/pdf/2504.08366v1>|- 问题：4D生成，单视图，运动插值<br />- 方法：关键帧识别，Gaussian Splatting，自注意力，变形场<br />- 效果：平滑过渡，时间一致性|
|🆕 发布|DreamFuse: Adaptive Image Fusion with Diffusion Transformer|DreamFuse：基于扩散变换器的自适应图像融合|Junjia Huang, Pengxiang Yan, Jiyang Liu, Jie Wu, Zhao Wang, Yitong Wang, Liang Lin, Guanbin Li|<http://arxiv.org/pdf/2504.08291v1>|- 问题：图像融合，自适应，交互式，前景背景融合<br />- 方法：扩散Transformer，位置仿射机制，局部直接偏好优化<br />- 效果：和谐融合，泛化能力强|
|🆕 发布|Palmprint De-Identification Using Diffusion Model for High-Quality and Diverse Synthesis|基于扩散模型的掌纹去标识化：实现高质量和多样化的合成|Licheng Yan, Bob Zhang, Andrew Beng Jin Teoh, Lu Leng, Shuyi Li, Yuqi Wang, Ziyuan Yang|<http://arxiv.org/pdf/2504.08272v1>|- 问题：palmprint de-identification, identity concealment, image utility<br />- 方法：diffusion model, semantic-guided embedding, prior interpolation<br />- 效果：high-quality synthesis, diverse samples|
|🆕 发布|CoProSketch: Controllable and Progressive Sketch Generation with Diffusion Model|CoProSketch：基于扩散模型的可控和渐进式草图生成|Ruohao Zhan, Yijin Li, Yisheng He, Shuo Chen, Yichen Shen, Xinyu Chen, Zilong Dong, Zhaoyang Huang .etc.|<http://arxiv.org/pdf/2504.08259v1>|- 问题：草图生成，控制性，细节<br />- 方法：扩散模型，无符号距离场，迭代细化<br />- 效果：语义一致性，可控性|
|🆕 发布|TokenMotion: Decoupled Motion Control via Token Disentanglement for Human-centric Video Generation|TokenMotion：通过Token解耦进行的人中心视频生成中的运动控制|Ruineng Li, Daitao Xing, Huiming Sun, Yuanzhou Ha, Jinglin Shen, Chiuman Ho|<http://arxiv.org/pdf/2504.08181v1>|- 问题：运动控制，视频生成，运动表示，控制集成<br />- 方法：TokenMotion，DiT框架，解耦融合策略<br />- 效果：细粒度控制，性能优越|


### 自回归模型 (Autoregressive Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GigaTok: Scaling Visual Tokenizers to 3 Billion Parameters for Autoregressive Image Generation|吉加Tok：扩展视觉分词器至30亿参数以实现自回归图像生成|Tianwei Xiong, Jun Hao Liew, Zilong Huang, Jiashi Feng, Xihui Liu|<http://arxiv.org/pdf/2504.08736v1>|- 问题：图像重建，生成质量，参数扩展<br />- 方法：语义正则化，1D分词器，熵损失<br />- 效果：性能提升，最佳表现|


### 生成对抗网络 (GANs)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CityGen: Infinite and Controllable City Layout Generation|城市生成器：无限且可控的城市布局生成|Jie Deng, Wenhao Chai, Jianshu Guo, Qixuan Huang, Junsheng Huang, Wenhao Hu, Shengyu Hao, Jenq-Neng Hwang .etc.|<http://arxiv.org/pdf/2312.01508v2>|- 问题：城市布局生成，缺乏多样性，交互性差<br />- 方法：无限扩展模块，多尺度细化，用户控制<br />- 效果：性能领先，适用广泛|
|🆕 发布|RealCam-Vid: High-resolution Video Dataset with Dynamic Scenes and Metric-scale Camera Movements|RealCam-Vid：具有动态场景和米级相机运动的超分辨率视频数据集|Guangcong Zheng, Teng Li, Xianpan Zhou, Xi Li|<http://arxiv.org/pdf/2504.08212v1>|[[代码]](<https://github.com/ZGCTroy/RealCam-Vid.>)<br />- 问题：动态场景，几何一致性，高分辨率，视频生成<br />- 方法：开源数据集，动态场景，度量级相机标注<br />- 效果：高分辨率，真实感|


## 多模态学习 (Multimodal Learning)


### 视觉语言模型 (Vision-Language Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visual Chronicles: Using Multimodal LLMs to Analyze Massive Collections of Images|视觉编年史：利用多模态大型语言模型分析海量图像集合|Boyang Deng, Songyou Peng, Kyle Genova, Gordon Wetzstein, Noah Snavely, Leonidas Guibas, Thomas Funkhouser|<http://arxiv.org/pdf/2504.08727v1>|- 问题：大规模图像分析，模式发现，无监督，开放查询<br />- 方法：MLLMs，数据分解，子问题解决方案<br />- 效果：超越基线，发现有趣趋势|
|📝 更新|UNEM: UNrolled Generalized EM for Transductive Few-Shot Learning|UNEM：用于归纳式小样本学习的展开广义EM算法|Long Zhou, Fereshteh Shakeri, Aymen Sadraoui, Mounir Kaaniche, Jean-Christophe Pesquet, Ismail Ben Ayed|<http://arxiv.org/pdf/2412.16739v2>|- 问题：超参数，性能波动，计算复杂<br />- 方法：UNEM，EM优化，超参数学习<br />- 效果：性能提升，效率提高|
|🆕 发布|Training-free Guidance in Text-to-Video Generation via Multimodal Planning and Structured Noise Initialization|基于多模态规划和结构化噪声初始化的无监督文本到视频生成引导|Jialu Li, Shoubin Yu, Han Lin, Jaemin Cho, Jaehong Yoon, Mohit Bansal|<http://arxiv.org/pdf/2504.08641v1>|- 问题：T2V模型，空间布局，轨迹控制，挑战<br />- 方法：Video-MSG，多模态规划，结构化噪声初始化<br />- 效果：无需微调，文本对齐，T2VCompBench|
|📝 更新|Fine-Grained Retrieval-Augmented Generation for Visual Question Answering|精细粒度检索增强视觉问答生成|Zhengxuan Zhang, Yin Wu, Yuyu Luo, Nan Tang|<http://arxiv.org/pdf/2502.20964v2>|- 问题：VQA，知识获取，细节丢失<br />- 方法：细粒度知识单元，KU-RAG框架，知识纠正链<br />- 效果：性能提升，平均3%，最佳11%|
|📝 更新|Standing on the Shoulders of Giants: Reprogramming Visual-Language Model for General Deepfake Detection|站在巨人的肩膀上：重新编程视觉-语言模型以实现通用深度伪造检测|Kaiqing Lin, Yuzhen Lin, Weixiang Li, Taiping Yao, Bin Li|<http://arxiv.org/pdf/2409.02664v4>|- 问题：deepfake检测泛化性差，模型可重编程<br />- 方法：VLM重编程，视觉扰动，自适应文本提示<br />- 效果：泛化性提升，参数少|
|📝 更新|SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models|SCAM：多模态基础模型的真实世界印刷鲁棒性评估|Justus Westerhoff, Erblina Purelku, Jakob Hackstein, Leo Pinetzki, Lorenz Hufe|<http://arxiv.org/pdf/2504.04893v2>|[[代码]](<https://github.com/Bliss-e-V/SCAM.>)<br />- 问题：字体攻击，数据集，多模态模型<br />- 方法：SCAM数据集，基准测试，VLMs评估<br />- 效果：性能下降，模型易受攻击|
|📝 更新|MLLM-Tool: A Multimodal Large Language Model For Tool Agent Learning|MLLM-Tool：一种用于工具智能体学习的多模态大型语言模型|Chenyu Wang, Weixin Luo, Sixun Dong, Xiaohua Xuan, Zhengxin Li, Lin Ma, Shenghua Gao|<http://arxiv.org/pdf/2401.10727v3>|[[代码]](<https://github.com/MLLM-Tool/MLLM-Tool.>)<br />- 问题：LLM感知工具使用能力有限，理解意图模糊<br />- 方法：MLLM-Tool，多模态编码器，工具选择<br />- 效果：推荐工具，多模态指令|
|🆕 发布|Towards Efficient and Robust Moment Retrieval System: A Unified Framework for Multi-Granularity Models and Temporal Reranking|迈向高效且鲁棒的矩检索系统：多粒度模型与时间重排序的统一框架|Huu-Loc Tran, Tinh-Anh Nguyen-Nhu, Huu-Phong Phan-Nguyen, Tien-Huy Nguyen, Nhat-Minh Nguyen-Dich, Anh Dao, Huy-Duc Do, Quan Nguyen .etc.|<http://arxiv.org/pdf/2504.08384v1>|- 问题：视频检索效率低，精度差，稳定性差<br />- 方法：多模型集成，存储优化，时间搜索，时间重排序<br />- 效果：检索精度提升，效率提高，用户可解释性增强|
|🆕 发布|FocalLens: Instruction Tuning Enables Zero-Shot Conditional Image Representations|焦点镜头：指令调整实现零样本条件图像表示|Cheng-Yu Hsieh, Pavan Kumar Anasosalu Vasu, Fartash Faghri, Raviteja Vemulapalli, Chun-Liang Li, Ranjay Krishna, Oncel Tuzel, Hadi Pouransari|<http://arxiv.org/pdf/2504.08368v1>|- 问题：图像上下文理解，固定特征向量，任务适应性<br />- 方法：FocalLens，指令微调，视觉编码器<br />- 效果：性能提升，特征突出|
|🆕 发布|LMM4LMM: Benchmarking and Evaluating Large-multimodal Image Generation with LMMs|LMM4LMM：基于LMM的大多模态图像生成基准与评估|Jiarui Wang, Huiyu Duan, Yu Zhao, Juntong Wang, Guangtao Zhai, Xiongkuo Min|<http://arxiv.org/pdf/2504.08358v1>|[[代码]](<https://github.com/IntMeGroup/LMM4LMM.>)<br />- 问题：图像生成质量，文本图像对齐<br />- 方法：EvalMi-50K数据集，LMM4LMM指标<br />- 效果：性能领先，泛化能力强|
|📝 更新|IdealGPT: Iteratively Decomposing Vision and Language Reasoning via Large Language Models|理想GPT：通过大型语言模型迭代分解视觉与语言推理|Haoxuan You, Zhecan Wang, Rui Sun, Long Chen, Gengyu Wang, Hammad A. Ayyubi, Kai-Wei Chang, Shih-Fu Chang|<http://arxiv.org/pdf/2305.14985v2>|[[代码]](<https://github.com/Hxyou/IdealGPT>)<br />- 问题：零样本推理，多步推断，分解视觉语言理解<br />- 方法：迭代分解，大语言模型，子问题生成<br />- 效果：性能提升，VCR 10%，SNLI-VE 15%|
|📝 更新|EgoPlan-Bench2: A Benchmark for Multimodal Large Language Model Planning in Real-World Scenarios|自我规划基准2：真实场景中多模态大型语言模型规划的基准|Lu Qiu, Yi Chen, Yuying Ge, Yixiao Ge, Ying Shan, Xihui Liu|<http://arxiv.org/pdf/2412.04447v2>|[[代码]](<https://qiulu66.github.io/egoplanbench2>)<br />- 问题：MLLM规划能力，现实场景，评估基准<br />- 方法：EgoPlan-Bench2，多模态CoT提示，无监督训练<br />- 效果：性能提升，局限性分析|
|📝 更新|SpaceVLLM: Endowing Multimodal Large Language Model with Spatio-Temporal Video Grounding Capability|空间VLLM：赋予多模态大型语言模型时空视频定位能力|Jiankang Wang, Zhihan Zhang, Zhihang Liu, Yang Li, Jiannan Ge, Hongtao Xie, Yongdong Zhang|<http://arxiv.org/pdf/2503.13983v3>|[[代码]](<https://github.com/Jayce1kk/SpaceVLLM.>)<br />- 问题：时空视频定位，信息提取，视觉映射<br />- 方法：时空感知查询，空间解码器，Uni-STG数据集<br />- 效果：SOTA性能，多任务覆盖|
|🆕 发布|VLMT: Vision-Language Multimodal Transformer for Multimodal Multi-hop Question Answering|视觉-语言多模态Transformer用于多模态多跳问答|Qi Zhi Lim, Chin Poo Lee, Kian Ming Lim, Kalaiarasi Sonai Muthu Anbananthen|<http://arxiv.org/pdf/2504.08269v1>|- 问题：MMQA，跨模态推理，模态转换，表示对齐<br />- 方法：VLMT，Transformer，直接注入，三阶段预训练<br />- 效果：精确匹配率提升，F1分数提升|
|📝 更新|CLAP: Isolating Content from Style through Contrastive Learning with Augmented Prompts|CLAP：通过增强提示的对比学习从风格中隔离内容|Yichao Cai, Yuhang Liu, Zhen Zhang, Javen Qinfeng Shi|<http://arxiv.org/pdf/2311.16445v5>|- 问题：特征混合，泛化能力受限<br />- 方法：因果生成，对比学习，数据增强<br />- 效果：性能提升，鲁棒性增强|
|📝 更新|EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents|具身评估：评估作为具身代理的多模态大型语言模型|Zhili Cheng, Yuge Tu, Ran Li, Shiqi Dai, Jinyi Hu, Shengding Hu, Jiahao Li, Yang Shi .etc.|<http://arxiv.org/pdf/2501.11858v2>|[[代码]](<https://github.com/thunlp/EmbodiedEval.>)<br />- 问题：MLLMs评估，非交互场景，任务特定<br />- 方法：EmbodiedEval，多模态任务，统一框架<br />- 效果：能力评估，能力不足|
|📝 更新|Constraint-Aware Zero-Shot Vision-Language Navigation in Continuous Environments|约束感知的连续环境中零样本视觉语言导航|Kehan Chen, Dong An, Yan Huang, Rongtao Xu, Yifei Su, Yonggen Ling, Ian Reid, Liang Wang|<http://arxiv.org/pdf/2412.10137v2>|- 问题：零样本，视觉语言导航，连续环境<br />- 方法：约束感知导航器，子指令管理，值映射器<br />- 效果：性能提升，实际应用|
|📝 更新|Unified Static and Dynamic Network: Efficient Temporal Filtering for Video Grounding|统一静态和动态网络：视频定位的高效时序滤波|Jingjing Hu, Dan Guo, Kun Li, Zhan Si, Xun Yang, Xiaojun Chang, Meng Wang|<http://arxiv.org/pdf/2403.14174v2>|[[代码]](<https://github.com/xian-sh/UniSDNet.>)<br />- 问题：视频 grounding，语义关联，动态建模<br />- 方法：ResMLP，持久活动机制，时空掩码<br />- 效果：SOTA性能，新数据集|
|🆕 发布|VL-UR: Vision-Language-guided Universal Restoration of Images Degraded by Adverse Weather Conditions|视觉-语言引导的恶劣天气条件下图像通用恢复|Ziyan Liu, Yuxu Lu, Huashan Yu, Dong yang|<http://arxiv.org/pdf/2504.08219v1>|- 问题：图像退化，适应性，非均匀退化<br />- 方法：视觉语言引导，CLIP模型，场景分类器<br />- 效果：性能领先，鲁棒，适应性强|
|📝 更新|AerialVG: A Challenging Benchmark for Aerial Visual Grounding by Exploring Positional Relations|空中视觉定位的挑战性基准：通过探索位置关系进行探索|Junli Liu, Qizhi Chen, Zhigang Wang, Yiwen Tang, Yiting Zhang, Chi Yan, Dong Wang, Xuelong Li .etc.|<http://arxiv.org/pdf/2504.07836v2>|- 问题：视觉定位，空中图像，空间关系，数据集<br />- 方法：AerialVG，层次交叉注意力，关系感知定位<br />- 效果：空间推理，模型有效性|


### 跨模态对齐 (Cross-modal Alignment)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MBE-ARI: A Multimodal Dataset Mapping Bi-directional Engagement in Animal-Robot Interaction|MBE-ARI：一个多模态数据集，用于映射动物-机器人交互中的双向参与|Ian Noronha, Advait Prasad Jawaji, Juan Camilo Soto, Jiajun An, Yan Gu, Upinder Kaur|<http://arxiv.org/pdf/2504.08646v1>|[[代码]](<https://github.com/RISELabPurdue/MBE-ARI>)<br />- 问题：动物-机器人交互，数据集，双向沟通<br />- 方法：MBE-ARI数据集，全身体姿估计模型<br />- 效果：高精度，公开资源|
|📝 更新|A Unified Framework for Iris Anti-Spoofing: Introducing Iris Anti-Spoofing Cross-Domain-Testing Protocol and Masked-MoE Method|统一虹膜反欺骗框架：引入虹膜反欺骗跨域测试协议和掩码MoE方法|Hang Zou, Chenxi Du, Ajian Liu, Yuan Zhang, Jing Liu, Mingchuan Yang, Jun Wan, Hui Zhang .etc.|<http://arxiv.org/pdf/2408.09752v2>|- 问题：跨域泛化，种族影响，设备差异<br />- 方法：IAS-CDT协议，MoE，Masked-MoE<br />- 效果：提升泛化能力，减少过拟合|
|📝 更新|VTON 360: High-Fidelity Virtual Try-On from Any Viewing Direction|VTON 360：从任何视角实现的高保真虚拟试穿|Zijian He, Yuwei Ning, Yipeng Qin, Guangrun Wang, Sibei Yang, Liang Lin, Guanbin Li|<http://arxiv.org/pdf/2503.12165v2>|[[代码]](<https://scnuhealthy.github.io/VTON360.>)<br />- 问题：高保真VTON，任意视角渲染<br />- 方法：3D模型等效，多视角输入，伪3D姿态表示<br />- 效果：多视角一致性，效果显著|


### 多模态融合 (Multimodal Fusion)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DiMoDif: Discourse Modality-information Differentiation for Audio-visual Deepfake Detection and Localization|DiMoDif：音频-视觉深度伪造检测与定位中的语篇模态信息差异化|Christos Koutlis, Symeon Papadopoulos|<http://arxiv.org/pdf/2411.10193v2>|[[代码]](<https://github.com/mever-team/dimodif.>)<br />- 问题：deepfake检测，模态差异，信息完整性<br />- 方法：跨模态融合，时序定位，差异映射<br />- 效果：AUC提升30.5，AP@0.75提升47.88|
|📝 更新|Scaling Laws for Native Multimodal Models|原生多模态模型的缩放定律|Mustafa Shukor, Enrico Fini, Victor Guilherme Turrisi da Costa, Matthieu Cord, Joshua Susskind, Alaaeldin El-Nouby|<http://arxiv.org/pdf/2504.07951v2>|- 问题：多模态模型，融合架构，性能比较<br />- 方法：NMMs，早融合，MoEs<br />- 效果：性能提升，效率提高|


## 目标检测识别 (Object Detection & Recognition)


### 三维检测 (3D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Multi-Modal AI System for Screening Mammography: Integrating 2D and 3D Imaging to Improve Breast Cancer Detection in a Prospective Clinical Study|多模态人工智能系统用于乳腺筛查：结合二维和三维成像以改善前瞻性临床研究中的乳腺癌检测|Jungkyu Park, Jan Witowski, Yanqi Xu, Hari Trivedi, Judy Gichoya, Beatrice Brown-Mulry, Malte Westerhoff, Linda Moy .etc.|<http://arxiv.org/pdf/2504.05636v2>|- 问题：乳腺癌筛查，假阳性，诊断性能<br />- 方法：多模态AI，2D/3D成像，深度学习<br />- 效果：召回率降低，工作量减少，AUROC提升|
|🆕 发布|GeoTexBuild: 3D Building Model Generation from Map Footprints|GeoTexBuild：从地图足迹生成3D建筑模型|Ruizhe Wang, Junyan Yang, Qiao Wang|<http://arxiv.org/pdf/2504.08419v1>|- 问题：3D建模，地图足迹，结构变化<br />- 方法：GeoTexBuild框架，ControlNet，Text2Mesh<br />- 效果：自动化建模，减少人力|
|📝 更新|BRepFormer: Transformer-Based B-rep Geometric Feature Recognition|BRepFormer：基于Transformer的B-rep几何特征识别|Yongkang Dai, Xiaoshui Huang, Yunpeng Bai, Hao Guo, Hongping Gan, Ling Yang, Yilei Shi|<http://arxiv.org/pdf/2504.07378v2>|- 问题：B-rep特征识别，拓扑几何特征，MFR<br />- 方法：Transformer，特征融合，几何约束<br />- 效果：高精度，CBF数据集|


### 二维检测 (2D Detection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Preserving Privacy Without Compromising Accuracy: Machine Unlearning for Handwritten Text Recognition|在不损害准确性的情况下保护隐私：手写文本识别的机器反学习|Lei Kang, Xuanshuo Fu, Lluis Gomez, Alicia Fornés, Ernest Valveny, Dimosthenis Karatzas|<http://arxiv.org/pdf/2504.08616v1>|- 问题：隐私保护，HTR，机器反学习，隐私-精度权衡<br />- 方法：两阶段策略，剪枝，随机标记，作者分类头<br />- 效果：隐私保留，精度维持|
|📝 更新|D-Feat Occlusions: Diffusion Features for Robustness to Partial Visual Occlusions in Object Recognition|D-Feat Occlusions：面向物体识别中部分视觉遮挡鲁棒性的扩散特征|Rupayan Mallick, Sibo Dong, Nataniel Ruiz, Sarah Adel Bargal|<http://arxiv.org/pdf/2504.06432v2>|- 问题：视觉遮挡，分类模型鲁棒性<br />- 方法：扩散模型，特征提取，图像补全<br />- 效果：模型鲁棒性提升，真实场景应用|
|📝 更新|ODverse33: Is the New YOLO Version Always Better? A Multi Domain benchmark from YOLO v5 to v11|ODverse33：新的YOLO版本是否总是更好？从YOLO v5到v11的多领域基准测试|Tianyou Jiang, Yang Zhong|<http://arxiv.org/pdf/2502.14314v3>|- 问题：YOLO版本比较，创新评估，多域基准<br />- 方法：ODverse33基准，版本创新总结，多域实验<br />- 效果：性能评估，应用指导|
|📝 更新|Open-CD: A Comprehensive Toolbox for Change Detection|开放-CD：一个用于变化检测的综合工具箱|Kaiyu Li, Jiawei Jiang, Andrea Codegoni, Chengxi Han, Yupeng Deng, Keyan Chen, Zhuo Zheng, Hao Chen .etc.|<http://arxiv.org/pdf/2407.15317v2>|[[代码]](<https://github.com/likyoo/open-cd.>)<br />- 问题：变化检测，工具箱，开源<br />- 方法：综合平台，多种方法，数据分析脚本<br />- 效果：全面，灵活，社区贡献|
|📝 更新|Thinking Racial Bias in Fair Forgery Detection: Models, Datasets and Evaluations|思考公平伪造检测中的种族偏见：模型、数据集和评估|Decheng Liu, Zongqi Wang, Chunlei Peng, Nannan Wang, Ruimin Hu, Xinbo Gao|<http://arxiv.org/pdf/2407.14367v3>|- 问题：种族偏见，伪造检测，公平性，数据集，评估<br />- 方法：FairFD数据集，公平性指标，BPFA后处理<br />- 效果：新SOTA，公平性提升|
|🆕 发布|Light-YOLOv8-Flame: A Lightweight High-Performance Flame Detection Algorithm|轻量级高性能火焰检测算法：Light-YOLOv8-Flame|Jiawei Lan, Zhibiao Wang, Haoyang Yu, Ye Tao, Wenhua Cui|<http://arxiv.org/pdf/2504.08389v1>|- 问题：高计算成本，延迟响应，实时系统应用受限<br />- 方法：Light-YOLOv8-Flame，FasterNet Block，PConv，Conv<br />- 效果：mAP提升，召回率提升，参数减少|
|📝 更新|Mixture of Gaussian-distributed Prototypes with Generative Modelling for Interpretable and Trustworthy Image Recognition|混合高斯分布原型与生成建模的图像识别可解释性与可信度|Chong Wang, Yuanhong Chen, Fengbei Liu, Yuyuan Liu, Davis James McCarthy, Helen Frazer, Gustavo Carneiro|<http://arxiv.org/pdf/2312.00092v3>|- 问题：原型学习，可解释性，OoD检测，性能退化，子显著区域<br />- 方法：MGProto，原型分布学习，原型剪枝<br />- 效果：SOTA性能，高可解释性|


## 三维重建 (3D Reconstruction)


### 神经隐式重建 (Neural Implicit Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|X2BR: High-Fidelity 3D Bone Reconstruction from a Planar X-Ray Image with Hybrid Neural Implicit Methods|X2BR：基于混合神经网络隐式方法的平面X射线图像高保真3D骨骼重建|Gokce Guven, H. Fatih Ugurdag, Hasan F. Ates|<http://arxiv.org/pdf/2504.08675v1>|- 问题：3D骨重建，X射线图像，解剖复杂性<br />- 方法：混合神经网络，隐式方法，模板引导<br />- 效果：高保真，解剖准确性|
|📝 更新|ASHiTA: Automatic Scene-grounded HIerarchical Task Analysis|ASHiTA：基于场景的自动分层任务分析|Yun Chang, Leonor Fermoselle, Duy Ta, Bernadette Bucher, Luca Carlone, Jiuguang Wang|<http://arxiv.org/pdf/2504.06553v3>|- 问题：高阶指令场景化，任务分解，环境依赖<br />- 方法：LLM辅助，层次任务分析，场景图构建<br />- 效果：性能提升，可比现有方法|
|📝 更新|Auto-Encoded Supervision for Perceptual Image Super-Resolution|自动编码监督感知图像超分辨率|MinKyu Lee, Sangeek Hyun, Woojin Jun, Jae-Pil Heo|<http://arxiv.org/pdf/2412.00124v2>|- 问题：感知超分辨率，L_p损失，模糊<br />- 方法：自动编码器，AESOP损失函数，AE空间<br />- 效果：感知质量提升，简单易用|


### 多视图重建 (Multi-view Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset|数字孪生目录：一个大规模逼真3D对象数字孪生数据集|Zhao Dong, Ka Chen, Zhaoyang Lv, Hong-Xing Yu, Yunzhi Zhang, Cheng Zhang, Yufeng Zhu, Stephen Tian .etc.|<http://arxiv.org/pdf/2504.08541v1>|- 问题：3D重建，数据集，评估，AR眼镜，数字孪生<br />- 方法：大规模，真实感，3D对象，数字孪生，基准<br />- 效果：性能比较，质量提升，基准建立|
|🆕 发布|PMNI: Pose-free Multi-view Normal Integration for Reflective and Textureless Surface Reconstruction|PMNI：无姿态多视图无反射无纹理表面重建|Mingzhi Pei, Xu Cao, Xiangyi Wang, Heng Guo, Zhanyu Ma|<http://arxiv.org/pdf/2504.08410v1>|- 问题：反射无纹理表面，多视角重建，相机姿态，形状重建<br />- 方法：表面法线图，几何约束，SDF优化<br />- 效果：高精度重建，无初始姿态|


## 神经渲染 (Neural Rendering)


### 神经辐射场 (Neural Radiance Fields)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FMLGS: Fast Multilevel Language Embedded Gaussians for Part-level Interactive Agents|快速多级语言嵌入高斯模型用于部件级交互式智能体|Xin Tan, Yuzhou Ji, He Zhu, Yuan Xie|<http://arxiv.org/pdf/2504.08581v1>|- 问题：多粒度交互，语言模糊，查询质量差<br />- 方法：SAM2语义嵌入，语义偏差策略，部分级查询<br />- 效果：速度提升，精度领先|
|📝 更新|3D Student Splatting and Scooping|三维学生喷溅和挖掘|Jialin Zhu, Jiangbei Yue, Feixiang He, He Wang|<http://arxiv.org/pdf/2503.10148v4>|- 问题：3DGS，表达性，学习挑战<br />- 方法：Student's t分布，Splatting & Scooping，优化采样<br />- 效果：质量提升，参数效率高|
|📝 更新|E-3DGS: Gaussian Splatting with Exposure and Motion Events|E-3DGS：基于曝光和运动事件的高斯分层|Xiaoting Yin, Hao Shi, Yuhan Bao, Zhenshan Bing, Yiyi Liao, Kailun Yang, Kaiwei Wang|<http://arxiv.org/pdf/2410.16995v2>|[[代码]](<https://github.com/MasterHow/E-3DGS.>)<br />- 问题：运动模糊，光照不足，3D重建<br />- 方法：事件相机，曝光事件，运动事件，3DGS<br />- 效果：高质量重建，快速重建，鲁棒性|


### 可控渲染 (Controllable Rendering)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Generative AI for Film Creation: A Survey of Recent Advances|电影创作中的生成式人工智能：近期进展综述|Ruihan Zhang, Borou Yu, Jiajian Min, Yetong Xin, Zheng Wei, Juncheng Nemo Shi, Mingzhen Huang, Xianghao Kong .etc.|<http://arxiv.org/pdf/2504.08296v1>|- 问题：GenAI在电影制作中的应用，技术采纳，艺术表达<br />- 方法：文本到图像，图像到视频扩散，神经辐射场，3D合成<br />- 效果：风格一致性，运动连续性，新艺术形式|


## 定位与映射 (Localization & Mapping)


### 位姿估计 (Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EMO-X: Efficient Multi-Person Pose and Shape Estimation in One-Stage|EMO-X：单阶段高效多人姿态和形状估计|Haohang Jian, Jinlu Zhang, Junyi Wu, Zhigang Tu|<http://arxiv.org/pdf/2504.08718v1>|- 问题：多人体姿态和形状估计，Transformer，计算复杂度高<br />- 方法：Mamba，SGLD，全局-局部解码<br />- 效果：效率提升，精度高|
|🆕 发布|The Invisible EgoHand: 3D Hand Forecasting through EgoBody Pose Estimation|无形自我手：通过自我身体姿态估计进行3D手预测|Masashi Hatano, Zhifan Zhu, Hideo Saito, Dima Damen|<http://arxiv.org/pdf/2504.08654v1>|[[代码]](<https://masashi-hatano.github.io/EgoH4>)<br />- 问题：手部运动预测，视角限制，可见性推断<br />- 方法：EgoH4架构，扩散模型，Transformer<br />- 效果：ADE降低，MPJPE降低|
|🆕 发布|Hardware, Algorithms, and Applications of the Neuromorphic Vision Sensor: a Review|神经形态视觉传感器的硬件、算法与应用综述|Claudio Cimarelli, Jose Andres Millan-Romera, Holger Voos, Jose Luis Sanchez-Lopez|<http://arxiv.org/pdf/2504.08588v1>|- 问题：神经形态视觉，数据格式，算法适应<br />- 方法：硬件特性，事件相机，图像处理算法<br />- 效果：应用广泛，挑战识别|
|🆕 发布|Ego4o: Egocentric Human Motion Capture and Understanding from Multi-Modal Input|自我4o：基于多模态输入的以自我为中心的人类动作捕捉与理解|Jian Wang, Rishabh Dabral, Diogo Luvizon, Zhe Cao, Lingjie Liu, Thabo Beeler, Christian Theobalt|<http://arxiv.org/pdf/2504.08449v1>|- 问题：多模态输入，运动捕捉，理解挑战<br />- 方法：Ego4o框架，VQ-VAE编码，多模态LLM<br />- 效果：准确预测，高质量描述|
|🆕 发布|Multi-person Physics-based Pose Estimation for Combat Sports|多人基于物理的格斗运动姿态估计|Hossein Feiz, David Labbé, Thomas Romeas, Jocelyn Faubert, Sheldon Andrews|<http://arxiv.org/pdf/2504.08175v1>|- 问题：3D人体姿态估计，多视角，运动捕捉<br />- 方法：Transformer，多视角跟踪，物理轨迹优化<br />- 效果：精度高，鲁棒性强|


### 语义建图 (Semantic Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FindAnything: Open-Vocabulary and Object-Centric Mapping for Robot Exploration in Any Environment|《FindAnything：适用于任何环境的开放词汇和以物体为中心的机器人探索映射》|Sebastián Barbas Laina, Simon Boche, Sotiris Papatheodorou, Simon Schaefer, Jaehyung Jung, Stefan Leutenegger|<http://arxiv.org/pdf/2504.08603v1>|- 问题：实时语义理解，开放词汇，SLAM，环境探索<br />- 方法：视觉语言特征，eSAM，对象中心子图，开放词汇映射<br />- 效果：语义精度高，场景理解，资源受限设备|


### 视觉SLAM (Visual SLAM)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|The Composite Visual-Laser Navigation Method Applied in Indoor Poultry Farming Environments|复合视觉激光导航方法在室内家禽养殖环境中的应用|Jiafan Lu, Dongcheng Hu, Yitian Ye, Anqi Liu, Zixian Zhang, Xin Peng|<http://arxiv.org/pdf/2504.08431v1>|- 问题：室内养殖环境，导航精度低，激光漂移，视觉导航线提取不准确<br />- 方法：复合导航，激光视觉融合，动态计算融合航向角<br />- 效果：导航精度高，效率提升|
|🆕 发布|Stereophotoclinometry Revisited|立体光测视差重探|Travis Driver, Andrew Vaughan, Yang Cheng, Adnan Ansar, John Christian, Panagiotis Tsiotras|<http://arxiv.org/pdf/2504.08252v1>|- 问题：表面重建，人机交互，先验信息，Stereophotoclinometry<br />- 方法：PhoMo框架，关键点SfM，深度学习匹配，因子图优化<br />- 效果：自主性，精度提升，无需先验信息|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|F$^3$Set: Towards Analyzing Fast, Frequent, and Fine-grained Events from Videos|F$^3$Set：迈向分析视频中的快速、频繁和细粒度事件|Zhaoyu Liu, Kan Jiang, Murong Ma, Zhe Hou, Yun Lin, Jin Song Dong|<http://arxiv.org/pdf/2504.08222v1>|[[代码]](<https://github.com/F3Set/F3Set.>)<br />- 问题：F$^3$事件分析，视频理解，挑战<br />- 方法：F$^3$Set基准，F$^3$ED方法<br />- 效果：性能提升，挑战揭示|


## 自监督学习 (Self-supervised Learning)


### 对比学习 (Contrastive Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Embodied Image Captioning: Self-supervised Learning Agents for Spatially Coherent Image Descriptions|具身图像描述：用于空间一致图像描述的自监督学习智能体|Tommaso Galliena, Tommaso Apicella, Stefano Rosa, Pietro Morerio, Alessio Del Bue, Lorenzo Natale|<http://arxiv.org/pdf/2504.08531v1>|[[代码]](<https://hsp-iit.github.io/embodied-captioning>)<br />- 问题：图像描述一致性，视角变化，噪声数据<br />- 方法：自监督学习，共识机制，伪标签<br />- 效果：语义相似度高，描述准确度提升|
|📝 更新|Video-Driven Graph Network-Based Simulators|基于视频驱动的图网络模拟器|Franciszek Szewczyk, Gilles Louppe, Matthia Sabatelli|<http://arxiv.org/pdf/2409.15344v3>|- 问题：物理模拟，资源需求，参数输入<br />- 方法：视频推断，图网络模拟，轨迹仿真<br />- 效果：物理属性捕获，线性关系|


## 迁移与适应 (Transfer & Adaptation)


### 域适应 (Domain Adaptation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhancing knowledge retention for continual learning with domain-specific adapters and features gating|利用领域特定适配器和特征门控增强持续学习中的知识保留|Mohamed Abbas Hedjazi, Oussama Hadjerci, Adel Hafiane|<http://arxiv.org/pdf/2504.08613v1>|- 问题：灾难性遗忘，知识保留，持续学习<br />- 方法：域特定适配器，特征门控，视觉Transformer<br />- 效果：高精度，参数高效|
|📝 更新|Anti-Forgetting Adaptation for Unsupervised Person Re-identification|对抗遗忘的自监督行人重识别适应性|Hao Chen, Francois Bremond, Nicu Sebe, Shiliang Zhang|<http://arxiv.org/pdf/2411.14695v3>|- 问题：遗忘，泛化，适应性<br />- 方法：DJAA框架，原型一致性，记忆缓冲<br />- 效果：抗遗忘，泛化能力，兼容性|
|📝 更新|Adaptive Hardness-driven Augmentation and Alignment Strategies for Multi-Source Domain Adaptations|自适应硬度驱动增强和对齐策略用于多源域适应|Yang Yuxiang, Zeng Xinyi, Zeng Pinxian, Zu Chen, Yan Binyu, Zhou Jiliu, Wang Yan|<http://arxiv.org/pdf/2501.01142v2>|- 问题：MDA，域适应，数据增强，域对齐，聚类约束<br />- 方法：A3MDA，自适应硬度度量，加权聚类MMD，伪标签<br />- 效果：性能提升，鲁棒性增强|


### 增量学习 (Incremental Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Federated Class-Incremental Learning with Prompting|联邦类增量学习与提示|Xin Luo, Fang-Yi Liang, Jiale Liu, Yu-Wei Zhan, Zhen-Duo Chen, Xin-Shun Xu|<http://arxiv.org/pdf/2310.08948v2>|- 问题：FCIL，数据隐私，非独立同分布，灾难性遗忘<br />- 方法：FCILPT，提示学习，知识编码<br />- 效果：准确率提升，性能优越|
|🆕 发布|Proxy-Anchor and EVT-Driven Continual Learning Method for Generalized Category Discovery|代理锚点和EVT驱动的泛化类别发现持续学习方法|Alireza Fathalizadeh, Roozbeh Razavi-Far|<http://arxiv.org/pdf/2504.08550v1>|- 问题：持续学习，类别发现，遗忘避免<br />- 方法：EVT，代理锚点，概率函数<br />- 效果：性能提升，遗忘减少|
|🆕 发布|CMIP-CIL: A Cross-Modal Benchmark for Image-Point Class Incremental Learning|CMIP-CIL：图像-点类增量学习跨模态基准|Chao Qi, Jianqin Yin, Ren Zhang|<http://arxiv.org/pdf/2504.08422v1>|- 问题：跨模态遗忘，模态差异，图像-点类增量学习<br />- 方法：CMIP-CIL基准，对比学习，原型保留<br />- 效果：SOTA结果，超越基线|
|🆕 发布|Boosting the Class-Incremental Learning in 3D Point Clouds via Zero-Collection-Cost Basic Shape Pre-Training|通过零收集成本的基本形状预训练提升3D点云中的类增量学习|Chao Qi, Jianqin Yin, Meng Chen, Yingchun Niu, Yuan Sun|<http://arxiv.org/pdf/2504.08412v1>|- 问题：3D点云增量学习，灾难性遗忘，预训练数据<br />- 方法：零成本基本形状预训练，3D几何知识嵌入，类别原型调整<br />- 效果：性能提升，基准数据集|


## 鲁棒学习 (Robust Learning)


### 对抗防御 (Adversarial Defense)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Multi-head Ensemble of Smoothed Classifiers for Certified Robustness|多头平滑分类器集成以实现认证鲁棒性|Kun Fang, Qinghua Tao, Yingwen Wu, Tao Li, Xiaolin Huang, Jie Yang|<http://arxiv.org/pdf/2211.10882v2>|- 问题：鲁棒性，计算负担，个体DNN，通信忽略<br />- 方法：SOME，多头结构，圆形通信<br />- 效果：高效，鲁棒|
|🆕 发布|Adversarial Examples in Environment Perception for Automated Driving (Review)|对抗样本在自动驾驶环境感知中的研究（综述）|Jun Yan, Huilin Yin|<http://arxiv.org/pdf/2504.08414v1>|- 问题：对抗样本，自动驾驶，深度学习，鲁棒性<br />- 方法：攻击与防御，综述，应用研究<br />- 效果：风险降低，AI可信|
|🆕 发布|A Knowledge-guided Adversarial Defense for Resisting Malicious Visual Manipulation|基于知识的对抗防御以抵抗恶意视觉操纵|Dawei Zhou, Suzhi Gang, Decheng Liu, Tongliang Liu, Nannan Wang, Xinbo Gao|<http://arxiv.org/pdf/2504.08411v1>|- 问题：恶意视觉操纵，数据仅方法，低级特征空间<br />- 方法：知识引导，语义混淆，感知相关度量<br />- 效果：防御效果佳，泛化能力强|
|📝 更新|Enhancing Lane Segment Perception and Topology Reasoning with Crowdsourcing Trajectory Priors|利用众包轨迹先验增强车道分割感知和拓扑推理|Peijin Jia, Ziang Luo, Tuopu Wen, Mengmeng Yang, Kun Jiang, Le Cui, Diange Yang|<http://arxiv.org/pdf/2411.17161v2>|[[代码]](<https://github.com/wowlza/TrajTopo>)<br />- 问题：车道感知，先验信息，融合，轨迹先验<br />- 方法：轨迹数据，编码，融合模块，置信度<br />- 效果：性能提升，优于现有方法|
|📝 更新|A Robust Real-Time Lane Detection Method with Fog-Enhanced Feature Fusion for Foggy Conditions|一种雾天条件下具有雾增强特征融合的鲁棒实时车道检测方法|Ronghui Zhang, Yuhang Ma, Tengfei Li, Ziyu Lin, Yueying Wu, Junzhou Chen, Lin Zhang, Jia Hu .etc.|<http://arxiv.org/pdf/2504.06121v2>|- 问题：雾天，车道检测，性能下降<br />- 方法：FoggyLane，Fog-Enhanced Network，GFFM，KFFM，LEEM<br />- 效果：高F1分数，实时，鲁棒|


### 对抗攻击 (Adversarial Attack)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|TACO: Adversarial Camouflage Optimization on Trucks to Fool Object Detectors|TACO：针对卡车的对抗性伪装优化以欺骗目标检测器|Adonisz Dimitriu, Tamás Michaletzky, Viktor Remeli|<http://arxiv.org/pdf/2410.21443v2>|- 问题：对抗攻击，目标检测，鲁棒性，3D车辆模型<br />- 方法：TACO框架，可微分渲染，Photorealistic Rendering Network，Convolutional Smooth Loss<br />- 效果：检测性能下降，AP@0.5 0.0099，模型迁移性|
|🆕 发布|EO-VLM: VLM-Guided Energy Overload Attacks on Vision Models|EO-VLM：基于VLM引导的视觉模型能量过载攻击|Minjae Seo, Myoungsung You, Junhee Lee, Jaehan Kim, Hwanjo Heo, Jintae Oh, Jinwoo Kim|<http://arxiv.org/pdf/2504.08205v1>|- 问题：视觉模型，能量消耗，攻击，VLM<br />- 方法：VLM引导，能量过载，模型无关<br />- 效果：能量消耗增加，安全漏洞|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PNE-SGAN: Probabilistic NDT-Enhanced Semantic Graph Attention Network for LiDAR Loop Closure Detection|PNE-SGAN：用于激光雷达闭环检测的概率NDT增强语义图注意力网络|Xiong Li, Shulei Liu, Xingning Chen, Yisong Wu, Dong Zhu|<http://arxiv.org/pdf/2504.08280v1>|- 问题：LiDAR LCD，鲁棒性，精度，几何表示，时间鲁棒性<br />- 方法：PNE-SGAN，NDT，GAT，概率时间滤波，HMM/Bayes<br />- 效果：性能提升，平均精度高|


## 模型压缩加速 (Model Compression & Acceleration)


### 知识蒸馏 (Knowledge Distillation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Knowledge Distillation for Multimodal Egocentric Action Recognition Robust to Missing Modalities|多模态自回归动作识别中对缺失模态鲁棒的知识蒸馏|Maria Santos-Villafranca, Dustin Carrión-Ojeda, Alejandro Perez-Yus, Jesus Bermudez-Cameo, Jose J. Guerrero, Simone Schaub-Meyer|<http://arxiv.org/pdf/2504.08578v1>|- 问题：多模态，缺失模态，鲁棒性，动作识别<br />- 方法：知识蒸馏，预训练模型，学生模型<br />- 效果：处理缺失模态，降低精度下降|
|🆕 发布|Muon-Accelerated Attention Distillation for Real-Time Edge Synthesis via Optimized Latent Diffusion|μ子加速注意力蒸馏：通过优化潜在扩散实现实时边缘合成|Weiye Chen, Qingen Zhu, Qian Long|<http://arxiv.org/pdf/2504.08451v1>|- 问题：实时边缘合成，计算内存限制<br />- 方法：Muon优化器，注意力蒸馏，动态剪枝<br />- 效果：速度提升，质量保持|
|🆕 发布|Knowledge Distillation for Underwater Feature Extraction and Matching via GAN-synthesized Images|基于GAN合成图像的水下特征提取与匹配的知识蒸馏|Jinghe Yang, Mingming Gong, Ye Pu|<http://arxiv.org/pdf/2504.08253v1>|- 问题：水下特征提取，匹配，图像模糊，噪声<br />- 方法：GAN合成图像，知识蒸馏，自适应GAN<br />- 效果：鲁棒性提升，VSLAM应用验证|


## 泛化与鲁棒性 (Generalization & Robustness)


### 域泛化 (Domain Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|On Background Bias of Post-Hoc Concept Embeddings in Computer Vision DNNs|计算机视觉深度神经网络中后处理概念嵌入的背景偏差|Gesina Schwalbe, Georgii Mikriukov, Edgar Heinert, Stavros Gerolymatos, Mert Keser, Alois Knoll, Matthias Rottmann, Annika Mütze|<http://arxiv.org/pdf/2504.08602v1>|- 问题：背景偏差，后处理概念嵌入，DNN<br />- 方法：Net2Vec，背景随机化，概念分割<br />- 效果：背景鲁棒性，性能提升|


### 不确定性建模 (Uncertainty Modeling)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Road Grip Uncertainty Estimation Through Surface State Segmentation|通过表面状态分割进行路面抓地力不确定性估计|Jyri Maanpää, Julius Pesonen, Iaroslav Melekhov, Heikki Hyyti, Juha Hyyppä|<http://arxiv.org/pdf/2504.08452v1>|- 问题：道路抓地力不确定性，自动驾驶，安全控制<br />- 方法：表面状态分割，像素级概率分布，不确定性预测<br />- 效果：预测鲁棒性增强|
|📝 更新|Conformal Prediction and MLLM aided Uncertainty Quantification in Scene Graph Generation|基于共形预测和多层语言模型辅助的场景图生成中的不确定性量化|Sayak Nag, Udita Ghosh, Calvin-Khang Ta, Sarosij Bose, Jiachen Li, Amit K Roy Chowdhury|<http://arxiv.org/pdf/2503.13947v2>|- 问题：场景图生成，不确定性量化，长尾分布<br />- 方法：Conformal Prediction，MLLM后处理，预测集构建<br />- 效果：可靠性评估，性能提升|


## 可解释性 (Interpretability)


### 归因分析 (Attribution Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Task-conditioned Ensemble of Expert Models for Continuous Learning|基于任务条件的专家模型集成实现持续学习|Renu Sharma, Debasmita Pal, Arun Ross|<http://arxiv.org/pdf/2504.08626v1>|[[代码]](<https://github.com/iPRoBe-lab/Continuous_Learning_FE_DM.>)<br />- 问题：非平稳环境，模型准确性，分布偏移，持续学习<br />- 方法：任务条件集成，专家模型，任务成员信息<br />- 效果：性能维持，适应新数据|


## 医学影像分析 (Medical Image Analysis)


### 医学分割 (Medical Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HRDecoder: High-Resolution Decoder Network for Fundus Image Lesion Segmentation|HRDecoder：高分辨率解码网络用于眼底图像病变分割|Ziyuan Ding, Yixiong Liang, Shichao Kan, Qing Liu|<http://arxiv.org/pdf/2411.03976v2>|[[代码]](<https://github.com/CVIU-CSU/HRDecoder.>)<br />- 问题：高分辨率，内存成本，计算开销，小物体分割<br />- 方法：HRDecoder，高分辨率表示学习，多尺度融合<br />- 效果：精度提升，内存合理，速度满意|
|🆕 发布|Hands-On: Segmenting Individual Signs from Continuous Sequences|动手实践：从连续序列中分割单个标志|Low Jian He, Harry Walsh, Ozge Mercanoglu Sincan, Richard Bowden|<http://arxiv.org/pdf/2504.08593v1>|- 问题：连续手语分割，手语翻译，数据标注<br />- 方法：Transformer架构，BIO标签，HaMeR手部特征，3D角度<br />- 效果：DGS Corpus最佳，BIOCorpus超越|
|🆕 发布|Shadow Erosion and Nighttime Adaptability for Camera-Based Automated Driving Applications|基于摄像头自动驾驶应用的阴影侵蚀与夜间适应性|Mohamed Sabry, Gregory Schroeder, Joshua Varughese, Cristina Olaverri-Monreal|<http://arxiv.org/pdf/2504.08551v1>|- 问题：夜间图像增强，阴影消除，自动驾驶<br />- 方法：阴影侵蚀，夜间适应性，色彩纹理保留<br />- 效果：超越CLAHE，YOLO分割算法提升|
|📝 更新|F-LMM: Grounding Frozen Large Multimodal Models|F-LMM：冻结大型多模态模型的扎根|Size Wu, Sheng Jin, Wenwei Zhang, Lumin Xu, Wentao Liu, Wei Li, Chen Change Loy|<http://arxiv.org/pdf/2406.05821v3>|[[代码]](<https://github.com/wusize/F-LMM.>)<br />- 问题：LMM视觉定位，泛化能力弱<br />- 方法：冻结LMM，词像素对应，CNN层<br />- 效果：性能提升，保留对话能力|
|🆕 发布|SN-LiDAR: Semantic Neural Fields for Novel Space-time View LiDAR Synthesis|语义神经场：用于新颖时空视图激光雷达合成的语义神经网络|Yi Chen, Tianchen Deng, Wentao Zhao, Xiaoning Wang, Wenqian Xi, Weidong Chen, Jingchuan Wang|<http://arxiv.org/pdf/2504.08361v1>|[[代码]](<https://github.com/dtc111111/SN-Lidar.>)<br />- 问题：LiDAR点云语义分割，几何重建，合成<br />- 方法：平面网格特征，CNN编码器，语义神经网络场<br />- 效果：语义分割，几何重建，合成|
|🆕 发布|DSM: Building A Diverse Semantic Map for 3D Visual Grounding|DSM：构建一个用于3D视觉定位的多样化语义地图|Qinghongbing Xie, Zijian Liang, Long Zeng|<http://arxiv.org/pdf/2504.08307v1>|- 问题：3D视觉定位，语义信息提取，隐含语义理解<br />- 方法：VLMs，语义图，滑动窗口<br />- 效果：语义分割，3D定位，导航抓取|
|🆕 发布|STSeg-Complex Video Object Segmentation: The 1st Solution for 4th PVUW MOSE Challenge|STSeg-复杂视频目标分割：第四届PVUW MOSE挑战赛的首个解决方案|Kehuan Song, Xinglin Xie, Kexin Zhang, Licheng Jiao, Lingling Li, Shuyuan Yang|<http://arxiv.org/pdf/2504.08306v1>|- 问题：复杂场景视频对象分割，运动复杂，长视频序列<br />- 方法：SAM2微调，TMO无监督模型，自适应伪标签引导<br />- 效果：J&F分数87.26%，第一，技术进步|
|📝 更新|Comprehensive Evaluation of OCT-based Automated Segmentation of Retinal Layer, Fluid and Hyper-Reflective Foci: Impact on Diabetic Retinopathy Severity Assessment|全面评估基于OCT的视网膜层、液体和强反射焦点自动分割：对糖尿病视网膜病变严重程度评估的影响|S. Chen, D. Ma, M. Raviselvan, S. Sundaramoorthy, K. Popuri, M. J. Ju, M. V. Sarunic, D. Ratra .etc.|<http://arxiv.org/pdf/2503.01248v3>|- 问题：糖尿病视网膜病变，OCT自动分割，复杂模式<br />- 方法：深度学习，主动学习，多模型融合<br />- 效果：高精度，层特异性，临床应用|
|📝 更新|TwinLiteNetPlus: A Real-Time Multi-Task Segmentation Model for Autonomous Driving|TwinLiteNetPlus：面向自动驾驶的实时多任务分割模型|Quang-Huy Che, Duc-Tri Le, Minh-Quan Pham, Vinh-Tiep Nguyen, Duc-Khai Lam|<http://arxiv.org/pdf/2403.16958v4>|[[代码]](<https://github.com/chequanghuy/TwinLiteNetPlus.>)<br />- 问题：自动驾驶，语义分割，计算成本高<br />- 方法：TwinLiteNetPlus，分离卷积，多配置<br />- 效果：高精度，低FLOPs，实时性|
|🆕 发布|SynthFM: Training Modality-agnostic Foundation Models for Medical Image Segmentation without Real Medical Data|SynthFM：在无真实医学数据的情况下，训练适用于医学图像分割的无模态基础模型|Sourya Sengupta, Satrajit Chakrabarty, Keerthi Sravan Ravi, Gopal Avinash, Ravi Soni|<http://arxiv.org/pdf/2504.08177v1>|- 问题：医学图像分割，数据标注困难，模型泛化差<br />- 方法：合成数据生成，模态无关，SAM预训练<br />- 效果：超越基线，泛化能力强|


### 疾病诊断 (Disease Diagnosis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Latent Diffusion Autoencoders: Toward Efficient and Meaningful Unsupervised Representation Learning in Medical Imaging|潜在扩散自编码器：迈向医学图像中高效且具有意义的无监督表征学习|Gabriele Lozupone, Alessandro Bria, Francesco Fontanella, Frederick J. A. Meijer, Claudio De Stefano, Henkjan Huisman|<http://arxiv.org/pdf/2504.08635v1>|[[代码]](<https://github.com/GabrieleLozupone/LDAE>)<br />- 问题：医学图像，无监督学习，表示学习<br />- 方法：潜在扩散自编码器，压缩表示，3D医学图像<br />- 效果：诊断性能高，图像重建质量好，计算效率高|
|🆕 发布|Boosting multi-demographic federated learning for chest x-ray analysis using general-purpose self-supervised representations|提升多人口统计学联邦学习用于胸部X光分析的通用自监督表示|Mahshad Lotfinia, Arash Tayebiarasteh, Samaneh Samiei, Mehdi Joodaki, Soroosh Tayebi Arasteh|<http://arxiv.org/pdf/2504.08584v1>|- 问题：非独立同分布，联邦学习，儿科数据，数据稀缺<br />- 方法：通用自监督表示，迁移学习，视觉Transformer<br />- 效果：性能提升，儿科应用，患者结果改善|
|🆕 发布|A Hybrid Fully Convolutional CNN-Transformer Model for Inherently Interpretable Medical Image Classification|混合全卷积CNN-Transformer模型用于本质可解释的医学图像分类|Kerol Djoumessi, Samuel Ofosu Mensah, Philipp Berens|<http://arxiv.org/pdf/2504.08481v1>|- 问题：CNN-ViT模型可解释性差，医疗图像分类<br />- 方法：混合CNN-Transformer架构，生成证据图<br />- 效果：性能领先，可解释性高|


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Self-supervised Learning of LiDAR 3D Point Clouds via 2D-3D Neural Calibration|基于2D-3D神经网络校准的自监督LiDAR 3D点云学习|Yifan Zhang, Siyu Ren, Junhui Hou, Jinjian Wu, Yixuan Yuan, Guangming Shi|<http://arxiv.org/pdf/2401.12452v4>|[[代码]](<https://github.com/Eaphan/NCLR.>)<br />- 问题：3D感知，自监督学习，LiDAR点云<br />- 方法：2D-3D神经校准，特征统一空间，密集对应<br />- 效果：语义分割，物体检测，泛化能力|


## 智能驾驶 (Intelligent Driving)


### 环境感知 (Environment Perception)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Datasets for Lane Detection in Autonomous Driving: A Comprehensive Review|自动驾驶车道检测数据集：全面综述|Jörg Gamerdinger, Sven Teufel, Oliver Bringmann|<http://arxiv.org/pdf/2504.08540v1>|- 问题：车道检测，数据集，算法评估<br />- 方法：综合回顾，分类分析，挑战识别<br />- 效果：资源提供，创新驱动|


## 工业视觉 (Industrial Vision)


### 质量控制 (Quality Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Title block detection and information extraction for enhanced building drawings search|建筑图纸增强搜索中的块检测与信息提取|Alessio Lombardi, Li Duan, Ahmed Elnagar, Ahmed Zaalouk, Khalid Ismail, Edlira Vakaj|<http://arxiv.org/pdf/2504.08645v1>|- 问题：信息提取，历史建筑，标题块，搜索简化<br />- 方法：CNN，GPT-4o，检测，结构化提取<br />- 效果：高精度，效率提升，时间节省|


### 工业测量 (Industrial Measurement)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Poisson multi-Bernoulli mixture filter for trajectory measurements|泊松多伯努利混合滤波器在轨迹测量中的应用|Marco Fontana, Ángel F. García-Fernández, Simon Maskell|<http://arxiv.org/pdf/2504.08421v1>|- 问题：多目标跟踪，轨迹测量，滤波<br />- 方法：PMBM滤波，轨迹测量PMBM，KL散度最小化<br />- 效果：封闭形式解，状态估计|


## 其他 (Others)


### 其他

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Banana Ripeness Level Classification using a Simple CNN Model Trained with Real and Synthetic Datasets|香蕉成熟度等级分类：使用真实和合成数据集训练的简单CNN模型|Luis Chuquimarca, Boris Vintimilla, Sergio Velastin|<http://arxiv.org/pdf/2504.08568v1>|- 问题：香蕉成熟度评估，数据不足，CNN模型<br />- 方法：合成数据生成，简单CNN架构，迁移学习<br />- 效果：高精度，快速执行|
|🆕 发布|Comparative Analysis of Different Methods for Classifying Polychromatic Sketches|不同多色草图分类方法的比较分析|Fahd Baba, Devon Mack|<http://arxiv.org/pdf/2504.08186v1>|- 问题：多色草图分类，机器视觉，人类能力<br />- 方法：数据集构建，机器学习，分类模型<br />- 效果：模型准确率，超越人类|

