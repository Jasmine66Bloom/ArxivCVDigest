## [UPDATED!] **2025-04-22** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SignX: The Foundation Model for Sign Recognition|SignX：手语识别的基础模型|Sen Fang, Chunyu Sui, Hongwei Yi, Carol Neidle, Dimitris N. Metaxas|<http://arxiv.org/pdf/2504.16315v1>|提出SignX模型，通过融合多源姿态信息和视频直接转换，实现更准确的美国手语识别。|
|🆕 发布|Visual Place Cell Encoding: A Computational Model for Spatial Representation and Cognitive Mapping|视觉空间细胞编码：一种用于空间表征和认知映射的计算模型|Chance J. Hamilton, Alfredo Weitzenfeld|<http://arxiv.org/pdf/2504.15953v1>|提出VPCE模型，通过视觉地标聚类模拟生物空间细胞，实现空间认知映射。|
|📝 更新|AFiRe: Anatomy-Driven Self-Supervised Learning for Fine-Grained Representation in Radiographic Images|AFiRe：基于解剖学的自监督学习在放射影像中的细粒度表征|Yihang Liu, Lianghua He, Ying Wen, Longzhen Yang, Hongzhou Chen|<http://arxiv.org/pdf/2504.10972v2>|分类图像中的细微解剖细节，AFiRe通过结合解剖引导的对比学习和异常去除恢复，提升了放射图像的精细表...|
|🆕 发布|DINOv2-powered Few-Shot Semantic Segmentation: A Unified Framework via Cross-Model Distillation and 4D Correlation Mining|DINOv2驱动的少样本语义分割：通过跨模型蒸馏和4D相关性挖掘的统一框架|Wei Zhuo, Zhiyue Tang, Wufeng Xue, Hao Ding, Linlin Shen|<http://arxiv.org/pdf/2504.15669v1>|提出FS-DINO，通过跨模型蒸馏和4D关联挖掘，实现轻量级语义分割，有效解决数据稀缺问题。|
|📝 更新|Harmonizing Visual Representations for Unified Multimodal Understanding and Generation|视觉表示的和谐统一多模态理解和生成|Size Wu, Wenwei Zhang, Lumin Xu, Sheng Jin, Zhonghua Wu, Qingyi Tao, Wentao Liu, Wei Li .etc.|<http://arxiv.org/pdf/2503.21979v2>|[代码](https://github.com/wusize/Harmon.); 提出Harmon模型，通过共享掩码自回归编码器实现视觉理解和生成任务的统一。|
|📝 更新|Manipulating Multimodal Agents via Cross-Modal Prompt Injection|通过跨模态提示注入操纵多模态智能体|Le Wang, Zonghao Ying, Tianyuan Zhang, Siyuan Liang, Shengshan Hu, Mingchuan Zhang, Aishan Liu, Xianglong Liu|<http://arxiv.org/pdf/2504.14348v2>|提出了一种针对多模态智能体跨模态提示注入攻击的攻击框架，有效提升了攻击成功率。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Boosting Generative Image Modeling via Joint Image-Feature Synthesis|通过联合图像-特征合成增强生成图像建模|Theodoros Kouzelis, Efstathios Karypidis, Ioannis Kakogeorgiou, Spyros Gidaris, Nikos Komodakis|<http://arxiv.org/pdf/2504.16064v1>|提出了一种联合图像特征合成的生成图像建模框架，显著提升生成质量和训练效率。|
|📝 更新|Prompting Depth Anything for 4K Resolution Accurate Metric Depth Estimation|深度任何物：针对4K分辨率精确度量深度估计的提示|Haotong Lin, Sida Peng, Jingxiao Chen, Songyou Peng, Jiaming Sun, Minghuan Liu, Hujun Bao, Jiashi Feng .etc.|<http://arxiv.org/pdf/2412.14015v2>|引入提示技术，结合LiDAR数据，实现高分辨率精确深度估计。|
|📝 更新|Enhancing Features in Long-tailed Data Using Large Vision Model|利用大型视觉模型增强长尾数据中的特征|Pengxiao Han, Changkun Ye, Jinguang Tong, Cuicui Jiang, Jie Hong, Li Fang, Xuesong Li|<http://arxiv.org/pdf/2504.10852v2>|利用大型视觉模型增强长尾数据特征，提升长尾识别性能。|
|🆕 发布|Text-based Animatable 3D Avatars with Morphable Model Alignment|基于可变形模型对齐的文本可动3D头像|Yiqian Wu, Malte Prinzler, Xiaogang Jin, Siyu Tang|<http://arxiv.org/pdf/2504.15835v1>|提出了一种结合预训练模型和语义对齐的框架，有效生成逼真的可动3D头像。|
|📝 更新|MObI: Multimodal Object Inpainting Using Diffusion Models|MObI：基于扩散模型的跨模态物体修复|Alexandru Buburuzan, Anuj Sharma, John Redford, Puneet K. Dokania, Romain Mueller|<http://arxiv.org/pdf/2501.03173v2>|MObI利用扩散模型实现多模态物体修复，准确插入新物体至场景，提升感知模型测试效果。|
|🆕 发布|Vidi: Large Multimodal Models for Video Understanding and Editing|视频理解与编辑的大规模多模态模型：Vidi|Vidi Team, Celong Liu, Chia-Wen Kuo, Dawei Du, Fan Chen, Guang Chen, Jiamin Yuan, Lingxi Zhang .etc.|<http://arxiv.org/pdf/2504.15681v2>|Vidi提出了一种处理长视频多模态信息的大规模模型，显著提升了视频编辑中的时间检索能力。|
|🆕 发布|ZeroSlide: Is Zero-Shot Classification Adequate for Lifelong Learning in Whole-Slide Image Analysis in the Era of Pathology Vision-Language Foundation Models?|零滑移：在病理视觉-语言基础模型时代，零样本分类是否足以支持全切片图像分析的终身学习？|Doanh C. Bui, Hoai Luan Pham, Vu Trung Duong Le, Tuan Hai Vu, Van Duy Tran, Yasuhiko Nakashima|<http://arxiv.org/pdf/2504.15627v1>|首次比较了传统持续学习方法与视觉语言零样本分类在终身学习全切片图像分析中的应用。|
|🆕 发布|FaceInsight: A Multimodal Large Language Model for Face Perception|面部洞察：一种用于面部感知的多模态大型语言模型|Jingzhi Li, Changjiang Luo, Ruoyu Chen, Hua Zhang, Wenqi Ren, Jianhou Gan, Xiaochun Cao|<http://arxiv.org/pdf/2504.15624v1>|FaceInsight通过融合视觉和文本信息，显著提升了面对感知任务的准确性。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Onboard Satellite Image Classification for Earth Observation: A Comparative Study of ViT Models|卫星图像地球观测的机载分类：ViT模型的比较研究|Thanh-Dung Le, Vu Nguyen Ha, Ti Ti Nguyen, Geoffrey Eappen, Prabhu Thiruvasagam, Hong-fu Chou, Duc-Dung Tran, Hung Nguyen-Kha .etc.|<http://arxiv.org/pdf/2409.03901v3>|提出了一种基于ViT模型的卫星图像分类方法，显著提升了分类准确性和效率。|
|🆕 发布|AdaViP: Aligning Multi-modal LLMs via Adaptive Vision-enhanced Preference Optimization|AdaViP：通过自适应视觉增强偏好优化对多模态LLMs进行对齐|Jinda Lu, Jinghan Li, Yuan Gao, Junkang Wu, Jiancan Wu, Xiang Wang, Xiangnan He|<http://arxiv.org/pdf/2504.15619v1>|AdaViP通过视觉增强和自适应优化，有效提升了多模态LLMs与人类偏好的对齐准确性。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DeepCS-TRD, a Deep Learning-based Cross-Section Tree Ring Detector|深度CS-TRD：一种基于深度学习的横截面年轮检测器|Henry Marichal, Verónica Casaravilla, Candice Power, Karolain Mello, Joaquín Mazarino, Christine Lucas, Ludmila Profumo, Diego Passarella .etc.|<http://arxiv.org/pdf/2504.16242v1>|[代码](https://github.com/hmarichal93/deepcstrd); 提出了一种基于深度学习的树轮检测算法，可应用于不同图像领域和物种，并优于现有方法。|
|🆕 发布|Benchmarking the Reproducibility of Brain MRI Segmentation Across Scanners and Time|脑部MRI分割在扫描器和时间上的可重复性基准测试|Ekaterina Kondrateva, Sandzhi Barg, Mikhail Vasiliev|<http://arxiv.org/pdf/2504.15931v1>|[代码](https://github.com/kondratevakate/brain-mri-segmentation); 评估了脑MRI分割的重复性，提出基于表面的质量过滤策略以提升分割可靠性。|
|📝 更新|PIDSR: Complementary Polarized Image Demosaicing and Super-Resolution|PIDSR：互补偏振图像去马赛克和超分辨率|Shuangfan Zhou, Chu Zhou, Youwei Lyu, Heng Guo, Zhanyu Ma, Boxin Shi, Imari Sato|<http://arxiv.org/pdf/2504.07758v2>|提出PIDSR，一种联合去马赛克和超分辨率框架，有效提升极化图像质量并准确恢复极化参数。|
|🆕 发布|GADS: A Super Lightweight Model for Head Pose Estimation|GADS：一种超轻量级的头部姿态估计模型|Menan Velayuthan, Asiri Gawesha, Purushoth Velayuthan, Nuwan Kodagoda, Dharshana Kasthurirathna, Pradeepa Samarasinghe|<http://arxiv.org/pdf/2504.15751v1>|提出GADS模型，通过区域分组和轻量级Deep Set层，显著降低头部姿态估计的计算复杂度和模型大小...|
|🆕 发布|Multi-Scale Tensorial Summation and Dimensional Reduction Guided Neural Network for Edge Detection|多尺度张量求和与降维引导神经网络用于边缘检测|Lei Xu, Mehmet Yamac, Mete Ahishali, Moncef Gabbouj|<http://arxiv.org/pdf/2504.15770v1>|[代码](https://github.com/LeiXuAI/MTS-DR-Net.git.); 提出了一种基于多尺度张量求和的神经网络，有效提升了边缘检测性能。|
|📝 更新|Unsupervised Hyperspectral and Multispectral Image Fusion via Self-Supervised Modality Decoupling|无监督超光谱和多光谱图像融合通过自监督模态解耦|Songcheng Du, Yang Zou, Zixu Wang, Xingyuan Li, Ying Li, Changjing Shang, Qiang Shen|<http://arxiv.org/pdf/2412.04802v3>|[代码](https://github.com/dusongcheng/MossFuse); 提出了一种通过模态解耦进行无监督高光谱和多光谱图像融合的方法，显著提升了融合性能。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Semantic Segmentation and Scene Reconstruction of RGB-D Image Frames: An End-to-End Modular Pipeline for Robotic Applications|语义分割与RGB-D图像帧场景重建：适用于机器人应用的端到端模块化流程|Zhiwu Zheng, Lauren Mentzer, Berk Iskender, Michael Price, Colm Prendergast, Audren Cloitre|<http://arxiv.org/pdf/2410.17988v2>|提出了一种集成语义分割、场景重建的模块化管道，提升机器人对无结构环境的感知与交互能力。|
|🆕 发布|MS-Occ: Multi-Stage LiDAR-Camera Fusion for 3D Semantic Occupancy Prediction|MS-Occ：多阶段激光雷达-相机融合三维语义占用预测|Zhiqiang Wei, Lianqing Zheng, Jianan Liu, Tao Huang, Qing-Long Han, Wenwen Zhang, Fengdeng Zhang|<http://arxiv.org/pdf/2504.15888v1>|MS-Occ通过多阶段融合LiDAR和相机数据，显著提升了3D语义占用预测的准确性。|
|🆕 发布|Development and evaluation of a deep learning algorithm for German word recognition from lip movements|德国唇语识别的深度学习算法的开发与评估|Dinh Nam Pham, Torsten Rahne|<http://arxiv.org/pdf/2504.15792v1>|开发了一种针对德语唇语识别的深度学习算法，显著提升了识别准确率。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Efficient Adaptation of Deep Neural Networks for Semantic Segmentation in Space Applications|高效适应空间应用中语义分割的深度神经网络|Leonardo Olivi, Edoardo Santero Mormile, Enzo Tartaglione|<http://arxiv.org/pdf/2504.15991v1>|提出了一种高效迁移学习方法，通过适配器降低深度神经网络在空间应用中的带宽和内存需求。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|You Sense Only Once Beneath: Ultra-Light Real-Time Underwater Object Detection|仅下潜一次感知：超轻量级实时水下目标检测|Jun Dong, Wenli Wu, Jintao Cheng, Xiaoyu Tang|<http://arxiv.org/pdf/2504.15694v1>|提出YSOOB框架，通过多光谱小波编码和轻量级网络设计，实现高效水下物体检测。|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Dynamic EventNeRF: Reconstructing General Dynamic Scenes from Multi-view RGB and Event Streams|动态事件NeRF：从多视角RGB和事件流重建通用动态场景|Viktor Rudnev, Gereon Fox, Mohamed Elgharib, Christian Theobalt, Vladislav Golyanik|<http://arxiv.org/pdf/2412.06770v2>|提出了一种从多视角事件流和RGB帧重建动态场景的新方法，显著提升了动态场景重建效果。|
|📝 更新|Bayesian Cross-Modal Alignment Learning for Few-Shot Out-of-Distribution Generalization|贝叶斯跨模态对齐学习用于小样本分布外泛化|Lin Zhu, Xinbing Wang, Chenghu Zhou, Nanyang Ye|<http://arxiv.org/pdf/2504.09448v2>|[代码](https://github.com/LinLLLL/BayesCAL.); 提出了一种基于贝叶斯模型的跨模态图像-文本对齐方法，有效提升了少量样本下的分布外泛化能力。|
|📝 更新|EmoSEM: Segment and Explain Emotion Stimuli in Visual Art|情感视觉艺术中的分割与解释情绪刺激：EmoSEM|Jing Zhang, Dan Guo, Zhangbin Li, Meng Wang|<http://arxiv.org/pdf/2504.14658v2>|提出EmoSEM模型，通过情感引导和语义理解实现艺术作品中情感刺激的细粒度分割与解释。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Enhancing Low-Cost Video Editing with Lightweight Adaptors and Temporal-Aware Inversion|提升低成本视频编辑性能：轻量级适配器和时间感知逆变换|Yangfan He, Sida Li, Jianhui Wang, Kun Li, Xinyuan Song, Xinhang Yuan, Keqin Li, Kuan Lu .etc.|<http://arxiv.org/pdf/2501.04606v3>|提出GE-Adapter，通过融合时空和语义一致性，显著提升低成本视频编辑的时序连贯性和图像质量。|
|📝 更新|UniVG: A Generalist Diffusion Model for Unified Image Generation and Editing|统一图像生成与编辑的通用扩散模型：UniVG|Tsu-Jui Fu, Yusu Qian, Chen Chen, Wenze Hu, Zhe Gan, Yinfei Yang|<http://arxiv.org/pdf/2503.12652v2>|提出UniVG，一种通用扩散模型，实现统一图像生成与编辑，支持多任务处理。|
|🆕 发布|Efficient Temporal Consistency in Diffusion-Based Video Editing with Adaptor Modules: A Theoretical Framework|基于扩散的视频编辑中自适应模块的高效时序一致性：一个理论框架|Xinyuan Song, Yangfan He, Sida Li, Jianhui Wang, Hongyang He, Xinhang Yuan, Ruoyu Wang, Jiaqi Chen .etc.|<http://arxiv.org/pdf/2504.16016v1>|提出了一种基于适配模块的扩散模型，有效提升了视频编辑中的帧间一致性。|
|🆕 发布|FreeGraftor: Training-Free Cross-Image Feature Grafting for Subject-Driven Text-to-Image Generation|FreeGraftor：无需训练的跨图像特征移植，用于主题驱动的文本到图像生成|Zebin Yao, Lei Ren, Huixing Jiang, Chen Wei, Xiaojie Wang, Ruifan Li, Fangxiang Feng|<http://arxiv.org/pdf/2504.15958v1>|[代码](https://github.com/Nihukat/FreeGraftor.); FreeGraftor通过跨图像特征嫁接，实现无需训练的跨图像特征嫁接，精准传递主题身份并保持文本对...|
|🆕 发布|Reasoning Physical Video Generation with Diffusion Timestep Tokens via Reinforcement Learning|基于强化学习的扩散时间步标记推理物理视频生成|Wang Lin, Liyu Jia, Wentao Hu, Kaihang Pan, Zhongqi Yue, Wei Zhao, Jingyuan Chen, Fei Wu .etc.|<http://arxiv.org/pdf/2504.15932v1>|通过结合符号推理和强化学习，提出了一种基于扩散时间步标记的物理视频生成方法，确保生成视频符合物理规律...|
|🆕 发布|Satellite to GroundScape -- Large-scale Consistent Ground View Generation from Satellite Views|卫星至地面景观——从卫星图像生成大规模一致地面视图|Ningli Xu, Rongjun Qin|<http://arxiv.org/pdf/2504.15786v1>|提出了一种基于卫星图像生成地面视图的新方法，确保多视角输出的一致性和高真实感。|
|📝 更新|HoLa: B-Rep Generation using a Holistic Latent Representation|HoLa：基于整体潜在表示的B-Rep生成|Yilin Liu, Duoteng Xu, Xingyao Yu, Xiang Xu, Daniel Cohen-Or, Hao Zhang, Hui Huang|<http://arxiv.org/pdf/2504.14257v2>|提出了一种基于整体潜在表示的B-Rep生成方法，显著提升了CAD模型生成效率和准确性。|
|📝 更新|VistaDepth: Frequency Modulation With Bias Reweighting For Enhanced Long-Range Depth Estimation|视界深度：基于偏置重加权频率调制以增强长距离深度估计|Mingxia Zhan, Li Zhang, Xiaomeng Chu, Beibei Wang|<http://arxiv.org/pdf/2504.15095v2>|VistaDepth通过自适应频率域特征增强和权重平衡机制，显著提升了长距离深度估计的准确性。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Describe Anything: Detailed Localized Image and Video Captioning|描述一切：详细定位的图像和视频字幕|Long Lian, Yifan Ding, Yunhao Ge, Sifei Liu, Hanzi Mao, Boyi Li, Marco Pavone, Ming-Yu Liu .etc.|<http://arxiv.org/pdf/2504.16072v1>|提出DAM模型，通过焦点提示和定位视觉骨干，实现图像和视频的详细定位描述。|
|🆕 发布|Survey of Video Diffusion Models: Foundations, Implementations, and Applications|视频扩散模型综述：基础、实现与应用|Yimu Wang, Xuye Liu, Wei Pang, Li Ma, Shuai Yuan, Paul Debevec, Ning Yu|<http://arxiv.org/pdf/2504.16081v1>|[代码](https://github.com/Eyeline-Research/Survey-Video-Diffusion.); 全面综述了视频扩散模型，提出了一种更全面、更新、细致的方法，解决了视频生成中的运动一致性、计算效率和...|
|🆕 发布|From Reflection to Perfection: Scaling Inference-Time Optimization for Text-to-Image Diffusion Models via Reflection Tuning|从反射到完美：通过反射调优扩展文本到图像扩散模型的推理时间优化|Le Zhuo, Liangbing Zhao, Sayak Paul, Yue Liao, Renrui Zhang, Yi Xin, Peng Gao, Mohamed Elhoseiny .etc.|<http://arxiv.org/pdf/2504.16080v1>|提出ReflectionFlow，通过反射调优显著提升文本到图像扩散模型在复杂场景和细节上的生成质量...|
|📝 更新|Red Team Diffuser: Exposing Toxic Continuation Vulnerabilities in Vision-Language Models via Reinforcement Learning|红队扩散器：通过强化学习揭示视觉-语言模型中的毒性延续漏洞|Ruofan Wang, Xiang Zheng, Xiaosen Wang, Cong Wang, Xingjun Ma|<http://arxiv.org/pdf/2503.06223v2>|提出Red Team Diffuser，通过强化学习揭示并利用视觉语言模型中的有害文本延续漏洞。|
|🆕 发布|Structure-Preserving Zero-Shot Image Editing via Stage-Wise Latent Injection in Diffusion Models|结构保持零样本图像编辑：通过扩散模型中的阶段式潜在注入|Dasol Jeong, Donggoo Kang, Jiwon Park, Hyebean Lee, Joonki Paik|<http://arxiv.org/pdf/2504.15723v1>|提出了一种无需微调的零样本图像编辑框架，通过分阶段潜变量注入和跨注意力机制实现结构保持和语义对齐。|
|🆕 发布|DiTPainter: Efficient Video Inpainting with Diffusion Transformers|DiTPainter：基于扩散变换器的有效视频修复|Xian Wu, Chang Liu|<http://arxiv.org/pdf/2504.15661v1>|DiTPainter利用轻量级Diffusion Transformer模型，高效解决视频修复模糊和...|
|🆕 发布|AffordanceSAM: Segment Anything Once More in Affordance Grounding|affordanceSAM：在可及性定位中再次进行任何事物的分割|Dengyang Jiang, Mengmeng Wang, Teli Ma, Hengzhuang Li, Yong liu, Guang Dai, Lei Zhang|<http://arxiv.org/pdf/2504.15650v1>|AffordanceSAM通过扩展SAM的泛化能力，有效提升了未见对象和功能识别的泛化能力。|
|📝 更新|Gungnir: Exploiting Stylistic Features in Images for Backdoor Attacks on Diffusion Models|Gungnir：利用图像风格特征对扩散模型进行后门攻击|Yu Pan, Bingrong Dai, Jiahao Chen, Lin Wang, Yi Du, Jiao Liu|<http://arxiv.org/pdf/2502.20650v2>|[代码](https://github.com/paoche11/Gungnir.); 提出Gungnir，利用图像风格特征进行扩散模型后门攻击，绕过现有防御方法。|
|🆕 发布|VLM-based Prompts as the Optimal Assistant for Unpaired Histopathology Virtual Staining|基于VLM的提示作为无配对病理学虚拟染色的最佳助手|Zizhi Chen, Xinyu Zhang, Minghao Han, Yizhou Liu, Ziyun Qian, Weifeng Zhang, Xukun Zhang, Jingwei Wei .etc.|<http://arxiv.org/pdf/2504.15545v1>|[代码](https://github.com/CZZZZZZZZZZZZZZZZZ/VPGAN-HARBOR); 引入病理视觉语言大模型，结合对比学习提示和数据增强，提升无配对病理切片虚拟染色效果。|
|🆕 发布|InstaRevive: One-Step Image Enhancement via Dynamic Score Matching|InstaRevive：通过动态得分匹配的一步图像增强|Yixuan Zhu, Haolin Wang, Ao Li, Wenliang Zhao, Yansong Tang, Jingxuan Niu, Lei Chen, Jie Zhou .etc.|<http://arxiv.org/pdf/2504.15513v1>|[代码](https://github.com/EternalEvan/InstaRevive.); InstaRevive通过动态分数匹配和扩散蒸馏，实现了一步式高效图像增强。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LiveXiv -- A Multi-Modal Live Benchmark Based on Arxiv Papers Content|LiveXiv —— 基于Arxiv论文内容的跨模态实时基准|Nimrod Shabtay, Felipe Maia Polo, Sivan Doveh, Wei Lin, M. Jehanzeb Mirza, Leshem Chosen, Mikhail Yurochkin, Yuekai Sun .etc.|<http://arxiv.org/pdf/2410.10783v3>|提出LiveXiv，基于ArXiv论文内容构建的动态多模态基准，以评估模型真实能力并降低评估成本。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DERD-Net: Learning Depth from Event-based Ray Densities|基于事件射线密度的深度学习|Diego de Oliveira Hitzges, Suman Ghosh, Guillermo Gallego|<http://arxiv.org/pdf/2504.15863v1>|[代码](https://github.com/tub-rip/DERD-Net); 提出DERD-Net，通过深度学习从事件相机数据中学习深度，显著提升单目和立体场景的深度估计精度。|
|🆕 发布|DSDNet: Raw Domain Demoiréing via Dual Color-Space Synergy|DSDNet：通过双色彩空间协同的原始域去噪|Qirui Yang, Fangpu Zhang, Yeying Jin, Qihua Cheng, Pengtao Jiang, Huanjing Yue, Jingyu Yang|<http://arxiv.org/pdf/2504.15756v1>|[代码](https://xxxxxxxxdsdnet.github.io/DSDNet); 提出DSDNet，通过融合原始和YCbCr图像，实现屏幕拍摄图像摩尔纹去除，同时保持亮度与色彩真实度...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Normal-guided Detail-Preserving Neural Implicit Function for High-Fidelity 3D Surface Reconstruction|基于正常向引导的细节保留神经隐式函数的高保真3D表面重建|Aarya Patel, Hamid Laga, Ojaswa Sharma|<http://arxiv.org/pdf/2406.04861v2>|利用表面法线引导神经网络隐函数，实现高保真3D表面重建，有效捕捉细节和薄结构。|
|🆕 发布|Model-based Metric 3D Shape and Motion Reconstruction of Wild Bottlenose Dolphins in Drone-Shot Videos|基于模型的无人机视频野生瓶鼻海豚三维形状和运动重建|Daniele Baieri, Riccardo Cicciarella, Michael Krützen, Emanuele Rodolà, Silvia Zuffi|<http://arxiv.org/pdf/2504.15782v1>|提出了一种基于模型和透射模型的方法，从无人机视频估计野生海豚的3D形状和运动。|
|📝 更新|DRAWER: Digital Reconstruction and Articulation With Environment Realism|数字重建与环境真实感下的绘制器|Hongchi Xia, Entong Su, Marius Memmel, Arhan Jain, Raymond Yu, Numfor Mbiziwo-Tiapo, Ali Farhadi, Abhishek Gupta .etc.|<http://arxiv.org/pdf/2504.15278v2>|DRAWER通过双场景表示和关节识别，将静态室内场景视频转换为实时互动的逼真数字环境。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|3DGR-CT: Sparse-View CT Reconstruction with a 3D Gaussian Representation|3DGR-CT：基于3D高斯表示的稀疏视图CT重建|Yingtai Li, Xueming Fu, Han Li, Shang Zhao, Ruiyang Jin, S. Kevin Zhou|<http://arxiv.org/pdf/2312.15676v2>|提出了一种基于3D高斯表示的稀疏视图CT重建方法，显著提升了重建精度和速度。|
|🆕 发布|Motion-Enhanced Nonlocal Similarity Implicit Neural Representation for Infrared Dim and Small Target Detection|运动增强非局部相似性隐式神经网络表示用于红外暗小目标检测|Pei Liu, Yisi Luo, Wenzhen Wang, Xiangyong Cao|<http://arxiv.org/pdf/2504.15665v1>|提出了一种融合运动估计和非局部相似性的隐式神经网络表示方法，有效提升了红外弱小目标检测性能。|
|📝 更新|ThermalGaussian: Thermal 3D Gaussian Splatting|热高斯：热3D高斯分层渲染|Rongfeng Lu, Hangyu Chen, Zunjie Zhu, Yuhang Qin, Ming Lu, Le Zhang, Chenggang Yan, Anke Xue|<http://arxiv.org/pdf/2409.07200v2>|[代码](https://thermalgaussian.github.io/.); 提出ThermalGaussian，首个实现高质量热成像渲染的3D高斯分层方法。|
|📝 更新|Faster and Better 3D Splatting via Group Training|更快速、更优的3D Splatting通过组训练|Chengbo Wang, Guozheng Ma, Yifei Xue, Yizhen Lao|<http://arxiv.org/pdf/2412.07608v2>|通过将3D高斯散点分组训练，显著提升3D场景重建的训练效率和渲染质量。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MetaHarm: Harmful YouTube Video Dataset Annotated by Domain Experts, GPT-4-Turbo, and Crowdworkers|MetaHarm：由领域专家、GPT-4-Turbo和众包工作者标注的有害YouTube视频数据集|Wonjeong Jo, Magdalena Wojcieszak|<http://arxiv.org/pdf/2504.16304v1>|构建了标注专家、GPT-4-Turbo和众包工作者共同标注的YouTube有害视频数据集，助力有害内...|
|🆕 发布|MR. Video: "MapReduce" is the Principle for Long Video Understanding|MR. Video：以“MapReduce”为原则的长视频理解|Ziqi Pang, Yu-Xiong Wang|<http://arxiv.org/pdf/2504.16082v1>|[代码](https://github.com/ziqipang/MR-Video); 提出MR. Video框架，通过MapReduce原理提升长视频理解能力。|
|🆕 发布|LiveCC: Learning Video LLM with Streaming Speech Transcription at Scale|实时CC：大规模学习带有流式语音转录的视频LLM|Joya Chen, Ziyun Zeng, Yiqi Lin, Wei Li, Zejun Ma, Mike Zheng Shou|<http://arxiv.org/pdf/2504.16030v1>|[代码](https://showlab.github.io/livecc.); 提出了一种利用自动语音识别转录大规模训练视频LLM的方法，显著提升了模型性能和泛化能力。|
|🆕 发布|MVQA: Mamba with Unified Sampling for Efficient Video Quality Assessment|MVQA：基于统一采样的Mamba高效视频质量评估|Yachun Mi, Yu Li, Weicheng Meng, Chaofeng Chen, Chen Hui, Shaohui Liu|<http://arxiv.org/pdf/2504.16003v1>|提出MVQA模型，结合Mamba和USDS方法，高效评估视频质量。|
|🆕 发布|ViSMaP: Unsupervised Hour-long Video Summarisation by Meta-Prompting|ViSMaP：通过元提示的无监督一小时视频摘要|Jian Hu, Dimitrios Korkinof, Shaogang Gong, Mariano Beguerisse-Diaz|<http://arxiv.org/pdf/2504.15921v1>|ViSMaP通过元提示策略，实现无监督长视频自动摘要，无需标注，性能与全监督模型相当。|
|📝 更新|Switch-a-View: View Selection Learned from Unlabeled In-the-wild Videos|切换视图：从无标签的真实世界视频中学习视图选择|Sagnik Majumder, Tushar Nagarajan, Ziad Al-Halah, Kristen Grauman|<http://arxiv.org/pdf/2412.18386v3>|Switch-a-View通过学习从无标签视频中自动选择显示视角，为如何视频制作提供了一种新颖的视角...|
|🆕 发布|RepNet-VSR: Reparameterizable Architecture for High-Fidelity Video Super-Resolution|RepNet-VSR：用于高保真视频超分辨率的可重参数化架构|Biao Wu, Diankai Zhang, Shaoli Liu, Si Gao, Chengjian Zheng, Ning Wang|<http://arxiv.org/pdf/2504.15649v1>|提出Reparameterizable Architecture RepNet-VSR，实现实时高清...|
|🆕 发布|Multi-Modal Fusion of In-Situ Video Data and Process Parameters for Online Forecasting of Cookie Drying Readiness|多模态融合现场视频数据和工艺参数，用于在线预测饼干干燥成熟度|Shichen Li, Chenhui Shao|<http://arxiv.org/pdf/2504.15599v1>|提出了一种融合视频数据和工艺参数的模型，准确预测饼干干燥程度，提高生产效率和产品质量。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LASER: A Neuro-Symbolic Framework for Learning Spatial-Temporal Scene Graphs with Weak Supervision|LASER：一种用于弱监督学习时空场景图的神经符号框架|Jiani Huang, Ziyang Li, Mayur Naik, Ser-Nam Lim|<http://arxiv.org/pdf/2304.07647v5>|提出一种利用视频字幕弱监督学习时空场景图的神经符号框架，显著提升预测准确率。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A New Graph Grammar Formalism for Robust Syntactic Pattern Recognition|一种用于鲁棒句法模式识别的新图语法形式化方法|Peter Fletcher|<http://arxiv.org/pdf/2504.15975v2>|提出了一种新型图语法形式，实现鲁棒性语法模式识别，支持并行解析和错误容忍。|
|📝 更新|Talk is Not Always Cheap: Promoting Wireless Sensing Models with Text Prompts|对话并不总是廉价：通过文本提示促进无线传感模型|Zhenkui Yang, Zeyi Huang, Ge Wang, Han Ding, Tony Xiao Han, Fei Wang|<http://arxiv.org/pdf/2504.14621v2>|[代码](https://github.com/yangzhenkui/WiTalk.); 提出文本提示增强无线传感模型，显著提升动作识别和定位准确率。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SonarT165: A Large-scale Benchmark and STFTrack Framework for Acoustic Object Tracking|声纳T165：大规模基准和STFTrack框架用于声学目标跟踪|Yunfeng Li, Bo Wang, Jiahao Wan, Xueyi Wu, Ye Li|<http://arxiv.org/pdf/2504.15609v1>|[代码](https://github.com/LiYunfengLYF/SonarT165.); 构建了首个大规模水下声学目标跟踪基准SonarT165，并提出STFTrack框架提升跟踪性能。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Naturally Computed Scale Invariance in the Residual Stream of ResNet18|自然计算尺度不变性在ResNet18残差流中的实现|André Longon|<http://arxiv.org/pdf/2504.16290v1>|[代码](https://github.com/cest-andre/residual-stream-interp); 揭示了ResNet18残差流如何计算尺度不变性，为鲁棒物体识别提供了新见解。|
|🆕 发布|MMInference: Accelerating Pre-filling for Long-Context VLMs via Modality-Aware Permutation Sparse Attention|MMInference：通过模态感知排列稀疏注意力加速长上下文VLMs的预填充|Yucheng Li, Huiqiang Jiang, Chengruidong Zhang, Qianhui Wu, Xufang Luo, Surin Ahn, Amir H. Abdi, Dongsheng Li .etc.|<http://arxiv.org/pdf/2504.16083v1>|提出MMInference，通过模态感知排列稀疏注意力加速长上下文视觉语言模型预填充。|
|🆕 发布|Recent Advances and Future Directions in Extended Reality (XR): Exploring AI-Powered Spatial Intelligence|《扩展现实（XR）领域最新进展与未来方向：探索人工智能驱动的空间智能》|Baichuan Zeng|<http://arxiv.org/pdf/2504.15970v1>|探讨AI赋能空间智能，推动XR技术发展，构建未来数字空间。|
|🆕 发布|PointLoRA: Low-Rank Adaptation with Token Selection for Point Cloud Learning|点云学习中的低秩自适应与标记选择：PointLoRA|Song Wang, Xiaolu Liu, Lingdong Kong, Jianyun Xu, Chunyong Hu, Gongfan Fang, Wentong Li, Jianke Zhu .etc.|<http://arxiv.org/pdf/2504.16023v1>|[代码](https://github.com/songw-zju/PointLoRA.); PointLoRA通过结合低秩适应和多尺度token选择，实现了高效点云模型微调，显著降低参数需求。|
|🆕 发布|Fluorescence Reference Target Quantitative Analysis Library|荧光参考目标定量分析库|Eammon A. Littler, Emmanuel A. Mannoh, Ethan P. M. LaRochelle|<http://arxiv.org/pdf/2504.15496v1>|开发了一个开源Python库，用于标准化荧光图像的定量分析，以促进荧光成像系统的标准化评估。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Regularizing Differentiable Architecture Search with Smooth Activation|使用平滑激活正则化可微架构搜索|Yanlin Zhou, Mostafa El-Khamy, Kee-Bong Song|<http://arxiv.org/pdf/2504.16306v1>|提出Smooth Activation DARTS方法，有效解决DARTS的跳过优势问题，提升NAS...|
|📝 更新|Towards Robust Infrared Small Target Detection: A Feature-Enhanced and Sensitivity-Tunable Framework|迈向鲁棒红外小目标检测：一种特征增强和灵敏度可调的框架|Jinmiao Zhao, Zelin Shi, Chuang Yu, Yunpeng Liu, Yimian Dai|<http://arxiv.org/pdf/2407.20090v2>|提出了一种特征增强和灵敏度可调的框架，显著提升了红外小目标检测性能。|
|🆕 发布|An XAI-based Analysis of Shortcut Learning in Neural Networks|基于可解释人工智能的神经网络捷径学习分析|Phuong Quynh Le, Jörg Schlötterer, Christin Seifert|<http://arxiv.org/pdf/2504.15664v1>|提出了一种基于XAI的神经元虚假特征评分方法，分析并缓解了神经网络中的虚假相关性。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Comprehensive Evaluation of Quantitative Measurements from Automated Deep Segmentations of PSMA PET/CT Images|全面评估PSMA PET/CT图像自动深度分割的定量测量|Obed Korshie Dzikunu, Amirhossein Toosi, Shadab Ahamed, Sara Harsini, Francois Benard, Xiaoxiao Li, Arman Rahmim|<http://arxiv.org/pdf/2504.16237v1>|[代码](https://github.com/ObedDzik/pca); 提出了一种基于L1DFL的深度学习模型，显著提升了PSMA PET/CT图像分割的定量测量准确性。|
|🆕 发布|Evaluating Vision Language Models (VLMs) for Radiology: A Comprehensive Analysis|评估放射学领域视觉语言模型（VLMs）：全面分析|Frank Li, Hari Trivedi, Bardia Khosravi, Theo Dapamede, Mohammadreza Chavoshi, Abdulhameed Dere, Rohan Satya Isaac, Aawez Mansuri .etc.|<http://arxiv.org/pdf/2504.16047v1>|评估了三种视觉语言模型在放射学任务中的表现，并提出了一种结合全局和局部特征的定制分割模型，显著提升了...|
|🆕 发布|Classification of Firn Data via Topological Features|通过拓扑特征对雪冰数据的分类|Sarah Day, Jesse Dimino, Matt Jester, Kaitlin Keegan, Thomas Weighill|<http://arxiv.org/pdf/2504.16150v1>|利用拓扑特征对冰川雪层图像进行分类，揭示深度与结构间联系，并分析方法间的权衡。|
|📝 更新|HEMGS: A Hybrid Entropy Model for 3D Gaussian Splatting Data Compression|混合熵模型用于3D高斯分层数据压缩|Lei Liu, Zhenghao Chen, Wei Jiang, Wei Wang, Dong Xu|<http://arxiv.org/pdf/2411.18473v2>|提出HEMGS模型，通过混合熵模型实现3D高斯分层数据的高效压缩。|
|📝 更新|Localization Meets Uncertainty: Uncertainty-Aware Multi-Modal Localization|定位与不确定性：不确定性感知的多模态定位|Hye-Min Won, Jieun Lee, Jiyong Oh|<http://arxiv.org/pdf/2504.07677v2>|提出了一种基于百分位数拒绝策略的定位方法，显著提升了多模态定位的准确性和可靠性。|
|🆕 发布|A Vision-Enabled Prosthetic Hand for Children with Upper Limb Disabilities|儿童上肢残疾者的视觉辅助假肢|Md Abdul Baset Sarker, Art Nguyen, Sigmond Kukla, Kevin Fite, Masudul H. Imtiaz|<http://arxiv.org/pdf/2504.15654v1>|开发了一种低成本、可定制的AI视觉辅助儿童假肢，解决现有肌电假肢的局限性。|
|📝 更新|First-place Solution for Streetscape Shop Sign Recognition Competition|街道景观商店招牌识别竞赛第一名解决方案|Bin Wang, Li Jing|<http://arxiv.org/pdf/2501.02811v2>|提出多阶段融合特征、强化学习和文本校正的方案，显著提升复杂环境中街景招牌识别能力。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Scoping Review of Earth Observation and Machine Learning for Causal Inference: Implications for the Geography of Poverty|地球观测与机器学习在因果推断中的应用范围综述：对贫困地理学的影响|Kazuki Sakamoto, Connor T. Jerzak, Adel Daoud|<http://arxiv.org/pdf/2406.02584v4>|该论文通过综述地球观测与机器学习在因果推断中的应用，为贫困地理研究提供了详细的整合地球观测数据的方法...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Riemannian Patch Assignment Gradient Flows|黎曼补丁分配梯度流|Daniel Gonzalez-Alvarado, Fabio Schlindwein, Jonas Cassel, Laura Steingruber, Stefania Petra, Christoph Schnörr|<http://arxiv.org/pdf/2504.13024v2>|提出了一种基于Riemannian几何的图上数据标注方法，通过动态交互实现标签和分配变量的优化。|
|🆕 发布|SocialMOIF: Multi-Order Intention Fusion for Pedestrian Trajectory Prediction|社会MOIF：用于行人轨迹预测的多阶意图融合|Kai Chen, Xiaodong Zhao, Yujie Huang, Guoyu Fang, Xiao Song, Ruiping Wang, Ziyuan Wang|<http://arxiv.org/pdf/2504.15616v1>|SocialMOIF通过融合多阶意图信息，提高了行人轨迹预测的准确性和效率。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Is Large-Scale Pretraining the Secret to Good Domain Generalization?|大规模预训练是否是良好领域泛化的秘诀？|Piotr Teterwak, Kuniaki Saito, Theodoros Tsiligkaridis, Bryan A. Plummer, Kate Saenko|<http://arxiv.org/pdf/2412.02856v3>|提出“对齐假设”，强调预训练数据学习质量对领域泛化性能至关重要。|
|📝 更新|Distribution-aware Forgetting Compensation for Exemplar-Free Lifelong Person Re-identification|基于分布感知的无示例终身人物重识别遗忘补偿|Shiben Liu, Huijie Fan, Qiang Wang, Baojie Fan, Yandong Tang, Liangqiong Qu|<http://arxiv.org/pdf/2504.15041v2>|[代码](https://github.com/LiuShiBen/DAFC.); 提出DAFC模型，通过跨域共享表示学习和领域特定分布整合，解决LReID中的遗忘补偿问题。|
|🆕 发布|Locating and Mitigating Gradient Conflicts in Point Cloud Domain Adaptation via Saliency Map Skewness|通过显著性图偏斜定位和缓解点云域适应中的梯度冲突|Jiaqi Tang, Yinsong Xu, Qingchao Chen|<http://arxiv.org/pdf/2504.15796v1>|提出了一种基于显著性图偏斜度的数据采样策略，有效缓解点云域适应中的梯度冲突，提升分类性能。|
|🆕 发布|Analytical Softmax Temperature Setting from Feature Dimensions for Model- and Domain-Robust Classification|从特征维度分析软最大化温度设置以实现模型和领域鲁棒分类|Tatsuhito Hasegawa, Shunsuke Sakai|<http://arxiv.org/pdf/2504.15594v1>|提出了一种基于特征维度的softmax温度设置方法，实现模型和领域鲁棒的分类。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Human-Imperceptible Physical Adversarial Attack for NIR Face Recognition Models|人类不可察觉的近红外人脸识别模型物理对抗攻击|Songyan Xie, Jinghang Wen, Encheng Su, Qiucheng Yu|<http://arxiv.org/pdf/2504.15823v1>|设计了一种隐蔽的物理对抗攻击，显著提升了近红外人脸识别模型的攻击成功率。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|An Automated Pipeline for Few-Shot Bird Call Classification: A Case Study with the Tooth-Billed Pigeon|自动化的少量样本鸟类鸣叫分类流程：以啄木鸟为例|Abhishek Jana, Moeumu Uili, James Atherton, Mark O'Brien, Joe Wood, Leandra Brickson|<http://arxiv.org/pdf/2504.16276v1>|开发了一种针对稀有鸟类叫声的自动化分类流程，有效利用少量数据识别濒危物种。|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Co-domain Symmetry for Complex-Valued Deep Learning|复杂值深度学习的共域对称性|Utkarsh Singhal, Yifei Xing, Stella X. Yu|<http://arxiv.org/pdf/2112.01525v2>|设计了一种基于共域对称性的复杂值神经网络，显著提升了图像分类的准确性和泛化能力。|
|📝 更新|Hear the Scene: Audio-Enhanced Text Spotting|聆听场景：音频增强文本检测|Jing Li, Bo Wang|<http://arxiv.org/pdf/2412.19504v3>|提出一种仅利用转录标注训练文本检测模型的方法，通过音频增强实现高精度文本定位。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CityWalker: Learning Embodied Urban Navigation from Web-Scale Videos|城市行者：从大规模网络视频中学习具身城市导航|Xinhao Liu, Jintong Li, Yicheng Jiang, Niranjan Sujay, Zhicheng Yang, Juexiao Zhang, John Abanes, Jing Zhang .etc.|<http://arxiv.org/pdf/2411.17820v3>|[代码](https://ai4ce.github.io/CityWalker); 通过大规模网络视频数据训练，CityWalker实现了类似人类的动态城市导航。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Ask2Loc: Learning to Locate Instructional Visual Answers by Asking Questions|Ask2Loc：通过提问学习定位教学视觉答案|Chang Zong, Bin Li, Shoujun Zhou, Jian Wan, Lei Zhang|<http://arxiv.org/pdf/2504.15918v2>|[代码](https://github.com/changzong/Ask2Loc.); 提出Ask2Loc框架，通过提问解决视频问答定位中的语义鸿沟问题，显著提升定位准确度。|
|📝 更新|TextSquare: Scaling up Text-Centric Visual Instruction Tuning|文本广场：扩展以文本为中心的视觉指令微调|Jingqun Tang, Chunhui Lin, Zhen Zhao, Shu Wei, Binghong Wu, Qi Liu, Hao Feng, Yang Li .etc.|<http://arxiv.org/pdf/2404.12803v2>|通过构建大规模高质量指令微调数据集Square-10M，显著提升了文本中心视觉问答模型的性能。|
|📝 更新|NaturalBench: Evaluating Vision-Language Models on Natural Adversarial Samples|自然基准：在自然对抗样本上评估视觉-语言模型|Baiqi Li, Zhiqiu Lin, Wenxuan Peng, Jean de Dieu Nyandwi, Daniel Jiang, Zixian Ma, Simran Khanuja, Ranjay Krishna .etc.|<http://arxiv.org/pdf/2410.14669v3>|提出NaturalBench基准，揭示视觉语言模型在自然对抗样本上的局限性。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Progressive Language-guided Visual Learning for Multi-Task Visual Grounding|多任务视觉定位的渐进式语言引导视觉学习|Jingchao Wang, Hong Wang, Wenlong Zhang, Kunhua Ji, Dingjiang Huang, Yefeng Zheng|<http://arxiv.org/pdf/2504.16145v1>|[代码](https://github.com/jcwang0602/PLVL); 提出PLVL框架，通过语言引导视觉学习，提升多任务视觉定位准确度。|
|📝 更新|FocusedAD: Character-centric Movie Audio Description|聚焦AD：以角色为中心的电影音频描述|Xiaojun Ye, Chun Wang, Yiren Song, Sheng Zhou, Liangcheng Li, Jiajun Bu|<http://arxiv.org/pdf/2504.12157v2>|[代码](https://github.com/Thorin215/FocusedAD); 提出FocusedAD框架，通过角色感知和动态先验模块，实现以角色为中心的电影音频描述。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|To Match or Not to Match: Revisiting Image Matching for Reliable Visual Place Recognition|匹配与否：重新审视可靠视觉位置识别的图像匹配|Davide Sferrazza, Gabriele Berton, Gabriele Trivigno, Carlo Masone|<http://arxiv.org/pdf/2504.06116v2>|[代码](https://github.com/FarInHeight/To-Match-or-Not-to-Match.); 提出以图像匹配验证检索结果，优化视觉场景识别系统性能。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MedNNS: Supernet-based Medical Task-Adaptive Neural Network Search|MedNNS：基于超网络的医学任务自适应神经网络搜索|Lotfi Abdelkrim Mecharbat, Ibrahim Almakky, Martin Takac, Mohammad Yaqub|<http://arxiv.org/pdf/2504.15865v2>|[代码](https://github.com/BioMedIA-MBZUAI/MedNNS.); 提出MedNNS，通过超网络优化医学图像模型架构和初始化，显著提升性能和收敛速度。|
|🆕 发布|CLIP-IT: CLIP-based Pairing for Histology Images Classification|CLIP-IT：基于CLIP的病理图像配对分类|Banafsheh Karimian, Giulia Avanzato, Soufian Belharbi, Luke McCaffrey, Mohammadhadi Shateri, Eric Granger|<http://arxiv.org/pdf/2504.16181v1>|CLIP-IT通过结合外部文本信息，无需手动配对样本，有效利用特权文本信息，提升病理图像分类性能。|
|🆕 发布|A detection-task-specific deep-learning method to improve the quality of sparse-view myocardial perfusion SPECT images|针对稀疏视图心肌灌注SPECT图像质量提升的特定检测任务深度学习方法|Zezhang Yang, Zitong Yu, Nuri Choi, Abhinav K. Jha|<http://arxiv.org/pdf/2504.16171v1>|提出了一种针对稀疏视图心肌灌注SPECT图像的深度学习方法，显著提升了诊断准确性。|
|🆕 发布|Meta-Entity Driven Triplet Mining for Aligning Medical Vision-Language Models|基于元实体驱动的三元组挖掘以对齐医学视觉-语言模型|Saban Ozturk, Melih B. Yilmaz, Muti Kara, M. Talat Yavuz, Aykut Koç, Tolga Çukur|<http://arxiv.org/pdf/2504.15929v2>|提出MedTrim方法，通过元实体驱动的三元组挖掘，提升医学视觉-语言模型中图像与文本的匹配精度。|
|🆕 发布|A Clinician-Friendly Platform for Ophthalmic Image Analysis Without Technical Barriers|眼科图像分析的无技术障碍的医生友好平台|Meng Wang, Tian Lin, Qingshan Hou, Aidi Lin, Jingcheng Wang, Qingsheng Peng, Truong X. Nguyen, Danqi Fang .etc.|<http://arxiv.org/pdf/2504.15928v1>|开发了一款无需技术背景即可使用的眼科图像分析平台，实现跨中心、跨人群的高精度诊断。|
|🆕 发布|RaSCL: Radar to Satellite Crossview Localization|雷达与卫星交叉视定位：RaSCL|Blerim Abdullai, Tony Wang, Xinyuan Qiao, Florian Shkurti, Timothy D. Barfoot|<http://arxiv.org/pdf/2504.15899v1>|提出了一种基于地面雷达和卫星图像的GNSS-free全局定位方法，实现无GNSS的精准定位。|
|🆕 发布|Integrating Non-Linear Radon Transformation for Diabetic Retinopathy Grading|整合非线性Radon变换进行糖尿病视网膜病变分级|Farida Mohsen, Samir Belhaouari, Zubair Shah|<http://arxiv.org/pdf/2504.15883v1>|提出RadFuse框架，结合非线性Radon变换和传统图像，提升糖尿病视网膜病变检测和分级准确性。|
|🆕 发布|Towards prediction of morphological heart age from computed tomography angiography|向预测基于计算机断层扫描血管造影的形态学心脏年龄迈进|Johan Öfverstedt, Elin Lundström, Håkan Ahlström, Joel Kullberg|<http://arxiv.org/pdf/2504.15783v1>|开发了一种基于CTA图像的心脏形态学年龄预测方法，通过机器学习模型提高了年龄预测的准确性。|
|📝 更新|LOOC: Localizing Organs using Occupancy Networks and Body Surface Depth Images|局部器官定位：利用占用网络和体表深度图像进行定位|Pit Henrich, Franziska Mathis-Ullrich|<http://arxiv.org/pdf/2406.12407v2>|提出了一种基于深度学习和体表深度图像的器官定位方法，显著提升了医学影像诊断的准确性。|
|🆕 发布|Performance Estimation for Supervised Medical Image Segmentation Models on Unlabeled Data Using UniverSeg|基于UniverSeg在未标记数据上对监督医学图像分割模型的性能估计|Jingchen Zou, Jianqiang Li, Gabriel Jimenez, Qing Zhao, Daniel Racoceanu, Matias Cosarinsky, Enzo Ferrante, Guanghui Fu|<http://arxiv.org/pdf/2504.15667v1>|提出了一种无需标注数据的医学图像分割模型性能评估框架，有效解决临床应用中模型性能不确定性问题。|
|🆕 发布|Bayesian Autoencoder for Medical Anomaly Detection: Uncertainty-Aware Approach for Brain 2 MRI Analysis|贝叶斯自编码器在医学异常检测中的应用：脑部2 MRI分析的容错感知方法|Dip Roy|<http://arxiv.org/pdf/2504.15562v1>|提出了一种基于贝叶斯推理的脑部MRI异常检测方法，通过不确定性建模提升诊断性能。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Pose Optimization for Autonomous Driving Datasets using Neural Rendering Models|基于神经渲染模型的自动驾驶数据集姿态优化|Quentin Herau, Nathan Piasco, Moussab Bennehar, Luis Rolado, Dzmitry Tsishkou, Bingbing Liu, Cyrille Migniot, Pascal Vasseur .etc.|<http://arxiv.org/pdf/2504.15776v1>|利用NeRF优化自动驾驶数据集的传感器姿态，提升数据集基准的准确性。|
|📝 更新|PolyFootNet: Extracting Polygonal Building Footprints in Off-Nadir Remote Sensing Images|多边形足迹网络：从非正射遥感图像中提取多边形建筑足迹|Kai Li, Yupeng Deng, Jingbo Chen, Yu Meng, Zhihao Xi, Junxian Ma, Chenhao Wang, Maolin Wang .etc.|<http://arxiv.org/pdf/2408.08645v4>|[代码](https://github.com/likaiucas/PolyFootNet.); 提出PolyFootNet，直接从非正射遥感图像中提取精确的建筑物轮廓。|
|🆕 发布|HS-Mamba: Full-Field Interaction Multi-Groups Mamba for Hyperspectral Image Classification|HS-Mamba：全场交互多组Mamba用于高光谱图像分类|Hongxing Peng, Kang Lin, Huanai Liu|<http://arxiv.org/pdf/2504.15612v1>|HS-Mamba通过结合局部和全局特征，有效提升了高光谱图像分类的精度。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Quantum Doubly Stochastic Transformers|量子双随机变换器|Jannis Born, Filip Skogh, Kahn Rhrissorrakrai, Filippo Utro, Nico Wagner, Aleksandros Sobczyk|<http://arxiv.org/pdf/2504.16275v1>|提出量子双随机变换器，以量子电路替代Softmax，提升Transformer在视觉任务中的表现和稳...|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vision language models are unreliable at trivial spatial cognition|视觉语言模型在简单空间认知方面不可靠|Sangeet Khemlani, Tyler Tran, Nathaniel Gyory, Anthony M. Harrison, Wallace E. Lawson, Ravenna Thielstrom, Hunter Thompson, Taaren Singh .etc.|<http://arxiv.org/pdf/2504.16061v1>|该论文揭示了视觉语言模型在处理简单空间认知任务上的不可靠性，并提出了TableTest数据集以评估其...|
|🆕 发布|SAGA: Semantic-Aware Gray color Augmentation for Visible-to-Thermal Domain Adaptation across Multi-View Drone and Ground-Based Vision Systems|SAGA：多视角无人机和地面视觉系统跨可见光至热成像域适应的语义感知灰度颜色增强|Manjunath D, Aniruddh Sikdar, Prajwal Gurunath, Sumanth Udupa, Suresh Sundaram|<http://arxiv.org/pdf/2504.15728v1>|[代码](https://github.com/airliisc/IndraEye.); 提出SAGA方法，通过语义感知灰度色彩增强，有效缓解可见光到热成像域适应中的颜色偏差问题。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|On Symmetries in Convolutional Weights|关于卷积权重中的对称性|Bilal Alsallakh, Timothy Wroge, Vivek Miglani, Narine Kokhlikyan|<http://arxiv.org/pdf/2503.19215v2>|揭示了卷积神经网络权重中的对称性，并探讨了其对网络性能的影响。|
|🆕 发布|RePOPE: Impact of Annotation Errors on the POPE Benchmark|RePOPE：标注错误对POPE基准的影响|Yannic Neuhaus, Matthias Hein|<http://arxiv.org/pdf/2504.15707v1>|[代码](https://github.com/YanNeu/RePOPE); 评估了MSCOCO标注错误对POPE基准测试的影响，并提出了RePOPE重标注方法以提升模型评估准确...|
|🆕 发布|ForesightNav: Learning Scene Imagination for Efficient Exploration|前瞻导航：学习场景想象以实现高效探索|Hardik Shah, Jiaxu Xing, Nico Messikommer, Boyang Sun, Marc Pollefeys, Davide Scaramuzza|<http://arxiv.org/pdf/2504.16062v1>|ForesightNav通过模拟人类想象力和推理能力，使机器人能高效探索未知环境。|

