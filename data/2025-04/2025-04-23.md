## [UPDATED!] **2025-04-23** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hyperspectral Vision Transformers for Greenhouse Gas Estimations from Space|基于高光谱视觉Transformer的温室气体空间估算|Ruben Gonzalez Avilés, Linus Scheibenreif, Nassim Ait Ali Braham, Benedikt Blumenstiel, Thomas Brunschwiler, Ranjini Guruprasad, Damian Borth, Conrad Albrecht .etc.|<http://arxiv.org/pdf/2504.16851v1>|提出了一种结合多光谱和超光谱数据，通过深度学习模型提升温室气体估算精度的方法。|
|🆕 发布|Advanced Chest X-Ray Analysis via Transformer-Based Image Descriptors and Cross-Model Attention Mechanism|基于Transformer图像描述符和跨模型注意力机制的先进胸部X光分析|Lakshita Agarwal, Bindu Verma|<http://arxiv.org/pdf/2504.16774v1>|提出了一种结合ViT和GPT-4的跨模态注意力机制，显著提升了胸部X光图像分析的准确性和效率。|
|🆕 发布|Tri-FusionNet: Enhancing Image Description Generation with Transformer-based Fusion Network and Dual Attention Mechanism|三融合网络：基于Transformer融合网络和双注意力机制的图像描述生成增强|Lakshita Agarwal, Bindu Verma|<http://arxiv.org/pdf/2504.16761v1>|提出Tri-FusionNet，融合ViT、RoBERTa和CLIP，结合双注意力机制，显著提升图像...|
|🆕 发布|WiFi based Human Fall and Activity Recognition using Transformer based Encoder Decoder and Graph Neural Networks|基于Transformer编码器-解码器和图神经网络的WiFi人体跌倒和活动识别|Younggeol Cho, Elisa Motta, Olivia Nocentini, Marta Lagomarsino, Andrea Merello, Marco Crepaldi, Arash Ajoudani|<http://arxiv.org/pdf/2504.16655v1>|提出了一种基于WiFi信号的Transformer编码器-解码器网络和图神经网络，用于人体姿态估计和...|
|🆕 发布|Federated EndoViT: Pretraining Vision Transformers via Federated Learning on Endoscopic Image Collections|联邦EndoViT：通过在内镜图像集合上进行联邦学习预训练视觉Transformer|Max Kirchner, Alexander C. Jenke, Sebastian Bodenstedt, Fiona R. Kolbinger, Oliver Saldanha, Jakob N. Kather, Martin Wagner, Stefanie Speidel|<http://arxiv.org/pdf/2504.16612v1>|检测手术图像数据隐私问题，提出联邦学习预训练视觉Transformer模型，提升下游任务性能。|
|📝 更新|Decoding Vision Transformers: the Diffusion Steering Lens|解码视觉Transformer：扩散引导透镜|Ryota Takatsuki, Sonia Joseph, Ippei Fujisawa, Ryota Kanai|<http://arxiv.org/pdf/2504.13763v2>|提出Diffusion Steering Lens，有效解释视觉Transformer内部处理机制。|
|📝 更新|Pix2Next: Leveraging Vision Foundation Models for RGB to NIR Image Translation|Pix2Next：利用视觉基础模型实现RGB到近红外图像转换|Youngwan Jin, Incheol Park, Hanbin Song, Hyeongjin Ju, Yagiz Nalcakan, Shiho Kim|<http://arxiv.org/pdf/2409.16706v2>|Pix2Next利用视觉基础模型和跨注意力机制，有效提升了RGB到NIR图像的转换质量。|
|🆕 发布|Cross Paradigm Representation and Alignment Transformer for Image Deraining|跨范式表示和对齐变换器用于图像去雨|Shun Zou, Yi Zou, Juncheng Li, Guangwei Gao, Guojun Qi|<http://arxiv.org/pdf/2504.16455v1>|提出CPRAformer，通过融合全局-局部和空间-通道表示，解决图像去雨中的复杂雨迹问题。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DEFOM-Stereo: Depth Foundation Model Based Stereo Matching|DEFOM-Stereo：基于深度基础模型的立体匹配|Hualie Jiang, Zhiqiang Lou, Laiyan Ding, Rui Xu, Minglang Tan, Wenjie Jiang, Rui Huang|<http://arxiv.org/pdf/2501.09466v3>|DEFOM-Stereo通过结合单目深度信息和深度基础模型，实现了鲁棒的立体匹配，显著提升了深度估计...|
|📝 更新|MedMax: Mixed-Modal Instruction Tuning for Training Biomedical Assistants|MedMax：混合模态指令微调训练生物医学助手|Hritik Bansal, Daniel Israel, Siyan Zhao, Shufan Li, Tung Nguyen, Aditya Grover|<http://arxiv.org/pdf/2412.12661v2>|[代码](https://mint-medmax.github.io/.); 提出MedMax数据集，通过混合模态指令微调提升生物医学助手性能。|
|📝 更新|GFreeDet: Exploiting Gaussian Splatting and Foundation Models for Model-free Unseen Object Detection in the BOP Challenge 2024|GFreeDet：利用高斯喷溅和基础模型在BOP挑战2024中进行无模型未见物体检测|Xingyu Liu, Gu Wang, Chengxi Li, Yingyue Li, Chenyangguang Zhang, Ziqin Huang, Xiangyang Ji|<http://arxiv.org/pdf/2412.01552v4>|GFreeDet通过高斯分层和基础模型实现无模型未知物体检测，在BOP挑战赛中荣获最佳方法奖。|
|🆕 发布|CLPSTNet: A Progressive Multi-Scale Convolutional Steganography Model Integrating Curriculum Learning|CLPSTNet：一种融合课程学习的渐进式多尺度卷积隐写模型|Fengchun Liu, Tong Zhang, Chunying Zhang|<http://arxiv.org/pdf/2504.16364v1>|[代码](https://github.com/chaos-boops/CLPSTNet); 提出CLPSTNet，通过渐进式多尺度卷积和课程学习，有效提升了图像隐写术的隐蔽性和安全性。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ST-Think: How Multimodal Large Language Models Reason About 4D Worlds from Ego-Centric Videos|ST-Think：多模态大型语言模型如何从以自我为中心的视频中推理4D世界|Peiran Wu, Yunze Liu, Miao Liu, Junxiao Shen|<http://arxiv.org/pdf/2503.12542v2>|提出Ego-ST Bench基准和ST-R1模型，提升多模态大语言模型对4D世界的推理能力。|
|📝 更新|Effective Lymph Nodes Detection in CT Scans Using Location Debiased Query Selection and Contrastive Query Representation in Transformer|基于位置偏差查询选择和Transformer中的对比查询表示的有效淋巴结检测在CT扫描中|Yirui Wang, Qinji Yu, Ke Yan, Haoshen Li, Dazhou Guo, Li Zhang, Le Lu, Na Shen .etc.|<http://arxiv.org/pdf/2404.03819v2>|提出了一种基于Transformer的淋巴结检测方法，显著提升了检测精度和召回率。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Novel Adaptive Hybrid Focal-Entropy Loss for Enhancing Diabetic Retinopathy Detection Using Convolutional Neural Networks|一种用于增强糖尿病视网膜病变检测的卷积神经网络自适应混合焦点熵损失函数的新方法|Santhosh Malarvannan, Pandiyaraju V, Shravan Venkatraman, Abeshek A, Priyadarshini B, Kannan A|<http://arxiv.org/pdf/2411.10843v2>|提出自适应混合焦点熵损失函数，有效提升糖尿病视网膜病变检测准确率。|
|🆕 发布|SemanticSugarBeets: A Multi-Task Framework and Dataset for Inspecting Harvest and Storage Characteristics of Sugar Beets|语义糖 beet：一种用于检查糖 beet 收获和储存特性的多任务框架和数据集|Gerardus Croonen, Andreas Trondl, Julia Simon, Daniel Steininger|<http://arxiv.org/pdf/2504.16684v1>|构建了用于检测和分割糖 beet 损伤、腐烂等特征的视觉框架和数据集，显著提升了糖 beet 产后和...|
|📝 更新|BOP Challenge 2024 on Model-Based and Model-Free 6D Object Pose Estimation|基于模型和无模型6D物体姿态估计的BOP挑战2024|Van Nguyen Nguyen, Stephen Tyree, Andrew Guo, Mederic Fourmy, Anas Gouda, Taeyeop Lee, Sungphill Moon, Hyeontae Son .etc.|<http://arxiv.org/pdf/2504.02812v4>|BOP Challenge 2024提出新任务和更实用数据集，推动6D物体姿态估计技术向真实场景迈进...|
|🆕 发布|Federated Learning of Low-Rank One-Shot Image Detection Models in Edge Devices with Scalable Accuracy and Compute Complexity|联邦学习在边缘设备上实现低秩单样本图像检测模型的可扩展精度和计算复杂度|Abdul Hannaan, Zubair Shah, Aiman Erbad, Amr Mohamed, Ali Safa|<http://arxiv.org/pdf/2504.16515v1>|提出LoRa-FL框架，在边缘设备上训练低秩单样本图像检测模型，降低计算和通信开销，同时保持高精度。|
|🆕 发布|Assessing the Feasibility of Internet-Sourced Video for Automatic Cattle Lameness Detection|评估互联网视频用于自动检测牛跛行的可行性|Md Fahimuzzman Sohan|<http://arxiv.org/pdf/2504.16404v1>|该研究提出了一种利用互联网视频数据检测牛跛行的深度学习模型，有效简化了处理流程并提高了分类准确率。|
|📝 更新|A Robust Real-Time Lane Detection Method with Fog-Enhanced Feature Fusion for Foggy Conditions|雾天条件下具有雾增强特征融合的鲁棒实时车道检测方法|Ronghui Zhang, Yuhang Ma, Tengfei Li, Ziyu Lin, Yueying Wu, Junzhou Chen, Lin Zhang, Jia Hu .etc.|<http://arxiv.org/pdf/2504.06121v3>|提出了一种融合雾增强特征的实时车道检测方法，显著提升雾天环境下的检测性能。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EHGCN: Hierarchical Euclidean-Hyperbolic Fusion via Motion-Aware GCN for Hybrid Event Stream Perception|EHGCN：基于运动感知GCN的层次欧几里得-双曲融合用于混合事件流感知|Haosheng Chen, Lian Luo, Mengjingcheng Mo, Zhanjie Wu, Guobao Xiao, Ji Gan, Jiaxu Leng, Xinbo Gao|<http://arxiv.org/pdf/2504.16616v1>|提出EHGCN，通过融合欧几里得和双曲空间，实现运动感知的混合事件流感知。|
|🆕 发布|RGB-D Video Object Segmentation via Enhanced Multi-store Feature Memory|基于增强多存储特征记忆的RGB-D视频目标分割|Boyue Xu, Ruichao Hou, Tongwei Ren, Gangshan Wu|<http://arxiv.org/pdf/2504.16471v1>|提出了一种基于多存储特征记忆的RGB-D视频目标分割方法，有效提升了分割精度和鲁棒性。|
|🆕 发布|PixelWeb: The First Web GUI Dataset with Pixel-Wise Labels|像素Web：首个具有像素级标签的Web GUI数据集|Qi Yang, Weichen Bi, Haiyang Shen, Yaoqi Guo, Yun Ma|<http://arxiv.org/pdf/2504.16419v1>|PixelWeb通过精确标注和视觉特征提取，解决了GUI数据集标注不准确的问题，提升了下游任务性能。|
|📝 更新|SLAM-Based Navigation and Fault Resilience in a Surveillance Quadcopter with Embedded Vision Systems|基于SLAM的导航与嵌入式视觉系统在监控多旋翼无人机中的容错能力|Abhishek Tyagi, Charu Gaur|<http://arxiv.org/pdf/2504.15305v2>|提出了一种集视觉SLAM、故障容忍和嵌入式视觉识别于一体的无人机导航与故障恢复系统。|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Survey on Mixup Augmentations and Beyond|混合增强及其超越综述|Xin Jin, Hongyu Zhu, Siyuan Li, Zedong Wang, Zicheng Liu, Juanxi Tian, Chang Yu, Huafeng Qin .etc.|<http://arxiv.org/pdf/2409.05202v2>|[代码](https://github.com/Westlake-AI/Awesome-Mixup.); 全面综述了Mixup数据增强方法及其应用，为研究人员提供了当前最先进的Mixup方法和指导。|
|🆕 发布|Generalized Neighborhood Attention: Multi-dimensional Sparse Attention at the Speed of Light|广义邻域注意力：以光速的多维稀疏注意力|Ali Hassani, Fengzhe Zhou, Aditya Kane, Jiannan Huang, Chieh-Yun Chen, Min Shi, Steven Walton, Markus Hoehnerbach .etc.|<http://arxiv.org/pdf/2504.16922v1>|提出了一种高效的多维稀疏注意力机制，显著提升了计算机视觉模型的运行速度。|
|🆕 发布|Prompt-Tuning SAM: From Generalist to Specialist with only 2048 Parameters and 16 Training Images|提示微调SAM：仅用2048个参数和16张训练图像从通用型到专业型|Tristan Piater, Björn Barz, Alexander Freytag|<http://arxiv.org/pdf/2504.16739v1>|通过仅用2048参数和16张训练图像，提出Prompt-Tuning SAM方法，显著提升SAM在特...|
|🆕 发布|CountingDINO: A Training-free Pipeline for Class-Agnostic Counting using Unsupervised Backbones|CountingDINO：一种基于无监督骨干的无监督类别无关计数训练管道|Giacomo Pacini, Lorenzo Bianchi, Luca Ciampi, Nicola Messina, Giuseppe Amato, Fabrizio Falchi|<http://arxiv.org/pdf/2504.16570v1>|[代码](https://lorebianchi98.github.io/CountingDINO); 提出了一种无需训练的、基于无监督骨干的类无关计数方法，显著提升了计数准确性和泛化能力。|
|🆕 发布|Marginalized Generalized IoU (MGIoU): A Unified Objective Function for Optimizing Any Convex Parametric Shapes|边缘广义IoU（MGIoU）：优化任何凸参数形状的统一目标函数|Duy-Tho Le, Trung Pham, Jianfei Cai, Hamid Rezatofighi|<http://arxiv.org/pdf/2504.16443v2>|[代码](https://ldtho.github.io/MGIoU); 提出MGIoU，一种统一且高效的损失函数，优化任意凸形状的相似度。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Procedural Dataset Generation for Zero-Shot Stereo Matching|程序化数据集生成用于零样本立体匹配|David Yan, Alexander Raistrick, Jia Deng|<http://arxiv.org/pdf/2504.16930v1>|[代码](https://github.com/princeton-vl/InfinigenStereo); 提出了一种针对零样本立体匹配的生成式数据集构建方法，显著提升了模型性能。|
|🆕 发布|Towards Explainable AI: Multi-Modal Transformer for Video-based Image Description Generation|迈向可解释人工智能：基于视频的多模态Transformer图像描述生成|Lakshita Agarwal, Bindu Verma|<http://arxiv.org/pdf/2504.16788v1>|提出多模态Transformer模型，结合视觉和文本信息，实现视频描述生成，提升可解释AI能力。|
|📝 更新|AudioX: Diffusion Transformer for Anything-to-Audio Generation|音频X：任何到音频生成的扩散Transformer|Zeyue Tian, Yizhu Jin, Zhaoyang Liu, Ruibin Yuan, Xu Tan, Qifeng Chen, Wei Xue, Yike Guo|<http://arxiv.org/pdf/2503.10522v2>|[代码](https://zeyuet.github.io/AudioX); AudioX通过多模态掩码训练策略，实现了跨模态的统一音频和音乐生成。|
|🆕 发布|PMG: Progressive Motion Generation via Sparse Anchor Postures Curriculum Learning|PMG：通过稀疏锚姿态课程学习实现渐进式运动生成|Yingjie Xi, Jian Jun Zhang, Xiaosong Yang|<http://arxiv.org/pdf/2504.16722v1>|提出了一种结合轨迹引导和稀疏锚点姿态课程学习的渐进式动作生成方法，显著提升了动作的精确性和可控性。|
|🆕 发布|Rethinking Generalizable Infrared Small Target Detection: A Real-scene Benchmark and Cross-view Representation Learning|重新思考红外小目标检测的可迁移性：一个真实场景基准和跨视角表示学习方法|Yahao Lu, Yuehui Li, Xingyuan Guo, Shuai Yuan, Yukai Shi, Liang Lin|<http://arxiv.org/pdf/2504.16487v1>|[代码](https://github.com/luy0222/RealScene-ISTD.); 提出了一种结合域适应和跨视图表示学习的红外小目标检测框架，有效缓解了数据分布差异和噪声影响。|
|📝 更新|X-SG$^2$S: Safe and Generalizable Gaussian Splatting with X-dimensional Watermarks|X-SG$^2$S：基于X维水印的安全且可泛化的高斯喷溅|Zihang Cheng, Huiping Zhuang, Chun Li, Xin Meng, Ming Li, Fei Richard Yu, Liqiang Nie|<http://arxiv.org/pdf/2502.10475v2>|提出X-SG$^2$S框架，实现3D高斯分层场景安全且可泛化的多模态信息隐藏与提取。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BadVideo: Stealthy Backdoor Attack against Text-to-Video Generation|BadVideo：针对文本到视频生成的隐蔽后门攻击|Ruotong Wang, Mingli Zhu, Jiarong Ou, Rui Chen, Xin Tao, Pengfei Wan, Baoyuan Wu|<http://arxiv.org/pdf/2504.16907v1>|[代码](https://wrt2000.github.io/BadVideo2025); 提出BadVideo，首个针对文本到视频生成模型的隐蔽后门攻击框架，揭示其对抗性漏洞。|
|📝 更新|Anti-Aesthetics: Protecting Facial Privacy against Customized Text-to-Image Synthesis|反美学：保护面部隐私免受定制文本到图像合成攻击|Songping Wang, Yueming Lyu, Shiqi Liu, Ning Li, Tong Tong, Hao Sun, Caifeng Shan|<http://arxiv.org/pdf/2504.12129v2>|提出了一种基于美学降解的框架，有效保护面部隐私，对抗定制文本到图像合成。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DiffArtist: Towards Structure and Appearance Controllable Image Stylization|DiffArtist：迈向结构和外观可控的图像风格化|Ruixiang Jiang, Changwen Chen|<http://arxiv.org/pdf/2407.15842v3>|[代码](https://github.com/songrise/Artist.); DiffArtist首次实现结构化和外观可控的图像风格化，通过分离扩散过程赋予用户前所未有的控制力。|
|🆕 发布|DreamO: A Unified Framework for Image Customization|DreamO：图像定制的统一框架|Chong Mou, Yanze Wu, Wenxu Wu, Zinan Guo, Pengze Zhang, Yufeng Cheng, Yiming Luo, Fei Ding .etc.|<http://arxiv.org/pdf/2504.16915v1>|DreamO提出统一框架，实现多条件图像定制，提升生成质量与灵活性。|
|📝 更新|Novel computational workflows for natural and biomedical image processing based on hypercomplex algebras|新型基于超复数代数的自然和生物医学图像处理计算工作流程|Nektarios A. Valous, Eckhard Hitzer, Dragoş Duşe, Rodrigo Rojas Moraleda, Ferdinand Popp, Meggy Suarez-Carmona, Anna Berthel, Ismini Papageorgiou .etc.|<http://arxiv.org/pdf/2502.07758v4>|利用超复数代数提出了一种自然和生物医学图像处理新方法，提升了图像质量和机器学习性能。|
|🆕 发布|Energy-Based Pseudo-Label Refining for Source-free Domain Adaptation|基于能量的无源域自适应伪标签细化|Xinru Meng, Han Sun, Jiamei Liu, Ningzhong Liu, Huiyu Zhou|<http://arxiv.org/pdf/2504.16692v1>|提出EBPR方法，通过能量分数筛选伪标签，提升无源域自适应性能。|
|📝 更新|HandDiffuse: Generative Controllers for Two-Hand Interactions via Diffusion Models|手扩散：通过扩散模型实现双手交互的生成控制器|Pei Lin, Sihang Xu, Hongdi Yang, Yiran Liu, Xin Chen, Jingya Wang, Jingyi Yu, Lan Xu|<http://arxiv.org/pdf/2312.04867v2>|提出HandDiffuse，通过扩散模型和交互损失，实现可控双手交互动作生成。|
|📝 更新|SEGA: Drivable 3D Gaussian Head Avatar from a Single Image|SEGA：从单张图像生成可驾驶的3D高斯头部头像|Chen Guo, Zhuo Su, Jian Wang, Shuang Li, Xu Chang, Zhaohu Li, Yang Zhao, Guidong Wang .etc.|<http://arxiv.org/pdf/2504.14373v2>|提出了一种从单张图像创建可驱动3D高斯头像的新方法，实现了一步式虚拟人像生成。|
|🆕 发布|RouteWinFormer: A Route-Window Transformer for Middle-range Attention in Image Restoration|RouteWinFormer：一种用于图像恢复中程注意力的路由窗口Transformer|Qifan Li, Tianyi Liang, Xingtao Wang, Xiaopeng Fan|<http://arxiv.org/pdf/2504.16637v1>|提出RouteWinFormer，通过中间范围注意力机制有效提升图像修复性能。|
|📝 更新|UltraFusion: Ultra High Dynamic Imaging using Exposure Fusion|超融合：基于曝光融合的超高动态成像|Zixuan Chen, Yujin Wang, Xin Cai, Zhiyuan You, Zheming Lu, Fan Zhang, Shi Guo, Tianfan Xue|<http://arxiv.org/pdf/2501.11515v4>|[代码](https://openimaginglab.github.io/UltraFusion.); 提出了一种可融合9挡曝光差异图像的曝光融合技术，有效解决了高动态范围场景下的图像融合问题。|
|📝 更新|FREAK: Frequency-modulated High-fidelity and Real-time Audio-driven Talking Portrait Synthesis|频率调制高保真实时音频驱动说话人肖像合成：FREAK|Ziqi Ni, Ao Fu, Yi Zhou|<http://arxiv.org/pdf/2503.04067v2>|提出了一种基于频率域建模的实时高保真语音驱动肖像合成方法，显著提升了唇语同步和自然度。|
|📝 更新|Chain-of-Thought Textual Reasoning for Few-shot Temporal Action Localization|思维链文本推理在少样本时序动作定位中的应用|Hongwei Ji, Wulian Yun, Mengshi Qi, Huadong Ma|<http://arxiv.org/pdf/2504.13460v2>|提出了一种结合文本推理的少样本动作定位方法，显著提升了定位准确度。|
|🆕 发布|TraveLLaMA: Facilitating Multi-modal Large Language Models to Understand Urban Scenes and Provide Travel Assistance|TraveLLaMA：促进多模态大型语言模型理解城市场景并提供旅行辅助|Meng Chu, Yukang Chen, Haokun Gui, Shaozuo Yu, Yi Wang, Jiaya Jia|<http://arxiv.org/pdf/2504.16505v1>|TraveLLaMA通过大规模数据集和视觉语言模型，显著提升了城市场景理解和旅行辅助能力。|
|📝 更新|Compositional 4D Dynamic Scenes Understanding with Physics Priors for Video Question Answering|基于物理先验的4D动态场景组合理解及其在视频问答中的应用|Xingrui Wang, Wufei Ma, Angtian Wang, Shuo Chen, Adam Kortylewski, Alan Yuille|<http://arxiv.org/pdf/2406.00622v2>|[代码](https://xingruiwang.github.io/projects); 提出了一种结合物理先验和场景表示的视频问答模型，有效解决了4D动态场景理解问题。|
|📝 更新|DreamID: High-Fidelity and Fast diffusion-based Face Swapping via Triplet ID Group Learning|DreamID：基于三元组ID组学习的超高保真和快速扩散人脸交换|Fulong Ye, Miao Hua, Pengze Zhang, Xinghui Li, Qichao Sun, Songtao Zhao, Qian He, Xinglong Wu|<http://arxiv.org/pdf/2504.14509v2>|DreamID通过构建Triplet ID Group数据，结合SD Turbo模型和改进的模型架构...|
|📝 更新|Robust multi-coil MRI reconstruction via self-supervised denoising|鲁棒的多线圈MRI重建通过自监督去噪|Asad Aali, Marius Arvinte, Sidharth Kumar, Yamin I. Arefeen, Jonathan I. Tamir|<http://arxiv.org/pdf/2411.12919v3>|通过自监督去噪预处理，提升了基于深度学习的多线圈MRI重建效果。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Luminance-GS: Adapting 3D Gaussian Splatting to Challenging Lighting Conditions with View-Adaptive Curve Adjustment|亮度-全局分割：通过视点自适应曲线调整将3D高斯分层应用于具有挑战性光照条件|Ziteng Cui, Xuangeng Chu, Tatsuya Harada|<http://arxiv.org/pdf/2504.01503v2>|Luminance-GS通过自适应曲线调整，显著提升3D Gaussian Splatting在复杂...|
|🆕 发布|A Low-Cost Photogrammetry System for 3D Plant Modeling and Phenotyping|低成本植物三维建模与表型分析摄影测量系统|Joe Hrzich, Michael A. Beck, Christopher P. Bidinosti, Christopher J. Henry, Kalhari Manawasinghe, Karen Tanino|<http://arxiv.org/pdf/2504.16840v1>|开发了一种低成本、开源的植物三维建模与表型分析系统，通过结构光运动方法从点云中计算植物表型特征。|
|🆕 发布|Dual-Camera All-in-Focus Neural Radiance Fields|双摄像头全焦点神经辐射场|Xianrui Luo, Zijin Wu, Juewen Peng, Huiqiang Sun, Zhiguo Cao, Guosheng Lin|<http://arxiv.org/pdf/2504.16636v1>|提出了一种利用双摄像头技术实现无需手动对焦的NeRF合成方法，显著提升图像清晰度和质量。|
|🆕 发布|SaENeRF: Suppressing Artifacts in Event-based Neural Radiance Fields|SaENeRF：基于事件神经辐射场的伪影抑制|Yuanjian Wang, Yufei Deng, Rong Xiao, Jiahao Fan, Chenwei Tang, Deng Xiong, Jiancheng Lv|<http://arxiv.org/pdf/2504.16389v1>|[代码](https://github.com/Mr-firework/SaENeRF.); 提出SaENeRF，有效抑制事件相机NeRF重建中的伪影，实现高质量3D场景重建。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HUG: Hierarchical Urban Gaussian Splatting with Block-Based Reconstruction|HUG：基于块状重建的分层城市高斯分层渲染|Zhongtao Wang, Mai Su, Huishan Au, Yilong Li, Xizhe Cao, Chengwei Pan, Yisong Chen, Guoping Wang|<http://arxiv.org/pdf/2504.16606v1>|HUG通过分层神经网络高斯表示和块级重建，高效处理大规模城市场景，实现高质量渲染。|
|🆕 发布|ToF-Splatting: Dense SLAM using Sparse Time-of-Flight Depth and Multi-Frame Integration|ToF-Splatting：使用稀疏飞行时间深度和多帧融合的密集SLAM|Andrea Conti, Matteo Poggi, Valerio Cambareri, Martin R. Oswald, Stefano Mattoccia|<http://arxiv.org/pdf/2504.16545v1>|提出了一种适用于稀疏ToF数据的SLAM方法，通过多帧融合实现稠密深度图。|
|🆕 发布|PRaDA: Projective Radial Distortion Averaging|投影径向畸变平均：PRaDA|Daniil Sinitsyn, Linus Härenstam-Nielsen, Daniel Cremers|<http://arxiv.org/pdf/2504.16499v1>|提出了一种无需3D重建的径向畸变相机自动校准方法，通过投影空间平均畸变估计，简化了结构从运动问题。|


## 时序视觉分析 (Temporal Visual Analysis)


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Frequency-Compensated Network for Daily Arctic Sea Ice Concentration Prediction|频率补偿网络用于日常北极海冰浓度预测|Jialiang Zhang, Feng Gao, Yanhai Gan, Junyu Dong, Qian Du|<http://arxiv.org/pdf/2504.16745v1>|[代码](https://github.com/oucailab/FCNet); 提出了一种频率补偿网络，有效预测北极海冰浓度，提高边缘和细节预测精度。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PooDLe: Pooled and dense self-supervised learning from naturalistic videos|PooDLe：从自然视频中进行池化和密集自监督学习|Alex N. Wang, Christopher Hoang, Yuwen Xiong, Yann LeCun, Mengye Ren|<http://arxiv.org/pdf/2408.11208v3>|PooDLe通过结合池化表示的不变性和光流扭曲的等变性，从自然视频数据中学习有效的图像表示。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|P2P: Part-to-Part Motion Cues Guide a Strong Tracking Framework for LiDAR Point Clouds|P2P：基于部分到部分运动线索的激光雷达点云强跟踪框架|Jiahao Nie, Fei Xie, Sifan Zhou, Xueyi Zhou, Dong-Kyu Chae, Zhiwei He|<http://arxiv.org/pdf/2407.05238v3>|[代码](https://github.com/haooozi/P2P.); 提出P2P框架，通过部分到部分运动建模，显著提升LiDAR点云目标跟踪精度和速度。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|4D Multimodal Co-attention Fusion Network with Latent Contrastive Alignment for Alzheimer's Diagnosis|四维多模态共注意力融合网络与潜在对比对齐用于阿尔茨海默病诊断|Yuxiang Wei, Yanteng Zhang, Xi Xiao, Tianyang Wang, Xiao Wang, Vince D. Calhoun|<http://arxiv.org/pdf/2504.16798v1>|提出了一种融合sMRI和fMRI的4D多模态共注意力网络，通过潜在对比对齐提高阿尔茨海默病的诊断准确...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OSDFace: One-Step Diffusion Model for Face Restoration|OSDFace：一步人脸修复扩散模型|Jingkai Wang, Jue Gong, Lin Zhang, Zheng Chen, Xing Liu, Hong Gu, Yutong Liu, Yulun Zhang .etc.|<http://arxiv.org/pdf/2411.17163v2>|[代码](https://github.com/jkwang28/OSDFace.); OSDFace通过一步扩散模型和视觉表示嵌入，实现了高效且高保真的面部修复。|
|📝 更新|CF-CAM: Cluster Filter Class Activation Mapping for Reliable Gradient-Based Interpretability|CF-CAM：基于聚类滤波的可靠梯度解释性类激活映射|Hongjie He, Xu Pan, Yudong Yao|<http://arxiv.org/pdf/2504.00060v2>|提出CF-CAM技术，通过聚类滤波增强梯度解释性，解决现有CAM方法的不稳定性和计算开销问题。|
|📝 更新|A Deep Learning System for Rapid and Accurate Warning of Acute Aortic Syndrome on Non-contrast CT in China|中国非对比增强CT上急性主动脉综合征快速准确预警的深度学习系统|Yujian Hu, Yilang Xiang, Yan-Jie Zhou, Yangyan He, Dehai Lang, Shifeng Yang, Xiaolong Du, Chunlan Den .etc.|<http://arxiv.org/pdf/2406.15222v4>|开发了一种基于非对比CT的深度学习系统iAorta，快速准确预警急性主动脉综合征，缩短诊断时间。|
|🆕 发布|Streetscape Analysis with Generative AI (SAGAI): Vision-Language Assessment and Mapping of Urban Scenes|城市场景的生成式AI分析（SAGAI）：视觉-语言评估与城市景观映射|Joan Perez, Giovanni Fusco|<http://arxiv.org/pdf/2504.16538v1>|SAGAI通过结合视觉语言模型和开放数据，实现了对城市街景的自动评估和地图绘制。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Almost Right: Making First-layer Kernels Nearly Orthogonal Improves Model Generalization|几乎正确：使第一层核几乎正交以提高模型泛化能力|Colton R. Crum, Adam Czajka|<http://arxiv.org/pdf/2504.16362v1>|通过优化第一层卷积核的近似正交性，显著提升了模型泛化能力。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Feature Mixing Approach for Detecting Intraoperative Adverse Events in Laparoscopic Roux-en-Y Gastric Bypass Surgery|腹腔镜 Roux-en-Y 胃旁路手术术中不良事件检测的特征混合方法|Rupak Bose, Chinedu Innocent Nwoye, Jorge Lazo, Joël Lukas Lavanchy, Nicolas Padoy|<http://arxiv.org/pdf/2504.16749v1>|提出BetaMixer模型，通过Beta分布混合和生成模型，有效检测和量化腹腔镜胃旁路手术中的术中不...|
|📝 更新|CLAP: Isolating Content from Style through Contrastive Learning with Augmented Prompts|CLAP：通过增强提示的对比学习从风格中隔离内容|Yichao Cai, Yuhang Liu, Zhen Zhang, Javen Qinfeng Shi|<http://arxiv.org/pdf/2311.16445v6>|通过对比学习和数据增强，该论文提出了一种从视觉语言模型中分离内容和风格特征的方法，提升了模型在零样本...|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Fast Adversarial Training with Weak-to-Strong Spatial-Temporal Consistency in the Frequency Domain on Videos|快速频域视频中的弱到强时空一致性对抗训练|Songping Wang, Hanqing Liu, Yueming Lyu, Xiantao Hu, Ziwen He, Wei Wang, Caifeng Shan, Liang Wang|<http://arxiv.org/pdf/2504.14921v2>|提出VFAT-WS，通过弱到强时空一致性正则化，实现视频对抗训练快速提升鲁棒性。|
|📝 更新|Exploring Adversarial Transferability between Kolmogorov-arnold Networks|探索Kolmogorov-Arnold网络之间的对抗迁移性|Songping Wang, Xinquan Yue, Yueming Lyu, Caifeng Shan|<http://arxiv.org/pdf/2503.06276v2>|提出AdvKAN，首次针对Kolmogorov-Arnold网络提出迁移攻击方法，提升不同KAN间对...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|I-Con: A Unifying Framework for Representation Learning|I-Con：统一表示学习框架|Shaden Alshammari, John Hershey, Axel Feldmann, William T. Freeman, Mark Hamilton|<http://arxiv.org/pdf/2504.16929v1>|提出统一框架I-Con，通过信息论方程整合多种机器学习损失函数，揭示信息几何，提升无监督图像分类性能...|
|🆕 发布|Decoupled Global-Local Alignment for Improving Compositional Understanding|解耦全局-局部对齐以提升组合理解|Xiaoxing Hu, Kaicheng Yang, Jun Wang, Haoran Xu, Ziyong Feng, Yupei Wang|<http://arxiv.org/pdf/2504.16801v1>|[代码](https://github.com/xiaoxing2001/DeGLA); 提出DeGLA框架，通过解耦全局-局部对齐提升CLIP模型对组合概念的理解能力。|
|📝 更新|Adapter-Enhanced Semantic Prompting for Continual Learning|增强适配器语义提示的持续学习|Baocai Yin, Ji Zhao, Huajie Jiang, Ningning Hou, Yongli Hu, Amin Beheshti, Ming-Hsuan Yang, Yuankai Qi|<http://arxiv.org/pdf/2412.11074v2>|提出Adapter-Enhanced Semantic Prompting方法，有效缓解持续学习中的...|
|🆕 发布|Noise-Tolerant Coreset-Based Class Incremental Continual Learning|噪声容忍的核集基类增量持续学习|Edison Mucllari, Aswin Raghavan, Zachary Alan Daniels|<http://arxiv.org/pdf/2504.16763v1>|提出了一种抗噪声的Coreset方法，有效提升噪声环境下增量式持续学习的分类准确性和减少遗忘。|
|🆕 发布|Representation Learning via Non-Contrastive Mutual Information|通过非对比互信息进行表示学习|Zhaohan Daniel Guo, Bernardo Avila Pires, Khimya Khetarpal, Dale Schuurmans, Bo Dai|<http://arxiv.org/pdf/2504.16667v1>|提出了一种结合对比和非对比优点的自监督学习目标，有效提升了图像表示学习性能。|
|🆕 发布|SSLR: A Semi-Supervised Learning Method for Isolated Sign Language Recognition|SSLR：一种用于孤立手语识别的半监督学习方法|Hasan Algafri, Hamzah Luqman, Sarah Alyami, Issam Laradji|<http://arxiv.org/pdf/2504.16640v1>|提出了一种半监督学习方法，通过伪标签标注无标签样本，有效解决手语识别数据集标注稀缺问题。|
|🆕 发布|Skywork R1V2: Multimodal Hybrid Reinforcement Learning for Reasoning|天空工作R1V2：多模态混合强化学习推理|Chris, Yichen Wei, Yi Peng, Xiaokun Wang, Weijie Qiu, Wei Shen, Tianyidan Xie, Jiangbo Pei .etc.|<http://arxiv.org/pdf/2504.16656v1>|识别并解决多模态推理中平衡复杂推理能力与泛化能力的问题，提出混合强化学习范式和选择性样本缓冲机制。|
|🆕 发布|JEPA for RL: Investigating Joint-Embedding Predictive Architectures for Reinforcement Learning|基于联合嵌入的强化学习预测架构研究|Tristan Kenneweg, Philip Kenneweg, Barbara Hammer|<http://arxiv.org/pdf/2504.16591v1>|提出JEPA架构，用于图像强化学习，有效防止模型崩溃，提升Cart Pole任务表现。|
|🆕 发布|A Few-Shot Metric Learning Method with Dual-Channel Attention for Cross-Modal Same-Neuron Identification|少量样本度量学习方法，用于跨模态同神经元识别的双通道注意力机制|Wenwei Li, Liyi Cai, Wu Chen, Anan Li|<http://arxiv.org/pdf/2504.16520v1>|提出了一种结合双通道注意力和预训练视觉Transformer的少量样本度量学习方法，有效解决了跨模态...|
|🆕 发布|MTSGL: Multi-Task Structure Guided Learning for Robust and Interpretable SAR Aircraft Recognition|多任务结构引导学习：用于鲁棒和可解释的合成孔径雷达飞机识别|Qishan He, Lingjun Zhao, Ru Luo, Siqian Zhang, Lin Lei, Kefeng Ji, Gangyao Kuang|<http://arxiv.org/pdf/2504.16467v1>|提出一种结合结构信息和多任务学习的SAR飞机识别方法，显著提升识别的鲁棒性和可解释性。|
|🆕 发布|MAGIC: Near-Optimal Data Attribution for Deep Learning|MAGIC：深度学习近最优数据归因|Andrew Ilyas, Logan Engstrom|<http://arxiv.org/pdf/2504.16430v1>|提出MAGIC方法，有效解决大规模非凸场景下深度学习数据归因问题。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 目标导向视觉决策 (Goal-oriented Visual Decision Making)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Think Hierarchically, Act Dynamically: Hierarchical Multi-modal Fusion and Reasoning for Vision-and-Language Navigation|思考分层，行动动态：视觉与语言导航的分层多模态融合与推理|Junrong Yue, Yifan Zhang, Chuan Qin, Bo Li, Xiaomin Lie, Xinlei Yu, Wenxin Zhang, Zhendong Zhao|<http://arxiv.org/pdf/2504.16516v1>|提出了一种多级融合与推理架构，通过融合视觉、语言和导航历史信息，显著提升了视觉与语言导航的决策准确性...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Critic-V: VLM Critics Help Catch VLM Errors in Multimodal Reasoning|Critic-V：视觉语言模型批评家帮助捕捉多模态推理中的视觉语言模型错误|Di Zhang, Junxian Li, Jingdi Lei, Xunzhi Wang, Yujie Liu, Zonglin Yang, Jiatong Li, Weida Wang .etc.|<http://arxiv.org/pdf/2411.18203v5>|Critic-V通过引入独立推理和批评组件，显著提升了视觉语言模型在多模态推理任务中的准确性和效率。|
|🆕 发布|V$^2$R-Bench: Holistically Evaluating LVLM Robustness to Fundamental Visual Variations|V$^2$R-Bench：全面评估LVLM对基本视觉变化的鲁棒性|Zhiyuan Fan, Yumeng Wang, Sandeep Polisetty, Yi R. Fung|<http://arxiv.org/pdf/2504.16727v2>|构建V$^2$R-Bench评估框架，揭示大型视觉语言模型对视觉变化的脆弱性。|
|🆕 发布|Detecting and Understanding Hateful Contents in Memes Through Captioning and Visual Question-Answering|通过标题生成和视觉问答检测及理解表情包中的仇恨内容|Ali Anaissi, Junaid Akram, Kunal Chaturvedi, Ali Braytee|<http://arxiv.org/pdf/2504.16723v1>|提出一种多模态框架，通过OCR、字幕、子标签分类、RAG和VQA技术检测和解析仇恨内容。|
|📝 更新|Ask2Loc: Learning to Locate Instructional Visual Answers by Asking Questions|Ask2Loc：通过提问学习定位教学视觉答案|Chang Zong, Bin Li, Shoujun Zhou, Jian Wan, Lei Zhang|<http://arxiv.org/pdf/2504.15918v2>|[代码](https://github.com/changzong/Ask2Loc.); 提出Ask2Loc框架，通过提问交互式解决视频答案定位中的语义差距问题。|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MMMORRF: Multimodal Multilingual Modularized Reciprocal Rank Fusion|多模态多语言模块化互信息排序融合|Saron Samuel, Dan DeGenaro, Jimena Guallar-Blasco, Kate Sanders, Oluwaseun Eisape, Arun Reddy, Alexander Martin, Andrew Yates .etc.|<http://arxiv.org/pdf/2503.20698v3>|提出了一种融合多模态信息的视频检索系统，显著提升了检索效果。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|High-Quality Cloud-Free Optical Image Synthesis Using Multi-Temporal SAR and Contaminated Optical Data|高质量无云光学图像合成：基于多时相SAR和污染光学数据|Chenxi Duan|<http://arxiv.org/pdf/2504.16870v1>|提出CRSynthNet网络，利用多时相SAR和污染光学数据实现高质量无云光学图像合成。|
|📝 更新|MediSee: Reasoning-based Pixel-level Perception in Medical Images|MediSee：基于推理的医学图像像素级感知|Qinyue Tong, Ziqian Lu, Jun Liu, Yangming Zheng, Zheming Lu|<http://arxiv.org/pdf/2504.11008v2>|提出MediSee模型，通过逻辑推理实现医学图像的语义分割与检测。|
|📝 更新|Deep Anatomical Federated Network (Dafne): An open client-server framework for the continuous, collaborative improvement of deep learning-based medical image segmentation|深度解剖联邦网络（Dafne）：一个用于基于深度学习的医学图像分割持续、协作改进的开源客户端-服务器框架|Francesco Santini, Jakob Wasserthal, Abramo Agosti, Xeni Deligianni, Kevin R. Keene, Hermien E. Kan, Stefan Sommer, Fengdan Wang .etc.|<http://arxiv.org/pdf/2302.06352v4>|Dafne通过联邦增量学习，实现了医疗图像分割的持续协作改进，提升了分割精度。|
|📝 更新|MedNNS: Supernet-based Medical Task-Adaptive Neural Network Search|MedNNS：基于超网络的医学任务自适应神经网络搜索|Lotfi Abdelkrim Mecharbat, Ibrahim Almakky, Martin Takac, Mohammad Yaqub|<http://arxiv.org/pdf/2504.15865v2>|[代码](https://github.com/BioMedIA-MBZUAI/MedNNS.); 提出MedNNS，通过超网络优化医学图像模型架构和初始化，显著提升性能和收敛速度。|
|📝 更新|Embedding Radiomics into Vision Transformers for Multimodal Medical Image Classification|将放射组学嵌入视觉Transformer进行多模态医学图像分类|Zhenyu Yang, Haiming Zhu, Rihui Zhang, Haipeng Zhang, Jianliang Wang, Chunhao Wang, Minbin Chen, Fang-Fang Yin|<http://arxiv.org/pdf/2504.10916v2>|提出RE-ViT框架，将放射组学特征与视觉Transformer结合，提升多模态医学图像分类性能。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Gaussian Splatting is an Effective Data Generator for 3D Object Detection|高斯喷溅是3D目标检测的有效数据生成器|Farhad G. Zanjani, Davide Abati, Auke Wiggers, Dimitris Kalatzis, Jens Petersen, Hong Cai, Amirhossein Habibian|<http://arxiv.org/pdf/2504.16740v1>|利用高斯分层重建直接在3D空间放置物体，有效提升3D目标检测性能。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Diff-Attention Aware State Space Fusion Model for Remote Sensing Classification|差分注意力感知的遥感分类状态空间融合模型|Wenping Ma, Boyou Xue, Mengru Ma, Chuang Chen, Hekai Zhang, Hao Zhu|<http://arxiv.org/pdf/2504.16665v1>|[代码](https://github.com/AVKSKVL/DAS-F-Model); 提出了一种融合多源遥感图像特征并利用注意力机制进行有效融合的方法，提升了分类性能。|
|🆕 发布|SAIP-Net: Enhancing Remote Sensing Image Segmentation via Spectral Adaptive Information Propagation|SAIP-Net：通过光谱自适应信息传播增强遥感图像分割|Zhongtao Wang, Xizhe Cao, Yisong Chen, Guoping Wang|<http://arxiv.org/pdf/2504.16564v1>|SAIP-Net通过光谱自适应信息传播，有效提升遥感图像分割精度。|
|🆕 发布|FrogDogNet: Fourier frequency Retained visual prompt Output Guidance for Domain Generalization of CLIP in Remote Sensing|蛙狗网：基于傅里叶频率保留的视觉提示输出引导，用于遥感领域CLIP的域泛化|Hariseetharam Gunduboina, Muhammad Haris Khan, Biplab Banerjee|<http://arxiv.org/pdf/2504.16433v1>|[代码](https://github.com/HariseetharamG/FrogDogNet); FrogDogNet通过保留低频不变特征，有效提升了遥感图像分类和领域泛化能力。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Beyond Anonymization: Object Scrubbing for Privacy-Preserving 2D and 3D Vision Tasks|超越匿名化：隐私保护下的二维和三维视觉任务中的对象清洗|Murat Bilgehan Ertan, Ronak Sahu, Phuong Ha Nguyen, Kaleel Mahmood, Marten van Dijk|<http://arxiv.org/pdf/2504.16557v1>|提出ROAR框架，通过移除敏感对象而非修改它们，实现隐私保护数据集的鲁棒匿名化。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Revisiting Radar Camera Alignment by Contrastive Learning for 3D Object Detection|重新审视基于对比学习的雷达相机对准方法在3D目标检测中的应用|Linhua Kong, Dongxia Chang, Lian Liu, Zisen Kong, Pengyuan Li, Yao Zhao|<http://arxiv.org/pdf/2504.16368v1>|提出RCAlign模型，通过对比学习融合雷达与摄像头特征，显著提升3D目标检测性能。|
|📝 更新|EvTTC: An Event Camera Dataset for Time-to-Collision Estimation|EvTTC：用于碰撞时间估计的事件相机数据集|Kaizhen Sun, Jinghang Li, Kuan Dai, Bangyan Liao, Wei Xiong, Yi Zhou|<http://arxiv.org/pdf/2412.05053v3>|构建了首个多传感器数据集EvTTC，用于高相对速度场景下的碰撞时间估计研究。|
|🆕 发布|A Time Series Dataset of NIR Spectra and RGB and NIR-HSI Images of the Barley Germination Process|小麦发芽过程近红外光谱和RGB及NIR-HSI图像的时间序列数据集|Ole-Christian Galbo Engstrøm, Erik Schou Dreier, Birthe Møller Jespersen, Kim Steenstrup Pedersen|<http://arxiv.org/pdf/2504.16658v1>|构建了包含 barley 萌发过程 RGB、NIR-HSI 图像及光谱的时序数据集，以促进萌发时间分...|

