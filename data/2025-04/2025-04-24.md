## [UPDATED!] **2025-04-24** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Token-Shuffle: Towards High-Resolution Image Generation with Autoregressive Models|Token-Shuffle：迈向具有自回归模型的超分辨率图像生成|Xu Ma, Peize Sun, Haoyu Ma, Hao Tang, Chih-Yao Ma, Jialiang Wang, Kunpeng Li, Xiaoliang Dai .etc.|<http://arxiv.org/pdf/2504.17789v1>|Token-Shuffle通过减少Transformer中的图像token数量，实现了高效的高分辨率...|
|🆕 发布|PICO: Reconstructing 3D People In Contact with Objects|PICO：与物体接触的3D人体重建|Alpár Cseke, Shashank Tripathi, Sai Kumar Dwivedi, Arjun Lakshmipathy, Agniv Chatterjee, Michael J. Black, Dimitrios Tzionas|<http://arxiv.org/pdf/2504.17695v1>|提出PICO数据库和PICO-fit方法，从单色图像中重建3D人物与物体交互。|
|🆕 发布|DiMeR: Disentangled Mesh Reconstruction Model|DiMeR：解耦网格重建模型|Lutao Jiang, Jiantao Lin, Kanghao Chen, Wenhang Ge, Xin Yang, Yifan Jiang, Yuanhuiyi Lyu, Xu Zheng .etc.|<http://arxiv.org/pdf/2504.17670v1>|DiMeR通过分离几何和纹理，显著提升了稀疏视图网格重建的性能。|
|📝 更新|AgentsCoMerge: Large Language Model Empowered Collaborative Decision Making for Ramp Merging|智能体协同合并：基于大型语言模型的匝道合并协同决策|Senkang Hu, Zhengru Fang, Zihan Fang, Yiqin Deng, Xianhao Chen, Yuguang Fang, Sam Kwong|<http://arxiv.org/pdf/2408.03624v2>|提出 AgentsCoMerge 框架，利用大型语言模型实现多车道匝道合并的协同决策，提升交通效率和...|
|🆕 发布|Fine-tune Smarter, Not Harder: Parameter-Efficient Fine-Tuning for Geospatial Foundation Models|更智能的微调，而非更艰难：地理空间基础模型的参数高效微调|Francesc Marti-Escofet, Benedikt Blumenstiel, Linus Scheibenreif, Paolo Fraccaro, Konrad Schindler|<http://arxiv.org/pdf/2504.17397v1>|提出了一种参数高效的微调方法，显著提升了地理空间基础模型的适应性和效率。|
|🆕 发布|TimeSoccer: An End-to-End Multimodal Large Language Model for Soccer Commentary Generation|时间足球：用于足球解说生成的端到端多模态大型语言模型|Ling You, Wenxuan Huang, Xinni Xie, Xiangyi Wei, Bangyan Li, Shaohui Lin, Yang Li, Changbo Wang|<http://arxiv.org/pdf/2504.17365v1>|TimeSoccer提出了一种端到端的多模态大语言模型，实现了足球比赛视频的实时解说生成。|
|📝 更新|Dynamic Pyramid Network for Efficient Multimodal Large Language Model|动态金字塔网络：高效的多模态大型语言模型|Hao Ai, Kunyi Wang, Zezhou Wang, Hao Lu, Jin Tian, Yaxin Luo, Peng Xing, Jen-Yuan Huang .etc.|<http://arxiv.org/pdf/2503.20322v2>|[代码](https://github.com/aihao2000/DPN-LLaVA.); 提出动态金字塔网络，有效压缩视觉特征，提升多模态大语言模型性能。|
|🆕 发布|DIMT25@ICDAR2025: HW-TSC's End-to-End Document Image Machine Translation System Leveraging Large Vision-Language Model|2025@ICDAR2025：利用大型视觉-语言模型的HW-TSC端到端文档图像机器翻译系统|Zhanglin Wu, Tengfei Song, Ning Xie, Weidong Zhang, Pengfei Li, Shuang Wu, Chong Li, Junhao Zhu .etc.|<http://arxiv.org/pdf/2504.17315v1>|提出一种结合多任务学习和感知思维链的端到端文档图像机器翻译系统，有效解决复杂布局文档翻译问题。|
|📝 更新|Vidi: Large Multimodal Models for Video Understanding and Editing|视频理解与编辑的大规模多模态模型：Vidi|Vidi Team, Celong Liu, Chia-Wen Kuo, Dawei Du, Fan Chen, Guang Chen, Jiamin Yuan, Lingxi Zhang .etc.|<http://arxiv.org/pdf/2504.15681v2>|Vidi提出了一种处理视频理解和编辑的多模态模型，显著提升了视频检索和编辑效率。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|jina-clip-v2: Multilingual Multimodal Embeddings for Text and Images|Jina-Clip-v2：文本和图像的多语言多模态嵌入|Andreas Koukounas, Georgios Mastrapas, Sedigheh Eslami, Bo Wang, Mohammad Kalim Akram, Michael Günther, Isabelle Mohr, Saba Sturua .etc.|<http://arxiv.org/pdf/2412.08802v2>|提出jina-clip-v2，通过多语言多模态嵌入，提升文本和图像理解能力。|
|🆕 发布|Plasma State Monitoring and Disruption Characterization using Multimodal VAEs|等离子体状态监测与破坏特征化利用多模态变分自编码器|Yoeri Poels, Alessandro Pau, Christian Donner, Giulio Romanelli, Olivier Sauter, Cristina Venturini, Vlado Menkovski, the TCV team .etc.|<http://arxiv.org/pdf/2504.17710v1>|利用多模态变分自编码器，实现了对等离子体状态的可解释表征，以识别和预测等离子体破坏。|
|📝 更新|Lumina-mGPT: Illuminate Flexible Photorealistic Text-to-Image Generation with Multimodal Generative Pretraining|Lumina-mGPT：利用多模态生成预训练照亮灵活的逼真文本到图像生成|Dongyang Liu, Shitian Zhao, Le Zhuo, Weifeng Lin, Yi Xin, Xinyue Li, Qi Qin, Yu Qiao .etc.|<http://arxiv.org/pdf/2408.02657v3>|[代码](https://github.com/Alpha-VLLM/Lumina-mGPT.); Lumina-mGPT通过多模态生成预训练和灵活的图像表示，实现了高效、灵活的文本到图像生成。|
|📝 更新|PhysFlow: Unleashing the Potential of Multi-modal Foundation Models and Video Diffusion for 4D Dynamic Physical Scene Simulation|PhysFlow：释放多模态基础模型和视频扩散在4D动态物理场景模拟中的潜力|Zhuoman Liu, Weicai Ye, Yan Luximon, Pengfei Wan, Di Zhang|<http://arxiv.org/pdf/2411.14423v3>|PhysFlow通过多模态基础模型和视频扩散，实现了基于物理原理的4D动态场景模拟，提升了真实场景中...|
|📝 更新|QUART-Online: Latency-Free Large Multimodal Language Model for Quadruped Robot Learning|QUART-Online：用于四足机器人学习的无延迟大型多模态语言模型|Xinyang Tong, Pengxiang Ding, Yiguo Fan, Donglin Wang, Wenjie Zhang, Can Cui, Mingyang Sun, Han Zhao .etc.|<http://arxiv.org/pdf/2412.15576v4>|提出QUART-Online模型，解决四足机器人多模态语言模型推理延迟问题，提升任务成功率65%。|
|🆕 发布|A Genealogy of Multi-Sensor Foundation Models in Remote Sensing|遥感中多传感器基础模型的谱系|Kevin Lane, Morteza Karimzadeh|<http://arxiv.org/pdf/2504.17177v1>|探究了多传感器基础模型在遥感领域的应用，分析了其优势与挑战，并提出了改进方向。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Comprehensive Survey of Knowledge-Based Vision Question Answering Systems: The Lifecycle of Knowledge in Visual Reasoning Task|基于知识的视觉推理任务中知识生命周期的全面调查：知识在视觉问答系统中的应用|Jiaqi Deng, Zonghan Wu, Huan Huo, Guandong Xu|<http://arxiv.org/pdf/2504.17547v1>|构建了知识图谱视觉问答系统的生命周期框架，系统性地梳理了现有方法，并指出了未来研究方向。|
|📝 更新|3D-LLaVA: Towards Generalist 3D LMMs with Omni Superpoint Transformer|3D-LLaVA：迈向通用3D LMMs的万向超点Transformer|Jiajun Deng, Tianyu He, Li Jiang, Tianyu Wang, Feras Dayoub, Ian Reid|<http://arxiv.org/pdf/2501.01163v2>|提出3D-LLaVA，一种以点云为输入的3D LMM，通过Omni Superpoint Trans...|
|🆕 发布|Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery Simulation|基于心理图像模拟的视觉-语言模型中的透视感知推理|Phillip Y. Lee, Jihyeon Je, Chanho Park, Mikaela Angelina Uy, Leonidas Guibas, Minhyuk Sung|<http://arxiv.org/pdf/2504.17207v1>|通过模拟心理意象，提出了一种提升视觉语言模型视角感知推理能力的框架。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DDU-Net: A Domain Decomposition-Based CNN for High-Resolution Image Segmentation on Multiple GPUs|DDU-Net：基于域分解的CNN在多个GPU上实现高分辨率图像分割|Corné Verburg, Alexander Heinlein, Eric C. Cyr|<http://arxiv.org/pdf/2407.21266v3>|[代码](https://github.com/corne00/DDU-Net.); 提出了一种基于域分解的CNN，通过独立处理图像块并交换信息，有效提升了超高清图像分割的性能。|
|🆕 发布|Aerial Image Classification in Scarce and Unconstrained Environments via Conformal Prediction|通过一致预测在稀缺和不受约束环境中进行航空图像分类|Farhad Pourkamali-Anaraki|<http://arxiv.org/pdf/2504.17655v1>|该论文通过结合预训练模型和符合预测技术，在数据稀缺和复杂环境下实现了空中图像分类，并揭示了温度缩放和...|
|🆕 发布|Enhanced Sample Selection with Confidence Tracking: Identifying Correctly Labeled yet Hard-to-Learn Samples in Noisy Data|基于置信度跟踪的增强样本选择：在噪声数据中识别正确标注但难以学习的样本|Weiran Pan, Wei Wei, Feida Zhu, Yong Deng|<http://arxiv.org/pdf/2504.17474v1>|提出一种基于模型预测置信度趋势的样本选择方法，有效识别噪声数据中的正确标签且难以学习的样本。|
|🆕 发布|Group Downsampling with Equivariant Anti-aliasing|具有等变抗锯齿的分组下采样|Md Ashiqur Rahman, Raymond A. Yeh|<http://arxiv.org/pdf/2504.17258v1>|提出了一种基于群等变架构的降采样方法，有效提升图像分类准确率并减小模型尺寸。|
|📝 更新|On the Generalizability of Foundation Models for Crop Type Mapping|关于作物类型映射基础模型泛化能力的探讨|Yi-Chia Chang, Adam J. Stewart, Favyen Bastani, Piper Wolters, Shreya Kannan, George R. Huber, Jingtong Wang, Arindam Banerjee|<http://arxiv.org/pdf/2409.09451v3>|研究了EO基础模型在农业领域的迁移能力，发现针对特定卫星图像预训练的模型优于通用模型，并揭示了数据不...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Improving Open-World Object Localization by Discovering Background|通过发现背景改进开放世界物体定位|Ashish Singh, Michael J. Jones, Kuan-Chuan Peng, Anoop Cherian, Moitreya Chatterjee, Erik Learned-Miller|<http://arxiv.org/pdf/2504.17626v1>|通过发现背景信息，该论文提出了一种新框架，显著提升了开放世界场景下物体定位的准确性。|
|📝 更新|Large-image Object Detection for Fine-grained Recognition of Punches Patterns in Medieval Panel Painting|大型图像目标检测在中世纪木板画打孔图案精细识别中的应用|Josh Bruegger, Diana Ioana Catana, Vanja Macovaz, Matias Valdenegro-Toro, Matthia Sabatelli, Marco Zullich|<http://arxiv.org/pdf/2501.12489v2>|开发了一种基于YOLOv10的大图像目标检测方法，以辅助艺术史学家识别和提取中世纪壁画中的打孔图案。|
|🆕 发布|OUI Need to Talk About Weight Decay: A New Perspective on Overfitting Detection|我们需要谈谈权重衰减：过拟合检测的新视角|Alberto Fernández-Hernández, Jose I. Mestre, Manuel F. Dolz, Jose Duato, Enrique S. Quintana-Ortí|<http://arxiv.org/pdf/2504.17160v1>|[代码](https://github.com/AlbertoFdezHdez/OUI.); 提出OUI指标，通过监测训练动态识别过拟合和欠拟合，优化深度神经网络权重衰减超参数。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Tamper-evident Image using JPEG Fixed Points|防篡改图像：利用JPEG固定点|Zhaofeng Si, Siwei Lyu|<http://arxiv.org/pdf/2504.17594v1>|利用JPEG压缩固定点特性，提出了一种可验证篡改的图像生成方法。|
|📝 更新|OmniMamba4D: Spatio-temporal Mamba for longitudinal CT lesion segmentation|全视域Mamba4D：用于纵向CT病变分割的空间时间Mamba|Justin Namuk Kim, Yiqiao Liu, Rajath Soans, Keith Persson, Sarah Halek, Michal Tomaszewski, Jianda Yuan, Gregory Goldmacher .etc.|<http://arxiv.org/pdf/2504.09655v2>|提出OmniMamba4D模型，有效融合时空信息，提升纵向CT病变分割精度。|
|📝 更新|RSEND: Retinex-based Squeeze and Excitation Network with Dark Region Detection for Efficient Low Light Image Enhancement|基于Retinex的暗区检测Squeeze-and-Excitation网络用于高效低光图像增强：RSEND|Jingcheng Li, Ye Qiao, Haocheng Xu, Sitao Huang|<http://arxiv.org/pdf/2406.09656v2>|提出了一种基于Retinex和Squeeze and Excitation网络的低光图像增强方法，有...|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LiDPM: Rethinking Point Diffusion for Lidar Scene Completion|LiDPM：重新思考激光雷达场景补全中的点扩散|Tetiana Martyniuk, Gilles Puy, Alexandre Boulch, Renaud Marlet, Raoul de Charette|<http://arxiv.org/pdf/2504.17791v1>|[代码](https://astra-vision.github.io/LiDPM); 提出LiDPM方法，通过优化点扩散模型，有效提升了激光雷达场景补全效果。|
|📝 更新|Weak-to-Strong Diffusion with Reflection|弱到强扩散与反射|Lichen Bai, Masashi Sugiyama, Zeke Xie|<http://arxiv.org/pdf/2502.00473v3>|提出W2SD框架，通过弱到强模型差异引导潜在变量，显著提升生成模型性能。|
|🆕 发布|Occlusion-Aware Self-Supervised Monocular Depth Estimation for Weak-Texture Endoscopic Images|遮挡感知的自监督单目深度估计用于弱纹理内窥镜图像|Zebo Huang, Yinghui Wang|<http://arxiv.org/pdf/2504.17582v1>|提出了一种针对弱纹理内窥镜图像的遮挡感知自监督单目深度估计网络，显著提升了深度重建质量。|
|📝 更新|Continuous and complete liver vessel segmentation with graph-attention guided diffusion|基于图注意力引导的扩散连续完整肝脏血管分割|Xiaotong Zhang, Alexander Broersen, Gonnie CM van Erp, Silvia L. Pintea, Jouke Dijkstra|<http://arxiv.org/pdf/2411.00617v2>|提出了一种基于图注意力扩散模型，有效提升肝脏血管连续性和完整性分割的方法。|
|🆕 发布|Text-to-Image Alignment in Denoising-Based Models through Step Selection|基于步骤选择的去噪模型中的文本到图像对齐|Paul Grimal, Hervé Le Borgne, Olivier Ferret|<http://arxiv.org/pdf/2504.17525v1>|通过选择关键去噪步骤优化信号，本文提出的方法显著提升了基于文本的图像生成与语义对齐。|
|🆕 发布|ESDiff: Encoding Strategy-inspired Diffusion Model with Few-shot Learning for Color Image Inpainting|ESDiff：基于编码策略的扩散模型与少样本学习用于彩色图像修复|Junyan Zhang, Yan Li, Mengxiao Geng, Liu Shi, Qiegen Liu|<http://arxiv.org/pdf/2504.17524v1>|提出一种基于编码策略的扩散模型，实现少量样本下的彩色图像修复，提升细节和结构完整性。|
|🆕 发布|3DV-TON: Textured 3D-Guided Consistent Video Try-on via Diffusion Models|3DV-TON：基于扩散模型的纹理3D引导一致视频试穿|Min Wei, Chaohui Yu, Jingkai Zhou, Fan Wang|<http://arxiv.org/pdf/2504.17414v1>|[代码](https://2y7c3.github.io/3DV-TON); 提出了一种基于扩散模型的视频试穿新方法，通过3D纹理引导实现高质量和时序一致性。|
|🆕 发布|SDVPT: Semantic-Driven Visual Prompt Tuning for Open-World Object Counting|语义驱动开放世界物体计数视觉提示微调：SDVPT|Yiming Zhao, Guorong Li, Laiyun Qing, Amin Beheshti, Jian Yang, Michael Sheng, Yuankai Qi, Qingming Huang|<http://arxiv.org/pdf/2504.17395v1>|提出SDVPT框架，通过语义驱动视觉提示微调，提升开放世界物体计数模型的泛化能力。|
|🆕 发布|M-MRE: Extending the Mutual Reinforcement Effect to Multimodal Information Extraction|M-MRE：将互增强效应扩展到多模态信息提取|Chengguang Gan, Sunbowen Lee, Zhixi Cai, Yanbin Wei, Lei Zheng, Yunhao Liang, Shiwen Ni, Tatsunori Mori|<http://arxiv.org/pdf/2504.17353v1>|将互促效应扩展至多模态信息提取，提出Prompt格式适配器，提升多模态文本图像理解性能。|
|📝 更新|Diffusion Models Are Real-Time Game Engines|扩散模型是实时游戏引擎|Dani Valevski, Yaniv Leviathan, Moab Arar, Shlomi Fruchter|<http://arxiv.org/pdf/2408.14837v2>|提出GameNGen，首个利用神经网络实现实时游戏环境交互的游戏引擎。|
|🆕 发布|AUTHENTICATION: Identifying Rare Failure Modes in Autonomous Vehicle Perception Systems using Adversarially Guided Diffusion Models|认证：利用对抗引导扩散模型识别自动驾驶车辆感知系统中的罕见故障模式|Mohammad Zarei, Melanie A Jutras, Eliana Evans, Mike Tan, Omid Aaramoon|<http://arxiv.org/pdf/2504.17179v1>|利用对抗引导的扩散模型识别自动驾驶感知系统中的罕见故障模式，提升系统鲁棒性和可靠性。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Step1X-Edit: A Practical Framework for General Image Editing|Step1X-Edit：一种通用于图像编辑的实用框架|Shiyu Liu, Yucheng Han, Peng Xing, Fukun Yin, Rui Wang, Wei Cheng, Jiaqi Liao, Yingming Wang .etc.|<http://arxiv.org/pdf/2504.17761v1>|提出Step1X-Edit模型，通过多模态LLM和扩散图像解码器实现高效图像编辑，显著提升开源算法性...|
|🆕 发布|Dynamic Camera Poses and Where to Find Them|动态相机姿态及其寻找方法|Chris Rockwell, Joseph Tung, Tsung-Yi Lin, Ming-Yu Liu, David F. Fouhey, Chen-Hsuan Lin|<http://arxiv.org/pdf/2504.17788v1>|构建了大规模动态互联网视频姿态标注数据集，结合最新技术提升姿态估计准确性。|
|🆕 发布|Generative Fields: Uncovering Hierarchical Feature Control for StyleGAN via Inverted Receptive Fields|生成场：通过逆感受野揭示StyleGAN的层次化特征控制|Zhuo He, Paul Henderson, Nicolas Pugeault|<http://arxiv.org/pdf/2504.17712v1>|通过引入“生成场”概念，该论文揭示了StyleGAN的层级特征合成，并提出了一种基于CNN结构特征的...|
|🆕 发布|The effects of Hessian eigenvalue spectral density type on the applicability of Hessian analysis to generalization capability assessment of neural networks|赫塞尔特征值谱密度类型对赫塞尔分析在神经网络泛化能力评估中适用性的影响|Nikita Gabdullin|<http://arxiv.org/pdf/2504.17618v1>|研究了Hessian特征值谱密度对神经网络泛化能力评估的影响，提出了统一的分析方法。|
|🆕 发布|RefVNLI: Towards Scalable Evaluation of Subject-driven Text-to-image Generation|RefVNLI：迈向可扩展的主语驱动文本到图像生成评估|Aviv Slobodkin, Hagai Taitelbaum, Yonatan Bitton, Brian Gordon, Michal Sokolik, Nitzan Bitton Guetta, Almog Gueta, Royi Rassin .etc.|<http://arxiv.org/pdf/2504.17502v1>|提出RefVNLI，一种评估文本到图像生成中文本对齐和主题保持的指标，显著提升评价准确性。|
|🆕 发布|FRAG: Frame Selection Augmented Generation for Long Video and Long Document Understanding|帧选择增强生成：用于长视频和长文档理解|De-An Huang, Subhashree Radhakrishnan, Zhiding Yu, Jan Kautz|<http://arxiv.org/pdf/2504.17447v1>|[代码](https://github.com/NVlabs/FRAG); FRAG通过独立评分和Top-K选择，有效处理长视频和长文档，显著提升LMMs性能。|
|🆕 发布|Unveiling Hidden Vulnerabilities in Digital Human Generation via Adversarial Attacks|揭示数字人生成中的隐藏漏洞：通过对抗攻击揭露|Zhiying Li, Yeying Jin, Fan Shen, Zhi Liu, Weibin Chen, Pengju Zhang, Xiaomei Zhang, Boyu Chen .etc.|<http://arxiv.org/pdf/2504.17457v1>|提出了一种新型攻击框架，通过生成对抗样本显著提升了数字人生成模型的脆弱性。|
|🆕 发布|DIVE: Inverting Conditional Diffusion Models for Discriminative Tasks|DIVE：为判别任务反演条件扩散模型|Yinqi Li, Hong Chang, Ruibing Hou, Shiguang Shan, Xilin Chen|<http://arxiv.org/pdf/2504.17253v1>|[代码](https://github.com/LiYinqi/DIVE); 将预训练扩散模型应用于目标检测，通过逆模型和优化方法实现高效判别任务。|
|🆕 发布|Scene Perceived Image Perceptual Score (SPIPS): combining global and local perception for image quality assessment|场景感知图像感知评分（SPIPS）：结合全局和局部感知进行图像质量评估|Zhiqiang Lao, Heather Yu|<http://arxiv.org/pdf/2504.17234v1>|提出SPIPS方法，结合全局与局部感知，提升图像质量评估的准确性。|
|🆕 发布|We'll Fix it in Post: Improving Text-to-Video Generation with Neuro-Symbolic Feedback|我们在后期修复：利用神经符号反馈改进文本到视频生成|Minkyu Choi, S P Sharan, Harsh Goel, Sahil Shah, Sandeep Chinchali|<http://arxiv.org/pdf/2504.17180v1>|引入神经符号反馈，自动优化视频生成，显著提升文本到视频的时序和逻辑一致性。|
|📝 更新|Neuro-Symbolic Evaluation of Text-to-Video Models using Formal Verification|神经符号形式验证在文本到视频模型评估中的应用|S. P. Sharan, Minkyu Choi, Sahil Shah, Harsh Goel, Mohammad Omama, Sandeep Chinchali|<http://arxiv.org/pdf/2411.16718v4>|引入NeuS-V，通过神经符号形式验证技术评估文本到视频模型的时序一致性和对齐。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Contrastive Learning with Synthetic Positives|对比学习与合成正样本|Dewen Zeng, Yawen Wu, Xinrong Hu, Xiaowei Xu, Yiyu Shi|<http://arxiv.org/pdf/2408.16965v2>|提出CLSP方法，利用合成图像作为正样本，提升对比学习性能。|
|📝 更新|FMNV: A Dataset of Media-Published News Videos for Fake News Detection|FMNV：用于虚假新闻检测的媒体发布新闻视频数据集|Yihao Wang, Zhong Qian, Peifeng Li|<http://arxiv.org/pdf/2504.07687v2>|构建了专门针对媒体发布新闻视频的假新闻检测数据集，并提出了一种基于CLIP和Faster R-CNN...|
|📝 更新|ObjectAdd: Adding Objects into Image via a Training-Free Diffusion Modification Fashion|ObjectAdd：通过无训练扩散修改方式将对象添加到图像中|Ziyue Zhang, Mingbao Lin, Quanjian Song, Yuxin Zhang, Rongrong Ji|<http://arxiv.org/pdf/2404.17230v3>|ObjectAdd通过无监督扩散修改技术，实现将用户指定物体添加到图像指定区域，保持图像一致性。|
|🆕 发布|DRC: Enhancing Personalized Image Generation via Disentangled Representation Composition|DRC：通过解耦表示组合增强个性化图像生成|Yiyan Xu, Wuqiang Zheng, Wenjie Wang, Fengbin Zhu, Xinting Hu, Yang Zhang, Fuli Feng, Tat-Seng Chua|<http://arxiv.org/pdf/2504.17349v1>|DRC通过解耦表示组合增强LMM，有效解决个性化图像生成中的风格和语义融合问题。|
|🆕 发布|Towards Generalized and Training-Free Text-Guided Semantic Manipulation|通向泛化和免训练的文本引导语义操作|Yu Hong, Xiao Cai, Pengpeng Zeng, Shuai Zhang, Jingkuan Song, Lianli Gao, Heng Tao Shen|<http://arxiv.org/pdf/2504.17269v1>|提出了一种无需训练的通用文本引导语义操作方法，实现高效且多功能的图像内容编辑。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CLIPSE -- a minimalistic CLIP-based image search engine for research|CLIPSE ——一个基于CLIP的最小化图像搜索引擎，用于研究|Steve Göring|<http://arxiv.org/pdf/2504.17643v1>|CLIPSE利用CLIP模型简化图像搜索，适用于研究场景，支持小数据集，可扩展至大数据集。|
|📝 更新|Marginalized Generalized IoU (MGIoU): A Unified Objective Function for Optimizing Any Convex Parametric Shapes|边际广义IoU（MGIoU）：优化任何凸参数形状的统一目标函数|Duy-Tho Le, Trung Pham, Jianfei Cai, Hamid Rezatofighi|<http://arxiv.org/pdf/2504.16443v2>|[代码](https://ldtho.github.io/MGIoU); 提出MGIoU，统一了参数形状优化目标函数，有效解决了现有方法的不足。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CasualHDRSplat: Robust High Dynamic Range 3D Gaussian Splatting from Casually Captured Videos|非专业HDRSplat：从随意捕获的视频中鲁棒的3D高动态范围高斯Splatting|Shucheng Gong, Lingzhe Zhao, Wenpu Li, Hong Xie, Yin Zhang, Shiyu Zhao, Peidong Liu|<http://arxiv.org/pdf/2504.17728v1>|[代码](https://github.com/WU-CVGL/CasualHDRSplat); CasualHDRSplat从随手拍摄的带自动曝光的视频中，鲁棒地重建3D高动态范围场景。|
|📝 更新|ARF-Plus: Controlling Perceptual Factors in Artistic Radiance Fields for 3D Scene Stylization|ARF-Plus：控制艺术光场中的感知因素以实现3D场景风格化|Wenzhao Li, Tianhao Wu, Fangcheng Zhong, Cengiz Oztireli|<http://arxiv.org/pdf/2308.12452v3>|提出ARF-Plus框架，通过四种控制手段提升3D场景风格化效果的可感知性。|
|🆕 发布|When Gaussian Meets Surfel: Ultra-fast High-fidelity Radiance Field Rendering|当高斯遇见Surfel：超快速高保真辐射场渲染|Keyang Ye, Tianjia Shao, Kun Zhou|<http://arxiv.org/pdf/2504.17545v1>|提出了一种基于Gaussian和Surfel的混合表示方法，实现了超快速高保真辐射场渲染。|
|🆕 发布|Predict-Optimize-Distill: A Self-Improving Cycle for 4D Object Understanding|预测-优化-蒸馏：4D物体理解的自我改进循环|Mingxuan Wu, Huang Huang, Justin Kerr, Chung Min Kim, Anthony Zhang, Brent Yi, Angjoo Kanazawa|<http://arxiv.org/pdf/2504.17441v1>|提出Predict-Optimize-Distill循环，通过预测和优化相互强化，提升4D物体理解能...|
|🆕 发布|I-INR: Iterative Implicit Neural Representations|迭代隐式神经网络表示：I-INR|Ali Haider, Muhammad Salman Ali, Maryam Qamar, Tahir Khalil, Soo Ye Kim, Jihyong Oh, Enzo Tartaglione, Sung-Ho Bae|<http://arxiv.org/pdf/2504.17364v1>|提出I-INRs，通过迭代优化提升隐式神经网络表示在计算机视觉任务中的重建质量。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BIM-Constrained Optimization for Accurate Localization and Deviation Correction in Construction Monitoring|基于BIM约束的施工监测中精确定位与偏差校正优化|Asier Bikandi, Muhammad Shaheer, Hriday Bavle, Jayan Jevanesan, Holger Voos, Jose Luis Sanchez-Lopez|<http://arxiv.org/pdf/2504.17693v1>|提出BIM约束优化方法，有效解决建筑监测中定位偏差问题，提升AR可视化精度。|
|🆕 发布|EdgePoint2: Compact Descriptors for Superior Efficiency and Accuracy|EdgePoint2：高效与精确的紧凑描述符|Haodi Yao, Fenghua He, Ning Hao, Chen Xie|<http://arxiv.org/pdf/2504.17280v1>|EdgePoint2提出了一种高效且准确的轻量级关键点检测描述方法，优化了边缘计算应用。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HierarQ: Task-Aware Hierarchical Q-Former for Enhanced Video Understanding|HierarQ：任务感知的分层Q-Former以增强视频理解|Shehreen Azad, Vibhav Vineet, Yogesh Singh Rawat|<http://arxiv.org/pdf/2503.08585v2>|引入了任务感知的分层Q-Former框架，有效解决视频理解中的帧和上下文长度限制问题。|
|🆕 发布|MCAF: Efficient Agent-based Video Understanding Framework through Multimodal Coarse-to-Fine Attention Focusing|MCAF：基于多模态粗细粒度注意力聚焦的高效视频理解框架|Shiwen Cao, Zhaoxing Zhang, Junming Jiao, Juyi Qiao, Guowen Song, Rong Shen|<http://arxiv.org/pdf/2504.17213v1>|提出MCAF框架，通过多模态粗细粒度注意力聚焦，有效提升视频理解准确度。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hierarchical and Multimodal Data for Daily Activity Understanding|层次化和多模态数据用于日常活动理解|Ghazal Kaviani, Yavuz Yarici, Seulgi Kim, Mohit Prabhushankar, Ghassan AlRegib, Mashhour Solh, Ameya Patil|<http://arxiv.org/pdf/2504.17696v1>|构建了多模态、分层标注的DARai数据集，以理解日常活动并解决机器学习在人类中心应用中的挑战。|
|📝 更新|A New Graph Grammar Formalism for Robust Syntactic Pattern Recognition|一种用于鲁棒句法模式识别的新图语法形式化方法|Peter Fletcher|<http://arxiv.org/pdf/2504.15975v2>|提出了一种基于图语法的直接声明式语法形式，实现鲁棒性语法模式识别。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs|打破模态壁垒：多模态大型语言模型中的通用嵌入学习|Tiancheng Gu, Kaicheng Yang, Ziyong Feng, Xingjun Wang, Yanzhao Zhang, Dingkun Long, Yingda Chen, Weidong Cai .etc.|<http://arxiv.org/pdf/2504.17432v1>|提出UniME框架，利用MLLMs学习多模态嵌入，突破CLIP局限，提升下游任务性能。|
|🆕 发布|PhysioSync: Temporal and Cross-Modal Contrastive Learning Inspired by Physiological Synchronization for EEG-Based Emotion Recognition|生理同步启发的基于EEG的情绪识别的时序和跨模态对比学习：PhysioSync: Temporal and Cross-Modal Contrastive Learning Inspired by Physiological Synchronization for EEG-Based Emotion Recognition|Kai Cui, Jia Li, Yu Liu, Xuesong Zhang, Zhenzhen Hu, Meng Wang|<http://arxiv.org/pdf/2504.17163v1>|PhysioSync通过结合生理同步现象，提出了一种基于时间与跨模态对比学习的EEG情绪识别新框架，...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DPMambaIR:All-in-One Image Restoration via Degradation-Aware Prompt State Space Model|DPMambaIR：基于退化感知提示状态空间模型的全方位图像恢复|Zhanwen Liu, Sai Zhou, Yuchao Dai, Yang Wang, Yisheng An, Xiangmo Zhao|<http://arxiv.org/pdf/2504.17732v1>|提出DPMambaIR，通过融合DP-SSM和HEB，实现多退化图像的精细建模与高效整合，提升全图像...|
|🆕 发布|Range Image-Based Implicit Neural Compression for LiDAR Point Clouds|基于范围图像的隐式神经网络压缩用于激光雷达点云|Akihiro Kuwabara, Sorachi Kato, Takuya Fujihashi, Toshiaki Koike-Akino, Takashi Watanabe|<http://arxiv.org/pdf/2504.17229v1>|提出了一种基于隐式神经网络的二维激光雷达图像压缩方法，有效提升了压缩效率和3D重建质量。|
|📝 更新|Machine Learning-Based Automated Assessment of Intracorporeal Suturing in Laparoscopic Fundoplication|基于机器学习的腹腔镜胃底折叠术中体内缝合自动评估|Shekhar Madhav Khairnar, Huu Phong Nguyen, Alexis Desir, Carla Holcomb, Daniel J. Scott, Ganesh Sankaranarayanan|<http://arxiv.org/pdf/2412.16195v2>|开发了一种基于SAM的AI工具跟踪模型，实现无标注的腹腔镜缝合技能自动评估。|
|🆕 发布|A Comprehensive Review on RNA Subcellular Localization Prediction|RNA亚细胞定位预测的全面综述|Cece Zhang, Xuehuan Zhu, Nick Peterson, Jieqiong Wang, Shibiao Wan|<http://arxiv.org/pdf/2504.17162v1>|该论文综述了利用人工智能和机器学习预测RNA亚细胞定位的最新进展，为RNA研究加速和疾病治疗指导提供...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards One-Stage End-to-End Table Structure Recognition with Parallel Regression for Diverse Scenarios|迈向多场景并行回归的一阶段端到端表格结构识别|Anyi Xiao, Cihui Yang|<http://arxiv.org/pdf/2504.17522v1>|[代码](https://github.com/dreamy-xay/TableCenterNet.); 提出TableCenterNet，首次将表格空间和逻辑结构预测统一为并行回归任务，实现高效且适应多种...|
|🆕 发布|An Explainable Nature-Inspired Framework for Monkeypox Diagnosis: Xception Features Combined with NGBoost and African Vultures Optimization Algorithm|一种可解释的基于自然界的猴痘诊断框架：Xception特征结合NGBoost和非洲秃鹫优化算法|Ahmadreza Shateri, Negar Nourani, Morteza Dorrigiv, Hamid Nasiri|<http://arxiv.org/pdf/2504.17540v1>|提出了一种结合Xception特征、NGBoost和非洲秃鹫优化算法的深度学习框架，用于猴痘诊断，显...|
|🆕 发布|Precision Neural Network Quantization via Learnable Adaptive Modules|通过可学习自适应模块进行精确神经网络量化|Wenqiang Zhou, Zhendong Yu, Xinyu Liu, Jiaming Yang, Rong Xiao, Tao Wang, Chenwei Tang, Jiancheng Lv|<http://arxiv.org/pdf/2504.17263v1>|提出自适应步长量化方法，有效解决神经网络量化中的性能与灵活性冲突。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RGB-D Tracking via Hierarchical Modality Aggregation and Distribution Network|基于分层模态聚合和分布网络的RGB-D跟踪|Boyue Xu, Yi Xu, Ruichao Hou, Jia Bei, Tongwei Ren, Gangshan Wu|<http://arxiv.org/pdf/2504.17595v1>|提出了一种分层模态聚合与分布网络，有效提升了RGB-D跟踪的鲁棒性和实时性。|
|🆕 发布|Class-Conditional Distribution Balancing for Group Robust Classification|基于类条件分布平衡的分组鲁棒分类|Miaoyun Zhao, Qiang Zhang, Chenrong Li|<http://arxiv.org/pdf/2504.17314v1>|提出一种通过平衡类条件分布解决虚假相关性的鲁棒分类方法。|
|🆕 发布|Towards Generalizable Deepfake Detection with Spatial-Frequency Collaborative Learning and Hierarchical Cross-Modal Fusion|面向可泛化深度伪造检测的空域-频域协同学习和层次跨模态融合|Mengyu Qiao, Runze Tian, Yang Wang|<http://arxiv.org/pdf/2504.17223v1>|提出了一种结合空间频率分析和跨模态融合的通用深度伪造检测框架，显著提升了检测准确性和泛化能力。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DiffKillR: Killing and Recreating Diffeomorphisms for Cell Annotation in Dense Microscopy Images|DiffKillR：在密集显微镜图像中进行细胞注释的微分形态学消杀与重建|Chen Liu, Danqi Liao, Alejandro Parada-Mayorga, Alejandro Ribeiro, Marcello DiStasio, Smita Krishnaswamy|<http://arxiv.org/pdf/2410.03058v2>|[代码](https://github.com/KrishnaswamyLab/DiffKillR.); DiffKillR通过结合原型匹配和图像配准，实现密集显微镜图像中细胞的高效标注。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|The Fourth Monocular Depth Estimation Challenge|第四届全国单目深度估计挑战赛|Anton Obukhov, Matteo Poggi, Fabio Tosi, Ripudaman Singh Arora, Jaime Spencer, Chris Russell, Simon Hadfield, Richard Bowden .etc.|<http://arxiv.org/pdf/2504.17787v1>|通过改进评估协议和引入新方法，该论文在零样本泛化方面显著提升了单目深度估计性能。|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EgoCHARM: Resource-Efficient Hierarchical Activity Recognition using an Egocentric IMU Sensor|自我CHARM：使用以自我为中心的IMU传感器进行资源高效分层活动识别|Akhil Padmanabha, Saravanan Govindarajan, Hwanmun Kim, Sergio Ortiz, Rahul Rajan, Doruk Senkal, Sneha Kadetotad|<http://arxiv.org/pdf/2504.17735v1>|提出EgoCHARM算法，高效识别智能眼镜中的多层次活动，降低资源消耗。|
|📝 更新|Variational Self-Supervised Learning|变分自监督学习|Mehmet Can Yavuz, Berrin Yanikoglu|<http://arxiv.org/pdf/2504.04318v2>|提出VSSL框架，结合变分推理与自监督学习，实现高效无解码器表示学习。|
|🆕 发布|A Spatially-Aware Multiple Instance Learning Framework for Digital Pathology|空间感知的多实例学习框架在数字病理学中的应用|Hassan Keshvarikhojasteh, Mihail Tifrea, Sibylle Hess, Josien P. W. Pluim, Mitko Veta|<http://arxiv.org/pdf/2504.17379v1>|提出了一种空间感知的多实例学习框架，显著提升了病理图像分类性能。|
|🆕 发布|StereoMamba: Real-time and Robust Intraoperative Stereo Disparity Estimation via Long-range Spatial Dependencies|立体Mamba：通过长距离空间依赖性实现实时且鲁棒的术中立体视差估计|Xu Wang, Jialang Xu, Shuai Zhang, Baoru Huang, Danail Stoyanov, Evangelos B. Mazomenos|<http://arxiv.org/pdf/2504.17401v1>|提出StereoMamba，通过增强长距离空间依赖性，实现实时且鲁棒的手术内窥镜立体视差估计。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Guide to Structureless Visual Localization|视觉无结构定位指南|Vojtech Panek, Qunjie Zhou, Yaqing Ding, Sérgio Agostinho, Zuzana Kukelova, Torsten Sattler, Laura Leal-Taixé|<http://arxiv.org/pdf/2504.17636v1>|首次全面讨论并比较了无结构视觉定位方法，提出的方法在灵活性上优于传统方法，但精度略低。|
|📝 更新|Latent Representations for Visual Proprioception in Inexpensive Robots|潜在表示用于低成本机器人的视觉自感知|Sahara Sheikholeslami, Ladislau Bölöni|<http://arxiv.org/pdf/2504.14634v2>|该论文提出了一种利用快速回归架构从单张图像实现低成本机器人视觉自感知的方法。|
|📝 更新|Disentangling Visual Transformers: Patch-level Interpretability for Image Classification|视觉Transformer的解耦：图像分类的块级可解释性|Guillaume Jeanneret, Loïc Simon, Frédéric Jurie|<http://arxiv.org/pdf/2502.17196v2>|提出HiT架构，通过重新设计Transformer，实现图像分类中图像块影响的解耦，提高可解释性。|
|🆕 发布|Visual and textual prompts for enhancing emotion recognition in video|视觉和文本提示增强视频中的情感识别|Zhifeng Wang, Qixuan Zhang, Peter Zhang, Wenjia Niu, Kaihao Zhang, Ramesh Sankaranarayana, Sabrina Caldwell, Tom Gedeon|<http://arxiv.org/pdf/2504.17224v1>|提出SoVTP框架，通过整合视觉和文本提示，显著提升VLLMs在视频情感识别中的准确性。|
|📝 更新|How Well Can Vison-Language Models Understand Humans' Intention? An Open-ended Theory of Mind Question Evaluation Benchmark|视觉-语言模型理解人类意图的程度如何？开放式心智理论问题评估基准|Ximing Wen, Mallika Mainali, Anik Sen|<http://arxiv.org/pdf/2503.22093v2>|[代码](https://github.com/ximingwen/ToM-AAAI25-Multimodal.); 构建开放性问题框架评估视觉语言模型在理解人类意图方面的能力。|
|📝 更新|V$^2$R-Bench: Holistically Evaluating LVLM Robustness to Fundamental Visual Variations|V$^2$R-Bench：全面评估LVLM对基本视觉变化的鲁棒性|Zhiyuan Fan, Yumeng Wang, Sandeep Polisetty, Yi R. Fung|<http://arxiv.org/pdf/2504.16727v2>|构建V$^2$R-Bench评估框架，揭示大型视觉语言模型对视觉变化的脆弱性。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TimeChat-Online: 80% Visual Tokens are Naturally Redundant in Streaming Videos|时间聊天-在线：流媒体视频中80%的视觉标记自然冗余|Linli Yao, Yicheng Li, Yuancheng Wei, Lei Li, Shuhuai Ren, Yuanxin Liu, Kun Ouyang, Lean Wang .etc.|<http://arxiv.org/pdf/2504.17343v1>|TimeChat-Online通过创新差分标记丢弃模块，有效减少视频冗余，实现实时视频理解。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ImageFlowNet: Forecasting Multiscale Image-Level Trajectories of Disease Progression with Irregularly-Sampled Longitudinal Medical Images|图像流网络：利用不规则采样的纵向医学图像预测疾病进程的多尺度图像级轨迹|Chen Liu, Ke Xu, Liangbo L. Shen, Guillaume Huguet, Zilong Wang, Alexander Tong, Danilo Bzdok, Jay Stewart .etc.|<http://arxiv.org/pdf/2406.14794v6>|[代码](https://github.com/KrishnaswamyLab/ImageFlowNet.); ImageFlowNet通过学习多尺度图像表示和优化流场，有效预测疾病进展轨迹。|
|🆕 发布|Beyond Labels: Zero-Shot Diabetic Foot Ulcer Wound Segmentation with Self-attention Diffusion Models and the Potential for Text-Guided Customization|超越标签：基于自注意力扩散模型的零样本糖尿病足溃疡伤口分割及文本引导的定制潜力|Abderrachid Hamrani, Daniela Leizaola, Renato Sousa, Jose P. Ponce, Stanley Mathis, David G. Armstrong, Anuradha Godavarty|<http://arxiv.org/pdf/2504.17628v1>|提出了一种无需标注数据的文本引导扩散模型，实现了糖尿病足溃疡伤口的精准分割。|
|🆕 发布|STCL:Curriculum learning Strategies for deep learning image steganography models|STCL：深度学习图像隐写模型的学习课程策略|Fengchun Liu, Tong Zhang, Chunying Zhang|<http://arxiv.org/pdf/2504.17609v1>|[代码](https://github.com/chaos-boops/STCL); 提出STCL策略，通过难度评估和训练调度，提升深度学习图像隐写模型性能。|
|📝 更新|Putting the Segment Anything Model to the Test with 3D Knee MRI - A Comparison with State-of-the-Art Performance|将Segment Anything模型在3D膝关节MRI中的应用进行测试——与最先进性能的比较|Oliver Mills, Philip Conaghan, Nishant Ravikumar, Samuel Relton|<http://arxiv.org/pdf/2504.13340v3>|该研究将Segment Anything Model应用于3D膝关节MRI的半月板分割，发现其性能与...|
|🆕 发布|Mamba-Sea: A Mamba-based Framework with Global-to-Local Sequence Augmentation for Generalizable Medical Image Segmentation|曼巴-海：一种基于曼巴的框架，具有全局到局部序列增强，用于可泛化医学图像分割|Zihan Cheng, Jintao Guo, Jian Zhang, Lei Qi, Luping Zhou, Yinghuan Shi, Yang Gao|<http://arxiv.org/pdf/2504.17515v1>|[代码](https://github.com/orange-czh/Mamba-Sea.); 提出Mamba-Sea框架，通过全局到局部序列增强提升医疗图像分割在分布偏移下的泛化能力。|
|📝 更新|Causal Disentanglement for Robust Long-tail Medical Image Generation|因果解耦以实现鲁棒的长尾医学图像生成|Weizhi Nie, Zichun Zhang, Weijie Wang, Bruno Lepri, Anan Liu, Nicu Sebe|<http://arxiv.org/pdf/2504.14450v2>|提出一种基于因果解耦和文本引导的医学图像生成框架，有效解决数据稀缺和类别不平衡问题。|
|📝 更新|Shifts in Doctors' Eye Movements Between Real and AI-Generated Medical Images|医生在真实与AI生成医学图像间的眼动变化|David C Wong, Bin Wang, Gorkem Durak, Marouane Tliba, Mohamed Amine Kerkouri, Aladine Chetouani, Ahmet Enis Cetin, Cagdas Topel .etc.|<http://arxiv.org/pdf/2504.15007v2>|分析了医生在真实与AI生成医学图像间的眼动差异，揭示了诊断策略的视觉模式。|
|🆕 发布|Advanced Segmentation of Diabetic Retinopathy Lesions Using DeepLabv3+|基于DeepLabv3+的糖尿病视网膜病变病变高级分割|Meher Boulaabi, Takwa Ben Aïcha Gader, Afef Kacem Echi, Sameh Mbarek|<http://arxiv.org/pdf/2504.17306v1>|采用DeepLabv3+模型，结合特定预处理和数据增强，实现了对糖尿病视网膜病变的高精度分割。|
|📝 更新|Meta-Entity Driven Triplet Mining for Aligning Medical Vision-Language Models|基于元实体驱动的三元组挖掘以对齐医学视觉-语言模型|Saban Ozturk, Melih B. Yilmaz, Muti Kara, M. Talat Yavuz, Aykut Koç, Tolga Çukur|<http://arxiv.org/pdf/2504.15929v2>|提出MedTrim方法，通过元实体驱动的三元组挖掘，提升医学视觉-语言模型中图像与文本的匹配精度。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unsupervised Urban Land Use Mapping with Street View Contrastive Clustering and a Geographical Prior|无监督城市土地利用映射：基于街景对比聚类和地理先验|Lin Che, Yizi Chen, Tanhua Jin, Martin Raubal, Konrad Schindler, Peter Kiefer|<http://arxiv.org/pdf/2504.17551v1>|[代码](https://github.com/lin102/CCGP.); 提出了一种结合地理先验的无监督街景图像聚类方法，实现城市土地利用的灵活映射。|
|🆕 发布|S2S-Net: Addressing the Domain Gap of Heterogeneous Sensor Systems in LiDAR-Based Collective Perception|S2S-Net：解决基于激光雷达的集体感知中异构传感器系统领域差距问题|Sven Teufel, Jörg Gamerdinger, Oliver Bringmann|<http://arxiv.org/pdf/2504.17399v1>|S2S-Net解决异构传感器系统域差距问题，实现跨传感器域的高性能集体感知。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Highly Accurate and Diverse Traffic Data: The DeepScenario Open 3D Dataset|高度精确且多样化的交通数据：DeepScenario开放3D数据集|Oussema Dhaouadi, Johannes Meier, Luca Wahl, Jacques Kaiser, Luca Scalerandi, Nick Wandelburg, Zhuolun Zhou, Nijanthan Berinpanathan .etc.|<http://arxiv.org/pdf/2504.17371v1>|构建了DeepScenario Open 3D Dataset，通过单目相机无人机跟踪，提供高质量、...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhancing CNNs robustness to occlusions with bioinspired filters for border completion|基于生物启发滤波器增强CNN对遮挡的鲁棒性以实现边缘补全|Catarina P. Coutinho, Aneeqa Merhab, Janko Petkovic, Ferdinando Zanchetta, Rita Fioresi|<http://arxiv.org/pdf/2504.17619v1>|利用视觉皮层机制定义CNN定制滤波器，提升CNN对遮挡图像的识别准确率。|
|📝 更新|Review of Demographic Fairness in Face Recognition|人脸识别中的人口统计学公平性综述|Ketan Kotwal, Sebastien Marcel|<http://arxiv.org/pdf/2502.02309v2>|系统综述了人脸识别中的群体公平性问题，并提出了解决方法以提升公平性和可靠性。|

