## [UPDATED!] **2025-04-26** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PatternPaint: Practical Layout Pattern Generation Using Diffusion-Based Inpainting|基于扩散修复的实用布局图案生成：PatternPaint|Guanglei Zhou, Bhargav Korrapati, Gaurav Rajavendra Reddy, Chen-Chia Chang, Jingyu Pan, Jiang Hu, Yiran Chen, Dipto G. Thakurta|<http://arxiv.org/pdf/2409.01348v4>|PatternPaint通过扩散式修复技术，在少量设计规则样本下实现高效VLSI布局图案生成。|
|🆕 发布|Video CLIP Model for Multi-View Echocardiography Interpretation|多视图超声心动图解读的视频CLIP模型|Ryo Takizawa, Satoshi Kodera, Tempei Kabayama, Ryo Matsuoka, Yuta Ando, Yuto Nakamura, Haruki Settai, Norihiko Takeda|<http://arxiv.org/pdf/2504.18800v1>|开发了一种多视角视频CLIP模型，显著提升了超声心动图诊断的准确性。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|An Explainable Biomedical Foundation Model via Large-Scale Concept-Enhanced Vision-Language Pre-training|可解释的生物医学基础模型：基于大规模概念增强视觉-语言预训练|Yuxiang Nie, Sunan He, Yequan Bie, Yihui Wang, Zhixuan Chen, Shu Yang, Zhiyuan Cai, Hongmei Wang .etc.|<http://arxiv.org/pdf/2501.15579v2>|开发了一种可解释的生物医学基础模型ConceptCLIP，通过大规模概念增强视觉语言预训练实现高诊断...|
|🆕 发布|Multi-Resolution Pathology-Language Pre-training Model with Text-Guided Visual Representation|多分辨率病理语言预训练模型：基于文本引导的视觉表示|Shahad Albastaki, Anabia Sohail, Iyyakutti Iyappan Ganapathi, Basit Alawode, Asim Khan, Sajid Javed, Naoufel Werghi, Mohammed Bennamoun .etc.|<http://arxiv.org/pdf/2504.18856v1>|[代码](https://github.com/BasitAlawode/MR-PLIP); 提出了一种多分辨率病理语言预训练模型，通过文本引导的视觉表示提升病理图像分析能力。|
|📝 更新|Towards Interpreting Visual Information Processing in Vision-Language Models|迈向解释视觉语言模型中的视觉信息处理|Clement Neo, Luke Ong, Philip Torr, Mor Geva, David Krueger, Fazl Barez|<http://arxiv.org/pdf/2410.07149v2>|揭示了视觉语言模型中视觉信息处理机制，提升了对多模态系统的理解和可控性。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|IoT Botnet Detection: Application of Vision Transformer to Classification of Network Flow Traffic|物联网僵尸网络检测：视觉Transformer在网络安全流量分类中的应用|Hassan Wasswa, Timothy Lynar, Aziida Nanyonga, Hussein Abbass|<http://arxiv.org/pdf/2504.18781v1>|提出了一种基于视觉Transformer的IoT网络流量分类方法，有效检测物联网僵尸网络攻击。|
|🆕 发布|PyViT-FUSE: A Foundation Model for Multi-Sensor Earth Observation Data|PyViT-FUSE：多传感器地球观测数据的基础模型|Manuel Weber, Carly Beneke|<http://arxiv.org/pdf/2504.18770v1>|提出PyViT-FUSE模型，通过注意力机制融合多传感器遥感数据，实现多模态图像融合。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FetaFix: Automatic Fault Localization and Repair of Deep Learning Model Conversions|FetaFix：深度学习模型转换的自动故障定位与修复|Nikolaos Louloudakis, Perry Gibson, José Cano, Ajitha Rajan|<http://arxiv.org/pdf/2312.15101v4>|FetaFix自动定位和修复深度学习模型转换中的故障，提升模型兼容性和准确性。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spike Imaging Velocimetry: Dense Motion Estimation of Fluids Using Spike Cameras|脉冲成像流速计：使用脉冲相机进行流体密集运动估计|Yunzhong Zhang, Bo Xiong, You Zhou, Changqing Su, Zhen Cheng, Zhaofei Yu, Xun Cao, Tiejun Huang|<http://arxiv.org/pdf/2504.18864v1>|提出了一种利用深度学习进行密集运动估计的新方法，显著提升了流体运动测量精度。|
|📝 更新|Brain Tumor Identification using Improved YOLOv8|基于改进YOLOv8的脑肿瘤识别|Rupesh Dulal, Rabin Dulal|<http://arxiv.org/pdf/2502.03746v2>|提出改进YOLOv8模型，结合RT-DETR和Ghost Convolution，有效识别MRI图像...|
|🆕 发布|Multi-Stage Boundary-Aware Transformer Network for Action Segmentation in Untrimmed Surgical Videos|多阶段边界感知Transformer网络在未剪辑手术视频中的动作分割|Rezowan Shuvo, M S Mekala, Eyad Elyan|<http://arxiv.org/pdf/2504.18756v1>|提出了一种多阶段边界感知Transformer网络，有效提升了未剪辑手术视频中动作分割的精确度。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Semantic-Syntactic Discrepancy in Images (SSDI): Learning Meaning and Order of Features from Natural Images|图像中的语义-句法差异（SSDI）：从自然图像中学习特征的意义和顺序|Chun Tao, Timur Ibrayev, Kaushik Roy|<http://arxiv.org/pdf/2401.17515v2>|[代码](https://github.com/ChunTao1999/SSDI); 提出“图像语法”概念，通过学习图像语义和句法，有效检测图像中的语义-句法差异。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DEVICE: Depth and Visual Concepts Aware Transformer for OCR-based Image Captioning|设备：基于OCR图像字幕的深度和视觉概念感知的Transformer|Dongsheng Xu, Qingbao Huang, Xingmao Zhang, Haonan Cheng, Feng Shuang, Yi Cai|<http://arxiv.org/pdf/2302.01540v4>|提出DEVICE，通过融合深度信息和视觉概念语义，提升OCR图像描述的准确性和全面性。|
|🆕 发布|REED-VAE: RE-Encode Decode Training for Iterative Image Editing with Diffusion Models|REED-VAE：基于扩散模型的迭代图像编辑的重新编码解码训练|Gal Almog, Ariel Shamir, Ohad Fried|<http://arxiv.org/pdf/2504.18989v1>|[代码](https://github.com/galmog/REED-VAE); 提出REED-VAE方案，解决迭代图像编辑中累积噪声问题，实现多方法迭代编辑。|
|🆕 发布|R-Sparse R-CNN: SAR Ship Detection Based on Background-Aware Sparse Learnable Proposals|R-Sparse R-CNN：基于背景感知稀疏可学习提议的SAR舰船检测|Kamirul Kamirul, Odysseas Pappas, Alin Achim|<http://arxiv.org/pdf/2504.18959v1>|[代码](https://github.com/ka-mirul/R-Sparse-R-CNN.); R-Sparse R-CNN通过背景感知稀疏可学习候选框和双上下文池化，显著提升了SAR图像中船只检...|
|📝 更新|FLAME: Frozen Large Language Models Enable Data-Efficient Language-Image Pre-training|FLAME：冻结的大型语言模型实现数据高效的语言-图像预训练|Anjia Cao, Xing Wei, Zhiheng Ma|<http://arxiv.org/pdf/2411.11927v3>|[代码](https://github.com/MIV-XJTU/FLAME.); FLAME通过冻结大型语言模型作为文本编码器，有效提升语言-图像预训练的数据效率和泛化能力。|
|📝 更新|U-Shape Mamba: State Space Model for faster diffusion|U-Shape Mamba：用于更快扩散的状态空间模型|Alex Ergasti, Filippo Botti, Tomaso Fontanini, Claudio Ferrari, Massimo Bertozzi, Andrea Prati|<http://arxiv.org/pdf/2504.13499v2>|U-Shape Mamba通过U-Net结构降低扩散模型计算成本，同时提升图像生成质量。|
|📝 更新|Progressive Compositionality in Text-to-Image Generative Models|文本到图像生成模型中的渐进式组合性|Evans Xu Han, Linghao Jin, Xiaofeng Liu, Paul Pu Liang|<http://arxiv.org/pdf/2410.16719v2>|利用LLMs和VQA系统构建对比数据集，提出EvoGen多阶段课程，提升扩散模型在复杂场景下的文本到...|
|📝 更新|Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models|渐进式提示细化以提高文本到图像生成模型的对齐|Ketan Suhaas Saichandran, Xavier Thomas, Prakhar Kaushik, Deepti Ghadiyaram|<http://arxiv.org/pdf/2503.17794v3>|提出了一种渐进式细化提示细节的方法，显著提升文本到图像生成模型的图像对齐精度。|
|🆕 发布|CAMeL: Cross-modality Adaptive Meta-Learning for Text-based Person Retrieval|跨模态自适应元学习用于基于文本的人脸检索：CAMeL|Hang Yu, Jiahao Wen, Zhedong Zheng|<http://arxiv.org/pdf/2504.18782v1>|[代码](https://github.com/Jahawn-Wen/CAMeL-reID.); 提出了一种基于跨模态自适应元学习的预训练框架，有效提升了文本检索模型的泛化能力。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Koala-36M: A Large-scale Video Dataset Improving Consistency between Fine-grained Conditions and Video Content|考拉-36M：一个大规模视频数据集，用于提高细粒度条件与视频内容之间的一致性|Qiuheng Wang, Yukai Shi, Jiarong Ou, Rui Chen, Ke Lin, Jiahao Wang, Boyuan Jiang, Haotian Yang .etc.|<http://arxiv.org/pdf/2410.08260v2>|[代码](https://koala36m.github.io/.); 构建了高质量视频数据集Koala-36M，提升细粒度条件与视频内容一致性。|
|📝 更新|FineVQ: Fine-Grained User Generated Content Video Quality Assessment|精细VQ：细粒度用户生成内容视频质量评估|Huiyu Duan, Qiang Hu, Jiarui Wang, Liu Yang, Zitong Xu, Lu Liu, Xiongkuo Min, Chunlei Cai .etc.|<http://arxiv.org/pdf/2412.19238v2>|建立了首个大规模UGC视频质量评估数据库FineVD，并提出FineVQ模型实现细粒度视频质量评估。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Wonderland: Navigating 3D Scenes from a Single Image|奇境：从单张图像导航3D场景|Hanwen Liang, Junli Cao, Vidit Goel, Guocheng Qian, Sergei Korolev, Demetri Terzopoulos, Konstantinos N. Plataniotis, Sergey Tulyakov .etc.|<http://arxiv.org/pdf/2412.12091v2>|提出了一种基于视频扩散模型潜空间的高效3D场景重建方法，显著提升了单图生成3D场景的质量和效率。|
|🆕 发布|Dexonomy: Synthesizing All Dexterous Grasp Types in a Grasp Taxonomy|德克索尼米：在抓取分类中综合所有灵巧抓取类型|Jiayi Chen, Yubin Ke, Lin Peng, He Wang|<http://arxiv.org/pdf/2504.18829v1>|[代码](https://pku-epic.github.io/Dexonomy.); 提出了一种高效合成各类抓取方法的方法，显著提升了智能机器人抓取技能的通用性。|
|🆕 发布|Audio-Driven Talking Face Video Generation with Joint Uncertainty Learning|音频驱动的联合不确定性学习说话人脸视频生成|Yifan Xie, Fei Ma, Yi Bin, Ying He, Fei Yu|<http://arxiv.org/pdf/2504.18810v1>|提出联合不确定性学习网络，解决语音驱动人脸视频生成中视觉不确定性问题，提升视频质量和同步效果。|
|📝 更新|FreeGraftor: Training-Free Cross-Image Feature Grafting for Subject-Driven Text-to-Image Generation|FreeGraftor：无需训练的跨图像特征移植，用于主题驱动的文本到图像生成|Zebin Yao, Lei Ren, Huixing Jiang, Chen Wei, Xiaojie Wang, Ruifan Li, Fangxiang Feng|<http://arxiv.org/pdf/2504.15958v2>|[代码](https://github.com/Nihukat/FreeGraftor.); FreeGraftor通过跨图像特征嫁接，实现了无需训练的跨图像特征嫁接，有效解决了文本到图像生成中...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Kinship Verification through a Forest Neural Network|通过森林神经网络进行亲属验证|Ali Nazari, Mohsen Ebrahimi Moghaddam, Omidreza Borzoei|<http://arxiv.org/pdf/2504.18910v1>|[代码](https://github.com/ali-nazari/Kinship-Verification); 提出了一种融合图神经网络和中心损失的森林神经网络，有效提升了血缘关系验证的准确性。|
|🆕 发布|Exploiting Multiple Representations: 3D Face Biometrics Fusion with Application to Surveillance|利用多重表示：应用于监控的3D人脸生物识别融合|Simone Maurizio La Cava, Roberto Casula, Sara Concas, Giulia Orrù, Ruben Tolosana, Martin Drahansky, Julian Fierrez, Gian Luca Marcialis|<http://arxiv.org/pdf/2504.18886v1>|提出融合多种3D人脸重建算法，提升人脸识别系统在复杂场景下的鲁棒性和可靠性。|
|📝 更新|SIR: Multi-view Inverse Rendering with Decomposable Shadow Under Indoor Intense Lighting|多视角逆渲染：室内强光下的可分解阴影|Xiaokang Wei, Zhuoman Liu, Ping Li, Yan Luximon|<http://arxiv.org/pdf/2402.06136v4>|[代码](https://xiaokangwei.github.io/SIR); SIR通过多视角数据分解阴影，实现室内场景逆渲染，提升材质和光照条件分解的准确性。|
|🆕 发布|TransparentGS: Fast Inverse Rendering of Transparent Objects with Gaussians|透明GS：基于高斯函数的透明物体快速逆渲染|Letian Huang, Dongwei Ye, Jialin Dan, Chengzhi Tao, Huiwen Liu, Kun Zhou, Bo Ren, Yuanqi Li .etc.|<http://arxiv.org/pdf/2504.18768v1>|提出TransparentGS，通过改进3D-GS和GaussProbe，快速准确地渲染透明物体。|


## 时序视觉分析 (Temporal Visual Analysis)


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|3DPyranet Features Fusion for Spatio-temporal Feature Learning|三维Pyranet特征融合用于时空特征学习|Ihsan Ullah, Alfredo Petrosino|<http://arxiv.org/pdf/2504.18977v1>|提出3DPyraNet融合时空特征，有效提升视频动作和场景识别准确率。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Local-Global Temporal Difference Learning for Satellite Video Super-Resolution|局部-全局时序差异学习在卫星视频超分辨率中的应用|Yi Xiao, Qiangqiang Yuan, Kui Jiang, Xianyu Jin, Jiang He, Liangpei Zhang, Chia-Wen Lin|<http://arxiv.org/pdf/2304.04421v3>|[代码](https://github.com/XY-boy/LGTD); 提出了一种结合局部和全局时间差异学习的卫星视频超分辨率方法，有效提升了分辨率和图像质量。|
|🆕 发布|PiercingEye: Dual-Space Video Violence Detection with Hyperbolic Vision-Language Guidance|PiercingEye：基于双空间和双曲视觉语言引导的视频暴力检测|Jiaxu Leng, Zhanjie Wu, Mingpi Tan, Mengjingcheng Mo, Jiankang Zheng, Qingqing Li, Ji Gan, Xinbo Gao|<http://arxiv.org/pdf/2504.18866v1>|提出了一种结合欧几里得和双曲几何的视觉暴力检测框架，有效提升了细粒度暴力事件检测性能。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ComFace: Facial Representation Learning with Synthetic Data for Comparing Faces|ComFace：使用合成数据比较人脸的面部表征学习|Yusuke Akamatsu, Terumi Umematsu, Hitoshi Imaoka, Shizuko Gomi, Hideo Tsurushima|<http://arxiv.org/pdf/2405.16016v3>|ComFace通过合成数据学习面部表征，有效捕捉个体面部变化，提升人脸比较任务性能。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Neuro-LIFT: A Neuromorphic, LLM-based Interactive Framework for Autonomous Drone FlighT at the Edge|神经-LIFT：一种基于神经形态和大型语言模型的自适应边缘无人机飞行交互框架|Amogh Joshi, Sourav Sanyal, Kaushik Roy|<http://arxiv.org/pdf/2501.19259v2>|Neuro-LIFT通过结合LLM和神经形态视觉，实现了实时、低功耗的无人机自主飞行。|
|📝 更新|WMNav: Integrating Vision-Language Models into World Models for Object Goal Navigation|WMNav：将视觉-语言模型集成到世界模型中以实现物体目标导航|Dujun Nie, Xianda Guo, Yiqun Duan, Ruijun Zhang, Long Chen|<http://arxiv.org/pdf/2503.02247v4>|[代码](https://b0b8k1ng.github.io/WMNav); WMNav通过整合视觉语言模型构建世界模型，实现高效目标导航。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FEDORA: Flying Event Dataset fOr Reactive behAvior|FEDORA：用于反应性行为的飞行事件数据集|Amogh Joshi, Adarsh Kosta, Wachirawit Ponghiran, Manish Nagaraj, Kaushik Roy|<http://arxiv.org/pdf/2305.14392v3>|构建了FEDORA数据集，提供多源数据加速感知任务训练，解决现有数据集限制。|
|🆕 发布|WLTCL: Wide Field-of-View 3-D LiDAR Truck Compartment Automatic Localization System|WLTCL：宽视场3D激光雷达货车舱自动定位系统|Guodong Sun, Mingjing Li, Dingjie Liu, Mingxuan Liu, Bo Wu, Yang Zhang|<http://arxiv.org/pdf/2504.18870v1>|提出了一种适用于不同尺寸货车车厢的宽视场3D激光雷达自动定位系统，提高了定位精度和效率。|
|🆕 发布|Reservoir-enhanced Segment Anything Model for Subsurface Diagnosis|水库增强的任意分割模型用于地下诊断|Xiren Zhou, Shikang Liu, Xinyu Yan, Yizhan Fan, Xiangyu Wang, Yu Kang, Jian Cheng, Huanhuan Chen|<http://arxiv.org/pdf/2504.18802v1>|提出了一种结合水库模型和视觉分析的创新方法，显著提升了地下异常检测的准确性和效率。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Building Rome with Convex Optimization|用凸优化构建罗马|Haoyu Han, Heng Yang|<http://arxiv.org/pdf/2502.04640v3>|提出了一种基于深度预测和凸优化的全局光束调整方法，显著提升了SfM重建质量和效率。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Sim-to-Real: An Unsupervised Noise Layer for Screen-Camera Watermarking Robustness|模拟到现实：用于屏幕相机水印鲁棒性的无监督噪声层|Yufeng Wu, Xin Liao, Baowei Wang, Han Fang, Xiaoshuai Wu, Guiling Wang|<http://arxiv.org/pdf/2504.18906v1>|提出了一种无监督噪声层，有效提升了屏幕捕获图像水印的鲁棒性。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Real-time High-fidelity Gaussian Human Avatars with Position-based Interpolation of Spatially Distributed MLPs|实时高保真高斯人类头像：基于空间分布MLP的位置插值|Youyi Zhan, Tianjia Shao, Yin Yang, Kun Zhou|<http://arxiv.org/pdf/2504.12909v2>|提出了一种基于空间分布MLP的实时高保真高斯人像生成方法，有效平衡了细节和渲染速度。|
|📝 更新|DivShift: Exploring Domain-Specific Distribution Shift in Large-Scale, Volunteer-Collected Biodiversity Datasets|DivShift：探索大规模、志愿者收集的生物多样性数据集中的领域特定分布偏移|Elena Sierra, Lauren E. Gillespie, Salim Soltani, Moises Exposito-Alonso, Teja Kattenborn|<http://arxiv.org/pdf/2410.19816v4>|提出DivShift框架，量化特定领域分布偏移对机器学习模型性能的影响，并诊断志愿者收集的生物多样性...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MENTOR: Human Perception-Guided Pretraining for Increased Generalization|导师：基于人类感知的预训练以增强泛化能力|Colton R. Crum, Adam Czajka|<http://arxiv.org/pdf/2310.19545v3>|提出了一种结合人类感知的预训练方法MENTOR，有效提升了CNN在开放集识别任务中的泛化能力。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Deep Learning-Based Multi-Modal Fusion for Robust Robot Perception and Navigation|基于深度学习的多模态融合用于鲁棒的机器人感知与导航|Delun Lai, Yeyubei Zhang, Yunchong Liu, Chaojie Li, Huadong Mo|<http://arxiv.org/pdf/2504.19002v1>|提出了一种融合RGB图像和LiDAR数据的轻量级多模态融合架构，显著提升了复杂环境中的机器人感知和导...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VISUALCENT: Visual Human Analysis using Dynamic Centroid Representation|视觉中心：基于动态质心表示的人体视觉分析|Niaz Ahmad, Youngmoon Lee, Guanghui Wang|<http://arxiv.org/pdf/2504.19032v1>|VISUALCENT通过动态质心表示，实现多人体姿态和实例分割，提升泛化性和实时性能。|
|📝 更新|Long-Tailed Continual Learning For Visual Food Recognition|长尾视觉食物识别的持续学习|Jiangpeng He, Xiaoyan Zhang, Luotao Lin, Jack Ma, Heather A. Eicher-Miller, Fengqing Zhu|<http://arxiv.org/pdf/2307.00183v2>|提出了一种针对长尾分布食物识别的持续学习方法，显著提升了实例稀疏食物类别的泛化能力。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MRI super-resolution reconstruction using efficient diffusion probabilistic model with residual shifting|基于高效扩散概率模型和残差移位的MRI超分辨率重建|Mojtaba Safari, Shansong Wang, Zach Eidex, Qiang Li, Erik H. Middlebrooks, David S. Yu, Xiaofeng Yang|<http://arxiv.org/pdf/2503.01576v2>|[代码](https://github.com/mosaf/Res-SRDiff); 提出了一种结合残差误差移位的扩散概率模型，显著提升了MRI超分辨率重建的速度和质量。|
|🆕 发布|MediAug: Exploring Visual Augmentation in Medical Imaging|医图增强：探索医学影像中的视觉增强|Xuyin Qi, Zeyu Zhang, Canxuan Gang, Hao Zhang, Lei Zhang, Zhiwei Zhang, Yang Zhao|<http://arxiv.org/pdf/2504.18983v1>|[代码](https://github.com/AIGeeksGroup/MediAug.); 提出MediAug框架，通过混合增强策略提升医学图像分类和分割性能。|
|📝 更新|Accessible, At-Home Detection of Parkinson's Disease via Multi-task Video Analysis|通过多任务视频分析在家进行帕金森病的可及性检测|Md Saiful Islam, Tariq Adnan, Jan Freyberg, Sangwu Lee, Abdelrahman Abdelkader, Meghan Pawlik, Cathe Schwartz, Karen Jaffe .etc.|<http://arxiv.org/pdf/2406.14856v5>|开发了一种多任务视频分析网络，通过融合多模态数据显著提高了帕金森病的在家检测准确性。|
|📝 更新|Investigating the Feasibility of Patch-based Inference for Generalized Diffusion Priors in Inverse Problems for Medical Images|研究基于补丁的推理在医学图像逆问题中推广扩散先验的可行性|Saikat Roy, Mahmoud Mostapha, Radu Miron, Matt Holbrook, Mariappan Nadar|<http://arxiv.org/pdf/2501.15309v2>|探索了使用图像块训练和推理扩散先验在医学图像逆问题中的可行性。|
|📝 更新|Devil is in Details: Locality-Aware 3D Abdominal CT Volume Generation for Self-Supervised Organ Segmentation|魔鬼藏在细节中：用于自监督器官分割的局部感知3D腹部CT体积生成|Yuran Wang, Zhijing Wan, Yansheng Qiu, Zheng Wang|<http://arxiv.org/pdf/2409.20332v2>|提出了一种针对腹部CT体积生成的局部感知扩散模型，有效提升了自监督器官分割的性能。|
|📝 更新|DRIFT open dataset: A drone-derived intelligence for traffic analysis in urban environment|DRIFT开放数据集：城市环境中基于无人机智能的交通分析|Hyejin Lee, Seokjun Hong, Jeonghoon Song, Haechan Cho, Zhixiong Jin, Byeonghun Kim, Joobin Jin, Jaegyun Im .etc.|<http://arxiv.org/pdf/2504.11019v2>|[代码](https://github.com/AIxMobility/The-DRIFT.); 构建了DRIFT开放数据集，通过无人机视频分析城市交通，助力交通管理和研究。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Hierarchical Attention Diffusion Networks with Object Priors for Video Change Detection|基于对象先验的分层注意力扩散网络在视频变化检测中的应用|Andrew Kiruluta, Eric Lundy, Andreas Lemos|<http://arxiv.org/pdf/2408.10619v2>|提出一种结合多尺度注意力和语义分类的视频变化检测新方法，显著提升检测精度。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OccluTrack: Rethinking Awareness of Occlusion for Enhancing Multiple Pedestrian Tracking|OccluTrack：重新思考遮挡感知以增强多行人跟踪|Jianjun Gao, Yi Wang, Kim-Hui Yap, Kratika Garg, Boon Siew Han|<http://arxiv.org/pdf/2309.10360v2>|OccluTrack通过引入异常运动抑制和姿态引导重识别模块，有效提升了遮挡情况下多行人跟踪的准确性...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Surgeons vs. Computer Vision: A comparative analysis on surgical phase recognition capabilities|外科医生与计算机视觉：手术阶段识别能力比较分析|Marco Mezzina, Pieter De Backer, Tom Vercauteren, Matthew Blaschko, Alexandre Mottrie, Tinne Tuytelaars|<http://arxiv.org/pdf/2504.18954v1>|该研究通过比较专家手术师和计算机视觉在手术阶段识别能力上的差异，提出结合时间上下文信息可提升自动化手...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Depth as Points: Center Point-based Depth Estimation|深度即点：基于中心点的深度估计|Zhiheng Tu, Xinjian Huang, Yong He, Ruiyang Zhou, Bo Du, Weitao Wu|<http://arxiv.org/pdf/2504.18773v1>|提出了一种高效生成虚拟数据集和轻量级深度估计架构，显著提升了自动驾驶场景中深度估计的计算速度和准确性...|

