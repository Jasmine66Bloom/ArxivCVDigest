## [UPDATED!] **2025-04-27** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Token-Shuffle: Towards High-Resolution Image Generation with Autoregressive Models|Token-Shuffle：迈向具有自回归模型的超分辨率图像生成|Xu Ma, Peize Sun, Haoyu Ma, Hao Tang, Chih-Yao Ma, Jialiang Wang, Kunpeng Li, Xiaoliang Dai .etc.|<http://arxiv.org/pdf/2504.17789v2>|Token-Shuffle通过减少Transformer中的图像token数量，实现了高效的高分辨率...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EHGCN: Hierarchical Euclidean-Hyperbolic Fusion via Motion-Aware GCN for Hybrid Event Stream Perception|EHGCN：通过运动感知GCN实现层次欧几里得-双曲融合的混合事件流感知|Haosheng Chen, Lian Luo, Mengjingcheng Mo, Zhanjie Wu, Guobao Xiao, Ji Gan, Jiaxu Leng, Xinbo Gao|<http://arxiv.org/pdf/2504.16616v2>|提出EHGCN，通过融合欧几里得和双曲空间感知事件流，有效捕捉长距离依赖和层次结构。|
|📝 更新|PixelWeb: The First Web GUI Dataset with Pixel-Wise Labels|像素Web：首个具有像素级标签的Web GUI数据集|Qi Yang, Weichen Bi, Haiyang Shen, Yaoqi Guo, Yun Ma|<http://arxiv.org/pdf/2504.16419v2>|PixelWeb通过精确标注和视觉特征提取，解决了GUI数据集标注不准确的问题，显著提升了下游任务性...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Instance-Adaptive Keypoint Learning with Local-to-Global Geometric Aggregation for Category-Level Object Pose Estimation|基于局部到全局几何聚合的实例自适应关键点学习，用于类别级物体姿态估计|Xiao Zhang, Lu Zou, Tao Lu, Yuan Yao, Zhangjin Huang, Guoping Wang|<http://arxiv.org/pdf/2504.15134v2>|提出INKL-Pose框架，通过局部到全局几何聚合实现实例自适应关键点学习，提升物体姿态估计性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VistaDepth: Frequency Modulation With Bias Reweighting For Enhanced Long-Range Depth Estimation|视界深度：基于偏置重加权频率调制以增强长距离深度估计|Mingxia Zhan, Li Zhang, Xiaomeng Chu, Beibei Wang|<http://arxiv.org/pdf/2504.15095v3>|VistaDepth通过自适应频率域特征增强和权重平衡机制，显著提升了长距离深度估计的准确性。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Vision-Enabled Prosthetic Hand for Children with Upper Limb Disabilities|儿童上肢残疾者的视觉辅助假肢|Md Abdul Baset Sarker, Art Nguyen, Sigmond Kukla, Kevin Fite, Masudul H. Imtiaz|<http://arxiv.org/pdf/2504.15654v2>|开发了一种低成本、可定制的AI视觉辅助儿童假肢，解决现有肌电假肢的局限性。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Seeing from Another Perspective: Evaluating Multi-View Understanding in MLLMs|从另一个视角看：评估多视角理解在多语言大模型中的表现|Chun-Hsiao Yeh, Chenyu Wang, Shengbang Tong, Ta-Ying Cheng, Ruoyu Wang, Tianzhe Chu, Yuexiang Zhai, Yubei Chen .etc.|<http://arxiv.org/pdf/2504.15280v2>|[代码](https://danielchyeh.github.io/All-Angles-Bench); 提出All-Angles Bench基准，评估MLLMs在多视角理解上的挑战，揭示其与人类水平的差距...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection|异常CLIP：面向零样本异常检测的对象无关提示学习|Qihang Zhou, Guansong Pang, Yu Tian, Shibo He, Jiming Chen|<http://arxiv.org/pdf/2310.18961v10>|[代码](https://github.com/zqhang/AnomalyCLIP.); AnomalyCLIP通过学习无物体感知的文本提示，实现了不同领域零样本异常检测的准确识别。|

