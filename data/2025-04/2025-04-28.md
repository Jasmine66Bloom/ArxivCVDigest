## [UPDATED!] **2025-04-28** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LIRM: Large Inverse Rendering Model for Progressive Reconstruction of Shape, Materials and View-dependent Radiance Fields|LIRM：用于形状、材料和视依赖辐射场渐进重建的大规模逆渲染模型|Zhengqin Li, Dilin Wang, Ka Chen, Zhaoyang Lv, Thu Nguyen-Phuoc, Milim Lee, Jia-Bin Huang, Lei Xiao .etc.|<http://arxiv.org/pdf/2504.20026v1>|LIRM通过引入更新模型和新型神经网络机制，实现了快速且精确的3D重建。|
|🆕 发布|Enhancing Surgical Documentation through Multimodal Visual-Temporal Transformers and Generative AI|通过多模态视觉-时序转换器和生成式人工智能增强手术记录|Hugo Georgenthum, Cristian Cosentino, Fabrizio Marozzo, Pietro Liò|<http://arxiv.org/pdf/2504.19918v1>|提出了一种结合视觉-时序Transformer和生成AI的多模态框架，自动生成手术视频的全面总结，提...|
|📝 更新|A prototype-based model for set classification|基于原型的集合分类模型|Mohammad Mohammadi, Sreejita Ghosh|<http://arxiv.org/pdf/2408.13720v2>|提出了一种基于原型和子空间学习的集合分类方法，提高了分类效率和可解释性。|
|🆕 发布|GMAR: Gradient-Driven Multi-Head Attention Rollout for Vision Transformer Interpretability|GMAR：基于梯度的多头注意力滚动策略，用于视觉Transformer的可解释性|Sehyeong Jo, Gangjae Jang, Haesol Park|<http://arxiv.org/pdf/2504.19414v1>|提出GMAR方法，通过梯度评分量化ViT中每个注意力头的重要性，提升模型可解释性。|
|🆕 发布|UNet with Axial Transformer : A Neural Weather Model for Precipitation Nowcasting|基于轴向变换器的UNet：一种用于降水预报的神经天气模型|Maitreya Sonawane, Sumit Mamtani|<http://arxiv.org/pdf/2504.19408v1>|开发了一种基于Axial Transformer的UNet模型，实现了对降水的高精度短时天气预报。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SpatialReasoner: Towards Explicit and Generalizable 3D Spatial Reasoning|空间推理器：迈向显式和可泛化的3D空间推理|Wufei Ma, Yu-Cheng Chou, Qihao Liu, Xingrui Wang, Celso de Melo, Jieneng Chen, Jianwen Xie, Alan Yuille|<http://arxiv.org/pdf/2504.20024v1>|提出SpatialReasoner，通过显式3D表示实现更通用的3D空间推理。|
|🆕 发布|Learning Streaming Video Representation via Multitask Training|通过多任务训练学习流媒体视频表示|Yibin Yan, Jilan Xu, Shangzhe Di, Yikun Liu, Yudi Shi, Qirui Chen, Zeqian Li, Yifei Huang .etc.|<http://arxiv.org/pdf/2504.20041v1>|提出StreamFormer，通过多任务训练实现高效流媒体视频处理，同时提升实时应用能力。|
|🆕 发布|DEEMO: De-identity Multimodal Emotion Recognition and Reasoning|DEEMO：去身份多模态情感识别与推理|Deng Li, Bohao Xing, Xin Liu, Baiqiang Xia, Bihan Wen, Heikki Kälviäinen|<http://arxiv.org/pdf/2504.19549v1>|DEEMO提出去身份多模态情感识别与推理，保护隐私的同时提升情感理解准确率。|
|📝 更新|Learning Modality-Aware Representations: Adaptive Group-wise Interaction Network for Multimodal MRI Synthesis|学习模态感知表示：自适应组内交互网络用于多模态MRI合成|Tao Song, Yicheng Wu, Minhao Hu, Xiangde Luo, Linda Wei, Guotai Wang, Yi Guo, Feng Xu .etc.|<http://arxiv.org/pdf/2411.14684v2>|[代码](https://github.com/zunzhumu/Adaptive-Group-wise-Interaction-Network-for-Multimodal-MRI-Synthesis.git.); 提出AGI-Net，通过模态感知交互设计，有效提升了多模态MRI图像合成性能。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CoherenDream: Boosting Holistic Text Coherence in 3D Generation via Multimodal Large Language Models Feedback|CoherenDream：通过多模态大型语言模型反馈提升3D生成中的整体文本连贯性|Chenhan Jiang, Yihan Zeng, Hang Xu, Dit-Yan Yeung|<http://arxiv.org/pdf/2504.19860v1>|提出TCSD方法，通过MLLM反馈提升3D生成中文本的整体一致性。|
|🆕 发布|Foundation Model-Driven Framework for Human-Object Interaction Prediction with Segmentation Mask Integration|基于基础模型的人-物交互预测框架，集成分割掩码|Juhan Park, Kyungjae Lee, Hyung Jin Chang, Jungchan Cho|<http://arxiv.org/pdf/2504.19847v1>|提出Seg2HOI框架，通过整合分割基础模型预测人-物交互，显著提升交互预测性能。|
|🆕 发布|NORA: A Small Open-Sourced Generalist Vision Language Action Model for Embodied Tasks|NORA：一个用于具身任务的微型开源通用视觉语言动作模型|Chia-Yu Hung, Qi Sun, Pengfei Hong, Amir Zadeh, Chuan Li, U-Xuan Tan, Navonil Majumder, Soujanya Poria|<http://arxiv.org/pdf/2504.19854v1>|提出NORA模型，通过优化视觉编码和轻量化设计，显著降低计算开销，提升机器人任务执行效率。|
|🆕 发布|Pixels2Points: Fusing 2D and 3D Features for Facial Skin Segmentation|像素到点：融合二维和三维特征进行面部皮肤分割|Victoria Yue Chen, Daoye Wang, Stephan Garbin, Sebastian Winberg, Timo Bolkart, Thabo Beeler|<http://arxiv.org/pdf/2504.19718v1>|融合2D和3D特征，实现3D人脸扫描皮肤区域精确分割。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|More Clear, More Flexible, More Precise: A Comprehensive Oriented Object Detection benchmark for UAV|更清晰、更灵活、更精确：面向无人机的一个综合定向目标检测基准|Kai Ye, Haidi Tang, Bowen Liu, Pingyang Dai, Liujuan Cao, Rongrong Ji|<http://arxiv.org/pdf/2504.20032v1>|定位无人机目标检测数据集CODrone，提升实际应用中的泛化能力和鲁棒性。|
|📝 更新|OverLoCK: An Overview-first-Look-Closely-next ConvNet with Context-Mixing Dynamic Kernels|OverLoCK：一种以概述-先看-再仔细看的卷积神经网络及其上下文混合动态核|Meng Lou, Yizhou Yu|<http://arxiv.org/pdf/2502.20087v3>|[代码](https://github.com/LMMMEng/OverLoCK.); 设计了一种模拟人类视觉系统的OverLoCK网络，通过上下文混合动态卷积实现高效的特征提取和注意力引...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Shopformer: Transformer-Based Framework for Detecting Shoplifting via Human Pose|Shopformer：基于Transformer的人体姿态检测商店盗窃框架|Narges Rashvand, Ghazal Alinezhad Noghre, Armin Danesh Pazho, Babak Rahimi Ardabili, Hamed Tabkhi|<http://arxiv.org/pdf/2504.19970v1>|[代码](https://github.com/TeCSAR-UNCC/Shopformer.); Shopformer通过分析姿态序列而非原始视频，实现了隐私保护且可扩展的商店盗窃检测。|
|🆕 发布|Enhancing breast cancer detection on screening mammogram using self-supervised learning and a hybrid deep model of Swin Transformer and Convolutional Neural Network|利用自监督学习和Swin Transformer与卷积神经网络混合深度模型增强筛查乳腺摄影中的乳腺癌检测|Han Chen, Anne L. Martel|<http://arxiv.org/pdf/2504.19888v1>|提出了一种结合自监督学习和混合深度模型的方法，有效提升了乳腺钼靶图像的癌症检测性能。|
|🆕 发布|Open-set Anomaly Segmentation in Complex Scenarios|复杂场景下的开放集异常分割|Song Xia, Yi Yu, Henghui Ding, Wenhan Yang, Shifei Liu, Alex C. Kot, Xudong Jiang|<http://arxiv.org/pdf/2504.19706v1>|提出ComsAmy基准和DiffEEL方法，提升复杂场景下异常分割模型的鲁棒性和泛化能力。|
|🆕 发布|DG-DETR: Toward Domain Generalized Detection Transformer|DG-DETR：迈向领域泛化检测Transformer|Seongmin Hwang, Daeyoung Han, Moongu Jeon|<http://arxiv.org/pdf/2504.19574v1>|[代码](https://github.com/sminhwang/DG-DETR.); 提出DG-DETR，通过消除领域偏差和特征分解，增强DETR的跨领域检测鲁棒性。|
|🆕 发布|Neural network task specialization via domain constraining|通过领域约束进行神经网络任务专业化|Roman Malashin, Daniil Ilyukhin|<http://arxiv.org/pdf/2504.19592v1>|通过特定任务域约束实现神经网络专业化，提升网络在特定数据子空间上的性能。|
|🆕 发布|Category-Level and Open-Set Object Pose Estimation for Robotics|机器人领域的类别级和开放集物体姿态估计|Peter Hönig, Matthias Hirschmanner, Markus Vincze|<http://arxiv.org/pdf/2504.19572v1>|提出了一种解决机器人场景中物体姿态估计问题的方法，通过比较数据集、准确度指标和算法，实现类别级和开放...|
|📝 更新|Explicit Motion Handling and Interactive Prompting for Video Camouflaged Object Detection|显式运动处理与交互式提示的视频隐身目标检测|Xin Zhang, Tao Xiao, Gepeng Ji, Xuan Wu, Keren Fu, Qijun Zhao|<http://arxiv.org/pdf/2403.01968v2>|[代码](https://github.com/zhangxin06/EMIP.); 提出EMIP框架，通过显式处理运动和交互式提示，显著提升视频伪装目标检测性能。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Multi-Scale Grouped Prototypes for Interpretable Semantic Segmentation|多尺度分组原型用于可解释语义分割|Hugo Porta, Emanuele Dalsasso, Diego Marcos, Devis Tuia|<http://arxiv.org/pdf/2409.09497v2>|[代码](https://github.com/eceo-epfl/ScaleProtoSeg.); 提出多尺度分组原型方法，提升语义分割模型可解释性和性能。|
|🆕 发布|BARIS: Boundary-Aware Refinement with Environmental Degradation Priors for Robust Underwater Instance Segmentation|边界感知与环境退化先验的鲁棒水下实例分割方法：BARIS|Pin-Chi Pan, Soo-Chang Pei|<http://arxiv.org/pdf/2504.19643v1>|提出BARIS-ERA框架，结合边界感知解码和环境鲁棒适配器，显著提升水下实例分割准确度。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Conditional Electrocardiogram Generation Using Hierarchical Variational Autoencoders|条件心电图生成：基于分层变分自编码器|Ivan Sviridov, Konstantin Egorov|<http://arxiv.org/pdf/2503.13469v2>|提出了一种基于层次变分自编码器的条件心电图生成模型，有效提升了心血管疾病诊断的准确性和效率。|
|🆕 发布|AnimateAnywhere: Rouse the Background in Human Image Animation|AnimateAnywhere：唤醒人像动画中的背景|Xiaoyu Liu, Mingshuai Yao, Yabo Zhang, Xianhui Lin, Peiran Ren, Xiaoming Li, Ming Liu, Wangmeng Zuo|<http://arxiv.org/pdf/2504.19834v1>|[代码](https://github.com/liuxiaoyu1104/AnimateAnywhere.); AnimateAnywhere通过学习人体姿态序列来生成逼真的背景动画，无需依赖相机轨迹。|
|📝 更新|OmniEdit: Building Image Editing Generalist Models Through Specialist Supervision|全编辑：通过专家监督构建图像编辑通用模型|Cong Wei, Zheyang Xiong, Weiming Ren, Xinrun Du, Ge Zhang, Wenhu Chen|<http://arxiv.org/pdf/2411.07199v2>|[代码](https://tiger-ai-lab.github.io/OmniEdit); OmniEdit通过专家监督和高质量数据集，构建了可处理多种图像编辑任务的通用模型。|
|🆕 发布|Learning Brenier Potentials with Convex Generative Adversarial Neural Networks|利用凸生成对抗神经网络学习Brenier势函数|Claudia Drygala, Hanno Gottschalk, Thomas Kruse, Ségolène Martin, Annika Mütze|<http://arxiv.org/pdf/2504.19779v1>|开发了一种基于凸生成对抗神经网络的Brenier势学习理论，确保了网络学习到的势函数严格凸。|
|🆕 发布|RepText: Rendering Visual Text via Replicating|RepText：通过复制渲染视觉文本|Haofan Wang, Yujia Xu, Yimeng Li, Junchen Li, Chaowei Zhang, Jing Wang, Kejia Yang, Zhibo Chen|<http://arxiv.org/pdf/2504.19724v1>|RepText通过复刻技术，使预训练的文本到图像模型能准确渲染多语言视觉文本。|
|📝 更新|Step1X-Edit: A Practical Framework for General Image Editing|Step1X-Edit：一种通用于图像编辑的实用框架|Shiyu Liu, Yucheng Han, Peng Xing, Fukun Yin, Rui Wang, Wei Cheng, Jiaqi Liao, Yingming Wang .etc.|<http://arxiv.org/pdf/2504.17761v2>|提出Step1X-Edit模型，通过多模态LLM和扩散图像解码器实现高效图像编辑，缩小开源算法与闭源...|
|🆕 发布|Point2Quad: Generating Quad Meshes from Point Clouds via Face Prediction|点云到四边形单元网格：通过面预测生成四边形单元网格|Zezeng Li, Zhihui Qi, Weimin Wang, Ziliang Wang, Junyi Duan, Na Lei|<http://arxiv.org/pdf/2504.19545v1>|提出了一种从点云生成仅四边形网格的新方法，有效解决了网格生成中的共面性和凸性挑战。|
|🆕 发布|CasaGPT: Cuboid Arrangement and Scene Assembly for Interior Design|CasaGPT：室内设计中的立方体排列与场景组装|Weitao Feng, Hang Zhou, Jing Liao, Li Cheng, Wenbo Zhou|<http://arxiv.org/pdf/2504.19478v1>|CasaGPT通过立方体排列和场景组装，实现了室内场景的高效合成与真实感提升。|
|📝 更新|Automated Black-box Prompt Engineering for Personalized Text-to-Image Generation|自动黑盒提示工程实现个性化文本到图像生成|Yutong He, Alexander Robey, Naoki Murata, Yiding Jiang, Joshua Nathaniel Williams, George J. Pappas, Hamed Hassani, Yuki Mitsufuji .etc.|<http://arxiv.org/pdf/2403.19103v3>|开发了一种自动生成可解释且可迁移的提示算法，以实现仅通过黑盒访问T2I模型来个性化文本到图像生成。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CineVerse: Consistent Keyframe Synthesis for Cinematic Scene Composition|电影宇宙：电影场景合成的一致关键帧生成|Quynh Phung, Long Mai, Fabian David Caba Heilbron, Feng Liu, Jia-Bin Huang, Cusuh Ham|<http://arxiv.org/pdf/2504.19894v1>|CineVerse通过结合语言模型和图像生成模型，实现了连贯且丰富的电影场景合成。|
|🆕 发布|Federated Out-of-Distribution Generalization: A Causal Augmentation View|联邦分布外泛化：因果增强视角|Runhui Zhang, Sijin Zhou, Zhuang Qi|<http://arxiv.org/pdf/2504.19882v1>|提出FedCAug方法，通过因果增强提升联邦学习在分布外样本上的泛化能力。|
|📝 更新|Memory Regulation and Alignment toward Generalizer RGB-Infrared Person|记忆调节与对齐以实现通用RGB-红外人体识别|Feng Chen, Fei Wu, Qi Wu, Zhiguo Wan|<http://arxiv.org/pdf/2109.08843v2>|[代码](https://github.com/Chenfeng1271/MGMRA.); 提出了一种多粒度记忆调节与对齐模块，有效缓解了RGB-Infrared person re-iden...|
|🆕 发布|Masked Language Prompting for Generative Data Augmentation in Few-shot Fashion Style Recognition|掩码语言提示在少样本时尚风格识别中的生成数据增强|Yuki Hirakawa, Ryotaro Shimizu|<http://arxiv.org/pdf/2504.19455v1>|提出Masked Language Prompting方法，有效增强时尚风格识别数据集，提升识别效果...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DeeCLIP: A Robust and Generalizable Transformer-Based Framework for Detecting AI-Generated Images|DeepCLIP：一种基于Transformer的鲁棒且可泛化的检测AI生成图像的框架|Mamadou Keita, Wassim Hamidouche, Hessen Bougueffa Eutamene, Abdelmalik Taleb-Ahmed, Abdenour Hadid|<http://arxiv.org/pdf/2504.19876v1>|[代码](https://github.com/Mamadou-Keita/DeeCLIP); DeeCLIP通过融合特征和参数高效微调，提升了检测AI生成图像的鲁棒性和泛化能力。|
|🆕 发布|VCM: Vision Concept Modeling Based on Implicit Contrastive Learning with Vision-Language Instruction Fine-Tuning|基于视觉-语言指令微调的隐式对比学习视觉概念建模|Run Luo, Renke Shan, Longze Chen, Ziqiang Liu, Lu Wang, Min Yang, Xiaobo Xia|<http://arxiv.org/pdf/2504.19627v1>|提出VCM，通过视觉-语言指令微调，构建高效视觉概念模型，提升图像理解任务性能。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Image Generation Method Based on Heat Diffusion Models|基于热扩散模型的图像生成方法|Pengfei Zhang, Shouqing Jia|<http://arxiv.org/pdf/2504.19600v1>|提出基于热扩散模型的图像生成方法，提升细节保留和生成图像的真实性。|
|🆕 发布|WILD: a new in-the-Wild Image Linkage Dataset for synthetic image attribution|WILD：一个用于合成图像归因的野外图像链接新数据集|Pietro Bongini, Sara Mandelli, Andrea Montibeller, Mirko Casu, Orazio Pontorno, Claudio Ragaglia, Luca Zanchetta, Mattia Aquilina .etc.|<http://arxiv.org/pdf/2504.19595v1>|构建了WILD数据集，为合成图像归属提供强大训练和基准测试工具。|
|📝 更新|Infusion: internal diffusion for inpainting of dynamic textures and complex motion|注入：用于动态纹理和复杂运动修复的内部扩散|Nicolas Cherel, Andrés Almansa, Yann Gousseau, Alasdair Newson|<http://arxiv.org/pdf/2311.01090v4>|提出了一种基于内部扩散的轻量级视频修复方法，有效降低计算负担并提升动态纹理和复杂运动背景的修复效果。|
|📝 更新|MASR: Self-Reflective Reasoning through Multimodal Hierarchical Attention Focusing for Agent-based Video Understanding|MASR：基于多模态分层注意力聚焦的智能体视频理解中的自我反思推理|Shiwen Cao, Zhaoxing Zhang, Junming Jiao, Juyi Qiao, Guowen Song, Rong Shen, Xiangbing Meng|<http://arxiv.org/pdf/2504.17213v2>|MASR通过多模态层次注意力聚焦和自反推理，有效提升了视频理解准确度。|
|📝 更新|Lifting Motion to the 3D World via 2D Diffusion|通过二维扩散将运动提升到三维世界|Jiaman Li, C. Karen Liu, Jiajun Wu|<http://arxiv.org/pdf/2411.18808v2>|MVLift通过2D扩散模型预测3D运动，无需3D监督，实现跨领域运动估计。|
|🆕 发布|SynergyAmodal: Deocclude Anything with Text Control|SynergyAmodal：文本控制下的任意去遮挡|Xinyang Li, Chengjie Yi, Jiawei Lai, Mingbao Lin, Yansong Qu, Shengchuan Zhang, Liujuan Cao|<http://arxiv.org/pdf/2504.19506v1>|[代码](https://github.com/imlixinyang/SynergyAmodal.); 提出SynergyAmodal框架，通过数据、人类专家和模型协同，实现图像去遮挡和文本控制。|
|📝 更新|NCL-CIR: Noise-aware Contrastive Learning for Composed Image Retrieval|NCL-CIR：针对合成图像检索的噪声感知对比学习|Peng Gao, Yujian Lee, Zailong Chen, Hui zhang, Xubo Liu, Yiyang Hu, Guquang Jing|<http://arxiv.org/pdf/2504.04339v2>|提出NCL-CIR方法，通过噪声感知对比学习解决图像检索中噪声对模型性能的影响。|
|📝 更新|Self-Consistent Nested Diffusion Bridge for Accelerated MRI Reconstruction|自洽嵌套扩散桥加速MRI重建|Tao Song, Yicheng Wu, Minhao Hu, Xiangde Luo, Guoting Luo, Guotai Wang, Yi Guo, Feng Xu .etc.|<http://arxiv.org/pdf/2412.09998v2>|提出了一种基于自洽嵌套扩散桥的加速MRI重建方法，显著提升了重建质量。|
|🆕 发布|Boosting 3D Liver Shape Datasets with Diffusion Models and Implicit Neural Representations|基于扩散模型和隐式神经网络表示增强3D肝脏形状数据集|Khoa Tuan Nguyen, Francesca Tozzi, Wouter Willaert, Joris Vankerschaver, Nikdokht Rashidian, Wesley De Neve|<http://arxiv.org/pdf/2504.19402v1>|利用扩散模型和隐式神经网络表示扩充3D肝脏形状数据集，提升医学3D重建准确性。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MP-SfM: Monocular Surface Priors for Robust Structure-from-Motion|单目表面先验的鲁棒运动结构恢复|Zador Pataki, Paul-Edouard Sarlin, Johannes L. Schönberger, Marc Pollefeys|<http://arxiv.org/pdf/2504.20040v1>|[代码](https://github.com/cvg/mpsfm.); 通过引入深度神经网络推断的单目深度和法线先验，MP-SfM显著提升了结构从运动在极端视角变化下的鲁棒...|
|📝 更新|RGS-DR: Reflective Gaussian Surfels with Deferred Rendering for Shiny Objects|RGS-DR：用于光滑物体的反射高斯球面体与延迟渲染|Georgios Kouros, Minye Wu, Tinne Tuytelaars|<http://arxiv.org/pdf/2504.18468v2>|RGS-DR通过二维高斯球面元和延迟渲染技术，实现了对光滑反射物体的高质量重建和重光照。|
|📝 更新|CrossView-GS: Cross-view Gaussian Splatting For Large-scale Scene Reconstruction|跨视图高斯分层：大规模场景重建的跨视图高斯分层|Chenhao Zhang, Yuanping Cao, Lei Zhang|<http://arxiv.org/pdf/2501.01695v2>|提出了一种针对大规模场景重建的跨视图高斯分层方法，有效解决大视角变化带来的优化挑战。|
|📝 更新|GS-ROR$^2$: Bidirectional-guided 3DGS and SDF for Reflective Object Relighting and Reconstruction|GS-ROR$^2$：双向引导的3DGS和SDF用于反射物体重光照和重建|Zuo-Liang Zhu, Beibei Wang, Jian Yang|<http://arxiv.org/pdf/2406.18544v3>|提出一种双向引导的3DGS和SDF方法，有效解决反射物体重光照和重建问题。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|From Brainwaves to Brain Scans: A Robust Neural Network for EEG-to-fMRI Synthesis|从脑电波到脑扫描：一种鲁棒的脑电图到功能性磁共振成像合成神经网络|Kristofer Grover Roos, Atsushi Fukuda, Quan Huu Cap|<http://arxiv.org/pdf/2502.08025v3>|[代码](https://github.com/kgr20/E2fNet.); 提出E2fNet，一种从低成本EEG数据合成fMRI图像的深度学习模型，有效解决脑成像成本与精度问题...|
|🆕 发布|Towards Ball Spin and Trajectory Analysis in Table Tennis Broadcast Videos via Physically Grounded Synthetic-to-Real Transfer|基于物理基础的合成到真实转换，用于乒乓球直播视频中的球旋转和轨迹分析|Daniel Kienzle, Robin Schön, Rainer Lienhart, Shin'Ichi Satoh|<http://arxiv.org/pdf/2504.19863v1>|提出了一种基于合成数据训练的球拍乒乓球视频分析新方法，准确预测球旋转和轨迹。|
|🆕 发布|Joint Optimization of Neural Radiance Fields and Continuous Camera Motion from a Monocular Video|基于单目视频的神经辐射场与连续相机运动的联合优化|Hoang Chuong Nguyen, Wei Mao, Jose M. Alvarez, Miaomiao Liu|<http://arxiv.org/pdf/2504.19819v1>|[代码](https://github.com/HoangChuongNguyen/cope-nerf.); 提出了一种从单目视频中学习连续相机运动和神经辐射场的方法，显著提升了相机姿态和深度估计的准确性。|
|🆕 发布|Prompt Guiding Multi-Scale Adaptive Sparse Representation-driven Network for Low-Dose CT MAR|低剂量CT图像重建中的提示引导多尺度自适应稀疏表示驱动网络|Baoshun Shi, Bing Chen, Shaolei Zhang, Huazhu Fu, Zhanli Hu|<http://arxiv.org/pdf/2504.19687v1>|提出PMSRNet，通过多尺度自适应稀疏表示和提示引导策略，有效解决低剂量CT重建与金属伪影去除问题...|
|📝 更新|3D Gaussian Inpainting with Depth-Guided Cross-View Consistency|三维高斯去噪与深度引导的跨视图一致性|Sheng-Yu Huang, Zi-Ting Chou, Yu-Chiang Frank Wang|<http://arxiv.org/pdf/2502.11801v2>|提出了一种基于深度引导的跨视图一致性框架，有效提升了3D补洞的纹理和几何一致性。|
|🆕 发布|ShowMak3r: Compositional TV Show Reconstruction|ShowMak3r：组合式电视节目重建|Sangmin Kim, Seunguk Do, Jaesik Park|<http://arxiv.org/pdf/2504.19584v1>|[代码](https://nstar1125.github.io/showmak3r); ShowMak3r通过创新的三维定位和表情恢复技术，实现了电视节目场景的动态重建和编辑。|
|🆕 发布|A Real-Time Event-Based Normal Flow Estimator|实时基于事件的全局光流估计器|Dehao Yuan, Cornelia Fermüller|<http://arxiv.org/pdf/2504.19417v1>|[代码](https://github.com/dhyuan99/VecKM_flow_cpp.); 提出了一种基于事件坐标池化的实时正常流估计器，大幅降低计算成本。|


## 时序视觉分析 (Temporal Visual Analysis)


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Using Fixed and Mobile Eye Tracking to Understand How Visitors View Art in a Museum: A Study at the Bowes Museum, County Durham, UK|利用固定和移动眼动追踪理解访客在博物馆欣赏艺术的方式：英国达勒姆郡鲍斯博物馆的研究|Claire Warwick, Andrew Beresford, Soazig Casteau, Hubert P. H. Shum, Dan Smith, Francis Xiatian Zhang|<http://arxiv.org/pdf/2504.19881v1>|利用固定和移动眼动追踪技术，研究博物馆游客如何观赏艺术品，以优化展览布局。|
|🆕 发布|FSBench: A Figure Skating Benchmark for Advancing Artistic Sports Understanding|FSBench：用于推进艺术体育理解的滑冰基准|Rong Gao, Xin Liu, Zhuozhao Hu, Bohao Xing, Baiqiang Xia, Zitong Yu, Heikki Kälviäinen|<http://arxiv.org/pdf/2504.19514v1>|构建了FSBench基准，以促进对花样滑冰艺术体育的理解和评估。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|STCOcc: Sparse Spatial-Temporal Cascade Renovation for 3D Occupancy and Scene Flow Prediction|STCOcc：用于3D占用和场景流预测的稀疏时空级联修复|Zhimin Liao, Ping Wei, Shuaijia Chen, Haoxuan Wang, Ziyang Ren|<http://arxiv.org/pdf/2504.19749v1>|[代码](https://github.com/lzzzzzm/STCOcc); 提出一种基于占用状态的三维场景重建方法，有效提升预测精度并降低计算成本。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A computer vision method to estimate ventilation rate of Atlantic salmon in sea fish farms|一种用于估算大西洋鲑鱼在海水鱼场通风率的计算机视觉方法|Lukas Folkman, Quynh LK Vo, Colin Johnston, Bela Stantic, Kylie A Pitt|<http://arxiv.org/pdf/2504.19719v1>|开发了一种基于计算机视觉的方法，通过监测大西洋鲑鱼呼吸频率来评估其健康状况。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Exploiting Inter-Sample Correlation and Intra-Sample Redundancy for Partially Relevant Video Retrieval|利用样本间相关性及样本内冗余进行部分相关视频检索|Junlong Ren, Gangjian Zhang, Yu Hu, Jian Shu, Hao Wang|<http://arxiv.org/pdf/2504.19637v1>|提出了一种利用样本间相关性和样本内冗余的PRVR框架，有效提升了视频检索的准确性。|
|🆕 发布|Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video|普瑞玛：用于视觉和视频机制可解释性的开源工具包|Sonia Joseph, Praneet Suresh, Lorenz Hufe, Edward Stevinson, Robert Graham, Yash Vadi, Danilo Bzdok, Sebastian Lapuschkin .etc.|<http://arxiv.org/pdf/2504.19475v1>|[代码](https://github.com/Prisma-Multimodal/ViT-Prisma); 开发开源工具包Prisma，加速视觉机制可解释性研究，降低该领域入门门槛。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Contrastive Language-Image Learning with Augmented Textual Prompts for 3D/4D FER Using Vision-Language Model|对比语言-图像学习：用于3D/4D面部表情识别的增强文本提示与视觉-语言模型|Muzammil Behzad, Guoying Zhao|<http://arxiv.org/pdf/2504.19739v1>|提出AffectVLM，通过联合表示学习和文本提示增强，实现3D/4D面部情感识别的语义丰富和视觉全...|
|🆕 发布|Masked Point-Entity Contrast for Open-Vocabulary 3D Scene Understanding|掩码点-实体对比用于开放词汇3D场景理解|Yan Wang, Baoxiong Jia, Ziyu Zhu, Siyuan Huang|<http://arxiv.org/pdf/2504.19500v1>|提出了一种结合实体语言对齐和点实体一致性的开放词汇3D场景理解方法，显著提升了语义分割和零样本场景理...|
|📝 更新|Shape-centered Representation Learning for Visible-Infrared Person Re-identification|形状中心的人可见光-红外重识别表示学习|Shuang Li, Jiaxu Leng, Ji Gan, Mengjingcheng Mo, Xinbo Gao|<http://arxiv.org/pdf/2310.17952v3>|提出Shape-centered Representation Learning框架，有效整合形状和...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards AI-Driven Policing: Interdisciplinary Knowledge Discovery from Police Body-Worn Camera Footage|迈向人工智能驱动的警务：从警察佩戴式摄像头录像中实现跨学科知识发现|Anita Srbinovska, Angela Srbinovska, Vivek Senthil, Adrian Martin, John McCluskey, Ernest Fokoué|<http://arxiv.org/pdf/2504.20007v1>|提出了一种利用AI和机器学习分析警察执法视频，以识别警察与民众互动行为模式的新框架。|
|📝 更新|Better artificial intelligence does not mean better models of biology|更高级的人工智能并不意味着更好的生物学模型|Drew Linsley, Pinyuan Feng, Thomas Serre|<http://arxiv.org/pdf/2504.16940v3>|论文揭示深度神经网络在视觉基准测试上的进步并未带来与生物视觉模型的一致性提升，主张视觉科学应基于生物...|
|🆕 发布|Innovative Integration of 4D Cardiovascular Reconstruction and Hologram: A New Visualization Tool for Coronary Artery Bypass Grafting Planning|创新融合4D心血管重建与全息技术：冠状动脉旁路移植术规划的新可视化工具|Shuo Wang, Tong Ren, Nan Cheng, Li Zhang, Rong Wang|<http://arxiv.org/pdf/2504.19401v1>|开发了一种基于4D心血管重建和全息技术的冠状动脉搭桥手术规划新工具，提高了术前规划的准确性和可视化效...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhancing Quality for VVC Compressed Videos with Omniscient Quality Enhancement Model|基于全知质量提升模型的VVC压缩视频质量增强|Xiem HoangVan, Hieu Bui Minh, Sang NguyenQuang, Wen-Hsiao Peng|<http://arxiv.org/pdf/2504.19935v1>|提出了一种针对VVC压缩视频的Omniscient质量增强模型，显著提升了视频质量和压缩效率。|
|📝 更新|GranQ: Granular Zero-Shot Quantization with Unified Layer-Channel Awareness|GranQ：具有统一层-通道意识的粒度零样本量化|Inpyo Hong, Youngwan Jo, Hyojeong Lee, Sunghyun Ahn, Sanghyun Park|<http://arxiv.org/pdf/2503.18339v3>|GranQ通过层通道感知实现细粒度量化，有效减少激活损失，提升零样本量化性能。|
|📝 更新|Free-DyGS: Camera-Pose-Free Scene Reconstruction for Dynamic Surgical Videos with Gaussian Splatting|自由-DyGS：基于高斯喷溅的无相机姿态动态手术视频场景重建|Qian Li, Shuojue Yang, Daiyun Shen, Jimmy Bok Yan So, Jing Qin, Yueming Jin|<http://arxiv.org/pdf/2409.01003v3>|提出了一种无需相机姿态信息的动态手术场景重建方法，通过高斯分层技术实现快速高效重建。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Efficient Self-Supervised Learning for Earth Observation via Dynamic Dataset Curation|高效通过动态数据集管理进行地球观测的自监督学习|Thomas Kerdreux, Alexandre Tuel, Quentin Febvre, Alexis Mouche, Bertrand Chapron|<http://arxiv.org/pdf/2504.06962v2>|[代码](https://github.com/galeio-research/OceanSAR-models); 提出动态数据集修剪策略，提升地球观测自监督学习效率和模型迁移能力。|
|🆕 发布|xEdgeFace: Efficient Cross-Spectral Face Recognition for Edge Devices|xEdgeFace：边缘设备高效跨光谱人脸识别|Anjith George, Sebastien Marcel|<http://arxiv.org/pdf/2504.19646v1>|提出了一种轻量级混合CNN-Transformer架构，有效解决边缘设备上的跨光谱人脸识别问题。|
|🆕 发布|Magnifier: A Multi-grained Neural Network-based Architecture for Burned Area Delineation|放大镜：一种基于多粒度神经网络的烧伤区域划分架构|Daniele Rege Cambrin, Luca Colomba, Paolo Garza|<http://arxiv.org/pdf/2504.19589v1>|提出Magnifier方法，通过双编码器融合不同粒度信息，有效提升有限数据下的烧伤区域分割性能。|
|📝 更新|Physics-Driven Neural Compensation For Electrical Impedance Tomography|基于物理的神经补偿电阻抗断层成像|Chuyu Wang, Huiting Deng, Dong Liu|<http://arxiv.org/pdf/2504.18067v2>|提出了一种结合物理原理的深度学习框架，有效解决了EIT成像中的逆问题和灵敏度分布问题。|
|🆕 发布|Dynamic Arthroscopic Navigation System for Anterior Cruciate Ligament Reconstruction Based on Multi-level Memory Architecture|基于多层次记忆架构的动态关节镜导航系统用于前交叉韧带重建|Shuo Wang, Weili Shi, Shuai Yang, Jiahao Cui, Qinwei Guo|<http://arxiv.org/pdf/2504.19398v1>|提出了一种基于多级记忆架构的动态关节镜导航系统，显著提升了ACL重建手术的精度和稳定性。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Fine-Tuning Vision-Language-Action Models: Optimizing Speed and Success|视觉-语言-动作模型的微调：优化速度和成功率|Moo Jin Kim, Chelsea Finn, Percy Liang|<http://arxiv.org/pdf/2502.19645v2>|[代码](https://openvla-oft.github.io/.); 提出了一种优化视觉-语言-动作模型微调的方法，显著提升了任务执行效率和成功率。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SAMBLE: Shape-Specific Point Cloud Sampling for an Optimal Trade-Off Between Local Detail and Global Uniformity|SAMBLE：针对局部细节与全局均匀性之间最佳权衡的形状特定点云采样|Chengzhi Wu, Yuxin Wan, Hao Fu, Julius Pfrommer, Zeyun Zhong, Junwei Zheng, Jiaming Zhang, Jürgen Beyerer|<http://arxiv.org/pdf/2504.19581v1>|提出SAMBLE方法，针对点云采样问题，学习形状特定采样策略，平衡局部细节与全局均匀性。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Adversarial Shallow Watermarking|对抗浅水印|Guobiao Li, Lei Tan, Yuliang Xue, Gaozhi Liu, Zhenxing Qian, Sheng Li, Xinpeng Zhang|<http://arxiv.org/pdf/2504.19529v1>|提出Adversarial Shallow Watermarking方法，有效抵抗未知扭曲，提升数字...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mesh-Learner: Texturing Mesh with Spherical Harmonics|网格学习器：使用球谐函数纹理化网格|Yunfei Wan, Jianheng Liu, Jiarong Lin, Fu Zhang|<http://arxiv.org/pdf/2504.19938v1>|[代码](https://github.com/hku-mars/Mesh-Learner.); Mesh-Learner通过整合球谐纹理和3D重建，实现了高效渲染，显著提升了性能。|
|📝 更新|Estimating the Number of HTTP/3 Responses in QUIC Using Deep Learning|使用深度学习估计QUIC中HTTP/3响应的数量|Barak Gahtan, Robert J. Shahla, Reuven Cohen, Alex M. Bronstein|<http://arxiv.org/pdf/2410.06140v3>|利用深度学习将QUIC连接轨迹转化为图像序列，预测HTTP/3响应数量，提升网络监控效率。|
|🆕 发布|Taming the Randomness: Towards Label-Preserving Cropping in Contrastive Learning|驯服随机性：对比学习中的标签保留裁剪方法|Mohamed Hassan, Mohammad Wasil, Sebastian Houben|<http://arxiv.org/pdf/2504.19824v1>|提出参数化裁剪方法，提升对比学习中的自标签鲁棒性，显著提高模型分类准确率。|
|📝 更新|DD-rPPGNet: De-interfering and Descriptive Feature Learning for Unsupervised rPPG Estimation|DD-rPPGNet：无监督rPPG估计的去干扰和描述性特征学习|Pei-Kai Huang, Tzu-Hsien Chen, Ya-Ting Chan, Kuan-Wen Chen, Chiou-Ting Hsu|<http://arxiv.org/pdf/2407.21402v3>|[代码](https://github.com/Pei-KaiHuang/TIFS2025-DD-rPPGNet); 提出DD-rPPGNet，通过去干扰和描述性特征学习，提升无监督rPPG信号估计性能。|
|🆕 发布|Mjölnir: A Deep Learning Parametrization Framework for Global Lightning Flash Density|Mjölnir：一种用于全球闪电密度全局参数化的深度学习框架|Minjong Cheon|<http://arxiv.org/pdf/2504.19822v1>|Mjölnir通过深度学习，准确预测全球闪电活动，为地球系统模型提供数据驱动参数化方案。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|An $\ell^1$-Plug-and-Play Approach for MPI Using a Zero Shot Denoiser with Evaluation on the 3D Open MPI Dataset|基于零样本去噪器的MPI $\ell^1$-Plug-and-Play方法及其在3D Open MPI数据集上的评估|Vladyslav Gapyak, Corinna Rentschler, Thomas März, Andreas Weinmann|<http://arxiv.org/pdf/2401.00275v3>|提出一种基于零样本去噪器的$\ell^1$-先验插件式方法，有效提升了MPI图像重建质量。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Point-Cache: Test-time Dynamic and Hierarchical Cache for Robust and Generalizable Point Cloud Analysis|点缓存：用于鲁棒和泛化点云分析的测试时动态和分层缓存|Hongyu Sun, Qiuhong Ke, Ming Cheng, Yongcai Wang, Deying Li, Chenhui Gou, Jianfei Cai|<http://arxiv.org/pdf/2503.12150v3>|[代码](https://github.com/auniquesun/Point-Cache.); 提出Point-Cache，一种动态分层缓存模型，使点云识别模型能适应测试时的分布变化并识别未见类别...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SubGrapher: Visual Fingerprinting of Chemical Structures|SubGrapher：化学结构的视觉指纹|Lucas Morin, Gerhard Ingmar Meijer, Valéry Weber, Luc Van Gool, Peter W. J. Staar|<http://arxiv.org/pdf/2504.19695v1>|SubGrapher通过学习实例分割，从化学结构图像中提取指纹，实现化学结构检索。|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Explaining Vision GNNs: A Semantic and Visual Analysis of Graph-based Image Classification|解释视觉图神经网络：基于图像分类的语义和视觉分析|Nikolaos Chaidos, Angeliki Dimitriou, Nikolaos Spanos, Athanasios Voulodimos, Giorgos Stamou|<http://arxiv.org/pdf/2504.19682v1>|分析了基于图神经网络的图像分类模型，揭示了其决策过程的可解释性及其与人类感知的差异。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mitigating Catastrophic Forgetting in the Incremental Learning of Medical Images|缓解医学图像增量学习中的灾难性遗忘|Sara Yavari, Jacob Furst|<http://arxiv.org/pdf/2504.20033v1>|提出了一种利用知识蒸馏的增量学习方法，有效缓解了医疗图像分析中的灾难性遗忘问题。|
|🆕 发布|Monitoring digestate application on agricultural crops using Sentinel-2 Satellite imagery|利用Sentinel-2卫星影像监测农业作物上的消化液应用|Andreas Kalogeras, Dimitrios Bormpoudakis, Iason Tsardanidis, Dimitra A. Loka, Charalampos Kontoes|<http://arxiv.org/pdf/2504.19996v1>|利用Sentinel-2卫星图像和机器学习模型，实现了对农业作物上消化物应用的监测和效果评估。|
|🆕 发布|SRMF: A Data Augmentation and Multimodal Fusion Approach for Long-Tail UHR Satellite Image Segmentation|SRMF：一种用于长尾超分辨率卫星图像分割的数据增强和多模态融合方法|Yulong Guo, Zilun Zhang, Yongheng Shang, Tiancheng Zhao, Shuiguang Deng, Yingchun Yang, Jianwei Yin|<http://arxiv.org/pdf/2504.19839v1>|[代码](https://github.com/BinSpa/SRMF.git.); SRMF通过数据增强和多模态融合，有效缓解了UHR卫星图像分割中的长尾问题，显著提升了分割性能。|
|🆕 发布|CoDEx: Combining Domain Expertise for Spatial Generalization in Satellite Image Analysis|CoDEx：结合领域专业知识进行卫星图像分析中的空间泛化|Abhishek Kuriyal, Elliot Vincent, Mathieu Aubry, Loic Landrieu|<http://arxiv.org/pdf/2504.19737v1>|[代码](https://github.com/Abhishek19009/CoDEx.); 提出了一种结合领域专家知识的卫星图像分析框架，有效解决地域差异导致的模型性能问题。|
|🆕 发布|Hybrid Approach Combining Ultrasound and Blood Test Analysis with a Voting Classifier for Accurate Liver Fibrosis and Cirrhosis Assessment|超声与血液检测分析结合投票分类器进行准确肝纤维化和肝硬化评估的混合方法|Kapil Kashyap, Sean Fargose, Chrisil Dabre, Fatema Dolaria, Nilesh Patil, Aniket Kore|<http://arxiv.org/pdf/2504.19755v1>|提出结合超声和血液检测的混合模型，显著提升肝纤维化和肝硬化诊断准确性。|
|📝 更新|Unsupervised Tomato Split Anomaly Detection using Hyperspectral Imaging and Variational Autoencoders|基于高光谱成像和变分自编码器的无监督番茄分割异常检测|Mahmoud Abdulsalam, Usman Zahidi, Bradley Hurst, Simon Pearson, Grzegorz Cielniak, James Brown|<http://arxiv.org/pdf/2501.02921v2>|利用定制VAE和光谱成像，实现了对番茄裂痕等异常的高精度无监督检测。|
|🆕 发布|Crowd Detection Using Very-Fine-Resolution Satellite Imagery|基于超精细分辨率卫星图像的群体检测|Tong Xiao, Qunming Wang, Ping Lu, Tenghai Huang, Xiaohua Tong, Peter M. Atkinson|<http://arxiv.org/pdf/2504.19546v1>|利用高分辨率卫星图像，提出CrowdSat-Net网络，显著提升大规模人群检测准确率。|
|🆕 发布|LR-IAD:Mask-Free Industrial Anomaly Detection with Logical Reasoning|LR-IAD：基于逻辑推理的无掩码工业异常检测|Peijian Zeng, Feiyan Pang, Zhanbo Wang, Aimin Yang|<http://arxiv.org/pdf/2504.19524v1>|[代码](https://github.com/LilaKen/LR-IAD.); 提出了一种无需掩码的工业异常检测方法，通过逻辑推理和动态优先级处理，显著提升了检测准确性和可解释性。|
|🆕 发布|CLIP-KOA: Enhancing Knee Osteoarthritis Diagnosis with Multi-Modal Learning and Symmetry-Aware Loss Functions|CLIP-KOA：基于多模态学习和对称性感知损失函数增强膝关节骨关节炎诊断|Yejin Jeong, Donghun Lee|<http://arxiv.org/pdf/2504.19443v1>|提出CLIP-KOA框架，结合多模态学习和对称性损失函数，提高膝骨关节炎诊断的准确性和一致性。|
|📝 更新|VerteNet -- A Multi-Context Hybrid CNN Transformer for Accurate Vertebral Landmark Localization in Lateral Spine DXA Images|脊椎网络——一种用于侧位脊椎DXA图像中精确脊椎标志定位的多上下文混合CNN变换器|Zaid Ilyas, Arooba Maqsood, Afsah Saleem, Erchuan Zhang, David Suter, Parminder Raina, Jonathan M. Hodgson, John T. Schousboe .etc.|<http://arxiv.org/pdf/2502.02097v2>|[代码](https://github.com/zaidilyas89/VerteNet.); VerteNet通过引入双分辨率注意力机制，实现了对侧位脊柱DXA图像中椎骨标志的精确定位。|
|🆕 发布|Dual Attention Driven Lumbar Magnetic Resonance Image Feature Enhancement and Automatic Diagnosis of Herniation|双注意力驱动的腰椎磁共振图像特征增强及突出自动诊断|Lingrui Zhang, Liang Guo, Xiao An, Feng Lin, Binlong Zheng, Jiankun Wang, Zhirui Li|<http://arxiv.org/pdf/2504.19438v1>|提出了一种基于双注意力驱动的腰椎磁共振图像特征增强与自动诊断突出症的新框架，显著提升了诊断准确率。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Hybrid Video Anomaly Detection for Anomalous Scenarios in Autonomous Driving|混合视频异常检测用于自动驾驶中的异常场景|Daniel Bogdoll, Jan Imhof, Tim Joseph, Svetlana Pavlitska, J. Marius Zöllner|<http://arxiv.org/pdf/2406.06423v3>|提出了一种针对自动驾驶中异常场景的混合视频异常检测方法，从车辆视角学习正常性表示并评估像素级异常检测...|
|🆕 发布|EcoWikiRS: Learning Ecological Representation of Satellite Images from Weak Supervision with Species Observations and Wikipedia|EcoWikiRS：利用物种观察和维基百科从弱监督中学习卫星图像的生态表示|Valerie Zermatten, Javiera Castillo-Navarro, Pallavi Jain, Devis Tuia, Diego Marcos|<http://arxiv.org/pdf/2504.19742v1>|[代码](https://github.com/eceo-epfl/EcoWikiRS.); 提出EcoWikiRS，通过物种观察和维基百科信息，从遥感图像中学习生态表征，实现生态零样本分类。|
|🆕 发布|The ATLAS of Traffic Lights: A Reliable Perception Framework for Autonomous Driving|交通信号灯图鉴：自动驾驶的可靠感知框架|Rupert Polley, Nikolai Polley, Dominik Heid, Marc Heinrich, Sven Ochs, J. Marius Zöllner|<http://arxiv.org/pdf/2504.19722v1>|提出ATLAS数据集和模块化感知框架，显著提升自动驾驶车辆对交通灯的识别准确性和鲁棒性。|
|🆕 发布|NSegment : Noisy Segment Improves Remote Sensing Image Segmentation|NSegment：噪声段提升遥感图像分割|Yechan Kim, DongHo Yoon, SooYeon Kim, Moongu Jeon|<http://arxiv.org/pdf/2504.19634v1>|NSegment通过弹性变换增强标签数据，有效缓解遥感图像分割中的噪声问题。|
|🆕 发布|Lightweight Adapter Learning for More Generalized Remote Sensing Change Detection|轻量级适配器学习以实现更通用的遥感变化检测|Dou Quan, Rufan Zhou, Shuang Wang, Ning Huyan, Dong Zhao, Yunan Li, Licheng Jiao|<http://arxiv.org/pdf/2504.19598v1>|提出CANet，通过共享和特定学习模块，实现轻量级适配学习，提升遥感图像变化检测的泛化能力。|
|📝 更新|Remote sensing colour image semantic segmentation of trails created by large herbivorous Mammals|大型草食哺乳动物形成的路径的遥感彩色图像语义分割|Jose Francisco Diez-Pastor, Francisco Javier Gonzalez-Moya, Pedro Latorre-Carmona, Francisco Javier Perez-Barbería, Ludmila I. Kuncheva, Antonio Canepa-Oneto, Alvar Arnaiz-González, Cesar Garcia-Osorio|<http://arxiv.org/pdf/2504.12121v2>|提出了一种基于机器学习的自动检测大型草食性哺乳动物放牧路径的语义分割方法。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Breast Cancer Detection from Multi-View Screening Mammograms with Visual Prompt Tuning|多视角筛查乳腺摄影中的视觉提示调整进行乳腺癌检测|Han Chen, Anne L. Martel|<http://arxiv.org/pdf/2504.19900v1>|提出了一种基于多视角视觉提示调优的网络，有效提升了乳腺癌检测的准确性和效率。|
|🆕 发布|DiVE: Efficient Multi-View Driving Scenes Generation Based on Video Diffusion Transformer|DiVE：基于视频扩散变换器的有效多视角驾驶场景生成|Junpeng Jiang, Gangyi Hong, Miao Zhang, Hengtong Hu, Kun Zhan, Rui Shao, Liqiang Nie|<http://arxiv.org/pdf/2504.19614v1>|DiVE通过视频扩散Transformer生成高质量、时空一致的多视角驾驶场景视频，有效解决现有生成...|
|🆕 发布|CE-NPBG: Connectivity Enhanced Neural Point-Based Graphics for Novel View Synthesis in Autonomous Driving Scenes|CE-NPBG：增强连接的基于神经的点云图形在自动驾驶场景中的新颖视图合成|Mohammad Altillawi, Fengyi Shen, Liudi Yang, Sai Manoj Prakhya, Ziyuan Liu|<http://arxiv.org/pdf/2504.19557v1>|提出CE-NPBG方法，通过连接增强和神经点渲染，显著提升自动驾驶场景中新型视图合成的渲染质量和效率...|
|🆕 发布|EarthMapper: Visual Autoregressive Models for Controllable Bidirectional Satellite-Map Translation|地球测绘器：可控双向卫星-地图翻译的可视自回归模型|Zhe Dong, Yuzhe Sun, Tianzhu Liu, Wangmeng Zuo, Yanfeng Gu|<http://arxiv.org/pdf/2504.19432v1>|EarthMapper通过地理坐标嵌入和多尺度特征对齐，实现了可控的卫星图像与地图双向翻译，显著提升...|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Interpretable Dynamic Graph Neural Networks for Small Occluded Object Detection and Tracking|可解释的动态图神经网络在小遮挡物体检测与跟踪中的应用|Shahriar Soudeep, Md Abrar Jahin, M. F. Mridha|<http://arxiv.org/pdf/2411.17251v7>|提出DGNN-YOLO框架，有效解决小遮挡物体检测与跟踪难题。|
|🆕 发布|ClearVision: Leveraging CycleGAN and SigLIP-2 for Robust All-Weather Classification in Traffic Camera Imagery|清晰视觉：利用CycleGAN和SigLIP-2在交通摄像头图像中进行鲁棒全天候分类|Anush Lakshman Sivaraman, Kojo Adu-Gyamfi, Ibne Farabi Shihab, Anuj Sharma|<http://arxiv.org/pdf/2504.19684v1>|结合CycleGAN和SigLIP-2，提出了一种提升交通摄像头图像天气分类准确性的方法。|
|📝 更新|LaneCorrect: Self-supervised Lane Detection|车道纠正：自监督车道检测|Ming Nie, Xinyue Cai, Hang Xu, Li Zhang|<http://arxiv.org/pdf/2404.14671v2>|提出LaneCorrect，一种无需标注的自监督车道检测方法，显著提升车道检测性能并缓解领域差距。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Measuring Train Driver Performance as Key to Approval of Driverless Trains|测量火车驾驶员表现作为批准自动驾驶火车关键因素|Rustam Tagiew, Prasannavenkatesh Balaji|<http://arxiv.org/pdf/2504.19735v1>|提出了一种基于公开数据集的无人驾驶火车驾驶员性能量化方法，以促进自动驾驶火车安全认证。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CompleteMe: Reference-based Human Image Completion|CompleteMe：基于参考的人像补全|Yu-Ju Tsai, Brian Price, Qing Liu, Luis Figueroa, Daniil Pakhomov, Zhihong Ding, Scott Cohen, Ming-Hsuan Yang|<http://arxiv.org/pdf/2504.20042v1>|[代码](https://liagm.github.io/CompleteMe); CompleteMe通过区域专注注意力机制，有效捕捉细节，显著提升基于参考图像的人像补全质量。|
|🆕 发布|HOIGaze: Gaze Estimation During Hand-Object Interactions in Extended Reality Exploiting Eye-Hand-Head Coordination|HOIGaze：在扩展现实中的手-物体交互期间利用眼-手-头协调进行视线估计|Zhiming Hu, Daniel Haeufle, Syn Schmitt, Andreas Bulling|<http://arxiv.org/pdf/2504.19828v1>|HOIGaze通过利用眼手头协调，提出了一种新型学习算法，显著提升了XR中手-物体交互的注视估计性能...|
|🆕 发布|Accelerated 3D-3D rigid registration of echocardiographic images obtained from apical window using particle filter|加速使用粒子滤波从心尖窗获取的超声心动图图像的3D-3D刚性配准|Thanuja Uruththirakodeeswaran, Harald Becher, Michelle Noga, Lawrence H. Le, Pierre Boulanger, Jonathan Windram, Kumaradevan Punithakumar|<http://arxiv.org/pdf/2504.19930v1>|提出了一种加速的粒子滤波算法，用于快速且精确地注册超声心动图图像，显著提升了图像质量和处理速度。|
|🆕 发布|Mapping of Weed Management Methods in Orchards using Sentinel-2 and PlanetScope Data|果园杂草管理方法映射：基于Sentinel-2和PlanetScope数据|Ioannis Kontogiorgakis, Iason Tsardanidis, Dimitrios Bormpoudakis, Ilias Tsoumas, Dimitra A. Loka, Christos Noulas, Alexandros Tsitouras, Charalampos Kontoes|<http://arxiv.org/pdf/2504.19991v1>|利用卫星图像和机器学习技术，实现了果园中四种杂草管理方法的精准映射。|

