## [UPDATED!] **2025-04-30** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Detecting and Mitigating Hateful Content in Multimodal Memes with Vision-Language Models|在多模态迷因中检测和缓解仇恨内容的视觉-语言模型|Minh-Hao Van, Xintao Wu|<http://arxiv.org/pdf/2505.00150v1>|利用视觉-语言模型检测和减轻仇恨内容，将仇恨表情包转化为符合人类标准的非仇恨内容。|
|🆕 发布|Investigating Zero-Shot Diagnostic Pathology in Vision-Language Models with Efficient Prompt Design|探究基于高效提示设计的视觉-语言模型在零样本病理诊断中的应用|Vasudev Sharma, Ahmed Alagha, Abdelhakim Khellaf, Vincent Quoc-Huy Trinh, Mahdi S. Hosseini|<http://arxiv.org/pdf/2505.00134v1>|通过系统研究，提出了一种针对计算机病理学中视觉语言模型的提示工程框架，显著提升了诊断准确性。|
|🆕 发布|3D Stylization via Large Reconstruction Model|基于大型重建模型的三维风格化|Ipek Oztas, Duygu Ceylan, Aysegul Dundar|<http://arxiv.org/pdf/2504.21836v1>|利用大型重建模型中的注意力机制，实现了无需训练的3D外观风格化，显著提升了效率和视觉效果。|
|🆕 发布|Why Compress What You Can Generate? When GPT-4o Generation Ushers in Image Compression Fields|为何压缩可生成之物？当GPT-4o生成引领图像压缩领域|Yixin Gao, Xiaohan Pan, Xin Li, Zhibo Chen|<http://arxiv.org/pdf/2504.21814v1>|利用GPT-4o生成功能，提出结构扫描提示工程机制，实现图像压缩，突破超低比特率性能限制。|
|🆕 发布|A simple and effective approach for body part recognition on CT scans based on projection estimation|基于投影估计的CT扫描人体部位识别的简单有效方法|Franko Hrzic, Mohammadreza Movahhedi, Ophelie Lavoie-Gagne, Ata Kiapour|<http://arxiv.org/pdf/2504.21810v1>|提出了一种基于二维投影估计的简单有效方法，显著提升了CT扫描中人体部位识别的准确率。|
|🆕 发布|Visual Text Processing: A Comprehensive Review and Unified Evaluation|视觉文本处理：全面综述与统一评估|Yan Shu, Weichao Zeng, Fangmin Zhao, Zeyu Chen, Zhenhang Li, Xiaomeng Yang, Yu Zhou, Paolo Rota .etc.|<http://arxiv.org/pdf/2504.21682v1>|[代码](https://github.com/shuyansy/Visual-Text-Processing-survey.); 提出统一评估框架和基准，推动视觉文本处理模型改进。|
|🆕 发布|eNCApsulate: NCA for Precision Diagnosis on Capsule Endoscopes|eNCApsulate：胶囊内镜上的NCA精确诊断方法|Henry John Krumb, Anirban Mukhopadhyay|<http://arxiv.org/pdf/2504.21562v1>|提出了一种轻量级NCA模型，实现胶囊内窥镜的精准诊断和定位。|
|🆕 发布|Black-Box Visual Prompt Engineering for Mitigating Object Hallucination in Large Vision Language Models|黑盒视觉提示工程以减轻大型视觉语言模型中的对象幻觉|Sangmin Woo, Kang Zhou, Yun Zhou, Shuai Wang, Sheng Guan, Haibo Ding, Lin Lee Cheong|<http://arxiv.org/pdf/2504.21559v1>|提出黑盒视觉提示工程框架，有效减轻大型视觉语言模型中的物体幻觉问题。|
|🆕 发布|Nexus-Gen: A Unified Model for Image Understanding, Generation, and Editing|Nexus-Gen：一种统一的图像理解、生成和编辑模型|Hong Zhang, Zhongjie Duan, Xingjun Wang, Yingda Chen, Yuze Zhao, Yu Zhang|<http://arxiv.org/pdf/2504.21356v1>|[代码](https://github.com/modelscope/Nexus-Gen.git); Nexus-Gen通过结合LLM的语言推理和扩散模型的图像合成能力，实现了图像理解、生成和编辑的统一...|
|🆕 发布|UniBiomed: A Universal Foundation Model for Grounded Biomedical Image Interpretation|UniBiomed：一种通用的基于理解的生物医学图像解释基础模型|Linshan Wu, Yuxiang Nie, Sunan He, Jiaxin Zhuang, Hao Chen|<http://arxiv.org/pdf/2504.21336v1>|UniBiomed通过融合多模态大语言模型和分割模型，实现了对生物医学图像的全面理解和自动解释。|
|🆕 发布|MoSAM: Motion-Guided Segment Anything Model with Spatial-Temporal Memory Selection|MoSAM：基于时空记忆选择的运动引导分割任何模型|Qiushi Yang, Yuan Yao, Miaomiao Cui, Liefeng Bo|<http://arxiv.org/pdf/2505.00739v1>|MoSAM通过结合运动引导和时空记忆选择，提升了视频对象分割的准确性和跟踪能力。|
|📝 更新|SignDiff: Diffusion Model for American Sign Language Production|SignDiff：用于美国手语生成的扩散模型|Sen Fang, Chunyu Sui, Yanghao Zhou, Xuedong Zhang, Hongbin Zhong, Yapeng Tian, Chen Chen|<http://arxiv.org/pdf/2308.16082v4>|提出SignDiff模型，通过文本输入生成美国手语骨骼姿态视频，显著提升生成质量和准确性。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|S3Former: Self-supervised High-resolution Transformer for Solar PV Profiling|S3Former：用于太阳能光伏轮廓的自监督高分辨率Transformer|Minh Tran, Adrian De Luis, Haitao Liao, Ying Huang, Roy McCann, Alan Mantooth, Jack Cothren, Ngan Le|<http://arxiv.org/pdf/2405.04489v2>|S3Former通过自监督学习，实现了从航拍图像中准确分割太阳能板并定位，为分析光伏安装对电网的影响...|
|📝 更新|Explorations of the Softmax Space: Knowing When the Neural Network Doesn't Know|探索Softmax空间：了解神经网络何时不知情|Daniel Sikar, Artur d'Avila Garcez, Tillman Weyde|<http://arxiv.org/pdf/2502.00456v2>|提出了一种基于softmax层距离测量的方法，以评估神经网络预测的可靠性并确定何时应推迟决策。|
|🆕 发布|Vision Transformers in Precision Agriculture: A Comprehensive Survey|视觉Transformer在精准农业中的应用：全面综述|Saber Mehdipour, Seyed Abolghasem Mirroshandel, Seyed Amirhossein Tabatabaei|<http://arxiv.org/pdf/2504.21706v1>|该论文综述了Vision Transformers在精准农业中的应用，提高了植物病害检测的准确性和可...|
|📝 更新|Vision Transformers on the Edge: A Comprehensive Survey of Model Compression and Acceleration Strategies|边缘上的视觉Transformer：模型压缩与加速策略的全面调查|Shaibal Saha, Lanyu Xu|<http://arxiv.org/pdf/2503.02891v2>|该论文全面综述了视觉Transformer在边缘设备上的模型压缩和加速策略，以解决其计算复杂性和内存...|
|🆕 发布|SAM4EM: Efficient memory-based two stage prompt-free segment anything model adapter for complex 3D neuroscience electron microscopy stacks|SAM4EM：基于内存的高效两阶段无提示“分割任何东西”模型适配器，用于复杂3D神经科学电子显微镜堆栈|Uzair Shah, Marco Agus, Daniya Boges, Vanessa Chiappini, Mahmood Alzubaidi, Jens Schneider, Markus Hadwiger, Pierre J. Magistretti .etc.|<http://arxiv.org/pdf/2504.21544v1>|[代码](https://github.com/Uzshah/SAM4EM.); 开发了一种基于SAM的无需提示的3D神经结构分割模型，显著提升了复杂神经结构的分割精度。|
|🆕 发布|Comparison of Different Deep Neural Network Models in the Cultural Heritage Domain|不同深度神经网络模型在文化遗产领域的比较|Teodor Boyadzhiev, Gabriele Lagani, Luca Ciampi, Giuseppe Amato, Krassimira Ivanova|<http://arxiv.org/pdf/2504.21387v1>|比较了卷积神经网络和Transformer架构在文化遗产领域的应用，发现DenseNet在效率与计算...|
|🆕 发布|Towards Improved Cervical Cancer Screening: Vision Transformer-Based Classification and Interpretability|朝着改进宫颈癌筛查：基于视觉Transformer的分类与可解释性|Khoa Tuan Nguyen, Ho-min Park, Gaeun Oh, Joris Vankerschaver, Wesley De Neve|<http://arxiv.org/pdf/2504.21340v1>|[代码](https://github.com/Khoa-NT/isbi2025_ps3c.); 提出基于EVA-02的视觉Transformer模型，通过多模型特征选择和损失加权，显著提升宫颈癌筛...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Iterative Trajectory Exploration for Multimodal Agents|多模态代理的迭代轨迹探索|Pengxiang Li, Zhi Gao, Bofei Zhang, Yapeng Mi, Xiaojian Ma, Chenrui Shi, Tao Yuan, Yuwei Wu .etc.|<http://arxiv.org/pdf/2504.21561v1>|提出了一种无需专家标注的在线自我探索方法，通过逐步偏好优化提升多模态智能体在复杂任务中的适应能力。|
|🆕 发布|GarmentDiffusion: 3D Garment Sewing Pattern Generation with Multimodal Diffusion Transformers|服装扩散：基于多模态扩散变换器的3D服装缝纫图案生成|Xinyu Li, Qi Yao, Yuanda Wang|<http://arxiv.org/pdf/2504.21476v1>|[代码](https://shenfu-research.github.io/Garment-Diffusion); 提出GarmentDiffusion，一种高效生成精确3D服装缝纫图案的多模态扩散模型。|
|🆕 发布|Rethinking Visual Layer Selection in Multimodal LLMs|重新思考多模态大型语言模型中的视觉层选择|Haoran Chen, Junyan Lin, Xinhao Chen, Yue Fan, Xin Jin, Hui Su, Jianfeng Dong, Jinlan Fu .etc.|<http://arxiv.org/pdf/2504.21447v1>|提出了一种基于层次表示相似性的方法，系统性地优化了多模态LLMs中的视觉层选择。|
|📝 更新|PANGAEA: A Global and Inclusive Benchmark for Geospatial Foundation Models|全球包容性地理空间基础模型基准：PANGAEA|Valerio Marsocci, Yuru Jia, Georges Le Bellier, David Kerekes, Liang Zeng, Sebastian Hafner, Sebastian Gerard, Eric Brune .etc.|<http://arxiv.org/pdf/2412.04204v2>|[代码](https://github.com/VMarsocci/pangaea-bench.); PANGAEA构建了一个全面基准，评估GFMs性能，解决现有评估协议的局限性和地域偏见。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ObjectFinder: An Open-Vocabulary Assistive System for Interactive Object Search by Blind People|ObjectFinder：一种用于盲人交互式物体搜索的开源词汇辅助系统|Ruiping Liu, Jiaming Zhang, Angela Schön, Karin Müller, Junwei Zheng, Kailun Yang, Anhong Guo, Kathrin Gerling .etc.|<http://arxiv.org/pdf/2412.03118v2>|开发了一种开放词汇的辅助系统，帮助盲人通过交互式搜索物体，提高其独立性和导航能力。|
|📝 更新|Joint Modeling of Feature, Correspondence, and a Compressed Memory for Video Object Segmentation|联合建模特征、对应关系和压缩内存的视频目标分割|Jiaming Zhang, Yutao Cui, Gangshan Wu, Limin Wang|<http://arxiv.org/pdf/2308.13505v2>|提出JointFormer框架，通过联合建模特征提取、对应匹配和压缩记忆，实现视频目标分割性能新突破...|
|🆕 发布|Learning to Borrow Features for Improved Detection of Small Objects in Single-Shot Detectors|学习在单次检测器中借用特征以提高小物体检测性能|Richard Schmit|<http://arxiv.org/pdf/2505.00044v1>|提出一种新框架，通过“借取”大物体特征提升小物体检测精度。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LoC-LIC: Low Complexity Learned Image Coding Using Hierarchical Feature Transforms|LoC-LIC：基于分层特征变换的低复杂度学习图像编码|Ayman A. Ameen, Thomas Richter, André Kaup|<http://arxiv.org/pdf/2504.21778v1>|提出了一种利用分层特征变换的低复杂度图像编码方法，显著降低计算复杂度同时保持压缩效率。|
|📝 更新|CountingDINO: A Training-free Pipeline for Class-Agnostic Counting using Unsupervised Backbones|CountingDINO：一种基于无监督骨干的无监督类别无关计数训练管道|Giacomo Pacini, Lorenzo Bianchi, Luca Ciampi, Nicola Messina, Giuseppe Amato, Fabrizio Falchi|<http://arxiv.org/pdf/2504.16570v2>|[代码](https://lorebianchi98.github.io/CountingDINO); CountingDINO提出无监督方法实现无类别计数，无需标注数据，显著提升计数准确度。|
|🆕 发布|Common3D: Self-Supervised Learning of 3D Morphable Models for Common Objects in Neural Feature Space|Common3D：神经特征空间中常见物体3D可变形模型的自我监督学习|Leonhard Sommer, Olaf Dünkel, Christian Theobalt, Adam Kortylewski|<http://arxiv.org/pdf/2504.21749v1>|Common3D通过自监督学习，在神经特征空间中为常见物体构建3D可变形模型，实现零样本视觉任务解决...|
|📝 更新|HOT3D: Hand and Object Tracking in 3D from Egocentric Multi-View Videos|HOT3D：基于自视角多视图视频的3D手和物体跟踪|Prithviraj Banerjee, Sindi Shkodrani, Pierre Moulon, Shreyas Hampali, Shangchen Han, Fan Zhang, Linguang Zhang, Jade Fountain .etc.|<http://arxiv.org/pdf/2411.19167v2>|HOT3D构建了一个包含多视角视频的3D手和物体跟踪数据集，显著提升了多视角方法在3D手跟踪和物体姿...|
|🆕 发布|Consistency-aware Fake Videos Detection on Short Video Platforms|基于短视频平台的伪视频一致性检测|Junxi Wang, Jize liu, Na Zhang, Yaxiong Wang|<http://arxiv.org/pdf/2504.21495v1>|提出一种利用跨模态一致性检测假视频的新方法，显著提升检测准确率。|
|🆕 发布|Robust Orthogonal NMF with Label Propagation for Image Clustering|鲁棒正交NMF与标签传播用于图像聚类|Jingjing Liu, Nian Wu, Xianchao Xiu, Jianhua Zhang|<http://arxiv.org/pdf/2504.21472v1>|提出了一种鲁棒的基于NMF和标签传播的图像聚类方法，有效提高了聚类鲁棒性。|
|📝 更新|Learning 6-DoF Fine-grained Grasp Detection Based on Part Affordance Grounding|基于部分可及性定位的6自由度精细抓取检测学习|Yaoxian Song, Penglei Sun, Piaopiao Jin, Yi Ren, Yu Zheng, Zhixu Li, Xiaowen Chu, Yue Zhang .etc.|<http://arxiv.org/pdf/2301.11564v3>|提出了一种基于部分 affordance grounding 的语言引导 6-DoF 精细抓取检测方...|
|🆕 发布|Detection and Classification of Diseases in Multi-Crop Leaves using LSTM and CNN Models|基于LSTM和CNN模型的多作物叶片疾病检测与分类|Srinivas Kanakala, Sneha Ningappa|<http://arxiv.org/pdf/2505.00741v1>|利用CNN和LSTM模型，实现了对多作物叶片疾病的准确检测与分类。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DS_FusionNet: Dynamic Dual-Stream Fusion with Bidirectional Knowledge Distillation for Plant Disease Recognition|DS_FusionNet：基于双向知识蒸馏的动态双流融合植物病害识别|Yanghui Song, Chengfu Yang|<http://arxiv.org/pdf/2504.20948v2>|提出DS_FusionNet，通过动态双流融合和双向知识蒸馏，有效提升植物病害识别准确率。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ScaleFusionNet: Transformer-Guided Multi-Scale Feature Fusion for Skin Lesion Segmentation|尺度融合网络：用于皮肤病变分割的Transformer引导的多尺度特征融合|Saqib Qamar, Syed Furqan Qadri, Roobaea Alroobaea, Goram Mufarah M Alshmrani, Richard Jiang|<http://arxiv.org/pdf/2503.03327v2>|ScaleFusionNet通过结合Transformer和自适应融合块，显著提升了皮肤病变分割的准...|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Robust and Generalizable Gerchberg Saxton based Physics Inspired Neural Networks for Computer Generated Holography: A Sensitivity Analysis Framework|基于Gerchberg Saxton的鲁棒且泛化能力强的物理灵感神经网络在计算机生成全息图中的应用：敏感性分析框架|Ankit Amrutkar, Björn Kampa, Volkmar Schulz, Johannes Stegmaier, Markus Rothermel, Dorit Merhof|<http://arxiv.org/pdf/2505.00220v1>|提出了一种基于物理启发和敏感性分析的神经网络方法，提高了计算机全息图的生成性能和泛化能力。|
|🆕 发布|Can We Achieve Efficient Diffusion without Self-Attention? Distilling Self-Attention into Convolutions|能否在不使用自注意力机制的情况下实现高效扩散？将自注意力蒸馏到卷积中|ZiYi Dong, Chengxing Zhou, Weijian Deng, Pengxu Wei, Xiangyang Ji, Liang Lin|<http://arxiv.org/pdf/2504.21292v1>|提出了一种将自注意力机制转化为卷积操作的方法，显著降低计算成本并提升图像生成效率。|
|📝 更新|GATE3D: Generalized Attention-based Task-synergized Estimation in 3D*|GATE3D：基于泛化注意力的3D任务协同估计|Eunsoo Im, Changhyun Jee, Jung Kwon Lee|<http://arxiv.org/pdf/2504.11014v4>|[代码](https://ies0411.github.io/GATE3D); 提出GATE3D，通过弱监督和一致性损失实现通用单目3D物体检测，有效解决多域训练挑战。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Accelerating Diffusion Transformer via Error-Optimized Cache|加速通过错误优化的缓存进行扩散Transformer|Junxiang Qiu, Shuo Wang, Jinda Lu, Lin Liu, Houcheng Jiang, Xingyu Zhu, Yanbin Hao|<http://arxiv.org/pdf/2501.19243v2>|提出了一种优化缓存策略，显著降低扩散Transformer生成内容误差，提升图像生成质量。|
|🆕 发布|Active Light Modulation to Counter Manipulation of Speech Visual Content|主动光调制以对抗语音视觉内容的操纵|Hadleigh Schwartz, Xiaofeng Yan, Charles J. Carver, Xia Zhou|<http://arxiv.org/pdf/2504.21846v1>|提出Spotlight系统，通过动态物理签名保护语音视频真实性，有效对抗视觉篡改。|
|🆕 发布|Simple Visual Artifact Detection in Sora-Generated Videos|简单视觉伪影检测在Sora生成的视频中|Misora Sugiyama, Hirokatsu Kataoka|<http://arxiv.org/pdf/2504.21334v1>|提出了一种针对Sora生成视频视觉瑕疵的多标签分类框架，提升视频质量评估与安全性。|
|🆕 发布|SR-NeRV: Improving Embedding Efficiency of Neural Video Representation via Super-Resolution|SR-NeRV：通过超分辨率提高神经视频表示的嵌入效率|Taiga Hayami, Kakeru Koizumi, Hiroshi Watanabe|<http://arxiv.org/pdf/2505.00046v1>|提出了一种结合超分辨率网络的INR视频表示方法，有效提升重建质量并保持模型大小。|
|📝 更新|High-Frequency Enhanced Hybrid Neural Representation for Video Compression|高频增强混合神经网络视频压缩|Li Yu, Zhihui Li, Jimin Xiao, Moncef Gabbouj|<http://arxiv.org/pdf/2411.06685v2>|提出高频增强混合神经网络表示方法，提升视频压缩细节保留和性能。|
|📝 更新|DyST-XL: Dynamic Layout Planning and Content Control for Compositional Text-to-Video Generation|动态布局规划和内容控制用于组合文本到视频生成|Weijie He, Mushui Liu, Yunlong Yu, Zhao Wang, Chao Wu|<http://arxiv.org/pdf/2504.15032v2>|[代码](https://github.com/XiaoBuL/DyST-XL.); 提出DyST-XL框架，通过动态布局规划和内容控制，显著提升无监督文本到视频生成性能。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Efficient and robust 3D blind harmonization for large domain gaps|高效且鲁棒的跨大领域差距的3D盲和谐|Hwihun Jeong, Hayeon Lee, Se Young Chun, Jongho Lee|<http://arxiv.org/pdf/2505.00133v1>|提出了一种针对大域差距的鲁棒3D盲和谐框架，显著提升了图像质量与性能。|
|🆕 发布|Anomaly-Driven Approach for Enhanced Prostate Cancer Segmentation|异常驱动前列腺癌分割增强方法|Alessia Hu, Regina Beets-Tan, Lishan Cai, Eduardo Pooch|<http://arxiv.org/pdf/2504.21789v1>|提出了一种结合异常检测的U-Net模型，有效提升了前列腺癌自动分割性能。|
|🆕 发布|Cert-SSB: Toward Certified Sample-Specific Backdoor Defense|Cert-SSB：迈向认证样本特定后门防御|Ting Qiao, Yingjia Wang, Xing Liu, Sixing Wu, Jianbing Li, Yiming Li|<http://arxiv.org/pdf/2504.21730v1>|[代码](https://github.com/NcepuQiaoTing/Cert-SSB.); 提出了一种针对样本特定后门攻击的认证防御方法，显著提升了防御效果。|
|📝 更新|BiPrompt-SAM: Enhancing Image Segmentation via Explicit Selection between Point and Text Prompts|BiPrompt-SAM：通过显式选择点和文本提示增强图像分割|Suzhe Xu, Jialin Peng, Chengyuan Zhang|<http://arxiv.org/pdf/2503.19769v2>|提出一种结合点提示和文本提示的图像分割方法，有效融合空间精度和语义上下文。|
|🆕 发布|Mcity Data Engine: Iterative Model Improvement Through Open-Vocabulary Data Selection|Mcity数据引擎：通过开放词汇数据选择进行迭代模型改进|Daniel Bogdoll, Rajanikant Patnaik Ananta, Abeyankar Giridharan, Isabel Moore, Gregory Stevens, Henry X. Liu|<http://arxiv.org/pdf/2504.21614v1>|[代码](https://github.com/mcity/mcity_data_engine); Mcity Data Engine通过开放词汇数据选择，迭代优化模型，解决智能交通系统数据标注难题。|
|🆕 发布|DGSolver: Diffusion Generalist Solver with Universal Posterior Sampling for Image Restoration|DGSolver：具有通用后验采样的扩散泛化求解器用于图像恢复|Hebaixu Wang, Jing Zhang, Haonan Guo, Di Wang, Jiayi Ma, Bo Du|<http://arxiv.org/pdf/2504.21487v1>|[代码](https://github.com/MiliLab/DGSolver.); DGSolver通过精确求解和通用后验采样，显著提升了图像修复的准确性和效率。|
|🆕 发布|Multiview Point Cloud Registration via Optimization in an Autoencoder Latent Space|多视角点云注册通过自动编码器潜在空间中的优化|Luc Vedrenne, Sylvain Faisan, Denis Fortun|<http://arxiv.org/pdf/2504.21467v1>|[代码](https://github.com/pypolar/polar); 提出了一种基于自编码器潜在空间的点云多视角注册方法，有效处理大量视角和高退化。|
|📝 更新|AC-Lite : A Lightweight Image Captioning Model for Low-Resource Assamese Language|AC-Lite：适用于低资源阿萨姆语图像描述的轻量级模型|Pankaj Choudhury, Yogesh Aggarwal, Prabhanjan Jadhav, Prithwijit Guha, Sukumar Nandi|<http://arxiv.org/pdf/2503.01453v2>|提出AC-Lite模型，以轻量级网络实现低资源阿萨姆语图像描述生成。|
|🆕 发布|Sparse-to-Sparse Training of Diffusion Models|稀疏到稀疏的扩散模型训练|Inês Cardoso Oliveira, Decebal Constantin Mocanu, Luis A. Leiva|<http://arxiv.org/pdf/2504.21380v1>|首次将稀疏训练应用于扩散模型，显著降低训练和推理资源需求。|
|🆕 发布|IDDM: Bridging Synthetic-to-Real Domain Gap from Physics-Guided Diffusion for Real-world Image Dehazing|IDDM：基于物理引导扩散的从合成到真实域差距的跨越，用于真实图像去雾|Shijun Zhou, Yajing Liu, Chunhui Hao, Zhiyuan Liu, Jiandong Tian|<http://arxiv.org/pdf/2504.21385v1>|提出IDDM模型，通过物理引导的扩散过程，有效缩小合成与真实图像域差距，实现真实图像去雾。|
|🆕 发布|Revisiting Diffusion Autoencoder Training for Image Reconstruction Quality|重新审视扩散自编码器训练以提高图像重建质量|Pramook Khungurn, Sukit Seripanitkarn, Phonphrm Thawatdamrongkit, Supasorn Suwajanakorn|<http://arxiv.org/pdf/2504.21368v1>|提出改进扩散自编码器训练方法，提升图像重建质量，实现结构细节兼顾。|
|🆕 发布|Vision-Language Model-Based Semantic-Guided Imaging Biomarker for Early Lung Cancer Detection|基于视觉-语言模型的语义引导成像生物标志物用于早期肺癌检测|Luoting Zhuang, Seyed Mohammad Hossein Tabatabaei, Ramin Salehi-Rad, Linh M. Tran, Denise R. Aberle, Ashley E. Prosper, William Hsu|<http://arxiv.org/pdf/2504.21344v1>|提出了一种基于语义引导的图像生物标志物，通过结合语义特征和深度特征，实现了肺癌早期检测的准确性和可解...|
|🆕 发布|The Dual Power of Interpretable Token Embeddings: Jailbreaking Attacks and Defenses for Diffusion Model Unlearning|双管齐下的可解释Token嵌入：扩散模型反学习中的越狱攻击与防御|Siyi Chen, Yimeng Zhang, Sijia Liu, Qing Qu|<http://arxiv.org/pdf/2504.21307v1>|提出了一种基于可解释嵌入的攻击和防御方法，破解并防御扩散模型遗忘有害内容的能力。|
|📝 更新|ColorEdit: Training-free Image-Guided Color editing with diffusion model|ColorEdit：基于扩散模型的免训练图像引导式色彩编辑|Xingxi Yin, Zhi Li, Jingfeng Zhang, Chenglin Li, Yin Zhang|<http://arxiv.org/pdf/2411.10232v2>|提出了一种无需训练的图像引导色彩编辑方法，有效解决了文本引导图像编辑中的色彩失配问题。|
|📝 更新|DDM: A Metric for Comparing 3D Shapes Using Directional Distance Fields|DDM：基于方向距离场的3D形状比较度量|Siyu Ren, Junhui Hou, Xiaodong Chen, Hongkai Xiong, Wenping Wang|<http://arxiv.org/pdf/2401.09736v5>|[代码](https://github.com/rsy6318/DDM.); 提出了一种基于方向距离场的3D形状比较度量方法，显著提升了3D几何建模任务的准确性。|
|🆕 发布|CoCoDiff: Diversifying Skeleton Action Features via Coarse-Fine Text-Co-Guided Latent Diffusion|CoCoDiff：通过粗细文本共引导潜在扩散多样化骨架动作特征|Zhifu Zhao, Hanyang Hua, Jianan Li, Shaoxin Wu, Fu Li, Yangtao Zhou, Yang Li|<http://arxiv.org/pdf/2504.21266v1>|CoCoDiff通过文本引导的潜在扩散模型，有效提升了骨骼动作特征多样性，确保语义一致性。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Eye2Eye: A Simple Approach for Monocular-to-Stereo Video Synthesis|眼对眼：单目到立体视频合成的简单方法|Michal Geyer, Omer Tov, Linyi Jin, Richard Tucker, Inbar Mosseri, Tali Dekel, Noah Snavely|<http://arxiv.org/pdf/2505.00135v1>|提出了一种简单方法，通过直接合成新视角，实现从单目到立体视频的转换，有效避免传统方法的局限性。|
|🆕 发布|ReVision: High-Quality, Low-Cost Video Generation with Explicit 3D Physics Modeling for Complex Motion and Interaction|ReVision：具有显式3D物理建模的复杂运动和交互的高质量、低成本视频生成|Qihao Liu, Ju He, Qihang Yu, Liang-Chieh Chen, Alan Yuille|<http://arxiv.org/pdf/2504.21855v1>|ReVision通过整合3D物理知识，显著提升了视频生成中复杂动作和交互的逼真度和可控性。|
|🆕 发布|Anatomical Similarity as a New Metric to Evaluate Brain Generative Models|脑生成模型评估的新指标：解剖相似性|Bahram Jafrasteh, Wei Peng, Cheng Wan, Yimin Luo, Ehsan Adeli, Qingyu Zhao|<http://arxiv.org/pdf/2504.21771v1>|[代码](https://github.com/BahramJafrasteh/wasabi-mri.); 提出WASABI评估合成脑MRI的解剖真实性，强调解剖准确性。|
|📝 更新|Uncovering Bias in Large Vision-Language Models at Scale with Counterfactuals|标题翻译： 在规模上通过反事实揭示大型视觉-语言模型中的偏差|Phillip Howard, Kathleen C. Fraser, Anahita Bhiwandiwalla, Svetlana Kiritchenko|<http://arxiv.org/pdf/2405.20152v2>|通过对比实验揭示大规模视觉语言模型中图像信息对生成文本偏见的影响。|
|📝 更新|T2VEval: Benchmark Dataset and Objective Evaluation Method for T2V-generated Videos|T2VEval：T2V生成视频的基准数据集和客观评估方法|Zelu Qi, Ping Shi, Shuqi Wang, Chaoyang Zhang, Fei Zhao, Zefeng Ying, Da Pan, Xi Yang .etc.|<http://arxiv.org/pdf/2501.08545v6>|构建T2VEval-Bench基准数据集，提出多分支融合方案T2VEval，有效评估T2V生成视频质...|
|📝 更新|Garment3DGen: 3D Garment Stylization and Texture Generation|服装3D生成：三维服装风格化和纹理生成|Nikolaos Sarafianos, Tuur Stuyck, Xiaoyu Xiang, Yilei Li, Jovan Popovic, Rakesh Ranjan|<http://arxiv.org/pdf/2403.18816v3>|Garment3DGen通过图像引导，自动生成逼真的3D服装模型，无需艺术家干预。|
|📝 更新|PixelHacker: Image Inpainting with Structural and Semantic Consistency|像素黑客：基于结构和语义一致性的图像修复|Ziyang Xu, Kangsheng Duan, Xiaolei Shen, Zhifeng Ding, Wenyu Liu, Xiaohu Ruan, Xiaoxin Chen, Xinggang Wang|<http://arxiv.org/pdf/2504.20438v2>|[代码](https://hustvl.github.io/PixelHacker.); PixelHacker通过引入潜在类别引导和扩散模型，有效解决了图像修复中的结构和语义一致性难题。|
|📝 更新|Segmentation-Aware Generative Reinforcement Network (GRN) for Tissue Layer Segmentation in 3-D Ultrasound Images for Chronic Low-back Pain (cLBP) Assessment|基于分割感知生成式强化网络（GRN）的3D超声图像组织层分割及其在慢性腰痛（cLBP）评估中的应用|Zixue Zeng, Xiaoyan Zhao, Matthew Cartier, Tong Yu, Jing Wang, Xin Meng, Zhiyu Sheng, Maryam Satarpour .etc.|<http://arxiv.org/pdf/2501.17690v2>|提出了一种分段感知生成强化网络，显著降低标注工作量并提升3D超声图像组织层分割性能。|
|🆕 发布|HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene Generation|HoloTime：驯服视频扩散模型以生成全景4D场景|Haiyang Zhou, Wangbo Yu, Jiawen Guan, Xinhua Cheng, Yonghong Tian, Li Yuan|<http://arxiv.org/pdf/2504.21650v1>|HoloTime通过整合视频扩散模型和360度4D场景重建方法，实现了从单张图像生成沉浸式全景视频。|
|🆕 发布|MagicPortrait: Temporally Consistent Face Reenactment with 3D Geometric Guidance|魔幻肖像：基于3D几何引导的时间一致性人脸重演|Mengting Wei, Yante Li, Tuomas Varanka, Yan Jiang, Licai Sun, Guoying Zhao|<http://arxiv.org/pdf/2504.21497v1>|[代码](https://github.com/weimengting/MagicPortrait.); 提出了一种结合3D几何指导的时序一致人脸重放方法，显著提升了视频人脸生成质量。|
|📝 更新|Type-R: Automatically Retouching Typos for Text-to-Image Generation|Type-R：自动修正文本到图像生成中的错别字|Wataru Shimoda, Naoto Inoue, Daichi Haraguchi, Hayato Mitani, Seiichi Uchida, Kota Yamaguchi|<http://arxiv.org/pdf/2411.18159v2>|Type-R通过后处理自动修正文本图像中的错别字，提升文字渲染准确度。|
|📝 更新|Ditto: Motion-Space Diffusion for Controllable Realtime Talking Head Synthesis|Ditto：可控实时说话人头合成中的运动空间扩散|Tianqi Li, Ruobing Zheng, Minghui Yang, Jingdong Chen, Ming Yang|<http://arxiv.org/pdf/2411.19509v3>|提出Ditto，通过运动空间扩散实现可控且实时的人脸合成，解决控制不足和速度慢的问题。|
|📝 更新|Elucidating the Preconditioning in Consistency Distillation|揭示一致性蒸馏中的预处理条件|Kaiwen Zheng, Guande He, Jianfei Chen, Fan Bao, Jun Zhu|<http://arxiv.org/pdf/2502.02922v3>|揭示了一致性蒸馏中的预条件设计，提出了一种基于一致性差距的优化方法，显著加速了多步生成训练。|
|🆕 发布|Diff-Prompt: Diffusion-Driven Prompt Generator with Mask Supervision|Diff-Prompt：基于扩散的带掩码监督的提示生成器|Weicai Yan, Wang Lin, Zirun Guo, Ye Wang, Fangming Feng, Xiaoda Yang, Zehan Wang, Tao Jin|<http://arxiv.org/pdf/2504.21423v1>|[代码](https://github.com/Kelvin-ywc/diff-prompt.); 提出Diffusion-Driven Prompt Generator，利用扩散模型生成丰富、精细的...|
|📝 更新|OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis|OS-Genesis：通过逆向任务合成自动化GUI代理轨迹构建|Qiushi Sun, Kanzhi Cheng, Zichen Ding, Chuanyang Jin, Yian Wang, Fangzhi Xu, Zhenyu Wu, Chengyou Jia .etc.|<http://arxiv.org/pdf/2412.19723v2>|[代码](https://qiushisun.github.io/OS-Genesis-Home); OS-Genesis通过逆向任务合成自动化GUI代理轨迹构建，显著提升GUI代理性能。|
|📝 更新|LEyes: A Lightweight Framework for Deep Learning-Based Eye Tracking using Synthetic Eye Images|LEyes：基于合成眼图像的深度学习眼动追踪的轻量级框架|Sean Anthony Byrne, Virmarie Maquiling, Marcus Nyström, Enkelejda Kasneci, Diederick C. Niehorster|<http://arxiv.org/pdf/2309.06129v4>|提出LEyes框架，利用合成眼图简化深度学习眼动追踪，提高模型泛化能力和成本效益。|
|🆕 发布|Text-Conditioned Diffusion Model for High-Fidelity Korean Font Generation|基于文本条件的扩散模型用于高保真韩文字体生成|Abdul Sami, Avinash Kumar, Irfanullah Memon, Youngwon Jo, Muhammad Rizwan, Jaeyoung Choi|<http://arxiv.org/pdf/2504.21325v1>|提出一种基于扩散模型的韩文字体生成方法，有效解决传统方法训练不稳定和细节捕捉困难的问题。|
|🆕 发布|AGHI-QA: A Subjective-Aligned Dataset and Metric for AI-Generated Human Images|AGHI-QA：人工智能生成人类图像的主观对齐数据集和度量标准|Yunhao Li, Sijing Wu, Wei Sun, Zhichao Zhang, Yucheng Zhu, Zicheng Zhang, Huiyu Duan, Xiongkuo Min .etc.|<http://arxiv.org/pdf/2504.21308v1>|提出AGHI-QA数据集和AGHI-Assessor质量评估方法，解决AI生成人像质量评估难题。|
|📝 更新|Generalizable Synthetic Image Detection via Language-guided Contrastive Learning|基于语言引导的对比学习实现泛化合成图像检测|Haiwei Wu, Jiantao Zhou, Shile Zhang|<http://arxiv.org/pdf/2305.13800v2>|[代码](https://github.com/HighwayWu/LASTED.); 提出了一种语言引导的对比学习方法，有效提升了合成图像检测的泛化能力。|
|📝 更新|SignLLM: Sign Language Production Large Language Models|SignLLM：手语生成大型语言模型|Sen Fang, Chen Chen, Lei Wang, Ce Zheng, Chunyu Sui, Yapeng Tian|<http://arxiv.org/pdf/2405.10718v3>|提出SignLLM，一种多语言手语生成大语言模型，实现从文本到手语转换。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Neuroevolution of Self-Attention Over Proto-Objects|神经进化在原型对象上的自注意力|Rafael C. Pinto, Anderson R. Tavares|<http://arxiv.org/pdf/2505.00186v1>|利用原型对象进行神经进化，实现更高效的自注意力机制，大幅降低参数量和训练时间。|
|📝 更新|PPT: Pretraining with Pseudo-Labeled Trajectories for Motion Forecasting|基于伪标签轨迹的预训练用于运动预测|Yihong Xu, Yuan Yin, Éloi Zablocki, Tuan-Hung Vu, Alexandre Boulch, Matthieu Cord|<http://arxiv.org/pdf/2412.06491v2>|提出PPT方法，利用伪标签轨迹进行预训练，有效提升运动预测模型在低数据场景下的泛化能力。|
|📝 更新|Towards Understanding Depth Perception in Foveated Rendering|朝向理解注视点渲染中的深度感知|Sophie Kergaßner, Taimoor Tariq, Piotr Didyk|<http://arxiv.org/pdf/2501.18635v2>|首次评估了视场渲染对立体深度感知的影响，并提出了一种感知模型以确定不影响立体视力的视场渲染程度。|
|🆕 发布|Quaternion Nuclear Norms Over Frobenius Norms Minimization for Robust Matrix Completion|基于Frobenius范数的四元数核范数最小化用于鲁棒矩阵补全|Yu Guo, Guoqing Chen, Tieyong Zeng, Qiyu Jin, Michael Kwok-Po Ng|<http://arxiv.org/pdf/2504.21468v1>|引入QNOF优化方法，有效提升矩阵补全的鲁棒性。|
|🆕 发布|A Survey on 3D Reconstruction Techniques in Plant Phenotyping: From Classical Methods to Neural Radiance Fields (NeRF), 3D Gaussian Splatting (3DGS), and Beyond|植物表型3D重建技术综述：从经典方法到神经辐射场（NeRF）、3D高斯分层（3DGS）及其他|Jiajia Li, Xinda Qi, Seyed Hamidreza Nabaei, Meiqi Liu, Dong Chen, Xin Zhang, Xunyuan Yin, Zhaojian Li|<http://arxiv.org/pdf/2505.00737v1>|[代码](https://github.com/JiajiaLi04/3D-Reconstruction-Plants); 综述了植物表型分析中的3D重建技术，从经典方法到NeRF和3DGS，为精准农业提供高效解决方案。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Stereo4D: Learning How Things Move in 3D from Internet Stereo Videos|立体4D：从互联网立体视频中学习物体在3D中的运动|Linyi Jin, Richard Tucker, Zhengqi Li, David Fouhey, Noah Snavely, Aleksander Holynski|<http://arxiv.org/pdf/2412.09621v2>|提出了一种从互联网立体视频中挖掘高质量4D重建的系统，用于学习3D场景动态运动。|
|📝 更新|Multi-view Structural Convolution Network for Domain-Invariant Point Cloud Recognition of Autonomous Vehicles|多视角结构卷积网络用于自动驾驶车辆领域不变点云识别|Younggun Kim, Beomsik Cho, Seonghoon Ryoo, Soomok Lee|<http://arxiv.org/pdf/2501.16289v3>|[代码](https://github.com/MLMLab/MSCN.); 提出MSCN，通过多视角结构卷积网络实现自动驾驶车辆点云数据域不变识别。|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Direct Motion Models for Assessing Generated Videos|直接运动模型用于评估生成视频|Kelsey Allen, Carl Doersch, Guangyao Zhou, Mohammed Suhail, Danny Driess, Ignacio Rocco, Yulia Rubanova, Thomas Kipf .etc.|<http://arxiv.org/pdf/2505.00209v1>|开发了一种基于点轨迹的度量方法，有效评估生成视频的运动质量。|
|📝 更新|Leveraging Motion Information for Better Self-Supervised Video Correspondence Learning|利用运动信息提升自监督视频对应学习|Zihan Zhou, Changrui Dai, Aibo Song, Xiaolin Fang|<http://arxiv.org/pdf/2503.12026v2>|设计了一种结合运动信息的多簇采样策略，有效提升了视频对应学习的准确性。|
|🆕 发布|Enhancing Self-Supervised Fine-Grained Video Object Tracking with Dynamic Memory Prediction|增强基于动态记忆预测的自监督细粒度视频目标跟踪|Zihan Zhou, Changrui Dai, Aibo Song, Xiaolin Fang|<http://arxiv.org/pdf/2504.21692v1>|提出动态内存预测框架，利用多参考帧提升视频目标跟踪精度。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Early Exit and Multi Stage Knowledge Distillation in VLMs for Video Summarization|视频摘要中的VLMs早期退出和多阶段知识蒸馏|Anas Anwarul Haq Khan, Utkarsh Verma, Prateek Chanda, Ganesh Ramakrishnan|<http://arxiv.org/pdf/2504.21831v1>|提出了一种轻量级视频摘要模型，通过多阶段知识蒸馏和早期退出技术，在保持较高准确率的同时显著降低计算成...|
|🆕 发布|Static or Dynamic: Towards Query-Adaptive Token Selection for Video Question Answering|静态或动态：迈向视频问答中的查询自适应标记选择|Yumeng Shi, Quanyu Long, Wenya Wang|<http://arxiv.org/pdf/2504.21403v1>|提出了一种自适应视频问答中静态和动态信息选择的策略，显著提升了模型性能。|
|🆕 发布|Responsive DNN Adaptation for Video Analytics against Environment Shift via Hierarchical Mobile-Cloud Collaborations|响应式深度神经网络适应环境变化的视频分析：基于分层移动-云协作|Maozhe Zhao, Shengzhong Liu, Fan Wu, Guihai Chen|<http://arxiv.org/pdf/2505.00745v1>|MOCHA通过移动云协作优化模型适应性，显著提升视频分析系统对环境变化的响应速度。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding|银河漫步者：用于银河尺度理解的几何感知视觉语言模型|Tianyu Chen, Xingcheng Fu, Yisen Gao, Haodong Qian, Yuecen Wei, Kun Yan, Haoyi Zhou, Jianxin Li|<http://arxiv.org/pdf/2503.18578v2>|提出Galaxy-Walker，通过几何感知和自适应架构，实现宇宙级视觉理解，显著提升天体属性估计和...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Recursive KL Divergence Optimization: A Dynamic Framework for Representation Learning|递归KL散度优化：表示学习的动态框架|Anthony D Martin|<http://arxiv.org/pdf/2504.21707v1>|提出了一种基于递归KL散度优化的动态框架，有效提升了表示学习效率和模型稳定性。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Comparison of Kinematics and Kinetics Between OpenCap and a Marker-Based Motion Capture System in Cycling|开放CAP与基于标记的运动捕捉系统在自行车运动中的运动学和动力学比较|Reza Kakavand, Reza Ahmadi, Atousa Parsaei, W. Brent Edwards, Amin Komeili|<http://arxiv.org/pdf/2409.03766v3>|评估了OpenCap与标记式运动捕捉系统在自行车运动中关节运动学和动力学评估的一致性。|
|🆕 发布|AnimalMotionCLIP: Embedding motion in CLIP for Animal Behavior Analysis|动物运动CLIP：将运动嵌入CLIP以进行动物行为分析|Enmin Zhong, Carlos R. del-Blanco, Daniel Berjón, Fernando Jaureguizar, Narciso García|<http://arxiv.org/pdf/2505.00569v1>|提出AnimalMotionCLIP，通过融合视频帧和光流信息，有效解决动物行为分析中的运动信息整合...|
|🆕 发布|Entropy Heat-Mapping: Localizing GPT-Based OCR Errors with Sliding-Window Shannon Analysis|熵热图：基于滑动窗口香农分析的GPT OCR错误定位|Alexei Kaltchenko|<http://arxiv.org/pdf/2505.00746v1>|提出了一种利用滑动窗口熵分析定位GPT-4o OCR错误的轻量级方法。|
|🆕 发布|SeriesBench: A Benchmark for Narrative-Driven Drama Series Understanding|系列基准：基于叙事驱动的剧情理解基准|Chenkai Zhang, Yiming Lei, Zeming Liu, Haitao Leng, ShaoGuo Liu, Tingting Gao, Qingjie Liu, Yunhong Wang|<http://arxiv.org/pdf/2504.21435v1>|[代码](https://github.com/zackhxn/SeriesBench-CVPR2025.); 提出SeriesBench基准和PC-DCoT框架，以评估和提升多模态大语言模型对叙事驱动剧集的理解...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VividListener: Expressive and Controllable Listener Dynamics Modeling for Multi-Modal Responsive Interaction|生动听众：多模态响应交互中的表情和可控听众动态建模|Shiying Li, Xingqun Qi, Bingkun Yang, Chen Weile, Zezhao Tian, Muyi Sun, Qifeng Liu, Man Zhang .etc.|<http://arxiv.org/pdf/2504.21718v1>|提出VividListener框架，实现多模态响应交互中精细、表达和可控的听众动态建模。|
|📝 更新|Towards Writing Style Adaptation in Handwriting Recognition|迈向手写识别中的书写风格适应|Jan Kohút, Michal Hradiš, Martin Kišš|<http://arxiv.org/pdf/2302.06318v2>|提出了一种基于作者风格块的书写识别模型，提高了识别准确率。|
|🆕 发布|Cascade Detector Analysis and Application to Biomedical Microscopy|级联检测器分析与在生物显微镜中的应用|Thomas L. Athey, Shashata Sawmya, Nir Shavit|<http://arxiv.org/pdf/2504.21598v1>|利用级联检测器高效识别生物显微镜图像中的稀疏物体，显著提升检测速度。|
|📝 更新|Fine-tuning Is a Surprisingly Effective Domain Adaptation Baseline in Handwriting Recognition|精细调整在手写识别中的域适应基线令人惊讶地有效|Jan Kohút, Michal Hradiš|<http://arxiv.org/pdf/2302.06308v2>|在手写识别领域，简单微调和数据增强成为有效且抗过拟合的域自适应方法。|
|🆕 发布|CAE-DFKD: Bridging the Transferability Gap in Data-Free Knowledge Distillation|CAE-DFKD：弥合数据无关知识蒸馏的可迁移性差距|Zherui Zhang, Changwei Wang, Rongtao Xu, Wenhao Xu, Shibiao Xu, Yu Zhang, Li Guo|<http://arxiv.org/pdf/2504.21478v1>|提出CAE-DFKD方法，解决数据无关知识蒸馏中迁移性不足问题，提升模型泛化能力。|
|📝 更新|Uncertainty for SVBRDF Acquisition using Frequency Analysis|基于频率分析的SVBRDF获取的不确定性|Ruben Wiersma, Julien Philip, Miloš Hašan, Krishna Mullia, Fujun Luan, Elmar Eisemann, Valentin Deschaintre|<http://arxiv.org/pdf/2406.17774v2>|[代码](https://github.com/rubenwiersma/svbrdf_uncertainty.); 利用频率分析量化多视角SVBRDF获取的不确定性，加速熵计算并提升参数恢复性能。|
|🆕 发布|Fast2comm:Collaborative perception combined with prior knowledge|快速协同感知与先验知识结合|Zhengbin Zhang, Yan Wu, Hongkun Zhang|<http://arxiv.org/pdf/2505.00740v1>|[代码](https://github.com/Zhangzhengbin-TJ/Fast2comm.); 提出Fast2comm框架，通过融合先验知识和特征选择策略，提升协作感知的准确性和带宽效率。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|WARP-LCA: Efficient Convolutional Sparse Coding with Locally Competitive Algorithm|WARP-LCA：基于局部竞争算法的高效卷积稀疏编码|Geoffrey Kasenbacher, Felix Ehret, Gerrit Ecke, Sebastian Otte|<http://arxiv.org/pdf/2410.18794v2>|提出WARP-LCA，通过预测预初始化LCA状态，显著提升卷积稀疏编码的效率和效果。|
|📝 更新|GISE-TTT:A Framework for Global InformationSegmentation and Enhancement|GISE-TTT：全局信息分割与增强框架|Fenglei Hao, Yuliang Yang, Ruiyuan Su, Zhengran Zhao, Yukun Qiao, Mengyu Zhu|<http://arxiv.org/pdf/2504.00879v2>|[代码](https://github.com/uuool/GISE-TTT.); 提出GISE-TTT框架，通过集成TTT层和分层方法，有效捕捉长视频序列中的全局时间依赖关系，提升视...|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OPAL: Visibility-aware LiDAR-to-OpenStreetMap Place Recognition via Adaptive Radial Fusion|OPAL：基于自适应径向融合的可见性感知激光雷达到OpenStreetMap场所识别|Shuhao Kang, Martin Y. Liao, Yan Xia, Olaf Wysocki, Boris Jutzi, Daniel Cremers|<http://arxiv.org/pdf/2504.19258v2>|OPAL通过融合LiDAR和OpenStreetMap数据，实现了高效且准确的地点识别。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Adversarial Data Poisoning Attacks on Quantum Machine Learning in the NISQ Era|量子计算NISQ时代量子机器学习的对抗性数据投毒攻击|Satwik Kundu, Swaroop Ghosh|<http://arxiv.org/pdf/2411.14412v3>|提出量子机器学习数据中毒攻击方法，有效降低模型性能。|
|📝 更新|End-to-end Audio Deepfake Detection from RAW Waveforms: a RawNet-Based Approach with Cross-Dataset Evaluation|端到端基于原始波形音频深度伪造检测：一种基于RawNet的跨数据集评估方法|Andrea Di Pierno, Luca Guarnera, Dario Allegra, Sebastiano Battiato|<http://arxiv.org/pdf/2504.20923v2>|提出了一种基于原始波形和跨数据集评估的轻量级模型RawNetLite，有效检测音频深度伪造。|
|🆕 发布|Diffusion-based Adversarial Identity Manipulation for Facial Privacy Protection|基于扩散的对抗性身份操纵用于面部隐私保护|Liqin Wang, Qianyue Hu, Wei Lu, Xiangyang Luo|<http://arxiv.org/pdf/2504.21646v1>|提出Diffusion-based Adversarial Identity Manipulatio...|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Class Uncertainty: A Measure to Mitigate Class Imbalance|类别不确定性：缓解类别不平衡的度量|Z. S. Baltaci, K. Oksuz, S. Kuzucu, K. Tezoren, B. K. Konar, A. Ozkan, E. Akbas, S. Kalkan|<http://arxiv.org/pdf/2311.14090v2>|提出“类不确定性”度量，有效缓解长尾数据集和SVCI-20数据集上的类别不平衡问题。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CMD: Constraining Multimodal Distribution for Domain Adaptation in Stereo Matching|CMD：约束多模态分布以实现立体匹配中的域适应|Zhelun Shen, Zhuo Li, Chenming Wu, Zhibo Rao, Lina Liu, Yuchao Dai, Liangjun Zhang|<http://arxiv.org/pdf/2504.21302v1>|[代码](https://github.com/gallenszl/CMD); 提出CMD方法，通过约束多模态分布提升立体匹配在域适应场景下的泛化能力。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Space Group Determination from EBSD Patterns: The Role of Deep Learning and High-throughput Dynamical Simulations|从EBSD模式到空间群确定的进展：深度学习和高通量动力学模拟的作用|Alfred Yan, Muhammad Nur Talha Kilic, Gert Nolze, Ankit Agrawal, Alok Choudhary, Roberto dos Reis, Vinayak Dravid|<http://arxiv.org/pdf/2504.21331v2>|利用深度学习和动态模拟，该论文提出了一种从EBSD模式中确定空间群的新方法，显著提高了晶体对称性预测...|
|🆕 发布|Adaptive 3D UI Placement in Mixed Reality Using Deep Reinforcement Learning|自适应混合现实中的深度强化学习3D用户界面布局|Feiyu Lu, Mengyu Chen, Hsiang Hsu, Pranav Deshpande, Cheng Yao Wang, Blair MacIntyre|<http://arxiv.org/pdf/2504.21731v1>|利用深度强化学习实现自适应混合现实3D用户界面放置，优化用户体验。|
|🆕 发布|Learning Multi-view Multi-class Anomaly Detection|多视角多类别异常检测学习|Qianzi Yu, Yang Cao, Yu Kang|<http://arxiv.org/pdf/2504.21294v1>|提出MVMCAD模型，通过多视角特征融合和异常信号增强，提升多类别异常检测性能。|
|📝 更新|Rethinking Pseudo-Label Guided Learning for Weakly Supervised Temporal Action Localization from the Perspective of Noise Correction|重新思考基于噪声校正的弱监督时序动作定位伪标签引导学习|Quan Zhang, Yuxin Qi, Xi Tang, Rui Yuan, Xi Lin, Ke Zhang, Chun Yuan|<http://arxiv.org/pdf/2501.11124v2>|提出一种两阶段噪声标签学习策略，有效提升弱监督动作定位性能。|
|🆕 发布|Multi-modal Transfer Learning for Dynamic Facial Emotion Recognition in the Wild|多模态迁移学习在野外动态面部情感识别中的应用|Ezra Engel, Lishan Li, Chris Hudy, Robert Schleusner|<http://arxiv.org/pdf/2504.21248v1>|利用多模态迁移学习提升动态面部表情识别准确率。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Adapting In-Domain Few-Shot Segmentation to New Domains without Retraining|适应域内小样本分割以适应新领域而不需重新训练|Qi Fan, Kaiqi Liu, Nian Liu, Hisham Cholakkal, Rao Muhammad Anwer, Wenbin Li, Yang Gao|<http://arxiv.org/pdf/2504.21414v1>|提出一种无需重训练的跨域小样本分割方法，通过自适应调整模型结构适应新领域。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RoboGround: Robotic Manipulation with Grounded Vision-Language Priors|机器人地面操作：基于地面视觉-语言先验的机器人操作|Haifeng Huang, Xinyi Chen, Yilun Chen, Hao Li, Xiaoshen Han, Zehan Wang, Tai Wang, Jiangmiao Pang .etc.|<http://arxiv.org/pdf/2504.21530v1>|RoboGround通过利用地面掩码作为中间表示，显著提升了机器人操作任务的泛化能力。|
|📝 更新|AgiBot World Colosseo: A Large-scale Manipulation Platform for Scalable and Intelligent Embodied Systems|AgiBot世界斗兽场：一个用于可扩展和智能具身系统的规模化操作平台|AgiBot-World-Contributors, Qingwen Bu, Jisong Cai, Li Chen, Xiuqi Cui, Yan Ding, Siyuan Feng, Shenyuan Gao .etc.|<http://arxiv.org/pdf/2503.06669v3>|构建大规模机器人数据集，提出GO-1通用策略，显著提升机器人操作性能。|


### 目标导向视觉决策 (Goal-oriented Visual Decision Making)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DOPE: Dual Object Perception-Enhancement Network for Vision-and-Language Navigation|双重目标感知增强网络：用于视觉和语言导航|Yinfeng Yu, Dongsheng Yang|<http://arxiv.org/pdf/2505.00743v1>|提出DOPE网络，通过文本语义提取和跨模态对象感知增强，提升视觉语言导航的准确性和鲁棒性。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|COMPACT: COMPositional Atomic-to-Complex Visual Capability Tuning|紧凑型：基于组成原子的复杂视觉能力调整|Xindi Wu, Hee Seung Hwang, Polina Kirichenko, Olga Russakovsky|<http://arxiv.org/pdf/2504.21850v1>|提出了一种通过控制训练数据组合复杂度来提升多模态大语言模型视觉能力的方法。|
|📝 更新|Visual Encoders for Data-Efficient Imitation Learning in Modern Video Games|视觉编码器在现代视频游戏中的数据高效模仿学习|Lukas Schäfer, Logan Jones, Anssi Kanervisto, Yuhan Cao, Tabish Rashid, Raluca Georgescu, Dave Bignell, Siddhartha Sen .etc.|<http://arxiv.org/pdf/2312.02312v2>|通过系统研究，提出使用预训练视觉编码器进行数据高效模仿学习，降低现代视频游戏决策研究成本。|
|🆕 发布|UAV-VLN: End-to-End Vision Language guided Navigation for UAVs|无人机视觉语言引导导航：端到端方法|Pranav Saxena, Nishant Raghuvanshi, Neena Goveas|<http://arxiv.org/pdf/2504.21432v1>|提出UAV-VLN，通过视觉语言导航框架实现无人机基于自然语言指令的自主导航。|
|📝 更新|FILA: Fine-Grained Vision Language Models|FILA：细粒度视觉语言模型|Shiding Zhu, Wenhui Dong, Jun Song, Yingbo Wang, Yanan Guo, Bo Zheng|<http://arxiv.org/pdf/2412.08378v3>|提出HyViLM，通过融合全局视觉特征和优化特征融合策略，有效提升多模态大语言模型处理高分辨率图像的...|
|🆕 发布|Localizing Before Answering: A Benchmark for Grounded Medical Visual Question Answering|在回答之前定位：基于地标的医学视觉问答基准|Dung Nguyen, Minh Khoi Ho, Huy Ta, Thanh Tam Nguyen, Qi Chen, Kumar Rav, Quy Duong Dang, Satwik Ramchandre .etc.|<http://arxiv.org/pdf/2505.00744v1>|提出HEAL-MedVQA基准和LobA框架，解决医疗视觉问答中模型定位和幻觉问题。|
|🆕 发布|An Evaluation of a Visual Question Answering Strategy for Zero-shot Facial Expression Recognition in Still Images|对静态图像中零样本面部表情识别的视觉问答策略评估|Modesto Castrillón-Santana, Oliverio J Santana, David Freire-Obregón, Daniel Hernández-Sosa, Javier Lorenzo-Navarro|<http://arxiv.org/pdf/2504.21309v1>|评估了结合视觉问答策略的视觉语言模型，显著提升了零样本面部表情识别性能。|
|📝 更新|VideoMultiAgents: A Multi-Agent Framework for Video Question Answering|视频多智能体框架：用于视频问答的多智能体框架|Noriyuki Kugo, Xiang Li, Zixin Li, Ashish Gupta, Arpandeep Khatua, Nidhish Jain, Chaitanya Patel, Yuta Kyuragi .etc.|<http://arxiv.org/pdf/2504.20091v2>|[代码](https://github.com/PanasonicConnect/VideoMultiAgents.); 提出VideoMultiAgents框架，通过多智能体协同处理视频问答，显著提升答案准确率。|
|🆕 发布|Zoomer: Adaptive Image Focus Optimization for Black-box MLLM|Zoomer：针对黑盒多语言语言模型的自适应图像焦点优化|Jiaxu Qian, Chendong Wang, Yifan Yang, Chaoyun Zhang, Huiqiang Jiang, Xufang Luo, Yu Kang, Qingwei Lin .etc.|<http://arxiv.org/pdf/2505.00742v1>|Zoomer通过自适应图像焦点优化，提升黑盒MLLM在视觉任务中的表现，同时减少token消耗。|
|🆕 发布|Embracing Collaboration Over Competition: Condensing Multiple Prompts for Visual In-Context Learning|拥抱合作而非竞争：多提示视觉情境学习的压缩|Jinpeng Wang, Tianci Luo, Yaohua Zha, Yan Feng, Ruisheng Luo, Bin Chen, Tao Dai, Long Chen .etc.|<http://arxiv.org/pdf/2504.21263v1>|[代码](https://github.com/gimpong/CVPR25-Condenser.); 提出了一种通过多提示协作进行视觉情境学习的压缩方法，显著提升情境压缩和计算效率。|
|📝 更新|BRIGHT-VO: Brightness-Guided Hybrid Transformer for Visual Odometry with Multi-modality Refinement Module|BRIGHT-VO：基于亮度引导的混合Transformer视觉里程计和多模态细化模块|Dongzhihan Wang, Yang Yang, Liang Xu|<http://arxiv.org/pdf/2501.08659v4>|[代码](https://github.com/Anastasiawd/BrightVO.); 提出了一种结合亮度引导和IMU数据的Transformer视觉里程计模型，显著提升了低光环境下的定位...|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Semantic Positive Pairs for Enhancing Visual Representation Learning of Instance Discrimination Methods|语义正对增强实例判别方法的可视表征学习|Mohammad Alkhalefi, Georgios Leontidis, Mingjun Zhong|<http://arxiv.org/pdf/2306.16122v3>|提出语义正对识别方法，提升实例区分方法视觉表征学习效果。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|V3LMA: Visual 3D-enhanced Language Model for Autonomous Driving|V3LMA：用于自动驾驶的视觉3D增强语言模型|Jannik Lübberstedt, Esteban Rivera, Nico Uhlemann, Markus Lienkamp|<http://arxiv.org/pdf/2505.00156v1>|V3LMA通过融合LLMs和LVLMs，增强3D场景理解，提升自动驾驶安全性能。|
|📝 更新|3D StreetUnveiler with Semantic-aware 2DGS -- a simple baseline|3D StreetUnveiler with Semantic-aware 2DGS ——一个简单的基线|Jingwei Xu, Yikai Wang, Yiqun Zhao, Yanwei Fu, Shenghua Gao|<http://arxiv.org/pdf/2405.18416v4>|提出了一种基于语义感知的2DGS方法，用于从拥挤场景中重建空旷街道的3D表示。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Survey of Interactive Generative Video|交互式生成视频综述|Jiwen Yu, Yiran Qin, Haoxuan Che, Quande Liu, Xintao Wang, Pengfei Wan, Di Zhang, Kun Gai .etc.|<http://arxiv.org/pdf/2504.21853v1>|提出交互式生成视频技术，构建跨领域应用框架，推动视频内容互动性发展。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Optical aberrations in autonomous driving: Physics-informed parameterized temperature scaling for neural network uncertainty calibration|自动驾驶中的光学像差：神经网络不确定性校准的物理信息参数化温度缩放|Dominik Werner Wolf, Alexander Braun, Markus Ulrich|<http://arxiv.org/pdf/2412.13695v2>|提出了一种结合物理先验的神经网络校准方法，有效降低自动驾驶中光学畸变导致的误差。|
|🆕 发布|REHEARSE-3D: A Multi-modal Emulated Rain Dataset for 3D Point Cloud De-raining|REHEARSE-3D：用于3D点云去雨的多模态仿真雨数据集|Abu Mohammed Raisuddin, Jesper Holmblad, Hamed Haghighi, Yuri Poledna, Maikol Funk Drechsler, Valentina Donzella, Eren Erdal Aksoy|<http://arxiv.org/pdf/2504.21699v1>|[代码](https://sporsho.github.io/REHEARSE3D.); 构建了大规模多模态模拟雨数据集REHEARSE-3D，以促进3D点云去雨研究。|
|🆕 发布|Wireless Communication as an Information Sensor for Multi-agent Cooperative Perception: A Survey|无线通信作为多智能体协同感知的信息传感器：综述|Zhiying Song, Tenghui Xie, Fuxi Wen, Jun Li|<http://arxiv.org/pdf/2505.00747v1>|将V2X通信视为信息传感器，探讨多智能体协同感知在智能交通系统中的挑战与解决方案。|
|🆕 发布|ClassWise-CRF: Category-Specific Fusion for Enhanced Semantic Segmentation of Remote Sensing Imagery|基于类别的CRF：用于增强遥感图像语义分割的类别特定融合|Qinfeng Zhu, Yunxi Jiang, Lei Fan|<http://arxiv.org/pdf/2504.21491v1>|[代码](https://github.com/zhuqinfeng1999/ClassWise-CRF.); 提出了一种基于类别特定融合的语义分割方法，显著提升了遥感图像分割性能。|
|📝 更新|PreCM: The Padding-based Rotation Equivariant Convolution Mode for Semantic Segmentation|PreCM：基于填充的旋转等变卷积模式用于语义分割|Xinyu Xu, Huazhen Liu, Tao Zhang, Huilin Xiong, Wenxian Yu|<http://arxiv.org/pdf/2411.01624v2>|提出了一种基于填充的旋转等变卷积模式（PreCM），有效提升了语义分割的旋转不变性和性能。|
|🆕 发布|Subject Information Extraction for Novelty Detection with Domain Shifts|基于领域偏移的新颖性检测中的主题信息提取|Yangyang Qu, Dazhi Fu, Jicong Fan|<http://arxiv.org/pdf/2504.21247v1>|提出一种分离主体信息的方法，有效应对训练和测试数据域差异下的新颖性检测问题。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MeDSLIP: Medical Dual-Stream Language-Image Pre-training with Pathology-Anatomy Semantic Alignment|医学病理-解剖语义对齐的双流语言-图像预训练：MeDSLIP|Wenrui Fan, Mohammod N. I. Suvon, Shuo Zhou, Xianyuan Liu, Samer Alabed, Venet Osmani, Andrew J. Swift, Chen Chen .etc.|<http://arxiv.org/pdf/2403.10635v2>|[代码](https://github.com/Shef-AIRE/MeDSLIP); 提出MeDSLIP，通过双流机制和对比学习，有效分离病理和解剖语义，提升医学视觉语言模型性能。|
|📝 更新|BEVWorld: A Multimodal World Simulator for Autonomous Driving via Scene-Level BEV Latents|BEVWorld：基于场景级BEV潜变量的自动驾驶多模态世界模拟器|Yumeng Zhang, Shi Gong, Kaixin Xiong, Xiaoqing Ye, Xiaofan Li, Xiao Tan, Fan Wang, Jizhou Huang .etc.|<http://arxiv.org/pdf/2407.05679v3>|BEVWorld通过将多模态传感器数据转化为统一的BEV潜在空间，实现了自动驾驶场景的全面建模和未来...|
|🆕 发布|Mamba Based Feature Extraction And Adaptive Multilevel Feature Fusion For 3D Tumor Segmentation From Multi-modal Medical Image|基于Mamba的特征提取和自适应多级特征融合的多模态医学图像3D肿瘤分割|Zexin Ji, Beiji Zou, Xiaoyan Kui, Hua Li, Pierre Vera, Su Ruan|<http://arxiv.org/pdf/2504.21281v1>|提出了一种结合Mamba模型和自适应多级特征融合的3D肿瘤分割方法，有效提升了多模态医学图像分割的准...|
|📝 更新|IMDPrompter: Adapting SAM to Image Manipulation Detection by Cross-View Automated Prompt Learning|IMDPrompter：通过跨视图自动提示学习将SAM应用于图像操纵检测的适应性调整|Quan Zhang, Yuxin Qi, Xi Tang, Jinwei Fang, Xi Lin, Ke Zhang, Chun Yuan|<http://arxiv.org/pdf/2502.02454v4>|开发IMDPrompter，通过跨视图自动提示学习，使SAM在图像篡改检测中无需人工提示，实现自动化...|
|📝 更新|CAD-Unet: A Capsule Network-Enhanced Unet Architecture for Accurate Segmentation of COVID-19 Lung Infections from CT Images|CAD-Unet：一种用于从CT图像中准确分割COVID-19肺部感染的胶囊网络增强U-Net架构|Yijie Dang, Weijun Ma, Xiaohu Luo, Huaizhu Wang|<http://arxiv.org/pdf/2412.06314v2>|[代码](https://github.com/AmanoTooko-jie/CAD-Unet.); 提出CAD-Unet，结合胶囊网络与Unet，有效提升COVID-19肺感染CT图像分割精度。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Differentiable Room Acoustic Rendering with Multi-View Vision Priors|可微多视图视觉先验的室内声学渲染|Derong Jin, Ruohan Gao|<http://arxiv.org/pdf/2504.21847v1>|提出了一种结合多视角视觉先验和声学射线追踪的音频-视觉可微分房间声学渲染方法，显著提升了房间声学渲染...|


### 可解释视觉智能 (Explainable Visual Intelligence)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GDI-Bench: A Benchmark for General Document Intelligence with Vision and Reasoning Decoupling|GDI-Bench：一种具有视觉与推理解耦的通用文档智能基准|Siqi Li, Yufan Shen, Xiangnan Chen, Jiayi Chen, Hengwei Ju, Haodong Duan, Song Mao, Hongbin Zhou .etc.|<http://arxiv.org/pdf/2505.00063v1>|提出GDI-Bench基准，通过视觉与推理解耦评估文档智能模型，并设计GDI模型优化性能。|
|🆕 发布|VR-FuseNet: A Fusion of Heterogeneous Fundus Data and Explainable Deep Network for Diabetic Retinopathy Classification|VR-FuseNet：一种用于糖尿病视网膜病变分类的异构眼底数据融合与可解释深度网络|Shamim Rahim Refat, Ziyan Shirin Raha, Shuvashis Sarker, Faika Fairuj Preotee, MD. Musfikur Rahman, Tashreef Muhammad, Mohammad Shafiul Islam|<http://arxiv.org/pdf/2504.21464v1>|提出VR-FuseNet混合深度学习模型，融合异构眼底数据，实现糖尿病视网膜病变的高效准确分类。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Rootlets-based registration to the spinal cord PAM50 template|基于根丝的脊髓PAM50模板配准|Sandrine Bédard, Jan Valošek, Valeria Oliva, Kenneth A. Weber II, Julien Cohen-Adad|<http://arxiv.org/pdf/2505.00115v1>|提出了一种基于脊髓神经根的注册方法，提高了脊髓神经影像组分析的精度和可靠性。|

