## [UPDATED!] **2025-05-02** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GENMO: A GENeralist Model for Human MOtion|通用人类运动模型：GENMO|Jiefeng Li, Jinkun Cao, Haotian Zhang, Davis Rempe, Jan Kautz, Umar Iqbal, Ye Yuan|<http://arxiv.org/pdf/2505.01425v1>|提出GENMO模型，统一处理人体运动估计和生成，实现多样运动生成与精确运动估计。|
|🆕 发布|Multimodal Doctor-in-the-Loop: A Clinically-Guided Explainable Framework for Predicting Pathological Response in Non-Small Cell Lung Cancer|多模态闭环医生：一种临床指导的可解释框架，用于预测非小细胞肺癌的病理反应|Alice Natalina Caragliano, Claudia Tacconi, Carlo Greco, Lorenzo Nibid, Edy Ippolito, Michele Fiore, Giuseppe Perrone, Sara Ramella .etc.|<http://arxiv.org/pdf/2505.01390v1>|提出融合多模态数据和临床知识，指导模型从整体到局部预测肺癌病理反应的框架。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Insight-V: Exploring Long-Chain Visual Reasoning with Multimodal Large Language Models|Insight-V：利用多模态大型语言模型探索长链视觉推理|Yuhao Dong, Zuyan Liu, Hai-Long Sun, Jingkang Yang, Winston Hu, Yongming Rao, Ziwei Liu|<http://arxiv.org/pdf/2411.14432v2>|提出了一种生成长链视觉推理数据的多模态大语言模型训练方法，显著提升了视觉推理能力。|
|🆕 发布|Can Foundation Models Really Segment Tumors? A Benchmarking Odyssey in Lung CT Imaging|《基础模型真的能分割肿瘤吗？肺CT影像中的基准之旅》|Elena Mulero Ayllón, Massimiliano Mantegna, Linlin Shen, Paolo Soda, Valerio Guarrasi, Matteo Tortora|<http://arxiv.org/pdf/2505.01239v1>|该研究评估了基础模型在肺肿瘤分割中的性能，发现MedSAM~2模型在准确性和效率上优于传统模型。|
|🆕 发布|Any-to-Any Vision-Language Model for Multimodal X-ray Imaging and Radiological Report Generation|任意到任意视觉-语言模型在多模态X射线成像和放射报告生成中的应用|Daniele Molino, Francesco di Feola, Linlin Shen, Paolo Soda, Valerio Guarrasi|<http://arxiv.org/pdf/2505.01091v1>|提出了一种针对医学领域多模态数据生成的视觉-语言模型，有效提升了X光影像和报告生成的准确性。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Evaluating Vision Language Model Adaptations for Radiology Report Generation in Low-Resource Languages|评估低资源语言放射学报告生成中视觉语言模型适应性|Marco Salmè, Rosa Sicilia, Paolo Soda, Valerio Guarrasi|<http://arxiv.org/pdf/2505.01096v1>|评估了针对低资源语言放射学报告生成的视觉语言模型适应性，提出语言和领域特定训练可显著提升报告质量。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RoboPEPP: Vision-Based Robot Pose and Joint Angle Estimation through Embedding Predictive Pre-Training|RoboPEPP：通过嵌入预测预训练进行基于视觉的机器人姿态和关节角估计|Raktim Gautam Goswami, Prashanth Krishnamurthy, Yann LeCun, Farshad Khorrami|<http://arxiv.org/pdf/2411.17662v2>|RoboPEPP通过融合机器人物理模型信息，显著提升了基于视觉的机器人姿态和关节角估计的准确性和鲁棒...|
|📝 更新|Soybean Disease Detection via Interpretable Hybrid CNN-GNN: Integrating MobileNetV2 and GraphSAGE with Cross-Modal Attention|大豆病害检测通过可解释的混合CNN-GNN：结合MobileNetV2和GraphSAGE的跨模态注意力|Md Abrar Jahin, Soudeep Shahriar, M. F. Mridha, Md. Jakir Hossen, Nilanjan Dey|<http://arxiv.org/pdf/2503.01284v3>|提出了一种结合CNN和GNN的豆叶病害检测方法，通过跨模态注意力提高了准确性和可解释性。|
|🆕 发布|T-Graph: Enhancing Sparse-view Camera Pose Estimation by Pairwise Translation Graph|T-Graph：通过成对平移图增强稀疏视图相机位姿估计|Qingyu Xian, Weiqin Jiao, Hao Cheng, Berend Jan van der Zwaag, Yanqiu Huang|<http://arxiv.org/pdf/2505.01207v1>|T-Graph通过构建翻译图和引入两种翻译表示，有效提升了稀疏视图下的相机位姿估计精度。|
|📝 更新|$X^2$-DFD: A framework for eXplainable and eXtendable Deepfake Detection|X^2-DFD：一种可解释和可扩展的深度伪造检测框架|Yize Chen, Zhiyuan Yan, Siwei Lyu, Baoyuan Wu|<http://arxiv.org/pdf/2410.06126v3>|提出了一种基于多模态语言模型和特征分析的深度伪造检测框架，显著提升了检测和解释性能。|
|📝 更新|InterLoc: LiDAR-based Intersection Localization using Road Segmentation with Automated Evaluation Method|InterLoc：基于激光雷达的交叉口定位，采用道路分割与自动化评估方法|Nguyen Hoang Khoi Tran, Julie Stephany Berrio, Mao Shan, Zhenxing Ming, Stewart Worrall|<http://arxiv.org/pdf/2505.00512v2>|提出了一种基于LiDAR和语义分割的在线车辆中心交点定位方法，显著提升了定位精度和鲁棒性。|
|🆕 发布|Edge Detection based on Channel Attention and Inter-region Independence Test|基于通道注意力和跨区域独立性测试的边缘检测|Ru-yu Yan, Da-Qing Zhang|<http://arxiv.org/pdf/2505.01040v1>|提出了一种结合通道注意力和区域独立性测试的边缘检测新框架，显著提升了边缘检测的准确性和鲁棒性。|
|🆕 发布|3D Human Pose Estimation via Spatial Graph Order Attention and Temporal Body Aware Transformer|基于空间图序注意力和时序身体感知变换的三维人体姿态估计|Kamel Aouaidjia, Aofan Li, Wenhao Zhang, Chongsheng Zhang|<http://arxiv.org/pdf/2505.01003v1>|提出一种结合图卷积和Transformer的3D人体姿态估计方法，通过空间图序注意力和时间身体感知T...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Project-and-Fuse: Improving RGB-D Semantic Segmentation via Graph Convolution Networks|项目融合：通过图卷积网络提升RGB-D语义分割|Xiaoyan Jiang, Bohan Wang, Xinlong Wan, Shanshan Chen, Hamido Fujita, Hanan Abd. Al Juaid|<http://arxiv.org/pdf/2501.18851v3>|提出Project-and-Fuse方法，通过后期融合和图卷积网络优化RGB-D语义分割，有效提升分...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Core-Set Selection for Data-efficient Land Cover Segmentation|核心集选择以提高土地覆盖分类数据效率|Keiller Nogueira, Akram Zaytar, Wanli Ma, Ribana Roscher, Ronny Hänsch, Caleb Robinson, Anthony Ortiz, Simone Nsutezo .etc.|<http://arxiv.org/pdf/2505.01225v1>|[代码](https://github.com/keillernogueira/data-centric-rs-classification); 提出核心集选择方法，提升遥感图像分割数据效率。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RD-UIE: Relation-Driven State Space Modeling for Underwater Image Enhancement|RD-UIE：基于关系驱动的水下图像增强状态空间建模|Kui Jiang, Yan Luo, Junjun Jiang, Xin Xu, Fei Ma, Fei Yu|<http://arxiv.org/pdf/2505.01224v1>|[代码](https://github.com/kkoucy/RD-UIE); RD-UIE通过关系驱动和自适应状态空间建模，有效提升了水下图像增强效果。|
|🆕 发布|Fine-Tuning Without Forgetting: Adaptation of YOLOv8 Preserves COCO Performance|无遗忘微调：YOLOv8的适应保持COCO性能|Vishal Gandhi, Sagar Gandhi|<http://arxiv.org/pdf/2505.01016v1>|提出了一种深度微调YOLOv8模型的方法，在保持COCO性能的同时显著提升了细粒度水果检测任务的准确...|
|🆕 发布|CDFormer: Cross-Domain Few-Shot Object Detection Transformer Against Feature Confusion|CDFormer：对抗特征混淆的跨域小样本目标检测Transformer|Boyuan Meng, Xiaohan Zhang, Peilin Li, Zhe Wu, Yiming Li, Wenkai Zhao, Beinan Yu, Hui-Liang Shen|<http://arxiv.org/pdf/2505.00938v1>|CDFormer通过OBD和OOD模块解决跨域小样本目标检测中的特征混淆问题，显著提升检测准确率。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VIDSTAMP: A Temporally-Aware Watermark for Ownership and Integrity in Video Diffusion Models|VIDSTAMP：视频扩散模型中的时间感知所有权和完整性水印|Mohammadreza Teymoorianfard, Shiqing Ma, Amir Houmansadr|<http://arxiv.org/pdf/2505.01406v1>|[代码](https://github.com/SPIN-UMass/VidStamp); 提出VIDSTAMP，一种嵌入视频扩散模型中，兼具高容量和低视觉影响的视频水印方法。|
|📝 更新|HarmoniCa: Harmonizing Training and Inference for Better Feature Caching in Diffusion Transformer Acceleration|HarmoniCa：在扩散Transformer加速中实现更好的特征缓存，实现训练与推理的和谐统一|Yushi Huang, Zining Wang, Ruihao Gong, Jing Liu, Xinjie Zhang, Jinyang Guo, Xianglong Liu, Jun Zhang|<http://arxiv.org/pdf/2410.01723v4>|[代码](https://github.com/ModelTC/HarmoniCa.); HarmoniCa通过优化特征缓存和平衡训练与推理，显著提升了扩散Transformer的加速性能。|
|🆕 发布|VSC: Visual Search Compositional Text-to-Image Diffusion Model|视觉搜索组合文本到图像扩散模型|Do Huu Dat, Nam Hyeonu, Po-Yuan Mao, Tae-Hyun Oh|<http://arxiv.org/pdf/2505.01104v1>|提出了一种利用成对图像嵌入和分割定位训练的文本到图像扩散模型，有效提升了多属性绑定准确性。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FreeInsert: Disentangled Text-Guided Object Insertion in 3D Gaussian Scene without Spatial Priors|FreeInsert：无空间先验的3D高斯场景中解耦的文本引导对象插入|Chenxi Li, Weijie Wang, Qiang Li, Bruno Lepri, Nicu Sebe, Weizhi Nie|<http://arxiv.org/pdf/2505.01322v1>|提出FreeInsert，一种无需空间先验的3D场景文本引导对象插入方法，实现灵活且自然的场景编辑。|
|🆕 发布|GeloVec: Higher Dimensional Geometric Smoothing for Coherent Visual Feature Extraction in Image Segmentation|GeloVec：图像分割中用于一致视觉特征提取的高维几何平滑|Boris Kriuk, Matey Yordanov|<http://arxiv.org/pdf/2505.01057v1>|GeloVec通过高维几何平滑和自适应采样权重，有效提升了图像分割的准确性和稳定性。|
|🆕 发布|Edge-preserving Image Denoising via Multi-scale Adaptive Statistical Independence Testing|基于多尺度自适应统计独立性测试的边缘保持图像去噪|Ruyu Yan, Da-Qing Zhang|<http://arxiv.org/pdf/2505.01032v1>|提出了一种基于多尺度自适应统计独立性测试的边缘检测与去噪方法，有效提升了图像清晰度和去噪效果。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MASH: Masked Anchored SpHerical Distances for 3D Shape Representation and Generation|MASH：用于3D形状表示和生成的掩码锚定球面距离|Changhao Li, Yu Xin, Xiaowei Zhou, Ariel Shamir, Hao Zhang, Ligang Liu, Ruizhen Hu|<http://arxiv.org/pdf/2504.09149v3>|MASH通过多视角和参数化表示3D形状，实现表面重建、形状生成等应用，提升性能。|
|🆕 发布|TSTMotion: Training-free Scene-awarenText-to-motion Generation|TSTMotion：无需训练的场景感知文本到动作生成|Ziyan Guo, Haoxuan Qu, Hossein Rahmani, Dewen Soh, Ping Hu, Qiuhong Ke, Jun Liu|<http://arxiv.org/pdf/2505.01182v1>|提出了一种无需训练的基于场景感知的文本到动作生成框架，有效提升了预训练动作生成器的场景适应性。|
|🆕 发布|Improving Editability in Image Generation with Layer-wise Memory|基于层状记忆的图像生成可编辑性提升|Daneul Kim, Jaeah Lee, Jaesik Park|<http://arxiv.org/pdf/2505.01079v1>|通过层状记忆和背景一致性引导，该论文提出了一种改进图像生成编辑性的方法，支持多步骤编辑并保持内容一致...|
|🆕 发布|Deterministic-to-Stochastic Diverse Latent Feature Mapping for Human Motion Synthesis|确定性到随机性多样化潜在特征映射的人体运动合成|Yu Hua, Weiming Liu, Gui Xu, Yaqing Hou, Yew-Soon Ong, Qiang Zhang|<http://arxiv.org/pdf/2505.00998v1>|提出DSDFM方法，通过确定性到随机性映射，提高人类动作合成的多样性和准确性。|
|📝 更新|GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image Generation|GPT-ImgEval：用于诊断图像生成中GPT4o的综合基准|Zhiyuan Yan, Junyan Ye, Weijia Li, Zilong Huang, Shenghai Yuan, Xiangyang He, Kaiqing Lin, Jun He .etc.|<http://arxiv.org/pdf/2504.02782v3>|[代码](https://github.com/PicoTrex/GPT-ImgEval.); 构建了GPT-ImgEval基准，全面评估GPT-4o在图像生成和编辑中的性能，并提出了解构模型和安...|
|📝 更新|Visual-Friendly Concept Protection via Selective Adversarial Perturbations|通过选择性对抗扰动实现视觉友好的概念保护|Xiaoyue Mi, Fan Tang, Juan Cao, Peng Li, Yang Liu|<http://arxiv.org/pdf/2408.08518v2>|提出VCPro框架，通过低可见性对抗扰动优先保护图像关键概念。|
|🆕 发布|Generating Animated Layouts as Structured Text Representations|生成作为结构化文本表示的动画布局|Yeonsang Shin, Jihwan Kim, Yumin Song, Kyungseung Lee, Hyunhee Chung, Taeyoung Na|<http://arxiv.org/pdf/2505.00975v1>|[代码](https://yeonsangshin.github.io/projects); 提出了一种通过结构化文本表示生成动画布局的方法，显著提升了视频广告生成效果。|
|📝 更新|Visual Concept-driven Image Generation with Text-to-Image Diffusion Model|基于视觉概念的文本到图像扩散模型驱动的图像生成|Tanzila Rahman, Shweta Mahajan, Hsin-Ying Lee, Jian Ren, Sergey Tulyakov, Leonid Sigal|<http://arxiv.org/pdf/2402.11487v3>|提出了一种概念驱动的文本到图像扩散模型，有效生成包含多个交互概念的个性化图像。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|P-Hologen: An End-to-End Generative Framework for Phase-Only Holograms|P-Hologen：一种端到端生成仅相位全息图的框架|JooHyun Park, YuJin Jeon, HuiYong Kim, SeungHwan Baek, HyeongYeop Kang|<http://arxiv.org/pdf/2404.01330v2>|[代码](https://github.com/james0223/P-Hologen.); P-Hologen提出了一种端到端生成框架，有效解决了相位全息图生成中的复杂性和效率问题。|
|📝 更新|Empowering Agentic Video Analytics Systems with Video Language Models|赋予视频语言模型能力的代理视频分析系统|Yuxuan Yan, Shiqi Jiang, Ting Cao, Yifan Yang, Qianqian Yang, Yuanchao Shu, Yuqing Yang, Lili Qiu|<http://arxiv.org/pdf/2505.00254v2>|提出AVAS系统，通过构建事件知识图谱和智能检索生成机制，实现超长视频的开放式视频分析。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Fusing Foveal Fixations Using Linear Retinal Transformations and Bayesian Experimental Design|融合视觉注视点：基于线性视网膜变换和贝叶斯实验设计的融合方法|Christopher K. I. Williams|<http://arxiv.org/pdf/2505.01249v1>|利用线性视网膜变换和贝叶斯实验设计融合注视点，实现场景整体感知。|
|📝 更新|UDGS-SLAM : UniDepth Assisted Gaussian Splatting for Monocular SLAM|UDGS-SLAM：单目SLAM中的基于UniDepth辅助高斯融合|Mostafa Mansour, Ahmed Abdelsalam, Ari Happonen, Jari Porras, Esa Rahtu|<http://arxiv.org/pdf/2409.00362v2>|UDGS-SLAM通过结合UniDepth网络和统计滤波，实现了无需RGB-D传感器的单目SLAM深...|
|🆕 发布|LMDepth: Lightweight Mamba-based Monocular Depth Estimation for Real-World Deployment|LMDepth：基于轻量级Mamba的单目深度估计，适用于现实世界部署|Jiahuan Long, Xin Zhou|<http://arxiv.org/pdf/2505.00980v1>|提出LMDepth，一种轻量级Mamba架构，实现高精度单目深度估计，兼顾性能与效率。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment|CAV-MAE Sync：通过细粒度对齐提升对比音频-视觉掩码自编码器|Edson Araujo, Andrew Rouditchenko, Yuan Gong, Saurabhchand Bhati, Samuel Thomas, Brian Kingsbury, Leonid Karlinsky, Rogerio Feris .etc.|<http://arxiv.org/pdf/2505.01237v1>|提出CAV-MAE Sync，通过细粒度对齐和分离优化目标，提升音频-视觉掩码自编码器的性能。|
|🆕 发布|NeuroLoc: Encoding Navigation Cells for 6-DOF Camera Localization|神经定位：编码用于6自由度相机定位的导航细胞|Xun Li, Jian Yang, Fenli Jia, Muyu Wang, Qi Wu, Jun Wu, Jinpeng Mi, Jilin Hu .etc.|<http://arxiv.org/pdf/2505.01113v1>|NeuroLoc通过模拟生物导航机制，提出了一种基于单图像的相机定位方法，有效提升了复杂环境中的定位...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MoBGS: Motion Deblurring Dynamic 3D Gaussian Splatting for Blurry Monocular Video|MoBGS：运动去模糊动态3D高斯分层渲染用于模糊单目视频|Minh-Quan Viet Bui, Jongmin Park, Juan Luis Gonzalez Bello, Jaeho Moon, Jihyong Oh, Munchurl Kim|<http://arxiv.org/pdf/2504.15122v3>|MoBGS通过引入BLCE和LCEE方法，有效解决了动态模糊视频的清晰化问题，实现了动态场景的高质量...|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CAMELTrack: Context-Aware Multi-cue ExpLoitation for Online Multi-Object Tracking|骆驼追踪：上下文感知的多线索利用在线多目标跟踪|Vladimir Somers, Baptiste Standaert, Victor Joos, Alexandre Alahi, Christophe De Vleeschouwer|<http://arxiv.org/pdf/2505.01257v1>|[代码](https://github.com/TrackingLaboratory/CAMELTrack.); CAMELTrack通过学习数据中的关联策略，实现了在线多目标跟踪的突破性进展。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Neural Architecture Search Method using Auxiliary Evaluation Metric based on ResNet Architecture|基于ResNet架构的辅助评估指标神经架构搜索方法|Shang Wang, Huanrong Tang, Jianquan Ouyang|<http://arxiv.org/pdf/2505.01313v1>|提出基于ResNet的辅助评估指标，优化搜索空间，提升神经网络架构在MNIST、Fashion-MN...|
|📝 更新|MAVEN: Multi-modal Attention for Valence-Arousal Emotion Network|多模态注意力情感价值-唤醒网络|Vrushank Ahire, Kunal Shah, Mudasir Nazir Khan, Nikhil Pakhale, Lownish Rai Sookha, M. A. Ganaie, Abhinav Dhall|<http://arxiv.org/pdf/2503.12623v2>|[代码](https://github.com/Vrushank-Ahire/MAVEN_8th_ABAW); MAVEN通过多模态注意力机制，有效融合视觉、音频和文本信息，提升了动态情绪识别的准确性。|
|📝 更新|A Physics-Inspired Deep Learning Framework with Polar Coordinate Attention for Ptychographic Imaging|基于极坐标注意力的物理灵感深度学习框架在相干层析成像中的应用|Han Yue, Jun Cheng, Yu-Xuan Ren, Chien-Chun Chen, Grant A. van Riessen, Philip Heng Wai Leong, Steve Feng Shu|<http://arxiv.org/pdf/2412.06806v2>|提出一种结合极坐标注意力的物理启发深度学习框架，有效解决ptychographic成像中的相位恢复问...|
|🆕 发布|Optimizing Indoor Farm Monitoring Efficiency Using UAV: Yield Estimation in a GNSS-Denied Cherry Tomato Greenhouse|利用无人机优化室内农场监测效率：在无GNSS信号樱桃番茄温室中的产量估算|Taewook Park, Jinwoo Lee, Hyondong Oh, Won-Jae Yun, Kyu-Wha Lee|<http://arxiv.org/pdf/2505.00995v1>|检测室内樱桃番茄温室产量，开发轻量级无人机结合激光雷达和IMU实现精准导航与三维多目标跟踪。|
|🆕 发布|Towards the Resistance of Neural Network Watermarking to Fine-tuning|迈向对抗神经网络水印微调的抵抗|Ling Tang, Yuefeng Chen, Hui Xue, Quanshi Zhang|<http://arxiv.org/pdf/2505.01007v1>|提出了一种鲁棒于微调的神经网络水印方法，通过修改傅里叶变换提取卷积滤波器特定频率成分进行信息嵌入。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|High Dynamic Range Novel View Synthesis with Single Exposure|高动态范围单曝光新型视图合成|Kaixuan Zhang, Hu Wang, Minxian Li, Mingwu Ren, Mao Ye, Xiatian Zhu|<http://arxiv.org/pdf/2505.01212v1>|首次提出仅使用单曝光图像进行高动态范围新型视图合成的解决方案，显著提升性能。|
|🆕 发布|Efficient Vision-based Vehicle Speed Estimation|高效基于视觉的车辆速度估计|Andrej Macko, Lukáš Gajdošech, Viktor Kocur|<http://arxiv.org/pdf/2505.01203v1>|提出了一种高效车辆速度估计方法，显著提升实时性能并保持高精度。|
|📝 更新|DriveGPT: Scaling Autoregressive Behavior Models for Driving|驱动GPT：扩展自回归行为模型以用于驾驶|Xin Huang, Eric M. Wolff, Paul Vernaza, Tung Phan-Minh, Hongge Chen, David S. Hayden, Mark Edmonds, Brian Pierce .etc.|<http://arxiv.org/pdf/2412.14415v3>|DriveGPT通过扩展模型和数据规模，实现了可扩展的自动驾驶行为模型。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|On-demand Test-time Adaptation for Edge Devices|按需边缘设备测试时自适应|Xiao Ma, Young D. Kwon, Dong Ma|<http://arxiv.org/pdf/2505.00986v1>|提出了一种按需测试时自适应框架，显著降低边缘设备上的计算和能耗，提高模型适应性。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Diffusion-based Adversarial Purification from the Perspective of the Frequency Domain|基于频域的扩散对抗净化|Gaozheng Pei, Ke Ma, Yingfei Sun, Qianqian Xu, Qingming Huang|<http://arxiv.org/pdf/2505.01267v1>|从频域角度提出了一种基于扩散的对抗净化方法，有效消除对抗扰动并最大程度保留图像内容与结构。|
|🆕 发布|Transferable Adversarial Attacks on Black-Box Vision-Language Models|可迁移的黑盒视觉-语言模型对抗攻击|Kai Hu, Weichen Yu, Li Zhang, Alexander Robey, Andy Zou, Chengming Xu, Haoqi Hu, Matt Fredrikson|<http://arxiv.org/pdf/2505.01050v1>|揭示了视觉语言模型易受黑盒攻击，并提出通用扰动方法以提升其安全性。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VitalVideos-Europe: A dataset of face videos with PPG and blood pressure ground truths|VitalVideos-Europe：包含PPG和血压真实值的面部视频数据集|Pieter-Jan Toye|<http://arxiv.org/pdf/2306.11891v3>|构建包含PPG和血压真实值的欧洲人脸视频数据集，助力远程生命体征测量研究。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|An Automated Pipeline for Few-Shot Bird Call Classification: A Case Study with the Tooth-Billed Pigeon|自动化的少量样本鸟类鸣叫分类流程：以啄木鸟为例|Abhishek Jana, Moeumu Uili, James Atherton, Mark O'Brien, Joe Wood, Leandra Brickson|<http://arxiv.org/pdf/2504.16276v2>|开发了一种针对稀有鸟类叫声的自动化分类流程，有效利用少量数据识别濒危物种。|
|📝 更新|You KAN Do It in a Single Shot: Plug-and-Play Methods with Single-Instance Priors|一次完成：具有单实例先验的即插即用方法|Yanqi Cheng, Carola-Bibiane Schönlieb, Angelica I Aviles-Rivero|<http://arxiv.org/pdf/2412.06204v2>|引入KAN-PnP框架，利用KANs作为单实例先验的降噪器，实现单次学习中的高效去噪。|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Monitoring morphometric drift in lifelong learning segmentation of the spinal cord|监测脊髓终身学习分割中的形态学漂移|Enamundram Naga Karthik, Sandrine Bédard, Jan Valošek, Christoph S. Aigner, Elise Bannier, Josef Bednařík, Virginie Callot, Anna Combes .etc.|<http://arxiv.org/pdf/2505.01364v1>|提出了一种监测脊髓分割模型形态学漂移的终身学习框架，提高了分割准确性和数据库更新效率。|
|🆕 发布|FlowDubber: Movie Dubbing with LLM-based Semantic-aware Learning and Flow Matching based Voice Enhancing|FlowDubber：基于LLM语义感知学习和基于流匹配的语音增强的电影配音|Gaoxiang Cong, Liang Li, Jiadong Pan, Zhedong Zhang, Amin Beheshti, Anton van den Hengel, Yuankai Qi, Qingming Huang|<http://arxiv.org/pdf/2505.01263v1>|[代码](https://galaxycong.github.io/LLM-Flow-Dubber); FlowDubber通过结合语义感知学习和基于流的语音增强，实现了高质量的电影配音，同时优化了唇同步...|
|🆕 发布|Self-Supervision Enhances Instance-based Multiple Instance Learning Methods in Digital Pathology: A Benchmark Study|自我监督增强数字病理学中基于实例的多实例学习方法：一项基准研究|Ali Mammadov, Loic Le Folgoc, Julien Adam, Anne Buronfosse, Gilles Hayem, Guillaume Hocquet, Pietro Gori|<http://arxiv.org/pdf/2505.01109v1>|通过引入自监督学习，证明了简单实例级MIL方法在数字病理图像分类中可媲美复杂嵌入级方法，并建议更多关...|
|📝 更新|Towards Space Group Determination from EBSD Patterns: The Role of Deep Learning and High-throughput Dynamical Simulations|从EBSD模式到空间群确定的进展：深度学习和高通量动力学模拟的作用|Alfred Yan, Muhammad Nur Talha Kilic, Gert Nolze, Ankit Agrawal, Alok Choudhary, Roberto dos Reis, Vinayak Dravid|<http://arxiv.org/pdf/2504.21331v2>|利用深度学习和动态模拟，该论文提出了一种从EBSD模式中确定空间群的新方法，显著提高了晶体对称性预测...|
|🆕 发布|Autonomous Embodied Agents: When Robotics Meets Deep Learning Reasoning|自主具身智能体：当机器人遇见深度学习推理|Roberto Bigazzi|<http://arxiv.org/pdf/2505.00935v1>|开发了一种结合计算机视觉、机器人和深度学习推理的智能体，以实现室内环境中的自主行为。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Task-Oriented Communications for Visual Navigation with Edge-Aerial Collaboration in Low Altitude Economy|面向任务的边缘无人机协作低空经济视觉导航通信|Zhengru Fang, Zhenghao Liu, Jingjing Wang, Senkang Hu, Yu Guo, Yiqin Deng, Yuguang Fang|<http://arxiv.org/pdf/2504.18317v3>|[代码](https://github.com/fangzr/TOC-Edge-Aerial.); 提出一种基于任务导向的通信框架，通过O-VIB编码器实现无人机在低带宽环境下的高精度定位。|
|🆕 发布|Efficient Vocabulary-Free Fine-Grained Visual Recognition in the Age of Multimodal LLMs|高效的多模态LLMs时代下的无词汇细粒度视觉识别|Hari Chandana Kuchibhotla, Sai Srinivas Kancheti, Abbavaram Gowtham Reddy, Vineeth N Balasubramanian|<http://arxiv.org/pdf/2505.01064v1>|提出NeaR方法，利用MLLM生成标签并微调CLIP模型，实现高效的无词汇细粒度视觉识别。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Global Collinearity-aware Polygonizer for Polygonal Building Mapping in Remote Sensing|全球共线性感知的多边形化器：遥感中的多边形建筑映射|Fahong Zhang, Yilei Shi, Xiao Xiang Zhu|<http://arxiv.org/pdf/2505.01385v1>|提出了一种基于全局共线性的多边形化算法，有效提升了遥感图像中建筑多边形映射的准确性。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FreePCA: Integrating Consistency Information across Long-short Frames in Training-free Long Video Generation via Principal Component Analysis|自由PCA：通过主成分分析在无监督长视频生成中整合长短帧间的连续性信息|Jiangtong Tan, Hu Yu, Jie Huang, Jie Xiao, Feng Zhao|<http://arxiv.org/pdf/2505.01172v1>|[代码](https://github.com/JosephTiTan/FreePCA.); 提出FreePCA，通过PCA解耦全局和局部信息，实现无监督长视频生成，提升一致性和质量。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Multimodal Masked Autoencoder Pre-training for 3D MRI-Based Brain Tumor Analysis with Missing Modalities|多模态掩码自编码器预训练用于基于3D MRI的脑肿瘤分析及缺失模态处理|Lucas Robinet, Ahmad Berjaoui, Elizabeth Cohen-Jonathan Moyal|<http://arxiv.org/pdf/2505.00568v2>|[代码](https://github.com/Lucas-rbnt/BM-MAE); 提出了一种针对3D MRI脑肿瘤分析的缺失模态多模态掩码自编码器预训练策略，有效解决了资源密集和临床...|
|📝 更新|A Comprehensive Survey on Machine Learning Driven Material Defect Detection|机器学习驱动的材料缺陷检测综述|Jun Bai, Di Wu, Tristan Shelley, Peter Schubel, David Twine, John Russell, Xuesen Zeng, Ji Zhang|<http://arxiv.org/pdf/2406.07880v3>|系统综述了机器学习在材料缺陷检测中的应用，分类分析了多种技术，并展望了未来研究方向。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Deciphering scrolls with tomography: A training experiment|《利用断层扫描解读卷轴：一次训练实验》|Sonia Foschiatti, Axel Kittenberger, Otmar Scherzer|<http://arxiv.org/pdf/2504.11485v2>|开发模拟古代卷轴无损扫描与虚拟恢复的教育实验，以替代传统X射线技术。|
|🆕 发布|Compensating Spatiotemporally Inconsistent Observations for Online Dynamic 3D Gaussian Splatting|补偿时空不一致观测的在线动态3D高斯分层|Youngsik Yun, Jeongmin Bae, Hyunseung Son, Seoha Kim, Hahyun Lee, Gun Bang, Youngjung Uh|<http://arxiv.org/pdf/2505.01235v1>|[代码](https://bbangsik13.github.io/OR2.); 提出了一种补偿在线动态场景重建中时空不一致性的方法，显著提升了重建质量和时间一致性。|
|📝 更新|ADAPT: An Autonomous Forklift for Construction Site Operation|自适应：适用于建筑工地操作的自主叉车|Johannes Huemer, Markus Murschitz, Matthias Schörghuber, Lukas Reisinger, Thomas Kadiofsky, Christoph Weidinger, Mario Niedermeyer, Benedikt Widy .etc.|<http://arxiv.org/pdf/2503.14331v3>|开发了一种适应复杂环境的自主叉车，有效提升建筑物流效率与安全性。|

