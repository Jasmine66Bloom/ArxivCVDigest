## [UPDATED!] **2025-05-05** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|No Other Representation Component Is Needed: Diffusion Transformers Can Provide Representation Guidance by Themselves|无需其他表示组件：扩散变换器可自行提供表示指导|Dengyang Jiang, Mengmeng Wang, Liuzhuozheng Li, Lei Zhang, Haoyu Wang, Wei Wei, Guang Dai, Yanning Zhang .etc.|<http://arxiv.org/pdf/2505.02831v1>|提出SRA方法，通过自我蒸馏实现扩散模型内部表示指导，无需外部组件。|
|🆕 发布|R1-Reward: Training Multimodal Reward Model Through Stable Reinforcement Learning|R1-奖励：通过稳定强化学习训练多模态奖励模型|Yi-Fan Zhang, Xingyu Lu, Xiao Hu, Chaoyou Fu, Bin Wen, Tianke Zhang, Changyi Liu, Kaiyu Jiang .etc.|<http://arxiv.org/pdf/2505.02835v1>|提出StableReinforce算法，通过稳定强化学习训练多模态奖励模型，显著提升多模态大语言模型...|
|📝 更新|LMME3DHF: Benchmarking and Evaluating Multimodal 3D Human Face Generation with LMMs|LMME3DHF：基于LMMs的多模态3D人脸生成基准测试与评估|Woo Yi Yang, Jiarui Wang, Sijing Wu, Huiyu Duan, Yuxin Zhu, Liu Yang, Kang Fu, Guangtao Zhai .etc.|<http://arxiv.org/pdf/2504.20466v2>|提出Gen3DHF基准和LMME3DHF模型，评估AI生成3D人脸质量与真实性。|
|🆕 发布|Advancing Generalizable Tumor Segmentation with Anomaly-Aware Open-Vocabulary Attention Maps and Frozen Foundation Diffusion Models|基于异常感知开放词汇注意力图和冻结基础扩散模型的肿瘤分割泛化能力提升|Yankai Jiang, Peng Zhang, Donglin Yang, Yuan Tian, Hai Lin, Xiaosong Wang|<http://arxiv.org/pdf/2505.02753v1>|[代码](https://github.com/Yankai96/DiffuGTS.); 提出DiffuGTS框架，利用冻结基础扩散模型和异常感知注意力图实现跨区域肿瘤分割。|
|🆕 发布|Multimodal Deep Learning for Stroke Prediction and Detection using Retinal Imaging and Clinical Data|多模态深度学习在视网膜成像和临床数据基础上进行中风预测和检测|Saeed Shurrab, Aadim Nepal, Terrence J. Lee-St. John, Nicola G. Ghazi, Bartlomiej Piechowski-Jozwiak, Farah E. Shamout|<http://arxiv.org/pdf/2505.02677v1>|提出了一种结合视网膜影像和临床数据的深度学习模型，有效预测和检测中风。|
|🆕 发布|Ming-Lite-Uni: Advancements in Unified Architecture for Natural Multimodal Interaction|标题翻译结果：  明轻统一架构：自然多模态交互的进展|Biao Gong, Cheng Zou, Dandan Zheng, Hu Yu, Jingdong Chen, Jianxin Sun, Junbo Zhao, Jun Zhou .etc.|<http://arxiv.org/pdf/2505.02471v1>|Ming-Lite-Uni提出统一架构，融合视觉与语言，实现文本生成图像和指令编辑，推动自然多模态交...|
|📝 更新|Kubrick: Multimodal Agent Collaborations for Synthetic Video Generation|库布里克：用于合成视频生成的多模态代理协作|Liu He, Yizhi Song, Hejun Huang, Pinxin Liu, Yunlong Tang, Daniel Aliaga, Xin Zhou|<http://arxiv.org/pdf/2408.10453v2>|提出了一种基于VLM代理协作的自动视频生成方法，有效解决了传统视频生成模型的物理和视觉问题。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Using Knowledge Graphs to harvest datasets for efficient CLIP model training|利用知识图谱高效采集数据集以训练CLIP模型|Simon Ging, Sebastian Walter, Jelena Bratulić, Johannes Dienert, Hannah Bast, Thomas Brox|<http://arxiv.org/pdf/2505.02746v1>|利用知识图谱优化网络搜索策略，大幅减少数据量高效训练CLIP模型。|
|🆕 发布|DeepSparse: A Foundation Model for Sparse-View CBCT Reconstruction|深度稀疏：稀疏视图CBCT重建的基础模型|Yiqun Lin, Hualiang Wang, Jixiang Chen, Jiewen Yang, Jiarong Guo, Xiaomeng Li|<http://arxiv.org/pdf/2505.02628v1>|提出DeepSparse模型，通过多尺度特征融合和预训练，实现高效稀疏视图CBCT重建。|
|📝 更新|Active Data Curation Effectively Distills Large-Scale Multimodal Models|主动数据整理有效提炼大规模多模态模型|Vishaal Udandarao, Nikhil Parthasarathy, Muhammad Ferjad Naeem, Talfan Evans, Samuel Albanie, Federico Tombari, Yongqin Xian, Alessio Tonioni .etc.|<http://arxiv.org/pdf/2411.18674v2>|通过主动数据整理，有效提升了大规模多模态模型的知识蒸馏效果，实现了高性能且推理高效的模型训练。|
|🆕 发布|Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities|统一的多模态理解和生成模型：进展、挑战与机遇|Xinjie Zhang, Jintao Guo, Shanshan Zhao, Minghao Fu, Lunhao Duan, Guo-Hua Wang, Qing-Guo Chen, Zhao Xu .etc.|<http://arxiv.org/pdf/2505.02567v1>|提出统一的多模态理解和生成模型，解决架构差异挑战，推动跨领域融合研究。|
|🆕 发布|Text to Image Generation and Editing: A Survey|文本到图像生成与编辑：综述|Pengfei Yang, Ngai-Man Cheung, Xinda Ma|<http://arxiv.org/pdf/2505.02527v1>|首次系统性地综述了文本到图像生成与编辑技术，提出了提升模型性能的独特见解和未来发展方向。|
|📝 更新|How Does Audio Influence Visual Attention in Omnidirectional Videos? Database and Model|音频如何影响全息视频中视觉注意力的数据库与模型|Yuxin Zhu, Huiyu Duan, Kaiwei Zhang, Yucheng Zhu, Xilei Zhu, Long Teng, Xiongkuo Min, Guangtao Zhai|<http://arxiv.org/pdf/2408.05411v2>|构建了音频-视觉注意力数据库和预测模型，以提升全息视频中的视觉注意力预测。|
|📝 更新|LMMs-Eval: Reality Check on the Evaluation of Large Multimodal Models|LMMs-Eval：大型多模态模型评估的现实检验|Kaichen Zhang, Bo Li, Peiyuan Zhang, Fanyi Pu, Joshua Adrian Cahyono, Kairui Hu, Shuai Liu, Yuanhan Zhang .etc.|<http://arxiv.org/pdf/2407.12772v2>|[代码](https://github.com/EvolvingLMMs-Lab/lmms-eval); 提出LMMs-Eval和LMMs-EVAL LITE，解决大模型评估难题，推动多模态模型可靠基准建设...|
|📝 更新|Impact of Noisy Supervision in Foundation Model Learning|噪声监督在基础模型学习中的影响|Hao Chen, Zihan Wang, Ran Tao, Hongxin Wei, Xing Xie, Masashi Sugiyama, Bhiksha Raj, Jindong Wang|<http://arxiv.org/pdf/2403.06869v3>|首次分析预训练数据噪声影响，提出NMTune方法提升模型泛化能力。|
|📝 更新|Seaweed-7B: Cost-Effective Training of Video Generation Foundation Model|海藻-7B：视频生成基础模型的低成本训练|Team Seawead, Ceyuan Yang, Zhijie Lin, Yang Zhao, Shanchuan Lin, Zhibei Ma, Haoyuan Guo, Hao Chen .etc.|<http://arxiv.org/pdf/2504.08685v2>|Seaweed-7B以低成本训练出与大型视频生成模型相媲美的性能。|
|📝 更新|Large Language Model with Region-guided Referring and Grounding for CT Report Generation|大型语言模型：基于区域引导的指称和定位用于CT报告生成|Zhixuan Chen, Yequan Bie, Haibo Jin, Hao Chen|<http://arxiv.org/pdf/2411.15539v2>|[代码](https://github.com/zhi-xuan-chen/Reg2RG.); 提出区域引导的CT报告生成框架，提升诊断性能并增强报告可解释性。|
|🆕 发布|TeDA: Boosting Vision-Lanuage Models for Zero-Shot 3D Object Retrieval via Testing-time Distribution Alignment|TeDA：通过测试时分布对齐提升零样本3D物体检索的视觉-语言模型|Zhichuan Wang, Yang Zhou, Jinhai Xiang, Yulong Wang, Xinwei He|<http://arxiv.org/pdf/2505.02325v1>|[代码](https://github.com/wangzhichuan123/TeDA.); 提出TeDA框架，通过测试时分布对齐提升零样本3D物体检索的视觉-语言模型性能。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unsupervised training of keypoint-agnostic descriptors for flexible retinal image registration|无监督训练关键点无关描述符以实现灵活的视网膜图像配准|David Rivas-Villar, Álvaro S. Hervella, José Rouco, Jorge Novo|<http://arxiv.org/pdf/2505.02787v1>|开发了一种无需关键点检测的描述符学习方法，实现灵活的视网膜图像注册，提高医学领域无监督学习应用。|
|🆕 发布|Dance of Fireworks: An Interactive Broadcast Gymnastics Training System Based on Pose Estimation|烟花之舞：基于姿态估计的交互式广播体操训练系统|Haotian Chen, Ziyu Liu, Xi Cheng, Chuangqi Li|<http://arxiv.org/pdf/2505.02690v1>|开发了一种基于姿态估计的互动广播体操训练系统，通过动态映射用户动作到烟花动画，有效促进久坐人群的体育...|
|🆕 发布|Grasp the Graph (GtG) 2.0: Ensemble of GNNs for High-Precision Grasp Pose Detection in Clutter|掌握图（GtG）2.0：用于杂乱环境中高精度抓取姿态检测的GNN集成|Ali Rashidi Moghadam, Sayedmohammadreza Rastegari, Mehdi Tale Masouleh, Ahmad Kalhor|<http://arxiv.org/pdf/2505.02664v1>|GtG 2.0通过集成GNN，显著提升了复杂环境中抓取姿态检测的精度。|
|🆕 发布|Detect, Classify, Act: Categorizing Industrial Anomalies with Multi-Modal Large Language Models|检测、分类、行动：利用多模态大型语言模型对工业异常进行分类|Sassan Mokhtar, Arian Mousakhan, Silvio Galesso, Jawad Tayyub, Thomas Brox|<http://arxiv.org/pdf/2505.02626v1>|提出VELM，一种基于多模态大语言模型的工业异常分类方法，有效提升了异常分类准确率。|
|📝 更新|SiMHand: Mining Similar Hands for Large-Scale 3D Hand Pose Pre-training|SiMHand：大规模3D手部姿态预训练中的相似手部挖掘|Nie Lin, Takehiko Ohkawa, Yifei Huang, Mingfang Zhang, Minjie Cai, Ming Li, Ryosuke Furuta, Yoichi Sato|<http://arxiv.org/pdf/2502.15251v3>|[代码](https://github.com/ut-vision/SiMHand.); SiMHand通过挖掘相似手部特征，实现大规模3D手部姿态预训练，显著提升姿态估计准确度。|
|🆕 发布|Finger Pose Estimation for Under-screen Fingerprint Sensor|屏幕下指纹传感器的手指姿态估计|Xiongjun Guan, Zhiyu Pan, Jianjiang Feng, Jie Zhou|<http://arxiv.org/pdf/2505.02481v1>|[代码](https://github.com/XiongjunGuan/DRACO.); 提出了一种融合双模态输入的网络，显著提升了手机屏幕指纹传感器指纹姿态估计的准确性和稳定性。|
|🆕 发布|Uncertainty-Weighted Image-Event Multimodal Fusion for Video Anomaly Detection|不确定性加权图像事件多模态融合用于视频异常检测|Sungheon Jeong, Jihong Park, Mohsen Imani|<http://arxiv.org/pdf/2505.02393v1>|[代码](https://github.com/EavnJeong/IEF-VAD.); 提出了一种基于图像事件融合的视频异常检测框架，显著提升了检测准确性和鲁棒性。|
|🆕 发布|Diagnostic Uncertainty in Pneumonia Detection using CNN MobileNetV2 and CNN from Scratch|肺炎检测中CNN MobileNetV2与从头开始构建的CNN的诊断不确定性|Kennard Norbert Sudiardjo, Islam Nur Alam, Wilson Wijaya, Lili Ayu Wulandhari|<http://arxiv.org/pdf/2505.02396v1>|提出了一种结合MobileNetV2和从头开始训练的CNN模型，以减少肺炎诊断中的不确定性。|
|🆕 发布|Quaternion Multi-focus Color Image Fusion|四元数多焦点彩色图像融合|Weihua Yang, Yicong Zhou|<http://arxiv.org/pdf/2505.02365v1>|提出了一种基于四元数的多焦点彩色图像融合框架，有效提升了融合图像的清晰度和细节。|
|🆕 发布|6D Pose Estimation on Spoons and Hands|6D勺子和手的关键点估计|Kevin Tan, Fan Yang, Yuhao Chen|<http://arxiv.org/pdf/2505.02335v1>|提出了一种基于6D姿态估计的系统，用于追踪餐具和手部动作，以监测饮食习惯和促进健康饮食。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DPNet: Dynamic Pooling Network for Tiny Object Detection|动态池化网络：用于微小目标检测的动态池化网络|Luqi Gong, Haotian Chen, Yikun Chen, Tianliang Yao, Chao Li, Shuai Zhao, Guangjie Han|<http://arxiv.org/pdf/2505.02797v1>|提出DPNet动态池化网络，有效降低小目标检测的计算成本，同时保持检测性能。|
|📝 更新|SAM2MOT: A Novel Paradigm of Multi-Object Tracking by Segmentation|SAM2MOT：基于分割的多目标跟踪新范式|Junjie Jiang, Zelin Wang, Manqi Zhao, Yin Li, DongSheng Jiang|<http://arxiv.org/pdf/2504.04519v3>|[代码](https://github.com/TripleJoy/SAM2MOT.); 提出了一种基于分割的跟踪新范式SAM2MOT，显著提升了多目标跟踪性能。|
|🆕 发布|RGBX-DiffusionDet: A Framework for Multi-Modal RGB-X Object Detection Using DiffusionDet|RGBX-DiffusionDet：基于DiffusionDet的多模态RGB-X目标检测框架|Eliraz Orfaig, Inna Stainvas, Igal Bilik|<http://arxiv.org/pdf/2505.02586v1>|RGBX-DiffusionDet通过融合异构数据与RGB图像，实现了高效的多模态目标检测。|
|📝 更新|CaRe-Ego: Contact-aware Relationship Modeling for Egocentric Interactive Hand-object Segmentation|CaRe-Ego：基于接触感知的以自我为中心的手-物体交互分割关系建模|Yuejiao Su, Yi Wang, Lap-Pui Chau|<http://arxiv.org/pdf/2407.05576v3>|[代码](https://github.com/yuggiehk/CaRe-Ego); 提出CaRe-Ego方法，通过关注手与物体接触关系，显著提升交互式手-物体分割性能。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|BrushEdit: All-In-One Image Inpainting and Editing|刷绘编辑：一站式图像修复与编辑|Yaowei Li, Yuxuan Bian, Xuan Ju, Zhaoyang Zhang, Junhao Zhuang, Ying Shan, Yuexian Zou, Qiang Xu|<http://arxiv.org/pdf/2412.10316v3>|提出BrushEdit，结合多模态大语言模型和图像修复模型，实现自主、友好、交互式的自由编辑。|
|📝 更新|MSA-UNet3+: Multi-Scale Attention UNet3+ with New Supervised Prototypical Contrastive Loss for Coronary DSA Image Segmentation|MSA-UNet3+：基于新监督原型对比损失的冠脉DSA图像分割的多尺度注意力UNet3+|Rayan Merghani Ahmed, Adnan Iltaf, Bin Li, Shoujun Zhou|<http://arxiv.org/pdf/2504.05184v2>|[代码](https://github.com/rayanmerghani/MSA-UNet3plus.); 提出MSA-UNet3+，结合多尺度注意力和对比学习，有效提升冠状动脉DSA图像分割精度。|
|📝 更新|SSTFormer: Bridging Spiking Neural Network and Memory Support Transformer for Frame-Event based Recognition|SSTFormer：通过帧事件识别桥接脉冲神经网络和记忆支持Transformer|Xiao Wang, Yao Rong, Zongzhen Wu, Lin Zhu, Bo Jiang, Jin Tang, Yonghong Tian|<http://arxiv.org/pdf/2308.04369v3>|[代码](https://github.com/Event-AHU/SSTFormer); 提出SSTFormer框架，融合RGB帧和事件流，解决事件相机识别中信息丢失和效率问题。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|An Arbitrary-Modal Fusion Network for Volumetric Cranial Nerves Tract Segmentation|任意模态融合网络用于体积颅神经束分割|Lei Xie, Huajun Zhou, Junxiong Huang, Jiahao Huang, Qingrun Zeng, Jianzhong He, Jiawei Zhang, Baohua Fan .etc.|<http://arxiv.org/pdf/2505.02385v1>|提出了一种融合任意模态数据的颅神经束分割网络，显著提升了分割精度。|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TWIST: Teleoperated Whole-Body Imitation System|TWIST：远程操控全身模仿系统|Yanjie Ze, Zixuan Chen, João Pedro Araújo, Zi-ang Cao, Xue Bin Peng, Jiajun Wu, C. Karen Liu|<http://arxiv.org/pdf/2505.02833v1>|TWIST通过模仿人类全身动作，实现了人形机器人协调的全身运动控制。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Dataset Copyright Evasion Attack against Personalized Text-to-Image Diffusion Models|面向个性化文本到图像扩散模型的版权规避攻击研究|Kuofeng Gao, Yufei Zhu, Yiming Li, Jiawang Bai, Yong Yang, Zhifeng Li, Shu-Tao Xia|<http://arxiv.org/pdf/2505.02824v1>|提出了一种针对个性化文本到图像扩散模型的版权规避攻击方法，有效绕过数据集所有权验证机制。|
|🆕 发布|Advances in Automated Fetal Brain MRI Segmentation and Biometry: Insights from the FeTA 2024 Challenge|胎儿脑MRI分割与生物测量学进展：FeTA 2024挑战赛见解|Vladyslav Zalevskyi, Thomas Sanchez, Misha Kaandorp, Margaux Roulet, Diego Fajardo-Rojas, Liu Li, Jana Hutter, Hongwei Bran Li .etc.|<http://arxiv.org/pdf/2505.02784v1>|FeTA 2024挑战赛提出了一种结合生物计量预测的胎儿脑MRI自动分割方法，提升了分割和评估的准确...|
|🆕 发布|Multi-View Learning with Context-Guided Receptance for Image Denoising|多视角学习结合上下文引导接收性用于图像去噪|Binghong Chen, Tingting Chai, Wei Jiang, Yuanrong Xu, Guanglu Zhou, Xiangqian Wu|<http://arxiv.org/pdf/2505.02705v1>|提出了一种结合多视角学习和上下文引导的图像降噪模型，有效降低噪声并提升计算效率。|
|🆕 发布|Sim2Real in endoscopy segmentation with a novel structure aware image translation|基于新型结构感知图像翻译的腔镜分割中的Sim2Real|Clara Tomasini, Luis Riazuelo, Ana C. Murillo|<http://arxiv.org/pdf/2505.02654v1>|提出了一种结构感知图像翻译模型，为内镜图像分割提供无标注数据训练方案。|
|📝 更新|Quaternion Wavelet-Conditioned Diffusion Models for Image Super-Resolution|四元数小波条件扩散模型用于图像超分辨率|Luigi Sigillo, Christian Bianchi, Aurelio Uncini, Danilo Comminiello|<http://arxiv.org/pdf/2505.00334v2>|提出了一种结合四元数小波预处理和潜在扩散模型的图像超分辨率新框架，显著提升了重建图像的感知质量和结构...|
|🆕 发布|Sharpness-Aware Minimization with Z-Score Gradient Filtering for Neural Networks|基于Z分数梯度滤波的神经网络锐度感知最小化|Juyoung Yun|<http://arxiv.org/pdf/2505.02369v1>|提出ZSharp方法，通过筛选统计显著的梯度成分，提升神经网络泛化能力。|
|📝 更新|CAD-NeRF: Learning NeRFs from Uncalibrated Few-view Images by CAD Model Retrieval|CAD-NeRF：通过CAD模型检索从未校准的少量视角图像中学习NeRF|Xin Wen, Xuening Zhu, Renjiao Yi, Zhifeng Wang, Chenyang Zhu, Kai Xu|<http://arxiv.org/pdf/2411.02979v2>|CAD-NeRF通过从CAD模型检索中学习，实现了从少量未校准图像中重建NeRF。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Scenethesis: A Language and Vision Agentic Framework for 3D Scene Generation|场景生成：一种用于3D场景生成的语言与视觉代理框架|Lu Ling, Chen-Hsuan Lin, Tsung-Yi Lin, Yifan Ding, Yu Zeng, Yichen Sheng, Yunhao Ge, Ming-Yu Liu .etc.|<http://arxiv.org/pdf/2505.02836v1>|Scenethesis通过结合语言模型和视觉引导，生成多样化、真实且物理合理的3D场景。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FolAI: Synchronized Foley Sound Generation with Semantic and Temporal Alignment|FolAI：语义和时序对齐的同步福利奥声音生成|Riccardo Fosco Gramaccioni, Christian Marinoni, Emilian Postolache, Marco Comunità, Luca Cosmo, Joshua D. Reiss, Danilo Comminiello|<http://arxiv.org/pdf/2412.15023v3>|[代码](https://ispamm.github.io/FolAI.); 提出 FolAI，一种同步生成 Foley 音效的框架，实现语义和时序对齐。|
|🆕 发布|MCCD: Multi-Agent Collaboration-based Compositional Diffusion for Complex Text-to-Image Generation|基于多智能体协作的复合扩散复杂文本到图像生成|Mingcheng Li, Xiaolu Hou, Ziyang Liu, Dingkang Yang, Ziyun Qian, Jiawei Chen, Jinjie Wei, Yue Jiang .etc.|<http://arxiv.org/pdf/2505.02648v1>|提出MCCD方法，通过多智能体协作和分层组合扩散，有效提升复杂场景文本到图像生成的准确性和保真度。|
|🆕 发布|RobSurv: Vector Quantization-Based Multi-Modal Learning for Robust Cancer Survival Prediction|RobSurv：基于矢量量化的多模态学习在鲁棒癌症生存预测中的应用|Aiman Farooq, Azad Singh, Deepak Mishra, Santanu Chaudhury|<http://arxiv.org/pdf/2505.02529v1>|RobSurv通过向量量化实现鲁棒的多模态学习，有效预测癌症生存率。|
|🆕 发布|Point Cloud Recombination: Systematic Real Data Augmentation Using Robotic Targets for LiDAR Perception Validation|点云重组：利用机器人目标进行激光雷达感知验证的系统化真实数据增强|Hubert Padusinski, Christian Steinhauser, Christian Scherl, Julian Gaal, Jacob Langner|<http://arxiv.org/pdf/2505.02476v1>|提出点云重组技术，通过结合实验室测量点云，系统性地增强真实场景点云，以验证LiDAR感知系统。|
|📝 更新|Dynamic Importance in Diffusion U-Net for Enhanced Image Synthesis|动态扩散U-Net在增强图像合成中的重要性|Xi Wang, Ziqi He, Yang Zhou|<http://arxiv.org/pdf/2504.03471v2>|[代码](https://github.com/Hytidel/UNetReweighting); 提出动态重要性重加权策略，提升扩散U-Net图像合成效果。|
|🆕 发布|Quaternion Infrared Visible Image Fusion|四元数红外可见光图像融合|Weihua Yang, Yicong Zhou|<http://arxiv.org/pdf/2505.02364v1>|提出了一种基于四元数的红外可见光图像融合框架，有效提升了低可见度条件下的图像质量。|
|📝 更新|TSTMotion: Training-free Scene-aware Text-to-motion Generation|TSTMotion：无需训练的场景感知文本到动作生成|Ziyan Guo, Haoxuan Qu, Hossein Rahmani, Dewen Soh, Ping Hu, Qiuhong Ke, Jun Liu|<http://arxiv.org/pdf/2505.01182v2>|提出了一种无需训练的基于场景感知的文本到动作生成框架，有效提升了动作生成效果。|
|📝 更新|MIGC++: Advanced Multi-Instance Generation Controller for Image Synthesis|MIGC++：用于图像合成的先进多实例生成控制器|Dewei Zhou, You Li, Fan Ma, Zongxin Yang, Yi Yang|<http://arxiv.org/pdf/2407.02329v3>|[代码](https://github.com/limuloo/MIGC.); 提出MIGC++，通过文本和图像控制属性，通过框和掩码控制位置，实现多实例图像合成。|
|📝 更新|NeurCross: A Neural Approach to Computing Cross Fields for Quad Mesh Generation|神经交叉：用于四叉网格生成的交叉场计算神经网络方法|Qiujie Dong, Huibiao Wen, Rui Xu, Shuangmin Chen, Jiaran Zhou, Shiqing Xin, Changhe Tu, Taku Komura .etc.|<http://arxiv.org/pdf/2405.13745v2>|NeurCross通过优化神经SDF和交叉场，实现了高质量四边形网格生成，同时平衡了平滑性和主曲率方...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visually-Guided Linguistic Disambiguation for Monocular Depth Scale Recovery|视觉引导的单一图像深度尺度歧义消除|Bojin Wu, Jing Chen|<http://arxiv.org/pdf/2505.02704v1>|[代码](https://github.com/pakinwu/VGLD.); 提出VGLD方法，通过结合图像语义信息和文本描述，稳定地恢复单目深度尺度，实现高精度深度预测。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Enhancing person re-identification via Uncertainty Feature Fusion Method and Auto-weighted Measure Combination|通过不确定性特征融合方法和自动加权度量组合增强行人重识别|Quang-Huy Che, Le-Chuong Nguyen, Duc-Tuan Luu, Vinh-Tiep Nguyen|<http://arxiv.org/pdf/2405.01101v5>|[代码](https://github.com/chequanghuy/Enhancing-Person-Re-Identification-via-UFFM-and-AMC); 通过不确定性特征融合和自动加权度量组合，显著提升了跨摄像头视角的人脸重识别准确率。|
|🆕 发布|Marker-Based Extrinsic Calibration Method for Accurate Multi-Camera 3D Reconstruction|基于标记的外部标定方法，以实现精确的多相机3D重建|Nahuel Garcia-D'Urso, Bernabe Sanchez-Sos, Jorge Azorin-Lopez, Andres Fuster-Guillo, Antonio Macia-Lillo, Higinio Mora-Mora|<http://arxiv.org/pdf/2505.02539v1>|提出了一种利用三维标记的迭代外参标定方法，显著提升了多相机3D重建的精度。|
|📝 更新|RGS-DR: Reflective Gaussian Surfels with Deferred Rendering for Shiny Objects|RGS-DR：用于光滑物体的反射高斯球面体与延迟渲染|Georgios Kouros, Minye Wu, Tinne Tuytelaars|<http://arxiv.org/pdf/2504.18468v3>|RGS-DR通过二维高斯球面体表示和延迟渲染技术，实现了对光滑反射物体的高质量重建和重光照。|
|📝 更新|Vision-based 3D Semantic Scene Completion via Capture Dynamic Representations|基于视觉的捕获动态表示的3D语义场景补全|Meng Wang, Fan Wu, Yunchuan Qin, Ruihui Li, Zhuo Tang, Kenli Li|<http://arxiv.org/pdf/2503.06222v2>|提出CDScene方法，通过捕捉动态表示实现鲁棒的语义场景完成。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DELTA: Dense Depth from Events and LiDAR using Transformer's Attention|DELTA：基于Transformer注意力机制的密集事件和激光雷达深度估计|Vincent Brebion, Julien Moreau, Franck Davoine|<http://arxiv.org/pdf/2505.02593v1>|DELTA通过融合事件相机和激光雷达数据，利用Transformer的注意力机制实现密集深度图估计，...|
|🆕 发布|Sparse Ellipsoidal Radial Basis Function Network for Point Cloud Surface Representation|稀疏椭圆径向基函数网络用于点云表面表示|Bobo Lian, Dandan Wang, Chenjian Wu, Minxin Chen|<http://arxiv.org/pdf/2505.02350v1>|[代码](https://github.com/lianbobo/SE-RBFNet.git.); 提出了一种使用稀疏椭圆径向基函数网络的高效点云表面表示方法，显著提升了精度和计算效率。|
|🆕 发布|VAEmo: Efficient Representation Learning for Visual-Audio Emotion with Knowledge Injection|VAEmo：基于知识注入的视觉-音频情感高效表示学习|Hao Cheng, Zhiwei Zhao, Yichao He, Zhenzhen Hu, Jia Li, Meng Wang, Richang Hong|<http://arxiv.org/pdf/2505.02331v1>|VAEmo通过两阶段框架和知识注入，有效提升了视觉-音频情感识别的准确性和泛化能力。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Context-Aware Input Orchestration for Video Inpainting|基于上下文感知的视频修复输入编排|Hoyoung Kim, Azimbek Khudoyberdiev, Seonghwan Jeong, Jihoon Ryoo|<http://arxiv.org/pdf/2411.16926v2>|提出动态调整输入帧比例，优化内存使用，提升视频修复质量。|
|🆕 发布|A Rate-Quality Model for Learned Video Coding|学习视频编码的速率-质量模型|Sang NguyenQuang, Cheng-Wei Chen, Xiem HoangVan, Wen-Hsiao Peng|<http://arxiv.org/pdf/2505.02720v1>|提出了一种基于R-Q模型的视频编码方法，准确预测比特率与质量关系，提升编码性能。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CHOSEN: Contrastive Hypothesis Selection for Multi-View Depth Refinement|多视角深度细化对比假设选择：CHOSEN|Di Qiu, Yinda Zhang, Thabo Beeler, Vladimir Tankovich, Christian Häne, Sean Fanello, Christoph Rhemann, Sergio Orts Escolano|<http://arxiv.org/pdf/2404.02225v2>|CHOSEN通过对比学习在多视图深度细化中实现高效准确，提升多视图立体匹配质量。|
|🆕 发布|Generative Sign-description Prompts with Multi-positive Contrastive Learning for Sign Language Recognition|基于多正对比学习的生成符号描述提示在手语识别中的应用|Siyu Liang, Yunan Li, Wentian Xin, Huizhou Chen, Xujie Liu, Kang Liu, Qiguang Miao|<http://arxiv.org/pdf/2505.02304v1>|提出GSP-MC方法，结合LLMs和对比学习，显著提升手语识别准确率。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Platelet enumeration in dense aggregates|血小板在密集聚集中的计数|H. Martin Gillis, Yogeshwar Shendye, Paul Hollensen, Alan Fine, Thomas Trappenberg|<http://arxiv.org/pdf/2505.02751v1>|提出了一种针对血小板识别与计数的深度学习方法，优化了卷积操作和类别设计，显著提升了识别精度。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SuperEdit: Rectifying and Facilitating Supervision for Instruction-Based Image Editing|超级编辑：基于指令的图像编辑的校正与监督促进|Ming Li, Xin Gu, Fan Chen, Xiaoying Xing, Longyin Wen, Chen Chen, Sijie Zhu|<http://arxiv.org/pdf/2505.02370v1>|提出了一种通过优化编辑指令和引入对比监督信号的方法，有效提升了基于指令的图像编辑效果。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MUSAR: Exploring Multi-Subject Customization from Single-Subject Dataset via Attention Routing|MUSAR：通过注意力路由从单样本数据集探索多主题定制|Zinan Guo, Pengze Zhang, Yanze Wu, Chong Mou, Songtao Zhao, Qian He|<http://arxiv.org/pdf/2505.02823v1>|MUSAR通过注意力路由，从单样本数据集实现多样本定制，有效解决数据限制和属性纠缠问题。|
|🆕 发布|Database-Agnostic Gait Enrollment using SetTransformers|数据库无关的步态注册使用SetTransformers|Nicoleta Basoc, Adrian Cosma, Andy Cǎtrunǎ, Emilian Rǎdoi|<http://arxiv.org/pdf/2505.02815v1>|提出了一种无需特定数据集或识别架构的开放集步态注册方法，利用SetTransformer实现灵活且准...|
|📝 更新|Geometric Knowledge-Guided Localized Global Distribution Alignment for Federated Learning|几何知识引导的联邦学习局部全局分布对齐|Yanbiao Ma, Wei Dai, Wenke Huang, Jiayi Chen|<http://arxiv.org/pdf/2503.06457v2>|[代码](https://github.com/WeiDai-David/2025CVPR_GGEUR); 提出了一种基于几何知识的局部全局分布对齐方法，有效解决联邦学习中数据异构性问题。|
|🆕 发布|Corr2Distrib: Making Ambiguous Correspondences an Ally to Predict Reliable 6D Pose Distributions|Corr2Distrib：将模糊对应关系转化为预测可靠6D姿态分布的盟友|Asma Brazi, Boris Meden, Fabrice Mayran de Chamisso, Steve Bourgeois, Vincent Lepetit|<http://arxiv.org/pdf/2505.02501v1>|Corr2Distrib通过利用模糊对应关系，从RGB图像中预测可靠的6D姿态分布，有效解决了视觉模...|
|🆕 发布|Recent Advances in Out-of-Distribution Detection with CLIP-Like Models: A Survey|近期基于CLIP模型在分布外检测方面的最新进展：综述|Chaohua Li, Enhao Zhang, Chuanxing Geng, Songcan Chen|<http://arxiv.org/pdf/2505.02448v1>|提出了一种基于CLIP的多模态OOD检测分类框架，推动跨领域集成和理论理解。|
|🆕 发布|Estimating Commonsense Scene Composition on Belief Scene Graphs|估计基于信念场景图的常识场景构图|Mario A. V. Saucedo, Vignesh Kottayam Viswanathan, Christoforos Kanellakis, George Nikolakopoulos|<http://arxiv.org/pdf/2505.02405v1>|提出了一种基于信念场景图估计未见物体空间分布的方法，以理解场景中物体间空间关系。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unsupervised Deep Learning-based Keypoint Localization Estimating Descriptor Matching Performance|基于无监督深度学习的关键点定位与描述符匹配性能估计|David Rivas-Villar, Álvaro S. Hervella, José Rouco, Jorge Novo|<http://arxiv.org/pdf/2505.02779v1>|提出了一种无需标注数据的视网膜图像配准方法，通过无监督学习实现关键点定位和描述符匹配。|
|🆕 发布|Robust Duality Learning for Unsupervised Visible-Infrared Person Re-Identfication|鲁棒对偶学习在无监督可见光-红外行人重识别中的应用|Yongxiang Li, Yuan Sun, Yang Qin, Dezhong Peng, Xi Peng, Peng Hu|<http://arxiv.org/pdf/2505.02549v1>|提出了一种鲁棒对偶学习框架，有效缓解了无监督可见光-红外行人重识别中的伪标签噪声问题。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MetaScenes: Towards Automated Replica Creation for Real-world 3D Scans|元场景：迈向现实世界3D扫描的自动复制品创建|Huangyue Yu, Baoxiong Jia, Yixin Chen, Yandan Yang, Puhao Li, Rongpeng Su, Jiaxin Li, Qing Li .etc.|<http://arxiv.org/pdf/2505.02388v1>|[代码](https://meta-scenes.github.io/.); MetaScenes通过构建大规模3D场景数据集和Scan2Sim模型，实现了3D场景的自动复刻，推...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|When Pre-trained Visual Representations Fall Short: Limitations in Visuo-Motor Robot Learning|当预训练视觉表示不足：视动机器人学习的局限性|Nikolaos Tsagkas, Andreas Sochopoulos, Duolikun Danier, Sethu Vijayakumar, Chris Xiaoxuan Lu, Oisin Mac Aodha|<http://arxiv.org/pdf/2502.03270v2>|检测预训练视觉表示在机器人学习中的局限性，并提出时间感知和选择性注意力模块以增强其泛化能力。|
|📝 更新|A Cognitive Paradigm Approach to Probe the Perception-Reasoning Interface in VLMs|认知范式探查视觉语言模型中的感知-推理接口|Mohit Vaishnav, Tanel Tammet|<http://arxiv.org/pdf/2501.13620v4>|提出认知范式评估框架，揭示视觉语言模型中感知与推理界面，提升多图像推理能力。|
|🆕 发布|Token Coordinated Prompt Attention is Needed for Visual Prompting|需要令牌协调的提示注意力进行视觉提示|Zichen Liu, Xu Zou, Gang Hua, Jiahuan Zhou|<http://arxiv.org/pdf/2505.02406v1>|[代码](https://github.com/zhoujiahuan1991/ICML2025-TCPA.); 提出Token Coordinated Prompt Attention模块，提升视觉提示的多样性和...|
|📝 更新|Localizing Before Answering: A Hallucination Evaluation Benchmark for Grounded Medical Multimodal LLMs|在回答之前定位：基于地面医疗多模态LLMs的幻觉评估基准|Dung Nguyen, Minh Khoi Ho, Huy Ta, Thanh Tam Nguyen, Qi Chen, Kumar Rav, Quy Duong Dang, Satwik Ramchandre .etc.|<http://arxiv.org/pdf/2505.00744v2>|提出HEAL-MedVQA基准，通过定位先于回答框架提升医疗多模态LLMs的幻觉鲁棒性。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AOR: Anatomical Ontology-Guided Reasoning for Medical Large Multimodal Model in Chest X-Ray Interpretation|AOR：基于解剖学本体指导的胸部X光片解读中的医学大容量多模态模型推理|Qingqiu Li, Zihang Cui, Seongsu Bae, Jilan Xu, Runtian Yuan, Yuejie Zhang, Rui Feng, Quanli Shen .etc.|<http://arxiv.org/pdf/2505.02830v1>|提出AOR框架，通过解剖学知识增强医疗大模型在胸部X光片解读中的交互性和可解释性。|
|📝 更新|landmarker: a Toolkit for Anatomical Landmark Localization in 2D/3D Images|Landmarker：用于2D/3D图像中解剖学地标定位的工具包|Jef Jonkers, Luc Duchateau, Glenn Van Wallendael, Sofie Van Hoecke|<http://arxiv.org/pdf/2501.10098v2>|开发landmarker工具包，为2D/3D医学图像中的解剖标志定位提供灵活、精确的解决方案。|
|📝 更新|FissionVAE: Federated Non-IID Image Generation with Latent Space and Decoder Decomposition|裂变变分自编码器：基于潜在空间和解码器分解的联邦非独立同分布图像生成|Chen Hu, Hanchi Ren, Jingjing Deng, Xianghua Xie, Xiaoke Ma|<http://arxiv.org/pdf/2408.17090v2>|FissionVAE通过分解潜在空间和定制解码器，有效解决了非独立同分布数据环境下的联邦图像生成问题...|
|🆕 发布|Timing Is Everything: Finding the Optimal Fusion Points in Multimodal Medical Imaging|时间就是一切：在多模态医学成像中寻找最佳融合点|Valerio Guarrasi, Klara Mogensen, Sara Tassinari, Sara Qvarlander, Paolo Soda|<http://arxiv.org/pdf/2505.02467v1>|提出了一种算法，通过逐步搜索确定最佳融合时机，优化多模态医学影像融合。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Interpretable Dynamic Graph Neural Networks for Small Occluded Object Detection and Tracking|可解释的动态图神经网络在小遮挡物体检测与跟踪中的应用|Shahriar Soudeep, Md Abrar Jahin, M. F. Mridha|<http://arxiv.org/pdf/2411.17251v8>|提出DGNN-YOLO框架，有效解决小遮挡物体检测与跟踪难题。|
|📝 更新|DAGNet: A Dual-View Attention-Guided Network for Efficient X-ray Security Inspection|DAGNet：一种用于高效X射线安检的双视图注意力引导网络|Shilong Hong, Yanzhou Zhou, Weichao Xu|<http://arxiv.org/pdf/2502.01710v4>|[代码](https://github.com/ShilongHong/DAGNet.); 提出DAGNet，通过双视图注意力引导网络提高X射线安检效率。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|3D Vision-Language Gaussian Splatting|三维视觉-语言高斯分层|Qucheng Peng, Benjamin Planche, Zhongpai Gao, Meng Zheng, Anwesa Choudhuri, Terrence Chen, Chen Chen, Ziyan Wu|<http://arxiv.org/pdf/2410.07577v2>|提出了一种3D视觉语言高斯分层模型，有效解决语义分层和过拟合问题，显著提升语义分割性能。|
|🆕 发布|Structure Causal Models and LLMs Integration in Medical Visual Question Answering|医学视觉问答中的结构因果模型与大型语言模型集成|Zibo Xu, Qiang Li, Weizhi Nie, Weijie Wang, Anan Liu|<http://arxiv.org/pdf/2505.02703v1>|提出了一种基于结构因果模型和LLM的集成方法，有效消除医学视觉问答中的跨模态偏差，显著提升问答准确率...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Application-Specific Evaluation of Vision Models: Case Studies in Ecology and Biology|面向特定应用视觉模型评估：生态学和生物学案例研究|Alex Hoi Hang Chan, Otto Brookes, Urs Waldmann, Hemal Naik, Iain D. Couzin, Majid Mirmehdi, Noël Adiko Houa, Emmanuelle Normand .etc.|<http://arxiv.org/pdf/2505.02825v1>|提出应用特定指标评估视觉模型，以生态和生物学案例研究为例，强调模型在实际应用中的性能。|


### 可解释视觉智能 (Explainable Visual Intelligence)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GRAPHITE: Graph-Based Interpretable Tissue Examination for Enhanced Explainability in Breast Cancer Histopathology|石墨烯：基于图的可解释组织检查，用于增强乳腺癌组织病理学的可解释性|Raktim Kumar Mondol, Ewan K. A. Millar, Peter H. Graham, Lois Browne, Arcot Sowmya, Erik Meijering|<http://arxiv.org/pdf/2501.04206v2>|GRAPHITE通过构建层次图和利用GAT与SAN捕获特征，提高了乳腺癌病理图像的可解释性。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ForesightNav: Learning Scene Imagination for Efficient Exploration|前瞻导航：学习场景想象以实现高效探索|Hardik Shah, Jiaxu Xing, Nico Messikommer, Boyang Sun, Marc Pollefeys, Davide Scaramuzza|<http://arxiv.org/pdf/2504.16062v3>|ForesightNav通过模拟人类想象力和推理能力，为机器人提供高效探索未知环境的新策略。|

