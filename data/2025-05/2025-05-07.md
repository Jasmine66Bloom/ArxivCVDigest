## [UPDATED!] **2025-05-07** (Update Time)


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Merging and Disentangling Views in Visual Reinforcement Learning for Robotic Manipulation|视觉强化学习中的机器人操作视图融合与解耦|Abdulaziz Almuzairee, Rohan Patil, Dwait Bhatt, Henrik I. Christensen|<http://arxiv.org/pdf/2505.04619v1>|[代码](https://aalmuzairee.github.io/mad); 提出MAD算法，通过融合与解耦视觉信息，提高机器人操作中的样本效率和部署灵活性。|
|🆕 发布|FastMap: Revisiting Dense and Scalable Structure from Motion|快速映射：重新审视密集和可扩展的运动恢复结构|Jiahao Li, Haochen Wang, Muhammad Zubair Irshad, Igor Vasiljevic, Matthew R. Walter, Vitor Campagnolo Guizilini, Greg Shakhnarovich|<http://arxiv.org/pdf/2505.04612v1>|FastMap通过优化并行化和优化步骤，实现了快速且精确的大规模场景结构从运动估计。|
|📝 更新|Vision-Language Models Create Cross-Modal Task Representations|视觉-语言模型创建跨模态任务表示|Grace Luo, Trevor Darrell, Amir Bar|<http://arxiv.org/pdf/2410.22330v2>|揭示了视觉语言模型如何通过共享任务向量实现跨模态任务处理。|
|🆕 发布|OpenVision: A Fully-Open, Cost-Effective Family of Advanced Vision Encoders for Multimodal Learning|开放视觉：一个完全开放、成本效益高的多模态学习高级视觉编码器系列|Xianhang Li, Yanqing Liu, Haoqin Tu, Hongru Zhu, Cihang Xie|<http://arxiv.org/pdf/2505.04601v1>|提出OpenVision，一个开放、高效的多模态视觉编码器系列，提升多模态学习性能。|
|🆕 发布|On Path to Multimodal Generalist: General-Level and General-Bench|迈向多模态通才：通用级别与通用基准|Hao Fei, Yuan Zhou, Juncheng Li, Xiangtai Li, Qingshan Xu, Bobo Li, Shengqiong Wu, Yaoting Wang .etc.|<http://arxiv.org/pdf/2505.04620v1>|提出通用级评估框架，评估多模态大语言模型性能，推动通用人工智能发展。|
|🆕 发布|EchoInk-R1: Exploring Audio-Visual Reasoning in Multimodal LLMs via Reinforcement Learning|EchoInk-R1：通过强化学习探索多模态LLMs中的音频-视觉推理|Zhenghao Xing, Xiaowei Hu, Chi-Wing Fu, Wenhai Wang, Jifeng Dai, Pheng-Ann Heng|<http://arxiv.org/pdf/2505.04623v1>|EchoInk-R1通过强化学习提升多模态LLMs的音频-视觉推理能力。|
|🆕 发布|Person Recognition at Altitude and Range: Fusion of Face, Body Shape and Gait|高空与距离的人脸识别：人脸、体形和步态融合|Feng Liu, Nicholas Chimitt, Lanqing Guo, Jitesh Jain, Aditya Kane, Minchul Kim, Wes Robbins, Yiyang Su .etc.|<http://arxiv.org/pdf/2505.04616v1>|提出了一种融合面部、体态和步态特征的统一系统，有效提升了高空远距离人体识别准确率。|
|🆕 发布|PrimitiveAnything: Human-Crafted 3D Primitive Assembly Generation with Auto-Regressive Transformer|原始万物：基于自回归变换器的人造3D原始部件组装生成|Jingwen Ye, Yuze He, Yanning Zhou, Yiqin Zhu, Kaiwen Xiao, Yong-Jin Liu, Wei Yang, Xiao Han|<http://arxiv.org/pdf/2505.04622v1>|提出PrimitiveAnything，通过自回归Transformer生成人类定制3D原语组装，提...|
|📝 更新|Uncertainty for SVBRDF Acquisition using Frequency Analysis|基于频率分析的SVBRDF获取的不确定性|Ruben Wiersma, Julien Philip, Miloš Hašan, Krishna Mullia, Fujun Luan, Elmar Eisemann, Valentin Deschaintre|<http://arxiv.org/pdf/2406.17774v3>|[代码](https://github.com/rubenwiersma/svbrdf_uncertainty.); 利用频率分析量化多视角SVBRDF获取的不确定性，加速分析并提高参数恢复性能。|
|📝 更新|Is What You Ask For What You Get? Investigating Concept Associations in Text-to-Image Models|你所请求的就是你所得到的吗？探究文本到图像模型中的概念关联|Salma S. Abdel Magid, Weiwei Pan, Simon Warchol, Grace Guo, Junsik Kim, Mahia Rahman, Hanspeter Pfister|<http://arxiv.org/pdf/2410.04634v3>|提出了一种基于可解释概念的框架，用于审计文本到图像模型，以评估其生成图像与提示之间的关联性。|
|🆕 发布|MonoCoP: Chain-of-Prediction for Monocular 3D Object Detection|MonoCoP：单目3D目标检测的预测链|Zhihao Zhang, Abhinav Kumar, Girish Chandar Ganesan, Xiaoming Liu|<http://arxiv.org/pdf/2505.04594v1>|MonoCoP通过链式预测策略，提高了单目3D物体检测的深度估计准确性。|
|🆕 发布|Dynamic Network Flow Optimization for Task Scheduling in PTZ Camera Surveillance Systems|动态网络流优化在PTZ摄像机监控系统中的任务调度|Mohammad Merati, David Castañón|<http://arxiv.org/pdf/2505.04596v1>|提出动态网络流优化方法，提升PTZ摄像头在动态监控环境中的调度效率。|
|🆕 发布|Componential Prompt-Knowledge Alignment for Domain Incremental Learning|成分式提示-知识对齐的领域增量学习|Kunlun Xu, Xu Zou, Gang Hua, Jiahuan Zhou|<http://arxiv.org/pdf/2505.04575v1>|[代码](https://github.com/zhoujiahuan1991/ICML2025-KA-Prompt); 提出了一种组件式提示-知识对齐方法，有效解决领域增量学习中知识冲突问题。|
|🆕 发布|TetWeave: Isosurface Extraction using On-The-Fly Delaunay Tetrahedral Grids for Gradient-Based Mesh Optimization|TetWeave：基于梯度网格优化的实时Delaunay四面体网格等值面提取|Alexandre Binninger, Ruben Wiersma, Philipp Herholz, Olga Sorkine-Hornung|<http://arxiv.org/pdf/2505.04590v1>|TetWeave通过动态构建四面体网格优化梯度网格，实现高质量自适应网格提取。|
|🆕 发布|Active Sampling for MRI-based Sequential Decision Making|基于MRI的序列决策的主动采样|Yuning Du, Jingshuai Liu, Rohan Dharmakumar, Sotirios A. Tsaftaris|<http://arxiv.org/pdf/2505.04586v1>|[代码](https://github.com/vios-s/MRI_Sequential_Active_Sampling); 提出了一种基于多目标强化学习的MRI主动采样方法，有效减少样本数量并提高诊断准确性。|
|📝 更新|Efficiency Meets Fidelity: A Novel Quantization Framework for Stable Diffusion|效率与保真度兼顾：一种用于稳定扩散的新型量化框架|Shuaiting Li, Juncan Deng, Zeyu Wang, Kedong Xu, Rongtao Deng, Hong Gu, Haibin Shen, Kejie Huang|<http://arxiv.org/pdf/2412.06661v2>|提出了一种高效且保持图像质量的量化框架，优化了Stable Diffusion模型的实时应用。|
|📝 更新|LLM2CLIP: Powerful Language Model Unlocks Richer Visual Representation|LLM2CLIP：强大的语言模型解锁更丰富的视觉表征|Weiquan Huang, Aoqi Wu, Yifan Yang, Xufang Luo, Yuqing Yang, Liang Hu, Qi Dai, Chunyu Wang .etc.|<http://arxiv.org/pdf/2411.04997v4>|LLM2CLIP通过整合LLMs，显著提升了CLIP在处理复杂图像描述上的能力。|
|📝 更新|Enhancing Virtual Try-On with Synthetic Pairs and Error-Aware Noise Scheduling|增强虚拟试穿：合成配对与错误感知噪声调度|Nannan Li, Kevin J. Shih, Bryan A. Plummer|<http://arxiv.org/pdf/2501.04666v3>|通过合成数据增强和错误感知噪声调度，提升虚拟试衣效果。|
|🆕 发布|RAFT: Robust Augmentation of FeaTures for Image Segmentation|RAFT：用于图像分割的鲁棒特征增强|Edward Humes, Xiaomin Lin, Uttej Kallakuri, Tinoosh Mohsenin|<http://arxiv.org/pdf/2505.04529v1>|提出RAFT框架，通过数据增强和特征调整，有效解决图像分割模型在真实世界部署中的Syn2Real问题...|
|🆕 发布|Registration of 3D Point Sets Using Exponential-based Similarity Matrix|基于指数相似矩阵的3D点集配准|Ashutosh Singandhupe, Sanket Lokhande, Hung Manh La|<http://arxiv.org/pdf/2505.04540v1>|[代码](https://github.com/aralab-unr/ESM_ICP); 提出了一种改进的ICP算法，通过动态调整相似性矩阵，有效解决了大旋转差异和噪声数据下的3D点云配准问...|
|🆕 发布|HunyuanCustom: A Multimodal-Driven Architecture for Customized Video Generation|HunyuanCustom：一种基于多模态驱动的个性化视频生成架构|Teng Hu, Zhentao Yu, Zhengguang Zhou, Sen Liang, Yuan Zhou, Qin Lin, Qinglin Lu|<http://arxiv.org/pdf/2505.04512v1>|提出HunyuanCustom，一种多模态驱动的视频生成框架，解决身份一致性和输入模态限制问题。|
|📝 更新|VidMuse: A Simple Video-to-Music Generation Framework with Long-Short-Term Modeling|视频至音乐生成框架：基于长短期记忆模型的一种简单方法|Zeyue Tian, Zhaoyang Liu, Ruibin Yuan, Jiahao Pan, Qifeng Liu, Xu Tan, Qifeng Chen, Wei Xue .etc.|<http://arxiv.org/pdf/2406.04321v3>|[代码](https://vidmuse.github.io/.); 提出VidMuse框架，通过长短期建模实现视频到音乐的生成，显著提升音频质量与视听一致性。|
|🆕 发布|Text2CT: Towards 3D CT Volume Generation from Free-text Descriptions Using Diffusion Model|文本到CT：基于扩散模型从自由文本描述生成3D CT体积|Pengfei Guo, Can Zhao, Dong Yang, Yufan He, Vishwesh Nath, Ziyue Xu, Pedro R. A. S. Bassi, Zongwei Zhou .etc.|<http://arxiv.org/pdf/2505.04522v1>|提出Text2CT，利用扩散模型从自由文本描述生成3D CT体积，实现医学科研与诊断的革新。|
|🆕 发布|Edge-GPU Based Face Tracking for Face Detection and Recognition Acceleration|基于边缘GPU的人脸跟踪以加速人脸检测与识别|Asma Baobaid, Mahmoud Meribout|<http://arxiv.org/pdf/2505.04524v1>|提出了一种基于NVIDIA Jetson AGX Orin的边缘GPU硬件优化方案，通过整合硬件引擎...|
|🆕 发布|DFVO: Learning Darkness-free Visible and Infrared Image Disentanglement and Fusion All at Once|DFVO：一次性学习无暗光可见光和红外图像解耦与融合|Qi Zhou, Yukai Shi, Xiaojun Yang, Xiaoyu Xian, Lunjia Liao, Ruimao Zhang, Liang Lin|<http://arxiv.org/pdf/2505.04526v1>|[代码](https://github.com/DaVin-Qi530/DFVO.); 提出DFVO网络，一次性实现可见光和红外图像解耦与融合，有效解决光照退化问题。|
|🆕 发布|Leveraging Simultaneous Usage of Edge GPU Hardware Engines for Video Face Detection and Recognition|利用边缘GPU硬件引擎同时进行视频人脸检测与识别|Asma Baobaid, Mahmoud Meribout|<http://arxiv.org/pdf/2505.04502v1>|该论文通过充分利用边缘GPU硬件引擎并发处理，显著提升了视频人脸检测与识别的效率和功耗。|
|📝 更新|Enhancing Target-unspecific Tasks through a Features Matrix|通过特征矩阵增强目标非特异性任务|Fangming Cui, Yonggang Zhang, Xuan Wang, Xinmei Tian, Jun Yu|<http://arxiv.org/pdf/2505.03414v2>|提出特征矩阵正则化方法，有效提升大视觉语言模型在非特定目标任务上的泛化能力。|
|📝 更新|XLD: A Cross-Lane Dataset for Benchmarking Novel Driving View Synthesis|XLD：用于新型驾驶视图合成的跨车道数据集|Hao Li, Chenming Wu, Ming Yuan, Yan Zhang, Chen Zhao, Chunyu Song, Haocheng Feng, Errui Ding .etc.|<http://arxiv.org/pdf/2406.18360v3>|构建了首个针对自动驾驶模拟的跨车道视图合成数据集，以评估现有方法的实际应用能力。|
|🆕 发布|Defining and Quantifying Creative Behavior in Popular Image Generators|定义和量化流行图像生成器中的创造性行为|Aditi Ramaswamy|<http://arxiv.org/pdf/2505.04497v1>|提出量化评估方法，帮助用户选择合适的AI图像生成模型。|
|🆕 发布|"I Can See Forever!": Evaluating Real-time VideoLLMs for Assisting Individuals with Visual Impairments|《我能看得更远！》：评估实时视频LLMs辅助视障人士的研究|Ziyi Zhang, Zhen Sun, Zongmin Zhang, Zifan Peng, Yuemeng Zhao, Zichun Wang, Zeren Luo, Ruiting Zuo .etc.|<http://arxiv.org/pdf/2505.04488v1>|构建基准数据集并评估实时视频LLMs辅助视障人士，提升动态环境中的感知能力。|
|📝 更新|Bayesian computation with generative diffusion models by Multilevel Monte Carlo|基于多级蒙特卡洛的生成扩散模型贝叶斯计算|Abdul-Lateef Haji-Ali, Marcelo Pereyra, Luke Shaw, Konstantinos Zygalakis|<http://arxiv.org/pdf/2409.15511v3>|提出了一种基于多级蒙特卡洛的扩散模型，显著降低了贝叶斯计算成本。|
|🆕 发布|FA-KPConv: Introducing Euclidean Symmetries to KPConv via Frame Averaging|FA-KPConv：通过帧平均引入欧几里得对称性到KPConv|Ali Alawieh, Alexandru P. Condurache|<http://arxiv.org/pdf/2505.04485v1>|通过引入帧平均，FA-KPConv使KPConv网络对点云的平移、旋转和反射具有精确的不变性和等变性...|
|📝 更新|Ming-Lite-Uni: Advancements in Unified Architecture for Natural Multimodal Interaction|明轻一统：自然多模态交互统一架构的进展|Inclusion AI, Biao Gong, Cheng Zou, Dandan Zheng, Hu Yu, Jingdong Chen, Jianxin Sun, Junbo Zhao .etc.|<http://arxiv.org/pdf/2505.02471v2>|提出 Ming-Lite-Uni，一种统一视觉与语言的开放源代码多模态框架，实现文本到图像生成和指令...|
|📝 更新|Sharpness-Aware Minimization with Z-Score Gradient Filtering for Neural Networks|基于Z分数梯度滤波的神经网络锐度感知最小化|Juyoung Yun|<http://arxiv.org/pdf/2505.02369v3>|引入ZSharp优化方法，通过Z分数梯度过滤增强神经网络泛化能力。|
|📝 更新|Question-Answering Dense Video Events|问答密集型视频事件|Hangyu Qin, Junbin Xiao, Angela Yao|<http://arxiv.org/pdf/2409.04388v4>|提出DeVi方法，有效解决长视频密集事件问答问题，显著提升MLLMs问答准确率。|
|🆕 发布|CAD-Llama: Leveraging Large Language Models for Computer-Aided Design Parametric 3D Model Generation|CAD-Llama：利用大型语言模型进行计算机辅助设计参数化3D模型生成|Jiahao Li, Weijian Ma, Xueyang Li, Yunzhong Lou, Guichun Zhou, Xiangdong Zhou|<http://arxiv.org/pdf/2505.04481v1>|利用大型语言模型生成参数化3D CAD模型，提出CAD-Llama框架，显著提升模型性能。|
|📝 更新|XrayGPT: Chest Radiographs Summarization using Medical Vision-Language Models|XrayGPT：基于医学视觉-语言模型的胸部X光片摘要|Omkar Thawakar, Abdelrahman Shaker, Sahal Shaji Mullappilly, Hisham Cholakkal, Rao Muhammad Anwer, Salman Khan, Jorma Laaksonen, Fahad Shahbaz Khan|<http://arxiv.org/pdf/2306.07971v2>|[代码](https://github.com/mbzuai-oryx/XrayGPT.); 开发了一种新型医疗视觉语言模型XrayGPT，能分析胸片并回答相关问题。|
|🆕 发布|Efficient Flow Matching using Latent Variables|高效使用潜在变量进行光流匹配|Anirban Samaddar, Yixuan Sun, Viktor Nilsson, Sandeep Madireddy|<http://arxiv.org/pdf/2505.04486v1>|提出Latent-CFM，通过预训练的深度潜在变量模型简化训练/推理策略，有效提高流匹配模型的生成质...|
|🆕 发布|Learning Real Facial Concepts for Independent Deepfake Detection|学习真实面部概念以实现独立深度伪造检测|Ming-Hui Liu, Harry Cheng, Tianyi Wang, Xin Luo, Xin-Shun Xu|<http://arxiv.org/pdf/2505.04460v1>|提出RealID方法，通过学习真实人脸概念独立检测深度伪造，显著提升检测准确率。|
|📝 更新|Deep Learning for Sea Surface Temperature Reconstruction under Cloud Occlusion|基于深度学习的云遮挡下海面温度重建|Andrea Asperti, Ali Aydogdu, Angelo Greco, Fabio Merizzi, Pietro Miraglio, Beniamino Tartufoli, Alessandro Testa, Nadia Pinardi .etc.|<http://arxiv.org/pdf/2412.03413v2>|利用U-net卷积神经网络模型，有效填充卫星图像云层遮挡区域，显著降低温度重建误差。|
|📝 更新|Illumination and Shadows in Head Rotation: experiments with Denoising Diffusion Models|头部旋转中的光照与阴影：去噪扩散模型的实验|Andrea Asperti, Gabriele Colasuonno, Antonio Guerra|<http://arxiv.org/pdf/2308.06057v2>|利用DDIM在预训练模型中计算轨迹，实现头旋转下光照变化下的图像真实感增强。|
|🆕 发布|DeCLIP: Decoupled Learning for Open-Vocabulary Dense Perception|去耦学习用于开放词汇密集感知|Junjie Wang, Bin Chen, Yulin Li, Bin Kang, Yichi Chen, Zhuotao Tian|<http://arxiv.org/pdf/2505.04410v1>|[代码](https://github.com/xiaomoguhz/DeCLIP); DeCLIP通过解耦CLIP的注意力模块，提升开放词汇密集预测任务的表现。|
|🆕 发布|Deep residual learning with product units|深度残差学习与产品单元|Ziyuan Li, Uwe Jaekel, Babette Dellen|<http://arxiv.org/pdf/2505.04397v1>|提出了一种结合乘积单元的残差网络，提升了深度卷积网络的性能和效率。|
|🆕 发布|MFSeg: Efficient Multi-frame 3D Semantic Segmentation|MFSeg：高效的多帧3D语义分割|Chengjie Huang, Krzysztof Czarnecki|<http://arxiv.org/pdf/2505.04408v1>|MFSeg通过聚合点云序列和轻量级解码器，实现高效的多帧3D语义分割。|
|📝 更新|Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities|统一的多模态理解和生成模型：进展、挑战与机遇|Xinjie Zhang, Jintao Guo, Shanshan Zhao, Minghao Fu, Lunhao Duan, Guo-Hua Wang, Qing-Guo Chen, Zhao Xu .etc.|<http://arxiv.org/pdf/2505.02567v2>|[代码](https://github.com/AIDC-AI/Awesome-Unified-Multimodal-Models); 提出统一的多模态理解和生成模型，解决独立发展带来的架构差异挑战。|
|🆕 发布|SwinLip: An Efficient Visual Speech Encoder for Lip Reading Using Swin Transformer|SwinLip：基于Swin Transformer的高效视觉语音编码器用于唇读|Young-Hu Park, Rae-Hong Park, Hyung-Min Park|<http://arxiv.org/pdf/2505.04394v1>|提出SwinLip，一种基于Swin Transformer的轻量级视觉语音编码器，有效提升唇读性能...|
|🆕 发布|Predicting Road Surface Anomalies by Visual Tracking of a Preceding Vehicle|通过前车视觉跟踪预测路面异常|Petr Jahoda, Jan Cech|<http://arxiv.org/pdf/2505.04392v1>|通过跟踪前车视觉信息，预测并实时检测道路异常，助力自动驾驶安全行驶。|
|🆕 发布|RLMiniStyler: Light-weight RL Style Agent for Arbitrary Sequential Neural Style Generation|RLMiniStyler：用于任意顺序神经风格生成的轻量级强化学习风格代理|Jing Hu, Chengming Feng, Shu Hu, Ming-Ching Chang, Xin Li, Xi Wu, Xin Wang|<http://arxiv.org/pdf/2505.04424v1>|[代码](https://github.com/fengxiaoming520/RLMiniStyler.); 提出RLMiniStyler，一种轻量级强化学习框架，实现高效且多样化的任意风格迁移。|
|🆕 发布|Geometry-Aware Texture Generation for 3D Head Modeling with Artist-driven Control|基于几何感知的纹理生成：具有艺术家驱动控制的3D头部建模|Amin Fadaeinejad, Abdallah Dib, Luiz Gustavo Hafemann, Emeline Got, Trevor Anderson, Amaury Depierre, Nikolaus F. Troje, Marcus A. Brubaker .etc.|<http://arxiv.org/pdf/2505.04387v1>|提出了一种几何感知纹理生成框架，简化了3D头部建模过程，赋予艺术家直观控制权。|
|📝 更新|mWhisper-Flamingo for Multilingual Audio-Visual Noise-Robust Speech Recognition|mWhisper-Flamingo：面向多语言音频-视觉噪声鲁棒语音识别|Andrew Rouditchenko, Samuel Thomas, Hilde Kuehne, Rogerio Feris, James Glass|<http://arxiv.org/pdf/2502.01547v3>|提出mWhisper-Flamingo，结合预训练模型，实现多语言视听噪声鲁棒语音识别。|
|🆕 发布|DATA: Multi-Disentanglement based Contrastive Learning for Open-World Semi-Supervised Deepfake Attribution|基于多解耦的开放世界半监督深度伪造归因对比学习|Ming-Hui Liu, Xiao-Qian Liu, Xin Luo, Xin-Shun Xu|<http://arxiv.org/pdf/2505.04384v1>|提出DATA框架，通过多解耦对比学习提升开放世界半监督深度伪造归因任务的泛化能力。|
|📝 更新|Advances in Automated Fetal Brain MRI Segmentation and Biometry: Insights from the FeTA 2024 Challenge|胎儿脑MRI分割与生物测量学进展：FeTA 2024挑战赛见解|Vladyslav Zalevskyi, Thomas Sanchez, Misha Kaandorp, Margaux Roulet, Diego Fajardo-Rojas, Liu Li, Jana Hutter, Hongwei Bran Li .etc.|<http://arxiv.org/pdf/2505.02784v2>|FeTA 2024挑战赛提出新方法，提高胎儿脑MRI分割和生物计量分析准确性，推动临床应用。|
|📝 更新|MultiSensor-Home: A Wide-area Multi-modal Multi-view Dataset for Action Recognition and Transformer-based Sensor Fusion|多传感器家庭：用于动作识别和基于Transformer的传感器融合的广域多模态多视角数据集|Trung Thanh Nguyen, Yasutomo Kawanishi, Vijay John, Takahiro Komamizu, Ichiro Ide|<http://arxiv.org/pdf/2504.02287v3>|[代码](https://github.com/thanhhff/MultiTSF.); 构建了MultiSensor-Home数据集，并提出MultiTSF方法，有效提升多模态多视角动作识...|
|📝 更新|End-to-end Surface Optimization for Light Control|端到端表面优化以实现光控制|Yuou Sun, Bailin Deng, Juyong Zhang|<http://arxiv.org/pdf/2408.13117v2>|提出了一种基于端到端优化和最优传输的表面设计方法，实现光控制目标分布。|
|🆕 发布|Label-efficient Single Photon Images Classification via Active Learning|基于主动学习的标签高效单光子图像分类|Zili Zhang, Ziting Wen, Yiheng Qiang, Hongzhou Dong, Wenle Dong, Xinyang Li, Xiaofan Wang, Xiaoqiang Ren|<http://arxiv.org/pdf/2505.04376v1>|提出了一种基于主动学习的单光子图像分类方法，显著降低标注成本并提高分类准确率。|
|🆕 发布|Tetrahedron-Net for Medical Image Registration|四棱锥网络在医学图像配准中的应用|Jinhai Xiang, Shuai Guo, Qianru Han, Dantong Shi, Xinwei He, Xiang Bai|<http://arxiv.org/pdf/2505.04380v1>|引入Tetrahedron-Net，通过附加解码器增强医学图像配准表现，显著提升注册精度。|
|🆕 发布|CountDiffusion: Text-to-Image Synthesis with Training-Free Counting-Guidance Diffusion|CountDiffusion：基于无监督计数引导的文本到图像合成|Yanyu Li, Pencheng Wan, Liang Han, Yaowei Wang, Liqiang Nie, Min Zhang|<http://arxiv.org/pdf/2505.04347v1>|提出CountDiffusion，无需训练即能从文本描述生成正确数量的图像。|
|🆕 发布|WDMamba: When Wavelet Degradation Prior Meets Vision Mamba for Image Dehazing|WDMamba：当小波退化先验与视觉Mamba相遇以实现图像去雾|Jie Sun, Heng Liu, Yongzhen Wang, Xiao-Ping Zhang, Mingqiang Wei|<http://arxiv.org/pdf/2505.04369v1>|[代码](https://github.com/SunJ000/WDMamba.); 提出了一种基于波分解的图像去雾新框架WDMamba，有效提升去雾效果。|
|🆕 发布|Balancing Accuracy, Calibration, and Efficiency in Active Learning with Vision Transformers Under Label Noise|在视觉Transformer下的有监督学习：在标签噪声中平衡准确率、校准和效率|Moseli Mots'oehli, Hope Mogale, Kyungim Baek|<http://arxiv.org/pdf/2505.04375v1>|研究了在标签噪声下，不同规模和配置的视觉Transformer在主动学习中的准确率、校准和效率平衡问...|
|📝 更新|EcoWeedNet: A Lightweight and Automated Weed Detection Method for Sustainable Next-Generation Agricultural Consumer Electronics|生态杂草网：一种轻量化和自动化的可持续下一代农业消费电子产品杂草检测方法|Omar H. Khater, Abdul Jabbar Siddiqui, M. Shamim Hossain, Aiman El-Maleh|<http://arxiv.org/pdf/2502.00205v2>|提出EcoWeedNet，一种轻量级且自动化的杂草检测方法，有效提升检测性能同时降低计算复杂度。|
|📝 更新|Stereo Anywhere: Robust Zero-Shot Deep Stereo Matching Even Where Either Stereo or Mono Fail|立体无处不在：即使在立体或单目失败的情况下也能实现鲁棒的零样本深度立体匹配|Luca Bartolomei, Fabio Tosi, Matteo Poggi, Stefano Mattoccia|<http://arxiv.org/pdf/2412.04472v2>|提出了一种结合几何约束和单目深度先验的零样本立体匹配框架，有效解决纹理缺失、遮挡和非朗伯表面等挑战。|
|🆕 发布|MoDE: Mixture of Diffusion Experts for Any Occluded Face Recognition|混合扩散专家模型用于任意遮挡人脸识别|Qiannan Fan, Zhuoyang Li, Jitong Li, Chenyang Cao|<http://arxiv.org/pdf/2505.04306v1>|提出MoDE混合扩散专家模型，有效识别遮挡人脸，提升现实场景下人脸识别准确率。|
|📝 更新|Weakly-supervised Audio Temporal Forgery Localization via Progressive Audio-language Co-learning Network|弱监督音频时间伪造定位通过渐进式音频-语言协同学习网络|Junyan Wu, Wenbo Xu, Wei Lu, Xiangyang Luo, Rui Yang, Shize Guo|<http://arxiv.org/pdf/2505.01880v2>|提出了一种基于渐进式音频-语言协同学习的弱监督音频篡改定位网络，显著提升了定位精度。|
|🆕 发布|Multi-turn Consistent Image Editing|多轮一致图像编辑|Zijun Zhou, Yingying Deng, Xiangyu He, Weiming Dong, Fan Tang|<http://arxiv.org/pdf/2505.04320v1>|提出多轮迭代编辑框架，通过精确图像反转和自适应注意力增强，显著提升图像编辑成功率和视觉质量。|
|📝 更新|FAST: Federated Active Learning with Foundation Models for Communication-efficient Sampling and Training|联邦主动学习：基于基础模型的高效通信采样与训练|Haoyuan Li, Mathias Funk, Jindong Wang, Aaqib Saeed|<http://arxiv.org/pdf/2504.03783v3>|提出了一种结合基础模型和两阶段采样策略的联邦主动学习方法，大幅降低通信成本并提升学习效率。|
|🆕 发布|HDiffTG: A Lightweight Hybrid Diffusion-Transformer-GCN Architecture for 3D Human Pose Estimation|HDiffTG：一种用于3D人体姿态估计的轻量级混合扩散-Transformer-GCN架构|Yajie Fu, Chaorui Huang, Junwei Li, Hui Kong, Yibin Tian, Huakang Li, Zhiyuan Zhang|<http://arxiv.org/pdf/2505.04276v1>|[代码](https://github.com/CirceJie/HDiffTG); 提出了一种融合Transformer、GCN和扩散模型的轻量级3D人体姿态估计方法，显著提升准确性和...|
|📝 更新|DA-Mamba: Domain Adaptive Hybrid Mamba-Transformer Based One-Stage Object Detection|DA-Mamba：基于域自适应混合Mamba-Transformer的单阶段目标检测|A. Enes Doruk, Hasan F. Ates|<http://arxiv.org/pdf/2502.11178v2>|DA-Mamba通过结合Mamba架构和注意力机制，实现了高效且鲁棒的跨域目标检测。|
|📝 更新|CLEAR: Cue Learning using Evolution for Accurate Recognition Applied to Sustainability Data Extraction|清晰：利用进化进行提示学习以实现准确识别，应用于可持续性数据提取|Peter J. Bentley, Soo Ling Lim, Fuyuki Ishikawa|<http://arxiv.org/pdf/2501.18504v3>|利用进化计算优化提示，显著提升LLM在可持续数据提取中的识别准确率。|
|📝 更新|Breaking Annotation Barriers: Generalized Video Quality Assessment via Ranking-based Self-Supervision|ervised Learning|Linhan Cao, Wei Sun, Kaiwei Zhang, Yicong Peng, Guangtao Zhai, Xiongkuo Min|<http://arxiv.org/pdf/2505.03631v2>|提出了一种基于自监督学习的视频质量评估方法，有效提升了模型泛化能力和性能。|
|🆕 发布|TS-Diff: Two-Stage Diffusion Model for Low-Light RAW Image Enhancement|TS-Diff：两阶段扩散模型用于低光RAW图像增强|Yi Li, Zhiyuan Zhang, Jiangnan Xia, Jianghan Cheng, Qilong Wu, Junwei Li, Yibin Tian, Hui Kong|<http://arxiv.org/pdf/2505.04281v1>|[代码](https://github.com/CircccleK/TS-Diff); 提出TS-Diff模型，通过两阶段扩散和颜色校正技术，有效提升低光RAW图像增强效果。|
|🆕 发布|Object-Shot Enhanced Grounding Network for Egocentric Video|基于Object-Shot增强的以自我为中心视频定位网络|Yisen Feng, Haoyu Zhang, Meng Liu, Weili Guan, Liqiang Nie|<http://arxiv.org/pdf/2505.04270v1>|[代码](https://github.com/Yisen-Feng/OSGNet.); 提出OSGNet，通过增强物体捕捉和利用自拍摄像头运动，显著提升自拍摄像头视频的定位准确性。|
|🆕 发布|RGB-Event Fusion with Self-Attention for Collision Prediction|基于自注意力的RGB-事件融合碰撞预测|Pietro Bonazzi, Christian Vogt, Michael Jost, Haotong Qin, Lyes Khacef, Federico Paredes-Valles, Michele Magno|<http://arxiv.org/pdf/2505.04258v1>|提出融合RGB和事件视觉的神经网络，提升无人机避障预测精度。|
|📝 更新|RoBridge: A Hierarchical Architecture Bridging Cognition and Execution for General Robotic Manipulation|罗桥：通用机器人操作中连接认知与执行的分层架构|Kaidong Zhang, Rongtao Xu, Pengzhen Ren, Junfan Lin, Hefeng Wu, Liang Lin, Xiaodan Liang|<http://arxiv.org/pdf/2505.01709v2>|提出RoBridge，通过认知规划和强化学习，解决机器人操作中的认知与执行能力不匹配问题。|
|🆕 发布|A Weak Supervision Learning Approach Towards an Equitable Parking Lot Occupancy Estimation|一种面向公平停车场占用率估计的弱监督学习方法|Theophilus Aidoo, Till Koebe, Akansh Maurya, Hewan Shrestha, Ingmar Weber|<http://arxiv.org/pdf/2505.04229v1>|提出了一种利用弱监督和粗时间标签估计停车场占用率的方法，降低了对高分辨率图像的依赖。|
|🆕 发布|An Enhanced YOLOv8 Model for Real-Time and Accurate Pothole Detection and Measurement|增强型YOLOv8模型用于实时精确的坑洞检测与测量|Mustafa Yurdakul, Şakir Tasdemir|<http://arxiv.org/pdf/2505.04207v1>|提出了一种基于RGB-D图像的YOLOv8模型，有效提升了路面坑洞检测与尺寸测量的准确性和实时性。|
|🆕 发布|CM1 - A Dataset for Evaluating Few-Shot Information Extraction with Large Vision Language Models|CM1 - 用于评估大视觉语言模型在少样本信息提取中的数据集|Fabian Wolf, Oliver Tüselmann, Arthur Matei, Lukas Hennies, Christoph Rass, Gernot A. Fink|<http://arxiv.org/pdf/2505.04214v1>|构建CM1数据集评估LVLM在少量样本下的信息提取能力，优于传统全页提取模型。|
|📝 更新|Navigating Neural Space: Revisiting Concept Activation Vectors to Overcome Directional Divergence|在神经空间中导航：重新审视概念激活向量以克服方向性发散|Frederik Pahde, Maximilian Dreyer, Leander Weber, Moritz Weckbecker, Christopher J. Anders, Thomas Wiegand, Wojciech Samek, Sebastian Lapuschkin|<http://arxiv.org/pdf/2202.03482v3>|提出了一种基于模式识别的CAVs计算方法，以克服概念方向偏差问题。|
|📝 更新|Antidote: A Unified Framework for Mitigating LVLM Hallucinations in Counterfactual Presupposition and Object Perception|对抗剂：缓解反事实预设和物体感知中LVLM幻觉的统一框架|Yuanchen Wu, Lu Zhang, Hang Yao, Junlong Du, Ke Yan, Shouhong Ding, Yunsheng Wu, Xiaoqiang Li|<http://arxiv.org/pdf/2504.20468v2>|提出Antidote框架，通过合成数据和偏好优化，有效缓解LVLM在反事实预设和物体感知中的幻觉问题...|
|🆕 发布|Bridging Geometry-Coherent Text-to-3D Generation with Multi-View Diffusion Priors and Gaussian Splatting|跨越几何一致文本到3D生成的多视图扩散先验和高斯分层|Feng Yang, Wenliang Qian, Wangmeng Zuo, Hui Li|<http://arxiv.org/pdf/2505.04262v1>|提出CSD框架，结合多视角先验和Gaussian Splatting优化，生成几何一致的高质量3D内...|
|📝 更新|MonoForce: Learnable Image-conditioned Physics Engine|MonoForce：可学习的图像条件物理引擎|Ruslan Agishev, Karel Zimmermann|<http://arxiv.org/pdf/2502.10156v3>|MonoForce提出了一种基于物理感知神经符号层的模型，通过学习图像条件下的物理引擎，实现了在粗糙...|
|📝 更新|Training-Free Sketch-Guided Diffusion with Latent Optimization|无监督草图引导扩散模型中的潜在优化训练|Sandra Zhang Ding, Jiafeng Mao, Kiyoharu Aizawa|<http://arxiv.org/pdf/2409.00313v2>|提出了一种无需训练的草图引导扩散模型，通过潜在优化实现图像生成与草图结构的高度契合。|
|🆕 发布|S3D: Sketch-Driven 3D Model Generation|S3D：基于草图的三维模型生成|Hail Song, Wonsik Shin, Naeun Lee, Soomin Chung, Nojun Kwak, Woontack Woo|<http://arxiv.org/pdf/2505.04185v1>|[代码](https://github.com/hailsong/S3D.); 提出了一种从2D草图生成3D模型的新框架S3D，显著提升了重建精度。|
|🆕 发布|VideoPath-LLaVA: Pathology Diagnostic Reasoning Through Video Instruction Tuning|视频路径-LLaVA：通过视频指令调优进行病理诊断推理|Trinh T. L. Vuong, Jin Tae Kwak|<http://arxiv.org/pdf/2505.04192v1>|[代码](https://github.com/trinhvg/VideoPath-LLaVA.); VideoPath-LLaVA通过整合多模态数据和视频指令微调，模拟病理学家诊断过程，提升病理视频分...|
|🆕 发布|DOTA: Deformable Optimized Transformer Architecture for End-to-End Text Recognition with Retrieval-Augmented Generation|DOTA：用于检索增强生成端到端文本识别的可变形优化Transformer架构|Naphat Nithisopa, Teerapong Panboonyuen|<http://arxiv.org/pdf/2505.04175v1>|提出了一种结合变形卷积和检索增强生成的新架构，显著提升了文本识别准确率。|
|📝 更新|No Other Representation Component Is Needed: Diffusion Transformers Can Provide Representation Guidance by Themselves|无需其他表示组件：扩散变换器可自行提供表示指导|Dengyang Jiang, Mengmeng Wang, Liuzhuozheng Li, Lei Zhang, Haoyu Wang, Wei Wei, Guang Dai, Yanning Zhang .etc.|<http://arxiv.org/pdf/2505.02831v2>|提出Self-Representation Alignment方法，无需额外组件，通过自蒸馏提升扩散...|
|📝 更新|Replace Anyone in Videos|《视频中的任意人物替换》|Xiang Wang, Shiwei Zhang, Haonan Qiu, Ruihang Chu, Zekun Li, Yingya Zhang, Changxin Gao, Yuehuan Wang .etc.|<http://arxiv.org/pdf/2409.19911v2>|[代码](https://github.com/ali-vilab/UniAnimate-DiT.); 提出ReplaceAnyone框架，实现视频中人物局部替换和插入，保持动作和外观连贯。|
|📝 更新|RaDialog: A Large Vision-Language Model for Radiology Report Generation and Conversational Assistance|RaDialog：一种用于放射学报告生成和对话辅助的大规模视觉-语言模型|Chantal Pellegrini, Ege Özsoy, Benjamin Busam, Nassir Navab, Matthias Keicher|<http://arxiv.org/pdf/2311.18681v3>|[代码](https://github.com/ChantalMP/RaDialog.); 开发了一种大型的视觉语言模型RaDialog，用于生成和讨论临床正确的放射学报告，并实现交互式对话。|
|📝 更新|LRFusionPR: A Polar BEV-Based LiDAR-Radar Fusion Network for Place Recognition|LRFusionPR：一种基于极坐标BEV的激光雷达-雷达融合网络用于地点识别|Zhangshuo Qi, Luqi Cheng, Zijie Zhou, Guangming Xiong|<http://arxiv.org/pdf/2504.19186v2>|[代码](https://github.com/QiZS-BIT/LRFusionPR.); 提出LRFusionPR，融合激光雷达与雷达数据，实现精准且鲁棒的地点识别。|
|🆕 发布|SToLa: Self-Adaptive Touch-Language Framework with Tactile Commonsense Reasoning in Open-Ended Scenarios|SToLa：开放场景中具有触觉常识推理的自适应触觉语言框架|Ning Cheng, Jinan Xu, Jialing Chen, Wenjuan Han|<http://arxiv.org/pdf/2505.04201v1>|提出SToLa框架，通过混合专家模型和触觉常识推理，解决开放场景中触觉与语言模态融合的难题。|
|📝 更新|TranSplat: Lighting-Consistent Cross-Scene Object Transfer with 3D Gaussian Splatting|TranSplat：基于3D高斯喷溅的跨场景物体光照一致性传输|Tony Yu, Yanlin Jin, Ashok Veeraraghavan, Akshat Dave, Guha Balakrishnan|<http://arxiv.org/pdf/2503.22676v2>|TranSplat通过3D高斯分层实现跨场景物体转移，无需显式估计材料属性，实现逼真重光照。|
|🆕 发布|Learning from Similarity Proportion Loss for Classifying Skeletal Muscle Recovery Stages|从相似性比例损失中学习以分类骨骼肌恢复阶段|Yu Yamaoka or Weng Ian Chan, Shigeto Seno, Soichiro Fukada, Hideo Matsuda|<http://arxiv.org/pdf/2505.04150v1>|提出OSLSP方法，通过相似性比例损失提升肌肉恢复阶段分类的准确性。|
|🆕 发布|R^3-VQA: "Read the Room" by Video Social Reasoning|R^3-VQA：通过视频社交推理“读懂房间”|Lixing Niu, Jiapeng Li, Xingping Yu, Shu Wang, Ruining Feng, Bo Wu, Ping Wei, Yisen Wang .etc.|<http://arxiv.org/pdf/2505.04147v1>|构建了R^3-VQA视频数据集，评估并提升了视频社交推理能力。|
|🆕 发布|Vision Graph Prompting via Semantic Low-Rank Decomposition|基于语义低秩分解的视觉图提示|Zixiang Ai, Zichen Liu, Jiahuan Zhou|<http://arxiv.org/pdf/2505.04121v1>|[代码](https://github.com/zhoujiahuan1991/ICML2025-VGP.); 提出一种基于图结构的视觉提示方法，通过语义低秩分解提升视觉GNN的迁移性能。|
|📝 更新|Enhancing Test Time Adaptation with Few-shot Guidance|提升测试时自适应能力的少样本引导|Siqi Luo, Yi Xin, Yuntao Du, Zhongwei Wan, Tao Tan, Guangtao Zhai, Xiaohong Liu|<http://arxiv.org/pdf/2409.01341v2>|提出FS-TTA方法，通过少量样本指导，有效提升测试时间适应能力，解决域偏移问题。|
|🆕 发布|GAPrompt: Geometry-Aware Point Cloud Prompt for 3D Vision Model|GAPrompt：面向3D视觉模型的几何感知点云提示|Zixiang Ai, Zichen Liu, Yuanhang Lei, Zhenyu Cui, Xu Zou, Jiahuan Zhou|<http://arxiv.org/pdf/2505.04119v1>|[代码](https://github.com/zhoujiahuan1991/ICML2025-VGP.); 提出GAPrompt，通过几何线索增强3D视觉模型适应性，实现高效参数高效微调。|
|📝 更新|Visual Imitation Enables Contextual Humanoid Control|视觉模仿实现情境化的人形机器人控制|Arthur Allshire, Hongsuk Choi, Junyi Zhang, David McAllister, Anthony Zhang, Chung Min Kim, Trevor Darrell, Pieter Abbeel .etc.|<http://arxiv.org/pdf/2505.03729v2>|通过视频模仿，让机器人从日常视频中学习环境上下文，实现上下楼梯、坐立等复杂动作。|
|📝 更新|Image-GS: Content-Adaptive Image Representation via 2D Gaussians|图像-高斯表示：基于二维高斯的内容自适应图像表示|Yunxiang Zhang, Bingxuan Li, Alexandr Kuznetsov, Akshay Jindal, Stavros Diolatzis, Kenneth Chen, Anton Sochenov, Anton Kaplanyan .etc.|<http://arxiv.org/pdf/2407.01866v2>|Image-GS通过自适应分配和优化二维高斯函数，实现了内容自适应的图像表示，平衡了视觉保真度和内存...|
|📝 更新|Advancements and limitations of LLMs in replicating human color-word associations|LLMs在复制人类颜色-词汇关联方面的进展与局限性|Makoto Fukushima, Shusuke Eshita, Hiroshige Fukuhara|<http://arxiv.org/pdf/2411.02116v3>|该研究通过对比多代LLM与人类颜色词关联，揭示了LLM在颜色词关联预测上的进步与局限。|
|📝 更新|DCS-ST for Classification of Breast Cancer Histopathology Images with Limited Annotations|基于有限标注的乳腺癌组织病理学图像分类的DCS-ST方法|Liu Suxing, Byungwon Min|<http://arxiv.org/pdf/2505.03204v2>|提出DCS-ST方法，有效提升有限标注数据下乳腺癌病理图像分类性能。|
|🆕 发布|One2Any: One-Reference 6D Pose Estimation for Any Object|One2Any：针对任意物体的单参考6D姿态估计|Mengya Liu, Siyuan Li, Ajad Chhatkuli, Prune Truong, Luc Van Gool, Federico Tombari|<http://arxiv.org/pdf/2505.04109v1>|One2Any通过单一参考图像实现任意物体6自由度姿态估计，无需3D模型或多视角数据。|
|📝 更新|PAHA: Parts-Aware Audio-Driven Human Animation with Diffusion Model|PAHA：基于扩散模型的部件感知音频驱动人体动画|Y. B. Wang, S. Z. Zhou, J. F. Wu, T. Hu, J. N. Zhang, Y. Liu|<http://arxiv.org/pdf/2505.03603v2>|PAHA通过引入部分感知重加权与部分一致性增强，显著提升了音频驱动人体动画的准确性和一致性。|
|📝 更新|DynamicControl: Adaptive Condition Selection for Improved Text-to-Image Generation|动态控制：用于改进文本到图像生成的自适应条件选择|Qingdong He, Jinlong Peng, Pengcheng Xu, Boyuan Jiang, Xiaobin Hu, Donghao Luo, Yong Liu, Yabiao Wang .etc.|<http://arxiv.org/pdf/2412.03255v2>|DynamicControl通过动态组合控制信号，有效管理多条件，提升文本到图像生成的可控性和质量。|
|🆕 发布|MAISY: Motion-Aware Image SYnthesis for MedicalImage Motion Correction|MAISY：基于运动感知的医学图像运动校正图像合成|Andrew Zhang, Hao Wang, Shuchang Ye, Michael Fulham, Jinman Kim|<http://arxiv.org/pdf/2505.04105v1>|MAISY通过结合SAM和VS-SSIM，有效纠正医学图像运动伪影，提升图像质量。|
|📝 更新|PNE-SGAN: Probabilistic NDT-Enhanced Semantic Graph Attention Network for LiDAR Loop Closure Detection|PNE-SGAN：用于激光雷达闭环检测的概率NDT增强语义图注意力网络|Xiong Li, Shulei Liu, Xingning Chen, Yisong Wu, Dong Zhu|<http://arxiv.org/pdf/2504.08280v2>|PNE-SGAN通过结合NDT几何和概率时间推理，为LiDAR闭环检测提供高精度和鲁棒性。|
|📝 更新|MSA-UNet3+: Multi-Scale Attention UNet3+ with New Supervised Prototypical Contrastive Loss for Coronary DSA Image Segmentation|MSA-UNet3+：基于新监督原型对比损失的冠脉DSA图像分割的多尺度注意力UNet3+|Rayan Merghani Ahmed, Adnan Iltaf, Mohamed Elmanna, Gang Zhao, Hongliang Li, Yue Du, Bin Li, Shoujun Zhou|<http://arxiv.org/pdf/2504.05184v3>|[代码](https://github.com/rayanmerghani/MSA-UNet3plus.); 提出了一种融合多尺度注意力和对比学习的MSA-UNet3+模型，有效提升了冠状动脉DSA图像分割的准...|
|🆕 发布|3D Brain MRI Classification for Alzheimer Diagnosis Using CNN with Data Augmentation|基于数据增强的卷积神经网络在3D脑部MRI图像上进行阿尔茨海默病诊断的分类|Thien Nhan Vo, Bac Nam Ho, Thanh Xuan Truong|<http://arxiv.org/pdf/2505.04097v1>|开发了一种基于3D卷积神经网络和数据增强的脑部MRI分类方法，显著提升了阿尔茨海默症诊断的准确性。|
|📝 更新|Probability Density Geodesics in Image Diffusion Latent Space|图像扩散潜在空间中的概率密度测地线|Qingtao Yu, Jaskirat Singh, Zhaoyuan Yang, Peter Henry Tu, Jing Zhang, Hongdong Li, Richard Hartley, Dylan Campbell|<http://arxiv.org/pdf/2504.06675v2>|提出了一种在图像扩散潜在空间中计算测地线的方法，用于分析图像结构并实现无监督的图像序列插值和外推。|
|📝 更新|Opening Articulated Structures in the Real World|在现实世界中打开可动结构|Arjun Gupta, Michelle Zhang, Rishik Sathua, Saurabh Gupta|<http://arxiv.org/pdf/2402.17767v3>|[代码](https://arjung128.github.io/opening-articulated-structures); 通过开发模块化系统，该论文揭示了在真实环境中操作未知物体时，感知而非精确末端执行器控制是主要瓶颈。|
|📝 更新|SceneLLM: Implicit Language Reasoning in LLM for Dynamic Scene Graph Generation|场景LLM：用于动态场景图生成的LLM中的隐式语言推理|Hang Zhang, Zhuoling Li, Jun Liu|<http://arxiv.org/pdf/2412.11026v2>|提出SceneLLM，利用LLM和V2L模块生成动态场景图，实现场景语义理解。|
|🆕 发布|Scalable Aerial GNSS Localization for Marine Robots|可扩展的海洋机器人空中GNSS定位|Shuo Wen, Edwin Meriaux, Mariana Sosa Guzmán, Charlotte Morissette, Chloe Si, Bobak Baghi, Gregory Dudek|<http://arxiv.org/pdf/2505.04095v1>|提出利用无人机GNSS定位技术，实现海洋机器人精准定位的新方法。|
|📝 更新|Benchmarking Multimodal Mathematical Reasoning with Explicit Visual Dependency|多模态数学推理的显式视觉依赖基准测试|Zhikai Wang, Jiashuo Sun, Wenqi Zhang, Zhiqiang Hu, Xin Li, Fan Wang, Deli Zhao|<http://arxiv.org/pdf/2504.18589v3>|[代码](https://alibaba-damo-academy.github.io/VCBench); 提出VCBENCH基准，评估多模态数学推理中的视觉依赖，揭示视觉-数学整合挑战。|
|🆕 发布|SMMT: Siamese Motion Mamba with Self-attention for Thermal Infrared Target Tracking|SMMT：基于自注意力机制的Siamese运动曼巴热红外目标跟踪|Shang Zhang, Huanbin Zhang, Dali Feng, Yujie Cui, Ruoyan Xiong, Cen He|<http://arxiv.org/pdf/2505.04088v1>|提出SMMT，结合双向状态空间模型和自注意力机制，有效解决热红外目标跟踪中的遮挡、模糊和背景干扰问题...|
|🆕 发布|FoodTrack: Estimating Handheld Food Portions with Egocentric Video|食品追踪：利用自视角视频估计手持食物分量|Ervin Wang, Yuhao Chen|<http://arxiv.org/pdf/2505.04055v1>|FoodTrack通过使用自拍摄像头视频直接测量手持食物体积，提高了食物摄入量跟踪的准确性。|
|📝 更新|Adaptive Aggregation Weights for Federated Segmentation of Pancreas MRI|自适应聚合权重用于胰腺MRI联邦分割|Hongyi Pan, Gorkem Durak, Zheyuan Zhang, Yavuz Taktak, Elif Keles, Halil Ertugrul Aktas, Alpay Medetalibeyoglu, Yury Velichko .etc.|<http://arxiv.org/pdf/2410.22530v3>|提出自适应聚合权重，提升联邦学习在胰腺MRI分割中的泛化能力。|
|🆕 发布|SEVA: Leveraging Single-Step Ensemble of Vicinal Augmentations for Test-Time Adaptation|SEVA：利用邻域增强的单步集成进行测试时自适应|Zixuan Hu, Yichun Hu, Ling-Yu Duan|<http://arxiv.org/pdf/2505.04087v1>|提出SEVA方法，通过单步集成邻域增强实现高效测试时自适应，提升模型鲁棒性。|
|🆕 发布|AS3D: 2D-Assisted Cross-Modal Understanding with Semantic-Spatial Scene Graphs for 3D Visual Grounding|AS3D：基于语义-空间场景图的2D辅助跨模态理解与3D视觉定位|Feng Xiao, Hongbin Xu, Guocan Zhao, Wenxiong Kang|<http://arxiv.org/pdf/2505.04058v1>|提出了一种结合2D辅助和语义空间图的方法，有效解决3D视觉定位中的多相似物体识别问题。|
|📝 更新|Token Coordinated Prompt Attention is Needed for Visual Prompting|需要令牌协调的提示注意力进行视觉提示|Zichen Liu, Xu Zou, Gang Hua, Jiahuan Zhou|<http://arxiv.org/pdf/2505.02406v2>|[代码](https://github.com/zhoujiahuan1991/ICML2025-TCPA.); 提出Token Coordinated Prompt Attention模块，提升视觉提示效果，增强...|
|📝 更新|VividListener: Expressive and Controllable Listener Dynamics Modeling for Multi-Modal Responsive Interaction|生动听众：多模态响应交互中的表情和可控听众动态建模|Shiying Li, Xingqun Qi, Bingkun Yang, Chen Weile, Zezhao Tian, Muyi Sun, Qifeng Liu, Man Zhang .etc.|<http://arxiv.org/pdf/2504.21718v2>|提出VividListener，通过多模态信息实现对话中听众动态表情和反应的精细控制。|
|📝 更新|Cyclic Vision-Language Manipulator: Towards Reliable and Fine-Grained Image Interpretation for Automated Report Generation|循环视觉-语言操纵器：迈向可靠且细粒度的图像解释以实现自动报告生成|Yingying Fang, Zihao Jin, Shaojie Guo, Jinda Liu, Zhiling Yue, Yijian Gao, Junzhi Ning, Zhi Li .etc.|<http://arxiv.org/pdf/2411.05261v2>|提出CVLM模块，通过循环操纵X光图像，实现可靠且细粒度的图像解释，提升自动报告生成模型的透明度和可...|
|🆕 发布|Person-In-Situ: Scene-Consistent Human Image Insertion with Occlusion-Aware Pose Control|人境合一：基于遮挡感知姿态控制的场景一致人体图像插入|Shun Masuda, Yuki Endo, Yoshihiro Kanamori|<http://arxiv.org/pdf/2505.04052v1>|提出了一种结合3D人体模型和潜在扩散模型的方法，实现场景一致的人像插入，并自然处理遮挡。|
|📝 更新|Uncertainty-Aware Prototype Semantic Decoupling for Text-Based Person Search in Full Images|基于全图文本的行人搜索中的不确定性感知原型语义解耦|Zengli Luo, Canlong Zhang, Xiaochun Lu, Zhixin Li, Zhiwen Wang|<http://arxiv.org/pdf/2505.03567v2>|提出UPD-TBPS框架，通过多粒度不确定性估计、原型语义解耦和跨模态重识别，提升基于文本的全图行人...|
|🆕 发布|TerraFusion: Joint Generation of Terrain Geometry and Texture Using Latent Diffusion Models|地球融合：利用潜在扩散模型联合生成地形几何和纹理|Kazuki Higo, Toshiki Kanai, Yuki Endo, Yoshihiro Kanamori|<http://arxiv.org/pdf/2505.04050v1>|提出了一种基于潜在扩散模型联合生成地形高度图和纹理的方法，实现直观的地形生成并保持高度图与纹理之间的...|

