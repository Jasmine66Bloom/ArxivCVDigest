## [UPDATED!] **2025-05-08** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|StreamBridge: Turning Your Offline Video Large Language Model into a Proactive Streaming Assistant|StreamBridge：将您的离线视频大型语言模型转变为主动流媒体助手|Haibo Wang, Bo Feng, Zhengfeng Lai, Mingze Xu, Shiyu Li, Weifeng Ge, Afshin Dehghan, Meng Cao .etc.|<http://arxiv.org/pdf/2505.05467v1>|StreamBridge将离线视频大语言模型转化为流式助手，解决实时理解和主动响应难题。|
|🆕 发布|Mogao: An Omni Foundation Model for Interleaved Multi-Modal Generation|莫高：一种用于交错多模态生成的全场景基础模型|Chao Liao, Liyang Liu, Xun Wang, Zhengxiong Luo, Xinyu Zhang, Wenliang Zhao, Jie Wu, Liang Li .etc.|<http://arxiv.org/pdf/2505.05472v1>|Mogao通过因果方法实现交错多模态生成，显著提升多模态理解和文本到图像生成性能。|
|🆕 发布|PillarMamba: Learning Local-Global Context for Roadside Point Cloud via Hybrid State Space Model|柱状马amba：通过混合状态空间模型学习路边点云的局部-全局上下文|Zhang Zhang, Chao Sun, Chao Yue, Da Wen, Tianze Wang, Jianghao Leng|<http://arxiv.org/pdf/2505.05397v1>|提出PillarMamba框架，通过混合状态空间模型学习路边点云的局部-全局上下文，提升3D物体检测...|
|🆕 发布|Hearing and Seeing Through CLIP: A Framework for Self-Supervised Sound Source Localization|通过CLIP听与见：自监督声源定位框架|Sooyoung Park, Arda Senocak, Joon Son Chung|<http://arxiv.org/pdf/2505.05343v1>|提出一种基于CLIP的音频驱动的自监督声音源定位框架，显著提升定位精度和泛化能力。|
|🆕 发布|Benchmarking Ophthalmology Foundation Models for Clinically Significant Age Macular Degeneration Detection|眼科基础模型在临床显著年龄相关性黄斑变性检测中的基准测试|Benjamin A. Cohen, Jonathan Fhima, Meishar Meisel, Baskin Meital, Luis Filipe Nakayama, Eran Berkowitz, Joachim A. Behar|<http://arxiv.org/pdf/2505.05291v1>|该论文通过比较不同预训练视觉Transformer在AMD检测中的性能，挑战了领域特定预训练的必要性...|
|🆕 发布|An Active Contour Model for Silhouette Vectorization using Bézier Curves|基于贝塞尔曲线的轮廓矢量化的主动轮廓模型|Luis Alvarez, Jean-Michel Morel|<http://arxiv.org/pdf/2505.05132v1>|提出了一种基于贝塞尔曲线的轮廓矢量化方法，有效降低轮廓与矢量化之间的平均距离。|
|📝 更新|How Do Multimodal Large Language Models Handle Complex Multimodal Reasoning? Placing Them in An Extensible Escape Game|如何处理复杂的多模态推理：将多模态大型语言模型置于可扩展的逃脱游戏中|Ziyue Wang, Yurui Dong, Fuwen Luo, Minyuan Ruan, Zhili Cheng, Chi Chen, Peng Li, Yang Liu|<http://arxiv.org/pdf/2503.10042v2>|提出MM-Escape基准，通过模拟逃脱游戏环境，评估和揭示多模态大语言模型在复杂推理任务中的行为和...|
|📝 更新|Search is All You Need for Few-shot Anomaly Detection|只需搜索即可实现少样本异常检测|Qishan Wang, Jia Guo, Shuyong Gao, Haofen Wang, Li Xiong, Junjie Hu, Hanqi Guo, Wenqiang Zhang|<http://arxiv.org/pdf/2504.11895v2>|[代码](https://github.com/Qiqigeww/VisionAD.); 提出了一种基于简单搜索框架的少样本异常检测方法，显著超越了现有技术。|
|📝 更新|Nexus-Gen: A Unified Model for Image Understanding, Generation, and Editing|Nexus-Gen：一种统一的图像理解、生成和编辑模型|Hong Zhang, Zhongjie Duan, Xingjun Wang, Yuze Zhao, Weiyi Lu, Zhipeng Di, Yixuan Xu, Yingda Chen .etc.|<http://arxiv.org/pdf/2504.21356v2>|[代码](https://github.com/modelscope/Nexus-Gen.git); Nexus-Gen通过结合LLM和扩散模型，实现统一框架下的图像理解、生成和编辑。|
|🆕 发布|UncertainSAM: Fast and Efficient Uncertainty Quantification of the Segment Anything Model|不确定SAM：快速高效的Segment Anything模型不确定性量化|Timo Kaiser, Thomas Norrenbrock, Bodo Rosenhahn|<http://arxiv.org/pdf/2505.05049v1>|提出了一种快速高效的Segment Anything Model不确定性量化方法，通过贝叶斯熵公式和...|
|📝 更新|Balanced 3DGS: Gaussian-wise Parallelism Rendering with Fine-Grained Tiling|平衡3DGS：基于高斯并行化的细粒度分块渲染|Hao Gui, Lin Hu, Rui Chen, Mingxiao Huang, Yuxin Yin, Jin Yang, Yong Wu, Chen Liu .etc.|<http://arxiv.org/pdf/2412.17378v4>|提出Balanced 3DGS，通过动态负载分配和Gaussian并行渲染解决3DGS训练中的负载不...|
|📝 更新|Look Twice Before You Answer: Memory-Space Visual Retracing for Hallucination Mitigation in Multimodal Large Language Models|在回答之前再看一眼：多模态大型语言模型中幻觉缓解的内存-空间视觉重绘|Xin Zou, Yizhou Wang, Yibo Yan, Yuanhuiyi Lyu, Kening Zheng, Sirui Huang, Junkai Chen, Peijie Jiang .etc.|<http://arxiv.org/pdf/2410.03577v2>|[代码](https://github.com/1zhou-Wang/MemVR); MemVR通过视觉重放机制，有效缓解了多模态大语言模型中的幻觉问题。|
|🆕 发布|CAG-VLM: Fine-Tuning of a Large-Scale Model to Recognize Angiographic Images for Next-Generation Diagnostic Systems|CAG-VLM：针对下一代诊断系统识别血管造影图像的大规模模型微调|Yuto Nakamura, Satoshi Kodera, Haruki Settai, Hiroki Shinohara, Masatsugu Tamura, Tomohiro Noguchi, Tatsuki Furusawa, Ryo Takizawa .etc.|<http://arxiv.org/pdf/2505.04964v1>|提出了一种基于大规模语言模型微调的冠状动脉造影图像识别方法，辅助医生生成临床报告和治疗建议。|
|📝 更新|Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene Understanding|Lexicon3D：探索复杂3D场景理解的视觉基础模型|Yunze Man, Shuhong Zheng, Zhipeng Bao, Martial Hebert, Liang-Yan Gui, Yu-Xiong Wang|<http://arxiv.org/pdf/2409.03757v3>|[代码](https://github.com/YunzeMan/Lexicon3D); 探究视觉基础模型在复杂3D场景理解中的优劣，为未来任务提供灵活的编码器选择。|
|🆕 发布|Mix-QSAM: Mixed-Precision Quantization of the Segment Anything Model|混合精度量化Segment Anything模型：Mix-QSAM|Navin Ranjan, Andreas Savakis|<http://arxiv.org/pdf/2505.04861v1>|提出了一种基于混合精度的量化框架，有效提升了Segment Anything Model在资源受限设...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TokLIP: Marry Visual Tokens to CLIP for Multimodal Comprehension and Generation|TokLIP：将视觉标记与CLIP结合以实现多模态理解和生成|Haokun Lin, Teng Wang, Yixiao Ge, Yuying Ge, Zhichao Lu, Ying Wei, Qingfu Zhang, Zhenan Sun .etc.|<http://arxiv.org/pdf/2505.05422v1>|[代码](https://github.com/TencentARC/TokLIP.); TokLIP通过结合视觉标记和CLIP语义，实现了高效的多模态理解和生成。|
|🆕 发布|EDmamba: A Simple yet Effective Event Denoising Method with State Space Model|EDmamba：一种简单而有效的基于状态空间模型的事件去噪方法|Ciyu Ruan, Zihang Gong, Ruishan Guo, Jingao Xu, Xinlei Chen|<http://arxiv.org/pdf/2505.05391v1>|提出了一种基于状态空间模型的事件去噪方法，有效平衡了速度与准确性。|
|📝 更新|Federated EndoViT: Pretraining Vision Transformers via Federated Learning on Endoscopic Image Collections|联邦EndoViT：通过在内镜图像集合上进行联邦学习预训练视觉Transformer|Max Kirchner, Alexander C. Jenke, Sebastian Bodenstedt, Fiona R. Kolbinger, Oliver L. Saldanha, Jakob N. Kather, Martin Wagner, Stefanie Speidel|<http://arxiv.org/pdf/2504.16612v2>|通过联邦学习在微创手术内窥镜图像集合上预训练视觉Transformer，解决数据共享限制，实现隐私保...|
|📝 更新|Vision Transformers for Efficient Indoor Pathloss Radio Map Prediction|视觉Transformer在高效室内路径损耗无线电地图预测中的应用|Rafayel Mkrtchyan, Edvard Ghukasyan, Khoren Petrosyan, Hrant Khachatrian, Theofanis P. Raptis|<http://arxiv.org/pdf/2412.09507v2>|提出利用视觉Transformer架构预测室内路径损耗，有效解决数据稀缺和环境复杂问题。|
|📝 更新|A nonlinear elasticity model in computer vision|计算机视觉中的非线性弹性模型|John M. Ball, Christopher L. Horner|<http://arxiv.org/pdf/2408.17237v3>|提出非线性弹性模型，通过优化函数比较图像，并证明其在特定条件下的存在性和唯一性。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PhysFlow: Unleashing the Potential of Multi-modal Foundation Models and Video Diffusion for 4D Dynamic Physical Scene Simulation|PhysFlow：释放多模态基础模型和视频扩散在4D动态物理场景模拟中的潜力|Zhuoman Liu, Weicai Ye, Yan Luximon, Pengfei Wan, Di Zhang|<http://arxiv.org/pdf/2411.14423v4>|PhysFlow通过多模态基础模型和视频扩散技术，实现了更精确和灵活的4D动态物理场景模拟。|
|🆕 发布|Perception, Reason, Think, and Plan: A Survey on Large Multimodal Reasoning Models|感知、推理、思考和规划：大型多模态推理模型综述|Yunxin Li, Zhenyu Liu, Zitao Li, Xuanyu Zhang, Zhenran Xu, Xinyu Chen, Haoyuan Shi, Shenyuan Jiang .etc.|<http://arxiv.org/pdf/2505.04921v1>|该论文综述了大型多模态推理模型，旨在解决跨模态理解和推理深度问题，并提出了一种四阶段发展路线图。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OcularAge: A Comparative Study of Iris and Periocular Images for Pediatric Age Estimation|眼龄：虹膜和眼周图像在儿童年龄估计中的比较研究|Naveenkumar G Venkataswamy, Poorna Ravi, Stephanie Schuckers, Masudul H. Imtiaz|<http://arxiv.org/pdf/2505.05374v1>|该研究通过比较虹膜和眼周图像，提出了一种基于多任务深度学习框架的儿童年龄估计方法，显著提升了儿童年龄...|
|🆕 发布|Biomed-DPT: Dual Modality Prompt Tuning for Biomedical Vision-Language Models|生物医学-DPT：生物医学视觉-语言模型的 双模态提示微调|Wei Peng, Kang Liu, Jianchen Hu, Meng Zhang|<http://arxiv.org/pdf/2505.05189v1>|[代码](https://github.com/Kanyooo/Biomed-DPT); 提出Biomed-DPT，通过结合文本和视觉提示，有效提升了生物医学图像分类的准确性。|
|🆕 发布|RepSNet: A Nucleus Instance Segmentation model based on Boundary Regression and Structural Re-parameterization|RepSNet：基于边界回归和结构重参数化的核实例分割模型|Shengchun Xiong, Xiangru Li, Yunpeng Zhong, Wanfen Peng|<http://arxiv.org/pdf/2505.05073v1>|设计了一种基于边界回归和结构重参数化的核实例分割模型，有效提升了病理图像中细胞核分割的准确性和效率。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PlaceIt3D: Language-Guided Object Placement in Real 3D Scenes|PlaceIt3D：基于语言的3D真实场景中物体放置|Ahmed Abdelreheem, Filippo Aleotti, Jamie Watson, Zawar Qureshi, Abdelrahman Eldesokey, Peter Wonka, Gabriel Brostow, Sara Vicente .etc.|<http://arxiv.org/pdf/2505.05288v1>|提出了一种语言引导三维场景中物体放置的新方法，并构建了首个相关基准数据集。|
|🆕 发布|Pro2SAM: Mask Prompt to SAM with Grid Points for Weakly Supervised Object Localization|Pro2SAM：基于网格点的掩码提示弱监督目标定位|Xi Yang, Songsong Duan, Nannan Wang, Xinbo Gao|<http://arxiv.org/pdf/2505.04905v1>|提出Pro2SAM网络，通过网格点掩码提示提升弱监督目标定位精度。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Two Views Are Better than One: Monocular 3D Pose Estimation with Multiview Consistency|两个视角胜过一个：基于多视角一致性的单目3D姿态估计|Christian Keilstrup Ingwersen, Rasmus Tirsgaard, Rasmus Nylander, Janus Nørtoft Jensen, Anders Bjorholm Dahl, Morten Rieger Hannemose|<http://arxiv.org/pdf/2311.12421v3>|提出了一种利用多视角一致性损失函数提升单目3D姿态估计模型性能的方法。|
|🆕 发布|PaniCar: Securing the Perception of Advanced Driving Assistance Systems Against Emergency Vehicle Lighting|PaniCar：保障高级驾驶辅助系统感知安全，抵御紧急车辆灯光干扰|Elad Feldman, Jacob Shams, Dudi Biton, Alfred Chen, Shaoyuan Xie, Satoru Koda, Yisroel Mirsky, Asaf Shabtai .etc.|<http://arxiv.org/pdf/2505.05183v1>|提出PaniCar框架，增强自动驾驶系统对紧急车辆灯光干扰的鲁棒性，提升安全性能。|
|🆕 发布|SSH-Net: A Self-Supervised and Hybrid Network for Noisy Image Watermark Removal|SSH-Net：一种用于噪声图像水印去除的自监督和混合网络|Wenyang Liu, Jianjun Gao, Kim-Hui Yap|<http://arxiv.org/pdf/2505.05088v1>|[代码](https://github.com/wenyang001/SSH-Net.); SSH-Net通过自监督和混合网络，有效解决了噪声图像去水印难题。|
|📝 更新|Uncertainty-Weighted Image-Event Multimodal Fusion for Video Anomaly Detection|不确定性加权图像事件多模态融合用于视频异常检测|Sungheon Jeong, Jihong Park, Mohsen Imani|<http://arxiv.org/pdf/2505.02393v2>|[代码](https://github.com/EavnJeong/IEF-VAD.); 提出了一种融合图像事件表示和图像特征的方法，显著提升了视频异常检测的准确性和鲁棒性。|
|🆕 发布|Adaptive Contextual Embedding for Robust Far-View Borehole Detection|自适应上下文嵌入的远视距钻孔检测|Xuesong Liu, Tianyu Hao, Emmett J. Ientilucci|<http://arxiv.org/pdf/2505.05008v1>|提出了一种自适应上下文嵌入方法，有效提升了远视距钻孔检测的准确性和鲁棒性。|
|📝 更新|MonoCoP: Chain-of-Prediction for Monocular 3D Object Detection|MonoCoP：单目3D目标检测的预测链|Zhihao Zhang, Abhinav Kumar, Girish Chandar Ganesan, Xiaoming Liu|<http://arxiv.org/pdf/2505.04594v2>|MonoCoP通过链式预测策略，提高了单目3D物体检测的深度估计精度。|
|🆕 发布|An Efficient Method for Accurate Pose Estimation and Error Correction of Cuboidal Objects|高效立方体物体姿态估计与误差校正方法|Utsav Rai, Hardik Mehta, Vismay Vakharia, Aditya Choudhary, Amit Parmar, Rolif Lima, Kaushik Das|<http://arxiv.org/pdf/2505.04962v1>|提出了一种高效方法，准确估计和校正立方体物体的姿态，减少误差并提高精度。|
|🆕 发布|A Simple Detector with Frame Dynamics is a Strong Tracker|具有帧动态的简单检测器是强大的跟踪器|Chenxu Peng, Chenxu Wang, Minrui Zou, Danyang Li, Zhengpeng Yang, Yimian Dai, Ming-Ming Cheng, Xiang Li|<http://arxiv.org/pdf/2505.04917v1>|提出一种结合全局检测和动态帧信息的小型红外目标跟踪器，显著提升跟踪性能。|
|📝 更新|Quaternionic Reweighted Amplitude Flow for Phase Retrieval in Image Reconstruction|四元数重加权振幅流在图像重建中的相位恢复|Ren Hu, Pan Lian|<http://arxiv.org/pdf/2501.02180v2>|提出QRAF算法及其变体，有效解决图像重建中的四元数相位恢复问题，显著提升恢复性能和计算效率。|
|🆕 发布|Auto-regressive transformation for image alignment|自回归变换用于图像配准|Kanggeon Lee, Soochahn Lee, Kyoung Mu Lee|<http://arxiv.org/pdf/2505.04864v1>|提出ART方法，通过迭代估计和聚焦关键区域，显著提升图像对齐精度。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Split Matching for Inductive Zero-shot Semantic Segmentation|分割匹配用于归纳式零样本语义分割|Jialei Chen, Xu Zheng, Dongyue Li, Chong Yi, Seigo Ito, Danda Pani Paudel, Luc Van Gool, Hiroshi Murase .etc.|<http://arxiv.org/pdf/2505.05023v1>|提出Split Matching方法，解决零样本语义分割中未见类别过拟合问题，显著提升模型性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DiffusionSfM: Predicting Structure and Motion via Ray Origin and Endpoint Diffusion|扩散SfM：通过射线起源和端点扩散预测结构和运动|Qitao Zhao, Amy Lin, Jeff Tan, Jason Y. Zhang, Deva Ramanan, Shubham Tulsiani|<http://arxiv.org/pdf/2505.05473v1>|DiffusionSfM通过多视角图像直接预测3D场景几何和相机位姿，有效解决SfM问题。|
|🆕 发布|Augmented Deep Contexts for Spatially Embedded Video Coding|增强深度上下文用于空间嵌入视频编码|Yifan Bian, Chuanbo Tang, Li Li, Dong Liu|<http://arxiv.org/pdf/2505.05309v1>|[代码](https://github.com/EsakaK/SEVC.); 提出了一种空间嵌入视频编码方法，有效缓解了大运动或新物体处理限制，并降低比特率。|
|🆕 发布|PRE-Mamba: A 4D State Space Model for Ultra-High-Frequent Event Camera Deraining|预-Mamba：用于超高频事件相机去雨的4D状态空间模型|Ciyu Ruan, Ruishan Guo, Zihang Gong, Jingao Xu, Wenhan Yang, Xinlei Chen|<http://arxiv.org/pdf/2505.05307v1>|提出PRE-Mamba，一种基于4D状态空间模型的超高频事件相机去雨方法，有效提升去雨效果和计算效率...|
|🆕 发布|Diffusion Model Quantization: A Review|扩散模型量化：综述|Qian Zeng, Chenggong Hu, Mingli Song, Jie Song|<http://arxiv.org/pdf/2505.05215v1>|[代码](https://github.com/TaylorJocelyn/Diffusion-Model-Quantization.); 综述了扩散模型量化技术，分析了量化方法及其对生成模型性能的影响。|
|🆕 发布|EAM: Enhancing Anything with Diffusion Transformers for Blind Super-Resolution|EAM：使用扩散Transformer增强任何内容的盲超分辨率|Haizhen Xie, Kunpeng Du, Qiangyu Yan, Sen Lu, Jianhong Han, Hanting Chen, Hailin Hu, Jie Hu|<http://arxiv.org/pdf/2505.05209v1>|EAM通过结合扩散Transformer和渐进式掩码图像建模，显著提升了盲超分辨率性能。|
|🆕 发布|Probabilistic Embeddings for Frozen Vision-Language Models: Uncertainty Quantification with Gaussian Process Latent Variable Models|概率嵌入用于冻结视觉-语言模型：高斯过程潜在变量模型的不确定性量化|Aishwarya Venkataramanan, Paul Bodesheim, Joachim Denzler|<http://arxiv.org/pdf/2505.05163v1>|提出GroVE方法，从冻结视觉语言模型中学习概率嵌入，实现不确定性量化。|
|🆕 发布|Research on Anomaly Detection Methods Based on Diffusion Models|基于扩散模型的异常检测方法研究|Yi Chen|<http://arxiv.org/pdf/2505.05137v1>|提出了一种基于扩散模型的异常检测新框架，有效识别图像和音频数据中的异常。|
|🆕 发布|MDAA-Diff: CT-Guided Multi-Dose Adaptive Attention Diffusion Model for PET Denoising|MDAA-Diff：基于CT引导的多剂量自适应注意力扩散模型用于PET降噪|Xiaolong Niu, Zanting Ye, Xu Han, Yanchao Huang, Hao Sun, Hubing Wu, Lijun Lu|<http://arxiv.org/pdf/2505.05112v1>|提出了一种结合CT引导和剂量自适应的扩散模型，有效提升了低剂量PET图像去噪质量。|
|🆕 发布|MDE-Edit: Masked Dual-Editing for Multi-Object Image Editing via Diffusion Models|MDE-Edit：基于扩散模型的掩码双重编辑多对象图像编辑|Hongyang Zhu, Haipeng Liu, Bo Fu, Yang Wang|<http://arxiv.org/pdf/2505.05101v1>|MDE-Edit通过双编辑和扩散模型，实现了复杂场景中多对象图像的精确编辑。|
|🆕 发布|PIDiff: Image Customization for Personalized Identities with Diffusion Models|PIDiff：基于扩散模型的个性化身份图像定制|Jinyu Gu, Haipeng Liu, Meng Wang, Yang Wang|<http://arxiv.org/pdf/2505.05081v1>|PIDiff通过W+空间和定制化微调策略，有效分离身份信息与背景，实现个性化身份图像生成。|
|📝 更新|Advances in Automated Fetal Brain MRI Segmentation and Biometry: Insights from the FeTA 2024 Challenge|胎儿脑MRI分割与生物测量学进展：FeTA 2024挑战赛见解|Vladyslav Zalevskyi, Thomas Sanchez, Misha Kaandorp, Margaux Roulet, Diego Fajardo-Rojas, Liu Li, Jana Hutter, Hongwei Bran Li .etc.|<http://arxiv.org/pdf/2505.02784v3>|FeTA 2024挑战赛提出新方法，通过引入生物计量预测和低场MRI数据，提高了胎儿脑部MRI分割和...|
|🆕 发布|ADNP-15: An Open-Source Histopathological Dataset for Neuritic Plaque Segmentation in Human Brain Whole Slide Images with Frequency Domain Image Enhancement for Stain Normalization|ADNP-15：一种开源的病理切片图像神经斑分割数据集，用于人类大脑全切片图像，并采用频域图像增强进行染色标准化|Chenxi Zhao, Jianqiang Li, Qing Zhao, Jing Bai, Susana Boluda, Benoit Delatour, Lev Stimmer, Daniel Racoceanu .etc.|<http://arxiv.org/pdf/2505.05041v1>|构建开源脑病理图像数据集，提出频率域增强方法，提升神经斑分割准确度。|
|📝 更新|DGSolver: Diffusion Generalist Solver with Universal Posterior Sampling for Image Restoration|DGSolver：具有通用后验采样的扩散泛化求解器用于图像恢复|Hebaixu Wang, Jing Zhang, Haonan Guo, Di Wang, Jiayi Ma, Bo Du|<http://arxiv.org/pdf/2504.21487v2>|[代码](https://github.com/MiliLab/DGSolver.); DGSolver通过精确求解和通用后验采样，显著提升了图像修复的准确性和效率。|
|📝 更新|LIVS: A Pluralistic Alignment Dataset for Inclusive Public Spaces|LIVS：包容性公共空间的多元对齐数据集|Rashid Mushkani, Shravan Nayak, Hugo Berard, Allison Cohen, Shin Koseki, Hadrien Bertrand|<http://arxiv.org/pdf/2503.01894v2>|构建了LIVS数据集，通过多标准对齐支持包容性城市规划中的文本到图像模型。|
|📝 更新|MAISY: Motion-Aware Image SYnthesis for Medical Image Motion Correction|MAISY：基于运动感知的医学图像运动校正图像合成|Andrew Zhang, Hao Wang, Shuchang Ye, Michael Fulham, Jinman Kim|<http://arxiv.org/pdf/2505.04105v2>|MAISY通过结合SAM和VS-SSIM，有效纠正医学图像运动伪影，提升图像质量。|
|📝 更新|Semi-supervised Underwater Image Enhancement Using A Physics-Aware Triple-Stream Network|基于物理感知的三重流网络的半监督水下图像增强|Shixuan Xu, Hao Qi, Xinghui Dong|<http://arxiv.org/pdf/2307.11470v5>|提出一种结合物理模型和深度学习的半监督水下图像增强网络，有效提升图像质量。|
|🆕 发布|D-CODA: Diffusion for Coordinated Dual-Arm Data Augmentation|D-CODA：用于协调双臂数据增强的扩散模型|I-Chun Arthur Liu, Jason Chen, Gaurav Sukhatme, Daniel Seita|<http://arxiv.org/pdf/2505.04860v1>|[代码](https://dcodaaug.github.io/D-CODA); D-CODA通过扩散模型实现双臂操作数据增强，提高眼手仿学习效率。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Generating Physically Stable and Buildable LEGO Designs from Text|从文本生成物理稳定且可建造的乐高设计|Ava Pun, Kangle Deng, Ruixuan Liu, Deva Ramanan, Changliu Liu, Jun-Yan Zhu|<http://arxiv.org/pdf/2505.05469v1>|[代码](https://avalovelace1.github.io/LegoGPT); 提出LegoGPT，从文本生成稳定可构建的乐高模型。|
|📝 更新|Free Discontinuity Regression: With an Application to the Economic Effects of Internet Shutdowns|自由不连续回归：应用于互联网关闭的经济影响|Florian Gunsilius, David Van Dijcke|<http://arxiv.org/pdf/2309.14630v3>|提出了一种同时平滑、分割并精确恢复回归表面跳跃的Free Discontinuity Regress...|
|🆕 发布|General Transform: A Unified Framework for Adaptive Transform to Enhance Representations|通用变换：一种用于增强表示的自适应变换的统一框架|Gekko Budiutama, Shunsuke Daimon, Hirofumi Nishi, Yu-ichiro Matsushita|<http://arxiv.org/pdf/2505.04969v1>|提出自适应变换框架，提升机器学习模型在计算机视觉和自然语言处理任务中的表现。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Flow-GRPO: Training Flow Matching Models via Online RL|Flow-GRPO：通过在线强化学习训练流匹配模型|Jie Liu, Gongye Liu, Jiajun Liang, Yangguang Li, Jiaheng Liu, Xintao Wang, Pengfei Wan, Di Zhang .etc.|<http://arxiv.org/pdf/2505.05470v1>|Flow-GRPO通过在线强化学习提升流匹配模型，显著提高文本到图像任务准确率。|
|🆕 发布|SVAD: From Single Image to 3D Avatar via Synthetic Data Generation with Video Diffusion and Data Augmentation|SVAD：通过视频扩散和数据增强生成合成数据，从单张图像到3D虚拟形象的转换|Yonwoo Choi|<http://arxiv.org/pdf/2505.05475v1>|SVAD通过结合视频扩散和数据增强，从单张图像生成高质量3D人偶，克服了传统方法的局限性。|
|🆕 发布|3D Scene Generation: A Survey|三维场景生成：综述|Beichen Wen, Haozhe Xie, Zhaoxi Chen, Fangzhou Hong, Ziwei Liu|<http://arxiv.org/pdf/2505.05474v1>|[代码](https://github.com/hzxie/Awesome-3D-Scene-Generation.); 综述了3D场景生成技术，通过分类和比较不同方法，揭示了该领域的关键挑战和未来方向。|
|📝 更新|Rethinking Video Super-Resolution: Towards Diffusion-Based Methods without Motion Alignment|重新思考视频超分辨率：迈向无需运动对齐的扩散方法|Zhihao Zhan, Wang Pang, Xiang Zhu, Yechao Bai|<http://arxiv.org/pdf/2503.03355v4>|提出了一种无需运动对齐的基于扩散后验采样的视频超分辨率方法，显著提升了处理效率和适应性。|
|📝 更新|Defining and Quantifying Creative Behavior in Popular Image Generators|定义和量化流行图像生成器中的创造性行为|Aditi Ramaswamy, Hana Chockler, Melane Navaratnarajah|<http://arxiv.org/pdf/2505.04497v2>|提出量化评估方法，帮助用户选择合适的AI图像生成模型。|
|📝 更新|HunyuanCustom: A Multimodal-Driven Architecture for Customized Video Generation|HunyuanCustom：一种基于多模态驱动的个性化视频生成架构|Teng Hu, Zhentao Yu, Zhengguang Zhou, Sen Liang, Yuan Zhou, Qin Lin, Qinglin Lu|<http://arxiv.org/pdf/2505.04512v2>|提出HunyuanCustom，一种多模态驱动的视频生成框架，解决身份一致性和输入模态限制问题。|
|📝 更新|Generalizable Human Gaussians from Single-View Image|单视图图像中的一般化人类高斯分布|Jinnan Chen, Chen Li, Jianfeng Zhang, Lingting Zhu, Buzhen Huang, Hanlin Chen, Gim Hee Lee|<http://arxiv.org/pdf/2406.06050v5>|提出了一种从单张图像学习3D人体高斯模型的方法，结合人体先验和扩散先验，实现精细外观和几何恢复。|
|🆕 发布|SOAP: Style-Omniscient Animatable Portraits|SOAP：风格全知可动画肖像|Tingting Liao, Yujian Zheng, Adilbek Karmanov, Liwen Hu, Leyang Jin, Yuliang Xiu, Hao Li|<http://arxiv.org/pdf/2505.05022v1>|[代码](https://github.com/TingtingLiao/soap.); SOAP提出了一种从单张图像生成可动画3D头像的方法，克服了风格限制和细节处理难题。|
|🆕 发布|Inter-Diffusion Generation Model of Speakers and Listeners for Effective Communication|说话者和听众之间的交互扩散生成模型，以实现有效沟通|Jinhe Huang, Yongkang Cheng, Yuming Hang, Gaoge Han, Jinewei Li, Jing Zhang, Xingjian Gu|<http://arxiv.org/pdf/2505.04996v1>|提出了一种融合听众全身体势的交互扩散生成模型，有效提升了沟通中的手势自然度和同步性。|
|🆕 发布|ReAlign: Bilingual Text-to-Motion Generation via Step-Aware Reward-Guided Alignment|ReAlign：基于步态感知奖励引导的对齐的双语文本到动作生成|Wanjiang Weng, Xiaofeng Tan, Hongsong Wang, Pan Zhou|<http://arxiv.org/pdf/2505.04974v1>|[代码](https://wengwanjiang.github.io/ReAlign-page); 提出ReAlign方法，通过奖励引导对齐，显著提升双语文本到动作生成质量。|
|📝 更新|SceneCraft: Layout-Guided 3D Scene Generation|场景工艺：布局引导的3D场景生成|Xiuyu Yang, Yunze Man, Jun-Kun Chen, Yu-Xiong Wang|<http://arxiv.org/pdf/2410.09049v3>|[代码](https://orangesodahub.github.io/SceneCraft); SceneCraft通过用户描述和布局指导，生成复杂室内场景，实现多视角图像生成和真实感渲染。|
|🆕 发布|Canny2Palm: Realistic and Controllable Palmprint Generation for Large-scale Pre-training|Canny2Palm：大规模预训练的逼真且可控掌纹生成|Xingzeng Lan, Xing Duan, Chen Chen, Weiyu Lin, Bo Wang|<http://arxiv.org/pdf/2505.04922v1>|Canny2Palm通过Canny边缘检测和Pix2Pix网络生成逼真可控的掌纹数据，提升大规模预训...|
|🆕 发布|GlyphMastero: A Glyph Encoder for High-Fidelity Scene Text Editing|GlyphMastero：高保真场景文本编辑的符号编码器|Tong Wang, Ting Liu, Xiaochao Qu, Chengjing Wu, Luoqi Liu, Xiaolin Hu|<http://arxiv.org/pdf/2505.04915v1>|提出了一种基于字形编码的文本编辑方法，显著提升了场景文本编辑的准确性和连贯性。|
|🆕 发布|Advanced 3D Imaging Approach to TSV/TGV Metrology and Inspection Using Only Optical Microscopy|高级仅使用光学显微镜的TSV/TGV计量和检测的3D成像方法|Gugeong Sung|<http://arxiv.org/pdf/2505.04913v1>|结合混合场显微镜和光度立体法，该论文提出了一种突破传统光学显微镜局限性的硅和玻璃通孔检测新方法。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Adaptive Markup Language Generation for Contextually-Grounded Visual Document Understanding|自适应基于上下文视觉文档理解的标记语言生成|Han Xiao, Yina Xie, Guanxin Tan, Yinghao Chen, Rui Hu, Ke Wang, Aojun Zhou, Hao Li .etc.|<http://arxiv.org/pdf/2505.05446v1>|提出自适应标记语言生成方法，提升视觉文档理解能力。|
|🆕 发布|Aesthetics Without Semantics|美学无关语义|C. Alejandro Parraga, Olivier Penacchio, Marcos Muňoz Gonzalez, Bogdan Raducanu, Xavier Otazu|<http://arxiv.org/pdf/2505.05331v1>|构建无语义内容图像库，揭示美学评价与图像特征间关系。|
|🆕 发布|Does CLIP perceive art the same way we do?|CLIP是否以与我们相同的方式感知艺术？|Andrea Asperti, Leonardo Dessì, Maria Chiara Tonetti, Nico Wu|<http://arxiv.org/pdf/2505.05229v1>|探究CLIP在艺术作品理解上的能力，评估其与人类感知的契合度，并提出改进建议。|
|🆕 发布|T2VTextBench: A Human Evaluation Benchmark for Textual Control in Video Generation Models|T2VTextBench：视频生成模型中文本控制的评价指标基准|Xuyang Guo, Jiayan Huo, Zhenmei Shi, Zhao Song, Jiahao Zhang, Jiale Zhao|<http://arxiv.org/pdf/2505.04946v1>|构建了首个评估视频生成模型中文字准确性和一致性的基准，揭示了当前模型在文字处理上的不足。|
|📝 更新|DejAIvu: Identifying and Explaining AI Art on the Web in Real-Time with Saliency Maps|DejAIvu：利用显著性图实时识别和解释网络上的AI艺术|Jocelyn Dzuong|<http://arxiv.org/pdf/2502.08821v2>|[代码](https://github.com/Noodulz/dejAIvu.); DejAIvu实时检测并解释网页上的AI艺术，通过显著性图提高图像问责性。|
|🆕 发布|Cross-Branch Orthogonality for Improved Generalization in Face Deepfake Detection|跨分支正交性以提升人脸深度伪造检测泛化能力|Tharindu Fernando, Clinton Fookes, Sridha Sridharan, Simon Denman|<http://arxiv.org/pdf/2505.04888v1>|提出了一种基于特征正交解耦的深度fake检测方法，显著提升了泛化能力。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GeomHair: Reconstruction of Hair Strands from Colorless 3D Scans|几何头发：从无色3D扫描中重建发丝|Rachmadio Noval Lazuardi, Artem Sevastopolsky, Egor Zakharov, Matthias Niessner, Vanessa Sklyarova|<http://arxiv.org/pdf/2505.05376v1>|提出了一种从无色3D扫描中直接重建发丝的新方法，无需依赖颜色信息。|
|📝 更新|MonST3R: A Simple Approach for Estimating Geometry in the Presence of Motion|MonST3R：运动存在下估计几何形状的简单方法|Junyi Zhang, Charles Herrmann, Junhwa Hur, Varun Jampani, Trevor Darrell, Forrester Cole, Deqing Sun, Ming-Hsuan Yang|<http://arxiv.org/pdf/2410.03825v2>|MonST3R通过直接估计动态场景中的每帧几何，实现了对运动场景几何估计的突破。|
|📝 更新|TetWeave: Isosurface Extraction using On-The-Fly Delaunay Tetrahedral Grids for Gradient-Based Mesh Optimization|TetWeave：基于梯度网格优化的实时Delaunay四面体网格等值面提取|Alexandre Binninger, Ruben Wiersma, Philipp Herholz, Olga Sorkine-Hornung|<http://arxiv.org/pdf/2505.04590v2>|TetWeave通过动态构建四面体网格优化梯度网格，实现高质量、自适应且内存占用低的等值面提取。|
|📝 更新|LUDO: Low-Latency Understanding of Deformable Objects using Point Cloud Occupancy Functions|LUDO：利用点云占用函数实现可变形物体的低延迟理解|Pit Henrich, Franziska Mathis-Ullrich, Paul Maria Scheikl|<http://arxiv.org/pdf/2411.08777v4>|LUDO通过点云和不确定性估计，实现了对变形物体内部结构的快速理解与定位。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Time of the Flight of the Gaussians: Optimizing Depth Indirectly in Dynamic Radiance Fields|高斯飞行时间：在动态辐射场中间接优化深度|Runfeng Li, Mikhail Okunev, Zixuan Guo, Anh Ha Duong, Christian Richardt, Matthew O'Toole, James Tompkin|<http://arxiv.org/pdf/2505.05356v1>|提出一种间接优化动态场景深度的新方法，显著提升C-ToF相机动态场景重建速度与精度。|
|🆕 发布|Progressive Inertial Poser: Progressive Real-Time Kinematic Chain Estimation for 3D Full-Body Pose from Three IMU Sensors|渐进式惯性姿态估计器：基于三个IMU传感器的3D全身姿态的渐进式实时运动链估计|Zunjie Zhu, Yan Zhao, Yihan Hu, Guoxiang Wang, Hai Qiu, Bolun Zheng, Chenggang Yan, Feng Xu|<http://arxiv.org/pdf/2505.05336v1>|提出Progressive Inertial Poser，利用头部和手腕IMU传感器实时估计3D全身...|
|🆕 发布|MoRe-3DGSMR: Motion-resolved reconstruction framework for free-breathing pulmonary MRI based on 3D Gaussian representation|MoRe-3DGSMR：基于3D高斯表示的自由呼吸肺MRI运动解析重建框架|Tengya Peng, Ruyi Zha, Qing Zou|<http://arxiv.org/pdf/2505.04959v1>|提出了一种基于3D高斯表示的运动解析重建框架，有效提升了自由呼吸肺MRI图像质量。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FindAnything: Open-Vocabulary and Object-Centric Mapping for Robot Exploration in Any Environment|《FindAnything：适用于任何环境的开放词汇和以物体为中心的机器人探索映射》|Sebastián Barbas Laina, Simon Boche, Sotiris Papatheodorou, Simon Schaefer, Jaehyung Jung, Stefan Leutenegger|<http://arxiv.org/pdf/2504.08603v2>|检测并构建基于视觉-语言信息的开放词汇地图，实现机器人自主探索未知环境。|
|📝 更新|Leveraging Depth Maps and Attention Mechanisms for Enhanced Image Inpainting|利用深度图和注意力机制增强图像修复|Jin Hyun Park, Harine Choi, Praewa Pitiphat|<http://arxiv.org/pdf/2505.00735v2>|结合深度图和注意力机制，提出了一种提升图像修复精度的创新方法。|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Transformer-based assignment decision network for multiple object tracking|基于Transformer的多目标跟踪分配决策网络|Athena Psalta, Vasileios Tsironis, Konstantinos Karantzalos|<http://arxiv.org/pdf/2208.03571v3>|[代码](https://github.com/psaltaath/tadn-mot.); 提出了一种基于Transformer的无需优化步骤的数据关联网络，有效提升了多目标跟踪性能。|
|📝 更新|CloudTrack: Scalable UAV Tracking with Cloud Semantics|云追踪：基于云语义的 scalable 无人机跟踪|Yannik Blei, Michael Krawez, Nisarga Nilavadi, Tanja Katharina Kaiser, Wolfram Burgard|<http://arxiv.org/pdf/2409.16111v3>|提出了一种基于云语义的无人机追踪方法，可自动识别空中影像中失踪人员。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|The City that Never Settles: Simulation-based LiDAR Dataset for Long-Term Place Recognition Under Extreme Structural Changes|《永不静止的城市：极端结构变化下的长期场所识别的基于模拟的激光雷达数据集》|Hyunho Song, Dongjae Lee, Seunghun Oh, Minwoo Jung, Ayoung Kim|<http://arxiv.org/pdf/2505.05076v1>|[代码](https://github.com/Hyunho111/CNS_dataset.); 构建了模拟城市变化数据集，提出对称度量方法，以应对长期场所识别中的极端结构变化挑战。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Image-Text Relation Prediction for Multilingual Tweets|多语言推文中的图像-文本关系预测|Matīss Rikters, Edison Marrese-Taylor|<http://arxiv.org/pdf/2505.05040v1>|构建多语言推特图像-文本关系预测基准，展示近期视觉语言模型在预测任务上的提升空间。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Adaptive Rate Control for Deep Video Compression with Rate-Distortion Prediction|自适应率控结合率失真预测的深度视频压缩|Bowen Gu, Hao Chen, Ming Lu, Jie Yao, Zhan Ma|<http://arxiv.org/pdf/2412.18834v2>|提出了一种基于深度学习的自适应视频压缩速率控制方法，显著提升了压缩效率和视频质量稳定性。|
|📝 更新|Transforming faces into video stories -- VideoFace2.0|将人脸转化为视频故事 —— VideoFace2.0|Branko Brkljač, Vladimir Kalušev, Branislav Popović, Milan Sečujski|<http://arxiv.org/pdf/2505.02060v2>|VideoFace2.0通过结合人脸检测、识别和跟踪，实现了高效且鲁棒的实时人脸重识别，为视频分析和...|
|🆕 发布|StabStitch++: Unsupervised Online Video Stitching with Spatiotemporal Bidirectional Warps|StabStitch++：基于时空双向变形的无监督在线视频拼接|Lang Nie, Chunyu Lin, Kang Liao, Yun Zhang, Shuaicheng Liu, Yao Zhao|<http://arxiv.org/pdf/2505.05001v1>|提出了一种无监督在线视频拼接框架，同时实现空间拼接和时序稳定，有效解决拼接抖动问题。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Boosting Adverse Weather Crowd Counting via Multi-queue Contrastive Learning|通过多队列对比学习增强恶劣天气下的人群计数|Tianhang Pan, Xiuyi Jia|<http://arxiv.org/pdf/2408.05956v3>|提出MQCL方法，通过多队列对比学习提升恶劣天气下人群计数准确性。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Interact with me: Joint Egocentric Forecasting of Intent to Interact, Attitude and Social Actions|与我互动：意图、态度和社会行为的自回归预测|Tongfei Bian, Yiming Ma, Mathieu Chollet, Victor Sanchez, Tanaya Guha|<http://arxiv.org/pdf/2412.16698v3>|提出SocialEgoNet，从第一视角预测人机交互意图、态度和动作，实现实时高精度预测。|
|🆕 发布|xTrace: A Facial Expressive Behaviour Analysis Tool for Continuous Affect Recognition|xTrace：一种用于连续情感识别的面部表情行为分析工具|Mani Kumar Tellamekala, Shashank Jaiswal, Thomas Smith, Timur Alamev, Gary McKeown, Anthony Brown, Michel Valstar|<http://arxiv.org/pdf/2505.05043v1>|xTrace工具通过大规模数据集和高效特征提取，实现了对自然面部表情的实时连续情感识别。|
|🆕 发布|Driving with Context: Online Map Matching for Complex Roads Using Lane Markings and Scenario Recognition|驾驶中的上下文：利用车道标记和场景识别进行复杂道路的在线地图匹配|Xin Bi, Zhichao Li, Yuxuan Xia, Panpan Tong, Lijuan Zhang, Yang Chen, Junsheng Fu|<http://arxiv.org/pdf/2505.05007v1>|[代码](https://github.com/TRV-Lab/LMSR-OMM.); 提出了一种利用车道标记和场景识别的在线地图匹配方法，有效提升了复杂道路网络中的匹配精度。|
|🆕 发布|AI and Vision based Autonomous Navigation of Nano-Drones in Partially-Known Environments|基于AI和视觉的纳米无人机在部分已知环境中的自主导航|Mattia Sartori, Chetna Singhal, Neelabhro Roy, Davide Brunelli, James Gross|<http://arxiv.org/pdf/2505.04972v1>|提出了一种基于边缘计算和深度学习的AI辅助视觉导航方法，实现纳米无人机在未知环境中的安全自主飞行。|
|🆕 发布|Learning from Loss Landscape: Generalizable Mixed-Precision Quantization via Adaptive Sharpness-Aware Gradient Aligning|从损失景观中学习：通过自适应锐度感知梯度对齐的通用混合精度量化|Lianbo Ma, Jianlun Ma, Yuee Zhou, Guoyang Xie, Qiang He, Zhichao Lu|<http://arxiv.org/pdf/2505.04877v1>|提出了一种基于小数据集搜索和泛化的混合精度量化方法，显著降低计算成本并提升效率。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HQC-NBV: A Hybrid Quantum-Classical View Planning Approach|混合量子-经典视图规划方法：HQC-NBV|Xiaotong Yu, Chang Wen Chen|<http://arxiv.org/pdf/2505.05212v1>|HQC-NBV通过结合量子计算，显著提升了计算机视觉中的场景探索效率。|
|📝 更新|FA-KPConv: Introducing Euclidean Symmetries to KPConv via Frame Averaging|FA-KPConv：通过帧平均引入欧几里得对称性到KPConv|Ali Alawieh, Alexandru P. Condurache|<http://arxiv.org/pdf/2505.04485v2>|通过引入帧平均，FA-KPConv使KPConv网络对点云的平移、旋转和反射具有精确的不变性和等变性...|
|📝 更新|HESSO: Towards Automatic Efficient and User Friendly Any Neural Network Training and Pruning|HESSO：迈向自动高效且用户友好的任意神经网络训练与剪枝|Tianyi Chen, Xiaoyi Qu, David Aponte, Colby Banbury, Jongwoo Ko, Tianyu Ding, Yong Ma, Vladimir Lyapunov .etc.|<http://arxiv.org/pdf/2409.09085v2>|提出HESSO，一种自动高效且用户友好的神经网络训练与剪枝方法，有效解决性能退化问题。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Automated vision-based assistance tools in bronchoscopy: stenosis severity estimation|支气管镜检查中基于自动视觉辅助工具的狭窄程度评估|Clara Tomasini, Javier Rodriguez-Puigvert, Dinora Polanco, Manuel Viñuales, Luis Riazuelo, Ana Cristina Murillo|<http://arxiv.org/pdf/2505.05136v1>|提出了一种基于支气管镜图像的自动狭窄程度评估方法，提高了诊断效率和准确性。|
|📝 更新|SeriesBench: A Benchmark for Narrative-Driven Drama Series Understanding|系列基准：基于叙事驱动的剧情理解基准|Chenkai Zhang, Yiming Lei, Zeming Liu, Haitao Leng, Shaoguo Liu, Tingting Gao, Qingjie Liu, Yunhong Wang|<http://arxiv.org/pdf/2504.21435v2>|[代码](https://github.com/zackhxn/SeriesBench-CVPR2025.); 提出SeriesBench基准，评估多模态大语言模型对叙事驱动剧集的理解能力，并引入PC-DCoT框...|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Federated Deconfounding and Debiasing Learning for Out-of-Distribution Generalization|联邦去混淆和去偏学习以实现分布外泛化|Zhuang Qi, Sijin Zhou, Lei Meng, Han Hu, Han Yu, Xiangxu Meng|<http://arxiv.org/pdf/2505.04979v1>|提出FedDDL方法，通过构建因果图和消除混淆路径，有效解决联邦学习中属性偏差问题，提升模型泛化能力...|
|📝 更新|FieldNet: Efficient Real-Time Shadow Removal for Enhanced Vision in Field Robotics|场域网络：场域机器人视觉增强中的高效实时阴影去除|Alzayat Saleh, Alex Olsen, Jake Wood, Bronson Philippa, Mostafa Rahimi Azghadi|<http://arxiv.org/pdf/2403.08142v2>|FieldNet通过深度学习实现高效实时去影，提升野外机器人视觉识别准确性。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Threshold Modulation for Online Test-Time Adaptation of Spiking Neural Networks|阈值调制用于脉冲神经网络在线测试时自适应|Kejie Zhao, Wenjia Hua, Aiersi Tuerhong, Luziwei Leng, Yuxin Ma, Qinghua Guo|<http://arxiv.org/pdf/2505.05375v1>|[代码](https://github.com/NneurotransmitterR/TM-OTTA-SNN.); 提出了一种适用于脉冲神经网络在线测试时自适应的阈值调制方法，有效提升了模型对分布变化的鲁棒性。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Concept-Based Unsupervised Domain Adaptation|基于概念的无需监督领域自适应|Xinyue Xu, Yueying Hu, Hui Tang, Yi Qin, Lu Mi, Hao Wang, Xiaomeng Li|<http://arxiv.org/pdf/2505.05195v1>|提出CUDA框架，通过概念对齐和放松阈值，实现无监督领域自适应，提升CBM鲁棒性和可解释性。|
|🆕 发布|ADD: Physics-Based Motion Imitation with Adversarial Differential Discriminators|基于物理的运动模仿与对抗性差异判别器|Ziyu Zhang, Sergey Bashkirov, Dun Yang, Michael Taylor, Xue Bin Peng|<http://arxiv.org/pdf/2505.04961v1>|提出了一种基于对抗性差异判别器的物理运动模仿方法，无需手动调整奖励函数即可实现高保真运动跟踪。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|USTEP: Spatio-Temporal Predictive Learning under A Unified View|USTEP：统一视角下的时空预测学习|Cheng Tan, Jue Wang, Zhangyang Gao, Siyuan Li, Stan Z. Li|<http://arxiv.org/pdf/2310.05829v2>|USTEP通过整合微观和宏观时间尺度，统一了时空预测学习中的循环和循环自由方法，显著提升了时空预测性...|
|🆕 发布|MTL-UE: Learning to Learn Nothing for Multi-Task Learning|MTL-UE：多任务学习中的无学习学习|Yi Yu, Song Xia, Siyuan Yang, Chenqi Kong, Wenhan Yang, Shijian Lu, Yap-Peng Tan, Alex C. Kot|<http://arxiv.org/pdf/2505.05279v1>|MTL-UE首次为多任务学习模型生成不可学习示例，显著提升攻击性能。|
|🆕 发布|White Light Specular Reflection Data Augmentation for Deep Learning Polyp Detection|白光镜面反射数据增强用于深度学习息肉检测|Jose Angel Nuñez, Fabian Vazquez, Diego Adame, Xiaoyan Fu, Pengfei Gu, Bin Fu|<http://arxiv.org/pdf/2505.05248v1>|提出白光反射数据增强方法，提升深度学习息肉检测准确性。|
|📝 更新|Evaluating Deep Learning Models for Breast Cancer Classification: A Comparative Study|评估深度学习模型在乳腺癌分类中的应用：一项比较研究|Sania Eskandari, Ali Eslamian, Nusrat Munia, Amjad Alqarni, Qiang Cheng|<http://arxiv.org/pdf/2408.16859v2>|该研究通过比较八种深度学习模型，证明了Vision Transformer在乳腺癌病理图像分类中的高...|
|📝 更新|AirMorph: Topology-Preserving Deep Learning for Pulmonary Airway Analysis|AirMorph：肺气道分析中保持拓扑结构的深度学习|Minghui Zhang, Chenyu Li, Fangfang Xie, Yaoyu Liu, Hanxiao Zhang, Junyang Wu, Chunxi Zhang, Jie Yang .etc.|<http://arxiv.org/pdf/2412.11039v2>|AirMorph通过深度学习实现肺气道结构自动标注，提升诊断和治疗效率。|
|📝 更新|Expanding Event Modality Applications through a Robust CLIP-Based Encoder|通过鲁棒的CLIP编码器扩展事件模态应用|Sungheon Jeong, Hanning Chen, Sanggeon Yun, Suhyeon Cho, Wenjun Huang, Xiangjian Liu, Mohsen Imani|<http://arxiv.org/pdf/2412.03093v2>|提出一种基于CLIP的鲁棒编码器，扩展事件数据应用，提升跨模态交互能力。|
|🆕 发布|Nonlinear Motion-Guided and Spatio-Temporal Aware Network for Unsupervised Event-Based Optical Flow|非线性运动引导和时空感知网络用于无监督的事件驱动光流|Zuntao Liu, Hao Zhuang, Junjie Jiang, Yuhang Song, Zheng Fang|<http://arxiv.org/pdf/2505.05089v1>|[代码](https://wynelio.github.io/E-NMSTFlow.); 提出了一种针对事件相机光流估计的非线性运动引导时空感知网络，显著提升了长时序列光流估计的准确性。|
|🆕 发布|ULFine: Unbiased Lightweight Fine-tuning for Foundation-Model-Assisted Long-Tailed Semi-Supervised Learning|ULFine：基于基础模型辅助的长尾半监督学习的无偏轻量级微调|Enhao Zhang, Chaohua Li, Chuanxing Geng, Songcan Chen|<http://arxiv.org/pdf/2505.05062v1>|ULFine提出了一种无偏轻量级微调策略，显著降低训练成本并提升长尾半监督学习预测准确率。|
|📝 更新|Learning from Similarity Proportion Loss for Classifying Skeletal Muscle Recovery Stages|从相似性比例损失中学习以分类骨骼肌恢复阶段|Yu Yamaoka, Weng Ian Chan, Shigeto Seno, Soichiro Fukada, Hideo Matsuda|<http://arxiv.org/pdf/2505.04150v2>|提出OSLSP方法，通过相似性比例损失，提升肌肉恢复阶段分类的准确性。|
|📝 更新|MambaNUT: Nighttime UAV Tracking via Mamba-based Adaptive Curriculum Learning|MambaNUT：基于Mamba的自适应课程学习的夜间无人机跟踪|You Wu, Xiangyang Yang, Xucheng Wang, Hengzhou Ye, Dan Zeng, Shuiwang Li|<http://arxiv.org/pdf/2412.00626v2>|[代码](https://github.com/wuyou3474/MambaNUT.); 提出MambaNUT，通过自适应课程学习实现夜间无人机跟踪，提升性能并降低计算成本。|
|🆕 发布|Building-Guided Pseudo-Label Learning for Cross-Modal Building Damage Mapping|基于构建引导的伪标签学习用于跨模态建筑损伤映射|Jiepan Li, He Huang, Yu Sheng, Yujun Guo, Wei He|<http://arxiv.org/pdf/2505.04941v1>|提出了一种基于建筑引导的伪标签学习方法，有效提升了跨模态建筑损伤映射的准确性。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SITE: towards Spatial Intelligence Thorough Evaluation|空间智能全面评估：SITE|Wenqi Wang, Reuben Tan, Pengyue Zhu, Jianwei Yang, Zhengyuan Yang, Lijuan Wang, Andrey Kolobov, Jianfeng Gao .etc.|<http://arxiv.org/pdf/2505.05456v1>|构建了SITE基准数据集，全面评估视觉语言模型的空间智能。|
|🆕 发布|Visual Affordances: Enabling Robots to Understand Object Functionality|视觉可及性：使机器人理解物体功能|Tommaso Apicella, Alessio Xompero, Andrea Cavallaro|<http://arxiv.org/pdf/2505.05074v1>|提出统一框架预测视觉 affordance，解决可重复性问题，连接视觉感知与机器人行动。|
|📝 更新|3DSRBench: A Comprehensive 3D Spatial Reasoning Benchmark|3DSRBench：一个全面的3D空间推理基准|Wufei Ma, Haoyu Chen, Guofeng Zhang, Yu-Cheng Chou, Celso M de Melo, Alan Yuille|<http://arxiv.org/pdf/2412.07825v3>|构建了首个全面评估3D空间推理能力的基准3DSRBench，揭示了大型多模态模型在3D空间理解方面的...|
|📝 更新|WorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines|世界美食：全球美食多语言和多文化视觉问答的大规模基准|Genta Indra Winata, Frederikus Hudi, Patrick Amadeus Irawan, David Anugraha, Rifki Afina Putri, Yutong Wang, Adam Nohejl, Ubaidillah Ariq Prathama .etc.|<http://arxiv.org/pdf/2410.12705v5>|构建了大规模多语言多文化视觉问答基准WorldCuisines，评估VLM在理解特定文化知识上的表现...|
|📝 更新|Locality-aware Cross-modal Correspondence Learning for Dense Audio-Visual Events Localization|局部感知跨模态对应学习用于密集音频-视觉事件定位|Ling Xing, Hongyu Qu, Rui Yan, Xiangbo Shu, Jinhui Tang|<http://arxiv.org/pdf/2409.07967v3>|提出了一种基于局部连续性的跨模态对应学习框架，有效提升了密集音频-视觉事件定位的准确性。|
|🆕 发布|SpatialPrompting: Keyframe-driven Zero-Shot Spatial Reasoning with Off-the-Shelf Multimodal Large Language Models|空间提示：基于关键帧的零样本空间推理与现成多模态大型语言模型|Shun Taguchi, Hideki Deguchi, Takumi Hamazaki, Hiroyuki Sakai|<http://arxiv.org/pdf/2505.04911v1>|SpatialPrompting通过关键帧驱动和视觉语言模型实现零样本3D空间推理，无需3D特定输入...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FG-CLIP: Fine-Grained Visual and Textual Alignment|FG-CLIP：细粒度视觉与文本对齐|Chunyu Xie, Bin Wang, Fanjing Kong, Jincheng Li, Dawei Liang, Gengshen Zhang, Dawei Leng, Yuhui Yin|<http://arxiv.org/pdf/2505.05071v1>|[代码](https://github.com/360CVGroup/FG-CLIP.); FG-CLIP通过生成海量长描述和构建高质量数据集，显著提升了细粒度视觉和文本对齐能力。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DenseGrounding: Improving Dense Language-Vision Semantics for Ego-Centric 3D Visual Grounding|密集定位：提升以自我为中心的3D视觉定位的密集语言-视觉语义|Henry Zheng, Hao Shi, Qihang Peng, Yong Xien Chng, Rui Huang, Yepeng Weng, Zhongchao Shi, Gao Huang|<http://arxiv.org/pdf/2505.04965v1>|DenseGrounding通过增强视觉和文本语义，显著提升了3D视觉定位的准确度。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Automated detection of underdiagnosed medical conditions via opportunistic imaging|通过机会性成像自动检测被低估的医疗状况|Asad Aali, Andrew Johnston, Louis Blankemeier, Dave Van Veen, Laura T Derry, David Svec, Jason Hom, Robert D. Boutin .etc.|<http://arxiv.org/pdf/2409.11686v3>|检测利用深度学习从CT扫描中自动识别未被诊断的医学状况，提高诊断准确性和风险调整模型。|
|🆕 发布|Feature-Augmented Deep Networks for Multiscale Building Segmentation in High-Resolution UAV and Satellite Imagery|多尺度高分辨率无人机和卫星影像建筑分割的特征增强深度网络|Chintan B. Maniyar, Minakshi Kumar, Gengchen Mai|<http://arxiv.org/pdf/2505.05321v1>|提出了一种结合多尺度图像、特征增强和优化训练策略的深度学习框架，有效提升了高分辨率遥感图像中的建筑分...|
|🆕 发布|PADriver: Towards Personalized Autonomous Driving|个性化自动驾驶：迈向个性化自动驾驶|Genghua Kou, Fan Jia, Weixin Mao, Yingfei Liu, Yucheng Zhao, Ziheng Zhang, Osamu Yoshie, Tiancai Wang .etc.|<http://arxiv.org/pdf/2505.05240v1>|提出PADriver，一种基于多模态大语言模型的个性化自动驾驶框架，实现场景理解、危险评估和个性化决...|
|📝 更新|Label-Efficient Deep Learning in Medical Image Analysis: Challenges and Future Directions|医学图像分析中的标签高效深度学习：挑战与未来方向|Cheng Jin, Zhengrui Guo, Yi Lin, Luyang Luo, Hao Chen|<http://arxiv.org/pdf/2303.12484v5>|该论文综述了在医疗图像分析中，通过利用标注、未标注和弱标注数据，实现有限监督下的深度学习，以缓解标注...|
|🆕 发布|Improved Brain Tumor Detection in MRI: Fuzzy Sigmoid Convolution in Deep Learning|改进的MRI脑肿瘤检测：深度学习中的模糊Sigmoid卷积|Muhammad Irfan, Anum Nawaz, Riku Klen, Abdulhamit Subasi, Tomi Westerlund, Wei Chen|<http://arxiv.org/pdf/2505.05208v1>|引入模糊Sigmoid卷积和额外模块，显著降低参数数量，提高脑肿瘤检测准确率。|
|🆕 发布|DispBench: Benchmarking Disparity Estimation to Synthetic Corruptions|dispBench：基准测试合成畸变下的视差估计|Shashank Agnihotri, Amaan Ansari, Annika Dackermann, Fabian Rösch, Margret Keuper|<http://arxiv.org/pdf/2505.05091v1>|[代码](https://github.com/shashankskagnihotri/benchmarking_robustness); 提出DispBench，系统评估视差估计方法可靠性，解决深度学习视差估计鲁棒性问题。|
|🆕 发布|Direct Image Classification from Fourier Ptychographic Microscopy Measurements without Reconstruction|直接从傅里叶全息显微镜测量中进行图像分类，无需重建|Navya Sonal Agarwal, Jan Philipp Schneider, Kanchana Vaishnavi Gandikota, Syed Muhammad Kazim, John Meshreki, Ivo Ihrke, Michael Moeller|<http://arxiv.org/pdf/2505.05054v1>|直接从傅里叶ptychographic显微镜测量中分类图像内容，无需先进行重建，显著提高效率。|
|🆕 发布|Automated Thoracolumbar Stump Rib Detection and Analysis in a Large CT Cohort|自动在大规模CT队列中检测和分析胸腰段残端肋骨|Hendrik Möller, Hanna Schön, Alina Dima, Benjamin Keinert-Weth, Robert Graf, Matan Atad, Johannes Paetzold, Friederike Jungmann .etc.|<http://arxiv.org/pdf/2505.05004v1>|开发了一种深度学习模型，自动化识别和分析胸腰段残端肋骨形态，显著提升检测准确性和量化分析能力。|
|🆕 发布|ViCTr: Vital Consistency Transfer for Pathology Aware Image Synthesis|ViCTr：病理感知图像合成的关键一致性迁移|Onkar Susladkar, Gayatri Deshmukh, Yalcin Tur, Ulas Bagci|<http://arxiv.org/pdf/2505.04963v1>|ViCTr通过结合纠正流轨迹和Tweedie校正扩散过程，实现了高保真、病理感知的医学图像合成。|
|🆕 发布|FF-PNet: A Pyramid Network Based on Feature and Field for Brain Image Registration|FF-PNet：基于特征和域的脑图像配准金字塔网络|Ying Zhang, Shuai Guo, Chenxi Sun, Yuchen Zhu, Jinhai Xiang|<http://arxiv.org/pdf/2505.04938v1>|FF-PNet通过并行提取粗细粒度特征，有效处理复杂图像变形，显著提升脑图像配准精度。|
|🆕 发布|OWT: A Foundational Organ-Wise Tokenization Framework for Medical Imaging|OWT：面向医学影像的基础器官级分词框架|Sifan Song, Siyeop Yoon, Pengfei Jin, Sekeun Kim, Matthew Tivnan, Yujin Oh, Runqi Meng, Ling Chen .etc.|<http://arxiv.org/pdf/2505.04899v1>|提出了一种基于器官分组的医学图像表示学习方法，提升了可解释性和泛化能力。|
|📝 更新|IntelliCardiac: An Intelligent Platform for Cardiac Image Segmentation and Classification|智能心卡：心脏图像分割与分类的智能平台|Ting Yu Tsai, An Yu, Meghana Spurthi Maadugundu, Ishrat Jahan Mohima, Umme Habiba Barsha, Mei-Hwa F. Chen, Balakrishnan Prabhakaran, Ming-Ching Chang|<http://arxiv.org/pdf/2505.03838v2>|IntelliCardiac通过深度学习模型自动分割和分类心脏图像，为心血管疾病诊断提供准确高效的辅...|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-Objective Reinforcement Learning for Adaptive Personalized Autonomous Driving|多目标强化学习在自适应个性化自动驾驶中的应用|Hendrik Surmann, Jorge de Heuvel, Maren Bennewitz|<http://arxiv.org/pdf/2505.05223v1>|提出多目标强化学习，实现自动驾驶车辆根据用户偏好动态调整驾驶风格。|
|🆕 发布|X-Driver: Explainable Autonomous Driving with Vision-Language Models|X-Driver：基于视觉-语言模型的可解释自动驾驶|Wei Liu, Jiyuan Zhang, Binxiong Zheng, Yufeng Hu, Yingzhan Lin, Zengfeng Zeng|<http://arxiv.org/pdf/2505.05098v1>|X-Driver通过结合视觉和语言模型，提升了闭环自动驾驶的感知和决策能力，实现了可解释的驾驶决策。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|REHEARSE-3D: A Multi-modal Emulated Rain Dataset for 3D Point Cloud De-raining|REHEARSE-3D：用于3D点云去雨的多模态仿真雨数据集|Abu Mohammed Raisuddin, Jesper Holmblad, Hamed Haghighi, Yuri Poledna, Maikol Funk Drechsler, Valentina Donzella, Eren Erdal Aksoy|<http://arxiv.org/pdf/2504.21699v2>|[代码](https://sporsho.github.io/REHEARSE3D.); 构建了大规模多模态模拟雨数据集REHEARSE-3D，以促进3D点云去雨研究。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mapping User Trust in Vision Language Models: Research Landscape, Challenges, and Prospects|用户对视觉语言模型信任度映射：研究现状、挑战与展望|Agnese Chiatti, Sara Bernardini, Lara Shibelski Godoy Piccolo, Viola Schiaffonati, Matteo Matteucci|<http://arxiv.org/pdf/2505.05318v1>|构建用户对视觉语言模型信任的评估框架，以指导用户何时信赖这些系统。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Joint Super-Resolution and Segmentation for 1-m Impervious Surface Area Mapping in China's Yangtze River Economic Belt|联合超分辨率与分割用于中国长江经济带1米不透水面积制图|Jie Deng, Danfeng Hong, Chenyu Li, Naoto Yokoya|<http://arxiv.org/pdf/2505.05367v1>|提出JointSeg框架，实现从免费卫星图像直接生成1米不透水面面积图，提高分类精度并揭示城市化动态...|
|📝 更新|Semantic Shift Estimation via Dual-Projection and Classifier Reconstruction for Exemplar-Free Class-Incremental Learning|基于双投影和分类器重建的无示例类增量学习语义偏移估计|Run He, Di Fang, Yicheng Xu, Yawen Cui, Ming Li, Cen Chen, Ziqian Zeng, Huiping Zhuang|<http://arxiv.org/pdf/2503.05423v2>|提出DPCR方法，通过双重投影和分类器重构解决无样本增量学习中的语义偏移和决策偏差问题。|

