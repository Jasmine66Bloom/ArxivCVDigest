## [UPDATED!] **2025-05-09** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Adapting a Segmentation Foundation Model for Medical Image Classification|适应医学图像分类的分割基础模型|Pengfei Gu, Haoteng Tang, Islam A. Ebeid, Jose A. Nunez, Fabian Vazquez, Diego Adame, Marcus Zhan, Huimin Li .etc.|<http://arxiv.org/pdf/2505.06217v1>|提出了一种基于SAM的医学图像分类新框架，通过空间定位通道注意力机制提升分类性能。|
|📝 更新|How to build the best medical image segmentation algorithm using foundation models: a comprehensive empirical study with Segment Anything Model|如何利用基础模型构建最佳的医学图像分割算法：基于Segment Anything Model的全面实证研究|Hanxue Gu, Haoyu Dong, Jichen Yang, Maciej A. Mazurowski|<http://arxiv.org/pdf/2404.09957v3>|[代码](https://github.com/mazurowski-lab/finetune-SAM.); 通过系统研究，提出了一种基于Segment Anything Model的医学图像分割优化方法，显著...|
|📝 更新|Foundation Models For Seismic Data Processing: An Extensive Review|地震数据处理的基础模型：全面综述|Fabian Fuchs, Mario Ruben Fernandez, Norman Ettrich, Janis Keuper|<http://arxiv.org/pdf/2503.24166v2>|探索自然图像基础模型在地震数据处理中的应用，为地震处理提供高效且通用的解决方案。|
|📝 更新|AnySat: One Earth Observation Model for Many Resolutions, Scales, and Modalities|AnySat：一种适用于多种分辨率、尺度和模态的地球观测模型|Guillaume Astruc, Nicolas Gonthier, Clement Mallet, Loic Landrieu|<http://arxiv.org/pdf/2412.14123v3>|[代码](https://github.com/gastruc/AnySat.); 提出AnySat模型，实现多分辨率、尺度和模态的地球观测数据统一建模。|
|📝 更新|UncertainSAM: Fast and Efficient Uncertainty Quantification of the Segment Anything Model|不确定SAM：快速高效的Segment Anything模型不确定性量化|Timo Kaiser, Thomas Norrenbrock, Bodo Rosenhahn|<http://arxiv.org/pdf/2505.05049v2>|提出了一种快速高效的Segment Anything Model不确定性量化方法，基于贝叶斯熵公式，...|
|🆕 发布|Multimodal Integrated Knowledge Transfer to Large Language Models through Preference Optimization with Biomedical Applications|多模态集成知识迁移至大型语言模型：通过偏好优化实现，并应用于生物医学领域|Da Wu, Zhanliang Wang, Quan Nguyen, Zhuoran Xu, Kai Wang|<http://arxiv.org/pdf/2505.05736v1>|MINT通过偏好优化将多模态生物医学数据与单模态LLM结合，提升预测任务性能。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|R1-Reward: Training Multimodal Reward Model Through Stable Reinforcement Learning|R1-奖励：通过稳定强化学习训练多模态奖励模型|Yi-Fan Zhang, Xingyu Lu, Xiao Hu, Chaoyou Fu, Bin Wen, Tianke Zhang, Changyi Liu, Kaiyu Jiang .etc.|<http://arxiv.org/pdf/2505.02835v2>|提出StableReinforce算法，通过稳定强化学习训练多模态奖励模型，显著提升多模态大语言模型...|
|🆕 发布|HyperspectralMAE: The Hyperspectral Imagery Classification Model using Fourier-Encoded Dual-Branch Masked Autoencoder|超光谱MAE：基于傅里叶编码双分支掩码自动编码器的超光谱图像分类模型|Wooyoung Jeong, Hyun Jae Park, Seonghun Jeong, Jong Wook Jang, Tae Hoon Lim, Dae Seoung Kim|<http://arxiv.org/pdf/2505.05710v1>|HyperspectralMAE通过双维度掩码和波长感知嵌入，显著提升了高光谱图像分类的迁移学习准确...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Learning an Adaptive and View-Invariant Vision Transformer for Real-Time UAV Tracking|学习自适应和视角不变视觉Transformer以实现实时无人机跟踪|You Wu, Yongxin Li, Mengyuan Liu, Xucheng Wang, Xiangyang Yang, Hengzhou Ye, Dan Zeng, Qijun Zhao .etc.|<http://arxiv.org/pdf/2412.20002v2>|提出AVTrack，通过自适应计算和视角不变性学习，实现实时无人机跟踪的高效与准确。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Brain Hematoma Marker Recognition Using Multitask Learning: SwinTransformer and Swin-Unet|脑出血标志物识别：多任务学习中的SwinTransformer和Swin-U-Net|Kodai Hirata, Tsuyoshi Okita|<http://arxiv.org/pdf/2505.06185v1>|提出一种基于多任务学习的SwinTransformer和Swin-Unet模型，有效识别脑出血标记。|
|🆕 发布|Document Image Rectification Bases on Self-Adaptive Multitask Fusion|基于自适应多任务融合的文档图像校正|Heng Li, Xiangping Wu, Qingcai Chen|<http://arxiv.org/pdf/2505.06038v1>|提出了一种自适应多任务融合网络，有效提升了文档图像校正性能。|
|🆕 发布|Efficient Quantum Convolutional Neural Networks for Image Classification: Overcoming Hardware Constraints|高效量子卷积神经网络用于图像分类：克服硬件限制|Peter Röseler, Oliver Schaudt, Helmut Berg, Christian Bauckhage, Matthias Koch|<http://arxiv.org/pdf/2505.05957v1>|提出了一种高效量子卷积神经网络，通过降低输入维度，在NISQ设备上实现图像分类，超越传统方法。|
|🆕 发布|Achieving 3D Attention via Triplet Squeeze and Excitation Block|通过三元组压缩和激励块实现3D注意力|Maan Alhazmi, Abdulrahman Altahhan|<http://arxiv.org/pdf/2505.05943v1>|提出结合Triplet注意力与Squeeze-and-Excitation机制，显著提升CNN模型在...|
|📝 更新|Neural Slot Interpreters: Grounding Object Semantics in Emergent Slot Representations|神经槽位解释器：在涌现槽位表示中锚定对象语义|Bhishma Dedhia, Niraj K. Jha|<http://arxiv.org/pdf/2403.07887v4>|提出了一种将物体语义与槽位表示相结合的方法，以实现视觉场景的语义理解和推理。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Patch distribution modeling framework adaptive cosine estimator (PaDiM-ACE) for anomaly detection and localization in synthetic aperture radar imagery|合成孔径雷达图像中的异常检测与定位的补丁分布建模框架自适应余弦估计器（PaDiM-ACE）|Angelina Ibarra, Joshua Peeples|<http://arxiv.org/pdf/2504.08049v2>|[代码](https://github.com/Advanced-Vision-and-Learning-Lab/PaDiM-ACE.); 提出PaDiM-ACE框架，利用自适应余弦估计器提高SAR图像异常检测与定位性能。|
|🆕 发布|DiGIT: Multi-Dilated Gated Encoder and Central-Adjacent Region Integrated Decoder for Temporal Action Detection Transformer|DiGIT：用于时间动作检测的Transformer的多膨胀门控编码器和中心相邻区域集成解码器|Ho-Joong Kim, Yearang Lee, Jung-Ho Hong, Seong-Whan Lee|<http://arxiv.org/pdf/2505.05711v1>|[代码](https://github.com/Dotori-HJ/DiGIT); DiGIT通过多尺度门控编码器和中心相邻区域集成解码器，有效解决了时间动作检测中的特征冗余和时间上下...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Directed-CP: Directed Collaborative Perception for Connected and Autonomous Vehicles via Proactive Attention|定向-CP：通过主动注意力实现连接和自动驾驶汽车的定向协作感知|Yihang Tao, Senkang Hu, Zhengru Fang, Yuguang Fang|<http://arxiv.org/pdf/2409.08840v3>|提出一种针对自动驾驶车辆的方向感知协同感知系统，通过主动关注特定方向提高感知精度。|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation|群智生成：零样本文本驱动集体运动生成|Yukang Cao, Xinying Guo, Mingyuan Zhang, Haozhe Xie, Chenyang Gu, Ziwei Liu|<http://arxiv.org/pdf/2407.06188v2>|CrowdMoGen首次实现零样本集体运动生成，通过文本驱动有效分组和生成事件同步动作序列。|
|🆕 发布|ArtRAG: Retrieval-Augmented Generation with Structured Context for Visual Art Understanding|艺术RAG：结构化上下文增强的视觉艺术理解检索生成|Shuai Wang, Ivona Najdenkoska, Hongyi Zhu, Stevan Rudinac, Monika Kackovic, Nachoem Wijnberg, Marcel Worring|<http://arxiv.org/pdf/2505.06020v1>|ArtRAG通过结合结构化知识和检索增强生成，实现了对艺术作品的多元视角理解和描述。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MonetGPT: Solving Puzzles Enhances MLLMs' Image Retouching Skills|《MonetGPT：解决谜题提升多模态语言模型图像修复技能》|Niladri Shekhar Dutt, Duygu Ceylan, Niloy J. Mitra|<http://arxiv.org/pdf/2505.06176v1>|通过训练多模态大语言模型解决视觉谜题，提升其图像修复技能，实现可解释且保留原始物体身份的图像编辑。|
|📝 更新|NeurCross: A Neural Approach to Computing Cross Fields for Quad Mesh Generation|神经交叉：用于四叉网格生成的交叉场计算神经网络方法|Qiujie Dong, Huibiao Wen, Rui Xu, Shuangmin Chen, Jiaran Zhou, Shiqing Xin, Changhe Tu, Taku Komura .etc.|<http://arxiv.org/pdf/2405.13745v3>|NeurCross通过优化交叉场和神经距离函数，实现了高质量四边形网格生成，同时平衡了平滑性和曲率方...|
|🆕 发布|Towards Better Cephalometric Landmark Detection with Diffusion Data Generation|朝着更好的头影测量标志点检测：基于扩散数据生成|Dongqian Guo, Wencheng Han, Pang Lyu, Yuxi Zhou, Jianbing Shen|<http://arxiv.org/pdf/2505.06055v1>|[代码](https://um-lab.github.io/cepha-generation); 开发了一种基于扩散数据生成的创新方法，有效提升了头影测量学标志点检测的准确率。|
|📝 更新|Egocentric and Exocentric Methods: A Short Survey|自我中心与外中心方法：简短综述|Anirudh Thatipelli, Shao-Yuan Lo, Amit K. Roy-Chowdhury|<http://arxiv.org/pdf/2410.20621v2>|该论文综述了结合自视角和外部视角的视觉方法，推动了多视角建模在视频理解领域的进展。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DiffLocks: Generating 3D Hair from a Single Image using Diffusion Models|DiffLocks：利用扩散模型从单张图像生成3D头发|Radu Alexandru Rosu, Keyu Wu, Yao Feng, Youyi Zheng, Michael J. Black|<http://arxiv.org/pdf/2505.06166v1>|[代码](https://radualexandru.github.io/difflocks); DiffLocks通过自动生成大规模合成数据集，利用扩散模型从单张图像中直接生成逼真的3D发型。|
|🆕 发布|Why Are You Wrong? Counterfactual Explanations for Language Grounding with 3D Objects|为何错误？基于3D物体的语言定位的逆事实解释|Tobias Preintner, Weixuan Yuan, Qi Huang, Adrian König, Thomas Bäck, Elena Raponi, Niki van Stein|<http://arxiv.org/pdf/2505.06030v1>|提出了一种生成反事实示例的方法，以解释语言定位3D物体时神经网络模型的错误预测。|
|📝 更新|Curriculum Direct Preference Optimization for Diffusion and Consistency Models|课程直接偏好优化：扩散和一致性模型|Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, Nicu Sebe, Mubarak Shah|<http://arxiv.org/pdf/2405.13637v6>|[代码](https://github.com/CroitoruAlin/Curriculum-DPO.); 提出了一种基于课程学习的直接偏好优化方法，有效提升了文本到图像生成模型的质量。|
|🆕 发布|Towards Facial Image Compression with Consistency Preserving Diffusion Prior|面向保持一致性的扩散先验的人脸图像压缩|Yimin Zhou, Yichong Xia, Bin Chen, Baoyi An, Haoqian Wang, Zhi Wang, Yaowei Wang, Zikun Zhou|<http://arxiv.org/pdf/2505.05870v1>|提出了一种基于扩散先验的图像压缩方法，有效提升了面部图像压缩质量。|
|📝 更新|Enhancing Target-unspecific Tasks through a Features Matrix|通过特征矩阵增强目标非特异性任务|Fangming Cui, Yonggang Zhang, Xuan Wang, Xinmei Tian, Jun Yu|<http://arxiv.org/pdf/2505.03414v3>|提出特征矩阵正则化方法，有效提升大视觉语言模型在非特定目标任务上的泛化能力。|
|🆕 发布|PICD: Versatile Perceptual Image Compression with Diffusion Rendering|PICD：基于扩散渲染的通用感知图像压缩|Tongda Xu, Jiahao Li, Bin Li, Yan Wang, Ya-Qin Zhang, Yan Lu|<http://arxiv.org/pdf/2505.05853v1>|提出PICD，一种结合扩散渲染的通用感知图像压缩方法，有效解决屏幕内容压缩中的文本失真问题。|
|🆕 发布|Image Segmentation via Variational Model Based Tailored UNet: A Deep Variational Framework|基于定制UNet的变分模型图像分割：一个深度变分框架|Kaili Qi, Wenli Yang, Ye Li, Zhongyi Huang|<http://arxiv.org/pdf/2505.05806v1>|提出VM_TUNet，融合变分模型与UNet，实现高精度图像分割。|
|🆕 发布|Accelerating Diffusion Transformer via Increment-Calibrated Caching with Channel-Aware Singular Value Decomposition|加速扩散Transformer通过增量校准缓存与通道感知奇异值分解|Zhiyuan Chen, Keyi Li, Yifan Jia, Le Ye, Yufei Ma|<http://arxiv.org/pdf/2505.05829v1>|[代码](https://github.com/ccccczzy/icc.); 提出一种基于增量校准缓存和通道感知奇异值分解的扩散变换器加速方法，显著降低计算复杂度并提升图像生成质...|
|🆕 发布|3D CAVLA: Leveraging Depth and 3D Context to Generalize Vision Language Action Models for Unseen Tasks|3D CAVLA：利用深度和3D上下文泛化未见任务的视觉语言动作模型|Vineet Bhat, Yu-Hsiang Lan, Prashanth Krishnamurthy, Ramesh Karri, Farshad Khorrami|<http://arxiv.org/pdf/2505.05800v1>|通过整合思维链推理、深度感知和任务导向区域检测，3D CAVLA模型提升了视觉语言动作模型在未见任务...|
|📝 更新|MAISY: Motion-Aware Image SYnthesis for Medical Image Motion Correction|MAISY：基于运动感知的医学图像运动校正图像合成|Andrew Zhang, Hao Wang, Shuchang Ye, Michael Fulham, Jinman Kim|<http://arxiv.org/pdf/2505.04105v3>|MAISY通过结合SAM和VS-SSIM，有效纠正医学图像运动伪影，提升图像质量。|
|🆕 发布|Automated Learning of Semantic Embedding Representations for Diffusion Models|自动学习扩散模型的语义嵌入表示|Limai Jiang, Yunpeng Cai|<http://arxiv.org/pdf/2505.05732v1>|提出多级去噪自编码框架，通过自条件扩散学习提升去噪扩散模型语义嵌入表示能力。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|S2MNet: Speckle-To-Mesh Net for Three-Dimensional Cardiac Morphology Reconstruction via Echocardiogram|S2MNet：基于超声心动图的斑点到网格三维心脏形态重建网络|Xilin Gong, Yongkai Chen, Shushan Wu, Fang Wang, Ping Ma, Wenxuan Zhong|<http://arxiv.org/pdf/2505.06105v1>|提出了一种基于深度学习的超声心动图三维心脏形态重建方法，有效提高了重建的连续性和高保真度。|
|📝 更新|From Flatland to Space: Teaching Vision-Language Models to Perceive and Reason in 3D|从平面到空间：教导视觉-语言模型感知和推理三维世界|Jiahui Zhang, Yurui Chen, Yanpeng Zhou, Yueming Xu, Ze Huang, Jilin Mei, Junhui Chen, Yu-Jie Yuan .etc.|<http://arxiv.org/pdf/2503.22976v3>|提出了一种利用空间相关图像数据增强视觉语言模型空间感知能力的方法，显著提升了其在3D场景理解与推理上...|
|🆕 发布|Decoupling Multi-Contrast Super-Resolution: Pairing Unpaired Synthesis with Implicit Representations|解耦多对比超分辨率：配对无监督合成与隐式表示|Hongyu Rui, Yinzhe Wu, Fanwen Wang, Jiahao Huang, Liutao Yang, Zi Wang, Guang Yang|<http://arxiv.org/pdf/2505.05855v1>|提出了一种无需配对训练数据的多对比度超分辨率方法，通过无监督合成和超分辨率重建，实现了可扩展的MRI...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects|《用于重建折射和反射物体的合成数据集和基准》|Yue Yin, Enze Tao, Weijian Deng, Dylan Campbell|<http://arxiv.org/pdf/2505.05848v1>|构建了合成数据集和基准，用于从图像中重建折射和反射物体，并提出了一种基于几何和折射率的精确光路计算方...|


## 时序视觉分析 (Temporal Visual Analysis)


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Task-Adapter++: Task-specific Adaptation with Order-aware Alignment for Few-shot Action Recognition|任务适配++：基于顺序感知对齐的特定任务自适应方法在少样本动作识别中的应用|Congqi Cao, Peiheng Han, Yueran zhang, Yating Yu, Qinyi Lv, Lingtong Min, Yanning zhang|<http://arxiv.org/pdf/2505.06002v1>|[代码](https://github.com/Jaulin-Bage/Task-Adapter-pp.); Task-Adapter++通过任务特定适应和语义顺序对齐，有效提升了少样本动作识别的性能。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CGTrack: Cascade Gating Network with Hierarchical Feature Aggregation for UAV Tracking|CGTrack：用于无人机跟踪的级联门控网络与分层特征聚合|Weihong Li, Xiaoqiong Liu, Heng Fan, Libo Zhang|<http://arxiv.org/pdf/2505.05936v1>|[代码](https://github.com/Nightwatch-Fox11/CGTrack.); 提出CGTrack，通过层次特征聚合和级联门控网络提升无人机跟踪效率和准确性。|
|📝 更新|TAPTRv2: Attention-based Position Update Improves Tracking Any Point|TAPTRv2：基于注意力的位置更新提升任意点跟踪|Hongyang Li, Hao Zhang, Shilong Liu, Zhaoyang Zeng, Feng Li, Tianhe Ren, Bohan Li, Lei Zhang|<http://arxiv.org/pdf/2407.16291v2>|TAPTRv2通过引入注意力机制的位置更新，有效提升了任意点跟踪任务性能。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 掩码自编码 (Masked Autoencoding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Self-Supervised Pretraining for Fine-Grained Plankton Recognition|自监督预训练用于细粒度浮游生物识别|Joona Kareinen, Tuomas Eerola, Kaisa Kraft, Lasse Lensu, Sanna Suikkanen, Heikki Kälviäinen|<http://arxiv.org/pdf/2503.11341v2>|该论文提出了一种基于自监督预训练的细粒度浮游生物识别方法，显著提升了识别准确率。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VIN-NBV: A View Introspection Network for Next-Best-View Selection for Resource-Efficient 3D Reconstruction|VIN-NBV：一种用于资源高效3D重建的下一最佳视图选择的视角内省网络|Noah Frahm, Dongxu Zhao, Andrea Dunn Beltran, Ron Alterovitz, Jan-Michael Frahm, Junier Oliva, Roni Sengupta|<http://arxiv.org/pdf/2505.06219v1>|提出VIN-NBV网络，通过预测视图质量提升直接优化3D重建，显著提升重建质量。|
|🆕 发布|Camera-Only Bird's Eye View Perception: A Neural Approach to LiDAR-Free Environmental Mapping for Autonomous Vehicles|仅使用相机的鸟瞰视图感知：一种用于自动驾驶汽车的免激光雷达环境映射的神经网络方法|Anupkumar Bochare|<http://arxiv.org/pdf/2505.06113v1>|提出了一种仅用相机输入生成鸟瞰图的环境映射方法，实现低成本且高精度的自动驾驶感知。|
|📝 更新|Replay to Remember (R2R): An Efficient Uncertainty-driven Unsupervised Continual Learning Framework Using Generative Replay|重放以记忆（R2R）：一种高效的基于生成重放的未标记持续学习框架|Sriram Mandalika, Harsha Vardhan, Athira Nambiar|<http://arxiv.org/pdf/2505.04787v2>|提出R2R框架，通过生成式重放和不确定性驱动，实现高效无监督持续学习，有效缓解灾难性遗忘。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Towards Foundation Models and Few-Shot Parameter-Efficient Fine-Tuning for Volumetric Organ Segmentation|面向体积器官分割的基础模型和少样本参数高效微调|Julio Silva-Rodríguez, Jose Dolz, Ismail Ben Ayed|<http://arxiv.org/pdf/2303.17051v4>|提出了一种针对少量样本的参数高效微调方法，以解决医学图像分割中数据稀缺的问题。|
|📝 更新|Human Perception-Inspired Grain Segmentation Refinement Using Conditional Random Fields|基于人类感知的粒度分割细化：条件随机字段的应用|Doruk Aksoy, Huolin L. Xin, Timothy J. Rupert, William J. Bowman|<http://arxiv.org/pdf/2312.09968v2>|引入条件随机字段和感知分组规则，显著提升了电子显微镜图像中晶界分割的准确性和数据分析能力。|
|🆕 发布|From Pixels to Perception: Interpretable Predictions via Instance-wise Grouped Feature Selection|从像素到感知：通过实例分组特征选择的可解释预测|Moritz Vandenhirtz, Julia E. Vogt|<http://arxiv.org/pdf/2505.06003v1>|提出了一种通过实例级分组特征选择实现可解释预测的计算机视觉方法。|
|📝 更新|Mixed Text Recognition with Efficient Parameter Fine-Tuning and Transformer|混合文本识别：高效参数微调和Transformer|Da Chang, Yu Li|<http://arxiv.org/pdf/2404.12734v4>|提出DLoRA-TrOCR，通过高效参数微调Transformer，显著提升混合场景文本识别准确性和...|
|🆕 发布|Automating Infrastructure Surveying: A Framework for Geometric Measurements and Compliance Assessment Using Point Cloud Data|自动化基础设施测绘：基于点云数据的几何测量与合规性评估框架|Amin Ghafourian, Andrew Lee, Dechen Gao, Tyler Beer, Kin Yen, Iman Soltani|<http://arxiv.org/pdf/2505.05752v1>|[代码](https://github.com/Soltanilara/SurveyAutomation.); 提出了一种利用点云数据和深度学习自动化基础设施测量和合规性评估的框架，显著提高效率和准确性。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Towards AI-Driven Policing: Interdisciplinary Knowledge Discovery from Police Body-Worn Camera Footage|迈向人工智能驱动的警务：从警察佩戴式摄像头录像中实现跨学科知识发现|Anita Srbinovska, Angela Srbinovska, Vivek Senthil, Adrian Martin, John McCluskey, Jonathan Bateman, Ernest Fokoué|<http://arxiv.org/pdf/2504.20007v2>|提出了一种利用AI和机器学习分析警察执法视频，以识别警察与民众互动行为模式的新框架。|
|📝 更新|Image space formalism of convolutional neural networks for k-space interpolation|卷积神经网络在k空间插值中的图像空间形式|Peter Dawood, Felix Breuer, Istvan Homolya, Maximilian Gram, Peter M. Jakob, Moritz Zaiss, Martin Blaimer|<http://arxiv.org/pdf/2402.17410v2>|引入图像空间形式化方法，分析卷积神经网络在k空间插值中的非线性激活对噪声鲁棒性的影响。|
|📝 更新|Visualization of a multidimensional point cloud as a 3D swarm of avatars|多维点云作为3D化身群的可视化|Leszek Luchowski, Dariusz Pojda|<http://arxiv.org/pdf/2504.06751v2>|提出了一种将多维数据可视化为一群3D头像的新方法，通过面部表情模拟数据特征，辅助数据分析和探索。|
|🆕 发布|Predicting Diabetic Macular Edema Treatment Responses Using OCT: Dataset and Methods of APTOS Competition|利用OCT预测糖尿病黄斑水肿治疗反应：APTOS竞赛数据集与方法|Weiyi Zhang, Peranut Chotcomwongse, Yinwen Li, Pusheng Xu, Ruijie Yao, Lianhao Zhou, Yuxuan Zhou, Hui Feng .etc.|<http://arxiv.org/pdf/2505.05768v1>|首次通过APTOS竞赛，利用OCT图像预测糖尿病黄斑水肿治疗反应，推动个性化治疗策略。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Wasserstein Distances Made Explainable: Insights into Dataset Shifts and Transport Phenomena|Wasserstein距离的可解释性：数据集偏移和传输现象的见解|Philip Naumann, Jacob Kauffmann, Grégoire Montavon|<http://arxiv.org/pdf/2505.06123v1>|提出可解释的Wasserstein距离方法，准确归因数据差异，揭示数据变化原因。|
|📝 更新|Threshold Modulation for Online Test-Time Adaptation of Spiking Neural Networks|阈值调制用于脉冲神经网络在线测试时自适应|Kejie Zhao, Wenjia Hua, Aiersi Tuerhong, Luziwei Leng, Yuxin Ma, Qinghai Guo|<http://arxiv.org/pdf/2505.05375v2>|[代码](https://github.com/NneurotransmitterR/TM-OTTA-SNN.); 提出了一种适用于脉冲神经网络在线测试时自适应的阈值调制方法，有效提升了模型对分布变化的鲁棒性。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Neuro-Symbolic Concepts|神经符号概念|Jiayuan Mao, Joshua B. Tenenbaum, Jiajun Wu|<http://arxiv.org/pdf/2505.06191v1>|提出概念中心范式，利用神经符号概念实现跨域任务学习和零样本迁移。|
|🆕 发布|Anymate: A Dataset and Baselines for Learning 3D Object Rigging|Anymate：用于学习3D物体绑定的数据集和基线|Yufan Deng, Yuhao Zhang, Chen Geng, Shangzhe Wu, Jiajun Wu|<http://arxiv.org/pdf/2505.06227v1>|[代码](https://anymate3d.github.io/.); 构建大规模3D资产数据集，提出学习型自动绑定框架，显著提升3D动画自动化制作效率。|
|🆕 发布|TREND: Tri-teaching for Robust Preference-based Reinforcement Learning with Demonstrations|趋势：基于演示的鲁棒偏好强化学习的三重教学|Shuaiyi Huang, Mara Levy, Anubhav Gupta, Daniel Ekpo, Ruijie Zheng, Abhinav Shrivastava|<http://arxiv.org/pdf/2505.06079v1>|[代码](https://shuaiyihuang.github.io/publications); 提出TREND框架，通过三重教学策略和少量专家演示，有效降低偏好强化学习中的噪声问题。|
|📝 更新|Structure-preserving contrastive learning for spatial time series|空间时间序列的结构保持对比学习|Yiru Jiao, Sander van Cranenburgh, Simeon Calvert, Hans van Lint|<http://arxiv.org/pdf/2502.06380v3>|[代码](https://github.com/yiru-jiao/spclt); 提出了一种结构保持对比学习方法，有效提升了时空序列数据的分类和预测性能。|
|📝 更新|Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding|利用自动CAD标注进行3D场景理解的有监督学习|Yuchen Rao, Stefan Ainetter, Sinisa Stekovic, Vincent Lepetit, Friedrich Fraundorfer|<http://arxiv.org/pdf/2504.13580v2>|利用自动CAD模型检索技术，实现了高质量3D场景标注，显著提升了深度学习模型性能。|
|🆕 发布|Dual-level Fuzzy Learning with Patch Guidance for Image Ordinal Regression|双级模糊学习结合补丁引导的图像序数回归|Chunlai Dong, Haochao Ying, Qibo Qiu, Jinhong Wang, Danny Chen, Jian Wu|<http://arxiv.org/pdf/2505.05834v1>|[代码](https://github.com/ZJUMAI/DFPG-ord.); 提出DFPG框架，通过模糊学习与图像块指导，从模糊的有序标签中学习精确的特征边界，提升图像有序回归性...|
|🆕 发布|A review of advancements in low-light image enhancement using deep learning|低光图像增强深度学习进展综述|Fangxue Liu, Lei Fan|<http://arxiv.org/pdf/2505.05759v1>|系统综述了深度学习在低光图像增强中的应用，分析了不同方法及其对下游视觉任务的影响。|
|🆕 发布|Hybrid Learning: A Novel Combination of Self-Supervised and Supervised Learning for MRI Reconstruction without High-Quality Training Reference|混合学习：一种用于无高质量训练参考的MRI重建的自监督和监督学习的新颖组合|Haoyang Pei, Ding Xia, Xiang Xu, William Moore, Yao Wang, Hersh Chandarana, Li Feng|<http://arxiv.org/pdf/2505.05703v1>|提出混合学习，结合自监督和监督学习，有效提升MRI重建图像质量。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|You Are Your Best Teacher: Semi-Supervised Surgical Point Tracking with Cycle-Consistent Self-Distillation|你是你最好的老师：循环一致性自蒸馏的半监督手术点跟踪|Valay Bundele, Mehran Hosseinzadeh, Hendrik Lensch|<http://arxiv.org/pdf/2505.05722v1>|提出了一种半监督方法，通过循环一致性自蒸馏，将合成数据集训练的点跟踪器适应手术视频。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 目标导向视觉决策 (Goal-oriented Visual Decision Making)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Let Humanoids Hike! Integrative Skill Development on Complex Trails|让类人机器人徒步旅行！复杂路径上的综合技能发展|Kwan-Yee Lin, Stella X. Yu|<http://arxiv.org/pdf/2505.06218v1>|提出了一种集成技能发展框架，使机器人能在复杂地形上自主徒步旅行。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MMMORRF: Multimodal Multilingual Modularized Reciprocal Rank Fusion|多模态多语言模块化互信息排序融合|Saron Samuel, Dan DeGenaro, Jimena Guallar-Blasco, Kate Sanders, Oluwaseun Eisape, Tanner Spendlove, Arun Reddy, Alexander Martin .etc.|<http://arxiv.org/pdf/2503.20698v4>|提出了一种融合多模态信息的视频检索方法，显著提升了检索效果。|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Locality-aware Cross-modal Correspondence Learning for Dense Audio-Visual Events Localization|局部感知跨模态对应学习用于密集音频-视觉事件定位|Ling Xing, Hongyu Qu, Rui Yan, Xiangbo Shu, Jinhui Tang|<http://arxiv.org/pdf/2409.07967v4>|提出一种基于局部连续性的跨模态对应学习框架，有效解决音频-视觉事件定位中的模态异步问题。|
|🆕 发布|Leveraging Vision-Language Models for Visual Grounding and Analysis of Automotive UI|利用视觉-语言模型进行汽车UI视觉定位与分析|Benjamin Raphael Ernhofer, Daniil Prokhorov, Jannica Langner, Dominik Bollmann|<http://arxiv.org/pdf/2505.05895v1>|提出了一种基于视觉语言模型的车载UI视觉定位与分析框架，显著提升了UI理解与交互性能。|
|🆕 发布|Semantic-Space-Intervened Diffusive Alignment for Visual Classification|语义空间介入的扩散对齐用于视觉分类|Zixuan Li, Lei Meng, Guoqing Chao, Wei Wu, Xiaoshuo Yan, Yimeng Yang, Zhuang Qi, Xiangxu Meng|<http://arxiv.org/pdf/2505.05721v1>|提出SeDA方法，通过语义空间干预和渐进式特征交互，有效解决跨模态视觉分类中的特征对齐问题。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Distributional Drift Detection in Medical Imaging with Sketching and Fine-Tuned Transformer|基于草图和微调变换器的医学影像分布漂移检测|Yusen Wu, Phuong Nguyen, Rose Yesha, Yelena Yesha|<http://arxiv.org/pdf/2408.08456v2>|提出了一种利用数据草图和微调技术检测医学图像分布漂移的方法，显著提升了模型准确性和鲁棒性。|
|🆕 发布|BrainSegDMlF: A Dynamic Fusion-enhanced SAM for Brain Lesion Segmentation|脑损伤分割动态融合增强的SAM|Hongming Wang, Yifeng Wu, Huimin Huang, Hongtao Wu, Jia-Xuan Jiang, Xiaodong Zhang, Hao Zheng, Xian Wu .etc.|<http://arxiv.org/pdf/2505.06133v1>|开发了一种融合多模态信息、自动分割脑部病变的动态融合增强SAM模型，有效提升了小病变检测和诊断效率。|
|🆕 发布|MM-Skin: Enhancing Dermatology Vision-Language Model with an Image-Text Dataset Derived from Textbooks|MM-Skin：基于教科书图像-文本数据集增强皮肤病学视觉-语言模型的MM-Skin：基于教科书图像-文本数据集增强皮肤病学视觉-语言模型|Wenqi Zeng, Yuqi Sun, Chenxi Ma, Weimin Tan, Bo Yan|<http://arxiv.org/pdf/2505.06152v1>|[代码](https://github.com/ZwQ803/MM-Skin); 构建了首个大规模皮肤病学图像-文本数据集MM-Skin，并开发了针对皮肤疾病诊断的视觉语言模型Ski...|
|🆕 发布|The Application of Deep Learning for Lymph Node Segmentation: A Systematic Review|深度学习在淋巴结分割中的应用：系统综述|Jingguo Qu, Xinyang Han, Man-Lik Chui, Yao Pu, Simon Takadiyi Gunda, Ziman Chen, Jing Qin, Ann Dorothy King .etc.|<http://arxiv.org/pdf/2505.06118v1>|首次全面综述了深度学习在淋巴结分割中的应用，探讨了提升癌症诊断和治疗的策略。|
|🆕 发布|Noise-Consistent Siamese-Diffusion for Medical Image Synthesis and Segmentation|噪声一致性Siamese-Diffusion在医学图像合成与分割中的应用|Kunpeng Qiu, Zhiqiang Gao, Zhiying Zhou, Mingjie Sun, Yongxin Guo|<http://arxiv.org/pdf/2505.06068v1>|提出Siamese-Diffusion模型，结合噪声一致性提升医学图像合成与分割性能。|
|🆕 发布|Photovoltaic Defect Image Generator with Boundary Alignment Smoothing Constraint for Domain Shift Mitigation|光伏缺陷图像生成器：用于域迁移缓解的边界对齐平滑约束|Dongying Li, Binyi Su, Hua Zhang, Yong Li, Haiyong Chen|<http://arxiv.org/pdf/2505.06117v1>|提出PDIG，一种结合语义嵌入和工业风格适配的稳定扩散模型，有效缓解光伏缺陷图像生成中的数据稀缺和领...|
|📝 更新|FF-PNet: A Pyramid Network Based on Feature and Field for Brain Image Registration|FF-PNet：基于特征和域的脑图像配准金字塔网络|Ying Zhang, Shuai Guo, Chenxi Sun, Yuchen Zhu, Jinhai Xiang|<http://arxiv.org/pdf/2505.04938v2>|FF-PNet通过并行提取粗细粒度特征，有效提升了脑图像配准的效率和精度。|
|🆕 发布|DFEN: Dual Feature Equalization Network for Medical Image Segmentation|双重特征均衡网络：用于医学图像分割|Jianjian Yin, Yi Chen, Chengyu Li, Zhichao Zheng, Yanhui Gu, Junsheng Zhou|<http://arxiv.org/pdf/2505.05913v1>|[代码](https://github.com/JianJianYin/DFEN.); 提出DFEN网络，通过图像级和类别级特征均衡，提升医学图像分割精度。|
|🆕 发布|Automated Knot Detection and Pairing for Wood Analysis in the Timber Industry|木材行业中的自动结检测与配对技术|Guohao Lin, Shidong Pan, Rasul Khanbayov, Changxi Yang, Ani Khaloian-Sarnaghi, Andriy Kovryga|<http://arxiv.org/pdf/2505.05845v1>|提出了一种基于机器学习的木材结点检测与配对自动化方法，提高木材加工效率。|
|🆕 发布|Towards order of magnitude X-ray dose reduction in breast cancer imaging using phase contrast and deep denoising|朝着通过相位对比和深度去噪在乳腺癌成像中实现数量级X射线剂量降低的研究|Ashkan Pakzad, Robert Turnbull, Simon J. Mutch, Thomas A. Leatham, Darren Lockie, Jane Fox, Beena Kumar, Daniel Häsermann .etc.|<http://arxiv.org/pdf/2505.05812v1>|通过相位对比成像和深度去噪技术，实现了乳腺癌成像中X射线剂量降低16倍以上，同时保持图像质量。|
|🆕 发布|Describe Anything in Medical Images|在医学图像中描述任何内容|Xi Xiao, Yunbei Zhang, Thanh-Huy Nguyen, Ba-Thinh Lam, Janet Wang, Jihun Hamm, Tianyang Wang, Xingjian Li .etc.|<http://arxiv.org/pdf/2505.05804v1>|提出MedDAM框架，利用大视觉语言模型实现医学图像区域描述，提升临床诊断准确性。|
|🆕 发布|Improving Generalizability of Kolmogorov-Arnold Networks via Error-Correcting Output Codes|通过纠错输出码提高 Kolmogorov-Arnold 网络的泛化能力|Youngjoon Lee, Jinu Gong, Joonhyuk Kang|<http://arxiv.org/pdf/2505.05798v1>|将ECOC融入KAN框架，提升多类医疗图像分类的泛化能力。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Examining the Source of Defects from a Mechanical Perspective for 3D Anomaly Detection|从机械角度分析3D异常检测中缺陷来源|Hanzhe Liang, Aoran Wang, Jie Zhou, Xin Jin, Can Gao, Jinbao Wang|<http://arxiv.org/pdf/2505.05901v1>|[代码](https://github.com/hzzzzzhappy/MC4AD); 提出了一种基于力学互补框架的3D异常检测方法，通过预测内外部修正力来识别和纠正异常。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RS2AD: End-to-End Autonomous Driving Data Generation from Roadside Sensor Observations|RS2AD：基于路边传感器观测的端到端自动驾驶数据生成|Ruidan Xing, Runyi Huang, Qing Xu, Lei He|<http://arxiv.org/pdf/2503.07085v3>|RS2AD通过路边传感器观测重建车载激光雷达数据，有效提升自动驾驶数据生成效率。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dome-DETR: DETR with Density-Oriented Feature-Query Manipulation for Efficient Tiny Object Detection|穹顶-DETR：基于密度导向特征查询操作的DETR高效微小目标检测|Zhangchi Hu, Peixi Wu, Jie Chen, Huyue Zhu, Yijun Wang, Yansong Peng, Hebei Li, Xiaoyan Sun|<http://arxiv.org/pdf/2505.05741v1>|提出Dome-DETR，通过密度导向特征查询操作，高效检测小目标，降低计算复杂度。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Topo-VM-UNetV2: Encoding Topology into Vision Mamba UNet for Polyp Segmentation|拓扑-VM-UNetV2：将拓扑编码到视觉Mamba UNet中进行息肉分割|Diego Adame, Jose A. Nunez, Fabian Vazquez, Nayeli Gurrola, Huimin Li, Haoteng Tang, Bin Fu, Pengfei Gu|<http://arxiv.org/pdf/2505.06210v1>|将拓扑特征编码进Mamba架构的VM-UNetV2，提升息肉分割精度。|
|🆕 发布|Register and CLS tokens yield a decoupling of local and global features in large ViTs|注册和CLS标记实现大ViTs中局部和全局特征的解耦|Alexander Lappe, Martin A. Giese|<http://arxiv.org/pdf/2505.05892v1>|通过引入注册和CLS标记，论文解决了大视觉Transformer中局部和全局特征解耦的问题，提升了模...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|kFuse: A novel density based agglomerative clustering|kFuse：一种基于密度的层次聚类新方法|Huan Yan, Junjie Hu|<http://arxiv.org/pdf/2505.05748v1>|kFuse通过自然邻域划分、边界连通性计算和密度相似度评估，改进了基于密度的层次聚类方法，提高了聚类...|

