## [UPDATED!] **2025-05-10** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Symbolic Rule Extraction from Attention-Guided Sparse Representations in Vision Transformers|从视觉Transformer中的注意力引导稀疏表示中提取符号规则|Parth Padalkar, Gopal Gupta|<http://arxiv.org/pdf/2505.06745v1>|提出了一种从视觉Transformer中提取可解释规则的方法，通过引入稀疏概念层实现。|
|📝 更新|TGBFormer: Transformer-GraphFormer Blender Network for Video Object Detection|TGBFormer：用于视频目标检测的Transformer-GraphFormer混合网络|Qiang Qi, Xiao Wang|<http://arxiv.org/pdf/2503.13903v2>|提出TGBFormer，融合Transformer和图卷积网络优势，提升视频目标检测性能。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HAMSTER: Hierarchical Action Models For Open-World Robot Manipulation|层次化动作模型用于开放式机器人操作：HAMSTER|Yi Li, Yuquan Deng, Jesse Zhang, Joel Jang, Marius Memmel, Raymond Yu, Caelan Reed Garrett, Fabio Ramos .etc.|<http://arxiv.org/pdf/2502.05485v4>|提出了一种分层视觉-语言-动作模型，有效利用离域数据提升机器人操作成功率。|
|📝 更新|An Active Contour Model for Silhouette Vectorization using Bézier Curves|基于贝塞尔曲线的轮廓矢量化的主动轮廓模型|Luis Alvarez, Jean-Michel Morel|<http://arxiv.org/pdf/2505.05132v2>|提出了一种基于贝塞尔曲线的轮廓矢量化方法，有效降低轮廓与矢量化之间的平均距离。|
|🆕 发布|Improving Generalization of Medical Image Registration Foundation Model|提升医学图像配准基础模型泛化能力|Jing Hu, Kaiwei Yu, Hongjiang Xian, Shu Hu, Xin Wang|<http://arxiv.org/pdf/2505.06527v1>|[代码](https://github.com/Promise13/fm_sam); 将SAM优化融入基础模型，提升医学图像配准的泛化能力和鲁棒性。|
|🆕 发布|Text-to-CadQuery: A New Paradigm for CAD Generation with Scalable Large Model Capabilities|文本到CADQuery：具有可扩展大型模型能力的CAD生成新范式|Haoyang Xie, Feng Ju|<http://arxiv.org/pdf/2505.06507v1>|[代码](https://github.com/Text-to-CadQuery/Text-to-CadQuery.); 提出了一种直接从文本生成CadQuery代码的新方法，利用预训练的大型语言模型生成3D模型，显著提升...|
|📝 更新|When SAM2 Meets Video Camouflaged Object Segmentation: A Comprehensive Evaluation and Adaptation|当SAM2遇见视频伪装目标分割：全面评估与适应|Yuli Zhou, Guolei Sun, Yawei Li, Guo-Sen Xie, Luca Benini, Ender Konukoglu|<http://arxiv.org/pdf/2409.18653v2>|[代码](https://github.com/zhoustan/SAM2-VCOS); 提出了一种基于SAM2的视频伪装物体分割方法，显著提升了检测准确率。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Emotion-Qwen: Training Hybrid Experts for Unified Emotion and General Vision-Language Understanding|情感-Qwen：训练混合专家以实现统一的情感和通用视觉-语言理解|Dawei Huang, Qing Li, Chuan Yan, Zebang Cheng, Yurong Huang, Xiang Li, Bin Li, Xiaohui Wang .etc.|<http://arxiv.org/pdf/2505.06685v1>|提出Emotion-Qwen，通过混合专家模型和大规模数据集，提升视频情感理解和通用视觉语言理解能力...|
|📝 更新|GarmentDiffusion: 3D Garment Sewing Pattern Generation with Multimodal Diffusion Transformers|服装扩散：基于多模态扩散变换器的3D服装缝纫图案生成|Xinyu Li, Qi Yao, Yuanda Wang|<http://arxiv.org/pdf/2504.21476v2>|[代码](https://shenfu-research.github.io/Garment-Diffusion); 提出GarmentDiffusion，一种高效生成精确3D服装缝纫图案的多模态扩散模型。|
|🆕 发布|Integrating Video and Text: A Balanced Approach to Multimodal Summary Generation and Evaluation|视频与文本融合：多模态摘要生成与评估的平衡方法|Galann Pennec, Zhengyuan Liu, Nicholas Asher, Philippe Muller, Nancy F. Chen|<http://arxiv.org/pdf/2505.06594v1>|提出零样本视频到文本摘要方法，结合视觉和文本信息，并引入MFactSum评估指标。|
|🆕 发布|TACFN: Transformer-based Adaptive Cross-modal Fusion Network for Multimodal Emotion Recognition|基于Transformer的自适应跨模态融合网络用于多模态情感识别|Feng Liu, Ziwang Fu, Yunlong Wang, Qijian Zheng|<http://arxiv.org/pdf/2505.06536v1>|[代码](https://github.com/shuzihuaiyu/TACFN.); 设计了一种基于Transformer的适应性跨模态融合网络，有效提升了多模态情感识别性能。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Condition numbers in multiview geometry, instability in relative pose estimation, and RANSAC|多视图几何中的条件数、相对姿态估计的不稳定性和RANSAC|Hongyi Fan, Joe Kileel, Benjamin Kimia|<http://arxiv.org/pdf/2310.02719v2>|提出了一种分析多视图几何中条件数的方法，以解决基于RANSAC的相对位姿估计的不稳定性问题。|
|🆕 发布|Minimizing Risk Through Minimizing Model-Data Interaction: A Protocol For Relying on Proxy Tasks When Designing Child Sexual Abuse Imagery Detection Models|通过最小化模型-数据交互来最小化风险：设计儿童性虐待图像检测模型时依赖代理任务的协议|Thamiris Coelho, Leo S. F. Ribeiro, João Macedo, Jefersson A. dos Santos, Sandra Avila|<http://arxiv.org/pdf/2505.06621v1>|提出了一种利用代理任务设计儿童色情图像检测模型的协议，以减少模型与敏感数据的交互，降低风险。|
|📝 更新|Enhancing Layer Attention Efficiency through Pruning Redundant Retrievals|通过剪枝冗余检索增强层注意力效率|Hanze Li, Xiande Huang|<http://arxiv.org/pdf/2503.06473v4>|通过量化相邻层之间的冗余并跳过冗余层，提出的方法显著提高了训练效率和模型性能。|
|📝 更新|CCi-YOLOv8n: Enhanced Fire Detection with CARAFE and Context-Guided Modules|CCi-YOLOv8n：基于CARAFE和上下文引导模块的增强火焰检测|Kunwei Lv, Ruobing Wu, Suyang Chen, Ping Lan|<http://arxiv.org/pdf/2411.11011v2>|提出CCi-YOLOv8n模型，结合CARAFE和上下文引导模块，有效提升火灾检测精度。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FNBench: Benchmarking Robust Federated Learning against Noisy Labels|FNBench：针对噪声标签的鲁棒联邦学习的基准测试|Xuefeng Jiang, Jia Li, Nannan Wu, Zhiyuan Wu, Xujing Li, Sheng Sun, Gang Xu, Yuwei Wang .etc.|<http://arxiv.org/pdf/2505.06684v1>|[代码](https://github.com/Sprinter1999/FNBench.); 提出FNBench基准，全面评估联邦学习在噪声标签下的鲁棒性。|
|🆕 发布|Compact and Efficient Neural Networks for Image Recognition Based on Learned 2D Separable Transform|紧凑高效的基于学习二维可分离变换的图像识别神经网络|Maxim Vashkevich, Egor Krivalcevich|<http://arxiv.org/pdf/2505.06578v1>|[代码](https://github.com/Mak-Sim/LST-2d); 提出了一种基于学习二维可分离变换的紧凑高效神经网络，显著减少模型参数并提高识别准确率。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Reducing Unimodal Bias in Multi-Modal Semantic Segmentation with Multi-Scale Functional Entropy Regularization|降低多模态语义分割中单模态偏差的多尺度功能熵正则化|Xu Zheng, Yuanhuiyi Lyu, Lutao Jiang, Danda Pani Paudel, Luc Van Gool, Xuming Hu|<http://arxiv.org/pdf/2505.06635v1>|通过多尺度功能熵正则化，该论文缓解了多模态语义分割中的单模态偏差问题，提升了分割性能。|
|🆕 发布|RESAR-BEV: An Explainable Progressive Residual Autoregressive Approach for Camera-Radar Fusion in BEV Segmentation|RESAR-BEV：一种用于BEV分割中相机-雷达融合的可解释渐进残差自回归方法|Zhiwen Zeng, Yunfei Yin, Zheng Yuan, Argho Dey, Xianjian Bao|<http://arxiv.org/pdf/2505.06515v1>|提出了一种渐进式残差自回归方法，有效解决BEV分割中的多模态对齐和传感器噪声问题。|
|📝 更新|Leveraging Modified Ex Situ Tomography Data for Segmentation of In Situ Synchrotron X-Ray Computed Tomography|利用改进的离体断层扫描数据对原位同步辐射X射线计算机断层扫描进行分割|Tristan Manchester, Adam Anders, Julio Spadotto, Hannah Eccleston, William Beavan, Hugues Arcis, Brian J. Connolly|<http://arxiv.org/pdf/2504.19200v2>|利用改进的离体断层扫描数据训练模型，实现原位同步辐射X射线断层扫描数据的快速、高精度分割。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Latent Feature-Guided Diffusion Models for Shadow Removal|潜特征引导的阴影去除扩散模型|Kangfu Mei, Luis Figueroa, Zhe Lin, Zhihong Ding, Scott Cohen, Vishal M. Patel|<http://arxiv.org/pdf/2312.02156v2>|提出了一种基于扩散模型和潜在特征空间的阴影去除方法，显著提升了图像质量。|
|🆕 发布|UnfoldIR: Rethinking Deep Unfolding Network in Illumination Degradation Image Restoration|展开红外：在光照退化图像恢复中重新思考深度展开网络|Chunming He, Rihan Zhang, Fengyang Xiao, Chengyu Fang, Longxiang Tang, Yulun Zhang, Sina Farsiu|<http://arxiv.org/pdf/2505.06683v1>|提出UnfoldIR方法，通过优化展开结构提升光照退化图像修复性能。|
|🆕 发布|Video Dataset Condensation with Diffusion Models|视频数据集压缩与扩散模型|Zhe Li, Hadrien Reynaud, Mischa Dombrowski, Sarah Cechnicka, Franciskus Xaverius Erick, Bernhard Kainz|<http://arxiv.org/pdf/2505.06670v1>|利用视频扩散模型和VST-UNet，提出了一种高效的视频数据集浓缩方法，显著提升了视频数据集蒸馏的性...|
|🆕 发布|MultiTaskVIF: Segmentation-oriented visible and infrared image fusion via multi-task learning|多任务VIF：基于多任务学习的面向分割的可见光与红外图像融合|Zixian Zhao, Andrew Howes, Xingchen Zhang|<http://arxiv.org/pdf/2505.06665v1>|提出了一种基于多任务学习的简化结构，有效提升了可见光与红外图像融合的语义信息整合效率。|
|🆕 发布|GRACE: Estimating Geometry-level 3D Human-Scene Contact from 2D Images|GRACE：从2D图像估计几何级3D人-场景接触|Chengfeng Wang, Wei Zhai, Yuhang Yang, Yang Cao, Zhengjun Zha|<http://arxiv.org/pdf/2505.06575v1>|GRACE通过结合点云编码解码架构和层次特征提取融合，实现了从2D图像到3D人体场景接触的几何级估计...|
|🆕 发布|ReplayCAD: Generative Diffusion Replay for Continual Anomaly Detection|ReplayCAD：用于持续异常检测的生成扩散重放|Lei Hu, Zhiyong Gan, Ling Deng, Jinglin Liang, Lingyu Liang, Shuangping Huang, Tianshui Chen|<http://arxiv.org/pdf/2505.06603v1>|[代码](https://github.com/HULEI7/ReplayCAD.); ReplayCAD通过生成性回放历史数据，有效保留像素级细节，提升持续异常检测的分割性能。|
|🆕 发布|HDGlyph: A Hierarchical Disentangled Glyph-Based Framework for Long-Tail Text Rendering in Diffusion Models|HDGlyph：基于层次解耦字元的长尾文本渲染在扩散模型中的框架|Shuhan Zhuang, Mengqi Huang, Fengyi Fu, Nan Chen, Bohan Lei, Zhendong Mao|<http://arxiv.org/pdf/2505.06543v1>|提出HDGlyph框架，通过分层解耦字符生成和视觉合成，有效提升长尾文本渲染效果。|
|📝 更新|Enhancing Wide-Angle Image Using Narrow-Angle View of the Same Scene|利用同一场景的窄角视图增强广角图像|Hussain Md. Safwan, Mahbub Islam Mahim|<http://arxiv.org/pdf/2504.09455v2>|提出了一种利用窄角图像细节增强宽角图像的新方法，通过GAN模型实现视觉质量参数的迁移。|
|🆕 发布|Causal Prompt Calibration Guided Segment Anything Model for Open-Vocabulary Multi-Entity Segmentation|因果提示校准引导的开放词汇多实体分割Segment Anything模型|Jingyao Wang, Jianqi Zhang, Wenwen Qiang, Changwen Zheng|<http://arxiv.org/pdf/2505.06524v1>|提出了一种基于因果提示校准的Segment Anything模型，有效解决了开放词汇多实体分割的泛化...|
|📝 更新|EDEN: Enhanced Diffusion for High-quality Large-motion Video Frame Interpolation|EDEN：用于高质量大运动视频帧插值的增强扩散|Zihao Zhang, Haoran Chen, Haoyu Zhao, Guansong Lu, Yanwei Fu, Hang Xu, Zuxuan Wu|<http://arxiv.org/pdf/2503.15831v2>|EDEN通过增强扩散模型和引入时间注意力，实现了高质量大运动视频帧插值。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Opt-In Art: Learning Art Styles Only from Few Examples|《仅从少量示例中学习艺术风格：自愿艺术》|Hui Ren, Joanna Materzynska, Rohit Gandikota, David Bau, Antonio Torralba|<http://arxiv.org/pdf/2412.00176v2>|通过仅用少量示例，该论文展示了无需绘画数据预训练，模型也能学习艺术风格。|
|🆕 发布|Jailbreaking the Text-to-Video Generative Models|破解文本到视频生成模型|Jiayang Liu, Siyuan Liang, Shiqian Zhao, Rongcheng Tu, Wenbo Zhou, Xiaochun Cao, Dacheng Tao, Siew Kei Lam|<http://arxiv.org/pdf/2505.06679v1>|提出首个针对文本到视频生成模型的安全漏洞攻击方法，有效生成安全内容绕过检测。|
|🆕 发布|StableMotion: Repurposing Diffusion-Based Image Priors for Motion Estimation|稳定运动：将基于扩散的图像先验重新用于运动估计|Ziyi Wang, Haipeng Li, Lin Sui, Tianhao Zhou, Hai Jiang, Lang Nie, Shuaicheng Liu|<http://arxiv.org/pdf/2505.06668v1>|StableMotion利用扩散模型知识，提出自适应集成策略和采样步骤灾难概念，实现高效运动估计。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ProFashion: Prototype-guided Fashion Video Generation with Multiple Reference Images|ProFashion：基于原型和多参考图像的时尚视频生成|Xianghao Kong, Qiaosong Qi, Yuanbin Wang, Anyi Rao, Biaolong Chen, Aixi Zhang, Si Liu, Hao Jiang|<http://arxiv.org/pdf/2505.06537v1>|提出ProFashion，利用多参考图像生成更一致的时尚视频。|
|📝 更新|MagicPortrait: Temporally Consistent Face Reenactment with 3D Geometric Guidance|魔幻肖像：基于3D几何引导的时间一致性人脸重演|Mengting Wei, Yante Li, Tuomas Varanka, Yan Jiang, Guoying Zhao|<http://arxiv.org/pdf/2504.21497v2>|[代码](https://github.com/weimengting/MagicPortrait.); 提出了一种结合3D几何引导的时序一致人脸重放方法，显著提升了视频人脸生成中的形状一致性和运动控制。|
|🆕 发布|HCMA: Hierarchical Cross-model Alignment for Grounded Text-to-Image Generation|HCMA：基于层次交叉模型对齐的 grounded 文本到图像生成|Hang Wang, Zhi-Qi Cheng, Chenhao Lin, Chao Shen, Lei Zhang|<http://arxiv.org/pdf/2505.06512v1>|[代码](https://github.com/hwang-cs-ime/HCMA); 提出HCMA框架，通过层次跨模态对齐实现语义精确的文本到图像生成。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Edge-Enabled VIO with Long-Tracked Features for High-Accuracy Low-Altitude IoT Navigation|边缘增强的基于长追踪特征的VIO，用于高精度低空物联网导航|Xiaohong Huang, Cui Yang, Miaowen Wen|<http://arxiv.org/pdf/2505.06517v1>|提出一种结合长追踪特征和主动解耦机制的高精度低空物联网导航视觉里程计方法。|
|🆕 发布|CompSLAM: Complementary Hierarchical Multi-Modal Localization and Mapping for Robot Autonomy in Underground Environments|互补分层多模态定位与建图，用于地下环境中的机器人自主导航|Shehryar Khattak, Timon Homberger, Lukas Bernreiter, Julian Nubert, Olov Andersson, Roland Siegwart, Kostas Alexis, Marco Hutter|<http://arxiv.org/pdf/2505.06483v1>|分类SLAM算法，在地下环境中实现鲁棒的定位与建图。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unmasking Deep Fakes: Leveraging Deep Learning for Video Authenticity Detection|揭露深度伪造：利用深度学习进行视频真实性检测|Mahmudul Hasan|<http://arxiv.org/pdf/2505.06528v1>|利用深度学习技术，特别是卷积神经网络，识别并检测深度伪造视频。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Feature Representation Transferring to Lightweight Models via Perception Coherence|通过感知一致性将特征表示迁移到轻量级模型|Hai-Vy Nguyen, Fabrice Gamboa, Sixin Zhang, Reda Chhaibi, Serge Gratton, Thierry Giaccone|<http://arxiv.org/pdf/2505.06595v1>|提出一种基于感知一致性的特征表示迁移方法，提升轻量级模型性能。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs|动态合并与虚拟解合并的高效VLMs|Zhenhailong Wang, Senthil Purushwalkam, Caiming Xiong, Silvio Savarese, Heng Ji, Ran Xu|<http://arxiv.org/pdf/2504.17040v2>|[代码](https://mikewangwzhl.github.io/dymu); DyMU通过动态合并和虚拟解合并，有效降低视觉语言模型计算负担，同时保持高性能。|
|📝 更新|Driving with Context: Online Map Matching for Complex Roads Using Lane Markings and Scenario Recognition|驾驶中的上下文：利用车道标记和场景识别进行复杂道路的在线地图匹配|Xin Bi, Zhichao Li, Yuxuan Xia, Panpan Tong, Lijuan Zhang, Yang Chen, Junsheng Fu|<http://arxiv.org/pdf/2505.05007v2>|[代码](https://github.com/TRV-Lab/LMSR-OMM.); 提出了一种结合车道标记和场景识别的在线地图匹配方法，有效提升了复杂道路网络中的匹配精度。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OT-Talk: Animating 3D Talking Head with Optimal Transportation|OT-Talk：使用最优传输动画3D说话头像|Xinmu Wang, Xiang Gao, Xiyun Song, Heather Yu, Zongfang Lin, Liang Peng, Xianfeng Gu|<http://arxiv.org/pdf/2505.01932v2>|OT-Talk利用最优传输优化3D头像动画，实现更自然准确的语音同步面部表情。|
|📝 更新|Multi-QuAD: Multi-Level Quality-Adaptive Dynamic Network for Reliable Multimodal Classification|多级质量自适应动态网络：用于可靠的多模态分类|Shu Shen, C. L. Philip Chen, Tong Zhang|<http://arxiv.org/pdf/2412.14489v3>|Multi-QuAD提出了一种基于质量自适应动态网络的多模态分类方法，显著提升了分类性能和可靠性。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dataset Distillation with Probabilistic Latent Features|基于概率潜在特征的_dataset蒸馏|Zhe Li, Sarah Cechnicka, Cheng Ouyang, Katharina Breininger, Peter Schüffler, Bernhard Kainz|<http://arxiv.org/pdf/2505.06647v1>|提出了一种基于概率潜在特征的合成数据生成方法，有效降低数据集蒸馏的计算成本。|
|🆕 发布|Quantum Conflict Measurement in Decision Making for Out-of-Distribution Detection|量子冲突测量在分布外检测决策中的决策制定|Yilin Dong, Tianyun Zhu, Xinde Li, Jean Dezert, Rigui Zhou, Changming Zhu, Lei Cao, Shuzhi Sam Ge|<http://arxiv.org/pdf/2505.06516v1>|提出量子冲突指标（QCI）以测量决策中的量子质量函数冲突，有效提升异常值检测性能。|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dynamic Uncertainty Learning with Noisy Correspondence for Text-Based Person Search|基于噪声对应关系的动态不确定性学习在文本基础上的人脸搜索|Zequn Xie, Haoming Ji, Lingwei Meng|<http://arxiv.org/pdf/2505.06566v1>|提出DURA框架，通过KFS和DSH-Loss增强文本检索鲁棒性，有效应对噪声数据。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PC-SRGAN: Physically Consistent Super-Resolution Generative Adversarial Network for General Transient Simulations|PC-SRGAN：适用于通用瞬态模拟的物理一致性超分辨率生成对抗网络|Md Rakibul Hasan, Pouria Behnoudfar, Dan MacKinlay, Thomas Poulet|<http://arxiv.org/pdf/2505.06502v1>|[代码](https://github.com/hasan-rakibul/PC-SRGAN); PC-SRGAN通过确保物理一致性，显著提升了图像超分辨率处理的质量和科学应用的可靠性。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SimMIL: A Universal Weakly Supervised Pre-Training Framework for Multi-Instance Learning in Whole Slide Pathology Images|SimMIL：一种适用于全切片病理图像多实例学习的通用弱监督预训练框架|Yicheng Song, Tiancheng Lin, Die Peng, Su Yang, Yi Xu|<http://arxiv.org/pdf/2505.06710v1>|提出SimMIL，通过弱监督预训练和关键组件优化，提升多实例学习在病理图像中的性能。|
|📝 更新|A Lightweight UDF Learning Framework for 3D Reconstruction Based on Local Shape Functions|基于局部形状函数的轻量级UDF学习框架用于3D重建|Jiangbei Hu, Yanggeng Li, Fei Hou, Junhui Hou, Zhebin Zhang, Shengfa Wang, Na Lei, Ying He|<http://arxiv.org/pdf/2407.01330v2>|[代码](https://jbhu67.github.io/LoSF-UDF.github.io.); 提出了一种基于局部形状函数的轻量级UDF学习框架，有效提升了3D点云表面重建的效率和鲁棒性。|
|🆕 发布|Batch Augmentation with Unimodal Fine-tuning for Multimodal Learning|批量增强与单模态微调的多模态学习|H M Dipu Kabir, Subrota Kumar Mondal, Mohammad Ali Moni|<http://arxiv.org/pdf/2505.06592v1>|[代码](https://github.com/dipuk0506/multimodal); 提出了一种结合批量增强和单模态微调的多模态学习方法，以从超声图像和临床文本信息中检测胎儿器官。|
|🆕 发布|Weakly Supervised Temporal Sentence Grounding via Positive Sample Mining|弱监督时间句子定位通过正样本挖掘|Lu Dong, Haiyu Zhang, Hongjie Zhang, Yifei Huang, Zhen-Hua Ling, Yu Qiao, Limin Wang, Yali Wang|<http://arxiv.org/pdf/2505.06557v1>|提出了一种通过正样本挖掘解决弱监督时间句子定位问题的方法，显著提升了模型性能。|
|📝 更新|MambaNUT: Nighttime UAV Tracking via Mamba-based Adaptive Curriculum Learning|曼巴NUT：基于曼巴的适应性课程学习的夜间无人机跟踪|You Wu, Xiangyang Yang, Xucheng Wang, Hengzhou Ye, Dan Zeng, Shuiwang Li|<http://arxiv.org/pdf/2412.00626v3>|[代码](https://github.com/wuyou3474/MambaNUT.); 提出MambaNUT，通过自适应课程学习实现夜间无人机跟踪，降低计算成本并提升性能。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Two-Stage Random Alternation Framework for Zero-Shot Pansharpening|两阶段随机交替框架用于零样本全色增强|Haorui Chen, Zeyu Ren, Jiaxuan Ren, Ran Ran, Jinliang Shao, Jie Huang, Liangjian Deng|<http://arxiv.org/pdf/2505.06576v1>|提出了一种两阶段随机交替框架，有效结合低分辨率图像的监督约束和高分辨率图像的物理特性，实现零样本全色...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|METOR: A Unified Framework for Mutual Enhancement of Objects and Relationships in Open-vocabulary Video Visual Relationship Detection|METOR：开放词汇视频视觉关系检测中对象与关系相互增强的统一框架|Yongqi Wang, Xinxiao Wu, Shuo Yang|<http://arxiv.org/pdf/2505.06663v1>|提出METOR框架，通过联合建模和相互增强，在开放词汇视频视觉关系检测中实现物体检测和关系分类性能提...|
|📝 更新|FusionSORT: Fusion Methods for Online Multi-object Visual Tracking|融合排序：在线多目标视觉跟踪的融合方法|Nathanael L. Baisa|<http://arxiv.org/pdf/2501.00843v3>|提出融合方法解决多目标视觉跟踪中的数据关联问题，提升跟踪准确性。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FocusedAD: Character-centric Movie Audio Description|聚焦AD：以角色为中心的电影音频描述|Xiaojun Ye, Chun Wang, Yiren Song, Sheng Zhou, Liangcheng Li, Jiajun Bu|<http://arxiv.org/pdf/2504.12157v3>|[代码](https://github.com/Thorin215/FocusedAD); 提出FocusedAD框架，通过人物感知和动态先验模块，实现以人物为中心的电影音频描述。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|M3CAD: Towards Generic Cooperative Autonomous Driving Benchmark|M3CAD：迈向通用的协同自动驾驶基准|Morui Zhu, Yongqi Zhu, Yihao Zhu, Qi Chen, Deyuan Qu, Song Fu, Qing Yang|<http://arxiv.org/pdf/2505.06746v1>|[代码](https://github.com/zhumorui/M3CAD); M3CAD构建了首个针对合作自动驾驶的多任务基准，推动研究并提升系统鲁棒性。|
|📝 更新|GeoGround: A Unified Large Vision-Language Model for Remote Sensing Visual Grounding|GeoGround：一种用于遥感视觉定位的统一大型视觉-语言模型|Yue Zhou, Mengcheng Lan, Xiang Li, Litong Feng, Yiping Ke, Xue Jiang, Qingyun Li, Xue Yang .etc.|<http://arxiv.org/pdf/2411.11904v3>|[代码](https://github.com/zytx121/GeoGround); GeoGround提出统一框架，支持多种遥感视觉定位任务，提升视觉语言模型在密集预测任务上的表现。|
|📝 更新|A Vision Centric Remote Sensing Benchmark|视觉中心遥感基准|Abduljaleel Adejumo, Faegheh Yeganli, Clifford Broni-bediako, Aoran Xiao, Naoto Yokoya, Mennatullah Siam|<http://arxiv.org/pdf/2503.15816v3>|构建了RSMMVP基准，评估MLLMs在RS任务中的表现，揭示CLIP模型在视觉编码上的局限性。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Underwater object detection in sonar imagery with detection transformer and Zero-shot neural architecture search|水下声纳图像中的目标检测：基于检测转换器和零样本神经架构搜索|XiaoTong Gu, Shengyu Tang, Yiming Cao, Changdong Yu|<http://arxiv.org/pdf/2505.06694v1>|提出了一种结合检测Transformer和零样本神经架构搜索的声呐图像目标检测方法，显著提升了检测性...|
|📝 更新|ReXGradient-160K: A Large-Scale Publicly Available Dataset of Chest Radiographs with Free-text Reports|ReXGradient-160K：一个包含自由文本报告的大规模公开胸部X光片数据集|Xiaoman Zhang, Julián N. Acosta, Josh Miller, Ouwen Huang, Pranav Rajpurkar|<http://arxiv.org/pdf/2505.00228v2>|构建了包含160,000份胸部X光片及其报告的大规模公开数据集，以促进医学影像AI研究。|
|🆕 发布|Reproducing and Improving CheXNet: Deep Learning for Chest X-ray Disease Classification|复现与改进CheXNet：胸部X光疾病分类的深度学习|Daniel Strick, Carlos Garcia, Anthony Huang|<http://arxiv.org/pdf/2505.06646v1>|该论文复现并改进了CheXNet算法，在胸部X光片疾病分类任务中实现了更高的准确率。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ElectricSight: 3D Hazard Monitoring for Power Lines Using Low-Cost Sensors|电力线路低成本传感器用于3D危险监测的ElectricSight|Xingchen Li, LiDian Wang, Yu Sheng, ZhiPeng Tang, Haojie Ren, Guoliang You, YiFan Duan, Jianmin Ji .etc.|<http://arxiv.org/pdf/2505.06573v1>|ElectricSight通过结合单目深度估计和环境点云先验，实现了低成本、高精度的电力线路三维距离...|

