## [UPDATED!] **2025-05-12** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DanceGRPO: Unleashing GRPO on Visual Generation|DanceGRPO：释放GRPO在视觉生成中的应用|Zeyue Xue, Jie Wu, Yu Gao, Fangyuan Kong, Lingting Zhu, Mengzhao Chen, Zhiheng Liu, Wei Liu .etc.|<http://arxiv.org/pdf/2505.07818v1>|DanceGRPO首次将GRPO应用于视觉生成，实现跨多种范式、任务、模型和奖励的统一强化学习框架，...|
|📝 更新|SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models|SCAM：多模态基础模型的真实世界印刷鲁棒性评估|Justus Westerhoff, Erblina Purelku, Jakob Hackstein, Jonas Loos, Leo Pinetzki, Lorenz Hufe|<http://arxiv.org/pdf/2504.04893v3>|构建了大规模真实世界印刷攻击数据集，揭示了多模态基础模型在印刷攻击下的脆弱性。|
|🆕 发布|TUM2TWIN: Introducing the Large-Scale Multimodal Urban Digital Twin Benchmark Dataset|TUM2TWIN：介绍大规模多模态城市数字孪生基准数据集|Olaf Wysocki, Benedikt Schwab, Manoj Kumar Biswanath, Qilin Zhang, Jingwei Zhu, Thomas Froech, Medhini Heeramaglore, Ihab Hijazi .etc.|<http://arxiv.org/pdf/2505.07396v1>|构建了首个大规模多模态城市数字孪生基准数据集，支持传感器分析和先进重建方法开发。|
|🆕 发布|Skywork-VL Reward: An Effective Reward Model for Multimodal Understanding and Reasoning|天空工作-VL奖励：一种有效的多模态理解和推理奖励模型|Xiaokun Wang, Chris, Jiangbo Pei, Wei Shen, Yi Peng, Yunzhuo Hao, Weijie Qiu, Ai Jian .etc.|<http://arxiv.org/pdf/2505.07263v1>|提出Skywork-VL Reward，一种基于大规模数据集和Qwen2.5-VL-7B-Instr...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hybrid Spiking Vision Transformer for Object Detection with Event Cameras|混合脉冲视觉Transformer用于事件相机目标检测|Qi Xu, Jie Deng, Jiangrong Shen, Biwu Chen, Huajin Tang, Gang Pan|<http://arxiv.org/pdf/2505.07715v1>|提出了一种融合时空特征的混合脉冲视觉Transformer模型，显著提升了基于事件相机的事件检测性能...|
|🆕 发布|LAMM-ViT: AI Face Detection via Layer-Aware Modulation of Region-Guided Attention|LAMM-ViT：通过层感知区域引导注意力调制的AI人脸检测|Jiangling Zhang, Weijie Zhu, Jirui Huang, Yaxiong Chen|<http://arxiv.org/pdf/2505.07734v1>|LAMM-ViT通过区域引导的注意力机制和层感知掩码调制，有效提升了AI合成人脸检测的准确性。|
|🆕 发布|Breast Cancer Classification in Deep Ultraviolet Fluorescence Images Using a Patch-Level Vision Transformer Framework|基于区域视觉Transformer框架的深紫外荧光图像乳腺癌分类|Pouya Afshin, David Helminiak, Tongtong Lu, Tina Yen, Julie M. Jorns, Mollie Patton, Bing Yu, Dong Hye Ye|<http://arxiv.org/pdf/2505.07654v1>|提出了一种基于Patch-Level Vision Transformer的深度紫外荧光图像乳腺癌分...|
|🆕 发布|MAIS: Memory-Attention for Interactive Segmentation|基于记忆的交互式分割|Mauricio Orbes-Arteaga, Oeslle Lucena, Sabastien Ourselin, M. Jorge Cardoso|<http://arxiv.org/pdf/2505.07511v1>|MAIS通过记忆和注意力机制，有效整合用户反馈，提升交互式医学图像分割的效率和准确性。|
|🆕 发布|Multi-Plane Vision Transformer for Hemorrhage Classification Using Axial and Sagittal MRI Data|多平面视觉Transformer在轴向和矢状MRI数据中用于出血分类|Badhan Kumar Das, Gengyan Zhao, Boris Mailhe, Thomas J. Re, Dorin Comaniciu, Eli Gibson, Andreas Maier|<http://arxiv.org/pdf/2505.07349v1>|提出了一种针对不同方向MRI数据的3D多平面视觉Transformer，有效提升了脑出血分类的准确性...|
|🆕 发布|L-SWAG: Layer-Sample Wise Activation with Gradients information for Zero-Shot NAS on Vision Transformers|L-SWAG：基于视觉Transformer的零样本NAS的层样本级激活与梯度信息|Sofia Casarin, Sergio Escalera, Oswald Lanz|<http://arxiv.org/pdf/2505.07300v1>|提出L-SWAG和LIBRA-NAS，有效提升零样本NAS在视觉Transformer上的性能。|
|🆕 发布|Synthetic Similarity Search in Automotive Production|合成相似性搜索在汽车生产中的应用|Christoph Huber, Ludwig Schleeh, Dino Knoll, Michael Guthe|<http://arxiv.org/pdf/2505.07256v1>|提出了一种结合视觉基础模型和合成数据的图像分类流程，以降低汽车生产中视觉质量检测对真实数据的依赖。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Beyond DAGs: A Latent Partial Causal Model for Multimodal Learning|超越有向无环图：一种用于多模态学习的潜在部分因果模型|Yuhang Liu, Zhen Zhang, Dong Gong, Erdun Gao, Biwei Huang, Mingming Gong, Anton van den Hengel, Kun Zhang .etc.|<http://arxiv.org/pdf/2402.06223v2>|提出了一种无需DAG假设的隐含部分因果模型，用于多模态学习，提高了预训练模型在跨域数据上的泛化能力。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Privacy Risks of Robot Vision: A User Study on Image Modalities and Resolution|机器人视觉的隐私风险：关于图像模态和分辨率的用户研究|Xuying Huang, Sicong Pan, Maren Bennewitz|<http://arxiv.org/pdf/2505.07766v1>|通过用户研究，揭示了不同图像模态和分辨率对隐私感知的影响。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Feedback-Driven Pseudo-Label Reliability Assessment: Redefining Thresholding for Semi-Supervised Semantic Segmentation|基于反馈的伪标签可靠性评估：重新定义半监督语义分割的阈值|Negin Ghamsarian, Sahar Nasirihaghighi, Klaus Schoeffmann, Raphael Sznitman|<http://arxiv.org/pdf/2505.07691v1>|提出了一种动态反馈驱动的伪标签可靠性评估方法，有效提升了半监督语义分割性能。|
|🆕 发布|SynID: Passport Synthetic Dataset for Presentation Attack Detection|SynID：护照合成数据集用于演示攻击检测|Juan E. Tapia, Fabian Stockhardt, Lázaro Janier González-Soler, Christoph Busch|<http://arxiv.org/pdf/2505.07540v1>|提出SynID，通过结合合成数据和公开信息构建护照数据集，以解决远程验证系统中假身份证检测难题。|
|📝 更新|Clinical Inspired MRI Lesion Segmentation|临床启发型MRI病变分割|Lijun Yan, Churan Wang, Fangwei Zhong, Yizhou Wang|<http://arxiv.org/pdf/2502.16032v2>|提出了一种受临床启发的MRI病变分割方法，通过融合对比序列特征实现精准分割。|
|📝 更新|Spike Imaging Velocimetry: Dense Motion Estimation of Fluids Using Spike Cameras|脉冲成像流速计：使用脉冲相机进行流体密集运动估计|Yunzhong Zhang, Bo Xiong, You Zhou, Changqing Su, Zhen Cheng, Zhaofei Yu, Xun Cao, Tiejun Huang|<http://arxiv.org/pdf/2504.18864v2>|提出了一种利用深度学习进行密集运动估计的新方法，显著提升了流体运动测量精度。|
|🆕 发布|Enabling Privacy-Aware AI-Based Ergonomic Analysis|赋能基于隐私感知人工智能的人体工程学分析|Sander De Coninck, Emilio Gamba, Bart Van Doninck, Abdellatif Bey-Temsamani, Sam Leroux, Pieter Simoens|<http://arxiv.org/pdf/2505.07306v1>|提出隐私感知的机器学习框架，通过视频数据模糊化实现工业环境中的安全、高效的人体工程学分析。|
|🆕 发布|Towards Accurate State Estimation: Kalman Filter Incorporating Motion Dynamics for 3D Multi-Object Tracking|向准确状态估计迈进：结合运动动力学用于3D多目标跟踪|Mohamed Nagy, Naoufel Werghi, Bilal Hassan, Jorge Dias, Majid Khonji|<http://arxiv.org/pdf/2505.07254v1>|提出了一种结合运动动态的改进卡尔曼滤波器，显著提升了3D多目标跟踪的精度和性能。|
|📝 更新|Towards Complementary Knowledge Distillation for Efficient Dense Image Prediction|迈向高效密集图像预测的互补知识蒸馏|Dong Zhang, Pingcheng Dong, Long Chen, Kwang-Ting Cheng|<http://arxiv.org/pdf/2401.13174v4>|提出互补边界与上下文蒸馏方法，有效提升密集图像预测模型边界完整性和目标区域连通性。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Self-Supervised Event Representations: Towards Accurate, Real-Time Perception on SoC FPGAs|自监督事件表示：在SoC FPGAs上实现准确、实时感知|Kamil Jeziorek, Tomasz Kryjak|<http://arxiv.org/pdf/2505.07556v1>|[代码](https://github.com/vision-agh/RecRepEvent.); 提出了一种基于GRU的自监督事件表示方法，在FPGA上实现了高精度、实时的事件感知。|
|🆕 发布|DepthFusion: Depth-Aware Hybrid Feature Fusion for LiDAR-Camera 3D Object Detection|深度融合：基于深度感知的激光雷达-摄像头3D目标检测混合特征融合|Mingqian Ji, Jian Yang, Shanshan Zhang|<http://arxiv.org/pdf/2505.07398v1>|提出深度感知混合特征融合策略，提升激光雷达-摄像头3D目标检测性能。|
|📝 更新|Msmsfnet: a multi-stream and multi-scale fusion net for edge detection|多流多尺度融合网络用于边缘检测：Msmsfnet|Chenguang Liu, Chisheng Wang, Feifei Dong, Xiayang Xiao, Xin Su, Chuanhua Zhu, Dejin Zhang, Qingquan Li|<http://arxiv.org/pdf/2404.04856v3>|设计了一种多流多尺度融合网络，从零开始训练，有效提升了边缘检测性能。|
|🆕 发布|Boosting Global-Local Feature Matching via Anomaly Synthesis for Multi-Class Point Cloud Anomaly Detection|通过异常合成增强全局-局部特征匹配的多类点云异常检测|Yuqi Cheng, Yunkang Cao, Dongfang Wang, Weiming Shen, Wenlong Li|<http://arxiv.org/pdf/2505.07375v1>|[代码](https://github.com/hustCYQ/GLFM-Multi-class-3DAD.); 提出一种多类点云异常检测方法，通过全局-局部特征匹配解决特征混淆问题，提升检测性能。|
|📝 更新|MOANA: Multi-Radar Dataset for Maritime Odometry and Autonomous Navigation Application|MOANA：多雷达海洋里程计与自主导航应用数据集|Hyesu Jang, Wooseong Yang, Hanguen Kim, Dongje Lee, Yongjin Kim, Jinbum Park, Minsoo Jeon, Jaeseong Koh .etc.|<http://arxiv.org/pdf/2412.03887v4>|构建了包含多雷达数据的海洋导航数据集，以提升海洋环境中的导航算法精度。|
|📝 更新|Referring to Any Person|指向任何人物|Qing Jiang, Lin Wu, Zhaoyang Zeng, Tianhe Ren, Yuda Xiong, Yihao Chen, Qin Liu, Lei Zhang|<http://arxiv.org/pdf/2503.08507v2>|[代码](https://github.com/IDEA-Research/RexSeek); 提出了一种结合多模态大语言模型和目标检测框架的RexSeek模型，有效解决指代任意人物的问题。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Lightweight Multispectral Crop-Weed Segmentation for Precision Agriculture|轻量级多光谱作物杂草分割用于精准农业|Zeynep Galymzhankyzy, Eric Martinson|<http://arxiv.org/pdf/2505.07444v1>|提出了一种轻量级多光谱作物杂草分割方法，显著提升精度农业杂草管理效率。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Pixel Motion as Universal Representation for Robot Control|像素运动作为机器人控制的通用表示|Kanchana Ranasinghe, Xiang Li, Cristina Mata, Jongwoo Park, Michael S Ryoo|<http://arxiv.org/pdf/2505.07817v1>|[代码](https://kahnchana.github.io/LangToMo); 提出LangToMo框架，利用像素运动预测作为通用表示，实现灵活可扩展的机器人控制。|
|🆕 发布|Continuous Visual Autoregressive Generation via Score Maximization|基于分数最大化的连续视觉自回归生成|Chenze Shao, Fandong Meng, Jie Zhou|<http://arxiv.org/pdf/2505.07812v1>|[代码](https://github.com/shaochenze/EAR.); 提出了一种无需量化直接生成连续视觉数据的连续VAR框架，基于严格得分规则优化模型。|
|🆕 发布|Imagine, Verify, Execute: Memory-Guided Agentic Exploration with Vision-Language Models|想象、验证、执行：基于视觉-语言模型的记忆引导智能体探索|Seungjae Lee, Daniel Ekpo, Haowen Liu, Furong Huang, Abhinav Shrivastava, Jia-Bin Huang|<http://arxiv.org/pdf/2505.07815v1>|提出了一种结合视觉语言模型和记忆引导的探索框架，以实现更丰富和有意义的机器人探索。|
|🆕 发布|Beyond Static Perception: Integrating Temporal Context into VLMs for Cloth Folding|超越静态感知：将时间上下文整合到VLMs用于衣物折叠|Oriol Barbany, Adrià Colomé, Carme Torras|<http://arxiv.org/pdf/2505.07600v1>|将时间上下文整合到视觉语言模型中，以改善衣物折叠状态估计。|
|🆕 发布|Discrete Visual Tokens of Autoregression, by Diffusion, and for Reasoning|离散自回归视觉标记，通过扩散，用于推理|Bohan Wang, Zhongqi Yue, Fengda Zhang, Shuo Chen, Li'an Bi, Junzhe Zhang, Xue Song, Kennard Yanting Chan .etc.|<http://arxiv.org/pdf/2505.07538v1>|[代码](https://selftok-team.github.io/report); 提出Selftok，一种基于自回归先验的视觉标记器，有效支持视觉生成中的强化学习。|
|📝 更新|Beyond Boundaries: A Comprehensive Survey of Transferable Attacks on AI Systems|超越边界：人工智能系统可迁移攻击的全面综述|Guangjing Wang, Ce Zhou, Yuanda Wang, Bocheng Chen, Hanqing Guo, Qiben Yan|<http://arxiv.org/pdf/2311.11796v2>|首次全面综述了AI系统可迁移攻击，并提出统一分类和提升攻击迁移性的方法。|
|🆕 发布|Unified Continuous Generative Models|统一连续生成模型|Peng Sun, Yi Jiang, Tao Lin|<http://arxiv.org/pdf/2505.07447v1>|[代码](https://github.com/LINs-lab/UCGM.); 提出统一框架，实现多步与少步连续生成模型的高效训练与采样，显著提升生成性能。|
|🆕 发布|Addressing degeneracies in latent interpolation for diffusion models|解决扩散模型中潜在插值退化问题|Erik Landolsi, Fredrik Kahl|<http://arxiv.org/pdf/2505.07481v1>|提出了一种简单归一化方案，有效缓解了扩散模型中潜在空间插值导致的退化问题，提升了图像生成质量。|
|📝 更新|A super-resolution reconstruction method for lightweight building images based on an expanding feature modulation network|基于扩展特征调制网络的轻量级建筑图像超分辨率重建方法|Yi Zhang, Ruonan Lin, Ang Ping|<http://arxiv.org/pdf/2503.13179v2>|提出了一种基于DCFMN的轻量级建筑图像超分辨率方法，有效解决长距离依赖问题，提升重建质量和效率。|
|📝 更新|Improving Tropical Cyclone Forecasting With Video Diffusion Models|利用视频扩散模型提升热带气旋预报|Zhibo Ren, Pritthijit Nath, Pancham Shukla|<http://arxiv.org/pdf/2501.16003v5>|[代码](https://github.com/Ren-creater/forecast-video-diffmodels.); 利用视频扩散模型显式建模时间依赖性，显著提升热带气旋预报的准确性和预测范围。|
|📝 更新|Less is More: Improving Motion Diffusion Models with Sparse Keyframes|少即是多：通过稀疏关键帧改进运动扩散模型|Jinseok Bae, Inwoo Hwang, Young Yoon Lee, Ziyu Guo, Joseph Liu, Yizhak Ben-Shabat, Young Min Kim, Mubbasir Kapadia|<http://arxiv.org/pdf/2503.13859v2>|提出一种基于稀疏关键帧的扩散模型，有效降低运动生成复杂度并提升性能。|
|📝 更新|Relationships between the degrees of freedom in the affine Gaussian derivative model for visual receptive fields and 2-D affine image transformations, with application to covariance properties of simple cells in the primary visual cortex|视觉感受野的仿射高斯导数模型自由度与二维仿射图像变换之间的关系，及其在初级视觉皮层简单细胞协方差性质中的应用|Tony Lindeberg|<http://arxiv.org/pdf/2411.05673v3>|分析了二维图像变换与视觉感受野模型自由度的关系，为理解生物视觉皮层响应提供理论依据。|
|🆕 发布|Towards user-centered interactive medical image segmentation in VR with an assistive AI agent|面向以用户为中心的VR辅助AI代理交互式医学图像分割|Pascal Spiegler, Arash Harirpoush, Yiming Xiao|<http://arxiv.org/pdf/2505.07214v1>|提出SAMIRA，一种结合VR和AI的交互式医疗图像分割系统，提高分割效率和用户体验。|
|📝 更新|Learning to Drive Anywhere with Model-Based Reannotation|学习在任何地方驾驶：基于模型的重标注|Noriaki Hirose, Lydia Ignatova, Kyle Stachowicz, Catherine Glossop, Sergey Levine, Dhruv Shah|<http://arxiv.org/pdf/2505.05592v2>|提出MBRA框架，通过模型重标注技术提升机器人视觉导航能力，实现跨环境导航。|
|📝 更新|MDE-Edit: Masked Dual-Editing for Multi-Object Image Editing via Diffusion Models|MDE-Edit：基于扩散模型的掩码双重编辑多对象图像编辑|Hongyang Zhu, Haipeng Liu, Bo Fu, Yang Wang|<http://arxiv.org/pdf/2505.05101v2>|MDE-Edit通过双编辑和扩散模型，实现了复杂场景中多对象图像的精确编辑。|
|📝 更新|PIDiff: Image Customization for Personalized Identities with Diffusion Models|PIDiff：基于扩散模型的个性化身份图像定制|Jinyu Gu, Haipeng Liu, Meng Wang, Yang Wang|<http://arxiv.org/pdf/2505.05081v2>|PIDiff通过W+空间和定制化微调策略，实现个性化身份图像生成，避免语义混淆，提高特征提取和定位准...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DexWild: Dexterous Human Interactions for In-the-Wild Robot Policies|DexWild：野外机器人策略中的灵巧人机交互|Tony Tao, Mohan Kumar Srirama, Jason Jingzhou Liu, Kenneth Shaw, Deepak Pathak|<http://arxiv.org/pdf/2505.07813v1>|DexWild通过低成本设备收集真实交互数据，结合人类和机器人演示，实现机器人策略在未知环境中的泛化...|
|🆕 发布|Deep Learning Advances in Vision-Based Traffic Accident Anticipation: A Comprehensive Review of Methods,Datasets,and Future Directions|基于视觉的交通事故预测的深度学习进展：方法、数据集和未来方向的全面综述|Yi Zhang, Wenye Zhou, Ruonan Lin, Xin Yang, Hao Zheng|<http://arxiv.org/pdf/2505.07611v1>|综述了基于深度学习的交通事故预测方法，提出融合多模态数据和Transformer架构以提升预测准确性...|
|🆕 发布|Generalizable Pancreas Segmentation via a Dual Self-Supervised Learning Framework|通用胰腺分割通过双重自监督学习框架|Jun Li, Hongzhang Zhu, Tao Chen, Xiaohua Qian|<http://arxiv.org/pdf/2505.07165v1>|提出了一种结合全局和局部解剖上下文的自我监督学习框架，以提升胰腺分割模型的泛化性能。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|H$^{\mathbf{3}}$DP: Triply-Hierarchical Diffusion Policy for Visuomotor Learning|H$^{\mathbf{3}}$DP：用于视觉运动学习的三重层次扩散策略|Yiyang Lu, Yufeng Tian, Zhecheng Yuan, Xianbang Wang, Pu Hua, Zhengrong Xue, Huazhe Xu|<http://arxiv.org/pdf/2505.07819v1>|[代码](https://lyy-iiis.github.io/h3dp); H$^{\mathbf{3}}$DP通过引入三重层次结构，强化视觉特征与动作生成间的整合，显著提升了...|
|🆕 发布|Step1X-3D: Towards High-Fidelity and Controllable Generation of Textured 3D Assets|Step1X-3D：迈向高保真和可控的纹理3D资产生成|Weiyu Li, Xuanyang Zhang, Zheng Sun, Di Qi, Hao Li, Wei Cheng, Weiwei Cai, Shihao Wu .etc.|<http://arxiv.org/pdf/2505.07747v1>|Step1X-3D通过构建高质量数据集和结合VAE-DiT与扩散纹理合成，实现了高保真可控的3D资产...|
|🆕 发布|ShotAdapter: Text-to-Multi-Shot Video Generation with Diffusion Models|《ShotAdapter：基于扩散模型的文本到多镜头视频生成》|Ozgur Kara, Krishna Kumar Singh, Feng Liu, Duygu Ceylan, James M. Rehg, Tobias Hinz|<http://arxiv.org/pdf/2505.07652v1>|提出了一种基于扩散模型的多镜头视频生成方法，可生成具有连续过渡的多镜头视频。|
|📝 更新|dc-GAN: Dual-Conditioned GAN for Face Demorphing From a Single Morph|双条件生成对抗网络：从单一形态进行人脸去形变|Nitish Shukla, Arun Ross|<http://arxiv.org/pdf/2411.14494v3>|提出dc-GAN，一种基于GAN的从单一形态图像恢复原始人脸图像的新方法。|
|🆕 发布|Noise Optimized Conditional Diffusion for Domain Adaptation|噪声优化条件扩散域适应|Lingkun Luo, Shiqiang Hu, Liming Chen|<http://arxiv.org/pdf/2505.07548v1>|提出NOCDDA方法，通过噪声优化条件扩散模型，有效解决无监督领域自适应中的伪标签稀疏问题，显著提升...|
|🆕 发布|FLUXSynID: A Framework for Identity-Controlled Synthetic Face Generation with Document and Live Images|FLUXSynID：一种基于身份控制的合成人脸生成框架，支持文档和实时图像|Raul Ismayilov, Luuk Spreeuwers, Dzemila Sero|<http://arxiv.org/pdf/2505.07530v1>|FLUXSynID框架通过用户定义身份属性分布，生成与真实世界身份分布更匹配的高分辨率合成人脸数据集...|
|🆕 发布|Ophora: A Large-Scale Data-Driven Text-Guided Ophthalmic Surgical Video Generation Model|Ophora：一个大规模数据驱动的文本引导眼科手术视频生成模型|Wei Li, Ming Hu, Guoan Wang, Lihao Liu, Kaijin Zhou, Junzhi Ning, Xin Guo, Zongyuan Ge .etc.|<http://arxiv.org/pdf/2505.07449v1>|[代码](https://github.com/mar-cry/Ophora.); 提出Ophora模型，通过自然语言指令生成逼真的眼科手术视频，解决数据标注难题。|
|📝 更新|RealRAG: Retrieval-augmented Realistic Image Generation via Self-reflective Contrastive Learning|真实图像生成中的检索增强：通过自反对比学习|Yuanhuiyi Lyu, Xu Zheng, Lutao Jiang, Yibo Yan, Xin Zou, Huiyu Zhou, Linfeng Zhang, Xuming Hu|<http://arxiv.org/pdf/2502.00848v2>|提出RealRAG，通过自反思对比学习增强检索，解决生成模型知识局限导致的幻觉问题，提升细粒度物体生...|
|📝 更新|HumanDiT: Pose-Guided Diffusion Transformer for Long-form Human Motion Video Generation|人类DiT：姿态引导的扩散变换器用于长格式人体运动视频生成|Qijun Gan, Yi Ren, Chen Zhang, Zhenhui Ye, Pan Xie, Xiang Yin, Zehuan Yuan, Bingyue Peng .etc.|<http://arxiv.org/pdf/2502.04847v4>|HumanDiT通过姿态引导的扩散Transformer，有效生成长序列高保真人体运动视频。|
|📝 更新|HoLa: B-Rep Generation using a Holistic Latent Representation|HoLa：基于整体潜在表示的B-Rep生成|Yilin Liu, Duoteng Xu, Xingyao Yu, Xiang Xu, Daniel Cohen-Or, Hao Zhang, Hui Huang|<http://arxiv.org/pdf/2504.14257v3>|提出了一种基于整体潜在表示的B-Rep生成方法，显著提升了CAD模型生成效率和准确性。|
|🆕 发布|Generative Pre-trained Autoregressive Diffusion Transformer|生成预训练自回归扩散Transformer|Yuan Zhang, Jiacheng Jiang, Guoqing Ma, Zhiying Lu, Haoyang Huang, Jianlong Yuan, Nan Duan|<http://arxiv.org/pdf/2505.07344v1>|GPDiT通过结合扩散和自回归模型，在连续潜在空间中实现了长视频合成，提升了生成质量和模型效率。|
|📝 更新|Direct Discriminative Optimization: Your Likelihood-Based Visual Generative Model is Secretly a GAN Discriminator|直接判别优化：你的基于似然的可视生成模型其实是一个GAN判别器|Kaiwen Zheng, Yongxin Chen, Huayu Chen, Guande He, Ming-Yu Liu, Jun Zhu, Qinsheng Zhang|<http://arxiv.org/pdf/2503.01103v2>|提出DDO框架，通过结合似然生成和GAN判别，突破MLE限制，显著提升视觉生成模型性能。|
|📝 更新|SerialGen: Personalized Image Generation by First Standardization Then Personalization|SerialGen：先标准化后个性化图像生成|Cong Xie, Han Zou, Ruiqi Yu, Yan Zhang, Zhenpeng Zhan|<http://arxiv.org/pdf/2412.01485v2>|SerialGen通过标准化和个性化两阶段生成，实现个性化人物图像的高可控性和全身外观一致性。|
|📝 更新|OmniAudio: Generating Spatial Audio from 360-Degree Video|全音频：从360度视频中生成空间音频|Huadai Liu, Tianyi Luo, Qikai Jiang, Kaicheng Luo, Peiwen Sun, Jialei Wan, Rongjie Huang, Qian Chen .etc.|<http://arxiv.org/pdf/2504.14906v2>|[代码](https://github.com/liuhuadai/OmniAudio.); 提出OmniAudio框架，从360度视频生成空间音频，实现更真实的3D音效。|
|🆕 发布|Language-Driven Dual Style Mixing for Single-Domain Generalized Object Detection|基于语言的单一领域泛化目标检测的双风格混合|Hongda Qin, Xiao Lu, Zhiyong Wei, Yihong Cao, Kailun Yang, Ningjiang Chen|<http://arxiv.org/pdf/2505.07219v1>|[代码](https://github.com/qinhongda8/LDDS.); 提出了一种利用视觉语言模型语义信息进行风格混合的方法，有效提升单域目标检测泛化能力。|
|📝 更新|DiffGAN: A Test Generation Approach for Differential Testing of Deep Neural Networks|深度神经网络差分测试的测试生成方法：DiffGAN|Zohreh Aghababaeyan, Manel Abdellatif, Lionel Briand, Ramesh S|<http://arxiv.org/pdf/2410.19794v2>|DiffGAN通过生成测试图像揭示深度神经网络行为差异，提升模型选择和组合效果。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|You Only Look One Step: Accelerating Backpropagation in Diffusion Sampling with Gradient Shortcuts|仅看一步：使用梯度捷径加速扩散采样的反向传播|Hongkun Dou, Zeyu Li, Xingyu Jiang, Hongjue Li, Lijun Yang, Wen Yao, Yue Deng|<http://arxiv.org/pdf/2505.07477v1>|[代码](https://github.com/deng-ai-lab/SDO.); 提出了一种通过仅保留生成过程中一步的计算图来加速扩散模型反向传播的方法，显著降低计算成本。|
|🆕 发布|RealRep: Generalized SDR-to-HDR Conversion with Style Disentangled Representation Learning|真实再现：基于风格解耦表示学习的广义SDR到HDR转换|Gang He, Siqi Wang, Kepeng Xu, Lin Zhang|<http://arxiv.org/pdf/2505.07322v1>|提出了一种基于风格解耦的SDR到HDR转换方法，有效处理风格多样的SDR内容。|
|📝 更新|Semantic and Expressive Variation in Image Captions Across Languages|图像标题在语言间的语义和表达变异|Andre Ye, Sebastin Santy, Jena D. Hwang, Amy X. Zhang, Ranjay Krishna|<http://arxiv.org/pdf/2310.14356v5>|该论文揭示了不同语言图像描述中的语义和表达差异，并提出了利用多语言数据集训练模型以提升视觉语言理解的...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GP-GS: Gaussian Processes for Enhanced Gaussian Splatting|GP-GS：增强高斯喷溅的高斯过程|Zhihao Guo, Jingxuan Su, Shenglin Wang, Jinlong Fan, Jing Zhang, Wei Zhou, Hadi Amirpour, Yunlong Zhao .etc.|<http://arxiv.org/pdf/2502.02283v4>|提出GP-GS方法，通过高斯过程增强稀疏SfM点云，提升3D场景重建质量。|
|📝 更新|Introducing Unbiased Depth into 2D Gaussian Splatting for High-accuracy Surface Reconstruction|引入无偏深度到二维高斯分层渲染以实现高精度表面重建|Xiaoming Peng, Yixin Yang, Yang Zhou, Hui Huang|<http://arxiv.org/pdf/2503.06587v2>|通过引入无偏深度优化二维高斯分层，显著提升了光滑表面重建的完整性和准确性。|
|🆕 发布|Geometric Prior-Guided Neural Implicit Surface Reconstruction in the Wild|野外几何先验引导的神经隐式表面重建|Lintao Xiang, Hongpei Zheng, Bailin Deng, Hujun Yin|<http://arxiv.org/pdf/2505.07373v1>|提出了一种结合几何先验的神经网络隐式表面重建方法，有效提升了对复杂场景中表面几何的精确重建。|
|🆕 发布|Link to the Past: Temporal Propagation for Fast 3D Human Reconstruction from Monocular Video|《链接过去：从单目视频中快速重建3D人体的时间传播》|Matthew Marchellus, Nadhira Noor, In Kyu Park|<http://arxiv.org/pdf/2505.07333v1>|提出了一种利用时间一致性的快速3D人体重建方法，显著提升重建速度和质量。|
|📝 更新|Stereo Hand-Object Reconstruction for Human-to-Robot Handover|立体手-物体重建用于人机手递|Yik Lung Pang, Alessio Xompero, Changjae Oh, Andrea Cavallaro|<http://arxiv.org/pdf/2412.07487v3>|提出了一种结合单视图重建和3D形状先验的立体手-物体重建方法，有效提升了透明物体识别和抓取任务的成功...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Unified Hierarchical Framework for Fine-grained Cross-view Geo-localization over Large-scale Scenarios|统一分层框架在大规模场景下的细粒度跨视图地理定位|Zhuo Song, Ye Zhang, Kunhong Li, Longguang Wang, Yulan Guo|<http://arxiv.org/pdf/2505.07622v1>|提出了一种统一分层框架，有效提升了大规模场景中的细粒度跨视图地理定位性能。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FANeRV: Frequency Separation and Augmentation based Neural Representation for Video|FANeRV：基于频率分离和增强的神经网络视频表示|Li Yu, Zhihui Li, Yao Zhao, Jimin Xiao, Moncef Gabbouj|<http://arxiv.org/pdf/2504.06755v3>|FANeRV通过波分频和增强神经网络，有效提升视频重建性能。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GIFStream: 4D Gaussian-based Immersive Video with Feature Stream|GIFStream：基于4D高斯沉浸式视频与特征流|Hao Li, Sicheng Li, Xiang Gao, Abudouaihati Batuer, Lu Yu, Yiyi Liao|<http://arxiv.org/pdf/2505.07539v1>|[代码](https://xdimlab.github.io/GIFStream); 提出GIFStream，通过4D高斯表示和特征流实现高效压缩，提升沉浸式视频质量与渲染速度。|
|🆕 发布|Few-shot Semantic Encoding and Decoding for Video Surveillance|少量样本语义编码与解码用于视频监控|Baoping Cheng, Yukun Zhang, Liming Wang, Xiaoyan Xie, Tao Fu, Dongkun Wang, Xiaoming Tao|<http://arxiv.org/pdf/2505.07381v1>|提出了一种仅需少量样本的语义编码与解码方法，有效降低视频监控信息存储与传输消耗。|
|🆕 发布|When Dance Video Archives Challenge Computer Vision|当舞蹈视频档案挑战计算机视觉|Philippe Colantoni, Rafique Ahmed, Prashant Ghimire, Damien Muselet, Alain Trémeau|<http://arxiv.org/pdf/2505.07249v1>|提出了一种结合最新技术和方法的3D人体姿态估计流程，以应对舞蹈视频对计算机视觉的挑战。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AdaWorld: Learning Adaptable World Models with Latent Actions|AdaWorld：通过潜在动作学习可适应的世界模型|Shenyuan Gao, Siyuan Zhou, Yilun Du, Jun Zhang, Chuang Gan|<http://arxiv.org/pdf/2503.18938v2>|AdaWorld通过在预训练中融入动作信息，实现了高效适应新环境的可迁移世界模型学习。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SAEN-BGS: Energy-Efficient Spiking AutoEncoder Network for Background Subtraction|SAEN-BGS：用于背景减法的节能脉冲自动编码器网络|Zhixuan Zhang, Xiaopeng Li, Qi Liu|<http://arxiv.org/pdf/2505.07336v1>|设计了一种基于脉冲神经网络的高效背景减除方法，有效提升了复杂场景下的分割性能。|
|📝 更新|Multi-camera orientation tracking method for anisotropic particles in particle-laden flows|多摄像头各向异性粒子在载流粒子中的姿态跟踪方法|Mees M. Flapper, Elian Bernard, Sander G. Huisman|<http://arxiv.org/pdf/2503.08694v2>|开发了一种针对各向异性粒子在粒子流中三维定位和方向跟踪的多相机方法。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 跨模态一致性学习 (Cross-modal Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Through the Looking Glass: Common Sense Consistency Evaluation of Weird Images|透过魔镜：怪异图像的常识一致性评估|Elisei Rykov, Kseniia Petrushina, Kseniia Titova, Anton Razzhigaev, Alexander Panchenko, Vasily Konovalov|<http://arxiv.org/pdf/2505.07704v1>|通过大型视觉语言模型评估图像常识一致性，提出TLG方法在常识一致性评估上取得新突破。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Skeletonization of neuronal processes using Discrete Morse techniques from computational topology|神经元过程的离散莫尔斯技术骨骼化|Samik Banerjee, Caleb Stam, Daniel J. Tward, Steven Savoia, Yusu Wang, Partha P. Mitra|<http://arxiv.org/pdf/2505.07754v1>|利用离散莫尔斯技术和深度学习，该论文提出了一种从神经元轴突片段中提取骨架并估计体积密度的新方法，以更...|
|🆕 发布|Hierarchical Sparse Attention Framework for Computationally Efficient Classification of Biological Cells|分层稀疏注意力框架用于生物细胞计算高效分类|Elad Yoshai, Dana Yagoda-Aharoni, Eden Dotan, Natan T. Shaked|<http://arxiv.org/pdf/2505.07661v1>|提出了一种高效分类生物细胞的方法，通过自适应选择关键像素，显著降低计算需求并提高准确率。|
|🆕 发布|Learning to Reason and Navigate: Parameter Efficient Action Planning with Large Language Models|学习推理与导航：大型语言模型的高效参数动作规划|Bahram Mohammadi, Ehsan Abbasnejad, Yuankai Qi, Qi Wu, Anton Van Den Hengel, Javen Qinfeng Shi|<http://arxiv.org/pdf/2505.07500v1>|提出了一种结合大语言模型和LoRA的参数高效动作规划器，有效解决复杂室内环境中的导航和定位问题。|
|🆕 发布|Feature Visualization in 3D Convolutional Neural Networks|3D卷积神经网络中的特征可视化|Chunpeng Li, Ya-tang Li|<http://arxiv.org/pdf/2505.07387v1>|[代码](https://github.com/YatangLiLab/3DKernelVisualizer.); 提出了一种可视化3D卷积核纹理和运动偏好的新方法，揭示3D卷积操作的动态模式。|
|📝 更新|Leveraging Habitat Information for Fine-grained Bird Identification|利用栖息地信息进行细粒度鸟类识别|Tin Nguyen, Peijie Chen, Anh Totti Nguyen|<http://arxiv.org/pdf/2312.14999v2>|首次将栖息地信息融入现代鸟类识别模型，显著提升了识别准确率。|
|📝 更新|V-NAW: Video-based Noise-aware Adaptive Weighting for Facial Expression Recognition|基于视频的噪声感知自适应加权面部表情识别|JunGyu Lee, Kunyoung Lee, Haesol Park, Ig-Jae Kim, Gi Pyo Nam|<http://arxiv.org/pdf/2503.15970v2>|提出V-NAW方法，通过视频噪声感知自适应加权，有效提升基于视频的人脸表情识别性能。|
|🆕 发布|Critique Before Thinking: Mitigating Hallucination through Rationale-Augmented Instruction Tuning|在思考之前进行批判：通过理由增强的指令微调减轻幻觉|Zexian Yang, Dian Li, Dayan Wu, Gang Liu, Weiping Wang|<http://arxiv.org/pdf/2505.07172v1>|通过引入理性增强的指令微调，Re-Critic框架有效减轻了大型视觉语言模型在图像解释中的幻觉问题。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BodyGPS: Anatomical Positioning System|人体GPS：解剖定位系统|Halid Ziya Yerebakan, Kritika Iyer, Xueqi Guo, Yoshihisa Shinagawa, Gerardo Hermosillo Valadez|<http://arxiv.org/pdf/2505.07744v1>|提出BodyGPS模型，通过神经网络实现医学图像中人体解剖结构的快速定位和解析。|
|🆕 发布|Gameplay Highlights Generation|游戏精彩片段生成|Vignesh Edithal, Le Zhang, Ilia Blank, Imran Junejo|<http://arxiv.org/pdf/2505.07721v1>|开发了一种基于X-CLIP的多模态模型，自动生成游戏精彩片段，提高社交媒体互动性。|
|🆕 发布|Simple Semi-supervised Knowledge Distillation from Vision-Language Models via $\mathbf{\texttt{D}}$ual-$\mathbf{\texttt{H}}$ead $\mathbf{\texttt{O}}$ptimization|简单通过 $\mathbf{\texttt{D}}$ual-$\mathbf{\texttt{H}}$ead $\mathbf{\texttt{O}}$ptimization 从视觉-语言模型中进行半监督知识蒸馏|Seongjae Kang, Dong Bok Lee, Hyungjoon Jang, Sung Ju Hwang|<http://arxiv.org/pdf/2505.07675v1>|提出了一种简单有效的半监督知识蒸馏框架，通过双预测头优化，显著提升了视觉语言模型在资源受限环境下的性...|
|🆕 发布|ICE-Pruning: An Iterative Cost-Efficient Pruning Pipeline for Deep Neural Networks|ICE-Pruning：一种用于深度神经网络的迭代成本高效剪枝流程|Wenhao Hu, Paul Henderson, José Cano|<http://arxiv.org/pdf/2505.07411v1>|[代码](https://github.com/gicLAB/ICE-Pruning); 提出ICE-Pruning，一种降低深度神经网络剪枝成本并保持高精度的迭代剪枝流程。|
|🆕 发布|Apple's Synthetic Defocus Noise Pattern: Characterization and Forensic Applications|苹果合成失焦噪声模式：特征分析与法医应用|David Vázquez-Padín, Fernando Pérez-González, Pablo Pérez-Miguélez|<http://arxiv.org/pdf/2505.07380v1>|详细刻画并利用苹果合成散焦噪声模式，提升相机源验证准确性和图像溯源能力。|
|🆕 发布|AI-Enabled Accurate Non-Invasive Assessment of Pulmonary Hypertension Progression via Multi-Modal Echocardiography|人工智能赋能的多模态超声心动图在肺动脉高压进展的非侵入性准确评估|Jiewen Yang, Taoran Huang, Shangwei Ding, Xiaowei Xu, Qinhua Zhao, Yong Jiang, Jiarong Guo, Bin Pu .etc.|<http://arxiv.org/pdf/2505.07347v1>|开发了一种基于多模态超声心动图的AI模型，准确评估肺高血压进展，为患者提供非侵入性监测方法。|
|🆕 发布|Ranking-aware Continual Learning for LiDAR Place Recognition|基于排名感知的激光雷达位姿识别持续学习|Xufei Wang, Gengxuan Tian, Junqiao Zhao, Siyue Tao, Qiwen Gu, Qiankun Yu, Tiantian Feng|<http://arxiv.org/pdf/2505.07198v1>|提出一种基于知识蒸馏和融合的持续学习方法，有效缓解了激光雷达场景识别中的灾难性遗忘问题。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Neural Brain: A Neuroscience-inspired Framework for Embodied Agents|神经大脑：一种受神经科学启发的具身智能体框架|Jian Liu, Xiongtao Shi, Thai Duy Nguyen, Haitian Zhang, Tianxiang Zhang, Wei Sun, Yanjie Li, Athanasios V. Vasilakos .etc.|<http://arxiv.org/pdf/2505.07634v1>|提出了一种神经科学启发的框架，通过整合多模态感知和认知能力，实现具身智能代理的动态适应和实时行动。|
|🆕 发布|Higher-Order Convolution Improves Neural Predictivity in the Retina|高阶卷积提升视网膜中的神经预测性|Simone Azeglio, Victor Calbiague Garcia, Guilhem Glaziou, Peter Neri, Olivier Marre, Ulisse Ferrari|<http://arxiv.org/pdf/2505.07620v1>|提出了一种结合高阶操作的卷积神经网络，有效提升了视网膜神经响应预测能力。|
|📝 更新|A Sliding Layer Merging Method for Efficient Depth-Wise Pruning in LLMs|滑动层合并方法在LLMs中实现高效深度剪枝|Xuan Ding, Rui Sun, Yunjian Zhang, Xiu Yan, Yueqi Zhou, Kaihao Huang, Suzhong Fu, Chuanlong Xie .etc.|<http://arxiv.org/pdf/2502.19159v2>|[代码](https://github.com/920927/SLM-a-sliding-layer-merging-method.); 提出了一种基于层间特征关系的滑动层合并方法，有效提升了LLMs的深度剪枝性能。|
|📝 更新|TableCenterNet: A one-stage network for table structure recognition|表结构识别的单阶段网络：TableCenterNet|Anyi Xiao, Cihui Yang|<http://arxiv.org/pdf/2504.17522v2>|[代码](https://github.com/dreamy-xay/TableCenterNet.); 提出TableCenterNet，一种一阶段网络，实现并行预测表格空间和逻辑结构，提高识别效率和准确...|
|🆕 发布|IKrNet: A Neural Network for Detecting Specific Drug-Induced Patterns in Electrocardiograms Amidst Physiological Variability|IKrNet：一种在生理变异性中检测特定药物诱导心电图模式的神经网络|Ahmad Fall, Federica Granese, Alex Lence, Dominique Fourer, Blaise Hanczar, Joe-Elie Salem, Jean-Daniel Zucker, Edi Prifti|<http://arxiv.org/pdf/2505.07533v1>|IKrNet通过结合时空动态捕捉，在生理变化中准确识别药物引起的ECG模式。|
|📝 更新|Efficient 3D Perception on Multi-Sweep Point Cloud with Gumbel Spatial Pruning|基于Gumbel空间剪枝的多扫描点云上的高效3D感知|Tianyu Sun, Jianhao Li, Xueqian Zhang, Zhongdao Wang, Bailan Feng, Hengshuang Zhao|<http://arxiv.org/pdf/2411.07742v4>|通过Gumbel空间剪枝，有效提升多扫描点云的3D感知精度，同时降低计算成本。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AttackBench: Evaluating Gradient-based Attacks for Adversarial Examples|攻击基准：评估基于梯度的对抗样本攻击|Antonio Emanuele Cinà, Jérôme Rony, Maura Pintor, Luca Demetrio, Ambra Demontis, Battista Biggio, Ismail Ben Ayed, Fabio Roli|<http://arxiv.org/pdf/2404.19460v3>|提出AttackBench，首次实现不同梯度攻击的公平比较，评估其优化对抗样本的有效性和效率。|


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Discovering Fine-Grained Visual-Concept Relations by Disentangled Optimal Transport Concept Bottleneck Models|通过解耦最优传输概念瓶颈模型发现细粒度视觉概念关系|Yan Xie, Zequn Zeng, Hao Zhang, Yucheng Ding, Yi Wang, Zhengjue Wang, Bo Chen, Hongwei Liu|<http://arxiv.org/pdf/2505.07209v1>|提出DOT-CBM框架，通过解耦最优传输探索局部图像与概念间的细粒度关系，提升模型可靠性和预测准确性...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Beyond CLIP Generalization: Against Forward&Backward Forgetting Adapter for Continual Learning of Vision-Language Models|超越CLIP泛化：针对视觉-语言模型持续学习的对抗前向和反向遗忘适配器|Songlin Dong, Chenhao Ding, Jiangyang Li, Jizhou Han, Qiang Wang, Yuhang He, Yihong Gong|<http://arxiv.org/pdf/2505.07690v1>|提出AFA框架，解决视觉语言模型在多域任务增量学习中的泛化问题，提升零样本识别和少样本学习能力。|
|📝 更新|Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding|利用自动CAD标注进行3D场景理解的有监督学习|Yuchen Rao, Stefan Ainetter, Sinisa Stekovic, Vincent Lepetit, Friedrich Fraundorfer|<http://arxiv.org/pdf/2504.13580v3>|利用自动CAD模型检索技术，实现了高质量3D场景标注，显著提升了深度学习模型性能。|
|📝 更新|A novel fusion of Sentinel-1 and Sentinel-2 with climate data for crop phenology estimation using Machine Learning|基于机器学习的Sentinel-1和Sentinel-2与气候数据的创新融合，用于作物物候估计|Shahab Aldin Shojaeezadeh, Abdelrazek Elnashar, Tobias Karl David Weber|<http://arxiv.org/pdf/2409.00020v2>|提出了一种融合Sentinel-1和Sentinel-2数据与气候数据，利用机器学习预测作物物候阶段...|
|🆕 发布|Incomplete In-context Learning|情境学习中的不完整学习|Wenqiang Wang, Yangshijie Zhang|<http://arxiv.org/pdf/2505.07251v1>|针对不完整检索数据库问题，提出迭代判断与集成预测框架，有效提升视觉语言模型在情境学习中的性能。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Adapting In-Domain Few-Shot Segmentation to New Domains without Retraining|适应域内小样本分割以适应新领域而不需重新训练|Qi Fan, Kaiqi Liu, Nian Liu, Hisham Cholakkal, Rao Muhammad Anwer, Wenbin Li, Yang Gao|<http://arxiv.org/pdf/2504.21414v2>|提出一种无需重训练的跨域小样本分割方法，通过自适应调整模型结构适应新领域。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Articulate AnyMesh: Open-Vocabulary 3D Articulated Objects Modeling|《Articulate AnyMesh：开放词汇的3D可动对象建模》|Xiaowen Qiu, Jincheng Yang, Yian Wang, Zhehuan Chen, Yufei Wang, Tsun-Hsuan Wang, Zhou Xian, Chuang Gan|<http://arxiv.org/pdf/2502.02590v2>|提出Articulate Anymesh，实现任意3D网格的开放词汇3D可动物体建模。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Evaluating Modern Visual Anomaly Detection Approaches in Semiconductor Manufacturing: A Comparative Study|评估半导体制造中现代视觉异常检测方法：一项比较研究|Manuel Barusco, Francesco Borsatti, Youssef Ben Khalifa, Davide Dalle Pezze, Gian Antonio Susto|<http://arxiv.org/pdf/2505.07576v1>|提出基于MIIC数据集的基准，评估现代无监督视觉异常检测在半导体制造中的有效性。|
|🆕 发布|Automated Visual Attention Detection using Mobile Eye Tracking in Behavioral Classroom Studies|基于移动眼动追踪在行为课堂研究中的自动视觉注意力检测|Efe Bozkir, Christian Kosel, Tina Seidel, Enkelejda Kasneci|<http://arxiv.org/pdf/2505.07552v1>|提出了一种利用移动眼动追踪和面部识别技术，以少量标注数据自动检测教师视觉注意力的方法。|
|🆕 发布|DocVXQA: Context-Aware Visual Explanations for Document Question Answering|文档问答中的上下文感知视觉解释：DocVXQA|Mohamed Ali Souibgui, Changkyu Choi, Andrey Barsky, Kangsoo Jung, Ernest Valveny, Dimosthenis Karatzas|<http://arxiv.org/pdf/2505.07496v1>|[代码](https://github.com/dali92002/DocVXQA.); 提出DocVXQA框架，通过学习视觉热图解释文档问答模型决策，实现准确回答与可解释性平衡。|
|📝 更新|Think or Not Think: A Study of Explicit Thinking in Rule-Based Visual Reinforcement Fine-Tuning|思考与否：基于规则视觉强化微调中显式思维的研究|Ming Li, Jike Zhong, Shitian Zhao, Yuxiang Lai, Haoquan Zhang, Wang Bill Zhu, Kaipeng Zhang|<http://arxiv.org/pdf/2503.16188v4>|提出CLS-RL和No-Thinking-RL，挑战RFT中显式思考的必要性，并探索自适应思考在视觉...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Prompt to Polyp: Medical Text-Conditioned Image Synthesis with Diffusion Models|提示至息肉：基于医学文本的扩散模型条件图像合成|Mikhail Chaichuk, Sushant Gautam, Steven Hicks, Elena Tutubalina|<http://arxiv.org/pdf/2505.05573v2>|提出了一种基于扩散模型的医疗文本条件图像合成方法，有效解决医疗数据稀缺问题。|
|🆕 发布|Anatomical Attention Alignment representation for Radiology Report Generation|解剖注意力对齐表示用于放射学报告生成|Quang Vinh Nguyen, Minh Duc Nguyen, Thanh Hoang Son Vo, Hyung-Jeong Yang, Soo-Hyung Kim|<http://arxiv.org/pdf/2505.07689v1>|[代码](https://github.com/Vinh-AI/A3Net); 提出A3Net，通过构建超视觉表示，提升放射报告生成中视觉与文本理解的准确性。|
|🆕 发布|ABS-Mamba: SAM2-Driven Bidirectional Spiral Mamba Network for Medical Image Translation|ABS-Mamba：基于SAM2的双向螺旋Mamba网络用于医学图像转换|Feng Yuan, Yifan Gao, Wenbin Wu, Keqing Wu, Xiaotong Guo, Jie Jiang, Xin Gao|<http://arxiv.org/pdf/2505.07687v1>|[代码](https://github.com/gatina-yone/ABS-Mamba); 提出ABS-Mamba，一种结合SAM2和CNN的医学图像翻译网络，提升诊断准确性。|
|🆕 发布|Robust Kidney Abnormality Segmentation: A Validation Study of an AI-Based Framework|鲁棒肾脏异常分割：基于人工智能框架的验证研究|Sarah de Boer, Hartmut Häntze, Kiran Vaidhya Venkadesh, Myrthe A. D. Buser, Gabriel E. Humpire Mamani, Lina Xu, Lisa C. Adams, Jawed Nawabi .etc.|<http://arxiv.org/pdf/2505.07573v1>|[代码](https://github.com/DIAGNijmegen/oncology-kidney-abnormality-segmentation.); 开发了一种基于nnU-Net的公开数据训练的肾脏异常分割算法，显著提升了临床评估的客观性和可靠性。|
|📝 更新|Efficient and Comprehensive Feature Extraction in Large Vision-Language Model for Clinical Pathology Analysis|高效且全面的临床病理分析大型视觉-语言模型特征提取|Shengxuming Zhang, Weihan Li, Tianhong Gao, Jiacong Hu, Haoming Luo, Xiuming Zhang, Jing Zhang, Mingli Song .etc.|<http://arxiv.org/pdf/2412.09521v2>|提出混合任务引导和提示引导策略，显著提升病理图像分析模型的诊断准确性和效率。|
|🆕 发布|Metrics that matter: Evaluating image quality metrics for medical image generation|重要指标：评估医学图像生成中的图像质量指标|Yash Deo, Yan Jia, Toni Lassila, William A. P. Smith, Tom Lawton, Siyuan Kang, Alejandro F. Frangi, Ibrahim Habli|<http://arxiv.org/pdf/2505.07175v1>|评估医学图像生成质量指标，揭示其局限性，并提出综合验证框架以确保模型临床适用性。|
|🆕 发布|Skull stripping with purely synthetic data|仅使用合成数据进行颅骨剥离|Jong Sung Park, Juhyung Ha, Siddhesh Thakur, Alexandra Badea, Spyridon Bakas, Eleftherios Garyfallidis|<http://arxiv.org/pdf/2505.07159v1>|提出PUMBA，一种无需真实脑部图像或标签训练模型进行脑部提取的新方法。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Self-Adaptive Gamma Context-Aware SSM-based Model for Metal Defect Detection|自适应性伽马上下文感知SSM模型在金属缺陷检测中的应用|Sijin Sun, Ming Deng, Xingrui Yu, Xingyu Xi, Liangbin Zhao|<http://arxiv.org/pdf/2503.01234v3>|提出了一种自适应伽马上下文感知状态空间搜索管理模型，有效提升了金属缺陷检测的准确性和鲁棒性。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Veri-Car: Towards Open-world Vehicle Information Retrieval|Veri-Car：迈向开放世界车辆信息检索|Andrés Muñoz, Nancy Thomas, Annita Vapsi, Daniel Borrajo|<http://arxiv.org/pdf/2411.06864v4>|Veri-Car通过结合预训练模型和多相似度损失，实现了对车辆信息的开放世界检索。|
|🆕 发布|Human Motion Prediction via Test-domain-aware Adaptation with Easily-available Human Motions Estimated from Videos|通过从视频中估计的易于获取的人体运动实现测试域感知自适应的人体运动预测|Katsuki Shimbo, Hiromu Taketsugu, Norimichi Ukita|<http://arxiv.org/pdf/2505.07301v1>|通过利用易于获取的视频估计人体动作，该方法增强了3D人体运动预测模型，提高了其在测试域的泛化能力。|

