## [UPDATED!] **2025-05-13** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Efficient Adaptation For Remote Sensing Visual Grounding|高效遥感视觉定位自适应|Hasan Moughnieh, Mohamad Chalhoub, Hasan Nasrallah, Cristiano Nattero, Paolo Campanella, Giovanni Nico, Ali J. Ghandour|<http://arxiv.org/pdf/2503.23083v2>|利用参数高效微调技术，显著降低计算成本，提升遥感视觉定位性能。|
|📝 更新|2.5 Years in Class: A Multimodal Textbook for Vision-Language Pretraining|2.5年课堂经验：视觉-语言预训练的多模态教科书|Wenqi Zhang, Hang Zhang, Xin Li, Jiashuo Sun, Yongliang Shen, Weiming Lu, Deli Zhao, Yueting Zhuang .etc.|<http://arxiv.org/pdf/2501.00958v4>|[代码](https://github.com/DAMO-NLP-SG/multimodal_textbook.); 构建高质量多模态教科书语料库，提升视觉语言模型预训练性能。|
|🆕 发布|SPAST: Arbitrary Style Transfer with Style Priors via Pre-trained Large-scale Model|SPAST：通过预训练大规模模型实现具有风格先验的任意风格迁移|Zhanjie Zhang, Quanwei Zhang, Junsheng Luan, Mengyuan Yang, Yun Wang, Lei Zhao|<http://arxiv.org/pdf/2505.08695v1>|提出SPAST框架，通过融合风格特征和引入风格先验损失，实现高效且高质量的任意风格迁移。|
|🆕 发布|Boosting Zero-shot Stereo Matching using Large-scale Mixed Images Sources in the Real World|基于大规模真实世界混合图像源提升零样本立体匹配|Yuran Wang, Yingping Liang, Ying Fu|<http://arxiv.org/pdf/2505.08607v1>|提出BooSTer框架，结合大规模混合图像源和视觉基础模型，有效提升零样本立体匹配准确度。|
|📝 更新|GBT-SAM: Adapting a Foundational Deep Learning Model for Generalizable Brain Tumor Segmentation via Efficient Integration of Multi-Parametric MRI Data|GBT-SAM：通过高效整合多参数MRI数据，将基础深度学习模型适应于通用脑肿瘤分割|Cecilia Diana-Albelda, Roberto Alcover-Couso, Álvaro García-Martín, Jesus Bescos, Marcos Escudero-Viñolo|<http://arxiv.org/pdf/2503.04325v3>|[代码](https://github.com/vpulab/med-sam-brain); 提出了一种基于SAM的轻量级脑肿瘤分割模型，有效利用mp-MRI数据并提高分割准确性。|
|📝 更新|TUM2TWIN: Introducing the Large-Scale Multimodal Urban Digital Twin Benchmark Dataset|TUM2TWIN：介绍大规模多模态城市数字孪生基准数据集|Olaf Wysocki, Benedikt Schwab, Manoj Kumar Biswanath, Michael Greza, Qilin Zhang, Jingwei Zhu, Thomas Froech, Medhini Heeramaglore .etc.|<http://arxiv.org/pdf/2505.07396v2>|构建了首个大规模多模态城市数字孪生基准数据集，支持城市数字孪生创建和下游任务研究。|
|🆕 发布|An integrated language-vision foundation model for conversational diagnostics and triaging in primary eye care|集成语言-视觉基础模型用于初级眼科护理中的对话诊断和分级|Zhi Da Soh, Yang Bai, Kai Yu, Yang Zhou, Xiaofeng Lei, Sahil Thakur, Zann Lee, Lee Ching Linette Phang .etc.|<http://arxiv.org/pdf/2505.08414v1>|开发了一种集成语言和视觉模型，用于提高初级眼科诊断的准确性和易用性。|
|📝 更新|Diffusion-VLA: Scaling Robot Foundation Models via Unified Diffusion and Autoregression|扩散-自回归语言模型：通过统一扩散和自回归扩展机器人基础模型|Junjie Wen, Minjie Zhu, Yichen Zhu, Zhibin Tang, Jinming Li, Zhongyi Zhou, Chengmeng Li, Xiaoyu Liu .etc.|<http://arxiv.org/pdf/2412.03293v2>|Diffusion-VLA通过结合扩散模型和自回归模型，实现了机器人视觉运动策略的推理和高效学习。|
|🆕 发布|A computer vision-based model for occupancy detection using low-resolution thermal images|基于计算机视觉的占用检测低分辨率热成像模型|Xue Cui, Vincent Gbouna Zakka, Minhyun Lee|<http://arxiv.org/pdf/2505.08336v1>|开发了一种利用低分辨率热图像和YOLOv5模型进行占用检测的方法，有效缓解隐私问题并降低计算需求。|
|🆕 发布|EventDiff: A Unified and Efficient Diffusion Model Framework for Event-based Video Frame Interpolation|事件差异：一种统一且高效的基于事件的视频帧插值扩散模型框架|Hanle Zheng, Xujie Han, Zegang Peng, Shangbin Zhang, Guangxun Du, Zhuo Zou, Xilin Wang, Jibin Wu .etc.|<http://arxiv.org/pdf/2505.08235v1>|检测并融合动态事件流与静态帧，EventDiff显著提升了基于事件的视频帧插值性能。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Aya Vision: Advancing the Frontier of Multilingual Multimodality|Aya视觉：推动多语言多模态前沿|Saurabh Dash, Yiyang Nan, John Dang, Arash Ahmadian, Shivalika Singh, Madeline Smith, Bharat Venkitesh, Vlad Shmyhlo .etc.|<http://arxiv.org/pdf/2505.08751v1>|提出Aya Vision，通过创新数据标注和跨模态模型融合技术，提升多语言多模态语言模型性能。|
|🆕 发布|TiMo: Spatiotemporal Foundation Model for Satellite Image Time Series|TiMo：卫星图像时间序列的空间时间基础模型|Xiaolei Qin, Di Wang, Jing Zhang, Fengxiang Wang, Xin Su, Bo Du, Liangpei Zhang|<http://arxiv.org/pdf/2505.08723v1>|[代码](https://github.com/MiliLab/TiMo.); 提出TiMo模型，通过时空陀螺仪注意力机制，有效捕捉卫星图像时间序列的多尺度时空关系。|
|📝 更新|MGPATH: Vision-Language Model with Multi-Granular Prompt Learning for Few-Shot WSI Classification|MGPATH：基于多粒度提示学习的视觉-语言模型在少样本WSI分类中的应用|Anh-Tien Nguyen, Duy Minh Ho Nguyen, Nghiem Tuong Diep, Trung Quoc Nguyen, Nhat Ho, Jacqueline Michelle Metsch, Miriam Cindy Maurer, Daniel Sonntag .etc.|<http://arxiv.org/pdf/2502.07409v2>|提出MGPATH，通过多粒度提示学习，有效提升了病理图像分类的泛化能力。|
|🆕 发布|CNN and ViT Efficiency Study on Tiny ImageNet and DermaMNIST Datasets|CNN与ViT在Tiny ImageNet和DermaMNIST数据集上的效率研究|Aidar Amangeldi, Angsar Taigonyrov, Muhammad Huzaid Jawad, Chinedu Emmanuel Mbonu|<http://arxiv.org/pdf/2505.08259v1>|研究CNN与ViT在Tiny ImageNet和DermaMNIST上的效率，提出微调策略，实现快速...|
|🆕 发布|Empowering Vision Transformers with Multi-Scale Causal Intervention for Long-Tailed Image Classification|赋能视觉Transformer的多尺度因果干预以实现长尾图像分类|Xiaoshuo Yan, Zhaochuan Li, Lei Meng, Zhuang Qi, Wei Wu, Zixuan Li, Xiangxu Meng|<http://arxiv.org/pdf/2505.08173v1>|提出TSCNet，通过多尺度因果干预解决视觉Transformer在长尾图像分类中的偏差问题。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|No Other Representation Component Is Needed: Diffusion Transformers Can Provide Representation Guidance by Themselves|无需其他表示组件：扩散变换器可自行提供表示指导|Dengyang Jiang, Mengmeng Wang, Liuzhuozheng Li, Lei Zhang, Haoyu Wang, Wei Wei, Guang Dai, Yanning Zhang .etc.|<http://arxiv.org/pdf/2505.02831v3>|提出Self-Representation Alignment方法，无需额外组件，提升扩散模型生成质...|
|🆕 发布|A portable diagnosis model for Keratoconus using a smartphone|基于智能手机的角膜圆锥形病变便携式诊断模型|Yifan Li, Myeongjun Kim, Yanjing Jin, Peter Ho, Jo Woon Chong|<http://arxiv.org/pdf/2505.08616v1>|开发了一种基于智能手机的便携式角膜圆锥形病变诊断模型，通过图像识别技术实现疾病阶段和严重程度的准确识...|
|🆕 发布|DFA-CON: A Contrastive Learning Approach for Detecting Copyright Infringement in DeepFake Art|DFA-CON：一种用于检测DeepFake艺术侵权行为的对比学习方法|Haroon Wahab, Hassan Ugail, Irfan Mehmood|<http://arxiv.org/pdf/2505.08552v1>|提出DFA-CON对比学习框架，有效检测AI生成艺术作品的版权侵权问题。|
|📝 更新|DexVLA: Vision-Language Model with Plug-In Diffusion Expert for General Robot Control|DexVLA：具有插件扩散专家的通用机器人控制视觉-语言模型|Junjie Wen, Yichen Zhu, Jinming Li, Zhibin Tang, Chaomin Shen, Feifei Feng|<http://arxiv.org/pdf/2502.05855v2>|提出DexVLA，通过插件式扩散专家和新型课程学习策略，提升VLA模型在复杂任务上的效率和泛化能力。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VIViT: Variable-Input Vision Transformer Framework for 3D MR Image Segmentation|VIViT：用于3D磁共振图像分割的可变输入视觉Transformer框架|Badhan Kumar Das, Ajay Singh, Gengyan Zhao, Han Liu, Thomas J. Re, Dorin Comaniciu, Eli Gibson, Andreas Maier|<http://arxiv.org/pdf/2505.08693v1>|提出VIViT，一种适应不同对比度的3D MR图像分割变输入ViT框架，提升实际异构MR数据分割性能...|
|🆕 发布|WaveGuard: Robust Deepfake Detection and Source Tracing via Dual-Tree Complex Wavelet and Graph Neural Networks|波盾：基于双树复小波和图神经网络的鲁棒深度伪造检测与溯源|Ziyuan He, Zhiqing Guo, Liejun Wang, Gaobo Yang, Yunfeng Diao, Dan Ma|<http://arxiv.org/pdf/2505.08614v1>|[代码](https://github.com/vpsg-research/WaveGuard.); WaveGuard通过双重树复波变换和图神经网络，实现了鲁棒的深度伪造检测和溯源。|
|🆕 发布|Thermal Detection of People with Mobility Restrictions for Barrier Reduction at Traffic Lights Controlled Intersections|人体行动受限者的热成像检测以降低交通信号灯控制交叉口的障碍|Xiao Ni, Carsten Kuehnel, Xiaoyi Jiang|<http://arxiv.org/pdf/2505.08568v1>|[代码](https://github.com/leon2014dresden/YOLO-THERMAL.); 提出了一种基于热成像的智能交通灯系统，为行动不便者提供无障碍通行，并提升隐私和检测鲁棒性。|
|📝 更新|Enhancing Scene Coordinate Regression with Efficient Keypoint Detection and Sequential Information|增强场景坐标回归的鲁棒性：高效关键点检测与序列信息|Kuan Xu, Zeyu Jiang, Haozhi Cao, Shenghai Yuan, Chen Wang, Lihua Xie|<http://arxiv.org/pdf/2412.06488v2>|提出了一种结合高效关键点检测和序列信息的场景坐标回归方法，显著提升了定位效率和准确度。|
|🆕 发布|MoKD: Multi-Task Optimization for Knowledge Distillation|MoKD：多任务优化知识蒸馏|Zeeshan Hayder, Ali Cheraghian, Lars Petersson, Mehrtash Harandi|<http://arxiv.org/pdf/2505.08170v1>|MoKD通过多任务优化和子空间学习框架，有效解决知识蒸馏中的梯度冲突和梯度主导问题，显著提升模型性能...|
|📝 更新|Assessing the Feasibility of Internet-Sourced Video for Automatic Cattle Lameness Detection|评估互联网视频用于自动检测牛跛行的可行性|Md Fahimuzzman Sohan, A. H. Abdul Hafez, Raid Alzubi|<http://arxiv.org/pdf/2504.16404v2>|该研究提出了一种利用互联网视频数据检测牛跛行的深度学习模型，简化了处理流程并提高了分类准确率。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MESSI: A Multi-Elevation Semantic Segmentation Image Dataset of an Urban Environment|城市环境多高程语义分割图像数据集：MESSI|Barak Pinkovich, Boaz Matalon, Ehud Rivlin, Hector Rotstein|<http://arxiv.org/pdf/2505.08589v1>|构建了包含多视角语义分割图像的MESSI数据集，用于评估无人机在密集城市环境中的语义分割。|
|🆕 发布|Dynamic Snake Upsampling Operater and Boundary-Skeleton Weighted Loss for Tubular Structure Segmentation|动态蛇形上采样算子和边界-骨架加权损失用于管状结构分割|Yiqi Chen, Ganghai Huang, Sheng Zhang, Jianglin Dai|<http://arxiv.org/pdf/2505.08525v1>|提出动态蛇形上采样算子和边界骨架加权损失，提升管状结构分割精度和拓扑一致性。|
|🆕 发布|GNCAF: A GNN-based Neighboring Context Aggregation Framework for Tertiary Lymphoid Structures Semantic Segmentation in WSI|GNCAF：一种基于图神经网络（GNN）的邻近上下文聚合框架，用于WSI中三级淋巴结构语义分割|Lei Su|<http://arxiv.org/pdf/2505.08430v1>|提出了一种基于图神经网络的邻近上下文聚合框架，有效提升了三级淋巴结构语义分割的准确率。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Calibrated and Efficient Sampling-Free Confidence Estimation for LiDAR Scene Semantic Segmentation|基于校准和高效的无采样置信度估计的激光雷达场景语义分割|Hanieh Shojaei Miandashti, Qianqian Zou, Claus Brenner|<http://arxiv.org/pdf/2411.11935v2>|提出了一种无采样、高效且置信度校准的LiDAR场景语义分割方法，显著提升处理速度并确保预测可靠性。|
|📝 更新|Clinically inspired enhance Explainability and Interpretability of an AI-Tool for BCC diagnosis based on expert annotation|基于专家标注的BCC诊断AI工具的临床启发式增强可解释性和可解释性|Iván Matas, Carmen Serrano, Francisca Silva, Amalia Serrano, Tomás Toledo-Pastrana, Begoña Acha|<http://arxiv.org/pdf/2407.00104v2>|开发了一种基于专家标注的AI工具，通过可视化解释提高BCC诊断的可解释性和准确性。|
|📝 更新|Brain Hematoma Marker Recognition Using Multitask Learning: SwinTransformer and Swin-Unet|脑出血标志物识别：多任务学习中的SwinTransformer和Swin-U-Net|Kodai Hirata, Tsuyoshi Okita|<http://arxiv.org/pdf/2505.06185v2>|提出MTL-Swin-Unet，利用多任务学习增强脑出血标记识别，提升分类和语义分割性能。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HMPNet: A Feature Aggregation Architecture for Maritime Object Detection from a Shipborne Perspective|HMPNet：一种从船载视角进行海事目标检测的特征聚合架构|Yu Zhang, Fengyuan Liu, Juan Lyu, Yi Wei, Changdong Yu|<http://arxiv.org/pdf/2505.08231v1>|HMPNet通过引入Navigation12数据集和轻量级架构，有效提升了船载目标检测的准确性和效率...|


## 生成式视觉模型 (Generative Visual Modeling)


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VideoUFO: A Million-Scale User-Focused Dataset for Text-to-Video Generation|视频UFO：面向用户的百万规模文本到视频生成数据集|Wenhao Wang, Yi Yang|<http://arxiv.org/pdf/2503.01739v2>|[代码](https://github.com/WangWenhao0716/BenchUFO); 构建了首个针对用户关注点的视频数据集VideoUFO，提升文本到视频生成模型的性能。|
|📝 更新|TextCenGen: Attention-Guided Text-Centric Background Adaptation for Text-to-Image Generation|文本中心背景自适应的注意力引导文本到图像生成|Tianyi Liang, Jiangqi Liu, Yifei Huang, Shiqi Jiang, Jianshen Shi, Changbo Wang, Chenhui Li|<http://arxiv.org/pdf/2404.11824v5>|TextCenGen通过注意力引导动态背景适配，有效解决文本到图像生成中背景与文本冲突问题。|
|📝 更新|FMNV: A Dataset of Media-Published News Videos for Fake News Detection|FMNV：用于虚假新闻检测的媒体发布新闻视频数据集|Yihao Wang, Zhong Qian, Peifeng Li|<http://arxiv.org/pdf/2504.07687v3>|[代码](https://github.com/DennisIW/FMNV.); 构建了包含媒体发布新闻视频的FMNV数据集，并提出了FMNVD模型以检测假新闻。|
|🆕 发布|FauForensics: Boosting Audio-Visual Deepfake Detection with Facial Action Units|面部动作单元增强的音频-视觉深度伪造检测：FauForensics|Jian Wang, Baoyuan Wu, Li Liu, Qingshan Liu|<http://arxiv.org/pdf/2505.08294v1>|提出FauForensics框架，利用面部动作单元提升多模态深伪视频检测准确率。|
|🆕 发布|Removing Watermarks with Partial Regeneration using Semantic Information|去除水印：利用语义信息进行部分重建|Krti Tallam, John Kevin Cava, Caleb Geniesse, N. Benjamin Erichson, Michael W. Mahoney|<http://arxiv.org/pdf/2505.08234v1>|提出了一种针对语义水印的攻击方法，通过部分图像再生去除水印，同时保持图像内容完整性。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HarmoniCa: Harmonizing Training and Inference for Better Feature Caching in Diffusion Transformer Acceleration|HarmoniCa：在扩散Transformer加速中实现更好的特征缓存，实现训练与推理的和谐统一|Yushi Huang, Zining Wang, Ruihao Gong, Jing Liu, Xinjie Zhang, Jinyang Guo, Xianglong Liu, Jun Zhang|<http://arxiv.org/pdf/2410.01723v5>|[代码](https://github.com/ModelTC/HarmoniCa.); HarmoniCa通过优化特征缓存和平衡训练与推理，显著提升了扩散Transformer的加速性能。|
|📝 更新|Deep Representation Learning for Unsupervised Clustering of Myocardial Fiber Trajectories in Cardiac Diffusion Tensor Imaging|深度表示学习在心脏扩散张量成像中无监督聚类心肌纤维轨迹|Mohini Anand, Xavier Tricoche|<http://arxiv.org/pdf/2504.01953v2>|提出了一种结合双向LSTM和Transformer的深度学习框架，实现了心肌纤维轨迹的无监督聚类，提...|
|🆕 发布|Controllable Image Colorization with Instance-aware Texts and Masks|可控图像着色：基于实例感知文本和掩码|Yanru An, Ling Gui, Qiang Hu, Chunlei Cai, Tianxiao Ye, Xiaoyun Zhang, Yanfeng Wang|<http://arxiv.org/pdf/2505.08705v1>|提出了一种基于扩散模型和注意力机制的图像色彩化方法，实现精确的实例级色彩化并解决色彩溢出和绑定问题。|
|📝 更新|EMPERROR: A Flexible Generative Perception Error Model for Probing Self-Driving Planners|EMPERROR：一种灵活的生成感知错误模型，用于探测自动驾驶规划器|Niklas Hanselmann, Simon Doll, Marius Cordts, Hendrik P. A. Lensch, Andreas Geiger|<http://arxiv.org/pdf/2411.07719v2>|提出EMPERROR模型，通过生成感知误差样本提升自动驾驶规划器的鲁棒性。|
|📝 更新|DiTPainter: Efficient Video Inpainting with Diffusion Transformers|DiTPainter：基于扩散变换器的有效视频修复|Xian Wu, Chang Liu|<http://arxiv.org/pdf/2504.15661v2>|DiTPainter利用轻量级Diffusion Transformer模型，高效解决视频修复问题，...|
|📝 更新|Gaussian Shading++: Rethinking the Realistic Deployment Challenge of Performance-Lossless Image Watermark for Diffusion Models|高斯阴影++：重新思考扩散模型中性能无损图像水印的实用部署挑战|Zijin Yang, Xin Zhang, Kejiang Chen, Kai Zeng, Qiyi Yao, Han Fang, Weiming Zhang, Nenghai Yu|<http://arxiv.org/pdf/2504.15026v2>|提出Gaussian Shading++方法，解决扩散模型图像水印性能损失与实际部署挑战。|
|📝 更新|Optimized View and Geometry Distillation from Multi-view Diffuser|多视角扩散器中的优化视图和几何蒸馏|Youjia Zhang, Zikai Song, Junqing Yu, Yawei Luo, Wei Yang|<http://arxiv.org/pdf/2312.06198v4>|[代码](https://youjiazhang.github.io/USD); 提出了一种优化多视角图像生成的方法，通过改进几何提取和视图一致性，实现高质量多视角图像生成。|
|🆕 发布|TT-DF: A Large-Scale Diffusion-Based Dataset and Benchmark for Human Body Forgery Detection|TT-DF：人体伪造检测的大规模扩散数据集和基准|Wenkui Yang, Zhida Zhang, Xiaoqiang Zhou, Junxian Duan, Jie Cao|<http://arxiv.org/pdf/2505.08437v1>|[代码](https://github.com/HashTAG00002/TT-DF.); 构建了大规模人体伪造检测数据集TT-DF，并提出TOF-Net模型有效识别伪造视频。|
|🆕 发布|Ultra Lowrate Image Compression with Semantic Residual Coding and Compression-aware Diffusion|超低比特率图像压缩：基于语义残差编码和感知扩散的压缩|Anle Ke, Xu Zhang, Tong Chen, Ming Lu, Chao Zhou, Jiawen Gu, Zhan Ma|<http://arxiv.org/pdf/2505.08281v1>|提出ResULIC，通过语义残差编码和压缩感知扩散模型，显著提升图像压缩效率和重建质量。|
|📝 更新|ConceptMaster: Multi-Concept Video Customization on Diffusion Transformer Models Without Test-Time Tuning|概念大师：无需测试时调整的扩散Transformer模型上的多概念视频定制|Yuzhou Huang, Ziyang Yuan, Quande Liu, Qiulin Wang, Xintao Wang, Ruimao Zhang, Pengfei Wan, Di Zhang .etc.|<http://arxiv.org/pdf/2501.04698v2>|ConceptMaster通过学习多概念嵌入并注入扩散模型，有效解决视频定制中的身份解耦问题，显著提...|
|🆕 发布|Identifying Memorization of Diffusion Models through p-Laplace Analysis|通过p-Laplace分析识别扩散模型的记忆化|Jonathan Brokman, Amit Giloni, Omer Hofman, Roman Vainshtein, Hisashi Kojima, Guy Gilboa|<http://arxiv.org/pdf/2505.08246v1>|通过p-Laplace分析识别扩散模型对训练数据的记忆，首次实现基于p-Laplace算子的记忆识别...|
|🆕 发布|ACT-R: Adaptive Camera Trajectories for 3D Reconstruction from Single Image|自适应相机轨迹从单张图像进行3D重建的ACT-R|Yizhi Wang, Mingrui Zhao, Ali Mahdavi-Amiri, Hao Zhang|<http://arxiv.org/pdf/2505.08239v1>|提出了一种自适应相机轨迹规划方法，有效揭示遮挡并提高单图3D重建的3D一致性。|
|📝 更新|Schrödinger Diffusion Driven Signal Recovery in 3T BOLD fMRI Using Unmatched 7T Observations|利用未匹配的7T观察数据在3T BOLD fMRI中驱动Schrödinger扩散驱动的信号恢复|Yujian Xiong, Xuanzhao Dong, Sebastian Waz, Wenhui Zhu, Negar Mallak, Zhong-lin Lu, Yalin Wang|<http://arxiv.org/pdf/2504.01004v2>|利用7T fMRI数据提升3T fMRI图像质量，实现无监督信号恢复。|
|🆕 发布|Visual Watermarking in the Era of Diffusion Models: Advances and Challenges|视觉水印在扩散模型时代：进展与挑战|Junxian Duan, Jiyang Guang, Wenkui Yang, Ran He|<http://arxiv.org/pdf/2505.08197v1>|利用扩散模型提升视觉水印鲁棒性，应对生成AI时代版权侵权挑战。|
|📝 更新|DreamO: A Unified Framework for Image Customization|DreamO：图像定制的统一框架|Chong Mou, Yanze Wu, Wenxu Wu, Zinan Guo, Pengze Zhang, Yufeng Cheng, Yiming Luo, Fei Ding .etc.|<http://arxiv.org/pdf/2504.16915v3>|DreamO提出统一框架，实现图像多样化定制，支持多条件灵活整合。|
|🆕 发布|Unsupervised Raindrop Removal from a Single Image using Conditional Diffusion Models|基于条件扩散模型的单图像无监督雨滴去除|Lhuqita Fazry, Valentino Vito|<http://arxiv.org/pdf/2505.08190v1>|提出了一种基于扩散模型的单图像雨滴去除技术，显著提升了图像质量。|
|📝 更新|Learning Phase Distortion with Selective State Space Models for Video Turbulence Mitigation|利用选择性状态空间模型学习视频湍流抑制中的相位失真|Xingguang Zhang, Nicholas Chimitt, Xijun Wang, Yu Yuan, Stanley H. Chan|<http://arxiv.org/pdf/2504.02697v2>|提出了一种基于选择性状态空间模型和潜在相位畸变学习的视频湍流抑制新方法，显著提升处理速度并超越现有技...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RT-GAN: Recurrent Temporal GAN for Adding Lightweight Temporal Consistency to Frame-Based Domain Translation Approaches|RT-GAN：用于基于帧的领域翻译方法添加轻量级时间一致性的循环时间生成对抗网络|Shawn Mathew, Saad Nadeem, Alvin C. Goh, Arie Kaufman|<http://arxiv.org/pdf/2310.00868v2>|[代码](https://github.com/nadeemlab/CEP); 提出RT-GAN，通过轻量级方法为基于帧的领域翻译添加时间一致性，降低训练需求五倍。|
|🆕 发布|CAD-Coder:Text-Guided CAD Files Code Generation|CAD-Coder：文本引导的CAD文件代码生成|Changqi He, Shuhan Zhang, Liguo Zhang, Jiajun Miao|<http://arxiv.org/pdf/2505.08686v1>|CAD-Coder将自然语言指令转化为可编辑的CAD文件，实现交互式个性化设计。|
|📝 更新|High-Quality Spatial Reconstruction and Orthoimage Generation Using Efficient 2D Gaussian Splatting|高效二维高斯分层技术实现高质量空间重建和正射影像生成|Qian Wang, Zhihao Zhan, Jialei He, Zhituo Tu, Xiang Zhu, Jie Yuan|<http://arxiv.org/pdf/2503.19703v2>|提出了一种基于2D高斯分层技术的高精度空间重建和正射影像生成方法，有效降低计算成本并提高效率。|
|🆕 发布|STORYANCHORS: Generating Consistent Multi-Scene Story Frames for Long-Form Narratives|故事锚点：为长篇叙事生成一致的多场景故事框架|Bo Wang, Haoyang Huang, Zhiyin Lu, Fengyuan Liu, Guoqing Ma, Jianlong Yuan, Yuan Zhang, Nan Duan|<http://arxiv.org/pdf/2505.08350v1>|提出StoryAnchors，一种生成具有时间一致性和丰富叙事的多场景故事框架的统一框架。|
|📝 更新|HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene Generation|HoloTime：驯服视频扩散模型以生成全景4D场景|Haiyang Zhou, Wangbo Yu, Jiawen Guan, Xinhua Cheng, Yonghong Tian, Li Yuan|<http://arxiv.org/pdf/2504.21650v2>|HoloTime通过整合视频扩散模型和360度4D场景重建方法，实现了从单张图像生成沉浸式全景视频。|
|📝 更新|FLUXSynID: A Framework for Identity-Controlled Synthetic Face Generation with Document and Live Images|FLUXSynID：一种基于身份控制的合成人脸生成框架，支持文档和实时图像|Raul Ismayilov, Dzemila Sero, Luuk Spreeuwers|<http://arxiv.org/pdf/2505.07530v2>|FLUXSynID框架通过用户定义身份属性分布，生成与真实世界身份分布更匹配的合成人脸数据集。|
|📝 更新|CAST: Component-Aligned 3D Scene Reconstruction from an RGB Image|CAST：基于RGB图像的组件对齐3D场景重建|Kaixin Yao, Longwen Zhang, Xinhao Yan, Yan Zeng, Qixuan Zhang, Wei Yang, Lan Xu, Jiayuan Gu .etc.|<http://arxiv.org/pdf/2502.12894v2>|CAST通过提取图像中的物体分割和深度信息，结合GPT模型和3D生成模型，实现了高精度、物理一致的3...|
|📝 更新|UAV-VLA: Vision-Language-Action System for Large Scale Aerial Mission Generation|无人机-视觉-语言-动作系统：大规模空中任务生成|Oleg Sautenkov, Yasheerah Yaqoot, Artem Lykov, Muhammad Ahsan Mustafa, Grik Tadevosyan, Aibek Akhmetkazy, Miguel Altamirano Cabrera, Mikhail Martynov .etc.|<http://arxiv.org/pdf/2501.05014v2>|UAV-VLA系统通过结合VLM和GPT，实现简单文本请求生成高效飞行路径和行动计划，提升大规模空中...|
|🆕 发布|M3G: Multi-Granular Gesture Generator for Audio-Driven Full-Body Human Motion Synthesis|M3G：音频驱动全身人类运动合成的多粒度手势生成器|Zhizhuo Yin, Yuk Hang Tsui, Pan Hui|<http://arxiv.org/pdf/2505.08293v1>|提出M3G框架，通过多粒度VQ-VAE和音频信息提取，生成自然且丰富的全身人类手势。|
|📝 更新|Ophora: A Large-Scale Data-Driven Text-Guided Ophthalmic Surgical Video Generation Model|Ophora：一个大规模数据驱动的文本引导眼科手术视频生成模型|Wei Li, Ming Hu, Guoan Wang, Lihao Liu, Kaijin Zhou, Junzhi Ning, Xin Guo, Zongyuan Ge .etc.|<http://arxiv.org/pdf/2505.07449v2>|[代码](https://github.com/mar-cry/Ophora.); 提出Ophora模型，通过自然语言指令生成逼真的眼科手术视频，解决数据标注难题。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visually Guided Decoding: Gradient-Free Hard Prompt Inversion with Language Models|视觉引导解码：基于语言模型的梯度无关硬提示逆变换|Donghoon Kim, Minji Bae, Kyuhong Shim, Byonghyo Shim|<http://arxiv.org/pdf/2505.08622v1>|提出Visually Guided Decoding，利用LLMs和CLIP指导生成可理解、语义一致...|
|🆕 发布|Where the Devil Hides: Deepfake Detectors Can No Longer Be Trusted|魔鬼藏身之处：深度伪造检测器不再可信|Shuaiwei Yuan, Junyu Dong, Yuezun Li|<http://arxiv.org/pdf/2505.08255v1>|揭示了深度伪造检测器易受恶意数据攻击的风险，并提出了一种生成隐蔽触发器的解决方案。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Advancing Food Nutrition Estimation via Visual-Ingredient Feature Fusion|通过视觉成分特征融合推进食品营养估计|Huiyan Qi, Bin Zhu, Chong-Wah Ngo, Jingjing Chen, Ee-Peng Lim|<http://arxiv.org/pdf/2505.08747v1>|[代码](https://huiyanqi.github.io/fastfood-nutrition-estimation); 提出FastFood数据集和VIF²方法，融合视觉和成分特征，提升食物营养估计准确性。|
|🆕 发布|Monocular Depth Guided Occlusion-Aware Disparity Refinement via Semi-supervised Learning in Laparoscopic Images|单目深度引导的遮挡感知视差细化：基于半监督学习在腹腔镜图像中的应用|Ziteng Liu, Dongdong He, Chenghong Zhang, Wenpeng Gao, Yili Fu|<http://arxiv.org/pdf/2505.08178v1>|提出DGORNet，通过半监督学习利用单目深度信息，有效提升腹腔镜图像视差估计精度。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UniSkill: Imitating Human Videos via Cross-Embodiment Skill Representations|UniSkill：通过跨化身技能表示模仿人类视频|Hanjung Kim, Jaehyun Kang, Hyolim Kang, Meedeum Cho, Seon Joo Kim, Youngwoon Lee|<http://arxiv.org/pdf/2505.08787v1>|[代码](https://kimhanjung.github.io/UniSkill.); 提出UniSkill，通过学习跨实体技能表示，实现人类视频动作到机器人动作的有效迁移。|
|🆕 发布|Leveraging Multi-Modal Information to Enhance Dataset Distillation|利用多模态信息增强数据集蒸馏|Zhe Li, Hadrien Reynaud, Bernhard Kainz|<http://arxiv.org/pdf/2505.08605v1>|通过结合文本信息和对象级掩码，该方法显著提升了数据集蒸馏的质量。|
|📝 更新|Towards Anytime Optical Flow Estimation with Event Cameras|面向任意时间的光流估计：基于事件相机|Yaozu Ye, Hao Shi, Kailun Yang, Ze Wang, Xiaoting Yin, Lei Sun, Yaonan Wang, Kaiwei Wang|<http://arxiv.org/pdf/2307.05033v3>|[代码](https://github.com/Yaozhuwa/EVA-Flow.); 提出EVA-Flow网络，利用低帧率光流数据实现高帧率事件光流估计，并评估中间光流。|
|🆕 发布|A Survey of 3D Reconstruction with Event Cameras: From Event-based Geometry to Neural 3D Rendering|基于事件相机的3D重建综述：从事件几何到神经3D渲染|Chuanzhi Xu, Haoxian Zhou, Langyi Chen, Haodong Chen, Ying Zhou, Vera Chung, Qiang Qu|<http://arxiv.org/pdf/2505.08438v1>|首次全面综述了基于事件相机的3D重建技术，分类讨论了立体、单目和多模态系统，并提出了未来研究方向。|
|📝 更新|FANeRV: Frequency Separation and Augmentation based Neural Representation for Video|FANeRV：基于频率分离和增强的神经网络视频表示|Li Yu, Zhihui Li, Chao Yao, Jimin Xiao, Moncef Gabbouj|<http://arxiv.org/pdf/2504.06755v4>|FANeRV通过波分频和增强神经网络，有效提升视频重建性能。|
|📝 更新|Equipping Sketch Patches with Context-Aware Positional Encoding for Graphic Sketch Representation|为图形草图表示配备上下文感知位置编码的草图块|Sicong Zang, Zhijun Fang|<http://arxiv.org/pdf/2403.17525v2>|[代码](https://github.com/SCZang/DC-gra2seq.); 提出了一种通过引入上下文感知位置编码来增强草图表示的方法，显著提升了草图修复和可控合成效果。|
|🆕 发布|SpNeRF: Memory Efficient Sparse Volumetric Neural Rendering Accelerator for Edge Devices|SpNeRF：边缘设备上内存高效的稀疏体积神经渲染加速器|Yipu Zhang, Jiawei Liang, Jian Peng, Jiang Xu, Wei Zhang|<http://arxiv.org/pdf/2505.08191v1>|SpNeRF通过软件硬件协同设计，有效减少内存占用，加速边缘设备上的神经渲染。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GP-GS: Gaussian Processes for Enhanced Gaussian Splatting|GP-GS：增强高斯喷溅的高斯过程|Zhihao Guo, Jingxuan Su, Shenglin Wang, Jinlong Fan, Jing Zhang, Wei Zhou, Hadi Amirpour, Yunlong Zhao .etc.|<http://arxiv.org/pdf/2502.02283v5>|提出GP-GS方法，通过高斯过程增强稀疏SfM点云，提升3D场景重建质量。|
|🆕 发布|ADC-GS: Anchor-Driven Deformable and Compressed Gaussian Splatting for Dynamic Scene Reconstruction|ADC-GS：基于锚点的可变形和压缩高斯喷溅用于动态场景重建|He Huang, Qi Yang, Mufan Liu, Yiling Xu, Zhu Li|<http://arxiv.org/pdf/2505.08196v1>|[代码](https://github.com/H-Huang774/ADC-GS.git.); 提出ADC-GS方法，通过锚点驱动和压缩高斯分层优化动态场景重建效率。|
|📝 更新|Self-Supervised Learning for Robotic Leaf Manipulation: A Hybrid Geometric-Neural Approach|机器人叶片操作的自监督学习：一种混合几何-神经网络方法|Srecharan Selvam|<http://arxiv.org/pdf/2505.03702v2>|提出一种结合几何与神经网络的自主抓取方法，显著提升农业机器人叶片操作成功率。|


## 时序视觉分析 (Temporal Visual Analysis)


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Hierarchical and Multimodal Data for Daily Activity Understanding|层次化和多模态数据用于日常活动理解|Ghazal Kaviani, Yavuz Yarici, Seulgi Kim, Mohit Prabhushankar, Ghassan AlRegib, Mashhour Solh, Ameya Patil|<http://arxiv.org/pdf/2504.17696v3>|构建了多模态、分层标注的DARai数据集，以理解真实场景中的人类活动。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SkillFormer: Unified Multi-View Video Understanding for Proficiency Estimation|技能前体：统一的多视角视频理解用于技能评估|Edoardo Bianchi, Antonio Liotta|<http://arxiv.org/pdf/2505.08665v1>|SkillFormer通过融合多视角视频特征，实现了高效且参数节约的技能水平评估。|
|🆕 发布|VCRBench: Exploring Long-form Causal Reasoning Capabilities of Large Video Language Models|VCRBench：探索大型视频语言模型的长篇因果推理能力|Pritam Sarkar, Ali Etemad|<http://arxiv.org/pdf/2505.08455v1>|构建VCRBench基准，通过识别-推理分解提升大视频语言模型在视频因果推理上的表现。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DLO-Splatting: Tracking Deformable Linear Objects Using 3D Gaussian Splatting|DLO-Splatting：利用3D高斯Splatting跟踪可变形线性物体|Holly Dinkel, Marcel Büsching, Alberta Longhini, Brian Coltin, Trey Smith, Danica Kragic, Mårten Björkman, Timothy Bretl|<http://arxiv.org/pdf/2505.08644v1>|提出DLO-Splatting算法，通过3D高斯分层渲染预测和更新滤波，从多视角图像和机械臂状态信息...|
|🆕 发布|ReSurgSAM2: Referring Segment Anything in Surgical Video via Credible Long-term Tracking|ReSurgSAM2：通过可信长期跟踪在手术视频中实现指称分割任何事物|Haofeng Liu, Mingqi Gao, Xuxiao Luo, Ziyue Wang, Guanyi Qin, Junde Wu, Yueming Jin|<http://arxiv.org/pdf/2505.08581v1>|[代码](https://github.com/jinlab-imvr/ReSurgSAM2.); 提出了一种结合长期跟踪的手术视频目标分割框架，显著提升分割准确性和效率。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Reinforcement Learning meets Masked Video Modeling : Trajectory-Guided Adaptive Token Selection|强化学习与掩码视频建模相遇：轨迹引导自适应标记选择|Ayush K. Rai, Kyle Min, Tarun Krishna, Feiyan Hu, Alan F. Smeaton, Noel E. O'Connor|<http://arxiv.org/pdf/2505.08561v1>|提出了一种轨迹引导自适应采样方法，有效提升视频掩码建模性能。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting|利用Segment Anything模型通过双重特征引导的自动提示实现无源域自适应|Zheang Huai, Hui Tang, Yi Li, Zhuangzhuang Chen, Xiaomeng Li|<http://arxiv.org/pdf/2505.08527v1>|[代码](https://github.com/zheangh/DFG.); 利用Segment Anything Model自动寻找精确边界提示，实现无源域自适应分割。|
|📝 更新|Vision-Language Models Do Not Understand Negation|视觉-语言模型并不理解否定|Kumail Alhamoud, Shaden Alshammari, Yonglong Tian, Guohao Li, Philip Torr, Yoon Kim, Marzyeh Ghassemi|<http://arxiv.org/pdf/2501.09425v2>|该论文揭示了现代视觉语言模型在理解否定方面的不足，并提出通过在大规模合成数据集上微调CLIP模型来提...|
|🆕 发布|Decoding Neighborhood Environments with Large Language Models|用大型语言模型解码邻域环境|Andrew Cart, Shaohu Zhang, Melanie Escue, Xugui Zhou, Haitao Zhao, Prashanth BusiReddyGari, Beiyu Lin, Shuang Li|<http://arxiv.org/pdf/2505.08163v1>|利用大型语言模型解码社区环境，实现无标注数据下的环境指标识别。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DHECA-SuperGaze: Dual Head-Eye Cross-Attention and Super-Resolution for Unconstrained Gaze Estimation|DHECA-SuperGaze：双头部眼动交叉注意力和超分辨率的无约束眼动估计|Franko Šikić, Donik Vršnak, Sven Lončarić|<http://arxiv.org/pdf/2505.08426v1>|DHECA-SuperGaze通过超分辨率和双头眼交叉注意力模块，有效提升了无约束视线估计的准确性。|
|📝 更新|SeriesBench: A Benchmark for Narrative-Driven Drama Series Understanding|系列基准：基于叙事驱动的剧情理解基准|Chenkai Zhang, Yiming Lei, Zeming Liu, Haitao Leng, Shaoguo Liu, Tingting Gao, Qingjie Liu, Yunhong Wang|<http://arxiv.org/pdf/2504.21435v3>|[代码](https://github.com/zackhxn/SeriesBench-CVPR2025.); 提出SeriesBench基准，评估多模态大语言模型对叙事驱动剧集的理解能力，并引入PC-DCoT框...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DArFace: Deformation Aware Robustness for Low Quality Face Recognition|DArFace：面向低质量人脸识别的形变感知鲁棒性|Sadaf Gulshad, Abdullah Aldahlawi Thakaa|<http://arxiv.org/pdf/2505.08423v1>|DArFace通过引入局部变形建模，显著提升了低质量人脸识别的鲁棒性。|
|🆕 发布|Efficient Unstructured Pruning of Mamba State-Space Models for Resource-Constrained Environments|高效针对资源受限环境的Mamba状态空间模型的无结构剪枝|Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma|<http://arxiv.org/pdf/2505.08299v1>|提出了一种高效的无结构剪枝框架，显著降低Mamba模型参数量，同时保持高性能。|
|🆕 发布|G-MSGINet: A Grouped Multi-Scale Graph-Involution Network for Contactless Fingerprint Recognition|G-MSGINet：一种用于无接触指纹识别的分组多尺度图自旋网络|Santhoshkumar Peddi, Soham Bandyopadhyay, Debasis Samanta|<http://arxiv.org/pdf/2505.08233v1>|提出了一种高效的无接触指纹识别网络G-MSGINet，通过联合定位细节点和嵌入身份信息，显著提升了识...|
|📝 更新|An Analysis of Data Transformation Effects on Segment Anything 2|对Segment Anything 2数据转换效果的分析|Clayton Bromley, Alexander Moore, Amar Saini, Doug Poland, Carmen Carrano|<http://arxiv.org/pdf/2503.00042v2>|分析了数据变换对Segment Anything 2视频分割性能的影响，揭示了其架构如何处理复杂场景...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Large-scale Benchmark on Geological Fault Delineation Models: Domain Shift, Training Dynamics, Generalizability, Evaluation and Inferential Behavior|大规模地质断层边界模型基准：领域偏移、训练动态、泛化性、评估和推理行为|Jorge Quesada, Chen Zhou, Prithwijit Chowdhury, Mohammad Alotaibi, Ahmad Mustafa, Yusufjon Kumamnov, Mohit Prabhushankar, Ghassan AlRegib|<http://arxiv.org/pdf/2505.08585v1>|构建了首个大规模基准，系统评估地震解释中地质断层模型在不同数据集上的泛化能力，为领域迁移策略提供指导...|
|🆕 发布|Attention-based Generative Latent Replay: A Continual Learning Approach for WSI Analysis|基于注意力的生成潜在重放：一种用于WSI分析的持续学习方法|Pratibha Kumari, Daniel Reisenbüchler, Afshin Bozorgpour, Nadine S. Schaadt, Friedrich Feuerhake, Dorit Merhof|<http://arxiv.org/pdf/2505.08524v1>|提出AGLR-CL框架，通过注意力机制和生成式潜在重放，实现WSI分类的隐私保护持续学习。|
|🆕 发布|FAD: Frequency Adaptation and Diversion for Cross-domain Few-shot Learning|跨域小样本学习中的频率自适应与转移|Ruixiao Shi, Fu Feng, Yucheng Xie, Jing Wang, Xin Geng|<http://arxiv.org/pdf/2505.08349v1>|提出FAD方法，通过频率域自适应和转换提升跨域小样本学习泛化能力。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Breast Cancer Histopathology Classification using CBAM-EfficientNetV2 with Transfer Learning|基于迁移学习的CBAM-EfficientNetV2在乳腺癌组织病理学分类中的应用|Naren Sengodan|<http://arxiv.org/pdf/2410.22392v6>|提出了一种基于CBAM-EfficientNetV2的乳腺癌病理图像分类方法，显著提升了诊断精度。|
|🆕 发布|Rejoining fragmented ancient bamboo slips with physics-driven deep learning|利用物理驱动深度学习重新拼接破碎的古代竹简|Jinchi Zhu, Zhou Zhao, Hailong Lei, Xiaoguang Wang, Jialiang Lu, Jing Li, Qianqian Tang, Jiachen Shen .etc.|<http://arxiv.org/pdf/2505.08601v1>|利用物理原理和深度学习，WisePanda显著提升了古代竹简碎片拼接的准确性和效率。|
|🆕 发布|PrePrompt: Predictive prompting for class incremental learning|预测提示：类增量学习的预测提示|Libo Huang, Zhulin An, Chuanguang Yang, Boyu Diao, Fei Wang, Yan Zeng, Zhifeng Hao, Yongjun Xu|<http://arxiv.org/pdf/2505.08586v1>|PrePrompt通过预测特定任务提示，有效解决了增量学习中的特征空间拟合难题。|
|🆕 发布|The RaspGrade Dataset: Towards Automatic Raspberry Ripeness Grading with Deep Learning|RaspGrade数据集：基于深度学习的自动树莓成熟度分级|Mohamed Lamine Mekhalfi, Paul Chippendale, Fabio Poiesi, Samuele Bonecher, Gilberto Osler, Nicola Zancanella|<http://arxiv.org/pdf/2505.08537v1>|构建RaspGrade数据集，利用深度学习实现快速、准确的红莓分级。|
|🆕 发布|GradMix: Gradient-based Selective Mixup for Robust Data Augmentation in Class-Incremental Learning|GradMix：基于梯度的选择性Mixup在类增量学习中的鲁棒数据增强|Minsu Kim, Seong-Hyeon Hwang, Steven Euijong Whang|<http://arxiv.org/pdf/2505.08528v1>|GradMix通过基于梯度的选择性Mixup，有效缓解了增量学习中的灾难性遗忘问题。|
|📝 更新|Transforming Hyperspectral Images Into Chemical Maps: An End-to-End Deep Learning Approach|将高光谱图像转换为化学图谱：一种端到端的深度学习方法|Ole-Christian Galbo Engstrøm, Michela Albano-Gaglio, Erik Schou Dreier, Yamine Bouzembrak, Maria Font-i-Furnols, Puneet Mishra, Kim Steenstrup Pedersen|<http://arxiv.org/pdf/2504.14131v3>|提出了一种基于U-Net的深度学习方法，有效提升了从高光谱图像生成化学地图的准确性和空间相关性。|
|📝 更新|Using Few-Shot Learning to Classify Primary Lung Cancer and Other Malignancy with Lung Metastasis in Cytological Imaging via Endobronchial Ultrasound Procedures|利用小样本学习通过内窥镜超声程序对细胞学成像中的原发性肺癌和其他具有肺转移的恶性肿瘤进行分类|Ching-Kai Lin, Di-Chun Wei, Yun-Chien Cheng|<http://arxiv.org/pdf/2404.06080v3>|提出一种基于少量样本学习的模型，有效识别肺转移癌，助力早期诊断。|
|🆕 发布|Congenital Heart Disease recognition using Deep Learning/Transformer models|先天性心脏病识别利用深度学习/Transformer模型|Aidar Amangeldi, Vladislav Yarovenko, Angsar Taigonyrov|<http://arxiv.org/pdf/2505.08242v1>|利用深度学习和Transformer模型，通过双模态数据有效识别先天性心脏病。|
|📝 更新|Web2Grasp: Learning Functional Grasps from Web Images of Hand-Object Interactions|Web2Grasp：从手-物体交互的Web图像中学习功能性抓取|Hongyi Chen, Yunchao Yao, Yufei Ye, Zhixuan Xu, Homanga Bharadhwaj, Jiashun Wang, Shubham Tulsiani, Zackory Erickson .etc.|<http://arxiv.org/pdf/2505.05517v2>|[代码](https://web2grasp.github.io/.); 从网络图片中学习功能性抓取，为机器人手提供有效抓取能力。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Few-shot Novel Category Discovery|少量样本新型类别发现|Chunming Li, Shidong Wang, Haofeng Zhang|<http://arxiv.org/pdf/2505.08260v1>|提出FSNCD方法，通过少量支持样本实现新类别发现，提升模型推理能力。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|TinyVLA: Towards Fast, Data-Efficient Vision-Language-Action Models for Robotic Manipulation|TinyVLA：迈向快速、数据高效视觉-语言-动作模型用于机器人操作|Junjie Wen, Yichen Zhu, Jinming Li, Minjie Zhu, Kun Wu, Zhiyuan Xu, Ning Liu, Ran Cheng .etc.|<http://arxiv.org/pdf/2409.12514v5>|TinyVLA通过引入高效、紧凑的视觉-语言-动作模型，显著提升了推理速度和数据效率，解决了现有VL...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Autonomous UAV Visual Object Search in City Space: Benchmark and Agentic Methodology|面向城市空间中自主无人机视觉目标搜索：基准与代理方法|Yatai Ji, Zhengqiu Zhu, Yong Zhao, Beidan Liu, Chen Gao, Yihao Zhao, Sihang Qiu, Yue Hu .etc.|<http://arxiv.org/pdf/2505.08765v1>|提出CityAVOS基准数据集和PRPSearcher方法，解决城市空间中无人机自主视觉目标搜索问题...|
|📝 更新|Visual Imitation Enables Contextual Humanoid Control|视觉模仿实现情境化的人形机器人控制|Arthur Allshire, Hongsuk Choi, Junyi Zhang, David McAllister, Anthony Zhang, Chung Min Kim, Trevor Darrell, Pieter Abbeel .etc.|<http://arxiv.org/pdf/2505.03729v3>|通过模仿日常视频，VIDEOMIMIC实现了人形机器人对复杂环境的自适应控制。|
|🆕 发布|OpenThinkIMG: Learning to Think with Images via Visual Tool Reinforcement Learning|OpenThinkIMG：通过视觉工具强化学习学习用图像思考|Zhaochen Su, Linjie Li, Mingyang Song, Yunzhuo Hao, Zhengyuan Yang, Jun Zhang, Guanjie Chen, Jiawei Gu .etc.|<http://arxiv.org/pdf/2505.08617v1>|OpenThinkIMG通过视觉工具强化学习，使大型视觉语言模型学会灵活运用视觉工具解决问题。|
|🆕 发布|Judging the Judges: Can Large Vision-Language Models Fairly Evaluate Chart Comprehension and Reasoning?|评判者评判：大型视觉-语言模型能否公平评估图表理解和推理？|Md Tahmid Rahman Laskar, Mohammed Saidul Islam, Ridwan Mahbub, Ahmed Masry, Mizanur Rahman, Amran Bhuiyan, Mir Tafseer Nayeem, Shafiq Joty .etc.|<http://arxiv.org/pdf/2505.08468v1>|提出了一种利用开源大视觉语言模型评估图表理解与推理的标准化方法，揭示了其性能差异和潜在偏见。|
|🆕 发布|Improving Unsupervised Task-driven Models of Ventral Visual Stream via Relative Position Predictivity|通过相对位置预测性改进腹侧视觉通路的无监督任务驱动模型|Dazhong Rong, Hao Dong, Xing Gao, Jiyu Wei, Di Hong, Yaoyao Hao, Qinming He, Yueming Wang|<http://arxiv.org/pdf/2505.08316v1>|通过引入相对位置预测功能，提出了一种更符合生物现实的视觉通路无监督建模方法，提升了物体识别性能。|
|🆕 发布|Decoupled Multimodal Prototypes for Visual Recognition with Missing Modalities|解耦的多模态原型在视觉识别中处理缺失模态|Jueqing Lu, Yuanyuan Qi, Xiaohao Yang, Shujie Zhou, Lan Du|<http://arxiv.org/pdf/2505.08283v1>|提出了一种针对缺失模态的解耦原型输出头，显著提升多模态视觉识别性能。|
|📝 更新|HLV-1K: A Large-scale Hour-Long Video Benchmark for Time-Specific Long Video Understanding|HLV-1K：一个大规模的时长一小时视频基准，用于特定时间点长视频理解|Heqing Zou, Tianze Luo, Guiyang Xie, Victor Xiao Jie Zhang, Fengmao Lv, Guangcong Wang, Junyang Chen, Zhuochen Wang .etc.|<http://arxiv.org/pdf/2501.01645v3>|构建了大规模长视频理解基准HLV-1K，以评估长视频理解模型。|
|📝 更新|Benchmarking Multimodal Mathematical Reasoning with Explicit Visual Dependency|多模态数学推理的显式视觉依赖基准测试|Zhikai Wang, Jiashuo Sun, Wenqi Zhang, Zhiqiang Hu, Xin Li, Fan Wang, Deli Zhao|<http://arxiv.org/pdf/2504.18589v4>|[代码](https://alibaba-damo-academy.github.io/VCBench); 检测并解决现有基准测试在评估多模态数学推理时忽视视觉依赖性的问题，提出VCBENCH基准测试。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visual Image Reconstruction from Brain Activity via Latent Representation|通过潜在表示从脑活动进行视觉图像重建|Yukiyasu Kamitani, Misato Tanaka, Ken Shirakawa|<http://arxiv.org/pdf/2505.08429v1>|通过深度神经网络和生成模型，该论文提出了一种从脑活动重建视觉图像的新方法，提升了图像重建的准确性和泛...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FG-CLIP: Fine-Grained Visual and Textual Alignment|FG-CLIP：细粒度视觉与文本对齐|Chunyu Xie, Bin Wang, Fanjing Kong, Jincheng Li, Dawei Liang, Gengshen Zhang, Dawei Leng, Yuhui Yin|<http://arxiv.org/pdf/2505.05071v2>|[代码](https://github.com/360CVGroup/FG-CLIP.); FG-CLIP通过构建高质量数据集和引入负样本，提升了CLIP在细粒度视觉和文本对齐方面的性能。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Extending Large Vision-Language Model for Diverse Interactive Tasks in Autonomous Driving|扩展大型视觉-语言模型以支持自动驾驶中的多样化交互任务|Zongchuang Zhao, Haoyu Fu, Dingkang Liang, Xin Zhou, Dingyuan Zhang, Hongwei Xie, Bing Wang, Xiang Bai|<http://arxiv.org/pdf/2505.08725v1>|[代码](https://github.com/zc-zhao/DriveMonkey.); 提出NuInteract数据集和DriveMonkey框架，提升自动驾驶场景中视觉语言模型的全面理解...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Unsupervised Urban Land Use Mapping with Street View Contrastive Clustering and a Geographical Prior|无监督城市土地利用映射：基于街景对比聚类和地理先验|Lin Che, Yizi Chen, Tanhua Jin, Martin Raubal, Konrad Schindler, Peter Kiefer|<http://arxiv.org/pdf/2504.17551v2>|[代码](https://github.com/lin102/CCGP.); 提出了一种结合地理先验的无监督街景图像聚类方法，实现城市土地利用的无监督映射。|
|📝 更新|CHOICE: Benchmarking the Remote Sensing Capabilities of Large Vision-Language Models|CHOICE：评估大型视觉-语言模型的遥感能力基准|Xiao An, Jiaxing Sun, Zihan Gui, Wei He|<http://arxiv.org/pdf/2411.18145v3>|[代码](https://github.com/ShawnAn-WHU/CHOICE.); 提出CHOICE基准，系统评估大型视觉语言模型在遥感领域的感知和推理能力。|
|🆕 发布|Knowledge-Informed Deep Learning for Irrigation Type Mapping from Remote Sensing|基于知识的深度学习在遥感灌溉类型映射中的应用|Oishee Bintey Hoque, Nibir Chandra Mandal, Abhijin Adiga, Samarth Swarup, Sayjro Kossi Nouwakpo, Amanda Wilson, Madhav Marathe|<http://arxiv.org/pdf/2505.08302v1>|提出KIIM方法，结合专业知识与深度学习，有效提升灌溉类型遥感映射的准确性。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Calibration and Uncertainty for multiRater Volume Assessment in multiorgan Segmentation (CURVAS) challenge results|多器官分割中多评体积评估的校准与不确定性（CURVAS）挑战赛结果|Meritxell Riera-Marin, Sikha O K, Julia Rodriguez-Comas, Matthias Stefan May, Zhaohong Pan, Xiang Zhou, Xiaokun Liang, Franciskus Xaverius Erick .etc.|<http://arxiv.org/pdf/2505.08685v1>|CURVAS挑战通过多标注者评估和不确定性估计，提高了多器官分割深度学习模型的可靠性和临床适用性。|
|🆕 发布|Unsupervised Out-of-Distribution Detection in Medical Imaging Using Multi-Exit Class Activation Maps and Feature Masking|基于多出口类激活图和特征掩码的医学图像无监督异常值检测|Yu-Jen Chen, Xueyang Li, Yiyu Shi, Tsung-Yi Ho|<http://arxiv.org/pdf/2505.08604v1>|提出了一种利用多出口激活图和特征掩码的医学图像无监督异常检测框架，有效提升了异常检测的鲁棒性。|
|🆕 发布|A Deep Learning-Driven Framework for Inhalation Injury Grading Using Bronchoscopy Images|基于深度学习的支气管镜图像吸入性损伤分级框架|Yifan Li, Alan W Pang, Jo Woon Chong|<http://arxiv.org/pdf/2505.08517v1>|提出了一种基于深度学习的吸入性损伤分级框架，利用增强StarGAN生成图像提高分类准确率。|
|🆕 发布|An incremental algorithm for non-convex AI-enhanced medical image processing|增量算法在非凸AI增强医学图像处理中的应用|Elena Morotti|<http://arxiv.org/pdf/2505.08324v1>|incDG算法结合深度学习与增量优化，有效解决医学图像处理中的非凸问题，提升图像重建质量。|
|🆕 发布|IrrMap: A Large-Scale Comprehensive Dataset for Irrigation Method Mapping|IrrMap：用于灌溉方法映射的大规模综合数据集|Nibir Chandra Mandal, Oishee Bintey Hoque, Abhijin Adiga, Samarth Swarup, Mandy Wilson, Lu Feng, Yangfeng Ji, Miaomiao Zhang .etc.|<http://arxiv.org/pdf/2505.08273v1>|[代码](https://github.com/Nibir088/IrrMap); 构建了大规模灌溉方法映射数据集IrrMap，助力精准灌溉分析。|
|📝 更新|Automatic quality control in multi-centric fetal brain MRI super-resolution reconstruction|多中心胎儿脑MRI超分辨率重建中的自动质量控制|Thomas Sanchez, Vladyslav Zalevskyi, Angeline Mihailov, Gerard Martí-Juan, Elisenda Eixarch, Andras Jakab, Vincent Dunet, Mériam Koob .etc.|<http://arxiv.org/pdf/2503.10156v3>|[代码](https://github.com/Medical-Image-Analysis-Laboratory/fetmrqc_sr); 提出了一种基于机器学习的胎儿脑MRI超分辨率重建质量控制系统，有效预测图像质量。|
|🆕 发布|Skeleton-Guided Diffusion Model for Accurate Foot X-ray Synthesis in Hallux Valgus Diagnosis|骨骼引导的扩散模型在拇外翻诊断中实现精确足部X光合成|Midi Wan, Pengfei Li, Yizhuo Liang, Di Wu, Yushan Pan, Guangzhen Zhu, Hao Wang|<http://arxiv.org/pdf/2505.08247v1>|[代码](https://github.com/midisec/SCCDM.); 提出骨骼引导扩散模型，显著提升足部X光合成准确性，助力拇外翻诊断。|
|🆕 发布|Object detection in adverse weather conditions for autonomous vehicles using Instruct Pix2Pix|在恶劣天气条件下使用Instruct Pix2Pix进行自动驾驶汽车目标检测|Unai Gurbindo, Axel Brando, Jaume Abella, Caroline König|<http://arxiv.org/pdf/2505.08228v1>|利用Instruct Pix2Pix扩散模型生成真实数据集，提升自动驾驶在恶劣天气下目标检测的鲁棒性...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Open the Eyes of MPNN: Vision Enhances MPNN in Link Prediction|开启MPNN的视野：视觉增强在链接预测中的应用|Yanbin Wei, Xuehao Wang, Zhan Zhuang, Yang Chen, Shuhao Chen, Yulong Zhang, Yu Zhang, James Kwok|<http://arxiv.org/pdf/2505.08266v1>|首次为MPNN引入视觉感知，提出GVN框架，显著提升链接预测性能。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Human Motion Prediction via Test-domain-aware Adaptation with Easily-available Human Motions Estimated from Videos|通过从视频中估计的易于获取的人体运动实现测试域感知自适应的人体运动预测|Katsuki Shimbo, Hiromu Taketsugu, Norimichi Ukita|<http://arxiv.org/pdf/2505.07301v2>|通过利用易于获取的视频估计人体动作，该方法提升了3D人体运动预测模型在测试域的泛化能力。|
|🆕 发布|Claycode: Stylable and Deformable 2D Scannable Codes|粘土码：可风格化和可变形的二维可扫描码|Marco Maida, Alberto Crescini, Marco Perronet, Elena Camuffo|<http://arxiv.org/pdf/2505.08666v1>|提出了一种新型可变形二维条码Claycode，实现风格化和变形，同时保持高容错性。|
|📝 更新|Semantic Shift Estimation via Dual-Projection and Classifier Reconstruction for Exemplar-Free Class-Incremental Learning|基于双投影和分类器重建的无示例类增量学习的语义偏移估计|Run He, Di Fang, Yicheng Xu, Yawen Cui, Ming Li, Cen Chen, Ziqian Zeng, Huiping Zhuang|<http://arxiv.org/pdf/2503.05423v3>|[代码](https://github.com/RHe502/ICML25-DPCR.); 提出DPCR方法，通过双重投影和分类器重构解决无样本增量学习中的语义偏移和决策偏差问题。|
|📝 更新|Decadal analysis of sea surface temperature patterns, climatology, and anomalies in temperate coastal waters with Landsat-8 TIRS observations|十年海温模式、气候学及其在温带沿海水域中的异常分析：基于Landsat-8 TIRS观测|Yiqing Guo, Nagur Cherukuru, Eric Lehmann, Xiubin Qi, Mark Doubelld, S. L. Kesav Unnithan, Ming Feng|<http://arxiv.org/pdf/2503.05843v2>|利用Landsat-8 TIRS数据，分析了南澳大利亚沿海水域的表层水温模式，揭示了异常事件及其与渔...|
|🆕 发布|Disruptive Transformation of Artworks in Master-Disciple Relationships: The Case of Ukiyo-e Artworks|艺术作品在师徒关系中的颠覆性转型：浮世绘作品的案例|Honna Shinichi, Akira Matsui|<http://arxiv.org/pdf/2505.08284v1>|利用机器学习对日本浮世绘艺术作品进行定量分析，揭示其艺术风格与文化演变关系。|

