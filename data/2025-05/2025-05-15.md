## [UPDATED!] **2025-05-15** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|End-to-End Vision Tokenizer Tuning|端到端视觉分词器微调|Wenxuan Wang, Fan Zhang, Yufeng Cui, Haiwen Diao, Zhuoyan Luo, Huchuan Lu, Jing Liu, Xinlong Wang|<http://arxiv.org/pdf/2505.10562v1>|提出ETT，通过端到端联合优化视觉分词器和目标任务，显著提升多模态理解和视觉生成任务性能。|
|🆕 发布|MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning|MathCoder-VL：连接视觉与代码以增强多模态数学推理|Ke Wang, Junting Pan, Linda Wei, Aojun Zhou, Weikang Shi, Zimu Lu, Han Xiao, Yunqiao Yang .etc.|<http://arxiv.org/pdf/2505.10557v1>|[代码](https://github.com/mathllm/MathCoder.); 提出MathCoder-VL模型，利用代码作为监督，提升多模态数学推理能力。|
|🆕 发布|Vision language models have difficulty recognizing virtual objects|视觉语言模型难以识别虚拟对象|Tyler Tran, Sangeet Khemlani, J. G. Trafton|<http://arxiv.org/pdf/2505.10453v1>|提出虚拟物体识别挑战，揭示视觉语言模型在理解场景空间关系上的不足。|
|📝 更新|CryoSAMU: Enhancing 3D Cryo-EM Density Maps of Protein Structures at Intermediate Resolution with Structure-Aware Multimodal U-Nets|CryoSAMU：利用结构感知多模态U-Nets提升中等分辨率蛋白质结构3D冷冻电镜密度图的增强|Chenwei Zhang, Khanh Dao Duc|<http://arxiv.org/pdf/2503.20291v2>|[代码](https://github.com/chenwei-zhang/CryoSAMU.); 提出CryoSAMU，利用结构感知多模态U-Nets提升蛋白质结构3D冷冻电镜密度图中间分辨率。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Exploring Implicit Visual Misunderstandings in Multimodal Large Language Models through Attention Analysis|通过注意力分析探索多模态大型语言模型中的隐式视觉误解|Pengfei Wang, Guohai Xu, Weinong Wang, Junjie Yang, Jie Lou, Yunhua Xue|<http://arxiv.org/pdf/2505.10541v1>|通过注意力分析揭示多模态大语言模型中的隐式视觉误解，并提出注意力准确率指标和新型基准来量化这种误解。|
|🆕 发布|MIPHEI-ViT: Multiplex Immunofluorescence Prediction from H&E Images using ViT Foundation Models|MIPHEI-ViT：基于ViT基础模型的H&E图像多重免疫荧光预测|Guillaume Balezo, Roger Trullo, Albert Pla Planas, Etienne Decenciere, Thomas Walter|<http://arxiv.org/pdf/2505.10294v1>|MIPHEI利用ViT模型从H&E图像预测mIF信号，实现癌症组织细胞类型识别。|
|📝 更新|Latent Action Pretraining from Videos|视频中的潜在动作预训练|Seonghyeon Ye, Joel Jang, Byeongguk Jeon, Sejune Joo, Jianwei Yang, Baolin Peng, Ajay Mandlekar, Reuben Tan .etc.|<http://arxiv.org/pdf/2410.11758v2>|提出了一种从无标签视频中预训练视觉-语言-动作模型的方法，显著提升机器人操作性能。|
|📝 更新|CreativeSynth: Cross-Art-Attention for Artistic Image Synthesis with Multimodal Diffusion|创意合成：跨艺术注意力在多模态扩散艺术图像合成中的应用|Nisha Huang, Weiming Dong, Yuxin Zhang, Fan Tang, Ronghui Li, Chongyang Ma, Xiu Li, Tong-Yee Lee .etc.|<http://arxiv.org/pdf/2401.14066v3>|[代码](https://github.com/haha-lisa/CreativeSynth.); CreativeSynth通过跨艺术注意力机制，将多模态语义信息融入艺术图像合成，实现风格与内容的和...|
|📝 更新|Scaling Laws for Black box Adversarial Attacks|黑盒对抗攻击的缩放定律|Chuan Liu, Huanran Chen, Yichi Zhang, Yinpeng Dong, Jun Zhu|<http://arxiv.org/pdf/2411.16782v2>|探究了黑盒对抗攻击的规模效应，通过增加模型数量显著提升了攻击成功率。|
|📝 更新|EndoMamba: An Efficient Foundation Model for Endoscopic Videos via Hierarchical Pre-training|EndoMamba：一种通过分层预训练的高效内窥镜视频基础模型|Qingyao Tian, Huai Liao, Xinyan Huang, Bingyu Yang, Dongdong Lei, Sebastien Ourselin, Hongbin Liu|<http://arxiv.org/pdf/2502.19090v2>|[代码](https://github.com/TianCuteQY/EndoMamba.); EndoMamba通过高效模型和分层预训练，提升了内窥镜视频任务性能。|
|📝 更新|Behind Maya: Building a Multilingual Vision Language Model|《玛雅背后：构建多语言视觉语言模型》|Nahid Alam, Karthik Reddy Kanjula, Surya Guthikonda, Timothy Chung, Bala Krishna S Vegesna, Abhipsha Das, Anthony Susevski, Ryan Sze-Yin Chan .etc.|<http://arxiv.org/pdf/2505.08910v2>|[代码](https://github.com/nahidalam/maya.); 构建了多语言视觉语言模型Maya，提升低资源语言和文化背景下的视觉语言任务性能。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models|多模态自适应与自数据蒸馏用于视觉-语言模型的投机解码|Mugilan Ganesan, Shane Segal, Ankur Aggarwal, Nish Sinnadurai, Sean Lie, Vithursan Thangarasa|<http://arxiv.org/pdf/2505.10526v1>|检测并加速视觉语言模型推理，MASSV通过多模态适应和自数据蒸馏将小语言模型转化为有效的多模态草稿生...|
|📝 更新|DINO-X: A Unified Vision Model for Open-World Object Detection and Understanding|DINO-X：一个用于开放世界物体检测与理解的统一视觉模型|Tianhe Ren, Yihao Chen, Qing Jiang, Zhaoyang Zeng, Yuda Xiong, Wenlong Liu, Zhengyu Ma, Junyi Shen .etc.|<http://arxiv.org/pdf/2411.14347v3>|DINO-X通过大规模预训练和灵活的提示机制，实现了开放世界物体检测和理解的突破。|
|📝 更新|UniCAD: Efficient and Extendable Architecture for Multi-Task Computer-Aided Diagnosis System|UniCAD：多任务计算机辅助诊断系统的有效且可扩展架构|Yitao Zhu, Yuan Yin, Zhenrong Shen, Zihao Zhao, Haiyu Song, Sheng Wang, Dinggang Shen, Qian Wang|<http://arxiv.org/pdf/2505.09178v2>|[代码](https://mii-laboratory.github.io/UniCAD); 提出UniCAD，一种高效且可扩展的多任务计算机辅助诊断系统架构，解决医学图像诊断的复杂性和资源需求...|
|🆕 发布|PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language|PsOCR：评估低资源帕什图语光学字符识别的多模态大模型的基准|Ijazul Haq, Yingjie Zhang, Irfan Ali Khan|<http://arxiv.org/pdf/2505.10055v1>|[代码](https://github.com/zirak-ai/PashtoOCR.); 开发PsOCR数据集，评估大型多模态模型在低资源帕什图语OCR任务中的性能。|
|📝 更新|Unified theory for joint covariance properties under geometric image transformations for spatio-temporal receptive fields according to the generalized Gaussian derivative model for visual receptive fields|基于广义高斯导数模型的空间时间感受野的几何图像变换下的联合协方差性质统一理论|Tony Lindeberg|<http://arxiv.org/pdf/2311.10543v9>|建立了统一理论，通过几何图像变换下的联合协方差性质，优化时空感受野模型。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PIF: Anomaly detection via preference embedding|PIF：通过偏好嵌入进行异常检测|Filippo Leveni, Luca Magri, Giacomo Boracchi, Cesare Alippi|<http://arxiv.org/pdf/2505.10441v1>|提出PIF方法，结合偏好嵌入和自适应隔离，有效检测结构化模式中的异常。|
|📝 更新|SeagrassFinder: Deep Learning for Eelgrass Detection and Coverage Estimation in the Wild|海草寻踪：野外鸢尾草检测与覆盖度估计的深度学习|Jannik Elsäßer, Laura Weihl, Veronika Cheplygina, Lisbeth Tangaa Nielsen|<http://arxiv.org/pdf/2412.16147v2>|开发深度学习模型自动识别和估算海草覆盖，提高海洋生态监测效率。|
|📝 更新|Pose Priors from Language Models|姿态先验来自语言模型|Sanjay Subramanian, Evonne Ng, Lea Müller, Dan Klein, Shiry Ginosar, Trevor Darrell|<http://arxiv.org/pdf/2405.03689v2>|利用大型多模态模型作为先验，从语言描述中重建接触姿态，为3D人体姿态估计提供了一种可扩展的替代方案。|
|🆕 发布|CSPENet: Contour-Aware and Saliency Priors Embedding Network for Infrared Small Target Detection|CSPENet：红外小目标检测的轮廓感知和显著性先验嵌入网络|Jiakun Deng, Kexuan Li, Xingye Cui, Jiaxuan Li, Chang Long, Tian Pu, Zhenming Peng|<http://arxiv.org/pdf/2505.09943v1>|[代码](https://github.com/IDIP2025/CSPENet.); 提出了一种结合轮廓感知和显著性先验的嵌入网络，有效提升了红外小目标检测性能。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\mathcal{O}(T)$ Complexity|脉冲视频former：一种高效的脉冲驱动视频变换器，具有汉明注意力和 $\mathcal{O}(T)$ 复杂度|Shihao Zou, Qingfeng Li, Wei Ji, Jingjing Li, Yongkui Yang, Guoqi Li, Chao Dong|<http://arxiv.org/pdf/2505.10352v1>|[代码](https://github.com/JimmyZou/SpikeVideoFormer); 提出了一种高效的视频Transformer，通过Hamming注意力机制和线性时间复杂度，显著提升了...|
|📝 更新|Efficient Quantum Convolutional Neural Networks for Image Classification: Overcoming Hardware Constraints|高效量子卷积神经网络用于图像分类：克服硬件限制|Peter Röseler, Oliver Schaudt, Helmut Berg, Christian Bauckhage, Matthias Koch|<http://arxiv.org/pdf/2505.05957v2>|提出了一种高效量子卷积神经网络，通过降低输入维度，在NISQ设备上实现图像分类，超越传统方法。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MFogHub: Bridging Multi-Regional and Multi-Satellite Data for Global Marine Fog Detection and Forecasting|MFogHub：连接多区域和多卫星数据以实现全球海洋雾检测与预测|Mengqiu Xu, Kaixin Chen, Heng Guo, Yixiang Huang, Ming Wu, Zhenwei Shi, Chuang Zhang, Jun Guo|<http://arxiv.org/pdf/2505.10281v1>|[代码](https://github.com/kaka0910/MFogHub); 构建了首个多区域、多卫星海洋雾数据集，促进全球海洋雾检测与预测研究。|
|📝 更新|Saliency-Motion Guided Trunk-Collateral Network for Unsupervised Video Object Segmentation|显著度-运动引导的躯干-旁支网络用于无监督视频目标分割|Xiangyu Zheng, Wanyun Li, Songcheng He, Jianping Fan, Xiaoqiang Li, We Zhang|<http://arxiv.org/pdf/2504.05904v2>|提出了一种融合显著性和运动信息的网络结构，有效提升了无监督视频目标分割性能。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|APCoTTA: Continual Test-Time Adaptation for Semantic Segmentation of Airborne LiDAR Point Clouds|APCoTTA：空中激光雷达点云语义分割的持续测试时自适应|Yuan Gao, Shaobo Xia, Sheng Nie, Cheng Wang, Xiaohuan Xi, Bisheng Yang|<http://arxiv.org/pdf/2505.09971v1>|[代码](https://github.com/Gaoyuan2/APCoTTA.); APCoTTA提出针对空中激光雷达点云语义分割的持续测试时自适应方法，有效缓解模型遗忘问题，显著提升...|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Style Customization of Text-to-Vector Generation with Image Diffusion Priors|基于图像扩散先验的文本到向量生成风格定制|Peiying Zhang, Nanxuan Zhao, Jing Liao|<http://arxiv.org/pdf/2505.10558v1>|提出了一种结合T2V模型和T2I先验的SVG风格定制方法，有效解决结构一致性和风格多样性问题。|
|🆕 发布|Sage Deer: A Super-Aligned Driving Generalist Is Your Copilot|智慧鹿：一位超级对齐的驾驶通用助手，您的副驾驶|Hao Lu, Jiaqi Tang, Jiyao Wang, Yunfan LU, Xu Cao, Qingyong Hu, Yin Wang, Yuting Zhang .etc.|<http://arxiv.org/pdf/2505.10257v1>|构建了SAGE DeeR，一种能根据用户偏好和场景自适应的智能驾驶助手。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|3D-Fixup: Advancing Photo Editing with 3D Priors|3D-Fixup：利用3D先验知识推进照片编辑|Yen-Chi Cheng, Krishna Kumar Singh, Jae Shin Yoon, Alex Schwing, Liangyan Gui, Matheus Gadelha, Paul Guerrero, Nanxuan Zhao|<http://arxiv.org/pdf/2505.10566v1>|提出3D-Fixup框架，利用3D先验知识指导2D图像编辑，实现复杂、身份一致的3D感知编辑。|
|🆕 发布|CheXGenBench: A Unified Benchmark For Fidelity, Privacy and Utility of Synthetic Chest Radiographs|CheXGenBench：合成胸部X光片保真度、隐私性和实用性的统一基准|Raman Dutt, Pedro Sanchez, Yongchen Yao, Steven McDonagh, Sotirios A. Tsaftaris, Timothy Hospedales|<http://arxiv.org/pdf/2505.10496v1>|[代码](https://raman1121.github.io/CheXGenBench); CheXGenBench提出统一基准，评估合成胸片生成模型的保真度、隐私和临床效用。|
|🆕 发布|UniEval: Unified Holistic Evaluation for Unified Multimodal Understanding and Generation|统一多模态理解和生成统一全面评估：UniEval|Yi Li, Haonan Wang, Qixiang Zhang, Boyu Xiao, Chenchang Hu, Hualiang Wang, Xiaomeng Li|<http://arxiv.org/pdf/2505.10483v1>|提出了UniEval，首个无需额外模型、图像或标注的统一多模态理解与生成模型评估框架。|
|📝 更新|TactileNet: Bridging the Accessibility Gap with AI-Generated Tactile Graphics for Individuals with Vision Impairment|触觉网：利用人工智能生成的触觉图形弥合视障人士的可用性差距|Adnan Khan, Alireza Choubineh, Mai A. Shaaban, Abbas Akkasi, Majid Komeili|<http://arxiv.org/pdf/2504.04722v2>|TactileNet通过AI生成触觉图形，解决视觉障碍者获取视觉信息难题。|
|🆕 发布|StoryReasoning Dataset: Using Chain-of-Thought for Scene Understanding and Grounded Story Generation|场景理解与基于思维链的 grounded 故事生成数据集|Daniel A. P. Oliveira, David Martins de Matos|<http://arxiv.org/pdf/2505.10292v1>|提出StoryReasoning数据集，通过跨帧对象重识别和链式思维推理，有效降低视觉叙事系统中的幻...|
|🆕 发布|MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation|MTVCrafter：面向开放世界人类图像动画的4D运动标记化|Yanbo Ding|<http://arxiv.org/pdf/2505.10238v1>|MTVCrafter通过直接建模4D运动序列，实现了更灵活和独立的3D人物动画。|
|🆕 发布|IMITATE: Image Registration with Context for unknown time frame recovery|IMITATE：用于未知时间帧恢复的基于上下文的图像配准|Ziad Kheil, Lucas Robinet, Laurent Risser, Soleakhena Ken|<http://arxiv.org/pdf/2505.10124v1>|[代码](https://github.com/Kheil-Z/IMITATE); 提出了一种基于条件U-Net的图像配准新方法，有效恢复未知时间帧的图像。|
|📝 更新|Generative Pre-trained Autoregressive Diffusion Transformer|生成预训练自回归扩散Transformer|Yuan Zhang, Jiacheng Jiang, Guoqing Ma, Zhiying Lu, Haoyang Huang, Jianlong Yuan, Nan Duan|<http://arxiv.org/pdf/2505.07344v2>|提出GPDiT，一种结合扩散和自回归模型的视频生成Transformer，实现连续潜在空间中的长距离...|
|📝 更新|IntrinsicEdit: Precise generative image manipulation in intrinsic space|内蕴编辑：内蕴空间中的精确生成图像操作|Linjie Lyu, Valentin Deschaintre, Yannick Hold-Geoffroy, Miloš Hašan, Jae Shin Yoon, Thomas Leimkühler, Christian Theobalt, Iliyan Georgiev|<http://arxiv.org/pdf/2505.08889v2>|IntrinsicEdit通过在内在图像潜在空间中进行精确编辑，实现了对复杂图像的高质量、精确操控。|
|🆕 发布|ToonifyGB: StyleGAN-based Gaussian Blendshapes for 3D Stylized Head Avatars|基于StyleGAN的Gaussian Blendshapes用于3D风格化头像|Rui-Yang Ju, Sheng-Yen Huang, Yi-Ping Hung|<http://arxiv.org/pdf/2505.10072v1>|提出ToonifyGB框架，利用StyleGAN和Gaussian blendshapes高效生成多...|
|🆕 发布|From Air to Wear: Personalized 3D Digital Fashion with AR/VR Immersive 3D Sketching|从空中到穿戴：基于AR/VR沉浸式3D绘制的个性化3D数字时尚|Ying Zang, Yuanqi Hu, Xinyu Chen, Yuxia Xu, Suhui Wang, Chunan Yu, Lanyun Zhu, Deyi Ji .etc.|<http://arxiv.org/pdf/2505.09998v1>|提出了一种基于3D草图驱动的AR/VR环境下的个性化3D服装生成框架，降低了3D服装设计的门槛。|
|📝 更新|OSMLoc: Single Image-Based Visual Localization in OpenStreetMap with Fused Geometric and Semantic Guidance|OSMLoc：基于单图像的OpenStreetMap视觉定位，融合几何和语义引导|Youqi Liao, Xieyuanli Chen, Shuhao Kang, Jianping Li, Zhen Dong, Hongchao Fan, Bisheng Yang|<http://arxiv.org/pdf/2411.08665v2>|[代码](https://github.com/WHU-USI3DV/OSMLoc.); OSMLoc通过融合几何和语义指导，显著提升了基于单张图像在OpenStreetMap中的视觉定位精...|
|📝 更新|HCMA: Hierarchical Cross-model Alignment for Grounded Text-to-Image Generation|HCMA：基于层次交叉模型对齐的 grounded 文本到图像生成|Hang Wang, Zhi-Qi Cheng, Chenhao Lin, Chao Shen, Lei Zhang|<http://arxiv.org/pdf/2505.06512v3>|[代码](https://github.com/hwang-cs-ime/HCMA.); 提出HCMA框架，通过层次跨模态对齐实现语义精确且空间可控的文本到图像生成。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Teaching Humans Subtle Differences with DIFFusion|人类学习微妙的差异：DIFFusion方法|Mia Chiquier, Orr Avrech, Yossi Gandelsman, Berthy Feng, Katherine Bouman, Carl Vondrick|<http://arxiv.org/pdf/2504.08046v2>|利用生成模型自动发现并可视化类别间细微差异，提升人类视觉学习与科学研究的准确性。|
|📝 更新|Improving Fine-Grained Control via Aggregation of Multiple Diffusion Models|通过多个扩散模型的聚合提高细粒度控制|Conghan Yue, Zhengwei Peng, Shiyan Du, Zhi Ji, Chuangjian Cai, Le Wan, Dongyu Zhang|<http://arxiv.org/pdf/2410.01262v3>|[代码](https://github.com/Hammour-steak/AMDM.); 提出AMDM算法，通过聚合多个扩散模型特征，实现无训练的细粒度控制。|
|🆕 发布|ADHMR: Aligning Diffusion-based Human Mesh Recovery via Direct Preference Optimization|ADHMR：通过直接偏好优化对齐基于扩散的人体网格恢复|Wenhao Shen, Wanqi Yin, Xiaofeng Yang, Cheng Chen, Chaoyue Song, Zhongang Cai, Lei Yang, Hao Wang .etc.|<http://arxiv.org/pdf/2505.10250v1>|[代码](https://github.com/shenwenhao01/ADHMR.); 提出ADHMR，通过直接偏好优化对基于扩散的人体网格恢复模型进行对齐，显著提升模型性能。|
|🆕 发布|Modeling Saliency Dataset Bias|建模显著性数据集偏差|Matthias Kümmerer, Harneet Khanuja, Matthias Bethge|<http://arxiv.org/pdf/2505.10169v1>|提出了一种针对数据集偏差的视觉注意力模型，显著提升了跨数据集的泛化能力。|
|📝 更新|Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic Assessment|魅力：图像美学评估中ViT微调的缺失环节|Fatemeh Behrad, Tinne Tuytelaars, Johan Wagemans|<http://arxiv.org/pdf/2504.02522v2>|[代码](https://github.com/FBehrad/Charm.); Charm通过创新分词方法，同时保留图像的构图、分辨率、宽高比和多尺度信息，显著提升了ViT在图像美...|
|🆕 发布|MMRL++: Parameter-Efficient and Interaction-Aware Representation Learning for Vision-Language Models|MMRL++：视觉-语言模型中参数高效和交互感知的表示学习方法|Yuncheng Guo, Xiaodong Gu|<http://arxiv.org/pdf/2505.10088v1>|MMRL++通过引入模态无关的表示空间和参数高效的扩展，有效提升了视觉语言模型的泛化能力。|
|📝 更新|Single View Garment Reconstruction Using Diffusion Mapping Via Pattern Coordinates|基于图案坐标的扩散映射单视图服装重建|Ren Li, Cong Cao, Corentin Dumery, Yingxuan You, Hao Li, Pascal Fua|<http://arxiv.org/pdf/2504.08353v2>|提出了一种结合图案坐标的扩散映射方法，从单张图像中高保真重建服装三维模型。|
|📝 更新|CoCoGaussian: Leveraging Circle of Confusion for Gaussian Splatting from Defocused Images|CoCoGaussian：利用模糊圈进行失焦图像高斯喷溅的利用|Jungho Lee, Suhwan Cho, Taeoh Kim, Ho-Deok Jang, Minhyeok Lee, Geonho Cha, Dongyoon Wee, Dogyoon Lee .etc.|<http://arxiv.org/pdf/2412.16028v2>|提出了一种基于模糊圈模型的Gaussian Splatting方法，从模糊图像中精确重建3D场景。|
|🆕 发布|Exploring the Deep Fusion of Large Language Models and Diffusion Transformers for Text-to-Image Synthesis|探索大型语言模型与扩散变换器在文本到图像合成中的深度融合|Bingda Tang, Boyang Zheng, Xichen Pan, Sayak Paul, Saining Xie|<http://arxiv.org/pdf/2505.10046v1>|深入探索了大型语言模型与扩散变换器在文本到图像合成中的深度融合，为多模态生成提供实证研究和实用指南。|
|🆕 发布|ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction|ORL-LDM：基于离线强化学习的潜在扩散模型超分辨率重建|Shijie Lyu|<http://arxiv.org/pdf/2505.10027v1>|提出了一种基于强化学习的LDM超分辨率重建方法，显著提升了遥感图像细节和场景适应性。|
|🆕 发布|Ordered-subsets Multi-diffusion Model for Sparse-view CT Reconstruction|有序子集多扩散模型用于稀疏视图CT重建|Pengfei Yu, Bin Huang, Minghui Zhang, Weiwen Wu, Shaoyu Wang, Qiegen Liu|<http://arxiv.org/pdf/2505.09985v1>|提出OSMM模型，通过有序子集多扩散学习，有效提升稀疏视图CT重建图像质量与噪声鲁棒性。|
|🆕 发布|Descriptive Image-Text Matching with Graded Contextual Similarity|描述性图像-文本匹配：基于分级上下文相似度|Jinhyun Jang, Jiyeong Lee, Kwanghoon Sohn|<http://arxiv.org/pdf/2505.09997v1>|提出了一种基于描述性灵活性的图像-文本匹配方法，有效提升了匹配精度和多样性。|
|📝 更新|Towards user-centered interactive medical image segmentation in VR with an assistive AI agent|面向以用户为中心的VR辅助AI代理交互式医学图像分割|Pascal Spiegler, Arash Harirpoush, Yiming Xiao|<http://arxiv.org/pdf/2505.07214v2>|提出SAMIRA，一种结合VR和AI的交互式医疗图像分割系统，提高分割效率和用户体验。|
|📝 更新|Translating Electrocardiograms to Cardiac Magnetic Resonance Imaging Useful for Cardiac Assessment and Disease Screening: A Multi-Center Study AI for ECG to CMR Translation Study|将心电图转换为心脏磁共振成像以用于心脏评估和疾病筛查：一项多中心研究——心电图到磁共振成像翻译研究|Zhengyao Ding, Ziyu Li, Yujian Hu, Youyao Xu, Chengchen Zhao, Yiheng Mao, Haitao Li, Zhikang Li .etc.|<http://arxiv.org/pdf/2411.13602v2>|开发了一种深度学习框架，将心电图信号转换为心脏磁共振成像，以实现低成本的心脏评估和疾病筛查。|
|📝 更新|Learned Image Compression with Dictionary-based Entropy Model|基于字典熵模型的图像压缩学习|Jingbo Lu, Leheng Zhang, Xingyu Zhou, Mu Li, Wen Li, Shuhang Gu|<http://arxiv.org/pdf/2504.00496v2>|提出字典增强的交叉注意力熵模型，提升学习图像压缩性能与效率。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Depth Anything with Any Prior|深度感知任何事物，无需任何先验知识|Zehan Wang, Siyu Chen, Lihe Yang, Jialei Wang, Ziang Zhang, Hengshuang Zhao, Zhou Zhao|<http://arxiv.org/pdf/2505.10565v1>|提出了一种融合深度先验和预测的深度估计框架，实现任意场景的精确深度图生成。|
|📝 更新|Estimating the Diameter at Breast Height of Trees in a Forest With a Single 360 Camera|森林中单台360度相机的树木胸径估算|Siming He, Zachary Osman, Fernando Cladera, Dexter Ong, Nitant Rai, Patrick Corey Green, Vijay Kumar, Pratik Chaudhari|<http://arxiv.org/pdf/2505.03093v2>|利用单台360度相机，通过半自动化流程实现树木胸径的精确测量，成本远低于传统LiDAR技术。|
|🆕 发布|VolE: A Point-cloud Framework for Food 3D Reconstruction and Volume Estimation|VolE：一种用于食品3D重建和体积估计的点云框架|Umair Haroon, Ahmad AlMughrabi, Thanasis Zoumpekas, Ricardo Marques, Petia Radeva|<http://arxiv.org/pdf/2505.10205v1>|VolE通过利用移动设备进行3D重建，实现了无需参考物和深度信息的食物体积精确估计。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|UniSkill: Imitating Human Videos via Cross-Embodiment Skill Representations|UniSkill：通过跨化身技能表示模仿人类视频|Hanjung Kim, Jaehyun Kang, Hyolim Kang, Meedeum Cho, Seon Joo Kim, Youngwoon Lee|<http://arxiv.org/pdf/2505.08787v2>|[代码](https://kimhanjung.github.io/UniSkill.); 提出UniSkill，通过学习跨实体技能表示，实现无标签数据下人类视频技能到机器人策略的有效迁移。|
|📝 更新|PEP-GS: Perceptually-Enhanced Precise Structured 3D Gaussians for View-Adaptive Rendering|感知增强精确结构化3D高斯用于视适应渲染|Junxi Jin, Xiulai Li, Haiping Huang, Lianjun Liu, Yujie Sun, Logan Liu|<http://arxiv.org/pdf/2411.05731v3>|PEP-GS通过感知增强和结构化高斯方法，提升了3D场景渲染的视觉效果和细节表现。|
|📝 更新|SMURF: Continuous Dynamics for Motion-Deblurring Radiance Fields|SMURF：运动去模糊辐射场的连续动力学|Jungho Lee, Dogyoon Lee, Minhyeok Lee, Donghyung Kim, Sangyoun Lee|<http://arxiv.org/pdf/2403.07547v2>|提出SMURF，通过连续运动理解建模和体积表示，有效解决运动模糊对NeRF重建图像质量的影响。|
|📝 更新|Leveraging Multi-Modal Information to Enhance Dataset Distillation|利用多模态信息增强数据集蒸馏|Zhe Li, Hadrien Reynaud, Bernhard Kainz|<http://arxiv.org/pdf/2505.08605v2>|通过结合文本信息和对象级掩码，该方法显著提升了数据集蒸馏的质量。|
|🆕 发布|FlowDreamer: A RGB-D World Model with Flow-based Motion Representations for Robot Manipulation|FlowDreamer：基于光流运动表示的RGB-D世界模型用于机器人操作|Jun Guo, Xiaojian Ma, Yikai Wang, Min Yang, Huaping Liu, Qing Li|<http://arxiv.org/pdf/2505.10075v1>|FlowDreamer通过使用3D场景流作为运动表示，显著提升了RGB-D世界模型在机器人操作中的视...|
|🆕 发布|Advances in Radiance Field for Dynamic Scene: From Neural Field to Gaussian Field|动态场景辐射场进展：从神经场到高斯场|Jinlong Fan, Xuepu Zeng, Jing Zhang, Mingming Gong, Yuxiang Yang, Dacheng Tao|<http://arxiv.org/pdf/2505.10049v1>|该论文提出了一种从神经网络场到高斯场的动态场景表示方法，显著提升了动态场景重建的质量。|
|🆕 发布|Large-Scale Gaussian Splatting SLAM|大规模高斯喷溅SLAM|Zhe Xin, Chenyang Wu, Penghui Huang, Yanyong Zhang, Yinian Mao, Guoquan Huang|<http://arxiv.org/pdf/2505.09915v1>|提出了一种基于大规模3D高斯分层SLAM的视觉SLAM方法，有效解决了大规模室外场景下的鲁棒重建问题...|


## 时序视觉分析 (Temporal Visual Analysis)


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-Token Prediction Needs Registers|多令牌预测需要寄存器|Anastasios Gerontopoulos, Spyros Gidaris, Nikos Komodakis|<http://arxiv.org/pdf/2505.10518v1>|[代码](https://github.com/nasosger/MuToR.); 提出MuToR方法，通过插入可学习寄存器提高多标记预测在预训练和微调中的效果。|
|📝 更新|Highly Efficient 3D Human Pose Tracking from Events with Spiking Spatiotemporal Transformer|高效率基于脉冲时空变换的事件3D人体姿态跟踪|Shihao Zou, Yuxuan Mu, Wei Ji, Zi-An Wang, Xinxin Zuo, Sen Wang, Weixin Si, Li Cheng|<http://arxiv.org/pdf/2303.09681v5>|[代码](https://github.com/JimmyZou/HumanPoseTracking_SNN.); 提出了一种基于事件相机和稀疏脉冲神经网络的高效3D人体姿态跟踪方法，显著降低了计算量和能耗。|
|🆕 发布|VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety|VRU-CIPI：为提高易受伤害道路使用者安全在交叉口的跨意图预测|Ahmed S. Abdelrahman, Mohamed Abdel-Aty, Quoc Dai Tran|<http://arxiv.org/pdf/2505.09935v1>|提出VRU-CIPI框架，通过注意力机制预测交叉路口行人意图，提升道路使用者安全。|
|📝 更新|BiECVC: Gated Diversification of Bidirectional Contexts for Learned Video Compression|双向上下文门控多样化学习视频压缩|Wei Jiang, Junru Li, Kai Zhang, Li Zhang|<http://arxiv.org/pdf/2505.09193v2>|[代码](https://github.com/JiangWeibeta/ECVC.); 提出BiECVC，通过双向上下文门控和多样化建模，显著提升了学习视频压缩性能。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|S2-Track: A Simple yet Strong Approach for End-to-End 3D Multi-Object Tracking|S2-Track：一种简单而强大的端到端3D多目标跟踪方法|Tao Tang, Lijun Zhou, Pengkun Hao, Zihang He, Kalok Ho, Shuo Gu, Zhihui Hao, Haiyang Sun .etc.|<http://arxiv.org/pdf/2406.02147v2>|提出S2-Track，通过改进初始化、传播和匹配，实现高效3D多目标跟踪。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Measuring Student Behavioral Engagement using Histogram of Actions|使用动作直方图测量学生行为参与度|Ahmed Abdelkawy, Aly Farag, Islam Alkabbany, Asem Ali, Chris Foreman, Thomas Tretter, Nicholas Hindy|<http://arxiv.org/pdf/2307.09420v2>|提出了一种通过学生动作识别和SVM分类器测量学生行为参与度的方法。|
|🆕 发布|SOS: A Shuffle Order Strategy for Data Augmentation in Industrial Human Activity Recognition|SOS：工业人体活动识别中的数据增强洗牌顺序策略|Anh Tuan Ha, Hoang Khang Phan, Thai Minh Tien Ngo, Anh Phan Truong, Nhat Tan Le|<http://arxiv.org/pdf/2505.10312v1>|提出了一种通过随机顺序打乱数据来增强工业人体活动识别准确性的方法。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Video-R1: Reinforcing Video Reasoning in MLLMs|视频-R1：在多模态语言模型中强化视频推理|Kaituo Feng, Kaixiong Gong, Bohao Li, Zonghao Guo, Yibing Wang, Tianshuo Peng, Junfei Wu, Xiaoying Zhang .etc.|<http://arxiv.org/pdf/2503.21776v3>|[代码](https://github.com/tulerfeng/Video-R1.); 提出T-GRPO算法，结合图像数据，显著提升MLLM在视频推理任务上的表现。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A portable diagnosis model for Keratoconus using a smartphone|基于智能手机的角膜圆锥形病变便携式诊断模型|Yifan Li, Peter Ho, Jo Woon Chong|<http://arxiv.org/pdf/2505.08616v2>|开发了一种基于智能手机的便携式角膜圆锥病变诊断模型，通过图像分析和机器学习技术实现高精度诊断。|
|🆕 发布|MorphGuard: Morph Specific Margin Loss for Enhancing Robustness to Face Morphing Attacks|形态保护：针对人脸形态攻击的形态特定边缘损失增强鲁棒性|Iurii Medvedev, Nuno Goncalves|<http://arxiv.org/pdf/2505.10497v1>|提出MorphGuard，通过引入双分支分类策略增强人脸识别系统对脸形变换攻击的鲁棒性。|
|🆕 发布|High Quality Underwater Image Compression with Adaptive Correction and Codebook-based Augmentation|高质量水下图像压缩：自适应校正与基于码本增强|Yimin Zhou, Yichong Xia, Sicheng Pan, Bin Chen, Baoyi An, Haoqian Wang, Zhi Wang, Yaowei Wang .etc.|<http://arxiv.org/pdf/2505.09986v1>|提出HQUIC算法，通过自适应校正和代码簿增强，有效提升水下图像压缩效率。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-contrast laser endoscopy for in vivo gastrointestinal imaging|多对比度激光内窥镜活体胃肠道成像|Taylor L. Bobrow, Mayank Golhar, Suchapa Arayakarnkul, Anthony A. Song, Saowanee Ngamruengphong, Nicholas J. Durr|<http://arxiv.org/pdf/2505.10492v1>|提出多对比度激光内窥镜技术，显著提升胃肠道成像的对比度和诊断准确性。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SEAL: Searching Expandable Architectures for Incremental Learning|SEAL：搜索可扩展架构以实现增量学习|Matteo Gambella, Vicente Javier Castro Solar, Manuel Roveri|<http://arxiv.org/pdf/2505.10457v1>|SEAL通过动态调整模型结构，实现增量学习中的稳定性和可塑性平衡，有效减少遗忘并提升准确率。|
|🆕 发布|RainPro-8: An Efficient Deep Learning Model to Estimate Rainfall Probabilities Over 8 Hours|RainPro-8：一种高效深度学习模型，用于估算8小时内的降雨概率|Rafael Pablos Sarabia, Joachim Nyborg, Morten Birk, Jeppe Liborius Sjørup, Anders Lillevang Vesterholt, Ira Assent|<http://arxiv.org/pdf/2505.10271v1>|RainPro-8模型通过整合多源数据，实现了高效且准确的8小时降雨概率预测。|
|🆕 发布|HandReader: Advanced Techniques for Efficient Fingerspelling Recognition|手读器：高效手指拼写识别的高级技术|Pavel Korotaev, Petr Surovtsev, Alexander Kapitanov, Karina Kvanchiani, Aleksandr Nagaev|<http://arxiv.org/pdf/2505.10267v1>|HandReader提出三种架构，有效提升了手指拼写识别的准确性。|
|🆕 发布|VRSplat: Fast and Robust Gaussian Splatting for Virtual Reality|VRSplat：虚拟现实中的快速鲁棒高斯分层|Xuechang Tu, Lukas Radl, Michael Steiner, Markus Steinberger, Bernhard Kerbl, Fernando de la Torre|<http://arxiv.org/pdf/2505.10144v1>|VRSplat通过结合多种技术，实现了快速且鲁棒的3D高斯分层，有效解决了VR中的时间伪影、投影扭曲...|
|📝 更新|Exploring Convolutional Neural Networks for Rice Grain Classification: An Explainable AI Approach|探索用于稻谷分类的卷积神经网络：一种可解释人工智能方法|Muhammad Junaid Asif, Hamza Khan, Rabia Tehseen, Syed Tahir Hussain Rizvi, Mujtaba Asad, Shazia Saqib, Rana Fayyaz Ahmad|<http://arxiv.org/pdf/2505.05513v2>|提出了一种基于CNN的自动水稻品种分类框架，并利用可解释AI技术揭示模型决策过程。|
|📝 更新|A Sliding Layer Merging Method for Efficient Depth-Wise Pruning in LLMs|滑动层合并方法在LLMs中实现高效深度剪枝|Xuan Ding, Rui Sun, Yunjian Zhang, Xiu Yan, Yueqi Zhou, Kaihao Huang, Suzhong Fu, Angelica I Aviles-Rivero .etc.|<http://arxiv.org/pdf/2502.19159v3>|[代码](https://github.com/920927/SLM-a-sliding-layer-merging-method.); 提出了一种滑动层合并方法，通过动态融合连续层提高LLMs深度剪枝效率。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Inferring Driving Maps by Deep Learning-based Trail Map Extraction|基于深度学习的轨迹地图提取推断驾驶地图|Michael Hubbertz, Pascal Colling, Qi Han, Tobias Meisen|<http://arxiv.org/pdf/2505.10258v1>|提出了一种将驾驶轨迹融入地图创建的深度学习方法，显著提升了在线地图的实时性和泛化能力。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Does Feasibility Matter? Understanding the Impact of Feasibility on Synthetic Training Data|可行性重要吗？理解可行性对合成训练数据的影响|Yiwen Liu, Jessica Bader, Jae Myung Kim|<http://arxiv.org/pdf/2505.10551v1>|研究合成数据可行性对CLIP分类器性能的影响，提出VariReal管道，验证可行性对模型泛化能力影响...|
|🆕 发布|Multi-Source Collaborative Style Augmentation and Domain-Invariant Learning for Federated Domain Generalization|多源协同风格增强与联邦域泛化中的域不变学习|Yikang Wei|<http://arxiv.org/pdf/2505.10152v1>|提出了一种多源协同风格增强和域不变学习方法，有效提升了联邦域泛化性能。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|An unsupervised method for MRI recovery: Deep image prior with structured sparsity|无监督MRI恢复方法：具有结构稀疏性的深度图像先验|Muhammad Ahmad Sultan, Chong Chen, Yingmin Liu, Katarzyna Gil, Karolina Zareba, Rizwan Ahmad|<http://arxiv.org/pdf/2501.01482v2>|提出了一种无需全采样k空间数据的MRI重建方法，通过引入结构化稀疏性优化深度图像先验。|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Logos as a Well-Tempered Pre-train for Sign Language Recognition|作为调适良好的预训练的标志用于手语识别|Ilya Ovodov, Petr Surovtsev, Karina Kvanchiani, Alexander Kapitanov, Alexander Nagaev|<http://arxiv.org/pdf/2505.10481v1>|提出Logos数据集，通过跨语言迁移学习提高手语识别准确率。|
|🆕 发布|Learned Lightweight Smartphone ISP with Unpaired Data|学习轻量级智能手机ISP（图像信号处理器）的无配对数据|Andrei Arhire, Radu Timofte|<http://arxiv.org/pdf/2505.10420v1>|[代码](https://github.com/AndreiiArhire/Learned-Lightweight-Smartphone-ISP-with-Unpaired-Data); 提出了一种无需配对数据的轻量级手机ISP训练方法，显著提升了图像质量。|
|🆕 发布|MSCI: Addressing CLIP's Inherent Limitations for Compositional Zero-Shot Learning|MSCI：解决CLIP在组合零样本学习中的固有局限性|Yue Wang, Shuai Xu, Xuelin Zhu, Yicong Li|<http://arxiv.org/pdf/2505.10289v1>|[代码](https://github.com/ltpwy/MSCI.); 提出MSCI模型，通过多阶段跨模态交互增强CLIP在细粒度视觉信息感知能力，解决CZSL问题。|
|🆕 发布|TKFNet: Learning Texture Key Factor Driven Feature for Facial Expression Recognition|TKFNet：学习纹理关键因素驱动的面部表情识别特征|Liqian Deng|<http://arxiv.org/pdf/2505.09967v1>|提出TKFNet，通过聚焦纹理关键驱动因素，显著提升面部表情识别准确率。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|WildFireCan-MMD: A Multimodal Dataset for Classification of User-Generated Content During Wildfires in Canada|加拿大野火期间用户生成内容分类的多模态数据集：WildFireCan-MMD|Braeden Sherritt, Isar Nejadgholi, Marzieh Amini|<http://arxiv.org/pdf/2504.13231v2>|构建了WildFireCan-MMD多模态数据集，提升了对加拿大野火用户生成内容的分类准确率。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PointArena: Probing Multimodal Grounding Through Language-Guided Pointing|点竞技场：通过语言引导的指向探究多模态定位|Long Cheng, Jiafei Duan, Yi Ru Wang, Haoquan Fang, Boyang Li, Yushan Huang, Elvis Wang, Ainaz Eftekhar .etc.|<http://arxiv.org/pdf/2505.09990v1>|PointArena通过构建多场景基准平台，提升了多模态指向任务的评估与模型性能。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhancing Multi-Image Question Answering via Submodular Subset Selection|通过子模集选择增强多图像问答|Aaryan Sharma, Shivansh Gupta, Samar Agarwal, Vishak Prasad C., Ganesh Ramakrishnan|<http://arxiv.org/pdf/2505.10533v1>|通过子模块子集选择技术，提升多图像问答场景中检索框架的效率和性能。|
|📝 更新|Towards Scalable IoT Deployment for Visual Anomaly Detection via Efficient Compression|面向高效压缩的视觉异常检测的可扩展物联网部署|Arianna Stropeni, Francesco Borsatti, Manuel Barusco, Davide Dalle Pezze, Marco Fabris, Gian Antonio Susto|<http://arxiv.org/pdf/2505.07119v2>|提出了一种高效压缩方法，显著降低视觉异常检测的延迟，同时保持高准确率。|
|🆕 发布|A Unified and Scalable Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability|一种基于部分感知能力的视觉自监督编码器统一且可扩展的成员推理方法|Jie Zhu, Jirong Zha, Ding Li, Leye Wang|<http://arxiv.org/pdf/2505.10351v1>|[代码](https://github.com/JiePKU/PartCrop.); 提出了一种针对视觉自监督编码器的统一且可扩展的成员推理方法，有效应对隐私泄露问题。|
|🆕 发布|Why 1 + 1 < 1 in Visual Token Pruning: Beyond Naive Integration via Multi-Objective Balanced Covering|视觉Token剪枝中1+1<1的原因：超越简单的集成通过多目标平衡覆盖|Yangfu Li, Hongjian Zhan, Tianyi Chen, Qi Liu, Yue Lu|<http://arxiv.org/pdf/2505.10118v1>|提出了一种基于多目标平衡覆盖的视觉token剪枝方法，有效平衡了性能与效率。|
|🆕 发布|AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection|适应CLIP：为通用视觉异常检测调整CLIP|Bin-Bin Gao, Yue Zhu, Jiangtao Yan, Yuezhi Cai, Weixi Zhang, Meng Wang, Jun Liu, Yong Liu .etc.|<http://arxiv.org/pdf/2505.09926v1>|[代码](https://github.com/gaobb/AdaptCLIP.); AdaptCLIP通过交替学习视觉和文本表示，结合上下文和残差特征，实现了无需微调的通用视觉异常检测...|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CoGenAV: Versatile Audio-Visual Representation Learning via Contrastive-Generative Synchronization|CoGenAV：通过对比-生成同步的通用视听表征学习|Detao Bai, Zhiheng Ma, Xihan Wei, Liefeng Bo|<http://arxiv.org/pdf/2505.03186v2>|CoGenAV通过对比生成同步策略，有效学习跨模态关联，提升语音和视觉任务性能。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Deep Learning-Driven Inhalation Injury Grading Assistant Using Bronchoscopy Images|基于深度学习的支气管镜图像驱动的吸入性损伤分级助手|Yifan Li, Alan W Pang, Jo Woon Chong|<http://arxiv.org/pdf/2505.08517v2>|开发了一种基于深度学习的支气管镜图像分析工具，以客观、准确地对吸入性损伤进行分级。|
|📝 更新|Examining the Source of Defects from a Mechanical Perspective for 3D Anomaly Detection|从机械角度分析3D异常检测中缺陷来源|Hanzhe Liang, Aoran Wang, Jie Zhou, Xin Jin, Can Gao, Jinbao Wang|<http://arxiv.org/pdf/2505.05901v2>|[代码](https://github.com/hzzzzzhappy/MC4AD); 检测3D异常，从力学角度分析缺陷来源，提出MC4AD框架，模拟内外部修正力。|
|🆕 发布|HWA-UNETR: Hierarchical Window Aggregate UNETR for 3D Multimodal Gastric Lesion Segmentation|HWA-UNETR：用于3D多模态胃病变分割的分层窗口聚合UNETR|Jiaming Liang, Lihuan Dai, Xiaoqi Sheng, Xiangguang Chen, Chun Yao, Guihua Tao, Qibin Leng, Honming Cai .etc.|<http://arxiv.org/pdf/2505.10464v1>|[代码](https://github.com/JeMing-creater/HWA-UNETR.); 提出HWA-UNETR框架，解决3D多模态胃部病变分割难题，显著提升分割准确率。|
|🆕 发布|Data-Agnostic Augmentations for Unknown Variations: Out-of-Distribution Generalisation in MRI Segmentation|数据无关增强应对未知变化：MRI分割中的分布外泛化|Puru Vaish, Felix Meister, Tobias Heimann, Christoph Brune, Jelmer M. Wolterink|<http://arxiv.org/pdf/2505.10223v1>|提出了一种针对MRI分割的通用数据增强方法，显著提升了模型对未知分布变化的泛化能力。|
|🆕 发布|On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging|关于医学成像中人类-人工智能对齐、公平性和性能权衡的相互作用|Haozhe Luo, Ziyu Zhou, Zixin Shu, Aurélie Pahud de Mortanges, Robert Berke, Mauricio Reyes|<http://arxiv.org/pdf/2505.10231v1>|[代码](https://github.com/Roypic/Aligner.); 探索了人机对齐与公平性在医学影像中的相互作用，提出结合人类洞察力以减少公平差距并提升泛化能力的方法。|
|🆕 发布|DeepSeqCoco: A Robust Mobile Friendly Deep Learning Model for Detection of Diseases in Cocos nucifera|DeepSeqCoco：一种鲁棒且适用于移动设备的深度学习模型，用于检测椰子疾病|Miit Daga, Dhriti Parikh, Swarna Priya Ramu|<http://arxiv.org/pdf/2505.10030v1>|开发了一种高效、准确的深度学习模型，用于自动识别椰子树疾病，显著提升农业病害监测效率。|
|📝 更新|Cyclic 2.5D Perceptual Loss for Cross-Modal 3D Medical Image Synthesis: T1w MRI to Tau PET|循环2.5D感知损失在跨模态3D医学图像合成中的应用：T1w MRI到Tau PET|Junho Moon, Symac Kim, Haejun Chung, Ikbeom Jang|<http://arxiv.org/pdf/2406.12632v2>|提出循环2.5D感知损失，有效合成3D医学图像，提升跨模态医学图像合成性能。|
|📝 更新|A Trust-Guided Approach to MR Image Reconstruction with Side Information|基于辅助信息的信任引导磁共振图像重建方法|Arda Atalık, Sumit Chopra, Daniel K. Sodickson|<http://arxiv.org/pdf/2501.03021v2>|[代码](https://github.com/sodicksonlab/TGVN.); 提出了一种结合辅助信息的深度学习框架，有效提高MRI图像重建质量。|
|🆕 发布|DDFP: Data-dependent Frequency Prompt for Source Free Domain Adaptation of Medical Image Segmentation|DDFP：基于数据的频率提示，用于源自由医学图像分割的域适应|Siqi Yin, Shaolei Liu, Manning Wang|<http://arxiv.org/pdf/2505.09927v1>|提出一种基于预适应和数据依赖频率提示的源域无关域适应框架，有效提升医学图像分割性能。|
|🆕 发布|MambaControl: Anatomy Graph-Enhanced Mamba ControlNet with Fourier Refinement for Diffusion-Based Disease Trajectory Prediction|MambaControl：基于傅里叶精炼的解剖图增强Mamba ControlNet，用于扩散疾病轨迹预测|Hao Yang, Tao Tan, Shuai Tan, Weiqin Yang, Kunyan Cai, Calvin Chen, Yue Sun|<http://arxiv.org/pdf/2505.09965v1>|MambaControl通过结合图增强和傅里叶变换，提升了扩散模型在疾病轨迹预测中的解剖结构和时间动...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Consistent Quantity-Quality Control across Scenes for Deployment-Aware Gaussian Splatting|场景间一致性数量-质量控制，以适应部署感知高斯分层|Fengdi Zhang, Hongkun Cao, Ruqi Huang|<http://arxiv.org/pdf/2505.10473v1>|提出ControlGS方法，实现场景间一致的质量-数量控制，优化3D渲染性能。|
|📝 更新|Illegal Waste Detection in Remote Sensing Images: A Case Study|遥感图像中的非法垃圾检测：一个案例研究|Federico Gibellini, Piero Fraternali, Giacomo Boracchi, Luca Morandini, Thomas Martinoli, Andrea Diecidue, Simona Malegori|<http://arxiv.org/pdf/2502.06607v3>|开发了一种半自动废物检测流程，有效识别遥感图像中的非法倾倒点，大幅提升环保效率。|
|🆕 发布|Non-Registration Change Detection: A Novel Change Detection Task and Benchmark Dataset|非配准变化检测：一种新的变化检测任务和基准数据集|Zhe Shan, Lei Zhou, Liu Mao, Shaofan Chen, Chuanqiu Ren, Xia Xie|<http://arxiv.org/pdf/2505.09939v1>|[代码](https://github.com/ShanZard/NRCD.); 提出非注册变化检测任务，通过定制图像转换方案解决传统方法在灾害等紧急情况下的失效问题。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visual Fidelity Index for Generative Semantic Communications with Critical Information Embedding|视觉保真度指数：基于关键信息嵌入的生成语义通信|Jianhao Huang, Qunsong Zeng, Kaibin Huang|<http://arxiv.org/pdf/2505.10405v1>|提出了一种结合关键信息嵌入和GVIF指标的混合生成语义通信系统，有效提升图像视觉保真度。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Application of YOLOv8 in monocular downward multiple Car Target detection|YOLOv8在单目向下多车目标检测中的应用|Shijie Lyu|<http://arxiv.org/pdf/2505.10016v1>|提出基于YOLOv8的改进网络，有效检测单目下行多车目标，提升自动驾驶安全与效率。|

