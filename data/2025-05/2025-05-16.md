## [UPDATED!] **2025-05-16** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CoMP: Continual Multimodal Pre-training for Vision Foundation Models|持续多模态预训练用于视觉基础模型|Yitong Chen, Lingchen Meng, Wujian Peng, Zuxuan Wu, Yu-Gang Jiang|<http://arxiv.org/pdf/2503.18931v2>|提出CoMP，通过多模态预训练提升视觉基础模型处理不同尺寸视觉输入和生成与语言更对齐的视觉表示的能力...|
|🆕 发布|EmotionHallucer: Evaluating Emotion Hallucinations in Multimodal Large Language Models|情感幻觉评估：多模态大型语言模型中的情感幻觉评估|Bohao Xing, Xin Liu, Guoying Zhao, Chengyu Liu, Xiaolan Fu, Heikki Kälviäinen|<http://arxiv.org/pdf/2505.11405v1>|[代码](https://github.com/xxtars/EmotionHallucer.); 构建了首个评估多模态大语言模型情感幻觉的基准，并提出PEP-MEK框架提升检测准确率。|
|🆕 发布|Patho-R1: A Multimodal Reinforcement Learning-Based Pathology Expert Reasoner|病理-R1：一种基于多模态强化学习的病理专家推理器|Wenchuan Zhang, Penghao Zhang, Jingru Guo, Tao Cheng, Jie Chen, Shuwan Zhang, Zhang Zhang, Yuhao Yi .etc.|<http://arxiv.org/pdf/2505.11404v1>|[代码](https://github.com/Wenchuan-Zhang/Patho-R1.); 开发了一种基于多模态强化学习的病理推理器，显著提升了病理诊断的准确性和合理性。|
|🆕 发布|Breaking the Batch Barrier (B3) of Contrastive Learning via Smart Batch Mining|打破对比学习批处理壁垒（B3）的智能批挖掘|Raghuveer Thirukovalluru, Rui Meng, Ye Liu, Karthikeyan K, Mingyi Su, Ping Nie, Semih Yavuz, Yingbo Zhou .etc.|<http://arxiv.org/pdf/2505.11293v1>|提出了一种通过智能批挖掘突破对比学习批处理限制的新方法，显著提升了模型性能。|
|🆕 发布|Seeing Sound, Hearing Sight: Uncovering Modality Bias and Conflict of AI models in Sound Localization|视觉听声，听觉观景：揭示AI模型在声源定位中的模态偏差与冲突|Yanhao Jia, Ji Xie, S Jivaganesh, Hao Li, Xu Wu, Mengmi Zhang|<http://arxiv.org/pdf/2505.11217v1>|揭示了AI在声音定位中存在模态偏差和冲突，并通过微调模型提升了性能。|
|📝 更新|Customizing Visual-Language Foundation Models for Multi-modal Anomaly Detection and Reasoning|定制视觉-语言基础模型以实现多模态异常检测与推理|Xiaohao Xu, Yunkang Cao, Huaxin Zhang, Nong Sang, Xiaonan Huang|<http://arxiv.org/pdf/2403.11083v2>|[代码](https://github.com/Xiaohao-Xu/Customizable-VLM); 构建通用视觉语言基础模型，实现多模态异常检测与推理。|
|🆕 发布|Generative Models in Computational Pathology: A Comprehensive Survey on Methods, Applications, and Challenges|计算病理学中的生成模型：方法、应用与挑战综述|Yuan Zhang, Xinfeng Zhang, Xiaoming Qi Xinyu Wu, Feng Chen, Guanyu Yang, Huazhu Fu|<http://arxiv.org/pdf/2505.10993v1>|综述了计算病理学中生成模型的方法、应用和挑战，推动了高效学习、数据增强和多模态表示的发展。|
|📝 更新|From Image to Video, what do we need in multimodal LLMs?|从图像到视频：多模态大型语言模型需要什么？|Suyuan Huang, Haoxin Zhang, Linqing Zhong, Honggu Chen, Yan Gao, Yao Hu, Zengchang Qin|<http://arxiv.org/pdf/2404.11865v2>|提出RED-VILLM，通过利用图像LLMs先验知识构建高效、可扩展的视频LLMs。|
|🆕 发布|A Light and Smart Wearable Platform with Multimodal Foundation Model for Enhanced Spatial Reasoning in People with Blindness and Low Vision|轻巧智能的可穿戴平台，基于多模态基础模型以增强盲人和低视力人群的空间推理能力|Alexey Magay, Dhurba Tripathi, Yu Hao, Yi Fang|<http://arxiv.org/pdf/2505.10875v1>|提出了一种结合轻量级硬件和空间推理能力的多模态大语言模型，有效提升视障人士的环境理解和导航能力。|
|📝 更新|DARTer: Dynamic Adaptive Representation Tracker for Nighttime UAV Tracking|动态自适应表示跟踪器：夜间无人机跟踪|Xuzhao Li, Xuchen Li, Shiyu Hu|<http://arxiv.org/pdf/2505.00752v2>|DARTer通过动态融合多视角夜间特征和自适应激活Vision Transformer层，有效提升了...|
|🆕 发布|Multimodal Event Detection: Current Approaches and Defining the New Playground through LLMs and VLMs|多模态事件检测：当前方法与通过大型语言模型和视觉语言模型定义新竞技场|Abhishek Dey, Aabha Bothera, Samhita Sarikonda, Rishav Aryan, Sanjay Kumar Podishetty, Akshay Havalgi, Gaurav Singh, Saurabh Srivastava|<http://arxiv.org/pdf/2505.10836v1>|该论文通过结合LLMs和VLMs，提出了一种多模态事件检测方法，显著提升了社交媒体事件检测的准确性。|
|🆕 发布|Unifying Segment Anything in Microscopy with Multimodal Large Language Model|统一显微镜中的“任何分割”与多模态大型语言模型|Manyu Li, Ruian He, Zixian Zhang, Weimin Tan, Bo Yan|<http://arxiv.org/pdf/2505.10769v1>|[代码](https://github.com/ieellee/uLLSAM.); 利用多模态大语言模型增强显微镜图像分割，显著提升跨域数据集上的性能。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HumaniBench: A Human-Centric Framework for Large Multimodal Models Evaluation|人本基准：大型多模态模型评估的人中心框架|Shaina Raza, Aravind Narayanan, Vahid Reza Khazaie, Ashmal Vayani, Mukund S. Chettiar, Amandeep Singh, Mubarak Shah, Deval Pandya|<http://arxiv.org/pdf/2505.11454v1>|[代码](https://vectorinstitute.github.io/HumaniBench); HumaniBench构建首个以人为中心的AI基准，评估大型多模态模型在公平、伦理等原则上的表现。|
|🆕 发布|Dynamic Base model Shift for Delta Compression|动态基础模型位移用于Delta压缩|Chenyu Huang, Peng Ye, Shenghe Zheng, Xiaohui Wang, Lei Bai, Tao Chen, Wanli Ouyang|<http://arxiv.org/pdf/2505.11344v1>|提出动态基模型迁移方法，显著提升Delta压缩性能。|
|📝 更新|SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models|SCAM：多模态基础模型的真实世界印刷鲁棒性评估|Justus Westerhoff, Erblina Purelku, Jakob Hackstein, Jonas Loos, Leo Pinetzki, Lorenz Hufe|<http://arxiv.org/pdf/2504.04893v4>|构建了大规模真实世界印刷攻击数据集，揭示了多模态基础模型在印刷攻击下的脆弱性。|
|🆕 发布|Redundancy-Aware Pretraining of Vision-Language Foundation Models in Remote Sensing|遥感中的冗余感知视觉-语言基础模型预训练|Mathis Jürgen Adler, Leonard Hackel, Gencer Sumbul, Begüm Demir|<http://arxiv.org/pdf/2505.11121v1>|提出了一种基于特征聚合和注意力机制的策略，有效减少遥感视觉语言模型预训练中的冗余信息。|
|🆕 发布|Pretrained hybrid transformer for generalizable cardiac substructures segmentation from contrast and non-contrast CTs in lung and breast cancers|预训练混合Transformer在肺和乳腺癌中从对比和非对比CT图像中进行可泛化心脏亚结构分割|Aneesh Rangnekar, Nikhil Mankuzhy, Jonas Willmann, Chloe Choi, Abraham Wu, Maria Thor, Andreas Rimner, Harini Veeraraghavan|<http://arxiv.org/pdf/2505.10855v1>|提出了一种结合预训练和混合变换器卷积网络的模型，有效提高了不同成像和患者特征下心脏亚结构的CT分割准...|
|🆕 发布|From Embeddings to Accuracy: Comparing Foundation Models for Radiographic Classification|从嵌入到准确度：比较放射学分类的基础模型|Xue Li, Jameson Merkow, Noel C. F. Codella, Alberto Santamaria-Pang, Naiteek Sangani, Alexander Ersoy, Christopher Burt, John W. Garrett .etc.|<http://arxiv.org/pdf/2505.10823v1>|该研究比较了不同基础模型在放射学分类中的应用，发现MedImageInsight嵌入与支持向量机适配...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Espresso: High Compression For Rich Extraction From Videos for Your Vision-Language Model|Espresso：为您的视觉-语言模型提供丰富提取的高压缩视频|Keunwoo Peter Yu, Achal Dave, Rares Ambrus, Jean Mercat|<http://arxiv.org/pdf/2412.04729v3>|提出Espresso，通过固定长度序列压缩视频，实现高效编码并保持长视频理解能力。|
|🆕 发布|PhiNet v2: A Mask-Free Brain-Inspired Vision Foundation Model from Video|PhiNet v2：基于视频的无掩码脑启发视觉基础模型|Makoto Yamada, Kian Ming A. Chai, Ayoub Rhim, Satoki Ishikawa, Mohammad Sabokrou, Yao-Hung Hubert Tsai|<http://arxiv.org/pdf/2505.11129v1>|PhiNet v2通过Transformer架构，实现了无需强数据增强的时序视觉输入处理，推进了更符...|
|📝 更新|Normalized Matching Transformer|归一化匹配转换器|Abtin Pourhadi, Paul Swoboda|<http://arxiv.org/pdf/2503.17715v2>|提出了一种基于深度学习的图像关键点匹配新方法，显著提升了匹配精度和效率。|
|🆕 发布|CTP: A hybrid CNN-Transformer-PINN model for ocean front forecasting|海洋前沿预测的混合CNN-Transformer-PINN模型：CTP|Yishuo Wang, Feng Zhou, Muping Zhou, Qicheng Meng, Zhijun Hu, Yi Wang|<http://arxiv.org/pdf/2505.10894v1>|提出CTP模型，融合CNN、Transformer和PINN，有效预测海洋锋动态变化。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Disentangling CLIP for Multi-Object Perception|解耦CLIP以实现多对象感知|Samyak Rawlekar, Yujun Cai, Yiwei Wang, Ming-Hsuan Yang, Narendra Ahuja|<http://arxiv.org/pdf/2502.02977v3>|提出DCLIP框架，通过解耦CLIP特征，显著提升多对象感知能力。|
|🆕 发布|Improving Object Detection Performance through YOLOv8: A Comprehensive Training and Evaluation Study|通过YOLOv8提升目标检测性能：一项全面的训练与评估研究|Rana Poureskandar, Shiva Razzagzadeh|<http://arxiv.org/pdf/2505.11424v1>|通过YOLOv8模型，本研究提升了面部图像中皱纹检测与分割的性能。|
|🆕 发布|AW-GATCN: Adaptive Weighted Graph Attention Convolutional Network for Event Camera Data Joint Denoising and Object Recognition|自适应加权图注意力卷积网络在事件相机数据联合去噪和目标识别中的应用|Haiyu Li, Charith Abhayaratne|<http://arxiv.org/pdf/2505.11232v1>|提出了一种自适应加权图注意力卷积网络，有效去除事件相机数据噪声并提高物体识别准确率。|
|🆕 发布|Hashing for Structure-based Anomaly Detection|基于结构的异常检测的哈希方法|Filippo Leveni, Luca Magri, Cesare Alippi, Giacomo Boracchi|<http://arxiv.org/pdf/2505.10873v1>|[代码](https://github.com/ineveLoppiliF/Hashing-for-Structure-based-Anomaly-Detection.); 利用局部敏感哈希在偏好空间中实现高效的结构异常检测。|
|🆕 发布|A High-Performance Thermal Infrared Object Detection Framework with Centralized Regulation|高性能集中调控热红外目标检测框架|Jinke Li, Yue Wu, Xiaoyan Yang|<http://arxiv.org/pdf/2505.10825v1>|提出CRT-YOLO框架，通过集中特征调节和全局信息融合，显著提升热红外图像目标检测性能。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection|MTevent：用于6D姿态估计和移动目标检测的多任务事件相机数据集|Shrutarv Awasthi, Anas Gouda, Sven Franke, Jérôme Rutinowski, Frank Hoffmann, Moritz Roidl|<http://arxiv.org/pdf/2505.11282v1>|构建了MTevent数据集，用于解决高速移动机器人场景下的6D姿态估计和移动目标检测问题。|
|🆕 发布|Pseudo-Label Quality Decoupling and Correction for Semi-Supervised Instance Segmentation|伪标签质量解耦与校正的半监督实例分割|Jianghang Lin, Yilin Lu, Yunhang Shen, Chaoyang Zhu, Shengchuan Zhang, Liujuan Cao, Rongrong Ji|<http://arxiv.org/pdf/2505.11075v1>|提出PL-DC框架，通过解耦伪标签质量和动态校正，显著提升半监督实例分割性能。|
|🆕 发布|PoseBench3D: A Cross-Dataset Analysis Framework for 3D Human Pose Estimation|3D人体姿态估计的跨数据集分析框架：PoseBench3D|Saad Manzur, Bryan Vela, Brandon Vela, Aditya Agrawal, Lan-Anh Dang-Vu, David Li, Wayne Hayes|<http://arxiv.org/pdf/2505.10888v1>|PoseBench3D提出统一框架，评估3D人体姿态估计模型跨数据集性能，分析预处理和准备参数影响。|
|🆕 发布|Preference Isolation Forest for Structure-based Anomaly Detection|基于结构的异常检测的偏好隔离森林|Filippo Leveni, Luca Magri, Cesare Alippi, Giacomo Boracchi|<http://arxiv.org/pdf/2505.10876v1>|提出了一种结合偏好嵌入和隔离森林的异常检测框架，通过高维偏好空间识别结构异常。|
|🆕 发布|RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects|RefPose：利用参考几何对应关系进行未见物体精确6D姿态估计|Jaeguk Kim, Jaewoo Park, Keuntek Lee, Nam Ik Cho|<http://arxiv.org/pdf/2505.10841v1>|RefPose通过利用参考图像和几何对应关系，实现了未见物体的准确6D姿态估计。|
|📝 更新|Fast and Robust Localization for Humanoid Soccer Robot via Iterative Landmark Matching|快速且鲁棒的类人形足球机器人定位方法通过迭代地标匹配|Ruochen Hou, Mingzhang Zhu, Hyunwoo Nam, Gabriel I. Fernandez, Dennis W. Hong|<http://arxiv.org/pdf/2503.11020v2>|提出了一种通过迭代地标匹配快速且鲁棒的机器人定位方法，有效解决了传感器噪声和视野限制问题。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CleanPatrick: A Benchmark for Image Data Cleaning|CleanPatrick：图像数据清洗基准|Fabian Gröger, Simone Lionetti, Philippe Gottfrois, Alvaro Gonzalez-Jimenez, Ludovic Amruthalingam, Elisabeth Victoria Goessinger, Hanna Lindemann, Marie Bargiela .etc.|<http://arxiv.org/pdf/2505.11034v1>|构建了首个大规模图像数据清洗基准CleanPatrick，推动数据清洗策略比较和人工智能可靠性。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Completely Weakly Supervised Class-Incremental Learning for Semantic Segmentation|完全弱监督类增量学习用于语义分割|David Minkwan Kim, Soeun Lee, Byeongkeun Kang|<http://arxiv.org/pdf/2505.10781v1>|首次提出完全弱监督的类增量学习语义分割方法，通过结合伪标签和示例引导数据增强，有效提升了分割准确率。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|QVGen: Pushing the Limit of Quantized Video Generative Models|QVGen：推动量化视频生成模型的极限|Yushi Huang, Ruihao Gong, Jing Liu, Yifu Ding, Chengtao Lv, Haotong Qin, Jun Zhang|<http://arxiv.org/pdf/2505.11497v1>|QVGen通过量化感知训练和降秩策略，首次在4位量化下实现与全精度视频生成模型相当的质量。|
|🆕 发布|Unsupervised Detection of Distribution Shift in Inverse Problems using Diffusion Models|无监督检测逆问题中的分布偏移：基于扩散模型|Shirin Shoushtari, Edward P. Chandler, Yuanhao Wang, M. Salman Asif, Ulugbek S. Kamilov|<http://arxiv.org/pdf/2505.11482v1>|提出了一种无需清洁测试图像的完全无监督方法，利用扩散模型识别和量化图像逆问题中的分布偏移。|
|📝 更新|Novel computational workflows for natural and biomedical image processing based on hypercomplex algebras|新型基于超复数代数的自然和生物医学图像处理计算工作流程|Nektarios A. Valous, Eckhard Hitzer, Dragoş Duşe, Rodrigo Rojas Moraleda, Ferdinand Popp, Meggy Suarez-Carmona, Anna Berthel, Ismini Papageorgiou .etc.|<http://arxiv.org/pdf/2502.07758v6>|利用超复数代数提出了一种统一处理自然和生物医学图像的新方法，提升了图像处理性能。|
|🆕 发布|A Fourier Space Perspective on Diffusion Models|傅里叶空间视角下的扩散模型|Fabian Falck, Teodora Pandeva, Kiarash Zahirnia, Rachel Lawrence, Richard Turner, Edward Meeds, Javier Zazo, Sushrut Karmalkar|<http://arxiv.org/pdf/2505.11278v1>|提出了一种基于傅里叶空间的扩散模型新方法，有效提升了高频信息生成质量。|
|🆕 发布|DiCo: Revitalizing ConvNets for Scalable and Efficient Diffusion Modeling|DiCo：为可扩展和高效的扩散建模重振卷积神经网络|Yuang Ai, Qihang Fan, Xuefeng Hu, Zhenheng Yang, Ran He, Huaibo Huang|<http://arxiv.org/pdf/2505.11196v1>|[代码](https://github.com/shallowdream204/DiCo.); 提出了一种基于卷积和通道注意力机制的DiCo模型，显著提升了扩散模型的生成效率和图像质量。|
|📝 更新|FreeA: Human-object Interaction Detection using Free Annotation Labels|FreeA：使用自由标注标签进行人-物交互检测|Qi Liu, Yuxiao Wang, Xinyu Jiang, Wolin Liang, Zhenao Wei, Yu Lei, Nan Zhuang, Weiying Xue|<http://arxiv.org/pdf/2403.01840v2>|提出FreeA方法，通过文本图像模型自动标注，实现弱监督下的人物-物体交互检测，显著提升检测准确率。|
|🆕 发布|What's Inside Your Diffusion Model? A Score-Based Riemannian Metric to Explore the Data Manifold|您内部的扩散模型有何奥秘？一种基于评分的黎曼度量来探索数据流形|Simone Azeglio, Arianna Di Bernardo|<http://arxiv.org/pdf/2505.11128v1>|引入了一种基于得分函数的黎曼度量，以探索数据流形并揭示扩散模型学习到的几何结构。|
|🆕 发布|Towards Self-Improvement of Diffusion Models via Group Preference Optimization|通过组偏好优化实现扩散模型的自我改进|Renjie Chen, Wenfeng Lin, Yichen Zhang, Jiangchuan Wei, Boyuan Liu, Chao Feng, Jiao Ran, Mingyu Guo|<http://arxiv.org/pdf/2505.11070v1>|提出了一种基于群体偏好优化的方法，有效提升扩散模型生成质量，无需额外数据。|
|🆕 发布|Towards Robust and Controllable Text-to-Motion via Masked Autoregressive Diffusion|面向鲁棒且可控的掩码自回归扩散文本到动作|Zongye Zhang, Bohan Kong, Qingjie Liu, Yunhong Wang|<http://arxiv.org/pdf/2505.11013v1>|提出MoMADiff框架，结合掩码建模与扩散过程，实现从文本到运动的鲁棒生成，并支持灵活的关键帧控制...|
|🆕 发布|ForensicHub: A Unified Benchmark & Codebase for All-Domain Fake Image Detection and Localization|法医中心：全领域伪造图像检测与定位的统一基准与代码库|Bo Du, Xuekang Zhu, Xiaochen Ma, Chenfan Qu, Kaiwen Feng, Zhe Yang, Chi-Man Pun, Jian Liu .etc.|<http://arxiv.org/pdf/2505.11003v1>|ForensicHub构建了首个统一基准，打破FIDL领域领域壁垒，推动跨域比较与发展。|
|🆕 发布|Towards Cross-modal Retrieval in Chinese Cultural Heritage Documents: Dataset and Solution|面向中国文化遗产文献的跨模态检索：数据集与解决方案|Junyi Yuan, Jian Zhang, Fangyu Wu, Dongming Lu, Huanda Lu, Qiufeng Wang|<http://arxiv.org/pdf/2505.10921v1>|构建了针对中国文化遗产的CulTi数据集，并提出LACLIP方法提升跨模态检索性能。|
|📝 更新|Visual Watermarking in the Era of Diffusion Models: Advances and Challenges|视觉水印在扩散模型时代：进展与挑战|Junxian Duan, Jiyang Guan, Wenkui Yang, Ran He|<http://arxiv.org/pdf/2505.08197v2>|利用扩散模型提升视觉水印鲁棒性，应对生成AI时代版权侵权挑战。|
|📝 更新|Descriptive Image-Text Matching with Graded Contextual Similarity|描述性图像-文本匹配：基于分级上下文相似度|Jinhyun Jang, Jiyoung Lee, Kwanghoon Sohn|<http://arxiv.org/pdf/2505.09997v2>|提出了一种基于描述性灵活性的图像-文本匹配方法，有效提升了匹配精度和发现潜在匹配对的能力。|
|🆕 发布|SynRailObs: A Synthetic Dataset for Obstacle Detection in Railway Scenarios|铁路场景中障碍物检测的合成数据集：SynRailObs|Qiushi Guo, Jason Rambach|<http://arxiv.org/pdf/2505.10784v1>|构建了SynRailObs合成数据集，利用扩散模型生成罕见障碍物，提升铁路场景障碍物检测性能。|
|📝 更新|GLDiTalker: Speech-Driven 3D Facial Animation with Graph Latent Diffusion Transformer|GLDiTalker：基于图潜在扩散变换器的语音驱动3D面部动画|Yihong Lin, Zhaoxin Fan, Xianjia Wu, Lingyu Xiong, Liang Peng, Xiandong Li, Wenxiong Kang, Songju Lei .etc.|<http://arxiv.org/pdf/2408.01826v4>|提出GLDiTalker，通过图潜扩散Transformer解决语音驱动3D面部动画中的模态不一致问...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PSDiffusion: Harmonized Multi-Layer Image Generation via Layout and Appearance Alignment|PSDiffusion：通过布局和外观对齐实现和谐的多层图像生成|Dingbang Huang, Wenbo Li, Yifei Zhao, Xinyu Pan, Yanhong Zeng, Bo Dai|<http://arxiv.org/pdf/2505.11468v1>|PSDiffusion通过全局层交互机制，同时生成高质量、完整的多层图像，解决现有方法在处理层间交互...|
|🆕 发布|Exploiting Radiance Fields for Grasp Generation on Novel Synthetic Views|利用辐射场在新型合成视图中生成抓取|Abhishek Kashyap, Henrik Andreasson, Todor Stoyanov|<http://arxiv.org/pdf/2505.11467v1>|利用辐射场生成新合成视图，以提升机器人抓取生成精度和覆盖范围。|
|🆕 发布|SurgPose: Generalisable Surgical Instrument Pose Estimation using Zero-Shot Learning and Stereo Vision|SurgPose：基于零样本学习和立体视觉的通用手术器械姿态估计|Utsav Rai, Haozheng Xu, Stamatia Giannarou|<http://arxiv.org/pdf/2505.11439v1>|提出了一种基于零样本学习和立体视觉的手术工具位姿估计新方法，显著提升了未见过工具的位姿估计准确性。|
|📝 更新|VideoHallu: Evaluating and Mitigating Multi-modal Hallucinations on Synthetic Video Understanding|视频幻觉：评估和缓解合成视频理解中的多模态幻觉|Zongxia Li, Xiyang Wu, Guangyao Shi, Yubin Qin, Hongyang Du, Tianyi Zhou, Dinesh Manocha, Jordan Lee Boyd-Graber|<http://arxiv.org/pdf/2505.01481v2>|VideoHallu构建基准评估MLLMs在合成视频中的异常检测能力，并通过GRPO和课程学习提升其...|
|🆕 发布|MARRS: Masked Autoregressive Unit-based Reaction Synthesis|MARRS：基于掩码自回归单元的反应合成|Y. B. Wang, S Wang, J. N. Zhang, J. F. Wu, Q. D. He, C. C. Fu, C. J. Wang, Y. Liu|<http://arxiv.org/pdf/2505.11334v1>|MARRS通过融合动作条件和自适应单元调制，实现了基于动作序列的精细反应动作生成。|
|📝 更新|Inspiring the Next Generation of Segment Anything Models: Comprehensively Evaluate SAM and SAM 2 with Diverse Prompts Towards Context-Dependent Concepts under Different Scenes|激发下一代分割任何事物模型：全面评估SAM和SAM 2，在不同场景下通过多样化的提示向上下文相关概念迈进|Xiaoqi Zhao, Youwei Pang, Shijie Chang, Yuan Zhao, Lihe Zhang, Huchuan Lu, Georges El Fakhri, Xiaofeng Liu|<http://arxiv.org/pdf/2412.01240v2>|该论文全面评估了SAM和SAM 2在场景依赖概念上的分割能力，并提出了统一评估框架和提示生成策略。|
|🆕 发布|CROC: Evaluating and Training T2I Metrics with Pseudo- and Human-Labeled Contrastive Robustness Checks|CROC：使用伪标签和人工标注的对比鲁棒性检查评估和训练T2I度量|Christoph Leiter, Yuki M. Asano, Margret Keuper, Steffen Eger|<http://arxiv.org/pdf/2505.11314v1>|提出CROC框架，通过伪标签和人工标注数据评估T2I生成任务的度量指标鲁棒性。|
|🆕 发布|Diffusion-NPO: Negative Preference Optimization for Better Preference Aligned Generation of Diffusion Models|扩散模型负偏好优化：提升偏好对齐生成的质量|Fu-Yun Wang, Yunhao Shui, Jingtan Piao, Keqiang Sun, Hongsheng Li|<http://arxiv.org/pdf/2505.11245v1>|提出了一种针对扩散模型负偏好优化的方法，提升生成图像与人类偏好的一致性。|
|🆕 发布|CompAlign: Improving Compositional Text-to-Image Generation with a Complex Benchmark and Fine-Grained Feedback|CompAlign：利用复杂基准和细粒度反馈提升组合文本到图像生成|Yixin Wan, Kai-Wei Chang|<http://arxiv.org/pdf/2505.11178v1>|提出CompAlign基准和CompQuest评估框架，提升文本到图像生成中复杂场景的准确性。|
|🆕 发布|HSRMamba: Efficient Wavelet Stripe State Space Model for Hyperspectral Image Super-Resolution|HSRMamba：高效的小波条纹状态空间模型用于高光谱图像超分辨率|Baisong Li, Xingwang Wang, Haixiao Xu|<http://arxiv.org/pdf/2505.11062v1>|HSRMamba通过引入条带扫描和波分解，有效降低计算量并提升超分辨率性能，解决视觉Mamba的潜在...|
|📝 更新|Ophora: A Large-Scale Data-Driven Text-Guided Ophthalmic Surgical Video Generation Model|Ophora：一个大规模数据驱动的文本引导眼科手术视频生成模型|Wei Li, Ming Hu, Guoan Wang, Lihao Liu, Kaijin Zhou, Junzhi Ning, Xin Guo, Zongyuan Ge .etc.|<http://arxiv.org/pdf/2505.07449v3>|[代码](https://github.com/mar-cry/Ophora.); 提出Ophora模型，通过自然语言指令生成逼真的眼科手术视频，解决数据标注难题。|
|📝 更新|MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation|MTVCrafter：面向开放世界人类图像动画的4D运动标记化|Yanbo Ding, Xirui Hu, Zhizhi Guo, Yali Wang|<http://arxiv.org/pdf/2505.10238v2>|[代码](https://github.com/DINGYANB/MTVCrafter.); MTVCrafter通过直接建模4D运动序列，为开放世界人类图像动画提供更灵活和可控的解决方案。|
|🆕 发布|DDAE++: Enhancing Diffusion Models Towards Unified Generative and Discriminative Learning|DDAE++：提升扩散模型以实现统一的生成和判别学习|Weilai Xiang, Hongyu Yang, Di Huang, Yunhong Wang|<http://arxiv.org/pdf/2505.10999v1>|DDAE++通过引入自条件机制，提升了扩散模型在生成和判别学习上的表现，实现了更优的图像生成和理解。|
|🆕 发布|MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation|MoCLIP：基于运动的CLIP微调和蒸馏以实现人类动作生成|Gabriel Maldonado, Armin Danesh Pazho, Ghazal Alinezhad Noghre, Vinit Katariya, Hamed Tabkhi|<http://arxiv.org/pdf/2505.10810v1>|MoCLIP通过引入运动编码头，提升了CLIP在运动生成中的文本到动作的匹配精度。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GIE-Bench: Towards Grounded Evaluation for Text-Guided Image Editing|GIE-Bench：迈向基于文本引导的图像编辑的 grounded 评估|Yusu Qian, Jiasen Lu, Tsu-Jui Fu, Xinze Wang, Chen Chen, Yinfei Yang, Wenze Hu, Zhe Gan|<http://arxiv.org/pdf/2505.11493v1>|提出GIE-Bench基准，以更接地气的方式评估文本引导的图像编辑模型。|
|🆕 发布|Face Consistency Benchmark for GenAI Video|生成对抗网络视频人脸一致性基准|Michal Podstawski, Malgorzata Kudelska, Haohong Wang|<http://arxiv.org/pdf/2505.11425v1>|构建Face Consistency Benchmark评估AI生成视频人物一致性，推动技术发展。|
|🆕 发布|Temporally-Grounded Language Generation: A Benchmark for Real-Time Vision-Language Models|基于时间基础的文本生成：实时视觉-语言模型的基准|Keunwoo Peter Yu, Joyce Chai|<http://arxiv.org/pdf/2505.11326v1>|[代码](https://github.com/yukw777/tglg); 提出TGLG基准任务，评估实时视觉语言模型在视频场景中的语义准确性和时间同步能力。|
|🆕 发布|DRAGON: A Large-Scale Dataset of Realistic Images Generated by Diffusion Models|DRAGON：由扩散模型生成的真实图像大规模数据集|Giulia Bertazzini, Daniele Baracchi, Dasara Shullani, Isao Echizen, Alessandro Piva|<http://arxiv.org/pdf/2505.11257v1>|构建了包含25个扩散模型生成的真实图像数据集DRAGON，以支持合成内容检测和归因技术的研究与评估。|
|📝 更新|HiFlow: Training-free High-Resolution Image Generation with Flow-Aligned Guidance|HiFlow：无需训练的基于流对齐的高分辨率图像生成|Jiazi Bu, Pengyang Ling, Yujie Zhou, Pan Zhang, Tong Wu, Xiaoyi Dong, Yuhang Zang, Yuhang Cao .etc.|<http://arxiv.org/pdf/2504.06232v2>|HiFlow通过引入虚拟参考流，有效指导高分辨率图像生成，显著提升T2I模型生成图像质量。|
|🆕 发布|One Image is Worth a Thousand Words: A Usability Preservable Text-Image Collaborative Erasing Framework|一张图胜千言：一种可保留可用性的文本-图像协同擦除框架|Feiran Li, Qianqian Xu, Shilong Bao, Zhiyong Yang, Xiaochun Cao, Qingming Huang|<http://arxiv.org/pdf/2505.11131v1>|[代码](https://github.com/Ferry-Li/Co-Erasing.); 提出了一种结合视觉监督的文本-图像协同概念擦除框架，有效提升擦除效率和可用性。|
|🆕 发布|MAVOS-DD: Multilingual Audio-Video Open-Set Deepfake Detection Benchmark|多语言音频-视频开放集深度伪造检测基准：MAVOS-DD|Florinel-Alin Croitoru, Vlad Hondru, Marius Popescu, Radu Tudor Ionescu, Fahad Shahbaz Khan, Mubarak Shah|<http://arxiv.org/pdf/2505.11109v1>|构建首个大规模多语言音视频深度伪造检测基准，揭示现有检测器在开放集场景下的局限性。|
|📝 更新|Empowering Agentic Video Analytics Systems with Video Language Models|赋予视频语言模型能力的代理视频分析系统|Yuxuan Yan, Shiqi Jiang, Ting Cao, Yifan Yang, Qianqian Yang, Yuanchao Shu, Yuqing Yang, Lili Qiu|<http://arxiv.org/pdf/2505.00254v3>|提出AVAS系统，通过构建事件知识图谱和智能检索生成机制，实现超长视频的开放式视频分析。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Fibers to Cells: Fourier-Based Registration Enables Virtual Cresyl Violet Staining From 3D Polarized Light Imaging|从纤维到细胞：基于傅里叶变换的配准实现三维偏振光成像的虚拟 Cresyl Violet 染色|Alexander Oberstrass, Esteban Vaca, Eric Upschulte, Meiqi Niu, Nicola Palomero-Gallagher, David Graessel, Christian Schiffer, Markus Axer .etc.|<http://arxiv.org/pdf/2505.11394v1>|利用傅里叶变换和深度学习，实现了从3D偏振光成像到虚拟 Cresyl Violet 染色的细胞级空间...|
|🆕 发布|DexGarmentLab: Dexterous Garment Manipulation Environment with Generalizable Policy|DexGarmentLab：具有可泛化策略的灵巧服装操作环境|Yuran Wang, Ruihai Wu, Yue Chen, Jiarui Wang, Jiaqi Liang, Ziyu Zhu, Haoran Geng, Jitendra Malik .etc.|<http://arxiv.org/pdf/2505.11032v1>|[代码](https://wayrise.github.io/DexGarmentLab); 提出DexGarmentLab环境，通过HALO算法实现通用服装操作策略，有效解决服装操作难题。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Discriminating image representations with principal distortions|利用主失真区分图像表示|Jenelle Feather, David Lipshutz, Sarah E. Harvey, Alex H. Williams, Eero P. Simoncelli|<http://arxiv.org/pdf/2410.15433v2>|提出了一种基于局部几何结构的图像表示比较框架，通过主扭曲识别模型差异。|
|🆕 发布|MutualNeRF: Improve the Performance of NeRF under Limited Samples with Mutual Information Theory|相互NeRF：利用互信息理论在有限样本下提升NeRF的性能|Zifan Wang, Jingwei Li, Yitang Li, Yunze Liu|<http://arxiv.org/pdf/2505.11386v1>|利用互信息理论，MutualNeRF在样本有限的情况下提升了NeRF的性能。|
|🆕 发布|Equal is Not Always Fair: A New Perspective on Hyperspectral Representation Non-Uniformity|光谱表示非均匀性：一个新的视角|Wuzhou Quan, Mingqiang Wei, Jinhui Tang|<http://arxiv.org/pdf/2505.11267v1>|提出FairHyp框架，解决高光谱图像非均匀性问题，实现维度特定自适应。|
|📝 更新|Are We Truly Forgetting? A Critical Re-examination of Machine Unlearning Evaluation Protocols|我们真的在遗忘吗？对机器反学习评估协议的批判性再审视|Yongwoo Kim, Sungmin Cha, Donghyun Kim|<http://arxiv.org/pdf/2503.06991v2>|提出了一种针对机器反学习评估的新方法，以验证其是否真正消除目标遗忘数据。|
|🆕 发布|CUBIC: Concept Embeddings for Unsupervised Bias Identification using VLMs|CUBIC：基于VLMs的无监督偏差识别的概念嵌入|David Méndez, Gianpaolo Bontempo, Elisa Ficarra, Roberto Confalonieri, Natalia Díaz-Rodríguez|<http://arxiv.org/pdf/2505.11060v1>|CUBIC利用VLMs自动发现可能影响模型预测的潜在概念，以识别数据集中的偏见。|
|🆕 发布|Artifacts of Idiosyncracy in Global Street View Data|全球街景数据中的个性特征伪影|Tim Alpherts, Sennay Ghebreab, Nanne van Noord|<http://arxiv.org/pdf/2505.11046v1>|揭示了全球街景数据中城市独特性导致的偏差，并提出了一种评估覆盖分布的方法以改善城市覆盖的洞察。|
|📝 更新|UniSkill: Imitating Human Videos via Cross-Embodiment Skill Representations|UniSkill：通过跨化身技能表示模仿人类视频|Hanjung Kim, Jaehyun Kang, Hyolim Kang, Meedeum Cho, Seon Joo Kim, Youngwoon Lee|<http://arxiv.org/pdf/2505.08787v3>|[代码](https://kimhanjung.github.io/UniSkill.); 提出UniSkill，通过学习跨实体技能表示，实现人类视频模仿，使机器人能从无标签数据中学习技能并应...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dynam3D: Dynamic Layered 3D Tokens Empower VLM for Vision-and-Language Navigation|Dynam3D：动态分层3D标记赋能视觉-语言导航的VLM|Zihan Wang, Seungjun Lee, Gim Hee Lee|<http://arxiv.org/pdf/2505.11383v1>|Dynam3D通过动态分层3D表示，增强VLM在视觉语言导航中的大规模探索和长期记忆能力。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects|《用于重建折射和反射物体的合成数据集和基准》|Yue Yin, Enze Tao, Weijian Deng, Dylan Campbell|<http://arxiv.org/pdf/2505.05848v2>|构建了合成数据集和基准，用于评估从图像中重建折射和反射物体场景的方法。|
|🆕 发布|NeuSEditor: From Multi-View Images to Text-Guided Neural Surface Edits|NeuSEditor：从多视图图像到文本引导的神经表面编辑|Nail Ibrahimli, Julian F. P. Kooij, Liangliang Nan|<http://arxiv.org/pdf/2505.10827v1>|NeuSEditor通过文本指导，实现多视角图像到神经隐式表面的精确编辑，有效解决编辑中的身份保留和...|
|🆕 发布|EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes|EA-3DGS：针对户外场景的高效自适应3D高斯，质量显著提升|Jianlin Guo, Haihong Xiao, Wenxiong Kang|<http://arxiv.org/pdf/2505.10787v1>|提出EA-3DGS，通过高效自适应的3D高斯点优化，实现户外场景的高质量实时渲染。|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SynCL: A Synergistic Training Strategy with Instance-Aware Contrastive Learning for End-to-End Multi-Camera 3D Tracking|SynCL：一种用于端到端多相机3D跟踪的实例感知对比学习协同训练策略|Shubo Lin, Yutong Kou, Zirui Wu, Shaoru Wang, Bing Li, Weiming Hu, Jin Gao|<http://arxiv.org/pdf/2411.06780v3>|提出SynCL协同训练策略，通过混合匹配和动态查询过滤，解决多摄像头3D跟踪中的自关注机制问题，显著...|
|📝 更新|Just Functioning as a Hook for Two-Stage Referring Multi-Object Tracking|仅作为两阶段指称多目标跟踪的钩子功能|Weize Li, Yunhao Du, Qixiang Yin, Zhicheng Zhao, Fei Su, Daqi Liu|<http://arxiv.org/pdf/2503.07516v2>|提出JustHook框架，通过视觉特征钩和并行组合解码器，有效提升了两阶段多目标跟踪的效率和准确性。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Question-Answering Dense Video Events|问答密集型视频事件|Hangyu Qin, Junbin Xiao, Angela Yao|<http://arxiv.org/pdf/2409.04388v5>|[代码](https://github.com/QHUni/DeVE-QA.); 提出DeVi方法，通过多模块协同，有效解答长视频中密集事件问题。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GrowSplat: Constructing Temporal Digital Twins of Plants with Gaussian Splats|植物高斯块时间数字孪生的构建：GrowSplat|Simeon Adebola, Shuangyu Xie, Chung Min Kim, Justin Kerr, Bart M. van Marrewijk, Mieke van Vlaardingen, Tim van Daalen, Robert van Loo .etc.|<http://arxiv.org/pdf/2505.10923v1>|[代码](https://berkeleyautomation.github.io/GrowSplat); GrowSplat通过结合3D高斯Splatting和鲁棒的样本对齐流程，实现了植物生长的精确时间重...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FALCON: False-Negative Aware Learning of Contrastive Negatives in Vision-Language Pretraining|FALCON：视觉-语言预训练中对比负样本的假阴性感知学习|Myunsoo Kim, Seong-Woong Shim, Byung-Jun Lee|<http://arxiv.org/pdf/2505.11192v1>|FALCON通过动态选择合适难度的负样本，有效缓解了视觉语言预训练中的假阴性问题，提升了模型性能。|
|🆕 发布|Assessing the Performance of Analog Training for Transfer Learning|评估模拟训练在迁移学习中的性能|Omobayode Fagbohungbe, Corey Lammie, Malte J. Rasch, Takashi Ando, Tayfun Gokmen, Vijay Narayanan|<http://arxiv.org/pdf/2505.11067v1>|提出c-TTv2算法，解决模拟训练在迁移学习中的性能问题，提高算法鲁棒性。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VIN-NBV: A View Introspection Network for Next-Best-View Selection for Resource-Efficient 3D Reconstruction|VIN-NBV：一种用于资源高效3D重建的下一最佳视图选择的视角内省网络|Noah Frahm, Dongxu Zhao, Andrea Dunn Beltran, Ron Alterovitz, Jan-Michael Frahm, Junier Oliva, Roni Sengupta|<http://arxiv.org/pdf/2505.06219v2>|提出VIN-NBV网络，通过预测视图质量提升直接优化3D重建，显著提升重建质量。|
|🆕 发布|Entropy-Driven Genetic Optimization for Deep-Feature-Guided Low-Light Image Enhancement|熵驱动的深度特征引导低光图像增强遗传优化|Nirjhor Datta, Afroza Akther, M. Sohel Rahman|<http://arxiv.org/pdf/2505.11246v1>|提出了一种基于深度特征和遗传算法的低光图像增强方法，有效提升了图像质量和语义一致性。|
|📝 更新|EdgeOL: Efficient in-situ Online Learning on Edge Devices|EdgeOL：边缘设备上的高效就地在线学习|Sheng Li, Geng Yuan, Yue Dai, Tianyu Wang, Yawen Wu, Alex K. Jones, Jingtong Hu, Tony .etc.|<http://arxiv.org/pdf/2401.16694v6>|EdgeOL通过优化调优和执行时间，有效降低边缘设备上的在线学习能耗。|
|📝 更新|Rethinking Weight-Averaged Model-merging|重新思考加权平均模型融合|Hu Wang, Congbo Ma, Ibrahim Almakky, Ian Reid, Gustavo Carneiro, Mohammad Yaqub|<http://arxiv.org/pdf/2411.09263v4>|[代码](https://github.com/billhhh/Rethink-Merge.); 探究了权重平均模型融合的内在机制，揭示了其有效性的原因和方式。|
|🆕 发布|Hybrid-Emba3D: Geometry-Aware and Cross-Path Feature Hybrid Enhanced State Space Model for Point Cloud Classification|混合-Emba3D：点云分类的几何感知和跨路径特征混合增强状态空间模型|Bin Liu, Chunyang Wang, Xuelian Liu, Guan Xi, Ge Zhang, Ziteng Yao, Mengxue Dong|<http://arxiv.org/pdf/2505.11099v1>|提出Hybrid-Emba3D模型，通过几何特征耦合和跨路径特征混合，有效提升点云分类精度。|
|🆕 发布|Deepfake Forensic Analysis: Source Dataset Attribution and Legal Implications of Synthetic Media Manipulation|深度伪造法医分析：源数据集归因与合成媒体操纵的法律影响|Massimiliano Cassia, Luca Guarnera, Mirko Casu, Ignazio Zangara, Sebastiano Battiato|<http://arxiv.org/pdf/2505.11110v1>|提出了一种基于特征分析的深度伪造检测框架，用于识别GAN生成图像的训练数据集，并探讨其法律意义。|
|📝 更新|RGB-Event Fusion with Self-Attention for Collision Prediction|基于自注意力的RGB-事件融合用于碰撞预测|Pietro Bonazzi, Christian Vogt, Michael Jost, Haotong Qin, Lyes Khacef, Federico Paredes-Valles, Michele Magno|<http://arxiv.org/pdf/2505.04258v2>|提出融合RGB和事件视觉的神经网络，提升无人机避障预测准确性。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|From Pixels to Perception: Interpretable Predictions via Instance-wise Grouped Feature Selection|从像素到感知：通过实例分组特征选择的可解释预测|Moritz Vandenhirtz, Julia E. Vogt|<http://arxiv.org/pdf/2505.06003v2>|提出了一种通过实例级分组特征选择实现可解释预测的计算机视觉方法。|
|🆕 发布|Planar Velocity Estimation for Fast-Moving Mobile Robots Using Event-Based Optical Flow|基于事件光流的快速移动机器人平面速度估计|Liam Boyle, Jonas Kühne, Nicolas Baumann, Niklas Bastuck, Michele Magno|<http://arxiv.org/pdf/2505.11116v1>|利用平面运动学和事件相机光流，提出了一种不受车轮与地面摩擦假设影响的快速移动机器人速度估计方法。|
|📝 更新|Towards Low-Latency Event-based Obstacle Avoidance on a FPGA-Drone|面向FPGA-Drone的低延迟事件驱动障碍物避障|Pietro Bonazzi, Christian Vogt, Michael Jost, Lyes Khacef, Federico Paredes-Vallés, Michele Magno|<http://arxiv.org/pdf/2504.10400v2>|该论文提出了一种基于事件驱动的视觉系统，显著提升了FPGA-Drone的实时避障性能。|
|🆕 发布|A Convolution-Based Gait Asymmetry Metric for Inter-Limb Synergistic Coordination|基于卷积的步态不对称度指标用于肢体协同协调|Go Fukino, Kanta Tachibana|<http://arxiv.org/pdf/2505.10869v1>|提出了一种基于卷积的步态不对称度指标，用于评估肢体协同运动协调性。|
|🆕 发布|MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection|多链：通过层次聚类和模型选择进行多类结构恢复|Luca Magri, Filippo Leveni, Giacomo Boracchi|<http://arxiv.org/pdf/2505.10874v1>|MultiLink通过聚类和模型选择，实现了多类别结构在噪声和异常值数据集中的鲁棒恢复。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Maximizing Asynchronicity in Event-based Neural Networks|基于事件神经网络的异步性最大化|Haiqing Hao, Nikola Zubić, Weihua He, Zhipeng Sui, Davide Scaramuzza, Wenhui Wang|<http://arxiv.org/pdf/2505.11165v1>|提出EVA框架，通过类比语言模型，有效解决事件相机数据在异步神经网络中的表达和泛化问题。|
|🆕 发布|A Survey on the Safety and Security Threats of Computer-Using Agents: JARVIS or Ultron?|计算机使用代理的安全与安全威胁综述：JARVIS还是乌龙？|Ada Chen, Yongjiang Wu, Junyuan Zhang, Shu Yang, Jen-tse Huang, Kun Wang, Wenxuan Wang, Shuai Wang|<http://arxiv.org/pdf/2505.10924v1>|系统化分析了计算机使用代理的安全威胁，并提出了防御策略和评估方法。|
|📝 更新|Structured Preference Optimization for Vision-Language Long-Horizon Task Planning|结构化偏好优化用于视觉-语言长时任务规划|Xiwen Liang, Min Lin, Weiqi Ruan, Rongtao Xu, Yuecheng Liu, Jiaqi Chen, Bingqian Lin, Yuzheng Zhuang .etc.|<http://arxiv.org/pdf/2502.20742v3>|提出SPO方法，通过结构化偏好优化和课程引导训练，显著提升视觉语言长时任务规划中的推理质量和决策准确...|
|🆕 发布|Benchmarking performance, explainability, and evaluation strategies of vision-language models for surgery: Challenges and opportunities|手术视觉-语言模型性能、可解释性和评估策略的基准测试：挑战与机遇|Jiajun Cheng, Xianwu Zhao, Shan Lin|<http://arxiv.org/pdf/2505.10764v1>|评估了视觉语言模型在手术领域的性能和局限性，揭示了其在场景理解中的关键差距。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Self-Supervised Representation Learning for Nerve Fiber Distribution Patterns in 3D-PLI|自监督表示学习在3D-PLI中用于神经纤维分布模式|Alexander Oberstrass, Sascha E. A. Muenzing, Meiqi Niu, Nicola Palomero-Gallagher, Christian Schiffer, Markus Axer, Katrin Amunts, Timo Dickscheid|<http://arxiv.org/pdf/2401.17207v2>|提出了一种基于自监督学习的3D-PLI图像神经纤维结构特征提取方法，实现了对神经纤维组织的有效表征。|
|🆕 发布|Learning Dense Hand Contact Estimation from Imbalanced Data|从不平衡数据中学习密集手部接触估计|Daniel Sungho Jung, Kyoung Mu Lee|<http://arxiv.org/pdf/2505.11152v1>|提出了一种从不平衡数据中学习密集手接触估计的方法，有效解决了类别和空间不平衡问题。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Robust Spiking Neural Networks:Mitigating Heterogeneous Training Vulnerability via Dominant Eigencomponent Projection|迈向鲁棒的脉冲神经网络：通过主特征分量投影缓解异构训练脆弱性|Desong Zhang, Jia Hu, Geyong Min|<http://arxiv.org/pdf/2505.11134v1>|通过主成分投影缓解SNN训练中的异构数据脆弱性。|
|🆕 发布|Textured mesh Quality Assessment using Geometry and Color Field Similarity|基于几何和色彩域相似性的纹理网格质量评估|Kaifa Yang, Qi Yang, Zhu Li, Yiling Xu|<http://arxiv.org/pdf/2505.10824v1>|[代码](https://github.com/yyyykf/FMQM.); 提出了一种基于几何和颜色场相似度的纹理网格质量评估方法，显著提升了评估准确性和效率。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Words in Motion: Extracting Interpretable Control Vectors for Motion Transformers|动态中的词语：提取运动变换器的可解释控制向量|Omer Sahin Tas, Royden Wagner|<http://arxiv.org/pdf/2406.11624v5>|提出了一种通过分析Transformer模型隐藏状态来提取可解释控制向量，从而改善运动预测的方法。|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?|强化学习是否真的激励了LLMs在基模型之外的推理能力？|Yang Yue, Zhiqi Chen, Rui Lu, Andrew Zhao, Zhaokai Wang, Yang Yue, Shiji Song, Gao Huang|<http://arxiv.org/pdf/2504.13837v2>|研究发现，当前强化学习训练的LLMs并未激发出超越基础模型的全新推理能力。|
|📝 更新|TwinTURBO: Semi-Supervised Fine-Tuning of Foundation Models via Mutual Information Decompositions for Downstream Task and Latent Spaces|TwinTURBO：通过下游任务和潜在空间的互信息分解进行基础模型半监督微调|Guillaume Quétant, Pavlo Molchanov, Slava Voloshynovskiy|<http://arxiv.org/pdf/2503.07851v2>|TwinTURBO通过分解互信息，实现基础模型在少量标记数据下的半监督微调，显著提升下游任务性能。|
|🆕 发布|GeoMM: On Geodesic Perspective for Multi-modal Learning|GeoMM：关于多模态学习中的测地线视角|Shibin Mei, Hang Wang, Bingbing Ni|<http://arxiv.org/pdf/2505.11216v1>|首次将测地距离应用于多模态学习，有效捕捉样本复杂关系，提升模型性能。|
|📝 更新|A Review on Discriminative Self-supervised Learning Methods in Computer Vision|计算机视觉中判别性自监督学习方法综述|Nikolaos Giakoumoglou, Tania Stathaki, Athanasios Gkelias|<http://arxiv.org/pdf/2405.04969v2>|综述了计算机视觉中判别自监督学习方法，系统分类并分析了其原理和贡献。|
|🆕 发布|Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning|无插补和无对齐：由一致性语义学习驱动的缺失多视图聚类|Yuzhuo Dai, Jiaqi Jin, Zhibin Dong, Siwei Wang, Xinwang Liu, En Zhu, Xihong Yang, Xinbiao Gan .etc.|<http://arxiv.org/pdf/2505.11182v1>|提出了一种无需插补和校准的基于共识语义学习的多视角聚类框架，有效解决了不完整多视角聚类问题。|
|📝 更新|Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding|利用自动CAD标注进行3D场景理解的有监督学习|Yuchen Rao, Stefan Ainetter, Sinisa Stekovic, Vincent Lepetit, Friedrich Fraundorfer|<http://arxiv.org/pdf/2504.13580v4>|利用自动CAD模型检索技术，实现了高精度3D场景理解标注，显著提升了深度学习模型性能。|
|📝 更新|Two-Stage Random Alternation Framework for One-Shot Pansharpening|两阶段随机交替框架用于单次全色增强|Haorui Chen, Zeyu Ren, Jiaxuan Ren, Ran Ran, Jinliang Shao, Jie Huang, Liangjian Deng|<http://arxiv.org/pdf/2505.06576v2>|提出一种两阶段随机交替框架，有效解决了一次性多光谱/全色图像融合的泛化问题。|
|📝 更新|Learning to Deblur Polarized Images|学习去模糊偏振图像|Chu Zhou, Minggui Teng, Xinyu Zhou, Chao Xu, Imari Sato, Boxin Shi|<http://arxiv.org/pdf/2402.18134v2>|提出了一种针对偏振图像去模糊的方法，通过分解问题并设计两阶段神经网络，显著提升了去模糊效果。|
|📝 更新|HaHeAE: Learning Generalisable Joint Representations of Human Hand and Head Movements in Extended Reality|HaHeAE：在扩展现实学习中学习人类手部和头部运动的可泛化联合表示|Zhiming Hu, Guanhua Zhang, Zheming Yin, Daniel Haeufle, Syn Schmitt, Andreas Bulling|<http://arxiv.org/pdf/2410.16430v3>|HaHeAE通过自监督学习，有效提升了XR中手和头部动作的联合表示能力。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Evaluating Vision-Language Models as Evaluators in Path Planning|评估视觉-语言模型作为路径规划评估者的研究|Mohamed Aghzal, Xiang Yue, Erion Plaku, Ziyu Yao|<http://arxiv.org/pdf/2411.18711v4>|提出PathEval基准，评估视觉语言模型在路径规划中的评估能力。|


### 目标导向视觉决策 (Goal-oriented Visual Decision Making)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Open-Source Multi-Viewpoint Surgical Telerobotics|开源多视角远程手术遥操作技术|Guido Caccianiga, Yarden Sharon, Bernard Javot, Senya Polikovsky, Gökce Ergün, Ivan Capobianco, André L. Mihaljevic, Anton Deguet .etc.|<http://arxiv.org/pdf/2505.11142v1>|提出开源多视角手术遥操作系统，提升手术机器人感知和协作能力。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|L-WISE: Boosting Human Visual Category Learning Through Model-Based Image Selection and Enhancement|L-WISE：通过基于模型的图像选择和增强提升人类视觉类别学习|Morgan B. Talbot, Gabriel Kreiman, James J. DiCarlo, Guy Gaziv|<http://arxiv.org/pdf/2412.09765v4>|通过模型估计图像识别难度并应用图像扰动，提升人类视觉分类学习准确性和效率。|
|🆕 发布|Visual Planning: Let's Think Only with Images|视觉规划：让我们只用图像思考|Yi Xu, Chengzu Li, Han Zhou, Xingchen Wan, Caiqi Zhang, Anna Korhonen, Ivan Vulić|<http://arxiv.org/pdf/2505.11409v1>|提出视觉规划新范式，通过图像序列进行推理，实现无需文字的规划。|
|📝 更新|A-I-RAVEN and I-RAVEN-Mesh: Two New Benchmarks for Abstract Visual Reasoning|A-I-RAVEN和I-RAVEN-Mesh：抽象视觉推理的两个新基准|Mikołaj Małkiński, Jacek Mańdziuk|<http://arxiv.org/pdf/2406.11061v2>|构建了两个抽象视觉推理基准，评估了深度神经网络在知识迁移和泛化能力上的不足。|
|🆕 发布|Human-Aligned Bench: Fine-Grained Assessment of Reasoning Ability in MLLMs vs. Humans|人机对齐基准：多模态大型语言模型与人类推理能力的细粒度评估|Yansheng Qiu, Li Xiao, Zhaopan Xu, Pengfei Zhou, Zheng Wang, Kaipeng Zhang|<http://arxiv.org/pdf/2505.11141v1>|构建了Human-Aligned Bench基准，评估MLLM在多模态推理上的能力，并与人类表现进行...|
|🆕 发布|Classifying Shelf Life Quality of Pineapples by Combining Audio and Visual Features|通过结合音频和视觉特征对菠萝货架寿命质量进行分类|Yi-Lu Jiang, Wen-Chang Chang, Ching-Lin Wang, Kung-Liang Hsu, Chih-Yi Chiu|<http://arxiv.org/pdf/2505.11020v1>|构建多模态多视角模型，结合音频和视觉特征，提高菠萝货架期质量分类准确率。|
|🆕 发布|Visual Anomaly Detection under Complex View-Illumination Interplay: A Large-Scale Benchmark|复杂视-光照交互下的视觉异常检测：一个大规模基准|Yunkang Cao, Yuqi Cheng, Xiaohao Xu, Yiheng Zhang, Yihan Sun, Yuxiang Tan, Yuxin Zhang, Xiaonan Huang .etc.|<http://arxiv.org/pdf/2505.10996v1>|[代码](https://hustcyq.github.io/M2AD); 构建大规模基准M2AD，解决视觉异常检测对视角和光照交互敏感的问题。|
|📝 更新|Visual Feedback of Pattern Separability Improves Myoelectric Decoding Performance of Upper Limb Prostheses|视觉反馈提高上肢假肢肌电图解码性能的图案可分性视觉反馈|Ruichen Yang, György M. Lévay, Christopher L. Hunt, Dániel Czeiner, Megan C. Hodgson, Damini Agarwal, Rahul R. Kaliki, Nitish V. Thakor|<http://arxiv.org/pdf/2505.09819v2>|通过引入3D视觉反馈，该论文提出了一种直观的训练方法，显著提升了上肢假肢的肌电解码性能。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Resolving the Ambiguity of Complete-to-Partial Point Cloud Registration for Image-Guided Liver Surgery with Patches-to-Partial Matching|解决基于图像引导的肝脏手术中完整到部分点云配准的歧义：使用补丁到部分匹配|Zixin Yang, Jon S. Heiselman, Cheng Han, Kelly Merrell, Richard Simon, Cristian. A. Linte|<http://arxiv.org/pdf/2412.19328v2>|提出一种补丁到部分匹配策略，有效解决术中视野有限导致的点云配准模糊问题。|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|V-MAGE: A Game Evaluation Framework for Assessing Vision-Centric Capabilities in Multimodal Large Language Models|V-MAGE：一种用于评估多模态大型语言模型视觉中心能力的游戏评估框架|Xiangxi Zheng, Linjie Li, Zhengyuan Yang, Ping Yu, Alex Jinpeng Wang, Rui Yan, Yuan Yao, Lijuan Wang|<http://arxiv.org/pdf/2504.06148v2>|[代码](https://github.com/CSU-JPG/V-MAGE.); V-MAGE提出了一种基于游戏的评估框架，用于评估多模态大语言模型在动态视觉推理方面的能力。|
|🆕 发布|WildDoc: How Far Are We from Achieving Comprehensive and Robust Document Understanding in the Wild?|WildDoc：我们离实现野外全面且鲁棒的文档理解还有多远？|An-Lan Wang, Jingqun Tang, Liao Lei, Hao Feng, Qi Liu, Xiang Fei, Jinghui Lu, Han Wang .etc.|<http://arxiv.org/pdf/2505.11015v1>|[代码](https://bytedance.github.io/WildDoc.); WildDoc提出首个针对真实场景文档理解的基准，揭示现有模型在复杂环境下的不足。|
|🆕 发布|VISTA: Enhancing Vision-Text Alignment in MLLMs via Cross-Modal Mutual Information Maximization|VISTA：通过跨模态互信息最大化增强多模态语言模型中的视觉-文本对齐|Mingxiao Li, Na Su, Fang Qu, Zhizhou Zhong, Ziyang Chen, Zhaopeng Tu, Xiaolong Li|<http://arxiv.org/pdf/2505.10917v1>|VISTA通过最大化跨模态互信息，有效提升了MLLMs的视觉-文本对齐能力。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|INSIGHT: Enhancing Autonomous Driving Safety through Vision-Language Models on Context-Aware Hazard Detection and Edge Case Evaluation|洞察：通过基于上下文感知危险检测和边缘情况评估的视觉-语言模型增强自动驾驶安全性|Dianwei Chen, Zifan Zhang, Yuchen Liu, Xianfeng Terry Yang|<http://arxiv.org/pdf/2502.00262v3>|提出了一种融合语义视觉信息的视觉语言模型，显著提升了自动驾驶系统对边缘案例的识别和预测能力。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|reBEN: Refined BigEarthNet Dataset for Remote Sensing Image Analysis|精炼大地球网数据集：用于遥感图像分析的reBEN|Kai Norman Clasen, Leonard Hackel, Tom Burgert, Gencer Sumbul, Begüm Demir, Volker Markl|<http://arxiv.org/pdf/2407.03653v5>|构建了高质量、多模态的reBEN数据集，优化了遥感图像分析中的深度学习模型训练。|
|📝 更新|Communication-Efficient Federated Learning Based on Explanation-Guided Pruning for Remote Sensing Image Classification|基于解释引导剪枝的通信高效联邦学习用于遥感图像分类|Jonas Klotz, Barış Büyüktaş, Begüm Demir|<http://arxiv.org/pdf/2501.11493v2>|提出了一种基于解释引导剪枝的通信高效联邦学习方法，有效降低遥感图像分类的模型更新传输量。|
|📝 更新|A Plasticity-Aware Method for Continual Self-Supervised Learning in Remote Sensing|一种针对遥感领域持续自监督学习的可塑性感知方法|Lars Möllenbrok, Behnood Rasti, Begüm Demir|<http://arxiv.org/pdf/2503.24088v2>|提出一种兼顾连续自监督学习和学习塑性的遥感方法，有效提升模型性能。|
|🆕 发布|M4-SAR: A Multi-Resolution, Multi-Polarization, Multi-Scene, Multi-Source Dataset and Benchmark for Optical-SAR Fusion Object Detection|M4-SAR：一种多分辨率、多极化、多场景、多源数据集和基准，用于光学SAR融合目标检测|Chao Wang, Wei Lu, Xiang Li, Jian Yang, Lei Luo|<http://arxiv.org/pdf/2505.10931v1>|[代码](https://github.com/wchao0601/M4-SAR.); 构建了首个多源融合目标检测数据集M4-SAR，显著提升了复杂环境下的检测精度。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-view dense image matching with similarity learning and geometry priors|多视角密集图像匹配：基于相似性学习和几何先验|Mohamed Ali Chebbi, Ewelina Rupnik, Paul Lopes, Marc Pierrot-Deseilligny|<http://arxiv.org/pdf/2505.11264v1>|提出了一种利用深度学习进行多视角图像匹配的新方法，显著提升了重建精度和泛化能力。|
|📝 更新|IMPACT: A Generic Semantic Loss for Multimodal Medical Image Registration|IMPACT：一种通用的多模态医学图像配准语义损失|Valentin Boussot, Cédric Hémon, Jean-Claude Nunes, Jason Dowling, Simon Rouzé, Caroline Lafond, Anaïs Barateau, Jean-Louis Dillenseger|<http://arxiv.org/pdf/2503.24121v3>|提出了一种基于预训练模型特征的通用语义损失函数，有效提升了多模态医学图像配准的精度和鲁棒性。|
|📝 更新|In-Model Merging for Enhancing the Robustness of Medical Imaging Classification Models|模型内融合以增强医学图像分类模型的鲁棒性|Hu Wang, Ibrahim Almakky, Congbo Ma, Numan Saeed, Mohammad Yaqub|<http://arxiv.org/pdf/2502.20516v2>|提出InMerge方法，通过模型内合并增强医疗图像分类模型的鲁棒性。|
|🆕 发布|CheX-DS: Improving Chest X-ray Image Classification with Ensemble Learning Based on DenseNet and Swin Transformer|CheX-DS：基于DenseNet和Swin Transformer的集成学习提升胸部X光图像分类|Xinran Li, Yu Liu, Xiujuan Xu, Xiaowei Zhao|<http://arxiv.org/pdf/2505.11168v1>|提出CheX-DS模型，结合DenseNet和Swin Transformer，有效提升胸部X光片分...|
|🆕 发布|Diffusion Model in Hyperspectral Image Processing and Analysis: A Review|扩散模型在高光谱图像处理与分析中的应用综述|Xing Hu, Xiangcheng Liu, Qianqian Duan, Danfeng Hong, Dawei Zhang|<http://arxiv.org/pdf/2505.11158v1>|该论文提出利用扩散模型有效处理高光谱图像，提升分析准确性和效率。|
|📝 更新|Efficient and Comprehensive Feature Extraction in Large Vision-Language Model for Pathology Analysis|高效且全面的特征提取在大规模病理分析视觉-语言模型中|Shengxuming Zhang, Weihan Li, Tianhong Gao, Jiacong Hu, Haoming Luo, Xiuming Zhang, Jing Zhang, Mingli Song .etc.|<http://arxiv.org/pdf/2412.09521v3>|提出混合任务引导和提示引导的特征提取策略，显著提升病理图像分析的准确性和效率。|
|🆕 发布|Rethinking the Mean Teacher Strategy from the Perspective of Self-paced Learning|重新审视自学习步长视角下的平均教师策略|Pengchen Zhang, Alan J. X. Guo, Sipin Luo, Zhe Han, Lin Guo|<http://arxiv.org/pdf/2505.11018v1>|将均值教师策略重新诠释为一种自定步速学习，通过不同架构的教师-学生模型输出一致性生成伪标签，有效提升...|
|🆕 发布|Patient-Specific Dynamic Digital-Physical Twin for Coronary Intervention Training: An Integrated Mixed Reality Approach|患者特异性动态数字-物理孪生用于冠状动脉介入训练：一种集成混合现实方法|Shuo Wang, Tong Ren, Nan Cheng, Rong Wang, Li Zhang|<http://arxiv.org/pdf/2505.10902v1>|开发了一种结合数字孪生、计算机视觉和物理模型制造的综合动态心脏模型，用于冠状动脉介入训练。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|An Enhanced YOLOv8 Model for Real-Time and Accurate Pothole Detection and Measurement|增强型YOLOv8模型用于实时精确的坑洞检测与测量|Mustafa Yurdakul, Şakir Tasdemir|<http://arxiv.org/pdf/2505.04207v2>|提出了一种基于RGB-D图像的YOLOv8模型，有效提升了路面坑洞检测与尺寸测量的准确性和实时性。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EmoFace: Emotion-Content Disentangled Speech-Driven 3D Talking Face Animation|情感面孔：情感-内容解耦的语音驱动3D说话人脸动画|Yihong Lin, Liang Peng, Zhaoxin Fan, Xianjia Wu, Jianqiao Hu, Xiandong Li, Wenxiong Kang, Songju Lei|<http://arxiv.org/pdf/2408.11518v3>|提出EmoFace，通过双流网络和Mesh Attention机制，实现情感与内容驱动的3D人脸动画...|

