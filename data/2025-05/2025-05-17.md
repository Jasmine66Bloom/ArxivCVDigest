## [UPDATED!] **2025-05-17** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HISTAI: An Open-Source, Large-Scale Whole Slide Image Dataset for Computational Pathology|HISTAI：一个开源的大规模全切片图像数据集，用于计算病理学|Dmitry Nechaev, Alexey Pchelnikov, Ekaterina Ivanova|<http://arxiv.org/pdf/2505.12120v1>|[代码](https://github.com/HistAI/HISTAI.); 构建了HISTAI开放数据集，解决病理图像数据规模和多样性不足问题。|
|📝 更新|Differentially Private Synthetic Data via APIs 3: Using Simulators Instead of Foundation Model|通过APIs 3生成差分隐私合成数据：使用模拟器而非基础模型|Zinan Lin, Tadas Baltrusaitis, Wenyu Wang, Sergey Yekhanin|<http://arxiv.org/pdf/2502.05505v2>|[代码](https://github.com/microsoft/DPSDA.); 提出了一种利用模拟器而非基础模型生成差分隐私合成数据的新方法，显著提升了数据合成效率和分类准确率。|
|📝 更新|Differentially Private Synthetic Data via Foundation Model APIs 1: Images|基于基础模型API的差异隐私合成数据：图像|Zinan Lin, Sivakanth Gopi, Janardhan Kulkarni, Harsha Nori, Sergey Yekhanin|<http://arxiv.org/pdf/2305.15560v4>|[代码](https://github.com/microsoft/DPSDA.); 提出了一种无需训练的API方法，通过私有演化框架生成与原始数据相似的不同隐私合成图像。|
|📝 更新|TAMP: Token-Adaptive Layerwise Pruning in Multimodal Large Language Models|TAMP：多模态大型语言模型中的基于标记的自适应层间剪枝|Jaewoo Lee, Keyang Xuan, Chanakya Ekbote, Sandeep Polisetty, Yi R. Fung, Paul Pu Liang|<http://arxiv.org/pdf/2504.09897v3>|提出TAMP框架，有效解决多模态大语言模型剪枝问题，显著提升模型性能。|
|📝 更新|Low-hallucination Synthetic Captions for Large-Scale Vision-Language Model Pre-training|低幻觉大规模视觉-语言模型预训练的合成字幕|Xinsong Zhang, Yarong Zeng, Xinting Huang, Hu Hu, Runquan Xie, Han Hu, Zhanhui Kang|<http://arxiv.org/pdf/2504.13123v2>|提出了一种生成低幻觉合成字幕的方法，有效提升了大规模视觉语言模型预训练的性能。|
|🆕 发布|Are vision language models robust to uncertain inputs?|视觉语言模型对不确定输入的鲁棒性如何？|Xi Wang, Eric Nalisnick|<http://arxiv.org/pdf/2505.11804v1>|提出基于模型内部不确定性的新机制，提升视觉语言模型对不确定输入的鲁棒性。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Cross-Model Transfer of Task Vectors via Few-Shot Orthogonal Alignment|通过少量样本正交对齐的任务向量跨模型迁移|Kazuhiko Kawamoto, Atsuhiro Endo, Hiroshi Kera|<http://arxiv.org/pdf/2505.12021v1>|[代码](https://github.com/kawakera-lab/CrossModelTransfer.); 提出了一种通过少量样本对齐任务向量，实现跨模型迁移的新方法，有效提升了模型迁移准确性。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhanced Multimodal Hate Video Detection via Channel-wise and Modality-wise Fusion|基于通道和模态融合的增强多模态仇恨视频检测|Yinghui Zhang, Tailin Chen, Yuchen Zhang, Zeyu Fu|<http://arxiv.org/pdf/2505.12051v1>|[代码](https://github.com/EvelynZ10/cmfusion.); 提出了一种融合文本、音频和视频模态的CMFusion模型，有效提升了仇恨视频检测的准确性。|
|📝 更新|No Other Representation Component Is Needed: Diffusion Transformers Can Provide Representation Guidance by Themselves|ems 无需其他表示组件：扩散变换器可自行提供表示指导|Dengyang Jiang, Mengmeng Wang, Liuzhuozheng Li, Lei Zhang, Haoyu Wang, Wei Wei, Guang Dai, Yanning Zhang .etc.|<http://arxiv.org/pdf/2505.02831v4>|提出Self-Representation Alignment方法，无需额外组件，提升扩散模型生成质...|
|📝 更新|On the Value of Cross-Modal Misalignment in Multimodal Representation Learning|关于跨模态不匹配在多模态表示学习中的价值|Yichao Cai, Yuhang Liu, Erdun Gao, Tianjiao Jiang, Zhen Zhang, Anton van den Hengel, Javen Qinfeng Shi|<http://arxiv.org/pdf/2504.10143v4>|揭示了跨模态失配的价值，并提出利用失配机制提升多模态表征学习效果。|
|📝 更新|Enhancing Multimodal Unified Representations for Cross Modal Generalization|提升跨模态泛化中的多模态统一表示|Hai Huang, Yan Xia, Shengpeng Ji, Shulei Wang, Hanting Wang, Minghui Fang, Jieming Zhu, Zhenhua Dong .etc.|<http://arxiv.org/pdf/2403.05168v2>|提出TOC和FCID方法，解决离散表示冗余和模态特性未充分利用问题，显著提升跨模态泛化性能。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SoftPQ: Robust Instance Segmentation Evaluation via Soft Matching and Tunable Thresholds|软PQ：通过软匹配和可调阈值实现鲁棒的实例分割评估|Ranit Karmakar, Simon F. Nørrelykke|<http://arxiv.org/pdf/2505.12155v1>|提出SoftPQ，通过软匹配和可调阈值，实现鲁棒的实例分割评估。|
|🆕 发布|Keypoints as Dynamic Centroids for Unified Human Pose and Segmentation|关键点作为统一人体姿态和分割的动态质心|Niaz Ahmad, Jawad Khan, Kang G. Shin, Youngmoon Lee, Guanghui Wang|<http://arxiv.org/pdf/2505.12130v1>|提出KDC方法，通过动态关键点作为中心，实现人体姿态估计和实例分割的统一。|
|📝 更新|Rethinking Image Forgery Detection via Soft Contrastive Learning and Unsupervised Clustering|重新思考基于软对比学习和无监督聚类的图像伪造检测|Haiwei Wu, Yiming Chen, Jiantao Zhou, Yuanman Li|<http://arxiv.org/pdf/2308.09307v2>|[代码](https://github.com/HighwayWu/FOCAL.); 提出FOCAL方法，通过软对比学习和无监督聚类，有效解决图像伪造检测中跨图像区域定义问题。|
|🆕 发布|ElderFallGuard: Real-Time IoT and Computer Vision-Based Fall Detection System for Elderly Safety|老年跌倒守护者：基于实时物联网和计算机视觉的老年人安全跌倒检测系统|Tasrifur Riahi, Md. Azizul Hakim Bappy, Md. Mehedi Islam|<http://arxiv.org/pdf/2505.11845v1>|ElderFallGuard利用计算机视觉和物联网技术，实现了对老年人跌倒的实时检测和快速通知。|
|📝 更新|GSplatLoc: Ultra-Precise Camera Localization via 3D Gaussian Splatting|GSplatLoc：基于3D高斯散布的超精确相机定位|Atticus J. Zeller, Haijuan Wu|<http://arxiv.org/pdf/2412.20056v2>|GSplatLoc通过3D高斯分层渲染实现超精确相机定位，显著优于现有方法。|
|🆕 发布|Image-based Visibility Analysis Replacing Line-of-Sight Simulation: An Urban Landmark Perspective|基于图像的可见性分析：取代视距模拟——城市地标视角|Zicheng Fan, Kunihiko Fujiwara, Pengyuan Liu, Fan Zhang, Filip Biljecki|<http://arxiv.org/pdf/2505.11809v1>|提出了一种基于图像的可见性分析方法，替代传统的视距模拟，提升城市地标可见性评估的准确性和全面性。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bayesian Deep Learning Approaches for Uncertainty-Aware Retinal OCT Image Segmentation for Multiple Sclerosis|基于贝叶斯深度学习的多发性硬化症视网膜OCT图像分割的不确定性感知方法|Samuel T. M. Ball|<http://arxiv.org/pdf/2505.12061v1>|利用贝叶斯深度学习提供不确定性估计，提高视网膜OCT图像分割的准确性和可靠性。|
|🆕 发布|Technical Report for ICRA 2025 GOOSE 2D Semantic Segmentation Challenge: Boosting Off-Road Segmentation via Photometric Distortion and Exponential Moving Average|ICRA 2025 GOOSE 2D语义分割挑战技术报告：通过光度失真和指数移动平均提升越野分割|Wonjune Kim, Lae-kyoung Lee, Su-Yong An|<http://arxiv.org/pdf/2505.11769v1>|通过结合光效扭曲和指数移动平均，该方法有效提升了非结构化越野场景的语义分割性能。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Graph Network for Sign Language Tasks|图网络在手语任务中的应用|Shiwei Gan, Yafeng Yin, Zhiwei Jiang, Hongkai Wen, Lei Xie, Sanglu Lu|<http://arxiv.org/pdf/2504.12020v2>|提出MixSignGraph，通过混合图结构捕捉手语特征，显著提升手语识别性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning to Highlight Audio by Watching Movies|通过观看电影学习突出音频|Chao Huang, Ruohan Gao, J. M. F. Tsang, Jan Kurcius, Cagdas Bilen, Chenliang Xu, Anurag Kumar, Sanjeel Parekh|<http://arxiv.org/pdf/2505.12154v1>|[代码](https://wikichao.github.io/VisAH); 提出了一种基于视觉引导的音频突出显示方法，通过电影中的视觉信息优化音频内容，提升视听体验。|
|🆕 发布|VFRTok: Variable Frame Rates Video Tokenizer with Duration-Proportional Information Assumption|VFRTok：基于时长成比例信息假设的可变帧率视频标记器|Tianxiong Zhong, Xingye Tian, Boyuan Jiang, Xuebo Wang, Xin Tao, Pengfei Wan, Zhiwei Zhang|<http://arxiv.org/pdf/2505.12053v1>|提出VFRTok，通过时长比例信息假设和不对称帧率训练，实现高效视频编码和解码。|
|🆕 发布|Accelerating Diffusion-based Super-Resolution with Dynamic Time-Spatial Sampling|加速基于扩散的超分辨率动态时空采样|Rui Qin, Qijie Wang, Ming Sun, Haowei Zhu, Chao Zhou, Bin Wang|<http://arxiv.org/pdf/2505.12048v1>|提出了一种基于动态时间-空间采样的加速扩散超分辨率方法，显著提升性能并减少迭代次数。|
|🆕 发布|Robust Cross-View Geo-Localization via Content-Viewpoint Disentanglement|鲁棒跨视角地理定位通过内容视角解耦|Ke Li, Di Wang, Xiaowei Wang, Zhihong Wu, Yiming Zhang, Yifeng Wang, Quan Wang|<http://arxiv.org/pdf/2505.11822v1>|提出了一种通过内容-视角解耦的鲁棒跨视图地理定位框架，显著提升了定位精度和泛化能力。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Gradient descent with generalized Newton's method|广义牛顿法下的梯度下降|Zhiqi Bu, Shiyun Xu|<http://arxiv.org/pdf/2407.02772v3>|提出了一种基于广义牛顿法的优化方法，自动调整学习率，加速收敛，并在视觉任务中达到最先进性能。|
|📝 更新|A Quality-Centric Framework for Generic Deepfake Detection|基于质量的通用深度伪造检测框架|Wentang Song, Zhiyuan Yan, Yuzhen Lin, Taiping Yao, Changsheng Chen, Shen Chen, Yandan Zhao, Shouhong Ding .etc.|<http://arxiv.org/pdf/2411.05335v3>|提出一种以质量为中心的通用深度伪造检测框架，显著提升现有检测模型的泛化性能。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Preliminary Study for GPT-4o on Image Restoration|GPT-4o在图像修复方面的初步研究|Hao Yang, Yan Yang, Ruikun Zhang, Liyuan Pan|<http://arxiv.org/pdf/2505.05621v2>|首次评估GPT-4o在图像修复中的应用，将其作为先验信息显著提升现有去雾网络性能。|
|🆕 发布|LOVE: Benchmarking and Evaluating Text-to-Video Generation and Video-to-Text Interpretation|LOVE：文本到视频生成和视频到文本解释的基准测试与评估|Jiarui Wang, Huiyu Duan, Ziheng Jia, Yu Zhao, Woo Yi Yang, Zicheng Zhang, Zijian Chen, Juntong Wang .etc.|<http://arxiv.org/pdf/2505.12098v1>|[代码](https://github.com/IntMeGroup/LOVE.); 提出AIGVE-60K数据集和LOVE指标，全面评估AI生成视频质量。|
|🆕 发布|Online Iterative Self-Alignment for Radiology Report Generation|在线迭代自对齐用于放射学报告生成|Ting Xiao, Lei Shi, Yang Zhang, HaoFeng Yang, Zhe Wang, Chenjia Bai|<http://arxiv.org/pdf/2505.11983v1>|提出OISA方法，通过迭代多目标优化显著提升放射报告生成模型性能。|
|🆕 发布|SafeVid: Toward Safety Aligned Video Large Multimodal Models|安全视频：迈向与安全一致的视频大模态模型|Yixu Wang, Jiaxin Song, Yifeng Gao, Xin Wang, Yang Yao, Yan Teng, Xingjun Ma, Yingchun Wang .etc.|<http://arxiv.org/pdf/2505.11926v1>|SafeVid通过文本描述促进视频大模型安全推理，显著提升模型安全性。|
|📝 更新|Culture-TRIP: Culturally-Aware Text-to-Image Generation with Iterative Prompt Refinement|文化之旅：基于文化感知的文本到图像生成与迭代提示优化|Suchae Jeong, Inseong Choi, Youngsik Yun, Jihie Kim|<http://arxiv.org/pdf/2502.16902v2>|[代码](https://shane3606.github.io/Culture-TRIP.); 提出Culture-TRIP方法，通过迭代提示优化，提升文化概念在文本到图像生成中的准确匹配。|
|🆕 发布|GenZSL: Generative Zero-Shot Learning Via Inductive Variational Autoencoder|GenZSL：基于归纳变分自动编码器的生成式零样本学习|Shiming Chen, Dingjie Fu, Salman Khan, Fahad Shahbaz Khan|<http://arxiv.org/pdf/2505.11882v1>|[代码](https://github.com/shiming-chen/GenZSL.); 提出GenZSL，通过归纳变分自编码器生成零样本学习中的新类别样本，提升ZSL性能和泛化能力。|
|📝 更新|InstanceGen: Image Generation with Instance-level Instructions|实例生成：基于实例级指令的图像生成|Etai Sella, Yanir Kleiman, Hadar Averbuch-Elor|<http://arxiv.org/pdf/2505.05678v3>|提出结合图像结构和文本指令的生成方法，提升复杂场景下图像生成质量。|
|🆕 发布|RVTBench: A Benchmark for Visual Reasoning Tasks|RVTBench：视觉推理任务基准|Yiqing Shen, Chenjia Li, Chenxiao Fan, Mathias Unberath|<http://arxiv.org/pdf/2505.11838v1>|构建了RVTBench基准，通过数字孪生技术提升视觉推理任务复杂度，实现零样本泛化。|
|📝 更新|STORYANCHORS: Generating Consistent Multi-Scene Story Frames for Long-Form Narratives|故事锚点：为长篇叙事生成一致的多场景故事框架|Bo Wang, Haoyang Huang, Zhiying Lu, Fengyuan Liu, Guoqing Ma, Jianlong Yuan, Yuan Zhang, Nan Duan .etc.|<http://arxiv.org/pdf/2505.08350v2>|提出StoryAnchors，一种生成具有时间一致性和丰富叙事的多场景故事框架的统一框架。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Efficient Diversity-Preserving Diffusion Alignment via Gradient-Informed GFlowNets|高效保留多样性的梯度信息GFlowNets扩散对齐|Zhen Liu, Tim Z. Xiao, Weiyang Liu, Yoshua Bengio, Dinghuai Zhang|<http://arxiv.org/pdf/2412.07775v6>|提出了一种基于GFlowNets的快速且保持多样性和先验的扩散模型微调方法，有效解决了现有方法的不足...|
|🆕 发布|EarthSynth: Generating Informative Earth Observation with Diffusion Models|地球合成：利用扩散模型生成信息丰富的地球观测数据|Jiancheng Pan, Shiye Lei, Yuqian Fu, Jiahao Li, Yanxing Liu, Yuze Sun, Xiao He, Long Peng .etc.|<http://arxiv.org/pdf/2505.12108v1>|EarthSynth利用扩散模型生成多类别地球观测数据，提升遥感图像解释性能。|
|📝 更新|Boosting Diffusion-Based Text Image Super-Resolution Model Towards Generalized Real-World Scenarios|基于扩散的文本图像超分辨率模型在通用真实世界场景中的提升|Chenglu Pan, Xiaogang Xu, Ganggui Ding, Yunke Zhang, Wenbo Li, Jiarong Xu, Qingbiao Wu|<http://arxiv.org/pdf/2503.07232v3>|提出一种融合数据采样和预训练先验的扩散模型，有效提升文本图像超分辨率准确性和真实感。|
|📝 更新|SANA 1.5: Efficient Scaling of Training-Time and Inference-Time Compute in Linear Diffusion Transformer|SANA 1.5：线性扩散Transformer中训练时间和推理时间计算的高效扩展|Enze Xie, Junsong Chen, Yuyang Zhao, Jincheng Yu, Ligeng Zhu, Chengyue Wu, Yujun Lin, Zhekai Zhang .etc.|<http://arxiv.org/pdf/2501.18427v4>|SANA-1.5通过深度增长、模型剪枝和推理时缩放，实现了高效扩展训练和推理计算，显著提升了文本到图...|
|🆕 发布|SpatialCrafter: Unleashing the Imagination of Video Diffusion Models for Scene Reconstruction from Limited Observations|空间工匠：释放视频扩散模型从有限观察中重建场景的想象力|Songchun Zhang, Huiyao Xu, Sitong Guo, Zhongwei Xie, Pengwei Liu, Hujun Bao, Weiwei Xu, Changqing Zou|<http://arxiv.org/pdf/2505.11992v1>|SpatialCrafter通过视频扩散模型和几何约束，从稀疏视角重建逼真3D场景。|
|📝 更新|IntLoRA: Integral Low-rank Adaptation of Quantized Diffusion Models|积分低秩自适应量化扩散模型|Hang Guo, Yawei Li, Tao Dai, Shu-Tao Xia, Luca Benini|<http://arxiv.org/pdf/2410.21759v3>|提出IntLoRA，通过低秩参数优化量化扩散模型，实现高效训练和推理。|
|📝 更新|PAHA: Parts-Aware Audio-Driven Human Animation with Diffusion Model|PAHA：基于扩散模型的部件感知音频驱动人体动画|S. Z. Zhou, Y. B. Wang, J. F. Wu, T. Hu, J. N. Zhang, Z. J. Li, Y. Liu|<http://arxiv.org/pdf/2505.03603v4>|PAHA通过引入部分感知重加权与一致性增强，显著提升了音频驱动人体动画的准确性和效率。|
|🆕 发布|Video-SafetyBench: A Benchmark for Safety Evaluation of Video LVLMs|视频安全基准：视频低级视觉模块安全评估基准|Xuannan Liu, Zekun Li, Zheqi He, Peipei Li, Shuhan Xia, Xing Cui, Huaibo Huang, Xi Yang .etc.|<http://arxiv.org/pdf/2505.11842v1>|构建了首个针对视频文本攻击的LVLM安全评估基准，并提出RJScore评估模型输出。|
|🆕 发布|Bootstrapping Diffusion: Diffusion Model Training Leveraging Partial and Corrupted Data|自举扩散：利用部分和损坏数据的扩散模型训练|Xudong Ma|<http://arxiv.org/pdf/2505.11825v1>|提出一种利用部分和损坏数据训练扩散模型的新方法，显著提升数据利用效率。|
|📝 更新|DiffusionAD: Norm-guided One-step Denoising Diffusion for Anomaly Detection|扩散AD：基于范数引导的单步去噪扩散异常检测|Hui Zhang, Zheng Wang, Dan Zeng, Zuxuan Wu, Yu-Gang Jiang|<http://arxiv.org/pdf/2303.08730v4>|[代码](https://github.com/HuiZhang0812/DiffusionAD); DiffusionAD通过将扩散模型重构过程转化为噪声到范数范式，实现快速、高精度异常检测。|
|🆕 发布|SGD-Mix: Enhancing Domain-Specific Image Classification with Label-Preserving Data Augmentation|SGD-Mix：通过标签保留数据增强提升领域特定图像分类|Yixuan Dong, Fang-Yi Su, Jung-Hsien Chiang|<http://arxiv.org/pdf/2505.11813v1>|提出了一种融合多样性和标签一致性的数据增强方法，显著提升了特定领域图像分类性能。|
|🆕 发布|Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model|自适应残差引导子空间扩散模型进行高光谱和多光谱图像融合的自学习|Jian Zhu, He Wang, Yang Xu, Zebin Wu, Zhihui Wei|<http://arxiv.org/pdf/2505.11800v1>|[代码](https://github.com/Zhu1116/ARGS-Diff.); 提出一种无需额外训练数据的自学习HSI-MSI融合方法，通过自适应残差引导子空间扩散模型实现高分辨率...|
|📝 更新|MoVer: Motion Verification for Motion Graphics Animations|MoVer：运动图形动画的运动验证|Jiaju Ma, Maneesh Agrawala|<http://arxiv.org/pdf/2502.13372v2>|MoVer通过逻辑语言验证动画时空属性，辅助LLM迭代优化动画效果。|
|🆕 发布|Self-NPO: Negative Preference Optimization of Diffusion Models by Simply Learning from Itself without Explicit Preference Annotations|自NPO：通过自身简单学习而不需要显式偏好注释的扩散模型负偏好优化|Fu-Yun Wang, Keqiang Sun, Yao Teng, Xihui Liu, Jiaming Song, Hongsheng Li|<http://arxiv.org/pdf/2505.11777v1>|Self-NPO通过仅从模型自身学习，实现了无需人工标注的负偏好优化，有效提升了扩散模型生成图像的质...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Omni-ID: Holistic Identity Representation Designed for Generative Tasks|全息-ID：专为生成任务设计的整体身份表示|Guocheng Qian, Kuan-Chieh Wang, Or Patashnik, Negin Heravi, Daniil Ostashev, Sergey Tulyakov, Daniel Cohen-Or, Kfir Aberman|<http://arxiv.org/pdf/2412.09694v2>|Omni-ID提出了一种针对生成任务的全新面部表征方法，通过融合多种姿态和表情下的信息，实现更全面的...|
|📝 更新|Incremental Multi-Scene Modeling via Continual Neural Graphics Primitives|增量多场景建模通过持续神经图形原语|Prajwal Singh, Ashish Tiwari, Gautam Vashishtha, Shanmuganathan Raman|<http://arxiv.org/pdf/2411.19903v3>|提出C-NGP框架，实现多场景NeRF模型增量建模，无需额外参数，提高渲染质量。|
|📝 更新|MoDGS: Dynamic Gaussian Splatting from Casually-captured Monocular Videos with Depth Priors|MoDGS：基于深度先验的动态高斯分层从随意捕获的单目视频中生成|Qingming Liu, Yuan Liu, Jiepeng Wang, Xianqiang Lyv, Peng Wang, Wenping Wang, Junhui Hou|<http://arxiv.org/pdf/2406.00434v3>|MoDGS通过深度先验和3D感知初始化，从单目视频渲染高质量动态场景新视图。|
|📝 更新|Explicit and Implicit Representations in AI-based 3D Reconstruction for Radiology: A Systematic Review|基于人工智能的放射学3D重建中的显式和隐式表示：系统评价|Yuezhe Yang, Boyu Yang, Yaqian Wang, Yang He, Xingbo Dong, Zhe Jin|<http://arxiv.org/pdf/2504.11349v2>|[代码](https://github.com/Bean-Young/AI4Radiology.); 系统综述了基于AI的放射学3D重建算法，区分了显式和隐式方法，并探讨了该领域的挑战与未来方向。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CHRIS: Clothed Human Reconstruction with Side View Consistency|克里斯：具有侧面视图一致性的着装人体重建|Dong Liu, Yifan Yang, Zixiong Huang, Yuxin Gao, Mingkui Tan|<http://arxiv.org/pdf/2505.12005v1>|CHRIS通过侧视图一致性增强，解决了单视图图像中全身人类重建的拓扑和表面不一致问题。|
|🆕 发布|GTR: Gaussian Splatting Tracking and Reconstruction of Unknown Objects Based on Appearance and Geometric Complexity|GTR：基于外观和几何复杂度的未知物体高斯散斑跟踪与重建|Takuya Ikeda, Sergey Zakharov, Muhammad Zubair Irshad, Istvan Balazs Opra, Shun Iwase, Dian Chen, Mark Tjersland, Robert Lee .etc.|<http://arxiv.org/pdf/2505.11905v1>|提出了一种结合3D高斯分层和混合几何外观跟踪的新方法，有效解决复杂物体单目RGBD视频的跟踪与重建问...|
|🆕 发布|MonoMobility: Zero-Shot 3D Mobility Analysis from Monocular Videos|MonoMobility：基于单目视频的零样本3D运动分析|Hongyi Zhou, Xiaogang Wang, Yulan Guo, Kai Xu|<http://arxiv.org/pdf/2505.11868v1>|提出了一种从单目视频中零样本分析3D运动的新框架，无需标注数据。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Behind the Screens: Uncovering Bias in AI-Driven Video Interview Assessments Using Counterfactuals|屏幕背后：利用反事实揭示AI驱动视频面试评估中的偏见|Dena F. Mujtaba, Nihar R. Mahapatra|<http://arxiv.org/pdf/2505.12114v1>|开发了一种基于反事实的框架，以评估和量化AI视频面试评估中的偏见。|
|📝 更新|Low-Light Video Enhancement via Spatial-Temporal Consistent Decomposition|低光照视频增强通过时空一致性分解|Xiaogang Xu, Kun Zhou, Tao Hu, Jiafei Wu, Ruixing Wang, Hao Peng, Bei Yu|<http://arxiv.org/pdf/2405.15660v2>|提出了一种结合时空一致分解的视频增强方法，显著提升了低光照视频画质。|
|🆕 发布|CoT-Vid: Dynamic Chain-of-Thought Routing with Self Verification for Training-Free Video Reasoning|CoT-Vid：基于自我验证的无监督视频推理中的动态思维链路由|Hongbo Jin, Ruyang Liu, Wenhao Zhang, Guibo Luo, Ge Li|<http://arxiv.org/pdf/2505.11830v1>|提出CoT-Vid，一种无需训练的视频推理范式，通过动态推理路径路由和视频自一致性验证实现复杂视频推...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Data-centric Prediction Explanation via Kernelized Stein Discrepancy|基于核化Stein差异的数据中心预测解释|Mahtab Sarvmaili, Hassan Sajjad, Ga Wu|<http://arxiv.org/pdf/2403.15576v3>|提出一种基于核化Stein差异的高精度数据中心预测解释方法，有效解决现有方法计算量大、解释粗糙的问题...|
|🆕 发布|Patient-Specific Autoregressive Models for Organ Motion Prediction in Radiotherapy|针对放疗中器官运动预测的患者特异性自回归模型|Yuxiang Lai, Jike Zhong, Vanessa Su, Xiaofeng Yang|<http://arxiv.org/pdf/2505.11832v1>|提出了一种基于自回归模型的器官运动预测方法，有效提高了放疗前的运动预测精度。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Developing a Hybrid Convolutional Neural Network for Automatic Aphid Counting in Sugar Beet Fields|开发一种用于糖 beet 田间自动蚜虫计数的混合卷积神经网络|Xumin Gao, Wenxin Xue, Callum Lennox, Mark Stevens, Junfeng Gao|<http://arxiv.org/pdf/2308.05257v2>|[代码](https://github.com/JunfengGaolab/Counting-Aphids.); 提出了一种混合神经网络，有效解决糖 beet 田间蚜虫自动计数难题。|
|🆕 发布|FiGKD: Fine-Grained Knowledge Distillation via High-Frequency Detail Transfer|FiGKD：通过高频细节迁移的细粒度知识蒸馏|Seonghak Kim|<http://arxiv.org/pdf/2505.11897v1>|提出FiGKD，通过高频细节传递解决细粒度视觉识别中知识蒸馏的不足。|


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DC-Seg: Disentangled Contrastive Learning for Brain Tumor Segmentation with Missing Modalities|DC-Seg：具有缺失模态的脑肿瘤分割的解耦对比学习|Haitao Li, Ziyu Li, Yiheng Mao, Zhengyao Ding, Zhengxing Huang|<http://arxiv.org/pdf/2505.11921v1>|[代码](https://github.com/CuCl-2/DC-Seg.); DC-Seg通过解耦对比学习，有效处理脑肿瘤分割中缺失模态的问题，提升模型鲁棒性。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|NTIRE 2025 Challenge on Efficient Burst HDR and Restoration: Datasets, Methods, and Results|NTIRE 2025 高效爆闪HDR与修复挑战：数据集、方法与结果|Sangmin Lee, Eunpil Park, Angel Canelo, Hyunhee Park, Youngjo Kim, Hyung-Ju Chun, Xin Jin, Chongyi Li .etc.|<http://arxiv.org/pdf/2505.12089v1>|提出了一种基于新型数据集和效率限制的HDR融合方法，显著提升了图像质量。|
|🆕 发布|Denoising Mutual Knowledge Distillation in Bi-Directional Multiple Instance Learning|双向多实例学习中的去噪互信息蒸馏|Chen Shu, Boyu Fu, Yiman Li, Ting Yin, Wenchuan Zhang, Jie Chen, Yuhao Yi, Hong Bu|<http://arxiv.org/pdf/2505.12074v1>|提出了一种基于伪标签校正的双向多实例学习去噪方法，显著提升了病理图像分类的准确性。|
|🆕 发布|Advanced Integration of Discrete Line Segments in Digitized P&ID for Continuous Instrument Connectivity|数字化P&ID中离散线段的先进集成以实现连续仪表连接|Soumya Swarup Prusty, Astha Agarwal, Srinivasan Iyenger|<http://arxiv.org/pdf/2505.11976v1>|提出了一种基于计算机视觉的P&ID数字化方法，通过合并线段实现设备连接，提高信息处理效率。|
|📝 更新|Adaptive Extrapolated Proximal Gradient Methods with Variance Reduction for Composite Nonconvex Finite-Sum Minimization|自适应扩展近端梯度方法及其在复合非凸有限和最小化中的方差缩减|Ganzhao Yuan|<http://arxiv.org/pdf/2502.21099v2>|提出了一种自适应扩展近端梯度方法AEPG-SPIDER，有效降低复合非凸有限和函数最小化问题的方差，...|
|📝 更新|Robustness-Reinforced Knowledge Distillation with Correlation Distance and Network Pruning|鲁棒性增强的知识蒸馏：基于相关距离和网络剪枝|Seonghak Kim, Gyeongdo Ham, Yucheol Cho, Daeshik Kim|<http://arxiv.org/pdf/2311.13934v2>|提出了一种结合相关距离和网络剪枝的鲁棒知识蒸馏方法，有效提升了学生模型的性能。|
|📝 更新|Geometric Framework for Cell Oversegmentation|细胞超分割的几何框架|Peter Chen, Bryan Chang, Olivia Annette Creasey, Julie Beth Sneddon, Zev Gartner, Yining Liu|<http://arxiv.org/pdf/2502.01890v2>|提出了一种几何框架解决3D细胞分割过度分割问题，通过Geo-Wasserstein度量改进分割质量。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-modal Collaborative Optimization and Expansion Network for Event-assisted Single-eye Expression Recognition|多模态协同优化与扩展网络在辅助单眼表情识别中的应用|Runduo Han, Xiuping Liu, Shangxuan Yi, Yi Zhang, Hongchen Tan|<http://arxiv.org/pdf/2505.12007v1>|提出MCO-E Net，通过多模态协作优化和扩展网络，有效提升单眼表情识别在低光照条件下的准确性。|
|🆕 发布|Parameter Efficient Continual Learning with Dynamic Low-Rank Adaptation|参数高效的动态低秩自适应持续学习|Prashant Shivaram Bhat, Shakib Yazdani, Elahe Arani, Bahram Zonooz|<http://arxiv.org/pdf/2505.11998v1>|提出了一种动态低秩自适应的参数高效持续学习方法，有效解决灾难性遗忘问题。|
|🆕 发布|MINGLE: Mixtures of Null-Space Gated Low-Rank Experts for Test-Time Continual Model Merging|MINGLE：测试时持续模型合并的零空间门控低秩专家混合|Zihuan Qiu, Yi Xu, Chiyuan He, Fanman Meng, Linfeng Xu, Qingbo Wu, Hongliang Li|<http://arxiv.org/pdf/2505.11883v1>|MINGLE通过混合低秩专家和空间约束门控，有效解决持续学习中的参数干扰和适应性不足问题。|
|🆕 发布|Revisiting Residual Connections: Orthogonal Updates for Stable and Efficient Deep Networks|重新审视残差连接：稳定高效的深度网络正交更新|Giyeong Oh, Woohyun Cho, Siyeol Kim, Suhwan Choi, Younjae Yu|<http://arxiv.org/pdf/2505.11881v1>|引入正交残差更新策略，提升深度网络特征学习和训练效率。|
|🆕 发布|UniMoCo: Unified Modality Completion for Robust Multi-Modal Embeddings|统一模态补全：用于鲁棒多模态嵌入的统一方法|Jiajun Qin, Yuan Pu, Zhuolun He, Seunggeun Kim, David Z. Pan, Bei Yu|<http://arxiv.org/pdf/2505.11815v1>|[代码](https://github.com/HobbitQia/UniMoCo.); UniMoCo通过模态补全和统一嵌入空间，提升了多模态嵌入任务的鲁棒性。|
|📝 更新|Exploring the Potential of Encoder-free Architectures in 3D LMMs|探索无编码器架构在3D LMMs中的潜力|Yiwen Tang, Zoey Guo, Zhuhao Wang, Ray Zhang, Qizhi Chen, Junli Liu, Delin Qu, Zhigang Wang .etc.|<http://arxiv.org/pdf/2502.09620v2>|[代码](https://github.com/Ivan-Tang-3D/ENEL); 提出无编码器架构，解决3D LMMs适应性和语义需求问题，显著提升3D理解性能。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AUTO: Adaptive Outlier Optimization for Test-Time OOD Detection|自适应异常优化用于测试时异常检测|Puning Yang, Jian Liang, Jie Cao, Ran He|<http://arxiv.org/pdf/2303.12267v2>|提出自适应异常优化方法，显著提升测试时异常检测性能。|
|🆕 发布|Continuous Subspace Optimization for Continual Learning|持续学习中的连续子空间优化|Quan Cheng, Yuanyu Wan, Lingyu Wu, Chenping Hou, Lijun Zhang|<http://arxiv.org/pdf/2505.11816v1>|提出CoSO方法，通过动态调整子空间优化模型，有效缓解了持续学习中的灾难性遗忘问题。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Black-box Adversaries from Latent Space: Unnoticeable Attacks on Human Pose and Shape Estimation|黑盒对抗攻击：对人类姿态和形状估计的无察觉攻击|Zhiying Li, Guanggang Geng, Yeying Jin, Zhizhi Guo, Bruce Gu, Jidong Huo, Zhaoxin Fan, Wenjun Wu|<http://arxiv.org/pdf/2505.12009v1>|提出了一种无需内部知识的不可见黑盒攻击方法，显著提升了人体姿态和形状估计模型的攻击效果。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Adversarial Attacks on Both Face Recognition and Face Anti-spoofing Models|对抗攻击针对人脸识别和人脸反欺骗模型|Fengfan Zhou, Qianyu Zhou, Hefei Ling, Xuequan Lu|<http://arxiv.org/pdf/2405.16940v2>|提出了一种同时攻击人脸识别和防伪模型的新方法，显著提升了对抗攻击的实用性。|
|🆕 发布|Adversarial Robustness for Unified Multi-Modal Encoders via Efficient Calibration|对抗鲁棒性：通过高效校准实现统一多模态编码器的鲁棒性|Chih-Ting Liao, Bin Ren, Guofeng Mei, Xu Zheng|<http://arxiv.org/pdf/2505.11895v1>|提出了一种高效校准框架，提升统一多模态编码器对抗鲁棒性，同时保持零样本和检索性能。|
|🆕 发布|Facial Recognition Leveraging Generative Adversarial Networks|基于生成对抗网络的 facial recognition|Zhongwen Li, Zongwei Li, Xiaoqi Li|<http://arxiv.org/pdf/2505.11884v1>|提出一种基于GAN的数据增强方法，显著提升人脸识别准确率。|
|📝 更新|Adversarial Attacks of Vision Tasks in the Past 10 Years: A Survey|过去十年视觉任务中的对抗攻击：综述|Chiyu Zhang, Lu Zhou, Xiaogang Xu, Jiafei Wu, Zhe Liu|<http://arxiv.org/pdf/2410.23687v2>|总结了过去十年视觉任务中的对抗攻击，并提出了统一分析框架和未来研究方向。|
|🆕 发布|CL-BioGAN: Biologically-Inspired Cross-Domain Continual Learning for Hyperspectral Anomaly Detection|CL-BioGAN：基于生物启发的跨域持续学习用于高光谱异常检测|Jianing Wang, Zheng Hua, Wan Zhang, Shengjia Hao, Yuqiong Yao, Maoguo Gong|<http://arxiv.org/pdf/2505.11796v1>|提出CL-BioGAN，通过生物灵感持续学习，增强跨域高光谱异常检测的鲁棒性和准确性。|
|🆕 发布|CL-CaGAN: Capsule differential adversarial continuous learning for cross-domain hyperspectral anomaly detection|CL-CaGAN：跨域高光谱异常检测的胶囊差分对抗连续学习|Jianing Wang, Siying Guo, Zheng Hua, Runhu Huang, Jinyu Hu, Maoguo Gong|<http://arxiv.org/pdf/2505.11793v1>|提出CL-CaGAN，通过胶囊网络和持续学习策略，有效提升跨域高光谱异常检测性能。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Dataset Distillation with Probabilistic Latent Features|基于概率潜在特征的_dataset蒸馏|Zhe Li, Sarah Cechnicka, Cheng Ouyang, Katharina Breininger, Peter Schüffler, Bernhard Kainz|<http://arxiv.org/pdf/2505.06647v2>|提出了一种基于概率潜在特征的合成数据生成方法，有效降低数据集蒸馏的计算成本。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Latent Action Learning Requires Supervision in the Presence of Distractors|潜在动作学习在存在干扰因素时需要监督|Alexander Nikulin, Ilya Zisman, Denis Tarasov, Nikita Lyubaykin, Andrei Polubarov, Igor Kiselev, Vladislav Kurenkov|<http://arxiv.org/pdf/2502.00379v3>|在存在干扰因素的情况下，提出了一种改进的潜在动作学习模型，通过少量监督显著提升了下游性能。|
|🆕 发布|Multimodal Cancer Survival Analysis via Hypergraph Learning with Cross-Modality Rebalance|多模态癌症生存分析：基于跨模态平衡的超图学习|Mingcheng Qu, Guang Yang, Donglin, Tonghua Su, Yue Gao, Yang Song, Lei Fan|<http://arxiv.org/pdf/2505.11997v1>|提出一种融合超图学习和跨模态平衡的癌症生存分析框架，有效缓解病理-基因组数据不平衡问题。|
|📝 更新|Dual-level Fuzzy Learning with Patch Guidance for Image Ordinal Regression|双级模糊学习结合补丁引导的图像序数回归|Chunlai Dong, Haochao Ying, Qibo Qiu, Jinhong Wang, Danny Chen, Jian Wu|<http://arxiv.org/pdf/2505.05834v2>|[代码](https://github.com/ZJUMAI/DFPG-ord.); 提出DFPG框架，通过模糊学习与图像块指导，从模糊的有序标签中学习精确的分级边界，提升图像有序回归性...|
|🆕 发布|Joint Manifold Learning and Optimal Transport for Dynamic Imaging|联合流形学习和最优传输动态成像|Sven Dummer, Puru Vaish, Christoph Brune|<http://arxiv.org/pdf/2505.11913v1>|提出了一种结合流形学习和最优传输的动态成像方法，有效解决数据稀缺问题。|
|📝 更新|DeepFRC: An End-to-End Deep Learning Model for Functional Registration and Classification|深度FRC：一种用于功能配准和分类的端到端深度学习模型|Siyuan Jiang, Yihan Hu, Wenjie Li, Pengcheng Zeng|<http://arxiv.org/pdf/2501.18116v2>|[代码](https://github.com/Drivergo-93589/DeepFRC.); 提出DeepFRC模型，实现功能数据的联合对齐与分类，提升分析准确性和可解释性。|
|🆕 发布|Experimental Study on Automatically Assembling Custom Catering Packages With a 3-DOF Delta Robot Using Deep Learning Methods|基于深度学习方法的3自由度Delta机器人自动组装定制餐饮包装的实验研究|Reihaneh Yourdkhani, Arash Tavoosian, Navid Asadi Khomami, Mehdi Tale Masouleh|<http://arxiv.org/pdf/2505.11879v1>|利用深度学习实现3-DOF Delta机器人自动组装定制餐饮包装，提高了包装自动化效率。|
|📝 更新|PrePrompt: Predictive prompting for class incremental learning|预测提示：类增量学习的预测提示|Libo Huang, Zhulin An, Chuanguang Yang, Boyu Diao, Fei Wang, Yan Zeng, Zhifeng Hao, Yongjun Xu|<http://arxiv.org/pdf/2505.08586v2>|[代码](https://github.com/libo-huang/preprompt); PrePrompt通过预测特定任务提示，有效解决了增量学习中的特征空间拟合难题。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AoP-SAM: Automation of Prompts for Efficient Segmentation|AoP-SAM：高效分割的提示自动化|Yi Chen, Mu-Young Son, Chuanbo Hua, Joo-Young Kim|<http://arxiv.org/pdf/2505.11980v1>|提出AoP-SAM，自动生成SAM分割提示，提高其效率和实用性。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|iSegMan: Interactive Segment-and-Manipulate 3D Gaussians|iSegMan：交互式分割与操纵3D高斯分布|Yian Zhao, Wanshi Xu, Ruochong Zheng, Pengchong Qiao, Chang Liu, Jie Chen|<http://arxiv.org/pdf/2505.11934v1>|[代码](https://zhao-yian.github.io/iSegMan.); iSegMan通过交互式分割和操纵3D高斯，实现了高效且可靠的场景操控。|
|🆕 发布|GLOVER++: Unleashing the Potential of Affordance Learning from Human Behaviors for Robotic Manipulation|GLOVER++：从人类行为中释放 affordance 学习潜力以用于机器人操作|Teli Ma, Jia Zheng, Zifan Wang, Ziyao Gao, Jiaming Zhou, Junwei Liang|<http://arxiv.org/pdf/2505.11865v1>|提出HOVA-500K数据集和GLOVER++框架，从人类行为中学习可操作属性，提升机器人操作能力。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VisionReasoner: Unified Visual Perception and Reasoning via Reinforcement Learning|视觉推理器：通过强化学习实现统一的视觉感知与推理|Yuqi Liu, Tianyuan Qu, Zhisheng Zhong, Bohao Peng, Shu Liu, Bei Yu, Jiaya Jia|<http://arxiv.org/pdf/2505.12081v1>|VisionReasoner通过强化学习实现视觉感知与推理的统一，提升多任务处理能力。|
|📝 更新|Logic-in-Frames: Dynamic Keyframe Search via Visual Semantic-Logical Verification for Long Video Understanding|逻辑帧：通过视觉语义-逻辑验证的动态关键帧搜索，用于长视频理解|Weiyu Guo, Ziyang Chen, Shaoguang Wang, Jianxiang He, Yijie Xu, Jinhui Ye, Ying Sun, Hui Xiong|<http://arxiv.org/pdf/2503.13139v2>|提出了一种基于视觉语义逻辑验证的动态关键帧搜索框架，有效解决了长视频理解中的逻辑关系问题。|
|🆕 发布|IQBench: How "Smart'' Are Vision-Language Models? A Study with Human IQ Tests|IQBench：视觉-语言模型“智能”如何？一项人类智商测试研究|Tan-Hanh Pham, Phu-Vinh Nguyen, Dang The Hung, Bui Trong Duong, Vu Nguyen Thanh, Chris Ngo, Tri Quang Truong, Truong-Son Hy|<http://arxiv.org/pdf/2505.12000v1>|设计IQBench基准，评估视觉语言模型在标准化视觉智力测试中的推理能力。|
|🆕 发布|Top-Down Compression: Revisit Efficient Vision Token Projection for Visual Instruction Tuning|自上而下压缩：重新审视高效视觉令牌投影以实现视觉指令微调|Bonan li, Zicheng Zhang, Songhua Liu, Weihao Yu, Xinchao Wang|<http://arxiv.org/pdf/2505.11945v1>|提出LLaVA-Meteor，通过Top-Down压缩策略高效降低视觉指令微调中的视觉标记数量，提升...|
|🆕 发布|Are Multimodal Large Language Models Ready for Omnidirectional Spatial Reasoning?|多模态大型语言模型准备好进行全向空间推理了吗？|Zihao Dongfang, Xu Zheng, Ziqiao Weng, Yuanhuiyi Lyu, Danda Pani Paudel, Luc Van Gool, Kailun Yang, Xuming Hu|<http://arxiv.org/pdf/2505.11907v1>|该论文提出OSR-Bench基准，评估MLLM在全景场景中的空间推理能力，发现当前模型在此方面存在挑...|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VLSBench: Unveiling Visual Leakage in Multimodal Safety|VLSBench：揭示多模态安全中的视觉泄露|Xuhao Hu, Dongrui Liu, Hao Li, Xuanjing Huang, Jing Shao|<http://arxiv.org/pdf/2411.19939v3>|[代码](https://github.com/AI45Lab/VLSBench); 构建了无视觉泄露的多模态安全基准VLSBench，揭示了文本对齐在多模态安全评估中的局限性。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TinyRS-R1: Compact Multimodal Language Model for Remote Sensing|TinyRS-R1：用于遥感的高效多模态语言模型|Aybora Koksal, A. Aydin Alatan|<http://arxiv.org/pdf/2505.12099v1>|提出TinyRS-R1，首个针对遥感任务的2B参数多模态小语言模型，显著提升性能同时降低资源需求。|
|📝 更新|RS-Agent: Automating Remote Sensing Tasks through Intelligent Agent|RS-Agent：通过智能代理自动化遥感任务|Wenjia Xu, Zijian Yu, Boyang Mu, Zhiwei Wei, Yuanben Zhang, Guangzuo Li, Mugen Peng|<http://arxiv.org/pdf/2406.07089v2>|RS-Agent通过集成多组件和新型机制，实现了智能自动化远程传感任务。|
|📝 更新|JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust Multi-Teacher Knowledge Distillation Framework|JL1-CD：遥感变化检测的新基准与鲁棒的多教师知识蒸馏框架|Ziyuan Liu, Ruifei Zhu, Long Gao, Yuanxiu Zhou, Jingyu Ma, Yuantao Gu|<http://arxiv.org/pdf/2502.13407v3>|提出JL1-CD数据集和MTKD框架，提升遥感图像变化检测性能。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Beluga Whale Detection from Satellite Imagery with Point Labels|基于点标签的卫星图像中白鲸检测|Yijie Zheng, Jinxuan Yang, Yu Chen, Yaxuan Wang, Yihang Lu, Guoqing Li|<http://arxiv.org/pdf/2505.12066v1>|[代码](http://github.com/voyagerxvoyagerx/beluga-seeker); 利用点标注和SAM模型自动标注卫星图像，提升鲸鱼检测准确率，降低人工标注成本。|
|🆕 发布|Bridging the Inter-Domain Gap through Low-Level Features for Cross-Modal Medical Image Segmentation|通过低级特征弥合跨模态医学图像分割的域间差距|Pengfei Lyu, Pak-Hei Yeung, Xiaosheng Yu, Jing Xia, Jianning Chi, Chengdong Wu, Jagath C. Rajapakse|<http://arxiv.org/pdf/2505.11909v1>|[代码](https://github.com/JoshuaLPF/LowBridge.); 提出了一种基于低级特征的模型无关无监督域自适应框架，显著提升了跨模态医学图像分割性能。|
|🆕 发布|PRS-Med: Position Reasoning Segmentation with Vision-Language Model in Medical Imaging|PRS-Med：基于视觉-语言模型的医学影像位置推理分割|Quoc-Huy Trinh, Minh-Van Nguyen, Jung Peng, Ulas Bagci, Debesh Jha|<http://arxiv.org/pdf/2505.11872v1>|PRS-Med通过融合视觉语言模型和分割能力，实现了医学图像中肿瘤的准确分割和空间关系推理。|
|🆕 发布|MedSG-Bench: A Benchmark for Medical Image Sequences Grounding|医图序列定位基准：MedSG-Bench|Jingkun Yue, Siqi Zhang, Zinan Jia, Huihuan Xu, Zongbo Han, Xiaohong Liu, Guangyu Wang|<http://arxiv.org/pdf/2505.11852v1>|提出MedSG-Bench，首个针对医学图像序列定位的基准，推动多模态大语言模型在医学领域的应用。|
|🆕 发布|MedVKAN: Efficient Feature Extraction with Mamba and KAN for Medical Image Segmentation|MedVKAN：基于Mamba和KAN的医学图像分割高效特征提取|Hancan Zhu, Jinhao Chen, Guanghua He|<http://arxiv.org/pdf/2505.11797v1>|[代码](https://github.com/beginner-cjh/MedVKAN.); 提出MedVKAN，结合Mamba和KAN，有效解决医疗图像分割中的特征提取问题，显著提升分割性能。|
|📝 更新|Dynamic Attention Analysis for Backdoor Detection in Text-to-Image Diffusion Models|动态注意力分析用于文本到图像扩散模型中的后门检测|Zhongqi Wang, Jie Zhang, Shiguang Shan, Xilin Chen|<http://arxiv.org/pdf/2504.20518v2>|[代码](https://github.com/Robin-WZQ/DAA.); 提出动态注意力分析，有效检测文本到图像扩散模型中的后门攻击。|


### 生物特征识别 (Biometric Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FIGhost: Fluorescent Ink-based Stealthy and Flexible Backdoor Attacks on Physical Traffic Sign Recognition|FIGhost：基于荧光墨水的隐蔽和柔性物理交通标志识别后门攻击|Shuai Yuan, Guowen Xu, Hongwei Li, Rui Zhang, Xinyuan Qian, Wenbo Jiang, Hangcheng Cao, Qingchuan Zhao|<http://arxiv.org/pdf/2505.12045v1>|利用荧光墨水实现隐蔽且灵活的物理交通标志识别后门攻击，有效规避现有防御。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Knowledge-Informed Multi-Agent Trajectory Prediction at Signalized Intersections for Infrastructure-to-Everything|基于知识的信号交叉口多智能体轨迹预测：基础设施到万物|Huilin Yin, Yangwenhui Xu, Jiaxiang Li, Hao Zhang, Gerhard Rigoll|<http://arxiv.org/pdf/2501.13461v2>|提出了一种基于基础设施的协同预测方案，显著提升了信号交叉口多智能体轨迹预测的准确性。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MT-CYP-Net: Multi-Task Network for Pixel-Level Crop Yield Prediction Under Very Few Samples|MT-CYP-Net：在极少量样本下的像素级作物产量预测的多任务网络|Shenzhou Liu, Di Wang, Haonan Guo, Chengxi Han, Wenzhi Zeng|<http://arxiv.org/pdf/2505.12069v1>|提出MT-CYP-Net，通过多任务特征共享策略，实现少量样本下的精细像素级作物产量预测。|

