## [UPDATED!] **2025-05-18** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PainFormer: a Vision Foundation Model for Automatic Pain Assessment|痛感前体：用于自动疼痛评估的视觉基础模型|Stefanos Gkikas, Raul Fernandez Rojas, Manolis Tsiknakis|<http://arxiv.org/pdf/2505.01571v2>|提出PainFormer模型，通过多任务学习实现自动疼痛评估，显著提升疼痛评估准确性。|
|📝 更新|Mamba-MOC: A Multicategory Remote Object Counting via State Space Model|曼巴-MOC：基于状态空间模型的多类别远程物体计数|Peng Liu, Sen Lei, Heng-Chao Li|<http://arxiv.org/pdf/2501.06697v2>|提出Mamba-MOC，一种基于Mamba的远程多类别物体计数网络，有效解决全局依赖建模和计算效率问...|
|📝 更新|MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models|多模态自适应与自数据蒸馏用于视觉-语言模型的投机解码|Mugilan Ganesan, Shane Segal, Ankur Aggarwal, Nish Sinnadurai, Sean Lie, Vithursan Thangarasa|<http://arxiv.org/pdf/2505.10526v2>|MASSV通过多模态适应和自数据蒸馏，将小语言模型转化为有效的视觉语言模型草稿生成器，显著加速了视觉...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LR0.FM: Low-Res Benchmark and Improving Robustness for Zero-Shot Classification in Foundation Models|LR0.FM：低分辨率基准与基础模型中零样本分类鲁棒性的提升|Priyank Pathak, Shyam Marjit, Shruti Vyas, Yogesh S Rawat|<http://arxiv.org/pdf/2502.03950v3>|[代码](https://github.com/shyammarjit/LR0.FM); LR0.FM构建低分辨率基准，提出LR-TK0策略提升基础模型零样本分类对低分辨率图像的鲁棒性。|
|📝 更新|Bridge the Modality and Capability Gaps in Vision-Language Model Selection|跨越视觉-语言模型选择中的模态和能力差距|Chao Yi, Yu-Hang He, De-Chuan Zhan, Han-Jia Ye|<http://arxiv.org/pdf/2403.13797v3>|提出SWAB方法，通过桥接模态和能力差距，实现无需图像数据的视觉语言模型选择。|
|🆕 发布|DragLoRA: Online Optimization of LoRA Adapters for Drag-based Image Editing in Diffusion Model|DragLoRA：基于拖动图像编辑的扩散模型中LoRA适配器的在线优化|Siwei Xia, Li Sun, Tiantian Sun, Qingli Li|<http://arxiv.org/pdf/2505.12427v1>|[代码](https://github.com/Sylvie-X/DragLoRA.); DragLoRA通过集成LoRA适配器和优化运动监督，显著提升了拖动式图像编辑的精度和效率。|
|📝 更新|Orthogonal Subspace Decomposition for Generalizable AI-Generated Image Detection|正交子空间分解用于泛化AI生成图像检测|Zhiyuan Yan, Jiangming Wang, Peng Jin, Ke-Yue Zhang, Chengchun Liu, Shen Chen, Taiping Yao, Shouhong Ding .etc.|<http://arxiv.org/pdf/2411.15633v3>|[代码](https://github.com/YZY-stack/Effort-AIGI-Detection); 通过正交子空间分解，该论文提出了一种增强AI生成图像检测泛化能力的方法，有效缓解了模型对伪造图像的过...|
|📝 更新|ForestSplats: Deformable transient field for Gaussian Splatting in the Wild|森林滴溅：野外的可变形瞬态场高斯滴溅|Wongi Park, Myeongseok Nam, Siwon Kim, Sangwoo Jo, Soomok Lee|<http://arxiv.org/pdf/2503.06179v2>|ForestSplats通过可变形场和超像素掩码高效表示动态元素，有效分解静态场景，无需VFM。|
|🆕 发布|LogicOCR: Do Your Large Multimodal Models Excel at Logical Reasoning on Text-Rich Images?|逻辑OCR：你的大型多模态模型在富含文本的图像上的逻辑推理能力如何？|Maoyuan Ye, Jing Zhang, Juhua Liu, Bo Du, Dacheng Tao|<http://arxiv.org/pdf/2505.12307v1>|[代码](https://github.com/MiliLab/LogicOCR.); 构建LogicOCR基准，评估大型多模态模型在文本丰富图像上的逻辑推理能力。|
|🆕 发布|Can Large Multimodal Models Understand Agricultural Scenes? Benchmarking with AgroMind|《大型多模态模型能否理解农业场景？以AgroMind为基准的评估》|Qingmei Li, Yang Zhang, Zurong Mai, Yuhang Chen, Shuohong Lou, Henglian Huang, Jiarui Zhang, Zhiwei Zhang .etc.|<http://arxiv.org/pdf/2505.12207v1>|[代码](https://rssysu.github.io/AgroMind); 构建了AgroMind基准，评估大型多模态模型在农业遥感领域的理解能力，揭示了其局限性。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|UniCMs: A Unified Consistency Model For Efficient Multimodal Generation and Understanding|统一一致性模型：高效多模态生成与理解|Chenkai Xu, Xu Wang, Zhenyi Liao, Yishun Li, Tianqi Hou, Zhijie Deng|<http://arxiv.org/pdf/2502.05415v2>|[代码](https://github.com/zhijie-group/UniCMs.); 提出了一种统一的多模态生成与理解一致性模型，显著提升了生成效率和速度。|
|🆕 发布|MMS-VPR: Multimodal Street-Level Visual Place Recognition Dataset and Benchmark|多模态街景视觉位置识别数据集和基准：MMS-VPR|Yiwei Ou, Xiaobin Ren, Ronggui Sun, Guansong Gao, Ziyi Jiang, Kaiqi Zhao, Manfredo Manfredini|<http://arxiv.org/pdf/2505.12254v1>|构建了大规模多模态街景视觉地点识别数据集，提升复杂环境下的地点识别性能。|
|🆕 发布|PRETI: Patient-Aware Retinal Foundation Model via Metadata-Guided Representation Learning|患者感知视网膜基础模型：通过元数据引导的表示学习|Yeonkyung Lee, Woojung Han, Youngjun Jun, Hyeonmin Kim, Jungkyung Cho, Seong Jae Hwang|<http://arxiv.org/pdf/2505.12233v1>|[代码](https://github.com/MICV-yonsei/PRETI); 提出PRETI模型，通过元数据引导的表示学习，有效结合患者信息，提升视网膜疾病分析性能。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spectral-Spatial Self-Supervised Learning for Few-Shot Hyperspectral Image Classification|光谱-空间自监督学习在少样本高光谱图像分类中的应用|Wenchen Chen, Yanmei Zhang, Zhongwei Xiao, Jianping Chu, Xingbo Wang|<http://arxiv.org/pdf/2505.12482v1>|提出了一种结合光谱-空间自监督学习和少样本学习的超光谱图像分类方法，有效提升了分类性能。|
|🆕 发布|SRLoRA: Subspace Recomposition in Low-Rank Adaptation via Importance-Based Fusion and Reinitialization|SRLoRA：基于重要性融合和重初始化的低秩自适应子空间重组|Haodong Yang, Lei Wang, Md Zakir Hossain|<http://arxiv.org/pdf/2505.12433v1>|SRLoRA通过重要性融合和重新初始化，扩展了LoRA的表达能力，提升了模型性能。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Bootstraping Clustering of Gaussians for View-consistent 3D Scene Understanding|自举高斯聚类以实现视一致性3D场景理解|Wenbo Zhang, Lu Zhang, Ping Hu, Liqian Ma, Yunzhi Zhuge, Huchuan Lu|<http://arxiv.org/pdf/2411.19551v2>|[代码](https://github.com/wb014/FreeGS.); 提出了一种无需2D标签的FreeGS框架，通过引入IDSF实现3D场景的视图一致性理解。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Attention-Enhanced U-Net for Accurate Segmentation of COVID-19 Infected Lung Regions in CT Scans|基于注意力增强的U-Net在CT扫描中准确分割COVID-19感染肺区域的网络|Amal Lahchim, Lazar Davic|<http://arxiv.org/pdf/2505.12298v1>|提出了一种基于注意力增强U-Net的COVID-19肺部感染区域自动分割方法，显著提升了分割精度。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Refinement Module based on Parse Graph of Feature Map for Human Pose Estimation|基于特征图解析图的精炼模块用于人体姿态估计|Shibang Liu, Xuemei Xie, Guangming Shi|<http://arxiv.org/pdf/2501.11069v5>|设计了一种基于特征图解析图的优化模块，提升了人体姿态估计的准确性和适应性。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SOAP: Style-Omniscient Animatable Portraits|SOAP：风格全知可动画肖像|Tingting Liao, Yujian Zheng, Adilbek Karmanov, Liwen Hu, Leyang Jin, Yuliang Xiu, Hao Li|<http://arxiv.org/pdf/2505.05022v2>|[代码](https://github.com/TingtingLiao/soap.); SOAP提出了一种风格通用的3D头像生成方法，可从单张图像创建可动画的、拓扑一致的3D头像。|
|🆕 发布|Exploring Sparsity for Parameter Efficient Fine Tuning Using Wavelets|探索小波变换在参数高效微调中的稀疏性|Ahmet Bilican, M. Akın Yılmaz, A. Murat Tekalp, R. Gökberk Cinbiş|<http://arxiv.org/pdf/2505.12532v1>|提出Wavelet Fine-Tuning方法，通过小波域稀疏更新实现参数高效微调，显著提升低参数场...|
|📝 更新|Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset|数字孪生目录：一个大规模逼真3D对象数字孪生数据集|Zhao Dong, Ka Chen, Zhaoyang Lv, Hong-Xing Yu, Yunzhi Zhang, Cheng Zhang, Yufeng Zhu, Stephen Tian .etc.|<http://arxiv.org/pdf/2504.08541v2>|构建了首个大规模、高保真3D物体数字孪生数据集，推动3D重建方法比较与优化。|
|📝 更新|DynamiCtrl: Rethinking the Basic Structure and the Role of Text for High-quality Human Image Animation|DynamiCtrl：重新思考高质量人像动画的基本结构和文本角色|Haoyu Zhao, Zhongang Qi, Cong Wang, Qingping Zheng, Guansong Lu, Fei Chen, Hang Xu, Zuxuan Wu|<http://arxiv.org/pdf/2503.21246v2>|[代码](https://gulucaptain.github.io/DynamiCtrl); 提出DynamiCtrl框架，通过联合文本和姿态控制，显著提升视频人像动画质量。|
|🆕 发布|Joint Embedding vs Reconstruction: Provable Benefits of Latent Space Prediction for Self Supervised Learning|联合嵌入与重建：潜在空间预测对自监督学习的可证明优势|Hugues Van Assel, Mark Ibrahim, Tommaso Biancalani, Aviv Regev, Randall Balestriero|<http://arxiv.org/pdf/2505.12477v1>|揭示了自监督学习两种范式（重建与联合嵌入）的内在机制，证明了联合嵌入在处理无关特征时更具优势。|
|📝 更新|Going Beyond Feature Similarity: Effective Dataset Distillation based on Class-Aware Conditional Mutual Information|超越特征相似性：基于类感知条件互信息的有效数据集蒸馏|Xinhao Zhong, Bin Chen, Hao Fang, Xulin Gu, Shu-Tao Xia, En-Hui Yang|<http://arxiv.org/pdf/2412.09945v4>|提出一种基于条件互信息的类感知数据蒸馏方法，有效提升训练效率和性能。|
|🆕 发布|Is Artificial Intelligence Generated Image Detection a Solved Problem?|人工智能生成图像检测是否已解决？|Ziqiang Li, Jiazhen Yan, Ziwen He, Kai Zeng, Weiwei Jiang, Lizhi Xiong, Zhangjie Fu|<http://arxiv.org/pdf/2505.12335v1>|提出AIGIBench基准，评估AIGI检测器在实际场景中的鲁棒性和泛化能力。|
|🆕 发布|Model alignment using inter-modal bridges|基于跨模态桥梁的模型对齐|Ali Gholamzadeh, Noor Sajid|<http://arxiv.org/pdf/2505.12322v1>|提出了一种半监督方法，通过条件流匹配实现跨模态模型对齐，有效提高数据稀缺情况下的模型性能。|
|🆕 发布|VoiceCloak: A Multi-Dimensional Defense Framework against Unauthorized Diffusion-based Voice Cloning|《VoiceCloak：针对未经授权的基于扩散的语音克隆的多维防御框架》|Qianyue Hu, Junyan Wu, Wei Lu, Xiangyang Luo|<http://arxiv.org/pdf/2505.12332v1>|[代码](https://voice-cloak.github.io/VoiceCloak); VoiceCloak通过引入对抗性扰动和噪声引导语义破坏，有效防御基于扩散模型的非法语音克隆。|
|📝 更新|REArtGS: Reconstructing and Generating Articulated Objects via 3D Gaussian Splatting with Geometric and Motion Constraints|REArtGS：基于3D高斯分层与几何运动约束的关节对象重建与生成|Di Wu, Liu Liu, Zhou Linli, Anran Huang, Liangtu Song, Qiaojun Yu, Qi Wu, Cewu Lu|<http://arxiv.org/pdf/2503.06677v3>|提出REArtGS框架，通过引入几何和运动约束，实现关节物体的高保真纹理表面重建和生成。|
|🆕 发布|Context-Aware Autoregressive Models for Multi-Conditional Image Generation|基于上下文的自回归模型用于多条件图像生成|Yixiao Chen, Zhiyuan Ma, Guoli Jia, Che Jiang, Jianjun Li, Bowen Zhou|<http://arxiv.org/pdf/2505.12274v1>|[代码](https://context-ar.github.io/.); 提出ContextAR模型，通过融合多种条件信息实现高效的多条件图像生成。|
|📝 更新|TexPro: Text-guided PBR Texturing with Procedural Material Modeling|文本引导的PBR纹理与过程式材质建模：TexPro|Ziqiang Dang, Wenqi Dong, Zesong Yang, Bangbang Yang, Liang Li, Yuewen Ma, Zhaopeng Cui|<http://arxiv.org/pdf/2410.15891v2>|提出了一种基于文本提示生成高保真材质的新方法，通过程序化材质建模实现物理渲染和重光照。|
|📝 更新|Towards Enhanced Image Inpainting: Mitigating Unwanted Object Insertion and Preserving Color Consistency|迈向增强图像修复：减轻不希望的对象插入并保持色彩一致性|Yikai Wang, Chenjie Cao, Junqiu Yu, Ke Fan, Xiangyang Xue, Yanwei Fu|<http://arxiv.org/pdf/2312.04831v3>|提出ASUKA方法，通过后处理缓解图像修复中的物体插入和色彩不一致问题。|
|📝 更新|This&That: Language-Gesture Controlled Video Generation for Robot Planning|这是那：基于语言手势控制的机器人规划视频生成|Boyang Wang, Nikhil Sridhar, Chao Feng, Mark Van der Merwe, Adam Fishman, Nima Fazeli, Jeong Joon Park|<http://arxiv.org/pdf/2407.05530v2>|提出This&That框架，通过语言和手势控制视频生成，实现机器人复杂任务规划。|
|🆕 发布|CompBench: Benchmarking Complex Instruction-guided Image Editing|CompBench：复杂指令引导的图像编辑基准测试|Bohan Jia, Wenxuan Huang, Yuntian Tang, Junbo Qiao, Jincheng Liao, Shaosheng Cao, Fei Zhao, Zhaopeng Feng .etc.|<http://arxiv.org/pdf/2505.12200v1>|构建了CompBench基准，通过复杂指令引导图像编辑，评估模型精确操控能力。|
|🆕 发布|Always Clear Depth: Robust Monocular Depth Estimation under Adverse Weather|始终清晰深度：恶劣天气下的鲁棒单目深度估计|Kui Jiang, Jing Cao, Zhaocheng Yu, Junjun Jiang, Jingchun Zhou|<http://arxiv.org/pdf/2505.12199v1>|提出ACDepth方法，通过生成模拟恶劣天气的样本和知识蒸馏策略，实现恶劣天气下鲁棒的深度估计。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Selftok: Discrete Visual Tokens of Autoregression, by Diffusion, and for Reasoning|自回归扩散推理的离散视觉标记：Selftok|Bohan Wang, Zhongqi Yue, Fengda Zhang, Shuo Chen, Li'an Bi, Junzhe Zhang, Xue Song, Kennard Yanting Chan .etc.|<http://arxiv.org/pdf/2505.07538v2>|[代码](https://selftok-team.github.io/report); 提出Selftok，一种基于自回归先验的离散视觉标记器，有效支持视觉生成中的强化学习。|
|📝 更新|Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models|深度压缩自编码器用于高效的高分辨率扩散模型|Junyu Chen, Han Cai, Junsong Chen, Enze Xie, Shang Yang, Haotian Tang, Muyang Li, Yao Lu .etc.|<http://arxiv.org/pdf/2410.10733v8>|[代码](https://github.com/mit-han-lab/efficientvit.); 提出深度压缩自动编码器，有效提升高分辨率扩散模型压缩比和重建质量。|
|🆕 发布|Guiding Diffusion with Deep Geometric Moments: Balancing Fidelity and Variation|引导扩散的深度几何矩：平衡保真度和变异性|Sangmin Jung, Utkarsh Nath, Yezhou Yang, Giulia Pedrielli, Joydeep Biswas, Amy Zhang, Hassan Ghasemzadeh, Pavan Turaga|<http://arxiv.org/pdf/2505.12486v1>|引入深度几何矩作为引导，平衡了扩散模型图像生成的精细度和多样性。|
|🆕 发布|Video-GPT via Next Clip Diffusion|视频GPT：通过下一帧扩散|Shaobin Zhuang, Zhipeng Huang, Ying Zhang, Fangyikang Wang, Canmiao Fu, Binxin Yang, Chong Sun, Chen Li .etc.|<http://arxiv.org/pdf/2505.12489v1>|提出Video-GPT，通过视频序列建模视觉世界，实现视频预测和理解的突破。|
|📝 更新|Progressive Autoregressive Video Diffusion Models|渐进式自回归视频扩散模型|Desai Xie, Zhan Xu, Yicong Hong, Hao Tan, Difan Liu, Feng Liu, Arie Kaufman, Yang Zhou|<http://arxiv.org/pdf/2410.08151v2>|[代码](https://desaixie.github.io/pa-vdm); 提出了一种基于渐进噪声级和分步去噪的自动回归视频生成方法，显著提升了长视频生成质量。|
|📝 更新|Long-Context Autoregressive Video Modeling with Next-Frame Prediction|长上下文自回归视频建模与下一帧预测|Yuchao Gu, Weijia Mao, Mike Zheng Shou|<http://arxiv.org/pdf/2503.19325v3>|提出了一种基于不对称核的长期短时上下文建模方法，有效降低了长视频训练成本，显著提升了视频生成效果。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FreqSelect: Frequency-Aware fMRI-to-Image Reconstruction|FreqSelect：频率感知的fMRI到图像重建|Junliang Ye, Lei Wang, Md Zakir Hossain|<http://arxiv.org/pdf/2505.12552v1>|FreqSelect通过自适应选择频率带，提高了从fMRI数据重建自然图像的质量，并揭示了大脑中不同...|
|📝 更新|WMCopier: Forging Invisible Image Watermarks on Arbitrary Images|WMCopier：在任意图像上锻造隐形图像水印|Ziping Dong, Chao Shuai, Zhongjie Ba, Peng Cheng, Zhan Qin, Qinglong Wang, Kui Ren|<http://arxiv.org/pdf/2503.22330v2>|WMCopier提出了一种无需先验知识的图像水印伪造攻击方法，有效欺骗了开源和闭源水印系统。|
|🆕 发布|Mitigating Hallucinations via Inter-Layer Consistency Aggregation in Large Vision-Language Models|通过层间一致性聚合减轻大型视觉-语言模型中的幻觉|Kai Tang, Jinhao You, Xiuqi Ge, Hanze Li, Yichen Guo, Xiande Huang|<http://arxiv.org/pdf/2505.12343v1>|提出DCLA方法，通过层间一致性聚合减轻大型视觉语言模型中的幻觉问题。|
|🆕 发布|NOFT: Test-Time Noise Finetune via Information Bottleneck for Highly Correlated Asset Creation|NOFT：通过信息瓶颈进行测试时噪声微调，以实现高度相关资产的高效创建|Jia Li, Nan Gao, Huaibo Huang, Ran He|<http://arxiv.org/pdf/2505.12235v1>|提出NOFT模块，通过信息瓶颈优化噪声微调，实现高度相关且多样化的图像生成。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Open-world Generalized Deepfake Detection: General Feature Extraction via Unsupervised Domain Adaptation|面向开放世界泛化深度伪造检测：通过无监督领域自适应的通用特征提取|Midou Guo, Qilin Yin, Wei Lu, Xiangyang Luo|<http://arxiv.org/pdf/2505.12339v1>|提出了一种基于无监督域适应的通用深度伪造检测方法，有效提升模型泛化能力。|
|🆕 发布|LLaVA-4D: Embedding SpatioTemporal Prompt into LMMs for 4D Scene Understanding|LLaVA-4D：将时空提示嵌入到LMMs中进行4D场景理解|Hanyu Zhou, Gim Hee Lee|<http://arxiv.org/pdf/2505.12253v1>|LLaVA-4D通过引入时空提示，增强了LMM在4D场景理解中的动态物体识别能力。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VGGT-SLAM: Dense RGB SLAM Optimized on the SL(4) Manifold|VGGT-SLAM：基于SL(4)流形优化的密集RGB SLAM|Dominic Maggio, Hyungtae Lim, Luca Carlone|<http://arxiv.org/pdf/2505.12549v1>|VGGT-SLAM通过优化SL(4)流形，解决了无标定相机下RGB SLAM的重建模糊性问题，显著提...|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Irregular Tensor Low-Rank Representation for Hyperspectral Image Representation|不规则张量低秩表示用于高光谱图像表示|Bo Han, Yuheng Jia, Hui Liu, Junhui Hou|<http://arxiv.org/pdf/2410.18388v4>|[代码](https://github.com/hb-studying/ITLRR.); 针对超光谱图像中不规则性，提出了一种新型不规则张量低秩表示模型，有效提升了图像分析性能。|
|📝 更新|See What You Seek: Semantic Contextual Integration for Cloth-Changing Person Re-Identification|《所见即所得：衣物更换人员重识别的语义上下文集成》|Xiyu Han, Xian Zhong, Wenxin Huang, Xuemei Jia, Xiaohan Yu, Alex Chichung Kot|<http://arxiv.org/pdf/2412.01345v2>|[代码](https://github.com/hxy-499/CCREID-SCI.); 提出SCI框架，通过语义上下文整合提升衣物变化下的人体重识别性能。|
|🆕 发布|From Low Field to High Value: Robust Cortical Mapping from Low-Field MRI|从低场到高价值：低场MRI的鲁棒性皮层映射|Karthik Gopinath, Annabel Sorby-Adams, Jonathan W. Ramirez, Dina Zemlyanker, Jennifer Guo, David Hunt, Christine L. Mac Donald, C. Dirk Keene .etc.|<http://arxiv.org/pdf/2505.12228v1>|开发了一种适用于低场MRI的机器学习方法，实现高精度脑皮层表面重建与分析。|
|🆕 发布|From Shots to Stories: LLM-Assisted Video Editing with Unified Language Representations|从镜头到故事：基于统一语言表示的LLM辅助视频编辑|Yuzhi Li, Haojun Xu, Fang Tian|<http://arxiv.org/pdf/2505.12237v1>|提出L-Storyboard和StoryFlow策略，提升LLM在视频编辑中的准确性和逻辑一致性。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Structureless VIO|无结构视觉惯性里程计|Junlin Song, Miguel Olivares-Mendez|<http://arxiv.org/pdf/2505.12337v1>|提出了一种无需地图的结构化视觉里程计，显著提升计算效率和精度。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VideoRFT: Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning|视频RFT：通过强化微调激励多模态大语言模型中的视频推理能力|Qi Wang, Yanrui Yu, Ye Yuan, Rui Mao, Tianfei Zhou|<http://arxiv.org/pdf/2505.12434v1>|提出VideoRFT，通过强化微调提升多模态语言模型在视频推理上的能力。|
|🆕 发布|PMQ-VE: Progressive Multi-Frame Quantization for Video Enhancement|PMQ-VE：视频增强的渐进式多帧量化|ZhanFeng Feng, Long Peng, Xin Di, Yong Guo, Wenbo Li, Yulun Zhang, Renjing Pei, Yang Wang .etc.|<http://arxiv.org/pdf/2505.12266v1>|[代码](https://github.com/xiaoBIGfeng/PMQ-VE.); 提出了一种渐进式多帧量化方法，有效提升视频增强性能并降低计算需求。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PillarTrack:Boosting Pillar Representation for Transformer-based 3D Single Object Tracking on Point Clouds|PillarTrack：增强Transformer在点云上基于柱状表示的3D单目标跟踪|Weisheng Xu, Sifan Zhou, Jiaqi Xiong, Ziyu Zhao, Zhihang Yuan|<http://arxiv.org/pdf/2404.07495v2>|提出PillarTrack，通过柱状体表示和Transformer架构提升点云3D单目标跟踪性能。|
|🆕 发布|DIMM: Decoupled Multi-hierarchy Kalman Filter for 3D Object Tracking|解耦多层级卡尔曼滤波器在3D目标跟踪中的应用|Jirong Zha, Yuxuan Fan, Kai Li, Han Li, Chen Gao, Xinlei Chen, Yong Li|<http://arxiv.org/pdf/2505.12340v1>|提出了一种基于多层级解耦卡尔曼滤波的3D目标跟踪方法，显著提升了跟踪精度。|
|📝 更新|Cognitive Disentanglement for Referring Multi-Object Tracking|认知解耦用于多对象跟踪的指称|Shaofeng Liang, Runwei Guan, Wangwang Lian, Daizong Liu, Xiaolou Sun, Dongming Wu, Yutao Yue, Weiping Ding .etc.|<http://arxiv.org/pdf/2503.11496v3>|提出认知解耦框架，有效融合语言描述与视觉特征，提升多目标跟踪性能。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Rebalancing Contrastive Alignment with Learnable Semantic Gaps in Text-Video Retrieval|文本-视频检索中通过可学习语义差距重新平衡对比对齐|Jian Xiao, Zijie Song, Jialong Hu, Hao Cheng, Zhenzhen Hu, Jia Li, Richang Hong|<http://arxiv.org/pdf/2505.12499v1>|提出GARE框架，通过可学习语义差距缓解文本-视频检索中的模态差距和梯度冲突。|
|📝 更新|PseudoNeg-MAE: Self-Supervised Point Cloud Learning using Conditional Pseudo-Negative Embeddings|伪负样本-MAE：基于条件伪负嵌入的自监督点云学习|Sutharsan Mahendren, Saimunur Rahman, Piotr Koniusz, Tharindu Fernando, Sridha Sridharan, Clinton Fookes, Peyman Moghadam|<http://arxiv.org/pdf/2409.15832v2>|提出PseudoNeg-MAE，通过条件伪负嵌入增强点云自监督学习，解决不变性塌陷问题，提升全局特征...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SSR: Enhancing Depth Perception in Vision-Language Models via Rationale-Guided Spatial Reasoning|SSR：通过理性引导的空间推理增强视觉-语言模型中的深度感知|Yang Liu, Ming Ma, Xiaomin Yu, Pengxiang Ding, Han Zhao, Mingyang Sun, Siteng Huang, Donglin Wang|<http://arxiv.org/pdf/2505.12448v1>|[代码](https://yliu-cs.github.io/SSR.); 提出SSR方法，通过理性引导的空间推理增强视觉语言模型对深度信息的理解和利用。|
|🆕 发布|DPCD: A Quality Assessment Database for Dynamic Point Clouds|动态点云质量评估数据库：DPCD|Yating Liu, Yujie Zhang, Qi Yang, Yiling Xu, Zhu Li, Ye-Kui Wang|<http://arxiv.org/pdf/2505.12431v1>|构建了动态点云质量评估数据库DPCD，推动动态点云质量评估研究。|
|📝 更新|Submillimeter-Accurate 3D Lumbar Spine Reconstruction from Biplanar X-Ray Images: Incorporating a Multi-Task Network and Landmark-Weighted Loss|亚毫米级精确的双平面X射线图像腰椎脊柱三维重建：结合多任务网络和地标加权损失|Wanxin Yu, Zhemin Zhu, Cong Wang, Yihang Bao, Chunjie Xia, Rongshan Cheng, Yan Yu, Tsung-Yuan Tsai|<http://arxiv.org/pdf/2503.14573v2>|开发了一种基于多任务网络和地标加权损失函数的高精度腰椎三维重建方法，显著提升重建精度。|
|🆕 发布|Modeling Aesthetic Preferences in 3D Shapes: A Large-Scale Paired Comparison Study Across Object Categories|3D形状美学偏好的建模：跨对象类别的大规模成对比较研究|Kapil Dev|<http://arxiv.org/pdf/2505.12373v1>|通过大规模人类判断数据，提出了一种基于几何特征的3D形状美学建模方法，揭示了美学偏好的普遍原则和特定...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|STAR: Stage-Wise Attention-Guided Token Reduction for Efficient Large Vision-Language Models Inference|STAR：基于阶段注意力引导的标记减少，用于高效的大视觉语言模型推理|Yichen Guo, Hanze Li, Zonghao Zhang, Jinhao You, Kai Tang, Xiande Huang|<http://arxiv.org/pdf/2505.12359v1>|STAR提出了一种全局视角的注意力引导的token剪枝方法，有效降低大视觉语言模型推理的计算成本。|
|🆕 发布|OpenPros: A Large-Scale Dataset for Limited View Prostate Ultrasound Computed Tomography|OpenPros：有限视角前列腺超声计算机断层扫描的大规模数据集|Hanchen Wang, Yixuan Wu, Yinan Feng, Peng Jin, Shihang Feng, Yiming Mao, James Wiskin, Baris Turkbey .etc.|<http://arxiv.org/pdf/2505.12261v1>|[代码](https://open-pros.github.io/.); 构建了首个大规模有限视角前列腺超声CT数据集，推动深度学习在前列腺超声图像重建中的应用。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Does Vector Quantization Fail in Spatio-Temporal Forecasting? Exploring a Differentiable Sparse Soft-Vector Quantization Approach|向量量化在时空预测中失效了吗？探索可微稀疏软向量量化方法|Chao Chen, Tian Zhou, Yanjun Zhao, Hui Liu, Liang Sun, Rong Jin|<http://arxiv.org/pdf/2312.03406v4>|[代码](https://github.com/Pachark/SVQ-Forecasting.); 提出了一种可微稀疏软向量量化方法，有效提升了时空预测的准确性。|
|🆕 发布|DNOI-4DRO: Deep 4D Radar Odometry with Differentiable Neural-Optimization Iterations|深度4D雷达里程计与可微神经优化迭代|Shouyi Lu, Huanyu Zhou, Guirong Zhuo|<http://arxiv.org/pdf/2505.12310v1>|提出了一种结合深度学习和几何优化的4D雷达里程计模型，显著提升了定位精度。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EasyInv: Toward Fast and Better DDIM Inversion|EasyInv：迈向快速且更好的DDIM反演|Ziyue Zhang, Mingbao Lin, Shuicheng Yan, Rongrong Ji|<http://arxiv.org/pdf/2408.05159v3>|[代码](https://github.com/potato-kitty/EasyInv.); EasyInv通过优化DDIM逆变换，显著提升效率并增强准确性。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Redefining non-IID Data in Federated Learning for Computer Vision Tasks: Migrating from Labels to Embeddings for Task-Specific Data Distributions|重新定义联邦学习中计算机视觉任务的非独立同分布数据：从标签迁移到嵌入以特定任务数据分布|Kasra Borazjani, Payam Abdisarabshali, Naji Khosravan, Seyyedali Hosseinalipour|<http://arxiv.org/pdf/2503.14553v3>|提出了一种基于任务特定数据嵌入的联邦学习方法，有效解决了非独立同分布数据在计算机视觉任务中的挑战。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Improving Out-of-Domain Robustness with Targeted Augmentation in Frequency and Pixel Spaces|基于频率和像素空间的有针对性的增强来提高域外鲁棒性|Ruoqi Wang, Haitao Wang, Shaojie Guo, Qiong Luo|<http://arxiv.org/pdf/2505.12317v1>|提出Frequency-Pixel Connect框架，通过频率和像素空间的有针对性增强，显著提升跨...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GlobalGeoTree: A Multi-Granular Vision-Language Dataset for Global Tree Species Classification|全球GeoTree：一种用于全球树种分类的多粒度视觉-语言数据集|Yang Mu, Zhitong Xiong, Yi Wang, Muhammad Shahzad, Franz Essl, Mark van Kleunen, Xiao Xiang Zhu|<http://arxiv.org/pdf/2505.12513v1>|构建了大规模多粒度视觉语言数据集GlobalGeoTree，显著提升了全球树种分类的零样本和少样本识...|
|🆕 发布|ProMi: An Efficient Prototype-Mixture Baseline for Few-Shot Segmentation with Bounding-Box Annotations|ProMi：一种高效的基于原型混合的少样本分割带边界框标注的基线|Florent Chiaroni, Ali Ayub, Ola Ahmad|<http://arxiv.org/pdf/2505.12547v1>|[代码](https://github.com/ThalesGroup/promi.); 提出了一种基于边界框标注的少样本分割方法，有效降低了标注成本并提升了分割效果。|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Scalable Strategies for Continual Learning with Replay|可扩展的持续学习重放策略|Truman Hickok|<http://arxiv.org/pdf/2505.12512v1>|提出了一种高效可扩展的持续学习方法，通过整合低秩适应、巩固和序列合并策略，显著降低了重放样本需求并提...|
|🆕 发布|Observe-R1: Unlocking Reasoning Abilities of MLLMs with Dynamic Progressive Reinforcement Learning|观察-R1：利用动态渐进式强化学习解锁多模态语言大模型的推理能力|Zirun Guo, Minjie Hong, Tao Jin|<http://arxiv.org/pdf/2505.12432v1>|[代码](https://github.com/zrguo/Observe-R1.); 提出Observe-R1框架，通过动态渐进式强化学习提升多模态大语言模型的推理能力。|
|🆕 发布|CLIP-aware Domain-Adaptive Super-Resolution|基于CLIP的域自适应超分辨率|Zhengyang Lu, Qian Xia, Weifan Wang, Feng Wang|<http://arxiv.org/pdf/2505.12391v1>|CDASR通过结合CLIP语义信息和元学习策略，实现了跨域自适应图像超分辨率，显著提升了性能。|
|🆕 发布|Ditch the Denoiser: Emergence of Noise Robustness in Self-Supervised Learning from Data Curriculum|摒弃降噪器：从数据课程中自监督学习噪声鲁棒性的出现|Wenquan Lu, Jiaqi Zhang, Hugues Van Assel, Randall Balestriero|<http://arxiv.org/pdf/2505.12191v1>|[代码](https://github.com/wenquanlu/noisy_dinov2.); 提出了一种无需降噪器的自监督学习方法，通过噪声感知预训练实现噪声鲁棒性。|
|📝 更新|Pseudo-Labeling Based Practical Semi-Supervised Meta-Training for Few-Shot Learning|基于伪标签的实用半监督元训练在少样本学习中的应用|Xingping Dong, Tianran Ouyang, Shengcai Liao, Bo Du, Ling Shao|<http://arxiv.org/pdf/2207.06817v4>|提出了一种基于伪标签的半监督元学习框架，有效提升少量样本学习性能。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 目标导向视觉决策 (Goal-oriented Visual Decision Making)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SiCo: An Interactive Size-Controllable Virtual Try-On Approach for Informed Decision-Making|SiCo：一种用于信息决策的交互式可调节尺寸虚拟试穿方法|Sherry X. Chen, Alex Christopher Lim, Yimeng Liu, Pradeep Sen, Misha Sra|<http://arxiv.org/pdf/2408.02803v2>|SiCo通过交互式尺寸可控虚拟试穿，提升用户对服装尺寸选择的信心，降低在线购物退货率。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ViEEG: Hierarchical Neural Coding with Cross-Modal Progressive Enhancement for EEG-Based Visual Decoding|ViEEG：基于EEG的视觉解码的层次化神经编码与跨模态渐进增强|Minxu Liu, Donghai Guan, Chuhang Zheng, Chunwei Tian, Jie Wen, Qi Zhu|<http://arxiv.org/pdf/2505.12408v1>|提出了一种基于视觉层次结构的EEG解码框架，显著提升了基于脑电的视觉解码性能。|
|🆕 发布|Towards Visuospatial Cognition via Hierarchical Fusion of Visual Experts|通过视觉专家分层融合实现视觉空间认知|Qi Feng, Hidetoshi Shimodaira|<http://arxiv.org/pdf/2505.12363v1>|通过融合视觉专家和大规模数据集，ViCA2显著提升了视觉空间认知能力。|
|🆕 发布|Emergent Active Perception and Dexterity of Simulated Humanoids from Visual Reinforcement Learning|从视觉强化学习中涌现的模拟人形机器人的主动感知和灵巧|Zhengyi Luo, Chen Tessler, Toru Lin, Ye Yuan, Tairan He, Wenli Xiao, Yunrong Guo, Gal Chechik .etc.|<http://arxiv.org/pdf/2505.12278v1>|通过视觉强化学习，该论文提出了一种模拟人形机器人感知和灵巧控制框架，实现多任务操作并涌现出主动搜索等...|
|📝 更新|Probing Human Visual Robustness with Neurally-Guided Deep Neural Networks|探究人类视觉鲁棒性的神经引导深度神经网络|Zhenan Shao, Linjian Ma, Yiqing Zhou, Yibo Jacky Zhang, Sanmi Koyejo, Bo Li, Diane M. Beck|<http://arxiv.org/pdf/2405.02564v2>|通过神经引导的深度神经网络，揭示了人类视觉鲁棒性与大脑视觉通路中表征空间演变的关系。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Remote sensing colour image semantic segmentation of trails created by large herbivorous Mammals|大型草食哺乳动物形成的路径的遥感彩色图像语义分割|Jose Francisco Diez-Pastor, Francisco Javier Gonzalez-Moya, Pedro Latorre-Carmona, Francisco Javier Perez-Barbería, Ludmila I. Kuncheva, Antonio Canepa-Oneto, Alvar Arnaiz-González, Cesar Garcia-Osorio|<http://arxiv.org/pdf/2504.12121v3>|提出了一种基于深度学习的自动检测大型食草动物活动轨迹的方法，以支持生态监测和保护。|
|🆕 发布|Temporal-Spectral-Spatial Unified Remote Sensing Dense Prediction|时谱空统一遥感密集预测|Sijie Zhao, Feng Liu, Xueliang Zhang, Hao Chen, Pengfeng Xiao, Lei Bai|<http://arxiv.org/pdf/2505.12280v1>|提出TSSUN网络，统一处理遥感数据，实现多种密集预测任务的高效适应。|
|🆕 发布|SEPT: Standard-Definition Map Enhanced Scene Perception and Topology Reasoning for Autonomous Driving|SEPT：标准定义地图增强的自动驾驶场景感知与拓扑推理|Muleilan Pei, Jiayao Shan, Peiliang Li, Jieqi Shi, Jing Huo, Yang Gao, Shaojie Shen|<http://arxiv.org/pdf/2505.12246v1>|提出SEPT框架，通过融合SD地图和BEV特征，显著提升自动驾驶场景感知和拓扑推理能力。|
|📝 更新|ImageRAG: Enhancing Ultra High Resolution Remote Sensing Imagery Analysis with ImageRAG|图像RAG：利用图像RAG增强超高清遥感影像分析|Zilun Zhang, Haozhan Shen, Tiancheng Zhao, Zian Guan, Bin Chen, Yuhao Wang, Xu Jia, Yuxiang Cai .etc.|<http://arxiv.org/pdf/2411.07688v3>|[代码](https://github.com/om-ai-lab/ImageRAG); ImageRAG通过RAG技术，高效处理超高清遥感图像，提升分析准确性和效率。|
|🆕 发布|Road Segmentation for ADAS/AD Applications|道路分割应用于高级驾驶辅助系统/自动驾驶系统|Mathanesh Vellingiri Ramasamy, Dimas Rizky Kurniasalim|<http://arxiv.org/pdf/2505.12206v1>|该论文通过对比VGG-16和U-Net模型在道路分割任务上的表现，分析了模型架构和数据集对分割效果的...|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mutual Evidential Deep Learning for Medical Image Segmentation|相互证据深度学习在医学图像分割中的应用|Yuanpeng He, Yali Bi, Lijian Li, Chi-Man Pun, Wenpin Jiao, Zhi Jin|<http://arxiv.org/pdf/2505.12418v1>|提出了一种基于多源互补证据和不确定性驱动的深度学习框架，有效提升了医疗图像分割的半监督学习性能。|
|🆕 发布|SMFusion: Semantic-Preserving Fusion of Multimodal Medical Images for Enhanced Clinical Diagnosis|SMFusion：多模态医学图像语义保留融合以增强临床诊断|Haozhe Xiang, Han Zhang, Yu Cheng, Xiongwen Quan, Wanwan Huang|<http://arxiv.org/pdf/2505.12251v1>|提出一种结合医学先验知识的语义引导多模态医学图像融合方法，有效提升临床诊断准确性。|
|📝 更新|Beyond Conventional Transformers: The Medical X-ray Attention (MXA) Block for Improved Multi-Label Diagnosis Using Knowledge Distillation|超越传统Transformer：基于知识蒸馏的医学X射线注意力（MXA）块，用于改进多标签诊断|Amit Rand, Hadi Ibrahim|<http://arxiv.org/pdf/2504.02277v2>|提出MXA块，针对X光片多标签诊断，显著提升EfficientViT模型性能。|
|🆕 发布|Hyperspectral Image Land Cover Captioning Dataset for Vision Language Models|高光谱图像土地覆盖描述数据集用于视觉语言模型|Aryan Das, Tanishq Rachamalla, Pravendra Singh, Koushik Biswas, Vinay Kumar Verma, Swalpa Kumar Roy|<http://arxiv.org/pdf/2505.12217v1>|构建了首个大规模高光谱图像标注数据集HyperCap，提升视觉语言模型在遥感应用中的性能。|
|🆕 发布|CTLformer: A Hybrid Denoising Model Combining Convolutional Layers and Self-Attention for Enhanced CT Image Reconstruction|CTLformer：一种结合卷积层和自注意力机制的混合去噪模型，用于增强CT图像重建|Zhiting Zheng, Shuqi Wu, Wen Ding|<http://arxiv.org/pdf/2505.12203v1>|CTLformer结合卷积和自注意力机制，有效去噪低剂量CT图像，提升诊断准确性。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Parametric PerceptNet: A bio-inspired deep-net trained for Image Quality Assessment|参数感知网络：一种用于图像质量评估的生物启发深度网络|Jorge Vila-Tomás, Pablo Hernández-Cámara, Valero Laparra, Jesús Malo|<http://arxiv.org/pdf/2412.03210v3>|提出了一种结合生物视觉原理的参数化神经网络，有效降低参数数量并提升图像质量评估性能。|
|🆕 发布|Kornia-rs: A Low-Level 3D Computer Vision Library In Rust|Kornia-rs：Rust语言中的低级3D计算机视觉库|Edgar Riba, Jian Shi, Aditya Kumar, Andrew Shen, Gary Bradski|<http://arxiv.org/pdf/2505.12425v1>|开发了一个基于Rust的3D计算机视觉库，实现高效、安全的图像和3D操作。|
|📝 更新|Vision-Encoders (Already) Know What They See: Mitigating Object Hallucination via Simple Fine-Grained CLIPScore|视觉编码器（早已）知道他们看到了什么：通过简单的细粒度CLIPScore减轻对象幻觉|Hongseok Oh, Wonseok Hwang|<http://arxiv.org/pdf/2502.20034v2>|提出F-CLIPScore评估方法，有效降低大视觉语言模型中的物体幻觉。|


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visuospatial Cognitive Assistant|视觉空间认知助手|Qi Feng, Hidetoshi Shimodaira|<http://arxiv.org/pdf/2505.12312v1>|提出ViCA-7B模型，通过大规模数据集和可解释性研究，显著提升了视频空间认知能力。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Scalable Density-based Clustering with Random Projections|可扩展的基于密度的随机投影聚类|Haochuan Xu, Ninh Pham|<http://arxiv.org/pdf/2402.15679v2>|提出了一种基于随机投影的sDBSCAN算法，显著提高了高维数据密度聚类效率和准确性。|
|📝 更新|Semantic Shift Estimation via Dual-Projection and Classifier Reconstruction for Exemplar-Free Class-Incremental Learning|基于双投影和分类器重建的无示例类增量学习语义偏移估计|Run He, Di Fang, Yicheng Xu, Yawen Cui, Ming Li, Cen Chen, Ziqian Zeng, Huiping Zhuang|<http://arxiv.org/pdf/2503.05423v4>|[代码](https://github.com/RHe502/ICML25-DPCR.); 提出DPCR方法，通过双重投影和分类器重构解决无样本增量学习中的语义偏移和决策偏差问题。|

