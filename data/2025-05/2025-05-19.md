## [UPDATED!] **2025-05-19** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable Step-Level Supervision|MM-PRM：通过可扩展的步骤级监督增强多模态数学推理|Lingxiao Du, Fanqing Meng, Zongkai Liu, Zhixiang Zhou, Ping Luo, Qiaosheng Zhang, Wenqi Shao|<http://arxiv.org/pdf/2505.13427v1>|[代码](https://github.com/ModalMinds/MM-PRM.); 提出MM-PRM模型，通过过程级监督增强多模态数学推理能力。|
|📝 更新|Understanding the Effect of using Semantically Meaningful Tokens for Visual Representation Learning|理解使用语义上有意义的标记进行视觉表示学习的影响|Neha Kalibhat, Priyatham Kattakinda, Sumit Nawathe, Arman Zarei, Nikita Seleznev, Samuel Sharpe, Senthil Kumar, Soheil Feizi|<http://arxiv.org/pdf/2405.16401v2>|提出语义有意义的视觉标记，提升视觉表征学习，显著增强视觉-语言预训练模型。|
|🆕 发布|Unlocking the Potential of Difficulty Prior in RL-based Multimodal Reasoning|解锁基于RL的多模态推理中的难度先验潜力|Mingrui Chen, Haogeng Liu, Hao Liang, Huaibo Huang, Wentao Zhang, Ran He|<http://arxiv.org/pdf/2505.13261v1>|通过建模问题难度先验信息，提升基于强化学习的多模态推理效果。|
|📝 更新|FAST: Federated Active Learning with Foundation Models for Communication-efficient Sampling and Training|联邦主动学习：基于基础模型的高效通信采样与训练|Haoyuan Li, Mathias Funk, Jindong Wang, Aaqib Saeed|<http://arxiv.org/pdf/2504.03783v4>|提出一种结合基础模型和两阶段采样的联邦主动学习方法，大幅降低通信成本并提升模型性能。|
|🆕 发布|TinyAlign: Boosting Lightweight Vision-Language Models by Mitigating Modal Alignment Bottlenecks|TinyAlign：通过缓解模态对齐瓶颈提升轻量级视觉-语言模型|Yuanze Hu, Zhaoxin Fan, Xinyu Wang, Gen Li, Ye Qiu, Zhichao Yang, Wenjun Wu, Kejian Wu .etc.|<http://arxiv.org/pdf/2505.12884v1>|TinyAlign通过缓解模式对齐瓶颈，显著提升了轻量级视觉语言模型的数据效率和性能。|
|🆕 发布|Robust Multimodal Segmentation with Representation Regularization and Hybrid Prototype Distillation|鲁棒的多模态分割：基于表示正则化和混合原型蒸馏|Jiaqi Tan, Xu Zheng, Yang Liu|<http://arxiv.org/pdf/2505.12861v1>|[代码](https://github.com/RobustSeg/RobustSeg.); 提出RobustSeg框架，通过混合原型蒸馏和表示正则化提升多模态语义分割的鲁棒性。|
|🆕 发布|FLASH: Latent-Aware Semi-Autoregressive Speculative Decoding for Multimodal Tasks|FLASH：多模态任务中的潜在感知半自回归投机解码|Zihua Wang, Ruibo Li, Haozhe Du, Joey Tianyi Zhou, Yu Zhang, Xu Yang|<http://arxiv.org/pdf/2505.12728v1>|提出FLASH框架，通过利用多模态数据的特性加速LMM的解码速度。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FEALLM: Advancing Facial Emotion Analysis in Multimodal Large Language Models with Emotional Synergy and Reasoning|FEALLM：利用情感协同和推理推进多模态大型语言模型中的面部情感分析|Zhuozhao Hu, Kaishen Yuan, Xin Liu, Zitong Yu, Yuan Zong, Jingang Shi, Huanjing Yue, Jingyu Yang|<http://arxiv.org/pdf/2505.13419v1>|[代码](https://github.com/953206211/FEALLM.); 提出FEALLM模型，通过情感协同和推理提升多模态大语言模型在面部情感分析任务中的表现。|
|📝 更新|JetFormer: An Autoregressive Generative Model of Raw Images and Text|JetFormer：原始图像和文本的自回归生成模型|Michael Tschannen, André Susano Pinto, Alexander Kolesnikov|<http://arxiv.org/pdf/2411.19722v2>|JetFormer提出了一种无需预训练组件的自动回归解码器，实现了图像和文本的联合生成。|
|🆕 发布|Scaling Computer-Use Grounding via User Interface Decomposition and Synthesis|通过用户界面分解与合成扩展计算机使用基础|Tianbao Xie, Jiaqi Deng, Xiaochuan Li, Junlin Yang, Haoyuan Wu, Jixuan Chen, Wenjing Hu, Xinyuan Wang .etc.|<http://arxiv.org/pdf/2505.13227v1>|通过用户界面分解与合成，构建大规模基准数据集，提升计算机使用指令的映射能力。|
|🆕 发布|Emergence of Fixational and Saccadic Movements in a Multi-Level Recurrent Attention Model for Vision|视觉多级循环注意力模型中固定和扫视运动的涌现|Pengcheng Pan, Yonekura Shogo, Yasuo Kuniyoshi|<http://arxiv.org/pdf/2505.13191v1>|提出多级循环注意力模型，模拟人眼运动，实现更自然的视觉探索动态。|
|🆕 发布|Industry-focused Synthetic Segmentation Pre-training|行业定向的合成分割预训练|Shinichi Mae, Ryosuke Yamada, Hirokatsu Kataoka|<http://arxiv.org/pdf/2505.13099v1>|提出InsCore合成数据集，有效提升工业场景实例分割性能，无需真实图像或人工标注。|
|🆕 发布|ORQA: A Benchmark and Foundation Model for Holistic Operating Room Modeling|全面手术室建模的基准和基础模型：ORQA|Ege Özsoy, Chantal Pellegrini, David Bani-Harouni, Kun Yuan, Matthias Keicher, Nassir Navab|<http://arxiv.org/pdf/2505.12890v1>|构建了综合手术室模型基准和基础模型，提升手术室智能。|
|📝 更新|Vision-centric Token Compression in Large Language Model|视觉中心化的大语言模型中的令牌压缩|Ling Xing, Alex Jinpeng Wang, Rui Yan, Xiangbo Shu, Jinhui Tang|<http://arxiv.org/pdf/2502.00791v3>|提出Vist，一种视觉中心化的慢快压缩框架，显著降低大语言模型计算和内存成本。|
|📝 更新|Bias and Generalizability of Foundation Models across Datasets in Breast Mammography|基础模型在乳腺钼靶数据集间的偏差与泛化性|Elodie Germani, Ilayda Selin Türk, Fatima Zeineddine, Charbel Mourad, Shadi Albarqouni|<http://arxiv.org/pdf/2505.10579v2>|该论文揭示了基础模型在乳腺摄影分类中的偏见和泛化问题，并提出公平性感知技术以改善模型性能。|
|🆕 发布|Mamba-Adaptor: State Space Model Adaptor for Visual Recognition|Mamba-Adaptor：视觉识别的状态空间模型适配器|Fei Xie, Jiahao Nie, Yujin Tang, Wenkang Zhang, Hongshen Zhao|<http://arxiv.org/pdf/2505.12685v1>|提出Mamba-Adaptor，通过增强记忆和空间建模，提升视觉识别任务性能。|
|🆕 发布|Temporal-Oriented Recipe for Transferring Large Vision-Language Model to Video Understanding|时间导向的大视觉-语言模型迁移至视频理解的方法|Thong Nguyen, Zhiyuan Hu, Xu Lin, Cong-Duy Nguyen, See-Kiong Ng, Luu Anh Tuan|<http://arxiv.org/pdf/2505.12605v1>|提出了一种针对视频理解，通过优化视觉编码器与语言模型接口的时序训练方法，显著提升了大型视觉语言模型的...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|WriteViT: Handwritten Text Generation with Vision Transformer|WriteViT：基于视觉Transformer的手写文本生成|Dang Hoai Nam, Huynh Tong Dang Khoa, Vo Nguyen Le Duy|<http://arxiv.org/pdf/2505.13235v1>|提出WriteViT，一种结合Vision Transformer的轻量级手写文本生成框架，有效捕捉...|
|📝 更新|Vision Transformers in Precision Agriculture: A Comprehensive Survey|视觉Transformer在精准农业中的应用：全面综述|Saber Mehdipour, Seyed Abolghasem Mirroshandel, Seyed Amirhossein Tabatabaei|<http://arxiv.org/pdf/2504.21706v2>|综述了视觉Transformer在精准农业中的应用，提高了植物病害检测的准确性和可扩展性。|
|🆕 发布|Learning to Adapt to Position Bias in Vision Transformer Classifiers|学习适应视觉Transformer分类器中的位置偏差|Robert-Jan Bruintjes, Jan van Gemert|<http://arxiv.org/pdf/2505.13137v1>|提出Position-SHAP和Auto-PE，解决视觉Transformer分类中的位置偏差问题，...|
|🆕 发布|RGB-to-Polarization Estimation: A New Task and Benchmark Study|RGB到偏振估计：一项新任务与基准研究|Beibei Lin, Zifeng Yuan, Tingting Chen|<http://arxiv.org/pdf/2505.13050v1>|定位图像信息，提出RGB到偏振图像估计新任务，建立首个综合基准，评估多种深度学习模型。|
|📝 更新|Ultrasound Report Generation with Multimodal Large Language Models for Standardized Texts|超声报告生成：多模态大型语言模型标准化文本|Peixuan Ge, Tongkun Su, Faqin Lv, Baoliang Zhao, Peng Zhang, Chi Hong Wong, Liang Yao, Yu Sun .etc.|<http://arxiv.org/pdf/2505.08838v2>|提出了一种基于多模态大语言模型的超声报告生成框架，实现跨器官和语言的标准化文本生成。|
|📝 更新|Underwater Camouflaged Object Tracking Meets Vision-Language SAM2|水下伪装目标跟踪与视觉-语言SAM2相遇|Chunhui Zhang, Li Liu, Guanjie Huang, Zhipeng Zhang, Hao Wen, Xi Zhou, Shiming Ge, Yanfeng Wang|<http://arxiv.org/pdf/2409.16902v5>|[代码](https://github.com/983632847/Awesome-Multimodal-Object-Tracking); 构建首个大规模水下伪装物体跟踪数据集，提出基于SAM2的视觉语言跟踪框架，显著提升水下及开放场景物体...|
|📝 更新|Vision Transformers on the Edge: A Comprehensive Survey of Model Compression and Acceleration Strategies|边缘上的视觉Transformer：模型压缩与加速策略的全面调查|Shaibal Saha, Lanyu Xu|<http://arxiv.org/pdf/2503.02891v3>|系统综述了视觉Transformer在边缘设备上的模型压缩和加速策略，以优化其部署效率。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Quantifying Context Bias in Domain Adaptation for Object Detection|量化领域自适应中对象检测的上下文偏差|Hojun Son, Asma Almutairi, Arpan Kusari|<http://arxiv.org/pdf/2409.14679v2>|该论文通过分析背景特征变化量化域适应中的上下文偏差，并提出了一种缓解上下文偏差的方法，有效提升了目标...|
|🆕 发布|Dynamic Graph Induced Contour-aware Heat Conduction Network for Event-based Object Detection|基于动态图诱导的轮廓感知热传导网络的事件驱动目标检测|Xiao Wang, Yu Jin, Lan Chen, Bo Jiang, Lin Zhu, Yonghong Tian, Jin Tang, Bin Luo|<http://arxiv.org/pdf/2505.12908v1>|[代码](https://github.com/Event-AHU/OpenEvDET.); 提出了一种动态图诱导的轮廓感知热传导网络，有效提升了基于事件流的目标检测性能。|
|🆕 发布|Rethinking Features-Fused-Pyramid-Neck for Object Detection|重新思考用于目标检测的特征融合金字塔颈网络|Hulin Li|<http://arxiv.org/pdf/2505.12820v1>|[代码](https://github.com/AlanLi1997/rethinking-fpn.); 设计了独立层次金字塔架构和软最近邻插值，解决特征融合导致的误对齐问题，提升实时目标检测性能。|
|🆕 发布|Enhancing Transformers Through Conditioned Embedded Tokens|通过条件嵌入标记增强Transformer|Hemanth Saratchandran, Simon Lucey|<http://arxiv.org/pdf/2505.12789v1>|通过引入条件嵌入令牌，该方法有效缓解了Transformer中注意力机制的病态条件，提升了训练效率和...|
|🆕 发布|LiDAR MOT-DETR: A LiDAR-based Two-Stage Transformer for 3D Multiple Object Tracking|基于激光雷达的两种阶段Transformer用于3D多目标跟踪|Martha Teiko Teye, Ori Maoz, Matthias Rottmann|<http://arxiv.org/pdf/2505.12753v1>|提出了一种基于LiDAR的Transformer模型，有效解决3D多目标跟踪中的时空一致性问题。|
|📝 更新|Integrating Extra Modality Helps Segmentor Find Camouflaged Objects Well|整合额外模态助力分割器有效识别伪装物体|Chengyu Fang, Chunming He, Longxiang Tang, Yuelin Zhang, Chenyang Zhu, Yuqi Shen, Chubin Chen, Guoxia Xu .etc.|<http://arxiv.org/pdf/2502.14471v2>|[代码](https://github.com/cnyvfang/MultiCOS); 提出多模态融合框架，有效利用多种数据模态提升伪装物体分割性能。|
|🆕 发布|Long-RVOS: A Comprehensive Benchmark for Long-term Referring Video Object Segmentation|长时参照视频目标分割的全面基准：Long-RVOS|Tianming Liang, Haichao Jiang, Yuting Yang, Chaolei Tan, Shuai Li, Wei-Shi Zheng, Jian-Fang Hu|<http://arxiv.org/pdf/2505.12702v1>|构建了Long-RVOS基准，提出ReferMo方法，提升长期视频目标分割性能。|
|📝 更新|CQ-DINO: Mitigating Gradient Dilution via Category Queries for Vast Vocabulary Object Detection|CQ-DINO：通过类别查询缓解梯度稀释的大词汇量目标检测|Zhichao Sun, Huazhang Hu, Yidong Ma, Gang Liu, Nemo Chen, Xu Tang, Yao Hu, Yongchao Xu|<http://arxiv.org/pdf/2503.18430v3>|[代码](https://github.com/RedAIGC/CQ-DINO.); CQ-DINO通过类别查询缓解梯度稀释，提升大规模词汇目标检测性能。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Joint Depth and Reflectivity Estimation using Single-Photon LiDAR|基于单光子激光雷达的深度与反射率联合估计|Hashan K. Weerasooriya, Prateek Chennuri, Weijian Zhang, Istvan Gyongy, Stanley H. Chan|<http://arxiv.org/pdf/2505.13250v1>|提出了一种同时恢复深度和反射率的新方法，显著提升了动态场景下的SP-LiDAR重建质量。|
|🆕 发布|The Way Up: A Dataset for Hold Usage Detection in Sport Climbing|《攀登之路：攀岩握法检测数据集》|Anna Maschek, David C. Schedl|<http://arxiv.org/pdf/2505.12854v1>|构建了首个攀岩握点使用数据集，并探索了基于关键点的2D姿态估计模型以检测攀岩握点使用。|
|🆕 发布|Structure-based Anomaly Detection and Clustering|基于结构的异常检测与聚类|Filippo Leveni|<http://arxiv.org/pdf/2505.12751v1>|提出结构化异常检测与聚类新方法，有效提升数据流中异常检测和聚类性能。|
|🆕 发布|Single Image Reflection Removal via inter-layer Complementarity|单图反射消除：基于层间互补性|Yue Huang, Zi'ang Li, Tianle Hu, Jie Wen, Guanbin Li, Jinglin Zhang, Guoxu Zhou, Xiaozhao Fang|<http://arxiv.org/pdf/2505.12641v1>|提出了一种通过层间互补性模型和注意力机制提升单图像反光去除效果的方法。|
|🆕 发布|Degradation-Aware Feature Perturbation for All-in-One Image Restoration|全图修复中的退化感知特征扰动|Xiangpeng Tian, Xiangyu Liao, Xiao Liu, Meng Li, Chao Ren|<http://arxiv.org/pdf/2505.12630v1>|[代码](https://github.com/TxpHome/DFPIR.); 提出DFPIR，通过引入退化感知特征扰动解决全场景图像修复中的任务干扰问题。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FlowCut: Unsupervised Video Instance Segmentation via Temporal Mask Matching|FlowCut：基于时间掩码匹配的无监督视频实例分割|Alp Eren Sari, Paolo Favaro|<http://arxiv.org/pdf/2505.13174v1>|FlowCut通过特征亲和性和时序匹配，构建伪标签视频数据集，实现无监督视频实例分割。|
|📝 更新|High Accuracy Pulmonary Vessel Segmentation for Contrast and Non-contrast CT Images and Clinical Evaluation|高精度肺血管分割对比与非对比CT图像及临床评估|Ying Ming, Shaoze Luo, Longfei Zhao, Ruijie Zhao, Bing Li, Qiqi Xu, Wei Song|<http://arxiv.org/pdf/2503.16988v2>|提出了一种适用于对比和非对比CT图像的肺血管自动分割算法，显著提升了分割精度和完整性。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EPIC: Explanation of Pretrained Image Classification Networks via Prototype|EPIC：通过原型解释预训练图像分类网络|Piotr Borycki, Magdalena Trędowicz, Szymon Janusz, Jacek Tabor, Przemysław Spurek, Arkadiusz Lewicki, Łukasz Struski|<http://arxiv.org/pdf/2505.12897v1>|EPIC提出了一种结合后置和先验解释方法，为预训练图像分类网络提供直观的基于原型解释。|
|🆕 发布|Unified Cross-modal Translation of Score Images, Symbolic Music, and Performance Audio|统一跨模态翻译得分图像、符号音乐和表演音频|Jongmin Jung, Dongmin Kim, Sihun Lee, Seola Cho, Hyungjoon Soh, Irmak Bukey, Chris Donahue, Dasaem Jeong|<http://arxiv.org/pdf/2505.12863v1>|提出了一种统一的多模态音乐翻译方法，显著提升了音乐信息检索的准确性。|
|📝 更新|Complementary Frequency-Varying Awareness Network for Open-Set Fine-Grained Image Recognition|互补频率变化感知网络用于开放集细粒度图像识别|Qiulei Dong, Jiayin Sun, Mengyu Gao|<http://arxiv.org/pdf/2307.07214v2>|提出了一种互补频率变异性感知网络，有效提升了开放集细粒度图像识别性能。|
|🆕 发布|An approach based on class activation maps for investigating the effects of data augmentation on neural networks for image classification|基于类别激活图探究数据增强对图像分类神经网络影响的方法|Lucas M. Dorneles, Luan Fonseca Garcia, Joel Luís Carbonera|<http://arxiv.org/pdf/2505.12581v1>|提出了一种利用类激活图分析数据增强对图像分类神经网络影响的方法。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mean Flows for One-step Generative Modeling|一步生成模型中的均值流|Zhengyang Geng, Mingyang Deng, Xingjian Bai, J. Zico Kolter, Kaiming He|<http://arxiv.org/pdf/2505.13447v1>|提出MeanFlow模型，通过平均速度概念实现一步生成模型，显著提升单步扩散/流模型性能。|
|📝 更新|Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning|宇宙-Reason1：从物理常识到具身推理|NVIDIA, :, Alisson Azzolini, Junjie Bai, Hannah Brandon, Jiaxin Cao, Prithvijit Chattopadhyay, Huayu Chen .etc.|<http://arxiv.org/pdf/2503.15558v3>|[代码](https://github.com/nvidia-cosmos/cosmos-reason1.); 提出Cosmos-Reason1模型，通过物理常识和具身推理，使物理AI系统在自然语言中生成合适的决...|
|🆕 发布|Faster Video Diffusion with Trainable Sparse Attention|更快的有监督稀疏注意力视频扩散|Peiyuan Zhang, Haofeng Huang, Yongqi Chen, Will Lin, Zhengzhong Liu, Ion Stoica, Eric P. Xing, Hao Zhang|<http://arxiv.org/pdf/2505.13389v1>|提出了一种可训练的稀疏注意力机制，显著提升了视频扩散模型的训练速度和效率。|
|🆕 发布|GuidedMorph: Two-Stage Deformable Registration for Breast MRI|引导形态：乳腺MRI的两阶段可变形配准|Yaqian Chen, Hanxue Gu, Haoyu Dong, Qihang Li, Yuwen Chen, Nicholas Konz, Lin Li, Maciej A. Mazurowski|<http://arxiv.org/pdf/2505.13414v1>|提出GuidedMorph，一种两阶段变形配准框架，有效解决乳腺MRI图像配准难题。|
|🆕 发布|Denoising Diffusion Probabilistic Model for Point Cloud Compression at Low Bit-Rates|低比特率点云压缩的去噪扩散概率模型|Gabriele Spadaro, Alberto Presta, Jhony H. Giraldo, Marco Grangetto, Wei Hu, Giuseppe Valenzise, Attilio Fiandrotti, Enzo Tartaglione|<http://arxiv.org/pdf/2505.13316v1>|[代码](https://github.com/EIDOSLAB/DDPM-PCC.); 提出DDPM-PCC模型，有效压缩低比特率点云，在低速率下实现高质量压缩。|
|🆕 发布|DD-Ranking: Rethinking the Evaluation of Dataset Distillation|DD-Ranking：重新思考数据集蒸馏的评估|Zekai Li, Xinhao Zhong, Samir Khaki, Zhiyuan Liang, Yuhao Zhou, Mingjia Shi, Ziqiao Wang, Xuanlei Zhao .etc.|<http://arxiv.org/pdf/2505.13300v1>|提出DD-Ranking统一评估框架，解决数据蒸馏方法评价不公问题。|
|🆕 发布|Swin DiT: Diffusion Transformer using Pseudo Shifted Windows|Swin DiT：基于伪平移窗口的扩散Transformer|Jiafu Wu, Yabiao Wang, Jian Li, Jinlong Peng, Yun Cao, Chengjie Wang, Jiangning Zhang|<http://arxiv.org/pdf/2505.13219v1>|[代码](https://github.com/wujiafu007/Swin-DiT); 提出PSWA和PCCA策略，有效降低DiT计算成本，显著提升图像生成性能。|
|🆕 发布|CacheFlow: Fast Human Motion Prediction by Cached Normalizing Flow|缓存流：通过缓存归一化流快速预测人类运动|Takahiro Maeda, Jinkun Cao, Norimichi Ukita, Kris Kitani|<http://arxiv.org/pdf/2505.13140v1>|CacheFlow通过缓存预计算结果，显著提升了3D人体运动预测的速度和准确性。|
|📝 更新|DPBridge: Latent Diffusion Bridge for Dense Prediction|DPBridge：密集预测的潜在扩散桥|Haorui Ji, Taojun Lin, Hongdong Li|<http://arxiv.org/pdf/2412.20506v3>|提出DPBridge，一种结合扩散桥模型与视觉先验的密集预测框架，有效提升深度估计和表面法线预测性能...|
|🆕 发布|Anti-Inpainting: A Proactive Defense against Malicious Diffusion-based Inpainters under Unknown Conditions|对抗修复：在未知条件下对恶意扩散型修复器的主动防御|Yimao Guo, Zuomin Qu, Wei Lu, Xiangyang Luo|<http://arxiv.org/pdf/2505.13023v1>|提出Anti-Inpainting，一种在未知条件下防御恶意扩散图像篡改的主动防御方法。|
|🆕 发布|Enhancing Diffusion-Weighted Images (DWI) for Diffusion MRI: Is it Enough without Non-Diffusion-Weighted B=0 Reference?|增强扩散加权图像（DWI）用于扩散磁共振成像（Diffusion MRI）：没有非扩散加权B=0参考是否足够？|Yinzhe Wu, Jiahao Huang, Fanwen Wang, Mengze Gao, Congyu Liao, Guang Yang, Kawin Setsompop|<http://arxiv.org/pdf/2505.12978v1>|提出了一种结合比率的损失函数，显著提升了扩散加权图像的重建质量及扩散参数的准确性。|
|📝 更新|Grokking at the Edge of Numerical Stability|探索数值稳定性的边缘|Lucas Prieto, Melih Barsbey, Pedro A. M. Mediano, Tolga Birdal|<http://arxiv.org/pdf/2501.04697v2>|[代码](https://github.com/LucasPrietoAl/grokking-at-the-edge-of-numerical-stability.); 揭示了深度学习中的“Grokking”现象，通过防止Softmax Collapse和优化梯度方向，...|
|📝 更新|DiTPainter: Efficient Video Inpainting with Diffusion Transformers|DiTPainter：基于扩散变换器的有效视频修复|Xian Wu, Chang Liu|<http://arxiv.org/pdf/2504.15661v3>|DiTPainter利用轻量级Diffusion Transformer模型，高效解决视频修复问题，...|
|🆕 发布|LatentINDIGO: An INN-Guided Latent Diffusion Algorithm for Image Restoration|潜在INDIGO：一种基于INN引导的潜在扩散图像恢复算法|Di You, Daniel Siromani, Pier Luigi Dragotti|<http://arxiv.org/pdf/2505.12935v1>|提出了一种基于波let INN的图像恢复算法，有效解决复杂退化与计算效率问题。|
|📝 更新|What's Inside Your Diffusion Model? A Score-Based Riemannian Metric to Explore the Data Manifold|您内部的扩散模型有何奥秘？一种基于分数的黎曼度量来探索数据流形|Simone Azeglio, Arianna Di Bernardo|<http://arxiv.org/pdf/2505.11128v2>|引入了一种基于得分函数的黎曼度量，以探索数据流形并揭示扩散模型学习到的几何结构。|
|📝 更新|Origin Identification for Text-Guided Image-to-Image Diffusion Models|文本引导的图像到图像扩散模型的起源识别|Wenhao Wang, Yifan Sun, Zongxin Yang, Zhentao Tan, Zhengdong Hu, Yi Yang|<http://arxiv.org/pdf/2501.02376v2>|提出了一种识别图像来源的方法，通过跨扩散模型的数据集和线性变换，有效提高了图像识别的准确性。|
|🆕 发布|Mitigating Hallucination in VideoLLMs via Temporal-Aware Activation Engineering|通过时间感知激活工程减轻VideoLLMs中的幻觉|Jianfeng Cai, Wengang Zhou, Zongmeng Zhang, Jiale Hong, Nianji Zhan, Houqiang Li|<http://arxiv.org/pdf/2505.12826v1>|提出了一种基于时间感知的激活工程框架，有效减轻了视频LLMs中的幻觉问题。|
|📝 更新|DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models|DPM-Solver++：扩散概率模型的引导采样快速求解器|Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, Jun Zhu|<http://arxiv.org/pdf/2211.01095v3>|提出DPM-Solver++，高效解决扩散概率模型引导采样问题，大幅提升采样速度和质量。|
|🆕 发布|The Gaussian Latent Machine: Efficient Prior and Posterior Sampling for Inverse Problems|高斯潜在机：逆问题中高效先验和后验采样|Muhamed Kuric, Martin Zach, Andreas Habring, Michael Unser, Thomas Pock|<http://arxiv.org/pdf/2505.12836v1>|提出了一种高效统一的采样方法，解决逆问题中的先验和后验采样问题。|
|🆕 发布|FlightGPT: Towards Generalizable and Interpretable UAV Vision-and-Language Navigation with Vision-Language Models|飞行GPT：迈向具有视觉-语言模型的通用且可解释的无人机视觉与语言导航|Hengxing Cai, Jinhan Dong, Jingjun Tan, Jingcheng Deng, Sihang Li, Zhifeng Gao, Haidong Wang, Zicheng Su .etc.|<http://arxiv.org/pdf/2505.12835v1>|FlightGPT通过结合视觉语言模型和强化学习，实现了可解释的无人机视觉与语言导航。|
|🆕 发布|CURE: Concept Unlearning via Orthogonal Representation Editing in Diffusion Models|CURE：通过扩散模型中的正交表示编辑进行概念去学习|Shristi Das Biswas, Arani Roy, Kaushik Roy|<http://arxiv.org/pdf/2505.12677v1>|CURE通过正交表示编辑在扩散模型中实现无监督的概念遗忘，有效抑制不希望的内容。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance|精细物理：通过显式结合物理定律以有效骨骼引导进行精细粒度人类动作生成|Dian Shao, Mingfei Shi, Shengda Xu, Haodong Chen, Yongle Huang, Binglu Wang|<http://arxiv.org/pdf/2505.13437v1>|FinePhys通过结合物理定律和骨骼引导，有效提升了细粒度人类动作生成的自然性和合理性。|
|🆕 发布|VTBench: Evaluating Visual Tokenizers for Autoregressive Image Generation|VTBench：评估自回归图像生成中的视觉分词器|Huawei Lin, Tong Geng, Zhaozhuo Xu, Weijie Zhao|<http://arxiv.org/pdf/2505.13439v1>|VTBench提出全面评估视觉分词器，揭示连续VAEs在图像生成中优于离散VTs。|
|🆕 发布|Understanding Complexity in VideoQA via Visual Program Generation|通过视觉程序生成理解视频问答中的复杂性|Cristobal Eyzaguirre, Igor Vasiljevic, Achal Dave, Jiajun Wu, Rares Andrei Ambrus, Thomas Kollar, Juan Carlos Niebles, Pavel Tokmakov|<http://arxiv.org/pdf/2505.13429v1>|通过视觉程序生成分析视频问答问题复杂度，提出算法从代码估算问题难度，构建更难的新基准。|
|🆕 发布|RoPECraft: Training-Free Motion Transfer with Trajectory-Guided RoPE Optimization on Diffusion Transformers|RoPECraft：基于轨迹引导的RoPE优化在扩散变换器上的无监督运动迁移|Ahmet Berke Gokmen, Yigit Ekin, Bahri Batuhan Bilecen, Aysegul Dundar|<http://arxiv.org/pdf/2505.13344v1>|提出了一种无需训练的视频运动迁移方法，通过轨迹引导的RoPE优化在扩散变换器中实现运动编码。|
|🆕 发布|eStonefish-scenes: A synthetically generated dataset for underwater event-based optical flow prediction tasks|eStonefish-scenes：用于水下事件驱动光流预测任务的人工合成数据集|Jad Mansour, Sebastian Realpe, Hayat Rajani, Michele Grimaldi, Rafael Garcia, Nuno Gracias|<http://arxiv.org/pdf/2505.13309v1>|构建了eStonefish-scenes合成数据集，以促进水下事件驱动光流预测研究。|
|📝 更新|Anomaly Anything: Promptable Unseen Visual Anomaly Generation|异常万物：可提示的未见视觉异常生成|Han Sun, Yunkang Cao, Hao Dong, Olga Fink|<http://arxiv.org/pdf/2406.01078v3>|提出Anomaly Anything框架，利用Stable Diffusion生成多样化、真实的未见...|
|🆕 发布|MAGI-1: Autoregressive Video Generation at Scale|MAGI-1：大规模自回归视频生成|Sand. ai, Hansi Teng, Hongyu Jia, Lei Sun, Lingzhi Li, Maolin Li, Mingqiu Tang, Shuai Han .etc.|<http://arxiv.org/pdf/2505.13211v1>|[代码](https://github.com/SandAI-org/MAGI-1); MAGI-1通过自回归预测视频片段，实现大规模视频生成，支持可控生成和实时部署。|
|📝 更新|RevCD -- Reversed Conditional Diffusion for Generalized Zero-Shot Learning|RevCD -- 逆向条件扩散在广义零样本学习中的应用|William Heyden, Habib Ullah, M. Salman Siddiqui, Fadi Al Machot|<http://arxiv.org/pdf/2409.00511v2>|RevCD通过逆向条件扩散模型，有效提升了零样本学习中的知识迁移效率。|
|📝 更新|Controlled Training Data Generation with Diffusion Models|基于扩散模型的受控训练数据生成|Teresa Yeo, Andrei Atanov, Harold Benoit, Aleksandr Alekseev, Ruchira Ray, Pooya Esmaeil Akhoondi, Amir Zamir|<http://arxiv.org/pdf/2403.15309v2>|提出了一种结合反馈机制的自动生成训练数据方法，有效控制文本到图像生成模型。|
|🆕 发布|Higher fidelity perceptual image and video compression with a latent conditioned residual denoising diffusion model|高保真感知图像和视频压缩：基于潜在条件残差去噪扩散模型|Jonas Brenig, Radu Timofte|<http://arxiv.org/pdf/2505.13152v1>|提出了一种结合扩散模型和解码网络的混合图像压缩方案，显著提升了压缩图像的保真度。|
|📝 更新|M3G: Multi-Granular Gesture Generator for Audio-Driven Full-Body Human Motion Synthesis|M3G：音频驱动全身人类运动合成的多粒度手势生成器|Zhizhuo Yin, Yuk Hang Tsui, Pan Hui|<http://arxiv.org/pdf/2505.08293v2>|提出M3G框架，通过多粒度VQ-VAE和音频信息提取，实现音频驱动全身体态的自然生成。|
|🆕 发布|Just Dance with $π$! A Poly-modal Inductor for Weakly-supervised Video Anomaly Detection|与π共舞！一种用于弱监督视频异常检测的多模态感应器|Snehashis Majhi, Giacomo D'Amicantonio, Antitza Dantcheva, Quan Kong, Lorenzo Garattoni, Gianpiero Francesca, Egor Bondarev, Francois Bremond|<http://arxiv.org/pdf/2505.13123v1>|提出了一种融合多模态信息的视频异常检测方法，显著提升了检测准确率。|
|🆕 发布|Touch2Shape: Touch-Conditioned 3D Diffusion for Shape Exploration and Reconstruction|触感2形状：触感条件下的3D扩散用于形状探索与重建|Yuanbo Wang, Zhaoxuan Zhang, Jiajin Qiu, Dilong Sun, Zhengyu Meng, Xiaopeng Wei, Xin Yang|<http://arxiv.org/pdf/2505.13091v1>|利用触觉图像，提出Touch2Shape模型，通过触觉条件扩散模型实现形状探索与重建。|
|📝 更新|Multi-Faceted Multimodal Monosemanticity|多角度多模态单义性|Hanqi Yan, Xiangxiang Cui, Lu Yin, Paul Pu Liang, Yulan He, Yifei Wang|<http://arxiv.org/pdf/2502.14888v2>|开发多模态可解释性工具，揭示CLIP模型中不同模态特征，提升下游任务性能。|
|📝 更新|UniTok: A Unified Tokenizer for Visual Generation and Understanding|UniTok：视觉生成与理解统一分词器|Chuofan Ma, Yi Jiang, Junfeng Wu, Jihan Yang, Xin Yu, Zehuan Yuan, Bingyue Peng, Xiaojuan Qi|<http://arxiv.org/pdf/2502.20321v2>|[代码](https://github.com/FoundationVision/UniTok.); 提出UniTok，一种解决视觉生成与理解模型间冲突的统一分词器，显著提升性能。|
|🆕 发布|A Generalized Label Shift Perspective for Cross-Domain Gaze Estimation|广义标签偏移视角下的跨域视线估计|Hao-Ran Yang, Xiaohui Chen, Chuan-Xian Ren|<http://arxiv.org/pdf/2505.13043v1>|提出一种基于广义标签偏移理论的跨域注视估计方法，有效提升模型泛化能力。|
|🆕 发布|A Skull-Adaptive Framework for AI-Based 3D Transcranial Focused Ultrasound Simulation|基于AI的3D经颅聚焦超声模拟的颅骨自适应框架|Vinkle Srivastav, Juliette Puel, Jonathan Vappou, Elijah Van Houten, Paolo Cabras, Nicolas Padoy|<http://arxiv.org/pdf/2505.12998v1>|[代码](https://github.com/CAMMA-public/TFUScapes.); 开发首个大规模tFUS模拟数据集，并构建深度学习模型实现脑超声精准模拟。|
|📝 更新|UniversalRAG: Retrieval-Augmented Generation over Corpora of Diverse Modalities and Granularities|通用RAG：跨多样性和粒度细分的语料库上的检索增强生成|Woongyeong Yeo, Kangsan Kim, Soyeong Jeong, Jinheon Baek, Sung Ju Hwang|<http://arxiv.org/pdf/2504.20734v2>|UniversalRAG通过跨模态和粒度异构知识库，实现更精准的检索增强生成。|
|📝 更新|DeLoRA: Decoupling Angles and Strength in Low-rank Adaptation|DeLoRA：低秩自适应中角度与强度的解耦|Massimo Bini, Leander Girrbach, Zeynep Akata|<http://arxiv.org/pdf/2503.18225v2>|[代码](https://github.com/ExplainableML/DeLoRA.); 提出DeLoRA方法，通过解耦角度和强度，提高低秩自适应的鲁棒性和性能。|
|🆕 发布|UniHM: Universal Human Motion Generation with Object Interactions in Indoor Scenes|通用室内场景中具有物体交互的人体运动生成：UniHM|Zichen Geng, Zeeshan Hayder, Wei Liu, Ajmal Mian|<http://arxiv.org/pdf/2505.12774v1>|UniHM通过融合多模态信息和创新模型，实现了复杂场景中场景感知的人体运动生成。|
|📝 更新|3DGen-Bench: Comprehensive Benchmark Suite for 3D Generative Models|3DGen-Bench：三维生成模型的全面基准套件|Yuhan Zhang, Mengchen Zhang, Tong Wu, Tengfei Wang, Gordon Wetzstein, Dahua Lin, Ziwei Liu|<http://arxiv.org/pdf/2503.21745v2>|构建了3D生成模型综合基准3DGen-Bench，通过人类偏好数据集和自动评分模型，提升了3D生成模...|
|🆕 发布|MVAR: Visual Autoregressive Modeling with Scale and Spatial Markovian Conditioning|MVAR：基于尺度与空间马尔可夫条件下的视觉自回归建模|Jinhua Zhang, Wei Long, Minghao Han, Weiyi You, Shuhang Gu|<http://arxiv.org/pdf/2505.12742v1>|提出MVAR模型，通过引入尺度和空间马尔可夫假设，降低视觉自回归建模的复杂度，提高生成效率。|
|📝 更新|Learning to Learn Weight Generation via Local Consistency Diffusion|通过局部一致性扩散学习权重生成|Yunchuan Guan, Yu Liu, Ke Zhou, Zhiqi Shen, Jenq-Neng Hwang, Lei Li|<http://arxiv.org/pdf/2502.01117v3>|提出Mc-Di，通过元学习和局部一致性扩散算法解决权重生成中的泛化性和局部目标分配问题。|
|🆕 发布|Few-Step Diffusion via Score identity Distillation|基于分数身份蒸馏的少步扩散|Mingyuan Zhou, Yi Gu, Zhendong Wang|<http://arxiv.org/pdf/2505.12674v1>|[代码](https://github.com/mingyuanzhou/SiD-LSG.); 通过优化Score identity Distillation，实现高效的多步扩散模型蒸馏，提升文本...|
|📝 更新|Generative Pre-trained Autoregressive Diffusion Transformer|生成预训练自回归扩散Transformer|Yuan Zhang, Jiacheng Jiang, Guoqing Ma, Zhiying Lu, Haoyang Huang, Jianlong Yuan, Nan Duan|<http://arxiv.org/pdf/2505.07344v3>|提出GPDiT，一种结合扩散和自回归模型的视频生成Transformer，实现连续潜在空间中的长距离...|
|🆕 发布|MVPainter: Accurate and Detailed 3D Texture Generation via Multi-View Diffusion with Geometric Control|MVPainter：基于多视图扩散和几何控制的精确且详细的3D纹理生成|Mingqi Shao, Feng Xiong, Zhaoxu Sun, Mu Xu|<http://arxiv.org/pdf/2505.12635v1>|MVPainter通过多视角扩散和几何控制，实现了精确且详细的3D纹理生成。|
|🆕 发布|Diff-MM: Exploring Pre-trained Text-to-Image Generation Model for Unified Multi-modal Object Tracking|Diff-MM：探索用于统一多模态目标跟踪的预训练文本到图像生成模型|Shiyu Xuan, Zechao Li, Jinhui Tang|<http://arxiv.org/pdf/2505.12606v1>|提出Diff-MM，利用预训练文本到图像生成模型的多模态理解能力，实现统一的多模态目标跟踪。|
|🆕 发布|Event-based Star Tracking under Spacecraft Jitter: the e-STURT Dataset|基于事件的空间飞行器抖动下的星跟踪：e-STURT 数据集|Samya Bagchi, Peter Anastasiou, Matthew Tetlow, Tat-Jun Chin, Yasir Latif|<http://arxiv.org/pdf/2505.12588v1>|构建首个模拟航天器抖动的基于事件相机的星跟踪数据集，以促进抖动感知算法开发。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VCM: Vision Concept Modeling Based on Implicit Contrastive Learning with Vision-Language Instruction Fine-Tuning|基于视觉-语言指令微调的隐式对比学习视觉概念建模|Run Luo, Renke Shan, Longze Chen, Ziqiang Liu, Lu Wang, Min Yang, Xiaobo Xia|<http://arxiv.org/pdf/2504.19627v2>|提出VCM，通过视觉语言指令微调，构建高效视觉概念模型，提升图像理解任务性能。|
|🆕 发布|ARIW-Framework: Adaptive Robust Iterative Watermarking Framework|自适应鲁棒迭代水印框架|Shaowu Wu, Liting Zeng, Wei Lu, Xiangyang Luo|<http://arxiv.org/pdf/2505.13101v1>|提出ARIW-Framework，通过迭代优化和图像梯度嵌入，实现高质量且鲁棒的图像版权保护。|
|🆕 发布|Towards a Universal Image Degradation Model via Content-Degradation Disentanglement|迈向通用图像退化模型：基于内容退化解耦|Wenbo Yang, Zhongling Wang, Zhou Wang|<http://arxiv.org/pdf/2505.12860v1>|[代码](https://github.com/yangwenbo99/content-degradation-disentanglement.); 提出首个通用图像退化模型，自动提取并分离退化特征，实现复杂退化效果合成。|
|📝 更新|Super-Resolution Generative Adversarial Networks based Video Enhancement|基于超分辨率生成对抗网络的视频增强|Kağan ÇETİN|<http://arxiv.org/pdf/2505.10589v2>|提出了一种结合3D非局部块的视频超分辨率方法，有效提升了视频画质和连贯性。|
|🆕 发布|Safe-Sora: Safe Text-to-Video Generation via Graphical Watermarking|安全-Sora：通过图形水印实现的安全文本到视频生成|Zihan Su, Xuerui Qiu, Hongbin Xu, Tangyu Jiang, Junhao Zhuang, Chun Yuan, Ming Li, Shengfeng He .etc.|<http://arxiv.org/pdf/2505.12667v1>|Safe-Sora通过将图形水印嵌入视频生成过程，实现了AI生成内容的可靠版权保护。|
|🆕 发布|Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents|可扩展的视频到数据集生成，用于跨平台移动代理|Yunseok Jang, Yeda Song, Sungryull Sohn, Lajanugen Logeswaran, Tiange Luo, Dong-Ki Kim, Kyunghoon Bae, Honglak Lee|<http://arxiv.org/pdf/2505.12632v1>|构建了大规模跨平台移动操作系统导航数据集MONDAY，并开发了自动化视频到数据集生成框架，提升模型跨...|
|🆕 发布|BusterX: MLLM-Powered AI-Generated Video Forgery Detection and Explanation|BusterX：基于MLLM的AI生成视频伪造检测与解释|Haiquan Wen, Yiwei He, Zhenglin Huang, Tianxiao Li, Zihan YU, Xingru Huang, Lu Qi, Baoyuan Wu .etc.|<http://arxiv.org/pdf/2505.12620v1>|提出BusterX框架，利用MLLM和强化学习检测AI生成视频伪造并解释其决策过程。|
|🆕 发布|SurveillanceVQA-589K: A Benchmark for Comprehensive Surveillance Video-Language Understanding with Large Models|SurveillanceVQA-589K：大型模型全面监控视频语言理解的基准|Bo Liu, Pengfei Qiao, Minhan Ma, Xuange Zhang, Yinan Tang, Peng Xu, Kun Liu, Tongtong Yuan|<http://arxiv.org/pdf/2505.12589v1>|构建了大规模开放视频问答基准SurveillanceVQA-589K，以促进安全关键应用中的视频语言...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A generalisable head MRI defacing pipeline: Evaluation on 2,566 meningioma scans|一种通用的头部MRI去伪影流程：在2,566个脑膜瘤扫描上的评估|Lorena Garcia-Foncillas Macias, Aaron Kujawa, Aya Elshalakany, Jonathan Shapey, Tom Vercauteren|<http://arxiv.org/pdf/2505.12999v1>|[代码](https://github.com/cai4cai/defacing_pipeline.); 提出了一种基于图谱注册和脑部掩码的MRI去头技术，有效保护患者隐私并保留脑部解剖结构。|
|🆕 发布|A Study on the Refining Handwritten Font by Mixing Font Styles|关于混合字体风格优化手写体字形的探讨|Avinash Kumar, Kyeolhee Kang, Ammar ul Hassan, Jaeyoung Choi|<http://arxiv.org/pdf/2505.12834v1>|提出FFGAN，通过混合手写和印刷字体特征，显著提升手写字体可读性。|
|📝 更新|DexGarmentLab: Dexterous Garment Manipulation Environment with Generalizable Policy|DexGarmentLab：具有可泛化策略的灵巧服装操作环境|Yuran Wang, Ruihai Wu, Yue Chen, Jiarui Wang, Jiaqi Liang, Ziyu Zhu, Haoran Geng, Jitendra Malik .etc.|<http://arxiv.org/pdf/2505.11032v2>|[代码](https://wayrise.github.io/DexGarmentLab); 提出DexGarmentLab环境，通过HALO算法实现通用服装操作策略，有效解决服装操作难题。|
|📝 更新|Mitigate Language Priors in Large Vision-Language Models by Cross-Images Contrastive Decoding|通过跨图像对比解码缓解大型视觉-语言模型中的语言先验|Jianfei Zhao, Feng Zhang, Xin Sun, Chong Feng|<http://arxiv.org/pdf/2505.10634v2>|提出CICD方法，通过跨图像对比解码减轻大型视觉语言模型中的语言先验问题，减少幻觉同时保持语言流畅。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Recollection from Pensieve: Novel View Synthesis via Learning from Uncalibrated Videos|《从记忆之泉中回忆：通过学习未校准视频进行新颖视图合成》|Ruoyu Wang, Yi Ma, Shenghua Gao|<http://arxiv.org/pdf/2505.13440v1>|[代码](https://github.com/Dwawayu/Pensieve.); 提出了一种无需相机参数的全新视角合成方法，通过自监督学习从未校准视频中提取三维信息。|
|🆕 发布|VesselGPT: Autoregressive Modeling of Vascular Geometry|血管GPT：血管几何的自回归建模|Paula Feldman, Martin Sinnona, Viviana Siless, Claudio Delrieux, Emmanuel Iarussi|<http://arxiv.org/pdf/2505.13318v1>|提出了一种基于GPT-2的自动回归模型，有效捕捉血管几何结构，实现血管树的高保真合成。|
|📝 更新|EndoMetric: Near-Light Monocular Metric Scale Estimation in Endoscopy|EndoMetric：内镜中的近光单目度量尺度估计|Raúl Iranzo, Víctor M. Batlle, Juan D. Tardós, José M. M. Montiel|<http://arxiv.org/pdf/2410.15065v2>|提出了一种基于内窥镜近光源和光衰减定律的全新方法，实现单目内窥镜图像的近光距离尺度估计。|
|🆕 发布|IA-MVS: Instance-Focused Adaptive Depth Sampling for Multi-View Stereo|IA-MVS：基于实例的适应性多视图立体深度采样|Yinzhe Wang, Yiwen Xiao, Hu Wang, Yiping Xu, Yan Tian|<http://arxiv.org/pdf/2505.12714v1>|[代码](https://github.com/KevinWang73106/IA-MVS.); 提出IA-MVS，通过聚焦实例自适应深度采样和置信度估计，显著提升多视图立体深度估计精度。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hybrid 3D-4D Gaussian Splatting for Fast Dynamic Scene Representation|混合3D-4D高斯分层快速动态场景表示|Seungjun Oh, Younggeun Lee, Hyejin Jeon, Eunbyung Park|<http://arxiv.org/pdf/2505.13215v1>|提出了一种混合3D-4D高斯分层方法，有效降低动态场景重建的计算成本，同时保持视觉质量。|
|📝 更新|LightNeuS: Neural Surface Reconstruction in Endoscopy using Illumination Decline|光神经S：内镜中的神经表面重建利用光照衰减|Víctor M. Batlle, José M. M. Montiel, Pascal Fua, Juan D. Tardós|<http://arxiv.org/pdf/2309.02777v2>|提出了一种结合光照衰减和密封先验的神经表面重建方法，实现了结肠内镜图像的精确三维重建。|
|📝 更新|Unsupervised Multi-Parameter Inverse Solving for Reducing Ring Artifacts in 3D X-Ray CBCT|无监督多参数逆解方法在3D X射线CBCT中减少环状伪影|Qing Wu, Hongjiang Wei, Jingyi Yu, Yuyao Zhang|<http://arxiv.org/pdf/2412.05853v2>|提出了一种无监督方法Riner，通过理论分析降低3D X射线CBCT中的环状伪影。|
|🆕 发布|AutoMat: Enabling Automated Crystal Structure Reconstruction from Microscopy via Agentic Tool Use|AutoMat：通过代理工具使用实现显微镜下晶体结构的自动化重建|Yaotian Yang, Yiwen Tang, Yizhe Chen, Xiao Chen, Jiangjie Qiu, Hao Xiong, Haoyu Yin, Zhiyao Luo .etc.|<http://arxiv.org/pdf/2505.12650v1>|[代码](https://github.com/yyt-2378/AutoMat); AutoMat通过自动化显微镜图像处理，实现了从图像到原子晶体结构的重建，推动了材料科学领域显微镜与...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FIOVA: A Multi-Annotator Benchmark for Human-Aligned Video Captioning|FIOVA：面向人类对齐视频描述的多人标注基准|Shiyu Hu, Xuchen Li, Xuzhao Li, Jing Zhang, Yipei Wang, Xin Zhao, Kang Hao Cheong|<http://arxiv.org/pdf/2410.15270v2>|[代码](https://huuuuusy.github.io/fiova); 提出FIOVA基准，通过多标注者和认知权重评估视频描述与人类理解的契合度。|
|🆕 发布|Adaptive Image Restoration for Video Surveillance: A Real-Time Approach|自适应视频监控图像恢复：实时方法|Muhammad Awais Amin, Adama Ilboudo, Abdul Samad bin Shahid, Amjad Ali, Waqas Haider Khan Bangyal|<http://arxiv.org/pdf/2505.13130v1>|开发了一种基于ResNet_50的实时图像恢复模型，有效应对视频监控中的图像退化问题。|
|📝 更新|$\infty$-Video: A Training-Free Approach to Long Video Understanding via Continuous-Time Memory Consolidation|无限视频：通过连续时间记忆巩固的无监督长视频理解方法|Saul Santos, António Farinhas, Daniel C. McNamee, André F. T. Martins|<http://arxiv.org/pdf/2501.19098v2>|提出了一种无需训练的连续时间长期记忆机制，有效理解任意长视频。|
|🆕 发布|HiERO: understanding the hierarchy of human behavior enhances reasoning on egocentric videos|HiERO：理解人类行为层次以增强以自我为中心的视频推理|Simone Alberto Peirone, Francesca Pistilli, Giuseppe Averta|<http://arxiv.org/pdf/2505.12911v1>|HiERO通过提取人类行为层次结构，显著提升了自拍摄像头视频的推理能力。|
|📝 更新|Scene-Text Grounding for Text-Based Video Question Answering|场景文本定位用于基于文本的视频问答|Sheng Zhou, Junbin Xiao, Xun Yang, Peipei Song, Dan Guo, Angela Yao, Meng Wang, Tat-Seng Chua|<http://arxiv.org/pdf/2409.14319v3>|[代码](https://github.com/zhousheng97/ViTXT-GQA.git); 提出了一种基于场景文本定位的文本视频问答方法，提高了问答系统的可解释性和准确性。|
|🆕 发布|SPKLIP: Aligning Spike Video Streams with Natural Language|SPKLIP：对自然语言与尖峰视频流进行对齐|Yongchang Gao, Meiling Jin, Zhaofei Yu, Tiejun Huang, Guozhang Chen|<http://arxiv.org/pdf/2505.12656v1>|SPKLIP通过引入层次化特征提取和对比学习，有效解决了脉冲视频与自然语言对齐问题，提升了脉冲视频语...|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CAMOT: Camera Angle-aware Multi-Object Tracking|相机角度感知多目标跟踪：CAMOT|Felix Limanta, Kuniaki Uto, Koichi Shinoda|<http://arxiv.org/pdf/2409.17533v2>|提出CAMOT，通过估计相机角度解决多目标跟踪中的遮挡和距离估计问题。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-Resolution Haar Network: Enhancing human motion prediction via Haar transform|标题翻译：多分辨率Haar网络：通过Haar变换增强人体运动预测|Li Lin|<http://arxiv.org/pdf/2505.12631v1>|提出HaarMoDic网络，通过多分辨率Haar变换提升人体动作预测精度。|
|🆕 发布|Coarse Attribute Prediction with Task Agnostic Distillation for Real World Clothes Changing ReID|粗粒度属性预测与任务无关蒸馏用于现实世界衣物更换的ReID|Priyank Pathak, Yogesh S Rawat|<http://arxiv.org/pdf/2505.12580v1>|提出RLQ框架，通过CAP和TAD提升CC-ReID模型在低质量图像下的识别准确率。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation|超越马特洛什卡：重新审视自适应表示中的稀疏编码|Tiansheng Wen, Yifei Wang, Zequn Zeng, Zhong Peng, Yudi Su, Xinyang Liu, Bo Chen, Hongwei Liu .etc.|<http://arxiv.org/pdf/2503.01776v4>|[代码](https://github.com/neilwen987/CSR_Adaptive_Rep); 提出了一种基于稀疏编码的Contrastive Sparse Representation方法，有效...|
|🆕 发布|Multiscale Adaptive Conflict-Balancing Model For Multimedia Deepfake Detection|多尺度自适应冲突平衡模型用于多媒体深度伪造检测|Zihan Xiong, Xiaohua Wu, Lei Chen, Fangqi Lou|<http://arxiv.org/pdf/2505.12966v1>|提出了一种多尺度自适应冲突平衡模型，有效提升了多媒体深度伪造检测的准确性和泛化能力。|
|📝 更新|COMAE: COMprehensive Attribute Exploration for Zero-shot Hashing|COMAE：零样本哈希的全面属性探索|Yuqi Li, Qingqing Long, Yihang Zhou, Ran Zhang, Zhiyuan Ning, Zhihong Zhu, Yuanchun Zhou, Xuezhi Wang .etc.|<http://arxiv.org/pdf/2402.16424v5>|COMAE通过综合属性探索，有效解决零样本哈希中局部关系和连续属性利用不足的问题，显著提升检索性能。|
|🆕 发布|On the Mechanisms of Adversarial Data Augmentation for Robust and Adaptive Transfer Learning|关于鲁棒自适应迁移学习的对抗数据增强机制|Hana Satou, Alan Mitkiy|<http://arxiv.org/pdf/2505.12681v1>|该论文提出利用对抗数据增强提升跨域迁移学习鲁棒性和适应性。|
|📝 更新|FALCON: False-Negative Aware Learning of Contrastive Negatives in Vision-Language Pretraining|FALCON：视觉-语言预训练中对比负样本的假阴性感知学习|Myunsoo Kim, Seong-Woong Shim, Byung-Jun Lee|<http://arxiv.org/pdf/2505.11192v2>|FALCON通过动态选择合适难度的负样本，有效缓解了视觉语言预训练中的假阴性问题，提升了模型性能。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Fine-tuning Quantized Neural Networks with Zeroth-order Optimization|基于零阶优化的量化神经网络微调|Sifeng Shang, Jiayi Zhou, Chenyu Lin, Minxian Li, Kaiyang Zhou|<http://arxiv.org/pdf/2505.13430v1>|提出了一种基于零阶优化的量化神经网络微调方法，大幅降低大模型微调内存需求。|
|🆕 发布|RBF++: Quantifying and Optimizing Reasoning Boundaries across Measurable and Unmeasurable Capabilities for Chain-of-Thought Reasoning|RBF++：量化与优化跨可测量与不可测量能力之间的推理边界以实现思维链推理|Qiguang Chen, Libo Qin, Jinhao Liu, Yue Liao, Jiaqi Wang, Jingxuan Zhou, Wanxiang Che|<http://arxiv.org/pdf/2505.13307v1>|[代码](https://github.com/LightChen233/reasoning-boundary.); 引入RBF++框架，量化优化可测量与不可测量推理边界，提升LLM推理能力。|
|🆕 发布|Automatic Complementary Separation Pruning Toward Lightweight CNNs|自动互补分离剪枝以实现轻量级CNN|David Levin, Gonen Singer|<http://arxiv.org/pdf/2505.13225v1>|提出ACSP自动剪枝方法，有效降低CNN计算成本，提升网络性能。|
|🆕 发布|CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs|CALM-PDE：用于时变偏微分方程潜在空间建模的连续自适应卷积|Jan Hagnberger, Daniel Musekamp, Mathias Niepert|<http://arxiv.org/pdf/2505.12944v1>|提出了一种连续自适应卷积模型，高效解决任意离散PDEs，降低计算成本。|
|🆕 发布|Segmentation of temporomandibular joint structures on mri images using neural networks for diagnosis of pathologies|基于神经网络在MRI图像上对颞下颌关节结构进行分割以诊断病理学|Maksim I. Ivanov, Olga E. Mendybaeva, Yuri E. Karyakin, Igor N. Glukhikh, Aleksey V. Lebedev|<http://arxiv.org/pdf/2505.12963v1>|提出了一种基于神经网络的方法，用于提高颞下颌关节MRI图像中关节盘分割的准确性和速度。|
|🆕 发布|Accelerate TarFlow Sampling with GS-Jacobi Iteration|加速TarFlow采样使用GS-Jacobi迭代|Ben Liu, Zhen Qin|<http://arxiv.org/pdf/2505.12849v1>|[代码](https://github.com/encoreus/GS-Jacobi_for_TarFlow); 利用GS-Jacobi迭代加速TarFlow采样，显著提升效率并保持图像质量。|
|🆕 发布|AdaToken-3D: Dynamic Spatial Gating for Efficient 3D Large Multimodal-Models Reasoning|AdaToken-3D：高效3D大多模态模型推理的动态空间门控|Kai Zhang, Xingyu Chen, Xiaofeng Zhang|<http://arxiv.org/pdf/2505.12782v1>|AdaToken-3D通过动态剪枝冗余空间标记，显著提升3D多模态模型推理效率和准确性。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|KinTwin: Imitation Learning with Torque and Muscle Driven Biomechanical Models Enables Precise Replication of Able-Bodied and Impaired Movement from Markerless Motion Capture|KinTwin：基于扭矩和肌肉驱动的生物力学模型进行模仿学习，实现无标记运动捕捉的健全和残疾运动的精确复制|R. James Cotton|<http://arxiv.org/pdf/2505.13436v1>|KinTwin通过模仿学习，利用生物力学模型精确复制正常和障碍运动，实现高质量运动分析。|
|📝 更新|High Dynamic Range Novel View Synthesis with Single Exposure|高动态范围单曝光新型视图合成|Kaixuan Zhang, Hu Wang, Minxian Li, Mingwu Ren, Mao Ye, Xiatian Zhu|<http://arxiv.org/pdf/2505.01212v2>|首次提出仅使用单曝光图像进行高动态范围新视图合成的解决方案，显著提升性能。|
|📝 更新|Rolling with the Punches: Resilient Contrastive Pre-training under Non-Stationary Drift|滚动应对冲击：非平稳漂移下的鲁棒对比预训练|Xiaoyu Yang, Jie Lu, En Yu|<http://arxiv.org/pdf/2502.07620v2>|提出了一种应对数据分布变化的鲁棒对比预训练方法，有效缓解概念漂移带来的负面影响。|
|📝 更新|BrainPrompt: Multi-Level Brain Prompt Enhancement for Neurological Condition Identification|脑提示：多级脑提示增强用于神经系统疾病识别|Jiaxing Xu, Kai He, Yue Tang, Wei Li, Mengcheng Lan, Xia Dong, Yiping Ke, Mengling Feng|<http://arxiv.org/pdf/2504.16096v2>|[代码](https://github.com/AngusMonroe/BrainPrompt); BrainPrompt通过结合LLMs和知识驱动提示，有效提升了神经疾病识别的准确性和可解释性。|
|🆕 发布|Uniformity First: Uniformity-aware Test-time Adaptation of Vision-language Models against Image Corruption|统一优先：针对图像损坏的视觉-语言模型统一感知的测试时自适应|Kazuki Adachi, Shin'ya Yamaguchi, Tomoki Hamagami|<http://arxiv.org/pdf/2505.12912v1>|提出了一种针对图像传感器退化导致的分布偏移，通过均匀性感知信息平衡的测试时自适应方法，提升视觉语言模...|
|🆕 发布|Use as Many Surrogates as You Want: Selective Ensemble Attack to Unleash Transferability without Sacrificing Resource Efficiency|任意使用代理：选择性集成攻击以释放迁移性而不牺牲资源效率|Bo Yang, Hengwei Zhang, Jindong Wang, Yuchen Ren, Chenhao Lin, Chao Shen, Zhengyu Zhao|<http://arxiv.org/pdf/2505.12644v1>|提出了一种选择性集成攻击方法，在保持效率的同时显著提升模型迁移能力。|
|🆕 发布|Two out of Three (ToT): using self-consistency to make robust predictions|两中取一（ToT）：利用自一致性进行鲁棒预测|Jung Hoon Lee, Sujith Vijayan|<http://arxiv.org/pdf/2505.12642v1>|开发ToT算法，通过生成两个预测来增强深度学习模型的决策鲁棒性。|
|📝 更新|A Deeper Look into Second-Order Feature Aggregation for LiDAR Place Recognition|对激光雷达位姿识别中二阶特征聚合的深入研究|Saimunur Rahman, Peyman Moghadam|<http://arxiv.org/pdf/2409.15919v2>|提出了一种高效的LiDAR地点识别方法，通过改进第二阶特征聚合，在保持性能的同时显著降低维度和参数。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|G1: Bootstrapping Perception and Reasoning Abilities of Vision-Language Model via Reinforcement Learning|通过强化学习自举视觉-语言模型的感知和推理能力|Liang Chen, Hongcheng Gao, Tianyu Liu, Zhiqi Huang, Flood Sung, Xinyu Zhou, Yuxin Wu, Baobao Chang|<http://arxiv.org/pdf/2505.13426v1>|[代码](https://github.com/chenllliang/G1); 通过强化学习，提出VLM-Gym环境，实现视觉语言模型在多游戏环境中的感知和推理能力自进化。|
|🆕 发布|Benchmarking Unified Face Attack Detection via Hierarchical Prompt Tuning|通过分层提示调优的统一人脸攻击检测基准测试|Ajian Liu, Haocheng Yuan, Xiao Guo, Hui Ma, Wanyi Zhuang, Changtao Miao, Yan Hong, Chuanbiao Song .etc.|<http://arxiv.org/pdf/2505.13327v1>|提出UniAttackDataPlus数据集和HiPTune框架，实现统一的人脸攻击检测。|
|🆕 发布|Pyramid Sparse Transformer: Enhancing Multi-Scale Feature Fusion with Dynamic Token Selection|金字塔稀疏变换器：通过动态标记选择增强多尺度特征融合|Junyi Hu, Tian Bai, Fengyi Wu, Zhengming Peng, Yi Zhang|<http://arxiv.org/pdf/2505.12772v1>|提出PST模块，通过动态选词和共享注意力参数，简化多尺度特征融合，提升检测和分类任务性能。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RECON: Robust symmetry discovery via Explicit Canonical Orientation Normalization|RECON：通过显式规范方向归一化的鲁棒对称性发现|Alonso Urbano, David W. Romero, Max Zimmer, Sebastian Pokutta|<http://arxiv.org/pdf/2505.13289v1>|提出RECON框架，通过数据驱动归一化发现输入数据的内在对称性分布。|
|🆕 发布|StarFT: Robust Fine-tuning of Zero-shot Models via Spuriosity Alignment|星FT：通过稀疏性对齐实现零样本模型的鲁棒微调|Younghyun Kim, Jongheon Jeong, Sangkyung Kwak, Kyungmin Lee, Juho Lee, Jinwoo Shin|<http://arxiv.org/pdf/2505.13232v1>|StarFT通过文本对齐防止零样本模型学习无关特征，提升模型鲁棒性和泛化能力。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Local Details to Global Context: Advancing Vision-Language Models with Attention-Based Selection|从局部细节到全局上下文：基于注意力选择的视觉-语言模型推进|Lincan Cai, Jingxuan Kang, Shuang Li, Wenxuan Ma, Binhui Xie, Zhida Qin, Jian Liang|<http://arxiv.org/pdf/2505.13233v1>|[代码](https://github.com/BIT-DA/ABS); 提出ABS方法，通过注意力引导裁剪和特征选择，提升视觉语言模型的全局语义理解能力。|
|🆕 发布|Walking the Tightrope: Disentangling Beneficial and Detrimental Drifts in Non-Stationary Custom-Tuning|在非平稳定制调整中解耦有益和有害的漂移：走钢丝|Xiaoyu Yang, Jie Lu, En Yu|<http://arxiv.org/pdf/2505.13081v1>|提出了一种对抗概念漂移的RFT方法，通过生成反事实推理轨迹实现稳定非平稳环境下的微调。|
|📝 更新|Rethinking Attention: Polynomial Alternatives to Softmax in Transformers|重新思考注意力：Transformer中的多项式替代Softmax|Hemanth Saratchandran, Jianqiao Zheng, Yiping Ji, Wenbo Zhang, Simon Lucey|<http://arxiv.org/pdf/2410.18613v2>|探索了多项式激活替代softmax，以实现Transformer中注意力机制的稳定训练和高效性能。|
|🆕 发布|Informed Mixing -- Improving Open Set Recognition via Attribution-based Augmentation|信息混合——通过基于归因的增强改进开放集识别|Jiawen Xu, Odej Kao, Margret Keuper|<http://arxiv.org/pdf/2505.12803v1>|提出GradMix，通过动态利用模型梯度属性图进行数据增强，提升开放集识别性能。|
|📝 更新|Multi-modal MRI Translation via Evidential Regression and Distribution Calibration|多模态MRI翻译通过证据回归和分布校准|Jiyao Liu, Shangqi Gao, Yuxin Li, Lihao Liu, Xin Gao, Zhaohu Xing, Junzhi Ning, Yanzhou Su .etc.|<http://arxiv.org/pdf/2407.07372v2>|提出一种基于证据回归和分布校准的多模态MRI翻译框架，有效解决不确定性量化与跨中心鲁棒性问题。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LadderMIL: Multiple Instance Learning with Coarse-to-Fine Self-Distillation|LadderMIL：基于粗到细自蒸馏的多实例学习|Shuyang Wu, Yifu Qiu, Ines P. Nearchou, Sandrine Prost, Jonathan A. Fallowfield, David J. Harrison, Hakan Bilen, Timothy J. Kendall|<http://arxiv.org/pdf/2502.02707v3>|LadderMIL通过引入实例级监督和上下文编码，显著提升了MIL在病理图像分析中的性能。|
|📝 更新|Captured by Captions: On Memorization and its Mitigation in CLIP Models|被标题捕获：关于CLIP模型中的记忆及其缓解|Wenhao Wang, Adam Dziedzic, Grace C. Kim, Michael Backes, Franziska Boenisch|<http://arxiv.org/pdf/2502.07830v2>|该论文揭示了CLIP模型中记忆化现象，并提出策略降低记忆化同时提升模型效用。|
|🆕 发布|MatPredict: a dataset and benchmark for learning material properties of diverse indoor objects|MatPredict：用于学习多样化室内物体材料属性的数据库和基准|Yuzhen Chen, Hojun Son, Arpan Kusari|<http://arxiv.org/pdf/2505.13201v1>|[代码](https://github.com/arpan-kusari/MatPredict); 构建MatPredict数据集，提供多样化材料属性室内物体图像，以提升消费机器人视觉感知能力。|
|🆕 发布|Any-to-Any Learning in Computational Pathology via Triplet Multimodal Pretraining|通过三元组多模态预训练在计算病理学中的任意到任意学习|Qichen Sun, Zhengrui Guo, Rui Peng, Hao Chen, Jinzhuo Wang|<http://arxiv.org/pdf/2505.12711v1>|提出ALTER，一种灵活的跨模态预训练框架，解决计算病理学中数据融合和任务多样性挑战。|
|📝 更新|Robust Emotion Recognition via Bi-Level Self-Supervised Continual Learning|基于双级自监督持续学习的鲁棒情感识别|Adnan Ahmad, Bahareh Nakisa, Mohammad Naim Rastgoo|<http://arxiv.org/pdf/2505.10575v2>|提出了一种基于动态缓冲的分层自监督持续学习方法，有效识别生理信号中的情绪。|
|🆕 发布|Learning Cross-Spectral Point Features with Task-Oriented Training|学习面向任务的跨光谱点特征|Mia Thomas, Trevor Ablett, Jonathan Kelly|<http://arxiv.org/pdf/2505.12593v1>|提出了一种通过任务导向训练学习跨光谱点特征的方法，以提升无人机在低可见条件下的导航精度。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SpatialLLM: From Multi-modality Data to Urban Spatial Intelligence|空间LLM：从多模态数据到城市空间智能|Jiabin Chen, Haiping Wang, Jinpeng Li, Yuan Liu, Zhen Dong, Bisheng Yang|<http://arxiv.org/pdf/2505.12703v1>|[代码](https://github.com/WHU-USI3DV/SpatialLLM.); 提出SpatialLLM，一种无需训练和专家干预的统一语言模型，实现复杂城市场景中的空间智能任务。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models|ChartMuseum：测试大型视觉-语言模型的视觉推理能力|Liyan Tang, Grace Kim, Xinyu Zhao, Thom Lake, Wenxuan Ding, Fangcong Yin, Prasann Singhal, Manya Wadhwa .etc.|<http://arxiv.org/pdf/2505.13444v1>|构建ChartMuseum基准，揭示大型视觉语言模型在复杂视觉推理上的不足。|
|🆕 发布|Advancing Generalization Across a Variety of Abstract Visual Reasoning Tasks|提升跨多种抽象视觉推理任务的泛化能力|Mikołaj Małkiński, Jacek Mańdziuk|<http://arxiv.org/pdf/2505.13391v1>|提出PoNG模型，通过组卷积和归一化提升抽象视觉推理任务的泛化能力。|
|📝 更新|Feedback-Driven Vision-Language Alignment with Minimal Human Supervision|基于最小人工监督的反馈驱动视觉-语言对齐|Giorgio Giannone, Ruoteng Li, Qianli Feng, Evgeny Perevodchikov, Rui Chen, Aleix Martinez|<http://arxiv.org/pdf/2501.04568v2>|提出SVP框架，通过少量人工图像和反馈机制，显著提升视觉语言模型性能，减少幻觉并提高任务表现。|
|🆕 发布|3D Visual Illusion Depth Estimation|三维视觉错觉深度估计|CHengtang Yao, Zhidan Liu, Jiaxi Zeng, Lidong Yu, Yuwei Wu, Yunde Jia|<http://arxiv.org/pdf/2505.13061v1>|提出了一种结合常识和视觉语言模型的深度估计框架，有效应对3D视觉错觉挑战。|
|🆕 发布|Towards Low-Latency Event Stream-based Visual Object Tracking: A Slow-Fast Approach|面向低延迟事件流视觉目标跟踪：一种慢-快方法|Shiao Wang, Xiao Wang, Liye Jin, Bo Jiang, Lin Zhu, Lan Chen, Yonghong Tian, Bin Luo|<http://arxiv.org/pdf/2505.12903v1>|[代码](https://github.com/Event-AHU/SlowFast_Event_Track.); 提出了一种适应不同需求的Slow-Fast跟踪框架，有效解决了低延迟视觉目标跟踪问题。|
|📝 更新|How Panel Layouts Define Manga: Insights from Visual Ablation Experiments|《面板布局如何定义漫画：视觉消融实验的见解》|Siyuan Feng, Teruya Yoshinaga, Katsuhiko Hayashi, Koki Washio, Hidetaka Kamigaito|<http://arxiv.org/pdf/2412.19141v2>|通过深度学习模型和消融实验，揭示了漫画作品独特性在分镜布局中的体现。|
|🆕 发布|Reasoning-OCR: Can Large Multimodal Models Solve Complex Logical Reasoning Problems from OCR Cues?|推理-OCR：大型多模态模型能否从OCR线索解决复杂的逻辑推理问题？|Haibin He, Maoyuan Ye, Jing Zhang, Xiantao Cai, Juhua Liu, Bo Du, Dacheng Tao|<http://arxiv.org/pdf/2505.12766v1>|[代码](https://github.com/Hxyz-123/ReasoningOCR.); 构建Reasoning-OCR基准，挑战大型多模态模型解决基于OCR的复杂推理问题。|
|🆕 发布|It's not you, it's me -- Global urban visual perception varies across demographics and personalities|《不是你，而是我——全球城市视觉感知在人口统计学和个性上的差异》|Matias Quintana, Youlong Gu, Xiucheng Liang, Yujun Hou, Koichi Ito, Yihan Zhu, Mahmoud Abdelrahman, Filip Biljecki|<http://arxiv.org/pdf/2505.12758v1>|首次将个性和人口统计学因素纳入城市视觉感知研究，揭示不同群体对城市街景的感知差异。|
|🆕 发布|TS-VLM: Text-Guided SoftSort Pooling for Vision-Language Models in Multi-View Driving Reasoning|TS-VLM：多视图驾驶推理中视觉-语言模型的文本引导软排序池化|Lihong Chen, Hossein Hassani, Soodeh Nikan|<http://arxiv.org/pdf/2505.12670v1>|设计轻量级视觉语言模型TS-VLM，通过文本引导的软排序池化技术，有效融合多视角数据，提升自动驾驶场...|
|📝 更新|AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection|适应CLIP：为通用视觉异常检测调整CLIP|Bin-Bin Gao, Yue Zhou, Jiangtao Yan, Yuezhi Cai, Weixi Zhang, Meng Wang, Jun Liu, Yong Liu .etc.|<http://arxiv.org/pdf/2505.09926v2>|[代码](https://github.com/gaobb/AdaptCLIP.); AdaptCLIP通过交替学习视觉和文本表示，结合上下文和残差特征，实现了无需微调的通用视觉异常检测...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GMM-Based Comprehensive Feature Extraction and Relative Distance Preservation For Few-Shot Cross-Modal Retrieval|基于高斯混合模型的综合特征提取和相对距离保持的少样本跨模态检索|Chengsong Sun, Weiping Li, Xiang Li, Yuankun Liu, Lianlei Shan|<http://arxiv.org/pdf/2505.13306v1>|提出GMM模型和对比学习机制，有效解决跨模态检索中的多峰分布和数据对齐问题，提升检索准确率。|
|🆕 发布|Cross-modal feature fusion for robust point cloud registration with ambiguous geometry|跨模态特征融合实现鲁棒点云配准的模糊几何|Zhaoyi Wang, Shengyu Huang, Jemil Avers Butt, Yuanzhou Cai, Matej Varga, Andreas Wieser|<http://arxiv.org/pdf/2505.13088v1>|提出了一种融合点云几何和图像特征的方法，有效提升了点云配准的鲁棒性。|
|🆕 发布|TACOcc:Target-Adaptive Cross-Modal Fusion with Volume Rendering for 3D Semantic Occupancy|TACOcc：基于体积渲染的目标自适应跨模态融合用于3D语义占用|Luyao Lei, Shuo Xu, Yifan Bai, Xing Wei|<http://arxiv.org/pdf/2505.12693v1>|提出TACOcc，通过自适应融合和体积渲染提升3D语义占用预测的准确性。|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VISTA: Enhancing Vision-Text Alignment in MLLMs via Cross-Modal Mutual Information Maximization|VISTA：通过跨模态互信息最大化增强多模态语言模型中的视觉-文本对齐|Mingxiao Li, Na Su, Fang Qu, Zhizhou Zhong, Ziyang Chen, Yuan Li, Zhaopeng Tu, Xiaolong Li|<http://arxiv.org/pdf/2505.10917v2>|VISTA通过最大化跨模态互信息，有效提升MLLM视觉理解能力，克服了模态对齐挑战。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Predicting Reaction Time to Comprehend Scenes with Foveated Scene Understanding Maps|预测通过注视点场景理解图理解场景的反应时间|Ziqi Wen, Jonathan Skaza, Shravan Murlidaran, William Y. Wang, Miguel P. Eckstein|<http://arxiv.org/pdf/2505.12660v1>|提出了一种基于视觉注视点与视觉语言模型的F-SUM模型，预测场景理解反应时间。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DB3D-L: Depth-aware BEV Feature Transformation for Accurate 3D Lane Detection|DB3D-L：用于精确3D车道检测的深度感知BEV特征变换|Yehao Liu, Xiaosu Xu, Zijian Wang, Yiqing Yao|<http://arxiv.org/pdf/2505.13266v1>|提出深度感知BEV特征转换方法，有效提升3D车道检测精度。|
|📝 更新|Iterative Deployment Exposure for Unsupervised Out-of-Distribution Detection|迭代部署曝光用于无监督的分布外检测|Lars Doorenbos, Raphael Sznitman, Pablo Márquez-Neila|<http://arxiv.org/pdf/2406.02327v2>|提出IDE，通过CSO方法在部署中迭代学习，有效提升无监督异常检测性能。|
|🆕 发布|Expert-Like Reparameterization of Heterogeneous Pyramid Receptive Fields in Efficient CNNs for Fair Medical Image Classification|高效CNN中异构金字塔感受野的专家级重参数化在公平医疗图像分类中的应用|Xiao Wu, Xiaoqing Zhang, Zunjie Xiao, Lingxi Hu, Risa Higashita, Jiang Liu|<http://arxiv.org/pdf/2505.13039v1>|提出ERoHPRF方法，通过异构金字塔感受野和结构重参数化，提升医疗图像分类效率和公平性。|
|🆕 发布|VLC Fusion: Vision-Language Conditioned Sensor Fusion for Robust Object Detection|视觉-语言条件传感融合：鲁棒目标检测|Aditya Taparia, Noel Ngu, Mario Leiva, Joshua Shay Kricheli, John Corcoran, Nathaniel D. Bastian, Gerardo Simari, Paulo Shakarian .etc.|<http://arxiv.org/pdf/2505.12715v1>|VLC Fusion通过视觉-语言模型引导动态调整传感器融合权重，提升目标检测鲁棒性。|
|📝 更新|A Semantic-Aware and Multi-Guided Network for Infrared-Visible Image Fusion|语义感知和多引导网络用于红外可见光图像融合|Xiaoli Zhang, Liying Wang, Libo Zhao, Xiongfei Li, Siwei Ma|<http://arxiv.org/pdf/2407.06159v3>|[代码](https://github.com/Abraham-Einstein/SMFNet); 提出了一种语义感知和多引导网络，有效融合红外可见图像，提升融合图像质量并增强下游任务性能。|
|📝 更新|MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization|MMedPO：通过临床感知的多模态偏好优化对齐医学视觉-语言模型|Kangyu Zhu, Peng Xia, Yun Li, Hongtu Zhu, Sheng Wang, Huaxiu Yao|<http://arxiv.org/pdf/2412.06141v2>|[代码](https://github.com/aiming-lab/MMedPO.); MMedPO通过考虑偏好样本的临床相关性，有效提升了医学视觉-语言模型的准确性。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RB-SCD: A New Benchmark for Semantic Change Detection of Roads and Bridges in Traffic Scenes|RB-SCD：交通场景中道路和桥梁语义变化检测的新基准|Qingling Shu, Sibao Chen, Zhihui You, Wei Lu, Jin Tang, Bin Luo|<http://arxiv.org/pdf/2505.13212v1>|构建RB-SCD数据集，提出MFDCD框架，有效检测交通场景中道路和桥梁的语义变化。|
|📝 更新|CDMamba: Incorporating Local Clues into Mamba for Remote Sensing Image Binary Change Detection|CDMamba：将局部线索融入Mamba进行遥感图像二值变化检测|Haotian Zhang, Keyan Chen, Chenyang Liu, Hao Chen, Zhengxia Zou, Zhenwei Shi|<http://arxiv.org/pdf/2406.04207v2>|[代码](https://github.com/zmoka-zht/CDMamba.); CDMamba模型通过结合全局和局部特征，有效提升了遥感图像二值变化检测的准确度。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Offboard Occupancy Refinement with Hybrid Propagation for Autonomous Driving|基于混合传播的离线占用区域细化用于自动驾驶|Hao Shi, Song Wang, Jiaming Zhang, Xiaoting Yin, Guangming Wang, Jianke Zhu, Kailun Yang, Kaiwei Wang|<http://arxiv.org/pdf/2403.08504v4>|[代码](https://github.com/MasterHow/OccFiner.); 提出OccFiner，通过混合传播提升自动驾驶场景理解精度。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Computer Vision Models Show Human-Like Sensitivity to Geometric and Topological Concepts|计算机视觉模型展现出对几何和拓扑概念的类似人类敏感性|Zekun Wang, Sashank Varma|<http://arxiv.org/pdf/2505.13281v1>|该论文通过计算机视觉模型研究，揭示了人类对几何和拓扑概念的敏感性可能通过日常环境互动自然习得。|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ReGraP-LLaVA: Reasoning enabled Graph-based Personalized Large Language and Vision Assistant|ReGraP-LLaVA：推理增强的基于图的大语言和视觉个性化助手|Yifan Xiang, Zhenxi Zhang, Bin Li, Yixuan Weng, Shoujun Zhou, Yangfan He, Keqin Li|<http://arxiv.org/pdf/2505.03654v2>|[代码](https://github.com/xyfyyds/ReGraP.); 提出ReGraP-LLaVA模型，通过知识图谱和问答对训练，实现个性化MLLM的关联推理能力。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Event-Driven Dynamic Scene Depth Completion|事件驱动动态场景深度补全|Zhiqiang Yan, Jianhao Jiao, Zhengxue Wang, Gim Hee Lee|<http://arxiv.org/pdf/2505.13279v1>|提出EventDC，首个基于事件驱动的动态场景深度补全框架，有效解决动态场景深度信息获取难题。|
|📝 更新|RefDrone: A Challenging Benchmark for Referring Expression Comprehension in Drone Scenes|RefDrone：无人机场景中指代表达理解的一个挑战性基准|Zhichao Sun, Yepeng Liu, Huachao Zhu, Yuliang Gu, Yuda Zou, Zelong Liu, Gui-Song Xia, Bo Du .etc.|<http://arxiv.org/pdf/2502.00392v2>|[代码](https://github.com/sunzc-sunny/refdrone.); 构建了RefDrone基准数据集，提出NGDINO方法，有效解决无人机场景中指代表达理解难题。|
|🆕 发布|RetinaLogos: Fine-Grained Synthesis of High-Resolution Retinal Images Through Captions|视网膜Logo：通过标题进行高分辨率视网膜图像的精细合成|Junzhi Ning, Cheng Tang, Kaijin Zhou, Diping Song, Lihao Liu, Ming Hu, Wei Li, Yanzhou Su .etc.|<http://arxiv.org/pdf/2505.12887v1>|提出了一种基于描述的视网膜图像合成方法，有效缓解了高质量视网膜图像数据稀缺的问题。|
|🆕 发布|TeleOpBench: A Simulator-Centric Benchmark for Dual-Arm Dexterous Teleoperation|TeleOpBench：一个以模拟器为中心的双臂灵巧遥操作基准测试|Hangyu Li, Qin Zhao, Haoran Xu, Xinyu Jiang, Qingwei Ben, Feiyu Jia, Haoyu Zhao, Liang Xu .etc.|<http://arxiv.org/pdf/2505.12748v1>|TeleOpBench构建了一个针对双臂灵巧遥操作的高保真模拟器基准，以促进公平、可复现的系统比较。|

