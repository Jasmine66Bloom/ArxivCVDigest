## [UPDATED!] **2025-05-20** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Emerging Properties in Unified Multimodal Pretraining|统一多模态预训练中的新兴特性|Chaorui Deng, Deyao Zhu, Kunchang Li, Chenhui Gou, Feng Li, Zeyu Wang, Shu Zhong, Weihao Yu .etc.|<http://arxiv.org/pdf/2505.14683v1>|提出BAGEL模型，通过大规模多模态预训练，显著提升多模态理解和生成能力。|
|📝 更新|ReVLA: Reverting Visual Domain Limitation of Robotic Foundation Models|ReVLA：逆转机器人基础模型视觉领域局限性的方法|Sombit Dey, Jan-Nico Zaech, Nikolay Nikolov, Luc Van Gool, Danda Pani Paudel|<http://arxiv.org/pdf/2409.15250v3>|提出了一种通过模型融合的渐进式骨干反转方法，有效解决了视觉领域限制问题，显著提升了机器人视觉模型的泛...|
|📝 更新|Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model|广义少样本3D点云分割与视觉-语言模型|Zhaochong An, Guolei Sun, Yun Liu, Runjia Li, Junlin Han, Ender Konukoglu, Serge Belongie|<http://arxiv.org/pdf/2503.16282v2>|[代码](https://github.com/ZhaochongAn/GFS-VL); 提出了一种结合3D视觉语言模型和少量样本的3D点云分割框架，有效提升新类别识别能力。|
|📝 更新|Does Acceleration Cause Hidden Instability in Vision Language Models? Uncovering Instance-Level Divergence Through a Large-Scale Empirical Study|《加速是否导致视觉语言模型隐藏的不稳定性？通过大规模实证研究揭示实例级差异》|Yizheng Sun, Hao Li, Chang Xu, Hongpeng Zhou, Chenghua Lin, Riza Batista-Navarro, Jingyuan Sun|<http://arxiv.org/pdf/2503.06794v3>|揭示了视觉语言模型加速后实例级差异，强调需进行稳定性检查以确保可靠部署。|
|🆕 发布|Investigating and Enhancing the Robustness of Large Multimodal Models Against Temporal Inconsistency|探究并增强大型多模态模型对时间不一致性的鲁棒性|Jiafeng Liang, Shixin Jiang, Xuan Dong, Ning Wang, Zheng Chu, Hui Su, Jinlan Fu, Ming Liu .etc.|<http://arxiv.org/pdf/2505.14405v1>|提出TemRobBench评估LMMs时间分析鲁棒性，设计PanoDPO优化模型，提升其时间分析可靠...|
|📝 更新|Orthogonal Subspace Decomposition for Generalizable AI-Generated Image Detection|正交子空间分解用于泛化AI生成图像检测|Zhiyuan Yan, Jiangming Wang, Peng Jin, Ke-Yue Zhang, Chengchun Liu, Shen Chen, Taiping Yao, Shouhong Ding .etc.|<http://arxiv.org/pdf/2411.15633v4>|[代码](https://github.com/YZY-stack/Effort-AIGI-Detection); 通过正交子空间分解，有效缓解AI生成图像检测中的过拟合问题，提升泛化能力。|
|🆕 发布|Speculative Decoding Reimagined for Multimodal Large Language Models|多模态大型语言模型中的投机解码再构想|Luxi Lin, Zhihang Lin, Zhanpeng Zeng, Rongrong Ji|<http://arxiv.org/pdf/2505.14260v1>|[代码](https://github.com/Lyn-Lucy/MSD.); 提出MSD方法，针对多模态大语言模型加速推理，实现速度提升。|
|📝 更新|InternLM-XComposer2.5-Reward: A Simple Yet Effective Multi-Modal Reward Model|InternLM-XComposer2.5-Reward：一种简单而有效的多模态奖励模型|Yuhang Zang, Xiaoyi Dong, Pan Zhang, Yuhang Cao, Ziyu Liu, Shengyuan Ding, Shenxi Wu, Yubo Ma .etc.|<http://arxiv.org/pdf/2501.12368v2>|[代码](https://github.com/InternLM/InternLM-XComposer); 提出了一种简单有效的多模态奖励模型，提升视觉语言模型生成质量。|
|📝 更新|DragLoRA: Online Optimization of LoRA Adapters for Drag-based Image Editing in Diffusion Model|DragLoRA：基于拖动图像编辑的扩散模型中LoRA适配器的在线优化|Siwei Xia, Li Sun, Tiantian Sun, Qingli Li|<http://arxiv.org/pdf/2505.12427v2>|[代码](https://github.com/Sylvie-X/DragLoRA.); DragLoRA通过集成LoRA适配器和优化运动监督，显著提升了拖动式图像编辑的精度和效率。|
|🆕 发布|Generalizable Multispectral Land Cover Classification via Frequency-Aware Mixture of Low-Rank Token Experts|基于频率感知的低秩标记专家混合的多光谱土地覆盖分类的泛化|Xi Chen, Shen Yan, Juelin Zhu, Chen Chen, Yu Liu, Maojun Zhang|<http://arxiv.org/pdf/2505.14088v1>|提出了一种针对多光谱土地覆盖分类的新方法，通过频率感知的低秩专家混合模型有效应对光谱偏移问题。|
|📝 更新|LogicQA: Logical Anomaly Detection with Vision Language Model Generated Questions|逻辑QA：基于视觉语言模型生成问题的逻辑异常检测|Yejin Kwon, Daeun Moon, Youngje Oh, Hyunsoo Yoon|<http://arxiv.org/pdf/2503.20252v2>|LogicQA通过自动生成问题清单，实现无需训练和标注的逻辑异常检测，显著提升工业应用中的异常检测性...|
|📝 更新|Industrial Synthetic Segment Pre-training|工业合成段预训练|Shinichi Mae, Ryousuke Yamada, Hirokatsu Kataoka|<http://arxiv.org/pdf/2505.13099v2>|提出InsCore合成数据集，有效提升工业场景实例分割性能，无需真实图像或人工标注。|
|📝 更新|Differentially Private Synthetic Data via APIs 3: Using Simulators Instead of Foundation Model|通过APIs 3生成差分隐私合成数据：使用模拟器而非基础模型|Zinan Lin, Tadas Baltrusaitis, Wenyu Wang, Sergey Yekhanin|<http://arxiv.org/pdf/2502.05505v3>|[代码](https://github.com/microsoft/DPSDA.); 提出了一种利用模拟器而非基础模型生成差分隐私合成数据的新方法，显著提升了数据合成效率和分类准确率。|
|📝 更新|Open3DVQA: A Benchmark for Comprehensive Spatial Reasoning with Multimodal Large Language Model in Open Space|开放3DVQA：开放空间中多模态大型语言模型全面空间推理基准|Weichen Zhang, Zile Zhou, Zhiheng Zheng, Chen Gao, Jinqiang Cui, Yong Li, Xinlei Chen, Xiao-Ping Zhang|<http://arxiv.org/pdf/2503.11094v2>|[代码](https://github.com/WeichenZh/Open3DVQA.); 构建了Open3DVQA基准，全面评估了多模态大语言模型在开放3D空间中的空间推理能力。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UniGen: Enhanced Training & Test-Time Strategies for Unified Multimodal Understanding and Generation|UniGen：统一多模态理解和生成增强训练与测试时策略|Rui Tian, Mingfei Gao, Mingze Xu, Jiaming Hu, Jiasen Lu, Zuxuan Wu, Yinfei Yang, Afshin Dehghan|<http://arxiv.org/pdf/2505.14682v1>|UniGen通过创新训练和测试策略，显著提升了统一多模态大语言模型在图像理解和生成方面的性能。|
|🆕 发布|Beyond Words: Multimodal LLM Knows When to Speak|超越文字：多模态大型语言模型知道何时开口|Zikai Liao, Yi Ouyang, Yi-Lun Lee, Chen-Ping Yu, Yi-Hsuan Tsai, Zhaozheng Yin|<http://arxiv.org/pdf/2505.14654v1>|提出了一种基于多模态LLM的实时对话反应预测模型，显著提升了对话的及时性和自然度。|
|📝 更新|Multimodal Fusion of Glucose Monitoring and Food Imagery for Caloric Content Prediction|多模态融合血糖监测与食物图像进行卡路里含量预测|Adarsh Kumar|<http://arxiv.org/pdf/2505.09018v2>|该论文提出了一种融合血糖监测、人口统计和食物图像的多模态深度学习框架，显著提升了卡路里摄入量的预测准...|
|📝 更新|SG-Reg: Generalizable and Efficient Scene Graph Registration|SG-Reg：可泛化和高效的场景图配准|Chuhao Liu, Zhijian Qiao, Jieqi Shi, Ke Wang, Peize Liu, Shaojie Shen|<http://arxiv.org/pdf/2504.14440v2>|[代码](http://github.com/HKUST-Aerial-Robotics/SG-Reg); 设计了一种高效且通用的场景图注册方法，显著提升了多智能体任务中的注册成功率。|
|🆕 发布|Diving into the Fusion of Monocular Priors for Generalized Stereo Matching|深入单目先验融合的广义立体匹配|Chengtang Yao, Lidong Yu, Zhidan Liu, Jiaxi Zeng, Yuwei Wu, Yunde Jia|<http://arxiv.org/pdf/2505.14414v1>|提出了一种融合视觉基础模型单目先验的方法，有效提升立体匹配在复杂场景下的泛化能力。|
|🆕 发布|Vision-Language Modeling Meets Remote Sensing: Models, Datasets and Perspectives|视觉-语言建模遇见遥感：模型、数据集与展望|Xingxing Weng, Chao Pang, Gui-Song Xia|<http://arxiv.org/pdf/2505.14361v1>|该论文综述了视觉语言模型在遥感领域的应用，提出了基于大规模图像-文本对预训练和任务特定数据微调的模型...|
|📝 更新|Iterative Tool Usage Exploration for Multimodal Agents via Step-wise Preference Tuning|迭代工具使用探索：通过逐步偏好调整的多模态智能体|Pengxiang Li, Zhi Gao, Bofei Zhang, Yapeng Mi, Xiaojian Ma, Chenrui Shi, Tao Yuan, Yuwei Wu .etc.|<http://arxiv.org/pdf/2504.21561v3>|提出了一种无需人工标注数据的迭代工具使用探索方法，使多模态智能体自主发现有效工具使用策略。|
|📝 更新|Customizing Visual-Language Foundation Models for Multi-modal Anomaly Detection and Reasoning|定制视觉-语言基础模型以实现多模态异常检测与推理|Xiaohao Xu, Yunkang Cao, Huaxin Zhang, Nong Sang, Xiaonan Huang|<http://arxiv.org/pdf/2403.11083v3>|[代码](https://github.com/Xiaohao-Xu/Customizable-VLM); 构建通用视觉语言基础模型，实现多模态异常检测与推理。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SpaceJAM: a Lightweight and Regularization-free Method for Fast Joint Alignment of Images|空间联合对齐：一种轻量级且无需正则化的快速图像联合对齐方法|Nir Barel, Ron Shapira Weber, Nir Mualem, Shahaf E. Finder, Oren Freifeld|<http://arxiv.org/pdf/2407.11850v2>|[代码](https://bgu-cs-vil.github.io/SpaceJAM); SpaceJAM提出了一种轻量级、无需正则化的图像联合对齐方法，大幅提升速度并降低计算需求。|
|🆕 发布|FlashKAT: Understanding and Addressing Performance Bottlenecks in the Kolmogorov-Arnold Transformer|FlashKAT：理解并解决Kolmogorov-Arnold变换中的性能瓶颈|Matthew Raffel, Lizhong Chen|<http://arxiv.org/pdf/2505.13813v1>|[代码](https://github.com/OSU-STARLAB/FlashKAT.); FlashKAT通过优化梯度累积，显著提升了KAT的训练速度。|
|📝 更新|A Separable Self-attention Inspired by the State Space Model for Computer Vision|基于状态空间模型的计算机视觉可分离自注意力机制|Juntao Zhang, Shaogeng Liu, Kun Bian, You Zhou, Pei Zhang, Jianning Liu, Jun Zhou, Bingyan Liu|<http://arxiv.org/pdf/2501.02040v2>|[代码](https://github.com/yws-wxs/VMINet.); 提出了一种基于Mamba模型的分离自注意力机制，显著提升了计算机视觉任务的性能。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|On the Generalizability of Foundation Models for Crop Type Mapping|关于作物类型映射基础模型泛化能力的探讨|Yi-Chia Chang, Adam J. Stewart, Favyen Bastani, Piper Wolters, Shreya Kannan, George R. Huber, Jingtong Wang, Arindam Banerjee|<http://arxiv.org/pdf/2409.09451v4>|评估了三种地球观测基础模型在跨大陆的作物分类任务上的泛化能力，发现针对特定卫星图像数据预训练的模型效...|
|📝 更新|Spectral-Spatial Self-Supervised Learning for Few-Shot Hyperspectral Image Classification|光谱-空间自监督学习在少量样本高光谱图像分类中的应用|Wenchen Chen, Yanmei Zhang, Zhongwei Xiao, Jianping Chu, Xingbo Wang|<http://arxiv.org/pdf/2505.12482v2>|提出了一种结合光谱-空间自监督学习和少样本学习的超光谱图像分类方法，有效提升了分类性能。|
|🆕 发布|ReservoirTTA: Prolonged Test-time Adaptation for Evolving and Recurring Domains|水库TTA：针对演变和重复领域的长期测试时自适应|Guillaume Vray, Devavrat Tomar, Xufeng Gao, Jean-Philippe Thiran, Evan Shelhamer, Behzad Bozorgtabar|<http://arxiv.org/pdf/2505.14511v1>|ReservoirTTA通过维护模型库，实现持续变化的测试域下的鲁棒适应，有效克服了单一模型适应的局...|
|🆕 发布|Domain Adaptation for Multi-label Image Classification: a Discriminator-free Approach|多标签图像分类的领域自适应：一种无判别器方法|Inder Pal Singh, Enjie Ghorbel, Anis Kacem, Djamila Aouada|<http://arxiv.org/pdf/2505.14333v1>|[代码](https://github.com/cvi2snt/DDA-MLIC.); 提出了一种无需判别器的对抗性方法DDA-MLIC，有效解决了多标签图像分类中的领域自适应问题。|
|🆕 发布|Accuracy and Fairness of Facial Recognition Technology in Low-Quality Police Images: An Experiment With Synthetic Faces|低质量警察图像中面部识别技术的准确性和公平性：合成人脸实验|Maria Cuellar, Hon Kiu, To, Arush Mehrotra|<http://arxiv.org/pdf/2505.14320v1>|研究低质量图像下人脸识别技术的准确性和公平性，通过合成人脸实验评估其性能。|
|🆕 发布|Every Pixel Tells a Story: End-to-End Urdu Newspaper OCR|每个像素都在讲述一个故事：端到端乌尔都文报纸OCR|Samee Arif, Sualeha Farid|<http://arxiv.org/pdf/2505.13943v1>|提出了一种针对乌尔都文报纸的端到端OCR解决方案，有效处理复杂布局和低分辨率扫描。|
|🆕 发布|Exploring Image Quality Assessment from a New Perspective: Pupil Size|从瞳孔大小新视角探索图像质量评估|Yixuan Gao, Xiongkuo Min, Guangtao Zhai|<http://arxiv.org/pdf/2505.13841v1>|从瞳孔大小视角研究图像质量评估，揭示视觉注意力机制与图像质量关系。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Instance Segmentation for Point Sets|点集的实例分割|Abhimanyu Talwar, Julien Laasri|<http://arxiv.org/pdf/2505.14583v1>|提出了一种基于采样和近邻插值的点集实例分割方法，有效降低内存消耗并提升速度。|
|📝 更新|Bayesian Deep Learning Approaches for Uncertainty-Aware Retinal OCT Image Segmentation for Multiple Sclerosis|基于贝叶斯深度学习的多发性硬化症视网膜OCT图像分割的不确定性感知方法|Samuel T. M. Ball|<http://arxiv.org/pdf/2505.12061v2>|利用贝叶斯深度学习提供不确定性估计，提高视网膜OCT图像分割的准确性和可靠性。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Decoupling Classifier for Boosting Few-shot Object Detection and Instance Segmentation|解耦分类器用于提升小样本目标检测与实例分割|Bin-Bin Gao, Xiaochen Chen, Zhongyi Huang, Congchong Nie, Jun Liu, Jinxiang Lai, Guannan Jiang, Xi Wang .etc.|<http://arxiv.org/pdf/2505.14239v1>|[代码](https://csgaobb.github.io/Projects); 提出一种解耦分类器，有效提升少量样本下的目标检测和实例分割性能。|
|🆕 发布|Scaling Vision Mamba Across Resolutions via Fractal Traversal|通过分形遍历在多个分辨率上扩展视觉Mamba|Bo Li, Haoke Xiao, Lv Tang|<http://arxiv.org/pdf/2505.14062v1>|提出FractalMamba++，通过分形遍历和跨状态路由，提升视觉模型在不同分辨率下的适应性和泛化...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Intra-class Patch Swap for Self-Distillation|类内补丁交换用于自蒸馏|Hongjun Choi, Eun Som Jeon, Ankita Shukla, Pavan Turaga|<http://arxiv.org/pdf/2505.14124v1>|[代码](https://github.com/hchoi71/Intra-class-Patch-Swap.); 检测领域，提出了一种基于类内补丁交换的自蒸馏方法，有效提升了模型性能。|
|🆕 发布|InstanceBEV: Unifying Instance and BEV Representation for Global Modeling|实例BEV：统一实例和BEV表示以实现全局建模|Feng Li, Kun Xu, Zhaoyue Wang, Yunduan Cui, Mohammad Masum Billah, Jia Liu|<http://arxiv.org/pdf/2505.13817v1>|提出InstanceBEV，首次为BEV引入实例级降维，实现高效全局建模。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AKRMap: Adaptive Kernel Regression for Trustworthy Visualization of Cross-Modal Embeddings|自适应核回归：跨模态嵌入的可信可视化|Yilin Ye, Junchao Huang, Xingchen Zeng, Jiazhi Xia, Wei Zeng|<http://arxiv.org/pdf/2505.14664v1>|[代码](https://github.com/yilinye/AKRMap.); AKRMap通过自适应核回归，提高了跨模态嵌入的可信可视化准确性。|
|📝 更新|StainDiffuser: MultiTask Dual Diffusion Model for Virtual Staining|染色扩散器：用于虚拟染色的多任务双重扩散模型|Tushar Kataria, Beatrice Knudsen, Shireen Y. Elhabian|<http://arxiv.org/pdf/2403.11340v2>|提出了一种多任务扩散模型，通过少量数据实现虚拟染色，提高诊断准确性和效率。|
|🆕 发布|Neural Inverse Scattering with Score-based Regularization|基于得分正则化的神经逆散射|Yuan Gao, Wenhan Guo, Yu Sun|<http://arxiv.org/pdf/2505.14560v1>|提出了一种结合去噪评分函数的神经场方法，有效提升了逆散射成像质量。|
|🆕 发布|Dynadiff: Single-stage Decoding of Images from Continuously Evolving fMRI|动态差异：从持续演变的fMRI中单阶段解码图像|Marlène Careil, Yohann Benchetrit, Jean-Rémi King|<http://arxiv.org/pdf/2505.14556v1>|提出Dynadiff模型，实现单阶段从动态fMRI记录中重建图像，突破时间分辨率限制。|
|🆕 发布|SparC: Sparse Representation and Construction for High-Resolution 3D Shapes Modeling|稀疏表示与构建：高分辨率3D形状建模|Zhihao Li, Yufei Wang, Heliang Zheng, Yihao Luo, Bihan Wen|<http://arxiv.org/pdf/2505.14521v1>|SparC通过结合稀疏表示和新型编码器，实现了高分辨率3D形状的无损重建。|
|🆕 发布|Enhancing Interpretability of Sparse Latent Representations with Class Information|增强稀疏潜在表示的可解释性：利用类别信息|Farshad Sangari Abiz, Reshad Hosseini, Babak N. Araabi|<http://arxiv.org/pdf/2505.14476v1>|通过引入新损失函数，确保同一类样本的潜在空间中活跃维度一致，从而提升稀疏潜在表示的可解释性。|
|📝 更新|A Unified Framework for Event-based Frame Interpolation with Ad-hoc Deblurring in the Wild|基于现场事件帧插值与野外即兴去模糊的统一框架|Lei Sun, Daniel Gehrig, Christos Sakaridis, Mathias Gehrig, Jingyun Liang, Peng Sun, Zhijie Xu, Kaiwei Wang .etc.|<http://arxiv.org/pdf/2301.05191v3>|[代码](https://github.com/AHupuJR/REFID.); 检测并去除视频中的运动模糊，同时实现帧插值和去模糊。|
|📝 更新|Diffusion Model as a Noise-Aware Latent Reward Model for Step-Level Preference Optimization|扩散模型作为噪声感知的潜在奖励模型用于步级偏好优化|Tao Zhang, Cheng Da, Kun Ding, Huan Yang, Kun Jin, Yan Li, Tingting Gao, Di Zhang .etc.|<http://arxiv.org/pdf/2502.01051v3>|[代码](https://github.com/Kwai-Kolors/LPO.); 提出了一种基于扩散模型的噪声感知潜在奖励模型，用于优化图像生成中的偏好。|
|🆕 发布|Vid2World: Crafting Video Diffusion Models to Interactive World Models|视频到世界：构建视频扩散模型以交互式世界模型|Siqiao Huang, Jialong Wu, Qixing Zhou, Shangchen Miao, Mingsheng Long|<http://arxiv.org/pdf/2505.14357v1>|将预训练视频扩散模型转化为交互式世界模型，提升复杂环境中的决策效率。|
|📝 更新|CRCE: Coreference-Retention Concept Erasure in Text-to-Image Diffusion Models|CRCE：文本到图像扩散模型中的核心指代保留概念消除|Yuyang Xue, Edward Moroshko, Feng Chen, Jingyu Sun, Steven McDonagh, Sotirios A. Tsaftaris|<http://arxiv.org/pdf/2503.14232v2>|CRCE通过利用大型语言模型识别应删除和保留的概念，实现了更精确的文本到图像扩散模型中的概念擦除。|
|📝 更新|Unified Continuous Generative Models|统一连续生成模型|Peng Sun, Yi Jiang, Tao Lin|<http://arxiv.org/pdf/2505.07447v2>|[代码](https://github.com/LINs-lab/UCGM.); 提出统一框架，实现多步与少步连续生成模型的高效训练与采样，显著提升生成性能。|
|🆕 发布|Instructing Text-to-Image Diffusion Models via Classifier-Guided Semantic Optimization|通过分类器引导的语义优化指导文本到图像的扩散模型|Yuanyuan Chang, Yinghua Yao, Tao Qin, Mengmeng Wang, Ivor Tsang, Guang Dai|<http://arxiv.org/pdf/2505.14254v1>|通过属性分类器引导语义优化，实现无需文本提示的文本到图像模型编辑。|
|📝 更新|Breaking Language Barriers in Visual Language Models via Multilingual Textual Regularization|通过多语言文本正则化打破视觉语言模型的语言障碍|Iñigo Pikabea, Iñaki Lacunza, Oriol Pareras, Carlos Escolano, Aitor Gonzalez-Agirre, Javier Hernando, Marta Villegas|<http://arxiv.org/pdf/2503.22577v2>|提出了一种通过多语言文本正则化策略，解决视觉语言模型跨语言响应准确度问题的新方法。|
|🆕 发布|From stability of Langevin diffusion to convergence of proximal MCMC for non-log-concave sampling|从Langevin扩散的稳定性到非对数凹采样中近端MCMC的收敛性|Marien Renaud, Valentin De Bortoli, Arthur Leclaire, Nicolas Papadakis|<http://arxiv.org/pdf/2505.14177v1>|证明了PSGLA在非凸势函数下的收敛性，提高了后验采样速度。|
|📝 更新|Attentive Eraser: Unleashing Diffusion Model's Object Removal Potential via Self-Attention Redirection Guidance|注意擦除器：通过自注意力重定向引导释放扩散模型的对象去除潜力|Wenhao Sun, Benlei Cui, Xue-Mei Dong, Jingqun Tang|<http://arxiv.org/pdf/2412.12974v5>|[代码](https://github.com/Anonym0u3/AttentiveEraser.); 提出了一种基于自注意力重定向的扩散模型，有效解决图像中物体去除问题。|
|📝 更新|Structure-Preserving Zero-Shot Image Editing via Stage-Wise Latent Injection in Diffusion Models|结构保持零样本图像编辑：通过扩散模型中的阶段式潜在注入|Dasol Jeong, Donggoo Kang, Jiwon Park, Hyebean Lee, Joonki Paik|<http://arxiv.org/pdf/2504.15723v2>|提出了一种无需微调的零样本图像编辑框架，通过分阶段潜在注入和跨注意力机制实现结构保持和语义对齐。|
|📝 更新|Swin DiT: Diffusion Transformer using Pseudo Shifted Windows|斯温DiT：使用伪平移窗口的扩散Transformer|Jiafu Wu, Yabiao Wang, Jian Li, Jinlong Peng, Yun Cao, Chengjie Wang, Jiangning Zhang|<http://arxiv.org/pdf/2505.13219v2>|[代码](https://github.com/wujiafu007/Swin-DiT); 提出PSWA和PCCA策略，有效降低DiT计算成本，显著提升图像生成性能。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UniCTokens: Boosting Personalized Understanding and Generation via Unified Concept Tokens|统一概念标记：通过统一概念标记提升个性化理解和生成|Ruichuan An, Sihan Yang, Renrui Zhang, Zijun Shen, Ming Lu, Gaole Dai, Hao Liang, Ziyu Guo .etc.|<http://arxiv.org/pdf/2505.14671v1>|[代码](https://github.com/arctanxarc/UniCTokens); UniCTokens通过统一概念标记，提升个性化理解和生成能力，实现知识驱动生成。|
|🆕 发布|Training-Free Watermarking for Autoregressive Image Generation|无训练水印用于自回归图像生成|Yu Tong, Zihao Pan, Shuai Yang, Kaiyang Zhou|<http://arxiv.org/pdf/2505.14673v1>|提出IndexMark，为自回归图像生成模型提供无需训练的隐形水印技术。|
|🆕 发布|Grouping First, Attending Smartly: Training-Free Acceleration for Diffusion Transformers|首先分组，然后智能关注：扩散变换器的无监督加速|Sucheng Ren, Qihang Yu, Ju He, Alan Yuille, Liang-Chieh Chen|<http://arxiv.org/pdf/2505.14687v1>|提出了一种基于分组和智能注意加速的扩散Transformer，大幅提升图像和视频生成速度。|
|🆕 发布|CAD-Coder: An Open-Source Vision-Language Model for Computer-Aided Design Code Generation|CAD-Coder：一个开源的计算机辅助设计代码生成视觉语言模型|Anna C. Doris, Md Ferdous Alam, Amin Heyrani Nobari, Faez Ahmed|<http://arxiv.org/pdf/2505.14646v1>|[代码](https://github.com/anniedoris/CAD-Coder.); CAD-Coder通过视觉语言模型直接从图像生成可编辑的CAD代码，提高了设计效率和准确性。|
|📝 更新|Automatic Synthetic Data and Fine-grained Adaptive Feature Alignment for Composed Person Retrieval|自动合成数据与细粒度自适应特征对齐的复合人物检索|Delong Liu, Haiwen Li, Zhaohui Hou, Zhicheng Zhao, Fei Su, Yuan Dong|<http://arxiv.org/pdf/2311.16515v4>|[代码](https://github.com/Delong-liu-bupt/Composed_Person_Retrieval.); 提出了一种结合视觉和文本查询的合成数据生成与特征对齐方法，有效提升了组合人物检索性能。|
|🆕 发布|Neural Video Compression with Context Modulation|神经视频压缩与上下文调制|Chuanbo Tang, Zhuoyuan Li, Yifan Bian, Li Li, Dong Liu|<http://arxiv.org/pdf/2505.14541v1>|[代码](https://github.com/Austin4USTC/DCMVC.); 通过调节时间上下文并利用参考帧信息，该论文提出了一种提高视频压缩效率的方法。|
|🆕 发布|Personalize Your Gaussian: Consistent 3D Scene Personalization from a Single Image|个性化高斯：从单张图像实现一致的3D场景个性化|Yuxuan Wang, Xuanyu Yi, Qingshan Xu, Yuan Zhou, Long Chen, Hanwang Zhang|<http://arxiv.org/pdf/2505.14537v1>|[代码](https://github.com/Yuxuan-W/CP-GS.); 提出了一种从单张图像出发，实现3D场景个性化定制的框架，有效缓解视角偏差，实现高质量个性化。|
|📝 更新|Evaluating the Correctness of Inference Patterns Used by LLMs for Judgment|评估大型语言模型用于判断的推理模式正确性|Lu Chen, Yuxuan Huang, Yixing Li, Dongrui Liu, Qihan Ren, Shuai Zhao, Kun Kuang, Zilong Zheng .etc.|<http://arxiv.org/pdf/2410.09083v2>|提出评估LLM推理模式正确性的方法，揭示其看似正确输出背后的潜在错误逻辑。|
|📝 更新|Towards Rich Emotions in 3D Avatars: A Text-to-3D Avatar Generation Benchmark|迈向丰富情感的3D虚拟形象：文本到3D虚拟形象生成基准|Haidong Xu, Meishan Zhang, Hao Ju, Zhedong Zheng, Erik Cambria, Min Zhang, Hao Fei|<http://arxiv.org/pdf/2412.02508v2>|提出了一种基于文本生成3D表情的基准和模型，以提升3D情感虚拟人渲染质量。|
|📝 更新|Online Iterative Self-Alignment for Radiology Report Generation|标题翻译结果：  在线迭代自对齐用于放射学报告生成|Ting Xiao, Lei Shi, Yang Zhang, HaoFeng Yang, Zhe Wang, Chenjia Bai|<http://arxiv.org/pdf/2505.11983v2>|提出OISA方法，通过迭代多目标优化显著提升放射报告生成模型性能。|
|🆕 发布|Video Compression Commander: Plug-and-Play Inference Acceleration for Video Large Language Models|视频压缩指挥官：视频大型语言模型即插即用推理加速|Xuyang Liu, Yiyu Wang, Junpeng Ma, Linfeng Zhang|<http://arxiv.org/pdf/2505.14454v1>|[代码](https://github.com/xuyang-liu16/VidCom2.); 提出“视频压缩指挥官”框架，有效压缩视频大语言模型，提升效率和性能。|
|🆕 发布|VisualQuality-R1: Reasoning-Induced Image Quality Assessment via Reinforcement Learning to Rank|视觉质量-R1：通过强化学习排序的推理诱导图像质量评估|Tianhe Wu, Jian Zou, Jie Liang, Lei Zhang, Kede Ma|<http://arxiv.org/pdf/2505.14460v1>|提出一种基于强化学习的视觉质量评估模型，通过推理能力提升图像质量评价准确性。|
|📝 更新|IP-Prompter: Training-Free Theme-Specific Image Generation via Dynamic Visual Prompting|IP-Prompter：通过动态视觉提示进行免训练的主题特定图像生成|Yuxin Zhang, Minyan Luo, Weiming Dong, Xiao Yang, Haibin Huang, Chongyang Ma, Oliver Deussen, Tong-Yee Lee .etc.|<http://arxiv.org/pdf/2501.15641v2>|提出IP-Prompter，通过动态视觉提示实现无需训练的主题特定图像生成。|
|📝 更新|LED: LLM Enhanced Open-Vocabulary Object Detection without Human Curated Data Generation|LED：基于LLM的无需人工生成数据的开放词汇目标检测|Yang Zhou, Shiyu Zhao, Yuxiao Chen, Zhenting Wang, Can Jin, Dimitris N. Metaxas|<http://arxiv.org/pdf/2503.13794v2>|提出LED方法，通过融合LLM隐藏状态增强开放词汇目标检测，无需人工生成数据。|
|🆕 发布|Handloom Design Generation Using Generative Networks|手工织品设计生成：基于生成网络的实现|Rajat Kanti Bhattacharjee, Meghali Nandi, Amrit Jha, Gunajit Kalita, Ferdous Ahmed Barbhuiya|<http://arxiv.org/pdf/2505.14330v1>|利用生成网络和风格迁移算法，该论文提出了一种手织布料设计生成方法，并构建了新的数据集。|
|🆕 发布|Replace in Translation: Boost Concept Alignment in Counterfactual Text-to-Image|《在反事实文本到图像中提升概念对齐》|Sifan Li, Ming Tao, Hao Zhao, Ling Shao, Hao Tang|<http://arxiv.org/pdf/2505.14341v1>|提出ELNP策略，通过语言模型指导，提升反事实文本到图像中概念对齐。|
|🆕 发布|RADAR: Enhancing Radiology Report Generation with Supplementary Knowledge Injection|雷达：通过补充知识注入增强放射学报告生成|Wenjun Hou, Yi Cheng, Kaishuai Xu, Heng Li, Yan Hu, Wenjie Li, Jiang Liu|<http://arxiv.org/pdf/2505.14318v1>|RADAR通过结合LLM内部知识和外部补充知识，提升了放射报告生成的准确性和信息量。|
|📝 更新|CompBench: Benchmarking Complex Instruction-guided Image Editing|CompBench：复杂指令引导的图像编辑基准测试|Bohan Jia, Wenxuan Huang, Yuntian Tang, Junbo Qiao, Jincheng Liao, Shaosheng Cao, Fei Zhao, Zhaopeng Feng .etc.|<http://arxiv.org/pdf/2505.12200v2>|[代码](https://comp-bench.github.io/.); 构建了CompBench基准，以评估复杂指令引导的图像编辑模型的精确操控能力。|
|🆕 发布|ReactDiff: Latent Diffusion for Facial Reaction Generation|ReactDiff：面部反应生成的潜在扩散|Jiaming Li, Sheng Wang, Xin Wang, Yitao Zhu, Honglin Xiong, Zixu Zhuang, Qian Wang|<http://arxiv.org/pdf/2505.14151v1>|[代码](https://github.com/Hunan-Tiger/ReactDiff); ReactDiff通过融合多模态Transformer和条件扩散，在潜在空间中生成逼真且多样化的面部...|
|📝 更新|CraftsMan3D: High-fidelity Mesh Generation with 3D Native Generation and Interactive Geometry Refiner|CraftsMan3D：基于3D原生生成和交互式几何精修的高保真网格生成|Weiyu Li, Jiarui Liu, Rui Chen, Yixun Liang, Xuelin Chen, Ping Tan, Xiaoxiao Long|<http://arxiv.org/pdf/2405.14979v2>|[代码](https://github.com/wyysf-98/CraftsMan); CraftsMan3D通过3D原生生成和交互式几何细化，实现了高效生成高质量3D模型。|
|📝 更新|Conjuring Positive Pairs for Efficient Unification of Representation Learning and Image Synthesis|召唤正对以高效统一表征学习和图像合成|Imanol G. Estepa, Jesús M. Rodríguez-de-Vera, Ignacio Sarasúa, Bhalaji Nagarajan, Petia Radeva|<http://arxiv.org/pdf/2503.15060v3>|提出Sorcen，一种无需外部标记器的统一自监督学习框架，有效融合了表征学习和图像合成。|
|🆕 发布|Large-Scale Multi-Character Interaction Synthesis|大规模多角色交互合成|Ziyi Chang, He Wang, George Alex Koulieris, Hubert P. H. Shum|<http://arxiv.org/pdf/2505.14087v1>|提出了一种生成大规模多角色互动的新方法，通过协调空间和过渡规划网络实现角色间的自然互动和协调。|
|📝 更新|DiffDesign: Controllable Diffusion with Meta Prior for Efficient Interior Design Generation|DiffDesign：基于元先验的可控扩散，用于高效室内设计生成|Yuxuan Yang, Tao Geng, Jingyao Wang, Changwen Zheng, Fuchun Sun|<http://arxiv.org/pdf/2411.16301v2>|DiffDesign通过元先验和可控制扩散模型，高效生成满足多样化需求的室内设计图。|
|📝 更新|MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation|MTVCrafter：面向开放世界人类图像动画的4D运动标记化|Yanbo Ding, Xirui Hu, Zhizhi Guo, Yali Wang|<http://arxiv.org/pdf/2505.10238v3>|[代码](https://github.com/DINGYANB/MTVCrafter.); MTVCrafter通过直接建模4D运动序列，为开放世界人类图像动画提供更灵活和可控的解决方案。|
|📝 更新|Rethinking Text-Promptable Surgical Instrument Segmentation with Robust Framework|重新思考基于文本提示的手术器械分割的鲁棒框架|Tae-Min Choi, Juyoun Park|<http://arxiv.org/pdf/2411.12199v3>|提出了一种应对手术器械分割中未知和动态器械的鲁棒文本提示分割方法，有效减少错误分割。|
|📝 更新|Diffusion based Semantic Outlier Generation via Nuisance Awareness for Out-of-Distribution Detection|基于扩散的语义异常值生成：通过噪声意识进行分布外检测|Suhee Yoon, Sanghyu Yoon, Ye Seul Sim, Sungik Choi, Kyungeun Lee, Hye-Seung Cho, Hankook Lee, Woohyung Lim|<http://arxiv.org/pdf/2408.14841v2>|提出一种通过扩散模型生成语义异常值的方法，有效提升异常检测性能。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A General Framework for Group Sparsity in Hyperspectral Unmixing Using Endmember Bundles|基于端元捆绑的 hyperspectral unmixing 中组稀疏性的通用框架|Gokul Bhusal, Yifei Lou, Cristina Garcia-Cardona, Ekaterina Merkurjev|<http://arxiv.org/pdf/2505.14634v1>|提出了一种利用端元束和组稀疏性的超光谱解混新框架，有效提升了解混精度。|
|🆕 发布|KERL: Knowledge-Enhanced Personalized Recipe Recommendation using Large Language Models|知识增强的大语言模型个性化菜谱推荐：KERL|Fnu Mohbat, Mohammed J Zaki|<http://arxiv.org/pdf/2505.14629v1>|[代码](https://github.com/mohbattharani/KERL.); 提出一种结合知识图谱和大型语言模型的个性化食谱推荐系统，显著提升食谱生成和营养分析效果。|
|📝 更新|Technical Report: Quantifying and Analyzing the Generalization Power of a DNN|技术报告：量化与分析深度神经网络泛化能力|Yuxuan He, Junpeng Zhang, Lei Cheng, Hongyuan Zhang, Quanshi Zhang|<http://arxiv.org/pdf/2505.06993v2>|提出了一种分析DNN泛化能力的方法，揭示了训练过程中泛化与不泛化交互的动态变化。|
|🆕 发布|Towards Generating Realistic Underwater Images|朝着生成逼真水下图像的研究|Abdul-Kazeem Shamba|<http://arxiv.org/pdf/2505.14296v1>|提出了一种基于对比学习和生成对抗网络的方法，有效生成逼真的水下图像。|
|📝 更新|Cross-Image Contrastive Decoding: Precise, Lossless Suppression of Language Priors in Large Vision-Language Models|跨图像对比解码：在大视觉-语言模型中精确、无损抑制语言先验|Jianfei Zhao, Feng Zhang, Xin Sun, Chong Feng|<http://arxiv.org/pdf/2505.10634v3>|提出CICD方法，通过跨图像对比解码抑制大视觉语言模型中的语言先验，减少幻觉并保持语言流畅性。|
|📝 更新|Learning Coherent Matrixized Representation in Latent Space for Volumetric 4D Generation|在潜在空间中学习体素4D生成的连贯矩阵化表示|Qitong Yang, Mingtao Feng, Zijie Wu, Shijie Sun, Weisheng Dong, Yaonan Wang, Ajmal Mian|<http://arxiv.org/pdf/2403.13238v2>|提出了一种基于潜在空间和矩阵化表示的4D体积生成方法，有效提升了3D形状和动画质量。|
|🆕 发布|EGFormer: Towards Efficient and Generalizable Multimodal Semantic Segmentation|EGFormer：迈向高效且可泛化的多模态语义分割|Zelin Zhang, Tao Zhang, KediLI, Xu Zheng|<http://arxiv.org/pdf/2505.14014v1>|EGFormer通过灵活整合任意数量模态并显著减少模型参数和推理时间，实现了高效且通用的多模态语义分...|
|🆕 发布|LoVR: A Benchmark for Long Video Retrieval in Multimodal Contexts|LoVR：多模态场景下长视频检索基准|Qifeng Cai, Hao Liang, Hejun Dong, Meiyi Qiang, Ruichuan An, Zhaoyang Han, Zhengzhou Zhu, Bin Cui .etc.|<http://arxiv.org/pdf/2505.13928v1>|[代码](https://github.com/TechNomad-ds/LoVR-benchmark); 构建了针对长视频检索的LoVR基准，提出高效字幕生成框架和语义融合方法，提升检索准确性。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dual Data Alignment Makes AI-Generated Image Detector Easier Generalizable|双数据对齐使AI生成图像检测器更容易泛化|Ruoxin Chen, Junwei Xi, Zhiyuan Yan, Ke-Yue Zhang, Shuang Wu, Jingyi Xie, Xu Chen, Lei Xu .etc.|<http://arxiv.org/pdf/2505.14359v1>|提出Dual Data Alignment方法，通过像素和频率域对齐，提升AI图像检测器泛化能力。|
|📝 更新|A Survey on Future Frame Synthesis: Bridging Deterministic and Generative Approaches|未来帧合成综述：连接确定性和生成性方法|Ruibo Ming, Zhewei Huang, Jingwei Wu, Zhuoxuan Ju, Jianming Hu, Lihui Peng, Shuchang Zhou|<http://arxiv.org/pdf/2401.14718v6>|综述未来帧合成，探讨从确定性到生成式方法的转变，强调生成模型在生成逼真预测中的重要性。|
|🆕 发布|Unify Graph Learning with Text: Unleashing LLM Potentials for Session Search|统一图学习与文本：释放大型语言模型在会话搜索中的潜力|Songhao Wu, Quan Tu, Hong Liu, Jia Xu, Zhongyi Liu, Guannan Zhang, Ran Wang, Xiuying Chen .etc.|<http://arxiv.org/pdf/2505.14156v1>|提出一种结合文本和图学习的方法，利用LLM提升会话搜索性能。|
|📝 更新|Multi-granular body modeling with Redundancy-Free Spatiotemporal Fusion for Text-Driven Motion Generation|基于冗余消除时空融合的多粒度人体建模用于文本驱动运动生成|Xingzu Zhan, Chen Xie, Honghang Chen, Haoran Sun, Xiaochun Mai|<http://arxiv.org/pdf/2503.06897v2>|提出HiSTF Mamba框架，通过时空融合生成与文本高度匹配的运动。|
|🆕 发布|LMP: Leveraging Motion Prior in Zero-Shot Video Generation with Diffusion Transformer|LMP：利用运动先验的扩散Transformer在零样本视频生成中的应用|Changgu Chen, Xiaoyan Yang, Junwei Shu, Changbo Wang, Yang Li|<http://arxiv.org/pdf/2505.14167v1>|[代码](https://vpx-ecnu.github.io/LMP-Website); 提出LMP框架，利用运动先验在零样本视频生成中实现复杂动作控制。|
|🆕 发布|Hunyuan-Game: Industrial-grade Intelligent Game Creation Model|Hunyuan-Game：工业级智能游戏创作模型|Ruihuang Li, Caijin Zhou, Shoujian Zheng, Jianxiang Lu, Jiabin Huang, Comi Chen, Junshu Tang, Guangzheng Xu .etc.|<http://arxiv.org/pdf/2505.14135v1>|Hunyuan-Game通过构建图像和视频生成模型，实现高质量游戏内容的高效创作。|
|🆕 发布|Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting|海豚：通过异构锚提示进行文档图像解析|Hao Feng, Shu Wei, Xiang Fei, Wei Shi, Yingdong Han, Lei Liao, Jinghui Lu, Binghong Wu .etc.|<http://arxiv.org/pdf/2505.14059v1>|[代码](https://github.com/ByteDance/Dolphin); Dolphin通过异构锚点提示，实现了高效的多模态文档图像解析，显著提升了性能和效率。|
|🆕 发布|OmniStyle: Filtering High Quality Style Transfer Data at Scale|全风格：大规模过滤高质量风格迁移数据|Ye Wang, Ruiqi Liu, Jiang Lin, Fei Liu, Zili Yi, Yilin Wang, Rui Ma|<http://arxiv.org/pdf/2505.14028v1>|构建OmniStyle-1M大规模风格迁移数据集，提出OmniFilter质量评估框架，实现高效、高...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|3D Reconstruction from Sketches|从草图中进行三维重建|Abhimanyu Talwar, Julien Laasri|<http://arxiv.org/pdf/2505.14621v1>|提出了一种从草图重建3D场景的方法，通过拼接草图、生成真实图像和估计深度图实现。|
|📝 更新|Point2Primitive: CAD Reconstruction from Point Cloud by Direct Primitive Prediction|点至原语：通过直接原语预测从点云进行CAD重建|Cheng Wang, Xinzhu Ma, Bin Wang, Shixiang Tang, Yuan Meng, Ping Jiang|<http://arxiv.org/pdf/2505.02043v2>|提出了一种直接从点云预测挤压原语的方法，实现高精度CAD模型重建。|
|🆕 发布|End-to-end Cortical Surface Reconstruction from Clinical Magnetic Resonance Images|端到端从临床磁共振图像中重建皮质表面|Jesper Duemose Nielsen, Karthik Gopinath, Andrew Hoopes, Adrian Dalca, Colin Magdamo, Steven Arnold, Sudeshna Das, Axel Thielscher .etc.|<http://arxiv.org/pdf/2505.14017v1>|[代码](https://github.com/simnibs/brainnet.); 开发了一种无需重新训练的神经网络，可从任意对比度和分辨率的临床MRI图像中准确重建大脑皮层表面。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ViC-Bench: Benchmarking Visual-Interleaved Chain-of-Thought Capability in MLLMs with Free-Style Intermediate State Representations|ViC-Bench：在MLLMs中通过自由式中间状态表示评估视觉交织思维链能力的基准测试|Xuecheng Wu, Jiaxing Liu, Danlei Huang, Xiaoyu Li, Yifan Wang, Chen Chen, Liya Ma, Xuezhi Cao .etc.|<http://arxiv.org/pdf/2505.14404v1>|提出ViC-Bench基准，通过自由式中间状态评估MLLM的视觉思维链能力。|
|🆕 发布|M3Depth: Wavelet-Enhanced Depth Estimation on Mars via Mutual Boosting of Dual-Modal Data|M3Depth：基于双模态数据互促的火星波纹增强深度估计|Junjie Li, Jiawei Wang, Miyu Li, Yu Liu, Yumei Wang, Haitao Xu|<http://arxiv.org/pdf/2505.14159v1>|M3Depth通过结合小波变换和一致性损失，显著提升了火星表面深度估计的准确性。|
|📝 更新|Interactive Rendering of Relightable and Animatable Gaussian Avatars|可重光照和可动画化高斯头像的交互式渲染|Youyi Zhan, Tianjia Shao, He Wang, Yin Yang, Kun Zhou|<http://arxiv.org/pdf/2407.10707v2>|提出了一种基于高斯分层和交互式渲染的快速重建可重光照和可动画虚拟人像的方法。|
|🆕 发布|Multi-Label Stereo Matching for Transparent Scene Depth Estimation|多标签立体匹配用于透明场景深度估计|Zhidan Liu, Chengtang Yao, Jiaxi Zeng, Yuwei Wu, Yunde Jia|<http://arxiv.org/pdf/2505.14008v1>|[代码](https://github.com/BFZD233/TranScene.); 提出了一种多标签立体匹配方法，同时估计透明场景中透明物体和遮挡背景的深度。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Place Recognition: A Comprehensive Review, Current Challenges and Future Directions|场所识别：全面综述、当前挑战与未来方向|Zhenyu Li, Tianyi Shang, Pengjie Xu, Zhaojun Deng|<http://arxiv.org/pdf/2505.14068v1>|[代码](https://github.com/CV4RA/SOTA-Place-Recognitioner.); 综述了地点识别方法，包括CNN、Transformer和跨模态策略，并展望了未来研究方向。|
|📝 更新|FastMap: Revisiting Dense and Scalable Structure from Motion|快速映射：重新审视密集和可扩展的运动恢复结构|Jiahao Li, Haochen Wang, Muhammad Zubair Irshad, Igor Vasiljevic, Matthew R. Walter, Vitor Campagnolo Guizilini, Greg Shakhnarovich|<http://arxiv.org/pdf/2505.04612v2>|FastMap通过优化GPU并行操作和简化优化步骤，实现了快速且精确的大规模场景结构从运动估计。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VideoEval-Pro: Robust and Realistic Long Video Understanding Evaluation|视频评估-Pro：鲁棒且真实的长视频理解评估|Wentao Ma, Weiming Ren, Yiming Jia, Zhuofeng Li, Ping Nie, Ge Zhang, Wenhu Chen|<http://arxiv.org/pdf/2505.14640v1>|提出VideoEval-Pro，解决现有长视频理解基准的可靠性问题，提供更真实可靠的评估方法。|
|🆕 发布|Breaking Down Video LLM Benchmarks: Knowledge, Spatial Perception, or True Temporal Understanding?|视频LLM基准的剖析：知识、空间感知还是真正的时序理解？|Bo Feng, Zhengfeng Lai, Shiyu Li, Zizhen Wang, Simon Wang, Ping Huang, Meng Cao|<http://arxiv.org/pdf/2505.14321v1>|提出VBenchComp，区分视频LLM的时序理解能力，揭示传统评估的局限性。|
|📝 更新|VideoVista-CulturalLingo: 360$^\circ$ Horizons-Bridging Cultures, Languages, and Domains in Video Comprehension|视频视界-文化语言：360°视野-在视频理解中跨越文化、语言和领域|Xinyu Chen, Yunxin Li, Haoyuan Shi, Baotian Hu, Wenhan Luo, Yaowei Wang, Min Zhang|<http://arxiv.org/pdf/2504.17821v2>|构建了跨文化、语言和领域的首个视频理解基准，评估多模态AI系统的理解与推理能力。|
|🆕 发布|Blind Restoration of High-Resolution Ultrasound Video|盲修复高分辨率超声视频|Chu Chen, Kangning Cui, Pasquale Cascarano, Wei Tang, Elena Loli Piccolomini, Raymond H. Chan|<http://arxiv.org/pdf/2505.13915v1>|提出了一种无需配对训练数据的自监督超声视频超分辨率算法，显著提升了超声视频的分辨率和清晰度。|
|📝 更新|MomentSeeker: A Task-Oriented Benchmark For Long-Video Moment Retrieval|MomentSeeker：面向任务的长时间视频瞬间检索基准|Huaying Yuan, Jian Ni, Zheng Liu, Yueze Wang, Junjie Zhou, Zhengyang Liang, Bo Zhao, Zhao Cao .etc.|<http://arxiv.org/pdf/2502.12558v4>|[代码](https://yhy-2000.github.io/MomentSeeker); 提出MomentSeeker基准，解决长视频关键帧检索的准确性和效率问题。|
|🆕 发布|Domain Adaptation of VLM for Soccer Video Understanding|足球视频理解中视觉语言模型的领域自适应|Tiancheng Jiang, Henry Wang, Md Sirajus Salekin, Parmida Atighehchian, Shinan Zhang|<http://arxiv.org/pdf/2505.13860v1>|探索开源视觉语言模型在特定领域（如足球）的可适应性，通过大规模数据集和指令遵循数据实现模型微调，显著...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Egocentric Action-aware Inertial Localization in Point Clouds|以自我为中心的动作感知惯性定位在点云中|Mingfang Zhang, Ryo Yonetani, Yifei Huang, Liangyang Ouyang, Ruicong Liu, Yoichi Sato|<http://arxiv.org/pdf/2505.14346v1>|提出一种利用动作感知的惯性定位框架，通过融合IMU信号和点云特征实现人体在3D空间中的定位。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RETRO: REthinking Tactile Representation Learning with Material PriOrs|RETRO：基于材料先验重新思考触觉表征学习|Weihao Xia, Chenliang Zhou, Cengiz Oztireli|<http://arxiv.org/pdf/2505.14319v1>|提出一种结合材料先验的触觉表征学习方法，提升触觉模型对不同材质和纹理的捕捉与泛化能力。|
|📝 更新|Uni4D: A Unified Self-Supervised Learning Framework for Point Cloud Videos|Uni4D：一种统一的点云视频自监督学习框架|Zhi Zuo, Chenyi Zhuang, Pan Gao, Jie Qin, Hao Feng, Nicu Sebe|<http://arxiv.org/pdf/2504.04837v2>|提出了一种无需显式知识学习运动和融合低级几何与高级语义的统一自监督学习框架，显著提升了点云视频的时空...|
|📝 更新|Contrastive Alignment with Semantic Gap-Aware Corrections in Text-Video Retrieval|对比对齐与语义差距感知校正的文本-视频检索|Jian Xiao, Zijie Song, Jialong Hu, Hao Cheng, Zhenzhen Hu, Jia Li, Richang Hong|<http://arxiv.org/pdf/2505.12499v2>|提出GARE框架，通过语义间隙感知校正缓解文本-视频检索中的模态间隙和梯度冲突问题。|
|📝 更新|FALCON: False-Negative Aware Learning of Contrastive Negatives in Vision-Language Pretraining|FALCON：视觉-语言预训练中对比负样本的假阴性感知学习|Myunsoo Kim, Seong-Woong Shim, Byung-Jun Lee|<http://arxiv.org/pdf/2505.11192v3>|FALCON通过动态选择负样本，有效缓解了视觉语言预训练中的假阴性问题，提升了模型性能。|
|📝 更新|Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation|超越马特洛什卡：重新审视自适应表示中的稀疏编码|Tiansheng Wen, Yifei Wang, Zequn Zeng, Zhong Peng, Yudi Su, Xinyang Liu, Bo Chen, Hongwei Liu .etc.|<http://arxiv.org/pdf/2503.01776v5>|[代码](https://github.com/neilwen987/CSR_Adaptive_Rep); 提出了一种基于稀疏编码的适应性表示学习方法，有效提升了性能和效率。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Two Experts Are All You Need for Steering Thinking: Reinforcing Cognitive Effort in MoE Reasoning Models Without Additional Training|仅需两位专家进行引导思考：在不额外训练的情况下增强MoE推理模型中的认知努力|Mengru Wang, Xingyu Chen, Yue Wang, Zhiwei He, Jiahao Xu, Tian Liang, Qiuzhi Liu, Yunzhi Yao .etc.|<http://arxiv.org/pdf/2505.14681v1>|通过强化认知专家，RICE方法有效提升了MoE推理模型的认知效率。|
|🆕 发布|Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference|双精度量化以提高深度神经网络推理效率和准确性|Tomer Gafni, Asaf Karnieli, Yair Hanani|<http://arxiv.org/pdf/2505.14638v1>|提出了一种高效且精确的深度神经网络推理量化方案，通过W4A8方案和DPQ算法显著提升性能。|
|📝 更新|Deep activity propagation via weight initialization in spiking neural networks|深度活动传播：通过脉冲神经网络中的权重初始化|Aurora Micheli, Olaf Booij, Jan van Gemert, Nergis Tömen|<http://arxiv.org/pdf/2410.00580v2>|提出了一种针对脉冲神经网络的有效权重初始化方法，解决了深度SNN训练中的信息丢失和退化问题。|
|🆕 发布|Plane Geometry Problem Solving with Multi-modal Reasoning: A Survey|多模态推理下的平面几何问题求解：综述|Seunghyuk Cho, Zhenyue Qin, Yang Liu, Youngbin Choi, Seungbeom Lee, Dongwoo Kim|<http://arxiv.org/pdf/2505.14340v1>|系统综述了平面几何问题解决方法，分类分析了编码器-解码器架构，并探讨了未来研究方向。|
|📝 更新|Multi-modal Collaborative Optimization and Expansion Network for Event-assisted Single-eye Expression Recognition|多模态协同优化与扩展网络在辅助单眼表情识别中的应用|Runduo Han, Xiuping Liu, Shangxuan Yi, Yi Zhang, Hongchen Tan|<http://arxiv.org/pdf/2505.12007v2>|提出了一种多模态协作优化网络，有效提升单眼表情识别在低光照条件下的准确性。|
|🆕 发布|Towards Efficient Multi-Scale Deformable Attention on NPU|迈向NPU上的高效多尺度可变形注意力|Chenghuan Huang, Zhigeng Xu, Chong Sun, Chen Li, Ziyang Ma|<http://arxiv.org/pdf/2505.14022v1>|提出了一种针对NPU的MSDA高效实现方法，显著提升了多尺度可变形注意力机制的计算速度。|
|🆕 发布|UHD Image Dehazing via anDehazeFormer with Atmospheric-aware KV Cache|基于大气感知KV缓存的DehazeFormer实现UHD图像去雾|Pu Wang, Pengwen Dai, Chen Wu, Yeying Jin, Dianjie Lu, Guijuan Zhang, Youshan Zhang, Zhuoran Zheng|<http://arxiv.org/pdf/2505.14010v1>|提出DehazeFormer，通过自适应归一化和大气散射感知KV缓存机制，实现超高清图像去雾，大幅提...|
|🆕 发布|An Explorative Analysis of SVM Classifier and ResNet50 Architecture on African Food Classification|非洲食品分类中SVM分类器和ResNet50架构的探索性分析|Chinedu Emmanuel Mbonu, Kenechukwu Anigbogu, Doris Asogwa, Tochukwu Belonwu|<http://arxiv.org/pdf/2505.13923v1>|评估了SVM和ResNet50在非洲食品分类中的应用，为非洲菜肴的食品识别提供了新见解。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|KIND: Knowledge Integration and Diversion for Training Decomposable Models|知识集成与分散训练可分解模型|Yucheng Xie, Fu Feng, Ruixiao Shi, Jing Wang, Yong Rui, Xin Geng|<http://arxiv.org/pdf/2408.07337v2>|[代码](https://github.com/Te4P0t/KIND.); KIND通过知识整合与转移，构建可分解模型，有效解决预训练模型在资源受限部署和领域迁移中的挑战。|
|📝 更新|BigReg: An Efficient Registration Pipeline for High-Resolution X-Ray and Light-Sheet Fluorescence Microscopy|BigReg：高效的高分辨率X射线和光片荧光显微镜配准管道|Siyuan Mei, Fuxin Fan, Mareike Thies, Mingxuan Gu, Fabian Wagner, Oliver Aust, Ina Erceg, Zeynab Mirzaei .etc.|<http://arxiv.org/pdf/2404.14807v2>|提出BigReg，一种高效的大体积XRM和LSFM数据配准方法，显著提升骨微结构分析精度。|
|📝 更新|Continual Distillation Learning: Knowledge Distillation in Prompt-based Continual Learning|持续蒸馏学习：基于提示的持续学习中的知识蒸馏|Qifan Zhang, Yunhui Guo, Yu Xiang|<http://arxiv.org/pdf/2407.13911v4>|提出了一种基于提示的知识蒸馏方法，有效提升了基于提示的持续学习模型的推理效率。|
|📝 更新|GranQ: Granular Zero-Shot Quantization with Channel-Wise Activation Scaling in QAT|GranQ：基于通道激活缩放的粒度零样本量化在QAT中的应用|Inpyo Hong, Youngwan Jo, Hyojeong Lee, Sunghyun Ahn, Sanghyun Park|<http://arxiv.org/pdf/2503.18339v4>|GranQ通过向量计算实现细粒度量化，有效缓解了零样本量化中的激活失真问题。|
|🆕 发布|AppleGrowthVision: A large-scale stereo dataset for phenological analysis, fruit detection, and 3D reconstruction in apple orchards|AppleGrowthVision：用于苹果园物候分析、果实检测和3D重建的大规模立体数据集|Laura-Sophia von Hirschhausen, Jannes S. Magnusson, Mykyta Kovalenko, Fredrik Boye, Tanay Rawat, Peter Eisert, Anna Hilsmann, Sebastian Pretzsch .etc.|<http://arxiv.org/pdf/2505.14029v1>|构建大规模苹果园立体数据集，提升果实检测和3D重建精度。|
|🆕 发布|StPR: Spatiotemporal Preservation and Routing for Exemplar-Free Video Class-Incremental Learning|时空保持与路由的无示例视频类增量学习|Huaijie Wang, De Cheng, Guozhang Li, Zhipeng Xu, Lingfeng He, Jie Li, Nannan Wang, Xinbo Gao|<http://arxiv.org/pdf/2505.13997v1>|提出StPR框架，通过时空信息保留和路由，实现无样本视频增量学习，有效缓解灾难性遗忘。|
|🆕 发布|MGStream: Motion-aware 3D Gaussian for Streamable Dynamic Scene Reconstruction|MGStream：感知运动的流式动态场景重建的三维高斯|Zhenyu Bao, Qing Li, Guibiao Liao, Zhongyuan Zhao, Kanglin Liu|<http://arxiv.org/pdf/2505.13839v1>|[代码](https://github.com/pcl3dv/MGStream.); MGStream通过引入运动相关的3D高斯函数，有效解决了动态场景重建中的闪烁伪影和存储效率问题。|
|📝 更新|A portable diagnosis model for Keratoconus using a smartphone|基于智能手机的角膜圆锥形病变便携式诊断模型|Yifan Li, Peter Ho, Jo Woon Chong|<http://arxiv.org/pdf/2505.08616v3>|开发了一种便携式智能手机诊断模型，通过图像分析准确识别和定位角膜圆锥形病变。|
|🆕 发布|Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels|像素级地面化：教导VLMs在像素中实现复杂指令的地面化|Yongshuo Zong, Qin Zhang, Dongsheng An, Zhihua Li, Xiang Xu, Linghan Xu, Zhuowen Tu, Yifan Xing .etc.|<http://arxiv.org/pdf/2505.13788v1>|提出一种通过知识蒸馏自动扩展指令数据，提升视觉语言模型像素级定位能力的方法，显著提升复杂指令下的定位...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Automated Fetal Biometry Assessment with Deep Ensembles using Sparse-Sampling of 2D Intrapartum Ultrasound Images|基于稀疏采样的二维分娩超声图像的深度集成自动胎儿生物测量评估|Jayroop Ramesh, Valentin Bacher, Mark C. Eid, Hoda Kalabizadeh, Christian Rupprecht, Ana IL Namburete, Pak-Hei Yeung, Madeleine K. Wyburd .etc.|<http://arxiv.org/pdf/2505.14572v1>|提出了一种基于深度集成和稀疏采样的自动胎儿生物测量方法，显著提升了测量准确性和可靠性。|
|📝 更新|MMDocIR: Benchmarking Multi-Modal Retrieval for Long Documents|MMDocIR：长文档多模态检索基准测试|Kuicai Dong, Yujing Chang, Xin Deik Goh, Dexun Li, Ruiming Tang, Yong Liu|<http://arxiv.org/pdf/2501.08828v2>|[代码](https://mmdocrag.github.io/MMDocIR); 构建了MMDocIR基准，为多模态长文档检索提供全面评估。|
|🆕 发布|Scaling and Enhancing LLM-based AVSR: A Sparse Mixture of Projectors Approach|基于LLM的AVSR的扩展与增强：投影器稀疏混合方法|Umberto Cappellazzo, Minsu Kim, Stavros Petridis, Daniele Falavigna, Alessio Brutti|<http://arxiv.org/pdf/2505.14336v1>|提出Llama-SMoP，通过稀疏混合投影器模块降低LLM-AVSR计算成本，提升模型性能。|
|📝 更新|Exploring Social Media Image Categorization Using Large Models with Different Adaptation Methods: A Case Study on Cultural Nature's Contributions to People|探索使用不同自适应方法的大型模型进行社交媒体图像分类：关于文化自然对人类贡献的案例研究|Rohaifa Khaldi, Domingo Alcaraz-Segura, Ignacio Sánchez-Herrera, Javier Martinez-Lopez, Carlos Javier Navarro, Siham Tabik|<http://arxiv.org/pdf/2410.00275v3>|利用大型模型和自适应方法，探索社交媒体图像分类，构建FLIPS数据集并评估性能。|
|📝 更新|Pyramid Sparse Transformer: Enhancing Multi-Scale Feature Fusion with Dynamic Token Selection|金字塔稀疏变换器：通过动态标记选择增强多尺度特征融合|Junyi Hu, Tian Bai, Fengyi Wu, Zhenming Peng, Yi Zhang|<http://arxiv.org/pdf/2505.12772v2>|提出PST模块，通过动态选词和共享注意力参数，简化多尺度特征融合，提升视觉模型性能。|
|📝 更新|Benchmarking Unified Face Attack Detection via Hierarchical Prompt Tuning|通过分层提示调优的统一人脸攻击检测基准测试|Ajian Liu, Haocheng Yuan, Xiao Guo, Hui Ma, Wanyi Zhuang, Changtao Miao, Yan Hong, Chuanbiao Song .etc.|<http://arxiv.org/pdf/2505.13327v2>|提出UniAttackDataPlus数据集和HiPTune框架，统一检测人脸攻击，提升模型应对未知...|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bridge the Gap between Past and Future: Siamese Model Optimization for Context-Aware Document Ranking|跨越过去与未来的鸿沟：基于上下文感知的文档排序的Siamese模型优化|Songhao Wu, Quan Tu, Mingjie Zhong, Hong Liu, Jia Xu, Jinjie Gu, Rui Yan|<http://arxiv.org/pdf/2505.14180v1>|提出一种结合历史与未来上下文的Siamese模型优化方法，有效提升文档排序性能。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Universal Incremental Learning: Mitigating Confusion from Inter- and Intra-task Distribution Randomness|通用增量学习：缓解任务间和任务内分布随机性带来的混淆|Sheng Luo, Yi Zhou, Tao Zhou|<http://arxiv.org/pdf/2503.07035v2>|[代码](https://github.com/rolsheng/UIL); 提出了一种应对任务间和任务内分布随机性的通用增量学习方法，有效缓解了混淆问题。|
|🆕 发布|Flexible-weighted Chamfer Distance: Enhanced Objective Function for Point Cloud Completion|柔性加权 Chamfer 距离：点云补全的增强目标函数|Jie Li, Shengwei Tian, Long Yu, Xin Ning|<http://arxiv.org/pdf/2505.14218v1>|提出了一种改进的Chamfer距离，通过调整权重提升点云补全的全球分布和整体性能。|
|🆕 发布|NOVA: A Benchmark for Anomaly Localization and Clinical Reasoning in Brain MRI|NOVA：脑MRI异常定位和临床推理的基准|Cosmin I. Bercea, Jun Li, Philipp Raffler, Evamaria O. Riedel, Lena Schmitzer, Angela Kurz, Felix Bitzer, Paula Roßmüller .etc.|<http://arxiv.org/pdf/2505.14064v1>|NOVA构建了首个真实脑MRI异常定位与临床推理基准，挑战现有模型在未知异常检测上的能力。|
|📝 更新|OT-DETECTOR: Delving into Optimal Transport for Zero-shot Out-of-Distribution Detection|OT-DETECTOR：深入探索最优传输技术在零样本分布外检测中的应用|Yu Liu, Hao Tang, Haiqi Zhang, Jing Qin, Zechao Li|<http://arxiv.org/pdf/2503.06442v2>|OT-DETECTOR利用最优传输量化语义和分布差异，实现零样本异常检测。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|StarFT: Robust Fine-tuning of Zero-shot Models via Spuriosity Alignment|星FT：通过稀疏性对齐实现零样本模型的鲁棒微调|Younghyun Kim, Jongheon Jeong, Sangkyung Kwak, Kyungmin Lee, Juho Lee, Jinwoo Shin|<http://arxiv.org/pdf/2505.13232v2>|StarFT通过引入文本对齐正则化，防止零样本模型学习无关特征，提升其鲁棒性和泛化能力。|
|🆕 发布|Adversarially Pretrained Transformers may be Universally Robust In-Context Learners|对抗预训练的Transformer可能是通用的情境学习器|Soichiro Kumano, Hiroshi Kera, Toshihiko Yamasaki|<http://arxiv.org/pdf/2505.14042v1>|[代码](https://github.com/s-kumano/universally-robust-in-context-learner.); 通过对抗预训练，Transformer模型可在下游任务中无需额外训练实现通用鲁棒性。|
|🆕 发布|Adversarial Training from Mean Field Perspective|从平均场视角的对抗训练|Soichiro Kumano, Hiroshi Kera, Toshihiko Yamasaki|<http://arxiv.org/pdf/2505.14021v1>|从平均场理论视角，首次分析了对抗训练，并提出了新的理论框架，解决了现有方法的局限性。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|How Effective Can Dropout Be in Multiple Instance Learning ?|Dropout在多实例学习中的有效性如何？|Wenhui Zhu, Peijie Qiu, Xiwen Chen, Zhangsihao Yang, Aristeidis Sotiras, Abolfazl Razi, Yalin Wang|<http://arxiv.org/pdf/2504.14783v2>|[代码](https://github.com/ChongQingNoSubway/MILDropout.); 提出MIL-Dropout方法，有效提升MIL在WSI分类中的性能。|
|🆕 发布|DeepEyes: Incentivizing "Thinking with Images" via Reinforcement Learning|深度视觉：通过强化学习激励“以图思考”|Ziwei Zheng, Michael Yang, Jack Hong, Chenxiao Zhao, Guohai Xu, Le Yang, Chao Shen, Xing Yu|<http://arxiv.org/pdf/2505.14362v1>|[代码](https://github.com/Visual-Agent/DeepEyes.); 通过强化学习激励模型“以图像思考”，实现视觉与文本推理的无缝结合。|
|📝 更新|Latent Action Learning Requires Supervision in the Presence of Distractors|潜在动作学习在存在干扰因素时需要监督|Alexander Nikulin, Ilya Zisman, Denis Tarasov, Nikita Lyubaykin, Andrei Polubarov, Igor Kiselev, Vladislav Kurenkov|<http://arxiv.org/pdf/2502.00379v4>|在存在干扰因素时，提出了一种改进的潜在动作学习模型，通过少量监督显著提升了下游性能。|
|📝 更新|Any-to-Any Learning in Computational Pathology via Triplet Multimodal Pretraining|通过三元组多模态预训练在计算病理学中的任意到任意学习|Qichen Sun, Zhengrui Guo, Rui Peng, Hao Chen, Jinzhuo Wang|<http://arxiv.org/pdf/2505.12711v2>|提出ALTER框架，通过三模态预训练实现计算病理学中任意模态间的学习，有效融合异构数据并应对模态缺失...|
|🆕 发布|Beginning with You: Perceptual-Initialization Improves Vision-Language Representation and Alignment|从你开始：感知初始化提升视觉-语言表示与对齐|Yang Hu, Runchen Wang, Stephen Chong Zhao, Xuhui Zhan, Do Hun Kim, Mark Wallace, David A. Tovar|<http://arxiv.org/pdf/2505.14204v1>|引入感知初始化，通过结合人类感知结构提升视觉语言表示和零样本性能。|
|📝 更新|Multimodal Cancer Survival Analysis via Hypergraph Learning with Cross-Modality Rebalance|多模态癌症生存分析：基于跨模态平衡的超图学习|Mingcheng Qu, Guang Yang, Donglin Di, Tonghua Su, Yue Gao, Yang Song, Lei Fan|<http://arxiv.org/pdf/2505.11997v2>|提出一种融合超图学习和跨模态平衡机制的癌症生存预测框架，有效缓解病理-基因组数据不平衡问题。|
|📝 更新|Gradient Leakage Defense with Key-Lock Module for Federated Learning|基于关键锁模块的联邦学习梯度泄露防御|Hanchi Ren, Jingjing Deng, Xianghua Xie, Xiaoke Ma, Jianfeng Ma|<http://arxiv.org/pdf/2305.04095v2>|提出了一种基于密钥锁模块的联邦学习梯度泄露防御技术，有效保护了隐私数据安全。|
|📝 更新|Semantics-Oriented Multitask Learning for DeepFake Detection: A Joint Embedding Approach|面向语义的多任务学习用于深度伪造检测：一种联合嵌入方法|Mian Zou, Baosheng Yu, Yibing Zhan, Siwei Lyu, Kede Ma|<http://arxiv.org/pdf/2408.16305v2>|提出了一种基于语义联合嵌入的多任务学习方法，有效提升了DeepFake检测的泛化能力和可解释性。|
|🆕 发布|Bronchovascular Tree-Guided Weakly Supervised Learning Method for Pulmonary Segment Segmentation|支气管血管树引导的弱监督学习肺段分割方法|Ruijie Zhao, Zuopeng Tan, Xiao Xue, Longfei Zhao, Bing Li, Zicheng Liao, Ying Ming, Jiaru Wang .etc.|<http://arxiv.org/pdf/2505.13911v1>|提出了一种基于解剖层次和支气管血管树引导的弱监督学习方法，有效提升了肺段分割的准确性。|
|🆕 发布|4D-ROLLS: 4D Radar Occupancy Learning via LiDAR Supervision|4D-ROLLS：基于激光雷达监督的4D雷达占用学习|Ruihan Liu, Xiaoyi Wu, Xijun Chen, Liang Hu, Yunjiang Lou|<http://arxiv.org/pdf/2505.13905v1>|[代码](https://github.com/CLASS-Lab/4D-ROLLS.); 提出了一种基于LiDAR监督的4D雷达弱监督占用估计方法，显著提升了在恶劣环境下的鲁棒性和泛化能力。|
|🆕 发布|Physics-Driven Local-Whole Elastic Deformation Modeling for Point Cloud Representation Learning|基于物理的局部-整体弹性变形建模用于点云表示学习|Zhongyu Chen, Rong Zhao, Xie Han, Xindong Guo, Song Wang, Zherui Qiao|<http://arxiv.org/pdf/2505.13812v1>|提出了一种基于物理驱动的局部-整体弹性变形模型，有效提升了点云表示学习性能。|
|📝 更新|RoCoDA: Counterfactual Data Augmentation for Data-Efficient Robot Learning from Demonstrations|RoCoDA：基于演示的数据高效机器人学习中的反事实数据增强|Ezra Ameperosa, Jeremy A. Collins, Mrinal Jain, Animesh Garg|<http://arxiv.org/pdf/2411.16959v2>|RoCoDA通过结合不变性、等变性及因果性，提升机器人从演示中学习的样本效率。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unlocking the Power of SAM 2 for Few-Shot Segmentation|解锁SAM 2在少样本分割中的潜力|Qianxiong Xu, Lanyun Zhu, Xuanyi Liu, Guosheng Lin, Cheng Long, Ziyue Li, Rui Zhao|<http://arxiv.org/pdf/2505.14100v1>|设计伪提示生成器和迭代记忆优化，有效解决SAM 2在少样本分割中的匹配问题。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Review of Vision-Based Assistive Systems for Visually Impaired People: Technologies, Applications, and Future Directions|视觉障碍人士基于视觉辅助系统的综述：技术、应用和未来方向|Fulong Yao, Wenju Zhou, Huosheng Hu|<http://arxiv.org/pdf/2505.14298v1>|综述了视觉辅助系统在障碍检测、导航和用户交互方面的最新技术，为视障人士提供独立生活支持。|


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visual Agentic Reinforcement Fine-Tuning|视觉自主强化微调|Ziyu Liu, Yuhang Zang, Yushan Zou, Zijian Liang, Xiaoyi Dong, Yuhang Cao, Haodong Duan, Dahua Lin .etc.|<http://arxiv.org/pdf/2505.14246v1>|Visual-ARFT通过视觉强化微调，赋予大型视觉语言模型灵活的图像处理和搜索能力，显著提升其多模...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visionary-R1: Mitigating Shortcuts in Visual Reasoning with Reinforcement Learning|视觉推理中的捷径缓解：强化学习视角|Jiaer Xia, Yuhang Zang, Peng Gao, Yixuan Li, Kaiyang Zhou|<http://arxiv.org/pdf/2505.14677v1>|通过强化学习和图像描述先于推理，Visionary-R1有效缓解了视觉推理中的捷径学习问题。|
|🆕 发布|EmoGist: Efficient In-Context Learning for Visual Emotion Understanding|EmoGist：视觉情感理解的效率性情境学习|Ronald Seoh, Dan Goldwasser|<http://arxiv.org/pdf/2505.14660v1>|检测图像中的情绪，EmoGist通过上下文学习实现高效分类。|
|🆕 发布|RAVENEA: A Benchmark for Multimodal Retrieval-Augmented Visual Culture Understanding|标题翻译：RAVENEA：多模态检索增强视觉文化理解基准|Jiaang Li, Yifei Yuan, Wenyan Li, Mohammad Aliannejadi, Daniel Hershcovich, Anders Søgaard, Ivan Vulić, Wenxuan Zhang .etc.|<http://arxiv.org/pdf/2505.14462v1>|构建RAVENEA基准，通过检索增强提升多模态视觉文化理解能力。|
|🆕 发布|Aligning Attention Distribution to Information Flow for Hallucination Mitigation in Large Vision-Language Models|对大型视觉-语言模型中幻觉缓解进行注意力分布与信息流对齐|Jianfei Zhao, Feng Zhang, Xin Sun, Chong Feng|<http://arxiv.org/pdf/2505.14257v1>|通过优化注意力分配，该论文有效缓解了大视觉语言模型中的幻觉问题。|
|🆕 发布|VoQA: Visual-only Question Answering|视觉问答：仅视觉问答|Luyang Jiang, Jianing An, Jie Luo, Wenjun Wu, Lei Huang|<http://arxiv.org/pdf/2505.14227v1>|VoQA提出视觉问答任务，通过结构化微调显著提升模型视觉理解能力。|
|🆕 发布|UniVG-R1: Reasoning Guided Universal Visual Grounding with Reinforcement Learning|UniVG-R1：基于强化学习的推理引导的通用视觉定位|Sule Bai, Mingxing Li, Yong Liu, Jing Tang, Haoji Zhang, Lei Sun, Xiangxiang Chu, Yansong Tang|<http://arxiv.org/pdf/2505.14231v1>|[代码](https://amap-ml.github.io/UniVG-R1-page); 提出UniVG-R1，通过强化学习和冷启动数据增强推理能力，解决多模态视觉定位问题。|
|🆕 发布|Towards Omnidirectional Reasoning with 360-R1: A Dataset, Benchmark, and GRPO-based Method|面向全向推理的360-R1：一个数据集、基准和基于GRPO的方法|Xinshen Zhang, Zhen Ye, Xu Zheng|<http://arxiv.org/pdf/2505.14197v1>|提出OmniVQA数据集和360-R1方法，解决多模态大语言模型在处理全景场景中的理解与推理难题。|
|🆕 发布|Textual Steering Vectors Can Improve Visual Understanding in Multimodal Large Language Models|文本引导向量可提升多模态大型语言模型中的视觉理解|Woody Haosheng Gan, Deqing Fu, Julian Asilis, Ollie Liu, Dani Yogatama, Vatsal Sharan, Robin Jia, Willie Neiswanger|<http://arxiv.org/pdf/2505.14071v1>|利用文本引导向量有效提升多模态大语言模型视觉理解能力。|
|🆕 发布|Toward Effective Reinforcement Learning Fine-Tuning for Medical VQA in Vision-Language Models|面向视觉-语言模型中医疗视觉问答的有效强化学习微调|Wenhui Zhu, Xuanzhao Dong, Xin Li, Peijie Qiu, Xiwen Chen, Abolfazl Razi, Aris Sotiras, Yi Su .etc.|<http://arxiv.org/pdf/2505.13973v1>|提出了一种针对医疗视觉问答的强化学习微调方法，显著提升了模型在准确性和推理质量上的表现。|
|📝 更新|3D Visual Illusion Depth Estimation|三维视觉错觉深度估计|Chengtang Yao, Zhidan Liu, Jiaxi Zeng, Lidong Yu, Yuwei Wu, Yunde Jia|<http://arxiv.org/pdf/2505.13061v2>|提出了一种利用视觉语言模型常识的鲁棒深度估计框架，有效应对3D视觉错觉挑战。|
|📝 更新|Re-Align: Aligning Vision Language Models via Retrieval-Augmented Direct Preference Optimization|重对齐：通过检索增强的直接偏好优化对齐视觉语言模型|Shuo Xing, Yuping Wang, Peiran Li, Ruizheng Bai, Yueqi Wang, Chan-wei Hu, Chengxuan Qian, Huaxiu Yao .etc.|<http://arxiv.org/pdf/2502.13146v2>|[代码](https://github.com/taco-group/Re-Align.); Re-Align通过检索增强直接偏好优化，有效缓解视觉语言模型跨模态不一致问题。|
|🆕 发布|Transfer Learning from Visual Speech Recognition to Mouthing Recognition in German Sign Language|从视觉语音识别到德语手语嘴型识别的迁移学习|Dinh Nam Pham, Eleftherios Avramidis|<http://arxiv.org/pdf/2505.13784v1>|从视觉语音识别迁移学习至德语手语口型识别，提升手语识别准确性和鲁棒性。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RadCLIP: Enhancing Radiologic Image Analysis through Contrastive Language-Image Pre-training|RadCLIP：通过对比语言-图像预训练增强放射学图像分析|Zhixiu Lu, Hailong Li, Nehal A. Parikh, Jonathan R. Dillman, Lili He|<http://arxiv.org/pdf/2403.09948v3>|RadCLIP通过结合医学影像与文本信息，显著提升了放射影像分析的准确性和效率。|
|🆕 发布|RA-Touch: Retrieval-Augmented Touch Understanding with Enriched Visual Data|RA-Touch：基于检索增强的触觉理解与丰富视觉数据|Yoorhim Cho, Hongyeob Kim, Semin Kim, Youjia Zhang, Yunseok Choi, Sungeun Hong|<http://arxiv.org/pdf/2505.14270v1>|[代码](https://aim-skku.github.io/RA-Touch); 提出RA-Touch，通过检索增强视觉数据，提升物体触觉理解能力。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AS3D: 2D-Assisted Cross-Modal Understanding with Semantic-Spatial Scene Graphs for 3D Visual Grounding|AS3D：基于语义-空间场景图的2D辅助跨模态理解与3D视觉定位|Feng Xiao, Hongbin Xu, Guocan Zhao, Wenxiong Kang|<http://arxiv.org/pdf/2505.04058v2>|提出了一种结合2D辅助和语义空间图的方法，有效解决3D视觉定位中的多相似物体识别问题。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ActiveSSF: An Active-Learning-Guided Self-Supervised Framework for Long-Tailed Megakaryocyte Classification|主动SSF：一种基于主动学习的长尾巨核细胞分类自监督框架|Linghao Zhuang, Ying Zhang, Gege Yuan, Xingyue Zhao, Zhiping Jiang|<http://arxiv.org/pdf/2502.08200v2>|ActiveSSF通过结合主动学习和自监督预训练，有效解决了医学图像中巨核细胞分类的背景噪声、数据不...|
|🆕 发布|CONSIGN: Conformal Segmentation Informed by Spatial Groupings via Decomposition|CONSIGN：基于分解的空間組合信息驅動的共形分割|Bruno Viti, Elias Karabelas, Martin Holler|<http://arxiv.org/pdf/2505.14113v1>|CONSIGN通过引入空间分组，改进了基于一致预测的图像分割不确定性量化。|
|🆕 发布|Unintended Bias in 2D+ Image Segmentation and Its Effect on Attention Asymmetry|二维加图像分割中的无意偏差及其对注意力不对称性的影响|Zsófia Molnár, Gergely Szabó, András Horváth|<http://arxiv.org/pdf/2505.14105v1>|揭示了预训练模型在图像分割中的偏见及其对注意力不对称的影响，并提出策略减轻这些偏见。|
|🆕 发布|Learning Concept-Driven Logical Rules for Interpretable and Generalizable Medical Image Classification|学习基于概念驱动的逻辑规则以实现可解释和可泛化的医学图像分类|Yibo Gao, Hangqi Zhou, Zheyao Gao, Bomin Wang, Shangqi Gao, Sihan Wang, Xiahai Zhuang|<http://arxiv.org/pdf/2505.14049v1>|[代码](https://github.com/obiyoag/crl.); 提出CRL框架，通过学习逻辑规则提升医疗图像分类的可解释性和泛化能力。|
|🆕 发布|XDementNET: An Explainable Attention Based Deep Convolutional Network to Detect Alzheimer Progression from MRI data|XDementNET：一种基于可解释注意力的深度卷积网络，用于从MRI数据中检测阿尔茨海默病进展|Soyabul Islam Lincoln, Mirza Mohd Shahriar Maswood|<http://arxiv.org/pdf/2505.13906v1>|提出了一种可解释的注意力深度卷积网络，从MRI数据中准确检测阿尔茨海默病进展。|
|🆕 发布|Automated Quality Evaluation of Cervical Cytopathology Whole Slide Images Based on Content Analysis|基于内容分析的宫颈细胞病理学全切片图像自动质量评估|Lanlan Kang, Jian Wang, Jian QIn, Yiqin Liang, Yongjun He|<http://arxiv.org/pdf/2505.13875v1>|提出了一种基于人工智能的自动化宫颈细胞学图像质量评估方法，显著提升诊断效率和一致性。|
|🆕 发布|SuperMapNet for Long-Range and High-Accuracy Vectorized HD Map Construction|SuperMapNet：用于长距离和高精度矢量化高清地图构建|Ruqin Zhou, San Jiang, Wanshou Jiang, Yongsheng Zhang, Chenguang Dai|<http://arxiv.org/pdf/2505.13856v1>|SuperMapNet通过融合多模态信息和点元素交互，实现了长距离和高精度的向量化高精度地图构建。|
|📝 更新|HWA-UNETR: Hierarchical Window Aggregate UNETR for 3D Multimodal Gastric Lesion Segmentation|HWA-UNETR：用于3D多模态胃病变分割的分层窗口聚合UNETR|Jiaming Liang, Lihuan Dai, Xiaoqi Sheng, Xiangguang Chen, Chun Yao, Guihua Tao, Qibin Leng, Hongmin Cai .etc.|<http://arxiv.org/pdf/2505.10464v2>|[代码](https://github.com/JeMing-creater/HWA-UNETR.); 提出HWA-UNETR框架，解决3D多模态胃癌病变分割难题，显著提升分割准确率。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Customized SAM 2 for Referring Remote Sensing Image Segmentation|定制化SAM 2用于遥感图像分割|Fu Rong, Meng Lan, Qian Zhang, Lefei Zhang|<http://arxiv.org/pdf/2503.07266v2>|提出RS2-SAM 2框架，通过融合文本描述和遥感图像特征，实现高精度遥感图像分割。|
|📝 更新|DeepForest: Sensing Into Self-Occluding Volumes of Vegetation With Aerial Imaging|深度森林：利用航空影像感知植被的自遮挡体积|Mohamed Youssef, Jian Peng, Oliver Bimber|<http://arxiv.org/pdf/2502.02171v2>|利用无人机合成孔径成像和3D卷积神经网络，实现了对遮挡植被体积的深度感知。|
|🆕 发布|Selective Structured State Space for Multispectral-fused Small Target Detection|选择性结构化状态空间用于多光谱融合小目标检测|Qianqian Zhang, WeiJun Wang, Yunxing Liu, Li Zhou, Hao Zhao, Junshe An, Zihan Wang|<http://arxiv.org/pdf/2505.14043v1>|提出了一种融合多光谱信息和局部细节的轻量级模型，有效提升了小目标检测精度。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Unforgettable Lessons from Forgettable Images: Intra-Class Memorability Matters in Computer Vision|难忘的教训来自易忘的图像：在计算机视觉中，类内可记忆性至关重要|Jie Jing, Qing Lin, Shuangpeng Han, Lucia Schiatti, Yen-Ling Kuo, Mengmi Zhang|<http://arxiv.org/pdf/2412.20761v3>|提出ICMscore评估图像记忆度，揭示记忆度对计算机视觉任务的影响。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|diffDemorph: Extending Reference-Free Demorphing to Unseen Faces|diffDemorph：将无参考去畸扩展到未见过的面孔|Nitish Shukla, Arun Ross|<http://arxiv.org/pdf/2505.14527v1>|提出了一种基于扩散模型的通用人脸去变形方法，显著提升了去变形效果和实用性。|
|📝 更新|VLMs as GeoGuessr Masters: Exceptional Performance, Hidden Biases, and Privacy Risks|《VLMs作为GeoGuessr大师：卓越性能、隐藏偏见和隐私风险》|Jingyuan Huang, Jen-tse Huang, Ziyi Liu, Xiaoyuan Liu, Wenxuan Wang, Jieyu Zhao|<http://arxiv.org/pdf/2502.11163v2>|[代码](https://github.com/uscnlp-lime/FairLocator.); 评估VLMs在地理信息识别中的性能，揭示其区域偏见和隐私风险。|
|📝 更新|Event-Driven Dynamic Scene Depth Completion|事件驱动动态场景深度补全|Zhiqiang Yan, Jianhao Jiao, Zhengxue Wang, Gim Hee Lee|<http://arxiv.org/pdf/2505.13279v2>|提出EventDC，利用事件相机实现动态场景深度补全，提升融合和定位精度。|

