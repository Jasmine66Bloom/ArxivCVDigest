## [UPDATED!] **2025-05-21** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MMaDA: Multimodal Large Diffusion Language Models|多模态大扩散语言模型：MMaDA|Ling Yang, Ye Tian, Bowen Li, Xinchen Zhang, Ke Shen, Yunhai Tong, Mengdi Wang|<http://arxiv.org/pdf/2505.15809v1>|[代码](https://github.com/Gen-Verse/MMaDA); MMaDA通过统一扩散架构和混合CoT策略，实现了跨模态理解与生成任务的卓越性能。|
|🆕 发布|FragFake: A Dataset for Fine-Grained Detection of Edited Images with Vision Language Models|FragFake：用于视觉语言模型进行细粒度编辑图像检测的数据集|Zhen Sun, Ziyi Zhang, Zeren Luo, Zeyang Sha, Tianshuo Cong, Zheng Li, Shiwen Cui, Weiqiang Wang .etc.|<http://arxiv.org/pdf/2505.15644v1>|开发FragFake数据集，首次利用视觉语言模型进行编辑图像检测与定位，推动内容真实性验证。|
|🆕 发布|LENS: Multi-level Evaluation of Multimodal Reasoning with Large Language Models|多模态推理的大语言模型的多层次评估：LENS|Ruilin Yao, Bo Zhang, Jirui Huang, Xinwei Long, Yifang Zhang, Tianyu Zou, Yufei Wu, Shichao Su .etc.|<http://arxiv.org/pdf/2505.15616v1>|[代码](https://github.com/Lens4MLLMs/lens.); 构建多级基准测试Lens，评估MLLMs在复杂场景中的推理能力。|
|🆕 发布|UWSAM: Segment Anything Model Guided Underwater Instance Segmentation and A Large-scale Benchmark Dataset|UWSAM：基于Segment Anything模型的水下实例分割与大规模基准数据集|Hua Li, Shijie Lian, Zhiyuan Li, Runmin Cong, Sam Kwong|<http://arxiv.org/pdf/2505.15581v1>|[代码](https://github.com/LiamLian0727/UIIS10K.); 提出UWSAM模型，结合水下知识蒸馏和提示生成，有效提升水下实例分割性能。|
|🆕 发布|Beyond Classification: Evaluating Diffusion Denoised Smoothing for Security-Utility Trade off|超越分类：评估扩散去噪平滑在安全-效用权衡中的性能|Yury Belousov, Brian Pulfer, Vitaliy Kinakh, Slava Voloshynovskiy|<http://arxiv.org/pdf/2505.15594v1>|研究扩散去噪平滑在安全与性能平衡中的有效性，并提出针对扩散过程的攻击策略。|
|🆕 发布|Prompt Tuning Vision Language Models with Margin Regularizer for Few-Shot Learning under Distribution Shifts|基于分布偏移的少样本学习中的边缘正则化视觉语言模型提示微调|Debarshi Brahma, Anuska Roy, Soma Biswas|<http://arxiv.org/pdf/2505.15506v1>|[代码](https://github.com/debarshigit/PromptMargin.); 提出PromptMargin方法，通过边缘正则化器对视觉语言模型进行提示微调，有效应对分布偏移下的少...|
|🆕 发布|Seeing Through Deception: Uncovering Misleading Creator Intent in Multimodal News with Vision-Language Models|透过欺骗：利用视觉-语言模型揭示多模态新闻中的误导性创作者意图|Jiaying Wu, Fanxiao Li, Min-Yen Kan, Bryan Hooi|<http://arxiv.org/pdf/2505.15489v1>|构建大规模基准，评估视觉语言模型在识别误导性意图方面的不足，并提出意识模型以提升多模态新闻误导检测。|
|🆕 发布|The P$^3$ dataset: Pixels, Points and Polygons for Multimodal Building Vectorization|P$^3$数据集：多模态建筑矢量化的像素、点和多边形|Raphael Sulzer, Liuyun Duan, Nicolas Girard, Florent Lafarge|<http://arxiv.org/pdf/2505.15379v1>|[代码](https://github.com/raphaelsulzer/PixelsPointsPolygons); 构建了包含多模态信息的P$^3$数据集，通过融合LiDAR和图像信息提升了建筑矢量化的准确性和几何质...|
|📝 更新|A Survey of Pathology Foundation Model: Progress and Future Directions|病理学基础模型综述：进展与未来方向|Conghao Xiong, Hao Chen, Joseph J. Y. Sung|<http://arxiv.org/pdf/2504.04045v2>|[代码](https://github.com/BearCleverProud/AwesomeWSI.); 构建了病理学基础模型（PFM）的系统性分析框架，并提出了未来研究方向。|
|🆕 发布|Parameter-Efficient Fine-Tuning of Multispectral Foundation Models for Hyperspectral Image Classification|多光谱基础模型参数高效微调用于高光谱图像分类|Bernardin Ligan, Khalide Jbilou, Fahd Kalloubi, Ahmed Ratnani|<http://arxiv.org/pdf/2505.15334v1>|提出了一种高效微调多光谱基础模型用于高光谱图像分类的方法，显著降低训练成本。|
|📝 更新|ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning through Step-by-Step Verification|胸部X-Reasoner：通过逐步验证推进放射学基础模型推理|Ziqing Fan, Cheng Liang, Chaoyi Wu, Ya Zhang, Yanfeng Wang, Weidi Xie|<http://arxiv.org/pdf/2504.20930v2>|ChestX-Reasoner通过结合过程监督和强化学习，显著提升了医学影像诊断的推理能力和准确性。|
|📝 更新|The Jumping Reasoning Curve? Tracking the Evolution of Reasoning Performance in GPT-[n] and o-[n] Models on Multimodal Puzzles|跳跃推理曲线？追踪GPT-[n]和o-[n]模型在多模态谜题上推理性能的演变|Vernon Y. H. Toh, Yew Ken Chia, Deepanway Ghosal, Soujanya Poria|<http://arxiv.org/pdf/2502.01081v2>|[代码](https://github.com/declare-lab/LLM-PuzzleTest.); 该论文通过追踪GPT-[n]和o-[n]系列模型在多模态谜题上的推理性能，揭示了其在视觉感知和组合推...|
|📝 更新|UncertainSAM: Fast and Efficient Uncertainty Quantification of the Segment Anything Model|不确定SAM：快速高效的Segment Anything模型不确定性量化|Timo Kaiser, Thomas Norrenbrock, Bodo Rosenhahn|<http://arxiv.org/pdf/2505.05049v3>|提出了一种快速高效的Segment Anything Model不确定性量化方法，通过贝叶斯熵公式追...|
|📝 更新|SpikeCLIP: A Contrastive Language-Image Pretrained Spiking Neural Network|SpikeCLIP：一种对比语言-图像预训练的脉冲神经网络|Changze Lv, Tianlong Li, Wenhao Liu, Yufei Gu, Jianhan Xu, Cenyuan Zhang, Muling Wu, Xiaoqing Zheng .etc.|<http://arxiv.org/pdf/2310.06488v4>|[代码](https://github.com/Lvchangze/SpikeCLIP.); 提出SpikeCLIP框架，通过对比预训练和双损失微调，实现高效节能的多模态学习。|
|📝 更新|SPA-VL: A Comprehensive Safety Preference Alignment Dataset for Vision Language Model|SPA-VL：视觉语言模型的综合安全偏好对齐数据集|Yongting Zhang, Lu Chen, Guodong Zheng, Yifeng Gao, Rui Zheng, Jinlan Fu, Zhenfei Yin, Senjie Jin .etc.|<http://arxiv.org/pdf/2406.12030v4>|构建了大规模、高质量、多样化的SPA-VL数据集，以解决视觉语言模型安全对齐问题。|
|📝 更新|Investigating and Enhancing Vision-Audio Capability in Omnimodal Large Language Models|探究与提升全模态大型语言模型的视觉-音频能力|Rui Hu, Delai Qiu, Shuyu Wei, Jiaming Zhang, Yining Wang, Shengping Liu, Jitao Sang|<http://arxiv.org/pdf/2503.00059v2>|提出Self-KD训练法，提升OLLMs处理音频的能力，改善视觉与音频交互。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Aggregation Schemes for Single-Vector WSI Representation Learning in Digital Pathology|单向量WSI表示学习在数字病理学中的聚合方案|Sobhan Hemati, Ghazal Alabtah, Saghir Alfasly, H. R. Tizhoosh|<http://arxiv.org/pdf/2501.17822v2>|提出了一种针对数字病理学中全切片图像表示学习的聚合方案，显著提升了检索性能。|
|🆕 发布|Chain-of-Focus: Adaptive Visual Search and Zooming for Multimodal Reasoning via RL|链式焦点：通过强化学习实现的多模态推理的自适应视觉搜索和缩放|Xintong Zhang, Zhi Gao, Bofei Zhang, Pengxiang Li, Xiaowen Zhang, Yang Liu, Tao Yuan, Yuwei Wu .etc.|<http://arxiv.org/pdf/2505.15436v1>|提出了一种基于视觉语言模型的多模态推理方法，通过自适应聚焦和缩放实现高效的多模态推理。|
|📝 更新|DINOv2-powered Few-Shot Semantic Segmentation: A Unified Framework via Cross-Model Distillation and 4D Correlation Mining|DINOv2驱动的少样本语义分割：通过跨模型蒸馏和4D相关性挖掘的统一框架|Wei Zhuo, Zhiyue Tang, Wufeng Xue, Hao Ding, Linlin Shen|<http://arxiv.org/pdf/2504.15669v2>|提出FS-DINO，通过跨模型蒸馏和4D关联挖掘，实现轻量级语义分割，有效解决数据稀缺问题。|
|🆕 发布|Leveraging Foundation Models for Multimodal Graph-Based Action Recognition|利用基础模型进行多模态基于图的动作识别|Fatemeh Ziaeetabar, Florentin Wörgötter|<http://arxiv.org/pdf/2505.15192v1>|利用基础模型和动态图推理，实现了细粒度双臂操作动作的识别。|
|🆕 发布|MonoSplat: Generalizable 3D Gaussian Splatting from Monocular Depth Foundation Models|MonoSplat：基于单目深度基础模型的通用3D高斯分层|Yifan Liu, Keyu Fan, Weihao Yu, Chenxin Li, Hao Lu, Yixuan Yuan|<http://arxiv.org/pdf/2505.15185v1>|[代码](https://github.com/CUHK-AIM-Group/MonoSplat.); MonoSplat通过结合单目深度模型和轻量级特征适配器，实现了通用3D高保真渲染，提升了新场景下的...|
|📝 更新|MIRe: Enhancing Multimodal Queries Representation via Fusion-Free Modality Interaction for Multimodal Retrieval|MIRe：通过无融合模态交互增强多模态查询表示的多模态检索|Yeong-Joon Ju, Ho-Joong Kim, Seong-Whan Lee|<http://arxiv.org/pdf/2411.08334v3>|[代码](https://github.com/yeongjoonJu/MIRe); MIRe通过非融合模态交互增强多模态查询表示，有效缓解了文本主导问题，显著提升多模态检索性能。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visual Thoughts: A Unified Perspective of Understanding Multimodal Chain-of-Thought|视觉思维：理解多模态思维链的统一视角|Zihui Cheng, Qiguang Chen, Xiao Xu, Jiaqi Wang, Weiyun Wang, Hao Fei, Yidong Wang, Alex Jinpeng Wang .etc.|<http://arxiv.org/pdf/2505.15510v1>|揭示视觉思维如何提升多模态思维链，并提出四种视觉思维表达形式，以增强视觉语言模型的多模态理解能力。|
|🆕 发布|Directional Non-Commutative Monoidal Structures for Compositional Embeddings in Machine Learning|机器学习中的组合嵌入方向非交换幺半结构|Mahesh Godavarti|<http://arxiv.org/pdf/2505.15507v1>|引入了基于方向非交换张量算子的多维组合嵌入新框架，为机器学习中的序列建模提供统一的多维方法。|
|🆕 发布|Stronger ViTs With Octic Equivariance|更强的八次方等变性ViTs|David Nordström, Johan Edstedt, Fredrik Kahl, Georg Bökman|<http://arxiv.org/pdf/2505.15441v1>|通过引入八次对称性，提出的新架构八次ViT在保持性能的同时显著降低了计算复杂度。|
|🆕 发布|Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks|高效的数据驱动混合专家提取训练网络|Uranik Berisha, Jens Mehnert, Alexandru Paul Condurache|<http://arxiv.org/pdf/2505.15414v1>|提出一种从预训练模型中高效提取专家子网络的方法，显著降低模型复杂度和计算需求。|
|🆕 发布|Scaling Diffusion Transformers Efficiently via $μ$P|通过μP高效扩展扩散Transformer|Chenyu Zheng, Xinyu Zhang, Rongzhen Wang, Wei Huang, Zhi Tian, Weilin Huang, Jun Zhu, Chongxuan Li|<http://arxiv.org/pdf/2505.15270v1>|将Maximal Update Parametrization（$\mu$P）推广至扩散Transf...|
|🆕 发布|X-GRM: Large Gaussian Reconstruction Model for Sparse-view X-rays to Computed Tomography|X-GRM：用于稀疏视图X射线到计算机断层扫描的大高斯重建模型|Yifan Liu, Wuyang Li, Weihao Yu, Chenxin Li, Alexandre Alahi, Max Meng, Yixuan Yuan|<http://arxiv.org/pdf/2505.15235v1>|[代码](https://github.com/CUHK-AIM-Group/X-GRM.); 提出X-GRM模型，通过大规模训练数据和高容量模型，实现从稀疏X射线投影到高质量CT重建。|
|🆕 发布|Lossless Token Merging Even Without Fine-Tuning in Vision Transformers|视觉Transformer中即使不进行微调也能实现无损令牌合并|Jaeyeon Lee, Dong-Wan Choi|<http://arxiv.org/pdf/2505.15160v1>|提出ATM方法，实现视觉Transformer的无损token合并，无需微调即可保持高性能。|
|📝 更新|Efficient Partitioning Vision Transformer on Edge Devices for Distributed Inference|高效边缘设备上用于分布式推理的视觉Transformer分区|Xiang Liu, Yijun Song, Xia Li, Yifei Sun, Huiying Lan, Zemin Liu, Linshan Jiang, Jialin Li|<http://arxiv.org/pdf/2410.11650v2>|提出了一种高效分割执行复杂视觉Transformer的框架ED-ViT，显著降低边缘设备上的推理延迟...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Gompertz Linear Units: Leveraging Asymmetry for Enhanced Learning Dynamics|Gompertz线性单元：利用非对称性增强学习动态|Indrashis Das, Mahmoud Safari, Steven Adriaensen, Frank Hutter|<http://arxiv.org/pdf/2502.03654v2>|引入Gompertz线性单元，有效降低潜在空间方差，提升深度学习模型性能。|
|📝 更新|RGBX-DiffusionDet: A Framework for Multi-Modal RGB-X Object Detection Using DiffusionDet|RGBX-DiffusionDet：基于DiffusionDet的多模态RGB-X目标检测框架|Eliraz Orfaig, Inna Stainvas, Igal Bilik|<http://arxiv.org/pdf/2505.02586v2>|RGBX-DiffusionDet通过融合多模态数据并引入自适应编码器和新型正则化损失，显著提升了基...|
|📝 更新|Boosting Few-Shot Open-Set Object Detection via Prompt Learning and Robust Decision Boundary|通过提示学习和鲁棒决策边界提升小样本开放集目标检测|Zhaowei Wu, Binyi Su, Qichuan Geng, Hua Zhang, Zhong Zhou|<http://arxiv.org/pdf/2406.18443v3>|提出了一种基于提示学习和鲁棒决策边界构建的少量样本开放集目标检测框架，有效提升了未知类别拒绝能力。|
|🆕 发布|Multispectral Detection Transformer with Infrared-Centric Sensor Fusion|多光谱检测Transformer与以红外为中心的传感器融合|Seongmin Hwang, Daeyoung Han, Moongu Jeon|<http://arxiv.org/pdf/2505.15137v1>|[代码](https://github.com/smin-hwang/IC-Fusion.); 提出了一种以红外为中心的多光谱检测器，通过融合可见光和红外特征，有效提升了物体检测的鲁棒性。|
|📝 更新|Mask Image Watermarking|图像遮罩水印|Runyi Hu, Jie Zhang, Shiqian Zhao, Nils Lukas, Jiwei Li, Qing Guo, Han Qiu, Tianwei Zhang|<http://arxiv.org/pdf/2504.12739v2>|提出MaskMark，一种支持全局和局部水印嵌入、提取与定位的高效图像水印框架。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CLIMB-3D: Continual Learning for Imbalanced 3D Instance Segmentation|CLIMB-3D：不平衡3D实例分割的持续学习|Vishal Thengane, Jean Lahoud, Hisham Cholakkal, Rao Muhammad Anwer, Lu Yin, Xiatian Zhu, Salman Khan|<http://arxiv.org/pdf/2502.17429v2>|CLIMB-3D提出了一种针对不平衡3D实例分割的持续学习方法，通过伪标签生成和类别平衡重加权策略，...|
|🆕 发布|Detection of Underwater Multi-Targets Based on Self-Supervised Learning and Deformable Path Aggregation Feature Pyramid Network|基于自监督学习和可变形路径聚合特征金字塔网络的水下多目标检测|Chang Liu|<http://arxiv.org/pdf/2505.15518v1>|提出了一种基于自监督学习和可变形路径聚合特征金字塔网络的水下多目标检测方法，有效提升了检测精度和鲁棒...|
|🆕 发布|RAZER: Robust Accelerated Zero-Shot 3D Open-Vocabulary Panoptic Reconstruction with Spatio-Temporal Aggregation|RAZER：基于时空聚合的鲁棒加速零样本3D开放词汇全景重建|Naman Patel, Prashanth Krishnamurthy, Farshad Khorrami|<http://arxiv.org/pdf/2505.15373v1>|开发了一种无需训练的零样本3D场景理解框架，实现实时语义地图构建和自然语言交互。|
|🆕 发布|AuxDet: Auxiliary Metadata Matters for Omni-Domain Infrared Small Target Detection|辅助元数据对全域红外小目标检测至关重要|Yangting Shi, Renjie He, Le Hui, Xiang Li, Jian Yang, Ming-Ming Cheng, Yimian Dai|<http://arxiv.org/pdf/2505.15184v1>|[代码](https://github.com/GrokCV/AuxDet.); 提出了一种结合辅助元数据的红外小目标检测方法，显著提升了跨域检测的准确性和鲁棒性。|
|📝 更新|FaVoR: Features via Voxel Rendering for Camera Relocalization|基于体素渲染的相机重定位特征|Vincenzo Polizzi, Marco Cannici, Davide Scaramuzza, Jonathan Kelly|<http://arxiv.org/pdf/2409.07571v4>|提出了一种通过体素渲染构建稀疏特征描述符的方法，有效提升了相机重定位的鲁棒性和准确性。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spectral-Aware Global Fusion for RGB-Thermal Semantic Segmentation|光谱感知的RGB-热成像语义分割全局融合|Ce Zhang, Zifu Wan, Simon Stepputtis, Katia Sycara, Yaqi Xie|<http://arxiv.org/pdf/2505.15491v1>|提出了一种基于光谱感知的全局融合网络，有效融合RGB和热成像数据，提升语义分割性能。|
|🆕 发布|From Pixels to Images: Deep Learning Advances in Remote Sensing Image Semantic Segmentation|从像素到图像：遥感图像语义分割的深度学习进展|Quanwei Liu, Tao Huang, Yanni Dong, Jiaqi Yang, Wei Xiang|<http://arxiv.org/pdf/2505.15147v1>|该论文综述了深度学习在遥感图像语义分割领域的进展，通过分类和评估现有方法，揭示了从像素级到图像级、单...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Beyond Linearity: Squeeze-and-Recalibrate Blocks for Few-Shot Whole Slide Image Classification|超越线性：用于少样本全切片图像分类的挤压和重新校准块|Conghao Xiong, Zhengrui Guo, Zhe Xu, Yifei Zhang, Raymond Kai-Yu Tong, Si Yong Yeo, Hao Chen, Joseph J. Y. Sung .etc.|<http://arxiv.org/pdf/2505.15504v1>|提出Squeeze-and-Recalibrate块，有效解决少样本病理图像分类中的过拟合和特征误表...|
|🆕 发布|Objective Bicycle Occlusion Level Classification using a Deformable Parts-Based Model|基于可变形部件模型的客观自行车遮挡等级分类|Angelique Mangubat, Shane Gilroy|<http://arxiv.org/pdf/2505.15358v1>|提出了一种基于可变形部件模型的自行车遮挡等级分类方法，客观量化自行车可见性和遮挡程度。|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Symmetry-Robust 3D Orientation Estimation|对称鲁棒的3D姿态估计|Christopher Scarvelis, David Benhaim, Paul Zhang|<http://arxiv.org/pdf/2410.02101v3>|提出了一种基于Shapenet的对称鲁棒三维方向估计方法，有效解决了旋转对称形状的方向估计难题。|
|🆕 发布|Constructing a 3D Town from a Single Image|从单张图像构建3D城镇|Kaizhi Zheng, Ruijian Zhang, Jing Gu, Jie Yang, Xin Eric Wang|<http://arxiv.org/pdf/2505.15765v1>|提出了一种从单张俯视图生成真实3D城镇场景的无监督框架，克服了现有方法的几何不一致和布局幻觉问题。|
|🆕 发布|seg_3D_by_PC2D: Multi-View Projection for Domain Generalization and Adaptation in 3D Semantic Segmentation|基于PC2D的3D语义分割中的多视图投影与领域泛化和自适应|Andrew Caunes, Thierry Chateau, Vincent Fremont|<http://arxiv.org/pdf/2505.15545v1>|[代码](https://github.com/andrewcaunes/ia4markings); 提出了一种基于多视角投影的3D语义分割方法，有效解决域泛化和无监督域自适应问题。|
|📝 更新|TongUI: Building Generalized GUI Agents by Learning from Multimodal Web Tutorials|通UI：通过多模态网络教程学习构建通用GUI智能体|Bofei Zhang, Zirui Shang, Zhi Gao, Wang Zhang, Rui Xie, Xiaojian Ma, Tao Yuan, Xinxiao Wu .etc.|<http://arxiv.org/pdf/2504.12679v2>|提出TongUI框架，通过学习多模态网络教程构建通用GUI智能体，有效解决GUI智能体训练数据不足问...|
|🆕 发布|Reconsider the Template Mesh in Deep Learning-based Mesh Reconstruction|重新审视基于深度学习的网格重建中的模板网格|Fengting Zhang, Boxu Liang, Qinghao Liu, Min Liu, Xiang Chen, Yaonan Wang|<http://arxiv.org/pdf/2505.15285v1>|提出自适应模板方法，提升基于深度学习的网格重建精度和泛化能力。|
|🆕 发布|gen2seg: Generative Models Enable Generalizable Instance Segmentation|Gen2Seg：生成模型实现可泛化实例分割|Om Khangaonkar, Hamed Pirsiavash|<http://arxiv.org/pdf/2505.15263v1>|利用生成模型预训练，实现无需大量标注数据即可进行泛化实例分割。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Leveraging the Powerful Attention of a Pre-trained Diffusion Model for Exemplar-based Image Colorization|利用预训练扩散模型的强大注意力进行基于范例的图像着色|Satoshi Kosugi|<http://arxiv.org/pdf/2505.15812v1>|[代码](https://github.com/satoshi-kosugi/powerful-attention.); 利用预训练扩散模型的强大注意力机制，提出了一种无需微调的图像着色方法，显著提升了着色质量和参考图像的...|
|🆕 发布|VARD: Efficient and Dense Fine-Tuning for Diffusion Models with Value-based RL|VARD：基于值函数的强化学习在扩散模型中的高效且密集微调|Fengyuan Dai, Zifeng Zhuang, Yufei Huang, Siteng Huang, Bangyan Liao, Donglin Wang, Fajie Yuan|<http://arxiv.org/pdf/2505.15791v1>|提出VARD方法，通过价值函数和KL正则化实现扩散模型的高效和密集微调。|
|📝 更新|Dress-1-to-3: Single Image to Simulation-Ready 3D Outfit with Diffusion Prior and Differentiable Physics|服装1到3：基于扩散先验和可微物理的单图像到模拟准备3D服装|Xuan Li, Chang Yu, Wenxin Du, Ying Jiang, Tianyi Xie, Yunuo Chen, Yin Yang, Chenfanfu Jiang|<http://arxiv.org/pdf/2502.03449v2>|提出了一种从单张图片生成可模拟的3D服装的新方法，实现服装分离和动态动画。|
|📝 更新|Faster Video Diffusion with Trainable Sparse Attention|更快的学习稀疏注意力视频扩散|Peiyuan Zhang, Haofeng Huang, Yongqi Chen, Will Lin, Zhengzhong Liu, Ion Stoica, Eric Xing, Hao Zhang|<http://arxiv.org/pdf/2505.13389v2>|提出了一种可训练的稀疏注意力机制，显著提升了视频扩散模型的训练速度和效率。|
|🆕 发布|Visual Perturbation and Adaptive Hard Negative Contrastive Learning for Compositional Reasoning in Vision-Language Models|视觉扰动与自适应硬负对比学习在视觉-语言模型中的组合推理|Xin Huang, Ruibin Li, Tong Jia, Wei Zheng, Ya Wang|<http://arxiv.org/pdf/2505.15576v1>|[代码](https://github.com/nynu-BDAI/AHNPL.); 提出AHNPL方法，通过视觉扰动和自适应硬负样本对比学习，提升视觉语言模型在组合推理任务上的性能。|
|🆕 发布|PlantDreamer: Achieving Realistic 3D Plant Models with Diffusion-Guided Gaussian Splatting|植物梦境者：利用扩散引导高斯喷溅实现逼真的3D植物模型|Zane K J Hartley, Lewis A G Stuart, Andrew P French, Michael P Pound|<http://arxiv.org/pdf/2505.15528v1>|PlantDreamer通过扩散引导高斯分层技术，实现了比现有文本到3D模型更逼真的3D植物模型生成...|
|📝 更新|M3TR: A Generalist Model for Real-World HD Map Completion|M3TR：一种用于现实世界高清地图补全的通用模型|Fabian Immel, Richard Fehler, Frank Bieder, Jan-Hendrik Pauls, Christoph Stiller|<http://arxiv.org/pdf/2411.10316v4>|[代码](https://github.com/immel-f/m3tr); M3TR模型通过多掩码和利用先验信息，实现了高效且通用的真实世界高精度地图补全。|
|🆕 发布|Comprehensive Evaluation and Analysis for NSFW Concept Erasure in Text-to-Image Diffusion Models|全面评估与分析文本到图像扩散模型中的NSFW概念擦除|Die Chen, Zhiwen Li, Cen Chen, Yuexiang Xie, Xiaodan Li, Jinyan Ye, Yingda Chen, Yaliang Li|<http://arxiv.org/pdf/2505.15450v1>|首次系统评估NSFW内容擦除方法，提出全流程工具包以提升文本到图像扩散模型内容安全性。|
|🆕 发布|Expanding Zero-Shot Object Counting with Rich Prompts|基于丰富提示的零样本目标计数扩展|Huilin Zhu, Senyao Li, Jingling Yuan, Zhengwei Yang, Yu Guo, Wenxuan Liu, Xian Zhong, Shengfeng He|<http://arxiv.org/pdf/2505.15398v1>|RichCount通过丰富文本特征和强化图像关联，实现零样本计数模型对未见类别的高效泛化。|
|🆕 发布|My Face Is Mine, Not Yours: Facial Protection Against Diffusion Model Face Swapping|我的脸是我的，不是你的：对抗扩散模型人脸交换的隐私保护|Hon Ming Yam, Zhongliang Guo, Chun Pong Lau|<http://arxiv.org/pdf/2505.15336v1>|针对扩散模型人脸换脸风险，提出一种基于对抗攻击的主动防御策略，有效保护人脸图像不被滥用。|
|🆕 发布|BadSR: Stealthy Label Backdoor Attacks on Image Super-Resolution|BadSR：图像超分辨率中的隐蔽标签后门攻击|Ji Guo, Xiaolei Wen, Wenbo Jiang, Cheng Huang, Jinjin Li, Hongwei Li|<http://arxiv.org/pdf/2505.15308v1>|提出BadSR，通过优化特征空间和触发器设计，提升了图像超分辨率模型中恶意样本的隐蔽性。|
|📝 更新|SpaceR: Reinforcing MLLMs in Video Spatial Reasoning|空间R：强化视频空间推理中的多模态语言模型|Kun Ouyang, Yuanxin Liu, Haoning Wu, Yi Liu, Hao Zhou, Jie Zhou, Fandong Meng, Xu Sun|<http://arxiv.org/pdf/2504.01805v2>|[代码](https://github.com/OuyangKun10/SpaceR.); SpaceR通过引入SG-RLVR和SpaceR-151k数据集，显著提升了MLLM在视频空间推理方...|
|🆕 发布|Exploring In-Image Machine Translation with Real-World Background|探索具有真实世界背景的图像内机器翻译|Yanzhi Tian, Zeming Liu, Zhengyang Liu, Yuhang Guo|<http://arxiv.org/pdf/2505.15282v1>|提出DebackX模型，解决复杂场景下图像字幕机器翻译问题，提升翻译质量和视觉效果。|
|📝 更新|MagicTailor: Component-Controllable Personalization in Text-to-Image Diffusion Models|魔裁缝：文本到图像扩散模型中的组件可控个性化|Donghao Zhou, Jiancheng Huang, Jinbin Bai, Jiaze Wang, Hao Chen, Guangyong Chen, Xiaowei Hu, Pheng-Ann Heng|<http://arxiv.org/pdf/2410.13370v3>|MagicTailor通过组件可控个性化，解决文本到图像扩散模型缺乏细粒度视觉概念控制的问题，实现更...|
|📝 更新|Sparc3D: Sparse Representation and Construction for High-Resolution 3D Shapes Modeling|稀疏表示与构建：高分辨率3D形状建模|Zhihao Li, Yufei Wang, Heliang Zheng, Yihao Luo, Bihan Wen|<http://arxiv.org/pdf/2505.14521v2>|Sparc3D通过结合稀疏表示和新型编码器，实现了高分辨率3D形状的无损重建。|
|📝 更新|Video-GPT via Next Clip Diffusion|视频GPT：通过下一帧扩散|Shaobin Zhuang, Zhipeng Huang, Ying Zhang, Fangyikang Wang, Canmiao Fu, Binxin Yang, Chong Sun, Chen Li .etc.|<http://arxiv.org/pdf/2505.12489v2>|[代码](https://zhuangshaobin.github.io/Video-GPT.github.io); 提出Video-GPT，通过视频序列建模视觉世界，实现视频预测和理解的突破。|
|📝 更新|DD-Ranking: Rethinking the Evaluation of Dataset Distillation|DD-Ranking：重新思考数据集蒸馏的评估|Zekai Li, Xinhao Zhong, Samir Khaki, Zhiyuan Liang, Yuhao Zhou, Mingjia Shi, Ziqiao Wang, Xuanlei Zhao .etc.|<http://arxiv.org/pdf/2505.13300v2>|提出DD-Ranking统一评估框架，解决数据蒸馏方法评价不公问题。|
|🆕 发布|Non-rigid Motion Correction for MRI Reconstruction via Coarse-To-Fine Diffusion Models|非刚性运动校正的MRI重建：通过粗到细的扩散模型|Frederic Wang, Jonathan I. Tamir|<http://arxiv.org/pdf/2505.15057v1>|提出了一种利用定制扩散模型进行MRI重建和非刚性运动校正的新框架，有效减少运动伪影。|
|🆕 发布|AsynFusion: Towards Asynchronous Latent Consistency Models for Decoupled Whole-Body Audio-Driven Avatars|异步融合：迈向解耦全身音频驱动虚拟角色的异步潜在一致性模型|Tianbao Zhang, Jian Zhao, Yuer Li, Zheng Zhu, Ping Hu, Zhaoxin Fan, Wenjun Wu, Xuelong Li|<http://arxiv.org/pdf/2505.15058v1>|提出AsynFusion，通过扩散变换器实现同步生成面部表情和手势，解决全身体验动画协调性问题。|
|📝 更新|Unsupervised Detection of Distribution Shift in Inverse Problems using Diffusion Models|无监督检测逆问题中的分布偏移：基于扩散模型|Shirin Shoushtari, Edward P. Chandler, M. Salman Asif, Ulugbek S. Kamilov|<http://arxiv.org/pdf/2505.11482v2>|提出了一种无需监督的基于扩散模型的方法，用于检测和量化图像逆问题中的分布偏移。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Interspatial Attention for Efficient 4D Human Video Generation|空间间注意力在高效4D人体视频生成中的应用|Ruizhi Shao, Yinghao Xu, Yujun Shen, Ceyuan Yang, Yang Zheng, Changan Chen, Yebin Liu, Gordon Wetzstein|<http://arxiv.org/pdf/2505.15800v1>|[代码](https://dsaurus.github.io/isa4d); 引入 interspatial attention 机制，显著提升 4D 人体视频生成质量与一致性。|
|📝 更新|Denoising Score Distillation: From Noisy Diffusion Pretraining to One-Step High-Quality Generation|去噪评分蒸馏：从噪声扩散预训练到一步高质量生成|Tianyu Chen, Yasi Zhang, Zhendong Wang, Ying Nian Wu, Oscar Leong, Mingyuan Zhou|<http://arxiv.org/pdf/2503.07578v2>|提出了一种从低质量数据训练高质量生成模型的新方法，即去噪得分蒸馏。|
|🆕 发布|IA-T2I: Internet-Augmented Text-to-Image Generation|IA-T2I：互联网增强的文本到图像生成|Chuanhao Li, Jianwen Sun, Yukang Feng, Mingliang Zhai, Yifan Chang, Kaipeng Zhang|<http://arxiv.org/pdf/2505.15779v1>|提出IA-T2I框架，通过提供参考图像帮助T2I模型处理文本提示中的不确定知识。|
|📝 更新|MIRACL-VISION: A Large, multilingual, visual document retrieval benchmark|MIRACL-VISION：一个大型、多语言、视觉文档检索基准|Radek Osmulski, Gabriel de Souza P. Moreira, Ronay Ak, Mengyao Xu, Benedikt Schifferer, Even Oldridge|<http://arxiv.org/pdf/2505.11651v2>|构建了多语言视觉文档检索基准MIRACL-VISION，解决了现有基准语言单一、数据量小的问题。|
|🆕 发布|Exploring the Limits of Vision-Language-Action Manipulations in Cross-task Generalization|探索跨任务泛化中视觉-语言-动作操作的极限|Jiaming Zhou, Ke Ye, Jiayi Liu, Teli Ma, Zifang Wang, Ronghe Qiu, Kun-Yu Lin, Zhilin Zhao .etc.|<http://arxiv.org/pdf/2505.15660v1>|设计AGNOSTOS基准和X-ICM方法，提升VLA模型在未知任务上的跨任务泛化能力。|
|📝 更新|How far can we go with ImageNet for Text-to-Image generation?|我们能将ImageNet在文本到图像生成中推进多远？|L. Degeorge, A. Ghosh, N. Dufour, D. Picard, V. Kalogeiton|<http://arxiv.org/pdf/2502.21318v2>|利用增强的ImageNet数据集，通过精心设计的文本和图像增强，实现了与大规模网络爬取数据集训练的模...|
|📝 更新|Scaling Text-Rich Image Understanding via Code-Guided Synthetic Multimodal Data Generation|通过代码引导的合成多模态数据生成扩展文本丰富图像理解|Yue Yang, Ajay Patel, Matt Deitke, Tanmay Gupta, Luca Weihs, Andrew Head, Mark Yatskar, Chris Callison-Burch .etc.|<http://arxiv.org/pdf/2502.14846v2>|提出CoSyn框架，通过代码生成合成多模态数据，解决文本丰富图像理解数据稀缺问题。|
|🆕 发布|FRN: Fractal-Based Recursive Spectral Reconstruction Network|基于分形的多级谱重建网络|Ge Meng, Zhongnan Cai, Ruizhe Chen, Jingyan Tu, Yingying Wang, Yue Huang, Xinghao Ding|<http://arxiv.org/pdf/2505.15439v1>|提出了一种基于分形递归的渐进式光谱重建网络，有效降低了高光谱图像重建成本。|
|📝 更新|PlaySlot: Learning Inverse Latent Dynamics for Controllable Object-Centric Video Prediction and Planning|PlaySlot：学习可控制的对象中心视频预测与规划的反向潜在动力学|Angel Villar-Corrales, Sven Behnke|<http://arxiv.org/pdf/2502.07600v2>|[代码](https://play-slot.github.io/PlaySlot); 提出PlaySlot，一种从无标签视频中学习物体表示和动作，实现可控物体中心视频预测和规划的模型。|
|🆕 发布|Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study|在野外的视觉-语言模型安全吗？基于迷因的基准研究|DongGeon Lee, Joonwon Jang, Jihae Jeong, Hwanjo Yu|<http://arxiv.org/pdf/2505.15389v1>|研究视觉语言模型在真实网络迷因图像下的安全性，提出MemeSafetyBench基准测试，揭示模型对...|
|📝 更新|Ca2-VDM: Efficient Autoregressive Video Diffusion Model with Causal Generation and Cache Sharing|Ca2-VDM：具有因果生成和缓存共享的高效自回归视频扩散模型|Kaifeng Gao, Jiaxin Shi, Hanwang Zhang, Chunping Wang, Jun Xiao, Long Chen|<http://arxiv.org/pdf/2411.16375v2>|[代码](https://github.com/Dawn-LX/CausalCache-VDM); 提出Ca2-VDM，通过因果生成和缓存共享，有效提升视频扩散模型的生成效率和速度。|
|🆕 发布|FaceCrafter: Identity-Conditional Diffusion with Disentangled Control over Facial Pose, Expression, and Emotion|面部工匠：基于身份条件的扩散模型，对面部姿态、表情和情感的解耦控制|Kazuaki Mishima, Antoni Bigata Casademunt, Stavros Petridis, Maja Pantic, Kenji Suzuki|<http://arxiv.org/pdf/2505.15313v1>|提出了一种新型身份条件扩散模型，独立控制面部姿态、表情和情绪，同时保持身份特征。|
|🆕 发布|R3GS: Gaussian Splatting for Robust Reconstruction and Relocalization in Unconstrained Image Collections|R3GS：非约束图像集合中的鲁棒重建和重定位的高斯喷溅|Xu yan, Zhaohui Wang, Rong Wei, Jingbo Yu, Dong Li, Xiangde Liu|<http://arxiv.org/pdf/2505.15294v1>|R3GS通过结合CNN全局特征和局部特征，以及优化天空处理和重定位方法，实现了对无约束图像集的鲁棒重...|
|🆕 发布|GS2E: Gaussian Splatting is an Effective Data Generator for Event Stream Generation|GS2E：高斯喷溅是事件流生成中有效的数据生成器|Yuchen Li, Chaoran Feng, Zhenyu Tang, Kaiyuan Deng, Wangbo Yu, Yonghong Tian, Li Yuan|<http://arxiv.org/pdf/2505.15287v1>|GS2E通过3D高斯分层重建和物理信息驱动的模拟，生成高保真事件数据集，解决现有事件数据集视角多样性...|
|🆕 发布|Intentional Gesture: Deliver Your Intentions with Gestures for Speech|有意手势：用手势传达你的意图以实现语音|Pinxin Liu, Haiyang Liu, Luchuan Song, Chenliang Xu|<http://arxiv.org/pdf/2505.15197v1>|[代码](https://andypinxinliu.github.io/Intentional-Gesture); 提出了一种基于意图的动态手势生成框架，显著提升了手势的语义丰富度和与语音的同步性。|
|🆕 发布|Harnessing Caption Detailness for Data-Efficient Text-to-Image Generation|利用描述细节提高数据高效文本到图像生成|Xinran Wang, Muxi Diao, Yuanzhi Liu, Chunyu Wang, Kongming Liang, Zhanyu Ma, Jun Guo|<http://arxiv.org/pdf/2505.15172v1>|提出基于图像覆盖率和平均对象细节度的新指标，提升文本到图像生成模型的数据效率。|
|📝 更新|AnyCharV: Bootstrap Controllable Character Video Generation with Fine-to-Coarse Guidance|AnyCharV：基于细到粗引导的自举可控字符视频生成|Zhao Wang, Hao Wen, Lingting Zhu, Chenming Shang, Yujiu Yang, Qi Dou|<http://arxiv.org/pdf/2502.08189v2>|AnyCharV通过两阶段训练和自增强机制，实现灵活可控的字符视频生成。|
|🆕 发布|CineTechBench: A Benchmark for Cinematographic Technique Understanding and Generation|电影技术基准：电影技术理解和生成基准|Xinran Wang, Songyu Xu, Xiangxuan Shan, Yuxuan Zhang, Muxi Diao, Xueyan Duan, Yanhua Huang, Kongming Liang .etc.|<http://arxiv.org/pdf/2505.15145v1>|[代码](https://github.com/PRIS-CV/CineTechBench.); 构建CineTechBench基准，以解决电影摄影技术理解和生成中的数据稀缺问题。|
|📝 更新|VoiceCloak: A Multi-Dimensional Defense Framework against Unauthorized Diffusion-based Voice Cloning|《VoiceCloak：针对未经授权的基于扩散的语音克隆的多维防御框架》|Qianyue Hu, Junyan Wu, Wei Lu, Xiangyang Luo|<http://arxiv.org/pdf/2505.12332v2>|VoiceCloak通过引入对抗性扰动和噪声引导语义破坏，有效防御基于扩散模型的非法语音克隆。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|BusterX: MLLM-Powered AI-Generated Video Forgery Detection and Explanation|BusterX：基于MLLM的AI生成视频伪造检测与解释|Haiquan Wen, Yiwei He, Zhenglin Huang, Tianxiao Li, Zihan Yu, Xingru Huang, Lu Qi, Baoyuan Wu .etc.|<http://arxiv.org/pdf/2505.12620v2>|提出BusterX框架，利用MLLM和强化学习检测并解释AI生成视频伪造，解决现有方法缺乏可解释性和...|
|📝 更新|MLEP: Multi-granularity Local Entropy Patterns for Universal AI-generated Image Detection|多粒度局部熵模式用于通用AI生成图像检测|Lin Yuan, Xiaowan Li, Yan Zhang, Jiawei Zhang, Hongbo Li, Xinbo Gao|<http://arxiv.org/pdf/2504.13726v2>|提出MLEP方法，通过多尺度局部熵模式识别AI生成图像，显著提升检测准确性和泛化能力。|
|🆕 发布|Blind Spot Navigation: Evolutionary Discovery of Sensitive Semantic Concepts for LVLMs|盲点导航：LVLMs敏感语义概念的进化发现|Zihao Pan, Yu Tong, Weibin Wu, Jingyi Wang, Lifeng Chen, Zhe Zhao, Jiajia Wei, Yitong Qiao .etc.|<http://arxiv.org/pdf/2505.15265v1>|提出了一种基于LLMs和T2I模型的语义进化框架，以发现LVLMs敏感的语义概念，提升模型鲁棒性。|
|🆕 发布|CAD: A General Multimodal Framework for Video Deepfake Detection via Cross-Modal Alignment and Distillation|计算机视觉：一种基于跨模态对齐和蒸馏的通用多模态视频深度伪造检测框架|Yuxuan Du, Zhendong Wang, Yuhao Luo, Caiyong Piao, Zhiyuan Yan, Hao Li, Li Yuan|<http://arxiv.org/pdf/2505.15233v1>|提出CAD框架，通过跨模态对齐和蒸馏，有效检测视频深度伪造。|
|📝 更新|Accelerating Diffusion-based Super-Resolution with Dynamic Time-Spatial Sampling|加速基于扩散的超分辨率动态时空采样|Rui Qin, Qijie Wang, Ming Sun, Haowei Zhu, Chao Zhou, Bin Wang|<http://arxiv.org/pdf/2505.12048v2>|提出了一种基于动态时间-空间采样的加速扩散超分辨率方法，显著提升性能并减少迭代次数。|
|📝 更新|SeMv-3D: Towards Concurrency of Semantic and Multi-view Consistency in General Text-to-3D Generation|SeMv-3D：迈向通用文本到3D生成中语义和多视图一致性并行的研究|Xiao Cai, Pengpeng Zeng, Lianli Gao, Sitong Su, Heng Tao Shen, Jingkuan Song|<http://arxiv.org/pdf/2410.07658v2>|SeMv-3D通过引入Triplane Prior Learning和SAT，实现了语义对齐与多视角...|
|🆕 发布|AvatarShield: Visual Reinforcement Learning for Human-Centric Video Forgery Detection|AvatarShield：以人为中心的视频伪造检测的视觉强化学习|Zhipei Xu, Xuanyu Zhang, Xing Zhou, Jian Zhang|<http://arxiv.org/pdf/2505.15173v1>|提出AvatarShield，首个基于可解释的MLLM框架，通过GRPO优化，有效检测人类中心化视频...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Taxonomy of Structure from Motion Methods|运动结构分类法|Federica Arrigoni|<http://arxiv.org/pdf/2505.15814v1>|构建了结构从运动方法的分类体系，为现有方法提供新视角并指导未来研究方向。|
|🆕 发布|RUSplatting: Robust 3D Gaussian Splatting for Sparse-View Underwater Scene Reconstruction|鲁棒3D高斯分层：稀疏视场水下场景重建的鲁棒分层|Zhuodong Jiang, Haoran Wang, Guoxi Huang, Brett Seymour, Nantheera Anantrasirichai|<http://arxiv.org/pdf/2505.15737v1>|提出了一种鲁棒的3D高斯分层渲染框架，有效提升水下场景重建的视觉质量和几何精度。|
|🆕 发布|EVA: Expressive Virtual Avatars from Multi-view Videos|EVA：基于多视角视频的富有表现力的虚拟形象|Hendrik Junkawitsch, Guoxing Sun, Heming Zhu, Christian Theobalt, Marc Habermann|<http://arxiv.org/pdf/2505.15385v1>|提出EVA框架，通过分离面部和身体模型，实现高保真、可控制的人形虚拟角色渲染。|
|🆕 发布|GT^2-GS: Geometry-aware Texture Transfer for Gaussian Splatting|GT^2-GS：高斯分层中的几何感知纹理迁移|Wenjie Liu, Zhongliang Liu, Junwei Shu, Changbo Wang, Yang Li|<http://arxiv.org/pdf/2505.15208v1>|[代码](https://vpx-ecnu.github.io/GT2-GS-website.); 提出了一种结合几何信息的纹理迁移框架，显著提升了3D场景纹理的视觉效果。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HAMF: A Hybrid Attention-Mamba Framework for Joint Scene Context Understanding and Future Motion Representation Learning|混合注意力-曼巴框架：用于联合场景上下文理解和未来运动表示学习的框架|Xiaodong Mei, Sheng Wang, Jie Cheng, Yingbing Chen, Dan Xu|<http://arxiv.org/pdf/2505.15703v1>|提出了一种结合场景理解和未来运动预测的混合注意力-Mamba框架，显著提升了运动预测的准确性。|
|📝 更新|P3P: Pseudo-3D Pre-training for Scaling 3D Voxel-based Masked Autoencoders|P3P：用于扩展3D体素基掩码自编码器的伪3D预训练|Xuechao Chen, Ying Chen, Jialin Li, Qiang Nie, Hanqiu Deng, Yong Liu, Qixing Huang, Yang Li|<http://arxiv.org/pdf/2408.10007v3>|[代码](https://github.com/XuechaoChen/P3P-MAE.); 提出P3P框架，通过深度估计模型扩展3D数据集，实现高效3D模型预训练，提升3D感知任务性能。|
|🆕 发布|Continuous Representation Methods, Theories, and Applications: An Overview and Perspectives|连续表示方法、理论与应用：综述与展望|Yisi Luo, Xile Zhao, Deyu Meng|<http://arxiv.org/pdf/2505.15222v1>|[代码](https://github.com/YisiLuo/Continuous-Representation-Zoo.); 该论文综述了连续表示方法在计算机视觉中的应用，提出了基于函数映射的连续框架，提高了数据表示和重建的性...|
|📝 更新|EventSplat: 3D Gaussian Splatting from Moving Event Cameras for Real-time Rendering|事件喷溅：基于移动事件相机的3D高斯喷溅实时渲染|Toshiya Yura, Ashkan Mirzaei, Igor Gilitschenski|<http://arxiv.org/pdf/2412.07293v2>|EventSplat通过3D高斯分层从移动事件相机中实现实时渲染，有效解决快速运动场景下的新型视图合...|
|🆕 发布|Exploring Generalized Gait Recognition: Reducing Redundancy and Noise within Indoor and Outdoor Datasets|探索广义步态识别：降低室内和室外数据集中的冗余和噪声|Qian Zhou, Xianda Guo, Jilong Wang, Chuanfu Shen, Zhongyuan Wang, Hua Zou, Qin Zou, Chao Liang .etc.|<http://arxiv.org/pdf/2505.15176v1>|[代码](https://github.com/li1er3/Generalized_Gait.); 提出了一种统一框架，通过解耦三元组损失和目标数据集蒸馏策略，有效提升跨域步态识别性能。|
|🆕 发布|Unified Cross-Modal Attention-Mixer Based Structural-Functional Connectomics Fusion for Neuropsychiatric Disorder Diagnosis|统一跨模态注意力-混合器基于结构-功能连接组学融合的神经精神疾病诊断|Badhan Mazumder, Lei Wu, Vince D. Calhoun, Dong Hye Ye|<http://arxiv.org/pdf/2505.15139v1>|提出了一种融合结构-功能连接组学数据的跨模态注意力混合方法，有效提升了神经精神疾病诊断性能。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment|CAV-MAE Sync：通过细粒度对齐提升对比音频-视觉掩码自编码器|Edson Araujo, Andrew Rouditchenko, Yuan Gong, Saurabhchand Bhati, Samuel Thomas, Brian Kingsbury, Leonid Karlinsky, Rogerio Feris .etc.|<http://arxiv.org/pdf/2505.01237v2>|提出CAV-MAE Sync，通过细粒度对齐和分离优化目标，提升音频-视觉掩码自编码器的性能。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Clapper: Compact Learning and Video Representation in VLMs|紧凑学习与VLMs中的视频表示：Clapper|Lingyu Kong, Hongzhi Zhang, Jingyuan Zhang, Jianzhao Huang, Kunze Li, Qi Wang, Fuzheng Zhang|<http://arxiv.org/pdf/2505.15529v1>|Clapper通过慢快策略和时间感知器模块，有效建模视频输入，实现长视频理解的高效压缩。|
|🆕 发布|LiveVLM: Efficient Online Video Understanding via Streaming-Oriented KV Cache and Retrieval|实时视频理解：通过流式导向的KV缓存和检索的高效在线方法|Zhenyu Ning, Guangda Liu, Qihao Jin, Wenchao Ding, Minyi Guo, Jieru Zhao|<http://arxiv.org/pdf/2505.15269v1>|LiveVLM通过构建流式KV缓存和检索，实现高效在线视频理解，大幅提升处理速度和内存效率。|
|🆕 发布|Flashback: Memory-Driven Zero-shot, Real-time Video Anomaly Detection|闪回：基于记忆的零样本、实时视频异常检测|Hyogun Lee, Haksub Kim, Ig-Jae Kim, Yonghun Choi|<http://arxiv.org/pdf/2505.15205v1>|Flashback通过构建伪场景记忆库，实现零样本、实时视频异常检测。|
|📝 更新|VideoPASTA: 7K Preference Pairs That Matter for Video-LLM Alignment|视频PASTA：对视频-LLM对齐至关重要的7K偏好对|Yogesh Kulkarni, Pooyan Fazli|<http://arxiv.org/pdf/2504.14096v2>|VideoPASTA通过偏好优化和对抗训练，有效提升视频语言模型对视频内容的理解和空间、时间关系的捕...|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DLO-Splatting: Tracking Deformable Linear Objects Using 3D Gaussian Splatting|DLO-Splatting：利用3D高斯Splatting跟踪可变形线性物体|Holly Dinkel, Marcel Büsching, Alberta Longhini, Brian Coltin, Trey Smith, Danica Kragic, Mårten Björkman, Timothy Bretl|<http://arxiv.org/pdf/2505.08644v2>|提出DLO-Splatting算法，通过3D高斯分层渲染预测和更新滤波，从多视角图像和机械臂状态信息...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes|鼠标锁盒数据集：解决锁盒的鼠标行为识别|Patrik Reiske, Marcus N. Boon, Niek Andresen, Sole Traverso, Katharina Hohlbaum, Lars Lewejohann, Christa Thöne-Reineke, Olaf Hellwich .etc.|<http://arxiv.org/pdf/2505.15408v1>|构建了Mouse Lockbox数据集，用于识别小鼠解决机械锁盒行为的动作分类。|
|📝 更新|SPRMamba: Surgical Phase Recognition for Endoscopic Submucosal Dissection with Mamba|SPRMamba：基于Mamba的内镜黏膜下剥离手术阶段识别|Xiangning Zhang, Qingwei Zhang, Jinnan Chen, Chengfeng Zhou, Yaqi Wang, Zhengjie Zhang, Xiaobo Li, Dahong Qian|<http://arxiv.org/pdf/2409.12108v2>|[代码](https://github.com/Zxnyyyyy/SPRMamba.); 提出SPRMamba，通过结合Mamba架构和SRTM块，实现高效实时识别ESD手术阶段。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Contrastive Learning-Enhanced Trajectory Matching for Small-Scale Dataset Distillation|对比学习增强的小规模数据集蒸馏轨迹匹配|Wenmin Li, Shunsuke Sakai, Tatsuhito Hasegawa|<http://arxiv.org/pdf/2505.15267v1>|提出了一种结合对比学习的轨迹匹配方法，有效提升小规模数据集蒸馏的语义丰富度和模型性能。|
|🆕 发布|GAMA++: Disentangled Geometric Alignment with Adaptive Contrastive Perturbation for Reliable Domain Transfer|GAMA++：基于自适应对比扰动解耦几何对齐的可靠领域迁移|Kim Yun, Hana Satou, F Monkey|<http://arxiv.org/pdf/2505.15241v1>|GAMA++通过解耦几何对齐和自适应对比扰动，提升了可靠领域迁移的准确性。|
|🆕 发布|Geometrically Regularized Transfer Learning with On-Manifold and Off-Manifold Perturbation|基于流形内和外扰动几何正则化的迁移学习|Hana Satou, Alan Mitkiy, F Monkey|<http://arxiv.org/pdf/2505.15191v1>|提出MAADA框架，通过分解对抗扰动，同时捕捉语义变化和模型脆弱性，有效解决域偏移下的迁移学习问题。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Streamline Without Sacrifice -- Squeeze out Computation Redundancy in LMM|简化而不牺牲 —— 在LMM中挤压计算冗余|Penghao Wu, Lewei Lu, Ziwei Liu|<http://arxiv.org/pdf/2505.15816v1>|[代码](https://github.com/penghao-wu/ProxyV); 提出ProxyV方法，通过代理视觉token减轻计算负担，提升LMM效率而不牺牲性能。|
|📝 更新|Scaling and Enhancing LLM-based AVSR: A Sparse Mixture of Projectors Approach|基于LLM的AVSR的扩展与增强：投影器稀疏混合方法|Umberto Cappellazzo, Minsu Kim, Stavros Petridis, Daniele Falavigna, Alessio Brutti|<http://arxiv.org/pdf/2505.14336v2>|提出Llama-SMoP，通过稀疏混合投影器模块降低LLM-AVSR计算成本，提升模型性能。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Learning Task-preferred Inference Routes for Gradient De-conflict in Multi-output DNNs|学习多输出深度神经网络中梯度去冲突的任务偏好推理路径|Yi Sun, Xin Xu, Jian Li, Xiaochang Hu, Yifei Shi, Ling-Li Zeng|<http://arxiv.org/pdf/2305.19844v2>|提出DR-MGF算法，通过学习任务偏好路径解决多输出DNN梯度冲突问题，提升模型性能。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Convolutional Long Short-Term Memory Neural Networks Based Numerical Simulation of Flow Field|卷积长短期记忆神经网络在流场数值模拟中的应用|Chang Liu|<http://arxiv.org/pdf/2505.15533v1>|提出了一种基于改进ConvLSTM的轻量级流体场预测模型，有效提升了预测精度和效率。|
|🆕 发布|Pura: An Efficient Privacy-Preserving Solution for Face Recognition|Pura：一种高效的人脸识别隐私保护解决方案|Guotao Xu, Bowen Zhao, Yang Xiao, Yantao Zhong, Liang Zhai, Qingqi Pei|<http://arxiv.org/pdf/2505.15476v1>|Pura提出了一种高效隐私保护的人脸识别方案，实现加密数据上的快速人脸识别。|
|🆕 发布|DiffProb: Data Pruning for Face Recognition|DiffProb：面向人脸识别的数据剪枝|Eduarda Caldeira, Jan Niklas Kolf, Naser Damer, Fadi Boutros|<http://arxiv.org/pdf/2505.15272v1>|DiffProb通过数据剪枝技术，有效减少人脸识别训练数据量，同时保持或提升识别准确率。|
|📝 更新|MambaFlow: A Mamba-Centric Architecture for End-to-End Optical Flow Estimation|MambaFlow：一种以Mamba为中心的端到端光流估计架构|Juntian Du, Yuan Sun, Zhihu Zhou, Pinyi Chen, Runzhe Zhang, Keji Mao|<http://arxiv.org/pdf/2503.07046v2>|提出MambaFlow架构，首次将Mamba设计应用于光流估计，显著提升准确性和效率。|
|🆕 发布|Physics-Guided Multi-View Graph Neural Network for Schizophrenia Classification via Structural-Functional Coupling|基于物理引导的多视图图神经网络通过结构-功能耦合进行精神分裂症分类|Badhan Mazumder, Ayush Kanyal, Lei Wu, Vince D. Calhoun, Dong Hye Ye|<http://arxiv.org/pdf/2505.15135v1>|提出了一种基于物理引导的多视图图神经网络，通过结构-功能耦合提高了精神分裂症分类的准确性。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DeepKD: A Deeply Decoupled and Denoised Knowledge Distillation Trainer|深度解耦和降噪知识蒸馏训练器：DeepKD|Haiduo Huang, Jiangcheng Song, Yadong Zhang, Pengju Ren|<http://arxiv.org/pdf/2505.15133v1>|[代码](https://github.com/haiduo/DeepKD.); DeepKD通过双级解耦和自适应降噪，有效解决了知识蒸馏中的噪声和冲突问题。|
|📝 更新|SSR: Enhancing Depth Perception in Vision-Language Models via Rationale-Guided Spatial Reasoning|SSR：通过理性引导的空间推理增强视觉-语言模型中的深度感知|Yang Liu, Ming Ma, Xiaomin Yu, Pengxiang Ding, Han Zhao, Mingyang Sun, Siteng Huang, Donglin Wang|<http://arxiv.org/pdf/2505.12448v2>|[代码](https://yliu-cs.github.io/SSR.); 提出SSR方法，通过理性引导的空间推理增强视觉语言模型对深度信息的理解和利用。|
|📝 更新|Volumetrically Consistent 3D Gaussian Rasterization|体素一致的三维高斯光栅化|Chinmay Talegaonkar, Yash Belhe, Ravi Ramamoorthi, Nicholas Antipa|<http://arxiv.org/pdf/2412.03378v3>|[代码](https://github.com/chinmay0301ucsd/Vol3DGS); 提出了一种更精确的3D体积渲染方法，通过直接体积积分3D高斯，超越3DGS，实现更快的视图合成。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhancing Monte Carlo Dropout Performance for Uncertainty Quantification|增强蒙特卡洛Dropout在不确定性量化中的性能|Hamzeh Asgharnezhad, Afshar Shamsi, Roohallah Alizadehsani, Arash Mohammadi, Hamid Alinejad-Rokny|<http://arxiv.org/pdf/2505.15671v1>|提出创新框架增强蒙特卡洛dropout，提升深度学习模型不确定性量化可靠性。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|The Devil is in Fine-tuning and Long-tailed Problems:A New Benchmark for Scene Text Detection|细节调优与长尾问题中的魔鬼：场景文本检测的新基准|Tianjiao Cao, Jiahao Lyu, Weichao Zeng, Weimin Mu, Yu Zhou|<http://arxiv.org/pdf/2505.15649v1>|[代码](https://github.com/pd162/LTB.); 提出长尾场景文本检测新基准LTB，倡导联合数据集学习缓解微调差距。|
|🆕 发布|A Methodology to Evaluate Strategies Predicting Rankings on Unseen Domains|标题翻译结果：  评估预测未见领域排名策略的方法|Sébastien Piérard, Adrien Deliège, Anaïs Halin, Marc Van Droogenbroeck|<http://arxiv.org/pdf/2505.15595v1>|提出一种评估预测未见领域排名策略的方法，以降低新领域评估成本。|
|📝 更新|DisCoPatch: Batch Statistics Are All You Need For OOD Detection, But Only If You Can Trust Them|DisCoPatch：批量统计量是用于异常检测的全部所需，但前提是您能信任它们|Francisco Caetano, Christiaan Viviers, Luis A. Zavala-Mondragón, Peter H. N. de With, Fons van der Sommen|<http://arxiv.org/pdf/2501.08005v2>|DisCoPatch通过利用批处理统计信息，有效提升了异常检测性能，尤其适用于数据分布变化问题。|
|🆕 发布|Kernel PCA for Out-of-Distribution Detection: Non-Linear Kernel Selections and Approximations|核主成分分析用于分布外检测：非线性核选择与近似|Kun Fang, Qinghua Tao, Mingzhen He, Kexin Lv, Runze Yang, Haibo Hu, Xiaolin Huang, Jie Yang .etc.|<http://arxiv.org/pdf/2505.15284v1>|提出了一种基于非线性特征子空间和高效核函数的KPCA方法，有效提升了异常检测的准确性和效率。|
|📝 更新|Towards Real-world Debiasing: Rethinking Evaluation, Challenge, and Solution|迈向现实世界去偏：重新思考评估、挑战与解决方案|Peng Kuang, Zhibo Wang, Zhixuan Chu, Jingyi Wang, Kui Ren|<http://arxiv.org/pdf/2405.15240v4>|提出RDBench评估框架，通过分析真实世界偏差分布特征，解决无偏差标签的稀疏偏差捕捉挑战。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GAMA: Geometry-Aware Manifold Alignment via Structured Adversarial Perturbations for Robust Domain Adaptation|GAMA：通过结构化对抗扰动实现几何感知流形对齐的鲁棒域适应|Hana Satou, F Monkey|<http://arxiv.org/pdf/2505.15194v1>|GAMA通过结构化对抗扰动和几何信息引导，实现显式流形对齐，提升域适应鲁棒性。|


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Reliable Disentanglement Multi-view Learning Against View Adversarial Attacks|可靠的解耦多视角学习对抗视角攻击|Xuyang Wang, Siyuan Duan, Qizhi Li, Guiduo Duan, Yuan Sun, Dezhong Peng|<http://arxiv.org/pdf/2505.04046v2>|[代码](https://github.com/Willy1005/2025-IJCAI-RDML.); 提出了一种对抗攻击下的可靠多视角学习方法，通过证据解耦和特征重校准提高多视角学习可靠性。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Oral Imaging for Malocclusion Issues Assessments: OMNI Dataset, Deep Learning Baselines and Benchmarking|口腔影像学在错颌问题评估中的应用：OMNI数据集、深度学习基线与基准测试|Pujun Xue, Junyi Ge, Xiaotong Jiang, Siyang Song, Zijian Wu, Yupeng Huo, Weicheng Xie, Linlin Shen .etc.|<http://arxiv.org/pdf/2505.15637v1>|[代码](https://github.com/RoundFaceJ/OMNI.); 构建OMNI数据集，通过深度学习基准测试，提升牙颌畸形诊断的准确性和效率。|
|🆕 发布|Deep Learning Enabled Segmentation, Classification and Risk Assessment of Cervical Cancer|深度学习赋能的宫颈癌分割、分类及风险评估|Abdul Samad Shaik, Shashaank Mattur Aswatha, Rahul Jashvantbhai Pandya|<http://arxiv.org/pdf/2505.15505v1>|提出了一种多分辨率融合深度卷积网络，用于宫颈癌细胞分割、分类和风险评估。|
|🆕 发布|Bridging Sign and Spoken Languages: Pseudo Gloss Generation for Sign Language Translation|跨越符号与口语语言：手语翻译中的伪字幕生成|Jianyuan Guo, Peike Li, Trevor Cohn|<http://arxiv.org/pdf/2505.15438v1>|提出了一种无需人工标注的伪义符生成框架，以解决手语翻译中的数据稀缺问题。|
|🆕 发布|DC-Scene: Data-Centric Learning for 3D Scene Understanding|DC-Scene：以数据为中心的3D场景理解学习|Ting Huang, Zeyu Zhang, Ruicheng Zhang, Yang Zhao|<http://arxiv.org/pdf/2505.15232v1>|[代码](https://github.com/AIGeeksGroup/DC-Scene.); DC-Scene通过数据质量提升和训练效率优化，实现了高效3D场景理解。|
|📝 更新|Learning Cross-Spectral Point Features with Task-Oriented Training|学习面向任务的跨光谱点特征|Mia Thomas, Trevor Ablett, Jonathan Kelly|<http://arxiv.org/pdf/2505.12593v2>|提出了一种通过任务导向训练学习跨光谱点特征的方法，以整合热成像到现有相机导航系统。|
|📝 更新|Transductive One-Shot Learning Meet Subspace Decomposition|基于归纳的单样本学习遇见子空间分解|Kyle Stein, Andrew A. Mahyari, Guillermo Francia III, Eman El-Sheikh|<http://arxiv.org/pdf/2504.00348v2>|该论文提出了一种利用子空间分解进行迁移学习的方法，通过单张标注图像实现跨类别识别。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Zero-Shot Differential Morphing Attack Detection with Multimodal Large Language Models|迈向零样本差分形态变换攻击检测的多模态大型语言模型|Ria Shekhawat, Hailin Li, Raghavendra Ramachandra, Sushma Venkatesh|<http://arxiv.org/pdf/2505.15332v1>|首次利用多模态大型语言模型检测生物识别中的形态攻击，并通过思维链提示提高准确性和可解释性。|
|📝 更新|Unlocking the Power of SAM 2 for Few-Shot Segmentation|解锁SAM 2在少样本分割中的潜力|Qianxiong Xu, Lanyun Zhu, Xuanyi Liu, Guosheng Lin, Cheng Long, Ziyue Li, Rui Zhao|<http://arxiv.org/pdf/2505.14100v2>|设计伪提示生成器和迭代记忆优化，有效解决SAM 2在少样本分割中的匹配问题。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OpenFly: A Comprehensive Platform for Aerial Vision-Language Navigation|开放飞：一个全面的空中视觉-语言导航平台|Yunpeng Gao, Chenhui Li, Zhongrui You, Junli Liu, Zhen Li, Pengan Chen, Qizhi Chen, Zhonghan Tang .etc.|<http://arxiv.org/pdf/2502.18041v5>|提出OpenFly平台，解决室外空中视觉语言导航数据稀缺问题，构建大规模数据集并提升导航模型性能。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GUI-G1: Understanding R1-Zero-Like Training for Visual Grounding in GUI Agents|GUI-G1：理解GUI代理中视觉定位的R1-Zero-like训练|Yuqi Zhou, Sunhao Dai, Shuai Wang, Kaiwen Zhou, Qinqlin Jia, Junxu|<http://arxiv.org/pdf/2505.15810v1>|[代码](https://github.com/Yuqi-Zhou/GUI-G1.); 提出GUI-G1，通过优化输入设计、输出评估和策略更新，显著提升GUI视觉定位性能。|
|🆕 发布|STAR-R1: Spacial TrAnsformation Reasoning by Reinforcing Multimodal LLMs|STAR-R1：通过强化多模态LLMs进行空间变换推理|Zongzhao Li, Zongyang Ma, Mingze Li, Songyou Li, Yu Rong, Tingyang Xu, Ziqi Zhang, Deli Zhao .etc.|<http://arxiv.org/pdf/2505.15804v1>|[代码](https://github.com/zongzhao23/STAR-R1.); STAR-R1通过强化学习，结合精细奖励机制，显著提升了多模态LLMs在空间推理方面的能力。|
|🆕 发布|Exploring The Visual Feature Space for Multimodal Neural Decoding|探索多模态神经解码的视觉特征空间|Weihao Xia, Cengiz Oztireli|<http://arxiv.org/pdf/2505.15755v1>|[代码](https://github.com/weihaox/VINDEX.); 提出了一种基于多模态大语言模型视觉特征空间的零样本脑解码方法，提升了神经解码精度。|
|🆕 发布|Discovering Pathology Rationale and Token Allocation for Efficient Multimodal Pathology Reasoning|发现病理推理的依据和标记分配以实现高效的多模态病理推理|Zhe Xu, Cheng Jin, Yihui Wang, Ziyi Liu, Hao Chen|<http://arxiv.org/pdf/2505.15687v1>|提出了一种结合强化学习和自适应token分配的框架，有效提升病理图像理解效率和推理准确性。|
|🆕 发布|SNAP: A Benchmark for Testing the Effects of Capture Conditions on Fundamental Vision Tasks|SNAP：测试捕获条件对基本视觉任务影响的标准基准|Iuliia Kotseruba, John K. Tsotsos|<http://arxiv.org/pdf/2505.15628v1>|[代码](https://github.com/ykotseruba/SNAP); 构建了SNAP基准，评估了捕获条件对计算机视觉模型性能的影响。|
|🆕 发布|VP Lab: a PEFT-Enabled Visual Prompting Laboratory for Semantic Segmentation|VP Lab：一个用于语义分割的PEFT-赋能视觉提示实验室|Niccolo Avogaro, Thomas Frick, Yagmur G. Cinar, Daniel Caraballo, Cezary Skura, Filip M. Janicki, Piotr Kluska, Brown Ebouky .etc.|<http://arxiv.org/pdf/2505.15592v1>|VP Lab通过E-PEFT技术，显著提升了视觉提示在语义分割领域的应用效率，实现了快速、高效和交互...|
|🆕 发布|ViaRL: Adaptive Temporal Grounding via Visual Iterated Amplification Reinforcement Learning|通过视觉迭代增强强化学习实现自适应时间定位|Ziqiang Xu, Qi Dai, Tian Xie, Yifan Yang, Kai Qiu, DongDong Chen, Zuxuan Wu, Chong Luo|<http://arxiv.org/pdf/2505.15447v1>|ViaRL通过基于规则的强化学习优化视频理解中的帧选择，显著提升时间定位性能。|
|🆕 发布|TimeCausality: Evaluating the Causal Ability in Time Dimension for Vision Language Models|时间因果性：评估视觉语言模型在时间维度上的因果能力|Zeqing Wang, Shiyuan Zhang, Chengpei Tang, Keze Wang|<http://arxiv.org/pdf/2505.15435v1>|[代码](https://github.com/Zeqing-Wang/TimeCausality); 提出TimeCausality基准，评估视觉语言模型在时间维度上的因果推理能力。|
|📝 更新|VisionReasoner: Unified Visual Perception and Reasoning via Reinforcement Learning|视觉推理器：通过强化学习实现统一的视觉感知与推理|Yuqi Liu, Tianyuan Qu, Zhisheng Zhong, Bohao Peng, Shu Liu, Bei Yu, Jiaya Jia|<http://arxiv.org/pdf/2505.12081v2>|VisionReasoner通过强化学习实现视觉感知与推理的统一，在多个视觉任务上显著提升性能。|
|🆕 发布|SoftHGNN: Soft Hypergraph Neural Networks for General Visual Recognition|软超图神经网络：用于通用视觉识别的软超图神经网络|Mengqi Lei, Yihong Wu, Siqi Li, Xinhu Zheng, Juan Wang, Yue Gao, Shaoyi Du|<http://arxiv.org/pdf/2505.15325v1>|提出SoftHGNN，通过软超边和稀疏选择机制，有效捕捉视觉场景中的高阶关联，提升视觉识别性能。|
|🆕 发布|Fooling the LVLM Judges: Visual Biases in LVLM-Based Evaluation|欺骗LVLM评委：基于LVLM评估中的视觉偏差|Yerin Hwang, Dongryeol Lee, Kyungmin Min, Taegwan Kang, Yong-il Kim, Kyomin Jung|<http://arxiv.org/pdf/2505.15249v1>|首次揭示视觉偏差可系统性误导LVLM评分，并提出FRAME基准以增强评估鲁棒性。|
|📝 更新|Enhanced Textual Feature Extraction for Visual Question Answering: A Simple Convolutional Approach|增强视觉问答中的文本特征提取：一种简单的卷积方法|Zhilin Zhang, Fangyu Wu|<http://arxiv.org/pdf/2405.00479v3>|提出ConvGRU模型，通过卷积层优化文本特征提取，提升VQA性能，同时降低模型复杂度。|
|📝 更新|Localizing Before Answering: A Hallucination Evaluation Benchmark for Grounded Medical Multimodal LLMs|在回答之前定位：基于地面医学多模态LLMs的幻觉评估基准|Dung Nguyen, Minh Khoi Ho, Huy Ta, Thanh Tam Nguyen, Qi Chen, Kumar Rav, Quy Duong Dang, Satwik Ramchandre .etc.|<http://arxiv.org/pdf/2505.00744v3>|提出HEAL-MedVQA基准和LobA框架，解决医疗多模态LLMs定位推理不足和幻觉问题。|
|🆕 发布|Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs|跨越语言：跨语言多模态大型语言模型的一致性基准测试|Hao Wang, Pinzhi Huang, Jihan Yang, Saining Xie, Daisuke Kawahara|<http://arxiv.org/pdf/2505.15075v1>|引入KnowRecall和VisRecall基准，评估跨语言一致性，揭示MLLMs在多语言和文化知识...|
|📝 更新|PixelWorld: Towards Perceiving Everything as Pixels|像素世界：迈向将万物感知为像素|Zhiheng Lyu, Xueguang Ma, Wenhu Chen|<http://arxiv.org/pdf/2501.19339v2>|提出PixelWorld基准，通过将所有信息转化为像素，实现统一视觉语言模型感知。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Explainable embeddings with Distance Explainer|可解释的嵌入与距离解释器|Christiaan Meijer, E. G. Patrick Bos|<http://arxiv.org/pdf/2505.15516v1>|提出Distance Explainer，通过解释嵌入空间中数据点间的距离，提升机器学习模型的可解释...|
|📝 更新|FG-CLIP: Fine-Grained Visual and Textual Alignment|FG-CLIP：细粒度视觉与文本对齐|Chunyu Xie, Bin Wang, Fanjing Kong, Jincheng Li, Dawei Liang, Gengshen Zhang, Dawei Leng, Yuhui Yin|<http://arxiv.org/pdf/2505.05071v3>|[代码](https://github.com/360CVGroup/FG-CLIP.); FG-CLIP通过构建高质量数据集和引入负样本，提升了CLIP在细粒度视觉和文本对齐方面的性能。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Better Safe Than Sorry? Overreaction Problem of Vision Language Models in Visual Emergency Recognition|更安全还是更遗憾？视觉紧急情况识别中视觉语言模型的过度反应问题|Dasol Choi, Seunghyun Lee, Youngsook Song|<http://arxiv.org/pdf/2505.15367v1>|该论文揭示了视觉语言模型在紧急情况识别中存在过度反应问题，并提出通过构建诊断基准和两阶段评估协议来提...|
|📝 更新|Enrich the content of the image Using Context-Aware Copy Paste|利用上下文感知的复制粘贴丰富图像内容|Qiushi Guo|<http://arxiv.org/pdf/2407.08151v2>|提出一种基于BLIP和SAM的上下文感知图像内容增强方法，有效提升数据多样性和生成伪图像质量。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|InstructSAM: A Training-Free Framework for Instruction-Oriented Remote Sensing Object Recognition|指令SAM：面向指令的遥感目标识别的无监督框架|Yijie Zheng, Weijie Wu, Qingyun Li, Xuehui Wang, Xu Zhou, Aiai Ren, Jun Shen, Long Zhao .etc.|<http://arxiv.org/pdf/2505.15818v1>|提出InstructSAM，一种无需训练的框架，通过语义相似性和计数约束实现指令驱动的遥感目标识别。|
|🆕 发布|Visual Question Answering on Multiple Remote Sensing Image Modalities|多遥感图像模态上的视觉问答|Hichem Boussaid, Lucrezia Tosato, Flora Weissgerber, Camille Kurtz, Laurent Wendling, Sylvain Lobry|<http://arxiv.org/pdf/2505.15401v1>|提出了一种结合多模态遥感图像的视觉问答方法，显著提升了问答准确率。|
|🆕 发布|CEBSNet: Change-Excited and Background-Suppressed Network with Temporal Dependency Modeling for Bitemporal Change Detection|CEBSNet：基于时间依赖建模的二元时间变化检测中的变化激发和背景抑制网络|Qi'ao Xu, Yan Xing, Jiali Hu, Yunan Jia, Rui Huang|<http://arxiv.org/pdf/2505.15322v1>|提出CEBSNet，一种结合时间依赖建模的背景抑制网络，有效识别双时相变化检测中的细微变化。|
|📝 更新|Selective Structured State Space for Multispectral-fused Small Target Detection|选择性结构化状态空间用于多光谱融合小目标检测|Qianqian Zhang, WeiJun Wang, Yunxing Liu, Li Zhou, Hao Zhao, Junshe An, Zihan Wang|<http://arxiv.org/pdf/2505.14043v2>|提出了一种融合多光谱信息并增强局部细节的轻量级目标检测方法，有效提升了小目标检测精度。|
|🆕 发布|Data Augmentation and Resolution Enhancement using GANs and Diffusion Models for Tree Segmentation|基于GANs和扩散模型的树分割数据增强与分辨率提升|Alessandro dos Santos Ferreira, Ana Paula Marques Ramos, José Marcato Junior, Wesley Nunes Gonçalves|<http://arxiv.org/pdf/2505.15077v1>|提出了一种结合GAN和扩散模型的数据增强与分辨率提升方法，有效提升了低分辨率图像的树木分割准确率。|
|📝 更新|A re-calibration method for object detection with multi-modal alignment bias in autonomous driving|自动驾驶中多模态对齐偏差下的目标检测重标定方法|Zhihang Song, Dingyi Yao, Ruibo MIng, Lihui Peng, Jianming Hu, Danya Yao, Yi Zhang|<http://arxiv.org/pdf/2405.16848v2>|提出了一种基于语义分割的再校准模型，有效提升多模态检测在自动驾驶中的性能和鲁棒性。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TinyDrive: Multiscale Visual Question Answering with Selective Token Routing for Autonomous Driving|TinyDrive：基于选择性标记路由的多尺度视觉问答系统，用于自动驾驶|Hossein Hassani, Soodeh Nikan, Abdallah Shami|<http://arxiv.org/pdf/2505.15564v1>|TinyDrive通过多尺度视觉编码和选择性标记路由，实现了轻量级且高效的自动驾驶视觉问答。|
|📝 更新|MiniDrive: More Efficient Vision-Language Models with Multi-Level 2D Features as Text Tokens for Autonomous Driving|MiniDrive：更高效的自动驾驶视觉-语言模型，以多级2D特征作为文本标记|Enming Zhang, Xingyuan Dai, Min Huang, Yisheng Lv, Qinghai Miao|<http://arxiv.org/pdf/2409.07267v5>|MiniDrive通过多级2D特征文本标记，实现高效视觉语言模型，提升自动驾驶感知能力。|
|🆕 发布|ALN-P3: Unified Language Alignment for Perception, Prediction, and Planning in Autonomous Driving|ALN-P3：自动驾驶中的感知、预测和规划统一语言对齐|Yunsheng Ma, Burhaneddin Yaman, Xin Ye, Mahmut Yurt, Jingru Luo, Abhirup Mallik, Ziran Wang, Liu Ren|<http://arxiv.org/pdf/2505.15158v1>|提出ALN-P3，通过跨模态对齐，实现自动驾驶中的感知、预测和规划统一，显著提升驾驶决策和语言推理能...|
|🆕 发布|Seeing the Trees for the Forest: Rethinking Weakly-Supervised Medical Visual Grounding|看清森林中的树木：重新思考弱监督医学视觉定位|Ta Duc Huy, Duy Anh Huynh, Yutong Xie, Yuankai Qi, Qi Chen, Phi Le Nguyen, Sen Kim Tran, Son Lam Phung .etc.|<http://arxiv.org/pdf/2505.15123v1>|提出Disease-Aware Prompting方法，显著提升医疗视觉定位准确率。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HV-BEV: Decoupling Horizontal and Vertical Feature Sampling for Multi-View 3D Object Detection|HV-BEV：多视图3D目标检测中水平与垂直特征采样的解耦|Di Wu, Feng Yang, Benlian Xu, Pan Liao, Wenhui Zhao, Dingwen Zhang|<http://arxiv.org/pdf/2412.18884v3>|[代码](https://github.com/Uddd821/HV-BEV.); 提出了一种解耦水平与垂直特征采样的多视图3D目标检测方法，有效提升了对象信息聚合和高度分布感知。|
|🆕 发布|On the Robustness of Medical Vision-Language Models: Are they Truly Generalizable?|关于医学视觉-语言模型的鲁棒性：它们真的具有泛化能力吗？|Raza Imam, Rufael Marew, Mohammad Yaqub|<http://arxiv.org/pdf/2505.15425v1>|该论文提出了一种针对医疗视觉语言模型的鲁棒性评估框架，并通过低秩自适应和少样本调整提升了模型在噪声环...|
|📝 更新|Augmenting Chest X-ray Datasets with Non-Expert Annotations|增强胸部X光数据集的非专家标注|Veronika Cheplygina, Cathrine Damgaard, Trine Naja Eriksen, Dovile Juodelyte, Amelia Jiménez-Sánchez|<http://arxiv.org/pdf/2309.02244v3>|[代码](https://github.com/purrlab/chestxr-label-reliability.); 通过引入非专家标注，提高了胸片数据集的规模和质量，并验证了其与专家标注的可靠性。|
|📝 更新|MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization|MMedPO：通过临床感知的多模态偏好优化对齐医学视觉-语言模型|Kangyu Zhu, Peng Xia, Yun Li, Hongtu Zhu, Sheng Wang, Huaxiu Yao|<http://arxiv.org/pdf/2412.06141v3>|[代码](https://github.com/aiming-lab/MMedPO.); MMedPO通过考虑偏好样本的临床相关性，显著提升了医学视觉语言模型的事实准确性。|
|🆕 发布|Zero-Shot Gaze-based Volumetric Medical Image Segmentation|零样本基于注视的体素医学图像分割|Tatyana Shmykova, Leila Khaertdinova, Ilya Pershin|<http://arxiv.org/pdf/2505.15256v1>|引入眼动作为交互式3D医学图像分割的新信息输入，提高了分割效率。|
|🆕 发布|VET-DINO: Learning Anatomical Understanding Through Multi-View Distillation in Veterinary Imaging|VET-DINO：通过兽医影像的多视角蒸馏学习解剖理解|Andre Dourson, Kylie Taylor, Xiaoli Qiao, Michael Fitzke|<http://arxiv.org/pdf/2505.15248v1>|VET-DINO通过多视角蒸馏学习，在兽医影像中实现了对解剖结构的理解，提升了医学影像的自监督学习。|
|🆕 发布|SAMA-UNet: Enhancing Medical Image Segmentation with Self-Adaptive Mamba-Like Attention and Causal-Resonance Learning|SAMA-UNet：通过自适应性Mamba-like注意力机制和因果共振学习增强医学图像分割|Saqib Qamar, Mohd Fazil, Parvez Ahmad, Ghulam Muhammad|<http://arxiv.org/pdf/2505.15234v1>|SAMA-UNet通过自适应注意力机制和因果共振学习，有效提升了医学图像分割的准确性和效率。|
|🆕 发布|Multimodal Conditional Information Bottleneck for Generalizable AI-Generated Image Detection|多模态条件信息瓶颈用于可泛化的人工智能图像检测|Haotian Qin, Dongliang Chang, Yueying Gao, Bingyao Yu, Lei Chen, Zhanyu Ma|<http://arxiv.org/pdf/2505.15217v1>|[代码](https://github.com/Ant0ny44/InfoFD.); 提出了一种基于多模态条件信息瓶颈的AI生成图像检测框架，有效降低特征冗余并提升模型泛化能力。|
|📝 更新|Generalizing Medical Image Representations via Quaternion Wavelet Networks|通过四元数小波网络泛化医学图像表示|Luigi Sigillo, Eleonora Grassucci, Aurelio Uncini, Danilo Comminiello|<http://arxiv.org/pdf/2310.10224v5>|[代码](https://github.com/ispamm/QWT.); 提出了一种通用的医疗图像特征提取框架，通过四元数小波网络提高神经网络泛化能力。|
|🆕 发布|iPad: Iterative Proposal-centric End-to-End Autonomous Driving|iPad：基于迭代提议的端到端自动驾驶|Ke Guo, Haochen Liu, Xiaojun Wu, Jia Pan, Chen Lv|<http://arxiv.org/pdf/2505.15111v1>|提出iPad，一种以提议为中心的迭代自动驾驶框架，显著提升规划效率和性能。|
|🆕 发布|Lung Nodule-SSM: Self-Supervised Lung Nodule Detection and Classification in Thoracic CT Images|肺结节-SSM：基于自监督学习的胸肺CT图像中肺结节检测与分类|Muniba Noreen, Furqan Shaukat|<http://arxiv.org/pdf/2505.15120v1>|[代码](https://github.com/EMeRALDsNRPU/Lung-Nodule-SSM-Self-Supervised-Lung-Nodule-Detection-and-Classification); 提出了一种基于自监督学习的肺结节检测与分类方法，显著提升了诊断准确率。|
|📝 更新|Local Clustering for Lung Cancer Image Classification via Sparse Solution Technique|基于稀疏解法技术的局部聚类肺癌图像分类|Jackson Hamel, Ming-Jun Lai, Zhaiming Shen, Ye Tian|<http://arxiv.org/pdf/2407.08800v2>|利用稀疏解技术进行局部聚类，有效提升了肺癌图像分类性能。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving|AgentThink：用于自动驾驶视觉-语言模型的工具辅助思维链推理的统一框架|Kangan Qian, Sicong Jiang, Yang Zhong, Ziang Luo, Zilin Huang, Tianze Zhu, Kun Jiang, Mengmeng Yang .etc.|<http://arxiv.org/pdf/2505.15298v1>|AgentThink通过融合思维链推理和动态工具调用，显著提升了视觉语言模型在自动驾驶中的推理准确性...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World|曼哈顿世界中的鲁棒消失点估计的凸松弛|Bangyan Liao, Zhenjun Zhao, Haoang Li, Yi Zhou, Yingping Zeng, Hao Li, Peidong Liu|<http://arxiv.org/pdf/2505.04788v2>|[代码](https://github.com/WU-CVGL/GlobustVP.); 首次引入凸松弛技术，高效且鲁棒地估计曼哈顿世界的消失点。|
|📝 更新|SANER: Annotation-free Societal Attribute Neutralizer for Debiasing CLIP|SANER：无标注社会属性中立化器，用于CLIP去偏|Yusuke Hirota, Min-Hung Chen, Chien-Yi Wang, Yuta Nakashima, Yu-Chiang Frank Wang, Ryo Hachiuma|<http://arxiv.org/pdf/2408.10202v4>|提出了一种无需标注的CLIP去偏方法，通过消除属性信息实现社会偏见中立化。|
|📝 更新|Diversity-Driven View Subset Selection for Indoor Novel View Synthesis|室内新视角合成中的多样性驱动视图子集选择|Zehao Wang, Han Zhou, Matthew B. Blaschko, Tinne Tuytelaars, Minye Wu|<http://arxiv.org/pdf/2409.07098v2>|[代码](https://github.com/zehao-wang/IndoorTraj); 提出了一种基于多样性的室内场景新视图合成方法，通过高效的数据选择提升了场景建模效率。|

