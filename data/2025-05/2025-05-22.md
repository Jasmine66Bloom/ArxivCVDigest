## [UPDATED!] **2025-05-22** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dimple: Discrete Diffusion Multimodal Large Language Model with Parallel Decoding|Dimple：具有并行解码的离散扩散多模态大型语言模型|Runpeng Yu, Xinyin Ma, Xinchao Wang|<http://arxiv.org/pdf/2505.16990v1>|[代码](https://github.com/yu-rp/Dimple.); 提出Dimple模型，结合自回归和扩散训练，提升DMLLM性能并优化解码效率。|
|📝 更新|MindGYM: What Matters in Question Synthesis for Thinking-Centric Fine-Tuning?|MindGYM：思维导向微调中问题合成中的关键因素是什么？|Zhe Xu, Daoyuan Chen, Zhenqing Ling, Yaliang Li, Ying Shen|<http://arxiv.org/pdf/2503.09499v2>|MindGYM通过认知引导的数据合成，提升大模型推理能力，实现高效思考导向微调。|
|🆕 发布|LaViDa: A Large Diffusion Language Model for Multimodal Understanding|LaViDa：一种用于多模态理解的超大扩散语言模型|Shufan Li, Konstantinos Kallidromitis, Hritik Bansal, Akash Gokul, Yusuke Kato, Kazuki Kozuka, Jason Kuen, Zhe Lin .etc.|<http://arxiv.org/pdf/2505.16839v1>|LaViDa通过结合扩散模型和视觉编码器，实现了快速、可控的多模态理解。|
|🆕 发布|REOBench: Benchmarking Robustness of Earth Observation Foundation Models|REOBench：地球观测基础模型鲁棒性基准测试|Xiang Li, Yong Tao, Siyuan Zhang, Siwei Liu, Zhitong Xiong, Chunbo Luo, Lu Liu, Mykola Pechenizkiy .etc.|<http://arxiv.org/pdf/2505.16793v1>|构建REOBench基准，评估地球观测基础模型对现实世界干扰的鲁棒性。|
|📝 更新|Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities|统一的多模态理解和生成模型：进展、挑战与机遇|Xinjie Zhang, Jintao Guo, Shanshan Zhao, Minghao Fu, Lunhao Duan, Guo-Hua Wang, Qing-Guo Chen, Zhao Xu .etc.|<http://arxiv.org/pdf/2505.02567v3>|[代码](https://github.com/AIDC-AI/Awesome-Unified-Multimodal-Models); 提出统一的多模态理解和生成模型，克服架构差异挑战，推动跨领域融合研究。|
|🆕 发布|Masked Conditioning for Deep Generative Models|掩码条件化深度生成模型|Phillip Mueller, Jannik Wiese, Sebastian Mueller, Lars Mikelsons|<http://arxiv.org/pdf/2505.16725v1>|提出了一种针对小数据集和混合类型数据的生成模型，通过掩码条件训练提高生成质量。|
|📝 更新|GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design|GeoBiked：一个包含几何特征和自动标注技术以实现工程设计中深度生成模型的数据库|Phillip Mueller, Sebastian Mueller, Lars Mikelsons|<http://arxiv.org/pdf/2409.17045v2>|GeoBiked数据集结合自动标注技术，推动深度生成模型在工程设计中的应用。|
|🆕 发布|TextureSAM: Towards a Texture Aware Foundation Model for Segmentation|纹理SAM：迈向纹理感知的分割基础模型|Inbal Cohen, Boaz Meivar, Peihan Tu, Shai Avidan, Gal Oren|<http://arxiv.org/pdf/2505.16540v1>|提出TextureSAM，通过纹理增强和调整训练数据，有效缓解了SAM模型在纹理主导场景中的形状偏差...|
|📝 更新|Transferring Textual Preferences to Vision-Language Understanding through Model Merging|通过模型融合将文本偏好迁移到视觉-语言理解|Chen-An Li, Tzu-Han Lin, Yun-Nung Chen, Hung-yi Lee|<http://arxiv.org/pdf/2502.13487v2>|通过融合文本奖励模型与视觉语言模型，提出了一种高效地将文本偏好融入视觉语言理解的方法。|
|📝 更新|Benchmarking Ophthalmology Foundation Models for Clinically Significant Age Macular Degeneration Detection|眼科基础模型在临床显著年龄相关性黄斑变性检测中的基准测试|Benjamin A. Cohen, Jonathan Fhima, Meishar Meisel, Baskin Meital, Luis Filipe Nakayama, Eran Berkowitz, Joachim A. Behar|<http://arxiv.org/pdf/2505.05291v2>|该论文通过比较不同预训练视觉Transformer在AMD检测中的性能，挑战了领域特定预训练的必要性...|
|🆕 发布|PCMamba: Physics-Informed Cross-Modal State Space Model for Dual-Camera Compressive Hyperspectral Imaging|PCMamba：基于物理信息的跨模态状态空间模型用于双摄像头压缩超光谱成像|Ge Meng, Zhongnan Cai, Jingyan Tu, Yingying Wang, Chenxin Li, Yue Huang, Xinghao Ding|<http://arxiv.org/pdf/2505.16373v1>|提出PCMamba模型，结合物理信息和跨模态交互，有效提升双相机压缩超光谱成像重建质量。|
|🆕 发布|Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation|基于扩散模型的合成到真实域自适应风格迁移|Estelle Chigot, Dennis G. Wilson, Meriem Ghrib, Thomas Oberlin|<http://arxiv.org/pdf/2505.16360v1>|[代码](https://github.com/echigot/cactif.); 利用扩散模型进行风格迁移，有效缩小合成数据与真实数据之间的领域差距。|
|📝 更新|Looking Beyond Language Priors: Enhancing Visual Comprehension and Attention in Multimodal Models|超越语言先验：提升多模态模型中的视觉理解和注意力|Aarti Ghatkesar, Uddeshya Upadhyay, Ganesh Venkatesh|<http://arxiv.org/pdf/2505.05626v2>|提出新方法增强多模态模型视觉理解，显著提升视觉依赖任务表现。|
|🆕 发布|DOVE: Efficient One-Step Diffusion Model for Real-World Video Super-Resolution|DOVE：高效的一步式现实世界视频超分辨率扩散模型|Zheng Chen, Zichen Zou, Kewei Zhang, Xiongfei Su, Xin Yuan, Yong Guo, Yulun Zhang|<http://arxiv.org/pdf/2505.16239v1>|[代码](https://github.com/zhengchen1999/DOVE.); 提出了一种高效的一步扩散模型DOVE，显著提升了真实视频超分辨率的速度和性能。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Native Segmentation Vision Transformers|原生分割视觉Transformer|Guillem Brasó, Aljoša Ošep, Laura Leal-Taixé|<http://arxiv.org/pdf/2505.16993v1>|提出了一种基于内容感知的空间分组层的视觉Transformer，实现了无需额外分割头部的原生分割。|
|📝 更新|Remote Sensing Spatio-Temporal Vision-Language Models: A Comprehensive Survey|遥感时空视觉-语言模型：全面综述|Chenyang Liu, Jiafan Zhang, Keyan Chen, Man Wang, Zhengxia Zou, Zhenwei Shi|<http://arxiv.org/pdf/2412.02573v2>|[代码](https://github.com/Chen-Yang-Liu/Awesome-RS-SpatioTemporal-VLMs); 首次全面综述了遥感时空视觉语言模型，融合视觉与语言信息，实现更深入的变化检测与语义分析。|
|📝 更新|Stronger ViTs With Octic Equivariance|更强的八次方等变性ViTs|David Nordström, Johan Edstedt, Fredrik Kahl, Georg Bökman|<http://arxiv.org/pdf/2505.15441v2>|通过引入八次对称性，提出的新架构八次ViT在保持性能的同时显著降低了计算复杂度。|
|📝 更新|TRACE: Transformer-based Risk Assessment for Clinical Evaluation|基于Transformer的临床评估风险评估方法：TRACE|Dionysis Christopoulos, Sotiris Spanos, Valsamis Ntouskos, Konstantinos Karantzalos|<http://arxiv.org/pdf/2411.08701v2>|提出TRACE，一种基于Transformer的集成多模态临床数据风险评估方法，有效处理缺失值并提升...|
|🆕 发布|Fusion of Foundation and Vision Transformer Model Features for Dermatoscopic Image Classification|基于基础和视觉Transformer模型特征的皮肤镜图像分类融合|Amirreza Mahbod, Rupert Ecker, Ramona Woitek|<http://arxiv.org/pdf/2505.16338v1>|融合基础模型和视觉Transformer模型特征，提升皮肤病变图像分类准确率。|
|🆕 发布|SAMba-UNet: Synergizing SAM2 and Mamba in UNet with Heterogeneous Aggregation for Cardiac MRI Segmentation|SAMba-UNet：在UNet中协同SAM2和Mamba，采用异构聚合进行心脏MRI分割|Guohao Huo, Ruiting Dai, Hao Tang|<http://arxiv.org/pdf/2505.16304v1>|提出SAMba-UNet，融合SAM2和Mamba，实现跨模态特征协作学习，提高心脏MRI分割精度。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|R1-ShareVL: Incentivizing Reasoning Capability of Multimodal Large Language Models via Share-GRPO|R1-ShareVL：通过共享GRPO激励多模态大型语言模型的推理能力|Huanjin Yao, Qixiang Yin, Jingyi Zhang, Min Yang, Yibo Wang, Wenhao Wu, Fei Su, Li Shen .etc.|<http://arxiv.org/pdf/2505.16673v1>|[代码](https://github.com/HJYao00/R1-ShareVL.); 通过Share-GRPO方法，激励多模态大语言模型推理能力，有效缓解强化学习中稀疏奖励和优势消失问题...|
|🆕 发布|MEgoHand: Multimodal Egocentric Hand-Object Interaction Motion Generation|MEgoHand：多模态自视角手-物体交互运动生成|Bohan Zhou, Yi Zhan, Zhongbin Zhang, Zongqing Lu|<http://arxiv.org/pdf/2505.16602v1>|MEgoHand通过融合视觉、文本和初始手姿，提出了一种多模态框架，有效生成逼真的手-物体交互运动。|
|🆕 发布|Bridging the Dynamic Perception Gap: Training-Free Draft Chain-of-Thought for Dynamic Multimodal Spatial Reasoning|弥合动态感知差距：无需训练的动态多模态空间推理思维链|Siqu Ou, Hongcheng Liu, Pingjie Wang, Yusheng Liao, Chuan Xuan, Yanfeng Wang, Yu Wang|<http://arxiv.org/pdf/2505.16579v1>|[代码](https://github.com/Cratileo/D2R.); 提出D2R框架，通过动态视觉草稿增强文本推理，实现动态多模态空间推理。|
|🆕 发布|Beyond Face Swapping: A Diffusion-Based Digital Human Benchmark for Multimodal Deepfake Detection|超越面部交换：一种基于扩散的多模态深度伪造检测的数字人基准|Jiaxin Liu, Jia Wang, Saihui Hou, Min Ren, Huijia Wu, Zhaofeng He|<http://arxiv.org/pdf/2505.16512v1>|提出首个基于扩散模型的数字人伪造数据集，并构建了时空跨模态融合检测基准，有效识别深度伪造视频。|
|📝 更新|Uncovering Cultural Representation Disparities in Vision-Language Models|揭示视觉-语言模型中的文化表征差异|Ram Mohan Rao Kadiyala, Siddhant Gupta, Jebish Purbey, Srishti Yadav, Alejandro Salamanca, Desmond Elliott|<http://arxiv.org/pdf/2505.14729v2>|探究视觉语言模型的文化偏差，通过多策略评估揭示其性能差异。|
|📝 更新|MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark|MMMU-Pro：一个更鲁棒的多学科多模态理解基准|Xiang Yue, Tianyu Zheng, Yuansheng Ni, Yubo Wang, Kai Zhang, Shengbang Tong, Yuxuan Sun, Botao Yu .etc.|<http://arxiv.org/pdf/2409.02813v3>|MMMU-Pro通过过滤、增强选项和引入视觉输入，构建了更严格的跨模态理解基准，挑战AI同时“看”和...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification|新型探索：当智能体成为科学家——从假设到验证构建闭环系统|NovelSeek Team, Bo Zhang, Shiyang Feng, Xiangchao Yan, Jiakang Yuan, Zhiyin Yu, Xiaohan He, Songtao Huang .etc.|<http://arxiv.org/pdf/2505.16938v1>|NovelSeek构建了从假设到验证的闭环多智能体框架，实现跨领域自主科学研究，大幅提升研究效率和精...|
|🆕 发布|Sketchy Bounding-box Supervision for 3D Instance Segmentation|草图边界框监督的3D实例分割|Qian Deng, Le Hui, Jin Xie, Jian Yang|<http://arxiv.org/pdf/2505.16399v1>|[代码](https://github.com/dengq7/Sketchy-3DIS.); 提出了一种基于草图边界框的弱监督3D实例分割框架，显著提升了分割性能。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LiDAR MOT-DETR: A LiDAR-based Two-Stage Transformer for 3D Multiple Object Tracking|基于激光雷达的两种阶段Transformer用于3D多目标跟踪|Martha Teiko Teye, Ori Maoz, Matthias Rottmann|<http://arxiv.org/pdf/2505.12753v2>|提出了一种基于两阶段Transformer的LiDAR点云多目标跟踪方法，有效提升了跟踪精度和鲁棒性...|
|🆕 发布|Robust Vision-Based Runway Detection through Conformal Prediction and Conformal mAP|鲁棒基于视觉的跑道检测：通过一致性预测和一致性mAP|Alya Zouzou, Léo andéol, Mélanie Ducoffe, Ryma Boumazouza|<http://arxiv.org/pdf/2505.16740v1>|利用符合预测和C-mAP指标，提升了基于视觉的跑道检测系统的可靠性。|
|📝 更新|Persistence-based Hough Transform for Line Detection|基于持久性的霍夫变换线检测|Johannes Ferner, Stefan Huber, Saverio Messineo, Angel Pop, Martin Uray|<http://arxiv.org/pdf/2504.16114v2>|提出了一种基于持久同调的Hough变换改进方法，有效提升了线检测的鲁棒性。|
|🆕 发布|Investigating Fine- and Coarse-grained Structural Correspondences Between Deep Neural Networks and Human Object Image Similarity Judgments Using Unsupervised Alignment|探究深度神经网络与人类物体图像相似性判断之间细粒度和粗粒度结构对应关系的无监督对齐研究|Soh Takahashi, Masaru Sasaki, Ken Takeda, Masafumi Oizumi|<http://arxiv.org/pdf/2505.16419v1>|利用无监督对齐方法，探究深度神经网络与人类物体图像相似度判断在细粒度和粗粒度结构对应关系上的贡献。|
|🆕 发布|MAFE R-CNN: Selecting More Samples to Learn Category-aware Features for Small Object Detection|MAFE R-CNN：通过选择更多样本学习小目标检测中的类别感知特征|Yichen Li, Qiankun Liu, Zhenchao Jin, Jiuzhe Wei, Jing Nie, Ying Fu|<http://arxiv.org/pdf/2505.16442v1>|MAFE R-CNN通过多线索样本选择和类别感知特征增强机制，有效提升了小目标检测性能。|
|🆕 发布|LINEA: Fast and Accurate Line Detection Using Scalable Transformers|LINEA：基于可扩展变换器的快速且精确的线检测|Sebastian Janampa, Marios Pattichis|<http://arxiv.org/pdf/2505.16264v1>|提出了一种快速准确的线检测方法，通过可变形线注意力机制显著提升检测速度。|
|🆕 发布|Self-Classification Enhancement and Correction for Weakly Supervised Object Detection|弱监督目标检测中的自分类增强与校正|Yufei Yin, Lechao Cheng, Wengang Zhou, Jiajun Deng, Zhou Yu, Houqiang Li|<http://arxiv.org/pdf/2505.16294v1>|提出一种融合二分类增强和校正算法的弱监督目标检测框架，有效提升检测精度。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unsupervised Network Anomaly Detection with Autoencoders and Traffic Images|无监督网络异常检测：基于自编码器和交通图像|Michael Neri, Sara Baldoni|<http://arxiv.org/pdf/2505.16650v1>|[代码](https://github.com/michaelneri/image-based-network-traffic-anomaly-detection.); 提出了一种基于自编码器和图像表示的轻量级网络异常检测方法，有效简化了数据处理架构。|
|🆕 发布|Towards Texture- And Shape-Independent 3D Keypoint Estimation in Birds|面向鸟类纹理和形状无关的3D关键点估计|Valentin Schmuker, Alex Hoi Hang Chan, Bastian Goldluecke, Urs Waldmann|<http://arxiv.org/pdf/2505.16633v1>|提出了一种基于分割轮廓的纹理无关3D关键点估计方法，提高了鸟类姿态估计的准确性和泛化能力。|
|🆕 发布|CMRINet: Joint Groupwise Registration and Segmentation for Cardiac Function Quantification from Cine-MRI|CMRINet：基于电影MRI的心脏功能量化中的联合分组配准与分割|Mohamed S. Elmahdy, Marius Staring, Patrick J. H. de Koning, Samer Alabed, Mahan Salehi, Faisal Alandejani, Michael Sharkey, Ziad Aldabbagh .etc.|<http://arxiv.org/pdf/2505.16452v1>|提出了一种联合群组配准和分割的深度学习模型，提高了心脏功能量化准确性和效率。|
|🆕 发布|Swin Transformer for Robust CGI Images Detection: Intra- and Inter-Dataset Analysis across Multiple Color Spaces|斯温变换器在鲁棒CGI图像检测中的应用：跨多个颜色空间的跨数据集分析和比较|Preeti Mehta, Aman Sagar, Suchi Kumari|<http://arxiv.org/pdf/2505.16253v1>|提出Swin Transformer模型，有效识别不同颜色空间中的CGI图像。|
|🆕 发布|RE-TRIP : Reflectivity Instance Augmented Triangle Descriptor for 3D Place Recognition|RE-TRIP：用于3D场景识别的反射性实例增强三角形描述符|Yechan Park, Gyuhyeon Pak, Euntai Kim|<http://arxiv.org/pdf/2505.16165v1>|提出RE-TRIP，结合几何和反射率信息，提升3D场景识别鲁棒性。|
|🆕 发布|Breaking Complexity Barriers: High-Resolution Image Restoration with Rank Enhanced Linear Attention|打破复杂性壁垒：基于秩增强线性注意力的超分辨率图像恢复|Yuang Ai, Huaibo Huang, Tao Wu, Qihang Fan, Ran He|<http://arxiv.org/pdf/2505.16157v1>|提出RELA和LAformer，解决Transformer在图像修复中的复杂度问题，显著提升高分辨率...|
|🆕 发布|GMatch: Geometry-Constrained Feature Matching for RGB-D Object Pose Estimation|GMatch：基于几何约束的RGB-D物体位姿估计特征匹配|Ming Yang, Haoran Li|<http://arxiv.org/pdf/2505.16144v1>|GMatch通过几何约束特征匹配，实现了无学习、鲁棒的6自由度物体位姿估计。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Detailed Evaluation of Modern Machine Learning Approaches for Optic Plastics Sorting|现代机器学习技术在光学塑料分类中的详细评估|Vaishali Maheshkar, Aadarsh Anantha Ramakrishnan, Charuvahan Adhivarahan, Karthik Dantu|<http://arxiv.org/pdf/2505.16513v1>|评估了现代机器学习在光学塑料分类中的应用，发现其依赖物理属性导致准确性受限。|
|📝 更新|Objective Bicycle Occlusion Level Classification using a Deformable Parts-Based Model|基于可变形部件模型的客观自行车遮挡等级分类|Angelique Mangubat, Shane Gilroy|<http://arxiv.org/pdf/2505.15358v2>|提出了一种基于可变形部件模型的自行车遮挡等级分类方法，客观量化自行车可见性和遮挡程度。|
|🆕 发布|Deep Learning-Driven Ultra-High-Definition Image Restoration: A Survey|深度学习驱动的超高清图像恢复：综述|Liyan Wang, Weixiang Zhou, Cong Wang, Kin-Man Lam, Zhixun Su, Jinshan Pan|<http://arxiv.org/pdf/2505.16161v1>|[代码](https://github.com/wlydlut/UHD-Image-Restoration-Survey.); 综述了深度学习在超高清图像修复领域的应用，提出了基于网络架构和采样策略的分类框架。|
|🆕 发布|When VLMs Meet Image Classification: Test Sets Renovation via Missing Label Identification|当视觉语言模型遇见图像分类：通过缺失标签识别进行测试集革新|Zirui Pang, Haosheng Tan, Yuhan Pu, Zhijie Deng, Zhouan Shen, Keyu Hu, Jiaheng Wei|<http://arxiv.org/pdf/2505.16149v1>|提出REVEAL框架，通过集成预训练视觉语言模型和高级标签清理方法，有效识别图像分类数据集中的缺失和...|


## 生成式视觉模型 (Generative Visual Modeling)


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Let Androids Dream of Electric Sheep: A Human-like Image Implication Understanding and Reasoning Framework|《让安卓梦见电子羊：一种类似人类的图像含义理解和推理框架》|Chenhao Zhang, Yazhe Niu|<http://arxiv.org/pdf/2505.17019v1>|[代码](https://github.com/MING-ZCH/Let-Androids-Dream-of-Electric-Sheep.); 提出LAD框架，通过感知、搜索和推理三阶段解决图像隐喻理解难题。|
|🆕 发布|GoT-R1: Unleashing Reasoning Capability of MLLM for Visual Generation with Reinforcement Learning|GoT-R1：利用强化学习释放多模态语言模型在视觉生成中的推理能力|Chengqi Duan, Rongyao Fang, Yuqing Wang, Kun Wang, Linjiang Huang, Xingyu Zeng, Hongsheng Li, Xihui Liu|<http://arxiv.org/pdf/2505.17022v1>|[代码](https://github.com/gogoduan/GoT-R1.); GoT-R1通过强化学习增强视觉生成中的语义-空间推理能力，显著提升复杂图像生成效果。|
|🆕 发布|Learning Adaptive and Temporally Causal Video Tokenization in a 1D Latent Space|学习一维潜在空间中的自适应和时序因果视频标记化|Yan Li, Changyao Tian, Renqiu Xia, Ning Liao, Weiwei Guo, Junchi Yan, Hongsheng Li, Jifeng Dai .etc.|<http://arxiv.org/pdf/2505.17011v1>|提出AdapTok，一种自适应视频分词器，可根据视频内容灵活分配分词，提高重建质量和生成性能。|
|🆕 发布|RBench-V: A Primary Assessment for Visual Reasoning Models with Multi-modal Outputs|RBench-V：一种针对多模态输出视觉推理模型的初步评估|Meng-Hao Guo, Xuanyu Chu, Qianrui Yang, Zhe-Han Mo, Yiqing Shen, Pei-lin Li, Xinjie Lin, Jinnian Zhang .etc.|<http://arxiv.org/pdf/2505.16770v1>|[代码](https://evalmodels.github.io/rbenchv); 提出RBench-V基准，评估模型通过多模态输出进行视觉推理的能力。|
|🆕 发布|One-Step Diffusion-Based Image Compression with Semantic Distillation|一步扩散式图像压缩与语义蒸馏|Naifu Xue, Zhaoyang Jia, Jiahao Li, Bin Li, Yuan Zhang, Yan Lu|<http://arxiv.org/pdf/2505.16687v1>|提出了一种一步扩散图像压缩方法，通过语义蒸馏和混合域优化实现高感知质量与快速解码。|
|🆕 发布|MAGIC: Motion-Aware Generative Inference via Confidence-Guided LLM|MAGIC：基于置信度引导的LLM的感知运动生成推理|Siwei Meng, Yawei Luo, Ping Liu|<http://arxiv.org/pdf/2505.16456v1>|MAGIC通过结合预训练模型和迭代推理，实现了无需训练的物理属性推断和动态视频生成，有效解决了现有视...|
|🆕 发布|DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos|DeCafNet：委托与征服，实现长视频中高效的时间定位|Zijia Lu, A S M Iftekhar, Gaurav Mittal, Tianjian Meng, Xiawei Wang, Cheng Zhao, Rohith Kukkala, Ehsan Elhamifar .etc.|<http://arxiv.org/pdf/2505.16376v1>|[代码](https://github.com/ZijiaLewisLu/CVPR2025-DeCafNet.); DeCafNet通过“委托-征服”策略，高效处理长视频中的关键帧定位，显著降低计算成本并提升性能。|
|🆕 发布|TensorAR: Refinement is All You Need in Autoregressive Image Generation|TensorAR：自回归图像生成中，优化即是全部所需|Cheng Cheng, Lin Song, Yicheng Xiao, Yuxin Chen, Xuchong Zhang, Hongbin Sun, Ying Shan|<http://arxiv.org/pdf/2505.16324v1>|TensorAR通过将图像生成从预测下一个图像标记转变为预测下一个图像块，实现了对自回归图像生成模型...|
|📝 更新|How Well Can General Vision-Language Models Learn Medicine By Watching Public Educational Videos?|通过观看公开教育视频，通用视觉-语言模型能学到多少医学知识？|Rahul Thapa, Andrew Li, Qingyang Wu, Bryan He, Yuki Sahashi, Christina Binder, Angela Zhang, Ben Athiwaratkun .etc.|<http://arxiv.org/pdf/2504.14391v2>|通过利用公开医学教育视频，该研究证明了非标准化视频对通用视觉语言模型学习医学知识的有效性。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SophiaVL-R1: Reinforcing MLLMs Reasoning with Thinking Reward|SophiaVL-R1：通过思维奖励强化MLLM推理|Kaixuan Fan, Kaituo Feng, Haoming Lyu, Dongzhan Zhou, Xiangyu Yue|<http://arxiv.org/pdf/2505.17018v1>|[代码](https://github.com/kxfan2002/SophiaVL-R1.); 提出SophiaVL-R1，通过思考奖励强化MLLM推理能力，提升模型泛化能力。|
|🆕 发布|When Are Concepts Erased From Diffusion Models?|当概念从扩散模型中被擦除时？|Kevin Lu, Nicky Kriplani, Rohit Gandikota, Minh Pham, David Bau, Chinmay Hegde, Niv Cohen|<http://arxiv.org/pdf/2505.17013v1>|提出评估方法，揭示扩散模型中概念消除的全面性及其与鲁棒性的权衡。|
|🆕 发布|CoMo: Learning Continuous Latent Motion from Internet Videos for Scalable Robot Learning|CoMo：从互联网视频中学习连续潜在运动以实现可扩展机器人学习|Jiange Yang, Yansong Shi, Haoyi Zhu, Mingyu Liu, Kaijing Ma, Yating Wang, Gangshan Wu, Tong He .etc.|<http://arxiv.org/pdf/2505.17006v1>|CoMo通过学习连续运动表示，从互联网视频中为可扩展的机器人学习提供更丰富的信息。|
|🆕 发布|Deep mineralogical segmentation of thin section images based on QEMSCAN maps|基于QEMSCAN图的薄片图像深度矿物学分割|Jean Pablo Vieira de Mello, Matheus Augusto Alves Cuglieri, Leandro P. de Figueiredo, Fernando Bordignon, Marcelo Ramalho Albuquerque, Rodrigo Surmas, Bruno Cavalcanti de Paula|<http://arxiv.org/pdf/2505.17008v1>|提出了一种基于U-Net的深度学习模型，自动分割碳酸盐岩薄片图像，实现低成本、高效且通用的矿物学分析...|
|🆕 发布|Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction|通过动态姿态交互追求时间一致的视频虚拟试穿|Dong Li, Wenqi Zhong, Wei Yu, Yingwei Pan, Dingwen Zhang, Ting Yao, Junwei Han, Tao Mei|<http://arxiv.org/pdf/2505.16980v1>|提出动态姿态交互扩散模型，解决视频虚拟试衣中的时间一致性挑战。|
|🆕 发布|Incorporating Visual Correspondence into Diffusion Model for Virtual Try-On|将视觉对应关系融入扩散模型以实现虚拟试穿|Siqi Wan, Jingwen Chen, Yingwei Pan, Ting Yao, Tao Mei|<http://arxiv.org/pdf/2505.16977v1>|[代码](https://github.com/HiDream-ai/SPM-Diff.); 提出利用视觉对应性作为先验，结合3D感知线索，改进扩散模型，实现虚拟试衣中的服装细节精确保留。|
|🆕 发布|LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning|LLaDA-V：具有视觉指令微调的大型语言扩散模型|Zebin You, Shen Nie, Xiaolu Zhang, Jun Hu, Jun Zhou, Zhiwu Lu, Ji-Rong Wen, Chongxuan Li|<http://arxiv.org/pdf/2505.16933v1>|[代码](https://ml-gsai.github.io/LLaDA-V-demo); LLaDA-V通过视觉指令调整，将视觉特征映射到语言嵌入空间，显著提升了多模态大语言模型在理解任务上...|
|🆕 发布|Backdoor Cleaning without External Guidance in MLLM Fine-tuning|《在多语言语言模型微调中，无需外部指导的后门清理》|Xuankun Rong, Wenke Huang, Jian Liang, Jinhe Bi, Xun Xiao, Yiming Li, Bo Du, Mang Ye|<http://arxiv.org/pdf/2505.16916v1>|提出BYE框架，利用注意力熵模式识别和过滤MLLMs中的后门样本，有效防御恶意微调攻击。|
|🆕 发布|T2I-ConBench: Text-to-Image Benchmark for Continual Post-training|T2I-ConBench：持续后训练的文本到图像基准测试|Zhehao Huang, Yuhang Liu, Yixin Lou, Zhengbao He, Mingzhen He, Wenxing Zhou, Tao Li, Kehan Li .etc.|<http://arxiv.org/pdf/2505.16875v1>|构建了T2I-ConBench基准，评估并促进了持续后训练的文本到图像模型研究。|
|🆕 发布|From EduVisBench to EduVisAgent: A Benchmark and Multi-Agent Framework for Pedagogical Visualization|从EduVisBench到EduVisAgent：教学可视化基准和多智能体框架|Haonian Ji, Shi Qiu, Siyang Xin, Siwei Han, Zhaorun Chen, Hongyi Wang, Dake Zhang, Huaxiu Yao|<http://arxiv.org/pdf/2505.16832v1>|[代码](https://github.com/aiming-lab/EduVisBench); 构建了教育可视化基准和协作框架，提升模型生成教育性视觉解释的能力。|
|📝 更新|More Text, Less Point: Towards 3D Data-Efficient Point-Language Understanding|更多文本，更少点云：迈向3D数据高效点云语言理解|Yuan Tang, Xu Han, Xianzhi Li, Qiao Yu, Jinfeng Xu, Yixue Hao, Long Hu, Min Chen|<http://arxiv.org/pdf/2408.15966v3>|[代码](https://github.com/TangYuan96/GreenPLM.); 提出GreenPLM，通过增加文本数据，实现LLMs对3D点云的鲁棒理解，降低对3D数据的依赖。|
|🆕 发布|REPA Works Until It Doesn't: Early-Stopped, Holistic Alignment Supercharges Diffusion Training|REPA Works Until It Doesn't: Early-Stopped, Holistic Alignment Supercharges Diffusion Training  REPA直到失效：提前停止的全面对齐极大地提升了扩散训练|Ziqiao Wang, Wangbo Zhao, Yuhao Zhou, Zekai Li, Zhiyuan Liang, Mingjia Shi, Xuanlei Zhao, Pengfei Zhou .etc.|<http://arxiv.org/pdf/2505.16792v1>|[代码](https://github.com/NUS-HPC-AI-Lab/HASTE); HASTE通过分阶段整体对齐和终止，显著加速了扩散训练，同时保持性能。|
|🆕 发布|Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining|半监督状态空间模型结合动态堆叠滤波器用于真实世界视频去雨|Shangquan Sun, Wenqi Ren, Juxiang Zhou, Shu Wang, Jianhou Gan, Xiaochun Cao|<http://arxiv.org/pdf/2505.16811v1>|提出了一种结合动态堆叠滤波器和半监督学习的视频去雨模型，有效提升真实场景下视频去雨效果。|
|🆕 发布|Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles|四眼胜过双眼：通过差异化思维和互补集成利用大型模型的协作潜力|Jun Xie, Xiongjun Guan, Yingjian Zhu, Zhaoran Zhao, Xinming Wang, Feng Chen, Zhepeng Wang|<http://arxiv.org/pdf/2505.16784v1>|通过差异化思维和互补集成，该论文提出了一种利用大型模型协作潜力进行视频理解的新方法，显著超越了现有技...|
|📝 更新|Fast Sampling Through The Reuse Of Attention Maps In Diffusion Models|快速采样：通过在扩散模型中重用注意力图进行采样|Rosco Hunter, Łukasz Dudziak, Mohamed S. Abdelfattah, Abhinav Mehrotra, Sourav Bhattacharya, Hongkai Wen|<http://arxiv.org/pdf/2401.01008v4>|通过复用注意力图，该方法在扩散模型中实现了快速采样，显著降低了生成图像的延迟。|
|🆕 发布|SHaDe: Compact and Consistent Dynamic 3D Reconstruction via Tri-Plane Deformation and Latent Diffusion|SHaDe：通过三平面变形和潜在扩散的紧凑且一致动态3D重建|Asrar Alruwayqi|<http://arxiv.org/pdf/2505.16535v1>|SHaDe通过三平面变形和潜在扩散，实现了紧凑且一致的动态3D场景重建。|
|📝 更新|UniRestorer: Universal Image Restoration via Adaptively Estimating Image Degradation at Proper Granularity|通用图像修复：通过自适应估计适当粒度下的图像退化|Jingbo Lin, Zhilu Zhang, Wenbo Li, Renjing Pei, Hang Xu, Hongzhi Zhang, Wangmeng Zuo|<http://arxiv.org/pdf/2412.20157v3>|UniRestorer通过自适应估计图像退化，实现了跨退化类型的图像修复，显著提升了整体性能。|
|📝 更新|Demystifying Variational Diffusion Models|揭秘变分扩散模型|Fabio De Sousa Ribeiro, Ben Glocker|<http://arxiv.org/pdf/2401.06281v2>|本文通过简化扩散模型的理论，为非专业人士提供了易于理解的模型视角，降低了新研究者入门门槛。|
|🆕 发布|Consistent World Models via Foresight Diffusion|通过前瞻扩散实现一致的世界模型|Yu Zhang, Xingzhuo Guo, Haoran Xu, Mingsheng Long|<http://arxiv.org/pdf/2505.16474v1>|提出ForeDiff方法，通过解耦条件理解和目标去噪，提升扩散模型在构建一致世界模型中的预测准确性和...|
|🆕 发布|Mitigating Hallucinations in Vision-Language Models through Image-Guided Head Suppression|通过图像引导的头抑制减轻视觉-语言模型中的幻觉|Sreetama Sarkar, Yue Che, Alex Gavin, Peter A. Beerel, Souvik Kundu|<http://arxiv.org/pdf/2505.16411v1>|[代码](https://github.com/YUECHE77/SPIN.); 提出SPIN方法，通过抑制对图像关注度低的注意力头，有效降低视觉语言模型幻觉，同时提升处理速度。|
|🆕 发布|Panoptic Captioning: Seeking An Equivalency Bridge for Image and Text|全景描述：寻求图像与文本的等价桥梁|Kun-Yu Lin, Hongjun Wang, Weining Ren, Kai Han|<http://arxiv.org/pdf/2505.16334v1>|[代码](https://visual-ai.github.io/pancap); 提出了一种名为PancapChain的图像描述生成方法，有效提升了图像与文本的等价性。|
|🆕 发布|FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design|FPQVAR：基于FPGA硬件协同设计的视觉自回归模型浮点量化|Renjie Wei, Songqiang Xu, Qingyu Guo, Meng Li|<http://arxiv.org/pdf/2505.16335v1>|提出FPQVAR，通过算法和硬件协同设计，有效降低视觉自回归模型在边缘设备上的内存和计算成本。|
|📝 更新|Strengthening Generative Robot Policies through Predictive World Modeling|通过预测世界建模强化生成式机器人策略|Han Qi, Haocheng Yin, Aris Zhu, Yilun Du, Heng Yang|<http://arxiv.org/pdf/2502.00622v2>|通过结合行为克隆和预测世界模型，提出了一种增强机器人策略的生成预测控制方法，显著提升了机器人操作性能...|
|🆕 发布|Erased or Dormant? Rethinking Concept Erasure Through Reversibility|已删除或休眠？通过可逆性重新思考概念删除|Ping Liu, Chi Zhang|<http://arxiv.org/pdf/2505.16174v1>|该论文揭示了现有概念擦除方法未能彻底消除生成能力，并提出了通过轻量级微调评估擦除概念复活的策略。|
|🆕 发布|TRAIL: Transferable Robust Adversarial Images via Latent diffusion|TRAIL：通过潜在扩散实现的可迁移鲁棒对抗图像|Yuhao Xue, Zhifei Zhang, Xinyang Jiang, Yifei Shen, Junyao Gao, Wentao Gu, Jiale Zhao, Miaojing Shi .etc.|<http://arxiv.org/pdf/2505.16166v1>|提出TRAIL方法，通过潜在扩散生成可迁移的鲁棒对抗图像，显著提升跨模型攻击的可行性。|
|📝 更新|ADHMR: Aligning Diffusion-based Human Mesh Recovery via Direct Preference Optimization|ADHMR：通过直接偏好优化对齐基于扩散的人体网格恢复|Wenhao Shen, Wanqi Yin, Xiaofeng Yang, Cheng Chen, Chaoyue Song, Zhongang Cai, Lei Yang, Hao Wang .etc.|<http://arxiv.org/pdf/2505.10250v2>|[代码](https://github.com/shenwenhao01/ADHMR.); 提出ADHMR，通过直接偏好优化对基于扩散的人体网格恢复模型进行对齐，显著提升模型性能。|
|🆕 发布|OSCAR: One-Step Diffusion Codec Across Multiple Bit-rates|OSCAR：多比特率一步扩散编解码器|Jinpei Guo, Yifei Ji, Zheng Chen, Kai Liu, Min Liu, Wang Rao, Wenbo Li, Yong Guo .etc.|<http://arxiv.org/pdf/2505.16091v1>|[代码](https://github.com/jp-guo/OSCAR.); OSCAR提出了一种一步扩散编解码器，实现多比特率图像压缩，显著提升效率。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Delving into RL for Image Generation with CoT: A Study on DPO vs. GRPO|深入探索基于CoT的图像生成中的强化学习：DPO与GRPO的比较研究|Chengzhuo Tong, Ziyu Guo, Renrui Zhang, Wenyu Shan, Xinyu Wei, Zhenghao Xing, Hongsheng Li, Pheng-Ann Heng|<http://arxiv.org/pdf/2505.17017v1>|[代码](https://github.com/ZiyuGuo99/Image-Generation-CoT); 首次全面研究了GRPO和DPO算法在自回归图像生成中的应用，揭示了奖励模型对算法泛化能力的影响。|
|🆕 发布|Creatively Upscaling Images with Global-Regional Priors|创意提升图像质量：全局-区域先验|Yurui Qian, Qi Cai, Yingwei Pan, Ting Yao, Tao Mei|<http://arxiv.org/pdf/2505.16976v1>|提出C-Upscale，通过全局-区域先验实现无调优图像超分辨率，提升视觉保真度和创意细节。|
|🆕 发布|DetailMaster: Can Your Text-to-Image Model Handle Long Prompts?|DetailMaster：您的文本到图像模型能处理长提示吗？|Qirui Jiao, Daoyuan Chen, Yilun Huang, Xika Lin, Ying Shen, Yaliang Li|<http://arxiv.org/pdf/2505.16915v1>|提出DetailMaster基准，评估T2I模型处理长、细节丰富提示的能力，揭示其性能局限。|
|📝 更新|L2RDaS: Synthesizing 4D Radar Tensors for Model Generalization via Dataset Expansion|L2RDaS：通过数据集扩展合成4D雷达张量以实现模型泛化|Woo-Jin Jung, Dong-Hee Paek, Seung-Hyun Kong|<http://arxiv.org/pdf/2503.03637v2>|[代码](https://github.com/kaist-avelab/K-Radar.); 提出L2RDaS框架，通过从LiDAR数据合成空间信息丰富的4D雷达张量，提升模型泛化能力。|
|🆕 发布|Training-Free Efficient Video Generation via Dynamic Token Carving|无需训练的高效视频生成：动态令牌雕刻|Yuechen Zhang, Jinbo Xing, Bin Xia, Shaoteng Liu, Bohao Peng, Xin Tao, Pengfei Wan, Eric Lo .etc.|<http://arxiv.org/pdf/2505.16864v1>|[代码](https://github.com/dvlab-research/Jenga); 提出Jenga，通过动态注意力裁剪和渐进式分辨率生成，实现高效的无监督视频生成。|
|🆕 发布|Conditional Panoramic Image Generation via Masked Autoregressive Modeling|条件全景图像生成通过掩码自回归建模|Chaoyang Wang, Xiangtai Li, Lu Qi, Xiaofan Lin, Jinbin Bai, Qianyu Zhou, Yunhai Tong|<http://arxiv.org/pdf/2505.16862v1>|提出PAR模型，统一处理全景图像生成，解决扩散模型不适配和条件生成分离问题。|
|📝 更新|Retrieval-Augmented Perception: High-Resolution Image Perception Meets Visual RAG|检索增强感知：高分辨率图像感知遇见视觉RAG|Wenbin Wang, Yongcheng Jing, Liang Ding, Yingjie Wang, Li Shen, Yong Luo, Bo Du, Dacheng Tao|<http://arxiv.org/pdf/2503.01222v2>|提出RAP，利用RAG增强MLLM的HR图像感知能力，显著提升图像识别准确率。|
|🆕 发布|V2V: Scaling Event-Based Vision through Efficient Video-to-Voxel Simulation|基于事件的视觉扩展：通过高效的视频到体素模拟进行扩展|Hanyue Lou, Jinxiu Liang, Minggui Teng, Yi Wang, Boxin Shi|<http://arxiv.org/pdf/2505.16797v1>|V2V通过高效视频到体素模拟，解决事件视觉模型数据集扩展难题，大幅提升模型性能。|
|🆕 发布|Mesh-RFT: Enhancing Mesh Generation via Fine-grained Reinforcement Fine-Tuning|网格-RFT：通过细粒度强化微调增强网格生成|Jian Liu, Jing Xu, Song Guo, Jing Li, Jingfeng Guo, Jiaao Yu, Haohan Weng, Biwen Lei .etc.|<http://arxiv.org/pdf/2505.16761v1>|[代码](https://hitcslj.github.io/mesh-rft); Mesh-RFT通过精细的强化学习优化，显著提升了3D网格生成质量，实现了局部细节的精确调整。|
|🆕 发布|Self-Rewarding Large Vision-Language Models for Optimizing Prompts in Text-to-Image Generation|自我奖励的大视觉-语言模型用于优化文本到图像生成中的提示|Hongji Yang, Yucheng Zhou, Wencheng Han, Jianbing Shen|<http://arxiv.org/pdf/2505.16763v1>|提出一种利用大型视觉语言模型自优化文本提示，提升文本到图像生成质量的方法。|
|📝 更新|Playmate: Flexible Control of Portrait Animation via 3D-Implicit Space Guided Diffusion|玩伴：通过3D隐式空间引导扩散实现肖像动画的灵活控制|Xingpei Ma, Jiaran Cai, Yuansheng Guan, Shenneng Huang, Qiang Zhang, Shunsi Zhang|<http://arxiv.org/pdf/2502.07203v3>|[代码](https://github.com/Playmate111/Playmate.); 提出Playmate，通过3D隐式空间引导扩散实现灵活控制人像动画，解决现有语音驱动人脸生成模型中表...|
|🆕 发布|KRIS-Bench: Benchmarking Next-Level Intelligent Image Editing Models|KRIS-Bench：下一代智能图像编辑模型的基准测试|Yongliang Wu, Zonghui Li, Xinting Hu, Xinyu Ye, Xianfang Zeng, Gang Yu, Wenbo Zhu, Bernt Schiele .etc.|<http://arxiv.org/pdf/2505.16707v1>|构建KRIS-Bench基准，评估智能图像编辑模型的知识推理能力，揭示推理性能差距。|
|🆕 发布|Grounding Chest X-Ray Visual Question Answering with Generated Radiology Reports|基于生成放射学报告的胸部X光视觉问答定位|Francesco Dalla Serra, Patrick Schrempf, Chaoyang Wang, Zaiqiao Meng, Fani Deligianni, Alison Q. O'Neil|<http://arxiv.org/pdf/2505.16624v1>|提出了一种结合放射学报告的胸部X光视觉问答方法，显著提升了问答准确率。|
|🆕 发布|M2SVid: End-to-End Inpainting and Refinement for Monocular-to-Stereo Video Conversion|M2SVid：单目到立体视频转换的端到端修复和细化|Nina Shvetsova, Goutam Bhat, Prune Truong, Hilde Kuehne, Federico Tombari|<http://arxiv.org/pdf/2505.16565v1>|提出了一种基于SVD模型和注意力机制的端到端单目到立体视频转换方法，显著提升了转换质量和速度。|
|🆕 发布|Temporal Object Captioning for Street Scene Videos from LiDAR Tracks|基于激光雷达轨迹的街景视频时序物体标题生成|Vignesh Gopinathan, Urs Zimmermann, Michael Arnold, Matthias Rottmann|<http://arxiv.org/pdf/2505.16594v1>|提出了一种基于LiDAR的街景视频时序对象描述方法，显著提升了视频描述的时序理解能力。|
|📝 更新|Leveraging Large Language Models For Scalable Vector Graphics Processing: A Review|利用大型语言模型进行可扩展矢量图形处理的综述|Boris Malashenko, Ivan Jarsky, Valeria Efimova|<http://arxiv.org/pdf/2503.04983v2>|该论文通过利用大型语言模型，提高了矢量图形处理效率，特别是在SVG格式生成和编辑方面。|
|🆕 发布|Clear Nights Ahead: Towards Multi-Weather Nighttime Image Restoration|晴朗的夜晚：迈向多天气象夜间图像修复|Yuetong Liu, Yunqiu Xu, Yang Wei, Xiuli Bi, Bin Xiao|<http://arxiv.org/pdf/2505.16479v1>|[代码](https://henlyta.github.io/ClearNight); 提出了一种多天气夜间图像修复框架，有效去除复杂退化，实现高质量夜间图像恢复。|
|🆕 发布|ALTo: Adaptive-Length Tokenizer for Autoregressive Mask Generation|自适应长度分词器用于自回归掩码生成|Lingfeng Wang, Hualing Lin, Senda Chen, Tao Wang, Changxu Cheng, Yangyang Zhong, Dong Zheng, Wuyue Zhao|<http://arxiv.org/pdf/2505.16495v1>|[代码](https://github.com/yayafengzi/ALToLLM.); 提出ALTo，一种自适应长度分词器，用于自动回归掩码生成，显著提升多模态大语言模型在图像分割上的性能...|
|📝 更新|When LLMs Learn to be Students: The SOEI Framework for Modeling and Evaluating Virtual Student Agents in Educational Interaction|当大型语言模型学习成为学生：教育互动中虚拟学生代理建模与评估的SOEI框架|Yiping Ma, Shiyu Hu, Xuchen Li, Yipei Wang, Yuqing Chen, Shiqing Liu, Kang Hao Cheong|<http://arxiv.org/pdf/2410.15701v2>|提出SOEI框架，构建并评估具有个性行为的虚拟学生代理，以支持教育互动中的适应性教学。|
|🆕 发布|Benchmarking Retrieval-Augmented Multimomal Generation for Document Question Answering|基准测试用于文档问答的多模态检索增强生成|Kuicai Dong, Yujing Chang, Shijie Huang, Yasheng Wang, Ruiming Tang, Yong Liu|<http://arxiv.org/pdf/2505.16470v1>|[代码](https://mmdocrag.github.io/MMDocRAG); 构建了MMDocRAG基准，通过创新指标评估多模态证据选择，提升文档问答系统性能。|
|🆕 发布|AdvReal: Adversarial Patch Generation Framework with Application to Adversarial Safety Evaluation of Object Detection Systems|AdvReal：应用于目标检测系统对抗安全性评估的对抗性补丁生成框架|Yuanhao Huang, Yilong Ren, Jinlei Wang, Lujia Huo, Xuesong Bai, Jinchuan Zhang, Haiyan Yu|<http://arxiv.org/pdf/2505.16402v1>|[代码](https://github.com/Huangyh98/AdvReal.git.); 提出了一种结合非刚性表面建模和3D匹配机制的对抗样本生成框架，有效评估目标检测系统安全性。|
|🆕 发布|NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment|NTIRE 2025 文本到图像生成模型质量评估挑战赛|Shuhao Han, Haotian Fan, Fangyuan Kong, Wenjie Liao, Chunle Guo, Chongyi Li, Radu Timofte, Liang Li .etc.|<http://arxiv.org/pdf/2505.16314v1>|举办NTIRE 2025挑战赛，评估T2I模型质量，通过图像-文本对齐和结构扭曲检测，显著提升评估性...|
|🆕 发布|Paired and Unpaired Image to Image Translation using Generative Adversarial Networks|配对与非配对图像到图像翻译使用生成对抗网络|Gaurav Kumar, Soham Satyadharma, Harpreet Singh|<http://arxiv.org/pdf/2505.16310v1>|提出了一种结合条件GAN和循环一致性损失的图像到图像翻译方法，有效提升了翻译质量。|
|📝 更新|UniCTokens: Boosting Personalized Understanding and Generation via Unified Concept Tokens|统一概念标记：通过统一概念标记提升个性化理解和生成|Ruichuan An, Sihan Yang, Renrui Zhang, Zijun Shen, Ming Lu, Gaole Dai, Hao Liang, Ziyu Guo .etc.|<http://arxiv.org/pdf/2505.14671v2>|[代码](https://github.com/arctanxarc/UniCTokens); 提出UniCTokens，通过统一概念标记提升个性化理解和生成能力。|
|📝 更新|Generative Pre-trained Autoregressive Diffusion Transformer|生成预训练自回归扩散Transformer|Yuan Zhang, Jiacheng Jiang, Guoqing Ma, Zhiying Lu, Haoyang Huang, Jianlong Yuan, Nan Duan|<http://arxiv.org/pdf/2505.07344v4>|提出GPDiT，一种结合扩散和自回归模型的视频生成方法，显著提升视频质量和学习效率。|
|📝 更新|TWIG: Two-Step Image Generation using Segmentation Masks in Diffusion Models|TWIG：基于扩散模型的分段掩码两步图像生成|Mazharul Islam Rakib, Showrin Rahman, Joyanta Jyoti Mondal, Xi Xiao, David Lewis, Alessandra Mileo, Meem Arafat Manab|<http://arxiv.org/pdf/2504.14933v2>|提出一种利用分割掩模避免版权侵权和源复制的两步图像生成方法。|
|🆕 发布|Understanding Generative AI Capabilities in Everyday Image Editing Tasks|理解在日常图像编辑任务中生成式人工智能的能力|Mohammad Reza Taesiri, Brandon Collins, Logan Bolton, Viet Dac Lai, Franck Dernoncourt, Trung Bui, Anh Totti Nguyen|<http://arxiv.org/pdf/2505.16181v1>|分析Reddit社区图像编辑请求，揭示AI编辑局限性，为改进AI编辑提供指导。|
|🆕 发布|Compressing Human Body Video with Interactive Semantics: A Generative Approach|人体视频交互语义压缩：一种生成方法|Bolin Chen, Shanzhi Yin, Hanwei Zhu, Lingyu Zhu, Zihan Zhang, Jie Chen, Ru-Ling Liao, Shiqi Wang .etc.|<http://arxiv.org/pdf/2505.16152v1>|提出了一种基于交互语义的生成式方法，有效压缩人体视频并实现高质量重建。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Motion by Queries: Identity-Motion Trade-offs in Text-to-Video Generation|运动查询：文本到视频生成中的身份-运动权衡|Yuval Atzmon, Rinon Gal, Yoad Tewel, Yoni Kasten, Gal Chechik|<http://arxiv.org/pdf/2412.07750v3>|揭示了文本到视频生成中运动、结构和身份之间的交互影响，并提出了一种高效的运动迁移和身份保持方法。|
|🆕 发布|Action2Dialogue: Generating Character-Centric Narratives from Scene-Level Prompts|动作到对话：从场景级提示生成以角色为中心的叙事|Taewon Kang, Ming C. Lin|<http://arxiv.org/pdf/2505.16819v1>|提出了一种将动作提示转化为角色对话的方法，为视觉叙事增添了自然语音和角色表达。|
|📝 更新|Provable Ordering and Continuity in Vision-Language Pretraining for Generalizable Embodied Agents|可证明的顺序和连续性在视觉-语言预训练中用于泛化具身智能体|Zhizhen Zhang, Lei Zhu, Zhen Fang, Zi Huang, Yadan Luo|<http://arxiv.org/pdf/2502.01218v2>|提出AcTOL方法，通过学习视频的连续性和顺序性，提升视觉语言预训练的泛化能力。|
|🆕 发布|Redemption Score: An Evaluation Framework to Rank Image Captions While Redeeming Image Semantics and Language Pragmatics|救赎分数：一种在救赎图像语义和语言语用学的同时对图像标题进行排名的评估框架|Ashim Dahal, Ankit Ghimire, Saydul Akbar Murad, Nick Rahimi|<http://arxiv.org/pdf/2505.16180v1>|提出Redemption Score，通过融合多信号评估图像描述，实现更全面的图像语义和语言评价。|
|🆕 发布|Generative Latent Coding for Ultra-Low Bitrate Image and Video Compression|超低比特率图像和视频压缩的生成潜在编码|Linfeng Qi, Zhaoyang Jia, Jiahao Li, Bin Li, Houqiang Li, Yan Lu|<http://arxiv.org/pdf/2505.16177v1>|提出GLC模型，通过在潜在空间进行变换编码，实现超低比特率图像和视频的高保真压缩。|
|🆕 发布|QuickVideo: Real-Time Long Video Understanding with System Algorithm Co-Design|快速视频：基于系统算法协同设计的实时长视频理解|Benjamin Schneider, Dongfu Jiang, Chao Du, Tianyu Pang, Wenhu Chen|<http://arxiv.org/pdf/2505.16175v1>|QuickVideo通过系统算法协同设计，大幅加速长视频理解，实现实时应用。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Decoupled Geometric Parameterization and its Application in Deep Homography Estimation|解耦几何参数化及其在深度单应性估计中的应用|Yao Huang, Si-Yuan Cao, Yaqing Ding, Hao Yin, Shibin Xie, Shuting Wang, Zhijun Fang, Jiachun Wang .etc.|<http://arxiv.org/pdf/2505.16599v1>|提出了一种基于SKS分解的几何参数化方法，实现深度同态估计，无需线性系统求解。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Motion Matters: Compact Gaussian Streaming for Free-Viewpoint Video Reconstruction|运动至关重要：用于自由视点视频重建的紧凑高斯流|Jiacong Chen, Qingyu Mao, Youneng Bao, Xiandong Meng, Fanyang Meng, Ronggang Wang, Yongsheng Liang|<http://arxiv.org/pdf/2505.16533v1>|提出ComGS框架，通过关键点驱动运动表示，实现高效存储的免费视点视频重建。|
|🆕 发布|Pose-invariant face recognition via feature-space pose frontalization|基于特征空间姿态正面的姿态不变人脸识别|Nikolay Stanishev, Yuhang Lu, Touradj Ebrahimi|<http://arxiv.org/pdf/2505.16412v1>|提出了一种在特征空间内进行人脸正脸化的新方法，有效提升了人脸识别的鲁棒性。|
|📝 更新|Continuous Representation Methods, Theories, and Applications: An Overview and Perspectives|连续表示方法、理论与应用：综述与展望|Yisi Luo, Xile Zhao, Deyu Meng|<http://arxiv.org/pdf/2505.15222v2>|[代码](https://github.com/YisiLuo/Continuous-Representation-Zoo); 该论文综述了连续表示方法在计算机视觉中的应用，提出了基于函数映射的连续框架，提高了数据表示和重建的性...|
|📝 更新|OCSU: Optical Chemical Structure Understanding for Molecule-centric Scientific Discovery|光学化学结构理解：以分子为中心的科学发现|Siqi Fan, Yuguang Xie, Bowen Cai, Ailin Xie, Gaochao Liu, Mu Qiao, Jie Xing, Zaiqing Nie|<http://arxiv.org/pdf/2501.15415v2>|[代码](https://github.com/PharMolix/OCSU.); 提出OCSU任务，通过视觉语言模型和大规模数据集，实现化学结构图向可读字符串的转换。|
|🆕 发布|BadDepth: Backdoor Attacks Against Monocular Depth Estimation in the Physical World|BadDepth：针对物理世界单目深度估计的恶意攻击|Ji Guo, Long Zhou, Zhijin Wang, Jiaming He, Qiyang Song, Aiguo Chen, Wenbo Jiang|<http://arxiv.org/pdf/2505.16154v1>|提出BadDepth，首次实现针对单目深度估计模型的物理世界后门攻击。|
|📝 更新|Advances in Radiance Field for Dynamic Scene: From Neural Field to Gaussian Field|动态场景辐射场进展：从神经网络场到高斯场|Jinlong Fan, Xuepu Zeng, Jing Zhang, Mingming Gong, Yuxiang Yang, Dacheng Tao|<http://arxiv.org/pdf/2505.10049v2>|该论文系统分析了动态场景中基于辐射场的200多篇论文，提出了从神经网络场到高斯场的动态场景表示和重建...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Place Recognition: A Comprehensive Review, Current Challenges and Future Directions|场所识别：全面综述、当前挑战与未来方向|Zhenyu Li, Tianyi Shang, Pengjie Xu, Zhaojun Deng|<http://arxiv.org/pdf/2505.14068v2>|[代码](https://github.com/CV4RA/SOTA-Place-Recognitioner.); 综述了地点识别方法，包括CNN、Transformer和跨模态策略，并展望了未来研究方向。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CrossLMM: Decoupling Long Video Sequences from LMMs via Dual Cross-Attention Mechanisms|跨LMM：通过双重交叉注意力机制解耦长视频序列|Shilin Yan, Jiaming Han, Joey Tsai, Hongwei Xue, Rongyao Fang, Lingyi Hong, Ziyu Guo, Ray Zhang|<http://arxiv.org/pdf/2505.17020v1>|通过双交叉注意力机制，CrossLMM有效压缩长视频序列的视觉标记，降低计算成本，同时保持性能。|
|🆕 发布|Fact-R1: Towards Explainable Video Misinformation Detection with Deep Reasoning|事实-R1：迈向可解释的视频虚假信息检测与深度推理|Fanrui Zhang, Dian Li, Qiang Zhang, Chenjun, sinbadliu, Junxiong Lin, Jiahong Yan, Jiawei Liu .etc.|<http://arxiv.org/pdf/2505.16836v1>|Fact-R1通过结合深度推理和协同规则强化学习，实现了可解释的视频虚假信息检测。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SoccerChat: Integrating Multimodal Data for Enhanced Soccer Game Understanding|足球聊天：多模态数据集成以增强足球比赛理解|Sushant Gautam, Cise Midoglu, Vajira Thambawita, Michael A. Riegler, Pål Halvorsen, Mubarak Shah|<http://arxiv.org/pdf/2505.16630v1>|[代码](https://github.com/simula/SoccerChat); 提出SoccerChat，通过融合视觉和文本数据，提升足球比赛理解和分析能力。|
|🆕 发布|Temporal and Spatial Feature Fusion Framework for Dynamic Micro Expression Recognition|动态微表情识别的时间-空间特征融合框架|Feng Liu, Bingyu Nan, Xuezhong Qian, Xiaolan Fu|<http://arxiv.org/pdf/2505.16372v1>|提出了一种融合时空特征的动态微表情识别框架，显著提升了识别准确率。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Evaluation to Defense: Advancing Safety in Video Large Language Models|从评估到防御：提升视频大型语言模型的安全性|Yiwei Sun, Peiqi Jiang, Chuanbin Liu, Luohao Lin, Zhiying Lu, Hongtao Xie|<http://arxiv.org/pdf/2505.16643v1>|构建首个大规模视频LLM安全基准，并提出双阶段框架提升视频LLM安全性。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Advanced Knowledge Transfer: Refined Feature Distillation for Zero-Shot Quantization in Edge Computing|高级知识迁移：边缘计算中零样本量化的精细特征蒸馏|Inpyo Hong, Youngwan Jo, Hyojeong Lee, Sunghyun Ahn, Sanghyun Park|<http://arxiv.org/pdf/2412.19125v2>|[代码](https://github.com/Inpyo-Hong/AKT-Advanced-knowledge-Transfer.); 提出AKT方法，通过特征蒸馏提升低比特量化模型在零样本量化中的训练能力。|


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Contrastive Learning-Enhanced Trajectory Matching for Small-Scale Dataset Distillation|对比学习增强的小规模数据集蒸馏轨迹匹配|Wenmin Li, Shunsuke Sakai, Tatsuhito Hasegawa|<http://arxiv.org/pdf/2505.15267v2>|提出了一种结合对比学习的轨迹匹配方法，有效提升小规模数据集的模型蒸馏性能。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-SpatialMLLM: Multi-Frame Spatial Understanding with Multi-Modal Large Language Models|多空间MLLM：多帧空间理解的多模态大型语言模型|Runsen Xu, Weiyao Wang, Hao Tang, Xingyu Chen, Xiaodong Wang, Fu-Jen Chu, Dahua Lin, Matt Feiszli .etc.|<http://arxiv.org/pdf/2505.17015v1>|提出Multi-SpatialMLLM，通过多模态大语言模型实现多帧空间理解，提升机器人等应用的多帧...|
|🆕 发布|Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga)|追踪飞行：探索分析平原斑马（Equus quagga）逃逸反应的计算框架|Isla Duporge, Sofia Minano, Nikoloz Sirmpilatze, Igor Tatarnikov, Scott Wolf, Adam L. Tyson, Daniel Rubenstein|<http://arxiv.org/pdf/2505.16882v1>|开发了一种计算框架，通过图像注册和SfM技术，有效分离动物和无人机运动，分析草原斑马逃逸行为。|
|📝 更新|Evaluating Automated Radiology Report Quality through Fine-Grained Phrasal Grounding of Clinical Findings|通过临床发现的细粒度短语定位评估自动放射学报告质量|Razi Mahmood, Pingkun Yan, Diego Machado Reyes, Ge Wang, Mannudeep K. Kalra, Parisa Kaviani, Joy T. Wu, Tanveer Syeda-Mahmood|<http://arxiv.org/pdf/2412.01031v3>|开发了一种基于细粒度临床发现定位和文本-视觉结合的放射报告质量评估方法。|
|📝 更新|Leveraging Habitat Information for Fine-grained Bird Identification|利用栖息地信息进行细粒度鸟类识别|Tin Nguyen, Peijie Chen, Anh Totti Nguyen|<http://arxiv.org/pdf/2312.14999v3>|首次将栖息地信息融入现代鸟类识别模型，显著提升识别准确率。|
|🆕 发布|Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding|远观清晰：通过注意力因果解码减轻MLLM中的幻觉|Feilong Tang, Chengzhi Liu, Zhongxing Xu, Ming Hu, Zelin Peng, Zhiwei Yang, Jionglong Su, Minquan Lin .etc.|<http://arxiv.org/pdf/2505.16652v1>|提出FarSight解码策略，通过优化因果掩码减轻MLLMs中的幻觉问题。|
|🆕 发布|Training-Free Reasoning and Reflection in MLLMs|无监督推理与反思在多模态大型语言模型中的训练|Hongchen Wei, Zhenzhong Chen|<http://arxiv.org/pdf/2505.16151v1>|提出FRANK模型，通过分层权重融合，赋予MLLM推理和反思能力，无需额外训练。|
|📝 更新|Auto-Prompting SAM for Weakly Supervised Landslide Extraction|自动提示SAM进行弱监督滑坡提取|Jian Wang, Xiaokang Zhang, Xianping Ma, Weikang Yu, Pedram Ghamisi|<http://arxiv.org/pdf/2501.13426v2>|提出APSAM方法，通过自动提示Segment Anything Model，有效提升弱监督滑坡提取...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Interactive Post-Training for Vision-Language-Action Models|交互式训练后的视觉-语言-动作模型|Shuhan Tan, Kairan Dou, Yue Zhao, Philipp Krähenbühl|<http://arxiv.org/pdf/2505.17016v1>|提出RIPT-VLA，通过交互式后训练提高视觉-语言-动作模型适应新任务的能力。|
|🆕 发布|An Effective Training Framework for Light-Weight Automatic Speech Recognition Models|一种轻量级自动语音识别模型的有效训练框架|Abdul Hannan, Alessio Brutti, Shah Nawaz, Mubashir Noman|<http://arxiv.org/pdf/2505.16991v1>|提出一种两步表示学习方法，从大型模型生成多个小型模型，显著提升轻量级语音识别模型性能。|
|🆕 发布|UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation|UniPhy：学习用于逆物理模拟的统一本构模型|Himangi Mittal, Peiye Zhuang, Hsin-Ying Lee, Shubham Tulsiani|<http://arxiv.org/pdf/2505.16971v1>|提出UniPhy，一种无需用户指定材料类型，通过优化场景特定潜在变量来推断材料属性的统一神经网络模型...|
|🆕 发布|Efficient Correlation Volume Sampling for Ultra-High-Resolution Optical Flow Estimation|高效的超高分辨率光流估计相关体积采样|Karlis Martins Briedis, Markus Gross, Christopher Schroers|<http://arxiv.org/pdf/2505.16942v1>|提出高效关联体积采样方法，大幅提升超高清光流估计的准确性和效率。|
|📝 更新|Reconciling Privacy and Explainability in High-Stakes: A Systematic Inquiry|在高风险中协调隐私和可解释性：一项系统性调查|Supriya Manna, Niladri Sett|<http://arxiv.org/pdf/2412.20798v4>|提出了一种在深度学习中平衡隐私和可解释性的系统框架，以保护用户隐私并提高模型透明度。|
|📝 更新|Artificial intelligence in digital pathology: a systematic review and meta-analysis of diagnostic test accuracy|人工智能在数字病理学中的应用：诊断测试准确性的系统评价和荟萃分析|Clare McGenity, Emily L Clarke, Charlotte Jennings, Gillian Matthews, Caroline Cartlidge, Henschel Freduah-Agyemang, Deborah D Stocken, Darren Treanor|<http://arxiv.org/pdf/2306.07999v3>|对数字病理学中AI诊断准确率进行系统回顾和荟萃分析，评估其临床应用潜力。|
|🆕 发布|SEDD-PCC: A Single Encoder-Dual Decoder Framework For End-To-End Learned Point Cloud Compression|SEDD-PCC：一种用于端到端学习点云压缩的单编码器-双解码器框架|Kai Hsiang Hsieh, Monyneath Yim, Jui Chiu Chiang|<http://arxiv.org/pdf/2505.16709v1>|提出了一种联合压缩点云几何和属性的新框架，显著提升了压缩效率。|
|📝 更新|Supervising 3D Talking Head Avatars with Analysis-by-Audio-Synthesis|基于音频合成的3D说话头像监督|Radek Daněček, Carolin Schmitt, Senya Polikovsky, Michael J. Black|<http://arxiv.org/pdf/2504.13386v2>|开发了一种基于音频合成的监督机制，显著提升了3D说话头像的唇同步质量。|
|🆕 发布|Semantic Compression of 3D Objects for Open and Collaborative Virtual Worlds|语义压缩三维对象以用于开放和协作的虚拟世界|Jordan Dotzel, Tony Montes, Mohamed S. Abdelfattah, Zhiru Zhang|<http://arxiv.org/pdf/2505.16679v1>|提出了一种基于语义的3D对象压缩方法，显著提升了压缩率和质量。|
|🆕 发布|Circle-RoPE: Cone-like Decoupled Rotary Positional Embedding for Large Vision-Language Models|圆环RoPE：用于大型视觉-语言模型的锥形解耦旋转位置嵌入|Chengcheng Wang, Jianyuan Guo, Hongguang Li, Yuchuan Tian, Ying Nie, Chang Xu, Kai Han|<http://arxiv.org/pdf/2505.16416v1>|[代码](https://github.com/lose4578/CircleRoPE); 提出Circle-RoPE，通过环形轨迹解决大视觉语言模型中的跨模态位置偏差问题。|
|🆕 发布|DualComp: End-to-End Learning of a Unified Dual-Modality Lossless Compressor|DualComp：统一双模态无损压缩的端到端学习|Yan Zhao, Zhengxue Cheng, Junxuan Zhang, Qunshan Gu, Qi Wang, Li Song|<http://arxiv.org/pdf/2505.16256v1>|提出了一种轻量级学习型双模态无损压缩器，有效解决了多模态数据压缩问题。|
|🆕 发布|Hierarchical Safety Realignment: Lightweight Restoration of Safety in Pruned Large Vision-Language Models|分层安全重置：剪枝大型视觉-语言模型的轻量级安全恢复|Yue Li, Xin Yi, Dongsheng Shi, Gerard de Melo, Xiaoling Wang, Linlin Wang|<http://arxiv.org/pdf/2505.16104v1>|提出了一种轻量级方法，通过分层恢复剪枝大型视觉语言模型的安全性能。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Feature Map Similarity Reduction in Convolutional Neural Networks|卷积神经网络中特征图相似度降低|Zakariae Belmekki, Jun Li, Patrick Reuter, David Antonio Gómez Jáuregui, Karl Jenkins|<http://arxiv.org/pdf/2411.03226v2>|提出了一种基于卷积相似度减少的方法，有效降低CNN特征图冗余，提升模型效率和准确度。|
|📝 更新|Fast computation of the TGOSPA metric for multiple target tracking via unbalanced optimal transport|快速计算多目标跟踪的TGOSPA度量通过不平衡最优传输|Viktor Nevelius Wernholm, Alfred Wärnsäter, Axel Ringh|<http://arxiv.org/pdf/2503.09449v2>|提出一种基于不平衡最优传输的近似算法，快速计算多目标跟踪的TGOSPA指标。|
|🆕 发布|InspectionV3: Enhancing Tobacco Quality Assessment with Deep Convolutional Neural Networks for Automated Workshop Management|检查V3：利用深度卷积神经网络增强烟草质量评估以实现自动化车间管理|Yao Wei, Muhammad Usman, Hazrat Bilal|<http://arxiv.org/pdf/2505.16485v1>|提出InspectionV3，利用定制深度卷积神经网络自动评估烟草质量，提升工作坊管理效率。|
|📝 更新|Refining CNN-based Heatmap Regression with Gradient-based Corner Points for Electrode Localization|基于CNN的热图回归优化：用于电极定位的基于梯度的角点检测|Lin Wu|<http://arxiv.org/pdf/2412.17105v3>|提出结合梯度角点先验的CNN热图回归法，显著提升锂电池电极定位精度。|
|🆕 发布|Joint Flow And Feature Refinement Using Attention For Video Restoration|基于注意力机制的联合光流与特征精炼用于视频恢复|Ranjith Merugu, Mohammad Sameer Suhail, Akshay P Sarashetti, Venkata Bharath Reddy Reddem, Pankaj Kumar Bajpai, Amit Satish Unde|<http://arxiv.org/pdf/2505.16434v1>|提出了一种结合流和特征精炼的注意力机制视频修复框架，显著提升了视频修复性能。|
|🆕 发布|MAGE: A Multi-task Architecture for Gaze Estimation with an Efficient Calibration Module|MAGE：一种用于注视估计的多任务架构及高效校准模块|Haoming Huang, Musen Zhang, Jianxin Yang, Zhen Li, Jinkai Li, Yao Guo|<http://arxiv.org/pdf/2505.16384v1>|提出MAGE，一种多任务架构，通过高效校准模块预测6自由度注视信息，解决现有注视估计方法信息不足和泛...|
|🆕 发布|ARPO:End-to-End Policy Optimization for GUI Agents with Experience Replay|ARPO：具有经验回放的GUI代理端到端策略优化|Fanbin Lu, Zhisheng Zhong, Shu Liu, Chi-Wing Fu, Jiaya Jia|<http://arxiv.org/pdf/2505.16282v1>|[代码](https://github.com/dvlab-research/ARPO.git.); 提出ARPO，一种结合经验回放和任务选择的端到端策略优化方法，提升GUI代理的交互性能。|
|📝 更新|Maximizing Discrimination Capability of Knowledge Distillation with Energy Function|利用能量函数最大化知识蒸馏的判别能力|Seonghak Kim, Gyeongdo Ham, Suin Lee, Donggon Jang, Daeshik Kim|<http://arxiv.org/pdf/2311.14334v3>|利用能量函数优化知识蒸馏，显著提升模型在复杂数据集上的性能。|
|🆕 发布|A Shape-Aware Total Body Photography System for In-focus Surface Coverage Optimization|形状感知全身摄影系统，用于优化焦点表面覆盖|Wei-Lun Huang, Joshua Liu, Davood Tashayyod, Jun Kang, Amir Gandjbakhche, Misha Kazhdan, Mehran Armand|<http://arxiv.org/pdf/2505.16228v1>|提出了一种形状感知全身摄影系统，通过优化图像分辨率和清晰度，提高皮肤癌筛查中皮肤病变检测的准确性。|
|📝 更新|Multi-modal Collaborative Optimization and Expansion Network for Event-assisted Single-eye Expression Recognition|多模态协同优化与扩展网络在辅助单眼表情识别中的应用|Runduo Han, Xiuping Liu, Shangxuan Yi, Yi Zhang, Hongchen Tan|<http://arxiv.org/pdf/2505.12007v3>|提出了一种多模态协作优化网络，有效提升单眼表情识别在低光照条件下的准确性。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Harnessing the Computation Redundancy in ViTs to Boost Adversarial Transferability|利用ViTs中的计算冗余来提升对抗迁移性|Jiani Liu, Zhiyuan Wang, Zeliang Zhang, Chao Huang, Susan Liang, Yunlong Tang, Chenliang Xu|<http://arxiv.org/pdf/2504.10804v2>|利用ViT的计算冗余提升对抗样本迁移性。|
|🆕 发布|Accelerating Targeted Hard-Label Adversarial Attacks in Low-Query Black-Box Settings|加速低查询黑盒设置下的针对性硬标签对抗攻击|Arjhun Swaminathan, Mete Akgün|<http://arxiv.org/pdf/2505.16313v1>|提出TEA攻击，利用目标图像边缘信息在低查询黑盒环境下高效生成对抗样本。|
|🆕 发布|SuperPure: Efficient Purification of Localized and Distributed Adversarial Patches via Super-Resolution GAN Models|超级纯净：通过超分辨率生成对抗网络模型高效净化局部和分布式对抗样本|Hossein Khalili, Seongbin Park, Venkat Bollapragada, Nader Sehatbakhsh|<http://arxiv.org/pdf/2505.16318v1>|SuperPure通过超分辨率GAN模型有效净化对抗性补丁，提升对抗攻击防御能力并降低延迟。|
|📝 更新|ErasableMask: A Robust and Erasable Privacy Protection Scheme against Black-box Face Recognition Models|可擦除掩码：针对黑盒人脸识别模型的鲁棒且可擦除隐私保护方案|Sipeng Shen, Yunming Zhang, Dengpan Ye, Xiuwen Shi, Long Tang, Haoran Duan, Yueyun Shang, Zhihong Tian|<http://arxiv.org/pdf/2412.17038v4>|ErasableMask提出了一种针对黑盒人脸识别模型的鲁棒且可擦除的隐私保护方案，有效提升了隐私保...|
|📝 更新|Robust 6DoF Pose Tracking Considering Contour and Interior Correspondence Uncertainty for AR Assembly Guidance|鲁棒6自由度姿态跟踪：考虑轮廓和内部对应不确定性以实现AR装配引导|Jixiang Chen, Jing Chen, Kai Liu, Haochen Chang, Shanfeng Fu, Jian Yang|<http://arxiv.org/pdf/2502.11971v3>|提出了一种结合轮廓和内部对应关系的不确定性鲁棒的6DoF姿态跟踪方法，显著提升了AR装配指导的准确性...|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Single Domain Generalization for Few-Shot Counting via Universal Representation Matching|通过通用表示匹配的单一领域泛化在少样本计数中的应用|Xianing Chen, Si Huo, Borui Jiang, Hailin Hu, Xinghao Chen|<http://arxiv.org/pdf/2505.16778v1>|提出了一种基于通用视觉语言表示的单一领域泛化方法，显著提升了小样本计数在领域迁移中的鲁棒性。|
|📝 更新|Logit Scaling for Out-of-Distribution Detection|对分布外检测的Logit缩放|Andrija Djurisic, Rosanne Liu, Mladen Nikolic|<http://arxiv.org/pdf/2409.01175v2>|提出Logit Scaling方法，无需训练数据，有效检测不同架构中的异常数据。|
|🆕 发布|Ranked Entropy Minimization for Continual Test-Time Adaptation|排序熵最小化用于持续测试时自适应|Jisu Han, Jaemin Na, Wonjun Hwang|<http://arxiv.org/pdf/2505.16441v1>|[代码](https://github.com/pilsHan/rem); 提出了一种解决模型坍塌的排名熵最小化方法，提升持续测试时适应的稳定性。|
|📝 更新|VAE-QWGAN: Addressing Mode Collapse in Quantum GANs via Autoencoding Priors|VAE-QWGAN：通过自动编码先验解决量子GAN中的模式坍塌问题|Aaron Mark Thomas, Harry Youel, Sharu Theresa Jose|<http://arxiv.org/pdf/2409.10339v2>|提出VAE-QWGAN，结合VAE和QWGAN优势，解决量子GAN模式坍塌问题，提升图像生成质量。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ATR-Bench: A Federated Learning Benchmark for Adaptation, Trust, and Reasoning|ATR-Bench：适应、信任和推理的联邦学习基准|Tajamul Ashraf, Mohammed Mohsen Peerzada, Moloud Abdar, Yutong Xie, Yuyin Zhou, Xiaofeng Liu, Iqra Altaf Gillani, Janibul Bashir|<http://arxiv.org/pdf/2505.16850v1>|构建了ATR-Bench基准，统一评估联邦学习中的适应、信任和推理能力。|
|📝 更新|DongbaMIE: A Multimodal Information Extraction Dataset for Evaluating Semantic Understanding of Dongba Pictograms|东巴MIE：用于评估东巴象形文字语义理解的跨模态信息提取数据集|Xiaojun Bi, Shuo Li, Junyao Xing, Ziyue Wang, Fuwen Luo, Weizheng Qiao, Lu Han, Ziwei Sun .etc.|<http://arxiv.org/pdf/2503.03644v4>|构建了首个多模态信息提取数据集DongbaMIE，以评估对东巴象形文字的语义理解。|
|🆕 发布|Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models|思考与否？通过强化学习为视觉-语言模型进行选择性推理|Jiaqi Wang, Kevin Qinghong Lin, James Cheng, Mike Zheng Shou|<http://arxiv.org/pdf/2505.16854v1>|[代码](https://github.com/kokolerk/TON.); 提出TON方法，通过选择性推理降低视觉语言模型计算成本，实现类似人类思考模式。|
|🆕 发布|Hypergraph Tversky-Aware Domain Incremental Learning for Brain Tumor Segmentation with Missing Modalities|超图Tversky感知域增量学习在缺失模态下进行脑肿瘤分割|Junze Wang, Lei Fan, Weipeng Jing, Donglin Di, Yang Song, Sidong Liu, Cong Cong|<http://arxiv.org/pdf/2505.16809v1>|提出了一种针对脑肿瘤分割的域增量学习方法，有效应对缺失模态问题并提升分割性能。|
|📝 更新|Liver Cirrhosis Stage Estimation from MRI with Deep Learning|基于深度学习的MRI肝脏肝硬化阶段估计|Jun Zeng, Debesh Jha, Ertugrul Aktas, Elif Keles, Alpay Medetalibeyoglu, Matthew Antalek, Federica Proietto Salanitri, Amir A. Borhani .etc.|<http://arxiv.org/pdf/2502.18225v3>|[代码](https://github.com/JunZengz/CirrhosisStage.); 开发了一种深度学习框架，通过多尺度特征学习和序列特定注意力机制，实现了从MRI图像中自动评估肝硬化阶...|
|📝 更新|Relation-R1: Progressively Cognitive Chain-of-Thought Guided Reinforcement Learning for Unified Relation Comprehension|关系-R1：统一关系理解中的渐进式认知思维链引导强化学习|Lin Li, Wei Chen, Jiahui Li, Kwang-Ting Cheng, Long Chen|<http://arxiv.org/pdf/2504.14642v2>|Relation-R1通过认知链式思维引导的强化学习，实现了对统一关系理解的突破。|
|📝 更新|seq-JEPA: Autoregressive Predictive Learning of Invariant-Equivariant World Models|seq-JEPA：不变-等变世界模型的自回归预测学习|Hafez Ghaemi, Eilif Muller, Shahab Bakhtiari|<http://arxiv.org/pdf/2505.03176v2>|seq-JEPA通过引入架构诱导偏差，同时学习可变和不变表示，解决了自监督学习中的可变性与不变性之间...|
|🆕 发布|MM-MovieDubber: Towards Multi-Modal Learning for Multi-Modal Movie Dubbing|MM-MovieDubber：迈向多模态电影配音的多模态学习|Junjie Zheng, Zihao Chen, Chaofan Ding, Yunming Liang, Yihan Fan, Huan Yang, Lei Xie, Xinhan Di|<http://arxiv.org/pdf/2505.16279v1>|提出了一种多模态学习框架，有效提升电影配音质量和风格适应性。|
|🆕 发布|IRONIC: Coherence-Aware Reasoning Chains for Multi-Modal Sarcasm Detection|Ironic：多模态讽刺检测中的连贯性感知推理链|Aashish Anantha Ramakrishnan, Aadarsh Anantha Ramakrishnan, Dongwon Lee|<http://arxiv.org/pdf/2505.16258v1>|[代码](https://github.com/aashish2000/IRONIC); 提出了一种利用多模态连贯关系分析图像-文本链接的框架，显著提升了多模态讽刺检测的性能。|
|🆕 发布|An Empirical Study on Configuring In-Context Learning Demonstrations for Unleashing MLLMs' Sentimental Perception Capability|对释放多语言大模型情感感知能力的情境学习演示配置的实证研究|Daiqing Wu, Dongbao Yang, Sicheng Zhao, Can Ma, Yu Zhou|<http://arxiv.org/pdf/2505.16193v1>|通过优化演示配置，提升MLLM在情感分析任务中的感知能力。|
|📝 更新|Understanding Deep Representation Learning via Layerwise Feature Compression and Discrimination|通过层状特征压缩和判别理解深度表示学习|Peng Wang, Xiao Li, Can Yaras, Zhihui Zhu, Laura Balzano, Wei Hu, Qing Qu|<http://arxiv.org/pdf/2311.02960v3>|[代码](https://github.com/Heimine/PNC_DLN.); 揭示了深度神经网络中特征层次学习的结构，通过层间特征压缩和区分度分析，量化了特征从浅层到深层的演变过...|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 目标导向视觉决策 (Goal-oriented Visual Decision Making)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Perceptual Quality Assessment for Embodied AI|具身人工智能的感知质量评估|Chunyi Li, Jiaohao Xiao, Jianbo Zhang, Farong Wen, Zicheng Zhang, Yuan Tian, Xiangyang Zhu, Xiaohong Liu .etc.|<http://arxiv.org/pdf/2505.16815v1>|[代码](https://github.com/lcysyzxdxc/EmbodiedIQA); 提出了一种针对Embodied AI的感知质量评估方法，构建了感知-认知-决策-执行流程，并建立了E...|
|🆕 发布|Unlocking Smarter Device Control: Foresighted Planning with a World Model-Driven Code Execution Approach|解锁更智能的设备控制：基于世界模型驱动的代码执行前瞻性规划方法|Xiaoran Yin, Xu Luo, Hao Wu, Lianli Gao, Jingkuan Song|<http://arxiv.org/pdf/2505.16422v1>|提出FPWC框架，通过世界模型驱动代码执行实现预见性规划，提升移动设备任务执行效率。|


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ManipLVM-R1: Reinforcement Learning for Reasoning in Embodied Manipulation with Large Vision-Language Models|ManipLVM-R1：基于大型视觉-语言模型的具身操作推理强化学习|Zirui Song, Guangxian Ouyang, Mingzhe Li, Yuheng Ji, Chenxi Wang, Zixiang Xu, Zeyu Zhang, Xiaoqing Zhang .etc.|<http://arxiv.org/pdf/2505.16517v1>|提出ManipLVM-R1，通过强化学习与可验证奖励，提升机器人操作中的视觉语言模型泛化能力和物理推...|
|🆕 发布|SEM: Enhancing Spatial Understanding for Robust Robot Manipulation|SEM：增强空间理解以实现鲁棒的机器人操作|Xuewu Lin, Tianwei Lin, Lichao Huang, Hongyu Xie, Yiwei Jin, Keyu Li, Zhizhong Su|<http://arxiv.org/pdf/2505.16196v1>|SEM模型通过融合3D几何和机器人状态信息，显著提升了机器人操作的空间理解能力。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark|阿拉伯语多模态推理综合基准（ARB）|Sara Ghaboura, Ketan More, Wafa Alghallabi, Omkar Thawakar, Jorma Laaksonen, Hisham Cholakkal, Salman Khan, Rao Muhammad Anwer|<http://arxiv.org/pdf/2505.17021v1>|[代码](https://github.com/mbzuai-oryx/ARB); 构建首个阿拉伯语多模态推理基准，评估阿拉伯语多模态推理能力。|
|🆕 发布|SpatialScore: Towards Unified Evaluation for Multimodal Spatial Understanding|空间评分：迈向多模态空间理解的统一评估|Haoning Wu, Xiao Huang, Yaohui Chen, Ya Zhang, Yanfeng Wang, Weidi Xie|<http://arxiv.org/pdf/2505.17012v1>|构建了评估多模态空间理解的基准SpatialScore，并开发了支持多种推理范式的SpatialAg...|
|🆕 发布|OpenSeg-R: Improving Open-Vocabulary Segmentation via Step-by-Step Visual Reasoning|OpenSeg-R：通过逐步视觉推理提升开放词汇分割|Zongyan Han, Jiale Cao, Shuo Chen, Tong Wang, Jorma Laaksonen, Rao Muhammad Anwer|<http://arxiv.org/pdf/2505.16974v1>|[代码](https://github.com/Hanzy1996/OpenSeg-R.); 提出了一种基于逐步视觉推理的开放词汇分割框架，显著提升了分割精度和可解释性。|
|📝 更新|Top-Down Compression: Revisit Efficient Vision Token Projection for Visual Instruction Tuning|自上而下压缩：重新审视高效视觉令牌投影以实现视觉指令微调|Bonan li, Zicheng Zhang, Songhua Liu, Weihao Yu, Xinchao Wang|<http://arxiv.org/pdf/2505.11945v2>|提出LLaVA-Meteor，通过Top-Down压缩和视觉原生选择机制，有效降低视觉指令微调的效率...|
|🆕 发布|CoNav: Collaborative Cross-Modal Reasoning for Embodied Navigation|协同跨模态推理实现具身导航|Haihong Hao, Mingfei Han, Changlin Li, Zhihui Li, Xiaojun Chang|<http://arxiv.org/pdf/2505.16663v1>|[代码](https://oceanhao.github.io/CoNav); CoNav通过融合3D文本模型的空间语义知识，有效指导图像文本导航，显著提升导航效率和路径长度。|
|📝 更新|VisionReasoner: Unified Visual Perception and Reasoning via Reinforcement Learning|视觉推理器：通过强化学习实现统一的视觉感知与推理|Yuqi Liu, Tianyuan Qu, Zhisheng Zhong, Bohao Peng, Shu Liu, Bei Yu, Jiaya Jia|<http://arxiv.org/pdf/2505.12081v3>|VisionReasoner通过强化学习实现视觉感知与推理的统一，在多个视觉任务上显著提升性能。|
|🆕 发布|Zero-Shot Anomaly Detection in Battery Thermal Images Using Visual Question Answering with Prior Knowledge|基于先验知识的视觉问答在电池热图像中的零样本异常检测|Marcella Astrid, Abdelrahman Shabayek, Djamila Aouada|<http://arxiv.org/pdf/2505.16674v1>|利用视觉问答模型和先验知识实现零样本电池热图像异常检测。|
|📝 更新|GUI-G1: Understanding R1-Zero-Like Training for Visual Grounding in GUI Agents|GUI-G1：理解GUI代理中视觉定位的R1-Zero-like训练|Yuqi Zhou, Sunhao Dai, Shuai Wang, Kaiwen Zhou, Qinglin Jia, Jun Xu|<http://arxiv.org/pdf/2505.15810v2>|[代码](https://github.com/Yuqi-Zhou/GUI-G1.); 提出GUI-G1，通过优化输入设计、输出评估和策略更新，显著提升GUI视觉定位性能。|
|🆕 发布|Efficient Motion Prompt Learning for Robust Visual Tracking|高效运动提示学习以实现鲁棒视觉跟踪|Jie Zhao, Xin Chen, Yongsheng Yuan, Michael Felsberg, Dong Wang, Huchuan Lu|<http://arxiv.org/pdf/2505.16321v1>|[代码](https://github.com/zj5559/Motion-Prompt-Tracking.); 提出一种轻量级运动提示学习法，显著提升视觉跟踪鲁棒性。|
|🆕 发布|CT-Agent: A Multimodal-LLM Agent for 3D CT Radiology Question Answering|CT-Agent：一种多模态-LLM 3D CT 放射学问答代理|Yuren Mao, Wenyi Xu, Yuyang Qin, Yunjun Gao|<http://arxiv.org/pdf/2505.16229v1>|提出CT-Agent，一种解决CT影像复杂性和空间关系问题的多模态智能问答系统。|
|🆕 发布|VLM-R$^3$: Region Recognition, Reasoning, and Refinement for Enhanced Multimodal Chain-of-Thought|VLM-R$^3$：区域识别、推理和优化以增强多模态思维链|Chaoya Jiang, Yongrui Heng, Wei Ye, Han Yang, Haiyang Xu, Ming Yan, Ji Zhang, Fei Huang .etc.|<http://arxiv.org/pdf/2505.16192v1>|VLM-R$^3$通过区域识别、推理和细化，提升了多模态思维链的视觉证据精确性。|
|🆕 发布|Steering LVLMs via Sparse Autoencoder for Hallucination Mitigation|通过稀疏自编码器引导LVLMs以减轻幻觉|Zhenglin Hua, Jinghan He, Zijun Yao, Tianxu Han, Haiyun Guo, Yuheng Jia, Junfeng Fang|<http://arxiv.org/pdf/2505.16146v1>|利用稀疏自编码器识别语义方向，通过引导LVLMs内部表示减轻幻觉问题。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EDM: Efficient Deep Feature Matching|高效深度特征匹配：EDM|Xi Li, Tong Rao, Cihui Pan|<http://arxiv.org/pdf/2503.05122v2>|[代码](https://github.com/chicleee/EDM.); 提出了一种高效深度特征匹配网络EDM，显著提升了特征匹配的准确性和效率。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TAT-VPR: Ternary Adaptive Transformer for Dynamic and Efficient Visual Place Recognition|TAT-VPR：用于动态和高效视觉位置识别的三值自适应Transformer|Oliver Grainge, Michael Milford, Indu Bodala, Sarvapali D. Ramchurn, Shoaib Ehsan|<http://arxiv.org/pdf/2505.16447v1>|提出TAT-VPR，通过三元量化自适应变换器实现动态视觉SLAM闭环检测的高效准确平衡。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Extremely Simple Multimodal Outlier Synthesis for Out-of-Distribution Detection and Segmentation|极简多模态异常值合成用于分布外检测和分割|Moru Liu, Hao Dong, Jessica Kelly, Olga Fink, Mario Trapp|<http://arxiv.org/pdf/2505.16985v1>|[代码](https://github.com/mona4399/FeatureMixing.); 提出了一种简单快速的多模态异常样本生成方法，显著提升了机器学习模型在异常检测和分割中的性能。|
|🆕 发布|MedFrameQA: A Multi-Image Medical VQA Benchmark for Clinical Reasoning|MedFrameQA：一个用于临床推理的多图像医学视觉问答基准|Suhao Yu, Haojin Wang, Juncheng Wu, Cihang Xie, Yuyin Zhou|<http://arxiv.org/pdf/2505.16964v1>|构建了首个多图像医学视觉问答基准MedFrameQA，评估临床推理中的多图像推理能力。|
|🆕 发布|Mitigating Overfitting in Medical Imaging: Self-Supervised Pretraining vs. ImageNet Transfer Learning for Dermatological Diagnosis|减轻医学影像中的过拟合：皮肤病学诊断中自监督预训练与ImageNet迁移学习的比较|Iván Matas, Carmen Serrano, Miguel Nogales, David Moreno, Lara Ferrándiz, Teresa Ojeda, Begoña Acha|<http://arxiv.org/pdf/2505.16773v1>|该研究通过自监督预训练在皮肤病学图像诊断中减轻过拟合，优于基于ImageNet的迁移学习。|
|🆕 发布|On the use of Graphs for Satellite Image Time Series|关于卫星图像时间序列中图的应用|Corentin Dufourg, Charlotte Pelletier, Stéphane May, Sébastien Lefèvre|<http://arxiv.org/pdf/2505.16685v1>|提出了一种基于图的方法，用于分析卫星图像时间序列，以解决土地覆盖映射和水资源预测问题。|
|🆕 发布|SD-MAD: Sign-Driven Few-shot Multi-Anomaly Detection in Medical Images|SD-MAD：医学图像中的基于显著性驱动的少样本多异常检测|Kaiyu Guo, Tan Pan, Chen Jiang, Zijian Wang, Brian C. Lovell, Limei Han, Yuan Cheng, Mahsa Baktashmotlagh|<http://arxiv.org/pdf/2505.16659v1>|提出了一种基于视觉语言模型和文本描述的医学图像多异常检测框架，有效识别多种异常类别。|
|🆕 发布|Point, Detect, Count: Multi-Task Medical Image Understanding with Instruction-Tuned Vision-Language Models|点、检测、计数：基于指令调整的视觉-语言模型的多任务医学图像理解|Sushant Gautam, Michael A. Riegler, Pål Halvorsen|<http://arxiv.org/pdf/2505.16647v1>|[代码](https://github.com/simula/PointDetectCount.); 通过指令微调通用视觉语言模型，实现医学图像的多任务理解，提高诊断准确性和效率。|
|🆕 发布|Background Matters: A Cross-view Bidirectional Modeling Framework for Semi-supervised Medical Image Segmentation|背景很重要：一种跨视图双向建模框架用于半监督医学图像分割|Luyang Cao, Jianwei Li, Yinghuan Shi|<http://arxiv.org/pdf/2505.16625v1>|[代码](https://github.com/caoluyang0830/CVBM.git.); 提出了一种结合背景建模的半监督医学图像分割框架，显著提升了分割性能。|
|📝 更新|Progressive Local Alignment for Medical Multimodal Pre-training|渐进式局部对齐用于医学多模态预训练|Huimin Yan, Xian Yang, Liang Bai, Jiye Liang|<http://arxiv.org/pdf/2502.18047v2>|提出PLAN网络，通过渐进式局部对齐技术提升医学图像与文本的精准匹配。|
|🆕 发布|Auto-nnU-Net: Towards Automated Medical Image Segmentation|自动nnU-Net：迈向自动化医学图像分割|Jannis Becktepe, Leona Hennig, Steffen Oeltze-Jafra, Marius Lindauer|<http://arxiv.org/pdf/2505.16561v1>|[代码](https://github.com/LUH-AI/AutonnUNet.); 提出Auto-nnU-Net，通过自动化超参数优化和架构搜索，显著提升医学图像分割性能，同时平衡计算...|
|🆕 发布|Implicit Neural Shape Optimization for 3D High-Contrast Electrical Impedance Tomography|隐式神经网络形状优化用于3D高对比度电阻抗断层成像|Junqing Chen, Haibo Liu|<http://arxiv.org/pdf/2505.16487v1>|提出了一种结合形状优化和隐式神经网络的新框架，有效解决高对比度EIT重建难题。|
|📝 更新|Mask of truth: model sensitivity to unexpected regions of medical images|真实掩码：模型对医学图像中意外区域的敏感性|Théo Sourget, Michelle Hestbek-Møller, Amelia Jiménez-Sánchez, Jack Junchi Xu, Veronika Cheplygina|<http://arxiv.org/pdf/2412.04030v3>|[代码](https://github.com/TheoSourget/MMC_Masking); 揭示了医学图像模型对非相关区域的敏感性，并提出通过遮挡关键区域来评估模型性能。|
|📝 更新|PRS-Med: Position Reasoning Segmentation with Vision-Language Model in Medical Imaging|PRS-Med：基于视觉-语言模型的医学影像位置推理分割|Quoc-Huy Trinh, Minh-Van Nguyen, Jung Peng, Ulas Bagci, Debesh Jha|<http://arxiv.org/pdf/2505.11872v2>|PRS-Med通过结合视觉语言模型和分割能力，实现了医学图像中肿瘤的准确分割和空间推理，提升了医生与...|
|📝 更新|KAN-Mamba FusionNet: Redefining Medical Image Segmentation with Non-Linear Modeling|KAN-Mamba FusionNet：用非线性建模重新定义医学图像分割|Akansh Agrawal, Akshan Agrawal, Shashwat Gupta, Priyanka Bagade|<http://arxiv.org/pdf/2411.11926v2>|提出KAN-Mamba FusionNet，融合非线性建模与长距离依赖处理，显著提升医学图像分割准确...|
|🆕 发布|Efficient Prototype Consistency Learning in Medical Image Segmentation via Joint Uncertainty and Data Augmentation|通过联合不确定性和数据增强在医学图像分割中进行高效原型一致性学习|Lijian Li, Yuanpeng He, Chi-Man Pun|<http://arxiv.org/pdf/2505.16283v1>|提出了一种结合不确定性量化与数据增强的半监督医学图像分割方法，有效提升了原型学习的语义表达能力。|
|📝 更新|VisionPAD: A Vision-Centric Pre-training Paradigm for Autonomous Driving|视觉驾驶平台：自动驾驶中的视觉中心预训练范式|Haiming Zhang, Wending Zhou, Yiyao Zhu, Xu Yan, Jiantao Gao, Dongfeng Bai, Yingjie Cai, Bingbing Liu .etc.|<http://arxiv.org/pdf/2411.14716v2>|VisionPAD通过高效的三维高斯分层和自监督方法，显著提升了自动驾驶中的3D物体检测和地图分割性...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RealEngine: Simulating Autonomous Driving in Realistic Context|真实引擎：在真实环境中模拟自动驾驶|Junzhe Jiang, Nan Song, Jingyu Li, Xiatian Zhu, Li Zhang|<http://arxiv.org/pdf/2505.16902v1>|提出RealEngine，通过3D场景重建和视图合成技术，实现真实灵活的自动驾驶模拟。|
|🆕 发布|Representation Discrepancy Bridging Method for Remote Sensing Image-Text Retrieval|遥感图像-文本检索中的表示差异桥接方法|Hailong Ning, Siying Wang, Tao Lei, Xiaopeng Cao, Huanmin Dou, Bin Zhao, Asoke K. Nandi, Petia Radeva|<http://arxiv.org/pdf/2505.16756v1>|提出RDB方法解决遥感图像-文本检索中模态不平衡问题，通过不对称适配器和双任务优化框架提升检索性能。|
|📝 更新|Copy-Move Forgery Detection and Question Answering for Remote Sensing Image|遥感图像的复制-移动伪造检测与问答|Ze Zhang, Enyuan Zhao, Di Niu, Jie Nie, Xinyue Liang, Lei Huang|<http://arxiv.org/pdf/2412.02575v2>|[代码](https://github.com/shenyedepisa/RSCMQA.); 提出RSCMQA任务，构建多模态数据集，并设计CMFPF框架，提升遥感图像篡改检测与问答准确度。|
|🆕 发布|Raw2Drive: Reinforcement Learning with Aligned World Models for End-to-End Autonomous Driving (in CARLA v2)|原始2驾驶：使用对齐世界模型的强化学习实现端到端自动驾驶（在CARLA v2中）|Zhenjie Yang, Xiaosong Jia, Qifeng Li, Xue Yang, Maoqing Yao, Junchi Yan|<http://arxiv.org/pdf/2505.16394v1>|设计Raw2Drive，通过结合辅助世界模型和原始传感器世界模型，实现端到端自动驾驶的强化学习。|
|📝 更新|Efficient Feature Fusion for UAV Object Detection|高效特征融合用于无人机目标检测|Xudong Wang, Yaxin Peng, Chaomin Shen|<http://arxiv.org/pdf/2501.17983v3>|提出了一种针对无人机目标检测的特征融合框架，有效提升了小目标的定位精度和分类性能。|
|📝 更新|Consistent Quantity-Quality Control across Scenes for Deployment-Aware Gaussian Splatting|场景间一致性数量-质量控制，以适应部署感知高斯分层|Fengdi Zhang, Hongkun Cao, Ruqi Huang|<http://arxiv.org/pdf/2505.10473v2>|[代码](https://zhang-fengdi.github.io/ControlGS); 提出ControlGS方法，实现3D场景中量质平衡的自动调整，优化渲染质量与计算效率。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving|SOLVE：自动驾驶中的语言-视觉协同与端到端网络|Xuesong Chen, Linjiang Huang, Tao Ma, Rongyao Fang, Shaoshuai Shi, Hongsheng Li|<http://arxiv.org/pdf/2505.16805v1>|SOLVE通过融合视觉语言模型与端到端网络，有效提升了自动驾驶轨迹预测的准确性和实时性。|
|🆕 发布|DriveMoE: Mixture-of-Experts for Vision-Language-Action Model in End-to-End Autonomous Driving|驱动MoE：端到端自动驾驶中的视觉-语言-动作模型混合专家|Zhenjie Yang, Yilin Chai, Xiaosong Jia, Qifeng Li, Yuqian Shao, Xuekai Zhu, Haisheng Su, Junchi Yan|<http://arxiv.org/pdf/2505.16278v1>|提出DriveMoE，通过结合视觉和动作MoE，有效提升自动驾驶场景处理能力。|
|🆕 发布|A Causal Approach to Mitigate Modality Preference Bias in Medical Visual Question Answering|因果方法减轻医学视觉问答中的模态偏好偏差|Shuchang Ye, Usman Naseem, Mingyuan Meng, Dagan Feng, Jinman Kim|<http://arxiv.org/pdf/2505.16209v1>|提出了一种基于因果图和反事实学习的医疗视觉问答模型，有效缓解了模态偏好偏差。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Zero-Shot Hyperspectral Pansharpening Using Hysteresis-Based Tuning for Spectral Quality Control|基于滞回调谐的零样本高光谱全色融合用于光谱质量控制|Giuseppe Guarino, Matteo Ciotola, Gemine Vivone, Giovanni Poggi, Giuseppe Scarpa|<http://arxiv.org/pdf/2505.16658v1>|[代码](https://github.com/giu-guarino/rho-PNN.); 提出了一种基于自适应权重和动态调整的轻量级神经网络，有效解决了高光谱图像融合中的光谱质量不均问题。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving|AgentThink：用于自动驾驶视觉-语言模型的工具辅助思维链推理的统一框架|Kangan Qian, Sicong Jiang, Yang Zhong, Ziang Luo, Zilin Huang, Tianze Zhu, Kun Jiang, Mengmeng Yang .etc.|<http://arxiv.org/pdf/2505.15298v2>|AgentThink通过整合思维链推理和动态工具调用，显著提升了视觉语言模型在自动驾驶中的推理准确性...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AnchorFormer: Differentiable Anchor Attention for Efficient Vision Transformer|锚前驱器：用于高效视觉变换器的可微分锚注意力|Jiquan Shan, Junxiao Wang, Lifeng Zhao, Liang Cai, Hongyuan Zhang, Ioannis Liritzis|<http://arxiv.org/pdf/2505.16463v1>|引入锚点注意力机制，提升视觉Transformer效率，实现高效图像识别。|


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Praxis-VLM: Vision-Grounded Decision Making via Text-Driven Reinforcement Learning|实践-视觉语言模型：基于文本驱动的强化学习进行视觉基础决策|Zhe Hu, Jing Li, Zhongzhu Pu, Hou Pong Chan, Yu Yin|<http://arxiv.org/pdf/2503.16965v2>|提出Praxis-VLM，通过文本驱动强化学习实现视觉场景的决策推理，显著提升决策性能和泛化能力。|


### 可解释视觉智能 (Explainable Visual Intelligence)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GDI-Bench: A Benchmark for General Document Intelligence with Vision and Reasoning Decoupling|GDI-Bench：一种具有视觉与推理解耦的通用文档智能基准|Siqi Li, Yufan Shen, Xiangnan Chen, Jiayi Chen, Hengwei Ju, Haodong Duan, Song Mao, Hongbin Zhou .etc.|<http://arxiv.org/pdf/2505.00063v2>|提出GDI-Bench基准，通过视觉与推理解耦评估文档智能模型，并提出GDI-Model以优化模型性...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Seeing through Satellite Images at Street Views|透过卫星图像看街景|Ming Qian, Bin Tan, Qiuyu Wang, Xianwei Zheng, Hanjiang Xiong, Gui-Song Xia, Yujun Shen, Nan Xue|<http://arxiv.org/pdf/2505.17001v1>|提出Sat2Density++方法，通过神经网络模型渲染卫星图像至逼真街景全景。|
|🆕 发布|PAEFF: Precise Alignment and Enhanced Gated Feature Fusion for Face-Voice Association|PAEFF：精确对齐与增强门控特征融合的人脸-语音关联|Abdul Hannan, Muhammad Arslan Manzoor, Shah Nawaz, Muhammad Irzam Liaqat, Markus Schedl, Mubashir Noman|<http://arxiv.org/pdf/2505.17002v1>|提出了一种精确对齐和增强门控特征融合方法，有效提升了人脸语音关联性能。|
|📝 更新|Relative-Interior Solution for the (Incomplete) Linear Assignment Problem with Applications to the Quadratic Assignment Problem|相对内部解法在（不完整）线性指派问题中的应用及其在二次指派问题中的应用|Tomáš Dlask, Bogdan Savchynskyy|<http://arxiv.org/pdf/2301.11201v4>|提出了一种从线性指派问题相对内部求解最优解的方法，并应用于二次指派问题求解。|
|📝 更新|GOTPR: General Outdoor Text-based Place Recognition Using Scene Graph Retrieval with OpenStreetMap|GOTPR：基于场景图检索和OpenStreetMap的通用户外文本化地点识别|Donghwi Jung, Keonwoo Kim, Seong-Woo Kim|<http://arxiv.org/pdf/2501.08575v2>|[代码](https://donghwijung.github.io/GOTPR_page); 提出了一种利用场景图和OpenStreetMap进行室外地点识别的方法，有效降低存储需求并提高识别效...|
|🆕 发布|CodeMerge: Codebook-Guided Model Merging for Robust Test-Time Adaptation in Autonomous Driving|代码合并：自动驾驶中鲁棒测试时自适应的代码簿引导模型合并|Huitong Yang, Zhuoxiao Chen, Fengyi Zhang, Zi Huang, Yadan Luo|<http://arxiv.org/pdf/2505.16524v1>|CodeMerge通过在紧凑的潜在空间中构建代码簿，实现了轻量级且可扩展的模型合并，有效提升了自动驾...|

