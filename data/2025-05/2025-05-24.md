## [UPDATED!] **2025-05-24** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SD-OVON: A Semantics-aware Dataset and Benchmark Generation Pipeline for Open-Vocabulary Object Navigation in Dynamic Scenes|SD-OVONï¼šåŠ¨æ€åœºæ™¯ä¸­å¼€æ”¾è¯æ±‡ç‰©ä½“å¯¼èˆªçš„è¯­ä¹‰æ„ŸçŸ¥æ•°æ®é›†å’ŒåŸºå‡†ç”Ÿæˆç®¡é“|Dicong Qiu, Jiadi You, Zeying Gong, Ronghe Qiu, Hui Xiong, Junwei Liang|<http://arxiv.org/pdf/2505.18881v1>|æå‡ºSD-OVONï¼Œä¸ºåŠ¨æ€åœºæ™¯ä¸­çš„å¼€æ”¾è¯æ±‡ç‰©ä½“å¯¼èˆªæ„å»ºè¯­ä¹‰æ„ŸçŸ¥æ•°æ®é›†å’ŒåŸºå‡†ç”Ÿæˆæµç¨‹ã€‚|
|ğŸ†• å‘å¸ƒ|Inference Compute-Optimal Video Vision Language Models|æ¨ç†è®¡ç®—æœ€ä¼˜è§†é¢‘è§†è§‰è¯­è¨€æ¨¡å‹|Peiqi Wang, ShengYun Peng, Xuewen Zhang, Hanchao Yu, Yibo Yang, Lifu Huang, Fujun Liu, Qifan Wang|<http://arxiv.org/pdf/2505.18855v1>|è¯¥è®ºæ–‡é€šè¿‡ä¼˜åŒ–è®¡ç®—èµ„æºåˆ†é…ï¼Œæ­ç¤ºäº†è§†é¢‘è§†è§‰è¯­è¨€æ¨¡å‹ä¸­è¯­è¨€æ¨¡å‹å¤§å°ã€å¸§æ•°å’Œè§†è§‰æ ‡è®°æ•°é‡çš„æœ€ä½³é…ç½®ã€‚|
|ğŸ“ æ›´æ–°|Pixels2Points: Fusing 2D and 3D Features for Facial Skin Segmentation|åƒç´ åˆ°ç‚¹ï¼šèåˆäºŒç»´å’Œä¸‰ç»´ç‰¹å¾è¿›è¡Œé¢éƒ¨çš®è‚¤åˆ†å‰²|Victoria Yue Chen, Daoye Wang, Stephan Garbin, Jan Bednarik, Sebastian Winberg, Timo Bolkart, Thabo Beeler|<http://arxiv.org/pdf/2504.19718v3>|èåˆ2Då’Œ3Dç‰¹å¾ï¼Œå®ç°3Däººè„¸æ‰«æçš®è‚¤åŒºåŸŸå‡†ç¡®åˆ†å‰²ã€‚|
|ğŸ†• å‘å¸ƒ|Reinforcement Fine-Tuning Powers Reasoning Capability of Multimodal Large Language Models|å¼ºåŒ–å¾®è°ƒæå‡å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›|Haoyuan Sun, Jiaqi Wu, Bo Xia, Yifu Luo, Yifei Zhao, Kai Qin, Xufei Lv, Tiantian Zhang .etc.|<http://arxiv.org/pdf/2505.18536v1>|[ä»£ç ](https://github.com/Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs.); é€šè¿‡å¼ºåŒ–å¾®è°ƒæå‡å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|BiomechGPT: Towards a Biomechanically Fluent Multimodal Foundation Model for Clinically Relevant Motion Tasks|ç”Ÿç‰©åŠ›å­¦GPTï¼šè¿ˆå‘ä¸´åºŠç›¸å…³è¿åŠ¨ä»»åŠ¡çš„ç”Ÿç‰©åŠ›å­¦æµç•…å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹|Ruize Yang, Ann Kennedy, R. James Cotton|<http://arxiv.org/pdf/2505.18465v1>|å¼€å‘äº†ä¸€ç§åŸºäºè¯­è¨€æ¨¡å‹çš„ç”Ÿç‰©åŠ›å­¦æ•°æ®åˆ†æå·¥å…·ï¼Œæœ‰æ•ˆæå‡ä¸´åºŠè¿åŠ¨ä»»åŠ¡åˆ†æèƒ½åŠ›ã€‚|


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|SCHEME: Scalable Channel Mixer for Vision Transformers|æ–¹æ¡ˆï¼šå¯æ‰©å±•çš„è§†è§‰Transformeré€šé“æ··åˆå™¨|Deepak Sridhar, Yunsheng Li, Nuno Vasconcelos|<http://arxiv.org/pdf/2312.00412v4>|æå‡ºSCHEMEï¼Œä¸€ç§é«˜æ•ˆå¯æ‰©å±•çš„é€šé“æ··åˆå™¨ï¼Œæ˜¾è‘—æå‡è§†è§‰Transformeræ¨¡å‹æ€§èƒ½ã€‚|


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|OpenOmni: Advancing Open-Source Omnimodal Large Language Models with Progressive Multimodal Alignment and Real-Time Self-Aware Emotional Speech Synthesis|OpenOmniï¼šé€šè¿‡æ¸è¿›å¼å¤šæ¨¡æ€å¯¹é½å’Œå®æ—¶è‡ªæˆ‘æ„ŸçŸ¥æƒ…æ„Ÿè¯­éŸ³åˆæˆæ¨è¿›å¼€æºå…¨æ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹|Run Luo, Ting-En Lin, Haonan Zhang, Yuchuan Wu, Xiong Liu, Min Yang, Yongbin Li, Longze Chen .etc.|<http://arxiv.org/pdf/2501.04561v5>|æå‡ºOpenOmniï¼Œé€šè¿‡æ¸è¿›å¼å¤šæ¨¡æ€å¯¹é½å’Œå®æ—¶æƒ…æ„Ÿè¯­éŸ³åˆæˆï¼Œçªç ´å¼€æºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„æŠ€æœ¯ç“¶é¢ˆã€‚|


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### è¯­ä¹‰/å®ä¾‹åˆ†å‰² (Semantic/Instance Segmentation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Unsupervised cell segmentation by fast Gaussian Processes|æ— ç›‘ç£ç»†èƒåˆ†å‰²ï¼šå¿«é€Ÿé«˜æ–¯è¿‡ç¨‹|Laura Baracaldo, Blythe King, Haoran Yan, Yizi Lin, Nina Miolane, Mengyang Gu|<http://arxiv.org/pdf/2505.18902v1>|å¼€å‘äº†ä¸€ç§åŸºäºå¿«é€Ÿé«˜æ–¯è¿‡ç¨‹çš„æ— éœ€å‚æ•°è°ƒæ•´çš„æ— ç›‘ç£ç»†èƒåˆ†å‰²ç®—æ³•ï¼Œæœ‰æ•ˆæé«˜äº†ç»†èƒåˆ†å‰²çš„å‡†ç¡®æ€§å’Œå¯æ‰©å±•æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Reasoning Segmentation for Images and Videos: A Survey|å›¾åƒä¸è§†é¢‘çš„æ¨ç†åˆ†å‰²ï¼šç»¼è¿°|Yiqing Shen, Chenjia Li, Fei Xiong, Jeong-O Jeong, Tianpeng Wang, Michael Latman, Mathias Unberath|<http://arxiv.org/pdf/2505.18816v1>|é¦–æ¬¡å…¨é¢ç»¼è¿°äº†åŸºäºæ¨ç†çš„å›¾åƒå’Œè§†é¢‘åˆ†å‰²æ–¹æ³•ï¼Œæ¨åŠ¨è‡ªç„¶è¯­è¨€ä¸è§†è§‰æ„ŸçŸ¥èåˆã€‚|


### ç›®æ ‡æ£€æµ‹ä¸å®šä½ (Object Detection & Localization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Deep Learning for Breast Cancer Detection: Comparative Analysis of ConvNeXT and EfficientNet|æ·±åº¦å­¦ä¹ åœ¨ä¹³è…ºç™Œæ£€æµ‹ä¸­çš„åº”ç”¨ï¼šConvNeXTä¸EfficientNetçš„å¯¹æ¯”åˆ†æ|Mahmudul Hasan|<http://arxiv.org/pdf/2505.18725v1>|æ¯”è¾ƒConvNeXTå’ŒEfficientNetåœ¨ä¹³è…ºé’¼é¶å›¾åƒä¸­é¢„æµ‹ç™Œç—‡é£é™©ï¼ŒConvNeXTæ¨¡å‹è¡¨ç°...|
|ğŸ“ æ›´æ–°|DitHub: A Modular Framework for Incremental Open-Vocabulary Object Detection|DitHubï¼šä¸€ä¸ªç”¨äºå¢é‡å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹çš„æ¨¡å—åŒ–æ¡†æ¶|Chiara Cappellino, Gianluca Mancusi, Matteo Mosconi, Angelo Porrello, Simone Calderara, Rita Cucchiara|<http://arxiv.org/pdf/2503.09271v2>|[ä»£ç ](https://aimagelab.github.io/DitHub); æå‡ºDitHubæ¡†æ¶ï¼Œé€šè¿‡æ¨¡å—åŒ–æ–¹æ³•å®ç°å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹çš„å¢é‡é€‚åº”ï¼Œæ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|ASGrasp: Generalizable Transparent Object Reconstruction and 6-DoF Grasp Detection from RGB-D Active Stereo Camera|ASGraspï¼šé€šç”¨é€æ˜ç‰©ä½“é‡å»ºä¸6è‡ªç”±åº¦æŠ“å–æ£€æµ‹çš„RGB-Dä¸»åŠ¨ç«‹ä½“ç›¸æœº|Jun Shi, Yong A, Yixiang Jin, Dingzhe Li, Haoyu Niu, Zhezhu Jin, He Wang|<http://arxiv.org/pdf/2405.05648v2>|[ä»£ç ](https://pku-epic.github.io/ASGrasp); æå‡ºASGraspï¼Œé€šè¿‡RGB-Dç›¸æœºå®ç°é€æ˜ç‰©ä½“é‡å»ºå’Œ6è‡ªç”±åº¦æŠ“å–æ£€æµ‹ï¼Œçªç ´æ·±åº¦ç›¸æœºåœ¨é€æ˜ç‰©ä½“å‡ ä½•...|
|ğŸ†• å‘å¸ƒ|Mitigating Context Bias in Domain Adaptation for Object Detection using Mask Pooling|ç¼“è§£åŸŸé€‚åº”ä¸­ç›®æ ‡æ£€æµ‹çš„ä¸Šä¸‹æ–‡åå·®ï¼šä½¿ç”¨æ©ç æ± åŒ–|Hojun Son, Asma Almutairi, Arpan Kusari|<http://arxiv.org/pdf/2505.18446v1>|é€šè¿‡å¼•å…¥Mask Poolingï¼Œè¯¥è®ºæ–‡æœ‰æ•ˆç¼“è§£äº†åŸŸé€‚åº”ç›®æ ‡æ£€æµ‹ä¸­çš„ä¸Šä¸‹æ–‡åå·®é—®é¢˜ã€‚|
|ğŸ“ æ›´æ–°|IGL-DT: Iterative Global-Local Feature Learning with Dual-Teacher Semantic Segmentation Framework under Limited Annotation Scheme|IGL-DTï¼šåœ¨æœ‰é™æ ‡æ³¨æ–¹æ¡ˆä¸‹ï¼ŒåŸºäºåŒé‡æ•™å¸ˆè¯­ä¹‰åˆ†å‰²æ¡†æ¶çš„è¿­ä»£å…¨å±€-å±€éƒ¨ç‰¹å¾å­¦ä¹ æ–¹æ³•|Dinh Dai Quan Tran, Hoang-Thien Nguyen, Thanh-Huy Nguyen, Gia-Van To, Tien-Huy Nguyen, Quan Nguyen|<http://arxiv.org/pdf/2504.09797v2>|IGL-DTé€šè¿‡ç»“åˆåŒæ•™å¸ˆç­–ç•¥å’Œè¿­ä»£å…¨å±€-å±€éƒ¨ç‰¹å¾å­¦ä¹ ï¼Œæœ‰æ•ˆæå‡äº†åŠç›‘ç£è¯­ä¹‰åˆ†å‰²çš„å‡†ç¡®æ€§ã€‚|


### å›¾åƒåˆ†ç±»ä¸è¯†åˆ« (Image Classification & Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SerendibCoins: Exploring The Sri Lankan Coins Dataset|æ–¯é‡Œå…°å¡ç¡¬å¸æ•°æ®é›†æ¢ç´¢ï¼šSerendibCoins|NH Wanigasingha, ES Sithpahan, MKA Ariyaratne, PRS De Silva|<http://arxiv.org/pdf/2505.18634v1>|æ„å»ºäº†æ–¯é‡Œå…°å¡ç¡¬å¸æ•°æ®é›†ï¼Œå¹¶éªŒè¯äº†CNNåœ¨ç¡¬å¸åˆ†ç±»ä¸­çš„ä¼˜è¶Šæ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Guiding the Experts: Semantic Priors for Efficient and Focused MoE Routing|å¼•å¯¼ä¸“å®¶ï¼šé«˜æ•ˆä¸”ä¸“æ³¨çš„MoEè·¯ç”±çš„è¯­ä¹‰å…ˆéªŒ|Chengxi Min, Wei Wang, Yahui Liu, Weixin Ye, Enver Sangineto, Qi Wang, Yao Zhao|<http://arxiv.org/pdf/2505.18586v1>|æå‡ºäº†ä¸€ç§åŸºäºè¯­ä¹‰å…ˆéªŒçš„MoEè·¯ç”±å¢å¼ºç­–ç•¥ï¼Œæ˜¾è‘—æå‡äº†ä¸“å®¶è·¯ç”±æ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½ã€‚|


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Tropical Geometry Based Edge Detection Using Min-Plus and Max-Plus Algebra|åŸºäºçƒ­å¸¦å‡ ä½•çš„è¾¹ç¼˜æ£€æµ‹ï¼šä½¿ç”¨æœ€å°-åŠ å’Œæœ€å¤§-åŠ ä»£æ•°|Shivam Kumar Jha S, Jaya NN Iyer|<http://arxiv.org/pdf/2505.18625v1>|æå‡ºäº†ä¸€ç§åŸºäºçƒ­å¸¦å‡ ä½•çš„è¾¹ç¼˜æ£€æµ‹æ–¹æ³•ï¼Œåˆ©ç”¨æœ€å°-åŠ å’Œæœ€å¤§-åŠ ä»£æ•°æ”¹è¿›è¾¹ç¼˜æ¸…æ™°åº¦å’Œè¿ç»­æ€§ã€‚|


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity|LinGenï¼šè¿ˆå‘å…·æœ‰çº¿æ€§è®¡ç®—å¤æ‚åº¦çš„é«˜åˆ†è¾¨ç‡åˆ†é’Ÿçº§æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆ|Hongjie Wang, Chih-Yao Ma, Yen-Cheng Liu, Ji Hou, Tao Xu, Jialiang Wang, Felix Juefei-Xu, Yaqiao Luo .etc.|<http://arxiv.org/pdf/2412.09856v2>|[ä»£ç ](https://lineargen.github.io/.); LinGené€šè¿‡çº¿æ€§å¤æ‚åº¦è®¡ç®—å®ç°é«˜åˆ†è¾¨ç‡çŸ­æ—¶è§†é¢‘ç”Ÿæˆï¼Œæ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬å¹¶æå‡è§†é¢‘è´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|Localizing Knowledge in Diffusion Transformers|åœ¨æ‰©æ•£Transformerä¸­å®šä½çŸ¥è¯†|Arman Zarei, Samyadeep Basu, Keivan Rezaei, Zihao Lin, Sayan Nag, Soheil Feizi|<http://arxiv.org/pdf/2505.18832v1>|æå‡ºäº†ä¸€ç§å®šä½æ‰©æ•£Transformerä¸­çŸ¥è¯†çš„æ–¹æ³•ï¼Œä»¥æå‡æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œå¯æ§æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|StyleGuard: Preventing Text-to-Image-Model-based Style Mimicry Attacks by Style Perturbations|é£æ ¼å®ˆæŠ¤ï¼šé€šè¿‡é£æ ¼æ‰°åŠ¨é¢„é˜²åŸºäºæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„é£è²Œæ¨¡ä»¿æ”»å‡»|Yanjie Li, Wenxuan Zhang, Xinqi Lyu, Yihao Liu, Bin Xiao|<http://arxiv.org/pdf/2505.18766v1>|StyleGuardé€šè¿‡é£æ ¼æ‰°åŠ¨å’Œå‡çº§æŸå¤±ï¼Œæœ‰æ•ˆé˜²å¾¡äº†åŸºäºæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„é£æ ¼æ¨¡ä»¿æ”»å‡»ã€‚|


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Sparse VideoGen2: Accelerate Video Generation with Sparse Attention via Semantic-Aware Permutation|ç¨€ç–VideoGen2ï¼šé€šè¿‡è¯­ä¹‰æ„ŸçŸ¥æ’åˆ—çš„ç¨€ç–æ³¨æ„åŠ›åŠ é€Ÿè§†é¢‘ç”Ÿæˆ|Shuo Yang, Haocheng Xi, Yilong Zhao, Muyang Li, Jintao Zhang, Han Cai, Yujun Lin, Xiuyu Li .etc.|<http://arxiv.org/pdf/2505.18875v1>|SVG2é€šè¿‡è¯­ä¹‰æ„ŸçŸ¥æ’åˆ—å’Œç¨€ç–æ³¨æ„åŠ›ï¼Œæœ‰æ•ˆæå‡äº†è§†é¢‘ç”Ÿæˆé€Ÿåº¦å’Œè´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|Eye-See-You: Reverse Pass-Through VR and Head Avatars|çœ¼è§ä¸ºå®ï¼šåå‘ä¼ é€’VRä¸å¤´éƒ¨è™šæ‹Ÿå½¢è±¡|Ankan Dash, Jingyi Gu, Guiling Wang, Chen Chen|<http://arxiv.org/pdf/2505.18869v1>|æå‡ºRevAvataræ¡†æ¶ï¼Œåˆ©ç”¨AIæŠ€æœ¯å®ç°VRåå‘é€è§†ï¼Œè§£å†³VRå¤´æ˜¾é®æŒ¡é—®é¢˜ï¼Œæå‡è™šæ‹Ÿç¯å¢ƒäº¤äº’ä½“éªŒ...|
|ğŸ†• å‘å¸ƒ|REGen: Multimodal Retrieval-Embedded Generation for Long-to-Short Video Editing|REGenï¼šé•¿è§†é¢‘åˆ°çŸ­è§†é¢‘çš„å¤šæ¨¡æ€æ£€ç´¢åµŒå…¥ç”Ÿæˆ|Weihan Xu, Yimeng Ma, Jingyue Huang, Yang Li, Wenye Ma, Taylor Berg-Kirkpatrick, Julian McAuley, Paul Pu Liang .etc.|<http://arxiv.org/pdf/2505.18880v1>|æå‡ºREGenæ¨¡å‹ï¼Œé€šè¿‡æ£€ç´¢åµŒå…¥ç”ŸæˆæŠ€æœ¯ï¼Œå®ç°é•¿è§†é¢‘åˆ°çŸ­è§†é¢‘çš„è¿è´¯ç¼–è¾‘ï¼Œæœ‰æ•ˆæ’å…¥è§†é¢‘ç‰‡æ®µã€‚|
|ğŸ†• å‘å¸ƒ|OmniGenBench: A Benchmark for Omnipotent Multimodal Generation across 50+ Tasks|å…¨èƒ½åŠ›å¤šæ¨¡æ€ç”ŸæˆåŸºå‡†ï¼š50+ä»»åŠ¡è¯„æµ‹|Jiayu Wang, Yang Jiao, Yue Yu, Tianwen Qian, Shaoxiang Chen, Jingjing Chen, Yu-Gang Jiang|<http://arxiv.org/pdf/2505.18775v1>|[ä»£ç ](https://github.com/emilia113/OmniGenBench.); OmniGenBenchæ„å»ºäº†ä¸€ä¸ªå…¨é¢åŸºå‡†ï¼Œè¯„ä¼°å¤šæ¨¡æ€æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆä¸­çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|VORTA: Efficient Video Diffusion via Routing Sparse Attention|VORTAï¼šé€šè¿‡è·¯ç”±ç¨€ç–æ³¨æ„åŠ›å®ç°é«˜æ•ˆè§†é¢‘æ‰©æ•£|Wenhao Sun, Rong-Cheng Tu, Yifu Ding, Zhao Jin, Jingyi Liao, Shunyu Liu, Dacheng Tao|<http://arxiv.org/pdf/2505.18809v1>|VORTAé€šè¿‡ç¨€ç–æ³¨æ„åŠ›å’Œè·¯ç”±ç­–ç•¥ï¼Œæœ‰æ•ˆåŠ é€Ÿè§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œå®ç°é«˜æ•ˆè§†é¢‘ç”Ÿæˆã€‚|
|ğŸ†• å‘å¸ƒ|Dual-Path Stable Soft Prompt Generation for Domain Generalization|åŒè·¯å¾„ç¨³å®šè½¯æç¤ºç”Ÿæˆä»¥å®ç°é¢†åŸŸæ³›åŒ–|Yuedi Zhang, Shuanghao Bai, Wanqi Zhou, Zhirong Luan, Badong Chen|<http://arxiv.org/pdf/2505.18770v1>|æå‡ºDPSPGæ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥è´Ÿå­¦ä¹ è§£å†³é¢†åŸŸæ³›åŒ–ä¸­æç¤ºç”Ÿæˆçš„ä¸ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›ä¸è¶³é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|C3R: Channel Conditioned Cell Representations for unified evaluation in microscopy imaging|C3Rï¼šç”¨äºæ˜¾å¾®é•œæˆåƒç»Ÿä¸€è¯„ä¼°çš„é€šé“æ¡ä»¶ç»†èƒè¡¨ç¤º|Umar Marikkar, Syed Sameed Husain, Muhammad Awais, Sara Atito|<http://arxiv.org/pdf/2505.18745v1>|æå‡ºC3Ræ¡†æ¶ï¼Œé€šè¿‡é€šé“æ¡ä»¶åŒ–ç»†èƒè¡¨ç¤ºå®ç°æ˜¾å¾®é•œå›¾åƒçš„ç»Ÿä¸€è¯„ä¼°å’Œè·¨æ•°æ®é›†æ³›åŒ–ã€‚|
|ğŸ†• å‘å¸ƒ|Align Beyond Prompts: Evaluating World Knowledge Alignment in Text-to-Image Generation|è¶…è¶Šæç¤ºçš„æ ¡å‡†ï¼šè¯„ä¼°æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„ä¸–ç•ŒçŸ¥è¯†å¯¹é½|Wenchao Zhang, Jiahe Tian, Runze He, Jizhong Han, Jiao Dai, Miaomiao Feng, Wei Mi, Xiaodan Zhang|<http://arxiv.org/pdf/2505.18730v1>|[ä»£ç ](https://github.com/smile365317/ABP.); æå‡ºABPåŸºå‡†å’ŒABPScoreæŒ‡æ ‡ï¼Œè¯„ä¼°T2Iæ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒä¸è¶…æç¤ºä¸–ç•ŒçŸ¥è¯†å¯¹é½æ–¹é¢çš„èƒ½åŠ›ã€‚|
|ğŸ“ æ›´æ–°|Exploring the Limits of Vision-Language-Action Manipulations in Cross-task Generalization|æ¢ç´¢è·¨ä»»åŠ¡æ³›åŒ–ä¸­è§†è§‰-è¯­è¨€-åŠ¨ä½œæ“ä½œçš„æé™|Jiaming Zhou, Ke Ye, Jiayi Liu, Teli Ma, Zifan Wang, Ronghe Qiu, Kun-Yu Lin, Zhilin Zhao .etc.|<http://arxiv.org/pdf/2505.15660v2>|è®¾è®¡AGNOSTOSåŸºå‡†å’ŒX-ICMæ–¹æ³•ï¼Œæå‡VLAæ¨¡å‹åœ¨æœªçŸ¥ä»»åŠ¡ä¸Šçš„è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|Affective Image Editing: Shaping Emotional Factors via Text Descriptions|æƒ…æ„Ÿå›¾åƒç¼–è¾‘ï¼šé€šè¿‡æ–‡æœ¬æè¿°å¡‘é€ æƒ…æ„Ÿå› ç´ |Peixuan Zhang, Shuchen Weng, Chengxuan Zhu, Binghao Tang, Zijian Jia, Si Li, Boxin Shi|<http://arxiv.org/pdf/2505.18699v1>|æå‡ºAIEdiTï¼Œé€šè¿‡æ–‡æœ¬æè¿°å¡‘é€ å›¾åƒæƒ…æ„Ÿï¼Œå®ç°ç”¨æˆ·æƒ…æ„Ÿéœ€æ±‚çš„å›¾åƒç¼–è¾‘ã€‚|
|ğŸ†• å‘å¸ƒ|Manifold-aware Representation Learning for Degradation-agnostic Image Restoration|åŸºäºæµå½¢çš„é€€åŒ–æ— å…³å›¾åƒæ¢å¤è¡¨ç¤ºå­¦ä¹ |Bin Ren, Yawei Li, Xu Zheng, Yuqian Fu, Danda Pani Paudel, Ming-Hsuan Yang, Luc Van Gool, Nicu Sebe|<http://arxiv.org/pdf/2505.18679v1>|[ä»£ç ](https://amazingren.github.io/MIRAGE); MIRAGEé€šè¿‡åˆ†è§£ç‰¹å¾ç©ºé—´å’Œè·¨å±‚å¯¹æ¯”å­¦ä¹ ï¼Œå®ç°äº†å¯¹å¤šç§é€€åŒ–å›¾åƒçš„é²æ£’ä¿®å¤ã€‚|
|ğŸ†• å‘å¸ƒ|ChartGalaxy: A Dataset for Infographic Chart Understanding and Generation|å›¾è¡¨é“¶æ²³ï¼šä¿¡æ¯å›¾è¡¨ç†è§£å’Œç”Ÿæˆæ•°æ®é›†|Zhen Li, Yukai Guo, Duan Li, Xinyuan Guo, Bowen Li, Lanxi Xiao, Shenyu Qiao, Jiashu Chen .etc.|<http://arxiv.org/pdf/2505.18668v1>|æ„å»ºChartGalaxyæ•°æ®é›†ï¼Œæå‡å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹å¯¹ä¿¡æ¯å›¾è¡¨çš„ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|Mod-Adapter: Tuning-Free and Versatile Multi-concept Personalization via Modulation Adapter|æ¨¡é€‚é…å™¨ï¼šæ— éœ€è°ƒä¼˜ä¸”é€šç”¨çš„å¤šæ¦‚å¿µä¸ªæ€§åŒ–é€šè¿‡è°ƒåˆ¶é€‚é…å™¨|Weizhi Zhong, Huan Yang, Zheng Liu, Huiguo He, Zijian He, Xuesong Niu, Di Zhang, Guanbin Li|<http://arxiv.org/pdf/2505.18612v1>|æå‡ºäº†ä¸€ç§æ— éœ€å¾®è°ƒçš„å¤šæ¦‚å¿µä¸ªæ€§åŒ–ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡è°ƒåˆ¶é€‚é…å™¨å®ç°æŠ½è±¡å’Œç‰©ä½“æ¦‚å¿µçš„å®šåˆ¶ã€‚|
|ğŸ†• å‘å¸ƒ|Improved Immiscible Diffusion: Accelerate Diffusion Training by Reducing Its Miscibility|æ”¹è¿›ä¸ç›¸å®¹æ‰©æ•£ï¼šé€šè¿‡é™ä½å…¶ç›¸å®¹æ€§æ¥åŠ é€Ÿæ‰©æ•£è®­ç»ƒ|Yiheng Li, Feng Liang, Dan Kondratyuk, Masayoshi Tomizuka, Kurt Keutzer, Chenfeng Xu|<http://arxiv.org/pdf/2505.18521v1>|[ä»£ç ](https://github.com/yhli123/Immiscible-Diffusion.); é€šè¿‡é™ä½æ‰©æ•£æ¨¡å‹ä¸­å™ªå£°ç©ºé—´çš„æ··åˆåº¦ï¼Œè¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŠ é€Ÿæ‰©æ•£è®­ç»ƒçš„æ–°æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†è®­ç»ƒæ•ˆç‡ã€‚|
|ğŸ“ æ›´æ–°|LiDAR-EDIT: LiDAR Data Generation by Editing the Object Layouts in Real-World Scenes|LiDAR-EDITï¼šé€šè¿‡ç¼–è¾‘çœŸå®åœºæ™¯ä¸­çš„ç‰©ä½“å¸ƒå±€ç”Ÿæˆæ¿€å…‰é›·è¾¾æ•°æ®|Shing-Hei Ho, Bao Thach, Minghan Zhu|<http://arxiv.org/pdf/2412.00592v3>|LiDAR-EDITé€šè¿‡ç¼–è¾‘çœŸå®åœºæ™¯ä¸­çš„ç‰©ä½“å¸ƒå±€ç”Ÿæˆåˆæˆæ¿€å…‰é›·è¾¾æ•°æ®ï¼Œå®ç°åœºæ™¯å¯æ§ä¸”ä¿æŒèƒŒæ™¯çœŸå®ã€‚|
|ğŸ“ æ›´æ–°|OneDiff: A Generalist Model for Image Difference Captioning|OneDiffï¼šä¸€ç§ç”¨äºå›¾åƒå·®å¼‚æè¿°çš„é€šç”¨æ¨¡å‹|Erdong Hu, Longteng Guo, Tongtian Yue, Zijia Zhao, Shuning Xue, Jing Liu|<http://arxiv.org/pdf/2407.05645v4>|OneDiffæ¨¡å‹é€šè¿‡ç»“åˆè§†è§‰Deltaæ¨¡å—å’ŒSiameseå›¾åƒç¼–ç å™¨ï¼Œå®ç°äº†å¯¹å›¾åƒå·®å¼‚çš„ç²¾ç¡®æè¿°ï¼Œ...|
|ğŸ“ æ›´æ–°|EvAnimate: Event-conditioned Image-to-Video Generation for Human Animation|EvAnimateï¼šåŸºäºäº‹ä»¶æ¡ä»¶çš„å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆçš„äººä½“åŠ¨ç”»|Qiang Qu, Ming Li, Xiaoming Chen, Tongliang Liu|<http://arxiv.org/pdf/2503.18552v2>|æå‡ºEvAnimateï¼Œåˆ©ç”¨äº‹ä»¶ç›¸æœºæ•°æ®ç”Ÿæˆé«˜è´¨é‡ã€æ—¶é—´ä¸€è‡´çš„äººä½“åŠ¨ç”»ï¼Œè§£å†³ä¼ ç»Ÿæ–¹æ³•åœ¨å¤æ‚æ¡ä»¶ä¸‹çš„ä¸...|
|ğŸ†• å‘å¸ƒ|Syn3DTxt: Embedding 3D Cues for Scene Text Generation|Syn3DTxtï¼šä¸ºåœºæ™¯æ–‡æœ¬ç”ŸæˆåµŒå…¥3Dçº¿ç´¢|Li-Syun Hsiung, Jun-Kai Tu, Kuan-Wu Chu, Yu-Hsuan Chiu, Yan-Tsung Peng, Sheng-Luen Chung, Gee-Sern Jison Hsu|<http://arxiv.org/pdf/2505.18479v1>|æå‡ºäº†ä¸€ç§ç»“åˆè¡¨é¢æ³•çº¿æ„å»ºåˆæˆæ•°æ®é›†çš„æ–°æ ‡å‡†ï¼Œä»¥å¢å¼ºåœºæ™¯æ–‡æœ¬ç”Ÿæˆä¸­çš„ä¸‰ç»´ç©ºé—´å…³ç³»è¡¨ç¤ºã€‚|
|ğŸ†• å‘å¸ƒ|TNG-CLIP:Training-Time Negation Data Generation for Negation Awareness of CLIP|TNG-CLIPï¼šä¸ºCLIPå¦å®šæ„è¯†è®­ç»ƒæ—¶å¦å®šæ•°æ®ç”Ÿæˆ|Yuliang Cai, Jesse Thomason, Mohammad Rostami|<http://arxiv.org/pdf/2505.18434v1>|TNG-CLIPé€šè¿‡è®­ç»ƒæ—¶ç”Ÿæˆå¦å®šæ•°æ®ï¼Œæå‡CLIPå¯¹å¦å®šè¯­ä¹‰çš„ç†è§£èƒ½åŠ›ã€‚|


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Robust multi-coil MRI reconstruction via self-supervised denoising|é²æ£’çš„å¤šçº¿åœˆMRIé‡å»ºé€šè¿‡è‡ªç›‘ç£å»å™ª|Asad Aali, Marius Arvinte, Sidharth Kumar, Yamin I. Arefeen, Jonathan I. Tamir|<http://arxiv.org/pdf/2411.12919v4>|é€šè¿‡è‡ªç›‘ç£å»å™ªé¢„å¤„ç†ï¼Œæå‡äº†åŸºäºæ·±åº¦å­¦ä¹ çš„å¤šçº¿åœˆMRIé‡å»ºæ•ˆæœã€‚|
|ğŸ†• å‘å¸ƒ|How to build a consistency model: Learning flow maps via self-distillation|å¦‚ä½•æ„å»ºä¸€è‡´æ€§æ¨¡å‹ï¼šé€šè¿‡è‡ªè’¸é¦å­¦ä¹ æµå›¾|Nicholas M. Boffi, Michael S. Albergo, Eric Vanden-Eijnden|<http://arxiv.org/pdf/2505.18825v1>|é€šè¿‡è‡ªè’¸é¦å°†ç°æœ‰è’¸é¦æ–¹æ¡ˆè½¬åŒ–ä¸ºç›´æ¥è®­ç»ƒç®—æ³•ï¼Œæå‡ºäº†ä¸€ç§å­¦ä¹ æµå›¾çš„æ–°æ–¹æ³•ï¼Œæé«˜äº†ç”Ÿæˆæ¨¡å‹çš„æ•ˆç‡ã€‚|
|ğŸ†• å‘å¸ƒ|SAMA: Towards Multi-Turn Referential Grounded Video Chat with Large Language Models|SAMAï¼šè¿ˆå‘å¤šè½®å‚è€ƒå¼åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è§†é¢‘èŠå¤©|Ye Sun, Hao Zhang, Henghui Ding, Tiehua Zhang, Xingjun Ma, Yu-Gang Jiang|<http://arxiv.org/pdf/2505.18812v1>|æå‡ºSAMAæ¨¡å‹ï¼Œé€šè¿‡è”åˆå­¦ä¹ è§†é¢‘ç†è§£å’Œå®šä½ï¼Œå®ç°å¤šè½®è§†é¢‘å¯¹è¯ã€‚|
|ğŸ“ æ›´æ–°|AsymRnR: Video Diffusion Transformers Acceleration with Asymmetric Reduction and Restoration|æ ‡é¢˜ç¿»è¯‘ï¼šAsymRnRï¼šåŸºäºéå¯¹ç§°ç¼©å‡å’Œæ¢å¤çš„è§†é¢‘æ‰©æ•£TransformeråŠ é€Ÿ|Wenhao Sun, Rong-Cheng Tu, Jingyi Liao, Zhao Jin, Dacheng Tao|<http://arxiv.org/pdf/2412.11706v3>|æå‡ºAsymRnRæ–¹æ³•ï¼Œé€šè¿‡ä¸å¯¹ç§°é™ç»´å’Œæ¢å¤åŠ é€Ÿè§†é¢‘æ‰©æ•£Transformerï¼Œæ˜¾è‘—æå‡å¤„ç†é€Ÿåº¦ã€‚|
|ğŸ†• å‘å¸ƒ|Rethinking Direct Preference Optimization in Diffusion Models|é‡æ–°æ€è€ƒæ‰©æ•£æ¨¡å‹ä¸­çš„ç›´æ¥åå¥½ä¼˜åŒ–|Junyong Kang, Seohyun Lim, Kyungjune Baek, Hyunjung Shim|<http://arxiv.org/pdf/2505.18736v1>|æå‡ºäº†ä¸€ç§æ–°ç­–ç•¥ï¼Œé€šè¿‡ç¨³å®šå‚è€ƒæ¨¡å‹æ›´æ–°å’Œæ—¶æ­¥æ„ŸçŸ¥è®­ç»ƒï¼Œæå‡æ‰©æ•£æ¨¡å‹ä¸­ç›´æ¥åå¥½ä¼˜åŒ–çš„æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|Restoring Real-World Images with an Internal Detail Enhancement Diffusion Model|ä½¿ç”¨å†…éƒ¨ç»†èŠ‚å¢å¼ºæ‰©æ•£æ¨¡å‹æ¢å¤çœŸå®ä¸–ç•Œå›¾åƒ|Peng Xiao, Hongbo Zhao, Yijun Wang, Jianxin Lin|<http://arxiv.org/pdf/2505.18674v1>|æå‡ºäº†ä¸€ç§å†…éƒ¨ç»†èŠ‚å¢å¼ºæ‰©æ•£æ¨¡å‹ï¼Œæœ‰æ•ˆæ¢å¤ç°å®ä¸–ç•Œé€€åŒ–å›¾åƒç»†èŠ‚ã€‚|
|ğŸ“ æ›´æ–°|OSCAR: One-Step Diffusion Codec Across Multiple Bit-rates|OSCARï¼šå¤šæ¯”ç‰¹ç‡ä¸€æ­¥æ‰©æ•£ç¼–è§£ç å™¨|Jinpei Guo, Yifei Ji, Zheng Chen, Kai Liu, Min Liu, Wang Rao, Wenbo Li, Yong Guo .etc.|<http://arxiv.org/pdf/2505.16091v2>|[ä»£ç ](https://github.com/jp-guo/OSCAR.); OSCARæå‡ºäº†ä¸€ç§ä¸€æ­¥æ‰©æ•£ç¼–è§£ç å™¨ï¼Œå®ç°å¤šæ¯”ç‰¹ç‡å›¾åƒå‹ç¼©ï¼Œæ˜¾è‘—æå‡æ•ˆç‡ã€‚|
|ğŸ†• å‘å¸ƒ|Can MLLMs Guide Me Home? A Benchmark Study on Fine-Grained Visual Reasoning from Transit Maps|ã€Šèƒ½å¦æŒ‡å¼•æˆ‘å›å®¶ï¼ŸåŸºäºå…¬äº¤åœ°å›¾çš„ç»†ç²’åº¦è§†è§‰æ¨ç†åŸºå‡†ç ”ç©¶ã€‹|Sicheng Feng, Song Wang, Shuyi Ouyang, Lingdong Kong, Zikai Song, Jianke Zhu, Huan Wang, Xinchao Wang|<http://arxiv.org/pdf/2505.18675v1>|æ„å»ºReasonMapåŸºå‡†ï¼Œè¯„ä¼°MLLMsåœ¨ç»†ç²’åº¦è§†è§‰æ¨ç†ä¸Šçš„èƒ½åŠ›ï¼Œæ­ç¤ºå¼€æºä¸é—­æºæ¨¡å‹æ€§èƒ½å·®å¼‚ã€‚|
|ğŸ†• å‘å¸ƒ|Memory-Efficient Super-Resolution of 3D Micro-CT Images Using Octree-Based GANs: Enhancing Resolution and Segmentation Accuracy|åŸºäºå…«å‰æ ‘GANçš„3Då¾®CTå›¾åƒå†…å­˜é«˜æ•ˆè¶…åˆ†è¾¨ç‡ï¼šæå‡åˆ†è¾¨ç‡å’Œåˆ†å‰²ç²¾åº¦|Evgeny Ugolkov, Xupeng He, Hyung Kwak, Hussein Hoteit|<http://arxiv.org/pdf/2505.18664v1>|æå‡ºäº†ä¸€ç§åŸºäºå…«å‰æ ‘GANçš„å†…å­˜é«˜æ•ˆ3Då¾®CTå›¾åƒè¶…åˆ†è¾¨ç‡ç®—æ³•ï¼Œæ˜¾è‘—æå‡åˆ†è¾¨ç‡å’Œåˆ†å‰²ç²¾åº¦ã€‚|
|ğŸ†• å‘å¸ƒ|So-Fake: Benchmarking and Explaining Social Media Image Forgery Detection|So-Fakeï¼šç¤¾äº¤åª’ä½“å›¾åƒä¼ªé€ æ£€æµ‹çš„åŸºå‡†ä¸è§£é‡Š|Zhenglin Huang, Tianxiao Li, Xiangtai Li, Haiquan Wen, Yiwei He, Jiangning Zhang, Hao Fei, Xi Yang .etc.|<http://arxiv.org/pdf/2505.18660v1>|æ„å»ºäº†å¤§è§„æ¨¡ç¤¾äº¤åª’ä½“å›¾åƒä¼ªé€ æ£€æµ‹åŸºå‡†å’Œè§£é‡Šæ€§æ£€æµ‹æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†ä¼ªé€ æ£€æµ‹å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚|
|ğŸ†• å‘å¸ƒ|DVD-Quant: Data-free Video Diffusion Transformers Quantization|DVD-Quantï¼šæ— æ•°æ®è§†é¢‘æ‰©æ•£å˜æ¢å™¨é‡åŒ–|Zhiteng Li, Hanxuan Li, Junyi Wu, Kai Liu, Linghe Kong, Guihai Chen, Yulun Zhang, Xiaokang Yang|<http://arxiv.org/pdf/2505.18663v1>|[ä»£ç ](https://github.com/lhxcs/DVD-Quant.); æå‡ºDVD-Quantï¼Œä¸€ç§æ— éœ€æ•°æ®æ ¡å‡†çš„è§†é¢‘æ‰©æ•£Transformeré‡åŒ–æ¡†æ¶ï¼Œæ˜¾è‘—æå‡è§†é¢‘ç”Ÿæˆé€Ÿ...|
|ğŸ†• å‘å¸ƒ|EvdCLIP: Improving Vision-Language Retrieval with Entity Visual Descriptions from Large Language Models|EvdCLIPï¼šåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„å®ä½“è§†è§‰æè¿°æ”¹è¿›è§†è§‰-è¯­è¨€æ£€ç´¢|GuangHao Meng, Sunan He, Jinpeng Wang, Tao Dai, Letian Zhang, Jieming Zhu, Qing Li, Gang Wang .etc.|<http://arxiv.org/pdf/2505.18594v1>|EvdCLIPé€šè¿‡åˆ©ç”¨å®ä½“è§†è§‰æè¿°å¢å¼ºæŸ¥è¯¢ï¼Œæœ‰æ•ˆæå‡äº†è§†è§‰è¯­è¨€æ£€ç´¢çš„å‡†ç¡®æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Chain-of-Zoom: Extreme Super-Resolution via Scale Autoregression and Preference Alignment|é“¾å¼ç¼©æ”¾ï¼šé€šè¿‡å°ºåº¦è‡ªå›å½’å’Œåå¥½å¯¹é½å®ç°æç«¯è¶…åˆ†è¾¨ç‡|Bryan Sangwoo Kim, Jeongsol Kim, Jong Chul Ye|<http://arxiv.org/pdf/2505.18600v1>|æå‡ºChain-of-Zoomæ¡†æ¶ï¼Œé€šè¿‡å¤šå°ºåº¦æç¤ºå’Œè‡ªå›å½’é“¾å®ç°è¶…åˆ†è¾¨ç‡å›¾åƒçš„æç«¯æ”¾å¤§ã€‚|
|ğŸ†• å‘å¸ƒ|Unleashing Diffusion Transformers for Visual Correspondence by Modulating Massive Activations|é‡Šæ”¾æ‰©æ•£å˜æ¢å™¨é€šè¿‡è°ƒèŠ‚å¤§é‡æ¿€æ´»è¿›è¡Œè§†è§‰å¯¹åº”|Chaofan Gan, Yuanpeng Tu, Xi Chen, Tieyuan Chen, Yuxi Li, Mehrtash Harandi, Weiyao Lin|<http://arxiv.org/pdf/2505.18584v1>|æå‡ºäº†ä¸€ç§é€šè¿‡è°ƒèŠ‚æ‰©æ•£æ¨¡å‹ä¸­çš„å¤§è§„æ¨¡æ¿€æ´»æ¥æå‡è§†è§‰å¯¹åº”ç²¾åº¦çš„æ–¹æ³•ã€‚|
|ğŸ†• å‘å¸ƒ|On Denoising Walking Videos for Gait Recognition|å…³äºæ­¥è¡Œè§†é¢‘å»å™ªä»¥å®ç°æ­¥æ€è¯†åˆ«|Dongyang Jin, Chao Fan, Jingzhe Ma, Jingkai Zhou, Weihua Chen, Shiqi Yu|<http://arxiv.org/pdf/2505.18582v1>|[ä»£ç ](https://github.com/ShiqiYu/OpenGait.); æå‡ºDenoisingGaitï¼Œé€šè¿‡å»å™ªå’Œç‰¹å¾åŒ¹é…æå‡æ­¥è¡Œè§†é¢‘å§¿æ€è¯†åˆ«å‡†ç¡®åº¦ã€‚|
|ğŸ†• å‘å¸ƒ|ThinkVideo: High-Quality Reasoning Video Segmentation with Chain of Thoughts|ThinkVideoï¼šåŸºäºæ€ç»´é“¾çš„é«˜è´¨é‡æ¨ç†è§†é¢‘åˆ†å‰²|Shiu-hong Kao, Yu-Wing Tai, Chi-Keung Tang|<http://arxiv.org/pdf/2505.18561v1>|ThinkVideoé€šè¿‡åˆ©ç”¨MLLMçš„é›¶æ ·æœ¬æ€ç»´é“¾èƒ½åŠ›ï¼Œå®ç°äº†é«˜è´¨é‡çš„è§†é¢‘å¯¹è±¡åˆ†å‰²ã€‚|
|ğŸ†• å‘å¸ƒ|Diffusion Blend: Inference-Time Multi-Preference Alignment for Diffusion Models|æ‰©æ•£èåˆï¼šæ‰©æ•£æ¨¡å‹æ¨ç†æ—¶çš„å¤šåå¥½å¯¹é½|Min Cheng, Fatemeh Doudi, Dileep Kalathil, Mohammad Ghavamzadeh, Panganamala R. Kumar|<http://arxiv.org/pdf/2505.18547v1>|[ä»£ç ](https://github.com/bluewoods127/DB-2025); æå‡ºDiffusion Blendæ–¹æ³•ï¼Œå®ç°æ¨ç†æ—¶å¤šåå¥½å¯¹é½ï¼Œä¼˜åŒ–æ‰©æ•£æ¨¡å‹ã€‚|
|ğŸ“ æ›´æ–°|Context Matters: Query-aware Dynamic Long Sequence Modeling of Gigapixel Images|ä¸Šä¸‹æ–‡å¾ˆé‡è¦ï¼šé’ˆå¯¹å‰åƒç´ å›¾åƒçš„æŸ¥è¯¢æ„ŸçŸ¥åŠ¨æ€é•¿åºåˆ—å»ºæ¨¡|Zhengrui Guo, Qichen Sun, Jiabo Ma, Lishuang Feng, Jinzhuo Wang, Hao Chen|<http://arxiv.org/pdf/2501.18984v2>|[ä»£ç ](https://github.com/dddavid4real/Querent.); æå‡ºäº†ä¸€ç§é«˜æ•ˆåŠ¨æ€å»ºæ¨¡æ¡†æ¶ï¼Œé€šè¿‡æŸ¥è¯¢æ„ŸçŸ¥ä¼˜åŒ–é•¿åºåˆ—å›¾åƒåˆ†æï¼Œæ˜¾è‘—æå‡è®¡ç®—æ•ˆç‡å’Œé¢„æµ‹æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|HonestFace: Towards Honest Face Restoration with One-Step Diffusion Model|è¯šå®è„¸ï¼šè¿ˆå‘ä¸€æ­¥æ‰©æ•£æ¨¡å‹ä¸‹çš„è¯šå®äººè„¸ä¿®å¤|Jingkai Wang, Wu Miao, Jue Gong, Zheng Chen, Xing Liu, Hong Gu, Yutong Liu, Yulun Zhang|<http://arxiv.org/pdf/2505.18469v1>|[ä»£ç ](https://github.com/jkwang28/HonestFace); HonestFaceé€šè¿‡ä¸€æ­¥æ‰©æ•£æ¨¡å‹ï¼Œå®ç°é«˜ä¿çœŸã€çœŸå®æ„Ÿçš„é¢éƒ¨å›¾åƒä¿®å¤ã€‚|
|ğŸ“ æ›´æ–°|Role Bias in Text-to-Image Diffusion Models: Diagnosing and Mitigating Compositional Failures through Intermediate Decomposition|æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­çš„è§’è‰²åå·®ï¼šé€šè¿‡ä¸­é—´åˆ†è§£è¯Šæ–­å’Œç¼“è§£ç»„åˆå¤±è´¥|Sina Malakouti, Adriana Kovashka|<http://arxiv.org/pdf/2503.10037v2>|é€šè¿‡ä¸­é—´åˆ†è§£è¯Šæ–­å’Œç¼“è§£æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­çš„è§’è‰²åå·®ï¼Œæå‡ºäº†ä¸€ç§å‡è½»è§’è‰²å´©æºƒçš„è½»é‡çº§æ¡†æ¶ã€‚|
|ğŸ†• å‘å¸ƒ|OmniConsistency: Learning Style-Agnostic Consistency from Paired Stylization Data|å…¨ä¸€è‡´æ€§ï¼šä»é…å¯¹é£æ ¼åŒ–æ•°æ®ä¸­å­¦ä¹ é£æ ¼æ— å…³çš„ä¸€è‡´æ€§|Yiren Song, Cheng Liu, Mike Zheng Shou|<http://arxiv.org/pdf/2505.18445v1>|OmniConsistencyé€šè¿‡å¤§è§„æ¨¡Diffusion Transformersï¼Œæå‡ºäº†ä¸€ç§è·¨é£...|


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Self-Supervised and Generalizable Tokenization for CLIP-Based 3D Understanding|åŸºäºCLIPçš„3Dç†è§£çš„è‡ªç›‘ç£å’Œæ³›åŒ–æ€§åˆ†è¯|Guofeng Mei, Bin Ren, Juan Liu, Luigi Riz, Xiaoshui Huang, Xu Zheng, Yongshun Gong, Ming-Hsuan Yang .etc.|<http://arxiv.org/pdf/2505.18819v1>|æå‡ºS4Tokenï¼Œé€šè¿‡ç»“åˆè¶…ç‚¹åˆ†ç»„å’Œåæ ‡ç¼©æ”¾å½’ä¸€åŒ–ï¼Œå®ç°è·¨åŸŸé€šç”¨çš„3Dåœºæ™¯ç†è§£ã€‚|
|ğŸ†• å‘å¸ƒ|Generative RLHF-V: Learning Principles from Multi-modal Human Preference|ç”Ÿæˆå¼RLHF-Vï¼šä»å¤šæ¨¡æ€äººç±»åå¥½ä¸­å­¦ä¹ åŸåˆ™|Jiayi Zhou, Jiaming Ji, Boyuan Chen, Jiapeng Sun, Wenqi Chen, Donghai Hong, Sirui Han, Yike Guo .etc.|<http://arxiv.org/pdf/2505.18531v1>|Generative RLHF-Vé€šè¿‡ç»“åˆç”Ÿæˆå¼å¥–åŠ±æ¨¡å‹ä¸å¤šæ¨¡æ€RLHFï¼Œæœ‰æ•ˆæå‡äº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹...|


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### è§†è§‰å®šä½ä¸æ˜ å°„ (Visual Localization & Mapping)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Beyond Domain Randomization: Event-Inspired Perception for Visually Robust Adversarial Imitation from Videos|è¶…è¶Šé¢†åŸŸéšæœºåŒ–ï¼šåŸºäºäº‹ä»¶çš„è§†è§‰é²æ£’å¯¹æŠ—æ¨¡ä»¿æ„ŸçŸ¥|Andrea Ramazzina, Vittorio Giammarino, Matteo El-Hariry, Mario Bijelic|<http://arxiv.org/pdf/2505.18899v1>|æå‡ºäº†ä¸€ç§åŸºäºäº‹ä»¶æ„ŸçŸ¥çš„è§†è§‰é²æ£’æ¨¡ä»¿æ–¹æ³•ï¼Œé€šè¿‡è½¬æ¢è§†é¢‘ä¸ºäº‹ä»¶è¡¨ç¤ºï¼Œå®ç°å¯¹æŠ—æ€§æ¨¡ä»¿çš„è§†è§‰ä¸å˜æ€§ã€‚|


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SuperGS: Consistent and Detailed 3D Super-Resolution Scene Reconstruction via Gaussian Splatting|è¶…çº§GSï¼šé€šè¿‡é«˜æ–¯åˆ†å±‚å®ç°ä¸€è‡´ä¸”è¯¦ç»†çš„3Dè¶…åˆ†è¾¨ç‡åœºæ™¯é‡å»º|Shiyun Xie, Zhiru Wang, Yinghao Zhu, Xu Wang, Chengwei Pan, Xiwang Dong|<http://arxiv.org/pdf/2505.18649v1>|SuperGSé€šè¿‡ä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶å’Œä¸ç¡®å®šæ€§å»ºæ¨¡ï¼Œå®ç°äº†é«˜åˆ†è¾¨ç‡åœºæ™¯é‡å»ºï¼Œè§£å†³äº†ä½åˆ†è¾¨ç‡è¾“å…¥å¯¼è‡´çš„ç»†èŠ‚...|
|ğŸ†• å‘å¸ƒ|Spiking Transformers Need High Frequency Information|è„‰å†²ç¥ç»ç½‘ç»œéœ€è¦é«˜é¢‘ä¿¡æ¯|Yuetong Fang, Deming Zhou, Ziqing Wang, Hongwei Ren, ZeCui Zeng, Lusong Li, Shibo Zhou, Renjing Xu|<http://arxiv.org/pdf/2505.18608v1>|æ­ç¤ºè„‰å†²ç¥ç»ç½‘ç»œåå¥½ä¼ æ’­ä½é¢‘ä¿¡æ¯ï¼Œæå‡ºMax-Formeré€šè¿‡å¢å¼ºé«˜é¢‘ä¿¡å·æå‡æ€§èƒ½ã€‚|


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|PromptHMR: Promptable Human Mesh Recovery|PromptHMRï¼šå¯æç¤ºçš„äººä½“ç½‘æ ¼æ¢å¤|Yufu Wang, Yu Sun, Priyanka Patel, Kostas Daniilidis, Michael J. Black, Muhammed Kocabas|<http://arxiv.org/pdf/2504.06397v2>|PromptHMRé€šè¿‡ç©ºé—´å’Œè¯­ä¹‰æç¤ºï¼Œå®ç°äº†åœ¨å¤æ‚åœºæ™¯ä¸­å‡†ç¡®ä¼°è®¡äººä½“å§¿æ€å’Œå½¢çŠ¶ã€‚|


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### è§†é¢‘ç›®æ ‡è·Ÿè¸ª (Video Object Tracking)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|FusionTrack: End-to-End Multi-Object Tracking in Arbitrary Multi-View Environment|èåˆè·Ÿè¸ªï¼šä»»æ„å¤šè§†å›¾ç¯å¢ƒä¸­çš„ç«¯åˆ°ç«¯å¤šç›®æ ‡è·Ÿè¸ª|Xiaohe Li, Pengfei Li, Zide Fan, Ying Geng, Fangli Mou, Haohua Wu, Yunping Ge|<http://arxiv.org/pdf/2505.18727v1>|æå‡ºFusionTrackæ¡†æ¶ï¼Œå®ç°ä»»æ„å¤šè§†è§’ç¯å¢ƒä¸‹çš„å¤šç›®æ ‡è·Ÿè¸ªï¼Œæ˜¾è‘—æå‡è·Ÿè¸ªç²¾åº¦ã€‚|


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|PMQ-VE: Progressive Multi-Frame Quantization for Video Enhancement|PMQ-VEï¼šè§†é¢‘å¢å¼ºçš„æ¸è¿›å¼å¤šå¸§é‡åŒ–|ZhanFeng Feng, Long Peng, Xin Di, Yong Guo, Wenbo Li, Yulun Zhang, Renjing Pei, Yang Wang .etc.|<http://arxiv.org/pdf/2505.12266v2>|[ä»£ç ](https://github.com/xiaoBIGfeng/PMQ-VE.); æå‡ºPMQ-VEï¼Œé€šè¿‡æ¸è¿›å¼å¤šå¸§é‡åŒ–æå‡è§†é¢‘å¢å¼ºæ€§èƒ½ï¼Œè§£å†³ç°æœ‰æ–¹æ³•è®¡ç®—å’Œå†…å­˜éœ€æ±‚é«˜çš„é—®é¢˜ã€‚|


### åŠ¨ä½œè¯†åˆ«ä¸ç†è§£ (Action Recognition & Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ZooplanktonBench: A Geo-Aware Zooplankton Recognition and Classification Dataset from Marine Observations|æµ·æ´‹è§‚æµ‹ä¸­çš„åœ°ç†æ„ŸçŸ¥æµ®æ¸¸åŠ¨ç‰©è¯†åˆ«ä¸åˆ†ç±»æ•°æ®é›†ï¼šZooplanktonBench|Fukun Liu, Adam T. Greer, Gengchen Mai, Jin Sun|<http://arxiv.org/pdf/2505.18477v1>|æ„å»ºäº†åŒ…å«åœ°ç†ä¿¡æ¯çš„æµ®æ¸¸åŠ¨ç‰©æ•°æ®é›†ï¼Œä»¥è§£å†³å¤æ‚ç¯å¢ƒä¸‹è®¡ç®—æœºè§†è§‰è¯†åˆ«å’Œåˆ†ç±»çš„æŒ‘æˆ˜ã€‚|


## è‡ªç›‘ç£ä¸è¡¨å¾å­¦ä¹  (Self-supervised & Representation Learning)


### å¯¹æ¯”å­¦ä¹ æ–¹æ³• (Contrastive Learning Methods)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|REAL: Representation Enhanced Analytic Learning for Exemplar-free Class-incremental Learning|çœŸå®ï¼šåŸºäºè¡¨ç¤ºå¢å¼ºçš„ç¤ºä¾‹æ— å…³ç±»å¢é‡å­¦ä¹ åˆ†æå­¦ä¹ |Run He, Di Fang, Yizhu Chen, Kai Tong, Cen Chen, Yi Wang, Lap-pui Chau, Huiping Zhuang|<http://arxiv.org/pdf/2403.13522v2>|æå‡ºäº†ä¸€ç§å¢å¼ºè¡¨å¾çš„è§£æå­¦ä¹ æ–¹æ³•ï¼Œæœ‰æ•ˆç¼“è§£äº†æ— æ ·æœ¬ç±»å¢é‡å­¦ä¹ ä¸­çš„é—å¿˜é—®é¢˜ã€‚|


### è·¨æ¨¡æ€ä¸€è‡´æ€§å­¦ä¹  (Cross-modal Consistency Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Multi-Level Embedding and Alignment Network with Consistency and Invariance Learning for Cross-View Geo-Localization|å¤šçº§åµŒå…¥ä¸å¯¹é½ç½‘ç»œï¼šåŸºäºä¸€è‡´æ€§å’Œä¸å˜æ€§å­¦ä¹ çš„è·¨è§†å›¾åœ°ç†å®šä½|Zhongwei Chen, Zhao-Xu Yang, Hai-Jun Rong|<http://arxiv.org/pdf/2412.14819v4>|[ä»£ç ](https://github.com/ISChenawei/MEAN.); æå‡ºäº†ä¸€ç§è½»é‡çº§ç½‘ç»œï¼Œé€šè¿‡å¤šçº§åµŒå…¥å’Œä¸€è‡´æ€§å­¦ä¹ ï¼Œæœ‰æ•ˆè§£å†³è·¨è§†å›¾åœ°ç†å®šä½ä¸­çš„ç‰¹å¾å…³è”å’Œè®¡ç®—é—®é¢˜ã€‚|


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations|é‚£æ˜¯åœ¨è°ˆè®ºä»€ä¹ˆï¼Ÿç§‘å­¦æ¼”ç¤ºçš„è§†é¢‘åˆ°æ–‡æœ¬æ‘˜è¦æ•°æ®é›†|Dongqi Liu, Chenxi Whitehouse, Xi Yu, Louis Mahon, Rohit Saxena, Zheng Zhao, Yifu Qiu, Mirella Lapata .etc.|<http://arxiv.org/pdf/2502.08279v4>|æ„å»ºäº†é’ˆå¯¹ç§‘å­¦æ¼”è®²çš„è§†é¢‘åˆ°æ–‡æœ¬æ‘˜è¦æ•°æ®é›†VISTAï¼Œå¹¶åº”ç”¨åŸºäºè®¡åˆ’çš„æ¡†æ¶æå‡æ‘˜è¦è´¨é‡ã€‚|
|ğŸ“ æ›´æ–°|GAPrompt: Geometry-Aware Point Cloud Prompt for 3D Vision Model|GAPromptï¼šé¢å‘3Dè§†è§‰æ¨¡å‹çš„å‡ ä½•æ„ŸçŸ¥ç‚¹äº‘æç¤º|Zixiang Ai, Zichen Liu, Yuanhang Lei, Zhenyu Cui, Xu Zou, Jiahuan Zhou|<http://arxiv.org/pdf/2505.04119v2>|[ä»£ç ](https://github.com/zhoujiahuan1991/ICML2025-VGP.); æå‡ºGAPromptï¼Œé€šè¿‡å‡ ä½•çº¿ç´¢å¢å¼º3Dè§†è§‰æ¨¡å‹é€‚åº”æ€§ï¼Œå®ç°é«˜æ•ˆå‚æ•°é«˜æ•ˆå¾®è°ƒã€‚|


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Rethinking Causal Mask Attention for Vision-Language Inference|é‡æ–°æ€è€ƒè§†è§‰-è¯­è¨€æ¨ç†ä¸­çš„å› æœæ©ç æ³¨æ„åŠ›|Xiaohuan Pei, Tao Huang, YanXiang Ma, Chang Xu|<http://arxiv.org/pdf/2505.18605v1>|æå‡ºæœªæ¥æ„ŸçŸ¥æ³¨æ„åŠ›æœºåˆ¶ï¼Œè§£å†³å› æœæ©ç åœ¨è§†è§‰è¯­è¨€æ¨ç†ä¸­çš„ä¸è¶³ï¼Œæå‡æ¨¡å‹æ¨ç†èƒ½åŠ›ã€‚|


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### ä¸ç¡®å®šæ€§é‡åŒ– (Uncertainty Quantification)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Token Sampling Uncertainty Does Not Explain Homogeneity Bias in Large Language Models|å¤§è¯­è¨€æ¨¡å‹ä¸­åŒè´¨æ€§åå·®ä¸èƒ½ç”±æ ‡è®°é‡‡æ ·ä¸ç¡®å®šæ€§è§£é‡Š|Messi H. J. Lee, Soyeon Jeon|<http://arxiv.org/pdf/2501.19337v2>|ç ”ç©¶å‘ç°ï¼Œå¤§è¯­è¨€æ¨¡å‹ä¸­çš„åŒè´¨æ€§åå·®å¹¶éç”±tokené‡‡æ ·ä¸ç¡®å®šæ€§å¼•èµ·ï¼Œå»ºè®®ä¼˜å…ˆå¹²é¢„è¡¨ç¤ºå­¦ä¹ æœºåˆ¶å’Œè®­ç»ƒè¯­...|


### åˆ†å¸ƒå¤–æ³›åŒ– (Out-of-distribution Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Think Twice before Adaptation: Improving Adaptability of DeepFake Detection via Online Test-Time Adaptation|æ·±æ€ç†Ÿè™‘åå†è¿›è¡Œé€‚åº”ï¼šé€šè¿‡åœ¨çº¿æµ‹è¯•æ—¶é€‚åº”æé«˜DeepFakeæ£€æµ‹çš„é€‚åº”æ€§|Hong-Hanh Nguyen-Le, Van-Tuan Tran, Dinh-Thuc Nguyen, Nhien-An Le-Khac|<http://arxiv.org/pdf/2505.18787v1>|[ä»£ç ](https://github.com/HongHanh2104/T2A-Think-Twice-Before-Adaptation); æå‡ºäº†ä¸€ç§åœ¨çº¿æµ‹è¯•æ—¶è‡ªé€‚åº”æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†Deepfakeæ£€æµ‹å™¨çš„é€‚åº”æ€§å’Œé²æ£’æ€§ã€‚|
|ğŸ“ æ›´æ–°|The Double-Ellipsoid Geometry of CLIP|CLIPçš„åŒæ¤­çƒå‡ ä½•å½¢çŠ¶|Meir Yossef Levi, Guy Gilboa|<http://arxiv.org/pdf/2411.14517v3>|æ­ç¤ºäº†CLIPåµŒå…¥çš„åŒæ¤­çƒå‡ ä½•ç»“æ„ï¼Œä¼˜åŒ–äº†å¯¹æ¯”è®­ç»ƒä¸­çš„å®ä¾‹åµŒå…¥å’ŒåŒ¹é…ã€‚|


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|CageNet: A Meta-Framework for Learning on Wild Meshes|ç¬¼ç½‘ï¼šé‡ç”Ÿç½‘æ ¼å­¦ä¹ å…ƒæ¡†æ¶|Michal Edelstein, Hsueh-Ti Derek Liu, Mirela Ben-Chen|<http://arxiv.org/pdf/2505.18772v1>|æå‡ºCageNetå…ƒæ¡†æ¶ï¼Œé€šè¿‡ç¬¼å½¢å‡ ä½•æ¦‚å¿µæ‰©å±•é€šç”¨æ¡†æ¶åœ¨å¤æ‚ç½‘æ ¼ä¸Šçš„åº”ç”¨ã€‚|
|ğŸ†• å‘å¸ƒ|WeakMCN: Multi-task Collaborative Network for Weakly Supervised Referring Expression Comprehension and Segmentation|å¼±MCNï¼šå¼±ç›‘ç£æŒ‡ä»£è¡¨è¾¾ç†è§£ä¸åˆ†å‰²çš„å¤šä»»åŠ¡åä½œç½‘ç»œ|Yang Liu, Silin Cheng, Xinwei He, Sebastien Ourselin, Lei Tan, Gen Luo|<http://arxiv.org/pdf/2505.18686v1>|[ä»£ç ](https://github.com/MRUIL/WeakMCN.); æå‡ºWeakMCNï¼Œé€šè¿‡å¤šä»»åŠ¡åä½œç½‘ç»œæå‡å¼±ç›‘ç£æŒ‡ä»£è¡¨è¾¾å¼ç†è§£å’Œåˆ†å‰²çš„æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|Learning without Isolation: Pathway Protection for Continual Learning|æ— éš”ç¦»å­¦ä¹ ï¼šæŒç»­å­¦ä¹ çš„è·¯å¾„ä¿æŠ¤|Zhikang Chen, Abudukelimu Wuerkaixi, Sen Cui, Haoxuan Li, Ding Li, Jingfeng Zhang, Bo Han, Gang Niu .etc.|<http://arxiv.org/pdf/2505.18568v1>|æå‡ºäº†ä¸€ç§åŸºäºè·¯å¾„ä¿æŠ¤çš„æŒç»­å­¦ä¹ æ–¹æ³•ï¼Œæœ‰æ•ˆé˜²æ­¢ç¾éš¾æ€§é—å¿˜ã€‚|
|ğŸ“ æ›´æ–°|Paper Copilot Position: The Artificial Intelligence and Machine Learning Community Should Adopt a More Transparent and Regulated Peer Review Process|è®ºæ–‡åˆä½œè€…èŒä½ï¼šäººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ ç¤¾åŒºåº”é‡‡ç”¨æ›´é€æ˜å’Œè§„èŒƒçš„åŒè¡Œè¯„å®¡æµç¨‹|Jing Yang|<http://arxiv.org/pdf/2502.00874v2>|å€¡å¯¼å»ºç«‹æ›´é€æ˜ã€å¼€æ”¾çš„åŒè¡Œè¯„å®¡æµç¨‹ï¼Œä»¥ä¿ƒè¿›ç¤¾åŒºå‚ä¸å’Œæ¨åŠ¨äººå·¥æ™ºèƒ½ä¸æœºå™¨å­¦ä¹ é¢†åŸŸå‘å±•ã€‚|


## å…·èº«æ™ºèƒ½ä¸äº¤äº’è§†è§‰ (Embodied Intelligence & Interactive Vision)


### è§†è§‰æ“ä½œä¸æ§åˆ¶ (Visual Manipulation & Control)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|ManipLVM-R1: Reinforcement Learning for Reasoning in Embodied Manipulation with Large Vision-Language Models|ManipLVM-R1ï¼šåŸºäºå¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹çš„å…·èº«æ“ä½œæ¨ç†å¼ºåŒ–å­¦ä¹ |Zirui Song, Guangxian Ouyang, Mingzhe Li, Yuheng Ji, Chenxi Wang, Zixiang Xu, Zeyu Zhang, Xiaoqing Zhang .etc.|<http://arxiv.org/pdf/2505.16517v2>|æå‡ºManipLVM-R1ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ ä¸å¯éªŒè¯å¥–åŠ±ï¼Œæå‡æœºå™¨äººæ“ä½œä¸­çš„ç‰©ç†æ¨ç†å’Œæ³›åŒ–èƒ½åŠ›ã€‚|


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Why Vision Language Models Struggle with Visual Arithmetic? Towards Enhanced Chart and Geometry Understanding|è§†è§‰è¯­è¨€æ¨¡å‹ä¸ºä½•åœ¨è§†è§‰ç®—æœ¯ä¸­æŒ£æ‰ï¼Ÿè¿ˆå‘å¢å¼ºçš„å›¾è¡¨å’Œå‡ ä½•ç†è§£|Kung-Hsiang Huang, Can Qin, Haoyi Qiu, Philippe Laban, Shafiq Joty, Caiming Xiong, Chien-Sheng Wu|<http://arxiv.org/pdf/2502.11492v3>|æå‡ºCogAlignæ–¹æ³•ï¼Œé€šè¿‡è®¤çŸ¥å‘å±•ç†è®ºå¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹åœ¨è§†è§‰ç®—æœ¯ç†è§£ä¸Šçš„èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|LORE: Lagrangian-Optimized Robust Embeddings for Visual Encoders|æ´›ä¼¦å…¹ä¼˜åŒ–é²æ£’åµŒå…¥ï¼šç”¨äºè§†è§‰ç¼–ç å™¨çš„æ‹‰æ ¼æœ—æ—¥ä¼˜åŒ–åµŒå…¥|Borna Khodabandeh, Amirabbas Afzali, Amirhossein Afsharrad, Seyed Shahabeddin Mousavi, Sanjay Lall, Sajjad Amini, Seyed-Mohsen Moosavi-Dezfooli|<http://arxiv.org/pdf/2505.18884v1>|æå‡ºLOREæ¡†æ¶ï¼Œé€šè¿‡çº¦æŸä¼˜åŒ–æå‡è§†è§‰ç¼–ç å™¨å¯¹å¯¹æŠ—æ”»å‡»çš„é²æ£’æ€§ï¼ŒåŒæ—¶ä¿æŒæ¸…æ´æ•°æ®å‡†ç¡®æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Don't Look Only Once: Towards Multimodal Interactive Reasoning with Selective Visual Revisitation|ä¸€æ¬¡ä¸åªéœ€çœ‹ï¼šè¿ˆå‘å…·æœ‰é€‰æ‹©æ€§è§†è§‰é‡è®¿çš„å¤šæ¨¡æ€äº¤äº’æ¨ç†|Jiwan Chung, Junhyeok Kim, Siyeol Kim, Jaeyoung Lee, Min Soo Kim, Youngjae Yu|<http://arxiv.org/pdf/2505.18842v1>|æå‡ºäº†ä¸€ç§è½»é‡çº§æ¨¡å‹v1ï¼Œé€šè¿‡é€‰æ‹©æ€§è§†è§‰é‡è®¿å¢å¼ºå¤šæ¨¡æ€äº¤äº’æ¨ç†èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|ToDRE: Visual Token Pruning via Diversity and Task Awareness for Efficient Large Vision-Language Models|ToDREï¼šåŸºäºå¤šæ ·æ€§å’Œä»»åŠ¡æ„ŸçŸ¥çš„è§†è§‰æ ‡è®°å‰ªæï¼Œä»¥å®ç°é«˜æ•ˆçš„å¤§è§„æ¨¡è§†è§‰-è¯­è¨€æ¨¡å‹|Duo Li, Zuhao Yang, Shijian Lu|<http://arxiv.org/pdf/2505.18757v1>|è®¾è®¡ToDREæ¡†æ¶ï¼Œé€šè¿‡å¤šæ ·æ€§å’Œä»»åŠ¡ç›¸å…³æ€§å‰ªæè§†è§‰tokenï¼Œæå‡å¤§è§†è§‰è¯­è¨€æ¨¡å‹æ•ˆç‡ã€‚|
|ğŸ†• å‘å¸ƒ|GRE Suite: Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains|GRE Suiteï¼šé€šè¿‡å¾®è°ƒè§†è§‰-è¯­è¨€æ¨¡å‹å’Œå¢å¼ºæ¨ç†é“¾è¿›è¡Œåœ°ç†å®šä½æ¨æ–­|Chun Wang, Xiaoran Pan, Zihao Pan, Haofan Wang, Yiren Song|<http://arxiv.org/pdf/2505.18700v1>|[ä»£ç ](https://github.com/Thorin215/GRE.); æå‡ºGRE Suiteï¼Œé€šè¿‡å¢å¼ºæ¨ç†é“¾æé«˜è§†è§‰è¯­è¨€æ¨¡å‹åœ¨åœ°ç†å®šä½ä»»åŠ¡ä¸­çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Why Not Replace? Sustaining Long-Term Visual Localization via Handcrafted-Learned Feature Collaboration on CPU|ä¸ºä½•ä¸æ›¿æ¢ï¼Ÿé€šè¿‡CPUä¸Šçš„æ‰‹å·¥åˆ¶ä½œ-å­¦ä¹ ç‰¹å¾åä½œå®ç°é•¿æœŸè§†è§‰å®šä½çš„ç»´æŒ|Yicheng Lin, Yunlong Jiang, Xujia Jiao, Bin Han|<http://arxiv.org/pdf/2505.18652v1>|[ä»£ç ](https://github.com/linyicheng1/ORB_SLAM3_localization.); æå‡ºä¸€ç§ç»“åˆæ‰‹å·¥å’Œæ·±åº¦å­¦ä¹ ç‰¹å¾çš„è§†è§‰å®šä½æ¡†æ¶ï¼Œæ˜¾è‘—æå‡é•¿æœŸå®šä½ç²¾åº¦å’Œæ•ˆç‡ã€‚|
|ğŸ†• å‘å¸ƒ|Doc-CoB: Enhancing Multi-Modal Document Understanding with Visual Chain-of-Boxes Reasoning|Doc-CoBï¼šåŸºäºè§†è§‰é“¾å¼æ¡†æ¨ç†çš„å¤šæ¨¡æ€æ–‡æ¡£ç†è§£å¢å¼º|Ye Mo, Zirui Shao, Kai Ye, Xianwei Mao, Bo Zhang, Hangdi Xing, Peng Ye, Gang Huang .etc.|<http://arxiv.org/pdf/2505.18603v1>|å¼•å…¥è§†è§‰é“¾å¼æ¡†æ¨ç†ï¼Œæå‡å¤šæ¨¡æ€æ–‡æ¡£ç†è§£å‡†ç¡®æ€§ã€‚|
|ğŸ“ æ›´æ–°|3D Visual Illusion Depth Estimation|ä¸‰ç»´è§†è§‰é”™è§‰æ·±åº¦ä¼°è®¡|Chengtang Yao, Zhidan Liu, Jiaxi Zeng, Lidong Yu, Yuwei Wu, Yunde Jia|<http://arxiv.org/pdf/2505.13061v3>|æå‡ºäº†ä¸€ç§åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹å¸¸è¯†çš„é²æ£’æ·±åº¦ä¼°è®¡æ¡†æ¶ï¼Œæœ‰æ•ˆåº”å¯¹3Dè§†è§‰é”™è§‰æŒ‘æˆ˜ã€‚|
|ğŸ†• å‘å¸ƒ|Focus on What Matters: Enhancing Medical Vision-Language Models with Automatic Attention Alignment Tuning|èšç„¦äºå…³é”®ä¿¡æ¯ï¼šé€šè¿‡è‡ªåŠ¨æ³¨æ„åŠ›å¯¹é½è°ƒæ•´å¢å¼ºåŒ»å­¦è§†è§‰-è¯­è¨€æ¨¡å‹|Aofei Chang, Le Huang, Alex James Boyd, Parminder Bhatia, Taha Kass-Hout, Cao Xiao, Fenglong Ma|<http://arxiv.org/pdf/2505.18503v1>|æå‡ºA$^3$Tuneæ¡†æ¶ï¼Œé€šè¿‡è‡ªåŠ¨æ³¨æ„åŠ›å¯¹é½è°ƒæ•´æå‡åŒ»å­¦è§†è§‰è¯­è¨€æ¨¡å‹æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|Grounding Bodily Awareness in Visual Representations for Efficient Policy Learning|åœ¨è§†è§‰è¡¨ç¤ºä¸­é”šå®šèº«ä½“æ„è¯†ä»¥å®ç°é«˜æ•ˆç­–ç•¥å­¦ä¹ |Junlin Wang, Zhiyun Lin|<http://arxiv.org/pdf/2505.18487v1>|[ä»£ç ](https://github.com/HenryWJL/icon); æå‡ºIConæ–¹æ³•ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ å¢å¼ºè§†è§‰Transformerçš„è¡¨ç¤ºï¼Œæå‡æœºå™¨äººæ“ä½œç­–ç•¥å­¦ä¹ æ•ˆç‡ã€‚|
|ğŸ“ æ›´æ–°|Human-Aligned Bench: Fine-Grained Assessment of Reasoning Ability in MLLMs vs. Humans|äººæœºå¯¹é½åŸºå‡†ï¼šå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸äººç±»æ¨ç†èƒ½åŠ›çš„ç»†ç²’åº¦è¯„ä¼°|Yansheng Qiu, Li Xiao, Zhaopan Xu, Pengfei Zhou, Zheng Wang, Kaipeng Zhang|<http://arxiv.org/pdf/2505.11141v2>|æå‡ºHuman-Aligned Benchï¼Œè¯„ä¼°MLLMåœ¨å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ä¸Šä¸äººç±»è¡¨ç°çš„ç»†å¾®å·®å¼‚ã€‚|
|ğŸ“ æ›´æ–°|LLaVA-ReID: Selective Multi-image Questioner for Interactive Person Re-Identification|LLaVA-ReIDï¼šäº¤äº’å¼è¡Œäººé‡è¯†åˆ«çš„é€‰ä¼˜å¤šå›¾åƒæé—®è€…|Yiding Lu, Mouxing Yang, Dezhong Peng, Peng Hu, Yijie Lin, Xi Peng|<http://arxiv.org/pdf/2504.10174v3>|åˆ†ç±»äº¤äº’å¼äººç‰©é‡è¯†åˆ«ï¼ŒLLaVA-ReIDé€šè¿‡ç”Ÿæˆé’ˆå¯¹æ€§é—®é¢˜æå‡è¯†åˆ«å‡†ç¡®ç‡ã€‚|


### è§†è§‰å†…å®¹æè¿° (Visual Content Description)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Little Data, Big Impact: Privacy-Aware Visual Language Models via Minimal Tuning|å°‘é‡æ•°æ®ï¼Œå·¨å¤§å½±å“ï¼šé€šè¿‡æœ€å°è°ƒæ•´å®ç°éšç§æ„ŸçŸ¥è§†è§‰è¯­è¨€æ¨¡å‹|Laurens Samson, Nimrod Barazani, Sennay Ghebreab, Yuki M. Asano|<http://arxiv.org/pdf/2405.17423v3>|é€šè¿‡æœ€å°æ•°æ®è°ƒæ•´ï¼Œè¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§éšç§æ„ŸçŸ¥è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†éšç§æ•æ„Ÿå†…å®¹çš„è¯†åˆ«èƒ½åŠ›ã€‚|


### å¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿ (Multimodal Dialogue Systems)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|VISTANet: VIsual Spoken Textual Additive Net for Interpretable Multimodal Emotion Recognition|VISTANetï¼šç”¨äºå¯è§£é‡Šå¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«çš„è§†è§‰è¯­éŸ³æ–‡æœ¬åŠ æ€§ç½‘ç»œ|Puneet Kumar, Sarthak Malik, Balasubramanian Raman, Xiaobai Li|<http://arxiv.org/pdf/2208.11450v4>|[ä»£ç ](https://github.com/MIntelligence-Group/MMEmoRec.); æå‡ºVISTANetï¼Œèåˆè§†è§‰ã€è¯­éŸ³å’Œæ–‡æœ¬ä¿¡æ¯ï¼Œå®ç°å¯è§£é‡Šçš„å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«ã€‚|


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|FairREAD: Re-fusing Demographic Attributes after Disentanglement for Fair Medical Image Classification|å…¬å¹³READï¼šè§£è€¦åé‡æ–°èåˆäººå£ç»Ÿè®¡å±æ€§ä»¥å®ç°å…¬å¹³åŒ»å­¦å›¾åƒåˆ†ç±»|Yicheng Gao, Jinkui Hao, Bo Zhou|<http://arxiv.org/pdf/2412.16373v2>|FairREADé€šè¿‡é‡æ–°èåˆè§£è€¦åçš„æ•æ„Ÿå±æ€§ï¼Œæ˜¾è‘—é™ä½åŒ»ç–—å›¾åƒåˆ†ç±»ä¸­çš„ä¸å…¬å¹³æ€§ï¼ŒåŒæ—¶ä¿æŒè¯Šæ–­å‡†ç¡®æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|MSLAU-Net: A Hybird CNN-Transformer Network for Medical Image Segmentation|MSLAU-Netï¼šä¸€ç§ç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²çš„æ··åˆCNN-Transformerç½‘ç»œ|Libin Lan, Yanxin Li, Xiaojuan Liu, Juan Zhou, Jianxun Zhang, Nannan Huang, Yudong Zhang|<http://arxiv.org/pdf/2505.18823v1>|[ä»£ç ](https://github.com/Monsoon49/MSLAU-Net.); æå‡ºMSLAU-Netï¼ŒèåˆCNNä¸Transformerä¼˜åŠ¿ï¼Œæœ‰æ•ˆæå‡åŒ»å­¦å›¾åƒåˆ†å‰²æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|Exploring QUIC Dynamics: A Large-Scale Dataset for Encrypted Traffic Analysis|æ¢ç´¢QUICåŠ¨æ€ï¼šç”¨äºåŠ å¯†æµé‡åˆ†æçš„å¤§è§„æ¨¡æ•°æ®é›†|Barak Gahtan, Robert J. Shahla, Alex M. Bronstein, Reuven Cohen|<http://arxiv.org/pdf/2410.03728v6>|æ„å»ºäº†å¤§è§„æ¨¡QUICæµé‡æ•°æ®é›†VisQUICï¼Œæ”¯æŒå¯æ§è§£å¯†å’Œæœºå™¨å­¦ä¹ åˆ†æï¼Œæ¨åŠ¨åŠ å¯†æµé‡ç ”ç©¶ã€‚|
|ğŸ†• å‘å¸ƒ|MoMBS: Mixed-order minibatch sampling enhances model training from diverse-quality images|MoMBSï¼šæ··åˆé˜¶æ•°å°æ‰¹é‡é‡‡æ ·æå‡ä»ä¸åŒè´¨é‡å›¾åƒä¸­çš„æ¨¡å‹è®­ç»ƒ|Han Li, Hu Han, S. Kevin Zhou|<http://arxiv.org/pdf/2505.18741v1>|æå‡ºMoMBSæ–¹æ³•ï¼Œé€šè¿‡æ··åˆé˜¶æ¬¡å°æ‰¹é‡é‡‡æ ·ä¼˜åŒ–ä¸åŒè´¨é‡è®­ç»ƒæ ·æœ¬çš„ä½¿ç”¨ã€‚|
|ğŸ†• å‘å¸ƒ|ReflectGAN: Modeling Vegetation Effects for Soil Carbon Estimation from Satellite Imagery|ReflectGANï¼šä»å«æ˜Ÿå›¾åƒä¸­å»ºæ¨¡æ¤è¢«æ•ˆåº”ä»¥ä¼°ç®—åœŸå£¤ç¢³å«é‡çš„æ–¹æ³•|Dristi Datta, Manoranjan Paul, Manzur Murshed, Shyh Wei Teng, Leigh M. Schmidtke|<http://arxiv.org/pdf/2505.18546v1>|ReflectGANé€šè¿‡é‡å»ºè£¸åœŸåå°„ç‡ï¼Œæœ‰æ•ˆæå‡äº†æ¤è¢«è¦†ç›–åŒºåœŸå£¤æœ‰æœºç¢³ä¼°ç®—çš„å‡†ç¡®æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|TK-Mamba: Marrying KAN with Mamba for Text-Driven 3D Medical Image Segmentation|TK-Mambaï¼šç»“åˆKANä¸Mambaè¿›è¡Œæ–‡æœ¬é©±åŠ¨3DåŒ»å­¦å›¾åƒåˆ†å‰²|Haoyu Yang, Yuxiang Cai, Jintao Chen, Xuhong Zhang, Wenhui Lei, Xiaoming Shi, Jianwei Yin, Yankai Jiang|<http://arxiv.org/pdf/2505.18525v1>|[ä»£ç ](https://github.com/yhy-whu/TK-Mamba.); ç»“åˆMambaå’ŒKANï¼Œæå‡ºäº†ä¸€ç§é«˜æ•ˆçš„å¤šæ¨¡æ€æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†3DåŒ»å­¦å›¾åƒåˆ†å‰²çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚|


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|L2RSI: Cross-view LiDAR-based Place Recognition for Large-scale Urban Scenes via Remote Sensing Imagery|L2RSIï¼šåŸºäºè·¨è§†å›¾æ¿€å…‰é›·è¾¾å’Œé¥æ„Ÿå›¾åƒçš„å¤§è§„æ¨¡åŸå¸‚åœºæ™¯å®šä½è¯†åˆ«|Ziwei Shi, Xiaoran Zhang, Yan Xia, Yu Zang, Siqi Shen, Cheng Wang|<http://arxiv.org/pdf/2503.11245v2>|[ä»£ç ](https://shizw695.github.io/L2RSI); æå‡ºäº†ä¸€ç§åˆ©ç”¨é¥æ„Ÿå›¾åƒè¿›è¡Œå¤§è§„æ¨¡åŸå¸‚åœºæ™¯æ¿€å…‰é›·è¾¾åœ°ç‚¹è¯†åˆ«çš„æ–°æ–¹æ³•ï¼Œæœ‰æ•ˆé™ä½äº†æˆæœ¬å¹¶æé«˜äº†å®šä½ç²¾åº¦ã€‚|
|ğŸ“ æ›´æ–°|RSTeller: Scaling Up Visual Language Modeling in Remote Sensing with Rich Linguistic Semantics from Openly Available Data and Large Language Models|RSTellerï¼šåˆ©ç”¨å…¬å¼€å¯ç”¨æ•°æ®å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œåœ¨é¥æ„Ÿé¢†åŸŸæ‰©å±•è§†è§‰è¯­è¨€æ¨¡å‹çš„è§„æ¨¡ï¼Œå¹¶ä¸°å¯Œè¯­è¨€è¯­ä¹‰|Junyao Ge, Xu Zhang, Yang Zheng, Kaitai Guo, Jimin Liang|<http://arxiv.org/pdf/2408.14744v4>|[ä»£ç ](https://github.com/SlytherinGe/RSTeller.); åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆè¯­ä¹‰ä¸°å¯Œçš„é¥æ„Ÿå›¾åƒæè¿°ï¼Œé™ä½æ ‡æ³¨æˆæœ¬ï¼Œæ¨åŠ¨è§†è§‰è¯­è¨€æ¨¡å‹å‘å±•ã€‚|


### åˆ›æ„åª’ä½“ç”Ÿæˆ (Creative Media Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ProphetDWM: A Driving World Model for Rolling Out Future Actions and Videos|ProphetDWMï¼šä¸€ç§ç”¨äºé¢„æµ‹æœªæ¥åŠ¨ä½œå’Œè§†é¢‘çš„é©¾é©¶ä¸–ç•Œæ¨¡å‹|Xiaodong Wang, Peixi Peng|<http://arxiv.org/pdf/2505.18650v1>|æå‡ºProphetDWMï¼Œä¸€ç§é¢„æµ‹æœªæ¥åŠ¨ä½œå’Œè§†é¢‘çš„é©¾é©¶ä¸–ç•Œæ¨¡å‹ï¼Œè§£å†³åŠ¨ä½œæ§åˆ¶å’Œé¢„æµ‹é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|HyperFake: Hyperspectral Reconstruction and Attention-Guided Analysis for Advanced Deepfake Detection|è¶…å‡ï¼šé«˜çº§æ·±åº¦ä¼ªé€ æ£€æµ‹çš„è¶…å…‰è°±é‡å»ºå’Œæ³¨æ„åŠ›å¼•å¯¼åˆ†æ|Pavan C Shekar, Pawan Soni, Vivek Kanhangad|<http://arxiv.org/pdf/2505.18587v1>|æå‡ºHyperFakeï¼Œé€šè¿‡é‡å»ºé«˜å…‰è°±æ•°æ®å¹¶åˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°æ›´ç²¾å‡†çš„æ·±åº¦ä¼ªé€ æ£€æµ‹ã€‚|


## æ–°å…´ç†è®ºä¸è·¨å­¦ç§‘æ–¹å‘ (Emerging Theory & Interdisciplinary Directions)


### é‡å­è§†è§‰ç®—æ³• (Quantum Visual Algorithms)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Vision Graph Prompting via Semantic Low-Rank Decomposition|åŸºäºè¯­ä¹‰ä½ç§©åˆ†è§£çš„è§†è§‰å›¾æç¤º|Zixiang Ai, Zichen Liu, Jiahuan Zhou|<http://arxiv.org/pdf/2505.04121v2>|[ä»£ç ](https://github.com/zhoujiahuan1991/ICML2025-VGP.); æå‡ºä¸€ç§åŸºäºè¯­ä¹‰ä½ç§©åˆ†è§£çš„è§†è§‰å›¾æç¤ºæ–¹æ³•ï¼Œæ˜¾è‘—æå‡è§†è§‰å›¾ç¥ç»ç½‘ç»œåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„è¿ç§»æ€§èƒ½ã€‚|

