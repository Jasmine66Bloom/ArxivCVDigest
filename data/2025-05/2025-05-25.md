## [UPDATED!] **2025-05-25** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Single Images to Motion Policies via Video-Generation Environment Representations|从单张图像到运动策略：通过视频生成环境表示|Weiming Zhi, Ziyong Ma, Tianyi Zhang, Matthew Johnson-Roberson|<http://arxiv.org/pdf/2505.19306v1>|提出VGER框架，从单张图像生成运动策略，实现无碰撞运动生成。|
|🆕 发布|Advancing Video Self-Supervised Learning via Image Foundation Models|通过图像基础模型推进视频自监督学习|Jingwei Wu, Zhewei Huang, Chang Liu|<http://arxiv.org/pdf/2505.19218v1>|[代码](https://github.com/JingwWu/advise-video-ssl.); 提出AdViSe方法，通过预训练图像基础模型和视频自监督学习，显著降低视频表示模型训练成本。|
|🆕 发布|CardioCoT: Hierarchical Reasoning for Multimodal Survival Analysis|CardioCoT：多模态生存分析的层次推理|Shaohao Rui, Haoyang Su, Jinyi Xiang, Lian-Ming Wu, Xiaosong Wang|<http://arxiv.org/pdf/2505.19195v1>|CardioCoT通过两阶段分层推理增强生存分析，提升心肌梗死患者心血管事件复发风险预测的准确性和可...|
|🆕 发布|I2MoE: Interpretable Multimodal Interaction-aware Mixture-of-Experts|I2MoE：可解释的多模态交互感知专家混合模型|Jiayi Xin, Sukwon Yun, Jie Peng, Inyoung Choi, Jenna L. Ballard, Tianlong Chen, Qi Long|<http://arxiv.org/pdf/2505.19190v1>|[代码](https://github.com/Raina-Xin/I2MoE.); I2MoE通过建模多模态交互并赋予解释性，提升了模态融合的性能和可解释性。|
|🆕 发布|ChartSketcher: Reasoning with Multimodal Feedback and Reflection for Chart Understanding|ChartSketcher：基于多模态反馈和反思的图表理解推理|Muye Huang, Lingling Zhang, Jie Ma, Han Lai, Fangzhi Xu, Yifei Li, Wenjun Wu, Yaqiang Wu .etc.|<http://arxiv.org/pdf/2505.19076v1>|ChartSketcher通过多模态反馈和反思，实现了图表理解的交互式和可解释性。|
|📝 更新|FLASH: Latent-Aware Semi-Autoregressive Speculative Decoding for Multimodal Tasks|FLASH：多模态任务中的潜在感知半自回归投机解码|Zihua Wang, Ruibo Li, Haozhe Du, Joey Tianyi Zhou, Yu Zhang, Xu Yang|<http://arxiv.org/pdf/2505.12728v2>|[代码](https://github.com/ZihuaEvan/FlashSD); 提出FLASH框架，通过利用多模态数据的特性加速多模态模型解码速度。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|The Eye of Sherlock Holmes: Uncovering User Private Attribute Profiling via Vision-Language Model Agentic Framework|《福尔摩斯的眼睛：通过视觉-语言模型代理框架揭示用户隐私属性分析》|Feiran Liu, Yuzhe Zhang, Xinyi Huang, Yinan Peng, Xinfeng Li, Lixu Wang, Yutong Shen, Ranjie Duan .etc.|<http://arxiv.org/pdf/2505.19139v1>|构建了PAPI数据集，提出HolmesEye框架，通过结合VLM和LLM提升图像隐私属性推断能力。|
|🆕 发布|Can Multimodal Large Language Models Understand Spatial Relations?|多模态大型语言模型能否理解空间关系？|Jingping Liu, Ziyan Liu, Zhedong Cen, Yan Zhou, Yinan Zou, Weiyan Zhang, Haiyun Jiang, Tong Ruan|<http://arxiv.org/pdf/2505.19015v1>|[代码](https://github.com/ziyan-xiaoyu/SpatialMQA.git.); 构建了SpatialMQA基准，提升多模态大语言模型对空间关系的理解能力。|
|🆕 发布|OpenHOI: Open-World Hand-Object Interaction Synthesis with Multimodal Large Language Model|开放世界手-物体交互合成：多模态大型语言模型|Zhenhao Zhang, Ye Shi, Lingxiao Yang, Suting Ni, Qi Ye, Jingya Wang|<http://arxiv.org/pdf/2505.18947v1>|OpenHOI通过融合多模态大语言模型和物理驱动的扩散模型，实现了开放世界手-物体交互的生成与优化。|
|🆕 发布|WeedNet: A Foundation Model-Based Global-to-Local AI Approach for Real-Time Weed Species Identification and Classification|WeedNet：基于基础模型的从全局到局部实时杂草种类识别与分类的AI方法|Yanben Shen, Timilehin T. Ayanlade, Venkata Naresh Boddepalli, Mojdeh Saadati, Ashlyn Rairdin, Zi K. Deng, Muhammad Arbab Arshad, Aditya Balu .etc.|<http://arxiv.org/pdf/2505.18930v1>|WeedNet提出了一种基于全局到局部策略的实时杂草识别模型，有效解决了杂草种类识别难题。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EDTformer: An Efficient Decoder Transformer for Visual Place Recognition|EDTformer：一种高效的视觉地点识别解码器Transformer|Tong Jin, Feng Lu, Shuyu Hu, Chun Yuan, Yunpeng Liu|<http://arxiv.org/pdf/2412.00784v2>|[代码](https://github.com/Tong-Jin01/EDTformer.); 提出EDTformer，一种高效解码器Transformer，显著提升视觉地点识别准确度。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|WaveGuard: Robust Deepfake Detection and Source Tracing via Dual-Tree Complex Wavelet and Graph Neural Networks|波盾：基于双树复小波和图神经网络的鲁棒深度伪造检测与溯源|Ziyuan He, Zhiqing Guo, Liejun Wang, Gaobo Yang, Yunfeng Diao, Dan Ma|<http://arxiv.org/pdf/2505.08614v3>|[代码](https://github.com/vpsg-research/WaveGuard.); WaveGuard通过双重树复波变换和图神经网络，实现了鲁棒的深度伪造检测和溯源。|
|📝 更新|PointOBB-v3: Expanding Performance Boundaries of Single Point-Supervised Oriented Object Detection|点OBB-v3：扩展单点监督定向目标检测的性能边界|Peiyuan Zhang, Junwei Luo, Xue Yang, Yi Yu, Qingyun Li, Yue Zhou, Xiaosong Jia, Xudong Lu .etc.|<http://arxiv.org/pdf/2501.13898v2>|[代码](https://github.com/ZpyWHU/PointOBB-v3.); PointOBB-v3通过结合多视角和自监督学习，显著提升了单点监督目标检测的准确率。|
|📝 更新|Rethinking Edge Detection through Perceptual Asymmetry: The SWBCE Loss|通过感知不对称性重新思考边缘检测：SWBCE 损失函数|Hao Shu|<http://arxiv.org/pdf/2501.13365v2>|提出SWBCE损失函数，通过利用人类边缘感知的不对称性，有效提升边缘检测的准确性和感知质量。|
|📝 更新|DMAGaze: Gaze Estimation Based on Feature Disentanglement and Multi-Scale Attention|DMAGaze：基于特征解耦和多尺度注意力的注视估计|Haohan Chen, Hongjia Liu, Shiyong Lan, Wenwu Wang, Yixin Qiao, Yao Li, Guonan Deng|<http://arxiv.org/pdf/2504.11160v2>|DMAGaze通过特征解耦和多尺度注意力机制，有效提升了基于面部图像的注视方向预测精度。|
|🆕 发布|Words as Geometric Features: Estimating Homography using Optical Character Recognition as Compressed Image Representation|《以词语为几何特征：利用光学字符识别作为压缩图像表示估计单应性》|Ross Greer, Alisha Ukani, Katherine Izhikevich, Earlence Fernandes, Stefan Savage, Alex C. Snoeren|<http://arxiv.org/pdf/2505.18925v1>|利用OCR输出作为特征，实现无需原始图像的文档对齐与注册。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Joint Learning Framework with Feature Reconstruction and Prediction for Incomplete Satellite Image Time Series in Agricultural Semantic Segmentation|农业语义分割中不完整卫星图像时间序列的特征重建与预测联合学习框架|Yuze Wang, Mariana Belgiu, Haiyang Wu, Dandan Zhong, Yangyang Cao, Chao Tao|<http://arxiv.org/pdf/2505.19159v1>|提出了一种结合特征重建和预测的框架，有效解决卫星图像时间序列不完整问题，提升农业语义分割性能。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SpecDETR: A Transformer-based Hyperspectral Point Object Detection Network|SpecDETR：一种基于Transformer的超光谱点目标检测网络|Zhaoxu Li, Wei An, Gaowei Guo, Longguang Wang, Yingqian Wang, Zaiping Lin|<http://arxiv.org/pdf/2405.10148v3>|[代码](https://github.com/ZhaoxuLi123/SpecDETR.); 提出了一种基于Transformer的专用于高光谱点目标检测的网络，显著提升了检测性能。|
|🆕 发布|Co-AttenDWG: Co-Attentive Dimension-Wise Gating and Expert Fusion for Multi-Modal Offensive Content Detection|协同注意力维度门控与专家融合的多模态攻击性内容检测|Md. Mithun Hossain, Md. Shakil Hossain, Sudipto Chaki, M. F. Mridha|<http://arxiv.org/pdf/2505.19010v1>|提出了一种融合多模态信息的新架构，通过协同注意和专家融合显著提升了恶意内容检测性能。|
|🆕 发布|A Smart Healthcare System for Monkeypox Skin Lesion Detection and Tracking|智能猴痘皮肤病变检测与追踪的健康系统|Huda Alghoraibi, Nuha Alqurashi, Sarah Alotaibi, Renad Alkhudaydi, Bdoor Aldajani, Lubna Alqurashi, Jood Batweel, Maha A. Thafar|<http://arxiv.org/pdf/2505.19023v1>|开发ITMAINN系统，利用深度学习技术从皮肤病变图像中检测猴痘，并提供症状追踪和医疗建议。|
|🆕 发布|VL-SAM-V2: Open-World Object Detection with General and Specific Query Fusion|VL-SAM-V2：基于通用和特定查询融合的开放世界目标检测|Zhiwei Lin, Yongtao Wang|<http://arxiv.org/pdf/2505.18986v1>|VL-SAM-V2融合开放集和开放端查询，实现开放世界物体检测，提升罕见物体识别性能。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SPARS: Self-Play Adversarial Reinforcement Learning for Segmentation of Liver Tumours|SPARS：用于肝脏肿瘤分割的自博弈对抗强化学习|Catalina Tan, Yipeng Hu, Shaheer U. Saeed|<http://arxiv.org/pdf/2505.18989v1>|提出SPARS，一种基于少量标注的弱监督学习方法，有效提高肝脏肿瘤分割的准确性。|
|📝 更新|NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification|新型探索：当智能体成为科学家——从假设到验证构建闭环系统|NovelSeek Team, Bo Zhang, Shiyang Feng, Xiangchao Yan, Jiakang Yuan, Zhiyin Yu, Xiaohan He, Songtao Huang .etc.|<http://arxiv.org/pdf/2505.16938v2>|NovelSeek构建了从假设到验证的闭环多智能体框架，实现跨领域自主科学研究，大幅提升研究效率和精...|


## 生成式视觉模型 (Generative Visual Modeling)


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GC-KBVQA: A New Four-Stage Framework for Enhancing Knowledge Based Visual Question Answering Performance|GC-KBVQA：一种提升基于知识视觉问答性能的新四阶段框架|Mohammad Mahdi Moradi, Sudhir Mudur|<http://arxiv.org/pdf/2505.19354v1>|提出GC-KBVQA框架，通过生成上下文丰富的描述和利用外部知识，显著提升基于知识的视觉问答性能。|
|🆕 发布|TextDiffuser-RL: Efficient and Robust Text Layout Optimization for High-Fidelity Text-to-Image Synthesis|文本扩散-强化学习：高效且鲁棒的高保真文本到图像合成文本布局优化|Kazi Mahathir Rahman, Showrin Rahman, Sharmin Sultana Srishty|<http://arxiv.org/pdf/2505.19291v1>|提出TextDiffuser-RL，通过结合强化学习优化文本布局，实现高效且鲁棒的文本到图像合成。|
|📝 更新|Super-Resolution Generative Adversarial Networks based Video Enhancement|基于超分辨率生成对抗网络的视频增强|Kağan ÇETİN|<http://arxiv.org/pdf/2505.10589v3>|提出了一种结合3D非局部块的视频超分辨率方法，有效提升了视频画质和连贯性。|
|🆕 发布|RAISE: Realness Assessment for Image Synthesis and Evaluation|RAISE：图像合成与评估的真实性评估|Aniruddha Mukherjee, Spriha Dubey, Somdyuti Paul|<http://arxiv.org/pdf/2505.19233v1>|构建了RAISE数据集，通过深度学习模型评估AI生成图像的真实感。|
|📝 更新|Recursive InPainting (RIP): how much information is lost under recursive inferences?|递归修复（RIP）：递归推理下损失了多少信息？|Javier Conde, Miguel González, Gonzalo Martínez, Fernando Moral, Elena Merino-Gómez, Pedro Reviriego|<http://arxiv.org/pdf/2407.09549v2>|评估了递归修复图像信息损失，揭示其可能导致图像退化。|
|📝 更新|Natural Language Generation from Visual Events: Challenges and Future Directions|从视觉事件生成自然语言：挑战与未来方向|Aditya K Surikuchi, Raquel Fernández, Sandro Pezzelle|<http://arxiv.org/pdf/2502.13034v2>|提出了一种基于视觉事件与语言特征建模的多模态自然语言生成方法，以解决视频或图像序列中的事件描述挑战。|
|🆕 发布|Towards Generalized Proactive Defense against Face Swappingwith Contour-Hybrid Watermark|面向基于轮廓混合水印的通用主动防御人脸交换|Ruiyang Xia, Dawei Zhou, Decheng Liu, Lin Yuan, Jie Li, Nannan Wang, Xinbo Gao|<http://arxiv.org/pdf/2505.19081v1>|提出了一种基于面部轮廓的混合水印技术，有效防御未知人脸交换攻击。|
|🆕 发布|Training-free Stylized Text-to-Image Generation with Fast Inference|无训练风格化文本到图像生成与快速推理|Xin Ma, Yaohui Wang, Xinyuan Chen, Tien-Tsin Wong, Cunjian Chen|<http://arxiv.org/pdf/2505.19063v1>|提出了一种无需训练的快速风格化文本到图像生成方法，显著提升风格化效果。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|One Step Diffusion via Shortcut Models|一步扩散通过捷径模型|Kevin Frans, Danijar Hafner, Sergey Levine, Pieter Abbeel|<http://arxiv.org/pdf/2410.12557v2>|提出了一种单网络一步扩散模型，通过跳过生成过程步骤，显著提升了图像生成速度和质量。|
|🆕 发布|Improving Novel view synthesis of 360$^\circ$ Scenes in Extremely Sparse Views by Jointly Training Hemisphere Sampled Synthetic Images|通过联合训练半球采样合成图像来提高极稀疏视图下360°场景的新视角合成|Guangan Chen, Anh Minh Truong, Hanhe Lin, Michiel Vlaminck, Wilfried Philips, Hiep Luong|<http://arxiv.org/pdf/2505.19264v1>|提出了一种基于半球采样和3D模型重建的360°场景稀疏视角新型视图合成方法，显著提升了合成图像质量。|
|📝 更新|CLIP-UP: A Simple and Efficient Mixture-of-Experts CLIP Training Recipe with Sparse Upcycling|CLIP-UP：一种简单高效的混合专家CLIP训练配方与稀疏升级回收|Xinze Wang, Chen Chen, Yinfei Yang, Hong-You Chen, Bowen Zhang, Aditya Pal, Xiangxin Zhu, Xianzhi Du|<http://arxiv.org/pdf/2502.00965v2>|提出CLIP-UP训练策略，高效将密集CLIP模型转化为稀疏MoE架构，显著降低训练复杂度和成本。|
|🆕 发布|Step-level Reward for Free in RL-based T2I Diffusion Model Fine-tuning|基于强化学习T2I扩散模型微调的免费步级奖励|Xinyao Liao, Wei Wei, Xiaoye Qu, Yu Cheng|<http://arxiv.org/pdf/2505.19196v1>|提出动态奖励分配框架，提升T2I扩散模型微调的样本效率和泛化能力。|
|🆕 发布|JEDI: The Force of Jensen-Shannon Divergence in Disentangling Diffusion Models|JEDI：Jensen-Shannon 散度在解耦扩散模型中的力量|Eric Tillmann Bill, Enis Simsar, Thomas Hofmann|<http://arxiv.org/pdf/2505.19166v1>|JEDI通过Jensen-Shannon散度优化，提升扩散模型在测试时的主题分离和组合对齐。|
|🆕 发布|Exploring Magnitude Preservation and Rotation Modulation in Diffusion Transformers|探索扩散变换器中的幅度保持和旋转调制|Eric Tillman Bill, Cristian Perez Jensen, Sotiris Anagnostidis, Dimitri von Rütte|<http://arxiv.org/pdf/2505.19122v1>|提出了一种基于幅度保持和旋转调制的扩散变换器设计，显著提升了训练稳定性和性能。|
|🆕 发布|MGD$^3$: Mode-Guided Dataset Distillation using Diffusion Models|MGD$^3$：基于扩散模型的模式引导数据蒸馏|Jeffrey A. Chan-Santiago, Praveen Tirupattur, Gaurav Kumar Nayak, Gaowen Liu, Mubarak Shah|<http://arxiv.org/pdf/2505.18963v1>|[代码](https://jachansantiago.github.io/mode-guided-distillation); 提出了一种无需微调的扩散模型，通过模式引导实现数据集蒸馏，显著降低训练成本并提升模型性能。|
|📝 更新|Towards user-centered interactive medical image segmentation in VR with an assistive AI agent|面向以用户为中心的VR辅助AI代理交互式医学图像分割|Pascal Spiegler, Arash Harirpoush, Yiming Xiao|<http://arxiv.org/pdf/2505.07214v3>|提出SAMIRA，一种结合VR和AI的交互式医疗图像分割系统，简化了医学图像处理流程。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Improving Compositional Generation with Diffusion Models Using Lift Scores|利用提升分数改进扩散模型在组合生成中的应用|Chenning Yu, Sicun Gao|<http://arxiv.org/pdf/2505.13740v2>|[代码](http://rainorangelemon.github.io/complift.); 利用提升分数改进扩散模型，提升组合生成样本与条件的一致性。|
|🆕 发布|Beyond Editing Pairs: Fine-Grained Instructional Image Editing via Multi-Scale Learnable Regions|超越编辑对：通过多尺度可学习区域进行细粒度指导图像编辑|Chenrui Ma, Xi Xiao, Tianyang Wang, Yanning Shen|<http://arxiv.org/pdf/2505.19352v1>|提出了一种基于多尺度可学习区域的细粒度图像编辑方法，显著提升了编辑精度和一致性。|
|🆕 发布|Enhancing Text-to-Image Diffusion Transformer via Split-Text Conditioning|通过分割文本条件增强文本到图像扩散Transformer|Yu Zhang, Jialei Zhou, Xinchen Li, Qi Zhang, Zhongwei Wan, Tianyu Wang, Duoqian Miao, Changwei Wang .etc.|<http://arxiv.org/pdf/2505.19261v1>|提出分文本条件框架DiT-ST，缓解扩散模型对完整文本理解缺陷，提升文本到图像生成质量。|
|📝 更新|Interspatial Attention for Efficient 4D Human Video Generation|空间间注意力在高效4D人体视频生成中的应用|Ruizhi Shao, Yinghao Xu, Yujun Shen, Ceyuan Yang, Yang Zheng, Changan Chen, Yebin Liu, Gordon Wetzstein|<http://arxiv.org/pdf/2505.15800v2>|[代码](https://dsaurus.github.io/isa4d); 引入 interspatial attention 机制，显著提升 4D 人类视频生成质量与一致性。|
|📝 更新|Inference-Time Scaling for Flow Models via Stochastic Generation and Rollover Budget Forcing|基于随机生成和回滚预算强制的流模型推理时间缩放|Jaihoon Kim, Taehoon Yoon, Jisung Hwang, Minhyuk Sung|<http://arxiv.org/pdf/2503.19385v3>|提出了一种基于SDE和RBF的流模型推理时间缩放方法，显著提升了生成样本质量。|
|🆕 发布|Towards Understanding the Mechanisms of Classifier-Free Guidance|迈向理解无分类器引导机制|Xiang Li, Rongrong Wang, Qing Qu|<http://arxiv.org/pdf/2505.19210v1>|揭示了无分类器引导机制，通过线性扩散模型分析其提升图像生成质量的三种成分。|
|📝 更新|DIAGen: Semantically Diverse Image Augmentation with Generative Models for Few-Shot Learning|DIAGen：基于生成模型的语义多样化图像增强用于小样本学习|Tobias Lingenberg, Markus Reuter, Gopika Sudhakaran, Dominik Gojny, Stefan Roth, Simone Schaub-Meyer|<http://arxiv.org/pdf/2408.14584v2>|DIAGen通过结合文本逆转换和生成模型，实现了语义丰富的图像增强，有效提升了少样本学习性能。|
|🆕 发布|Benchmarking Laparoscopic Surgical Image Restoration and Beyond|腹腔镜手术图像恢复基准测试及其超越|Jialun Pei, Diandian Guo, Donghui Yang, Zhixi Li, Yuxin Feng, Long Ma, Bo Du, Pheng-Ann Heng|<http://arxiv.org/pdf/2505.19161v1>|构建了SurgClean数据集，评估并改进了腹腔镜手术图像的修复算法。|
|🆕 发布|SRDiffusion: Accelerate Video Diffusion Inference via Sketching-Rendering Cooperation|SRDiffusion：通过草图-渲染协作加速视频扩散推理|Shenggan Cheng, Yuanxin Wei, Lansong Diao, Yong Liu, Bujiao Chen, Lianghua Huang, Yu Liu, Wenyuan Yu .etc.|<http://arxiv.org/pdf/2505.19151v1>|SRDiffusion通过大模型处理高噪声步骤保证语义和运动保真，小模型细化低噪声步骤的视觉细节，显...|
|🆕 发布|CreatiDesign: A Unified Multi-Conditional Diffusion Transformer for Creative Graphic Design|创意设计：一个统一的多条件扩散Transformer用于创意图形设计|Hui Zhang, Dexiang Hong, Maoke Yang, Yutao Chen, Zhao Zhang, Jie Shao, Xinglong Wu, Zuxuan Wu .etc.|<http://arxiv.org/pdf/2505.19114v1>|提出 CreatiDesign，一种统一的多条件扩散模型，解决创意图形设计中多条件控制难题。|
|🆕 发布|Plug-and-Play Context Feature Reuse for Efficient Masked Generation|可插拔上下文特征重用，实现高效掩码生成|Xuejie Liu, Anji Liu, Guy Van den Broeck, Yitao Liang|<http://arxiv.org/pdf/2505.19089v1>|提出ReCAP模块，通过复用特征嵌入加速掩码生成模型，在保持生成质量的同时显著降低推理成本。|
|📝 更新|Many Heads Are Better Than One: Improved Scientific Idea Generation by A LLM-Based Multi-Agent System|多头胜过单头：基于LLM的多智能体系统提升科学创意生成|Haoyang Su, Renqi Chen, Shixiang Tang, Zhenfei Yin, Xinzhe Zheng, Jinzhe Li, Biqing Qi, Qi Wu .etc.|<http://arxiv.org/pdf/2410.09403v3>|[代码](https://github.com/open-sciencelab/Virtual-Scientists.); 提出一种模拟团队合作的多智能体系统，显著提升基于LLM的科学创意生成能力。|
|🆕 发布|Jodi: Unification of Visual Generation and Understanding via Joint Modeling|视觉生成与理解的统一建模：Jodi|Yifeng Xu, Zhenliang He, Meina Kan, Shiguang Shan, Xilin Chen|<http://arxiv.org/pdf/2505.19084v1>|[代码](https://github.com/VIPL-GENUN/Jodi.); 提出Jodi，通过联合建模图像和标签域，实现视觉生成与理解的统一。|
|📝 更新|Drag Your Gaussian: Effective Drag-Based Editing with Score Distillation for 3D Gaussian Splatting|拖动你的高斯：基于拖动的高效编辑与分数蒸馏用于3D高斯喷溅|Yansong Qu, Dian Chen, Xinyang Li, Xiaofan Li, Shengchuan Zhang, Liujuan Cao, Rongrong Ji|<http://arxiv.org/pdf/2501.18672v6>|[代码](https://quyans.github.io/Drag-Your-Gaussian.); 提出了一种基于拖拽的3D场景编辑方法，通过控制点引导实现精确的几何和纹理编辑。|
|📝 更新|Barbie: Text to Barbie-Style 3D Avatars|芭比：文本到芭比风格的3D头像|Xiaokun Sun, Zhenyu Zhang, Ying Tai, Hao Tang, Zili Yi, Jian Yang|<http://arxiv.org/pdf/2408.09126v6>|[代码](https://xiaokunsun.github.io/Barbie.github.io); 提出Barbie，一种从文本生成具有分离鞋、配饰和服装的3D芭比娃娃风格动画角色的框架。|
|🆕 发布|WorldEval: World Model as Real-World Robot Policies Evaluator|世界评估：世界模型作为真实世界机器人策略评估器|Yaxuan Li, Yichen Zhu, Junjie Wen, Chaomin Shen, Yi Xu|<http://arxiv.org/pdf/2505.19017v1>|提出WorldEval，利用世界模型评估机器人策略，实现高效、可靠的在线评估。|
|📝 更新|FERGI: Automatic Scoring of User Preferences for Text-to-Image Generation from Spontaneous Facial Expression Reaction|FERGI：从自发面部表情反应自动评分用户偏好于文本到图像生成|Shuangquan Feng, Junhua Ma, Virginia R. de Sa|<http://arxiv.org/pdf/2312.03187v4>|[代码](https://github.com/ShuangquanFeng/FERGI); 开发了一种基于面部表情反应自动评分用户偏好的方法，以优化文本到图像生成模型。|
|📝 更新|GenAnalysis: Joint Shape Analysis by Learning Man-Made Shape Generators with Deformation Regularizations|GenAnalysis：通过学习变形正则化的手工形状生成器进行联合形状分析|Yuezhi Yang, Haitao Yang, Kiyohiro Nakayama, Xiangru Huang, Leonidas Guibas, Qixing Huang|<http://arxiv.org/pdf/2503.00807v2>|提出GenAnalysis，通过学习人工形状生成器并引入变形正则化，实现形状匹配和联合分割。|
|📝 更新|Self-Guidance: Boosting Flow and Diffusion Generation on Their Own|自我引导：提升自身在光流和扩散生成上的性能|Tiancheng Li, Weijian Luo, Zhiyang Chen, Liyuan Ma, Guo-Jun Qi|<http://arxiv.org/pdf/2412.05827v3>|提出Self-Guidance方法，无需额外训练即提升扩散和流模型生成图像质量。|
|📝 更新|Envisioning Beyond the Pixels: Benchmarking Reasoning-Informed Visual Editing|超越像素的想象：基于推理的视觉编辑基准测试|Xiangyu Zhao, Peiyuan Zhang, Kexian Tang, Xiaorong Zhu, Hao Li, Wenhao Chai, Zicheng Zhang, Xiaqiu Ren .etc.|<http://arxiv.org/pdf/2504.02826v3>|[代码](https://github.com/PhoenixZ810/RISEBench.); 构建RISEBench基准，评估推理驱动的视觉编辑，揭示现有模型在复杂指令理解和视觉一致性上的局限。|
|🆕 发布|How Do Images Align and Complement LiDAR? Towards a Harmonized Multi-modal 3D Panoptic Segmentation|图像如何与激光雷达对齐和互补？迈向和谐的多模态3D全景分割|Yining Pan, Qiongjie Cui, Xulei Yang, Na Zhao|<http://arxiv.org/pdf/2505.18956v1>|[代码](https://github.com/IMPL-Lab/IAL.git); 提出了一种融合图像与LiDAR数据的3D全景分割框架，有效解决了数据稀疏性和特征融合问题。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Alchemist: Turning Public Text-to-Image Data into Generative Gold|炼金术士：将公共文本到图像数据转化为生成性黄金|Valerii Startsev, Alexander Ustyuzhanin, Alexey Kirillov, Dmitry Baranchuk, Sergey Kastryulin|<http://arxiv.org/pdf/2505.19297v1>|提出一种利用预训练模型估算高影响样本的方法，构建了高效通用的T2I微调数据集Alchemist。|
|📝 更新|TheoremExplainAgent: Towards Video-based Multimodal Explanations for LLM Theorem Understanding|定理解释代理：迈向基于视频的多模态LLM定理理解|Max Ku, Thomas Chong, Jonathan Leung, Krish Shah, Alvin Yu, Wenhu Chen|<http://arxiv.org/pdf/2502.19400v2>|开发了一种基于代理的动画生成方法，为大型语言模型提供视频形式的定理解释，并构建了相应的评估基准。|
|📝 更新|Zero4D: Training-Free 4D Video Generation From Single Video Using Off-the-Shelf Video Diffusion|Zero4D：基于单视频的无监督4D视频生成|Jangho Park, Taesung Kwon, Jong Chul Ye|<http://arxiv.org/pdf/2503.22622v2>|提出了一种无需训练的4D视频生成方法，从单视频生成多视角视频。|
|🆕 发布|MIND-Edit: MLLM Insight-Driven Editing via Language-Vision Projection|MIND-Edit：基于语言-视觉投影的MLLM洞察驱动的编辑|Shuyu Wang, Weiqi Li, Qian Wang, Shijie Zhao, Jian Zhang|<http://arxiv.org/pdf/2505.19149v1>|MIND-Edit通过结合预训练扩散模型和MLLM，实现了基于语义理解的图像编辑，显著提升了编辑精度...|
|🆕 发布|STRICT: Stress Test of Rendering Images Containing Text|严格：包含文本的图像渲染压力测试|Tianyu Zhang, Xinyu Wang, Zhenghan Tai, Lu Li, Jijun Chi, Jingrui Tian, Hailin He, Suyuchen Wang|<http://arxiv.org/pdf/2505.18985v1>|[代码](https://github.com/tianyu-z/STRICT-Bench.); 提出STRICT基准，评估扩散模型在图像中渲染清晰可读文本的能力。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Triangle Splatting for Real-Time Radiance Field Rendering|实时辐射场渲染的三角形分层|Jan Held, Renaud Vandeghen, Adrien Deliege, Abdullah Hamdi, Silvio Giancola, Anthony Cioppa, Andrea Vedaldi, Bernard Ghanem .etc.|<http://arxiv.org/pdf/2505.19175v1>|提出了一种基于三角形的光照场实时渲染方法，显著提升了视觉效果和渲染效率。|
|📝 更新|3D Convex Splatting: Radiance Field Rendering with 3D Smooth Convexes|三维凸面块绘制：使用三维平滑凸面的辐射场渲染|Jan Held, Renaud Vandeghen, Abdullah Hamdi, Adrien Deliege, Anthony Cioppa, Silvio Giancola, Andrea Vedaldi, Bernard Ghanem .etc.|<http://arxiv.org/pdf/2411.14974v3>|提出3D Convex Splatting方法，有效解决3D场景重建中边缘捕捉和平面表示问题，提升渲...|
|📝 更新|Inductive Gradient Adjustment For Spectral Bias In Implicit Neural Representations|归纳梯度调整以解决隐式神经网络表示中的光谱偏差|Kexuan Shi, Hai Chen, Leheng Zhang, Shuhang Gu|<http://arxiv.org/pdf/2410.13271v2>|提出了一种针对隐式神经网络表示光谱偏差的归纳梯度调整方法，显著提升了纹理细节和边缘锐度。|
|📝 更新|From Flatland to Space: Teaching Vision-Language Models to Perceive and Reason in 3D|从平面到空间：教授视觉-语言模型感知和推理三维世界|Jiahui Zhang, Yurui Chen, Yanpeng Zhou, Yueming Xu, Ze Huang, Jilin Mei, Junhui Chen, Yu-Jie Yuan .etc.|<http://arxiv.org/pdf/2503.22976v4>|提出了一种利用空间相关图像数据增强视觉语言模型，提升其3D场景理解和推理能力的方法。|
|📝 更新|Towards Better Robustness: Pose-Free 3D Gaussian Splatting for Arbitrarily Long Videos|迈向更好的鲁棒性：适用于任意长视频的无姿态3D高斯分层|Zhen-Hui Dong, Sheng Ye, Yu-Hui Wen, Nannan Li, Yong-Jin Liu|<http://arxiv.org/pdf/2501.15096v2>|提出Rob-GS，通过连续帧跟踪和分段优化，实现任意长视频的鲁棒3D渲染。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EventEgoHands: Event-based Egocentric 3D Hand Mesh Reconstruction|基于事件的自我中心3D手部网格重建：EventEgoHands|Ryosei Hara, Wataru Ikeda, Masashi Hatano, Mariko Isogawa|<http://arxiv.org/pdf/2505.19169v1>|EventEgoHands通过引入手部分割模块，有效减轻动态背景事件影响，显著提升了基于事件相机的人...|
|🆕 发布|Disentangled Human Body Representation Based on Unsupervised Semantic-Aware Learning|基于无监督语义感知学习的解耦人体表示|Lu Wang, Xishuai Peng, S. Kevin Zhou|<http://arxiv.org/pdf/2505.19049v1>|提出了一种无监督语义感知学习方法，实现可控细粒度语义和精确的人体姿态重建。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VPGS-SLAM: Voxel-based Progressive 3D Gaussian SLAM in Large-Scale Scenes|基于体素的渐进式大规模场景3D高斯SLAM|Tianchen Deng, Wenhua Wu, Junjie He, Yue Pan, Xirui Jiang, Shenghai Yuan, Danwei Wang, Hesheng Wang .etc.|<http://arxiv.org/pdf/2505.18992v1>|[代码](https://github.com/dtc111111/vpgs-slam.); 提出VPGS-SLAM，首个适用于大规模场景的3D高斯SLAM框架，解决内存爆炸和位姿漂移问题。|


## 时序视觉分析 (Temporal Visual Analysis)


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BAH Dataset for Ambivalence/Hesitancy Recognition in Videos for Behavioural Change|BAH视频数据集：用于识别视频中行为改变的矛盾/犹豫|Manuela González-González, Soufiane Belharbi, Muhammad Osama Zeeshan, Masoumeh Sharafi, Muhammad Haseeb Aslam, Marco Pedersoli, Alessandro Lameiras Koerich, Simon L Bacon .etc.|<http://arxiv.org/pdf/2505.19328v1>|构建了首个用于视频情感识别的BAH数据集，以促进行为改变干预的个性化与有效性。|
|🆕 发布|PosePilot: An Edge-AI Solution for Posture Correction in Physical Exercises|姿态飞行员：一种边缘人工智能解决方案，用于体育锻炼中的姿势纠正|Rushiraj Gadhvi, Priyansh Desai, Siddharth|<http://arxiv.org/pdf/2505.19186v1>|PosePilot通过集成姿态识别和实时个性化纠正反馈，为健身系统中的姿态纠正提供了一种边缘AI解决...|
|📝 更新|Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding|银河漫步者：用于银河尺度理解的几何感知视觉语言模型|Tianyu Chen, Xingcheng Fu, Yisen Gao, Haodong Qian, Yuecen Wei, Kun Yan, Haoyi Zhou, Jianxin Li|<http://arxiv.org/pdf/2503.18578v3>|提出Galaxy-Walker，通过几何感知和自适应架构，实现宇宙级视觉理解，显著提升天体属性估计和...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Saliency-guided Emotion Modeling: Predicting Viewer Reactions from Video Stimuli|显著度引导的情绪建模：从视频刺激中预测观众反应|Akhila Yaragoppa, Siddharth|<http://arxiv.org/pdf/2505.19178v1>|利用视觉显著性特征，通过深度学习预测视频引起的观众情绪反应。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Sparse-to-Dense: A Free Lunch for Lossless Acceleration of Video Understanding in LLMs|稀疏到密集：LLMs中视频理解无损加速的免费午餐|Xuan Zhang, Cunxiao Du, Sicheng Yu, Jiawei Wu, Fengzhuo Zhang, Wei Gao, Qian Liu|<http://arxiv.org/pdf/2505.19155v1>|提出稀疏到密集解码策略，加速视频LLM处理，无损失提升效率。|
|🆕 发布|RTime-QA: A Benchmark for Atomic Temporal Event Understanding in Large Multi-modal Models|RTime-QA：大型多模态模型中原子时间事件理解的基准|Yuqi Liu, Qin Jin, Tianyuan Qu, Xuan Liu, Yang Du, Bei Yu, Jiaya Jia|<http://arxiv.org/pdf/2505.19125v1>|构建RTime-QA基准，评估大型多模态模型对原子时间事件的准确理解能力。|
|🆕 发布|Rethinking Metrics and Benchmarks of Video Anomaly Detection|重新思考视频异常检测的指标和基准|Zihao Liu, Xiaoyu Wu, Wenna Li, Linlin Yang|<http://arxiv.org/pdf/2505.19022v1>|重新审视视频异常检测评估方法，提出改进指标和基准以提升检测准确性和早期识别能力。|
|🆕 发布|NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results|NTIRE 2025视频会议视频质量增强挑战赛：数据集、方法和结果|Varun Jain, Zongwei Wu, Quan Zou, Louis Florentin, Henrik Turbell, Sandeep Siddhartha, Radu Timofte, others|<http://arxiv.org/pdf/2505.18988v1>|提出NTIRE 2025视频会议视频质量提升挑战，通过多种方法提升视频会议画质。|
|🆕 发布|Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency|基于几何引导的多视角时序一致性在线3D视频合成|Hyunho Ha, Lei Xiao, Christian Richardt, Thu Nguyen-Phuoc, Changil Kim, Min H. Kim, Douglas Lanman, Numair Khan|<http://arxiv.org/pdf/2505.18932v1>|提出了一种基于全局几何引导的在线3D视频合成方法，有效解决了多视角和时间一致性难题。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Learning Transformer-based World Models with Contrastive Predictive Coding|基于对比预测编码学习Transformer世界的模型|Maxime Burchi, Radu Timofte|<http://arxiv.org/pdf/2503.04416v2>|提出TWISTER，通过对比预测编码学习高级时间特征，显著提升Transformer世界模型性能。|
|🆕 发布|An Interpretable Representation Learning Approach for Diffusion Tensor Imaging|一种用于扩散张量成像的可解释表示学习方法|Vishwa Mohan Singh, Alberto Gaston Villagran Asiares, Luisa Sophie Schuhmacher, Kate Rendall, Simon Weißbrod, David Rügamer, Inga Körte|<http://arxiv.org/pdf/2505.19110v1>|提出了一种将DTI轨迹图编码为2D图像并学习可解释嵌入的方法，有效提升了下游任务性能。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Consistency-based Abductive Reasoning over Perceptual Errors of Multiple Pre-trained Models in Novel Environments|基于一致性的多预训练模型在新型环境感知错误中的归因推理|Mario Leiva, Noel Ngu, Joshua Shay Kricheli, Aditya Taparia, Ransalu Senanayake, Paulo Shakarian, Nathaniel Bastian, John Corcoran .etc.|<http://arxiv.org/pdf/2505.19361v1>|提出了一种基于一致性推理的框架，通过整合多个预训练模型来提高在新型环境中的感知模型性能。|
|🆕 发布|CoreMatching: A Co-adaptive Sparse Inference Framework with Token and Neuron Pruning for Comprehensive Acceleration of Vision-Language Models|核心匹配：一种用于视觉-语言模型全面加速的基于标记和神经元剪枝的协同自适应稀疏推理框架|Qinsi Wang, Hancheng Ye, Ming-Yu Chung, Yudong Liu, Yueqian Lin, Martin Kuo, Mingyuan Ma, Jianyi Zhang .etc.|<http://arxiv.org/pdf/2505.19235v1>|[代码](https://github.com/wangqinsi1/2025-ICML-CoreMatching); 提出CoreMatching框架，通过协同剪枝加速视觉语言模型推理。|
|🆕 发布|DISTA-Net: Dynamic Closely-Spaced Infrared Small Target Unmixing|DISTA-网：动态紧密间距红外小目标解混|Shengdong Han, Shangdong Yang, Xin Zhang, Yuxuan Li, Xiang Li, Jian Yang, Ming-Ming Cheng, Yimian Dai|<http://arxiv.org/pdf/2505.19148v1>|[代码](https://github.com/GrokCV/GrokCSO.); DISTA-Net提出动态框架解决红外密集小目标分离难题，首次实现高精度亚像素检测。|
|🆕 发布|Shifting AI Efficiency From Model-Centric to Data-Centric Compression|从模型中心到数据中心的AI效率转换|Xuyang Liu, Zichen Wen, Shaobo Wang, Junjie Chen, Zhishan Tao, Yubo Wang, Xiangqi Jin, Chang Zou .etc.|<http://arxiv.org/pdf/2505.19147v1>|将AI效率从模型压缩转向数据压缩，通过减少训练和推理中的token数量提升效率。|
|📝 更新|Efficient Lung Ultrasound Severity Scoring Using Dedicated Feature Extractor|高效使用专用特征提取器进行肺部超声严重程度评分|Jiaqi Guo, Yunan Wu, Evangelos Kaimakamis, Georgios Petmezas, Vasileios E. Papageorgiou, Nicos Maglaveras, Aggelos K. Katsaggelos|<http://arxiv.org/pdf/2501.12524v3>|提出MeDiVLAD，通过预训练和特征聚合，有效提升肺超声严重程度评分的准确性和效率。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PolyPose: Localizing Deformable Anatomy in 3D from Sparse 2D X-ray Images using Polyrigid Transforms|PolyPose：利用多刚体变换从稀疏二维X射线图像中定位3D可变形解剖结构|Vivek Gopalakrishnan, Neel Dey, Polina Golland|<http://arxiv.org/pdf/2505.19256v1>|PolyPose通过利用人体骨骼的刚性约束，实现了从稀疏X光片到3D解剖结构的准确定位。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RGC-Bent: A Novel Dataset for Bent Radio Galaxy Classification|RGC-Bent：一种用于弯曲射电星系分类的新型数据集|Mir Sazzat Hossain, Khan Muhammad Bin Asad, Payaswini Saikia, Adrita Khan, Md Akil Raihan Iftee, Rakibul Hasan Rajib, Arshad Momen, Md Ashraful Amin .etc.|<http://arxiv.org/pdf/2505.19249v1>|构建了针对弯曲射电星系分类的新数据集，并验证了深度学习模型的有效性。|
|🆕 发布|FHGS: Feature-Homogenized Gaussian Splatting|特征同质化高斯分层渲染|Q. G. Duan, Benyun Zhao, Mingqiao Han Yijun Huang, Ben M. Chen|<http://arxiv.org/pdf/2505.19154v1>|提出FHGS，通过特征融合和优化策略，解决3D场景中特征一致性不足的问题，实现高效渲染。|
|🆕 发布|Freqformer: Image-Demoiréing Transformer via Efficient Frequency Decomposition|Freqformer：基于高效频率分解的图像去摩尔纹Transformer|Xiaoyang Liu, Bolin Qiu, Jiezhang Cao, Zheng Chen, Yulun Zhang, Xiaokang Yang|<http://arxiv.org/pdf/2505.19120v1>|[代码](https://github.com/xyLiu339/Freqformer.); Freqformer通过高效频率分解，实现了图像去摩尔纹，显著提升了重建效果。|
|🆕 发布|ASPO: Adaptive Sentence-Level Preference Optimization for Fine-Grained Multimodal Reasoning|自适应句子级偏好优化用于细粒度多模态推理|Yeyuan Wang, Dehong Gao, Rujiao Long, Lei Yi, Linbo Jin, Libin Yang, Xiaoyan Cai|<http://arxiv.org/pdf/2505.19100v1>|提出ASPO方法，通过句子级自适应偏好优化，显著提升多模态推理的准确性。|
|🆕 发布|Less is More: Efficient Point Cloud Reconstruction via Multi-Head Decoders|少即是多：通过多头解码器实现高效的点云重建|Pedro Alonso, Tianrui Li, Chongshou Li|<http://arxiv.org/pdf/2505.19057v1>|提出多头解码器，通过输出多样性提升点云重建效率和准确性。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VerIPO: Cultivating Long Reasoning in Video-LLMs via Verifier-Gudied Iterative Policy Optimization|VerIPO：通过验证器引导的迭代策略优化培养视频-LLMs中的长推理|Yunxin Li, Xinyu Chen, Zitao Li, Zhenyu Liu, Longyue Wang, Wenhan Luo, Baotian Hu, Min Zhang|<http://arxiv.org/pdf/2505.19000v1>|提出VerIPO方法，通过验证器引导迭代策略优化，显著提升视频LLMs的长期推理能力。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|IT$^3$: Idempotent Test-Time Training|IT$^3$：幂等的测试时训练|Nikita Durasov, Assaf Shocher, Doruk Oner, Gal Chechik, Alexei A. Efros, Pascal Fua|<http://arxiv.org/pdf/2410.04201v2>|IT$^3$通过强制函数幂等性，实现仅用当前测试实例的实时适应分布偏移，提升模型泛化能力。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|On the status of current quantum machine learning software|当前量子机器学习软件的现状|Manish K. Gupta, Tomasz Rybotycki, Piotr Gawron|<http://arxiv.org/pdf/2503.08962v2>|研究量子机器学习软件在卫星图像分割中的应用，揭示其成本与模型质量变化。|
|📝 更新|Dynamic Angle Selection in X-Ray CT: A Reinforcement Learning Approach to Optimal Stopping|动态X射线CT角度选择：一种基于强化学习的最优停止方法|Tianyuan Wang, Felix Lucka, Daniël M. Pelt, K. Joost Batenburg, Tristan van Leeuwen|<http://arxiv.org/pdf/2503.12688v2>|提出了一种基于强化学习的动态角度选择方法，优化X射线CT扫描效率。|
|📝 更新|Without Paired Labeled Data: End-to-End Self-Supervised Learning for Drone-view Geo-Localization|无配对标注数据：无人机视角地理定位的端到端自监督学习|Zhongwei Chen, Zhao-Xu Yang, Hai-Jun Rong|<http://arxiv.org/pdf/2502.11381v3>|[代码](https://github.com/ISChenawei/DMNIL.); 提出了一种无需配对标签数据的无人机视角地理定位自监督学习方法，显著提升了定位精度。|
|🆕 发布|AmorLIP: Efficient Language-Image Pretraining via Amortization|AmorLIP：通过摊销的高效语言-图像预训练|Haotian Sun, Yitong Li, Yuchen Zhuang, Niao He, Hanjun Dai, Bo Dai|<http://arxiv.org/pdf/2505.18983v1>|AmorLIP通过轻量级神经网络实现高效CLIP预训练，显著提升训练效率和性能。|
|🆕 发布|LLM-Guided Taxonomy and Hierarchical Uncertainty for 3D Point CLoud Active Learning|基于LLM引导的3D点云主动学习分类与层次不确定性|Chenxi Li, Nuo Chen, Fengyun Tan, Yantong Chen, Bochun Yuan, Tianrui Li, Chongshou Li|<http://arxiv.org/pdf/2505.18924v1>|首次将大型语言模型应用于3D点云语义分割，构建层次标签结构并指导基于不确定性的样本选择，显著提升标注...|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GlobalGeoTree: A Multi-Granular Vision-Language Dataset for Global Tree Species Classification|全球GeoTree：一种用于全球树种分类的多粒度视觉-语言数据集|Yang Mu, Zhitong Xiong, Yi Wang, Muhammad Shahzad, Franz Essl, Mark van Kleunen, Xiao Xiang Zhu|<http://arxiv.org/pdf/2505.12513v2>|构建了全球多尺度视觉语言数据集，显著提升了树物种分类的零样本和少样本识别能力。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Do Vision-Language Models Really Understand Visual Language?|视觉-语言模型真的理解视觉语言吗？|Yifan Hou, Buse Giledereli, Yilei Tu, Mrinmaya Sachan|<http://arxiv.org/pdf/2410.00193v3>|开发测试套件评估大型视觉语言模型对图表的理解能力，揭示其理解关系的能力有限。|
|🆕 发布|Deformable Attentive Visual Enhancement for Referring Segmentation Using Vision-Language Model|可变形注意力视觉增强：基于视觉-语言模型的指称分割|Alaa Dalaq, Muzammil Behzad|<http://arxiv.org/pdf/2505.19242v1>|提出SegVLM模型，结合视觉语言模型和改进架构，提升指代表示图像分割的准确性和跨模态对齐。|
|📝 更新|ViEEG: Hierarchical Neural Coding with Cross-Modal Progressive Enhancement for EEG-Based Visual Decoding|ViEEG：基于EEG的视觉解码的层次化神经编码与跨模态渐进增强|Minxu Liu, Donghai Guan, Chuhang Zheng, Chunwei Tian, Jie Wen, Qi Zhu|<http://arxiv.org/pdf/2505.12408v2>|提出了一种基于视觉层次结构的EEG解码框架，显著提升了基于脑电的视觉解码性能。|
|🆕 发布|SATORI-R1: Incentivizing Multimodal Reasoning with Spatial Grounding and Verifiable Rewards|SATORI-R1：通过空间定位和可验证奖励激励多模态推理|Chuming Shen, Wei Wei, Xiaoye Qu, Yu Cheng|<http://arxiv.org/pdf/2505.19094v1>|[代码](https://github.com/justairr/SATORI-R1.); SATORI-R1通过空间定位和可验证奖励，解决VQA任务中推理链扩散和中间步骤不可验证的问题，显著...|
|🆕 发布|ReadBench: Measuring the Dense Text Visual Reading Ability of Vision-Language Models|阅读基准：评估视觉-语言模型的密集文本视觉阅读能力|Benjamin Clavié, Florian Brand|<http://arxiv.org/pdf/2505.19091v1>|[代码](https://github.com/answerdotai/ReadBench); ReadBench评估VLMs阅读理解能力，揭示其处理长文本图像的不足。|
|🆕 发布|InfoChartQA: A Benchmark for Multimodal Question Answering on Infographic Charts|信息图表问答基准：信息图表上的多模态问答基准|Minzhi Lin, Tianchi Xie, Mengchen Liu, Yilin Ye, Changjian Chen, Shixia Liu|<http://arxiv.org/pdf/2505.19028v1>|[代码](https://github.com/CoolDawnAnt/InfoChartQA.); 构建了InfoChartQA基准，评估多模态大语言模型在理解信息图表方面的能力。|
|📝 更新|Visual Program Distillation with Template-Based Augmentation|基于模板增强的视觉程序蒸馏|Michal Shlapentokh-Rothman, Yu-Xiong Wang, Derek Hoiem|<http://arxiv.org/pdf/2412.08564v3>|提出了一种基于模板和参数分离的低成本视觉程序蒸馏方法，有效降低视觉编程的标注和推理成本。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Describe Anything in Medical Images|在医学图像中描述任何内容|Xi Xiao, Yunbei Zhang, Thanh-Huy Nguyen, Ba-Thinh Lam, Janet Wang, Lin Zhao, Jihun Hamm, Tianyang Wang .etc.|<http://arxiv.org/pdf/2505.05804v2>|提出MedDAM框架，首次利用大型视觉语言模型在医学图像中进行区域特定描述，提升医学图像理解。|
|📝 更新|Part-aware Prompted Segment Anything Model for Adaptive Segmentation|基于部分感知的提示式Segment Anything模型用于自适应分割|Chenhui Zhao, Liyue Shen|<http://arxiv.org/pdf/2403.05433v2>|[代码](https://github.com/Zch0414/p2sam); 提出了一种无需模型微调的Part-aware Prompted Segment Anything M...|
|🆕 发布|DriveX: Omni Scene Modeling for Learning Generalizable World Knowledge in Autonomous Driving|DriveX：自动驾驶中的全场景建模以学习可泛化世界知识|Chen Shi, Shaoshuai Shi, Kehua Sheng, Bo Zhang, Li Jiang|<http://arxiv.org/pdf/2505.19239v1>|DriveX通过统一多模态监督和自监督学习，构建了一个通用的场景模型，显著提升了自动驾驶中的场景预测...|
|🆕 发布|Domain and Task-Focused Example Selection for Data-Efficient Contrastive Medical Image Segmentation|领域和任务导向的示例选择以提高数据高效对比医学图像分割的效率|Tyler Ward, Aaron Moseley, Abdullah-Al-Zubaer Imran|<http://arxiv.org/pdf/2505.19208v1>|[代码](https://github.com/tbwa233/PolyCL.); 提出了一种基于自监督学习的医疗图像分割方法，通过选择相关示例和结合SAM模型，有效提升了低数据场景下...|
|🆕 发布|MedITok: A Unified Tokenizer for Medical Image Synthesis and Interpretation|MedITok：医学图像合成与解释的统一分词器|Chenglong Ma, Yuanfeng Ji, Jin Ye, Zilong Li, Chenhui Wang, Junzhi Ning, Wei Li, Lihao Liu .etc.|<http://arxiv.org/pdf/2505.19225v1>|[代码](https://github.com/Masaaki-75/meditok.); MedITok提出首个针对医学图像的统一分词器，实现图像重建与合成及诊断与解释的统一语义表示。|
|🆕 发布|MMP-2K: A Benchmark Multi-Labeled Macro Photography Image Quality Assessment Database|MMP-2K：一个基准多标签宏观摄影图像质量评估数据库|Jiashuo Chang, Zhengyi Li, Jianxun Lou, Zhen Qiu, Hanhe Lin|<http://arxiv.org/pdf/2505.19065v1>|[代码](https://github.com/Future-IQA/MMP-2k.); 构建了MMP-2K数据库，为宏观摄影图像质量评估提供大规模数据集。|
|🆕 发布|Medical Large Vision Language Models with Multi-Image Visual Ability|医学大视觉语言模型与多图像视觉能力|Xikai Yang, Juzheng Miao, Yuchen Yuan, Jiaze Wang, Qi Dou, Jinpeng Li, Pheng-Ann Heng|<http://arxiv.org/pdf/2505.19031v1>|提出Med-MIM数据集和模型，提升医学大视觉语言模型的多图像理解能力。|
|📝 更新|Alberta Wells Dataset: Pinpointing Oil and Gas Wells from Satellite Imagery|阿尔伯塔韦尔斯数据集：从卫星图像中精确识别油气井|Pratinav Seth, Michelle Lin, Brefo Dwamena Yaw, Jade Boutot, Mary Kang, David Rolnick|<http://arxiv.org/pdf/2410.09032v3>|构建了首个大规模基准数据集，利用卫星图像识别全球废弃油气井。|
|🆕 发布|CDPDNet: Integrating Text Guidance with Hybrid Vision Encoders for Medical Image Segmentation|CDPDNet：结合文本引导与混合视觉编码器进行医学图像分割|Jiong Wu, Yang Xing, Boxiao Yu, Wei Shao, Kuang Gong|<http://arxiv.org/pdf/2505.18958v1>|[代码](https://github.com/wujiong-hub/CDPDNet.git.); CDPDNet通过结合文本指导和混合视觉编码器，有效提升了医学图像分割的准确性和泛化能力。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Glioma Multimodal MRI Analysis System for Tumor Layered Diagnosis via Multi-task Semi-supervised Learning|胶质瘤多模态MRI分析系统：基于多任务半监督学习的肿瘤分层诊断|Yihao Liu, Zhihao Cui, Liming Li, Junjie You, Xinle Feng, Jianxin Wang, Xiangyu Wang, Qing Liu .etc.|<http://arxiv.org/pdf/2501.17758v2>|提出了一种基于多任务半监督学习的脑胶质瘤多模态MRI分析系统，提高了肿瘤分层诊断的精度。|
|🆕 发布|Are Vision Language Models Ready for Clinical Diagnosis? A 3D Medical Benchmark for Tumor-centric Visual Question Answering|视觉语言模型是否已准备好进行临床诊断？一个以肿瘤为中心的3D医学视觉问答基准|Yixiong Chen, Wenjie Xiao, Pedro R. A. S. Bassi, Xinze Zhou, Sezgin Er, Ibrahim Ethem Hamamci, Zongwei Zhou, Alan Yuille|<http://arxiv.org/pdf/2505.18915v1>|[代码](https://github.com/Schuture/DeepTumorVQA.); 构建了DeepTumorVQA基准，评估VLM在3D医学诊断中的表现，发现当前模型在肿瘤识别和推理上...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Remote Sensing Image Classification with Decoupled Knowledge Distillation|基于解耦知识蒸馏的遥感图像分类|Yaping He, Jianfeng Cai, Qicong Hu, Peiqing Wang|<http://arxiv.org/pdf/2505.19111v1>|提出一种基于知识蒸馏的轻量级遥感图像分类方法，显著降低模型参数，提升分类精度。|
|🆕 发布|Kernel Space Diffusion Model for Efficient Remote Sensing Pansharpening|核空间扩散模型在高效遥感全色融合中的应用|Hancong Jin, Zihan Cao, Liangjian Deng|<http://arxiv.org/pdf/2505.18991v1>|提出了一种基于核空间扩散模型的遥感图像融合方法，有效提升了融合图像质量和推理速度。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Echo Planning for Autonomous Driving: From Current Observations to Future Trajectories and Back|自动驾驶中的回声规划：从当前观测到未来轨迹及返回|Jintao Sun, Hu Zhang, Gangyi Ding, Zhedong Zheng|<http://arxiv.org/pdf/2505.18945v1>|Echo Planning通过建立CFC循环，实现自动驾驶中预测轨迹与场景动态的时序一致性，有效减少...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AnchorFormer: Differentiable Anchor Attention for Efficient Vision Transformer|锚前驱器：用于高效视觉变换器的可微分锚注意力|Jiquan Shan, Junxiao Wang, Lifeng Zhao, Liang Cai, Hongyuan Zhang, Ioannis Liritzis|<http://arxiv.org/pdf/2505.16463v2>|提出AnchorFormer，通过锚点注意力机制降低视觉Transformer的计算复杂度，提升下游...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Veta-GS: View-dependent deformable 3D Gaussian Splatting for thermal infrared Novel-view Synthesis|Veta-GS：基于视点依赖的变形3D高斯分层用于热红外新视角合成|Myeongseok Nam, Wongi Park, Minsol Kim, Hyejin Hur, Soomok Lee|<http://arxiv.org/pdf/2505.19138v1>|Veta-GS通过引入视依赖变形场和热特征提取器，有效解决了热红外图像新视角合成中的模糊和漂移问题。|
|🆕 发布|Holistic White-light Polyp Classification via Alignment-free Dense Distillation of Auxiliary Optical Chromoendoscopy|整体白光息肉分类：通过辅助光学染色内镜的无对齐密集蒸馏|Qiang Hu, Qimei Wang, Jia Chen, Xuantao Ji, Qiang Li, Zhiwei Wang|<http://arxiv.org/pdf/2505.19319v1>|[代码](https://github.com/Huster-Hq/ADD.); 提出了一种无需对齐的密集蒸馏方法，通过全图诊断提高白光图像息肉分类性能。|

