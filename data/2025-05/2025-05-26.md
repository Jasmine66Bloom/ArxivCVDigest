## [UPDATED!] **2025-05-26** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hard Negative Contrastive Learning for Fine-Grained Geometric Understanding in Large Multimodal Models|硬负对比学习在大型多模态模型中实现细粒度几何理解|Kai Sun, Yushi Bai, Zhen Yang, Jiajie Zhang, Ji Qi, Lei Hou, Juanzi Li|<http://arxiv.org/pdf/2505.20152v1>|[代码](https://github.com/THU-KEG/MMGeoLM.); 提出了一种结合图像和文本对比学习的框架，显著提升了大型多模态模型在几何问题解决上的能力。|
|🆕 发布|FUDOKI: Discrete Flow-based Unified Understanding and Generation via Kinetic-Optimal Velocities|FUDOKI：基于离散流的统一理解和生成通过动力学最优速度|Jin Wang, Yao Lai, Aoxue Li, Shifeng Zhang, Jiacheng Sun, Ning Kang, Chengyue Wu, Zhenguo Li .etc.|<http://arxiv.org/pdf/2505.20147v1>|FUDOKI通过离散流匹配挑战了基于自回归架构的多模态模型，实现了视觉理解和图像生成的统一。|
|📝 更新|Time-VLM: Exploring Multimodal Vision-Language Models for Augmented Time Series Forecasting|时间-视觉语言模型：探索多模态视觉-语言模型用于增强时间序列预测|Siru Zhong, Weilin Ruan, Ming Jin, Huan Li, Qingsong Wen, Yuxuan Liang|<http://arxiv.org/pdf/2502.04395v2>|[代码](https://github.com/CityMind-Lab/ICML25-TimeVLM.); 提出Time-VLM，通过融合视觉、文本和时序信息，显著提升时间序列预测的准确性。|
|📝 更新|WorldSense: Evaluating Real-world Omnimodal Understanding for Multimodal LLMs|标题翻译：世界感知：评估多模态LLMs的实世界全模态理解|Jack Hong, Shilin Yan, Jiayin Cai, Xiaolong Jiang, Yao Hu, Weidi Xie|<http://arxiv.org/pdf/2502.04326v2>|WorldSense构建首个多模态视频理解基准，评估模型在构建和解析多模态上下文中的能力。|
|📝 更新|Multimodal 3D Reasoning Segmentation with Complex Scenes|多模态复杂场景3D推理分割|Xueying Jiang, Lewei Lu, Ling Shao, Shijian Lu|<http://arxiv.org/pdf/2411.13927v3>|提出了一种针对复杂场景中多物体推理分割的新方法，显著提升了3D场景理解能力。|
|🆕 发布|ScienceBoard: Evaluating Multimodal Autonomous Agents in Realistic Scientific Workflows|科学板：评估在现实科学工作流程中的多模态自主智能体|Qiushi Sun, Zhoumianze Liu, Chang Ma, Zichen Ding, Fangzhi Xu, Zhangyue Yin, Haiteng Zhao, Zhenyu Wu .etc.|<http://arxiv.org/pdf/2505.19897v1>|[代码](https://qiushisun.github.io/ScienceBoard-Home); ScienceBoard构建了真实科学工作流程环境，提出基准测试，评估多模态自主代理在科学发现中的表...|
|🆕 发布|FruitNeRF++: A Generalized Multi-Fruit Counting Method Utilizing Contrastive Learning and Neural Radiance Fields|水果NeRF++：一种利用对比学习和神经辐射场的通用多水果计数方法|Lukas Meyer, Andrei-Timotei Ardelean, Tim Weyrich, Marc Stamminger|<http://arxiv.org/pdf/2505.19863v1>|FruitNeRF++通过结合对比学习和神经辐射场，实现了一种通用的多水果计数方法，无需针对每种水果...|
|🆕 发布|MLLM-Guided VLM Fine-Tuning with Joint Inference for Zero-Shot Composed Image Retrieval|基于MLLM引导的联合推理VLM微调用于零样本组合图像检索|Rong-Cheng Tu, Zhao Jin, Jingyi Liao, Xiao Luo, Yingjie Wang, Li Shen, Dacheng Tao|<http://arxiv.org/pdf/2505.19707v1>|提出一种基于MLLM引导的VLM微调方法，通过联合推理提升零样本组合图像检索性能。|
|📝 更新|CauSkelNet: Causal Representation Learning for Human Behaviour Analysis|因果骨骼网络：用于人类行为分析的因果表示学习|Xingrui Gu, Chuyi Jiang, Erte Wang, Zekun Wu, Qiang Cui, Leimin Tian, Lianlong Wu, Siyang Song .etc.|<http://arxiv.org/pdf/2409.15564v3>|提出因果推理框架，结合PC算法和KL散度，提升人体行为分析准确性和可解释性。|
|📝 更新|Beyond One-Hot Labels: Semantic Mixing for Model Calibration|超越单热标签：模型校准的语义混合|Haoyang Luo, Linwei Tao, Minjing Dong, Chang Xu|<http://arxiv.org/pdf/2504.13548v2>|[代码](https://github.com/E-Galois/CSM); 提出了一种基于语义混合的数据增强方法，显著提升了模型校准的准确性。|
|🆕 发布|Aggregated Structural Representation with Large Language Models for Human-Centric Layout Generation|基于大型语言模型的人中心布局生成中的聚合结构表示|Jiongchao Jin, Shengchu Zhao, Dajun Chen, Wei Jiang, Yong Li|<http://arxiv.org/pdf/2505.19554v1>|提出ASR模块，结合图网络和大型语言模型，实现结构信息保留和布局生成能力提升。|
|🆕 发布|A Contrastive Learning Foundation Model Based on Perfectly Aligned Sample Pairs for Remote Sensing Images|基于完美对齐样本对的遥感图像对比学习基础模型|Hengtong Shen, Haiyan Gu, Haitao Li, Yi Yang, Agen qiu|<http://arxiv.org/pdf/2505.19447v1>|提出了一种基于完美对齐样本对的对比学习方法，有效提升了遥感图像特征提取性能。|
|📝 更新|Mirror: Multimodal Cognitive Reframing Therapy for Rolling with Resistance|镜像：应对抵抗的多模态认知重构疗法|Subin Kim, Hoonrae Kim, Jihyun Lee, Yejin Jeon, Gary Geunbae Lee|<http://arxiv.org/pdf/2504.13211v2>|提出Mirror数据集，结合非言语线索，提升AI心理治疗师应对客户抵抗的能力。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Data to Modeling: Fully Open-vocabulary Scene Graph Generation|从数据到建模：全开放词汇场景图生成|Zuyao Chen, Jinlin Wu, Zhen Lei, Chang Wen Chen|<http://arxiv.org/pdf/2505.20106v1>|提出OvSGTR，一种基于Transformer的开放词汇场景图生成框架，突破传统模型限制，实现更广...|
|📝 更新|X-GRM: Large Gaussian Reconstruction Model for Sparse-view X-rays to Computed Tomography|X-GRM：用于稀疏视图X射线到计算机断层扫描的大高斯重建模型|Yifan Liu, Wuyang Li, Weihao Yu, Chenxin Li, Alexandre Alahi, Max Meng, Yixuan Yuan|<http://arxiv.org/pdf/2505.15235v2>|[代码](https://github.com/CUHK-AIM-Group/X-GRM.); 提出X-GRM模型，通过大规模Transformer架构和灵活的体积表示，高效重建稀疏X射线投影的3...|
|🆕 发布|ViTaPEs: Visuotactile Position Encodings for Cross-Modal Alignment in Multimodal Transformers|ViTaPEs：多模态Transformer中跨模态对齐的视觉触觉位置编码|Fotios Lygerakis, Ozan Özdenizci, Elmar Rückert|<http://arxiv.org/pdf/2505.20032v1>|ViTaPEs通过引入多尺度位置编码，实现了视觉和触觉数据的鲁棒融合，提升了跨模态感知能力。|
|🆕 发布|Structured Initialization for Vision Transformers|结构化初始化用于视觉Transformer|Jianqiao Zheng, Xueqian Li, Hemanth Saratchandran, Simon Lucey|<http://arxiv.org/pdf/2505.19985v1>|提出了一种通过初始化策略将CNN的归纳偏置融入ViT，显著提升小数据集上ViT性能的方法。|
|🆕 发布|Attention! You Vision Language Model Could Be Maliciously Manipulated|注意！您的视觉语言模型可能被恶意操纵|Xiaosen Wang, Shaokang Wang, Zhijin Ge, Yuyang Luo, Shudong Zhang|<http://arxiv.org/pdf/2505.19911v1>|提出VMA攻击，揭示视觉语言模型易受图像对抗攻击，同时实现版权保护和多种攻击。|
|🆕 发布|Dynamic-I2V: Exploring Image-to-Video Generaion Models via Multimodal LLM|动态-I2V：通过多模态大型语言模型探索图像到视频生成模型|Peng Liu, Xiaoming Ren, Fengkai Liu, Qingsong Xie, Quanlong Zheng, Yanhao Zhang, Haonan Lu, Yujiu Yang|<http://arxiv.org/pdf/2505.19901v1>|Dynamic-I2V通过整合多模态LLM，显著提升了视频生成中的动态范围和可控性。|
|🆕 发布|The Missing Point in Vision Transformers for Universal Image Segmentation|视觉Transformer在通用图像分割中的缺失点|Sajjad Shahabodini, Mobina Mansoori, Farnoush Bayatmakou, Jamshid Abouei, Konstantinos N. Plataniotis, Arash Mohammadi|<http://arxiv.org/pdf/2505.19795v1>|[代码](https://github.com/sajjad-sh33/ViT-P); 提出ViT-P，一种两阶段分割框架，通过解耦掩码生成与分类，实现图像分割性能提升。|
|📝 更新|Explanatory Instructions: Towards Unified Vision Tasks Understanding and Zero-shot Generalization|解释性指令：迈向统一视觉任务理解和零样本泛化|Yang Shen, Xiu-Shen Wei, Yifan Sun, Yuxin Song, Tao Yuan, Jian Jin, Heyang Xu, Yazhou Yao .etc.|<http://arxiv.org/pdf/2412.18525v3>|通过引入解释性指令，该论文提出了一种新的方法，使计算机视觉模型能够实现跨任务理解和零样本泛化。|
|🆕 发布|TESSER: Transfer-Enhancing Adversarial Attacks from Vision Transformers via Spectral and Semantic Regularization|TESSER：通过频谱和语义正则化的视觉Transformer迁移增强对抗攻击|Amira Guesmi, Bassem Ouni, Muhammad Shafique|<http://arxiv.org/pdf/2505.19613v1>|TESSER通过特征敏感梯度缩放和光谱平滑正则化，显著提升了视觉Transformer对抗攻击的迁移...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EmoNet-Face: An Expert-Annotated Benchmark for Synthetic Emotion Recognition|EmoNet-Face：合成情绪识别的专家标注基准|Christoph Schuhmann, Robert Kaczmarczyk, Gollam Rabby, Maurice Kraus, Felix Friedrich, Huu Nguyen, Krishna Kalyan, Kourosh Nadi .etc.|<http://arxiv.org/pdf/2505.20033v1>|构建了EmoNet Face基准，提供更细粒度的情绪分类和高质量数据集，以促进合成情绪识别研究。|
|🆕 发布|StyleAR: Customizing Multimodal Autoregressive Model for Style-Aligned Text-to-Image Generation|风格AR：定制多模态自回归模型以实现风格对齐的文本到图像生成|Yi Wu, Lingting Zhu, Shengju Qian, Lei Liu, Wandi Qiao, Lequan Yu, Bin Li|<http://arxiv.org/pdf/2505.19874v1>|提出StyleAR，通过数据定制和AR模型，实现风格对齐的文本到图像生成。|
|🆕 发布|Advancements in Medical Image Classification through Fine-Tuning Natural Domain Foundation Models|通过微调自然领域基础模型在医学图像分类中的进展|Mobina Mansoori, Sajjad Shahabodini, Farnoush Bayatmakou, Jamshid Abouei, Konstantinos N. Plataniotis, Arash Mohammadi|<http://arxiv.org/pdf/2505.19779v1>|[代码](https://github.com/sajjad-sh33/Medical-Transfer-Learning.); 通过微调自然领域基础模型，显著提升了医学图像分类的准确性和效率。|
|🆕 发布|Modeling Beyond MOS: Quality Assessment Models Must Integrate Context, Reasoning, and Multimodality|超越MOS：质量评估模型必须整合上下文、推理和多模态|Mohamed Amine Kerkouri, Marouane Tliba, Aladine Chetouani, Nour Aburaed, Alessandro Bruno|<http://arxiv.org/pdf/2505.19696v1>|提出新方法，将质量评估模型从单一MOS评分扩展至融合情境、推理和多模态信息。|
|📝 更新|DiMeR: Disentangled Mesh Reconstruction Model|DiMeR：解耦网格重建模型|Lutao Jiang, Jiantao Lin, Kanghao Chen, Wenhang Ge, Xin Yang, Yifan Jiang, Yuanhuiyi Lyu, Xu Zheng .etc.|<http://arxiv.org/pdf/2504.17670v2>|DiMeR通过分离几何和纹理，结合3D监督，有效解决了稀疏视图网格重建中的几何错误和冗余提取问题。|
|📝 更新|Unlocking Text Capabilities in Vision Models|解锁视觉模型中的文本能力|Fawaz Sammani, Jonas Fischer, Nikos Deligiannis|<http://arxiv.org/pdf/2503.10981v2>|提出了一种将视觉模型与文本结合的方法，实现无标签、零样本的可解释性应用。|
|🆕 发布|Diagnosing and Mitigating Modality Interference in Multimodal Large Language Models|诊断和缓解多模态大型语言模型中的模态干扰|Rui Cai, Bangzheng Li, Xiaofei Wen, Muhao Chen, Zhe Zhao|<http://arxiv.org/pdf/2505.19616v1>|提出了一种针对多模态大语言模型中模态干扰问题的诊断和缓解框架，显著提升了模型在单模态和多模态任务上的...|
|📝 更新|Dimple: Discrete Diffusion Multimodal Large Language Model with Parallel Decoding|Dimple：具有并行解码的离散扩散多模态大型语言模型|Runpeng Yu, Xinyin Ma, Xinchao Wang|<http://arxiv.org/pdf/2505.16990v2>|[代码](https://github.com/yu-rp/Dimple.); 提出Dimple模型，结合自回归和扩散训练，提升DMLLM性能并优化解码效率。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RapidPoseTriangulation: Multi-view Multi-person Whole-body Human Pose Triangulation in a Millisecond|快速姿态三角测量：毫秒级的多视角多人全身人体姿态三角测量|Daniel Bermuth, Alexander Poeppel, Wolfgang Reif|<http://arxiv.org/pdf/2503.21692v2>|提出快速三角测量算法，实现毫秒级多视角多人全身姿态估计。|
|🆕 发布|SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect|SuperAD：CVPR 2025 VAND 3.0 工作坊挑战赛第1赛道：适应与检测的无监督异常分类与分割方法|Huaiyuan Zhang, Hang Chen, Yu Cheng, Shunyi Wu, Linghao Sun, Linao Han, Zeyu Shi, Lei Qi|<http://arxiv.org/pdf/2505.19750v1>|提出一种无需训练的基于DINOv2模型的异常检测与分割方法SuperAD，有效应对复杂工业环境中的异...|
|🆕 发布|Burst Image Super-Resolution via Multi-Cross Attention Encoding and Multi-Scan State-Space Decoding|突发图像超分辨率通过多交叉注意力编码和多扫描状态空间解码|Tengda Huang, Yu Zhang, Tianren Li, Yufu Qu, Fulin Liu, Zhenzhong Wei|<http://arxiv.org/pdf/2505.19668v1>|提出了一种基于多交叉注意力编码和多扫描状态空间解码的突发图像超分辨率方法，显著提升了图像质量。|
|🆕 发布|Beyond Segmentation: Confidence-Aware and Debiased Estimation of Ratio-based Biomarkers|超越分割：基于置信度和去偏估计的比率生物标志物|Jiameng Li, Teodora Popordanoska, Sebastian G. Gruber, Frederik Maes, Matthew B. Blaschko|<http://arxiv.org/pdf/2505.19585v1>|提出了一种基于软分割的比生物标志物估计方法，通过引入置信度感知和偏差校正，提高了临床应用的可靠性。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Underwater Diffusion Attention Network with Contrastive Language-Image Joint Learning for Underwater Image Enhancement|水下扩散注意力网络与对比语言-图像联合学习用于水下图像增强|Afrah Shaahid, Muzammil Behzad|<http://arxiv.org/pdf/2505.19895v1>|提出UDAN-CLIP模型，通过对比语言-图像联合学习，有效增强水下图像，提升视觉效果和真实性。|
|📝 更新|HazyDet: Open-Source Benchmark for Drone-View Object Detection with Depth-Cues in Hazy Scenes|HazyDet：雾天场景中无人机视角物体检测的深度线索开源基准|Changfeng Feng, Zhenyuan Chen, Xiang Li, Chunping Wang, Jian Yang, Ming-Ming Cheng, Yimian Dai, Qiang Fu|<http://arxiv.org/pdf/2409.19833v2>|[代码](https://github.com/GrokCV/HazyDet.); HazyDet提出首个针对无人机在雾霾场景下目标检测的基准，并设计DeCoDet模型提升检测精度。|
|🆕 发布|Locality-Aware Zero-Shot Human-Object Interaction Detection|局部感知零样本人-物交互检测|Sanghyun Kim, Deunsol Jung, Minsu Cho|<http://arxiv.org/pdf/2505.19503v1>|提出LAIN框架，通过增强CLIP的局部和交互意识，有效提升零样本人-物交互检测性能。|
|🆕 发布|Objective, Absolute and Hue-aware Metrics for Intrinsic Image Decomposition on Real-World Scenes: A Proof of Concept|客观、绝对和色调感知的指标用于真实场景中的内在图像分解：一个概念验证|Shogo Sato, Masaru Tsuchida, Mariko Yamaguchi, Takuhiro Kaneko, Kazuhiko Murasaki, Taiga Yoshida, Ryuichi Tanida|<http://arxiv.org/pdf/2505.19500v1>|提出了一种基于超光谱成像和LiDAR的客观、绝对和色调感知的图像分解评估方法。|
|🆕 发布|ADD-SLAM: Adaptive Dynamic Dense SLAM with Gaussian Splatting|自适应动态稠密SLAM：基于高斯喷溅的解决方案|Wenhua Wu, Chenpeng Su, Siting Zhu, Tianchen Deng, Zhe Liu, Hesheng Wang|<http://arxiv.org/pdf/2505.19420v1>|ADD-SLAM通过自适应动态识别和动态-静态分离映射策略，有效解决动态SLAM中的场景一致性挑战，...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|What You Perceive Is What You Conceive: A Cognition-Inspired Framework for Open Vocabulary Image Segmentation|你所感知即你所构想：一种受认知启发的开放词汇图像分割框架|Jianghang Lin, Yue Hu, Jiangtao Shen, Yunhang Shen, Liujuan Cao, Shengchuan Zhang, Rongrong Ji|<http://arxiv.org/pdf/2505.19569v1>|提出认知启发式框架，模拟人类视觉识别过程，实现开放词汇图像分割。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HunyuanVideo-Avatar: High-Fidelity Audio-Driven Human Animation for Multiple Characters|HunyuanVideo-Avatar：多角色高保真音频驱动的人体动画|Yi Chen, Sen Liang, Zixiang Zhou, Ziyao Huang, Yifeng Ma, Junshu Tang, Qin Lin, Yuan Zhou .etc.|<http://arxiv.org/pdf/2505.20156v1>|HunyuanVideo-Avatar通过创新模块实现多角色、高保真、情感同步的人动画。|
|📝 更新|Unsupervised Detection of Distribution Shift in Inverse Problems using Diffusion Models|无监督检测逆问题中的分布偏移：基于扩散模型|Shirin Shoushtari, Edward P. Chandler, Yuanhao Wang, M. Salman Asif, Ulugbek S. Kamilov|<http://arxiv.org/pdf/2505.11482v3>|提出了一种无需监督的基于扩散模型的方法，用于检测和量化图像逆问题中的分布偏移。|
|🆕 发布|Understanding Generalization in Diffusion Models via Probability Flow Distance|通过概率流距离理解扩散模型中的泛化|Huijie Zhang, Zijian Huang, Siyi Chen, Jinfan Zhou, Zekai Zhang, Peng Wang, Qing Qu|<http://arxiv.org/pdf/2505.20123v1>|引入概率流距离，评估扩散模型泛化能力，揭示泛化行为。|
|🆕 发布|Multimodal LLM-Guided Semantic Correction in Text-to-Image Diffusion|多模态大型语言模型引导的文本到图像扩散中的语义校正|Zheqi Lv, Junhao Chen, Qi Tian, Keting Yin, Shengyu Zhang, Fei Wu|<http://arxiv.org/pdf/2505.20053v1>|提出MLLM语义校正，实时分析中间生成图像，提升文本到图像生成质量。|
|📝 更新|Efficient Training-Free High-Resolution Synthesis with Energy Rectification in Diffusion Models|高效的无训练高分辨率合成：扩散模型中的能量校正|Zhen Yang, Guibao Shen, Minyang Li, Liang Hou, Mushui Liu, Luozhou Wang, Xin Tao, Pengfei Wan .etc.|<http://arxiv.org/pdf/2503.02537v3>|提出RectifiedHR，通过噪声刷新策略和能量校正，实现高效的无监督高分辨率图像合成。|
|📝 更新|Attentive Eraser: Unleashing Diffusion Model's Object Removal Potential via Self-Attention Redirection Guidance|注意擦除器：通过自注意力重定向引导释放扩散模型的对象去除潜力|Wenhao Sun, Benlei Cui, Xue-Mei Dong, Jingqun Tang, Yi Liu|<http://arxiv.org/pdf/2412.12974v6>|[代码](https://github.com/Anonym0u3/AttentiveEraser.); 提出了一种基于自注意力重定向的扩散模型，有效解决图像去噪中的随机伪影和前景内容缺失问题。|
|🆕 发布|ICDM: Interference Cancellation Diffusion Models for Wireless Semantic Communications|无线语义通信的干扰消除扩散模型|Tong Wu, Zhiyong Chen, Dazhi He, Feng Yang, Meixia Tao, Xiaodong Xu, Wenjun Zhang, Ping Zhang|<http://arxiv.org/pdf/2505.19983v1>|提出了一种基于扩散模型的干扰消除方法，有效降低了无线语义通信中的信号干扰。|
|🆕 发布|Multimodal Reasoning Agent for Zero-Shot Composed Image Retrieval|多模态推理代理用于零样本组合图像检索|Rong-Cheng Tu, Wenhao Sun, Hanzhe You, Yingjie Wang, Jiaxing Huang, Li Shen, Dacheng Tao|<http://arxiv.org/pdf/2505.19952v1>|提出了一种无需文本中介的零样本图像检索方法，通过多模态推理直接关联查询和目标图像。|
|📝 更新|Inverse Problem Sampling in Latent Space Using Sequential Monte Carlo|逆问题采样在潜在空间中的顺序蒙特卡洛方法|Idan Achituve, Hai Victor Habi, Amir Rosenfeld, Arnon Netzer, Idit Diamant, Ethan Fetaya|<http://arxiv.org/pdf/2502.05908v2>|提出了一种基于LD-SMC的逆问题采样方法，有效解决图像去噪和修复难题。|
|🆕 发布|ErpGS: Equirectangular Image Rendering enhanced with 3D Gaussian Regularization|ErpGS：基于3D高斯正则化的等角图像渲染增强|Shintaro Ito, Natsuki Takama, Koichi Ito, Hwann-Tzong Chen, Takafumi Aoki|<http://arxiv.org/pdf/2505.19883v1>|提出ErpGS，通过3D高斯正则化提升等角图像渲染精度，解决360度相机投影模型导致的畸变问题。|
|🆕 发布|A Regularization-Guided Equivariant Approach for Image Restoration|基于正则化的等变图像恢复方法|Yulu Bai, Jiahong Fu, Qi Xie, Deyu Meng|<http://arxiv.org/pdf/2505.19799v1>|提出了一种自适应旋转等变正则化策略，显著提升了图像修复任务的准确性和泛化能力。|
|🆕 发布|HAODiff: Human-Aware One-Step Diffusion via Dual-Prompt Guidance|HAODiff：基于双提示引导的人感知一步扩散|Jue Gong, Tingyu Yang, Jingkai Wang, Zheng Chen, Xing Liu, Hong Gu, Yulun Zhang, Xiaokang Yang|<http://arxiv.org/pdf/2505.19742v1>|[代码](https://github.com/gobunu/HAODiff.); HAODiff通过双重提示引导，实现人感知的一步扩散，有效提升图像修复鲁棒性。|
|🆕 发布|SAIL: Self-supervised Albedo Estimation from Real Images with a Latent Diffusion Model|SAIL：基于潜在扩散模型的从真实图像中进行自监督反照率估计|Hala Djeghim, Nathan Piasco, Luis Roldão, Moussab Bennehar, Dzmitry Tsishkou, Céline Loscos, Désiré Sidibé|<http://arxiv.org/pdf/2505.19751v1>|SAIL通过潜扩散模型和自监督学习，实现了从真实图像中稳定估计反照率，有效解决了光照变化下的反照率一...|
|🆕 发布|Cross-Sequence Semi-Supervised Learning for Multi-Parametric MRI-Based Visual Pathway Delineation|跨序列半监督学习在多参数MRI视觉通路勾勒中的应用|Alou Diakite, Cheng Li, Lei Xie, Yuanjing Feng, Ruoyou Wu, Jianzhong He, Hairong Zheng, Shanshan Wang|<http://arxiv.org/pdf/2505.19733v1>|提出了一种基于半监督学习的多参数MRI视觉通路分割框架，有效处理跨序列关系并缓解数据标注难题。|
|📝 更新|Expanding Zero-Shot Object Counting with Rich Prompts|基于丰富提示的零样本目标计数扩展|Huilin Zhu, Senyao Li, Jingling Yuan, Zhengwei Yang, Yu Guo, Wenxuan Liu, Xian Zhong, Shengfeng He|<http://arxiv.org/pdf/2505.15398v2>|RichCount通过丰富文本特征和强化图像关联，实现零样本计数中未见类别的高效泛化。|
|🆕 发布|Regularized Personalization of Text-to-Image Diffusion Models without Distributional Drift|文本到图像扩散模型的正则化个性化，避免分布漂移|Gihoon Kim, Hyungjin Park, Taesup Kim|<http://arxiv.org/pdf/2505.19519v1>|提出了一种基于Lipschitz约束的文本到图像扩散模型个性化方法，有效控制分布漂移并提升生成质量。|
|📝 更新|VSA: Faster Video Diffusion with Trainable Sparse Attention|VSA：可训练稀疏注意力加速视频扩散|Peiyuan Zhang, Haofeng Huang, Yongqi Chen, Will Lin, Zhengzhong Liu, Ion Stoica, Eric Xing, Hao Zhang|<http://arxiv.org/pdf/2505.13389v3>|[代码](https://github.com/hao-ai-lab/FastVideo.); 提出VSA，一种可训练的稀疏注意力机制，显著提升视频扩散模型的训练速度和效率。|
|📝 更新|RDEIC: Accelerating Diffusion-Based Extreme Image Compression with Relay Residual Diffusion|RDEIC：基于扩散的极端图像压缩的加速方法：中继残差扩散|Zhiyuan Li, Yanhui Zhou, Hao Wei, Chenyang Ge, Ajmal Mian|<http://arxiv.org/pdf/2410.02640v3>|[代码](https://github.com/huai-chang/RDEIC.); 提出RDEIC，通过压缩特征初始化和残差扩散加速扩散图像压缩，显著提升压缩效率和图像质量。|
|🆕 发布|Diversity-Driven Generative Dataset Distillation Based on Diffusion Model with Self-Adaptive Memory|基于自适应性记忆的扩散模型驱动的多样性生成数据集蒸馏|Mingzhuo Li, Guang Li, Jiafeng Mao, Takahiro Ogawa, Miki Haseyama|<http://arxiv.org/pdf/2505.19469v1>|提出一种基于扩散模型和自适应记忆的多样化数据集蒸馏方法，有效提升下游验证准确率。|
|📝 更新|Stay-Positive: A Case for Ignoring Real Image Features in Fake Image Detection|保持积极：在伪造图像检测中忽略真实图像特征的论点|Anirudh Sundara Rajan, Yong Jae Lee|<http://arxiv.org/pdf/2502.07778v2>|提出Stay Positive算法，专注于检测生成模型引入的伪造图像特征，提高检测准确性和鲁棒性。|
|📝 更新|Cancer-Net PCa-Seg: Benchmarking Deep Learning Models for Prostate Cancer Segmentation Using Synthetic Correlated Diffusion Imaging|癌症-网络PCa-Seg：使用合成相关扩散成像对前列腺癌分割深度学习模型进行基准测试|Jarett Dewbury, Chi-en Amy Tai, Alexander Wong|<http://arxiv.org/pdf/2501.09185v2>|该论文通过合成相关扩散成像，评估了深度学习模型在前列腺癌分割中的应用，发现SegResNet和Att...|
|🆕 发布|Advancing Limited-Angle CT Reconstruction Through Diffusion-Based Sinogram Completion|ogram Completion|Jiaqi Guo, Santiago Lopez-Tapia, Aggelos K. Katsaggelos|<http://arxiv.org/pdf/2505.19385v1>|提出了一种基于扩散模型和伪逆矩阵的有限角CT重建新方法，显著提升了重建质量和效率。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Agentic 3D Scene Generation with Spatially Contextualized VLMs|具有空间上下文信息的VLMs进行代理式3D场景生成|Xinhang Liu, Yu-Wing Tai, Chi-Keung Tang|<http://arxiv.org/pdf/2505.20129v1>|引入空间上下文，使VLM生成、理解和编辑复杂3D场景，提升空间智能系统潜力。|
|🆕 发布|Refining Few-Step Text-to-Multiview Diffusion via Reinforcement Learning|通过强化学习精炼少量步骤的文本到多视图扩散|Ziyi Zhang, Li Shen, Deheng Ye, Yong Luo, Huangxuan Zhao, Lefei Zhang|<http://arxiv.org/pdf/2505.20107v1>|提出了一种基于强化学习的T2MV扩散模型微调框架，优化图像质量和视图一致性。|
|🆕 发布|MEBench: A Novel Benchmark for Understanding Mutual Exclusivity Bias in Vision-Language Models|MEBench：理解视觉-语言模型中互斥偏差的新基准|Anh Thai, Stefan Stojanov, Zixuan Huang, Bikram Boote, James M. Rehg|<http://arxiv.org/pdf/2505.20122v1>|构建了MEBench基准，评估视觉语言模型中的互斥性偏差，并引入空间推理以提升评估的挑战性和现实性。|
|📝 更新|NFIG: Autoregressive Image Generation with Next-Frequency Prediction|NFIG：基于下一频率预测的自回归图像生成|Zhihao Huang, Xi Qiu, Yukuo Ma, Yifu Zhou, Junjie Chen, Hongyuan Zhang, Chi Zhang, Xuelong Li|<http://arxiv.org/pdf/2503.07076v2>|NFIG通过频率引导的多个阶段分解图像生成过程，有效捕捉长距离依赖关系，降低计算成本，实现高效图像生...|
|🆕 发布|PAMD: Plausibility-Aware Motion Diffusion Model for Long Dance Generation|PAMD：用于长舞蹈生成的基于合理性感知的运动扩散模型|Hongsong Wang, Yin Zhu, Qiuxia Lai, Yang Zhang, Guo-Sen Xie, Xin Geng|<http://arxiv.org/pdf/2505.20056v1>|[代码](https://mucunzhuzhu.github.io/PAMD-page); 提出PAMD模型，通过引入物理合理性约束和运动引导，显著提升长舞蹈生成序列的音乐同步性和物理真实性。|
|📝 更新|Domain-Agnostic Stroke Lesion Segmentation Using Physics-Constrained Synthetic Data|基于物理约束合成数据的域无关脑卒中病灶分割|Liam Chalcroft, Jenny Crinion, Cathy J. Price, John Ashburner|<http://arxiv.org/pdf/2412.03318v2>|[代码](https://github.com/liamchalcroft/qsynth); 提出了一种利用物理约束生成合成MRI图像的方法，显著提升了脑卒中病变分割的鲁棒性和泛化能力。|
|📝 更新|OmniSVG: A Unified Scalable Vector Graphics Generation Model|全息SVG：一种统一的可缩放矢量图形生成模型|Yiying Yang, Wei Cheng, Sijin Chen, Xianfang Zeng, Fukun Yin, Jiaxu Zhang, Liao Wang, Gang Yu .etc.|<http://arxiv.org/pdf/2504.06263v2>|提出OmniSVG模型，通过预训练视觉语言模型实现高效且高质量的SVG生成。|
|📝 更新|What Makes a Scene ? Scene Graph-based Evaluation and Feedback for Controllable Generation|场景构成要素：基于场景图的可控生成评估与反馈|Zuyao Chen, Jinlin Wu, Zhen Lei, Chang Wen Chen|<http://arxiv.org/pdf/2411.15435v2>|构建Scene-Bench基准和SGScore评估指标，提升场景图生成图像的事实一致性。|
|🆕 发布|Harnessing the Power of Training-Free Techniques in Text-to-2D Generation for Text-to-3D Generation via Score Distillation Sampling|利用无监督训练技术在文本到2D生成中的力量，通过分数蒸馏采样实现文本到3D生成|Junhong Lee, Seungwook Kim, Minsu Cho|<http://arxiv.org/pdf/2505.19868v1>|通过结合无监督技术和动态缩放策略，本文显著提升了文本到3D生成中的纹理细节和表面平滑度。|
|📝 更新|Diff-Def: Diffusion-Generated Deformation Fields for Conditional Atlases|Diff-Def：条件图谱的扩散生成形变场|Sophie Starck, Vasiliki Sideri-Lampretsa, Bernhard Kainz, Martin J. Menten, Tamara T. Mueller, Daniel Rueckert|<http://arxiv.org/pdf/2403.16776v2>|提出了一种利用潜在扩散模型生成变形场的方法，以生成针对特定子群体的条件图谱，显著提升了图谱的解剖准确...|
|🆕 发布|ReDDiT: Rehashing Noise for Discrete Visual Generation|ReDDiT：为离散视觉生成重哈希噪声|Tianren Ma, Xiaosong Zhang, Boyu Yang, Junlan Feng, Qixiang Ye|<http://arxiv.org/pdf/2505.19656v1>|提出ReDDiT框架，通过改进噪声设计和采样策略，显著提升离散扩散模型生成质量。|
|🆕 发布|Grounding Language with Vision: A Conditional Mutual Information Calibrated Decoding Strategy for Reducing Hallucinations in LVLMs|基于视觉的语言定位：用于减少LVLMs中幻觉的条件互信息校准解码策略|Hao Fang, Changle Zhou, Jiawei Kong, Kuofeng Gao, Bin Chen, Tao Liang, Guojun Ma, Shu-Tao Xia|<http://arxiv.org/pdf/2505.19678v1>|提出C-PMI解码策略，有效降低LVLMs生成文本的幻觉现象。|
|🆕 发布|Guard Me If You Know Me: Protecting Specific Face-Identity from Deepfakes|守护我的身份：保护特定人脸免受深度伪造攻击|Kaiqing Lin, Zhiyuan Yan, Ke-Yue Zhang, Li Hao, Yue Zhou, Yuzhen Lin, Weixiang Li, Taiping Yao .etc.|<http://arxiv.org/pdf/2505.19582v1>|提出VIPGuard框架，结合多模态语言模型和个性化定制，有效识别并解释名人深伪视频。|
|🆕 发布|VTBench: Comprehensive Benchmark Suite Towards Real-World Virtual Try-on Models|VTBench：面向现实世界虚拟试穿模型的全面基准套件|Hu Xiaobin, Liang Yujie, Luo Donghao, Peng Xu, Zhang Jiangning, Zhu Junwei, Wang Chengjie, Fu Yanwei|<http://arxiv.org/pdf/2505.19571v1>|VTBench提出了一套全面基准，通过多维评估和人类标注，推动虚拟试穿模型向真实场景发展。|
|🆕 发布|TDVE-Assessor: Benchmarking and Evaluating the Quality of Text-Driven Video Editing with LMMs|TDVE-Assessor：基于LMMs的文本驱动视频编辑质量基准与评估|Juntong Wang, Jiarui Wang, Huiyu Duan, Guangtao Zhai, Xiongkuo Min|<http://arxiv.org/pdf/2505.19535v1>|构建大规模数据集TDVE-DB，提出TDVE-Assessor模型，提升文本驱动视频编辑质量评估。|
|📝 更新|Fast Video Generation with Sliding Tile Attention|快速滑动拼图注意力视频生成|Peiyuan Zhang, Yongqi Chen, Runlong Su, Hangliang Ding, Ion Stoica, Zhengzhong Liu, Hao Zhang|<http://arxiv.org/pdf/2502.04507v2>|[代码](https://github.com/hao-ai-lab/FastVideo.); 提出滑动瓷砖注意力机制，大幅提升视频生成效率，降低计算成本。|
|🆕 发布|Toward Patient-specific Partial Point Cloud to Surface Completion for Pre- to Intra-operative Registration in Image-guided Liver Interventions|面向图像引导肝脏干预术前至术中注册的个性化部分点云到表面补全|Nakul Poudel, Zixin Yang, Kelly Merrell, Richard Simon, Cristian A. Linte|<http://arxiv.org/pdf/2505.19518v1>|提出了一种基于VN-OccNet的个性化点云补全方法，以改善术中图像引导肝脏干预的术前到术中注册。|
|🆕 发布|Enhancing Visual Reliance in Text Generation: A Bayesian Perspective on Mitigating Hallucination in Large Vision-Language Models|增强文本生成中的视觉依赖：大型视觉-语言模型缓解幻觉的贝叶斯视角|Nanxing Hu, Xiaoyue Duan, Jinchao Zhang, Guoliang Kang|<http://arxiv.org/pdf/2505.19498v1>|从贝叶斯视角出发，通过评估和去除冗余视觉信息、修正先验信息和停止无信息视觉依赖的文本生成，有效缓解了...|
|📝 更新|CGI: Identifying Conditional Generative Models with Example Images|CGI：通过示例图像识别条件生成模型|Zhi Zhou, Hao-Zhe Tan, Peng-Xiao Song, Lan-Zhe Guo|<http://arxiv.org/pdf/2501.13991v2>|提出CGI方法，通过用户示例图像识别最合适的生成模型，提高模型搜索效率。|
|🆕 发布|LlamaSeg: Image Segmentation via Autoregressive Mask Generation|LlamaSeg：通过自回归掩码生成进行图像分割|Jiru Deng, Tengjin Weng, Tianyu Yang, Wenhan Luo, Zhiheng Li, Wenhao Jiang|<http://arxiv.org/pdf/2505.19422v1>|提出LlamaSeg，通过自回归掩码生成实现图像分割，提升分割精度。|
|📝 更新|HPPP: Halpern-type Preconditioned Proximal Point Algorithms and Applications to Image Restoration|HPPP：Halpern型预条件近端点算法及其在图像恢复中的应用|Shuchang Zhang, Hui Zhang, Hongxia Wang|<http://arxiv.org/pdf/2407.13120v4>|提出HPPP算法，结合Halpern迭代加速图像修复，解决PPP方法收敛慢问题。|
|🆕 发布|MMIG-Bench: Towards Comprehensive and Explainable Evaluation of Multi-Modal Image Generation Models|MMIG-Bench：迈向全面且可解释的多模态图像生成模型评估|Hang Hua, Ziyun Zeng, Yizhi Song, Yunlong Tang, Liu He, Daniel Aliaga, Wei Xiong, Jiebo Luo|<http://arxiv.org/pdf/2505.19415v1>|提出MMIG-Bench，统一评估多模态图像生成模型，解决现有评估工具的不足。|
|🆕 发布|Force Prompting: Video Generation Models Can Learn and Generalize Physics-based Control Signals|强制提示：视频生成模型可以学习和泛化基于物理的控制信号|Nate Gillman, Charles Herrmann, Michael Freeman, Daksh Aggarwal, Evan Luo, Deqing Sun, Chen Sun|<http://arxiv.org/pdf/2505.19386v1>|提出了一种利用物理力作为控制信号的视频生成方法，使模型能通过视觉和运动先验学习物理控制信号，实现逼真...|
|🆕 发布|Absolute Coordinates Make Motion Generation Easy|绝对坐标使运动生成变得简单|Zichong Meng, Zeyu Han, Xiaogang Peng, Yiming Xie, Huaizu Jiang|<http://arxiv.org/pdf/2505.19377v1>|提出绝对坐标简化了运动生成，显著提升了运动精度和下游任务应用。|
|📝 更新|Understanding Generative AI Capabilities in Everyday Image Editing Tasks|理解在日常图像编辑任务中生成式人工智能的能力|Mohammad Reza Taesiri, Brandon Collins, Logan Bolton, Viet Dac Lai, Franck Dernoncourt, Trung Bui, Anh Totti Nguyen|<http://arxiv.org/pdf/2505.16181v2>|分析Reddit社区图像编辑请求，揭示AI编辑局限与改进方向。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations|双言：3D说话头像对话中的双发言人交互|Ziqiao Peng, Yanbo Fan, Haoyu Wu, Xuan Wang, Hongyan Liu, Jun He, Zhaoxin Fan|<http://arxiv.org/pdf/2505.18096v2>|[代码](https://ziqiaopeng.github.io/dualtalk.); DualTalk通过模拟说话者和听众的动态行为，显著提升了3D对话头像的自然性和表现力。|
|📝 更新|VideoJAM: Joint Appearance-Motion Representations for Enhanced Motion Generation in Video Models|视频JAM：视频模型中增强运动生成的联合外观-运动表示|Hila Chefer, Uriel Singer, Amit Zohar, Yuval Kirstain, Adam Polyak, Yaniv Taigman, Lior Wolf, Shelly Sheynin|<http://arxiv.org/pdf/2502.02492v2>|[代码](https://hila-chefer.github.io/videojam-paper.github.io); VideoJAM通过引入联合外观-运动表示，有效提升了视频生成模型中运动的一致性和视觉质量。|
|🆕 发布|UltraVSR: Achieving Ultra-Realistic Video Super-Resolution with Efficient One-Step Diffusion Space|超逼真视频超分辨率：高效一步扩散空间的实现|Yong Liu, Jinshan Pan, Yinchuan Li, Qingji Dong, Chao Zhu, Yu Guo, Fei Wang|<http://arxiv.org/pdf/2505.19958v1>|提出了一种基于扩散模型和时空信息融合的超分辨率方法，实现单步重建并显著提升视频清晰度。|
|🆕 发布|A Unified Solution to Video Fusion: From Multi-Frame Learning to Benchmarking|视频融合的统一解决方案：从多帧学习到基准测试|Zixiang Zhao, Haowen Bai, Bingxin Ke, Yukun Cui, Lilun Deng, Yulun Zhang, Kai Zhang, Konrad Schindler|<http://arxiv.org/pdf/2505.19858v1>|提出UniVF框架，结合多帧学习和光流特征融合，实现视频融合的时空一致性，并构建了首个视频融合基准V...|
|📝 更新|Faster and Stronger: When ANN-SNN Conversion Meets Parallel Spiking Calculation|更快更强：当人工神经网络-脉冲神经网络转换遇到并行脉冲计算|Zecheng Hao, Qichao Ma, Kang Chen, Yi Zhang, Zhaofei Yu, Tiejun Huang|<http://arxiv.org/pdf/2412.13610v2>|[代码](https://github.com/hzc1208/Parallel_Conversion.); 提出了一种结合并行脉冲计算和ANN-SNN转换的并行学习框架，显著提升了脉冲神经网络的学习效率和性能...|
|🆕 发布|ViewCraft3D: High-Fidelity and View-Consistent 3D Vector Graphics Synthesis|ViewCraft3D：高保真和视角一致的三维矢量图形合成|Chuang Wang, Haitao Zhou, Ling Luo, Qian Yu|<http://arxiv.org/pdf/2505.19492v1>|ViewCraft3D通过利用3D先验知识，高效生成保持视角一致性的高保真3D矢量图形。|
|📝 更新|Marmot: Multi-Agent Reasoning for Multi-Object Self-Correcting in Improving Image-Text Alignment|多智能体推理在多对象自校正中提升图像-文本对齐的Marmot|Jiayang Sun, Hongbo Wang, Jie Cao, Huaibo Huang, Ran He|<http://arxiv.org/pdf/2504.20054v2>|Marmot通过多智能体推理实现多对象自我校正，显著提升图像与文本对齐的准确性。|
|📝 更新|MoRE-Brain: Routed Mixture of Experts for Interpretable and Generalizable Cross-Subject fMRI Visual Decoding|MoRE-Brain：用于可解释和泛化跨受试者fMRI视觉解码的路径混合专家|Yuxiang Wei, Yanteng Zhang, Xi Xiao, Tianyang Wang, Xiao Wang, Vince D. Calhoun|<http://arxiv.org/pdf/2505.15946v2>|[代码](https://github.com/yuxiangwei0808/MoRE-Brain.); MoRE-Brain通过模拟人脑网络，提出了一种可解释且通用的fMRI视觉解码框架，显著提升了重建图...|
|🆕 发布|Structure Disruption: Subverting Malicious Diffusion-Based Inpainting via Self-Attention Query Perturbation|结构破坏：通过自注意力查询扰动颠覆恶意扩散式修复|Yuhao He, Jinyu Tian, Haiwei Wu, Jianqing Li|<http://arxiv.org/pdf/2505.19425v1>|提出结构破坏攻击，通过自注意力查询扰动破坏扩散模型的结构生成能力，有效防止恶意图像修复。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks|朝着具有表演支持链的从视频到钢琴音乐生成的基准研究|Chang Liu, Haomin Zhang, Shiyu Xia, Zihao Chen, Chaofan Ding, Xin Yue, Huizhe Chen, Xinhan Di|<http://arxiv.org/pdf/2505.20038v1>|[代码](https://github.com/acappemin/Video-to-Audio-and-Piano); 构建了针对视频到钢琴音乐生成的CoP基准数据集，以促进高质量音乐生成研究。|
|📝 更新|TokBench: Evaluating Your Visual Tokenizer before Visual Generation|TokBench：在视觉生成之前评估您的视觉分词器|Junfeng Wu, Dongliang Luo, Weizhi Zhao, Zhihao Xie, Yuanhao Wang, Junyi Li, Xudong Xie, Yuliang Liu .etc.|<http://arxiv.org/pdf/2505.18142v2>|提出TokBench基准评估视觉编码器，揭示其保真度限制，提升视觉生成质量评估。|
|📝 更新|One Image is Worth a Thousand Words: A Usability Preservable Text-Image Collaborative Erasing Framework|一张图胜千言：一种可保留可用性的文本-图像协同擦除框架|Feiran Li, Qianqian Xu, Shilong Bao, Zhiyong Yang, Xiaochun Cao, Qingming Huang|<http://arxiv.org/pdf/2505.11131v2>|[代码](https://github.com/Ferry-Li/Co-Erasing.); 提出了一种结合视觉监督的文本-图像协同概念擦除框架，有效提升擦除效率和可用性。|
|📝 更新|On the Fairness, Diversity and Reliability of Text-to-Image Generative Models|关于文本到图像生成模型的公平性、多样性和可靠性|Jordan Vice, Naveed Akhtar, Leonid Sigal, Richard Hartley, Ajmal Mian|<http://arxiv.org/pdf/2411.13981v2>|[代码](https://github.com/JJ-Vice/T2I_Fairness_Diversity_Reliability.); 提出评估框架，分析文本到图像生成模型的可靠性和公平性，以识别不稳定的或偏颇的行为。|
|📝 更新|Slot-MLLM: Object-Centric Visual Tokenization for Multimodal LLM|槽-MLLM：多模态LLM的对象中心视觉标记化|Donghwan Chi, Hyomin Kim, Yoonjin Oh, Yongjin Kim, Donghoon Lee, Daejin Jo, Jongmin Kim, Junyeob Baek .etc.|<http://arxiv.org/pdf/2505.17726v2>|提出一种以对象为中心的视觉标记器，提升多模态LLM对细节视觉内容的理解和生成能力。|
|🆕 发布|The Role of Video Generation in Enhancing Data-Limited Action Understanding|视频生成在提升数据受限动作理解中的作用|Wei Li, Dezhao Luo, Dongbao Yang, Zhenhang Li, Weiping Wang, Yu Zhou|<http://arxiv.org/pdf/2505.19495v1>|提出一种利用文本生成视频数据的方法，有效缓解数据稀缺问题，提升动作理解模型性能。|
|🆕 发布|Erasing Concepts, Steering Generations: A Comprehensive Survey of Concept Suppression|擦除概念，引导生成：概念抑制的全面综述|Yiwei Xie, Ping Liu, Zheng Zhang|<http://arxiv.org/pdf/2505.19398v1>|提出了一种概念擦除方法，从T2I模型中去除特定语义概念，以促进生成AI的负责任发展。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OB3D: A New Dataset for Benchmarking Omnidirectional 3D Reconstruction Using Blender|OB3D：用于基准测试Blender中全向3D重建的新数据集|Shintaro Ito, Natsuki Takama, Toshiki Watanabe, Koichi Ito, Hwann-Tzong Chen, Takafumi Aoki|<http://arxiv.org/pdf/2505.20126v1>|OB3D提出新数据集，解决全向3D重建中几何畸变问题，推动技术发展。|
|🆕 发布|NEXT: Multi-Grained Mixture of Experts via Text-Modulation for Multi-Modal Object Re-ID|下一代：通过文本调制实现的多模态物体重识别的多粒度专家混合|Shihao Li, Chenglong Li, Aihua Zheng, Andong Lu, Jin Tang, Jixin Ma|<http://arxiv.org/pdf/2505.20001v1>|提出一种基于文本调控的多模态物体重识别框架，有效提升识别准确率。|
|🆕 发布|GraphAU-Pain: Graph-based Action Unit Representation for Pain Intensity Estimation|基于图的动作单元表示用于疼痛强度估计|Zhiyu Wang, Yang Liu, Hatice Gunes|<http://arxiv.org/pdf/2505.19802v1>|GraphAU-Pain通过图神经网络建模面部动作单元，实现疼痛强度的高效准确估计。|
|🆕 发布|GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis|GoLF-NRT：融合全局上下文和局部几何的少样本视图合成|You Wang, Li Fang, Hao Zhu, Fei Hu, Long Ye, Zhan Ma|<http://arxiv.org/pdf/2505.19813v1>|[代码](https://github.com/KLMAV-CUC/GoLF-NRT.); GoLF-NRT通过融合全局场景上下文和局部几何特征，显著提升了基于少量输入视图的神经渲染性能。|
|🆕 发布|Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction|深度引导的束采样用于高效且可泛化的神经辐射场重建|Li Fang, Hao Zhu, Longlong Chen, Fei Hu, Long Ye, Zhan Ma|<http://arxiv.org/pdf/2505.19793v1>|[代码](https://github.com/KLMAV-CUC/GDB-NeRF.); 提出了一种基于深度引导的束采样策略，有效加速了神经辐射场的高分辨率图像重建。|
|📝 更新|Exploring Generalized Gait Recognition: Reducing Redundancy and Noise within Indoor and Outdoor Datasets|探索广义步态识别：降低室内和室外数据集中的冗余和噪声|Qian Zhou, Xianda Guo, Jilong Wang, Chuanfu Shen, Zhongyuan Wang, Hua Zou, Qin Zou, Chao Liang .etc.|<http://arxiv.org/pdf/2505.15176v3>|[代码](https://github.com/li1er3/Generalized_Gait.); 提出了一种统一框架，通过解耦损失和筛选样本，有效提升跨域步态识别性能。|
|📝 更新|NeuRadar: Neural Radiance Fields for Automotive Radar Point Clouds|神经雷达：用于汽车雷达点云的神经辐射场|Mahan Rafidashti, Ji Lan, Maryam Fatemi, Junsheng Fu, Lars Hammarstrand, Lennart Svensson|<http://arxiv.org/pdf/2504.00859v3>|提出NeuRadar，利用NeRF技术实现雷达点云、图像和激光点云的联合生成，并提升雷达行为建模的准...|
|🆕 发布|K-Buffers: A Plug-in Method for Enhancing Neural Fields with Multiple Buffers|K-Buffers：一种用于增强多缓冲区神经场的插件方法|Haofan Ren, Zunjie Zhu, Xiang Chen, Ming Lu, Rongfeng Lu, Chenggang Yan|<http://arxiv.org/pdf/2505.19564v1>|K-Buffers通过多缓冲区融合技术，有效提升了神经场渲染性能。|
|📝 更新|Ocular Authentication: Fusion of Gaze and Periocular Modalities|眼动认证：注视与眼周模态的融合|Dillon Lohr, Michael J. Proulx, Mehedi Hasan Raju, Oleg V. Komogortsev|<http://arxiv.org/pdf/2505.17343v2>|提出融合注视和眼周图像的多模态认证系统，显著提升无标定眼动认证性能。|
|🆕 发布|SpikeStereoNet: A Brain-Inspired Framework for Stereo Depth Estimation from Spike Streams|SpikeStereoNet：基于脉冲流进行立体深度估计的脑启发框架|Zhuoheng Gao, Yihao Li, Jiyao Zhang, Rui Zhao, Tong Wu, Hao Tang, Zhaofei Yu, Hao Dong .etc.|<http://arxiv.org/pdf/2505.19487v1>|提出了一种从原始脉冲流直接估计立体深度的脑启发框架，显著提升了在快速变化场景中的深度估计性能。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Weather-Magician: Reconstruction and Rendering Framework for 4D Weather Synthesis In Real Time|实时四维天气合成重建与渲染框架：天气魔术师|Chen Sang, Yeqiang Qian, Jiale Zhang, Chunxiang Wang, Ming Yang|<http://arxiv.org/pdf/2505.19919v1>|提出了一种实时合成4D天气效果的重建与渲染框架，有效解决复杂场景渲染难题。|
|🆕 发布|Sparse2DGS: Sparse-View Surface Reconstruction using 2D Gaussian Splatting with Dense Point Cloud|稀疏2D高斯分层：基于密集点云的稀疏视图表面重建|Natsuki Takama, Shintaro Ito, Koichi Ito, Hwann-Tzong Chen, Takafumi Aoki|<http://arxiv.org/pdf/2505.19854v1>|提出Sparse2DGS，通过结合DUSt3R和COLMAP MVS生成密集点云，实现仅用三张图像的...|
|🆕 发布|HF-VTON: High-Fidelity Virtual Try-On via Consistent Geometric and Semantic Alignment|高保真虚拟试穿：通过一致几何和语义对齐|Ming Meng, Qi Dong, Jiajie Li, Zhe Zhu, Xingyu Wang, Zhaoxin Fan, Wei Zhao, Wenjun Wu|<http://arxiv.org/pdf/2505.19638v1>|提出HF-VTON，通过几何和语义对齐，实现高保真虚拟试衣，提升视觉和语义一致性。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TUNA: Comprehensive Fine-grained Temporal Understanding Evaluation on Dense Dynamic Videos|TUNA：密集动态视频中全面细粒度时间理解评估|Fanheng Kong, Jingyuan Zhang, Hongzhi Zhang, Shi Feng, Daling Wang, Linhao Yu, Xingguang Ji, Yu Tian .etc.|<http://arxiv.org/pdf/2505.20124v1>|[代码](https://friedrichor.github.io/projects); 构建了TUNA基准，全面评估密集动态视频的细粒度时间理解能力。|
|🆕 发布|AdaTP: Attention-Debiased Token Pruning for Video Large Language Models|AdaTP：针对视频大型语言模型的注意力偏差词元剪枝|Fengyuan Sun, Leqi Shen, Hui Chen, Sicheng Zhao, Jungong Han, Guiguang Ding|<http://arxiv.org/pdf/2505.20100v1>|提出AdaTP方法，通过注意力去偏技术有效降低视频大语言模型计算开销，同时保持性能。|
|🆕 发布|Vad-R1: Towards Video Anomaly Reasoning via Perception-to-Cognition Chain-of-Thought|Vad-R1：通过感知到认知思维链实现视频异常推理|Chao Huang, Benfeng Wang, Jie Wen, Chengliang Liu, Wei Wang, Li Shen, Xiaochun Cao|<http://arxiv.org/pdf/2505.19877v1>|[代码](https://github.com/wbfwonderful/Vad-R1.); 提出视频异常推理新任务，通过感知到认知思维链引导MLLM逐步推理异常。|
|🆕 发布|Two Causally Related Needles in a Video Haystack|两个因果相关的针在视频稻草堆中|Miaoyu Li, Qin Chao, Boyang Li|<http://arxiv.org/pdf/2505.19853v1>|提出Causal2Needles基准，评估VLMs在视频信息提取和因果建模方面的能力。|
|📝 更新|FastVID: Dynamic Density Pruning for Fast Video Large Language Models|快速VID：动态密度剪枝用于快速视频大型语言模型|Leqi Shen, Guoqiang Gong, Tao He, Yifeng Zhang, Pengzhang Liu, Sicheng Zhao, Guiguang Ding|<http://arxiv.org/pdf/2503.11187v2>|[代码](https://github.com/LunarShen/FastVID.); FastVID通过动态密度剪枝，有效减少视频大语言模型计算量，同时保持视频理解和准确性。|
|📝 更新|SPKLIP: Aligning Spike Video Streams with Natural Language|SPKLIP：对自然语言与尖峰视频流进行对齐|Yongchang Gao, Meiling Jin, Zhaofei Yu, Tiejun Huang, Guozhang Chen|<http://arxiv.org/pdf/2505.12656v2>|SPKLIP通过引入层次化特征提取和对比学习，有效解决了脉冲视频与自然语言对齐问题，提升了脉冲视频语...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PHI: Bridging Domain Shift in Long-Term Action Quality Assessment via Progressive Hierarchical Instruction|PHI：通过渐进式分层指令弥合长期动作质量评估中的领域迁移|Kanglei Zhou, Hubert P. H. Shum, Frederick W. B. Li, Xingxing Zhang, Xiaohui Liang|<http://arxiv.org/pdf/2505.19972v1>|提出PHI方法，通过渐进式分层指令解决长期动作质量评估中的领域偏移问题。|
|🆕 发布|CA3D: Convolutional-Attentional 3D Nets for Efficient Video Activity Recognition on the Edge|CA3D：用于边缘高效视频活动识别的卷积-注意力3D网络|Gabriele Lagani, Fabrizio Falchi, Claudio Gennaro, Giuseppe Amato|<http://arxiv.org/pdf/2505.19928v1>|提出了一种结合卷积层和线性复杂度注意力机制的轻量级视频活动识别模型，有效降低计算成本并提升识别准确率...|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HybridTrack: A Hybrid Approach for Robust Multi-Object Tracking|混合跟踪：一种鲁棒的多目标跟踪混合方法|Leandro Di Bella, Yangxintong Lyu, Bruno Cornelis, Adrian Munteanu|<http://arxiv.org/pdf/2501.01275v2>|[代码](https://github.com/leandro-svg/HybridTrack.); 提出HybridTrack，一种结合数据驱动卡尔曼滤波的混合方法，实现鲁棒的多目标跟踪。|
|📝 更新|Compositional Physical Reasoning of Objects and Events from Videos|视频中的物体和事件组合物理推理|Zhenfang Chen, Shilong Dong, Kexin Yi, Yunzhu Li, Mingyu Ding, Antonio Torralba, Joshua B. Tenenbaum, Chuang Gan|<http://arxiv.org/pdf/2408.02687v2>|提出ComPhy数据集和PCR框架，从视频推断物体隐藏物理属性并预测相应动态。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CSTrack: Enhancing RGB-X Tracking via Compact Spatiotemporal Features|CSTrack：通过紧凑时空特征增强RGB-X跟踪|X. Feng, D. Zhang, S. Hu, X. Li, M. Wu, J. Zhang, X. Chen, K. Huang|<http://arxiv.org/pdf/2505.19434v1>|[代码](https://github.com/XiaokunFeng/CSTrack.); CSTrack通过建模紧凑时空特征，有效整合RGB和X模态数据，简化模型结构并提升RGB-X跟踪性能...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 跨模态一致性学习 (Cross-modal Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Compile Scene Graphs with Reinforcement Learning|使用强化学习编译场景图|Zuyao Chen, Jinlin Wu, Zhen Lei, Marc Pollefeys, Chang Wen Chen|<http://arxiv.org/pdf/2504.13617v4>|[代码](https://github.com/gpt4vision/R1-SGG); 提出R1-SGG，通过强化学习提升多模态语言模型生成场景图的能力。|


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Modality Curation: Building Universal Embeddings for Advanced Multimodal Information Retrieval|模态精炼：构建高级多模态信息检索的通用嵌入|Fanheng Kong, Jingyuan Zhang, Yahui Liu, Hongzhi Zhang, Shi Feng, Xiaocui Yang, Daling Wang, Yu Tian .etc.|<http://arxiv.org/pdf/2505.19650v1>|[代码](https://friedrichor.github.io/projects); 提出UNITE框架，通过数据管理和模态感知训练解决多模态信息检索的异构性和对齐难题。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Data-Free Class-Incremental Gesture Recognition with Prototype-Guided Pseudo Feature Replay|无数据类增量手势识别：基于原型引导的伪特征重放|Hongsong Wang, Ao Sun, Jie Gui, Liang Wang|<http://arxiv.org/pdf/2505.20049v1>|[代码](https://github.com/sunao-101/PGPFR-3); 提出一种数据无关的类增量手势识别方法，通过原型引导伪特征重放框架提升识别准确率。|
|📝 更新|A Survey on the Safety and Security Threats of Computer-Using Agents: JARVIS or Ultron?|计算机使用代理的安全与安全威胁综述：JARVIS还是乌龙？|Ada Chen, Yongjiang Wu, Junyuan Zhang, Jingyu Xiao, Shu Yang, Jen-tse Huang, Kun Wang, Wenxuan Wang .etc.|<http://arxiv.org/pdf/2505.10924v2>|系统化分析了计算机使用代理的安全威胁，并提出了防御策略和评估方法。|
|📝 更新|Semantic Correspondence: Unified Benchmarking and a Strong Baseline|语义对应：统一基准测试和强大基线|Kaiyan Zhang, Xinghui Li, Jingyi Lu, Kai Han|<http://arxiv.org/pdf/2505.18060v2>|[代码](https://github.com/Visual-AI/Semantic-Correspondence.); 首次全面综述语义对应方法，提出统一基准和高效基线。|
|📝 更新|PillarHist: A Quantization-aware Pillar Feature Encoder based on Height-aware Histogram|柱状图感知的Pillar特征编码器：基于高度感知直方图|Sifan Zhou, Zhihang Yuan, Dawei Yang, Ziyu Zhao, Jian Qian, Xing Hu|<http://arxiv.org/pdf/2405.18734v4>|提出PillarHist，通过高度感知的柱状图编码，有效提升3D物体检测性能并降低量化复杂度。|
|🆕 发布|FlowCut: Rethinking Redundancy via Information Flow for Efficient Vision-Language Models|FlowCut：通过信息流重新思考冗余以提高视觉-语言模型的效率|Jintao Tong, Wenwei Jin, Pengda Qin, Anqi Li, Yixiong Zou, Yuhong Li, Yuhua Li, Ruixuan Li|<http://arxiv.org/pdf/2505.19536v1>|[代码](https://github.com/TungChintao/FlowCut); FlowCut通过信息流分析，有效识别并剪枝视觉语言模型中的冗余视觉标记，显著提升模型效率。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Survey of LLM-based Agents in Medicine: How far are we from Baymax?|医学领域基于LLM代理的综述：我们离Baymax还有多远？|Wenxuan Wang, Zizhan Ma, Zheng Wang, Chenghan Wu, Jiaming Ji, Wenting Chen, Xiang Li, Yixuan Yuan|<http://arxiv.org/pdf/2502.11211v2>|综述了基于大型语言模型的医疗智能体，分析了其架构、应用和挑战，展望了未来研究方向。|
|🆕 发布|Optimizing edge AI models on HPC systems with the edge in the loop|在边缘循环中优化高性能计算系统上的边缘AI模型|Marcel Aach, Cyril Blanc, Andreas Lintermann, Kurt De Grave|<http://arxiv.org/pdf/2505.19995v1>|提出了一种结合边缘设备和HPC系统进行硬件感知神经架构搜索，以优化边缘AI模型的方法，显著提升模型性...|
|🆕 发布|A Responsible Face Recognition Approach for Small and Mid-Scale Systems Through Personalized Neural Networks|负责任的小型和中型系统个性化神经网络人脸识别方法|Sebastian Groß, Stefan Heindorf, Philipp Terhörst|<http://arxiv.org/pdf/2505.19920v1>|提出个性化神经网络，为小中规模系统提供更负责任的识别方法，提升公平性和隐私保护。|
|📝 更新|Distilling Textual Priors from LLM to Efficient Image Fusion|从大型语言模型中提取文本先验以实现高效图像融合|Ran Zhang, Xuanhua He, Ke Cao, Liu Liu, Li Zhang, Man Zhou, Jie Zhang|<http://arxiv.org/pdf/2504.07029v3>|提出了一种从大型语言模型中提取文本先验的图像融合框架，显著降低计算成本并提升融合质量。|
|📝 更新|Adaptive Rank, Reduced Forgetting: Knowledge Retention in Continual Learning Vision-Language Models with Dynamic Rank-Selective LoRA|自适应排名，减少遗忘：动态排名选择LoRA在持续学习视觉-语言模型中的知识保留|Haodong Lu, Chongyang Zhao, Jason Xue, Lina Yao, Kristen Moore, Dong Gong|<http://arxiv.org/pdf/2412.01004v5>|提出了一种动态排名选择LoRA方法，有效保留预训练知识并提升视觉语言模型在持续学习中的表现。|
|🆕 发布|Revolutionizing Wildfire Detection with Convolutional Neural Networks: A VGG16 Model Approach|利用卷积神经网络革新野火检测：VGG16模型方法|Lakshmi Aishwarya Malladi, Navarun Gupta, Ahmed El-Sayed, Xingguo Xiong|<http://arxiv.org/pdf/2505.19479v1>|利用VGG16模型和数据增强技术，有效提升了野火检测的准确率。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Efficient Multi-modal Long Context Learning for Training-free Adaptation|高效的多模态长上下文学习用于无监督自适应|Zehong Ma, Shiliang Zhang, Longhui Wei, Qi Tian|<http://arxiv.org/pdf/2505.19812v1>|[代码](https://github.com/Zehong-Ma/EMLoC.); 提出EMLoC，一种高效的多模态长上下文学习新方法，实现无监督任务适应。|
|📝 更新|CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting|CompMarkGS：压缩3D高斯分层鲁棒水印|Sumin In, Youngdong Jang, Utae Jeong, MinHyuk Jang, Hyeongcheol Park, Eunbyung Park, Sangpil Kim|<http://arxiv.org/pdf/2503.12836v4>|提出了一种抗压缩鲁棒的3DGS水印方法，确保水印在模型压缩后仍能保持高质量。|
|🆕 发布|SMART-PC: Skeletal Model Adaptation for Robust Test-Time Training in Point Clouds|智能-PC：点云中的鲁棒测试时训练的骨骼模型自适应|Ali Bahri, Moslem Yazdanpanah, Sahar Dastani, Mehrdad Noori, Gustavo Adolfo Vargas Hakim, David Osowiechi, Farzad Beizaee, Ismail Ben Ayed .etc.|<http://arxiv.org/pdf/2505.19546v1>|[代码](https://github.com/AliBahri94/SMART-PC.); SMART-PC通过骨骼模型预测，实现点云分类的实时自适应，显著提升鲁棒性和效率。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ZeroPur: Succinct Training-Free Adversarial Purification|零净化：简洁的无训练对抗净化|Erhu Liu, Zonglin Yang, Bo Liu, Bin Xiao, Xiuli Bi|<http://arxiv.org/pdf/2406.03143v2>|提出ZeroPur，一种无需训练的对抗净化方法，有效提升对抗攻击防御能力。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OmniFall: A Unified Staged-to-Wild Benchmark for Human Fall Detection|全场景跌倒检测：一个从场景到真实世界的统一分阶段基准|David Schneider, Zdravko Marinov, Rafael Baur, Zeyun Zhong, Rodi Düger, Rainer Stiefelhagen|<http://arxiv.org/pdf/2505.19889v1>|[代码](https://github.com/simplexsigil/omnifall-experiments); OmniFall构建了一个统一的基准，通过标准化数据和评估协议，解决了现有跌倒检测数据集的域偏倚和泛...|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|WQLCP: Weighted Adaptive Conformal Prediction for Robust Uncertainty Quantification Under Distribution Shifts|WQLCP：基于分布偏移的鲁棒不确定性量化加权自适应一致预测|Shadi Alijani, Homayoun Najjaran|<http://arxiv.org/pdf/2505.19587v1>|提出WQLCP方法，通过加权自适应调整，提高分布偏移下的一致性预测的鲁棒性。|
|🆕 发布|Certainty and Uncertainty Guided Active Domain Adaptation|确定性及不确定性引导的主动域自适应|Bardia Safaei, Vibashan VS, Vishal M. Patel|<http://arxiv.org/pdf/2505.19421v1>|提出一种结合置信度引导的主动域适应方法，有效提升模型跨域适应性能。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Improvement Strategies for Few-Shot Learning in OCT Image Classification of Rare Retinal Diseases|OCT图像分类中罕见视网膜疾病少样本学习的改进策略|Cheng-Yu Tai, Ching-Wen Chen, Chi-Chin Wu, Bo-Chen Chiu, Cheng-Hung, Lin, Cheng-Kai Lu, Jia-Kang Wang .etc.|<http://arxiv.org/pdf/2505.20149v1>|提出基于U-GAT-IT和CBAM的GAN增强策略，显著提升OCT图像分类准确率。|
|🆕 发布|DepthMatch: Semi-Supervised RGB-D Scene Parsing through Depth-Guided Regularization|深度匹配：通过深度引导正则化的半监督RGB-D场景解析|Jianxin Huang, Jiahang Li, Sergey Vityazev, Alexander Dvorkovich, Rui Fan|<http://arxiv.org/pdf/2505.20041v1>|DepthMatch通过深度引导正则化和半监督学习，有效提升了RGB-D场景解析的效率和准确性。|
|🆕 发布|SaSi: A Self-augmented and Self-interpreted Deep Learning Approach for Few-shot Cryo-ET Particle Detection|SaSi：一种用于少量样本冷冻电子断层扫描粒子检测的自增强和自解释深度学习方法|Gokul Adethya, Bhanu Pratyush Mantha, Tianyang Wang, Xingjian Li, Min Xu|<http://arxiv.org/pdf/2505.19948v1>|提出SaSi方法，通过自增强和自解释技术，在少量标注数据下显著提升cryo-ET粒子检测性能。|
|📝 更新|DeepEyes: Incentivizing "Thinking with Images" via Reinforcement Learning|深度视觉：通过强化学习激励“以图思考”|Ziwei Zheng, Michael Yang, Jack Hong, Chenxiao Zhao, Guohai Xu, Le Yang, Chao Shen, Xing Yu|<http://arxiv.org/pdf/2505.14362v2>|[代码](https://github.com/Visual-Agent/DeepEyes.); 通过强化学习激励模型“以图像思考”，实现视觉与文本推理的无缝结合。|
|🆕 发布|Multi-Timescale Motion-Decoupled Spiking Transformer for Audio-Visual Zero-Shot Learning|多尺度运动解耦脉冲变换器在音频-视觉零样本学习中的应用|Wenrui Li, Penghong Wang, Xingtao Wang, Wangmeng Zuo, Xiaopeng Fan, Yonghong Tian|<http://arxiv.org/pdf/2505.19938v1>|提出了一种多尺度运动解耦的脉冲神经网络，有效提升了音频视觉零样本学习性能。|
|📝 更新|UAV-Flow Colosseo: A Real-World Benchmark for Flying-on-a-Word UAV Imitation Learning|无人机-流动科洛塞奥：飞行在单词无人机模仿学习的一个真实世界基准|Xiangyu Wang, Donglin Yang, Yue Liao, Wenhao Zheng, wenjun wu, Bin Dai, Hongsheng Li, Si Liu|<http://arxiv.org/pdf/2505.15725v2>|构建了首个真实世界基准UAV-Flow，通过模仿学习实现语言引导的UAV精细控制。|
|📝 更新|Generalizable Prompt Learning of CLIP: A Brief Overview|CLIP的泛化提示学习：简要概述|Fangming Cui, Yonggang Zhang, Xuan Wang, Xule Wang, Liang Xiao|<http://arxiv.org/pdf/2503.01263v5>|该论文概述了CLIP的通用提示学习方法，通过少量样本训练实现跨15个数据集的分类。|
|📝 更新|Navigating Conflicting Views: Harnessing Trust for Learning|在冲突观点中导航：利用信任进行学习|Jueqing Lu, Wray Buntine, Yuanyuan Qi, Joanna Dipnall, Belinda Gabbe, Lan Du|<http://arxiv.org/pdf/2406.00958v3>|开发了一种基于信任机制的降权方法，有效解决多视角分类中的冲突，提升预测可靠性。|
|🆕 发布|Multiplicity is an Inevitable and Inherent Challenge in Multimodal Learning|多模态学习中的多义性是一个不可避免且固有的挑战|Sanghyuk Chun|<http://arxiv.org/pdf/2505.19614v1>|提出新框架应对多模态学习中的“多重性”挑战，提升数据质量和训练可靠性。|
|🆕 发布|Few-Shot Class-Incremental Learning For Efficient SAR Automatic Target Recognition|少量样本类增量学习用于高效的SAR自动目标识别|George Karantaidis, Athanasios Pantsios, Ioannis Kompatsiaris, Symeon Papadopoulos|<http://arxiv.org/pdf/2505.19565v1>|提出了一种基于双分支架构的轻量级FSCIL框架，有效解决了SAR-ATR中的数据稀缺问题。|
|🆕 发布|Applications and Effect Evaluation of Generative Adversarial Networks in Semi-Supervised Learning|半监督学习中生成对抗网络的应用与效果评估|Jiyu Hu, Haijiang Zeng, Zhen Tian|<http://arxiv.org/pdf/2505.19522v1>|构建基于GANs的半监督图像分类模型，有效利用有限标注数据与大量未标注数据，提升分类精度。|
|📝 更新|SUFFICIENT: A scan-specific unsupervised deep learning framework for high-resolution 3D isotropic fetal brain MRI reconstruction|SUFFICIENT：一种针对扫描特定的高分辨率3D各向同性胎儿脑MRI重建的无监督深度学习框架|Jiangjie Wu, Lixuan Chen, Zhenghao Li, Xin Li, Saban Ozturk, Lihui Wang, Rongpin Wang, Hongjiang Wei .etc.|<http://arxiv.org/pdf/2505.17472v2>|提出了一种无监督深度学习框架，有效解决胎儿脑MRI重建中的运动伪影问题。|
|🆕 发布|Exploring the Possibility of TypiClust for Low-Budget Federated Active Learning|探索TypiClust在低成本联邦主动学习中的可能性|Yuta Ono, Hiroshi Nakamura, Hideki Takase|<http://arxiv.org/pdf/2505.19404v1>|在低预算联邦主动学习中，验证了TypiClust方法的有效性，即使在数据异质和标注有限的挑战下。|
|🆕 发布|DiSa: Directional Saliency-Aware Prompt Learning for Generalizable Vision-Language Models|DiSa：面向泛化视觉-语言模型的定向显著性感知提示学习|Niloufar Alipour Talemi, Hossein Kashiani, Hossein R. Nowdeh, Fatemeh Afghah|<http://arxiv.org/pdf/2505.19373v1>|DiSa通过结合交叉交互正则化和方向性正则化，提升了视觉语言模型在下游任务中的泛化能力。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Exploring 3D Activity Reasoning and Planning: From Implicit Human Intentions to Route-Aware Planning|探索3D活动推理与规划：从隐含人类意图到路径感知规划|Xueying Jiang, Wenhao Li, Xiaoqin Zhang, Ling Shao, Shijian Lu|<http://arxiv.org/pdf/2503.12974v2>|提出了一种从隐含指令推理活动并规划路径的3D任务，有效解决现有研究的依赖指令和忽略路径规划问题。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|STAR-R1: Spatial TrAnsformation Reasoning by Reinforcing Multimodal LLMs|STAR-R1：通过强化多模态LLMs进行空间变换推理|Zongzhao Li, Zongyang Ma, Mingze Li, Songyou Li, Yu Rong, Tingyang Xu, Ziqi Zhang, Deli Zhao .etc.|<http://arxiv.org/pdf/2505.15804v2>|[代码](https://github.com/zongzhao23/STAR-R1.); STAR-R1通过强化学习，有效提升了多模态LLMs在空间推理方面的能力。|
|📝 更新|Task-Oriented Communications for Visual Navigation with Edge-Aerial Collaboration in Low Altitude Economy|面向任务的边缘无人机协作低空经济视觉导航通信|Zhengru Fang, Zhenghao Liu, Jingjing Wang, Senkang Hu, Yu Guo, Yiqin Deng, Yuguang Fang|<http://arxiv.org/pdf/2504.18317v4>|[代码](https://github.com/fangzr/TOC-Edge-Aerial.); 提出一种基于任务导向的通信框架，通过O-VIB编码器实现无人机在低带宽环境下的高精度定位。|
|📝 更新|NoisyRollout: Reinforcing Visual Reasoning with Data Augmentation|噪声回滚：通过数据增强强化视觉推理|Xiangyan Liu, Jinjie Ni, Zijian Wu, Chao Du, Longxu Dou, Haonan Wang, Tianyu Pang, Michael Qizhe Shieh|<http://arxiv.org/pdf/2504.13055v2>|NoisyRollout通过混合不同视觉感知轨迹，有效增强视觉语言模型推理能力。|
|📝 更新|VR-Robo: A Real-to-Sim-to-Real Framework for Visual Robot Navigation and Locomotion|VR-Robo：一种真实到模拟再到真实视觉机器人导航与运动框架|Shaoting Zhu, Linzhan Mou, Derun Li, Baijun Ye, Runhan Huang, Hang Zhao|<http://arxiv.org/pdf/2502.01536v2>|提出VR-Robo框架，通过生成逼真模拟环境，解决视觉机器人导航和运动中的真实与模拟差距问题。|
|🆕 发布|Decomposing Complex Visual Comprehension into Atomic Visual Skills for Vision Language Models|将复杂视觉理解分解为原子视觉技能用于视觉语言模型|Hyunsik Chae, Seungwoo Yoon, Jaden Park, Chloe Yewon Chun, Yongin Cho, Mu Cai, Yong Jae Lee, Ernest K. Ryu|<http://arxiv.org/pdf/2505.20021v1>|将复杂视觉理解分解为原子视觉技能，构建数据集评估视觉语言模型在基础视觉任务上的表现。|
|🆕 发布|Progressive Scaling Visual Object Tracking|渐进式缩放视觉目标跟踪|Jack Hong, Shilin Yan, Zehao Xiao, Jiayin Cai, Xiaolong Jiang, Yao Hu, Henghui Ding|<http://arxiv.org/pdf/2505.19990v1>|提出渐进式缩放训练策略，显著提升视觉目标跟踪性能。|
|📝 更新|Dynamic Multimodal Evaluation with Flexible Complexity by Vision-Language Bootstrapping|动态多模态评估：通过视觉-语言引导的灵活复杂性|Yue Yang, Shuibai Zhang, Wenqi Shao, Kaipeng Zhang, Yi Bin, Yu Wang, Ping Luo|<http://arxiv.org/pdf/2410.08695v3>|提出Vision-Language Bootstrapping方法，动态评估LVLMs，减少数据污染...|
|🆕 发布|Point-RFT: Improving Multimodal Reasoning with Visually Grounded Reinforcement Finetuning|点-RFT：通过视觉基础强化微调提升多模态推理|Minheng Ni, Zhengyuan Yang, Linjie Li, Chung-Ching Lin, Kevin Lin, Wangmeng Zuo, Lijuan Wang|<http://arxiv.org/pdf/2505.19702v1>|Point-RFT通过视觉基础CoT推理，显著提升了视觉文档理解的多模态推理能力。|
|🆕 发布|Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition|知识对齐的对抗增强扩散感知用于无监督跨域视觉情感识别|Wen Yin, Yong Wang, Guiduo Duan, Dongyang Zhang, Xin Hu, Yuan-Fang Li, Tao He|<http://arxiv.org/pdf/2505.19694v1>|[代码](https://yinwen2019.github.io/ucdver.); 定位跨域视觉情感识别挑战，提出知识对齐的对抗增强扩散感知框架，提升模型感知和泛化能力。|
|🆕 发布|VisCRA: A Visual Chain Reasoning Attack for Jailbreaking Multimodal Large Language Models|视觉链推理攻击：用于越狱多模态大型语言模型的VisCRA|Bingrui Sima, Linhua Cong, Wenxuan Wang, Kun He|<http://arxiv.org/pdf/2505.19684v1>|提出VisCRA攻击框架，利用视觉推理链破解多模态大型语言模型的安全机制。|
|🆕 发布|Benchmarking Large Multimodal Models for Ophthalmic Visual Question Answering with OphthalWeChat|眼科视觉问答中大型多模态模型的基准测试：基于OphthalWeChat|Pusheng Xu, Xia Gong, Xiaolan Chen, Weiyi Zhang, Jiancheng Yang, Bingjie Yan, Meng Yuan, Yalin Zheng .etc.|<http://arxiv.org/pdf/2505.19624v1>|构建了首个眼科双语视觉问答基准，评估了大型多模态模型在眼科领域的性能。|
|🆕 发布|Align and Surpass Human Camouflaged Perception: Visual Refocus Reinforcement Fine-Tuning|对齐并超越人类伪装感知：视觉重新聚焦强化微调|Ruolin Shen, Xiaozhong Ji, Kai WU, Jiangning Zhang, Yijun He, HaiHua Yang, Xiaobin Hu, Xiaoyu Sun|<http://arxiv.org/pdf/2505.19611v1>|提出视觉重聚焦强化框架，使多模态模型在伪装感知任务上超越人类视觉系统。|
|🆕 发布|Multimodal Machine Translation with Visual Scene Graph Pruning|多模态机器翻译与视觉场景图剪枝|Chenyu Lu, Shiliang Sun, Jing Zhao, Nan Zhang, Tengfei Song, Hao Yang|<http://arxiv.org/pdf/2505.19507v1>|通过视觉场景图剪枝，有效减少冗余视觉信息，提升多模态机器翻译准确度。|
|📝 更新|Parrot: Multilingual Visual Instruction Tuning|鹦鹉：多语言视觉指令微调|Hai-Long Sun, Da-Wei Zhou, Yang Li, Shiyin Lu, Chao Yi, Qing-Guo Chen, Zhao Xu, Weihua Luo .etc.|<http://arxiv.org/pdf/2406.02539v3>|[代码](https://github.com/AIDC-AI/Parrot); PARROT通过文本引导视觉标记对齐，提升多语言视觉指令理解能力。|
|🆕 发布|MM-Prompt: Cross-Modal Prompt Tuning for Continual Visual Question Answering|MM-Prompt：跨模态提示微调用于持续视觉问答|Xu Li, Fan Lyu|<http://arxiv.org/pdf/2505.19455v1>|MM-Prompt通过跨模态提示查询和恢复，解决CVQA中模态不平衡问题，提升持续学习性能。|
|📝 更新|Pixel Reasoner: Incentivizing Pixel-Space Reasoning with Curiosity-Driven Reinforcement Learning|像素推理器：利用好奇心驱动的强化学习激励像素空间推理|Alex Su, Haozhe Wang, Weiming Ren, Fangzhen Lin, Wenhu Chen|<http://arxiv.org/pdf/2505.15966v2>|通过引入像素空间推理和强化学习，显著提升了视觉语言模型在视觉推理任务上的性能。|
|📝 更新|Semantic-Space-Intervened Diffusive Alignment for Visual Classification|语义空间介入的扩散对齐用于视觉分类|Zixuan Li, Lei Meng, Guoqing Chao, Wei Wu, Xiaoshuo Yan, Yimeng Yang, Zhuang Qi, Xiangxu Meng|<http://arxiv.org/pdf/2505.05721v2>|提出SeDA方法，通过语义空间干预和渐进式特征交互，有效解决跨模态视觉分类中的特征对齐问题。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Human-Aligned Image Models Improve Visual Decoding from the Brain|人脑视觉解码的图像模型：与人类对齐|Nona Rajabi, Antônio H. Ribeiro, Miguel Vasco, Farzaneh Taleb, Mårten Björkman, Danica Kragic|<http://arxiv.org/pdf/2502.03081v2>|利用人类对图像的感知特性，提出了一种新的脑电图图像解码方法，显著提升了图像检索准确率。|
|🆕 发布|Can Visual Encoder Learn to See Arrows?|视觉编码器能否学会识别箭头？|Naoyuki Terashita, Yusuke Tozaki, Hideaki Omote, Congkha Nguyen, Ryosuke Nakamoto, Yuta Koreeda, Hiroaki Ozaki|<http://arxiv.org/pdf/2505.19944v1>|通过消除文本和位置偏见，本研究提出了一种训练视觉编码器识别图像中箭头的方法，显著提升了视觉语言模型对...|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Corrupted but Not Broken: Understanding and Mitigating the Negative Impacts of Corrupted Data in Visual Instruction Tuning|损坏但未破碎：理解并减轻视觉指令微调中损坏数据的负面影响|Yunhao Gou, Hansi Yang, Zhili Liu, Kai Chen, Yihan Zeng, Lanqing Hong, Zhenguo Li, Qun Liu .etc.|<http://arxiv.org/pdf/2502.12635v2>|提出了一种应对视觉指令微调中数据损坏问题的鲁棒训练范式，显著提升模型性能。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ReasonPlan: Unified Scene Prediction and Decision Reasoning for Closed-loop Autonomous Driving|ReasonPlan：闭环自动驾驶的统一场景预测与决策推理|Xueyi Liu, Zuodong Zhong, Yuxin Guo, Yun-Fu Liu, Zhiguo Su, Qichao Zhang, Junli Wang, Yinfeng Gao .etc.|<http://arxiv.org/pdf/2505.20024v1>|[代码](https://github.com/Liuxueyi/ReasonPlan.); ReasonPlan通过结合自监督场景预测和决策推理，显著提升了闭环自动驾驶的决策能力。|
|🆕 发布|DriveCamSim: Generalizable Camera Simulation via Explicit Camera Modeling for Autonomous Driving|自动驾驶中的通用相机模拟：通过显式相机建模实现|Wenchao Sun, Xuewu Lin, Keyu Chen, Zixiang Pei, Yining Shi, Chuang Zhang, Sifa Zheng|<http://arxiv.org/pdf/2505.19692v1>|[代码](https://github.com/swc-17/DriveCamSim); DriveCamSim通过显式相机建模，实现了可扩展的相机模拟，解决了现有方法在多视角视频生成和可控...|
|📝 更新|NuGrounding: A Multi-View 3D Visual Grounding Framework in Autonomous Driving|NuGrounding：自动驾驶中的多视角3D视觉定位框架|Fuhao Li, Huan Jin, Bin Gao, Liaoyuan Fan, Lihui Jiang, Long Zeng|<http://arxiv.org/pdf/2503.22436v2>|NuGrounding提出了一种结合多模态LLMs和检测模型的方法，显著提升了自动驾驶中多视图3D视...|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Zero-Shot Pseudo Labels Generation Using SAM and CLIP for Semi-Supervised Semantic Segmentation|基于SAM和CLIP的零样本伪标签生成用于半监督语义分割|Nagito Saito, Shintaro Ito, Koichi Ito, Takafumi Aoki|<http://arxiv.org/pdf/2505.19846v1>|利用SAM和CLIP生成伪标签，结合UniMatch提升半监督语义分割模型精度。|
|🆕 发布|Improving Heart Rejection Detection in XPCI Images Using Synthetic Data Augmentation|利用合成数据增强提高XPCI图像中心脏排斥检测的准确性|Jakov Samardžija, Donik Vršnak, Sven Lončarić|<http://arxiv.org/pdf/2505.19746v1>|利用StyleGAN生成合成数据，有效缓解了心脏排斥检测中数据不平衡问题，提升了分类性能。|
|🆕 发布|LangDAug: Langevin Data Augmentation for Multi-Source Domain Generalization in Medical Image Segmentation|LangDAug：用于医学图像分割的多源域泛化的Langevin数据增强|Piyush Tiwary, Kinjawl Bhattacharyya, Prathosh A. P|<http://arxiv.org/pdf/2505.19659v1>|[代码](https://github.com/backpropagator/LangDAug.); LangDAug通过Langevin动力学和EBM实现多源域泛化，有效提升医学图像分割性能。|
|📝 更新|DAE-Fuse: An Adaptive Discriminative Autoencoder for Multi-Modality Image Fusion|DAE-Fuse：一种自适应判别自编码器用于多模态图像融合|Yuchen Guo, Ruoxiang Xu, Rongcheng Li, Weifeng Su|<http://arxiv.org/pdf/2409.10080v3>|DAE-Fuse提出了一种自适应判别自编码器，有效融合多模态图像，提升夜间或低可见环境下的感知能力。|
|🆕 发布|Rep3D: Re-parameterize Large 3D Kernels with Low-Rank Receptive Modeling for Medical Imaging|Rep3D：利用低秩感受野建模对大型3D核进行重新参数化以用于医学成像|Ho Hin Lee, Quan Liu, Shunxing Bao, Yuankai Huo, Bennett A. Landman|<http://arxiv.org/pdf/2505.19603v1>|[代码](https://github.com/leeh43/Rep3D.); Rep3D通过低秩感受野建模，优化大核卷积，提升3D医学图像分析性能。|
|📝 更新|Auto-nnU-Net: Towards Automated Medical Image Segmentation|自动nnU-Net：迈向自动化医学图像分割|Jannis Becktepe, Leona Hennig, Steffen Oeltze-Jafra, Marius Lindauer|<http://arxiv.org/pdf/2505.16561v2>|[代码](https://github.com/LUH-AI/AutonnUNet.); 提出Auto-nnU-Net，通过自动化超参数优化和架构搜索，显著提升医学图像分割性能，同时平衡计算...|
|📝 更新|Unsupervised Anomaly Detection Using Diffusion Trend Analysis for Display Inspection|基于扩散趋势分析的显示检查无监督异常检测|Eunwoo Kim, Un Yang, Cheol Lae Roh, Stefano Ermon|<http://arxiv.org/pdf/2407.09578v2>|提出了一种基于重建趋势分析的异常检测方法，有效解决了显示检测中的噪声参数和正常区域波动问题。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ImageRAG: Enhancing Ultra High Resolution Remote Sensing Imagery Analysis with ImageRAG|图像RAG：利用图像RAG增强超高分辨率遥感图像分析|Zilun Zhang, Haozhan Shen, Tiancheng Zhao, Zian Guan, Bin Chen, Yuhao Wang, Xu Jia, Yuxiang Cai .etc.|<http://arxiv.org/pdf/2411.07688v4>|[代码](https://github.com/om-ai-lab/ImageRAG); ImageRAG通过RAG技术，高效处理超高清遥感图像，提升分析准确性和效率。|
|📝 更新|Cross-Modal Bidirectional Interaction Model for Referring Remote Sensing Image Segmentation|跨模态双向交互模型用于遥感图像分割|Zhe Dong, Yuzhe Sun, Tianzhu Liu, Wangmeng Zuo, Yanfeng Gu|<http://arxiv.org/pdf/2410.08613v2>|[代码](https://github.com/HIT-SIRS/CroBIM); 检测并分割遥感图像中的目标物体，提出了一种跨模态双向交互模型，显著提升了分割精度。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OpenAD: Open-World Autonomous Driving Benchmark for 3D Object Detection|开放世界自动驾驶3D目标检测基准：OpenAD|Zhongyu Xia, Jishuo Li, Zhiwei Lin, Xinhao Wang, Yongtao Wang, Ming-Hsuan Yang|<http://arxiv.org/pdf/2411.17761v2>|[代码](https://github.com/VDIGPKU/OpenAD.); 构建首个开放世界自动驾驶3D物体检测基准OpenAD，并提出融合模型解决精度问题。|
|🆕 发布|DiffVLA: Vision-Language Guided Diffusion Planning for Autonomous Driving|DiffVLA：视觉-语言引导的自动驾驶扩散规划|Anqing Jiang, Yu Gao, Zhigang Sun, Yiru Wang, Jijun Wang, Jinghao Chai, Qian Cao, Yuweng Heng .etc.|<http://arxiv.org/pdf/2505.19381v1>|DiffVLA通过结合视觉语言模型和稀疏密集扩散策略，有效提升了自动驾驶在复杂场景下的决策性能。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|JailBound: Jailbreaking Internal Safety Boundaries of Vision-Language Models|《JailBound：突破视觉-语言模型内部安全边界》|Jiaxin Song, Yixu Wang, Jie Li, Rui Yu, Yan Teng, Xingjun Ma, Yingchun Wang|<http://arxiv.org/pdf/2505.19610v1>|提出JailBound框架，通过探测和跨越视觉语言模型内部安全边界，有效提升对抗攻击成功率。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Deep Spectral Prior|深度光谱先验|Yanqi Cheng, Tieyong Zeng, Pietro Lio, Carola-Bibiane Schönlieb, Angelica I Aviles-Rivero|<http://arxiv.org/pdf/2505.19873v1>|提出深度光谱先验，将图像重建视为频域对齐问题，有效抑制噪声并提升重建质量。|
|🆕 发布|Translation-Equivariance of Normalization Layers and Aliasing in Convolutional Neural Networks|卷积神经网络中归一化层的平移等变性和混叠|Jérémy Scanvic, Quentin Barthélemy, Julián Tachella|<http://arxiv.org/pdf/2505.19805v1>|揭示了归一化层对平移的等变性，为构建更精确的卷积神经网络提供了理论框架。|
|🆕 发布|Rotation-Equivariant Self-Supervised Method in Image Denoising|旋转等变图像去噪的自监督方法|Hanze Liu, Jiahong Fu, Qi Xie, Deyu Meng|<http://arxiv.org/pdf/2505.19618v1>|首次将旋转等变先验引入自监督图像去噪，并设计新机制融合旋转等变网络与普通CNN网络输出，显著提升去噪...|
|🆕 发布|FieldWorkArena: Agentic AI Benchmark for Real Field Work Tasks|FieldWorkArena：真实野外工作任务的代理人工智能基准|Atsunori Moteki, Shoichi Masui, Fan Yang, Yueqi Song, Yonatan Bisk, Graham Neubig, Ikuo Kusajima, Yasuto Watanabe .etc.|<http://arxiv.org/pdf/2505.19662v1>|FieldWorkArena提出首个针对真实世界现场工作任务的Agentic AI基准，评估其在多模...|
|🆕 发布|M3DHMR: Monocular 3D Hand Mesh Recovery|M3DHMR：单目3D手部网格恢复|Yihong Lin, Xianjia Wu, Xilai Wang, Jianqiao Hu, Songju Lei, Xiandong Li, Wenxiong Kang|<http://arxiv.org/pdf/2505.20058v1>|M3DHMR通过创新解码器直接从单张图像恢复3D手部网格，显著提升实时性能。|

