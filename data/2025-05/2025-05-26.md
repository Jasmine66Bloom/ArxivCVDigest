## [UPDATED!] **2025-05-26** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Hard Negative Contrastive Learning for Fine-Grained Geometric Understanding in Large Multimodal Models|ç¡¬è´Ÿå¯¹æ¯”å­¦ä¹ åœ¨å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ä¸­å®ç°ç»†ç²’åº¦å‡ ä½•ç†è§£|Kai Sun, Yushi Bai, Zhen Yang, Jiajie Zhang, Ji Qi, Lei Hou, Juanzi Li|<http://arxiv.org/pdf/2505.20152v1>|[ä»£ç ](https://github.com/THU-KEG/MMGeoLM.); æå‡ºäº†ä¸€ç§ç»“åˆå›¾åƒå’Œæ–‡æœ¬å¯¹æ¯”å­¦ä¹ çš„æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†å¤§å‹å¤šæ¨¡æ€æ¨¡å‹åœ¨å‡ ä½•é—®é¢˜è§£å†³ä¸Šçš„èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|FUDOKI: Discrete Flow-based Unified Understanding and Generation via Kinetic-Optimal Velocities|FUDOKIï¼šåŸºäºç¦»æ•£æµçš„ç»Ÿä¸€ç†è§£å’Œç”Ÿæˆé€šè¿‡åŠ¨åŠ›å­¦æœ€ä¼˜é€Ÿåº¦|Jin Wang, Yao Lai, Aoxue Li, Shifeng Zhang, Jiacheng Sun, Ning Kang, Chengyue Wu, Zhenguo Li .etc.|<http://arxiv.org/pdf/2505.20147v1>|FUDOKIé€šè¿‡ç¦»æ•£æµåŒ¹é…æŒ‘æˆ˜äº†åŸºäºè‡ªå›å½’æ¶æ„çš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œå®ç°äº†è§†è§‰ç†è§£å’Œå›¾åƒç”Ÿæˆçš„ç»Ÿä¸€ã€‚|
|ğŸ“ æ›´æ–°|Time-VLM: Exploring Multimodal Vision-Language Models for Augmented Time Series Forecasting|æ—¶é—´-è§†è§‰è¯­è¨€æ¨¡å‹ï¼šæ¢ç´¢å¤šæ¨¡æ€è§†è§‰-è¯­è¨€æ¨¡å‹ç”¨äºå¢å¼ºæ—¶é—´åºåˆ—é¢„æµ‹|Siru Zhong, Weilin Ruan, Ming Jin, Huan Li, Qingsong Wen, Yuxuan Liang|<http://arxiv.org/pdf/2502.04395v2>|[ä»£ç ](https://github.com/CityMind-Lab/ICML25-TimeVLM.); æå‡ºTime-VLMï¼Œé€šè¿‡èåˆè§†è§‰ã€æ–‡æœ¬å’Œæ—¶åºä¿¡æ¯ï¼Œæ˜¾è‘—æå‡æ—¶é—´åºåˆ—é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚|
|ğŸ“ æ›´æ–°|WorldSense: Evaluating Real-world Omnimodal Understanding for Multimodal LLMs|æ ‡é¢˜ç¿»è¯‘ï¼šä¸–ç•Œæ„ŸçŸ¥ï¼šè¯„ä¼°å¤šæ¨¡æ€LLMsçš„å®ä¸–ç•Œå…¨æ¨¡æ€ç†è§£|Jack Hong, Shilin Yan, Jiayin Cai, Xiaolong Jiang, Yao Hu, Weidi Xie|<http://arxiv.org/pdf/2502.04326v2>|WorldSenseæ„å»ºé¦–ä¸ªå¤šæ¨¡æ€è§†é¢‘ç†è§£åŸºå‡†ï¼Œè¯„ä¼°æ¨¡å‹åœ¨æ„å»ºå’Œè§£æå¤šæ¨¡æ€ä¸Šä¸‹æ–‡ä¸­çš„èƒ½åŠ›ã€‚|
|ğŸ“ æ›´æ–°|Multimodal 3D Reasoning Segmentation with Complex Scenes|å¤šæ¨¡æ€å¤æ‚åœºæ™¯3Dæ¨ç†åˆ†å‰²|Xueying Jiang, Lewei Lu, Ling Shao, Shijian Lu|<http://arxiv.org/pdf/2411.13927v3>|æå‡ºäº†ä¸€ç§é’ˆå¯¹å¤æ‚åœºæ™¯ä¸­å¤šç‰©ä½“æ¨ç†åˆ†å‰²çš„æ–°æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†3Dåœºæ™¯ç†è§£èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|ScienceBoard: Evaluating Multimodal Autonomous Agents in Realistic Scientific Workflows|ç§‘å­¦æ¿ï¼šè¯„ä¼°åœ¨ç°å®ç§‘å­¦å·¥ä½œæµç¨‹ä¸­çš„å¤šæ¨¡æ€è‡ªä¸»æ™ºèƒ½ä½“|Qiushi Sun, Zhoumianze Liu, Chang Ma, Zichen Ding, Fangzhi Xu, Zhangyue Yin, Haiteng Zhao, Zhenyu Wu .etc.|<http://arxiv.org/pdf/2505.19897v1>|[ä»£ç ](https://qiushisun.github.io/ScienceBoard-Home); ScienceBoardæ„å»ºäº†çœŸå®ç§‘å­¦å·¥ä½œæµç¨‹ç¯å¢ƒï¼Œæå‡ºåŸºå‡†æµ‹è¯•ï¼Œè¯„ä¼°å¤šæ¨¡æ€è‡ªä¸»ä»£ç†åœ¨ç§‘å­¦å‘ç°ä¸­çš„è¡¨...|
|ğŸ†• å‘å¸ƒ|FruitNeRF++: A Generalized Multi-Fruit Counting Method Utilizing Contrastive Learning and Neural Radiance Fields|æ°´æœNeRF++ï¼šä¸€ç§åˆ©ç”¨å¯¹æ¯”å­¦ä¹ å’Œç¥ç»è¾å°„åœºçš„é€šç”¨å¤šæ°´æœè®¡æ•°æ–¹æ³•|Lukas Meyer, Andrei-Timotei Ardelean, Tim Weyrich, Marc Stamminger|<http://arxiv.org/pdf/2505.19863v1>|FruitNeRF++é€šè¿‡ç»“åˆå¯¹æ¯”å­¦ä¹ å’Œç¥ç»è¾å°„åœºï¼Œå®ç°äº†ä¸€ç§é€šç”¨çš„å¤šæ°´æœè®¡æ•°æ–¹æ³•ï¼Œæ— éœ€é’ˆå¯¹æ¯ç§æ°´æœ...|
|ğŸ†• å‘å¸ƒ|MLLM-Guided VLM Fine-Tuning with Joint Inference for Zero-Shot Composed Image Retrieval|åŸºäºMLLMå¼•å¯¼çš„è”åˆæ¨ç†VLMå¾®è°ƒç”¨äºé›¶æ ·æœ¬ç»„åˆå›¾åƒæ£€ç´¢|Rong-Cheng Tu, Zhao Jin, Jingyi Liao, Xiao Luo, Yingjie Wang, Li Shen, Dacheng Tao|<http://arxiv.org/pdf/2505.19707v1>|æå‡ºä¸€ç§åŸºäºMLLMå¼•å¯¼çš„VLMå¾®è°ƒæ–¹æ³•ï¼Œé€šè¿‡è”åˆæ¨ç†æå‡é›¶æ ·æœ¬ç»„åˆå›¾åƒæ£€ç´¢æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|CauSkelNet: Causal Representation Learning for Human Behaviour Analysis|å› æœéª¨éª¼ç½‘ç»œï¼šç”¨äºäººç±»è¡Œä¸ºåˆ†æçš„å› æœè¡¨ç¤ºå­¦ä¹ |Xingrui Gu, Chuyi Jiang, Erte Wang, Zekun Wu, Qiang Cui, Leimin Tian, Lianlong Wu, Siyang Song .etc.|<http://arxiv.org/pdf/2409.15564v3>|æå‡ºå› æœæ¨ç†æ¡†æ¶ï¼Œç»“åˆPCç®—æ³•å’ŒKLæ•£åº¦ï¼Œæå‡äººä½“è¡Œä¸ºåˆ†æå‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚|
|ğŸ“ æ›´æ–°|Beyond One-Hot Labels: Semantic Mixing for Model Calibration|è¶…è¶Šå•çƒ­æ ‡ç­¾ï¼šæ¨¡å‹æ ¡å‡†çš„è¯­ä¹‰æ··åˆ|Haoyang Luo, Linwei Tao, Minjing Dong, Chang Xu|<http://arxiv.org/pdf/2504.13548v2>|[ä»£ç ](https://github.com/E-Galois/CSM); æå‡ºäº†ä¸€ç§åŸºäºè¯­ä¹‰æ··åˆçš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹æ ¡å‡†çš„å‡†ç¡®æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Aggregated Structural Representation with Large Language Models for Human-Centric Layout Generation|åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„äººä¸­å¿ƒå¸ƒå±€ç”Ÿæˆä¸­çš„èšåˆç»“æ„è¡¨ç¤º|Jiongchao Jin, Shengchu Zhao, Dajun Chen, Wei Jiang, Yong Li|<http://arxiv.org/pdf/2505.19554v1>|æå‡ºASRæ¨¡å—ï¼Œç»“åˆå›¾ç½‘ç»œå’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå®ç°ç»“æ„ä¿¡æ¯ä¿ç•™å’Œå¸ƒå±€ç”Ÿæˆèƒ½åŠ›æå‡ã€‚|
|ğŸ†• å‘å¸ƒ|A Contrastive Learning Foundation Model Based on Perfectly Aligned Sample Pairs for Remote Sensing Images|åŸºäºå®Œç¾å¯¹é½æ ·æœ¬å¯¹çš„é¥æ„Ÿå›¾åƒå¯¹æ¯”å­¦ä¹ åŸºç¡€æ¨¡å‹|Hengtong Shen, Haiyan Gu, Haitao Li, Yi Yang, Agen qiu|<http://arxiv.org/pdf/2505.19447v1>|æå‡ºäº†ä¸€ç§åŸºäºå®Œç¾å¯¹é½æ ·æœ¬å¯¹çš„å¯¹æ¯”å­¦ä¹ æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†é¥æ„Ÿå›¾åƒç‰¹å¾æå–æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|Mirror: Multimodal Cognitive Reframing Therapy for Rolling with Resistance|é•œåƒï¼šåº”å¯¹æŠµæŠ—çš„å¤šæ¨¡æ€è®¤çŸ¥é‡æ„ç–—æ³•|Subin Kim, Hoonrae Kim, Jihyun Lee, Yejin Jeon, Gary Geunbae Lee|<http://arxiv.org/pdf/2504.13211v2>|æå‡ºMirroræ•°æ®é›†ï¼Œç»“åˆéè¨€è¯­çº¿ç´¢ï¼Œæå‡AIå¿ƒç†æ²»ç–—å¸ˆåº”å¯¹å®¢æˆ·æŠµæŠ—çš„èƒ½åŠ›ã€‚|


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|From Data to Modeling: Fully Open-vocabulary Scene Graph Generation|ä»æ•°æ®åˆ°å»ºæ¨¡ï¼šå…¨å¼€æ”¾è¯æ±‡åœºæ™¯å›¾ç”Ÿæˆ|Zuyao Chen, Jinlin Wu, Zhen Lei, Chang Wen Chen|<http://arxiv.org/pdf/2505.20106v1>|æå‡ºOvSGTRï¼Œä¸€ç§åŸºäºTransformerçš„å¼€æ”¾è¯æ±‡åœºæ™¯å›¾ç”Ÿæˆæ¡†æ¶ï¼Œçªç ´ä¼ ç»Ÿæ¨¡å‹é™åˆ¶ï¼Œå®ç°æ›´å¹¿...|
|ğŸ“ æ›´æ–°|X-GRM: Large Gaussian Reconstruction Model for Sparse-view X-rays to Computed Tomography|X-GRMï¼šç”¨äºç¨€ç–è§†å›¾Xå°„çº¿åˆ°è®¡ç®—æœºæ–­å±‚æ‰«æçš„å¤§é«˜æ–¯é‡å»ºæ¨¡å‹|Yifan Liu, Wuyang Li, Weihao Yu, Chenxin Li, Alexandre Alahi, Max Meng, Yixuan Yuan|<http://arxiv.org/pdf/2505.15235v2>|[ä»£ç ](https://github.com/CUHK-AIM-Group/X-GRM.); æå‡ºX-GRMæ¨¡å‹ï¼Œé€šè¿‡å¤§è§„æ¨¡Transformeræ¶æ„å’Œçµæ´»çš„ä½“ç§¯è¡¨ç¤ºï¼Œé«˜æ•ˆé‡å»ºç¨€ç–Xå°„çº¿æŠ•å½±çš„3...|
|ğŸ†• å‘å¸ƒ|ViTaPEs: Visuotactile Position Encodings for Cross-Modal Alignment in Multimodal Transformers|ViTaPEsï¼šå¤šæ¨¡æ€Transformerä¸­è·¨æ¨¡æ€å¯¹é½çš„è§†è§‰è§¦è§‰ä½ç½®ç¼–ç |Fotios Lygerakis, Ozan Ã–zdenizci, Elmar RÃ¼ckert|<http://arxiv.org/pdf/2505.20032v1>|ViTaPEsé€šè¿‡å¼•å…¥å¤šå°ºåº¦ä½ç½®ç¼–ç ï¼Œå®ç°äº†è§†è§‰å’Œè§¦è§‰æ•°æ®çš„é²æ£’èåˆï¼Œæå‡äº†è·¨æ¨¡æ€æ„ŸçŸ¥èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|Structured Initialization for Vision Transformers|ç»“æ„åŒ–åˆå§‹åŒ–ç”¨äºè§†è§‰Transformer|Jianqiao Zheng, Xueqian Li, Hemanth Saratchandran, Simon Lucey|<http://arxiv.org/pdf/2505.19985v1>|æå‡ºäº†ä¸€ç§é€šè¿‡åˆå§‹åŒ–ç­–ç•¥å°†CNNçš„å½’çº³åç½®èå…¥ViTï¼Œæ˜¾è‘—æå‡å°æ•°æ®é›†ä¸ŠViTæ€§èƒ½çš„æ–¹æ³•ã€‚|
|ğŸ†• å‘å¸ƒ|Attention! You Vision Language Model Could Be Maliciously Manipulated|æ³¨æ„ï¼æ‚¨çš„è§†è§‰è¯­è¨€æ¨¡å‹å¯èƒ½è¢«æ¶æ„æ“çºµ|Xiaosen Wang, Shaokang Wang, Zhijin Ge, Yuyang Luo, Shudong Zhang|<http://arxiv.org/pdf/2505.19911v1>|æå‡ºVMAæ”»å‡»ï¼Œæ­ç¤ºè§†è§‰è¯­è¨€æ¨¡å‹æ˜“å—å›¾åƒå¯¹æŠ—æ”»å‡»ï¼ŒåŒæ—¶å®ç°ç‰ˆæƒä¿æŠ¤å’Œå¤šç§æ”»å‡»ã€‚|
|ğŸ†• å‘å¸ƒ|Dynamic-I2V: Exploring Image-to-Video Generaion Models via Multimodal LLM|åŠ¨æ€-I2Vï¼šé€šè¿‡å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹æ¢ç´¢å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆæ¨¡å‹|Peng Liu, Xiaoming Ren, Fengkai Liu, Qingsong Xie, Quanlong Zheng, Yanhao Zhang, Haonan Lu, Yujiu Yang|<http://arxiv.org/pdf/2505.19901v1>|Dynamic-I2Vé€šè¿‡æ•´åˆå¤šæ¨¡æ€LLMï¼Œæ˜¾è‘—æå‡äº†è§†é¢‘ç”Ÿæˆä¸­çš„åŠ¨æ€èŒƒå›´å’Œå¯æ§æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|The Missing Point in Vision Transformers for Universal Image Segmentation|è§†è§‰Transformeråœ¨é€šç”¨å›¾åƒåˆ†å‰²ä¸­çš„ç¼ºå¤±ç‚¹|Sajjad Shahabodini, Mobina Mansoori, Farnoush Bayatmakou, Jamshid Abouei, Konstantinos N. Plataniotis, Arash Mohammadi|<http://arxiv.org/pdf/2505.19795v1>|[ä»£ç ](https://github.com/sajjad-sh33/ViT-P); æå‡ºViT-Pï¼Œä¸€ç§ä¸¤é˜¶æ®µåˆ†å‰²æ¡†æ¶ï¼Œé€šè¿‡è§£è€¦æ©ç ç”Ÿæˆä¸åˆ†ç±»ï¼Œå®ç°å›¾åƒåˆ†å‰²æ€§èƒ½æå‡ã€‚|
|ğŸ“ æ›´æ–°|Explanatory Instructions: Towards Unified Vision Tasks Understanding and Zero-shot Generalization|è§£é‡Šæ€§æŒ‡ä»¤ï¼šè¿ˆå‘ç»Ÿä¸€è§†è§‰ä»»åŠ¡ç†è§£å’Œé›¶æ ·æœ¬æ³›åŒ–|Yang Shen, Xiu-Shen Wei, Yifan Sun, Yuxin Song, Tao Yuan, Jian Jin, Heyang Xu, Yazhou Yao .etc.|<http://arxiv.org/pdf/2412.18525v3>|é€šè¿‡å¼•å…¥è§£é‡Šæ€§æŒ‡ä»¤ï¼Œè¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œä½¿è®¡ç®—æœºè§†è§‰æ¨¡å‹èƒ½å¤Ÿå®ç°è·¨ä»»åŠ¡ç†è§£å’Œé›¶æ ·æœ¬æ³›åŒ–ã€‚|
|ğŸ†• å‘å¸ƒ|TESSER: Transfer-Enhancing Adversarial Attacks from Vision Transformers via Spectral and Semantic Regularization|TESSERï¼šé€šè¿‡é¢‘è°±å’Œè¯­ä¹‰æ­£åˆ™åŒ–çš„è§†è§‰Transformerè¿ç§»å¢å¼ºå¯¹æŠ—æ”»å‡»|Amira Guesmi, Bassem Ouni, Muhammad Shafique|<http://arxiv.org/pdf/2505.19613v1>|TESSERé€šè¿‡ç‰¹å¾æ•æ„Ÿæ¢¯åº¦ç¼©æ”¾å’Œå…‰è°±å¹³æ»‘æ­£åˆ™åŒ–ï¼Œæ˜¾è‘—æå‡äº†è§†è§‰Transformerå¯¹æŠ—æ”»å‡»çš„è¿ç§»...|


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|EmoNet-Face: An Expert-Annotated Benchmark for Synthetic Emotion Recognition|EmoNet-Faceï¼šåˆæˆæƒ…ç»ªè¯†åˆ«çš„ä¸“å®¶æ ‡æ³¨åŸºå‡†|Christoph Schuhmann, Robert Kaczmarczyk, Gollam Rabby, Maurice Kraus, Felix Friedrich, Huu Nguyen, Krishna Kalyan, Kourosh Nadi .etc.|<http://arxiv.org/pdf/2505.20033v1>|æ„å»ºäº†EmoNet FaceåŸºå‡†ï¼Œæä¾›æ›´ç»†ç²’åº¦çš„æƒ…ç»ªåˆ†ç±»å’Œé«˜è´¨é‡æ•°æ®é›†ï¼Œä»¥ä¿ƒè¿›åˆæˆæƒ…ç»ªè¯†åˆ«ç ”ç©¶ã€‚|
|ğŸ†• å‘å¸ƒ|StyleAR: Customizing Multimodal Autoregressive Model for Style-Aligned Text-to-Image Generation|é£æ ¼ARï¼šå®šåˆ¶å¤šæ¨¡æ€è‡ªå›å½’æ¨¡å‹ä»¥å®ç°é£æ ¼å¯¹é½çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ|Yi Wu, Lingting Zhu, Shengju Qian, Lei Liu, Wandi Qiao, Lequan Yu, Bin Li|<http://arxiv.org/pdf/2505.19874v1>|æå‡ºStyleARï¼Œé€šè¿‡æ•°æ®å®šåˆ¶å’ŒARæ¨¡å‹ï¼Œå®ç°é£æ ¼å¯¹é½çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€‚|
|ğŸ†• å‘å¸ƒ|Advancements in Medical Image Classification through Fine-Tuning Natural Domain Foundation Models|é€šè¿‡å¾®è°ƒè‡ªç„¶é¢†åŸŸåŸºç¡€æ¨¡å‹åœ¨åŒ»å­¦å›¾åƒåˆ†ç±»ä¸­çš„è¿›å±•|Mobina Mansoori, Sajjad Shahabodini, Farnoush Bayatmakou, Jamshid Abouei, Konstantinos N. Plataniotis, Arash Mohammadi|<http://arxiv.org/pdf/2505.19779v1>|[ä»£ç ](https://github.com/sajjad-sh33/Medical-Transfer-Learning.); é€šè¿‡å¾®è°ƒè‡ªç„¶é¢†åŸŸåŸºç¡€æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†åŒ»å­¦å›¾åƒåˆ†ç±»çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚|
|ğŸ†• å‘å¸ƒ|Modeling Beyond MOS: Quality Assessment Models Must Integrate Context, Reasoning, and Multimodality|è¶…è¶ŠMOSï¼šè´¨é‡è¯„ä¼°æ¨¡å‹å¿…é¡»æ•´åˆä¸Šä¸‹æ–‡ã€æ¨ç†å’Œå¤šæ¨¡æ€|Mohamed Amine Kerkouri, Marouane Tliba, Aladine Chetouani, Nour Aburaed, Alessandro Bruno|<http://arxiv.org/pdf/2505.19696v1>|æå‡ºæ–°æ–¹æ³•ï¼Œå°†è´¨é‡è¯„ä¼°æ¨¡å‹ä»å•ä¸€MOSè¯„åˆ†æ‰©å±•è‡³èåˆæƒ…å¢ƒã€æ¨ç†å’Œå¤šæ¨¡æ€ä¿¡æ¯ã€‚|
|ğŸ“ æ›´æ–°|DiMeR: Disentangled Mesh Reconstruction Model|DiMeRï¼šè§£è€¦ç½‘æ ¼é‡å»ºæ¨¡å‹|Lutao Jiang, Jiantao Lin, Kanghao Chen, Wenhang Ge, Xin Yang, Yifan Jiang, Yuanhuiyi Lyu, Xu Zheng .etc.|<http://arxiv.org/pdf/2504.17670v2>|DiMeRé€šè¿‡åˆ†ç¦»å‡ ä½•å’Œçº¹ç†ï¼Œç»“åˆ3Dç›‘ç£ï¼Œæœ‰æ•ˆè§£å†³äº†ç¨€ç–è§†å›¾ç½‘æ ¼é‡å»ºä¸­çš„å‡ ä½•é”™è¯¯å’Œå†—ä½™æå–é—®é¢˜ã€‚|
|ğŸ“ æ›´æ–°|Unlocking Text Capabilities in Vision Models|è§£é”è§†è§‰æ¨¡å‹ä¸­çš„æ–‡æœ¬èƒ½åŠ›|Fawaz Sammani, Jonas Fischer, Nikos Deligiannis|<http://arxiv.org/pdf/2503.10981v2>|æå‡ºäº†ä¸€ç§å°†è§†è§‰æ¨¡å‹ä¸æ–‡æœ¬ç»“åˆçš„æ–¹æ³•ï¼Œå®ç°æ— æ ‡ç­¾ã€é›¶æ ·æœ¬çš„å¯è§£é‡Šæ€§åº”ç”¨ã€‚|
|ğŸ†• å‘å¸ƒ|Diagnosing and Mitigating Modality Interference in Multimodal Large Language Models|è¯Šæ–­å’Œç¼“è§£å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„æ¨¡æ€å¹²æ‰°|Rui Cai, Bangzheng Li, Xiaofei Wen, Muhao Chen, Zhe Zhao|<http://arxiv.org/pdf/2505.19616v1>|æå‡ºäº†ä¸€ç§é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸­æ¨¡æ€å¹²æ‰°é—®é¢˜çš„è¯Šæ–­å’Œç¼“è§£æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å•æ¨¡æ€å’Œå¤šæ¨¡æ€ä»»åŠ¡ä¸Šçš„...|
|ğŸ“ æ›´æ–°|Dimple: Discrete Diffusion Multimodal Large Language Model with Parallel Decoding|Dimpleï¼šå…·æœ‰å¹¶è¡Œè§£ç çš„ç¦»æ•£æ‰©æ•£å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹|Runpeng Yu, Xinyin Ma, Xinchao Wang|<http://arxiv.org/pdf/2505.16990v2>|[ä»£ç ](https://github.com/yu-rp/Dimple.); æå‡ºDimpleæ¨¡å‹ï¼Œç»“åˆè‡ªå›å½’å’Œæ‰©æ•£è®­ç»ƒï¼Œæå‡DMLLMæ€§èƒ½å¹¶ä¼˜åŒ–è§£ç æ•ˆç‡ã€‚|


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|RapidPoseTriangulation: Multi-view Multi-person Whole-body Human Pose Triangulation in a Millisecond|å¿«é€Ÿå§¿æ€ä¸‰è§’æµ‹é‡ï¼šæ¯«ç§’çº§çš„å¤šè§†è§’å¤šäººå…¨èº«äººä½“å§¿æ€ä¸‰è§’æµ‹é‡|Daniel Bermuth, Alexander Poeppel, Wolfgang Reif|<http://arxiv.org/pdf/2503.21692v2>|æå‡ºå¿«é€Ÿä¸‰è§’æµ‹é‡ç®—æ³•ï¼Œå®ç°æ¯«ç§’çº§å¤šè§†è§’å¤šäººå…¨èº«å§¿æ€ä¼°è®¡ã€‚|
|ğŸ†• å‘å¸ƒ|SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect|SuperADï¼šCVPR 2025 VAND 3.0 å·¥ä½œåŠæŒ‘æˆ˜èµ›ç¬¬1èµ›é“ï¼šé€‚åº”ä¸æ£€æµ‹çš„æ— ç›‘ç£å¼‚å¸¸åˆ†ç±»ä¸åˆ†å‰²æ–¹æ³•|Huaiyuan Zhang, Hang Chen, Yu Cheng, Shunyi Wu, Linghao Sun, Linao Han, Zeyu Shi, Lei Qi|<http://arxiv.org/pdf/2505.19750v1>|æå‡ºä¸€ç§æ— éœ€è®­ç»ƒçš„åŸºäºDINOv2æ¨¡å‹çš„å¼‚å¸¸æ£€æµ‹ä¸åˆ†å‰²æ–¹æ³•SuperADï¼Œæœ‰æ•ˆåº”å¯¹å¤æ‚å·¥ä¸šç¯å¢ƒä¸­çš„å¼‚...|
|ğŸ†• å‘å¸ƒ|Burst Image Super-Resolution via Multi-Cross Attention Encoding and Multi-Scan State-Space Decoding|çªå‘å›¾åƒè¶…åˆ†è¾¨ç‡é€šè¿‡å¤šäº¤å‰æ³¨æ„åŠ›ç¼–ç å’Œå¤šæ‰«æçŠ¶æ€ç©ºé—´è§£ç |Tengda Huang, Yu Zhang, Tianren Li, Yufu Qu, Fulin Liu, Zhenzhong Wei|<http://arxiv.org/pdf/2505.19668v1>|æå‡ºäº†ä¸€ç§åŸºäºå¤šäº¤å‰æ³¨æ„åŠ›ç¼–ç å’Œå¤šæ‰«æçŠ¶æ€ç©ºé—´è§£ç çš„çªå‘å›¾åƒè¶…åˆ†è¾¨ç‡æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†å›¾åƒè´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|Beyond Segmentation: Confidence-Aware and Debiased Estimation of Ratio-based Biomarkers|è¶…è¶Šåˆ†å‰²ï¼šåŸºäºç½®ä¿¡åº¦å’Œå»åä¼°è®¡çš„æ¯”ç‡ç”Ÿç‰©æ ‡å¿—ç‰©|Jiameng Li, Teodora Popordanoska, Sebastian G. Gruber, Frederik Maes, Matthew B. Blaschko|<http://arxiv.org/pdf/2505.19585v1>|æå‡ºäº†ä¸€ç§åŸºäºè½¯åˆ†å‰²çš„æ¯”ç”Ÿç‰©æ ‡å¿—ç‰©ä¼°è®¡æ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥ç½®ä¿¡åº¦æ„ŸçŸ¥å’Œåå·®æ ¡æ­£ï¼Œæé«˜äº†ä¸´åºŠåº”ç”¨çš„å¯é æ€§ã€‚|


### ç›®æ ‡æ£€æµ‹ä¸å®šä½ (Object Detection & Localization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Underwater Diffusion Attention Network with Contrastive Language-Image Joint Learning for Underwater Image Enhancement|æ°´ä¸‹æ‰©æ•£æ³¨æ„åŠ›ç½‘ç»œä¸å¯¹æ¯”è¯­è¨€-å›¾åƒè”åˆå­¦ä¹ ç”¨äºæ°´ä¸‹å›¾åƒå¢å¼º|Afrah Shaahid, Muzammil Behzad|<http://arxiv.org/pdf/2505.19895v1>|æå‡ºUDAN-CLIPæ¨¡å‹ï¼Œé€šè¿‡å¯¹æ¯”è¯­è¨€-å›¾åƒè”åˆå­¦ä¹ ï¼Œæœ‰æ•ˆå¢å¼ºæ°´ä¸‹å›¾åƒï¼Œæå‡è§†è§‰æ•ˆæœå’ŒçœŸå®æ€§ã€‚|
|ğŸ“ æ›´æ–°|HazyDet: Open-Source Benchmark for Drone-View Object Detection with Depth-Cues in Hazy Scenes|HazyDetï¼šé›¾å¤©åœºæ™¯ä¸­æ— äººæœºè§†è§’ç‰©ä½“æ£€æµ‹çš„æ·±åº¦çº¿ç´¢å¼€æºåŸºå‡†|Changfeng Feng, Zhenyuan Chen, Xiang Li, Chunping Wang, Jian Yang, Ming-Ming Cheng, Yimian Dai, Qiang Fu|<http://arxiv.org/pdf/2409.19833v2>|[ä»£ç ](https://github.com/GrokCV/HazyDet.); HazyDetæå‡ºé¦–ä¸ªé’ˆå¯¹æ— äººæœºåœ¨é›¾éœ¾åœºæ™¯ä¸‹ç›®æ ‡æ£€æµ‹çš„åŸºå‡†ï¼Œå¹¶è®¾è®¡DeCoDetæ¨¡å‹æå‡æ£€æµ‹ç²¾åº¦ã€‚|
|ğŸ†• å‘å¸ƒ|Locality-Aware Zero-Shot Human-Object Interaction Detection|å±€éƒ¨æ„ŸçŸ¥é›¶æ ·æœ¬äºº-ç‰©äº¤äº’æ£€æµ‹|Sanghyun Kim, Deunsol Jung, Minsu Cho|<http://arxiv.org/pdf/2505.19503v1>|æå‡ºLAINæ¡†æ¶ï¼Œé€šè¿‡å¢å¼ºCLIPçš„å±€éƒ¨å’Œäº¤äº’æ„è¯†ï¼Œæœ‰æ•ˆæå‡é›¶æ ·æœ¬äºº-ç‰©äº¤äº’æ£€æµ‹æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|Objective, Absolute and Hue-aware Metrics for Intrinsic Image Decomposition on Real-World Scenes: A Proof of Concept|å®¢è§‚ã€ç»å¯¹å’Œè‰²è°ƒæ„ŸçŸ¥çš„æŒ‡æ ‡ç”¨äºçœŸå®åœºæ™¯ä¸­çš„å†…åœ¨å›¾åƒåˆ†è§£ï¼šä¸€ä¸ªæ¦‚å¿µéªŒè¯|Shogo Sato, Masaru Tsuchida, Mariko Yamaguchi, Takuhiro Kaneko, Kazuhiko Murasaki, Taiga Yoshida, Ryuichi Tanida|<http://arxiv.org/pdf/2505.19500v1>|æå‡ºäº†ä¸€ç§åŸºäºè¶…å…‰è°±æˆåƒå’ŒLiDARçš„å®¢è§‚ã€ç»å¯¹å’Œè‰²è°ƒæ„ŸçŸ¥çš„å›¾åƒåˆ†è§£è¯„ä¼°æ–¹æ³•ã€‚|
|ğŸ†• å‘å¸ƒ|ADD-SLAM: Adaptive Dynamic Dense SLAM with Gaussian Splatting|è‡ªé€‚åº”åŠ¨æ€ç¨ å¯†SLAMï¼šåŸºäºé«˜æ–¯å–·æº…çš„è§£å†³æ–¹æ¡ˆ|Wenhua Wu, Chenpeng Su, Siting Zhu, Tianchen Deng, Zhe Liu, Hesheng Wang|<http://arxiv.org/pdf/2505.19420v1>|ADD-SLAMé€šè¿‡è‡ªé€‚åº”åŠ¨æ€è¯†åˆ«å’ŒåŠ¨æ€-é™æ€åˆ†ç¦»æ˜ å°„ç­–ç•¥ï¼Œæœ‰æ•ˆè§£å†³åŠ¨æ€SLAMä¸­çš„åœºæ™¯ä¸€è‡´æ€§æŒ‘æˆ˜ï¼Œ...|


### å›¾åƒåˆ†ç±»ä¸è¯†åˆ« (Image Classification & Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|What You Perceive Is What You Conceive: A Cognition-Inspired Framework for Open Vocabulary Image Segmentation|ä½ æ‰€æ„ŸçŸ¥å³ä½ æ‰€æ„æƒ³ï¼šä¸€ç§å—è®¤çŸ¥å¯å‘çš„å¼€æ”¾è¯æ±‡å›¾åƒåˆ†å‰²æ¡†æ¶|Jianghang Lin, Yue Hu, Jiangtao Shen, Yunhang Shen, Liujuan Cao, Shengchuan Zhang, Rongrong Ji|<http://arxiv.org/pdf/2505.19569v1>|æå‡ºè®¤çŸ¥å¯å‘å¼æ¡†æ¶ï¼Œæ¨¡æ‹Ÿäººç±»è§†è§‰è¯†åˆ«è¿‡ç¨‹ï¼Œå®ç°å¼€æ”¾è¯æ±‡å›¾åƒåˆ†å‰²ã€‚|


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|HunyuanVideo-Avatar: High-Fidelity Audio-Driven Human Animation for Multiple Characters|HunyuanVideo-Avatarï¼šå¤šè§’è‰²é«˜ä¿çœŸéŸ³é¢‘é©±åŠ¨çš„äººä½“åŠ¨ç”»|Yi Chen, Sen Liang, Zixiang Zhou, Ziyao Huang, Yifeng Ma, Junshu Tang, Qin Lin, Yuan Zhou .etc.|<http://arxiv.org/pdf/2505.20156v1>|HunyuanVideo-Avataré€šè¿‡åˆ›æ–°æ¨¡å—å®ç°å¤šè§’è‰²ã€é«˜ä¿çœŸã€æƒ…æ„ŸåŒæ­¥çš„äººåŠ¨ç”»ã€‚|
|ğŸ“ æ›´æ–°|Unsupervised Detection of Distribution Shift in Inverse Problems using Diffusion Models|æ— ç›‘ç£æ£€æµ‹é€†é—®é¢˜ä¸­çš„åˆ†å¸ƒåç§»ï¼šåŸºäºæ‰©æ•£æ¨¡å‹|Shirin Shoushtari, Edward P. Chandler, Yuanhao Wang, M. Salman Asif, Ulugbek S. Kamilov|<http://arxiv.org/pdf/2505.11482v3>|æå‡ºäº†ä¸€ç§æ— éœ€ç›‘ç£çš„åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ï¼Œç”¨äºæ£€æµ‹å’Œé‡åŒ–å›¾åƒé€†é—®é¢˜ä¸­çš„åˆ†å¸ƒåç§»ã€‚|
|ğŸ†• å‘å¸ƒ|Understanding Generalization in Diffusion Models via Probability Flow Distance|é€šè¿‡æ¦‚ç‡æµè·ç¦»ç†è§£æ‰©æ•£æ¨¡å‹ä¸­çš„æ³›åŒ–|Huijie Zhang, Zijian Huang, Siyi Chen, Jinfan Zhou, Zekai Zhang, Peng Wang, Qing Qu|<http://arxiv.org/pdf/2505.20123v1>|å¼•å…¥æ¦‚ç‡æµè·ç¦»ï¼Œè¯„ä¼°æ‰©æ•£æ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼Œæ­ç¤ºæ³›åŒ–è¡Œä¸ºã€‚|
|ğŸ†• å‘å¸ƒ|Multimodal LLM-Guided Semantic Correction in Text-to-Image Diffusion|å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹å¼•å¯¼çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£ä¸­çš„è¯­ä¹‰æ ¡æ­£|Zheqi Lv, Junhao Chen, Qi Tian, Keting Yin, Shengyu Zhang, Fei Wu|<http://arxiv.org/pdf/2505.20053v1>|æå‡ºMLLMè¯­ä¹‰æ ¡æ­£ï¼Œå®æ—¶åˆ†æä¸­é—´ç”Ÿæˆå›¾åƒï¼Œæå‡æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆè´¨é‡ã€‚|
|ğŸ“ æ›´æ–°|Efficient Training-Free High-Resolution Synthesis with Energy Rectification in Diffusion Models|é«˜æ•ˆçš„æ— è®­ç»ƒé«˜åˆ†è¾¨ç‡åˆæˆï¼šæ‰©æ•£æ¨¡å‹ä¸­çš„èƒ½é‡æ ¡æ­£|Zhen Yang, Guibao Shen, Minyang Li, Liang Hou, Mushui Liu, Luozhou Wang, Xin Tao, Pengfei Wan .etc.|<http://arxiv.org/pdf/2503.02537v3>|æå‡ºRectifiedHRï¼Œé€šè¿‡å™ªå£°åˆ·æ–°ç­–ç•¥å’Œèƒ½é‡æ ¡æ­£ï¼Œå®ç°é«˜æ•ˆçš„æ— ç›‘ç£é«˜åˆ†è¾¨ç‡å›¾åƒåˆæˆã€‚|
|ğŸ“ æ›´æ–°|Attentive Eraser: Unleashing Diffusion Model's Object Removal Potential via Self-Attention Redirection Guidance|æ³¨æ„æ“¦é™¤å™¨ï¼šé€šè¿‡è‡ªæ³¨æ„åŠ›é‡å®šå‘å¼•å¯¼é‡Šæ”¾æ‰©æ•£æ¨¡å‹çš„å¯¹è±¡å»é™¤æ½œåŠ›|Wenhao Sun, Benlei Cui, Xue-Mei Dong, Jingqun Tang, Yi Liu|<http://arxiv.org/pdf/2412.12974v6>|[ä»£ç ](https://github.com/Anonym0u3/AttentiveEraser.); æå‡ºäº†ä¸€ç§åŸºäºè‡ªæ³¨æ„åŠ›é‡å®šå‘çš„æ‰©æ•£æ¨¡å‹ï¼Œæœ‰æ•ˆè§£å†³å›¾åƒå»å™ªä¸­çš„éšæœºä¼ªå½±å’Œå‰æ™¯å†…å®¹ç¼ºå¤±é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|ICDM: Interference Cancellation Diffusion Models for Wireless Semantic Communications|æ— çº¿è¯­ä¹‰é€šä¿¡çš„å¹²æ‰°æ¶ˆé™¤æ‰©æ•£æ¨¡å‹|Tong Wu, Zhiyong Chen, Dazhi He, Feng Yang, Meixia Tao, Xiaodong Xu, Wenjun Zhang, Ping Zhang|<http://arxiv.org/pdf/2505.19983v1>|æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„å¹²æ‰°æ¶ˆé™¤æ–¹æ³•ï¼Œæœ‰æ•ˆé™ä½äº†æ— çº¿è¯­ä¹‰é€šä¿¡ä¸­çš„ä¿¡å·å¹²æ‰°ã€‚|
|ğŸ†• å‘å¸ƒ|Multimodal Reasoning Agent for Zero-Shot Composed Image Retrieval|å¤šæ¨¡æ€æ¨ç†ä»£ç†ç”¨äºé›¶æ ·æœ¬ç»„åˆå›¾åƒæ£€ç´¢|Rong-Cheng Tu, Wenhao Sun, Hanzhe You, Yingjie Wang, Jiaxing Huang, Li Shen, Dacheng Tao|<http://arxiv.org/pdf/2505.19952v1>|æå‡ºäº†ä¸€ç§æ— éœ€æ–‡æœ¬ä¸­ä»‹çš„é›¶æ ·æœ¬å›¾åƒæ£€ç´¢æ–¹æ³•ï¼Œé€šè¿‡å¤šæ¨¡æ€æ¨ç†ç›´æ¥å…³è”æŸ¥è¯¢å’Œç›®æ ‡å›¾åƒã€‚|
|ğŸ“ æ›´æ–°|Inverse Problem Sampling in Latent Space Using Sequential Monte Carlo|é€†é—®é¢˜é‡‡æ ·åœ¨æ½œåœ¨ç©ºé—´ä¸­çš„é¡ºåºè’™ç‰¹å¡æ´›æ–¹æ³•|Idan Achituve, Hai Victor Habi, Amir Rosenfeld, Arnon Netzer, Idit Diamant, Ethan Fetaya|<http://arxiv.org/pdf/2502.05908v2>|æå‡ºäº†ä¸€ç§åŸºäºLD-SMCçš„é€†é—®é¢˜é‡‡æ ·æ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³å›¾åƒå»å™ªå’Œä¿®å¤éš¾é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|ErpGS: Equirectangular Image Rendering enhanced with 3D Gaussian Regularization|ErpGSï¼šåŸºäº3Dé«˜æ–¯æ­£åˆ™åŒ–çš„ç­‰è§’å›¾åƒæ¸²æŸ“å¢å¼º|Shintaro Ito, Natsuki Takama, Koichi Ito, Hwann-Tzong Chen, Takafumi Aoki|<http://arxiv.org/pdf/2505.19883v1>|æå‡ºErpGSï¼Œé€šè¿‡3Dé«˜æ–¯æ­£åˆ™åŒ–æå‡ç­‰è§’å›¾åƒæ¸²æŸ“ç²¾åº¦ï¼Œè§£å†³360åº¦ç›¸æœºæŠ•å½±æ¨¡å‹å¯¼è‡´çš„ç•¸å˜é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|A Regularization-Guided Equivariant Approach for Image Restoration|åŸºäºæ­£åˆ™åŒ–çš„ç­‰å˜å›¾åƒæ¢å¤æ–¹æ³•|Yulu Bai, Jiahong Fu, Qi Xie, Deyu Meng|<http://arxiv.org/pdf/2505.19799v1>|æå‡ºäº†ä¸€ç§è‡ªé€‚åº”æ—‹è½¬ç­‰å˜æ­£åˆ™åŒ–ç­–ç•¥ï¼Œæ˜¾è‘—æå‡äº†å›¾åƒä¿®å¤ä»»åŠ¡çš„å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|HAODiff: Human-Aware One-Step Diffusion via Dual-Prompt Guidance|HAODiffï¼šåŸºäºåŒæç¤ºå¼•å¯¼çš„äººæ„ŸçŸ¥ä¸€æ­¥æ‰©æ•£|Jue Gong, Tingyu Yang, Jingkai Wang, Zheng Chen, Xing Liu, Hong Gu, Yulun Zhang, Xiaokang Yang|<http://arxiv.org/pdf/2505.19742v1>|[ä»£ç ](https://github.com/gobunu/HAODiff.); HAODiffé€šè¿‡åŒé‡æç¤ºå¼•å¯¼ï¼Œå®ç°äººæ„ŸçŸ¥çš„ä¸€æ­¥æ‰©æ•£ï¼Œæœ‰æ•ˆæå‡å›¾åƒä¿®å¤é²æ£’æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|SAIL: Self-supervised Albedo Estimation from Real Images with a Latent Diffusion Model|SAILï¼šåŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„ä»çœŸå®å›¾åƒä¸­è¿›è¡Œè‡ªç›‘ç£åç…§ç‡ä¼°è®¡|Hala Djeghim, Nathan Piasco, Luis RoldÃ£o, Moussab Bennehar, Dzmitry Tsishkou, CÃ©line Loscos, DÃ©sirÃ© SidibÃ©|<http://arxiv.org/pdf/2505.19751v1>|SAILé€šè¿‡æ½œæ‰©æ•£æ¨¡å‹å’Œè‡ªç›‘ç£å­¦ä¹ ï¼Œå®ç°äº†ä»çœŸå®å›¾åƒä¸­ç¨³å®šä¼°è®¡åç…§ç‡ï¼Œæœ‰æ•ˆè§£å†³äº†å…‰ç…§å˜åŒ–ä¸‹çš„åç…§ç‡ä¸€...|
|ğŸ†• å‘å¸ƒ|Cross-Sequence Semi-Supervised Learning for Multi-Parametric MRI-Based Visual Pathway Delineation|è·¨åºåˆ—åŠç›‘ç£å­¦ä¹ åœ¨å¤šå‚æ•°MRIè§†è§‰é€šè·¯å‹¾å‹’ä¸­çš„åº”ç”¨|Alou Diakite, Cheng Li, Lei Xie, Yuanjing Feng, Ruoyou Wu, Jianzhong He, Hairong Zheng, Shanshan Wang|<http://arxiv.org/pdf/2505.19733v1>|æå‡ºäº†ä¸€ç§åŸºäºåŠç›‘ç£å­¦ä¹ çš„å¤šå‚æ•°MRIè§†è§‰é€šè·¯åˆ†å‰²æ¡†æ¶ï¼Œæœ‰æ•ˆå¤„ç†è·¨åºåˆ—å…³ç³»å¹¶ç¼“è§£æ•°æ®æ ‡æ³¨éš¾é¢˜ã€‚|
|ğŸ“ æ›´æ–°|Expanding Zero-Shot Object Counting with Rich Prompts|åŸºäºä¸°å¯Œæç¤ºçš„é›¶æ ·æœ¬ç›®æ ‡è®¡æ•°æ‰©å±•|Huilin Zhu, Senyao Li, Jingling Yuan, Zhengwei Yang, Yu Guo, Wenxuan Liu, Xian Zhong, Shengfeng He|<http://arxiv.org/pdf/2505.15398v2>|RichCounté€šè¿‡ä¸°å¯Œæ–‡æœ¬ç‰¹å¾å’Œå¼ºåŒ–å›¾åƒå…³è”ï¼Œå®ç°é›¶æ ·æœ¬è®¡æ•°ä¸­æœªè§ç±»åˆ«çš„é«˜æ•ˆæ³›åŒ–ã€‚|
|ğŸ†• å‘å¸ƒ|Regularized Personalization of Text-to-Image Diffusion Models without Distributional Drift|æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æ­£åˆ™åŒ–ä¸ªæ€§åŒ–ï¼Œé¿å…åˆ†å¸ƒæ¼‚ç§»|Gihoon Kim, Hyungjin Park, Taesup Kim|<http://arxiv.org/pdf/2505.19519v1>|æå‡ºäº†ä¸€ç§åŸºäºLipschitzçº¦æŸçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸ªæ€§åŒ–æ–¹æ³•ï¼Œæœ‰æ•ˆæ§åˆ¶åˆ†å¸ƒæ¼‚ç§»å¹¶æå‡ç”Ÿæˆè´¨é‡ã€‚|
|ğŸ“ æ›´æ–°|VSA: Faster Video Diffusion with Trainable Sparse Attention|VSAï¼šå¯è®­ç»ƒç¨€ç–æ³¨æ„åŠ›åŠ é€Ÿè§†é¢‘æ‰©æ•£|Peiyuan Zhang, Haofeng Huang, Yongqi Chen, Will Lin, Zhengzhong Liu, Ion Stoica, Eric Xing, Hao Zhang|<http://arxiv.org/pdf/2505.13389v3>|[ä»£ç ](https://github.com/hao-ai-lab/FastVideo.); æå‡ºVSAï¼Œä¸€ç§å¯è®­ç»ƒçš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ˜¾è‘—æå‡è§†é¢‘æ‰©æ•£æ¨¡å‹çš„è®­ç»ƒé€Ÿåº¦å’Œæ•ˆç‡ã€‚|
|ğŸ“ æ›´æ–°|RDEIC: Accelerating Diffusion-Based Extreme Image Compression with Relay Residual Diffusion|RDEICï¼šåŸºäºæ‰©æ•£çš„æç«¯å›¾åƒå‹ç¼©çš„åŠ é€Ÿæ–¹æ³•ï¼šä¸­ç»§æ®‹å·®æ‰©æ•£|Zhiyuan Li, Yanhui Zhou, Hao Wei, Chenyang Ge, Ajmal Mian|<http://arxiv.org/pdf/2410.02640v3>|[ä»£ç ](https://github.com/huai-chang/RDEIC.); æå‡ºRDEICï¼Œé€šè¿‡å‹ç¼©ç‰¹å¾åˆå§‹åŒ–å’Œæ®‹å·®æ‰©æ•£åŠ é€Ÿæ‰©æ•£å›¾åƒå‹ç¼©ï¼Œæ˜¾è‘—æå‡å‹ç¼©æ•ˆç‡å’Œå›¾åƒè´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|Diversity-Driven Generative Dataset Distillation Based on Diffusion Model with Self-Adaptive Memory|åŸºäºè‡ªé€‚åº”æ€§è®°å¿†çš„æ‰©æ•£æ¨¡å‹é©±åŠ¨çš„å¤šæ ·æ€§ç”Ÿæˆæ•°æ®é›†è’¸é¦|Mingzhuo Li, Guang Li, Jiafeng Mao, Takahiro Ogawa, Miki Haseyama|<http://arxiv.org/pdf/2505.19469v1>|æå‡ºä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹å’Œè‡ªé€‚åº”è®°å¿†çš„å¤šæ ·åŒ–æ•°æ®é›†è’¸é¦æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡ä¸‹æ¸¸éªŒè¯å‡†ç¡®ç‡ã€‚|
|ğŸ“ æ›´æ–°|Stay-Positive: A Case for Ignoring Real Image Features in Fake Image Detection|ä¿æŒç§¯æï¼šåœ¨ä¼ªé€ å›¾åƒæ£€æµ‹ä¸­å¿½ç•¥çœŸå®å›¾åƒç‰¹å¾çš„è®ºç‚¹|Anirudh Sundara Rajan, Yong Jae Lee|<http://arxiv.org/pdf/2502.07778v2>|æå‡ºStay Positiveç®—æ³•ï¼Œä¸“æ³¨äºæ£€æµ‹ç”Ÿæˆæ¨¡å‹å¼•å…¥çš„ä¼ªé€ å›¾åƒç‰¹å¾ï¼Œæé«˜æ£€æµ‹å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚|
|ğŸ“ æ›´æ–°|Cancer-Net PCa-Seg: Benchmarking Deep Learning Models for Prostate Cancer Segmentation Using Synthetic Correlated Diffusion Imaging|ç™Œç—‡-ç½‘ç»œPCa-Segï¼šä½¿ç”¨åˆæˆç›¸å…³æ‰©æ•£æˆåƒå¯¹å‰åˆ—è…ºç™Œåˆ†å‰²æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•|Jarett Dewbury, Chi-en Amy Tai, Alexander Wong|<http://arxiv.org/pdf/2501.09185v2>|è¯¥è®ºæ–‡é€šè¿‡åˆæˆç›¸å…³æ‰©æ•£æˆåƒï¼Œè¯„ä¼°äº†æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å‰åˆ—è…ºç™Œåˆ†å‰²ä¸­çš„åº”ç”¨ï¼Œå‘ç°SegResNetå’ŒAtt...|
|ğŸ†• å‘å¸ƒ|Advancing Limited-Angle CT Reconstruction Through Diffusion-Based Sinogram Completion|ogram Completion|Jiaqi Guo, Santiago Lopez-Tapia, Aggelos K. Katsaggelos|<http://arxiv.org/pdf/2505.19385v1>|æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹å’Œä¼ªé€†çŸ©é˜µçš„æœ‰é™è§’CTé‡å»ºæ–°æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†é‡å»ºè´¨é‡å’Œæ•ˆç‡ã€‚|


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Agentic 3D Scene Generation with Spatially Contextualized VLMs|å…·æœ‰ç©ºé—´ä¸Šä¸‹æ–‡ä¿¡æ¯çš„VLMsè¿›è¡Œä»£ç†å¼3Dåœºæ™¯ç”Ÿæˆ|Xinhang Liu, Yu-Wing Tai, Chi-Keung Tang|<http://arxiv.org/pdf/2505.20129v1>|å¼•å…¥ç©ºé—´ä¸Šä¸‹æ–‡ï¼Œä½¿VLMç”Ÿæˆã€ç†è§£å’Œç¼–è¾‘å¤æ‚3Dåœºæ™¯ï¼Œæå‡ç©ºé—´æ™ºèƒ½ç³»ç»Ÿæ½œåŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|Refining Few-Step Text-to-Multiview Diffusion via Reinforcement Learning|é€šè¿‡å¼ºåŒ–å­¦ä¹ ç²¾ç‚¼å°‘é‡æ­¥éª¤çš„æ–‡æœ¬åˆ°å¤šè§†å›¾æ‰©æ•£|Ziyi Zhang, Li Shen, Deheng Ye, Yong Luo, Huangxuan Zhao, Lefei Zhang|<http://arxiv.org/pdf/2505.20107v1>|æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„T2MVæ‰©æ•£æ¨¡å‹å¾®è°ƒæ¡†æ¶ï¼Œä¼˜åŒ–å›¾åƒè´¨é‡å’Œè§†å›¾ä¸€è‡´æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|MEBench: A Novel Benchmark for Understanding Mutual Exclusivity Bias in Vision-Language Models|MEBenchï¼šç†è§£è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­äº’æ–¥åå·®çš„æ–°åŸºå‡†|Anh Thai, Stefan Stojanov, Zixuan Huang, Bikram Boote, James M. Rehg|<http://arxiv.org/pdf/2505.20122v1>|æ„å»ºäº†MEBenchåŸºå‡†ï¼Œè¯„ä¼°è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„äº’æ–¥æ€§åå·®ï¼Œå¹¶å¼•å…¥ç©ºé—´æ¨ç†ä»¥æå‡è¯„ä¼°çš„æŒ‘æˆ˜æ€§å’Œç°å®æ€§ã€‚|
|ğŸ“ æ›´æ–°|NFIG: Autoregressive Image Generation with Next-Frequency Prediction|NFIGï¼šåŸºäºä¸‹ä¸€é¢‘ç‡é¢„æµ‹çš„è‡ªå›å½’å›¾åƒç”Ÿæˆ|Zhihao Huang, Xi Qiu, Yukuo Ma, Yifu Zhou, Junjie Chen, Hongyuan Zhang, Chi Zhang, Xuelong Li|<http://arxiv.org/pdf/2503.07076v2>|NFIGé€šè¿‡é¢‘ç‡å¼•å¯¼çš„å¤šä¸ªé˜¶æ®µåˆ†è§£å›¾åƒç”Ÿæˆè¿‡ç¨‹ï¼Œæœ‰æ•ˆæ•æ‰é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼Œé™ä½è®¡ç®—æˆæœ¬ï¼Œå®ç°é«˜æ•ˆå›¾åƒç”Ÿ...|
|ğŸ†• å‘å¸ƒ|PAMD: Plausibility-Aware Motion Diffusion Model for Long Dance Generation|PAMDï¼šç”¨äºé•¿èˆè¹ˆç”Ÿæˆçš„åŸºäºåˆç†æ€§æ„ŸçŸ¥çš„è¿åŠ¨æ‰©æ•£æ¨¡å‹|Hongsong Wang, Yin Zhu, Qiuxia Lai, Yang Zhang, Guo-Sen Xie, Xin Geng|<http://arxiv.org/pdf/2505.20056v1>|[ä»£ç ](https://mucunzhuzhu.github.io/PAMD-page); æå‡ºPAMDæ¨¡å‹ï¼Œé€šè¿‡å¼•å…¥ç‰©ç†åˆç†æ€§çº¦æŸå’Œè¿åŠ¨å¼•å¯¼ï¼Œæ˜¾è‘—æå‡é•¿èˆè¹ˆç”Ÿæˆåºåˆ—çš„éŸ³ä¹åŒæ­¥æ€§å’Œç‰©ç†çœŸå®æ€§ã€‚|
|ğŸ“ æ›´æ–°|Domain-Agnostic Stroke Lesion Segmentation Using Physics-Constrained Synthetic Data|åŸºäºç‰©ç†çº¦æŸåˆæˆæ•°æ®çš„åŸŸæ— å…³è„‘å’ä¸­ç—…ç¶åˆ†å‰²|Liam Chalcroft, Jenny Crinion, Cathy J. Price, John Ashburner|<http://arxiv.org/pdf/2412.03318v2>|[ä»£ç ](https://github.com/liamchalcroft/qsynth); æå‡ºäº†ä¸€ç§åˆ©ç”¨ç‰©ç†çº¦æŸç”ŸæˆåˆæˆMRIå›¾åƒçš„æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†è„‘å’ä¸­ç—…å˜åˆ†å‰²çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚|
|ğŸ“ æ›´æ–°|OmniSVG: A Unified Scalable Vector Graphics Generation Model|å…¨æ¯SVGï¼šä¸€ç§ç»Ÿä¸€çš„å¯ç¼©æ”¾çŸ¢é‡å›¾å½¢ç”Ÿæˆæ¨¡å‹|Yiying Yang, Wei Cheng, Sijin Chen, Xianfang Zeng, Fukun Yin, Jiaxu Zhang, Liao Wang, Gang Yu .etc.|<http://arxiv.org/pdf/2504.06263v2>|æå‡ºOmniSVGæ¨¡å‹ï¼Œé€šè¿‡é¢„è®­ç»ƒè§†è§‰è¯­è¨€æ¨¡å‹å®ç°é«˜æ•ˆä¸”é«˜è´¨é‡çš„SVGç”Ÿæˆã€‚|
|ğŸ“ æ›´æ–°|What Makes a Scene ? Scene Graph-based Evaluation and Feedback for Controllable Generation|åœºæ™¯æ„æˆè¦ç´ ï¼šåŸºäºåœºæ™¯å›¾çš„å¯æ§ç”Ÿæˆè¯„ä¼°ä¸åé¦ˆ|Zuyao Chen, Jinlin Wu, Zhen Lei, Chang Wen Chen|<http://arxiv.org/pdf/2411.15435v2>|æ„å»ºScene-BenchåŸºå‡†å’ŒSGScoreè¯„ä¼°æŒ‡æ ‡ï¼Œæå‡åœºæ™¯å›¾ç”Ÿæˆå›¾åƒçš„äº‹å®ä¸€è‡´æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Harnessing the Power of Training-Free Techniques in Text-to-2D Generation for Text-to-3D Generation via Score Distillation Sampling|åˆ©ç”¨æ— ç›‘ç£è®­ç»ƒæŠ€æœ¯åœ¨æ–‡æœ¬åˆ°2Dç”Ÿæˆä¸­çš„åŠ›é‡ï¼Œé€šè¿‡åˆ†æ•°è’¸é¦é‡‡æ ·å®ç°æ–‡æœ¬åˆ°3Dç”Ÿæˆ|Junhong Lee, Seungwook Kim, Minsu Cho|<http://arxiv.org/pdf/2505.19868v1>|é€šè¿‡ç»“åˆæ— ç›‘ç£æŠ€æœ¯å’ŒåŠ¨æ€ç¼©æ”¾ç­–ç•¥ï¼Œæœ¬æ–‡æ˜¾è‘—æå‡äº†æ–‡æœ¬åˆ°3Dç”Ÿæˆä¸­çš„çº¹ç†ç»†èŠ‚å’Œè¡¨é¢å¹³æ»‘åº¦ã€‚|
|ğŸ“ æ›´æ–°|Diff-Def: Diffusion-Generated Deformation Fields for Conditional Atlases|Diff-Defï¼šæ¡ä»¶å›¾è°±çš„æ‰©æ•£ç”Ÿæˆå½¢å˜åœº|Sophie Starck, Vasiliki Sideri-Lampretsa, Bernhard Kainz, Martin J. Menten, Tamara T. Mueller, Daniel Rueckert|<http://arxiv.org/pdf/2403.16776v2>|æå‡ºäº†ä¸€ç§åˆ©ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆå˜å½¢åœºçš„æ–¹æ³•ï¼Œä»¥ç”Ÿæˆé’ˆå¯¹ç‰¹å®šå­ç¾¤ä½“çš„æ¡ä»¶å›¾è°±ï¼Œæ˜¾è‘—æå‡äº†å›¾è°±çš„è§£å‰–å‡†ç¡®...|
|ğŸ†• å‘å¸ƒ|ReDDiT: Rehashing Noise for Discrete Visual Generation|ReDDiTï¼šä¸ºç¦»æ•£è§†è§‰ç”Ÿæˆé‡å“ˆå¸Œå™ªå£°|Tianren Ma, Xiaosong Zhang, Boyu Yang, Junlan Feng, Qixiang Ye|<http://arxiv.org/pdf/2505.19656v1>|æå‡ºReDDiTæ¡†æ¶ï¼Œé€šè¿‡æ”¹è¿›å™ªå£°è®¾è®¡å’Œé‡‡æ ·ç­–ç•¥ï¼Œæ˜¾è‘—æå‡ç¦»æ•£æ‰©æ•£æ¨¡å‹ç”Ÿæˆè´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|Grounding Language with Vision: A Conditional Mutual Information Calibrated Decoding Strategy for Reducing Hallucinations in LVLMs|åŸºäºè§†è§‰çš„è¯­è¨€å®šä½ï¼šç”¨äºå‡å°‘LVLMsä¸­å¹»è§‰çš„æ¡ä»¶äº’ä¿¡æ¯æ ¡å‡†è§£ç ç­–ç•¥|Hao Fang, Changle Zhou, Jiawei Kong, Kuofeng Gao, Bin Chen, Tao Liang, Guojun Ma, Shu-Tao Xia|<http://arxiv.org/pdf/2505.19678v1>|æå‡ºC-PMIè§£ç ç­–ç•¥ï¼Œæœ‰æ•ˆé™ä½LVLMsç”Ÿæˆæ–‡æœ¬çš„å¹»è§‰ç°è±¡ã€‚|
|ğŸ†• å‘å¸ƒ|Guard Me If You Know Me: Protecting Specific Face-Identity from Deepfakes|å®ˆæŠ¤æˆ‘çš„èº«ä»½ï¼šä¿æŠ¤ç‰¹å®šäººè„¸å…å—æ·±åº¦ä¼ªé€ æ”»å‡»|Kaiqing Lin, Zhiyuan Yan, Ke-Yue Zhang, Li Hao, Yue Zhou, Yuzhen Lin, Weixiang Li, Taiping Yao .etc.|<http://arxiv.org/pdf/2505.19582v1>|æå‡ºVIPGuardæ¡†æ¶ï¼Œç»“åˆå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹å’Œä¸ªæ€§åŒ–å®šåˆ¶ï¼Œæœ‰æ•ˆè¯†åˆ«å¹¶è§£é‡Šåäººæ·±ä¼ªè§†é¢‘ã€‚|
|ğŸ†• å‘å¸ƒ|VTBench: Comprehensive Benchmark Suite Towards Real-World Virtual Try-on Models|VTBenchï¼šé¢å‘ç°å®ä¸–ç•Œè™šæ‹Ÿè¯•ç©¿æ¨¡å‹çš„å…¨é¢åŸºå‡†å¥—ä»¶|Hu Xiaobin, Liang Yujie, Luo Donghao, Peng Xu, Zhang Jiangning, Zhu Junwei, Wang Chengjie, Fu Yanwei|<http://arxiv.org/pdf/2505.19571v1>|VTBenchæå‡ºäº†ä¸€å¥—å…¨é¢åŸºå‡†ï¼Œé€šè¿‡å¤šç»´è¯„ä¼°å’Œäººç±»æ ‡æ³¨ï¼Œæ¨åŠ¨è™šæ‹Ÿè¯•ç©¿æ¨¡å‹å‘çœŸå®åœºæ™¯å‘å±•ã€‚|
|ğŸ†• å‘å¸ƒ|TDVE-Assessor: Benchmarking and Evaluating the Quality of Text-Driven Video Editing with LMMs|TDVE-Assessorï¼šåŸºäºLMMsçš„æ–‡æœ¬é©±åŠ¨è§†é¢‘ç¼–è¾‘è´¨é‡åŸºå‡†ä¸è¯„ä¼°|Juntong Wang, Jiarui Wang, Huiyu Duan, Guangtao Zhai, Xiongkuo Min|<http://arxiv.org/pdf/2505.19535v1>|æ„å»ºå¤§è§„æ¨¡æ•°æ®é›†TDVE-DBï¼Œæå‡ºTDVE-Assessoræ¨¡å‹ï¼Œæå‡æ–‡æœ¬é©±åŠ¨è§†é¢‘ç¼–è¾‘è´¨é‡è¯„ä¼°ã€‚|
|ğŸ“ æ›´æ–°|Fast Video Generation with Sliding Tile Attention|å¿«é€Ÿæ»‘åŠ¨æ‹¼å›¾æ³¨æ„åŠ›è§†é¢‘ç”Ÿæˆ|Peiyuan Zhang, Yongqi Chen, Runlong Su, Hangliang Ding, Ion Stoica, Zhengzhong Liu, Hao Zhang|<http://arxiv.org/pdf/2502.04507v2>|[ä»£ç ](https://github.com/hao-ai-lab/FastVideo.); æå‡ºæ»‘åŠ¨ç“·ç –æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¤§å¹…æå‡è§†é¢‘ç”Ÿæˆæ•ˆç‡ï¼Œé™ä½è®¡ç®—æˆæœ¬ã€‚|
|ğŸ†• å‘å¸ƒ|Toward Patient-specific Partial Point Cloud to Surface Completion for Pre- to Intra-operative Registration in Image-guided Liver Interventions|é¢å‘å›¾åƒå¼•å¯¼è‚è„å¹²é¢„æœ¯å‰è‡³æœ¯ä¸­æ³¨å†Œçš„ä¸ªæ€§åŒ–éƒ¨åˆ†ç‚¹äº‘åˆ°è¡¨é¢è¡¥å…¨|Nakul Poudel, Zixin Yang, Kelly Merrell, Richard Simon, Cristian A. Linte|<http://arxiv.org/pdf/2505.19518v1>|æå‡ºäº†ä¸€ç§åŸºäºVN-OccNetçš„ä¸ªæ€§åŒ–ç‚¹äº‘è¡¥å…¨æ–¹æ³•ï¼Œä»¥æ”¹å–„æœ¯ä¸­å›¾åƒå¼•å¯¼è‚è„å¹²é¢„çš„æœ¯å‰åˆ°æœ¯ä¸­æ³¨å†Œã€‚|
|ğŸ†• å‘å¸ƒ|Enhancing Visual Reliance in Text Generation: A Bayesian Perspective on Mitigating Hallucination in Large Vision-Language Models|å¢å¼ºæ–‡æœ¬ç”Ÿæˆä¸­çš„è§†è§‰ä¾èµ–ï¼šå¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹ç¼“è§£å¹»è§‰çš„è´å¶æ–¯è§†è§’|Nanxing Hu, Xiaoyue Duan, Jinchao Zhang, Guoliang Kang|<http://arxiv.org/pdf/2505.19498v1>|ä»è´å¶æ–¯è§†è§’å‡ºå‘ï¼Œé€šè¿‡è¯„ä¼°å’Œå»é™¤å†—ä½™è§†è§‰ä¿¡æ¯ã€ä¿®æ­£å…ˆéªŒä¿¡æ¯å’Œåœæ­¢æ— ä¿¡æ¯è§†è§‰ä¾èµ–çš„æ–‡æœ¬ç”Ÿæˆï¼Œæœ‰æ•ˆç¼“è§£äº†...|
|ğŸ“ æ›´æ–°|CGI: Identifying Conditional Generative Models with Example Images|CGIï¼šé€šè¿‡ç¤ºä¾‹å›¾åƒè¯†åˆ«æ¡ä»¶ç”Ÿæˆæ¨¡å‹|Zhi Zhou, Hao-Zhe Tan, Peng-Xiao Song, Lan-Zhe Guo|<http://arxiv.org/pdf/2501.13991v2>|æå‡ºCGIæ–¹æ³•ï¼Œé€šè¿‡ç”¨æˆ·ç¤ºä¾‹å›¾åƒè¯†åˆ«æœ€åˆé€‚çš„ç”Ÿæˆæ¨¡å‹ï¼Œæé«˜æ¨¡å‹æœç´¢æ•ˆç‡ã€‚|
|ğŸ†• å‘å¸ƒ|LlamaSeg: Image Segmentation via Autoregressive Mask Generation|LlamaSegï¼šé€šè¿‡è‡ªå›å½’æ©ç ç”Ÿæˆè¿›è¡Œå›¾åƒåˆ†å‰²|Jiru Deng, Tengjin Weng, Tianyu Yang, Wenhan Luo, Zhiheng Li, Wenhao Jiang|<http://arxiv.org/pdf/2505.19422v1>|æå‡ºLlamaSegï¼Œé€šè¿‡è‡ªå›å½’æ©ç ç”Ÿæˆå®ç°å›¾åƒåˆ†å‰²ï¼Œæå‡åˆ†å‰²ç²¾åº¦ã€‚|
|ğŸ“ æ›´æ–°|HPPP: Halpern-type Preconditioned Proximal Point Algorithms and Applications to Image Restoration|HPPPï¼šHalpernå‹é¢„æ¡ä»¶è¿‘ç«¯ç‚¹ç®—æ³•åŠå…¶åœ¨å›¾åƒæ¢å¤ä¸­çš„åº”ç”¨|Shuchang Zhang, Hui Zhang, Hongxia Wang|<http://arxiv.org/pdf/2407.13120v4>|æå‡ºHPPPç®—æ³•ï¼Œç»“åˆHalpernè¿­ä»£åŠ é€Ÿå›¾åƒä¿®å¤ï¼Œè§£å†³PPPæ–¹æ³•æ”¶æ•›æ…¢é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|MMIG-Bench: Towards Comprehensive and Explainable Evaluation of Multi-Modal Image Generation Models|MMIG-Benchï¼šè¿ˆå‘å…¨é¢ä¸”å¯è§£é‡Šçš„å¤šæ¨¡æ€å›¾åƒç”Ÿæˆæ¨¡å‹è¯„ä¼°|Hang Hua, Ziyun Zeng, Yizhi Song, Yunlong Tang, Liu He, Daniel Aliaga, Wei Xiong, Jiebo Luo|<http://arxiv.org/pdf/2505.19415v1>|æå‡ºMMIG-Benchï¼Œç»Ÿä¸€è¯„ä¼°å¤šæ¨¡æ€å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œè§£å†³ç°æœ‰è¯„ä¼°å·¥å…·çš„ä¸è¶³ã€‚|
|ğŸ†• å‘å¸ƒ|Force Prompting: Video Generation Models Can Learn and Generalize Physics-based Control Signals|å¼ºåˆ¶æç¤ºï¼šè§†é¢‘ç”Ÿæˆæ¨¡å‹å¯ä»¥å­¦ä¹ å’Œæ³›åŒ–åŸºäºç‰©ç†çš„æ§åˆ¶ä¿¡å·|Nate Gillman, Charles Herrmann, Michael Freeman, Daksh Aggarwal, Evan Luo, Deqing Sun, Chen Sun|<http://arxiv.org/pdf/2505.19386v1>|æå‡ºäº†ä¸€ç§åˆ©ç”¨ç‰©ç†åŠ›ä½œä¸ºæ§åˆ¶ä¿¡å·çš„è§†é¢‘ç”Ÿæˆæ–¹æ³•ï¼Œä½¿æ¨¡å‹èƒ½é€šè¿‡è§†è§‰å’Œè¿åŠ¨å…ˆéªŒå­¦ä¹ ç‰©ç†æ§åˆ¶ä¿¡å·ï¼Œå®ç°é€¼çœŸ...|
|ğŸ†• å‘å¸ƒ|Absolute Coordinates Make Motion Generation Easy|ç»å¯¹åæ ‡ä½¿è¿åŠ¨ç”Ÿæˆå˜å¾—ç®€å•|Zichong Meng, Zeyu Han, Xiaogang Peng, Yiming Xie, Huaizu Jiang|<http://arxiv.org/pdf/2505.19377v1>|æå‡ºç»å¯¹åæ ‡ç®€åŒ–äº†è¿åŠ¨ç”Ÿæˆï¼Œæ˜¾è‘—æå‡äº†è¿åŠ¨ç²¾åº¦å’Œä¸‹æ¸¸ä»»åŠ¡åº”ç”¨ã€‚|
|ğŸ“ æ›´æ–°|Understanding Generative AI Capabilities in Everyday Image Editing Tasks|ç†è§£åœ¨æ—¥å¸¸å›¾åƒç¼–è¾‘ä»»åŠ¡ä¸­ç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„èƒ½åŠ›|Mohammad Reza Taesiri, Brandon Collins, Logan Bolton, Viet Dac Lai, Franck Dernoncourt, Trung Bui, Anh Totti Nguyen|<http://arxiv.org/pdf/2505.16181v2>|åˆ†æRedditç¤¾åŒºå›¾åƒç¼–è¾‘è¯·æ±‚ï¼Œæ­ç¤ºAIç¼–è¾‘å±€é™ä¸æ”¹è¿›æ–¹å‘ã€‚|


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations|åŒè¨€ï¼š3Dè¯´è¯å¤´åƒå¯¹è¯ä¸­çš„åŒå‘è¨€äººäº¤äº’|Ziqiao Peng, Yanbo Fan, Haoyu Wu, Xuan Wang, Hongyan Liu, Jun He, Zhaoxin Fan|<http://arxiv.org/pdf/2505.18096v2>|[ä»£ç ](https://ziqiaopeng.github.io/dualtalk.); DualTalké€šè¿‡æ¨¡æ‹Ÿè¯´è¯è€…å’Œå¬ä¼—çš„åŠ¨æ€è¡Œä¸ºï¼Œæ˜¾è‘—æå‡äº†3Då¯¹è¯å¤´åƒçš„è‡ªç„¶æ€§å’Œè¡¨ç°åŠ›ã€‚|
|ğŸ“ æ›´æ–°|VideoJAM: Joint Appearance-Motion Representations for Enhanced Motion Generation in Video Models|è§†é¢‘JAMï¼šè§†é¢‘æ¨¡å‹ä¸­å¢å¼ºè¿åŠ¨ç”Ÿæˆçš„è”åˆå¤–è§‚-è¿åŠ¨è¡¨ç¤º|Hila Chefer, Uriel Singer, Amit Zohar, Yuval Kirstain, Adam Polyak, Yaniv Taigman, Lior Wolf, Shelly Sheynin|<http://arxiv.org/pdf/2502.02492v2>|[ä»£ç ](https://hila-chefer.github.io/videojam-paper.github.io); VideoJAMé€šè¿‡å¼•å…¥è”åˆå¤–è§‚-è¿åŠ¨è¡¨ç¤ºï¼Œæœ‰æ•ˆæå‡äº†è§†é¢‘ç”Ÿæˆæ¨¡å‹ä¸­è¿åŠ¨çš„ä¸€è‡´æ€§å’Œè§†è§‰è´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|UltraVSR: Achieving Ultra-Realistic Video Super-Resolution with Efficient One-Step Diffusion Space|è¶…é€¼çœŸè§†é¢‘è¶…åˆ†è¾¨ç‡ï¼šé«˜æ•ˆä¸€æ­¥æ‰©æ•£ç©ºé—´çš„å®ç°|Yong Liu, Jinshan Pan, Yinchuan Li, Qingji Dong, Chao Zhu, Yu Guo, Fei Wang|<http://arxiv.org/pdf/2505.19958v1>|æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹å’Œæ—¶ç©ºä¿¡æ¯èåˆçš„è¶…åˆ†è¾¨ç‡æ–¹æ³•ï¼Œå®ç°å•æ­¥é‡å»ºå¹¶æ˜¾è‘—æå‡è§†é¢‘æ¸…æ™°åº¦ã€‚|
|ğŸ†• å‘å¸ƒ|A Unified Solution to Video Fusion: From Multi-Frame Learning to Benchmarking|è§†é¢‘èåˆçš„ç»Ÿä¸€è§£å†³æ–¹æ¡ˆï¼šä»å¤šå¸§å­¦ä¹ åˆ°åŸºå‡†æµ‹è¯•|Zixiang Zhao, Haowen Bai, Bingxin Ke, Yukun Cui, Lilun Deng, Yulun Zhang, Kai Zhang, Konrad Schindler|<http://arxiv.org/pdf/2505.19858v1>|æå‡ºUniVFæ¡†æ¶ï¼Œç»“åˆå¤šå¸§å­¦ä¹ å’Œå…‰æµç‰¹å¾èåˆï¼Œå®ç°è§†é¢‘èåˆçš„æ—¶ç©ºä¸€è‡´æ€§ï¼Œå¹¶æ„å»ºäº†é¦–ä¸ªè§†é¢‘èåˆåŸºå‡†V...|
|ğŸ“ æ›´æ–°|Faster and Stronger: When ANN-SNN Conversion Meets Parallel Spiking Calculation|æ›´å¿«æ›´å¼ºï¼šå½“äººå·¥ç¥ç»ç½‘ç»œ-è„‰å†²ç¥ç»ç½‘ç»œè½¬æ¢é‡åˆ°å¹¶è¡Œè„‰å†²è®¡ç®—|Zecheng Hao, Qichao Ma, Kang Chen, Yi Zhang, Zhaofei Yu, Tiejun Huang|<http://arxiv.org/pdf/2412.13610v2>|[ä»£ç ](https://github.com/hzc1208/Parallel_Conversion.); æå‡ºäº†ä¸€ç§ç»“åˆå¹¶è¡Œè„‰å†²è®¡ç®—å’ŒANN-SNNè½¬æ¢çš„å¹¶è¡Œå­¦ä¹ æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†è„‰å†²ç¥ç»ç½‘ç»œçš„å­¦ä¹ æ•ˆç‡å’Œæ€§èƒ½...|
|ğŸ†• å‘å¸ƒ|ViewCraft3D: High-Fidelity and View-Consistent 3D Vector Graphics Synthesis|ViewCraft3Dï¼šé«˜ä¿çœŸå’Œè§†è§’ä¸€è‡´çš„ä¸‰ç»´çŸ¢é‡å›¾å½¢åˆæˆ|Chuang Wang, Haitao Zhou, Ling Luo, Qian Yu|<http://arxiv.org/pdf/2505.19492v1>|ViewCraft3Dé€šè¿‡åˆ©ç”¨3Då…ˆéªŒçŸ¥è¯†ï¼Œé«˜æ•ˆç”Ÿæˆä¿æŒè§†è§’ä¸€è‡´æ€§çš„é«˜ä¿çœŸ3DçŸ¢é‡å›¾å½¢ã€‚|
|ğŸ“ æ›´æ–°|Marmot: Multi-Agent Reasoning for Multi-Object Self-Correcting in Improving Image-Text Alignment|å¤šæ™ºèƒ½ä½“æ¨ç†åœ¨å¤šå¯¹è±¡è‡ªæ ¡æ­£ä¸­æå‡å›¾åƒ-æ–‡æœ¬å¯¹é½çš„Marmot|Jiayang Sun, Hongbo Wang, Jie Cao, Huaibo Huang, Ran He|<http://arxiv.org/pdf/2504.20054v2>|Marmoté€šè¿‡å¤šæ™ºèƒ½ä½“æ¨ç†å®ç°å¤šå¯¹è±¡è‡ªæˆ‘æ ¡æ­£ï¼Œæ˜¾è‘—æå‡å›¾åƒä¸æ–‡æœ¬å¯¹é½çš„å‡†ç¡®æ€§ã€‚|
|ğŸ“ æ›´æ–°|MoRE-Brain: Routed Mixture of Experts for Interpretable and Generalizable Cross-Subject fMRI Visual Decoding|MoRE-Brainï¼šç”¨äºå¯è§£é‡Šå’Œæ³›åŒ–è·¨å—è¯•è€…fMRIè§†è§‰è§£ç çš„è·¯å¾„æ··åˆä¸“å®¶|Yuxiang Wei, Yanteng Zhang, Xi Xiao, Tianyang Wang, Xiao Wang, Vince D. Calhoun|<http://arxiv.org/pdf/2505.15946v2>|[ä»£ç ](https://github.com/yuxiangwei0808/MoRE-Brain.); MoRE-Brainé€šè¿‡æ¨¡æ‹Ÿäººè„‘ç½‘ç»œï¼Œæå‡ºäº†ä¸€ç§å¯è§£é‡Šä¸”é€šç”¨çš„fMRIè§†è§‰è§£ç æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†é‡å»ºå›¾...|
|ğŸ†• å‘å¸ƒ|Structure Disruption: Subverting Malicious Diffusion-Based Inpainting via Self-Attention Query Perturbation|ç»“æ„ç ´åï¼šé€šè¿‡è‡ªæ³¨æ„åŠ›æŸ¥è¯¢æ‰°åŠ¨é¢ è¦†æ¶æ„æ‰©æ•£å¼ä¿®å¤|Yuhao He, Jinyu Tian, Haiwei Wu, Jianqing Li|<http://arxiv.org/pdf/2505.19425v1>|æå‡ºç»“æ„ç ´åæ”»å‡»ï¼Œé€šè¿‡è‡ªæ³¨æ„åŠ›æŸ¥è¯¢æ‰°åŠ¨ç ´åæ‰©æ•£æ¨¡å‹çš„ç»“æ„ç”Ÿæˆèƒ½åŠ›ï¼Œæœ‰æ•ˆé˜²æ­¢æ¶æ„å›¾åƒä¿®å¤ã€‚|


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks|æœç€å…·æœ‰è¡¨æ¼”æ”¯æŒé“¾çš„ä»è§†é¢‘åˆ°é’¢ç´éŸ³ä¹ç”Ÿæˆçš„åŸºå‡†ç ”ç©¶|Chang Liu, Haomin Zhang, Shiyu Xia, Zihao Chen, Chaofan Ding, Xin Yue, Huizhe Chen, Xinhan Di|<http://arxiv.org/pdf/2505.20038v1>|[ä»£ç ](https://github.com/acappemin/Video-to-Audio-and-Piano); æ„å»ºäº†é’ˆå¯¹è§†é¢‘åˆ°é’¢ç´éŸ³ä¹ç”Ÿæˆçš„CoPåŸºå‡†æ•°æ®é›†ï¼Œä»¥ä¿ƒè¿›é«˜è´¨é‡éŸ³ä¹ç”Ÿæˆç ”ç©¶ã€‚|
|ğŸ“ æ›´æ–°|TokBench: Evaluating Your Visual Tokenizer before Visual Generation|TokBenchï¼šåœ¨è§†è§‰ç”Ÿæˆä¹‹å‰è¯„ä¼°æ‚¨çš„è§†è§‰åˆ†è¯å™¨|Junfeng Wu, Dongliang Luo, Weizhi Zhao, Zhihao Xie, Yuanhao Wang, Junyi Li, Xudong Xie, Yuliang Liu .etc.|<http://arxiv.org/pdf/2505.18142v2>|æå‡ºTokBenchåŸºå‡†è¯„ä¼°è§†è§‰ç¼–ç å™¨ï¼Œæ­ç¤ºå…¶ä¿çœŸåº¦é™åˆ¶ï¼Œæå‡è§†è§‰ç”Ÿæˆè´¨é‡è¯„ä¼°ã€‚|
|ğŸ“ æ›´æ–°|One Image is Worth a Thousand Words: A Usability Preservable Text-Image Collaborative Erasing Framework|ä¸€å¼ å›¾èƒœåƒè¨€ï¼šä¸€ç§å¯ä¿ç•™å¯ç”¨æ€§çš„æ–‡æœ¬-å›¾åƒååŒæ“¦é™¤æ¡†æ¶|Feiran Li, Qianqian Xu, Shilong Bao, Zhiyong Yang, Xiaochun Cao, Qingming Huang|<http://arxiv.org/pdf/2505.11131v2>|[ä»£ç ](https://github.com/Ferry-Li/Co-Erasing.); æå‡ºäº†ä¸€ç§ç»“åˆè§†è§‰ç›‘ç£çš„æ–‡æœ¬-å›¾åƒååŒæ¦‚å¿µæ“¦é™¤æ¡†æ¶ï¼Œæœ‰æ•ˆæå‡æ“¦é™¤æ•ˆç‡å’Œå¯ç”¨æ€§ã€‚|
|ğŸ“ æ›´æ–°|On the Fairness, Diversity and Reliability of Text-to-Image Generative Models|å…³äºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„å…¬å¹³æ€§ã€å¤šæ ·æ€§å’Œå¯é æ€§|Jordan Vice, Naveed Akhtar, Leonid Sigal, Richard Hartley, Ajmal Mian|<http://arxiv.org/pdf/2411.13981v2>|[ä»£ç ](https://github.com/JJ-Vice/T2I_Fairness_Diversity_Reliability.); æå‡ºè¯„ä¼°æ¡†æ¶ï¼Œåˆ†ææ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„å¯é æ€§å’Œå…¬å¹³æ€§ï¼Œä»¥è¯†åˆ«ä¸ç¨³å®šçš„æˆ–åé¢‡çš„è¡Œä¸ºã€‚|
|ğŸ“ æ›´æ–°|Slot-MLLM: Object-Centric Visual Tokenization for Multimodal LLM|æ§½-MLLMï¼šå¤šæ¨¡æ€LLMçš„å¯¹è±¡ä¸­å¿ƒè§†è§‰æ ‡è®°åŒ–|Donghwan Chi, Hyomin Kim, Yoonjin Oh, Yongjin Kim, Donghoon Lee, Daejin Jo, Jongmin Kim, Junyeob Baek .etc.|<http://arxiv.org/pdf/2505.17726v2>|æå‡ºä¸€ç§ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„è§†è§‰æ ‡è®°å™¨ï¼Œæå‡å¤šæ¨¡æ€LLMå¯¹ç»†èŠ‚è§†è§‰å†…å®¹çš„ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|The Role of Video Generation in Enhancing Data-Limited Action Understanding|è§†é¢‘ç”Ÿæˆåœ¨æå‡æ•°æ®å—é™åŠ¨ä½œç†è§£ä¸­çš„ä½œç”¨|Wei Li, Dezhao Luo, Dongbao Yang, Zhenhang Li, Weiping Wang, Yu Zhou|<http://arxiv.org/pdf/2505.19495v1>|æå‡ºä¸€ç§åˆ©ç”¨æ–‡æœ¬ç”Ÿæˆè§†é¢‘æ•°æ®çš„æ–¹æ³•ï¼Œæœ‰æ•ˆç¼“è§£æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œæå‡åŠ¨ä½œç†è§£æ¨¡å‹æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|Erasing Concepts, Steering Generations: A Comprehensive Survey of Concept Suppression|æ“¦é™¤æ¦‚å¿µï¼Œå¼•å¯¼ç”Ÿæˆï¼šæ¦‚å¿µæŠ‘åˆ¶çš„å…¨é¢ç»¼è¿°|Yiwei Xie, Ping Liu, Zheng Zhang|<http://arxiv.org/pdf/2505.19398v1>|æå‡ºäº†ä¸€ç§æ¦‚å¿µæ“¦é™¤æ–¹æ³•ï¼Œä»T2Iæ¨¡å‹ä¸­å»é™¤ç‰¹å®šè¯­ä¹‰æ¦‚å¿µï¼Œä»¥ä¿ƒè¿›ç”ŸæˆAIçš„è´Ÿè´£ä»»å‘å±•ã€‚|


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|OB3D: A New Dataset for Benchmarking Omnidirectional 3D Reconstruction Using Blender|OB3Dï¼šç”¨äºåŸºå‡†æµ‹è¯•Blenderä¸­å…¨å‘3Dé‡å»ºçš„æ–°æ•°æ®é›†|Shintaro Ito, Natsuki Takama, Toshiki Watanabe, Koichi Ito, Hwann-Tzong Chen, Takafumi Aoki|<http://arxiv.org/pdf/2505.20126v1>|OB3Dæå‡ºæ–°æ•°æ®é›†ï¼Œè§£å†³å…¨å‘3Dé‡å»ºä¸­å‡ ä½•ç•¸å˜é—®é¢˜ï¼Œæ¨åŠ¨æŠ€æœ¯å‘å±•ã€‚|
|ğŸ†• å‘å¸ƒ|NEXT: Multi-Grained Mixture of Experts via Text-Modulation for Multi-Modal Object Re-ID|ä¸‹ä¸€ä»£ï¼šé€šè¿‡æ–‡æœ¬è°ƒåˆ¶å®ç°çš„å¤šæ¨¡æ€ç‰©ä½“é‡è¯†åˆ«çš„å¤šç²’åº¦ä¸“å®¶æ··åˆ|Shihao Li, Chenglong Li, Aihua Zheng, Andong Lu, Jin Tang, Jixin Ma|<http://arxiv.org/pdf/2505.20001v1>|æå‡ºä¸€ç§åŸºäºæ–‡æœ¬è°ƒæ§çš„å¤šæ¨¡æ€ç‰©ä½“é‡è¯†åˆ«æ¡†æ¶ï¼Œæœ‰æ•ˆæå‡è¯†åˆ«å‡†ç¡®ç‡ã€‚|
|ğŸ†• å‘å¸ƒ|GraphAU-Pain: Graph-based Action Unit Representation for Pain Intensity Estimation|åŸºäºå›¾çš„åŠ¨ä½œå•å…ƒè¡¨ç¤ºç”¨äºç–¼ç—›å¼ºåº¦ä¼°è®¡|Zhiyu Wang, Yang Liu, Hatice Gunes|<http://arxiv.org/pdf/2505.19802v1>|GraphAU-Painé€šè¿‡å›¾ç¥ç»ç½‘ç»œå»ºæ¨¡é¢éƒ¨åŠ¨ä½œå•å…ƒï¼Œå®ç°ç–¼ç—›å¼ºåº¦çš„é«˜æ•ˆå‡†ç¡®ä¼°è®¡ã€‚|
|ğŸ†• å‘å¸ƒ|GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis|GoLF-NRTï¼šèåˆå…¨å±€ä¸Šä¸‹æ–‡å’Œå±€éƒ¨å‡ ä½•çš„å°‘æ ·æœ¬è§†å›¾åˆæˆ|You Wang, Li Fang, Hao Zhu, Fei Hu, Long Ye, Zhan Ma|<http://arxiv.org/pdf/2505.19813v1>|[ä»£ç ](https://github.com/KLMAV-CUC/GoLF-NRT.); GoLF-NRTé€šè¿‡èåˆå…¨å±€åœºæ™¯ä¸Šä¸‹æ–‡å’Œå±€éƒ¨å‡ ä½•ç‰¹å¾ï¼Œæ˜¾è‘—æå‡äº†åŸºäºå°‘é‡è¾“å…¥è§†å›¾çš„ç¥ç»æ¸²æŸ“æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction|æ·±åº¦å¼•å¯¼çš„æŸé‡‡æ ·ç”¨äºé«˜æ•ˆä¸”å¯æ³›åŒ–çš„ç¥ç»è¾å°„åœºé‡å»º|Li Fang, Hao Zhu, Longlong Chen, Fei Hu, Long Ye, Zhan Ma|<http://arxiv.org/pdf/2505.19793v1>|[ä»£ç ](https://github.com/KLMAV-CUC/GDB-NeRF.); æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å¼•å¯¼çš„æŸé‡‡æ ·ç­–ç•¥ï¼Œæœ‰æ•ˆåŠ é€Ÿäº†ç¥ç»è¾å°„åœºçš„é«˜åˆ†è¾¨ç‡å›¾åƒé‡å»ºã€‚|
|ğŸ“ æ›´æ–°|Exploring Generalized Gait Recognition: Reducing Redundancy and Noise within Indoor and Outdoor Datasets|æ¢ç´¢å¹¿ä¹‰æ­¥æ€è¯†åˆ«ï¼šé™ä½å®¤å†…å’Œå®¤å¤–æ•°æ®é›†ä¸­çš„å†—ä½™å’Œå™ªå£°|Qian Zhou, Xianda Guo, Jilong Wang, Chuanfu Shen, Zhongyuan Wang, Hua Zou, Qin Zou, Chao Liang .etc.|<http://arxiv.org/pdf/2505.15176v3>|[ä»£ç ](https://github.com/li1er3/Generalized_Gait.); æå‡ºäº†ä¸€ç§ç»Ÿä¸€æ¡†æ¶ï¼Œé€šè¿‡è§£è€¦æŸå¤±å’Œç­›é€‰æ ·æœ¬ï¼Œæœ‰æ•ˆæå‡è·¨åŸŸæ­¥æ€è¯†åˆ«æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|NeuRadar: Neural Radiance Fields for Automotive Radar Point Clouds|ç¥ç»é›·è¾¾ï¼šç”¨äºæ±½è½¦é›·è¾¾ç‚¹äº‘çš„ç¥ç»è¾å°„åœº|Mahan Rafidashti, Ji Lan, Maryam Fatemi, Junsheng Fu, Lars Hammarstrand, Lennart Svensson|<http://arxiv.org/pdf/2504.00859v3>|æå‡ºNeuRadarï¼Œåˆ©ç”¨NeRFæŠ€æœ¯å®ç°é›·è¾¾ç‚¹äº‘ã€å›¾åƒå’Œæ¿€å…‰ç‚¹äº‘çš„è”åˆç”Ÿæˆï¼Œå¹¶æå‡é›·è¾¾è¡Œä¸ºå»ºæ¨¡çš„å‡†...|
|ğŸ†• å‘å¸ƒ|K-Buffers: A Plug-in Method for Enhancing Neural Fields with Multiple Buffers|K-Buffersï¼šä¸€ç§ç”¨äºå¢å¼ºå¤šç¼“å†²åŒºç¥ç»åœºçš„æ’ä»¶æ–¹æ³•|Haofan Ren, Zunjie Zhu, Xiang Chen, Ming Lu, Rongfeng Lu, Chenggang Yan|<http://arxiv.org/pdf/2505.19564v1>|K-Buffersé€šè¿‡å¤šç¼“å†²åŒºèåˆæŠ€æœ¯ï¼Œæœ‰æ•ˆæå‡äº†ç¥ç»åœºæ¸²æŸ“æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|Ocular Authentication: Fusion of Gaze and Periocular Modalities|çœ¼åŠ¨è®¤è¯ï¼šæ³¨è§†ä¸çœ¼å‘¨æ¨¡æ€çš„èåˆ|Dillon Lohr, Michael J. Proulx, Mehedi Hasan Raju, Oleg V. Komogortsev|<http://arxiv.org/pdf/2505.17343v2>|æå‡ºèåˆæ³¨è§†å’Œçœ¼å‘¨å›¾åƒçš„å¤šæ¨¡æ€è®¤è¯ç³»ç»Ÿï¼Œæ˜¾è‘—æå‡æ— æ ‡å®šçœ¼åŠ¨è®¤è¯æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|SpikeStereoNet: A Brain-Inspired Framework for Stereo Depth Estimation from Spike Streams|SpikeStereoNetï¼šåŸºäºè„‰å†²æµè¿›è¡Œç«‹ä½“æ·±åº¦ä¼°è®¡çš„è„‘å¯å‘æ¡†æ¶|Zhuoheng Gao, Yihao Li, Jiyao Zhang, Rui Zhao, Tong Wu, Hao Tang, Zhaofei Yu, Hao Dong .etc.|<http://arxiv.org/pdf/2505.19487v1>|æå‡ºäº†ä¸€ç§ä»åŸå§‹è„‰å†²æµç›´æ¥ä¼°è®¡ç«‹ä½“æ·±åº¦çš„è„‘å¯å‘æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†åœ¨å¿«é€Ÿå˜åŒ–åœºæ™¯ä¸­çš„æ·±åº¦ä¼°è®¡æ€§èƒ½ã€‚|


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Weather-Magician: Reconstruction and Rendering Framework for 4D Weather Synthesis In Real Time|å®æ—¶å››ç»´å¤©æ°”åˆæˆé‡å»ºä¸æ¸²æŸ“æ¡†æ¶ï¼šå¤©æ°”é­”æœ¯å¸ˆ|Chen Sang, Yeqiang Qian, Jiale Zhang, Chunxiang Wang, Ming Yang|<http://arxiv.org/pdf/2505.19919v1>|æå‡ºäº†ä¸€ç§å®æ—¶åˆæˆ4Då¤©æ°”æ•ˆæœçš„é‡å»ºä¸æ¸²æŸ“æ¡†æ¶ï¼Œæœ‰æ•ˆè§£å†³å¤æ‚åœºæ™¯æ¸²æŸ“éš¾é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|Sparse2DGS: Sparse-View Surface Reconstruction using 2D Gaussian Splatting with Dense Point Cloud|ç¨€ç–2Dé«˜æ–¯åˆ†å±‚ï¼šåŸºäºå¯†é›†ç‚¹äº‘çš„ç¨€ç–è§†å›¾è¡¨é¢é‡å»º|Natsuki Takama, Shintaro Ito, Koichi Ito, Hwann-Tzong Chen, Takafumi Aoki|<http://arxiv.org/pdf/2505.19854v1>|æå‡ºSparse2DGSï¼Œé€šè¿‡ç»“åˆDUSt3Rå’ŒCOLMAP MVSç”Ÿæˆå¯†é›†ç‚¹äº‘ï¼Œå®ç°ä»…ç”¨ä¸‰å¼ å›¾åƒçš„...|
|ğŸ†• å‘å¸ƒ|HF-VTON: High-Fidelity Virtual Try-On via Consistent Geometric and Semantic Alignment|é«˜ä¿çœŸè™šæ‹Ÿè¯•ç©¿ï¼šé€šè¿‡ä¸€è‡´å‡ ä½•å’Œè¯­ä¹‰å¯¹é½|Ming Meng, Qi Dong, Jiajie Li, Zhe Zhu, Xingyu Wang, Zhaoxin Fan, Wei Zhao, Wenjun Wu|<http://arxiv.org/pdf/2505.19638v1>|æå‡ºHF-VTONï¼Œé€šè¿‡å‡ ä½•å’Œè¯­ä¹‰å¯¹é½ï¼Œå®ç°é«˜ä¿çœŸè™šæ‹Ÿè¯•è¡£ï¼Œæå‡è§†è§‰å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚|


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|TUNA: Comprehensive Fine-grained Temporal Understanding Evaluation on Dense Dynamic Videos|TUNAï¼šå¯†é›†åŠ¨æ€è§†é¢‘ä¸­å…¨é¢ç»†ç²’åº¦æ—¶é—´ç†è§£è¯„ä¼°|Fanheng Kong, Jingyuan Zhang, Hongzhi Zhang, Shi Feng, Daling Wang, Linhao Yu, Xingguang Ji, Yu Tian .etc.|<http://arxiv.org/pdf/2505.20124v1>|[ä»£ç ](https://friedrichor.github.io/projects); æ„å»ºäº†TUNAåŸºå‡†ï¼Œå…¨é¢è¯„ä¼°å¯†é›†åŠ¨æ€è§†é¢‘çš„ç»†ç²’åº¦æ—¶é—´ç†è§£èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|AdaTP: Attention-Debiased Token Pruning for Video Large Language Models|AdaTPï¼šé’ˆå¯¹è§†é¢‘å¤§å‹è¯­è¨€æ¨¡å‹çš„æ³¨æ„åŠ›åå·®è¯å…ƒå‰ªæ|Fengyuan Sun, Leqi Shen, Hui Chen, Sicheng Zhao, Jungong Han, Guiguang Ding|<http://arxiv.org/pdf/2505.20100v1>|æå‡ºAdaTPæ–¹æ³•ï¼Œé€šè¿‡æ³¨æ„åŠ›å»åæŠ€æœ¯æœ‰æ•ˆé™ä½è§†é¢‘å¤§è¯­è¨€æ¨¡å‹è®¡ç®—å¼€é”€ï¼ŒåŒæ—¶ä¿æŒæ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|Vad-R1: Towards Video Anomaly Reasoning via Perception-to-Cognition Chain-of-Thought|Vad-R1ï¼šé€šè¿‡æ„ŸçŸ¥åˆ°è®¤çŸ¥æ€ç»´é“¾å®ç°è§†é¢‘å¼‚å¸¸æ¨ç†|Chao Huang, Benfeng Wang, Jie Wen, Chengliang Liu, Wei Wang, Li Shen, Xiaochun Cao|<http://arxiv.org/pdf/2505.19877v1>|[ä»£ç ](https://github.com/wbfwonderful/Vad-R1.); æå‡ºè§†é¢‘å¼‚å¸¸æ¨ç†æ–°ä»»åŠ¡ï¼Œé€šè¿‡æ„ŸçŸ¥åˆ°è®¤çŸ¥æ€ç»´é“¾å¼•å¯¼MLLMé€æ­¥æ¨ç†å¼‚å¸¸ã€‚|
|ğŸ†• å‘å¸ƒ|Two Causally Related Needles in a Video Haystack|ä¸¤ä¸ªå› æœç›¸å…³çš„é’ˆåœ¨è§†é¢‘ç¨»è‰å †ä¸­|Miaoyu Li, Qin Chao, Boyang Li|<http://arxiv.org/pdf/2505.19853v1>|æå‡ºCausal2NeedlesåŸºå‡†ï¼Œè¯„ä¼°VLMsåœ¨è§†é¢‘ä¿¡æ¯æå–å’Œå› æœå»ºæ¨¡æ–¹é¢çš„èƒ½åŠ›ã€‚|
|ğŸ“ æ›´æ–°|FastVID: Dynamic Density Pruning for Fast Video Large Language Models|å¿«é€ŸVIDï¼šåŠ¨æ€å¯†åº¦å‰ªæç”¨äºå¿«é€Ÿè§†é¢‘å¤§å‹è¯­è¨€æ¨¡å‹|Leqi Shen, Guoqiang Gong, Tao He, Yifeng Zhang, Pengzhang Liu, Sicheng Zhao, Guiguang Ding|<http://arxiv.org/pdf/2503.11187v2>|[ä»£ç ](https://github.com/LunarShen/FastVID.); FastVIDé€šè¿‡åŠ¨æ€å¯†åº¦å‰ªæï¼Œæœ‰æ•ˆå‡å°‘è§†é¢‘å¤§è¯­è¨€æ¨¡å‹è®¡ç®—é‡ï¼ŒåŒæ—¶ä¿æŒè§†é¢‘ç†è§£å’Œå‡†ç¡®æ€§ã€‚|
|ğŸ“ æ›´æ–°|SPKLIP: Aligning Spike Video Streams with Natural Language|SPKLIPï¼šå¯¹è‡ªç„¶è¯­è¨€ä¸å°–å³°è§†é¢‘æµè¿›è¡Œå¯¹é½|Yongchang Gao, Meiling Jin, Zhaofei Yu, Tiejun Huang, Guozhang Chen|<http://arxiv.org/pdf/2505.12656v2>|SPKLIPé€šè¿‡å¼•å…¥å±‚æ¬¡åŒ–ç‰¹å¾æå–å’Œå¯¹æ¯”å­¦ä¹ ï¼Œæœ‰æ•ˆè§£å†³äº†è„‰å†²è§†é¢‘ä¸è‡ªç„¶è¯­è¨€å¯¹é½é—®é¢˜ï¼Œæå‡äº†è„‰å†²è§†é¢‘è¯­...|


### åŠ¨ä½œè¯†åˆ«ä¸ç†è§£ (Action Recognition & Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|PHI: Bridging Domain Shift in Long-Term Action Quality Assessment via Progressive Hierarchical Instruction|PHIï¼šé€šè¿‡æ¸è¿›å¼åˆ†å±‚æŒ‡ä»¤å¼¥åˆé•¿æœŸåŠ¨ä½œè´¨é‡è¯„ä¼°ä¸­çš„é¢†åŸŸè¿ç§»|Kanglei Zhou, Hubert P. H. Shum, Frederick W. B. Li, Xingxing Zhang, Xiaohui Liang|<http://arxiv.org/pdf/2505.19972v1>|æå‡ºPHIæ–¹æ³•ï¼Œé€šè¿‡æ¸è¿›å¼åˆ†å±‚æŒ‡ä»¤è§£å†³é•¿æœŸåŠ¨ä½œè´¨é‡è¯„ä¼°ä¸­çš„é¢†åŸŸåç§»é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|CA3D: Convolutional-Attentional 3D Nets for Efficient Video Activity Recognition on the Edge|CA3Dï¼šç”¨äºè¾¹ç¼˜é«˜æ•ˆè§†é¢‘æ´»åŠ¨è¯†åˆ«çš„å·ç§¯-æ³¨æ„åŠ›3Dç½‘ç»œ|Gabriele Lagani, Fabrizio Falchi, Claudio Gennaro, Giuseppe Amato|<http://arxiv.org/pdf/2505.19928v1>|æå‡ºäº†ä¸€ç§ç»“åˆå·ç§¯å±‚å’Œçº¿æ€§å¤æ‚åº¦æ³¨æ„åŠ›æœºåˆ¶çš„è½»é‡çº§è§†é¢‘æ´»åŠ¨è¯†åˆ«æ¨¡å‹ï¼Œæœ‰æ•ˆé™ä½è®¡ç®—æˆæœ¬å¹¶æå‡è¯†åˆ«å‡†ç¡®ç‡...|


### è§†é¢‘ç›®æ ‡è·Ÿè¸ª (Video Object Tracking)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|HybridTrack: A Hybrid Approach for Robust Multi-Object Tracking|æ··åˆè·Ÿè¸ªï¼šä¸€ç§é²æ£’çš„å¤šç›®æ ‡è·Ÿè¸ªæ··åˆæ–¹æ³•|Leandro Di Bella, Yangxintong Lyu, Bruno Cornelis, Adrian Munteanu|<http://arxiv.org/pdf/2501.01275v2>|[ä»£ç ](https://github.com/leandro-svg/HybridTrack.); æå‡ºHybridTrackï¼Œä¸€ç§ç»“åˆæ•°æ®é©±åŠ¨å¡å°”æ›¼æ»¤æ³¢çš„æ··åˆæ–¹æ³•ï¼Œå®ç°é²æ£’çš„å¤šç›®æ ‡è·Ÿè¸ªã€‚|
|ğŸ“ æ›´æ–°|Compositional Physical Reasoning of Objects and Events from Videos|è§†é¢‘ä¸­çš„ç‰©ä½“å’Œäº‹ä»¶ç»„åˆç‰©ç†æ¨ç†|Zhenfang Chen, Shilong Dong, Kexin Yi, Yunzhu Li, Mingyu Ding, Antonio Torralba, Joshua B. Tenenbaum, Chuang Gan|<http://arxiv.org/pdf/2408.02687v2>|æå‡ºComPhyæ•°æ®é›†å’ŒPCRæ¡†æ¶ï¼Œä»è§†é¢‘æ¨æ–­ç‰©ä½“éšè—ç‰©ç†å±æ€§å¹¶é¢„æµ‹ç›¸åº”åŠ¨æ€ã€‚|


### æ—¶åºå»ºæ¨¡ä¸é¢„æµ‹ (Temporal Modeling & Prediction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|CSTrack: Enhancing RGB-X Tracking via Compact Spatiotemporal Features|CSTrackï¼šé€šè¿‡ç´§å‡‘æ—¶ç©ºç‰¹å¾å¢å¼ºRGB-Xè·Ÿè¸ª|X. Feng, D. Zhang, S. Hu, X. Li, M. Wu, J. Zhang, X. Chen, K. Huang|<http://arxiv.org/pdf/2505.19434v1>|[ä»£ç ](https://github.com/XiaokunFeng/CSTrack.); CSTracké€šè¿‡å»ºæ¨¡ç´§å‡‘æ—¶ç©ºç‰¹å¾ï¼Œæœ‰æ•ˆæ•´åˆRGBå’ŒXæ¨¡æ€æ•°æ®ï¼Œç®€åŒ–æ¨¡å‹ç»“æ„å¹¶æå‡RGB-Xè·Ÿè¸ªæ€§èƒ½...|


## è‡ªç›‘ç£ä¸è¡¨å¾å­¦ä¹  (Self-supervised & Representation Learning)


### è·¨æ¨¡æ€ä¸€è‡´æ€§å­¦ä¹  (Cross-modal Consistency Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Compile Scene Graphs with Reinforcement Learning|ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ç¼–è¯‘åœºæ™¯å›¾|Zuyao Chen, Jinlin Wu, Zhen Lei, Marc Pollefeys, Chang Wen Chen|<http://arxiv.org/pdf/2504.13617v4>|[ä»£ç ](https://github.com/gpt4vision/R1-SGG); æå‡ºR1-SGGï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ æå‡å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ç”Ÿæˆåœºæ™¯å›¾çš„èƒ½åŠ›ã€‚|


### å¯¹æ¯”å­¦ä¹ æ–¹æ³• (Contrastive Learning Methods)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Modality Curation: Building Universal Embeddings for Advanced Multimodal Information Retrieval|æ¨¡æ€ç²¾ç‚¼ï¼šæ„å»ºé«˜çº§å¤šæ¨¡æ€ä¿¡æ¯æ£€ç´¢çš„é€šç”¨åµŒå…¥|Fanheng Kong, Jingyuan Zhang, Yahui Liu, Hongzhi Zhang, Shi Feng, Xiaocui Yang, Daling Wang, Yu Tian .etc.|<http://arxiv.org/pdf/2505.19650v1>|[ä»£ç ](https://friedrichor.github.io/projects); æå‡ºUNITEæ¡†æ¶ï¼Œé€šè¿‡æ•°æ®ç®¡ç†å’Œæ¨¡æ€æ„ŸçŸ¥è®­ç»ƒè§£å†³å¤šæ¨¡æ€ä¿¡æ¯æ£€ç´¢çš„å¼‚æ„æ€§å’Œå¯¹é½éš¾é¢˜ã€‚|


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Data-Free Class-Incremental Gesture Recognition with Prototype-Guided Pseudo Feature Replay|æ— æ•°æ®ç±»å¢é‡æ‰‹åŠ¿è¯†åˆ«ï¼šåŸºäºåŸå‹å¼•å¯¼çš„ä¼ªç‰¹å¾é‡æ”¾|Hongsong Wang, Ao Sun, Jie Gui, Liang Wang|<http://arxiv.org/pdf/2505.20049v1>|[ä»£ç ](https://github.com/sunao-101/PGPFR-3); æå‡ºä¸€ç§æ•°æ®æ— å…³çš„ç±»å¢é‡æ‰‹åŠ¿è¯†åˆ«æ–¹æ³•ï¼Œé€šè¿‡åŸå‹å¼•å¯¼ä¼ªç‰¹å¾é‡æ”¾æ¡†æ¶æå‡è¯†åˆ«å‡†ç¡®ç‡ã€‚|
|ğŸ“ æ›´æ–°|A Survey on the Safety and Security Threats of Computer-Using Agents: JARVIS or Ultron?|è®¡ç®—æœºä½¿ç”¨ä»£ç†çš„å®‰å…¨ä¸å®‰å…¨å¨èƒç»¼è¿°ï¼šJARVISè¿˜æ˜¯ä¹Œé¾™ï¼Ÿ|Ada Chen, Yongjiang Wu, Junyuan Zhang, Jingyu Xiao, Shu Yang, Jen-tse Huang, Kun Wang, Wenxuan Wang .etc.|<http://arxiv.org/pdf/2505.10924v2>|ç³»ç»ŸåŒ–åˆ†æäº†è®¡ç®—æœºä½¿ç”¨ä»£ç†çš„å®‰å…¨å¨èƒï¼Œå¹¶æå‡ºäº†é˜²å¾¡ç­–ç•¥å’Œè¯„ä¼°æ–¹æ³•ã€‚|
|ğŸ“ æ›´æ–°|Semantic Correspondence: Unified Benchmarking and a Strong Baseline|è¯­ä¹‰å¯¹åº”ï¼šç»Ÿä¸€åŸºå‡†æµ‹è¯•å’Œå¼ºå¤§åŸºçº¿|Kaiyan Zhang, Xinghui Li, Jingyi Lu, Kai Han|<http://arxiv.org/pdf/2505.18060v2>|[ä»£ç ](https://github.com/Visual-AI/Semantic-Correspondence.); é¦–æ¬¡å…¨é¢ç»¼è¿°è¯­ä¹‰å¯¹åº”æ–¹æ³•ï¼Œæå‡ºç»Ÿä¸€åŸºå‡†å’Œé«˜æ•ˆåŸºçº¿ã€‚|
|ğŸ“ æ›´æ–°|PillarHist: A Quantization-aware Pillar Feature Encoder based on Height-aware Histogram|æŸ±çŠ¶å›¾æ„ŸçŸ¥çš„Pillarç‰¹å¾ç¼–ç å™¨ï¼šåŸºäºé«˜åº¦æ„ŸçŸ¥ç›´æ–¹å›¾|Sifan Zhou, Zhihang Yuan, Dawei Yang, Ziyu Zhao, Jian Qian, Xing Hu|<http://arxiv.org/pdf/2405.18734v4>|æå‡ºPillarHistï¼Œé€šè¿‡é«˜åº¦æ„ŸçŸ¥çš„æŸ±çŠ¶å›¾ç¼–ç ï¼Œæœ‰æ•ˆæå‡3Dç‰©ä½“æ£€æµ‹æ€§èƒ½å¹¶é™ä½é‡åŒ–å¤æ‚åº¦ã€‚|
|ğŸ†• å‘å¸ƒ|FlowCut: Rethinking Redundancy via Information Flow for Efficient Vision-Language Models|FlowCutï¼šé€šè¿‡ä¿¡æ¯æµé‡æ–°æ€è€ƒå†—ä½™ä»¥æé«˜è§†è§‰-è¯­è¨€æ¨¡å‹çš„æ•ˆç‡|Jintao Tong, Wenwei Jin, Pengda Qin, Anqi Li, Yixiong Zou, Yuhong Li, Yuhua Li, Ruixuan Li|<http://arxiv.org/pdf/2505.19536v1>|[ä»£ç ](https://github.com/TungChintao/FlowCut); FlowCuté€šè¿‡ä¿¡æ¯æµåˆ†æï¼Œæœ‰æ•ˆè¯†åˆ«å¹¶å‰ªæè§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„å†—ä½™è§†è§‰æ ‡è®°ï¼Œæ˜¾è‘—æå‡æ¨¡å‹æ•ˆç‡ã€‚|


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|A Survey of LLM-based Agents in Medicine: How far are we from Baymax?|åŒ»å­¦é¢†åŸŸåŸºäºLLMä»£ç†çš„ç»¼è¿°ï¼šæˆ‘ä»¬ç¦»Baymaxè¿˜æœ‰å¤šè¿œï¼Ÿ|Wenxuan Wang, Zizhan Ma, Zheng Wang, Chenghan Wu, Jiaming Ji, Wenting Chen, Xiang Li, Yixuan Yuan|<http://arxiv.org/pdf/2502.11211v2>|ç»¼è¿°äº†åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„åŒ»ç–—æ™ºèƒ½ä½“ï¼Œåˆ†æäº†å…¶æ¶æ„ã€åº”ç”¨å’ŒæŒ‘æˆ˜ï¼Œå±•æœ›äº†æœªæ¥ç ”ç©¶æ–¹å‘ã€‚|
|ğŸ†• å‘å¸ƒ|Optimizing edge AI models on HPC systems with the edge in the loop|åœ¨è¾¹ç¼˜å¾ªç¯ä¸­ä¼˜åŒ–é«˜æ€§èƒ½è®¡ç®—ç³»ç»Ÿä¸Šçš„è¾¹ç¼˜AIæ¨¡å‹|Marcel Aach, Cyril Blanc, Andreas Lintermann, Kurt De Grave|<http://arxiv.org/pdf/2505.19995v1>|æå‡ºäº†ä¸€ç§ç»“åˆè¾¹ç¼˜è®¾å¤‡å’ŒHPCç³»ç»Ÿè¿›è¡Œç¡¬ä»¶æ„ŸçŸ¥ç¥ç»æ¶æ„æœç´¢ï¼Œä»¥ä¼˜åŒ–è¾¹ç¼˜AIæ¨¡å‹çš„æ–¹æ³•ï¼Œæ˜¾è‘—æå‡æ¨¡å‹æ€§...|
|ğŸ†• å‘å¸ƒ|A Responsible Face Recognition Approach for Small and Mid-Scale Systems Through Personalized Neural Networks|è´Ÿè´£ä»»çš„å°å‹å’Œä¸­å‹ç³»ç»Ÿä¸ªæ€§åŒ–ç¥ç»ç½‘ç»œäººè„¸è¯†åˆ«æ–¹æ³•|Sebastian GroÃŸ, Stefan Heindorf, Philipp TerhÃ¶rst|<http://arxiv.org/pdf/2505.19920v1>|æå‡ºä¸ªæ€§åŒ–ç¥ç»ç½‘ç»œï¼Œä¸ºå°ä¸­è§„æ¨¡ç³»ç»Ÿæä¾›æ›´è´Ÿè´£ä»»çš„è¯†åˆ«æ–¹æ³•ï¼Œæå‡å…¬å¹³æ€§å’Œéšç§ä¿æŠ¤ã€‚|
|ğŸ“ æ›´æ–°|Distilling Textual Priors from LLM to Efficient Image Fusion|ä»å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æå–æ–‡æœ¬å…ˆéªŒä»¥å®ç°é«˜æ•ˆå›¾åƒèåˆ|Ran Zhang, Xuanhua He, Ke Cao, Liu Liu, Li Zhang, Man Zhou, Jie Zhang|<http://arxiv.org/pdf/2504.07029v3>|æå‡ºäº†ä¸€ç§ä»å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æå–æ–‡æœ¬å…ˆéªŒçš„å›¾åƒèåˆæ¡†æ¶ï¼Œæ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬å¹¶æå‡èåˆè´¨é‡ã€‚|
|ğŸ“ æ›´æ–°|Adaptive Rank, Reduced Forgetting: Knowledge Retention in Continual Learning Vision-Language Models with Dynamic Rank-Selective LoRA|è‡ªé€‚åº”æ’åï¼Œå‡å°‘é—å¿˜ï¼šåŠ¨æ€æ’åé€‰æ‹©LoRAåœ¨æŒç»­å­¦ä¹ è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­çš„çŸ¥è¯†ä¿ç•™|Haodong Lu, Chongyang Zhao, Jason Xue, Lina Yao, Kristen Moore, Dong Gong|<http://arxiv.org/pdf/2412.01004v5>|æå‡ºäº†ä¸€ç§åŠ¨æ€æ’åé€‰æ‹©LoRAæ–¹æ³•ï¼Œæœ‰æ•ˆä¿ç•™é¢„è®­ç»ƒçŸ¥è¯†å¹¶æå‡è§†è§‰è¯­è¨€æ¨¡å‹åœ¨æŒç»­å­¦ä¹ ä¸­çš„è¡¨ç°ã€‚|
|ğŸ†• å‘å¸ƒ|Revolutionizing Wildfire Detection with Convolutional Neural Networks: A VGG16 Model Approach|åˆ©ç”¨å·ç§¯ç¥ç»ç½‘ç»œé©æ–°é‡ç«æ£€æµ‹ï¼šVGG16æ¨¡å‹æ–¹æ³•|Lakshmi Aishwarya Malladi, Navarun Gupta, Ahmed El-Sayed, Xingguo Xiong|<http://arxiv.org/pdf/2505.19479v1>|åˆ©ç”¨VGG16æ¨¡å‹å’Œæ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œæœ‰æ•ˆæå‡äº†é‡ç«æ£€æµ‹çš„å‡†ç¡®ç‡ã€‚|


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Efficient Multi-modal Long Context Learning for Training-free Adaptation|é«˜æ•ˆçš„å¤šæ¨¡æ€é•¿ä¸Šä¸‹æ–‡å­¦ä¹ ç”¨äºæ— ç›‘ç£è‡ªé€‚åº”|Zehong Ma, Shiliang Zhang, Longhui Wei, Qi Tian|<http://arxiv.org/pdf/2505.19812v1>|[ä»£ç ](https://github.com/Zehong-Ma/EMLoC.); æå‡ºEMLoCï¼Œä¸€ç§é«˜æ•ˆçš„å¤šæ¨¡æ€é•¿ä¸Šä¸‹æ–‡å­¦ä¹ æ–°æ–¹æ³•ï¼Œå®ç°æ— ç›‘ç£ä»»åŠ¡é€‚åº”ã€‚|
|ğŸ“ æ›´æ–°|CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting|CompMarkGSï¼šå‹ç¼©3Dé«˜æ–¯åˆ†å±‚é²æ£’æ°´å°|Sumin In, Youngdong Jang, Utae Jeong, MinHyuk Jang, Hyeongcheol Park, Eunbyung Park, Sangpil Kim|<http://arxiv.org/pdf/2503.12836v4>|æå‡ºäº†ä¸€ç§æŠ—å‹ç¼©é²æ£’çš„3DGSæ°´å°æ–¹æ³•ï¼Œç¡®ä¿æ°´å°åœ¨æ¨¡å‹å‹ç¼©åä»èƒ½ä¿æŒé«˜è´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|SMART-PC: Skeletal Model Adaptation for Robust Test-Time Training in Point Clouds|æ™ºèƒ½-PCï¼šç‚¹äº‘ä¸­çš„é²æ£’æµ‹è¯•æ—¶è®­ç»ƒçš„éª¨éª¼æ¨¡å‹è‡ªé€‚åº”|Ali Bahri, Moslem Yazdanpanah, Sahar Dastani, Mehrdad Noori, Gustavo Adolfo Vargas Hakim, David Osowiechi, Farzad Beizaee, Ismail Ben Ayed .etc.|<http://arxiv.org/pdf/2505.19546v1>|[ä»£ç ](https://github.com/AliBahri94/SMART-PC.); SMART-PCé€šè¿‡éª¨éª¼æ¨¡å‹é¢„æµ‹ï¼Œå®ç°ç‚¹äº‘åˆ†ç±»çš„å®æ—¶è‡ªé€‚åº”ï¼Œæ˜¾è‘—æå‡é²æ£’æ€§å’Œæ•ˆç‡ã€‚|


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### å¯¹æŠ—é²æ£’æ€§ (Adversarial Robustness)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|ZeroPur: Succinct Training-Free Adversarial Purification|é›¶å‡€åŒ–ï¼šç®€æ´çš„æ— è®­ç»ƒå¯¹æŠ—å‡€åŒ–|Erhu Liu, Zonglin Yang, Bo Liu, Bin Xiao, Xiuli Bi|<http://arxiv.org/pdf/2406.03143v2>|æå‡ºZeroPurï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„å¯¹æŠ—å‡€åŒ–æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡å¯¹æŠ—æ”»å‡»é˜²å¾¡èƒ½åŠ›ã€‚|


### åˆ†å¸ƒå¤–æ³›åŒ– (Out-of-distribution Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|OmniFall: A Unified Staged-to-Wild Benchmark for Human Fall Detection|å…¨åœºæ™¯è·Œå€’æ£€æµ‹ï¼šä¸€ä¸ªä»åœºæ™¯åˆ°çœŸå®ä¸–ç•Œçš„ç»Ÿä¸€åˆ†é˜¶æ®µåŸºå‡†|David Schneider, Zdravko Marinov, Rafael Baur, Zeyun Zhong, Rodi DÃ¼ger, Rainer Stiefelhagen|<http://arxiv.org/pdf/2505.19889v1>|[ä»£ç ](https://github.com/simplexsigil/omnifall-experiments); OmniFallæ„å»ºäº†ä¸€ä¸ªç»Ÿä¸€çš„åŸºå‡†ï¼Œé€šè¿‡æ ‡å‡†åŒ–æ•°æ®å’Œè¯„ä¼°åè®®ï¼Œè§£å†³äº†ç°æœ‰è·Œå€’æ£€æµ‹æ•°æ®é›†çš„åŸŸåå€šå’Œæ³›...|


### ä¸ç¡®å®šæ€§é‡åŒ– (Uncertainty Quantification)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|WQLCP: Weighted Adaptive Conformal Prediction for Robust Uncertainty Quantification Under Distribution Shifts|WQLCPï¼šåŸºäºåˆ†å¸ƒåç§»çš„é²æ£’ä¸ç¡®å®šæ€§é‡åŒ–åŠ æƒè‡ªé€‚åº”ä¸€è‡´é¢„æµ‹|Shadi Alijani, Homayoun Najjaran|<http://arxiv.org/pdf/2505.19587v1>|æå‡ºWQLCPæ–¹æ³•ï¼Œé€šè¿‡åŠ æƒè‡ªé€‚åº”è°ƒæ•´ï¼Œæé«˜åˆ†å¸ƒåç§»ä¸‹çš„ä¸€è‡´æ€§é¢„æµ‹çš„é²æ£’æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Certainty and Uncertainty Guided Active Domain Adaptation|ç¡®å®šæ€§åŠä¸ç¡®å®šæ€§å¼•å¯¼çš„ä¸»åŠ¨åŸŸè‡ªé€‚åº”|Bardia Safaei, Vibashan VS, Vishal M. Patel|<http://arxiv.org/pdf/2505.19421v1>|æå‡ºä¸€ç§ç»“åˆç½®ä¿¡åº¦å¼•å¯¼çš„ä¸»åŠ¨åŸŸé€‚åº”æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡æ¨¡å‹è·¨åŸŸé€‚åº”æ€§èƒ½ã€‚|


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Improvement Strategies for Few-Shot Learning in OCT Image Classification of Rare Retinal Diseases|OCTå›¾åƒåˆ†ç±»ä¸­ç½•è§è§†ç½‘è†œç–¾ç—…å°‘æ ·æœ¬å­¦ä¹ çš„æ”¹è¿›ç­–ç•¥|Cheng-Yu Tai, Ching-Wen Chen, Chi-Chin Wu, Bo-Chen Chiu, Cheng-Hung, Lin, Cheng-Kai Lu, Jia-Kang Wang .etc.|<http://arxiv.org/pdf/2505.20149v1>|æå‡ºåŸºäºU-GAT-ITå’ŒCBAMçš„GANå¢å¼ºç­–ç•¥ï¼Œæ˜¾è‘—æå‡OCTå›¾åƒåˆ†ç±»å‡†ç¡®ç‡ã€‚|
|ğŸ†• å‘å¸ƒ|DepthMatch: Semi-Supervised RGB-D Scene Parsing through Depth-Guided Regularization|æ·±åº¦åŒ¹é…ï¼šé€šè¿‡æ·±åº¦å¼•å¯¼æ­£åˆ™åŒ–çš„åŠç›‘ç£RGB-Dåœºæ™¯è§£æ|Jianxin Huang, Jiahang Li, Sergey Vityazev, Alexander Dvorkovich, Rui Fan|<http://arxiv.org/pdf/2505.20041v1>|DepthMatché€šè¿‡æ·±åº¦å¼•å¯¼æ­£åˆ™åŒ–å’ŒåŠç›‘ç£å­¦ä¹ ï¼Œæœ‰æ•ˆæå‡äº†RGB-Dåœºæ™¯è§£æçš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|SaSi: A Self-augmented and Self-interpreted Deep Learning Approach for Few-shot Cryo-ET Particle Detection|SaSiï¼šä¸€ç§ç”¨äºå°‘é‡æ ·æœ¬å†·å†»ç”µå­æ–­å±‚æ‰«æç²’å­æ£€æµ‹çš„è‡ªå¢å¼ºå’Œè‡ªè§£é‡Šæ·±åº¦å­¦ä¹ æ–¹æ³•|Gokul Adethya, Bhanu Pratyush Mantha, Tianyang Wang, Xingjian Li, Min Xu|<http://arxiv.org/pdf/2505.19948v1>|æå‡ºSaSiæ–¹æ³•ï¼Œé€šè¿‡è‡ªå¢å¼ºå’Œè‡ªè§£é‡ŠæŠ€æœ¯ï¼Œåœ¨å°‘é‡æ ‡æ³¨æ•°æ®ä¸‹æ˜¾è‘—æå‡cryo-ETç²’å­æ£€æµ‹æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|DeepEyes: Incentivizing "Thinking with Images" via Reinforcement Learning|æ·±åº¦è§†è§‰ï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ æ¿€åŠ±â€œä»¥å›¾æ€è€ƒâ€|Ziwei Zheng, Michael Yang, Jack Hong, Chenxiao Zhao, Guohai Xu, Le Yang, Chao Shen, Xing Yu|<http://arxiv.org/pdf/2505.14362v2>|[ä»£ç ](https://github.com/Visual-Agent/DeepEyes.); é€šè¿‡å¼ºåŒ–å­¦ä¹ æ¿€åŠ±æ¨¡å‹â€œä»¥å›¾åƒæ€è€ƒâ€ï¼Œå®ç°è§†è§‰ä¸æ–‡æœ¬æ¨ç†çš„æ— ç¼ç»“åˆã€‚|
|ğŸ†• å‘å¸ƒ|Multi-Timescale Motion-Decoupled Spiking Transformer for Audio-Visual Zero-Shot Learning|å¤šå°ºåº¦è¿åŠ¨è§£è€¦è„‰å†²å˜æ¢å™¨åœ¨éŸ³é¢‘-è§†è§‰é›¶æ ·æœ¬å­¦ä¹ ä¸­çš„åº”ç”¨|Wenrui Li, Penghong Wang, Xingtao Wang, Wangmeng Zuo, Xiaopeng Fan, Yonghong Tian|<http://arxiv.org/pdf/2505.19938v1>|æå‡ºäº†ä¸€ç§å¤šå°ºåº¦è¿åŠ¨è§£è€¦çš„è„‰å†²ç¥ç»ç½‘ç»œï¼Œæœ‰æ•ˆæå‡äº†éŸ³é¢‘è§†è§‰é›¶æ ·æœ¬å­¦ä¹ æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|UAV-Flow Colosseo: A Real-World Benchmark for Flying-on-a-Word UAV Imitation Learning|æ— äººæœº-æµåŠ¨ç§‘æ´›å¡å¥¥ï¼šé£è¡Œåœ¨å•è¯æ— äººæœºæ¨¡ä»¿å­¦ä¹ çš„ä¸€ä¸ªçœŸå®ä¸–ç•ŒåŸºå‡†|Xiangyu Wang, Donglin Yang, Yue Liao, Wenhao Zheng, wenjun wu, Bin Dai, Hongsheng Li, Si Liu|<http://arxiv.org/pdf/2505.15725v2>|æ„å»ºäº†é¦–ä¸ªçœŸå®ä¸–ç•ŒåŸºå‡†UAV-Flowï¼Œé€šè¿‡æ¨¡ä»¿å­¦ä¹ å®ç°è¯­è¨€å¼•å¯¼çš„UAVç²¾ç»†æ§åˆ¶ã€‚|
|ğŸ“ æ›´æ–°|Generalizable Prompt Learning of CLIP: A Brief Overview|CLIPçš„æ³›åŒ–æç¤ºå­¦ä¹ ï¼šç®€è¦æ¦‚è¿°|Fangming Cui, Yonggang Zhang, Xuan Wang, Xule Wang, Liang Xiao|<http://arxiv.org/pdf/2503.01263v5>|è¯¥è®ºæ–‡æ¦‚è¿°äº†CLIPçš„é€šç”¨æç¤ºå­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡å°‘é‡æ ·æœ¬è®­ç»ƒå®ç°è·¨15ä¸ªæ•°æ®é›†çš„åˆ†ç±»ã€‚|
|ğŸ“ æ›´æ–°|Navigating Conflicting Views: Harnessing Trust for Learning|åœ¨å†²çªè§‚ç‚¹ä¸­å¯¼èˆªï¼šåˆ©ç”¨ä¿¡ä»»è¿›è¡Œå­¦ä¹ |Jueqing Lu, Wray Buntine, Yuanyuan Qi, Joanna Dipnall, Belinda Gabbe, Lan Du|<http://arxiv.org/pdf/2406.00958v3>|å¼€å‘äº†ä¸€ç§åŸºäºä¿¡ä»»æœºåˆ¶çš„é™æƒæ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³å¤šè§†è§’åˆ†ç±»ä¸­çš„å†²çªï¼Œæå‡é¢„æµ‹å¯é æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Multiplicity is an Inevitable and Inherent Challenge in Multimodal Learning|å¤šæ¨¡æ€å­¦ä¹ ä¸­çš„å¤šä¹‰æ€§æ˜¯ä¸€ä¸ªä¸å¯é¿å…ä¸”å›ºæœ‰çš„æŒ‘æˆ˜|Sanghyuk Chun|<http://arxiv.org/pdf/2505.19614v1>|æå‡ºæ–°æ¡†æ¶åº”å¯¹å¤šæ¨¡æ€å­¦ä¹ ä¸­çš„â€œå¤šé‡æ€§â€æŒ‘æˆ˜ï¼Œæå‡æ•°æ®è´¨é‡å’Œè®­ç»ƒå¯é æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Few-Shot Class-Incremental Learning For Efficient SAR Automatic Target Recognition|å°‘é‡æ ·æœ¬ç±»å¢é‡å­¦ä¹ ç”¨äºé«˜æ•ˆçš„SARè‡ªåŠ¨ç›®æ ‡è¯†åˆ«|George Karantaidis, Athanasios Pantsios, Ioannis Kompatsiaris, Symeon Papadopoulos|<http://arxiv.org/pdf/2505.19565v1>|æå‡ºäº†ä¸€ç§åŸºäºåŒåˆ†æ”¯æ¶æ„çš„è½»é‡çº§FSCILæ¡†æ¶ï¼Œæœ‰æ•ˆè§£å†³äº†SAR-ATRä¸­çš„æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|Applications and Effect Evaluation of Generative Adversarial Networks in Semi-Supervised Learning|åŠç›‘ç£å­¦ä¹ ä¸­ç”Ÿæˆå¯¹æŠ—ç½‘ç»œçš„åº”ç”¨ä¸æ•ˆæœè¯„ä¼°|Jiyu Hu, Haijiang Zeng, Zhen Tian|<http://arxiv.org/pdf/2505.19522v1>|æ„å»ºåŸºäºGANsçš„åŠç›‘ç£å›¾åƒåˆ†ç±»æ¨¡å‹ï¼Œæœ‰æ•ˆåˆ©ç”¨æœ‰é™æ ‡æ³¨æ•°æ®ä¸å¤§é‡æœªæ ‡æ³¨æ•°æ®ï¼Œæå‡åˆ†ç±»ç²¾åº¦ã€‚|
|ğŸ“ æ›´æ–°|SUFFICIENT: A scan-specific unsupervised deep learning framework for high-resolution 3D isotropic fetal brain MRI reconstruction|SUFFICIENTï¼šä¸€ç§é’ˆå¯¹æ‰«æç‰¹å®šçš„é«˜åˆ†è¾¨ç‡3Då„å‘åŒæ€§èƒå„¿è„‘MRIé‡å»ºçš„æ— ç›‘ç£æ·±åº¦å­¦ä¹ æ¡†æ¶|Jiangjie Wu, Lixuan Chen, Zhenghao Li, Xin Li, Saban Ozturk, Lihui Wang, Rongpin Wang, Hongjiang Wei .etc.|<http://arxiv.org/pdf/2505.17472v2>|æå‡ºäº†ä¸€ç§æ— ç›‘ç£æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæœ‰æ•ˆè§£å†³èƒå„¿è„‘MRIé‡å»ºä¸­çš„è¿åŠ¨ä¼ªå½±é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|Exploring the Possibility of TypiClust for Low-Budget Federated Active Learning|æ¢ç´¢TypiCluståœ¨ä½æˆæœ¬è”é‚¦ä¸»åŠ¨å­¦ä¹ ä¸­çš„å¯èƒ½æ€§|Yuta Ono, Hiroshi Nakamura, Hideki Takase|<http://arxiv.org/pdf/2505.19404v1>|åœ¨ä½é¢„ç®—è”é‚¦ä¸»åŠ¨å­¦ä¹ ä¸­ï¼ŒéªŒè¯äº†TypiClustæ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå³ä½¿åœ¨æ•°æ®å¼‚è´¨å’Œæ ‡æ³¨æœ‰é™çš„æŒ‘æˆ˜ä¸‹ã€‚|
|ğŸ†• å‘å¸ƒ|DiSa: Directional Saliency-Aware Prompt Learning for Generalizable Vision-Language Models|DiSaï¼šé¢å‘æ³›åŒ–è§†è§‰-è¯­è¨€æ¨¡å‹çš„å®šå‘æ˜¾è‘—æ€§æ„ŸçŸ¥æç¤ºå­¦ä¹ |Niloufar Alipour Talemi, Hossein Kashiani, Hossein R. Nowdeh, Fatemeh Afghah|<http://arxiv.org/pdf/2505.19373v1>|DiSaé€šè¿‡ç»“åˆäº¤å‰äº¤äº’æ­£åˆ™åŒ–å’Œæ–¹å‘æ€§æ­£åˆ™åŒ–ï¼Œæå‡äº†è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚|


## å…·èº«æ™ºèƒ½ä¸äº¤äº’è§†è§‰ (Embodied Intelligence & Interactive Vision)


### è§†è§‰å¯¼èˆªä¸è·¯å¾„è§„åˆ’ (Visual Navigation & Path Planning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Exploring 3D Activity Reasoning and Planning: From Implicit Human Intentions to Route-Aware Planning|æ¢ç´¢3Dæ´»åŠ¨æ¨ç†ä¸è§„åˆ’ï¼šä»éšå«äººç±»æ„å›¾åˆ°è·¯å¾„æ„ŸçŸ¥è§„åˆ’|Xueying Jiang, Wenhao Li, Xiaoqin Zhang, Ling Shao, Shijian Lu|<http://arxiv.org/pdf/2503.12974v2>|æå‡ºäº†ä¸€ç§ä»éšå«æŒ‡ä»¤æ¨ç†æ´»åŠ¨å¹¶è§„åˆ’è·¯å¾„çš„3Dä»»åŠ¡ï¼Œæœ‰æ•ˆè§£å†³ç°æœ‰ç ”ç©¶çš„ä¾èµ–æŒ‡ä»¤å’Œå¿½ç•¥è·¯å¾„è§„åˆ’é—®é¢˜ã€‚|


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|STAR-R1: Spatial TrAnsformation Reasoning by Reinforcing Multimodal LLMs|STAR-R1ï¼šé€šè¿‡å¼ºåŒ–å¤šæ¨¡æ€LLMsè¿›è¡Œç©ºé—´å˜æ¢æ¨ç†|Zongzhao Li, Zongyang Ma, Mingze Li, Songyou Li, Yu Rong, Tingyang Xu, Ziqi Zhang, Deli Zhao .etc.|<http://arxiv.org/pdf/2505.15804v2>|[ä»£ç ](https://github.com/zongzhao23/STAR-R1.); STAR-R1é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼Œæœ‰æ•ˆæå‡äº†å¤šæ¨¡æ€LLMsåœ¨ç©ºé—´æ¨ç†æ–¹é¢çš„èƒ½åŠ›ã€‚|
|ğŸ“ æ›´æ–°|Task-Oriented Communications for Visual Navigation with Edge-Aerial Collaboration in Low Altitude Economy|é¢å‘ä»»åŠ¡çš„è¾¹ç¼˜æ— äººæœºåä½œä½ç©ºç»æµè§†è§‰å¯¼èˆªé€šä¿¡|Zhengru Fang, Zhenghao Liu, Jingjing Wang, Senkang Hu, Yu Guo, Yiqin Deng, Yuguang Fang|<http://arxiv.org/pdf/2504.18317v4>|[ä»£ç ](https://github.com/fangzr/TOC-Edge-Aerial.); æå‡ºä¸€ç§åŸºäºä»»åŠ¡å¯¼å‘çš„é€šä¿¡æ¡†æ¶ï¼Œé€šè¿‡O-VIBç¼–ç å™¨å®ç°æ— äººæœºåœ¨ä½å¸¦å®½ç¯å¢ƒä¸‹çš„é«˜ç²¾åº¦å®šä½ã€‚|
|ğŸ“ æ›´æ–°|NoisyRollout: Reinforcing Visual Reasoning with Data Augmentation|å™ªå£°å›æ»šï¼šé€šè¿‡æ•°æ®å¢å¼ºå¼ºåŒ–è§†è§‰æ¨ç†|Xiangyan Liu, Jinjie Ni, Zijian Wu, Chao Du, Longxu Dou, Haonan Wang, Tianyu Pang, Michael Qizhe Shieh|<http://arxiv.org/pdf/2504.13055v2>|NoisyRollouté€šè¿‡æ··åˆä¸åŒè§†è§‰æ„ŸçŸ¥è½¨è¿¹ï¼Œæœ‰æ•ˆå¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›ã€‚|
|ğŸ“ æ›´æ–°|VR-Robo: A Real-to-Sim-to-Real Framework for Visual Robot Navigation and Locomotion|VR-Roboï¼šä¸€ç§çœŸå®åˆ°æ¨¡æ‹Ÿå†åˆ°çœŸå®è§†è§‰æœºå™¨äººå¯¼èˆªä¸è¿åŠ¨æ¡†æ¶|Shaoting Zhu, Linzhan Mou, Derun Li, Baijun Ye, Runhan Huang, Hang Zhao|<http://arxiv.org/pdf/2502.01536v2>|æå‡ºVR-Roboæ¡†æ¶ï¼Œé€šè¿‡ç”Ÿæˆé€¼çœŸæ¨¡æ‹Ÿç¯å¢ƒï¼Œè§£å†³è§†è§‰æœºå™¨äººå¯¼èˆªå’Œè¿åŠ¨ä¸­çš„çœŸå®ä¸æ¨¡æ‹Ÿå·®è·é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|Decomposing Complex Visual Comprehension into Atomic Visual Skills for Vision Language Models|å°†å¤æ‚è§†è§‰ç†è§£åˆ†è§£ä¸ºåŸå­è§†è§‰æŠ€èƒ½ç”¨äºè§†è§‰è¯­è¨€æ¨¡å‹|Hyunsik Chae, Seungwoo Yoon, Jaden Park, Chloe Yewon Chun, Yongin Cho, Mu Cai, Yong Jae Lee, Ernest K. Ryu|<http://arxiv.org/pdf/2505.20021v1>|å°†å¤æ‚è§†è§‰ç†è§£åˆ†è§£ä¸ºåŸå­è§†è§‰æŠ€èƒ½ï¼Œæ„å»ºæ•°æ®é›†è¯„ä¼°è§†è§‰è¯­è¨€æ¨¡å‹åœ¨åŸºç¡€è§†è§‰ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚|
|ğŸ†• å‘å¸ƒ|Progressive Scaling Visual Object Tracking|æ¸è¿›å¼ç¼©æ”¾è§†è§‰ç›®æ ‡è·Ÿè¸ª|Jack Hong, Shilin Yan, Zehao Xiao, Jiayin Cai, Xiaolong Jiang, Yao Hu, Henghui Ding|<http://arxiv.org/pdf/2505.19990v1>|æå‡ºæ¸è¿›å¼ç¼©æ”¾è®­ç»ƒç­–ç•¥ï¼Œæ˜¾è‘—æå‡è§†è§‰ç›®æ ‡è·Ÿè¸ªæ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|Dynamic Multimodal Evaluation with Flexible Complexity by Vision-Language Bootstrapping|åŠ¨æ€å¤šæ¨¡æ€è¯„ä¼°ï¼šé€šè¿‡è§†è§‰-è¯­è¨€å¼•å¯¼çš„çµæ´»å¤æ‚æ€§|Yue Yang, Shuibai Zhang, Wenqi Shao, Kaipeng Zhang, Yi Bin, Yu Wang, Ping Luo|<http://arxiv.org/pdf/2410.08695v3>|æå‡ºVision-Language Bootstrappingæ–¹æ³•ï¼ŒåŠ¨æ€è¯„ä¼°LVLMsï¼Œå‡å°‘æ•°æ®æ±¡æŸ“...|
|ğŸ†• å‘å¸ƒ|Point-RFT: Improving Multimodal Reasoning with Visually Grounded Reinforcement Finetuning|ç‚¹-RFTï¼šé€šè¿‡è§†è§‰åŸºç¡€å¼ºåŒ–å¾®è°ƒæå‡å¤šæ¨¡æ€æ¨ç†|Minheng Ni, Zhengyuan Yang, Linjie Li, Chung-Ching Lin, Kevin Lin, Wangmeng Zuo, Lijuan Wang|<http://arxiv.org/pdf/2505.19702v1>|Point-RFTé€šè¿‡è§†è§‰åŸºç¡€CoTæ¨ç†ï¼Œæ˜¾è‘—æå‡äº†è§†è§‰æ–‡æ¡£ç†è§£çš„å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition|çŸ¥è¯†å¯¹é½çš„å¯¹æŠ—å¢å¼ºæ‰©æ•£æ„ŸçŸ¥ç”¨äºæ— ç›‘ç£è·¨åŸŸè§†è§‰æƒ…æ„Ÿè¯†åˆ«|Wen Yin, Yong Wang, Guiduo Duan, Dongyang Zhang, Xin Hu, Yuan-Fang Li, Tao He|<http://arxiv.org/pdf/2505.19694v1>|[ä»£ç ](https://yinwen2019.github.io/ucdver.); å®šä½è·¨åŸŸè§†è§‰æƒ…æ„Ÿè¯†åˆ«æŒ‘æˆ˜ï¼Œæå‡ºçŸ¥è¯†å¯¹é½çš„å¯¹æŠ—å¢å¼ºæ‰©æ•£æ„ŸçŸ¥æ¡†æ¶ï¼Œæå‡æ¨¡å‹æ„ŸçŸ¥å’Œæ³›åŒ–èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|VisCRA: A Visual Chain Reasoning Attack for Jailbreaking Multimodal Large Language Models|è§†è§‰é“¾æ¨ç†æ”»å‡»ï¼šç”¨äºè¶Šç‹±å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„VisCRA|Bingrui Sima, Linhua Cong, Wenxuan Wang, Kun He|<http://arxiv.org/pdf/2505.19684v1>|æå‡ºVisCRAæ”»å‡»æ¡†æ¶ï¼Œåˆ©ç”¨è§†è§‰æ¨ç†é“¾ç ´è§£å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨æœºåˆ¶ã€‚|
|ğŸ†• å‘å¸ƒ|Benchmarking Large Multimodal Models for Ophthalmic Visual Question Answering with OphthalWeChat|çœ¼ç§‘è§†è§‰é—®ç­”ä¸­å¤§å‹å¤šæ¨¡æ€æ¨¡å‹çš„åŸºå‡†æµ‹è¯•ï¼šåŸºäºOphthalWeChat|Pusheng Xu, Xia Gong, Xiaolan Chen, Weiyi Zhang, Jiancheng Yang, Bingjie Yan, Meng Yuan, Yalin Zheng .etc.|<http://arxiv.org/pdf/2505.19624v1>|æ„å»ºäº†é¦–ä¸ªçœ¼ç§‘åŒè¯­è§†è§‰é—®ç­”åŸºå‡†ï¼Œè¯„ä¼°äº†å¤§å‹å¤šæ¨¡æ€æ¨¡å‹åœ¨çœ¼ç§‘é¢†åŸŸçš„æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|Align and Surpass Human Camouflaged Perception: Visual Refocus Reinforcement Fine-Tuning|å¯¹é½å¹¶è¶…è¶Šäººç±»ä¼ªè£…æ„ŸçŸ¥ï¼šè§†è§‰é‡æ–°èšç„¦å¼ºåŒ–å¾®è°ƒ|Ruolin Shen, Xiaozhong Ji, Kai WU, Jiangning Zhang, Yijun He, HaiHua Yang, Xiaobin Hu, Xiaoyu Sun|<http://arxiv.org/pdf/2505.19611v1>|æå‡ºè§†è§‰é‡èšç„¦å¼ºåŒ–æ¡†æ¶ï¼Œä½¿å¤šæ¨¡æ€æ¨¡å‹åœ¨ä¼ªè£…æ„ŸçŸ¥ä»»åŠ¡ä¸Šè¶…è¶Šäººç±»è§†è§‰ç³»ç»Ÿã€‚|
|ğŸ†• å‘å¸ƒ|Multimodal Machine Translation with Visual Scene Graph Pruning|å¤šæ¨¡æ€æœºå™¨ç¿»è¯‘ä¸è§†è§‰åœºæ™¯å›¾å‰ªæ|Chenyu Lu, Shiliang Sun, Jing Zhao, Nan Zhang, Tengfei Song, Hao Yang|<http://arxiv.org/pdf/2505.19507v1>|é€šè¿‡è§†è§‰åœºæ™¯å›¾å‰ªæï¼Œæœ‰æ•ˆå‡å°‘å†—ä½™è§†è§‰ä¿¡æ¯ï¼Œæå‡å¤šæ¨¡æ€æœºå™¨ç¿»è¯‘å‡†ç¡®åº¦ã€‚|
|ğŸ“ æ›´æ–°|Parrot: Multilingual Visual Instruction Tuning|é¹¦é¹‰ï¼šå¤šè¯­è¨€è§†è§‰æŒ‡ä»¤å¾®è°ƒ|Hai-Long Sun, Da-Wei Zhou, Yang Li, Shiyin Lu, Chao Yi, Qing-Guo Chen, Zhao Xu, Weihua Luo .etc.|<http://arxiv.org/pdf/2406.02539v3>|[ä»£ç ](https://github.com/AIDC-AI/Parrot); PARROTé€šè¿‡æ–‡æœ¬å¼•å¯¼è§†è§‰æ ‡è®°å¯¹é½ï¼Œæå‡å¤šè¯­è¨€è§†è§‰æŒ‡ä»¤ç†è§£èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|MM-Prompt: Cross-Modal Prompt Tuning for Continual Visual Question Answering|MM-Promptï¼šè·¨æ¨¡æ€æç¤ºå¾®è°ƒç”¨äºæŒç»­è§†è§‰é—®ç­”|Xu Li, Fan Lyu|<http://arxiv.org/pdf/2505.19455v1>|MM-Prompté€šè¿‡è·¨æ¨¡æ€æç¤ºæŸ¥è¯¢å’Œæ¢å¤ï¼Œè§£å†³CVQAä¸­æ¨¡æ€ä¸å¹³è¡¡é—®é¢˜ï¼Œæå‡æŒç»­å­¦ä¹ æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|Pixel Reasoner: Incentivizing Pixel-Space Reasoning with Curiosity-Driven Reinforcement Learning|åƒç´ æ¨ç†å™¨ï¼šåˆ©ç”¨å¥½å¥‡å¿ƒé©±åŠ¨çš„å¼ºåŒ–å­¦ä¹ æ¿€åŠ±åƒç´ ç©ºé—´æ¨ç†|Alex Su, Haozhe Wang, Weiming Ren, Fangzhen Lin, Wenhu Chen|<http://arxiv.org/pdf/2505.15966v2>|é€šè¿‡å¼•å…¥åƒç´ ç©ºé—´æ¨ç†å’Œå¼ºåŒ–å­¦ä¹ ï¼Œæ˜¾è‘—æå‡äº†è§†è§‰è¯­è¨€æ¨¡å‹åœ¨è§†è§‰æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|Semantic-Space-Intervened Diffusive Alignment for Visual Classification|è¯­ä¹‰ç©ºé—´ä»‹å…¥çš„æ‰©æ•£å¯¹é½ç”¨äºè§†è§‰åˆ†ç±»|Zixuan Li, Lei Meng, Guoqing Chao, Wei Wu, Xiaoshuo Yan, Yimeng Yang, Zhuang Qi, Xiangxu Meng|<http://arxiv.org/pdf/2505.05721v2>|æå‡ºSeDAæ–¹æ³•ï¼Œé€šè¿‡è¯­ä¹‰ç©ºé—´å¹²é¢„å’Œæ¸è¿›å¼ç‰¹å¾äº¤äº’ï¼Œæœ‰æ•ˆè§£å†³è·¨æ¨¡æ€è§†è§‰åˆ†ç±»ä¸­çš„ç‰¹å¾å¯¹é½é—®é¢˜ã€‚|


### è·¨æ¨¡æ€æ£€ç´¢ä¸åŒ¹é… (Cross-modal Retrieval & Matching)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Human-Aligned Image Models Improve Visual Decoding from the Brain|äººè„‘è§†è§‰è§£ç çš„å›¾åƒæ¨¡å‹ï¼šä¸äººç±»å¯¹é½|Nona Rajabi, AntÃ´nio H. Ribeiro, Miguel Vasco, Farzaneh Taleb, MÃ¥rten BjÃ¶rkman, Danica Kragic|<http://arxiv.org/pdf/2502.03081v2>|åˆ©ç”¨äººç±»å¯¹å›¾åƒçš„æ„ŸçŸ¥ç‰¹æ€§ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è„‘ç”µå›¾å›¾åƒè§£ç æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†å›¾åƒæ£€ç´¢å‡†ç¡®ç‡ã€‚|
|ğŸ†• å‘å¸ƒ|Can Visual Encoder Learn to See Arrows?|è§†è§‰ç¼–ç å™¨èƒ½å¦å­¦ä¼šè¯†åˆ«ç®­å¤´ï¼Ÿ|Naoyuki Terashita, Yusuke Tozaki, Hideaki Omote, Congkha Nguyen, Ryosuke Nakamoto, Yuta Koreeda, Hiroaki Ozaki|<http://arxiv.org/pdf/2505.19944v1>|é€šè¿‡æ¶ˆé™¤æ–‡æœ¬å’Œä½ç½®åè§ï¼Œæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§è®­ç»ƒè§†è§‰ç¼–ç å™¨è¯†åˆ«å›¾åƒä¸­ç®­å¤´çš„æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†è§†è§‰è¯­è¨€æ¨¡å‹å¯¹...|


### è§†è§‰å†…å®¹æè¿° (Visual Content Description)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Corrupted but Not Broken: Understanding and Mitigating the Negative Impacts of Corrupted Data in Visual Instruction Tuning|æŸåä½†æœªç ´ç¢ï¼šç†è§£å¹¶å‡è½»è§†è§‰æŒ‡ä»¤å¾®è°ƒä¸­æŸåæ•°æ®çš„è´Ÿé¢å½±å“|Yunhao Gou, Hansi Yang, Zhili Liu, Kai Chen, Yihan Zeng, Lanqing Hong, Zhenguo Li, Qun Liu .etc.|<http://arxiv.org/pdf/2502.12635v2>|æå‡ºäº†ä¸€ç§åº”å¯¹è§†è§‰æŒ‡ä»¤å¾®è°ƒä¸­æ•°æ®æŸåé—®é¢˜çš„é²æ£’è®­ç»ƒèŒƒå¼ï¼Œæ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½ã€‚|


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### å·¥ä¸šè§†è§‰æ£€æµ‹ (Industrial Visual Inspection)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ReasonPlan: Unified Scene Prediction and Decision Reasoning for Closed-loop Autonomous Driving|ReasonPlanï¼šé—­ç¯è‡ªåŠ¨é©¾é©¶çš„ç»Ÿä¸€åœºæ™¯é¢„æµ‹ä¸å†³ç­–æ¨ç†|Xueyi Liu, Zuodong Zhong, Yuxin Guo, Yun-Fu Liu, Zhiguo Su, Qichao Zhang, Junli Wang, Yinfeng Gao .etc.|<http://arxiv.org/pdf/2505.20024v1>|[ä»£ç ](https://github.com/Liuxueyi/ReasonPlan.); ReasonPlané€šè¿‡ç»“åˆè‡ªç›‘ç£åœºæ™¯é¢„æµ‹å’Œå†³ç­–æ¨ç†ï¼Œæ˜¾è‘—æå‡äº†é—­ç¯è‡ªåŠ¨é©¾é©¶çš„å†³ç­–èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|DriveCamSim: Generalizable Camera Simulation via Explicit Camera Modeling for Autonomous Driving|è‡ªåŠ¨é©¾é©¶ä¸­çš„é€šç”¨ç›¸æœºæ¨¡æ‹Ÿï¼šé€šè¿‡æ˜¾å¼ç›¸æœºå»ºæ¨¡å®ç°|Wenchao Sun, Xuewu Lin, Keyu Chen, Zixiang Pei, Yining Shi, Chuang Zhang, Sifa Zheng|<http://arxiv.org/pdf/2505.19692v1>|[ä»£ç ](https://github.com/swc-17/DriveCamSim); DriveCamSimé€šè¿‡æ˜¾å¼ç›¸æœºå»ºæ¨¡ï¼Œå®ç°äº†å¯æ‰©å±•çš„ç›¸æœºæ¨¡æ‹Ÿï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨å¤šè§†è§’è§†é¢‘ç”Ÿæˆå’Œå¯æ§...|
|ğŸ“ æ›´æ–°|NuGrounding: A Multi-View 3D Visual Grounding Framework in Autonomous Driving|NuGroundingï¼šè‡ªåŠ¨é©¾é©¶ä¸­çš„å¤šè§†è§’3Dè§†è§‰å®šä½æ¡†æ¶|Fuhao Li, Huan Jin, Bin Gao, Liaoyuan Fan, Lihui Jiang, Long Zeng|<http://arxiv.org/pdf/2503.22436v2>|NuGroundingæå‡ºäº†ä¸€ç§ç»“åˆå¤šæ¨¡æ€LLMså’Œæ£€æµ‹æ¨¡å‹çš„æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†è‡ªåŠ¨é©¾é©¶ä¸­å¤šè§†å›¾3Dè§†...|


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Zero-Shot Pseudo Labels Generation Using SAM and CLIP for Semi-Supervised Semantic Segmentation|åŸºäºSAMå’ŒCLIPçš„é›¶æ ·æœ¬ä¼ªæ ‡ç­¾ç”Ÿæˆç”¨äºåŠç›‘ç£è¯­ä¹‰åˆ†å‰²|Nagito Saito, Shintaro Ito, Koichi Ito, Takafumi Aoki|<http://arxiv.org/pdf/2505.19846v1>|åˆ©ç”¨SAMå’ŒCLIPç”Ÿæˆä¼ªæ ‡ç­¾ï¼Œç»“åˆUniMatchæå‡åŠç›‘ç£è¯­ä¹‰åˆ†å‰²æ¨¡å‹ç²¾åº¦ã€‚|
|ğŸ†• å‘å¸ƒ|Improving Heart Rejection Detection in XPCI Images Using Synthetic Data Augmentation|åˆ©ç”¨åˆæˆæ•°æ®å¢å¼ºæé«˜XPCIå›¾åƒä¸­å¿ƒè„æ’æ–¥æ£€æµ‹çš„å‡†ç¡®æ€§|Jakov SamardÅ¾ija, Donik VrÅ¡nak, Sven LonÄariÄ‡|<http://arxiv.org/pdf/2505.19746v1>|åˆ©ç”¨StyleGANç”Ÿæˆåˆæˆæ•°æ®ï¼Œæœ‰æ•ˆç¼“è§£äº†å¿ƒè„æ’æ–¥æ£€æµ‹ä¸­æ•°æ®ä¸å¹³è¡¡é—®é¢˜ï¼Œæå‡äº†åˆ†ç±»æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|LangDAug: Langevin Data Augmentation for Multi-Source Domain Generalization in Medical Image Segmentation|LangDAugï¼šç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²çš„å¤šæºåŸŸæ³›åŒ–çš„Langevinæ•°æ®å¢å¼º|Piyush Tiwary, Kinjawl Bhattacharyya, Prathosh A. P|<http://arxiv.org/pdf/2505.19659v1>|[ä»£ç ](https://github.com/backpropagator/LangDAug.); LangDAugé€šè¿‡LangevinåŠ¨åŠ›å­¦å’ŒEBMå®ç°å¤šæºåŸŸæ³›åŒ–ï¼Œæœ‰æ•ˆæå‡åŒ»å­¦å›¾åƒåˆ†å‰²æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|DAE-Fuse: An Adaptive Discriminative Autoencoder for Multi-Modality Image Fusion|DAE-Fuseï¼šä¸€ç§è‡ªé€‚åº”åˆ¤åˆ«è‡ªç¼–ç å™¨ç”¨äºå¤šæ¨¡æ€å›¾åƒèåˆ|Yuchen Guo, Ruoxiang Xu, Rongcheng Li, Weifeng Su|<http://arxiv.org/pdf/2409.10080v3>|DAE-Fuseæå‡ºäº†ä¸€ç§è‡ªé€‚åº”åˆ¤åˆ«è‡ªç¼–ç å™¨ï¼Œæœ‰æ•ˆèåˆå¤šæ¨¡æ€å›¾åƒï¼Œæå‡å¤œé—´æˆ–ä½å¯è§ç¯å¢ƒä¸‹çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|Rep3D: Re-parameterize Large 3D Kernels with Low-Rank Receptive Modeling for Medical Imaging|Rep3Dï¼šåˆ©ç”¨ä½ç§©æ„Ÿå—é‡å»ºæ¨¡å¯¹å¤§å‹3Dæ ¸è¿›è¡Œé‡æ–°å‚æ•°åŒ–ä»¥ç”¨äºåŒ»å­¦æˆåƒ|Ho Hin Lee, Quan Liu, Shunxing Bao, Yuankai Huo, Bennett A. Landman|<http://arxiv.org/pdf/2505.19603v1>|[ä»£ç ](https://github.com/leeh43/Rep3D.); Rep3Dé€šè¿‡ä½ç§©æ„Ÿå—é‡å»ºæ¨¡ï¼Œä¼˜åŒ–å¤§æ ¸å·ç§¯ï¼Œæå‡3DåŒ»å­¦å›¾åƒåˆ†ææ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|Auto-nnU-Net: Towards Automated Medical Image Segmentation|è‡ªåŠ¨nnU-Netï¼šè¿ˆå‘è‡ªåŠ¨åŒ–åŒ»å­¦å›¾åƒåˆ†å‰²|Jannis Becktepe, Leona Hennig, Steffen Oeltze-Jafra, Marius Lindauer|<http://arxiv.org/pdf/2505.16561v2>|[ä»£ç ](https://github.com/LUH-AI/AutonnUNet.); æå‡ºAuto-nnU-Netï¼Œé€šè¿‡è‡ªåŠ¨åŒ–è¶…å‚æ•°ä¼˜åŒ–å’Œæ¶æ„æœç´¢ï¼Œæ˜¾è‘—æå‡åŒ»å­¦å›¾åƒåˆ†å‰²æ€§èƒ½ï¼ŒåŒæ—¶å¹³è¡¡è®¡ç®—...|
|ğŸ“ æ›´æ–°|Unsupervised Anomaly Detection Using Diffusion Trend Analysis for Display Inspection|åŸºäºæ‰©æ•£è¶‹åŠ¿åˆ†æçš„æ˜¾ç¤ºæ£€æŸ¥æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹|Eunwoo Kim, Un Yang, Cheol Lae Roh, Stefano Ermon|<http://arxiv.org/pdf/2407.09578v2>|æå‡ºäº†ä¸€ç§åŸºäºé‡å»ºè¶‹åŠ¿åˆ†æçš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†æ˜¾ç¤ºæ£€æµ‹ä¸­çš„å™ªå£°å‚æ•°å’Œæ­£å¸¸åŒºåŸŸæ³¢åŠ¨é—®é¢˜ã€‚|


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|ImageRAG: Enhancing Ultra High Resolution Remote Sensing Imagery Analysis with ImageRAG|å›¾åƒRAGï¼šåˆ©ç”¨å›¾åƒRAGå¢å¼ºè¶…é«˜åˆ†è¾¨ç‡é¥æ„Ÿå›¾åƒåˆ†æ|Zilun Zhang, Haozhan Shen, Tiancheng Zhao, Zian Guan, Bin Chen, Yuhao Wang, Xu Jia, Yuxiang Cai .etc.|<http://arxiv.org/pdf/2411.07688v4>|[ä»£ç ](https://github.com/om-ai-lab/ImageRAG); ImageRAGé€šè¿‡RAGæŠ€æœ¯ï¼Œé«˜æ•ˆå¤„ç†è¶…é«˜æ¸…é¥æ„Ÿå›¾åƒï¼Œæå‡åˆ†æå‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚|
|ğŸ“ æ›´æ–°|Cross-Modal Bidirectional Interaction Model for Referring Remote Sensing Image Segmentation|è·¨æ¨¡æ€åŒå‘äº¤äº’æ¨¡å‹ç”¨äºé¥æ„Ÿå›¾åƒåˆ†å‰²|Zhe Dong, Yuzhe Sun, Tianzhu Liu, Wangmeng Zuo, Yanfeng Gu|<http://arxiv.org/pdf/2410.08613v2>|[ä»£ç ](https://github.com/HIT-SIRS/CroBIM); æ£€æµ‹å¹¶åˆ†å‰²é¥æ„Ÿå›¾åƒä¸­çš„ç›®æ ‡ç‰©ä½“ï¼Œæå‡ºäº†ä¸€ç§è·¨æ¨¡æ€åŒå‘äº¤äº’æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†åˆ†å‰²ç²¾åº¦ã€‚|


### æ™ºèƒ½äº¤é€šè§†è§‰ (Intelligent Transportation Vision)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|OpenAD: Open-World Autonomous Driving Benchmark for 3D Object Detection|å¼€æ”¾ä¸–ç•Œè‡ªåŠ¨é©¾é©¶3Dç›®æ ‡æ£€æµ‹åŸºå‡†ï¼šOpenAD|Zhongyu Xia, Jishuo Li, Zhiwei Lin, Xinhao Wang, Yongtao Wang, Ming-Hsuan Yang|<http://arxiv.org/pdf/2411.17761v2>|[ä»£ç ](https://github.com/VDIGPKU/OpenAD.); æ„å»ºé¦–ä¸ªå¼€æ”¾ä¸–ç•Œè‡ªåŠ¨é©¾é©¶3Dç‰©ä½“æ£€æµ‹åŸºå‡†OpenADï¼Œå¹¶æå‡ºèåˆæ¨¡å‹è§£å†³ç²¾åº¦é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|DiffVLA: Vision-Language Guided Diffusion Planning for Autonomous Driving|DiffVLAï¼šè§†è§‰-è¯­è¨€å¼•å¯¼çš„è‡ªåŠ¨é©¾é©¶æ‰©æ•£è§„åˆ’|Anqing Jiang, Yu Gao, Zhigang Sun, Yiru Wang, Jijun Wang, Jinghao Chai, Qian Cao, Yuweng Heng .etc.|<http://arxiv.org/pdf/2505.19381v1>|DiffVLAé€šè¿‡ç»“åˆè§†è§‰è¯­è¨€æ¨¡å‹å’Œç¨€ç–å¯†é›†æ‰©æ•£ç­–ç•¥ï¼Œæœ‰æ•ˆæå‡äº†è‡ªåŠ¨é©¾é©¶åœ¨å¤æ‚åœºæ™¯ä¸‹çš„å†³ç­–æ€§èƒ½ã€‚|


## æ–°å…´ç†è®ºä¸è·¨å­¦ç§‘æ–¹å‘ (Emerging Theory & Interdisciplinary Directions)


### é‡å­è§†è§‰ç®—æ³• (Quantum Visual Algorithms)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|JailBound: Jailbreaking Internal Safety Boundaries of Vision-Language Models|ã€ŠJailBoundï¼šçªç ´è§†è§‰-è¯­è¨€æ¨¡å‹å†…éƒ¨å®‰å…¨è¾¹ç•Œã€‹|Jiaxin Song, Yixu Wang, Jie Li, Rui Yu, Yan Teng, Xingjun Ma, Yingchun Wang|<http://arxiv.org/pdf/2505.19610v1>|æå‡ºJailBoundæ¡†æ¶ï¼Œé€šè¿‡æ¢æµ‹å’Œè·¨è¶Šè§†è§‰è¯­è¨€æ¨¡å‹å†…éƒ¨å®‰å…¨è¾¹ç•Œï¼Œæœ‰æ•ˆæå‡å¯¹æŠ—æ”»å‡»æˆåŠŸç‡ã€‚|


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Deep Spectral Prior|æ·±åº¦å…‰è°±å…ˆéªŒ|Yanqi Cheng, Tieyong Zeng, Pietro Lio, Carola-Bibiane SchÃ¶nlieb, Angelica I Aviles-Rivero|<http://arxiv.org/pdf/2505.19873v1>|æå‡ºæ·±åº¦å…‰è°±å…ˆéªŒï¼Œå°†å›¾åƒé‡å»ºè§†ä¸ºé¢‘åŸŸå¯¹é½é—®é¢˜ï¼Œæœ‰æ•ˆæŠ‘åˆ¶å™ªå£°å¹¶æå‡é‡å»ºè´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|Translation-Equivariance of Normalization Layers and Aliasing in Convolutional Neural Networks|å·ç§¯ç¥ç»ç½‘ç»œä¸­å½’ä¸€åŒ–å±‚çš„å¹³ç§»ç­‰å˜æ€§å’Œæ··å |JÃ©rÃ©my Scanvic, Quentin BarthÃ©lemy, JuliÃ¡n Tachella|<http://arxiv.org/pdf/2505.19805v1>|æ­ç¤ºäº†å½’ä¸€åŒ–å±‚å¯¹å¹³ç§»çš„ç­‰å˜æ€§ï¼Œä¸ºæ„å»ºæ›´ç²¾ç¡®çš„å·ç§¯ç¥ç»ç½‘ç»œæä¾›äº†ç†è®ºæ¡†æ¶ã€‚|
|ğŸ†• å‘å¸ƒ|Rotation-Equivariant Self-Supervised Method in Image Denoising|æ—‹è½¬ç­‰å˜å›¾åƒå»å™ªçš„è‡ªç›‘ç£æ–¹æ³•|Hanze Liu, Jiahong Fu, Qi Xie, Deyu Meng|<http://arxiv.org/pdf/2505.19618v1>|é¦–æ¬¡å°†æ—‹è½¬ç­‰å˜å…ˆéªŒå¼•å…¥è‡ªç›‘ç£å›¾åƒå»å™ªï¼Œå¹¶è®¾è®¡æ–°æœºåˆ¶èåˆæ—‹è½¬ç­‰å˜ç½‘ç»œä¸æ™®é€šCNNç½‘ç»œè¾“å‡ºï¼Œæ˜¾è‘—æå‡å»å™ª...|
|ğŸ†• å‘å¸ƒ|FieldWorkArena: Agentic AI Benchmark for Real Field Work Tasks|FieldWorkArenaï¼šçœŸå®é‡å¤–å·¥ä½œä»»åŠ¡çš„ä»£ç†äººå·¥æ™ºèƒ½åŸºå‡†|Atsunori Moteki, Shoichi Masui, Fan Yang, Yueqi Song, Yonatan Bisk, Graham Neubig, Ikuo Kusajima, Yasuto Watanabe .etc.|<http://arxiv.org/pdf/2505.19662v1>|FieldWorkArenaæå‡ºé¦–ä¸ªé’ˆå¯¹çœŸå®ä¸–ç•Œç°åœºå·¥ä½œä»»åŠ¡çš„Agentic AIåŸºå‡†ï¼Œè¯„ä¼°å…¶åœ¨å¤šæ¨¡...|
|ğŸ†• å‘å¸ƒ|M3DHMR: Monocular 3D Hand Mesh Recovery|M3DHMRï¼šå•ç›®3Dæ‰‹éƒ¨ç½‘æ ¼æ¢å¤|Yihong Lin, Xianjia Wu, Xilai Wang, Jianqiao Hu, Songju Lei, Xiandong Li, Wenxiong Kang|<http://arxiv.org/pdf/2505.20058v1>|M3DHMRé€šè¿‡åˆ›æ–°è§£ç å™¨ç›´æ¥ä»å•å¼ å›¾åƒæ¢å¤3Dæ‰‹éƒ¨ç½‘æ ¼ï¼Œæ˜¾è‘—æå‡å®æ—¶æ€§èƒ½ã€‚|

