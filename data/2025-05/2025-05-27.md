## [UPDATED!] **2025-05-27** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vision Transformers with Self-Distilled Registers|视觉Transformer与自蒸馏寄存器|Yinjie Chen, Zipeng Yan, Chong Zhou, Bo Dai, Andrew F. Luo|<http://arxiv.org/pdf/2505.21501v1>|提出一种高效的自蒸馏方法，为预训练ViT添加注册标记，有效减少异常标记，提升分割和深度预测性能。|
|🆕 发布|AgriFM: A Multi-source Temporal Remote Sensing Foundation Model for Crop Mapping|农业FM：一种用于作物制图的多元源时序遥感基础模型|Wenyuan Li, Shunlin Liang, Keyan Chen, Yongzhe Chen, Han Ma, Jianglei Xu, Yichuan Ma, Shikang Guan .etc.|<http://arxiv.org/pdf/2505.21357v1>|[代码](https://github.com/flyakon/AgriFM.); 提出AgriFM，一种多源遥感基础模型，有效解决作物映射中的多尺度时空特征提取问题。|
|🆕 发布|MagicTryOn: Harnessing Diffusion Transformer for Garment-Preserving Video Virtual Try-on|魔幻试穿：利用扩散Transformer实现服装保留的视频虚拟试穿|Guangyuan Li, Siming Zheng, Hao Zhang, Jinwei Chen, Junsheng Luan, Binkai Ou, Lei Zhao, Bo Li .etc.|<http://arxiv.org/pdf/2505.21325v1>|提出MagicTryOn，利用扩散Transformer实现服装保留的视频虚拟试穿，提升时空一致性和...|
|📝 更新|RemoteSAM: Towards Segment Anything for Earth Observation|远程SAM：迈向地球观测的“任何分割”|Liang Yao, Fan Liu, Delong Chen, Chuanyi Zhang, Yijun Wang, Ziyun Chen, Wei Xu, Shimin Di .etc.|<http://arxiv.org/pdf/2505.18022v2>|[代码](https://github.com/1e12Leon/RemoteSAM.); 开发了一种适用于地球观测的Segment Anything模型，通过数据与模型创新，实现了高效的多任...|
|🆕 发布|HTMNet: A Hybrid Network with Transformer-Mamba Bottleneck Multimodal Fusion for Transparent and Reflective Objects Depth Completion|HTMNet：一种具有Transformer-Mamba瓶颈多模态融合的透明和反射物体深度补全的混合网络|Guanghu Xie, Yonglong Zhang, Zhiduo Jiang, Yang Liu, Zongwu Xie, Baoshi Cao, Hong Liu|<http://arxiv.org/pdf/2505.20904v1>|提出HTMNet，融合Transformer和Mamba架构，有效解决透明和反光物体深度信息不完整问...|
|🆕 发布|In Context Learning with Vision Transformers: Case Study|基于视觉Transformer的上下文学习：案例研究|Antony Zhao, Alex Proshkin, Fergal Hennessy, Francesco Crivelli|<http://arxiv.org/pdf/2505.20872v1>|利用视觉Transformer实现图像空间中的情境学习，分析其学习复杂函数的能力。|
|🆕 发布|Leaner Transformers: More Heads, Less Depth|更轻量级的Transformer：更多头，更少深度|Hemanth Saratchandran, Damien Teney, Simon Lucey|<http://arxiv.org/pdf/2505.20802v1>|通过增加Transformer的头部数量而非深度，实现了模型参数减少30-50%的同时保持准确率。|
|📝 更新|EDmamba: A Simple yet Effective Event Denoising Method with State Space Model|EDmamba：一种简单而有效的基于状态空间模型的事件去噪方法|Ciyu Ruan, Zihang Gong, Ruishan Guo, Jingao Xu, Xinlei Chen|<http://arxiv.org/pdf/2505.05391v2>|提出了一种基于状态空间模型的事件去噪框架，有效平衡了速度与鲁棒性。|
|📝 更新|Dynamic-I2V: Exploring Image-to-Video Generation Models via Multimodal LLM|动态-I2V：通过多模态大型语言模型探索图像到视频生成模型|Peng Liu, Xiaoming Ren, Fengkai Liu, Qingsong Xie, Quanlong Zheng, Yanhao Zhang, Haonan Lu, Yujiu Yang|<http://arxiv.org/pdf/2505.19901v2>|Dynamic-I2V通过整合多模态LLM，显著提升了视频生成中的动态范围、可控性和质量。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GeoLLaVA-8K: Scaling Remote-Sensing Multimodal Large Language Models to 8K Resolution|GeoLLaVA-8K：将遥感多模态大型语言模型扩展至8K分辨率|Fengxiang Wang, Mingshuo Chen, Yueying Li, Di Wang, Haotian Wang, Zonghao Guo, Zefan Wang, Boqi Shan .etc.|<http://arxiv.org/pdf/2505.21375v1>|GeoLLaVA-8K通过引入高分辨率视觉语言数据集和背景token剪枝策略，首次实现了8K分辨率遥...|
|🆕 发布|DynamicVL: Benchmarking Multimodal Large Language Models for Dynamic City Understanding|动态VL：动态城市理解的多模态大型语言模型基准测试|Weihao Xuan, Junjue Wang, Heli Qi, Zihang Chen, Zhuo Zheng, Yanfei Zhong, Junshi Xia, Naoto Yokoya|<http://arxiv.org/pdf/2505.21076v1>|提出DVL-Suite框架，评估多模态大语言模型在动态城市理解中的表现，并构建DVLChat模型以提...|
|🆕 发布|Create Anything Anywhere: Layout-Controllable Personalized Diffusion Model for Multiple Subjects|《随时随地创造任何事物：多主体布局可控个性化扩散模型》|Wei Li, Hebei Li, Yansong Peng, Siying Wu, Yueyi Zhang, Xiaoyan Sun|<http://arxiv.org/pdf/2505.20909v1>|提出LCP-Diffusion模型，实现个性化图像生成，精确控制布局并保持身份。|
|📝 更新|How Do Multimodal Large Language Models Handle Complex Multimodal Reasoning? Placing Them in An Extensible Escape Game|如何处理复杂的多模态推理？将多模态大型语言模型置于可扩展的逃脱游戏中|Ziyue Wang, Yurui Dong, Fuwen Luo, Minyuan Ruan, Zhili Cheng, Chi Chen, Peng Li, Yang Liu|<http://arxiv.org/pdf/2503.10042v3>|提出MM-Escape基准，通过模拟逃脱游戏环境，评估和揭示多模态大语言模型在复杂推理任务中的行为和...|
|🆕 发布|Fork-Merge Decoding: Enhancing Multimodal Understanding in Audio-Visual Large Language Models|分叉-合并解码：提升音频-视觉大型语言模型的多模态理解|Chaeyoung Jung, Youngjoon Jang, Jongmin Choi, Joon Son Chung|<http://arxiv.org/pdf/2505.20873v1>|提出Fork-Merge Decoding策略，缓解AV-LLMs中的模态偏差，提升多模态理解能力。|
|📝 更新|EmoNet-Face: An Expert-Annotated Benchmark for Synthetic Emotion Recognition|EmoNet-Face：合成情绪识别的专家标注基准|Christoph Schuhmann, Robert Kaczmarczyk, Gollam Rabby, Felix Friedrich, Maurice Kraus, Krishna Kalyan, Kourosh Nadi, Huu Nguyen .etc.|<http://arxiv.org/pdf/2505.20033v2>|构建了EmoNet Face基准，提供更细粒度的情绪分类和高质量数据集，以促进合成情绪识别研究。|
|🆕 发布|PARTONOMY: Large Multimodal Models with Part-Level Visual Understanding|帕特诺米：具有部分级视觉理解的庞大多模态模型|Ansel Blume, Jeonghwan Kim, Hyeonjeong Ha, Elen Chatikyan, Xiaomeng Jin, Khanh Duy Nguyen, Nanyun Peng, Kai-Wei Chang .etc.|<http://arxiv.org/pdf/2505.20759v1>|PARTONOMY提出了一种新的多模态模型，通过部分级视觉理解能力，显著提升了细粒度视觉理解。|
|🆕 发布|Intern-GS: Vision Model Guided Sparse-View 3D Gaussian Splatting|Intern-GS：视觉模型引导的稀疏视图3D高斯分层|Xiangyu Sun, Runnan Chen, Mingming Gong, Dong Xu, Tongliang Liu|<http://arxiv.org/pdf/2505.20729v1>|Intern-GS通过利用视觉基础模型指导稀疏视图高斯分层，显著提升了稀疏视图场景重建的质量。|
|🆕 发布|OccLE: Label-Efficient 3D Semantic Occupancy Prediction|OccLE：标签高效的3D语义占用预测|Naiyu Fang, Zheyuan Zhou, Fayao Liu, Xulei Yang, Jiacheng Wei, Lemiao Qiu, Guosheng Lin|<http://arxiv.org/pdf/2505.20617v1>|OccLE通过解耦语义和几何学习，融合特征网格，实现高效3D语义占用预测。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Uni3D-MoE: Scalable Multimodal 3D Scene Understanding via Mixture of Experts|Uni3D-MoE：通过专家混合实现可扩展的多模态3D场景理解|Yue Zhang, Yingzhao Jian, Hehe Fan, Yi Yang, Roger Zimmermann|<http://arxiv.org/pdf/2505.21079v1>|提出Uni3D-MoE，通过混合专家模型实现自适应3D多模态融合，提升3D场景理解能力。|
|🆕 发布|Advancing high-fidelity 3D and Texture Generation with 2.5D latents|提升高保真3D和纹理生成的2.5D潜在表示|Xin Yang, Jiantao Lin, Yingjie Xu, Haodong Li, Yingcong Chen|<http://arxiv.org/pdf/2505.21050v1>|提出了一种基于2.5D表示的联合生成方法，显著提升了3D几何和纹理的生成质量。|
|📝 更新|QUART-Online: Latency-Free Large Multimodal Language Model for Quadruped Robot Learning|QUART-Online：用于四足机器人学习的零延迟大型多模态语言模型|Xinyang Tong, Pengxiang Ding, Yiguo Fan, Donglin Wang, Wenjie Zhang, Can Cui, Mingyang Sun, Han Zhao .etc.|<http://arxiv.org/pdf/2412.15576v5>|提出QUART-Online模型，解决四足机器人学习中多模态语言模型延迟问题，提升任务成功率65%。|
|🆕 发布|Understand, Think, and Answer: Advancing Visual Reasoning with Large Multimodal Models|理解、思考、回答：通过大型多模态模型推进视觉推理|Yufei Zhan, Hongyin Zhao, Yousong Zhu, Shurong Zheng, Fan Yang, Ming Tang, Jinqiao Wang|<http://arxiv.org/pdf/2505.20753v1>|[代码](https://github.com/jefferyZhan/Griffon); 提出统一视觉推理机制，使大型多模态模型具备复杂问题解决能力。|
|📝 更新|LatentExplainer: Explaining Latent Representations in Deep Generative Models with Multimodal Large Language Models|潜在解释器：利用多模态大型语言模型解释深度生成模型中的潜在表示|Mengdan Zhu, Raasikh Kanjiani, Jiahui Lu, Andrew Choi, Qirui Ye, Liang Zhao|<http://arxiv.org/pdf/2406.14862v6>|提出LatentExplainer，利用多模态大语言模型解释深度生成模型中的潜在变量，提升模型可解释...|
|🆕 发布|Music's Multimodal Complexity in AVQA: Why We Need More than General Multimodal LLMs|音乐在AVQA中的多模态复杂性：为什么我们需要比通用多模态LLMs更多的东西|Wenhao You, Xingjian Diao, Chunhui Zhang, Keyi Kong, Weiyi Wu, Zhongyu Ouyang, Chiyu Ma, Tingxuan Wu .etc.|<http://arxiv.org/pdf/2505.20638v1>|[代码](https://github.com/xid32/Survey4MusicAVQA.); 提出针对音乐领域的AVQA问题，需专门设计输入处理、时空架构和音乐建模策略。|
|📝 更新|GarmentDiffusion: 3D Garment Sewing Pattern Generation with Multimodal Diffusion Transformers|服装扩散：基于多模态扩散变换器的3D服装缝纫图案生成|Xinyu Li, Qi Yao, Yuanda Wang|<http://arxiv.org/pdf/2504.21476v3>|[代码](https://shenfu-research.github.io/Garment-Diffusion); 提出GarmentDiffusion，一种高效生成精确3D服装缝纫图案的多模态扩散模型。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OrionBench: A Benchmark for Chart and Human-Recognizable Object Detection in Infographics|奥里恩基准：信息图表中图表和可识别物体检测的基准|Jiangning Zhu, Yuxing Zhou, Zheng Wang, Juntao Yao, Yima Gu, Yuhui Yuan, Shixia Liu|<http://arxiv.org/pdf/2505.17473v2>|构建OrionBench基准，提升图表和可识别物体检测在信息图表中的准确性。|
|🆕 发布|VisAlgae 2023: A Dataset and Challenge for Algae Detection in Microscopy Images|VisAlgae 2023：显微镜图像中藻类检测的数据集和挑战|Mingxuan Sun, Juntao Jiang, Zhiqiang Yang, Shenao Kong, Jiamin Qi, Jianru Shang, Shuangling Luo, Wanfa Sun .etc.|<http://arxiv.org/pdf/2505.20687v1>|[代码](https://github.com/juntaoJianggavin/Visalgae2023); 构建VisAlgae 2023数据集，挑战微藻检测难题，提升检测准确率。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Efficient Leaf Disease Classification and Segmentation using Midpoint Normalization Technique and Attention Mechanism|高效利用中点归一化技术和注意力机制进行叶片病害分类与分割|Enam Ahmed Taufik, Antara Firoz Parsa, Seraj Al Mahmud Mostafa|<http://arxiv.org/pdf/2505.21316v1>|提出了一种结合MPN和注意力机制的方法，有效提升了叶病图像分类和分割的准确性和效率。|
|🆕 发布|Supervised and self-supervised land-cover segmentation & classification of the Biesbosch wetlands|比斯博斯湿地监督和自监督土地覆盖分割与分类|Eva Gmelich Meijling, Roberto Del Prete, Arnoud Visser|<http://arxiv.org/pdf/2505.21269v1>|提出结合监督学习和自监督学习的方法，有效提升了湿地土地覆盖分类的准确性。|
|📝 更新|Quantum autoencoders for image classification|量子自编码器在图像分类中的应用|Hinako Asaoka, Kazue Kudo|<http://arxiv.org/pdf/2502.15254v2>|提出了一种基于量子自编码器的图像分类方法，显著提高分类精度并减少参数优化需求。|
|📝 更新|Multiple Different Black Box Explanations for Image Classifiers|多种不同的黑盒解释用于图像分类器|Hana Chockler, David A. Kelly, Daniel Kroening|<http://arxiv.org/pdf/2309.14309v4>|提出了一种基于因果关系的算法，为图像分类器提供多个黑盒解释，提升了解释质量和数量。|
|📝 更新|Lean classical-quantum hybrid neural network model for image classification|轻量级经典-量子混合神经网络模型用于图像分类|Ao Liu, Cuihong Wen, Jieci Wang|<http://arxiv.org/pdf/2412.02059v3>|提出了一种参数量少的经典-量子混合神经网络模型，有效降低计算成本并提升图像分类准确率。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spectral Compression Transformer with Line Pose Graph for Monocular 3D Human Pose Estimation|基于线姿态图的频谱压缩Transformer用于单目3D人体姿态估计|Zenghao Zheng, Lianping Yang, Hegui Zhu, Mingrui Ye|<http://arxiv.org/pdf/2505.21309v1>|提出了一种基于谱压缩和线姿态图的轻量级单目3D人体姿态估计方法，显著提升了性能和计算效率。|
|📝 更新|SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect|SuperAD：CVPR 2025 VAND 3.0 工作坊挑战赛第1赛道：适应与检测的无监督异常分类与分割方法|Huaiyuan Zhang, Hang Chen, Yu Cheng, Shunyi Wu, Linghao Sun, Linao Han, Zeyu Shi, Lei Qi|<http://arxiv.org/pdf/2505.19750v2>|提出一种无需训练的基于DINOv2模型的异常检测与分割方法SuperAD，有效应对复杂工业环境中的异...|
|🆕 发布|YOLO-FireAD: Efficient Fire Detection via Attention-Guided Inverted Residual Learning and Dual-Pooling Feature Preservation|YOLO-FireAD：通过注意力引导的倒残差学习和双池化特征保留实现高效的火焰检测|Weichao Pan, Bohan Xu, Xu Wang, Chengze Lv, Shuoyang Wang, Zhenke Duan|<http://arxiv.org/pdf/2505.20884v1>|提出YOLO-FireAD，通过注意力引导和双池化融合，有效提升动态环境火灾检测效率和准确性。|
|🆕 发布|Open-Det: An Efficient Learning Framework for Open-Ended Detection|开放检测：一种高效的开源检测学习框架|Guiping Cao, Tao Wang, Wenjian Huang, Xiangyuan Lan, Jianguo Zhang, Dongmei Jiang|<http://arxiv.org/pdf/2505.20639v1>|[代码](https://github.com/Med-Process/Open-Det.); 提出Open-Det框架，高效解决开放式目标检测问题，显著提升性能。|
|📝 更新|SoftPQ: Robust Instance Segmentation Evaluation via Soft Matching and Tunable Thresholds|软PQ：通过软匹配和可调阈值实现鲁棒的实例分割评估|Ranit Karmakar, Simon F. Nørrelykke|<http://arxiv.org/pdf/2505.12155v2>|提出SoftPQ，通过软匹配和可调阈值，实现鲁棒的实例分割评估。|
|🆕 发布|Mamba-Driven Topology Fusion for Monocular 3-D Human Pose Estimation|基于Mamba驱动的单目3D人体姿态估计拓扑融合|Zenghao Zheng, Lianping Yang, Jinshan Pan, Hegui Zhu|<http://arxiv.org/pdf/2505.20611v1>|提出Mamba-Driven Topology Fusion框架，融合骨骼拓扑信息，提升单目3D人体...|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Frame In-N-Out: Unbounded Controllable Image-to-Video Generation|帧内与外：无界可控图像到视频生成|Boyang Wang, Xuweiyi Chen, Matheus Gadelha, Zezhou Cheng|<http://arxiv.org/pdf/2505.21491v1>|提出了一种基于帧内外的可控图像到视频生成方法，显著提升了视频生成效果。|
|🆕 发布|UI-Genie: A Self-Improving Approach for Iteratively Boosting MLLM-based Mobile GUI Agents|UI-Genie：一种用于迭代提升基于多语言语言模型（MLLM）的移动GUI代理的自改进方法|Han Xiao, Guozhi Wang, Yuxiang Chai, Zimu Lu, Weifeng Lin, Hao He, Lue Fan, Liuyang Bian .etc.|<http://arxiv.org/pdf/2505.21496v1>|[代码](https://github.com/Euphoria16/UI-Genie.); UI-Genie通过奖励模型和自改进流程，解决GUI代理训练数据不可扩展和轨迹验证困难的问题。|
|🆕 发布|Be Decisive: Noise-Induced Layouts for Multi-Subject Generation|果断决策：多主体生成中的噪声诱导布局|Omer Dahary, Yehonathan Cohen, Or Patashnik, Kfir Aberman, Daniel Cohen-Or|<http://arxiv.org/pdf/2505.21488v1>|通过预测与初始噪声一致的布局，该方法有效避免了多主题生成中的泄漏问题，提升了文本与图像的匹配度和稳定...|
|🆕 发布|Generalizable and Relightable Gaussian Splatting for Human Novel View Synthesis|通用且可重光照的高斯分层用于人类新视角合成|Yipengjing Sun, Chenyang Wang, Shunyuan Zheng, Zonglin Li, Shengping Zhang, Xiangyang Ji|<http://arxiv.org/pdf/2505.21502v1>|提出了一种基于3D高斯模型的人体新视角合成方法，实现不同光照条件下的高保真渲染。|
|🆕 发布|Policy Optimized Text-to-Image Pipeline Design|策略优化文本到图像管道设计|Uri Gadot, Rinon Gal, Yftah Ziser, Gal Chechik, Shie Mannor|<http://arxiv.org/pdf/2505.21478v1>|提出一种基于强化学习的文本到图像生成流程设计方法，有效降低计算需求并提升图像质量。|
|🆕 发布|MV-CoLight: Efficient Object Compositing with Consistent Lighting and Shadow Generation|MV-CoLight：具有一致光照和阴影生成的有效物体合成|Kerui Ren, Jiayang Bai, Linning Xu, Lihan Jiang, Jiangmiao Pang, Mulin Yu, Bo Dai|<http://arxiv.org/pdf/2505.21483v1>|提出MV-CoLight，一种高效且一致的物体合成方法，解决多视角一致性和复杂场景问题。|
|🆕 发布|Mitigating Hallucination in Large Vision-Language Models via Adaptive Attention Calibration|通过自适应注意力校准减轻大型视觉-语言模型中的幻觉|Mehrdad Fazli, Bowen Wei, Ziwei Zhu|<http://arxiv.org/pdf/2505.21472v1>|提出CAAC框架，通过自适应注意力校准有效减少大型视觉语言模型在多模态任务中的幻觉问题。|
|📝 更新|Bringing Objects to Life: training-free 4D generation from 3D objects through view consistent noise|让物体栩栩如生：通过视图一致噪声从3D物体进行无训练的4D生成|Ohad Rahamim, Ori Malca, Dvir Samuel, Gal Chechik|<http://arxiv.org/pdf/2412.20422v2>|提出了一种无需训练的基于文本提示的4D生成方法，通过视图一致噪声使3D物体动画更逼真。|
|🆕 发布|Empowering Vector Graphics with Consistently Arbitrary Viewing and View-dependent Visibility|赋予矢量图形一致任意视角和视依赖可见性的能力|Yidi Li, Jun Xiao, Zhengda Lu, Yiqun Wang, Haiyong Jiang|<http://arxiv.org/pdf/2505.21377v1>|提出Dream3DVG，实现文本到矢量图形的任意视角生成，优化细节并感知遮挡。|
|📝 更新|Envisioning Beyond the Pixels: Benchmarking Reasoning-Informed Visual Editing|超越像素的想象：基于推理的视觉编辑基准测试|Xiangyu Zhao, Peiyuan Zhang, Kexian Tang, Xiaorong Zhu, Hao Li, Wenhao Chai, Zicheng Zhang, Renqiu Xia .etc.|<http://arxiv.org/pdf/2504.02826v4>|[代码](https://github.com/PhoenixZ810/RISEBench.); 构建RISEBench基准，评估推理驱动的视觉编辑，揭示现有模型在复杂指令理解和视觉一致性上的局限。|
|🆕 发布|SageAttention2++: A More Efficient Implementation of SageAttention2|智慧注意力2++：SageAttention2的更高效实现|Jintao Zhang, Xiaoming Xu, Jia Wei, Haofeng Huang, Pengle Zhang, Chendong Xiang, Jun Zhu, Jianfei Chen|<http://arxiv.org/pdf/2505.21136v1>|[代码](https://github.com/thu-ml/SageAttention.); 提出SageAttention2++，通过FP8 Matmul加速，有效提升SageAttentio...|
|🆕 发布|IKMo: Image-Keyframed Motion Generation with Trajectory-Pose Conditioned Motion Diffusion Model|图像关键帧运动生成：基于轨迹姿态条件运动扩散模型|Yang Zhao, Yan Zhang, Xubo Yang|<http://arxiv.org/pdf/2505.21146v1>|提出了一种基于轨迹和姿态解耦的扩散模型，显著提升了运动生成的空间和语义保真度。|
|🆕 发布|Inverse Virtual Try-On: Generating Multi-Category Product-Style Images from Clothed Individuals|逆向虚拟试穿：从着装个体生成多类别产品风格图像|Davide Lobba, Fulvio Sanguigni, Bin Ren, Marcella Cornia, Rita Cucchiara, Nicu Sebe|<http://arxiv.org/pdf/2505.21062v1>|提出TEMU-VTOFF，通过多模态信息增强和注意力机制，实现从着装者照片生成标准化服装产品图。|
|🆕 发布|Minute-Long Videos with Dual Parallelisms|极短视频的双并行性|Zeqing Wang, Bowen Zheng, Xingyi Yang, Yuecong Xu, Xinchao Wang|<http://arxiv.org/pdf/2505.21070v1>|提出了一种名为DualParal的分布式推理策略，通过并行处理视频帧和模型层，显著降低了长视频生成的...|
|🆕 发布|RainFusion: Adaptive Video Generation Acceleration via Multi-Dimensional Visual Redundancy|RainFusion：通过多维度视觉冗余实现自适应视频生成加速|Aiyue Chen, Bin Dong, Jingru Li, Jing Lin, Yiwu Yao, Gongyi Wang|<http://arxiv.org/pdf/2505.21036v1>|RainFusion通过识别视频生成中的稀疏模式，显著加速了注意力计算，同时保持视频质量。|
|🆕 发布|DreamBoothDPO: Improving Personalized Generation using Direct Preference Optimization|DreamBoothDPO：通过直接偏好优化提升个性化生成|Shamil Ayupov, Maksim Nakhodnov, Anastasia Yaschenko, Andrey Kuznetsov, Aibek Alanov|<http://arxiv.org/pdf/2505.20975v1>|[代码](https://github.com/ControlGenAI/DreamBoothDPO.); 通过直接偏好优化，DreamBoothDPO提升了个性化生成图像的忠实度和上下文一致性。|
|🆕 发布|Facial Attribute Based Text Guided Face Anonymization|基于面部属性的文字引导面部匿名化|Mustafa İzzet Muştu, Hazım Kemal Ekenel|<http://arxiv.org/pdf/2505.21002v1>|提出一种基于扩散模型的文本引导人脸匿名化方法，有效保护隐私并生成自然人脸图像。|
|🆕 发布|Object-Centric Action-Enhanced Representations for Robot Visuo-Motor Policy Learning|以对象为中心的动作增强表示用于机器人视觉-运动策略学习|Nikos Giannakakis, Argyris Manetas, Panagiotis P. Filntisis, Petros Maragos, George Retsinas|<http://arxiv.org/pdf/2505.20962v1>|提出一种基于物体中心编码的视觉表示学习方法，有效提升机器人视觉运动策略学习。|
|🆕 发布|OrienText: Surface Oriented Textual Image Generation|面向表面的文本图像生成|Shubham Singh Paliwal, Arushi Jain, Monika Sharma, Vikram Jamwal, Lovekesh Vig|<http://arxiv.org/pdf/2505.20958v1>|OrienText通过利用表面法线信息，提高了文本在复杂表面上的准确渲染和正确方向。|
|🆕 发布|Geometry-Editable and Appearance-Preserving Object Compositon|几何可编辑且外观保持的对象合成|Jianman Lin, Haojie Li, Chunmei Qing, Zhijing Yang, Liang Lin, Tianshui Chen|<http://arxiv.org/pdf/2505.20914v1>|提出DGAD模型，通过语义嵌入和交叉注意力机制实现几何可编辑且外观保持的对象合成。|
|🆕 发布|ISAC: Training-Free Instance-to-Semantic Attention Control for Improving Multi-Instance Generation|ISAC：无需训练的实例到语义注意力控制，以提升多实例生成|Sanghyun Jo, Wooyeol Lee, Ziseok Lee, Kyungsu Kim|<http://arxiv.org/pdf/2505.20935v1>|ISAC通过实例优先建模，有效解决多实例生成中的对象合并和遗漏问题，显著提升多实例生成准确率。|
|🆕 发布|Frame-Level Captions for Long Video Generation with Complex Multi Scenes|基于复杂多场景的长视频帧级字幕生成|Guangcong Zheng, Jianlong Yuan, Bo Wang, Haoyang Huang, Guoqing Ma, Nan Duan|<http://arxiv.org/pdf/2505.20827v1>|[代码](https://zgctroy.github.io/frame-level-captions); 提出帧级标注和注意力机制，有效解决长视频复杂多场景生成中的误差累积问题。|
|🆕 发布|Exploring Timeline Control for Facial Motion Generation|探索面部运动生成的时间线控制|Yifeng Ma, Jinwei Qi, Chaonan Ji, Peng Zhang, Bang Zhang, Zhidong Deng, Liefeng Bo|<http://arxiv.org/pdf/2505.20861v1>|提出了一种基于时间线控制的生成模型，实现精确的动态面部表情生成。|
|📝 更新|Exploring Disentangled and Controllable Human Image Synthesis: From End-to-End to Stage-by-Stage|探索解耦和可控的人脸图像合成：从端到端到分阶段|Zhengwentai Sun, Chenghong Li, Hongjie Liao, Xihe Yang, Keru Zheng, Heyuan Li, Yihao Zhi, Shuliang Ning .etc.|<http://arxiv.org/pdf/2503.19486v2>|[代码](https://taited.github.io/discohuman-project); 提出了一种分阶段的人像合成方法，有效提升了细粒度可控性和泛化能力。|
|🆕 发布|Spatial RoboGrasp: Generalized Robotic Grasping Control Policy|空间机器人抓取：通用机器人抓取控制策略|Yiqi Huang, Travis Davies, Jiahuan Yan, Jiankai Sun, Xiang Chen, Luhui Hu|<http://arxiv.org/pdf/2505.20814v1>|提出融合多模态感知与可靠预测的框架，实现通用机器人抓取控制。|
|🆕 发布|ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval|从文本概念中学习以实现组合图像检索：ConText-CIR|Eric Xing, Pranavi Kolouju, Robert Pless, Abby Stylianou, Nathan Jacobs|<http://arxiv.org/pdf/2505.20764v1>|[代码](https://github.com/mvrl/ConText-CIR.); 提出ConText-CIR框架，通过文本概念一致性损失和合成数据生成，提升组合图像检索性能。|
|🆕 发布|LeDiFlow: Learned Distribution-guided Flow Matching to Accelerate Image Generation|学习分布引导的流匹配以加速图像生成：LeDiFlow|Pascal Zwick, Nils Friederich, Maximilian Beichter, Lennart Hilbert, Ralf Mikut, Oliver Bringmann|<http://arxiv.org/pdf/2505.20723v1>|LeDiFlow通过学习更适合的先验分布，显著提升了基于Flow Matching的图像生成效率。|
|📝 更新|Shaping a Stabilized Video by Mitigating Unintended Changes for Concept-Augmented Video Editing|通过减轻意外变化来塑造稳定视频以实现概念增强视频编辑|Mingce Guo, Jingxuan He, Shengeng Tang, Zhangye Wang, Lechao Cheng|<http://arxiv.org/pdf/2410.12526v2>|提出了一种通过概念对增强和双重先验监督机制，实现稳定且灵活的视频编辑方法。|
|📝 更新|Many Heads Are Better Than One: Improved Scientific Idea Generation by A LLM-Based Multi-Agent System|多头胜过单头：基于LLM的多智能体系统提升科学创意生成|Haoyang Su, Renqi Chen, Shixiang Tang, Zhenfei Yin, Xinzhe Zheng, Jinzhe Li, Biqing Qi, Qi Wu .etc.|<http://arxiv.org/pdf/2410.09403v4>|[代码](https://github.com/open-sciencelab/Virtual-Scientists.); 提出虚拟科学家多智能体系统，通过模拟团队合作提升科学创新。|
|🆕 发布|Photography Perspective Composition: Towards Aesthetic Perspective Recommendation|摄影透视构图：迈向美学视角推荐|Lujian Yao, Siming Zheng, Xinbin Yuan, Zhuoxuan Cai, Pu Wu, Jinwei Chen, Bo Li, Peng-Tao Jiang|<http://arxiv.org/pdf/2505.20655v1>|提出了一种基于专家照片的摄影视角构图方法，通过视频展示和评估模型，帮助用户提升构图技巧。|
|📝 更新|BCDDM: Branch-Corrected Denoising Diffusion Model for Black Hole Image Generation|BCDDM：用于黑洞图像生成的分支校正去噪扩散模型|Ao liu, Zelin Zhang, Songbai Chen, Cuihong Wen, Jieci Wang|<http://arxiv.org/pdf/2502.08528v3>|提出BCDDM模型，通过物理参数直接生成黑洞图像，提高参数预测性能并降低计算成本。|
|🆕 发布|Incorporating Flexible Image Conditioning into Text-to-Video Diffusion Models without Training|将灵活的图像预处理融入文本到视频扩散模型中而不进行训练|Bolin Lai, Sangmin Lee, Xu Cao, Xiang Li, James M. Rehg|<http://arxiv.org/pdf/2505.20629v1>|提出了一种无需训练的灵活图像条件方法，显著提升了文本到视频生成模型的视觉效果。|
|🆕 发布|ConsiStyle: Style Diversity in Training-Free Consistent T2I Generation|ConsiStyle：无训练一致T2I生成中的风格多样性|Yohai Mazuz, Janna Bruner, Lior Wolf|<http://arxiv.org/pdf/2505.20626v1>|提出一种无需训练的方法，通过调整注意力机制实现风格一致且主题外观不变的文本到图像生成。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers|《从科学论文到多模态海报自动化的研究》|Wei Pang, Kevin Qinghong Lin, Xiangru Jian, Xi He, Philip Torr|<http://arxiv.org/pdf/2505.21497v1>|[代码](https://github.com/Paper2Poster/Paper2Poster.); 提出首个学术海报自动生成基准和指标，并设计多智能体流程实现高效海报生成。|
|📝 更新|DADM: Dual Alignment of Domain and Modality for Face Anti-spoofing|DADM：域和模态的双重对齐用于人脸反欺骗|Jingyi Yang, Xun Lin, Zitong Yu, Liepiao Zhang, Xin Liu, Hui Li, Xiaochen Yuan, Xiaochun Cao|<http://arxiv.org/pdf/2503.00429v2>|提出DADM方法，通过模态间对齐和双域优化，有效解决多模态人脸反欺骗中的模态和域不匹配问题。|
|🆕 发布|Generative Image Compression by Estimating Gradients of the Rate-variable Feature Distribution|基于估计率变量特征分布梯度的生成图像压缩|Minghao Han, Weiyi You, Jinhua Zhang, Leheng Zhang, Ce Zhu, Shuhang Gu|<http://arxiv.org/pdf/2505.20984v1>|提出了一种基于扩散模型的生成图像压缩方法，通过直接反向扩散路径重建图像，实现高质量压缩。|
|🆕 发布|Not All Thats Rare Is Lost: Causal Paths to Rare Concept Synthesis|并非所有罕见之物都失之交臂：罕见概念合成的因果路径|Bo-Kai Ruan, Zi-Xiang Ni, Bo-Lun Huang, Teng-Fang Hsiao, Hong-Han Shuai|<http://arxiv.org/pdf/2505.20808v1>|提出RAP框架，通过因果路径导航生成罕见概念，提升扩散模型罕见概念合成能力。|
|🆕 发布|Rendering-Aware Reinforcement Learning for Vector Graphics Generation|基于渲染感知的矢量图形生成强化学习|Juan A. Rodriguez, Haotian Zhang, Abhay Puri, Aarash Feizi, Rishav Pramanik, Pascal Wichmann, Arnab Mondal, Mohammad Reza Samsami .etc.|<http://arxiv.org/pdf/2505.20793v1>|引入了基于渲染反馈的强化学习方法，显著提升了向量图形生成的准确性和效率。|
|🆕 发布|HCQA-1.5 @ Ego4D EgoSchema Challenge 2025|HCQA-1.5 在 Ego4D EgoSchema 挑战赛 2025|Haoyu Zhang, Yisen Feng, Qiaohui Chu, Meng Liu, Weili Guan, Yaowei Wang, Liqiang Nie|<http://arxiv.org/pdf/2505.20644v1>|[代码](https://github.com/Hyu-Zhang/HCQA.); 提出HCQA框架扩展，通过多源聚合和置信度筛选提升自视角视频问答准确率。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ID-Align: RoPE-Conscious Position Remapping for Dynamic High-Resolution Adaptation in Vision-Language Models|ID-Align：视觉-语言模型中动态高分辨率自适应的RoPE意识位置重映射|Bozhou Li, Wentao Zhang|<http://arxiv.org/pdf/2505.21465v1>|[代码](https://github.com/zooblastlbz/ID-Align.); 提出ID-Align方法，通过重新排列位置ID，解决VLMs中高分辨率图像与缩略图、文本与图像间交互...|
|📝 更新|When Are Concepts Erased From Diffusion Models?|当概念从扩散模型中被擦除时？|Kevin Lu, Nicky Kriplani, Rohit Gandikota, Minh Pham, David Bau, Chinmay Hegde, Niv Cohen|<http://arxiv.org/pdf/2505.17013v3>|提出评估方法，揭示扩散模型中概念消除的全面性及其与鲁棒性的权衡。|
|🆕 发布|CoDA: Coordinated Diffusion Noise Optimization for Whole-Body Manipulation of Articulated Objects|协调扩散噪声优化：用于关节对象全身操纵|Huaijin Pi, Zhi Cen, Zhiyang Dou, Taku Komura|<http://arxiv.org/pdf/2505.21437v1>|提出了一种协调扩散噪声优化框架，以实现更精确的人体和物体运动协调。|
|🆕 发布|Video-Holmes: Can MLLM Think Like Holmes for Complex Video Reasoning?|视频霍姆斯：多模态语言模型能否像霍姆斯一样进行复杂视频推理？|Junhao Cheng, Yuying Ge, Teng Wang, Yixiao Ge, Jing Liao, Ying Shan|<http://arxiv.org/pdf/2505.21374v1>|[代码](https://github.com/TencentARC/Video-Holmes.); 设计Video-Holmes基准，评估MLLM在复杂视频推理中的能力，揭示其信息整合和线索识别的不足...|
|📝 更新|Regularized Personalization of Text-to-Image Diffusion Models without Distributional Drift|文本到图像扩散模型的正则化个性化，避免分布漂移|Gihoon Kim, Hyungjin Park, Taesup Kim|<http://arxiv.org/pdf/2505.19519v2>|提出了一种基于Lipschitz约束的文本到图像扩散模型个性化方法，有效控制分布漂移并提升生成质量。|
|📝 更新|Chain-of-Zoom: Extreme Super-Resolution via Scale Autoregression and Preference Alignment|链式缩放：通过尺度自回归和偏好对齐实现极端超分辨率|Bryan Sangwoo Kim, Jeongsol Kim, Jong Chul Ye|<http://arxiv.org/pdf/2505.18600v2>|[代码](https://bryanswkim.github.io/chain-of-zoom); 提出了一种通过多尺度自回归和偏好对齐实现极端超分辨率的新框架，有效解决了现有模型在放大倍数超出训练范...|
|📝 更新|One-Step Residual Shifting Diffusion for Image Super-Resolution via Distillation|一步残差移位扩散通过蒸馏进行图像超分辨率|Daniil Selikhanovych, David Li, Aleksei Leonov, Nikita Gushchin, Sergei Kushneriuk, Alexander Filippov, Evgeny Burnaev, Iaroslav Koshelev .etc.|<http://arxiv.org/pdf/2503.13358v2>|提出RSD方法，通过蒸馏技术提升ResShift图像超分辨率模型，实现高效且高质量的图像恢复。|
|🆕 发布|Normalized Attention Guidance: Universal Negative Guidance for Diffusion Model|标准化注意力引导：扩散模型的通用负引导|Dar-Yen Chen, Hmrishav Bandyopadhyay, Kai Zou, Yi-Zhe Song|<http://arxiv.org/pdf/2505.21179v1>|提出了一种通用的负向引导方法，通过注意力空间外推和L1归一化，有效提升扩散模型在多种场景下的性能。|
|🆕 发布|FastFace: Tuning Identity Preservation in Distilled Diffusion via Guidance and Attention|快速人脸：通过引导和注意力调整蒸馏扩散中的身份保留|Sergey Karpukhin, Vadim Titov, Andrey Kuznetsov, Aibek Alanov|<http://arxiv.org/pdf/2505.21144v1>|提出FastFace框架，通过指导与注意力机制加速身份保留的扩散模型训练。|
|🆕 发布|Learning Single Index Models with Diffusion Priors|学习具有扩散先验的单指数模型|Anqi Tang, Youming Chen, Shuchen Xue, Zhaoqiang Liu|<http://arxiv.org/pdf/2505.21135v1>|提出了一种基于扩散模型的单指数模型信号恢复方法，有效提高了重建信号质量。|
|🆕 发布|RoBiS: Robust Binary Segmentation for High-Resolution Industrial Images|鲁棒二值分割：高分辨率工业图像的鲁棒二值分割|Xurui Li, Zhonesheng Jiang, Tingxuan Ai, Yu Zhou|<http://arxiv.org/pdf/2505.21152v1>|[代码](https://github.com/xrli-U/RoBiS.); 提出RoBiS框架，通过预处理、数据增强和联合自适应二值化，显著提升工业图像异常检测性能。|
|🆕 发布|Differentiable Solver Search for Fast Diffusion Sampling|可微求解器搜索实现快速扩散采样|Shuai Wang, Zexian Li, Qipeng zhang, Tianhui Song, Xubin Li, Tiezheng Ge, Bo Zheng, Limin Wang|<http://arxiv.org/pdf/2505.21114v1>|提出了一种基于可微求解器搜索的快速扩散采样方法，显著提升了扩散模型生成质量。|
|🆕 发布|Red-Teaming Text-to-Image Systems by Rule-based Preference Modeling|基于规则偏好建模的文本到图像系统红队测试|Yichuan Cao, Yibo Miao, Xiao-Shan Gao, Yinpeng Dong|<http://arxiv.org/pdf/2505.21074v1>|提出RPG-RT方法，通过规则化偏好建模引导红队测试，有效评估T2I系统的安全性。|
|🆕 发布|ReassembleNet: Learnable Keypoints and Diffusion for 2D Fresco Reconstruction|重组网络：可学习的关键点和扩散用于二维壁画重建|Adeela Islam, Stefano Fiorini, Stuart James, Pietro Morerio, Alessio Del Bue|<http://arxiv.org/pdf/2505.21117v1>|ReassembleNet通过学习关键点和扩散技术，有效降低重建复杂度，提升2D壁画重构精度。|
|🆕 发布|CityGo: Lightweight Urban Modeling and Rendering with Proxy Buildings and Residual Gaussians|城市行：使用代理建筑和残差高斯的城市建模与渲染|Weihang Liu, Yuhui Zhong, Yuke Li, Xi Chen, Jiadi Cui, Honglong Zhang, Lan Xu, Xin Lou .etc.|<http://arxiv.org/pdf/2505.21041v1>|CityGo通过结合纹理代理几何和残差高斯，实现了轻量级、逼真的大规模城市场景渲染。|
|🆕 发布|FeatInv: Spatially resolved mapping from feature space to input space using conditional diffusion models|FeatInv：基于条件扩散模型的特征空间到输入空间的时空解析映射|Nils Neukirch, Johanna Vielhaben, Nils Strodthoff|<http://arxiv.org/pdf/2505.21032v1>|提出了一种利用条件扩散模型从特征空间到输入空间进行空间解析映射的方法，以提升计算机视觉模型中特征空间...|
|📝 更新|Selftok: Discrete Visual Tokens of Autoregression, by Diffusion, and for Reasoning|自回归扩散推理的离散视觉标记：Selftok|Bohan Wang, Zhongqi Yue, Fengda Zhang, Shuo Chen, Li'an Bi, Junzhe Zhang, Xue Song, Kennard Yanting Chan .etc.|<http://arxiv.org/pdf/2505.07538v3>|[代码](https://selftok-team.github.io/report); Selftok通过引入自回归先验，为视觉语言模型提供了一种高效且简洁的离散视觉标记器，有效解决了视觉...|
|📝 更新|UltraBones100k: A reliable automated labeling method and large-scale dataset for ultrasound-based bone surface extraction|超骨100k：一种可靠的超声骨表面提取自动化标注方法和大规模数据集|Luohong Wu, Nicola A. Cavalcanti, Matthias Seibold, Giuseppe Loggia, Lisa Reissner, Jonas Hein, Silvan Beeler, Arnd Viehöfer .etc.|<http://arxiv.org/pdf/2502.03783v3>|提出UltraBones100k，通过自动标注和大规模数据集，显著提升超声骨表面提取的准确性和完整性...|
|📝 更新|SAIL: Self-supervised Albedo Estimation from Real Images with a Latent Diffusion Model|SAIL：基于潜在扩散模型的从真实图像中进行自监督反照率估计|Hala Djeghim, Nathan Piasco, Luis Roldão, Moussab Bennehar, Dzmitry Tsishkou, Céline Loscos, Désiré Sidibé|<http://arxiv.org/pdf/2505.19751v2>|SAIL通过潜扩散模型和自监督学习，实现了从真实图像中稳定估计反照率。|
|🆕 发布|PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter|PMA：通过点Mamba适配器实现参数高效的点云理解|Yaohua Zha, Yanzi Wang, Hang Guo, Jinpeng Wang, Tao Dai, Bin Chen, Zhihao Ouyang, Xue Yuerong .etc.|<http://arxiv.org/pdf/2505.20941v1>|[代码](https://github.com/zyh16143998882/PMA.); 提出PMA方法，通过融合预训练模型多层级特征，提升点云理解能力。|
|📝 更新|Towards Training One-Step Diffusion Models Without Distillation|迈向无需蒸馏训练一步扩散模型|Mingtian Zhang, Wenlin Chen, Jiajun He, Zijing Ou, José Miguel Hernández-Lobato, Bernhard Schölkopf, David Barber|<http://arxiv.org/pdf/2502.08005v3>|直接训练一步扩散模型，无需蒸馏，通过教师模型权重初始化，提升学生模型性能。|
|🆕 发布|Multitemporal Latent Dynamical Framework for Hyperspectral Images Unmixing|多时相潜在动态框架用于高光谱图像解混|Ruiying Li, Bin Pan, Lan Ma, Xia Xu, Zhenwei Shi|<http://arxiv.org/pdf/2505.20902v1>|提出了一种基于多时相潜动态框架的超光谱图像解混方法，有效捕捉材料动态演化。|
|🆕 发布|Causality-Driven Infrared and Visible Image Fusion|因果驱动红外与可见光图像融合|Linli Ma, Suzhen Lin, Jianchao Zeng, Zanxia Jin, Yanbo Wang, Fengyuan Li, Yubing Luo|<http://arxiv.org/pdf/2505.20830v1>|从因果角度重新审视图像融合，提出BAFFM模块消除干扰，显著提升红外与可见光图像融合性能。|
|🆕 发布|Integrating Intermediate Layer Optimization and Projected Gradient Descent for Solving Inverse Problems with Diffusion Models|融合中间层优化和投影梯度下降以解决扩散模型中的逆问题|Yang Zheng, Wen Li, Zhaoqiang Liu|<http://arxiv.org/pdf/2505.20789v1>|提出DMILO和DMILO-PGD方法，优化扩散模型解决逆问题，提升重建性能。|
|🆕 发布|Uni-Instruct: One-step Diffusion Model through Unified Diffusion Divergence Instruction|统一扩散散度指令一步扩散模型|Yifei Wang, Weimin Bai, Colin Zhang, Debing Zhang, Weijian Luo, He Sun|<http://arxiv.org/pdf/2505.20755v1>|提出Uni-Instruct框架，统一多种一步扩散模型，显著提升生成性能。|
|📝 更新|ACT-R: Adaptive Camera Trajectories for Single View 3D Reconstruction|自适应相机轨迹的单视图3D重建：ACT-R|Yizhi Wang, Mingrui Zhao, Ali Mahdavi-Amiri, Hao Zhang|<http://arxiv.org/pdf/2505.08239v2>|提出自适应相机轨迹规划，有效揭示遮挡并提高单视图3D重建的3D一致性。|
|📝 更新|Restoring Real-World Images with an Internal Detail Enhancement Diffusion Model|使用内部细节增强扩散模型恢复真实世界图像|Peng Xiao, Hongbo Zhao, Yijun Wang, Jianxin Lin|<http://arxiv.org/pdf/2505.18674v2>|提出了一种内部细节增强扩散模型，有效恢复现实世界退化图像并支持对象级色彩控制。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DetailFlow: 1D Coarse-to-Fine Autoregressive Image Generation via Next-Detail Prediction|细节流：通过下一细节预测的1D自回归图像生成|Yiheng Liu, Liao Qu, Huichao Zhang, Xu Wang, Yi Jiang, Yiming Gao, Hu Ye, Xian Li .etc.|<http://arxiv.org/pdf/2505.21473v1>|提出了一种基于细节预测的1D自回归图像生成方法，实现高效且高质量的图像合成。|
|🆕 发布|OmniSync: Towards Universal Lip Synchronization via Diffusion Transformers|全同步：通过扩散变换器实现通用唇同步|Ziqiao Peng, Jiwen Liu, Haoxian Zhang, Xiaoqiang Liu, Songlin Tang, Pengfei Wan, Di Zhang, Hongyan Liu .etc.|<http://arxiv.org/pdf/2505.21448v1>|OmniSync通过Diffusion Transformer模型实现无掩码训练，显著提升唇同步准确...|
|📝 更新|Deepfake-Eval-2024: A Multi-Modal In-the-Wild Benchmark of Deepfakes Circulated in 2024|2024年Deepfake评估：2024年流传的深度伪造的多模态野外基准|Nuria Alina Chandra, Ryan Murtfeldt, Lin Qiu, Arnab Karmakar, Hannah Lee, Emmanuel Tanumihardja, Kevin Farhat, Ben Caffee .etc.|<http://arxiv.org/pdf/2503.02857v4>|[代码](https://github.com/nuriachandra/Deepfake-Eval-2024.); 构建了2024年最新深伪视频音频数据集，揭示了现有检测模型在真实世界中的不足。|
|📝 更新|Towards Generalized Proactive Defense against Face Swapping with Contour-Hybrid Watermark|面向基于轮廓混合水印的泛化主动防御人脸交换|Ruiyang Xia, Dawei Zhou, Decheng Liu, Lin Yuan, Jie Li, Nannan Wang, Xinbo Gao|<http://arxiv.org/pdf/2505.19081v2>|提出了一种基于面部轮廓的混合水印技术，有效防御未知人脸交换攻击。|
|🆕 发布|Sci-Fi: Symmetric Constraint for Frame Inbetweening|科幻：帧插值中的对称约束|Liuhan Chen, Xiaodong Cun, Xiaoyu Li, Xianyi He, Shenghai Yuan, Jie Chen, Ying Shan, Li Yuan|<http://arxiv.org/pdf/2505.21205v1>|Sci-Fi通过引入EF-Net模块，实现起始和结束帧的对称约束，提升视频插帧的连贯性和稳定性。|
|📝 更新|Dual Data Alignment Makes AI-Generated Image Detector Easier Generalizable|双数据对齐使AI生成图像检测器更容易泛化|Ruoxin Chen, Junwei Xi, Zhiyuan Yan, Ke-Yue Zhang, Shuang Wu, Jingyi Xie, Xu Chen, Lei Xu .etc.|<http://arxiv.org/pdf/2505.14359v2>|提出Dual Data Alignment方法，通过像素和频率域对齐，提升AI图像检测器的泛化能力。|
|🆕 发布|Instance Data Condensation for Image Super-Resolution|实例数据压缩用于图像超分辨率|Tianhao Peng, Ho Man Kwan, Yuxuan Jiang, Ge Gao, Fan Zhang, Xiaozhong Xu, Shan Liu, David Bull|<http://arxiv.org/pdf/2505.21099v1>|提出了一种针对图像超分辨率的数据压缩方法，通过实例数据浓缩优化训练效率和稳定性。|
|📝 更新|Training-free Stylized Text-to-Image Generation with Fast Inference|无训练风格化文本到图像生成与快速推理|Xin Ma, Yaohui Wang, Xinyuan Chen, Tien-Tsin Wong, Cunjian Chen|<http://arxiv.org/pdf/2505.19063v2>|提出了一种无需训练的快速风格化文本到图像生成方法，显著提升风格化效果。|
|📝 更新|OpenS2V-Nexus: A Detailed Benchmark and Million-Scale Dataset for Subject-to-Video Generation|OpenS2V-Nexus：面向主题到视频生成的详细基准和百万规模数据集|Shenghai Yuan, Xianyi He, Yufan Deng, Yang Ye, Jinfa Huang, Bin Lin, Chongyang Ma, Jiebo Luo .etc.|<http://arxiv.org/pdf/2505.20292v2>|构建了OpenS2V-Nexus，提供细粒度基准和大规模数据集，推动主体到视频生成研究。|
|📝 更新|SC-Pro: Training-Free Framework for Defending Unsafe Image Synthesis Attack|SC-Pro：无需训练的防御不安全图像合成攻击框架|Junha Park, Jaehui Hwang, Ian Ryu, Hyungkeun Park, Jiyoon Kim, Jong-Seok Lee|<http://arxiv.org/pdf/2501.05359v2>|提出SC-Pro框架，无需训练即可防御生成不安全图像的攻击。|
|🆕 发布|Unpaired Image-to-Image Translation for Segmentation and Signal Unmixing|无配对图像到图像的分割和信号分离翻译|Nikola Andrejic, Milica Spasic, Igor Mihajlovic, Petra Milosavljevic, Djordje Pavlovic, Filip Milisavljevic, Uros Milivojevic, Danilo Delibasic .etc.|<http://arxiv.org/pdf/2505.20746v1>|提出Ui2i模型，通过改进CycleGAN，实现无配对图像风格迁移，同时保持内容完整性。|
|🆕 发布|Scan-and-Print: Patch-level Data Summarization and Augmentation for Content-aware Layout Generation in Poster Design|扫描与打印：海报设计中内容感知布局生成中的补丁级数据摘要与增强|HsiaoYuan Hsu, Yuxin Peng|<http://arxiv.org/pdf/2505.20649v1>|提出Scan-and-Print方法，通过数据摘要和增强，实现海报设计中的内容感知布局生成，大幅提升...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Structure from Collision|从碰撞中重建结构|Takuhiro Kaneko|<http://arxiv.org/pdf/2505.21335v1>|提出了一种从碰撞中重建物体结构的SfC-NeRF模型，有效识别可见和不可见内部结构。|
|🆕 发布|efunc: An Efficient Function Representation without Neural Networks|efunc：一种无需神经网络的效率函数表示|Biao Zhang, Peter Wonka|<http://arxiv.org/pdf/2505.21319v1>|提出了一种无需神经网络的高效函数表示方法，显著降低了参数数量并提升了性能。|
|🆕 发布|DiMoSR: Feature Modulation via Multi-Branch Dilated Convolutions for Efficient Image Super-Resolution|DiMoSR：通过多分支扩张卷积进行特征调制的有效图像超分辨率|M. Akin Yilmaz, Ahmet Bilican, A. Murat Tekalp|<http://arxiv.org/pdf/2505.21262v1>|[代码](https://github.com/makinyilmaz/DiMoSR); DiMoSR通过多分支扩张卷积和特征调制，实现了高效图像超分辨率，提升了重建质量与模型效率的平衡。|
|📝 更新|PLGSLAM: Progressive Neural Scene Represenation with Local to Global Bundle Adjustment|PLGSLAM：基于局部到全局捆绑调整的渐进式神经场景表示|Tianchen Deng, Guole Shen, Tong Qin, Jianyu Wang, Wentao Zhao, Jingchuan Wang, Danwei Wang, Weidong Chen|<http://arxiv.org/pdf/2312.09866v3>|[代码](https://github.com/dtc111111/plgslam.); PLGSLAM通过渐进式场景表示和局部到全局调整，实现了大场景下的高精度视觉SLAM。|
|📝 更新|From Flatland to Space: Teaching Vision-Language Models to Perceive and Reason in 3D|从平面到空间：教导视觉-语言模型感知和推理三维世界|Jiahui Zhang, Yurui Chen, Yanpeng Zhou, Yueming Xu, Ze Huang, Jilin Mei, Junhui Chen, Yu-Jie Yuan .etc.|<http://arxiv.org/pdf/2503.22976v5>|提出了一种利用空间相关图像数据增强视觉语言模型，提升其3D场景理解和推理能力的方法。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Plenodium: UnderWater 3D Scene Reconstruction with Plenoptic Medium Representation|全视域：基于全视场介质表示的水下3D场景重建|Changguanng Wu, Jiangxin Dong, Chengjian Li, Jinhui Tang|<http://arxiv.org/pdf/2505.21258v1>|[代码](https://plenodium.github.io/.); 提出了一种结合全息介质表示和伪深度互补的3D水下场景重建方法，显著提升了重建精度。|
|🆕 发布|3D-UIR: 3D Gaussian for Underwater 3D Scene Reconstruction via Physics-Based Appearance-Medium Decouplin|3D-UIR：基于物理外观-介质解耦的3D水下场景重建的3D高斯|Jieyu Yuan, Yujun Li, Yuanlin Zhang, Chunle Guo, Xiongxin Tang, Ruixing Wang, Chongyi Li|<http://arxiv.org/pdf/2505.21238v1>|[代码](https://bilityniu.github.io/3D-UIR); 提出了一种基于物理建模的3D水下场景重建方法，有效解决了散射介质导致的渲染失真问题。|
|🆕 发布|Occlusion Boundary and Depth: Mutual Enhancement via Multi-Task Learning|遮挡边界与深度：多任务学习下的相互增强|Lintao Xu, Yinghao Wang, Chaohui Wang|<http://arxiv.org/pdf/2505.21231v1>|通过多任务学习联合估计遮挡边界和深度，显著提升了场景理解和3D重建能力。|
|📝 更新|EventEgoHands: Event-based Egocentric 3D Hand Mesh Reconstruction|基于事件的自我中心3D手部网格重建：EventEgoHands|Ryosei Hara, Wataru Ikeda, Masashi Hatano, Mariko Isogawa|<http://arxiv.org/pdf/2505.19169v2>|EventEgoHands通过引入手部分割模块，有效降低动态背景事件影响，显著提升基于事件相机的人体...|
|🆕 发布|Styl3R: Instant 3D Stylized Reconstruction for Arbitrary Scenes and Styles|Styl3R：任意场景和风格的即时3D风格化重建|Peng Wang, Xiang Liu, Peidong Liu|<http://arxiv.org/pdf/2505.21060v1>|Styl3R通过快速利用稀疏视图和风格图像实现3D场景即时风格化，同时保持多视图一致性和风格与场景的...|
|🆕 发布|OmniIndoor3D: Comprehensive Indoor 3D Reconstruction|全室内3D重建：全面室内三维重建|Xiaobao Wei, Xiaoan Zhang, Hao Wang, Qingpo Wuwu, Ming Lu, Wenzhao Zheng, Shanghang Zhang|<http://arxiv.org/pdf/2505.20610v1>|[代码](https://ucwxb.github.io/OmniIndoor3D); OmniIndoor3D提出了一种结合多源RGB-D图像和轻量级MLP的室内3D重建框架，显著提升了...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LazyVLM: Neuro-Symbolic Approach to Video Analytics|懒性视觉语言模型：视频分析的神经符号方法|Xiangru Jian, Wei Pang, Zhengyuan Dong, Chao Zhang, M. Tamer Özsu|<http://arxiv.org/pdf/2505.21459v1>|LazyVLM通过神经符号方法，实现了高效、易用的开放域视频数据分析。|
|🆕 发布|HoliTom: Holistic Token Merging for Fast Video Large Language Models|HoliTom：快速视频大型语言模型的全面令牌合并|Kele Shao, Keda Tao, Can Qin, Haoxuan You, Yang Sui, Huan Wang|<http://arxiv.org/pdf/2505.21334v1>|HoliTom通过结合内外LLM剪枝，实现视频LLM高效压缩，大幅降低计算负担。|
|🆕 发布|Predicting Implicit Arguments in Procedural Video Instructions|预测程序性视频指令中的隐含参数|Anil Batra, Laura Sevilla-Lara, Marcus Rohrbach, Frank Keller|<http://arxiv.org/pdf/2505.21068v1>|提出隐式语义角色标注方法，提升烹饪视频指令理解能力。|
|🆕 发布|Assessing the Use of Face Swapping Methods as Face Anonymizers in Videos|评估视频中使用面部交换方法作为面部匿名化工具的效果|Mustafa İzzet Muştu, Hazım Kemal Ekenel|<http://arxiv.org/pdf/2505.20985v1>|该论文评估了视频中的面部交换方法作为隐私保护工具的有效性。|
|🆕 发布|HuMoCon: Concept Discovery for Human Motion Understanding|HuMoCon：人体运动理解的概念发现|Qihang Fang, Chengcheng Tang, Bugra Tekin, Shugao Ma, Yanchao Yang|<http://arxiv.org/pdf/2505.20920v1>|HuMoCon通过多模态特征提取和速度重建机制，有效解决了运动概念发现难题，显著提升了人类行为分析能...|
|🆕 发布|MUSEG: Reinforcing Video Temporal Understanding via Timestamp-Aware Multi-Segment Grounding|MUSEG：通过时间戳感知多段定位强化视频时间理解|Fuwen Luo, Shengfeng Lou, Chi Chen, Ziyue Wang, Chenliang Li, Weizhou Shen, Jiyue Guo, Peng Li .etc.|<http://arxiv.org/pdf/2505.20715v1>|[代码](https://github.com/THUNLP-MT/MUSEG.); MUSEG通过时间戳感知的多段定位，显著提升了多模态大语言模型对视频事件的细粒度推理能力。|
|🆕 发布|Temporal Saliency-Guided Distillation: A Scalable Framework for Distilling Video Datasets|时间显著性引导的蒸馏：一个用于视频数据集蒸馏的可扩展框架|Xulin Gu, Xinhao Zhong, Zhixing Wei, Yimin Zhou, Shuoyang Sun, Bin Chen, Hongpeng Wang, Yuan Luo|<http://arxiv.org/pdf/2505.20694v1>|提出了一种基于时间显著性引导的视频数据蒸馏框架，有效降低视频数据集的维度并保持时间动态。|
|📝 更新|H2VU-Benchmark: A Comprehensive Benchmark for Hierarchical Holistic Video Understanding|H2VU-Benchmark：一个用于分层整体视频理解的全面基准|Qi Wu, Quanlong Zheng, Yanhao Zhang, Junlin Xie, Jinguo Luo, Kuo Wang, Peng Liu, Qingsong Xie .etc.|<http://arxiv.org/pdf/2503.24008v2>|提出H2VU基准，全面评估视频理解能力，推动多模态模型进步。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VoxAging: Continuously Tracking Speaker Aging with a Large-Scale Longitudinal Dataset in English and Mandarin|VoxAging：利用大规模纵向数据集在英语和普通话中持续跟踪说话人年龄|Zhiqi Ai, Meixuan Bao, Zhiyong Chen, Zhi Yang, Xinnuo Li, Shugong Xu|<http://arxiv.org/pdf/2505.21445v1>|构建大规模纵向数据集，研究并分析说话人年龄变化对语音识别系统的影响。|
|📝 更新|Cognitive Disentanglement for Referring Multi-Object Tracking|认知解耦用于多对象跟踪的指称|Shaofeng Liang, Runwei Guan, Wangwang Lian, Daizong Liu, Xiaolou Sun, Dongming Wu, Yutao Yue, Weiping Ding .etc.|<http://arxiv.org/pdf/2503.11496v4>|提出认知解耦框架，有效融合语言描述与视觉特征，提升多目标跟踪准确率。|
|🆕 发布|Fully Spiking Neural Networks for Unified Frame-Event Object Tracking|全脉冲神经网络用于统一帧事件目标跟踪|Jingjun Yang, Liangwei Fan, Jinpu Zhang, Xiangkai Lian, Hui Shen, Dewen Hu|<http://arxiv.org/pdf/2505.20834v1>|提出了一种融合帧和事件流的脉冲神经网络，实现高效且低功耗的视觉目标跟踪。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SHARDeg: A Benchmark for Skeletal Human Action Recognition in Degraded Scenarios|SHARDeg：退化场景下骨骼人体动作识别基准|Simon Malzard, Nitish Mital, Richard Walters, Victoria Nockles, Raghuveer Rao, Celso M. De Melo|<http://arxiv.org/pdf/2505.18048v2>|构建了首个针对骨骼人体动作识别在退化场景下的基准，并提升了模型对退化数据的鲁棒性。|
|🆕 发布|MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition|MoPFormer：用于可穿戴传感器活动识别的运动原语Transformer|Hao Zhang, Zhan Zhuang, Xuehao Wang, Xiaodong Yang, Yu Zhang|<http://arxiv.org/pdf/2505.20744v1>|MoPFormer通过将传感器信号转化为语义运动原语，并利用Transformer学习丰富的时间表示...|
|🆕 发布|Detecting Informative Channels: ActionFormer|检测信息通道：ActionFormer|Kunpeng Zhao, Asahi Miyazaki, Tsuyoshi Okita|<http://arxiv.org/pdf/2505.20739v1>|提出ActionFormer模型，通过序列和激励策略优化传感器信号处理，显著提升人体活动识别准确率。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Toward Unified Practices in Trajectory Prediction Research on Bird's-Eye-View Datasets|面向鸟瞰视角数据集轨迹预测研究中的统一实践|Theodor Westny, Björn Olofsson, Erik Frisk|<http://arxiv.org/pdf/2405.00604v4>|[代码](https://github.com/westny/dronalize.); 提出统一标准工具箱，简化鸟瞰视角轨迹预测研究比较分析。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Automatically Identify and Rectify: Robust Deep Contrastive Multi-view Clustering in Noisy Scenarios|自动识别与校正：噪声场景下鲁棒的深度对比多视角聚类|Xihong Yang, Siwei Wang, Fangdi Wang, Jiaqi Jin, Suyuan Liu, Yue Liu, En Zhu, Xinwang Liu .etc.|<http://arxiv.org/pdf/2505.21387v1>|[代码](https://github.com/xihongyang1999/AIRMVC); 提出AIRMVC框架，自动识别和校正噪声数据，提升深度多视角聚类在噪声场景下的鲁棒性。|
|📝 更新|SPF-Portrait: Towards Pure Text-to-Portrait Customization with Semantic Pollution-Free Fine-Tuning|SPF-Portrait：迈向语义污染无的纯文本到肖像定制|Xiaole Xian, Zhichao Liao, Qingyu Li, Wenyu Qin, Pengfei Wan, Weicheng Xie, Long Zeng, Linlin Shen .etc.|<http://arxiv.org/pdf/2504.00396v3>|[代码](https://spf-portrait.github.io/SPF-Portrait); 提出SPF-Portrait，通过语义污染-free微调实现纯文本到肖像的定制，显著提升性能。|
|📝 更新|Modality Curation: Building Universal Embeddings for Advanced Multimodal Information Retrieval|模态精炼：构建高级多模态信息检索的通用嵌入|Fanheng Kong, Jingyuan Zhang, Yahui Liu, Hongzhi Zhang, Shi Feng, Xiaocui Yang, Daling Wang, Yu Tian .etc.|<http://arxiv.org/pdf/2505.19650v2>|[代码](https://friedrichor.github.io/projects); 提出UNITE框架，通过数据管理和模态感知训练解决多模态信息检索中的异构数据和跨模态对齐挑战。|
|🆕 发布|AVCD: Mitigating Hallucinations in Audio-Visual Large Language Models through Contrastive Decoding|AVCD：通过对比解码减轻音频-视觉大型语言模型中的幻觉|Chaeyoung Jung, Youngjoon Jang, Joon Son Chung|<http://arxiv.org/pdf/2505.20862v1>|提出AVCD方法，通过对比解码减轻音频-视觉大语言模型中的幻觉问题。|
|🆕 发布|Contrastive Desensitization Learning for Cross Domain Face Forgery Detection|对比去敏感化学习在跨域人脸伪造检测中的应用|Lingyu Qiu, Ke Jiang, Xiaoyang Tan|<http://arxiv.org/pdf/2505.20675v1>|提出了一种基于对比去敏感化学习的跨域人脸伪造检测方法，有效降低误报率。|
|📝 更新|Rebalancing Contrastive Alignment with Learnable Semantic Gaps in Text-Video Retrieval|文本-视频检索中通过可学习语义差距重新平衡对比对齐|Jian Xiao, Zijie Song, Jialong Hu, Hao Cheng, Zhenzhen Hu, Jia Li, Richang Hong|<http://arxiv.org/pdf/2505.12499v3>|提出GARE框架，通过可学习语义差距缓解文本-视频检索中的模态差距和梯度冲突。|
|🆕 发布|Intelligent Incident Hypertension Prediction in Obstructive Sleep Apnea|智能阻塞性睡眠呼吸暂停事件高血压预测|Omid Halimi Milani, Ahmet Enis Cetin, Bharati Prasad|<http://arxiv.org/pdf/2505.20615v1>|该论文提出了一种结合DCT和迁移学习的深度学习方法，提高了OSA患者高血压预测的准确性。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ZigzagPointMamba: Spatial-Semantic Mamba for Point Cloud Understanding|ZigzagPointMamba：用于点云理解的时空语义Mamba|Linshuang Diao, Dayong Ren, Sensen Song, Yurong Qian|<http://arxiv.org/pdf/2505.21381v1>|提出ZigzagPointMamba，通过改进扫描路径和语义掩码策略，提升点云理解性能。|
|🆕 发布|Prostate Cancer Screening with Artificial Intelligence-Enhanced Micro-Ultrasound: A Comparative Study with Traditional Methods|人工智能增强微超声在前列腺癌筛查中的应用：与传统方法的比较研究|Muhammad Imran, Wayne G. Brisbane, Li-Ming Su, Jason P. Joseph, Wei Shao|<http://arxiv.org/pdf/2505.21355v1>|开发AI系统分析前列腺微超声图像，在检测前列腺癌方面优于PSA和指诊，可减少不必要的活检。|
|🆕 发布|MME-Reasoning: A Comprehensive Benchmark for Logical Reasoning in MLLMs|MME-Reasoning：多模态语言模型中逻辑推理的全面基准|Jiakang Yuan, Tianshuo Peng, Yilei Jiang, Yiting Lu, Renrui Zhang, Kaituo Feng, Chaoyou Fu, Tao Chen .etc.|<http://arxiv.org/pdf/2505.21327v1>|构建了MME-Reasoning基准，全面评估MLLMs的逻辑推理能力，揭示其性能局限。|
|🆕 发布|Think Twice, Act Once: Token-Aware Compression and Action Reuse for Efficient Inference in Vision-Language-Action Models|深思熟虑，一次行动：视觉-语言-动作模型中高效推理的token感知压缩和动作重用|Xudong Tan, Yaoxin Yang, Peng Ye, Jialin Zheng, Bizhe Bai, Xinyi Wang, Jia Hao, Tao Chen|<http://arxiv.org/pdf/2505.21200v1>|提出FlashVLA框架，通过动作重用和视觉标记压缩，显著降低视觉-语言-动作模型的推理成本。|
|📝 更新|MetaGS: A Meta-Learned Gaussian-Phong Model for Out-of-Distribution 3D Scene Relighting|元GS：一种用于分布外3D场景重照明的元学习高斯- phong模型|Yumeng He, Yunbo Wang, Xiaokang Yang|<http://arxiv.org/pdf/2405.20791v2>|MetaGS通过元学习和物理先验，有效解决3D场景在未知光照下的重光照问题。|
|📝 更新|Denoising Mutual Knowledge Distillation in Bi-Directional Multiple Instance Learning|双向多实例学习中的去噪互信息蒸馏|Chen Shu, Boyu Fu, Yiman Li, Ting Yin, Wenchuan Zhang, Jie Chen, Yuhao Yi, Hong Bu|<http://arxiv.org/pdf/2505.12074v2>|提出一种融合伪标签校正的MIL算法，提升双向多实例学习在病理图像分类中的性能。|
|🆕 发布|RefAV: Towards Planning-Centric Scenario Mining|RefAV：迈向以规划为中心的场景挖掘|Cainan Davidson, Deva Ramanan, Neehar Peri|<http://arxiv.org/pdf/2505.20981v1>|[代码](https://github.com/CainanD/RefAV); 提出RefAV，通过视觉语言模型检测并定位自动驾驶日志中的复杂场景。|
|📝 更新|Efficient LiDAR Reflectance Compression via Scanning Serialization|高效激光雷达反射率压缩：扫描序列化方法|Jiahao Zhu, Kang You, Dandan Ding, Zhan Ma|<http://arxiv.org/pdf/2505.09433v2>|提出了一种基于序列化的神经网络压缩方法，有效降低LiDAR反射率数据体积。|
|🆕 发布|Beyond Entropy: Region Confidence Proxy for Wild Test-Time Adaptation|超越熵：用于野外观测时自适应的区域置信度代理|Zixuan Hu, Yichun Hu, Xiaotong Li, Shixiang Tang, Ling-Yu Duan|<http://arxiv.org/pdf/2505.20704v1>|提出了一种基于区域信心的WTTA方法，有效提升了模型在极端数据稀缺和多个域变化下的适应效率。|
|🆕 发布|A False Discovery Rate Control Method Using a Fully Connected Hidden Markov Random Field for Neuroimaging Data|基于全连接隐马尔可夫随机场的神经影像数据假发现率控制方法|Taehyo Kim, Qiran Jia, Mony J. de Leon, Hai Shu|<http://arxiv.org/pdf/2505.20688v1>|提出fcHMRF-LIS方法，有效控制神经影像数据中假发现率，提高检测准确性。|
|🆕 发布|IndustryEQA: Pushing the Frontiers of Embodied Question Answering in Industrial Scenarios|工业场景中的具身问答前沿推动：IndustryEQA|Yifan Li, Yuhang Chen, Anh Dao, Lichi Li, Zhongyi Cai, Zhen Tan, Tianlong Chen, Yu Kong|<http://arxiv.org/pdf/2505.20640v1>|构建了首个针对工业场景的EQA基准IndustryEQA，以评估安全关键仓库环境中的智能体能力。|
|🆕 发布|TrustSkin: A Fairness Pipeline for Trustworthy Facial Affect Analysis Across Skin Tone|信任皮肤：跨肤色可信面部情感分析的公平性管道|Ana M. Cabanas, Alma Pedro, Domingo Mery|<http://arxiv.org/pdf/2505.20637v1>|提出了一种公平性管道，通过改进皮肤色调分类方法，提升面部情感分析在不同肤色群体中的公平性。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PointLoRA: Low-Rank Adaptation with Token Selection for Point Cloud Learning|点云学习中的低秩自适应与标记选择：PointLoRA|Song Wang, Xiaolu Liu, Lingdong Kong, Jianyun Xu, Chunyong Hu, Gongfan Fang, Wentong Li, Jianke Zhu .etc.|<http://arxiv.org/pdf/2504.16023v2>|[代码](https://github.com/songw-zju/PointLoRA.); 提出PointLoRA，结合低秩适应和token选择，高效微调点云模型，降低参数需求。|
|🆕 发布|Making Every Event Count: Balancing Data Efficiency and Accuracy in Event Camera Subsampling|让每个事件都算数：在事件相机子采样中平衡数据效率和准确性|Hesam Araghi, Jan van Gemert, Nergis Tomen|<http://arxiv.org/pdf/2505.21187v1>|[代码](https://github.com/hesamaraghi/event-camera-subsampling-methods.); 提出了一种基于事件密度的事件相机降采样方法，有效平衡了数据效率和分类准确率。|
|🆕 发布|LPOI: Listwise Preference Optimization for Vision Language Models|LPOI：视觉语言模型的列表式偏好优化|Fatemeh Pesaran Zadeh, Yoojin Oh, Gunhee Kim|<http://arxiv.org/pdf/2505.21061v1>|[代码](https://github.com/fatemehpesaran310/lpoi.); 提出LPOI，通过对象感知列表优化减少视觉语言模型中的幻觉。|
|📝 更新|Semantic Correspondence: Unified Benchmarking and a Strong Baseline|语义对应：统一基准测试和强大基线|Kaiyan Zhang, Xinghui Li, Jingyi Lu, Kai Han|<http://arxiv.org/pdf/2505.18060v3>|[代码](https://github.com/Visual-AI/Semantic-Correspondence.); 首次全面综述语义对应方法，提出统一基准和高效基线。|
|📝 更新|LIB-KD: Learning Inductive Bias, Not Just Parameters A New Perspective on Knowledge Distillations|LIB-KD：学习归纳偏差，而不仅仅是参数——知识蒸馏的新视角|Gousia Habib, Tausifa Jan Saleem, Ishfaq Ahmad Malik, Brejesh Lall|<http://arxiv.org/pdf/2310.00369v3>|通过结合不同架构倾向的轻量级教师模型，LIB-KD从知识蒸馏中学习归纳偏差，有效提升学生模型性能。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Parameter Efficient Continual Learning with Dynamic Low-Rank Adaptation|参数高效的动态低秩自适应持续学习|Prashant Shivaram Bhat, Shakib Yazdani, Elahe Arani, Bahram Zonooz|<http://arxiv.org/pdf/2505.11998v2>|提出一种动态低秩自适应方法，有效解决持续学习中的灾难性遗忘问题。|
|🆕 发布|RF4D:Neural Radar Fields for Novel View Synthesis in Outdoor Dynamic Scenes|RF4D：用于户外动态场景新颖视图合成的神经雷达场|Jiarui Zhang, Zhihao Li, Chong Wang, Bihan Wen|<http://arxiv.org/pdf/2505.20967v1>|提出RF4D，一种结合雷达和时空建模的神经场框架，显著提升动态户外场景的新视角合成质量。|
|🆕 发布|QwT-v2: Practical, Effective and Efficient Post-Training Quantization|QwT-v2：实用、有效且高效的训练后量化|Ningyuan Tang, Minghao Fu, Hao Yu, Jianxin Wu|<http://arxiv.org/pdf/2505.20932v1>|提出QwT-v2方法，通过轻量级补偿模块有效降低量化参数和延迟，提升精度并兼容现有硬件。|
|🆕 发布|Frequency Composition for Compressed and Domain-Adaptive Neural Networks|频率组成：压缩和域自适应神经网络|Yoojin Kwon, Hongjun Suh, Wooseok Lee, Taesik Gong, Songyi Han, Hyung-Sin Kim|<http://arxiv.org/pdf/2505.20890v1>|提出了一种统一压缩和域适应的频率组成框架，显著提升压缩模型在域变化下的准确率。|
|🆕 发布|Cross from Left to Right Brain: Adaptive Text Dreamer for Vision-and-Language Navigation|从左脑到右脑的跨越：自适应视觉-语言导航的文本梦境生成器|Pingrui Zhang, Yifei Su, Pengyuan Wu, Dong An, Li Zhang, Zhigang Wang, Dong Wang, Yan Ding .etc.|<http://arxiv.org/pdf/2505.20897v1>|[代码](https://github.com/zhangpingrui/Adaptive-Text-Dreamer); 提出自适应文本梦者，通过语言形式想象关键环境语义，实现视觉与语言导航的高效策略。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DSOcc: Leveraging Depth Awareness and Semantic Aid to Boost Camera-Based 3D Semantic Occupancy Prediction|DSOcc：利用深度感知和语义辅助提升基于相机的3D语义占用预测|Naiyu Fang, Zheyuan Zhou, Kang Wang, Ruibo Li, Lemiao Qiu, Shuyou Zhang, Zhe Wang, Guosheng Lin|<http://arxiv.org/pdf/2505.20951v1>|DSOcc通过结合深度感知和语义辅助，提升了基于摄像头的3D语义占用预测的准确性。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Adversarial Attacks against Closed-Source MLLMs via Feature Optimal Alignment|对抗性攻击针对闭源多语言语言模型通过特征最优对齐|Xiaojun Jia, Sensen Gao, Simeng Qin, Tianyu Pang, Chao Du, Yihao Huang, Xinfeng Li, Yiming Li .etc.|<http://arxiv.org/pdf/2505.21494v1>|[代码](https://github.com/jiaxiaojunQAQ/FOA-Attack.); 提出FOA-Attack方法，通过特征最优对齐提升对抗样本对闭源MLLMs的攻击能力。|
|📝 更新|ZeroPur: Succinct Training-Free Adversarial Purification|零净化：简洁的无训练对抗净化|Erhu Liu, Zonglin Yang, Bo Liu, Bin Xiao, Xiuli Bi|<http://arxiv.org/pdf/2406.03143v3>|提出ZeroPur，一种无需训练的对抗净化方法，有效提升对抗攻击防御能力。|
|🆕 发布|ProBA: Probabilistic Bundle Adjustment with the Bhattacharyya Coefficient|概率捆绑调整与Bhattacharyya系数|Jason Chui, Daniel Cremers|<http://arxiv.org/pdf/2505.20858v1>|提出了一种基于概率模型的BA方法，无需初始估计和已知内参，提高了SLAM系统在未知环境中的实用性。|
|🆕 发布|Breaking Dataset Boundaries: Class-Agnostic Targeted Adversarial Attacks|打破数据集边界：类无关的针对性对抗攻击|Taïga Gonçalves, Tomo Miyazaki, Shinichiro Omachi|<http://arxiv.org/pdf/2505.20782v1>|CD-MTA通过图像条件输入和类无关损失，实现了对未见类别的高效跨域多目标对抗攻击。|
|🆕 发布|RoGA: Towards Generalizable Deepfake Detection through Robust Gradient Alignment|RoGA：通过鲁棒梯度对齐实现可泛化深度伪造检测|Lingyu Qiu, Ke Jiang, Xiaoyang Tan|<http://arxiv.org/pdf/2505.20653v1>|[代码](https://github.com/Lynn0925/RoGA.); 提出了一种通过鲁棒梯度对齐增强深度伪造检测模型鲁棒性的新方法。|


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Boosting Adversarial Transferability via High-Frequency Augmentation and Hierarchical-Gradient Fusion|通过高频增强和分层梯度融合提升对抗迁移性|Yayin Zheng, Chen Wan, Zihong Guo, Hailing Kuang, Xiaohai Lu|<http://arxiv.org/pdf/2505.21181v1>|提出FSA框架，结合高频增强和分层梯度融合，有效提升对抗攻击的迁移性。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Multi-Granularity Class Prototype Topology Distillation for Class-Incremental Source-Free Unsupervised Domain Adaptation|多粒度类别原型拓扑蒸馏用于类增量源自由无监督领域自适应|Peihua Deng, Jiehua Zhang, Xichun Sheng, Chenggang Yan, Yaoqi Sun, Ying Fu, Liang Li|<http://arxiv.org/pdf/2411.16064v4>|[代码](https://github.com/dengpeihua/GROTO.); 提出了一种针对无源增量式域自适应问题的多粒度类原型拓扑蒸馏算法，有效转移源知识至目标域。|
|🆕 发布|Unified Alignment Protocol: Making Sense of the Unlabeled Data in New Domains|统一对齐协议：在新领域中对未标记数据进行解读|Sabbir Ahmed, Mamshad Nayeem Rizve, Abdullah Al Arafat, Jacqueline Liu, Rahim Hossain, Mohaiminul Al Nahian, Adnan Siraj Rakin|<http://arxiv.org/pdf/2505.21010v1>|提出统一对齐协议，解决半监督联邦学习中的域偏移问题，提升模型泛化能力。|
|📝 更新|Double Descent Meets Out-of-Distribution Detection: Theoretical Insights and Empirical Analysis on the role of model complexity|双下降与分布外检测相遇：关于模型复杂度作用的理论与实证分析|Mouïn Ben Ammar, David Brellmann, Arturo Mendoza, Antoine Manzanera, Gianni Franchi|<http://arxiv.org/pdf/2411.02184v2>|揭示了模型复杂度与异常检测性能的关系，并提出了一种基于双下降现象的异常检测优化方法。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mentor3AD: Feature Reconstruction-based 3D Anomaly Detection via Multi-modality Mentor Learning|基于多模态导师学习的特征重建3D异常检测：Mentor3AD|Jinbao Wang, Hanzhe Liang, Can Gao, Chenxi Hu, Jie Zhou, Yunkang Cao, Linlin Shen, Weiming Shen|<http://arxiv.org/pdf/2505.21420v1>|提出Mentor3AD，通过多模态导师学习提升3D异常检测性能。|
|🆕 发布|Beyond Accuracy: Uncovering the Role of Similarity Perception and its Alignment with Semantics in Supervised Learning|超越准确性：揭示相似性感知在监督学习中的作用及其与语义的关联|Katarzyna Filus, Mateusz Żarski|<http://arxiv.org/pdf/2505.21338v1>|提出Deep Similarity Inspector框架，揭示深度视觉网络相似性感知与语义相似性对...|
|📝 更新|Plan-R1: Safe and Feasible Trajectory Planning as Language Modeling|Plan-R1：作为语言模型的 安全且可行的轨迹规划|Xiaolong Tang, Meina Kan, Shiguang Shan, Xilin Chen|<http://arxiv.org/pdf/2505.17659v2>|提出Plan-R1，将轨迹规划作为语言建模，显著提升自动驾驶安全性。|
|🆕 发布|Learning Annotation Consensus for Continuous Emotion Recognition|学习连续情感识别的标注共识|Ibrahim Shoer, Engin Erzin|<http://arxiv.org/pdf/2505.21196v1>|提出了一种基于多标注者数据共识网络的方法，有效提升了连续情感识别的准确性。|
|🆕 发布|Topological Deep Learning for Speech Data|拓扑深度学习在语音数据中的应用|Zhiwang Yu|<http://arxiv.org/pdf/2505.21173v1>|设计拓扑感知卷积核，显著提升语音识别网络性能。|
|📝 更新|Efficient Robotic Policy Learning via Latent Space Backward Planning|高效通过潜在空间反向规划进行机器人策略学习|Dongxiu Liu, Haoyi Niu, Zhihao Wang, Jinliang Zheng, Yinan Zheng, Zhonghong Ou, Jianming Hu, Jianxiong Li .etc.|<http://arxiv.org/pdf/2505.06861v2>|提出了一种基于潜在空间反向规划的机器人策略学习方法，有效解决了实时控制和长期任务中的效率和准确性问题...|
|🆕 发布|Stereo Radargrammetry Using Deep Learning from Airborne SAR Images|基于机载SAR图像的深度学习立体雷达测图|Tatsuya Sasayama, Shintaro Ito, Koichi Ito, Takafumi Aoki|<http://arxiv.org/pdf/2505.20876v1>|提出了一种基于深度学习的立体雷达测图法，显著提升了SAR图像的立体测量精度。|
|🆕 发布|MetaSlot: Break Through the Fixed Number of Slots in Object-Centric Learning|MetaSlot：突破对象中心学习中的固定槽位数量|Hongjia Liu, Rongzhen Zhao, Haohan Chen, Joni Pajarinen|<http://arxiv.org/pdf/2505.20772v1>|MetaSlot通过自适应调整槽位数量，提升了基于槽位注意力机制的对象学习性能。|
|🆕 发布|Continual Learning on CLIP via Incremental Prompt Tuning with Intrinsic Textual Anchors|基于增量提示调整和内在文本锚点的CLIP持续学习|Haodong Lu, Xinyu Zhang, Kristen Moore, Jason Xue, Lina Yao, Anton van den Hengel, Dong Gong|<http://arxiv.org/pdf/2505.20680v1>|提出TPPT方法，通过文本原型引导的提示微调，有效解决CLIP模型在持续学习中的遗忘问题。|
|🆕 发布|Supervised Contrastive Learning for Ordinal Engagement Measurement|监督对比学习用于有序参与度测量|Sadaf Safa, Ali Abedi, Shehroz S. Khan|<http://arxiv.org/pdf/2505.20676v1>|提出了一种利用监督对比学习进行学生参与度等级分类的新方法，有效解决虚拟学习环境中学生参与度测量问题。|
|🆕 发布|See through the Dark: Learning Illumination-affined Representations for Nighttime Occupancy Prediction|穿透黑暗：学习用于夜间占用预测的照明亲和表示|Yuan Wu, Zhiqiang Yan, Yigong Zhang, Xiang Li, ian Yang|<http://arxiv.org/pdf/2505.20641v1>|[代码](https://github.com/yanzq95/LIAR); 提出了一种基于光照感知的夜间占用预测框架，显著提升了夜间场景下的预测性能。|
|📝 更新|Few-Shot Learning from Gigapixel Images via Hierarchical Vision-Language Alignment and Modeling|基于层次视觉-语言对齐与建模的吉像素图像小样本学习|Bryan Wong, Jong Woo Kim, Huazhu Fu, Mun Yong Yi|<http://arxiv.org/pdf/2505.17982v2>|[代码](https://github.com/bryanwong17/HiVE-MIL); HiVE-MIL通过构建统一图和动态过滤机制，有效提升了从有限病理数据中学习的能力。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ViewSpatial-Bench: Evaluating Multi-perspective Spatial Localization in Vision-Language Models|视空间基准：评估视觉-语言模型中的多视角空间定位|Dingming Li, Hongxing Li, Zixuan Wang, Yuchen Yan, Hang Zhang, Siqi Chen, Guiyang Hou, Shengpei Jiang .etc.|<http://arxiv.org/pdf/2505.21500v1>|构建了ViewSpatial-Bench基准，提升视觉语言模型在多视角空间定位识别上的性能。|
|🆕 发布|Visual Product Graph: Bridging Visual Products And Composite Images For End-to-End Style Recommendations|视觉产品图：连接视觉产品和合成图像以实现端到端风格推荐|Yue Li Du, Ben Alexander, Mikhail Antonenka, Rohan Mahadev, Hao-yu Wu, Dmitry Kislyuk|<http://arxiv.org/pdf/2505.21454v1>|构建视觉产品图，实现风格化推荐，提升视觉搜索系统语义相似但视觉差异内容检索能力。|
|📝 更新|ClearSight: Visual Signal Enhancement for Object Hallucination Mitigation in Multimodal Large language Models|清晰视界：多模态大型语言模型中对象幻觉缓解的视觉信号增强|Hao Yin, Guangzong Si, Zilei Wang|<http://arxiv.org/pdf/2503.13107v2>|提出VAF技术，增强视觉信号，有效减少多模态大语言模型中的幻觉，同时保持生成内容连贯性和准确性。|
|📝 更新|Corrupted but Not Broken: Understanding and Mitigating the Negative Impacts of Corrupted Data in Visual Instruction Tuning|损坏但未破碎：理解并减轻视觉指令微调中损坏数据的负面影响|Yunhao Gou, Hansi Yang, Zhili Liu, Kai Chen, Yihan Zeng, Lanqing Hong, Zhenguo Li, Qun Liu .etc.|<http://arxiv.org/pdf/2502.12635v3>|提出了一种应对视觉指令微调中数据损坏问题的鲁棒训练范式，显著提升模型性能。|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Can Large Language Models Understand Symbolic Graphics Programs?|大型语言模型能否理解符号图形程序？|Zeju Qiu, Weiyang Liu, Haiwen Feng, Zhen Liu, Tim Z. Xiao, Katherine M. Collins, Joshua B. Tenenbaum, Adrian Weller .etc.|<http://arxiv.org/pdf/2408.08313v4>|提出了一种评估大型语言模型在理解符号图形程序方面能力的新方法，并通过符号指令微调提升了其推理能力。|
|🆕 发布|MME-VideoOCR: Evaluating OCR-Based Capabilities of Multimodal LLMs in Video Scenarios|MME-VideoOCR：评估多模态大型语言模型在视频场景下的OCR能力|Yang Shi, Huanqian Wang, Wulin Xie, Huanyao Zhang, Lijie Zhao, Yi-Fan Zhang, Xinfeng Li, Chaoyou Fu .etc.|<http://arxiv.org/pdf/2505.21333v1>|构建MME-VideoOCR基准，评估多模态LLMs在视频OCR中的能力，揭示其局限性与重要性。|
|🆕 发布|CROP: Contextual Region-Oriented Visual Token Pruning|CROP：基于上下文区域导向的视觉标记剪枝|Jiawei Guo, Feifei Zhai, Pu Jian, Qianrun Wei, Yu Zhou|<http://arxiv.org/pdf/2505.21233v1>|CROP通过定位和剪枝，有效压缩视觉标记，提升VQA性能。|
|📝 更新|Towards Visuospatial Cognition via Hierarchical Fusion of Visual Experts|通过视觉专家分层融合实现视觉空间认知|Qi Feng|<http://arxiv.org/pdf/2505.12363v2>|通过融合视觉专家和大规模数据集，ViCA2显著提升了视觉空间认知能力。|
|📝 更新|Minimal Interaction Separated Tuning: A New Paradigm for Visual Adaptation|最小交互分离调优：视觉适应的新范式|Ningyuan Tang, Minghao Fu, Jianxin Wu|<http://arxiv.org/pdf/2406.17559v3>|提出MIST方法，通过分离调优和轻量级适配网络，有效解决低资源设备上视觉模型微调难题。|
|🆕 发布|TACO: Think-Answer Consistency for Optimized Long-Chain Reasoning and Efficient Data Learning via Reinforcement Learning in LVLMs|TACO：基于LVLMs的优化长链推理和高效数据学习中的思考-回答一致性强化学习|Zhehan Kan, Yanlin Liu, Kun Yin, Xinghua Jiang, Xin Li, Haoyu Cao, Yinsong Liu, Deqiang Jiang .etc.|<http://arxiv.org/pdf/2505.20777v1>|提出TACO算法，通过强化学习优化长链推理和高效数据学习，解决视觉推理中的不一致性和低效率问题。|
|🆕 发布|VLM Can Be a Good Assistant: Enhancing Embodied Visual Tracking with Self-Improving Visual-Language Models|视觉语言模型可以作为好助手：通过自改进视觉语言模型增强具身视觉跟踪|Kui Wu, Shuhang Xu, Hao Chen, Churan Wang, Zhoujun Li, Yizhou Wang, Fangwei Zhong|<http://arxiv.org/pdf/2505.20718v1>|提出一种结合视觉语言模型和自我改进机制的框架，显著提升主动视觉跟踪在复杂环境中的恢复能力。|
|🆕 发布|Hierarchical Instruction-aware Embodied Visual Tracking|分层指令感知具身视觉跟踪|Kui Wu, Hao Chen, Churan Wang, Fakhri Karray, Zhoujun Li, Yizhou Wang, Fangwei Zhong|<http://arxiv.org/pdf/2505.20710v1>|提出HIEVT方法，通过语义空间目标桥接指令理解与动作生成，提升视觉跟踪的鲁棒性和泛化能力。|
|📝 更新|NoisyRollout: Reinforcing Visual Reasoning with Data Augmentation|噪声回滚：通过数据增强强化视觉推理|Xiangyan Liu, Jinjie Ni, Zijian Wu, Chao Du, Longxu Dou, Haonan Wang, Tianyu Pang, Michael Qizhe Shieh|<http://arxiv.org/pdf/2504.13055v3>|NoisyRollout通过混合不同视觉感知轨迹，有效增强视觉语言模型推理能力。|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|WildDoc: How Far Are We from Achieving Comprehensive and Robust Document Understanding in the Wild?|WildDoc：我们离实现野外全面且鲁棒的文档理解还有多远？|An-Lan Wang, Jingqun Tang, Liao Lei, Hao Feng, Qi Liu, Xiang Fei, Jinghui Lu, Han Wang .etc.|<http://arxiv.org/pdf/2505.11015v2>|[代码](https://bytedance.github.io/WildDoc.); WildDoc提出首个针对真实场景文档理解的基准，揭示现有模型在复杂环境下的不足。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Active-O3: Empowering Multimodal Large Language Models with Active Perception via GRPO|主动-O3：通过GRPO赋能多模态大型语言模型以主动感知|Muzhi Zhu, Hao Zhong, Canyu Zhao, Zongze Du, Zheng Huang, Mingyu Liu, Hao Chen, Cheng Zou .etc.|<http://arxiv.org/pdf/2505.21457v1>|提出ACTIVE-O3框架，通过强化学习增强MLLM的主动感知能力，提升多模态任务表现。|
|🆕 发布|YOLO-SPCI: Enhancing Remote Sensing Object Detection via Selective-Perspective-Class Integration|YOLO-SPCI：通过选择性视角-类别集成增强遥感目标检测|Xinyuan Wang, Lian Peng, Xiangcheng Li, Yilin He, KinTak U|<http://arxiv.org/pdf/2505.21370v1>|提出YOLO-SPCI，通过选择性视角-类别集成模块提升遥感图像检测性能。|
|🆕 发布|DisasterM3: A Remote Sensing Vision-Language Dataset for Disaster Damage Assessment and Response|灾害M3：用于灾害损失评估和响应的遥感视觉-语言数据集|Junjue Wang, Weihao Xuan, Heli Qi, Zhihao Liu, Kunyi Liu, Yuhan Wu, Hongruixuan Chen, Jian Song .etc.|<http://arxiv.org/pdf/2505.21089v1>|构建了多灾害、多传感器、多任务的灾害评估视觉语言数据集，提升了灾害相关视觉语言模型性能。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CDPDNet: Integrating Text Guidance with Hybrid Vision Encoders for Medical Image Segmentation|CDPDNet：结合文本引导与混合视觉编码器进行医学图像分割|Jiong Wu, Yang Xing, Boxiao Yu, Wei Shao, Kuang Gong|<http://arxiv.org/pdf/2505.18958v2>|[代码](https://github.com/wujiong-hub/CDPDNet.git.); CDPDNet通过结合文本指导和混合视觉编码器，有效提升了医学图像分割的准确性和泛化能力。|
|📝 更新|Recent Advances in Diffusion Models for Hyperspectral Image Processing and Analysis: A Review|近期在超光谱图像处理与分析中扩散模型的最新进展：综述|Xing Hu, Xiangcheng Liu, Danfeng Hong, Qianqian Duan, Linghua Jiang, Haima Yang, Dawei Zhan|<http://arxiv.org/pdf/2505.11158v2>|该论文提出利用扩散模型解决高光谱图像处理难题，显著提升分析准确性和效率。|
|🆕 发布|Is Hyperbolic Space All You Need for Medical Anomaly Detection?|超曲空间是否是医学异常检测的全部所需？|Alvaro Gonzalez-Jimenez, Simone Lionetti, Ludovic Amruthalingam, Philippe Gottfrois, Fabian Gröger, Marc Pouly, Alexander A. Navarini|<http://arxiv.org/pdf/2505.21228v1>|提出将特征投影到双曲空间，实现医疗异常检测，显著提升检测性能。|
|📝 更新|PUSSM: Point Cloud Upsampling as Implicit Statistical Shape Model|PUSSM：点云上采样作为隐式统计形状模型|Tongxu Zhang, Bei Wang|<http://arxiv.org/pdf/2501.16716v3>|提出了一种基于点云上采样学习形状先验的隐式统计形状模型，显著提升了骨盆结构的重建质量。|
|📝 更新|Exploring Out-of-distribution Detection for Sparse-view Computed Tomography with Diffusion Models|探索基于扩散模型的稀疏视图计算机断层扫描的分布外检测|Ezgi Demircan-Tureyen, Felix Lucka, Tristan van Leeuwen|<http://arxiv.org/pdf/2411.06308v2>|利用扩散模型检测稀疏视图CT重建中的异常数据，提高重建系统的可靠性。|
|📝 更新|Structure-Accurate Medical Image Translation via Dynamic Frequency Balance and Knowledge Guidance|结构精确的医学图像翻译：动态频率平衡与知识引导|Jiahua Xu, Dawei Zhou, Lei Hu, Zaiyi Liu, Nannan Wang, Xinbo Gao|<http://arxiv.org/pdf/2504.09441v2>|提出了一种基于动态频率平衡和知识引导的医学图像翻译方法，有效解决了结构失真问题。|
|🆕 发布|Good Enough: Is it Worth Improving your Label Quality?|足够好：提升标签质量是否值得？|Alexander Jaus, Zdravko Marinov, Constantin Seibold, Simon Reiß, Jens Kleesiek, Rainer Stiefelhagen|<http://arxiv.org/pdf/2505.20928v1>|评估医疗图像分割中标签质量提升的价值，发现低于一定阈值时收益不明显。|
|🆕 发布|The Role of AI in Early Detection of Life-Threatening Diseases: A Retinal Imaging Perspective|人工智能在危及生命疾病早期检测中的作用：视网膜成像视角|Tariq M Khan, Toufique Ahmed Soomro, Imran Razzak|<http://arxiv.org/pdf/2505.20810v1>|该论文提出利用AI和机器学习技术，结合OCT/OCTA和AO技术，实现早期检测生命威胁性疾病，并推动...|
|📝 更新|Auto-nnU-Net: Towards Automated Medical Image Segmentation|自动nnU-Net：迈向自动化医学图像分割|Jannis Becktepe, Leona Hennig, Steffen Oeltze-Jafra, Marius Lindauer|<http://arxiv.org/pdf/2505.16561v3>|[代码](https://github.com/automl/AutoNNUnet.); 提出Auto-nnU-Net，通过自动化超参数优化和架构搜索，显著提升医学图像分割性能并平衡计算资源...|
|📝 更新|HWA-UNETR: Hierarchical Window Aggregate UNETR for 3D Multimodal Gastric Lesion Segmentation|HWA-UNETR：用于3D多模态胃病变分割的层次窗口聚合UNETR|Jiaming Liang, Lihuan Dai, Xiaoqi Sheng, Xiangguang Chen, Chun Yao, Guihua Tao, Qibin Leng, Hongmin Cai .etc.|<http://arxiv.org/pdf/2505.10464v3>|[代码](https://github.com/JeMing-creater/HWA-UNETR.); 提出HWA-UNETR框架，解决3D多模态胃部病变分割难题，显著提升分割准确率。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Robust Video-Based Pothole Detection and Area Estimation for Intelligent Vehicles with Depth Map and Kalman Smoothing|基于深度图和卡尔曼滤波的鲁棒视频路面坑洞检测与面积估计的智能车辆|Dehao Wang, Haohang Zhu, Yiwen Xu, Kaiqi Liu|<http://arxiv.org/pdf/2505.21049v1>|提出了一种结合深度图和卡尔曼滤波的鲁棒视频路面坑洞检测与面积估计方法，显著提升了检测准确性和实用性。|
|📝 更新|DiffVLA: Vision-Language Guided Diffusion Planning for Autonomous Driving|差分VLA：视觉-语言引导的扩散规划用于自动驾驶|Anqing Jiang, Yu Gao, Zhigang Sun, Yiru Wang, Jijun Wang, Jinghao Chai, Qian Cao, Yuweng Heng .etc.|<http://arxiv.org/pdf/2505.19381v2>|DiffVLA通过结合视觉语言模型和稀疏密集扩散策略，有效提升了自动驾驶在复杂场景下的决策性能。|
|🆕 发布|DriveRX: A Vision-Language Reasoning Model for Cross-Task Autonomous Driving|DriveRX：一种用于跨任务自动驾驶的视觉-语言推理模型|Muxi Diao, Lele Yang, Hongbo Yin, Zhexu Wang, Yejie Wang, Daxin Tian, Kongming Liang, Zhanyu Ma|<http://arxiv.org/pdf/2505.20665v1>|提出DriveRX模型，通过结构化推理实现跨任务自动驾驶，提升决策能力。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models|Roboflow100-VL：面向视觉-语言模型的跨域目标检测基准|Peter Robicheaux, Matvei Popov, Anish Madan, Isaac Robinson, Joseph Nelson, Deva Ramanan, Neehar Peri|<http://arxiv.org/pdf/2505.20612v1>|[代码](https://github.com/roboflow/rf100-vl); 构建Roboflow100-VL基准，提升视觉语言模型在罕见类别和任务上的检测能力。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SURDS: Benchmarking Spatial Understanding and Reasoning in Driving Scenarios with Vision Language Models|视觉语言模型在驾驶场景中空间理解和推理的基准测试：SURDS|Xianda Guo, Ruijun Zhang, Yiqun Duan, Yuhang He, Dujun Nie, Wenke Huang, Chenming Zhang, Shuai Liu .etc.|<http://arxiv.org/pdf/2411.13112v3>|[代码](https://github.com/XiandaGuo/Drive-MLLM.); 提出SURDS基准，通过强化学习提升视觉语言模型在驾驶场景中的空间推理能力。|


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Visuospatial Cognitive Assistant|视觉空间认知助手|Qi Feng|<http://arxiv.org/pdf/2505.12312v2>|提出ViCA-7B模型，通过大规模数据集和可解释性研究，显著提升视频空间认知能力。|
|📝 更新|Two Experts Are All You Need for Steering Thinking: Reinforcing Cognitive Effort in MoE Reasoning Models Without Additional Training|仅需两位专家进行引导思考：在不额外训练的情况下，增强MoE推理模型中的认知努力|Mengru Wang, Xingyu Chen, Yue Wang, Zhiwei He, Jiahao Xu, Tian Liang, Qiuzhi Liu, Yunzhi Yao .etc.|<http://arxiv.org/pdf/2505.14681v2>|引入RICE方法，通过强化认知专家，显著提升MoE推理模型的认知效率和推理准确度。|
|📝 更新|Unforgettable Lessons from Forgettable Images: Intra-Class Memorability Matters in Computer Vision|难忘的教训来自易忘的图像：在计算机视觉中，类内可记忆性至关重要|Jie Jing, Qing Lin, Shuangpeng Han, Lucia Schiatti, Yen-Ling Kuo, Mengmi Zhang|<http://arxiv.org/pdf/2412.20761v4>|提出ICMscore评估图像记忆度，揭示记忆度对计算机视觉任务影响。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|diffDemorph: Extending Reference-Free Demorphing to Unseen Faces|diffDemorph：将无参考去畸扩展到未见过的面孔|Nitish Shukla, Arun Ross|<http://arxiv.org/pdf/2505.14527v2>|提出了一种基于扩散模型的通用人脸去变形方法，显著提升了去变形效果和实用性。|
|📝 更新|HA-VLN: A Benchmark for Human-Aware Navigation in Discrete-Continuous Environments with Dynamic Multi-Human Interactions, Real-World Validation, and an Open Leaderboard|HA-VLN：动态多人类交互的离散-连续环境中的人感知导航基准，真实世界验证及公开排行榜|Yifei Dong, Fengyi Wu, Qi He, Heng Li, Minghan Li, Zebang Cheng, Yuxuan Zhou, Jingdong Sun .etc.|<http://arxiv.org/pdf/2503.14229v2>|构建了融合离散-连续环境的感知导航基准，提升了人机交互下的导航能力。|
|📝 更新|UOD: Unseen Object Detection in 3D Point Cloud|UOD：3D点云中的未见物体检测|Hyunjun Choi, Daeho Um, Hawook Jeong|<http://arxiv.org/pdf/2401.03846v2>|提出UOD方法，有效提升3D点云中未见对象检测与分类性能。|

