## [UPDATED!] **2025-05-28** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|3DLLM-Mem: Long-Term Spatial-Temporal Memory for Embodied 3D Large Language Model|3DLLM-Mem：具身3D大型语言模型的长期时空记忆|Wenbo Hu, Yining Hong, Yanjun Wang, Leison Gao, Zibu Wei, Xingcheng Yao, Nanyun Peng, Yonatan Bitton .etc.|<http://arxiv.org/pdf/2505.22657v1>|提出3DLLM-Mem模型，为LLMs在3D环境中实现长期时空记忆和高效推理提供解决方案。|
|🆕 发布|RiverMamba: A State Space Model for Global River Discharge and Flood Forecasting|河蟒：全球河流径流和洪水预报的状态空间模型|Mohamad Hakam Shams Eddin, Yikui Zahng, Stefan Kollet, Juergen Gall|<http://arxiv.org/pdf/2505.22535v1>|RiverMamba通过全局时空建模，提升了全球河流径流和洪水预报的准确性。|
|📝 更新|HumanAesExpert: Advancing a Multi-Modality Foundation Model for Human Image Aesthetic Assessment|人类美学专家：推进多模态基础模型用于人类图像美学评估|Zhichao Liao, Xiaokun Liu, Wenyu Qin, Qingyu Li, Qiulin Wang, Pengfei Wan, Di Zhang, Long Zeng .etc.|<http://arxiv.org/pdf/2503.23907v2>|[代码](https://humanaesexpert.github.io/HumanAesExpert); 开发首个针对人类图像美学评估的数据库和模型，显著提升评估精度。|
|🆕 发布|A Survey on Training-free Open-Vocabulary Semantic Segmentation|无监督开放词汇语义分割综述|Naomi Kombol, Ivan Martinović, Siniša Šegvić|<http://arxiv.org/pdf/2505.22209v1>|该论文综述了无需训练的开源词汇语义分割方法，通过利用现有模型实现高效分类。|
|🆕 发布|Adapting Segment Anything Model for Power Transmission Corridor Hazard Segmentation|适应电力走廊危险区域分割的Segment Anything模型|Hang Chen, Maoyuan Ye, Peng Yang, Haibin He, Juhua Liu, Bo Du|<http://arxiv.org/pdf/2505.22105v1>|[代码](https://github.com/Hhaizee/ELE-SAM.); 提出ELE-SAM模型，有效解决输电走廊危险区域分割难题，显著提升分割精度。|
|🆕 发布|DvD: Unleashing a Generative Paradigm for Document Dewarping via Coordinates-based Diffusion Model|usion: 基于坐标扩散模型的文档去畸变生成范式解耦|Weiguang Zhang, Huangcheng Lu, Maizhen Ning, Xiaowei Huang, Wei Wang, Kaizhu Huang, Qiufeng Wang|<http://arxiv.org/pdf/2505.21975v1>|提出了一种基于坐标扩散模型的文档去扭曲方法，显著提升了文档结构的保留和去扭曲效果。|
|🆕 发布|InfoSAM: Fine-Tuning the Segment Anything Model from An Information-Theoretic Perspective|信息理论视角下对Segment Anything Model的微调：InfoSAM|Yuanhong Zhang, Muyao Yuan, Weizhan Zhang, Tieliang Gong, Wen Wen, Jiangyong Ying, Weijie Shi|<http://arxiv.org/pdf/2505.21920v1>|InfoSAM通过信息理论优化SAM微调，提升其在特定领域性能。|
|🆕 发布|Subspecialty-Specific Foundation Model for Intelligent Gastrointestinal Pathology|针对特定亚专业的智能胃肠病理学基础模型|Lianghui Zhu, Xitong Ling, Minxi Ouyang, Xiaoping Liu, Mingxi Fu, Tian Guan, Fanglei Fu, Xuanyu Wang .etc.|<http://arxiv.org/pdf/2505.21928v1>|开发了一种针对胃肠道病理学的专用基础模型，显著提升了病理诊断和预测的准确性。|
|🆕 发布|CAST: Contrastive Adaptation and Distillation for Semi-Supervised Instance Segmentation|CAST：对比自适应与蒸馏的半监督实例分割|Pardis Taghavi, Tian Liu, Renjie Li, Reza Langari, Zhengzhong Tu|<http://arxiv.org/pdf/2505.21904v1>|CAST通过半监督知识蒸馏，将预训练模型压缩成紧凑专家，实现半监督实例分割。|
|🆕 发布|Vision-Language-Action Model with Open-World Embodied Reasoning from Pretrained Knowledge|开放世界预训练知识中的视觉-语言-动作模型与具身推理|Zhongyi Zhou, Yichen Zhu, Junjie Wen, Chaomin Shen, Yi Xu|<http://arxiv.org/pdf/2505.21906v1>|提出ChatVLA-2模型，通过混合专家和三阶段训练，使VLA模型具备开放世界推理和数学问题解决能力...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spatial Knowledge Graph-Guided Multimodal Synthesis|空间知识图谱引导的多模态合成|Yida Xue, Zhen Bi, Jinnan Yang, Jungang Lou, Huajun Chen, Ningyu Zhang|<http://arxiv.org/pdf/2505.22633v1>|提出SKG2Data，利用空间知识图谱引导多模态数据合成，提升MLLMs的空间感知能力。|
|🆕 发布|A Closer Look at Multimodal Representation Collapse|多模态表示坍缩的深入研究|Abhra Chaudhuri, Anjan Dutta, Tu Bui, Serban Georgescu|<http://arxiv.org/pdf/2505.22483v1>|[代码](https://abhrac.github.io/mmcollapse); 揭示了多模态融合中的模态坍塌现象，并提出通过知识蒸馏和显式基础重分配算法防止其发生。|
|🆕 发布|Advancing Multimodal Reasoning via Reinforcement Learning with Cold Start|通过冷启动强化学习推进多模态推理|Lai Wei, Yuting Li, Kaipeng Zheng, Chen Wang, Yue Wang, Linghe Kong, Lichao Sun, Weiran Huang|<http://arxiv.org/pdf/2505.22334v1>|[代码](https://github.com/waltonfuture/RL-with-Cold-Start.); 通过结合监督微调和强化学习，该论文提升了多模态推理能力，实现了在多模态推理基准上的性能突破。|
|🆕 发布|YH-MINER: Multimodal Intelligent System for Natural Ecological Reef Metric Extraction|YH-MINER：自然生态珊瑚指标提取的多模态智能系统|Mingzhuang Wang, Yvyang Li, Xiyang Zhang, Fei Tan, Qi Shi, Guotao Zhang, Siqi Chen, Yufei Liu .etc.|<http://arxiv.org/pdf/2505.22250v1>|开发YH-MINER系统，利用多模态智能技术高效提取珊瑚礁生态指标。|
|🆕 发布|MObyGaze: a film dataset of multimodal objectification densely annotated by experts|MObyGaze：由专家密集标注的多模态物化电影数据集|Julie Tores, Elisa Ancarani, Lucile Sassatelli, Hui-Yin Wu, Clement Bergman, Lea Andolfi, Victor Ecrement, Remy Sun .etc.|<http://arxiv.org/pdf/2505.22084v1>|构建了MObyGaze数据集，用于量化电影中的性别物化现象，并提出了相应的机器学习任务。|
|🆕 发布|AquaMonitor: A multimodal multi-view image sequence dataset for real-life aquatic invertebrate biodiversity monitoring|AquaMonitor：用于现实生活水生无脊椎动物生物多样性监测的多模态多视角图像序列数据集|Mikko Impiö, Philipp M. Rehsen, Tiina Laamanen, Arne J. Beermann, Florian Leese, Jenni Raitoharju|<http://arxiv.org/pdf/2505.22065v1>|构建首个大规模水生无脊椎动物多模态多视角图像序列数据集，用于评估真实场景下的自动识别方法。|
|📝 更新|Advancing high-fidelity 3D and Texture Generation with 2.5D latents|提升高保真3D和纹理生成的2.5D潜在表示|Xin Yang, Jiantao Lin, Yingjie Xu, Haodong Li, Yingcong Chen|<http://arxiv.org/pdf/2505.21050v2>|提出了一种基于2.5D latents的联合生成框架，有效提升3D几何和纹理生成质量。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Fast 3D point clouds retrieval for Large-scale 3D Place Recognition|快速大规模3D场景识别中的3D点云检索|Chahine-Nicolas Zede, Laurent Carrafa, Valérie Gouet-Brunet|<http://arxiv.org/pdf/2502.21067v2>|提出了一种基于DSI的快速3D点云检索方法，显著提升了大规模3D场景识别的速度和质量。|
|📝 更新|MagicTryOn: Harnessing Diffusion Transformer for Garment-Preserving Video Virtual Try-on|魔幻试穿：利用扩散Transformer实现服装保留的视频虚拟试穿|Guangyuan Li, Siming Zheng, Hao Zhang, Jinwei Chen, Junsheng Luan, Binkai Ou, Lei Zhao, Bo Li .etc.|<http://arxiv.org/pdf/2505.21325v2>|提出MagicTryOn，利用扩散Transformer实现服装保留的视频虚拟试穿，提升时空一致性和...|
|🆕 发布|S2AFormer: Strip Self-Attention for Efficient Vision Transformer|S2AFormer：用于高效视觉Transformer的条带自注意力|Guoan Xu, Wenfeng Huang, Wenjing Jia, Jiamao Li, Guangwei Gao, Guo-Jun Qi|<http://arxiv.org/pdf/2505.22195v1>|提出S2AFormer，通过Strip Self-Attention降低计算量，实现高效视觉Tran...|
|📝 更新|AgriFM: A Multi-source Temporal Remote Sensing Foundation Model for Crop Mapping|农业FM：一种用于作物制图的多元源时序遥感基础模型|Wenyuan Li, Shunlin Liang, Keyan Chen, Yongzhe Chen, Han Ma, Jianglei Xu, Yichuan Ma, Shikang Guan .etc.|<http://arxiv.org/pdf/2505.21357v2>|[代码](https://github.com/flyakon/AgriFM.); 提出AgriFM，一种多源遥感基础模型，有效解决作物映射中时空特征提取问题。|
|📝 更新|Imitating Radiological Scrolling: A Global-Local Attention Model for 3D Chest CT Volumes Multi-Label Anomaly Classification|模拟放射学滚动：一种用于3D胸部CT体积多标签异常分类的全局-局部注意力模型|Theo Di Piazza, Carole Lazarus, Olivier Nempont, Loic Boussel|<http://arxiv.org/pdf/2503.20652v3>|提出CT-Scroll模型，模拟放射科医生浏览3D CT扫描切片时的全局-局部注意力，有效进行多标签...|
|📝 更新|HTMNet: A Hybrid Network with Transformer-Mamba Bottleneck Multimodal Fusion for Transparent and Reflective Objects Depth Completion|HTMNet：一种具有Transformer-Mamba瓶颈多模态融合的透明和反射物体深度补全的混合网络|Guanghu Xie, Yonglong Zhang, Zhiduo Jiang, Yang Liu, Zongwu Xie, Baoshi Cao, Hong Liu|<http://arxiv.org/pdf/2505.20904v2>|提出HTMNet，融合Transformer和Mamba架构，有效解决透明和反光物体深度信息不完整问...|
|🆕 发布|RenderFormer: Transformer-based Neural Rendering of Triangle Meshes with Global Illumination|基于Transformer的三角形网格全局光照神经渲染：RenderFormer|Chong Zeng, Yue Dong, Pieter Peers, Hongzhi Wu, Xin Tong|<http://arxiv.org/pdf/2505.21925v1>|提出了一种基于Transformer的端到端场景渲染方法，实现全局光照效果，无需场景特定训练。|
|🆕 发布|RePaViT: Scalable Vision Transformer Acceleration via Structural Reparameterization on Feedforward Network Layers|RePaViT：通过前馈网络层的结构重参数化实现可扩展视觉Transformer加速|Xuwei Xu, Yang Li, Yudong Chen, Jiajun Liu, Sen Wang|<http://arxiv.org/pdf/2505.21847v1>|[代码](https://github.com/Ackesnal/RePaViT.); 提出了一种通过结构重参数化FFN层加速大规模ViT的方法，显著降低延迟并提升准确率。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ObjectClear: Complete Object Removal via Object-Effect Attention|ObjectClear：基于对象-效果注意力的完整对象去除|Jixin Zhao, Shangchen Zhou, Zhouxia Wang, Peiqing Yang, Chen Change Loy|<http://arxiv.org/pdf/2505.22636v1>|ObjectClear通过引入注意力机制，有效去除物体及其效果，提升背景真实度。|
|🆕 发布|Risk-Sensitive Conformal Prediction for Catheter Placement Detection in Chest X-rays|胸部X光片中的导管放置检测的风险敏感一致预测|Long Hui|<http://arxiv.org/pdf/2505.22496v1>|提出结合多任务学习和风险敏感一致性预测的新方法，提高胸片导管定位检测的准确性和可靠性。|
|🆕 发布|LiDAR Based Semantic Perception for Forklifts in Outdoor Environments|基于激光雷达的室外环境中叉车语义感知|Benjamin Serfling, Hannes Reichert, Lorenzo Bayerlein, Konrad Doll, Kati Radkhah-Lens|<http://arxiv.org/pdf/2505.22258v1>|提出了一种适用于叉车在复杂户外环境中的基于双LiDAR的语义感知框架，提高了动态和静态障碍物的检测与...|
|🆕 发布|Learning A Robust RGB-Thermal Detector for Extreme Modality Imbalance|学习一种针对极端模态不平衡的鲁棒RGB-热成像检测器|Chao Tian, Chao Yang, Guoqing Zhu, Qiang Wang, Zhenyu He|<http://arxiv.org/pdf/2505.22154v1>|提出了一种应对极端模态不平衡的RGB-T检测器，通过自适应调整模态权重和模拟退化数据，增强模型鲁棒性...|
|📝 更新|Cross-Layer Feature Pyramid Transformer for Small Object Detection in Aerial Images|跨层特征金字塔变换器在航空图像中小目标检测中的应用|Zewen Du, Zhenjiang Hu, Guiyu Zhao, Ying Jin, Hongbin Ma|<http://arxiv.org/pdf/2407.19696v2>|[代码](https://github.com/duzw9311/CFPT.); 提出了一种针对空中小目标检测的CFPT网络，通过跨层交互和全局上下文信息提升检测性能。|
|🆕 发布|Prototype Embedding Optimization for Human-Object Interaction Detection in Livestreaming|直播中人类-物体交互检测的原型嵌入优化|Menghui Zhang, Jing Zhang, Lin Chen, Li Zhuo|<http://arxiv.org/pdf/2505.22011v1>|提出PeO-HOI方法，优化原型嵌入以解决直播中人物-物体交互检测的对象偏差问题。|
|🆕 发布|UniTalk: Towards Universal Active Speaker Detection in Real World Scenarios|UniTalk：迈向现实场景中的通用主动说话者检测|Le Thien Phuc Nguyen, Zhuoran Yu, Khoa Quang Nhat Cao, Yuwei Guo, Tu Ho Manh Pham, Tuan Tai Nguyen, Toan Ngo Duc Vo, Lucas Poon .etc.|<http://arxiv.org/pdf/2505.21954v1>|[代码](https://github.com/plnguyen2908/UniTalk-ASD-code); UniTalk提出针对真实场景的通用主动说话者检测，通过新数据集提升模型泛化能力。|
|🆕 发布|LiDARDustX: A LiDAR Dataset for Dusty Unstructured Road Environments|LiDARDustX：用于尘土飞扬的非结构化道路环境的激光雷达数据集|Chenfeng Wei, Qi Wu, Si Zuo, Jiahua Xu, Boyang Zhao, Zeyu Yang, Guotao Xie, Shenhong Wang|<http://arxiv.org/pdf/2505.21914v1>|[代码](https://github.com/vincentweikey/LiDARDustX.); 构建了针对尘土环境下的LiDAR数据集，以评估和改进自动驾驶感知算法。|
|🆕 发布|Cross-DINO: Cross the Deep MLP and Transformer for Small Object Detection|跨DINO：跨越深度MLP和Transformer进行小目标检测|Guiping Cao, Wenjian Huang, Xiangyuan Lan, Jianguo Zhang, Dongmei Jiang, Yaowei Wang|<http://arxiv.org/pdf/2505.21868v1>|[代码](https://github.com/Med-Process/Cross-DINO.); 提出Cross-DINO方法，结合MLP和Transformer，有效提升小目标检测性能。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MultiFormer: A Multi-Person Pose Estimation System Based on CSI and Attention Mechanism|多前体：基于CSI和注意力机制的多人姿态估计系统|Yanyi Qu, Haoyang Ma, Wenhui Xiong|<http://arxiv.org/pdf/2505.22555v1>|MultiFormer通过结合Transformer和注意力机制，有效提升了基于CSI的人体姿态估计...|
|🆕 发布|CADReview: Automatically Reviewing CAD Programs with Error Detection and Correction|CADReview：自动审查CAD程序，包含错误检测与纠正|Jiali Chen, Xusen Hei, HongFei Liu, Yuancheng Wei, Zikun Deng, Jiayuan Xie, Yi Cai, Li Qing|<http://arxiv.org/pdf/2505.22304v1>|提出CADReview，自动检测和纠正CAD程序错误，提升设计审查效率。|
|📝 更新|Semantics-aware Test-time Adaptation for 3D Human Pose Estimation|语义感知的3D人体姿态估计测试时自适应|Qiuxia Lin, Rongyu Chen, Kerui Gu, Angela Yao|<http://arxiv.org/pdf/2502.10724v2>|提出语义感知运动先验，显著提升3D人体姿态估计测试时自适应性能。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Complex Wavelet Mutual Information Loss: A Multi-Scale Loss Function for Semantic Segmentation|复杂小波互信息损失：语义分割的多尺度损失函数|Renhao Lu|<http://arxiv.org/pdf/2502.00563v2>|[代码](https://github.com/lurenhaothu/CWMI); 提出复杂小波互信息损失函数，有效解决语义分割中的尺度问题，提升分割精度。|
|🆕 发布|Universal Domain Adaptation for Semantic Segmentation|通用领域自适应语义分割|Seun-An Choe, Keon-Hee Park, Jinwoo Choi, Gyeong-Moon Park|<http://arxiv.org/pdf/2505.22458v1>|[代码](https://github.com/KU-VGI/UniMAP); 提出UniMAP，解决无类别设置先验知识下的语义分割领域自适应问题。|
|🆕 发布|On Geometry-Enhanced Parameter-Efficient Fine-Tuning for 3D Scene Segmentation|基于几何增强的参数高效微调用于3D场景分割|Liyao Tang, Zhe Chen, Dacheng Tao|<http://arxiv.org/pdf/2505.22444v1>|提出了一种针对3D场景分割的几何增强参数高效微调方法，显著降低训练成本。|
|📝 更新|SLoRD: Structural Low-Rank Descriptors for Shape Consistency in Vertebrae Segmentation|SLoRD：用于脊椎分割形状一致性的结构低秩描述符|Xin You, Yixin Lou, Minghui Zhang, Jie Yang, Yun Gu|<http://arxiv.org/pdf/2407.08555v3>|SLoRD通过结构低秩描述符和轮廓生成网络，有效解决了脊椎分割中的形状一致性问题。|
|📝 更新|DreamMask: Boosting Open-vocabulary Panoptic Segmentation with Synthetic Data|DreamMask：通过合成数据提升开放词汇全景分割|Yuanpeng Tu, Xi Chen, Ser-Nam Lim, Hengshuang Zhao|<http://arxiv.org/pdf/2501.02048v2>|DreamMask通过合成数据增强，显著提升了开放词汇全景分割模型的泛化能力。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PreP-OCR: A Complete Pipeline for Document Image Restoration and Enhanced OCR Accuracy|PreP-OCR：文档图像恢复与增强OCR精度的完整流程|Shuhao Guan, Moule Lin, Cheng Xu, Xinyi Liu, Jinman Zhao, Jiexin Fan, Qi Xu, Derek Greene|<http://arxiv.org/pdf/2505.20429v2>|提出PreP-OCR，结合图像修复和语义OCR校正，显著提升历史文档文本提取准确性。|
|📝 更新|The Impact of the Single-Label Assumption in Image Recognition Benchmarking|图像识别基准测试中单标签假设的影响|Esla Timothy Anzaku, Seyed Amir Mousavi, Arnout Van Messem, Wesley De Neve|<http://arxiv.org/pdf/2412.18409v2>|揭示了单标签评估的局限性，提出多标签评估方法以更准确地评估图像识别模型。|
|🆕 发布|Test-Time Adaptation of Vision-Language Models for Open-Vocabulary Semantic Segmentation|开放词汇语义分割中视觉-语言模型的测试时自适应|Mehrdad Noori, David Osowiechi, Gustavo Adolfo Vargas Hakim, Ali Bahri, Moslem Yazdanpanah, Sahar Dastani, Farzad Beizaee, Ismail Ben Ayed .etc.|<http://arxiv.org/pdf/2505.21844v1>|提出了一种针对开放词汇语义分割的测试时自适应视觉语言模型方法，显著提升了分割效果。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Let Them Talk: Audio-Driven Multi-Person Conversational Video Generation|让他们说话：音频驱动的多人物对话视频生成|Zhe Kong, Feng Gao, Yong Zhang, Zhuoliang Kang, Xiaoming Wei, Xunliang Cai, Guanying Chen, Wenhan Luo|<http://arxiv.org/pdf/2505.22647v1>|提出MultiTalk框架，解决多人物对话视频生成中音频绑定和指令跟随问题。|
|🆕 发布|SPIRAL: Semantic-Aware Progressive LiDAR Scene Generation|螺旋：语义感知的渐进式激光雷达场景生成|Dekai Zhu, Yixuan Hu, Youquan Liu, Dongyue Lu, Lingdong Kong, Slobodan Ilic|<http://arxiv.org/pdf/2505.22643v1>|SPIRAL提出了一种语义感知的激光雷达场景生成模型，同时生成深度、反射图像和语义图，显著提升生成质...|
|📝 更新|Shielded Diffusion: Generating Novel and Diverse Images using Sparse Repellency|屏蔽扩散：利用稀疏排斥生成新颖且多样化的图像|Michael Kirchhof, James Thornton, Louis Béthune, Pierre Ablin, Eugene Ndiaye, Marco Cuturi|<http://arxiv.org/pdf/2410.06025v3>|提出SPELL方法，通过稀疏排斥力增强扩散模型生成多样图像，有效解决图像生成多样性不足问题。|
|🆕 发布|RICO: Improving Accuracy and Completeness in Image Recaptioning via Visual Reconstruction|RICO：通过视觉重建提高图像重述的准确性和完整性|Yuchi Wang, Yishuo Cai, Shuhuai Ren, Sihan Yang, Linli Yao, Yuanxin Liu, Yuanxing Zhang, Pengfei Wan .etc.|<http://arxiv.org/pdf/2505.22613v1>|[代码](https://github.com/wangyuchi369/RICO.); RICO通过视觉重建优化图像重述，显著提升描述准确性和完整性。|
|📝 更新|Preference Adaptive and Sequential Text-to-Image Generation|偏好自适应的顺序文本到图像生成|Ofir Nabati, Guy Tennenholtz, ChihWei Hsu, Moonkyung Ryu, Deepak Ramachandran, Yinlam Chow, Xiang Li, Craig Boutilier|<http://arxiv.org/pdf/2412.10419v2>|设计了一种基于强化学习的自适应多轮交互式文本到图像生成方法，显著提升了用户满意度。|
|🆕 发布|Thinking with Generated Images|思考生成的图像|Ethan Chern, Zhulin Hu, Steffi Chern, Siqi Kou, Jiadi Su, Yan Ma, Zhijie Deng, Pengfei Liu|<http://arxiv.org/pdf/2505.22525v1>|[代码](https://github.com/GAIR-NLP/thinking-with-generated-images.); 提出了一种通过生成图像促进跨模态推理的新方法，显著提升了复杂场景视觉理解能力。|
|🆕 发布|PrismLayers: Open Data for High-Quality Multi-Layer Transparent Image Generative Models|棱镜层：高质量多层透明图像生成模型的开源数据|Junwen Chen, Heyang Jiang, Yanbin Wang, Keming Wu, Ji Li, Chao Zhang, Keiji Yanai, Dong Chen .etc.|<http://arxiv.org/pdf/2505.22523v1>|发布首个多层透明图像数据集，提出无监督生成模型，显著提升透明图像生成质量。|
|🆕 发布|Understanding Adversarial Training with Energy-based Models|基于能量模型的对抗训练理解|Mujtaba Hussain Mirza, Maria Rosaria Briglia, Filippo Bartolucci, Senad Beadini, Giuseppe Lisanti, Iacopo Masi|<http://arxiv.org/pdf/2505.22486v1>|利用能量模型分析对抗训练，提出Delta能量正则化器缓解过拟合，提升鲁棒分类器的生成能力。|
|🆕 发布|ProCrop: Learning Aesthetic Image Cropping from Professional Compositions|ProCrop：从专业构图学习美学图像裁剪|Ke Zhang, Tianyu Ding, Jiachen Jiang, Tianyi Chen, Ilya Zharkov, Vishal M. Patel, Luming Liang|<http://arxiv.org/pdf/2505.22490v1>|ProCrop通过融合专业摄影特征，从专业作品中学习图像裁剪，显著提升裁剪效果。|
|🆕 发布|Self-Reflective Reinforcement Learning for Diffusion-based Image Reasoning Generation|自反强化学习在基于扩散的图像推理生成中的应用|Jiadong Pan, Zhiyuan Ma, Kaiyan Zhang, Ning Ding, Bowen Zhou|<http://arxiv.org/pdf/2505.22407v1>|[代码](https://jadenpan0.github.io/srrl.github.io); 提出SRRL算法，通过反思和迭代生成轨迹，实现基于逻辑推理的图像生成。|
|📝 更新|Inference-Time Scaling for Flow Models via Stochastic Generation and Rollover Budget Forcing|基于随机生成和回滚预算强制的流模型推理时间缩放|Jaihoon Kim, Taehoon Yoon, Jisung Hwang, Minhyuk Sung|<http://arxiv.org/pdf/2503.19385v4>|提出了一种基于SDE和RBF的流模型推理时间缩放方法，显著提升了生成样本质量。|
|🆕 发布|PacTure: Efficient PBR Texture Generation on Packed Views with Visual Autoregressive Models|PacTure：基于视觉自回归模型的打包视图中高效PBR纹理生成|Fan Fei, Jiajun Tang, Fei-Peng Tian, Boxin Shi, Ping Tan|<http://arxiv.org/pdf/2505.22394v1>|PacTure通过引入视图打包和细粒度控制，高效生成高质量PBR纹理，同时提升训练和推理效率。|
|🆕 发布|Identity-Preserving Text-to-Image Generation via Dual-Level Feature Decoupling and Expert-Guided Fusion|身份保持的文本到图像生成：通过双级特征解耦和专家引导融合|Kewen Chen, Xiaobin Hu, Wenqi Ren|<http://arxiv.org/pdf/2505.22360v1>|提出了一种通过双重特征解耦和专家引导融合的文本到图像生成方法，有效提升了图像质量和文本对齐。|
|📝 更新|DIPO: Dual-State Images Controlled Articulated Object Generation Powered by Diverse Data|DIPO：由多样化数据驱动的双态图像控制可动对象生成|Ruiqi Wu, Xinjie Wang, Liu Liu, Chunle Guo, Jiaxiong Qiu, Chongyi Li, Lichao Huang, Zhizhong Su .etc.|<http://arxiv.org/pdf/2505.20460v2>|DIPO通过双态图像输入，有效控制生成可动3D物体，并显著提升复杂可动物体生成性能。|
|🆕 发布|From Controlled Scenarios to Real-World: Cross-Domain Degradation Pattern Matching for All-in-One Image Restoration|从控制场景到真实世界：跨域退化模式匹配的全能图像修复|Junyu Fan, Chuanlin Liao, Yi Lin|<http://arxiv.org/pdf/2505.22284v1>|提出了一种跨域自适应图像修复框架，有效解决真实场景下图像修复性能下降问题。|
|🆕 发布|Q-VDiT: Towards Accurate Quantization and Distillation of Video-Generation Diffusion Transformers|Q-VDiT：迈向视频生成扩散变换器的精确量化和蒸馏|Weilun Feng, Chuanguang Yang, Haotong Qin, Xiangqi Li, Yu Wang, Zhulin An, Libo Huang, Boyu Diao .etc.|<http://arxiv.org/pdf/2505.22167v1>|[代码](https://github.com/cantbebetter2/Q-VDiT.); 提出Q-VDiT，解决视频生成扩散模型量化问题，显著提升场景一致性。|
|🆕 发布|FaceEditTalker: Interactive Talking Head Generation with Facial Attribute Editing|面部属性编辑的交互式说话头像生成|Guanwen Feng, Zhiyuan Ma, Yunan Li, Junwei Jing, Jiahao Yang, Qiguang Miao|<http://arxiv.org/pdf/2505.22141v1>|[代码](https://peterfanfan.github.io/FaceEditTalker); FaceEditTalker提出了一种可控制面部属性编辑的交互式说话头生成方法，显著提升了视频质量和...|
|🆕 发布|What Makes for Text to 360-degree Panorama Generation with Stable Diffusion?|文本到360度全景图生成中的稳定扩散因素是什么？|Jinhong Ni, Chang-Bin Zhang, Qiang Zhang, Jing Zhang|<http://arxiv.org/pdf/2505.22129v1>|揭示了预训练扩散模型在生成360度全景图中的内在机制，并提出UniPano框架实现高效全景生成。|
|📝 更新|VideoAnydoor: High-fidelity Video Object Insertion with Precise Motion Control|视频任意门：具有精确运动控制的超高保真视频对象插入|Yuanpeng Tu, Hao Luo, Xi Chen, Sihui Ji, Xiang Bai, Hengshuang Zhao|<http://arxiv.org/pdf/2501.01427v4>|VideoAnydoor提出了一种高保真视频物体插入方法，通过精确运动控制和细节保留，实现了零样本视...|
|📝 更新|CHATS: Combining Human-Aligned Optimization and Test-Time Sampling for Text-to-Image Generation|CHATS：结合人类对齐优化和测试时采样进行文本到图像生成|Minghao Fu, Guo-Hua Wang, Liangfu Cao, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang|<http://arxiv.org/pdf/2502.12579v2>|CHATS通过结合人类偏好优化和测试时采样，显著提升了文本到图像生成的质量和一致性。|
|🆕 发布|LatentMove: Towards Complex Human Movement Video Generation|潜在移动：迈向复杂人类运动视频生成|Ashkan Taghipour, Morteza Ghahremani, Mohammed Bennamoun, Farid Boussaid, Aref Miri Rekavandi, Zinuo Li, Qiuhong Ke, Hamid Laga|<http://arxiv.org/pdf/2505.22046v1>|提出LatentMove框架，有效生成复杂人类动作视频，提升I2V生成质量。|
|📝 更新|ORIGEN: Zero-Shot 3D Orientation Grounding in Text-to-Image Generation|ORIGEN：文本到图像生成中的零样本3D姿态定位|Yunhong Min, Daehyeon Choi, Kyeongmin Yeo, Jihyun Lee, Minhyuk Sung|<http://arxiv.org/pdf/2503.22194v2>|ORIGEN提出了一种零样本方法，通过奖励引导采样实现3D方向定位，提升文本到图像生成中多物体和多样...|
|🆕 发布|GL-PGENet: A Parameterized Generation Framework for Robust Document Image Enhancement|GL-PGENet：一种鲁棒文档图像增强的参数化生成框架|Zhihong Tang, Yang Li|<http://arxiv.org/pdf/2505.22021v1>|GL-PGENet通过结合全局和局部参数化生成，实现了高效且鲁棒的文档图像增强。|
|📝 更新|SageAttention2++: A More Efficient Implementation of SageAttention2|智慧注意力2++：SageAttention2的更高效实现|Jintao Zhang, Xiaoming Xu, Jia Wei, Haofeng Huang, Pengle Zhang, Chendong Xiang, Jun Zhu, Jianfei Chen|<http://arxiv.org/pdf/2505.21136v2>|[代码](https://github.com/thu-ml/SageAttention.); 提出SageAttention2++，通过FP8 Matmul加速，实现高效注意力机制，提升模型处理...|
|📝 更新|SoPo: Text-to-Motion Generation Using Semi-Online Preference Optimization|SoPo：基于半在线偏好优化的文本到动作生成|Xiaofeng Tan, Hongsong Wang, Xin Geng, Pan Zhou|<http://arxiv.org/pdf/2412.05095v2>|[代码](https://xiaofeng-tan.github.io/projects); SoPo通过半在线偏好优化，有效提升了文本到动作生成的质量和一致性。|
|🆕 发布|Event-based Egocentric Human Pose Estimation in Dynamic Environment|基于事件的自主导航环境下人体姿态估计|Wataru Ikeda, Masashi Hatano, Ryosei Hara, Mariko Isogawa|<http://arxiv.org/pdf/2505.22007v1>|提出了一种基于事件相机的人体姿态估计新方法，有效解决动态环境中的运动模糊和低光照问题。|
|🆕 发布|Learning World Models for Interactive Video Generation|学习用于交互式视频生成的世界模型|Taiye Chen, Xun Hu, Zihan Ding, Chi Jin|<http://arxiv.org/pdf/2505.21996v1>|提出VRAG方法，通过全局状态条件化和视频检索增强，显著降低长期累积误差，提高世界模型时空一致性。|
|🆕 发布|Cross-modal RAG: Sub-dimensional Retrieval-Augmented Text-to-Image Generation|跨模态RAG：子维度检索增强的文本到图像生成|Mengdan Zhu, Senhao Cheng, Guangji Bai, Yifei Zhang, Liang Zhao|<http://arxiv.org/pdf/2505.21956v1>|提出了一种基于子维度检索增强的文本到图像生成方法，有效解决复杂查询的元素检索问题。|
|📝 更新|MIDI: Multi-Instance Diffusion for Single Image to 3D Scene Generation|多实例扩散：单张图像到3D场景生成|Zehuan Huang, Yuan-Chen Guo, Xingqiao An, Yunhan Yang, Yangguang Li, Zi-Xin Zou, Ding Liang, Xihui Liu .etc.|<http://arxiv.org/pdf/2412.03558v2>|MIDI通过多实例扩散模型，实现了从单张图像到3D场景的准确生成。|
|🆕 发布|Higher-Order Group Synchronization|高阶组同步|Adriana L. Duncan, Joe Kileel|<http://arxiv.org/pdf/2505.21932v1>|提出了一种基于超图的高阶群同步方法，有效提高了计算机视觉中的旋转和角度同步精度。|
|📝 更新|CreatiDesign: A Unified Multi-Conditional Diffusion Transformer for Creative Graphic Design|创意设计：一个统一的多条件扩散Transformer用于创意图形设计|Hui Zhang, Dexiang Hong, Maoke Yang, Yutao Cheng, Zhao Zhang, Jie Shao, Xinglong Wu, Zuxuan Wu .etc.|<http://arxiv.org/pdf/2505.19114v2>|提出 CreatiDesign，一种统一的多条件扩散模型，解决创意图形设计中多条件控制难题。|
|📝 更新|ControlTac: Force- and Position-Controlled Tactile Data Augmentation with a Single Reference Image|控制触觉：基于单一参考图像的力与位置控制触觉数据增强|Dongyu Luo, Kelin Yu, Amir-Hossein Shahidzadeh, Cornelia Fermüller, Yiannis Aloimonos, Ruohan Gao|<http://arxiv.org/pdf/2505.20498v2>|[代码](https://dongyuluo.github.io/controltac.); 提出ControlTac，通过单参考图像、接触力和位置控制生成逼真触觉图像，有效提升触觉数据集质量。|
|📝 更新|Eye-See-You: Reverse Pass-Through VR and Head Avatars|眼见为实：反向传递VR与头部虚拟形象|Ankan Dash, Jingyi Gu, Guiling Wang, Chen Chen|<http://arxiv.org/pdf/2505.18869v2>|提出RevAvatar框架，通过AI技术实现VR反向透视，解决VR头显遮挡问题，提升虚拟环境交互体验...|
|🆕 发布|UniMoGen: Universal Motion Generation|通用运动生成：UniMoGen|Aliasghar Khani, Arianna Rampini, Evan Atherton, Bruno Roy|<http://arxiv.org/pdf/2505.21837v1>|UniMoGen通过无骨骼限制的扩散模型，实现了灵活、高效且可控的多样化角色动作生成。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ReLearn: Unlearning via Learning for Large Language Models|ReLearn：通过学习进行去学习的大语言模型|Haoming Xu, Ningyuan Zhao, Liming Yang, Sendong Zhao, Shumin Deng, Mengru Wang, Bryan Hooi, Nay Oo .etc.|<http://arxiv.org/pdf/2502.11190v3>|[代码](https://github.com/zjunlp/unlearn.); ReLearn通过数据增强和微调，有效实现大型语言模型的有目标遗忘，同时保持高质量输出。|
|📝 更新|X-GAN: A Generative AI-Powered Unsupervised Model for Main Vessel Segmentation of Glaucoma Screening|X-GAN：一种基于生成式AI的无监督模型，用于青光眼筛查中的主要血管分割|Cheng Huang, Weizheng Xie, Tsengdar J. Lee, Jui-Kai Wang, Karanjit Kooner, Ning Zhang, Jia Zhang|<http://arxiv.org/pdf/2503.06743v3>|[代码](https://github.com/VikiXie/SatMar8.); 提出X-GAN，一种基于生成对抗网络的血管分割模型，实现无监督的青光眼筛查血管分割。|
|📝 更新|Causality and "In-the-Wild" Video-Based Person Re-ID: A Survey|因果性与“真实场景”视频基础的人体重识别：综述|Md Rashidunnabi, Kailash Hambarde, Hugo Proença|<http://arxiv.org/pdf/2505.20540v2>|该论文探讨了因果推理在视频人物重识别中的应用，以解决传统方法在泛化性上的不足。|
|🆕 发布|Fast Feature Matching of UAV Images via Matrix Band Reduction-based GPU Data Schedule|基于矩阵带宽缩减的GPU数据调度实现无人机图像快速特征匹配|San Jiang, Kan You, Wanshou Jiang, Qingquan Li|<http://arxiv.org/pdf/2505.22089v1>|提出了一种基于矩阵带缩减的GPU数据调度算法，显著提升了无人机图像特征匹配效率。|
|🆕 发布|Efficiently Enhancing General Agents With Hierarchical-categorical Memory|高效利用分层分类记忆增强通用智能体|Changze Qiao, Mingming Lu|<http://arxiv.org/pdf/2505.22006v1>|提出EHC，一种无需参数更新的通用智能体，通过分层分类记忆和经验学习，高效处理复杂多模态任务。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Tell me Habibi, is it Real or Fake?|告诉我，哈比比，这是真的还是假的？|Kartik Kuckreja, Parul Gupta, Injy Hamed, Thamar Solorio, Muhammad Haris Khan, Abhinav Dhall|<http://arxiv.org/pdf/2505.22581v1>|构建首个大规模阿拉伯-英语音频-视觉深度伪造数据集，解决多语言混合带来的检测难题。|
|📝 更新|A Plug-and-Play Method for Guided Multi-contrast MRI Reconstruction based on Content/Style Modeling|基于内容/风格建模的引导多对比度MRI重建的即插即用方法|Chinmay Rao, Matthias van Osch, Nicola Pezzotti, Jeroen de Bresser, Laurens Beljaards, Jakob Meineke, Elwin de Weerdt, Huangling Lu .etc.|<http://arxiv.org/pdf/2409.13477v3>|提出了一种基于内容/风格建模的插件式多对比度MRI重建方法，有效解决了数据集不足问题并提高了重建质量...|
|📝 更新|Hunyuan-Game: Industrial-grade Intelligent Game Creation Model|hunyuan-Game：工业级智能游戏创作模型|Ruihuang Li, Caijin Zhou, Shoujian Zheng, Jianxiang Lu, Jiabin Huang, Comi Chen, Junshu Tang, Guangzheng Xu .etc.|<http://arxiv.org/pdf/2505.14135v2>|Hunyuan-Game通过构建图像和视频生成模型，实现高质量游戏内容的高效创作。|
|📝 更新|OpenS2V-Nexus: A Detailed Benchmark and Million-Scale Dataset for Subject-to-Video Generation|OpenS2V-Nexus：面向主题到视频生成的详细基准和百万规模数据集|Shenghai Yuan, Xianyi He, Yufan Deng, Yang Ye, Jinfa Huang, Bin Lin, Jiebo Luo, Li Yuan|<http://arxiv.org/pdf/2505.20292v3>|构建了OpenS2V-Nexus，为Subject-to-Video生成提供详细基准和大规模数据集，...|
|🆕 发布|SridBench: Benchmark of Scientific Research Illustration Drawing of Image Generation Model|SridBench：图像生成模型科学研究插图绘制基准|Yifan Chang, Yukang Feng, Jianwen Sun, Jiaxin Ai, Chuanhao Li, S. Kevin Zhou, Kaipeng Zhang|<http://arxiv.org/pdf/2505.22126v1>|构建了首个科学插图生成基准SridBench，评估AI在生成准确科学图像方面的能力。|
|🆕 发布|RESOUND: Speech Reconstruction from Silent Videos via Acoustic-Semantic Decomposed Modeling|RESOUND：通过声学-语义分解建模从静默视频中重建语音|Long-Khanh Pham, Thanh V. T. Tran, Minh-Tan Pham, Van Nguyen|<http://arxiv.org/pdf/2505.22024v1>|提出RESOUND，通过声学-语义分解模型从无声视频中重建语音，提升语音合成准确性和自然度。|
|🆕 发布|PanoWan: Lifting Diffusion Video Generation Models to 360° with Latitude/Longitude-aware Mechanisms|PanoWan：利用经纬度感知机制将扩散视频生成模型提升至360°|Yifei Xia, Shuchen Weng, Siqi Yang, Jingqi Liu, Chengxuan Zhu, Minggui Teng, Zijian Jia, Han Jiang .etc.|<http://arxiv.org/pdf/2505.22016v1>|PanoWan通过引入纬度感知机制和旋转语义降噪，有效提升了全景视频生成质量。|
|🆕 发布|AlignGen: Boosting Personalized Image Generation with Cross-Modality Prior Alignment|AlignGen：通过跨模态先验对齐提升个性化图像生成|Yiheng Lin, Shifang Zhao, Ting Liu, Xiaochao Qu, Luoqi Liu, Yao Zhao, Yunchao Wei|<http://arxiv.org/pdf/2505.21911v1>|AlignGen通过跨模态先验对齐机制，有效解决个性化图像生成中提示与参考图像不匹配问题，提升生成效...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ImageReFL: Balancing Quality and Diversity in Human-Aligned Diffusion Models|图像ReFL：在人类对齐的扩散模型中平衡质量和多样性|Dmitrii Sorokin, Maksim Nakhodnov, Andrey Kuznetsov, Aibek Alanov|<http://arxiv.org/pdf/2505.22569v1>|[代码](https://github.com/ControlGenAI/ImageReFL); ImageReFL通过结合生成和引入多种正则化器，在保持图像质量的同时显著提升多样性。|
|🆕 发布|PathFL: Multi-Alignment Federated Learning for Pathology Image Segmentation|路径联邦学习：病理图像分割的多对齐联邦学习|Yuan Zhang, Feng Chen, Yaolei Qi, Guanyu Yang, Huazhu Fu|<http://arxiv.org/pdf/2505.22522v1>|PathFL通过多级对齐策略，有效解决病理图像分割中的数据异构性问题，提升模型性能和泛化能力。|
|🆕 发布|Surf2CT: Cascaded 3D Flow Matching Models for Torso 3D CT Synthesis from Skin Surface|Surf2CT：基于皮肤表面的胸廓3D CT合成的级联3D流匹配模型|Siyeop Yoon, Yujin Oh, Pengfei Jin, Sifan Song, Matthew Tivnan, Dufan Wu, Xiang Li, Quanzheng Li|<http://arxiv.org/pdf/2505.22511v1>|Surf2CT通过外部表面扫描和简单人口数据生成真实人体胸腔3D CT图像，实现非侵入式内部解剖成像...|
|📝 更新|Latent Beam Diffusion Models for Decoding Image Sequences|潜在光束扩散模型用于解码图像序列|Guilherme Fernandes, Vasco Ramos, Regev Cohen, Idan Szpektor, João Magalhães|<http://arxiv.org/pdf/2503.20429v2>|提出了一种基于潜空间探索的图像序列生成方法，显著提升了视觉连贯性和文本对齐。|
|🆕 发布|Cascaded 3D Diffusion Models for Whole-body 3D 18-F FDG PET/CT synthesis from Demographics|级联3D扩散模型用于从人口统计数据中合成全身3D 18-F FDG PET/CT|Siyeop Yoon, Sifan Song, Pengfei Jin, Matthew Tivnan, Yujin Oh, Sekeun Kim, Dufan Wu, Xiang Li .etc.|<http://arxiv.org/pdf/2505.22489v1>|提出了一种从人口统计学变量生成高保真3D PET/CT图像的级联3D扩散模型框架，解决了临床和研究应...|
|🆕 发布|Unsupervised Post-Training for Multi-Modal LLM Reasoning via GRPO|无监督后训练通过GRPO实现的多模态LLM推理|Lai Wei, Yuting Li, Chen Wang, Yue Wang, Linghe Kong, Weiran Huang, Lichao Sun|<http://arxiv.org/pdf/2505.22453v1>|[代码](https://github.com/waltonfuture/MM-UPT.); 提出MM-UPT框架，利用GRPO算法实现无监督后训练，显著提升多模态LLM推理能力。|
|🆕 发布|Zooming from Context to Cue: Hierarchical Preference Optimization for Multi-Image MLLMs|从上下文到线索的缩放：多图像MLLMs的分层偏好优化|Xudong Li, Mengdan Zhang, Peixian Chen, Xiawu Zheng, Yan Zhang, Jingyuan Zheng, Yunhang Shen, Ke Li .etc.|<http://arxiv.org/pdf/2505.22396v1>|提出CcDPO框架，通过上下文到线索的多级偏好优化，有效减少多图像MLLMs的幻觉问题。|
|📝 更新|Beyond External Monitors: Enhancing Transparency of Large Language Models for Easier Monitoring|超越外部监控器：提升大型语言模型透明度以实现更易监控|Guanxu Chen, Dongrui Liu, Tao Luo, Lijie Hu, Jing Shao|<http://arxiv.org/pdf/2502.05242v2>|提出TELLME方法，提升大型语言模型透明度，便于监测其潜在思维过程。|
|🆕 发布|Frugal Incremental Generative Modeling using Variational Autoencoders|节俭的增量生成模型：基于变分自编码器|Victor Enescu, Hichem Sahbi|<http://arxiv.org/pdf/2505.22408v1>|提出一种基于VAEs的无重放增量学习模型，有效缓解灾难性遗忘并大幅降低内存需求。|
|🆕 发布|DAM: Domain-Aware Module for Multi-Domain Dataset Condensation|领域感知模块：多域数据集压缩的领域感知模块|Jaehyun Choi, Gyojin Han, Dong-Jae Lee, Sunghyun Baek, Junmo Kim|<http://arxiv.org/pdf/2505.22387v1>|提出了一种针对多域数据集的领域感知模块，有效提升了数据压缩和模型泛化能力。|
|🆕 发布|Task-Driven Implicit Representations for Automated Design of LiDAR Systems|基于任务驱动的激光雷达系统自动化设计隐式表示|Nikhil Behari, Aaron Young, Akshat Dave, Ramesh Raskar|<http://arxiv.org/pdf/2505.22344v1>|提出了一种基于任务驱动的隐式表示方法，实现自动化的激光雷达系统设计。|
|📝 更新|AKRMap: Adaptive Kernel Regression for Trustworthy Visualization of Cross-Modal Embeddings|自适应核回归：跨模态嵌入的可信可视化|Yilin Ye, Junchao Huang, Xingchen Zeng, Jiazhi Xia, Wei Zeng|<http://arxiv.org/pdf/2505.14664v2>|[代码](https://github.com/yilinye/AKRMap.); AKRMap通过自适应核回归，提高了跨模态嵌入的可信可视化准确性。|
|🆕 发布|Large-Area Fabrication-aware Computational Diffractive Optics|大面积制造感知计算衍射光学|Kaixuan Wei, Hector A. Jimenez-Romero, Hadi Amata, Jipeng Sun, Qiang Fu, Felix Heide, Wolfgang Heidrich|<http://arxiv.org/pdf/2505.22313v1>|提出了一种基于直接写光刻和纳米压印的大面积衍射光学设计方法，实现从模拟到实际制造的无缝优化。|
|🆕 发布|Domain Adaptation of Attention Heads for Zero-shot Anomaly Detection|领域自适应的注意力头用于零样本异常检测|Kiyoon Jeong, Jaehyuk Heo, Junyeong Son, Pilsung Kang|<http://arxiv.org/pdf/2505.22259v1>|提出HeadCLIP，通过域适应提升零样本异常检测性能。|
|🆕 发布|StateSpaceDiffuser: Bringing Long Context to Diffusion World Models|状态空间扩散器：将长上下文引入扩散世界模型|Nedko Savov, Naser Kazemi, Deheng Zhang, Danda Pani Paudel, Xi Wang, Luc Van Gool|<http://arxiv.org/pdf/2505.22246v1>|StateSpaceDiffuser通过整合状态空间模型，为扩散模型带来长期记忆，显著提升视觉一致性...|
|🆕 发布|Physics-inspired Generative AI models via real hardware-based noisy quantum diffusion|受物理启发的基于真实硬件噪声量子扩散的生成式AI模型|Marco Parigi, Stefano Martina, Francesco Aldo Venturelli, Filippo Caruso|<http://arxiv.org/pdf/2505.22193v1>|提出利用真实量子硬件噪声的物理启发式协议，提升生成模型性能。|
|🆕 发布|Improving Brain-to-Image Reconstruction via Fine-Grained Text Bridging|通过细粒度文本桥接改进脑到图像重建|Runze Xia, Shuo Feng, Renzhi Wang, Congchi Yin, Xuyun Wen, Piji Li|<http://arxiv.org/pdf/2505.22150v1>|提出了一种利用细粒度文本作为桥梁的脑到图像重建方法，有效提升了重建图像的细节和语义一致性。|
|📝 更新|UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control|统一扩散桥框架：基于随机最优控制的统一数据库|Kaizhen Zhu, Mokai Pan, Yuexin Ma, Yanwei Fu, Jingyi Yu, Jingya Wang, Ye Shi|<http://arxiv.org/pdf/2502.05749v4>|[代码](https://github.com/UniDB-SOC/UniDB); 提出UniDB，通过随机最优控制统一扩散桥框架，显著提升图像细节保留和输出质量。|
|🆕 发布|Autoregression-free video prediction using diffusion model for mitigating error propagation|无自回归的扩散模型视频预测以减轻误差传播|Woonho Ko, Jin Bok Park, Il Yong Chun|<http://arxiv.org/pdf/2505.22111v1>|提出ARFree视频预测框架，利用扩散模型避免误差传播，提升长期视频预测性能。|
|📝 更新|Diffusion Models as Cartoonists: The Curious Case of High Density Regions|扩散模型作为卡通画家：高密度区域的奇特案例|Rafał Karczewski, Markus Heinonen, Vikas Garg|<http://arxiv.org/pdf/2411.01293v4>|[代码](https://github.com/Aalto-QuML/high-density-diffusion.); 提出了一种追踪扩散模型高密度区域的理论方法，并设计了高效采样器生成卡通风格图像。|
|🆕 发布|UAVPairs: A Challenging Benchmark for Match Pair Retrieval of Large-scale UAV Images|无人机对：大规模无人机图像匹配对检索的挑战性基准|Junhuan Liu, San Jiang, Wei Ge, Wei Huang, Bingxuan Guo, Qingquan Li|<http://arxiv.org/pdf/2505.22098v1>|[代码](https://github.com/json87/UAVPairs.); 构建了大规模无人机图像匹配对检索基准数据集UAVPairs，并提出高效训练方法，显著提升检索精度。|
|📝 更新|Enhancing Target-unspecific Tasks through a Features Matrix|通过特征矩阵增强目标非特异性任务|Fangming Cui, Yonggang Zhang, Xuan Wang, Xinmei Tian, Jun Yu|<http://arxiv.org/pdf/2505.03414v4>|提出特征矩阵方法，有效提升模型在非特定目标任务上的泛化能力。|
|🆕 发布|Guess the Age of Photos: An Interactive Web Platform for Historical Image Age Estimation|猜照片年龄：一个用于历史图像年龄估计的交互式网络平台|Hasan Yucedag, Adam Jatowt|<http://arxiv.org/pdf/2505.22031v1>|构建了一个互动式网页平台，通过游戏化方式提高历史照片年代估计的准确性和用户参与度。|
|🆕 发布|D-Fusion: Direct Preference Optimization for Aligning Diffusion Models with Visually Consistent Samples|D-Fusion：直接偏好优化以对齐扩散模型与视觉一致样本|Zijing Hu, Fengda Zhang, Kun Kuang|<http://arxiv.org/pdf/2505.22002v1>|D-Fusion通过构建视觉一致样本，有效解决扩散模型生成图像与文本提示不匹配问题。|
|🆕 发布|One-Way Ticket:Time-Independent Unified Encoder for Distilling Text-to-Image Diffusion Models|单向通行证：用于文本到图像扩散模型的独立时间统一编码器|Senmao Li, Lei Wang, Kai Wang, Tao Liu, Jiehang Xie, Joost van de Weijer, Fahad Shahbaz Khan, Shiqi Yang .etc.|<http://arxiv.org/pdf/2505.21960v1>|提出了一种时间无关统一编码器TiUE，有效提升T2I扩散模型推理速度和图像质量。|
|📝 更新|Integrating Intermediate Layer Optimization and Projected Gradient Descent for Solving Inverse Problems with Diffusion Models|融合中间层优化和投影梯度下降以解决扩散模型中的逆问题|Yang Zheng, Wen Li, Zhaoqiang Liu|<http://arxiv.org/pdf/2505.20789v2>|提出DMILO和DMILO-PGD方法，优化扩散模型解决逆问题，提升重建性能。|
|🆕 发布|Hyperspectral Gaussian Splatting|高光谱高斯喷溅|Sunil Kumar Narayanan, Lingjun Zhao, Lu Gan, Yongsheng Chen|<http://arxiv.org/pdf/2505.21890v1>|提出HS-GS方法，结合3D高斯分层与扩散模型，实现高光谱场景的3D显式重建和全光谱范围的新颖视图合...|
|📝 更新|CityGo: Lightweight Urban Modeling and Rendering with Proxy Buildings and Residual Gaussians|城市行：使用代理建筑和残差高斯的城市建模与渲染|Weihang Liu, Yuhui Zhong, Yuke Li, Xi Chen, Jiadi Cui, Honglong Zhang, Lan Xu, Xin Lou .etc.|<http://arxiv.org/pdf/2505.21041v2>|CityGo通过结合纹理代理几何和残差高斯，实现了轻量级、逼真的大规模城市场景渲染。|
|🆕 发布|EPiC: Efficient Video Camera Control Learning with Precise Anchor-Video Guidance|EPiC：基于精确锚点-视频引导的高效视频摄像头控制学习|Zun Wang, Jaemin Cho, Jialu Li, Han Lin, Jaehong Yoon, Yue Zhang, Mohit Bansal|<http://arxiv.org/pdf/2505.21876v1>|EPiC通过自动构建高质量锚视频，实现高效且精确的视频相机控制学习，无需昂贵的相机轨迹标注。|
|🆕 发布|FPAN: Mitigating Replication in Diffusion Models through the Fine-Grained Probabilistic Addition of Noise to Token Embeddings|FPAN：通过向标记嵌入添加细粒度概率噪声减轻扩散模型中的复制|Jingqi Xu, Chenghao Li, Yuke Zhang, Peter A. Beerel|<http://arxiv.org/pdf/2505.21848v1>|提出FPAN方法，通过向词嵌入添加概率性噪声，有效降低扩散模型中的数据复制问题。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multipath cycleGAN for harmonization of paired and unpaired low-dose lung computed tomography reconstruction kernels|多路径cycleGAN用于配对和非配对低剂量肺计算机断层扫描重建核的和谐化|Aravind R. Krishnan, Thomas Z. Li, Lucas W. Remedios, Michael E. Kim, Chenyu Gao, Gaurav Rudravaram, Elyssa M. McMaster, Adam M. Saunders .etc.|<http://arxiv.org/pdf/2505.22568v1>|提出了一种多路径循环GAN模型，用于和谐配对和非配对低剂量肺CT重建核，以改善肺气肿量化并保持解剖准...|
|🆕 发布|RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network|RC-AutoCalib：一种端到端雷达-摄像头自动校准网络|Van-Tin Luu, Yon-Lin Cai, Vu-Hoang Tran, Wei-Chen Chiu, Yi-Ting Chen, Ching-Chun Huang|<http://arxiv.org/pdf/2505.22427v1>|[代码](https://github.com/nycu-acm/RC-AutoCalib.); 提出了一种基于多视角融合和跨模态匹配的雷达-摄像头自动校准网络，有效解决了数据稀疏和测量不确定性问题...|
|📝 更新|EventEgoHands: Event-based Egocentric 3D Hand Mesh Reconstruction|基于事件的自我中心3D手部网格重建：EventEgoHands|Ryosei Hara, Wataru Ikeda, Masashi Hatano, Mariko Isogawa|<http://arxiv.org/pdf/2505.19169v3>|EventEgoHands通过引入手部分割模块，有效减轻动态背景事件影响，显著提升了基于事件相机的人...|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Can NeRFs See without Cameras?|《NeRFs能否无需相机即可“看见”？》|Chaitanya Amballa, Sattwik Basu, Yu-Lin Wei, Zhijian Yang, Mehmet Ergezer, Romit Roy Choudhury|<http://arxiv.org/pdf/2505.22441v1>|通过改进NeRFs，使其能够从多路径信号中学习，从而实现无摄像头环境感知。|
|🆕 发布|Learning Fine-Grained Geometry for Sparse-View Splatting via Cascade Depth Loss|通过级联深度损失学习稀疏视图分层贴图精细几何|Wenjun Lu, Haodong Chen, Anqi Yi, Yuk Ying Chung, Zhiyong Wang, Kun Hu|<http://arxiv.org/pdf/2505.22279v1>|通过引入层次深度引导的分层渲染方法，显著提升了稀疏视角下的三维重建质量。|
|📝 更新|Human-Object Interaction via Automatically Designed VLM-Guided Motion Policy|通过自动设计的VLM引导的运动策略实现人-物交互|Zekai Deng, Ye Shi, Kaiyang Ji, Lan Xu, Shaoli Huang, Jingya Wang|<http://arxiv.org/pdf/2503.18349v2>|[代码](https://vlm-rmd.github.io/.); 该论文提出了一种利用视觉语言模型自动设计运动策略的HOI合成框架，有效提升了交互动作的自然性和多样性...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UP-SLAM: Adaptively Structured Gaussian SLAM with Uncertainty Prediction in Dynamic Environments|自适应结构高斯SLAM：动态环境中的不确定性预测|Wancai Zheng, Linlin Ou, Jiajie He, Libo Zhou, Xinyi Yu, Yan Wei|<http://arxiv.org/pdf/2505.22335v1>|[代码](https://aczheng-cai.github.io/up_slam.github.io); UP-SLAM通过并行框架和自适应结构化高斯SLAM，实现了动态环境中的实时定位与建图，并提高了鲁棒...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PRISM: Video Dataset Condensation with Progressive Refinement and Insertion for Sparse Motion|PRISM：基于渐进式细化与插入的稀疏运动视频数据集压缩|Jaehyun Choi, Jiwan Hur, Gyojin Han, Jaemyung Yu, Junmo Kim|<http://arxiv.org/pdf/2505.22564v1>|PRISM通过渐进式优化和插入，实现了视频数据集的压缩，同时保持动作的动态性和性能。|
|🆕 发布|Universal Visuo-Tactile Video Understanding for Embodied Interaction|通用视觉触觉视频理解以实现具身交互|Yifan Xie, Mingyang Li, Shoujie Li, Xingting Li, Guangyu Chen, Fei Ma, Fei Richard Yu, Wenbo Ding|<http://arxiv.org/pdf/2505.22566v1>|提出VTV-LLM，首个跨模态大语言模型，实现触觉视频理解，提升人机交互直觉性。|
|🆕 发布|Scaling-up Perceptual Video Quality Assessment|感知视频质量评估的规模化|Ziheng Jia, Zicheng Zhang, Zeyu Zhang, Yingji Liang, Xiaorong Zhu, Chunyi Li, Jinliang Han, Haoning Wu .etc.|<http://arxiv.org/pdf/2505.22543v1>|提出OmniVQA框架，通过大规模数据增强和互补训练策略，显著提升视频质量评估性能。|
|🆕 发布|Fostering Video Reasoning via Next-Event Prediction|通过下一事件预测促进视频推理|Haonan Wang, Hongfu Liu, Xiangyan Liu, Chao Du, Kenji Kawaguchi, Ye Wang, Tianyu Pang|<http://arxiv.org/pdf/2505.22457v1>|提出next-event prediction任务，利用未来视频片段促进视频输入的MLLM时间推理能...|
|📝 更新|HoliTom: Holistic Token Merging for Fast Video Large Language Models|HoliTom：快速视频大型语言模型的全面令牌合并|Kele Shao, Keda Tao, Can Qin, Haoxuan You, Yang Sui, Huan Wang|<http://arxiv.org/pdf/2505.21334v2>|HoliTom通过结合内外LLM剪枝策略，实现视频LLM高效压缩，大幅降低计算负担。|
|🆕 发布|GoMatching++: Parameter- and Data-Efficient Arbitrary-Shaped Video Text Spotting and Benchmarking|GoMatching++：参数和数据高效的任意形状视频文本检测与基准测试|Haibin He, Jing Zhang, Maoyuan Ye, Juhua Liu, Bo Du, Dacheng Tao|<http://arxiv.org/pdf/2505.22228v1>|[代码](https://github.com/Hxyz-123/GoMatching.); GoMatching++通过轻量级跟踪器和重评分机制，将图像文本检测器高效转化为视频文本检测器，显著...|
|📝 更新|FocusChat: Text-guided Long Video Understanding via Spatiotemporal Information Filtering|聚焦聊天：通过时空信息过滤实现文本引导的长视频理解|Zheng Cheng, Rendong Wang, Zhicheng Wang|<http://arxiv.org/pdf/2412.12833v2>|FocusChat通过文本引导和时空信息过滤，有效提升了长视频理解能力。|
|📝 更新|Deep Video Discovery: Agentic Search with Tool Use for Long-form Video Understanding|深度视频发现：用于长视频理解的代理搜索与工具使用|Xiaoyi Zhang, Zhaoyang Jia, Zongyu Guo, Jiahao Li, Bin Li, Houqiang Li, Yan Lu|<http://arxiv.org/pdf/2505.18079v2>|提出了一种利用代理搜索策略和工具使用来提升长视频理解的深度视频发现方法。|
|🆕 发布|Detecting Cultural Differences in News Video Thumbnails via Computational Aesthetics|通过计算美学检测新闻视频缩略图中的文化差异|Marvin Limpijankit, John Kender|<http://arxiv.org/pdf/2505.21912v1>|提出了一种通过计算美学检测新闻视频缩略图中文化差异的方法。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes|鼠标锁箱数据集：解决锁箱的鼠标行为识别|Patrik Reiske, Marcus N. Boon, Niek Andresen, Sole Traverso, Katharina Hohlbaum, Lars Lewejohann, Christa Thöne-Reineke, Olaf Hellwich .etc.|<http://arxiv.org/pdf/2505.15408v2>|构建了Mouse Lockbox数据集，用于识别小鼠解决机械锁盒行为的动作分类。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Base and Exponent Prediction in Mathematical Expressions using Multi-Output CNN|基于多输出CNN的数学表达式基数和指数预测|Md Laraib Salam, Akash S Balsaraf, Gaurav Gupta, Ashish Rajeshwar Kulkarni|<http://arxiv.org/pdf/2407.14967v2>|提出了一种简化高效的CNN模型，准确预测数学表达式的底数和指数。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Single Domain Generalization for Alzheimer's Detection from 3D MRIs with Pseudo-Morphological Augmentations and Contrastive Learning|基于伪形态学增强和对比学习的阿尔茨海默病3D MRI检测的单域泛化|Zobia Batool, Huseyin Ozkan, Erchan Aptoula|<http://arxiv.org/pdf/2505.22465v1>|[代码](https://github.com/zobia111/SDG-Alzheimer.); 提出了一种结合伪形态学增强和对比学习的单域泛化方法，有效提升了阿尔茨海默病检测的泛化能力。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Sherlock: Self-Correcting Reasoning in Vision-Language Models|Sherlock：视觉-语言模型中的自纠正推理|Yi Ding, Ruqi Zhang|<http://arxiv.org/pdf/2505.22651v1>|Sherlock通过自纠正策略提升视觉语言模型推理能力，实现少样本数据下的自我改进。|
|🆕 发布|Neural Restoration of Greening Defects in Historical Autochrome Photographs Based on Purely Synthetic Data|基于纯合成数据的绿色缺陷神经修复：历史自动着色照片|Saptarshi Neil Sinha, P. Julius Kuehn, Johannes Koppe, Arjan Kuijper, Michael Weinmann|<http://arxiv.org/pdf/2505.22291v1>|提出了一种基于合成数据生成和改进损失函数的自动修复历史照片绿色缺陷的方法。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|An Effective Training Framework for Light-Weight Automatic Speech Recognition Models|一种轻量级自动语音识别模型的有效训练框架|Abdul Hannan, Alessio Brutti, Shah Nawaz, Mubashir Noman|<http://arxiv.org/pdf/2505.16991v2>|提出一种高效的两步表示学习方法，从大型模型生成多个小型模型，显著提升轻量级语音识别模型性能。|
|🆕 发布|Synonymous Variational Inference for Perceptual Image Compression|同义变分推理在感知图像压缩中的应用|Zijian Liang, Kai Niu, Changshuo Wang, Jin Xu, Ping Zhang|<http://arxiv.org/pdf/2505.22438v1>|提出基于同义词关系的SVI方法，优化感知图像压缩，实现高效压缩与感知质量平衡。|
|🆕 发布|STDR: Spatio-Temporal Decoupling for Real-Time Dynamic Scene Rendering|时空解耦实时动态场景渲染|Zehao Li, Hao Jiang, Yujun Cai, Jianing Chen, Baolong Bi, Shuqin Gao, Honglong Zhao, Yiwei Wang .etc.|<http://arxiv.org/pdf/2505.22400v1>|提出STDR模块，通过时空解耦提高动态场景重建的时空一致性。|
|🆕 发布|Real-Time Blind Defocus Deblurring for Earth Observation: The IMAGIN-e Mission Approach|实时地球观测盲去焦去模糊：IMAGIN-e任务方法|Alejandro D. Mousist|<http://arxiv.org/pdf/2505.22128v1>|针对地球观测图像的盲去模糊，提出了一种适应空间边缘计算的实时去模糊方法。|
|🆕 发布|Balanced Token Pruning: Accelerating Vision Language Models Beyond Local Optimization|平衡Token剪枝：超越局部优化的视觉语言模型加速|Kaiyuan Li, Xiaoyue Chen, Chen Gao, Yong Li, Xinlei Chen|<http://arxiv.org/pdf/2505.22038v1>|提出Balanced Token Pruning方法，有效平衡剪枝对局部和全局输出的影响，加速视觉语...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization|PS4PRO：用于逼真渲染和优化的像素级监督|Yezhi Shen, Qiuchen Zhai, Fengqing Zhu|<http://arxiv.org/pdf/2505.22616v1>|提出PS4PRO模型，通过视频帧插值增强数据，提升神经渲染在复杂场景下的重建质量。|
|📝 更新|SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge Refinement|SynWorld：用于代理行动知识精炼的虚拟场景合成|Runnan Fang, Xiaobin Wang, Yuan Liang, Shuofei Qiao, Jialong Wu, Zekun Xi, Ningyu Zhang, Yong Jiang .etc.|<http://arxiv.org/pdf/2504.03561v2>|[代码](https://github.com/zjunlp/SynWorld.); SynWorld通过合成虚拟场景和MCTS探索，帮助智能体在未知环境中优化行动知识。|
|🆕 发布|NFR: Neural Feature-Guided Non-Rigid Shape Registration|神经特征引导的非刚性形状配准|Puhua Jiang, Zhangquan Chen, Mingze Sun, Ruqi Huang|<http://arxiv.org/pdf/2505.22445v1>|提出了一种结合神经网络特征的非刚性形状配准方法，无需对应标注即可实现高精度配准。|
|📝 更新|Variational Positive-incentive Noise: How Noise Benefits Models|变分正激励噪声：噪声如何使模型受益|Hongyuan Zhang, Sida Huang, Yubin Guo, Xuelong Li|<http://arxiv.org/pdf/2306.07651v2>|提出了一种基于变分推理的噪声优化方法，通过引入VPN增强模型性能。|
|🆕 发布|Neural Face Skinning for Mesh-agnostic Facial Expression Cloning|神经网络驱动的网格无关面部表情克隆|Sihun Cha, Serin Yoon, Kwanggyoon Seo, Junyong Noh|<http://arxiv.org/pdf/2505.22416v1>|提出了一种结合全局和局部变形模型的方法，实现跨不同面部网格的精确表情克隆。|
|🆕 发布|Learning to Infer Parameterized Representations of Plants from 3D Scans|学习从3D扫描中推断植物参数化表示|Samara Ghrer, Christophe Godin, Stefanie Wuhrer|<http://arxiv.org/pdf/2505.22337v1>|提出了一种从3D扫描中推断植物参数化表示的方法，实现植物重建、分割和骨架提取等任务。|
|🆕 发布|Progressive Data Dropout: An Embarrassingly Simple Approach to Faster Training|渐进式数据丢弃：一种令人尴尬简单的快速训练方法|Shriram M S, Xinyue Hao, Shihao Hou, Yang Lu, Laura Sevilla-Lara, Anurag Arnab, Shreyank N Gowda|<http://arxiv.org/pdf/2505.22342v1>|[代码](https://github.com/bazyagami/LearningWithRevision); 提出渐进式数据丢弃法，大幅减少训练时间并提升模型精度。|
|📝 更新|Interpreting CLIP with Hierarchical Sparse Autoencoders|利用分层稀疏自编码器解释CLIP|Vladimir Zaigrajew, Hubert Baniecki, Przemyslaw Biecek|<http://arxiv.org/pdf/2502.20578v2>|[代码](https://github.com/WolodjaZ/MSAE.); 提出Matryoshka稀疏自编码器，优化CLIP模型的可解释性和控制性。|
|📝 更新|Dual-Head Knowledge Distillation: Enhancing Logits Utilization with an Auxiliary Head|双头知识蒸馏：通过辅助头增强对logits的利用|Penghui Yang, Chen-Chen Zong, Sheng-Jun Huang, Lei Feng, Bo An|<http://arxiv.org/pdf/2411.08937v2>|[代码](https://github.com/penghui-yang/DHKD.); 提出了一种双头知识蒸馏方法，通过分离损失函数，有效利用logits信息，提升模型性能。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Training Free Stylized Abstraction|训练自由风格抽象|Aimon Rahman, Kartik Narayan, Vishal M. Patel|<http://arxiv.org/pdf/2505.22663v1>|提出了一种无需训练的图像风格化抽象生成框架，通过视觉语言模型和跨域流逆变换实现风格化抽象。|
|🆕 发布|A2Seek: Towards Reasoning-Centric Benchmark for Aerial Anomaly Understanding|A2Seek：面向空中异常理解推理中心基准|Mengjingcheng Mo, Xinyang Tong, Jiaxu Leng, Mingpi Tan, Jiankang Zheng, Yiran Liu, Haosheng Chen, Ji Gan .etc.|<http://arxiv.org/pdf/2505.21962v1>|[代码](https://hayneyday.github.io/A2Seek); 构建了A2Seek数据集，提出A2Seek-R1框架，提升无人机异常检测准确性和定位精度。|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Deep Learning-Based BMD Estimation from Radiographs with Conformal Uncertainty Quantification|基于深度学习的X光片骨密度估计与正则化不确定性量化|Long Hui, Wai Lok Yeung|<http://arxiv.org/pdf/2505.22551v1>|提出了一种利用膝部X光片进行骨密度估计的深度学习方法，并实现了可靠的置信区间估计。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Rethinking Gradient-based Adversarial Attacks on Point Cloud Classification|重新思考基于梯度的点云分类对抗攻击|Jun Chen, Xinke Li, Mingyue Xu, Tianrui Li, Chongshou Li|<http://arxiv.org/pdf/2505.21854v1>|提出改进的加权梯度策略，有效提升点云分类对抗攻击的隐蔽性和有效性。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Zero-Shot Vision Encoder Grafting via LLM Surrogates|基于LLM代理的零样本视觉编码器嫁接|Kaiyu Yue, Vasu Singla, Menglin Jia, John Kirchenbauer, Rifaa Qadri, Zikui Cai, Abhinav Bhatele, Furong Huang .etc.|<http://arxiv.org/pdf/2505.22664v1>|通过构建共享嵌入空间的小型“代理模型”，实现了视觉编码器的零样本移植，显著降低了视觉语言模型训练成本...|
|🆕 发布|3D Question Answering via only 2D Vision-Language Models|仅通过2D视觉语言模型进行3D问答|Fengyun Wang, Sicheng Yu, Jiawei Wu, Jinhui Tang, Hanwang Zhang, Qianru Sun|<http://arxiv.org/pdf/2505.22143v1>|提出cdViews，通过自动选择关键且多样化的2D视图，实现仅用2D视觉语言模型解决3D问答问题。|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SAM-R1: Leveraging SAM for Reward Feedback in Multimodal Segmentation via Reinforcement Learning|SAM-R1：利用SAM在多模态分割中通过强化学习实现奖励反馈|Jiaqi Huang, Zunnan Xu, Jun Zhou, Ting Liu, Yicheng Xiao, Mingwen Ou, Bowen Ji, Xiu Li .etc.|<http://arxiv.org/pdf/2505.22596v1>|提出SAM-R1，通过强化学习赋予多模态大模型图像分割的推理能力。|
|📝 更新|Automating tumor-infiltrating lymphocyte assessment in breast cancer histopathology images using QuPath: a transparent and accessible machine learning pipeline|利用QuPath自动评估乳腺癌组织病理学图像中的肿瘤浸润淋巴细胞：一个透明且易于访问的机器学习流程|Masoud Tafavvoghi, Lars Ailo Bongo, André Berli Delgado, Nikita Shvetsov, Anders Sildnes, Line Moi, Lill-Tove Rasmussen Busund, Kajsa Møllersen|<http://arxiv.org/pdf/2504.16979v2>|开发了一种基于QuPath的自动化乳腺癌病理图像中肿瘤浸润淋巴细胞评估的机器学习流程，提高了病理诊断...|
|📝 更新|CLIP-MoE: Towards Building Mixture of Experts for CLIP with Diversified Multiplet Upcycling|CLIP-MoE：迈向具有多样化多重升级的CLIP混合专家构建|Jihai Zhang, Xiaoye Qu, Tong Zhu, Yu Cheng|<http://arxiv.org/pdf/2409.19291v3>|提出CLIP-MoE模型，通过多模型融合和高效微调，提升CLIP在多模态任务中的性能。|
|📝 更新|Stereo Radargrammetry Using Deep Learning from Airborne SAR Images|基于机载SAR图像的深度学习立体雷达测图|Tatsuya Sasayama, Shintaro Ito, Koichi Ito, Takafumi Aoki|<http://arxiv.org/pdf/2505.20876v2>|提出了一种基于深度学习的立体雷达测图法，显著提升SAR图像高程测量精度。|
|📝 更新|See through the Dark: Learning Illumination-affined Representations for Nighttime Occupancy Prediction|透过黑暗：学习用于夜间占用预测的照明亲和表示|Yuan Wu, Zhiqiang Yan, Yigong Zhang, Xiang Li, Jian Yang|<http://arxiv.org/pdf/2505.20641v2>|[代码](https://github.com/yanzq95/LIAR); 提出了一种基于光照感知的夜间占用预测框架，有效解决夜间场景下的可见性和光照问题。|
|🆕 发布|On the Transferability and Discriminability of Repersentation Learning in Unsupervised Domain Adaptation|关于无监督领域自适应中表征学习的可迁移性和可区分性|Wenwen Qiang, Ziyin Gu, Lingyu Si, Jiangmeng Li, Changwen Zheng, Fuchun Sun, Hui Xiong|<http://arxiv.org/pdf/2505.22099v1>|提出了一种结合域对齐和可判别性约束的对抗性无监督域自适应方法，显著提升了模型性能。|
|🆕 发布|Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting|Counting Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting|Wei Lin, Chenyang Zhao, Antoni B. Chan|<http://arxiv.org/pdf/2505.21943v1>|[代码](https://github.com/Elin24/P2RLoss.); 提出点到区域损失，解决半监督点云人群计数中伪标签置信度传播问题。|
|🆕 发布|Taming Transformer Without Using Learning Rate Warmup|驯服Transformer而不使用学习率预热|Xianbiao Qi, Yelin He, Jiaquan Ye, Chun-Guang Li, Bojia Zi, Xili Dai, Qin Zou, Rong Xiao|<http://arxiv.org/pdf/2505.21910v1>|提出一种无需学习率预热策略的Transformer训练优化方法，有效避免模型崩溃。|
|📝 更新|Few-Shot Learning from Gigapixel Images via Hierarchical Vision-Language Alignment and Modeling|基于层次视觉-语言对齐与建模的吉像素图像小样本学习|Bryan Wong, Jong Woo Kim, Huazhu Fu, Mun Yong Yi|<http://arxiv.org/pdf/2505.17982v3>|[代码](https://github.com/bryanwong17/HiVE-MIL); HiVE-MIL通过构建层次化视觉-语言模型，有效提升了从有限病理数据中学习的能力。|
|📝 更新|Meta Co-Training: Two Views are Better than One|元协同训练：两个视角胜过一个|Jay C. Rothenberger, Dimitrios I. Diochnos|<http://arxiv.org/pdf/2311.18083v5>|提出Meta Co-Training算法，通过构建预训练模型视图实现半监督学习，显著提升图像分类性能...|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation|力感知MoE增强的VLA模型在接触丰富操作中的应用|Jiawen Yu, Hairuo Liu, Qiaojun Yu, Jieji Ren, Ce Hao, Haitong Ding, Guangyu Huang, Guofan Huang .etc.|<http://arxiv.org/pdf/2505.22159v1>|提出ForceVLA，通过融合力感知MoE模块，显著提升接触密集型机器人操作的成功率。|
|🆕 发布|Learning Compositional Behaviors from Demonstration and Language|从演示和语言中学习组合行为|Weiyu Liu, Neil Nie, Ruohan Zhang, Jiayuan Mao, Jiajun Wu|<http://arxiv.org/pdf/2505.21981v1>|BLADE通过结合模仿学习和基于模型的规划，从演示和语言中学习长时程机器人操作。|


### 交互式感知 (Interactive Perception)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Functionality understanding and segmentation in 3D scenes|三维场景中的功能理解和分割|Jaime Corsetti, Francesco Giuliari, Alice Fasoli, Davide Boscaini, Fabio Poiesi|<http://arxiv.org/pdf/2411.16310v5>|[代码](https://tev-fbk.github.io/fun3du); Fun3DU通过语言模型和视觉语言模型实现3D场景中功能理解与分割。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VScan: Rethinking Visual Token Reduction for Efficient Large Vision-Language Models|VScan：重新思考视觉标记缩减以实现高效的大视觉语言模型|Ce Zhang, Kaixin Ma, Tianqing Fang, Wenhao Yu, Hongming Zhang, Zhisong Zhang, Yaqi Xie, Katia Sycara .etc.|<http://arxiv.org/pdf/2505.22654v1>|VScan通过两阶段视觉标记减少框架，有效降低大视觉语言模型计算成本，提升实时部署效率。|
|📝 更新|VLM Can Be a Good Assistant: Enhancing Embodied Visual Tracking with Self-Improving Vision-Language Models|视觉语言模型可以作为好助手：通过自改进视觉语言模型增强具身视觉跟踪|Kui Wu, Shuhang Xu, Hao Chen, Churan Wang, Zhoujun Li, Yizhou Wang, Fangwei Zhong|<http://arxiv.org/pdf/2505.20718v2>|提出了一种结合视觉语言模型和自我改进机制的视觉跟踪方法，显著提升了跟踪失败后的恢复能力。|
|📝 更新|VisCRA: A Visual Chain Reasoning Attack for Jailbreaking Multimodal Large Language Models|视觉链推理攻击：用于越狱多模态大型语言模型的VisCRA|Bingrui Sima, Linhua Cong, Wenxuan Wang, Kun He|<http://arxiv.org/pdf/2505.19684v2>|VisCRA通过利用视觉推理链路，提出了一种针对多模态大型语言模型的视觉推理攻击框架，揭示了其安全风...|
|🆕 发布|IKIWISI: An Interactive Visual Pattern Generator for Evaluating the Reliability of Vision-Language Models Without Ground Truth|IKIWISI：一种用于评估无地面真相视觉语言模型可靠性的交互式视觉模式生成器|Md Touhidul Islam, Imran Kabir, Md Alimoor Reza, Syed Masum Billah|<http://arxiv.org/pdf/2505.22305v1>|IKIWISI通过交互式视觉模式生成，评估无地面真相下的视觉语言模型可靠性。|
|📝 更新|Progressive Scaling Visual Object Tracking|渐进式缩放视觉目标跟踪|Jack Hong, Shilin Yan, Zehao Xiao, Jiayin Cai, Xiaolong Jiang, Yao Hu, Henghui Ding|<http://arxiv.org/pdf/2505.19990v2>|提出渐进式缩放训练策略，显著提升视觉目标跟踪性能。|
|📝 更新|Towards Visuospatial Cognition via Hierarchical Fusion of Visual Experts|通过视觉专家分层融合实现视觉空间认知|Qi Feng|<http://arxiv.org/pdf/2505.12363v3>|提出ViCA2模型，通过视觉专家层次融合和大规模数据集，显著提升视觉空间认知能力。|
|📝 更新|From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration|从头到尾：通过自适应数据校准实现大型视觉-语言模型中平衡表示的研究|Mingyang Song, Xiaoye Qu, Jiawei Zhou, Yu Cheng|<http://arxiv.org/pdf/2503.12821v3>|提出ADR框架，通过数据重平衡和生成，缓解LVLM训练数据长尾问题，提升模型性能。|
|🆕 发布|OmniAD: Detect and Understand Industrial Anomaly via Multimodal Reasoning|全视AD：通过多模态推理检测和理解工业异常|Shifang Zhao, Yiheng Lin, Lu Han, Yao Zhao, Yunchao Wei|<http://arxiv.org/pdf/2505.22039v1>|OmniAD通过融合视觉和文本推理，实现了对工业异常的细粒度分析和检测。|
|🆕 发布|VRAG-RL: Empower Vision-Perception-Based RAG for Visually Rich Information Understanding via Iterative Reasoning with Reinforcement Learning|VRAG-RL：通过强化学习迭代推理赋能基于视觉感知的RAG以理解视觉丰富信息|Qiuchen Wang, Ruixue Ding, Yu Zeng, Zehui Chen, Lin Chen, Shihang Wang, Pengjun Xie, Fei Huang .etc.|<http://arxiv.org/pdf/2505.22019v1>|[代码](https://github.com/Alibaba-NLP/VRAG); VRAG-RL通过强化学习赋能视觉信息理解，实现迭代推理以优化视觉丰富信息的检索与理解。|
|🆕 发布|Towards Comprehensive Scene Understanding: Integrating First and Third-Person Views for LVLMs|迈向全面场景理解：将第一人称和第三人称视角整合到LVLMs中|Insu Lee, Wooje Park, Jaeyun Jang, Minyoung Noh, Kyuhong Shim, Byonghyo Shim|<http://arxiv.org/pdf/2505.21955v1>|提出了一种结合第一人称和第三人称视角的框架，以增强大型视觉语言模型在多视角推理中的性能。|
|📝 更新|MTVQA: Benchmarking Multilingual Text-Centric Visual Question Answering|MTVQA：多语言文本中心视觉问答基准测试|Jingqun Tang, Qi Liu, Yongjie Ye, Jinghui Lu, Shu Wei, Chunhui Lin, Wanqing Li, Mohamad Fitri Faiz Bin Mahmood .etc.|<http://arxiv.org/pdf/2405.11985v4>|[代码](https://bytedance.github.io/MTVQA); 构建了首个涵盖9种语言的TEC-VQA基准，显著提升了多语言视觉问答性能。|
|📝 更新|A Knowledge-guided Adversarial Defense for Resisting Malicious Visual Manipulation|基于知识的对抗防御以抵抗恶意视觉操纵|Dawei Zhou, Suzhi Gang, Decheng Liu, Tongliang Liu, Nannan Wang, Xinbo Gao|<http://arxiv.org/pdf/2504.08411v2>|提出知识引导对抗防御，有效抵抗恶意视觉操纵。|
|🆕 发布|Beyond Perception: Evaluating Abstract Visual Reasoning through Multi-Stage Task|超越感知：通过多阶段任务评估抽象视觉推理|Yanbei Jiang, Yihao Ding, Chao Lei, Jiayang Ao, Jey Han Lau, Krista A. Ehinger|<http://arxiv.org/pdf/2505.21850v1>|构建了多阶段抽象视觉推理基准和多阶段评估指标，揭示现有模型在复杂推理阶段的不足。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Chain-of-Talkers (CoTalk): Fast Human Annotation of Dense Image Captions|链式说话者（CoTalk）：密集图像标题的快速人工标注|Yijun Shen, Delong Chen, Fan Liu, Xingyu Wang, Chuanyi Zhang, Liang Yao, Yuhui Zheng|<http://arxiv.org/pdf/2505.22627v1>|分析失败|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Zero-Shot 3D Visual Grounding from Vision-Language Models|零样本3D视觉定位：基于视觉-语言模型|Rong Li, Shijie Li, Lingdong Kong, Xulei Yang, Junwei Liang|<http://arxiv.org/pdf/2505.22429v1>|提出了一种无需3D训练的零样本3D视觉定位框架，显著提升了定位精度。|
|📝 更新|Progressive Language-guided Visual Learning for Multi-Task Visual Grounding|多任务视觉定位的渐进式语言引导视觉学习|Jingchao Wang, Hong Wang, Wenlong Zhang, Kunhua Ji, Dingjiang Huang, Yefeng Zheng|<http://arxiv.org/pdf/2504.16145v2>|[代码](https://github.com/jcwang0602/PLVL); 提出PLVL框架，通过语言引导视觉学习，提升多任务视觉定位准确度。|
|🆕 发布|Mitigating Audiovisual Mismatch in Visual-Guide Audio Captioning|缓解视觉引导音频字幕中的视听失配|Le Xu, Chenxing Li, Yong Ren, Yujie Chen, Yu Gu, Ruibo Fu, Shan Yang, Dong Yu|<http://arxiv.org/pdf/2505.22045v1>|提出了一种基于熵感知的融合框架，有效缓解视觉引导音频字幕中的视听失配问题，显著提升模型性能和推理速度...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Adversarially Robust AI-Generated Image Detection for Free: An Information Theoretic Perspective|对抗鲁棒的免费AI生成图像检测：信息论视角|Ruixuan Zhang, He Wang, Zhengyu Zhao, Zhiqing Guo, Xun Yang, Yunfeng Diao, Meng Wang|<http://arxiv.org/pdf/2505.22604v1>|提出一种无需训练的基于信息论度量方法，有效防御AI生成图像检测中的对抗攻击。|
|🆕 发布|Comparative Analysis of Machine Learning Models for Lung Cancer Mutation Detection and Staging Using 3D CT Scans|3D CT扫描在肺癌突变检测和分期中机器学习模型的比较分析|Yiheng Li, Francisco Carrillo-Perez, Mohammed Alawad, Olivier Gevaert|<http://arxiv.org/pdf/2505.22592v1>|比较了两种机器学习模型在3D CT扫描肺癌突变检测和分期中的应用，FMCIB+XGBoost在突变检...|
|🆕 发布|Chest Disease Detection In X-Ray Images Using Deep Learning Classification Method|基于深度学习分类方法的X射线图像胸部疾病检测|Alanna Hazlett, Naomi Ohashi, Timothy Rodriguez, Sodiq Adewole|<http://arxiv.org/pdf/2505.22609v1>|利用深度学习和迁移学习技术，实现了对X光胸片的高精度疾病分类。|
|📝 更新|Structurally Different Neural Network Blocks for the Segmentation of Atrial and Aortic Perivascular Adipose Tissue in Multi-centre CT Angiography Scans|结构不同的神经网络块在多中心CT血管造影扫描中用于心房和主动脉周围脂肪组织的分割|Ikboljon Sobirov, Cheng Xie, Muhammad Siddique, Parijat Patel, Kenneth Chan, Thomas Halborg, Christos P. Kotanidis, Zarqaish Fatima .etc.|<http://arxiv.org/pdf/2306.03494v2>|提出了一种新型深度学习框架LegoNet，通过交替使用不同结构的神经网络块，提高了心血管图像分割的准...|
|🆕 发布|Distance Transform Guided Mixup for Alzheimer's Detection|基于距离变换引导的Mixup用于阿尔茨海默病检测|Zobia Batool, Huseyin Ozkan, Erchan Aptoula|<http://arxiv.org/pdf/2505.22434v1>|提出了一种基于距离变换的Mixup方法，有效解决阿尔茨海默病检测数据集不平衡问题，提升模型泛化性能。|
|📝 更新|MOSformer: Momentum encoder-based inter-slice fusion transformer for medical image segmentation|MOSformer：基于动量编码器的医学图像分割切片间融合Transformer|De-Xing Huang, Xiao-Hu Zhou, Mei-Jiang Gui, Xiao-Liang Xie, Shi-Qi Liu, Shuang-Yi Wang, Zhen-Qiu Feng, Zeng-Guang Hou|<http://arxiv.org/pdf/2401.11856v2>|提出了一种基于动量编码器的多尺度融合Transformer，有效融合了医学图像切片间的信息，提升了分...|
|🆕 发布|VME: A Satellite Imagery Dataset and Benchmark for Detecting Vehicles in the Middle East and Beyond|VME：中东及以外地区车辆检测的卫星图像数据集和基准|Noora Al-Emadi, Ingmar Weber, Yin Yang, Ferda Ofli|<http://arxiv.org/pdf/2505.22353v1>|构建了中东地区卫星图像车辆检测数据集，显著提升了该地区车辆检测准确率。|
|🆕 发布|Look & Mark: Leveraging Radiologist Eye Fixations and Bounding boxes in Multimodal Large Language Models for Chest X-ray Report Generation|视觉定位：利用放射科医生的眼动数据和边界框在多模态大型语言模型中生成胸部X光报告|Yunsoo Kim, Jinge Wu, Su-Hwan Kim, Pardeep Vasudev, Jiashu Shen, Honghan Wu|<http://arxiv.org/pdf/2505.22222v1>|通过结合放射科医生注视点和边界框，Look & Mark策略显著提升了LLM在生成胸部X光报告中的准...|
|🆕 发布|Enjoying Information Dividend: Gaze Track-based Medical Weakly Supervised Segmentation|享受信息红利：基于注视跟踪的医疗弱监督分割|Zhisong Wang, Yiwen Ye, Ziyang Chen, Yong Xia|<http://arxiv.org/pdf/2505.22230v1>|提出GradTrack框架，利用医生注视轨迹提升医疗图像弱监督分割性能。|
|📝 更新|Coverage Biases in High-Resolution Satellite Imagery|高分辨率卫星影像的覆盖偏差|Vadim Musienko, Axel Jacquet, Ingmar Weber, Till Koebe|<http://arxiv.org/pdf/2505.03842v2>|揭示了高分辨率卫星影像覆盖偏差，并分析了其受地理、社会经济和地缘政治因素影响。|
|📝 更新|A Weak Supervision Learning Approach Towards an Equitable Mobility Estimation|一种面向公平移动性估计的弱监督学习方法|Theophilus Aidoo, Till Koebe, Akansh Maurya, Hewan Shrestha, Ingmar Weber|<http://arxiv.org/pdf/2505.04229v2>|提出了一种利用弱监督学习估计停车场占用率的方法，以降低对高分辨率图像的依赖。|
|🆕 发布|Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis|将CLIP带入临床：用于医学分析的动态软标签和否定感知学习|Hanbin Ko, Chang-Min Park|<http://arxiv.org/pdf/2505.22079v1>|提出动态软标签和否定感知学习，提升医学图像分析中的视觉语言处理能力。|
|🆕 发布|BD Open LULC Map: High-resolution land use land cover mapping & benchmarking for urban development in Dhaka, Bangladesh|BD Open LULC Map：孟加拉达卡市高分辨率土地利用/土地覆盖制图与基准测试|Mir Sazzat Hossain, Ovi Paul, Md Akil Raihan Iftee, Rakibul Hasan Rajib, Abu Bakar Siddik Nayem, Anis Sarker, Arshad Momen, Md. Ashraful Amin .etc.|<http://arxiv.org/pdf/2505.21915v1>|构建BD Open LULC Map，提供高分辨率土地覆盖标注，助力南亚城市可持续发展。|
|🆕 发布|Concentrate on Weakness: Mining Hard Prototypes for Few-Shot Medical Image Segmentation|聚焦弱点：挖掘困难原型以实现少样本医学图像分割|Jianchao Jiang, Haofeng Zhang|<http://arxiv.org/pdf/2505.21897v1>|[代码](https://github.com/jcjiang99/CoW.); 针对少量样本医学图像分割，提出了一种基于弱特征挖掘的硬原型生成方法，显著提升了分割精度。|
|🆕 发布|GETReason: Enhancing Image Context Extraction through Hierarchical Multi-Agent Reasoning|GETReason：通过分层多智能体推理增强图像上下文提取|Shikhhar Siingh, Abhinav Rawat, Vivek Gupta, Chitta Baral|<http://arxiv.org/pdf/2505.21863v1>|GETReason通过分层多智能体推理，提升图像上下文提取，有效关联图像与事件背景。|
|🆕 发布|Towards Scalable Language-Image Pre-training for 3D Medical Imaging|面向可扩展的3D医学影像语言-图像预训练|Chenhui Zhao, Yiwei Lyu, Asadur Chowdury, Edward Harake, Akhil Kondepudi, Akshay Rao, Xinhai Hou, Honglak Lee .etc.|<http://arxiv.org/pdf/2505.21862v1>|[代码](https://github.com/Zch0414/hlip); 提出HLIP，一种轻量级分层注意力机制，有效降低3D医学影像预训练的计算需求，实现大规模无标注数据集...|
|🆕 发布|MAMBO-NET: Multi-Causal Aware Modeling Backdoor-Intervention Optimization for Medical Image Segmentation Network|MAMBO-NET：针对医学图像分割网络的多元因果感知建模后门干预优化|Ruiguo Yu, Yiyang Zhang, Yuan Tian, Yujie Diao, Di Jin, Witold Pedrycz|<http://arxiv.org/pdf/2505.21874v1>|提出MAMBO-NET网络，通过因果推理和干预优化，有效降低混淆因素影响，提升医学图像分割精度。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|The Meeseeks Mesh: Spatially Consistent 3D Adversarial Objects for BEV Detector|《寻求网格：用于BEV检测器的空间一致3D对抗性对象》|Aixuan Li, Mochu Xiang, Jing Zhang, Yuchao Dai|<http://arxiv.org/pdf/2505.22499v1>|提出了一种生成空间一致3D对抗物体的方法，以评估BEV检测器的鲁棒性。|


### 生物特征识别 (Biometric Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SHTOcc: Effective 3D Occupancy Prediction with Sparse Head and Tail Voxels|SHTOcc：基于稀疏头部和尾部体素的有效的3D占用预测|Qiucheng Yu, Yuan Xie, Xin Tan|<http://arxiv.org/pdf/2505.22461v1>|[代码](https://github.com/ge95net/SHTOcc); 提出SHTOcc方法，通过稀疏头尾体素构建和去耦学习，有效解决3D占用预测中的长尾问题和模型偏差。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Bridging Scales in Map Generation: A scale-aware cascaded generative mapping framework for seamless and consistent multi-scale cartographic representation|跨越尺度在地图生成中的应用：一种具有尺度感知的级联生成映射框架，用于实现无缝且一致的多尺度地图表示|Chenxing Sun, Yongyang Xu, Xuwei Xu, Xixi Fan, Jing Bai, Xiechun Lu, Zhanlong Chen|<http://arxiv.org/pdf/2502.04991v3>|提出了一种基于条件引导扩散和多层次级联架构的地图生成框架，有效解决了多尺度地图生成中的尺度感知和空间...|
|🆕 发布|GeoDrive: 3D Geometry-Informed Driving World Model with Precise Action Control|GeoDrive：基于3D几何信息的精确动作控制的驾驶世界模型|Anthony Chen, Wenzhao Zheng, Yida Wang, Xueyang Zhang, Kun Zhan, Peng Jia, Kurt Keutzer, Shangbang Zhang|<http://arxiv.org/pdf/2505.22421v1>|GeoDrive通过整合3D几何信息，提升了自动驾驶场景建模的准确性和可靠性。|
|📝 更新|Galileo: Learning Global & Local Features of Many Remote Sensing Modalities|伽利略：学习多种遥感模态的全局与局部特征|Gabriel Tseng, Anthony Fuller, Marlena Reil, Henry Herzog, Patrick Beukema, Favyen Bastani, James R. Green, Evan Shelhamer .etc.|<http://arxiv.org/pdf/2502.09356v2>|Galileo通过自监督学习，提取多尺度特征，实现多模态遥感数据共享表示，提升遥感任务性能。|
|🆕 发布|Learnable Burst-Encodable Time-of-Flight Imaging for High-Fidelity Long-Distance Depth Sensing|可学习的突发编码飞行时间成像技术，实现高保真长距离深度感知|Manchao Bao, Shengjiang Fang, Tao Yue, Xuemei Hu|<http://arxiv.org/pdf/2505.22025v1>|提出了一种新型BE-ToF成像方法，有效解决了长距离深度传感中的相位缠绕和信噪比低问题。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Failures to Fixes: LLM-Driven Scenario Repair for Self-Evolving Autonomous Driving|从失败到修复：基于LLM的自动驾驶场景修复自进化|Xinyu Xia, Xingjun Ma, Yunfeng Hu, Ting Qu, Hong Chen, Xun Gong|<http://arxiv.org/pdf/2505.22067v1>|提出了一种基于LLM的自动驾驶场景修复框架，通过推荐相关场景提升系统鲁棒性和泛化能力。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hadaptive-Net: Efficient Vision Models via Adaptive Cross-Hadamard Synergy|自适应-网：通过自适应交叉哈达玛协同的高效视觉模型|Xuyang Zhang, Xi Zhang, Liang Chen, Hao Shi, Qingshan Guo|<http://arxiv.org/pdf/2505.22226v1>|提出Hadamard自适应网络，通过自适应交叉Hadamard产品实现高效视觉模型。|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Investigating Mechanisms for In-Context Vision Language Binding|探究情境视觉语言绑定机制|Darshana Saravanan, Makarand Tapaswi, Vineet Gandhi|<http://arxiv.org/pdf/2505.22200v1>|探究了视觉语言模型中图像-文本绑定机制，提出绑定ID方法实现情境关联。|


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Flexible Tool Selection through Low-dimensional Attribute Alignment of Vision and Language|通过视觉与语言低维属性对齐的灵活工具选择|Guangfu Hao, Haojie Wen, Liangxuna Guo, Yang Chen, Yanchao Bi, Shan Yu|<http://arxiv.org/pdf/2505.22146v1>|开发了一种通过低维属性对齐视觉与语言的方法，实现灵活的工具选择，显著提升工具识别准确率。|
|📝 更新|Visuospatial Cognitive Assistant|视觉空间认知助手|Qi Feng|<http://arxiv.org/pdf/2505.12312v3>|提出ViCA-7B模型，通过大规模数据集和可解释性研究，显著提升了视频空间认知能力。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Dormant to Deleted: Tamper-Resistant Unlearning Through Weight-Space Regularization|从休眠到删除：通过权重空间正则化的抗篡改反学习|Shoaib Ahmed Siddiqui, Adrian Weller, David Krueger, Gintare Karolina Dziugaite, Michael Curtis Mozer, Eleni Triantafillou|<http://arxiv.org/pdf/2505.22310v1>|通过权重空间正则化，提出了一种抗篡改的模型遗忘方法，显著提升了模型对重新学习的抵抗力。|
|📝 更新|PAEFF: Precise Alignment and Enhanced Gated Feature Fusion for Face-Voice Association|PAEFF：精确对齐与增强门控特征融合的人脸-语音关联|Abdul Hannan, Muhammad Arslan Manzoor, Shah Nawaz, Muhammad Irzam Liaqat, Markus Schedl, Mubashir Noman|<http://arxiv.org/pdf/2505.17002v2>|提出了一种精确对齐和增强门控特征融合方法，有效提升了人脸语音关联性能。|
|🆕 发布|Reference-Guided Identity Preserving Face Restoration|参考引导的身份保持人脸修复|Mo Zhou, Keren Ye, Viraj Shah, Kangfu Mei, Mauricio Delbracio, Peyman Milanfar, Vishal M. Patel, Hossein Talebi|<http://arxiv.org/pdf/2505.21905v1>|提出一种融合多级信息和新型损失函数的方法，有效提升基于参考人脸的图像修复和身份保持。|

