## [UPDATED!] **2025-05-30** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MIRAGE: Assessing Hallucination in Multimodal Reasoning Chains of MLLM|MIRAGEï¼šè¯„ä¼°å¤šæ¨¡æ€æ¨ç†é“¾ä¸­MLLMçš„å¹»è§‰|Bowen Dong, Minheng Ni, Zitong Huang, Guanglei Yang, Wangmeng Zuo, Lei Zhang|<http://arxiv.org/pdf/2505.24238v2>|æå‡ºMIRAGEåŸºå‡†å’Œæ”¹è¿›æ–¹æ³•ï¼Œæœ‰æ•ˆè¯†åˆ«å’Œå‡å°‘å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸­çš„æ¨ç†å¹»è§‰ã€‚|
|ğŸ†• å‘å¸ƒ|Mixpert: Mitigating Multimodal Learning Conflicts with Efficient Mixture-of-Vision-Experts|æ··åˆä¸“å®¶ï¼šé€šè¿‡é«˜æ•ˆæ··åˆè§†è§‰ä¸“å®¶ç¼“è§£å¤šæ¨¡æ€å­¦ä¹ å†²çª|Xin He, Xumeng Han, Longhui Wei, Lingxi Xie, Qi Tian|<http://arxiv.org/pdf/2505.24541v1>|Mixperté€šè¿‡æ··åˆè§†è§‰ä¸“å®¶æ¶æ„å’ŒåŠ¨æ€è·¯ç”±æœºåˆ¶ï¼Œæœ‰æ•ˆç¼“è§£äº†å¤šæ¨¡æ€å­¦ä¹ ä¸­çš„å†²çªï¼Œæé«˜äº†å¤šä»»åŠ¡å­¦ä¹ æ•ˆç‡...|
|ğŸ“ æ›´æ–°|VITA: Towards Open-Source Interactive Omni Multimodal LLM|VITAï¼šè¿ˆå‘å¼€æºäº¤äº’å¼å…¨æ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹|Chaoyou Fu, Haojia Lin, Zuwei Long, Yunhang Shen, Yuhang Dai, Meng Zhao, Yi-Fan Zhang, Shaoqi Dong .etc.|<http://arxiv.org/pdf/2408.05211v3>|æå‡ºVITAï¼Œé¦–ä¸ªå¼€æºçš„å¤šæ¨¡æ€LLMï¼Œå®ç°è§†é¢‘ã€å›¾åƒã€æ–‡æœ¬å’ŒéŸ³é¢‘çš„äº¤äº’å¼å¤„ç†ä¸åˆ†æã€‚|
|ğŸ“ æ›´æ–°|Emotion-Qwen: Training Hybrid Experts for Unified Emotion and General Vision-Language Understanding|æƒ…æ„Ÿ-Qwenï¼šè®­ç»ƒæ··åˆä¸“å®¶ä»¥å®ç°ç»Ÿä¸€çš„æƒ…æ„Ÿå’Œé€šç”¨è§†è§‰-è¯­è¨€ç†è§£|Dawei Huang, Qing Li, Chuan Yan, Zebang Cheng, Yurong Huang, Xiang Li, Bin Li, Xiaohui Wang .etc.|<http://arxiv.org/pdf/2505.06685v2>|[ä»£ç ](https://github.com/24DavidHuang/Emotion-Qwen.); æå‡ºEmotion-Qwenï¼Œé€šè¿‡æ··åˆä¸“å®¶æ¨¡å‹å’Œå¤§è§„æ¨¡æ•°æ®é›†ï¼Œæå‡è§†é¢‘æƒ…æ„Ÿç†è§£å’Œé€šç”¨è§†è§‰è¯­è¨€ç†è§£èƒ½åŠ›...|
|ğŸ†• å‘å¸ƒ|un$^2$CLIP: Improving CLIP's Visual Detail Capturing Ability via Inverting unCLIP|un$^2$CLIPï¼šé€šè¿‡é€†unCLIPæå‡CLIPçš„è§†è§‰ç»†èŠ‚æ•æ‰èƒ½åŠ›|Yinqi Li, Jiahe Zhao, Hong Chang, Ruibing Hou, Shiguang Shan, Xilin Chen|<http://arxiv.org/pdf/2505.24517v1>|[ä»£ç ](https://github.com/LiYinqi/un2CLIP.); é€šè¿‡é€†unCLIPæ¨¡å‹ï¼Œæå‡CLIPæ•æ‰å›¾åƒç»†èŠ‚çš„èƒ½åŠ›ã€‚|
|ğŸ“ æ›´æ–°|Patho-R1: A Multimodal Reinforcement Learning-Based Pathology Expert Reasoner|ç—…ç†-R1ï¼šä¸€ç§åŸºäºå¤šæ¨¡æ€å¼ºåŒ–å­¦ä¹ çš„ç—…ç†ä¸“å®¶æ¨ç†å™¨|Wenchuan Zhang, Penghao Zhang, Jingru Guo, Tao Cheng, Jie Chen, Shuwan Zhang, Zhang Zhang, Yuhao Yi .etc.|<http://arxiv.org/pdf/2505.11404v2>|[ä»£ç ](https://github.com/Wenchuan-Zhang/Patho-R1.); æ„å»ºé«˜è´¨é‡ç—…ç†æ¨ç†æ•°æ®é›†ï¼Œæå‡ºPatho-R1æ¨¡å‹ï¼Œæå‡ç—…ç†è¯Šæ–­å‡†ç¡®æ€§å’Œæ¨ç†åˆç†æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Mixed-R1: Unified Reward Perspective For Reasoning Capability in Multimodal Large Language Models|æ··åˆ-R1ï¼šå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›çš„ç»Ÿä¸€å¥–åŠ±è§†è§’|Shilin Xu, Yanwei Li, Rui Yang, Tao Zhang, Yueyi Sun, Wei Chow, Linfeng Li, Hang Song .etc.|<http://arxiv.org/pdf/2505.24164v1>|[ä»£ç ](https://github.com/xushilin1/mixed-r1.); æå‡ºMixed-R1æ¡†æ¶ï¼Œé€šè¿‡æ··åˆå¥–åŠ±å’Œè®­ç»ƒæ•°æ®æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|Towards a Generalizable Bimanual Foundation Policy via Flow-based Video Prediction|åŸºäºæµå¼è§†é¢‘é¢„æµ‹çš„åŒæ‰‹é€šç”¨åŸºç¡€ç­–ç•¥|Chenyou Fan, Fangzheng Yan, Chenjia Bai, Jiepeng Wang, Chi Zhang, Zhen Wang, Xuelong Li|<http://arxiv.org/pdf/2505.24156v1>|æå‡ºäº†ä¸€ç§åŸºäºæ–‡æœ¬é¢„æµ‹çš„è½»é‡çº§åŒè‡‚æ“ä½œç­–ç•¥ï¼Œæœ‰æ•ˆè§£å†³äº†æ•°æ®ç¨€ç¼ºå’Œæ³›åŒ–å›°éš¾é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|S4-Driver: Scalable Self-Supervised Driving Multimodal Large Language Modelwith Spatio-Temporal Visual Representation|S4-Driverï¼šå¯æ‰©å±•çš„è‡ªç›‘ç£é©¾é©¶å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå…·æœ‰æ—¶ç©ºè§†è§‰è¡¨ç¤º|Yichen Xie, Runsheng Xu, Tong He, Jyh-Jing Hwang, Katie Luo, Jingwei Ji, Hubert Lin, Letian Chen .etc.|<http://arxiv.org/pdf/2505.24139v1>|æå‡ºS4-Driverï¼Œé€šè¿‡æ—¶ç©ºè§†è§‰è¡¨ç¤ºå®ç°æ— éœ€æ ‡æ³¨çš„è‡ªåŠ¨é©¾é©¶è¿åŠ¨è§„åˆ’ã€‚|
|ğŸ†• å‘å¸ƒ|Proxy-FDA: Proxy-based Feature Distribution Alignment for Fine-tuning Vision Foundation Models without Forgetting|ä»£ç†-FDAï¼šåŸºäºä»£ç†çš„ç‰¹å¾åˆ†å¸ƒå¯¹é½ï¼Œç”¨äºå¾®è°ƒè§†è§‰åŸºç¡€æ¨¡å‹è€Œä¸å¿˜å´|Chen Huang, Skyler Seto, Hadi Pouransari, Mehrdad Farajtabar, Raviteja Vemulapalli, Fartash Faghri, Oncel Tuzel, Barry-John Theobald .etc.|<http://arxiv.org/pdf/2505.24088v1>|æå‡ºProxy-FDAæ–¹æ³•ï¼Œé€šè¿‡ç‰¹å¾åˆ†å¸ƒå¯¹é½å‡å°‘è§†è§‰åŸºç¡€æ¨¡å‹å¾®è°ƒæ—¶çš„æ¦‚å¿µé—å¿˜é—®é¢˜ã€‚|


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Enhancing Large Vision Model in Street Scene Semantic Understanding through Leveraging Posterior Optimization Trajectory|é€šè¿‡åˆ©ç”¨åéªŒä¼˜åŒ–è½¨è¿¹å¢å¼ºè¡—æ™¯åœºæ™¯è¯­ä¹‰ç†è§£çš„å¤§å‹è§†è§‰æ¨¡å‹|Wei-Bin Kou, Qingfeng Lin, Ming Tang, Jingreng Lei, Shuai Wang, Rongguang Ye, Guangxu Zhu, Yik-Chung Wu|<http://arxiv.org/pdf/2501.01710v2>|é€šè¿‡ç»“åˆé¢„è®­ç»ƒçš„å¤§è§†è§‰æ¨¡å‹å’ŒåéªŒä¼˜åŒ–è½¨è¿¹å¼•å¯¼ä¼˜åŒ–æ–¹æ¡ˆï¼Œæœ‰æ•ˆæå‡äº†è‡ªåŠ¨é©¾é©¶åœºæ™¯è¯­ä¹‰ç†è§£æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œ...|
|ğŸ“ æ›´æ–°|Using Knowledge Graphs to harvest datasets for efficient CLIP model training|åˆ©ç”¨çŸ¥è¯†å›¾è°±é«˜æ•ˆé‡‡é›†æ•°æ®é›†ä»¥è®­ç»ƒCLIPæ¨¡å‹|Simon Ging, Sebastian Walter, Jelena BratuliÄ‡, Johannes Dienert, Hannah Bast, Thomas Brox|<http://arxiv.org/pdf/2505.02746v2>|åˆ©ç”¨çŸ¥è¯†å›¾è°±ä¼˜åŒ–ç½‘ç»œæœç´¢ç­–ç•¥ï¼Œå¤§å¹…å‡å°‘æ•°æ®é‡é«˜æ•ˆè®­ç»ƒCLIPæ¨¡å‹ã€‚|
|ğŸ“ æ›´æ–°|Efficient Adaptation For Remote Sensing Visual Grounding|é«˜æ•ˆé¥æ„Ÿè§†è§‰å®šä½è‡ªé€‚åº”|Hasan Moughnieh, Mohamad Chalhoub, Hasan Nasrallah, Cristiano Nattero, Paolo Campanella, Giovanni Nico, Ali J. Ghandour|<http://arxiv.org/pdf/2503.23083v3>|åˆ©ç”¨å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯ï¼Œæœ‰æ•ˆé™ä½é¥æ„Ÿè§†è§‰å®šä½çš„è®¡ç®—æˆæœ¬ï¼Œå®ç°é«˜æ•ˆè·¨æ¨¡æ€ç†è§£ã€‚|
|ğŸ†• å‘å¸ƒ|Geospatial Foundation Models to Enable Progress on Sustainable Development Goals|åœ°ç†ç©ºé—´åŸºç¡€æ¨¡å‹ä»¥ä¿ƒè¿›å¯æŒç»­å‘å±•ç›®æ ‡è¿›å±•|Pedram Ghamisi, Weikang Yu, Xiaokang Zhang, Aldino Rizaldy, Jian Wang, Chufeng Zhou, Richard Gloaguen, Gustau Camps-Valls|<http://arxiv.org/pdf/2505.24528v1>|æ„å»ºSustainFMæ¡†æ¶ï¼Œè¯„ä¼°åœ°ç†ç©ºé—´åŸºç¡€æ¨¡å‹åœ¨å¯æŒç»­å‘å±•ç›®æ ‡ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model|å‘¨æœŸ-LLMï¼šæ‰©å±•å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„å‘¨æœŸèƒ½åŠ›|Yuting Zhang, Hao Lu, Qingyong Hu, Yin Wang, Kaishen Yuan, Xin Liu, Kaishun Wu|<http://arxiv.org/pdf/2505.24476v1>|[ä»£ç ](https://github.com/keke-nice/Period-LLM.); æå‡ºPeriod-LLMæ¨¡å‹ï¼Œå¢å¼ºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å‘¨æœŸæ€§ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚|
|ğŸ“ æ›´æ–°|Unpaired Deblurring via Decoupled Diffusion Model|æ— é…å¯¹å»æ¨¡ç³Šé€šè¿‡è§£è€¦æ‰©æ•£æ¨¡å‹|Junhao Cheng, Wei-Ting Chen, Xi Lu, Ming-Hsuan Yang|<http://arxiv.org/pdf/2502.01522v2>|UID-Diffé€šè¿‡è§£è€¦ç»“æ„ç‰¹å¾å’Œæ¨¡ç³Šæ¨¡å¼ï¼Œæœ‰æ•ˆæå‡äº†æœªçŸ¥é¢†åŸŸå›¾åƒå»æ¨¡ç³Šæ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|Reefknot: A Comprehensive Benchmark for Relation Hallucination Evaluation, Analysis and Mitigation in Multimodal Large Language Models|çŠç‘šç»“ï¼šå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å…³ç³»å¹»è§‰è¯„ä¼°ã€åˆ†æå’Œç¼“è§£çš„å…¨é¢åŸºå‡†|Kening Zheng, Junkai Chen, Yibo Yan, Xin Zou, Xuming Hu|<http://arxiv.org/pdf/2408.09429v3>|æ„å»ºäº†é’ˆå¯¹å…³ç³»å¹»è§‰çš„ç»¼åˆåŸºå‡†Reefknotï¼Œå¹¶æå‡ºåŸºäºç½®ä¿¡åº¦çš„ç¼“è§£ç­–ç•¥ï¼Œæœ‰æ•ˆé™ä½å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸­...|
|ğŸ†• å‘å¸ƒ|Harnessing Foundation Models for Robust and Generalizable 6-DOF Bronchoscopy Localization|åˆ©ç”¨åŸºç¡€æ¨¡å‹å®ç°é²æ£’ä¸”é€šç”¨çš„6è‡ªç”±åº¦æ”¯æ°”ç®¡é•œå®šä½|Qingyao Tian, Huai Liao, Xinyan Huang, Bingyu Yang, Hongbin Liu|<http://arxiv.org/pdf/2505.24249v1>|æå‡ºPANSv2æ¡†æ¶ï¼Œåˆ©ç”¨åŸºç¡€æ¨¡å‹å¢å¼ºæ·±åº¦ä¼°è®¡å’Œåœ°æ ‡æ£€æµ‹ï¼Œå®ç°é²æ£’ä¸”é€šç”¨çš„æ”¯æ°”ç®¡é•œå®šä½ã€‚|
|ğŸ†• å‘å¸ƒ|From Hallucinations to Jailbreaks: Rethinking the Vulnerability of Large Foundation Models|ä»å¹»è§‰åˆ°è¶Šç‹±ï¼šé‡æ–°æ€è€ƒå¤§å‹åŸºç¡€æ¨¡å‹çš„è„†å¼±æ€§|Haibo Jin, Peiyan Zhang, Peiran Wang, Man Luo, Haohan Wang|<http://arxiv.org/pdf/2505.24232v1>|æå‡ºç»Ÿä¸€æ¡†æ¶æ­ç¤ºå¤§æ¨¡å‹å¹»è§‰ä¸è¶Šç‹±æ”»å‡»çš„å…³è”ï¼Œæå‡ºè”åˆé˜²å¾¡ç­–ç•¥æå‡æ¨¡å‹é²æ£’æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Benchmarking Foundation Models for Zero-Shot Biometric Tasks|åŸºå‡†æµ‹è¯•ç”¨äºé›¶æ ·æœ¬ç”Ÿç‰©è¯†åˆ«ä»»åŠ¡çš„åŸºåº§æ¨¡å‹|Redwan Sony, Parisa Farmanifard, Hamzeh Alzwairy, Nitish Shukla, Arun Ross|<http://arxiv.org/pdf/2505.24214v1>|æ„å»ºåŸºå‡†è¯„ä¼°é¢„è®­ç»ƒæ¨¡å‹åœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬ç”Ÿç‰©è¯†åˆ«ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå®ç°è·¨æ¨¡æ€ç”Ÿç‰©è¯†åˆ«ã€‚|
|ğŸ†• å‘å¸ƒ|Pretraining Deformable Image Registration Networks with Random Images|åŸºäºéšæœºå›¾åƒé¢„è®­ç»ƒå¯å˜å½¢å›¾åƒé…å‡†ç½‘ç»œ|Junyu Chen, Shuwen Wei, Yihao Liu, Aaron Carass, Yong Du|<http://arxiv.org/pdf/2505.24167v1>|æå‡ºä»¥éšæœºå›¾åƒæ³¨å†Œä½œä¸ºä»£ç†ä»»åŠ¡ï¼Œé¢„è®­ç»ƒå›¾åƒæ³¨å†Œç½‘ç»œï¼Œæå‡ç²¾åº¦å’Œæ•ˆç‡ã€‚|


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Agent-X: Evaluating Deep Multimodal Reasoning in Vision-Centric Agentic Tasks|Agent-Xï¼šè¯„ä¼°ä»¥è§†è§‰ä¸ºä¸­å¿ƒçš„æ™ºèƒ½ä½“ä»»åŠ¡ä¸­çš„æ·±åº¦å¤šæ¨¡æ€æ¨ç†|Tajamul Ashraf, Amal Saqib, Hanan Ghani, Muhra AlMahri, Yuhao Li, Noor Ahsan, Umair Nawaz, Jean Lahoud .etc.|<http://arxiv.org/pdf/2505.24876v1>|[ä»£ç ](https://github.com/mbzuai-oryx/Agent-X); æ„å»ºäº†å¤§è§„æ¨¡åŸºå‡†Agent-Xï¼Œè¯„ä¼°è§†è§‰ä¸­å¿ƒå‹æ™ºèƒ½ä½“åœ¨å¤šæ­¥å’Œæ·±åº¦æ¨ç†èƒ½åŠ›ã€‚|
|ğŸ“ æ›´æ–°|A Decade of Wheat Mapping for Lebanon|é»å·´å«©å°éº¦åˆ¶å›¾åå¹´å›é¡¾|Hasan Wehbi, Hasan Nasrallah, Mohamad Hasan Zahweh, Zeinab Takach, Veera Ganesh Yalla, Ali J. Ghandour|<http://arxiv.org/pdf/2504.11366v2>|æå‡ºäº†ä¸€ç§åŸºäºTSViTå’ŒFTWæ¡†æ¶çš„æ”¹è¿›æ–¹æ³•ï¼Œæé«˜äº†å°éº¦ç”°è¾¹ç•Œæå–çš„ç²¾åº¦å’Œå‡†ç¡®æ€§ã€‚|
|ğŸ“ æ›´æ–°|Structured 3D Latents for Scalable and Versatile 3D Generation|ç»“æ„åŒ–3Dæ½œåœ¨è¡¨ç¤ºï¼šå¯æ‰©å±•ä¸”é€šç”¨çš„3Dç”Ÿæˆ|Jianfeng Xiang, Zelong Lv, Sicheng Xu, Yu Deng, Ruicheng Wang, Bowen Zhang, Dong Chen, Xin Tong .etc.|<http://arxiv.org/pdf/2412.01506v3>|æå‡ºäº†ä¸€ç§åŸºäºç»“æ„åŒ–3Dæ½œå˜é‡çš„3Dç”Ÿæˆæ–¹æ³•ï¼Œå®ç°çµæ´»çš„è¾“å‡ºæ ¼å¼å’Œé«˜è´¨é‡3Dèµ„äº§åˆ›å»ºã€‚|
|ğŸ†• å‘å¸ƒ|PCIE_Pose Solution for EgoExo4D Pose and Proficiency Estimation Challenge|PCIE_Poseï¼šç”¨äºEgoExo4Då§¿æ€å’Œç†Ÿç»ƒåº¦ä¼°è®¡æŒ‘æˆ˜çš„è§£å†³æ–¹æ¡ˆ|Feng Chen, Kanokphan Lertniphonphan, Qiancheng Yan, Xiaohui Fan, Jun Xie, Tao Zhang, Zhepeng Wang|<http://arxiv.org/pdf/2505.24411v1>|å¼€å‘HP-ViT+å’Œèåˆå¤šæ¨¡æ€ç‰¹å¾ï¼Œå®ç°é«˜ç²¾åº¦æ‰‹éƒ¨å’Œå…¨èº«å§¿æ€ä¼°è®¡åŠæŠ€èƒ½è¯„ä¼°ã€‚|
|ğŸ†• å‘å¸ƒ|Leveraging Intermediate Features of Vision Transformer for Face Anti-Spoofing|åˆ©ç”¨è§†è§‰Transformerçš„ä¸­é—´ç‰¹å¾è¿›è¡Œäººè„¸é˜²ä¼ª|Mika Feng, Koichi Ito, Takafumi Aoki, Tetsushi Ohki, Masakatsu Nishigaki|<http://arxiv.org/pdf/2505.24402v1>|æå‡ºä¸€ç§åŸºäºViTçš„ä¸­é—´ç‰¹å¾ï¼Œç»“åˆæ•°æ®å¢å¼ºçš„å¯¹æŠ—æ”»å‡»æ£€æµ‹æ–¹æ³•ï¼Œæœ‰æ•ˆè¯†åˆ«ä¼ªé€ äººè„¸ã€‚|
|ğŸ“ æ›´æ–°|Large Language Model-Driven Distributed Integrated Multimodal Sensing and Semantic Communications|å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„åˆ†å¸ƒå¼é›†æˆå¤šæ¨¡æ€æ„ŸçŸ¥ä¸è¯­ä¹‰é€šä¿¡|Yubo Peng, Luping Xiang, Bingxin Zhang, Kun Yang|<http://arxiv.org/pdf/2505.18194v2>|æå‡ºäº†ä¸€ç§åŸºäºLLMçš„åˆ†å¸ƒå¼å¤šæ¨¡æ€æ„ŸçŸ¥ä¸è¯­ä¹‰é€šä¿¡æ¡†æ¶ï¼Œæœ‰æ•ˆæå‡äº†å¤æ‚ç¯å¢ƒä¸‹çš„æ„ŸçŸ¥ç²¾åº¦å’Œé€šä¿¡æ•ˆç‡ã€‚|
|ğŸ“ æ›´æ–°|ExPLoRA: Parameter-Efficient Extended Pre-Training to Adapt Vision Transformers under Domain Shifts|ExPLoRAï¼šå‚æ•°é«˜æ•ˆçš„æ‰©å±•é¢„è®­ç»ƒä»¥é€‚åº”åŸŸåç§»ä¸‹çš„è§†è§‰Transformer|Samar Khanna, Medhanie Irgau, David B. Lobell, Stefano Ermon|<http://arxiv.org/pdf/2406.10973v4>|[ä»£ç ](https://samar-khanna.github.io/ExPLoRA); ExPLoRAé€šè¿‡é«˜æ•ˆçš„è‡ªç›‘ç£é¢„è®­ç»ƒï¼Œæœ‰æ•ˆæå‡è§†è§‰Transformeråœ¨é¢†åŸŸè¿ç§»ä¸‹çš„è¿ç§»å­¦ä¹ æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|Enhancing Table Recognition with Vision LLMs: A Benchmark and Neighbor-Guided Toolchain Reasoner|å¢å¼ºè¡¨æ ¼è¯†åˆ«çš„è§†è§‰LLMsï¼šä¸€ä¸ªåŸºå‡†å’Œé‚»åŸŸå¼•å¯¼çš„å·¥å…·é“¾æ¨ç†å™¨|Yitong Zhou, Mingyue Cheng, Qingyang Mao, Feiyang Xu, Xin Li|<http://arxiv.org/pdf/2412.20662v3>|æå‡ºåŸºå‡†å’Œå·¥å…·é“¾æ¨ç†å™¨ï¼Œæ˜¾è‘—æå‡VLLMsåœ¨æ— ç›‘ç£è¡¨æ ¼è¯†åˆ«ä¸­çš„æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|Mamba-R: Vision Mamba ALSO Needs Registers|Mamba-Rï¼šè§†è§‰MambaåŒæ ·éœ€è¦å¯„å­˜å™¨|Feng Wang, Jiahao Wang, Sucheng Ren, Guoyizhe Wei, Jieru Mei, Wei Shao, Yuyin Zhou, Alan Yuille .etc.|<http://arxiv.org/pdf/2405.14858v2>|[ä»£ç ](https://github.com/wangf3014/Mamba-Reg.); é€šè¿‡å¼•å…¥å¯„å­˜å™¨å¹¶ä¼˜åŒ–å…¶ä½¿ç”¨ï¼ŒMamba-Ræ˜¾è‘—æå‡äº†Vision Mambaåœ¨å›¾åƒè¯†åˆ«ä»»åŠ¡ä¸­çš„æ€§èƒ½å’Œ...|


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### è¯­ä¹‰/å®ä¾‹åˆ†å‰² (Semantic/Instance Segmentation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|NUC-Net: Non-uniform Cylindrical Partition Network for Efficient LiDAR Semantic Segmentation|éå‡åŒ€åœ†æŸ±åˆ†å‰²ç½‘ç»œï¼šé«˜æ•ˆæ¿€å…‰é›·è¾¾è¯­ä¹‰åˆ†å‰²|Xuzhi Wang, Wei Feng, Lingdong Kong, Liang Wan|<http://arxiv.org/pdf/2505.24634v2>|[ä»£ç ](https://github.com/alanWXZ/NUC-Net); æå‡ºNUC-Netï¼Œé€šè¿‡éå‡åŒ€åœ†æŸ±åˆ†å‰²ç½‘ç»œé«˜æ•ˆè§£å†³LiDARè¯­ä¹‰åˆ†å‰²ä¸­çš„è®¡ç®—æˆæœ¬å’Œç‚¹åˆ†å¸ƒä¸å‡é—®é¢˜ã€‚|


### ç›®æ ‡æ£€æµ‹ä¸å®šä½ (Object Detection & Localization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|MSVCOD:A Large-Scale Multi-Scene Dataset for Video Camouflage Object Detection|MSVCODï¼šå¤§è§„æ¨¡å¤šåœºæ™¯è§†é¢‘ä¼ªè£…ç›®æ ‡æ£€æµ‹æ•°æ®é›†|Shuyong Gao, Yu'ang Feng, Qishan Wang, Lingyi Hong, Xinyu Zhou, Liu Fei, Yan Wang, Wenqiang Zhang|<http://arxiv.org/pdf/2502.13859v2>|æ„å»ºäº†å¤§è§„æ¨¡å¤šåœºæ™¯è§†é¢‘ä¼ªè£…ç‰©ä½“æ£€æµ‹æ•°æ®é›†MSVCODï¼Œå¹¶æå‡ºäº†ä¸€ç§æ— éœ€é¢å¤–è¿åŠ¨ç‰¹å¾èåˆæ¨¡å—çš„ä¸€ä½“åŒ–æ£€...|
|ğŸ“ æ›´æ–°|ENACT: Entropy-based Clustering of Attention Input for Reducing the Computational Needs of Object Detection Transformers|ENACTï¼šåŸºäºç†µçš„æ³¨æ„åŠ›è¾“å…¥èšç±»ä»¥é™ä½ç›®æ ‡æ£€æµ‹Transformerçš„è®¡ç®—éœ€æ±‚|Giorgos Savathrakis, Antonis Argyros|<http://arxiv.org/pdf/2409.07541v2>|[ä»£ç ](https://github.com/GSavathrakis/ENACT.); æå‡ºåŸºäºç†µçš„æ³¨æ„åŠ›è¾“å…¥èšç±»æ–¹æ³•ï¼Œé™ä½ç›®æ ‡æ£€æµ‹Transformerçš„è®¡ç®—éœ€æ±‚ã€‚|
|ğŸ“ æ›´æ–°|WTEFNet: Real-Time Low-Light Object Detection for Advanced Driver Assistance Systems|WTEFNetï¼šé«˜çº§é©¾é©¶è¾…åŠ©ç³»ç»Ÿå®æ—¶ä½å…‰ç‰©ä½“æ£€æµ‹|Hao Wu, Junzhou Chen, Ronghui Zhang, Nengchao Lyu, Hongyu Hu, Yanyong Guo, Tony Z. Qiu|<http://arxiv.org/pdf/2505.23201v2>|WTEFNeté€šè¿‡ä½å…‰å¢å¼ºã€ç‰¹å¾æå–å’Œè‡ªé€‚åº”èåˆï¼Œå®ç°å®æ—¶ä½å…‰åœºæ™¯ä¸‹çš„ç‰©ä½“æ£€æµ‹ã€‚|


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Bi-Manual Joint Camera Calibration and Scene Representation|åŒç›®è”åˆç›¸æœºæ ‡å®šä¸åœºæ™¯è¡¨ç¤º|Haozhan Tang, Tianyi Zhang, Matthew Johnson-Roberson, Weiming Zhi|<http://arxiv.org/pdf/2505.24819v1>|æå‡ºäº†ä¸€ç§æ— éœ€æ ‡è®°çš„è”åˆç›¸æœºæ ‡å®šå’Œåœºæ™¯è¡¨ç¤ºæ¡†æ¶ï¼Œå®ç°å¤šæœºå™¨äººååŒæ“ä½œã€‚|
|ğŸ“ æ›´æ–°|Good Keypoints for the Two-View Geometry Estimation Problem|ä¼˜è´¨å…³é”®ç‚¹ç”¨äºåŒè§†å›¾å‡ ä½•ä¼°è®¡é—®é¢˜|Konstantin Pakulev, Alexander Vakhitov, Gonzalo Ferrer|<http://arxiv.org/pdf/2503.18767v2>|æå‡ºBoNeSS-STå…³é”®ç‚¹æ£€æµ‹å™¨ï¼Œä¼˜åŒ–ä¸¤è§†å›¾å‡ ä½•ä¼°è®¡ä¸­çš„å…³é”®ç‚¹é€‰æ‹©ï¼Œæå‡å•åº”æ€§ä¼°è®¡ç²¾åº¦ã€‚|
|ğŸ†• å‘å¸ƒ|RT-X Net: RGB-Thermal cross attention network for Low-Light Image Enhancement|RT-X Netï¼šç”¨äºä½å…‰å›¾åƒå¢å¼ºçš„RGB-çƒ­æˆåƒè·¨æ³¨æ„åŠ›ç½‘ç»œ|Raman Jha, Adithya Lenka, Mani Ramanagopal, Aswin Sankaranarayanan, Kaushik Mitra|<http://arxiv.org/pdf/2505.24705v1>|[ä»£ç ](https://github.com/jhakrraman/rt-xnet.); æå‡ºRT-X Netï¼ŒèåˆRGBå’Œçƒ­å›¾åƒï¼Œæœ‰æ•ˆæå‡å¤œé—´å›¾åƒå¢å¼ºæ•ˆæœã€‚|
|ğŸ†• å‘å¸ƒ|6D Pose Estimation on Point Cloud Data through Prior Knowledge Integration: A Case Study in Autonomous Disassembly|åŸºäºå…ˆéªŒçŸ¥è¯†é›†æˆçš„ç‚¹äº‘æ•°æ®6Då§¿æ€ä¼°è®¡ï¼šè‡ªä¸»æ‹†è§£æ¡ˆä¾‹ç ”ç©¶|Chengzhi Wu, Hao Fu, Jan-Philipp Kaiser, Erik Tabuchi Barczak, Julius Pfrommer, Gisela Lanza, Michael Heizmann, JÃ¼rgen Beyerer|<http://arxiv.org/pdf/2505.24669v1>|é€šè¿‡æ•´åˆå…ˆéªŒçŸ¥è¯†ï¼Œæå‡ºäº†ä¸€ç§ç”¨äºç‚¹äº‘æ•°æ®ä¸Š6Då§¿æ€ä¼°è®¡çš„å…¨é¢ç®¡é“ï¼Œæœ‰æ•ˆè§£å†³äº†èºæ “æ£€æµ‹å’Œè‡ªåŠ¨æ‹†è§£é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|Leadership Assessment in Pediatric Intensive Care Unit Team Training|å„¿ç§‘é‡ç—‡ç›‘æŠ¤å®¤å›¢é˜ŸåŸ¹è®­ä¸­çš„é¢†å¯¼åŠ›è¯„ä¼°|Liangyang Ouyang, Yuki Sakai, Ryosuke Furuta, Hisataka Nozawa, Hikoro Matsui, Yoichi Sato|<http://arxiv.org/pdf/2505.24389v1>|å¼€å‘åŸºäºè‡ªè§†è§’è§†è§‰çš„è‡ªåŠ¨åŒ–åˆ†ææ¡†æ¶ï¼Œä»¥è¯„ä¼°å„¿ç§‘é‡ç—‡ç›‘æŠ¤å®¤å›¢é˜Ÿé¢†å¯¼æŠ€èƒ½ã€‚|
|ğŸ“ æ›´æ–°|MonoCoP: Chain-of-Prediction for Monocular 3D Object Detection|MonoCoPï¼šå•ç›®3Dç›®æ ‡æ£€æµ‹çš„é¢„æµ‹é“¾|Zhihao Zhang, Abhinav Kumar, Girish Chandar Ganesan, Xiaoming Liu|<http://arxiv.org/pdf/2505.04594v4>|MonoCoPé€šè¿‡é“¾å¼é¢„æµ‹ç­–ç•¥ï¼Œæœ‰æ•ˆæå‡äº†å•ç›®3Dç‰©ä½“æ£€æµ‹çš„æ·±åº¦ä¼°è®¡ç²¾åº¦ã€‚|
|ğŸ“ æ›´æ–°|Refinement Module based on Parse Graph of Feature Map for Human Pose Estimation|åŸºäºç‰¹å¾å›¾è§£æå›¾çš„ç²¾ç‚¼æ¨¡å—ç”¨äºäººä½“å§¿æ€ä¼°è®¡|Shibang Liu, Xuemei Xie, Guangming Shi|<http://arxiv.org/pdf/2501.11069v6>|è®¾è®¡äº†ä¸€ç§åŸºäºç‰¹å¾å›¾è§£æå›¾çš„ä¼˜åŒ–æ¨¡å—ï¼Œæå‡äº†äººä½“å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§å’Œé€‚åº”æ€§ã€‚|


### å›¾åƒåˆ†ç±»ä¸è¯†åˆ« (Image Classification & Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SASP: Strip-Aware Spatial Perception for Fine-Grained Bird Image Classification|SASPï¼šåŸºäºæ¡å¸¦æ„ŸçŸ¥çš„ç»†ç²’åº¦é¸Ÿç±»å›¾åƒåˆ†ç±»|Zheng Wang|<http://arxiv.org/pdf/2505.24380v1>|æå‡ºäº†ä¸€ç§åŸºäºæ¡å¸¦æ„ŸçŸ¥çš„ç©ºé—´æ„ŸçŸ¥æ¡†æ¶ï¼Œæœ‰æ•ˆæå‡äº†é¸Ÿç±»å›¾åƒåˆ†ç±»çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚|


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|ART-DECO: Arbitrary Text Guidance for 3D Detailizer Construction|ä»»æ„æ–‡æœ¬å¼•å¯¼çš„3Dç»†èŠ‚åŒ–æ„å»º|Qimin Chen, Yuezhi Yang, Yifang Wang, Vladimir G. Kim, Siddhartha Chaudhuri, Hao Zhang, Zhiqin Chen|<http://arxiv.org/pdf/2505.20431v2>|æå‡ºäº†ä¸€ç§åŸºäºæ–‡æœ¬æŒ‡å¯¼çš„3Dç»†èŠ‚åŒ–æ¨¡å‹ï¼Œå¯å¿«é€Ÿå°†ç²—ç•¥3Då½¢çŠ¶è½¬æ¢ä¸ºé«˜è´¨é‡èµ„äº§ã€‚|
|ğŸ“ æ›´æ–°|Absolute Coordinates Make Motion Generation Easy|ç»å¯¹åæ ‡ä½¿è¿åŠ¨ç”Ÿæˆå˜å¾—ç®€å•|Zichong Meng, Zeyu Han, Xiaogang Peng, Yiming Xie, Huaizu Jiang|<http://arxiv.org/pdf/2505.19377v2>|æå‡ºä½¿ç”¨ç»å¯¹åæ ‡ç®€åŒ–è¿åŠ¨ç”Ÿæˆï¼Œæ˜¾è‘—æå‡è¿åŠ¨ç²¾åº¦å’Œä¸‹æ¸¸ä»»åŠ¡åº”ç”¨ã€‚|
|ğŸ“ æ›´æ–°|HandCraft: Anatomically Correct Restoration of Malformed Hands in Diffusion Generated Images|ã€ŠHandCraftï¼šåŸºäºæ‰©æ•£ç”Ÿæˆå›¾åƒçš„ç•¸å½¢æ‰‹è§£å‰–æ­£ç¡®ä¿®å¤ã€‹|Zhenyue Qin, Yiqun Zhang, Yang Liu, Dylan Campbell|<http://arxiv.org/pdf/2411.04332v3>|HandCrafté€šè¿‡æ„å»ºæ‰‹éƒ¨æ©ç å’Œæ·±åº¦å›¾ï¼Œå®ç°äº†å¯¹ç”Ÿæˆå›¾åƒä¸­ç•¸å½¢æ‰‹çš„è§£å‰–ä¿®å¤ã€‚|
|ğŸ“ æ›´æ–°|LaWa: Using Latent Space for In-Generation Image Watermarking|LaWaï¼šåˆ©ç”¨æ½œåœ¨ç©ºé—´è¿›è¡Œç”Ÿæˆå›¾åƒæ°´å°|Ahmad Rezaei, Mohammad Akbari, Saeed Ranjbar Alvar, Arezou Fatemi, Yong Zhang|<http://arxiv.org/pdf/2408.05868v3>|LaWaé€šè¿‡åœ¨ç”Ÿæˆæ¨¡å‹ä¸­åµŒå…¥æ°´å°ï¼Œå®ç°äº†å¯¹AIç”Ÿæˆå›¾åƒçš„ä¸å¯è§æ°´å°ï¼Œæé«˜äº†å›¾åƒçš„é²æ£’æ€§å’Œæ„ŸçŸ¥è´¨é‡ã€‚|
|ğŸ“ æ›´æ–°|GenHancer: Imperfect Generative Models are Secretly Strong Vision-Centric Enhancers|GenHancerï¼šä¸å®Œç¾çš„ç”Ÿæˆæ¨¡å‹å®é™…ä¸Šæ˜¯ç§˜å¯†å¼ºå¤§çš„è§†è§‰å¢å¼ºå™¨|Shijie Ma, Yuying Ge, Teng Wang, Yuxin Guo, Yixiao Ge, Ying Shan|<http://arxiv.org/pdf/2503.19480v2>|GenHanceré€šè¿‡ä¼˜åŒ–ç”Ÿæˆæ¨¡å‹æ¡ä»¶å’Œä½¿ç”¨è½»é‡çº§é™å™ªå™¨ï¼Œæœ‰æ•ˆæå‡äº†è§†è§‰è¡¨å¾å¢å¼ºèƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|AdaHuman: Animatable Detailed 3D Human Generation with Compositional Multiview Diffusion|AdaHumanï¼šåŸºäºç»„åˆå¤šè§†å›¾æ‰©æ•£çš„å¯åŠ¨è¯¦ç»†3Däººä½“ç”Ÿæˆ|Yangyi Huang, Ye Yuan, Xueting Li, Jan Kautz, Umar Iqbal|<http://arxiv.org/pdf/2505.24877v1>|AdaHumané€šè¿‡ç»„åˆå¤šè§†è§’æ‰©æ•£æ¨¡å‹å’Œ3DGSç»†åŒ–æ¨¡å—ï¼Œå®ç°äº†ä»å•å¼ å›¾ç‰‡ç”Ÿæˆé«˜è´¨é‡ã€å¯åŠ¨ç”»çš„3Däºº...|
|ğŸ†• å‘å¸ƒ|GenSpace: Benchmarking Spatially-Aware Image Generation|ç©ºé—´æ„ŸçŸ¥å›¾åƒç”ŸæˆåŸºå‡†ï¼šGenSpace|Zehan Wang, Jiayang Xu, Ziang Zhang, Tianyu Pan, Chao Du, Hengshuang Zhao, Zhou Zhao|<http://arxiv.org/pdf/2505.24870v1>|æå‡ºGenSpaceè¯„ä¼°æ¡†æ¶ï¼Œæ­ç¤ºAIå›¾åƒç”Ÿæˆåœ¨ç©ºé—´æ„ŸçŸ¥ä¸Šçš„å±€é™æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|ReasonGen-R1: CoT for Autoregressive Image generation models through SFT and RL|ReasonGen-R1ï¼šé€šè¿‡SFTå’ŒRLå®ç°è‡ªå›å½’å›¾åƒç”Ÿæˆæ¨¡å‹çš„CoT|Yu Zhang, Yunqi Li, Yifan Yang, Rui Wang, Yuqing Yang, Dai Qi, Jianmin Bao, Dongdong Chen .etc.|<http://arxiv.org/pdf/2505.24875v1>|é€šè¿‡ç»“åˆæ€ç»´é“¾æ¨ç†å’Œå¼ºåŒ–å­¦ä¹ ï¼ŒReasonGen-R1æ˜¾è‘—æå‡äº†è‡ªå›å½’å›¾åƒç”Ÿæˆæ¨¡å‹çš„ç”Ÿæˆè´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|MiniMax-Remover: Taming Bad Noise Helps Video Object Removal|æœ€å°-æœ€å¤§ç§»é™¤å™¨ï¼šé©¯æœä¸è‰¯å™ªå£°æœ‰åŠ©äºè§†é¢‘ç‰©ä½“å»é™¤|Bojia Zi, Weixuan Peng, Xianbiao Qi, Jianan Wang, Shihao Zhao, Rong Xiao, Kam-Fai Wong|<http://arxiv.org/pdf/2505.24873v1>|MiniMax-Removeré€šè¿‡ç®€åŒ–æ¨¡å‹å’Œä¼˜åŒ–ç­–ç•¥ï¼Œå®ç°äº†é«˜æ•ˆä¸”é«˜è´¨é‡çš„è§†é¢‘ç‰©ä½“å»é™¤ã€‚|
|ğŸ†• å‘å¸ƒ|Draw ALL Your Imagine: A Holistic Benchmark and Agent Framework for Complex Instruction-based Image Generation|ç»˜åˆ¶æ‰€æœ‰ä½ çš„æƒ³è±¡ï¼šå¤æ‚æŒ‡ä»¤å›¾åƒç”Ÿæˆçš„å…¨é¢åŸºå‡†å’Œä»£ç†æ¡†æ¶|Yucheng Zhou, Jiahao Yuan, Qianning Wang|<http://arxiv.org/pdf/2505.24787v1>|[ä»£ç ](https://github.com/yczhou001/LongBench-T2I.); æ„å»ºäº†LongBench-T2IåŸºå‡†å’ŒPlan2Genæ¡†æ¶ï¼Œä»¥è¯„ä¼°å’Œä¿ƒè¿›å¤æ‚æŒ‡ä»¤é©±åŠ¨çš„å›¾åƒç”Ÿæˆã€‚|
|ğŸ†• å‘å¸ƒ|DreamDance: Animating Character Art via Inpainting Stable Gaussian Worlds|æ¢¦èˆï¼šé€šè¿‡ä¿®å¤ç¨³å®šé«˜æ–¯ä¸–ç•ŒåŠ¨ç”»è§’è‰²è‰ºæœ¯|Jiaxu Zhang, Xianfang Zeng, Xin Chen, Wei Zuo, Gang Yu, Guosheng Lin, Zhigang Tu|<http://arxiv.org/pdf/2505.24733v1>|DreamDanceé€šè¿‡ç»“åˆåœºæ™¯å’Œå§¿æ€æ„ŸçŸ¥çš„ä¿®å¤æŠ€æœ¯ï¼Œå®ç°äº†ç¨³å®šã€è¿è´¯çš„è§’è‰²åŠ¨ç”»ã€‚|
|ğŸ“ æ›´æ–°|HEIE: MLLM-Based Hierarchical Explainable AIGC Image Implausibility Evaluator|HEIEï¼šåŸºäºMLLMçš„åˆ†å±‚å¯è§£é‡ŠAIGCå›¾åƒå¯ä¿¡åº¦è¯„ä¼°å™¨|Fan Yang, Ru Zhen, Jianing Wang, Yanhao Zhang, Haoxiang Chen, Haonan Lu, Sicheng Zhao, Guiguang Ding|<http://arxiv.org/pdf/2411.17261v2>|[ä»£ç ](https://yfthu.github.io/HEIE); æå‡ºäº†ä¸€ç§åŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„å±‚æ¬¡åŒ–å¯è§£é‡ŠAIGCå›¾åƒå¯ä¿¡åº¦è¯„ä¼°æ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³å›¾åƒè´¨é‡é—®é¢˜å’Œå¯è§£é‡Š...|
|ğŸ†• å‘å¸ƒ|TumorGen: Boundary-Aware Tumor-Mask Synthesis with Rectified Flow Matching|è‚¿ç˜¤åŸºå› ï¼šåŸºäºè¾¹ç•Œæ„ŸçŸ¥çš„è‚¿ç˜¤æ©ç åˆæˆä¸æ ¡æ­£æµåŒ¹é…|Shengyuan Liu, Wenting Chen, Boyun Zheng, Wentao Pan, Xiang Li, Yixuan Yuan|<http://arxiv.org/pdf/2505.24687v1>|TumorGené€šè¿‡è¾¹ç•Œæ„ŸçŸ¥å’Œé«˜æ•ˆåŒ¹é…æŠ€æœ¯ï¼Œå®ç°äº†é«˜æ•ˆä¸”é€¼çœŸçš„è‚¿ç˜¤æ•°æ®åˆæˆã€‚|
|ğŸ“ æ›´æ–°|DCTdiff: Intriguing Properties of Image Generative Modeling in the DCT Space|DCTdiffï¼šDCTç©ºé—´ä¸­å›¾åƒç”Ÿæˆå»ºæ¨¡çš„æœ‰è¶£ç‰¹æ€§|Mang Ning, Mingxiao Li, Jianlin Su, Haozhe Jia, Lanmiao Liu, Martin BeneÅ¡, Wenshuo Chen, Albert Ali Salah .etc.|<http://arxiv.org/pdf/2412.15032v2>|[ä»£ç ](https://github.com/forever208/DCTdiff.); DCTdiffé€šè¿‡åœ¨DCTç©ºé—´å»ºæ¨¡å›¾åƒï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆè´¨é‡å’Œè®­ç»ƒæ•ˆç‡ï¼ŒåŒæ—¶æ­ç¤ºäº†å›¾åƒå»ºæ¨¡çš„æœ‰è¶£æ€§è´¨ã€‚|
|ğŸ“ æ›´æ–°|AnimeGamer: Infinite Anime Life Simulation with Next Game State Prediction|ã€ŠAnimeGamerï¼šåŸºäºä¸‹ä¸€æ¸¸æˆçŠ¶æ€é¢„æµ‹çš„æ— å°½åŠ¨æ¼«ç”Ÿæ´»æ¨¡æ‹Ÿã€‹|Junhao Cheng, Yuying Ge, Yixiao Ge, Jing Liao, Ying Shan|<http://arxiv.org/pdf/2504.01014v2>|[ä»£ç ](https://github.com/TencentARC/AnimeGamer.); AnimeGameré€šè¿‡é¢„æµ‹ä¸‹ä¸€æ¸¸æˆçŠ¶æ€ï¼Œå®ç°äº†å…·æœ‰åŠ¨æ€åŠ¨ç”»å’Œè¯­å¢ƒä¸€è‡´æ€§çš„æ— é™åŠ¨æ¼«ç”Ÿæ´»æ¨¡æ‹Ÿã€‚|
|ğŸ“ æ›´æ–°|TheaterGen: Character Management with LLM for Consistent Multi-turn Image Generation|å‰§é™¢ç”Ÿæˆï¼šä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œä¸€è‡´çš„å¤šè½®å›¾åƒç”Ÿæˆçš„äººç‰©ç®¡ç†|Junhao Cheng, Baiqiao Yin, Kaixin Cai, Minbin Huang, Hanhui Li, Yuxin He, Xi Lu, Yue Li .etc.|<http://arxiv.org/pdf/2404.18919v2>|TheaterGené€šè¿‡æ•´åˆLLMå’ŒT2Iæ¨¡å‹ï¼Œå®ç°å¤šè½®å›¾åƒç”Ÿæˆï¼Œæ˜¾è‘—æå‡è¯­ä¹‰å’Œä¸Šä¸‹æ–‡ä¸€è‡´æ€§ã€‚|
|ğŸ“ æ›´æ–°|DiffDecompose: Layer-Wise Decomposition of Alpha-Composited Images via Diffusion Transformers|DiffDecomposeï¼šé€šè¿‡æ‰©æ•£å˜æ¢è¿›è¡Œé€å±‚åˆ†è§£çš„Alphaåˆæˆå›¾åƒ|Zitong Wang, Hang Zhao, Qianyu Zhou, Xuequan Lu, Xiangtai Li, Yiren Song|<http://arxiv.org/pdf/2505.21541v2>|[ä»£ç ](https://github.com/Wangzt1121/DiffDecompose.); æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒåˆ†è§£æ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†åŠé€æ˜å±‚åˆ†è§£éš¾é¢˜ã€‚|
|ğŸ“ æ›´æ–°|GPT4Point: A Unified Framework for Point-Language Understanding and Generation|GPT4Pointï¼šç‚¹äº‘-è¯­è¨€ç†è§£å’Œç”Ÿæˆç»Ÿä¸€æ¡†æ¶|Zhangyang Qi, Ye Fang, Zeyi Sun, Xiaoyang Wu, Tong Wu, Jiaqi Wang, Dahua Lin, Hengshuang Zhao|<http://arxiv.org/pdf/2312.02980v2>|æå‡ºGPT4Pointï¼Œä¸€ç§ç»Ÿä¸€3Dç‚¹äº‘è¯­è¨€ç†è§£å’Œç”Ÿæˆæ¡†æ¶ï¼Œçªç ´MLLMåœ¨3Dç†è§£ä¸Šçš„å±€é™ã€‚|
|ğŸ†• å‘å¸ƒ|UniGeo: Taming Video Diffusion for Unified Consistent Geometry Estimation|UniGeoï¼šé©¯æœè§†é¢‘æ‰©æ•£ä»¥å®ç°ç»Ÿä¸€ä¸€è‡´å‡ ä½•ä¼°è®¡|Yang-Tian Sun, Xin Yu, Zehuan Huang, Yi-Hua Huang, Yuan-Chen Guo, Ziyi Yang, Yan-Pei Cao, Xiaojuan Qi|<http://arxiv.org/pdf/2505.24521v1>|åˆ©ç”¨è§†é¢‘ç”Ÿæˆæ¨¡å‹å†…åœ¨ä¸€è‡´æ€§ï¼Œå®ç°è·¨å¸§å‡ ä½•å±æ€§ä¸€è‡´ä¼°è®¡ã€‚|
|ğŸ†• å‘å¸ƒ|Reason-SVG: Hybrid Reward RL for Aha-Moments in Vector Graphics Generation|åŸå› -SVGï¼šæ··åˆå¥–åŠ±å¼ºåŒ–å­¦ä¹ åœ¨çŸ¢é‡å›¾å½¢ç”Ÿæˆä¸­çš„â€œå•Šå“ˆâ€æ—¶åˆ»|Ximing Xing, Yandong Guan, Jing Zhang, Dong Xu, Qian Yu|<http://arxiv.org/pdf/2505.24499v1>|Reason-SVGé€šè¿‡â€œç»˜å›¾æ€ç»´â€å’Œæ··åˆå¥–åŠ±å¼ºåŒ–å­¦ä¹ ï¼Œæ˜¾è‘—æå‡äº†LLMç”Ÿæˆé«˜è´¨é‡SVGçš„èƒ½åŠ›ã€‚|
|ğŸ“ æ›´æ–°|CAE-Net: Generalized Deepfake Image Detection using Convolution and Attention Mechanisms with Spatial and Frequency Domain Features|CAE-Netï¼šåŸºäºå·ç§¯å’Œæ³¨æ„åŠ›æœºåˆ¶ï¼Œç»“åˆç©ºé—´å’Œé¢‘åŸŸç‰¹å¾çš„é€šç”¨æ·±åº¦ä¼ªé€ å›¾åƒæ£€æµ‹|Kafi Anan, Anindya Bhattacharjee, Ashir Intesher, Kaidul Islam, Abrar Assaeem Fuad, Utsab Saha, Hafiz Imtiaz|<http://arxiv.org/pdf/2502.10682v2>|æå‡ºäº†ä¸€ç§åŸºäºå·ç§¯å’Œæ³¨æ„åŠ›æœºåˆ¶çš„æ·±åº¦ä¼ªé€ å›¾åƒæ£€æµ‹æ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜å¹¶æé«˜äº†æ£€æµ‹å‡†ç¡®ç‡ã€‚|
|ğŸ†• å‘å¸ƒ|SPPSFormer: High-quality Superpoint-based Transformer for Roof Plane Instance Segmentation from Point Clouds|SPPSFormerï¼šåŸºäºSuperpointçš„é«˜è´¨é‡Transformerï¼Œç”¨äºç‚¹äº‘ä¸­çš„å±‹é¡¶å¹³é¢å®ä¾‹åˆ†å‰²|Cheng Zeng, Xiatian Qi, Chi Chen, Kai Sun, Wangle Zhang, Yuxuan Liu, Yan Meng, Bisheng Yang|<http://arxiv.org/pdf/2505.24475v1>|æå‡ºäº†ä¸€ç§åŸºäºé«˜è´¨é‡Superpointå’ŒTransformerçš„å±‹é¡¶å¹³é¢å®ä¾‹åˆ†å‰²æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†åˆ†...|
|ğŸ†• å‘å¸ƒ|Graph Flow Matching: Enhancing Image Generation with Neighbor-Aware Flow Fields|å›¾æµåŒ¹é…ï¼šé€šè¿‡é‚»åŸŸæ„ŸçŸ¥æµåœºå¢å¼ºå›¾åƒç”Ÿæˆ|Md Shahriar Rahim Siddiqui, Moshe Eliasof, Eldad Haber|<http://arxiv.org/pdf/2505.24434v1>|æå‡ºGraph Flow Matchingï¼Œé€šè¿‡èšåˆé‚»åŸŸä¿¡æ¯æå‡å›¾åƒç”Ÿæˆè´¨é‡ã€‚|
|ğŸ“ æ›´æ–°|CraftsMan3D: High-fidelity Mesh Generation with 3D Native Generation and Interactive Geometry Refiner|CraftsMan3Dï¼šåŸºäº3DåŸç”Ÿç”Ÿæˆå’Œäº¤äº’å¼å‡ ä½•ç²¾ä¿®çš„é«˜ä¿çœŸç½‘æ ¼ç”Ÿæˆ|Weiyu Li, Jiarui Liu, Hongyu Yan, Rui Chen, Yixun Liang, Xuelin Chen, Ping Tan, Xiaoxiao Long|<http://arxiv.org/pdf/2405.14979v4>|[ä»£ç ](https://github.com/wyysf-98/CraftsMan); CraftsMan3Dé€šè¿‡3DåŸç”Ÿç”Ÿæˆå’Œäº¤äº’å¼å‡ ä½•ç»†åŒ–ï¼Œå®ç°äº†é«˜ä¿çœŸ3Dæ¨¡å‹çš„é«˜æ•ˆç”Ÿæˆå’Œç»†èŠ‚ä¼˜åŒ–ã€‚|
|ğŸ†• å‘å¸ƒ|InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing|InteractAnythingï¼šé€šè¿‡LLMåé¦ˆå’Œç‰©ä½“åŠŸèƒ½è§£æå®ç°é›¶æ ·æœ¬äººæœºäº¤äº’åˆæˆ|Jinlu Zhang, Yixin Chen, Zan Wang, Jie Yang, Yizhou Wang, Siyuan Huang|<http://arxiv.org/pdf/2505.24315v1>|æå‡ºäº†ä¸€ç§æ— éœ€ç‰¹å®šæ•°æ®é›†è®­ç»ƒçš„é›¶æ ·æœ¬3Däºº-ç‰©äº¤äº’ç”Ÿæˆæ¡†æ¶ï¼Œé€šè¿‡LLMåé¦ˆå’Œç‰©ä½“å±æ€§è§£æå®ç°è‡ªç„¶äº¤äº’...|
|ğŸ†• å‘å¸ƒ|Category-aware EEG image generation based on wavelet transform and contrast semantic loss|åŸºäºå°æ³¢å˜æ¢å’Œå¯¹æ¯”è¯­ä¹‰æŸå¤±çš„ç±»åˆ«æ„ŸçŸ¥è„‘ç”µå›¾å›¾åƒç”Ÿæˆ|Enshang Zhang, Zhicheng Zhang, Takashi Hanakawa|<http://arxiv.org/pdf/2505.24301v1>|[ä»£ç ](https://github.com/zes0v0inn/DWT_EEG_Reconstruction); æå‡ºäº†ä¸€ç§åŸºäºæ³¢å˜æ¢å’Œå¯¹æ¯”è¯­ä¹‰æŸå¤±çš„Transformerç¼–ç å™¨ï¼Œæ˜¾è‘—æå‡äº†EEGä¿¡å·åˆ°å›¾åƒçš„ç”Ÿæˆå’Œ...|
|ğŸ†• å‘å¸ƒ|Interactive Video Generation via Domain Adaptation|é€šè¿‡é¢†åŸŸè‡ªé€‚åº”çš„äº¤äº’å¼è§†é¢‘ç”Ÿæˆ|Ishaan Rawal, Suryansh Kumar|<http://arxiv.org/pdf/2505.24253v1>|é€šè¿‡å¼•å…¥åŸŸé€‚åº”å’Œæ—¶åºå…ˆéªŒï¼Œè¯¥è®ºæ–‡æå‡äº†äº¤äº’å¼è§†é¢‘ç”Ÿæˆä¸­è¿åŠ¨è½¨è¿¹æ§åˆ¶å’Œè§†è§‰è´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|LTM3D: Bridging Token Spaces for Conditional 3D Generation with Auto-Regressive Diffusion Framework|LTM3Dï¼šåˆ©ç”¨è‡ªå›å½’æ‰©æ•£æ¡†æ¶è¿æ¥æ ‡è®°ç©ºé—´ä»¥å®ç°æ¡ä»¶3Dç”Ÿæˆ|Xin Kang, Zihan Zheng, Lei Chu, Yue Gao, Jiahao Li, Hao Pan, Xuejin Chen, Yan Lu|<http://arxiv.org/pdf/2505.24245v1>|LTM3Dé€šè¿‡ç»“åˆæ‰©æ•£å’Œè‡ªå›å½’æ¨¡å‹ï¼Œå®ç°äº†æ¡ä»¶3Då½¢çŠ¶ç”Ÿæˆï¼Œæé«˜äº†ç”Ÿæˆå½¢çŠ¶çš„å‡†ç¡®æ€§å’Œçµæ´»æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Unleashing High-Quality Image Generation in Diffusion Sampling Using Second-Order Levenberg-Marquardt-Langevin|åˆ©ç”¨äºŒé˜¶Levenberg-Marquardt-Langeviné‡Šæ”¾æ‰©æ•£é‡‡æ ·ä¸­çš„é«˜è´¨é‡å›¾åƒç”Ÿæˆ|Fangyikang Wang, Hubery Yin, Lei Qian, Yinan Li, Shaobin Zhuang, Huminhao Zhu, Yilin Zhang, Yanlong Tang .etc.|<http://arxiv.org/pdf/2505.24222v1>|å¼•å…¥Levenberg-Marquardt-Langevinæ–¹æ³•ï¼Œæ˜¾è‘—æå‡æ‰©æ•£æ¨¡å‹å›¾åƒç”Ÿæˆè´¨é‡ã€‚|
|ğŸ“ æ›´æ–°|dc-GAN: Dual-Conditioned GAN for Face Demorphing From a Single Morph|åŒæ¡ä»¶ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼šä»å•ä¸€å½¢æ€è¿›è¡Œäººè„¸å»å½¢å˜|Nitish Shukla, Arun Ross|<http://arxiv.org/pdf/2411.14494v4>|æå‡ºdc-GANï¼Œä¸€ç§åŸºäºå½¢æ€å›¾åƒå’ŒåµŒå…¥çš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼Œæœ‰æ•ˆè§£å†³äººè„¸å»å˜å½¢é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|Reasoning Can Hurt the Inductive Abilities of Large Language Models|æ¨ç†å¯èƒ½æŸå®³å¤§å‹è¯­è¨€æ¨¡å‹çš„å½’çº³èƒ½åŠ›|Haibo Jin, Peiyan Zhang, Man Luo, Haohan Wang|<http://arxiv.org/pdf/2505.24225v1>|ç ”ç©¶å‘ç°ï¼Œè¿‡åº¦æ¨ç†ä¼šæŸå®³å¤§å‹è¯­è¨€æ¨¡å‹çš„å½’çº³èƒ½åŠ›ï¼Œå¹¶æå‡ºç»“æ„åŒ–å¹²é¢„æ¥ä¼˜åŒ–æ¨ç†æ­¥éª¤ã€‚|
|ğŸ“ æ›´æ–°|Diagram-Driven Course Questions Generation|åŸºäºå›¾è¡¨çš„è¯¾ç¨‹é—®é¢˜ç”Ÿæˆ|Xinyu Zhang, Lingling Zhang, Yanrui Wu, Muye Huang, Wenjun Wu, Bo Li, Shaowei Wang, Basura Fernando .etc.|<http://arxiv.org/pdf/2411.17771v4>|æå‡ºDDCQGä»»åŠ¡ï¼Œæ„å»ºDiagramQGæ•°æ®é›†ï¼Œå¹¶è®¾è®¡HKI-DDCQGæ¡†æ¶ç”Ÿæˆè¯¾ç¨‹ç›¸å…³çš„é—®é¢˜ã€‚|
|ğŸ“ æ›´æ–°|Show-1: Marrying Pixel and Latent Diffusion Models for Text-to-Video Generation|å±•ç¤º-1ï¼šå°†åƒç´ å’Œæ½œåœ¨æ‰©æ•£æ¨¡å‹ç»“åˆç”¨äºæ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆ|David Junhao Zhang, Jay Zhangjie Wu, Jia-Wei Liu, Rui Zhao, Lingmin Ran, Yuchao Gu, Difei Gao, Mike Zheng Shou|<http://arxiv.org/pdf/2309.15818v3>|[ä»£ç ](https://github.com/showlab/Show-1.); æå‡ºShow-1æ··åˆæ¨¡å‹ï¼Œç»“åˆåƒç´ å’Œæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œé«˜æ•ˆç”Ÿæˆç²¾ç¡®æ–‡æœ¬-è§†é¢‘åŒ¹é…çš„é«˜æ¸…è§†é¢‘ã€‚|
|ğŸ“ æ›´æ–°|MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation|MTVCrafterï¼šé¢å‘å¼€æ”¾ä¸–ç•Œäººç±»å›¾åƒåŠ¨ç”»çš„4Dè¿åŠ¨æ ‡è®°åŒ–|Yanbo Ding, Xirui Hu, Zhizhi Guo, Chi Zhang, Yali Wang|<http://arxiv.org/pdf/2505.10238v4>|[ä»£ç ](https://github.com/DINGYANB/MTVCrafter.); MTVCrafteré€šè¿‡ç›´æ¥å»ºæ¨¡4Dè¿åŠ¨åºåˆ—ï¼Œä¸ºå¼€æ”¾ä¸–ç•Œäººç±»å›¾åƒåŠ¨ç”»æä¾›æ›´çµæ´»å’Œå¯æ§çš„è§£å†³æ–¹æ¡ˆã€‚|
|ğŸ“ æ›´æ–°|Theorem-Validated Reverse Chain-of-Thought Problem Generation for Geometric Reasoning|å®šç†éªŒè¯çš„é€†å‘æ€ç»´é—®é¢˜ç”Ÿæˆç”¨äºå‡ ä½•æ¨ç†|Linger Deng, Linghao Zhu, Yuliang Liu, Yu Wang, Qunyi Xie, Jingjing Wu, Gang Zhang, Yingying Zhu .etc.|<http://arxiv.org/pdf/2410.17885v4>|æå‡ºTR-CoTæ¡†æ¶ï¼Œé€šè¿‡å®šç†éªŒè¯åå‘æ¨ç†ç”Ÿæˆå‡ ä½•æ¨ç†é—®é¢˜ï¼Œæå‡æ¨¡å‹å‡ ä½•æ¨ç†èƒ½åŠ›ã€‚|


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|The Structural Safety Generalization Problem|ç»“æ„å®‰å…¨æ³›åŒ–é—®é¢˜|Julius Broomfield, Tom Gibbs, Ethan Kosak-Hine, George Ingebretsen, Tia Nasir, Jason Zhang, Reihaneh Iranmanesh, Sara Pieri .etc.|<http://arxiv.org/pdf/2504.09712v2>|æå‡ºç»“æ„å®‰å…¨æ³›åŒ–é—®é¢˜è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡ç»“æ„é‡å†™é˜²æŠ¤æ æå‡AIå®‰å…¨ã€‚|
|ğŸ†• å‘å¸ƒ|ViStoryBench: Comprehensive Benchmark Suite for Story Visualization|ViStoryBenchï¼šæ•…äº‹å¯è§†åŒ–å…¨é¢åŸºå‡†å¥—ä»¶|Cailin Zhuang, Ailin Huang, Wei Cheng, Jingwei Wu, Yaoqi Hu, Jiaqi Liao, Zhewei Huang, Hongyuan Wang .etc.|<http://arxiv.org/pdf/2505.24862v1>|æ„å»ºäº†ViStoryBenchåŸºå‡†ï¼Œå…¨é¢è¯„ä¼°æ•…äº‹å¯è§†åŒ–æ¨¡å‹çš„æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|V2SFlow: Video-to-Speech Generation with Speech Decomposition and Rectified Flow|V2SFlowï¼šåŸºäºè¯­éŸ³åˆ†è§£å’Œæ ¡æ­£æµçš„è§†é¢‘åˆ°è¯­éŸ³ç”Ÿæˆ|Jeongsoo Choi, Ji-Hoon Kim, Jinyu Li, Joon Son Chung, Shujie Liu|<http://arxiv.org/pdf/2411.19486v2>|[ä»£ç ](https://github.com/kaistmm/V2SFlow); V2SFlowé€šè¿‡åˆ†è§£è¯­éŸ³ä¿¡å·å¹¶ä½¿ç”¨Transformeræ¶æ„çš„æµåŒ¹é…è§£ç å™¨ï¼Œä»æ— å£°è§†é¢‘ä¸­ç›´æ¥ç”Ÿæˆè‡ª...|
|ğŸ†• å‘å¸ƒ|LegalEval-Q: A New Benchmark for The Quality Evaluation of LLM-Generated Legal Text|LegalEval-Qï¼šç”¨äºè¯„ä¼°LLMç”Ÿæˆæ³•å¾‹æ–‡æœ¬è´¨é‡çš„æ–°åŸºå‡†|Li yunhan, Wu gengshen|<http://arxiv.org/pdf/2505.24826v1>|[ä»£ç ](https://github.com/lyxx3rd/LegalEval-Q.); æå‡ºLegalEval-QåŸºå‡†ï¼Œè¯„ä¼°LLMç”Ÿæˆæ³•å¾‹æ–‡æœ¬è´¨é‡ï¼Œæ­ç¤ºè®­ç»ƒæ•°æ®ä¼˜åŒ–å±€é™ã€‚|
|ğŸ†• å‘å¸ƒ|Reinforcing Video Reasoning with Focused Thinking|å¼ºåŒ–è§†é¢‘æ¨ç†çš„ä¸“æ³¨æ€è€ƒ|Jisheng Dang, Jingze Wu, Teng Wang, Xuanhui Lin, Nannan Zhu, Hongbo Chen, Wei-Shi Zheng, Meng Wang .etc.|<http://arxiv.org/pdf/2505.24718v1>|[ä»£ç ](https://github.com/longmalongma/TW-GRPO); æå‡ºTW-GRPOæ¡†æ¶ï¼Œé€šè¿‡èšç„¦æ€ç»´å’Œå¯†é›†å¥–åŠ±ç²’åº¦æå‡è§†é¢‘æ¨ç†çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚|
|ğŸ“ æ›´æ–°|Efficient Universal Goal Hijacking with Semantics-guided Prompt Organization|é«˜æ•ˆè¯­ä¹‰å¼•å¯¼çš„æç¤ºç»„ç»‡é€šç”¨ç›®æ ‡åŠ«æŒ|Yihao Huang, Chong Wang, Xiaojun Jia, Qing Guo, Felix Juefei-Xu, Jian Zhang, Geguang Pu, Yang Liu|<http://arxiv.org/pdf/2405.14189v2>|æå‡ºä¸€ç§é«˜æ•ˆè¯­ä¹‰å¼•å¯¼çš„æç¤ºç»„ç»‡æ–¹æ³•ï¼Œå®ç°ä¾¿æ·çš„é€šç”¨ç›®æ ‡åŠ«æŒæ”»å‡»ã€‚|
|ğŸ“ æ›´æ–°|AutoStudio: Crafting Consistent Subjects in Multi-turn Interactive Image Generation|AutoStudioï¼šæ„å»ºå¤šè½®äº¤äº’å¼å›¾åƒç”Ÿæˆä¸­çš„ç»Ÿä¸€ä¸»é¢˜|Junhao Cheng, Xi Lu, Hanhui Li, Khun Loun Zai, Baiqiao Yin, Yuhao Cheng, Yiqiang Yan, Xiaodan Liang|<http://arxiv.org/pdf/2406.01388v3>|AutoStudioé€šè¿‡å¤šæ™ºèƒ½ä½“æ¡†æ¶å®ç°å¤šè½®äº¤äº’å¼å›¾åƒç”Ÿæˆï¼Œä¿æŒä¸»é¢˜ä¸€è‡´æ€§å¹¶æå‡ç”Ÿæˆè´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|VUDG: A Dataset for Video Understanding Domain Generalization|è§†é¢‘ç†è§£é¢†åŸŸæ³›åŒ–æ•°æ®é›†ï¼šVUDG|Ziyi Wang, Zhi Gao, Boxuan Yu, Zirui Dai, Yuxiang Song, Qingyuan Lu, Jin Chen, Xinxiao Wu|<http://arxiv.org/pdf/2505.24346v1>|æ„å»ºäº†VUDGæ•°æ®é›†ï¼Œè¯„ä¼°è§†é¢‘ç†è§£ä¸­çš„é¢†åŸŸæ³›åŒ–èƒ½åŠ›ï¼Œæ­ç¤ºæ¨¡å‹å¯¹æ•°æ®åˆ†å¸ƒå˜åŒ–çš„é²æ£’æ€§å·®å¼‚ã€‚|
|ğŸ†• å‘å¸ƒ|Threading Keyframe with Narratives: MLLMs as Strong Long Video Comprehenders|çº¿ç¨‹å…³é”®å¸§ä¸å™äº‹ï¼šä½œä¸ºå¼ºå¤§é•¿è§†é¢‘ç†è§£è€…çš„MLLMs|Bo Fang, Wenhao Wu, Qiangqiang Wu, Yuxin Song, Antoni B. Chan|<http://arxiv.org/pdf/2505.24158v1>|æå‡ºNar-KFCæ¨¡å—ï¼Œé€šè¿‡å…³é”®å¸§ä¸å™äº‹ç»“åˆï¼Œæœ‰æ•ˆæå‡é•¿è§†é¢‘ç†è§£èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|ComposeAnything: Composite Object Priors for Text-to-Image Generation|ã€ŠComposeAnythingï¼šç”¨äºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„å¤åˆå¯¹è±¡å…ˆéªŒã€‹|Zeeshan Khan, Shizhe Chen, Cordelia Schmid|<http://arxiv.org/pdf/2505.24086v1>|ComposeAnythingé€šè¿‡å¼•å…¥2.5Dè¯­ä¹‰å¸ƒå±€ï¼Œæ˜¾è‘—æå‡äº†æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­å¤æ‚ç‰©ä½“ç»„åˆçš„ç”Ÿæˆ...|


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|$\textit{Revelio}$: Interpreting and leveraging semantic information in diffusion models|Revelioï¼šåœ¨æ‰©æ•£æ¨¡å‹ä¸­è§£é‡Šå’Œåˆ©ç”¨è¯­ä¹‰ä¿¡æ¯|Dahye Kim, Xavier Thomas, Deepti Ghadiyaram|<http://arxiv.org/pdf/2411.16725v2>|[ä»£ç ](https://github.com/revelio-diffusion/revelio); æ­ç¤ºå¹¶åˆ©ç”¨æ‰©æ•£æ¨¡å‹ä¸­çš„è¯­ä¹‰ä¿¡æ¯ï¼Œé€šè¿‡kç¨€ç–è‡ªåŠ¨ç¼–ç å™¨æå‡æ¨¡å‹å¯è§£é‡Šæ€§ã€‚|
|ğŸ“ æ›´æ–°|Autoregression-free video prediction using diffusion model for mitigating error propagation|æ— è‡ªå›å½’æ‰©æ•£æ¨¡å‹ç”¨äºç¼“è§£è¯¯å·®ä¼ æ’­çš„è§†é¢‘é¢„æµ‹|Woonho Ko, Jin Bok Park, Il Yong Chun|<http://arxiv.org/pdf/2505.22111v2>|æå‡ºARFreeè§†é¢‘é¢„æµ‹æ¡†æ¶ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹é¿å…è¯¯å·®ä¼ æ’­ï¼Œæå‡é•¿æœŸè§†é¢‘é¢„æµ‹æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models|æ¸è¿›å¼æç¤ºç»†åŒ–ä»¥æé«˜æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„å¯¹é½|Ketan Suhaas Saichandran, Xavier Thomas, Prakhar Kaushik, Deepti Ghadiyaram|<http://arxiv.org/pdf/2503.17794v4>|æå‡ºSCoPEæ–¹æ³•ï¼Œé€šè¿‡é€æ­¥ç»†åŒ–è¾“å…¥æç¤ºï¼Œæå‡æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„å¯¹é½ç²¾åº¦ã€‚|
|ğŸ“ æ›´æ–°|DiffusionTrend: A Minimalist Approach to Virtual Fashion Try-On|æ‰©æ•£è¶‹åŠ¿ï¼šè™šæ‹Ÿè¯•è¡£çš„æç®€æ–¹æ³•|Wengyi Zhan, Mingbao Lin, Shuicheng Yan, Rongrong Ji|<http://arxiv.org/pdf/2412.14465v2>|DiffusionTrendé€šè¿‡æ— éœ€é‡æ–°è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œå®ç°äº†è™šæ‹Ÿè¯•è¡£çš„ç»†èŠ‚æ•æ‰ä¸é«˜æ•ˆç”Ÿæˆã€‚|
|ğŸ“ æ›´æ–°|On the Design Fundamentals of Diffusion Models: A Survey|å…³äºæ‰©æ•£æ¨¡å‹è®¾è®¡åŸç†çš„ç»¼è¿°|Ziyi Chang, George Alex Koulieris, Hyung Jin Chang, Hubert P. H. Shum|<http://arxiv.org/pdf/2306.04542v4>|è¯¥è®ºæ–‡å…¨é¢ç»¼è¿°äº†æ‰©æ•£æ¨¡å‹è®¾è®¡è¦ç´ ï¼Œä¸ºç»„ä»¶åˆ†æå’Œæ¨¡å‹å®ç°æä¾›ç»†è‡´è§†è§’ã€‚|
|ğŸ“ æ›´æ–°|One-Step is Enough: Sparse Autoencoders for Text-to-Image Diffusion Models|ä¸€æ­¥åˆ°ä½ï¼šç”¨äºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„ç¨€ç–è‡ªç¼–ç å™¨|Viacheslav Surkov, Chris Wendler, Antonio Mari, Mikhail Terekhov, Justin Deschenaux, Robert West, Caglar Gulcehre, David Bau|<http://arxiv.org/pdf/2410.22366v3>|åˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨å­¦ä¹ æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„å¯è§£é‡Šç‰¹å¾ï¼Œæå‡ç†è§£å’Œæ“æ§æ¨¡å‹å†…éƒ¨æœºåˆ¶ã€‚|
|ğŸ“ æ›´æ–°|Image Captioning Evaluation in the Age of Multimodal LLMs: Challenges and Future Perspectives|å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹æ—¶ä»£çš„å›¾åƒæ ‡é¢˜è¯„ä¼°ï¼šæŒ‘æˆ˜ä¸æœªæ¥å±•æœ›|Sara Sarto, Marcella Cornia, Rita Cucchiara|<http://arxiv.org/pdf/2503.14604v2>|åˆ†æäº†å¤šæ¨¡æ€LLMsæ—¶ä»£å›¾åƒæè¿°è¯„ä¼°çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†æ”¹è¿›ç°æœ‰è¯„ä¼°æŒ‡æ ‡å’Œæœªæ¥ç ”ç©¶æ–¹å‘çš„å»ºè®®ã€‚|
|ğŸ†• å‘å¸ƒ|Category-Level 6D Object Pose Estimation in Agricultural Settings Using a Lattice-Deformation Framework and Diffusion-Augmented Synthetic Data|åŸºäºæ™¶æ ¼å˜å½¢æ¡†æ¶å’Œæ‰©æ•£å¢å¼ºåˆæˆæ•°æ®çš„å†œä¸šåœºæ™¯ä¸­ç±»åˆ«çº§6Dç›®æ ‡å§¿æ€ä¼°è®¡|Marios Glytsos, Panagiotis P. Filntisis, George Retsinas, Petros Maragos|<http://arxiv.org/pdf/2505.24636v1>|æå‡ºPLANTPoseï¼Œä¸€ç§åŸºäºRGBè¾“å…¥çš„å†œä¸šåœºæ™¯ä¸­ç±»åˆ«çº§6Då§¿æ€ä¼°è®¡æ¡†æ¶ï¼Œæœ‰æ•ˆå¤„ç†å½¢çŠ¶ã€å¤§å°å’Œçº¹...|
|ğŸ“ æ›´æ–°|MedDiff-FM: A Diffusion-based Foundation Model for Versatile Medical Image Applications|MedDiff-FMï¼šä¸€ç§é€‚ç”¨äºå¤šç§åŒ»å­¦å›¾åƒåº”ç”¨çš„æ‰©æ•£åŸºç¡€æ¨¡å‹|Yongrui Yu, Yannian Gu, Shaoting Zhang, Xiaofan Zhang|<http://arxiv.org/pdf/2410.15432v2>|æå‡ºMedDiff-FMï¼Œä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„é€šç”¨åŒ»å­¦å›¾åƒåº”ç”¨åŸºç¡€æ¨¡å‹ï¼Œè§£å†³å¤šä»»åŠ¡éœ€æ±‚ã€‚|
|ğŸ†• å‘å¸ƒ|SORCE: Small Object Retrieval in Complex Environments|å¤æ‚ç¯å¢ƒä¸­çš„å°ç›®æ ‡æ£€ç´¢ï¼šSORCE|Chunxu Liu, Chi Xie, Xiaxu Chen, Wei Li, Feng Zhu, Rui Zhao, Limin Wang|<http://arxiv.org/pdf/2505.24441v1>|æå‡ºSORCEï¼Œé€šè¿‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å’ŒåŒºåŸŸæç¤ºï¼Œæœ‰æ•ˆæ£€ç´¢å¤æ‚ç¯å¢ƒä¸­çš„å°ç‰©ä½“ã€‚|
|ğŸ†• å‘å¸ƒ|EasyText: Controllable Diffusion Transformer for Multilingual Text Rendering|EasyTextï¼šå¯æ§æ‰©æ•£Transformerçš„å¤šè¯­è¨€æ–‡æœ¬æ¸²æŸ“|Runnan Lu, Yuxuan Zhang, Jiaming Liu, Haofan Wang, Yiren Song|<http://arxiv.org/pdf/2505.24417v1>|EasyTexté€šè¿‡Diffusion Transformerå®ç°å¯æ§å¤šè¯­è¨€æ–‡æœ¬æ¸²æŸ“ï¼Œæ˜¾è‘—æå‡è§†è§‰è´¨...|
|ğŸ“ æ›´æ–°|A Survey on Self-supervised Contrastive Learning for Multimodal Text-Image Analysis|å¤šæ¨¡æ€æ–‡æœ¬-å›¾åƒåˆ†æä¸­è‡ªç›‘ç£å¯¹æ¯”å­¦ä¹ çš„ç»¼è¿°|Asifullah Khan, Laiba Asmatullah, Anza Malik, Shahzaib Khan, Hamna Asif|<http://arxiv.org/pdf/2503.11101v3>|è¯¥è®ºæ–‡ç»¼è¿°äº†è‡ªç›‘ç£å¯¹æ¯”å­¦ä¹ åœ¨æ–‡æœ¬-å›¾åƒåˆ†æä¸­çš„åº”ç”¨ï¼Œæé«˜äº†å›¾åƒç†è§£å’Œæ–‡æœ¬åˆ†æèƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|IRBridge: Solving Image Restoration Bridge with Pre-trained Generative Diffusion Models|IRBridgeï¼šåˆ©ç”¨é¢„è®­ç»ƒç”Ÿæˆæ‰©æ•£æ¨¡å‹è§£å†³å›¾åƒæ¢å¤æ¡¥é—®é¢˜|Hanting Wang, Tao Jin, Wang Lin, Shulei Wang, Hai Huang, Shengpeng Ji, Zhou Zhao|<http://arxiv.org/pdf/2505.24406v1>|IRBridgeé€šè¿‡åˆ©ç”¨é¢„è®­ç»ƒç”Ÿæˆæ¨¡å‹ï¼Œæœ‰æ•ˆè§£å†³äº†å›¾åƒä¿®å¤ä¸­è®¡ç®—æˆæœ¬é«˜å’Œæ€§èƒ½æœ‰é™çš„é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|Grid-LOGAT: Grid Based Local and Global Area Transcription for Video Question Answering|ç½‘æ ¼-LOGATï¼šåŸºäºç½‘æ ¼çš„å±€éƒ¨å’Œå…¨å±€åŒºåŸŸè½¬å½•ç”¨äºè§†é¢‘é—®ç­”|Md Intisar Chowdhury, Kittinun Aukkapinyo, Hiroshi Fujimura, Joo Ann Woo, Wasu Wasusatein, Fadoua Ghourabi|<http://arxiv.org/pdf/2505.24371v1>|Grid-LOGATé€šè¿‡ç»“åˆè§†è§‰è¯­è¨€æ¨¡å‹å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œåœ¨è§†é¢‘é—®ç­”ä¸­å®ç°åŸºäºç½‘æ ¼çš„å±€éƒ¨å’Œå…¨å±€åŒºåŸŸè½¬å½•...|
|ğŸ†• å‘å¸ƒ|DisTime: Distribution-based Time Representation for Video Large Language Models|DisTimeï¼šåŸºäºåˆ†å¸ƒçš„è§†é¢‘å¤§å‹è¯­è¨€æ¨¡å‹çš„æ—¶é—´è¡¨ç¤º|Yingsen Zeng, Zepeng Huang, Yujie Zhong, Chengjian Feng, Jie Hu, Lin Ma, Yang Liu|<http://arxiv.org/pdf/2505.24329v1>|[ä»£ç ](https://github.com/josephzpng/DisTime.); DisTimeé€šè¿‡åˆ›å»ºè¿ç»­æ—¶é—´åµŒå…¥ç©ºé—´å’Œåˆ†å¸ƒå¼æ—¶é—´è§£ç å™¨ï¼Œæœ‰æ•ˆæå‡è§†é¢‘å¤§è¯­è¨€æ¨¡å‹çš„æ—¶é—´ç†è§£èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|Out of Sight, Not Out of Context? Egocentric Spatial Reasoning in VLMs Across Disjoint Frames|ã€Šè§†åŸŸä¹‹å¤–ï¼Œä»å¤„è¯­å¢ƒä¹‹ä¸­ï¼ŸVLMsè·¨æ–­å¸§çš„ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„ç©ºé—´æ¨ç†ã€‹|Sahithya Ravi, Gabriel Sarch, Vibhav Vineet, Andrew D. Wilson, Balasaravanan Thoravi Kumaravel|<http://arxiv.org/pdf/2505.24257v1>|æå‡ºDisjoint-3DQAåŸºå‡†ï¼Œè¯„ä¼°VLMsåœ¨å¤šå¸§åœºæ™¯ä¸­ç†è§£ç‰©ä½“ç©ºé—´å…³ç³»çš„èƒ½åŠ›ã€‚|
|ğŸ“ æ›´æ–°|When Are Concepts Erased From Diffusion Models?|å½“æ¦‚å¿µä»æ‰©æ•£æ¨¡å‹ä¸­è¢«æŠ¹å»æ—¶ï¼Ÿ|Kevin Lu, Nicky Kriplani, Rohit Gandikota, Minh Pham, David Bau, Chinmay Hegde, Niv Cohen|<http://arxiv.org/pdf/2505.17013v4>|æå‡ºè¯„ä¼°æ–¹æ³•ï¼Œæ­ç¤ºæ‰©æ•£æ¨¡å‹ä¸­æ¦‚å¿µæ¶ˆé™¤çš„å…¨é¢æ€§åŠå…¶ä¸é²æ£’æ€§çš„æƒè¡¡ã€‚|
|ğŸ“ æ›´æ–°|T2VUnlearning: A Concept Erasing Method for Text-to-Video Diffusion Models|T2VUnlearningï¼šæ–‡æœ¬åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ¦‚å¿µæ“¦é™¤æ–¹æ³•|Xiaoyu Ye, Songjie Cheng, Yongtao Wang, Yajiao Xiong, Yishen Li|<http://arxiv.org/pdf/2505.17550v2>|[ä»£ç ](https://github.com/VDIGPKU/T2VUnlearning.git); æå‡ºT2VUnlearningæ–¹æ³•ï¼Œæœ‰æ•ˆæ¶ˆé™¤T2Væ¨¡å‹ä¸­ç‰¹å®šæœ‰å®³æ¦‚å¿µï¼ŒåŒæ—¶ä¿æŒå…¶ä»–å†…å®¹ç”Ÿæˆèƒ½åŠ›ã€‚|
|ğŸ“ æ›´æ–°|Masked Autoencoders Are Effective Tokenizers for Diffusion Models|æ©ç è‡ªç¼–ç å™¨æ˜¯æ‰©æ•£æ¨¡å‹æœ‰æ•ˆçš„æ ‡è®°åŒ–å™¨|Hao Chen, Yujin Han, Fangyi Chen, Xiang Li, Yidong Wang, Jindong Wang, Ze Wang, Zicheng Liu .etc.|<http://arxiv.org/pdf/2502.03444v2>|æå‡ºMAETokï¼Œé€šè¿‡æ©ç å»ºæ¨¡çš„è‡ªåŠ¨ç¼–ç å™¨å­¦ä¹ è¯­ä¹‰ä¸°å¯Œçš„æ½œåœ¨ç©ºé—´ï¼Œæ˜¾è‘—æå‡æ‰©æ•£æ¨¡å‹ç”Ÿæˆè´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|Shuffle PatchMix Augmentation with Confidence-Margin Weighted Pseudo-Labels for Enhanced Source-Free Domain Adaptation|åŸºäºç½®ä¿¡åº¦è¾¹è·åŠ æƒä¼ªæ ‡ç­¾çš„Shuffle PatchMixå¢å¼ºç”¨äºå¢å¼ºæ— æºåŸŸé€‚åº”|Prasanna Reddy Pulakurthi, Majid Rabbani, Jamison Heard, Sohail Dianat, Celso M. de Melo, Raghuveer Rao|<http://arxiv.org/pdf/2505.24216v1>|[ä»£ç ](https://github.com/PrasannaPulakurthi/SPM); æå‡ºäº†ä¸€ç§ç»“åˆShuffle PatchMixå¢å¼ºå’Œç½®ä¿¡åº¦åŠ æƒä¼ªæ ‡ç­¾çš„æºå…è´¹åŸŸè‡ªé€‚åº”æ–°æ–¹æ³•ï¼Œæ˜¾è‘—æå‡...|
|ğŸ†• å‘å¸ƒ|STORK: Improving the Fidelity of Mid-NFE Sampling for Diffusion and Flow Matching Models|STORKï¼šæå‡æ‰©æ•£å’ŒæµåŒ¹é…æ¨¡å‹çš„ä¸­é—´NFEé‡‡æ ·çš„ä¿çœŸåº¦|Zheng Tan, Weizhen Wang, Andrea L. Bertozzi, Ernest K. Ryu|<http://arxiv.org/pdf/2505.24210v1>|[ä»£ç ](https://github.com/ZT220501/STORK.); æå‡ºSTORKæ–¹æ³•ï¼Œæœ‰æ•ˆæå‡ä¸­NFEé‡‡æ ·åœ¨æ‰©æ•£å’ŒæµåŒ¹é…æ¨¡å‹ä¸­çš„å›¾åƒç”Ÿæˆè´¨é‡ã€‚|
|ğŸ“ æ›´æ–°|ErpGS: Equirectangular Image Rendering enhanced with 3D Gaussian Regularization|ErpGSï¼šåŸºäº3Dé«˜æ–¯æ­£åˆ™åŒ–çš„ç­‰è§’å›¾åƒæ¸²æŸ“å¢å¼º|Shintaro Ito, Natsuki Takama, Koichi Ito, Hwann-Tzong Chen, Takafumi Aoki|<http://arxiv.org/pdf/2505.19883v2>|æå‡ºErpGSï¼Œé€šè¿‡3Dé«˜æ–¯æ­£åˆ™åŒ–æå‡ç­‰è§’å›¾åƒæ¸²æŸ“ç²¾åº¦ï¼Œè§£å†³360åº¦ç›¸æœºæŠ•å½±æ¨¡å‹å¯¼è‡´çš„ç•¸å˜é—®é¢˜ã€‚|
|ğŸ“ æ›´æ–°|Graph-guided Cross-composition Feature Disentanglement for Compositional Zero-shot Learning|å›¾å¼•å¯¼çš„è·¨ç»„åˆç‰¹å¾è§£è€¦ç”¨äºç»„åˆé›¶æ ·æœ¬å­¦ä¹ |Yuxia Geng, Runkai Zhu, Jiaoyan Chen, Jintai Chen, Xiang Chen, Zhuo Chen, Shuofei Qiao, Yuxiang Wang .etc.|<http://arxiv.org/pdf/2408.09786v2>|[ä»£ç ](https://github.com/zhurunkai/DCDA.); æå‡ºäº†ä¸€ç§åŸºäºå›¾å¼•å¯¼çš„è·¨ç»„åˆç‰¹å¾è§£è€¦æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†ç»„åˆé›¶æ ·æœ¬å­¦ä¹ æ€§èƒ½ã€‚|


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Re-ttention: Ultra Sparse Visual Generation via Attention Statistical Reshape|é‡ä¿ç•™ï¼šé€šè¿‡æ³¨æ„åŠ›ç»Ÿè®¡é‡å¡‘çš„è¶…ç¨€ç–è§†è§‰ç”Ÿæˆ|Ruichen Chen, Keith G. Mills, Liyao Jiang, Chao Gao, Di Niu|<http://arxiv.org/pdf/2505.22918v2>|[ä»£ç ](https://github.com/cccrrrccc/Re-ttention); æå‡ºRe-ttentionæ–¹æ³•ï¼Œé€šè¿‡åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ—¶é—´å†—ä½™ï¼Œå®ç°è¶…ç¨€ç–è§†è§‰ç”Ÿæˆï¼Œå¤§å¹…é™ä½è®¡ç®—å¤æ‚åº¦ã€‚|
|ğŸ“ æ›´æ–°|Video-MME: The First-Ever Comprehensive Evaluation Benchmark of Multi-modal LLMs in Video Analysis|è§†é¢‘-MMEï¼šè§†é¢‘åˆ†æä¸­å¤šæ¨¡æ€LLMsçš„é¦–ä¸ªå…¨é¢è¯„ä¼°åŸºå‡†|Chaoyou Fu, Yuhan Dai, Yongdong Luo, Lei Li, Shuhuai Ren, Renrui Zhang, Zihan Wang, Chenyu Zhou .etc.|<http://arxiv.org/pdf/2405.21075v3>|æ„å»ºäº†é¦–ä¸ªå…¨é¢è¯„ä¼°å¤šæ¨¡æ€LLMsåœ¨è§†é¢‘åˆ†æä¸­æ€§èƒ½çš„åŸºå‡†ï¼Œæ¨åŠ¨äº†å¯¹é•¿åºåˆ—å’Œå¤šæ¨¡æ€æ•°æ®çš„å¤„ç†ç ”ç©¶ã€‚|
|ğŸ“ æ›´æ–°|Boost-and-Skip: A Simple Guidance-Free Diffusion for Minority Generation|å¢å¼ºä¸è·³è¿‡ï¼šä¸€ç§ç®€å•æ— æŒ‡å¯¼çš„å°‘æ•°æ—è£”ç”Ÿæˆæ‰©æ•£æ–¹æ³•|Soobin Um, Beomsu Kim, Jong Chul Ye|<http://arxiv.org/pdf/2502.06516v2>|[ä»£ç ](https://github.com/soobin-um/BnS.); æå‡ºäº†ä¸€ç§ç®€å•é«˜æ•ˆçš„Boost-and-Skipæ–¹æ³•ï¼Œæ— éœ€æŒ‡å¯¼ç”Ÿæˆå°‘æ•°æ—è£”æ ·æœ¬ã€‚|
|ğŸ“ æ›´æ–°|A Survey on Text-Driven 360-Degree Panorama Generation|æ–‡æœ¬é©±åŠ¨360åº¦å…¨æ™¯å›¾ç”Ÿæˆç»¼è¿°|Hai Wang, Xiaoyu Xiang, Weihao Xia, Jing-Hao Xue|<http://arxiv.org/pdf/2502.14799v2>|[ä»£ç ](https://littlewhitesea.github.io/Text-Driven-Pano-Gen); æå‡ºäº†ä¸€ç§ä»æ–‡æœ¬æè¿°ç›´æ¥ç”Ÿæˆ360åº¦å…¨æ™¯å›¾çš„æ–¹æ³•ï¼Œç®€åŒ–äº†ä¼ ç»Ÿå†…å®¹åˆ¶ä½œæµç¨‹ã€‚|


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Tackling View-Dependent Semantics in 3D Language Gaussian Splatting|è§£å†³3Dè¯­è¨€é«˜æ–¯åˆ†å±‚ä¸­çš„è§†è§’ä¾èµ–è¯­ä¹‰é—®é¢˜|Jiazhong Cen, Xudong Zhou, Jiemin Fang, Changsong Wen, Lingxi Xie, Xiaopeng Zhang, Wei Shen, Qi Tian|<http://arxiv.org/pdf/2505.24746v1>|[ä»£ç ](https://github.com/SJTU-DeepVisionLab/LaGa.); æå‡ºLaGaæ–¹æ³•ï¼Œé€šè¿‡è·¨è§†è§’è¯­ä¹‰è¿æ¥è§£å†³3Dåœºæ™¯ä¸­è§†è§’ä¾èµ–è¯­ä¹‰é—®é¢˜ï¼Œæ˜¾è‘—æå‡è¯­ä¹‰ç†è§£ç²¾åº¦ã€‚|
|ğŸ†• å‘å¸ƒ|SR3D: Unleashing Single-view 3D Reconstruction for Transparent and Specular Object Grasping|SR3Dï¼šé‡Šæ”¾å•è§†å›¾3Dé‡å»ºä»¥å®ç°é€æ˜å’Œé•œé¢ç‰©ä½“æŠ“å–|Mingxu Zhang, Xiaoqi Li, Jiahui Xu, Kaichen Zhou, Hojin Bae, Yan Shen, Chuyan Xiong, Jiaming Liu .etc.|<http://arxiv.org/pdf/2505.24305v1>|SR3Dé€šè¿‡å•è§†å›¾3Dé‡å»ºæŠ€æœ¯ï¼Œå®ç°äº†é€æ˜å’Œé•œé¢ç‰©ä½“çš„é«˜ç²¾åº¦æŠ“å–ã€‚|
|ğŸ“ æ›´æ–°|Towards Dynamic 3D Reconstruction of Hand-Instrument Interaction in Ophthalmic Surgery|æœå‘çœ¼ç§‘æ‰‹æœ¯ä¸­æ‰‹-å™¨æ¢°äº¤äº’çš„åŠ¨æ€3Dé‡å»º|Ming Hu, Zhengdi Yu, Feilong Tang, Kaiwen Chen, Yulong Li, Imran Razzak, Junjun He, Tolga Birdal .etc.|<http://arxiv.org/pdf/2505.17677v2>|æ„å»ºäº†OphNet-3Dæ•°æ®é›†ï¼Œæå‡ºH-Netå’ŒOH-Netæ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†çœ¼ç§‘æ‰‹æœ¯ä¸­æ‰‹å’Œå™¨æ¢°çš„3D...|


### è§†è§‰å®šä½ä¸æ˜ å°„ (Visual Localization & Mapping)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Black-box Adversarial Attacks on CNN-based SLAM Algorithms|åŸºäºCNNçš„SLAMç®—æ³•çš„é»‘ç›’å¯¹æŠ—æ”»å‡»|Maria Rafaela Gkeka, Bowen Sun, Evgenia Smirni, Christos D. Antonopoulos, Spyros Lalis, Nikolaos Bellas|<http://arxiv.org/pdf/2505.24654v1>|æå‡ºé»‘ç›’å¯¹æŠ—æ”»å‡»æ–¹æ³•ï¼Œæ­ç¤ºCNN-SLAMç®—æ³•å¯¹æ·±åº¦æ”»å‡»çš„è„†å¼±æ€§ã€‚|


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|GARLIC: GAussian Representation LearnIng for spaCe partitioning|GARLICï¼šç”¨äºç©ºé—´åˆ’åˆ†çš„Gaussianè¡¨ç¤ºå­¦ä¹ |Panagiotis Rigas, Panagiotis Drivas, Charalambos Tzamos, Ioannis Chamodrakas, George Ioannakis, Leonidas J. Guibas, Ioannis Z. Emiris|<http://arxiv.org/pdf/2505.24608v1>|GARLICé€šè¿‡é«˜æ–¯è¡¨ç¤ºå­¦ä¹ ï¼Œé«˜æ•ˆå¤„ç†é«˜ç»´ç©ºé—´ï¼Œå®ç°å¿«é€Ÿæ£€ç´¢å’Œåˆ†ç±»ã€‚|
|ğŸ†• å‘å¸ƒ|Bridging 3D Anomaly Localization and Repair via High-Quality Continuous Geometric Representation|é€šè¿‡é«˜è´¨é‡è¿ç»­å‡ ä½•è¡¨ç¤ºè¿æ¥3Då¼‚å¸¸å®šä½ä¸ä¿®å¤|Bozhong Zheng, Jinye Gan, Xiaohao Xu, Wenqiao Li, Xiaonan Huang, Na Ni, Yingna Wu|<http://arxiv.org/pdf/2505.24431v1>|[ä»£ç ](https://github.com/ZZZBBBZZZ/PASDF); æå‡ºPASDFæ¡†æ¶ï¼Œé€šè¿‡è¿ç»­å‡ ä½•è¡¨ç¤ºå®ç°3Då¼‚å¸¸æ£€æµ‹ä¸ä¿®å¤ï¼Œæå‡å®šä½ç²¾åº¦å’Œä¿®å¤è´¨é‡ã€‚|


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|FlashDepth: Real-time Streaming Video Depth Estimation at 2K Resolution|FlashDepthï¼š2Kåˆ†è¾¨ç‡ä¸‹çš„å®æ—¶æµåª’ä½“è§†é¢‘æ·±åº¦ä¼°è®¡|Gene Chou, Wenqi Xian, Guandao Yang, Mohamed Abdelfattah, Bharath Hariharan, Noah Snavely, Ning Yu, Paul Debevec|<http://arxiv.org/pdf/2504.07093v2>|[ä»£ç ](https://github.com/Eyeline-Research/FlashDepth); FlashDepthæå‡ºäº†ä¸€ç§å®æ—¶é«˜åˆ†è¾¨ç‡è§†é¢‘æ·±åº¦ä¼°è®¡æ–¹æ³•ï¼Œæ˜¾è‘—æå‡è¾¹ç•Œæ¸…æ™°åº¦å’Œé€Ÿåº¦ã€‚|
|ğŸ†• å‘å¸ƒ|Time Blindness: Why Video-Language Models Can't See What Humans Can?|æ—¶é—´ç›²è§†ï¼šä¸ºä½•è§†é¢‘-è¯­è¨€æ¨¡å‹æ— æ³•çœ‹åˆ°äººç±»æ‰€èƒ½çœ‹åˆ°çš„ï¼Ÿ|Ujjwal Upadhyay, Mukul Ranjan, Zhiqiang Shen, Mohamed Elhoseiny|<http://arxiv.org/pdf/2505.24867v1>|[ä»£ç ](https://timeblindness.github.io/.); æ­ç¤ºäº†è§†é¢‘è¯­è¨€æ¨¡å‹åœ¨æ—¶é—´æ„ŸçŸ¥ä¸Šçš„å±€é™æ€§ï¼Œå¹¶æå‡ºäº†SpookyBenchåŸºå‡†ä»¥ä¿ƒè¿›æ—¶é—´æ¨¡å¼è¯†åˆ«ç ”ç©¶ã€‚|
|ğŸ†• å‘å¸ƒ|SiLVR: A Simple Language-based Video Reasoning Framework|SiLVRï¼šä¸€ç§åŸºäºç®€å•è¯­è¨€çš„è§†é¢‘æ¨ç†æ¡†æ¶|Ce Zhang, Yan-Bo Lin, Ziyang Wang, Mohit Bansal, Gedas Bertasius|<http://arxiv.org/pdf/2505.24869v1>|[ä»£ç ](https://github.com/CeeZh/SILVR.); æå‡ºSiLVRæ¡†æ¶ï¼Œé€šè¿‡è¯­è¨€æè¿°å’Œæ¨ç†æ¨¡å‹è§£å†³å¤æ‚è§†é¢‘ç†è§£é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|Learning reusable concepts across different egocentric video understanding tasks|è·¨ä¸åŒè‡ªè§†è§’è§†é¢‘ç†è§£ä»»åŠ¡å­¦ä¹ å¯é‡ç”¨æ¦‚å¿µ|Simone Alberto Peirone, Francesca Pistilli, Antonio Alliegro, Tatiana Tommasi, Giuseppe Averta|<http://arxiv.org/pdf/2505.24690v1>|æå‡ºHier-EgoPackæ¡†æ¶ï¼Œé€šè¿‡è·¨ä»»åŠ¡å­¦ä¹ ï¼Œä½¿æœºå™¨äººå…·å¤‡æºå¸¦å’Œè¿ç”¨é€šç”¨æŠ€èƒ½çš„èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|Spatiotemporal Analysis of Forest Machine Operations Using 3D Video Classification|åŸºäº3Dè§†é¢‘åˆ†ç±»çš„æ£®æ—æœºæ¢°ä½œä¸šæ—¶ç©ºåˆ†æ|Maciej Wielgosz, Simon Berg, Heikki Korpunen, Stephan Hoffmann|<http://arxiv.org/pdf/2505.24375v1>|æå‡ºäº†ä¸€ç§åŸºäº3Dè§†é¢‘åˆ†ç±»çš„æ¡†æ¶ï¼Œæœ‰æ•ˆè¯†åˆ«æ£®æ—æœºæ¢°æ“ä½œï¼Œå‡è½»ä¼ ç»Ÿæ—¶é—´ç ”ç©¶çš„å·¥ä½œè´Ÿæ‹…ã€‚|
|ğŸ“ æ›´æ–°|VideoRoPE: What Makes for Good Video Rotary Position Embedding?|è§†é¢‘RoPEï¼šä»€ä¹ˆå› ç´ é€ å°±äº†ä¼˜ç§€çš„è§†é¢‘æ—‹è½¬ä½ç½®åµŒå…¥ï¼Ÿ|Xilin Wei, Xiaoran Liu, Yuhang Zang, Xiaoyi Dong, Pan Zhang, Yuhang Cao, Jian Tong, Haodong Duan .etc.|<http://arxiv.org/pdf/2502.05173v3>|[ä»£ç ](https://github.com/Wiselnn570/VideoRoPE); æå‡ºVideoRoPEï¼Œé€šè¿‡3Dç»“æ„ä¼˜åŒ–RoPEåœ¨è§†é¢‘ä¸­çš„æ—¶ç©ºå…³ç³»ï¼Œæå‡è§†é¢‘æ£€ç´¢å’Œç†è§£çš„æ€§èƒ½ã€‚|


### è§†é¢‘ç›®æ ‡è·Ÿè¸ª (Video Object Tracking)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|EasyREG: Easy Depth-Based Markerless Registration and Tracking using Augmented Reality Device for Surgical Guidance|EasyREGï¼šåˆ©ç”¨å¢å¼ºç°å®è®¾å¤‡å®ç°ç®€æ˜“åŸºäºæ·±åº¦æ ‡è®°çš„æ— æ ‡è®°é…å‡†å’Œè·Ÿè¸ªç”¨äºæ‰‹æœ¯å¼•å¯¼|Yue Yang, Christoph Leuze, Brian Hargreaves, Bruce Daniel, Fred Baik|<http://arxiv.org/pdf/2504.09498v2>|æå‡ºäº†ä¸€ç§åŸºäºARè®¾å¤‡æ·±åº¦ä¼ æ„Ÿå™¨çš„æ— æ ‡è®°æ‰‹æœ¯å¯¼èˆªç³»ç»Ÿï¼Œå®ç°é«˜ç²¾åº¦å®šä½å’Œå®æ—¶è·Ÿè¸ªã€‚|
|ğŸ“ æ›´æ–°|Camouflaged Object Tracking: A Benchmark|ä¼ªè£…ç›®æ ‡è·Ÿè¸ªï¼šä¸€ä¸ªåŸºå‡†|Xiaoyu Guo, Pengzhi Zhong, Hao Zhang, Defeng Huang, Huikai Shao, Qijun Zhao, Shuiwang Li|<http://arxiv.org/pdf/2408.13877v4>|[ä»£ç ](https://github.com/openat25/HIPTrack-MLS.); æ„å»ºäº†é¦–ä¸ªä¼ªè£…ç‰©ä½“è·Ÿè¸ªæ•°æ®é›†ï¼Œå¹¶æå‡ºHiPTrack-MLSæ¡†æ¶æå‡è·Ÿè¸ªæ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|SSF-Net: Spatial-Spectral Fusion Network with Spectral Angle Awareness for Hyperspectral Object Tracking|SSF-Netï¼šå…·æœ‰å…‰è°±è§’åº¦æ„ŸçŸ¥çš„ç©ºè°±èåˆç½‘ç»œç”¨äºé«˜å…‰è°±ç›®æ ‡è·Ÿè¸ª|Hanzheng Wang, Wei Li, Xiang-Gen Xia, Qian Du, Jing Tian|<http://arxiv.org/pdf/2403.05852v2>|æå‡ºäº†ä¸€ç§èåˆç©ºé—´å…‰è°±ä¿¡æ¯å’Œå…‰è°±è§’åº¦æ„ŸçŸ¥çš„è·Ÿè¸ªç½‘ç»œï¼Œæœ‰æ•ˆæå‡äº†è¶…å…‰è°±ç›®æ ‡è·Ÿè¸ªçš„å‡†ç¡®æ€§ã€‚|


### åŠ¨ä½œè¯†åˆ«ä¸ç†è§£ (Action Recognition & Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Reading Recognition in the Wild|é‡å¤–åœºæ™¯ä¸­çš„é˜…è¯»è¯†åˆ«|Charig Yang, Samiul Alam, Shakhrul Iman Siam, Michael J. Proulx, Lambert Mathias, Kiran Somasundaram, Luis Pesqueira, James Fort .etc.|<http://arxiv.org/pdf/2505.24848v1>|æ„å»ºé¦–ä¸ªå¤§è§„æ¨¡å¤šæ¨¡æ€é˜…è¯»è¯†åˆ«æ•°æ®é›†ï¼Œæå‡ºçµæ´»çš„Transformeræ¨¡å‹å®ç°é˜…è¯»è¡Œä¸ºè¯†åˆ«ã€‚|
|ğŸ†• å‘å¸ƒ|EgoExOR: An Ego-Exo-Centric Operating Room Dataset for Surgical Activity Understanding|è‡ªæˆ‘-å¤–ä¸­å¿ƒæ‰‹æœ¯å®¤æ´»åŠ¨ç†è§£æ•°æ®é›†ï¼šEgoExOR|Ege Ã–zsoy, Arda Mamur, Felix Tristram, Chantal Pellegrini, Magdalena Wysocki, Benjamin Busam, Nassir Navab|<http://arxiv.org/pdf/2505.24287v1>|æ„å»ºé¦–ä¸ªèåˆç¬¬ä¸€äººç§°å’Œç¬¬ä¸‰äººç§°è§†è§’çš„æ‰‹æœ¯å®¤æ•°æ®é›†ï¼Œä»¥æå‡æ‰‹æœ¯æ´»åŠ¨ç†è§£ã€‚|


### æ—¶åºå»ºæ¨¡ä¸é¢„æµ‹ (Temporal Modeling & Prediction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|LLM-powered Query Expansion for Enhancing Boundary Prediction in Language-driven Action Localization|åŸºäºLLMçš„æŸ¥è¯¢æ‰©å±•ä»¥å¢å¼ºè¯­è¨€é©±åŠ¨åŠ¨ä½œå®šä½ä¸­çš„è¾¹ç•Œé¢„æµ‹|Zirui Shang, Xinxiao Wu, Shuo Yang|<http://arxiv.org/pdf/2505.24282v1>|åˆ©ç”¨LLMæ‰©å±•æŸ¥è¯¢ï¼Œç»“åˆè¯­ä¹‰ç›¸ä¼¼åº¦å’Œæ—¶é—´è·ç¦»å»ºæ¨¡ï¼Œæå‡è¯­è¨€é©±åŠ¨åŠ¨ä½œå®šä½è¾¹ç•Œé¢„æµ‹çš„ç¨³å®šæ€§ã€‚|


## è‡ªç›‘ç£ä¸è¡¨å¾å­¦ä¹  (Self-supervised & Representation Learning)


### å¯¹æ¯”å­¦ä¹ æ–¹æ³• (Contrastive Learning Methods)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Contrast-Invariant Self-supervised Segmentation for Quantitative Placental MRI|å¯¹æ¯”ä¸å˜çš„è‡ªç›‘ç£èƒç›˜MRIåˆ†å‰²|Xinliu Zhong, Ruiying Liu, Emily S. Nichols, Xuzhe Zhang, Andrew F. Laine, Emma G. Duerden, Yun Wang|<http://arxiv.org/pdf/2505.24739v1>|æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤šå›æ³¢T2*-åŠ æƒMRIè¿›è¡Œèƒç›˜åˆ†å‰²çš„å¯¹æ¯”ä¸å˜è‡ªç›‘ç£åˆ†å‰²æ¡†æ¶ï¼Œæœ‰æ•ˆæé«˜äº†åˆ†å‰²å‡†ç¡®æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|A Cross Branch Fusion-Based Contrastive Learning Framework for Point Cloud Self-supervised Learning|åŸºäºè·¨åˆ†æ”¯èåˆçš„å¯¹æ¯”å­¦ä¹ æ¡†æ¶ç”¨äºç‚¹äº‘è‡ªç›‘ç£å­¦ä¹ |Chengzhi Wu, Qianliang Huang, Kun Jin, Julius Pfrommer, JÃ¼rgen Beyerer|<http://arxiv.org/pdf/2505.24641v1>|æå‡ºäº†ä¸€ç§åŸºäºè·¨åˆ†æ”¯èåˆçš„å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œæœ‰æ•ˆæå‡äº†ç‚¹äº‘è‡ªç›‘ç£å­¦ä¹ çš„æ€§èƒ½ã€‚|


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Beyond Pretty Pictures: Combined Single- and Multi-Image Super-resolution for Sentinel-2 Images|è¶…è¶Šç¾ä¸½å›¾ç‰‡ï¼šç»“åˆå•å›¾åƒå’Œå¤šå›¾åƒè¶…åˆ†è¾¨ç‡å¤„ç†Sentinel-2å›¾åƒ|Aditya Retnanto, Son Le, Sebastian Mueller, Armin Leitner, Michael Riffler, Konrad Schindler, Yohan Iddawela|<http://arxiv.org/pdf/2505.24799v2>|æå‡ºSEN4Xæ··åˆè¶…åˆ†è¾¨ç‡æ¶æ„ï¼Œç»“åˆå•å›¾å’Œå¤šå›¾æŠ€æœ¯æå‡Sentinel-2å›¾åƒåˆ†è¾¨ç‡ï¼Œæ˜¾è‘—æ”¹å–„åŸå¸‚åœŸ...|
|ğŸ†• å‘å¸ƒ|CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning|CL-LoRAï¼šæ— é‡æ”¾ç±»å¢é‡å­¦ä¹ çš„æŒç»­ä½ç§©è‡ªé€‚åº”|Jiangpeng He, Zhihao Duan, Fengqing Zhu|<http://arxiv.org/pdf/2505.24816v1>|æå‡ºCL-LoRAï¼Œé€šè¿‡åŒé‡é€‚é…å™¨æ¶æ„å®ç°æ— é‡æ”¾ç±»å¢é‡å­¦ä¹ ï¼Œæœ‰æ•ˆé™ä½å‚æ•°å†—ä½™å¹¶æå‡æ¨¡å‹æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|Adversarial Pruning: A Survey and Benchmark of Pruning Methods for Adversarial Robustness|å¯¹æŠ—å‰ªæï¼šå¯¹æŠ—é²æ£’æ€§å‰ªææ–¹æ³•ç»¼è¿°ä¸åŸºå‡†|Giorgio Piras, Maura Pintor, Ambra Demontis, Battista Biggio, Giorgio Giacinto, Fabio Roli|<http://arxiv.org/pdf/2409.01249v2>|[ä»£ç ](https://github.com/pralab/AdversarialPruningBenchmark); æ„å»ºäº†å¯¹æŠ—é²æ£’æ€§å‰ªææ–¹æ³•çš„åˆ†ç±»æ¡†æ¶å’Œå…¬å¹³è¯„ä¼°åŸºå‡†ï¼Œä»¥è§£å†³ç°æœ‰æ–¹æ³•çš„æ¯”è¾ƒéš¾é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|Optimal Weighted Convolution for Classification and Denosing|æœ€ä¼˜åŠ æƒå·ç§¯ç”¨äºåˆ†ç±»å’Œå»å™ª|Simone Cammarasana, Giuseppe PatanÃ¨|<http://arxiv.org/pdf/2505.24558v1>|[ä»£ç ](https://github.com/cammarasana123/weightedConvolution2.0.); æå‡ºäº†ä¸€ç§åŠ æƒå·ç§¯æ–¹æ³•ï¼Œé€šè¿‡ç©ºé—´å¯†åº¦å‡½æ•°å¢å¼ºCNNï¼Œæå‡å›¾åƒåˆ†ç±»å’Œå»å™ªæ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|IDEA: An Inverse Domain Expert Adaptation Based Active DNN IP Protection Method|IDEAï¼šåŸºäºé€†é¢†åŸŸä¸“å®¶é€‚åº”çš„ä¸»åŠ¨æ·±åº¦ç¥ç»ç½‘ç»œçŸ¥è¯†äº§æƒä¿æŠ¤æ–¹æ³•|Chaohui Xu, Qi Cui, Jinxin Dong, Weiyang He, Chip-Hong Chang|<http://arxiv.org/pdf/2410.00059v2>|IDEAé€šè¿‡é€†å‘é¢†åŸŸè‡ªé€‚åº”å’Œä¸“å®¶æ¨¡å‹æ··åˆï¼Œå®ç°äº†ä¸»åŠ¨æˆæƒå’Œæºè¿½è¸ªï¼Œæœ‰æ•ˆä¿æŠ¤DNNçŸ¥è¯†äº§æƒã€‚|
|ğŸ†• å‘å¸ƒ|Optimal Density Functions for Weighted Convolution in Learning Models|æœ€ä¼˜å¯†åº¦å‡½æ•°åœ¨åŠ æƒå·ç§¯å­¦ä¹ æ¨¡å‹ä¸­çš„åº”ç”¨|Simone Cammarasana, Giuseppe PatanÃ¨|<http://arxiv.org/pdf/2505.24527v1>|æå‡ºåŠ æƒå·ç§¯æ–¹æ³•ï¼Œé€šè¿‡ä¼˜åŒ–å¯†åº¦å‡½æ•°æå‡å›¾åƒå¤„ç†æ¨¡å‹ç²¾åº¦ã€‚|
|ğŸ†• å‘å¸ƒ|A Novel Coronary Artery Registration Method Based on Super-pixel Particle Swarm Optimization|åŸºäºè¶…åƒç´ ç²’å­ç¾¤ä¼˜åŒ–çš„æ–°å‹å† çŠ¶åŠ¨è„‰é…å‡†æ–¹æ³•|Peng Qi, Wenxi Qu, Tianliang Yao, Haonan Ma, Dylan Wintle, Yinyi Lai, Giorgos Papanastasiou, Chengjia Wang|<http://arxiv.org/pdf/2505.24351v1>|æå‡ºäº†ä¸€ç§åŸºäºè¶…çº§åƒç´ ç²’å­ç¾¤ä¼˜åŒ–çš„å† çŠ¶åŠ¨è„‰å›¾åƒé…å‡†æ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†å¤šæ¨¡æ€å›¾åƒé…å‡†çš„æŒ‘æˆ˜ã€‚|
|ğŸ†• å‘å¸ƒ|50 Years of Automated Face Recognition|äº”åå¹´è‡ªåŠ¨åŒ–äººè„¸è¯†åˆ«å‘å±•å†ç¨‹|Minchul Kim, Anil Jain, Xiaoming Liu|<http://arxiv.org/pdf/2505.24247v1>|æ¦‚è¿°äº†50å¹´äººè„¸è¯†åˆ«æŠ€æœ¯å‘å±•å†ç¨‹ï¼Œåˆ†æäº†å…³é”®åˆ›æ–°ï¼Œå¹¶å±•æœ›äº†æœªæ¥ç ”ç©¶æ–¹å‘ã€‚|
|ğŸ“ æ›´æ–°|Adventurer: Optimizing Vision Mamba Architecture Designs for Efficiency|æ¢é™©å®¶ï¼šä¼˜åŒ–è§†è§‰Mambaæ¶æ„è®¾è®¡ä»¥æé«˜æ•ˆç‡|Feng Wang, Timing Yang, Yaodong Yu, Sucheng Ren, Guoyizhe Wei, Angtian Wang, Wei Shao, Yuyin Zhou .etc.|<http://arxiv.org/pdf/2410.07599v2>|[ä»£ç ](https://github.com/wangf3014/Adventurer.); Adventureré€šè¿‡å°†å›¾åƒè§†ä¸ºåºåˆ—å¹¶ä½¿ç”¨å•å‘è¯­è¨€æ¨¡å‹å­¦ä¹ è§†è§‰è¡¨ç¤ºï¼Œæœ‰æ•ˆè§£å†³äº†é«˜åˆ†è¾¨ç‡å›¾åƒçš„å†…å­˜å’Œ...|
|ğŸ†• å‘å¸ƒ|Boosting All-in-One Image Restoration via Self-Improved Privilege Learning|é€šè¿‡è‡ªæˆ‘æ”¹è¿›çš„ç‰¹æƒå­¦ä¹ æå‡ä¸€ä½“åŒ–å›¾åƒæ¢å¤|Gang Wu, Junjun Jiang, Kui Jiang, Xianming Liu|<http://arxiv.org/pdf/2505.24207v1>|[ä»£ç ](https://github.com/Aitical/SIPL.); é€šè¿‡è‡ªæ”¹è¿›ç‰¹æƒå­¦ä¹ ï¼Œè¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åœ¨å›¾åƒä¿®å¤ä¸­åˆ©ç”¨æ¨¡å‹è‡ªèº«è¾“å‡ºè¿›è¡Œè¿­ä»£ä¼˜åŒ–çš„æ–°æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†ä¿®å¤...|


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|U2-BENCH: Benchmarking Large Vision-Language Models on Ultrasound Understanding|U2-BENCHï¼šåœ¨è¶…å£°ç†è§£ä¸Šå¯¹å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹çš„åŸºå‡†æµ‹è¯•|Anjie Le, Henan Liu, Yue Wang, Zhenyu Liu, Rongkun Zhu, Taohan Weng, Jinze Yu, Boyang Wang .etc.|<http://arxiv.org/pdf/2505.17779v2>|æ„å»ºäº†é¦–ä¸ªè¶…å£°å›¾åƒç†è§£åŸºå‡†U2-BENCHï¼Œè¯„ä¼°å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹åœ¨åŒ»å­¦è¶…å£°é¢†åŸŸçš„æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|DiG-Net: Enhancing Quality of Life through Hyper-Range Dynamic Gesture Recognition in Assistive Robotics|DiG-Netï¼šé€šè¿‡è¶…èŒƒå›´åŠ¨æ€æ‰‹åŠ¿è¯†åˆ«æå‡è¾…åŠ©æœºå™¨äººç”Ÿæ´»è´¨é‡|Eran Bamani Beeri, Eden Nissinman, Avishai Sintov|<http://arxiv.org/pdf/2505.24786v1>|DiG-Neté€šè¿‡è¶…è¿œè·ç¦»åŠ¨æ€æ‰‹åŠ¿è¯†åˆ«ï¼Œæ˜¾è‘—æå‡äº†è¾…åŠ©æœºå™¨äººçš„å¯ç”¨æ€§å’Œç”Ÿæ´»è´¨é‡ã€‚|
|ğŸ“ æ›´æ–°|Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data|è§£è€¦æ— æºä¸ªæ€§åŒ–ä¸­æ€§ç›®æ ‡æ•°æ®é¢éƒ¨è¡¨æƒ…è¯†åˆ«|Masoumeh Sharafi, Emma Ollivier, Muhammad Osama Zeeshan, Soufiane Belharbi, Marco Pedersoli, Alessandro Lameiras Koerich, Simon Bacon, Eric Granger|<http://arxiv.org/pdf/2503.20771v4>|æå‡ºä¸€ç§åˆ©ç”¨ä¸­æ€§æ§åˆ¶è§†é¢‘æ•°æ®ï¼Œé€šè¿‡è§£è€¦ç‰¹å¾ç”Ÿæˆç¼ºå¤±è¡¨æƒ…æ•°æ®ï¼Œæå‡é¢éƒ¨è¡¨æƒ…è¯†åˆ«æ¨¡å‹é€‚åº”æ€§çš„æ–¹æ³•ã€‚|
|ğŸ†• å‘å¸ƒ|Hyperbolic Dataset Distillation|åŒæ›²æ•°æ®è’¸é¦|Wenyuan Li, Guang Li, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama|<http://arxiv.org/pdf/2505.24623v1>|æå‡ºäº†ä¸€ç§åŸºäºåŒæ›²ç©ºé—´çš„è¶…å‚æ•°æ•°æ®è’¸é¦æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†æ¨¡å‹æ€§èƒ½å’Œè®­ç»ƒç¨³å®šæ€§ã€‚|
|ğŸ†• å‘å¸ƒ|SARD: A Large-Scale Synthetic Arabic OCR Dataset for Book-Style Text Recognition|SARDï¼šç”¨äºä¹¦ç±é£æ ¼æ–‡æœ¬è¯†åˆ«çš„å¤§è§„æ¨¡åˆæˆé˜¿æ‹‰ä¼¯è¯­OCRæ•°æ®é›†|Omer Nacar, Yasser Al-Habashi, Serry Sibaee, Adel Ammar, Wadii Boulila|<http://arxiv.org/pdf/2505.24600v1>|æ„å»ºå¤§è§„æ¨¡åˆæˆé˜¿æ‹‰ä¼¯OCRæ•°æ®é›†ï¼Œä»¥è§£å†³ç°æœ‰æ•°æ®é›†è§„æ¨¡å’Œå¤šæ ·æ€§ä¸è¶³çš„é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|Model-Guided Network with Cluster-Based Operators for Spatio-Spectral Super-Resolution|åŸºäºèšç±»ç®—å­çš„æ¨¡å‹å¼•å¯¼ç½‘ç»œç”¨äºç©ºé—´å…‰è°±è¶…åˆ†è¾¨ç‡|Ivan Pereira-SÃ¡nchez, Julia Navarro, Ana BelÃ©n Petro, Joan Duran|<http://arxiv.org/pdf/2505.24605v1>|[ä»£ç ](https://github.com/TAMI-UIB/JSSUNet); æå‡ºäº†ä¸€ç§æ¨¡å‹é©±åŠ¨çš„è”åˆç©ºé—´å…‰è°±è¶…åˆ†è¾¨ç‡æ¡†æ¶ï¼Œæœ‰æ•ˆæå‡äº†ä½åˆ†è¾¨ç‡é«˜å…‰è°±å›¾åƒé‡å»ºè´¨é‡ã€‚|
|ğŸ“ æ›´æ–°|Scaling Large Motion Models with Million-Level Human Motions|å¤§è§„æ¨¡è¿åŠ¨æ¨¡å‹ä¸ç™¾ä¸‡çº§äººç±»åŠ¨ä½œçš„æ‰©å±•|Ye Wang, Sipeng Zheng, Bin Cao, Qianshan Wei, Weishuai Zeng, Qin Jin, Zongqing Lu|<http://arxiv.org/pdf/2410.03311v3>|[ä»£ç ](https://beingbeyond.github.io/Being-M0); æ„å»ºç™¾ä¸‡çº§åŠ¨ä½œæ•°æ®é›†ï¼Œæå‡ºMotionbookæ–¹æ³•ï¼Œæå‡åŠ¨ä½œç”Ÿæˆæ¨¡å‹çš„æ€§èƒ½å’Œçµæ´»æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Digital twins enable full-reference quality assessment of photoacoustic image reconstructions|æ•°å­—å­ªç”Ÿå®ç°å…¨å‚è€ƒè´¨é‡è¯„ä¼°å…‰å£°å›¾åƒé‡å»º|Janek GrÃ¶hl, Leonid Kunyansky, Jenni Poimala, Thomas R. Else, Francesca Di Cecio, Sarah E. Bohndiek, Ben T. Cox, Andreas Hauptmann|<http://arxiv.org/pdf/2505.24514v1>|åˆ©ç”¨æ•°å­—å­ªç”ŸæŠ€æœ¯ï¼Œå®ç°äº†åŸºäºå…¨å‚è€ƒçš„è¶…å£°å…‰å£°å›¾åƒé‡å»ºç®—æ³•è´¨é‡è¯„ä¼°ã€‚|
|ğŸ†• å‘å¸ƒ|AMIA: Automatic Masking and Joint Intention Analysis Makes LVLMs Robust Jailbreak Defenders|AMIAï¼šè‡ªåŠ¨é®æŒ¡å’Œè”åˆæ„å›¾åˆ†æä½¿LVLMsæˆä¸ºé²æ£’çš„è¶Šç‹±é˜²å¾¡è€…|Yuqi Zhang, Yuchun Miao, Zuchao Li, Liang Ding|<http://arxiv.org/pdf/2505.24519v1>|AMIAé€šè¿‡è‡ªåŠ¨é®æŒ¡æ— å…³å›¾åƒåŒºåŸŸå’Œè”åˆæ„å›¾åˆ†æï¼Œæ˜¾è‘—æå‡äº†å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹çš„é²æ£’æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|S3CE-Net: Spike-guided Spatiotemporal Semantic Coupling and Expansion Network for Long Sequence Event Re-Identification|S3CE-Netï¼šç”¨äºé•¿åºåˆ—äº‹ä»¶é‡è¯†åˆ«çš„è„‰å†²å¼•å¯¼æ—¶ç©ºè¯­ä¹‰è€¦åˆä¸æ‰©å±•ç½‘ç»œ|Xianheng Ma, Hongchen Tan, Xiuping Liu, Yi Zhang, Huasheng Wang, Jiang Liu, Ying Chen, Hantao Liu|<http://arxiv.org/pdf/2505.24401v1>|[ä»£ç ](https://github.com/Mhsunshine/SC3E_Net.); æå‡ºäº†ä¸€ç§åŸºäºè„‰å†²ç¥ç»ç½‘ç»œçš„ä½å‚æ•°é•¿åºåˆ—äº‹ä»¶é‡è¯†åˆ«æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†è¯†åˆ«å‡†ç¡®ç‡ã€‚|
|ğŸ†• å‘å¸ƒ|Progressive Class-level Distillation|æ¸è¿›å¼ç±»çº§åˆ«è’¸é¦|Jiayan Li, Jun Li, Zhourui Zhang, Jianhua Xu|<http://arxiv.org/pdf/2505.24310v1>|æå‡ºæ¸è¿›å¼ç±»åˆ«çº§è’¸é¦æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡ä½æ¦‚ç‡ç±»åˆ«çŸ¥è¯†åœ¨çŸ¥è¯†è’¸é¦ä¸­çš„ä¼ é€’ã€‚|
|ğŸ“ æ›´æ–°|ZPressor: Bottleneck-Aware Compression for Scalable Feed-Forward 3DGS|ZPressorï¼šé¢å‘å¯æ‰©å±•å‰é¦ˆ3DGSçš„ç“¶é¢ˆæ„ŸçŸ¥å‹ç¼©|Weijie Wang, Donny Y. Chen, Zeyu Zhang, Duochao Shi, Akide Liu, Bohan Zhuang|<http://arxiv.org/pdf/2505.23734v2>|ZPressoré€šè¿‡ä¿¡æ¯ç“¶é¢ˆåŸç†ï¼Œå®ç°è½»é‡çº§å‹ç¼©ï¼Œæå‡3DGSæ¨¡å‹å¤„ç†å¤šè§†è§’è¾“å…¥çš„æ•ˆç‡å’Œé²æ£’æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Towards Unified Modeling in Federated Multi-Task Learning via Subspace Decoupling|è¿ˆå‘é€šè¿‡å­ç©ºé—´è§£è€¦çš„è”é‚¦å¤šä»»åŠ¡å­¦ä¹ ç»Ÿä¸€å»ºæ¨¡|Yipan Wei, Yuchen Zou, Yapeng Li, Bo Du|<http://arxiv.org/pdf/2505.24185v1>|æå‡ºFedDEAæ–¹æ³•ï¼Œé€šè¿‡å­ç©ºé—´è§£è€¦å®ç°è”é‚¦å¤šä»»åŠ¡å­¦ä¹ ï¼Œæœ‰æ•ˆè§£å†³å¼‚æ„ä»»åŠ¡è”åˆè®­ç»ƒéš¾é¢˜ã€‚|
|ğŸ“ æ›´æ–°|Expansion Quantization Network: An Efficient Micro-emotion Annotation and Detection Framework|æ‰©å±•é‡åŒ–ç½‘ç»œï¼šä¸€ç§é«˜æ•ˆçš„å¾®è¡¨æƒ…æ ‡æ³¨ä¸æ£€æµ‹æ¡†æ¶|Jingyi Zhou, Senlin Luo, Haofan Chen|<http://arxiv.org/pdf/2411.06160v3>|æå‡ºEQNæ¡†æ¶ï¼Œæœ‰æ•ˆè§£å†³å¾®è¡¨æƒ…æ ‡æ³¨ä¸æ£€æµ‹éš¾é¢˜ï¼Œå®ç°è‡ªåŠ¨å¾®è¡¨æƒ…æ ‡æ³¨ä¸èƒ½é‡çº§è¯„åˆ†ã€‚|
|ğŸ†• å‘å¸ƒ|Federated Foundation Model for GI Endoscopy Images|è”é‚¦åŸºç¡€æ¨¡å‹ç”¨äºèƒƒé•œå›¾åƒ|Alina Devkota, Annahita Amireskandari, Joel Palko, Shyam Thakkar, Donald Adjeroh, Xiajun Jiang, Binod Bhattarai, Prashnna K. Gyawali|<http://arxiv.org/pdf/2505.24108v1>|æå‡ºäº†ä¸€ç§è”é‚¦å­¦ä¹ æ¡†æ¶ï¼Œåœ¨ä¿æŠ¤éšç§çš„å‰æä¸‹ï¼Œè®­ç»ƒç”¨äºèƒƒè‚ é•œå›¾åƒçš„é€šç”¨åŸºç¡€æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½...|


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Efficient RAW Image Deblurring with Adaptive Frequency Modulation|é«˜æ•ˆè‡ªé€‚åº”é¢‘ç‡è°ƒåˆ¶ä¸‹çš„RAWå›¾åƒå»æ¨¡ç³Š|Wenlong Jiao, Binglong Li, Wei Shang, Ping Wang, Dongwei Ren|<http://arxiv.org/pdf/2505.24407v1>|[ä»£ç ](https://github.com/WenlongJiao/FrENet); æå‡ºäº†ä¸€ç§é’ˆå¯¹RAWå›¾åƒå»æ¨¡ç³Šçš„FrENetæ¡†æ¶ï¼Œé€šè¿‡è‡ªé€‚åº”é¢‘ç‡è°ƒåˆ¶å’Œé¢‘ç‡åŸŸè·³è¿‡è¿æ¥ï¼Œå®ç°äº†é«˜æ•ˆä¸”é«˜...|
|ğŸ†• å‘å¸ƒ|PCIE_Interaction Solution for Ego4D Social Interaction Challenge|PCIE_é’ˆå¯¹Ego4Dç¤¾äº¤äº¤äº’æŒ‘æˆ˜çš„äº¤äº’è§£å†³æ–¹æ¡ˆ|Kanokphan Lertniphonphan, Feng Chen, Junda Xu, Fengbu Lan, Jun Xie, Tao Zhang, Zhepeng Wang|<http://arxiv.org/pdf/2505.24404v1>|[ä»£ç ](https://github.com/KanokphanL/PCIE_Ego4D_Social_Interaction); é’ˆå¯¹Ego4Dç¤¾äº¤äº¤äº’æŒ‘æˆ˜ï¼Œæå‡ºèåˆè§†è§‰å’ŒéŸ³é¢‘ä¿¡æ¯çš„PCIE_Interactionè§£å†³æ–¹æ¡ˆï¼Œæ˜¾è‘—æ...|
|ğŸ†• å‘å¸ƒ|Sparsity-Driven Parallel Imaging Consistency for Improved Self-Supervised MRI Reconstruction|åŸºäºç¨€ç–æ€§çš„å¹¶è¡Œæˆåƒä¸€è‡´æ€§æå‡è‡ªç›‘ç£MRIé‡å»º|YaÅŸar Utku AlÃ§alar, Mehmet AkÃ§akaya|<http://arxiv.org/pdf/2505.24136v1>|æå‡ºäº†ä¸€ç§é€šè¿‡ç¨€ç–åŸŸä¸€è‡´æ€§å¢å¼ºçš„å¹¶è¡Œæˆåƒä¸€è‡´æ€§è®­ç»ƒæ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†è‡ªç›‘ç£MRIé‡å»ºçš„å›¾åƒè´¨é‡ã€‚|


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### å¯¹æŠ—é²æ£’æ€§ (Adversarial Robustness)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|RenderBender: A Survey on Adversarial Attacks Using Differentiable Rendering|æ¸²æŸ“å¼¯æ›²ï¼šåŸºäºå¯å¾®æ¸²æŸ“çš„å¯¹æŠ—æ”»å‡»ç»¼è¿°|Matthew Hull, Haoran Wang, Matthew Lau, Alec Helbling, Mansi Phute, Chao Zhang, Zsolt Kira, Willian Lunardi .etc.|<http://arxiv.org/pdf/2411.09749v2>|é¦–æ¬¡æå‡ºç»Ÿä¸€æ¡†æ¶ï¼Œæ•´åˆä¸åŒç›®æ ‡ä¸ä»»åŠ¡ï¼Œæ¨åŠ¨å¯å¾®åˆ†æ¸²æŸ“åœ¨å¯¹æŠ—æ”»å‡»ä¸­çš„åº”ç”¨ç ”ç©¶ã€‚|
|ğŸ“ æ›´æ–°|GSBA$^K$: $top$-$K$ Geometric Score-based Black-box Attack|GSBA$^K$ï¼šåŸºäºå‡ ä½•åˆ†æ•°çš„$top$-$K$é»‘ç›’æ”»å‡»|Md Farhamdur Reza, Richeng Jin, Tianfu Wu, Huaiyu Dai|<http://arxiv.org/pdf/2503.12827v3>|GSBA$^K$æå‡ºäº†ä¸€ç§é’ˆå¯¹å¤šæ ‡ç­¾åˆ†ç±»å™¨çš„$top$-$K$é»‘ç›’æ”»å‡»æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡æ”»å‡»æˆåŠŸç‡ä¸æŸ¥è¯¢...|
|ğŸ†• å‘å¸ƒ|PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches|PatchDEMUXï¼šé’ˆå¯¹å¯¹æŠ—æ€§è¡¥ä¸çš„å¤šæ ‡ç­¾åˆ†ç±»å™¨çš„å¯è®¤è¯é²æ£’æ¡†æ¶|Dennis Jacob, Chong Xiang, Prateek Mittal|<http://arxiv.org/pdf/2505.24703v1>|PatchDEMUXæå‡ºäº†ä¸€ç§é’ˆå¯¹å¤šæ ‡ç­¾åˆ†ç±»å™¨å¯¹æŠ—æ€§è¡¥ä¸çš„è®¤è¯é²æ£’æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†é˜²å¾¡èƒ½åŠ›ã€‚|
|ğŸ“ æ›´æ–°|Improving Adversarial Robustness via Phase and Amplitude-aware Prompting|é€šè¿‡ç›¸ä½å’Œå¹…åº¦æ„ŸçŸ¥æç¤ºæé«˜å¯¹æŠ—é²æ£’æ€§|Yibo Xu, Dawei Zhou, Decheng Liu, Nannan Wang|<http://arxiv.org/pdf/2502.03758v2>|æå‡ºäº†ä¸€ç§åŸºäºç›¸ä½å’Œå¹…åº¦æç¤ºçš„é˜²å¾¡æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†å¯¹æŠ—æ ·æœ¬çš„é²æ£’æ€§ã€‚|


### åˆ†å¸ƒå¤–æ³›åŒ– (Out-of-distribution Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MoDoMoDo: Multi-Domain Data Mixtures for Multimodal LLM Reinforcement Learning|MoDoMoDoï¼šå¤šåŸŸæ•°æ®æ··åˆç”¨äºå¤šæ¨¡æ€LLMå¼ºåŒ–å­¦ä¹ |Yiqing Liang, Jielin Qiu, Wenhao Ding, Zuxin Liu, James Tompkin, Mengdi Xu, Mengzhou Xia, Zhengzhong Tu .etc.|<http://arxiv.org/pdf/2505.24871v1>|æå‡ºäº†ä¸€ç§å¤šé¢†åŸŸæ•°æ®æ··åˆç­–ç•¥ï¼Œæ˜¾è‘—æå‡äº†å¤šæ¨¡æ€LLMåœ¨è§†è§‰è¯­è¨€ä»»åŠ¡ä¸Šçš„æ³›åŒ–èƒ½åŠ›å’Œæ¨ç†èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|Efficient Estimation of Regularized Tyler's M-Estimator Using Approximate LOOCV|é«˜æ•ˆåˆ©ç”¨è¿‘ä¼¼ç•™ä¸€æ³•ä¼°è®¡æ­£åˆ™åŒ–æ³°å‹’Mä¼°è®¡é‡|Karim Abou-Moustafa|<http://arxiv.org/pdf/2505.24781v1>|æå‡ºäº†ä¸€ç§é«˜æ•ˆä¼°è®¡RTMEæ­£åˆ™åŒ–å‚æ•°çš„æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†LOOCVä¼°è®¡çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚|
|ğŸ“ æ›´æ–°|SAMBLE: Shape-Specific Point Cloud Sampling for an Optimal Trade-Off Between Local Detail and Global Uniformity|SAMBLEï¼šé’ˆå¯¹å±€éƒ¨ç»†èŠ‚ä¸å…¨å±€å‡åŒ€æ€§ä¹‹é—´æœ€ä½³æƒè¡¡çš„å½¢çŠ¶ç‰¹å®šç‚¹äº‘é‡‡æ ·|Chengzhi Wu, Yuxin Wan, Hao Fu, Julius Pfrommer, Zeyun Zhong, Junwei Zheng, Jiaming Zhang, JÃ¼rgen Beyerer|<http://arxiv.org/pdf/2504.19581v2>|æå‡ºSAMBLEæ–¹æ³•ï¼Œé€šè¿‡å­¦ä¹ å½¢çŠ¶ç‰¹å®šé‡‡æ ·ç­–ç•¥ï¼Œä¼˜åŒ–ç‚¹äº‘å±€éƒ¨ç»†èŠ‚ä¸å…¨å±€å‡åŒ€æ€§çš„å¹³è¡¡ã€‚|
|ğŸ“ æ›´æ–°|Analysis of Pseudo-Labeling for Online Source-Free Universal Domain Adaptation|ä¼ªæ ‡ç­¾åœ¨åœ¨çº¿æ— æºé€šç”¨åŸŸè‡ªé€‚åº”ä¸­çš„åº”ç”¨åˆ†æ|Pascal Schlachter, Jonathan Fuss, Bin Yang|<http://arxiv.org/pdf/2504.11992v2>|[ä»£ç ](https://github.com/pascalschlachter/PLAnalysis.); åˆ†æäº†ä¼ªæ ‡ç­¾åœ¨åœ¨çº¿æ— æºé€šç”¨åŸŸè‡ªé€‚åº”ä¸­çš„ä½œç”¨ï¼Œæ­ç¤ºäº†å…¶å…³é”®æ€§å’Œä¼˜åŒ–ç­–ç•¥ã€‚|
|ğŸ†• å‘å¸ƒ|Provably Improving Generalization of Few-Shot Models with Synthetic Data|ä½¿ç”¨åˆæˆæ•°æ®è¯æ˜æé«˜å°‘æ ·æœ¬æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„è®ºæ–‡æ ‡é¢˜ç¿»è¯‘ä¸ºä¸­æ–‡ä¸ºï¼š  åˆ©ç”¨åˆæˆæ•°æ®è¯æ˜æå‡å°‘æ ·æœ¬æ¨¡å‹æ³›åŒ–æ€§èƒ½|Lan-Cuong Nguyen, Quan Nguyen-Tri, Bang Tran Khanh, Dung D. Le, Long Tran-Thanh, Khoat Than|<http://arxiv.org/pdf/2505.24190v1>|æå‡ºäº†ä¸€ç§ç†è®ºæ¡†æ¶ï¼Œé€šè¿‡åŸå‹å­¦ä¹ ä¼˜åŒ–æ•°æ®åˆ†åŒºå’Œæ¨¡å‹è®­ç»ƒï¼Œæœ‰æ•ˆæå‡å°æ ·æœ¬å›¾åƒåˆ†ç±»æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚|


### ä¸ç¡®å®šæ€§é‡åŒ– (Uncertainty Quantification)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Post-hoc Probabilistic Vision-Language Models|åå¤„ç†æ¦‚ç‡è§†è§‰-è¯­è¨€æ¨¡å‹|Anton Baumann, Rui Li, Marcus Klasson, Santeri Mentu, Shyamgopal Karthik, Zeynep Akata, Arno Solin, Martin Trapp|<http://arxiv.org/pdf/2412.06014v3>|æå‡ºäº†ä¸€ç§æ— éœ€é¢å¤–è®­ç»ƒçš„VLMåå¤„ç†ä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡é¢„æµ‹ä¸ç¡®å®šæ€§å’Œä¸»åŠ¨å­¦ä¹ æ•ˆç‡ã€‚|


### è§†è§‰å®‰å…¨ä¸éšç§ (Visual Security & Privacy)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|The Butterfly Effect in Pathology: Exploring Security in Pathology Foundation Models|ç—…ç†å­¦ä¸­çš„è´è¶æ•ˆåº”ï¼šæ¢ç´¢ç—…ç†åŸºç¡€æ¨¡å‹ä¸­çš„å®‰å…¨æ€§|Jiashuai Liu, Yingjia Shang, Yingkang Zhan, Di Zhang, Yi Niu, Dong Wei, Xian Wu, Zeyu Gao .etc.|<http://arxiv.org/pdf/2505.24141v1>|[ä»£ç ](https://github.com/Jiashuai-Liu-hmos/Attack-WSI-pathology-foundation-models.); é¦–æ¬¡ç³»ç»Ÿæ€§åœ°ç ”ç©¶äº†ç—…ç†åŸºç¡€æ¨¡å‹åœ¨å¯¹æŠ—æ”»å‡»ä¸‹çš„å®‰å…¨æ€§ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ— éœ€æ ‡ç­¾çš„æ”»å‡»æ¡†æ¶ã€‚|


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|MorphoSeg: An Uncertainty-Aware Deep Learning Method for Biomedical Segmentation of Complex Cellular Morphologies|å½¢æ€åˆ†å‰²ï¼šä¸€ç§ç”¨äºå¤æ‚ç»†èƒå½¢æ€ç”Ÿç‰©åŒ»å­¦åˆ†å‰²çš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥æ·±åº¦å­¦ä¹ æ–¹æ³•|Tianhao Zhang, Heather J. McCourty, Berardo M. Sanchez-Tafolla, Anton Nikolaev, Lyudmila S. Mihaylova|<http://arxiv.org/pdf/2409.17110v2>|[ä»£ç ](https://github.com/RanchoGoose/MorphoSeg.); æå‡ºMorphoSegï¼Œä¸€ç§åˆ©ç”¨ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œæ˜¾è‘—æå‡å¤æ‚ç»†èƒå½¢æ€åˆ†å‰²çš„å‡†ç¡®æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Segmenting France Across Four Centuries|æ³•å›½å››ç™¾å¹´é—´çš„åˆ†å‰²|Marta LÃ³pez-Rauhut, Hongyu Zhou, Mathieu Aubry, Loic Landrieu|<http://arxiv.org/pdf/2505.24824v1>|[ä»£ç ](https://github.com/Archiel19/FRAx4.git.); æ„å»ºäº†åŒ…å«å¤šä¸–çºªæ³•å›½åœ°å›¾çš„æ•°æ®åº“ï¼Œç”¨äºåˆ†æåœŸåœ°åˆ©ç”¨å˜åŒ–ï¼Œå¹¶è¯„ä¼°äº†ä¸åŒæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å†å²åœ°å›¾åˆ†å‰²ä¸­çš„è¡¨...|
|ğŸ“ æ›´æ–°|Deep Augmentation: Dropout as Augmentation for Self-Supervised Learning|æ·±åº¦å¢å¼ºï¼šDropoutä½œä¸ºè‡ªç›‘ç£å­¦ä¹ çš„å¢å¼ºæ–¹æ³•|Rickard BrÃ¼el-Gabrielsson, Tongzhou Wang, Manel Baradad, Justin Solomon|<http://arxiv.org/pdf/2303.14537v5>|æå‡ºDeep Augmentationï¼Œé€šè¿‡åœ¨ç¥ç»ç½‘ç»œæ·±å±‚åº”ç”¨dropoutæˆ–PCAï¼Œæœ‰æ•ˆç¼“è§£è‡ªç›‘ç£...|
|ğŸ†• å‘å¸ƒ|Conformal Prediction for Zero-Shot Models|é›¶æ ·æœ¬æ¨¡å‹ä¸­çš„ä¿å½¢é¢„æµ‹|Julio Silva-RodrÃ­guez, Ismail Ben Ayed, Jose Dolz|<http://arxiv.org/pdf/2505.24693v1>|æå‡ºConf-OTæ–¹æ³•ï¼Œé€šè¿‡è¿ç§»å­¦ä¹ æé«˜é›¶æ ·æœ¬æ¨¡å‹åœ¨è§†è§‰ä»»åŠ¡ä¸­çš„å¯é æ€§å’Œä¸ç¡®å®šæ€§ã€‚|
|ğŸ†• å‘å¸ƒ|BIMA: Bijective Maximum Likelihood Learning Approach to Hallucination Prediction and Mitigation in Large Vision-Language Models|BIMAï¼šç”¨äºå¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹å¹»è§‰é¢„æµ‹å’Œç¼“è§£çš„åŒå°„æœ€å¤§ä¼¼ç„¶å­¦ä¹ æ–¹æ³•|Huu-Thien Tran, Thanh-Dat Truong, Khoa Luu|<http://arxiv.org/pdf/2505.24649v1>|æå‡ºBIMAæ–¹æ³•ï¼Œåˆ©ç”¨å½’ä¸€åŒ–æµç†è®ºæœ‰æ•ˆç¼“è§£å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|Cloud Optical Thickness Retrievals Using Angle Invariant Attention Based Deep Learning Models|åŸºäºè§’åº¦ä¸å˜æ³¨æ„åŠ›æ·±åº¦å­¦ä¹ æ¨¡å‹çš„äº‘å…‰å­¦åšåº¦åæ¼”|Zahid Hassan Tushar, Adeleke Ademakinwa, Jianwu Wang, Zhibo Zhang, Sanjay Purushotham|<http://arxiv.org/pdf/2505.24638v1>|æå‡ºäº†ä¸€ç§åŸºäºè§’åº¦ç¼–ç çš„æ³¨æ„åŠ›æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œæ˜¾è‘—æé«˜äº†äº‘å…‰å­¦åšåº¦ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Diversify and Conquer: Open-set Disagreement for Robust Semi-supervised Learning with Outliers|å¤šæ ·åŒ–ä¸å¾æœï¼šå«å¼‚å¸¸å€¼çš„å¼€æ”¾é›†ä¸ä¸€è‡´æ€§åœ¨é²æ£’åŠç›‘ç£å­¦ä¹ ä¸­çš„åº”ç”¨|Heejo Kong, Sung-Jin Kim, Gunho Jung, Seong-Whan Lee|<http://arxiv.org/pdf/2505.24443v1>|[ä»£ç ](https://github.com/heejokong/DivCon.); æå‡ºäº†ä¸€ç§é€šè¿‡æ„å»ºä¸åŒåå¥½çš„æ¨¡å‹é›†åˆæ¥å¢å¼ºå¼€æ”¾é›†åŠç›‘ç£å­¦ä¹ é²æ£’æ€§çš„æ–¹æ³•ï¼Œä»¥åº”å¯¹å¼‚å¸¸å€¼å½±å“ã€‚|
|ğŸ†• å‘å¸ƒ|Advancing Compositional Awareness in CLIP with Efficient Fine-Tuning|åœ¨CLIPä¸­é€šè¿‡é«˜æ•ˆå¾®è°ƒæå‡ç»„åˆæ„è¯†|Amit Peleg, Naman Deep Singh, Matthias Hein|<http://arxiv.org/pdf/2505.24424v1>|CLICé€šè¿‡ç»“åˆå¤šå›¾åƒå’Œæè¿°ï¼Œæœ‰æ•ˆæå‡CLIPçš„ç»„æˆç†è§£ï¼Œæ”¹å–„æ£€ç´¢æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|Nested Hash Layer: A Plug-and-play Module for Multiple-length Hash Code Learning|åµŒå¥—å“ˆå¸Œå±‚ï¼šå¤šé•¿åº¦å“ˆå¸Œç å­¦ä¹ çš„å³æ’å³ç”¨æ¨¡å—|Liyang He, Yuren Zhang, Rui Li, Zhenya Huang, Runze Wu, Enhong Chen|<http://arxiv.org/pdf/2412.08922v2>|æå‡ºNested Hash Layerï¼Œè§£å†³å¤šé•¿åº¦å“ˆå¸Œç å­¦ä¹ æ•ˆç‡ä¸æ•ˆæœå¹³è¡¡é—®é¢˜ï¼Œæå‡æ¨¡å‹æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|A Mathematical Perspective On Contrastive Learning|å¯¹æ¯”å­¦ä¹ çš„æ•°å­¦è§†è§’|Ricardo Baptista, Andrew M. Stuart, Son Tran|<http://arxiv.org/pdf/2505.24134v1>|ä»æ•°å­¦è§’åº¦è§£æå¯¹æ¯”å­¦ä¹ ï¼Œæå‡ºæ¦‚ç‡æ¡†æ¶å’Œä½ç§©çŸ©é˜µè¿‘ä¼¼ï¼Œæ‹“å±•äº†å¤šæ¨¡æ€å­¦ä¹ ç®—æ³•ã€‚|
|ğŸ†• å‘å¸ƒ|Weakly-Supervised Affordance Grounding Guided by Part-Level Semantic Priors|å¼±ç›‘ç£ä¸‹åŸºäºéƒ¨åˆ†çº§è¯­ä¹‰å…ˆéªŒçš„é€‚åº”æ€§å®šä½å¼•å¯¼|Peiran Xu, Yadong Mu|<http://arxiv.org/pdf/2505.24103v1>|[ä»£ç ](https://github.com/woyut/WSAG-PLSP); åˆ©ç”¨ç°æœ‰æ¨¡å‹è¯­ä¹‰çŸ¥è¯†ï¼Œæå‡ºå¼±ç›‘ç£æ–¹æ³•ï¼Œæ˜¾è‘—æå‡ç‰©ä½“åŠŸèƒ½å®šä½æ€§èƒ½ã€‚|


### å°æ ·æœ¬å­¦ä¹  (Few-shot Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Zero-Shot Chinese Character Recognition with Hierarchical Multi-Granularity Image-Text Aligning|é›¶æ ·æœ¬æ±‰å­—è¯†åˆ«ï¼šåŸºäºåˆ†å±‚å¤šç²’åº¦å›¾åƒ-æ–‡æœ¬å¯¹é½|Yinglian Zhu, Haiyang Yu, Qizao Wang, Wei Lu, Xiangyang Xue, Bin Li|<http://arxiv.org/pdf/2505.24837v1>|æå‡ºäº†ä¸€ç§åŸºäºå±‚æ¬¡å¤šç²’åº¦å›¾åƒ-æ–‡æœ¬å¯¹é½çš„é›¶æ ·æœ¬æ±‰å­—è¯†åˆ«æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†è¯†åˆ«å‡†ç¡®ç‡ã€‚|
|ğŸ†• å‘å¸ƒ|Lightweight Relational Embedding in Task-Interpolated Few-Shot Networks for Enhanced Gastrointestinal Disease Classification|è½»é‡çº§å…³ç³»åµŒå…¥åœ¨ä»»åŠ¡æ’å€¼å°‘æ ·æœ¬ç½‘ç»œä¸­ç”¨äºå¢å¼ºèƒƒè‚ é“ç–¾ç—…åˆ†ç±»|Xinliu Zhong, Leo Hwa Liang, Angela S. Koh, Yeo Si Yong|<http://arxiv.org/pdf/2505.24792v1>|æå‡ºäº†ä¸€ç§è½»é‡çº§å…³ç³»åµŒå…¥æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†èƒƒè‚ é“ç–¾ç—…åˆ†ç±»çš„å‡†ç¡®æ€§ã€‚|


### é›¶/å°‘æ ·æœ¬æ³›åŒ– (Zero/Few-shot Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Behind the Magic, MERLIM: Multi-modal Evaluation Benchmark for Large Image-Language Models|é­”æ³•çš„èƒŒåï¼ŒMERLIMï¼šå¤§å‹å›¾åƒ-è¯­è¨€æ¨¡å‹çš„å¤šæ¨¡æ€è¯„ä¼°åŸºå‡†|AndrÃ©s Villa, Juan Carlos LeÃ³n AlcÃ¡zar, Alvaro Soto, Bernard Ghanem|<http://arxiv.org/pdf/2312.02219v3>|æ„å»ºMERLIMå¤šæ¨¡æ€è¯„ä¼°åŸºå‡†ï¼Œè¯„ä¼°IT-LVLMsåœ¨åŸºç¡€è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸Šçš„èƒ½åŠ›ï¼Œæ­ç¤ºå…¶å±€é™æ€§ã€‚|


## å…·èº«æ™ºèƒ½ä¸äº¤äº’è§†è§‰ (Embodied Intelligence & Interactive Vision)


### è§†è§‰æ“ä½œä¸æ§åˆ¶ (Visual Manipulation & Control)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Right Side Up? Disentangling Orientation Understanding in MLLMs with Fine-grained Multi-axis Perception Tasks|ã€Šæ­£ç«‹å—ï¼Ÿé€šè¿‡ç»†ç²’åº¦å¤šè½´æ„ŸçŸ¥ä»»åŠ¡åœ¨å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ä¸­è§£è€¦æ–¹å‘ç†è§£ã€‹|Keanu Nichols, Nazia Tasnim, Yuting Yan, Nicholas Ikechukwu, Elva Zou, Deepti Ghadiyaram, Bryan A. Plummer|<http://arxiv.org/pdf/2505.21649v3>|æå‡ºDORIåŸºå‡†ï¼Œæ­ç¤ºå¤šæ¨¡æ€ç³»ç»Ÿåœ¨ç‰©ä½“æ–¹å‘ç†è§£ä¸Šçš„å±€é™æ€§ã€‚|


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### å¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿ (Multimodal Dialogue Systems)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents|å¼€æ”¾CaptchaWorldï¼šä¸€ä¸ªç”¨äºæµ‹è¯•å’ŒåŸºå‡†æµ‹è¯•å¤šæ¨¡æ€LLMä»£ç†çš„å…¨é¢åœ¨çº¿å¹³å°|Yaxin Luo, Zhaoyi Li, Jiacheng Liu, Jiacheng Cui, Xiaohan Zhao, Zhiqiang Shen|<http://arxiv.org/pdf/2505.24878v1>|æ„å»ºäº†Open CaptchaWorldå¹³å°ï¼Œé€šè¿‡å¤šæ¨¡æ€LLMåœ¨åŠ¨æ€CAPTCHAæµ‹è¯•ä¸­è¯„ä¼°å…¶è§†è§‰æ¨...|


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ProxyThinker: Test-Time Guidance through Small Visual Reasoners|ProxyThinkerï¼šé€šè¿‡å°å‹è§†è§‰æ¨ç†å™¨è¿›è¡Œæµ‹è¯•æ—¶å¼•å¯¼|Zilin Xiao, Jaywon Koo, Siru Ouyang, Jefferson Hernandez, Yu Meng, Vicente Ordonez|<http://arxiv.org/pdf/2505.24872v1>|[ä»£ç ](https://github.com/MrZilinXiao/ProxyThinker.); ProxyThinkeré€šè¿‡å°å‹è§†è§‰æ¨ç†å™¨åœ¨æ¨ç†æ—¶å¼•å¯¼å¤§å‹æ¨¡å‹ï¼Œå®ç°æ— éœ€è®­ç»ƒçš„è§†è§‰æ¨ç†èƒ½åŠ›æå‡ã€‚|
|ğŸ†• å‘å¸ƒ|VideoCAD: A Large-Scale Video Dataset for Learning UI Interactions and 3D Reasoning from CAD Software|è§†é¢‘CADï¼šä¸€ä¸ªç”¨äºä»CADè½¯ä»¶ä¸­å­¦ä¹ UIäº¤äº’å’Œ3Dæ¨ç†çš„å¤§è§„æ¨¡è§†é¢‘æ•°æ®é›†|Brandon Man, Ghadi Nehme, Md Ferdous Alam, Faez Ahmed|<http://arxiv.org/pdf/2505.24838v1>|æ„å»ºå¤§è§„æ¨¡è§†é¢‘æ•°æ®é›†VideoCADï¼Œç”¨äºä»CADè½¯ä»¶å­¦ä¹ UIäº¤äº’å’Œ3Dæ¨ç†ã€‚|
|ğŸ†• å‘å¸ƒ|Vision LLMs Are Bad at Hierarchical Visual Understanding, and LLMs Are the Bottleneck|è§†è§‰LLMsåœ¨å±‚æ¬¡è§†è§‰ç†è§£æ–¹é¢è¡¨ç°ä¸ä½³ï¼ŒLLMsæ˜¯ç“¶é¢ˆ|Yuwen Tan, Yuan Qing, Boqing Gong|<http://arxiv.org/pdf/2505.24840v1>|æ­ç¤ºè§†è§‰LLMsç¼ºä¹å±‚æ¬¡è§†è§‰ç†è§£èƒ½åŠ›ï¼Œå¹¶æå‡ºé€šè¿‡VQAä»»åŠ¡æå‡LLMså±‚æ¬¡ä¸€è‡´æ€§çš„æ–¹æ³•ã€‚|
|ğŸ“ æ›´æ–°|SoTA with Less: MCTS-Guided Sample Selection for Data-Efficient Visual Reasoning Self-Improvement|SoTA with Lessï¼šåŸºäºMCTSçš„æ ·æœ¬é€‰æ‹©ï¼Œå®ç°æ•°æ®é«˜æ•ˆè§†è§‰æ¨ç†è‡ªæˆ‘æ”¹è¿›|Xiyao Wang, Zhengyuan Yang, Chao Feng, Hongjin Lu, Linjie Li, Chung-Ching Lin, Kevin Lin, Furong Huang .etc.|<http://arxiv.org/pdf/2504.07934v3>|é€šè¿‡MCTSæŒ‡å¯¼çš„æ ·æœ¬é€‰æ‹©ï¼ŒThinkLite-VLæ¨¡å‹åœ¨æ›´å°‘è®­ç»ƒæ ·æœ¬ä¸‹å®ç°è§†è§‰æ¨ç†æ€§èƒ½çš„æ˜¾è‘—æå‡ã€‚|
|ğŸ“ æ›´æ–°|Hierarchical Attention Fusion of Visual and Textual Representations for Cross-Domain Sequential Recommendation|è·¨åŸŸåºåˆ—æ¨èçš„è§†è§‰å’Œæ–‡æœ¬è¡¨ç¤ºçš„å±‚æ¬¡æ³¨æ„åŠ›èåˆ|Wangyu Wu, Zhenhong Chen, Siqi Song, Xianglin Qiu, Xiaowei Huang, Fei Ma, Jimin Xiao|<http://arxiv.org/pdf/2504.15085v2>|æå‡ºHAF-VTæ¨¡å‹ï¼Œèåˆè§†è§‰å’Œæ–‡æœ¬è¡¨ç¤ºï¼Œæå‡è·¨åŸŸæ¨èè®¤çŸ¥å»ºæ¨¡ã€‚|
|ğŸ“ æ›´æ–°|RedundancyLens: Revealing and Exploiting Visual Token Processing Redundancy for Efficient Decoder-Only MLLMs|å†—ä½™é•œå¤´ï¼šæ­ç¤ºå’Œåˆ©ç”¨è§†è§‰æ ‡è®°å¤„ç†å†—ä½™ä»¥å®ç°é«˜æ•ˆä»…è§£ç å™¨å¤šè¯­è¨€è¯­è¨€æ¨¡å‹|Hongliang Li, Jiaxin Zhang, Wenhui Liao, Dezhi Peng, Kai Ding, Lianwen Jin|<http://arxiv.org/pdf/2501.19036v3>|[ä»£ç ](https://github.com/L-Hugh/RedundancyLens.); RedundancyLensæ­ç¤ºå¹¶åˆ©ç”¨è§†è§‰tokenå¤„ç†å†—ä½™ï¼Œå®ç°é«˜æ•ˆè§£ç å™¨ä»…MLLMã€‚|
|ğŸ“ æ›´æ–°|"See the World, Discover Knowledge": A Chinese Factuality Evaluation for Large Vision Language Models|ã€Šè§ä¸–ç•Œï¼Œè¯†çŸ¥è¯†ï¼šå¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹çš„ä¸­å›½äº‹å®æ€§è¯„ä¼°ã€‹|Jihao Gu, Yingyao Wang, Pi Bu, Chen Wang, Ziming Wang, Tengtao Song, Donglai Wei, Jiale Yuan .etc.|<http://arxiv.org/pdf/2502.11718v4>|æ„å»ºé¦–ä¸ªä¸­æ–‡è§†è§‰é—®ç­”åŸºå‡†ï¼Œè¯„ä¼°å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹çš„äº‹å®å‡†ç¡®æ€§ã€‚|
|ğŸ“ æ›´æ–°|Expanding the Boundaries of Vision Prior Knowledge in Multi-modal Large Language Models|æ‹“å±•å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­è§†è§‰å…ˆéªŒçŸ¥è¯†çš„è¾¹ç•Œ|Qiao Liang, Yanjiang Liu, Weixiang Zhou, Ben He, Yaojie Lu, Hongyu Lin, Jia Zheng, Xianpei Han .etc.|<http://arxiv.org/pdf/2503.18034v2>|æå‡ºVisPREæ¡†æ¶ï¼Œé€šè¿‡å¢å¼ºè§†è§‰ç¼–ç å™¨å…ˆéªŒçŸ¥è¯†ï¼Œæ˜¾è‘—æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å¯¹è§†è§‰å†…å®¹çš„ç†è§£èƒ½åŠ›ã€‚|
|ğŸ“ æ›´æ–°|Qwen Look Again: Guiding Vision-Language Reasoning Models to Re-attention Visual Information|Qwenå†æ¬¡å®¡è§†ï¼šå¼•å¯¼è§†è§‰-è¯­è¨€æ¨ç†æ¨¡å‹é‡æ–°å…³æ³¨è§†è§‰ä¿¡æ¯|Xu Chu, Xinrong Chen, Guanyu Wang, Zhijie Tan, Kui Huang, Wenyu Lv, Tong Mo, Weiping Li|<http://arxiv.org/pdf/2505.23558v2>|[ä»£ç ](https://github.com/Liar406/Look_Again); Qwen-LookAgainé€šè¿‡å¼•å¯¼æ¨¡å‹é‡æ–°å…³æ³¨è§†è§‰ä¿¡æ¯ï¼Œæœ‰æ•ˆå‡è½»äº†è§†è§‰è¯­è¨€æ¨ç†æ¨¡å‹ä¸­çš„å¹»è§‰é—®é¢˜ã€‚|
|ğŸ“ æ›´æ–°|ProReason: Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom|ProReasonï¼šè§£è€¦è§†è§‰ä¸æ™ºæ…§çš„è·¨æ¨¡æ€ä¸»åŠ¨æ¨ç†|Jingqi Zhou, Sheng Wang, Jingwei Dong, Kai Liu, Lei Li, Jiahui Gao, Jiyue Jiang, Lingpeng Kong .etc.|<http://arxiv.org/pdf/2410.14138v3>|æå‡ºProReasonæ¡†æ¶ï¼Œé€šè¿‡è§£è€¦è§†è§‰æ„ŸçŸ¥å’Œæ–‡æœ¬æ¨ç†ï¼Œæå‡è§†è§‰è¯­è¨€æ¨¡å‹åœ¨æ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚|
|ğŸ“ æ›´æ–°|VLM-R$^3$: Region Recognition, Reasoning, and Refinement for Enhanced Multimodal Chain-of-Thought|VLM-R$^3$ï¼šåŒºåŸŸè¯†åˆ«ã€æ¨ç†å’Œä¼˜åŒ–ä»¥å¢å¼ºå¤šæ¨¡æ€æ€ç»´é“¾|Chaoya Jiang, Yongrui Heng, Wei Ye, Han Yang, Haiyang Xu, Ming Yan, Ji Zhang, Fei Huang .etc.|<http://arxiv.org/pdf/2505.16192v2>|VLM-R$^3$é€šè¿‡åŒºåŸŸè¯†åˆ«ã€æ¨ç†å’Œç»†åŒ–ï¼Œæå‡äº†å¤šæ¨¡æ€æ€ç»´é“¾çš„è§†è§‰è¯æ®ç²¾ç¡®æ€§ã€‚|
|ğŸ“ æ›´æ–°|Evaluating Visual and Cultural Interpretation: The K-Viscuit Benchmark with Human-VLM Collaboration|è¯„ä¼°è§†è§‰ä¸æ–‡åŒ–è§£è¯»ï¼šK-ViscuitåŸºå‡†ä¸äººç±»-VLMåä½œ|ChaeHun Park, Yujin Baek, Jaeseok Kim, Yu-Jung Heo, Du-Seong Chang, Jaegul Choo|<http://arxiv.org/pdf/2406.16469v3>|æå‡ºK-ViscuitåŸºå‡†ï¼Œé€šè¿‡äººæœºåä½œæ„å»ºæ–‡åŒ–VLMåŸºå‡†ï¼Œè¯„ä¼°VLMåœ¨æ–‡åŒ–ç›¸å…³é—®é¢˜ä¸Šçš„ç†è§£èƒ½åŠ›ã€‚|
|ğŸ“ æ›´æ–°|Beyond Perception: Evaluating Abstract Visual Reasoning through Multi-Stage Task|è¶…è¶Šæ„ŸçŸ¥ï¼šé€šè¿‡å¤šé˜¶æ®µä»»åŠ¡è¯„ä¼°æŠ½è±¡è§†è§‰æ¨ç†|Yanbei Jiang, Yihao Ding, Chao Lei, Jiayang Ao, Jey Han Lau, Krista A. Ehinger|<http://arxiv.org/pdf/2505.21850v2>|æ„å»ºäº†å¤šé˜¶æ®µæŠ½è±¡è§†è§‰æ¨ç†åŸºå‡†å’Œå¤šé˜¶æ®µè¯„ä¼°æŒ‡æ ‡ï¼Œæ­ç¤ºäº†ç°æœ‰å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†é˜¶æ®µçš„æŒ‘æˆ˜ã€‚|
|ğŸ†• å‘å¸ƒ|Light as Deception: GPT-driven Natural Relighting Against Vision-Language Pre-training Models|è½»å¦‚æ¬ºéª—ï¼šGPTé©±åŠ¨çš„è‡ªç„¶é‡å…‰ç…§å¯¹æŠ—è§†è§‰-è¯­è¨€é¢„è®­ç»ƒæ¨¡å‹|Ying Yang, Jie Zhang, Xiao Lv, Di Lin, Tao Xiang, Qing Guo|<http://arxiv.org/pdf/2505.24227v1>|æå‡ºLightDæ¡†æ¶ï¼Œé€šè¿‡è¯­ä¹‰å¼•å¯¼çš„é‡æ–°ç…§æ˜ç”Ÿæˆè‡ªç„¶å¯¹æŠ—æ ·æœ¬ï¼Œæœ‰æ•ˆå¯¹æŠ—è§†è§‰è¯­è¨€é¢„è®­ç»ƒæ¨¡å‹ã€‚|
|ğŸ†• å‘å¸ƒ|Seeing is Not Reasoning: MVPBench for Graph-based Evaluation of Multi-path Visual Physical CoT|è§†è§‰æ¨ç†å¹¶éæ¨ç†ï¼šåŸºäºå›¾çš„å¤šå…ƒè·¯å¾„è§†è§‰ç‰©ç†CoTè¯„ä¼°çš„MVPBench|Zhuobai Dong, Junchao Yi, Ziyuan Zheng, Haochen Han, Xiangxi Zheng, Alex Jinpeng Wang, Fangming Liu, Linjie Li|<http://arxiv.org/pdf/2505.24182v1>|æ„å»ºMVPBenchåŸºå‡†ï¼Œè¯„ä¼°å¤šè·¯å¾„è§†è§‰ç‰©ç†æ¨ç†èƒ½åŠ›ï¼Œæ­ç¤ºMLLMsåœ¨ç‰©ç†åœºæ™¯ä¸­æ¨ç†èƒ½åŠ›ä¸è¶³ã€‚|
|ğŸ†• å‘å¸ƒ|Training-free zero-shot 3D symmetry detection with visual features back-projected to geometry|æ— éœ€è®­ç»ƒçš„åŸºäºè§†è§‰ç‰¹å¾çš„å‡ ä½•æŠ•å½±é›¶æ ·æœ¬3Då¯¹ç§°æ€§æ£€æµ‹|Isaac Aguirre, Ivan Sipiran|<http://arxiv.org/pdf/2505.24162v1>|æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„é›¶æ ·æœ¬3Då¯¹ç§°æ€§æ£€æµ‹æ–¹æ³•ï¼Œåˆ©ç”¨è§†è§‰ç‰¹å¾åœ¨å‡ ä½•ä¸Šå›å°„è¯†åˆ«åå°„å¯¹ç§°é¢ã€‚|
|ğŸ“ æ›´æ–°|IMTS is Worth Time $\times$ Channel Patches: Visual Masked Autoencoders for Irregular Multivariate Time Series Prediction|IMTSå€¼å¾—æ—¶é—´Ã—é€šé“è¡¥ä¸ï¼šç”¨äºä¸è§„åˆ™å¤šå…ƒæ—¶é—´åºåˆ—é¢„æµ‹çš„è§†è§‰æ©ç è‡ªç¼–ç å™¨|Zhangyi Hu, Jiemin Wu, Hua Xu, Mingqian Liao, Ninghui Feng, Bo Gao, Songning Lai, Yutao Yue|<http://arxiv.org/pdf/2505.22815v2>|[ä»£ç ](https://github.com/WHU-HZY/VIMTS.); æå‡ºVIMTSæ¡†æ¶ï¼Œåˆ©ç”¨è§†è§‰æ©ç è‡ªç¼–ç å™¨å¤„ç†ä¸è§„åˆ™å¤šå˜é‡æ—¶é—´åºåˆ—é¢„æµ‹ï¼Œæœ‰æ•ˆè§£å†³ç¼ºå¤±å€¼é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|CSVQA: A Chinese Multimodal Benchmark for Evaluating STEM Reasoning Capabilities of VLMs|CSVQAï¼šç”¨äºè¯„ä¼°VLMs STEMæ¨ç†èƒ½åŠ›çš„ä¸­æ–‡å¤šæ¨¡æ€åŸºå‡†|Ai Jian, Weijie Qiu, Xiaokun Wang, Peiyu Wang, Yunzhuo Hao, Jiangbo Pei, Yichen Wei, Yi Peng .etc.|<http://arxiv.org/pdf/2505.24120v1>|æ„å»ºCSVQAåŸºå‡†ï¼Œè¯„ä¼°VLMsåœ¨ç§‘å­¦æ¨ç†æ–¹é¢çš„èƒ½åŠ›ï¼Œæ­ç¤ºå…¶å±€é™æ€§ã€‚|


### è§†è§‰å†…å®¹æè¿° (Visual Content Description)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|VideoGameBench: Can Vision-Language Models complete popular video games?|è§†é¢‘æ¸¸æˆåŸºå‡†ï¼šè§†è§‰-è¯­è¨€æ¨¡å‹èƒ½å¦å®Œæˆæµè¡Œè§†é¢‘æ¸¸æˆï¼Ÿ|Alex L. Zhang, Thomas L. Griffiths, Karthik R. Narasimhan, Ofir Press|<http://arxiv.org/pdf/2505.18134v2>|VideoGameBenchæŒ‘æˆ˜VLMåœ¨æ— è¾…åŠ©ä¿¡æ¯ä¸‹å®Œæˆç»å…¸æ¸¸æˆï¼Œæ­ç¤ºå®æ—¶äº¤äº’é™åˆ¶ã€‚|
|ğŸ“ æ›´æ–°|Are MLMs Trapped in the Visual Room?|MLMsæ˜¯å¦è¢«å›°åœ¨è§†è§‰æˆ¿é—´å†…ï¼Ÿ|Yazhou Zhang, Chunwang Zou, Qimeng Liu, Lu Rong, Ben Yao, Zheng Lian, Qiuchi Li, Peng Zhang .etc.|<http://arxiv.org/pdf/2505.23272v2>|æå‡ºâ€œè§†è§‰æˆ¿é—´â€å‡è¯´ï¼Œé€šè¿‡æ„ŸçŸ¥ä¸è®¤çŸ¥åŒå±‚è¯„ä¼°æ¡†æ¶æ­ç¤ºå¤šæ¨¡æ€å¤§æ¨¡å‹åœ¨è§†è§‰ç†è§£ä¸Šçš„å±€é™æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|KEVER^2: Knowledge-Enhanced Visual Emotion Reasoning and Retrieval|KEVER^2ï¼šçŸ¥è¯†å¢å¼ºçš„è§†è§‰æƒ…æ„Ÿæ¨ç†ä¸æ£€ç´¢|Fanhang Man, Xiaoyue Chen, Huandong Wang, Baining Zhao, Han Li, Xinlei Chen, Yong Li|<http://arxiv.org/pdf/2505.24342v1>|æå‡ºäº†ä¸€ç§ç»“åˆçŸ¥è¯†å¢å¼ºçš„è§†è§‰æƒ…æ„Ÿæ¨ç†ä¸æ£€ç´¢æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†è·¨é¢†åŸŸæƒ…æ„Ÿè¯†åˆ«çš„å‡†ç¡®ç‡ã€‚|
|ğŸ†• å‘å¸ƒ|D2AF: A Dual-Driven Annotation and Filtering Framework for Visual Grounding|D2AFï¼šä¸€ç§ç”¨äºè§†è§‰å®šä½çš„é©±åŠ¨å¼æ ‡æ³¨ä¸è¿‡æ»¤æ¡†æ¶|Yichi Zhang, Gongwei Chen, Jun Zhu, Jia Wan|<http://arxiv.org/pdf/2505.24372v1>|æå‡ºD2AFæ¡†æ¶ï¼Œé€šè¿‡å›¾åƒè‡ªåŠ¨æ ‡æ³¨å’Œç­›é€‰ï¼Œæœ‰æ•ˆæå‡è§†è§‰å®šä½ä»»åŠ¡æ€§èƒ½ã€‚|


### è·¨æ¨¡æ€æ£€ç´¢ä¸åŒ¹é… (Cross-modal Retrieval & Matching)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SA-Person: Text-Based Person Retrieval with Scene-aware Re-ranking|åŸºäºåœºæ™¯æ„ŸçŸ¥é‡æ’åºçš„æ–‡æœ¬å¼äººç‰©æ£€ç´¢ï¼šSA-Person|Yingjia Xu, Jinlin Wu, Zhen Chen, Daming Gao, Yang Yang, Zhen Lei, Min Cao|<http://arxiv.org/pdf/2505.24466v1>|æå‡ºä¸€ç§ç»“åˆåœºæ™¯æ„ŸçŸ¥é‡æ’åºçš„æ–‡æœ¬åŸºäººç‰©æ£€ç´¢æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡åœºæ™¯çº§æ£€ç´¢æ•ˆæœã€‚|


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### åˆ›æ„åª’ä½“ç”Ÿæˆ (Creative Media Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|TalkingHeadBench: A Multi-Modal Benchmark & Analysis of Talking-Head DeepFake Detection|äººå£°å¤´åƒåŸºå‡†ä¸æ·±åº¦ä¼ªé€ æ£€æµ‹çš„å¤šæ¨¡æ€åˆ†æä¸è¯„ä¼°|Xinqi Xiong, Prakrut Patel, Qingyuan Fan, Amisha Wadhwa, Sarathy Selvam, Xiao Guo, Luchao Qi, Xiaoming Liu .etc.|<http://arxiv.org/pdf/2505.24866v1>|æ„å»ºäº†TalkingHeadBenchåŸºå‡†ï¼Œè¯„ä¼°äº†å…ˆè¿›ç”Ÿæˆæ¨¡å‹ä¸‹æ·±åº¦ä¼ªé€ æ£€æµ‹æ¨¡å‹çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚|


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|CLIP-IT: CLIP-based Pairing for Histology Images Classification|CLIP-ITï¼šåŸºäºCLIPçš„ç—…ç†å›¾åƒé…å¯¹åˆ†ç±»|Banafsheh Karimian, Giulia Avanzato, Soufian Belharbi, Luke McCaffrey, Mohammadhadi Shateri, Eric Granger|<http://arxiv.org/pdf/2504.16181v2>|CLIP-ITé€šè¿‡ç»“åˆå¤–éƒ¨æ–‡æœ¬ä¿¡æ¯ï¼Œæ— éœ€æ‰‹åŠ¨é…å¯¹æ ·æœ¬ï¼Œæœ‰æ•ˆåˆ©ç”¨ç‰¹æƒæ–‡æœ¬ä¿¡æ¯ï¼Œæå‡ç—…ç†å›¾åƒåˆ†ç±»æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|Decoupled Competitive Framework for Semi-supervised Medical Image Segmentation|è§£è€¦ç«äº‰æ¡†æ¶ç”¨äºåŠç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²|Jiahe Chen, Jiahe Ying, Shen Wang, Jianwei Zheng|<http://arxiv.org/pdf/2505.24667v1>|[ä»£ç ](https://github.com/JiaheChen2002/DCF.); æå‡ºäº†ä¸€ç§è§£è€¦ç«äº‰æ¡†æ¶ï¼Œæœ‰æ•ˆç¼“è§£äº†åŠç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­çš„è¿‡è€¦åˆå’Œè®¤çŸ¥åå·®é—®é¢˜ã€‚|
|ğŸ“ æ›´æ–°|LesionDiffusion: Towards Text-controlled General Lesion Synthesis|æŸä¼¤æ‰©æ•£ï¼šè¿ˆå‘æ–‡æœ¬æ§åˆ¶çš„é€šç”¨æŸä¼¤åˆæˆ|Henrui Tian, Wenhui Lei, Linrui Dai, Hanyu Chen, Xiaofan Zhang|<http://arxiv.org/pdf/2503.00741v4>|[ä»£ç ](https://github.com/HengruiTianSJTU/LesionDiffusion.); æå‡ºLesionDiffusionï¼Œé€šè¿‡æ–‡æœ¬æ§åˆ¶å®ç°åŒ»å­¦å›¾åƒä¸­ç—…å˜çš„åˆæˆï¼Œæå‡ç—…å˜è¯†åˆ«æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|Unleashing the Power of Intermediate Domains for Mixed Domain Semi-Supervised Medical Image Segmentation|é‡Šæ”¾ä¸­é—´åŸŸåŠ›é‡ä»¥å®ç°æ··åˆåŸŸåŠç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²|Qinghe Ma, Jian Zhang, Lei Qi, Qian Yu, Yinghuan Shi, Yang Gao|<http://arxiv.org/pdf/2505.24567v1>|[ä»£ç ](https://github.com/MQinghe/UST-RUN); æå‡ºUST-RUNæ¡†æ¶ï¼Œåˆ©ç”¨ä¸­é—´åŸŸä¿¡æ¯è§£å†³æ··åˆåŸŸåŠç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|ACM-UNet: Adaptive Integration of CNNs and Mamba for Efficient Medical Image Segmentation|ACM-UNetï¼šCNNä¸Mambaè‡ªé€‚åº”é›†æˆä»¥å®ç°é«˜æ•ˆçš„åŒ»å­¦å›¾åƒåˆ†å‰²|Jing Huang, Yongkang Zhao, Yuhan Li, Zhitao Dai, Cheng Chen, Qiying Lai|<http://arxiv.org/pdf/2505.24481v1>|[ä»£ç ](https://github.com/zyklcode/ACM-UNet.); ACM-UNeté€šè¿‡è½»é‡é€‚é…å™¨ç»“åˆCNNå’ŒMambaï¼Œæœ‰æ•ˆæå‡åŒ»ç–—å›¾åƒåˆ†å‰²æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|Adversarially Robust AI-Generated Image Detection for Free: An Information Theoretic Perspective|å¯¹æŠ—é²æ£’çš„å…è´¹AIç”Ÿæˆå›¾åƒæ£€æµ‹ï¼šä¿¡æ¯è®ºè§†è§’|Ruixuan Zhang, He Wang, Zhengyu Zhao, Zhiqing Guo, Xun Yang, Yunfeng Diao, Meng Wang|<http://arxiv.org/pdf/2505.22604v2>|æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„åŸºäºä¿¡æ¯ç†è®ºçš„å›¾åƒæ£€æµ‹æ–¹æ³•ï¼Œæœ‰æ•ˆé˜²å¾¡å¯¹æŠ—æ”»å‡»ã€‚|
|ğŸ†• å‘å¸ƒ|pyMEAL: A Multi-Encoder Augmentation-Aware Learning for Robust and Generalizable Medical Image Translation|pyMEALï¼šä¸€ç§é’ˆå¯¹é²æ£’å’Œæ³›åŒ–åŒ»å­¦å›¾åƒç¿»è¯‘çš„å¤šç¼–ç å™¨å¢å¼ºæ„ŸçŸ¥å­¦ä¹ |Abdul-mojeed Olabisi Ilyas, Adeleke Maradesa, Jamal Banzi, Jianpan Huang, Henry K. F. Mak, Kannie W. Y. Chan|<http://arxiv.org/pdf/2505.24421v1>|æå‡ºMEALæ¡†æ¶ï¼Œé€šè¿‡å¤šç¼–ç å™¨èåˆä¸åŒå¢å¼ºç‰¹å¾ï¼Œæå‡åŒ»å­¦å›¾åƒè½¬æ¢çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|KairosAD: A SAM-Based Model for Industrial Anomaly Detection on Embedded Devices|å‡¯ç½—æ–¯ADï¼šåŸºäºSAMçš„åµŒå…¥å¼è®¾å¤‡å·¥ä¸šå¼‚å¸¸æ£€æµ‹æ¨¡å‹|Uzair Khan, Franco Fummi, Luigi Capogrosso|<http://arxiv.org/pdf/2505.24334v1>|[ä»£ç ](https://github.com/intelligolabs/KairosAD.); æå‡ºäº†ä¸€ç§åŸºäºMobileSAMçš„è½»é‡çº§å·¥ä¸šå¼‚å¸¸æ£€æµ‹æ¨¡å‹ï¼Œæœ‰æ•ˆé™ä½è®¡ç®—éœ€æ±‚å¹¶æå‡éƒ¨ç½²æ•ˆç‡ã€‚|
|ğŸ†• å‘å¸ƒ|DrVD-Bench: Do Vision-Language Models Reason Like Human Doctors in Medical Image Diagnosis?|DrVD-Benchï¼šåœ¨åŒ»å­¦å›¾åƒè¯Šæ–­ä¸­ï¼Œè§†è§‰-è¯­è¨€æ¨¡å‹æ¨ç†æ˜¯å¦åƒäººç±»åŒ»ç”Ÿä¸€æ ·ï¼Ÿ|Tianhong Zhou, Yin Xu, Yingtao Zhu, Chuxi Xiao, Haiyang Bian, Lei Wei, Xuegong Zhang|<http://arxiv.org/pdf/2505.24173v1>|æ„å»ºäº†é¦–ä¸ªä¸´åºŠè§†è§‰æ¨ç†å¤šæ¨¡æ€åŸºå‡†DrVD-Benchï¼Œè¯„ä¼°è§†è§‰è¯­è¨€æ¨¡å‹åœ¨åŒ»å­¦å›¾åƒè¯Šæ–­ä¸­çš„æ¨ç†èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|Beyond the LUMIR challenge: The pathway to foundational registration models|è¶…è¶ŠLUMIRæŒ‘æˆ˜ï¼šåŸºç¡€é…å‡†æ¨¡å‹çš„è·¯å¾„|Junyu Chen, Shuwen Wei, Joel Honkamaa, Pekka Marttinen, Hang Zhang, Min Liu, Yichao Zhou, Zuopeng Tan .etc.|<http://arxiv.org/pdf/2505.24160v1>|æå‡ºLUMIRæŒ‘æˆ˜ï¼Œæ¨åŠ¨æ— ç›‘ç£è„‘MRIå›¾åƒæ³¨å†Œï¼Œå®ç°è·¨æ¨¡æ€ã€ç–¾ç—…å’Œç‰©ç§çš„é›¶æ ·æœ¬æ³›åŒ–ã€‚|


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|REJEPA: A Novel Joint-Embedding Predictive Architecture for Efficient Remote Sensing Image Retrieval|REJEPAï¼šä¸€ç§ç”¨äºé«˜æ•ˆé¥æ„Ÿå›¾åƒæ£€ç´¢çš„æ–°å‹è”åˆåµŒå…¥é¢„æµ‹æ¶æ„|Shabnam Choudhury, Yash Salunkhe, Sarthak Mehrotra, Biplab Banerjee|<http://arxiv.org/pdf/2504.03169v2>|æå‡ºREJEPAï¼Œä¸€ç§é«˜æ•ˆã€ç²¾ç¡®çš„é¥æ„Ÿå›¾åƒæ£€ç´¢æ¡†æ¶ï¼Œé€šè¿‡è”åˆåµŒå…¥é¢„æµ‹æ¶æ„æå‡æ£€ç´¢å‡†ç¡®ç‡ã€‚|
|ğŸ†• å‘å¸ƒ|Deformable Attention Mechanisms Applied to Object Detection, case of Remote Sensing|å¯å˜å½¢æ³¨æ„åŠ›æœºåˆ¶åœ¨ç›®æ ‡æ£€æµ‹ä¸­çš„åº”ç”¨ï¼šé¥æ„Ÿæ¡ˆä¾‹|Anasse Boutayeb, Iyad Lahsen-cherif, Ahmed El Khadimi|<http://arxiv.org/pdf/2505.24489v1>|æå‡ºDeformable-DETRæ¨¡å‹ï¼Œæœ‰æ•ˆæå‡é¥æ„Ÿå›¾åƒç›®æ ‡æ£€æµ‹å‡†ç¡®ç‡ã€‚|
|ğŸ†• å‘å¸ƒ|GeoVision Labeler: Zero-Shot Geospatial Classification with Vision and Language Models|åœ°ç†è§†è§‰æ ‡æ³¨å™¨ï¼šåŸºäºè§†è§‰å’Œè¯­è¨€æ¨¡å‹çš„é›¶æ ·æœ¬åœ°ç†ç©ºé—´åˆ†ç±»|Gilles Quentin Hacheme, Girmaw Abebe Tadesse, Caleb Robinson, Akram Zaytar, Rahul Dodhia, Juan M. Lavista Ferres|<http://arxiv.org/pdf/2505.24340v1>|[ä»£ç ](https://github.com/microsoft/geo-vision-labeler); GeoVision Labeleré€šè¿‡ç»“åˆè§†è§‰å’Œè¯­è¨€æ¨¡å‹å®ç°é›¶æ ·æœ¬åœ°ç†ç©ºé—´å›¾åƒåˆ†ç±»ï¼Œæé«˜ç¾å®³å“åº”å’ŒåœŸ...|
|ğŸ†• å‘å¸ƒ|Revisiting Cross-Modal Knowledge Distillation: A Disentanglement Approach for RGBD Semantic Segmentation|é‡æ–°å®¡è§†è·¨æ¨¡æ€çŸ¥è¯†è’¸é¦ï¼šä¸€ç§ç”¨äºRGBDè¯­ä¹‰åˆ†å‰²çš„è§£è€¦æ–¹æ³•|Roger Ferrod, CÃ¡ssio F. Dantas, Luigi Di Caro, Dino Ienco|<http://arxiv.org/pdf/2505.24361v1>|æå‡ºäº†ä¸€ç§åŸºäºè§£è€¦è¡¨ç¤ºå’Œå¯¹æ¯”å­¦ä¹ çš„è·¨æ¨¡æ€çŸ¥è¯†è’¸é¦æ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†RGBDè¯­ä¹‰åˆ†å‰²ä¸­æ¨¡æ€ä¸åŒ¹é…é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|STAR-Net: An Interpretable Model-Aided Network for Remote Sensing Image Denoising|STAR-Netï¼šä¸€ç§ç”¨äºé¥æ„Ÿå›¾åƒå»å™ªçš„å¯è§£é‡Šæ¨¡å‹è¾…åŠ©ç½‘ç»œ|Jingjing Liu, Jiashun Jin, Xianchao Xiu, Jianhua Zhang, Wanquan Liu|<http://arxiv.org/pdf/2505.24327v1>|STAR-Netæå‡ºäº†ä¸€ç§åŸºäºä½ç§©å…ˆéªŒçš„é¥æ„Ÿå›¾åƒå»å™ªæ–¹æ³•ï¼Œæœ‰æ•ˆæ•æ‰éå±€éƒ¨è‡ªç›¸ä¼¼æ€§å¹¶è‡ªåŠ¨å­¦ä¹ æ­£åˆ™åŒ–å‚æ•°...|


## æ–°å…´ç†è®ºä¸è·¨å­¦ç§‘æ–¹å‘ (Emerging Theory & Interdisciplinary Directions)


### é‡å­è§†è§‰ç®—æ³• (Quantum Visual Algorithms)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision Geometry Priors|ä»è§†é¢‘ä¸­å­¦ä¹ 3Dä¸–ç•Œï¼šåˆ©ç”¨3Dè§†è§‰å‡ ä½•å…ˆéªŒå¢å¼ºå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹|Duo Zheng, Shijia Huang, Yanyang Li, Liwei Wang|<http://arxiv.org/pdf/2505.24625v1>|æå‡ºä¸€ç§ä»è§†é¢‘æ•°æ®ä¸­ç›´æ¥å­¦ä¹ 3Dç©ºé—´ç†è§£çš„MLLMå¢å¼ºæ–¹æ³•ï¼Œæ˜¾è‘—æå‡3Dåœºæ™¯ç†è§£å’Œç©ºé—´æ¨ç†èƒ½åŠ›ã€‚|
|ğŸ“ æ›´æ–°|GUICourse: From General Vision Language Models to Versatile GUI Agents|GUIè¯¾ç¨‹ï¼šä»é€šç”¨è§†è§‰è¯­è¨€æ¨¡å‹åˆ°å¤šæ‰å¤šè‰ºçš„GUIæ™ºèƒ½ä½“|Wentong Chen, Junbo Cui, Jinyi Hu, Yujia Qin, Junjie Fang, Yue Zhao, Chongyi Wang, Jun Liu .etc.|<http://arxiv.org/pdf/2406.11317v2>|[ä»£ç ](https://github.com/yiye3/GUICourse.); æå‡ºGUICourseï¼Œé€šè¿‡æ•°æ®é›†å¢å¼ºï¼Œå°†é€šç”¨è§†è§‰è¯­è¨€æ¨¡å‹è®­ç»ƒæˆå¤šæ‰å¤šè‰ºçš„GUIæ™ºèƒ½ä½“ã€‚|
|ğŸ“ æ›´æ–°|JailBound: Jailbreaking Internal Safety Boundaries of Vision-Language Models|ã€ŠJailBoundï¼šçªç ´è§†è§‰-è¯­è¨€æ¨¡å‹å†…éƒ¨å®‰å…¨è¾¹ç•Œã€‹|Jiaxin Song, Yixu Wang, Jie Li, Rui Yu, Yan Teng, Xingjun Ma, Yingchun Wang|<http://arxiv.org/pdf/2505.19610v2>|æå‡ºJailBoundæ¡†æ¶ï¼Œé€šè¿‡æ¢æµ‹å’Œè·¨è¶Šè§†è§‰è¯­è¨€æ¨¡å‹å†…éƒ¨å®‰å…¨è¾¹ç•Œï¼Œæœ‰æ•ˆæå‡å…¶å¯¹æŠ—æ”»å‡»æˆåŠŸç‡ã€‚|


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|TC-GS: A Faster Gaussian Splatting Module Utilizing Tensor Cores|TC-GSï¼šåˆ©ç”¨å¼ é‡æ ¸å¿ƒçš„æ›´å¿«é«˜æ–¯åˆ†å±‚æ¨¡å—|Zimu Liao, Jifeng Ding, Rong Fu, Siwei Cui, Ruixuan Gong, Li Wang, Boni Hu, Yi Wang .etc.|<http://arxiv.org/pdf/2505.24796v1>|[ä»£ç ](https://github.com/TensorCore3DGS/3DGSTensorCore); æå‡ºTC-GSæ¨¡å—ï¼Œåˆ©ç”¨å¼ é‡æ ¸å¿ƒåŠ é€Ÿ3Dé«˜æ–¯åˆ†å±‚æ¸²æŸ“ï¼Œå®ç°2.18å€é€Ÿåº¦æå‡ã€‚|
|ğŸ†• å‘å¸ƒ|Beyond FACS: Data-driven Facial Expression Dictionaries, with Application to Predicting Autism|è¶…è¶ŠFACSï¼šæ•°æ®é©±åŠ¨çš„é¢éƒ¨è¡¨æƒ…è¯å…¸åŠå…¶åœ¨é¢„æµ‹è‡ªé—­ç—‡ä¸­çš„åº”ç”¨|Evangelos Sariyanidi, Lisa Yankowitz, Robert T. Schultz, John D. Herrington, Birkan Tunc, Jeffrey Cohn|<http://arxiv.org/pdf/2505.24679v1>|[ä»£ç ](https://github.com/sariyanidi/FacialBasis.); æå‡ºäº†ä¸€ç§æ•°æ®é©±åŠ¨çš„é¢éƒ¨è¡¨æƒ…å­—å…¸ï¼Œç”¨äºæ›´å…¨é¢åœ°é¢„æµ‹è‡ªé—­ç—‡è¯Šæ–­ã€‚|
|ğŸ“ æ›´æ–°|FieldWorkArena: Agentic AI Benchmark for Real Field Work Tasks|FieldWorkArenaï¼šçœŸå®é‡å¤–å·¥ä½œä»»åŠ¡çš„ä»£ç†äººå·¥æ™ºèƒ½åŸºå‡†|Atsunori Moteki, Shoichi Masui, Fan Yang, Yueqi Song, Yonatan Bisk, Graham Neubig, Ikuo Kusajima, Yasuto Watanabe .etc.|<http://arxiv.org/pdf/2505.19662v2>|FieldWorkArenaæå‡ºé¦–ä¸ªé’ˆå¯¹çœŸå®ä¸–ç•Œç°åœºå·¥ä½œä»»åŠ¡çš„Agentic AIåŸºå‡†ï¼Œè¯„ä¼°å…¶åœ¨å¤šæ¨¡...|

