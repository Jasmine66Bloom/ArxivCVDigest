## [UPDATED!] **2025-05-31** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Robust Adaptation of Foundation Models with Black-Box Visual Prompting|基于黑盒视觉提示的鲁棒基础模型自适应|Changdae Oh, Gyeongdeok Seo, Geunyoung Jung, Zhi-Qi Cheng, Hosik Choi, Jiyoung Jung, Kyungwoo Song|<http://arxiv.org/pdf/2407.17491v2>|提出黑盒视觉提示方法，实现参数高效的大规模预训练模型适应。|
|📝 更新|More Thinking, Less Seeing? Assessing Amplified Hallucination in Multimodal Reasoning Models|更多思考，更少观察？评估多模态推理模型中的增强幻觉|Chengzhi Liu, Zhongxing Xu, Qingyue Wei, Juncheng Wu, James Zou, Xin Eric Wang, Yuyin Zhou, Sheng Liu|<http://arxiv.org/pdf/2505.21523v2>|提出RH-AUC和RH-Bench评估模型在多模态推理中的幻觉问题，揭示模型推理与感知平衡的重要性。|
|📝 更新|ChatReID: Open-ended Interactive Person Retrieval via Hierarchical Progressive Tuning for Vision Language Models|ChatReID：基于分层渐进调优的视觉语言模型的开端交互式人物检索|Ke Niu, Haiyang Yu, Mengyang Zhao, Teng Fu, Siyang Yi, Wei Lu, Bin Li, Xuelin Qian .etc.|<http://arxiv.org/pdf/2502.19958v3>|ChatReID通过文本主导的检索范式和分层渐进调优策略，显著提升了跨视图人物重识别的准确性。|
|📝 更新|Harnessing PDF Data for Improving Japanese Large Multimodal Models|利用PDF数据提升日语大型多模态模型|Jeonghun Baek, Akiko Aizawa, Kiyoharu Aizawa|<http://arxiv.org/pdf/2502.14778v2>|利用日本PDF数据，构建自动化流程提取图像文本对，提升日本多模态模型性能。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Autoregressive Models in Vision: A Survey|视觉中的自回归模型：综述|Jing Xiong, Gongye Liu, Lun Huang, Chengyue Wu, Taiqiang Wu, Yao Mu, Yuan Yao, Hui Shen .etc.|<http://arxiv.org/pdf/2411.05902v2>|[代码](https://github.com/ChaofanTao/Autoregressive-Models-in-Vision-Survey.); 综述了计算机视觉中自回归模型的应用，分类并探讨了其在图像、视频、3D和多模态生成等领域的应用与挑战。|
|📝 更新|AVadCLIP: Audio-Visual Collaboration for Robust Video Anomaly Detection|AVadCLIP：用于鲁棒视频异常检测的视听协作|Peng Wu, Wanshun Su, Guansong Pang, Yujia Sun, Qingsen Yan, Peng Wang, Yanning Zhang|<http://arxiv.org/pdf/2504.04495v2>|提出一种结合音频视觉信息的弱监督视频异常检测框架，显著提升检测准确率。|
|📝 更新|Graph-Driven Multimodal Feature Learning Framework for Apparent Personality Assessment|图驱动多模态特征学习框架用于外观性格评估|Kangsheng Wang, Chengwei Ye, Huanzhen Zhang, Linuo Xu, Shuyan Liu|<http://arxiv.org/pdf/2504.11515v2>|提出了一种融合多模态特征学习的视频人脸分析框架，有效预测视频片段中的人物性格特征。|
|📝 更新|GAME: Learning Multimodal Interactions via Graph Structures for Personality Trait Estimation|游戏：通过图结构学习多模态交互以进行人格特质估计|Kangsheng Wang, Yuhang Li, Chengwei Ye, Yufei Lin, Huanzhen Zhang, Bohan Hu, Linuo Xu, Shuyan Liu|<http://arxiv.org/pdf/2505.03846v2>|提出了一种基于图结构和多模态融合的自动性格预测方法，显著提升了预测准确度。|
|📝 更新|Beyond Face Swapping: A Diffusion-Based Digital Human Benchmark for Multimodal Deepfake Detection|超越面部交换：一种基于扩散的多模态深度伪造检测的数字人基准|Jiaxin Liu, Jia Wang, Saihui Hou, Min Ren, Huijia Wu, Zhaofeng He|<http://arxiv.org/pdf/2505.16512v3>|提出DigiShield，有效检测多模态深伪视频，应对扩散模型带来的挑战。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Insight Over Sight: Exploring the Vision-Knowledge Conflicts in Multimodal LLMs|洞察胜于视觉：探索多模态LLMs中的视觉-知识冲突|Xiaoyuan Liu, Wenxuan Wang, Youliang Yuan, Jen-tse Huang, Qiuzhi Liu, Pinjia He, Zhaopeng Tu|<http://arxiv.org/pdf/2410.08145v2>|提出框架评估多模态LLMs中视觉知识与常识知识冲突，并提出“Focus-on-Vision”策略缓解...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FastCAR: Fast Classification And Regression Multi-Task Learning via Task Consolidation for Modelling a Continuous Property Variable of Object Classes|快速分类与回归多任务学习：通过任务融合建模对象类别的连续属性变量——FastCAR|Anoop Kini, Andreas Jansche, Timo Bernthaler, Gerhard Schneider|<http://arxiv.org/pdf/2403.17926v2>|[代码](https://github.com/fastcandr/Advanced-Steel-Property-Dataset); FastCAR通过任务整合实现快速分类和回归，有效提升多任务学习效率。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|M$^3$-VOS: Multi-Phase, Multi-Transition, and Multi-Scenery Video Object Segmentation|M$^3$-VOS：多阶段、多转换和多场景视频目标分割|Zixuan Chen, Jiaxin Li, Liming Tan, Yejie Guo, Junxuan Liang, Cewu Lu, Yong-Lu Li|<http://arxiv.org/pdf/2412.13803v3>|[代码](https://zixuan-chen.github.io/M-cube-VOS.github.io); 提出M$^3$-VOS新基准，针对物体相变问题改进视频目标分割方法。|
|📝 更新|PADetBench: Towards Benchmarking Physical Attacks against Object Detection|PADetBench：面向目标检测的物理攻击基准测试|Jiawei Lian, Jianhong Pan, Lefan Wang, Yi Wang, Lap-Pui Chau, Shaohui Mei|<http://arxiv.org/pdf/2408.09181v3>|[代码](https://github.com/JiaweiLian/Benchmarking_Physical_Attack); 开发PADetBench基准，通过模拟严格评估物理攻击对目标检测的影响。|
|📝 更新|FMNet: Frequency-Assisted Mamba-Like Linear Attention Network for Camouflaged Object Detection|FMNet：用于伪装目标检测的频率辅助Mamba-like线性注意力网络|Ming Deng, Sijin Sun, Zihao Li, Xiaochuan Hu, Xing Wu|<http://arxiv.org/pdf/2503.11030v2>|[代码](https://github.com/Chranos/FMNet.); 提出FMNet，通过频率辅助和线性注意力机制，有效提升伪装目标检测性能和效率。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SpargeAttention: Accurate and Training-free Sparse Attention Accelerating Any Model Inference|稀疏注意力：准确且无需训练的稀疏注意力加速任何模型推理|Jintao Zhang, Chendong Xiang, Haofeng Huang, Jia Wei, Haocheng Xi, Jun Zhu, Jianfei Chen|<http://arxiv.org/pdf/2502.18137v3>|[代码](https://github.com/thu-ml/SpargeAttn.); 提出了一种通用的稀疏注意力机制，显著加速各类模型推理，无需额外训练。|
|📝 更新|SageAttention2: Efficient Attention with Thorough Outlier Smoothing and Per-thread INT4 Quantization|智慧注意力2：高效注意力机制与彻底的异常值平滑及线程级INT4量化|Jintao Zhang, Haofeng Huang, Pengle Zhang, Jia Wei, Jun Zhu, Jianfei Chen|<http://arxiv.org/pdf/2411.10958v5>|[代码](https://github.com/thu-ml/SageAttention.); 提出SageAttention2，通过INT4量化、异常值平滑和双级累积策略，显著提升注意力计算效率...|
|📝 更新|ChartGalaxy: A Dataset for Infographic Chart Understanding and Generation|图表银河：信息图表理解和生成数据集|Zhen Li, Duan Li, Yukai Guo, Xinyuan Guo, Bowen Li, Lanxi Xiao, Shenyu Qiao, Jiashu Chen .etc.|<http://arxiv.org/pdf/2505.18668v2>|构建ChartGalaxy数据集，提升大型视觉语言模型对信息图表的理解和生成能力。|
|📝 更新|StarVector: Generating Scalable Vector Graphics Code from Images and Text|星向量：从图像和文本生成可缩放矢量图形代码|Juan A. Rodriguez, Abhay Puri, Shubham Agarwal, Issam H. Laradji, Pau Rodriguez, Sai Rajeswar, David Vazquez, Christopher Pal .etc.|<http://arxiv.org/pdf/2312.11556v4>|StarVector通过理解图像语义，直接在SVG代码空间生成更紧凑、语义丰富的SVG图形。|
|📝 更新|Co-Reinforcement Learning for Unified Multimodal Understanding and Generation|协同强化学习实现统一的多模态理解和生成|Jingjing Jiang, Chongjie Si, Jun Luo, Hanwang Zhang, Chao Ma|<http://arxiv.org/pdf/2505.17534v2>|[代码](https://github.com/mm-vl/ULM-R1.); 提出CoRL框架，通过联合优化提升ULMs的多模态理解和生成能力。|
|📝 更新|Alignment is All You Need: A Training-free Augmentation Strategy for Pose-guided Video Generation|《对齐即一切：一种用于姿态引导视频生成的无训练增强策略》|Xiaoyu Jin, Zunnan Xu, Mingwen Ou, Wenming Yang|<http://arxiv.org/pdf/2408.16506v2>|提出了一种无需训练的动画生成方法，通过双对齐策略确保动画保持静态图像的细节。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HarmoniCa: Harmonizing Training and Inference for Better Feature Caching in Diffusion Transformer Acceleration|HarmoniCa：在扩散Transformer加速中实现更好的特征缓存，实现训练与推理的和谐统一|Yushi Huang, Zining Wang, Ruihao Gong, Jing Liu, Xinjie Zhang, Jinyang Guo, Xianglong Liu, Jun Zhang|<http://arxiv.org/pdf/2410.01723v6>|[代码](https://github.com/ModelTC/HarmoniCa.); HarmoniCa通过优化特征缓存，解决了扩散Transformer在推理中高成本的问题，显著提升了...|
|📝 更新|Normalized Attention Guidance: Universal Negative Guidance for Diffusion Model|归一化注意力引导：扩散模型的通用负引导|Dar-Yen Chen, Hmrishav Bandyopadhyay, Kai Zou, Yi-Zhe Song|<http://arxiv.org/pdf/2505.21179v2>|提出了一种名为NAG的通用负向引导机制，有效解决扩散模型中负向引导的挑战。|
|📝 更新|TSD-SR: One-Step Diffusion with Target Score Distillation for Real-World Image Super-Resolution|TSD-SR：基于目标分数蒸馏的实时图像超分辨率一步扩散方法|Linwei Dong, Qingnan Fan, Yihong Guo, Zhonghao Wang, Qi Zhang, Jinwei Chen, Yawei Luo, Changqing Zou|<http://arxiv.org/pdf/2411.18263v4>|提出TSD-SR，通过目标分数蒸馏和分布感知采样，实现高效且有效的单步图像超分辨率。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|QuickVideo: Real-Time Long Video Understanding with System Algorithm Co-Design|快速视频：系统算法协同设计下的实时长视频理解|Benjamin Schneider, Dongfu Jiang, Chao Du, Tianyu Pang, Wenhu Chen|<http://arxiv.org/pdf/2505.16175v2>|QuickVideo通过系统算法协同设计，大幅加速长视频理解，实现实时应用。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Dyn-HaMR: Recovering 4D Interacting Hand Motion from a Dynamic Camera|动态HaMR：从动态相机中恢复4D交互手部运动|Zhengdi Yu, Stefanos Zafeiriou, Tolga Birdal|<http://arxiv.org/pdf/2412.12861v3>|[代码](https://dyn-hamr.github.io/.); 提出了一种从动态摄像头单目视频中恢复4D手部运动的方法，显著提升了手部运动重建的准确性。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|WaterSplatting: Fast Underwater 3D Scene Reconstruction Using Gaussian Splatting|水溅法：利用高斯溅射快速水下三维场景重建|Huapeng Li, Wenxuan Song, Tianao Xu, Alexandre Elsig, Jonas Kulhanek|<http://arxiv.org/pdf/2408.08206v2>|提出融合3D高斯分层与体渲染技术，实现快速水下三维场景重建。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|An Interpretable Representation Learning Approach for Diffusion Tensor Imaging|一种用于扩散张量成像的可解释表示学习方法|Vishwa Mohan Singh, Alberto Gaston Villagran Asiares, Luisa Sophie Schuhmacher, Kate Rendall, Simon Weißbrod, David Rügamer, Inga Körte|<http://arxiv.org/pdf/2505.19110v2>|提出了一种将DTI轨迹图编码为2D图像并学习可解释嵌入的方法，有效提升了下游任务性能。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Efficiency Bottlenecks of Convolutional Kolmogorov-Arnold Networks: A Comprehensive Scrutiny with ImageNet, AlexNet, LeNet and Tabular Classification|卷积柯尔莫哥洛夫-阿诺德网络效率瓶颈：基于ImageNet、AlexNet、LeNet和表格分类的全面审视|Ashim Dahal, Saydul Akbar Murad, Nick Rahimi|<http://arxiv.org/pdf/2501.15757v3>|[代码](https://github.com/ashimdahal/Study-of-Convolutional-Kolmogorov-Arnold-networks); 该论文分析了卷积Kolmogorov-Arnold网络在效率上的瓶颈，并通过实验与CNN模型对比，揭...|
|📝 更新|PHT-CAD: Efficient CAD Parametric Primitive Analysis with Progressive Hierarchical Tuning|PHT-CAD：基于渐进式分层调优的高效CAD参数化原语分析|Ke Niu, Yuwen Chen, Haiyang Yu, Zhuofan Chen, Xianghui Que, Bin Li, Xiangyang Xue|<http://arxiv.org/pdf/2503.18147v3>|PHT-CAD通过渐进式分层调整，高效分析CAD参数化原语，提升二维工程图纸理解能力。|
|📝 更新|Efficient Open Set Single Image Test Time Adaptation of Vision Language Models|高效开放集单图像视觉语言模型测试时自适应|Manogna Sreenivas, Soma Biswas|<http://arxiv.org/pdf/2406.00481v2>|[代码](https://manogna-s.github.io/rosita); 提出ROSITA，一种基于视觉语言模型的开集单图像测试时自适应框架，有效应对数据分布变化和未知类别识...|
|📝 更新|Towards Modality Generalization: A Benchmark and Prospective Analysis|迈向模态泛化：一个基准和前瞻性分析|Xiaohao Liu, Xiaobo Xia, Zhuo Huang, See-Kiong Ng, Tat-Seng Chua|<http://arxiv.org/pdf/2412.18277v2>|提出模态泛化方法，使模型能泛化到未见过的模态。|
|📝 更新|Point Cloud Mixture-of-Domain-Experts Model for 3D Self-supervised Learning|点云域专家混合模型用于3D自监督学习|Yaohua Zha, Tao Dai, Hang Guo, Yanzi Wang, Bin Chen, Ke Chen, Shu-Tao Xia|<http://arxiv.org/pdf/2410.09886v2>|提出了一种融合场景和对象领域专家的3D自监督学习模型，通过跨域知识互补提升3D表示学习。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RF4D:Neural Radar Fields for Novel View Synthesis in Outdoor Dynamic Scenes|RF4D：用于户外动态场景新颖视图合成的神经雷达场|Jiarui Zhang, Zhihao Li, Chong Wang, Bihan Wen|<http://arxiv.org/pdf/2505.20967v2>|提出RF4D，一种结合雷达和时空建模的神经场框架，显著提升动态户外场景的新视角合成质量。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CTRL-GS: Cascaded Temporal Residue Learning for 4D Gaussian Splatting|CTRL-GS：级联时间残差学习用于四维高斯分层|Karly Hou, Wanhua Li, Hanspeter Pfister|<http://arxiv.org/pdf/2505.18306v2>|提出了一种基于残差学习的4D高斯分层模型，有效提升了动态场景的实时渲染质量。|
|📝 更新|View-Invariant Policy Learning via Zero-Shot Novel View Synthesis|基于零样本新视角合成的视角不变策略学习|Stephen Tian, Blake Wulfe, Kyle Sargent, Katherine Liu, Sergey Zakharov, Vitor Guizilini, Jiajun Wu|<http://arxiv.org/pdf/2409.03685v3>|[代码](https://s-tian.github.io/projects); 通过零样本新视角合成，学习观测视角不变的操作策略。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Don't Let Your Robot be Harmful: Responsible Robotic Manipulation via Safety-as-Policy|不让你的机器人造成伤害：通过安全策略实现负责任的机器人操作|Minheng Ni, Lei Zhang, Zihan Chen, Kaixin Bai, Zhaopeng Chen, Jianwei Zhang, Lei Zhang, Wangmeng Zuo|<http://arxiv.org/pdf/2411.18289v2>|提出“安全策略”解决机器人操作中的安全风险，通过虚拟交互和认知推理提高任务完成效率和安全性。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|One RL to See Them All: Visual Triple Unified Reinforcement Learning|一视同仁：视觉三元统一强化学习|Yan Ma, Linge Du, Xuyang Shen, Shaoxiang Chen, Pengfei Li, Qibing Ren, Lizhuang Ma, Yuchao Dai .etc.|<http://arxiv.org/pdf/2505.18129v2>|提出V-Triune系统，通过统一强化学习实现视觉推理和感知任务的学习，显著提升视觉语言模型性能。|
|📝 更新|CLEAR: Character Unlearning in Textual and Visual Modalities|清晰：文本和视觉模态中的字符去学习|Alexey Dontsov, Dmitrii Korzh, Alexey Zhavoronkin, Boris Mikheev, Denis Bobkov, Aibek Alanov, Oleg Y. Rogov, Ivan Oseledets .etc.|<http://arxiv.org/pdf/2410.18057v4>|提出CLEAR开源基准，推动跨模态数据去除研究。|
|📝 更新|InfoChartQA: A Benchmark for Multimodal Question Answering on Infographic Charts|信息图表问答基准：信息图表上的多模态问答基准|Minzhi Lin, Tianchi Xie, Mengchen Liu, Yilin Ye, Changjian Chen, Shixia Liu|<http://arxiv.org/pdf/2505.19028v2>|[代码](https://github.com/CoolDawnAnt/InfoChartQA.); 构建了InfoChartQA基准，评估多模态大语言模型在理解信息图表方面的能力。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Open High-Resolution Satellite Imagery: The WorldStrat Dataset -- With Application to Super-Resolution|开放高分辨率卫星影像：WorldStrat数据集——及其在超分辨率中的应用|Julien Cornebise, Ivan Oršolić, Freddie Kalaitzis|<http://arxiv.org/pdf/2207.06418v2>|[代码](https://github.com/worldstrat/worldstrat); 构建了世界最大的开放高分辨率卫星图像数据集，并应用于超分辨率任务。|
|📝 更新|Subpixel Edge Localization Based on Converted Intensity Summation under Stable Edge Region|基于稳定边缘区域转换强度求和的亚像素边缘定位|Yingyuan Yang, Guoyuan Liang, Xianwen Wang, Kaiming Wang, Can Wang, Xinyu Wu|<http://arxiv.org/pdf/2502.16502v2>|提出了一种基于局部积分映射的子像素边缘定位方法，结合稳定边缘区域算法，显著提升了边缘检测精度和鲁棒性...|
|📝 更新|Exploring Compositional Generalization of Multimodal LLMs for Medical Imaging|探索多模态LLMs在医学影像中的组合泛化|Zhenyang Cai, Junying Chen, Rongsheng Wang, Weihong Wang, Yonglin Deng, Dingjie Song, Yize Chen, Zixu Zhang .etc.|<http://arxiv.org/pdf/2412.20070v2>|[代码](https://github.com/FreedomIntelligence/Med-MAT.); 该论文通过探索组合泛化，揭示了多模态LLMs在医学图像分析中的泛化能力，并证实了其在数据有限和跨任务...|
|📝 更新|IrrMap: A Large-Scale Comprehensive Dataset for Irrigation Method Mapping|IrrMap：用于灌溉方法映射的大规模综合数据集|Nibir Chandra Mandal, Oishee Bintey Hoque, Abhijin Adiga, Samarth Swarup, Mandy Wilson, Lu Feng, Yangfeng Ji, Miaomiao Zhang .etc.|<http://arxiv.org/pdf/2505.08273v2>|[代码](https://github.com/Nibir088/IrrMap); 构建了大规模灌溉方法映射数据集IrrMap，助力精准灌溉分析。|
|📝 更新|Understanding differences in applying DETR to natural and medical images|理解将DETR应用于自然图像和医学图像的差异|Yanqi Xu, Yiqiu Shen, Carlos Fernandez-Granda, Laura Heacock, Krzysztof J. Geras|<http://arxiv.org/pdf/2405.17677v2>|针对医学图像检测，论文提出简化模型结构，优化了自然图像检测模型在医学图像上的应用。|
|📝 更新|Leveraging Complementary Attention maps in vision transformers for OCT image analysis|利用互补注意力图在OCT图像分析中的视觉Transformer|Haz Sameen Shahgir, Tanjeem Azwad Zaman, Khondker Salman Sayeed, Md. Asif Haider, Sheikh Saifur Rahman Jony, M. Sohel Rahman|<http://arxiv.org/pdf/2310.14005v3>|提出了一种结合MaxViT和EVA-02的混合模型，有效提升了OCT图像生物标志物检测的准确率。|
|📝 更新|SurgRIPE challenge: Benchmark of Surgical Robot Instrument Pose Estimation|手术机器人工具姿态估计基准：SurgRIPE挑战|Haozheng Xu, Alistair Weld, Chi Xu, Alfie Roddan, Joao Cartucho, Mert Asim Karaoglu, Alexander Ladikos, Yangke Li .etc.|<http://arxiv.org/pdf/2501.02990v2>|SurgRIPE挑战赛提出无标记方法，为手术机器人工具姿态估计建立新基准。|
|📝 更新|YOLO advances to its genesis: a decadal and comprehensive review of the You Only Look Once (YOLO) series|YOLO系列溯源：对“你只需看一次”（YOLO）系列十年全面回顾|Ranjan Sapkota, Marco Flores Calero, Rizwan Qureshi, Chetan Badgujar, Upesh Nepal, Alwin Poulose, Peter Zeno, Uday Bhanu Prakash Vaddevolu .etc.|<http://arxiv.org/pdf/2406.19407v7>|全面回顾YOLO系列算法发展，揭示其提升实时目标检测速度、准确性和效率的路径。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Advancing Image Super-resolution Techniques in Remote Sensing: A Comprehensive Survey|遥感图像超分辨率技术进展：全面综述|Yunliang Qi, Meng Lou, Yimin Liu, Lu Li, Zhen Yang, Wen Nie|<http://arxiv.org/pdf/2505.23248v2>|系统综述了遥感图像超分辨率技术，揭示了现有方法的局限性，并提出了未来研究方向。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CRAVES: Controlling Robotic Arm with a Vision-based Economic System|CRAVES：基于视觉经济系统的机器人臂控制|Yiming Zuo, Weichao Qiu, Lingxi Xie, Fangwei Zhong, Yizhou Wang, Alan L. Yuille|<http://arxiv.org/pdf/1812.00725v3>|[代码](https://github.com/zuoym15/craves.ai); 提出了一种基于3D模型和半监督学习的机器人视觉控制方法，有效降低标注成本并提升3D姿态估计精度。|
|📝 更新|Don't Miss the Forest for the Trees: Attentional Vision Calibration for Large Vision Language Models|不要只见树木不见森林：大型视觉语言模型中的注意力视觉校准|Sangmin Woo, Donguk Kim, Jaehyuk Jang, Yubin Choi, Changick Kim|<http://arxiv.org/pdf/2405.17820v2>|提出AvisC方法，通过动态调整注意力权重减少大型视觉语言模型中的幻觉现象。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Organizing Unstructured Image Collections using Natural Language|利用自然语言组织非结构化图像集合|Mingxuan Liu, Zhun Zhong, Jun Li, Gianni Franchi, Subhankar Roy, Elisa Ricci|<http://arxiv.org/pdf/2410.05217v4>|提出了一种自动从无结构图像集中发现语义聚类标准的方法，无需人工输入。|

