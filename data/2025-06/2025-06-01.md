## [UPDATED!] **2025-06-01** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Self-Supervised Multi-View Representation Learning using Vision-Language Model for 3D/4D Facial Expression Recognition|自监督多视角表示学习：用于3D/4D面部表情识别的视觉-语言模型|Muzammil Behzad|<http://arxiv.org/pdf/2506.01203v1>|提出SMILE-VLM，通过多视角视觉表示学习和自然语言监督，实现3D/4D面部表情识别的突破性进展...|
|📝 更新|LLaVA-ST: A Multimodal Large Language Model for Fine-Grained Spatial-Temporal Understanding|LLaVA-ST：一种用于细粒度时空理解的跨模态大型语言模型|Hongyu Li, Jinyu Chen, Ziyu Wei, Shaofei Huang, Tianrui Hui, Jialin Gao, Xiaoming Wei, Si Liu|<http://arxiv.org/pdf/2501.08282v2>|[代码](https://github.com/appletea233/LLaVA-ST); LLaVA-ST提出了一种多模态大语言模型，有效处理视频中的细粒度时空理解。|
|🆕 发布|AuralSAM2: Enabling SAM2 Hear Through Pyramid Audio-Visual Feature Prompting|AuralSAM2：通过金字塔音频-视觉特征提示实现SAM2的听觉感知|Yuyuan Liu, Yuanhong Chen, Chong Wang, Junlin Han, Junde Wu, Can Peng, Jingkun Chen, Yu Tian .etc.|<http://arxiv.org/pdf/2506.01015v1>|[代码](https://github.com/yyliu01/AuralSAM2.); 提出AuralSAM2，通过音频-视觉特征金字塔融合，显著提升SAM2在视频中的音频引导分割能力。|
|📝 更新|MFCLIP: Multi-modal Fine-grained CLIP for Generalizable Diffusion Face Forgery Detection|多模态细粒度CLIP：通用扩散人脸伪造检测|Yaning Zhang, Tianyi Wang, Zitong Yu, Zan Gao, Linlin Shen, Shengyong Chen|<http://arxiv.org/pdf/2409.09724v3>|提出MFCLIP模型，通过多模态细粒度特征学习，实现通用扩散人脸伪造检测。|
|🆕 发布|Speaking Beyond Language: A Large-Scale Multimodal Dataset for Learning Nonverbal Cues from Video-Grounded Dialogues|超越语言：一个大规模多模态数据集，用于从基于视频的对话中学习非语言线索|Youngmin Kim, Jiwan Chung, Jisoo Kim, Sunghyun Lee, Sangkyu Lee, Junhyeok Kim, Cheoljong Yang, Youngjae Yu|<http://arxiv.org/pdf/2506.00958v1>|构建大规模多模态数据集，提升对话AI的非语言理解与生成能力。|
|🆕 发布|Leveraging CLIP Encoder for Multimodal Emotion Recognition|利用CLIP编码器进行多模态情感识别|Yehun Song, Sunyoung Cho|<http://arxiv.org/pdf/2506.00903v1>|利用CLIP编码器，通过标签编码引导的多模态情感识别框架，有效提升了多模态情感识别性能。|
|📝 更新|Enhancing Multimodal Unified Representations for Cross Modal Generalization|提升跨模态泛化中的多模态统一表示|Hai Huang, Yan Xia, Shengpeng Ji, Shulei Wang, Hanting Wang, Minghui Fang, Jieming Zhu, Zhenhua Dong .etc.|<http://arxiv.org/pdf/2403.05168v3>|[代码](https://github.com/haihuangcode/CMG.); 提出TOC和FCID方法，优化跨模态统一表示，提升跨模态泛化性能。|
|🆕 发布|TIME: TabPFN-Integrated Multimodal Engine for Robust Tabular-Image Learning|时间：基于TabPFN的鲁棒表格-图像学习多模态引擎|Jiaqi Luo, Yuan Yuan, Shixin Xu|<http://arxiv.org/pdf/2506.00813v1>|提出TIME，一种结合TabPFN和预训练视觉模型的多模态学习框架，有效解决表格数据缺失值问题。|
|🆕 发布|GeoChain: Multimodal Chain-of-Thought for Geographic Reasoning|地理推理的多模态思维链：GeoChain|Sahiti Yerramilli, Nilay Pande, Rynaa Grover, Jayant Sravan Tamarapalli|<http://arxiv.org/pdf/2506.00785v1>|GeoChain构建大规模地理推理基准，助力多模态大语言模型提升地理推理能力。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OG-VLA: 3D-Aware Vision Language Action Model via Orthographic Image Generation|OG-VLA：通过正射图像生成实现3D感知视觉语言动作模型|Ishika Singh, Ankit Goyal, Stan Birchfield, Dieter Fox, Animesh Garg, Valts Blukis|<http://arxiv.org/pdf/2506.01196v1>|OG-VLA通过结合视觉语言动作模型和3D感知策略，实现了对未见场景的泛化能力，显著提升了机器人操作...|
|📝 更新|Distill CLIP (DCLIP): Enhancing Image-Text Retrieval via Cross-Modal Transformer Distillation|DCLIP（Distill CLIP）：通过跨模态Transformer蒸馏增强图像-文本检索|Daniel Csizmadia, Andrei Codreanu, Victor Sim, Vighnesh Prabhu, Michael Lu, Kevin Zhu, Sean O'Brien, Vasu Sharma|<http://arxiv.org/pdf/2505.21549v3>|DCLIP通过跨模态Transformer蒸馏，提升了图像-文本检索效果，同时保持零样本分类能力。|
|🆕 发布|ECP-Mamba: An Efficient Multi-scale Self-supervised Contrastive Learning Method with State Space Model for PolSAR Image Classification|ECP-Mamba：一种用于PolSAR图像分类的基于状态空间模型的效率多尺度自监督对比学习方法|Zuzheng Kuang, Haixia Bi, Chen Xu, Jian Sun|<http://arxiv.org/pdf/2506.01040v1>|[代码](https://github.com/HaixiaBi1982/ECP_Mamba.); ECP-Mamba通过多尺度自监督对比学习和状态空间模型，有效解决了PolSAR图像分类中标注数据稀...|
|📝 更新|DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers|DA-VPT：视觉Transformer的语义引导视觉提示微调|Li Ren, Chen Chen, Liqiang Wang, Kien Hua|<http://arxiv.org/pdf/2505.23694v2>|提出DA-VPT框架，通过语义信息引导视觉提示学习，提升ViT模型微调效率。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ProstaTD: A Large-scale Multi-source Dataset for Structured Surgical Triplet Detection|ProstaTD：用于结构化手术三元组检测的大规模多源数据集|Yiliang Chen, Zhixi Li, Cheng Xu, Alex Qinyang Liu, Xuemiao Xu, Jeremy Yuen-Chun Teoh, Shengfeng He, Jing Qin|<http://arxiv.org/pdf/2506.01130v1>|构建了大规模多源手术三重检测数据集ProstaTD，解决现有数据集标注不足和泛化能力有限的问题。|
|🆕 发布|Revolutionizing Radiology Workflow with Factual and Efficient CXR Report Generation|利用事实与高效进行胸部X光报告生成的放射学工作流程革命|Pimchanok Sukjai, Apiradee Boonmee|<http://arxiv.org/pdf/2506.01118v1>|开发了一种结合临床反馈和知识图谱增强的LLM模型，显著提升了CXR报告生成的准确性和效率。|
|📝 更新|Exploring Model Kinship for Merging Large Language Models|探索大型语言模型融合的模型亲缘关系|Yedi Hu, Yunzhi Yao, Shumin Deng, Huajun Chen, Ningyu Zhang|<http://arxiv.org/pdf/2410.12613v2>|[代码](https://github.com/zjunlp/ModelKinship.); 引入模型亲缘度概念，提出基于亲缘度的模型合并策略，提升大型语言模型合并性能。|
|📝 更新|Uni-MuMER: Unified Multi-Task Fine-Tuning of Vision-Language Model for Handwritten Mathematical Expression Recognition|统一多任务视觉-语言模型在手写数学表达式识别中的微调|Yu Li, Jin Jiang, Jianhua Zhu, Shuai Peng, Baole Wei, Yuxuan Zhou, Liangcai Gao|<http://arxiv.org/pdf/2505.23566v2>|[代码](https://github.com/BFlameSwift/Uni-MuMER); 提出Uni-MuMER，通过微调预训练视觉语言模型实现手写数学表达式识别，显著提升识别准确率。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ItTakesTwo: Leveraging Peer Representations for Semi-supervised LiDAR Semantic Segmentation|ItTakesTwo：利用同伴表示进行半监督激光雷达语义分割|Yuyuan Liu, Yuanhong Chen, Hu Wang, Vasileios Belagiannis, Ian Reid, Gustavo Carneiro|<http://arxiv.org/pdf/2407.07171v3>|[代码](https://github.com/yyliu01/IT2.); 提出ItTakesTwo框架，通过利用同伴LiDAR表示和更广泛的对比学习样本，显著提升半监督LiD...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Edge-Based Idle State Detection in Construction Machinery Using Surveillance Cameras|基于监控摄像头的建筑机械边缘空闲状态检测方法|Xander Küpers, Jeroen Klein Brinke, Rob Bemthuis, Ozlem Durmaz Incel|<http://arxiv.org/pdf/2506.00904v1>|提出Edge-IMI框架，利用边缘计算设备实时检测施工机械闲置状态，提高设备利用率。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MDMP: Multi-modal Diffusion for supervised Motion Predictions with uncertainty|多模态扩散用于具有不确定性的监督运动预测|Leo Bringer, Joey Wilson, Kira Barton, Maani Ghaffari|<http://arxiv.org/pdf/2410.03860v2>|提出MDMP模型，融合骨骼数据和文本描述，实现长期运动预测并量化不确定性。|
|🆕 发布|Generic Token Compression in Multimodal Large Language Models from an Explainability Perspective|通用令牌压缩在多模态大型语言模型中的可解释性视角|Lei Lei, Jie Gu, Xiaokang Ma, Chu Tang, Jingmin Chen, Tong Xu|<http://arxiv.org/pdf/2506.01097v1>|提出一种基于可解释性的方法，在LLMs输入阶段进行视觉token压缩，有效降低计算成本并保持性能。|
|🆕 发布|Modality Translation and Registration of MR and Ultrasound Images Using Diffusion Models|基于扩散模型的MR和超声图像模态转换与配准|Xudong Ma, Nantheera Anantrasirichai, Stefanos Bolomytis, Alin Achim|<http://arxiv.org/pdf/2506.01025v1>|提出一种基于扩散模型的ACMT网络，有效解决MR和超声图像模态转换与配准难题。|
|📝 更新|Conditional Image Synthesis with Diffusion Models: A Survey|条件图像合成与扩散模型：综述|Zheyuan Zhan, Defang Chen, Jian-Ping Mei, Zhenghe Zhao, Jiawei Chen, Chun Chen, Siwei Lyu, Can Wang|<http://arxiv.org/pdf/2409.19365v3>|[代码](https://github.com/zju-pi/Awesome-Conditional-Diffusion-Models.); 对基于扩散模型的条件图像合成进行综述，分类现有工作并总结主流条件机制，为未来研究提供方向。|
|🆕 发布|Temporal In-Context Fine-Tuning for Versatile Control of Video Diffusion Models|时间上下文微调以实现视频扩散模型的灵活控制|Kinam Kim, Junha Hyung, Jaegul Choo|<http://arxiv.org/pdf/2506.00996v1>|[代码](https://kinam0252.github.io/TIC-FT); 提出了一种无需架构修改的TIC-FT方法，有效提升了视频扩散模型的可控生成能力。|
|📝 更新|Marine Saliency Segmenter: Object-Focused Conditional Diffusion with Region-Level Semantic Knowledge Distillation|海洋显著性分割器：基于区域级语义知识蒸馏的对象聚焦条件扩散|Laibin Chang, Yunke Wang, JiaXing Huang, Longxiang Deng, Bo Du, Chang Xu|<http://arxiv.org/pdf/2504.02391v2>|提出DiffMSS，一种结合扩散模型和语义知识蒸馏的海洋显著性分割器，有效解决水下环境中的物体定位和...|
|📝 更新|ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On|基于图像的虚拟试穿图像-时间步自适应掩码扩散Transformer框架：ITA-MDT|Ji Woo Hong, Tri Ton, Trung X. Pham, Gwanhyeong Koo, Sunjae Yoon, Chang D. Yoo|<http://arxiv.org/pdf/2503.20418v2>|提出一种轻量级Transformer框架，通过自适应特征聚合和显著区域提取，实现高效且逼真的服装虚拟...|
|🆕 发布|QuantFace: Low-Bit Post-Training Quantization for One-Step Diffusion Face Restoration|QuantFace：一步扩散人脸修复的低比特后训练量化|Jiatong Li, Libo Zhu, Haotong Qin, Jingkai Wang, Linghe Kong, Guihai Chen, Yulun Zhang, Xiaokang Yang|<http://arxiv.org/pdf/2506.00820v1>|[代码](https://github.com/jiatongli2024/QuantFace.); 提出QuantFace，通过低比特量化技术显著提升了一步扩散人脸修复模型的效率。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EWGN: Elastic Weight Generation and Context Switching in Deep Learning|弹性权重生成与深度学习中的上下文切换：EWGN|Shriraj P. Sawant, Krishna P. Miyapuram|<http://arxiv.org/pdf/2506.02065v1>|提出EWGN，通过动态权重生成和上下文切换，有效缓解了深度学习中的灾难性遗忘问题。|
|🆕 发布|DeepVerse: 4D Autoregressive Video Generation as a World Model|深度宇宙：作为世界模型的4D自回归视频生成|Junyi Chen, Haoyi Zhu, Xianglong He, Yifan Wang, Jianjun Zhou, Wenzheng Chang, Yang Zhou, Zizun Li .etc.|<http://arxiv.org/pdf/2506.01103v1>|DeepVerse通过结合几何预测，显著提升了4D视频生成模型的预测准确性和时空一致性。|
|📝 更新|Deep Learning Framework for Infrastructure Maintenance: Crack Detection and High-Resolution Imaging of Infrastructure Surfaces|基础设施维护的深度学习框架：裂缝检测和基础设施表面的高分辨率成像|Nikhil M. Pawar, Jorge A. Prozzi, Feng Hong, Surya Sarat Chandra Congress|<http://arxiv.org/pdf/2505.03974v2>|开发了一种CNN与ESPCNN结合的框架，有效提升了基础设施表面裂缝检测的准确性和效率。|
|🆕 发布|GOBench: Benchmarking Geometric Optics Generation and Understanding of MLLMs|GOBench：多模态语言模型几何光学生成与理解基准测试|Xiaorong Zhu, Ziheng Jia, Jiarui Wang, Xiangyu Zhao, Haodong Duan, Xiongkuo Min, Jia Wang, Zicheng Zhang .etc.|<http://arxiv.org/pdf/2506.00991v1>|构建GOBench基准，评估MLLMs在光学图像生成和理解方面的能力。|
|📝 更新|NFIG: Autoregressive Image Generation with Next-Frequency Prediction|NFIG：基于下一频率预测的自回归图像生成|Zhihao Huang, Xi Qiu, Yukuo Ma, Yifu Zhou, Junjie Chen, Hongyuan Zhang, Chi Zhang, Xuelong Li|<http://arxiv.org/pdf/2503.07076v3>|NFIG通过分解图像生成过程为多个频率引导阶段，有效捕捉长距离依赖关系，提高图像生成质量和效率。|
|🆕 发布|Camera Trajectory Generation: A Comprehensive Survey of Methods, Metrics, and Future Directions|相机轨迹生成：方法、指标和未来方向的全面综述|Zahra Dehghanian, Pouya Ardekhani, Amir Vahedi, Hamid Beigy, Hamid R. Rabiee|<http://arxiv.org/pdf/2506.00974v1>|首次全面综述了相机轨迹生成领域，涵盖了从基础定义到高级方法，并分析了评估指标。|
|🆕 发布|Deformable registration and generative modelling of aortic anatomies by auto-decoders and neural ODEs|可变形配准和通过自动解码器与神经常微分方程生成主动脉解剖结构|Riccardo Tenderini, Luca Pegolotti, Fanwei Kong, Stefano Pagani, Francesco Regazzoni, Alison L. Marsden, Simone Deparis|<http://arxiv.org/pdf/2506.00947v1>|提出AD-SVFD模型，通过神经ODE和自动解码器实现血管形状的变形配准和合成解剖结构生成。|
|🆕 发布|TIGeR: Text-Instructed Generation and Refinement for Template-Free Hand-Object Interaction|TIGeR：基于文本指令的无模板手-物体交互生成与细化|Yiyao Huang, Zhedong Zheng, Yu Ziwei, Yaxiong Wang, Tze Ho Elden Tse, Angela Yao|<http://arxiv.org/pdf/2506.00953v1>|提出TIGeR框架，通过文本指令生成和细化，实现无模板手-物体交互的3D重建。|
|🆕 发布|ProtInvTree: Deliberate Protein Inverse Folding with Reward-guided Tree Search|蛋白质逆向折叠的奖励引导树搜索：ProtInvTree|Mengdi Liu, Xiaoxue Cheng, Zhangyang Gao, Hong Chang, Cheng Tan, Shiguang Shan, Xilin Chen|<http://arxiv.org/pdf/2506.00925v1>|提出了一种基于树搜索的蛋白质逆向折叠方法，有效生成多样且结构一致的蛋白质序列。|
|🆕 发布|DS-VTON: High-Quality Virtual Try-on via Disentangled Dual-Scale Generation|DS-VTON：通过解耦双尺度生成实现高质量虚拟试穿|Xianbing Sun, Yan Hong, Jiahui Zhan, Jun Lan, Huijia Zhu, Weiqiang Wang, Liqing Zhang, Jianfu Zhang|<http://arxiv.org/pdf/2506.00908v1>|DS-VTON通过双尺度生成和去耦，实现了服装虚拟试穿的高质量效果。|
|🆕 发布|Breaking Latent Prior Bias in Detectors for Generalizable AIGC Image Detection|打破检测器中可泛化AIGC图像检测的潜在先验偏差|Yue Zhou, Xinan He, KaiQing Lin, Bin Fan, Feng Ding, Bin Li|<http://arxiv.org/pdf/2506.00874v1>|提出OMAT方法，通过对抗训练消除检测器中的潜在先验偏差，提升AIGC图像检测的泛化能力。|
|🆕 发布|SkyReels-Audio: Omni Audio-Conditioned Talking Portraits in Video Diffusion Transformers|天空卷轴-音频：全音频条件化视频扩散变换器中的对话肖像|Zhengcong Fei, Hao Jiang, Di Qiu, Baoxuan Gu, Youqiang Zhang, Jiahua Wang, Jialin Bai, Debang Li .etc.|<http://arxiv.org/pdf/2506.00830v1>|提出SkyReels-Audio，通过多模态输入实现高质量、同步的语音引导视频人像生成与编辑。|
|📝 更新|Domain-Agnostic Stroke Lesion Segmentation Using Physics-Constrained Synthetic Data|基于物理约束合成数据的域无关脑卒中病灶分割|Liam Chalcroft, Jenny Crinion, Cathy J. Price, John Ashburner|<http://arxiv.org/pdf/2412.03318v3>|[代码](https://github.com/liamchalcroft/qsynth); 提出了一种基于物理约束的合成数据生成方法，显著提升了脑卒中病变分割的鲁棒性和泛化能力。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FlowMo: Variance-Based Flow Guidance for Coherent Motion in Video Generation|FlowMo：基于方差的视频生成中的一致运动引导|Ariel Shaulov, Itay Hazan, Lior Wolf, Hila Chefer|<http://arxiv.org/pdf/2506.01144v1>|FlowMo通过分析模型预测的连续帧之间的差异，增强了视频生成中的运动连贯性。|
|🆕 发布|GThinker: Towards General Multimodal Reasoning via Cue-Guided Rethinking|GThinker：通过线索引导的重新思考实现通用多模态推理|Yufei Zhan, Ziheng Wu, Yousong Zhu, Rongkun Xue, Ruipu Luo, Zhenghao Chen, Can Zhang, Yifan Li .etc.|<http://arxiv.org/pdf/2506.01078v1>|[代码](https://github.com/jefferyZhan/GThinker.); GThinker通过引入视觉线索引导的反思模式，提升了多模态推理能力。|
|🆕 发布|Motion-Aware Concept Alignment for Consistent Video Editing|运动感知概念对齐以实现一致的视频编辑|Tong Zhang, Juan C Leon Alcazar, Bernard Ghanem|<http://arxiv.org/pdf/2506.01004v1>|MoCA-Video通过在视频对象中注入图像语义特征，实现无需训练的视频编辑，保持运动和视觉一致性。|
|📝 更新|DragPoser: Motion Reconstruction from Variable Sparse Tracking Signals via Latent Space Optimization|DragPoser：通过潜在空间优化从可变稀疏跟踪信号中重建运动|Jose Luis Ponton, Eduard Pujol, Andreas Aristidou, Carlos Andujar, Nuria Pelechano|<http://arxiv.org/pdf/2406.14567v3>|DragPoser通过在潜在空间中优化姿态，实现了从稀疏跟踪信号中实时重建高精度运动。|
|📝 更新|FreeInsert: Disentangled Text-Guided Object Insertion in 3D Gaussian Scene without Spatial Priors|FreeInsert：无空间先验的3D高斯场景中解耦的文本引导对象插入|Chenxi Li, Weijie Wang, Qiang Li, Bruno Lepri, Nicu Sebe, Weizhi Nie|<http://arxiv.org/pdf/2505.01322v2>|FreeInsert提出了一种无需空间先验的3D场景文本引导对象插入方法，通过解耦对象生成与空间放置...|
|📝 更新|Flash3D: Feed-Forward Generalisable 3D Scene Reconstruction from a Single Image|Flash3D：基于单张图像的前馈通用3D场景重建|Stanislaw Szymanowicz, Eldar Insafutdinov, Chuanxia Zheng, Dylan Campbell, João F. Henriques, Christian Rupprecht, Andrea Vedaldi|<http://arxiv.org/pdf/2406.04343v2>|Flash3D通过单张图像实现高效且通用的三维场景重建与合成。|
|🆕 发布|SynPO: Synergizing Descriptiveness and Preference Optimization for Video Detailed Captioning|协同描述性和偏好优化用于视频详细字幕的SynPO|Jisheng Dang, Yizhou Zhang, Hao Ye, Teng Wang, Siming Chen, Huicheng Zheng, Yulan Guo, Jianhuang Lai .etc.|<http://arxiv.org/pdf/2506.00835v1>|[代码](https://github.com/longmalongma/SynPO); 提出SynPO方法，通过协同描述性和偏好优化，显著提升视频详细描述的准确性和训练效率。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Inference-Time Text-to-Video Alignment with Diffusion Latent Beam Search|基于扩散潜在束搜索的推理时文本到视频对齐|Yuta Oshima, Masahiro Suzuki, Yutaka Matsuo, Hiroki Furuta|<http://arxiv.org/pdf/2501.19252v2>|提出了一种基于扩散模型和前瞻估计的文本到视频对齐方法，显著提升了视频生成质量。|
|🆕 发布|PromptVFX: Text-Driven Fields for Open-World 3D Gaussian Animation|PromptVFX：开放世界3D高斯动画的文本驱动场|Mert Kiray, Paul Uhlenbruck, Nassir Navab, Benjamin Busam|<http://arxiv.org/pdf/2506.01091v1>|提出了一种基于文本驱动的3D动画方法，简化了视觉效果制作过程。|
|📝 更新|ObjectAdd: Adding Objects into Image via a Training-Free Diffusion Modification Fashion|ObjectAdd：通过无训练扩散修改方式将对象添加到图像中|Ziyue Zhang, Quanjian Song, Yuxin Zhang, Rongrong Ji|<http://arxiv.org/pdf/2404.17230v4>|ObjectAdd通过无监督扩散修改技术，实现用户指定区域添加物体，保持图像一致性。|
|🆕 发布|Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution|自监督控制网络结合时空Mamba进行真实世界视频超分辨率|Shijun Shi, Jing Xu, Lijing Lu, Zhihang Li, Kai Hu|<http://arxiv.org/pdf/2506.01037v1>|提出了一种结合自监督学习和时空Mamba的鲁棒视频超分辨率框架，显著提升了真实世界视频的感知质量。|
|📝 更新|SemanticDraw: Towards Real-Time Interactive Content Creation from Image Diffusion Models|语义绘制：从图像扩散模型向实时交互式内容创建迈进|Jaerin Lee, Daniel Sungho Jung, Kanggeon Lee, Kyoung Mu Lee|<http://arxiv.org/pdf/2403.09055v4>|提出SemanticDraw，通过区域控制和加速技术，实现实时交互式图像内容创作。|
|🆕 发布|FlexSelect: Flexible Token Selection for Efficient Long Video Understanding|FlexSelect：高效长视频理解中的灵活标记选择|Yunzhu Zhang, Yu Lu, Tianyi Wang, Fengyun Rao, Yi Yang, Linchao Zhu|<http://arxiv.org/pdf/2506.00993v1>|[代码](https://yunzhuzhang0918.github.io/flex_select); FlexSelect通过灵活的token选择策略，有效提升了长视频理解的效率和速度。|
|🆕 发布|IVY-FAKE: A Unified Explainable Framework and Benchmark for Image and Video AIGC Detection|IVY-FAKE：图像和视频AIGC检测的统一可解释框架和基准|Wayne Zhang, Changjiang Jiang, Zhonghao Zhang, Chenyang Si, Fengchang Yu, Wei Peng|<http://arxiv.org/pdf/2506.00979v1>|提出IVY-FAKE，统一检测图像和视频AI生成内容，并提高模型可解释性。|
|🆕 发布|Multiverse Through Deepfakes: The MultiFakeVerse Dataset of Person-Centric Visual and Conceptual Manipulations|通过深度伪造的多宇宙：以人为中心的视觉和概念操纵的多伪造宇宙数据集|Parul Gupta, Shreya Ghosh, Tom Gedeon, Thanh-Toan Do, Abhinav Dhall|<http://arxiv.org/pdf/2506.00868v1>|[代码](https://github.com/Parul-Gupta/MultiFakeVerse); 构建了大规模、语义驱动的MultiFakeVerse数据集，用于评估针对人物和场景的深度伪造检测。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VLM-3R: Vision-Language Models Augmented with Instruction-Aligned 3D Reconstruction|VLM-3R：基于指令对齐的3D重建增强视觉-语言模型|Zhiwen Fan, Jian Zhang, Renjie Li, Junge Zhang, Runjin Chen, Hezhen Hu, Kevin Wang, Huaizhi Qu .etc.|<http://arxiv.org/pdf/2505.20279v2>|VLM-3R通过融合3D重建指令，实现了视觉语言模型对3D场景的深度理解和时空推理。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SVarM: Linear Support Varifold Machines for Classification and Regression on Geometric Data|SVarM：用于几何数据分类和回归的线性支持变分流形机|Emmanuel Hartman, Nicolas Charon|<http://arxiv.org/pdf/2506.01189v1>|提出SVarM，一种基于变分表示的几何数据分析框架，有效解决形状数据的分类和回归问题。|
|📝 更新|Accurate Differential Operators for Hybrid Neural Fields|精确的混合神经网络场微分算子|Aditya Chetan, Guandao Yang, Zichen Wang, Steve Marschner, Bharath Hariharan|<http://arxiv.org/pdf/2312.05984v2>|提出改进方法，使混合神经网络场准确计算空间导数，减少渲染和模拟中的伪影。|
|🆕 发布|CountingFruit: Real-Time 3D Fruit Counting with Language-Guided Semantic Gaussian Splatting|计数水果：基于语言引导的语义高斯散布的实时3D水果计数|Fengze Li, Yangle Liu, Jieming Ma, Hai-Ning Liang, Yaochun Shen, Huangxiang Li, Zhijing Wu|<http://arxiv.org/pdf/2506.01109v1>|提出了一种实时3D水果计数框架，通过语言引导的语义高斯分层实现快速、准确的计数。|
|📝 更新|OpenGait: A Comprehensive Benchmark Study for Gait Recognition towards Better Practicality|OpenGait：面向更好实用性的步态识别全面基准研究|Chao Fan, Saihui Hou, Junhao Liang, Chuanfu Shen, Jingzhe Ma, Dongyang Jin, Yongzhen Huang, Shiqi Yu|<http://arxiv.org/pdf/2405.09138v2>|[代码](https://github.com/ShiqiYu/OpenGait.); 提出OpenGait基准平台，通过改进模型和揭示关键洞察，提升实际应用中的步态识别效果。|
|📝 更新|NEXT: Multi-Grained Mixture of Experts via Text-Modulation for Multi-Modal Object Re-ID|下一代：通过文本调制实现多模态目标重识别的多粒度专家混合|Shihao Li, Chenglong Li, Aihua Zheng, Andong Lu, Jin Tang, Jixin Ma|<http://arxiv.org/pdf/2505.20001v3>|提出一种基于文本调控的多模态对象重识别框架，有效提升识别准确率。|


## 时序视觉分析 (Temporal Visual Analysis)


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Uneven Event Modeling for Partially Relevant Video Retrieval|不均匀事件建模用于部分相关视频检索|Sa Zhu, Huashan Chen, Wanqian Zhang, Jinchao Zhang, Zexian Yang, Xiaoshuai Hao, Bo Li|<http://arxiv.org/pdf/2506.00891v2>|[代码](https://github.com/Sasa77777779/UEM.git.); 提出了一种基于动态事件建模的视频检索方法，有效提升了文本与视频片段的匹配精度。|
|🆕 发布|Towards Predicting Any Human Trajectory In Context|面向预测任何情境下的人类轨迹|Ryo Fujii, Hideo Saito, Ryo Hachiuma|<http://arxiv.org/pdf/2506.00871v1>|[代码](https://fujiry0.github.io/TrajICL-project-page.); 提出了一种无需微调的行人轨迹预测框架，通过场景内学习快速适应不同环境。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Review on Coarse to Fine-Grained Animal Action Recognition|从粗粒度到细粒度的动物动作识别综述|Ali Zia, Renuka Sharma, Abdelwahed Khamis, Xuesong Li, Muhammad Husnain, Numan Shafi, Saeed Anwar, Sabine Schmoelzl .etc.|<http://arxiv.org/pdf/2506.01214v1>|综述了动物动作识别技术，提出从粗粒度到细粒度的识别方法，以应对户外环境中动物动作识别的挑战。|
|🆕 发布|Keystep Recognition using Graph Neural Networks|基于图神经网络的按键识别|Julia Lee Romero, Kyle Min, Subarna Tripathi, Morteza Karimzadeh|<http://arxiv.org/pdf/2506.01102v1>|提出了一种基于图神经网络的灵活框架，有效识别自拍摄像头视频中的细微步态变化。|
|🆕 发布|3D Skeleton-Based Action Recognition: A Review|基于3D骨骼的动作识别：综述|Mengyuan Liu, Hong Liu, Qianshuo Hu, Bin Ren, Junsong Yuan, Jiaying Lin, Jiajun Wen|<http://arxiv.org/pdf/2506.00915v1>|构建了全面的任务导向框架，深入解析3D骨骼动作识别的子任务和最新进展。|
|🆕 发布|Improving Keystep Recognition in Ego-Video via Dexterous Focus|通过灵巧聚焦提升自我视频中的关键步识别|Zachary Chavis, Stephen J. Guy, Hyun Soo Park|<http://arxiv.org/pdf/2506.00827v1>|通过限制输入视频为稳定的手部聚焦视频，该论文提出的方法独立于网络架构，显著提升了自拍摄像头视频中的关...|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MOOSE: Pay Attention to Temporal Dynamics for Video Understanding via Optical Flows|MOOSE：通过光流关注时序动态的视频理解|Hong Nguyen, Dung Tran, Hieu Hoang, Phong Nguyen, Shrikanth Narayanan|<http://arxiv.org/pdf/2506.01119v1>|提出MOOSE，通过结合光流和空间嵌入，高效建模视频中的时间动态，提升理解能力。|
|🆕 发布|Deep Temporal Reasoning in Video Language Models: A Cross-Linguistic Evaluation of Action Duration and Completion through Perfect Times|深度视频语言模型中的时间推理：通过完美时间对动作持续时间和完成度的跨语言评估|Olga Loginova, Sofía Ortega Loguinova|<http://arxiv.org/pdf/2506.00928v1>|构建了“完美时间”数据集，评估视频语言模型在时间推理上的能力，揭示其难以理解视频中的动作持续和完成。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Depth-Aware Scoring and Hierarchical Alignment for Multiple Object Tracking|深度感知评分与分层对齐的多目标跟踪|Milad Khanchi, Maria Amer, Charalambos Poullis|<http://arxiv.org/pdf/2506.00774v1>|[代码](https://github.com/Milad-Khanchi/DepthMOT); 提出深度感知评分和分层对齐方法，提升多目标跟踪精度。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Perceptual Inductive Bias Is What You Need Before Contrastive Learning|感知归纳偏差是对比学习之前你需要的东西|Tianqin Li, Junru Zhao, Dunhan Jiang, Shenghao Wu, Alan Ramirez, Tai Sing Lee|<http://arxiv.org/pdf/2506.01201v1>|该论文通过借鉴人类视觉的多阶段处理理论，在对比学习前引入感知先验，显著提升了模型收敛速度和最终表现。|
|📝 更新|Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation|微观思考，宏观行动：面向终身机器人操作的原始提示学习|Yuanqi Yao, Siao Liu, Haoming Song, Delin Qu, Qizhi Chen, Yan Ding, Bin Zhao, Zhigang Wang .etc.|<http://arxiv.org/pdf/2504.00420v2>|提出了一种通过学习可复用原语实现终身机器人操作的方法，有效解决技能迁移和遗忘问题。|
|🆕 发布|Aligned Contrastive Loss for Long-Tailed Recognition|对长尾识别的校准对比损失|Jiali Ma, Jiequan Cui, Maeno Kazuki, Lakshmi Subramanian, Karlekar Jayashree, Sugiri Pranata, Hanwang Zhang|<http://arxiv.org/pdf/2506.01071v1>|提出ACL算法解决长尾识别问题，显著提升模型性能。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Real-time Chest X-Ray Distributed Decision Support for Resource-constrained Clinics|实时资源受限诊所胸部X光分布式决策支持|Omar H. Khater, Basem Almadani, Farouq Aliyu|<http://arxiv.org/pdf/2412.07818v2>|开发实时远程胸部X光诊断系统，助力资源匮乏地区医院提高诊断效率。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Alzheimers Disease Classification in Functional MRI With 4D Joint Temporal-Spatial Kernels in Novel 4D CNN Model|基于新颖4D CNN模型的4D联合时空核在功能MRI中用于阿尔茨海默病分类|Javier Salazar Cavazos, Scott Peltier|<http://arxiv.org/pdf/2506.02060v1>|开发了一种新型4D卷积神经网络，通过提取4D时空核，提高了阿尔茨海默病在fMRI数据中的诊断准确性和...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LensCraft: Your Professional Virtual Cinematographer|镜头工艺：您的专业虚拟摄影师|Zahra Dehghanian, Morteza Abolghasemi, Hossein Azizinaghsh, Amir Vahedi, Hamid Beigy, Hamid R. Rabiee|<http://arxiv.org/pdf/2506.00988v1>|LensCraft通过模拟专业摄影师的技巧，结合数据驱动和实时架构，实现了高精度、低复杂度的智能摄像...|
|📝 更新|SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge Refinement|SynWorld：用于代理行动知识精炼的虚拟场景合成|Runnan Fang, Xiaobin Wang, Yuan Liang, Shuofei Qiao, Jialong Wu, Zekun Xi, Ningyu Zhang, Yong Jiang .etc.|<http://arxiv.org/pdf/2504.03561v3>|[代码](https://github.com/zjunlp/SynWorld.); SynWorld通过合成虚拟场景和MCTS探索，帮助智能体在未知环境中优化行动知识。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Why Does Little Robustness Help? A Further Step Towards Understanding Adversarial Transferability|为什么微小的鲁棒性有助于？迈向理解对抗迁移性的进一步一步|Yechao Zhang, Shengshan Hu, Leo Yu Zhang, Junyu Shi, Minghui Li, Xiaogeng Liu, Wei Wan, Hai Jin|<http://arxiv.org/pdf/2307.07873v7>|揭示了模型平滑度和梯度相似性之间的权衡对对抗样本迁移性的影响，并提出了一种优化两者以提升迁移性的方法...|
|🆕 发布|CAPAA: Classifier-Agnostic Projector-Based Adversarial Attack|CAPAA：基于分类器无关投影器的对抗攻击|Zhan Li, Mingyu Zhao, Xin Dong, Haibin Ling, Bingyao Huang|<http://arxiv.org/pdf/2506.00978v1>|[代码](https://github.com/ZhanLiQxQ/CAPAA.); 提出CAPAA，解决多分类器和不同相机姿态下的对抗攻击问题，提高攻击成功率与隐蔽性。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Neural Path Guiding with Distribution Factorization|神经路径引导与分布分解|Pedro Figueiredo, Qihao He, Nima Khademi Kalantari|<http://arxiv.org/pdf/2506.00839v1>|提出了一种基于分布分解的神经网络路径引导方法，有效提升了渲染中的蒙特卡洛积分速度和精度。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning What Matters: Prioritized Concept Learning via Relative Error-driven Sample Selection|学习关键内容：通过相对误差驱动的样本选择进行优先级概念学习|Shivam Chandhok, Qian Yang, Oscar Manas, Kanishk Jain, Leonid Sigal, Aishwarya Agrawal|<http://arxiv.org/pdf/2506.01085v1>|提出PROGRESS方法，通过相对误差驱动的样本选择，实现视觉语言模型高效且数据计算效率高的指令微调...|
|🆕 发布|A Large Convolutional Neural Network for Clinical Target and Multi-organ Segmentation in Gynecologic Brachytherapy with Multi-stage Learning|大型卷积神经网络在妇科近距离放射治疗中的临床靶区和多器官分割及多阶段学习|Mingzhe Hu, Yuan Gao, Yuheng Li, Ricahrd LJ Qiu, Chih-Wei Chang, Keyur D. Shah, Priyanka Kapoor, Beth Bradshaw .etc.|<http://arxiv.org/pdf/2506.01073v1>|提出GynBTNet，通过多阶段学习策略显著提升妇科近距离放疗中临床靶区和多器官分割的准确性。|
|🆕 发布|Quotient Network -- A Network Similar to ResNet but Learning Quotients|商数网络——一个类似于ResNet但学习商数的网络|Peng Hui, Jiamuyang Zhao, Changxin Li, Qingzhen Zhu|<http://arxiv.org/pdf/2506.00992v1>|提出一种学习特征商的Quotient网络，有效解决ResNet学习目标问题，性能优于ResNet。|
|📝 更新|IMPROVE: Iterative Model Pipeline Refinement and Optimization Leveraging LLM Experts|IMPROVE：利用LLM专家的迭代模型管道精炼和优化|Eric Xue, Ke Chen, Zeyi Huang, Yuyang Ji, Yong Jae Lee, Haohan Wang|<http://arxiv.org/pdf/2502.18530v2>|提出迭代优化策略，通过逐步改进模型组件，显著提升LLM驱动的机器学习流程性能。|
|🆕 发布|L3A: Label-Augmented Analytic Adaptation for Multi-Label Class Incremental Learning|L3A：多标签类别增量学习中的标签增强分析自适应|Xiang Zhang, Run He, Jiao Chen, Di Fang, Ming Li, Ziqian Zeng, Cen Chen, Huiping Zhuang|<http://arxiv.org/pdf/2506.00816v1>|[代码](https://github.com/scut-zx/L3A.); 提出L3A方法，通过伪标签和加权分析分类器解决多标签增量学习中的标签缺失和类别不平衡问题。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|NavBench: Probing Multimodal Large Language Models for Embodied Navigation|NavBench：探究多模态大型语言模型在具身导航中的应用|Yanyuan Qiao, Haodong Hong, Wenqi Lyu, Dong An, Siqi Zhang, Yutong Xie, Xinyu Wang, Qi Wu|<http://arxiv.org/pdf/2506.01031v1>|构建NavBench基准，评估MLLM在零样本条件下的导航能力，并提出将模型输出转换为机器人动作的流...|
|🆕 发布|Continual-MEGA: A Large-scale Benchmark for Generalizable Continual Anomaly Detection|持续-MEGA：一个可泛化持续异常检测的大规模基准|Geonu Lee, Yujeong Oh, Geonhui Jang, Soyoung Lee, Jeonghyo Song, Sungmin Cha, YoungJoon Yoo|<http://arxiv.org/pdf/2506.00956v1>|[代码](https://github.com/Continual-Mega/Continual-Mega.); 构建了大规模基准Continual-MEGA，推动可泛化持续异常检测方法发展。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Fighting Fire with Fire (F3): A Training-free and Efficient Visual Adversarial Example Purification Method in LVLMs|以火攻火（F3）：LVLMs中一种无需训练且高效的视觉对抗样本净化方法|Yudong Zhang, Ruobing Xie, Yiqing Huang, Jiansheng Chen, Xingwu Sun, Zhanhui Kang, Di Wang, Yu Wang|<http://arxiv.org/pdf/2506.01064v1>|提出一种利用噪声净化对抗样本的F3方法，有效提升视觉语言模型鲁棒性。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Understanding Model Reprogramming for CLIP via Decoupling Visual Prompts|通过解耦视觉提示理解CLIP的模型重编程|Chengyi Cai, Zesheng Ye, Lei Feng, Jianzhong Qi, Feng Liu|<http://arxiv.org/pdf/2506.01000v1>|[代码](https://github.com/tmlr-group/DecoupledVP.); 提出了一种通过解耦和重新加权框架改进CLIP视觉提示的方法，有效提升了下游任务的分类性能。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Chain-of-Talkers (CoTalk): Fast Human Annotation of Dense Image Captions|链式说话者（CoTalk）：密集图像标题的快速人工标注|Yijun Shen, Delong Chen, Fan Liu, Xingyu Wang, Chuanyi Zhang, Liang Yao, Yuhui Zheng|<http://arxiv.org/pdf/2505.22627v2>|提出CoTalk方法，通过序列标注和语音交互，提高密集图像标注效率和准确性。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AceVFI: A Comprehensive Survey of Advances in Video Frame Interpolation|AceVFI：视频帧插值技术进展综述|Dahyeon Kye, Changhyun Roh, Sukhun Ko, Chanho Eom, Jihyong Oh|<http://arxiv.org/pdf/2506.01061v1>|AceVFI全面综述了视频帧插值技术，涵盖了多种方法并分析了关键挑战。|
|📝 更新|Towards Resource-Efficient Streaming of Large-Scale Medical Image Datasets for Deep Learning|面向深度学习的资源高效大规模医学图像数据集流式传输|Pranav Kulkarni, Adway Kanhere, Eliot Siegel, Paul H. Yi, Vishwa S. Parekh|<http://arxiv.org/pdf/2307.00438v3>|提出MIST工具，实现大规模医学图像数据集的高效格式无关流式传输。|
|📝 更新|Translation Consistent Semi-supervised Segmentation for 3D Medical Images|3D医学图像的一致性半监督分割|Yuyuan Liu, Yu Tian, Chong Wang, Yuanhong Chen, Fengbei Liu, Vasileios Belagiannis, Gustavo Carneiro|<http://arxiv.org/pdf/2203.14523v3>|[代码](https://github.com/yyliu01/TraCoCo.); 提出了一种通过改变空间输入上下文进行数据扰动，并使用新的损失函数和3D数据增强的半监督3D医学图像分...|
|🆕 发布|Pseudo-Labeling Driven Refinement of Benchmark Object Detection Datasets via Analysis of Learning Patterns|伪标签驱动的基准目标检测数据集细化：通过学习模式分析|Min Je Kim, Muhammad Munsif, Altaf Hussain, Hikmat Yar, Sung Wook Baik|<http://arxiv.org/pdf/2506.00997v1>|提出一种伪标签驱动的数据集精炼方法，显著提升MS-COCO标注质量和检测模型性能。|
|📝 更新|SCC-YOLO: An Improved Object Detector for Assisting in Brain Tumor Diagnosis|SCC-YOLO：辅助脑肿瘤诊断的改进目标检测器|Runci Bai, Guibao Xu, Yanze Shi|<http://arxiv.org/pdf/2501.03836v4>|提出SCC-YOLO架构，通过整合SCConv模块优化YOLOv9，显著提升脑肿瘤检测准确率。|
|🆕 发布|Aiding Medical Diagnosis through Image Synthesis and Classification|通过图像合成与分类辅助医学诊断|Kanishk Choudhary|<http://arxiv.org/pdf/2506.00786v1>|开发了一种基于文本描述生成医学图像并自我验证准确性的系统，助力医学诊断与教育。|
|🆕 发布|HSCR: Hierarchical Self-Contrastive Rewarding for Aligning Medical Vision Language Models|HSCR：用于对齐医学视觉语言模型的层次自对比奖励|Songtao Jiang, Yan Zhang, Yeying Jin, Zhihang Tang, Yangyang Wu, Yang Feng, Jian Wu, Zuozhu Liu|<http://arxiv.org/pdf/2506.00805v1>|HSCR通过生成高质量偏好数据和多层次优化策略，有效解决医学视觉语言模型模态对齐问题。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CogAD: Cognitive-Hierarchy Guided End-to-End Autonomous Driving|认知层次引导的端到端自动驾驶|Zhennan Wang, Jianing Teng, Canqun Xiang, Kangliang Chen, Xing Pan, Lu Deng, Weihao Gu|<http://arxiv.org/pdf/2505.21581v2>|提出CogAD模型，模拟人类驾驶员的认知机制，实现端到端自动驾驶。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Advancing from Automated to Autonomous Beamline by Leveraging Computer Vision|从自动化到自主束线的计算机视觉赋能进步|Baolu Li, Hongkai Yu, Huiming Sun, Jin Ma, Yuewei Lin, Lu Ma, Yonghua Du|<http://arxiv.org/pdf/2506.00836v1>|提出一种基于计算机视觉的实时碰撞检测系统，助力自主同步辐射光束线操作。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Transport Network, Graph, and Air Pollution|交通网络、图和空气污染|Nan Xu|<http://arxiv.org/pdf/2506.01164v1>|通过分析全球城市交通网络图像，提出了一种基于图特征的城市污染研究方法，为城市规划提供减污策略。|
|📝 更新|DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations|DiTASK：基于微分同胚变换的多任务微调|Krishna Sri Ipsit Mantri, Carola-Bibiane Schönlieb, Bruno Ribeiro, Chaim Baskin, Moshe Eliasof|<http://arxiv.org/pdf/2502.06029v3>|[代码](https://github.com/ipsitmantri/DiTASK); DiTASK通过保持预训练特征结构，实现高效的多任务学习，显著降低参数量。|
|📝 更新|How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on Continual Pre-Training|LLMs如何获取新知识？从知识电路视角看持续预训练|Yixin Ou, Yunzhi Yao, Ningyu Zhang, Hui Jin, Jiacheng Sun, Shumin Deng, Zhenguo Li, Huajun Chen|<http://arxiv.org/pdf/2502.11196v2>|[代码](https://github.com/zjunlp/DynamicKnowledgeCircuits.); 通过知识电路演化视角，揭示了LLMs获取新知识的机制，并提出了改进持续预训练策略的方法。|
|📝 更新|ADS-Edit: A Multimodal Knowledge Editing Dataset for Autonomous Driving Systems|ADS-Edit：自动驾驶系统多模态知识编辑数据集|Chenxi Wang, Jizhan Fang, Xiang Chen, Bozhong Tian, Ziwen Xu, Huajun Chen, Ningyu Zhang|<http://arxiv.org/pdf/2503.20756v2>|[代码](https://github.com/zjunlp/EasyEdit.); 提出ADS-Edit，通过知识编辑解决自动驾驶系统中的交通知识理解难题。|
|🆕 发布|Revolutionizing Blood Banks: AI-Driven Fingerprint-Blood Group Correlation for Enhanced Safety|革新血库：人工智能驱动的指纹-血型相关性提升安全性|Malik A. Altayar, Muhyeeddin Alqaraleh, Mowafaq Salem Alzboon, Wesam T. Almagharbeh|<http://arxiv.org/pdf/2506.01069v1>|该研究通过分析指纹与血型关联，探索了血型数据在生物识别中的应用潜力，为提升个人识别方法提供新思路。|

