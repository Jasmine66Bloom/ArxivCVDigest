## [UPDATED!] **2025-06-03** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HumanRAM: Feed-forward Human Reconstruction and Animation Model using Transformers|人脑RAM：基于Transformer的前馈人类重建与动画模型|Zhiyuan Yu, Zhe Li, Hujun Bao, Can Yang, Xiaowei Zhou|<http://arxiv.org/pdf/2506.03118v1>|[代码](https://zju3dv.github.io/humanram); 提出HumanRAM，一种基于Transformer的通用3D人体重建与动画模型，显著提升重建精度和...|
|🆕 发布|Revisiting Continuity of Image Tokens for Cross-domain Few-shot Learning|重新审视图像标记的连续性以实现跨域小样本学习|Shuai Yi, Yixiong Zou, Yuhua Li, Ruixuan Li|<http://arxiv.org/pdf/2506.03110v1>|[代码](https://github.com/shuaiyi308/ReCIT.); 提出了一种通过破坏图像标记连续性来提升跨域小样本学习性能的方法。|
|🆕 发布|HaploOmni: Unified Single Transformer for Multimodal Video Understanding and Generation|HaploOmni：统一单Transformer用于多模态视频理解和生成|Yicheng Xiao, Lin Song, Rui Yang, Cheng Cheng, Zunnan Xu, Zhaoyang Zhang, Yixiao Ge, Xiu Li .etc.|<http://arxiv.org/pdf/2506.02975v1>|[代码](https://github.com/Tencent/HaploVLM.); 提出HaploOmni，一种高效的多模态视频理解和生成统一单Transformer模型，解决跨模态兼...|
|📝 更新|Towards Computation- and Communication-efficient Computational Pathology|迈向计算和通信高效的计算病理学|Chu Han, Bingchao Zhao, Jiatai Lin, Shanshan Lyu, Longfei Wang, Tianpeng Deng, Cheng Lu, Changhong Liang .etc.|<http://arxiv.org/pdf/2504.02628v2>|提出MAG-GLTrans框架，通过低倍镜输入实现高效病理图像分析，大幅提升诊断效率和传输效率。|
|📝 更新|T-TAME: Trainable Attention Mechanism for Explaining Convolutional Networks and Vision Transformers|T-TAME：用于解释卷积网络和视觉Transformer的可训练注意力机制|Mariano V. Ntrougkas, Nikolaos Gkalelis, Vasileios Mezaris|<http://arxiv.org/pdf/2403.04523v2>|提出T-TAME，一种适用于解释卷积网络和视觉Transformer的可训练注意力机制，显著提升了解...|
|📝 更新|OmniTalker: One-shot Real-time Text-Driven Talking Audio-Video Generation With Multimodal Style Mimicking|全息对话者：一次实时文本驱动多模态风格模仿的音频-视频生成|Zhongjian Wang, Peng Zhang, Jinwei Qi, Guangyuan Wang, Chaonan Ji, Sheng Xu, Bang Zhang, Liefeng Bo|<http://arxiv.org/pdf/2504.02433v2>|OmniTalker提出了一种实时从文本生成同步音视频的方法，同时模仿目标身份的说话和面部动作风格。|
|📝 更新|Dynamic-I2V: Exploring Image-to-Video Generation Models via Multimodal LLM|动态-I2V：通过多模态大型语言模型探索图像到视频生成模型|Peng Liu, Xiaoming Ren, Fengkai Liu, Qingsong Xie, Quanlong Zheng, Yanhao Zhang, Haonan Lu, Yujiu Yang|<http://arxiv.org/pdf/2505.19901v3>|Dynamic-I2V通过融合多模态LLM，显著提升了视频生成中的动态范围和可控性。|
|📝 更新|ViFOR: A Fourier-Enhanced Vision Transformer for Multi-Image Super-Resolution in Earth System|ViFOR：一种用于地球系统多图像超分辨率的傅里叶增强视觉Transformer|Ehsan Zeraatkar, Salah A Faroughi, Jelena Tešić|<http://arxiv.org/pdf/2502.12427v3>|ViFOR通过融合ViT与基于傅里叶的隐式神经网络，显著提升了多图像超分辨率性能。|
|🆕 发布|ViTNF: Leveraging Neural Fields to Boost Vision Transformers in Generalized Category Discovery|ViTNF：利用神经场提升通用类别发现中的视觉Transformer|Jiayi Su, Dequan Jin|<http://arxiv.org/pdf/2506.02367v1>|提出ViTNF，通过神经场替换MLP头，降低训练难度，提升泛化类别发现准确率。|
|📝 更新|GvT: A Graph-based Vision Transformer with Talking-Heads Utilizing Sparsity, Trained from Scratch on Small Datasets|基于图的可视化Transformer：利用稀疏性，从小型数据集从头训练的“说话头”|Dongjing Shan, guiqiang chen|<http://arxiv.org/pdf/2404.04924v2>|提出了一种基于图卷积和稀疏选择的视觉Transformer，有效缩小了小数据集上训练的ViT与CNN...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Targeted Forgetting of Image Subgroups in CLIP Models|针对CLIP模型中图像子组的定向遗忘|Zeliang Zhang, Gaowen Liu, Charles Fleming, Ramana Rao Kompella, Chenliang Xu|<http://arxiv.org/pdf/2506.03117v1>|提出了一种无需预训练数据，针对特定图像子组进行细粒度遗忘的CLIP模型方法。|
|📝 更新|SceneSplat: Gaussian Splatting-based Scene Understanding with Vision-Language Pretraining|场景Splat：基于高斯Splatting和视觉-语言预训练的场景理解|Yue Li, Qi Ma, Runyi Yang, Huapeng Li, Mengjiao Ma, Bin Ren, Nikola Popovic, Nicu Sebe .etc.|<http://arxiv.org/pdf/2503.18052v2>|SceneSplat通过3D高斯分层和自监督学习，实现了对室内场景的端到端理解。|
|🆕 发布|DFBench: Benchmarking Deepfake Image Detection Capability of Large Multimodal Models|DFBench：大型多模态模型深度伪造图像检测能力基准测试|Jiarui Wang, Huiyu Duan, Juntong Wang, Ziheng Jia, Woo Yi Yang, Xiaorong Zhu, Yu Zhao, Jiaying Qian .etc.|<http://arxiv.org/pdf/2506.03007v1>|[代码](https://github.com/IntMeGroup/DFBench.); 构建大规模深度伪造基准DFBench，提出MoA-DF混合模型，显著提升深度伪造检测能力。|
|📝 更新|Learning on Model Weights using Tree Experts|基于树专家的模型权重学习|Eliahu Horwitz, Bar Cavia, Jonathan Kahana, Yedid Hoshen|<http://arxiv.org/pdf/2410.13569v3>|提出了一种从模型权重学习的方法，通过轻量级探针专家（ProbeX）实现零样本模型分类。|
|📝 更新|A Novel Benchmark for Few-Shot Semantic Segmentation in the Era of Foundation Models|新型基础模型时代下的少样本语义分割基准|Reda Bensaid, Vincent Gripon, François Leduc-Primeau, Lukas Mauch, Ghouthi Boukli Hacene, Fabien Cardinaux|<http://arxiv.org/pdf/2401.11311v3>|提出首个针对基础模型在少样本语义分割任务上的适应性和性能评估基准。|
|🆕 发布|SAMJ: Fast Image Annotation on ImageJ/Fiji via Segment Anything Model|SAMJ：基于Segment Anything Model的ImageJ/Fiji快速图像标注|Carlos Garcia-Lopez-de-Haro, Caterina Fuster-Barcelo, Curtis T. Rueden, Jonathan Heras, Vladimir Ulman, Daniel Franco-Barranco, Adrian Ines, Kevin W. Eliceiri .etc.|<http://arxiv.org/pdf/2506.02783v1>|开发SAMJ插件，利用Segment Anything Model简化并加速生物医学图像的标注过程。|
|🆕 发布|Large-scale Self-supervised Video Foundation Model for Intelligent Surgery|大规模自监督视频基础模型用于智能手术|Shu Yang, Fengtao Zhou, Leon Mayer, Fuxiang Huang, Yiliang Chen, Yihui Wang, Sunan He, Yuxiang Nie .etc.|<http://arxiv.org/pdf/2506.02692v1>|构建了首个大规模自监督视频基础模型，通过时空建模提升智能手术场景理解。|
|🆕 发布|Towards Geometry Problem Solving in the Large Model Era: A Survey|面向大模型时代的几何问题求解：综述|Yurui Zhao, Xiang Wang, Jiahong Liu, Irwin King, Zhitao Huang|<http://arxiv.org/pdf/2506.02690v1>|该论文系统综述了大型模型时代几何问题求解的进展，提出了统一分析范式，以推动向人类水平几何推理发展。|
|📝 更新|Evaluating and Advancing Multimodal Large Language Models in Perception Ability Lens|评估与提升多模态大型语言模型在感知能力方面的研究|Feng Chen, Chenhui Gou, Jing Liu, Yang Yang, Zhaoyang Li, Jiyuan Zhang, Zhenbang Sun, Bohan Zhuang .etc.|<http://arxiv.org/pdf/2411.14725v2>|[代码](https://github.com/Chenfeng1271/AbilityLens.); 提出统一基准AbilityLens评估MLLM视觉感知能力，揭示模型性能差异及解决能力冲突策略。|
|🆕 发布|SiamNAS: Siamese Surrogate Model for Dominance Relation Prediction in Multi-objective Neural Architecture Search|SiamNAS：多目标神经架构搜索中优势关系预测的Siamese代理模型|Yuyang Zhou, Ferrante Neri, Yew-Soon Ong, Ruibin Bai|<http://arxiv.org/pdf/2506.02623v1>|SiamNAS通过Siamese网络预测架构优势关系，降低多目标NAS计算成本。|
|🆕 发布|VisuRiddles: Fine-grained Perception is a Primary Bottleneck for Multimodal Large Language Models in Abstract Visual Reasoning|视觉谜题：细粒度感知是抽象视觉推理中多模态大型语言模型的主要瓶颈|Hao Yan, Handong Zheng, Hao Wang, Liang Yin, Xingchen Liu, Zhenbiao Cao, Xinxing Su, Zihao Chen .etc.|<http://arxiv.org/pdf/2506.02537v1>|[代码](https://github.com/yh-hust/VisuRiddles); 提出VisuRiddles基准和PRS框架，提升MLLMs在抽象视觉推理中的感知能力。|
|🆕 发布|Minos: A Multimodal Evaluation Model for Bidirectional Generation Between Image and Text|Minos：图像与文本之间双向生成多模态评估模型|Junzhe Zhang, Huixuan Zhang, Xinyu Hu, Li Lin, Mingqi Gao, Shi Qiu, Xiaojun Wan|<http://arxiv.org/pdf/2506.02494v1>|提出Minos模型，结合人类和GPT评估数据，提升图像和文本双向生成任务评估性能。|
|📝 更新|InfoSAM: Fine-Tuning the Segment Anything Model from An Information-Theoretic Perspective|信息论视角下对Segment Anything Model的微调：InfoSAM|Yuanhong Zhang, Muyao Yuan, Weizhan Zhang, Tieliang Gong, Wen Wen, Jiangyong Ying, Weijie Shi|<http://arxiv.org/pdf/2505.21920v2>|InfoSAM通过信息理论优化SAM微调，提升其在特定领域应用性能。|
|📝 更新|VideoLLaMA 3: Frontier Multimodal Foundation Models for Image and Video Understanding|视频LLaMA 3：图像和视频理解的领先多模态基础模型|Boqiang Zhang, Kehan Li, Zesen Cheng, Zhiqiang Hu, Yuqian Yuan, Guanzheng Chen, Sicong Leng, Yuming Jiang .etc.|<http://arxiv.org/pdf/2501.13106v4>|VideoLLaMA3通过构建高质量图像-文本数据集，实现视觉中心的多模态基础模型，提升图像和视频理...|
|📝 更新|Foundation Models for Remote Sensing and Earth Observation: A Survey|遥感与地球观测的基础模型：综述|Aoran Xiao, Weihao Xuan, Junjue Wang, Jiaxing Huang, Dacheng Tao, Shijian Lu, Naoto Yokoya|<http://arxiv.org/pdf/2410.16602v3>|[代码](https://github.com/xiaoaoran/awesome-RSFMs); 提出RSFMs以解决遥感领域复杂需求，提升地球观测任务性能。|
|🆕 发布|Auto-Labeling Data for Object Detection|自动标注数据用于目标检测|Brent A. Griffin, Manushree Gangwar, Jacob Sela, Jason J. Corso|<http://arxiv.org/pdf/2506.02359v1>|提出无需标注数据训练目标检测模型，通过视觉语言模型自动生成伪标签，降低成本并保持高效。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|S4-Driver: Scalable Self-Supervised Driving Multimodal Large Language Modelwith Spatio-Temporal Visual Representation|S4-Driver：可扩展的自监督驾驶多模态大型语言模型，具有时空视觉表示|Yichen Xie, Runsheng Xu, Tong He, Jyh-Jing Hwang, Katie Luo, Jingwei Ji, Hubert Lin, Letian Chen .etc.|<http://arxiv.org/pdf/2505.24139v2>|提出S4-Driver，通过时空视觉表示实现无需标注的自动驾驶运动规划。|
|🆕 发布|FuseLIP: Multimodal Embeddings via Early Fusion of Discrete Tokens|融合LIP：通过早期融合离散标记的多模态嵌入|Christian Schlarmann, Francesco Croce, Nicolas Flammarion, Matthias Hein|<http://arxiv.org/pdf/2506.03096v1>|提出FuseLIP，通过早期融合文本和图像标记，实现多模态嵌入，提升多模态任务性能。|
|🆕 发布|Open-PMC-18M: A High-Fidelity Large Scale Medical Dataset for Multimodal Representation Learning|开放-PMC-18M：一个用于多模态表示学习的高保真大规模医学数据集|Negin Baghbanzadeh, Sajad Ashkezari, Elham Dolatabadi, Arash Afkanpour|<http://arxiv.org/pdf/2506.02738v1>|构建大规模医学数据集，通过子图提取提升视觉语言模型的表现。|
|📝 更新|Diving into Self-Evolving Training for Multimodal Reasoning|深入探索多模态推理的自进化训练|Wei Liu, Junlong Li, Xiwen Zhang, Fan Zhou, Yu Cheng, Junxian He|<http://arxiv.org/pdf/2412.17451v2>|提出M-STAR框架，通过强化学习优化自进化训练，显著提升多模态推理能力。|
|🆕 发布|Kernel-based Unsupervised Embedding Alignment for Enhanced Visual Representation in Vision-language Models|基于核的无需监督嵌入对齐以增强视觉语言模型中的视觉表示|Shizhan Gong, Yankai Jiang, Qi Dou, Farzan Farnia|<http://arxiv.org/pdf/2506.02557v1>|提出一种基于核函数的方法，将CLIP视觉表示与DINOv2对齐，增强视觉语言模型的多模态性能。|
|📝 更新|Beyond Face Swapping: A Diffusion-Based Digital Human Benchmark for Multimodal Deepfake Detection|超越面部交换：一种基于扩散的多模态深度伪造检测的数字人基准|Jiaxin Liu, Jia Wang, Saihui Hou, Min Ren, Huijia Wu, Long Ma, Renwang Pei, Zhaofeng He|<http://arxiv.org/pdf/2505.16512v4>|提出DigiShield，通过时空和跨模态融合有效检测多模态深伪视频。|
|🆕 发布|Video-Level Language-Driven Video-Based Visible-Infrared Person Re-Identification|基于视频级语言驱动的可见光-红外人物重识别|Shuang Li, Jiaxu Leng, Changjiang Kuang, Mingpi Tan, Xinbo Gao|<http://arxiv.org/pdf/2506.02439v1>|[代码](https://github.com/Visuang/VLD.); 提出了一种利用视频级语言驱动的VVI-ReID框架，通过模态无关语言提示和时空信息增强，有效解决跨模...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SASP: Strip-Aware Spatial Perception for Fine-Grained Bird Image Classification|SASP：基于条带感知的细粒度鸟类图像分类|Zheng Wang|<http://arxiv.org/pdf/2505.24380v2>|提出了一种基于条带感知的空间感知框架，有效提升了鸟类图像分类的准确性和鲁棒性。|
|📝 更新|Visual-TCAV: Concept-based Attribution and Saliency Maps for Post-hoc Explainability in Image Classification|视觉-TCAV：基于概念的归因和显著性图在图像分类后的解释性分析|Antonio De Santis, Riccardo Campi, Matteo Bianchi, Marco Brambilla|<http://arxiv.org/pdf/2411.05698v2>|[代码](https://github.com/DataSciencePolimi/Visual-TCAV.); Visual-TCAV通过结合概念激活向量和集成梯度，实现了图像分类中概念贡献的局部和全局可解释性。|
|📝 更新|PixelCAM: Pixel Class Activation Mapping for Histology Image Classification and ROI Localization|像素CAM：用于组织学图像分类和ROI定位的像素级激活映射|Alexis Guichemerre, Soufiane Belharbi, Mohammadhadi Shateri, Luke McCaffrey, Eric Granger|<http://arxiv.org/pdf/2503.24135v2>|PixelCAM通过在像素特征空间中同时训练图像和像素分类器，实现了对组织学图像的ROI定位和分类。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|UDA4Inst: Unsupervised Domain Adaptation for Instance Segmentation|UDA4Inst：实例分割的无监督领域自适应|Yachan Guo, Yi Xiao, Danna Xue, Jose L. Gomez, Antonio M. Lopez|<http://arxiv.org/pdf/2405.09682v6>|[代码](https://github.com/gyc-code/UDA4Inst.); 提出UDA4Inst，通过语义类别训练和双向混合训练，显著提升实例分割在自动驾驶领域的泛化能力。|
|📝 更新|OralBBNet: Spatially Guided Dental Segmentation of Panoramic X-Rays with Bounding Box Priors|口腔BBNet：基于边界框先验的口腔全景X射线空间引导分割|Devichand Budagam, Azamat Zhanatuly Imanbayev, Iskander Rafailovich Akhmetov, Aleksandr Sinitca, Sergey Antonov, Dmitrii Kaplun|<http://arxiv.org/pdf/2406.03747v2>|OralBBNet通过结合U-Net和YOLOv8的优势，实现了对全景X光片中牙齿的高精度分割和检测...|
|📝 更新|LeYOLO, New Embedded Architecture for Object Detection|LeYOLO：面向对象检测的新嵌入式架构|Lilian Hollard, Lucas Mohimont, Nathalie Gaveau, Luiz Angelo Steffenel|<http://arxiv.org/pdf/2406.14239v2>|提出LeNeck和LeYOLO，显著提升YOLO架构在低资源环境下的检测效率和准确度。|
|📝 更新|Inclusion 2024 Global Multimedia Deepfake Detection Challenge: Towards Multi-dimensional Face Forgery Detection|2024全球多媒体深度伪造检测挑战赛：迈向多维面部伪造检测|Yi Zhang, Weize Gao, Changtao Miao, Man Luo, Jianshu Li, Wenzhong Deng, Zhe Li, Bingyu Hu .etc.|<http://arxiv.org/pdf/2412.20833v2>|举办全球多媒体深度伪造检测挑战赛，推动多维人脸伪造检测方法研究。|
|🆕 发布|Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning|高效基于敏感度引导剪枝的测试时自适应目标检测|Kunyu Wang, Xueyang Fu, Xin Lu, Chengjie Ge, Chengzhi Cao, Wei Zhai, Zheng-Jun Zha|<http://arxiv.org/pdf/2506.02462v1>|提出了一种通过敏感度引导剪枝的CTTA-OD方法，有效提升适应性能并降低计算开销。|
|🆕 发布|InterRVOS: Interaction-aware Referring Video Object Segmentation|交互感知的指代视频目标分割|Woojeong Jin, Seongchan Kim, Seungryong Kim|<http://arxiv.org/pdf/2506.02356v1>|[代码](https://cvlab-kaist.github.io/InterRVOS); 提出了一种交互感知的视频目标分割方法，通过建模物体间关系提升分割性能。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Auto-Annotation from Annotation Guidelines: A Benchmark through 3D LiDAR Detection|迈向基于标注指南的自动标注：通过3D激光雷达检测的基准|Yechi Ma, Wei Hua, Shu Kong|<http://arxiv.org/pdf/2506.02914v1>|[代码](https://annoguide.github.io/annoguide3Dbenchmark); 提出AnnoGuide基准，通过3D LiDAR检测实现从标注指南到自动标注的突破。|
|🆕 发布|Dense Match Summarization for Faster Two-view Estimation|密集匹配摘要以加速双视图估计|Jonathan Astermark, Anders Heyden, Viktor Larsson|<http://arxiv.org/pdf/2506.02893v1>|提出高效匹配摘要方案，加速两视图估计，实现快速且准确的位置估计。|
|🆕 发布|Learning Pyramid-structured Long-range Dependencies for 3D Human Pose Estimation|学习金字塔结构的长距离依赖关系用于3D人体姿态估计|Mingjie Wei, Xuemei Xie, Yutong Zhong, Guangming Shi|<http://arxiv.org/pdf/2506.02853v1>|[代码](https://github.com/MingjieWe/PGFormer.); 提出了一种基于金字塔结构的图注意力模块，有效学习人体姿态估计中的长距离依赖关系，实现低误差和小模型。|
|📝 更新|CMRINet: Joint Groupwise Registration and Segmentation for Cardiac Function Quantification from Cine-MRI|CMRINet：基于电影MRI的心脏功能量化中的联合分组配准与分割|Mohamed S. Elmahdy, Marius Staring, Patrick J. H. de Koning, Samer Alabed, Mahan Salehi, Faisal Alandejani, Michael Sharkey, Ziad Aldabbagh .etc.|<http://arxiv.org/pdf/2505.16452v2>|提出了一种联合群组配准和分割的深度学习模型，有效提升了心脏功能量化评估的准确性和效率。|
|🆕 发布|A Dynamic Transformer Network for Vehicle Detection|动态变换网络在车辆检测中的应用|Chunwei Tian, Kai Liu, Bob Zhang, Zhixiang Huang, Chia-Wen Lin, David Zhang|<http://arxiv.org/pdf/2506.02765v1>|[代码](https://github.com/hellloxiaotian/DTNet.); 提出动态Transformer网络，通过混合注意力机制和翻译变分卷积，提升车辆检测适应性和准确性。|
|🆕 发布|GeneA-SLAM2: Dynamic SLAM with AutoEncoder-Preprocessed Genetic Keypoints Resampling and Depth Variance-Guided Dynamic Region Removal|基因A-SLAM2：基于自动编码器预处理遗传关键点重采样和深度方差引导的动态区域去除的动态SLAM|Shufan Qing, Anzhen Li, Qiandi Wang, Yuefeng Niu, Mingchen Feng, Guoliang Hu, Jinqiao Wu, Fengtao Nan .etc.|<http://arxiv.org/pdf/2506.02736v1>|[代码](https://github.com/qingshufan/GeneA-SLAM2.); GeneA-SLAM2通过深度方差约束和自动编码器预处理，有效识别动态场景并提高SLAM精度。|
|🆕 发布|HRTR: A Single-stage Transformer for Fine-grained Sub-second Action Segmentation in Stroke Rehabilitation|HRTR：用于中风康复中细粒度亚秒级动作分割的单阶段Transformer|Halil Ismail Helvaci, Justin Philip Huber, Jihye Bae, Sen-ching Samson Cheung|<http://arxiv.org/pdf/2506.02472v1>|HRTR通过单阶段Transformer实现高分辨率、亚秒级动作分割，有效解决康复训练中的动作监测难...|
|🆕 发布|RRCANet: Recurrent Reusable-Convolution Attention Network for Infrared Small Target Detection|RRCANet：用于红外小目标检测的循环可复用卷积注意力网络|Yongxian Liu, Boyang Li, Ting Liu, Zaiping Lin, Wei An|<http://arxiv.org/pdf/2506.02393v1>|[代码](https://code will be available at https://github.com/yongxianLiu/); 提出RRCA-Net，通过循环可复用卷积和交互注意力机制，有效提升红外小目标检测性能。|
|📝 更新|CodeEnhance: A Codebook-Driven Approach for Low-Light Image Enhancement|代码增强：一种基于代码簿的低光图像增强方法|Xu Wu, XianXu Hou, Zhihui Lai, Jie Zhou, Ya-nan Zhang, Witold Pedrycz, Linlin Shen|<http://arxiv.org/pdf/2404.05253v3>|提出CodeEnhance方法，通过代码本和图像细化解决低光图像增强中的不确定性和信息丢失问题。|
|🆕 发布|A TRPCA-Inspired Deep Unfolding Network for Hyperspectral Image Denoising via Thresholded t-SVD and Top-K Sparse Transformer|基于阈值t-SVD和Top-K稀疏变换器的TRPCA启发式深度展开网络用于高光谱图像去噪|Liang Li, Jianli Zhao, Sheng Fang, Siyu Chen, Hui Sun|<http://arxiv.org/pdf/2506.02364v1>|[代码](https://github.com/liangli97/TRPCA-Deep-Unfolding-HSI-Denoising.); 提出了一种基于TRPCA的深度展开网络，通过阈值t-SVD和Top-K稀疏变换器有效去噪高光谱图像。|
|📝 更新|Robust 6DoF Pose Estimation Against Depth Noise and a Comprehensive Evaluation on a Mobile Dataset|鲁棒6自由度姿态估计对抗深度噪声及在移动数据集上的全面评估|Zixun Huang, Keling Yao, Seth Z. Zhao, Chuanyu Pan, Allen Y. Yang|<http://arxiv.org/pdf/2309.13570v5>|[代码](https://openark-berkeley.github.io/DTTDNet); 提出了一种基于Transformer的鲁棒6DoF姿态估计方法，显著提升了移动设备在噪声深度数据下的...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Low-Resolution Self-Attention for Semantic Segmentation|低分辨率自注意力机制在语义分割中的应用|Yu-Huan Wu, Shi-Chen Zhang, Yun Liu, Le Zhang, Xin Zhan, Daquan Zhou, Jiashi Feng, Ming-Ming Cheng .etc.|<http://arxiv.org/pdf/2310.05026v3>|[代码](https://github.com/yuhuan-wu/LRFormer.); 引入低分辨率自注意力机制，降低计算成本，提升语义分割性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Context as Memory: Scene-Consistent Interactive Long Video Generation with Memory Retrieval|场景一致性交互式长视频生成与记忆检索：记忆作为背景|Jiwen Yu, Jianhong Bai, Yiran Qin, Quande Liu, Xintao Wang, Pengfei Wan, Di Zhang, Xihui Liu|<http://arxiv.org/pdf/2506.03141v1>|[代码](https://context-as-memory.github.io/.); 提出“记忆检索”机制，利用历史上下文信息，实现长视频场景一致性生成。|
|🆕 发布|SVGenius: Benchmarking LLMs in SVG Understanding, Editing and Generation|SVGenius：在SVG理解、编辑和生成中对大型语言模型进行基准测试|Siqi Chen, Xinyu Dong, Haolei Xu, Xingyu Wu, Fei Tang, Hang Zhang, Yuchen Yan, Linjuan Wu .etc.|<http://arxiv.org/pdf/2506.03139v1>|[代码](https://zju-real.github.io/SVGenius.); 构建了SVGenius基准，系统评估了LLMs在SVG理解和生成中的性能，揭示了当前方法的局限性和改...|
|🆕 发布|UniWorld: High-Resolution Semantic Encoders for Unified Visual Understanding and Generation|UniWorld：统一视觉理解和生成的高分辨率语义编码器|Bin Lin, Zongjian Li, Xinhua Cheng, Yuwei Niu, Yang Ye, Xianyi He, Shenghai Yuan, Wangbo Yu .etc.|<http://arxiv.org/pdf/2506.03147v1>|提出UniWorld模型，利用语义特征实现高效统一的视觉理解和生成。|
|🆕 发布|MERIT: Multilingual Semantic Retrieval with Interleaved Multi-Condition Query|MERIT：交错多条件查询的多语言语义检索|Wei Chow, Yuan Gao, Linfeng Li, Xian Wang, Qi Xu, Hang Song, Lingdong Kong, Ran Zhou .etc.|<http://arxiv.org/pdf/2506.03144v1>|提出MERIT多语言语义检索数据集，并设计Coral框架提升多条件查询性能。|
|🆕 发布|CamCloneMaster: Enabling Reference-based Camera Control for Video Generation|CamCloneMaster：实现基于参考的视频生成相机控制|Yawen Luo, Jianhong Bai, Xiaoyu Shi, Menghan Xia, Xintao Wang, Pengfei Wan, Di Zhang, Kun Gai .etc.|<http://arxiv.org/pdf/2506.03140v1>|提出CamCloneMaster，通过参考视频实现直观的相机控制，无需参数调整，提升视频生成质量。|
|🆕 发布|IllumiCraft: Unified Geometry and Illumination Diffusion for Controllable Video Generation|光绘术：可控视频生成的统一几何和光照扩散|Yuanze Lin, Yi-Wen Chen, Yi-Hsuan Tsai, Ronald Clark, Ming-Hsuan Yang|<http://arxiv.org/pdf/2506.03150v1>|IllumiCraft通过整合光照、外观和几何信息，实现了可控视频生成，提高了视频质量与连贯性。|
|🆕 发布|Simulate Any Radar: Attribute-Controllable Radar Simulation via Waveform Parameter Embedding|模拟任何雷达：通过波形参数嵌入的属性可控雷达模拟|Weiqing Xiao, Hao Huang, Chonghao Zhong, Yujie Lin, Nan Wang, Xiaoxue Chen, Zhaoxi Chen, Saining Zhang .etc.|<http://arxiv.org/pdf/2506.03134v1>|[代码](https://zhuxing0.github.io/projects); 提出了一种基于波形参数嵌入的雷达模拟方法，实现可控高效生成雷达数据。|
|🆕 发布|DCM: Dual-Expert Consistency Model for Efficient and High-Quality Video Generation|双专家一致性模型：高效且高质量的视频生成|Zhengyao Lv, Chenyang Si, Tianlin Pan, Zhaoxi Chen, Kwan-Yee K. Wong, Yu Qiao, Ziwei Liu|<http://arxiv.org/pdf/2506.03123v1>|[代码](https://github.com/Vchitect/DCM); 提出DCM模型，通过专家分工和时序一致性损失，有效提升视频生成质量和效率。|
|🆕 发布|Controllable Human-centric Keyframe Interpolation with Generative Prior|标题翻译：可控以人为中心的生成先验关键帧插值|Zujin Guo, Size Wu, Zhongang Cai, Wei Li, Chen Change Loy|<http://arxiv.org/pdf/2506.03119v1>|引入3D人体引导信号，提出PoseFuse3D-KI框架，显著提升可控关键帧插值效果。|
|🆕 发布|AnimeShooter: A Multi-Shot Animation Dataset for Reference-Guided Video Generation|AnimeShooter：一个用于参考引导视频生成的多帧动画数据集|Lu Qiu, Yizhuo Li, Yuying Ge, Yixiao Ge, Ying Shan, Xihui Liu|<http://arxiv.org/pdf/2506.03126v1>|构建AnimeShooter数据集，以参考图像指导生成连贯的多镜头动画视频。|
|🆕 发布|ByteMorph: Benchmarking Instruction-Guided Image Editing with Non-Rigid Motions|ByteMorph：非刚性运动指导下的图像编辑基准测试|Di Chang, Mingdeng Cao, Yichun Shi, Bo Liu, Shengqu Cai, Shijie Zhou, Weilin Huang, Gordon Wetzstein .etc.|<http://arxiv.org/pdf/2506.03107v1>|提出ByteMorph框架，解决非刚性运动指导下的图像编辑问题，构建大规模数据集并评估现有方法。|
|🆕 发布|InterMamba: Efficient Human-Human Interaction Generation with Adaptive Spatio-Temporal Mamba|InterMamba：自适应时空Mamba的高效人-人交互生成|Zizhao Wu, Yingying Sun, Yiming Chen, Xiaoling Gu, Ruyu Liu, Jiazhou Chen|<http://arxiv.org/pdf/2506.03084v1>|提出了一种基于Mamba框架的轻量级交互生成方法，有效提升了交互生成效率和准确性。|
|📝 更新|Chain-of-Jailbreak Attack for Image Generation Models via Editing Step by Step|链式越狱攻击：通过逐步编辑对图像生成模型的攻击|Wenxuan Wang, Kuiyi Gao, Youliang Yuan, Jen-tse Huang, Qiuzhi Liu, Shuai Wang, Wenxiang Jiao, Zhaopeng Tu|<http://arxiv.org/pdf/2410.03869v2>|提出了一种通过逐步编辑的Chain-of-Jailbreak攻击方法，有效评估并提升基于文本的图像生...|
|🆕 发布|ORV: 4D Occupancy-centric Robot Video Generation|基于占用中心的4D机器人视频生成|Xiuyu Yang, Bohan Li, Shaocong Xu, Nan Wang, Chongjie Ye, Zhaoxi Chen, Minghan Qin, Yikang Ding .etc.|<http://arxiv.org/pdf/2506.03079v1>|[代码](https://orangesodahub.github.io/ORV); 提出ORV框架，利用4D语义占用序列生成逼真机器人视频，提升控制精度和泛化能力。|
|🆕 发布|MIND: Material Interface Generation from UDFs for Non-Manifold Surface Reconstruction|MIND：基于UDF的非流形表面重建的材质界面生成|Xuhui Chen, Fei Hou, Wencheng Wang, Hong Qin, Ying He|<http://arxiv.org/pdf/2506.02938v1>|提出MIND算法，从UDFs直接生成材料界面，实现非流形表面重建。|
|🆕 发布|Interaction Field Matching: Overcoming Limitations of Electrostatic Models|交互场匹配：克服静电模型局限性|Stepan I. Manukhov, Alexander Kolesov, Vladimir V. Palyulin, Alexander Korotin|<http://arxiv.org/pdf/2506.02950v1>|提出了一种超越静电场匹配的交互场匹配方法，有效解决了静电场建模问题。|
|📝 更新|Beyond Prompt Engineering: Robust Behavior Control in LLMs via Steering Target Atoms|超越提示工程：通过引导目标原子在LLMs中实现鲁棒行为控制|Mengru Wang, Ziwen Xu, Shengyu Mao, Shumin Deng, Zhaopeng Tu, Huajun Chen, Ningyu Zhang|<http://arxiv.org/pdf/2505.20322v2>|提出 Steering Target Atoms 方法，通过操控解耦知识组件提升语言模型行为控制精度...|
|📝 更新|VectorPainter: Advanced Stylized Vector Graphics Synthesis Using Stroke-Style Priors|向量画家：基于笔触风格先验的高级风格化矢量图形合成|Juncheng Hu, Ximing Xing, Jing Zhang, Qian Yu|<http://arxiv.org/pdf/2405.02962v4>|VectorPainter通过模仿学习策略和风格保持损失函数，实现了基于参考图像的文本到矢量图形的合...|
|🆕 发布|LinkTo-Anime: A 2D Animation Optical Flow Dataset from 3D Model Rendering|《基于3D模型渲染的2D动画光流数据集：LinkTo-Anime》|Xiaoyi Feng, Kaifeng Zou, Caichun Cen, Tao Huang, Hui Guo, Zizhou Huang, Yingli Zhao, Mingqing Zhang .etc.|<http://arxiv.org/pdf/2506.02733v1>|构建首个针对手绘动画角色运动的3D渲染光流数据集，推动动画视频生成和线稿着色等研究。|
|🆕 发布|LayoutRAG: Retrieval-Augmented Model for Content-agnostic Conditional Layout Generation|布局RAG：内容无关条件布局生成的检索增强模型|Yuxuan Wu, Le Wang, Sanping Zhou, Mengnan Liu, Gang Hua, Haoxiang Li|<http://arxiv.org/pdf/2506.02697v1>|提出一种通过检索和条件引导生成内容无关布局的模型，显著提升布局生成质量。|
|🆕 发布|ToothForge: Automatic Dental Shape Generation using Synchronized Spectral Embeddings|牙匠：同步频谱嵌入的自动牙形生成|Tibor Kubík, François Guibault, Michal Španěl, Hervé Lombaert|<http://arxiv.org/pdf/2506.02702v1>|[代码](https://github.com/tiborkubik/toothForge.); 提出了一种利用同步频谱嵌入自动生成高分辨率3D牙齿模型的方法，有效解决了牙科形状数据集的稀疏性问题。|
|📝 更新|S3D: Sketch-Driven 3D Model Generation|S3D：基于草图的三维模型生成|Hail Song, Wonsik Shin, Naeun Lee, Soomin Chung, Nojun Kwak, Woontack Woo|<http://arxiv.org/pdf/2505.04185v2>|[代码](https://github.com/hailsong/S3D.); 提出了一种从2D草图生成3D模型的新框架S3D，通过风格对齐和数据增强显著提升了重建质量。|
|🆕 发布|MotionRAG-Diff: A Retrieval-Augmented Diffusion Framework for Long-Term Music-to-Dance Generation|运动RAG-Diff：一种用于长期音乐到舞蹈生成的检索增强扩散框架|Mingyang Huang, Peng Zhang, Bang Zhang|<http://arxiv.org/pdf/2506.02661v1>|提出了一种结合检索增强和扩散模型的混合框架，有效解决了音乐到舞蹈的长期生成问题。|
|🆕 发布|Solving Inverse Problems with FLAIR|利用FLAIR解决逆问题|Julius Erbach, Dominik Narnhofer, Andreas Dombos, Bernt Schiele, Jan Eric Lenssen, Konrad Schindler|<http://arxiv.org/pdf/2506.02680v1>|FLAIR通过结合流式生成模型和变分框架，有效解决了逆问题中的数据恢复难题。|
|🆕 发布|Synthetic Iris Image Databases and Identity Leakage: Risks and Mitigation Strategies|合成虹膜图像数据库与身份泄露：风险与缓解策略|Ada Sawilska, Mateusz Trokielewicz|<http://arxiv.org/pdf/2506.02626v1>|该论文提出合成虹膜图像数据库，以解决生物识别数据泄露风险，并探讨其替代真实数据的可行性。|
|🆕 发布|ControlMambaIR: Conditional Controls with State-Space Model for Image Restoration|控制曼巴IR：基于状态空间模型的图像恢复条件控制|Cheng Yang, Lijing Liang, Zhixun Su|<http://arxiv.org/pdf/2506.02633v1>|ControlMambaIR通过结合Mamba网络和扩散模型，实现了对图像去雨、去模糊和去噪的精细条...|
|🆕 发布|FlexPainter: Flexible and Multi-View Consistent Texture Generation|FlexPainter：灵活且多视图一致的纹理生成|Dongyu Yan, Leyi Wu, Jiantao Lin, Luozhou Wang, Tianshuo Xu, Zhifei Chen, Zhen Yang, Lie Xu .etc.|<http://arxiv.org/pdf/2506.02620v1>|FlexPainter通过灵活的多模态引导和同步多视图生成，实现了高质量的纹理生成。|
|🆕 发布|Hyperspectral Image Generation with Unmixing Guided Diffusion Model|usion Guided Diffusion Model生成高光谱图像|Shiyu Shen, Bin Pan, Ziye Zhang, Zhenwei Shi|<http://arxiv.org/pdf/2506.02601v1>|提出了一种基于光谱解混引导的扩散模型，有效降低了高光谱图像生成的计算复杂度并保证了物理一致性。|
|🆕 发布|DCI: Dual-Conditional Inversion for Boosting Diffusion-Based Image Editing|DCI：用于增强扩散图像编辑的双条件逆变换|Zixiang Li, Haoyu Wang, Wei Wang, Chuangchuang Tan, Yunchao Wei, Yao Zhao|<http://arxiv.org/pdf/2506.02560v1>|DCI通过联合条件化源提示和参考图像，优化了扩散模型中的图像编辑和重建过程，显著提升了编辑精度和重建...|
|📝 更新|ViDoRAG: Visual Document Retrieval-Augmented Generation via Dynamic Iterative Reasoning Agents|ViDoRAG：通过动态迭代推理代理进行视觉文档检索增强生成|Qiuchen Wang, Ruixue Ding, Zehui Chen, Weiqi Wu, Shihang Wang, Pengjun Xie, Feng Zhao|<http://arxiv.org/pdf/2502.18017v2>|[代码](https://github.com/Alibaba-NLP/ViDoRAG.); ViDoRAG通过动态迭代推理代理，有效提升了视觉文档检索增强生成中的检索、理解和推理能力。|
|🆕 发布|Towards Better De-raining Generalization via Rainy Characteristics Memorization and Replay|通过雨天气特征记忆与重放实现更好的去雨泛化|Kunyu Wang, Xueyang Fu, Chengzhi Cao, Chengjie Ge, Wei Zhai, Zheng-Jun Zha|<http://arxiv.org/pdf/2506.02477v1>|通过记忆和重放雨天特征，该框架使去雨网络从多个数据集中积累知识，显著提升其泛化能力。|
|📝 更新|DC-ControlNet: Decoupling Inter- and Intra-Element Conditions in Image Generation with Diffusion Models|DC-ControlNet：使用扩散模型解耦图像生成中的元素间和元素内条件|Hongji Yang, Wencheng Han, Yucheng Zhou, Jianbing Shen|<http://arxiv.org/pdf/2502.14779v2>|[代码](https://um-lab.github.io/DC-ControlNet); DC-ControlNet通过解耦元素间和元素内条件，实现了更灵活、精确的多条件图像生成控制。|
|🆕 发布|Generative Perception of Shape and Material from Differential Motion|形状和材料差异运动感知的生成式理解|Xinran Nicole Han, Ko Nishino, Todd Zickler|<http://arxiv.org/pdf/2506.02473v1>|提出了一种从物体运动视频中生成形状和材质图的条件去噪扩散模型，以解决单张图像中形状和材质的感知难题。|
|🆕 发布|ReSpace: Text-Driven 3D Scene Synthesis and Editing with Preference Alignment|ReSpace：基于文本驱动的3D场景合成与编辑及偏好对齐|Martin JJ. Bucher, Iro Armeni|<http://arxiv.org/pdf/2506.02459v1>|ReSpace通过文本驱动和偏好对齐，实现了3D室内场景的生成与编辑。|
|🆕 发布|SViMo: Synchronized Diffusion for Video and Motion Generation in Hand-object Interaction Scenarios|SViMo：手-物体交互场景中的同步扩散视频和运动生成|Lingwei Dang, Ruizhi Shao, Hongwen Zhang, Wei Min, Yebin Liu, Qingyao Wu|<http://arxiv.org/pdf/2506.02444v1>|提出同步扩散方法，同时生成手-物体交互视频和动作，显著提升视频-动作一致性。|
|🆕 发布|ANT: Adaptive Neural Temporal-Aware Text-to-Motion Model|自适应神经时序感知文本到动作模型|Wenshuo Chen, Kuimou Yu, Haozhe Jia, Kaishen Yuan, Bowen Tian, Songning Lai, Hongru Xiao, Erhang Zhang .etc.|<http://arxiv.org/pdf/2506.02452v1>|提出自适应神经时序感知架构ANT，解决文本到动作生成中语义与时序不匹配问题，显著提升模型性能。|
|📝 更新|Datasheets Aren't Enough: DataRubrics for Automated Quality Metrics and Accountability|数据说明书不够：用于自动质量指标和责任的数据评分标准|Genta Indra Winata, David Anugraha, Emmy Liu, Alham Fikri Aji, Shou-Yi Hung, Aditya Parashar, Patrick Amadeus Irawan, Ruochen Zhang .etc.|<http://arxiv.org/pdf/2506.01789v2>|[代码](https://github.com/datarubrics/datarubrics.); 提出DataRubrics框架，通过系统化评估指标提升数据集质量评估和透明度。|
|🆕 发布|Modelship Attribution: Tracing Multi-Stage Manipulations Across Generative Models|模型归因：追踪生成模型中的多阶段操作|Zhiya Tan, Xin Zhang, Joey Tianyi Zhou|<http://arxiv.org/pdf/2506.02405v1>|首次提出模型船归因方法，追踪生成模型多阶段操作以识别图像编辑过程。|
|🆕 发布|Towards Explicit Geometry-Reflectance Collaboration for Generalized LiDAR Segmentation in Adverse Weather|面向恶劣天气下广义激光雷达分割的显式几何-反射率协作|Longyu Yang, Ping Hu, Shangbo Yuan, Lu Zhang, Jun Liu, Hengtao Shen, Xiaofeng Zhu|<http://arxiv.org/pdf/2506.02396v1>|提出了一种基于几何-反射协作的LiDAR分割框架，有效提升恶劣天气下的分割准确率。|
|📝 更新|OmniAudio: Generating Spatial Audio from 360-Degree Video|全息音频：从360度视频中生成空间音频|Huadai Liu, Tianyi Luo, Kaicheng Luo, Qikai Jiang, Peiwen Sun, Jialei Wang, Rongjie Huang, Qian Chen .etc.|<http://arxiv.org/pdf/2504.14906v3>|[代码](https://github.com/liuhuadai/OmniAudio.); 提出OmniAudio框架，从360度视频生成空间音频，实现真实3D音效再现。|
|📝 更新|Video Motion Graphs|视频运动图|Haiyang Liu, Zhan Xu, Fa-Ting Hong, Hsin-Ping Huang, Yi Zhou, Yang Zhou|<http://arxiv.org/pdf/2503.20218v2>|[代码](https://h-liu1997.github.io/Video-Motion-Graphs); 提出视频运动图系统，通过结合运动扩散模型和条件渐进训练，实现高质量的人体运动视频生成。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Native-Resolution Image Synthesis|原生分辨率图像合成|Zidong Wang, Lei Bai, Xiangyu Yue, Wanli Ouyang, Yiyuan Zhang|<http://arxiv.org/pdf/2506.03131v1>|提出NiT模型，实现任意分辨率和宽高比图像的生成，突破传统方法的限制。|
|🆕 发布|SG2VID: Scene Graphs Enable Fine-Grained Control for Video Synthesis|SG2VID：场景图实现视频合成的细粒度控制|Ssharvien Kumar Sivakumar, Yannik Frisch, Ghazal Ghazaei, Anirban Mukhopadhyay|<http://arxiv.org/pdf/2506.03082v1>|SG2VID通过利用场景图实现精细的视频合成和人类控制，解决了传统模拟工具缺乏真实性和多样性的问题。|
|🆕 发布|EDITOR: Effective and Interpretable Prompt Inversion for Text-to-Image Diffusion Models|有效的可解释文本到图像扩散模型提示反转|Mingzhe Li, Gehao Zhang, Zhenting Wang, Shiqing Ma, Siqi Pan, Richard Cartwright, Juan Zhai|<http://arxiv.org/pdf/2506.03067v1>|提出了一种基于预训练模型和反向工程的有效文本到图像提示逆方法，显著提升了图像相似度和提示可解释性。|
|📝 更新|Effective Dual-Region Augmentation for Reduced Reliance on Large Amounts of Labeled Data|有效的双区域增强以减少对大量标记数据的依赖|Prasanna Reddy Pulakurthi, Majid Rabbani, Celso M. de Melo, Sohail A. Dianat, Raghuveer M. Rao|<http://arxiv.org/pdf/2504.13077v2>|[代码](https://github.com/PrasannaPulakurthi/Foreground-Background-Augmentation); 提出了一种通过双重区域增强方法，减少对大量标注数据依赖，提升模型鲁棒性和泛化能力的计算机视觉技术。|
|📝 更新|MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset|多环境、多物种、低空无人机数据集：MMLA|Jenna Kline, Samuel Stevens, Guy Maalouf, Camille Rondeau Saint-Jean, Dat Nguyen Ngoc, Majid Mirmehdi, David Guerin, Tilo Burghardt .etc.|<http://arxiv.org/pdf/2504.07744v2>|构建多环境、多物种低空无人机数据集，提升YOLO模型在野生动物检测中的泛化能力。|
|🆕 发布|PartComposer: Learning and Composing Part-Level Concepts from Single-Image Examples|部分合成器：从单图像示例中学习和合成部分级概念|Junyu Liu, R. Kenny Jones, Daniel Ritchie|<http://arxiv.org/pdf/2506.03004v1>|PartComposer通过动态数据合成和概念预测，实现从单图学习部件级概念，并有效组合成新颖物体。|
|🆕 发布|Astrophotography turbulence mitigation via generative models|天文摄影中的湍流缓解通过生成模型|Joonyeoup Kim, Yu Yuan, Xingguang Zhang, Xijun Wang, Stanley Chan|<http://arxiv.org/pdf/2506.02981v1>|提出AstroDiff，一种基于扩散模型的生成式图像恢复方法，有效缓解天文摄影中的大气湍流问题。|
|📝 更新|HunyuanVideo-Avatar: High-Fidelity Audio-Driven Human Animation for Multiple Characters|HunyuanVideo-Avatar：多角色高保真音频驱动的人体动画|Yi Chen, Sen Liang, Zixiang Zhou, Ziyao Huang, Yifeng Ma, Junshu Tang, Qin Lin, Yuan Zhou .etc.|<http://arxiv.org/pdf/2505.20156v2>|HunyuanVideo-Avatar通过创新模块实现多角色、高保真、情感同步的人动画。|
|🆕 发布|NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results|NTIRE 2025 XGC图像质量评估挑战：方法与结果|Xiaohong Liu, Xiongkuo Min, Qiang Hu, Xiaoyun Zhang, Jie Guo, Guangtao Zhai, Shushi Wang, Yingjie Zhou .etc.|<http://arxiv.org/pdf/2506.02875v1>|举办NTIRE 2025 XGC质量评估挑战，提出多方法提升视频和头部处理质量。|
|🆕 发布|GaRA-SAM: Robustifying Segment Anything Model with Gated-Rank Adaptation|GaRA-SAM：通过门控排序自适应增强的Segment Anything模型|Sohyun Lee, Yeho Kwon, Lukas Hoyer, Suha Kwak|<http://arxiv.org/pdf/2506.02882v1>|通过引入门控秩自适应，GaRA-SAM显著提升了Segment Anything Model对输入退...|
|🆕 发布|PBR-SR: Mesh PBR Texture Super Resolution from 2D Image Priors|PBR-SR：基于2D图像先验的网格PBR纹理超分辨率|Yujin Chen, Yinyu Nie, Benjamin Ummenhofer, Reiner Birkl, Michael Paulitsch, Matthias Nießner|<http://arxiv.org/pdf/2506.02846v1>|PBR-SR通过结合自然图像超分辨率模型和2D先验约束，实现了从低分辨率PBR输入到高分辨率纹理的零...|
|📝 更新|P-TAME: Explain Any Image Classifier with Trained Perturbations|P-TAME：使用训练扰动解释任何图像分类器|Mariano V. Ntrougkas, Vasileios Mezaris, Ioannis Patras|<http://arxiv.org/pdf/2501.17813v2>|P-TAME通过训练扰动解释任何图像分类器，提供高效、高分辨率的可解释性。|
|📝 更新|DeepSPV: A Deep Learning Pipeline for 3D Spleen Volume Estimation from 2D Ultrasound Images|深度SPV：一种从二维超声图像中估计三维脾脏体积的深度学习流程|Zhen Yuan, David Stojanovski, Lei Li, Alberto Gomez, Haran Jogeesvaran, Esther Puyol-Antón, Baba Inusa, Andrew P. King|<http://arxiv.org/pdf/2411.11190v2>|提出了一种从二维超声图像中精确估计脾脏体积的深度学习管道DeepSPV，超越人类专家水平。|
|🆕 发布|FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts|自由场景：基于自由提示的3D场景合成的混合图扩散|Tongyuan Bai, Wangyuanfan Bai, Dong Chen, Tieru Wu, Manyi Li, Rui Ma|<http://arxiv.org/pdf/2506.02781v1>|FreeScene通过混合图扩散技术，实现了从自由提示到3D场景合成的便捷且可控的用户体验。|
|📝 更新|No Training, No Problem: Rethinking Classifier-Free Guidance for Diffusion Models|无需训练，无惧问题：重新思考扩散模型的无分类器引导|Seyedmorteza Sadat, Manuel Kansy, Otmar Hilliges, Romann M. Weber|<http://arxiv.org/pdf/2407.02687v2>|提出独立条件引导和时间步引导，无需特殊训练即提升扩散模型生成质量。|
|📝 更新|Eliminating Oversaturation and Artifacts of High Guidance Scales in Diffusion Models|消除扩散模型中高指导尺度过度饱和和伪影的方法|Seyedmorteza Sadat, Otmar Hilliges, Romann M. Weber|<http://arxiv.org/pdf/2410.02416v2>|提出自适应投影引导方法，解决扩散模型高指导尺度导致的过度饱和和伪影问题。|
|📝 更新|Constant Rate Scheduling: Constant-Rate Distributional Change for Efficient Training and Sampling in Diffusion Models|恒定速率调度：扩散模型中高效训练和采样的恒定速率分布变化|Shuntaro Okada, Kenji Doi, Ryota Yoshihashi, Hirokatsu Kataoka, Tomohiro Tanaka|<http://arxiv.org/pdf/2411.12188v3>|提出了一种优化扩散模型噪声调度方法，实现训练和采样效率提升。|
|🆕 发布|Smoothed Preference Optimization via ReNoise Inversion for Aligning Diffusion Models with Varied Human Preferences|通过ReNoise反演进行平滑偏好优化，以与不同人类偏好对齐扩散模型|Yunhong Lu, Qichao Wang, Hengyuan Cao, Xiaoyin Xu, Min Zhang|<http://arxiv.org/pdf/2506.02698v1>|[代码](https://jaydenlyh.github.io/SmPO-project-page); 提出了一种通过ReNoise逆变换平滑偏好优化方法，以更精细地调整扩散模型与人类偏好的一致性。|
|🆕 发布|Iterative Self-Improvement of Vision Language Models for Image Scoring and Self-Explanation|视觉语言模型在图像评分和自我解释中的迭代自我提升|Naoto Tanji, Toshihiko Yamasaki|<http://arxiv.org/pdf/2506.02708v1>|提出了一种基于自训练和优化的方法，使视觉语言模型不仅能准确评分图像，还能自然地解释其理由。|
|🆕 发布|Grasp2Grasp: Vision-Based Dexterous Grasp Translation via Schrödinger Bridges|抓取2抓取：通过薛定谔桥实现的基于视觉的灵巧抓取转换|Tao Zhong, Jonah Buchanan, Christine Allen-Blanchette|<http://arxiv.org/pdf/2506.02489v1>|提出了一种基于Schrödinger桥梁的视觉方法，实现不同形态机器人手之间灵巧抓取的转换。|
|🆕 发布|Flexiffusion: Training-Free Segment-Wise Neural Architecture Search for Efficient Diffusion Models|Flexiffusion：无需训练的基于段级的神经网络架构搜索，用于高效扩散模型|Hongtao Huang, Xiaojun Chang, Lina Yao|<http://arxiv.org/pdf/2506.02488v1>|Flexiffusion通过无监督的段式搜索和轻量级评估，实现了高效扩散模型的无需训练的架构搜索。|
|📝 更新|PHISWID: Physics-Inspired Underwater Image Dataset Synthesized from RGB-D Images|PHISWID：基于物理的从RGB-D图像合成的水下图像数据集|Reina Kaneko, Takumi Ueda, Hiroshi Higashi, Yuichi Tanaka|<http://arxiv.org/pdf/2404.03998v3>|构建了基于物理模型的PHISWID水下图像数据集，有效提升图像增强性能。|
|📝 更新|Shallow Diffuse: Robust and Invisible Watermarking through Low-Dimensional Subspaces in Diffusion Models|浅层漫反射：通过扩散模型中的低维子空间实现鲁棒且不可见的水印嵌入|Wenda Li, Huijie Zhang, Qing Qu|<http://arxiv.org/pdf/2410.21088v2>|[代码](https://github.com/liwd190019/Shallow-Diffuse.); 提出了一种通过低维子空间嵌入鲁棒且隐形水印的Shallow Diffuse技术，有效防止AI生成内容...|
|📝 更新|Latent Wavelet Diffusion: Enabling 4K Image Synthesis for Free|潜波扩散：实现免费4K图像合成|Luigi Sigillo, Shengfeng He, Danilo Comminiello|<http://arxiv.org/pdf/2506.00433v2>|提出Latent Wavelet Diffusion，实现免费超高清图像合成，提升感知质量和降低FI...|
|📝 更新|Enhancing Target-unspecific Tasks through a Features Matrix|通过特征矩阵增强目标非特异性任务|Fangming Cui, Yonggang Zhang, Xuan Wang, Xinmei Tian, Jun Yu|<http://arxiv.org/pdf/2505.03414v5>|提出特征矩阵方法，有效提升模型在非特定目标任务上的泛化能力。|
|📝 更新|A Similarity Paradigm Through Textual Regularization Without Forgetting|通过文本正则化实现的无遗忘相似性范式|Fangming Cui, Jan Fong, Rongfei Zeng, Xinmei Tian, Jun Yu|<http://arxiv.org/pdf/2502.14376v2>|提出SPTR方法，通过文本正则化和相似性范式，解决提示学习中的遗忘问题，提升模型泛化能力。|
|🆕 发布|The Devil is in the Darkness: Diffusion-Based Nighttime Dehazing Anchored in Brightness Perception|ness: 基于亮度感知的扩散式夜间去雾锚定|Xiaofeng Cong, Yu-Xin Zhang, Haoran Wei, Yeying Jin, Junming Hou, Jie Gui, Jing Zhang, Dacheng Tao|<http://arxiv.org/pdf/2506.02395v1>|提出了一种基于亮度感知的扩散模型，有效解决夜间图像去雾和亮度映射问题。|
|📝 更新|Concept Corrector: Erase concepts on the fly for text-to-image diffusion models|概念纠正器：实时擦除文本到图像扩散模型中的概念|Zheling Meng, Bo Peng, Xiaochuan Jin, Yueming Lyu, Wei Wang, Jing Dong, Tieniu Tan|<http://arxiv.org/pdf/2502.16368v3>|提出了一种基于生成图像中间特征的概念擦除方法，有效去除文本到图像模型生成的不当内容。|
|📝 更新|Normalized Attention Guidance: Universal Negative Guidance for Diffusion Models|标准化注意力引导：扩散模型的通用负引导|Dar-Yen Chen, Hmrishav Bandyopadhyay, Kai Zou, Yi-Zhe Song|<http://arxiv.org/pdf/2505.21179v3>|提出了一种名为NAG的通用负向引导机制，有效解决扩散模型中负向引导的挑战。|
|📝 更新|Rethinking Diffusion Posterior Sampling: From Conditional Score Estimator to Maximizing a Posterior|重新思考扩散后验采样：从条件得分估计到最大化后验|Tongda Xu, Xiyan Cai, Xinjie Zhang, Xingtong Ge, Dailan He, Ming Sun, Jingjing Liu, Ya-Qin Zhang .etc.|<http://arxiv.org/pdf/2501.18913v2>|[代码](https://github.com/tongdaxu/Rethinking-Diffusion-Posterior-Sampling-From-Conditional-Score-Estimator-to-Maximizing-a-Posterior.); 重新审视扩散后验采样，从条件得分估计器转向最大化后验概率，显著提升了扩散模型样本质量。|
|🆕 发布|Unrolling Nonconvex Graph Total Variation for Image Denoising|非凸图全变分展开用于图像去噪|Songlin Wei, Gene Cheung, Fei Chen, Ivan Selesnick|<http://arxiv.org/pdf/2506.02381v1>|提出了一种基于非凸图总变分的新图像去噪方法，有效提升了去噪性能并减少了网络参数。|
|📝 更新|SyncSDE: A Probabilistic Framework for Diffusion Synchronization|同步SDE：扩散同步的概率框架|Hyunjun Lee, Hyunsoo Lee, Sookwan Han|<http://arxiv.org/pdf/2503.21555v2>|提出了一种基于概率框架的扩散同步方法，优化了多扩散模型协同生成效果。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Adversarial Robustness of AI-Generated Image Detectors in the Real World|人工智能生成图像检测器在现实世界中的对抗鲁棒性|Sina Mavali, Jonas Ricker, David Pape, Asja Fischer, Lea Schönherr|<http://arxiv.org/pdf/2410.01574v3>|揭示了AI生成图像检测器在现实世界中的对抗鲁棒性问题，并提出使用鲁棒预训练模型生成特征以增强其鲁棒性...|
|🆕 发布|Sparse-vDiT: Unleashing the Power of Sparse Attention to Accelerate Video Diffusion Transformers|稀疏-vDiT：释放稀疏注意力加速视频扩散Transformer的潜力|Pengtao Chen, Xianfang Zeng, Maosen Zhao, Peng Ye, Mingzhu Shen, Wei Cheng, Gang Yu, Tao Chen|<http://arxiv.org/pdf/2506.03065v1>|通过识别视频扩散Transformer中的稀疏模式，提出Sparse-vDiT框架，显著加速视频生成...|
|🆕 发布|Rethinking Machine Unlearning in Image Generation Models|重新思考图像生成模型中的机器反学习|Renyang Liu, Wenjie Feng, Tianwei Zhang, Wei Zhou, Xueqi Cheng, See-Kiong Ng|<http://arxiv.org/pdf/2506.02761v1>|[代码](https://github.com/ryliu68/IGMU.); 设计CatIGMU分类框架和EvalIGMU评估框架，构建DataIGM数据集，推动图像生成模型反学...|
|📝 更新|OpenS2V-Nexus: A Detailed Benchmark and Million-Scale Dataset for Subject-to-Video Generation|OpenS2V-Nexus：面向主题到视频生成的详细基准和百万规模数据集|Shenghai Yuan, Xianyi He, Yufan Deng, Yang Ye, Jinfa Huang, Bin Lin, Jiebo Luo, Li Yuan|<http://arxiv.org/pdf/2505.20292v4>|构建了OpenS2V-Nexus，提供细粒度基准和大规模数据集，以提升主体到视频生成的一致性和自然度...|
|🆕 发布|One-Step Diffusion-based Real-World Image Super-Resolution with Visual Perception Distillation|一步扩散视觉感知蒸馏的实时图像超分辨率|Xue Wu, Jingwei Xin, Zhijun Tu, Jie Hu, Jie Li, Nannan Wang, Xinbo Gao|<http://arxiv.org/pdf/2506.02605v1>|提出了一种基于视觉感知蒸馏的图像超分辨率方法，通过一步采样显著提升了重建图像的感知质量和语义一致性。|
|📝 更新|Generative Emotion Cause Explanation in Multimodal Conversations|多模态对话中的生成情感原因解释|Lin Wang, Xiaocui Yang, Shi Feng, Daling Wang, Yifei Zhang, Zhitao Zhang|<http://arxiv.org/pdf/2411.02430v2>|[代码](https://github.com/3222345200/FAME-Net.); 提出了一种基于LLMs的多模态情感原因解释方法，有效识别对话中的情感触发因素。|
|🆕 发布|RelationAdapter: Learning and Transferring Visual Relation with Diffusion Transformers|关系适配器：通过扩散变换器学习和迁移视觉关系|Yan Gong, Yiren Song, Yicheng Li, Chenglin Li, Yin Zhang|<http://arxiv.org/pdf/2506.02528v1>|RelationAdapter通过扩散Transformer学习并迁移视觉关系，显著提升了图像编辑的...|
|📝 更新|AvatarShield: Visual Reinforcement Learning for Human-Centric Video Forgery Detection|AvatarShield：以人为中心的视频伪造检测的视觉强化学习|Zhipei Xu, Xuanyu Zhang, Xing Zhou, Jian Zhang|<http://arxiv.org/pdf/2505.15173v2>|AvatarShield通过可解释的MLLM框架和GRPO优化，有效检测人类中心视频伪造，显著提升检...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Self-supervised Learning of Event-guided Video Frame Interpolation for Rolling Shutter Frames|基于事件引导的滚动快门帧视频帧插值的自监督学习|Yunfan Lu, Guoqiang Liang, Yiran Shen, Lin Wang|<http://arxiv.org/pdf/2306.15507v2>|提出了一种基于事件相机和自监督学习的滚动快门视频帧插值方法，有效消除扭曲并提升视频质量。|
|🆕 发布|Hierarchical Question-Answering for Driving Scene Understanding Using Vision-Language Models|基于视觉-语言模型的驾驶场景理解分层问答|Safaa Abdullahi Moallim Mohamud, Minjin Baek, Dong Seog Han|<http://arxiv.org/pdf/2506.02615v1>|提出了一种高效视觉语言模型，通过分层问答策略实现自动驾驶场景理解，兼顾成本与细节。|
|🆕 发布|LumosFlow: Motion-Guided Long Video Generation|光流：运动引导的长视频生成|Jiahao Chen, Hangjie Yuan, Yichen Qian, Jingyun Liang, Jiazheng Xing, Pengwei Liu, Weihua Chen, Fan Wang .etc.|<http://arxiv.org/pdf/2506.02497v1>|[代码](https://jiahaochen1.github.io/LumosFlow); LumosFlow通过引入运动引导，有效生成连贯且具有多样性的长视频序列。|
|🆕 发布|Empowering Functional Neuroimaging: A Pre-trained Generative Framework for Unified Representation of Neural Signals|赋能功能性神经影像：一种用于统一表示神经信号的预训练生成框架|Weiheng Yao, Xuhang Chen, Shuqiang Wang|<http://arxiv.org/pdf/2506.02433v1>|提出一种生成式AI框架，统一表示多模态神经信号，降低获取成本并提升BCI解码公平性。|
|📝 更新|Reinforcing Video Reasoning with Focused Thinking|强化视频推理的专注思考|Jisheng Dang, Jingze Wu, Teng Wang, Xuanhui Lin, Nannan Zhu, Hongbo Chen, Wei-Shi Zheng, Meng Wang .etc.|<http://arxiv.org/pdf/2505.24718v2>|[代码](https://github.com/longmalongma/TW-GRPO); 提出TW-GRPO框架，通过聚焦思维和精细奖励增强视频推理能力。|
|📝 更新|MCU: An Evaluation Framework for Open-Ended Game Agents|MCU：开放式游戏智能体的评估框架|Xinyue Zheng, Haowei Lin, Kaichen He, Zihao Wang, Zilong Zheng, Yitao Liang|<http://arxiv.org/pdf/2310.08367v4>|[代码](https://github.com/CraftJarvis/MCU.); 提出MCU框架，解决开放世界AI代理评估难题，推动AI在开放环境中的发展。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Self-Supervised Spatial Correspondence Across Modalities|跨模态的自监督空间对应|Ayush Shrivastava, Andrew Owens|<http://arxiv.org/pdf/2506.03148v1>|提出了一种无需空间对齐的多模态图像配准方法，通过对比随机游走学习跨模态和同模态特征表示。|
|🆕 发布|BEVCALIB: LiDAR-Camera Calibration via Geometry-Guided Bird's-Eye View Representations|BEVCALIB：基于几何引导的鸟瞰视图表示的激光雷达-相机标定|Weiduo Yuan, Jerry Li, Justin Yue, Divyank Shah, Konstantinos Karydis, Hang Qiu|<http://arxiv.org/pdf/2506.02587v1>|提出BEVCALIB模型，利用鸟瞰图特征实现激光雷达-摄像头校准，显著提升校准精度。|
|🆕 发布|Towards In-the-wild 3D Plane Reconstruction from a Single Image|从单张图像中实现野外3D平面重建|Jiachen Liu, Rui Yu, Sili Chen, Sharon X. Huang, Hengkai Guo|<http://arxiv.org/pdf/2506.02493v1>|[代码](https://github.com/jcliu0428/ZeroPlane.); 提出ZeroPlane框架，实现跨域单图3D平面检测与重建。|
|🆕 发布|Approximate Borderline Sampling using Granular-Ball for Classification Tasks|基于粒度球体的近似边界线采样在分类任务中的应用|Qin Xie, Qinghua Zhang, Shuyin Xia|<http://arxiv.org/pdf/2506.02366v1>|[代码](https://github.com/CherylTse/GBABS.); 提出了一种基于粒度球近似边界采样的方法，有效提升了分类任务中数据集质量和分类器性能。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LEG-SLAM: Real-Time Language-Enhanced Gaussian Splatting for SLAM|LEGS-LAM：实时语言增强高斯分层SLAM|Roman Titkov, Egor Zubkov, Dmitry Yudin, Jaafar Mahmoud, Malik Mohrat, Gennady Sidorov|<http://arxiv.org/pdf/2506.03073v1>|[代码](https://titrom025.github.io/LEG-SLAM); 提出LEG-SLAM，融合优化高斯分层与语义信息，实现实时语义3D场景重建。|
|📝 更新|A Comparative Study of Scanpath Models in Graph-Based Visualization|基于图可视化的扫描路径模型比较研究|Angela Lopez-Cardona, Parvin Emami, Sebastian Idesis, Saravanakumar Duraisamy, Luis A. Leiva, Ioannis Arapakis|<http://arxiv.org/pdf/2503.24160v3>|比较了多种扫描路径模型在图可视化中的表现，为信息可视化系统设计提供预测模型。|
|🆕 发布|VTGaussian-SLAM: RGBD SLAM for Large Scale Scenes with Splatting View-Tied 3D Gaussians|VTGaussian-SLAM：基于喷溅视图相关3D高斯的大规模场景RGBD SLAM|Pengchong Hu, Zhizhong Han|<http://arxiv.org/pdf/2506.02741v1>|[代码](https://machineperceptionlab.github.io/VTGaussian-SLAM-Project); 提出了一种基于视图关联高斯表示的RGBD SLAM方法，有效提升了大场景处理效率和精度。|
|📝 更新|3D Trajectory Reconstruction of Moving Points Based on Asynchronous Cameras|基于异步相机的移动点3D轨迹重建|Huayu Huang, Banglei Guan, Yang Shang, Qifeng Yu|<http://arxiv.org/pdf/2506.00541v2>|提出了一种基于异步相机同步的3D轨迹重建方法，有效解决了运动点目标定位问题。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VolTex: Food Volume Estimation using Text-Guided Segmentation and Neural Surface Reconstruction|VolTex：基于文本引导分割和神经表面重建的食品体积估计|Ahmad AlMughrabi, Umair Haroon, Ricardo Marques, Petia Radeva|<http://arxiv.org/pdf/2506.02895v1>|[代码](https://github.com/GCVCG/VolTex.); VolTex通过文本引导分割和神经表面重建，实现特定食物体积的精确估计。|
|📝 更新|MoBluRF: Motion Deblurring Neural Radiance Fields for Blurry Monocular Video|MoBluRF：用于模糊单目视频的运动去模糊神经辐射场|Minh-Quan Viet Bui, Jongmin Park, Jihyong Oh, Munchurl Kim|<http://arxiv.org/pdf/2312.13528v3>|MoBluRF通过运动去模糊NeRF框架，有效解决了模糊单目视频中的运动模糊问题。|
|🆕 发布|Enhancing Monocular Height Estimation via Weak Supervision from Imperfect Labels|通过不完美标签的弱监督增强单目高度估计|Sining Chen, Yilei Shi, Xiao Xiang Zhu|<http://arxiv.org/pdf/2506.02534v1>|[代码](https://github.com/zhu-xlab/weakim2h.); 提出一种利用弱监督从标签不完美数据中增强单目高度估计的方法，显著提升模型泛化能力。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|METok: Multi-Stage Event-based Token Compression for Efficient Long Video Understanding|METok：基于多阶段事件驱动的长视频理解高效标记压缩|Mengyue Wang, Shuo Chen, Kristian Kersting, Volker Tresp, Yunpu Ma|<http://arxiv.org/pdf/2506.02850v1>|METok通过多阶段事件驱动压缩，有效降低长视频理解模型的计算需求，同时保持高精度。|
|🆕 发布|MemoryOut: Learning Principal Features via Multimodal Sparse Filtering Network for Semi-supervised Video Anomaly Detection|MemoryOut：通过多模态稀疏滤波网络学习主特征以实现半监督视频异常检测|Juntong Li, Lingwei Dang, Yukun Su, Yun Hao, Qingxin Xiao, Yongwei Nie, Qingyao Wu|<http://arxiv.org/pdf/2506.02535v1>|[代码](https://qzfm.github.io/sfn_vad_project_page); 提出了一种结合多模态联合建模和稀疏特征过滤的半监督视频异常检测框架，有效识别异常事件。|
|📝 更新|Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video|普瑞玛：用于视觉和视频机制可解释性的开源工具包|Sonia Joseph, Praneet Suresh, Lorenz Hufe, Edward Stevinson, Robert Graham, Yash Vadi, Danilo Bzdok, Sebastian Lapuschkin .etc.|<http://arxiv.org/pdf/2504.19475v3>|[代码](https://github.com/Prisma-Multimodal/ViT-Prisma); 开发开源工具包Prisma，加速视觉机制可解释性研究，降低该领域入门门槛。|
|🆕 发布|VidEvent: A Large Dataset for Understanding Dynamic Evolution of Events in Videos|视频事件：理解视频中事件动态演化的大型数据集|Baoyu Liang, Qile Su, Shoutai Zhu, Yuchen Liang, Chao Tong|<http://arxiv.org/pdf/2506.02448v1>|构建了大规模视频事件理解数据集VidEvent，推动视频事件理解研究。|
|📝 更新|StimuVAR: Spatiotemporal Stimuli-aware Video Affective Reasoning with Multimodal Large Language Models|StimuVAR：基于多模态大型语言模型的时空刺激感知视频情感推理|Yuxiang Guo, Faizan Siddiqui, Yang Zhao, Rama Chellappa, Shao-Yuan Lo|<http://arxiv.org/pdf/2409.00304v2>|[代码](https://github.com/EthanG97/StimuVAR); StimuVAR通过引入时空刺激感知机制，显著提升了多模态大语言模型在视频情感推理方面的准确性和解释...|
|📝 更新|SignMusketeers: An Efficient Multi-Stream Approach for Sign Language Translation at Scale|SignMusketeers：大规模手语翻译的高效多流方法|Shester Gueuwou, Xiaodan Du, Greg Shakhnarovich, Karen Livescu|<http://arxiv.org/pdf/2406.06907v2>|SignMusketeers通过聚焦于手语视频中的关键部分，并采用自监督学习，实现了高效且节省计算的...|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Automated Measurement of Optic Nerve Sheath Diameter Using Ocular Ultrasound Video|眼超声视频自动测量视神经鞘直径|Renxing Li, Weiyi Tang, Peiqi Li, Qiming Huang, Jiayuan She, Shengkai Li, Haoran Xu, Yeyun Wan .etc.|<http://arxiv.org/pdf/2506.02789v1>|开发了一种基于KCF和SLIC算法的自动测量视神经鞘直径的新方法，显著提高了测量准确性。|
|🆕 发布|High Performance Space Debris Tracking in Complex Skylight Backgrounds with a Large-Scale Dataset|高性能复杂天空背景下的空间碎片跟踪：大规模数据集研究|Guohang Zhuang, Weixi Song, Jinyang Huang, Chenwei Yang, Yan Lu|<http://arxiv.org/pdf/2506.02614v1>|提出SDT-Net模型，结合大规模数据集，实现复杂背景下的高效空间碎片追踪。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025|2025年Ego4D长期动作预测挑战赛技术报告|Qiaohui Chu, Haoyu Zhang, Yisen Feng, Meng Liu, Weili Guan, Yaowei Wang, Liqiang Nie|<http://arxiv.org/pdf/2506.02550v1>|[代码](https://github.com/CorrineQiu/Ego4D-LTA-Challenge-2025.); 提出了一种三阶段框架，通过视觉编码器、Transformer和LLM实现长时动作预测，在Ego4D挑...|
|🆕 发布|Multi-level and Multi-modal Action Anticipation|多层次多模态动作预测|Seulgi Kim, Ghazal Kaviani, Mohit Prabhushankar, Ghassan AlRegib|<http://arxiv.org/pdf/2506.02382v1>|[代码](https://github.com/olivesgatech/mM-ant.); 提出了一种结合视觉和文本信息，并建模语义层次的多模态动作预测方法，显著提升了动作预测的准确性。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Uneven Event Modeling for Partially Relevant Video Retrieval|不均匀事件建模用于部分相关视频检索|Sa Zhu, Huashan Chen, Wanqian Zhang, Jinchao Zhang, Zexian Yang, Xiaoshuai Hao, Bo Li|<http://arxiv.org/pdf/2506.00891v2>|[代码](https://github.com/Sasa77777779/UEM.git.); 提出了一种基于动态事件建模的视频检索方法，有效提升了文本与视频片段的匹配精度。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FORLA:Federated Object-centric Representation Learning with Slot Attention|FORLA：基于槽位注意力的联邦以对象为中心的表示学习|Guiqiu Liao, Matjaz Jogan, Eric Eaton, Daniel A. Hashimoto|<http://arxiv.org/pdf/2506.02964v1>|提出了一种基于槽位注意力的联邦学习框架，有效学习跨域视觉表示。|
|🆕 发布|Self-Disentanglement and Re-Composition for Cross-Domain Few-Shot Segmentation|自解耦与跨域小样本分割的重构|Jintao Tong, Yixiong Zou, Guangyao Chen, Yuhua Li, Ruixuan Li|<http://arxiv.org/pdf/2506.02677v1>|提出了一种解决跨域小样本分割中特征纠缠问题的方法，通过学习加权比较以实现特征解耦和重组，显著提升了分...|
|📝 更新|PointCloud-Text Matching: Benchmark Datasets and a Baseline|点云-文本匹配：基准数据集和基线|Yanglin Feng, Yang Qin, Dezhong Peng, Hongyuan Zhu, Xi Peng, Peng Hu|<http://arxiv.org/pdf/2403.19386v3>|提出了一种解决点云与文本匹配问题的Robust PointCloud-Text Matching方法...|
|🆕 发布|Contrast & Compress: Learning Lightweight Embeddings for Short Trajectories|对比与压缩：学习用于短轨迹的轻量级嵌入|Abhishek Vivekanandan, Christian Hubschneider, J. Marius Zöllner|<http://arxiv.org/pdf/2506.02571v1>|提出了一种基于对比学习的轻量级轨迹嵌入方法，有效提升了检索效率和准确性。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DyTact: Capturing Dynamic Contacts in Hand-Object Manipulation|动态触觉：捕捉手-物体操作中的动态接触|Xiaoyan Cong, Angela Xing, Chandradeep Pokhariya, Rao Fu, Srinath Sridhar|<http://arxiv.org/pdf/2506.03103v1>|[代码](https://oliver-cong02.github.io/DyTact.github.io); 提出了一种无标记捕捉手-物体动态接触的方法，显著提升了接触估计精度和新型视图合成质量。|
|📝 更新|We Should Chart an Atlas of All the World's Models|我们应该绘制出全世界所有模型的图谱|Eliahu Horwitz, Nitzan Kurer, Jonathan Kahana, Liel Amar, Yedid Hoshen|<http://arxiv.org/pdf/2503.10633v2>|倡导构建全球模型图谱，通过分析模型权重推断属性，解决模型库无序问题。|
|🆕 发布|PhysGaia: A Physics-Aware Dataset of Multi-Body Interactions for Dynamic Novel View Synthesis|PhysGaia：用于动态新视角合成的多体交互物理感知数据集|Mijeong Kim, Gunhee Kim, Jungyoon Choi, Wonjae Roh, Bohyung Han|<http://arxiv.org/pdf/2506.02794v1>|PhysGaia构建了一个包含物理现象的动态场景数据集，支持物理感知动态场景建模。|
|🆕 发布|RobustSplat: Decoupling Densification and Dynamics for Transient-Free 3DGS|RobustSplat：解耦密化和动态以实现无瞬态3DGS|Chuanyu Fu, Yuqi Zhang, Kunbin Yao, Guanying Chen, Yuan Xiong, Chuan Huang, Shuguang Cui, Xiaochun Cao|<http://arxiv.org/pdf/2506.02751v1>|[代码](https://fcyycf.github.io/RobustSplat); 提出RobustSplat方法，通过延迟高斯增长和级联掩码引导，有效解决3DGS中瞬态物体建模问题。|
|🆕 发布|Small Aid, Big Leap: Efficient Test-Time Adaptation for Vision-Language Models with AdaptNet|小助大跃：基于AdaptNet的视觉-语言模型高效测试时自适应|Xiao Chen, Jiazhen Huang, Qinting Jiang, Fanding Huang, Xianghua Fu, Jingyan Jiang, Zhi Wang|<http://arxiv.org/pdf/2506.02671v1>|提出了一种轻量级框架SAIL，通过高效的自适应网络降低视觉语言模型测试时适应的计算成本。|
|🆕 发布|PAID: Pairwise Angular-Invariant Decomposition for Continual Test-Time Adaptation|PAID：用于持续测试时自适应的成对角度不变分解|Kunyu Wang, Xueyang Fu, Yunfei Bao, Chengjie Ge, Chengzhi Cao, Wei Zhai, Zheng-Jun Zha|<http://arxiv.org/pdf/2506.02453v1>|提出PAID方法，通过保留预训练模型中的成对角度结构，实现持续测试时自适应，有效提升模型适应变化环境...|
|📝 更新|Point Cloud Mixture-of-Domain-Experts Model for 3D Self-supervised Learning|点云域专家混合模型用于3D自监督学习|Yaohua Zha, Tao Dai, Hang Guo, Yanzi Wang, Bin Chen, Ke Chen, Shu-Tao Xia|<http://arxiv.org/pdf/2410.09886v3>|提出了一种融合场景和对象领域知识的点云自监督学习模型，提升3D表示的全面性。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DPO Learning with LLMs-Judge Signal for Computer Use Agents|基于LLMs的DPO学习——用于计算机使用代理的判断信号|Man Luo, David Cobbley, Xin Su, Shachar Rosenman, Vasudev Lal, Shao-Yen Tseng, Phillip Howard|<http://arxiv.org/pdf/2506.03095v1>|开发轻量级视觉语言模型，通过LLM作为裁判筛选数据，实现隐私保护和资源高效的计算机使用代理。|
|🆕 发布|SurgVLM: A Large Vision-Language Model and Systematic Evaluation Benchmark for Surgical Intelligence|手术视觉语言模型：用于手术智能的大规模视觉语言模型和系统评估基准|Zhitao Zeng, Zhu Zhuo, Xiaojun Jia, Erli Zhang, Junde Wu, Jiaan Zhang, Yuxuan Wang, Chang Han Low .etc.|<http://arxiv.org/pdf/2506.02555v1>|构建了首个大型视觉语言模型SurgVLM，并建立手术智能评估基准，解决手术领域视觉语言理解难题。|
|📝 更新|Efficient RAW Image Deblurring with Adaptive Frequency Modulation|高效自适应频率调制下的RAW图像去模糊|Wenlong Jiao, Binglong Li, Wei Shang, Ping Wang, Dongwei Ren|<http://arxiv.org/pdf/2505.24407v2>|[代码](https://github.com/WenlongJiao/FrENet); 提出了一种基于频率域的RAW图像去模糊方法，显著提升了去模糊效果和效率。|
|🆕 发布|EyeNavGS: A 6-DoF Navigation Dataset and Record-n-Replay Software for Real-World 3DGS Scenes in VR|EyeNavGS：一个用于VR中真实世界3DGS场景的6自由度导航数据集和记录-回放软件|Zihao Ding, Cheng-Tse Lee, Mufeng Zhu, Tao Guan, Yuan-Chun Sun, Cheng-Hsin Hsu, Yao Liu|<http://arxiv.org/pdf/2506.02380v1>|[代码](https://symmru.github.io/EyeNavGS); 构建了首个6自由度导航数据集，并开发了记录-回放软件，以促进3DGS场景在VR中的研究。|
|🆕 发布|DIAMOND: An LLM-Driven Agent for Context-Aware Baseball Highlight Summarization|DIAMOND：一个基于LLM的上下文感知棒球精彩集锦摘要代理|Jeonghun Kang, Soonmok Kwon, Joonseok Lee, Byung-Hak Kim|<http://arxiv.org/pdf/2506.02351v1>|DIAMOND通过结合结构化体育分析和自然语言推理，实现了基于上下文的棒球精彩瞬间自动总结，显著提升...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Explicitly Modeling Subcortical Vision with a Neuro-Inspired Front-End Improves CNN Robustness|利用神经启发前端显式建模皮层下视觉以提高CNN鲁棒性|Lucas Piper, Arlindo L. Oliveira, Tiago Marques|<http://arxiv.org/pdf/2506.03089v1>|通过结合模拟大脑视觉皮层的VOneBlock和SubcorticalBlock，显著提升了CNN对视...|
|🆕 发布|Smartflow: Enabling Scalable Spatiotemporal Geospatial Research|智能流：实现可扩展的时空地理空间研究|David McVicar, Brian Avant, Adrian Gould, Diego Torrejon, Charles Della Porta, Ryan Mukherjee|<http://arxiv.org/pdf/2506.03022v1>|Smartflow通过云平台和开源工具，实现大规模时空地理空间数据分析和模型训练，并创新性地应用于大...|
|📝 更新|Scene Structure Guidance Network: Unfolding Graph Partitioning into Pixel-Wise Feature Learning|场景结构引导网络：将图划分展开为像素级特征学习|Jisu Shin, Seunghyun Shin, Hae-Gon Jeon|<http://arxiv.org/pdf/2301.00555v2>|提出了一种将图划分展开为像素级特征学习的场景结构引导网络，显著提升了低级视觉任务性能。|
|🆕 发布|OpenFace 3.0: A Lightweight Multitask System for Comprehensive Facial Behavior Analysis|OpenFace 3.0：一种轻量级多任务系统，用于全面的面部行为分析|Jiewen Hu, Leena Mathur, Paul Pu Liang, Louis-Philippe Morency|<http://arxiv.org/pdf/2506.02891v1>|OpenFace 3.0提出了一种轻量级多任务模型，实现实时面部行为分析。|
|📝 更新|TestDG: Test-time Domain Generalization for Continual Test-time Adaptation|测试域泛化：持续测试时自适应的测试时域泛化|Sohyun Lee, Nayeong Kim, Juwon Kang, Seong Joon Oh, Suha Kwak|<http://arxiv.org/pdf/2504.04981v2>|提出TestDG框架，通过学习域不变特征实现持续测试时域泛化，提升模型对未来测试域的泛化能力。|
|🆕 发布|FaceSleuth: Learning-Driven Single-Orientation Attention Verifies Vertical Dominance in Micro-Expression Recognition|FaceSleuth：学习驱动的单方向注意力验证微表情识别中的垂直主导性|Linquan Wu, Tianxiang Jiang, Wenhao Duan, Yini Fang, Jacky Keung|<http://arxiv.org/pdf/2506.02695v1>|FaceSleuth通过引入垂直注意力机制，显著提升了微表情识别的准确率。|
|🆕 发布|Rodrigues Network for Learning Robot Actions|罗德里格斯网络学习机器人动作|Jialiang Zhang, Haoran Geng, Yang You, Congyue Deng, Pieter Abbeel, Jitendra Malik, Leonidas Guibas|<http://arxiv.org/pdf/2506.02618v1>|提出Rodrigues网络，通过引入结构化运动学先验，显著提升机器人动作学习效果。|
|🆕 发布|Application of convolutional neural networks in image super-resolution|卷积神经网络在图像超分辨率中的应用|Tian Chunwei, Song Mingjian, Zuo Wangmeng, Du Bo, Zhang Yanning, Zhang Shichao|<http://arxiv.org/pdf/2506.02604v1>|总结了不同CNN图像超分辨率方法的原理、差异及性能，为CNN在图像超分辨率中的应用提供了参考。|
|🆕 发布|A Tree-guided CNN for image super-resolution|基于树引导的卷积神经网络进行图像超分辨率|Chunwei Tian, Mingjian Song, Xiaopeng Fan, Xiangtao Zheng, Bob Zhang, David Zhang|<http://arxiv.org/pdf/2506.02585v1>|[代码](https://github.com/hellloxiaotian/TSRNet.); 设计了一种树状结构的CNN，通过引导关键节点增强层次信息关系，有效提升了图像超分辨率性能。|
|🆕 发布|HIEGNet: A Heterogenous Graph Neural Network Including the Immune Environment in Glomeruli Classification|HIEGNet：一种包含肾小球免疫环境的异构图神经网络|Niklas Kormann, Masoud Ramuz, Zeeshan Nisar, Nadine S. Schaadt, Hendrik Annuth, Benjamin Doerr, Friedrich Feuerhake, Thomas Lampert .etc.|<http://arxiv.org/pdf/2506.02542v1>|[代码](https://github.com/nklsKrmnn/HIEGNet.git.); 提出HIEGNet，一种结合免疫环境的异构图神经网络，有效提升了肾小球健康分类的准确性。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhancing Abnormality Identification: Robust Out-of-Distribution Strategies for Deepfake Detection|提升异常识别：针对深度伪造检测的鲁棒异常分布策略|Luca Maiano, Fabrizio Casadei, Irene Amerini|<http://arxiv.org/pdf/2506.02857v1>|提出两种新型异常检测方法，有效提升深度伪造检测的鲁棒性和适应性。|
|📝 更新|Bayesian Prompt Flow Learning for Zero-Shot Anomaly Detection|贝叶斯提示流学习用于零样本异常检测|Zhen Qu, Xian Tao, Xinyi Gong, Shichen Qu, Qiyu Chen, Zhengtao Zhang, Xingang Wang, Guiguang Ding|<http://arxiv.org/pdf/2503.10080v3>|[代码](https://github.com/xiaozhen228/Bayes-PFL.); 提出Bayes-PFL，通过贝叶斯方法学习提示空间分布，提升零样本异常检测泛化能力。|
|📝 更新|Spatio-Temporal Fuzzy-oriented Multi-Modal Meta-Learning for Fine-grained Emotion Recognition|时空模糊导向的多模态元学习用于细粒度情感识别|Jingyao Wang, Wenwen Qiang, Changwen Zheng, Fuchun Sun|<http://arxiv.org/pdf/2412.13541v4>|提出了一种融合时空模糊多模态元学习的细粒度情感识别框架，有效解决了情感识别中的数据依赖、时序异质性和...|
|🆕 发布|Rethinking Post-Unlearning Behavior of Large Vision-Language Models|重新思考大型视觉-语言模型的后学习行为|Minsung Kim, Nakyeong Yang, Kyomin Jung|<http://arxiv.org/pdf/2506.02541v1>|提出了一种新方法PUBG，有效缓解了大型视觉语言模型隐私解学习后的不良行为。|
|🆕 发布|Generalized Category Discovery via Reciprocal Learning and Class-Wise Distribution Regularization|基于互学习和类间分布正则化的泛化类别发现|Duo Liu, Zhiquan Tan, Linglan Zhao, Zhongqiang Zhang, Xiangzhong Fang, Weiran Huang|<http://arxiv.org/pdf/2506.02334v1>|[代码](https://github.com/APORduo/RLCD.); 提出了一种结合互学习和类别分布正则化的泛化类别发现方法，有效提升基础和新型类别识别性能。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Open-world Machine Learning: A Systematic Review and Future Directions|开放世界机器学习：系统综述与未来方向|Fei Zhu, Shijie Ma, Zhen Cheng, Xu-Yao Zhang, Zhaoxiang Zhang, Dacheng Tao, Cheng-Lin Liu|<http://arxiv.org/pdf/2403.01759v3>|提出开放世界机器学习新范式，通过未知拒绝、新颖性发现和持续学习提升AI系统能力。|
|🆕 发布|Deep Learning for Retinal Degeneration Assessment: A Comprehensive Analysis of the MARIO AMD Progression Challenge|深度学习在视网膜退行性疾病评估中的应用：MARIO AMD 进展挑战的全面分析|Rachid Zeghlache, Ikram Brahim, Pierre-Henri Conze, Mathieu Lamard, Mohammed El Amine Lazouni, Zineb Aziza Elaouaber, Leila Ryma Lazouni, Christopher Nielsen .etc.|<http://arxiv.org/pdf/2506.02976v1>|该论文通过分析OCT图像，提出了一种基于深度学习的AMD评估方法，在监测AMD进展方面达到与医生相当...|
|📝 更新|LLM-Guided Taxonomy and Hierarchical Uncertainty for 3D Point Cloud Active Learning|基于LLM引导的3D点云主动学习分类与层次不确定性|Chenxi Li, Nuo Chen, Fengyun Tan, Yantong Chen, Bochun Yuan, Tianrui Li, Chongshou Li|<http://arxiv.org/pdf/2505.18924v2>|首次将大型语言模型应用于3D点云语义分割，构建层次化标签结构并指导基于不确定性的样本选择，显著提升标...|
|🆕 发布|FlySearch: Exploring how vision-language models explore|飞搜：探索视觉-语言模型如何探索|Adam Pardyl, Dominik Matuszek, Mateusz Przebieracz, Marek Cygan, Bartosz Zieliński, Maciej Wołczyk|<http://arxiv.org/pdf/2506.02896v1>|FlySearch通过构建复杂场景搜索和导航基准，揭示了视觉语言模型在探索性任务中的局限性。|
|🆕 发布|Random Registers for Cross-Domain Few-Shot Learning|随机寄存器用于跨域小样本学习|Shuai Yi, Yixiong Zou, Yuhua Li, Ruixuan Li|<http://arxiv.org/pdf/2506.02843v1>|[代码](https://github.com/shuaiyi308/REAP.); 提出随机寄存器方法，有效提升跨域小样本学习性能。|
|📝 更新|Learning from True-False Labels via Multi-modal Prompt Retrieving|通过多模态提示检索学习真伪标签|Zhongnian Li, Jinghao Xu, Peng Ying, Meng Wei, Xinzheng Xu|<http://arxiv.org/pdf/2405.15228v2>|[代码](https://github.com/Tranquilxu/TMP.); 提出True-False标签和基于卷积的多模态提示检索方法，提升弱监督学习在计算机视觉任务中的准确性...|
|📝 更新|Hierarchical Relational Learning for Few-Shot Knowledge Graph Completion|基于层次关系学习的少样本知识图谱补全|Han Wu, Jie Yin, Bala Rajaratnam, Jianyuan Guo|<http://arxiv.org/pdf/2209.01205v4>|[代码](https://github.com/alexhw15/HiRe.git.); 提出了一种层次关系学习方法，有效学习并优化少量样本下的知识图谱三元组补全。|
|🆕 发布|Probabilistic Online Event Downsampling|概率在线事件降采样|Andreu Girbau-Xalabarder, Jun Nagata, Shinichi Sumiyoshi|<http://arxiv.org/pdf/2506.02547v1>|提出了一种基于概率框架的在线事件降采样方法，有效降低带宽和计算需求。|
|🆕 发布|Revisiting End-to-End Learning with Slide-level Supervision in Computational Pathology|重新审视计算病理学中的滑动级监督的端到端学习|Wenhao Tang, Rong Qin, Heng Fang, Fengtao Zhou, Hao Chen, Xiang Li, Ming-Ming Cheng|<http://arxiv.org/pdf/2506.02408v1>|[代码](https://github.com/DearCaat/E2E-WSI-ABMILX.); 提出ABMILX方法，通过全局关联注意力优化和多头机制，提升计算病理学中端到端学习的性能。|
|📝 更新|SHuBERT: Self-Supervised Sign Language Representation Learning via Multi-Stream Cluster Prediction|SHuBERT：通过多流聚类预测进行自监督手语表征学习|Shester Gueuwou, Xiaodan Du, Greg Shakhnarovich, Karen Livescu, Alexander H. Liu|<http://arxiv.org/pdf/2411.16765v2>|SHuBERT通过多流聚类预测，实现了自监督手语表征学习，提升了手语翻译和识别等任务性能。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GUI-Actor: Coordinate-Free Visual Grounding for GUI Agents|GUI-Actor：GUI代理的无坐标视觉定位|Qianhui Wu, Kanzhi Cheng, Rui Yang, Chaoyun Zhang, Jianwei Yang, Huiqiang Jiang, Jian Mu, Baolin Peng .etc.|<http://arxiv.org/pdf/2506.03143v1>|GUI-Actor通过引入注意力机制和验证器，实现了无需坐标的GUI视觉定位，显著提升了GUI动作执...|
|📝 更新|Can't See the Forest for the Trees: Benchmarking Multimodal Safety Awareness for Multimodal LLMs|看不清森林中的树木：多模态LLMs多模态安全意识基准测试|Wenxuan Wang, Xiaoyuan Liu, Kuiyi Gao, Jen-tse Huang, Youliang Yuan, Pinjia He, Shuai Wang, Zhaopeng Tu|<http://arxiv.org/pdf/2502.11184v2>|构建首个多模态安全意识基准MMSafeAware，评估多模态LLMs在29个安全场景下的安全意识能力...|
|🆕 发布|SemVink: Advancing VLMs' Semantic Understanding of Optical Illusions via Visual Global Thinking|SemVink：通过视觉全局思维提升VLMs对光学错觉的语义理解|Sifan Li, Yujun Cai, Yiwei Wang|<http://arxiv.org/pdf/2506.02803v1>|通过降低图像分辨率，SemVink显著提升了视觉语言模型对光学错觉的语义理解能力。|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EgoVLM: Policy Optimization for Egocentric Video Understanding|自我视角视频理解中的策略优化：EgoVLM|Ashwin Vinod, Shrey Pandit, Aditya Vavre, Linshen Liu|<http://arxiv.org/pdf/2506.03097v1>|EgoVLM通过强化学习优化，显著提升了基于第一人称视频的理解能力。|
|🆕 发布|MVTD: A Benchmark Dataset for Maritime Visual Object Tracking|MVTD：海洋视觉目标跟踪基准数据集|Ahsan Baidar Bakht, Muhayy Ud Din, Sajid Javed, Irfan Hussain|<http://arxiv.org/pdf/2506.02866v1>|[代码](https://github.com/AhsanBaidar/MVTD); 构建了针对海事视觉跟踪的基准数据集，显著提升了相关算法在复杂环境下的性能。|
|🆕 发布|Go Beyond Earth: Understanding Human Actions and Scenes in Microgravity Environments|超越地球：理解微重力环境中的人类动作与场景|Di Wen, Lei Qi, Kunyu Peng, Kailun Yang, Fei Teng, Ao Luo, Jia Fu, Yufan Chen .etc.|<http://arxiv.org/pdf/2506.02845v1>|[代码](https://github.com/LEI-QI-233/HAR-in-Space.); 构建首个微重力环境下的动作和场景理解基准MicroG-4M，推动空间应用中的视频理解。|
|🆕 发布|Unified Attention Modeling for Efficient Free-Viewing and Visual Search via Shared Representations|统一注意力建模：通过共享表示实现高效自由观看和视觉搜索|Fatma Youssef Mohammed, Kostas Alexis|<http://arxiv.org/pdf/2506.02764v1>|提出一种基于共享表示的统一注意力模型，有效降低自由观看和视觉搜索的计算成本。|
|📝 更新|InfoChartQA: A Benchmark for Multimodal Question Answering on Infographic Charts|信息图表问答基准：信息图表上的多模态问答基准|Minzhi Lin, Tianchi Xie, Mengchen Liu, Yilin Ye, Changjian Chen, Shixia Liu|<http://arxiv.org/pdf/2505.19028v3>|[代码](https://github.com/CoolDawnAnt/InfoChartQA.); 构建了InfoChartQA基准，评估多模态大语言模型在理解信息图表方面的能力。|
|📝 更新|VR-Robo: A Real-to-Sim-to-Real Framework for Visual Robot Navigation and Locomotion|VR-Robo：一种真实到模拟再到真实视觉机器人导航与运动框架|Shaoting Zhu, Linzhan Mou, Derun Li, Baijun Ye, Runhan Huang, Hang Zhao|<http://arxiv.org/pdf/2502.01536v3>|提出VR-Robo框架，通过生成逼真模拟环境，解决视觉机器人导航和运动中的真实-模拟-真实差距问题。|
|📝 更新|VRAG-RL: Empower Vision-Perception-Based RAG for Visually Rich Information Understanding via Iterative Reasoning with Reinforcement Learning|VRAG-RL：通过强化学习迭代推理赋能基于视觉感知的RAG以理解视觉丰富信息|Qiuchen Wang, Ruixue Ding, Yu Zeng, Zehui Chen, Lin Chen, Shihang Wang, Pengjun Xie, Fei Huang .etc.|<http://arxiv.org/pdf/2505.22019v2>|[代码](https://github.com/Alibaba-NLP/VRAG.); VRAG-RL通过强化学习赋能视觉信息理解，实现迭代推理以优化视觉丰富信息的检索与理解。|
|📝 更新|NeurIPS 2023 Competition: Privacy Preserving Federated Learning Document VQA|NeurIPS 2023 竞赛：隐私保护联邦学习文档视觉问答|Marlon Tobaben, Mohamed Ali Souibgui, Rubèn Tito, Khanh Nguyen, Raouf Kerkouche, Kangsoo Jung, Joonas Jälkö, Lei Kang .etc.|<http://arxiv.org/pdf/2411.03730v2>|提出了一种在联邦学习环境中保护隐私且高效的文档视觉问答模型，为隐私保护联邦学习挑战提供了最佳实践。|
|📝 更新|On the Expressiveness of Visual Prompt Experts|关于视觉提示专家的表达能力|Minh Le, Anh Nguyen, Huy Nguyen, Chau Nguyen, Anh Tran, Nhat Ho|<http://arxiv.org/pdf/2501.18936v5>|提出了一种增强视觉提示专家表达力的方法，显著提升了视觉提示调优的性能。|
|📝 更新|SparseVLM: Visual Token Sparsification for Efficient Vision-Language Model Inference|稀疏VLM：高效视觉-语言模型推理中的视觉标记稀疏化|Yuan Zhang, Chun-Kai Fan, Junpeng Ma, Wenzhao Zheng, Tao Huang, Kuan Cheng, Denis Gudovskiy, Tomoyuki Okuno .etc.|<http://arxiv.org/pdf/2410.04417v4>|[代码](https://github.com/Gumpest/SparseVLMs.); 提出SparseVLM，通过文本引导无参数优化机制，有效降低视觉语言模型计算量。|
|📝 更新|FIHA: Autonomous Hallucination Evaluation in Vision-Language Models with Davidson Scene Graphs|FIHA：基于Davidson场景图的视觉-语言模型中自主幻觉评估|Bowen Yan, Zhengsong Zhang, Liqiang Jing, Eftekhar Hossain, Xinya Du|<http://arxiv.org/pdf/2409.13612v2>|提出FIHA方法，通过Davidson场景图评估视觉语言模型中的幻觉问题。|
|📝 更新|Mitigating Visual Forgetting via Take-along Visual Conditioning for Multi-modal Long CoT Reasoning|通过携带视觉条件化减轻视觉遗忘，以实现多模态长CoT推理|Hai-Long Sun, Zhun Sun, Houwen Peng, Han-Jia Ye|<http://arxiv.org/pdf/2503.13360v2>|提出TVC策略，通过动态剪枝和关键阶段视觉输入，缓解多模态长CoT推理中的视觉遗忘问题。|
|🆕 发布|RATE-Nav: Region-Aware Termination Enhancement for Zero-shot Object Navigation with Vision-Language Models|区域感知终止增强：基于视觉-语言模型的零样本目标导航|Junjie Li, Nan Zhang, Xiaoyang Qu, Kai Lu, Guokuan Li, Jiguang Wan, Jianzong Wang|<http://arxiv.org/pdf/2506.02354v1>|提出RATE-Nav方法，通过区域感知终止增强，有效提升零样本目标导航的效率。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Zero-Shot Tree Detection and Segmentation from Aerial Forest Imagery|零样本树木检测与分割：基于航空森林影像|Michelle Chen, David Russell, Amritha Pallavoor, Derek Young, Jane Wu|<http://arxiv.org/pdf/2506.03114v1>|[代码](https://github.com/open-forest-observatory/tree-detection-framework.); 利用预训练模型SAM2实现零样本树木检测与分割，提高遥感图像处理效率。|
|📝 更新|Improving Heart Rejection Detection in XPCI Images Using Synthetic Data Augmentation|利用合成数据增强提高XPCI图像中心脏排斥检测的准确性|Jakov Samardžija, Donik Vršnak, Sven Lončarić|<http://arxiv.org/pdf/2505.19746v2>|利用StyleGAN生成合成数据，有效缓解了心脏排斥检测中数据不平衡问题，提升了分类性能。|
|📝 更新|Can Large Language Models Challenge CNNs in Medical Image Analysis?|大型语言模型能否在医学图像分析中挑战卷积神经网络？|Shibbir Ahmed, Shahnewaz Karim Sakib, Anindya Bijoy Das|<http://arxiv.org/pdf/2505.23503v2>|该研究提出了一种多模态AI框架，通过对比CNN和LLM在医学图像分析中的性能，揭示了LLM在诊断准确...|
|📝 更新|T-FAKE: Synthesizing Thermal Images for Facial Landmarking|T-FAKE：用于面部特征定位的热图像合成|Philipp Flotho, Moritz Piening, Anna Kukleva, Gabriele Steidl|<http://arxiv.org/pdf/2408.15127v3>|提出T-FAKE数据集和RGB2Thermal损失函数，显著提升热图像面部特征检测性能。|
|🆕 发布|Hierarchical Self-Prompting SAM: A Prompt-Free Medical Image Segmentation Framework|分层自提示SAM：一种无提示医学图像分割框架|Mengmeng Zhang, Xingyuan Dai, Yicheng Sun, Jing Wang, Yueyang Yao, Xiaoyan Gong, Fuze Cong, Feiyue Wang .etc.|<http://arxiv.org/pdf/2506.02854v1>|提出了一种无需提示的医学图像分割框架，通过引入抽象提示显著提升了分割性能。|
|📝 更新|Likelihood-Scheduled Score-Based Generative Modeling for Fully 3D PET Image Reconstruction|基于似然调度分数的3D PET图像重建生成模型|George Webber, Yuya Mizuno, Oliver D. Howes, Alexander Hammers, Andrew P. King, Andrew J. Reader|<http://arxiv.org/pdf/2412.04339v2>|提出了一种加速3D PET图像重建的方法，通过优化超参数和消除切片不一致性，显著提升了重建速度和图像...|
|📝 更新|MedEBench: Revisiting Text-instructed Image Editing on Medical Domain|MedEBench：重新审视医学领域的文本指令图像编辑|Minghao Liu, Zhitao He, Zhiyuan Fan, Qingyun Wang, Yi R. Fung|<http://arxiv.org/pdf/2506.01921v2>|构建了MedEBench基准，评估医疗图像文本引导编辑，提升临床应用可靠性。|
|🆕 发布|Co-Evidential Fusion with Information Volume for Medical Image Segmentation|基于信息量的共证融合在医学图像分割中的应用|Yuanpeng He, Lijian Li, Tianxiang Zhan, Chi-Man Pun, Wenpin Jiao, Zhi Jin|<http://arxiv.org/pdf/2506.02492v1>|提出了一种融合信息量度的共证证据融合策略，有效利用多源不确定性进行医学图像分割。|
|🆕 发布|Multi-modal brain MRI synthesis based on SwinUNETR|基于SwinUNETR的多模态脑部MRI合成|Haowen Pang, Weiyan Guo, Chuyang Ye|<http://arxiv.org/pdf/2506.02467v1>|利用SwinUNETR合成缺失的脑MRI模态，显著提升图像质量和诊断价值。|
|🆕 发布|Guiding Registration with Emergent Similarity from Pre-Trained Diffusion Models|基于预训练扩散模型的涌现相似性引导配准|Nurislam Tursynbek, Hastings Greer, Basar Demir, Marc Niethammer|<http://arxiv.org/pdf/2506.02419v1>|[代码](https://github.com/uncbiag/dgir); 利用预训练扩散模型特征引导图像配准，提高医学图像对齐准确性。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Pan-Arctic Permafrost Landform and Human-built Infrastructure Feature Detection with Vision Transformers and Location Embeddings|泛北极永久冻土地形和人工基础设施特征检测：基于视觉Transformer和位置嵌入|Amal S. Perera, David Fernandez, Chandi Witharana, Elias Manos, Michael Pimenta, Anna K. Liljedahl, Ingmar Nitze, Yili Yang .etc.|<http://arxiv.org/pdf/2506.02868v1>|利用视觉Transformer和位置嵌入，提高了北极地区特征检测的准确性和泛化能力。|
|🆕 发布|Dynamic mapping from static labels: remote sensing dynamic sample generation with temporal-spectral embedding|动态映射自静态标签：基于时间-光谱嵌入的遥感动态样本生成|Shuai Yuan, Shuang Chen, Tianwu Lin, Jie Wang, Peng Gong|<http://arxiv.org/pdf/2506.02574v1>|利用现有静态标签数据，通过时间-光谱嵌入自动生成动态样本，解决遥感地理制图样本更新问题。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|X-Driver: Explainable Autonomous Driving with Vision-Language Models|X-Driver：基于视觉-语言模型的可解释自动驾驶|Wei Liu, Jiyuan Zhang, Binxiong Zheng, Yufeng Hu, Yingzhan Lin, Zengfeng Zeng|<http://arxiv.org/pdf/2505.05098v2>|X-Driver通过融合视觉和语言模型，提升闭环自动驾驶的感知和决策能力，实现高成功率与可解释性。|
|📝 更新|DiffVLA: Vision-Language Guided Diffusion Planning for Autonomous Driving|差分VLA：视觉-语言引导的自动驾驶扩散规划|Anqing Jiang, Yu Gao, Zhigang Sun, Yiru Wang, Jijun Wang, Jinghao Chai, Qian Cao, Yuweng Heng .etc.|<http://arxiv.org/pdf/2505.19381v4>|DiffVLA通过结合视觉语言模型和稀疏密集扩散策略，有效提升了自动驾驶在复杂场景下的决策性能。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HiLO: High-Level Object Fusion for Autonomous Driving using Transformers|HiLO：基于Transformer的高级目标融合用于自动驾驶|Timo Osterburg, Franz Albers, Christopher Diehl, Rajesh Pushparaj, Torsten Bertram|<http://arxiv.org/pdf/2506.02554v1>|[代码](https://github.com/rst-tu-dortmund/HiLO); 提出HiLO，一种基于Transformer的高级对象融合方法，显著提升自动驾驶环境感知的准确性和鲁...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RoadFormer : Local-Global Feature Fusion for Road Surface Classification in Autonomous Driving|道路前驱器：自动驾驶中道路表面分类的局部-全局特征融合|Tianze Wang, Zhang Zhang, Chao Sun|<http://arxiv.org/pdf/2506.02358v1>|RoadFormer通过融合局部和全局特征，有效提升了自动驾驶中路面分类的准确性。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OmniSpatial: Towards Comprehensive Spatial Reasoning Benchmark for Vision Language Models|全空间：迈向视觉语言模型全面空间推理基准|Mengdi Jia, Zekun Qi, Shaochen Zhang, Wenyao Zhang, Xinqiang Yu, Jiawei He, He Wang, Li Yi|<http://arxiv.org/pdf/2506.03135v1>|构建了OmniSpatial基准，全面评估视觉语言模型的空间推理能力。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Mobile-Agent-V: A Video-Guided Approach for Effortless and Efficient Operational Knowledge Injection in Mobile Automation|移动代理-V：一种轻松高效的移动自动化操作知识注入的视频引导方法|Junyang Wang, Haiyang Xu, Xi Zhang, Ming Yan, Ji Zhang, Fei Huang, Jitao Sang|<http://arxiv.org/pdf/2502.17110v3>|Mobile-Agent-V通过视频引导，高效地将操作知识注入移动自动化，显著提升性能。|

