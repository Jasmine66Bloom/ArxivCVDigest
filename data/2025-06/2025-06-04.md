## [UPDATED!] **2025-06-04** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Struct2D: A Perception-Guided Framework for Spatial Reasoning in Large Multimodal Models|结构2D：大型多模态模型中空间推理的感知引导框架|Fangrui Zhu, Hanhui Wang, Yiming Xie, Jing Gu, Tianye Ding, Jianwei Yang, Huaizu Jiang|<http://arxiv.org/pdf/2506.04220v1>|Struct2D通过结合2D图像和元数据，使大型多模态模型具备强大的空间推理能力。|
|🆕 发布|MMR-V: What's Left Unsaid? A Benchmark for Multimodal Deep Reasoning in Videos|MMR-V：还有什么未言说？视频多模态深度推理基准|Kejian Zhu, Zhuoran Jin, Hongbang Yuan, Jiachun Li, Shangqing Tu, Pengfei Cao, Yubo Chen, Kang Liu .etc.|<http://arxiv.org/pdf/2506.04141v1>|提出MMR-V基准，解决视频多模态深度推理难题，推动模型理解能力提升。|
|📝 更新|MM-IQ: Benchmarking Human-Like Abstraction and Reasoning in Multimodal Models|MM-IQ：多模态模型中人类似抽象和推理的基准测试|Huanqia Cai, Yijun Yang, Winston Hu|<http://arxiv.org/pdf/2502.00698v2>|提出MM-IQ评估框架，揭示多模态模型在抽象推理上的局限性，并发布一个高效的多模态推理模型。|
|🆕 发布|Multimodal Tabular Reasoning with Privileged Structured Information|多模态表格推理与特权结构化信息|Jun-Peng Jiang, Yu Xia, Hai-Long Sun, Shiyin Lu, Qing-Guo Chen, Weihua Luo, Kaifu Zhang, De-Chuan Zhan .etc.|<http://arxiv.org/pdf/2506.04088v1>|提出了一种从表格图像进行推理的新框架，利用结构化信息增强多模态大语言模型，显著提升表格推理能力。|
|🆕 发布|Seeing What Tastes Good: Revisiting Multimodal Distributional Semantics in the Billion Parameter Era|看见美味：在百亿参数时代重新审视多模态分布语义|Dan Oneata, Desmond Elliott, Stella Frank|<http://arxiv.org/pdf/2506.03994v1>|探究大规模模型如何表征具体物体概念的语义特征，发现多模态图像编码器略优于仅语言模型。|
|🆕 发布|MS-YOLO: A Multi-Scale Model for Accurate and Efficient Blood Cell Detection|MS-YOLO：一种用于准确高效血细胞检测的多尺度模型|Guohua Wu, Shengqi Chen, Pengchao Deng, Wenting Yu|<http://arxiv.org/pdf/2506.03972v1>|提出MS-YOLO模型，有效解决血细胞检测中重叠和多尺度目标识别难题，实现高精度和实时检测。|
|📝 更新|Open-PMC-18M: A High-Fidelity Large Scale Medical Dataset for Multimodal Representation Learning|开放-PMC-18M：一个用于多模态表示学习的高保真大规模医学数据集|Negin Baghbanzadeh, Sajad Ashkezari, Elham Dolatabadi, Arash Afkanpour|<http://arxiv.org/pdf/2506.02738v2>|构建大规模医学数据集，通过子图提取提升视觉语言模型的表现。|
|📝 更新|SemEval-2025 Task 1: AdMIRe -- Advancing Multimodal Idiomaticity Representation|SemEval-2025 任务 1：AdMIRe -- 推进多模态习语表示|Thomas Pickard, Aline Villavicencio, Maggie Mi, Wei He, Dylan Phelps, Marco Idiart|<http://arxiv.org/pdf/2503.15358v3>|提出AdMiRe任务，挑战模型在多模态和多语言环境下理解习语表达的能力。|
|📝 更新|Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces|逃离柏拉图洞穴：迈向3D与文本潜在空间的对齐|Souhail Hadgi, Luca Moschella, Andrea Santilli, Diego Gomez, Qixing Huang, Emanuele Rodolà, Simone Melzi, Maks Ovsjanikov|<http://arxiv.org/pdf/2503.05283v2>|[代码](https://github.com/Souhail-01/3d-text-alignment); 首次提出后训练对齐3D和文本特征空间的方法，显著提升匹配和检索任务准确性。|
|📝 更新|MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale|MAmmoTH-VL：通过大规模指令调整激发多模态推理|Jarvis Guo, Tuney Zheng, Yuelin Bai, Bo Li, Yubo Wang, King Zhu, Yizhi Li, Graham Neubig .etc.|<http://arxiv.org/pdf/2412.05237v2>|构建大规模多模态指令微调数据集，提升大语言模型推理能力。|
|📝 更新|EscapeCraft: A 3D Room Escape Environment for Benchmarking Complex Multimodal Reasoning Ability|逃离工艺：一个用于基准测试复杂多模态推理能力的3D房间逃脱环境|Ziyue Wang, Yurui Dong, Fuwen Luo, Minyuan Ruan, Zhili Cheng, Chi Chen, Peng Li, Yang Liu|<http://arxiv.org/pdf/2503.10042v4>|构建了EscapeCraft环境，以评估和揭示多模态大语言模型在复杂推理任务中的行为和局限性。|
|📝 更新|MDPE: A Multimodal Deception Dataset with Personality and Emotional Characteristics|多模态欺骗数据集：包含个性和情感特征的MDPE|Cong Cai, Shan Liang, Xuefei Liu, Kang Zhu, Zhengqi Wen, Jianhua Tao, Heng Xie, Jizhou Cui .etc.|<http://arxiv.org/pdf/2407.12274v2>|构建了包含个性与情感特征的跨模态欺骗数据集MDPE，以促进欺骗检测和情感计算研究。|
|📝 更新|SemHiTok: A Unified Image Tokenizer via Semantic-Guided Hierarchical Codebook for Multimodal Understanding and Generation|语义引导的分层码本统一图像标记器，用于多模态理解和生成|Zisheng Chen, Chunwei Wang, Xiuwei Chen, Hongbin Xu, Runhui Huang, Jun Zhou, Jianhua Han, Hang Xu .etc.|<http://arxiv.org/pdf/2503.06764v4>|提出了一种语义引导的分层代码簿，解决多模态理解和生成中语义与像素特征平衡问题。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mitigating Hallucinations in Large Vision-Language Models via Entity-Centric Multimodal Preference Optimization|通过实体中心的多模态偏好优化减轻大型视觉-语言模型中的幻觉|Jiulong Wu, Zhengliang Shi, Shuaiqiang Wang, Jizhou Huang, Dawei Yin, Lingyong Yan, Min Cao, Min Zhang|<http://arxiv.org/pdf/2506.04039v1>|提出EMPO方法，通过实体中心的多模态偏好优化，有效降低大型视觉语言模型中的幻觉问题。|
|🆕 发布|DiffCAP: Diffusion-based Cumulative Adversarial Purification for Vision Language Models|基于扩散的视觉语言模型累积对抗净化：DiffCAP|Jia Fu, Yongtao Wu, Yihang Chen, Kunyu Peng, Xiao Zhang, Volkan Cevher, Sepideh Pashami, Anders Holst|<http://arxiv.org/pdf/2506.03933v1>|DiffCAP通过累积噪声注入和扩散模型去噪，有效净化视觉语言模型对抗攻击。|
|📝 更新|Data-Juicer Sandbox: A Feedback-Driven Suite for Multimodal Data-Model Co-development|数据榨汁机沙盒：一种反馈驱动的多模态数据-模型协同开发套件|Daoyuan Chen, Haibin Wang, Yilun Huang, Ce Ge, Yaliang Li, Bolin Ding, Jingren Zhou|<http://arxiv.org/pdf/2407.11784v3>|提出Data-Juicer Sandbox，通过反馈驱动实现数据与模型协同开发，优化多模态大模型性能...|
|📝 更新|Diffusion-VLA: Generalizable and Interpretable Robot Foundation Model via Self-Generated Reasoning|扩散-VLA：通过自生成推理实现的通用且可解释的机器人基础模型|Junjie Wen, Minjie Zhu, Yichen Zhu, Zhibin Tang, Jinming Li, Zhongyi Zhou, Chengmeng Li, Xiaoyu Liu .etc.|<http://arxiv.org/pdf/2412.03293v3>|Diffusion-VLA通过自生成推理，构建了可解释且通用的机器人基础模型，有效提升视觉运动策略学...|
|🆕 发布|CHIME: Conditional Hallucination and Integrated Multi-scale Enhancement for Time Series Diffusion Model|CHIME：条件幻觉与集成多尺度增强用于时间序列扩散模型|Yuxuan Chen, Haipeng Xie|<http://arxiv.org/pdf/2506.03502v1>|提出CHIME框架，通过条件幻觉和多尺度增强提升时间序列扩散模型的生成能力。|
|📝 更新|Large-Scale Text-to-Image Model with Inpainting is a Zero-Shot Subject-Driven Image Generator|大规模文本到图像模型结合修复的零样本主题驱动图像生成器|Chaehun Shin, Jooyoung Choi, Heeseung Kim, Sungroh Yoon|<http://arxiv.org/pdf/2411.15466v2>|提出Diptych Prompting，通过图像修复实现零样本主题驱动图像生成，显著提升生成图像质量...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MambaNeXt-YOLO: A Hybrid State Space Model for Real-time Object Detection|MambaNeXt-YOLO：一种用于实时目标检测的混合状态空间模型|Xiaochun Lei, Siqi Wu, Weilin Wu, Zetao Jiang|<http://arxiv.org/pdf/2506.03654v1>|MambaNeXt-YOLO通过结合CNN和Mamba模型，实现高效实时物体检测。|
|📝 更新|Mixed Non-linear Quantization for Vision Transformers|混合非线性量化用于视觉Transformer|Gihwan Kim, Jemin Lee, Sihyeong Park, Yongin Kwon, Hyungshin Kim|<http://arxiv.org/pdf/2407.18437v2>|提出混合非线性量化方法，针对视觉Transformer的非线性操作进行优化，显著提升模型性能。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Single-Pass Object-Focused Data Selection|单次遍历目标聚焦数据选择|Niclas Popp, Dan Zhang, Jan Hendrik Metzen, Matthias Hein, Lukas Schott|<http://arxiv.org/pdf/2412.10032v2>|提出了一种基于对象级别的数据选择方法，有效提高了标注效率。|
|📝 更新|NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution|NTIRE 2025 挑战赛：原始图像恢复与超分辨率|Marcos V. Conde, Radu Timofte, Zihao Lu, Xiangyu Kong, Xiaoxia Xing, Fan Wang, Suejin Han, MinKyu Park .etc.|<http://arxiv.org/pdf/2506.02197v2>|提出NTIRE 2025挑战，推动RAW图像修复与超分辨率技术发展。|
|🆕 发布|Accelerating SfM-based Pose Estimation with Dominating Set|基于支配集加速SfM的位姿估计|Joji Joseph, Bharadwaj Amrutur, Shalabh Bhatnagar|<http://arxiv.org/pdf/2506.03667v1>|利用图论中的支配集概念，该论文加速了基于SfM的位姿估计，显著提升了处理速度和效率。|
|🆕 发布|WIFE-Fusion:Wavelet-aware Intra-inter Frequency Enhancement for Multi-model Image Fusion|WIFE-Fusion：多模型图像融合的基于小波感知的频域增强|Tianpei Zhang, Jufeng Zhao, Yiming Zhu, Guangmang Cui|<http://arxiv.org/pdf/2506.03555v1>|[代码](https://github.com/Lmmh058/WIFE-Fusion.); 提出WIFE-Fusion，通过频率域特征交互增强，有效提升多模态图像融合质量。|
|📝 更新|ExeChecker: Where Did I Go Wrong?|ExeChecker：我错在哪里了？|Yiwen Gu, Mahir Patel, Margrit Betke|<http://arxiv.org/pdf/2412.10573v2>|ExeChecker通过对比学习识别康复运动中的错误动作，提供反馈辅助用户正确完成锻炼。|
|📝 更新|DAS3D: Dual-modality Anomaly Synthesis for 3D Anomaly Detection|DAS3D：用于3D异常检测的混合模态异常合成|Kecen Li, Bingquan Dai, Jingjing Fu, Xinwen Hou|<http://arxiv.org/pdf/2410.09821v2>|提出了一种基于双模态异常合成的3D异常检测方法，显著提升了检测精度和分割性能。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EV-Flying: an Event-based Dataset for In-The-Wild Recognition of Flying Objects|基于事件的野外飞行物体识别数据集：EV-Flying|Gabriele Magrini, Federico Becattini, Giovanni Colombo, Pietro Pala|<http://arxiv.org/pdf/2506.04048v1>|提出EV-Flying数据集，利用事件相机和轻量级架构识别野外飞行物体。|
|🆕 发布|DSSAU-Net:U-Shaped Hybrid Network for Pubic Symphysis and Fetal Head Segmentation|DSSAU-Net：用于耻骨联合和胎儿头部分割的U型混合网络|Zunhui Xia, Hongxing Li, Libin Lan|<http://arxiv.org/pdf/2506.03684v1>|[代码](https://github.com/XiaZunhui/DSSAU-Net.); 提出了一种U型混合网络DSSAU-Net，有效提高了胎儿头部和耻骨联合的分割精度。|
|🆕 发布|BiXFormer: A Robust Framework for Maximizing Modality Effectiveness in Multi-Modal Semantic Segmentation|BiXFormer：一种最大化多模态语义分割模态有效性的鲁棒框架|Jialei Chen, Xu Zheng, Danda Pani Paudel, Luc Van Gool, Hiroshi Murase, Daisuke Deguchi|<http://arxiv.org/pdf/2506.03675v1>|提出BiXFormer，通过模态匹配和跨模态对齐，提升多模态语义分割效果。|
|🆕 发布|Intersectional Bias in Pre-Trained Image Recognition Models|交叉性偏见在预训练图像识别模型中|Valerie Krug, Sebastian Stober|<http://arxiv.org/pdf/2506.03664v1>|探究了预训练图像识别模型中年龄、种族和性别的交叉偏见，并使用线性分类器探针和可视化方法揭示了模型在年...|
|🆕 发布|ViTSGMM: A Robust Semi-Supervised Image Recognition Network Using Sparse Labels|ViTSGMM：一种使用稀疏标签的鲁棒半监督图像识别网络|Rui Yann, Xianglei Xing|<http://arxiv.org/pdf/2506.03582v1>|[代码](https://github.com/Shu1L0n9/ViTSGMM.); ViTSGMM通过优化特征表示与目标类别的互信息，构建混合密度分类决策机制，在极少量标注数据下实现半...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|InterRVOS: Interaction-aware Referring Video Object Segmentation|交互感知的指代视频目标分割：InterRVOS|Woojeong Jin, Seongchan Kim, Seungryong Kim|<http://arxiv.org/pdf/2506.02356v2>|[代码](https://cvlab-kaist.github.io/InterRVOS.); 提出了一种交互感知的视频目标分割方法，通过建模交互关系提升分割性能。|
|🆕 发布|FSHNet: Fully Sparse Hybrid Network for 3D Object Detection|FSHNet：用于3D目标检测的完全稀疏混合网络|Shuai Liu, Mingyue Cui, Boyang Li, Quanmin Liang, Tinghe Hong, Kai Huang, Yunxiao Shan, Kai Huang|<http://arxiv.org/pdf/2506.03714v1>|[代码](https://github.com/Say2L/FSHNet.); FSHNet通过引入SlotFormer块和动态稀疏标签分配策略，有效提升了3D物体检测的远距离特征...|
|🆕 发布|DiagNet: Detecting Objects using Diagonal Constraints on Adjacency Matrix of Graph Neural Network|DiagNet：基于图神经网络邻接矩阵对角约束的对象检测|Chong Hyun Lee, Kibae Lee|<http://arxiv.org/pdf/2506.03571v1>|DiagNet通过在图卷积网络的邻接矩阵上施加对角约束，实现了无需锚框的物体检测，显著提升了检测准确...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation|OV-COAST：基于最优传输的开集词汇语义分割的成本聚合|Aditya Gandhamal, Aniruddh Sikdar, Suresh Sundaram|<http://arxiv.org/pdf/2506.03706v1>|[代码](https://github.com/adityagandhamal/OV-COAST); 提出OV-COAST方法，通过最优传输理论优化成本聚合，显著提升开放词汇语义分割性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Sounding that Object: Interactive Object-Aware Image to Audio Generation|声音那物体：交互式物体感知图像到音频生成|Tingle Li, Baihe Huang, Xiaobin Zhuang, Dongya Jia, Jiawei Chen, Yuping Wang, Zhuo Chen, Gopala Anumanchipalli .etc.|<http://arxiv.org/pdf/2506.04214v1>|提出了一种基于图像分割的交互式对象感知音频生成模型，实现物体与声音的精准匹配。|
|🆕 发布|UNIC: Unified In-Context Video Editing|统一情境视频编辑：UNIC|Zixuan Ye, Xuanhua He, Quande Liu, Qiulin Wang, Xintao Wang, Pengfei Wan, Di Zhang, Kun Gai .etc.|<http://arxiv.org/pdf/2506.04216v1>|提出UNIC框架，实现视频编辑任务统一处理，提升性能并支持灵活任务组合。|
|🆕 发布|Voyager: Long-Range and World-Consistent Video Diffusion for Explorable 3D Scene Generation|航行者：用于可探索3D场景生成的长距离和世界一致的视频扩散|Tianyu Huang, Wangguandong Zheng, Tengfei Wang, Yuhao Liu, Zhenwei Wang, Junta Wu, Jie Jiang, Hui Li .etc.|<http://arxiv.org/pdf/2506.04225v1>|Voyager通过视频扩散技术，实现了从单张图像生成长距离、世界一致的3D场景。|
|🆕 发布|FullDiT2: Efficient In-Context Conditioning for Video Diffusion Transformers|全DiT2：视频扩散变换器的高效上下文条件化|Xuanhua He, Quande Liu, Zixuan Ye, Wecai Ye, Qiulin Wang, Xintao Wang, Qifeng Chen, Pengfei Wan .etc.|<http://arxiv.org/pdf/2506.04213v1>|提出FullDiT2，通过动态选择和缓存机制，有效降低视频扩散Transformer的计算复杂度，提...|
|📝 更新|A Survey on (M)LLM-Based GUI Agents|基于（M）LLM的GUI代理综述|Fei Tang, Haolei Xu, Hang Zhang, Siqi Chen, Xingyu Wu, Yongliang Shen, Wenqi Zhang, Guiyang Hou .etc.|<http://arxiv.org/pdf/2504.13865v2>|该论文全面分析了基于大型语言模型的GUI代理，揭示了其革命性进步及其在智能界面自动化领域的应用潜力。|
|📝 更新|UniWorld: High-Resolution Semantic Encoders for Unified Visual Understanding and Generation|UniWorld：统一视觉理解和生成的高分辨率语义编码器|Bin Lin, Zongjian Li, Xinhua Cheng, Yuwei Niu, Yang Ye, Xianyi He, Shenghai Yuan, Wangbo Yu .etc.|<http://arxiv.org/pdf/2506.03147v2>|提出UniWorld，通过语义特征实现统一视觉理解和生成，突破现有模型在图像感知和操作上的局限。|
|🆕 发布|RAID: A Dataset for Testing the Adversarial Robustness of AI-Generated Image Detectors|RAID：用于测试AI生成图像检测器对抗鲁棒性的数据集|Hicham Eddoubi, Jonas Ricker, Federico Cocchi, Lorenzo Baraldi, Angelo Sotgiu, Maura Pintor, Marcella Cornia, Lorenzo Baraldi .etc.|<http://arxiv.org/pdf/2506.03988v1>|[代码](https://github.com/pralab/RAID.); 构建了RAID数据集，以评估AI生成图像检测器的对抗鲁棒性。|
|📝 更新|Flow-GRPO: Training Flow Matching Models via Online RL|Flow-GRPO：通过在线强化学习训练流匹配模型|Jie Liu, Gongye Liu, Jiajun Liang, Yangguang Li, Jiaheng Liu, Xintao Wang, Pengfei Wan, Di Zhang .etc.|<http://arxiv.org/pdf/2505.05470v3>|Flow-GRPO通过在线强化学习优化流匹配模型，显著提升文本到图像生成任务的准确性和多样性。|
|📝 更新|FlexTok: Resampling Images into 1D Token Sequences of Flexible Length|FlexTok：将图像重采样为灵活长度的1D标记序列|Roman Bachmann, Jesse Allardice, David Mizrahi, Enrico Fini, Oğuzhan Fatih Kar, Elmira Amirloo, Alaaeldin El-Nouby, Amir Zamir .etc.|<http://arxiv.org/pdf/2502.13967v2>|FlexTok通过将图像转换为灵活长度的1D序列，实现了高效且适应性强的图像自动生成。|
|📝 更新|SViMo: Synchronized Diffusion for Video and Motion Generation in Hand-object Interaction Scenarios|SViMo：手-物体交互场景中的同步扩散视频和运动生成|Lingwei Dang, Ruizhi Shao, Hongwen Zhang, Wei Min, Yebin Liu, Qingyao Wu|<http://arxiv.org/pdf/2506.02444v2>|[代码](https://github.com/Droliven/SViMo); 提出同步扩散模型，实现手-物交互视频和动作同时生成，提升视频-动作一致性。|
|📝 更新|Implicit Inversion turns CLIP into a Decoder|隐式逆变换将CLIP转化为解码器|Antonio D'Orazio, Maria Rosaria Briglia, Donato Crisostomi, Dario Loi, Emanuele Rodolà, Iacopo Masi|<http://arxiv.org/pdf/2505.23161v2>|将CLIP模型直接转化为图像生成器，无需额外解码器或训练。|
|🆕 发布|ComRoPE: Scalable and Robust Rotary Position Embedding Parameterized by Trainable Commuting Angle Matrices|ComRoPE：基于可训练通勤角度矩阵的可扩展且鲁棒的旋转位置嵌入|Hao Yu, Tangyu Jiang, Shuning Jia, Shannan Yan, Shunning Liu, Haolong Qian, Guanghao Li, Shuting Dong .etc.|<http://arxiv.org/pdf/2506.03737v1>|[代码](https://github.com/Longin-Yu/ComRoPE); 提出了一种基于可训练旋转角度矩阵的ComRoPE，有效提升了Transformer模型的位置编码鲁棒...|
|📝 更新|Graph Flow Matching: Enhancing Image Generation with Neighbor-Aware Flow Fields|图流匹配：通过邻域感知流场增强图像生成|Md Shahriar Rahim Siddiqui, Moshe Eliasof, Eldad Haber|<http://arxiv.org/pdf/2505.24434v2>|提出Graph Flow Matching方法，通过聚合邻域信息提升图像生成质量。|
|🆕 发布|EmoArt: A Multidimensional Dataset for Emotion-Aware Artistic Generation|情感艺术：一个用于情感感知艺术生成的多维度数据集|Cheng Zhang, Hongxia xie, Bin Wen, Songhan Zuo, Ruoxuan Zhang, Wen-huang Cheng|<http://arxiv.org/pdf/2506.03652v1>|构建了EmoArt数据集，为情感驱动的艺术图像生成提供基准和资源。|
|🆕 发布|Negative-Guided Subject Fidelity Optimization for Zero-Shot Subject-Driven Generation|负向引导的零样本主题驱动生成中的主题保真度优化|Chaehun Shin, Jooyoung Choi, Johan Barthelemy, Jungbeom Lee, Sungroh Yoon|<http://arxiv.org/pdf/2506.03621v1>|提出了一种基于负样本引导的零样本主题驱动生成优化框架，显著提升了主题一致性。|
|📝 更新|Visual Attention Never Fades: Selective Progressive Attention ReCalibration for Detailed Image Captioning in Multimodal Large Language Models|视觉注意力永不褪去：多模态大型语言模型中详细图像描述的选区渐进式注意力重校准|Mingi Jung, Saehyung Lee, Eunji Kim, Sungroh Yoon|<http://arxiv.org/pdf/2502.01419v2>|提出SPARC方法，通过选择性渐进式注意力重校准，提升多模态大语言模型在详细图像描述中的精确度和召回...|
|🆕 发布|Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision|从自视角视觉中的动作描述生成6自由度物体操作轨迹|Tomoya Yoshida, Shuhei Kurita, Taichi Nishimura, Shinsuke Mori|<http://arxiv.org/pdf/2506.03605v1>|提出了一种从动作描述生成6自由度物体操作轨迹的方法，利用大规模视频数据集和视觉语言模型。|
|🆕 发布|ControlThinker: Unveiling Latent Semantics for Controllable Image Generation through Visual Reasoning|控制思考者：通过视觉推理揭示可控图像生成的潜在语义|Feng Han, Yang Jiao, Shaoxiang Chen, Junhao Xu, Jingjing Chen, Yu-Gang Jiang|<http://arxiv.org/pdf/2506.03596v1>|[代码](https://github.com/Maplebb/ControlThinker.); ControlThinker通过视觉推理挖掘语义，实现可控图像生成，缩小语义差距。|
|🆕 发布|Resolving Task Objective Conflicts in Unified Multimodal Understanding and Generation via Task-Aware Mixture-of-Experts|通过任务感知混合专家解决统一多模态理解和生成中的任务目标冲突|Jiaxing Zhang, Xinyi Zeng, Hao Tang|<http://arxiv.org/pdf/2506.03591v1>|提出UTAMoE框架，通过任务感知混合专家层解耦AR模块，有效解决统一多模态理解与生成中的任务目标冲...|
|📝 更新|ReactDiff: Latent Diffusion for Facial Reaction Generation|ReactDiff：面部反应生成的潜在扩散|Jiaming Li, Sheng Wang, Xin Wang, Yitao Zhu, Honglin Xiong, Zixu Zhuang, Qian Wang|<http://arxiv.org/pdf/2505.14151v3>|[代码](https://github.com/Hunan-Tiger/ReactDiff); ReactDiff通过融合多模态Transformer和条件扩散，有效提升了面部反应生成的相关性和多...|
|📝 更新|T2I-FactualBench: Benchmarking the Factuality of Text-to-Image Models with Knowledge-Intensive Concepts|T2I-FactualBench：基于知识密集型概念的文本到图像模型事实性基准测试|Ziwei Huang, Wanggui He, Quanyu Long, Yandi Wang, Haoyuan Li, Zhelun Yu, Fangxun Shu, Long Chan .etc.|<http://arxiv.org/pdf/2412.04300v3>|构建T2I-FactualBench基准，评估知识密集型概念生成的事实性，揭示现有T2I模型在真实性...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LayerFlow: A Unified Model for Layer-aware Video Generation|层流：一种面向层感知的视频生成统一模型|Sihui Ji, Hao Luo, Xi Chen, Yuanpeng Tu, Yiyang Wang, Hengshuang Zhao|<http://arxiv.org/pdf/2506.04228v1>|LayerFlow通过统一框架实现层感知视频生成，支持多种视频处理变体。|
|🆕 发布|UniCUE: Unified Recognition and Generation Framework for Chinese Cued Speech Video-to-Speech Generation|UniCUE：面向中文提示语音视频到语音生成的统一识别与生成框架|Jinting Wang, Shan Yang, Li Liu|<http://arxiv.org/pdf/2506.04134v1>|提出UniCUE，直接从CS视频生成语音，显著降低错误率并提升唇语同步。|
|🆕 发布|PRJ: Perception-Retrieval-Judgement for Generated Images|感知-检索-判断：生成图像的评估方法|Qiang Fu, Zonglei Jing, Zonghao Ying, Xiaoqian Li|<http://arxiv.org/pdf/2506.03683v1>|提出PRJ框架，通过感知-检索-判断三阶段，提升AI生成图像毒性检测的准确性和可解释性。|
|🆕 发布|VLMs Can Aggregate Scattered Training Patches|《VLMs能够聚合分散的训练块》|Zhanhui Zhou, Lingjie Chen, Chao Yang, Chaochao Lu|<http://arxiv.org/pdf/2506.03614v1>|[代码](https://github.com/ZHZisZZ/visual-stitching.); 提出了一种通过视觉拼接能力识别和防御VLMs训练数据中毒的方法。|
|🆕 发布|BiMa: Towards Biases Mitigation for Text-Video Retrieval via Scene Element Guidance|BiMa：基于场景元素引导的文本-视频检索偏差缓解方法|Huy Le, Nhat Chung, Tung Kieu, Anh Nguyen, Ngan Le|<http://arxiv.org/pdf/2506.03589v1>|提出BiMa框架，通过场景元素引导缓解文本-视频检索中的视觉-语言偏差。|
|📝 更新|Generative Emotion Cause Explanation in Multimodal Conversations|多模态对话中的生成情感原因解释|Lin Wang, Xiaocui Yang, Shi Feng, Daling Wang, Yifei Zhang, Zhitao Zhang|<http://arxiv.org/pdf/2411.02430v3>|[代码](https://github.com/3222345200/FAME-Net.); 提出了一种基于LLMs的多模态情感原因解释方法，有效识别对话中的情感触发因素。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Diffusion Domain Teacher: Diffusion Guided Domain Adaptive Object Detector|扩散域教师：扩散引导的域自适应目标检测器|Boyong He, Yuxiang Ji, Zhuoyue Tan, Liaoni Wu|<http://arxiv.org/pdf/2506.04211v1>|[代码](https://github.com/heboyong/Diffusion-Domain-Teacher.); 提出了一种基于扩散模型的域自适应目标检测方法，显著提升了跨域检测性能。|
|🆕 发布|Image Editing As Programs with Diffusion Models|图像编辑作为扩散模型的程序|Yujia Hu, Songhua Liu, Zhenxiong Tan, Xingyi Yang, Xinchao Wang|<http://arxiv.org/pdf/2506.04158v1>|[代码](https://github.com/YujiaHu1109/IEAP.); 提出IEAP框架，通过分解编辑指令为原子操作，显著提升图像编辑的准确性和语义保真度。|
|📝 更新|Generalized Diffusion Detector: Mining Robust Features from Diffusion Models for Domain-Generalized Detection|广义扩散检测器：从扩散模型中挖掘鲁棒特征以实现领域泛化检测|Boyong He, Yuxiang Ji, Qianwen Ye, Zhuoyue Tan, Liaoni Wu|<http://arxiv.org/pdf/2503.02101v2>|[代码](https://github.com/heboyong/Generalized-Diffusion-Detector.); 提出了一种从扩散模型中挖掘鲁棒特征的方法，显著提升了域泛化检测性能。|
|🆕 发布|Dreaming up scale invariance via inverse renormalization group|通过逆重整化群实现尺度不变性的梦想|Adam Rançon, Ulysse Rançon, Tomislav Ivek, Ivan Balog|<http://arxiv.org/pdf/2506.04016v1>|通过逆向重整化群，该论文展示了简单神经网络能够从粗粒化状态中“梦想”出微观配置，实现尺度不变分布的重...|
|📝 更新|UltraBones100k: A reliable automated labeling method and large-scale dataset for ultrasound-based bone surface extraction|超骨100k：一种可靠的超声骨表面提取自动化标注方法和大规模数据集|Luohong Wu, Nicola A. Cavalcanti, Matthias Seibold, Giuseppe Loggia, Lisa Reissner, Jonas Hein, Silvan Beeler, Arnd Viehöfer .etc.|<http://arxiv.org/pdf/2502.03783v4>|提出了一种自动标注超声骨骼图像的方法，构建了大规模UltraBones100k数据集，显著提升了骨表...|
|🆕 发布|Solving Inverse Problems via Diffusion-Based Priors: An Approximation-Free Ensemble Sampling Approach|通过基于扩散先验解决逆问题：一种无近似的无监督采样方法|Haoxuan Chen, Yinuo Ren, Martin Renqiang Min, Lexing Ying, Zachary Izzo|<http://arxiv.org/pdf/2506.03979v1>|提出了一种基于扩散模型的近似无关后验采样方法，有效解决了计算机视觉中的逆问题。|
|📝 更新|VCT: Training Consistency Models with Variational Noise Coupling|VCT：基于变分噪声耦合的训练一致性模型|Gianluigi Silvestri, Luca Ambrogioni, Chieh-Hsin Lai, Yuhta Takida, Yuki Mitsufuji|<http://arxiv.org/pdf/2502.18197v2>|[代码](https://github.com/sony/vct.); 提出VCT，通过学习噪声-数据耦合方案，有效降低一致性训练的方差，提升图像生成质量。|
|🆕 发布|SAAT: Synergistic Alternating Aggregation Transformer for Image Super-Resolution|协同交替聚合Transformer用于图像超分辨率|Jianfeng Wu, Nannan Xu|<http://arxiv.org/pdf/2506.03740v1>|提出SAAT模型，通过融合通道和空间注意力机制，有效提升图像超分辨率性能。|
|📝 更新|MMAR: Towards Lossless Multi-Modal Auto-Regressive Probabilistic Modeling|MMAR：迈向无损多模态自回归概率建模|Jian Yang, Dacheng Yin, Yizhou Zhou, Fengyun Rao, Wei Zhai, Yang Cao, Zheng-Jun Zha|<http://arxiv.org/pdf/2410.10798v3>|检测并解决多模态模型中图像信息丢失问题，提出MMAR模型，有效提升图像理解和生成能力。|
|📝 更新|DiffoRA: Enabling Parameter-Efficient Fine-Tuning via Differential Module Selection|DiffoRA：通过差异模块选择实现参数高效微调|Tangyu Jiang, Haodi Wang, Chun Yuan|<http://arxiv.org/pdf/2502.08905v2>|DiffoRA通过差异模块选择，实现参数高效的微调，显著提升预训练模型性能。|
|📝 更新|Grid-LOGAT: Grid Based Local and Global Area Transcription for Video Question Answering|网格-LOGAT：基于网格的局部和全局区域转录用于视频问答|Md Intisar Chowdhury, Kittinun Aukkapinyo, Hiroshi Fujimura, Joo Ann Woo, Wasu Wasusatein, Fadoua Ghourabi|<http://arxiv.org/pdf/2505.24371v2>|Grid-LOGAT通过结合视觉语言模型和大型语言模型，在视频问答中实现高精度答案生成，同时保护图像...|
|📝 更新|LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning|LLaDA-V：具有视觉指令微调的大型语言扩散模型|Zebin You, Shen Nie, Xiaolu Zhang, Jun Hu, Jun Zhou, Zhiwu Lu, Ji-Rong Wen, Chongxuan Li|<http://arxiv.org/pdf/2505.16933v2>|[代码](https://ml-gsai.github.io/LLaDA-V-demo); LLaDA-V通过视觉指令调整，将视觉特征映射到语言嵌入空间，显著提升了多模态大语言模型的多模态性能...|
|🆕 发布|How Far Are We from Predicting Missing Modalities with Foundation Models?|我们离使用基础模型预测缺失模态还有多远？|Guanzhou Ke, Yi Xie, Xiaoli Wang, Guoqing Chao, Bo Wang, Shengfeng He|<http://arxiv.org/pdf/2506.03530v1>|提出了一种针对缺失模态预测的智能框架，显著提升了预测准确性和适应性。|
|🆕 发布|DenseDPO: Fine-Grained Temporal Preference Optimization for Video Diffusion Models|密集DPO：视频扩散模型的细粒度时间偏好优化|Ziyi Wu, Anil Kag, Ivan Skorokhodov, Willi Menapace, Ashkan Mirzaei, Igor Gilitschenski, Sergey Tulyakov, Aliaksandr Siarohin|<http://arxiv.org/pdf/2506.03517v1>|DenseDPO通过优化视频生成模型，实现了更精细的运动偏好标注，同时提升了自动标注的准确性。|
|🆕 发布|Facial Appearance Capture at Home with Patch-Level Reflectance Prior|家庭环境中基于补丁级反射先验的人脸外观捕捉|Yuxuan Han, Junfeng Lyu, Kuan Sheng, Minghao Que, Qixuan Zhang, Lan Xu, Feng Xu|<http://arxiv.org/pdf/2506.03478v1>|[代码](https://github.com/yxuhan/DoRA.); 开发了一种基于智能手机和闪光灯的日常面部外观捕捉方法，显著提升了低成本设备捕捉的图像质量。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EnergyMoGen: Compositional Human Motion Generation with Energy-Based Diffusion Model in Latent Space|基于潜在空间的能量扩散模型组合人类运动生成|Jianrong Zhang, Hehe Fan, Yi Yang|<http://arxiv.org/pdf/2412.14706v2>|提出EnergyMoGen，通过融合能量模型和语义感知，有效合成复杂的人类运动序列。|
|🆕 发布|Towards generating more interpretable counterfactuals via concept vectors: a preliminary study on chest X-rays|通过概念向量生成更具可解释性的反事实：胸部X光片初步研究|Bulat Maksudov, Kathleen Curran, Alessandra Mileo|<http://arxiv.org/pdf/2506.04058v1>|通过概念向量生成更具解释性的反事实，为医学影像模型提供与临床知识相符的可解释性。|
|🆕 发布|Animal Pose Labeling Using General-Purpose Point Trackers|动物姿态标注利用通用点跟踪器|Zhuoyang Pan, Boxiao Pan, Guandao Yang, Adam W. Harley, Leonidas Guibas|<http://arxiv.org/pdf/2506.03868v1>|[代码](https://zhuoyang-pan.github.io/animal-labeling.); 提出一种基于预训练点跟踪器的动物姿态标注流程，实现高效标注动物行为。|
|📝 更新|DreamFrame: Enhancing Video Understanding via Automatically Generated QA and Style-Consistent Keyframes|DreamFrame：通过自动生成的问答和风格一致的关键帧增强视频理解|Zhende Song, Chenchen Wang, Jiamu Sheng, Chi Zhang, Shengji Tang, Jiayuan Fan, Tao Chen|<http://arxiv.org/pdf/2403.01422v3>|DreamFrame通过自动生成风格一致的关键帧和问答对，有效提升了视频理解模型的性能。|
|📝 更新|M3-AGIQA: Multimodal, Multi-Round, Multi-Aspect AI-Generated Image Quality Assessment|M3-AGIQA：多模态、多轮、多角度人工智能图像质量评估|Chuan Cui, Kejiang Chen, Zhihua Wei, Wen Shen, Weiming Zhang, Nenghai Yu|<http://arxiv.org/pdf/2502.15167v2>|[代码](https://github.com/strawhatboy/M3-AGIQA.); M3-AGIQA提出了一种利用多模态大语言模型评估AI生成图像质量的方法，实现更全面、符合人类判断的...|
|📝 更新|Sonic: Shifting Focus to Global Audio Perception in Portrait Animation|声动：转向人像动画中的全局音频感知|Xiaozhong Ji, Xiaobin Hu, Zhihong Xu, Junwei Zhu, Chuming Lin, Qingdong He, Jiangning Zhang, Donghao Luo .etc.|<http://arxiv.org/pdf/2411.16331v2>|提出Sonic方法，通过全局音频感知提升人像动画的自然度和时间一致性。|
|📝 更新|FlowMo: Variance-Based Flow Guidance for Coherent Motion in Video Generation|FlowMo：基于方差的视频生成中的一致运动引导|Ariel Shaulov, Itay Hazan, Lior Wolf, Hila Chefer|<http://arxiv.org/pdf/2506.01144v2>|FlowMo通过分析模型预测的连续帧之间的差异，增强视频生成中的运动连贯性。|
|🆕 发布|YOND: Practical Blind Raw Image Denoising Free from Camera-Specific Data Dependency|YOND：无需相机特定数据依赖的实用盲原始图像去噪|Hansen Feng, Lizhi Wang, Yiqi Huang, Tong Li, Lin Zhu, Hua Huang|<http://arxiv.org/pdf/2506.03645v1>|[代码](https://fenghansen.github.io/publication); YOND提出了一种无需特定相机数据的盲图像降噪方法，有效解决了相机依赖问题。|
|📝 更新|Reasoning is All You Need for Video Generalization: A Counterfactual Benchmark with Sub-question Evaluation|视频泛化只需推理：带有子问题评估的反事实基准|Qiji Zhou, Yifan Gong, Guangsheng Bao, Hongjie Qiu, Jinqiang Li, Xiangrong Zhu, Huajian Zhang, Yue Zhang|<http://arxiv.org/pdf/2503.10691v2>|[代码](https://github.com/gongyifan-hash/COVER-Benchmark.); 提出COVER基准，通过子问题评估提升视频理解中的反事实推理能力。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Object-centric 3D Motion Field for Robot Learning from Human Videos|以物体为中心的机器人从人类视频中学习3D运动场|Zhao-Heng Yin, Sherry Yang, Pieter Abbeel|<http://arxiv.org/pdf/2506.04227v1>|提出了一种基于物体中心3D运动场的方法，从人类视频中学习机器人控制策略，显著提升了动作理解和零样本控...|
|🆕 发布|FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting|FlexGS：一次训练，无处不在——多合一灵活3D高斯分层|Hengyu Liu, Yuehao Wang, Chenxin Li, Ruisi Cai, Kevin Wang, Wuyang Li, Pavlo Molchanov, Peihao Wang .etc.|<http://arxiv.org/pdf/2506.04174v1>|FlexGS通过弹性推理和可学习模块，实现了3D Gaussian Splatting的灵活压缩，适...|
|📝 更新|Objective drives the consistency of representational similarity across datasets|目标驱动数据集间表征相似性的一致性|Laure Ciernik, Lorenz Linhardt, Marco Morik, Jonas Dippel, Simon Kornblith, Lukas Muttenthaler|<http://arxiv.org/pdf/2411.05561v2>|研究发现目标函数是决定模型表示在不同数据集间一致性关键因素。|
|📝 更新|Learning 3D Representations from Procedural 3D Programs|从程序化3D程序中学习3D表示|Xuweiyi Chen, Zezhou Cheng|<http://arxiv.org/pdf/2411.17467v2>|从程序化3D程序中学习3D表示，无需语义信息即可实现与语义3D模型相当的性能。|
|🆕 发布|HUMOF: Human Motion Forecasting in Interactive Social Scenes|人机交互社交场景中的人体运动预测：HUMOF|Caiyi Sun, Yujing Sun, Xiao Han, Zemin Yang, Jiawei Liu, Xinge Zhu, Siu Ming Yiu, Yuexin Ma|<http://arxiv.org/pdf/2506.03753v1>|提出了一种基于层次交互特征表示和粗细粒度推理模块的人体运动预测方法，有效提升了复杂场景中运动预测的准...|
|🆕 发布|Images are Worth Variable Length of Representations|图像价值可变长度表示|Lingjun Mao, Rodolfo Corona, Xin Liang, Wenhao Yan, Zineng Tang|<http://arxiv.org/pdf/2506.03643v1>|[代码](https://dove-encoder.github.io/dove-encoder.); 提出DOVE，一种动态视觉编码器，通过生成可变长度的视觉标记，有效减少标记数量并提高图像重建质量。|
|📝 更新|Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders|注视-LLE：通过大规模学习编码器进行注视目标估计|Fiona Ryan, Ajay Bati, Sangmin Lee, Daniel Bolya, Judy Hoffman, James M. Rehg|<http://arxiv.org/pdf/2412.09586v2>|[代码](http://github.com/fkryan/gazelle); 提出Gaze-LLE，通过利用预训练的DINOv2编码器特征，实现高效的人眼注视目标估计。|
|🆕 发布|Target Semantics Clustering via Text Representations for Robust Universal Domain Adaptation|基于文本表示的目标语义聚类以实现鲁棒的通用域自适应|Weinan He, Zilei Wang, Yixin Zhang|<http://arxiv.org/pdf/2506.03521v1>|通过文本表示寻找语义中心，实现鲁棒的通用领域自适应。|
|📝 更新|CMAR-Net: Accurate Cross-Modal 3D SAR Reconstruction of Vehicle Targets with Sparse-Aspect Multi-Baseline Data|CMAR-Net：基于稀疏视角多基线数据的车辆目标精确跨模态3D合成孔径雷达重建|Da Li, Guoqiang Zhao, Chen Yao, Kaiqiang Zhu, Houjun Sun, Jiacheng Bao|<http://arxiv.org/pdf/2406.04158v4>|提出CMAR-Net，融合多模态信息，显著提升稀疏视场多基线SAR三维重建精度。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-view Surface Reconstruction Using Normal and Reflectance Cues|Fields of View and Camera Calibration|Robin Bruneau, Baptiste Brument, Yvain Quéau, Jean Mélou, François Bernard Lauze, Jean-Denis Durou, Lilian Calvet|<http://arxiv.org/pdf/2506.04115v1>|[代码](https://github.com/RobinBruneau/RNb-NeuS2.); 提出了一种融合多视角法线与反射率信息的表面重建方法，显著提升了重建细节和可见性处理能力。|
|🆕 发布|JointSplat: Probabilistic Joint Flow-Depth Optimization for Sparse-View Gaussian Splatting|联合Splat：稀疏视图高斯Splatting的概率联合光流-深度优化|Yang Xiao, Guoan Xu, Qiang Wu, Wenjing Jia|<http://arxiv.org/pdf/2506.03872v1>|提出JointSplat，通过概率优化融合光流与深度信息，有效解决稀疏视图3D重建中的定位与一致性难...|
|🆕 发布|PlückeRF: A Line-based 3D Representation for Few-view Reconstruction|PlückeRF：基于线的少视图重建的3D表示|Sam Bahrami, Dylan Campbell|<http://arxiv.org/pdf/2506.03713v1>|提出了一种基于线条的3D表示方法，有效利用多视角信息提升少视角重建质量。|
|🆕 发布|SplArt: Articulation Estimation and Part-Level Reconstruction with 3D Gaussian Splatting|SplArt：基于3D高斯喷溅的关节估计和部件级重建|Shengjie Lin, Jiading Fang, Muhammad Zubair Irshad, Vitor Campagnolo Guizilini, Rares Andrei Ambrus, Greg Shakhnarovich, Matthew R. Walter|<http://arxiv.org/pdf/2506.03594v1>|[代码](https://github.com/ripl/splart.); 提出了一种基于3D高斯分层渲染的端到端自监督方法，实现实时、高保真的人体关节估计和部分级重建。|
|📝 更新|SAB3R: Semantic-Augmented Backbone in 3D Reconstruction|SAB3R：3D重建中的语义增强骨干网络|Xuweiyi Chen, Tian Xia, Sihan Xu, Jianing Yang, Joyce Chai, Zezhou Cheng|<http://arxiv.org/pdf/2506.02112v2>|提出了一种结合语义增强和轻量级蒸馏的3D重建方法，实现了语义分割和3D重建的统一。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Your Turn: At Home Turning Angle Estimation for Parkinson's Disease Severity Assessment|您的回合：家庭环境中的帕金森病严重程度评估中的转向角估计|Qiushuo Cheng, Catherine Morgan, Arindam Sikdar, Alessandro Masullo, Alan Whone, Majid Mirmehdi|<http://arxiv.org/pdf/2408.08182v3>|该论文提出了一种基于深度学习的方法，通过分析日常生活中的视频，自动量化帕金森病患者的转身角度，以评估...|
|🆕 发布|EDCFlow: Exploring Temporally Dense Difference Maps for Event-based Optical Flow Estimation|EDCFlow：探索基于事件的光流估计中的时间密集型差异图|Daikun Liu, Lei Cheng, Teng Wang, changyin Sun|<http://arxiv.org/pdf/2506.03512v1>|提出EDCFlow网络，通过融合高分辨率差异运动特征和低分辨率相关运动特征，实现高效的光流估计，提升...|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Contour Errors: An Ego-Centric Metric for Reliable 3D Multi-Object Tracking|轮廓误差：可靠3D多目标跟踪的以自我为中心的度量|Sharang Kaul, Mario Berk, Thiemo Gerbich, Abhinav Valada|<http://arxiv.org/pdf/2506.04122v1>|提出了一种基于轮廓误差的3D多目标跟踪方法，显著提升了匹配的可靠性。|
|📝 更新|High Performance Space Debris Tracking in Complex Skylight Backgrounds with a Large-Scale Dataset|高性能复杂天空背景下的空间碎片跟踪及大规模数据集|Guohang Zhuang, Weixi Song, Jinyang Huang, Chenwei Yang, Yan Lu|<http://arxiv.org/pdf/2506.02614v2>|提出SDT-Net，通过大规模数据集实现复杂背景下的高性能空间碎片跟踪。|
|🆕 发布|Zero-Shot Temporal Interaction Localization for Egocentric Videos|零样本自回归视频中的自回归视频交互定位|Erhang Zhang, Junyi Ma, Yin-Dong Zheng, Yixuan Zhou, Hesheng Wang|<http://arxiv.org/pdf/2506.03662v1>|[代码](https://github.com/IRMVLab/EgoLoc.); 提出EgoLoc方法，实现零样本时序交互定位，提升自拍摄像头视频中抓取动作定位精度。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Video Deblurring with Deconvolution and Aggregation Networks|视频去模糊化：去卷积与聚合网络|Giyong Choi, HyunWook Park|<http://arxiv.org/pdf/2506.04054v1>|提出了一种利用邻帧信息的去卷积和聚合网络，有效提升了视频去模糊性能。|
|📝 更新|MammAlps: A multi-view video behavior monitoring dataset of wild mammals in the Swiss Alps|阿尔卑斯山哺乳动物多视角视频行为监测数据集：MammAlps|Valentin Gabeff, Haozhe Qi, Brendan Flaherty, Gencer Sumbül, Alexander Mathis, Devis Tuia|<http://arxiv.org/pdf/2503.18223v2>|[代码](https://github.com/eceo-epfl/MammAlps); 构建了多视角野生动物行为监测数据集MammAlps，并提出行为识别和生态分析基准，促进机器学习与生态...|
|🆕 发布|Video, How Do Your Tokens Merge?|视频，你的标记是如何合并的？|Sam Pollard, Michael Wray|<http://arxiv.org/pdf/2506.03885v1>|[代码](https://github.com/sjpollard/video-how-do-your-tokens-merge.); 探索了视频Transformer模型的无监督token合并，显著提升速度并保持准确率。|
|🆕 发布|Joint Video Enhancement with Deblurring, Super-Resolution, and Frame Interpolation Network|联合去模糊、超分辨率和帧插值网络的视频增强|Giyong Choi, HyunWook Park|<http://arxiv.org/pdf/2506.03892v1>|提出了一种同时解决视频去模糊、超分辨率和帧插值问题的联合视频增强网络，显著提升视频质量。|
|📝 更新|MemoryOut: Learning Principal Features via Multimodal Sparse Filtering Network for Semi-supervised Video Anomaly Detection|MemoryOut：通过多模态稀疏滤波网络学习主特征以实现半监督视频异常检测|Juntong Li, Lingwei Dang, Yukun Su, Yun Hao, Qingxin Xiao, Yongwei Nie, Qingyao Wu|<http://arxiv.org/pdf/2506.02535v2>|[代码](https://qzfm.github.io/sfn_vad_project_page); 提出一种结合多模态联合建模和稀疏特征过滤的半监督视频异常检测框架，有效识别异常事件。|
|📝 更新|Fact-R1: Towards Explainable Video Misinformation Detection with Deep Reasoning|事实-R1：迈向可解释的视频虚假信息检测的深度推理|Fanrui Zhang, Dian Li, Qiang Zhang, Chenjun, sinbadliu, Junxiong Lin, Jiahong Yan, Jiawei Liu .etc.|<http://arxiv.org/pdf/2505.16836v2>|Fact-R1通过融合深度推理和协同规则强化学习，实现了可解释的视频虚假信息检测。|
|🆕 发布|Video-Skill-CoT: Skill-based Chain-of-Thoughts for Domain-Adaptive Video Reasoning|视频技能-思维链：基于技能的领域自适应视频推理|Daeun Lee, Jaehong Yoon, Jaemin Cho, Mohit Bansal|<http://arxiv.org/pdf/2506.03525v1>|提出Video-SKoT框架，通过技能感知思维链训练，实现视频领域自适应推理。|
|🆕 发布|MamFusion: Multi-Mamba with Temporal Fusion for Partially Relevant Video Retrieval|MamFusion：基于多Mamba和时序融合的局部相关视频检索|Xinru Ying, Jiaqi Mo, Jingyang Lin, Canghong Jin, Fangfang Wang, Lina Wei|<http://arxiv.org/pdf/2506.03473v1>|[代码](https://github.com/Vision-Multimodal-Lab-HZCU/MamFusion.); MamFusion通过多Mamba模块和时间融合框架，有效解决部分相关视频检索中的信息冗余问题，显著...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|KAN-HyperpointNet for Point Cloud Sequence-Based 3D Human Action Recognition|基于点云序列的3D人体动作识别的KAN-HyperpointNet|Zhaoyu Chen, Xing Li, Qian Huang, Qiang Geng, Tianjin Yang, Shihao Han|<http://arxiv.org/pdf/2409.09444v2>|提出KAN-HyperpointNet，通过D-Hyperpoint嵌入和KANsMixer模块，平...|
|📝 更新|MAC-Gaze: Motion-Aware Continual Calibration for Mobile Gaze Tracking|MAC-Gaze：移动注视跟踪的运动感知持续校准|Yaxiong Lei, Mingyue Zhao, Yuheng Wang, Shijing He, Yusuke Sugano, Mohamed Khamis, Juan Ye|<http://arxiv.org/pdf/2505.22769v2>|提出MAC-Gaze，通过结合IMU和持续学习技术，实现移动端注视跟踪的动态校准，显著降低误差。|
|🆕 发布|FingerVeinSyn-5M: A Million-Scale Dataset and Benchmark for Finger Vein Recognition|指纹静脉识别的百万规模数据集和基准：FingerVeinSyn-5M|Yinfan Wang, Jie Gui, Baosheng Yu, Qi Li, Zhenan Sun, Juho Kannala, Guoying Zhao|<http://arxiv.org/pdf/2506.03635v1>|[代码](https://github.com/EvanWang98/FingerVeinSyn-5M.); 构建了大规模合成指纹静脉数据集，显著提升了指纹静脉识别模型性能。|
|🆕 发布|Isharah: A Large-Scale Multi-Scene Dataset for Continuous Sign Language Recognition|《Isharah：用于连续手语识别的大规模多场景数据集》|Sarah Alyami, Hamzah Luqman, Sadam Al-Azani, Maad Alowaifeer, Yazeed Alharbi, Yaser Alonaizan|<http://arxiv.org/pdf/2506.03615v1>|[代码](https://snalyami.github.io/Isharah_CSLR); 构建了首个大规模、多场景、非约束环境下的连续手语识别数据集，推动手语理解模型发展。|
|📝 更新|Moving Beyond Discrete Categories: Continuous Demographic Labels for Fair Facial Recognition|超越离散类别：公平面部识别的连续人口标签|Pedro C. Neto, Naser Damer, Jaime S. Cardoso, Ana F. Sequeira|<http://arxiv.org/pdf/2506.01532v2>|提出将种族标签作为连续变量而非离散值，以实现更公平的人脸识别。|
|🆕 发布|Heterogeneous Skeleton-Based Action Representation Learning|异构骨骼动作表示学习|Hongsong Wang, Xiaoyan Ma, Jidong Kuang, Jie Gui|<http://arxiv.org/pdf/2506.03481v1>|针对骨骼数据异质性问题，提出了一种融合三维骨骼处理和统一表示学习的动作识别框架。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Language-Image Alignment with Fixed Text Encoders|语言-图像对齐与固定文本编码器|Jingfeng Yang, Ziyang Wu, Yue Zhao, Yi Ma|<http://arxiv.org/pdf/2506.04209v1>|提出LIFT方法，仅训练图像编码器即能实现与CLIP相当的语言-图像对齐效果。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Bézier Splatting for Fast and Differentiable Vector Graphics Rendering|贝塞尔斯普拉特快速且可微分的矢量图形渲染|Xi Liu, Chaoyi Zhou, Nanxuan Zhao, Siyu Huang|<http://arxiv.org/pdf/2503.16424v3>|引入Bezier Splatting，实现快速且高保真矢量图形渲染，显著提升优化速度和视觉质量。|
|🆕 发布|Identifying Alzheimer's Disease Prediction Strategies of Convolutional Neural Network Classifiers using R2* Maps and Spectral Clustering|利用R2*图和谱聚类识别卷积神经网络分类器的阿尔茨海默病预测策略|Christian Tinauer, Maximilian Sackl, Stefan Ropele, Christian Langkammer|<http://arxiv.org/pdf/2506.03890v1>|利用R2*图和谱聚类分析，揭示了卷积神经网络在阿尔茨海默病预测中的决策策略差异。|
|🆕 发布|Robust Neural Rendering in the Wild with Asymmetric Dual 3D Gaussian Splatting|鲁棒野外神经渲染：非对称双3D高斯分层|Chengqi Li, Zhihao Shi, Yangdi Lu, Wenbo He, Xiangyu Xu|<http://arxiv.org/pdf/2506.03538v1>|提出了一种基于不对称双3D高斯分层的新框架，有效解决了野外图像3D重建中的稳定性和一致性难题。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Person Re-Identification System at Semantic Level based on Pedestrian Attributes Ontology|基于行人属性本体在语义层面的行人重识别系统|Ngoc Q. Ly, Hieu N. M. Cao, Thi T. Nguyen|<http://arxiv.org/pdf/2506.04143v1>|提出基于语义层和属性平衡的统一行人重识别系统，有效解决数据不平衡问题并提升识别性能。|
|📝 更新|FaceSleuth: Learning-Driven Single-Orientation Attention Verifies Vertical Dominance in Micro-Expression Recognition|FaceSleuth：学习驱动的单方向注意力验证微表情识别中的垂直主导性|Linquan Wu, Tianxiang Jiang, Wenhao Duan, Yini Fang, Jacky Keung|<http://arxiv.org/pdf/2506.02695v2>|FaceSleuth通过垂直注意力机制和单方向注意力模块，有效提升了微表情识别的准确率。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Point Cloud Quality Assessment Using the Perceptual Clustering Weighted Graph (PCW-Graph) and Attention Fusion Network|基于感知聚类加权图（PCW-Graph）和注意力融合网络的点云质量评估|Abdelouahed Laazoufi, Mohammed El Hassouni, Hocine Cherifi|<http://arxiv.org/pdf/2506.04081v1>|提出了一种基于感知聚类加权图和注意力融合网络的点云质量评估方法，有效评估无参考3D内容。|
|🆕 发布|GlobalBuildingAtlas: An Open Global and Complete Dataset of Building Polygons, Heights and LoD1 3D Models|全球建筑图集：一个开放的全全球建筑多边形、高度和LoD1 3D模型完整数据集|Xiao Xiang Zhu, Sining Chen, Fahong Zhang, Yilei Shi, Yuanyuan Wang|<http://arxiv.org/pdf/2506.04106v1>|构建了首个全球范围内完整覆盖的建筑物多边形、高度和LoD1 3D模型数据库，大幅提升了地理空间分析能...|
|🆕 发布|Conformal coronary calcification volume estimation with conditional coverage via histogram clustering|基于直方图聚类的条件覆盖下的冠状动脉钙化体积估计|Olivier Jaubert, Salman Mohammadi, Keith A. Goatman, Shadia S. Mikhael, Conor Bradley, Rebecca Hughes, Richard Good, John H. Hipwell .etc.|<http://arxiv.org/pdf/2506.04030v1>|提出了一种基于聚类和条件预测的框架，以准确估计冠状动脉钙化体积，避免过度报告。|
|🆕 发布|OSGNet @ Ego4D Episodic Memory Challenge 2025|OSGNet @ Ego4D 经典记忆挑战 2025|Yisen Feng, Haoyu Zhang, Qiaohui Chu, Meng Liu, Weili Guan, Yaowei Wang, Liqiang Nie|<http://arxiv.org/pdf/2506.03710v1>|[代码](https://github.com/Yisen-Feng/OSGNet.); 采用早期融合策略，OSGNet在Ego4D挑战赛中实现视频定位任务的三项第一。|
|📝 更新|Prescribing the Right Remedy: Mitigating Hallucinations in Large Vision-Language Models via Targeted Instruction Tuning|精准施策：通过针对性指令微调减轻大型视觉-语言模型中的幻觉|Rui Hu, Yahan Tu, Shuyu Wei, Dongyuan Lu, Jitao Sang|<http://arxiv.org/pdf/2404.10332v2>|针对大型视觉语言模型中的幻觉问题，提出了一种基于模型幻觉特异性的针对性指令数据生成框架，有效缓解了模...|
|📝 更新|Beyond Entropy: Region Confidence Proxy for Wild Test-Time Adaptation|超越熵：用于野外观测时自适应的区域置信度代理|Zixuan Hu, Yichun Hu, Xiaotong Li, Shixiang Tang, Ling-Yu Duan|<http://arxiv.org/pdf/2505.20704v2>|提出了一种基于区域信心的WTTA方法，有效提升了模型在极端数据稀缺和多个域变化下的适应效率。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EasyInv: Toward Fast and Better DDIM Inversion|EasyInv：迈向快速且更好的DDIM反演|Ziyue Zhang, Mingbao Lin, Shuicheng Yan, Rongrong Ji|<http://arxiv.org/pdf/2408.05159v4>|[代码](https://github.com/potato-kitty/EasyInv.); EasyInv通过优化DDIM逆变换过程，显著提升效率和准确性。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Optimal Transport-based Domain Alignment as a Preprocessing Step for Federated Learning|基于最优传输的联邦学习域对齐预处理步骤|Luiz Manella Pereira, M. Hadi Amini|<http://arxiv.org/pdf/2506.04071v1>|提出了一种基于最优传输的预处理算法，通过最小化边缘设备数据分布差异来优化联邦学习中的数据集不平衡问题...|
|📝 更新|CondiMen: Conditional Multi-Person Mesh Recovery|条件多人体网格恢复：CondiMen|Brégier Romain, Baradel Fabien, Lucas Thomas, Galaaoui Salma, Armando Matthieu, Weinzaepfel Philippe, Rogez Grégory|<http://arxiv.org/pdf/2412.13058v2>|CondiMen通过贝叶斯网络输出联合概率分布，有效解决多人体态恢复中的模糊性和不确定性。|
|📝 更新|Multi-Source Collaborative Style Augmentation and Domain-Invariant Learning for Federated Domain Generalization|多源协同风格增强与联邦域泛化中的域不变学习|Yikang Wei|<http://arxiv.org/pdf/2505.10152v2>|提出了一种多源协同风格增强和域不变学习方法，显著提升了联邦域泛化性能。|
|🆕 发布|CoLa: Chinese Character Decomposition with Compositional Latent Components|CoLa：基于组合潜在成分的汉字分解|Fan Shi, Haiyang Yu, Bin Li, Xiangyang Xue|<http://arxiv.org/pdf/2506.03798v1>|提出了一种基于组合潜在成分的汉字分解模型，实现零样本汉字识别。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Estimating Total Lung Volume from Pixel-level Thickness Maps of Chest Radiographs Using Deep Learning|基于深度学习的胸部X光片像素级厚度图估计总肺体积|Tina Dorosti, Manuel Schultheiss, Philipp Schmette, Jule Heuchert, Johannes Thalhammer, Florian T. Gassert, Thorsten Sellerer, Rafael Schick .etc.|<http://arxiv.org/pdf/2110.12509v6>|利用U-Net深度学习模型生成像素级肺厚度图，成功估计了合成和真实胸片的总肺体积。|
|🆕 发布|Advancing Multimodal Reasoning: From Optimized Cold Start to Staged Reinforcement Learning|推进多模态推理：从优化冷启动到分阶段强化学习|Shuang Chen, Yue Guo, Zhaochen Su, Yafu Li, Yulun Wu, Jiacheng Chen, Jiayu Chen, Weijie Wang .etc.|<http://arxiv.org/pdf/2506.04207v1>|提出了一种分阶段训练方法，通过优化冷启动初始化和改进多模态强化学习，显著提升了多模态大语言模型推理能...|
|🆕 发布|Vocabulary-free few-shot learning for Vision-Language Models|无词汇的视觉-语言模型小样本学习|Maxime Zanella, Clément Fuchs, Ismail Ben Ayed, Christophe De Vleeschouwer|<http://arxiv.org/pdf/2506.04005v1>|[代码](https://github.com/MaxZanella/vocabulary-free-FSL.); 提出了一种无需词汇表的视觉语言模型少样本学习方法，通过相似度映射实现高效分类。|
|📝 更新|Two-stage deep learning framework for the restoration of incomplete-ring PET images|两阶段深度学习框架用于不完整环PET图像的恢复|Yeqi Fang, Rong Zhou|<http://arxiv.org/pdf/2504.00816v3>|提出了一种两阶段深度学习框架，有效恢复不完整环PET图像，显著提升图像质量。|
|🆕 发布|Adapt before Continual Learning|在持续学习之前进行自适应|Aojun Lu, Tao Feng, Hangjie Yuan, Chunhui Ding, Yanan Sun|<http://arxiv.org/pdf/2506.03956v1>|提出ACL框架，通过预适应PTM骨架，平衡稳定性与可塑性，显著提升基于PTM的持续学习能力。|
|🆕 发布|Rethinking the Stability-Plasticity Trade-off in Continual Learning from an Architectural Perspective|重新从架构角度思考持续学习中的稳定性-塑性权衡|Aojun Lu, Hangjie Yuan, Tao Feng, Yanan Sun|<http://arxiv.org/pdf/2506.03951v1>|提出了一种名为Dual-Arch的框架，通过结合深度和宽度网络解决连续学习中的稳定性-可塑性权衡问题...|
|🆕 发布|Multiple Stochastic Prompt Tuning for Practical Cross-Domain Few Shot Learning|多随机提示调优在实用跨域小样本学习中的应用|Debarshi Brahma, Soma Biswas|<http://arxiv.org/pdf/2506.03926v1>|提出MIST框架，通过多随机提示和可学习高斯分布，有效解决跨域小样本学习问题。|
|📝 更新|Towards a deep learning approach for classifying treatment response in glioblastomas|迈向胶质母细胞瘤治疗反应分类的深度学习方法|Ana Matoso, Catarina Passarinho, Marta P. Loureiro, José Maria Moreira, Patrícia Figueiredo, Rita G. Nunes|<http://arxiv.org/pdf/2504.18268v2>|开发了一种基于深度学习的RANO标准响应分类方法，提高了胶质母细胞瘤治疗反应评估的效率和准确性。|
|📝 更新|Skywork R1V2: Multimodal Hybrid Reinforcement Learning for Reasoning|天空工作R1V2：多模态混合强化学习推理|Chris, Yichen Wei, Yi Peng, Xiaokun Wang, Weijie Qiu, Wei Shen, Tianyidan Xie, Jiangbo Pei .etc.|<http://arxiv.org/pdf/2504.16656v3>|Skywork R1V2通过混合强化学习，结合MPO和GRPO，有效平衡推理能力与泛化性，显著提升多...|
|📝 更新|FlySearch: Exploring how vision-language models explore|飞搜：探索视觉-语言模型如何探索|Adam Pardyl, Dominik Matuszek, Mateusz Przebieracz, Marek Cygan, Bartosz Zieliński, Maciej Wołczyk|<http://arxiv.org/pdf/2506.02896v2>|FlySearch通过构建复杂场景搜索与导航基准，揭示了视觉语言模型在探索任务中的局限性并提出了改进...|
|🆕 发布|ConText: Driving In-context Learning for Text Removal and Segmentation|ConText：文本去除与分割的上下文驱动学习|Fei Zhang, Pei Zhang, Baosong Yang, Fei Huang, Yanfeng Wang, Ya Zhang|<http://arxiv.org/pdf/2506.03799v1>|[代码](https://github.com/Ferenas/ConText.); 提出ConText模型，通过任务链式组合器和上下文感知聚合，实现文本去除和分割的视觉情境学习。|
|📝 更新|A Flag Decomposition for Hierarchical Datasets|基于层次数据集的旗帜分解|Nathan Mankovich, Ignacio Santamaria, Gustau Camps-Valls, Tolga Birdal|<http://arxiv.org/pdf/2502.07782v2>|提出了一种基于旗分解的算法，用于处理和分解层次化数据集。|
|📝 更新|Crowd Scene Analysis using Deep Learning Techniques|基于深度学习技术的拥挤场景分析|Muhammad Junaid Asif|<http://arxiv.org/pdf/2505.08834v2>|提出自监督训练和多列CNN结合的方法，有效解决人群计数和异常检测问题。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Kinship in Speech: Leveraging Linguistic Relatedness for Zero-Shot TTS in Indian Languages|语音中的亲属关系：利用语言相关性进行印度语种零样本TTS|Utkarsh Pathak, Chandra Sai Krishna Gunda, Anusha Prakash, Keshav Agarwal, Hema A. Murthy|<http://arxiv.org/pdf/2506.03884v1>|利用语言关联性，通过调整文本解析规则和共享音素表示，实现印度语言零样本语音合成。|
|🆕 发布|AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives|AetherVision-Bench：一个针对空中和地面视角多角度分割的开放词汇RGB-红外基准|Aniruddh Sikdar, Aditya Gandhamal, Suresh Sundaram|<http://arxiv.org/pdf/2506.03709v1>|构建了AetherVision-Bench基准，评估多角度语义分割，促进开放词汇语义分割模型在跨域泛...|
|📝 更新|Improving Knowledge Distillation Under Unknown Covariate Shift Through Confidence-Guided Data Augmentation|通过置信度引导的数据增强改善未知协变量偏移下的知识蒸馏|Niclas Popp, Kevin Alexander Laube, Matthias Hein, Lukas Schott|<http://arxiv.org/pdf/2506.02294v2>|通过引入基于差异最大化的数据增强策略，有效提升知识蒸馏在未知协变量偏移情况下的学生网络鲁棒性。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Right Side Up? Disentangling Orientation Understanding in MLLMs with Fine-grained Multi-axis Perception Tasks|《正立吗？通过细粒度多轴感知任务在多模态语言模型中解耦方向理解》|Keanu Nichols, Nazia Tasnim, Yuting Yan, Nicholas Ikechukwu, Elva Zou, Deepti Ghadiyaram, Bryan A. Plummer|<http://arxiv.org/pdf/2505.21649v4>|提出DORI基准，揭示多模态系统在物体方向理解上的局限性。|
|📝 更新|SEM: Enhancing Spatial Understanding for Robust Robot Manipulation|SEM：增强空间理解以实现鲁棒的机器人操作|Xuewu Lin, Tianwei Lin, Lichao Huang, Hongyu Xie, Yiwei Jin, Keyu Li, Zhizhong Su|<http://arxiv.org/pdf/2505.16196v2>|提出SEM模型，通过增强空间理解提升机器人操作鲁棒性和泛化能力。|


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spatial Understanding from Videos: Structured Prompts Meet Simulation Data|从视频中理解空间：结构化提示与仿真数据|Haoyu Zhang, Meng Liu, Zaijing Li, Haokun Wen, Weili Guan, Yaowei Wang, Liqiang Nie|<http://arxiv.org/pdf/2506.03642v1>|提出结构化提示与模拟数据结合，提升预训练视觉语言模型的三维空间推理能力。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Rex-Thinker: Grounded Object Referring via Chain-of-Thought Reasoning|Rex-Thinker：基于思维链推理的 grounded 对象指称|Qing Jiang, Xingyu Chen, Zhaoyang Zeng, Junzhi Yu, Lei Zhang|<http://arxiv.org/pdf/2506.04034v1>|提出Rex-Thinker模型，通过思维链推理实现可解释且可靠的物体指称。|
|🆕 发布|DynTok: Dynamic Compression of Visual Tokens for Efficient and Effective Video Understanding|动态视觉标记压缩：高效有效的视频理解|Hongzhi Zhang, Jingyuan Zhang, Xingguang Ji, Qi Wang, Fuzheng Zhang|<http://arxiv.org/pdf/2506.03990v1>|提出DynTok动态压缩视觉标记策略，有效减少视频理解中的计算负担。|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Go Beyond Earth: Understanding Human Actions and Scenes in Microgravity Environments|超越地球：理解微重力环境中的人类动作与场景|Di Wen, Lei Qi, Kunyu Peng, Kailun Yang, Fei Teng, Ao Luo, Jia Fu, Yufan Chen .etc.|<http://arxiv.org/pdf/2506.02845v2>|[代码](https://github.com/LEI-QI-233/HAR-in-Space.); 构建首个微重力环境下的动作和场景理解基准MicroG-4M，推动空间应用中的视频理解。|
|🆕 发布|Vision Remember: Alleviating Visual Forgetting in Efficient MLLM with Vision Feature Resample|视觉记忆：通过视觉特征重采样缓解高效多模态语言模型中的视觉遗忘|Ze Feng, Jiang-Jiang Liu, Sen Yang, Lingyu Xiao, Xiaofan Li, Wankou Yang, Jingdong Wang|<http://arxiv.org/pdf/2506.03928v1>|提出Vision Remember，通过局部注意力机制增强视觉特征重采样，缓解视觉遗忘问题，提升高效...|
|📝 更新|AlignMMBench: Evaluating Chinese Multimodal Alignment in Large Vision-Language Models|AlignMMBench：评估大型视觉-语言模型中的中文多模态对齐|Yuhang Wu, Wenmeng Yu, Yean Cheng, Yan Wang, Xiaohan Zhang, Jiazheng Xu, Ming Ding, Yuxiao Dong|<http://arxiv.org/pdf/2406.09295v3>|[代码](https://github.com/THUDM/AlignMMBench.); 提出AlignMMBench，首个针对中文视觉场景的多模态对齐能力基准，评估大型视觉语言模型的有效性...|
|🆕 发布|ROSA: Addressing text understanding challenges in photographs via ROtated SAmpling|ROSA：通过旋转采样解决照片中的文本理解挑战|Hernán Maina, Guido Ivetta, Mateo Lione Stuto, Julian Martin Eisenschlos, Jorge Sánchez, Luciana Benotti|<http://arxiv.org/pdf/2506.03665v1>|提出ROSA解码策略，提升视觉问答系统在倾斜文本图像中的理解能力。|
|📝 更新|The Role of Visual Modality in Multimodal Mathematical Reasoning: Challenges and Insights|视觉模态在多模态数学推理中的作用：挑战与启示|Yufang Liu, Yao Du, Tao Ji, Jianing Wang, Yang Liu, Yuanbin Wu, Aimin Zhou, Mengdi Zhang .etc.|<http://arxiv.org/pdf/2503.04167v2>|[代码](https://github.com/Yufang-Liu/visual_modality_role); 揭示了视觉信息在多模态数学推理中的重要性，并提出了HC-M3D数据集以增强模型对图像的依赖。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Pseudo-Simulation for Autonomous Driving|伪仿真在自动驾驶中的应用|Wei Cao, Marcel Hallgarten, Tianyu Li, Daniel Dauner, Xunjiang Gu, Caojun Wang, Yakov Miron, Marco Aiello .etc.|<http://arxiv.org/pdf/2506.04218v1>|[代码](https://github.com/autonomousvision/navsim.); 提出伪仿真方法，通过合成数据增强真实数据集，有效评估自动驾驶系统性能。|
|🆕 发布|A Diffusion-Driven Temporal Super-Resolution and Spatial Consistency Enhancement Framework for 4D MRI imaging|基于扩散驱动的4D MRI成像时间超分辨率和空间一致性增强框架|Xuanru Zhou, Jiarun Liu, Shoujun Yu, Hao Yang, Cheng Li, Tao Tan, Shanshan Wang|<http://arxiv.org/pdf/2506.04116v1>|提出TSSC-Net框架，通过扩散驱动时间超分辨率和空间一致性增强，实现快速运动下4D MRI的高分...|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Recent Advances in Medical Image Classification|医学图像分类的最新进展|Loan Dao, Ngoc Quoc Ly|<http://arxiv.org/pdf/2506.04129v1>|该论文综述了医疗图像分类的最新进展，聚焦于深度学习模型和可解释人工智能在解决数据稀缺和结果解释方面的...|
|📝 更新|Rapid Bone Scintigraphy Enhancement via Semantic Prior Distillation from Segment Anything Model|快速骨显像增强：通过从Segment Anything模型中蒸馏语义先验|Pengchen Liang, Leijun Shi, Huiping Yao, Bin Pu, Jianguo Chen, Lei Zhao, Haishan Huang, Zhuangzhuang Chen .etc.|<http://arxiv.org/pdf/2503.02321v3>|利用Segment Anything Model语义先验提升儿童快速骨显像图像质量。|
|🆕 发布|A Comprehensive Study on Medical Image Segmentation using Deep Neural Networks|基于深度神经网络的医学图像分割综合研究|Loan Dao, Ngoc Quoc Ly|<http://arxiv.org/pdf/2506.04121v1>|该论文全面研究了基于深度神经网络的医学图像分割，提出了解释性人工智能方法以提升透明度和诊断效率。|
|📝 更新|Comparing the Effects of Persistence Barcodes Aggregation and Feature Concatenation on Medical Imaging|比较持久条码聚合与特征拼接对医学影像的影响|Dashti A. Ali, Richard K. G. Do, William R. Jarnagin, Aras T. Asaad, Amber L. Simpson|<http://arxiv.org/pdf/2505.23637v2>|比较了持久性条码聚合和特征拼接对医学图像分类性能的影响，提出特征拼接方法更优。|
|📝 更新|CARL: Camera-Agnostic Representation Learning for Spectral Image Analysis|相机无关的表征学习用于光谱图像分析：CARL|Alexander Baumann, Leonardo Ayala, Silvia Seidlitz, Jan Sellner, Alexander Studier-Fischer, Berkin Özdemir, Lena Maier-Hein, Slobodan Ilic|<http://arxiv.org/pdf/2504.19223v2>|CARL通过波长位置编码和自注意力机制，实现了跨不同光谱相机模态的通用图像表示学习。|
|🆕 发布|Average Calibration Losses for Reliable Uncertainty in Medical Image Segmentation|平均校准损失以实现可靠的不确定性在医学图像分割中的应用|Theodore Barfoot, Luis C. Garcia-Peraza-Herrera, Samet Akcay, Ben Glocker, Tom Vercauteren|<http://arxiv.org/pdf/2506.03942v1>|[代码](https://github.com/cai4cai/Average-Calibration-Losses); 提出mL1-ACE辅助损失，有效降低医学图像分割的不确定性，提升分割预测的可靠性。|
|📝 更新|RAC3: Retrieval-Augmented Corner Case Comprehension for Autonomous Driving with Vision-Language Models|RAC3：基于视觉-语言模型的自动驾驶边缘案例理解检索增强|Yujin Wang, Quanfeng Liu, Jiaqi Fan, Jinlong Hong, Hongqing Chu, Mengjian Tian, Bingzhao Gao, Hong Chen|<http://arxiv.org/pdf/2412.11050v3>|RAC3通过检索增强和跨模态对齐，显著提升了视觉语言模型在自动驾驶场景理解中的准确性。|
|📝 更新|MedEBench: Revisiting Text-instructed Image Editing on Medical Domain|MedEBench：重新审视医学领域的文本指令图像编辑|Minghao Liu, Zhitao He, Zhiyuan Fan, Qingyun Wang, Yi R. Fung|<http://arxiv.org/pdf/2506.01921v3>|[代码](https://mliuby.github.io/MedEBench_Website); 构建了MedEBench基准，评估医疗图像文本引导编辑，推动临床应用。|
|🆕 发布|Personalized MR-Informed Diffusion Models for 3D PET Image Reconstruction|个性化基于MR信息的扩散模型在3D PET图像重建中的应用|George Webber, Alexander Hammers, Andrew P. King, Andrew J. Reader|<http://arxiv.org/pdf/2506.03804v1>|提出了一种利用个性化“伪PET”图像预训练扩散模型，显著提升3D PET图像重建准确性的方法。|
|🆕 发布|How PARTs assemble into wholes: Learning the relative composition of images|图像的相对组成学习：PARTs如何组装成整体|Melika Ayoughi, Samira Abnar, Chen Huang, Chris Sandino, Sayeri Lala, Eeshan Gunesh Dhekane, Dan Busbridge, Shuangfei Zhai .etc.|<http://arxiv.org/pdf/2506.03682v1>|通过利用非网格化补丁间的连续相对变换，PART学习图像的相对组成，突破网格限制，提升空间理解能力。|
|🆕 发布|Advancements in Artificial Intelligence Applications for Cardiovascular Disease Research|人工智能在心血管疾病研究中的应用进展|Yuanlin Mo, Haishan Huang, Bocheng Liang, Weibo Ma|<http://arxiv.org/pdf/2506.03698v1>|该论文提出利用深度学习提升心血管疾病诊断精度，同时强调验证数据准确性的重要性。|
|🆕 发布|INP-Former++: Advancing Universal Anomaly Detection via Intrinsic Normal Prototypes and Residual Learning|INP-Former++：通过内在正常原型和残差学习推进通用异常检测|Wei Luo, Haiming Yao, Yunkang Cao, Qiyu Chen, Ang Gao, Weiming Shen, Weihang Zhang, Wenyong Yu|<http://arxiv.org/pdf/2506.03660v1>|提出INP-Former++，通过内在正常原型和残差学习，显著提升通用异常检测性能。|
|📝 更新|MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization|MMedPO：与临床感知的多模态偏好优化对齐医学视觉-语言模型|Kangyu Zhu, Peng Xia, Yun Li, Hongtu Zhu, Sheng Wang, Huaxiu Yao|<http://arxiv.org/pdf/2412.06141v4>|[代码](https://github.com/aiming-lab/MMedPO.); MMedPO通过考虑偏好样本的临床相关性，有效提升了医学视觉-语言模型的准确性。|
|🆕 发布|PDSE: A Multiple Lesion Detector for CT Images using PANet and Deformable Squeeze-and-Excitation Block|PDSE：基于PANet和可变形 squeeze-and-excitation 块的CT图像多病灶检测器|Di Fan, Heng Yu, Zhiyuan Xu|<http://arxiv.org/pdf/2506.03608v1>|提出PDSE框架，结合PANet和可变形SE块，显著提升CT图像多类病变检测精度。|
|🆕 发布|Analyzing Transformer Models and Knowledge Distillation Approaches for Image Captioning on Edge AI|分析边缘AI中图像描述的Transformer模型和知识蒸馏方法|Wing Man Casca Kwok, Yip Chiu Tung, Kunal Bhagchandani|<http://arxiv.org/pdf/2506.03607v1>|提出了一种在边缘设备上高效运行的轻量级Transformer图像描述模型，通过知识蒸馏技术加速推理同...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Galileo: Learning Global & Local Features of Many Remote Sensing Modalities|伽利略：学习多种遥感模态的全局与局部特征|Gabriel Tseng, Anthony Fuller, Marlena Reil, Henry Herzog, Patrick Beukema, Favyen Bastani, James R. Green, Evan Shelhamer .etc.|<http://arxiv.org/pdf/2502.09356v3>|Galileo通过自监督学习，提取多尺度特征，实现多模态遥感数据共享表示，提升遥感任务性能。|
|🆕 发布|A Large-Scale Referring Remote Sensing Image Segmentation Dataset and Benchmark|大规模指代遥感图像分割数据集和基准|Zhigang Yang, Huiguang Yao, Linmao Tian, Xuezhi Zhao, Qiang Li, Qi Wang|<http://arxiv.org/pdf/2506.03583v1>|[代码](https://github.com/CVer-Yang/NWPU-Refer.); 构建了大规模遥感图像分割数据集NWPU-Refer，并提出MRSNet模型，显著提升分割性能。|
|📝 更新|Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation|信息驱动自适应丢弃率以提升推理时不确定性估计|Tal Zeevi, Ravid Shwartz-Ziv, Yann LeCun, Lawrence H. Staib, John A. Onofrey|<http://arxiv.org/pdf/2412.07169v4>|提出Rate-In算法，动态调整推理时dropout率，优化预测不确定性估计。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Seeing in the Dark: Benchmarking Egocentric 3D Vision with the Oxford Day-and-Night Dataset|在黑暗中看见：使用牛津日夜数据集对自视角3D视觉进行基准测试|Zirui Wang, Wenjing Bian, Xinghui Li, Yifu Tao, Jianeng Wang, Maurice Fallon, Victor Adrian Prisacariu|<http://arxiv.org/pdf/2506.04224v1>|构建了Oxford Day-and-Night数据集，通过多会话SLAM实现暗光条件下的新型视角合成...|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection|从噪声中学习：通过可控噪声注入增强事件视觉中的深度神经网络|Marcin Kowalczyk, Kamil Jeziorek, Tomasz Kryjak|<http://arxiv.org/pdf/2506.03918v1>|[代码](https://github.com/vision-agh/DVS_Filtering); 通过在训练数据中注入可控噪声，该方法增强了深度神经网络对事件视觉噪声的鲁棒性。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Diffusing DeBias: Synthetic Bias Amplification for Model Debiasing|扩散去偏：用于模型去偏的合成偏差放大|Massimiliano Ciranni, Vito Paolo Pastore, Roberto Di Via, Enzo Tartaglione, Francesca Odone, Vittorio Murino|<http://arxiv.org/pdf/2502.09564v4>|提出Diffusing DeBias方法，利用生成合成数据解决深度学习模型中的数据偏差问题。|
|📝 更新|DualMap: Online Open-Vocabulary Semantic Mapping for Natural Language Navigation in Dynamic Changing Scenes|双图映射：动态变化场景中自然语言导航的在线开放词汇语义映射|Jiajun Jiang, Yiming Zhu, Zirui Wu, Jie Song|<http://arxiv.org/pdf/2506.01950v2>|DualMap通过混合分割和双重地图表示，实现了动态场景中的在线开放词汇语义映射和导航。|
|🆕 发布|Analytical Reconstruction of Periodically Deformed Objects in Time-resolved CT|时间分辨CT中周期性变形物体的解析重建|Qianwei Qu, Christian M. Schlepütz, Marco Stampanoni|<http://arxiv.org/pdf/2506.03792v1>|提出了一种基于周期性变形物体分析的CT重建方法，有效降低辐射剂量并提高重建图像质量。|

