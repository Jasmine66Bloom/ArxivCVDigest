## [UPDATED!] **2025-06-05** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Can Foundation Models Generalise the Presentation Attack Detection Capabilities on ID Cards?|基础模型能否泛化身份证上的呈现攻击检测能力？|Juan E. Tapia, Christoph Busch|<http://arxiv.org/pdf/2506.05263v1>|利用基础模型提升身份证防伪检测泛化能力，以应对不同国家身份证的检测挑战。|
|🆕 发布|Towards Vision-Language-Garment Models For Web Knowledge Garment Understanding and Generation|面向网络知识服装理解的视觉-语言-服装模型构建|Jan Ackermann, Kiyohiro Nakayama, Guandao Yang, Tong Wu, Gordon Wetzstein|<http://arxiv.org/pdf/2506.05210v1>|提出VLG模型，通过文本和视觉信息合成服装，实现跨领域知识迁移。|
|🆕 发布|Single GPU Task Adaptation of Pathology Foundation Models for Whole Slide Image Analysis|单GPU病理基础模型的全切片图像分析任务自适应|Neeraj Kumar, Swaraj Nanda, Siddharth Singi, Jamal Benhamida, David Kim, Jie-Fu Chen, Amir Momeni-Boroujeni, Gregory M. Goldgof .etc.|<http://arxiv.org/pdf/2506.05184v1>|提出了一种基于视觉Transformer的MIL聚合方法，有效提升了病理基础模型在临床任务中的适应性...|
|📝 更新|GenLit: Reformulating Single-Image Relighting as Video Generation|GenLit：将单图像重光照重新表述为视频生成|Shrisha Bharadwaj, Haiwen Feng, Giorgio Becherini, Victoria Abrevaya, Michael J. Black|<http://arxiv.org/pdf/2412.11224v2>|将单图重光照问题转化为视频生成，利用视频扩散模型实现高效且逼真的光照调整。|
|📝 更新|David and Goliath: Small One-step Model Beats Large Diffusion with Score Post-training|大卫与歌利亚：小型一步模型在评分后训练中击败大型扩散模型|Weijian Luo, Colin Zhang, Debing Zhang, Zhengyang Geng|<http://arxiv.org/pdf/2410.20898v3>|[代码](https://github.com/pkulwj1994/diff_instruct_star.); 提出DI*后训练方法，使小型一步生成模型在图像奖励、选择分数和CLIP分数上超越大型多步扩散模型。|
|🆕 发布|OpenMaskDINO3D : Reasoning 3D Segmentation via Large Language Model|OpenMaskDINO3D：通过大型语言模型进行3D分割推理|Kunshen Zhang|<http://arxiv.org/pdf/2506.04837v1>|提出OpenMaskDINO3D，通过大语言模型实现3D理解与分割，无需预设类别，直接从自然语言指令...|
|🆕 发布|MMRefine: Unveiling the Obstacles to Robust Refinement in Multimodal Large Language Models|MMRefine：揭示多模态大型语言模型稳健精炼的障碍|Gio Paik, Geewook Kim, Jinbae Im|<http://arxiv.org/pdf/2506.04688v1>|[代码](https://github.com/naver-ai/MMRefine.); MMRefine提出多模态大语言模型错误修正基准，揭示其推理中有效推理增强的障碍。|
|📝 更新|Efficiently Serving Large Multimodal Models Using EPD Disaggregation|高效服务大型多模态模型：基于EPD解耦|Gursimran Singh, Xinglu Wang, Yifan Hu, Timothy Yu, Linzi Xing, Wei Jiang, Zhefeng Wang, Xiaolong Bai .etc.|<http://arxiv.org/pdf/2501.05460v3>|[代码](https://github.com/vbdi/epdserve.); 提出EPD解耦框架，有效提升大型多模态模型服务效率。|
|🆕 发布|Unfolding Spatial Cognition: Evaluating Multimodal Models on Visual Simulations|空间认知展开：在视觉模拟中评估多模态模型|Linjie Li, Mahtab Bigverdi, Jiawei Gu, Zixian Ma, Yinuo Yang, Ziang Li, Yejin Choi, Ranjay Krishna|<http://arxiv.org/pdf/2506.04633v1>|提出STARE基准，评估多模态模型在视觉模拟任务上的表现，揭示模型在复杂任务上的局限性。|
|📝 更新|OCRBench v2: An Improved Benchmark for Evaluating Large Multimodal Models on Visual Text Localization and Reasoning|OCRBench v2：用于评估大型多模态模型在视觉文本定位与推理上的改进基准|Ling Fu, Zhebin Kuang, Jiajun Song, Mingxin Huang, Biao Yang, Yuzhe Li, Linghao Zhu, Qidi Luo .etc.|<http://arxiv.org/pdf/2501.00321v2>|[代码](https://99franklin.github.io/ocrbench_v2); 构建了OCR Bench v2，全面评估大型多模态模型在视觉文本定位和推理上的能力。|
|🆕 发布|StatsMerging: Statistics-Guided Model Merging via Task-Specific Teacher Distillation|StatsMerging：基于任务特定教师蒸馏的统计引导模型合并|Ranjith Merugu, Bryan Bo Cao, Shubham Jain|<http://arxiv.org/pdf/2506.04567v1>|StatsMerging通过利用SVD和轻量级学习，实现了无需标签的模型合并，提高了模型泛化能力和鲁...|
|🆕 发布|Handle-based Mesh Deformation Guided By Vision Language Model|基于视觉语言模型的基于手柄的网格变形|Xingpeng Sun, Shiyang Jia, Zherong Pan, Kui Wu, Aniket Bera|<http://arxiv.org/pdf/2506.04562v1>|利用视觉语言模型自动识别和变形3D模型，实现高质量的无需训练的网格变形。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MokA: Multimodal Low-Rank Adaptation for MLLMs|MokA：多模态低秩自适应用于多语言语言模型|Yake Wei, Yu Miao, Dongzhan Zhou, Di Hu|<http://arxiv.org/pdf/2506.05191v1>|[代码](https://gewu-lab.github.io/MokA.); 提出MokA方法，通过多模态低秩自适应优化多模态LLMs的微调效果。|
|📝 更新|DREAM: Disentangling Risks to Enhance Safety Alignment in Multimodal Large Language Models|DREAM：解耦风险以增强多模态大型语言模型的安全对齐|Jianyu Liu, Hangyu Guo, Ranjie Duan, Xingyuan Bu, Yancheng He, Shilong Li, Hui Huang, Jiaheng Liu .etc.|<http://arxiv.org/pdf/2504.18053v2>|[代码](https://github.com/Kizna1ver/DREAM.); 提出DREAM方法，通过多模态风险解耦和强化学习，提升多模态大语言模型的安全性和性能。|
|🆕 发布|PixCell: A generative foundation model for digital histopathology images|PixCell：数字病理图像的生成基础模型|Srikar Yellapragada, Alexandros Graikos, Zilinghan Li, Kostas Triaridis, Varun Belagali, Saarthak Kapse, Tarak Nath Nandi, Ravi K Madduri .etc.|<http://arxiv.org/pdf/2506.05127v1>|提出PixCell，首个基于扩散模型的病理图像生成模型，解决病理图像合成和数据共享问题。|
|🆕 发布|Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model|面向人工智能生成视频的全面视觉质量评估：基于大型语言模型的多元评估模型|Zelu Qi, Ping Shi, Chaoyang Zhang, Shuqi Wang, Fei Zhao, Da Pan, Zefeng Ying|<http://arxiv.org/pdf/2506.04715v1>|[代码](https://github.com/QiZelu/AIGVEval.); 提出了一种基于LLM的多维度AI生成视频质量评估模型，有效解决视觉质量缺陷问题。|
|📝 更新|GarmageNet: A Multimodal Generative Framework for Sewing Pattern Design and Generic Garment Modeling|GarmageNet：一种用于缝纫图案设计和通用服装建模的多模态生成框架|Siran Li, Ruiyang Liu, Chen Liu, Zhendong Wang, Gaofeng He, Yong-Lu Li, Xiaogang Jin, Huamin Wang|<http://arxiv.org/pdf/2504.01483v2>|[代码](https://style3d.github.io/garmagenet.); GarmageNet通过统一生成框架和新型服装表示，自动化2D缝纫图案到3D服装的转换，实现数字时尚...|
|📝 更新|MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable Step-Level Supervision|MM-PRM：通过可扩展的步骤级监督增强多模态数学推理|Lingxiao Du, Fanqing Meng, Zongkai Liu, Zhixiang Zhou, Ping Luo, Qiaosheng Zhang, Wenqi Shao|<http://arxiv.org/pdf/2505.13427v2>|[代码](https://github.com/ModalMinds/MM-PRM.); 提出MM-PRM模型，通过过程级监督增强多模态数学推理能力。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Interpretable Multimodal Framework for Human-Centered Street Assessment: Integrating Visual-Language Models for Perceptual Urban Diagnostics|可解释的人本化街道评估多模态框架：整合视觉-语言模型进行感知城市诊断|HaoTian Lan|<http://arxiv.org/pdf/2506.05087v1>|构建了融合视觉和语言模型的框架，以实现可解释的街道评估，提升城市设计中的主观感知分析。|
|🆕 发布|Feature-Based Lie Group Transformer for Real-World Applications|基于特征的黎曼群变换器在现实世界应用中的研究|Takayuki Komatsu, Yoshiyuki Ohmura, Kayato Nishitsunoi, Yasuo Kuniyoshi|<http://arxiv.org/pdf/2506.04668v1>|提出了一种基于特征和对象分割的Lie群变换方法，以实现更真实的现实世界应用。|
|📝 更新|MambaNeXt-YOLO: A Hybrid State Space Model for Real-time Object Detection|MambaNeXt-YOLO：一种用于实时目标检测的混合状态空间模型|Xiaochun Lei, Siqi Wu, Weilin Wu, Zetao Jiang|<http://arxiv.org/pdf/2506.03654v2>|MambaNeXt-YOLO通过融合CNN和Mamba模型，实现高效实时目标检测。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Grounding Beyond Detection: Enhancing Contextual Understanding in Embodied 3D Grounding|超越检测：增强具身3D定位中的上下文理解|Yani Zhang, Dongming Wu, Hao Shi, Yingfei Liu, Tiancai Wang, Haoqiang Fan, Xingping Dong|<http://arxiv.org/pdf/2506.05199v1>|[代码](https://github.com/zyn213/DEGround.); 提出DEGround方法，通过共享检测查询增强3D定位的上下文理解。|
|🆕 发布|Bridging Annotation Gaps: Transferring Labels to Align Object Detection Datasets|弥合标注差距：将标签迁移以对齐目标检测数据集|Mikhail Kennerley, Angelica Alives-Reviro, Carola-Bibiane Schönlieb, Robby T. Tan|<http://arxiv.org/pdf/2506.04737v1>|提出了一种跨数据集标签对齐方法，通过投影和融合标注，提升目标检测性能。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DACN: Dual-Attention Convolutional Network for Hyperspectral Image Super-Resolution|双注意力卷积网络用于高光谱图像超分辨率|Usman Muhammad, Jorma Laaksonen|<http://arxiv.org/pdf/2506.05041v1>|DACN通过结合多头和通道注意力机制，有效提升了高光谱图像超分辨率性能。|
|🆕 发布|CzechLynx: A Dataset for Individual Identification and Pose Estimation of the Eurasian Lynx|捷克林克斯：用于欧亚猞猁个体识别和姿态估计的数据集|Lukas Picek, Elisa Belotti, Michal Bojda, Ludek Bufka, Vojtech Cermak, Martin Dula, Rostislav Dvorak, Luboslav Hrdy .etc.|<http://arxiv.org/pdf/2506.04931v1>|构建了首个用于欧亚猞猁个体识别、姿态估计和实例分割的大型开放数据集CzechLynx。|
|🆕 发布|SupeRANSAC: One RANSAC to Rule Them All|苏佩RANSAC：一RANSAC统治所有|Daniel Barath|<http://arxiv.org/pdf/2506.04803v1>|[代码](https://github.com/danini/superansac); SupeRANSAC提出了一种统一的RANSAC流程，显著提升了计算机视觉中几何模型估计的准确性和一...|
|🆕 发布|VoxDet: Rethinking 3D Semantic Occupancy Prediction as Dense Object Detection|VoxDet：重新思考3D语义占用预测为密集目标检测|Wuyang Li, Zhu Yu, Alexandre Alahi|<http://arxiv.org/pdf/2506.04623v1>|将3D语义占用预测重新定义为密集目标检测，通过实例中心的方法提高了预测的完整性和准确性。|
|🆕 发布|EECD-Net: Energy-Efficient Crack Detection with Spiking Neural Networks and Gated Attention|EECD-Net：基于脉冲神经网络和门控注意力的节能裂缝检测|Shuo Zhang|<http://arxiv.org/pdf/2506.04526v1>|提出EECD-Net，通过稀疏脉冲序列和自适应注意力机制，实现高效且准确的路面裂缝检测。|
|🆕 发布|LGM-Pose: A Lightweight Global Modeling Network for Real-time Human Pose Estimation|LGM-Pose：一种用于实时人体姿态估计的轻量级全局建模网络|Biao Guo, Fangmin Guo, Guibo Luo, Xiaonan Luo, Feng Zhang|<http://arxiv.org/pdf/2506.04561v1>|提出LGM-Pose轻量级全局建模网络，解决实时人体姿态估计中全局信息捕捉与低延迟问题。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Point Cloud Segmentation of Agricultural Vehicles using 3D Gaussian Splatting|基于3D高斯散布的农业车辆点云分割|Alfred T. Christiansen, Andreas H. Højrup, Morten K. Stephansen, Md Ibtihaj A. Sakib, Taman S. Poojary, Filip Slezak, Morten S. Laursen, Thomas B. Moeslund .etc.|<http://arxiv.org/pdf/2506.05009v1>|利用3D高斯分层和透明度场生成农业车辆合成数据，显著提升点云分割模型性能。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Geological Field Restoration through the Lens of Image Inpainting|通过图像修复镜头进行地质现场恢复|Vladislav Trifonov, Ivan Oseledets, Ekaterina Muravleva|<http://arxiv.org/pdf/2506.04869v1>|利用图像修复技术重建地质场，显著提升重建精度。|
|🆕 发布|Interpretable Few-Shot Image Classification via Prototypical Concept-Guided Mixture of LoRA Experts|基于原型概念引导的LoRA专家混合的可解释小样本图像分类|Zhong Ji, Rongshuai Wei, Jingren Liu, Yanwei Pang, Jungong Han|<http://arxiv.org/pdf/2506.04673v1>|提出了一种基于原型概念学习的少样本图像分类框架，显著提升了模型解释性和分类准确率。|


## 生成式视觉模型 (Generative Visual Modeling)


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ContentV: Efficient Training of Video Generation Models with Limited Compute|内容V：在有限计算资源下高效训练视频生成模型|Wenfeng Lin, Renjie Chen, Boyuan Liu, Shiyue Yan, Ruoyu Feng, Jiangchuan Wei, Yichen Zhang, Yimeng Zhou .etc.|<http://arxiv.org/pdf/2506.05343v1>|ContentV通过高效训练策略，实现低计算成本下高质视频生成。|
|🆕 发布|Direct Numerical Layout Generation for 3D Indoor Scene Synthesis via Spatial Reasoning|直接通过空间推理进行3D室内场景合成的直接数值布局生成|Xingjian Ran, Yixuan Li, Linning Xu, Mulin Yu, Bo Dai|<http://arxiv.org/pdf/2506.05341v1>|提出DirectLayout，通过大语言模型的空间推理直接生成3D室内场景布局。|
|🆕 发布|SeedEdit 3.0: Fast and High-Quality Generative Image Editing|SeedEdit 3.0：快速且高质量的生成图像编辑|Peng Wang, Yichun Shi, Xiaochen Lian, Zhonghua Zhai, Xin Xia, Xuefeng Xiao, Weilin Huang, Jianchao Yang|<http://arxiv.org/pdf/2506.05083v1>|SeedEdit 3.0通过改进数据管理和联合学习，实现了快速且高质量的图像编辑。|
|🆕 发布|Follow-Your-Creation: Empowering 4D Creation through Video Inpainting|跟随你的创作：通过视频修复赋能四维创作|Yue Ma, Kunyu Feng, Xinhua Zhang, Hongyu Liu, David Junhao Zhang, Jinbo Xing, Yinhan Zhang, Ayden Yang .etc.|<http://arxiv.org/pdf/2506.04590v1>|提出了一种基于视频修复的4D视频创作框架，通过单目视频输入实现4D内容的生成与编辑。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Contrastive Flow Matching|对比流匹配|George Stoica, Vivek Ramanujan, Xiang Fan, Ali Farhadi, Ranjay Krishna, Judy Hoffman|<http://arxiv.org/pdf/2506.05350v1>|[代码](https://github.com/gstoica27/DeltaFM.git.); Contrastive Flow Matching通过增强条件分离，显著提升了扩散模型在条件设置下的...|
|🆕 发布|Perceive Anything: Recognize, Explain, Caption, and Segment Anything in Images and Videos|感知一切：在图像和视频中识别、解释、描述和分割任何事物|Weifeng Lin, Xinyu Wei, Ruichuan An, Tianhe Ren, Tingwei Chen, Renrui Zhang, Ziyu Guo, Wentao Zhang .etc.|<http://arxiv.org/pdf/2506.05302v1>|提出PAM模型，通过整合LLMs实现图像和视频中的区域级视觉理解，同时生成多样化语义输出。|
|📝 更新|ReasonGen-R1: CoT for Autoregressive Image generation models through SFT and RL|ReasonGen-R1：通过SFT和RL实现自回归图像生成模型的CoT|Yu Zhang, Yunqi Li, Yifan Yang, Rui Wang, Yuqing Yang, Dai Qi, Jianmin Bao, Dongdong Chen .etc.|<http://arxiv.org/pdf/2505.24875v2>|通过结合思维链推理和强化学习，ReasonGen-R1显著提升了自回归图像生成模型的生成质量和逻辑性...|
|🆕 发布|Rectified Point Flow: Generic Point Cloud Pose Estimation|校正点流：通用点云姿态估计|Tao Sun, Liyuan Zhu, Shengyu Huang, Shuran Song, Iro Armeni|<http://arxiv.org/pdf/2506.05282v1>|[代码](https://rectified-pointflow.github.io/.); 提出了一种将点云配准和形状组装统一为条件生成问题的方法，显著提升了点云姿态估计的准确性。|
|📝 更新|UniWorld-V1: High-Resolution Semantic Encoders for Unified Visual Understanding and Generation|UniWorld-V1：高分辨率统一视觉理解和生成语义编码器|Bin Lin, Zongjian Li, Xinhua Cheng, Yuwei Niu, Yang Ye, Xianyi He, Shenghai Yuan, Wangbo Yu .etc.|<http://arxiv.org/pdf/2506.03147v3>|提出UniWorld-V1，通过语义特征实现视觉理解与生成任务的统一框架。|
|🆕 发布|Aligning Latent Spaces with Flow Priors|对齐潜在空间与流先验|Yizhuo Li, Yuying Ge, Yixiao Ge, Ying Shan, Ping Luo|<http://arxiv.org/pdf/2506.05240v1>|提出了一种利用流模型先验对可学习潜在空间进行对齐的新框架，有效简化了优化过程。|
|🆕 发布|Synthetic Dataset Generation for Autonomous Mobile Robots Using 3D Gaussian Splatting for Vision Training|基于3D高斯分层合成数据集生成，用于自主移动机器人的视觉训练|Aneesh Deogan, Wout Beks, Peter Teurlings, Koen de Vos, Mark van den Brand, Rene van de Molengraft|<http://arxiv.org/pdf/2506.05092v1>|检测机器人足球场景，提出3D高斯分层合成数据生成方法，提高检测性能。|
|🆕 发布|Physical Annotation for Automated Optical Inspection: A Concept for In-Situ, Pointer-Based Trainingdata Generation|物理标注用于自动光学检测：一种基于指针的现场训练数据生成概念|Oliver Krumpek, Oliver Heimann, Jörg Krüger|<http://arxiv.org/pdf/2506.05026v1>|提出了一种基于物理交互的自动光学检测训练数据生成方法，提高标注效率和准确性。|
|📝 更新|Diff-Instruct++: Training One-step Text-to-image Generator Model to Align with Human Preferences|Diff-Instruct++：训练一步式文本到图像生成模型以与人类偏好对齐|Weijian Luo|<http://arxiv.org/pdf/2410.18881v2>|[代码](https://github.com/pkulwj1994/diff_instruct_pp.); 提出Diff-Instruct++方法，首次实现快速收敛且无需图像数据的人机偏好对齐，提升一步式文本...|
|📝 更新|RAID: A Dataset for Testing the Adversarial Robustness of AI-Generated Image Detectors|RAID：用于测试AI生成图像检测器对抗鲁棒性的数据集|Hicham Eddoubi, Jonas Ricker, Federico Cocchi, Lorenzo Baraldi, Angelo Sotgiu, Maura Pintor, Marcella Cornia, Lorenzo Baraldi .etc.|<http://arxiv.org/pdf/2506.03988v2>|[代码](https://github.com/pralab/RAID.); 构建了RAID数据集，以评估AI生成图像检测器的对抗鲁棒性。|
|🆕 发布|FEAT: Full-Dimensional Efficient Attention Transformer for Medical Video Generation|FEAT：全维高效注意力Transformer在医学视频生成中的应用|Huihan Wang, Zhiwen Yang, Hui Zhang, Dan Zhao, Bingzheng Wei, Yan Xu|<http://arxiv.org/pdf/2506.04956v1>|[代码](https://github.com/Yaziwel/FEAT.); 提出FEAT，一种高效的全维度注意力Transformer，解决医学视频生成中的空间一致性和时间动态...|
|🆕 发布|Invisible Backdoor Triggers in Image Editing Model via Deep Watermarking|图像编辑模型中的隐形后门触发器通过深度水印|Yu-Feng Chen, Tzuhsuan Huang, Pin-Yen Chiu, Jun-Cheng Chen|<http://arxiv.org/pdf/2506.04879v1>|[代码](https://github.com/aiiu-lab/BackdoorImageEditing); 提出了一种通过深度水印嵌入隐形触发器的图像编辑模型后门攻击方法。|
|🆕 发布|DualX-VSR: Dual Axial Spatial$\times$Temporal Transformer for Real-World Video Super-Resolution without Motion Compensation|双轴空间×时间变换器DualX-VSR：无需运动补偿的实时视频超分辨率|Shuo Cao, Yihao Liu, Xiaohui Li. Yuanting Gao. Yu Zhou, Chao Dong|<http://arxiv.org/pdf/2506.04830v1>|提出DualX-VSR，通过双轴时空注意力机制实现无需运动补偿的真实世界视频超分辨率。|
|📝 更新|Psi-Sampler: Initial Particle Sampling for SMC-Based Inference-Time Reward Alignment in Score Models|Psi-Sampler：基于SMC的得分模型推理时奖励对齐的初始粒子采样|Taehoon Yoon, Yunhong Min, Kyeongmin Yeo, Minhyuk Sung|<http://arxiv.org/pdf/2506.01320v2>|Psi-Sampler通过使用pCNL算法从奖励感知后验初始化粒子，有效提升了基于SMC的推理时奖励...|
|🆕 发布|Gen-n-Val: Agentic Image Data Generation and Validation|Gen-n-Val：代理图像数据生成与验证|Jing-En Huang, I-Sheng Fang, Tzuhsuan Huang, Chih-Yu Wang, Jun-Cheng Chen|<http://arxiv.org/pdf/2506.04676v1>|Gen-n-Val通过结合LLMs和VLLMs生成高质量合成数据，有效解决计算机视觉任务中的数据稀缺...|
|🆕 发布|SmartAvatar: Text- and Image-Guided Human Avatar Generation with VLM AI Agents|智能Avatar：基于VLM AI代理的文本和图像引导的人形头像生成|Alexander Huang-Menders, Xinhang Liu, Andy Xu, Yuyao Zhang, Chi-Keung Tang, Yu-Wing Tai|<http://arxiv.org/pdf/2506.04606v1>|SmartAvatar通过结合VLM和参数化人体生成器，实现了从单张照片或文字提示生成高质量、可定制...|
|📝 更新|SpargeAttention: Accurate and Training-free Sparse Attention Accelerating Any Model Inference|稀疏注意力：准确且无需训练的稀疏注意力加速任何模型推理|Jintao Zhang, Chendong Xiang, Haofeng Huang, Jia Wei, Haocheng Xi, Jun Zhu, Jianfei Chen|<http://arxiv.org/pdf/2502.18137v4>|[代码](https://github.com/thu-ml/SpargeAttn.); 提出了一种通用的稀疏注意力机制，显著加速各类模型推理，不牺牲性能。|
|📝 更新|FullDiT2: Efficient In-Context Conditioning for Video Diffusion Transformers|全DiT2：视频扩散变换器的高效上下文条件化|Xuanhua He, Quande Liu, Zixuan Ye, Weicai Ye, Qiulin Wang, Xintao Wang, Qifeng Chen, Pengfei Wan .etc.|<http://arxiv.org/pdf/2506.04213v2>|提出FullDiT2，通过动态选词和选择性缓存机制，有效降低视频扩散模型计算量，提升生成和编辑效率。|
|📝 更新|SViMo: Synchronized Diffusion for Video and Motion Generation in Hand-object Interaction Scenarios|SViMo：手-物体交互场景中的同步扩散视频和运动生成|Lingwei Dang, Ruizhi Shao, Hongwen Zhang, Wei Min, Yebin Liu, Qingyao Wu|<http://arxiv.org/pdf/2506.02444v3>|[代码](https://github.com/Droliven/SViMo_project.); 提出同步扩散方法，同时生成手-物体交互场景中的视频和动作，显著提升视频-动作一致性。|
|📝 更新|Generating by Understanding: Neural Visual Generation with Logical Symbol Groundings|通过理解生成：具有逻辑符号归一化的神经视觉生成|Yifei Peng, Zijie Zha, Yu Jin, Zhexu Luo, Wang-Zhou Dai, Zhong Ren, Yao-Xiang Ding, Kun Zhou|<http://arxiv.org/pdf/2310.17451v4>|[代码](https://github.com/future-item/AbdGen.); 提出AbdGen方法，通过逻辑符号 grounding 增强神经视觉生成模型的可控性和透明度。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Refer to Anything with Vision-Language Prompts|《通过视觉-语言提示进行任意对象的引用》|Shengcao Cao, Zijun Wei, Jason Kuen, Kangning Liu, Lingzhi Zhang, Jiuxiang Gu, HyunJoon Jung, Liang-Yan Gui .etc.|<http://arxiv.org/pdf/2506.05342v1>|提出ORES任务，通过RAS框架实现基于视觉-语言提示的任意分割掩码组生成。|
|🆕 发布|AV-Reasoner: Improving and Benchmarking Clue-Grounded Audio-Visual Counting for MLLMs|AV-Reasoner：提升和基准测试基于线索的音频-视觉计数对多语言大模型的改进|Lidong Lu, Guo Chen, Zhiqi Li, Yicheng Liu, Tong Lu|<http://arxiv.org/pdf/2506.05328v1>|提出CG-AV-Counting基准和AV-Reasoner模型，提升MLLM在视频计数任务上的表现...|
|🆕 发布|MARBLE: Material Recomposition and Blending in CLIP-Space|MARBLE：在CLIP空间中的材料重组与融合|Ta-Ying Cheng, Prafull Sharma, Mark Boss, Varun Jampani|<http://arxiv.org/pdf/2506.05313v1>|提出了一种基于CLIP空间的材料编辑方法，通过寻找材料嵌入实现材质混合和重组。|
|🆕 发布|SeedVR2: One-Step Video Restoration via Diffusion Adversarial Post-Training|SeedVR2：一步式视频恢复通过扩散对抗后训练|Jianyi Wang, Shanchuan Lin, Zhijie Lin, Yuxi Ren, Meng Wei, Zongsheng Yue, Shangchen Zhou, Hao Chen .etc.|<http://arxiv.org/pdf/2506.05301v1>|SeedVR2通过引入自适应窗口注意力机制和改进的损失函数，实现了单步扩散视频恢复，有效降低了计算成...|
|🆕 发布|AliTok: Towards Sequence Modeling Alignment between Tokenizer and Autoregressive Model|AliTok：迈向分词器和自回归模型之间的序列建模对齐|Pingyu Wu, Kai Zhu, Yu Liu, Longxiang Tang, Jian Yang, Yansong Peng, Wei Zhai, Yang Cao .etc.|<http://arxiv.org/pdf/2506.05289v1>|[代码](https://github.com/ali-vilab/alitok.); AliTok通过因果解码建立编码token单向依赖，实现编码器与自回归模型间序列建模对齐，提升图像生...|
|🆕 发布|DSG-World: Learning a 3D Gaussian World Model from Dual State Videos|DSG-World：从双状态视频中学习3D高斯世界模型|Wenhao Hu, Xuexiang Wen, Xi Li, Gaoang Wang|<http://arxiv.org/pdf/2506.05217v1>|DSG-World通过双状态视频学习3D高斯世界模型，有效解决遮挡问题，实现高效真实到模拟的转换。|
|📝 更新|AnyTop: Character Animation Diffusion with Any Topology|任意拓扑：任意拓扑结构的角色动画扩散|Inbar Gat, Sigal Raab, Guy Tevet, Yuval Reshef, Amit H. Bermano, Daniel Cohen-Or|<http://arxiv.org/pdf/2502.17327v2>|[代码](https://anytop2025.github.io/Anytop-page); AnyTop通过拓扑信息和文本描述，实现仅用骨骼结构输入生成多样化角色动画。|
|📝 更新|Detection-Driven Object Count Optimization for Text-to-Image Diffusion Models|基于检测驱动的文本到图像扩散模型物体计数优化|Oz Zafar, Yuval Cohen, Lior Wolf, Idan Schwartz|<http://arxiv.org/pdf/2408.11721v2>|提出了一种基于预训练计数模型和检测驱动的优化框架，有效提升了文本到图像生成中物体数量的准确性。|
|📝 更新|Eddeep: Fast eddy-current distortion correction for diffusion MRI with deep learning|Eddeep：基于深度学习的快速涡流畸变校正扩散加权磁共振成像|Antoine Legouhy, Ross Callaghan, Whitney Stee, Philippe Peigneux, Hojjat Azadbakht, Hui Zhang|<http://arxiv.org/pdf/2405.10723v3>|提出了一种基于深度学习的快速涡流畸变校正方法，有效提升了扩散磁共振成像的预处理效率。|
|🆕 发布|DIMCIM: A Quantitative Evaluation Framework for Default-mode Diversity and Generalization in Text-to-Image Generative Models|标题翻译结果：  文本到图像生成模型中默认模式多样性和泛化能力的定量评估框架：DIMCIM|Revant Teotia, Candace Ross, Karen Ullrich, Sumit Chopra, Adriana Romero-Soriano, Melissa Hall, Matthew J. Muckley|<http://arxiv.org/pdf/2506.05108v1>|提出了一种无参考框架DIM-CIM，评估文本到图像生成模型的多样性和泛化能力。|
|🆕 发布|Astraea: A GPU-Oriented Token-wise Acceleration Framework for Video Diffusion Transformers|Astraea：面向GPU的视频扩散Transformer的词级加速框架|Haosong Liu, Yuge Cheng, Zihan Liu, Aiyue Chen, Yiwu Yao, Chen Chen, Jingwen Leng, Yu Feng .etc.|<http://arxiv.org/pdf/2506.05096v1>|ASTRAEA通过轻量级token选择和GPU并行稀疏注意力策略，显著加速视频扩散Transform...|
|🆕 发布|Practical Manipulation Model for Robust Deepfake Detection|实用鲁棒深度伪造检测操作模型|Benedikt Hopf, Radu Timofte|<http://arxiv.org/pdf/2506.05119v1>|[代码](https://github.com/BenediktHopf/PMM); 开发了一种实用操作模型（PMM），增强了对深度伪造检测的鲁棒性，显著提升了检测性能。|
|📝 更新|Attentive Eraser: Unleashing Diffusion Model's Object Removal Potential via Self-Attention Redirection Guidance|注意擦除器：通过自注意力重定向引导释放扩散模型的对象去除潜力|Benlei Cui, Wenhao Sun, Xue-Mei Dong, Jingqun Tang, Yi Liu|<http://arxiv.org/pdf/2412.12974v7>|[代码](https://github.com/Anonym0u3/AttentiveEraser.); 提出了一种基于自注意力重定向的扩散模型，有效解决图像去除任务中的随机伪影和前景内容重绘问题。|
|🆕 发布|Deep learning image burst stacking to reconstruct high-resolution ground-based solar observations|深度学习图像爆堆技术重建高分辨率地面太阳观测|Christoph Schirninger, Robert Jarolim, Astrid M. Veronig, Christoph Kuckein|<http://arxiv.org/pdf/2506.04781v1>|提出了一种实时深度学习图像堆叠方法，有效提升地面太阳观测图像分辨率。|
|📝 更新|GaRA-SAM: Robustifying Segment Anything Model with Gated-Rank Adaptation|GaRA-SAM：通过门控排序自适应增强的Segment Anything模型|Sohyun Lee, Yeho Gwon, Lukas Hoyer, Suha Kwak|<http://arxiv.org/pdf/2506.02882v2>|通过引入门控秩自适应，GaRA-SAM显著提升了Segment Anything Model对输入退...|
|🆕 发布|Learning dissection trajectories from expert surgical videos via imitation learning with equivariant diffusion|通过等变扩散的模仿学习从专家手术视频中学习分割轨迹|Hongyu Wang, Yonghao Long, Yueyao Chen, Hon-Chi Yip, Markus Scheppach, Philip Wai-Yan Chiu, Yeung Yam, Helen Mei-Ling Meng .etc.|<http://arxiv.org/pdf/2506.04716v1>|通过引入iDPOE方法，该论文解决了从专家视频中学习手术切割轨迹的难题，实现了更准确和泛化的轨迹预测...|
|🆕 发布|Robust Few-Shot Vision-Language Model Adaptation|鲁棒性少样本视觉-语言模型自适应|Hanxin Wang, Tian Liu, Shu Kong|<http://arxiv.org/pdf/2506.04713v1>|提出SRAPF方法，通过部分微调和简单增强技术，显著提升视觉语言模型在少量样本下的分布内和分布外泛化...|
|📝 更新|OmnimatteZero: Fast Training-free Omnimatte with Pre-trained Video Diffusion Models|全场景零训练：基于预训练视频扩散模型的快速全场景渲染|Dvir Samuel, Matan Levy, Nir Darshan, Gal Chechik, Rami Ben-Ari|<http://arxiv.org/pdf/2503.18033v2>|OmnimatteZero通过预训练视频扩散模型实现快速无训练的全方位马赛克分解。|
|🆕 发布|Text-Aware Real-World Image Super-Resolution via Diffusion Model with Joint Segmentation Decoders|基于扩散模型与联合分割解码器的文本感知真实世界图像超分辨率|Qiming Hu, Linlong Fan, Yiyan Luo, Yuhang Yu, Xiaojie Guo, Qingnan Fan|<http://arxiv.org/pdf/2506.04641v1>|[代码](https://github.com/mingcv/TADiSR); 提出TADiSR模型，通过文本感知注意力和联合分割解码器，有效提升超分辨率图像中文本结构的清晰度和真...|
|📝 更新|Solving Inverse Problems via Diffusion-Based Priors: An Approximation-Free Ensemble Sampling Approach|通过基于扩散先验解决逆问题：一种无近似的无监督采样方法|Haoxuan Chen, Yinuo Ren, Martin Renqiang Min, Lexing Ying, Zachary Izzo|<http://arxiv.org/pdf/2506.03979v2>|提出了一种无需近似的高效后验采样算法，利用扩散模型解决逆问题，实现更精确的图像重建。|
|🆕 发布|Exploring bidirectional bounds for minimax-training of Energy-based models|探索基于能量的模型最小-最大训练的双向边界|Cong Geng, Jia Wang, Li Chen, Zhiyong Gao, Jes Frellsen, Søren Hauberg|<http://arxiv.org/pdf/2506.04609v1>|提出双向边界法稳定能量模型训练，实现高质量密度估计和样本生成。|
|🆕 发布|Enhancing Frequency for Single Image Super-Resolution with Learnable Separable Kernels|使用可学习可分离核增强单图像超分辨率频率|Heng Tian|<http://arxiv.org/pdf/2506.04555v1>|提出可学习分离核（LSKs）模块，有效提升单图像超分辨率性能，减少参数和计算量。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VideoMolmo: Spatio-Temporal Grounding Meets Pointing|视频Molmo：时空定位与指向的结合|Ghazi Shazan Ahmad, Ahmed Heakl, Hanan Gani, Abdelrahman Shaker, Zhiqiang Shen, Ranjay Krishna, Fahad Shahbaz Khan, Salman Khan|<http://arxiv.org/pdf/2506.05336v1>|[代码](https://github.com/mbzuai-oryx/VideoMolmo.); VideoMolmo通过结合时空定位和指向，显著提升了视频理解与交互的准确性。|
|📝 更新|DEFAME: Dynamic Evidence-based FAct-checking with Multimodal Experts|动态基于证据的多模态专家事实核查：DEFAME|Tobias Braun, Mark Rothermel, Marcus Rohrbach, Anna Rohrbach|<http://arxiv.org/pdf/2412.10510v3>|DEFAME提出了一种动态多模态证据验证方法，显著提升了开放域事实核查的准确性和效率。|
|🆕 发布|Spatiotemporal Contrastive Learning for Cross-View Video Localization in Unstructured Off-road Terrains|时空对比学习在非结构化越野地形中的跨视图视频定位|Zhiyun Deng, Dongmyeong Lee, Amanda Adkins, Jesse Quattrociocchi, Christian Ellis, Joydeep Biswas|<http://arxiv.org/pdf/2506.05250v1>|提出MoViX框架，通过时空对比学习实现无GPS的越野地形视频定位。|
|🆕 发布|OGGSplat: Open Gaussian Growing for Generalizable Reconstruction with Expanded Field-of-View|OGGSplat：开放式高斯生长，实现具有扩展视场的可泛化重建|Yanbo Wang, Ziyi Wang, Wenzhao Zheng, Jie Zhou, Jiwen Lu|<http://arxiv.org/pdf/2506.05204v1>|OGGSplat通过开放高斯增长扩展视野，实现语义感知的3D场景重建。|
|🆕 发布|FlowDirector: Training-Free Flow Steering for Precise Text-to-Video Editing|FlowDirector：无需训练的流动引导，实现精确的文本到视频编辑|Guangzhao Li, Yanming Yang, Chenxi Song, Chi Zhang|<http://arxiv.org/pdf/2506.05046v1>|FlowDirector通过无逆变换和注意力引导，实现了精确的基于文本的视频编辑，提升了编辑的连贯性...|
|📝 更新|Sonic: Shifting Focus to Global Audio Perception in Portrait Animation|声动：转向人像动画中的全局音频感知|Xiaozhong Ji, Xiaobin Hu, Zhihong Xu, Junwei Zhu, Chuming Lin, Qingdong He, Jiangning Zhang, Donghao Luo .etc.|<http://arxiv.org/pdf/2411.16331v3>|提出Sonic方法，通过全局音频感知提升人像动画的自然度和时间一致性。|
|🆕 发布|SRD: Reinforcement-Learned Semantic Perturbation for Backdoor Defense in VLMs|SRD：基于强化学习的VLMs后门防御语义扰动|Shuhan Xu, Siyuan Liang, Hongling Zheng, Yong Luo, Aishan Liu, Dacheng Tao|<http://arxiv.org/pdf/2506.04743v1>|提出SRD方法，通过语义扰动防御视觉语言模型中的后门攻击。|
|📝 更新|Text-to-CAD Generation Through Infusing Visual Feedback in Large Language Models|通过在大型语言模型中注入视觉反馈进行文本到CAD生成|Ruiyu Wang, Yu Yuan, Shizhao Sun, Jiang Bian|<http://arxiv.org/pdf/2501.19054v3>|提出CADFusion框架，通过融合视觉反馈提升大型语言模型在文本到CAD生成中的性能。|
|🆕 发布|FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion|FPSAttention：训练感知的FP8和稀疏性协同设计以实现快速视频扩散|Akide Liu, Zeyu Zhang, Zhexin Li, Xuehai Bai, Yizeng Han, Jiasheng Tang, Yuanjie Xing, Jichao Wu .etc.|<http://arxiv.org/pdf/2506.04648v1>|FPSAttention通过联合优化FP8量化和稀疏性，显著提升了视频生成模型的推理速度。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FreeTimeGS: Free Gaussians at Anytime and Anywhere for Dynamic Scene Reconstruction|任意时间、任意地点的动态场景重建中的自由高斯|Yifan Wang, Peishan Yang, Zhen Xu, Jiaming Sun, Zhanhua Zhang, Yong Chen, Hujun Bao, Sida Peng .etc.|<http://arxiv.org/pdf/2506.05348v1>|提出FreeTimeGS，通过自由高斯表示和运动函数，有效重建复杂动态场景。|
|🆕 发布|Defurnishing with X-Ray Vision: Joint Removal of Furniture from Panoramas and Mesh|用X射线视觉进行去家具处理：全景和网格中家具的联合去除|Alan Dolhasz, Chen Ma, Dave Gausebeck, Kevin Chen, Gregor Miller, Lucas Hayne, Gunnar Hovden, Azwad Sabik .etc.|<http://arxiv.org/pdf/2506.05338v1>|提出了一种基于简化网格和全景图像的联合去家具方法，实现高质量室内空间重建。|
|🆕 发布|UAV4D: Dynamic Neural Rendering of Human-Centric UAV Imagery using Gaussian Splatting|无人机4D：基于高斯散布的人本无人机图像动态神经渲染|Jaehoon Choi, Dongki Jung, Christopher Maxey, Yonghan Lee, Sungmin Eum, Dinesh Manocha, Heesung Kwon|<http://arxiv.org/pdf/2506.05011v1>|UAV4D通过结合3D模型和人类网格重建，实现了无人机捕获的动态场景的逼真渲染。|
|🆕 发布|Structure-Aware Radar-Camera Depth Estimation|结构感知雷达-摄像头深度估计|Fuyi Zhang, Zhu Yu, Chunhao Li, Runmin Zhang, Xiaokai Bai, Zili Zhou, Si-Yuan Cao, Wang Wang .etc.|<http://arxiv.org/pdf/2506.05008v1>|提出了一种结构感知雷达-相机深度估计方法，通过融合多尺度特征和结构信息，实现了零样本单目深度估计。|
|🆕 发布|Generating Synthetic Stereo Datasets using 3D Gaussian Splatting and Expert Knowledge Transfer|利用3D高斯分层和专家知识迁移生成合成立体数据集|Filip Slezak, Magnus K. Gjerde, Joakim B. Haurum, Ivan Nikolov, Morten S. Laursen, Thomas B. Moeslund|<http://arxiv.org/pdf/2506.04908v1>|提出了一种基于3D高斯分层和专家知识迁移的立体数据集生成方法，有效提升了深度立体模型性能。|
|📝 更新|Images are Worth Variable Length of Representations|图像价值可变长度表示|Lingjun Mao, Rodolfo Corona, Xin Liang, Wenhao Yan, Zineng Tang|<http://arxiv.org/pdf/2506.03643v2>|[代码](https://dove-encoder.github.io/dove-encoder.); 提出DOVE，一种动态视觉编码器，通过生成可变长度的视觉标记，提高图像信息利用效率。|
|🆕 发布|Spike-TBR: a Noise Resilient Neuromorphic Event Representation|脉冲-TBR：一种噪声鲁棒的类神经形态事件表示|Gabriele Magrini. Federico Becattini, Luca Cultrera, Lorenzo Berlincioni, Pietro Pala, Alberto Del Bimbo|<http://arxiv.org/pdf/2506.04817v1>|提出了一种基于TBR和脉冲神经元的编码策略，有效解决事件相机噪声问题，提升事件流处理鲁棒性。|
|📝 更新|Self-Supervised Learning for Text Recognition: A Critical Survey|自监督学习在文本识别中的应用：关键综述|Carlos Penarrubia, Jose J. Valero-Mas, Jorge Calvo-Zaragoza|<http://arxiv.org/pdf/2407.19889v2>|综述了自监督学习在文本识别中的应用，提出标准化建议，推动领域发展。|
|🆕 发布|Line of Sight: On Linear Representations in VLLMs|视距：关于VLLMs中的线性表示|Achyuta Rajaram, Sarah Schwettmann, Jacob Andreas, Arthur Conmy|<http://arxiv.org/pdf/2506.04706v1>|探索了VLLM中图像概念的线性表示，通过训练多模态稀疏自动编码器揭示了跨模态表示的深层共享性。|
|🆕 发布|MARS: Radio Map Super-resolution and Reconstruction Method under Sparse Channel Measurements|MARS：稀疏信道测量下的无线电地图超分辨率与重建方法|Chuyun Deng, Na Liu, Wei Xie, Lianming Xu, Li Wang|<http://arxiv.org/pdf/2506.04682v1>|MARS通过结合CNN和Transformer，实现稀疏信道下无线电地图的超分辨率和重建，显著提升重...|
|📝 更新|HUMOF: Human Motion Forecasting in Interactive Social Scenes|人机交互社交场景中的人体运动预测：HUMOF|Caiyi Sun, Yujing Sun, Xiao Han, Zemin Yang, Jiawei Liu, Xinge Zhu, Siu Ming Yiu, Yuexin Ma|<http://arxiv.org/pdf/2506.03753v2>|提出了一种基于层次交互特征表示和粗细粒度推理模块的人体运动预测方法，有效提升了复杂场景中运动预测的准...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ProJo4D: Progressive Joint Optimization for Sparse-View Inverse Physics Estimation|渐进式联合优化用于稀疏视图逆物理估计|Daniel Rho, Jun Myeong Choi, Biswadip Dey, Roni Sengupta|<http://arxiv.org/pdf/2506.05317v1>|[代码](https://daniel03c1.github.io/ProJo4D); 提出ProJo4D框架，通过渐进式联合优化解决稀疏视图逆向物理估计问题，提升4D场景理解效果。|
|🆕 发布|Revisiting Depth Representations for Feed-Forward 3D Gaussian Splatting|重新审视用于前馈3D高斯分层的光度表示|Duochao Shi, Weijie Wang, Donny Y. Chen, Zeyu Zhang, Jia-Wang Bian, Bohan Zhuang, Chunhua Shen|<http://arxiv.org/pdf/2506.05327v1>|[代码](https://aim-uofa.github.io/PMLoss); 提出PM-Loss，通过预测点图改善深度图，显著提升3D Gaussian Splatting渲染质...|
|🆕 发布|Unifying Appearance Codes and Bilateral Grids for Driving Scene Gaussian Splatting|统一外观代码和双边网格进行驾驶场景高斯分层|Nan Wang, Yuantao Chen, Lixing Xiao, Weiqing Xiao, Bohan Li, Zhaoxi Chen, Chongjie Ye, Shaocong Xu .etc.|<http://arxiv.org/pdf/2506.05280v1>|提出了一种融合外观码和多尺度双边网格的驾驶场景高精度重建方法。|
|📝 更新|Stochastic Poisson Surface Reconstruction with One Solve using Geometric Gaussian Processes|基于几何高斯过程的单次求解随机泊松表面重建|Sidhanth Holalkere, David S. Bindel, Silvia Sellán, Alexander Terenin|<http://arxiv.org/pdf/2503.19136v2>|将几何高斯过程应用于单阶段随机泊松表面重建，实现高效且灵活的表面重建。|
|📝 更新|SR3D: Unleashing Single-view 3D Reconstruction for Transparent and Specular Object Grasping|SR3D：释放单视图3D重建以实现透明和镜面物体抓取|Mingxu Zhang, Xiaoqi Li, Jiahui Xu, Kaichen Zhou, Hojin Bae, Yan Shen, Chuyan Xiong, Jiaming Liu .etc.|<http://arxiv.org/pdf/2505.24305v2>|SR3D通过单视图3D重建技术，实现了透明和镜面物体的高精度抓取。|
|🆕 发布|Object-X: Learning to Reconstruct Multi-Modal 3D Object Representations|对象-X：学习重建多模态3D物体表示|Gaia Di Lorenzo, Federico Tombari, Marc Pollefeys, Daniel Barath|<http://arxiv.org/pdf/2506.04789v1>|Object-X提出了一种多模态3D物体表示框架，可高效编码和解码物体信息，实现高保真重建和任务泛化...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Place Recognition Meet Multiple Modalitie: A Comprehensive Review, Current Challenges and Future Directions|《地点识别遇见多模态：全面综述、当前挑战与未来方向》|Zhenyu Li, Tianyi Shang, Pengjie Xu, Zhaojun Deng|<http://arxiv.org/pdf/2505.14068v3>|[代码](https://github.com/CV4RA/SOTA-Place-Recognitioner.); 综述了地点识别方法，包括CNN、Transformer和跨模态策略，并展望了未来研究方向。|
|📝 更新|Contrastive Representation Distillation via Multi-Scale Feature Decoupling|对比表示蒸馏通过多尺度特征解耦|Cuipeng Wang, Tieyuan Chen, Haipeng Wang|<http://arxiv.org/pdf/2502.05835v2>|提出了一种通过多尺度特征解耦的对比表示蒸馏方法，有效提升学生网络性能。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unleashing Hour-Scale Video Training for Long Video-Language Understanding|释放小时级视频训练以实现长视频语言理解|Jingyang Lin, Jialian Wu, Ximeng Sun, Ze Wang, Jiang Liu, Yusheng Su, Xiaodong Yu, Hao Chen .etc.|<http://arxiv.org/pdf/2506.05332v1>|提出VideoMarathon数据集和Hour-LLaVA模型，扩展视频语言理解训练时长，提升长视频...|
|🆕 发布|Video World Models with Long-term Spatial Memory|视频世界模型与长期空间记忆|Tong Wu, Shuai Yang, Ryan Po, Yinghao Xu, Ziwei Liu, Dahua Lin, Gordon Wetzstein|<http://arxiv.org/pdf/2506.05284v1>|引入几何基础长期空间记忆机制，提升视频世界模型长期一致性。|
|🆕 发布|From Play to Replay: Composed Video Retrieval for Temporally Fine-Grained Videos|从玩耍到回放：针对时间细粒度视频的合成视频检索|Animesh Gupta, Jay Parmar, Ishan Rajendrakumar Dave, Mubarak Shah|<http://arxiv.org/pdf/2506.05274v1>|提出TF-CoVR基准，通过对比学习实现细粒度视频检索，显著提升检索准确率。|
|🆕 发布|Time-Lapse Video-Based Embryo Grading via Complementary Spatial-Temporal Pattern Mining|基于时间序列视频的胚胎评分通过互补时空模式挖掘|Yong Sun, Yipeng Wang, Junyu Shi, Zhiyuan Zhang, Yanmei Xiao, Lei Zhu, Manxi Jiang, Qiang Nie|<http://arxiv.org/pdf/2506.04950v1>|提出了一种基于时空模式挖掘的胚胎评分方法，通过时间推移视频预测胚胎整体质量。|
|📝 更新|Viewport Prediction for Volumetric Video Streaming by Exploring Video Saliency and Trajectory Information|基于视频显著性和轨迹信息探索的体量视频流视口预测|Jie Li, Zhixin Li, Zhi Liu, Pengyuan Zhou, Richang Hong, Qiyue Li, Han Hu|<http://arxiv.org/pdf/2311.16462v3>|提出了一种结合视频显著性和轨迹信息的viewport预测方法，显著提升了全息视频流预测精度。|
|📝 更新|Video Summarization with Large Language Models|基于大型语言模型的视频摘要|Min Jung Lee, Dayoung Gong, Minsu Cho|<http://arxiv.org/pdf/2504.11199v2>|提出利用大型语言模型进行视频摘要，有效捕捉视频语义并生成连贯总结。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MAC-Gaze: Motion-Aware Continual Calibration for Mobile Gaze Tracking|MAC-Gaze：移动注视跟踪的运动感知持续校准|Yaxiong Lei, Mingyue Zhao, Yuheng Wang, Shijing He, Yusuke Sugano, Mohamed Khamis, Juan Ye|<http://arxiv.org/pdf/2505.22769v3>|提出MAC-Gaze，通过结合IMU和持续学习技术，实现移动端注视跟踪的动态校准，显著提升跟踪精度。|
|🆕 发布|Through-the-Wall Radar Human Activity Recognition WITHOUT Using Neural Networks|通过墙壁雷达的人体活动识别无需使用神经网络|Weicheng Gao|<http://arxiv.org/pdf/2506.05169v1>|[代码](https://github.com/JoeyBGOfficial/Through-the-Wall-Radar-Human-Activity-Recognition-Without-Using-Neural-Networks.); 提出一种基于雷达图像的模板匹配方法，无需神经网络实现墙体雷达人体活动识别。|
|📝 更新|Reading Recognition in the Wild|野外场景中的阅读识别|Charig Yang, Samiul Alam, Shakhrul Iman Siam, Michael J. Proulx, Lambert Mathias, Kiran Somasundaram, Luis Pesqueira, James Fort .etc.|<http://arxiv.org/pdf/2505.24848v2>|构建首个大规模多模态阅读识别数据集，提出灵活的Transformer模型实现阅读行为识别。|
|📝 更新|Balancing Beyond Discrete Categories: Continuous Demographic Labels for Fair Facial Recognition|超越离散类别：公平面部识别的连续人口标签|Pedro C. Neto, Naser Damer, Jaime S. Cardoso, Ana F. Sequeira|<http://arxiv.org/pdf/2506.01532v3>|提出连续族裔标签，以平衡人脸识别数据集，提升模型公平性。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Follow-Your-Motion: Video Motion Transfer via Efficient Spatial-Temporal Decoupled Finetuning|跟随运动：通过高效时空解耦微调的视频运动迁移|Yue Ma, Yulong Liu, Qiyuan Zhu, Ayden Yang, Kunyu Feng, Xinhua Zhang, Zhifeng Li, Sirui Han .etc.|<http://arxiv.org/pdf/2506.05207v1>|提出Follow-Your-Motion，通过时空解耦LoRA和高效调优策略，有效解决视频运动迁移中...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Quantifying Cross-Modality Memorization in Vision-Language Models|视觉-语言模型中跨模态记忆的量化|Yuxin Wen, Yangsibo Huang, Tom Goldstein, Ravi Kumar, Badih Ghazi, Chiyuan Zhang|<http://arxiv.org/pdf/2506.05198v1>|研究视觉-语言模型中的跨模态记忆，提出方法量化知识迁移，提升跨模态学习。|
|🆕 发布|Learning to Plan via Supervised Contrastive Learning and Strategic Interpolation: A Chess Case Study|通过监督对比学习和战略插值学习进行规划：一项国际象棋案例研究|Andrew Hamara, Greg Hamerly, Pablo Rivas, Andrew C. Freeman|<http://arxiv.org/pdf/2506.04892v1>|[代码](https://github.com/andrewhamara/SOLIS.); 通过监督对比学习和策略插值，该论文提出了一种基于嵌入空间的直觉驱动规划方法，显著提升了棋类游戏的性能...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Neural Inverse Rendering from Propagating Light|基于光传播的神经逆渲染|Anagh Malik, Benjamin Attal, Andrew Xie, Matthew O'Toole, David B. Lindell|<http://arxiv.org/pdf/2506.05347v1>|提出了一种基于神经辐射缓存的光传播逆渲染系统，实现强间接光照下的3D重建和场景重光照。|
|🆕 发布|LeanPO: Lean Preference Optimization for Likelihood Alignment in Video-LLMs|轻优PO：视频LLMs中似然对齐的轻量级偏好优化|Xiaodong Wang, Jinfa Huang, Li Yuan, Peixi Peng|<http://arxiv.org/pdf/2506.05260v1>|提出LeanPO方法，通过优化视频LLMs的偏好，显著提升模型性能并减少噪声影响。|
|🆕 发布|Multi-scale Image Super Resolution with a Single Auto-Regressive Model|多尺度图像超分辨率与单一自回归模型|Enrique Sanchez, Isma Hadji, Adrian Bulat, Christos Tzelepis, Brais Martinez, Georgios Tzimiropoulos|<http://arxiv.org/pdf/2506.04990v1>|提出了一种基于多尺度图像标记和直接偏好优化的自回归模型，实现了高效的单次前向图像超分辨率。|
|🆕 发布|Robustness as Architecture: Designing IQA Models to Withstand Adversarial Perturbations|鲁棒性作为架构：设计能够抵御对抗性扰动的图像质量评估模型|Igor Meleshin, Anna Chistyakova, Anastasia Antsiferova, Dmitriy Vatolin|<http://arxiv.org/pdf/2506.04951v1>|设计鲁棒性作为架构先验，构建抗攻击的图像质量评估模型。|
|🆕 发布|Physics Informed Capsule Enhanced Variational AutoEncoder for Underwater Image Enhancement|水下图像增强的物理信息胶囊增强变分自编码器|Niki Martinel, Rita Pucci|<http://arxiv.org/pdf/2506.04753v1>|[代码](https://github.com/iN1k1/.); 提出了一种结合物理模型和胶囊网络的深度学习方法，显著提升了水下图像增强效果。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MonkeyOCR: Document Parsing with a Structure-Recognition-Relation Triplet Paradigm|MonkeyOCR：基于结构-识别-关系三元组范式的文档解析|Zhang Li, Yuliang Liu, Qiang Liu, Zhiyin Ma, Ziyang Zhang, Shuo Zhang, Zidun Guo, Jiarui Zhang .etc.|<http://arxiv.org/pdf/2506.05218v1>|[代码](https://github.com/Yuliang-Liu/MonkeyOCR.); MonkeyOCR通过结构-识别-关系三重范式简化文档解析，实现高效且精确的文档处理。|
|🆕 发布|CIVET: Systematic Evaluation of Understanding in VLMs|CIVET：视觉语言模型理解系统评估|Massimo Rizzoli, Simone Alghisi, Olha Khomyn, Gabriel Roccabruna, Seyed Mahed Mousavi, Giuseppe Riccardi|<http://arxiv.org/pdf/2506.05146v1>|提出CIVET框架，系统评估VLMs对场景结构和语义的理解能力。|
|🆕 发布|FRED: The Florence RGB-Event Drone Dataset|FRED：佛罗伦萨RGB-事件无人机数据集|Gabriele Magrini, Niccolò Marini, Federico Becattini, Lorenzo Berlincioni, Niccolò Biondi, Pietro Pala, Alberto Del Bimbo|<http://arxiv.org/pdf/2506.05163v1>|构建了FRED数据集，结合RGB和事件流，以促进无人机检测、跟踪和轨迹预测研究。|
|📝 更新|OmniCharacter: Towards Immersive Role-Playing Agents with Seamless Speech-Language Personality Interaction|全息角色：迈向无缝语音-语言个性交互的沉浸式角色扮演代理|Haonan Zhang, Run Luo, Xiong Liu, Yuchuan Wu, Ting-En Lin, Pengpeng Zeng, Qiang Qu, Feiteng Fang .etc.|<http://arxiv.org/pdf/2505.20277v2>|[代码](https://github.com/AlibabaResearch/DAMO-ConvAI); 提出OmniCharacter模型，实现沉浸式角色扮演，融合语音与语言个性互动。|
|🆕 发布|A Survey on Vietnamese Document Analysis and Recognition: Challenges and Future Directions|越南文档分析与识别综述：挑战与未来方向|Anh Le, Thanh Lam, Dung Nguyen|<http://arxiv.org/pdf/2506.05061v1>|该论文综述了越南文文档分析与识别的挑战，提出利用大型语言模型革新该领域，并展望了未来研究方向。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Beyond Cropped Regions: New Benchmark and Corresponding Baseline for Chinese Scene Text Retrieval in Diverse Layouts|超越裁剪区域：多样化布局下中文场景文本检索的新基准与对应基线|Gengluo Li, Huawen Shen, Yu Zhou|<http://arxiv.org/pdf/2506.04999v1>|提出针对中文场景文本检索的新基准和模型，有效应对复杂布局挑战。|
|📝 更新|Hybrid deep convolution model for lung cancer detection with transfer learning|混合深度卷积模型在肺癌检测中的迁移学习|Sugandha Saxena, S. N. Prasad, Ashwin M Polnaya, Shweta Agarwala|<http://arxiv.org/pdf/2501.02785v2>|提出了一种基于转移学习的混合深度卷积模型，显著提升了肺癌检测的准确性和诊断效率。|
|📝 更新|FlowCut: Rethinking Redundancy via Information Flow for Efficient Vision-Language Models|FlowCut：通过信息流重新思考冗余以提高视觉-语言模型的效率|Jintao Tong, Wenwei Jin, Pengda Qin, Anqi Li, Yixiong Zou, Yuhong Li, Yuhua Li, Ruixuan Li|<http://arxiv.org/pdf/2505.19536v2>|[代码](https://github.com/TungChintao/FlowCut); FlowCut通过信息流分析，有效识别并剪枝视觉语言模型中的冗余视觉标记，显著提升模型效率。|
|🆕 发布|LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table|莲花滤波器：通过学习截止表实现快速多样最近邻搜索|Yusuke Matsui|<http://arxiv.org/pdf/2506.04790v1>|[代码](https://github.com/matsui528/lotf.); 提出LotusFilter，通过学习截止表快速实现近似最近邻搜索结果的多样性。|
|🆕 发布|HoliSafe: Holistic Safety Benchmarking and Modeling with Safety Meta Token for Vision-Language Model|HoliSafe：基于视觉-语言模型的全面安全基准和建模与安全元令牌|Youngwan Lee, Kangsan Kim, Kwanyong Park, Ilcahe Jung, Soojin Jang, Seanie Lee, Yong-Ju Lee, Sung Ju Hwang|<http://arxiv.org/pdf/2506.04704v1>|HoliSafe提出全面安全数据集和模型，通过安全元标记增强VLM，显著提升视觉语言模型安全性。|
|🆕 发布|ViCocktail: Automated Multi-Modal Data Collection for Vietnamese Audio-Visual Speech Recognition|ViCocktail：越南音频-视觉语音识别的自动化多模态数据收集|Thai-Binh Nguyen, Thi Van Nguyen, Quoc Truong Do, Chi Mai Luong|<http://arxiv.org/pdf/2506.04635v1>|ViCocktail通过自动化多模态数据收集，为越南语音频-视觉语音识别提供高效数据集，提升噪声环境...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Identifying and Understanding Cross-Class Features in Adversarial Training|识别和理解对抗训练中的跨类别特征|Zeming Wei, Yiwen Guo, Yisen Wang|<http://arxiv.org/pdf/2506.05032v1>|[代码](https://github.com/PKU-ML/Cross-Class-Features-AT.); 通过分析跨类别特征，揭示了对抗训练中模型学习动态和鲁棒过拟合现象。|
|🆕 发布|Fool the Stoplight: Realistic Adversarial Patch Attacks on Traffic Light Detectors|愚弄交通信号灯：针对交通信号灯检测器的真实对抗性补丁攻击|Svetlana Pavlitska, Jamie Robb, Nikolai Polley, Melih Yazgan, J. Marius Zöllner|<http://arxiv.org/pdf/2506.04823v1>|[代码](https://github.com/KASTEL-MobilityLab/attacks-on-traffic-light-detection.); 提出了一种针对交通灯检测器的对抗性贴片攻击方法，通过打印贴片实现真实场景下的红绿灯识别欺骗。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MineInsight: A Multi-sensor Dataset for Humanitarian Demining Robotics in Off-Road Environments|MineInsight：适用于越野环境中人道主义排雷机器人的多传感器数据集|Mario Malizia, Charles Hamesse, Ken Hasselmann, Geert De Cubber, Nikolaos Tsiogkas, Eric Demeester, Rob Haelterman|<http://arxiv.org/pdf/2506.04842v1>|[代码](https://github.com/mariomlz99/MineInsight.); 构建了首个多传感器、多光谱的MineInsight数据集，以促进越野环境中地雷检测算法的可靠验证。|
|📝 更新|MoDoMoDo: Multi-Domain Data Mixtures for Multimodal LLM Reinforcement Learning|MoDoMoDo：多域数据混合用于多模态LLM强化学习|Yiqing Liang, Jielin Qiu, Wenhao Ding, Zuxin Liu, James Tompkin, Mengdi Xu, Mengzhou Xia, Zhengzhong Tu .etc.|<http://arxiv.org/pdf/2505.24871v2>|提出了一种多领域数据混合策略，有效提升了多模态LLM在视觉语言任务上的泛化能力和推理能力。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Do It Yourself: Learning Semantic Correspondence from Pseudo-Labels|自己动手：从伪标签中学习语义对应|Olaf Dünkel, Thomas Wimmer, Christian Theobalt, Christian Rupprecht, Adam Kortylewski|<http://arxiv.org/pdf/2506.05312v1>|通过3D感知伪标签学习，该论文提出了一种改进语义对应估计的方法，显著提升了性能。|
|📝 更新|BevSplat: Resolving Height Ambiguity via Feature-Based Gaussian Primitives for Weakly-Supervised Cross-View Localization|BevSplat：通过基于特征的Gaussian基元解决高度模糊性以实现弱监督跨视图定位|Qiwei Wang, Shaoxun Wu, Yujiao Shi|<http://arxiv.org/pdf/2502.09080v2>|BevSplat通过特征化高斯原语解决弱监督跨视图定位中的高度模糊问题，显著提升定位精度。|
|📝 更新|Electrolyzers-HSI: Close-Range Multi-Scene Hyperspectral Imaging Benchmark Dataset|电解质-HSI：近距离多场景高光谱成像基准数据集|Elias Arbash, Ahmed Jamal Afifi, Ymane Belahsen, Margret Fuchs, Pedram Ghamisi, Paul Scheunders, Richard Gloaguen|<http://arxiv.org/pdf/2505.20507v2>|[代码](https://github.com/hifexplo/Electrolyzers-HSI); 构建了Electrolyzers-HSI数据集，加速电解质材料分类，推动可持续回收。|
|🆕 发布|MegaHan97K: A Large-Scale Dataset for Mega-Category Chinese Character Recognition with over 97K Categories|MegaHan97K：一个包含超过97K类别的超大规模中文字符识别数据集|Yuyi Zhang, Yongxin Shi, Peirong Zhang, Yixin Zhao, Zhenhua Yang, Lianwen Jin|<http://arxiv.org/pdf/2506.04807v1>|[代码](https://github.com/SCUT-DLVCLab/MegaHan97K.); 构建了涵盖97K类别的MegaHan97K数据集，推动超大类别汉字识别研究。|
|📝 更新|Rethinking the Stability-Plasticity Trade-off in Continual Learning from an Architectural Perspective|重新从架构角度思考持续学习中的稳定性-塑性权衡|Aojun Lu, Hangjie Yuan, Tao Feng, Yanan Sun|<http://arxiv.org/pdf/2506.03951v2>|[代码](https://github.com/byyx666/Dual-Arch.); 提出了一种名为Dual-Arch的框架，通过架构层面解决连续学习中的稳定性-可塑性权衡问题，显著提升...|
|📝 更新|Adapt before Continual Learning|在持续学习之前进行自适应|Aojun Lu, Tao Feng, Hangjie Yuan, Chunhui Ding, Yanan Sun|<http://arxiv.org/pdf/2506.03956v2>|[代码](https://github.com/byyx666/ACL_code.); 提出Adapting PTMs before the core CL process，解决连续学习中...|
|🆕 发布|Scaling Laws for Robust Comparison of Open Foundation Language-Vision Models and Datasets|开放基础语言-视觉模型与数据集鲁棒比较的缩放定律|Marianna Nezhurina, Tomer Porian, Giovanni Pucceti, Tommie Kerssies, Romain Beaumont, Mehdi Cherti, Jenia Jitsev|<http://arxiv.org/pdf/2506.04598v1>|[代码](https://github.com/LAION-AI/scaling-laws-for-comparison.); 首次提出基于尺度定律比较开放语言视觉模型和数据集，为模型选择提供依据。|
|🆕 发布|Hierarchical-Task-Aware Multi-modal Mixture of Incremental LoRA Experts for Embodied Continual Learning|基于层次任务感知的多模态增量LoRA专家混合模型，用于具身持续学习|Ziqi Jia, Anmin Wang, Xiaoyang Qu, Xiaowen Yang, Jianzong Wang|<http://arxiv.org/pdf/2506.04595v1>|提出了一种分层任务感知混合增量LoRA专家模型，有效解决持续学习中的灾难性遗忘问题。|
|📝 更新|FOLIAGE: Towards Physical Intelligence World Models Via Unbounded Surface Evolution|叶脉：通过无界表面演化迈向物理智能世界模型|Xiaoyi Liu, Hao Tang|<http://arxiv.org/pdf/2506.03173v2>|FOLIAGE通过物理智能和多模态世界模型，实现了对无界表面生长的预测和塑造。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RaySt3R: Predicting Novel Depth Maps for Zero-Shot Object Completion|RaySt3R：预测零样本目标补全的新颖深度图|Bardienus P. Duisterhof, Jan Oberst, Bowen Wen, Stan Birchfield, Deva Ramanan, Jeffrey Ichnowski|<http://arxiv.org/pdf/2506.05285v1>|提出了一种基于单张RGB-D图像和查询射线预测深度图的新方法，有效解决了3D形状补全问题。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Navigating Motion Agents in Dynamic and Cluttered Environments through LLM Reasoning|在动态和拥挤环境中通过LLM推理导航运动代理|Yubo Zhao, Qi Wu, Yifan Wang, Yu-Wing Tai, Chi-Keung Tang|<http://arxiv.org/pdf/2503.07323v2>|利用大型语言模型实现动态复杂环境中多智能体自主导航，突破传统空间推理限制。|
|📝 更新|EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents|具身基准：全面基准测试视觉驱动具身智能体的多模态大型语言模型|Rui Yang, Hanyang Chen, Junyu Zhang, Mark Zhao, Cheng Qian, Kangrui Wang, Qineng Wang, Teja Venkat Koripella .etc.|<http://arxiv.org/pdf/2502.09560v3>|EmbodiedBench构建了全面基准，评估视觉驱动具身智能体，揭示MLLM在高级任务中出色但低级...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SparseMM: Head Sparsity Emerges from Visual Concept Responses in MLLMs|稀疏MM：在多语言大模型中，视觉概念响应中涌现的头稀疏性|Jiahui Wang, Zuyan Liu, Yongming Rao, Jiwen Lu|<http://arxiv.org/pdf/2506.05344v1>|[代码](https://github.com/CR400AF-A/SparseMM.); 揭示MLLMs中视觉注意力头的稀疏性，并提出SparseMM优化策略加速视觉理解。|
|🆕 发布|VideoMathQA: Benchmarking Mathematical Reasoning via Multimodal Understanding in Videos|视频数学问答：通过视频的多模态理解进行数学推理基准测试|Hanoona Rasheed, Abdelrahman Shaker, Anqi Tang, Muhammad Maaz, Ming-Hsuan Yang, Salman Khan, Fahad Khan|<http://arxiv.org/pdf/2506.05349v1>|[代码](https://mbzuai-oryx.github.io/VideoMathQA); 构建了VideoMathQA基准，评估视频中的多模态数学推理能力。|
|🆕 发布|Does Your 3D Encoder Really Work? When Pretrain-SFT from 2D VLMs Meets 3D VLMs|你的3D编码器真的有效吗？当2D视觉语言模型预训练的SFT遇到3D视觉语言模型|Haoyuan Li, Yanpeng Zhou, Yufei Gao, Tao Tang, Jianhua Han, Yujie Yuan, Dave Zhenyu Chen, Jiawang Bian .etc.|<http://arxiv.org/pdf/2506.05318v1>|该论文揭示了3D视觉语言模型在3D场景理解上的局限性，并提出了一种新的数据集以促进更有效的3D理解。|
|📝 更新|VCD: A Dataset for Visual Commonsense Discovery in Images|视觉常识发现图像数据集：VCD|Xiangqing Shen, Fanfan Wang, Siwei Wu, Rui Xia|<http://arxiv.org/pdf/2402.17213v2>|[代码](https://github.com/NUSTM/VCD.); 构建了大规模视觉常识数据集VCD，并开发模型VCM以发现图像中的视觉常识。|
|🆕 发布|TextVidBench: A Benchmark for Long Video Scene Text Understanding|文本视频基准：长视频场景文本理解基准|Yangyang Zhong, Ji Qi, Yuan Yao, Pengxin Luo, Yunfeng Yan, Donglian Qi, Zhiyuan Liu, Tat-Seng Chua|<http://arxiv.org/pdf/2506.04983v1>|构建首个针对长视频文本理解的基准TextVidBench，提出改进模型的方法以提升理解能力。|
|📝 更新|Geometric Visual Fusion Graph Neural Networks for Multi-Person Human-Object Interaction Recognition in Videos|几何视觉融合图神经网络在视频中进行多人人体-物体交互识别|Tanqiu Qiao, Ruochen Li, Frederick W. B. Li, Yoshiki Kubotani, Shigeo Morishima, Hubert P. H. Shum|<http://arxiv.org/pdf/2506.03440v2>|提出GeoVis-GNN，通过融合视觉和几何特征，有效识别视频中多人物体交互。|
|🆕 发布|From Objects to Anywhere: A Holistic Benchmark for Multi-level Visual Grounding in 3D Scenes|从物体到任何地方：3D场景多级视觉定位的全面基准|Tianxu Wang, Zhuofan Zhang, Ziyu Zhu, Yue Fan, Jing Xiong, Pengxiang Li, Xiaojian Ma, Qing Li|<http://arxiv.org/pdf/2506.04897v1>|构建了涵盖多级视觉定位的全面基准，揭示了空间和部分级视觉定位的挑战。|
|📝 更新|Contrastive Visual Data Augmentation|对比视觉数据增强|Yu Zhou, Bingxuan Li, Mohan Tang, Xiaomeng Jin, Te-Lin Wu, Kuan-Hao Huang, Heng Ji, Kai-Wei Chang .etc.|<http://arxiv.org/pdf/2502.17709v2>|提出CoDA策略，通过对比增强视觉数据，显著提升低资源概念和场景识别的准确率。|
|🆕 发布|Perceptual Decoupling for Scalable Multi-modal Reasoning via Reward-Optimized Captioning|感知解耦：通过奖励优化字幕实现可扩展的多模态推理|Yunhao Gou, Kai Chen, Zhili Liu, Lanqing Hong, Xin Jin, Zhenguo Li, James T. Kwok, Yu Zhang|<http://arxiv.org/pdf/2506.04559v1>|提出RACRO方法，通过奖励优化字幕生成，实现多模态推理的可扩展性。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MINT-CoT: Enabling Interleaved Visual Tokens in Mathematical Chain-of-Thought Reasoning|MINT-CoT：在数学思维链推理中启用交错视觉标记|Xinyan Chen, Renrui Zhang, Dongzhi Jiang, Aojun Zhou, Shilin Yan, Weifeng Lin, Hongsheng Li|<http://arxiv.org/pdf/2506.05331v1>|[代码](https://github.com/xinyan-cxy/MINT-CoT); MINT-CoT通过将数学问题中的视觉信息与文本推理步骤交织，有效提升了数学问题解决能力。|
|📝 更新|MMS-LLaMA: Efficient LLM-based Audio-Visual Speech Recognition with Minimal Multimodal Speech Tokens|MMS-LLaMA：基于最小多模态语音标记的高效LLM音频-视觉语音识别|Jeong Hun Yeo, Hyeongseop Rha, Se Jin Park, Yong Man Ro|<http://arxiv.org/pdf/2503.11315v2>|提出了一种高效的多模态语音LLM框架，通过最小化token长度和优化分配策略，显著降低了AVSR的计...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|APVR: Hour-Level Long Video Understanding with Adaptive Pivot Visual Information Retrieval|APVR：自适应枢轴视觉信息检索的每小时级长视频理解|Hong Gao, Yiming Bao, Xuezhan Tu, Bin Zhong, Minling Zhang|<http://arxiv.org/pdf/2506.04953v1>|提出APVR框架，通过自适应视觉信息检索实现小时级长视频理解，显著提升性能。|
|🆕 发布|HypeVPR: Exploring Hyperbolic Space for Perspective to Equirectangular Visual Place Recognition|超曲空间视角到等角视觉位置识别的探索：HypeVPR|Suhan Woo, Seongwon Lee, Jinwoo Jang, Euntai Kim|<http://arxiv.org/pdf/2506.04764v1>|[代码](https://github.com/suhan-woo/HypeVPR.git.); HypeVPR通过在双曲空间中构建层次化嵌入框架，有效解决了视角到等经纬投影的视觉场景识别问题，显著...|
|🆕 发布|Deep Learning Reforms Image Matching: A Survey and Outlook|深度学习革新图像匹配：综述与展望|Shihua Zhang, Zizhuo Li, Kaining Zhang, Yifan Lu, Yuxin Deng, Linfeng Tang, Xingyu Jiang, Jiayi Ma|<http://arxiv.org/pdf/2506.04619v1>|该论文综述了深度学习如何革新图像匹配，通过改进传统流程和引入端到端学习模块显著提升了鲁棒性和准确性。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Stable Vision Concept Transformers for Medical Diagnosis|稳定的视觉概念转换器用于医学诊断|Lijie Hu, Songning Lai, Yuan Hua, Shu Yang, Jingfeng Zhang, Di Wang|<http://arxiv.org/pdf/2506.05286v1>|提出稳定视觉概念转换器，解决医学诊断中模型可解释性和稳定性问题。|
|🆕 发布|DM-SegNet: Dual-Mamba Architecture for 3D Medical Image Segmentation with Global Context Modeling|DM-SegNet：用于3D医学图像分割的具有全局上下文建模的双Mamba架构|Hangyu Ji|<http://arxiv.org/pdf/2506.05297v1>|DM-SegNet通过融合Mamba架构和全局上下文建模，实现了3D医学图像分割的精确度提升。|
|🆕 发布|SAM-aware Test-time Adaptation for Universal Medical Image Segmentation|基于SAM感知的通用医学图像分割的测试时自适应|Jianghao Wu, Yicheng Wu, Yutong Xie, Wenjia Bai, You Zhang, Feilong Tang, Yulong Li, Yasmeen George .etc.|<http://arxiv.org/pdf/2506.05221v1>|[代码](https://github.com/JianghaoWu/SAM-TTA.); 提出SAM-TTA，通过测试时自适应框架提升医学图像分割性能，同时保持模型泛化能力。|
|🆕 发布|Track Any Anomalous Object: A Granular Video Anomaly Detection Pipeline|追踪任何异常物体：一种细粒度视频异常检测流程|Yuzhi Huang, Chenxin Li, Haitao Zhang, Zixu Lin, Yunlong Lin, Hengyu Liu, Wuyang Li, Xinyu Liu .etc.|<http://arxiv.org/pdf/2506.05175v1>|提出了一种细粒度视频异常检测框架，通过像素级异常对象跟踪实现更精确的异常定位。|
|📝 更新|Pre-training Everywhere: Parameter-Efficient Fine-Tuning for Medical Image Analysis via Target Parameter Pre-training|无处不在的预训练：通过目标参数预训练实现医学图像分析的高效微调|Xingliang Lei, Yiwen Ye, Zhisong Wang, Ziyang Chen, Minglei Shu, Weidong Cai, Yanning Zhang, Yong Xia|<http://arxiv.org/pdf/2408.15011v2>|提出了一种通过预训练目标参数的参数高效微调框架，显著提升了医学图像分析性能。|
|🆕 发布|Ontology-based knowledge representation for bone disease diagnosis: a foundation for safe and sustainable medical artificial intelligence systems|基于本体论的知识表示在骨病诊断中的应用：安全可持续医疗人工智能系统的基础|Loan Dao, Ngoc Quoc Ly|<http://arxiv.org/pdf/2506.04756v1>|构建基于本体知识的骨病诊断框架，提升医疗AI系统的可靠性和可解释性。|
|📝 更新|SuperMapNet for Long-Range and High-Accuracy Vectorized HD Map Construction|SuperMapNet：用于长距离和高精度矢量化高清地图构建|Ruqin Zhou, Chenguang Dai, Wanshou Jiang, Yongsheng Zhang, Hanyun Wang, San Jiang|<http://arxiv.org/pdf/2505.13856v2>|SuperMapNet通过融合视觉和激光数据，有效解决了长距离和高精度矢量高清地图构建中的特征感知和...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bringing SAM to new heights: Leveraging elevation data for tree crown segmentation from drone imagery|将SAM提升至新高度：利用高程数据从无人机影像中进行树冠分割|Mélisande Teng, Arthur Ouaknine, Etienne Laliberté, Yoshua Bengio, David Rolnick, Hugo Larochelle|<http://arxiv.org/pdf/2506.04970v1>|利用高程数据和SAM模型，实现了无人机影像中树木树冠的自动分割，提高了森林监测效率。|
|📝 更新|Knowledge-Informed Deep Learning for Irrigation Type Mapping from Remote Sensing|基于知识的深度学习在遥感灌溉类型映射中的应用|Oishee Bintey Hoque, Nibir Chandra Mandal, Abhijin Adiga, Samarth Swarup, Sayjro Kossi Nouwakpo, Amanda Wilson, Madhav Marathe|<http://arxiv.org/pdf/2505.08302v2>|提出KIIM方法，结合专业知识与深度学习，有效提升灌溉类型遥感映射的准确性。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Using In-Context Learning for Automatic Defect Labelling of Display Manufacturing Data|利用上下文学习自动标记显示制造数据的缺陷|Babar Hussain, Qiang Liu, Gang Chen, Bihai She, Dahai Yu|<http://arxiv.org/pdf/2506.04717v1>|提出了一种基于SegGPT的自动缺陷标注系统，显著提升工业显示面板检测效率。|
|🆕 发布|Perfecting Depth: Uncertainty-Aware Enhancement of Metric Depth|完美深度：基于不确定性的度量深度增强|Jinyoung Jun, Lei Chu, Jiahao Li, Yan Lu, Chang-Su Kim|<http://arxiv.org/pdf/2506.04612v1>|提出了一种结合随机不确定性和确定性优化的深度传感器增强框架，显著提升了深度图的可靠性和准确性。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EOC-Bench: Can MLLMs Identify, Recall, and Forecast Objects in an Egocentric World?|EOC-Bench：多模态语言大模型能否在自视角世界中识别、回忆和预测物体？|Yuqian Yuan, Ronghao Dang, Long Li, Wentong Li, Dian Jiao, Xin Li, Deli Zhao, Fan Wang .etc.|<http://arxiv.org/pdf/2506.05287v1>|提出EOC-Bench，评估MLLM在动态自视角场景中识别、回忆和预测物体的能力。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Parking, Perception, and Retail: Street-Level Determinants of Community Vitality in Harbin|哈尔滨社区活力的街道级决定因素：停车、感知与零售|HaoTian Lan|<http://arxiv.org/pdf/2506.05080v1>|构建了基于AI的社区商业活力指数，揭示街道特征对商业表现和用户满意度的影响。|
|🆕 发布|ComfyUI-Copilot: An Intelligent Assistant for Automated Workflow Development|舒适UI-协同助手：自动化工作流程开发智能助手|Zhenran Xu, Xue Yang, Yiyu Wang, Qingli Hu, Zijiao Wu, Longyue Wang, Weihua Luo, Kaifu Zhang .etc.|<http://arxiv.org/pdf/2506.05010v1>|[代码](https://github.com/AIDC-AI/ComfyUI-Copilot.); ComfyUI-Copilot通过智能推荐和一键构建，简化了AI艺术创作平台的操作流程。|
|📝 更新|Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World|曼哈顿世界中的鲁棒消失点估计的凸松弛|Bangyan Liao, Zhenjun Zhao, Haoang Li, Yi Zhou, Yingping Zeng, Hao Li, Peidong Liu|<http://arxiv.org/pdf/2505.04788v3>|[代码](https://github.com/WU-CVGL/GlobustVP.); 首次引入凸松弛技术，高效且鲁棒地估计曼哈顿世界的消失点。|
|🆕 发布|Truth in the Few: High-Value Data Selection for Efficient Multi-Modal Reasoning|真实在少数：高效多模态推理中的高价值数据选择|Shenshen Li, Kaiyuan Deng, Lei Wang, Hao Yang, Chong Peng, Peng Yan, Fumin Shen, Heng Tao Shen .etc.|<http://arxiv.org/pdf/2506.04755v1>|[代码](https://github.com/Leo-ssl/RAP.); 提出RAP方法，通过识别认知样本，实现高效的多模态推理。|
|📝 更新|Uncovering Memorization Effect in the Presence of Spurious Correlations|揭示存在虚假相关性时的记忆效应|Chenyu You, Haocheng Dai, Yifei Min, Jasjeet S. Sekhon, Sarang Joshi, James S. Duncan|<http://arxiv.org/pdf/2501.00961v3>|揭示了神经网络中虚假特征导致的记忆效应，并提出新框架消除这些特征以改善模型在少数群体上的性能。|
|🆕 发布|Vision-Based Autonomous MM-Wave Reflector Using ArUco-Driven Angle-of-Arrival Estimation|基于视觉的自主毫米波反射器：利用ArUco驱动的到达角估计|Josue Marroquin, Nan Inzali, Miles Dillon Lantz, Campbell Freeman, Amod Ashtekar, \\Ajinkya Umesh Mulik, Mohammed E Eltayeb|<http://arxiv.org/pdf/2506.05195v1>|提出了一种利用ArUco标记和视觉辅助的毫米波反射器系统，以增强非视距条件下的毫米波通信性能。|
|🆕 发布|Toward Better SSIM Loss for Unsupervised Monocular Depth Estimation|迈向更优的SSIM损失函数，用于无监督单目深度估计|Yijun Cao, Fuya Luo, Yongjie Li|<http://arxiv.org/pdf/2506.04758v1>|提出改进SSIM损失函数，优化无监督单目深度估计性能。|
|🆕 发布|FG 2025 TrustFAA: the First Workshop on Towards Trustworthy Facial Affect Analysis: Advancing Insights of Fairness, Explainability, and Safety (TrustFAA)|FG 2025 可信面部情感分析研讨会：迈向可信面部情感分析：推进公平性、可解释性和安全性（TrustFAA）的见解|Jiaee Cheong, Yang Liu, Harold Soh, Hatice Gunes|<http://arxiv.org/pdf/2506.05095v1>|首次提出“可信面部情感分析”概念，探讨公平性、可解释性和安全性问题，推动面部情感分析工具的伦理发展。|
|🆕 发布|PATS: Proficiency-Aware Temporal Sampling for Multi-View Sports Skill Assessment|PATS：基于熟练度感知的时间采样多视角运动技能评估|Edoardo Bianchi, Antonio Liotta|<http://arxiv.org/pdf/2506.04996v1>|PATS通过自适应时间采样，确保多视角运动技能评估中关键动作的完整性，显著提升评估准确率。|
|🆕 发布|Light and 3D: a methodological exploration of digitisation techniques adapted to a selection of objects from the Mus{é}e d'Arch{é}ologie Nationale|光与3D：针对国家考古博物馆选定对象数字化技术的方法论探索|Antoine Laurent, Jean Mélou, Catherine Schwab, Rolande Simon-Millot, Sophie Féret, Thomas Sagory, Carole Fritz, Jean-Denis Durou|<http://arxiv.org/pdf/2506.04925v1>|针对博物馆藏品数字化，提出应根据对象特性与用途选择适配的3D数字化方法。|
|🆕 发布|A Fast Unsupervised Scheme for Polygonal Approximation|快速无监督多边形逼近方案|Bimal Kumar Ray|<http://arxiv.org/pdf/2506.04664v1>|提出了一种快速无监督的闭合曲线多边形逼近方案，有效提升了逼近速度和美观度。|

