## [UPDATED!] **2025-06-08** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Generation to Generalization: Emergent Few-Shot Learning in Video Diffusion Models|从生成到泛化：视频扩散模型中的涌现式少样本学习|Pablo Acuaviva, Aram Davtyan, Mariam Hassan, Sebastian Stapf, Ahmad Rahimi, Alexandre Alahi, Paolo Favaro|<http://arxiv.org/pdf/2506.07280v1>|提出了一种利用少量样本快速适配新任务的视觉学习框架，实现了视频扩散模型从生成到泛化的突破。|
|🆕 发布|Advancing Multimodal Reasoning Capabilities of Multimodal Large Language Models via Visual Perception Reward|通过视觉感知奖励提升多模态大型语言模型的多模态推理能力|Tong Xiao, Xin Xu, Zhenya Huang, Hongyu Gao, Quan Liu, Qi Liu, Enhong Chen|<http://arxiv.org/pdf/2506.07218v1>|提出视觉感知奖励机制 Perception-R1，增强大型多模态语言模型的多模态感知与推理能力。|
|🆕 发布|Learning Compact Vision Tokens for Efficient Large Multimodal Models|学习紧凑视觉标记以实现高效大型多模态模型|Hao Tang, Chengchao Shen|<http://arxiv.org/pdf/2506.07138v1>|[代码](https://github.com/visresearch/LLaVA-STF.); 提出方法缩短视觉标记序列长度，提升大型多模态模型推理效率。|
|🆕 发布|SceneLCM: End-to-End Layout-Guided Interactive Indoor Scene Generation with Latent Consistency Model|场景LCM：基于潜在一致性模型的端到端布局引导交互式室内场景生成|Yangkai Lin, Jiabao Lei, Kui Jia|<http://arxiv.org/pdf/2506.07091v1>|[代码](https://scutyklin.github.io/SceneLCM); 提出SceneLCM框架，结合大语言模型与潜在一致性模型，实现用户指导的室内场景生成与优化。|
|🆕 发布|From Swath to Full-Disc: Advancing Precipitation Retrieval with Multimodal Knowledge Expansion|从条带到全盘：利用多模态知识扩展推进降水反演|Zheng Wang, Kai Ying, Bin Xu, Chunjiao Wang, Cong Bai|<http://arxiv.org/pdf/2506.07050v1>|[代码](https://github.com/Zjut-MultimediaPlus/PRE-Net.); 提出了一种两阶段的多模态知识扩展方法，通过PRE-Net模型显著提升了红外全盘降水检索的准确性。|
|🆕 发布|Lingshu: A Generalist Foundation Model for Unified Multimodal Medical Understanding and Reasoning|“灵术：一种用于统一多模态医学理解和推理的全能基础模型”|LASA Team, Weiwen Xu, Hou Pong Chan, Long Li, Mahani Aljunied, Ruifeng Yuan, Jianyu Wang, Chenghao Xiao .etc.|<http://arxiv.org/pdf/2506.07044v1>|提出了一种针对医疗领域定制的大型多模态语言模型Lingshu，通过综合数据策展和强化学习增强了医学理...|
|📝 更新|Vector-Quantized Vision Foundation Models for Object-Centric Learning|面向以对象为中心学习的矢量量化视觉基础模型|Rongzhen Zhao, Vivienne Wang, Juho Kannala, Joni Pajarinen|<http://arxiv.org/pdf/2502.20263v3>|[代码](https://github.com/Genera1Z/VQ-VFM-OCL.); 提出了一种统一架构VQ-VFM-OCL，通过共享量化视觉基础模型表示，增强了对象中心学习的监督效果。|
|📝 更新|Leveraging MLLM Embeddings and Attribute Smoothing for Compositional Zero-Shot Learning|利用大规模语言模型嵌入和属性平滑进行组合零样本学习|Xudong Yan, Songhe Feng, Yang Zhang, Jian Yang, Yueguan Lin, Haojun Fei|<http://arxiv.org/pdf/2411.12584v2>|[代码](https://github.com/xud-yan/Trident); 提出了一种融合多模态大语言模型嵌入和属性平滑的解耦框架，有效提升了组合零样本学习的泛化能力。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HotelMatch-LLM: Joint Multi-Task Training of Small and Large Language Models for Efficient Multimodal Hotel Retrieval|HotelMatch-LLM：小型和大型语言模型联合多任务训练，实现高效的多模态酒店检索|Arian Askari, Emmanouil Stergiadis, Ilya Gusev, Moran Beladev|<http://arxiv.org/pdf/2506.07296v1>|提出HotelMatch-LLM模型，融合大小语言模型进行多模态酒店检索，提升搜索效率和准确性。|
|🆕 发布|Mitigating Behavioral Hallucination in Multimodal Large Language Models for Sequential Images|减轻多模态大型语言模型在序列图像中的行为幻觉|Liangliang You, Junchi Yao, Shu Yang, Guimin Hu, Lijie Hu, Di Wang|<http://arxiv.org/pdf/2506.07184v1>|提出方法SHE减轻序列图像中大型多模态语言模型的行为幻觉问题。|
|🆕 发布|SAP-Bench: Benchmarking Multimodal Large Language Models in Surgical Action Planning|SAP-Bench：手术动作规划中多模态大型语言模型的基准测试|Mengya Xu, Zhongzhen Huang, Dillan Imans, Yiru Ye, Xiaofan Zhang, Qi Dou|<http://arxiv.org/pdf/2506.07196v1>|提出SAP-Bench基准，通过大规模、高质量数据集评估大型多模态语言模型在手术动作规划中的性能。|
|🆕 发布|FLAIR-HUB: Large-scale Multimodal Dataset for Land Cover and Crop Mapping|FLAIR-HUB：大规模多模态地表覆盖与作物映射数据集|Anatol Garioud, Sébastien Giordano, Nicolas David, Nicolas Gonthier|<http://arxiv.org/pdf/2506.07080v1>|[代码](https://ignf.github.io/FLAIR); 介绍了FLAIR-HUB，一个大规模多模态土地覆盖和作物映射数据集，提升了多传感器数据融合和细粒度分...|
|📝 更新|Stop Looking for Important Tokens in Multimodal Language Models: Duplication Matters More|不要在多模态语言模型中寻找重要标记：重复更为关键|Zichen Wen, Yifeng Gao, Shaobo Wang, Junyuan Zhang, Qintong Zhang, Weijia Li, Conghui He, Linfeng Zhang|<http://arxiv.org/pdf/2502.11494v2>|[代码](https://github.com/ZichenWen1/DART.); 提出新方法DART，通过基于重复度的视觉token剪枝，提升多模态语言模型效率。|
|🆕 发布|A Culturally-diverse Multilingual Multimodal Video Benchmark & Model|多语言多模态文化多样性视频基准与模型|Bhuiyan Sanjid Shafique, Ashmal Vayani, Muhammad Maaz, Hanoona Abdul Rasheed, Dinura Dissanayake, Mohammed Irfan Kurpath, Yahya Hmaiti, Go Inoue .etc.|<http://arxiv.org/pdf/2506.07032v1>|[代码](https://mbzuai-oryx.github.io/ViMUL); 提出多语言视频理解模型ViMUL及文化多样性的评估基准ViMUL-Bench，促进跨语言视频内容理解...|
|📝 更新|CAST: Contrastive Adaptation and Distillation for Semi-Supervised Instance Segmentation|CAST: 用于半监督实例分割的对比自适应与蒸馏|Pardis Taghavi, Tian Liu, Renjie Li, Reza Langari, Zhengzhong Tu|<http://arxiv.org/pdf/2505.21904v3>|CAST通过对比自适应和蒸馏，将大型视觉模型压缩为紧凑专家，实现半监督实例分割性能提升。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TABLET: Table Structure Recognition using Encoder-only Transformers|TABLET：使用仅编码器Transformer的表格结构识别|Qiyu Hou, Jun Wang|<http://arxiv.org/pdf/2506.07015v1>|提出了一种基于Split-Merge和双Transformer编码器的表格结构识别方法，提高了大规模...|
|🆕 发布|LaTtE-Flow: Layerwise Timestep-Expert Flow-based Transformer|层时专精流：基于流的时间步长逐层专精变换器|Ying Shen, Zhiyang Xu, Jiuhai Chen, Shizhe Diao, Jiaxin Zhang, Yuguang Yao, Joy Rimchala, Ismini Lourentzou .etc.|<http://arxiv.org/pdf/2506.06952v1>|LaTtE-Flow通过创新的层时专家长流架构，在统一的多模态模型中高效实现图像理解和生成。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Image segmentation and classification of E-waste for waste segregation|电子废物图像分割与分类用于废物分离|Prakriti Tripathi, Theertha Biju, Maniram Thota, Rakesh Lingam|<http://arxiv.org/pdf/2506.07122v1>|提出了一种利用机器学习模型对电子废弃物进行分类和分割的方法，以辅助机器人实现废品分拣。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Robust Real-Time Lane Detection Method with Fog-Enhanced Feature Fusion for Foggy Conditions|雾天条件下的鲁棒实时车道检测方法：基于雾增强特征融合|Ronghui Zhang, Yuhang Ma, Tengfei Li, Ziyu Lin, Yueying Wu, Junzhou Chen, Lin Zhang, Jia Hu .etc.|<http://arxiv.org/pdf/2504.06121v4>|提出了一种针对雾天条件下的鲁棒实时车道检测方法，通过特征融合网络显著提升了雾天环境下的检测性能。|
|🆕 发布|Task-driven real-world super-resolution of document scans|面向任务的文档扫描实时超分辨率重建|Maciej Zyrek, Tomasz Tarasiewicz, Jakub Sadel, Aleksandra Krzywon, Michal Kawulok|<http://arxiv.org/pdf/2506.06953v1>|提出了一种针对文档扫描的任务驱动超分辨率方法，通过多任务学习优化OCR性能，实现了真实场景下的效果提...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning|UCOD-DPL：基于动态伪标签学习的无监督伪装目标检测|Weiqi Yan, Lvhai Chen, Huaijia Kou, Shengchuan Zhang, Yan Zhang, Liujuan Cao|<http://arxiv.org/pdf/2506.07087v1>|提出动态伪标签学习框架UCOD-DPL，通过自适应伪标签模块和双分支对抗解码器，有效提升无监督伪装物...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Technical Report for ICRA 2025 GOOSE 3D Semantic Segmentation Challenge: Adaptive Point Cloud Understanding for Heterogeneous Robotic Systems|《2025年ICRA鹅群3D语义分割挑战技术报告：异质机器人系统的自适应点云理解》|Xiaoya Zhang|<http://arxiv.org/pdf/2506.06995v1>|提出自适应点云理解方法，通过特定平台条件化和跨数据集类别对齐，显著提升异构机器人系统在复杂环境下的3...|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EgoNormia: Benchmarking Physical Social Norm Understanding|自我规范：物理社会规范理解基准测试|MohammadHossein Rezaei, Yicheng Fu, Phil Cuvin, Caleb Ziems, Yanzhe Zhang, Hao Zhu, Diyi Yang|<http://arxiv.org/pdf/2502.20490v4>|提出了EGONORMIA基准，通过 egocentric 视频中的多选问题评估并提升视觉语言模型对社...|
|🆕 发布|HOI-PAGE: Zero-Shot Human-Object Interaction Generation with Part Affordance Guidance|基于部分功效引导的零样本人类-物体交互生成：HOI-PAGE|Lei Li, Angela Dai|<http://arxiv.org/pdf/2506.07209v1>|提出零样本文本驱动的4D人-物交互生成方法，通过部分功效图实现细粒度交互合成。|
|📝 更新|OctFusion: Octree-based Diffusion Models for 3D Shape Generation|八叉树融合：基于八叉树的扩散模型用于三维形状生成|Bojun Xiong, Si-Tong Wei, Xin-Yang Zheng, Yan-Pei Cao, Zhouhui Lian, Peng-Shuai Wang|<http://arxiv.org/pdf/2408.14732v2>|[代码](https://github.com/octree-nn/octfusion.); 提出OctFusion方法，利用八叉树和统一多尺度U-Net快速生成高质量3D形状。|
|🆕 发布|Hallucination at a Glance: Controlled Visual Edits and Fine-Grained Multimodal Learning|《一瞥之幻觉：可控视觉编辑与细粒度多模态学习》|Tianyi Bai, Yuxuan Fan, Jiantao Qiu, Fupeng Sun, Jiayi Song, Junlin Han, Zichen Liu, Conghui He .etc.|<http://arxiv.org/pdf/2506.07227v1>|提出了一种生成微调数据集和监督细粒度视觉推理的方法，有效减少了大型多模态语言模型的幻觉现象并提高了视...|
|🆕 发布|TV-LiVE: Training-Free, Text-Guided Video Editing via Layer Informed Vitality Exploitation|TV-LiVE：无需训练，基于文本指导的通过层信息驱动的视频编辑|Min-Jung Kim, Dongjin Kim, Seokju Yun, Jaegul Choo|<http://arxiv.org/pdf/2506.07205v1>|[代码](https://emjay73.github.io/TV_LiVE); 提出了一种无需训练、文本引导的视频编辑框架，实现了物体添加和非刚性变换的复杂编辑任务。|
|📝 更新|Lipschitz-Driven Noise Robustness in VQ-AE for High-Frequency Texture Repair in ID-Specific Talking Heads|lipschitz驱动噪声鲁棒性在VQ-AE中用于特定身份说话人高频纹理修复|Jian Yang, Xukun Wang, Wentao Wang, Guoming Li, Qihang Fang, Ruihong Yuan, Tianyang Wang, Xiaomei Zhang .etc.|<http://arxiv.org/pdf/2410.00990v3>|提出了一种基于Lipschitz连续性理论的VQ-AE后处理框架，实现了高频纹理修复和唇同步的实时稳...|
|🆕 发布|Hi-VAE: Efficient Video Autoencoding with Global and Detailed Motion|高效视频自动编码：全局与细节运动结合的方法|Huaize Liu, Wenzhang Sun, Qiyuan Zhang, Donglin Di, Biao Gong, Hao Li, Chen Wei, Changqing Zou|<http://arxiv.org/pdf/2506.07136v1>|提出Hi-VAE框架，分层编码视频运动表示，大幅提升压缩率和重建质量。|
|📝 更新|MeshArt: Generating Articulated Meshes with Structure-Guided Transformers|《结构引导变换器生成关节网格的MeshArt》|Daoyi Gao, Yawar Siddiqui, Lei Li, Angela Dai|<http://arxiv.org/pdf/2412.11596v2>|提出了一种分阶段生成关节3D网格的方法，通过结构引导的变换器实现了高质量、结构化的网格生成。|
|🆕 发布|D2R: dual regularization loss with collaborative adversarial generation for model robustness|D2R: 双重正则化损失与协同对抗生成以提高模型鲁棒性|Zhenyu Liu, Huizhi Liang, Rajiv Ranjan, Zhanxing Zhu, Vaclav Snasel, Varun Ojha|<http://arxiv.org/pdf/2506.07056v1>|提出D2R损失函数和协作对抗生成策略，增强模型对抗攻击的鲁棒性。|
|📝 更新|SageAttention2: Efficient Attention with Thorough Outlier Smoothing and Per-thread INT4 Quantization|SageAttention2：具有彻底异常值平滑和线程级INT4量化的高效注意力机制|Jintao Zhang, Haofeng Huang, Pengle Zhang, Jia Wei, Jun Zhu, Jianfei Chen|<http://arxiv.org/pdf/2411.10958v6>|[代码](https://github.com/thu-ml/SageAttention.); 提出INT4量化加速注意力计算方法，通过矩阵量化与平滑技术提升效率与精度。|
|🆕 发布|MAGNET: A Multi-agent Framework for Finding Audio-Visual Needles by Reasoning over Multi-Video Haystacks|磁针：一种通过多视频干草堆推理查找音频视觉 needles 的多智能体框架|Sanjoy Chowdhury, Mohamed Elmoghany, Yohan Abeysinghe, Junjie Fei, Sayan Nag, Salman Khan, Mohamed Elhoseiny, Dinesh Manocha|<http://arxiv.org/pdf/2506.07016v1>|[代码](https://schowdhury671.github.io/magnet_project); 提出新型任务AV-HaystacksQA，并引入多智能体框架MAGNET，提升大规模音视频检索与推理...|
|📝 更新|HAIC: Improving Human Action Understanding and Generation with Better Captions for Multi-modal Large Language Models|HAIC：通过为多模态大型语言模型提供更好的字幕来提高人类行为理解和生成|Xiao Wang, Jingyun Hua, Weihong Lin, Yuanxing Zhang, Fuzheng Zhang, Jianlong Wu, Di Zhang, Liqiang Nie|<http://arxiv.org/pdf/2502.20811v2>|提出两阶段数据标注流程，通过高质量视频数据集提升多模态大语言模型对人类动作的理解和生成能力。|
|📝 更新|ChartGalaxy: A Dataset for Infographic Chart Understanding and Generation|图表星系：一个用于信息图表理解和生成的数据集|Zhen Li, Duan Li, Yukai Guo, Xinyuan Guo, Bowen Li, Lanxi Xiao, Shenyu Qiao, Jiashu Chen .etc.|<http://arxiv.org/pdf/2505.18668v3>|提出了ChartGalaxy数据集，助力大型视觉语言模型更好地理解和生成信息图表。|
|🆕 发布|AR-RAG: Autoregressive Retrieval Augmentation for Image Generation|AR-RAG：自回归检索增强图像生成|Jingyuan Qi, Zhiyang Xu, Qifan Wang, Lifu Huang|<http://arxiv.org/pdf/2506.06962v1>|提出了一种动态检索增强的图像生成方法AR-RAG，通过逐步引入相关视觉片段，有效提升了生成图像的多样...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI|边缘设备上图像恢复的多步引导扩散：迈向具身AI的轻量级感知|Aditya Chakravarty|<http://arxiv.org/pdf/2506.07286v1>|提出多步优化策略提升图像修复质量，实现边缘设备上实时视觉感知的轻量级解决方案。|
|📝 更新|Decoupled Data Consistency with Diffusion Purification for Image Restoration|解耦数据一致性结合扩散净化用于图像恢复|Xiang Li, Soo Min Kwon, Shijun Liang, Ismail R. Alkhouri, Saiprasad Ravishankar, Qing Qu|<http://arxiv.org/pdf/2403.06054v6>|提出了一种解耦数据一致性与扩散净化的图像恢复方法，减少了计算负担并提高了效率。|
|🆕 发布|Frame Guidance: Training-Free Guidance for Frame-Level Control in Video Diffusion Models|帧引导：无需训练的帧级控制引导在视频扩散模型中的应用|Sangwon Jang, Taekyung Ki, Jaehyeong Jo, Jaehong Yoon, Soo Ye Kim, Zhe Lin, Sung Ju Hwang|<http://arxiv.org/pdf/2506.07177v1>|提出了一种无需训练的帧级指导方法Frame Guidance，实现了对视频生成的高效控制。|
|📝 更新|DiC: Rethinking Conv3x3 Designs in Diffusion Models|DiC：重新思考扩散模型中的卷积3x3设计|Yuchuan Tian, Jing Han, Chengcheng Wang, Yuchen Liang, Chao Xu, Hanting Chen|<http://arxiv.org/pdf/2501.00603v2>|[代码](https://github.com/YuchuanTian/DiC); 重新设计3x3卷积构建快速高效的扩散模型DiC，超越现有扩散变压器性能。|
|🆕 发布|SiliCoN: Simultaneous Nuclei Segmentation and Color Normalization of Histological Images|硅网：组织学图像的同时核分割与颜色标准化|Suman Mahapatra, Pradipta Maji|<http://arxiv.org/pdf/2506.07028v1>|提出了一种深度生成模型，能同时进行核分割和染色图像颜色标准化，通过解耦表示提高了泛化性和适应性。|
|📝 更新|LLM-HDR: Bridging LLM-based Perception and Self-Supervision for Unpaired LDR-to-HDR Image Reconstruction|LLM-HDR：基于LLM的感知与自监督融合的无配对低动态范围到高动态范围图像重建|Hrishav Bakul Barua, Kalin Stefanov, Lemuel Lai En Che, Abhinav Dhall, KokSheik Wong, Ganesh Krishnasamy|<http://arxiv.org/pdf/2410.15068v3>|[代码](https://github.com/HrishavBakulBarua/LLM-HDR); 提出了一种利用大型语言模型感知的LLM-HDR方法，通过无配对数据集实现LDR到HDR图像的高质量重...|
|🆕 发布|Towards Physics-informed Diffusion for Anomaly Detection in Trajectories|面向物理信息驱动的扩散模型在轨迹异常检测中的应用|Arun Sharma, Mingzhou Yang, Majid Farhadloo, Subhankar Ghosh, Bharat Jayaprakash, Shashi Shekhar|<http://arxiv.org/pdf/2506.06999v1>|[代码](https://github.com/arunshar/Physics-Informed-Diffusion-Probabilistic-Model.); 提出了一种融合物理知识的扩散模型，有效检测异常轨迹并降低误报率。|
|📝 更新|Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles|四目更胜双眸：通过差异化思维和互补集成来利用大型模型的协作潜力|Jun Xie, Xiongjun Guan, Yingjian Zhu, Zhaoran Zhao, Xinming Wang, Hongzhu Yi, Feng Chen, Zhepeng Wang|<http://arxiv.org/pdf/2505.16784v2>|[代码](https://github.com/XiongjunGuan/EgoSchema-CVPR25.); 利用多样化提示和模型集成策略，有效提升大型多模态模型在视频理解任务上的表现。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Reinforcing Video Reasoning with Focused Thinking|用聚焦思维强化视频推理|Jisheng Dang, Jingze Wu, Teng Wang, Xuanhui Lin, Nannan Zhu, Hongbo Chen, Wei-Shi Zheng, Meng Wang .etc.|<http://arxiv.org/pdf/2505.24718v3>|[代码](https://github.com/longmalongma/TW-GRPO); 提出TW-GRPO框架，通过聚焦思考和细粒度奖励提升视觉推理准确性和效率。|
|🆕 发布|GoTrack: Generic 6DoF Object Pose Refinement and Tracking|GoTrack：通用六自由度物体位姿精炼与跟踪|Van Nguyen Nguyen, Christian Forster, Sindi Shkodrani, Vincent Lepetit, Bugra Tekin, Cem Keskin, Tomas Hodan|<http://arxiv.org/pdf/2506.07155v1>|[代码](https://github.com/facebookresearch/gotrack); 提出了一种无需特定对象训练的通用6DoF对象位姿精炼与跟踪方法，通过结合模型到帧和帧到帧的光流估计，...|
|🆕 发布|Interpretable and Reliable Detection of AI-Generated Images via Grounded Reasoning in MLLMs|基于大型语言模型地面推理的可解释且可靠的AI生成图像检测|Yikun Ji, Hong Yan, Jun Lan, Huijia Zhu, Weiqiang Wang, Qi Fan, Liqing Zhang, Jianfu Zhang|<http://arxiv.org/pdf/2506.07045v1>|利用多模态大语言模型和分阶段优化策略，实现了对AI生成图像的准确检测与可解释的视觉定位。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Optimal Transport Driven Asymmetric Image-to-Image Translation for Nuclei Segmentation of Histological Images|基于最优传输驱动的核不对称图像到图像转换用于组织学图像的核分割|Suman Mahapatra, Pradipta Maji|<http://arxiv.org/pdf/2506.07023v1>|提出了一种结合最优传输理论的深度生成模型，有效解决了核分割中信息不对称问题，提升了分割性能并降低了网...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Fully-Geometric Cross-Attention for Point Cloud Registration|点云配准的全几何交叉注意力机制|Weijie Wang, Guofeng Mei, Jian Zhang, Nicu Sebe, Bruno Lepri, Fabio Poiesi|<http://arxiv.org/pdf/2502.08285v2>|引入一种全几何交叉注意力机制，通过融合超点级信息提高点云配准精度。|
|🆕 发布|UNO: Unified Self-Supervised Monocular Odometry for Platform-Agnostic Deployment|统一自监督单目里程计：面向跨平台部署的解决方案|Wentao Zhao, Yihe Niu, Yanbo Wang, Tianchen Deng, Shenghai Yuan, Zhenli Wang, Rui Guo, Jingchuan Wang|<http://arxiv.org/pdf/2506.07013v1>|提出了一种统一的单目视觉里程计框架，通过混合专家策略和可微分模块，实现了跨平台和场景的鲁棒定位。|
|🆕 发布|Hybrid Mesh-Gaussian Representation for Efficient Indoor Scene Reconstruction|混合网格-高斯表示法用于高效室内场景重建|Binxiao Huang, Zhihao Li, Shiyong Liu, Xiao Tang, Jiajun Tang, Jiaqi Lin, Yuxin Cheng, Zhenyu Chen .etc.|<http://arxiv.org/pdf/2506.06988v1>|提出了一种结合3D高斯分布和纹理网格的室内场景重建方法，优化了渲染效率并保持了渲染质量。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Faster than Fast: Accelerating Oriented FAST Feature Detection on Low-end Embedded GPUs|"快于快速：在低端嵌入式GPU上加速定向FAST特征检测"|Qiong Chang, Xinyuan Chen, Xiang Li, Weimin Wang, Jun Miyazaki|<http://arxiv.org/pdf/2506.07164v1>|提出两种加速面向低端嵌入式GPU的Oriented FAST特征检测方法，实现超过7.3倍的速度提升...|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AllTracker: Efficient Dense Point Tracking at High Resolution|"AllTracker：高效高分辨率密集点跟踪"|Adam W. Harley, Yang You, Xinglong Sun, Yang Zheng, Nikhil Raghuraman, Yunqi Gu, Sheldon Liang, Wen-Hsuan Chu .etc.|<http://arxiv.org/pdf/2506.07310v1>|提出了一种高效的高分辨率密集点跟踪方法，通过估计流场实现一帧对多帧的长距离点跟踪。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FANVID: A Benchmark for Face and License Plate Recognition in Low-Resolution Videos|低分辨率视频中人脸和车牌识别的基准测试：FANVID|Kavitha Viswanathan, Vrinda Goel, Shlesh Gholap, Devayan Ghosh, Madhav Gupta, Dhruvi Ganatra, Sanket Potdar, Amit Sethi|<http://arxiv.org/pdf/2506.07304v1>|提出了FANVID基准，通过低分辨率视频促进面部和车牌的时序识别研究。|
|🆕 发布|AugmentGest: Can Random Data Cropping Augmentation Boost Gesture Recognition Performance?|随机数据裁剪增强是否能提升手势识别性能？|Nada Aboudeshish, Dmitry Ignatov, Radu Timofte|<http://arxiv.org/pdf/2506.07216v1>|[代码](https://github.com/NadaAbodeshish/Random-Cropping-augmentation-HGR); 提出了一种数据增强框架，通过随机裁剪等方法提升手势识别模型的泛化能力和鲁棒性。|
|🆕 发布|Dual-view Spatio-Temporal Feature Fusion with CNN-Transformer Hybrid Network for Chinese Isolated Sign Language Recognition|双视角时空特征融合基于CNN-Transformer混合网络的中国孤立手语识别|Siyuan Jing, Guangxue Wang, Haoyang Zhai, Qin Tao, Jun Yang, Bing Wang, Peng Jin|<http://arxiv.org/pdf/2506.06966v1>|提出双视角数据集并采用CNN-Transformer混合网络，有效融合手语视频特征，提升孤立手语识别...|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AdaReTaKe: Adaptive Redundancy Reduction to Perceive Longer for Video-language Understanding|自适应冗余减少以增强视频-语言理解中的感知时长：AdaReTaKe|Xiao Wang, Qingyi Si, Jianlong Wu, Shiyu Zhu, Li Cao, Liqiang Nie|<http://arxiv.org/pdf/2503.12559v2>|[代码](https://github.com/SCZwangxiao/video-FlexReduc.git.); 提出了一种自适应视觉冗余减少方法AdaReTaKe，使大型多模态语言模型能处理更长的视频而保留关键信...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|"CASE: Contrastive Activation for Saliency Estimation|CASE: 对比激活用于显著性估计|Dane Williamson, Yangfeng Ji, Matthew Dwyer|<http://arxiv.org/pdf/2506.07327v1>|提出了一种新的对比解释方法CASE，解决了现有显著性方法在区分不同类别时的不足，提高了解释的准确性和...|
|🆕 发布|A Layered Self-Supervised Knowledge Distillation Framework for Efficient Multimodal Learning on the Edge|边缘计算中面向高效多模态学习的分层自监督知识蒸馏框架|Tarique Dahri, Zulfiqar Ali Memon, Zhenyu Yu, Mohd. Yamani Idna Idris, Sheheryar Khan, Sadiq Ahmad, Maged Shoman, Saddam Aziz .etc.|<http://arxiv.org/pdf/2506.07055v1>|提出了一种轻量级知识蒸馏框架，通过自监督学习增强模型泛化能力，无需大型教师网络即可提升边缘设备上的多...|
|🆕 发布|Guiding Cross-Modal Representations with MLLM Priors via Preference Alignment|通过偏好对齐引导跨模态表征的MLLM先验|Pengfei Zhao, Rongbo Luan, Wei Zhang, Peng Wu, Sifeng He|<http://arxiv.org/pdf/2506.06970v1>|提出MAPLE框架，利用MLLM的细粒度对齐先验引导跨模态表征学习，有效提升细粒度跨模态检索性能。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Unifying 2D and 3D Vision-Language Understanding|统一二维与三维视觉-语言理解|Ayush Jain, Alexander Swerdlow, Yuzhou Wang, Sergio Arnaud, Ada Martin, Alexander Sax, Franziska Meier, Katerina Fragkiadaki|<http://arxiv.org/pdf/2503.10745v3>|提出统一架构UniVLG，融合2D和3D视觉语言理解，利用2D模型预训练权重并引入语言条件掩码解码器...|
|🆕 发布|Hierarchical Feature-level Reverse Propagation for Post-Training Neural Networks|层次化特征级反向传播用于训练后神经网络|Ni Ding, Lei He, Shengbo Eben Li, Keqiang Li|<http://arxiv.org/pdf/2506.07188v1>|提出了一种分层特征级反向传播框架，通过独立训练网络组件提高模型透明度和训练灵活性。|
|📝 更新|QP-SNN: Quantized and Pruned Spiking Neural Networks|量化与剪枝脉冲神经网络：QP-SNN|Wenjie Wei, Malu Zhang, Zijian Zhou, Ammar Belatreche, Yimeng Shan, Yu Liang, Honglin Cao, Jieyuan Zhang .etc.|<http://arxiv.org/pdf/2502.05905v2>|提出了一种结合量化和剪枝的轻量级脉冲神经网络，提升了资源受限设备上的性能和效率。|
|🆕 发布|Accelerating 3D Gaussian Splatting with Neural Sorting and Axis-Oriented Rasterization|使用神经排序和轴向定向光栅化加速三维高斯散点绘制|Zhican Wang, Guanghui He, Dantong Liu, Lingjun Gao, Shell Xu Hu, Chen Zhang, Zhuoran Song, Nicholas Lane .etc.|<http://arxiv.org/pdf/2506.07069v1>|提出了一种结合硬件设计和神经网络优化的方法，大幅提高了3D Gaussian Splatting的渲...|
|🆕 发布|QForce-RL: Quantized FPGA-Optimized Reinforcement Learning Compute Engine|QForce-RL：量化FPGA优化强化学习计算引擎|Anushka Jha, Tanushree Dewangan, Mukul Lokhande, Santosh Kumar Vishvakarma|<http://arxiv.org/pdf/2506.07046v1>|提出QForce-RL方法，通过量化技术提升FPGA上强化学习部署的能效和吞吐量。|
|📝 更新|Not All Samples Should Be Utilized Equally: Towards Understanding and Improving Dataset Distillation|《并非所有样本都应同等利用：迈向理解与改进数据集精炼》|Shaobo Wang, Yantai Yang, Qilong Wang, Kaixin Li, Linfeng Zhang, Junchi Yan|<http://arxiv.org/pdf/2408.12483v2>|提出样本难度校正方法，优化数据集精简质量，提升低样本密度下数据集表现。|
|📝 更新|E2E-Swin-Unet++: An Enhanced End-to-End Swin-Unet Architecture With Dual Decoders For PTMC Segmentation|E2E-Swin-Unet++：一种具有双解码器的增强型端到端Swin-Unet架构，用于PTMC分割|Maryam Dialameh, Hossein Rajabzadeh, Moslem Sadeghi-Goughari, Jung Suk Sim, Hyock Ju Kwon|<http://arxiv.org/pdf/2410.18239v2>|提出了一种双解码器Transformer架构，通过结合甲状腺结构，显著提升了PTMC超声图像的分割精...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VORTEX: A Spatial Computing Framework for Optimized Drone Telemetry Extraction from First-Person View Flight Data|VORTEX：一种用于从第一人称视角飞行数据中优化无人机遥测提取的空间计算框架|James E. Gallagher, Edward J. Oughton|<http://arxiv.org/pdf/2412.18505v2>|提出VORTEX系统，利用OCR技术从FPV无人机视频提取遥测数据，优化了精度与效率。|
|🆕 发布|Flattery in Motion: Benchmarking and Analyzing Sycophancy in Video-LLMs|动态奉承：在视频大型语言模型中评估和分析谄媚行为|Wenrui Zhou, Shu Yang, Qingsong Yang, Zikun Guo, Lijie Hu, Di Wang|<http://arxiv.org/pdf/2506.07180v1>|提出首个视频大语言模型奉承行为评估基准，通过多角度分析降低视觉领域奉承偏差。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MolX: Enhancing Large Language Models for Molecular Understanding With A Multi-Modal Extension|MolX：通过多模态扩展增强大型语言模型对分子的理解能力|Khiem Le, Zhichun Guo, Kaiwen Dong, Xiaobao Huang, Bozhao Nan, Roshni Iyer, Xiangliang Zhang, Olaf Wiest .etc.|<http://arxiv.org/pdf/2406.06777v6>|提出多模态扩展MolX，增强大型语言模型对分子的理解能力，提升化学领域任务表现。|
|📝 更新|AgentDrug: Utilizing Large Language Models in an Agentic Workflow for Zero-Shot Molecular Optimization|AgentDrug：在智能体工作流中利用大型语言模型进行零样本分子优化|Khiem Le, Ting Hua, Nitesh V. Chawla|<http://arxiv.org/pdf/2410.13147v9>|提出了一种结合大型语言模型的代理工作流AgentDrug，实现了零样本分子优化的显著准确性提升。|
|🆕 发布|BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction|“BePo：利用俯视图和稀疏点进行高效准确的三维占用预测”|Yunxiao Shi, Hong Cai, Jisoo Jeong, Yinhao Zhu, Shizhong Han, Amin Ansari, Fatih Porikli|<http://arxiv.org/pdf/2506.07002v1>|提出了一种结合鸟瞰图和稀疏点的3D占位预测方法，有效解决了小物体和大表面建模难题。|
|🆕 发布|DM$^3$Net: Dual-Camera Super-Resolution via Domain Modulation and Multi-scale Matching|DM$^3$Net：基于域调制与多尺度匹配的双摄像头超分辨率网络|Cong Guan, Jiacheng Ying, Yuya Ieiri, Osamu Yoshie|<http://arxiv.org/pdf/2506.06993v1>|提出DM$^3$Net，通过领域调制和多尺度匹配提升双摄像头超分辨率性能。|
|📝 更新|Quantization without Tears|无泪量化|Minghao Fu, Hao Yu, Jie Shao, Junjie Zhou, Ke Zhu, Jianxin Wu|<http://arxiv.org/pdf/2411.13918v3>|[代码](https://github.com/wujx2001/QwT); 提出了一种简单高效的量化方法Quantization without Tears，通过引入轻量级结构...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Backdoor Attack on Vision Language Models with Stealthy Semantic Manipulation|具有隐秘语义操纵的视觉语言模型的后门攻击|Zhiyuan Zhong, Zhen Sun, Yepang Liu, Xinlei He, Guanhong Tao|<http://arxiv.org/pdf/2506.07214v1>|提出利用跨模态语义不匹配作为隐含触发器的后门攻击方法，通过数据污染实现隐蔽性强的语义操纵。|
|🆕 发布|Long-Tailed Learning for Generalized Category Discovery|长尾学习用于泛化类别发现|Cuong Manh Hoang|<http://arxiv.org/pdf/2506.06965v1>|提出了一种针对长尾分布的广义类别发现框架，通过自引导标注和表示平衡技术提高了模型对尾部类别的识别能力...|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Boosting Adversarial Transferability via Commonality-Oriented Gradient Optimization|通过共性导向梯度优化提升对抗性迁移性|Yanting Gao, Yepeng Liu, Junming Liu, Qi Zhang, Hongyun Zhang, Duoqian Miao, Cairong Zhao|<http://arxiv.org/pdf/2506.06992v1>|提出了一种针对Vision Transformers的梯度优化策略，通过增强模型共性信息扰动和抑制个...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Imperative Learning: A Self-supervised Neuro-Symbolic Learning Framework for Robot Autonomy|《命令式学习：一种用于机器人自主性的自监督神经符号学习框架》|Chen Wang, Kaiyi Ji, Junyi Geng, Zhongqiang Ren, Taimeng Fu, Fan Yang, Yifan Guo, Haonan He .etc.|<http://arxiv.org/pdf/2406.16087v6>|提出了一种自监督神经符号学习框架Imperative Learning，通过结合符号推理克服了数据驱...|
|🆕 发布|Transfer Learning and Explainable AI for Brain Tumor Classification: A Study Using MRI Data from Bangladesh|脑肿瘤分类中的迁移学习与可解释人工智能研究：基于孟加拉国MRI数据的分析|Shuvashis Sarker|<http://arxiv.org/pdf/2506.07228v1>|利用深度学习和解释性AI技术，提高了孟加拉国等资源受限地区脑肿瘤的自动分类准确性和透明度。|
|📝 更新|Hypergraph Tversky-Aware Domain Incremental Learning for Brain Tumor Segmentation with Missing Modalities|超图Tversky感知的域增量学习在缺失模态下的脑肿瘤分割|Junze Wang, Lei Fan, Weipeng Jing, Donglin Di, Yang Song, Sidong Liu, Cong Cong|<http://arxiv.org/pdf/2505.16809v3>|[代码](https://github.com/reeive/ReHyDIL.); 提出了一种针对缺失模态的脑肿瘤分割方法ReHyDIL，通过域增量学习和超图结构提高了分割准确度。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Group-On: Boosting One-Shot Segmentation with Supportive Query|"Group-On：利用支持性查询提升单次分割性能"|Hanjing Zhou, Mingze Yin, Danny Chen, Jian Wu, JinTai Chen|<http://arxiv.org/pdf/2404.11871v2>|提出了一种名为Group-On的一-shot语义分割方法，通过批量处理查询图像实现相互增强，显著优于...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-Step Visual Reasoning with Visual Tokens Scaling and Verification|多步骤视觉推理：视觉标记缩放与验证|Tianyi Bai, Zengjie Hu, Fupeng Sun, Jiantao Qiu, Yizhen Jiang, Guangxin He, Bohan Zeng, Conghui He .etc.|<http://arxiv.org/pdf/2506.07235v1>|引入动态视觉令牌缩放框架，使多模态大语言模型能进行迭代、验证器指导的视觉内容推理。|
|📝 更新|Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models|空间457：大型多模态模型的6D空间推理诊断基准|Xingrui Wang, Wufei Ma, Tiezheng Zhang, Celso M de Melo, Jieneng Chen, Alan Yuille|<http://arxiv.org/pdf/2502.08636v4>|[代码](https://github.com/XingruiWang/Spatial457.); 提出了Spatial457，一个用于评估大型多模态模型在6D空间推理能力上的无偏倚合成数据集及评估框...|
|📝 更新|VProChart: Answering Chart Question through Visual Perception Alignment Agent and Programmatic Solution Reasoning|VProChart：通过视觉感知对齐代理和程序化解决方案推理回答图表问题|Muye Huang, Lingling Zhang, Lai Han, Wenjun Wu, Xinyu Zhang, Jun Liu|<http://arxiv.org/pdf/2409.01667v2>|提出VProChart框架，结合视觉感知对齐代理和程序化解决方案推理，有效提升图表问题解答能力。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Narrative Review on Large AI Models in Lung Cancer Screening, Diagnosis, and Treatment Planning|大型人工智能模型在肺癌筛查、诊断和治疗计划中的叙事性综述|Jiachen Zhong, Yiting Wang, Di Zhu, Ziwei Wang|<http://arxiv.org/pdf/2506.07236v1>|系统综述了大型AI模型在肺癌筛查、诊断和治疗规划中的应用，推动了个性化医疗优化。|
|🆕 发布|A Comprehensive Analysis of COVID-19 Detection Using Bangladeshi Data and Explainable AI|《基于孟加拉国数据与可解释人工智能的COVID-19检测综合分析》|Shuvashis Sarker|<http://arxiv.org/pdf/2506.07234v1>|利用孟加拉国数据集，本研究通过深度学习模型提高了COVID-19的X光检测准确率并应用解释性AI增强...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Pendulum Tracker -- SimuFísica: A Web-based Tool for Real-time Measurement of Oscillatory Motion|摆锤追踪器 -- SimuFísica：一种基于网络的实时测量摆动运动的工具|Marco P. M. de Souza, Juciane G. Maia, Lilian N. de Andrade|<http://arxiv.org/pdf/2506.07301v1>|开发了Pendulum Tracker工具，利用计算机视觉实现物理摆实时振荡测量，提升实验物理教学效...|
|🆕 发布|EdgeSpotter: Multi-Scale Dense Text Spotting for Industrial Panel Monitoring|边缘探测者：面向工业面板监控的多尺度密集文本检测|Changhong Fu, Hua Lin, Haobo Zuo, Liangliang Yao, Liguo Zhang|<http://arxiv.org/pdf/2506.07112v1>|[代码](https://github.com/vision4robotics/EdgeSpotter.); 提出了一种多尺度密集文本检测方法EdgeSpotter，通过结合多级特征和新型采样技术，提高了工业面...|

