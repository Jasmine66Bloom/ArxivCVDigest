## [UPDATED!] **2025-06-09** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GUI-Reflection: Empowering Multimodal GUI Models with Self-Reflection Behavior|GUI-Reflection：赋予多模态GUI模型自我反思行为的能力|Penghao Wu, Shengnan Ma, Bo Wang, Jiaheng Yu, Lewei Lu, Ziwei Liu|<http://arxiv.org/pdf/2506.08012v1>|提出GUI-Reflection框架，通过自我反思和错误纠正提升多模态GUI模型的鲁棒性和适应性。|
|📝 更新|E3D-Bench: A Benchmark for End-to-End 3D Geometric Foundation Models|E3D-Bench：用于端到端3D几何基础模型的基准测试|Wenyan Cong, Yiqing Liang, Yancheng Zhang, Ziyi Yang, Yan Wang, Boris Ivanovic, Marco Pavone, Chen Chen .etc.|<http://arxiv.org/pdf/2506.01933v2>|提出了首个全面的端到端3D几何基础模型基准，涵盖核心任务并促进公平比较与未来优化。|
|🆕 发布|Decoupling the Image Perception and Multimodal Reasoning for Reasoning Segmentation with Digital Twin Representations|将图像感知与多模态推理解耦：基于数字孪生表示的推理分割|Yizhen Li, Dell Zhang, Xuelong Li, Yiqing Shen|<http://arxiv.org/pdf/2506.07943v1>|提出了一种利用数字孪生表示分离图像感知与多模态推理的分割方法，实现了推理分割任务的最佳性能。|
|📝 更新|Enhancing Few-Shot Vision-Language Classification with Large Multimodal Model Features|利用大规模多模态模型特征增强少量样本视觉语言分类|Chancharik Mitra, Brandon Huang, Tianning Chai, Zhiqiu Lin, Assaf Arbelle, Rogerio Feris, Leonid Karlinsky, Trevor Darrell .etc.|<http://arxiv.org/pdf/2412.00142v3>|提出了一种无需微调的稀疏注意力向量方法，从大型多模态模型中提取特征，实现了少量样本下的视觉语言分类任...|
|🆕 发布|Diffuse Everything: Multimodal Diffusion Models on Arbitrary State Spaces|“扩散一切：在任意状态空间上的多模态扩散模型”|Kevin Rojas, Yuchen Zhu, Sichen Zhu, Felix X. -F. Ye, Molei Tao|<http://arxiv.org/pdf/2506.07903v1>|提出了一种构建在任意状态空间上的多模态扩散模型框架，无需外部预处理即可直接生成跨模态耦合数据。|
|🆕 发布|Flow-Anything: Learning Real-World Optical Flow Estimation from Large-Scale Single-view Images|《Flow-Anything：从大规模单视角图像中学习真实世界光流估计》|Yingping Liang, Ying Fu, Yutao Hu, Wenqi Shao, Jiaming Liu, Debing Zhang|<http://arxiv.org/pdf/2506.07740v1>|提出了一种从大规模单视角图像学习光学流估计的方法，有效解决了现实世界应用中的域差距问题。|
|📝 更新|Weakly Supervised Temporal Action Localization via Dual-Prior Collaborative Learning Guided by Multimodal Large Language Models|通过多模态大型语言模型引导的双先验协同学习实现的弱监督时序动作定位|Quan Zhang, Jinwei Fang, Rui Yuan, Xi Tang, Yuxin Qi, Ke Zhang, Chun Yuan|<http://arxiv.org/pdf/2411.08466v2>|利用大型多模态语言模型指导，提出了一种改进弱监督视频动作定位的新学习范式，有效解决了结果不完整和过度...|
|📝 更新|GarmageNet: A Multimodal Generative Framework for Sewing Pattern Design and Generic Garment Modeling|GarmageNet：一种用于缝纫图案设计和通用服装建模的多模态生成框架|Siran Li, Chen Liu, Ruiyang Liu, Zhendong Wang, Gaofeng He, Yong-Lu Li, Xiaogang Jin, Huamin Wang|<http://arxiv.org/pdf/2504.01483v3>|[代码](https://style3d.github.io/garmagenet.); 提出了GarmageNet框架，自动化地将2D裁片图转化为逼真的3D服装模型，简化了数字服装制作流程...|
|📝 更新|Skywork R1V: Pioneering Multimodal Reasoning with Chain-of-Thought|天工R1V：开创性多模态推理与思维链|Yi Peng, Peiyu Wang, Xiaokun Wang, Yichen Wei, Jiangbo Pei, Weijie Qiu, Ai Jian, Yunzhuo Hao .etc.|<http://arxiv.org/pdf/2504.05599v2>|引入Skywork R1V模型，通过高效的多模态迁移方法将语言模型扩展至视觉领域，并采用混合优化策略...|
|📝 更新|Efficient Long-duration Talking Video Synthesis with Linear Diffusion Transformer under Multimodal Guidance|基于多模态引导的线性扩散变换器实现的长时间对话视频高效合成|Haojie Zhang, Zhihao Liang, Ruibo Fu, Bingyan Liu, Zhengqi Wen, Xuefei Liu, Chenxing Li, Yaling Liang|<http://arxiv.org/pdf/2411.16748v2>|提出了一种高效的线性扩散变换模型，通过多模态融合和记忆银行机制，实现了长时 Talking 视频的连...|
|🆕 发布|OpenDance: Multimodal Controllable 3D Dance Generation Using Large-scale Internet Data|《OpenDance：利用大规模互联网数据生成多模态可控三维舞蹈》|Jinlu Zhang, Zixi Kang, Yizhou Wang|<http://arxiv.org/pdf/2506.07565v1>|提出大规模多模态舞蹈数据集OpenDance5D及生成网络OpenDanceNet，实现基于音乐和文...|
|📝 更新|Towards Achieving Perfect Multimodal Alignment|迈向实现完美的多模态对齐|Abhi Kamboj, Minh N. Do|<http://arxiv.org/pdf/2503.15352v2>|提出了一种实现多模态数据完美对齐的方法，通过SVD近似对齐，显著提升了跨模态任务性能。|
|🆕 发布|Prompt to Protection: A Comparative Study of Multimodal LLMs in Construction Hazard Recognition|“从提示到保护：多模态大型语言模型在建筑隐患识别中的比较研究”|Nishi Chaudhary, S M Jamil Uddin, Sathvik Sharath Chandra, Anto Ovid, Alex Albert|<http://arxiv.org/pdf/2506.07436v1>|研究了不同多模态大语言模型在建筑工地视觉危害识别中的表现，发现提示策略对模型性能有显著影响。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vision Transformers Don't Need Trained Registers|视觉变换器无需训练寄存器|Nick Jiang, Amil Dravid, Alexei Efros, Yossi Gandelsman|<http://arxiv.org/pdf/2506.08010v1>|提出了一种无需重新训练的解决视觉变换器噪声问题的方法，通过转移高范数激活至未训练的额外令牌，改善模型...|
|📝 更新|Peer-Ranked Precision: Creating a Foundational Dataset for Fine-Tuning Vision Models from DataSeeds' Annotated Imagery|同侪排序精度：创建一个用于从数据种子的注释图像微调视觉模型的基础数据集|Sajjad Abdoli, Freeman Lewin, Gediminas Vasiliauskas, Fabian Schonholz|<http://arxiv.org/pdf/2506.05673v2>|构建了一个高质量、多层级注释的图像数据集，推动数据驱动模型性能提升。|
|📝 更新|Fine-grained Hierarchical Crop Type Classification from Integrated Hyperspectral EnMAP Data and Multispectral Sentinel-2 Time Series: A Large-scale Dataset and Dual-stream Transformer Method|细粒度层级作物类型分类：结合EnMAP高光谱数据和Sentinel-2多光谱时间序列的大规模数据集与双流变换器方法|Wenyuan Li, Shunlin Liang, Yuxiang Zhang, Liqin Liu, Keyan Chen, Yongzhe Chen, Han Ma, Jianglei Xu .etc.|<http://arxiv.org/pdf/2506.06155v2>|[代码](https://github.com/flyakon/H2Crop.); 提出了一种融合 hyperspectral 和 multispectral 数据的 dual-str...|
|📝 更新|Feature-Based Lie Group Transformer for Real-World Applications|基于特征的Lie群变换器用于现实世界应用|Takayuki Komatsu, Yoshiyuki Ohmura, Kayato Nishitsunoi, Yasuo Kuniyoshi|<http://arxiv.org/pdf/2506.04668v3>|提出了一种结合特征提取和对象分割的群分解理论方法，以适应现实世界场景并改善对象识别。|
|📝 更新|ComPtr: Towards Diverse Bi-source Dense Prediction Tasks via A Simple yet General Complementary Transformer|ComPtr: 通过一种简单而通用的互补变换器实现多样化的双源密集预测任务|Youwei Pang, Xiaoqi Zhao, Lihe Zhang, Huchuan Lu|<http://arxiv.org/pdf/2307.12349v2>|[代码](https://github.com/lartpang/ComPtr.); 提出了一种通用互补Transformer模型ComPtr，用于处理多种双源密集预测任务，提高了视觉任...|
|🆕 发布|Event-Priori-Based Vision-Language Model for Efficient Visual Understanding|基于事件先验的视觉语言模型用于高效视觉理解|Haotong Qin, Cheng Hu, Michele Magno|<http://arxiv.org/pdf/2506.07627v1>|提出一种基于动态事件视觉先验的视觉语言模型，通过精简计算显著提升了效率并保持了高准确度。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SpaCE-10: A Comprehensive Benchmark for Multimodal Large Language Models in Compositional Spatial Intelligence|空间智能组合性多模态大型语言模型的全面基准：SpaCE-10|Ziyang Gong, Wenhao Li, Oliver Ma, Songyuan Li, Jiayi Ji, Xue Yang, Gen Luo, Junchi Yan .etc.|<http://arxiv.org/pdf/2506.07966v1>|[代码](https://github.com/Cuzyoung/SpaCE-10.); 提出了SpaCE-10基准，全面评估多模态大语言模型在空间组合智能方面的能力。|
|📝 更新|DINeMo: Learning Neural Mesh Models with no 3D Annotations|DINeMo：无需三维标注的学习神经网格模型|Weijie Guo, Guofeng Zhang, Wufei Ma, Alan Yuille|<http://arxiv.org/pdf/2503.20220v2>|[代码](https://analysis-by-synthesis.github.io/DINeMo); 提出DINeMo模型，无需3D标注，通过视觉基础模型学习伪对应，实现高效3D姿态估计。|
|🆕 发布|EgoM2P: Egocentric Multimodal Multitask Pretraining|自我中心多模态多任务预训练：EgoM2P|Gen Li, Yutong Chen, Yiqian Wu, Kaifeng Zhao, Marc Pollefeys, Siyu Tang|<http://arxiv.org/pdf/2506.07886v1>|提出了EgoM2P框架，通过高效时间编码和多模态掩码建模，实现了快速且全面的 egocentric ...|
|🆕 发布|NOVA3D: Normal Aligned Video Diffusion Model for Single Image to 3D Generation|NOVA3D：基于法线对齐的视频扩散模型实现单张图像到三维模型的生成|Yuxiao Yang, Peihao Li, Yuhong Zhang, Junzhe Lu, Xianglong He, Minghan Qin, Weitao Wang, Haoqian Wang|<http://arxiv.org/pdf/2506.07698v1>|提出NOVA3D框架，利用视频扩散模型中的3D先验和几何信息对单张图像进行高效3D重建。|
|📝 更新|Unsolvable Problem Detection: Robust Understanding Evaluation for Large Multimodal Models|不可解问题检测：大型多模态模型的鲁棒理解评估|Atsuyuki Miyai, Jingkang Yang, Jingyang Zhang, Yifei Ming, Qing Yu, Go Irie, Yixuan Li, Hai Li .etc.|<http://arxiv.org/pdf/2403.20331v4>|[代码](https://github.com/AtsuMiyai/UPD.); 提出了一种评估大型多模态模型理解能力的任务，即不可解决问题检测，揭示了现有基准忽视的可靠性新方面。|
|📝 更新|Skywork-VL Reward: An Effective Reward Model for Multimodal Understanding and Reasoning|天空工作-VL奖励：一种用于多模态理解和推理的有效奖励模型|Xiaokun Wang, Peiyu Wang, Jiangbo Pei, Wei Shen, Yi Peng, Yunzhuo Hao, Weijie Qiu, Ai Jian .etc.|<http://arxiv.org/pdf/2505.07263v2>|提出了一种多模态奖励模型Skywork-VL Reward，通过大规模数据集和特定架构提升多模态理解...|
|📝 更新|Human-in-the-Loop Annotation for Image-Based Engagement Estimation: Assessing the Impact of Model Reliability on Annotation Accuracy|《基于图像的参与度估计中的人机循环标注：评估模型可靠性对标注准确性的影响》|Sahana Yadnakudige Subramanya, Ko Watanabe, Andreas Dengel, Shoya Ishimaru|<http://arxiv.org/pdf/2502.07404v2>|探究了模型可靠性和心理框架对人类-机器协作的影响，优化了情感标注的循环交互框架。|
|🆕 发布|DINO-CoDT: Multi-class Collaborative Detection and Tracking with Vision Foundation Models|DINO-CoDT：基于视觉基础模型的多类协同检测与跟踪|Xunjie He, Christina Dao Wen Lee, Meiling Wang, Chengran Yuan, Zefan Huang, Yufeng Yue, Marcelo H. Ang Jr|<http://arxiv.org/pdf/2506.07375v1>|提出多类协同检测与跟踪框架，通过全局空间注意力融合和视觉基础模型，提升复杂场景下的感知能力。|
|📝 更新|Scalable Vision Language Model Training via High Quality Data Curation|通过高质量数据筛选的可扩展视觉语言模型训练|Hongyuan Dong, Zijian Kang, Weijie Yin, Xiao Liang, Chao Feng, Jiao Ran|<http://arxiv.org/pdf/2501.05952v3>|通过高质量数据筛选，实现了大规模视觉语言模型的训练，达到领先性能。|
|📝 更新|From Pixels to Predicates: Learning Symbolic World Models via Pretrained Vision-Language Models|从像素到谓词：通过预训练的视觉语言模型学习符号世界模型|Ashay Athalye, Nishanth Kumar, Tom Silver, Yichao Liang, Tomás Lozano-Pérez, Leslie Pack Kaelbling|<http://arxiv.org/pdf/2501.00296v2>|利用预训练视觉语言模型学习符号世界模型，实现零样本泛化解决复杂决策问题。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References|UA-Pose：不确定性感知的6D物体姿态估计与基于部分参考的在线物体补全|Ming-Feng Li, Xin Yang, Fu-En Wang, Hritam Basak, Yuyin Sun, Shreekant Gayaka, Min Sun, Cheng-Hao Kuo|<http://arxiv.org/pdf/2506.07996v1>|[代码](https://minfenli.github.io/UA-Pose); 提出UA-Pose方法，通过部分参考实现6D物体姿态估计和在线物体补全，提升估计准确性和物体完整性。|
|📝 更新|ShapeMoiré: Channel-Wise Shape-Guided Network for Image Demoiréing|《ShapeMoiré：基于形状引导的逐通道图像去摩尔纹网络》|Jinming Cao, Sicheng Shen, Qiu Zhou, Yifang Yin, Yangyan Li, Roger Zimmermann|<http://arxiv.org/pdf/2404.18155v2>|提出ShapeMoiré方法，利用Shape信息有效捕获并消除图像中的摩尔纹。|
|📝 更新|RSNet: A Light Framework for The Detection of SAR Ship Detection|RSNet：一种用于合成孔径雷达船舶检测的轻量级框架|Hongyu Chen, Chengcheng Chen, Fei Wang, Yuhu Shi, Weiming Zeng|<http://arxiv.org/pdf/2410.23073v7>|RSNet通过Waveletpool-ContextGuided和Waveletpool-StarF...|
|🆕 发布|Hierarchical Scoring with 3D Gaussian Splatting for Instance Image-Goal Navigation|基于三维高斯散点绘制进行实例图像目标导航的层次化评分方法|Yijie Deng, Shuaihang Yuan, Geeta Chandra Raju Bethala, Anthony Tzes, Yu-Shen Liu, Yi Fang|<http://arxiv.org/pdf/2506.07338v1>|引入分层评分机制以优化视角选择，提升实例图像目标导航的准确性和效率。|
|🆕 发布|CBAM-STN-TPS-YOLO: Enhancing Agricultural Object Detection through Spatially Adaptive Attention Mechanisms|CBAM-STN-TPS-YOLO：通过空间自适应注意力机制增强农业目标检测|Satvik Praveen, Yoonsung Jung|<http://arxiv.org/pdf/2506.07357v1>|提出CBAM-STN-TPS-YOLO模型，通过灵活的非刚性空间变换和注意力机制提升农业对象检测准确...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection|SimLTD：简单监督与半监督长尾目标检测|Phi Vu Tran|<http://arxiv.org/pdf/2412.20047v3>|提出了一种利用未标注图像的简单监督与半监督长尾目标检测方法SimLTD，实现了在长尾分布数据上的性能...|
|🆕 发布|LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds|LogoSP：用于三维点云无监督语义分割的超点局部-全局分组|Zihui Zhang, Weisheng Dai, Hongtao Wen, Bo Yang|<http://arxiv.org/pdf/2506.07857v1>|提出LogoSP方法，通过结合局部和全局点特征进行三维点云的无监督语义分割，实现领先性能。|
|🆕 发布|HieraEdgeNet: A Multi-Scale Edge-Enhanced Framework for Automated Pollen Recognition|《HieraEdgeNet：一种多尺度边缘增强框架用于自动化花粉识别》|Yuchong Long, Wen Sun, Ningxiao Sun, Wenxiao Wang, Chao Li, Shan Yin|<http://arxiv.org/pdf/2506.07637v1>|提出了一种多尺度边缘增强框架HieraEdgeNet，通过整合边缘信息显著提升了微小目标如花粉的检测...|
|🆕 发布|Domain Randomization for Object Detection in Manufacturing Applications using Synthetic Data: A Comprehensive Study|制造应用中利用合成数据进行目标检测的领域随机化：一项全面研究|Xiaomeng Zhu, Jacob Henningsson, Duruo Li, Pär Mårtensson, Lars Hanson, Mårten Björkman, Atsuto Maki|<http://arxiv.org/pdf/2506.07539v1>|提出了一种生成合成数据并进行域随机化的方法，有效提升了制造业对象检测的准确性。|
|📝 更新|Detect Anything 3D in the Wild|在野外检测任何三维物体|Hanxue Zhang, Haoran Jiang, Qingsong Yao, Yanan Sun, Renrui Zhang, Hao Zhao, Hongyang Li, Hongzi Zhu .etc.|<http://arxiv.org/pdf/2504.07958v2>|提出DetAny3D模型，利用预训练2D模型知识，实现任意相机配置下3D物体的零样本检测。|
|📝 更新|Frequency-Adaptive Dilated Convolution for Semantic Segmentation|频率自适应膨胀卷积用于语义分割|Linwei Chen, Lin Gu, Ying Fu|<http://arxiv.org/pdf/2403.05369v7>|[代码](https://github.com/Linwei-Chen/FADC.); 提出动态调整膨胀率的频率自适应膨胀卷积方法，有效提升语义分割的准确性和范围。|
|🆕 发布|Multiple Object Stitching for Unsupervised Representation Learning|多目标拼接用于无监督表征学习|Chengchao Shen, Dawei Liu, Jianxin Wang|<http://arxiv.org/pdf/2506.07364v1>|[代码](https://github.com/visresearch/MultipleObjectStitching.); 提出了一种通过多对象拼接增强无监督表征学习的方法，有效提升了多对象图像的表征性能。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OG-HFYOLO :Orientation gradient guidance and heterogeneous feature fusion for deformation table cell instance segmentation|OG-HFYOLO：基于方向梯度引导和异质特征融合的变形表格单元格实例分割|Long Liu, Cihui Yang|<http://arxiv.org/pdf/2504.20682v3>|[代码](https://github.com/justliulong/OGHFYOLO.); 提出OG-HFYOLO模型，通过梯度方向引导和异质特征融合，有效应对表格结构识别中的几何变形问题。|
|📝 更新|TissUnet: Improved Extracranial Tissue and Cranium Segmentation for Children through Adulthood|TissUnet：通过成年期改进的儿童颅外组织与颅骨分割方法|Markiian Mandzak, Elvira Yang, Anna Zapaishchykova, Yu-Hui Chen, Lucas Heilbroner, John Zielke, Divyanshu Tak, Reza Mojahed-Yazdi .etc.|<http://arxiv.org/pdf/2506.05660v2>|提出TissUnet模型，通过深度学习实现儿童至成年人群颅外组织和颅骨的快速准确分割。|
|🆕 发布|OpenSplat3D: Open-Vocabulary 3D Instance Segmentation using Gaussian Splatting|OpenSplat3D：基于高斯散点法的开放词汇三维实例分割|Jens Piekenbrinck, Christian Schmidt, Alexander Hermans, Narunas Vaskevicius, Timm Linder, Bastian Leibe|<http://arxiv.org/pdf/2506.07697v1>|提出了一种无需手动标注的开词汇3D实例分割方法OpenSplat3D，通过结合高斯散点技术和自然语言...|
|🆕 发布|FAMSeg: Fetal Femur and Cranial Ultrasound Segmentation Using Feature-Aware Attention and Mamba Enhancement|胎儿股骨与颅骨超声分割中使用特征感知注意力和Mamba增强的FAMSeg|Jie He, Minglang Chen, Minying Lu, Bocheng Liang, Junming Wei, Guiyan Peng, Jiaxi Chen, Ying Tan|<http://arxiv.org/pdf/2506.07431v1>|提出了一种结合特征感知注意力和Mamba增强的超声图像分割模型，有效应对高噪声和相似度高的超声图像分...|
|🆕 发布|Adapter Naturally Serves as Decoupler for Cross-Domain Few-Shot Semantic Segmentation|适配器自然地作为解耦器服务于跨域少样本语义分割|Jintao Tong, Ran Ma, Yixiong Zou, Guangyao Chen, Yuhua Li, Ruixuan Li|<http://arxiv.org/pdf/2506.07376v1>|提出结构化的域特征导航器（DFN）作为解耦器，有效提升跨域少量样本语义分割性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|StableMTL: Repurposing Latent Diffusion Models for Multi-Task Learning from Partially Annotated Synthetic Datasets|稳定多任务学习：将潜在扩散模型重用于从部分注释合成数据集进行多任务学习|Anh-Quan Cao, Ivan Lopes, Raoul de Charette|<http://arxiv.org/pdf/2506.08013v1>|提出了一种利用生成模型进行多任务学习的方法，通过在合成数据集上零样本学习，实现了跨任务的高效共享和性...|
|🆕 发布|Dynamic View Synthesis as an Inverse Problem|动态视图合成作为逆问题|Hidir Yesiltepe, Pinar Yanardag|<http://arxiv.org/pdf/2506.08004v1>|将单目视频动态视角合成视为无训练逆问题，通过改进预训练模型噪声初始化实现高保真合成。|
|📝 更新|VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary|《VLog：通过生成性检索解说词汇的视频-语言模型》|Kevin Qinghong Lin, Mike Zheng Shou|<http://arxiv.org/pdf/2503.09402v2>|[代码](https://github.com/showlab/VLog.); 提出VLog框架，通过生成性检索和层次化词汇表实现视频流中日常活动的高效、准确叙述。|
|🆕 发布|GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution|高斯VAE：自适应学习三维高斯分布的动力特性以实现高保真超分辨率|Shuja Khalid, Mohamed Ibrahim, Yang Liu|<http://arxiv.org/pdf/2506.07897v1>|提出了一种高效预测和细化3D高斯分布的方法，实现了超分辨率三维场景重建的实时计算和高质量输出。|
|🆕 发布|Diffusion models under low-noise regime|低噪声条件下的扩散模型|Elizabeth Pavlova, Xue-Xin Wei|<http://arxiv.org/pdf/2506.07841v1>|探究了低噪声环境下扩散模型的行为，揭示了训练数据大小和模型目标对去噪轨迹的影响。|
|🆕 发布|Self-Cascaded Diffusion Models for Arbitrary-Scale Image Super-Resolution|用于任意尺度图像超分辨率的自级联扩散模型|Junseo Bang, Joonhee Lee, Kyeonghyun Lee, Haechang Lee, Dong Un Kang, Se Young Chun|<http://arxiv.org/pdf/2506.07813v1>|提出CasArbi框架，通过逐步分解和增强实现任意尺度图像超分辨率的无缝处理。|
|📝 更新|Benchmark Granularity and Model Robustness for Image-Text Retrieval|图像文本检索中的基准粒度与模型鲁棒性评估|Mariya Hendriksen, Shuo Zhang, Ridho Reinanda, Mohamed Yahya, Edgar Meij, Maarten de Rijke|<http://arxiv.org/pdf/2407.15239v4>|研究了图像文本检索中数据集粒度和查询扰动对模型性能的影响，提出细粒度标注和扰动分析的新方法。|
|📝 更新|Learning Efficient and Effective Trajectories for Differential Equation-based Image Restoration|学习用于微分方程基础图像恢复的高效有效轨迹|Zhiyu Zhu, Jinhui Hou, Hui Liu, Huanqiang Zeng, Junhui Hou|<http://arxiv.org/pdf/2410.04811v2>|[代码](https://zhu-zhiyu.github.io/FLUX-IR); 提出了一种优化的微分方程轨迹学习框架，通过强化学习和成本感知轨迹蒸馏提升了图像恢复的质量和效率。|
|🆕 发布|Adaptive Blind Super-Resolution Network for Spatial-Specific and Spatial-Agnostic Degradations|自适应盲超分辨率网络：针对空间特定与空间无关退化|Weilei Wen, Chunle Guo, Wenqi Ren, Hongpeng Wang, Xiuli Shao|<http://arxiv.org/pdf/2506.07705v1>|提出了一种区分空间无关和空间相关退化类型的自适应盲超分辨率网络，有效提升了图像重建性能。|
|🆕 发布|ProSplat: Improved Feed-Forward 3D Gaussian Splatting for Wide-Baseline Sparse Views|“ProSplat：改进的宽基线稀疏视角前馈三维高斯绘制方法”|Xiaohan Lu, Jiaye Fu, Jiaqi Zhang, Zetian Song, Chuanmin Jia, Siwei Ma|<http://arxiv.org/pdf/2506.07670v1>|提出ProSplat方法，通过两阶段框架提升宽基线条件下的3D渲染质量。|
|🆕 发布|Explore the vulnerability of black-box models via diffusion models|探究通过扩散模型揭示黑盒模型的脆弱性|Jiacheng Shi, Yanfu Zhang, Huajie Shao, Ashley Gao|<http://arxiv.org/pdf/2506.07590v1>|揭示了利用扩散模型API生成合成图像来训练替代模型，实现对黑盒分类模型高效攻击的新方法。|
|📝 更新|CityGo: Lightweight Urban Modeling and Rendering with Proxy Buildings and Residual Gaussians|城市漫步：基于代理建筑和残差高斯函数的轻量级城市建模与渲染|Weihang Liu, Yuhui Zhong, Yuke Li, Xi Chen, Jiadi Cui, Honglong Zhang, Lan Xu, Xin Lou .etc.|<http://arxiv.org/pdf/2505.21041v3>|提出了一种结合代理建筑和残差高斯分布的混合框架，实现了城市场景的轻量级建模和实时渲染。|
|🆕 发布|CoCoA-Mix: Confusion-and-Confidence-Aware Mixture Model for Context Optimization|CoCoA-Mix：面向上下文优化的混淆与置信度感知混合模型|Dasol Hong, Wooju Lee, Hyun Myung|<http://arxiv.org/pdf/2506.07484v1>|[代码](https://github.com/url-kaist/CoCoA-Mix.); 提出了一种改进视觉语言模型专化和泛化能力的混合模型CoCoA-Mix，通过细化决策边界和调整预测权重...|
|🆕 发布|SpatialLM: Training Large Language Models for Structured Indoor Modeling|空间语言模型：为结构化室内建模训练大型语言模型|Yongsen Mao, Junhao Zhong, Chuan Fang, Jia Zheng, Rui Tang, Hao Zhu, Ping Tan, Zihan Zhou|<http://arxiv.org/pdf/2506.07491v1>|提出了一种大型语言模型SpatialLM，可直接处理3D点云数据并生成结构化的室内场景理解输出，实现...|
|🆕 发布|Drive Any Mesh: 4D Latent Diffusion for Mesh Deformation from Video|驱动任意网格：基于视频的4D潜在扩散网格变形方法|Yahao Shi, Yang Liu, Yanmin Wu, Xing Liu, Chen Zhao, Jie Luo, Bin Zhou|<http://arxiv.org/pdf/2506.07489v1>|提出了一种4D扩散模型，通过视频驱动网格变形，提高了动画质量和渲染效率。|
|📝 更新|Astraea: A GPU-Oriented Token-wise Acceleration Framework for Video Diffusion Transformers|阿斯特赖亚：一种面向GPU的逐标记加速框架，用于视频扩散变换器|Haosong Liu, Yuge Cheng, Zihan Liu, Aiyue Chen, Jing Lin, Yiwu Yao, Chen Chen, Jingwen Leng .etc.|<http://arxiv.org/pdf/2506.05096v3>|ASTRAEA通过自动搜索最优配置，提出轻量级token选择和GPU并行稀疏注意力策略，大幅提升视频...|
|📝 更新|Gungnir: Exploiting Stylistic Features in Images for Backdoor Attacks on Diffusion Models|冈尼尔：利用图像风格特征对扩散模型进行后门攻击|Yu Pan, Jiahao Chen, Bingrong Dai, Lin Wang, Yi Du, Jiao Liu|<http://arxiv.org/pdf/2502.20650v3>|[代码](https://github.com/paoche11/Gungnir.); 提出利用图像风格特征作为触发器进行扩散模型的后门攻击新方法，实现了零检测率的攻击效果。|
|🆕 发布|Generative Models at the Frontier of Compression: A Survey on Generative Face Video Coding|生成模型在压缩前沿：关于生成人脸视频编码的综述|Bolin Chen, Shanzhi Yin, Goluck Konuko, Giuseppe Valenzise, Zihan Zhang, Shiqi Wang, Yan Ye|<http://arxiv.org/pdf/2506.07369v1>|这篇论文首次全面梳理了生成式人脸视频编码技术，实现了在极低码率下高质量人脸视频通信。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Self Forcing: Bridging the Train-Test Gap in Autoregressive Video Diffusion|自强化：缩小自回归视频扩散训练-测试差距|Xun Huang, Zhengqi Li, Guande He, Mingyuan Zhou, Eli Shechtman|<http://arxiv.org/pdf/2506.08009v1>|引入Self Forcing训练范式，通过在训练中利用自身输出改善视频生成质量，解决传统方法中的训练...|
|🆕 发布|MADFormer: Mixed Autoregressive and Diffusion Transformers for Continuous Image Generation|混合自回归与扩散变换器用于连续图像生成：MADFormer|Junhao Chen, Yulia Tsvetkov, Xiaochuang Han|<http://arxiv.org/pdf/2506.07999v1>|提出混合自回归与扩散变换器的MADFormer，优化了高分辨率图像生成的质量与效率平衡。|
|🆕 发布|Audio-Sync Video Generation with Multi-Stream Temporal Control|具有多流时间控制的音频同步视频生成|Shuchen Weng, Haojie Zheng, Zheng Chang, Si Li, Boxin Shi, Xinlong Wang|<http://arxiv.org/pdf/2506.08003v1>|提出MTV框架，通过分离音频类型实现精细且语义对齐的音视频同步生成。|
|🆕 发布|Generative Modeling of Weights: Generalization or Memorization?|生成模型权重：泛化还是记忆？|Boya Zeng, Yida Yin, Zhiqiu Xu, Zhuang Liu|<http://arxiv.org/pdf/2506.07998v1>|[代码](https://github.com/boyazeng/weight_memorization.); 发现生成模型在生成新神经网络权重时主要进行记忆而非泛化，挑战了现有方法的有效性。|
|🆕 发布|SlideCoder: Layout-aware RAG-enhanced Hierarchical Slide Generation from Design|《SlideCoder：基于布局感知的RAG增强型层次化幻灯片生成方法》|Wenxin Tang, Jingyu Xiao, Wenxuan Jiang, Xi Xiao, Yuhang Wang, Xuxin Tang, Qing Li, Yuehe Ma .etc.|<http://arxiv.org/pdf/2506.07964v1>|[代码](https://github.com/vinsontang1/SlideCoder.); 提出SlideCoder框架，通过结合布局感知和检索增强技术，从参考图像生成高质量可编辑幻灯片。|
|🆕 发布|Reinforcing Multimodal Understanding and Generation with Dual Self-rewards|用双向自我奖励强化多模态理解和生成|Jixiang Hong, Yiran Zhang, Guanzhong Wang, Yi Liu, Ji-Rong Wen, Rui Yan|<http://arxiv.org/pdf/2506.07963v1>|引入自我监督的双奖励机制，有效提升大型多模态模型在无需外部监督下的理解和生成能力。|
|🆕 发布|Squeeze3D: Your 3D Generation Model is Secretly an Extreme Neural Compressor|"Squeeze3D: 你的3D生成模型实际上是一个极端的神经压缩器"|Rishit Dagli, Yushi Guan, Sankeerth Durvasula, Mohammadreza Mofayezi, Nandita Vijaykumar|<http://arxiv.org/pdf/2506.07932v1>|提出Squeeze3D框架，利用预训练模型压缩3D数据，实现高压缩比且保持视觉质量。|
|📝 更新|Hummingbird: High Fidelity Image Generation via Multimodal Context Alignment|蜂鸟：通过多模态上下文对齐实现高保真图像生成|Minh-Quan Le, Gaurav Mittal, Tianjian Meng, A S M Iftekhar, Vishwas Suryanarayanan, Barun Patra, Dimitris Samaras, Mei Chen|<http://arxiv.org/pdf/2502.05153v2>|[代码](https://roar-ai.github.io/hummingbird); 提出了一种新型扩散模型Hummingbird，通过多模态上下文对齐生成既多样化又保持场景属性的高保真...|
|🆕 发布|Diffusion Counterfactual Generation with Semantic Abduction|扩散反事实生成与语义推理|Rajat Rasal, Avinash Kori, Fabio De Sousa Ribeiro, Tian Xia, Ben Glocker|<http://arxiv.org/pdf/2506.07883v1>|提出了一种融合语义表示的扩散模型框架，实现了在保证身份一致性的同时进行因果编辑的图像生成。|
|🆕 发布|SAM2Auto: Auto Annotation Using FLASH|SAM2Auto：使用FLASH的自动标注|Arash Rocky, Q. M. Jonathan Wu|<http://arxiv.org/pdf/2506.07850v1>|提出自动标注工具SAM2Auto，通过SMART-OD和FLASH技术实现无需人工干预的视频数据集标...|
|🆕 发布|VIVAT: Virtuous Improving VAE Training through Artifact Mitigation|VIVAT：通过消除伪迹来优化变分自编码器训练|Lev Novitskiy, Viacheslav Vasilev, Maria Kovaleva, Vladimir Arkhipkin, Denis Dimitrov|<http://arxiv.org/pdf/2506.07863v1>|提出了一种有效减少VAE训练中常见 artifacts的方法，通过调整损失权重和引入条件归一化显著提...|
|🆕 发布|PolyVivid: Vivid Multi-Subject Video Generation with Cross-Modal Interaction and Enhancement|PolyVivid：基于跨模态交互与增强的生动多主体视频生成|Teng Hu, Zhentao Yu, Zhengguang Zhou, Jiangning Zhang, Yuan Zhou, Qinglin Lu, Ran Yi|<http://arxiv.org/pdf/2506.07848v1>|PolyVivid通过跨模态交互与增强，实现了身份一致的多主体视频灵活生成。|
|📝 更新|PID: Physics-Informed Diffusion Model for Infrared Image Generation|基于物理信息的扩散模型用于红外图像生成|Fangyuan Mao, Jilin Mei, Shun Lu, Fuyang Liu, Liang Chen, Fangzhou Zhao, Yu Hu|<http://arxiv.org/pdf/2407.09299v2>|[代码](https://github.com/fangyuanmao/PID.); 提出Physics-Informed Diffusion模型，利用物理规律约束生成更真实的红外图像转...|
|🆕 发布|Design and Evaluation of Deep Learning-Based Dual-Spectrum Image Fusion Methods|深度学习基于的双谱图像融合方法设计与评估|Beining Xu, Junxian Li|<http://arxiv.org/pdf/2506.07779v1>|构建了校园环境下的双谱数据集，并提出了融合速度与下游任务性能并重的综合评价框架。|
|📝 更新|Detecting Out-of-Distribution Objects through Class-Conditioned Inpainting|通过类别条件修复检测分布外对象|Quang-Huy Nguyen, Jin Peng Zhou, Zhenzhen Liu, Khanh-Huyen Bui, Kilian Q. Weinberger, Wei-Lun Chao, Dung D. Le|<http://arxiv.org/pdf/2402.03292v3>|提出利用文本到图像生成模型通过比较原图与去除检测物体的修复图，有效识别分布外物体。|
|🆕 发布|Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation|差异反转：利用标记一致性对图像类比生成进行差异插值与隔离|Hyunsoo Kim, Donghyun Kim, Suhyun Kim|<http://arxiv.org/pdf/2506.07750v1>|提出Difference Inversion方法，通过隔离并应用差异生成图像类比，实现模型无关的图像...|
|📝 更新|Geometrical Properties of Text Token Embeddings for Strong Semantic Binding in Text-to-Image Generation|文本标记嵌入的几何属性在文本到图像生成中的强语义绑定作用|Hoigi Seo, Junseo Bang, Haechang Lee, Joohoon Lee, Byung Hyun Lee, Se Young Chun|<http://arxiv.org/pdf/2503.23011v2>|探究文本嵌入向量的几何属性，提出无训练文本感知框架TokeBi，增强文本到图像生成中的语义绑定效果。|
|🆕 发布|Consistent Video Editing as Flow-Driven Image-to-Video Generation|基于流动驱动的图像到视频生成的一致性视频编辑|Ge Wang, Songlin Fan, Hangxu Liu, Quanjian Song, Hewei Wang, Jinfeng Xu|<http://arxiv.org/pdf/2506.07713v1>|提出了一种基于光流引导的图像到视频生成方法FlowV2V，有效解决了视频编辑中的运动转移和形状变形问...|
|📝 更新|EmoVOCA: Speech-Driven Emotional 3D Talking Heads|情感驱动的语音驱动3D说话人头EmoVOCA|Federico Nocentini, Claudio Ferrari, Stefano Berretti|<http://arxiv.org/pdf/2403.12886v3>|提出了一种创新的语音驱动的情感3D聊天头生成技术，通过合成数据集解决了语音与表情动态结合的难题。|
|🆕 发布|PIG: Physically-based Multi-Material Interaction with 3D Gaussians|PIG：基于物理的多材料交互与三维高斯函数|Zeyu Xiao, Zhenyi Wu, Mingyang Sun, Qipeng Yan, Yufan Guo, Zhuoer Liang, Lihua Zhang|<http://arxiv.org/pdf/2506.07657v1>|提出了一种结合3D对象分割与高精度交互模拟的方法，实现了多材料间的物理交互和视觉一致性。|
|📝 更新|RainFusion: Adaptive Video Generation Acceleration via Multi-Dimensional Visual Redundancy|雨融合：通过多维视觉冗余实现自适应视频生成加速|Aiyue Chen, Bin Dong, Jingru Li, Jing Lin, Kun Tian, Yiwu Yao, Gongyi Wang|<http://arxiv.org/pdf/2505.21036v2>|提出了一种无需训练的 RainFusion 方法，通过利用视觉数据中的稀疏性加速视频生成中的注意力计...|
|📝 更新|RAID: A Dataset for Testing the Adversarial Robustness of AI-Generated Image Detectors|RAID：用于测试AI生成图像检测器对抗鲁棒性的数据集|Hicham Eddoubi, Jonas Ricker, Federico Cocchi, Lorenzo Baraldi, Angelo Sotgiu, Maura Pintor, Marcella Cornia, Lorenzo Baraldi .etc.|<http://arxiv.org/pdf/2506.03988v3>|[代码](https://github.com/pralab/RAID.); 提出RAID数据集，通过高转移性对抗示例评估AI生成图像检测器的鲁棒性。|
|🆕 发布|Scaling Human Activity Recognition: A Comparative Evaluation of Synthetic Data Generation and Augmentation Techniques|《扩展人体行为识别：合成数据生成与增强技术比较评估》|Zikang Leng, Archith Iyer, Thomas Plötz|<http://arxiv.org/pdf/2506.07612v1>|对比了两种虚拟IMU数据生成方法与传统数据增强技术，显著提升了有限数据下的人体活动识别性能。|
|🆕 发布|DragNeXt: Rethinking Drag-Based Image Editing|DragNeXt：重新思考基于拖拽的图像编辑|Yuan Zhou, Junbao Zhou, Qingshan Xu, Kesen Zhao, Yuxuan Wang, Hao Fei, Richang Hong, Hanwang Zhang|<http://arxiv.org/pdf/2506.07611v1>|DragNeXt通过将图像编辑重新定义为对用户指定区域的变形、旋转和位移，有效解决了传统拖拽编辑的模...|
|🆕 发布|LLM-driven Indoor Scene Layout Generation via Scaled Human-aligned Data Synthesis and Multi-Stage Preference Optimization|通过规模化的基于人类的对齐数据合成和多阶段偏好优化实现的LLM驱动的室内场景布局生成|Yixuan Yang, Zhen Luo, Tongsheng Ding, Junru Lu, Mingqi Gao, Jinyu Yang, Victor Sanchez, Feng Zheng|<http://arxiv.org/pdf/2506.07570v1>|提出了一种结合大规模合成数据与多阶段优化的室内布局生成方法，提升了布局质量和多样性。|
|🆕 发布|Synthesize Privacy-Preserving High-Resolution Images via Private Textual Intermediaries|通过私人文本中介合成保护隐私的高分辨率图像|Haoxiang Wang, Zinan Lin, Da Yu, Huishuai Zhang|<http://arxiv.org/pdf/2506.07555v1>|提出了一种利用隐私文本中介生成高分辨率差分隐私合成图像的新方法，大幅提升了图像质量。|
|🆕 发布|PhysiInter: Integrating Physical Mapping for High-Fidelity Human Interaction Generation|PhysiInter：集成物理映射以生成高保真人类交互|Wei Yao, Yunlian Sun, Chang Liu, Hongwen Zhang, Jinhui Tang|<http://arxiv.org/pdf/2506.07456v1>|[代码](http://yw0208.github.io/physiinter); 引入物理映射技术，提高了多人互动场景中生成人体运动的物理真实性和质量。|
|🆕 发布|GLOS: Sign Language Generation with Temporally Aligned Gloss-Level Conditioning|《GLOS：基于时序对齐的注释级别条件生成手语》|Taeryung Lee, Hyeongjin Nam, Gyeongsik Moon, Kyoung Mu Lee|<http://arxiv.org/pdf/2506.07460v1>|提出了一种基于词级别语义和时序结构对齐的生成手语框架，有效解决了现有方法中词汇顺序错误和语义精度低的...|
|📝 更新|Generative Photomontage|生成性照片拼贴|Sean J. Liu, Nupur Kumari, Ariel Shamir, Jun-Yan Zhu|<http://arxiv.org/pdf/2408.07116v3>|提出了一种生成图像组合框架，通过用户选择生成图像的局部区域并进行优化融合，实现了更符合用户需求的图像...|
|📝 更新|Reward-Instruct: A Reward-Centric Approach to Fast Photo-Realistic Image Generation|奖励指导：一种以奖励为中心的快速生成逼真图像的方法|Yihong Luo, Tianyang Hu, Weijian Luo, Kenji Kawaguchi, Jing Tang|<http://arxiv.org/pdf/2503.13070v2>|提出了一种基于奖励反馈的简单高效图像生成方法Reward-Instruct，无需依赖复杂的扩散蒸馏损...|
|🆕 发布|MapBERT: Bitwise Masked Modeling for Real-Time Semantic Mapping Generation|MapBERT：位运算掩码建模用于实时语义地图生成|Yijie Deng, Shuaihang Yuan, Congcong Wen, Hao Huang, Anthony Tzes, Geeta Chandra Raju Bethala, Yi Fang|<http://arxiv.org/pdf/2506.07350v1>|提出MapBERT框架，通过比特位编码和掩码Transformer生成实时语义地图，有效处理室内环境...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dreamland: Controllable World Creation with Simulator and Generative Models|梦境之地：利用模拟器和生成模型进行可控世界创造|Sicheng Mo, Ziyang Leng, Leon Liu, Weizhen Wang, Honglin He, Bolei Zhou|<http://arxiv.org/pdf/2506.08006v1>|提出Dreamland框架，结合物理模拟器和大型生成模型，实现动态世界创建中的细粒度控制与高质量图像...|
|🆕 发布|PairEdit: Learning Semantic Variations for Exemplar-based Image Editing|对示例基于图像编辑学习语义变化：PairEdit方法|Haoguang Lu, Jiacheng Chen, Zhenguo Yang, Aurele Tohokantche Gnanha, Fu Lee Wang, Li Qing, Xudong Mao|<http://arxiv.org/pdf/2506.07992v1>|[代码](https://github.com/xudonmao/PairEdit.); 提出了一种无需文本指导，仅通过图像对学习复杂编辑语义的视觉编辑方法PairEdit，大幅提升了内容一...|
|🆕 发布|Rethinking Cross-Modal Interaction in Multimodal Diffusion Transformers|重新思考多模态扩散变换器中的跨模态交互|Zhengyao Lv, Tianlin Pan, Chenyang Si, Zhaoxi Chen, Wangmeng Zuo, Ziwei Liu, Kwan-Yee K. Wong|<http://arxiv.org/pdf/2506.07986v1>|[代码](https://github.com/Vchitect/TACA); 提出Temperature-Adjusted Cross-modal Attention方法，有效平...|
|🆕 发布|OneIG-Bench: Omni-dimensional Nuanced Evaluation for Image Generation|OneIG-Bench：图像生成的全维度细微评价基准|Jingjing Chang, Yixiao Fang, Peng Xing, Shuhan Wu, Wei Cheng, Rui Wang, Xianfang Zeng, Gang Yu .etc.|<http://arxiv.org/pdf/2506.07977v1>|提出全面的OneIG-Bench评估框架，细致评价文本到图像生成模型在多维度性能。|
|📝 更新|RONA: Pragmatically Diverse Image Captioning with Coherence Relations|RONA：基于连贯性关系的语用多样性图像字幕生成|Aashish Anantha Ramakrishnan, Aadarsh Anantha Ramakrishnan, Dongwon Lee|<http://arxiv.org/pdf/2503.10997v2>|[代码](https://github.com/aashish2000/RONA); 提出RONA策略，利用连贯关系增强多模态大语言模型生成的图像标题多样性。|
|🆕 发布|Video Unlearning via Low-Rank Refusal Vector|通过低秩拒绝向量进行视频遗忘学习|Simone Facchiano, Stefano Saravalle, Matteo Migliarini, Edoardo De Matteis, Alessio Sampieri, Andrea Pilzer, Emanuele Rodolà, Indro Spinelli .etc.|<http://arxiv.org/pdf/2506.07891v1>|提出首个针对视频生成模型的“遗忘”技术，通过低秩拒绝向量消除有害内容，无需重训练或访问原始数据。|
|📝 更新|BiMa: Towards Biases Mitigation for Text-Video Retrieval via Scene Element Guidance|BiMa：面向场景元素引导的文本-视频检索偏差缓解方法|Huy Le, Nhat Chung, Tung Kieu, Anh Nguyen, Ngan Le|<http://arxiv.org/pdf/2506.03589v2>|提出BiMa框架，通过场景元素引导减轻文本-视频检索中的视觉与文本偏见。|
|🆕 发布|ARGUS: Hallucination and Omission Evaluation in Video-LLMs|ARGUS：视频大型语言模型中的虚构与遗漏评估|Ruchit Rawal, Reza Shirkavand, Heng Huang, Gowthami Somepalli, Tom Goldstein|<http://arxiv.org/pdf/2506.07371v1>|提出ARGUS基准，用于评估视频大语言模型在自由文本生成任务中的虚构和遗漏错误。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|WeThink: Toward General-purpose Vision-Language Reasoning via Reinforcement Learning|《WeThink：通过强化学习实现通用视觉-语言推理》|Jie Yang, Feipeng Ma, Zitian Wang, Dacheng Yin, Kang Rong, Fengyun Rao, Ruimao Zhang|<http://arxiv.org/pdf/2506.07905v1>|提出了一种结合强化学习的多模态视觉语言推理方法，通过自主生成QA对和综合奖励机制，实现了通用视觉语言...|
|🆕 发布|M2Restore: Mixture-of-Experts-based Mamba-CNN Fusion Framework for All-in-One Image Restoration|M2Restore：基于专家混合的Mamba-CNN融合框架实现一站式图像复原|Yongzhen Wang, Yongjun Li, Zhuoran Zheng, Xiao-Ping Zhang, Mingqiang Wei|<http://arxiv.org/pdf/2506.07814v1>|提出了一种融合Mixture-of-Experts和Mamba-CNN的框架，实现了对多种图像退化类...|
|📝 更新|An Overview of the Burer-Monteiro Method for Certifiable Robot Perception|《可证明机器人感知的Burer-Monteiro方法概述》|Alan Papalia, Yulun Tian, David M. Rosen, Jonathan P. How, John J. Leonard|<http://arxiv.org/pdf/2410.00117v2>|概述了Burer-Monteiro方法在实时机器人感知中的应用，通过优化半定规划降低计算成本以实现最...|
|🆕 发布|SceneRAG: Scene-level Retrieval-Augmented Generation for Video Understanding|场景级检索增强生成模型SceneRAG：用于视频理解|Nianbo Zeng, Haowen Hou, Fei Richard Yu, Si Shi, Ying Tiffany He|<http://arxiv.org/pdf/2506.07600v1>|提出了一种基于大语言模型的SceneRAG框架，通过场景级分割和跨模态信息融合，有效提升了长视频内容...|
|🆕 发布|Genesis: Multimodal Driving Scene Generation with Spatio-Temporal and Cross-Modal Consistency|创世纪：具有时空一致性和跨模态一致性的多模态驾驶场景生成|Xiangyu Guo, Zhanqian Wu, Kaixin Xiong, Ziyang Xu, Lijun Zhou, Gangwei Xu, Shaoqing Xu, Haiyang Sun .etc.|<http://arxiv.org/pdf/2506.07497v1>|提出了一种统一框架Genesis，实现了多视角驾驶视频和LiDAR序列的联合生成，保持了时空和跨模态...|
|📝 更新|Efficient MRI Parallel Imaging Reconstruction by K-Space Rendering via Generalized Implicit Neural Representation|通过广义隐式神经表示的K空间渲染进行高效MRI并行成像重建|Hao Li, Yusheng Zhou, Jianan Liu, Xiling Liu, Tao Huang, Zhihan Lyu, Weidong Cai, Wei Chen|<http://arxiv.org/pdf/2309.06067v8>|提出了一种基于广义隐式神经表示的MRI并行成像重建方法，有效克服了传统方法局限性，提高了重建效率和图...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Real-time Localization of a Soccer Ball from a Single Camera|单目相机下足球的实时定位|Dmitrii Vorobev, Artem Prosvetov, Karim Elhadji Daou|<http://arxiv.org/pdf/2506.07981v1>|提出了一种高效的单摄像头足球轨迹实时重建方法，通过多模式状态模型实现厘米级精度。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes|快速可变形三维高斯散点绘制：动态场景的快速渲染与压缩|Allen Tu, Haiyang Ying, Alex Hanson, Yonghan Lee, Tom Goldstein, Matthias Zwicker|<http://arxiv.org/pdf/2506.07917v1>|提出了一种加速动态场景渲染和压缩的方法，通过减少神经网络推理和优化高斯分布处理，大幅提升效率。|
|🆕 发布|Identifiable Object Representations under Spatial Ambiguities|在空间歧义下的可识别对象表示|Avinash Kori, Francesca Toni, Ben Glocker|<http://arxiv.org/pdf/2506.07806v1>|提出了一种多视角概率方法，通过聚合特定视角的槽来解析空间歧义并学习不变内容信息，无需视角标注即可实现...|
|🆕 发布|Language Embedding Meets Dynamic Graph: A New Exploration for Neural Architecture Representation Learning|语言嵌入遇见动态图：神经网络结构表征学习的新探索|Haizhao Jing, Haokui Zhang, Zhenhao Shang, Rong Xiao, Peng Wang, Yanning Zhang|<http://arxiv.org/pdf/2506.07735v1>|引入LeDG-Former框架，结合语言嵌入与动态图表示学习，实现跨硬件平台的零样本预测和提升神经架...|
|🆕 发布|Fine-Grained Motion Compression and Selective Temporal Fusion for Neural B-Frame Video Coding|细粒度运动压缩与选择性时间融合用于神经B帧视频编码|Xihua Sheng, Peilin Chen, Meng Wang, Li Zhang, Shiqi Wang, Dapeng Oliver Wu|<http://arxiv.org/pdf/2506.07709v1>|提出双向运动向量的细粒度压缩和选择性时间融合策略，提升神经B帧视频编码性能。|
|📝 更新|I-INR: Iterative Implicit Neural Representations|迭代隐式神经表示：I-INR|Ali Haider, Muhammad Salman Ali, Maryam Qamar, Tahir Khalil, Soo Ye Kim, Jihyong Oh, Enzo Tartaglione, Sung-Ho Bae|<http://arxiv.org/pdf/2504.17364v2>|提出迭代隐式神经表征方法，通过迭代优化显著提升信号重建质量与细节恢复能力。|
|📝 更新|Structure-Aware Radar-Camera Depth Estimation|结构感知的雷达-相机深度估计|Fuyi Zhang, Zhu Yu, Chunhao Li, Runmin Zhang, Xiaokai Bai, Zili Zhou, Si-Yuan Cao, Fang Wang .etc.|<http://arxiv.org/pdf/2506.05008v2>|提出结构感知方法，通过融合雷达与相机数据，实现更准确的零样本单目深度估计。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Image Reconstruction as a Tool for Feature Analysis|图像重构作为特征分析的工具|Eduard Allakhverdov, Dmitrii Tarasov, Elizaveta Goncharova, Andrey Kuznetsov|<http://arxiv.org/pdf/2506.07803v1>|通过图像重构分析视觉编码器内部特征表示，揭示了训练任务对特征保留的影响。|
|📝 更新|Robust 3D Shape Reconstruction in Zero-Shot from a Single Image in the Wild|零样本条件下从野外单张图像中鲁棒重建三维形状|Junhyeong Cho, Kim Youwang, Hunmin Yang, Tae-Hyun Oh|<http://arxiv.org/pdf/2403.14539v3>|提出了一种集成分割与重建的统一回归模型，实现了在遮挡环境下的零样本3D形状重建。|
|🆕 发布|HuSc3D: Human Sculpture dataset for 3D object reconstruction|HuSc3D：用于三维物体重建的人类雕塑数据集|Weronika Smolak-Dyżewska, Dawid Malarz, Grzegorz Wilczyński, Rafał Tobiasz, Joanna Waczyńska, Piotr Borycki, Przemysław Spurek|<http://arxiv.org/pdf/2506.07628v1>|提出HuSc3D数据集，专为评估3D重建模型在现实场景挑战下的性能。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CyberV: Cybernetics for Test-time Scaling in Video Understanding|《CyberV：视频理解中的测试时间尺度调整的控制系统》|Jiahao Meng, Shuyang Sun, Yue Tan, Lu Qi, Yunhai Tong, Xiangtai Li, Longyin Wen|<http://arxiv.org/pdf/2506.07971v1>|[代码](https://github.com/marinero4972/CyberV.); 提出了一种基于控制论的视频理解自适应框架CyberV，有效提升了多模态大语言模型处理长视频的能力。|
|📝 更新|What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning|“发生了什么以及可能发生了什么？面向过程感知视频表征学习的状态变化反事实”|Chi-Hsi Kung, Frangil Ramirez, Juhyung Ha, Yi-Ting Chen, David Crandall, Yi-Hsuan Tsai|<http://arxiv.org/pdf/2503.21055v2>|引入大语言模型生成状态变化描述及其反事实推理，提升视频表示学习对活动步骤因果理解的能力。|
|📝 更新|ViVo: A Dataset for Volumetric Video Reconstruction and Compression|ViVo：用于体积视频重建与压缩的数据集|Adrian Azzarelli, Ge Gao, Ho Man Kwan, Fan Zhang, Nantheera Anantrasirichai, Ollie Moolan-Feroze, David Bull|<http://arxiv.org/pdf/2506.00558v2>|提出 ViVo 数据集，包含丰富的人体特征和动态视觉现象，用于提升三维视频重建与压缩模型的性能。|
|🆕 发布|SurgBench: A Unified Large-Scale Benchmark for Surgical Video Analysis|手术视频分析统一大规模基准：SurgBench|Jianhui Wei, Zikai Xiao, Danyu Sun, Luqi Gong, Zongxin Yang, Zuozhu Liu, Jian Wu|<http://arxiv.org/pdf/2506.07603v1>|提出了SurgBench，一个包含大规模预训练和评估数据集的统一手术视频分析基准，显著提升了模型性能...|
|🆕 发布|Super Encoding Network: Recursive Association of Multi-Modal Encoders for Video Understanding|超级编码网络：多模态编码器的递归关联用于视频理解|Boyu Chen, Siran Chen, Kunchang Li, Qinglin Xu, Yu Qiao, Yali Wang|<http://arxiv.org/pdf/2506.07576v1>|提出统一的多模态编码网络，通过递归关联增强视频理解中的深层多模态交互。|
|🆕 发布|Ambiguity-Restrained Text-Video Representation Learning for Partially Relevant Video Retrieval|部分相关视频检索中的约束模糊性文本-视频表示学习|CH Cho, WJ Moon, W Jun, MS Jung, JP Heo|<http://arxiv.org/pdf/2506.07471v1>|提出了一种考虑文本与视频内容模糊性的学习方法，通过多正对比学习和双重三元组损失提升部分相关视频检索效...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|C3T: Cross-modal Transfer Through Time for Sensor-based Human Activity Recognition|基于时间的跨模态迁移传感器人体行为识别方法（C3T）|Abhi Kamboj, Anh Duy Nguyen, Minh N. Do|<http://arxiv.org/pdf/2407.16803v3>|提出了一种跨模态时间转移方法C3T，有效保留了时序信息以提升无监督学习活动识别的准确性。|
|📝 更新|OccludeNet: A Causal Journey into Mixed-View Actor-Centric Video Action Recognition under Occlusions|遮挡网：在混合视角以演员为中心的视频动作识别下的因果探索（遮挡情况下）|Guanyu Zhou, Wenxuan Liu, Wenxin Huang, Xuemei Jia, Xian Zhong, Chia-Wen Lin|<http://arxiv.org/pdf/2411.15729v2>|[代码](https://github.com/The-Martyr/OccludeNet-Dataset); 提出OccludeNet数据集及Causal Action Recognition方法，增强模型对遮...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SWAG: Long-term Surgical Workflow Prediction with Generative-based Anticipation|SWAG：基于生成式预测的长期手术工作流预测|Maxence Boels, Yang Liu, Prokar Dasgupta, Alejandro Granados, Sebastien Ourselin|<http://arxiv.org/pdf/2412.18849v3>|[代码](https://maxboels.github.io/swag.); 提出SWAG框架，结合生成式方法预测手术流程中的长期步骤，提高相位预测准确性。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO|深度视频R1：基于难度感知回归GRPO的视频强化微调|Jinyoung Park, Jeehye Na, Jinyoung Kim, Hyunwoo J. Kim|<http://arxiv.org/pdf/2506.07464v1>|提出了一种针对视频大语言模型的改进强化学习算法，通过回归任务和难度感知数据增强策略，有效提升了视频推...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Exploiting the Semantic Knowledge of Pre-trained Text-Encoders for Continual Learning|利用预训练文本编码器的语义知识进行持续学习|Lu Yu, Zhe Tao, Dipam Goswami, Hantao Yao, Bartłomiej Twardowski, Joost Van de Weijer, Changsheng Xu|<http://arxiv.org/pdf/2408.01076v2>|[代码](https://github.com/aprilsveryown/semantically-guided-continual-learning.); 利用预训练文本编码器的语义知识，提出了一种持续学习中的语义引导表示学习和知识蒸馏方法。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Aligning Text, Images, and 3D Structure Token-by-Token|文本、图像与3D结构逐标记对齐|Aadarsh Sahoo, Vansh Tibrewal, Georgia Gkioxari|<http://arxiv.org/pdf/2506.08002v1>|[代码](https://glab-caltech.github.io/kyvo); 提出统一的语言-图像-3D场景自回归模型，实现多模态理解和复杂3D任务处理。|
|🆕 发布|Rethinking Crowd-Sourced Evaluation of Neuron Explanations|重新思考基于众包的神经元解释评估方法|Tuomas Oikarinen, Ge Yan, Akshay Kulkarni, Tsui-Wei Weng|<http://arxiv.org/pdf/2506.07985v1>|提出了一种高效的众包评估策略，通过重要性采样和贝叶斯方法显著降低了神经元解释评估的成本和误差。|
|📝 更新|CORDIAL: Can Multimodal Large Language Models Effectively Understand Coherence Relationships?|CORDIAL: 多模态大型语言模型能有效理解连贯关系吗？|Aashish Anantha Ramakrishnan, Aadarsh Anantha Ramakrishnan, Dongwon Lee|<http://arxiv.org/pdf/2502.11300v2>|[代码](https://aashish2000.github.io/CORDIAL); 提出CORDIAL基准，评估大型多模态语言模型对连贯性关系的理解能力，发现现有模型表现不佳。|
|🆕 发布|BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation|比特VLA：面向机器人操作的1比特视觉-语言-动作模型|Hongyu Wang, Chuyan Xiong, Ruiping Wang, Xilin Chen|<http://arxiv.org/pdf/2506.07530v1>|[代码](https://github.com/ustcwhy/BitVLA.); 首次提出1-bit Vision-Language-Action模型BitVLA，降低机器人操作任务...|
|🆕 发布|Compressed Feature Quality Assessment: Dataset and Baselines|压缩特征质量评估：数据集与基线|Changsheng Gao, Wei Zhou, Guosheng Lin, Weisi Lin|<http://arxiv.org/pdf/2506.07412v1>|[代码](https://github.com/chansongoal/Compressed-Feature-Quality-Assessment); 提出压缩特征质量评估问题，构建首个评估数据集，并分析现有度量方法在语义失真捕捉上的不足。|
|🆕 发布|DPFormer: Dynamic Prompt Transformer for Continual Learning|DPFormer：动态提示Transformer用于持续学习|Sheng-Kai Huang, Jiun-Feng Chang, Chun-Rong Huang|<http://arxiv.org/pdf/2506.07414v1>|提出动态提示变换器DPFormer解决连续学习中的灾难性遗忘和任务混淆问题，实现单一网络结构下的持续...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow|基于事件驱动的光流计算的时空状态空间模型|Muhammad Ahmed Humais, Xiaoqian Huang, Hussain Sajwani, Sajid Javed, Yahya Zweiri|<http://arxiv.org/pdf/2506.07878v1>|[代码](https://github.com/AhmedHumais/E-STMFlow); 提出了一种高效的基于事件相机的事件光流估计方法STSSM，通过捕捉时空相关性，实现了优于传统方法的性...|
|🆕 发布|ETA: Efficiency through Thinking Ahead, A Dual Approach to Self-Driving with Large Models|“ETA：通过前瞻性思考提高效率，大型模型自动驾驶的双策略方法”|Shadi Hamdan, Chonghao Sima, Zetong Yang, Hongyang Li, Fatma Güney|<http://arxiv.org/pdf/2506.07725v1>|提出异步系统ETA，通过提前计算和批量推理，实现大模型在自动驾驶中的快速响应。|
|🆕 发布|ReverB-SNN: Reversing Bit of the Weight and Activation for Spiking Neural Networks|反向位权值与激活反转的脉冲神经网络：ReverB-SNN|Yufei Guo, Yuhan Zhang, Zhou Jie, Xiaode Liu, Xin Tong, Yuanpei Chen, Weihang Peng, Zhe Ma|<http://arxiv.org/pdf/2506.07720v1>|提出了一种反转权重和激活位的策略ReverB-SNN，通过使用实值激活和二值权重提升SNN的信息容量...|
|📝 更新|50 Years of Automated Face Recognition|《自动化人脸识别的五十年》|Minchul Kim, Anil Jain, Xiaoming Liu|<http://arxiv.org/pdf/2505.24247v2>|回顾自动化人脸识别50年发展，从简单手工系统到先进深度学习模型，显著提升识别准确度并指出未来研究方向...|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts|混合精度量化用于长上下文大语言模型推理的量化感知专家混合方法（MoQAE）|Wei Tao, Haocheng Lu, Xiaoyang Qu, Bin Zhang, Kai Lu, Jiguang Wan, Jianzong Wang|<http://arxiv.org/pdf/2506.07533v1>|提出混合精度量化方法MoQAE，通过专家混合选择最优配置，有效平衡大型语言模型长文本推理的准确性和内...|
|🆕 发布|Variational Supervised Contrastive Learning|变分监督对比学习|Ziwen Wang, Jiajun Fan, Thao Nguyen, Heng Ji, Ge Liu|<http://arxiv.org/pdf/2506.07413v1>|提出VarCon方法，通过变分推理优化对比学习，提高分类准确性和泛化能力。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MMScan: A Multi-Modal 3D Scene Dataset with Hierarchical Grounded Language Annotations|MMScan：一种带有分层基础语言注释的多模态三维场景数据集|Ruiyuan Lyu, Jingli Lin, Tai Wang, Shuai Yang, Xiaohan Mao, Yilun Chen, Runsen Xu, Haifeng Huang .etc.|<http://arxiv.org/pdf/2406.09401v2>|[代码](https://github.com/OpenRobotLab/EmbodiedScan.); 构建首个大规模多模态3D场景数据集MMScan，以分层语言注释增强空间与属性理解。|
|🆕 发布|MrM: Black-Box Membership Inference Attacks against Multimodal RAG Systems|MrM: 针对多模态RAG系统的黑盒成员推断攻击|Peiru Yang, Jinhua Yin, Haoran Zheng, Xueying Bai, Huili Wang, Yufei Sun, Xintian Li, Shangguang Wang .etc.|<http://arxiv.org/pdf/2506.07399v1>|提出首个针对多模态检索增强生成系统的黑盒成员推断攻击框架，通过数据扰动和掩码选择策略提高攻击效率。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CAPAA: Classifier-Agnostic Projector-Based Adversarial Attack|分类器无关投影器基础上的对抗性攻击：CAPAA|Zhan Li, Mingyu Zhao, Xin Dong, Haibin Ling, Bingyao Huang|<http://arxiv.org/pdf/2506.00978v2>|[代码](https://github.com/ZhanLiQxQ/CAPAA.); 提出了一种通用且适应性强的投影式对抗攻击方法CAPAA，通过多分类器聚合和注意力加权优化，提高了攻击...|
|📝 更新|Diffusion-based Adversarial Purification from the Perspective of the Frequency Domain|基于频率域视角的扩散式对抗性净化|Gaozheng Pei, Ke Ma, Yingfei Sun, Qianqian Xu, Qingming Huang|<http://arxiv.org/pdf/2505.01267v2>|提出了一种基于频率域的扩散式对抗性噪声消除方法，有效去除扰动同时保留图像原内容结构。|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Uncertainty-o: One Model-agnostic Framework for Unveiling Uncertainty in Large Multimodal Models|不确定性的揭示：一种模型无关框架，用于揭示大型多模态模型中的不确定性|Ruiyang Zhang, Hu Zhang, Hao Fei, Zhedong Zheng|<http://arxiv.org/pdf/2506.07575v1>|提出框架Uncertainty-o评估大型多模态模型的不确定性，增强下游任务性能。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Play to Generalize: Learning to Reason Through Game Play|《玩以泛化：通过游戏玩耍学习推理》|Yunfei Xie, Yinsong Ma, Shiyi Lan, Alan Yuille, Junfei Xiao, Chen Wei|<http://arxiv.org/pdf/2506.08011v1>|提出通过让大型语言模型玩简易电子游戏来增强其跨领域多模态推理能力的新训练范式。|
|🆕 发布|4DGT: Learning a 4D Gaussian Transformer Using Real-World Monocular Videos|4DGT：使用现实世界单目视频学习四维高斯变换器|Zhen Xu, Zhengqin Li, Zhao Dong, Xiaowei Zhou, Richard Newcombe, Zhaoyang Lv|<http://arxiv.org/pdf/2506.08015v1>|提出4DGT模型，通过4D高斯变换统一处理静态与动态场景，实现快速动态场景重建。|
|🆕 发布|CXR-LT 2024: A MICCAI challenge on long-tailed, multi-label, and zero-shot disease classification from chest X-ray|CXR-LT 2024：基于胸部X射线的长尾、多标签和零样本疾病分类的MICCAI挑战赛|Mingquan Lin, Gregory Holste, Song Wang, Yiliang Zhou, Yishu Wei, Imon Banerjee, Pengyi Chen, Tianjie Dai .etc.|<http://arxiv.org/pdf/2506.07984v1>|CXR-LT 2024通过扩展数据集并引入零样本学习，提升了胸部X射线疾病分类的准确性和泛化能力。|
|🆕 发布|Mimicking or Reasoning: Rethinking Multi-Modal In-Context Learning in Vision-Language Models|模仿还是推理：重新思考视觉语言模型中的多模态情境学习|Chengyue Huang, Yuchen Zhu, Sichen Zhu, Jingyun Xiao, Moises Andrade, Shivang Chopra, Zsolt Kira|<http://arxiv.org/pdf/2506.07936v1>|揭示了现有视觉语言模型在多模态情境学习中的不足，并提出了加入推理过程的新方法。|
|🆕 发布|FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity|高斯速度驱动的动态视频中的3D物理学习：FreeGave方法|Jinxi Li, Ziyang Song, Siyuan Zhou, Bo Yang|<http://arxiv.org/pdf/2506.07865v1>|提出了一种无需物体先验知识，通过估计每高斯速度场学习复杂动态三维场景物理的方法。|
|📝 更新|Improving Generalization in MRI-Based Deep Learning Models for Total Knee Replacement Prediction|提高基于MRI的深度学习模型在预测全膝关节置换中的泛化性能|Ehsan Karami, Hamid Soltanian-Zadeh|<http://arxiv.org/pdf/2504.19203v4>|通过替换批量归一化、使用数据增强和对比损失，提高了MRI深度学习模型预测膝关节置换的泛化能力。|
|🆕 发布|Cross-channel Perception Learning for H&E-to-IHC Virtual Staining|跨通道感知学习用于H&E至IHC虚拟染色|Hao Yang, JianYu Wu, Run Fang, Xuelian Zhao, Yuan Ji, Zhiyu Chen, Guibin He, Junceng Guo .etc.|<http://arxiv.org/pdf/2506.07559v1>|提出了一种跨通道感知学习方法，有效利用细胞核与细胞膜间的关联，提升了病理图像虚拟染色的质量和一致性。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GHOST 2.0: generative high-fidelity one shot transfer of heads|GHOST 2.0：生成高保真度单次头像迁移|Alexander Groshev, Anastasiia Iashchenko, Pavel Paramonov, Denis Dimitrov, Andrey Kuznetsov|<http://arxiv.org/pdf/2502.18417v4>|[代码](https://github.com/ai-forever/ghost-2.0); 提出GHOST 2.0方法，通过增强对齐模型和融合模块实现高保真度的头部一键转移。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hidden in plain sight: VLMs overlook their visual representations|《显而易见却视而不见：视觉语言模型忽视其视觉表征》|Stephanie Fu, Tyler Bonnen, Devin Guillory, Trevor Darrell|<http://arxiv.org/pdf/2506.08008v1>|发现视觉语言模型在视觉任务上表现不佳，揭示了其未能有效整合视觉信息的问题。|
|🆕 发布|ZeroVO: Visual Odometry with Minimal Assumptions|零假设视觉里程计：在最小假设下的视觉里程计算法|Lei Lai, Zekai Yin, Eshed Ohn-Bar|<http://arxiv.org/pdf/2506.08005v1>|提出了一种无需相机校准的视觉里程计算法，通过融合语义信息和半监督训练实现跨相机和环境零样本泛化。|
|🆕 发布|Looking Beyond Visible Cues: Implicit Video Question Answering via Dual-Clue Reasoning|超越可见线索：通过双线索推理实现隐式视频问答|Tieyuan Chen, Huabin Liu, Yi Wang, Chaofan Gan, Mingxi Lyu, Gui Zou, Weiyao Lin|<http://arxiv.org/pdf/2506.07811v1>|[代码](https://github.com/tychen-SJTU/Implicit-VideoQA.); 提出了一种针对隐含视觉证据的 Implicit Video Question Answering 任...|
|📝 更新|From Thousands to Billions: 3D Visual Language Grounding via Render-Supervised Distillation from 2D VLMs|从数千到数十亿：通过渲染监督的二维视觉语言模型蒸馏实现三维视觉语言的定位|Ang Cao, Sergio Arnaud, Oleksandr Maksymets, Jianing Yang, Ayush Jain, Sriram Yenamandra, Ada Martin, Vincent-Pierre Berges .etc.|<http://arxiv.org/pdf/2502.20389v2>|提出了一种通过可微分渲染将2D监督扩展到3D视觉语言定位的方法，大幅提升了性能。|
|📝 更新|GRE Suite: Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains|GRE 套件：通过微调视觉-语言模型和增强推理链进行地理定位推断|Chun Wang, Xiaoran Pan, Zihao Pan, Haofan Wang, Yiren Song|<http://arxiv.org/pdf/2505.18700v2>|[代码](https://github.com/Thorin215/GRE.); 提出GRE Suite框架，结合细粒度视觉和世界知识推理链，显著提升地理定位准确性和解释性。|
|🆕 发布|Re-ranking Reasoning Context with Tree Search Makes Large Vision-Language Models Stronger|用树搜索重新排序推理上下文使大规模视觉-语言模型更强大|Qi Yang, Chenghao Zhang, Lubin Fan, Kun Ding, Jieping Ye, Shiming Xiang|<http://arxiv.org/pdf/2506.07785v1>|[代码](https://github.com/yannqi/RCTS-RAG.); 提出方法增强大型视觉语言模型，通过构建丰富推理上下文的数据库和树搜索重排机制提升回答一致性。|
|🆕 发布|Language-Vision Planner and Executor for Text-to-Visual Reasoning|语言-视觉规划与执行者：用于文本到视觉推理|Yichang Xu, Gaowen Liu, Ramana Rao Kompella, Sihao Hu, Tiansheng Huang, Fatih Ilhan, Selim Furkan Tekin, Zachary Yahn .etc.|<http://arxiv.org/pdf/2506.07778v1>|提出了一种集成规划与执行的视觉推理系统VLAgent，通过实时修正和优化，显著提升了多模态视觉文本推...|
|🆕 发布|Trend-Aware Fashion Recommendation with Visual Segmentation and Semantic Similarity|基于视觉分割和语义相似性的趋势感知时尚推荐|Mohamed Djilani, Nassim Ali Ousalah, Nidhal Eddine Chenni|<http://arxiv.org/pdf/2506.07773v1>|[代码](https://github.com/meddjilani/FashionRecommender); 提出了一种结合视觉分割和语义相似度的趋势感知时尚推荐系统，通过综合视觉特征、购物行为模拟来提升个性化...|
|🆕 发布|Synthetic Visual Genome|合成视觉基因组|Jae Sung Park, Zixian Ma, Linjie Li, Chenhao Zheng, Cheng-Yu Hsieh, Ximing Lu, Khyathi Chandu, Quan Kong .etc.|<http://arxiv.org/pdf/2506.07643v1>|提出合成视觉基因组SVG和模型ROBIN，通过密集关系注释和自我蒸馏框架提升视觉关系理解性能。|
|🆕 发布|Learning Speaker-Invariant Visual Features for Lipreading|学习说话人不变视觉特征以用于唇读|Yu Li, Feng Xue, Shujie Li, Jinrui Zhang, Shuang Yang, Dan Guo, Richang Hong|<http://arxiv.org/pdf/2506.07572v1>|提出了一种学习说话人不变视觉特征的框架，通过解耦特定说话人属性，显著提升了唇读模型的泛化性能。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Incorporating Uncertainty-Guided and Top-k Codebook Matching for Real-World Blind Image Super-Resolution|将不确定性引导和Top-k码本匹配融入实际场景盲图像超分辨率中|Weilei Wen, Tianyi Zhang, Qianqian Zhao, Zhaohui Zheng, Chunle Guo, Xiuli Shao, Chongyi Li|<http://arxiv.org/pdf/2506.07809v1>|提出了一种结合不确定性指导和Top-k码本匹配的图像超分辨率框架，有效解决了特征匹配不准确和纹理细节...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Comparative Study of U-Net Architectures for Change Detection in Satellite Images|《卫星图像变化检测中U-Net架构的比较研究》|Yaxita Amin, Naimisha S Trivedi, Rashmi Bhattad|<http://arxiv.org/pdf/2506.07925v1>|对比分析了18种U-Net变体在卫星图像变化检测中的应用效果，强调了针对变化检测优化的网络结构的重要...|
|🆕 发布|CrosswalkNet: An Optimized Deep Learning Framework for Pedestrian Crosswalk Detection in Aerial Images with High-Performance Computing|“CrosswalkNet：一种面向高性能计算下航空影像行人横道检测的优化深度学习框架”|Zubin Bhuyan, Yuanchang Xie, AngkeaReach Rith, Xintong Yan, Nasko Apostolov, Jimi Oke, Chengbo Ai|<http://arxiv.org/pdf/2506.07885v1>|提出CrosswalkNet，一种高效深度学习框架，通过优化检测策略和计算方法，精确识别航拍图像中的...|
|🆕 发布|R3D2: Realistic 3D Asset Insertion via Diffusion for Autonomous Driving Simulation|R3D2：通过扩散实现自动驾驶模拟中的真实三维资产插入|William Ljungbergh, Bernardo Taveira, Wenzhao Zheng, Adam Tonderski, Chensheng Peng, Fredrik Kahl, Christoffer Petersson, Michael Felsberg .etc.|<http://arxiv.org/pdf/2506.07826v1>|提出了一种实时生成逼真3D资产插入效果的轻量级模型R3D2，解决了传统模拟平台资源消耗大和现实世界数...|
|🆕 发布|FMaMIL: Frequency-Driven Mamba Multi-Instance Learning for Weakly Supervised Lesion Segmentation in Medical Images|频率驱动的响尾蛇多实例学习用于医学图像的弱监督病变分割：FMaMIL|Hangbei Cheng, Xiaorong Dong, Xueyu Liu, Jianan Zhang, Xuetao Ma, Mingqiang Wei, Liansheng Wang, Junxin Chen .etc.|<http://arxiv.org/pdf/2506.07652v1>|提出了一种基于图像级标签的弱监督病变分割方法FMaMIL，通过频率域编码和自修正机制提升分割精度。|
|🆕 发布|APTOS-2024 challenge report: Generation of synthetic 3D OCT images from fundus photographs|APTOS-2024挑战报告：从眼底照片生成合成三维OCT图像|Bowen Liu, Weiyi Zhang, Peranut Chotcomwongse, Xiaolan Chen, Ruoyu Chen, Pawin Pakaymaskul, Niracha Arjkongharn, Nattaporn Vongsa .etc.|<http://arxiv.org/pdf/2506.07542v1>|提出APTOS-2024挑战，验证了从2D眼底照片生成3D OCT图像的可行性，提升眼科医疗可及性。|
|🆕 发布|Text-guided multi-stage cross-perception network for medical image segmentation|文本引导的多阶段交叉感知网络用于医学图像分割|Gaoyu Chen|<http://arxiv.org/pdf/2506.07475v1>|提出了一种文本引导的多阶段跨感知网络，有效解决了医学图像分割中目标区域语义表达弱的问题。|
|📝 更新|Learning Concept-Driven Logical Rules for Interpretable and Generalizable Medical Image Classification|学习用于可解释和泛化的医学图像分类的概念驱动逻辑规则|Yibo Gao, Hangqi Zhou, Zheyao Gao, Bomin Wang, Shangqi Gao, Sihan Wang, Xiahai Zhuang|<http://arxiv.org/pdf/2505.14049v2>|[代码](https://github.com/obiyoag/crl.); 提出Concept Rule Learner框架，通过学习布尔逻辑规则从视觉概念中提取可解释且泛化性...|
|🆕 发布|MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models|MedChat：基于大型语言模型的多模态诊断多智能体框架|Philip Liu, Sparsh Bansal, Jimmy Dinh, Aditya Pawar, Ramani Satishkumar, Shail Desai, Neeraj Gupta, Xin Wang .etc.|<http://arxiv.org/pdf/2506.07400v1>|[代码](https://github.com/Purdue-M2/MedChat.); 定位医学影像诊断挑战，提出MedChat多代理框架，融合专业视觉模型与角色化大语言模型，提升诊断准确...|
|🆕 发布|C3S3: Complementary Competition and Contrastive Selection for Semi-Supervised Medical Image Segmentation|C3S3：互补竞争与对比选择用于半监督医学图像分割|Jiaying He, Yitong Lin, Jiahe Chen, Honghui Xu, Jianwei Zheng|<http://arxiv.org/pdf/2506.07368v1>|[代码](https://github.com/Y-TARL/C3S3.); 提出C3S3模型，通过互补竞争和对比选择提升半监督医疗图像分割的边界精确度。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|F2Net: A Frequency-Fused Network for Ultra-High Resolution Remote Sensing Segmentation|F2Net：一种用于超高分遥感图像分割的频率融合网络|Hengzhi Chen, Liqian Feng, Wenhua Wu, Xiaogang Zhu, Shawn Leo, Kun Hu|<http://arxiv.org/pdf/2506.07847v1>|提出F2Net，通过高频保留细节和低频捕捉依赖，有效提升超高分遥感图像分割性能。|
|🆕 发布|SpikeSMOKE: Spiking Neural Networks for Monocular 3D Object Detection with Cross-Scale Gated Coding|"SpikeSMOKE：基于单目视觉的3D物体检测用尖峰神经网络及跨尺度门控编码"|Xuemei Chen, Huamin Wang, Hangchi Shen, Shukai Duan, Shiping Wen, Tingwen Huang|<http://arxiv.org/pdf/2506.07737v1>|提出 SpikeSMOKE 架构，结合跨尺度编码和轻量级残差块，实现低功耗的 3D 物体检测。|
|📝 更新|Remote Sensing Image Classification with Decoupled Knowledge Distillation|遥感图像分类中的解耦知识蒸馏|Yaping He, Jianfeng Cai, Qicong Hu, Peiqing Wang|<http://arxiv.org/pdf/2505.19111v2>|提出了一种基于知识蒸馏的轻量级遥感图像分类方法，通过分离目标和非目标类提高了准确率并减少了参数量。|
|📝 更新|Continuous Urban Change Detection from Satellite Image Time Series with Temporal Feature Refinement and Multi-Task Integration|基于时间特征精炼与多任务融合的卫星图像时间序列连续城市变化检测|Sebastian Hafner, Heng Fang, Hossein Azizpour, Yifang Ban|<http://arxiv.org/pdf/2406.17458v3>|提出了一种结合时间特征精炼和多任务集成的框架，用于从卫星图像时间序列中连续检测城市变化。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Diffusion-Driven Temporal Super-Resolution and Spatial Consistency Enhancement Framework for 4D MRI imaging|四维磁共振成像中的扩散驱动时间超分辨率与空间一致性增强框架|Xuanru Zhou, Jiarun Liu, Shoujun Yu, Hao Yang, Cheng Li, Tao Tan, Shanshan Wang|<http://arxiv.org/pdf/2506.04116v2>|提出了一种基于扩散驱动的4D MRI时空一致性增强框架，有效解决了快速大幅度运动下的时空分辨率权衡问...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Egocentric Event-Based Vision for Ping Pong Ball Trajectory Prediction|基于自我中心的逐帧视觉的乒乓球轨迹预测|Ivan Alberico, Marco Cannici, Giovanni Cioffi, Davide Scaramuzza|<http://arxiv.org/pdf/2506.07860v1>|利用事件相机实现实时乒乓球轨迹预测，通过人眼注视数据优化计算，显著降低延迟。|
|📝 更新|BiggerGait: Unlocking Gait Recognition with Layer-wise Representations from Large Vision Models|《BiggerGait：利用大型视觉模型逐层表征解锁步态识别》|Dingqing Ye, Chao Fan, Zhanbo Huang, Chengwen Luo, Jianqiang Li, Shiqi Yu, Xiaoming Liu|<http://arxiv.org/pdf/2505.18132v2>|提出了一种基于大型视觉模型层表示的简单通用步态识别基线BiggerGait，显著提升识别性能。|


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ArchiLense: A Framework for Quantitative Analysis of Architectural Styles Based on Vision Large Language Models|《ArchiLense：基于视觉大型语言模型的建筑风格定量分析框架》|Jing Zhong, Jun Yin, Peilin Li, Pengyu Zeng, Miao Zhang, Shuai Lu, Ran Luo|<http://arxiv.org/pdf/2506.07739v1>|提出ArchDiffBench数据集和ArchiLense框架，利用视觉语言模型自动识别和分类建筑风...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Creating a Historical Migration Dataset from Finnish Church Records, 1800-1920|从芬兰教堂记录创建历史移民数据集，1800-1920|Ari Vesalainen, Jenna Kanerva, Aida Nitsch, Kiia Korsu, Ilari Larkiola, Laura Ruotsalainen, Filip Ginter|<http://arxiv.org/pdf/2506.07960v1>|利用深度学习自动化处理，将芬兰历史教堂迁移记录转化为结构化大数据集。|
|🆕 发布|Towards the Influence of Text Quantity on Writer Retrieval|面向文本数量对作者检索影响的研究|Marco Peer, Robert Sablatnig, Florian Kleber|<http://arxiv.org/pdf/2506.07566v1>|探究文本量对作者检索性能的影响，发现增加文本量可显著提升检索准确率。|
|🆕 发布|Unblocking Fine-Grained Evaluation of Detailed Captions: An Explaining AutoRater and Critic-and-Revise Pipeline|解锁细粒度详细描述评价：一种解释性自动评分器和批评-修订流程|Brian Gordon, Yonatan Bitton, Andreea Marzoca, Yasumasa Onoe, Xiao Wang, Daniel Cohen-Or, Idan Szpektor|<http://arxiv.org/pdf/2506.07631v1>|[代码](https://google.github.io/unblocking-detail-caption); 提出详细图像描述的细粒度评估方法，创建了DOCCI-Critique基准和自动评分修订流程。|

