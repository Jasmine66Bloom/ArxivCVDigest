## [UPDATED!] **2025-06-11** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards a general-purpose foundation model for fMRI analysis|面向功能性磁共振成像分析通用基础模型的探索|Cheng Wang, Yu Jiang, Zhihao Peng, Chenxin Li, Changbae Bang, Lin Zhao, Jinglei Lv, Jorge Sepulcre .etc.|<http://arxiv.org/pdf/2506.11167v1>|提出了一种通用型fMRI分析框架 NeuroSTORM，通过大规模预训练提高了神经影像分析的再现性和...|
|📝 更新|TerraMind: Large-Scale Generative Multimodality for Earth Observation|“TerraMind：地球观测的大规模生成多模态”|Johannes Jakubik, Felix Yang, Benedikt Blumenstiel, Erik Scheurer, Rocco Sedona, Stefano Maurogiovanni, Jente Bosmans, Nikolaos Dionelis .etc.|<http://arxiv.org/pdf/2504.11171v2>|TerraMind提出首个地球观测任意模态生成模型，通过双尺度融合实现零样本和少样本应用，并引入生成...|
|📝 更新|RS-MTDF: Multi-Teacher Distillation and Fusion for Remote Sensing Semi-Supervised Semantic Segmentation|RS-MTDF：遥感多教师蒸馏与融合用于半监督语义分割|Jiayi Song, Kaiyu Li, Xiangyong Cao, Deyu Meng|<http://arxiv.org/pdf/2506.08772v2>|提出RS-MTDF框架，利用预训练视觉基础模型作为多教师指导半监督遥感图像语义分割，提升泛化能力和语...|
|📝 更新|Decoupling the Image Perception and Multimodal Reasoning for Reasoning Segmentation with Digital Twin Representations|将图像感知与多模态推理解耦：基于数字孪生表示的推理分割|Yizhen Li, Dell Zhang, Xuelong Li, Yiqing Shen|<http://arxiv.org/pdf/2506.07943v2>|提出了一种利用数字孪生表示分离图像感知与多模态推理的分割方法，实现了推理分割任务的最佳性能。|
|📝 更新|Human-like object concept representations emerge naturally in multimodal large language models|“类人对象概念表示在多模态大型语言模型中自然涌现”|Changde Du, Kaicheng Fu, Bincheng Wen, Yi Sun, Jie Peng, Wei Wei, Ying Gao, Shengpei Wang .etc.|<http://arxiv.org/pdf/2407.01067v3>|发现大型语言模型能自然形成类似人类的物体概念表征，通过多模态数据与人类认知紧密对应。|
|📝 更新|MCA-Bench: A Multimodal Benchmark for Evaluating CAPTCHA Robustness Against VLM-based Attacks|MCA-Bench：一种用于评估基于VLM攻击的验证码鲁棒性的多模态基准|Zonglin Wu, Yule Xue, Xin Wei, Yiren Song|<http://arxiv.org/pdf/2506.05982v2>|提出了MCA-Bench，一个统一的多模态评测基准，用于评估CAPTCHA对基于视觉语言模型的攻击的...|
|🆕 发布|An Effective End-to-End Solution for Multimodal Action Recognition|一种有效的端到端多模态动作识别解决方案|Songping Wang, Xiantao Hu, Yueming Lyu, Caifeng Shan|<http://arxiv.org/pdf/2506.09345v1>|提出了一种全面的多模态动作识别方案，通过数据增强和迁移学习扩展数据规模并提高模型适应性，实现了高效的...|
|📝 更新|GIQ: Benchmarking 3D Geometric Reasoning of Vision Foundation Models with Simulated and Real Polyhedra|GIQ：使用模拟和真实多面体对视觉基础模型的3D几何推理进行基准测试|Mateusz Michalkiewicz, Anekha Sokhal, Tadeusz Michalkiewicz, Piotr Pawlikowski, Mahsa Baktashmotlagh, Varun Jampani, Guha Balakrishnan|<http://arxiv.org/pdf/2506.08194v2>|提出了GIQ基准，揭示了当前视觉基础模型在几何推理方面的不足。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|California Crop Yield Benchmark: Combining Satellite Image, Climate, Evapotranspiration, and Soil Data Layers for County-Level Yield Forecasting of Over 70 Crops|加州作物产量基准：结合卫星图像、气候、蒸发蒸腾和土壤数据层进行超过70种作物县级产量预测|Hamid Kamangir, Mona Hajiesmaeeli, Mason Earles|<http://arxiv.org/pdf/2506.10228v1>|整合多源数据，开发深度学习模型，实现加州70多种作物县级别产量精准预测。|
|🆕 发布|A Navigation Framework Utilizing Vision-Language Models|利用视觉-语言模型的导航框架|Yicheng Duan, Kaiyu tang|<http://arxiv.org/pdf/2506.10172v1>|提出了一种模块化的视觉语言导航框架，通过解耦视觉语言理解和动作规划，实现快速灵活的导航。|
|🆕 发布|AnimateAnyMesh: A Feed-Forward 4D Foundation Model for Text-Driven Universal Mesh Animation|“AnimateAnyMesh：一种基于文本驱动的通用网格动画的前馈4D基础模型”|Zijie Wu, Chaohui Yu, Fan Wang, Xiang Bai|<http://arxiv.org/pdf/2506.09982v1>|提出了一种基于文本驱动的4D基础模型，实现了任意3D网格的高效动画生成。|
|📝 更新|Understanding Long Videos with Multimodal Language Models|《利用多模态语言模型理解长视频》|Kanchana Ranasinghe, Xiang Li, Kumara Kahatapitiya, Michael S. Ryoo|<http://arxiv.org/pdf/2403.16998v5>|[代码](https://github.com/kahnchana/mvu); 提出了一种融合自然语言和视觉信息的Multimodal Video Understanding框架，...|
|🆕 发布|3D-Aware Vision-Language Models Fine-Tuning with Geometric Distillation|三维感知的视觉语言模型通过几何蒸馏进行微调|Seonho Lee, Jiho Choi, Inha Kang, Jiwook Kim, Junsung Park, Hyunjung Shim|<http://arxiv.org/pdf/2506.09883v1>|提出了一种无需标注的几何蒸馏框架，将三维空间理解能力引入预训练的视觉语言模型。|
|📝 更新|ImageChain: Advancing Sequential Image-to-Text Reasoning in Multimodal Large Language Models|图像链：在多模态大型语言模型中推进序列图像到文本推理|Danae Sánchez Villegas, Ingo Ziegler, Desmond Elliott|<http://arxiv.org/pdf/2502.19409v2>|提出了一种框架ImageChain，通过模拟视觉序列为多轮对话，增强了大型多模态语言模型对图像序列的...|
|🆕 发布|OctoNav: Towards Generalist Embodied Navigation|八爪导航：迈向通用型具身导航|Chen Gao, Liankai Jin, Xingyu Peng, Jiazhao Zhang, Yue Deng, Annan Li, He Wang, Si Liu|<http://arxiv.org/pdf/2506.09839v1>|提出了一项通用型机器人导航方法OctoNav-R1，通过多模态指令和连续环境训练，增强了导航智能体的...|
|🆕 发布|Evaluating Multimodal Large Language Models on Video Captioning via Monte Carlo Tree Search|通过蒙特卡洛树搜索评估多模态大型语言模型在视频字幕生成中的应用|Linhao Yu, Xinguang Ji, Yahui Liu, Fanheng Kong, Chenxi Sun, Jingyuan Zhang, Hongzhi Zhang, V. W. .etc.|<http://arxiv.org/pdf/2506.11155v1>|[代码](https://github.com/tjunlp-lab/MCTS-VCB.); 提出自动框架AutoCaption，使用蒙特卡洛树搜索生成多样化视频描述，提升多模态大语言模型视频标...|
|🆕 发布|Hierarchical Image Matching for UAV Absolute Visual Localization via Semantic and Structural Constraints|通过语义和结构约束的无人机绝对视觉定位分层图像匹配|Xiangkai Zhang, Xiang Zhou, Mao Chen, Yuchen Lu, Xu Yang, Zhiyong Liu|<http://arxiv.org/pdf/2506.09748v1>|提出了一种结合语义和结构约束的分层图像匹配方法，用于无人机在GNSS信号不可用时的绝对视觉定位。|
|🆕 发布|Accurate and efficient zero-shot 6D pose estimation with frozen foundation models|准确且高效的无监督6D姿态估计与冻结基础模型|Andrea Caraffa, Davide Boscaini, Fabio Poiesi|<http://arxiv.org/pdf/2506.09784v1>|提出了一种无需任务特定训练的6D姿态估计方法FreeZeV2，通过预训练的几何和视觉基础模型实现对新...|
|📝 更新|Do Multiple Instance Learning Models Transfer?|多实例学习模型是否具有迁移性？|Daniel Shao, Richard J. Chen, Andrew H. Song, Joel Runevic, Ming Y. Lu, Tong Ding, Faisal Mahmood|<http://arxiv.org/pdf/2506.09022v2>|[代码](https://github.com/mahmoodlab/MIL-Lab); 揭示了多实例学习模型在计算病理学中的迁移性，证实预训练模型能显著提升小数据集的性能。|
|📝 更新|MIRAGE: Multimodal foundation model and benchmark for comprehensive retinal OCT image analysis|MIRAGE：多模态基础模型与全面视网膜OCT图像分析基准|José Morano, Botond Fazekas, Emese Sükei, Ronald Fecso, Taha Emre, Markus Gumpinger, Georg Faustmann, Marzieh Oghbaie .etc.|<http://arxiv.org/pdf/2506.08900v2>|[代码](https://github.com/j-morano/MIRAGE.); 提出MIRAGE模型，一种用于全面视网膜OCT图像分析的多模态基础模型，并创建了新的评估基准。|
|🆕 发布|Athena: Enhancing Multimodal Reasoning with Data-efficient Process Reward Models|雅典娜：利用数据高效过程奖励模型增强多模态推理|Shuai Wang, Zhenhua Liu, Jiaheng Wei, Xuanwu Yin, Dong Li, Emad Barsoum|<http://arxiv.org/pdf/2506.09532v1>|提出了一种高效生成高质量过程标注数据的方法，显著提升了多模态推理任务中奖励模型的表现。|
|🆕 发布|Ming-Omni: A Unified Multimodal Model for Perception and Generation|明-全息：一种用于感知与生成的统一多模态模型|Inclusion AI, Biao Gong, Cheng Zou, Chuanyang Zheng, Chunluan Zhou, Canxiang Yan, Chunxiang Jin, Chunjie Shen .etc.|<http://arxiv.org/pdf/2506.09344v1>|提出了一种统一的多模态模型Ming-Omni，能高效处理图像、文本、音频和视频，实现感知与生成一体化...|
|📝 更新|Autonomous Imagination: Closed-Loop Decomposition of Visual-to-Textual Conversion in Visual Reasoning for Multimodal Large Language Models|自主想象：视觉推理中视觉到文本转换的闭环分解在多模态大型语言模型中的应用|Jingming Liu, Yumeng Li, Boyuan Xiao, Yichang Jian, Ziang Qin, Tianjia Shao, Yao-Xiang Ding, Kun Zhou|<http://arxiv.org/pdf/2411.18142v3>|[代码](https://future-item.github.io/autoimagine-site); 提出方法让大型多模态语言模型通过迭代修改视觉输入，分解视觉推理任务，解决原本超感知能力的难题。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Peer-Ranked Precision: Creating a Foundational Dataset for Fine-Tuning Vision Models from DataSeeds' Annotated Imagery|同侪排序精度：创建一个用于从数据种子的注释图像微调视觉模型的基础数据集|Sajjad Abdoli, Freeman Lewin, Gediminas Vasiliauskas, Fabian Schonholz|<http://arxiv.org/pdf/2506.05673v3>|构建了一个高质量、多层级注释的图像数据集，推动数据驱动模型性能提升。|
|🆕 发布|Vision Matters: Simple Visual Perturbations Can Boost Multimodal Math Reasoning|《视觉至关重要：简单的视觉扰动可以提升多模态数学推理能力》|Yuting Li, Lai Wei, Kaipeng Zheng, Jingyuan Huang, Linghe Kong, Lichao Sun, Weiran Huang|<http://arxiv.org/pdf/2506.09736v1>|[代码](https://github.com/YutingLi0606/Vision-Matters.); 提出简单视觉扰动框架增强多模态数学推理，无需算法修改或额外训练数据。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PointNet with KAN versus PointNet with MLP for 3D Classification and Segmentation of Point Sets|点网结合KAN与点网结合MLP在点集三维分类与分割中的对比研究|Ali Kashefi|<http://arxiv.org/pdf/2410.10084v3>|首次将Kolmogorov-Arnold Networks集成到PointNet中，提升3D点云分类...|
|🆕 发布|HQFNN: A Compact Quantum-Fuzzy Neural Network for Accurate Image Classification|HQFNN：一种用于精确图像分类的紧凑量子-模糊神经网络|Jianhong Yao, Yangming Guo|<http://arxiv.org/pdf/2506.11146v1>|提出了一种结合量子计算与模糊逻辑的HQFNN网络，实现了在噪声环境下高准确度的图像分类。|
|📝 更新|Hyperspectral Image Classification via Transformer-based Spectral-Spatial Attention Decoupling and Adaptive Gating|通过基于Transformer的光谱-空间注意力解耦与自适应门控进行高光谱图像分类|Guandong Li, Mengxia Ye|<http://arxiv.org/pdf/2506.08324v2>|提出STNet网络，通过空间-光谱注意力解耦与自适应门控机制提升高光谱图像分类性能。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Rethinking Brain Tumor Segmentation from the Frequency Domain Perspective|从频域视角重新思考脑肿瘤分割问题|Minye Shao, Zeyu Wang, Haoran Duan, Yawen Huang, Bing Zhai, Shizheng Wang, Yang Long, Yefeng Zheng|<http://arxiv.org/pdf/2506.10142v1>|[代码](https://github.com/VinyehShaw/HFF.); 提出了一种基于频率域的脑肿瘤分割网络，通过分离频率成分和自适应强调边界细节，显著提升了对比增强区域的...|
|🆕 发布|Leveraging Depth and Language for Open-Vocabulary Domain-Generalized Semantic Segmentation|利用深度与语言进行开放词汇域泛化的语义分割|Siyu Chen, Ting Han, Chengzheng Fu, Changshe Zhang, Chaolei Wang, Jinhe Su, Guorong Cai, Meiliu Wu|<http://arxiv.org/pdf/2506.09881v1>|[代码](https://github.com/anonymouse-9c53tp182bvz/Vireo.); 提出了一种名为Vireo的框架，首次统一了开放词汇语义分割和领域泛化，通过结合视觉基础模型和深度信息...|
|🆕 发布|FARCLUSS: Fuzzy Adaptive Rebalancing and Contrastive Uncertainty Learning for Semi-Supervised Semantic Segmentation|FARCLUSS：模糊自适应重平衡与对比不确定性学习用于半监督语义分割|Ebenezer Tarubinga, Jenifer Kalafatovich|<http://arxiv.org/pdf/2506.11142v1>|将不确定性转化为学习优势，提出模糊自适应重平衡与对比不确定性学习的半监督语义分割框架，有效解决类别不...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Manually Annotated Image-Caption Dataset for Detecting Children in the Wild|《用于野外儿童检测的手动注释图像-字幕数据集》|Klim Kireev, Ana-Maria Creţu, Raphael Meier, Sarah Adel Bargal, Elissa Redmiles, Carmela Troncoso|<http://arxiv.org/pdf/2506.10117v1>|构建了一个含10,000对图像-字幕的儿童识别数据集，提升了未成年识别工具的评估基准。|
|📝 更新|HRTR: A Single-stage Transformer for Fine-grained Sub-second Action Segmentation in Stroke Rehabilitation|HRTR：一种用于中风康复中细粒度亚秒级动作分割的单阶段Transformer模型|Halil Ismail Helvaci, Justin Philip Huber, Jihye Bae, Sen-ching Samson Cheung|<http://arxiv.org/pdf/2506.02472v2>|提出HRTR模型，通过单阶段Transformer实现精细动作的亚秒级定位与分类，无需多阶段处理和后...|
|🆕 发布|EquiCaps: Predictor-Free Pose-Aware Pre-Trained Capsule Networks|等距胶囊网络：无需预测器的位姿感知预训练胶囊网络|Athinoulla Konstantinou, Georgios Leontidis, Mamatha Thota, Aiden Durrant|<http://arxiv.org/pdf/2506.09895v1>|提出了一种无需预测器的equivariant胶囊网络，通过内建的姿态感知能力提升姿态估计性能。|
|🆕 发布|The Four Color Theorem for Cell Instance Segmentation|细胞实例分割的四色定理|Ye Zhang, Yu Zhou, Yifeng Wang, Jun Xiao, Ziyue Wang, Yongbing Zhang, Jianxu Chen|<http://arxiv.org/pdf/2506.09724v1>|[代码](https://github.com/zhangye-zoe/FCIS.); 提出了一种基于四色定理的细胞实例分割方法，将问题转化为仅含四个类别的语义分割，实现了高效准确的细胞区...|
|🆕 发布|CHIP: A multi-sensor dataset for 6D pose estimation of chairs in industrial settings|CHIP：面向工业环境中椅子6D姿态估计的多传感器数据集|Mattia Nardon, Mikel Mujika Agirre, Ander González Tomé, Daniel Sedano Algarabel, Josep Rueda Collell, Ana Paola Caro, Andrea Caraffa, Fabio Poiesi .etc.|<http://arxiv.org/pdf/2506.09699v1>|介绍了专为工业环境设计的CHIP多传感器数据集，用于提升机器人对椅子6D位姿的估算准确性。|
|🆕 发布|DCIRNet: Depth Completion with Iterative Refinement for Dexterous Grasping of Transparent and Reflective Objects|深度完成迭代细化网络（DCIRNet）：用于透明和反射物体的灵巧抓取|Guanghu Xie, Zhiduo Jiang, Yonglong Zhang, Yang Liu, Zongwu Xie, Baoshi Cao, Hong Liu|<http://arxiv.org/pdf/2506.09491v1>|提出DCIRNet网络，融合RGB图像与深度图，有效提升透明和反光物体的深度估计质量。|
|📝 更新|LEMUR Neural Network Dataset: Towards Seamless AutoML|LEMUR神经网络数据集：迈向无缝自动机器学习|Arash Torabi Goodarzi, Roman Kochnev, Waleed Khalid, Furui Qin, Tolgay Atinc Uzun, Yashkumar Sanjaybhai Dhameliya, Yash Kanubhai Kathiriya, Zofia Antonina Bentyn .etc.|<http://arxiv.org/pdf/2504.10552v2>|[代码](https://github.com/ABrain-One/nn-dataset); 介绍了LEMUR神经网络数据集，支持自动机器学习并优化模型性能。|
|🆕 发布|A new approach for image segmentation based on diffeomorphic registration and gradient fields|基于微分同构配准和梯度场的新型图像分割方法|Junchao Zhou|<http://arxiv.org/pdf/2506.09357v1>|提出了一种结合形状分析和微分同构变换的图像分割新框架，无需大量训练数据即可实现准确分割。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Traveling Waves Integrate Spatial Information Through Time|旅行波通过时间整合空间信息|Mozes Jacobs, Roberto C. Budzinski, Lyle Muller, Demba Ba, T. Anderson Keller|<http://arxiv.org/pdf/2502.06034v4>|提出利用行波动态的卷积循环神经网络进行视觉信息全局整合，优于传统局部网络。|
|🆕 发布|CEM-FBGTinyDet: Context-Enhanced Foreground Balance with Gradient Tuning for tiny Objects|CEM-FBGTinyDet：基于上下文增强的前景平衡与梯度调整的小目标检测|Tao Liu, Zhenchao Cui|<http://arxiv.org/pdf/2506.09897v1>|提出了一种增强小目标检测的架构，通过多尺度特征增强和自适应优化平衡高低层特征梯度，提升小目标检测性能...|
|📝 更新|Exploring Test-Time Adaptation for Object Detection in Continually Changing Environments|探索在持续变化环境中目标检测的测试时适应方法|Shilei Cao, Juepeng Zheng, Yan Liu, Baoquan Zhao, Ziqi Yuan, Weijia Li, Runmin Dong, Haohuan Fu|<http://arxiv.org/pdf/2406.16439v5>|[代码](https://github.com/ShileiCao/AMROD.); 提出AMROD方法，通过自适应监控和随机参数重置解决对象检测在动态环境中的持续适应问题。|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Consistent Story Generation with Asymmetry Zigzag Sampling|具有对称之字形采样的连贯故事生成|Mingxiao Li, Mang Ning, Marie-Francine Moens|<http://arxiv.org/pdf/2506.09612v2>|[代码](https://github.com/Mingxiao-Li/Asymmetry-Zigzag-StoryDiffusion.); 提出了一种无训练的Zigzag采样策略，通过不对称提示和视觉共享增强视觉故事生成中的主题一致性。|
|📝 更新|Vastextures: Vast repository of textures and PBR materials extracted from real-world images using unsupervised methods|《Vastextures：使用无监督方法从现实世界图像中提取的纹理和PBR材料的大量库》|Sagi Eppel|<http://arxiv.org/pdf/2406.17146v3>|构建了一个包含50万纹理和PBR材料的庞大库，通过无监督方法自动提取，满足AI训练对多样化资产的需求...|
|🆕 发布|Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes|“听触之手：从三维场景中的物理交互生成声音”|Yiming Dou, Wonseok Oh, Yuqing Luo, Antonio Loquercio, Andrew Owens|<http://arxiv.org/pdf/2506.09989v1>|提出了一种将3D场景中手部互动产生的声音进行预测的方法，实现了互动式3D场景重建。|
|🆕 发布|From Intention to Execution: Probing the Generalization Boundaries of Vision-Language-Action Models|从意图到执行：探究视觉-语言-动作模型的泛化边界|Irving Fang, Juexiao Zhang, Shengbang Tong, Chen Feng|<http://arxiv.org/pdf/2506.09930v1>|[代码](https://ai4ce.github.io/INT-ACT); 探究了视觉语言行动模型泛化边界，提出统一任务套件以标准化评估机器人政策执行精准度。|
|🆕 发布|LEO-VL: Towards 3D Vision-Language Generalists via Data Scaling with Efficient Representation|LEO-VL：通过高效表征的数据缩放实现三维视觉-语言通用性|Jiangyong Huang, Xiaojian Ma, Xiongkun Linghu, Yue Fan, Junchao He, Wenxin Tan, Qing Li, Song-Chun Zhu .etc.|<http://arxiv.org/pdf/2506.09935v1>|提出了一种高效的3D场景表示方法，实现了大规模3D视觉语言模型训练，达到3D问答任务的最先进性能。|
|🆕 发布|Self-Calibrating BCIs: Ranking and Recovery of Mental Targets Without Labels|自校准脑机接口：无需标签的心智目标排序与恢复|Jonathan Grizou, Carlos de la Torre-Ortiz, Tuukka Ruotsalo|<http://arxiv.org/pdf/2506.11151v1>|提出了一种无标签自校准框架 CURSOR，通过 EEG 和图像数据恢复心中未知目标。|
|🆕 发布|3DGeoDet: General-purpose Geometry-aware Image-based 3D Object Detection|3DGeoDet：通用型感知几何的基于图像的3D目标检测|Yi Zhang, Yi Wang, Yawen Cui, Lap-Pui Chau|<http://arxiv.org/pdf/2506.09541v1>|[代码](https://cindy0725.github.io/3DGeoDet); 提出了一种基于预测深度信息的几何感知3D物体检测方法，有效提升了室内外环境下的检测准确性。|
|📝 更新|Genesis: Multimodal Driving Scene Generation with Spatio-Temporal and Cross-Modal Consistency|创世纪：具有时空一致性和跨模态一致性的多模态驾驶场景生成|Xiangyu Guo, Zhanqian Wu, Kaixin Xiong, Ziyang Xu, Lijun Zhou, Gangwei Xu, Shaoqing Xu, Haiyang Sun .etc.|<http://arxiv.org/pdf/2506.07497v2>|提出了一种统一框架Genesis，实现了多视角驾驶视频和LiDAR序列的联合生成，保持了时空和跨模态...|
|🆕 发布|TinySplat: Feedforward Approach for Generating Compact 3D Scene Representation|TinySplat：生成紧凑三维场景表示的前馈方法|Zetian Song, Jiaye Fu, Jiaqi Zhang, Xiaohan Lu, Chuanmin Jia, Siwei Ma, Wen Gao|<http://arxiv.org/pdf/2506.09479v1>|提出TinySplat方法，通过训练-free压缩框架大幅降低3D场景表示的存储成本。|
|📝 更新|FLoD: Integrating Flexible Level of Detail into 3D Gaussian Splatting for Customizable Rendering|FLoD：将灵活细节级别集成到3D高斯散点绘制中，以实现定制化渲染|Yunji Seo, Young Sun Choi, Hyun Seung Son, Youngjung Uh|<http://arxiv.org/pdf/2408.12894v2>|提出FLoD方法，通过多级细节调整使3D Gaussian Splatting适应不同硬件配置。|
|📝 更新|Neuromorphic Optical Tracking and Imaging of Randomly Moving Targets through Strongly Scattering Media|通过强散射介质对随机移动目标的类神经形态光学跟踪与成像|Ning Zhang, Timothy Shea, Arto Nurmikko|<http://arxiv.org/pdf/2501.03874v2>|提出了一种结合事件检测相机与类神经形态深度学习策略的方法，实现了对散射介质中随机移动目标的跟踪与成像...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Urban1960SatSeg: Unsupervised Semantic Segmentation of Mid-20$^{th}$ century Urban Landscapes with Satellite Imageries|《Urban1960SatSeg：基于卫星影像的20世纪中叶城市景观的无监督语义分割》|Tianxiang Hao, Lixian Zhang, Yingjia Zhang, Mengxuan Chen, Jinxiao Zhang, Haohuan Fu|<http://arxiv.org/pdf/2506.09476v2>|[代码](https://github.com/Tianxiang-Hao/Urban1960SatSeg.); 提出Urban1960SatBench数据集和Urban1960SatUSM框架，实现了无监督历史卫...|
|🆕 发布|ScoreMix: Improving Face Recognition via Score Composition in Diffusion Generators|分数混合：通过在扩散生成器中分数组合提升人脸识别|Parsa Rahimi, Sebastien Marcel|<http://arxiv.org/pdf/2506.10226v1>|[代码](https://parsa-ra.github.io/scoremix); 提出ScoreMix数据增强策略，利用扩散模型得分组合特性，在有限标注数据下提升识别性能。|
|🆕 发布|SPARKE: Scalable Prompt-Aware Diversity Guidance in Diffusion Models via RKE Score|SPARKE：通过RKE评分实现扩散模型中可扩展的提示感知多样性引导|Mohammad Jalali, Haoyu Lei, Amin Gohari, Farzan Farnia|<http://arxiv.org/pdf/2506.10173v1>|[代码](https://mjalali.github.io/SPARKE); 提出SPARKE方法，通过条件熵实现提示感知的多样性引导，降低计算复杂度，提升生成样本多样性。|
|🆕 发布|Attention, Please! Revisiting Attentive Probing for Masked Image Modeling|请注意！重新审视遮蔽图像建模中的注意力探测|Bill Psomas, Dionysis Christopoulos, Eirini Baltzi, Ioannis Kakogeorgiou, Tilemachos Aravanis, Nikos Komodakis, Konstantinos Karantzalos, Yannis Avrithis .etc.|<http://arxiv.org/pdf/2506.10178v1>|[代码](https://github.com/billpsomas/efficient-probing.); 提出了一种高效的注意力探测方法，通过减少参数和计算量，提升了自监督学习模型在多种任务中的性能和效率。|
|🆕 发布|Improving Personalized Search with Regularized Low-Rank Parameter Updates|使用正则化低秩参数更新改进个性化搜索|Fiona Ryan, Josef Sivic, Fabian Caba Heilbron, Judy Hoffman, James M. Rehg, Bryan Russell|<http://arxiv.org/pdf/2506.10182v1>|提出了一种正则化低秩参数更新方法，有效适应个性化视觉语言检索，实现了个人概念识别与通用知识保持。|
|🆕 发布|Text-Aware Image Restoration with Diffusion Models|基于扩散模型的文本感知图像恢复|Jaewon Min, Jin Hyeon Kim, Paul Hyunbin Cho, Jaeeun Lee, Jihye Park, Minkyu Park, Sangpil Kim, Hyunhee Park .etc.|<http://arxiv.org/pdf/2506.09993v1>|[代码](https://cvlab-kaist.github.io/TAIR); 提出文本感知图像复原方法TAIR，通过集成文本特征提升复原图像中文本区域的准确性。|
|📝 更新|Fine-Grained Spatially Varying Material Selection in Images|图像中精细粒度的空间变化材料选择|Julia Guerrero-Viu, Michael Fischer, Iliyan Georgiev, Elena Garces, Diego Gutierrez, Belen Masia, Valentin Deschaintre|<http://arxiv.org/pdf/2506.09023v2>|提出了一种基于视觉变换器的图像材质选择方法，能在不同光照和反射条件下稳定选择材质，并实现纹理和亚纹理...|
|🆕 发布|Vision Generalist Model: A Survey|《视觉通用模型：综述》|Ziyi Wang, Yongming Rao, Shuofeng Sun, Xinrun Liu, Yi Wei, Xumin Yu, Zuyan Liu, Yanbo Wang .etc.|<http://arxiv.org/pdf/2506.09954v1>|系统梳理了视觉通用模型的发展，探讨了其在计算机视觉任务中的应用与挑战。|
|🆕 发布|Canonical Latent Representations in Conditional Diffusion Models|条件扩散模型中的规范潜在表示|Yitao Xu, Tong Zhang, Ehsan Pajouheshgar, Sabine Süsstrunk|<http://arxiv.org/pdf/2506.09955v1>|提出Canonical LAtent Representations (CLAReps)优化扩散模型...|
|🆕 发布|HadaNorm: Diffusion Transformer Quantization through Mean-Centered Transformations|HadaNorm：通过均值中心变换的扩散变换器量化|Marco Federici, Riccardo Del Chiaro, Boris van Breugel, Paul Whatmough, Markus Nagel|<http://arxiv.org/pdf/2506.09932v1>|提出HadaNorm方法，通过特征通道归一化和Hadamard变换减少量化误差，提升模型压缩效率。|
|📝 更新|Video2BEV: Transforming Drone Videos to BEVs for Video-based Geo-localization|视频转鸟瞰图：将无人机视频转换为鸟瞰图以实现基于视频的地理定位|Hao Ju, Shaofei Huang, Si Liu, Zhedong Zheng|<http://arxiv.org/pdf/2411.13610v3>|提出视频转鸟瞰图方法Video2BEV，简化无人机视频跨平台匹配，增强低空遮挡下的定位鲁棒性。|
|🆕 发布|Q-SAM2: Accurate Quantization for Segment Anything Model 2|Q-SAM2：面向Segment Anything模型2的精确量化|Nicola Farronato, Florian Scheidegger, Mattia Rigotti, Cristiano Malossi, Michele Magno, Haotong Qin|<http://arxiv.org/pdf/2506.09782v1>|提出了一种低比特量化方法Q-SAM2，通过线性层校准和量化感知训练显著提升SAM2模型的效率与准确性...|
|🆕 发布|VideoMat: Extracting PBR Materials from Video Diffusion Models|视频材质：从视频扩散模型中提取基于物理的渲染材质|Jacob Munkberg, Zian Wang, Ruofan Liang, Tianchang Shen, Jon Hasselgren|<http://arxiv.org/pdf/2506.09665v1>|提出了一种结合视频扩散模型和物理渲染的方法，从视频和单张图片中生成高质量的三维模型材料。|
|🆕 发布|DGAE: Diffusion-Guided Autoencoder for Efficient Latent Representation Learning|DGAE：扩散引导自动编码器用于高效潜在表征学习|Dongxu Liu, Yuang Peng, Haomiao Tang, Yuwei Chen, Chunrui Han, Zheng Ge, Daxin Jiang, Mingxue Liao|<http://arxiv.org/pdf/2506.09644v1>|提出DGAE方法，通过扩散模型增强解码器表现，实现高效紧凑的潜在表征学习。|
|🆕 发布|Generalized Gaussian Entropy Model for Point Cloud Attribute Compression with Dynamic Likelihood Intervals|点云属性压缩的广义高斯熵模型与动态似然区间|Changhao Peng, Yuqi Ye, Wei Gao|<http://arxiv.org/pdf/2506.09510v1>|提出广义高斯熵模型和动态似然区间调整策略，提升点云属性压缩的率失真性能。|
|📝 更新|MIMO: Controllable Character Video Synthesis with Spatial Decomposed Modeling|MIMO：基于空间分解建模的可控字符视频合成|Yifang Men, Yuan Yao, Miaomiao Cui, Liefeng Bo|<http://arxiv.org/pdf/2409.16160v2>|提出MIMO框架，通过空间分解建模实现可控角色视频合成，扩展至任意角色、新颖动作和真实场景交互。|
|🆕 发布|Marrying Autoregressive Transformer and Diffusion with Multi-Reference Autoregression|将自回归变换器与扩散结合的多参考自回归方法|Dingcheng Zhen, Qian Qiao, Tan Yu, Kangxi Wu, Ziwei Zhang, Siyuan Liu, Shunshun Yin, Ming Tao|<http://arxiv.org/pdf/2506.09482v1>|结合自回归变换器和扩散模型，提出了一种新的图像生成方法，大幅提升了生成图像质量和效率。|
|📝 更新|Dynamic Negative Guidance of Diffusion Models|动态负向引导扩散模型|Felix Koulischer, Johannes Deleu, Gabriel Raya, Thomas Demeester, Luca Ambrogioni|<http://arxiv.org/pdf/2410.14398v3>|提出动态负向引导方法，优化了扩散模型中反向过程的非定常性和状态依赖问题。|
|📝 更新|Plug-and-Play image restoration with Stochastic deNOising REgularization|"使用随机去噪正则化的即插即用图像恢复"|Marien Renaud, Jean Prost, Arthur Leclaire, Nicolas Papadakis|<http://arxiv.org/pdf/2402.01779v3>|提出了一种改进的迭代图像恢复算法SNORE，通过在适当噪声水平的图像上应用去噪器，提高了去模糊和图像...|
|📝 更新|DeepMultiConnectome: Deep Multi-Task Prediction of Structural Connectomes Directly from Diffusion MRI Tractography|深度多连接组：直接从扩散MRI轨迹图进行深度多任务预测结构连接组|Marcus J. Vroemen, Yuqian Chen, Yui Lo, Tengfei Xue, Weidong Cai, Fan Zhang, Josien P. W. Pluim, Lauren J. O'Donnell|<http://arxiv.org/pdf/2505.22685v2>|提出了一种快速预测大脑结构连接图谱的深度学习方法，无需灰质分割，支持多种分割方案。|
|📝 更新|Directing Mamba to Complex Textures: An Efficient Texture-Aware State Space Model for Image Restoration|指导Mamba处理复杂纹理：一种用于图像恢复的高效纹理感知状态空间模型|Long Peng, Xin Di, Zhanfeng Feng, Wenbo Li, Renjing Pei, Yang Wang, Xueyang Fu, Yang Cao .etc.|<http://arxiv.org/pdf/2501.16583v2>|提出了一种纹理感知的图像复原方法TAMambaIR，通过增强纹理意识和优化计算效率，实现了复原质量和...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Prompt-Guided Latent Diffusion with Predictive Class Conditioning for 3D Prostate MRI Generation|基于预测性类别条件引导的潜在扩散模型用于三维前列腺MRI生成|Emerson P. Grabke, Masoom A. Haider, Babak Taati|<http://arxiv.org/pdf/2506.10230v1>|提出了一种高效的双头条件模型CCELLA，结合少量数据和文本提示，显著提升了3D前列腺MRI图像生成...|
|📝 更新|EgoNormia: Benchmarking Physical Social Norm Understanding|自我规范：物理社会规范理解基准测试|MohammadHossein Rezaei, Yicheng Fu, Phil Cuvin, Caleb Ziems, Yanzhe Zhang, Hao Zhu, Diyi Yang|<http://arxiv.org/pdf/2502.20490v5>|提出EGONORMIA基准，通过 egocentric 视频中的多选问题评估并提升视觉语言模型对社交...|
|📝 更新|Cosmos-Drive-Dreams: Scalable Synthetic Driving Data Generation with World Foundation Models|“Cosmos-Drive-Dreams：基于世界基础模型的可扩展合成驾驶数据生成”|Xuanchi Ren, Yifan Lu, Tianshi Cao, Ruiyuan Gao, Shengyu Huang, Amirmojtaba Sabour, Tianchang Shen, Tobias Pfaff .etc.|<http://arxiv.org/pdf/2506.09042v2>|提出了一种生成高保真合成驾驶数据的方法，有效解决了自动驾驶系统训练中的长尾分布问题并增强泛化能力。|
|📝 更新|Factorized Video Autoencoders for Efficient Generative Modelling|分解视频自动编码器：用于高效生成建模|Mohammed Suhail, Carlos Esteves, Leonid Sigal, Ameesh Makadia|<http://arxiv.org/pdf/2412.04452v2>|提出了一种将视频数据映射到亚线性增长的四平面分解潜在空间的自动编码器，有效提升了视频生成模型的训练和...|
|🆕 发布|PlayerOne: Egocentric World Simulator|“PlayerOne：主观视角世界模拟器”|Yuanpeng Tu, Hao Luo, Xi Chen, Xiang Bai, Fan Wang, Hengshuang Zhao|<http://arxiv.org/pdf/2506.09995v1>|首次提出PlayerOne，一种基于 coarse-to-fine 管道的 egocentric 世...|
|📝 更新|Spectral Image Tokenizer|光谱图像标记器|Carlos Esteves, Mohammed Suhail, Ameesh Makadia|<http://arxiv.org/pdf/2412.09607v2>|提出用离散小波变换对图像频谱进行编码，优化了自回归图像生成模型的性能和灵活性。|
|🆕 发布|EditInspector: A Benchmark for Evaluation of Text-Guided Image Edits|编辑检查器：用于评估文本引导图像编辑的基准|Ron Yosef, Moran Yanuka, Yonatan Bitton, Dani Lischinski|<http://arxiv.org/pdf/2506.09988v1>|提出EditInspector基准，用于评估文本引导的图像编辑质量，并提出两种新方法提升现有模型性能...|
|🆕 发布|Efficient Part-level 3D Object Generation via Dual Volume Packing|通过双向体积打包实现高效的部件级三维物体生成|Jiaxiang Tang, Ruijie Lu, Zhaoshuo Li, Zekun Hao, Xuan Li, Fangyin Wei, Shuran Song, Gang Zeng .etc.|<http://arxiv.org/pdf/2506.09980v1>|提出了一种端到端框架，通过双体积打包策略实现高质量、可编辑的部件级3D对象生成。|
|🆕 发布|InterActHuman: Multi-Concept Human Animation with Layout-Aligned Audio Conditions|《InterActHuman：基于布局对齐音频条件的多概念人物动画》|Zhenzhi Wang, Jiaqi Yang, Jianwen Jiang, Chao Liang, Gaojie Lin, Zerong Zheng, Ceyuan Yang, Dahua Lin|<http://arxiv.org/pdf/2506.09984v1>|提出了一种多模态条件下的端到端多人动画生成框架，通过区域特定绑定实现了精确的多概念控制。|
|📝 更新|One Pic is All it Takes: Poisoning Visual Document Retrieval Augmented Generation with a Single Image|一张图片足矣：利用单一图像对视觉文档检索增强生成进行中毒攻击|Ezzeldin Shereen, Dan Ristea, Shae McFadden, Burak Hasircioglu, Vasilios Mavroudis, Chris Hicks|<http://arxiv.org/pdf/2504.02132v2>|提出针对视觉文档检索的首次单图攻击方法，通过注入单个对抗图像实现拒绝服务和传播误导信息。|
|📝 更新|Unseen Visual Anomaly Generation|未见视觉异常生成|Han Sun, Yunkang Cao, Hao Dong, Olga Fink|<http://arxiv.org/pdf/2406.01078v4>|提出了一种生成未见异常图像的新框架AnomalyAny，通过利用稳定扩散模型和文本描述生成高质量、多...|
|🆕 发布|ELBO-T2IAlign: A Generic ELBO-Based Method for Calibrating Pixel-level Text-Image Alignment in Diffusion Models|ELBO-T2IAlign：一种基于ELBO的通用像素级文本-图像对齐校准方法在扩散模型中|Qin Zhou, Zhiyang Zhang, Jinglong Wang, Xiaobin Li, Jing Zhang, Qian Yu, Lu Sheng, Dong Xu|<http://arxiv.org/pdf/2506.09740v1>|提出了一种基于ELBO的像素级文本-图像对齐校准方法，有效解决了扩散模型中的对齐误差问题。|
|📝 更新|XMeCap: Meme Caption Generation with Sub-Image Adaptability|XMeCap：具有子图像适应性的梗图标题生成|Yuyan Chen, Songzhou Yan, Zhihong Zhu, Zhixu Li, Yanghua Xiao|<http://arxiv.org/pdf/2407.17152v4>|提出XMeCap框架，结合监督微调和基于新奖励模型的强化学习，有效提升多模态幽默内容如梗图的字幕生成...|
|🆕 发布|CINeMA: Conditional Implicit Neural Multi-Modal Atlas for a Spatio-Temporal Representation of the Perinatal Brain|CINeMA：条件隐式神经多模态图谱，用于围产期大脑的时空表征|Maik Dannecker, Vasiliki Sideri-Lampretsa, Sophie Starck, Angeline Mihailov, Mathieu Milh, Nadine Girard, Guillaume Auzias, Daniel Rueckert|<http://arxiv.org/pdf/2506.09668v1>|[代码](https://github.com/m-dannecker/CINeMA.); 提出CINeMA方法，通过在低数据量环境中快速构建高分辨率的多模态脑图谱，提高脑研究效率与准确性。|
|📝 更新|SmartEraser: Remove Anything from Images using Masked-Region Guidance|智能橡皮擦：使用遮蔽区域引导从图像中移除任意内容|Longtao Jiang, Zhendong Wang, Jianmin Bao, Wengang Zhou, Dongdong Chen, Lei Shi, Dong Chen, Houqiang Li|<http://arxiv.org/pdf/2501.08279v3>|提出Masked-Region Guidance新范式，通过保留并利用遮蔽区域信息提升图像去除效果。|
|📝 更新|SceneEval: Evaluating Semantic Coherence in Text-Conditioned 3D Indoor Scene Synthesis|场景评估：在文本条件下三维室内场景生成中的语义连贯性评价|Hou In Ivan Tam, Hou In Derek Pun, Austin T. Wang, Angel X. Chang, Manolis Savva|<http://arxiv.org/pdf/2503.14756v2>|提出了SceneEval评估框架，全面衡量文本驱动的3D室内场景生成与用户需求的契合度。|
|🆕 发布|Noise Conditional Variational Score Distillation|噪声条件下的变分得分蒸馏|Xinyu Peng, Ziyang Zheng, Yaoming Wang, Han Li, Nuowen Kan, Wenrui Dai, Chenglin Li, Junni Zou .etc.|<http://arxiv.org/pdf/2506.09416v1>|提出了一种新型方法NCVSD，将预训练的扩散模型压缩为生成去噪器，实现高效图像生成与去噪。|
|📝 更新|ByteMorph: Benchmarking Instruction-Guided Image Editing with Non-Rigid Motions|字节变形：基于指令引导的非刚性运动图像编辑基准测试|Di Chang, Mingdeng Cao, Yichun Shi, Bo Liu, Shengqu Cai, Shijie Zhou, Weilin Huang, Gordon Wetzstein .etc.|<http://arxiv.org/pdf/2506.03107v2>|提出了ByteMorph框架，通过大规模数据集和强基线模型，实现了基于指令的非刚性图像编辑。|
|🆕 发布|Synthetic Human Action Video Data Generation with Pose Transfer|姿态迁移的合成人类动作视频数据生成|Vaclav Knapp, Matyas Bohacek|<http://arxiv.org/pdf/2506.09411v1>|提出了一种利用姿态迁移生成合成人类动作视频数据的方法，有效提升了动作识别任务性能并扩展了少量样本数据...|
|📝 更新|SkipVAR: Accelerating Visual Autoregressive Modeling via Adaptive Frequency-Aware Skipping|跳变频率感知自回归建模加速方法：SkipVAR|Jiajun Li, Yue Ma, Xinyu Zhang, Qingyan Wei, Songhua Liu, Linfeng Zhang|<http://arxiv.org/pdf/2506.08908v2>|[代码](https://github.com/fakerone-li/SkipVAR); 提出了一种自适应频率感知的跳步策略，有效减少视觉自回归模型中的计算冗余，实现图像生成的加速。|
|🆕 发布|AlignHuman: Improving Motion and Fidelity via Timestep-Segment Preference Optimization for Audio-Driven Human Animation|《AlignHuman：通过时间步段偏好优化提升音频驱动人体动画的运动和保真度》|Chao Liang, Jianwen Jiang, Wang Liao, Jiaqi Yang, Zerong zheng, Weihong Zeng, Han Liang|<http://arxiv.org/pdf/2506.11144v1>|提出了一种结合偏好优化和分而治之策略的AlignHuman框架，有效平衡了运动自然度和视觉保真度。|
|📝 更新|Enhancing Low-Cost Video Editing with Lightweight Adaptors and Temporal-Aware Inversion|利用轻量级适配器和时间感知逆过程增强低成本视频编辑|Yangfan He, Sida Li, Jianhui Wang, Kun Li, Xinyuan Song, Xinhang Yuan, Keqin Li, Kuan Lu .etc.|<http://arxiv.org/pdf/2501.04606v4>|提出了一种轻量级适配器框架，通过时空一致性和语义一致性模块，有效提升了低成本视频编辑的时序连贯性和图...|
|🆕 发布|Autoregressive Adversarial Post-Training for Real-Time Interactive Video Generation|自回归对抗性后训练用于实时交互式视频生成|Shanchuan Lin, Ceyuan Yang, Hao He, Jianwen Jiang, Yuxi Ren, Xin Xia, Yang Zhao, Xuefeng Xiao .etc.|<http://arxiv.org/pdf/2506.09350v1>|提出了一种高效的 autoregressive adversarial post-training ...|
|🆕 发布|CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation|“CheckManual：基于手动操作的家务机器人操控新挑战与基准测试”|Yuxing Long, Jiyao Zhang, Mingjie Pan, Tianshu Wu, Taewhan Kim, Hao Dong|<http://arxiv.org/pdf/2506.09343v1>|提出首个基于使用手册的电器操作基准CheckManual，并设计了辅助大型模型的人类修订数据生成流程...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Geometric Regularity in Deterministic Sampling of Diffusion-based Generative Models|扩散基础生成模型的确定性采样中的几何正则性|Defang Chen, Zhenyu Zhou, Can Wang, Siwei Lyu|<http://arxiv.org/pdf/2506.10177v1>|揭示了扩散生成模型采样轨迹的几何规律，提出动态规划方案优化采样时间，提升图像生成性能。|
|📝 更新|Mitigating Object Hallucination in Large Vision-Language Models via Image-Grounded Guidance|通过图像基础指导减轻大型视觉语言模型中的对象幻觉|Linxi Zhao, Yihe Deng, Weitong Zhang, Quanquan Gu|<http://arxiv.org/pdf/2402.08680v2>|[代码](https://github.com/Linxi-ZHAO/MARINE.); 提出了一种无需训练和API调用的MARINE框架，通过引入图像级指导有效减少大型视觉语言模型中的对象...|
|📝 更新|Federated Unsupervised Visual Representation Learning via Exploiting General Content and Personal Style|通过利用通用内容和个性化风格进行联邦无监督视觉表征学习|Yuewei Yang, Jingwei Sun, Ang Li, Hai Li, Yiran Chen|<http://arxiv.org/pdf/2211.06470v2>|提出FedStyle方法，融合本地风格和内容信息，实现无需标签的联邦视觉表示学习中的泛化与个性化。|
|🆕 发布|Test-Time Adaptation for Generalizable Task Progress Estimation|测试时适应以实现通用任务进度估计|Christos Ziakas, Alessandra Russo|<http://arxiv.org/pdf/2506.10085v1>|提出了一种测试时自适应方法，通过在线适应视觉和时序上下文，提高了任务进度估计模型的泛化能力。|
|🆕 发布|LoRA-Edit: Controllable First-Frame-Guided Video Editing via Mask-Aware LoRA Fine-Tuning|LoRA-Edit：通过遮罩感知的LoRA微调实现可控的首帧引导视频编辑|Chenjian Gao, Lihe Ding, Xin Cai, Zhanpeng Huang, Zibin Wang, Tianfan Xue|<http://arxiv.org/pdf/2506.10082v1>|提出了一种基于掩码的LoRA微调方法，实现了对预训练图像到视频模型的灵活视频编辑，同时保持背景区域不...|
|🆕 发布|Only-Style: Stylistic Consistency in Image Generation without Content Leakage|"Only-Style：无需内容泄露的图像生成中的风格一致性"|Tilemachos Aravanis, Panagiotis Filntisis, Petros Maragos, George Retsinas|<http://arxiv.org/pdf/2506.09916v1>|提出了一种Only-Style方法，有效分离图像内容和风格，减少内容泄露，实现风格一致性。|
|📝 更新|ContentV: Efficient Training of Video Generation Models with Limited Compute|内容V：在计算资源有限的情况下高效训练视频生成模型|Wenfeng Lin, Renjie Chen, Boyuan Liu, Shiyue Yan, Ruoyu Feng, Jiangchuan Wei, Yichen Zhang, Yimeng Zhou .etc.|<http://arxiv.org/pdf/2506.05343v2>|提出ContentV模型，通过高效利用预训练图像模型、多阶段训练和强化学习，实现快速生成高质量视频。|
|🆕 发布|DreamCS: Geometry-Aware Text-to-3D Generation with Unpaired 3D Reward Supervision|DreamCS：具有无配对3D奖励监督的几何感知文本到3D生成|Xiandong Zou, Ruihao Xia, Hongsong Wang, Pan Zhou|<http://arxiv.org/pdf/2506.09814v1>|提出DreamCS框架，通过直接在无配对3D数据上训练奖励模型，生成符合人类偏好的高质量3D模型。|
|🆕 发布|ComfyUI-R1: Exploring Reasoning Models for Workflow Generation|ComfyUI-R1：探索用于工作流生成的推理模型|Zhenran Xu, Yiyu Wang, Xue Yang, Longyue Wang, Weihua Luo, Kaifu Zhang, Baotian Hu, Min Zhang|<http://arxiv.org/pdf/2506.09790v1>|提出ComfyUI-R1模型，通过长链推理和强化学习自动生成有效工作流，大幅提升格式有效性和创作流程...|
|🆕 发布|LLM-to-Phy3D: Physically Conform Online 3D Object Generation with LLMs|LLM至物理3D：使用LLM实现物理一致性的在线三维物体生成|Melvin Wong, Yueming Lyu, Thiago Rios, Stefan Menzel, Yew-Soon Ong|<http://arxiv.org/pdf/2506.11148v1>|提出LLM-to-Phy3D方法，通过在线黑盒精炼循环使3D对象生成符合物理规律。|
|🆕 发布|AngleRoCL: Angle-Robust Concept Learning for Physically View-Invariant T2I Adversarial Patches|角度稳健概念学习：用于物理视角不变的目标到图像对抗补丁|Wenjun Ji, Yuxiang Fu, Luyang Ying, Deng-Ping Fan, Yuyi Wang, Ming-Ming Cheng, Ivor Tsang, Qing Guo|<http://arxiv.org/pdf/2506.09538v1>|提出AngleRoCL方法，通过学习通用概念增强T2I对抗贴图的视角鲁棒性。|
|🆕 发布|A High-Quality Dataset and Reliable Evaluation for Interleaved Image-Text Generation|高质量数据集与可靠评估的交错图像-文本生成|Yukang Feng, Jianwen Sun, Chuanhao Li, Zizhen Li, Jiaxin Ai, Fanrui Zhang, Yifan Chang, Sizhuo Zhou .etc.|<http://arxiv.org/pdf/2506.09427v1>|构建了大规模多模态InterSyn数据集及SynJudge评估工具，提升大型多模态模型生成紧密交织的...|
|📝 更新|Rethinking Cross-Modal Interaction in Multimodal Diffusion Transformers|重新思考多模态扩散变换器中的跨模态交互|Zhengyao Lv, Tianlin Pan, Chenyang Si, Zhaoxi Chen, Wangmeng Zuo, Ziwei Liu, Kwan-Yee K. Wong|<http://arxiv.org/pdf/2506.07986v2>|[代码](https://github.com/Vchitect/TACA); 提出Temperature-Adjusted Cross-modal Attention方法，有效平...|
|🆕 发布|SAGE: Exploring the Boundaries of Unsafe Concept Domain with Semantic-Augment Erasing|SAGE：使用语义增强擦除探索不安全概念域的边界|Hongguang Zhu, Yunchao Wei, Mengyu Wang, Siyu Jiao, Yan Fang, Jiannan Huang, Yao Zhao|<http://arxiv.org/pdf/2506.09363v1>|[代码](https://github.com/KevinLight831/SAGE.); 提出了一种通过语义增强擦除技术优化扩散模型，有效避免生成敏感内容并保持无关概念完整性的方法。|
|📝 更新|RecipeGen: A Step-Aligned Multimodal Benchmark for Real-World Recipe Generation|《RecipeGen：一个面向现实世界食谱生成的步进对齐多模态基准》|Ruoxuan Zhang, Jidong Gao, Bin Wen, Hongxia Xie, Chenming Zhang, Hong-Han Shuai, Wen-Huang Cheng|<http://arxiv.org/pdf/2506.06733v3>|提出首个大规模真实世界食谱生成基准RecipeGen，涵盖文本到图像、图像到视频和文本到视频生成，并...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SemanticSplat: Feed-Forward 3D Scene Understanding with Language-Aware Gaussian Fields|语义喷溅：具有语言感知高斯场的前馈三维场景理解|Qijing Li, Jingxiang Sun, Liang An, Zhaoqi Su, Hongwen Zhang, Yebin Liu|<http://arxiv.org/pdf/2506.09565v2>|提出了SemanticSplat方法，通过融合3D高斯场与语义属性，实现了从稀疏视角图像中进行全面的...|
|🆕 发布|Sampling Theory for Super-Resolution with Implicit Neural Representations|用于隐式神经表示的超分辨率采样理论|Mahrokh Najaf, Gregory Ongie|<http://arxiv.org/pdf/2506.09949v1>|研究了隐式神经表示在超分辨率中的采样需求，提出了确保图像精确恢复的傅里叶样本数量。|
|🆕 发布|The Less You Depend, The More You Learn: Synthesizing Novel Views from Sparse, Unposed Images without Any 3D Knowledge|《依赖越少，学习越多：无需任何3D知识，从稀疏、无定位图像中合成新颖视角》|Haoru Wang, Kai Ye, Yangyan Li, Wenzheng Chen, Baoquan Chen|<http://arxiv.org/pdf/2506.09885v1>|[代码](https://pku-vcl-geometry.github.io/Less3Depend); 提出了一种最小化3D知识依赖的通用新型视图合成框架，直接从稀疏二维图像中学习隐式3D感知。|
|📝 更新|Using Shapley interactions to understand how models use structure|利用Shapley交互来理解模型如何使用结构|Divyansh Singhvi, Diganta Misra, Andrej Erkelens, Raghav Jain, Isabel Papadimitriou, Naomi Saphra|<http://arxiv.org/pdf/2403.13106v2>|利用Shapley交互指数揭示语言模型如何内部构建输入结构。|
|🆕 发布|AtmosMJ: Revisiting Gating Mechanism for AI Weather Forecasting Beyond the Year Scale|大气MJ：重新审视AI天气预报中的门控机制，超越年度尺度|Minjong Cheon|<http://arxiv.org/pdf/2506.09733v1>|提出了一种新型Gated Residual Fusion机制，实现了标准网格上稳定的长达500天的天...|
|🆕 发布|Self-Supervised Multi-Part Articulated Objects Modeling via Deformable Gaussian Splatting and Progressive Primitive Segmentation|通过可变形高斯散布和渐进基元分割进行自监督多部分关节对象建模|Haowen Wang, Xiaoping Yuan, Zhao Jin, Zhen Zhao, Zhengping Che, Yousong Xue, Jin Tian, Yakun Huang .etc.|<http://arxiv.org/pdf/2506.09663v1>|提出了一种无需人工标注的统一框架DeGSS，通过可变形3D高斯场建模多部件活动对象的几何、外观和运动...|
|📝 更新|Fourier-Modulated Implicit Neural Representation for Multispectral Satellite Image Compression|傅里叶调制隐式神经表示用于多光谱卫星图像压缩|Woojin Cho, Steve Andreas Immanuel, Junhyuk Heo, Darongsae Kwon|<http://arxiv.org/pdf/2506.01234v2>|提出了一种统一框架ImpliSat，利用隐式神经表示和傅里叶调制算法高效压缩和重建多光谱卫星图像。|
|🆕 发布|Gaussian Herding across Pens: An Optimal Transport Perspective on Global Gaussian Reduction for 3DGS|跨围栏的高斯放牧：从最优传输视角看全局高斯缩减在三维形状分析中的应用|Tao Wang, Mengyu Li, Geduo Zeng, Cheng Meng, Qiong Zhang|<http://arxiv.org/pdf/2506.09534v1>|提出全局最优传输视角以减少3D高斯分布数量，保持渲染质量同时提升效率。|
|🆕 发布|HAIF-GS: Hierarchical and Induced Flow-Guided Gaussian Splatting for Dynamic Scene|HAIF-GS：分层与诱导流引导的高斯散点绘制方法用于动态场景|Jianing Chen, Zehao Li, Yujun Cai, Hao Jiang, Chengxuan Qian, Juyuan Kang, Shuqin Gao, Honglong Zhao .etc.|<http://arxiv.org/pdf/2506.09518v1>|提出HAIF-GS框架，通过稀疏锚点驱动建模动态场景，提升三维重建的连贯性和效率。|
|📝 更新|NeRF-CA: Dynamic Reconstruction of X-ray Coronary Angiography with Extremely Sparse-views|极稀疏视角下X射线冠状动脉造影的动态重建：NeRF-CA方法|Kirsten W. H. Maas, Danny Ruijters, Anna Vilanova, Nicola Pezzotti|<http://arxiv.org/pdf/2408.16355v2>|[代码](https://github.com/kirstenmaas/NeRF-CA.); NeRF-CA通过分离动态冠状动脉与静态背景，实现了仅用少量X光造影图像进行高质量4D重建。|
|📝 更新|Sim-to-Real Causal Transfer: A Metric Learning Approach to Causally-Aware Interaction Representations|从仿真到现实：一种基于因果感知交互表示的度量学习方法的因果迁移|Ahmad Rahimi, Po-Chien Luan, Yuejiang Liu, Frano Rajič, Alexandre Alahi|<http://arxiv.org/pdf/2312.04540v2>|[代码](https://github.com/vita-epfl/CausalSim2Real.); 提出了一种通过因果注释正则化潜在表征的度量学习法，增强了多智能体交互的因果感知和泛化能力。|
|🆕 发布|UniForward: Unified 3D Scene and Semantic Field Reconstruction via Feed-Forward Gaussian Splatting from Only Sparse-View Images|统一三维场景与语义场重构：仅通过稀疏视图图像的前馈高斯散点绘制|Qijian Tian, Xin Tan, Jingyu Gong, Yuan Xie, Lizhuang Ma|<http://arxiv.org/pdf/2506.09378v1>|提出了一种统一3D场景与语义场重建的模型，通过前向传播预测各向异性语义特征的高斯分布，实现仅凭稀疏视...|
|📝 更新|Towards a Sampling Theory for Implicit Neural Representations|迈向隐式神经表示的采样理论|Mahrokh Najaf, Gregory Ongie|<http://arxiv.org/pdf/2405.18410v2>|研究了隐式神经表示在图像重建中的采样需求，提出了一种基于广义权重衰减正则化的方法来精确恢复图像。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vector Representations of Vessel Trees|血管树的向量表示|James Batten, Michiel Schaap, Matthew Sinclair, Ying Bai, Ben Glocker|<http://arxiv.org/pdf/2506.11163v1>|提出了一种基于Transformer的框架，用于学习血管网络的向量表示，实现了高效的三维结构建模。|
|📝 更新|Learning Geometric Invariant Features for Classification of Vector Polygons with Graph Message-passing Neural Network|学习图消息传递神经网络用于矢量多边形分类的几何不变特征|Zexian Huang, Kourosh Khoshelham, Martin Tomko|<http://arxiv.org/pdf/2407.04334v2>|提出图消息传递框架PolyMP及其变体PolyMP-DSC，学习矢量多边形的几何不变特征，提升形状分...|
|🆕 发布|DGS-LRM: Real-Time Deformable 3D Gaussian Reconstruction From Monocular Videos|单目视频实时可变形三维高斯重建：DGS-LRM|Chieh Hubert Lin, Zhaoyang Lv, Songyin Wu, Zhen Xu, Thu Nguyen-Phuoc, Hung-Yu Tseng, Julian Straub, Numair Khan .etc.|<http://arxiv.org/pdf/2506.09997v1>|提出了DGS-LRM模型，实现了从单目视频实时重建动态三维场景。|
|🆕 发布|UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting|统一三维点云模型的预训练：跨模态高斯绘制法|Ziyi Wang, Yanran Zhang, Jie Zhou, Jiwen Lu|<http://arxiv.org/pdf/2506.09952v1>|[代码](https://github.com/wangzy22/UniPre3D.); 提出首个统一预训练方法UniPre3D，适用于任意规模点云和3D模型架构，通过预测高斯基元和引入图像...|
|🆕 发布|MetricHMR: Metric Human Mesh Recovery from Monocular Images|单目图像的度量化人体网格恢复|He Zhang, Chentao Song, Hongwen Zhang, Tao Yu|<http://arxiv.org/pdf/2506.09919v1>|提出了一种从单目图像中恢复精确全局平移的度量人体网格的方法，有效解决了尺度与深度模糊问题。|
|🆕 发布|DynaSplat: Dynamic-Static Gaussian Splatting with Hierarchical Motion Decomposition for Scene Reconstruction|动态-静态高斯散点绘制与层次运动分解相结合的场景重建方法|Junli Deng, Ping Shi, Qipei Li, Jinyang Guo|<http://arxiv.org/pdf/2506.09836v1>|提出DynaSplat方法，通过动静分离和层级运动建模，实现了动态场景的高精度重建。|


## 时序视觉分析 (Temporal Visual Analysis)


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Evaluating BiLSTM and CNN+GRU Approaches for Human Activity Recognition Using WiFi CSI Data|评估基于BiLSTM和CNN+GRU方法在WiFi CSI数据下的人体活动识别效果|Almustapha A. Wakili, Babajide J. Asaju, Woosub Jung|<http://arxiv.org/pdf/2506.11165v1>|比较BiLSTM与CNN+GRU在WiFi CSI数据上的人体活动识别效果，发现CNN+GRU在提取...|
|🆕 发布|SLRNet: A Real-Time LSTM-Based Sign Language Recognition System|SLRNet：一种基于实时LSTM的的手语识别系统|Sharvari Kamble|<http://arxiv.org/pdf/2506.11154v1>|提出了一种基于MediaPipe Holistic和LSTM的实时美式手语识别系统，实现了86.7%...|
|📝 更新|Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025|《Ego4D长期动作预测挑战2025技术报告》|Qiaohui Chu, Haoyu Zhang, Yisen Feng, Meng Liu, Weili Guan, Yaowei Wang, Liqiang Nie|<http://arxiv.org/pdf/2506.02550v2>|[代码](https://github.com/CorrineQiu/Ego4D-LTA-Challenge-2025.); 提出三阶段框架预测长期行为，结合视觉编码器、Transformer和语言模型，实现动作预测新突破。|
|📝 更新|Temporal-Guided Spiking Neural Networks for Event-Based Human Action Recognition|基于时间引导的尖峰神经网络用于事件驱动的人体动作识别|Siyuan Yang, Shilin Lu, Shizheng Wang, Meng Hwa Er, Zengwei Zheng, Alex C. Kot|<http://arxiv.org/pdf/2503.17132v3>|提出两种新框架，通过分割动作片段和使用3D组件，增强事件相机下动作识别的长期时序处理能力。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Shortcut-aware Video-QA Benchmark for Physical Understanding via Minimal Video Pairs|一个用于通过最小视频对进行物理理解的视频问答快捷方式感知基准|Benno Krojer, Mojtaba Komeili, Candace Ross, Quentin Garrido, Koustuv Sinha, Nicolas Ballas, Mahmoud Assran|<http://arxiv.org/pdf/2506.09987v1>|提出了一个针对视频语言模型物理理解能力的 shortcut-aware 视频问答基准，通过最小变化对...|
|🆕 发布|V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning|V-JEPA 2：自监督视频模型实现理解、预测与规划|Mido Assran, Adrien Bardes, David Fan, Quentin Garrido, Russell Howes, Mojtaba, Komeili, Matthew Muckley .etc.|<http://arxiv.org/pdf/2506.09985v1>|探索自监督学习结合大规模视频数据与少量交互数据，实现物理世界的理解、预测与规划能力。|
|🆕 发布|IntPhys 2: Benchmarking Intuitive Physics Understanding In Complex Synthetic Environments|《IntPhys 2：在复杂合成环境中对直观物理理解进行基准测试》|Florian Bordes, Quentin Garrido, Justine T Kao, Adina Williams, Michael Rabbat, Emmanuel Dupoux|<http://arxiv.org/pdf/2506.09849v1>|提出IntPhys 2视频基准，评估深度学习模型对直观物理理解的能力，揭示与人类认知的差距。|
|🆕 发布|TOGA: Temporally Grounded Open-Ended Video QA with Weak Supervision|TOGA：基于时间定位的弱监督开放式视频问答|Ayush Gupta, Anirban Roy, Rama Chellappa, Nathaniel D. Bastian, Alvaro Velasquez, Susmit Jha|<http://arxiv.org/pdf/2506.09445v1>|提出TOGA模型，实现了无时间标注视频问答中的时间定位，达到两项任务最佳性能。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Fluoroscopic Shape and Pose Tracking of Catheters with Custom Radiopaque Markers|使用定制放射性标记物的导管形状与姿态在荧光透视下的跟踪|Jared Lawson, Rohan Chitale, Nabil Simaan|<http://arxiv.org/pdf/2506.09934v1>|提出了一种利用定制放射性标记物的微导管形状与姿态跟踪方法，实现了高精度导航。|
|📝 更新|SMMT: Siamese Motion Mamba with Self-attention for Thermal Infrared Target Tracking|《SMMT：具有自注意力机制的赛宗运动蟒蛇用于热红外目标跟踪》|Shang Zhang, Huanbin Zhang, Dali Feng, Yujie Cui, Ruoyan Xiong, Cen He|<http://arxiv.org/pdf/2505.04088v3>|提出了一种融合双向状态空间模型和自注意力机制的Siamese Motion Mamba Tracke...|
|🆕 发布|Optimizing Cooperative Multi-Object Tracking using Graph Signal Processing|利用图信号处理优化合作多目标跟踪|Maria Damanaki, Nikos Piperigkos, Alexandros Gkillas, Aris S. Lalos|<http://arxiv.org/pdf/2506.09469v1>|提出了一种利用图信号处理优化多车辆合作的三维目标跟踪方法，提升了定位和跟踪准确性。|
|📝 更新|Zero-Shot Temporal Interaction Localization for Egocentric Videos|零样本时间交互定位用于第一视角视频|Erhang Zhang, Junyi Ma, Yin-Dong Zheng, Yixuan Zhou, Hesheng Wang|<http://arxiv.org/pdf/2506.03662v2>|[代码](https://github.com/IRMVLab/EgoLoc.); 提出了一种零样本时序交互定位方法EgoLoc，通过自适应采样和视觉动态反馈，有效定位第一视角视频中的...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MMME: A Spontaneous Multi-Modal Micro-Expression Dataset Enabling Visual-Physiological Fusion|MMME：一种自发的多模态微表情数据集，实现视觉-生理融合|Chuang Ma, Yu Pei, Jianhang Zhang, Shaokai Zhao, Bowen Ji, Liang Xie, Ye Yan, Erwei Yin|<http://arxiv.org/pdf/2506.09834v2>|首次构建了多模态微表情数据集MMME，融合视觉与生理信号，显著提升微表情识别与检测性能。|


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Structural-Spectral Graph Convolution with Evidential Edge Learning for Hyperspectral Image Clustering|结构-谱图卷积与证据边学习用于高光谱图像聚类|Jianhan Qi, Yuheng Jia, Hui Liu, Junhui Hou|<http://arxiv.org/pdf/2506.09920v1>|[代码](https://github.com/jhqi/SSGCO-EGAEL.); 提出结构-光谱图卷积和证据引导的边学习策略，提升超像素级光谱图像聚类精度。|
|🆕 发布|Non-Contact Health Monitoring During Daily Personal Care Routines|日常个人护理过程中的非接触式健康监测|Xulin Ma, Jiankai Tang, Zhang Jiang, Songqin Cheng, Yuanchun Shi, Dong LI, Xin Liu, Daniel McDuff .etc.|<http://arxiv.org/pdf/2506.09718v1>|[代码](https://github.com/McJackTang/FusionVitals.); 提出首个长时高原日常保健rPPG数据集，结合RGB与IR视频输入提升生理信号监测准确性和鲁棒性。|
|🆕 发布|ECAM: A Contrastive Learning Approach to Avoid Environmental Collision in Trajectory Forecasting|ECAM：一种用于避免轨迹预测中环境碰撞的对比学习方法|Giacomo Rosin, Muhammad Rameez Ur Rahman, Sebastiano Vascon|<http://arxiv.org/pdf/2506.09626v1>|[代码](https://github.com/CVML-CFU/ECAM.); 提出ECAM模块，通过对比学习增强轨迹预测模型的碰撞避免能力，显著降低碰撞率。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VIBE: Can a VLM Read the Room?|VIBE：视觉语言模型能读懂房间吗？|Tania Chakraborty, Eylon Caplan, Dan Goldwasser|<http://arxiv.org/pdf/2506.11162v1>|分类|
|🆕 发布|Vectorized Region Based Brush Strokes for Artistic Rendering|基于向量的区域笔触渲染的艺术化绘制|Jeripothula Prudviraj, Vikram Jamwal|<http://arxiv.org/pdf/2506.09969v1>|提出了一种基于区域的图像到绘画方法，通过指导笔画和计算参数，实现了高保真度和优质笔触的艺术渲染。|
|📝 更新|HoliSafe: Holistic Safety Benchmarking and Modeling with Safety Meta Token for Vision-Language Model|《HoliSafe：基于安全元标记的视觉-语言模型的全局安全性基准测试与建模》|Youngwan Lee, Kangsan Kim, Kwanyong Park, Ilcahe Jung, Soojin Jang, Seanie Lee, Yong-Ju Lee, Sung Ju Hwang|<http://arxiv.org/pdf/2506.04704v2>|提出全面安全数据集HoliSafe及模型SafeLLaVA，增强视觉语言模型的安全性并提升解释性。|
|🆕 发布|Using Sign Language Production as Data Augmentation to enhance Sign Language Translation|使用手语生成作为数据增强来提升手语翻译性能|Harry Walsh, Maksym Ivashechkin, Richard Bowden|<http://arxiv.org/pdf/2506.09643v1>|利用_sign语言生成技术增强数据集，有效提升_sign语言翻译模型性能。|
|🆕 发布|On the development of an AI performance and behavioural measures for teaching and classroom management|关于开发用于教学和课堂管理的人工智能性能与行为度量方法|Andreea I. Niculescu, Jochen Ehnen, Chen Yi, Du Jiawei, Tay Chiat Pin, Joey Tianyi Zhou, Vigneshwaran Subbaraju, Teh Kah Kuan .etc.|<http://arxiv.org/pdf/2506.11143v1>|开发了一种基于AI的课堂动态分析工具，通过多模态传感器数据支持教师发展和教学策略改进。|
|📝 更新|Toward Reliable AR-Guided Surgical Navigation: Interactive Deformation Modeling with Data-Driven Biomechanics and Prompts|面向可靠的AR辅助手术导航：基于数据驱动的生物力学和提示的交互式形变建模|Zheng Han, Jun Zhou, Jialun Pei, Jing Qin, Yingfang Fan, Qi Dou|<http://arxiv.org/pdf/2506.08048v2>|提出了一种结合数据驱动生物力学和交互式校正提示的算法，提高了术中增强现实导航的准确性和效率。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EfficientVLA: Training-Free Acceleration and Compression for Vision-Language-Action Models|高效VLA：无需训练的视觉-语言-动作模型加速与压缩|Yantai Yang, Yuhao Wang, Zichen Wen, Luo Zhongwei, Chang Zou, Zhipeng Zhang, Chuan Wen, Linfeng Zhang|<http://arxiv.org/pdf/2506.10100v1>|EfficientVLA通过消除计算和内存冗余，实现了无需训练的视觉语言动作模型加速和压缩。|
|🆕 发布|Digitization of Document and Information Extraction using OCR|文档数字化与光学字符识别信息提取|Rasha Sinha, Rekha B S|<http://arxiv.org/pdf/2506.11156v1>|结合OCR技术和大型语言模型提取文档信息，提高了准确性和理解能力。|
|🆕 发布|MPFNet: A Multi-Prior Fusion Network with a Progressive Training Strategy for Micro-Expression Recognition|MPFNet：一种具有渐进式训练策略的多先验融合网络用于微表情识别|Chuang Ma, Shaokai Zhao, Dongdong Zhou, Yu Pei, Zhiguo Luo, Liang Xie, Ye Yan, Erwei Yin|<http://arxiv.org/pdf/2506.09735v1>|提出了一种多先验融合网络MPFNet，结合渐进式训练策略，有效提升了微表情识别的准确性。|
|🆕 发布|Reasoning Models Are More Easily Gaslighted Than You Think|推理模型比你想象的更容易被操纵|Bin Zhu, Hailong Yin, Jingjing Chen, Yu-Gang Jiang|<http://arxiv.org/pdf/2506.09677v1>|发现顶级推理模型在对抗性反馈下准确性大幅下降，并提出GaslightingBench-R评估模型抗误...|
|📝 更新|LLM2TEA: Agentic AI Designer Finds Innovative Objects with Generative Evolutionary Multitasking|LLM2TEA：代理型AI设计师通过生成演化多任务发现创新物体|Melvin Wong, Jiao Liu, Thiago Rios, Stefan Menzel, Yew Soon Ong|<http://arxiv.org/pdf/2406.14917v2>|提出LLM2TEA，一种结合大型语言模型和生成进化多任务框架的AI设计方法，实现跨领域创新物体的高效...|
|📝 更新|AugGen: Synthetic Augmentation Can Improve Discriminative Models|AugGen：合成增强可以提高判别性模型性能|Parsa Rahimi, Damien Teney, Sebastien Marcel|<http://arxiv.org/pdf/2503.11544v2>|[代码](https://parsa-ra.github.io/auggen); 提出了一种自包含的合成增强技术AugGen，通过在目标数据集上训练生成模型，有效提升了人脸识别性能并...|
|🆕 发布|A Cytology Dataset for Early Detection of Oral Squamous Cell Carcinoma|口腔鳞状细胞癌早期检测的细胞学数据集|Garima Jain, Sanghamitra Pati, Mona Duggal, Amit Sethi, Abhijeet Patil, Gururaj Malekar, Nilesh Kowe, Jitender Kumar .etc.|<http://arxiv.org/pdf/2506.09661v1>|介绍了首个大型多中心口腔细胞学数据集，助力提升口腔鳞状细胞癌早期诊断的自动化水平。|
|🆕 发布|ReID5o: Achieving Omni Multi-modal Person Re-identification in a Single Model|ReID5o：在单一模型中实现全模态行人重识别|Jialong Zuo, Yongtai Deng, Mengdan Tan, Rui Jin, Dongyue Wu, Nong Sang, Liang Pan, Changxin Gao|<http://arxiv.org/pdf/2506.09385v1>|[代码](https://github.com/Zplusdragon/ReID5o_ORBench.); 提出Omni Multi-modal Person Re-identification问题并构建首个...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Inverting Black-Box Face Recognition Systems via Zero-Order Optimization in Eigenface Space|通过在特征脸空间中应用零阶优化方法逆向黑盒人脸识别系统|Anton Razzhigaev, Matvey Mikhalchuk, Klim Kireev, Igor Udovichenko, Andrey Kuznetsov, Aleksandr Petiushko|<http://arxiv.org/pdf/2506.09777v1>|提出了一种仅利用相似度分数在特征脸空间进行零阶优化的方法，成功重构彩色面部图像。|
|🆕 发布|FedVLMBench: Benchmarking Federated Fine-Tuning of Vision-Language Models|FedVLMBench：视觉语言模型联邦微调基准测试|Weiying Zheng, Ziyue Lin, Pengxin Guo, Yuyin Zhou, Feifei Wang, Liangqiong Qu|<http://arxiv.org/pdf/2506.09638v1>|提出了FedVLMBench，首个针对视觉语言模型联邦微调的全面基准，揭示了关键配置和跨模态优化规律...|
|🆕 发布|Enhancing Human-Robot Collaboration: A Sim2Real Domain Adaptation Algorithm for Point Cloud Segmentation in Industrial Environments|增强人机协作：面向工业环境中点云分割的仿真至现实域自适应算法|Fatemeh Mohammadi Amin, Darwin G. Caldwell, Hans Wernher van de Venn|<http://arxiv.org/pdf/2506.09552v1>|提出了一种结合动态图卷积和卷积神经网络的Sim2Real域自适应算法，显著提升了工业环境中点云语义分...|
|🆕 发布|LPO: Towards Accurate GUI Agent Interaction via Location Preference Optimization|LPO：通过位置偏好优化实现精确的GUI智能体交互|Jiaqi Tang, Yu Xia, Yi-Feng Wu, Yuwei Hu, Yuhui Chen, Qing-Guo Chen, Xiaogang Xu, Xiangyu Wu .etc.|<http://arxiv.org/pdf/2506.09373v1>|[代码](https://github.com/AIDC-AI/LPO.); 提出位置偏好优化方法LPO，通过利用位置信息优化交互偏好，提高自主代理在GUI中的交互精度。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Balanced Hyperbolic Embeddings Are Natural Out-of-Distribution Detectors|“平衡的双曲嵌入是自然的非分布检测器”|Tejaswi Kasarla, Max van Spengler, Pascal Mettes|<http://arxiv.org/pdf/2506.10146v1>|提出平衡双曲学习算法，通过优化双曲空间嵌入提高异常样本检测准确性。|
|🆕 发布|Learning to Align: Addressing Character Frequency Distribution Shifts in Handwritten Text Recognition|学习对齐：解决手写文本识别中的字符频率分布偏移问题|Panagiotis Kaliosis, John Pavlopoulos|<http://arxiv.org/pdf/2506.09846v1>|[代码](https://github.com/pkaliosis/fada.); 提出了一种新损失函数，通过 Wasserstein 距离调整字符频率分布，提高了手写文本识别的准确性...|
|🆕 发布|Class Similarity-Based Multimodal Classification under Heterogeneous Category Sets|基于类别相似性的异质类别集下的多模态分类|Yangrui Zhu, Junhua Bao, Yipan Wei, Yapeng Li, Bo Du|<http://arxiv.org/pdf/2506.09745v1>|提出了一种处理多模态数据异质类别集分类问题的方法，通过类相似性实现跨模态信息融合。|
|📝 更新|ProbDiffFlow: An Efficient Learning-Free Framework for Probabilistic Single-Image Optical Flow Estimation|ProbDiffFlow：一种高效的无学习概率单图像光流估计框架|Mo Zhou, Jianwei Wang, Xuanmeng Zhang, Dylan Campbell, Kai Wang, Long Yuan, Wenjie Zhang, Xuemin Lin|<http://arxiv.org/pdf/2503.12348v2>|提出了一种无需训练的框架ProbDiffFlow，通过合成未来帧估计单张图像的光流概率分布，提高了准...|
|🆕 发布|Harmonizing and Merging Source Models for CLIP-based Domain Generalization|《协调和融合源模型以实现基于CLIP的域泛化》|Yuhe Ding, Jian Liang, Bo Jiang, Zi Wang, Aihua Zheng, Bin Luo|<http://arxiv.org/pdf/2506.09446v1>|提出了一种模型融合框架HAM，通过优化样本和融合策略，提升CLIP模型在不同领域间的泛化能力。|
|🆕 发布|Evidential Deep Learning with Spectral-Spatial Uncertainty Disentanglement for Open-Set Hyperspectral Domain Generalization|开集高光谱域泛化的谱-空不确定性解耦的证据深度学习|Amirreza Khoshbakht, Erchan Aptoula|<http://arxiv.org/pdf/2506.09460v1>|[代码](https://github.com/amir-khb/SSUDOSDG); 提出了一种面向开放集域泛化的新框架，通过频域特征提取和不确定性量化，有效应对未知类别和域偏移问题。|
|🆕 发布|Improving Out-of-Distribution Detection via Dynamic Covariance Calibration|通过动态协方差校准提高分布外检测性能|Kaiyu Guo, Zijian Wang, Brian C. Lovell, Mahsa Baktashmotlagh|<http://arxiv.org/pdf/2506.09399v1>|[代码](https://github.com/workerbcd/ooddcc.); 提出动态调整先验协方差矩阵的方法，有效改善异常分布样本对OOD检测的影响。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MVTamperBench: Evaluating Robustness of Vision-Language Models|MVTamperBench：评估视觉-语言模型的鲁棒性|Amit Agarwal, Srikant Panda, Angeline Charles, Bhargava Kumar, Hitesh Patel, Priyaranjan Pattnayak, Taki Hasan Rafi, Tejaswini Kumar .etc.|<http://arxiv.org/pdf/2412.19794v5>|[代码](https://amitbcp.github.io/MVTamperBench); 提出MVTamperBench基准，系统评估视觉语言模型对视频篡改的鲁棒性。|
|📝 更新|Diffusion-based Adversarial Purification from the Perspective of the Frequency Domain|基于频率域视角的扩散式对抗性净化|Gaozheng Pei, Ke Ma, Yingfei Sun, Qianqian Xu, Qingming Huang|<http://arxiv.org/pdf/2505.01267v3>|提出了一种基于频率域的扩散式对抗性噪声消除方法，有效去除扰动同时保留图像原内容结构。|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Holistic Uncertainty Estimation For Open-Set Recognition|开集识别中的整体不确定性估计|Leonid Erlygin, Alexey Zaytsev|<http://arxiv.org/pdf/2408.14229v2>|提出了一种全面的不确定性估计方法HolUE，有效应对开放集识别中的识别错误问题。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Synthetic Geology -- Structural Geology Meets Deep Learning|合成地质学 -- 结构地质学遇见深度学习|Simon Ghyselincks, Valeriia Okhmak, Stefano Zampini, George Turkiyyah, David Keyes, Eldad Haber|<http://arxiv.org/pdf/2506.11164v1>|利用生成式人工智能和神经网络，论文提出了一种创建地下三维地质结构图像的方法，通过模拟地质活动生成无限...|
|🆕 发布|Omni-DPO: A Dual-Perspective Paradigm for Dynamic Preference Learning of LLMs|全方位动态偏好学习双视角范式：面向大型语言模型|Shangpin Peng, Weinong Wang, Zhuotao Tian, Senqiao Yang, Xing Wu, Haotian Xu, Chengquan Zhang, Takashi Isobe .etc.|<http://arxiv.org/pdf/2506.10054v1>|[代码](https://github.com/pspdada/Omni-DPO.); 提出Omni-DPO方法，通过考虑数据质量和模型学习动态，优化了偏好学习，提升了模型性能。|
|📝 更新|Geometric deep learning for local growth prediction on abdominal aortic aneurysm surfaces|基于几何深度学习的腹主动脉瘤表面局部生长预测|Dieuwertje Alblas, Patryk Rygiel, Julian Suk, Kaj O. Kappe, Marieke Hofman, Christoph Brune, Kak Khee Yeung, Jelmer M. Wolterink|<http://arxiv.org/pdf/2506.08729v2>|提出了一种基于几何深度学习的方法，直接在血管表面预测腹主动脉瘤的生长，提高了个性化监测策略的准确性。|
|📝 更新|Gaussian2Scene: 3D Scene Representation Learning via Self-supervised Learning with 3D Gaussian Splatting|高斯到场景：通过三维高斯散点自监督学习进行三维场景表征学习|Keyi Liu, Weidong Yang, Ben Fei, Ying He|<http://arxiv.org/pdf/2506.08777v2>|提出了一种高效的3D场景自监督学习方法Gaussian2Scene，通过3D高斯散点技术提升几何理解...|
|📝 更新|Beyond Calibration: Physically Informed Learning for Raw-to-Raw Mapping|超越校准：基于物理信息的原始到原始映射学习|Peter Grönquist, Stepan Tulyakov, Dengxin Dai|<http://arxiv.org/pdf/2506.08650v2>|提出了一种物理信息驱动的轻量级模型，有效解决了多相机间色彩一致性难题。|
|🆕 发布|ScaleLSD: Scalable Deep Line Segment Detection Streamlined|scalable deep line segment detection streamlined《可扩展深度线段检测的优化》|Zeran Ke, Bin Tan, Xianwei Zheng, Yujun Shen, Tianfu Wu, Nan Xue|<http://arxiv.org/pdf/2506.09369v1>|[代码](https://github.com/ant-research/scalelsd); 提出了一种大规模自监督学习的线段检测模型ScaleLSD，在自然图像中实现了更完整准确的线段几何特征...|
|📝 更新|Enhancing Facial Classification and Recognition using 3D Facial Models and Deep Learning|利用三维面部模型和深度学习增强面部分类与识别|Houting Li, Mengxuan Dong, Lok Ming Lui|<http://arxiv.org/pdf/2312.05219v2>|整合3D面部模型与深度学习，显著提升面部分类与识别的准确性。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dataset of News Articles with Provenance Metadata for Media Relevance Assessment|新闻文章及其来源元数据集用于媒体相关性评估|Tomas Peterka, Matyas Bohacek|<http://arxiv.org/pdf/2506.09847v1>|提出新闻媒体来源数据集，包含带有来源标记的图像，定义了两个任务以评估媒体相关性。|
|📝 更新|ClimateViz: A Benchmark for Statistical Reasoning and Fact Verification on Scientific Charts|气候可视化：科学图表上的统计推理与事实验证基准|Ruiran Su, Jiasheng Si, Zhijiang Guo, Janet B. Pierrehumbert|<http://arxiv.org/pdf/2506.08700v2>|提出了首个大规模科学图表事实核查基准ClimateViz，结合知识图解释提升了模型性能。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Chain-of-Action: Trajectory Autoregressive Modeling for Robotic Manipulation|动作链：机器人操作中的轨迹自回归建模|Wenbo Zhang, Tianrun Hu, Yanyuan Qiao, Hanbo Zhang, Yuchu Qin, Yang Li, Jiajun Liu, Tao Kong .etc.|<http://arxiv.org/pdf/2506.09990v1>|提出了一种基于轨迹自回归模型的机器人操作策略Chain-of-Action，通过逆向推理生成完整动作...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ViCrit: A Verifiable Reinforcement Learning Proxy Task for Visual Perception in VLMs|ViCrit：一种用于大型视觉语言模型中视觉感知的可验证强化学习代理任务|Xiyao Wang, Zhengyuan Yang, Chao Feng, Yongyuan Liang, Yuhang Zhou, Xiaoyu Liu, Ziyi Zang, Ming Li .etc.|<http://arxiv.org/pdf/2506.10128v1>|提出了一种可验证的强化学习代理任务ViCrit，通过视觉幻觉批评提升视觉语言模型在视觉感知任务上的表...|
|🆕 发布|DeepTraverse: A Depth-First Search Inspired Network for Algorithmic Visual Understanding|深度遍历：一种基于深度优先搜索启发的算法视觉理解网络|Bin Guo, John H. L. Hansen|<http://arxiv.org/pdf/2506.10084v1>|提出了一种受算法搜索策略启发的深度学习架构DeepTraverse，通过递归探索和自适应调整显著提升...|
|🆕 发布|Reinforcing Spatial Reasoning in Vision-Language Models with Interwoven Thinking and Visual Drawing|《通过交织思维与视觉绘制强化视觉语言模型中的空间推理能力》|Junfei Wu, Jian Guan, Kaituo Feng, Qiang Liu, Shu Wu, Liang Wang, Wei Wu, Tieniu Tan|<http://arxiv.org/pdf/2506.09965v1>|提出通过视觉绘图增强空间推理能力，使大型视觉语言模型在空间推理任务上平均提高18.4%。|
|🆕 发布|Outside Knowledge Conversational Video (OKCV) Dataset -- Dialoguing over Videos|外部知识对话视频（OKCV）数据集 -- 视频对话|Benjamin Reichman, Constantin Patsch, Jack Truxal, Atishay Jain, Larry Heck|<http://arxiv.org/pdf/2506.09953v1>|[代码](https://github.com/c-patsch/OKCV.); 提出首个针对视频的视觉对话数据集OKCV，融合视觉识别与外部知识回答问题。|
|🆕 发布|CausalVQA: A Physically Grounded Causal Reasoning Benchmark for Video Models|因果VQA：一种基于物理基础的因果推理视频模型基准|Aaron Foss, Chloe Evans, Sasha Mitts, Koustuv Sinha, Ammar Rizvi, Justine T. Kao|<http://arxiv.org/pdf/2506.09943v1>|提出CausalVQA基准，通过现实世界场景的问题-答案对，测试视频模型对物理世界因果关系的理解能力...|
|🆕 发布|HopaDIFF: Holistic-Partial Aware Fourier Conditioned Diffusion for Referring Human Action Segmentation in Multi-Person Scenarios|HopaDIFF：面向多人场景中指引用户动作分割的全局-局部感知傅里叶条件扩散模型|Kunyu Peng, Junchao Huang, Xiangsheng Huang, Di Wen, Junwei Zheng, Yufan Chen, Kailun Yang, Jiamin Wu .etc.|<http://arxiv.org/pdf/2506.09650v1>|[代码](https://github.com/KPeng9510/HopaDIFF.git.); 提出首个针对多人在多场景下的文本引导人体动作分割方法HopaDIFF，实现最佳性能。|
|📝 更新|Question-Aware Gaussian Experts for Audio-Visual Question Answering|问题感知高斯专家用于音频视觉问答|Hongyeob Kim, Inyoung Jung, Dayoon Suh, Youjia Zhang, Sangmin Lee, Sungeun Hong|<http://arxiv.org/pdf/2503.04459v3>|[代码](https://aim-skku.github.io/QA-TIGER); 提出了一种结合问题信息的连续时间建模方法QA-TIGER，通过 Gaussian 专家模型精确捕捉关...|
|🆕 发布|Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning|通过探索-利用式上下文学习激发多模态少样本语言视觉模型|Cheng Chen, Yunpeng Zhai, Yifan Zhao, Jinyang Gao, Bolin Ding, Jia Li|<http://arxiv.org/pdf/2506.09473v1>|提出了一种探索-利用强化学习框架，有效融合多模态信息并自适应选择演示，增强了少量样本学习的大模型泛化...|
|📝 更新|MTVQA: Benchmarking Multilingual Text-Centric Visual Question Answering|多语言文本中心视觉问答基准测试：MTVQA|Jingqun Tang, Qi Liu, Yongjie Ye, Jinghui Lu, Shu Wei, Chunhui Lin, Wanqing Li, Mohamad Fitri Faiz Bin Mahmood .etc.|<http://arxiv.org/pdf/2405.11985v5>|[代码](https://bytedance.github.io/MTVQA); 提出MTVQA，首个涵盖9种语言的文本中心视觉问答数据集，显著提升了多语言视觉文本理解性能。|
|🆕 发布|DAVSP: Safety Alignment for Large Vision-Language Models via Deep Aligned Visual Safety Prompt|DAVSP：通过深度对齐视觉安全提示实现大型视觉-语言模型的安全对齐|Yitong Zhang, Jia Li, Liyi Cai, Ge Li|<http://arxiv.org/pdf/2506.09353v1>|[代码](https://github.com/zhangyitonggg/DAVSP.); 提出DAVSP方法，通过视觉安全提示和深度对齐训练，增强大型视觉语言模型对恶意查询的抵抗力。|
|📝 更新|TextSquare: Scaling up Text-Centric Visual Instruction Tuning|文本方阵：扩展文本中心视觉指令微调|Jingqun Tang, Chunhui Lin, Zhen Zhao, Shu Wei, Binghong Wu, Qi Liu, Yangfan He, Kuan Lu .etc.|<http://arxiv.org/pdf/2404.12803v3>|提出了一种大规模高质量指令微调数据集Square-10M，通过该方法显著提升了文本中心视觉问答模型的...|
|📝 更新|Do Large Vision-Language Models Distinguish between the Actual and Apparent Features of Illusions?|大型视觉-语言模型能否区分错觉的实际特征和表面特征？|Taiga Shinozaki, Tomoki Doi, Amane Watahiki, Satoshi Nishida, Hitomi Yanaka|<http://arxiv.org/pdf/2506.05765v2>|[代码](https://github.com/ynklab/FILM); 探究大型视觉语言模型对视觉错觉的实际与表面特征区分能力，引入了真假错觉分类的视觉问答数据集。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|TSVC:Tripartite Learning with Semantic Variation Consistency for Robust Image-Text Retrieval|TSVC：基于语义变化一致性的三分学习用于鲁棒图像-文本检索|Shuai Lyu, Zijing Tian, Zhonghong Ou, Yifan Zhu, Xiao Zhang, Qiankun Ha, Haoran Luo, Meina Song|<http://arxiv.org/pdf/2501.10935v2>|提出TSVC方法，通过三模型协作和软标签估计处理噪声数据，提升图像文本检索的鲁棒性。|
|🆕 发布|Adding simple structure at inference improves Vision-Language Compositionality|在推理过程中添加简单结构提高了视觉-语言组合性|Imanol Miranda, Ander Salaberria, Eneko Agirre, Gorka Azkune|<http://arxiv.org/pdf/2506.09691v1>|提出在推理时增加简单结构，通过图像分块和文本分段提升视觉语言模型的组合性表现。|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Modality-Balancing Preference Optimization of Large Multimodal Models by Adversarial Negative Mining|通过对抗性负样本挖掘实现大型多模态模型的模态平衡偏好优化|Chenxi Liu, Tianyi Xiong, Ruibo Chen, Yihan Wu, Junfeng Guo, Tianyi Zhou, Heng Huang|<http://arxiv.org/pdf/2506.08022v2>|提出了一种名为MBPO的偏好学习框架，通过对抗性负样本生成和在线奖励验证，有效平衡大型多模态模型中的...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ODG: Occupancy Prediction Using Dual Gaussians|ODG：使用双高斯分布进行占有率预测|Yunxiao Shi, Yinhao Zhu, Shizhong Han, Jisoo Jeong, Amin Ansari, Hong Cai, Fatih Porikli|<http://arxiv.org/pdf/2506.09417v2>|提出了一种分层双高斯查询方法，有效捕捉复杂驾驶场景动态，实现了实时占用预测和语义分类。|
|🆕 发布|Conditional diffusion models for guided anomaly detection in brain images using fluid-driven anomaly randomization|基于流体驱动异常随机化的脑图像引导异常检测的条件扩散模型|Ana Lawry Aguila, Peirong Liu, Oula Puonti, Juan Eugenio Iglesias|<http://arxiv.org/pdf/2506.10233v1>|提出了一种基于条件扩散模型的脑部图像异常检测方法，通过合成伪病变图像指导健康图像重建，无需病变数据即...|
|🆕 发布|Detecção da Psoríase Utilizando Visão Computacional: Uma Abordagem Comparativa Entre CNNs e Vision Transformers|银屑病的计算机视觉检测：卷积神经网络与视觉变换器的比较方法|Natanael Lucena, Fábio S. da Silva, Ricardo Rios|<http://arxiv.org/pdf/2506.10119v1>|比较CNN与ViT在银屑病图像分类中的表现，发现ViT在更小模型上性能更优。|
|🆕 发布|Kvasir-VQA-x1: A Multimodal Dataset for Medical Reasoning and Robust MedVQA in Gastrointestinal Endoscopy|Kvasir-VQA-x1：用于胃肠内窥镜医学推理和稳健医学视觉问答的多模态数据集|Sushant Gautam, Michael A. Riegler, Pål Halvorsen|<http://arxiv.org/pdf/2506.09958v1>|[代码](https://github.com/Simula/Kvasir-VQA-x1); 介绍了Kvasir-VQA-x1，一个大规模多模态医学视觉问答数据集，通过增强临床推理问题和视觉干扰...|
|🆕 发布|Towards Practical Alzheimer's Disease Diagnosis: A Lightweight and Interpretable Spiking Neural Model|迈向实用性的阿尔茨海默病诊断：一种轻量级且可解释的脉冲神经网络模型|Changwei Wu, Yifei Chen, Yuxin Du, Jinying Zong, Jie Dong, Mingxuan Liu, Yong Peng, Jin Fan .etc.|<http://arxiv.org/pdf/2506.09695v1>|[代码](https://github.com/wuchangw/FasterSNN.); 提出了一种结合生物启发神经元与区域自适应卷积的轻量级模型，用于高效准确的阿尔茨海默症早期诊断。|
|📝 更新|MedMoE: Modality-Specialized Mixture of Experts for Medical Vision-Language Understanding|MedMoE：用于医学视觉语言理解的模态专用混合专家模型|Shivang Chopra, Gabriela Sanchez-Rodriguez, Lingchao Mao, Andrew J Feola, Jing Li, Zsolt Kira|<http://arxiv.org/pdf/2506.08356v2>|提出MedMoE框架，针对不同医学影像模态特点动态调整视觉表示，提升临床视觉语言系统的对齐和检索性能...|
|🆕 发布|HSENet: Hybrid Spatial Encoding Network for 3D Medical Vision-Language Understanding|HSENet：混合空间编码网络用于三维医学视觉-语言理解|Yanzhao Shi, Xiaodan Zhang, Junzhong Ji, Haoning Jiang, Chengxin Zheng, Yinong Wang, Liangqiong Qu|<http://arxiv.org/pdf/2506.09634v1>|[代码](https://github.com/YanzhaoShi/HSENet.); 提出HSENet，通过双三维视觉编码器和空间压缩技术，提升三维医学图像与语言理解准确性。|
|🆕 发布|ADAgent: LLM Agent for Alzheimer's Disease Analysis with Collaborative Coordinator|ADAgent：面向阿尔茨海默病分析的协作协调器支持的LLM智能体|Wenlong Hou, Gangqian Yang, Ye Du, Yeung Lau, Lihao Liu, Junjun He, Ling Long, Shujun Wang|<http://arxiv.org/pdf/2506.11150v1>|提出ADAgent，一种基于大型语言模型的AI助手，用于处理多模态数据并提升阿尔茨海默症诊断与预后准...|
|🆕 发布|3D-RAD: A Comprehensive 3D Radiology Med-VQA Dataset with Multi-Temporal Analysis and Diverse Diagnostic Tasks|三维RAD：一个具有多时间分析及多样化诊断任务的综合三维放射学医疗视觉问答数据集|Xiaotang Gai, Jiaxiang Liu, Yichen Li, Zijie Meng, Jian Wu, Zuozhu Liu|<http://arxiv.org/pdf/2506.11147v1>|[代码](https://github.com/Tang-xiaoxiao/M3D-RAD.); 提出了3D-RAD数据集，扩展了3D医疗视觉问答研究，包含多任务类型，提升模型在复杂诊断任务中的表现...|
|🆕 发布|SRPL-SFDA: SAM-Guided Reliable Pseudo-Labels for Source-Free Domain Adaptation in Medical Image Segmentation|SRPL-SFDA：基于SAM引导的可靠伪标签用于无需源域的医疗图像分割领域自适应|Xinya Liu, Jianghao Wu, Tao Lu, Shaoting Zhang, Guotai Wang|<http://arxiv.org/pdf/2506.09403v1>|[代码](https://github.com/HiLab-git/SRPL-SFDA.); 提出了一种利用Segment Anything模型引导的可靠伪标签方法，有效提升了无源域适应在医疗图...|
|📝 更新|MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models|MedChat：基于大型语言模型的多模态诊断多智能体框架|Philip R. Liu, Sparsh Bansal, Jimmy Dinh, Aditya Pawar, Ramani Satishkumar, Shail Desai, Neeraj Gupta, Xin Wang .etc.|<http://arxiv.org/pdf/2506.07400v2>|[代码](https://github.com/Purdue-M2/MedChat.); 提出MedChat多代理框架，结合专业视觉模型与角色特定的大型语言模型，提高医疗影像诊断的准确性和报...|
|📝 更新|Adapting Vision-Language Foundation Model for Next Generation Medical Ultrasound Image Analysis|适配视觉-语言基础模型以应对下一代医学超声图像分析|Jingguo Qu, Xinyang Han, Tonghuan Xiao, Jia Ai, Juan Wu, Tong Zhao, Jing Qin, Ann Dorothy King .etc.|<http://arxiv.org/pdf/2506.08849v2>|[代码](https://github.com/jinggqu/NextGen-UIA.); 提出域自适应策略，优化了视觉语言基础模型在超声图像分析中的性能，实现了更精准的分割和分类。|
|📝 更新|IGraSS: Learning to Identify Infrastructure Networks from Satellite Imagery by Iterative Graph-constrained Semantic Segmentation|IGraSS：通过迭代图约束语义分割从卫星图像中学习识别基础设施网络|Oishee Bintey Hoque, Abhijin Adiga, Aniruddha Adiga, Siddharth Chaudhary, Madhav V. Marathe, S. S. Ravi, Kirti Rajagopalan, Amanda Wilson .etc.|<http://arxiv.org/pdf/2506.08137v2>|提出了一种迭代图约束语义分割框架IGraSS，通过结合图像分割和图论方法，有效改进了卫星图像中基础设...|
|🆕 发布|Autonomous Computer Vision Development with Agentic AI|具有自主性的代理人工智能的计算机视觉开发|Jin Kim, Muhammad Wahi-Anwa, Sangyun Park, Shawn Shin, John M. Hoffman, Matthew S. Brown|<http://arxiv.org/pdf/2506.11140v1>|利用大型语言模型，实现了计算机视觉系统的自主构建与任务配置。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos|动态查询与状态空间学习：用于多摄像头视频高效三维物体检测的方法|Rajeev Yasarla, Shizhong Han, Hong Cai, Fatih Porikli|<http://arxiv.org/pdf/2506.10242v1>|提出动态查询与状态空间学习框架 DySS，通过高效处理特征和动态更新查询，提升三维物体检测性能与效率...|
|🆕 发布|Retrieval of Surface Solar Radiation through Implicit Albedo Recovery from Temporal Context|通过从时间上下文中隐式恢复反照率来检索表面太阳辐射|Yael Frischholz, Devis Tuia, Michael Lehning|<http://arxiv.org/pdf/2506.10174v1>|[代码](https://github.com/frischwood/HeMu-dev.git); 提出了一种基于时序上下文的隐式反照率恢复方法，用于从卫星图像中准确检索地表太阳辐射。|
|🆕 发布|RoCA: Robust Cross-Domain End-to-End Autonomous Driving|RoCA:鲁棒跨域端到端自动驾驶|Rajeev Yasarla, Shizhong Han, Hsin-Pai Cheng, Litian Liu, Shweta Mahajan, Apratim Bhattacharyya, Yunxiao Shi, Risheek Garrepalli .etc.|<http://arxiv.org/pdf/2506.10145v1>|提出RoCA框架，通过学习基础轨迹 tokens 提升端到端自动驾驶跨域泛化与适应能力。|
|📝 更新|SpikeSMOKE: Spiking Neural Networks for Monocular 3D Object Detection with Cross-Scale Gated Coding|"SpikeSMOKE：基于单目视觉的3D物体检测用尖峰神经网络及跨尺度门控编码"|Xuemei Chen, Huamin Wang, Hangchi Shen, Shukai Duan, Shiping Wen, Tingwen Huang|<http://arxiv.org/pdf/2506.07737v2>|提出 SpikeSMOKE 架构，通过跨尺度门控编码增强特征表现，实现低功耗的3D物体检测。|
|🆕 发布|GLD-Road:A global-local decoding road network extraction model for remote sensing images|全局-局部解码遥感图像道路网络提取模型：GLD-Road|Ligao Deng, Yupeng Deng, Yu Meng, Jingbo Chen, Zhihao Xi, Diyou Liu, Qifeng Chu|<http://arxiv.org/pdf/2506.09553v1>|[代码](https://github.com/ucas-dlg/GLD-Road.); 提出了一种结合全局效率和局部精度的两阶段道路网络提取模型GLD-Road，有效提升了遥感图像中道路提...|
|📝 更新|BiCo-Fusion: Bidirectional Complementary LiDAR-Camera Fusion for Semantic- and Spatial-Aware 3D Object Detection|双向互补激光雷达-相机融合用于语义与空间感知的3D目标检测|Yang Song, Lin Wang|<http://arxiv.org/pdf/2406.19048v3>|[代码](https://t-ys.github.io/BiCo-Fusion); 提出了一种双向互补的激光雷达-相机融合框架BiCo-Fusion，通过增强激光雷达的语义意识和相机的...|
|🆕 发布|A Novel Lightweight Transformer with Edge-Aware Fusion for Remote Sensing Image Captioning|一种用于遥感图像标注的新型轻量级边缘感知融合变换器|Swadhin Das, Divyansh Mundra, Priyanshu Dayal, Raksha Sharma|<http://arxiv.org/pdf/2506.09429v1>|提出了一种轻量级Transformer架构，结合边缘感知增强策略，提升远程传感图像描述质量并降低计算...|
|🆕 发布|MSSDF: Modality-Shared Self-supervised Distillation for High-Resolution Multi-modal Remote Sensing Image Learning|MSSDF：用于高分辨率多模态遥感图像学习的模态共享自监督蒸馏|Tong Wang, Guanzhou Chen, Xiaodong Zhang, Chenxi Liu, Jiaqi Wang, Xiaoliang Tan, Wenchao Guo, Qingyuan Yang .etc.|<http://arxiv.org/pdf/2506.09327v1>|[代码](https://github.com/CVEO/MSSDF.); 提出了一种多模态自监督学习框架，利用高分辨率图像和多种数据模态进行预训练，有效提升了遥感图像学习的性...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Test-Time-Scaling for Zero-Shot Diagnosis with Visual-Language Reasoning|测试时缩放：基于视觉语言推理的零样本诊断|Ji Young Byun, Young-Jin Park, Navid Azizan, Rama Chellappa|<http://arxiv.org/pdf/2506.11166v1>|提出零样本医疗图像诊断框架，通过测试时缩放增强语言模型推理能力，提高诊断准确性。|
|🆕 发布|ReSim: Reliable World Simulation for Autonomous Driving|可靠世界仿真：面向自动驾驶的ReSim方法|Jiazhi Yang, Kashyap Chitta, Shenyuan Gao, Long Chen, Yuqian Shao, Xiaosong Jia, Hongyang Li, Andreas Geiger .etc.|<http://arxiv.org/pdf/2506.09981v1>|通过融合真实世界数据和模拟器中的非专家行为，ReSim模型可靠地模拟了多样化驾驶场景，提升了控制性和...|
|🆕 发布|AD^2-Bench: A Hierarchical CoT Benchmark for MLLM in Autonomous Driving under Adverse Conditions|AD^2- Bench：面向自动驾驶恶劣条件下的多模态大型语言模型分层CoT基准|Zhaoyang Wei, Chenhui Qiang, Bowen Jiang, Xumeng Han, Xuehui Yu, Zhenjun Han|<http://arxiv.org/pdf/2506.09557v1>|提出了AD^2-Bench，首个针对恶劣天气和复杂场景的自动驾驶CoT推理基准，推动多模态大模型推理...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Revisit What You See: Disclose Language Prior in Vision Tokens for Efficient Guided Decoding of LVLMs|重新审视你所见：在视觉标记中揭示语言先验，以实现LVLMs的高效引导解码|Beomsik Cho, Jaehyung Kim|<http://arxiv.org/pdf/2506.09522v1>|提出了一种简单有效的解码方法ReVisiT，通过引用视觉标记增强大型视觉语言模型中的视觉语义整合。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Training-Free Voice Conversion with Factorized Optimal Transport|无需训练的基于分解最优传输的语音转换|Alexander Lobashev, Assel Yermekova, Maria Larchenko|<http://arxiv.org/pdf/2506.09709v1>|提出了一种无需训练的跨语种声音转换方法，通过分解最优传输映射显著提升了转换质量和鲁棒性。|

