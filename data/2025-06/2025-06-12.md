## [UPDATED!] **2025-06-12** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Diffuse Everything: Multimodal Diffusion Models on Arbitrary State Spaces|“扩散一切：在任意状态空间上的多模态扩散模型”|Kevin Rojas, Yuchen Zhu, Sichen Zhu, Felix X. -F. Ye, Molei Tao|<http://arxiv.org/pdf/2506.07903v2>|提出了一种新型多模态扩散模型框架，无需外部预处理即可直接生成跨模态耦合数据。|
|📝 更新|Visually Descriptive Language Model for Vector Graphics Reasoning|用于矢量图形推理的可视化描述性语言模型|Zhenhailong Wang, Joy Hsu, Xingyao Wang, Kuan-Hao Huang, Manling Li, Jiajun Wu, Heng Ji|<http://arxiv.org/pdf/2404.06479v5>|[代码](https://mikewangwzhl.github.io/VDLM); 提出Visually Descriptive Language Model，通过将SVG图像转化为文...|
|📝 更新|Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model|面向AI生成视频的整体视觉质量评估：基于大规模语言模型的多维度评价模型|Zelu Qi, Ping Shi, Chaoyang Zhang, Shuqi Wang, Fei Zhao, Da Pan, Zefeng Ying|<http://arxiv.org/pdf/2506.04715v2>|[代码](https://github.com/QiZelu/AIGVEval.); 提出了一种基于大型语言模型的多维度视频质量评估方法，有效改善了AI生成视频的视觉质量评估问题。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HyBiomass: Global Hyperspectral Imagery Benchmark Dataset for Evaluating Geospatial Foundation Models in Forest Aboveground Biomass Estimation|“HyBiomass：全球高光谱图像基准数据集，用于评估森林地上生物量估算中的地理空间基础模型”|Aaron Banze, Timothée Stassin, Nassim Ait Ali Braham, Rıdvan Salih Kuzu, Simon Besnard, Michael Schmitt|<http://arxiv.org/pdf/2506.11314v1>|提出了全球分布式高光谱影像基准数据集，用于评估地理空间基础模型在森林地上生物量估算中的性能。|
|📝 更新|ColorBench: Can VLMs See and Understand the Colorful World? A Comprehensive Benchmark for Color Perception, Reasoning, and Robustness|ColorBench：视觉语言模型能否看见并理解多彩世界？一个关于颜色感知、推理和鲁棒性的全面基准|Yijun Liang, Ming Li, Chenrui Fan, Ziyue Li, Dang Nguyen, Kwesi Cobbina, Shweta Bhardwaj, Jiuhai Chen .etc.|<http://arxiv.org/pdf/2504.10514v2>|提出ColorBench基准，评估了视觉语言模型对颜色的感知、推理和鲁棒性，揭示了现有模型在颜色理解...|
|🆕 发布|DART: Differentiable Dynamic Adaptive Region Tokenizer for Vision Transformer and Mamba|DART：用于视觉变换器和Mamba的可微分动态自适应区域标记器|Shicheng Yin, Kaixuan Yin, Yang Liu, Weixing Chen, Liang Lin|<http://arxiv.org/pdf/2506.10390v1>|[代码](https://github.com/HCPLab-SYSU/DART.); 引入了动态自适应区域分片技术DART，通过调整不同区域的大小，有效提升了视觉Transformer模...|
|🆕 发布|FaceLiVT: Face Recognition using Linear Vision Transformer with Structural Reparameterization For Mobile Device|面向移动设备的基于线性视觉变换器和结构重参数化的面部识别方法 FaceLiVT|Novendra Setyawan, Chi-Chia Sun, Mao-Hsiu Hsu, Wen-Kai Kuo, Jun-Wei Hsieh|<http://arxiv.org/pdf/2506.10361v1>|FaceLiVT通过结合轻量级多头线性注意力和结构重参数化，实现了移动设备上快速准确的人脸识别。|
|🆕 发布|UrbanSense:AFramework for Quantitative Analysis of Urban Streetscapes leveraging Vision Large Language Models|《UrbanSense：一种利用视觉大型语言模型对城市街景进行定量分析框架》|Jun Yin, Jing Zhong, Peilin Li, Pengyu Zeng, Miao Zhang, Ran Luo, Shuai Lu|<http://arxiv.org/pdf/2506.10342v1>|提出了一种基于视觉语言模型的框架UrbanSense，实现了对城市街道风格的自动量化分析。|
|🆕 发布|WaveFormer: A Lightweight Transformer Model for sEMG-based Gesture Recognition|《WaveFormer：一种基于表面肌电图的手势识别轻量级Transformer模型》|Yanlong Chen, Mattia Orlandi, Pierangelo Maria Rapa, Simone Benatti, Luca Benini, Yawei Li|<http://arxiv.org/pdf/2506.11168v1>|提出了一种轻量级Transformer模型WaveFormer，通过结合时域和频域特征，提高了sEM...|
|🆕 发布|Uncertainty-Aware Deep Learning for Automated Skin Cancer Classification: A Comprehensive Evaluation|深度学习不确定性感知技术在自动化皮肤癌分类中的应用：全面评估|Hamzeh Asgharnezhad, Pegah Tabarisaadi, Abbas Khosravi, Roohallah Alizadehsani, U. Rajendra Acharya|<http://arxiv.org/pdf/2506.10302v1>|本研究通过结合深度学习模型和不确定性量化方法，提高了皮肤癌自动分类的准确性和可靠性。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Lifting Data-Tracing Machine Unlearning to Knowledge-Tracing for Foundation Models|将数据追踪机的遗忘提升为知识追踪以用于基础模型|Yuwen Tan, Boqing Gong|<http://arxiv.org/pdf/2506.11253v1>|提出将基础模型的数据追踪式遗忘提升为知识追踪式遗忘，以满足多样化的遗忘需求并更贴近人脑遗忘机制。|
|🆕 发布|InstaInpaint: Instant 3D-Scene Inpainting with Masked Large Reconstruction Model|即时3D场景修复：基于遮罩的大规模重建模型瞬时修复|Junqi You, Chieh Hubert Lin, Weijie Lyu, Zhengbo Zhang, Ming-Hsuan Yang|<http://arxiv.org/pdf/2506.10980v1>|[代码](https://dhmbb2.github.io/InstaInpaint_page); 提出了一种快速3D场景修复方法InstaInpaint，通过0.4秒内完成2D到3D的修复，大幅提升...|
|🆕 发布|Semi-Automated Quality Assurance in Digital Pathology: Tile Classification Approach|数字病理学中的半自动化质量保证：瓦片分类方法|Meredith VandeHaar, M. Clinch, I. Yilmaz, M. A. Rahman, Y. Xiao, F. Dogany, H. M. Alazab, A. Nassar .etc.|<http://arxiv.org/pdf/2506.10916v1>|提出了一种利用深度学习进行数字病理切片质量自动检测的方法，通过分析切片瓷砖并分类 artifacts...|
|🆕 发布|VideoDeepResearch: Long Video Understanding With Agentic Tool Using|视频深度研究：使用代理工具进行长视频理解的探索|Huaying Yuan, Zheng Liu, Junjie Zhou, Ji-Rong Wen, Zhicheng Dou|<http://arxiv.org/pdf/2506.10821v1>|提出了一种基于文本推理模型和多功能工具包的框架，有效提升了长视频理解任务的性能。|
|🆕 发布|High-resolution efficient image generation from WiFi CSI using a pretrained latent diffusion model|使用预训练潜在扩散模型从WiFi CSI生成高分辨率高效图像|Eshan Ramesh, Nishio Takayuki|<http://arxiv.org/pdf/2506.10605v1>|提出了一种利用预训练潜在扩散模型从WiFi CSI测量生成高分辨率图像的高效方法。|
|🆕 发布|Pisces: An Auto-regressive Foundation Model for Image Understanding and Generation|双鱼座：用于图像理解和生成的自回归基础模型|Zhiyang Xu, Jiuhai Chen, Zhaojiang Lin, Xichen Pan, Lifu Huang, Tianyi Zhou, Madian Khabsa, Qifan Wang .etc.|<http://arxiv.org/pdf/2506.10395v1>|提出了Pisces模型，通过分离视觉编码架构和优化训练技术，实现了图像理解和生成任务的统一模型。|
|🆕 发布|Leveraging 6DoF Pose Foundation Models For Mapping Marine Sediment Burial|利用6自由度位姿基础模型进行海洋沉积物埋藏制图|Jerry Yan, Chinmay Talegaonkar, Nicholas Antipa, Eric Terrill, Sophia Merrifield|<http://arxiv.org/pdf/2506.10386v1>|提出了一种结合深度基础模型特征与多视角摄影测量技术，用于从远程影像准确估算海底物体埋藏深度的计算机视...|
|📝 更新|GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest|GPT4RoI：在感兴趣区域上微调大型语言模型|Shilong Zhang, Peize Sun, Shoufa Chen, Min Xiao, Wenqi Shao, Wenwei Zhang, Yu Liu, Kai Chen .etc.|<http://arxiv.org/pdf/2307.03601v5>|[代码](https://github.com/jshilong/GPT4RoI.); 提出空间指令微调方法GPT4RoI，通过结合区域特征与文本，实现了更精细的图像-文本交互与推理能力。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GynSurg: A Comprehensive Gynecology Laparoscopic Surgery Dataset|《GynSurg：一个全面的妇科腹腔镜手术数据集》|Sahar Nasirihaghighi, Negin Ghamsarian, Leonie Peschek, Matteo Munari, Heinrich Husslein, Raphael Sznitman, Klaus Schoeffmann|<http://arxiv.org/pdf/2506.11356v1>|介绍了GynSurg，一个大规模多任务数据集，为妇科腹腔镜手术提供详细注释，助力手术辅助与术后分析。|
|🆕 发布|Unsupervised Deformable Image Registration with Structural Nonparametric Smoothing|无监督可变形图像配准与结构非参数平滑|Hang Zhang, Xiang Chen, Renjiu Hu, Rongguang Wang, Jinwei Zhang, Min Liu, Yaonan Wang, Gaolei Li .etc.|<http://arxiv.org/pdf/2506.10813v1>|[代码](https://github.com/tinymilky/SmoothProper.); 提出了一种无监督变形图像配准方法SmoothProper，通过优化神经网络传播流程，有效解决了特征稀...|
|🆕 发布|Text to Image for Multi-Label Image Recognition with Joint Prompt-Adapter Learning|文本到图像的多标签图像识别：联合提示-适配器学习|Chun-Mei Feng, Kai Yu, Xinxing Xu, Salman Khan, Rick Siow Mong Goh, Wangmeng Zuo, Yong Liu|<http://arxiv.org/pdf/2506.10575v1>|提出T2I-PAL方法，通过文本生成图像和联合提示-适配器学习减少模态差距，提升多标签图像识别性能。|
|🆕 发布|Boosting Adversarial Transferability for Hyperspectral Image Classification Using 3D Structure-invariant Transformation and Intermediate Feature Distance|使用三维结构不变变换与中间特征距离提升高光谱图像分类对抗迁移性|Chun Liu, Bingqian Zhu, Tao Xu, Zheng Zheng, Zheng Li, Wei Yang, Zhigang Han, Jiayao Wang|<http://arxiv.org/pdf/2506.10459v1>|提出了一种增强对抗样本在 Hyperspectral Image 分类中迁移性的方法，通过3D结构不...|
|🆕 发布|Revisiting Transformers with Insights from Image Filtering|重新审视基于图像滤波洞察的变换器|Laziz U. Abdullaev, Maksim Tkachenko, Tan M. Nguyen|<http://arxiv.org/pdf/2506.10371v1>|通过图像处理框架深入解释了Transformer架构及其变种的工作原理，并提出了两种改进方法以增强性...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Diversifying Human Pose in Synthetic Data for Aerial-view Human Detection|合成数据中多样化人体姿态以提高空中视角人体检测性能|Yi-Ting Shen, Hyungtae Lee, Heesung Kwon, Shuvra S. Bhattacharyya|<http://arxiv.org/pdf/2405.15939v2>|提出SynPoseDiv框架，通过扩散模型生成多样化3D姿态和图像翻译增强合成数据，提升空视图人体检...|
|🆕 发布|Enhanced Vehicle Speed Detection Considering Lane Recognition Using Drone Videos in California|基于无人机视频的加利福尼亚车道识别增强车辆速度检测|Amirali Ataee Naeini, Ashkan Teymouri, Ghazaleh Jafarsalehi, Michael Zhang|<http://arxiv.org/pdf/2506.11239v1>|提出了一种基于改进YOLOv11的无人机车辆速度检测方法，实现了高精度速度测量和车辆分类。|
|🆕 发布|Occlusion-Aware 3D Hand-Object Pose Estimation with Masked AutoEncoders|遮挡感知的3D手部与物体姿态估计：基于遮罩自编码器的方法|Hui Yang, Wei Sun, Jian Liu, Jin Zheng, Jian Xiao, Ajmal Mian|<http://arxiv.org/pdf/2506.10816v1>|提出了一种基于遮蔽自编码器的 occlusion-aware 手部与物体姿态估计方法，通过结构化遮蔽...|
|🆕 发布|Enhancing Deepfake Detection using SE Block Attention with CNN|使用SE块注意力机制与卷积神经网络增强深度伪造检测|Subhram Dasgupta, Janelle Mason, Xiaohong Yuan, Olusola Odeyomi, Kaushik Roy|<http://arxiv.org/pdf/2506.10683v1>|提出一种轻量级CNN模型，通过SE块注意力机制提升深伪检测准确度，减少计算资源需求。|
|📝 更新|DyFFPAD: Dynamic Fusion of Convolutional and Handcrafted Features for Fingerprint Presentation Attack Detection|动态融合卷积特征与手工特征进行指纹呈现攻击检测|Anuj Rai, Parsheel Kumar Tiwari, Jyotishna Baishya, Ram Prakash Sharma, Somnath Dey|<http://arxiv.org/pdf/2308.10015v5>|提出动态融合深度卷积网络与手工特征的方法，有效提高了指纹活体检测的准确率。|
|🆕 发布|It's Not the Target, It's the Background: Rethinking Infrared Small Target Detection via Deep Patch-Free Low-Rank Representations|“不是目标，而是背景：通过深度无补丁低秩表示重新思考红外小目标检测”|Guoyi Zhang, Guangsheng Xu, Siyang Chen, Han Wang, Xiaohu Zhang|<http://arxiv.org/pdf/2506.10425v1>|提出了一种不依赖图像块处理的端到端红外小目标检测框架，通过直接学习低秩背景结构提高了检测准确性和效率...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SLICK: Selective Localization and Instance Calibration for Knowledge-Enhanced Car Damage Segmentation in Automotive Insurance|SLICK：选择性定位与实例校准用于汽车保险中知识增强的车辆损伤分割|Teerapong Panboonyuen|<http://arxiv.org/pdf/2506.10528v1>|提出SLICK框架，通过结构先验和领域知识实现精确车辆损伤分割，提升保险车辆检测准确性和鲁棒性。|
|🆕 发布|J-DDL: Surface Damage Detection and Localization System for Fighter Aircraft|战斗机表面损伤检测与定位系统：J-DDL|Jin Huang, Mingqiang Wei, Zikuan Li, Hangyu Qu, Wei Zhao, Xinyu Bai|<http://arxiv.org/pdf/2506.10505v1>|提出了一种结合2D图像和3D点云的战斗机表面损伤检测与定位系统，提高了检测效率和准确性。|
|🆕 发布|Teaching in adverse scenes: a statistically feedback-driven threshold and mask adjustment teacher-student framework for object detection in UAV images under adverse scenes|在恶劣场景中教学：一种基于统计反馈驱动的阈值与掩码调整的教师-学生框架，用于无人机图像中恶劣场景下的目标检测|Hongyu Chen, Jiping Liu, Yong Wang, Jun Zhu, Dejun Feng, Yakun Xie|<http://arxiv.org/pdf/2506.11175v1>|提出首个面向无人机在恶劣场景下的目标检测基准，引入动态反馈调整机制提升伪标签质量和特征学习。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Motion-R1: Chain-of-Thought Reasoning and Reinforcement Learning for Human Motion Generation|运动R1：链式思维推理与强化学习用于人体运动生成|Runqi Ouyang, Haoyun Li, Zhenyuan Zhang, Xiaofeng Wang, Zheng Zhu, Guan Huang, Xingang Wang|<http://arxiv.org/pdf/2506.10353v2>|引入链式思维机制和强化学习，提出统一动作路径生成框架，提升文本到动作生成的控制性、一致性和多样性。|
|🆕 发布|MMMG: A Massive, Multidisciplinary, Multi-Tier Generation Benchmark for Text-to-Image Reasoning|大规模、跨学科、多层次生成基准：用于文本到图像推理的MMMG|Yuxuan Luo, Yuhui Yuan, Junwen Chen, Haonan Cai, Ziyi Yue, Yuwei Yang, Fatima Zohra Daha, Ji Li .etc.|<http://arxiv.org/pdf/2506.10963v2>|提出了知识图像生成任务及MMMG基准，评估了文本到图像推理能力，并推出了FLUX-Reason基线模...|
|📝 更新|One Diffusion to Generate Them All|一种扩散生成万物的算法|Duong H. Le, Tuan Pham, Sangho Lee, Christopher Clark, Aniruddha Kembhavi, Stephan Mandt, Ranjay Krishna, Jiasen Lu|<http://arxiv.org/pdf/2411.16318v2>|[代码](https://github.com/lehduong/OneDiffusion); 提出了一种通用的大规模扩散模型OneDiffusion，实现了多任务的无缝处理和高效生成。|
|🆕 发布|GenWorld: Towards Detecting AI-generated Real-world Simulation Videos|《GenWorld：迈向检测AI生成的现实世界模拟视频》|Weiliang Chen, Wenzhao Zheng, Yu Zheng, Lei Chen, Jie Zhou, Jiwen Lu, Yueqi Duan|<http://arxiv.org/pdf/2506.10975v1>|[代码](https://chen-wl20.github.io/GenWorld); 提出GenWorld数据集并设计SpannDetector模型，有效提升AI生成视频检测的准确性和泛...|
|🆕 发布|SpectralAR: Spectral Autoregressive Visual Generation|光谱自回归视觉生成方法：SpectralAR|Yuanhui Huang, Weiliang Chen, Wenzhao Zheng, Yueqi Duan, Jie Zhou, Jiwen Lu|<http://arxiv.org/pdf/2506.10962v1>|[代码](https://huang-yh.github.io/spectralar); 提出了一种基于频谱视角的视觉生成框架SpectralAR，通过有序频谱标记实现因果性，提高了生成效率...|
|🆕 发布|Fine-Grained Perturbation Guidance via Attention Head Selection|通过注意力头部选择实现的细粒度扰动引导|Donghoon Ahn, Jiwon Kang, Sanghyun Lee, Minjae Kim, Jaewon Min, Wooseok Jang, Saungwu Lee, Sayak Paul .etc.|<http://arxiv.org/pdf/2506.10978v1>|提出HeadHunter框架，通过选择特定注意力头实现细粒度生成控制和视觉风格调整。|
|📝 更新|CAT: A Conditional Adaptation Tailor for Efficient and Effective Instance-Specific Pansharpening on Real-World Data|CAT：面向实际数据高效有效实例特定 pansharpening 的条件适配定制方法|Tianyu Xin, Jin-Liang Xiao, Zeyu Xia, Shan Yin, Liang-Jian Deng|<http://arxiv.org/pdf/2504.10242v2>|提出了一种快速适应特定输入的CAT框架，实现高效的跨传感器 pansharpening 并提升计算效...|
|🆕 发布|VINCIE: Unlocking In-context Image Editing from Video|《VINCIE：解锁视频中的即时图像编辑》|Leigang Qu, Feng Cheng, Ziyan Yang, Qi Zhao, Shanchuan Lin, Yichun Shi, Yicong Li, Wenjie Wang .etc.|<http://arxiv.org/pdf/2506.10941v1>|提出了一种基于视频的直接学习方式，实现了无需特定任务管道的图像编辑，达到领先水平。|
|🆕 发布|CreatiPoster: Towards Editable and Controllable Multi-Layer Graphic Design Generation|CreatiPoster：迈向可编辑和可控的多层图形设计生成|Zhao Zhang, Yutao Cheng, Dexiang Hong, Maoke Yang, Gonglei Shi, Lei Ma, Hui Zhang, Jie Shao .etc.|<http://arxiv.org/pdf/2506.10890v1>|[代码](https://github.com/graphic-design-ai/creatiposter); 提出 CreatiPoster 框架，自动生成可编辑的多层平面设计，提升设计质量和效率。|
|📝 更新|A Unit Enhancement and Guidance Framework for Audio-Driven Avatar Video Generation|音频驱动虚拟人视频生成的单元增强与引导框架|S. Z. Zhou, Y. B. Wang, J. F. Wu, T. Hu, J. N. Zhang|<http://arxiv.org/pdf/2505.03603v5>|提出了一种针对音频驱动上肢动画的单元增强与引导框架，通过动态调整训练权重和一致性增强，显著提升了视觉...|
|🆕 发布|Symmetrical Flow Matching: Unified Image Generation, Segmentation, and Classification with Score-Based Generative Models|对称流匹配：基于评分生成模型的统一图像生成、分割与分类|Francisco Caetano, Christiaan Viviers, Peter H. N. De With, Fons van der Sommen|<http://arxiv.org/pdf/2506.10634v1>|统一了图像生成、分割和分类任务，Symmetrical Flow Matching通过对称学习目标实...|
|🆕 发布|GigaVideo-1: Advancing Video Generation via Automatic Feedback with 4 GPU-Hours Fine-Tuning|《GigaVideo-1：通过自动反馈与4个GPU小时微调推进视频生成》|Xiaoyi Bao, Jindi Lv, Xiaofeng Wang, Zheng Zhu, Xinze Chen, YuKun Zhou, Jiancheng Lv, Xingang Wang .etc.|<http://arxiv.org/pdf/2506.10639v1>|提出自动反馈微调框架GigaVideo-1，无需人工标注即可有效提升视频生成质量。|
|🆕 发布|DanceChat: Large Language Model-Guided Music-to-Dance Generation|舞语者：大型语言模型引导的音乐到舞蹈生成|Qing Wang, Xiaohang Yang, Yilan Dong, Naveen Raj Govindaraj, Gregory Slabaugh, Shanxin Yuan|<http://arxiv.org/pdf/2506.10574v1>|提出了一种大型语言模型指导的音乐到舞蹈生成方法，通过文本指令提高了舞蹈的多样性和与音乐风格的契合度。|
|🆕 发布|EmbodiedGen: Towards a Generative 3D World Engine for Embodied Intelligence|EmbodiedGen：面向具身智能的生成式三维世界引擎|Wang Xinjie, Liu Liu, Cao Yu, Wu Ruiqi, Qin Wenkang, Wang Dehui, Sui Wei, Su Zhizhong|<http://arxiv.org/pdf/2506.10600v1>|[代码](https://horizonrobotics.github.io/robot_lab); 提出 EmbodiedGen 平台，利用生成式 AI 生成低成本、高质量的 3D 资产，助力Embo...|
|🆕 发布|DreamActor-H1: High-Fidelity Human-Product Demonstration Video Generation via Motion-designed Diffusion Transformers|DreamActor-H1：通过运动设计扩散变换器实现高保真人-产品演示视频生成|Lizhen Wang, Zhurong Xia, Tianshu Hu, Pengrui Wang, Pengfei Wang, Zerong Zheng, Ming Zhou|<http://arxiv.org/pdf/2506.10568v1>|[代码](https://submit2025-dream.github.io/DreamActor-H1); 提出了一种基于扩散变换器的框架，通过精确的运动指导和交叉注意力机制，生成高质量的人类与产品互动演示视...|
|📝 更新|Reinforcing Multimodal Understanding and Generation with Dual Self-rewards|用双向自我奖励强化多模态理解和生成|Jixiang Hong, Yiran Zhang, Guanzhong Wang, Yi Liu, Ji-Rong Wen, Rui Yan|<http://arxiv.org/pdf/2506.07963v2>|引入自我监督的双奖励机制，有效提升大型多模态模型在无需外部监督下的理解和生成能力。|
|🆕 发布|AniMaker: Automated Multi-Agent Animated Storytelling with MCTS-Driven Clip Generation|《AniMaker：基于MCTS驱动的片段生成实现自动化多智能体动画故事讲述》|Haoyuan Shi, Yunxin Li, Xinyu Chen, Longyue Wang, Baotian Hu, Min Zhang|<http://arxiv.org/pdf/2506.10540v1>|提出了一种多智能体协同的动画制作框架AniMaker，通过MCTS搜索和专门评价机制生成连贯的高质量...|
|🆕 发布|Edit360: 2D Image Edits to 3D Assets from Any Angle|Edit360：从任意角度将2D图像编辑为3D资产|Junchao Huang, Xinting Hu, Zhuotao Tian, Shaoshuai Shi, Li Jiang|<http://arxiv.org/pdf/2506.10507v1>|Edit360通过锚点视角编辑传播机制，实现了任意视角的2D图像编辑到3D资产的高效转换。|
|📝 更新|AR-RAG: Autoregressive Retrieval Augmentation for Image Generation|AR-RAG：自回归检索增强图像生成|Jingyuan Qi, Zhiyang Xu, Qifan Wang, Lifu Huang|<http://arxiv.org/pdf/2506.06962v2>|提出了一种动态检索增强的图像生成方法AR-RAG，通过逐步引入相关视觉片段，有效提升了生成图像的多样...|
|🆕 发布|ReconMOST: Multi-Layer Sea Temperature Reconstruction with Observations-Guided Diffusion|基于观测引导扩散的多层海水温度重建：ReconMOST|Yuanyi Song, Pumeng Lyu, Ben Fei, Fenghua Ling, Wanli Ouyang, Lei Bai|<http://arxiv.org/pdf/2506.10391v1>|[代码](https://github.com/norsheep/ReconMOST.); 提出了一种基于观测数据引导的扩散模型框架ReconMOST，实现了全球多层级海温的精准重构。|
|📝 更新|Enhancing Intent Understanding for Ambiguous prompt: A Human-Machine Co-Adaption Strategy|《增强模糊提示意图理解：一种人机协同适应策略》|Yangfan He, Jianhui Wang, Yijin Wang, Kun Li, Yan Zhong, Xinyuan Song, Li Sun, Jingyuan Lu .etc.|<http://arxiv.org/pdf/2501.15167v6>|提出了一种人机协同适应策略，通过优化用户提示与图片间的相互信息，减少非专业用户调整图像的次数。|
|🆕 发布|GeoCAD: Local Geometry-Controllable CAD Generation|地理CAD：局部几何可控的CAD生成|Zhanwei Zhang, Kaiyuan Liu, Junjie Liu, Wenxiao Wang, Binbin Lin, Liang Xie, Chen Shen, Deng Cai|<http://arxiv.org/pdf/2506.10337v1>|[代码](https://github.com/Zhanwei-Z/GeoCAD.); 提出GeoCAD方法，通过几何指令自动修改CAD模型局部部分，提高设计效率并确保形状符合用户要求。|
|🆕 发布|Towards Scalable SOAP Note Generation: A Weakly Supervised Multimodal Framework|面向可扩展SOAP笔记生成的弱监督多模态框架|Sadia Kamal, Tim Oates, Joy Wan|<http://arxiv.org/pdf/2506.10328v1>|提出了一种弱监督多模态框架，从有限的输入生成结构化SOAP笔记，减轻医生负担并降低对大量标注数据的依...|
|📝 更新|DiffUMI: Training-Free Universal Model Inversion via Unconditional Diffusion for Face Recognition|无监督通用模型反转：通过无条件扩散进行人脸识别的训练无关方法|Hanrui Wang, Shuo Wang, Chun-Shien Lu, Isao Echizen|<http://arxiv.org/pdf/2504.18015v2>|提出了一种无需额外训练的通用模型攻击方法DiffUMI，利用无条件扩散生成技术从面部嵌入重建私人面部...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TARDIS STRIDE: A Spatio-Temporal Road Image Dataset for Exploration and Autonomy|时空道路图像数据集TARDIS STRIDE：用于探索与自主性研究|Héctor Carrión, Yutong Bai, Víctor A. Hernández Castro, Kishan Panaganti, Ayush Zenith, Matthew Trang, Tony Zhang, Pietro Perona .etc.|<http://arxiv.org/pdf/2506.11302v1>|提出了一种结合空间和时间动态的统一框架，通过STRIDE数据集训练TARDIS模型，实现了对真实世界...|
|🆕 发布|ReGuidance: A Simple Diffusion Wrapper for Boosting Sample Quality on Hard Inverse Problems|“ReGuidance：一种用于提升硬逆问题样本质量的简单扩散封装方法”|Aayush Karan, Kulin Shah, Sitan Chen|<http://arxiv.org/pdf/2506.10955v1>|提出了一种ReGuidance方法，通过反转概率流ODE并重新初始化，有效提升了硬逆问题中的样本质量...|
|🆕 发布|AIR: Zero-shot Generative Model Adaptation with Iterative Refinement|AIR：迭代细化驱动的零样本生成模型适应|Guimeng Liu, Milad Abdollahzadeh, Ngai-Man Cheung|<http://arxiv.org/pdf/2506.10895v1>|提出了一种针对零样本生成模型适应性的迭代细化方法，有效解决了文本与图像偏移不对齐问题，显著提升了生成...|
|🆕 发布|Scalable Context-Preserving Model-Aware Deep Clustering for Hyperspectral Images|用于高光谱图像的可扩展保持上下文模型感知深度聚类方法|Xianlu Li, Nicolas Nadisic, Shaoguang Huang, Nikos Deligiannis, Aleksandra Pižurica|<http://arxiv.org/pdf/2506.11377v1>|[代码](https://github.com/lxlscut/SCDSC); 提出了一种高效的深度聚类方法，通过同时捕捉局部和非局部结构，实现了大规模高光谱图像的精确聚类。|
|🆕 发布|Stroke-based Cyclic Amplifier: Image Super-Resolution at Arbitrary Ultra-Large Scales|基于笔划的循环放大器：任意超大规模图像超分辨率|Wenhao Guo, Peng Lu, Xujun Peng, Zhaoran Zhao, Sheng Li|<http://arxiv.org/pdf/2506.10774v1>|提出了一种基于笔划向量的循环放大模型，实现了超大规模图像超分辨率的无模糊重建。|
|🆕 发布|Modality-AGnostic Image Cascade (MAGIC) for Multi-Modality Cardiac Substructure Segmentation|多模态无关图像级联（MAGIC）用于多模态心脏亚结构分割|Nicholas Summerfield, Qisheng He, Alex Kuo, Ahmed I. Ghanem, Simeng Zhu, Chase Ruff, Joshua Pan, Anudeep Kumar .etc.|<http://arxiv.org/pdf/2506.10797v1>|提出了一种多模态心脏子结构分割方法MAGIC，能在单一模型中有效处理不同模态和重叠结构。|
|📝 更新|Towards Reliable Identification of Diffusion-based Image Manipulations|面向基于扩散的图像操作的可信识别|Alex Costanzino, Woody Bayliss, Juil Sock, Marc Gorriz Blanch, Danijela Horak, Ivan Laptev, Philip Torr, Fabio Pizzati|<http://arxiv.org/pdf/2506.05466v2>|[代码](https://alex-costanzino.github.io/radar); 提出了一种可靠识别扩散模型图像篡改的新方法RADAR，通过融合多模态特征和对比损失，有效检测和定位图...|
|🆕 发布|Uncertainty-Masked Bernoulli Diffusion for Camouflaged Object Detection Refinement|不确定遮挡的伯努利扩散用于伪装物体检测细化|Yuqi Shen, Fengyang Xiao, Sujie Hu, Youwei Pang, Yifan Pu, Chengyu Fang, Xiu Li, Chunming He|<http://arxiv.org/pdf/2506.10712v1>|提出了一种用于伪装目标检测的生成细化框架，通过不确定性遮蔽机制优化了Bernoulli扩散过程。|
|🆕 发布|Underage Detection through a Multi-Task and MultiAge Approach for Screening Minors in Unconstrained Imagery|通过多任务和多年龄段方法在非受限图像中筛选未成年人的未成年检测|Christopher Gaul, Eduardo Fidalgo, Enrique Alegre, Rocío Alaiz Rodríguez, Eri Pérez Corral|<http://arxiv.org/pdf/2506.10689v1>|提出了一种多任务、多年龄段检测框架，通过平衡样本分布和引入新基准，有效提升了未成年人识别的准确性和鲁...|
|🆕 发布|TexTailor: Customized Text-aligned Texturing via Effective Resampling|《TexTailor：通过有效重采样实现定制化文本对齐纹理》|Suin Lee, Dae-Shik Kim|<http://arxiv.org/pdf/2506.10612v1>|[代码](https://github.com/Adios42/Textailor); TexTailor通过改进扩散过程中的纹理信息整合和自适应调整相机位置，有效解决了多视角纹理一致性生...|
|🆕 发布|Hessian Geometry of Latent Space in Generative Models|生成模型中潜在空间的Hessian几何学|Alexander Lobashev, Dmitry Guskov, Maria Larchenko, Mikhail Tamm|<http://arxiv.org/pdf/2506.10632v1>|[代码](https://github.com/alobashev/hessian-geometry-of-diffusion-models.); 分析了生成模型潜在空间的几何结构，揭示了其分形相变特征，并通过重建费舍尔信息度量方法进行了验证。|
|🆕 发布|Harmonizing Geometry and Uncertainty: Diffusion with Hyperspheres|调和几何与不确定性：超球扩散|Muskan Dosi, Chiranjeev Chiranjeev, Kartik Thakral, Mayank Vatsa, Richa Singh|<http://arxiv.org/pdf/2506.10576v1>|[代码](https://github.com/IAB-IITJ/Harmonizing-Geometry-and-Uncertainty-Diffusion-with-Hyperspheres); 提出了一种新的生成模型HyperSphereDiff，通过引入方向性噪声保留了非欧几里得数据的几何结...|
|🆕 发布|CogStream: Context-guided Streaming Video Question Answering|上下文引导的流视频问答：CogStream|Zicheng Zhao, Kangyu Wang, Shijie Li, Rui Qian, Weiyao Lin, Huabin Liu|<http://arxiv.org/pdf/2506.10516v1>|提出CogStream任务，通过视觉流压缩和历史对话检索，高效处理流视频中的问题回答挑战。|
|🆕 发布|ContextRefine-CLIP for EPIC-KITCHENS-100 Multi-Instance Retrieval Challenge 2025|上下文细化-CLIP 用于 EPIC-KITCHENS-100 多实例检索挑战 2025|Jing He, Yiqing Wang, Lingling Li, Kexin Zhang, Puhua Chen|<http://arxiv.org/pdf/2506.10550v1>|[代码](https://github.com/delCayr/ContextRefine-Clip); 提出ContextRefine-CLIP模型，通过双向动态交互优化视觉文本特征，显著提升多实例检索性...|
|📝 更新|Expert Race: A Flexible Routing Strategy for Scaling Diffusion Transformer with Mixture of Experts|专家竞赛：一种用于扩展混合专家的扩散变换器的灵活路由策略|Yike Yuan, Ziyu Wang, Zihao Huang, Defa Zhu, Xun Zhou, Jingyi Yu, Qiyang Min|<http://arxiv.org/pdf/2503.16057v3>|提出了一种灵活的路由策略Expert Race，用于提升扩散变换器模型的可扩展性和性能。|
|📝 更新|Urban1960SatSeg: Unsupervised Semantic Segmentation of Mid-20$^{th}$ century Urban Landscapes with Satellite Imageries|《Urban1960SatSeg：基于卫星影像的20世纪中叶城市景观的无监督语义分割》|Tianxiang Hao, Lixian Zhang, Yingjia Zhang, Mengxuan Chen, Jinxiao Zhang, Haohuan Fu|<http://arxiv.org/pdf/2506.09476v2>|[代码](https://github.com/Tianxiang-Hao/Urban1960SatSeg.); 提出Urban1960SatBench数据集和Urban1960SatUSM框架，实现了无监督历史卫...|
|📝 更新|Sparc3D: Sparse Representation and Construction for High-Resolution 3D Shapes Modeling|稀疏表示与构建用于高分辨率三维形状建模的Sparc3D|Zhihao Li, Yufei Wang, Heliang Zheng, Yihao Luo, Bihan Wen|<http://arxiv.org/pdf/2505.14521v3>|提出了Sparc3D框架，通过稀疏表示和构造方法，实现了高效且高保真的高分辨率3D形状建模。|
|📝 更新|M-MRE: Extending the Mutual Reinforcement Effect to Multimodal Information Extraction|M-MRE: 将相互强化效应扩展到多模态信息提取|Chengguang Gan, Zhixi Cai, Yanbin Wei, Yunhao Liang, Shiwen Ni, Tatsunori Mori|<http://arxiv.org/pdf/2504.17353v2>|首次将互增强效应拓展到多模态信息提取领域，提出Prompt Format Adapter以兼容大型视...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Gondola: Grounded Vision Language Planning for Generalizable Robotic Manipulation|“贡多拉：面向泛化机器人操作的基于视觉语言的定位规划”|Shizhe Chen, Ricardo Garcia, Paul Pacaud, Cordelia Schmid|<http://arxiv.org/pdf/2506.11261v1>|提出了一种基于大型语言模型的 grounded 视觉语言规划模型 Gondola，通过处理多视角图像...|
|🆕 发布|SceneCompleter: Dense 3D Scene Completion for Generative Novel View Synthesis|场景补全器：用于生成新视角合成的稠密三维场景补全|Weiliang Chen, Jiayi Bi, Yuanhui Huang, Wenzhao Zheng, Yueqi Duan|<http://arxiv.org/pdf/2506.10981v1>|[代码](https://chen-wl20.github.io/SceneCompleter); 提出了一种通过稠密3D场景补全实现生成式新视角合成的框架，有效融合结构和纹理信息，提高了视觉一致性和...|
|🆕 发布|VRBench: A Benchmark for Multi-Step Reasoning in Long Narrative Videos|VRBench：长篇叙事视频中多步骤推理的基准测试|Jiashuo Yu, Yue Wu, Meng Chu, Zhifei Ren, Zizheng Huang, Pei Chu, Ruijie Zhang, Yinan He .etc.|<http://arxiv.org/pdf/2506.10857v1>|提出VRBench基准，针对长篇叙事视频评估大型模型的多步推理能力，涵盖时间推理和程序有效性。|
|🆕 发布|PosterCraft: Rethinking High-Quality Aesthetic Poster Generation in a Unified Framework|统一框架下对高质量审美海报生成的再思考：PosterCraft|SiXiang Chen, Jianyu Lai, Jialin Gao, Tian Ye, Haoyu Chen, Hengyu Shi, Shitong Shao, Yunlong Lin .etc.|<http://arxiv.org/pdf/2506.10741v1>|[代码](https://ephemeral182.github.io/PosterCraft); 提出 PosterCraft 框架，通过自动化数据管道和级联优化流程，实现了高质量审美海报的自由生成...|
|🆕 发布|Prompts to Summaries: Zero-Shot Language-Guided Video Summarization|提示到摘要：零样本语言引导的视频摘要|Mario Barbara, Alaa Maalouf|<http://arxiv.org/pdf/2506.10807v1>|提出首个无需特定训练数据的零样本文本引导视频摘要方法，通过大语言模型判断实现用户意图指导的视频精简。|
|📝 更新|Consistent Story Generation with Asymmetry Zigzag Sampling|具有对称之字形采样的连贯故事生成|Mingxiao Li, Mang Ning, Marie-Francine Moens|<http://arxiv.org/pdf/2506.09612v2>|[代码](https://github.com/Mingxiao-Li/Asymmetry-Zigzag-StoryDiffusion.); 提出了一种无训练的Zigzag采样策略，通过交替使用非对称提示和视觉共享机制，显著增强了视觉故事生成...|
|📝 更新|Few-Shot Learner Generalizes Across AI-Generated Image Detection|少量样本学习者在AI生成图像检测中具有泛化能力|Shiyu Wu, Jing Liu, Jing Li, Yequan Wang|<http://arxiv.org/pdf/2501.08763v2>|[代码](https://github.com/teheperinko541/Few-Shot-AIGI-Detector.); 提出Few-Shot Detector，通过少量样本学习区分未见AI生成图像，实现检测性能显著提升。|
|🆕 发布|Rethinking Generative Human Video Coding with Implicit Motion Transformation|重新思考基于隐式运动转换的生成式人类视频编码|Bolin Chen, Ru-Ling Liao, Jie Chen, Yan Ye|<http://arxiv.org/pdf/2506.10453v1>|提出了一种隐式运动转换方法，解决了传统显式运动编码在人体视频压缩中的局限性，实现了高效压缩和高保真重...|
|🆕 发布|FSATFusion: Frequency-Spatial Attention Transformer for Infrared and Visible Image Fusion|频率-空间注意力变换器用于红外与可见光图像融合：FSATFusion|Tianpei Zhang, Jufeng Zhao, Yiming Zhu, Guangmang Cui, Yuhan Lyu|<http://arxiv.org/pdf/2506.10366v1>|[代码](https://github.com/Lmmh058/FSATFusion.); 提出了一种基于频率-空间注意力Transformer的图像融合网络，有效捕获全局上下文并提升融合质量...|
|🆕 发布|DUN-SRE: Deep Unrolling Network with Spatiotemporal Rotation Equivariance for Dynamic MRI Reconstruction|DUN-SRE：具有时空旋转等方差性的深度展开网络用于动态MRI重建|Yuliang Zhu, Jing Cheng, Qi Xie, Zhuo-Xu Cui, Qingyong Zhu, Yuanyuan Liu, Xin Liu, Jianfeng Ren .etc.|<http://arxiv.org/pdf/2506.10309v1>|提出了一种结合时空旋转等变性的深度展开网络，有效提升了动态MRI重建的质量和泛化能力。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|M4V: Multi-Modal Mamba for Text-to-Video Generation|M4V: 用于文本到视频生成的多模态蟒蛇模型|Jiancheng Huang, Gengwei Zhang, Zequn Jie, Siyu Jiao, Yinlong Qian, Ling Chen, Yunchao Wei, Lin Ma|<http://arxiv.org/pdf/2506.10915v1>|[代码](https://huangjch526.github.io/M4V_project.); 提出了M4V框架，通过多模态扩散Mamba块有效整合文本与视频信息，降低计算成本并提升视频生成质量。|
|🆕 发布|DiffPR: Diffusion-Based Phase Reconstruction via Frequency-Decoupled Learning|基于解耦频率学习的扩散式相位重建：DiffPR|Yi Zhang|<http://arxiv.org/pdf/2506.11183v1>|提出了一种频率解耦的两阶段框架DiffPR，通过取消高层跳跃连接和迭代去噪，有效解决了深度学习在定量...|
|📝 更新|Aesthetics Without Semantics|无语义的美学|C. Alejandro Parraga, Olivier Penacchio, Marcos Muňoz Gonzalez, Bogdan Raducanu, Xavier Otazu|<http://arxiv.org/pdf/2505.05331v2>|创建最小语义内容数据库，通过引入丑陋图像平衡数据集，揭示了图像特征与美学评价的关系。|
|🆕 发布|Research on Audio-Visual Quality Assessment Dataset and Method for User-Generated Omnidirectional Video|用户生成全景视频的音视频质量评估数据集与方法研究|Fei Zhao, Da Pan, Zelu Qi, Ping Shi|<http://arxiv.org/pdf/2506.10331v1>|构建了用户生成全景视频的音频视觉质量评估数据集，并提出了有效的基线模型。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Anti-Aliased 2D Gaussian Splatting|抗锯齿二维高斯散点绘制|Mae Younes, Adnane Boukhayma|<http://arxiv.org/pdf/2506.11252v1>|提出了一种抗锯齿的二维高斯绘制方法，有效解决了在不同采样率下的走样问题，提高了渲染质量。|
|📝 更新|FrugalNeRF: Fast Convergence for Extreme Few-shot Novel View Synthesis without Learned Priors|FrugalNeRF：无需学习先验的极少量样本新视角合成快速收敛方法|Chin-Yang Lin, Chung-Ho Wu, Chang-Han Yeh, Shih-Han Yen, Cheng Sun, Yu-Lun Liu|<http://arxiv.org/pdf/2410.16271v3>|FrugalNeRF通过跨尺度几何适应方案，无需学习先验，有效提升少量样本下的三维场景重建速度和质量...|
|📝 更新|ViC-Bench: Benchmarking Visual-Interleaved Chain-of-Thought Capability in MLLMs with Free-Style Intermediate State Representations|ViC-Bench：基于自由风格中间状态表示在多模态大型语言模型中评估视觉交错的链式思维能力的基准测试|Xuecheng Wu, Jiaxing Liu, Danlei Huang, Xiaoyu Li, Yifan Wang, Chen Chen, Liya Ma, Xuezhi Cao .etc.|<http://arxiv.org/pdf/2505.14404v2>|提出ViC-Bench基准，通过自由式中间状态表示评估多模态大模型视觉交错的链式思维性能。|
|📝 更新|Spike-TBR: a Noise Resilient Neuromorphic Event Representation|尖峰-TBR：一种抗噪声的类神经形态事件表示方法|Gabriele Magrini, Federico Becattini, Luca Cultrera, Lorenzo Berlincioni, Pietro Pala, Alberto Del Bimbo|<http://arxiv.org/pdf/2506.04817v2>|提出Spike-TBR编码策略，结合了帧式优势与脉冲神经网络的噪声过滤能力，增强了事件流表示的鲁棒性...|
|🆕 发布|Low-Barrier Dataset Collection with Real Human Body for Interactive Per-Garment Virtual Try-On|面向交互式单件服装虚拟试穿的低门槛真实人体数据集收集|Zaiqiang Wu, Yechen Li, Jingyuan Liu, Yuki Shibata, Takayuki Hori, I-Chao Shen, Takeo Igarashi|<http://arxiv.org/pdf/2506.10468v1>|提出了一种使用真实人体收集数据集的低门槛方法，提高了虚拟试衣的准确性和实时性。|
|🆕 发布|PointGS: Point Attention-Aware Sparse View Synthesis with Gaussian Splatting|点注意力感知的稀疏视图合成与高斯绘制：PointGS|Lintao Xiang, Hongpei Zheng, Yating Huang, Qijun Yang, Hujun Yin|<http://arxiv.org/pdf/2506.10335v1>|提出了一种基于点注意力的高效稀疏视图合成方法，通过交互式网络提升了渲染质量。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ALBERT: Advanced Localization and Bidirectional Encoder Representations from Transformers for Automotive Damage Evaluation|ALBERT：面向汽车损伤评估的高级定位与双向编码器变换器表征|Teerapong Panboonyuen|<http://arxiv.org/pdf/2506.10524v1>|提出ALBERT模型，通过高级定位和双向编码器表征实现车辆损伤和部件的精确分割与分类。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Video-CoT: A Comprehensive Dataset for Spatiotemporal Understanding of Videos Based on Chain-of-Thought|视频-CoT：基于思维链的视频时空理解综合数据集|Shuyi Zhang, Xiaoshuai Hao, Yingbo Tang, Lingfeng Zhang, Pengwei Wang, Zhongyuan Wang, Hongxuan Ma, Shanghang Zhang|<http://arxiv.org/pdf/2506.08817v3>|提出Video-CoT数据集，利用Chain-of-Thought提升视频时空理解能力。|
|🆕 发布|Post-Training Quantization for Video Matting|视频抠图的后训练量化|Tianrui Zhu, Houyuan Chen, Ruihao Gong, Michele Magno, Haotong Qin, Kai Zhang|<http://arxiv.org/pdf/2506.10840v1>|提出一种视频抠图模型的后期训练量化框架，通过分阶段优化和全局校准显著提升量化精度并保持时序连贯性。|
|🆕 发布|MF2Summ: Multimodal Fusion for Video Summarization with Temporal Alignment|MF2Summ：基于时间对齐的多模态融合视频摘要方法|Shuo wang, Jihao Zhang|<http://arxiv.org/pdf/2506.10430v1>|提出了一种融合视觉与听觉信息的多模态视频摘要方法，通过跨模态注意力和时间对齐提升性能。|
|📝 更新|Simultaneous Localization and Affordance Prediction of Tasks from Egocentric Video|从第一人称视频中进行任务的同时定位与功效预测|Zachary Chavis, Hyun Soo Park, Stephen J. Guy|<http://arxiv.org/pdf/2407.13856v2>|扩展了视觉语言模型，通过理解空间任务亲和性和定位，提高了对第一视角视频任务的理解。|
|📝 更新|Tile Classification Based Viewport Prediction with Multi-modal Fusion Transformer|基于多模态融合变换器的瓦片分类视角预测|Zhihao Zhang, Yiwei Chen, Weizhan Zhang, Caixia Yan, Qinghua Zheng, Qi Wang, Wangdu Chen|<http://arxiv.org/pdf/2309.14704v4>|提出了一种基于多模态融合变换器的 viewport 预测方法，提高了预测准确性和鲁棒性。|
|📝 更新|What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning|“发生了什么以及可能发生了什么？面向过程感知视频表征学习的状态变化反事实”|Chi-Hsi Kung, Frangil Ramirez, Juhyung Ha, Yi-Ting Chen, David Crandall, Yi-Hsuan Tsai|<http://arxiv.org/pdf/2503.21055v3>|引入大语言模型生成状态变化描述及其反事实推理，提升视频表示学习对活动步骤因果理解的能力。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|TDS-CLIP: Temporal Difference Side Network for Efficient VideoAction Recognition|TDS-CLIP：用于高效视频行为识别的时间差侧网络|Bin Wang, Wentong Li, Wenqian Wang, Mingliang Gao, Runmin Cong, Wei Zhang|<http://arxiv.org/pdf/2408.10688v2>|提出了一种内存高效的时差侧网络TDS-CLIP，平衡知识迁移与时间建模，提升视频动作识别性能。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CORT: Class-Oriented Real-time Tracking for Embedded Systems|面向类别的嵌入式系统实时跟踪方法CORT|Edoardo Cittadini, Alessandro De Siena, Giorgio Buttazzo|<http://arxiv.org/pdf/2407.17521v2>|分类导向实时跟踪方法CORT，通过按类别拆分匹配问题，减少重识别需求，提高了嵌入式系统中的多目标跟踪...|
|📝 更新|DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO|深度视频R1：基于难度感知回归GRPO的视频强化微调|Jinyoung Park, Jeehye Na, Jinyoung Kim, Hyunwoo J. Kim|<http://arxiv.org/pdf/2506.07464v2>|提出了一种针对视频大语言模型的改进强化学习算法，通过回归任务和难度感知数据增强，有效提升了视频推理性...|
|📝 更新|High Performance Space Debris Tracking in Complex Skylight Backgrounds with a Large-Scale Dataset|在复杂天空背景下利用大规模数据集实现高性能空间碎片跟踪|Guohang Zhuang, Weixi Song, Jinyang Huang, Chenwei Yang, Wanli OuYang, Yan Lu|<http://arxiv.org/pdf/2506.02614v3>|提出了一种基于深度学习的空间碎片跟踪网络SDT-Net，有效处理复杂背景下的空间碎片追踪问题。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MMME: A Spontaneous Multi-Modal Micro-Expression Dataset Enabling Visual-Physiological Fusion|MMME：一种自发的多模态微表情数据集，实现视觉-生理融合|Chuang Ma, Yu Pei, Jianhang Zhang, Shaokai Zhao, Bowen Ji, Liang Xie, Ye Yan, Erwei Yin|<http://arxiv.org/pdf/2506.09834v2>|首次构建了多模态微表情数据集MMME，融合视觉与生理信号，显著提升微表情识别与检测性能。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Sheet Music Benchmark: Standardized Optical Music Recognition Evaluation|乐谱基准测试：标准化光学音乐识别评估|Juan C. Martinez-Sevilla, Joan Cerveto-Serrano, Noelia Luna, Greg Chapman, Craig Sapp, David Rizo, Jorge Calvo-Zaragoza|<http://arxiv.org/pdf/2506.10488v2>|提出Sheet Music Benchmark数据集和OMR Normalized Edit Dis...|
|🆕 发布|Joint Denoising of Cryo-EM Projection Images using Polar Transformers|使用极坐标变换器对冷冻电镜投影图像进行联合去噪|Joakim Andén, Justus Sagemüller|<http://arxiv.org/pdf/2506.11283v1>|提出了一种基于变换器的神经网络架构，通过同时进行聚类、对齐和去噪，有效改善低温电子显微镜图像的去噪效...|
|🆕 发布|Deep Learning-Based Digitization of Overlapping ECG Images with Open-Source Python Code|基于深度学习的重叠心电图图像数字化及开源Python代码实现|Reza Karbasi, Masoud Rahimi, Abdol-Hossein Vahabie, Hadi Moradi|<http://arxiv.org/pdf/2506.10617v1>|[代码](https://github.com/masoudrahimi39/ECG-code.); 提出了一种基于深度学习的ECG图像数字化方法，有效解决了信号重叠问题，显著提升了数字化精度。|
|🆕 发布|Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization|起始位置至关重要：关于神经网络量化中更优权重初始化的研究|Stone Yun, Alexander Wong|<http://arxiv.org/pdf/2506.10463v1>|研究了权重初始化对神经网络量化影响，提出使用图超网络提高量化模型准确性。|
|📝 更新|InceptionMamba: An Efficient Hybrid Network with Large Band Convolution and Bottleneck Mamba|“_inceptionMamba：一种具有大带宽卷积和瓶颈Mamba的高效混合网络_”|Yuhang Wang, Jun Li, Zhijian Wu, Jianhua Xu|<http://arxiv.org/pdf/2506.08735v2>|[代码](https://github.com/Wake1021/InceptionMamba.); 提出InceptionMamba架构，通过正交带卷积和瓶颈Mamba模块提升空间依赖捕捉和全局上下文...|
|🆕 发布|Semi-Tensor-Product Based Convolutional Neural Networks|基于半张量积的卷积神经网络|Daizhan Cheng|<http://arxiv.org/pdf/2506.10407v1>|提出了一种基于半张量积的卷积神经网络，避免了传统填充带来的无效信息，提高了图像识别的准确性。|
|📝 更新|Advanced deep architecture pruning using single filter performance|单滤波器性能的高级深度架构剪枝|Yarden Tzach, Yuval Meir, Ronit D. Gross, Ofek Tevet, Ella Koresh, Ido Kanter|<http://arxiv.org/pdf/2501.12880v2>|提出了一种基于单一滤波器性能统计的深度网络剪枝方法，实现了高比例剪枝而不影响网络准确度。|
|📝 更新|GD doesn't make the cut: Three ways that non-differentiability affects neural network training|GD不足以应对：非微分性影响神经网络训练的三种方式|Siddharth Krishna Kumar|<http://arxiv.org/pdf/2401.08426v9>|揭示了非微分函数梯度方法与传统梯度下降在神经网络训练中的差异，挑战了现有优化理论。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Capturing Temporal Dynamics in Large-Scale Canopy Tree Height Estimation|捕捉大规模树冠高度估计中的时间动态特性|Jan Pauls, Max Zimmer, Berkant Turan, Sassan Saatchi, Philippe Ciais, Sebastian Pokutta, Fabian Gieseke|<http://arxiv.org/pdf/2501.19328v2>|提出了一种利用卫星数据生成高分辨率树冠高度地图的新方法，为欧洲大陆提供了首个10米分辨率的2019-...|
|🆕 发布|QuadricFormer: Scene as Superquadrics for 3D Semantic Occupancy Prediction|四元数形器：将场景视为超四元数进行三维语义占据预测|Sicheng Zuo, Wenzhao Zheng, Xiaoyong Han, Longchao Yang, Yong Pan, Jiwen Lu|<http://arxiv.org/pdf/2506.10977v1>|提出使用几何表现力强的超二次曲面作为场景基元，通过较少基元高效预测三维语义占据状态。|
|🆕 发布|Hierarchical Error Assessment of CAD Models for Aircraft Manufacturing-and-Measurement|飞机制造与测量中CAD模型的分层误差评估|Jin Huang, Honghua Chen, Mingqiang Wei|<http://arxiv.org/pdf/2506.10594v1>|提出了一种分层误差评估框架HEA-MM，通过全局、部件和特征三级分析，精确评估飞机CAD模型的制造误...|
|🆕 发布|Transformer IMU Calibrator: Dynamic On-body IMU Calibration for Inertial Motion Capture|Transformer IMU校准器：动态在体IMU校准用于惯性运动捕捉|Chengxu Zuo, Jiawei Huang, Xiao Jiang, Yuan Yao, Xiangren Shi, Rui Cao, Xinyu Yi, Feng Xu .etc.|<http://arxiv.org/pdf/2506.10580v1>|[代码](https://github.com/ZuoCX1996/TIC.); 提出了一种动态的IMU校准方法，无需静态校准过程即可实现长期精确的运动捕捉。|
|📝 更新|CapST: Leveraging Capsule Networks and Temporal Attention for Accurate Model Attribution in Deep-fake Videos|CapST：利用胶囊网络与时间注意力进行深度伪造视频中精确的模型归因|Wasim Ahmad, Yan-Tsung Peng, Yuan-Hao Chang, Gaddisa Olani Ganfure, Sarwar Khan|<http://arxiv.org/pdf/2311.03782v4>|提出了一种融合胶囊网络和时空注意力的模型，有效提升了深伪视频生成模型的归因准确性。|
|🆕 发布|Towards Robust Multimodal Emotion Recognition under Missing Modalities and Distribution Shifts|面向缺失模态和分布偏移下的鲁棒多模态情感识别|Guowei Zhong, Ruohong Huan, Mingzhen Wu, Ronghua Liang, Peng Chen|<http://arxiv.org/pdf/2506.10452v1>|[代码](https://github.com/gw-zhong/CIDer.); 提出了一种鲁棒的多模态情感识别框架CIDer，有效应对缺失模态和数据分布偏移问题。|
|📝 更新|Towards Clinical Practice in CT-Based Pulmonary Disease Screening: An Efficient and Reliable Framework|面向临床实践的基于CT的肺部疾病筛查：一个高效可靠的研究框架|Qian Shao, Bang Du, Kai Zhang, Yixuan Wu, Zepeng Li, Qiyuan Chen, Qianqian Tang, Jian Wu .etc.|<http://arxiv.org/pdf/2412.01525v3>|提出了一种高效可靠框架，通过优化的子采样和不确定性量化，实现了CT扫描肺部疾病筛查的快速准确诊断。|
|🆕 发布|Ground Reaction Force Estimation via Time-aware Knowledge Distillation|通过时间感知知识蒸馏估计地面反作用力|Eun Som Jeon, Sinjini Mitra, Jisoo Lee, Omik M. Save, Ankita Shukla, Hyunglae Lee, Pavan Turaga|<http://arxiv.org/pdf/2506.10265v1>|提出了一种基于时间感知的知识蒸馏框架，有效提高了从鞋底传感器数据估计地面反作用力的准确性。|
|📝 更新|CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting|CompMarkGS：用于压缩3D高斯散点投射的鲁棒水印技术|Sumin In, Youngdong Jang, Utae Jeong, MinHyuk Jang, Hyeongcheol Park, Eunbyung Park, Sangpil Kim|<http://arxiv.org/pdf/2503.12836v5>|提出了一种压缩容忍的锚点基3D高斯溅射水印技术，有效保护版权且不影响渲染质量。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs|超越注意力或相似性：最大化条件多样性以优化多模态大型语言模型中的标记剪枝|Qizhe Zhang, Mengzhen Liu, Lichen Li, Ming Lu, Yuan Zhang, Junwen Pan, Qi She, Shanghang Zhang|<http://arxiv.org/pdf/2506.10967v1>|[代码](https://github.com/Theia-4869/CDPruner.); 提出了一种新的视觉token剪枝方法CDPruner，通过最大化条件多样性来优化多模态大语言模型的性...|
|🆕 发布|Human-Robot Navigation using Event-based Cameras and Reinforcement Learning|基于事件相机和强化学习的人类-机器人导航|Ignacio Bugueno-Cordova, Javier Ruiz-del-Solar, Rodrigo Verschae|<http://arxiv.org/pdf/2506.10790v1>|结合事件相机和强化学习实现实时以人为本的机器人导航与避障。|
|🆕 发布|BrainMAP: Multimodal Graph Learning For Efficient Brain Disease Localization|脑映射：多模态图学习用于高效的脑疾病定位|Nguyen Linh Dan Le, Jing Ren, Ciyuan Peng, Chengyao Xie, Bowen Li, Feng Xia|<http://arxiv.org/pdf/2506.11178v1>|提出BrainMAP框架，通过专注疾病相关子图和先进的多模态融合，高效定位神经退行性疾病影响的脑区。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Incentivizing Reasoning for Advanced Instruction-Following of Large Language Models|激励推理以提高大型语言模型的高级指令遵循能力|Yulei Qin, Gang Li, Zongyi Li, Zihan Xu, Yuchen Shi, Zhekai Lin, Xiao Cui, Ke Li .etc.|<http://arxiv.org/pdf/2506.01413v2>|[代码](https://github.com/yuleiqin/RAIF.); 提出了一种基于强化学习和专家行为克隆的推理激励方法，显著提升了大型语言模型处理复杂指令的能力。|
|🆕 发布|Balancing Tails when Comparing Distributions: Comprehensive Equity Index (CEI) with Application to Bias Evaluation in Operational Face Biometrics|在比较分布时平衡尾部：综合权益指数（CEI）及其在运营人脸生物特征偏见评估中的应用|Imanol Solano, Julian Fierrez, Aythami Morales, Alejandro Peña, Ruben Tolosana, Francisco Zamora-Martinez, Javier San Agustin|<http://arxiv.org/pdf/2506.10564v1>|提出Comprehensive Equity Index (CEI)指标，专门检测高绩效人脸识别系统...|
|📝 更新|Glimpse: Generalized Locality for Scalable and Robust CT|《瞥见：用于可扩展和鲁棒CT的广义局部性》|AmirEhsan Khorashadizadeh, Valentin Debarnot, Tianlin Liu, Ivan Dokmanić|<http://arxiv.org/pdf/2401.00816v3>|[代码](https://github.com/swing-research/Glimpse.); 提出Glimpse方法，通过局部坐标神经网络提高医学图像重建的泛化能力和效率。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unsourced Adversarial CAPTCHA: A Bi-Phase Adversarial CAPTCHA Framework|无源对抗验证码：一种双相对抗验证码框架|Xia Du, Xiaoyuan Liu, Jizhe Zhou, Zheng Lin, Chi-man Pun, Zhe Chen, Wei Ni, Jun Luo|<http://arxiv.org/pdf/2506.10685v1>|提出无源对抗验证码框架，通过文本提示生成高保真度对抗样例，有效抵御深度学习攻击。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Object-Centric Latent Action Learning|面向对象的潜在动作学习|Albina Klepach, Alexander Nikulin, Ilya Zisman, Denis Tarasov, Alexander Derevyagin, Andrei Polubarov, Nikita Lyubaykin, Vladislav Kurenkov|<http://arxiv.org/pdf/2502.09680v2>|提出了一种以对象为中心的潜在动作学习方法，通过自监督预训练分离动作相关和干扰动态，有效提高了在有干扰...|
|📝 更新|Latent Action Learning Requires Supervision in the Presence of Distractors|潜在动作学习在存在干扰物的情况下需要监督|Alexander Nikulin, Ilya Zisman, Denis Tarasov, Nikita Lyubaykin, Andrei Polubarov, Igor Kiselev, Vladislav Kurenkov|<http://arxiv.org/pdf/2502.00379v5>|发现现实世界视频中的干扰物影响潜在动作学习，提出添加少量监督信息的方法，显著提升学习效果。|
|🆕 发布|Continual Hyperbolic Learning of Instances and Classes|《实例与类别的连续双曲学习》|Melika Ayoughi, Mina Ghadimi Atigh, Mohammad Mahdi Derakhshani, Cees G. M. Snoek, Pascal Mettes, Paul Groth|<http://arxiv.org/pdf/2506.10710v1>|提出了一种适应实例与类别同时识别的连续学习算法HyperCLIC，利用双曲空间建模数据的层级结构。|
|🆕 发布|Class-Incremental Learning for Honey Botanical Origin Classification with Hyperspectral Images: A Study with Continual Backpropagation|基于高光谱图像的蜂蜜植物源分类的类增量学习：连续反向传播研究|Guyang Zhang, Waleed Abdulla|<http://arxiv.org/pdf/2506.10489v1>|提出了一种结合连续反向传播算法的类增量学习方法，有效提升蜂蜜植物源分类性能。|
|📝 更新|Improved Algorithm for Deep Active Learning under Imbalance via Optimal Separation|通过最优分离的不平衡条件下深度主动学习改进算法|Shyam Nuggehalli, Jifan Zhang, Lalit Jain, Robert Nowak|<http://arxiv.org/pdf/2312.09196v4>|提出DIRECT算法，通过优化类分离边界选择标注样本，有效应对不平衡数据集下的主动学习挑战。|
|📝 更新|A Survey on All-in-One Image Restoration: Taxonomy, Evaluation and Future Trends|《一体化图像修复综述：分类、评估与未来趋势》|Junjun Jiang, Zengyuan Zuo, Gang Wu, Kui Jiang, Xianming Liu|<http://arxiv.org/pdf/2410.15067v2>|[代码](https://github.com/Harbinzzy/All-in-One-Image-Restoration-Survey.); 系统梳理了全功能图像复原领域的创新方法，为评估和未来研究提供了框架。|
|🆕 发布|Using Vision Language Models to Detect Students' Academic Emotion through Facial Expressions|利用视觉语言模型通过面部表情检测学生学术情感|Deliang Wang, Chao Yang, Gaowei Chen|<http://arxiv.org/pdf/2506.10334v1>|利用视觉语言模型通过面部表情检测学生学术情感，减少了对大量标注数据的依赖。|
|📝 更新|Play to Generalize: Learning to Reason Through Game Play|《玩以泛化：通过游戏玩耍学习推理》|Yunfei Xie, Yinsong Ma, Shiyi Lan, Alan Yuille, Junfei Xiao, Chen Wei|<http://arxiv.org/pdf/2506.08011v2>|提出通过让大型语言模型玩简易电子游戏来增强其跨领域多模态推理能力的新训练范式。|
|🆕 发布|Energy Aware Camera Location Search Algorithm for Increasing Precision of Observation in Automated Manufacturing|能量感知的摄像头位置搜索算法以提高自动化制造中观测的精度|Rongfei Li, Francis Assadian|<http://arxiv.org/pdf/2506.10251v1>|提出了一种节能的相机位置搜索算法，通过自适应探索工作空间以最小化图像噪声，提升自动化制造中观测精度。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Eye, Robot: Learning to Look to Act with a BC-RL Perception-Action Loop|“眼睛，机器人：通过BC-RL感知-行动循环学习观察以行动”|Justin Kerr, Kush Hari, Ethan Weber, Chung Min Kim, Brent Yi, Tyler Bonnen, Ken Goldberg, Angjoo Kanazawa|<http://arxiv.org/pdf/2506.10968v1>|提出机器人EyeRobot，通过强化学习实现手眼协调，提高真实世界任务执行能力。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Q-Ponder: A Unified Training Pipeline for Reasoning-based Visual Quality Assessment|Q-Ponder：一种基于推理的视觉质量评估统一训练流程|Zhuoxuan Cai, Jian Zhang, Xinbin Yuan, Peng-Tao Jiang, Wenxiang Chen, Bowen Tang, Lujian Yao, Qiyuan Wang .etc.|<http://arxiv.org/pdf/2506.05384v2>|提出了一种统一的两阶段训练框架Q-Ponder，通过结合推理描述和质量评分，提升了视觉质量评估的准确...|
|🆕 发布|SlotPi: Physics-informed Object-centric Reasoning Models|槽位Pi：基于物理信息的对象中心推理模型|Jian Li, Wan Han, Ning Lin, Yu-Liang Zhan, Ruizhi Chengze, Haining Wang, Yi Zhang, Hongsheng Liu .etc.|<http://arxiv.org/pdf/2506.10778v1>|引入了SlotPi模型，融合物理知识与动态预测，增强物体交互与流体动力学模拟的适应性。|
|🆕 发布|LRSLAM: Low-rank Representation of Signed Distance Fields in Dense Visual SLAM System|LRSLAM：稠密视觉SLAM系统中符号距离场的低秩表示|Hongbeen Park, Minjeong Park, Giljoo Nam, Jinkyu Kim|<http://arxiv.org/pdf/2506.10567v1>|LRSLAM通过使用低秩张量分解技术，有效提升了密集视觉SLAM系统的实时性能、鲁棒性和大规模场景处...|
|🆕 发布|LLMs Are Not Yet Ready for Deepfake Image Detection|大型语言模型尚未准备好用于深度伪造图像检测|Shahroz Tariq, David Nguyen, M. A. P. Chamikara, Tingmin Wu, Alsharif Abuadbba, Kristen Moore|<http://arxiv.org/pdf/2506.10474v1>|指出大型视觉语言模型在深度伪造检测上存在不足，建议作为辅助工具而非独立系统。|
|📝 更新|VScan: Rethinking Visual Token Reduction for Efficient Large Vision-Language Models|VScan：重新思考视觉标记缩减以提高大型视觉语言模型的效率|Ce Zhang, Kaixin Ma, Tianqing Fang, Wenhao Yu, Hongming Zhang, Zhisong Zhang, Yaqi Xie, Katia Sycara .etc.|<http://arxiv.org/pdf/2505.22654v2>|[代码](https://github.com/Tencent/SelfEvolvingAgent); 提出VScan方法，通过视觉编码阶段的全局与局部扫描及语言模型中间层剪枝，有效减少计算负担并保持性能...|
|🆕 发布|HalLoc: Token-level Localization of Hallucinations for Vision Language Models|HalLoc：视觉语言模型中幻觉的标记级定位|Eunkyu Park, Minyeong Kim, Gunhee Kim|<http://arxiv.org/pdf/2506.10286v1>|[代码](https://github.com/dbsltm/cvpr25_halloc.); 提出 HalLoc 数据集和基准模型，实现高效的概率性幻觉检测，提升视觉语言模型可靠性。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MSTAR: Box-free Multi-query Scene Text Retrieval with Attention Recycling|基于注意力循环的无框多查询场景文本检索方法MSTAR|Liang Yin, Xudong Xie, Zhang Li, Xiang Bai, Yuliang Liu|<http://arxiv.org/pdf/2506.10609v1>|[代码](https://github.com/yingift/MSTAR.); 提出无框多查询场景文本检索方法MSTAR，通过动态捕获文本多粒度表示和风格感知指令，提升检索性能。|
|🆕 发布|Improving Medical Visual Representation Learning with Pathological-level Cross-Modal Alignment and Correlation Exploration|病理级别跨模态对齐与相关性探索提升医学视觉表征学习|Jun Wang, Lixing Zhu, Xiaohan Yu, Abhir Bhalerao, Yulan He|<http://arxiv.org/pdf/2506.10573v1>|提出了一种新的医学视觉表征学习框架PLACE，通过病理级别跨模态对齐和相关性探索，提升了多种下游任务...|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Burn After Reading: Do Multimodal Large Language Models Truly Capture Order of Events in Image Sequences?|“阅后即焚：多模态大型语言模型是否真正捕捉到了图像序列中的事件顺序？”|Yingjin Song, Yupei Du, Denis Paperno, Albert Gatt|<http://arxiv.org/pdf/2506.10415v1>|[代码](https://github.com/yjsong22/TempVS.); 提出TempVS基准，评估大型多模态语言模型在图像序列中理解事件时间顺序的能力。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PiPViT: Patch-based Visual Interpretable Prototypes for Retinal Image Analysis|基于斑块的可视化解释原型用于视网膜图像分析：PiPViT|Marzieh Oghbaie, Teresa Araújo, Hrvoje Bogunović|<http://arxiv.org/pdf/2506.10669v2>|[代码](https://github.com/marziehoghbaie/PiPViT); 提出PiPViT模型，通过捕获图像块间的长距离依赖学习直观原型，提高视网膜图像分析的准确性和解释性。|
|📝 更新|seg2med: a bridge from artificial anatomy to multimodal medical images|从人工解剖学到多模态医学图像的桥梁：seg2med|Zeyu Yang, Zhilin Chen, Yipeng Sun, Anika Strittmatter, Anish Raj, Ahmad Allababidi, Johann S. Rink, Frank G. Zöllner|<http://arxiv.org/pdf/2504.09182v2>|提出seg2med框架，通过解剖学驱动的多模态医学图像合成，实现高质量、结构对齐的CT和MR图像生成...|
|🆕 发布|Med-URWKV: Pure RWKV With ImageNet Pre-training For Medical Image Segmentation|Med-URWKV：基于ImageNet预训练的纯RWKV用于医学图像分割|Zhenhuan Zhou|<http://arxiv.org/pdf/2506.10858v1>|提出Med-URWKV模型，利用ImageNet预训练提升医学图像分割性能。|
|🆕 发布|Generalist Models in Medical Image Segmentation: A Survey and Performance Comparison with Task-Specific Approaches|医学图像分割中的通用模型：综述及与特定任务方法的性能比较|Andrea Moglia, Matteo Leccardi, Matteo Cavicchioli, Alice Maccarini, Marco Marcon, Luca Mainardi, Pietro Cerveri|<http://arxiv.org/pdf/2506.10825v1>|探讨了通用模型在医学图像分割中的应用，并与特定任务模型进行了性能对比。|
|🆕 发布|Deep Learning-based Multi Project InP Wafer Simulation for Unsupervised Surface Defect Detection|基于深度学习的多项目InP晶圆仿真在无监督表面缺陷检测中的应用|Emílio Dolgener Cantú, Rolf Klemens Wittmann, Oliver Abdeen, Patrick Wagner, Wojciech Samek, Moritz Baier, Sebastian Lapuschkin|<http://arxiv.org/pdf/2506.10713v1>|提出了一种基于深度学习的合成“黄金标准”生成方法，用于无监督检测InP晶圆表面缺陷，提高了检测效率。|
|📝 更新|ODG: Occupancy Prediction Using Dual Gaussians|ODG：使用双高斯分布进行占有率预测|Yunxiao Shi, Yinhao Zhu, Shizhong Han, Jisoo Jeong, Amin Ansari, Hong Cai, Fatih Porikli|<http://arxiv.org/pdf/2506.09417v2>|提出了一种分层双高斯查询方法，有效捕捉复杂驾驶场景动态，实现了实时占用预测和语义分类。|
|🆕 发布|ConStyX: Content Style Augmentation for Generalizable Medical Image Segmentation|《ConStyX：内容风格增强用于通用医疗图像分割》|Xi Chen, Zhiqiang Shen, Peng Cao, Jinzhu Yang, Osmar R. Zaiane|<http://arxiv.org/pdf/2506.10675v1>|[代码](https://github.com/jwxsp1/ConStyX.); 提出ConStyX方法，通过内容与风格增强训练数据，提升医学图像分割模型的泛化性能。|
|🆕 发布|Anatomy-Grounded Weakly Supervised Prompt Tuning for Chest X-ray Latent Diffusion Models|基于解剖学基础的弱监督提示微调用于胸部X射线潜在扩散模型|Konstantinos Vilouras, Ilias Stogiannidis, Junyu Yan, Alison Q. O'Neil, Sotirios A. Tsaftaris|<http://arxiv.org/pdf/2506.10633v1>|提出了一种基于解剖学知识的弱监督微调方法，提升了医学影像模型的多模态对齐性能。|
|🆕 发布|MedSeg-R: Reasoning Segmentation in Medical Images with Multimodal Large Language Models|医学图像中的推理分割：基于多模态大型语言模型|Yu Huang, Zelin Peng, Yichen Zhao, Piao Yang, Xiaokang Yang, Wei Shen|<http://arxiv.org/pdf/2506.10465v1>|提出了一种结合大型多模态语言模型推理能力的医疗图像分割框架，实现了根据复杂指令生成精确分割掩模。|
|🆕 发布|RealKeyMorph: Keypoints in Real-world Coordinates for Resolution-agnostic Image Registration|《RealKeyMorph：基于实际坐标的关键点用于分辨率无关的图像配准》|Mina C. Moghadam, Alan Q. Wang, Omer Taub, Martin R. Prince, Mert R. Sabuncu|<http://arxiv.org/pdf/2506.10344v1>|提出了一种无需固定分辨率重采样的图像配准方法RealKeyMorph，通过学习真实世界坐标中的关键点...|
|🆕 发布|SWDL: Stratum-Wise Difference Learning with Deep Laplacian Pyramid for Semi-Supervised 3D Intracranial Hemorrhage Segmentation|分层差异学习：基于深度拉普拉斯金字塔的半监督三维颅内出血分割|Cheng Wang, Siqi Chen, Donghua Mi, Yang Chen, Yudong Zhang, Yinsheng Li|<http://arxiv.org/pdf/2506.10325v1>|[代码](https://github.com/SIAT-CT-LAB/SWDL.); 提出了一种结合Laplacian金字塔和深度卷积的半监督学习框架，有效提升了少量标注数据下的3D颅内...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|IQE-CLIP: Instance-aware Query Embedding for Zero-/Few-shot Anomaly Detection in Medical Domain|IQE-CLIP：面向医疗领域零样本/少样本异常检测的实例感知查询嵌入|Hong Huang, Weixiang Sun, Zhijian Wu, Jingwen Niu, Donghuan Lu, Xian Wu, Yefeng Zheng|<http://arxiv.org/pdf/2506.10730v2>|[代码](https://github.com/hongh0/IQE-CLIP); 提出了一种结合文本和视觉信息的查询嵌入框架IQE-CLIP，用于医疗领域的零样本和少样本异常检测。|
|📝 更新|Enhancing Glass Defect Detection with Diffusion Models: Addressing Imbalanced Datasets in Manufacturing Quality Control|利用扩散模型增强玻璃缺陷检测：解决制造质量控制中的数据集不平衡问题|Sajjad Rezvani Boroujeni, Hossein Abedi, Tom Bush|<http://arxiv.org/pdf/2505.03134v2>|利用去噪扩散概率模型生成合成缺陷图像，有效解决玻璃制造中数据集不平衡问题，显著提升缺陷检测准确率。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Poutine: Vision-Language-Trajectory Pre-Training and Reinforcement Learning Post-Training Enable Robust End-to-End Autonomous Driving|“Poutine：视觉-语言-轨迹预训练与强化学习后训练助力稳健的端到端自动驾驶”|Luke Rowe, Rodrigue de Schaetzen, Roger Girgis, Christopher Pal, Liam Paull|<http://arxiv.org/pdf/2506.11234v1>|提出Poutine模型，通过大规模视觉语言轨迹预训练和强化学习微调，实现了长尾驾驶场景下的端到端自动...|
|📝 更新|AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving|“AgentThink：面向自动驾驶的视觉语言模型中工具增强链式思维推理的统一框架”|Kangan Qian, Sicong Jiang, Yang Zhong, Ziang Luo, Zilin Huang, Tianze Zhu, Kun Jiang, Mengmeng Yang .etc.|<http://arxiv.org/pdf/2505.15298v3>|提出AgentThink框架，首次结合链式思维推理与动态工具调用，显著提升自动驾驶任务中的推理质量和...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Semantic-decoupled Spatial Partition Guided Point-supervised Oriented Object Detection|语义解耦的空间划分引导点监督定向目标检测|Xinyuan Liu, Hang Xu, Yike Ma, Yucheng Zhang, Feng Dai|<http://arxiv.org/pdf/2506.10601v1>|[代码](https://github.com/antxinyuan/ssp.); 提出SSP框架，通过像素级空间划分和语义地图调制提升面向高密度场景的远程感知定向目标检测性能。|
|🆕 发布|Semantic Localization Guiding Segment Anything Model For Reference Remote Sensing Image Segmentation|语义定位引导的Segment Anything模型用于参考遥感图像分割|Shuyang Li, Shuang Wang, Zhuangzhuang Sun, Jing Xiao|<http://arxiv.org/pdf/2506.10503v1>|提出两阶段框架PSLG-SAM，通过视觉定位和精细分割提升遥感图像基于文本描述的分割性能。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 可解释视觉智能 (Explainable Visual Intelligence)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Images to Insights: Explainable Biodiversity Monitoring with Plain Language Habitat Explanations|从图像到洞察：基于通俗易懂生境解释的可解释生物多样性监测|Yutong Zhou, Masahiro Ryo|<http://arxiv.org/pdf/2506.10559v1>|提出了一种将物种图像转化为可解释的栖息地偏好因果洞察的端到端框架，助力非专业人士理解生态系统和保护生...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Rethinking Random Masking in Self Distillation on ViT|重新思考在ViT自蒸馏中的随机遮罩策略|Jihyeon Seong, Hyunkyung Han|<http://arxiv.org/pdf/2506.10582v1>|提出了一种针对Vision Transformers的自蒸馏框架中不对称随机遮蔽策略，有效保留了关键...|

