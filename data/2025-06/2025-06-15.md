## [UPDATED!] **2025-06-15** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Boundary-Aware Vision Transformer for Angiography Vascular Network Segmentation|边界感知视觉变换器用于血管造影血管网络分割|Nabil Hezil, Suraj Singh, Vita Vlasova, Oleg Rogov, Ahmed Bouridane, Rifat Hamoudi|<http://arxiv.org/pdf/2506.12980v1>|提出Boundary-Aware Vision Transformer，通过边缘感知损失提升血管网络...|
|🆕 发布|DuoFormer: Leveraging Hierarchical Representations by Local and Global Attention Vision Transformer|杜构former：通过局部和全局注意力视觉变换器利用层次化表示|Xiaoya Tang, Bodong Zhang, Man Minh Ho, Beatrice S. Knudsen, Tolga Tasdizen|<http://arxiv.org/pdf/2506.12982v1>|[代码](https://github.com/xiaoyatang/DuoFormer.git.); 提出了一种融合CNN与Vision Transformer的 hierarchical transf...|
|🆕 发布|EraserDiT: Fast Video Inpainting with Diffusion Transformer Model|擦除差分变换：基于扩散变换模型的快速视频修复|Jie Liu, Zheng Hui|<http://arxiv.org/pdf/2506.12853v1>|[代码](https://jieliu95.github.io/EraserDiT_demo.); 提出了一种基于扩散变换器的快速视频修复方法，有效解决了大范围遮挡区域的修复质量和时间一致性难题。|
|🆕 发布|GM-LDM: Latent Diffusion Model for Brain Biomarker Identification through Functional Data-Driven Gray Matter Synthesis|GM-LDM：通过功能数据驱动的灰质合成进行大脑生物标志物识别的潜在扩散模型|Hu Xu, Yang Jingling, Jia Sihan, Bi Yuda, Calhoun Vince|<http://arxiv.org/pdf/2506.12719v1>|提出GM-LDM框架，通过融合3D自编码器和Vision Transformer优化MRI生成，实现...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PARTONOMY: Large Multimodal Models with Part-Level Visual Understanding|部分本体论：具有部分级别视觉理解的大型多模态模型|Ansel Blume, Jeonghwan Kim, Hyeonjeong Ha, Elen Chatikyan, Xiaomeng Jin, Khanh Duy Nguyen, Nanyun Peng, Kai-Wei Chang .etc.|<http://arxiv.org/pdf/2505.20759v2>|提出PARTONOMY基准，挑战大型多模态模型在部件级视觉理解上的不足，并引入PLUM模型以提升其性...|
|📝 更新|VideoDeepResearch: Long Video Understanding With Agentic Tool Using|视频深度研究：使用代理工具进行长视频理解的探索|Huaying Yuan, Zheng Liu, Junjie Zhou, Hongjin Qian, Ji-Rong Wen, Zhicheng Dou|<http://arxiv.org/pdf/2506.10821v2>|提出了一种基于文本推理模型和多功能工具包的框架，实现了长视频理解任务的显著性能提升。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning to Fuse: Modality-Aware Adaptive Scheduling for Robust Multimodal Foundation Models|学习融合：面向稳健多模态基础模型的模态感知自适应调度|Liam Bennett, Mason Clark, Lucas Anderson, Hana Satou, Olivia Martinez|<http://arxiv.org/pdf/2506.12733v1>|提出了一种自适应调节多模态数据融合权重的框架，增强了模型在噪声和域偏移下的鲁棒性。|
|🆕 发布|Dynamic Modality Scheduling for Multimodal Large Models via Confidence, Uncertainty, and Semantic Consistency|通过置信度、不确定性和语义一致性进行多模态大型模型的动态模态调度|Hiroshi Tanaka, Anika Rao, Hana Satou, Michael Johnson, Sofia García|<http://arxiv.org/pdf/2506.12724v1>|提出动态模态调度方法，根据样本级别的置信度、不确定性和语义一致性调整模态贡献，提升多模态大模型性能。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Scene-aware SAR ship detection guided by unsupervised sea-land segmentation|基于无监督海陆分割的场景感知合成孔径雷达船舶检测|Han Ke, Xiao Ke, Ye Yan, Rui Liu, Jinpeng Yang, Tianwen Zhang, Xu Zhan, Xiaowo Xu|<http://arxiv.org/pdf/2506.12775v1>|提出了一种基于无监督海陆分割的Scene-aware SAR船舶检测方法，通过减少对陆地的关注来提高...|
|🆕 发布|Probing Deep into Temporal Profile Makes the Infrared Small Target Detector Much Better|深入探究时间剖面使得红外小目标检测性能大幅提升|Ruojing Li, Wei An, Xinyi Ying, Yingqian Wang, Yimian Dai, Longguang Wang, Miao Li, Yulan Guo .etc.|<http://arxiv.org/pdf/2506.12766v1>|[代码](https://github.com/TinaLRJ/DeepPro.); 提出了一种专注于时间剖面信息的红外小目标检测方法，大幅提升了复杂场景下的检测性能和效率。|
|📝 更新|It's Not the Target, It's the Background: Rethinking Infrared Small Target Detection via Deep Patch-Free Low-Rank Representations|“不是目标，而是背景：通过深度无补丁低秩表示重新思考红外小目标检测”|Guoyi Zhang, Guangsheng Xu, Siyang Chen, Han Wang, Xiaohu Zhang|<http://arxiv.org/pdf/2506.10425v2>|提出了一种不依赖图像块处理的端到端红外小目标检测框架，通过直接学习低秩背景结构提高了检测准确性和效率...|
|📝 更新|VIViT: Variable-Input Vision Transformer Framework for 3D MR Image Segmentation|VIViT：用于三维磁共振图像分割的可变输入视觉变换器框架|Badhan Kumar Das, Ajay Singh, Gengyan Zhao, Han Liu, Thomas J. Re, Dorin Comaniciu, Eli Gibson, Andreas Maier|<http://arxiv.org/pdf/2505.08693v2>|提出VIViT框架，通过自监督预训练适应多对比度MR图像，提升3D医学图像分割性能。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MGDFIS: Multi-scale Global-detail Feature Integration Strategy for Small Object Detection|多尺度全局-细节特征融合策略用于小目标检测（MGDFIS）|Yuxiang Wang, Xuecheng Bai, Boyu Hu, Chuanzhi Xu, Haodong Chen, Vera Chung, Tingxue Li|<http://arxiv.org/pdf/2506.12697v1>|提出了一种多尺度全局细节特征融合策略，有效提升了无人机影像中微小目标检测的准确性和效率。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Combining Self-attention and Dilation Convolutional for Semantic Segmentation of Coal Maceral Groups|结合自注意力与扩张卷积进行煤岩组语义分割|Zhenghao Xi, Zhengnan Lv, Yang Zheng, Xiang Liu, Zhuang Yu, Junran Chen, Jing Hu, Yaqi Liu|<http://arxiv.org/pdf/2506.12712v1>|提出物联网增强的DA-VIT网络，结合自注意力与扩张卷积，提升煤岩组图像分割精度且减少参数量。|


## 生成式视觉模型 (Generative Visual Modeling)


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content|Q-Eval-100K：评估文本到视觉内容的视觉质量和对齐级别|Zicheng Zhang, Tengchuan Kou, Shushi Wang, Chunyi Li, Wei Sun, Wei Wang, Xiaoyu Li, Zongyu Wang .etc.|<http://arxiv.org/pdf/2503.02357v3>|[代码](https://github.com/zzc-1998/Q-Eval.); 提出Q-EVAL-100K数据集和Q-Eval-Score模型，用于评估视觉质量和内容对齐度，实现卓...|
|📝 更新|AccDiffusion v2: Towards More Accurate Higher-Resolution Diffusion Extrapolation|AccDiffusion v2：迈向更精确的高分辨率扩散外推|Zhihang Lin, Mingbao Lin, Wengyi Zhan, Rongrong Ji|<http://arxiv.org/pdf/2412.02099v2>|[代码](https://github.com/lzhxmu/AccDiffusion_v2.); AccDiffusion v2通过创新的分块精确提示和引入局部结构信息，有效解决了高分辨率图像生成中...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Active Adversarial Noise Suppression for Image Forgery Localization|主动对抗性噪声抑制在图像伪造定位中的应用|Rongxuan Peng, Shunquan Tan, Xianbo Mo, Alex C. Kot, Jiwu Huang|<http://arxiv.org/pdf/2506.12871v1>|提出对抗性噪声抑制模块以抵御攻击，通过特征分布对齐和掩码引导优化，有效提升图像伪造定位模型对对抗样本...|
|🆕 发布|DiffS-NOCS: 3D Point Cloud Reconstruction through Coloring Sketches to NOCS Maps Using Diffusion Models|通过扩散模型将着色草图转换为NOCS图的三维点云重建：DiffS-NOCS|Di Kong, Qianhui Wan|<http://arxiv.org/pdf/2506.12835v1>|提出DiffS-NOCS方法，通过控制扩散模型从草图生成NOCS图，实现精准的3D点云重建。|
|🆕 发布|iDiT-HOI: Inpainting-based Hand Object Interaction Reenactment via Video Diffusion Transformer|基于图像修复的手物体交互重演：通过视频扩散变换器实现|Zhelun Shen, Chenming Wu, Junsheng Zhou, Chen Zhao, Kaisiyuan Wang, Hang Zhou, Yingying Li, Haocheng Feng .etc.|<http://arxiv.org/pdf/2506.12847v1>|提出了一种基于视频扩散变换器的 HOI 重建框架，通过重用预训练模型实现了对未见场景的强泛化能力。|
|📝 更新|Faces of the Mind: Unveiling Mental Health States Through Facial Expressions in 11,427 Adolescents|心灵之颜：通过11,427名青少年的面部表情揭示心理健康状态|Xiao Xu, Xizhe Zhang, Yan Zhang|<http://arxiv.org/pdf/2405.20072v2>|提出Symptom Discrepancy Index减少数据集异质性，提升抑郁和焦虑面部识别模型准...|
|📝 更新|Physics-informed DeepCT: Sinogram Wavelet Decomposition Meets Masked Diffusion|物理信息增强的深度CT：正弦图小波分解与掩码扩散相结合|Zekun Zhou, Tan Liu, Bing Yu, Yanru Gong, Liu Shi, Qiegen Liu|<http://arxiv.org/pdf/2501.09935v2>|提出SWARM模型，通过随机掩码策略和波let分解增强CT重建的泛化能力和细节捕捉。|
|📝 更新|Marrying Autoregressive Transformer and Diffusion with Multi-Reference Autoregression|将自回归变换器与扩散结合的多参考自回归方法|Dingcheng Zhen, Qian Qiao, Tan Yu, Kangxi Wu, Ziwei Zhang, Siyuan Liu, Shunshun Yin, Ming Tao|<http://arxiv.org/pdf/2506.09482v2>|结合自回归变换器和扩散模型，提出了一种新的图像生成方法TransDiff，显著提升了生成图像质量和推...|
|🆕 发布|3D Hand Mesh-Guided AI-Generated Malformed Hand Refinement with Hand Pose Transformation via Diffusion Model|三维手部网格引导的AI生成畸形手部细化通过手部姿态变换的扩散模型|Chen-Bin Feng, Kangdao Liu, Jian Sun, Jiping Jin, Yiguo Jiang, Chi-Man Vong|<http://arxiv.org/pdf/2506.12680v1>|提出了一种基于3D手部网格引导的扩散模型，有效改善了AI生成图像中手部形态的准确性并实现了手部姿态变...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning Unpaired Image Dehazing with Physics-based Rehazy Generation|基于物理的复原图生成无配对图像去雾学习|Haoyou Deng, Zhiqiang Li, Feng Zhang, Qingbo Lu, Zisheng Cao, Yuanjie Shao, Shuhang Gu, Changxin Gao .etc.|<http://arxiv.org/pdf/2506.12824v1>|提出了一种基于物理的未配对图像去雾训练策略，通过构建 haze-rehazy 对提高去雾性能和训练稳...|
|🆕 发布|ComplexBench-Edit: Benchmarking Complex Instruction-Driven Image Editing via Compositional Dependencies|复杂指令驱动图像编辑的组合依赖性基准测试：ComplexBench-Edit|Chenglin Wang, Yucheng Zhou, Qianning Wang, Zhe Wang, Kai Zhang|<http://arxiv.org/pdf/2506.12830v1>|[代码](https://github.com/llllly26/ComplexBench-Edit.); 提出了ComplexBench-Edit基准，用于评估模型处理复杂图像编辑指令的能力，并提出了Cha...|
|🆕 发布|A large-scale, physically-based synthetic dataset for satellite pose estimation|大规模基于物理的合成数据集用于卫星姿态估计|Szabolcs Velkei, Csaba Goldschmidt, Károly Vass|<http://arxiv.org/pdf/2506.12782v1>|介绍了DLVS3-HST-V1合成数据集，助力卫星姿态估计训练，缩小现实与模拟间的差距。|
|📝 更新|ARFlow: Autoregressive Flow with Hybrid Linear Attention|ARFlow：具有混合线性注意力的自回归流模型|Mude Hui, Rui-Jie Zhu, Songlin Yang, Yu Zhang, Zirui Wang, Yuyin Zhou, Jason Eshraghian, Cihang Xie|<http://arxiv.org/pdf/2501.16085v2>|将自回归模型与流模型结合，通过构建因果序列和定制注意力机制，有效建模图像生成中的长距离依赖。|
|📝 更新|Video Depth Anything: Consistent Depth Estimation for Super-Long Videos|视频深度任意：超长视频的一致深度估计|Sili Chen, Hengkai Guo, Shengnan Zhu, Feihu Zhang, Zilong Huang, Jiashi Feng, Bingyi Kang|<http://arxiv.org/pdf/2501.12375v3>|提出了针对超长视频的高效一致深度估计方法，通过时空头部和关键帧策略，实现了无需牺牲效率的高质量深度估...|
|🆕 发布|Adapting by Analogy: OOD Generalization of Visuomotor Policies via Functional Correspondence|通过类比适应：通过功能对应实现视觉运动策略的OOD泛化|Pranay Gupta, Henny Admoni, Andrea Bajcsy|<http://arxiv.org/pdf/2506.12678v1>|提出了一种通过功能对应关系实现视觉运动策略在未知环境下的泛化方法，有效利用少量反馈提升机器人行为适应...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Adaptive Dropout: Unleashing Dropout across Layers for Generalizable Image Super-Resolution|自适应丢弃：在层间释放丢弃以实现泛化的图像超分辨率|Hang Xu, Wei Yu, Jiangtong Tan, Zhen Zou, Feng Zhao|<http://arxiv.org/pdf/2506.12738v1>|[代码](https://github.com/xuhang07/Adpative-Dropout); 提出自适应dropout方法，通过在中间层引入正则化，有效提升盲超分辨率模型的泛化能力。|
|📝 更新|FATE: Focal-modulated Attention Encoder for Multivariate Time-series Forecasting|FATE：基于焦点调制注意力的多变量时间序列预测编码器|Tajamul Ashraf, Janibul Bashir|<http://arxiv.org/pdf/2408.11336v2>|[代码](https://github.com/Tajamul21/FATE.); 提出了一种名为Focal Modulated Attention Encoder的模型，通过捕捉时间...|
|📝 更新|Physics-informed generative real-time lens-free imaging|物理信息驱动的生成实时无透镜成像|Ronald B. Liu, Zhe Liu, Max G. A. Wolf, Krishna P. Purohit, Gregor Fritz, Yi Feng, Carsten G. Hansen, Pierre O. Bagnaninchi .etc.|<http://arxiv.org/pdf/2403.07786v4>|提出GenLFI方法，利用物理信息生成神经网络实现大视场实时无透镜成像。|
|🆕 发布|Generative 4D Scene Gaussian Splatting with Object View-Synthesis Priors|基于物体视图合成先验的四维场景高斯散点生成|Wen-Hsuan Chu, Lei Ke, Jianmeng Liu, Mingxiao Huo, Pavel Tokmakov, Katerina Fragkiadaki|<http://arxiv.org/pdf/2506.12716v1>|提出了一种生成4D动态场景的新方法GenMOJO，通过整合基于渲染的3D高斯优化和生成先验，实现了对...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Metropolis-Hastings Sampling for 3D Gaussian Reconstruction|“基于Metropolis-Hastings采样的三维高斯重建”|Hyunjin Kim, Haebeom Jung, Jaesik Park|<http://arxiv.org/pdf/2506.12945v1>|提出了一种自适应采样框架，通过Metropolis-Hastings方法优化3D高斯重建，减少计算量...|
|📝 更新|Deblur-Avatar: Animatable Avatars from Motion-Blurred Monocular Videos|《去模糊化Avatar：从运动模糊的单目视频中创建可动画化Avatar》|Xianrui Luo, Juewen Peng, Zhongang Cai, Lei Yang, Fan Yang, Zhiguo Cao, Guosheng Lin|<http://arxiv.org/pdf/2501.13335v3>|提出了一种针对运动模糊的单目视频重建高质量动态3D人类角色的新框架。|
|🆕 发布|SMPL Normal Map Is All You Need for Single-view Textured Human Reconstruction|单视图纹理化人体重建仅需SMPL法线图|Wenhao Shen, Gangjian Zhang, Jianfeng Zhang, Yu Feng, Nanjie Yao, Xuanmeng Zhang, Hao Wang|<http://arxiv.org/pdf/2506.12793v1>|提出了一种结合SMPL正常图的3D人体重建框架，无需预设扩散模型即可实现单视角纹理人体重建。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Efficient Neural Video Representation via Structure-Preseving Patch Decoding|通过结构保持的补丁解码实现高效的神经视频表示|Taiga Hayami, Kakeru Koizumi, Hiroshi Watanabe|<http://arxiv.org/pdf/2506.12896v1>|提出结构保持分块解码方法，提升神经视频表示的质量和压缩性能。|
|🆕 发布|Rasterizing Wireless Radiance Field via Deformable 2D Gaussian Splatting|通过可变形二维高斯散点绘制无线辐射场|Mufan Liu, Cixiao Zhang, Qi Yang, Yujie Cao, Yiling Xu, Yin Xu, Shu Sun, Mingzeng Dai .etc.|<http://arxiv.org/pdf/2506.12787v1>|提出高效Gaussian splatting框架SwiftWRF，实现快速准确的无线辐射场重建。|
|🆕 发布|Efficient multi-view training for 3D Gaussian Splatting|三维高斯散点投射的高效多视角训练|Minhyuk Choi, Injae Kim, Hyunwoo J. Kim|<http://arxiv.org/pdf/2506.12727v1>|提出多视角训练策略，优化3D Gaussian Splatting性能，克服单视角训练局限。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SmartHome-Bench: A Comprehensive Benchmark for Video Anomaly Detection in Smart Homes Using Multi-Modal Large Language Models|智能家居基准：使用多模态大型语言模型进行智能家居视频异常检测的全面基准|Xinyi Zhao, Congjing Zhang, Pei Guo, Wei Li, Lin Chen, Chaoyue Zhao, Shuai Huang|<http://arxiv.org/pdf/2506.12992v1>|[代码](https://github.com/Xinyi-0724/SmartHome-Bench-LLM.); 提出SmartHome-Bench基准，针对智能家庭视频异常检测，引入TRLC框架提升检测准确率。|
|📝 更新|Unmasking Deep Fakes: Leveraging Deep Learning for Video Authenticity Detection|《揭示深度伪造：利用深度学习进行视频真实性检测》|Mahmudul Hasan, Sadia Ruhama, Sabrina Tajnim Sithi, Chowdhury Mohammad Mutamir Samit, Oindrila Saha|<http://arxiv.org/pdf/2505.06528v2>|提出了一种基于深度学习的视频真伪检测方法，有效识别Deepfake视频中的细微不一致性。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Fine-Grained Emotion Understanding via Skeleton-Based Micro-Gesture Recognition|基于骨架的微动作识别向精细化情感理解迈进|Hao Xu, Lechao Cheng, Yaxiong Wang, Shengeng Tang, Zhun Zhong|<http://arxiv.org/pdf/2506.12848v1>|[代码](https://github.com/EGO-False-Sleep/Miga25_track1); 提出了一种基于骨架序列的微手势识别方法，用于细粒度情感理解，通过改进骨架表示、时间处理策略和引入语义...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Leveraging MIMIC Datasets for Better Digital Health: A Review on Open Problems, Progress Highlights, and Future Promises|利用MIMIC数据集提升数字健康：关于开放性问题、进展亮点与未来展望的综述|Afifa Khaled, Mohammed Sabir, Rizwan Qureshi, Camillo Maria Caruso, Valerio Guarrasi, Suncheng Xiang, S Kevin Zhou|<http://arxiv.org/pdf/2506.12808v1>|系统梳理MIMIC数据集在数字健康领域的挑战与进展，提出解决数据集成、表示和互操作性问题的方向。|
|📝 更新|SWAG: Long-term Surgical Workflow Prediction with Generative-based Anticipation|SWAG：基于生成式预测的长期手术工作流预测|Maxence Boels, Yang Liu, Prokar Dasgupta, Alejandro Granados, Sebastien Ourselin|<http://arxiv.org/pdf/2412.18849v4>|提出SWAG框架，结合生成式方法预测手术流程中的长期步骤，提高阶段预测准确性。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CASE: Contrastive Activation for Saliency Estimation|CASE: 对比激活用于显著性估计|Dane Williamson, Yangfeng Ji, Matthew Dwyer|<http://arxiv.org/pdf/2506.07327v3>|提出了一种新的对比性激活方法CASE，用于生成更忠实且针对特定类别的显著性解释。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LOP: Learning Optimal Pruning for Efficient On-Demand MLLMs Scaling|学习最优剪枝以实现高效按需多模态大型语言模型缩放|Zhihan Zhang, Xiang Pan, Hongchen Wei, Zhenzhong Chen|<http://arxiv.org/pdf/2506.12826v1>|提出了一种学习最优剪枝策略的LOP框架，无需迭代搜索即可高效适应多模态大语言模型在不同硬件上的部署。|
|📝 更新|LPO: Towards Accurate GUI Agent Interaction via Location Preference Optimization|LPO：通过位置偏好优化实现精确的GUI智能体交互|Jiaqi Tang, Yu Xia, Yi-Feng Wu, Yuwei Hu, Yuhui Chen, Qing-Guo Chen, Xiaogang Xu, Xiangyu Wu .etc.|<http://arxiv.org/pdf/2506.09373v2>|[代码](https://github.com/AIDC-AI/LPO.); 提出了一种利用位置偏好优化的方法LPO，通过强化位置信息处理，显著提升了GUI智能体的交互精度。|
|🆕 发布|Cross-architecture universal feature coding via distribution alignment|跨架构通用特征编码：通过分布对齐实现|Changsheng Gao, Shan Liu, Feng Wu, Weisi Lin|<http://arxiv.org/pdf/2506.12737v1>|提出了一种跨架构通用特征编码方法，通过分布对齐实现CNN和Transformer特征的统一压缩。|
|🆕 发布|NAP-Tuning: Neural Augmented Prompt Tuning for Adversarially Robust Vision-Language Models|神经增强提示调优：面向对抗性稳健的视觉-语言模型的NAP-Tuning|Jiaming Zhang, Xin Wang, Xingjun Ma, Lingyu Qiu, Yu-Gang Jiang, Jitao Sang|<http://arxiv.org/pdf/2506.12706v1>|提出了一种多模态神经增强对抗性提示调谐方法，有效提升了视觉语言模型对对抗性攻击的鲁棒性。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Predicting Genetic Mutations from Single-Cell Bone Marrow Images in Acute Myeloid Leukemia Using Noise-Robust Deep Learning Models|利用噪声鲁棒深度学习模型从急性髓细胞性白血病单个骨髓细胞图像预测基因突变|Garima Jain, Ravi Kant Gupta, Priyansh Jain, Abhijeet Patil, Ardhendu Sekhar, Gajendra Smeeta, Sanghamitra Pati, Amit Sethi|<http://arxiv.org/pdf/2506.12798v1>|提出了一种抗噪声深度学习方法，从单个细胞骨髓图像中预测急性髓细胞性白血病的遗传突变。|
|📝 更新|ICE-Pruning: An Iterative Cost-Efficient Pruning Pipeline for Deep Neural Networks|ICE-剪枝：一种深度神经网络迭代的成本高效剪枝流程|Wenhao Hu, Paul Henderson, José Cano|<http://arxiv.org/pdf/2505.07411v2>|[代码](https://github.com/gicLAB/ICE-Pruning); 提出了一种降低深度神经网络剪枝总体成本的ICE-Pruning方法，减少了 fine-tuning ...|
|🆕 发布|SP-VLA: A Joint Model Scheduling and Token Pruning Approach for VLA Model Acceleration|SP-VLA：一种联合模型调度与令牌剪枝的VLA模型加速方法|Ye Li, Yuan Meng, Zewen Sun, Kangye Ji, Chen Tang, Jiajun Fan, Xinzhu Ma, Shutao Xia .etc.|<http://arxiv.org/pdf/2506.12723v1>|提出了一种联合模型调度和令牌剪枝的框架，有效降低视觉语言动作模型的计算成本，实现实时任务加速。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Intriguing Frequency Interpretation of Adversarial Robustness for CNNs and ViTs|卷积神经网络与视觉变换器的对抗稳健性的频率解释探究|Lu Chen, Han Yang, Hu Wang, Yuxin Cao, Shaofeng Li, Yuan Luo|<http://arxiv.org/pdf/2506.12875v1>|揭示了对抗样本在频率域的特性，指出不同网络架构对频率成分的偏好影响模型鲁棒性。|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Model-Agnostic, Temperature-Informed Sampling Enhances Cross-Year Crop Mapping with Deep Learning|模型无关、温度指导的采样增强深度学习在跨年度作物映射中的应用|Mehmet Ozgur Turkoglu, Selene Ledain, Helge Aasen|<http://arxiv.org/pdf/2506.12885v1>|提出基于温度信息的采样策略，提升跨年度作物分类准确性和不确定性估计。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unsupervised Contrastive Learning Using Out-Of-Distribution Data for Long-Tailed Dataset|无监督对比学习：使用非分布内数据处理长尾数据集|Cuong Manh Hoang, Yeejin Lee, Byeongkeun Kang|<http://arxiv.org/pdf/2506.12698v1>|提出利用未标记的分布外数据，通过自监督学习改善长尾数据集的表示平衡性和分离性。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|What Do You See in Common? Learning Hierarchical Prototypes over Tree-of-Life to Discover Evolutionary Traits|你在常见事物中看到了什么？在生命树上学层次原型以发现进化特征|Harish Babu Manogaran, M. Maruf, Arka Daw, Kazi Sajeed Mehrab, Caleb Patrick Charpentier, Josef C. Uyeda, Wasila Dahdul, Matthew J Thompson .etc.|<http://arxiv.org/pdf/2409.02335v2>|提出了一种新型网络HComP-Net，通过学习生物图像中的层次原型，有效发现进化特征。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Zero-shot denoising via neural compression: Theoretical and algorithmic framework|零样本去噪通过神经压缩：理论与算法框架|Ali Zafari, Xi Chen, Shirin Jalali|<http://arxiv.org/pdf/2506.12693v1>|[代码](https://github.com/Computational-Imaging-RU/ZS-NCDenoiser.); 提出零样本神经压缩去噪框架，无需训练样本即可实现去噪，达到当前最佳性能。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Unifying Specialized Visual Encoders for Video Language Models|统一专业视觉编码器以用于视频语言模型|Jihoon Chung, Tyler Zhu, Max Gonzalez Saez-Diez, Juan Carlos Niebles, Honglu Zhou, Olga Russakovsky|<http://arxiv.org/pdf/2501.01426v2>|MERV通过使用多个视觉编码器创建统一视频表示，提升了视频理解能力，优于现有单编码器方法。|
|🆕 发布|Semantic-Aware Visual Information Transmission With Key Information Extraction Over Wireless Networks|面向语义感知的无线网络中关键信息提取的视觉信息传输|Chen Zhu, Kang Liang, Jianrong Bao, Zhouxiang Zhao, Zhaohui Yang, Zhaoyang Zhang, Mohammad Shikh-Bahaei|<http://arxiv.org/pdf/2506.12786v1>|提出一种针对6G网络的AI原生深度联合源信道编码框架，通过关键信息提取和自适应背景合成实现智能语义感...|
|🆕 发布|Native Visual Understanding: Resolving Resolution Dilemmas in Vision-Language Models|原生视觉理解：在视觉-语言模型中解决分辨率困境|Junbo Niu, Yuanhong Zheng, Ziyang Miao, Hejun Dong, Chunjiang Ge, Hao Liang, Ma Lu, Bohan Zeng .etc.|<http://arxiv.org/pdf/2506.12776v1>|[代码](https://github.com/Niujunbo2002/NativeRes-LLaVA.); 提出RC-Bench基准和NativeRes-LLaVA框架，解决视觉语言模型处理不同分辨率图像的挑...|
|🆕 发布|Evaluating Cell Type Inference in Vision Language Models Under Varying Visual Context|在变化的视觉上下文中评估视觉语言模型中的细胞类型推断|Samarth Singhal, Sandeep Singhal|<http://arxiv.org/pdf/2506.12683v1>|[代码](https://github.com/a12dongithub/VLMCCE.); 评估了视觉语言模型在病理图像细胞分类任务中的表现，发现一阶段提示能显著提升性能但仍低于监督训练的卷积...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CAPO: Reinforcing Consistent Reasoning in Medical Decision-Making|CAPO：在医疗决策中强化一致性推理|Songtao Jiang, Yuan Wang, Ruizhe Chen, Yan Zhang, Ruilin Luo, Bohan Lei, Sibo Song, Yang Feng .etc.|<http://arxiv.org/pdf/2506.12849v1>|提出了一种大规模强化学习框架CAPO，通过确保感知与推理的一致性和推理到答案的连贯性，提升了医疗视觉...|
|📝 更新|Semantic Segmentation Based Quality Control of Histopathology Whole Slide Images|基于语义分割的病理全切片图像质量控制|Abhijeet Patil, Garima Jain, Harsh Diwakar, Jay Sawant, Tripti Bameta, Swapnil Rane, Amit Sethi|<http://arxiv.org/pdf/2410.03289v2>|[代码](https://github.com/abhijeetptl5/wsisegqc); 提出了一种基于深度学习的病理切片质量控制流程，通过多模型平衡准确性与速度，提升了分割效果。|
|🆕 发布|Unleashing Diffusion and State Space Models for Medical Image Segmentation|释放扩散与状态空间模型在医学图像分割中的应用|Rong Wu, Ziqi Chen, Liming Zhong, Heng Li, Hai Shu|<http://arxiv.org/pdf/2506.12747v1>|[代码](https://github.com/Rows21/KMax-Mamba.); 提出DSM框架，结合扩散与状态空间模型，实现对训练数据外未见肿瘤类别的精准分割。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HyRet-Change: A hybrid retentive network for remote sensing change detection|HyRet-Change：一种用于遥感变化检测的混合保持网络|Mustansar Fiaz, Mubashir Noman, Hiyam Debary, Kamran Ali, Hisham Cholakkal|<http://arxiv.org/pdf/2506.12836v1>|[代码](https://github.com/mustansarfiaz/HyRect-Change.); 提出了一种融合卷积和保持机制的HyRet-Change框架，有效缓解伪变化并提升遥感变化检测的准确性...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LATTE: Learning to Think with Vision Specialists|LATTE: 学习与视觉专家一同思考|Zixian Ma, Jianguo Zhang, Zhiwei Liu, Jieyu Zhang, Juntao Tan, Manli Shu, Juan Carlos Niebles, Shelby Heinecke .etc.|<http://arxiv.org/pdf/2412.05479v3>|提出 LATTE 模型，通过将感知任务交给专业视觉模型，提升视觉语言模型处理复杂问题的推理能力。|


### 可解释视觉智能 (Explainable Visual Intelligence)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Unlocking Neural Transparency: Jacobian Maps for Explainable AI in Alzheimer's Detection|解锁神经透明度：阿尔茨海默症检测中用于可解释人工智能的雅可比映射|Yasmine Mustafa, Mohamed Elmahallawy, Tie Luo|<http://arxiv.org/pdf/2504.03230v3>|引入Jacobian Maps增强深度学习模型在阿尔茨海默症早期检测中的可解释性和准确性。|

