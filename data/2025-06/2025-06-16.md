## [UPDATED!] **2025-06-16** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OTFusion: Bridging Vision-only and Vision-Language Models via Optimal Transport for Transductive Zero-Shot Learning|OTFusion：通过最优传输法桥接仅视觉与视觉-语言模型以实现传递式零样本学习|Qiyu Xu, Wenyang Chen, Zhanxuan Hu, Huafeng Li, Yonghang Tai|<http://arxiv.org/pdf/2506.13723v1>|提出了一种结合视觉和视觉-语言模型的训练-free框架OTFusion，通过最优传输方法优化了零样本...|
|🆕 发布|Stream-Omni: Simultaneous Multimodal Interactions with Large Language-Vision-Speech Model|流-全模态：与大型语言-视觉-语音模型的同步多模态交互|Shaolei Zhang, Shoutao Guo, Qingkai Fang, Yan Zhou, Yang Feng|<http://arxiv.org/pdf/2506.13642v1>|提出了一种新型多模态模型Stream-Omni，通过层维映射实现更高效灵活的模态对齐，减少数据需求。|
|🆕 发布|Active Multimodal Distillation for Few-shot Action Recognition|用于少量样本动作识别的主动多模态蒸馏|Weijia Feng, Yichen Zhu, Ruojia Zhang, Chenyang Wang, Fei Ma, Xiaobao Wang, Xiaobai Li|<http://arxiv.org/pdf/2506.13322v1>|提出了一种主动多模态蒸馏框架，通过识别可靠模态显著提升少量样本动作识别性能。|
|🆕 发布|Metis-RISE: RL Incentivizes and SFT Enhances Multimodal Reasoning Model Learning|“Metis-RISE：强化学习激励与软频率调整增强多模态推理模型学习”|Haibo Qiu, Xiaohan Lan, Fanfan Liu, Xiaohu Sun, Delian Ruan, Peng Shi, Lin Ma|<http://arxiv.org/pdf/2506.13056v1>|Metis-RISE通过先用强化学习激励模型潜在推理能力，再用监督微调增强，提升了多模态推理模型的效...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Touch begins where vision ends: Generalizable policies for contact-rich manipulation|接触始于视觉的终结：面向丰富接触操作的泛化策略|Zifan Zhao, Siddhant Haldar, Jinda Cui, Lerrel Pinto, Raunaq Bhirangi|<http://arxiv.org/pdf/2506.13762v1>|分类|
|🆕 发布|Uncertainty-Aware Remaining Lifespan Prediction from Images|基于不确定性的图像剩余寿命预测|Tristan Kenneweg, Philip Kenneweg, Barbara Hammer|<http://arxiv.org/pdf/2506.13430v1>|提出了一种基于预训练视觉变换器模型预测剩余寿命并量化不确定性的方法，实现了最先进的误差表现。|
|📝 更新|Inherently Faithful Attention Maps for Vision Transformers|视觉变换器中的本质忠实注意力图|Ananthu Aniraj, Cassio F. Dantas, Dino Ienco, Diego Marcos|<http://arxiv.org/pdf/2506.08915v2>|[代码](https://github.com/ananthu-aniraj/ifam); 引入二值注意力掩码方法，通过聚焦相关区域增强视觉变换器的鲁棒性。|
|🆕 发布|ViT-NeBLa: A Hybrid Vision Transformer and Neural Beer-Lambert Framework for Single-View 3D Reconstruction of Oral Anatomy from Panoramic Radiographs|ViT-NeBLa：一种混合视觉变换器和神经啤酒-兰伯特框架，用于从全景X射线图像重建口腔解剖结构的三维单视角重建|Bikram Keshari Parida, Anusree P. Sunilkumar, Abhijit Sen, Wonsang You|<http://arxiv.org/pdf/2506.13195v1>|提出ViT-NeBLa模型，利用Vision Transformer和Neural Beer-Lam...|
|🆕 发布|MT-PCR: A Hybrid Mamba-Transformer with Spatial Serialization for Hierarchical Point Cloud Registration|MT-PCR：一种基于空间序列化的曼巴-变压器混合模型用于层次化点云配准|Bingxi Liu, An Liu, Hao Chen, Jinqiang Cui, Yiqun Wang, Hong Zhang|<http://arxiv.org/pdf/2506.13183v1>|提出MT-PCR框架，融合Mamba与Transformer，通过空间序列化提升点云配准的准确性与效...|
|📝 更新|Leveraging Intermediate Features of Vision Transformer for Face Anti-Spoofing|利用视觉变换器中间特征进行人脸防伪|Mika Feng, Koichi Ito, Takafumi Aoki, Tetsushi Ohki, Masakatsu Nishigaki|<http://arxiv.org/pdf/2505.24402v2>|[代码](https://gsisaoki.github.io/FAS-ViT-CVPRW); 提出了一种基于Vision Transformer的活体人脸检测方法，利用其中间特征区分真实与伪造人...|
|📝 更新|Distill CLIP (DCLIP): Enhancing Image-Text Retrieval via Cross-Modal Transformer Distillation|跨模态变换器蒸馏增强图像-文本检索的Distill CLIP（DCLIP）|Daniel Csizmadia, Andrei Codreanu, Victor Sim, Vighnesh Prabhu, Michael Lu, Kevin Zhu, Sean O'Brien, Vasu Sharma|<http://arxiv.org/pdf/2505.21549v4>|提出Distill CLIP模型，通过跨模态蒸馏增强图像-文本检索能力，同时保持零样本分类性能。|
|🆕 发布|DETRPose: Real-time end-to-end transformer model for multi-person pose estimation|DETRPose：用于多人姿态估计的实时端到端Transformer模型|Sebastian Janampa, Marios Pattichis|<http://arxiv.org/pdf/2506.13027v1>|提出了一种基于变压器的实时多人姿态估计模型，训练更快且参数更少。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Foundation Models in Medical Imaging -- A Review and Outlook|医学成像中的基础模型——综述与展望|Vivien van Veldhuizen, Vanessa Botha, Chunyao Lu, Melis Erdal Cesur, Kevin Groot Lipman, Edwin D. de Jong, Hugo Horlings, Clárisa I. Sanchez .etc.|<http://arxiv.org/pdf/2506.09095v3>|概述了基础模型在医学成像领域的应用，通过无监督学习提升临床任务适应性。|
|🆕 发布|Quantitative Comparison of Fine-Tuning Techniques for Pretrained Latent Diffusion Models in the Generation of Unseen SAR Image Concepts|《预训练潜在扩散模型在生成未见SAR图像概念中微调技术的定量比较》|Solène Debuysère, Nicolas Trouvé, Nathan Letheule, Olivier Lévêque, Elise Colin|<http://arxiv.org/pdf/2506.13307v1>|探究并比较了多种微调策略，以适应预训练模型生成未见过的合成孔径雷达图像。|
|🆕 发布|Brain Imaging Foundation Models, Are We There Yet? A Systematic Review of Foundation Models for Brain Imaging and Biomedical Research|大脑成像基础模型，我们是否已经到达那里？针对大脑成像和生物医学研究的基础模型系统性综述|Salah Ghamizi, Georgia Kanli, Yu Deng, Magali Perquin, Olivier Keunen|<http://arxiv.org/pdf/2506.13306v1>|系统评估了大脑成像基础模型，指出了现有研究的不足，并展望了未来发展方向。|
|🆕 发布|GreedyPrune: Retenting Critical Visual Token Set for Large Vision Language Models|GreedyPrune：为大型视觉语言模型保留关键视觉标记集|Ruiguang Pei, Weiqing Sun, Zhihui Fu, Jun Wang|<http://arxiv.org/pdf/2506.13166v1>|提出GreedyPrune算法，平衡语义重要性和视觉多样性以提升大型视觉语言模型的计算效率。|
|🆕 发布|SuperPlace: The Renaissance of Classical Feature Aggregation for Visual Place Recognition in the Era of Foundation Models|《SuperPlace：基础模型时代下经典特征聚合在视觉场景识别中的复兴》|Bingxi Liu, Pengju Zhang, Li He, Hao Chen, Shiyi Guo, Yihong Wu, Jinqiang Cui, Hong Zhang|<http://arxiv.org/pdf/2506.13073v1>|复兴经典特征聚合方法，提出SuperPlace模型，通过监督标签对齐和二次微调策略，提升视觉场景识别...|
|🆕 发布|Stress-Testing Multimodal Foundation Models for Crystallographic Reasoning|对晶体学推理的多模态基础模型进行压力测试|Can Polat, Hasan Kurban, Erchin Serpedin, Mustafa Kurban|<http://arxiv.org/pdf/2506.13051v1>|[代码](https://github.com/KurbanIntelligenceLab/StressTestingMMFMinCR.); 引入多尺度多晶体数据集和物理约束评估协议，以测试多模态基础模型在晶体学推理中的泛化能力。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Adaptive Sensitivity Analysis for Robust Augmentation against Natural Corruptions in Image Segmentation|自适应敏感性分析用于对抗图像分割中自然干扰的鲁棒增强|Laura Zheng, Wenjie Wei, Tony Wu, Jacob Clements, Shreelekha Revankar, Andre Harrison, Yu Shen, Ming C. Lin|<http://arxiv.org/pdf/2406.01425v5>|[代码](https://github.com/laurayuzheng/SensAug.); 提出了一种高效的适应性敏感度分析指导的数据增强方法，大幅提升了图像分割模型对自然干扰的鲁棒性。|
|🆕 发布|Advancing Image-Based Grapevine Variety Classification with a New Benchmark and Evaluation of Masked Autoencoders|基于图像的葡萄品种分类进展：一种新的基准与掩码自编码器的评估|Gabriel A. Carneiro, Thierry J. Aubry, António Cunha, Petia Radeva, Joaquim Sousa|<http://arxiv.org/pdf/2506.13335v1>|提出两个新基准用于葡萄品种图像分类，并验证了基于Masked Autoencoders的自监督学习方...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|XYZ-IBD: A High-precision Bin-picking Dataset for Object 6D Pose Estimation Capturing Real-world Industrial Complexity|XYZ-IBD：面向物体6D位姿估计的高精度料箱拣选数据集，捕捉实际工业复杂性|Junwen Huang, Jizhong Liang, Jiaqi Hu, Martin Sundermeyer, Peter KT Yu, Nassir Navab, Benjamin Busam|<http://arxiv.org/pdf/2506.00599v2>|[代码](https://xyz-ibd.github.io/XYZ-IBD); 介绍了XYZ-IBD数据集，捕捉工业复杂性，为6D姿态估计提供了真实世界挑战。|
|🆕 发布|JENGA: Object selection and pose estimation for robotic grasping from a stack|“JENGA：从堆叠中进行的机器人抓取对象选择与位姿估计”|Sai Srinivas Jeevanandam, Sandeep Inuganti, Shreedhar Govil, Didier Stricker, Jason Rambach|<http://arxiv.org/pdf/2506.13425v1>|提出了一种针对堆叠结构中物体抓取的选择与位姿估计方法，通过优先识别上层未遮挡物体并准确预测6自由度位...|
|🆕 发布|Automatic Multi-View X-Ray/CT Registration Using Bone Substructure Contours|基于骨骼子结构轮廓的自动多视角X射线/CT配准|Roman Flepp, Leon Nissen, Bastian Sigrist, Arend Nieuwland, Nicola Cavalcanti, Philipp Fürnstahl, Thomas Dreher, Lilian Calvet|<http://arxiv.org/pdf/2506.13292v1>|提出了一种基于骨子结构轮廓的多视角X射线/CT自动配准方法，实现了亚毫米级精度并减少了手动干预。|
|🆕 发布|Open-Set LiDAR Panoptic Segmentation Guided by Uncertainty-Aware Learning|开集激光雷达全景分割：基于不确定性感知学习引导|Rohit Mohan, Julia Hindel, Florian Drews, Claudius Gläser, Daniele Cattaneo, Abhinav Valada|<http://arxiv.org/pdf/2506.13265v1>|提出ULOPS框架，通过不确定性学习区分已知和未知物体，提升激光雷达全景分割在开放环境下的性能。|
|📝 更新|Multi-Knowledge-oriented Nighttime Haze Imaging Enhancer for Vision-driven Intelligent Systems|面向多知识驱动的夜间雾霾成像增强器，用于视觉驱动的智能系统|Ai Chen, Yuxu Lu, Dong Yang, Junlin Zhou, Yan Fu, Duanbing Chen|<http://arxiv.org/pdf/2502.07351v4>|提出了一种多知识导向的夜间雾霾图像增强方法，整合了白天去雾、低光增强和夜间去雾任务，提高了智能成像的...|
|📝 更新|A Robust Real-Time Lane Detection Method with Fog-Enhanced Feature Fusion for Foggy Conditions|雾天条件下的鲁棒实时车道检测方法：基于雾增强特征融合|Ronghui Zhang, Yuhang Ma, Tengfei Li, Ziyu Lin, Yueying Wu, Junzhou Chen, Lin Zhang, Jia Hu .etc.|<http://arxiv.org/pdf/2504.06121v5>|提出了针对雾天环境的高效车道检测方法，通过特征融合网络显著提升了雾天条件下的检测性能和实时性。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Comprehensive Survey on Video Scene Parsing:Advances, Challenges, and Prospects|视频场景解析的全面综述：进展、挑战与展望|Guohuan Xie, Syed Ariff Syed Hesham, Wenya Guo, Bing Li, Ming-Ming Cheng, Guolei Sun, Yun Liu|<http://arxiv.org/pdf/2506.13552v1>|系统梳理了视频场景解析的最新进展，探讨了技术挑战，并展望了未来研究方向。|
|📝 更新|Efficient Unsupervised Shortcut Learning Detection and Mitigation in Transformers|高效的无监督快捷学习检测与缓解方法在变换器中的应用|Lukas Kuhn, Sari Sadiya, Jorg Schlotterer, Florian Buettner, Christin Seifert, Gemma Roig|<http://arxiv.org/pdf/2501.00942v2>|提出了一种无监督框架，有效检测和减轻Transformer中的捷径学习问题，提升模型准确度且减少人工...|
|🆕 发布|Sparse Convolutional Recurrent Learning for Efficient Event-based Neuromorphic Object Detection|稀疏卷积循环学习用于高效基于事件的类神经形态目标检测|Shenqi Wang, Yingfu Xu, Amirreza Yousefzadeh, Sherif Eissa, Henk Corporaal, Federico Corradi, Guangzhi Tang|<http://arxiv.org/pdf/2506.13440v1>|提出Sparse Event-based Efficient Detector (SEED)，通过稀...|
|🆕 发布|Anomaly Object Segmentation with Vision-Language Models for Steel Scrap Recycling|基于视觉语言模型的钢铁废料回收中异常目标分割|Daichi Tanaka, Takumi Karasawa, Shu Takenouchi, Rei Kawakami|<http://arxiv.org/pdf/2506.13282v1>|提出了一种基于视觉语言模型的异常对象分割方法，实现了钢铁废料中杂质的精细检测。|
|📝 更新|Deep Learning-Based Breast Cancer Detection in Mammography: A Multi-Center Validation Study in Thai Population|基于深度学习的乳腺X线摄影中乳腺癌检测：泰国人群多中心验证研究|Isarun Chamveha, Supphanut Chaiyungyuen, Sasinun Worakriangkrai, Nattawadee Prasawang, Warasinee Chaisangmongkon, Pornpim Korpraphong, Voraparee Suvannarerg, Shanigarn Thiravit .etc.|<http://arxiv.org/pdf/2506.03177v2>|开发了一种基于深度学习的乳腺癌检测系统，通过改进EfficientNetV2架构，有效辅助哺乳动物图...|
|🆕 发布|Beyond the First Read: AI-Assisted Perceptual Error Detection in Chest Radiography Accounting for Interobserver Variability|超越初次阅读：考虑观察者间变异的AI辅助胸部X射线影像感知错误检测|Adhrith Vutukuri, Akash Awasthi, David Yang, Carol C. Wu, Hien Van Nguyen|<http://arxiv.org/pdf/2506.13049v1>|[代码](https://github.com/avutukuri01/RADAR.); 提出了一种AI辅助的胸部X光检查后读片错误检测系统，通过提供灵活的感兴趣区域建议以适应不同观察者间的...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Real-time Seafloor Segmentation and Mapping|实时海底分割与映射|Michele Grimaldi, Nouf Alkaabi, Francesco Ruscio, Sebastian Realpe Rua, Rafael Garcia, Nuno Gracias|<http://arxiv.org/pdf/2504.10750v3>|提出了一种结合机器学习和计算机视觉技术的框架，使自主水下机器人能自动检测海草床边界并实现岩石分割。|
|📝 更新|Test-time Contrastive Concepts for Open-world Semantic Segmentation with Vision-Language Models|开放世界语义分割中视觉-语言模型测试时的对比概念|Monika Wysoczańska, Antonin Vobecky, Amaia Cardiel, Tomasz Trzciński, Renaud Marlet, Andrei Bursuc, Oriane Siméoni|<http://arxiv.org/pdf/2407.05061v3>|提出在开放世界语义分割中自动生成对比性概念的方法，以提升单概念分割性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PF-LHM: 3D Animatable Avatar Reconstruction from Pose-free Articulated Human Images|PF-LHM：从无姿态约束的人体关节图像中重建可动画化三维头像|Lingteng Qiu, Peihao Li, Qi Zuo, Xiaodong Gu, Yuan Dong, Weihao Yuan, Siyu Zhu, Xiaoguang Han .etc.|<http://arxiv.org/pdf/2506.13766v1>|提出了一种快速生成高质量3D动画角色的方法PF-LHM，无需姿态或相机信息即可从多张随意拍摄的人体图...|
|🆕 发布|Diagnosing and Improving Diffusion Models by Estimating the Optimal Loss Value|通过估计最优损失值来诊断和改进扩散模型|Yixian Xu, Shengjie Luo, Liwei Wang, Di He, Chang Liu|<http://arxiv.org/pdf/2506.13763v1>|提出估计最优损失值的方法，用于诊断和提升扩散模型的训练质量。|
|🆕 发布|VideoPDE: Unified Generative PDE Solving via Video Inpainting Diffusion Models|视频PDE：通过视频修复扩散模型实现统一生成性偏微分方程求解|Edward Li, Zichen Wang, Jiahe Huang, Jeong Joon Park|<http://arxiv.org/pdf/2506.13754v1>|提出了一种统一的生成模型，通过视频修复扩散模型解决偏微分方程问题，实现了广泛的适用性和高效计算。|
|🆕 发布|Exploiting the Exact Denoising Posterior Score in Training-Free Guidance of Diffusion Models|usion模型的训练无关引导中利用精确去噪后验得分|Gregory Bellchambers|<http://arxiv.org/pdf/2506.13614v1>|提出了一种无需训练的扩散模型引导方法，通过精确的后验得分函数实现高效图像恢复。|
|📝 更新|MambaTalk: Efficient Holistic Gesture Synthesis with Selective State Space Models|MambaTalk：基于选择性状态空间模型的高效整体手势合成|Zunnan Xu, Yukang Lin, Haonan Han, Sicheng Yang, Ronghui Li, Yachao Zhang, Xiu Li|<http://arxiv.org/pdf/2403.09471v6>|[代码](https://kkakkkka.github.io/MambaTalk); 提出了一种基于状态空间模型的两阶段建模策略，通过引入MambaTalk实现高效的全局手势合成，提高了...|
|📝 更新|Adaptive Feature Selection for No-Reference Image Quality Assessment by Mitigating Semantic Noise Sensitivity|自适应特征选择用于无参考图像质量评估，通过减轻语义噪声敏感性|Xudong Li, Timin Gao, Runze Hu, Yan Zhang, Shengchuan Zhang, Xiawu Zheng, Jingyuan Zheng, Yunhang Shen .etc.|<http://arxiv.org/pdf/2312.06158v3>|提出质量感知特征匹配指标，通过对抗性噪声消除，自适应选择有效特征以提升无参考图像质量评估准确性。|
|🆕 发布|Flexible-length Text Infilling for Discrete Diffusion Models|《面向离散扩散模型的灵活长度文本填充》|Andrew Zhang, Anushka Sivakumar, Chiawei Tang, Chris Thomas|<http://arxiv.org/pdf/2506.13579v1>|提出DDOT模型，首次实现无需位置数据的离散扩散模型灵活长度文本填充。|
|🆕 发布|MambaMia: A State-Space-Model-Based Compression for Efficient Video Understanding in Large Multimodal Models|《MambaMia：基于状态空间模型的压缩方法，用于大型多模态模型中高效视频理解》|Geewook Kim, Minjoon Seo|<http://arxiv.org/pdf/2506.13564v1>|提出了一种基于状态空间模型的视频特征压缩框架，有效降低长视频处理中的计算负担，同时保持理解性能。|
|🆕 发布|Limited-Angle CBCT Reconstruction via Geometry-Integrated Cycle-domain Denoising Diffusion Probabilistic Models|通过集成几何学的循环域降噪扩散概率模型进行有限角度CBCT重建|Yuan Gao, Shaoyan Pan, Mingzhe Hu, Huiqiao Xie, Jill Remick, Chih-Wei Chang, Justin Roper, Zhen Tian .etc.|<http://arxiv.org/pdf/2506.13545v1>|提出了一种基于几何集成的双域学习框架，实现了从有限角度扫描重建高质量CBCT图像，降低了扫描时间和辐...|
|🆕 发布|Deep Diffusion Models and Unsupervised Hyperspectral Unmixing for Realistic Abundance Map Synthesis|深度扩散模型与无监督高光谱解混用于真实丰度图合成|Martina Pastorino, Michael Alibani, Nicola Acito, Gabriele Moser|<http://arxiv.org/pdf/2506.13484v1>|提出了一种无监督深度学习方法，结合盲线性解混和扩散模型，生成逼真的高光谱图像丰度图。|
|📝 更新|Bokeh Diffusion: Defocus Blur Control in Text-to-Image Diffusion Models|散焦模糊扩散：在文本到图像扩散模型中控制散焦模糊|Armando Fortes, Tianyi Wei, Shangchen Zhou, Xingang Pan|<http://arxiv.org/pdf/2503.08434v4>|提出了一种新的图像生成方法Bokeh Diffusion，通过物理性散焦模糊参数实现精确的景深控制。|
|📝 更新|VideoMat: Extracting PBR Materials from Video Diffusion Models|视频材质：从视频扩散模型中提取基于物理的渲染材质|Jacob Munkberg, Zian Wang, Ruofan Liang, Tianchang Shen, Jon Hasselgren|<http://arxiv.org/pdf/2506.09665v2>|提出了一种结合视频扩散模型和物理渲染的方法，从视频和单张图片中提取高质量的3D模型PBR材质。|
|🆕 发布|Zero-Shot Solving of Imaging Inverse Problems via Noise-Refined Likelihood Guided Diffusion Models|零样本解决成像逆问题：基于噪声细化似然引导的扩散模型|Zhen Wang, Hongyi Liu, Zhihui Wei|<http://arxiv.org/pdf/2506.13391v1>|提出了一种无需重训练即可处理多种成像逆问题的零样本框架，通过似然引导的噪声精炼机制优化了扩散模型的恢...|
|🆕 发布|AttentionDrag: Exploiting Latent Correlation Knowledge in Pre-trained Diffusion Models for Image Editing|注意力拖拽：利用预训练扩散模型中的潜在关联知识进行图像编辑|Biao Yang, Muqi Huang, Yuhui Zhang, Yun Xiong, Kun Zhou, Xi Chen, Shiyang Zhou, Huishuai Bao .etc.|<http://arxiv.org/pdf/2506.13301v1>|提出了一种名为AttentionDrag的一步式图像编辑方法，利用预训练扩散模型中的潜在关联知识，实...|
|📝 更新|RIFLEx: A Free Lunch for Length Extrapolation in Video Diffusion Transformers|RIFLEx：视频扩散变换中的长度外推自由午餐|Min Zhao, Guande He, Yixiao Chen, Hongzhou Zhu, Chongxuan Li, Jun Zhu|<http://arxiv.org/pdf/2502.15894v2>|[代码](https://riflex-video.github.io/.); 提出了一种无需训练即可有效延长视频时长的RIFLEx方法，解决了现有技术中的重复和减速问题。|
|📝 更新|HSRMamba: Contextual Spatial-Spectral State Space Model for Single Image Hyperspectral Super-Resolution|HSRMamba：单幅图像高光谱超分辨率的空间-光谱状态空间模型|Shi Chen, Lefei Zhang, Liangpei Zhang|<http://arxiv.org/pdf/2501.18500v2>|[代码](https://github.com/Tomchenshi/HSRMamba.); 提出HSRMamba模型，通过局部空间-光谱分区和全局光谱重排策略，有效提升 hyperspectr...|
|📝 更新|CAT: Contrastive Adversarial Training for Evaluating the Robustness of Protective Perturbations in Latent Diffusion Models|CAT：用于评估潜在扩散模型中保护性扰动鲁棒性的对比对抗训练|Sen Peng, Mingyue Wang, Jianfei He, Jijia Yang, Xiaohua Jia|<http://arxiv.org/pdf/2502.07225v2>|[代码](https://github.com/senp98/CAT.); 提出了一种对抗性训练方法，揭示了保护性扰动在潜在扩散模型中的脆弱性，并显著降低了其防护效果。|
|📝 更新|R2LDM: An Efficient 4D Radar Super-Resolution Framework Leveraging Diffusion Model|R2LDM：一种利用扩散模型的高效4D雷达超分辨率框架|Boyuan Zheng, Shouyi Lu, Renbo Huang, Minqing Huang, Fan Lu, Wei Tian, Guirong Zhuo, Lu Xiong|<http://arxiv.org/pdf/2503.17097v2>|提出了一种利用扩散模型从雷达数据生成高密度4D点云的方法，显著提升了点云密度和下游任务性能。|
|🆕 发布|DualFast: Dual-Speedup Framework for Fast Sampling of Diffusion Models|双速提升框架：用于快速采样扩散模型的双速提升框架|Hu Yu, Hao Luo, Fan Wang, Feng Zhao|<http://arxiv.org/pdf/2506.13058v1>|提出双误差解耦策略，引入无训练加速框架DualFast，大幅提升扩散模型采样速度与质量。|
|🆕 发布|NeuVAS: Neural Implicit Surfaces for Variational Shape Modeling|神经隐式表面用于变分形状建模|Pengfei Wang, Qiujie Dong, Fangtian Liang, Hao Pan, Lei Yang, Congyi Zhang, Guying Lin, Caiming Zhang .etc.|<http://arxiv.org/pdf/2506.13050v1>|提出NeuVAS方法，通过神经隐式表面和变分建模，有效处理稀疏形状控制问题，生成高质量三维曲面。|
|🆕 发布|Evolution of ReID: From Early Methods to LLM Integration|《行人重识别技术的发展：从早期方法到大型语言模型集成》|Amran Bhuiyan, Mizanur Rahman, Md Tahmid Rahman Laskar, Aijun An, Jimmy Xiangji Huang|<http://arxiv.org/pdf/2506.13039v1>|这篇论文综述了行人重识别技术的发展，特别是引入大型语言模型以融合视觉和文本信息，提出使用GPT-4o...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UltraZoom: Generating Gigapixel Images from Regular Photos|超分辨率变焦：从普通照片生成吉像素图像|Jingwei Ma, Vivek Jayaram, Brian Curless, Ira Kemelmacher-Shlizerman, Steven M. Seitz|<http://arxiv.org/pdf/2506.13756v1>|提出了一种利用普通照片生成超高分辨率图像的系统UltraZoom，通过学习特定物体的低至高分辨率映射...|
|🆕 发布|FOAM: A General Frequency-Optimized Anti-Overlapping Framework for Overlapping Object Perception|频率优化抗重叠框架：用于重叠目标感知的通用框架|Mingyuan Li, Tong Jia, Han Gu, Hui Lu, Hao Wang, Bowen Ma, Shuyang Lin, Shiyi Guo .etc.|<http://arxiv.org/pdf/2506.13501v1>|提出了一种频率优化抗重叠框架FOAM，通过频率域分析增强模型对重叠物体的纹理和轮廓特征提取能力。|
|🆕 发布|Deep Learning-Based Multi-Object Tracking: A Comprehensive Survey from Foundations to State-of-the-Art|基于深度学习的多目标跟踪：从基础到最新技术的全面综述|Momir Adžemović|<http://arxiv.org/pdf/2506.13457v1>|系统梳理了基于深度学习的多目标跟踪方法，揭示了不同方法在复杂场景中的性能差异。|
|🆕 发布|DicFace: Dirichlet-Constrained Variational Codebook Learning for Temporally Coherent Video Face Restoration|狄利克雷约束的变分码本学习用于时间一致的视频人脸修复：DicFace|Yan Chen, Hanlin Shang, Ce Liu, Yuxuan Chen, Hui Li, Weihao Yuan, Hao Zhu, Zilong Dong .etc.|<http://arxiv.org/pdf/2506.13355v1>|[代码](https://github.com/fudan-generative-vision/DicFace.); 提出了一种基于Dirichlet分布的连续变量替代离散码本，实现视频中人脸细节恢复与时间一致性的方法...|
|📝 更新|Learning Coherent Matrixized Representation in Latent Space for Volumetric 4D Generation|学习潜在空间中的连贯矩阵化表示以实现体素4D生成|Qitong Yang, Mingtao Feng, Zijie Wu, Shijie Sun, Weisheng Dong, Yaonan Wang, Ajmal Mian|<http://arxiv.org/pdf/2403.13238v3>|提出了一种新的四维体积生成框架，通过在潜在空间学习一致的矩阵化表示，实现了高质且连续的三维形状和颜色...|
|📝 更新|Genesis: Multimodal Driving Scene Generation with Spatio-Temporal and Cross-Modal Consistency|创世纪：具有时空一致性和跨模态一致性的多模态驾驶场景生成|Xiangyu Guo, Zhanqian Wu, Kaixin Xiong, Ziyang Xu, Lijun Zhou, Gangwei Xu, Shaoqing Xu, Haiyang Sun .etc.|<http://arxiv.org/pdf/2506.07497v3>|提出了一种统一框架Genesis，实现了多视角驾驶视频和LiDAR序列的联合生成，保持了时空和跨模态...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vid-CamEdit: Video Camera Trajectory Editing with Generative Rendering from Estimated Geometry|Vid-CamEdit：基于估计几何的生成渲染视频相机轨迹编辑|Junyoung Seo, Jisang Han, Jaewoo Jung, Siyoon Jin, Joungbin Lee, Takuya Narihira, Kazumi Fukuda, Takashi Shibuya .etc.|<http://arxiv.org/pdf/2506.13697v1>|Vid-CamEdit通过估计几何和生成渲染，实现了视频相机轨迹编辑和沿自定义路径的重合成。|
|🆕 发布|FreeQ-Graph: Free-form Querying with Semantic Consistent Scene Graph for 3D Scene Understanding|自由形查询与语义一致场景图用于三维场景理解：FreeQ-Graph|Chenlu Zhan, Gaoang Wang, Hongwei Wang|<http://arxiv.org/pdf/2506.13629v1>|提出FreeQ-Graph方法，通过构建无需预定义词汇的3D场景图实现自由形式查询与3D场景理解。|
|📝 更新|Agentic 3D Scene Generation with Spatially Contextualized VLMs|具有空间上下文化的VLMs的代理性3D场景生成|Xinhang Liu, Yu-Wing Tai, Chi-Keung Tang|<http://arxiv.org/pdf/2505.20129v2>|[代码](https://spatctxvlm.github.io/project_page); 引入空间上下文机制，使视觉语言模型能生成和理解复杂三维场景，提升其在空间智能任务中的应用。|
|🆕 发布|Dive3D: Diverse Distillation-based Text-to-3D Generation via Score Implicit Matching|Dive3D：通过分数隐式匹配的多样化蒸馏基于文本到3D生成|Weimin Bai, Yubo Li, Wenzheng Chen, Weijian Luo, He Sun|<http://arxiv.org/pdf/2506.13594v1>|提出了Dive3D框架，通过Score Implicit Matching损失函数替代KL散度，有效...|
|🆕 发布|Omni-AdaVideoRAG: Omni-Contextual Adaptive Retrieval-Augmented for Efficient Long Video Understanding|全场景自适应检索增强方法Omni-AdaVideoRAG：用于高效长视频理解的全场景自适应检索增强|Zhucun Xue, Jiangning Zhang, Xurong Xie, Yuxuan Cai, Yong Liu, Xiangtai Li, Dacheng Tao|<http://arxiv.org/pdf/2506.13589v1>|[代码](https://github.com/xzc-zju/AdaVideoRAG.); 提出了一种自适应检索的视频理解框架，通过动态调整检索粒度，有效提升了长视频处理的效率和准确性。|
|🆕 发布|GeoSDF: Plane Geometry Diagram Synthesis via Signed Distance Field|GeoSDF：通过签名距离场进行平面几何图示合成|Chengrui Zhang, Maizhen Ning, Zihao Zhou, Jie Sun, Kaizhu Huang, Qiufeng Wang|<http://arxiv.org/pdf/2506.13492v1>|提出GeoSDF框架，利用有符号距离场自动生成精确且逼真的几何图形，提升几何问题解决准确率至95%。|
|🆕 发布|PRO: Projection Domain Synthesis for CT Imaging|投影域合成技术在CT成像中的应用|Kang Chen, Bin Huang, Xuebin Yang, Junyan Zhang, Qiegen Liu|<http://arxiv.org/pdf/2506.13443v1>|[代码](https://github.com/yqx7150/PRO.); 首次在投影域使用潜在扩散模型进行CT图像合成，提高数据生成质量和下游任务性能。|
|🆕 发布|Fair Generation without Unfair Distortions: Debiasing Text-to-Image Generation with Entanglement-Free Attention|无偏见生成，无扭曲：使用无纠缠注意力去偏文本到图像生成|Jeonghoon Park, Juyoung Lee, Chaeyeon Chung, Jaeseong Lee, Jaegul Choo, Jindong Gu|<http://arxiv.org/pdf/2506.13298v1>|提出了一种无纠缠注意机制，有效减少文本到图像生成中的偏见，同时保持图像质量不受影响。|
|🆕 发布|VIS-Shepherd: Constructing Critic for LLM-based Data Visualization Generation|VIS-Shepherd：构建基于大型语言模型的数据可视化生成评判器|Bo Pan, Yixiao Fu, Ke Wang, Junyu Lu, Lunke Pan, Ziyang Qian, Yuhan Chen, Guoliang Wang .etc.|<http://arxiv.org/pdf/2506.13326v1>|[代码](https://github.com/bopan3/VIS-Shepherd.); 提出了一种基于大型语言模型的可视化评价方法，有效提升了数据可视化质量。|
|📝 更新|BiFold: Bimanual Cloth Folding with Language Guidance|双折：在语言指导下进行双手折布|Oriol Barbany, Adrià Colomé, Carme Torras|<http://arxiv.org/pdf/2501.16458v2>|提出了一种结合自然语言理解的机器人双臂折衣方法，实现了指令驱动的精准操作。|
|📝 更新|EmbodiedGen: Towards a Generative 3D World Engine for Embodied Intelligence|EmbodiedGen：面向具身智能的生成式三维世界引擎|Xinjie Wang, Liu Liu, Yu Cao, Ruiqi Wu, Wenkang Qin, Dehui Wang, Wei Sui, Zhizhong Su|<http://arxiv.org/pdf/2506.10600v2>|[代码](https://horizonrobotics.github.io/robot_lab); 提出 EmbodiedGen 平台，利用生成式 AI 生成低成本、高质量的 3D 资产，助力 Emb...|
|🆕 发布|High-Quality Facial Albedo Generation for 3D Face Reconstruction from a Single Image using a Coarse-to-Fine Approach|使用粗到细方法从单张图像进行三维人脸重建的高质量面部反照率生成|Jiashu Dai, Along Wang, Binfan Ni, Tao Cao|<http://arxiv.org/pdf/2506.13233v1>|[代码](https://github.com/MVIC-DAI/UVAPM); 提出了一种粗到细的方法生成高质量面部纹理，提高了3D人脸重建的单张图像纹理质量和真实感。|
|📝 更新|FrameBridge: Improving Image-to-Video Generation with Bridge Models|帧桥：利用桥接模型提高图像到视频生成的质量|Yuji Wang, Zehua Chen, Xiaoyu Chen, Yixiang Wei, Jun Zhu, Jianfei Chen|<http://arxiv.org/pdf/2410.15371v2>|[代码](https://framebridge-icml.github.io/.); 提出FrameBridge模型，通过桥接模型优化图像到视频生成过程，提升合成质量并引入两种新技术。|
|🆕 发布|STAGE: A Stream-Centric Generative World Model for Long-Horizon Driving-Scene Simulation|“STAGE：一种面向流处理的生成式长时驾驶场景模拟世界模型”|Jiamin Wang, Yichen Yao, Xiang Feng, Hang Wu, Yaming Wang, Qingqiu Huang, Yuexin Ma, Xinge Zhu|<http://arxiv.org/pdf/2506.13138v1>|提出STAGE模型，通过分层特征协调和多阶段优化，解决了长距离驾驶视频生成中的时间一致性和误差累积问...|
|🆕 发布|StgcDiff: Spatial-Temporal Graph Condition Diffusion for Sign Language Transition Generation|《StgcDiff：基于空间-时间图条件扩散的的手语过渡生成》|Jiashu He, Jiayi He, Shengeng Tang, Huixia Ben, Lechao Cheng, Richang Hong|<http://arxiv.org/pdf/2506.13156v1>|提出了一种基于图条件的扩散框架StgcDiff，通过捕捉手语独特的时空依赖性，生成连续平滑的手语过渡...|
|📝 更新|Counterfactual contrastive learning: robust representations via causal image synthesis|反事实对比学习：通过因果图像生成实现的鲁棒表征|Melanie Roschewitz, Fabio De Sousa Ribeiro, Tian Xia, Galvin Khara, Ben Glocker|<http://arxiv.org/pdf/2403.09605v3>|提出CF-SimCLR方法，利用近似反事实推理生成正样本对，增强模型对数据分布变化的鲁棒性。|
|📝 更新|Motion-R1: Chain-of-Thought Reasoning and Reinforcement Learning for Human Motion Generation|运动R1：链式思维推理与强化学习用于人体运动生成|Runqi Ouyang, Haoyun Li, Zhenyuan Zhang, Xiaofeng Wang, Zheng Zhu, Guan Huang, Xingang Wang|<http://arxiv.org/pdf/2506.10353v3>|引入链式思维机制和强化学习，提出了一种生成人类动作的新框架，提高了动作生成的控制性、一致性和多样性。|
|📝 更新|Flatfish Lesion Detection Based on Part Segmentation Approach and Lesion Image Generation|基于部分分割方法和病变图像生成的平鱼病变检测|Seo-Bin Hwang, Han-Young Kim, Chae-Yeon Heo, Hie-Yong Jeong, Sung-Ju Jung, Yeong-Jun Cho|<http://arxiv.org/pdf/2407.11348v2>|提出了一种分部位训练的鱼体病变检测框架，结合生成对抗网络和数据增强，显著提升了病变检测准确率。|
|📝 更新|Stochasticity-aware No-Reference Point Cloud Quality Assessment|基于随机性感知的无参考点云质量评估|Songlin Fan, Wei Gao, Zhineng Chen, Ge Li, Guoqing Liu, Qicheng Wang|<http://arxiv.org/pdf/2401.08926v2>|首次提出概率模型用于无参考点云质量评估，通过模拟主观评分的不确定性，提高了预测准确性。|
|🆕 发布|WildCAT3D: Appearance-Aware Multi-View Diffusion in the Wild|《WildCAT3D：在野外环境下的外观感知多视角扩散》|Morris Alper, David Novotny, Filippos Kokkinos, Hadar Averbuch-Elor, Tom Monnier|<http://arxiv.org/pdf/2506.13030v1>|提出了一种从野外多源图像学习场景外观的生成模型，实现了无需大量清洁多视角数据的高质量新视角合成。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UltraVideo: High-Quality UHD Video Dataset with Comprehensive Captions|"UltraVideo：高质量超高清视频数据集及全面字幕标注"|Zhucun Xue, Jiangning Zhang, Teng Hu, Haoyang He, Yinan Chen, Yuxuan Cai, Yabiao Wang, Chengjie Wang .etc.|<http://arxiv.org/pdf/2506.13691v1>|[代码](https://xzc-zju.github.io/projects); 提出了高质量UHD-4K视频数据集UltraVideo，通过自动化流程提升视频生成模型性能。|
|🆕 发布|SA-LUT: Spatial Adaptive 4D Look-Up Table for Photorealistic Style Transfer|空间自适应四维查找表：用于逼真风格迁移的方法|Zerui Gong, Zhonghua Wu, Qingyi Tao, Qinyue Li, Chen Change Loy|<http://arxiv.org/pdf/2506.13465v1>|[代码](https://github.com/Ry3nG/SA-LUT); 提出了一种结合查找表效率与神经网络适应性的空间自适应4D查找表方法，实现了高效且结构保真的照片级风格...|
|📝 更新|Multiverse Through Deepfakes: The MultiFakeVerse Dataset of Person-Centric Visual and Conceptual Manipulations|《通过深度伪造探索多元宇宙：以人为中心的视觉与概念操纵的MultiFakeVerse数据集》|Parul Gupta, Shreya Ghosh, Tom Gedeon, Thanh-Toan Do, Abhinav Dhall|<http://arxiv.org/pdf/2506.00868v2>|[代码](https://github.com/Parul-Gupta/MultiFakeVerse); 提出了MultiFakeVerse数据集，利用视觉语言模型生成针对人物中心的深伪内容，挑战现有检测技...|
|📝 更新|Beautiful Images, Toxic Words: Understanding and Addressing Offensive Text in Generated Images|美丽图像，有毒文字：理解与解决生成图像中的攻击性文本问题|Aditya Kumar, Tom Blanchard, Adam Dziedzic, Franziska Boenisch|<http://arxiv.org/pdf/2502.05066v3>|识别并解决生成图像中嵌入的NSFW文本问题，提出针对性的安全微调策略并发布评估基准。|
|📝 更新|T-SVG: Text-Driven Stereoscopic Video Generation|文本驱动的立体视频生成|Qiao Jin, Xiaodong Chen, Wu Liu, Tao Mei, Yongdong Zhang|<http://arxiv.org/pdf/2412.09323v2>|提出了一种基于文本提示的零样本3D视频生成方法，简化了立体视频制作流程，实现了自然立体效果。|
|🆕 发布|ZINA: Multimodal Fine-grained Hallucination Detection and Editing|ZINA：多模态细粒度幻觉检测与编辑|Yuiga Wada, Kazuki Matsuda, Komei Sugiura, Graham Neubig|<http://arxiv.org/pdf/2506.13130v1>|提出细粒度多模态幻觉检测与编辑任务，并设计ZINA方法准确识别并修正大语言模型生成的幻觉内容。|
|🆕 发布|A Comprehensive Survey on Continual Learning in Generative Models|生成模型中持续学习的全面调查|Haiyang Guo, Fanhu Zeng, Fei Zhu, Jiayi Wang, Xukai Wang, Jingang Zhou, Hongbo Zhao, Wenzhuo Liu .etc.|<http://arxiv.org/pdf/2506.13045v1>|[代码](https://github.com/Ghy0501/Awesome-Continual-Learning-in-Generative-Models.); 系统梳理了主流生成模型在持续学习中的方法，分为架构、正则化和重放三大类，以克服灾难性遗忘问题。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Test3R: Learning to Reconstruct 3D at Test Time|测试时学习重构三维：Test3R|Yuheng Yuan, Qiuhong Shen, Shizun Wang, Xingyi Yang, Xinchao Wang|<http://arxiv.org/pdf/2506.13750v1>|[代码](https://github.com/nopQAQ/Test3R.); Test3R通过测试时的自我监督优化，实现了3D重建中跨图像对的几何一致性，大幅提升了重建精度。|
|📝 更新|Unify3D: An Augmented Holistic End-to-end Monocular 3D Human Reconstruction via Anatomy Shaping and Twins Negotiating|统一3D：通过解剖塑形与双生子协商实现的增强型整体端到端单目3D人体重建|Nanjie Yao, Gangjian Zhang, Wenhao Shen, Jian Shu, Hao Wang|<http://arxiv.org/pdf/2504.18215v2>|[代码](https://e2e3dgsrecon.github.io/e2e3dgsrecon); 提出了整体端到端单目3D人体重建方法，通过解剖塑造和双模态交互提升重建完整性。|
|🆕 发布|Integrated Pipeline for Monocular 3D Reconstruction and Finite Element Simulation in Industrial Applications|单目3D重建与有限元仿真集成流程在工业应用中的研究|Bowen Zheng|<http://arxiv.org/pdf/2506.13573v1>|提出了一种集成单目3D重建、有限元仿真和混合现实显示的工作流，实现了工业场景的高效数字建模与仿真。|
|🆕 发布|Micro-macro Gaussian Splatting with Enhanced Scalability for Unconstrained Scene Reconstruction|微观-宏观高斯散点喷射增强可扩展性算法用于无约束场景重建|Yihui Li, Chengxin Lv, Hongyu Yang, Di Huang|<http://arxiv.org/pdf/2506.13516v1>|[代码](https://github.com/Kidleyh/SMW-GS.); 提出了一种多尺度分解的3D场景重建方法，通过微观宏观投影和频域采样显著提升了复杂场景的重建质量和扩展...|
|📝 更新|Comparative Evaluation of 3D Reconstruction Methods for Object Pose Estimation|三维重建方法在目标姿态估计中的比较评估|Varun Burde, Assia Benbihi, Pavel Burget, Torsten Sattler|<http://arxiv.org/pdf/2408.08234v2>|[代码](https://github.com/VarunBurde/reconstruction_pose_benchmark); 提出了一种新型基准测试，评估了从图像重建的3D模型对物体姿态估计准确性的影响。|
|🆕 发布|DVP-MVS++: Synergize Depth-Normal-Edge and Harmonized Visibility Prior for Multi-View Stereo|DVP-MVS++：融合深度-法线-边缘信息与和谐可视性先验的多视角立体匹配方法|Zhenlong Yuan, Dapeng Zhang, Zehao Li, Chengxuan Qian, Jianing Chen, Yinda Chen, Kehua Chen, Tianlu Mao .etc.|<http://arxiv.org/pdf/2506.13215v1>|提出了一种融合深度-法线-边缘信息和谐调可视性先验的稳健多视角立体匹配方法，有效解决了边缘跳跃和可视...|
|📝 更新|ActiveSplat: High-Fidelity Scene Reconstruction through Active Gaussian Splatting|主动泼洒：通过主动高斯泼洒实现高保真场景重建|Yuetao Li, Zijia Kuang, Ting Li, Qun Hao, Zike Yan, Guyue Zhou, Shaohui Zhang|<http://arxiv.org/pdf/2410.21955v2>|[代码](https://li-yuetao.github.io/ActiveSplat); 提出ActiveSplat系统，通过自主选择视角和路径，结合高效率渲染和详细环境映射实现高保真场景重...|
|🆕 发布|GS-2DGS: Geometrically Supervised 2DGS for Reflective Object Reconstruction|几何监督二维GS：用于反射物体重建的几何监督二维GS方法|Jinguang Tong, Xuesong li, Fahira Afzal Maken, Sundaram Muthu, Lars Petersson, Chuong Nguyen, Hongdong Li|<http://arxiv.org/pdf/2506.13110v1>|[代码](https://github.com/hirotong/GS2DGS); 提出了一种结合高斯散点快速渲染与基础模型几何信息的新方法GS-2DGS，实现了高质量反射物体重建与实...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Structureless VIO|无结构视觉惯性导航|Junlin Song, Miguel Olivares-Mendez|<http://arxiv.org/pdf/2505.12337v2>|提出了一种无需地图的视觉惯性里程计算法，提高了计算效率和精度。|
|🆕 发布|Self-Supervised Enhancement for Depth from a Lightweight ToF Sensor with Monocular Images|单目图像辅助下轻量级飞行时间传感器深度信息自监督增强|Laiyan Ding, Hualie Jiang, Jiwei Chen, Rui Huang|<http://arxiv.org/pdf/2506.13444v1>|提出了一种自监督学习框架SelfToF，利用低分辨率ToF传感器数据和单目图像生成高质量深度图。|
|🆕 发布|TR2M: Transferring Monocular Relative Depth to Metric Depth with Language Descriptions and Scale-Oriented Contrast|TR2M: 基于语言描述和尺度导向对比的单目相对深度转绝对深度方法|Beilei Cui, Yiming Huang, Long Bai, Hongliang Ren|<http://arxiv.org/pdf/2506.13387v1>|[代码](https://github.com/BeileiCui/TR2M); 提出了一种融合文本描述和图像输入的框架，将相对深度转换为度量深度，实现了跨领域深度估计的尺度不确定性...|
|🆕 发布|SuperPoint-SLAM3: Augmenting ORB-SLAM3 with Deep Features, Adaptive NMS, and Learning-Based Loop Closure|结果： 超点-SLAM3：通过深度特征、自适应非极大值抑制和基于学习的闭环检测增强ORB-SLAM3|Shahram Najam Syed, Ishir Roongta, Kavin Ravie, Gangadhar Nageswar|<http://arxiv.org/pdf/2506.13089v1>|[代码](https://github.com/shahram95/SuperPointSLAM3.); 提升ORB-SLAM3精度，通过融合深度特征、自适应非极大值抑制和学习型闭环检测。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multiview Geometric Regularization of Gaussian Splatting for Accurate Radiance Fields|多视角几何正则化高斯散点法用于精确辐射场重建|Jungeon Kim, Geonsoo Park, Seungyong Lee|<http://arxiv.org/pdf/2506.13508v1>|提出了一种多视角几何正则化策略，通过融合多视角立体深度信息优化高斯泼洒，提高了几何准确性和渲染质量。|
|🆕 发布|TextureSplat: Per-Primitive Texture Mapping for Reflective Gaussian Splatting|《纹理喷溅：基于反射高斯喷溅的逐原语纹理映射》|Mae Younes, Adnane Boukhayma|<http://arxiv.org/pdf/2506.13348v1>|提出了一种增强高反射场景渲染的方法，通过在每个图元局部空间中应用可变法线和材质属性的纹理映射来提升表...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Ego-R1: Chain-of-Tool-Thought for Ultra-Long Egocentric Video Reasoning|自我- R1：超长主观视频推理的链式工具思维|Shulin Tian, Ruiqi Wang, Hongming Guo, Penghao Wu, Yuhao Dong, Xiuying Wang, Jingkang Yang, Hao Zhang .etc.|<http://arxiv.org/pdf/2506.13654v1>|提出Ego-R1框架，通过强化学习训练的Ego-R1 Agent实现链式工具思维，有效处理超长第一视...|
|🆕 发布|Learning Event Completeness for Weakly Supervised Video Anomaly Detection|学习事件完整性用于弱监督视频异常检测|Yu Wang, Shiwei Chen|<http://arxiv.org/pdf/2506.13095v1>|提出了一种学习事件完整性的方法，通过语义规律和原型学习机制，提高了弱监督视频异常检测的事件定位完整性...|
|🆕 发布|Video Individual Counting With Implicit One-to-Many Matching|视频个体计数与隐式一对多匹配|Xuhui Zhu, Jing Xu, Bingjie Wang, Huikang Dai, Hao Lu|<http://arxiv.org/pdf/2506.13067v1>|[代码](https://github.com/tiny-smart/OMAN); 提出了一种基于隐式一对多匹配的视频个体计数模型，有效解决了行人计数中的匹配问题。|
|📝 更新|SurgBench: A Unified Large-Scale Benchmark for Surgical Video Analysis|手术视频分析统一大规模基准：SurgBench|Jianhui Wei, Zikai Xiao, Danyu Sun, Luqi Gong, Zongxin Yang, Zuozhu Liu, Jian Wu|<http://arxiv.org/pdf/2506.07603v2>|提出了SurgBench，一个包含大规模预训练和评估数据集的统一手术视频分析基准，显著提升了模型性能...|
|🆕 发布|MAMMA: Markerless & Automatic Multi-Person Motion Action Capture|无标记自动多人运动动作捕捉系统（MAMMA）|Hanz Cuevas-Velasquez, Anastasios Yiannakidis, Soyong Shin, Giorgio Becherini, Markus Höschle, Joachim Tesch, Taylor Obersat, Tsvetelina Alexiadis .etc.|<http://arxiv.org/pdf/2506.13040v1>|提出了MAMMA方法，实现了无需物理标记的多视角两人互动动作捕捉，提高了准确性和效率。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ROSA: Harnessing Robot States for Vision-Language and Action Alignment|ROSА: 利用机器人状态实现视觉-语言与动作对齐|Yuqing Wen, Kefan Gu, Haoxuan Liu, Yucheng Zhao, Tiancai Wang, Haoqiang Fan, Xiaoyan Sun|<http://arxiv.org/pdf/2506.13679v1>|提出ROSA方法，利用机器人状态估计促进视觉-语言与动作空间的更好对齐，提升机器人控制性能和泛化能力...|
|🆕 发布|Leveraging Vision-Language Pre-training for Human Activity Recognition in Still Images|利用视觉-语言预训练进行静态图像中的人体活动识别|Cristina Mahanta, Gagan Bhatia|<http://arxiv.org/pdf/2506.13458v1>|利用对比视觉语言预训练显著提升静态图像中人类活动识别的准确率。|
|🆕 发布|Action Dubber: Timing Audible Actions via Inflectional Flow|动作配音师：通过屈折流定时可听动作|Wenlong Wan, Weiying Zheng, Tianyi Xiang, Guiqing Li, Shengfeng He|<http://arxiv.org/pdf/2506.13320v1>|[代码](https://github.com/WenlongWan/Audible623.); 提出 Audible Action Temporal Localization 任务，通过 $TA^...|
|📝 更新|AgentSense: Virtual Sensor Data Generation Using LLM Agents in Simulated Home Environments|AgentSense：使用大型语言模型代理在模拟家庭环境中生成虚拟传感器数据|Zikang Leng, Megha Thukral, Yaqi Liu, Hrudhai Rajasekhar, Shruthi K. Hiremath, Thomas Plötz|<http://arxiv.org/pdf/2506.11773v2>|提出AgentSense方法，利用大型语言模型生成虚拟数据，提升智能家庭活动识别系统性能。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Zero-Shot Temporal Interaction Localization for Egocentric Videos|零样本时间交互定位用于第一视角视频|Erhang Zhang, Junyi Ma, Yin-Dong Zheng, Yixuan Zhou, Hesheng Wang|<http://arxiv.org/pdf/2506.03662v3>|[代码](https://github.com/IRMVLab/EgoLoc.); 提出了一种零样本时序交互定位方法EgoLoc，通过自适应采样和视觉动态反馈，有效定位第一视角视频中的...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CertDW: Towards Certified Dataset Ownership Verification via Conformal Prediction|CertDW：基于符合预测的认证数据集所有权验证方法|Ting Qiao, Yiming Li, Jianbin Li, Yingjia Wang, Leyi Qi, Junfeng Guo, Ruili Feng, Dacheng Tao|<http://arxiv.org/pdf/2506.13160v1>|[代码](https://github.com/NcepuQiaoTing/CertDW); 提出CertDW方法，通过引入统计度量确保数据集版权验证在恶意攻击下的可靠性。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RelTopo: Enhancing Relational Modeling for Driving Scene Topology Reasoning|《RelTopo：增强关系建模以进行驾驶场景拓扑推理》|Yueru Luo, Changqing Zhou, Yiming Yang, Erlong Li, Chao Zheng, Shuqi Mei, Shuguang Cui, Zhen Li|<http://arxiv.org/pdf/2506.13553v1>|引入关系建模以增强自动驾驶中的道路元素感知和拓扑推理，实现感知与推理的联合优化。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DualEdit: Dual Editing for Knowledge Updating in Vision-Language Models|双编辑：视觉语言模型中的知识更新双向编辑方法|Zhiyi Shi, Binjie Wang, Chongjie Si, Yichen Wu, Junsik Kim, Hanspeter Pfister|<http://arxiv.org/pdf/2506.13638v1>|提出双模态编辑方法DualEdit，有效更新视觉语言模型知识，同时保持原有能力。|
|📝 更新|Diffusion-Based Depth Inpainting for Transparent and Reflective Objects|基于扩散的透明和反射物体深度修复|Tianyu Sun, Dingchang Hu, Yixiang Dai, Guijin Wang|<http://arxiv.org/pdf/2410.08567v2>|提出DITR框架，通过扩散基于深度修复透明和反射物体的深度信息，有效解决了传统3D成像技术难题。|
|📝 更新|Evaluating Sensitivity Parameters in Smartphone-Based Gaze Estimation: A Comparative Study of Appearance-Based and Infrared Eye Trackers|评估基于智能手机的眼动估计中的敏感性参数：基于外观和红外眼动追踪的比较研究|Nishan Gunawardena, Gough Yumu Lui, Bahman Javadi, Jeewani Anupama Ginige|<http://arxiv.org/pdf/2506.11932v2>|评估了基于智能手机的视觉 gaze 估计算法，对比红外追踪器，揭示了敏感因素影响。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Enhancing Logits Distillation with Plug\&Play Kendall's $τ$ Ranking Loss|提升Logits蒸馏的Plug\&Play Kendall's $τ$ 排序损失增强方法|Yuchen Guan, Runxi Cheng, Kang Liu, Chun Yuan|<http://arxiv.org/pdf/2409.17823v2>|[代码](https://github.com/OvernighTea/RankingLoss-KD); 提出了一种基于Kendall's τ系数的排名损失，有效平衡梯度并增强蒸馏过程中的类间信息传递。|
|🆕 发布|From Flat to Feeling: A Feasibility and Impact Study on Dynamic Facial Emotions in AI-Generated Avatars|从平面到感知：关于AI生成虚拟人物中动态面部情感的可行性和影响研究|Pegah Salehi, Sajad Amouei Sheshkal, Vajira Thambawita, Pål Halvorsen|<http://arxiv.org/pdf/2506.13477v1>|实现实时架构，将语音韵律转化为高清面部表情，提升AI生成角色的情感表现力。|
|📝 更新|Deep Network Pruning: A Comparative Study on CNNs in Face Recognition|深度网络剪枝：卷积神经网络在人脸识别中的比较研究|Fernando Alonso-Fernandez, Kevin Hernandez-Diaz, Jose Maria Buades Rubio, Prayag Tiwari, Josef Bigun|<http://arxiv.org/pdf/2405.18302v2>|定位并提出了一种基于Taylor分数的深度网络剪枝方法，有效压缩了用于人脸识别的CNN模型大小，同时...|
|📝 更新|Efficient 3D Perception on Multi-Sweep Point Cloud with Gumbel Spatial Pruning|基于Gumbel空间剪枝的多扫描点云高效三维感知|Tianyu Sun, Jianhao Li, Xueqian Zhang, Zhongdao Wang, Bailan Feng, Hengshuang Zhao|<http://arxiv.org/pdf/2411.07742v5>|引入Gumbel Spatial Pruning层，有效减少点云数据冗余，提升远距离和遮挡物体识别准...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Improving Surgical Risk Prediction Through Integrating Automated Body Composition Analysis: a Retrospective Trial on Colectomy Surgery|通过整合自动化身体成分分析提高手术风险预测：一项关于结肠切除术的回顾性试验|Hanxue Gu, Yaqian Chen, Jisoo Lee, Diego Schaps, Regina Woody, Roy Colglazier, Maciej A. Mazurowski, Christopher Mantyh|<http://arxiv.org/pdf/2506.11996v2>|利用CT扫描自动提取的术前身体成分指标，结合临床变量，提高结直肠癌术后一年全因死亡预测准确性。|
|🆕 发布|Audio-Visual Driven Compression for Low-Bitrate Talking Head Videos|音频视觉驱动压缩：面向低比特率说话人头部的视频压缩|Riku Takahashi, Ryugo Morita, Jinjia Zhou|<http://arxiv.org/pdf/2506.13419v1>|提出一种音频视觉驱动的视频编解码方法，有效应对低比特率下的人头运动和唇同步问题，显著提升压缩效率和重...|
|🆕 发布|SeqPE: Transformer with Sequential Position Encoding|序列位置编码的Transformer：SeqPE|Huyang Li, Yahui Liu, Hongyu Sun, Deng Cai, Leyang Cui, Wei Bi, Peilin Zhao, Taro Watanabe|<http://arxiv.org/pdf/2506.13277v1>|[代码](https://github.com/ghrua/seqpe.); 提出了SeqPE，一种可学习且适用于多维度输入的统一位置编码框架，有效解决了Transformer中...|
|🆕 发布|Dynamic Context-oriented Decomposition for Task-aware Low-rank Adaptation with Less Forgetting and Faster Convergence|动态上下文导向分解用于任务感知的低秩适应，减少遗忘加快收敛|Yibo Yang, Sihao Liu, Chuan Rao, Bang An, Tiancheng Shen, Philip H. S. Torr, Ming-Hsuan Yang, Bernard Ghanem|<http://arxiv.org/pdf/2506.13187v1>|提出了一种考虑数据上下文的动态分解适应方法CorDA++，有效减少知识遗忘并加快收敛速度。|
|🆕 发布|HKD4VLM: A Progressive Hybrid Knowledge Distillation Framework for Robust Multimodal Hallucination and Factuality Detection in VLMs|HKD4VLM：一种用于大型视觉语言模型中稳健的多模态虚构与事实性检测的渐进式混合知识蒸馏框架|Zijian Zhang, Xuecheng Wu, Danlei Huang, Siyu Yan, Chong Peng, Xuezhi Cao|<http://arxiv.org/pdf/2506.13038v1>|提出了一种渐进式混合知识蒸馏框架HKD4VLM，有效提升了视觉语言模型在多模态幻觉检测和事实性检查的...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Overcoming Occlusions in the Wild: A Multi-Task Age Head Approach to Age Estimation|在野外克服遮挡：一种基于多任务年龄头部方法进行年龄估计|Waqar Tanveer, Laura Fernández-Robles, Eduardo Fidalgo, Víctor González-Castro, Enrique Alegre|<http://arxiv.org/pdf/2506.13445v1>|提出了一种结合生成对抗网络和变换器架构的方法，有效克服面部遮挡问题，提升野外环境下的年龄估计准确性。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Incentivizing Reasoning for Advanced Instruction-Following of Large Language Models|激励推理以提高大型语言模型的高级指令遵循能力|Yulei Qin, Gang Li, Zongyi Li, Zihan Xu, Yuchen Shi, Zhekai Lin, Xiao Cui, Ke Li .etc.|<http://arxiv.org/pdf/2506.01413v3>|提出了一种利用强化学习和可验证奖励信号激励推理的方法，显著提升了大型语言模型处理复杂指令的能力。|
|🆕 发布|ViewPCL: a point cloud based active learning method for multi-view segmentation|ViewPCL：一种基于点云的多视角分割主动学习方法|Christian Hilaire, Sima Didari|<http://arxiv.org/pdf/2506.13043v1>|[代码](https://github.com/chilai235/viewpclAL.); 提出了一种基于点云的主动学习方法，通过多视角几何信息差异提高多视图分割效率和可解释性。|
|📝 更新|Unified Source-Free Domain Adaptation|统一的无源域自适应|Song Tang, Wenxin Su, Mao Ye, Jianwei Zhang, Xiatian Zhu|<http://arxiv.org/pdf/2403.07601v2>|提出了一种统一的无源域自适应方法CausalDA，通过发现潜在因果因素，提高了模型在域迁移中的可靠性...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Heart Rate Classification in ECG Signals Using Machine Learning and Deep Learning|使用机器学习和深度学习对心电图信号进行心率分类|Thien Nhan Vo|<http://arxiv.org/pdf/2506.06349v2>|该研究通过机器学习和深度学习两种方法，有效实现了心电信号的心率分类。|
|📝 更新|AirIO: Learning Inertial Odometry with Enhanced IMU Feature Observability|Learning Inertial Odometry with Enhanced IMU Feature Observability  空气惯性导航：利用增强IMU特征可观性学习惯性里程计|Yuheng Qiu, Can Xu, Yutian Chen, Shibo Zhao, Junyi Geng, Sebastian Scherer|<http://arxiv.org/pdf/2501.15659v2>|提出了一种保持机体坐标系表示和编码姿态信息的惯性导航方法，显著提升了无人机在动态飞行中的状态估计准确...|
|🆕 发布|Hierarchical Multi-Positive Contrastive Learning for Patent Image Retrieval|层次化多正样本对比学习在专利图像检索中的应用|Kshitij Kavimandan, Angelos Nalmpantis, Emma Beauxis-Aussalet, Robert-Jan Sips|<http://arxiv.org/pdf/2506.13496v1>|提出了一种利用Locarno分类体系构建的层级多正样本对比损失，有效提升了专利图像检索的准确性。|
|📝 更新|Dissecting RGB-D Learning for Improved Multi-modal Fusion|剖析RGB-D学习以实现改进的多模态融合|Hao Chen, Haoran Zhou, Yunshu Zhang, Zheng Lin, Yongjian Deng|<http://arxiv.org/pdf/2308.10019v2>|提出分析框架和评分方法解析RGB-D学习，提出简单融合策略显著提升多模态任务表现。|
|📝 更新|Recognizing Unseen States of Unknown Objects by Leveraging Knowledge Graphs|利用知识图谱识别未见过的未知对象的状态|Filipos Gouidis, Konstantinos Papoutsakis, Theodore Patkos, Antonis Argyros, Dimitris Plexousakis|<http://arxiv.org/pdf/2307.12179v3>|提出了一种不依赖物体类别知识，利用知识图谱进行零样本物体状态分类的方法，实现了对未见物体状态的识别。|
|🆕 发布|SASep: Saliency-Aware Structured Separation of Geometry and Feature for Open Set Learning on Point Clouds|显眼性感知的结构化分离几何与特征方法：面向点云的开集学习|Jinfeng Xu, Xianzhi Li, Yuan Tang, Xu Han, Qiao Yu, Yixue Hao, Long Hu, Min Chen|<http://arxiv.org/pdf/2506.13224v1>|提出了一种针对点云的开集学习新方法，通过区分对象的重要和不重要部分来有效区分已知和未知类别。|
|🆕 发布|A Comprehensive Survey on Deep Learning Solutions for 3D Flood Mapping|深度学习在三维洪水制图解决方案中的全面调研|Wenfeng Jia, Bin Liang, Yuxi Liu, Muhammad Arif Khan, Lihong Zheng|<http://arxiv.org/pdf/2506.13201v1>|系统梳理了深度学习在3D洪水映射中的应用，提升了灾害管理和城市规划的准确性。|
|🆕 发布|Pro-AD: Learning Comprehensive Prototypes with Prototype-based Constraint for Multi-class Unsupervised Anomaly Detection|Pro-AD：基于原型约束学习综合原型进行多类无监督异常检测|Ziqing Zhou, Binbin Gao, Yuri Pan, Lidong Wang, Wenbing Zhu, Yong Liu, Jun Liu, MIngmin Chi .etc.|<http://arxiv.org/pdf/2506.13097v1>|提出Pro-AD方法，通过扩展原型集和动态双向解码器增强异常检测性能，引入原型约束避免异常重构。|
|🆕 发布|AS400-DET: Detection using Deep Learning Model for IBM i (AS/400)|AS400-DET：基于深度学习模型的IBM i（AS/400）检测|Thanh Tran, Son T. Luu, Quan Bui, Shoshin Nomura|<http://arxiv.org/pdf/2506.13032v1>|提出了一种用于IBM i系统自动GUI组件检测的深度学习方法，并构建了首个相关的人类注释数据集。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Lecture Video Visual Objects (LVVO) Dataset: A Benchmark for Visual Object Detection in Educational Videos|教育视频视觉对象（LVVO）数据集：一个用于教育视频视觉对象检测的基准|Dipayan Biswas, Shishir Shah, Jaspal Subhlok|<http://arxiv.org/pdf/2506.13657v1>|提出LVVO数据集，为教育视频中的视觉对象检测提供高质量标注和扩展标注方法。|
|🆕 发布|Stimulus Motion Perception Studies Imply Specific Neural Computations in Human Visual Stabilization|刺激运动感知研究暗示人类视觉稳定中的特定神经计算过程|David W Arathorn, Josephine C. D'Angelo, Austin Roorda|<http://arxiv.org/pdf/2506.13506v1>|揭示了人眼在固定注视时对图像稳定性的复杂感知机制，并提出了可能的神经计算模型。|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Inst3D-LMM: Instance-Aware 3D Scene Understanding with Multi-modal Instruction Tuning|Inst3D-LMM：基于多模态指令微调的实例感知三维场景理解|Hanxun Yu, Wentong Li, Song Wang, Junbo Chen, Jianke Zhu|<http://arxiv.org/pdf/2503.00513v2>|[代码](https://github.com/hanxunyu/Inst3D-LMM); 提出了一种统一的多模态模型Inst3D-LMM，通过融合2D语义与3D几何特征及空间关系，提升了3D...|
|📝 更新|VGR: Visual Grounded Reasoning|视觉定位推理：VGR（Visual Grounded Reasoning）|Jiacong Wang, Zijian Kang, Haochen Wang, Haiyong Jiang, Jiawen Li, Bohong Wu, Ya Wang, Jiao Ran .etc.|<http://arxiv.org/pdf/2506.11991v2>|提出了一种结合细粒度视觉感知的多模态大语言模型VGR，通过视觉参考和重放机制提升图像理解能力，实现了...|
|🆕 发布|A Novel ViDAR Device With Visual Inertial Encoder Odometry and Reinforcement Learning-Based Active SLAM Method|一种具有视觉惯性编码器里程计和基于强化学习的主动SLAM方法的创新ViDAR设备|Zhanhua Xin, Zhihao Wang, Shenghao Zhang, Wanchao Chi, Yan Meng, Shihan Kong, Yan Xiong, Chong Zhang .etc.|<http://arxiv.org/pdf/2506.13100v1>|提出了一种集成电机编码器的ViDAR设备与深度强化学习驱动的主动SLAM方法，显著提升了定位与建图性...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EmbodiedPlace: Learning Mixture-of-Features with Embodied Constraints for Visual Place Recognition|具身位置：在具身约束下学习特征混合以实现视觉位置识别|Bingxi Liu, Hao Chen, Shiyi Guo, Yihong Wu, Jinqiang Cui, Hong Zhang|<http://arxiv.org/pdf/2506.13133v1>|提出了一种结合机器人约束的混合特征学习方法，有效提升了视觉场景识别性能。|
|📝 更新|Decoupled Cross-Modal Alignment Network for Text-RGBT Person Retrieval and A High-Quality Benchmark|解耦跨模态对齐网络用于文本-RGBT人体检索与高质量基准集构建|Yifei Deng, Chenglong Li, Zhenyu Chen, Zihen Xu, Jin Tang|<http://arxiv.org/pdf/2503.07950v2>|提出了一种解耦跨模态对齐网络DCAlign，用于融合文本与RGBT多模态特征，提升复杂环境下的人像检...|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PRISM2: Unlocking Multi-Modal General Pathology AI with Clinical Dialogue|PRISM2：通过临床对话解锁多模态通用病理学人工智能|George Shaikovski, Eugene Vorontsov, Adam Casson, Julian Viret, Eric Zimmermann, Neil Tenenholtz, Yi Kan Wang, Jan H. Bernhard .etc.|<http://arxiv.org/pdf/2506.13063v1>|引入PRISM2模型，通过临床对话训练实现病理学AI的通用性和扩展性。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AutoVLA: A Vision-Language-Action Model for End-to-End Autonomous Driving with Adaptive Reasoning and Reinforcement Fine-Tuning|端到端自动驾驶的视觉-语言-动作模型：自适应推理与强化微调|Zewei Zhou, Tianhui Cai, Seth Z. Zhao, Yun Zhang, Zhiyu Huang, Bolei Zhou, Jiaqi Ma|<http://arxiv.org/pdf/2506.13757v1>|提出AutoVLA模型，整合视觉输入、语言指令与动作生成，通过自适应推理与强化微调提升自动驾驶性能。|
|🆕 发布|X-Scene: Large-Scale Driving Scene Generation with High Fidelity and Flexible Controllability|X-Scene：高保真与灵活可控的大规模驾驶场景生成|Yu Yang, Alan Liang, Jianbiao Mei, Yukai Ma, Yong Liu, Gim Hee Lee|<http://arxiv.org/pdf/2506.13558v1>|提出X-Scene框架，实现大规模驾驶场景的高保真生成与灵活控制。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Deep Learning for Wildfire Risk Prediction: Integrating Remote Sensing and Environmental Data|深度学习在森林火灾风险预测中的应用：融合遥感与环境数据|Zhengsen Xu, Jonathan Li, Sibo Cheng, Xue Rui, Yu Zhao, Hongjie He, Haiyan Guan, Aryan Sharma .etc.|<http://arxiv.org/pdf/2405.01607v5>|整合遥感与环境数据，利用深度学习提升 wildfire 风险预测准确性。|
|🆕 发布|Joint Analysis of Optical and SAR Vegetation Indices for Vineyard Monitoring: Assessing Biomass Dynamics and Phenological Stages over Po Valley, Italy|光学与合成孔径雷达植被指数联合分析在葡萄园监测中的应用：评估意大利波河河谷生物质动态与物候阶段|Andrea Bergamaschi, Abhinav Verma, Avik Bhattacharya, Fabio Dell'Acqua|<http://arxiv.org/pdf/2506.13327v1>|首次结合双极化雷达植被指数与光学指数监测葡萄园生长，揭示其互补特性以评估生物量动态和物候阶段。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|How Real is CARLAs Dynamic Vision Sensor? A Study on the Sim-to-Real Gap in Traffic Object Detection|CARLA动态视觉传感器的真实性研究：交通目标检测中的仿真与实际差距分析|Kaiyuan Tan, Pavan Kumar B N, Bharatesh Chakravarthi|<http://arxiv.org/pdf/2506.13722v1>|评估了CARLA模拟器生成的数据与真实世界数据间的差距，指出仅用模拟数据训练的模型在真实场景中性能显...|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MultiViT2: A Data-augmented Multimodal Neuroimaging Prediction Framework via Latent Diffusion Model|多模态神经影像预测框架：基于潜在扩散模型的数据增强MultiViT2|Bi Yuda, Jia Sihan, Gao Yutong, Abrol Anees, Fu Zening, Calhoun Vince|<http://arxiv.org/pdf/2506.13667v1>|提出了一种结合预训练模型和视觉变换器的神经影像预测框架MultiViT2，通过生成增广样本提高了预测...|
|📝 更新|Evaluation of Vision Transformers for Multimodal Image Classification: A Case Study on Brain, Lung, and Kidney Tumors|《多模态图像分类中视觉变换器的评估：以大脑、肺和肾脏肿瘤为案例研究》|Óscar A. Martín, Javier Sánchez|<http://arxiv.org/pdf/2502.05517v2>|评估了Vision Transformers在多模态医学图像分类中的表现，实现了高达99%的平均准确...|
|🆕 发布|Atomizer: Generalizing to new modalities by breaking satellite images down to a set of scalars|Atomizer：通过将卫星图像分解为一组标量来实现对新模态的泛化|Hugo Riffaud de Turckheim, Sylvain Lobry, Roberto Interdonato, Diego Marcos|<http://arxiv.org/pdf/2506.13542v1>|提出了一种灵活的Atomizer架构，将遥感图像分解为包含丰富上下文信息的标量集合，实现跨模态的泛化...|
|🆕 发布|A Semantically-Aware Relevance Measure for Content-Based Medical Image Retrieval Evaluation|基于语义感知的相关性度量方法用于内容驱动的医学图像检索评估|Xiaoyang Wei, Camille Kurtz, Florence Cloppet|<http://arxiv.org/pdf/2506.13509v1>|提出了一种基于知识图的医疗概念距离度量方法，用于评估基于内容的医学图像检索效果。|
|🆕 发布|ESRPCB: an Edge guided Super-Resolution model and Ensemble learning for tiny Printed Circuit Board Defect detection|ESRPCB：一种边缘引导的超分辨率模型与集成学习用于微小印刷电路板缺陷检测|Xiem HoangVan, Dang Bui Dinh, Thanh Nguyen Canh, Van-Truong Nguyen|<http://arxiv.org/pdf/2506.13476v1>|提出了一种边缘引导的超分辨率模型结合集成学习，有效提升了小尺寸电路板缺陷检测的准确性。|
|🆕 发布|Simple is what you need for efficient and accurate medical image segmentation|简单即是高效与精确的医学图像分割所需|Xiang Yu, Yayan Chen, Guannan He, Qing Zeng, Yue Qin, Meiling Liang, Dandan Luo, Yimei Liao .etc.|<http://arxiv.org/pdf/2506.13415v1>|[代码](https://github.com/Frankyu5666666/SimpleUNet.); 提出简易高效的SimpleUNet模型，通过部分特征选择和固定宽度架构提升医疗图像分割性能。|
|📝 更新|A robust and scalable framework for hallucination detection in virtual tissue staining and digital pathology|一个健壮且可扩展的框架：用于虚拟组织染色和数字病理学中的幻觉检测|Luzhe Huang, Yuzhu Li, Nir Pillar, Tal Keidar Haran, William Dean Wallace, Aydogan Ozcan|<http://arxiv.org/pdf/2404.18458v2>|提出了一种自动评估质量的AQuA方法，准确检测虚拟组织染色图像中的幻觉，与病理专家评估高度一致。|
|📝 更新|ADAgent: LLM Agent for Alzheimer's Disease Analysis with Collaborative Coordinator|ADAgent：面向阿尔茨海默病分析的协作协调器支持的LLM智能体|Wenlong Hou, Guangqian Yang, Ye Du, Yeung Lau, Lihao Liu, Junjun He, Ling Long, Shujun Wang|<http://arxiv.org/pdf/2506.11150v2>|提出首个基于大型语言模型的ADAGENT，用于处理多模态数据，提升阿尔茨海默症诊断和预后准确性。|
|📝 更新|Learning to utilize image second-order derivative information for crisp edge detection|学习利用图像二阶导数信息进行清晰边缘检测|Changsong Liu, Yimeng Fan, Mingyang Li, Wei Zhang, Yanyan Liu, Yuming Li, Wenlin Li, Liang Zhang|<http://arxiv.org/pdf/2406.05779v5>|提出利用图像二阶导数信息的新模块，精确检测清晰边缘，解决了厚边和噪声问题。|
|📝 更新|Autonomous Computer Vision Development with Agentic AI|具有自主性的代理人工智能的计算机视觉开发|Jin Kim, Muhammad Wahi-Anwa, Sangyun Park, Shawn Shin, John M. Hoffman, Matthew S. Brown|<http://arxiv.org/pdf/2506.11140v2>|实现了利用大型语言模型构建自主计算机视觉系统的创新方法，自动化任务规划和工具配置。|
|📝 更新|Learning-based 3D Reconstruction in Autonomous Driving: A Comprehensive Survey|基于学习的自动驾驶三维重建：全面综述|Liewen Liao, Weihao Yan, Ming Yang, Songan Zhang|<http://arxiv.org/pdf/2503.14537v3>|系统梳理了基于学习的三维重建技术在自动驾驶中的应用，分类总结方法并展望发展趋势。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|COME: Adding Scene-Centric Forecasting Control to Occupancy World Model|COME：向占用世界模型添加场景中心预测控制|Yining Shi, Kun Jiang, Qiang Meng, Ke Wang, Jiabao Wang, Wenchao Sun, Tuopu Wen, Mengmeng Yang .etc.|<http://arxiv.org/pdf/2506.13260v1>|[代码](https://github.com/synsin0/COME.); 提出了一种分离自我运动与环境变化的框架COME，通过场景中心坐标系提高未来占位预测的准确性和可控性。|

