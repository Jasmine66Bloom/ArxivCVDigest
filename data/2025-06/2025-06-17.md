## [UPDATED!] **2025-06-17** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Scaling-Up the Pretraining of the Earth Observation Foundation Model PhilEO to the MajorTOM Dataset|将地球观测基础模型PhilEO的预训练扩展到MajorTOM数据集|Nikolaos Dionelis, Jente Bosmans, Riccardo Musto, Giancarlo Paoletti, Simone Sarti, Giacomo Cascarano, Casper Fibaek, Luke Camilleri .etc.|<http://arxiv.org/pdf/2506.14765v1>|扩展地球观测基础模型PhilEO至大规模数据集MajorTOM，提升了多种下游任务性能。|
|📝 更新|Inherently Faithful Attention Maps for Vision Transformers|视觉变换器中的本质忠实注意力图|Ananthu Aniraj, Cassio F. Dantas, Dino Ienco, Diego Marcos|<http://arxiv.org/pdf/2506.08915v3>|[代码](https://github.com/ananthu-aniraj/ifam); 引入了一种二值注意力掩码方法，通过聚焦相关区域增强视觉变换器的鲁棒性。|
|📝 更新|MSVIT: Improving Spiking Vision Transformer Using Multi-scale Attention Fusion|MSVIT：使用多尺度注意力融合改进脉冲视觉变换器|Wei Hua, Chenlin Zhou, Jibin Wu, Yansong Chua, Yangyang Shu|<http://arxiv.org/pdf/2505.14719v2>|[代码](https://github.com/Nanhu-AI-Lab/MSViT.); 提出MSVIT架构，通过多尺度注意力融合提升基于脉冲神经网络的视觉Transformer性能。|
|📝 更新|3D Brain MRI Classification for Alzheimer Diagnosis Using CNN with Data Augmentation|使用数据增强的卷积神经网络进行3D脑部MRI分类以诊断阿尔茨海默病|Thien Nhan Vo, Bac Nam Ho|<http://arxiv.org/pdf/2505.04097v2>|提出了一种结合数据增强的三维卷积神经网络，用于脑部MRI扫描的阿尔茨海默症诊断，提高了准确性和ROC...|
|🆕 发布|SceneAware: Scene-Constrained Pedestrian Trajectory Prediction with LLM-Guided Walkability|《SceneAware：基于场景约束的行人轨迹预测方法，辅以LLM引导的可行走性分析》|Juho Bai, Inwook Shim|<http://arxiv.org/pdf/2506.14144v1>|[代码](https://github.com/juho127/SceneAware.); 提出了一种结合场景理解的轨迹预测框架SceneAware，通过融合视觉Transformer和语言模...|
|🆕 发布|Déjà Vu: Efficient Video-Language Query Engine with Learning-based Inter-Frame Computation Reuse|“déjà vu：基于学习驱动的帧间计算重用的高效视频-语言查询引擎”|Jinwoo Hwang, Daeun Kim, Sangyeop Lee, Yoonsung Kim, Guseul Heo, Hojoon Kim, Yunseok Jeong, Tadiwos Meaza .etc.|<http://arxiv.org/pdf/2506.14107v1>|提出了一种视频语言查询引擎，通过跨帧计算重用显著加速了视频嵌入生成。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ONEBench to Test Them All: Sample-Level Benchmarking Over Open-Ended Capabilities|"ONEBench全面测试：开放能力样本级别的基准测试"|Adhiraj Ghosh, Sebastian Dziadzio, Ameya Prabhu, Vishaal Udandarao, Samuel Albanie, Matthias Bethge|<http://arxiv.org/pdf/2412.06745v2>|提出ONEBench框架，通过整合样本级测试集评估基础模型的开放能力，减少过拟合和偏差。|
|🆕 发布|Foundation Model Insights and a Multi-Model Approach for Superior Fine-Grained One-shot Subset Selection|基础模型洞察与多模型方法相结合实现卓越的细粒度单次子集选择|Zhijing Wan, Zhixiang Wang, Zheng Wang, Xin Xu, Shin'ichi Satoh|<http://arxiv.org/pdf/2506.14473v1>|探究基础模型在细粒度数据集上的优势，提出RAM-APL多模型融合方法提升选择性能。|
|🆕 发布|MoTE: Mixture of Ternary Experts for Memory-efficient Large Multimodal Models|MoTE: 用于内存高效的大型多模态模型的 ternary 专家混合模型|Hongyu Wang, Jiayu Xu, Ruiping Wang, Yan Feng, Yitao Zhai, Peng Pei, Xunliang Cai, Xilin Chen|<http://arxiv.org/pdf/2506.14435v1>|提出了一种内存高效的混合三元专家模型，通过训练更多低精度专家以降低大型多模态模型的内存占用。|
|🆕 发布|EVA02-AT: Egocentric Video-Language Understanding with Spatial-Temporal Rotary Positional Embeddings and Symmetric Optimization|以自我为中心的视频-语言理解：使用空间-时间旋转位置嵌入和对称优化的EVA02-AT|Xiaoqi Wang, Yi Wang, Lap-Pui Chau|<http://arxiv.org/pdf/2506.14356v1>|[代码](https://github.com/xqwang14/EVA02-AT); 引入了统一的视频编码器和创新的时空编码方法，以及改进的损失函数，提升 egocentric 视频理解...|
|📝 更新|FlagEvalMM: A Flexible Framework for Comprehensive Multimodal Model Evaluation|FlagEvalMM：一种用于全面多模态模型评估的灵活框架|Zheqi He, Yesheng Liu, Jing-shu Zheng, Xuejing Li, Jin-Ge Yao, Bowen Qin, Richeng Xuan, Xi Yang|<http://arxiv.org/pdf/2506.09081v2>|[代码](https://github.com/flageval-baai/FlagEvalMM.); 提出FlagEvalMM框架，全面评估多模态模型在多种任务中的表现，提高评估准确性和效率。|
|🆕 发布|Leader360V: The Large-scale, Real-world 360 Video Dataset for Multi-task Learning in Diverse Environment|Leader360V：面向多样化环境下多任务学习的大规模现实世界360度视频数据集|Weiming Zhang, Dingwen Xiao, Aobotao Dai, Yexin Liu, Tianbo Pan, Shiqi Wen, Lei Chen, Lin Wang|<http://arxiv.org/pdf/2506.14271v1>|介绍了Leader360V，首个大规模标注真实360度视频数据集，通过自动标注流水线提升场景理解模型...|
|📝 更新|Scaling Computer-Use Grounding via User Interface Decomposition and Synthesis|通过用户界面分解与合成实现计算机使用场景的规模扩展|Tianbao Xie, Jiaqi Deng, Xiaochuan Li, Junlin Yang, Haoyuan Wu, Jixuan Chen, Wenjing Hu, Xinyuan Wang .etc.|<http://arxiv.org/pdf/2505.13227v2>|提出OSWorld-G基准和Jedi数据集，通过界面分解和合成提升计算机使用 grounding 性...|
|📝 更新|Distraction is All You Need for Multimodal Large Language Model Jailbreaking|“干扰是打破多模态大型语言模型束缚的全部所需”|Zuopeng Yang, Jiluan Fan, Anli Yan, Erdun Gao, Xin Lin, Tao Li, Kanghua Mo, Changyu Dong|<http://arxiv.org/pdf/2502.10794v2>|提出了一种基于干扰的框架CS-DJ，通过多层次视觉干扰破坏多模态大语言模型的文本-图像对齐，实现安全...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Patho-R1: A Multimodal Reinforcement Learning-Based Pathology Expert Reasoner|病理R1：一种基于多模态强化学习的病理专家推理器|Wenchuan Zhang, Penghao Zhang, Jingru Guo, Tao Cheng, Jie Chen, Shuwan Zhang, Zhang Zhang, Yuhao Yi .etc.|<http://arxiv.org/pdf/2505.11404v3>|[代码](https://github.com/Wenchuan-Zhang/Patho-R1.); 提出了一种基于多模态强化学习的病理学专家推理系统Patho-R1，通过三阶段训练显著提升了诊断准确性...|
|🆕 发布|A multi-stage augmented multimodal interaction network for fish feeding intensity quantification|一种多阶段增强的多模态交互网络用于鱼类投喂强度量化|Shulong Zhang, Mingyuan Yao, Jiayin Zhao, Xiao Liu, Haihua Wang|<http://arxiv.org/pdf/2506.14170v1>|提出了一种多阶段增强的多模态交互网络MAINet，通过特征提取、模态交互和证据推理规则，有效提升了鱼...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|YOLOv11-RGBT: Towards a Comprehensive Single-Stage Multispectral Object Detection Framework|面向全面的一阶段多光谱目标检测框架：YOLOv11-RGBT|Dahang Wan, Rongsheng Lu, Yang Fang, Xianli Lang, Shuangbao Shu, Jingjing Chen, Siyuan Shen, Ting Xu .etc.|<http://arxiv.org/pdf/2506.14696v1>|[代码](https://github.com/wandahangFY/YOLOv11-RGBT.); 提出了一种全面的一阶段多光谱目标检测框架YOLOv11-RGBT，通过六种融合模式和优化策略显著提升...|
|📝 更新|Concept Guided Co-salient Object Detection|概念引导的协同显著目标检测|Jiayi Zhu, Qing Guo, Felix Juefei-Xu, Yihao Huang, Yang Liu, Geguang Pu|<http://arxiv.org/pdf/2412.16609v2>|引入高阶语义知识提升协同显著性检测，提出概念引导的Co-SOD框架，有效增强复杂条件下的准确分割。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DDS-NAS: Dynamic Data Selection within Neural Architecture Search via On-line Hard Example Mining applied to Image Classification|DDS-NAS：通过在线难例挖掘在神经网络架构搜索中进行动态数据选择应用于图像分类|Matt Poyser, Toby P. Breckon|<http://arxiv.org/pdf/2506.14667v1>|通过动态困难样本选择加速神经架构搜索，DDS-NAS方法大幅提高了训练效率并保持了性能。|
|🆕 发布|3DGS-IEval-15K: A Large-scale Image Quality Evaluation Database for 3D Gaussian-Splatting|3DGS-IEval-15K：用于三维高斯散点投射的大规模图像质量评估数据库|Yuke Xing, Jiarui Wang, Peizhi Niu, Wenjie Huang, Guangtao Zhai, Yiling Xu|<http://arxiv.org/pdf/2506.14642v1>|[代码](https://github.com/YukeXing/3DGS-IEval-15K.); 构建了首个大规模3D Gaussian Splatting图像质量评估数据库，为压缩算法提供了全面的...|
|🆕 发布|synth-dacl: Does Synthetic Defect Data Enhance Segmentation Accuracy and Robustness for Real-World Bridge Inspections?|合成数据增强：合成缺陷数据是否提升了现实世界桥梁检测的分割精度和鲁棒性？|Johannes Flotzinger, Fabian Deuser, Achref Jaziri, Heiko Neumann, Norbert Oswald, Visvanathan Ramesh, Thomas Braml|<http://arxiv.org/pdf/2506.14255v1>|提出合成缺陷数据集synth-dacl，平衡类别分布并提升桥梁检测模型对裂纹和孔洞的分割性能。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FocalClick-XL: Towards Unified and High-quality Interactive Segmentation|面向统一与高质量交互式分割的FocalClick-XL|Xi Chen, Hengshuang Zhao|<http://arxiv.org/pdf/2506.14686v1>|提出了一种多任务分解的交互式分割方法FocalClick-XL，通过独立预训练和共享知识，实现了对多...|
|📝 更新|MSDNet: Multi-Scale Decoder for Few-Shot Semantic Segmentation via Transformer-Guided Prototyping|MSDNet：通过Transformer引导的原型多尺度解码器用于少量样本语义分割|Amirreza Fateh, Mohammad Reza Mohammadi, Mohammad Reza Jahed Motlagh|<http://arxiv.org/pdf/2409.11316v4>|[代码](https://github.com/amirrezafateh/MSDNet); 提出了一种基于Transformer架构的多尺度解码器，通过整合不同分辨率特征和全局信息，实现了高效...|
|📝 更新|A Simple Baseline with Single-encoder for Referring Image Segmentation|用于指引用图分割的单编码器简单基线|Seonghoon Yu, Ilchae Jung, Byeongju Han, Taeoh Kim, Yunho Kim, Dongyoon Wee, Jeany Son|<http://arxiv.org/pdf/2408.15521v3>|提出单编码器结构的图像分割方法，通过共享自注意力机制实现高效的多模态交互。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ProbRadarM3F: mmWave Radar based Human Skeletal Pose Estimation with Probability Map Guided Multi-Format Feature Fusion|基于概率图引导的多格式特征融合的毫米波雷达人体骨骼姿态估计：ProbRadarM3F|Bing Zhu, Zixin He, Weiyi Xiong, Guanhua Ding, Tao Huang, Wei Chen, Wei Xiang|<http://arxiv.org/pdf/2405.05164v3>|提出概率图引导的多格式特征融合模型ProbRadarM3F，利用毫米波雷达提高了人体姿态估计准确性。|
|🆕 发布|PoseGRAF: Geometric-Reinforced Adaptive Fusion for Monocular 3D Human Pose Estimation|单目3D人体姿态估计中的几何强化自适应融合：PoseGRAF|Ming Xu, Xu Zhang|<http://arxiv.org/pdf/2506.14596v1>|[代码](https://github.com/iCityLab/PoseGRAF.); 提出 PoseGRAF 框架，通过双图卷积结构和动态融合模块，有效处理人体姿态中的方向和角度相关性，...|
|🆕 发布|Towards Reliable WMH Segmentation under Domain Shift: An Application Study using Maximum Entropy Regularization to Improve Uncertainty Estimation|面向域偏移下可靠的脑白质病变分割：应用最大熵正则化提高不确定性估计的研究|Franco Matzkin, Agostina Larrazabal, Diego H Milone, Jose Dolz, Enzo Ferrante|<http://arxiv.org/pdf/2506.14497v1>|提出最大熵正则化方法，提高WMH分割模型在域偏移下的校准和不确定性估计准确性。|
|🆕 发布|GAMORA: A Gesture Articulated Meta Operative Robotic Arm for Hazardous Material Handling in Containment-Level Environments|GAMORA：一种用于危险材料在封闭环境级别中处理的姿态手势操控元机器人臂|Farha Abdul Wasay, Mohammed Abdul Rahman, Hania Ghouse|<http://arxiv.org/pdf/2506.14513v1>|提出了一种VR引导的远程操作机器人系统GAMORA，通过自然手势控制，实现了高风险实验室环境下的精确...|
|🆕 发布|MOL: Joint Estimation of Micro-Expression, Optical Flow, and Landmark via Transformer-Graph-Style Convolution|微表情、光流和特征点联合估计的Transformer-图风格卷积方法|Zhiwen Shao, Yifan Cheng, Feiran Li, Yong Zhou, Xuequan Lu, Yuan Xie, Lizhuang Ma|<http://arxiv.org/pdf/2506.14511v1>|[代码](https://github.com/CYF-cuber/MOL.); 提出了一种端到端的微表情识别框架，融合了Transformer、图卷积和传统卷积，无需关键帧即可直接...|
|🆕 发布|GrFormer: A Novel Transformer on Grassmann Manifold for Infrared and Visible Image Fusion|GrFormer：面向红外与可见光图像融合的 Grassmann 流形上的新颖Transformer结构|Huan Kang, Hui Li, Xiao-Jun Wu, Tianyang Xu, Rui Wang, Chunyang Cheng, Josef Kittler|<http://arxiv.org/pdf/2506.14384v1>|[代码](https://codes are available at https://github.com/Shaoyun2023.); 提出基于Grassmann流形的GrFormer方法，实现红外与可见光图像融合，提升多尺度语义融合效...|
|🆕 发布|Egocentric Human-Object Interaction Detection: A New Benchmark and Method|自我中心的人-物交互检测：一个新的基准与方法|Kunyuan Deng, Yi Wang, Lap-Pui Chau|<http://arxiv.org/pdf/2506.14189v1>|[代码](https://dengkunyuan.github.io/EgoHOIBench); 提出了首个以第一人称视角的Ego-HOI检测基准Ego-HOIBench，并引入了利用手部几何和交互...|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Cost-Aware Routing for Efficient Text-To-Image Generation|成本感知路由策略用于高效文本到图像生成|Qinchan, Li, Kenneth Chen, Changyue, Su, Wittawat Jitkrittum, Qi Sun, Patsorn Sangkloy|<http://arxiv.org/pdf/2506.14753v1>|提出了一种按提示复杂性动态调整计算量的方法，实现了文本到图像生成中质量与成本的最优平衡。|
|📝 更新|FigCaps-HF: A Figure-to-Caption Generative Framework and Benchmark with Human Feedback|图注生成框架及带有人工反馈的基准：FigCaps-HF|Ashish Singh, Ashutosh Singh, Prateek Agarwal, Zixuan Huang, Arpita Singh, Tong Yu, Sungchul Kim, Victor Bursztyn .etc.|<http://arxiv.org/pdf/2307.10867v2>|引入了结合人类反馈的图到标题生成框架，优化了科学图表标题的生成质量。|
|🆕 发布|Align Your Flow: Scaling Continuous-Time Flow Map Distillation|《对齐您的流：扩展连续时间流图蒸馏》|Amirmojtaba Sabour, Sanja Fidler, Karsten Kreis|<http://arxiv.org/pdf/2506.14603v1>|提出了一种高效的连续时间流映射蒸馏方法，实现了图像生成中的少步采样性能提升。|
|🆕 发布|VisText-Mosquito: A Multimodal Dataset and Benchmark for AI-Based Mosquito Breeding Site Detection and Reasoning|“VisText-蚊子：一种用于基于人工智能的蚊子孳生地点检测与推理的多模态数据集与基准”|Md. Adnanul Islam, Md. Faiyaz Abdullah Sayeedi, Md. Asaduzzaman Shuvo, Muhammad Ziaur Rahman, Shahanur Rahman Bappy, Raiyan Rahman, Swakkhar Shatabda|<http://arxiv.org/pdf/2506.14629v1>|[代码](https://github.com/adnanul-islam-jisun/VisText-Mosquito); 提出了VisText-Mosquito多模态数据集，融合视觉与文本数据，用于自动检测和推理蚊虫孳生地...|
|🆕 发布|DreamLight: Towards Harmonious and Consistent Image Relighting|“DreamLight：迈向和谐一致性的图像重光照”|Yong Liu, Wenpeng Xiao, Qianqian Wang, Junlin Chen, Shiyin Wang, Yitong Wang, Xinglong Wu, Yansong Tang|<http://arxiv.org/pdf/2506.14549v1>|提出DreamLight模型，实现基于图像和文本的通用图像重光照，保持美观统一性并增强前景与背景的光...|
|🆕 发布|Adapting Lightweight Vision Language Models for Radiological Visual Question Answering|为放射学视觉问答任务适配轻量级视觉语言模型|Aditya Shourya, Michel Dumontier, Chang Sun|<http://arxiv.org/pdf/2506.14451v1>|提出了一种高效的轻量级视觉语言模型微调方法，用于放射学视觉问答，实现了在小规模数据上的稳健性能。|
|🆕 发布|Toward Rich Video Human-Motion2D Generation|面向丰富的视频二维人体运动生成|Ruihao Xi, Xuekuan Wang, Yongcheng Li, Shuhua Li, Zichen Wang, Yiwei Wang, Feng Wei, Cairong Zhao|<http://arxiv.org/pdf/2506.14428v1>|提出了一种基于大规模数据集和扩散模型的方法，实现了丰富视频人物动作的生成与控制。|
|🆕 发布|Causally Steered Diffusion for Automated Video Counterfactual Generation|因果引导的扩散算法用于自动视频反事实生成|Nikos Spyrou, Athanasios Vlontzos, Paraskevas Pegios, Thomas Melistas, Nefeli Gkouti, Yannis Panagakis, Giorgos Papanastasiou, Sotirios A. Tsaftaris|<http://arxiv.org/pdf/2506.14404v1>|提出了一种基于文本提示和因果图的框架，实现了对视频编辑中因果关系的忠实保持。|
|🆕 发布|ImmerseGen: Agent-Guided Immersive World Generation with Alpha-Textured Proxies|沉浸生成：基于智能体引导的具有Alpha纹理代理的沉浸式世界生成|Jinyan Yuan, Bangbang Yang, Keke Wang, Panwang Pan, Lin Ma, Xuehai Zhang, Xiao Liu, Zhaopeng Cui .etc.|<http://arxiv.org/pdf/2506.14315v1>|提出了一种基于代理的生成框架ImmerseGen，通过简化几何代理和RGBA纹理合成实现高效、逼真的...|
|📝 更新|H$^3$DP: Triply-Hierarchical Diffusion Policy for Visuomotor Learning|H$^3$DP：三层级扩散策略用于视觉运动学习|Yiyang Lu, Yufeng Tian, Zhecheng Yuan, Xianbang Wang, Pu Hua, Zhengrong Xue, Huazhe Xu|<http://arxiv.org/pdf/2505.07819v2>|[代码](https://lyy-iiis.github.io/h3dp); 提出了一种三层级 visuomotor 学习框架 H$^3$DP，通过深度感知输入层、多尺度视觉表示...|
|🆕 发布|Exploring Non-contrastive Self-supervised Representation Learning for Image-based Profiling|探索基于图像的剖析的非对比性自监督表征学习|Siran Dai, Qianqian Xu, Peisong Wen, Yang Liu, Qingming Huang|<http://arxiv.org/pdf/2506.14265v1>|提出SSLProfiler框架，通过特定数据增强和表征后处理，为细胞图像分析实现非对比自监督学习。|
|📝 更新|Controllable Dance Generation with Style-Guided Motion Diffusion|可控风格引导的运动扩散舞蹈生成|Hongsong Wang, Ying Zhu, Yang Zhang, Junbo Wang, Xin Geng, Liang Wang|<http://arxiv.org/pdf/2406.07871v2>|[代码](https://github.com/mucunzhuzhu/DGSDP.); 提出了一种基于音乐风格描述的舞蹈生成框架，通过整合音乐条件和风格提示，实现了与音乐内容风格一致的舞蹈...|
|🆕 发布|VideoMAR: Autoregressive Video Generatio with Continuous Tokens|视频MAR：基于连续标记的自回归视频生成|Hu Yu, Biao Gong, Hangjie Yuan, DanDan Zheng, Weilong Chai, Jingdong Chen, Kecheng Zheng, Feng Zhao|<http://arxiv.org/pdf/2506.14168v1>|提出VideoMAR模型，通过连续标记实现高效视频生成，同时解决长序列建模难题。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CDP: Towards Robust Autoregressive Visuomotor Policy Learning via Causal Diffusion|CDP: 通过因果扩散实现鲁棒自回归视觉运动策略学习|Jiahua Ma, Yiran Qin, Yixiong Li, Xuanqi Liao, Yulan Guo, Ruimao Zhang|<http://arxiv.org/pdf/2506.14769v1>|提出了一种基于历史动作序列的因果扩散策略，增强了机器人 visuomotor 学习的鲁棒性和准确性。|
|🆕 发布|Iterative Camera-LiDAR Extrinsic Optimization via Surrogate Diffusion|通过代理扩散的迭代相机-激光雷达外参优化|Ni Ou, Zhuo Chen, Xinru Zhang, Junzheng Wang|<http://arxiv.org/pdf/2506.14706v1>|提出了一种迭代优化框架，通过代理扩散改进相机与LiDAR外参校准的精度和稳定性。|
|📝 更新|Infinity: Scaling Bitwise AutoRegressive Modeling for High-Resolution Image Synthesis|无限：扩展位运算自回归建模以实现高分辨率图像合成|Jian Han, Jinlai Liu, Yi Jiang, Bin Yan, Yuqi Zhang, Zehuan Yuan, Bingyue Peng, Xiaobing Liu|<http://arxiv.org/pdf/2412.04431v2>|提出Infinity模型，通过无限词汇量标记器和位运算机制，实现了高效的高分辨率图像生成。|
|🆕 发布|Unsupervised Imaging Inverse Problems with Diffusion Distribution Matching|无监督成像逆问题中的扩散分布匹配|Giacomo Meanti, Thomas Ryckeboer, Michael Arbel, Julien Mairal|<http://arxiv.org/pdf/2506.14605v1>|提出了一种基于无配对数据集的图像复原方法，无需完整的前向模型知识或成对数据，实现了高效图像复原。|
|🆕 发布|Exploring Diffusion with Test-Time Training on Efficient Image Restoration|探索在测试时训练中扩散用于高效图像恢复的方法|Rongchang Lu, Tianduo Luo, Yunzhi Zhang, Conghan Yue, Pei Yang, Guibao Liu, Changyang Gu|<http://arxiv.org/pdf/2506.14541v1>|提出DiffRWKVIR框架，融合测试时训练与高效扩散，优化图像恢复的效率和效果。|
|📝 更新|FlowAlign: Trajectory-Regularized, Inversion-Free Flow-based Image Editing|流对齐：轨迹正则化、无逆操作的基于流的图像编辑|Jeongsol Kim, Yeobin Hong, Jong Chul Ye|<http://arxiv.org/pdf/2505.23145v2>|FlowAlign通过引入流匹配损失，实现了无需逆变换的流畅且稳定的图像编辑。|
|📝 更新|DexHandDiff: Interaction-aware Diffusion Planning for Adaptive Dexterous Manipulation|《DexHandDiff：面向自适应灵巧操作的人际交互感知扩散规划》|Zhixuan Liang, Yao Mu, Yixiao Wang, Tianxing Chen, Wenqi Shao, Wei Zhan, Masayoshi Tomizuka, Ping Luo .etc.|<http://arxiv.org/pdf/2411.18562v6>|提出了一种自适应灵巧操作的新型规划框架，通过交互感知的双阶段扩散过程显著提升了复杂操作任务的适应性及...|
|📝 更新|InkSight: Offline-to-Online Handwriting Conversion by Teaching Vision-Language Models to Read and Write|墨迹洞察：通过教导视觉-语言模型读写实现离线到在线手写转换|Blagoj Mitrevski, Arina Rak, Julian Schnitzler, Chengkun Li, Andrii Maksai, Jesse Berent, Claudiu Musat|<http://arxiv.org/pdf/2402.05804v4>|提出InkSight方法，将纸质手写笔记高效转换为数字墨水，实现离线到在线手写转换。|
|🆕 发布|Decoupled Classifier-Free Guidance for Counterfactual Diffusion Models|解耦的无分类器引导策略用于反事实扩散模型|Tian Xia, Fabio De Sousa Ribeiro, Rajat R Rasal, Avinash Kori, Raghav Mehta, Ben Glocker|<http://arxiv.org/pdf/2506.14399v1>|提出了一种新的图像生成框架DCFG，通过分组的条件控制改善了身份保持和减少了不期望的属性变化。|
|📝 更新|BS-LDM: Effective Bone Suppression in High-Resolution Chest X-Ray Images with Conditional Latent Diffusion Models|BS-LDM：基于条件潜在扩散模型的高分辨率胸部X射线图像有效骨骼抑制|Yifei Sun, Zhanghao Chen, Hao Zheng, Wenming Deng, Jin Liu, Wenwen Min, Ahmed Elazab, Xiang Wan .etc.|<http://arxiv.org/pdf/2412.15670v4>|[代码](https://github.com/diaoquesang/BS-LDM.); 提出BS-LDM框架，利用条件潜在扩散模型有效抑制高分辨率胸片中的骨骼结构，提高肺部病变检测准确性。|
|🆕 发布|FRIDU: Functional Map Refinement with Guided Image Diffusion|FRIDU：功能图精炼与引导图像扩散|Avigail Cohen Rimon, Mirela Ben-Chen, Or Litany|<http://arxiv.org/pdf/2506.14322v1>|提出了一种在功能图空间中训练图像扩散模型的方法，用于精确细化初始形状间的对应关系图。|
|📝 更新|Hardware-Friendly Static Quantization Method for Video Diffusion Transformers|面向硬件友好的静态量化方法用于视频扩散变换器|Sanghyun Yi, Qingfeng Liu, Mostafa El-Khamy|<http://arxiv.org/pdf/2502.15077v3>|提出了一种静态量化方法，使视频扩散变压器模型在资源受限设备上高效部署，不牺牲性能。|
|📝 更新|Benchmarking Vision, Language, & Action Models in Procedurally Generated, Open Ended Action Environments|在程序生成、开放性动作环境中对视觉、语言和动作模型进行基准测试|Pranav Guruprasad, Yangyue Wang, Sudipta Chowdhury, Harshvardhan Sikka, Paul Pu Liang|<http://arxiv.org/pdf/2505.05540v2>|提出了一种全面基准MultiNet v0.2，评估了视觉语言动作模型在开放环境中的零样本泛化能力。|
|📝 更新|AgentCPM-GUI: Building Mobile-Use Agents with Reinforcement Fine-Tuning|强化微调构建移动使用代理的AgentCPM-GUI|Zhong Zhang, Yaxi Lu, Yikun Fu, Yupeng Huo, Shenzhi Yang, Yesai Wu, Han Si, Xin Cong .etc.|<http://arxiv.org/pdf/2506.01391v2>|AgentCPM-GUI通过预训练、监督微调及强化学习，实现了对移动设备GUI的高效稳健交互。|
|🆕 发布|GAF: Gaussian Action Field as a Dvnamic World Model for Robotic Mlanipulation|高斯动作场：作为机器人操作动态世界模型的GAF方法|Ying Chai, Litao Deng, Ruizhi Shao, Jiajun Zhang, Liangjun Xing, Hongwen Zhang, Yebin Liu|<http://arxiv.org/pdf/2506.14135v1>|[代码](http://chaiying1.github.io/GAF.github.io); 提出V-4D-A框架，通过Gaussian Action Field建模动态场景和动作，提升机器人操...|
|📝 更新|VideoPDE: Unified Generative PDE Solving via Video Inpainting Diffusion Models|视频PDE：通过视频修复扩散模型实现统一生成性偏微分方程求解|Edward Li, Zichen Wang, Jiahe Huang, Jeong Joon Park|<http://arxiv.org/pdf/2506.13754v2>|提出了一种统一的生成模型框架，通过视频修复扩散模型高效解决偏微分方程问题。|
|📝 更新|3D Hand Mesh-Guided AI-Generated Malformed Hand Refinement with Hand Pose Transformation via Diffusion Model|三维手部网格引导的AI生成畸形手部细化通过手部姿态变换的扩散模型|Chen-Bin Feng, Kangdao Liu, Jian Sun, Jiping Jin, Yiguo Jiang, Chi-Man Vong|<http://arxiv.org/pdf/2506.12680v2>|提出了一种基于3D手部网格引导的扩散模型，有效改善了AI生成图像中手部形态的准确性并实现了手部姿态转...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Synthetic Data Augmentation for Table Detection: Re-evaluating TableNet's Performance with Automatically Generated Document Images|合成数据增强用于表格检测：使用自动生成的文档图像重新评估TableNet的性能|Krishna Sahukara, Zineddine Bettouche, Andreas Fischer|<http://arxiv.org/pdf/2506.14583v1>|提出自动化生成合成文档图像的方法，有效提升表格检测准确率并减少人工标注工作量。|
|🆕 发布|MobileHolo: A Lightweight Complex-Valued Deformable CNN for High-Quality Computer-Generated Hologram|移动全息：一种用于高质量计算机生成全息图的轻量级复值可变形卷积神经网络|Xie Shuyang, Zhou Jie, Xu Bo, Wang Jun, Xu Renjing|<http://arxiv.org/pdf/2506.14542v1>|提出了一种轻量级复值可变形卷积神经网络，有效提升了计算机生成全息图的重建质量与效率。|
|🆕 发布|Comparison of Two Methods for Stationary Incident Detection Based on Background Image|两种基于背景图像的静止事件检测方法的比较|Deepak Ghimire, Joonwhoan Lee|<http://arxiv.org/pdf/2506.14256v1>|提出两种基于背景减除的静止目标检测方法，有效应对遮挡和光照变化，实现实时监测。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PunchBench: Benchmarking MLLMs in Multimodal Punchline Comprehension|PunchBench：多模态 punchline 理解中大型语言模型基准测试|Kun Ouyang, Yuanxin Liu, Shicheng Li, Yi Liu, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun|<http://arxiv.org/pdf/2412.11906v2>|提出了PunchBench基准，用于全面评估多模态大语言模型对幽默理解的准确性，并提出了SC-CoQ...|
|📝 更新|A Survey on Personalized Content Synthesis with Diffusion Models|《基于扩散模型的个性化内容合成研究综述》|Xulu Zhang, Xiaoyong Wei, Wentao Hu, Jinlin Wu, Jiaxin Wu, Wengyu Zhang, Zhaoxiang Zhang, Zhen Lei .etc.|<http://arxiv.org/pdf/2405.05538v4>|系统梳理了个性化内容合成领域的研究框架和方法，为未来PCS发展指明了方向。|
|🆕 发布|Compressed Video Super-Resolution based on Hierarchical Encoding|基于分层编码的压缩视频超分辨率|Yuxuan Jiang, Siyue Teng, Qiang Zhu, Chen Feng, Chengxi Zeng, Fan Zhang, Shuyuan Zhu, Bing Zeng .etc.|<http://arxiv.org/pdf/2506.14381v1>|提出了一种针对压缩视频的超分辨率方法VSR-HE，通过层级编码变换块有效消除压缩伪影并提升视频质量。|
|📝 更新|T2V-OptJail: Discrete Prompt Optimization for Text-to-Video Jailbreak Attacks|T2V-OptJail：文本到视频越狱攻击的离散提示优化|Jiayang Liu, Siyuan Liang, Shiqian Zhao, Rongcheng Tu, Wenbo Zhou, Aishan Liu, Dacheng Tao, Siew Kei Lam|<http://arxiv.org/pdf/2505.06679v2>|提出离散优化方法T2V-OptJail，提升文本到视频生成模型的安全性，有效对抗不良内容生成攻击。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dense360: Dense Understanding from Omnidirectional Panoramas|全方位稠密理解：从全向全景图到稠密理解|Yikang Zhou, Tao Zhang, Dizhe Zhang, Shunping Ji, Xiangtai Li, Lu Qi|<http://arxiv.org/pdf/2506.14471v1>|首次实现基于全向全景图的稠密理解，提出ERP-RoPE编码方案解决全景图特性挑战。|
|📝 更新|GraphAU-Pain: Graph-based Action Unit Representation for Pain Intensity Estimation|基于图的动作单元表示用于疼痛强度估计的GraphAU-Pain|Zhiyu Wang, Yang Liu, Hatice Gunes|<http://arxiv.org/pdf/2505.19802v2>|提出图基行动单元表示方法GraphAU-Pain，通过建模面部行动单元及其关系，有效提升疼痛强度估算...|
|🆕 发布|Discrete JEPA: Learning Discrete Token Representations without Reconstruction|离散JEPA：无重建学习离散标记表示|Junyeob Baek, Hosung Lee, Christopher Hoang, Mengye Ren, Sungjin Ahn|<http://arxiv.org/pdf/2506.14373v1>|提出Discrete-JEPA方法，通过语义符号化改进图像表示，增强符号推理能力。|
|📝 更新|Efficient multi-view training for 3D Gaussian Splatting|三维高斯散点投射的高效多视角训练|Minhyuk Choi, Injae Kim, Hyunwoo J. Kim|<http://arxiv.org/pdf/2506.12727v2>|提出多视角训练优化方法，提升3D Gaussian Splatting性能并克服单视角训练局限。|
|🆕 发布|FADPNet: Frequency-Aware Dual-Path Network for Face Super-Resolution|频率感知双路径网络用于人脸超分辨率：FADPNet|Siyu Xu, Wenjie Li, Guangwei Gao, Jian Yang, Guo-Jun Qi, Chia-Wen Lin|<http://arxiv.org/pdf/2506.14121v1>|提出了一种频率感知双路径网络FADPNet，通过分离处理面部图像的高低频特征，有效提升了面部超分辨率...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Cross-Modal Geometric Hierarchy Fusion: An Implicit-Submap Driven Framework for Resilient 3D Place Recognition|跨模态几何层次融合：一种由隐式子图驱动的鲁棒三维场景识别框架|Xiaohui Jiang, Haijiang Zhu, Chadei Li, Fulin Tang, Ning An|<http://arxiv.org/pdf/2506.14243v1>|提出了一种基于弹性点隐式表示和跨模态几何层次融合的3D场景识别框架，增强了场景描述的稳定性和辨识力。|
|🆕 发布|HRGS: Hierarchical Gaussian Splatting for Memory-Efficient High-Resolution 3D Reconstruction|HRGS：分层高斯散点绘制用于内存高效的高分辨率三维重建|Changbai Li, Haodong Zhu, Hanlin Chen, Juan Zhang, Tongfei Chen, Shuo Yang, Shuwei Shao, Wenhao Dong .etc.|<http://arxiv.org/pdf/2506.14229v1>|提出 Hierarchical Gaussian Splatting 方法，通过分层优化和重要性驱动...|
|📝 更新|Niagara: Normal-Integrated Geometric Affine Field for Scene Reconstruction from a Single View|尼亚加拉：场景重建中从单视角出发的集成法线几何仿射场|Xianzu Wu, Zhenxin Ai, Harry Yang, Ser-Nam Lim, Jun Liu, Huan Wang|<http://arxiv.org/pdf/2503.12553v2>|定位户外场景重建难题，提出Niagara框架，融合深度与法线估计，引入几何仿射场与3D自注意力，实现...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Self-Supervised Enhancement for Depth from a Lightweight ToF Sensor with Monocular Images|单目图像辅助下轻量级飞行时间传感器深度信息自监督增强|Laiyan Ding, Hualie Jiang, Jiwei Chen, Rui Huang|<http://arxiv.org/pdf/2506.13444v2>|[代码](https://github.com/denyingmxd/selftof); 提出了一种自监督学习框架SelfToF，通过融合低分辨率ToF传感器数据和单目图像，有效生成高质量深...|


## 时序视觉分析 (Temporal Visual Analysis)


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes|鼠标锁箱数据集：小鼠解决锁箱行为识别|Patrik Reiske, Marcus N. Boon, Niek Andresen, Sole Traverso, Katharina Hohlbaum, Lars Lewejohann, Christa Thöne-Reineke, Olaf Hellwich .etc.|<http://arxiv.org/pdf/2505.15408v3>|提出了一种基于视频和关键点追踪的鼠类复杂行为识别方法，并构建了首个相关的大型数据集。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AMPLIFY: Actionless Motion Priors for Robot Learning from Videos|AMPLIFY：无动作运动先验用于机器人从视频中的学习|Jeremy A. Collins, Loránd Cheng, Kunal Aneja, Albert Wilcox, Benjamin Joffe, Animesh Garg|<http://arxiv.org/pdf/2506.14198v1>|[代码](https://amplify-robotics.github.io/.); 利用无动作视频数据学习机器人控制策略，提出分离视觉运动预测与动作推断的AMPLIFY框架。|
|📝 更新|Tile Classification Based Viewport Prediction with Multi-modal Fusion Transformer|基于多模态融合变换器的瓦片分类视角预测|Zhihao Zhang, Yiwei Chen, Weizhan Zhang, Caixia Yan, Qinghua Zheng, Qi Wang, Wangdu Chen|<http://arxiv.org/pdf/2309.14704v5>|提出了一种基于多模态融合变换器的瓦片分类方法，提高了360度视频流中视域预测的鲁棒性和准确性。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SDTrack: A Baseline for Event-based Tracking via Spiking Neural Networks|基于尖峰神经网络的_event-based_跟踪基线：SDTrack|Yimeng Shan, Zhenbang Ren, Haodi Wu, Wenjie Wei, Rui-Jie Zhu, Shuai Wang, Dehao Zhang, Yichen Xiao .etc.|<http://arxiv.org/pdf/2503.08703v2>|提出首个基于Transformer的 spike-driven 跟踪方法SDTrack，提升事件相机...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DiFuse-Net: RGB and Dual-Pixel Depth Estimation using Window Bi-directional Parallax Attention and Cross-modal Transfer Learning|DiFuse-Net：基于窗口双向视差注意力和跨模态迁移学习的RGB与双像素深度估计|Kunal Swami, Debtanu Gupta, Amrit Kumar Muduli, Chirag Jaiswal, Pankaj Kumar Bajpai|<http://arxiv.org/pdf/2506.14709v1>|提出了一种新型解耦网络DiFuse-Net，通过双向视差注意和跨模态迁移学习，有效提升RGB和双像素...|
|📝 更新|CellCLIP -- Learning Perturbation Effects in Cell Painting via Text-Guided Contrastive Learning|细胞CLIP -- 通过文本引导的对比学习了解细胞绘画中的扰动效应|Mingyu Lu, Ethan Weinberger, Chanwoo Kim, Su-In Lee|<http://arxiv.org/pdf/2506.06290v2>|提出CellCLIP框架，通过跨模态对比学习将细胞图像与扰动效果关联，提升高内涵筛选数据分析性能。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SyncTalk++: High-Fidelity and Efficient Synchronized Talking Heads Synthesis Using Gaussian Splatting|"SyncTalk++：使用高斯散点绘制的高保真与高效同步说话人头合成"|Ziqiao Peng, Wentao Hu, Junyuan Ma, Xiangyu Zhu, Xiaomei Zhang, Hao Zhao, Hui Tian, Jun He .etc.|<http://arxiv.org/pdf/2506.14742v1>|[代码](https://ziqiaopeng.github.io/synctalk); SyncTalk++通过动态肖像渲染和面部同步控制，实现了高保真且高效的同步说话人头视频合成。|
|🆕 发布|Train Once, Forget Precisely: Anchored Optimization for Efficient Post-Hoc Unlearning|一旦训练，精确遗忘：基于锚点的优化策略实现高效的事后遗忘|Prabhav Sanga, Jaskaran Singh, Arun K. Dubey|<http://arxiv.org/pdf/2506.14515v1>|提出了一种高效的框架FAMR，通过约束优化实现深度图像分类器中的精确后修复遗忘，无需完全重训练。|
|📝 更新|Automated Muscle and Fat Segmentation in Computed Tomography for Comprehensive Body Composition Analysis|计算机断层扫描中肌肉与脂肪自动分割技术用于全面身体成分分析|Yaqian Chen, Hanxue Gu, Yuwen Chen, Jicheng Yang, Haoyu Dong, Joseph Y. Cao, Adrian Camarena, Christopher Mantyh .etc.|<http://arxiv.org/pdf/2502.09779v2>|提出了一种自动化肌肉和脂肪分割的CT影像分析模型，提高了身体成分评估的准确性和便捷性。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ASCD: Attention-Steerable Contrastive Decoding for Reducing Hallucination in MLLM|注意驱动的对比解码以减少大规模语言模型中的虚构现象|Yujun Wang, Jinhe Bi, Yunpu Ma, Soeren Pirk|<http://arxiv.org/pdf/2506.14766v1>|提出了一种直接干预模型注意力机制的对比解码框架，有效减少大型多模态语言模型的虚构现象。|
|📝 更新|Diverse Topology Optimization using Modulated Neural Fields|使用调制神经场的多样化拓扑优化|Andreas Radler, Eric Volkmann, Johannes Brandstetter, Arturs Berzins|<http://arxiv.org/pdf/2502.13174v2>|提出了一种无需数据集的拓扑优化新方法，通过显式多样性约束生成多样化的最优结构设计。|
|🆕 发布|HydroChronos: Forecasting Decades of Surface Water Change|《HydroChronos：预测数十年的地表水变化》|Daniele Rege Cambrin, Eleonora Poeta, Eliana Pastor, Isaac Corley, Tania Cerquitelli, Elena Baralis, Paolo Garza|<http://arxiv.org/pdf/2506.14362v1>|提出HydroChronos多模态数据集及AquaClimaTempo UNet模型，有效预测水体动...|
|🆕 发布|KDMOS:Knowledge Distillation for Motion Segmentation|知识蒸馏用于运动分割：KDMOS|Chunyu Cao, Jintao Cheng, Zeyu Chen, Linfan Zhan, Rui Fan, Zhijian He, Xiaoyu Tang|<http://arxiv.org/pdf/2506.14130v1>|[代码](https://github.com/SCNU-RISLAB/KDMOS.); 提出了一种基于知识蒸馏的运动分割框架，通过定制化策略和动态上采样，实现了高准确性和实时效率的平衡。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Strategic Client Selection to Address Non-IIDness in HAPS-enabled FL Networks|战略性地选择客户端以解决 HAPS 启用 FL 网络中的非独立同分布特性|Amin Farajzadeh, Animesh Yadav, Halim Yanikomeroglu|<http://arxiv.org/pdf/2401.05308v3>|提出了一种基于多属性加权的客户端选择策略，有效解决了非独立同分布数据问题，提升了联邦学习模型的准确性...|
|📝 更新|HKD4VLM: A Progressive Hybrid Knowledge Distillation Framework for Robust Multimodal Hallucination and Factuality Detection in VLMs|HKD4VLM：一种用于大型视觉语言模型中稳健的多模态虚构与事实性检测的渐进式混合知识蒸馏框架|Zijian Zhang, Xuecheng Wu, Danlei Huang, Siyu Yan, Chong Peng, Xuezhi Cao|<http://arxiv.org/pdf/2506.13038v2>|提出了一种渐进式混合知识蒸馏框架HKD4VLM，用于提升大规模视觉语言模型在多模态幻觉检测和事实性检...|
|📝 更新|Knowledge Bridger: Towards Training-free Missing Modality Completion|知识桥接器：迈向无需训练的缺失模态补全|Guanzhou Ke, Shengfeng He, Xiao Li Wang, Bo Wang, Guoqing Chao, Yuanyang Zhang, Yi Xie, HeXing Su|<http://arxiv.org/pdf/2502.19834v5>|提出了一种无需训练的“知识桥接器”框架，通过大型多模态模型高效完成缺失模态的生成与排序，实现了跨领域...|
|🆕 发布|Model compression using knowledge distillation with integrated gradients|使用集成梯度进行知识蒸馏的模型压缩|David E. Hernandez, Jose Chang, Torbjörn E. M. Nordling|<http://arxiv.org/pdf/2506.14440v1>|提出了一种结合集成梯度数据增广的模型压缩方法，有效提升了小模型在保持高准确度的同时实现显著压缩。|
|🆕 发布|FGA-NN: Film Grain Analysis Neural Network|电影颗粒分析神经网络（FGA-NN）|Zoubida Ameur, Frédéric Lefebvre, Philippe De Lagrange, Miloš Radosavljević|<http://arxiv.org/pdf/2506.14350v1>|定位并建模电影颗粒，FGA-NN网络高效保真地恢复压缩影片中的艺术效果。|
|📝 更新|SeqPE: Transformer with Sequential Position Encoding|序列位置编码的Transformer：SeqPE|Huayang Li, Yahui Liu, Hongyu Sun, Deng Cai, Leyang Cui, Wei Bi, Peilin Zhao, Taro Watanabe|<http://arxiv.org/pdf/2506.13277v2>|[代码](https://github.com/ghrua/seqpe.); 提出SeqPE框架，通过序列位置编码学习，实现了Transformer模型在多模态任务中的自适应和扩...|
|📝 更新|Hardware-Rasterized Ray-Based Gaussian Splatting|硬件光栅化射线基础的高斯散点绘制|Samuel Rota Bulò, Nemanja Bartolovic, Lorenzo Porzi, Peter Kontschieder|<http://arxiv.org/pdf/2503.18682v2>|提出硬件光栅化射线基础高斯泼洒方法，实现高质量novel view合成并解决运动模糊问题。|
|📝 更新|Analyzing Effects of Mixed Sample Data Augmentation on Model Interpretability|分析混合样本数据增强对模型可解释性的影响|Soyoun Won, Sung-Ho Bae, Seong Tae Kim|<http://arxiv.org/pdf/2303.14608v2>|探究混合样本数据增强对模型可解释性的影响，提出新度量方法，发现增强方式影响显著。|
|📝 更新|Image Corruption-Inspired Membership Inference Attacks against Large Vision-Language Models|基于图像腐蚀启发的针对大型视觉语言模型的成员推断攻击|Zongyu Wu, Minhua Lin, Zhiwei Zhang, Fali Wang, Xianren Zhang, Xiang Zhang, Suhang Wang|<http://arxiv.org/pdf/2506.12340v2>|提出了一种基于图像腐蚀的成员推断攻击方法，有效识别图像是否用于训练大型视觉语言模型。|
|📝 更新|HyMamba: Mamba with Hybrid Geometry-Feature Coupling for Efficient Point Cloud Classification|HyMamba：结合混合几何-特征耦合的高效点云分类方法|Bin Liu, Chunyang Wang, Xuelian Liu, Bo Xiao, Guan Xi|<http://arxiv.org/pdf/2505.11099v2>|[代码](https://github.com/L1277471578/HyMamba); 提出HyMamba模型，通过几何特征耦合提升点云分类的局部特征提取和整体性能。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Busting the Paper Ballot: Voting Meets Adversarial Machine Learning|打破纸票选票：投票遭遇对抗性机器学习|Kaleel Mahmood, Caleb Manicke, Ethan Rathbun, Aayushi Verma, Sohaib Ahmad, Nicholas Stamatakis, Laurent Michel, Benjamin Fuller|<http://arxiv.org/pdf/2506.14582v1>|揭示了机器学习分类器在美国选举计票系统中的安全风险，并提出了有效的对抗性攻击方法。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enclosing Prototypical Variational Autoencoder for Explainable Out-of-Distribution Detection|用于可解释的异常检测的封装原型变分自编码器|Conrad Orglmeister, Erik Bochinski, Volker Eiselein, Elvira Fleig|<http://arxiv.org/pdf/2506.14390v1>|提出了一种结合自解释原型变分自编码器和自动编码器的异常检测方法，通过新型损失函数提高了分布内区域的紧...|
|📝 更新|Incentivizing Reasoning for Advanced Instruction-Following of Large Language Models|激励推理以提高大型语言模型的高级指令遵循能力|Yulei Qin, Gang Li, Zongyi Li, Zihan Xu, Yuchen Shi, Zhekai Lin, Xiao Cui, Ke Li .etc.|<http://arxiv.org/pdf/2506.01413v4>|提出了一种利用强化学习和可验证奖励信号激励推理的方法，显著提升了大型语言模型处理复杂指令的能力。|
|📝 更新|Unified Source-Free Domain Adaptation|统一无源域自适应|Song Tang, Wenxin Su, Mao Ye, Jianwei Zhang, Xiatian Zhu|<http://arxiv.org/pdf/2403.07601v3>|提出了一种统一的无源域自适应方法CausalDA，通过发现潜在因果因素，提高了模型在域迁移中的可靠性...|
|🆕 发布|Meta-SurDiff: Classification Diffusion Model Optimized by Meta Learning is Reliable for Online Surgical Phase Recognition|元学习优化的分类扩散模型Meta-SurDiff：在线手术阶段识别的可靠性|Yufei Li, Jirui Wu, Long Tian, Liming Wang, Xiaonan Liu, Zijun Liu, Xiyang Liu|<http://arxiv.org/pdf/2506.14181v1>|提出了一种基于元学习的分类扩散模型Meta-SurDiff，有效处理手术视频中的不确定性，提高在线手...|
|🆕 发布|Interpreting Biomedical VLMs on High-Imbalance Out-of-Distributions: An Insight into BiomedCLIP on Radiology|在高度不平衡的分布外数据上解释生物医学视觉语言模型：对放射学中BiomedCLIP的深入分析|Nafiz Sadman, Farhana Zulkernine, Benjamin Kwan|<http://arxiv.org/pdf/2506.14136v1>|分析了BiomedCLIP在医学图像分类中的局限性，并探讨了其适应不平衡数据集的方法。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Language and Planning in Robotic Navigation: A Multilingual Evaluation of State-of-the-Art Models|语言与机器人导航中的规划：对现有先进模型的多语种评估|Malak Mansour, Ahmed Aly, Bahey Tharwat, Sarim Hashmi, Dong An, Ian Reid|<http://arxiv.org/pdf/2501.05478v2>|首次将阿拉伯语集成到机器人视觉与语言导航领域，评估了多语言模型在导航推理中的表现。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VisLanding: Monocular 3D Perception for UAV Safe Landing via Depth-Normal Synergy|“VisLanding：通过深度-法线协同实现无人机安全着陆的单目3D感知”|Zhuoyue Tan, Boyong He, Yuxiang Ji, Liaoni Wu|<http://arxiv.org/pdf/2506.14525v1>|提出VisLanding框架，利用深度-法向协同预测实现无人机安全着陆区精准识别。|
|📝 更新|SmartWay: Enhanced Waypoint Prediction and Backtracking for Zero-Shot Vision-and-Language Navigation|智能路径：零样本视觉与语言导航中的增强型航点预测与回溯|Xiangyu Shi, Zerui Li, Wenqi Lyu, Jiatong Xia, Feras Dayoub, Yanyuan Qiao, Qi Wu|<http://arxiv.org/pdf/2503.10069v2>|提出了一种零样本视觉与语言导航框架，通过增强的航点预测器和基于多模态大语言模型的导航器，提高了空间感...|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Integrating Radiomics with Deep Learning Enhances Multiple Sclerosis Lesion Delineation|将影像组学与传统深度学习结合提升多发性硬化症病变更精确勾画|Nadezhda Alsahanova, Pavel Bartenev, Maksim Sharaev, Milos Ljubisavljevic, Taleb Al. Mansoori, Yauhen Statsenko|<http://arxiv.org/pdf/2506.14524v1>|整合放射组学特征与深度学习模型，显著提升了多发性硬化症病变的分割准确性和稳定性。|
|📝 更新|Learning Invariant Causal Mechanism from Vision-Language Models|从视觉语言模型中学习不变因果机制|Zeen Song, Siyu Zhao, Xingyu Zhang, Jiangmeng Li, Changwen Zheng, Wenwen Qiang|<http://arxiv.org/pdf/2405.15289v4>|提出了一种基于因果模型的CLIP-ICM框架，通过识别并利用不变因素，显著提升了CLIP模型在分布外...|
|📝 更新|Learning Spatially Adaptive $\ell_1$-Norms Weights for Convolutional Synthesis Regularization|学习空间自适应$\ell_1$-范数权重以进行卷积合成正则化|Andreas Kofler, Luca Calatroni, Christoph Kolbitsch, Kostas Papafitsoros|<http://arxiv.org/pdf/2503.09483v3>|提出了一种学习空间自适应参数图的方法，通过卷积合成和稀疏正则化，有效提升了图像重建质量。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ClearDepth: Enhanced Stereo Perception of Transparent Objects for Robotic Manipulation|透明物体增强立体感知的ClearDepth：机器人操作中的应用|Kaixin Bai, Huajian Zeng, Lei Zhang, Yiwen Liu, Hongli Xu, Zhaopeng Chen, Jianwei Zhang|<http://arxiv.org/pdf/2409.08926v2>|提出了一种基于视觉变换器的算法，通过特征后融合模块增强透明物体深度感知，实现了高效的仿真到现实数据转...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Desiderata-Driven Design of Visual Counterfactual Explainers|面向期望驱动的视觉反事实解释器设计|Sidney Bender, Jan Herrmann, Klaus-Robert Müller, Grégoire Montavon|<http://arxiv.org/pdf/2506.14698v1>|提出新的视觉反事实解释生成机制，设计出满足多方面需求的平滑反事实探索算法。|
|🆕 发布|Recognition through Reasoning: Reinforcing Image Geo-localization with Large Vision-Language Models|通过推理识别：利用大型视觉-语言模型强化图像地理定位|Ling Li, Yao Zhou, Yuxuan Liang, Fugee Tsung, Jiaheng Wei|<http://arxiv.org/pdf/2506.14674v1>|提出基于大型视觉语言模型的地理定位推理方法，构建了多样化数据集并优化了定位准确性及解释性。|
|📝 更新|Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents|以人类方式导航数字世界：面向GUI代理的通用视觉定位|Boyu Gou, Ruohan Wang, Boyuan Zheng, Yanan Xie, Cheng Chang, Yiheng Shu, Huan Sun, Yu Su|<http://arxiv.org/pdf/2410.05243v3>|提出视觉定位模型UGround，使GUI智能体仅通过视觉感知即可高效导航数字世界。|
|🆕 发布|SIRI-Bench: Challenging VLMs' Spatial Intelligence through Complex Reasoning Tasks|SIRI-Bench：通过复杂推理任务挑战视觉语言模型的空间智能|Zijian Song, Xiaoxin Lin, Qiuming Huang, Guangrun Wang, Liang Lin|<http://arxiv.org/pdf/2506.14512v1>|提出SIRI-Bench基准，通过视频推理任务评估视觉语言模型的空间智能。|
|🆕 发布|I Speak and You Find: Robust 3D Visual Grounding with Noisy and Ambiguous Speech Inputs|我说你找：基于噪声和不明确语音输入的鲁棒3D视觉定位|Yu Qi, Lipeng Gu, Honghua Chen, Liangliang Nan, Mingqiang Wei|<http://arxiv.org/pdf/2506.14495v1>|提出SpeechRefer框架，通过结合声音信号和对比学习，有效提升含噪声和模糊语音输入的3D视觉定...|
|📝 更新|Hanfu-Bench: A Multimodal Benchmark on Cross-Temporal Cultural Understanding and Transcreation|汉服-基准：一个关于跨时文化理解与创生的多模态评估基准|Li Zhou, Lutong Yu, Dongchu Xie, Shaohuan Cheng, Wenyan Li, Haizhou Li|<http://arxiv.org/pdf/2506.01565v2>|提出Hanfu-Bench多模态数据集，解决跨时间文化理解和创新设计问题。|
|📝 更新|MMedAgent-RL: Optimizing Multi-Agent Collaboration for Multimodal Medical Reasoning|多模态医疗推理中多智能体协作优化：MMedAgent-RL|Peng Xia, Jinglu Wang, Yibo Peng, Kaide Zeng, Xian Wu, Xiangru Tang, Hongtu Zhu, Yun Li .etc.|<http://arxiv.org/pdf/2506.00555v2>|提出了一种基于强化学习的多代理协作框架MMedAgent-RL，优化了多模态医疗推理中的代理合作，提...|
|🆕 发布|RadFabric: Agentic AI System with Reasoning Capability for Radiology|《RadFabric：具有推理能力的放射学智能代理系统》|Wenting Chen, Yi Dong, Zhaojun Ding, Yucheng Shi, Yifan Zhou, Fang Zeng, Yijun Luo, Tianyu Lin .etc.|<http://arxiv.org/pdf/2506.14142v1>|提出RadFabric系统，融合视觉与文本分析，提升胸部X光诊断的准确性和透明度。|
|📝 更新|An Open-Source Software Toolkit & Benchmark Suite for the Evaluation and Adaptation of Multimodal Action Models|一个开源软件工具包及基准测试套件，用于评估和适配多模态动作模型|Pranav Guruprasad, Yangyue Wang, Sudipta Chowdhury, Jaewoo Song, Harshvardhan Sikka|<http://arxiv.org/pdf/2506.09172v2>|介绍了MultiNet，一个开源的评测和适配多模态动作模型的工具包和基准套件，以促进视觉、语言和动作...|
|📝 更新|CSVQA: A Chinese Multimodal Benchmark for Evaluating STEM Reasoning Capabilities of VLMs|CSVQA：用于评估大型视觉语言模型STEM推理能力的中文多模态基准|Ai Jian, Weijie Qiu, Xiaokun Wang, Peiyu Wang, Yunzhuo Hao, Jiangbo Pei, Yichen Wei, Yi Peng .etc.|<http://arxiv.org/pdf/2505.24120v2>|提出CSVQA基准，专用于评估视觉语言模型在STEM领域的科学推理能力。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unified Representation Space for 3D Visual Grounding|三维视觉定位的统一表示空间|Yinuo Zheng, Lipeng Gu, Honghua Chen, Liangliang Nan, Mingqiang Wei|<http://arxiv.org/pdf/2506.14238v1>|提出了统一表示空间UniSpace-3D，通过融合视觉和文本特征，有效提升3D视觉定位和分类准确性。|
|📝 更新|Lecture Video Visual Objects (LVVO) Dataset: A Benchmark for Visual Object Detection in Educational Videos|教育视频视觉对象（LVVO）数据集：一个用于教育视频视觉对象检测的基准|Dipayan Biswas, Shishir Shah, Jaspal Subhlok|<http://arxiv.org/pdf/2506.13657v2>|介绍了LVVO数据集，为教育视频中的视觉对象检测提供首个专用基准。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Plug-and-Play with 2.5D Artifact Reduction Prior for Fast and Accurate Industrial Computed Tomography Reconstruction|“使用2.5D去伪迹先验的即插即用方法实现快速精确的工业计算机断层扫描重建”|Haley Duba-Sullivan, Aniket Pramanik, Venkatakrishnan Singanallur, Amirkoushyar Ziabari|<http://arxiv.org/pdf/2506.14719v1>|提出了一种利用2.5D卷积神经网络的插拔式重建方法，有效提升了工业CT扫描的重建质量和效率。|
|🆕 发布|Risk Estimation of Knee Osteoarthritis Progression via Predictive Multi-task Modelling from Efficient Diffusion Model using X-ray Images|通过高效扩散模型使用X射线影像进行膝关节骨性关节炎进展风险预测的多任务建模风险评估|David Butler, Adrian Hilton, Gustavo Carneiro|<http://arxiv.org/pdf/2506.14560v1>|提出了一种高效生成未来X光图像的扩散模型，通过多任务学习预测膝骨关节炎进展风险并定位关键解剖标志。|
|🆕 发布|A large-scale heterogeneous 3D magnetic resonance brain imaging dataset for self-supervised learning|用于自监督学习的规模化异构三维磁共振脑成像数据集|Asbjørn Munk, Stefano Cerri, Jakob Ambsdorf, Julia Machnio, Sebastian Nørgaard Llambias, Vardan Nersesjan, Christian Hedeager Krag, Peirong Liu .etc.|<http://arxiv.org/pdf/2506.14432v1>|构建了大规模异构3D脑部MRI数据集，助力自监督学习在医疗成像领域的发展与评估。|
|🆕 发布|DGG-XNet: A Hybrid Deep Learning Framework for Multi-Class Brain Disease Classification with Explainable AI|DGG-XNet：一种结合可解释人工智能的多类脑疾病分类混合深度学习框架|Sumshun Nahar Eity, Mahin Montasir Afif, Tanisha Fairooz, Md. Mortuza Ahmmed, Md Saef Ullah Miah|<http://arxiv.org/pdf/2506.14367v1>|提出DGG-XNet模型，融合VGG16与DenseNet121进行脑疾病多类别分类，提升准确度并增...|
|🆕 发布|BRISC: Annotated Dataset for Brain Tumor Segmentation and Classification with Swin-HAFNet|BRISC: 用于脑肿瘤分割与分类的Swin-HAFNet标注数据集|Amirreza Fateh, Yasin Rezvani, Sara Moayedi, Sadjad Rezvani, Fatemeh Fateh, Mansoor Fateh|<http://arxiv.org/pdf/2506.14318v1>|介绍了BRISC数据集，并提出了基于Transformer的Swin-HAFNet模型，显著提升了脑...|
|🆕 发布|orGAN: A Synthetic Data Augmentation Pipeline for Simultaneous Generation of Surgical Images and Ground Truth Labels|“orGAN：一种用于同时生成手术图像和真实标签的合成数据增强管道”|Niran Nataraj, Maina Sogabe, Kenji Kawashima|<http://arxiv.org/pdf/2506.14303v1>|提出orGAN系统，利用GAN生成高保真度、精确标注的出血手术图像，降低伦理问题和数据采集成本。|
|📝 更新|Exploring Linear Attention Alternative for Single Image Super-Resolution|探索线性注意力替代方案用于单幅图像超分辨率|Rongchang Lu, Changyu Li, Donghang Li, Guojing Zhang, Jianqiang Huang, Xilai Li|<http://arxiv.org/pdf/2502.00404v2>|提出OmniRWKVSR模型，结合RWKV架构与特征提取技术，提升单幅图像超分辨率质量和效率。|
|🆕 发布|Latent Anomaly Detection: Masked VQ-GAN for Unsupervised Segmentation in Medical CBCT|潜在异常检测：基于遮蔽VQ-GAN的无监督医学CBCT图像分割|Pengwei Wang|<http://arxiv.org/pdf/2506.14209v1>|提出了一种无监督训练方法，通过VQ-GAN和随机遮罩技术自动识别医学影像中的异常。|
|🆕 发布|One-Shot Neural Architecture Search with Network Similarity Directed Initialization for Pathological Image Classification|单次神经网络架构搜索：利用网络相似性指导初始化进行病理图像分类|Renao Yan|<http://arxiv.org/pdf/2506.14176v1>|提出了一种针对病理图像分类的稳定神经架构搜索方法，通过相似网络初始化和领域适应优化性能。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DepthSeg: Depth prompting in remote sensing semantic segmentation|深度分割：遥感语义分割中的深度提示方法|Ning Zhou, Shanxiong Chen, Mingting Zhou, Haigang Sui, Lieyun Hu, Han Li, Li Hua, Qiming Zhou|<http://arxiv.org/pdf/2506.14382v1>|提出了一种深度提示的遥感图像语义分割框架，通过融合高度信息解决了阴影遮挡和光谱混淆问题。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|WHALES: A Multi-agent Scheduling Dataset for Enhanced Cooperation in Autonomous Driving|鲸鱼调度：一种用于增强自动驾驶中多智能体合作的数据集|Richard Wang, Siwei Chen, Ziyi Song, Sheng Zhou|<http://arxiv.org/pdf/2411.13340v2>|[代码](https://github.com/chensiweiTHU/WHALES.); 提出首个大规模V2X交互数据集WHALES，引入通信元数据并设计新颖调度算法，提升自动驾驶协同感知性...|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Image Segmentation with Large Language Models: A Survey with Perspectives for Intelligent Transportation Systems|基于大型语言模型的图像分割：面向智能交通系统的综述与展望|Sanjeda Akter, Ibne Farabi Shihab, Anuj Sharma|<http://arxiv.org/pdf/2506.14096v1>|系统综述了大规模语言模型增强的图像分割技术，为智能交通系统提供了新的理解和应用视角。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Compositional Attribute Imbalance in Vision Datasets|计算机视觉数据集中的组合属性不平衡问题|Jiayi Chen, Yanbiao Ma, Andi Zhang, Weidong Tang, Wei Dai, Bowei Liu|<http://arxiv.org/pdf/2506.14418v1>|提出了一种基于CLIP框架的视觉属性字典构建方法，通过调整采样概率和增强技术缓解视觉属性不平衡问题，...|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|BiggerGait: Unlocking Gait Recognition with Layer-wise Representations from Large Vision Models|《BiggerGait：利用大型视觉模型逐层表征解锁步态识别》|Dingqiang Ye, Chao Fan, Zhanbo Huang, Chengwen Luo, Jianqiang Li, Shiqi Yu, Xiaoming Liu|<http://arxiv.org/pdf/2505.18132v3>|提出了一种基于大型视觉模型层表示的简单通用步态识别基线BiggerGait，显著提升了识别性能。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Active InSAR monitoring of building damage in Gaza during the Israel-Hamas War|"以色列-哈马斯战争期间加沙地区建筑损毁的主动干涉合成孔径雷达监测"|Corey Scher, Jamon Van Den Hoek|<http://arxiv.org/pdf/2506.14730v1>|利用干涉合成孔径雷达数据，提出长时序弧形相干变化检测方法，有效监测冲突区建筑损毁情况。|

