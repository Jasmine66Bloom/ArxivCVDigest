## [UPDATED!] **2025-06-18** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Demystifying the Visual Quality Paradox in Multimodal Large Language Models|揭开多模态大型语言模型视觉质量悖论的神秘面纱|Shuo Xing, Lanqing Guo, Hongyuan Hua, Seoyoung Lee, Peiran Li, Yufei Wang, Zhangyang Wang, Zhengzhong Tu|<http://arxiv.org/pdf/2506.15645v1>|发现多模态大语言模型对图像质量的独特偏好，并提出视觉质量测试时调整方法以提升性能。|
|🆕 发布|Show-o2: Improved Native Unified Multimodal Models|展示-o2：改进的原生统一多模态模型|Jinheng Xie, Zhenheng Yang, Mike Zheng Shou|<http://arxiv.org/pdf/2506.15564v1>|[代码](https://github.com/showlab/Show-o.); 提出了一种统一的多模态模型Show-o2，通过自回归建模和流匹配，有效提升了对图像和视频的理解和生成...|
|📝 更新|The OCR Quest for Generalization: Learning to recognize low-resource alphabets with model editing|OCR通用性探索：通过模型编辑学习识别低资源字母表|Adrià Molina Rodríguez, Oriol Ramos Terrades, Josep Lladós|<http://arxiv.org/pdf/2506.06761v2>|提出了一种利用模型编辑技术加速低资源语种学习的方法，显著提升了跨领域字符识别的泛化能力。|
|🆕 发布|MapFM: Foundation Model-Driven HD Mapping with Multi-Task Contextual Learning|地图FM：基于基础模型驱动的高精度地图构建与多任务上下文学习|Leonid Ivanov, Vasily Yuryev, Dmitry Yudin|<http://arxiv.org/pdf/2506.15313v1>|[代码](https://github.com/LIvanoff/MapFM.); 提出了一种端到端模型MapFM，通过融合基础模型和多任务学习，实现了高清地图的在线生成和精度提升。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey|《视觉语言模型时代下的广义分布外检测及其超越：综述》|Atsuyuki Miyai, Jingkang Yang, Jingyang Zhang, Yifei Ming, Yueqian Lin, Qing Yu, Go Irie, Shafiq Joty .etc.|<http://arxiv.org/pdf/2407.21794v2>|[代码](https://github.com/AtsuMiyai/Awesome-OOD-VLM.); 提出广义异常检测框架，整合视觉语言模型进展，明确未来研究方向。|
|📝 更新|LaViDa: A Large Diffusion Language Model for Multimodal Understanding|LaViDa：用于多模态理解的的大型扩散语言模型|Shufan Li, Konstantinos Kallidromitis, Hritik Bansal, Akash Gokul, Yusuke Kato, Kazuki Kozuka, Jason Kuen, Zhe Lin .etc.|<http://arxiv.org/pdf/2505.16839v3>|提出了一种基于离散扩散模型的新型视觉语言模型LaViDa，实现了快速推理和可控生成，优于现有自回归模...|
|📝 更新|SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models|SCAM：面向多模态基础模型的现实世界印刷稳健性评估|Justus Westerhoff, Erblina Purelku, Jakob Hackstein, Jonas Loos, Leo Pinetzki, Lorenz Hufe|<http://arxiv.org/pdf/2504.04893v5>|介绍了SCAM数据集，揭示了文本视觉攻击对多模态模型的影响，并验证了合成攻击的有效性。|
|🆕 发布|Robust Instant Policy: Leveraging Student's t-Regression Model for Robust In-context Imitation Learning of Robot Manipulation|稳健即时策略：利用学生t回归模型进行机器人操作稳健的情境模仿学习|Hanbit Oh, Andrea M. Salcedo-Vázquez, Ixchel G. Ramirez-Alpizar, Yukiyasu Domae|<http://arxiv.org/pdf/2506.15157v1>|提出了一种利用Student's t-回归模型的稳健即时模仿学习算法，有效应对机器人操作中的轨迹幻觉...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Vision Transformers Don't Need Trained Registers|视觉变换器无需训练寄存器|Nick Jiang, Amil Dravid, Alexei Efros, Yossi Gandelsman|<http://arxiv.org/pdf/2506.08010v3>|提出了一种无需重新训练的解决视觉变换器中异常注意力图的方法，通过转移高范数激活至未训练的额外令牌。|
|📝 更新|MSVIT: Improving Spiking Vision Transformer Using Multi-scale Attention Fusion|MSVIT：使用多尺度注意力融合改进脉冲视觉变换器|Wei Hua, Chenlin Zhou, Jibin Wu, Yansong Chua, Yangyang Shu|<http://arxiv.org/pdf/2505.14719v3>|[代码](https://github.com/Nanhu-AI-Lab/MSViT.); 提出MSVIT架构，通过多尺度注意力融合提升基于脉冲神经网络的视觉Transformer性能。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BoxFusion: Reconstruction-Free Open-Vocabulary 3D Object Detection via Real-Time Multi-View Box Fusion|BoxFusion：无需重建的实时多视角框融合开放词汇三维物体检测|Yuqing Lan, Chenyang Zhu, Zhirui Gao, Jiazhao Zhang, Yihan Cao, Renjiao Yi, Yijie Wang, Kai Xu|<http://arxiv.org/pdf/2506.15610v1>|提出了无需重建的实时多视角框融合方法，实现了内存高效且实时的三维物体检测。|
|📝 更新|Instance-Adaptive Keypoint Learning with Local-to-Global Geometric Aggregation for Category-Level Object Pose Estimation|类别级对象姿态估计的实例自适应关键点学习与局部到全局几何聚合|Xiao Zhang, Lu Zou, Tao Lu, Yuan Yao, Zhangjin Huang, Guoping Wang|<http://arxiv.org/pdf/2504.15134v3>|提出了一种针对类别级对象位姿估计的实例自适应关键点学习方法，通过局部到全局几何聚合显著提高了预测准确...|
|🆕 发布|Convolutional Feature Enhancement and Attention Fusion BiFPN for Ship Detection in SAR Images|卷积特征增强与注意力融合 BiFPN 用于合成孔径雷达图像中的船舶检测|Liangjie Meng, Danxia Li, Jinrong He, Lili Ma, Zhixin Li|<http://arxiv.org/pdf/2506.15231v1>|提出了一种用于合成孔径雷达图像船舶检测的特征增强与注意力融合框架，有效提升了小目标检测准确性和多尺度...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Leveraging Depth and Language for Open-Vocabulary Domain-Generalized Semantic Segmentation|利用深度与语言进行开放词汇域泛化的语义分割|Siyu Chen, Ting Han, Chengzheng Fu, Changshe Zhang, Chaolei Wang, Jinhe Su, Guorong Cai, Meiliu Wu|<http://arxiv.org/pdf/2506.09881v2>|[代码](https://github.com/anonymouse-9c53tp182bvz/Vireo.); 提出了一种统一框架Vireo，结合深度信息和语言提示，实现了跨领域和开放词汇的语义分割。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|YOLOv11-RGBT: Towards a Comprehensive Single-Stage Multispectral Object Detection Framework|面向全面的一阶段多光谱目标检测框架：YOLOv11-RGBT|Dahang Wan, Rongsheng Lu, Yang Fang, Xianli Lang, Shuangbao Shu, Jingjing Chen, Siyuan Shen, Ting Xu .etc.|<http://arxiv.org/pdf/2506.14696v2>|[代码](https://github.com/wandahangFY/YOLOv11-RGBT.); 提出了一种全面的单阶段多光谱目标检测框架YOLOv11-RGBT，通过多模态融合策略和自适应调整，显...|
|🆕 发布|Retrospective Memory for Camouflaged Object Detection|“用于迷彩目标检测的后瞻性记忆”|Chenxi Zhang, Jiayun Wu, Qing Zhang, Yazhe Zhai, Youwei Pang|<http://arxiv.org/pdf/2506.15244v1>|提出了一种结合历史知识记忆的检测架构，有效提升了复杂迷彩场景中的目标检测性能。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OpenPath: Open-Set Active Learning for Pathology Image Classification via Pre-trained Vision-Language Models|开放路径：通过预训练视觉语言模型的病理图像分类开放集主动学习方法|Lanfeng Zhong, Xin Liao, Shichuan Zhang, Shaoting Zhang, Guotai Wang|<http://arxiv.org/pdf/2506.15318v1>|[代码](https://github.com/HiLab-git/OpenPath); 提出了一种针对病理图像分类的开集主动学习方法OpenPath，利用预训练的视觉语言模型有效选择样本，...|
|🆕 发布|Domain Adaptation for Image Classification of Defects in Semiconductor Manufacturing|半导体制造中缺陷图像分类的域自适应|Adrian Poniatowski, Natalie Gentner, Manuel Barusco, Davide Dalle Pezze, Samuele Salti, Gian Antonio Susto|<http://arxiv.org/pdf/2506.15260v1>|提出DBACS模型，通过增强损失项提升半导体制造中缺陷分类的域自适应性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Particle-Grid Neural Dynamics for Learning Deformable Object Models from RGB-D Videos|粒子-网格神经动力学：从RGB-D视频中学习可变形对象模型|Kaifeng Zhang, Baoyu Li, Kris Hauser, Yunzhu Li|<http://arxiv.org/pdf/2506.15680v1>|[代码](https://kywind.github.io/pgnd); 提出了一种结合粒子与空间网格的神经网络模型，有效学习可变形物体的动态行为。|
|🆕 发布|Evolutionary Caching to Accelerate Your Off-the-Shelf Diffusion Model|《利用进化缓存加速您的现成扩散模型》|Anirud Aggarwal, Abhinav Shrivastava, Matthew Gwilliam|<http://arxiv.org/pdf/2506.15682v1>|[代码](https://github.com/aniaggarwal/ecad.); 提出了一种进化缓存策略ECAD，通过遗传算法优化缓存方案，显著提升了扩散模型的推理速度和泛化能力。|
|🆕 发布|UniRelight: Learning Joint Decomposition and Synthesis for Video Relighting|统一重光照：学习视频重光照的联合分解与合成|Kai He, Ruofan Liang, Jacob Munkberg, Jon Hasselgren, Nandita Vijaykumar, Alexander Keller, Sanja Fidler, Igor Gilitschenski .etc.|<http://arxiv.org/pdf/2506.15673v1>|提出了一种视频重光照方法，通过单次估计反光率和合成重照输出，实现了高质量的场景内在理解和光线传输合成...|
|🆕 发布|One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution|一步扩散实现细节丰富且时间一致的视频超分辨率|Yujing Sun, Lingchen Sun, Shuaizheng Liu, Rongyuan Wu, Zhengqiang Zhang, Lei Zhang|<http://arxiv.org/pdf/2506.15591v1>|[代码](https://github.com/yjsunnn/DLoRAL.); 提出了一种双LoRA学习框架，通过迭代优化实现视频超分辨率中的细节丰富和时序一致性。|
|🆕 发布|HOIDiNi: Human-Object Interaction through Diffusion Noise Optimization|通过扩散噪声优化实现的人-物交互HOIDiNi|Roey Ron, Guy Tevet, Haim Sawdayee, Amit H. Bermano|<http://arxiv.org/pdf/2506.15625v1>|提出了一种基于文本驱动的扩散噪声优化框架，实现了高精度的人物-物体交互生成。|
|📝 更新|TARDIS STRIDE: A Spatio-Temporal Road Image Dataset and World Model for Autonomy|时空道路图像数据集与世界模型：TARDIS STRIDE 用于自主性研究|Héctor Carrión, Yutong Bai, Víctor A. Hernández Castro, Kishan Panaganti, Ayush Zenith, Matthew Trang, Tony Zhang, Pietro Perona .etc.|<http://arxiv.org/pdf/2506.11302v2>|提出了一种融合空间和时间动态的统一自回归框架，通过STRIDE数据集显著提升了自主代理的环境模拟和操...|
|📝 更新|Style-Preserving Lip Sync via Audio-Aware Style Reference|通过音频感知风格参照实现风格保持的唇形同步|Weizhi Zhong, Jichang Li, Yinqi Cai, Ming Li, Feng Gao, Liang Lin, Guanbin Li|<http://arxiv.org/pdf/2408.05412v2>|提出了一种音频感知的风格参考方案，实现了保留个人说话风格的精确唇语同步。|
|🆕 发布|When Model Knowledge meets Diffusion Model: Diffusion-assisted Data-free Image Synthesis with Alignment of Domain and Class|当模型知识与扩散模型相遇：基于域与类对齐的无数据图像生成辅助方法|Yujin Kim, Hyunsoo Kim, Hyunwoo J. Kim, Suhyun Kim|<http://arxiv.org/pdf/2506.15381v1>|提出了一种利用文本到图像扩散模型作为图像先验的DDIS方法，通过领域和类别对齐，有效生成符合训练数据...|
|🆕 发布|Human Motion Capture from Loose and Sparse Inertial Sensors with Garment-aware Diffusion Models|基于宽松稀疏惯性传感器和衣物感知扩散模型的人体运动捕捉|Andela Ilic, Jiaxi Jiang, Paul Streli, Xintong Liu, Christian Holz|<http://arxiv.org/pdf/2506.15290v1>|提出了一种基于变压器和扩散模型的方法，用于从松散和不密集的惯性传感器估计全身姿态。|
|🆕 发布|One-shot Face Sketch Synthesis in the Wild via Generative Diffusion Prior and Instruction Tuning|通过生成扩散先验和指令微调在野外环境中实现单次人脸草图合成|Han Wu, Junyao Li, Kangbo Zhao, Sen Zhang, Yukai Shi, Liang Lin|<http://arxiv.org/pdf/2506.15312v1>|[代码](https://github.com/HanWu3125/OS-Sketch); 提出了一种基于生成扩散先验和指令微调的一键式人脸草图合成方法，解决了数据稀缺和人力成本高的问题。|
|🆕 发布|video-SALMONN 2: Captioning-Enhanced Audio-Visual Large Language Models|视频-SALMONN 2：增强型字幕音频-视觉大型语言模型|Changli Tang, Yixuan Li, Yudong Yang, Jimin Zhuang, Guangzhi Sun, Wei Li, Zejun Ma, Chao Zhang|<http://arxiv.org/pdf/2506.15220v1>|[代码](https://github.com/bytedance/video-SALMONN-2); 提出video-SALMONN 2模型，通过低秩适应和新型多轮优化方法显著提升视频描述的完整性和准确...|
|📝 更新|Generative diffusion model surrogates for mechanistic agent-based biological models|生成扩散模型代理在机制性基于代理的生物模型中的应用|Tien Comlekoglu, J. Quetzalcoatl Toledo-Marín, Douglas W. DeSimone, Shayn M. Peirce, Geoffrey Fox, James A. Glazier|<http://arxiv.org/pdf/2505.09630v2>|利用生成扩散模型训练代理模型，大幅减少复杂生物系统计算时间。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Cosmos-Drive-Dreams: Scalable Synthetic Driving Data Generation with World Foundation Models|“Cosmos-Drive-Dreams：基于世界基础模型的可扩展合成驾驶数据生成”|Xuanchi Ren, Yifan Lu, Tianshi Cao, Ruiyuan Gao, Shengyu Huang, Amirmojtaba Sabour, Tianchang Shen, Tobias Pfaff .etc.|<http://arxiv.org/pdf/2506.09042v3>|提出了一种生成高保真合成驾驶数据的 pipeline，用于解决自动驾驶系统训练中的边缘案例问题。|
|🆕 发布|Sekai: A Video Dataset towards World Exploration|“世界探索之向：Sekai视频数据集”|Zhen Li, Chuanhao Li, Xiaofeng Mao, Shaoheng Lin, Ming Li, Shitian Zhao, Zhaopan Xu, Xinyue Li .etc.|<http://arxiv.org/pdf/2506.15675v1>|构建了全球首个大规模、多样化标注的探索型视频数据集Sekai，助力互动世界探索模型的训练。|
|📝 更新|VideoHallu: Evaluating and Mitigating Multi-modal Hallucinations on Synthetic Video Understanding|视频幻觉评估与缓解：在合成视频理解中的多模态幻觉处理|Zongxia Li, Xiyang Wu, Guangyao Shi, Yubin Qin, Hongyang Du, Tianyi Zhou, Dinesh Manocha, Jordan Lee Boyd-Graber|<http://arxiv.org/pdf/2505.01481v3>|[代码](https://github.com/zli12321/VideoHallu.git.); 提出VideoHallu基准，评估并提升多模态大语言模型在合成视频异常检测和批判性思维的能力。|
|🆕 发布|Control and Realism: Best of Both Worlds in Layout-to-Image without Training|在无需训练的情况下实现布局到图像的控制与真实感：两者的最佳结合|Bonan Li, Yinhan Hu, Songhua Liu, Xinchao Wang|<http://arxiv.org/pdf/2506.15563v1>|提出无训练生成精确控制与真实感兼备的布局到图像方法WinWinLay，通过非局部注意力与自适应更新策...|
|🆕 发布|NTIRE 2025 Image Shadow Removal Challenge Report|“NTIRE 2025图像阴影移除挑战赛报告”|Florin-Alexandru Vasluianu, Tim Seizinger, Zhuyun Zhou, Cailian Chen, Zongwei Wu, Radu Timofte, Mingjia Li, Jin Hu .etc.|<http://arxiv.org/pdf/2506.15524v1>|分析了NTIRE 2025阴影移除挑战的成果，推动了阴影去除技术在重建保真度和视觉感知上的进步。|
|📝 更新|Ophora: A Large-Scale Data-Driven Text-Guided Ophthalmic Surgical Video Generation Model|Ophora：一种大规模数据驱动、文本引导的眼科手术视频生成模型|Wei Li, Ming Hu, Guoan Wang, Lihao Liu, Kaijin Zhou, Junzhi Ning, Xin Guo, Zongyuan Ge .etc.|<http://arxiv.org/pdf/2505.07449v5>|[代码](https://github.com/mar-cry/Ophora.); 提出Ophora模型，通过自然语言指令生成高质量的眼科手术视频，解决了隐私和标注难题。|
|📝 更新|VideoMAR: Autoregressive Video Generatio with Continuous Tokens|视频MAR：基于连续标记的自回归视频生成|Hu Yu, Biao Gong, Hangjie Yuan, DanDan Zheng, Weilong Chai, Jingdong Chen, Kecheng Zheng, Feng Zhao|<http://arxiv.org/pdf/2506.14168v2>|提出VideoMAR模型，通过连续标记实现高效视频生成，同时解决长序列建模难题。|
|🆕 发布|ReSeDis: A Dataset for Referring-based Object Search across Large-Scale Image Collections|基于指示的对象搜索大规模图像集合的数据集：ReSeDis|Ziling Huang, Yidan Zhang, Shin'ichi Satoh|<http://arxiv.org/pdf/2506.15180v1>|提出了ReSeDis任务，将大规模图像集合中的文本描述与像素级定位相结合，提高了视觉搜索的准确性和效...|
|🆕 发布|Privacy-Shielded Image Compression: Defending Against Exploitation from Vision-Language Pretrained Models|隐私保护的图像压缩：抵御视觉-语言预训练模型的利用攻击|Xuelin Shen, Jiayin Xu, Kangsheng Yin, Wenhan Yang|<http://arxiv.org/pdf/2506.15201v1>|提出了一种隐私保护的图像压缩方法，通过编码策略抵御视觉语言预训练模型的利用风险。|
|📝 更新|PRO: Projection Domain Synthesis for CT Imaging|投影域合成技术在CT成像中的应用|Kang Chen, Bin Huang, Xuebin Yang, Junyan Zhang, Qiegen Liu|<http://arxiv.org/pdf/2506.13443v2>|[代码](https://github.com/yqx7150/PRO.); 首次在投影域实现CT图像合成，通过结构化表示和文本提示提升数据生成质量和应用泛化能力。|
|📝 更新|ImmerseGen: Agent-Guided Immersive World Generation with Alpha-Textured Proxies|沉浸生成：基于智能体引导的具有Alpha纹理代理的沉浸式世界生成|Jinyan Yuan, Bangbang Yang, Keke Wang, Panwang Pan, Lin Ma, Xuehai Zhang, Xiao Liu, Zhaopeng Cui .etc.|<http://arxiv.org/pdf/2506.14315v2>|提出了一种基于代理的生成框架ImmerseGen，通过简化几何代理和合成纹理实现高效、逼真的虚拟现实...|
|📝 更新|SurgSora: Object-Aware Diffusion Model for Controllable Surgical Video Generation|“SurgSora：面向可控手术视频生成的对象感知扩散模型”|Tong Chen, Shuya Yang, Junyi Wang, Long Bai, Hongliang Ren, Luping Zhou|<http://arxiv.org/pdf/2412.14018v2>|[代码](https://surgsora.github.io/surgsora.github.io.); 提出SurgSora框架，通过自预测对象特征和深度信息生成高质量、可控运动的手术视频。|
|📝 更新|Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think|表示对齐用于生成：训练扩散变换器比您想象的要简单|Sihyun Yu, Sangkyung Kwak, Huiwon Jang, Jongheon Jeong, Jonathan Huang, Jinwoo Shin, Saining Xie|<http://arxiv.org/pdf/2410.06940v4>|提出了一种简单有效的正则化策略REPA，通过引入外部预训练视觉编码器的干净图像表示，显著提升了扩散模...|
|📝 更新|AdaVideoRAG: Omni-Contextual Adaptive Retrieval-Augmented Efficient Long Video Understanding|AdaVideoRAG：全场景自适应检索增强的高效长视频理解|Zhucun Xue, Jiangning Zhang, Xurong Xie, Yuxuan Cai, Yong Liu, Xiangtai Li, Dacheng Tao|<http://arxiv.org/pdf/2506.13589v2>|[代码](https://github.com/xzc-zju/AdaVideoRAG.); 提出了一种自适应检索的视频理解框架AdaVideoRAG，根据查询复杂度动态调整检索粒度，提升长视频...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Nabla-R2D3: Effective and Efficient 3D Diffusion Alignment with 2D Rewards|Nabla-R2D3: 基于二维奖励的有效高效三维扩散对齐|Qingming Liu, Zhen Liu, Dinghuai Zhang, Kui Jia|<http://arxiv.org/pdf/2506.15684v1>|提出了一种高效且样本效率高的3D扩散模型强化学习对齐框架，使用2D奖励信号优化3D生成质量。|
|📝 更新|A Comprehensive Survey on Continual Learning in Generative Models|生成模型中持续学习的全面调查|Haiyang Guo, Fanhu Zeng, Fei Zhu, Jiayi Wang, Xukai Wang, Jingang Zhou, Hongbo Zhao, Wenzhuo Liu .etc.|<http://arxiv.org/pdf/2506.13045v2>|[代码](https://github.com/Ghy0501/Awesome-Continual-Learning-in-Generative-Models.); 系统梳理了生成模型中持续学习的方法，分为架构、正则化和重放三大类，以克服灾难性遗忘问题。|
|🆕 发布|Hunyuan3D 2.1: From Images to High-Fidelity 3D Assets with Production-Ready PBR Material|Hunyuan3D 2.1：从图像到高保真3D资产的生产就绪PBR材质|Team Hunyuan3D, Shuhui Yang, Mingxin Yang, Yifei Feng, Xin Huang, Sheng Zhang, Zebin He, Di Luo .etc.|<http://arxiv.org/pdf/2506.15442v1>|介绍了Hunyuan3D 2.1系统，通过简化3D数据加工和模型训练，实现了高保真3D资产的高效生成...|
|📝 更新|EmoEdit: Evoking Emotions through Image Manipulation|情感编辑：通过图像处理唤起情感|Jingyuan Yang, Jiawei Feng, Weibin Luo, Dani Lischinski, Daniel Cohen-Or, Hui Huang|<http://arxiv.org/pdf/2405.12661v3>|提出EmoEdit方法，通过内容修改增强图像的情感影响力，并训练情感适配器提升生成模型情感感知能力。|
|🆕 发布|Break Stylistic Sophon: Are We Really Meant to Confine the Imagination in Style Transfer?|打破风格性少子：我们真的应该将想象力限制在风格迁移中吗？|Gary Song Yan, Yusen Zhang, Jinyu Zhao, Hao Zhang, Zhangping Yang, Guanye Xiong, Yanfei Liu, Tao Zhang .etc.|<http://arxiv.org/pdf/2506.15033v1>|引入StyleWallfacer框架，通过语义风格注入和三元扩散过程实现高效、保真的艺术级风格迁移与...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GenHOI: Generalizing Text-driven 4D Human-Object Interaction Synthesis for Unseen Objects|《GenHOI：面向未见对象的文本驱动4D人-物交互合成的泛化》|Shujia Li, Haiyu Zhang, Xinyuan Chen, Yaohui Wang, Yutong Ban|<http://arxiv.org/pdf/2506.15483v1>|提出GenHOI框架，通过分阶段方法实现未见物体的高保真4D人-物交互生成。|
|🆕 发布|BCRNet: Enhancing Landmark Detection in Laparoscopic Liver Surgery via Bezier Curve Refinement|BCRNet：通过贝塞尔曲线细化增强腹腔镜肝脏手术中的地标检测|Qian Li, Feng Liu, Shuojue Yang, Daiyun Shen, Yueming Jin|<http://arxiv.org/pdf/2506.15279v1>|提出了一种通过贝塞尔曲线优化策略增强腹腔镜肝脏手术中关键解剖结构检测精度的BCRNet框架。|
|📝 更新|Improving LLM Video Understanding with 16 Frames Per Second|以16帧每秒提升大规模语言模型视频理解能力|Yixuan Li, Changli Tang, Jimin Zhuang, Yudong Yang, Guangzhi Sun, Wei Li, Zejun Ma, Chao Zhang|<http://arxiv.org/pdf/2503.13956v2>|[代码](https://github.com/bytedance/F-16); 提出高帧率视频理解新方法F-16，通过提升帧率至16FPS，有效增强视觉信息捕捉，实现视频理解性能突...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RDD: Robust Feature Detector and Descriptor using Deformable Transformer|RDD：基于可变形变换器的鲁棒特征检测与描述符|Gonglin Chen, Tianwen Fu, Haiwei Chen, Wenbin Teng, Hanyuan Xiao, Yajie Zhao|<http://arxiv.org/pdf/2505.08013v2>|提出RDD方法，利用可变形变换器捕获全局上下文和几何不变性，提升极端场景下的特征检测与描述鲁棒性。|
|🆕 发布|A Unified Graph-based Framework for Scalable 3D Tree Reconstruction and Non-Destructive Biomass Estimation from Point Clouds|一种基于图的统一框架，用于从点云中进行可扩展的3D树木重建和非破坏性生物量估算|Di Wang, Shi Li|<http://arxiv.org/pdf/2506.15577v1>|提出了一种统一的基于图的框架，实现了大规模点云的端到端处理，用于3D树木重建和非破坏性生物量估算。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RaCalNet: Radar Calibration Network for Sparse-Supervised Metric Depth Estimation|RaCalNet：用于稀疏监督度量深度估计的雷达校准网络|Xingrui Qin, Wentao Zhao, Chuan Cao, Yihe Niu, Houcheng Jiang, Jingchuan Wang|<http://arxiv.org/pdf/2506.15560v1>|提出RaCalNet，通过稀疏LiDAR监督精炼雷达测量，无需密集监督即可实现精确深度估计。|
|🆕 发布|An Empirical Study of Bugs in Data Visualization Libraries|数据可视化库中错误的实证研究|Weiqi Lu, Yongqiang Tian, Xiaohan Zhong, Haoyang Ma, Zhenyang Xu, Shing-Chi Cheung, Chengnian Sun|<http://arxiv.org/pdf/2506.15084v1>|首次全面分析数据可视化库中的错误，识别了主要根源并提出自动化测试方法。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MCOO-SLAM: A Multi-Camera Omnidirectional Object SLAM System|多相机全方位目标SLAM系统：MCOO-SLAM|Miaoxin Pan, Jinnan Li, Yaowen Zhang, Yi Yang, Yufeng Yue|<http://arxiv.org/pdf/2506.15402v1>|提出了一种多相机全景对象SLAM系统，通过环绕视图配置实现复杂户外场景的鲁棒、一致和语义丰富的映射。|
|📝 更新|Rasterizing Wireless Radiance Field via Deformable 2D Gaussian Splatting|通过可变形二维高斯散点绘制无线辐射场|Mufan Liu, Cixiao Zhang, Qi Yang, Yujie Cao, Yiling Xu, Yin Xu, Shu Sun, Mingzeng Dai .etc.|<http://arxiv.org/pdf/2506.12787v2>|[代码](https://evan-sudo.github.io/swiftwrf); 提出高效准确的无线辐射场建模方法，通过可变形二维高斯散点渲染实现快速重构。|
|🆕 发布|MSNeRV: Neural Video Representation with Multi-Scale Feature Fusion|多尺度特征融合的神经视频表示：MSNeRV|Jun Zhu, Xinfeng Zhang, Lv Tang, JunHao Jiang|<http://arxiv.org/pdf/2506.15276v1>|提出多尺度特征融合框架MSNeRV，提升视频细节表示和压缩效率。|
|📝 更新|PanopticNeRF-360: Panoramic 3D-to-2D Label Transfer in Urban Scenes|全景NeRF-360：城市场景中的全景3D到2D标签迁移|Xiao Fu, Shangzhan Zhang, Tianrun Chen, Yichong Lu, Xiaowei Zhou, Andreas Geiger, Yiyi Liao|<http://arxiv.org/pdf/2309.10815v4>|[代码](https://github.com/fuxiao0719/PanopticNeRF); 提出了一种结合3D和2D信息生成高质量全景标注的方法，提高了自动驾驶感知系统的泛化能力。|
|🆕 发布|RA-NeRF: Robust Neural Radiance Field Reconstruction with Accurate Camera Pose Estimation under Complex Trajectories|RA-NeRF：在复杂轨迹下具有精确相机位姿估计的稳健神经辐射场重建|Qingsong Yan, Qiang Wang, Kaiyong Zhao, Jie Chen, Bo Li, Xiaowen Chu, Fei Deng|<http://arxiv.org/pdf/2506.15242v1>|提出RA-NeRF方法，通过增强相机位姿估计准确性，在复杂轨迹下实现鲁棒的神经辐射场重建。|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Open-World Object Counting in Videos|视频中的开放世界目标计数|Niki Amini-Naieni, Andrew Zisserman|<http://arxiv.org/pdf/2506.15368v1>|[代码](https://github.com/niki-amini-naieni/CountVid); 提出CountVid模型，实现视频中的开放式目标对象计数，准确度高且能有效避免重复计数。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dual-Stage Value-Guided Inference with Margin-Based Reward Adjustment for Fast and Faithful VLM Captioning|双阶段价值引导推理与基于边缘的奖励调整方法用于快速准确的大规模语言模型生成描述|Ankan Deria, Adinath Madhavrao Dukre, Feilong Tang, Sara Atito, Sudipta Roy, Muhammad Awais, Muhammad Haris Khan, Imran Razzak|<http://arxiv.org/pdf/2506.15649v1>|提出双阶段价值引导推理方法ViMaR，通过边际奖励调整提升生成效率与准确性。|
|📝 更新|A Curated and Re-annotated Peripheral Blood Cell Dataset Integrating Four Public Resources|一个经过筛选和重新注释的周边血细胞数据集，整合了四个公共资源|Lu Gan, Xi Li, Xichun Wang|<http://arxiv.org/pdf/2407.13214v2>|整合四个公开资源构建了高精度标注的血液细胞数据集，提升了模型训练与评估的准确性和效率。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Pixel-level Certified Explanations via Randomized Smoothing|通过随机平滑进行的像素级可证明解释|Alaa Anani, Tobias Lorenz, Mario Fritz, Bernt Schiele|<http://arxiv.org/pdf/2506.15499v1>|[代码](https://github.com/AlaaAnani/certified-attributions.); 引入首个保证像素级解释稳健性的框架，通过随机平滑增强黑盒归因方法的可信度。|
|📝 更新|A Bird Song Detector for improving bird identification through Deep Learning: a case study from Doñana|基于深度学习的鸟类鸣声检测器以提高鸟类识别准确性：多尼亚自然公园的案例研究|Alba Márquez-Rodríguez, Miguel Ángel Mohedano-Munoz, Manuel J. Marín-Jiménez, Eduardo Santamaría-García, Giulia Bastianelli, Pedro Jordano, Irene Mendoza|<http://arxiv.org/pdf/2503.15576v2>|提出了一种多阶段自动识别鸟类鸣叫的模型，通过先使用Bird Song Detector分离鸟类声音，...|
|📝 更新|SFDLA: Source-Free Document Layout Analysis|无源文档布局分析：SFDLA|Sebastian Tewes, Yufan Chen, Omar Moured, Jiaming Zhang, Rainer Stiefelhagen|<http://arxiv.org/pdf/2503.18742v2>|[代码](https://github.com/s3setewe/sfdla-DLAdapter.); 提出无源数据适配的文档布局分析方法，通过DLAdapter框架提升跨领域性能。|
|📝 更新|Jailbreak Large Vision-Language Models Through Multi-Modal Linkage|通过多模态关联破解大型视觉-语言模型的安全限制|Yu Wang, Xiaofei Zhou, Yichen Wang, Geyuan Zhang, Tianxing He|<http://arxiv.org/pdf/2412.00473v5>|[代码](https://github.com/wangyu-ovo/MML.); 提出了一种加密解密的多模态链接攻击框架，有效破解了大型视觉语言模型的安全限制。|
|📝 更新|PLD: A Choice-Theoretic List-Wise Knowledge Distillation|PLD：一种基于选择理论的列表式知识蒸馏方法|Ejafa Bassam, Dawei Zhu, Kaigui Bian|<http://arxiv.org/pdf/2506.12542v2>|提出了一种基于选择理论的列表知识蒸馏方法PLD，通过优化教师模型的完整排名来提升学生网络的分类准确性...|
|🆕 发布|Enhancing Vector Quantization with Distributional Matching: A Theoretical and Empirical Study|利用分布匹配增强向量量化：理论与实证研究|Xianghong Fang, Litao Guo, Hengchao Chen, Yuxuan Zhang, XiaofanXia, Dingjie Song, Yexin Liu, Hao Wang .etc.|<http://arxiv.org/pdf/2506.15078v1>|提出了一种利用Wasserstein距离匹配特征分布和码向量分布的方法，有效解决了向量量化中的训练不...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Advanced cervical cancer classification: enhancing pap smear images with hybrid PMD Filter-CLAHE|高级宫颈癌分类：使用混合PMD滤波器-CLAHE增强巴氏涂片图像|Ach Khozaimi, Isnani Darti, Syaiful Anam, Wuryansari Muharini Kusumawinahyu|<http://arxiv.org/pdf/2506.15489v1>|提出了一种结合PMD滤波和CLAHE的图像预处理方法，有效提升了宫颈癌筛查中CNN的性能。|
|📝 更新|Click-Calib: A Robust Extrinsic Calibration Method for Surround-View Systems|点击校准：一种用于环视系统的鲁棒外部校准方法|Lihao Wang|<http://arxiv.org/pdf/2501.01557v3>|[代码](https://github.com/lwangvaleo/click_calib.); 提出了一种无需物理图案的Click-Calib方法，实现了 surround-view 系统的精确外...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Unsourced Adversarial CAPTCHA: A Bi-Phase Adversarial CAPTCHA Framework|无源对抗验证码：一种双相对抗验证码框架|Xia Du, Xiaoyuan Liu, Jizhe Zhou, Zheng Lin, Chi-man Pun, Cong Wu, Tao Li, Zhe Chen .etc.|<http://arxiv.org/pdf/2506.10685v2>|提出无源对抗验证码框架，通过文本提示生成高保真度对抗样例，有效抵御深度学习攻击。|
|📝 更新|FLARE: Towards Universal Dataset Purification against Backdoor Attacks|FLARE：面向后门攻击的通用数据集净化方法|Linshan Hou, Wei Luo, Zhongyun Hua, Songhua Chen, Leo Yu Zhang, Yiming Li|<http://arxiv.org/pdf/2411.19479v2>|[代码](https://github.com/THUYimingLi/BackdoorBox); 提出了一种名为FLARE的通用数据清洗方法，有效对抗多种后门攻击，通过聚合不同隐藏层的异常激活来识别...|
|📝 更新|Towards Cross-Subject EMG Pattern Recognition via Dual-Branch Adversarial Feature Disentanglement|面向跨个体肌电信号模式识别的双分支对抗特征解耦方法|Xinyue Niu, Akira Furui|<http://arxiv.org/pdf/2506.08555v2>|提出了一种无需模型校准的跨个体肌电信号识别方法，通过双分支对抗性特征分离实现鲁棒性能。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Incorporating Pre-training Data Matters in Unsupervised Domain Adaptation|无监督领域自适应中预训练数据的融入至关重要|Yinsong Xu, Aidong Men, Yang Liu, Xiahai Zhuang, Qingchao Chen|<http://arxiv.org/pdf/2308.03097v2>|提出三域问题解决框架TriDA，利用预训练数据优化无监督领域自适应性能。|
|📝 更新|SUEDE:Shared Unified Experts for Physical-Digital Face Attack Detection Enhancement|SUEDE：用于物理-数字人脸攻击检测增强的共享统一专家系统|Zuying Xie, Changtao Miao, Ajian Liu, Jiabao Guo, Feng Li, Dan Guo, Yunfeng Diao|<http://arxiv.org/pdf/2504.04818v2>|提出了一种融合共享专家和特定专家的框架，有效提升了物理和数字面部攻击的检测性能。|
|🆕 发布|Enhancing point cloud analysis via neighbor aggregation correction based on cross-stage structure correlation|通过基于跨阶段结构相关性的邻域聚合校正增强点云分析|Jiaqi Shi, Jin Xiao, Xiaoguang Hu, Boyang Song, Hao Jiang, Tianyou Chen, Baochang Zhang|<http://arxiv.org/pdf/2506.15160v1>|[代码](https://github.com/AGENT9717/PointDistribution); 提出了一种利用高维空间相关性修正特征分布的PDSA模块，提高了点云分析的效率和鲁棒性。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Baltimore Atlas: FreqWeaver Adapter for Semi-supervised Ultra-high Spatial Resolution Land Cover Classification|巴尔的摩地图集：FreqWeaver适配器用于半监督超高空分辨率土地覆盖分类|Junhao Wu, Aboagye-Ntow Stephen, Chuyuan Wang, Gang Chen, Xin Huang|<http://arxiv.org/pdf/2506.15565v1>|提出了一种高效的半监督分割框架，通过引入远程感知特定FreqWeaver适配器，实现了高分辨率图像的...|
|📝 更新|Exploring Personalized Federated Learning Architectures for Violence Detection in Surveillance Videos|探索个性化联邦学习架构在监控视频中暴力检测的应用|Mohammad Kassir, Siba Haidar, Antoun Yaacoub|<http://arxiv.org/pdf/2504.00857v2>|提出个性化联邦学习方法，有效提升监控视频暴力事件检测的准确性和效率。|
|📝 更新|Pro-AD: Learning Comprehensive Prototypes with Prototype-based Constraint for Multi-class Unsupervised Anomaly Detection|Pro-AD：基于原型约束学习综合原型进行多类无监督异常检测|Ziqing Zhou, Bin-Bin Gao, Yurui Pan, Lidong Wang, Wenbing Zhu, Yong Liu, Jun Liu, Mingmin Chi .etc.|<http://arxiv.org/pdf/2506.13097v2>|提出Pro-AD方法，通过扩展原型集和动态双向解码器增强异常检测性能，引入原型约束避免异常重构。|
|📝 更新|DRL-Based Resource Allocation for Motion Blur Resistant Federated Self-Supervised Learning in IoV|基于深度强化学习的运动模糊抵抗性车联网联邦自监督学习资源分配|Xueying Gu, Qiong Wu, Pingyi Fan, Qiang Fan, Nan Cheng, Wen Chen, Khaled B. Letaief|<http://arxiv.org/pdf/2408.09194v2>|提出了一种基于SimCo和DRL的资源分配方案，有效抵抗运动模糊并优化车联网中的联邦自监督学习性能。|
|🆕 发布|Classification of Multi-Parametric Body MRI Series Using Deep Learning|深度学习技术在多参数体部磁共振成像序列分类中的应用|Boah Kim, Tejas Sudharshan Mathai, Kimberly Helm, Peter A. Pinto, Ronald M. Summers|<http://arxiv.org/pdf/2506.15182v1>|提出了一种基于深度学习的多参数体部MRI系列分类模型，提高了分类准确性和效率。|
|📝 更新|MOS: Model Surgery for Pre-Trained Model-Based Class-Incremental Learning|模型手术：面向预训练模型的基础上的类别增量学习|Hai-Long Sun, Da-Wei Zhou, Hanbin Zhao, Le Gan, De-Chuan Zhan, Han-Jia Ye|<http://arxiv.org/pdf/2412.09441v2>|[代码](https://github.com/sun-hailong/AAAI25-MOS); 提出模型手术方法MOS，通过特定任务适配器调整预训练模型，有效防止了增量学习中的灾难性遗忘。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence|具身网络代理：桥接物理-数字领域以实现集成代理智能|Yining Hong, Rui Sun, Bingxuan Li, Xingcheng Yao, Maxine Wu, Alexander Chien, Da Yin, Ying Nian Wu .etc.|<http://arxiv.org/pdf/2506.15677v1>|[代码](https://embodied-web-agent.github.io/.); 提出Embodied Web Agents，将实体智能与网络推理结合，实现物理与数字世界的智能融合。|


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FindingDory: A Benchmark to Evaluate Memory in Embodied Agents|《FindingDory：一个用于评估具身智能体记忆的基准测试》|Karmesh Yadav, Yusuf Ali, Gunshi Gupta, Yarin Gal, Zsolt Kira|<http://arxiv.org/pdf/2506.15635v1>|提出了FindingDory基准，用于评估机器人在长期任务中的记忆能力。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EgoBlind: Towards Egocentric Visual Assistance for the Blind|面向盲人的自我中心视觉辅助系统EgoBlind|Junbin Xiao, Nanxin Huang, Hao Qiu, Zhulin Tao, Xun Yang, Richang Hong, Meng Wang, Angela Yao|<http://arxiv.org/pdf/2503.08221v2>|[代码](https://github.com/doc-doc/EgoBlind.); 提出了EgoBlind，首个由盲人收集的 egocentric VideoQA 数据集，用于评估多模...|
|📝 更新|RefChartQA: Grounding Visual Answer on Chart Images through Instruction Tuning|RefChartQA：通过指令微调在图表图像上定位视觉答案|Alexander Vogel, Omar Moured, Yufan Chen, Jiaming Zhang, Rainer Stiefelhagen|<http://arxiv.org/pdf/2503.23131v2>|[代码](https://github.com/moured/RefChartQA.); 提出RefChartQA，结合视觉定位的图表问答方法，提升模型准确性和可靠性。|
|🆕 发布|MEGC2025: Micro-Expression Grand Challenge on Spot Then Recognize and Visual Question Answering|MEGC2025：微表情大挑战——定位后识别与视觉问答|Xinqi Fan, Jingting Li, John See, Moi Hoon Yap, Wen-Huang Cheng, Xiaobai Li, Xiaopeng Hong, Su-Jing Wang .etc.|<http://arxiv.org/pdf/2506.15298v1>|整合微表情检测与识别流程，并利用大型多模态模型提升微表情理解能力。|
|🆕 发布|AI-driven visual monitoring of industrial assembly tasks|基于人工智能的工业装配任务视觉监控|Mattia Nardon, Stefano Messelodi, Antonio Granata, Fabio Poiesi, Alberto Danese, Davide Boscaini|<http://arxiv.org/pdf/2506.15285v1>|[代码](https://tev-fbk.github.io/ViMAT); 提出ViMAT系统，无约束地实时监控工业装配任务，结合多视角视频感知与推理模块提升作业安全与效率。|
|📝 更新|Bi-VLDoc: Bidirectional Vision-Language Modeling for Visually-Rich Document Understanding|双向视觉-语言建模用于视觉丰富文档理解|Chuwei Luo, Guozhi Tang, Qi Zheng, Cong Yao, Lianwen Jin, Chenliang Li, Yang Xue, Luo Si|<http://arxiv.org/pdf/2206.13155v2>|提出双向视觉语言监督策略和混合注意力机制，增强文档理解的跨模态表征，显著提升多个任务性能。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SemVink: Advancing VLMs' Semantic Understanding of Optical Illusions via Visual Global Thinking|SemVink：通过视觉全局思维提升视觉语言模型对光学错觉的语义理解能力|Sifan Li, Yujun Cai, Yiwei Wang|<http://arxiv.org/pdf/2506.02803v2>|提出HC-Bench基准测试，发现VLMs处理视觉错觉能力不足，并提出SemVink方法通过降低图像...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mono-Modalizing Extremely Heterogeneous Multi-Modal Medical Image Registration|单模态化极大异质多模态医学图像配准|Kyobin Choo, Hyunkyung Han, Jinyeong Kim, Chanyong Yoon, Seong Jae Hwang|<http://arxiv.org/pdf/2506.15596v1>|[代码](https://github.com/MICV-yonsei/M2M-Reg.); 提出了一种名为M2M-Reg的新框架，通过仅使用单模态相似性训练多模态图像配准模型，有效解决了高度异...|
|📝 更新|I2I-Mamba: Multi-modal medical image synthesis via selective state space modeling|I2I-Mamba：通过选择性状态空间建模实现多模态医学图像合成|Omer F. Atli, Bilal Kabas, Fuat Arslan, Arda C. Demirtas, Mahmut Yurt, Onat Dalmaz, Tolga Çukur|<http://arxiv.org/pdf/2405.14022v5>|提出了一种基于状态空间模型的多模态医学图像合成方法I2I-Mamba，通过双域Mamba块和螺旋扫描...|
|🆕 发布|CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation|《基于临床指导的LGE增强方法用于真实且多样化的心肌疤痕合成与分割》|Farheen Ramzan, Yusuf Kiberu, Nikesh Jathanna, Shahnaz Jamil-Copley, Richard H. Clayton, Chen, Chen|<http://arxiv.org/pdf/2506.15549v1>|提出了一种临床指导的LGE图像增强框架，实现了真实且多样化的心肌疤痕合成与分割。|
|🆕 发布|Automated MRI Tumor Segmentation using hybrid U-Net with Transformer and Efficient Attention|使用混合U-Net结合Transformer和高效注意力机制的自动MRI肿瘤分割|Syed Haider Ali, Asrar Ahmad, Muhammad Ali, Asifullah Khan, Muhammad Shahban, Nadeem Shaukat|<http://arxiv.org/pdf/2506.15562v1>|提出了一种结合U-Net与Transformer的混合网络，用于本地MRI数据集的肿瘤自动分割，提高...|
|🆕 发布|Multimodal Large Language Models for Medical Report Generation via Customized Prompt Tuning|通过定制化提示调谐的多模态大型语言模型用于医学报告生成|Chunlei Li, Jingyang Hou, Yilei Shi, Jingliang Hu, Xiao Xiang Zhu, Lichao Mou|<http://arxiv.org/pdf/2506.15477v1>|提出MRG-LLM模型，结合视觉编码器和动态提示定制，用于生成医学影像报告，实现最佳性能。|
|🆕 发布|NERO: Explainable Out-of-Distribution Detection with Neuron-level Relevance|NERO：基于神经元级别相关性的可解释性异常分布检测|Anju Chhetri, Jari Korhonen, Prashnna Gyawali, Binod Bhattarai|<http://arxiv.org/pdf/2506.15404v1>|提出了一种基于神经元级别相关性的新型OOD检测方法NERO，通过计算样本与类中心的相关性距离，提高了...|
|🆕 发布|A Real-time Endoscopic Image Denoising System|实时内窥镜图像去噪系统|Yu Xing, Shishi Huang, Meng Lv, Guo Chen, Huailiang Wang, Lingzhi Sui|<http://arxiv.org/pdf/2506.15395v1>|提出了一种针对微型内窥镜图像传感器的噪声模型及混合去噪系统，实现了实时降噪并提升了图像质量。|
|🆕 发布|FedWSIDD: Federated Whole Slide Image Classification via Dataset Distillation|联邦全切片图像分类通过数据集蒸馏：FedWSIDD|Haolong Jin, Shenglin Liu, Cong Cong, Qingmin Feng, Yongzhi Liu, Lina Huang, Yingzi Hu|<http://arxiv.org/pdf/2506.15365v1>|提出FedWSIDD方法，通过数据集蒸馏实现跨机构的全切片图像分类，保护隐私且提升性能。|
|🆕 发布|Privacy-Preserving Chest X-ray Classification in Latent Space with Homomorphically Encrypted Neural Inference|隐私保护的基于同态加密神经网络推理的潜在空间胸部X射线分类|Jonghun Kim, Gyeongdeok Jo, Shinyoung Ra, Hyunjin Park|<http://arxiv.org/pdf/2506.15258v1>|提出了一种利用同态加密和图像压缩技术在保证隐私的同时进行胸部X射线分类的方法。|
|🆕 发布|DM-FNet: Unified multimodal medical image fusion via diffusion process-trained encoder-decoder|DM-FNet：通过扩散过程训练的编码器-解码器实现统一的多模态医学图像融合|Dan He, Weisheng Li, Guofen Wang, Yuping Huang, Shiqiang Liu|<http://arxiv.org/pdf/2506.15218v1>|[代码](https://github.com/HeDan-11/DM-FNet.); 提出了一种基于扩散过程训练的编码器-解码器网络DM-FNet，有效提升了多模态医学图像融合的质量和细...|
|🆕 发布|Echo-DND: A dual noise diffusion model for robust and precise left ventricle segmentation in echocardiography|Echo-DND：一种用于超声心动图中左心室稳健精确分割的双噪声扩散模型|Abdur Rahman, Keerthiveena Balraj, Manojkumar Ramteke, Anurag Singh Rathore|<http://arxiv.org/pdf/2506.15166v1>|[代码](https://abdur75648.github.io/Echo-DND); 提出了一种双噪声扩散模型Echo-DND，通过结合高斯和伯努利噪声以及多尺度融合模块，实现了心超图像...|
|🆕 发布|SynPo: Boosting Training-Free Few-Shot Medical Segmentation via High-Quality Negative Prompts|SynPo：通过高质量负向提示增强无训练少样本医学分割|Yufei Liu, Haoke Xiao, Jiaxing Chai, Yongcun Zhang, Rong Wang, Zijie Meng, Zhiming Luo|<http://arxiv.org/pdf/2506.15153v1>|提出SynPo方法，通过提升负提示质量，无需训练实现医学图像少样本分割性能提升。|
|📝 更新|Multiclass Post-Earthquake Building Assessment Integrating High-Resolution Optical and SAR Satellite Imagery, Ground Motion, and Soil Data with Transformers|多类地震后建筑评估：融合高分辨率光学与合成孔径雷达卫星图像、地面运动与土壤数据使用Transformer模型|Deepank Singh, Vedhus Hoskere, Pietro Milillo|<http://arxiv.org/pdf/2412.04664v3>|提出了一种融合高分辨率光学和SAR卫星影像、地面运动及土壤数据的变压器模型，实现了震后建筑多类别损伤...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Conquering the Retina: Bringing Visual in-Context Learning to OCT|征服视网膜：将视觉上下文学习应用于光学相干断层扫描|Alessio Negrini, Simon Reiß|<http://arxiv.org/pdf/2506.15200v1>|探索利用视觉在位学习训练通用模型，以实现视网膜光学相干断层扫描领域的灵活任务定义。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Translation-Equivariance of Normalization Layers and Aliasing in Convolutional Neural Networks|《归一化层的平移等价性及卷积神经网络中的混叠现象》|Jérémy Scanvic, Quentin Barthélemy, Julián Tachella|<http://arxiv.org/pdf/2505.19805v2>|揭示了标准化层对平移等价性的影响，并提出了判断其等价性的理论框架。|
|📝 更新|Data Augmentation Through Random Style Replacement|通过随机风格替换进行数据增强|Qikai Yang, Cheng Ji, Huaiying Luo, Panfeng Li, Zhicheng Ding|<http://arxiv.org/pdf/2504.10563v2>|提出一种结合风格迁移和随机擦除的数据增强技术，增强了训练过程的鲁棒性并减少了过拟合。|
|🆕 发布|An accurate and revised version of optical character recognition-based speech synthesis using LabVIEW|基于光学字符识别的语音合成精确修订版使用LabVIEW|Prateek Mehta, Anasuya Patil|<http://arxiv.org/pdf/2506.15029v1>|开发了一种基于OCR的语音合成系统，帮助视障人士高效访问书籍。|
|📝 更新|A dataset of high-resolution plantar pressures for gait analysis across varying footwear and walking speeds|高分辨率足底压力数据集：用于不同鞋类和行走速度下的步态分析|Robyn Larracy, Angkoon Phinyomark, Ala Salehi, Eve MacDonald, Saeed Kazemi, Shikder Shafiul Bashar, Aaron Tabor, Erik Scheme|<http://arxiv.org/pdf/2502.17244v4>|介绍了UNB StepUP-P150高分辨率足部压力数据集，为步态分析和识别提供了新基准。|
|🆕 发布|Unsupervised Pelage Pattern Unwrapping for Animal Re-identification|无监督动物皮毛模式展开用于动物重识别|Aleksandr Algasov, Ekaterina Nepovinnykh, Fedor Zolotarev, Tuomas Eerola, Heikki Kälviäinen, Pavel Zemčík, Charles V. Stewart|<http://arxiv.org/pdf/2506.15369v1>|提出了一种无需标注的动物皮毛纹理展开方法，通过几何感知纹理映射提高了动物重识别的准确性。|

