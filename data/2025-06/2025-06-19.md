## [UPDATED!] **2025-06-19** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Overfitting in Histopathology Model Training: The Need for Customized Architectures|病理学模型训练中的过拟合问题：定制化架构的必要性|Saghir Alfasly, Ghazal Alabtah, H. R. Tizhoosh|<http://arxiv.org/pdf/2506.16631v1>|指出标准深度学习模型在病理图像分析中易过拟合，提出需定制化架构以提升性能并减少过拟合。|
|🆕 发布|Exoplanet Classification through Vision Transformers with Temporal Image Analysis|通过视觉变换器与时间图像分析进行系外行星分类|Anupma Choudhary, Sohith Bandari, B. S. Kushvah, C. Swastik|<http://arxiv.org/pdf/2506.16597v1>|利用视觉变换器模型分析时间序列图像，有效提升了系外行星分类的准确性和效率。|
|📝 更新|Demystify Transformers & Convolutions in Modern Image Deep Networks|揭秘现代图像深度网络中的Transformer与卷积|Xiaowei Hu, Min Shi, Weiyun Wang, Sitong Wu, Linjie Xing, Wenhai Wang, Xizhou Zhu, Lewei Lu .etc.|<http://arxiv.org/pdf/2211.05781v4>|揭示了现代图像深度网络中不同特征变换模块的性能差异，提出统一架构进行公平比较。|
|🆕 发布|Polyline Path Masked Attention for Vision Transformer|折线路径掩码注意力机制在视觉变换器中的应用|Zhongchen Zhao, Chaodong Xiao, Hui Lin, Qi Xie, Lei Zhang, Deyu Meng|<http://arxiv.org/pdf/2506.15940v1>|[代码](https://github.com/zhongchenzhao/PPMA.); 提出了一种结合 Vision Transformer 和 Mamba2 优势的 Polyline P...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Surg-3M: A Dataset and Foundation Model for Perception in Surgical Settings|手术环境中感知的Surg-3M数据集与基础模型|Chengan Che, Chao Wang, Tom Vercauteren, Sophia Tsoka, Luis C. Garcia-Peraza-Herrera|<http://arxiv.org/pdf/2503.19740v2>|提出了大规模手术视频数据集Surg-3M和预训练模型SurgFM，显著提升手术视觉任务性能。|
|🆕 发布|SafeTriage: Facial Video De-identification for Privacy-Preserving Stroke Triage|《SafeTriage：面向隐私保护的脑卒中分诊面部视频去识别》|Tongan Cai, Haomiao Ni, Wenchao Ma, Yuan Xue, Qian Ma, Rachel Leicht, Kelvin Wong, John Volpi .etc.|<http://arxiv.org/pdf/2506.16578v1>|提出了一种面部视频去识别方法SafeTriage，保护患者隐私同时保留诊断关键的运动特征。|
|🆕 发布|Subspace-Boosted Model Merging|子空间增强的模型融合|Ronald Skorobogat, Karsten Roth, Mariana-Iuliana Georgescu, Zeynep Akata|<http://arxiv.org/pdf/2506.16506v1>|提出方法解决模型融合中任务空间秩塌陷问题，显著提升多任务模型性能超过10%。|
|🆕 发布|DT-UFC: Universal Large Model Feature Coding via Peaky-to-Balanced Distribution Transformation|DT-UFC：通过峰值到平衡分布转换实现通用大模型特征编码|Changsheng Gao, Zijie Liu, Li Li, Dong Liu, Xiaoyan Sun, Weisi Lin|<http://arxiv.org/pdf/2506.16495v1>|提出通用特征编码方法DT-UFC，通过学习分布转换提升大型模型特征压缩效率和跨模型泛化能力。|
|🆕 发布|Hunyuan3D 2.5: Towards High-Fidelity 3D Assets Generation with Ultimate Details|面向超高保真3D资源生成的极限细节 Hunyuan3D 2.5|Zeqiang Lai, Yunfei Zhao, Haolin Liu, Zibo Zhao, Qingxiang Lin, Huiwen Shi, Xianghui Yang, Mingxin Yang .etc.|<http://arxiv.org/pdf/2506.16504v1>|提出了一种高效的两阶段3D扩散模型Hunyuan3D 2.5，实现了高保真、细节丰富的3D资产生成。|
|📝 更新|xGen-MM (BLIP-3): A Family of Open Large Multimodal Models|xGen-MM（BLIP-3）：一套开放的大型多模态模型系列|Le Xue, Manli Shu, Anas Awadalla, Jun Wang, An Yan, Senthil Purushwalkam, Honglu Zhou, Viraj Prabhu .etc.|<http://arxiv.org/pdf/2408.08872v3>|介绍了BLIP-3，一个开放的大型多模态模型开发框架，实现了具有竞争力的性能和图像文本理解能力。|
|🆕 发布|MambaHash: Visual State Space Deep Hashing Model for Large-Scale Image Retrieval|MambaHash：面向大规模图像检索的视觉状态空间深度哈希模型|Chao He, Hongxi Wei|<http://arxiv.org/pdf/2506.16353v1>|[代码](https://github.com/shuaichaochao/MambaHash.git); 提出MambaHash模型，通过结合Mamba操作和注意力机制增强图像特征，有效提升大规模图像检索性...|
|📝 更新|On Domain-Adaptive Post-Training for Multimodal Large Language Models|面向多模态大型语言模型的域自适应后训练研究|Daixuan Cheng, Shaohan Huang, Ziyu Zhu, Xintong Zhang, Wayne Xin Zhao, Zhongzhi Luan, Bo Dai, Zhenliang Zhang|<http://arxiv.org/pdf/2411.19930v3>|提出了一种针对多模态大语言模型进行领域自适应的后期训练方法，通过数据合成、单阶段训练和任务评估提高了...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HyperPath: Knowledge-Guided Hyperbolic Semantic Hierarchy Modeling for WSI Analysis|超路径：基于知识引导的双曲语义层次建模用于全切片图像分析|Peixiang Huang, Yanyan Huang, Weiqin Zhao, Junjun He, Lequan Yu|<http://arxiv.org/pdf/2506.16398v1>|提出了一种利用文本知识引导在双曲空间建模WSI语义层次的方法，提升了WSI分类性能。|
|📝 更新|A multimodal dataset for understanding the impact of mobile phones on remote online virtual education|多模态数据集：用于理解手机对远程在线虚拟教育影响的研究|Roberto Daza, Alvaro Becerra, Ruth Cobos, Julian Fierrez, Aythami Morales|<http://arxiv.org/pdf/2412.14195v2>|构建多模态IMPROVE数据集，分析手机使用对在线教育学习者影响。|
|📝 更新|Chest X-ray Foundation Model with Global and Local Representations Integration|胸部X射线基础模型与全局和局部表征集成|Zefan Yang, Xuanang Xu, Jiajin Zhang, Ge Wang, Mannudeep K. Kalra, Pingkun Yan|<http://arxiv.org/pdf/2502.05142v2>|[代码](https://github.com/RPIDIAL/CheXFound.); 提出CheXFound模型，通过整合全局与局部特征提升胸部X光图像多任务泛化性能。|
|🆕 发布|MBA: Multimodal Bidirectional Attack for Referring Expression Segmentation Models|MBA：用于指代表达式分割模型的多模态双向攻击|Xingbai Chen, Tingchao Fu, Renyang Liu, Wei Zhou, Chao Yi|<http://arxiv.org/pdf/2506.16157v1>|提出了一种针对指代表达式分割模型的多模态双向攻击方法，增强了对抗样本在不同文本输入间的泛化能力。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MonoSOWA: Scalable monocular 3D Object detector Without human Annotations|单目3D物体检测器MonoSOWA：无需人工标注的可扩展方法|Jan Skvrna, Lukas Neumann|<http://arxiv.org/pdf/2501.09481v3>|[代码](https://github.com/jskvrna/MonoSOWA.); 提出了一种无需人工标注的单目3D物体检测方法，大幅提高了训练数据利用率和检测性能。|
|📝 更新|Efficient Event-Based Object Detection: A Hybrid Neural Network with Spatial and Temporal Attention|基于事件的高效目标检测：一种融合空间与时间注意力的混合神经网络|Soikat Hasan Ahmed, Jan Finkbeiner, Emre Neftci|<http://arxiv.org/pdf/2403.10173v4>|提出了一种结合时空注意力的混合SNN-ANN网络，实现了高效的事件驱动的目标检测。|
|🆕 发布|How Hard Is Snow? A Paired Domain Adaptation Dataset for Clear and Snowy Weather: CADC+|雪有多硬？一个用于晴朗和雪天天气的配对域自适应数据集：CADC+|Mei Qi Tang, Sean Sedwards, Chengjie Huang, Krzysztof Czarnecki|<http://arxiv.org/pdf/2506.16531v1>|提出首个针对冬季自动驾驶的配对天气域自适应数据集CADC+，减少雪天对3D物体检测性能的影响。|
|📝 更新|UDA4Inst: Unsupervised Domain Adaptation for Instance Segmentation|UDA4Inst：无监督领域自适应实例分割|Yachan Guo, Yi Xiao, Danna Xue, Jose L. Gomez, Antonio M. Lopez|<http://arxiv.org/pdf/2405.09682v7>|[代码](https://github.com/gyc-code/UDA4Inst.); 提出UDA4Inst框架，通过语义类别训练和双向混合训练，实现了无监督领域自适应在实例分割上的应用与...|
|🆕 发布|LBMamba: Locally Bi-directional Mamba|局部双向Mamba：LBMamba|Jingwei Zhang, Xi Han, Hong Qin, Mahdi S. Hosseini, Dimitris Samaras|<http://arxiv.org/pdf/2506.15976v1>|提出了一种局部双向的SSM结构LBMamba，通过在单个扫描中嵌入轻量级局部反向扫描，提升了计算机视...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Semantic To Instance: A Semi-Self-Supervised Learning Approach|从语义到实例：一种半自监督学习方法|Keyhan Najafian, Farhad Maleki, Lingling Jin, Ian Stavness|<http://arxiv.org/pdf/2506.16563v1>|提出了一种半自监督学习法，用少量标注实现高效实例分割，达到农业及通用数据集的性能领先。|
|🆕 发布|Stepping Out of Similar Semantic Space for Open-Vocabulary Segmentation|走出相似语义空间以实现开放词汇分割|Yong Liu, SongLi Wu, Sule Bai, Jiahao Wang, Yitong Wang, Yansong Tang|<http://arxiv.org/pdf/2506.16058v1>|提出OpenBench基准和OVSNet方法，提升开放词汇分割模型对现实世界概念的理解和分割性能。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CLIP-MG: Guiding Semantic Attention with Skeletal Pose Features and RGB Data for Micro-Gesture Recognition on the iMiGUE Dataset|CLIP-MG：利用骨骼姿态特征与RGB数据引导语义注意力进行微手势识别在iMiGUE数据集上的应用|Santosh Patapati, Trisanth Srinivasan, Amith Adiraju|<http://arxiv.org/pdf/2506.16385v1>|引入了CLIP-MG模型，通过融合人体姿态信息提升微手势识别准确度至61.82%。|
|📝 更新|OpenPath: Open-Set Active Learning for Pathology Image Classification via Pre-trained Vision-Language Models|开放路径：通过预训练视觉语言模型的病理图像分类开放集主动学习方法|Lanfeng Zhong, Xin Liao, Shichuan Zhang, Shaoting Zhang, Guotai Wang|<http://arxiv.org/pdf/2506.15318v2>|[代码](https://github.com/HiLab-git/OpenPath); 提出了一种针对病理图像分类的开集主动学习方法OpenPath，利用预训练的视觉语言模型有效选择样本，...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dense 3D Displacement Estimation for Landslide Monitoring via Fusion of TLS Point Clouds and Embedded RGB Images|基于TLS点云与嵌入式RGB图像融合的滑坡监测稠密三维位移估计|Zhaoyi Wang, Jemil Avers Butt, Shengyu Huang, Tomislav Medic, Andreas Wieser|<http://arxiv.org/pdf/2506.16265v1>|[代码](https://github.com/zhaoyiww/fusion4landslide.); 提出了一种融合TLS点云和RGB图像的 hierarchical partition-based 方...|
|🆕 发布|Enhanced Dermatology Image Quality Assessment via Cross-Domain Training|通过跨域训练增强皮肤病学图像质量评估|Ignacio Hernández Montilla, Alfonso Medela, Paola Pasquali, Andy Aguilar, Taig Mac Carthy, Gerardo Fernández, Antonio Martorell, Enrique Onieva|<http://arxiv.org/pdf/2506.16116v1>|提出跨域训练的图像质量评估模型，结合皮肤科和非皮肤科数据，有效解决远程皮肤科咨询中的图像质量问题。|
|🆕 发布|STAR-Pose: Efficient Low-Resolution Video Human Pose Estimation via Spatial-Temporal Adaptive Super-Resolution|STAR-Pose：基于时空自适应超分辨率的低分辨率视频人体姿态估计|Yucheng Jin, Jinyan Chen, Ziyue He, Baojun Han, Furan An|<http://arxiv.org/pdf/2506.16061v1>|提出了一种针对低分辨率视频的人体姿态估计方法STAR-Pose，通过时空自适应超分辨率框架显著提升估...|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CodeDiffuser: Attention-Enhanced Diffusion Policy via VLM-Generated Code for Instruction Ambiguity|代码扩散器：通过VLM生成代码增强注意力扩散策略以解决指令歧义|Guang Yin, Yitong Li, Yixuan Wang, Dale McConachie, Paarth Shah, Kunimatsu Hashimoto, Huan Zhang, Katherine Liu .etc.|<http://arxiv.org/pdf/2506.16652v1>|提出了一种通过视觉语言模型生成代码以解析自然语言指令中的歧义，并利用注意力图解决操作任务中不确定性的...|
|🆕 发布|Watermarking Autoregressive Image Generation|"水印嵌入自回归图像生成"|Nikola Jovanović, Ismail Labiad, Tomáš Souček, Martin Vechev, Pierre Fernandez|<http://arxiv.org/pdf/2506.16349v1>|提出了一种在自动回归图像生成模型中嵌入水印的新方法，通过改进标记一致性和同步层增强了水印的鲁棒性。|
|🆕 发布|SycnMapV2: Robust and Adaptive Unsupervised Segmentation|同步映射V2：稳健且自适应的无监督分割|Heng Zhang, Zikang Wan, Danilo Vasconcellos Vargas|<http://arxiv.org/pdf/2506.16297v1>|提出SyncMapV2算法，实现无监督分割的高鲁棒性及在线自适应能力。|
|🆕 发布|R3eVision: A Survey on Robust Rendering, Restoration, and Enhancement for 3D Low-Level Vision|R3eVision：三维低层次视觉的鲁棒渲染、恢复与增强综述|Weeyoung Kwon, Jeahun Sung, Minkyu Jeon, Chanho Eom, Jihyong Oh|<http://arxiv.org/pdf/2506.16262v1>|概述了3D低级视觉任务在神经渲染中的应用，提升了模型在真实世界退化条件下的三维重建鲁棒性。|
|🆕 发布|Co-Speech Gesture and Facial Expression Generation for Non-Photorealistic 3D Characters|非真实感三维角色的协同语音手势与面部表情生成|Taisei Omine, Naoyuki Kawabata, Fuminori Homma|<http://arxiv.org/pdf/2506.16159v1>|提出方法生成非真实感3D角色的情感表达，利用漫画表情和对话特定语义手势。|
|🆕 发布|FastInit: Fast Noise Initialization for Temporally Consistent Video Generation|快速初始化：用于时间一致视频生成的快速噪声初始化|Chengyu Bai, Yuming Li, Zhongyu Zhao, Jintao Chen, Peidong Jia, Qi She, Ming Lu, Shanghang Zhang|<http://arxiv.org/pdf/2506.16119v1>|提出了一种快速噪声初始化方法FastInit，通过单次前向传播提高视频生成效率并保持帧间一致性。|
|🆕 发布|PAROAttention: Pattern-Aware ReOrdering for Efficient Sparse and Quantized Attention in Visual Generation Models|PAROAttention：模式感知重排以实现视觉生成模型中高效稀疏和量化注意力|Tianchen Zhao, Ke Hong, Xinhao Yang, Xuefeng Xiao, Huixia Li, Feng Ling, Ruiqi Xie, Siqi Chen .etc.|<http://arxiv.org/pdf/2506.16054v1>|提出Pattern-Aware ReOrdering方法，通过优化注意力模式，提升稀疏和量化注意力机...|
|🆕 发布|Noise Fusion-based Distillation Learning for Anomaly Detection in Complex Industrial Environments|基于噪声融合的蒸馏学习在复杂工业环境中的异常检测|Jiawen Yu, Jieji Ren, Yang Chang, Qiaojun Yu, Xuan Tong, Boyang Wang, Yan Song, You Li .etc.|<http://arxiv.org/pdf/2506.16050v1>|[代码](https://zihuatanejoyu.github.io/HetNet); 提出了一种针对复杂工业环境缺陷检测的噪声融合蒸馏学习方法，提升了系统的鲁棒性和实时检测能力。|
|📝 更新|Efficient Retail Video Annotation: A Robust Key Frame Generation Approach for Product and Customer Interaction Analysis|高效零售视频标注：一种用于产品和客户交互分析的抗干扰关键帧生成方法|Varun Mannam, Zhenyu Shi|<http://arxiv.org/pdf/2506.14854v2>|提出了一种基于深度学习的自动关键帧识别方法，大幅降低了零售视频标注的时间和成本。|
|🆕 发布|Advanced Sign Language Video Generation with Compressed and Quantized Multi-Condition Tokenization|先进的压缩量化多条件符号化手势语视频生成方法|Cong Wang, Zexuan Deng, Zhiwei Jiang, Fei Shen, Yafeng Yin, Shiwei Gan, Zifeng Cheng, Shiping Ge .etc.|<http://arxiv.org/pdf/2506.15980v1>|[代码](https://github.com/umnooob/signvip); 提出多条件细粒度表征的生成框架SignViP，通过离散化编码提升手语视频的自然度和表现力。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Layer-wise Alignment: Examining Safety Alignment Across Image Encoder Layers in Vision Language Models|逐层对齐：在视觉语言模型中检查图像编码器层之间的安全对齐|Saketh Bachu, Erfan Shayegani, Rohit Lal, Trishna Chakraborty, Arindam Dutta, Chengyu Song, Yue Dong, Nael Abu-Ghazaleh .etc.|<http://arxiv.org/pdf/2411.04291v2>|揭示了视觉语言模型中间层有害信息分布不均的问题，并提出了一种层wise多模态强化学习算法减少有害输出...|
|🆕 发布|MetaQAP -- A Meta-Learning Approach for Quality-Aware Pretraining in Image Quality Assessment|元学习驱动的图像质量评估质量感知预训练方法MetaQAP|Muhammad Azeem Aslam, Muhammad Hamza, Nisar Ahmed, Gulshan Saleem, Zhu Shuangtong, Hu Hongfei, Xu Wei, Saba Aslam .etc.|<http://arxiv.org/pdf/2506.16601v1>|提出MetaQAP模型，通过质量感知预训练和元学习提升图像质量评估性能。|
|🆕 发布|Reimagination with Test-time Observation Interventions: Distractor-Robust World Model Predictions for Visual Model Predictive Control|测试时观测干预下的再想象：用于视觉模型预测控制中的干扰稳健世界模型预测|Yuxin Chen, Jianglan Wei, Chenfeng Xu, Boyi Li, Masayoshi Tomizuka, Andrea Bajcsy, Ran Tian|<http://arxiv.org/pdf/2506.16565v1>|提出了一种Reimagination with Observation Intervention策略...|
|🆕 发布|DiffO: Single-step Diffusion for Image Compression at Ultra-Low Bitrates|DiffO：超低比特率下图像压缩的单步扩散方法|Chanung Park, Joo Chan Lee, Jong Hwan Ko|<http://arxiv.org/pdf/2506.16572v1>|[代码](https://github.com/Freemasti/DiffO.); 提出了一种单步扩散模型DiffO，实现了在极低比特率下的高感知质量和快速解码。|
|📝 更新|TARDIS STRIDE: A Spatio-Temporal Road Image Dataset and World Model for Autonomy|时空道路图像数据集与世界模型：TARDIS STRIDE 用于自主性研究|Héctor Carrión, Yutong Bai, Víctor A. Hernández Castro, Kishan Panaganti, Ayush Zenith, Matthew Trang, Tony Zhang, Pietro Perona .etc.|<http://arxiv.org/pdf/2506.11302v3>|提出了一种结合空间和时间动态的统一框架，通过STRIDE数据集训练了能理解环境变化的自主代理模型。|
|🆕 发布|Fine-grained Image Retrieval via Dual-Vision Adaptation|通过双视觉适配的细粒度图像检索|Xin Jiang, Meiqi Cao, Hao Tang, Fei Shen, Zechao Li|<http://arxiv.org/pdf/2506.16273v1>|提出了一种双视觉适应方法，通过样本和特征适应提升细粒度图像检索的泛化能力。|
|🆕 发布|VideoGAN-based Trajectory Proposal for Automated Vehicles|基于VideoGAN的自动车辆轨迹提议方法|Annajoyce Mariani, Kira Maag, Hanno Gottschalk|<http://arxiv.org/pdf/2506.16209v1>|提出了一种基于VideoGAN的轨迹生成方法，用于自动车辆准确捕捉未来轨迹的空间关系。|
|🆕 发布|FlowRAM: Grounding Flow Matching Policy with Region-Aware Mamba Framework for Robotic Manipulation|流RAM：基于区域感知Mamba框架的机器人操作流匹配策略定位|Sen Wang, Le Wang, Sanping Zhou, Jingyi Tian, Jiayi Li, Haowen Sun, Wei Tang|<http://arxiv.org/pdf/2506.16201v1>|FlowRAM通过结合生成模型和动态感知策略，提高了机器人操作的高精度任务效率和成功率。|
|🆕 发布|Fast Training-free Perceptual Image Compression|快速无训练感知图像压缩|Ziran Zhu, Tongda Xu, Minye Huang, Dailan He, Xingtong Ge, Xinjie Zhang, Ling Li, Yan Wang|<http://arxiv.org/pdf/2506.16102v1>|提出了一种无需训练的图像解码算法，大幅缩短解码时间同时保证感知质量。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|On Learning Multi-Modal Forgery Representation for Diffusion Generated Video Detection|学习多模态伪造表征用于扩散生成视频检测|Xiufeng Song, Xiao Guo, Jiache Zhang, Qirui Li, Lei Bai, Xiaoming Liu, Guangtao Zhai, Xiaohong Liu|<http://arxiv.org/pdf/2410.23623v3>|[代码](https://github.com/SparkleXFantasy/MM-Det.); 提出了一种多模态检测算法MM-Det，利用大型多模态模型生成多模态伪造表示，有效检测扩散生成的视频。|
|📝 更新|A Comprehensive Survey on Continual Learning in Generative Models|生成模型中持续学习的全面调查|Haiyang Guo, Fanhu Zeng, Fei Zhu, Jiayi Wang, Xukai Wang, Jingang Zhou, Hongbo Zhao, Wenzhuo Liu .etc.|<http://arxiv.org/pdf/2506.13045v3>|[代码](https://github.com/Ghy0501/Awesome-Continual-Learning-in-Generative-Models.); 系统梳理了生成模型中持续学习的方法，分为架构、正则化和重放三大类，以克服灾难性遗忘问题。|
|📝 更新|A Survey on Future Frame Synthesis: Bridging Deterministic and Generative Approaches|未来帧合成综述：桥接确定性方法与生成性方法|Ruibo Ming, Zhewei Huang, Jingwei Wu, Zhuoxuan Ju, Daxin Jiang, Jianming Hu, Lihui Peng, Shuchang Zhou|<http://arxiv.org/pdf/2401.14718v7>|概述了未来帧合成技术的发展，强调了从确定性到生成模型的转变，为未来研究提供了方向。|
|🆕 发布|Beyond Audio and Pose: A General-Purpose Framework for Video Synchronization|超越音频与姿态：一种通用视频同步框架|Yosub Shin, Igor Molybog|<http://arxiv.org/pdf/2506.15937v1>|提出通用视频同步框架VideoSync，不依赖特定特征提取，提升多场景下的同步准确性和鲁棒性。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Align the GAP: Prior-based Unified Multi-Task Remote Physiological Measurement Framework For Domain Generalization and Personalization|对齐GAP：基于先验的统一多任务远程生理测量框架，用于域泛化和个性化|Jiyao Wang, Xiao Yang, Hao Lu, Dengbo He, Kaishun Wu|<http://arxiv.org/pdf/2506.16160v1>|提出了一种基于先验信息的统一多任务远程生理测量框架，实现了领域泛化与个性化适应的融合。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TrajSceneLLM: A Multimodal Perspective on Semantic GPS Trajectory Analysis|轨迹场景语言模型：一种多模态视角下的语义GPS轨迹分析|Chunhou Ji, Qiumeng Li|<http://arxiv.org/pdf/2506.16401v1>|[代码](https://github.com/februarysea/TrajSceneLLM.); 提出了一种融合地图图像和文本描述的多模态方法，显著提升了GPS轨迹数据的语义理解能力。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RDD: Robust Feature Detector and Descriptor using Deformable Transformer|RDD：基于可变形变换器的鲁棒特征检测与描述符|Gonglin Chen, Tianwen Fu, Haiwei Chen, Wenbin Teng, Hanyuan Xiao, Yajie Zhao|<http://arxiv.org/pdf/2505.08013v3>|提出RDD方法，利用可变形变压器捕获全局上下文和几何不变性，提升极端条件下的特征检测与描述性能。|
|📝 更新|Representation Learning of Point Cloud Upsampling in Global and Local Inputs|点云上采样在全局和局部输入下的表征学习|Tongxu Zhang, Bei Wang|<http://arxiv.org/pdf/2501.07076v3>|提出ReLPU框架，通过学习点云的全局和局部特征显著提升上采样性能。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Wavelet-based Global Orientation and Surface Reconstruction for Point Clouds|基于小波的全局方向和表面重建算法在点云中的应用|Yueji Ma, Yanzun Meng, Dong Xiao, Zuoqiang Shi, Bin Wang|<http://arxiv.org/pdf/2506.16299v1>|提出了一种基于小波变换的点云全局定向和表面重建方法，有效处理稀疏点云并提升重建效果。|
|🆕 发布|From Coarse to Continuous: Progressive Refinement Implicit Neural Representation for Motion-Robust Anisotropic MRI Reconstruction|从粗到细：用于运动稳健各向异性MRI重建的渐进细化隐式神经表示|Zhenxuan Zhang, Lipei Zhang, Yanqi Cheng, Zi Wang, Fanwen Wang, Haosen Zhang, Yue Yang, Yinzhe Wu .etc.|<http://arxiv.org/pdf/2506.16210v1>|提出了一种逐步细化的隐式神经表示框架，用于运动稳健的各向异性MRI重建，有效抑制运动伪影并恢复局部结...|
|🆕 发布|TD3Net: A Temporal Densely Connected Multi-Dilated Convolutional Network for Lipreading|TD3Net：一种基于时间密集连接的多扩张卷积网络用于唇读|Byung Hoon Lee, Wooseok Shin, Sung Won Han|<http://arxiv.org/pdf/2506.16073v1>|[代码](https://github.com/Leebh-kor/TD3Net-A-Temporal-Densely-Connected-Multi-dilated-Convolutional-Network-for-Lipreading); 提出了一种结合密集跳跃连接和多尺度扩张卷积的网络结构TD3Net，有效提升了唇读任务的准确性和效率。|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Low-Resource Video Super-Resolution using Memory, Wavelets, and Deformable Convolutions|使用内存、小波和可变形卷积的低资源视频超分辨率|Kavitha Viswanathan, Shashwat Pathak, Piyush Bharambe, Harsh Choudhary, Amit Sethi|<http://arxiv.org/pdf/2502.01816v3>|提出了一种高效的轻量级视频超分辨率架构，通过结合波let分解、单一内存张量和可变形卷积，实现了低计算...|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PR-DETR: Injecting Position and Relation Prior for Dense Video Captioning|PR-DETR：为密集视频标注注入位置与关系先验|Yizhe Li, Sanping Zhou, Zheng Qin, Le Wang|<http://arxiv.org/pdf/2506.16082v1>|提出了一种注入位置和关系先验的密集视频标注框架PR-DETR，提高了事件定位准确性和字幕质量。|
|📝 更新|Action Spotting and Precise Event Detection in Sports: Datasets, Methods, and Challenges|体育中的动作定位和精确事件检测：数据集、方法与挑战|Hao Xu, Arbind Agrahari Baniya, Sam Well, Mohamed Reda Bouadjenek, Richard Dazeley, Sunil Aryal|<http://arxiv.org/pdf/2505.03991v2>|明确了体育视频事件检测的类别差异，并提出了针对动作定位和精确事件检测的深度学习方法与挑战。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 跨模态一致性学习 (Cross-modal Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GRPO-CARE: Consistency-Aware Reinforcement Learning for Multimodal Reasoning|GRPO-CARE: 用于多模态推理的一致性感知强化学习|Yi Chen, Yuying Ge, Rui Wang, Yixiao Ge, Junhao Cheng, Ying Shan, Xihui Liu|<http://arxiv.org/pdf/2506.16141v1>|提出SEED-Bench-R1基准和GRPO-CARE框架，提升多模态模型推理一致性和准确性。|


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Heterogeneous-Modal Unsupervised Domain Adaptation via Latent Space Bridging|异构模态无监督领域自适应通过潜在空间桥接|Jiawen Yang, Shuhao Chen, Yucong Duan, Ke Tang, Yu Zhang|<http://arxiv.org/pdf/2506.15971v1>|提出异模态无监督域自适应新设置，通过潜在空间桥接实现不同模态间的知识迁移。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Leveraging CNN and IoT for Effective E-Waste Management|利用卷积神经网络和物联网进行有效的电子废物管理|Ajesh Thangaraj Nadar, Gabriel Nixon Raj, Soham Chandane, Sushant Bhat|<http://arxiv.org/pdf/2506.16647v1>|提出了一种结合物联网和轻量级卷积神经网络的方法，自动化识别和分类电子废弃物，提升回收效率。|
|🆕 发布|AGC-Drive: A Large-Scale Dataset for Real-World Aerial-Ground Collaboration in Driving Scenarios|AGC-Drive：面向驾驶场景的大规模天地协同数据集|Yunhao Hou, Bochao Zou, Min Zhang, Ran Chen, Shangdong Yang, Yanmei Zhang, Junbao Zhuo, Siheng Chen .etc.|<http://arxiv.org/pdf/2506.16371v1>|[代码](https://github.com/PercepX/AGC-Drive.); 提出了AGC-Drive，首个大规模真实世界数据集，用于车辆与无人机协同的3D感知。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FlatCAD: Fast Curvature Regularization of Neural SDFs for CAD Models|快速曲率正则化神经SDF用于CAD模型的FlatCAD|Haotian Yin, Aleksander Plocharski, Michal Jan Wlodarczyk, Mikolaj Kida, Przemyslaw Musialski|<http://arxiv.org/pdf/2506.16627v1>|提出了一种高效的曲率正则化方法，通过仅调节混合二阶导数，实现了CAD模型神经SDFs的快速学习与优化...|
|🆕 发布|Hybrid Attention Network for Accurate Breast Tumor Segmentation in Ultrasound Images|混合注意力网络在超声图像中精确分割乳腺肿瘤的研究|Muhammad Azeem Aslam, Asim Naveed, Nisar Ahmed|<http://arxiv.org/pdf/2506.16592v1>|提出了一种结合全局和局部特征的混合注意力网络，用于准确分割超声图像中的乳腺肿瘤区域。|
|🆕 发布|Efficient Transformations in Deep Learning Convolutional Neural Networks|深度学习卷积神经网络中的高效转换|Berk Yilmaz, Daniel Fidel Harvey, Prajit Dhuri|<http://arxiv.org/pdf/2506.16418v1>|探究了在ResNet50中加入信号处理变换以提升图像分类效率，发现 Walsh-Hadamard 变...|
|🆕 发布|AGE-US: automated gestational age estimation based on fetal ultrasound images|AGE-US：基于胎儿超声图像的自动化孕周估计|César Díaz-Parga, Marta Nuñez-Garcia, Maria J. Carreira, Gabriel Bernardino, Nicolás Vila-Blanco|<http://arxiv.org/pdf/2506.16256v1>|提出了一种基于深度学习的自动化估算孕周方法，通过创新分割架构和距离图提高准确性，适用于资源有限环境。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Breaking the Compression Ceiling: Data-Free Pipeline for Ultra-Efficient Delta Compression|突破压缩上限：无需数据的高效差值压缩管道|Xiaohui Wang, Peng Ye, Chenyu Huang, Shenghe Zheng, Bo Zhang, Lei Bai, Wanli Ouyang, Tao Chen|<http://arxiv.org/pdf/2505.13563v2>|提出了一种无数据驱动的UltraDelta压缩方法，实现了高压缩率和强性能的平衡。|
|🆕 发布|Structured Semantic 3D Reconstruction (S23DR) Challenge 2025 -- Winning solution|结构化语义三维重建（S23DR）挑战赛2025 -- 获胜解决方案|Jan Skvrna, Lukas Neumann|<http://arxiv.org/pdf/2506.16421v1>|提出了一种直接在3D空间操作的方法，通过识别顶点候选和预测边来从稀疏点云重建房屋3D屋顶线框。|
|📝 更新|SP-VLA: A Joint Model Scheduling and Token Pruning Approach for VLA Model Acceleration|SP-VLA：一种联合模型调度与令牌剪枝的VLA模型加速方法|Ye Li, Yuan Meng, Zewen Sun, Kangye Ji, Chen Tang, Jiajun Fan, Xinzhu Ma, Shutao Xia .etc.|<http://arxiv.org/pdf/2506.12723v2>|提出了一种联合模型调度和令牌剪枝的框架SP-VLA，有效降低视觉语言动作模型的计算成本，实现实时任务...|
|📝 更新|CIVET: Systematic Evaluation of Understanding in VLMs|CIVET：大规模语言模型理解能力的系统评估|Massimo Rizzoli, Simone Alghisi, Olha Khomyn, Gabriel Roccabruna, Seyed Mahed Mousavi, Giuseppe Riccardi|<http://arxiv.org/pdf/2506.05146v2>|提出CIVET框架，系统评估了视觉语言模型对场景结构和语义的理解能力。|
|📝 更新|Core Knowledge Deficits in Multi-Modal Language Models|多模态语言模型中的核心知识缺陷|Yijiang Li, Qingying Gao, Tianwei Zhao, Bingyang Wang, Haoran Sun, Haiyun Lyu, Robert D. Hawkins, Nuno Vasconcelos .etc.|<http://arxiv.org/pdf/2410.10855v4>|揭示了多模态大语言模型在核心知识方面的缺陷，并提出了Concept Hacking评估方法。|
|📝 更新|ShapeLib: Designing a library of programmatic 3D shape abstractions with Large Language Models|《ShapeLib：利用大型语言模型设计程序化三维形状抽象库》|R. Kenny Jones, Paul Guerrero, Niloy J. Mitra, Daniel Ritchie|<http://arxiv.org/pdf/2502.08884v2>|提出ShapeLib方法，利用大型语言模型设计3D形状抽象库，实现功能描述和形状抽象的自动匹配。|
|📝 更新|Towards AI-Driven Policing: Interdisciplinary Knowledge Discovery from Police Body-Worn Camera Footage|迈向AI驱动的警务：从警察随身摄像头视频中跨学科知识发现|Anita Srbinovska, Angela Srbinovska, Vivek Senthil, Adrian Martin, John McCluskey, Jonathan Bateman, Ernest Fokoué|<http://arxiv.org/pdf/2504.20007v3>|提出了一种跨学科框架，利用人工智能和机器学习技术分析警察随身摄像头视频，以识别和分析警民互动中的关键...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FOCoOp: Enhancing Out-of-Distribution Robustness in Federated Prompt Learning for Vision-Language Models|FOCoOp：增强视觉语言模型联邦提示学习中分布外鲁棒性|Xinting Liao, Weiming Liu, Jiaming Qian, Pengyang Zhou, Jiahe Xu, Wenjie Wang, Chaochao Chen, Xiaolin Zheng .etc.|<http://arxiv.org/pdf/2506.16218v1>|提出FOCoOp框架，通过多级提示和分布优化增强联邦视觉语言模型在非分布内数据上的鲁棒性。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MoiréXNet: Adaptive Multi-Scale Demoiréing with Linear Attention Test-Time Training and Truncated Flow Matching Prior|莫尔X网络：基于线性注意力测试时间训练和截断流匹配先验的自适应多尺度去莫尔纹方法|Liangyan Li, Yimo Ning, Kevin Le, Wei Dong, Yunzhe Li, Jun Chen, Xiaohong Liu|<http://arxiv.org/pdf/2506.15929v1>|提出了一种结合最大后验估计和深度学习技术的混合框架，有效解决了去摩尔纹问题并恢复了高频细节。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|An Approach Towards Identifying Bangladeshi Leaf Diseases through Transfer Learning and XAI|一种基于迁移学习和可解释性人工智能识别孟加拉国树叶病害的方法|Faika Fairuj Preotee, Shuvashis Sarker, Shamim Rahim Refat, Tashreef Muhammad, Shifat Islam|<http://arxiv.org/pdf/2505.16033v2>|提出了一种结合转移学习和解释性人工智能的植物叶病识别方法，提高了疾病检测准确率并增强了结果的可解释性...|
|🆕 发布|Reliable Few-shot Learning under Dual Noises|双噪声下的可靠小样本学习|Ji Zhang, Jingkuan Song, Lianli Gao, Nicu Sebe, Heng Tao Shen|<http://arxiv.org/pdf/2506.16330v1>|提出了一种可靠的小样本学习方法DETA++，通过对比相关性聚合和噪声熵最大化，有效应对样本中的内外分...|
|🆕 发布|Learning Multi-scale Spatial-frequency Features for Image Denoising|学习多尺度空间频率特征进行图像去噪|Xu Zhao, Chen Zhao, Xiantao Hu, Hongliang Zhang, Ying Tai, Jian Yang|<http://arxiv.org/pdf/2506.16307v1>|提出了一种多尺度自适应双域网络，通过分离高频低频信息提升图像去噪效果。|
|📝 更新|Hierarchical Multi-Positive Contrastive Learning for Patent Image Retrieval|层次化多正样本对比学习在专利图像检索中的应用|Kshitij Kavimandan, Angelos Nalmpantis, Emma Beauxis-Aussalet, Robert-Jan Sips|<http://arxiv.org/pdf/2506.13496v3>|提出了一种利用Locarno分类体系构建的层级多正样本对比损失，有效提升了专利图像检索的准确性。|
|🆕 发布|Neurosymbolic Object-Centric Learning with Distant Supervision|神经符号化对象中心学习与远监督|Stefano Colamonaco, David Debot, Giuseppe Marra|<http://arxiv.org/pdf/2506.16129v1>|提出了一种无需对象级监督即可从原始感知数据中直接学习对象中心表示的神经符号方法。|
|🆕 发布|EndoMUST: Monocular Depth Estimation for Robotic Endoscopy via End-to-end Multi-step Self-supervised Training|EndoMUST：通过端到端多步骤自监督训练实现机器人内窥镜的单目深度估计|Liangjing Shao, Linxin Bai, Chenkang Du, Xinrong Chen|<http://arxiv.org/pdf/2506.16017v1>|[代码](https://github.com/BaymaxShao/EndoMUST.); 提出了一种多步骤自监督训练框架，有效应对内窥镜场景中的光照变化和纹理稀疏问题，实现领先的深度估计性能...|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 交互式感知 (Interactive Perception)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|IS-Bench: Evaluating Interactive Safety of VLM-Driven Embodied Agents in Daily Household Tasks|IS-Bench：评估日常家务任务中VLM驱动的具身智能体的交互安全性|Xiaoya Lu, Zeren Chen, Xuhao Hu, Yijin Zhou, Weichen Zhang, Dongrui Liu, Lu Sheng, Jing Shao|<http://arxiv.org/pdf/2506.16402v1>|提出IS-Bench基准，评估虚拟大型模型驱动的实体代理在日常家庭任务中的交互安全性。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AutoPresent: Designing Structured Visuals from Scratch|自动呈现：从零开始设计结构化视觉元素|Jiaxin Ge, Zora Zhiruo Wang, Xuhui Zhou, Yi-Hao Peng, Sanjay Subramanian, Qinyue Tan, Maarten Sap, Alane Suhr .etc.|<http://arxiv.org/pdf/2501.00912v2>|提出Slide Bench基准，并开发AutoPresent模型，自动化生成高质量的幻灯片。|
|📝 更新|Visual Image Reconstruction from Brain Activity via Latent Representation|通过潜在表征从大脑活动中视觉图像重建|Yukiyasu Kamitani, Misato Tanaka, Ken Shirakawa|<http://arxiv.org/pdf/2505.08429v2>|通过深度神经网络和生成模型，实现了从大脑活动到视觉图像的重建，探讨了模型泛化与人类感知的关联。|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spotting tell-tale visual artifacts in face swapping videos: strengths and pitfalls of CNN detectors|在人脸交换视频中检测关键视觉痕迹：卷积神经网络检测器的优势与陷阱|Riccardo Ziglio, Cecilia Pasquini, Silvio Ranise|<http://arxiv.org/pdf/2506.16497v1>|评估了CNN在检测视频换脸操作中视觉伪影的效果，指出其在跨数据集泛化上的局限性。|
|🆕 发布|How Far Can Off-the-Shelf Multimodal Large Language Models Go in Online Episodic Memory Question Answering?|现成多模态大型语言模型在在线情景记忆问答中能走多远？|Giuseppe Lando, Rosario Forte, Giovanni Maria Farinella, Antonino Furnari|<http://arxiv.org/pdf/2506.16450v1>|探索现成多模态大语言模型在在线视频记忆问答中的表现，实现高效存储与准确回答。|
|📝 更新|PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding|《PerceptionLM：用于详细视觉理解的开放获取数据与模型》|Jang Hyun Cho, Andrea Madotto, Effrosyni Mavroudi, Triantafyllos Afouras, Tushar Nagarajan, Muhammad Maaz, Yale Song, Tengyu Ma .etc.|<http://arxiv.org/pdf/2504.13180v2>|[代码](https://github.com/facebookresearch/perception_models); 提出全开放框架的PerceptionLM模型，通过大规模数据集和视频理解评测套件推动视觉研究透明度。|
|🆕 发布|Robustness Evaluation of OCR-based Visual Document Understanding under Multi-Modal Adversarial Attacks|基于OCR的视觉文档理解在多模态对抗攻击下的鲁棒性评估|Dong Nguyen Tien, Dung D. Le|<http://arxiv.org/pdf/2506.16407v1>|首次提出统一框架，评估OCR文档理解系统在多模态对抗攻击下的鲁棒性。|
|📝 更新|IllusionBench+: A Large-scale and Comprehensive Benchmark for Visual Illusion Understanding in Vision-Language Models|“ IllusionBench+：一个用于视觉错觉理解的大规模综合基准测试，面向视觉-语言模型”|Yiming Zhang, Zicheng Zhang, Xinyi Wei, Xiaohong Liu, Guangtao Zhai, Xiongkuo Min|<http://arxiv.org/pdf/2501.00848v2>|提出了 IllusionBench 数据集，全面评估视觉错觉理解能力，揭示现有视觉语言模型在真实场景...|
|🆕 发布|AutoV: Learning to Retrieve Visual Prompt for Large Vision-Language Models|自动视觉提示检索：用于大规模视觉语言模型的学习|Yuan Zhang, Chun-Kai Fan, Tao Huang, Ming Lu, Sicheng Yu, Junwen Pan, Kuan Cheng, Qi She .etc.|<http://arxiv.org/pdf/2506.16112v1>|提出自动选择最优视觉提示的方法AutoV，提升大型视觉语言模型的性能。|
|📝 更新|Reinforcing Spatial Reasoning in Vision-Language Models with Interwoven Thinking and Visual Drawing|强化视觉语言模型中的空间推理：交织思维与视觉绘图|Junfei Wu, Jian Guan, Kaituo Feng, Qiang Liu, Shu Wu, Liang Wang, Wei Wu, Tieniu Tan|<http://arxiv.org/pdf/2506.09965v2>|提出通过视觉绘图增强空间推理能力，使大型视觉语言模型在空间推理任务上平均提高18.4%。|
|🆕 发布|Adversarial Attacks and Detection in Visual Place Recognition for Safer Robot Navigation|视觉定位中的对抗性攻击与检测：为了更安全的机器人导航|Connor Malone, Owen Claxton, Iman Shames, Michael Milford|<http://arxiv.org/pdf/2506.15988v1>|提出了一种结合视觉定位与攻击检测的框架，显著减少了机器人导航中的定位误差。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Autonomous Computer Vision Development with Agentic AI|具有自主性的代理人工智能的计算机视觉开发|Jin Kim, Muhammad Wahi-Anwa, Sangyun Park, Shawn Shin, John M. Hoffman, Matthew S. Brown|<http://arxiv.org/pdf/2506.11140v3>|利用大型语言模型，实现了计算机视觉系统的自主构建与任务配置。|
|🆕 发布|Spatially-Aware Evaluation of Segmentation Uncertainty|空间感知的分割不确定性评估|Tal Zeevi, Eléonore V. Lieffrig, Lawrence H. Staib, John A. Onofrey|<http://arxiv.org/pdf/2506.16589v1>|提出三个考虑空间信息的分割不确定性评价指标，提高了与临床因素的一致性和区分有意义与虚假不确定性模式的...|
|📝 更新|An Exploratory Approach Towards Investigating and Explaining Vision Transformer and Transfer Learning for Brain Disease Detection|一种探索性方法：研究并解释视觉变换器和迁移学习在脑疾病检测中的应用|Shuvashis Sarker, Shamim Rahim Refat, Faika Fairuj Preotee, Shifat Islam, Tashreef Muhammad, Mohammad Ashraful Hoque|<http://arxiv.org/pdf/2505.16039v2>|探究并解释了Vision Transformer和迁移学习在脑疾病检测中的应用，提高了诊断准确性和模...|
|🆕 发布|VesselSDF: Distance Field Priors for Vascular Network Reconstruction|血管网络重建的距离场先验：VesselSDF|Salvatore Esposito, Daniel Rebain, Arno Onken, Changjian Li, Oisin Mac Aodha|<http://arxiv.org/pdf/2506.16556v1>|提出VesselSDF方法，通过连续距离场回归改善血管网络重建的准确性和几何保真度。|
|📝 更新|Comprehensive Lung Disease Detection Using Deep Learning Models and Hybrid Chest X-ray Data with Explainable AI|使用深度学习模型和混合胸部X射线数据的全面肺部疾病检测及可解释AI|Shuvashis Sarker, Shamim Rahim Refat, Faika Fairuj Preotee, Tanvir Rouf Shawon, Raihan Tanvir|<http://arxiv.org/pdf/2505.16028v2>|利用混合胸部X射线数据集，本研究提升了深度学习模型在肺病检测中的准确性和泛化能力。|
|📝 更新|Boosting multi-demographic federated learning for chest radiograph analysis using general-purpose self-supervised representations|提升多人口统计特征联邦学习用于胸部X射线分析，采用通用自监督表征|Mahshad Lotfinia, Arash Tayebiarasteh, Samaneh Samiei, Mehdi Joodaki, Soroosh Tayebi Arasteh|<http://arxiv.org/pdf/2504.08584v2>|利用通用自监督表征提升多人口学联邦学习在胸部X光分析中的性能。|
|📝 更新|A Survey of World Models for Autonomous Driving|自动驾驶领域世界模型研究综述|Tuo Feng, Wenguan Wang, Yi Yang|<http://arxiv.org/pdf/2501.11260v3>|系统综述了自动驾驶世界模型的发展，提出了分类框架及未来研究方向。|
|🆕 发布|Prompt-based Dynamic Token Pruning to Guide Transformer Attention in Efficient Segmentation|基于提示的动态令牌剪枝以引导Transformer注意力进行高效分割|Pallabi Dutta, Anubhab Maity, Sushmita Mitra|<http://arxiv.org/pdf/2506.16369v1>|提出了一种自适应提示引导的剪枝方法，有效降低无关 tokens 处理，提升医疗图像分割效率。|
|🆕 发布|Segment Anything for Satellite Imagery: A Strong Baseline and a Regional Dataset for Automatic Field Delineation|卫星影像的Segment Anything：自动田地划分的强基线与区域数据集|Carmelo Scribano, Elena Govi, Paolo bertellini, Simone Parisi, Giorgia Franchini, Marko Bertogna|<http://arxiv.org/pdf/2506.16318v1>|提出一种基于Segment Anything模型的农业地块自动提取方法，并构建了新的区域数据集ERA...|
|🆕 发布|CF-Seg: Counterfactuals meet Segmentation|CF-Seg: 对抗性样本遇见分割|Raghav Mehta, Fabio De Sousa Ribeiro, Tian Xia, Melanie Roschewitz, Ainkaran Santhirasekaram, Dominic C. Marshall, Ben Glocker|<http://arxiv.org/pdf/2506.16213v1>|利用生成的反事实图像改善疾病影响下的医学图像分割，提高解剖结构识别准确性。|
|📝 更新|Automatic dataset shift identification to support safe deployment of medical imaging AI|自动数据集偏移识别以支持医疗成像AI的安全部署|Mélanie Roschewitz, Raghav Mehta, Charles Jones, Ben Glocker|<http://arxiv.org/pdf/2411.07940v3>|提出首个无监督医学影像数据集漂移识别框架，区分不同类型漂移以支持安全部署。|
|🆕 发布|Integrating Generative Adversarial Networks and Convolutional Neural Networks for Enhanced Traffic Accidents Detection and Analysis|融合生成对抗网络与卷积神经网络以提高交通事故检测与分析性能|Zhenghao Xi, Xiang Liu, Yaqi Liu, Yitong Cai, Yangyu Zheng|<http://arxiv.org/pdf/2506.16186v1>|结合生成对抗网络和卷积神经网络，有效解决交通事故检测中的数据不足和监控问题。|
|🆕 发布|Towards Classifying Histopathological Microscope Images as Time Series Data|面向将病理学显微镜图像作为时间序列数据进行分类的研究|Sungrae Hong, Hyeongmin Park, Youngsin Ko, Sol Lee, Bryan Wong, Mun Yong Yi|<http://arxiv.org/pdf/2506.15977v1>|将显微镜图像视为时间序列数据进行分类，通过动态时间扭曲和注意力池化提升医学图像分析的准确性和稳定性。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|4Seasons: Benchmarking Visual SLAM and Long-Term Localization for Autonomous Driving in Challenging Conditions|四季：在具有挑战性条件下自动驾驶的视觉SLAM和长期定位基准测试|Patrick Wenzel, Nan Yang, Rui Wang, Niclas Zeller, Daniel Cremers|<http://arxiv.org/pdf/2301.01147v2>|提出了一个面向自动驾驶的视觉SLAM和长期定位基准，涵盖季节变化和复杂环境，促进真实场景下的性能评估...|
|📝 更新|LAECIPS: Large Vision Model Assisted Adaptive Edge-Cloud Collaboration for IoT-based Embodied Intelligence System|LAECIPS：面向物联网智能体系统的大视觉模型辅助自适应边缘-云协同|Shijing Hu, Zhihui Lu, Xin Xu, Ruijun Deng, Xin Du, Qiang Duan|<http://arxiv.org/pdf/2404.10498v2>|提出LAECIPS框架，通过云端大模型与边缘轻模型协作，实现智能视觉检测的高准确性与低延迟。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RealDriveSim: A Realistic Multi-Modal Multi-Task Synthetic Dataset for Autonomous Driving|《RealDriveSim：一种用于自动驾驶的逼真多模态多任务合成数据集》|Arpit Jadon, Haoran Wang, Phillip Thomas, Michael Stanley, S. Nathaniel Cibik, Rachel Laurat, Omar Maher, Lukas Hoyer .etc.|<http://arxiv.org/pdf/2506.16319v1>|[代码](https://realdrivesim.github.io/.); 提出了RealDriveSim，一个逼真的多模态多任务合成数据集，支持自动驾驶领域的多种应用并提升模...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Efficient Mixture-of-Expert for Video-based Driver State and Physiological Multi-task Estimation in Conditional Autonomous Driving|基于视频的驾驶员状态与生理多任务估计在条件自动驾驶中的高效混合专家模型|Jiyao Wang, Xiao Yang, Zhenyu Wang, Ximeng Wei, Ange Wang, Dengbo He, Kaishun Wu|<http://arxiv.org/pdf/2410.21086v2>|提出了一种多任务驾驶员监控系统VDMoE，通过视频和生理信号高效监测驾驶员状态，提升自动驾驶安全性。|
|🆕 发布|DIGMAPPER: A Modular System for Automated Geologic Map Digitization|DIGMAPPER：一种用于自动化地质图数字化 modular 系统|Weiwei Duan, Michael P. Gerlek, Steven N. Minton, Craig A. Knoblock, Fandel Lin, Theresa Chen, Leeje Jang, Sofia Kirsanova .etc.|<http://arxiv.org/pdf/2506.16006v1>|提出了一种模块化系统DIGMAPPER，利用深度学习自动化地质图数字化，大幅提升数据处理效率。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 可解释视觉智能 (Explainable Visual Intelligence)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Dual Thinking and Logical Processing -- Are Multi-modal Large Language Models Closing the Gap with Human Vision ?|双思维与逻辑处理——多模态大型语言模型是否正在缩小与人类视觉的差距？|Kailas Dayanandan, Nikhil Kumar, Anand Sinha, Brejesh Lall|<http://arxiv.org/pdf/2406.06967v4>|探讨了多模态大语言模型在逻辑处理上的不足，并提出了新的对抗性数据集来研究人眼双重思维框架。|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Contour Integration Underlies Human-Like Vision|轮廓整合是人类视觉的基础|Ben Lonnqvist, Elsa Scialom, Abdulkadir Gokce, Zehra Merchant, Michael H. Herzog, Martin Schrimpf|<http://arxiv.org/pdf/2504.05253v2>|揭示了人类视觉中的轮廓整合机制，并发现大数据训练的模型在模仿此机制上有所提升。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Transparency Techniques for Neural Networks trained on Writer Identification and Writer Verification|神经网络在书写者识别与书写者验证中的透明度技术|Viktoria Pundy, Marco Peer, Florian Kleber|<http://arxiv.org/pdf/2506.16331v1>|首次将两种透明度技术应用于训练在书写识别和验证上的神经网络，帮助法医专家分析笔迹相似性。|
|📝 更新|Variance-Based Defense Against Blended Backdoor Attacks|基于方差的对抗混合后门攻击的防御方法|Sujeevan Aseervatham, Achraf Kerzazi, Younès Bennani|<http://arxiv.org/pdf/2506.01444v2>|提出了一种不依赖干净数据集的防御方法，通过训练模型检测并揭示后门攻击的关键触发部分。|

