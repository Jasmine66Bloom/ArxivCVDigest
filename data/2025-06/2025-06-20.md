## [UPDATED!] **2025-06-20** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UniFork: Exploring Modality Alignment for Unified Multimodal Understanding and Generation|"UniFork：探索模态对齐以实现统一的多模态理解和生成"|Teng Li, Quanfeng Lu, Lirui Zhao, Hao Li, Xizhou Zhu, Yu Qiao, Jun Zhang, Wenqi Shao|<http://arxiv.org/pdf/2506.17202v1>|提出Y形结构的UniFork模型，平衡多模态理解和生成任务的学习与专精。|
|🆕 发布|With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You|在有限数据的多模态对齐中，让结构引导你|Fabian Gröger, Shuo Wen, Huyen Le, Maria Brbić|<http://arxiv.org/pdf/2506.16895v1>|提出了一种少量样本下的多模态模型构建方法STRUCTURE，实现了高质量的多模态对齐。|
|📝 更新|ICC: Quantifying Image Caption Concreteness for Multimodal Dataset Curation|图像描述具体性量化：用于多模态数据集整理的方法|Moran Yanuka, Morris Alper, Hadar Averbuch-Elor, Raja Giryes|<http://arxiv.org/pdf/2403.01306v4>|提出了一种评估图像描述具体性的新指标，有效筛选高质量样本以优化多模态学习数据集。|
|📝 更新|Show-o2: Improved Native Unified Multimodal Models|展示-o2：改进的原生统一多模态模型|Jinheng Xie, Zhenheng Yang, Mike Zheng Shou|<http://arxiv.org/pdf/2506.15564v2>|[代码](https://github.com/showlab/Show-o.); 提出了一种融合时空信息的统一多模态模型Show-o2，通过自回归建模和流匹配提升了多模态理解和生成能...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|BreastDCEDL: Curating a Comprehensive DCE-MRI Dataset and developing a Transformer Implementation for Breast Cancer Treatment Response Prediction|乳腺癌动态对比增强磁共振成像数据集的构建与用于乳腺癌治疗响应预测的变换器模型实现|Naomi Fridman, Bubby Solway, Tomer Fridman, Itamar Barnea, Anat Goldstein|<http://arxiv.org/pdf/2506.12190v2>|构建了首个深度学习兼容的DCE-MRI乳腺癌数据集，并开发了一种基于Transformer的预测模型...|
|📝 更新|Efficient Online Inference of Vision Transformers by Training-Free Tokenization|《通过无需训练的标记化实现视觉变换器的有效在线推理》|Leonidas Gee, Wing Yan Li, Viktoriia Sharmanska, Novi Quadrianto|<http://arxiv.org/pdf/2411.15397v2>|提出了一种无需训练的视觉词 tokenize 方法，减少能耗同时保持性能和实时性。|
|📝 更新|DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers|面向分布友好性和异常值感知的视觉变换器后训练量化方法：DopQ-ViT|Lianwei Yang, Haisong Gong, Haokun Lin, Yichen Wu, Zhenan Sun, Qingyi Gu|<http://arxiv.org/pdf/2408.03291v3>|提出了一种针对视觉变换器的分布友好和异常值感知的后训练量化方法，有效保留了模型性能。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MeDi: Metadata-Guided Diffusion Models for Mitigating Biases in Tumor Classification|MeDi：元数据引导的扩散模型用于减轻肿瘤分类中的偏见|David Jacob Drexlin, Jonas Dippel, Julius Hense, Niklas Prenißl, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller|<http://arxiv.org/pdf/2506.17140v1>|提出了一种元数据引导的生成扩散模型MeDi，通过合成数据增强代表性不足的亚群体，有效平衡训练数据并减...|
|🆕 发布|LAION-C: An Out-of-Distribution Benchmark for Web-Scale Vision Models|LAION-C：面向网络规模视觉模型的分布外基准测试|Fanfei Li, Thomas Klein, Wieland Brendel, Robert Geirhos, Roland S. Zimmermann|<http://arxiv.org/pdf/2506.16950v1>|提出了LAION-C，一种针对网络规模数据集设计的全新OOD基准，挑战现有模型并实现与人类观察者相当...|
|📝 更新|GenLit: Reformulating Single-Image Relighting as Video Generation|《GenLit：将单张图像重光照重定义为视频生成》|Shrisha Bharadwaj, Haiwen Feng, Giorgio Becherini, Victoria Fernandez Abrevaya, Michael J. Black|<http://arxiv.org/pdf/2412.11224v3>|将单张图像重光照问题转化为视频生成任务，GenLit框架利用视频扩散模型实现无需3D重建或复杂光线追...|
|📝 更新|More Thinking, Less Seeing? Assessing Amplified Hallucination in Multimodal Reasoning Models|“更多思考，更少观察？评估多模态推理模型中的增强幻觉”|Chengzhi Liu, Zhongxing Xu, Qingyue Wei, Juncheng Wu, James Zou, Xin Eric Wang, Yuyin Zhou, Sheng Liu|<http://arxiv.org/pdf/2505.21523v3>|提出RH-AUC指标和RH-Bench基准，评估多模态模型推理能力与幻觉现象的平衡。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MSCA-Net:Multi-Scale Context Aggregation Network for Infrared Small Target Detection|多尺度上下文聚合网络（MSCA-Net）用于红外小目标检测|Xiaojin Lu, Taoran yue, Jiaxi cai, Yuanping Chen, Cuihong Lv, Shibing Chu|<http://arxiv.org/pdf/2503.17193v2>|提出MSCA-Net网络，通过多尺度特征融合和深层次特征交互显著提升复杂环境下红外小目标检测性能。|
|🆕 发布|LunarLoc: Segment-Based Global Localization on the Moon|月球定位：基于分割的月球全局定位|Annika Thomas, Robaire Galliath, Aleksander Garbuz, Luke Anger, Cormac O'Neill, Trevor Johst, Dami Thomas, George Lordos .etc.|<http://arxiv.org/pdf/2506.16940v1>|[代码](https://github.com/mit-acl/lunarloc-data.); 分类|
|🆕 发布|Cross-modal Offset-guided Dynamic Alignment and Fusion for Weakly Aligned UAV Object Detection|跨模态偏移引导的动态对齐与融合用于弱对齐无人机目标检测|Liu Zongzhen, Luo Hui, Wang Zhixing, Wei Yuxing, Zuo Haorui, Zhang Jianlin|<http://arxiv.org/pdf/2506.16737v1>|提出了一种统一框架CoDAF，通过偏移引导的语义对齐和动态注意力融合，解决了无人机多模态目标检测中的...|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Emergent Temporal Correspondences from Video Diffusion Transformers|从视频扩散变换器中涌现的时序对应关系|Jisu Nam, Soowon Son, Dahyun Chung, Jiyoung Kim, Siyoon Jin, Junhwa Hur, Seungryong Kim|<http://arxiv.org/pdf/2506.17220v1>|提出DiffTrack框架，定量分析视频扩散模型如何建立帧间时间对应关系，并实现零样本点追踪性能突破...|
|🆕 发布|YASMOT: Yet another stereo image multi-object tracker|YASMOT：又一种立体图像多目标跟踪器|Ketil Malde|<http://arxiv.org/pdf/2506.17186v1>|提出了一种轻量级且灵活的多目标跟踪器，能处理来自流行对象检测器的输出，并适用于单目或双目摄像头配置。|
|🆕 发布|MEXA: Towards General Multimodal Reasoning with Dynamic Multi-Expert Aggregation|MEXA：迈向动态多专家聚合的通用多模态推理|Shoubin Yu, Yue Zhang, Ziyang Wang, Jaehong Yoon, Mohit Bansal|<http://arxiv.org/pdf/2506.17113v1>|提出了一种无需训练的MEXA框架，通过动态多专家聚合实现跨领域的有效多模态推理。|
|📝 更新|Genesis: Multimodal Driving Scene Generation with Spatio-Temporal and Cross-Modal Consistency|创世纪：具有时空一致性和跨模态一致性的多模态驾驶场景生成|Xiangyu Guo, Zhanqian Wu, Kaixin Xiong, Ziyang Xu, Lijun Zhou, Gangwei Xu, Shaoqing Xu, Haiyang Sun .etc.|<http://arxiv.org/pdf/2506.07497v4>|提出了一种统一框架Genesis，实现多视角驾驶视频和LiDAR序列的联合生成，确保时空和跨模态一致...|
|🆕 发布|Beyond Blur: A Fluid Perspective on Generative Diffusion Models|超越模糊：对生成扩散模型的一种流体视角|Grzegorz Gruszczynski, Michal Jan Wlodarczyk, Jakub J Meixner, Przemyslaw Musialski|<http://arxiv.org/pdf/2506.16827v1>|提出了一种基于流体动力学的图像生成方法，通过PDE驱动的扩散模型提高了生成图像的多样性和质量。|
|📝 更新|A CLIP-Powered Framework for Robust and Generalizable Data Selection|一个基于CLIP的鲁棒性和泛化性数据选择框架|Suorong Yang, Peng Ye, Wanli Ouyang, Dongzhan Zhou, Furao Shen|<http://arxiv.org/pdf/2410.11215v2>|提出了一种利用多模态信息的CLIP增强数据选择框架，有效提升样本选择稳健性和泛化能力。|
|🆕 发布|Infrared and Visible Image Fusion Based on Implicit Neural Representations|基于隐式神经表示的红外与可见光图像融合|Shuchen Sun, Ligen Shi, Chang Liu, Lina Wu, Jun Qiu|<http://arxiv.org/pdf/2506.16773v1>|提出了一种基于隐式神经表示的图像融合方法，通过连续函数参数化实现多模态信息融合，无需训练数据即可生成...|
|📝 更新|SD++: Enhancing Standard Definition Maps by Incorporating Road Knowledge using LLMs|SD++：通过集成大规模语言模型中的道路知识增强标准定义地图|Hitvarth Diwanji, Jing-Yan Liao, Akshar Tumu, Henrik I. Christensen, Marcell Vazquez-Chanlatte, Chikao Tsuchiya|<http://arxiv.org/pdf/2502.02773v2>|提出了一种利用道路手册知识通过大型语言模型增强标准定义地图的方法SD++，提高了地图的精确度和实用性...|
|🆕 发布|Extracting Multimodal Learngene in CLIP: Unveiling the Multimodal Generalizable Knowledge|在CLIP中提取多模态学习基因：揭示多模态通用知识|Ruiming Chen, Junming Yang, Shiyu Xia, Xu Yang, Jing Wang, Xin Geng|<http://arxiv.org/pdf/2506.16673v1>|提出MM-LG框架，通过提取多模态通用知识，初始化不同规模和模态的后代模型，提升性能同时降低存储和预...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Machine Mental Imagery: Empower Multimodal Reasoning with Latent Visual Tokens|机器心理想象：用潜在视觉标记赋能多模态推理|Zeyuan Yang, Xueyang Yu, Delin Chen, Maohao Shen, Chuang Gan|<http://arxiv.org/pdf/2506.17218v1>|提出了一种无需生成显式图像的机器心理想象框架，增强视觉语言模型的多模态推理能力。|
|🆕 发布|Hunyuan-GameCraft: High-dynamic Interactive Game Video Generation with Hybrid History Condition|混合历史条件下的高动态交互式游戏视频生成：Hunyuan-GameCraft|Jiaqi Li, Junshu Tang, Zhiyong Xu, Longhuang Wu, Yuan Zhou, Shuai Shao, Tianbao Yu, Zhiguo Cao .etc.|<http://arxiv.org/pdf/2506.17201v1>|提出了一种高效互动游戏视频生成框架Hunyuan-GameCraft，通过混合历史条件训练策略和模型...|
|🆕 发布|Long-term Traffic Simulation with Interleaved Autoregressive Motion and Scenario Generation|长时交通模拟：交织自回归运动与场景生成|Xiuyu Yang, Shuhan Tan, Philipp Krähenbühl|<http://arxiv.org/pdf/2506.17213v1>|[代码](https://orangesodahub.github.io/InfGen); 提出InfGen模型，实现闭环运动模拟与场景生成交替，显著提升长期交通模拟稳定性。|
|🆕 发布|On the Theory of Conditional Feature Alignment for Unsupervised Domain-Adaptive Counting|关于无条件特征对齐用于无监督域自适应计数理论的研究|Zhuonan Liang, Dongnan Liu, Jianan Fan, Yaxuan Song, Qiang Qu, Yu Yao, Peng Fu, Weidong Cai|<http://arxiv.org/pdf/2506.17137v1>|提出条件特征对齐理论框架，通过保持任务相关变化并过滤干扰变化，实现跨域计数模型的性能提升。|
|🆕 发布|Dynamic Watermark Generation for Digital Images using Perimeter Gated SPAD Imager PUFs|数字图像动态水印生成：基于周界门控SPAD图像传感器PUFs的方法|Md Sakibur Sajal, Marc Dandin|<http://arxiv.org/pdf/2506.17134v1>|提出利用周界控制的SPAD成像器生成动态数字图像水印，实现源识别与篡改检测。|
|🆕 发布|Assembler: Scalable 3D Part Assembly via Anchor Point Diffusion|装配器：通过锚点扩散实现可扩展的3D零件装配|Wang Zhao, Yan-Pei Cao, Jiale Xu, Yuejiang Dong, Ying Shan|<http://arxiv.org/pdf/2506.17074v1>|提出Assembler框架，通过锚点云扩散实现多样化3D部件组装，无需特定类别训练。|
|📝 更新|EmoAgent: A Multi-Agent Framework for Diverse Affective Image Manipulation|情感图像多样化操作的多元智能体框架：EmoAgent|Qi Mao, Haobo Hu, Yujie He, Difei Gao, Haokun Chen, Libiao Jin|<http://arxiv.org/pdf/2503.11290v2>|提出了一种多代理框架EmoAgent，用于生成符合单一情感目标的多种视觉编辑版本，提升了情感准确性和...|
|🆕 发布|ForestFormer3D: A Unified Framework for End-to-End Segmentation of Forest LiDAR 3D Point Clouds|森林形变器3D：一种用于森林激光雷达三维点云端到端分割的统一框架|Binbin Xiang, Maciej Wielgosz, Stefano Puliti, Kamil Král, Martin Krůček, Azim Missarov, Rasmus Astrup|<http://arxiv.org/pdf/2506.16991v1>|提出ForestFormer3D框架，实现了森林LiDAR 3D点云的精确分割，提升了复杂森林环境的...|
|🆕 发布|AI's Blind Spots: Geographic Knowledge and Diversity Deficit in Generated Urban Scenario|《AI的盲点：生成的城市场景中的地理知识与多样性缺陷》|Ciro Beneduce, Massimiliano Luca, Bruno Lepri|<http://arxiv.org/pdf/2506.16898v1>|揭示了图像生成模型在地理知识和多样性方面的缺陷，通过对比分析指出模型对大都市的偏好和对外来地名的混淆...|
|🆕 发布|Controllable and Expressive One-Shot Video Head Swapping|可控与表现力强的一次性视频头部交换|Chaonan Ji, Jinwei Qi, Peng Zhang, Bang Zhang, Liefeng Bo|<http://arxiv.org/pdf/2506.16852v1>|提出了一种基于扩散的框架，实现了视频头部替换并允许调整头部表情和动作。|
|📝 更新|Sekai: A Video Dataset towards World Exploration|“世界探索之向：Sekai视频数据集”|Zhen Li, Chuanhao Li, Xiaofeng Mao, Shaoheng Lin, Ming Li, Shitian Zhao, Zhaopan Xu, Xinyue Li .etc.|<http://arxiv.org/pdf/2506.15675v2>|[代码](https://lixsp11.github.io/sekai-project); 构建了全球首个面向世界探索的高质量视频数据集Sekai，包含丰富注释，助力视频生成与探索模型训练。|
|🆕 发布|Seeing What Matters: Generalizable AI-generated Video Detection with Forensic-Oriented Augmentation|《洞见关键：面向法医增强的通用人工智能生成视频检测》|Riccardo Corvi, Davide Cozzolino, Ekta Prashnani, Shalini De Mello, Koki Nagano, Luisa Verdoliva|<http://arxiv.org/pdf/2506.16802v1>|提出了一种针对视频检测的通用增强策略，通过关注生成模型引入的低级特征，提高了AI生成视频检测的泛化能...|
|🆕 发布|FOCUS: Unified Vision-Language Modeling for Interactive Editing Driven by Referential Segmentation|“FOCUS：基于参照分割驱动的交互式编辑统一视觉-语言建模”|Fan Yang, Yousong Zhu, Xin Li, Yufei Zhan, Hongyin Zhao, Shurong Zheng, Yaowei Wang, Ming Tang .etc.|<http://arxiv.org/pdf/2506.16806v1>|提出统一视觉语言模型FOCUS，整合感知与生成，实现精准可控的图像编辑。|
|📝 更新|Memory-enhanced Retrieval Augmentation for Long Video Understanding|内存增强的检索增强方法用于长视频理解|Huaying Yuan, Zheng Liu, Minghao Qin, Hongjin Qian, Yan Shu, Zhicheng Dou, Ji-Rong Wen, Nicu Sebe|<http://arxiv.org/pdf/2503.09149v2>|提出了一种基于人类认知记忆的MemVid方法，通过记忆增强检索增强生成，有效提升了长视频理解的效率和...|
|🆕 发布|Noise-Informed Diffusion-Generated Image Detection with Anomaly Attention|噪声指导的扩散生成图像检测与异常关注机制|Weinan Guan, Wei Wang, Bo Peng, Ziwen He, Jing Dong, Haonan Cheng|<http://arxiv.org/pdf/2506.16743v1>|[代码](https://github.com/WeinanGuan/NASA-Swin.); 提出了一种噪声感知的检测框架NASA-Swin，利用噪声模式识别未见过的扩散生成图像。|
|🆕 发布|Few-Shot Generalized Category Discovery With Retrieval-Guided Decision Boundary Enhancement|少量样本泛化类别发现与检索引导决策边界增强|Yunhan Ren, Feng Luo, Siyu Huang|<http://arxiv.org/pdf/2506.16728v1>|[代码](https://github.com/Ryh1218/FSGCD); 提出了一种少量样本条件下的广义类别发现方法，通过检索增强决策边界，提升已知类别边界学习并应用于未知类...|
|🆕 发布|Language-driven Description Generation and Common Sense Reasoning for Video Action Recognition|视频动作识别的语言驱动描述生成与常识推理|Xiaodan Hu, Chuhang Zou, Suchen Wang, Jaechul Kim, Narendra Ahuja|<http://arxiv.org/pdf/2506.16701v1>|引入语言驱动的常识推理框架，有效识别复杂视频动作序列中的遮挡动作。|
|🆕 发布|How to Train your Text-to-Image Model: Evaluating Design Choices for Synthetic Training Captions|如何训练你的文本到图像模型：评估合成训练标注的设计选择|Manuel Brack, Sudeep Katakol, Felix Friedrich, Patrick Schramowski, Hareesh Ravi, Kristian Kersting, Ajinkya Kale|<http://arxiv.org/pdf/2506.16679v1>|系统探究了不同合成训练描述策略对文本到图像模型性能的影响，优化了模型的美学、对齐和多样性。|
|📝 更新|CryoCCD: Conditional Cycle-consistent Diffusion with Biophysical Modeling for Cryo-EM Synthesis|冷冻CCD：基于生物物理建模的冷冻电子显微镜合成条件循环一致性扩散|Runmin Jiang, Genpei Zhang, Yuntian Yang, Siqi Wu, Yuheng Zhang, Wanyue Feng, Yizhou Zhao, Xi Xiao .etc.|<http://arxiv.org/pdf/2505.23444v2>|整合生物物理模型与生成技术，CryoCCD生成真实 cryo-EM 微图，提升下游任务性能。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DreamCube: 3D Panorama Generation via Multi-plane Synchronization|梦幻立方体：通过多平面同步生成三维全景图|Yukun Huang, Yanning Zhou, Jianan Wang, Kaiyi Huang, Xihui Liu|<http://arxiv.org/pdf/2506.17206v1>|提出了一种多平面同步方法，通过扩展2D模型能力实现了高质量的3D全景图生成。|
|🆕 发布|RealSR-R1: Reinforcement Learning for Real-World Image Super-Resolution with Vision-Language Chain-of-Thought|真实世界图像超分辨率中基于视觉-语言链式思维的强化学习：RealSR-R1|Junbo Qiao, Miaomiao Cai, Wei Li, Yutong Liu, Xudong Huang, Gaoqi He, Jiao Xie, Jie Hu .etc.|<http://arxiv.org/pdf/2506.16796v1>|提出了一种融合视觉与语言推理的RealSR-R1模型，通过强化学习实现真实世界图像超分辨率，有效恢复...|
|🆕 发布|Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models|跨模态混淆攻击：针对大型视觉-语言模型的开机攻击|Lei Jiang, Zixun Zhang, Zizhou Wang, Xiaobing Sun, Zhen Li, Liangli Zhen, Xiaohua Xu|<http://arxiv.org/pdf/2506.16760v1>|提出了一种隐蔽且高效的跨模态攻击框架CAMO，用于突破大型视觉语言模型的安全限制。|
|📝 更新|LoRA-Edit: Controllable First-Frame-Guided Video Editing via Mask-Aware LoRA Fine-Tuning|LoRA-Edit：通过遮罩感知的LoRA微调实现可控的首帧引导视频编辑|Chenjian Gao, Lihe Ding, Xin Cai, Zhanpeng Huang, Zibin Wang, Tianfan Xue|<http://arxiv.org/pdf/2506.10082v2>|[代码](https://cjeen.github.io/LoraEditPaper); 提出了一种基于掩码的LoRA微调方法，实现了对视频编辑的灵活控制，同时保持背景区域不变。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Do We Need Large VLMs for Spotting Soccer Actions?|我们是否需要大型语言模型来检测足球动作？|Ritabrata Chakraborty, Rajatsubhra Chakraborty, Avijit Dasgupta, Sandeep Chaurasia|<http://arxiv.org/pdf/2506.17144v1>|提出利用大型语言模型处理专家评论以识别足球比赛关键动作，无需依赖大型视觉语言模型。|
|📝 更新|One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution|一步扩散实现细节丰富且时间一致的视频超分辨率|Yujing Sun, Lingchen Sun, Shuaizheng Liu, Rongyuan Wu, Zhengqiang Zhang, Lei Zhang|<http://arxiv.org/pdf/2506.15591v2>|[代码](https://github.com/yjsunnn/DLoRAL.); 提出了一种双LoRA学习框架，通过迭代优化实现视频超分辨率中的细节丰富和时序一致性。|
|🆕 发布|Unsupervised Image Super-Resolution Reconstruction Based on Real-World Degradation Patterns|基于现实世界退化模式的无监督图像超分辨率重建|Yiyang Tie, Hong Zhu, Yunyun Luo, Jing Shi|<http://arxiv.org/pdf/2506.17027v1>|提出了一种TripleGAN框架，通过学习真实世界退化模式，有效提升了超分辨率图像重建质量。|
|📝 更新|Decoupled Classifier-Free Guidance for Counterfactual Diffusion Models|解耦的无分类器引导策略用于反事实扩散模型|Tian Xia, Fabio De Sousa Ribeiro, Rajat R Rasal, Avinash Kori, Raghav Mehta, Ben Glocker|<http://arxiv.org/pdf/2506.14399v2>|提出了一种新的图像生成框架DCFG，通过分组的条件控制改善了身份保持和减少了不期望的属性变化。|
|📝 更新|Learning Joint Denoising, Demosaicing, and Compression from the Raw Natural Image Noise Dataset|从原始自然图像噪声数据集学习联合去噪、去马赛克和压缩|Benoit Brummer, Christophe De Vleeschouwer|<http://arxiv.org/pdf/2501.08924v2>|提出RawNIND数据集并实现直接在原始数据上进行的去噪和压缩一体化方法，提升图像处理效率和性能。|
|🆕 发布|Reversing Flow for Image Restoration|图像恢复中的反向流方法|Haina Qin, Wenyang Luo, Libin Wang, Dandan Zheng, Jingdong Chen, Ming Yang, Bing Li, Weiming Hu|<http://arxiv.org/pdf/2506.16961v1>|提出ResFlow模型，将图像退化过程建模为确定性路径，有效提升图像复原性能与速度。|
|🆕 发布|Visual-Instructed Degradation Diffusion for All-in-One Image Restoration|视觉指导的退化扩散用于一体化图像恢复|Wenyang Luo, Haina Qin, Zewen Chen, Libin Wang, Dandan Zheng, Yuming Li, Yufan Liu, Bing Li .etc.|<http://arxiv.org/pdf/2506.16960v1>|提出了一种统一的图像复原框架Defusion，通过视觉指令引导的退化扩散处理多种退化类型，提高了图像...|
|🆕 发布|PET Tracer Separation Using Conditional Diffusion Transformer with Multi-latent Space Learning|使用条件扩散变换器和多潜在空间学习进行PET示踪剂分离|Bin Huang, Feihong Xu, Xinchong Shi, Shan Huang, Binxuan Li, Fei Li, Qiegen Liu|<http://arxiv.org/pdf/2506.16934v1>|[代码](https://github.com/yqx7150/MS-CDT.); 提出了一种基于纹理条件和多潜在空间的扩散变压器模型，实现了PET成像中不同示踪剂信号的分离。|
|🆕 发布|Self-supervised Feature Extraction for Enhanced Ball Detection on Soccer Robots|用于增强足球机器人球检测的自监督特征提取|Can Lin, Daniele Affinita, Marco E. P. Zimmatore, Daniele Nardi, Domenico D. Bloisi, Vincenzo Suriani|<http://arxiv.org/pdf/2506.16821v1>|提出了一种自监督学习框架，通过无需手动标注的方式，提高了足球机器人动态环境下的球检测性能。|
|🆕 发布|PQCAD-DM: Progressive Quantization and Calibration-Assisted Distillation for Extremely Efficient Diffusion Model|PQCAD-DM：渐进量化和校准辅助蒸馏用于极高效率的扩散模型|Beomseok Ko, Hyeryung Jang|<http://arxiv.org/pdf/2506.16776v1>|提出PQCAD-DM框架，结合逐级量化和校准辅助蒸馏，实现高效扩散模型压缩与性能保持。|
|🆕 发布|TeSG: Textual Semantic Guidance for Infrared and Visible Image Fusion|文本语义引导的红外与可见光图像融合方法|Mingrui Zhu, Xiru Chen, Xin Wei, Nannan Wang, Xinbo Gao|<http://arxiv.org/pdf/2506.16730v1>|引入文本语义引导红外与可见光图像融合，提升下游任务性能。|
|📝 更新|Label-guided Facial Retouching Reversion|标签引导的面部修饰反转|Guanhua Zhao, Yu Gu, Xuhan Sheng, Yujie Hu, Jian Zhang|<http://arxiv.org/pdf/2404.14177v2>|提出Re-Face框架，通过检测和模型反转面部修饰，并使用颜色校正技术恢复原始面貌。|
|🆕 发布|A Prior-Guided Joint Diffusion Model in Projection Domain for PET Tracer Conversion|投影域中先验引导的联合扩散模型用于PET示踪剂转换|Fang Chen, Weifeng Zhang, Xingyu Ai, BingXuan Li, An Li, Qiegen Liu|<http://arxiv.org/pdf/2506.16733v1>|[代码](https://github.com/yqx7150/PJDM.); 提出了一种基于先验引导的联合扩散模型，直接在投影域将18F-FDG PET图像转换为18F-DOPA...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Part$^{2}$GS: Part-aware Modeling of Articulated Objects using 3D Gaussian Splatting|基于三维高斯散点法的关节对象部分感知建模Part$^{2}$GS|Tianjiao Yu, Vedant Shah, Muntasir Wahed, Ying Shen, Kiet A. Nguyen, Ismini Lourentzou|<http://arxiv.org/pdf/2506.17212v1>|提出了一种用于高保真建模和物理一致运动的关节对象的新型框架Part$^{2}$GS。|
|📝 更新|Perceptual-GS: Scene-adaptive Perceptual Densification for Gaussian Splatting|《感知-GS：场景自适应感知加密用于高斯散点绘制》|Hongbi Zhou, Zhangkai Ni|<http://arxiv.org/pdf/2506.12400v2>|[代码](https://github.com/eezkni/Perceptual-GS); 提出了一种基于人类视觉敏感性的自适应 Gaussian Splatting 方法，有效平衡了三维场景...|
|🆕 发布|ParkFormer: A Transformer-Based Parking Policy with Goal Embedding and Pedestrian-Aware Control|ParkFormer：一种基于变换器的带有目标嵌入和行人感知控制的停车策略|Jun Fu, Bin Tian, Haonan Chen, Shi Meng, Tingting Yao|<http://arxiv.org/pdf/2506.16856v1>|[代码](https://github.com/little-snail-f/ParkFormer.); 提出了一种基于Transformer的自动驾驶停车策略，通过融合目标点与周围环境信息，提高了停车精度...|
|📝 更新|Efficient Depth-Guided Urban View Synthesis|高效深度引导的城市视图合成|Sheng Miao, Jiaxin Huang, Dongfeng Bai, Weichao Qiu, Bingbing Liu, Andreas Geiger, Yiyi Liao|<http://arxiv.org/pdf/2407.12395v2>|提出了一种高效的深度引导城市视图合成方法，通过利用预测的几何先验实现从稀疏输入图像的通用视图合成。|
|🆕 发布|3DeepRep: 3D Deep Low-rank Tensor Representation for Hyperspectral Image Inpainting|三维深度低秩张量表示法用于高光谱图像修复|Yunshan Li, Wenwu Gong, Qianqian Wang, Chao Wang, Lili Yang|<http://arxiv.org/pdf/2506.16735v1>|提出了一种沿三个方向进行深度非线性变换的3D低秩张量表示方法，有效提升了高光谱图像修复性能。|
|📝 更新|NeRF: Neural Radiance Field in 3D Vision: A Comprehensive Review (Updated Post-Gaussian Splatting)|神经辐射场在三维视觉中：全面回顾（高斯散点更新后）|Kyle Gao, Yina Gao, Hongjie He, Dening Lu, Linlin Xu, Jonathan Li|<http://arxiv.org/pdf/2210.00379v6>|系统梳理了NeRF在3D视觉中的发展，对比了其与传统方法及后续技术Gaussian Splattin...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SR3D: Unleashing Single-view 3D Reconstruction for Transparent and Specular Object Grasping|SR3D：释放单视角三维重建以实现透明和光滑物体的抓取|Mingxu Zhang, Xiaoqi Li, Jiahui Xu, Kaichen Zhou, Hojin Bae, Yan Shen, Chuyan Xiong, Hao Dong|<http://arxiv.org/pdf/2505.24305v3>|提出了一种无需训练的SR3D框架，通过单视角观测实现透明和光滑物体的3D重建与抓取。|
|📝 更新|Cross-Modal Geometric Hierarchy Fusion: An Implicit-Submap Driven Framework for Resilient 3D Place Recognition|跨模态几何层次融合：一种由隐式子图驱动的鲁棒三维场景识别框架|Xiaohui Jiang, Haijiang Zhu, Chade Li, Fulin Tang, Ning An|<http://arxiv.org/pdf/2506.14243v2>|提出了一种基于弹性点隐式表示的3D场景识别框架，融合宏观与微观几何信息，提高了识别稳定性和准确性。|


## 时序视觉分析 (Temporal Visual Analysis)


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Relaxed syntax modeling in Transformers for future-proof license plate recognition|Transformer中的松弛语法建模以实现面向未来的车牌识别|Florent Meyer, Laurent Guichard, Denis Coquenet, Guillaume Gravier, Yann Soullard, Bertrand Coüasnon|<http://arxiv.org/pdf/2506.17051v1>|提出 Syntax-Less Transformer，解决传统Transformer对车牌 synt...|
|📝 更新|DeSPITE: Exploring Contrastive Deep Skeleton-Pointcloud-IMU-Text Embeddings for Advanced Point Cloud Human Activity Understanding|尽管如此：探索对比深度骨架点云-IMU-文本嵌入以实现高级点云人体活动理解|Thomas Kreutz, Max Mühlhäuser, Alejandro Sanchez Guinea|<http://arxiv.org/pdf/2506.13897v2>|提出了一种多模态对比预训练方法DeSPITE，将点云、骨架、IMU和文本数据融合，提升了人体活动理解...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension|MaPPER：多模态先验引导的参数高效调整用于指代表达式理解|Ting Liu, Zunnan Xu, Yue Hu, Liangtao Shi, Zhiqiang Wang, Quanjun Yin|<http://arxiv.org/pdf/2409.13609v4>|[代码](https://github.com/liuting20/MaPPER.); 提出了一种高效的视觉语言理解框架MaPPER，通过引入动态先验适配器，实现了参数高效的微调，显著提升...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Facial Landmark Visualization and Emotion Recognition Through Neural Networks|神经网络实现的面部特征点可视化与情感识别|Israel Juárez-Jiménez, Tiffany Guadalupe Martínez Paredes, Jesús García-Ramírez, Eric Ramos Aguilar|<http://arxiv.org/pdf/2506.17191v1>|提出面部地标箱线图可视化技术，并比较不同特征对情感识别的神经网络性能影响。|
|🆕 发布|Prmpt2Adpt: Prompt-Based Zero-Shot Domain Adaptation for Resource-Constrained Environments|基于提示的零样本领域自适应：面向资源受限环境|Yasir Ali Farrukh, Syed Wali, Irfan Khan, Nathaniel D. Bastian|<http://arxiv.org/pdf/2506.16994v1>|提出了Prmpt2Adpt，一种适用于资源受限环境的轻量级零样本域自适应框架，通过提示驱动的特征对齐...|
|📝 更新|Real-time Free-view Human Rendering from Sparse-view RGB Videos using Double Unprojected Textures|使用双向未投影纹理从稀疏视角RGB视频实现实时自由视角人体渲染|Guoxing Sun, Rishabh Dabral, Heming Zhu, Pascal Fua, Christian Theobalt, Marc Habermann|<http://arxiv.org/pdf/2412.13183v3>|提出了一种分离几何变形估计与外观合成的实时自由视角人体渲染方法，实现了4K级的高质量渲染效果。|
|🆕 发布|LaVi: Efficient Large Vision-Language Models via Internal Feature Modulation|LaVi：通过内部特征调制实现高效的大规模视觉-语言模型|Tongtian Yue, Longteng Guo, Yepeng Tang, Zijia Zhao, Xinxin Zhu, Hua Huang, Jing Liu|<http://arxiv.org/pdf/2506.16691v1>|LaVi通过内部特征调制实现视觉与语言的高效融合，大幅提升多模态模型性能并降低计算成本。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Improving Surgical Risk Prediction Through Integrating Automated Body Composition Analysis: a Retrospective Trial on Colectomy Surgery|通过整合自动化身体成分分析提高手术风险预测：一项关于结肠切除术的回顾性试验|Hanxue Gu, Yaqian Chen, Jisoo Lee, Diego Schaps, Regina Woody, Roy Colglazier, Maciej A. Mazurowski, Christopher Mantyh|<http://arxiv.org/pdf/2506.11996v3>|利用CT扫描自动提取的术前身体成分指标，结合临床变量，有效预测结直肠癌术后一年全因死亡率。|
|📝 更新|SHAKTI: A 2.5 Billion Parameter Small Language Model Optimized for Edge AI and Low-Resource Environments|SHAKTI：面向边缘AI和低资源环境优化的25亿参数小型语言模型|Syed Abdul Gaffar Shakhadri, Kruthika KR, Rakshit Aralimatti|<http://arxiv.org/pdf/2410.11331v2>|介绍了Shakti，一种为边缘设备和低资源环境优化的2.5亿参数小语言模型，实现高效实时AI应用。|
|🆕 发布|Camera Calibration via Circular Patterns: A Comprehensive Framework with Measurement Uncertainty and Unbiased Projection Model|通过圆形图案进行相机标定：一个包含测量不确定性和无偏投影模型的综合框架|Chaehyeon Song, Dongjae Lee, Jongwoo Lim, Ayoung Kim|<http://arxiv.org/pdf/2506.16842v1>|[代码](https://github.com/chaehyeonsong/discocal.); 提出了一种无偏的圆模式投影模型及不确定性测量，提高了相机校准的准确性和鲁棒性。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RGBTrack: Fast, Robust Depth-Free 6D Pose Estimation and Tracking|RGBTrack：快速、稳健的无深度6D位姿估计与跟踪|Teng Guo, Jingjin Yu|<http://arxiv.org/pdf/2506.17119v1>|[代码](https://github.com/GreatenAnoymous/RGBTrack.git.); 提出了一种无需深度输入的RGBTrack框架，实现了实时、稳健的6D姿态估计与跟踪。|
|📝 更新|Training Multi-Layer Binary Neural Networks With Local Binary Error Signals|多层二值神经网络训练中的局部二值误差信号|Luca Colombo, Fabrizio Pittorino, Manuel Roveri|<http://arxiv.org/pdf/2412.00119v3>|首次提出了一种全二值、无需梯度的多层二值神经网络训练算法，显著提升准确度同时大幅降低计算成本。|
|🆕 发布|Temperature calibration of surface emissivities with an improved thermal image enhancement network|表面发射率温度校准的改进型热图像增强网络|Ning Chu, Siya Zheng, Shanqing Zhang, Li Li, Caifang Cai, Ali Mohammad-Djafari, Feng Zhao, Yuanbo Song|<http://arxiv.org/pdf/2506.16803v1>|提出了一种统一温度校正与图像增强的神经网络框架，有效解决了红外热成像中温度准确性问题。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Proportional Sensitivity in Generative Adversarial Network (GAN)-Augmented Brain Tumor Classification Using Convolutional Neural Network|使用卷积神经网络进行生成对抗网络（GAN）增强的脑肿瘤分类中的比例敏感性|Mahin Montasir Afif, Abdullah Al Noman, K. M. Tahsin Kabir, Md. Mortuza Ahmmed, Md. Mostafizur Rahman, Mufti Mahmud, Md. Ashraful Babu|<http://arxiv.org/pdf/2506.17165v1>|探究了GAN生成图像与真实图像的不同比例对CNN在脑肿瘤分类性能的影响。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Acquiring and Accumulating Knowledge from Diverse Datasets for Multi-label Driving Scene Classification|从多样化数据集中获取与累积知识以实现多标签驾驶场景分类|Ke Li, Chenyu Zhang, Yuxin Ding, Xianbiao Hu, Ruwen Qin|<http://arxiv.org/pdf/2506.17101v1>|[代码](https://github.com/KELISBU/KAA-CAL); 提出一种结合知识获取与累积及一致性主动学习的方法，有效提升多标签驾驶场景分类性能。|
|📝 更新|Generalized Category Discovery under the Long-Tailed Distribution|长尾分布下的泛化类别发现|Bingchen Zhao, Kai Han|<http://arxiv.org/pdf/2506.12515v2>|提出了一种针对长尾分布的广义类别发现框架，通过置信样本选择和密度聚类平衡分类器学习和类别数量估计。|
|📝 更新|When and How Does CLIP Enable Domain and Compositional Generalization?|何时及如何CLIP实现域与组合泛化？|Elias Kempf, Simon Schrodi, Max Argus, Thomas Brox|<http://arxiv.org/pdf/2502.09507v2>|探究CLIP模型在多样训练分布下的域泛化和组合泛化能力及其影响因素。|
|🆕 发布|Loupe: A Generalizable and Adaptive Framework for Image Forgery Detection|《loupe：一种通用且自适应的图像伪造检测框架》|Yuchu Jiang, Jiaming Chu, Jian Zhao, Xin Zhang, Xu Yang, Lei Jin, Chi Zhang, Xuelong Li|<http://arxiv.org/pdf/2506.16819v1>|[代码](https://github.com/Kamichanw/Loupe.); 提出了一种融合分类与定位的轻量级框架Loupe，有效提升了图像伪造检测的泛化能力和准确性。|
|📝 更新|Understanding and Reducing the Class-Dependent Effects of Data Augmentation with A Two-Player Game Approach|"理解并减少数据增强的类依赖效应：一种双玩家博弈方法"|Yunpeng Jiang, Yutong Ban, Paul Weng|<http://arxiv.org/pdf/2407.03146v4>|提出CLAM方法，通过对抗性双玩家游戏平衡数据增强对多类分类中不同类别的影响。|
|📝 更新|Improving Out-of-Distribution Detection via Dynamic Covariance Calibration|通过动态协方差校准提高分布外检测性能|Kaiyu Guo, Zijian Wang, Tan Pan, Brian C. Lovell, Mahsa Baktashmotlagh|<http://arxiv.org/pdf/2506.09399v2>|[代码](https://github.com/workerbcd/ooddcc.); 提出动态调整先验协方差矩阵的方法，有效改善了样本分布不均导致的异常检测问题。|


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DepthVanish: Optimizing Adversarial Interval Structures for Stereo-Depth-Invisible Patches|深度消失：优化立体深度不可见贴片的对抗性间隔结构|Yun Xing, Yue Cao, Nhat Chung, Jie Zhang, Ivor Tsang, Ming-Ming Cheng, Yang Liu, Lei Ma .etc.|<http://arxiv.org/pdf/2506.16690v1>|提出了一种带规律间隔的条纹结构，优化了立体深度攻击贴片，有效攻击了先进立体深度估计方法和商业RGB-...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation|Dex1B：基于10亿演示学习进行灵巧操作|Jianglong Ye, Keyi Wang, Chengjing Yuan, Ruihan Yang, Yiquan Li, Jiyue Zhu, Yuzhe Qin, Xueyan Zou .etc.|<http://arxiv.org/pdf/2506.17198v1>|提出了一种生成模型，创建了包含10亿个示范的大型手部操作数据集，显著提升了模拟和真实世界中的操作性能...|
|📝 更新|Deep Learning based Visually Rich Document Content Understanding: A Survey|基于深度学习的视觉丰富文档内容理解：综述|Yihao Ding, Soyeon Caren Han, Jean Lee, Eduard Hovy|<http://arxiv.org/pdf/2408.01287v2>|概述了深度学习在理解富含视觉元素的文档内容方面的进展，提升了信息提取效率。|
|📝 更新|Bridging Domain Gaps in Agricultural Image Analysis: A Comprehensive Review From Shallow Adaptation to Deep Learning|农业图像分析中的领域差距桥接：从浅层适应到深度学习的全面回顾|Xing Hu, Siyuan Chen, Xuming Huang, Qianqian Duan, LingKun Luo, Ruijiao Li, Huiliang Shang, Linhua Jiang .etc.|<http://arxiv.org/pdf/2506.05972v2>|系统总结了域适应技术在农业图像分析中的应用，提升了模型在不同环境下的迁移性。|
|🆕 发布|AnyTraverse: An off-road traversability framework with VLM and human operator in the loop|AnyTraverse：一种结合VLM和人工操作员参与的越野通行性评估框架|Sattwik Sahu, Agamdeep Singh, Karthik Nambiar, Srikanth Saripalli, P. B. Sujit|<http://arxiv.org/pdf/2506.16826v1>|提出了一种结合自然语言提示和人工辅助的AnyTraverse框架，实现了适应多种机器人的越野通行性识...|
|📝 更新|Cost-effective Instruction Learning for Pathology Vision and Language Analysis|病理视觉与语言分析的经济高效指令学习|Kaitao Chen, Mianxin Liu, Fang Yan, Lei Ma, Xiaoming Shi, Lilong Wang, Xiaosong Wang, Lifeng Zhu .etc.|<http://arxiv.org/pdf/2407.17734v2>|提出了一种经济的指令学习框架CLOVER，通过轻量级模块训练和指令微调，有效应对病理视觉问答中的资源...|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Monocular One-Shot Metric-Depth Alignment for RGB-Based Robot Grasping|单目一阶段度量-深度对准用于基于RGB的机器人抓取|Teng Guo, Baichuan Huang, Jingjin Yu|<http://arxiv.org/pdf/2506.17110v1>|提出了一种单目图像直接恢复度量深度的方法MOMA，通过一次适配实现精确深度估计，有效支持机器人抓取任...|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VLN-R1: Vision-Language Navigation via Reinforcement Fine-Tuning|VLN-R1：通过强化微调的视觉-语言导航|Zhangyang Qi, Zhixiong Zhang, Yizhou Yu, Jiaqi Wang, Hengshuang Zhao|<http://arxiv.org/pdf/2506.17221v1>|提出VLN-R1框架，利用大型视觉语言模型直接将视频流转化为连续导航动作，并通过强化微调提升路径规划...|
|📝 更新|Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence|具身网络代理：桥接物理-数字领域以实现集成代理智能|Yining Hong, Rui Sun, Bingxuan Li, Xingcheng Yao, Maxine Wu, Alexander Chien, Da Yin, Ying Nian Wu .etc.|<http://arxiv.org/pdf/2506.15677v2>|[代码](https://embodied-web-agent.github.io/.); 提出Embodied Web Agents新范式，整合实体感知与网络推理，解决物理与数字智能融合任务...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AerialVG: A Challenging Benchmark for Aerial Visual Grounding by Exploring Positional Relations|《AerialVG：通过探索位置关系构建的航空视觉定位基准测试》|Junli Liu, Qizhi Chen, Zhigang Wang, Yiwen Tang, Yiting Zhang, Chi Yan, Dong Wang, Bin Zhao .etc.|<http://arxiv.org/pdf/2504.07836v3>|提出首个针对航拍视觉定位的挑战性数据集AerialVG，并设计了一种结合空间关系推理的模型。|
|🆕 发布|Stretching Beyond the Obvious: A Gradient-Free Framework to Unveil the Hidden Landscape of Visual Invariance|《超越表象：一种无需梯度的框架揭示视觉不变性的隐藏景观》|Lorenzo Tausani, Paolo Muratore, Morgan B. Talbot, Giacomo Amerio, Gabriel Kreiman, Davide Zoccolan|<http://arxiv.org/pdf/2506.17040v1>|提出 Stretch-and-Squeeze 框架，系统探究视觉单元的不变性景观及其对抗性扰动脆弱性...|
|🆕 发布|Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs|增强基于大型语言模型的可逐步细化和可验证的医疗推理|Haoran Sun, Yankai Jiang, Wenjie Lou, Yujie Zhang, Wenjie Li, Lilong Wang, Mianxin Liu, Lei Liu .etc.|<http://arxiv.org/pdf/2506.16962v1>|提出MICS方法，通过导师模型引导，优化医疗多模态语言模型的推理路径生成高质量训练数据。|
|📝 更新|360VOTS: Visual Object Tracking and Segmentation in Omnidirectional Videos|全方位视觉目标跟踪与分割：360度视频中的研究|Yinzhe Xu, Huajian Huang, Yingshu Chen, Sai-Kit Yeung|<http://arxiv.org/pdf/2404.13953v2>|引入扩展视场定位方法，创建了首个全方位视觉目标跟踪与分割的通用框架及评估标准。|
|🆕 发布|Co-VisiON: Co-Visibility ReasONing on Sparse Image Sets of Indoor Scenes|室内场景稀疏图像集上的共可视推理：Co-VisiON|Chao Chen, Nobel Dang, Juexiao Zhang, Wenkai Sun, Pengfei Zheng, Xuhang He, Yimeng Ye, Taarun Srinivas .etc.|<http://arxiv.org/pdf/2506.16805v1>|[代码](https://ai4ce.github.io/CoVISION); 提出Co-VisiON基准，评估稀疏室内场景图像共可视性推理，提出Covis模型缩小与人类表现差距。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Class Agnostic Instance-level Descriptor for Visual Instance Search|用于视觉实例检索的无类别实例级描述符|Qi-Ying Sun, Wan-Lei Zhao, Yi-Bo Miao, Chong-Wah Ngo|<http://arxiv.org/pdf/2506.16745v1>|提出了一种基于自监督学习的无类别实例级描述符，有效解决了视觉实例搜索中的特征表示问题。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Semi-Supervised Multi-Modal Medical Image Segmentation for Complex Situations|复杂情况下的半监督多模态医学图像分割|Dongdong Meng, Sheng Li, Hao Wu, Guoping Wang, Xueqing Yan|<http://arxiv.org/pdf/2506.17136v1>|提出了一种半监督多模态医疗图像分割方法，利用多模态信息提升有限标注数据的分割性能。|
|🆕 发布|Co-Seg++: Mutual Prompt-Guided Collaborative Learning for Versatile Medical Segmentation|协同分割增强：基于相互提示引导的协作学习用于多功能的医学分割|Qing Xu, Yuxiang Luo, Wenting Duan, Zhen Chen|<http://arxiv.org/pdf/2506.17159v1>|[代码](https://github.com/xq141839/Co-Seg-Plus.); 提出了一种协同学习框架Co-Seg++，通过相互引导的编码器和解码器提升了医学图像分割的性能。|
|🆕 发布|Robust Training with Data Augmentation for Medical Imaging Classification|医学成像分类中的数据增强稳健训练|Josué Martínez-Martínez, Olivia Brown, Mostafa Karami, Sheida Nabavi|<http://arxiv.org/pdf/2506.17133v1>|提出了一种结合数据增强的鲁棒训练算法，有效提高了医疗图像分类模型对对抗攻击和分布偏移的抵抗力。|
|🆕 发布|From Lab to Factory: Pitfalls and Guidelines for Self-/Unsupervised Defect Detection on Low-Quality Industrial Images|从实验室到工厂：低质量工业图像中自监督/无监督缺陷检测的陷阱与指南|Sebastian Hönel, Jonas Nordqvist|<http://arxiv.org/pdf/2506.16890v1>|揭示了工业低质量图像中缺陷检测的挑战，并提供了评估和改进模型稳健性的实用指南。|
|🆕 发布|TextBraTS: Text-Guided Volumetric Brain Tumor Segmentation with Innovative Dataset Development and Fusion Module Exploration|文本引导的体积脑肿瘤分割：创新数据集开发与融合模块探索|Xiaoyu Shi, Rahul Kumar Jain, Yinhao Li, Ruibo Hou, Jingliang Cheng, Jie Bai, Guohua Zhao, Lanfen Lin .etc.|<http://arxiv.org/pdf/2506.16784v1>|[代码](https://github.com/Jupitern52/TextBraTS.); 提出首个结合文本注释的脑肿瘤分割多模态数据集TextBraTS，并实现了一种文本引导的体积分割框架提...|
|🆕 发布|Uncertainty-Aware Variational Information Pursuit for Interpretable Medical Image Analysis|不确定性感知的变分信息追求用于可解释性医学图像分析|Md Nahiduzzaman, Ruwan Tennakoon, Steven Korevaar, Zongyuan Ge, Alireza Bab-Hadiashar|<http://arxiv.org/pdf/2506.16742v1>|引入了考虑不确定性的变分信息追求框架，提升医疗图像分析的准确性和解释性。|
|📝 更新|Medical Artificial Intelligence for Early Detection of Lung Cancer: A Survey|医学人工智能在肺癌早期检测中的应用：综述|Guohui Cai, Ying Cai, Zeyu Zhang, Yuanzhouhan Cao, Lin Wu, Daji Ergu, Zhinbin Liao, Yang Zhao|<http://arxiv.org/pdf/2410.14769v2>|[代码](https://github.com/CaiGuoHui123/Awesome-Lung-Cancer-Detection.); 概述了深度学习在早期肺癌检测中的进展，提升了肺结节分析准确性和效率。|
|📝 更新|Privacy-Preserving Chest X-ray Classification in Latent Space with Homomorphically Encrypted Neural Inference|隐私保护的基于同态加密神经网络推理的潜在空间胸部X射线分类|Jonghun Kim, Gyeongdeok Jo, Sinyoung Ra, Hyunjin Park|<http://arxiv.org/pdf/2506.15258v2>|提出了一种利用同态加密和图像压缩技术在保证隐私的同时进行胸部X射线分类的方法。|
|📝 更新|SynPo: Boosting Training-Free Few-Shot Medical Segmentation via High-Quality Negative Prompts|“SynPo：通过高质量负向提示增强无需训练的少量样本医学分割”|Yufei Liu, Haoke Xiao, Jiaxing Chai, Yongcun Zhang, Rong Wang, Zijie Meng, Zhiming Luo|<http://arxiv.org/pdf/2506.15153v2>|提出SynPo方法，通过提升负提示质量，无需训练实现医学图像少样本分割性能提升。|
|📝 更新|Demographics-Informed Neural Network for Multi-Modal Spatiotemporal forecasting of Urban Growth and Travel Patterns Using Satellite Imagery|基于人口统计信息的神经网络：利用卫星图像进行城市增长与出行模式的多模态时空预测|Eugene Kofi Okrah Denteh, Andrews Danyo, Joshua Kofi Asamoah, Blessing Agyei Kyem, Armstrong Aboah|<http://arxiv.org/pdf/2506.12456v2>|提出了一种融合地理卫星影像、人口统计和出行行为数据的深度学习框架，实现了对未来城市空间变化的准确预测...|
|📝 更新|Event Cameras Meet SPADs for High-Speed, Low-Bandwidth Imaging|事件相机与SPAD相结合实现高速低带宽成像|Manasi Muglikar, Siddharth Somasundaram, Akshat Dave, Edoardo Charbon, Ramesh Raskar, Davide Scaramuzza|<http://arxiv.org/pdf/2404.11511v2>|融合事件相机与SPAD传感器，实现低光照下高速成像且降低带宽需求。|
|📝 更新|Enhancing Weakly Supervised 3D Medical Image Segmentation through Probabilistic-aware Learning|通过概率感知学习增强弱监督三维医学图像分割|Runmin Jiang, Zhaoxin Fan, Junhao Wu, Lenghan Zhu, Xin Huang, Tianyang Wang, Heng Huang, Min Xu|<http://arxiv.org/pdf/2403.02566v2>|[代码](https://github.com/runminjiang/PW4MedSeg.); 提出了一种概率感知的弱监督3D医疗图像分割方法，通过稀疏标注生成高质量分割结果，性能媲美全监督方法。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Synthetic Benchmark for Collaborative 3D Semantic Occupancy Prediction in V2X Autonomous Driving|面向V2X自动驾驶的协同三维语义占据预测合成基准|Hanlin Wu, Pengfei Lin, Ehsan Javanmardi, Naren Bao, Bo Qian, Hao Si, Manabu Tsukada|<http://arxiv.org/pdf/2506.17004v1>|构建合成数据集并设计基准，提升自动驾驶中协同3D语义占位预测的准确性与完整性。|
|📝 更新|Collaborative Perception Datasets for Autonomous Driving: A Review|自动驾驶协同感知数据集：综述|Naibang Wang, Deyong Shang, Yan Gong, Xiaoxi Hu, Ziying Song, Lei Yang, Yuhan Huang, Xiaoyu Wang .etc.|<http://arxiv.org/pdf/2504.12696v2>|[代码](https://github.com/frankwnb/Collaborative-Perception-Datasets-for-Autonomous-Driving.); 系统综述并比较了自动驾驶协同感知数据集，促进了资源有效利用和模型评估标准化。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|IQE-CLIP: Instance-aware Query Embedding for Zero-/Few-shot Anomaly Detection in Medical Domain|IQE-CLIP：面向医疗领域零样本/少样本异常检测的实例感知查询嵌入|Hong Huang, Weixiang Sun, Zhijian Wu, Jingwen Niu, Donghuan Lu, Xian Wu, Yefeng Zheng|<http://arxiv.org/pdf/2506.10730v3>|[代码](https://github.com/hongh0/IQE-CLIP); 提出了一种结合文本和视觉信息的查询嵌入框架IQE-CLIP，用于医疗领域的零样本和少样本异常检测。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Comparative Analysis of Principal Component Analysis (PCA) and Singular Value Decomposition (SVD) as Dimensionality Reduction Techniques|主成分分析（PCA）与奇异值分解（SVD）作为降维技术的比较分析|Michael Gyimadu, Gregory Bell|<http://arxiv.org/pdf/2506.16663v1>|对比分析了PCA和SVD两种降维技术，为选择适用算法提供了规则性指导。|

