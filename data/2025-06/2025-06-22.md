## [UPDATED!] **2025-06-22** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CLIP-HandID: Vision-Language Model for Hand-Based Person Identification|基于手的视觉-语言模型CLIP-HandID：用于手部识别人物身份|Nathanael L. Baisa, Babu Pallam, Amudhavel Jayavel|<http://arxiv.org/pdf/2506.12447v2>|提出了一种利用预训练的视觉语言模型CLIP进行手部图像识别的新方法，有效提升了犯罪调查中的身份识别准...|
|📝 更新|Multi-entity Video Transformers for Fine-Grained Video Representation Learning|多实体视频变换器用于细粒度视频表征学习|Matthew Walmer, Rose Kanjirathinkal, Kai Sheng Tai, Keyur Muzumdar, Taipeng Tian, Abhinav Shrivastava|<http://arxiv.org/pdf/2311.10873v2>|提出了一种多实体视频变换器模型，通过在时间管道中共享场景信息，提升了细粒度视频表示学习的性能。|
|🆕 发布|TEM^3-Learning: Time-Efficient Multimodal Multi-Task Learning for Advanced Assistive Driving|TEM^3-学习：高效时间多模态多任务学习用于高级辅助驾驶|Wenzhuo Liu, Yicheng Qiao, Zhen Wang, Qiannan Guo, Zilong Chen, Meihua Zhou, Xinran Li, Letian Wang .etc.|<http://arxiv.org/pdf/2506.18084v1>|[代码](https://github.com/Wenzhuo-Liu/TEM3-Learning.); 提出了一种高效的多模态多任务学习框架TEM^3-Learning，通过双阶段架构提升了辅助驾驶系统的...|
|🆕 发布|PP-DocBee2: Improved Baselines with Efficient Data for Multimodal Document Understanding|PP-DocBee2：基于高效数据的多模态文档理解改进基线|Kui Huang, Xinrong Chen, Wenyu Lv, Jincheng Liao, Guanzhong Wang, Yi Liu|<http://arxiv.org/pdf/2506.18023v1>|[代码](https://github.com/PaddlePaddle/PaddleMIX); PP-DocBee2通过优化数据质量和特征融合策略，提升了文档理解性能并减少了推理延迟。|
|🆕 发布|LLM-Enhanced Multimodal Fusion for Cross-Domain Sequential Recommendation|跨域序列推荐的长语言模型增强的多模态融合|Wangyu Wu, Zhenhong Chen, Xianglin Qiu, Siqi Song, Xiaowei Huang, Fei Ma, Jimin Xiao|<http://arxiv.org/pdf/2506.17966v1>|融合大语言模型知识，提出LLM-EMF方法，通过视觉与文本数据融合提升跨域序列推荐性能。|
|📝 更新|Stream-Omni: Simultaneous Multimodal Interactions with Large Language-Vision-Speech Model|流-全模态：与大型语言-视觉-语音模型的同步多模态交互|Shaolei Zhang, Shoutao Guo, Qingkai Fang, Yan Zhou, Yang Feng|<http://arxiv.org/pdf/2506.13642v2>|提出了一种新型多模态模型Stream-Omni，通过层维度映射实现更高效灵活的模态对齐，减少数据需求...|
|📝 更新|G3Flow: Generative 3D Semantic Flow for Pose-aware and Generalizable Object Manipulation|生成三维语义流G3Flow：用于姿态感知和泛化对象操作|Tianxing Chen, Yao Mu, Zhixuan Liang, Zanxin Chen, Shijia Peng, Qiangyu Chen, Mingkun Xu, Ruizhen Hu .etc.|<http://arxiv.org/pdf/2411.18369v3>|提出G3Flow框架，通过结合3D生成模型和视觉基础模型，实现了实时动态的语义流，显著提升了机器人操...|
|📝 更新|How Visual Representations Map to Language Feature Space in Multimodal LLMs|多模态大型语言模型中视觉表征映射到语言特征空间的研究|Constantin Venhoff, Ashkan Khakzar, Sonia Joseph, Philip Torr, Neel Nanda|<http://arxiv.org/pdf/2506.11976v2>|揭示了视觉表示如何通过线性适配器直接映射到大型语言模型的语言特征空间，避免了模型对视觉数据的适应。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ShareGPT-4o-Image: Aligning Multimodal Models with GPT-4o-Level Image Generation|《ShareGPT-4o-Image：将多模态模型与GPT-4o级别图像生成对齐》|Junying Chen, Zhenyang Cai, Pengcheng Chen, Shunian Chen, Ke Ji, Xidong Wang, Yunjin Yang, Benyou Wang|<http://arxiv.org/pdf/2506.18095v1>|提出了ShareGPT-4o-Image数据集和Janus-4o模型，实现了开放访问的文本到图像生成...|
|🆕 发布|CLGRPO: Reasoning Ability Enhancement for Small VLMs|CLGRPO：小型语言模型推理能力增强|Fanyi Wang, Binzhi Dong, Haotian Hu, Jinjin Xu, Zhiwang Zhang|<http://arxiv.org/pdf/2506.18048v1>|提出增量训练策略CLGRPO，显著增强小规模视觉语言模型的推理能力。|
|🆕 发布|On the Robustness of Human-Object Interaction Detection against Distribution Shift|《针对分布偏移下的人-物交互检测鲁棒性研究》|Chi Xie, Shuang Liang, Jie Li, Feng Zhu, Rui Zhao, Yichen Wei, Shengjie Zhao|<http://arxiv.org/pdf/2506.18021v1>|提出首个针对人-物交互检测的鲁棒性评估基准，并提出了增强模型鲁棒性的新策略。|
|📝 更新|Leveraging Foundation Models for Content-Based Image Retrieval in Radiology|利用基础模型进行放射学基于内容的图像检索|Stefan Denner, David Zimmerer, Dimitrios Bounias, Markus Bujotzek, Shuhan Xiao, Raphael Stock, Lisa Kausch, Philipp Schader .etc.|<http://arxiv.org/pdf/2403.06567v4>|[代码](https://github.com/MIC-DKFZ/foundation-models-for-cbmir.); 利用基础视觉模型作为即插即用的特征提取器，提升了医学影像内容检索的通用性和效率。|
|📝 更新|Leveraging Model Guidance to Extract Training Data from Personalized Diffusion Models|利用模型指导从个性化扩散模型中提取训练数据|Xiaoyu Wu, Jiaru Zhang, Zhiwei Steven Wu|<http://arxiv.org/pdf/2410.03039v2>|[代码](https://github.com/Nicholas0228/FineXtract.); 提出了一种 FineXtract 框架，通过模型引导从微调后的扩散模型中提取训练数据，验证了数据泄露...|
|🆕 发布|SurgVidLM: Towards Multi-grained Surgical Video Understanding with Large Language Model|面向多粒度手术视频理解的大语言模型：SurgVidLM|Guankun Wang, Wenjin Mo, Junyi Wang, Long Bai, Kun Yuan, Ming Hu, Jinlin Wu, Junjun He .etc.|<http://arxiv.org/pdf/2506.17873v1>|提出SurgVidLM模型，通过StageFocus机制和Multi-frequency Fusio...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Transformer-based RGB-T Tracking with Channel and Spatial Feature Fusion|基于Transformer的RGB-T跟踪：通道与空间特征融合|Yunfeng Li, Bo Wang, Ye Li|<http://arxiv.org/pdf/2405.03177v3>|[代码](https://github.com/LiYunfengLYF/CSTNet.); 提出了一种融合通道与空间特征的Transformer-based RGB-T跟踪方法，提升了跨模态图...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GmNet: Revisiting Gating Mechanisms From A Frequency View|GmNet：从频率视角重新审视门控机制|Yifan Wang, Xu Ma, Yitian Zhang, Zhongruo Wang, Sung-Cheol Kim, Vahid Mirjalili, Vidya Renganathan, Yun Fu|<http://arxiv.org/pdf/2503.22841v2>|从频率视角分析并改进了门控机制，提出GmNet模型，有效平衡了轻量级模型中的低频偏差与性能。|
|🆕 发布|Unfolding the Past: A Comprehensive Deep Learning Approach to Analyzing Incunabula Pages|展开过去：一种全面深度学习方法分析古腾堡时代印刷品页面|Klaudia Ropel, Krzysztof Kutt, Luiz do Valle Miranda, Grzegorz J. Nalepa|<http://arxiv.org/pdf/2506.18069v1>|提出了一种深度学习方法，自动分析古书页面结构内容，实现了高精度识别与分类。|
|🆕 发布|Classification of Tents in Street Bazaars Using CNN|使用卷积神经网络对街头市集中的帐篷进行分类|Azamat Ibragimov, Ruslan Isaev, Remudin Reshid Mekuria, Gulnaz Gimaletdinova, Dim Shaiakhmetov|<http://arxiv.org/pdf/2506.17946v1>|提出了一种基于深度学习的街市帐篷分类方法，通过自定义CNN和EfficientNetB0模型，大幅提...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HGO-YOLO: Advancing Anomaly Behavior Detection with Hierarchical Features and Lightweight Optimized Detection|HGO-YOLO：利用分层特征与轻量优化检测推进异常行为检测|Qizhi Zheng, Zhongze Luo, Meiyan Guo, Xinzhu Wang, Renqimuge Wu, Qiu Meng, Guanghui Dong|<http://arxiv.org/pdf/2503.07371v2>|提出轻量级检测器HGO-YOLO，融合多尺度特征和优化检测头，实现高效异常行为监测。|
|📝 更新|Towards Reflected Object Detection: A Benchmark|面向反射对象检测：一个基准|Yiquan Wu, Zhongtian Wang, You Wu, Ling Huang, Hui Zhou, Shuiwang Li|<http://arxiv.org/pdf/2407.05575v2>|[代码](https://github.com/jirouvan/ROD.); 提出反射物检测基准RODD，助力准确识别日常环境中的反射物体。|
|📝 更新|Efficient Feature Aggregation and Scale-Aware Regression for Monocular 3D Object Detection|单目3D目标检测中的高效特征聚合与尺度感知回归|Yifan Wang, Xiaochen Yang, Fanqi Pu, Qingmin Liao, Wenming Yang|<http://arxiv.org/pdf/2411.02747v2>|提出了一种高效的特征聚合和尺度感知回归框架，有效提升了单目3D物体检测的准确性和小物体检测能力。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MiCo: Multiple Instance Learning with Context-Aware Clustering for Whole Slide Image Analysis|MiCo：基于上下文感知聚类的多实例学习，用于全切片图像分析|Junjian Li, Hulin Kuang, Jin Liu, Hailin Yue, Mengshen He, Jianxin Wang|<http://arxiv.org/pdf/2506.18028v1>|[代码](https://github.com/junjianli106/MiCo.); 提出了一种结合上下文聚类的新型多实例学习方法MiCo，有效提升了病理切片中跨区域组织关联的建模能力。|
|📝 更新|A Robust Real-Time Lane Detection Method with Fog-Enhanced Feature Fusion for Foggy Conditions|雾天条件下的鲁棒实时车道检测方法：基于雾增强特征融合|Ronghui Zhang, Yuhang Ma, Tengfei Li, Ziyu Lin, Yueying Wu, Junzhou Chen, Lin Zhang, Jia Hu .etc.|<http://arxiv.org/pdf/2504.06121v6>|提出了针对雾天环境的高效车道检测方法，通过特征融合网络显著提升了雾天条件下的检测性能和实时性。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation|三维关系增强：提升点云实例分割中的关系建模|Jiahao Lu, Jiacheng Deng|<http://arxiv.org/pdf/2506.17891v1>|定位了现有3D实例分割方法中关系建模的不足，提出自适应聚合与对比学习模块增强特征表示，并引入关系感知...|
|🆕 发布|Cross-modal State Space Modeling for Real-time RGB-thermal Wild Scene Semantic Segmentation|跨模态状态空间建模用于实时 RGB-热成像野外场景语义分割|Xiaodong Guo, Zi'ang Lin, Luwen Hu, Zhihong Deng, Tong Liu, Wujie Zhou|<http://arxiv.org/pdf/2506.17869v1>|[代码](https://github.com/xiaodonguo/CMSSM.); 提出了一种高效的RGB-热成像语义分割架构，通过跨模态状态空间建模降低计算负担并提升性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|One-Step is Enough: Sparse Autoencoders for Text-to-Image Diffusion Models|一步足矣：文本到图像扩散模型中的稀疏自动编码器|Viacheslav Surkov, Chris Wendler, Antonio Mari, Mikhail Terekhov, Justin Deschenaux, Robert West, Caglar Gulcehre, David Bau|<http://arxiv.org/pdf/2410.22366v4>|探究了稀疏自动编码器在文本到图像扩散模型中学习可解释特征的可能性，并证明了其有效性。|
|🆕 发布|CDG-MAE: Learning Correspondences from Diffusion Generated Views|CDG-MAE：从扩散生成视角学习对应关系|Varun Belagali, Pierre Marza, Srikar Yellapragada, Zilinghan Li, Tarak Nath Nandi, Ravi K Madduri, Joel Saltz, Stergios Christodoulidis .etc.|<http://arxiv.org/pdf/2506.18164v1>|提出了一种利用图像条件扩散模型生成多视角训练数据的方法CDG-MAE，有效提升自监督学习性能。|
|🆕 发布|Targeted False Positive Synthesis via Detector-guided Adversarial Diffusion Attacker for Robust Polyp Detection|通过检测器引导的对抗性扩散攻击进行目标假阳性合成，以实现稳健的息肉检测|Quan Zhou, Gan Luo, Qiang Hu, Qingyong Zhang, Jinhua Zhang, Yinjiao Tian, Qiang Li, Zhiwei Wang|<http://arxiv.org/pdf/2506.18134v1>|[代码](https://github.com/Huster-Hq/DADA.); 提出了一种利用检测器引导的对抗性扩散攻击框架，有效合成高价值假阳性，以增强结直肠癌筛查中息肉检测的可...|
|📝 更新|Exploring Diffusion with Test-Time Training on Efficient Image Restoration|探索在测试时训练中扩散算法的高效图像恢复|Rongchang Lu, Tianduo Luo, Yunzhi Jiang, Conghan Yue, Pei Yang, Guibao Liu, Changyang Gu|<http://arxiv.org/pdf/2506.14541v2>|提出DiffRWKVIR框架，融合测试时训练与高效扩散，优化了图像恢复的效率和效果。|
|📝 更新|EDA-DM: Enhanced Distribution Alignment for Post-Training Quantization of Diffusion Models|EDA-DM：增强分布对齐用于扩散模型训练后的量化|Xuewen Liu, Zhikai Li, Junrui Xiao, Mengjuan Chen, Jianquan Li, Qingyi Gu|<http://arxiv.org/pdf/2401.04585v3>|[代码](http://github.com/BienLuky/EDA-DM); 提出了一种标准化后训练量化方法EDA-DM，有效解决了扩散模型量化中的分布不匹配问题，实现显著的速度...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Human Action CLIPs: Detecting AI-generated Human Motion|人类动作CLIPs：检测AI生成的人类运动|Matyas Bohacek, Hany Farid|<http://arxiv.org/pdf/2412.00526v2>|提出了一种区分真实与AI生成人类动作的新技术，有效抵御分辨率和压缩攻击。|
|📝 更新|MM-R5: MultiModal Reasoning-Enhanced ReRanker via Reinforcement Learning for Document Retrieval|多模态推理增强的重排器：通过强化学习进行文档检索的MM-R5|Mingjun Xu, Jinhan Dong, Jue Hou, Zehui Wang, Sihang Li, Zhifeng Gao, Renxin Zhong, Hengxing Cai|<http://arxiv.org/pdf/2506.12364v2>|[代码](https://github.com/i2vec/MM-R5); 提出了一种基于强化学习的多模态推理增强重排方法MM-R5，显著提升了文档检索的准确性和可靠性。|
|🆕 发布|BPCLIP: A Bottom-up Image Quality Assessment from Distortion to Semantics Based on CLIP|BPCLIP：基于CLIP的自下而上从失真到语义的图像质量评估方法|Chenyue Song, Chen Hui, Wei Zhang, Haiqi Zhu, Shaohui Liu, Hong Huang, Feng Jiang|<http://arxiv.org/pdf/2506.17969v1>|提出了一种基于CLIP的图像质量评估方法BPCLIP，通过逐步提取低级失真对高级语义的影响，提高了评...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation|RoboTwin 2.0：一种具有强域随机化的可扩展数据生成器和用于稳健双臂机器人操作的性能基准|Tianxing Chen, Zanxin Chen, Baijun Chen, Zijian Cai, Yibin Liu, Qiwei Liang, Zixuan Li, Xianliang Lin .etc.|<http://arxiv.org/pdf/2506.18088v1>|提出RoboTwin 2.0，通过大规模数据生成和域随机化提升双臂机器人操作鲁棒性。|
|🆕 发布|Deep Supervised LSTM for 3D morphology estimation from Multi-View RGB Images of Wheat Spikes|深度监督长短期记忆网络在基于多视角RGB图像的小麦穗三维形态估计中的应用|Olivia Zumsteg, Nico Graf, Aaron Haeusler, Norbert Kirchgessner, Nicola Storni, Lukas Roth, Andreas Hund|<http://arxiv.org/pdf/2506.18060v1>|提出了一种结合自监督Vision Transformer和LSTM的深度监督网络，用于从多视角RGB...|
|📝 更新|SurgSora: Object-Aware Diffusion Model for Controllable Surgical Video Generation|“SurgSora：面向可控手术视频生成的对象感知扩散模型”|Tong Chen, Shuya Yang, Junyi Wang, Long Bai, Hongliang Ren, Luping Zhou|<http://arxiv.org/pdf/2412.14018v3>|[代码](https://surgsora.github.io/surgsora.github.io.); 提出SurgSora框架，通过单帧输入和用户指定运动线索生成高质量、可控运动的手术视频。|
|🆕 发布|PlanMoGPT: Flow-Enhanced Progressive Planning for Text to Motion Synthesis|《PlanMoGPT：基于流增强的文本到动作合成的渐进规划方法》|Chuhao Jin, Haosen Li, Bingzi Zhang, Che Liu, Xiting Wang, Ruihua Song, Wenbing Huang, Ying Qin .etc.|<http://arxiv.org/pdf/2506.17912v1>|提出PlanMoGPT框架，融合渐进规划和增强细节的符号化，解决文本到动作生成中的细节与全局语义平衡...|
|📝 更新|How Far is Video Generation from World Model: A Physical Law Perspective|视频生成距离世界模型有多远：从物理定律视角出发|Bingyi Kang, Yang Yue, Rui Lu, Zhijie Lin, Yang Zhao, Kaixin Wang, Gao Huang, Jiashi Feng|<http://arxiv.org/pdf/2411.02385v2>|探讨了视频生成模型在发现物理定律方面的局限性，发现仅靠规模扩展不足以实现物理定律的准确学习和泛化。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhancing VICReg: Random-Walk Pairing for Improved Generalization and Better Global Semantics Capturing|增强VICReg：随机游走配对以提高泛化能力和更好的全局语义捕捉|Idan Simai, Ronen Talmon, Uri Shaham|<http://arxiv.org/pdf/2506.18104v1>|提出SAG-VICReg方法，通过随机游走配对增强自监督学习的泛化能力和全局语义捕捉。|
|🆕 发布|Auto-Regressive Surface Cutting|自回归表面切割|Yang Li, Victor Cheung, Xinhai Liu, Yuguang Chen, Zhongjin Luo, Biwen Lei, Haohan Weng, Zibo Zhao .etc.|<http://arxiv.org/pdf/2506.18017v1>|提出了一种基于GPT风格的自动回归模型 SeamGPT，通过模仿专业工作流程生成切割缝隙，显著提升了...|
|🆕 发布|EgoWorld: Translating Exocentric View to Egocentric View using Rich Exocentric Observations|自我世界：利用丰富的外心视角观测将外心视图转换为自我视图|Junho Park, Andrew Sangwoo Ye, Taein Kwon|<http://arxiv.org/pdf/2506.17896v1>|提出EgoWorld框架，通过融合多源信息将第三人称视角转换为第一人称视角，提升AR/VR及机器人应...|
|📝 更新|DriveSuprim: Towards Precise Trajectory Selection for End-to-End Planning|端到端规划中的精确轨迹选择方法：DriveSuprim|Wenhao Yao, Zhenxin Li, Shiyi Lan, Zi Wang, Xinglong Sun, Jose M. Alvarez, Zuxuan Wu|<http://arxiv.org/pdf/2506.06659v2>|提出了一种精确选择车辆轨迹的 coarse-to-fine 方法，通过旋转增强和自蒸馏训练，提高了自...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Limitations of NERF with pre-trained Vision Features for Few-Shot 3D Reconstruction|“预训练视觉特征NERF在少量样本三维重建中的局限性”|Ankit Sanjyal|<http://arxiv.org/pdf/2506.18208v1>|发现预训练视觉特征可能对少量样本3D重建无益，建议关注几何一致性的简单架构。|
|🆕 发布|STACT-Time: Spatio-Temporal Cross Attention for Cine Thyroid Ultrasound Time Series Classification|STACT-时间：用于电影甲状腺超声时间序列分类的时空交叉注意力|Irsyad Adam, Tengyue Zhang, Shrayes Raman, Zhuyu Qiu, Brandon Taraku, Hexiang Feng, Sile Wang, Ashwath Radhachandran .etc.|<http://arxiv.org/pdf/2506.18172v1>|提出STACT-Time模型，融合超声影像时空信息，提高甲状腺结节恶性预测精度。|
|📝 更新|Discrete JEPA: Learning Discrete Token Representations without Reconstruction|离散JEPA：无重建学习离散标记表示|Junyeob Baek, Hosung Lee, Christopher Hoang, Mengye Ren, Sungjin Ahn|<http://arxiv.org/pdf/2506.14373v2>|提出Discrete-JEPA方法，通过语义符号化改进图像表示，增强符号推理能力。|
|📝 更新|Layered Motion Fusion: Lifting Motion Segmentation to 3D in Egocentric Videos|分层运动融合：将运动分割提升至三维空间的第一人称视频处理|Vadim Tschernezki, Diane Larlus, Iro Laina, Andrea Vedaldi|<http://arxiv.org/pdf/2506.05546v2>|提出Layered Motion Fusion方法，将2D运动分割预测融合到3D模型中，显著提升动态...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multimodal Fusion SLAM with Fourier Attention|多模态融合SLAM的傅里叶注意力方法|Youjie Zhou, Guofeng Mei, Yiming Wang, Yi Wan, Fabio Poiesi|<http://arxiv.org/pdf/2506.18204v1>|[代码](https://github.com/youjie-zhou/FMF-SLAM.git.); 提出了一种高效的傅里叶注意力多模态融合SLAM方法，提升暗光和多变光照下的定位与建图性能。|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Pattern-Based Phase-Separation of Tracer and Dispersed Phase Particles in Two-Phase Defocusing Particle Tracking Velocimetry|基于模式分离的两相去焦粒子跟踪测速技术中示踪剂和分散相粒子的相分离|Christian Sax, Jochen Kriegseis|<http://arxiv.org/pdf/2506.18157v1>|提出了一种基于卷积神经网络和生成对抗网络的相位分离方法，实现了对两相流中示踪粒子和分散相粒子的精确识...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Adapting Vision-Language Models for Evaluating World Models|适应视觉-语言模型以评估世界模型|Mariya Hendriksen, Tabish Rashid, David Bignell, Raluca Georgescu, Abdelhak Lemkhenter, Katja Hofmann, Sam Devlin, Sarah Parisot|<http://arxiv.org/pdf/2506.17967v1>|提出了一种适应性的视觉语言模型UNIVERSE，用于精确评估世界模型的生成效果。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Cloud-Aware SAR Fusion for Enhanced Optical Sensing in Space Missions|云感知合成孔径雷达融合以提高空间任务中光学传感性能|Trong-An Bui, Thanh-Thoai Le|<http://arxiv.org/pdf/2506.17885v1>|提出了一种云感知的合成孔径雷达与光学数据融合框架，通过深度学习生成无云光学图像，提高了图像重建质量。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Chain-of-Memory: Enhancing GUI Agents for Cross-Application Navigation|“链式记忆：增强跨应用程序导航的图形用户界面代理”|Xinzge Gao, Chuanrui Hu, Bin Chen, Teng Li|<http://arxiv.org/pdf/2506.18158v1>|提出Chain-of-Memory方法，增强GUI代理在跨应用导航中的记忆能力，显著提升任务理解和历...|
|🆕 发布|Mobile Image Analysis Application for Mantoux Skin Test|移动图像分析应用：用于曼陀罗皮肤试验|Liong Gele, Tan Chye Cheah|<http://arxiv.org/pdf/2506.17954v1>|提出了一种利用ARCore和深度学习算法的移动应用，自动化测量 Mantoux 皮肤试验结果，提高了...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Cross from Left to Right Brain: Adaptive Text Dreamer for Vision-and-Language Navigation|从左脑到右脑的跨越：面向视觉与语言导航的自适应文本梦想者|Pingrui Zhang, Yifei Su, Pengyuan Wu, Dong An, Li Zhang, Zhigang Wang, Dong Wang, Yan Ding .etc.|<http://arxiv.org/pdf/2505.20897v2>|[代码](https://github.com/zhangpingrui/Adaptive-Text-Dreamer); 提出了一种基于大语言模型的适应性文本想象策略，有效提升了视觉与语言导航的效率和准确性。|
|🆕 发布|Fast Neural Inverse Kinematics on Human Body Motions|人体运动快速神经逆运动学|David Tolpin, Sefy Kagarlitsky|<http://arxiv.org/pdf/2506.17996v1>|提出了一种快速可靠的神经逆运动学框架，实现了实时捕捉人体运动，解决了计算需求高和推理速度慢的问题。|
|📝 更新|Training A Neural Network For Partially Occluded Road Sign Identification In The Context Of Autonomous Vehicles|在自动驾驶环境下针对部分遮挡交通标志识别的神经网络训练|Gulnaz Gimaletdinova, Dim Shaiakhmetov, Madina Akpaeva, Mukhammadmuso Abduzhabbarov, Kadyrmamat Momunov|<http://arxiv.org/pdf/2503.18177v2>|提出了一种专门训练的卷积神经网络，有效识别部分遮挡的路标，提高了自动驾驶的安全性。|
|🆕 发布|IDAL: Improved Domain Adaptive Learning for Natural Images Dataset|IDAL：改进的自然图像数据集领域自适应学习|Ravi Kant Gupta, Shounak Das, Amit Sethi|<http://arxiv.org/pdf/2506.17931v1>|提出了一种改进的无监督域自适应学习框架，通过结合特有损失函数和深度网络结构，有效应对自然图像域自适应...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|StainPIDR: A Pathological Image Decouplingand Reconstruction Method for StainNormalization Based on Color VectorQuantization and Structure Restaining|基于颜色向量量化与结构保持的病理图像解耦重建方法：用于染料归一化的StainPIDR|Zheng Chen|<http://arxiv.org/pdf/2506.17879v1>|提出了一种基于颜色向量量化和结构保持的病理图像去耦与重建方法，有效实现了染色归一化。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FLARE: Toward Universal Dataset Purification against Backdoor Attacks|FLARE：面向后门攻击的通用数据集净化方法|Linshan Hou, Wei Luo, Zhongyun Hua, Songhua Chen, Leo Yu Zhang, Yiming Li|<http://arxiv.org/pdf/2411.19479v3>|[代码](https://github.com/THUYimingLi/BackdoorBox); 提出了一种名为FLARE的通用数据集净化方法，有效对抗多种后门攻击，通过聚合不同隐藏层的异常激活来识...|
|📝 更新|PotatoGANs: Utilizing Generative Adversarial Networks, Instance Segmentation, and Explainable AI for Enhanced Potato Disease Identification and Classification|土豆生成对抗网络：利用生成对抗网络、实例分割与可解释人工智能进行土豆病害识别与分类增强|Fatema Tuj Johora Faria, Mukaffi Bin Moin, Mohammad Shafiul Alam, Ahmed Al Wase, Md. Rabius Sani, Khan Md Hasib|<http://arxiv.org/pdf/2405.07332v2>|提出PotatoGANs方法，利用GAN生成多样化合成图像，增强土豆病害识别与分类模型的泛化能力。|
|🆕 发布|DRO-Augment Framework: Robustness by Synergizing Wasserstein Distributionally Robust Optimization and Data Augmentation|DRO-Augment框架：通过融合Wasserstein分布鲁棒优化与数据增强提升鲁棒性|Jiaming Hu, Debarghya Mukherjee, Ioannis Ch. Paschalidis|<http://arxiv.org/pdf/2506.17874v1>|整合Wasserstein分布鲁棒优化与数据增强，提出DRO-Augment框架，大幅提升模型在各种...|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Decoding Federated Learning: The FedNAM+ Conformal Revolution|解码联邦学习：FedNAM+符合革命|Sree Bhargavi Balija, Amitash Nanda, Debashis Sahoo|<http://arxiv.org/pdf/2506.17872v1>|提出FedNAM+框架，结合神经加性模型与新型 conformal 预测，实现联邦学习中的可解释性和...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DExNet: Combining Observations of Domain Adapted Critics for Leaf Disease Classification with Limited Data|DExNet：结合领域适应评判者的观测数据进行叶部病害分类，在数据有限的情况下|Sabbir Ahmed, Md. Bakhtiar Hasan, Tasnim Ahmed, Md. Hasanul Kabir|<http://arxiv.org/pdf/2506.18173v1>|提出了一种针对少量数据下植物病害分类的DExNet框架，通过融合多个预训练网络的观测来补偿数据不足。|
|🆕 发布|Deciphering Emotions in Children Storybooks: A Comparative Analysis of Multimodal LLMs in Educational Applications|解读儿童故事书中的情感：教育应用中多模态大型语言模型的比较分析|Bushra Asseri, Estabraq Abdelaziz, Maha Al Mogren, Tayef Alhefdhi, Areej Al-Wabil|<http://arxiv.org/pdf/2506.18201v1>|评估了两种先进的多模态大语言模型在阿拉伯儿童故事书插图情感识别中的表现，强调了文化敏感训练方法的重要...|
|🆕 发布|BeltCrack: the First Sequential-image Industrial Conveyor Belt Crack Detection Dataset and Its Baseline with Triple-domain Feature Learning|“BeltCrack：首个基于序列图像的工业输送带裂纹检测数据集及其三域特征学习基线”|Jianghong Huang, Luping Ji, Xin Ma, Mao Ye|<http://arxiv.org/pdf/2506.17892v1>|[代码](https://github.com/UESTC-nnLab/BeltCrack.); 构建首个真实工业皮带裂纹序列图像数据集并提出三域特征融合学习方法。|
|📝 更新|Navigating Conflicting Views: Harnessing Trust for Learning|《导航冲突视角：利用信任进行学习》|Jueqing Lu, Wray Buntine, Yuanyuan Qi, Joanna Dipnall, Belinda Gabbe, Lan Du|<http://arxiv.org/pdf/2406.00958v4>|[代码](https://github.com/OverfitFlow/Trust4Conflict); 提出了一种基于信任度的多视角分类冲突解决方法，提高了模型在现实世界应用中的可靠性。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MUPA: Towards Multi-Path Agentic Reasoning for Grounded Video Question Answering|MUPA：面向地面视频问答的多路径代理推理|Jisheng Dang, Huilin Song, Junbin Xiao, Bimei Wang, Han Peng, Haoxuan Li, Xun Yang, Meng Wang .etc.|<http://arxiv.org/pdf/2506.18071v1>|[代码](https://github.com/longmalongma/MUPA.); 提出MUPA方法，通过多路径协同推理显著提升视频问答的接地性和准确性。|
|🆕 发布|Cause-Effect Driven Optimization for Robust Medical Visual Question Answering with Language Biases|基于因果驱动的优化以实现具有语言偏好的鲁棒医疗视觉问答|Huanjia Zhu, Yishu Liu, Xiaozhao Fang, Guangming Lu, Bingzhi Chen|<http://arxiv.org/pdf/2506.17903v1>|提出CEDO框架，通过多模态优化和损失重缩放减轻医学视觉问答中的语言偏见问题。|
|🆕 发布|PostAlign: Multimodal Grounding as a Corrective Lens for MLLMs|后对齐：多模态基础作为大型语言模型修正透镜|Yixuan Wu, Yang Zhang, Jian Wu, Philip Torr, Jindong Gu|<http://arxiv.org/pdf/2506.17901v1>|提出了一种后模态对齐框架MMGrounded-PostAlign，通过视觉和文本联合定位增强大型多模...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Hallucination-Aware Multimodal Benchmark for Gastrointestinal Image Analysis with Large Vision-Language Models|胃肠图像分析的大视觉-语言模型幻觉感知多模态基准|Bidur Khanal, Sandesh Pokhrel, Sanjay Bhandari, Ramesh Rana, Nikesh Shrestha, Ram Bahadur Gurung, Cristian Linte, Angus Watson .etc.|<http://arxiv.org/pdf/2505.07001v2>|[代码](https://github.com/bhattarailab/Hallucination-Aware-VLM.); 提出hallucination-aware finetuning方法，通过检测和纠正错误描述，提升医...|
|🆕 发布|Pitfalls of Conformal Predictions for Medical Image Classification|《医学图像分类中符合预测的陷阱》|Hendrik Mehrtens, Tabea Bucher, Titus J. Brinker|<http://arxiv.org/pdf/2506.18162v1>|揭示了在医学图像分类中，基于置信度的预测方法在输入数据分布变化时存在可靠性问题。|
|🆕 发布|See-in-Pairs: Reference Image-Guided Comparative Vision-Language Models for Medical Diagnosis|“See-in-Pairs：基于参考图像引导的比较性视觉-语言模型在医学诊断中的应用”|Ruinan Jin, Gexin Huang, Xinwei Shen, Qiong Zhang, Yan Shuo Tan, Xiaoxiao Li|<http://arxiv.org/pdf/2506.18140v1>|提出了一种参考图像引导的比较性视觉语言模型，通过引入临床比较分析显著提升了医学影像诊断的准确性。|
|📝 更新|UniDrive: Towards Universal Driving Perception Across Camera Configurations|"UniDrive：面向跨摄像头配置的通用驾驶感知"|Ye Li, Wenzhao Zheng, Xiaonan Huang, Kurt Keutzer|<http://arxiv.org/pdf/2410.13864v2>|提出UniDrive框架，通过虚拟相机投影优化，实现不同相机配置下的通用驾驶感知。|
|🆕 发布|Training-free Test-time Improvement for Explainable Medical Image Classification|无训练的测试时改进用于可解释的医疗图像分类|Hangzhou He, Jiachen Tang, Lei Zhu, Kaiwen Li, Yanye Lu|<http://arxiv.org/pdf/2506.18070v1>|[代码](https://github.com/riverback/TF-TTI-XMed.); 提出了一种无需训练的医学图像分类测试时改进策略，通过少量新数据增强模型跨领域性能。|
|🆕 发布|Multimodal Medical Image Binding via Shared Text Embeddings|通过共享文本嵌入实现多模态医学图像绑定|Yunhao Liu, Suyang Xi, Shiqi Liu, Hong Ding, Chicheng Jin, Chenxi Yang, Junjun He, Yiqing Shen|<http://arxiv.org/pdf/2506.18072v1>|提出了一种无需明确配对数据即可实现多模态医学图像对齐的新预训练框架M\textsuperscript...|
|🆕 发布|CmFNet: Cross-modal Fusion Network for Weakly-supervised Segmentation of Medical Images|跨模态融合网络CmFNet：用于弱监督医学图像分割|Dongdong Meng, Sheng Li, Hao Wu, Suqing Tian, Wenjun Ma, Guoping Wang, Xueqing Yan|<http://arxiv.org/pdf/2506.18042v1>|提出CmFNet，一种3D弱监督跨模态医疗图像分割方法，通过融合多模态信息提升性能并减少过拟合。|
|🆕 发布|Pre-Trained LLM is a Semantic-Aware and Generalizable Segmentation Booster|预训练语言模型是具有语义感知和泛化能力的分割增强器|Fenghe Tang, Wenxin Ma, Zhiyang He, Xiaodong Tao, Zihang Jiang, S. Kevin Zhou|<http://arxiv.org/pdf/2506.18034v1>|集成预训练语言模型层提升医学图像分割性能，实现语义感知与泛化增强。|
|🆕 发布|LVPNet: A Latent-variable-based Prediction-driven End-to-end Framework for Lossless Compression of Medical Images|LVPNet：一种基于潜在变量预测驱动的端到端框架，用于医学图像的无损压缩|Chenyue Song, Chen Hui, Qing Lin, Wei Zhang, Siqiao Li, Shengping Zhang, Haiqi Zhu, Zhixuan Li .etc.|<http://arxiv.org/pdf/2506.17983v1>|[代码](https://github.com/Anonymity00000/Anonymity-repository); 提出了一种基于全局变量预测的医学图像无损压缩方法LVPNet，通过提取紧凑的潜在表示和补偿量化损失，...|
|🆕 发布|Enabling PSO-Secure Synthetic Data Sharing Using Diversity-Aware Diffusion Models|利用多样性感知扩散模型的PSO安全合成数据共享|Mischa Dombrowski, Bernhard Kainz|<http://arxiv.org/pdf/2506.17975v1>|[代码](https://github.com/MischaD/Trichotomy.); 提出了一种保护隐私的合成数据共享框架，通过增强多样性确保数据不被特定个体识别，同时保持与真实数据相近...|
|📝 更新|DART: An Automated End-to-End Object Detection Pipeline with Data Diversification, Open-Vocabulary Bounding Box Annotation, Pseudo-Label Review, and Model Training|DART：一种集数据多样化、开放词汇边界框标注、伪标签审查和模型训练于一体的自动化端到端目标检测管道|Chen Xin, Andreas Hartel, Enkelejda Kasneci|<http://arxiv.org/pdf/2407.09174v4>|[代码](https://github.com/chen-xin-94/DART.); 提出了一种自动化的端到端目标检测流程DART，通过数据多样化、开放式标注、伪标签审核和模型训练，无需...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Visual Prompt Engineering for Vision Language Models in Radiology|放射学中视觉提示工程在视觉语言模型中的应用|Stefan Denner, Markus Bujotzek, Dimitrios Bounias, David Zimmerer, Raphael Stock, Klaus Maier-Hein|<http://arxiv.org/pdf/2408.15802v3>|[代码](https://github.com/MIC-DKFZ/VPE-in-Radiology); 提出利用视觉标记增强零样本分类，提升医学图像诊断准确性和可解释性。|
|🆕 发布|GEMeX-ThinkVG: Towards Thinking with Visual Grounding in Medical VQA via Reinforcement Learning|GEMeX-ThinkVG：通过强化学习实现医学视觉问答中的视觉定位思考|Bo Liu, Xiangyu Zhao, Along He, Yidi Chen, Huazhu Fu, Xiao-Ming Wu|<http://arxiv.org/pdf/2506.17939v1>|提出了一种基于视觉定位的医疗图像问答方法，通过分解推理步骤增强解释性并提高模型效率。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OSDMamba: Enhancing Oil Spill Detection from Remote Sensing Images Using Selective State Space Model|OSDMamba：利用选择性状态空间模型增强遥感图像中的油污检测|Shuaiyu Chen, Fu Wang, Peng Ren, Chunbo Luo, Zeyu Fu|<http://arxiv.org/pdf/2506.18006v1>|提出OSDMamba模型，利用状态空间模型提升遥感图像油污检测准确性和对小面积油污的识别能力。|
|🆕 发布|ELMAR: Enhancing LiDAR Detection with 4D Radar Motion Awareness and Cross-modal Uncertainty|ELMAR：利用4D雷达运动感知与跨模态不确定性增强LiDAR检测|Xiangyuan Peng, Miao Tang, Huawei Sun, Bierzynski Kay, Lorenzo Servadei, Robert Wille|<http://arxiv.org/pdf/2506.17958v1>|提出了一种融合4D雷达运动状态和跨模态不确定性的LiDAR检测框架，有效解决了不同模态间的对齐问题并...|
|🆕 发布|SegChange-R1:Augmented Reasoning for Remote Sensing Change Detection via Large Language Models|SegChange-R1：通过大型语言模型增强推理进行遥感变化检测|Fei Zhou|<http://arxiv.org/pdf/2506.17944v1>|[代码](https://github.com/Yu-Zhouz/SegChange-R1.); 提出了一种结合大型语言模型的空间变换模块，有效提升了遥感变化检测的准确性和速度。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Feedback Driven Multi Stereo Vision System for Real-Time Event Analysis|基于反馈驱动的多立体视觉系统用于实时事件分析|Mohamed Benkedadra, Matei Mancas, Sidi Ahmed Mahmoudi|<http://arxiv.org/pdf/2506.17910v1>|提出了一种融合多3D相机反馈的立体视觉系统，实现复杂环境下的实时事件分析和自适应学习。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|h-calibration: Rethinking Classifier Recalibration with Probabilistic Error-Bounded Objective|h校准：重新思考以概率误差界为目标的分类器重校准|Wenjian Huang, Guiping Cao, Jiahao Xia, Jingkun Chen, Hao Wang, Jianguo Zhang|<http://arxiv.org/pdf/2506.17968v1>|提出了一种概率学习框架h-calibration，通过有界误差目标实现了分类器校准，克服了传统方法局...|
|🆕 发布|Deep Learning-based Alignment Measurement in Knee Radiographs|基于深度学习的膝关节X射线照片中对齐度测量|Zhisen Hu, Dominic Cullen, Peter Thompson, David Johnson, Chang Bian, Aleksei Tiulpin, Timothy Cootes, Claudia Lindner|<http://arxiv.org/pdf/2506.18209v1>|提出了一种基于深度学习的膝关节对齐度测量方法，实现了高效准确的解剖学测量，提升了临床工作流程的数字化...|
|📝 更新|Holistic White-light Polyp Classification via Alignment-free Dense Distillation of Auxiliary Optical Chromoendoscopy|通过无需对齐的辅助光学染色内镜密集蒸馏实现的全息白光息肉分类|Qiang Hu, Qimei Wang, Jia Chen, Xuantao Ji, Qiang Li, Zhiwei Wang|<http://arxiv.org/pdf/2505.19319v2>|[代码](https://github.com/Huster-Hq/ADD.); 提出了一种无需对齐的全图白光结肠镜息肉分类方法，通过像素级跨域亲和力学习显著提升诊断准确性。|

