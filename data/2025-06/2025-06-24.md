## [UPDATED!] **2025-06-24** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unified Vision-Language-Action Model|统一视觉-语言-动作模型|Yuqi Wang, Xinghang Li, Wenxuan Wang, Junbo Zhang, Yingyan Li, Yuntao Chen, Xinlong Wang, Zhaoxiang Zhang|<http://arxiv.org/pdf/2506.19850v1>|提出UniVLA模型，通过将视觉、语言、动作信号统一建模为离散序列，有效提升机器人操作性能。|
|🆕 发布|SAM2-SGP: Enhancing SAM2 for Medical Image Segmentation via Support-Set Guided Prompting|SAM2-SGP：通过支持集引导提示增强SAM2用于医学图像分割|Yang Xing, Jiong Wu, Yuheng Bu, Kuang Gong|<http://arxiv.org/pdf/2506.19658v1>|[代码](https://github.com/astlian9/SAM_Support.); 提出SAM2-SGP方法，通过支持集引导提示和低秩适应策略，有效提升医学图像分割性能。|
|📝 更新|Cross-sensor self-supervised training and alignment for remote sensing|跨传感器自监督训练与对齐的遥感图像处理方法|Valerio Marsocci, Nicolas Audebert|<http://arxiv.org/pdf/2405.09922v2>|提出跨传感器自监督训练与对齐方法X-STARS，有效提升遥感数据模型在不同传感器间的泛化能力。|
|🆕 发布|SMARTIES: Spectrum-Aware Multi-Sensor Auto-Encoder for Remote Sensing Images|SMARTIES：面向光谱感知的多传感器自动编码器在遥感图像中的应用|Gencer Sumbul, Chang Xu, Emanuele Dalsasso, Devis Tuia|<http://arxiv.org/pdf/2506.19585v1>|[代码](https://gsumbul.github.io/SMARTIES.); 提出了一种通用型基础模型SMARTIES，通过将不同传感器数据投影到共享的频谱感知空间，实现了多传感...|
|🆕 发布|General Methods Make Great Domain-specific Foundation Models: A Case-study on Fetal Ultrasound|泛用方法打造出色的领域特定基础模型：以胎儿超声为例的研究|Jakob Ambsdorf, Asbjørn Munk, Sebastian Llambias, Anders Nymark Christensen, Kamil Mikolaj, Randall Balestriero, Martin Tolsgaard, Aasa Feragen .etc.|<http://arxiv.org/pdf/2506.19552v1>|通过常用计算机视觉方法训练定制基础模型，可提升医学图像处理性能。|
|🆕 发布|MSR-Align: Policy-Grounded Multimodal Alignment for Safety-Aware Reasoning in Vision-Language Models|MSR-Align：基于策略的多模态对齐方法，用于视觉语言模型中的安全感知推理|Yinan Xia, Yilei Jiang, Yingshui Tan, Xiaoyong Zhu, Xiangyu Yue, Bo Zheng|<http://arxiv.org/pdf/2506.19257v1>|提出了MSR-Align数据集，通过标准化安全策略的细粒度多模态推理，增强了视觉语言模型的安全性。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ASR-enhanced Multimodal Representation Learning for Cross-Domain Product Retrieval|跨域产品检索的ASR增强多模态表征学习|Ruixiang Zhao, Jian Jia, Yan Li, Xuehan Bai, Quan Chen, Han Li, Peng Jiang, Xirong Li|<http://arxiv.org/pdf/2408.02978v2>|提出了一种融合自动语音识别和视觉数据的多模态产品表示学习方法，有效提升了跨域产品检索性能。|
|🆕 发布|Genome-Anchored Foundation Model Embeddings Improve Molecular Prediction from Histology Images|基于基因组锚定的基础模型嵌入提升从组织学图像中的分子预测|Cheng Jin, Fengtao Zhou, Yunfang Yu, Jiabo Ma, Yihui Wang, Yingxue Xu, Huajun Zhou, Hao Jiang .etc.|<http://arxiv.org/pdf/2506.19681v1>|提出PathLUPI模型，利用基因组信息训练，通过病理图像预测分子特征，提升癌症分子预测准确性。|
|🆕 发布|Fake or Real, Can Robots Tell? Evaluating Embodied Vision-Language Models on Real and 3D-Printed Objects|“真假难辨，机器人能否分辨？评估具身视觉语言模型在真实与3D打印物体上的表现”|Federico Tavella, Kathryn Mearns, Angelo Cangelosi|<http://arxiv.org/pdf/2506.19579v1>|评估了机器人场景理解中视觉语言模型在识别真实与3D打印物体上的表现，揭示了模型在实际应用中的局限性。|
|🆕 发布|Surgery-R1: Advancing Surgical-VQLA with Reasoning Multimodal Large Language Model via Reinforcement Learning|手术-R1：通过强化学习利用推理多模态大型语言模型推进手术视觉问答与语言理解|Pengfei Hao, Shuaibo Li, Hongqiu Wang, Zhizhuo Kou, Junhang Zhang, Guang Yang, Lei Zhu|<http://arxiv.org/pdf/2506.19469v1>|[代码](https://github.com/FiFi-HAO467/Surgery-R1.); 提出首个用于手术场景的推理型多模态大语言模型，通过强化学习提升理解与推理能力。|
|🆕 发布|Continual Retinal Vision-Language Pre-training upon Incremental Imaging Modalities|基于增量成像模态的连续视网膜视觉-语言预训练|Yuang Yao, Ruiqi Wu, Yi Zhou, Tao Zhou|<http://arxiv.org/pdf/2506.19320v1>|[代码](https://github.com/Yuang-Yao/RetCoP.); 提出首个针对视网膜领域的连续视觉语言预训练框架RetCoP，有效整合多模态图像特征并减少遗忘率。|
|📝 更新|A Contrastive Learning Foundation Model Based on Perfectly Aligned Sample Pairs for Remote Sensing Images|基于完美对齐样本对的遥感图像对比学习基础模型|Hengtong Shen, Haiyan Gu, Haitao Li, Yi Yang, Agen Qiu|<http://arxiv.org/pdf/2505.19447v2>|提出了一种基于完美对齐样本对的遥感图像自监督学习方法，有效缩小了领域差距并提高了特征质量。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vision Transformer-Based Time-Series Image Reconstruction for Cloud-Filling Applications|基于视觉变换器的时序图像重建方法用于云填充应用|Lujun Li, Yiqun Wang, Radu State|<http://arxiv.org/pdf/2506.19591v1>|提出了一种基于Vision Transformer的时序多光谱图像重建框架，有效利用时序一致性和雷达...|
|🆕 发布|HMSViT: A Hierarchical Masked Self-Supervised Vision Transformer for Corneal Nerve Segmentation and Diabetic Neuropathy Diagnosis|层次化掩码自监督视觉变换器HMSViT：用于角膜神经分割和糖尿病神经病变诊断|Xin Zhang, Liangxiu Han, Yue Shi, Yanlin Zheng, Alam Uazman, Maryam Ferdousi, Rayaz Malik|<http://arxiv.org/pdf/2506.19474v1>|定位糖尿病神经病变的无创诊断，提出HMSViT模型，实现高效多尺度特征提取，提升分割与诊断性能。|
|📝 更新|Brain Mapping with Dense Features: Grounding Cortical Semantic Selectivity in Natural Images With Vision Transformers|稠密特征脑映射：利用视觉变压器在自然图像中奠定皮质语义选择性基础|Andrew F. Luo, Jacob Yeung, Rushikesh Zawar, Shaurya Dewan, Margaret M. Henderson, Leila Wehbe, Michael J. Tarr|<http://arxiv.org/pdf/2410.05266v2>|提出BrainSAIL方法，利用预训练视觉模型解析大脑视觉皮层对自然图像的语义选择性。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|One Prototype Is Enough: Single-Prototype Activation for Interpretable Image Classification|一个原型足矣：单一原型激活的可解释图像分类|Yitao Peng, Lianghua He, Die Hu|<http://arxiv.org/pdf/2506.19808v1>|[代码](https://github.com/pyt19/ProtoSolo.); 提出了一种仅使用单个原型进行分类的新架构，简化了解释复杂度并提升了分类性能。|
|📝 更新|Unfolding the Past: A Comprehensive Deep Learning Approach to Analyzing Incunabula Pages|展开过去：一种分析古版书页面的全面深度学习方法|Klaudia Ropel, Krzysztof Kutt, Luiz do Valle Miranda, Grzegorz J. Nalepa|<http://arxiv.org/pdf/2506.18069v2>|提出了一种深度学习方法，自动分析古书页面结构内容，实现了高精度识别和分类。|
|🆕 发布|Comparative Performance of Finetuned ImageNet Pre-trained Models for Electronic Component Classification|电子元件分类中微调ImageNet预训练模型的比较性能|Yidi Shao, Longfei Zhou, Fangshuo Tang, Xinyi Shi, Dalang Chen, Shengtao Xia|<http://arxiv.org/pdf/2506.19330v1>|比较了十二种基于ImageNet预训练的模型在电子元件分类中的性能，MobileNet-V2达到最高...|
|🆕 发布|Open-Vocabulary Camouflaged Object Segmentation with Cascaded Vision Language Models|级联视觉语言模型的开放词汇伪装目标分割|Kai Zhao, Wubang Yuan, Zheng Wang, Guanyi Li, Xiaoqiang Zhu, Deng-ping Fan, Dan Zeng|<http://arxiv.org/pdf/2506.19300v1>|提出了一种VLM引导的级联框架，有效解决了伪装物体分割与分类的难题。|
|🆕 发布|Explicit Residual-Based Scalable Image Coding for Humans and Machines|显式残差基可扩展图像编码：面向人类与机器|Yui Tatsumi, Ziyue Zeng, Hiroshi Watanabe|<http://arxiv.org/pdf/2506.19297v1>|提出显式残差压缩机制，提升图像编码效率与兼容性，实现机器与人类视觉需求的可扩展压缩。|
|📝 更新|Overlap-Aware Feature Learning for Robust Unsupervised Domain Adaptation for 3D Semantic Segmentation|用于三维语义分割的鲁棒无监督领域自适应的重叠感知特征学习|Junjie Chen, Yuecong Xu, Haosheng Li, Kemi Ding|<http://arxiv.org/pdf/2504.01668v3>|提出了一种针对3D语义分割的鲁棒无监督域自适应方法，通过抑制特征重叠和增强目标特征，提高了对抗性攻击...|
|📝 更新|DDS-NAS: Dynamic Data Selection within Neural Architecture Search via On-line Hard Example Mining applied to Image Classification|DDS-NAS：通过在线难例挖掘在神经网络架构搜索中进行动态数据选择应用于图像分类|Matt Poyser, Toby P. Breckon|<http://arxiv.org/pdf/2506.14667v2>|通过动态困难样本选择加速神经架构搜索，DDS-NAS方法大幅提高了训练效率并保持了性能。|
|🆕 发布|Ancient Script Image Recognition and Processing: A Review|古文字图像识别与处理：综述|Xiaolei Diao, Rite Bo, Yanling Xiao, Lida Shi, Zhihan Zhou, Hao Xu, Chuntao Li, Xiongfeng Tang .etc.|<http://arxiv.org/pdf/2506.19208v1>|系统综述了古文字图像识别方法，分析了挑战并提出未来发展方向。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Systematic Review of Pituitary Gland and Pituitary Adenoma Automatic Segmentation Techniques in Magnetic Resonance Imaging|磁共振成像中垂体腺和垂体腺瘤自动分割技术的系统性回顾|Mubaraq Yakubu, Navodini Wijethilake, Jonathan Shapey, Andrew King, Alexander Hammers|<http://arxiv.org/pdf/2506.19797v1>|定位并优化了垂体腺瘤和垂体自动分割技术，提升MRI图像处理准确性与效率。|
|📝 更新|Stepping Out of Similar Semantic Space for Open-Vocabulary Segmentation|走出相似语义空间以实现开放词汇分割|Yong Liu, SongLi Wu, Sule Bai, Jiahao Wang, Yitong Wang, Yansong Tang|<http://arxiv.org/pdf/2506.16058v2>|提出OpenBench基准和OVSNet方法，提升开放词汇分割模型对广泛概念的理解和分割性能。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Systematic Comparison of Projection Methods for Monocular 3D Human Pose Estimation on Fisheye Images|单目3D人体姿态估计在鱼眼图像上的投影方法系统比较|Stephanie Käs, Sven Peter, Henrik Thillmann, Anton Burenko, David Benjamin Adrian, Dennis Mack, Timm Linder, Bastian Leibe|<http://arxiv.org/pdf/2506.19747v1>|系统比较了多种投影方法在鱼眼相机图像中估计三维人体姿态的效果，提出了一种基于检测框选择最佳投影模型的...|
|📝 更新|GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation|全局上下文增强：用于类别级对象姿态估计|Weihang Li, Hongli Xu, Junwen Huang, Hyunjun Jung, Peter KT Yu, Nassir Navab, Benjamin Busam|<http://arxiv.org/pdf/2502.04293v2>|[代码](https://colin-de.github.io/GCE-Pose); 提出全局上下文增强策略，通过语义形状重建和特征融合模块，提高了部分可见物体姿态估计的准确性。|
|🆕 发布|EvDetMAV: Generalized MAV Detection from Moving Event Cameras|EvDetMAV：移动事件相机中通用微型空中车辆检测|Yin Zhang, Zian Ning, Xiaoyu Zhang, Shiliang Guo, Peidong Liu, Shiyu Zhao|<http://arxiv.org/pdf/2506.19416v1>|[代码](https://github.com/WindyLab/EvDetMAV.); 提出利用事件相机检测 MAV 的新方法，通过分析螺旋桨特征提高检测准确率。|
|📝 更新|RRCANet: Recurrent Reusable-Convolution Attention Network for Infrared Small Target Detection|循环可重用卷积注意力网络（RRCANet）用于红外小目标检测|Yongxian Liu, Boyang Li, Ting Liu, Zaiping Lin, Wei An|<http://arxiv.org/pdf/2506.02393v2>|[代码](https://code will be available at https://github.com/yongxianLiu/); 提出了一种循环复用卷积注意力网络，用于高效准确的红外小目标检测。|
|🆕 发布|Capturing Fine-Grained Alignments Improves 3D Affordance Detection|捕捉细粒度对齐提高三维可用性检测|Junsei Tokumitsu, Yuiga Wada|<http://arxiv.org/pdf/2506.19312v1>|提出LM-AD方法，通过Affordance Query Module高效捕捉点云与文本的细粒度对齐...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Grounding Beyond Detection: Enhancing Contextual Understanding in Embodied 3D Grounding|超越检测的定位：增强具身3D定位中的情境理解|Yani Zhang, Dongming Wu, Hao Shi, Yingfei Liu, Tiancai Wang, Haoqiang Fan, Xingping Dong|<http://arxiv.org/pdf/2506.05199v2>|[代码](https://github.com/zyn213/DEGround.); 提出方法DEGround，通过共享检测查询和引入区域激活模块，增强机器人对语言指令的情境理解能力。|
|🆕 发布|USIS16K: High-Quality Dataset for Underwater Salient Instance Segmentation|USIS16K：水下显著实例分割的高质量数据集|Lin Hong, Xin Wang, Yihao Li, Xia Wang|<http://arxiv.org/pdf/2506.19472v1>|提出了USIS16K，一个大规模、高质量水下显著实例分割数据集，助力解决了水下场景识别难题。|
|🆕 发布|Quantitative Benchmarking of Anomaly Detection Methods in Digital Pathology|数字病理学中异常检测方法的定量基准测试|Can Cui, Xindong Zheng, Ruining Deng, Quan Liu, Tianyuan Yao, Keith T Wilson, Lori A Coburn, Bennett A Landman .etc.|<http://arxiv.org/pdf/2506.19234v1>|系统评估了20余种异常检测方法在数字病理学图像中的应用效果，为该领域研究提供了全面的性能基准。|


## 生成式视觉模型 (Generative Visual Modeling)


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GenHSI: Controllable Generation of Human-Scene Interaction Videos|《GenHSI：可控的人类场景交互视频生成》|Zekun Li, Rui Zhou, Rahul Sajnani, Xiaoyan Cong, Daniel Ritchie, Srinath Sridhar|<http://arxiv.org/pdf/2506.19840v1>|[代码](https://kunkun0w0.github.io/project); 提出了一种无需训练、分三阶段生成具有丰富人景交互的长视频的方法，解决了现有方法在生成此类视频时的问题...|
|🆕 发布|ScaleCap: Inference-Time Scalable Image Captioning via Dual-Modality Debiasing|"ScaleCap：通过双模态去偏的推理时间可扩展图像字幕生成"|Long Xing, Qidong Huang, Xiaoyi Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Jinsong Li, Shuangrui Ding .etc.|<http://arxiv.org/pdf/2506.19848v1>|[代码](https://github.com/Cooperx521/ScaleCap.); 提出了一种可扩展的图像字幕生成策略ScaleCap，通过双模态去偏方法逐步丰富和调整字幕，有效克服了...|
|🆕 发布|SimpleGVR: A Simple Baseline for Latent-Cascaded Video Super-Resolution|简单GVR：用于潜在级联视频超分辨率的简单基线|Liangbin Xie, Yu Li, Shian Du, Menghan Xia, Xintao Wang, Fanghua Yu, Ziyan Chen, Pengfei Wan .etc.|<http://arxiv.org/pdf/2506.19838v1>|提出了一种高效的级联视频超分辨率框架，通过优化训练策略和模型结构，实现了更高质量的图像重建。|
|🆕 发布|Noise Consistency Training: A Native Approach for One-Step Generator in Learning Additional Controls|噪声一致性训练：一种原生方法用于学习额外控制的一步生成器|Yihong Luo, Shuchen Xue, Tianyang Hu, Jing Tang|<http://arxiv.org/pdf/2506.19741v1>|[代码](https://github.com/Luo-Yihong/NCT); 引入噪声一致性训练方法，直接将新控制信号融入预训练一步生成器，无需原始训练图像或重训练基础模型。|
|📝 更新|LoRA-Edit: Controllable First-Frame-Guided Video Editing via Mask-Aware LoRA Fine-Tuning|LoRA-Edit：通过遮罩感知的LoRA微调实现可控的首帧引导视频编辑|Chenjian Gao, Lihe Ding, Xin Cai, Zhanpeng Huang, Zibin Wang, Tianfan Xue|<http://arxiv.org/pdf/2506.10082v3>|[代码](https://cjeen.github.io/LoraEditPaper); 提出了一种基于掩码的LoRA微调方法，实现了对视频编辑的灵活控制，同时保持背景区域不变。|
|🆕 发布|Emergence of Text Readability in Vision Language Models|计算机视觉模型中文字可读性的涌现|Jaeyoo Park, Sanghyuk Chun, Wonjae Kim, Sangdoo Yun, Bohyung Han|<http://arxiv.org/pdf/2506.19389v1>|揭示了视觉语言模型训练中文字识别能力的突现现象，指出需定制化训练策略以加速文本理解。|
|📝 更新|Referring Expression Instance Retrieval and A Strong End-to-End Baseline|指代表达式实例检索与一种强大的端到端基线|Xiangzhao Hao, Kuan Zhu, Hongyu Guo, Haiyun Guo, Ning Jiang, Quan Lu, Ming Tang, JinQiao Wang|<http://arxiv.org/pdf/2506.18246v2>|提出REIR任务并设计CLARE模型，实现图像实例级检索与细粒度定位的统一。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AnimaX: Animating the Inanimate in 3D with Joint Video-Pose Diffusion Models|AnimaX：利用联合视频-姿态扩散模型在3D中对非生物物体进行动画化处理|Zehuan Huang, Haoran Feng, Yangtian Sun, Yuanchen Guo, Yanpei Cao, Lu Sheng|<http://arxiv.org/pdf/2506.19851v1>|AnimaX通过结合视频扩散模型和骨骼动画，实现了对任意骨架3D模型的灵活动画生成。|
|🆕 发布|CronusVLA: Transferring Latent Motion Across Time for Multi-Frame Prediction in Manipulation|CronusVLA：跨时间转移潜在运动以实现操作中多帧预测|Hao Li, Shuai Yang, Yilun Chen, Yang Tian, Xiaoda Yang, Xinyi Chen, Hanqing Wang, Tai Wang .etc.|<http://arxiv.org/pdf/2506.19816v1>|提出CronusVLA框架，通过高效后训练扩展单帧VLA模型至多帧，利用历史运动信息提升操作任务性能...|
|📝 更新|Beyond Reconstruction: A Physics Based Neural Deferred Shader for Photo-realistic Rendering|超越重建：基于物理的神经延迟着色器用于照片级真实感渲染|Zhuo He, Paul Henderson, Nicolas Pugeault|<http://arxiv.org/pdf/2504.12273v2>|提出了一种基于物理的神经延迟着色器，实现了光照和材质参数的分解，提高了照片级渲染的性能和控制能力。|
|📝 更新|ReconX: Reconstruct Any Scene from Sparse Views with Video Diffusion Model|ReconX：利用视频扩散模型从稀疏视角重建任意场景|Fangfu Liu, Wenqiang Sun, Hanyang Wang, Yikai Wang, Haowen Sun, Junliang Ye, Jun Zhang, Yueqi Duan|<http://arxiv.org/pdf/2408.16767v3>|提出ReconX，利用视频扩散模型从稀疏视角重建高质量3D场景。|
|📝 更新|Contactless Cardiac Pulse Monitoring Using Event Cameras|使用事件相机进行无接触式心脏脉搏监测|Mohamed Moustafa, Joseph Lemley, Peter Corcoran|<http://arxiv.org/pdf/2505.09529v2>|利用事件相机实现了无接触式心率监测，通过训练CNN模型从面部事件流中提取心脏信号。|
|📝 更新|Privacy Attacks on Image AutoRegressive Models|图像自回归模型隐私攻击研究|Antoni Kowalczuk, Jan Dubiński, Franziska Boenisch, Adam Dziedzic|<http://arxiv.org/pdf/2502.02514v4>|[代码](https://github.com/sprintml/privacy_attacks_against_iars); 揭示了图像自回归模型在隐私保护方面的缺陷，并开发了一种高效的成员推断攻击方法。|
|🆕 发布|Deblurring in the Wild: A Real-World Dataset from Smartphone High-Speed Videos|《野外去模糊：来自智能手机高速视频的实际世界数据集》|Mahdi Mohd Hossain Noki, Syed Mumtahin Mahmud, Prothito Shovon Majumder, Abdul Mohaimen Al Radi, Md. Haider Ali, Md. Mosaddek Khan|<http://arxiv.org/pdf/2506.19445v1>|构建了首个大规模真实世界图像去模糊数据集，推动去模糊模型性能显著提升。|
|🆕 发布|Generate the Forest before the Trees -- A Hierarchical Diffusion model for Climate Downscaling|在树木之前生成森林——一种用于气候降尺度的分层扩散模型|Declan J. Curran, Sanaa Hobeichi, Hira Saleem, Hao Xue, Flora D. Salim|<http://arxiv.org/pdf/2506.19391v1>|[代码](https://github.com/HDD-Hierarchical-Diffusion-Downscaling/HDD-Hierarchical-Diffusion-Downscaling.); 提出了一种分层扩散模型，通过粗到细的层级采样显著降低气候降尺度的计算负担，同时保持准确度。|
|📝 更新|MDeRainNet: An Efficient Macro-pixel Image Rain Removal Network|MDeRainNet：一种高效宏像素图像去雨网络|Tao Yan, Weijiang He, Chenglong Wang, Cihang Wei, Xiangjie Zhu, Yinghui Wang, Rynson W. H. Lau|<http://arxiv.org/pdf/2406.10652v3>|提出了一种高效网络MDeRainNet，利用宏观像素和扩展空间-角交互模块提升雨滴去除效果。|
|🆕 发布|OpenWildlife: Open-Vocabulary Multi-Species Wildlife Detector for Geographically-Diverse Aerial Imagery|《OpenWildlife：面向地理分布广泛航空影像的开词汇多物种野生动物检测器》|Muhammed Patel, Javier Noa Turnes, Jayden Hsiao, Linlin Xu, David Clausi|<http://arxiv.org/pdf/2506.19204v1>|提出了一种开放词汇的多物种野生动物检测器，通过语言感知嵌入和改进的Grounding-DINO框架，...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Radial Attention: $O(n\log n)$ Sparse Attention with Energy Decay for Long Video Generation|径向注意力：面向长视频生成的 $O(n\log n)$ 稀疏注意力机制及能量衰减|Xingyang Li, Muyang Li, Tianle Cai, Haocheng Xi, Shuo Yang, Yujun Lin, Lvmin Zhang, Songlin Yang .etc.|<http://arxiv.org/pdf/2506.19852v1>|提出Radial Attention方法，通过能量衰减实现长视频生成中的高效稀疏注意力，大幅提升速度...|
|🆕 发布|Improving Progressive Generation with Decomposable Flow Matching|使用可分解流匹配改进渐进式生成|Moayed Haji-Ali, Willi Menapace, Ivan Skorokhodov, Arpit Sahni, Sergey Tulyakov, Vicente Ordonez, Aliaksandr Siarohin|<http://arxiv.org/pdf/2506.19839v1>|提出了一种简单有效的多尺度视觉生成框架 Decomposable Flow Matching，提高了...|
|🆕 发布|Bind-Your-Avatar: Multi-Talking-Character Video Generation with Dynamic 3D-mask-based Embedding Router|"绑定你的虚拟形象：基于动态3D面具嵌入路由的多对话角色视频生成"|Yubo Huang, Weiqiang Wang, Sirui Zhao, Tong Xu, Lin Liu, Enhong Chen|<http://arxiv.org/pdf/2506.19833v1>|提出了一种多对话角色视频生成框架，通过3D掩码嵌入路由器实现了音频与角色的精确对应和时空连贯性。|
|📝 更新|ObjCtrl-2.5D: Training-free Object Control with Camera Poses|无需训练的基于相机姿态的对象控制ObjCtrl-2.5D|Zhouxia Wang, Yushi Lan, Shangchen Zhou, Chen Change Loy|<http://arxiv.org/pdf/2412.07721v2>|[代码](https://wzhouxiff.github.io/projects); 提出了一种无需训练的3D轨迹控制方法ObjCtrl-2.5D，通过模拟相机运动实现更精确和多样化的图...|
|📝 更新|Aligning Anime Video Generation with Human Feedback|将动画视频生成与人类反馈对齐|Bingwen Zhu, Yudong Jiang, Baohan Xu, Siqian Yang, Mingyu Yin, Yidi Wu, Huyang Sun, Zuxuan Wu|<http://arxiv.org/pdf/2504.10044v2>|[代码](https://github.com/bilibili/Index-anisora.); 利用人类反馈优化动漫视频生成，提出AnimeReward模型和GAPO训练方法，显著提升视频质量和一...|
|📝 更新|IgCONDA-PET: Weakly-Supervised PET Anomaly Detection using Implicitly-Guided Attention-Conditional Counterfactual Diffusion Modeling -- a Multi-Center, Multi-Cancer, and Multi-Tracer Study|IgCONDA-PET：基于隐式引导注意力条件对抗性扩散模型的弱监督PET异常检测——多中心、多癌症类型、多示踪剂研究|Shadab Ahamed, Arman Rahmim|<http://arxiv.org/pdf/2405.00239v3>|[代码](https://github.com/ahxmeds/IgCONDA-PET.git.); 提出了一种基于条件对抗生成和注意力引导的PET图像弱监督异常检测方法，减少了专家标注需求。|
|🆕 发布|Uncovering Conceptual Blindspots in Generative Image Models Using Sparse Autoencoders|使用稀疏自动编码器揭示生成图像模型中的概念盲点|Matyas Bohacek, Thomas Fel, Maneesh Agrawala, Ekdeep Singh Lubana|<http://arxiv.org/pdf/2506.19708v1>|提出了一种利用稀疏自动编码器揭示生成图像模型中概念盲点的方法，实现了对模型生成概念与训练数据间差异的...|
|📝 更新|ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation|简洁提示：通过生成过程中的连续简洁提示提升高效推理|Siao Tang, Xinyin Ma, Gongfan Fang, Xinchao Wang|<http://arxiv.org/pdf/2506.18810v2>|提出ConciseHint框架，通过生成过程中注入提示，减少大型推理模型冗长推理，提升效率。|
|📝 更新|Diff-Def: Diffusion-Generated Deformation Fields for Conditional Atlases|扩散生成的变形场用于条件性图谱的构建|Sophie Starck, Vasiliki Sideri-Lampretsa, Bernhard Kainz, Martin J. Menten, Tamara T. Mueller, Daniel Rueckert|<http://arxiv.org/pdf/2403.16776v3>|提出了一种利用潜在扩散模型生成变形场的方法，以创建特定子人群的高保真度解剖图谱。|
|📝 更新|Controllable Video Generation with Provable Disentanglement|可控视频生成与可证明解耦|Yifan Shen, Peiyuan Zhu, Zijian Li, Shaoan Xie, Zeyu Tang, Namrata Deka, Zongfang Liu, Guangyi Chen .etc.|<http://arxiv.org/pdf/2502.02690v2>|提出CoVoGAN方法，通过解耦视频概念实现高效独立控制视频生成。|
|🆕 发布|Training-Free Motion Customization for Distilled Video Generators with Adaptive Test-Time Distillation|无训练的运动定制化：自适应测试时蒸馏的精简视频生成器|Jintao Rong, Xin Xie, Xinyi Yu, Linlin Ou, Xinyu Zhang, Chunhua Shen, Dong Gong|<http://arxiv.org/pdf/2506.19348v1>|[代码](https://euminds.github.io/motionecho); 提出了一种无需训练的MotionEcho框架，通过教师模型指导，实现了视频生成模型中的运动定制化，提...|
|📝 更新|DeltaSpace: A Semantic-aligned Feature Space for Flexible Text-guided Image Editing|DeltaSpace：一种面向灵活文本引导图像编辑的语义对齐特征空间|Yueming Lyu, Kang Zhao, Bo Peng, Huafeng Chen, Yue Jiang, Yingya Zhang, Jing Dong, Caifeng Shan|<http://arxiv.org/pdf/2310.08785v2>|[代码](https://github.com/Yueming6568/DeltaEdit.); 提出DeltaSpace和DeltaEdit框架，通过语义对齐特征空间实现无需文本训练和零样本文本引...|
|🆕 发布|SoK: Can Synthetic Images Replace Real Data? A Survey of Utility and Privacy of Synthetic Image Generation|《系统化知识总结：合成图像能否替代真实数据？合成图像生成的实用性与隐私性调研》|Yunsung Chung, Yunbei Zhang, Nassir Marrouche, Jihun Hamm|<http://arxiv.org/pdf/2506.19360v1>|系统评估了合成图像生成方法的效用与隐私权衡，指导了最优数据发布策略的选择。|
|🆕 发布|Da Yu: Towards USV-Based Image Captioning for Waterway Surveillance and Scene Understanding|面向水道监控与场景理解的无人船基图像标注方法研究|Runwei Guan, Ningwei Ouyang, Tianhao Xu, Shaofeng Liang, Wei Dai, Yafeng Sun, Shang Gao, Songning Lai .etc.|<http://arxiv.org/pdf/2506.19288v1>|提出WaterCaption数据集及Da Yu模型，通过图像captioning实现水面环境全局语义...|
|📝 更新|SycnMapV2: Robust and Adaptive Unsupervised Segmentation|同步映射V2：稳健且自适应的无监督分割|Heng Zhang, Zikang Wan, Danilo Vasconcellos Vargas|<http://arxiv.org/pdf/2506.16297v2>|提出了SyncMapV2算法，实现了具有卓越鲁棒性的无监督分割，且能在线适应不同输入，无需重新初始化...|
|📝 更新|Privacy-Shielded Image Compression: Defending Against Exploitation from Vision-Language Pretrained Models|隐私保护的图像压缩：防御来自视觉-语言预训练模型的利用|Xuelin Shen, Jiayin Xu, Kangsheng Yin, Wenhan Yang|<http://arxiv.org/pdf/2506.15201v2>|提出了一种隐私保护的图像压缩方法，通过编码策略抵御视觉语言预训练模型的利用风险。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CoCo4D: Comprehensive and Complex 4D Scene Generation|《CoCo4D：全面与复杂四维场景生成》|Junwei Zhou, Xueting Li, Lu Qi, Ming-Hsuan Yang|<http://arxiv.org/pdf/2506.19798v1>|[代码](https://colezwhy.github.io/coco4d); 提出了一种生成详细动态4D场景的框架，通过分离动态前景和背景建模，实现了多视角一致性和沉浸感。|
|📝 更新|Dynamic PET Image Reconstruction via Non-negative INR Factorization|通过非负INR因子分解的动态PET图像重建|Chaozhi Zhang, Wenxiang Ding, Roy Y. He, Xiaoqun Zhang, Qiaoqiao Ding|<http://arxiv.org/pdf/2503.08025v2>|提出了一种基于神经网络的非负隐式表示分解方法，有效重构动态PET图像并保持图像细节特征。|
|🆕 发布|Segment Any 3D-Part in a Scene from a Sentence|从句子中分割场景中的任何3D部件|Hongyu Wu, Pengwan Yang, Yuki M. Asano, Cees G. M. Snoek|<http://arxiv.org/pdf/2506.19331v1>|提出首个大规模3D部分标注数据集，并设计3D输入框架，实现基于自然语言描述的任意3D场景部分分割。|
|📝 更新|Not All Thats Rare Is Lost: Causal Paths to Rare Concept Synthesis|《并非所有罕见之事物皆已丧失：罕见概念合成的因果路径》|Bo-Kai Ruan, Zi-Xiang Ni, Bo-Lun Huang, Teng-Fang Hsiao, Hong-Han Shuai|<http://arxiv.org/pdf/2505.20808v2>|提出了一种名为RAP的框架，通过引导模型沿着潜在因果路径从常见概念生成罕见概念，有效提升了罕见概念的...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Active View Selector: Fast and Accurate Active View Selection with Cross Reference Image Quality Assessment|主动视图选择器：具有交叉参考图像质量评估的快速准确主动视图选择|Zirui Wang, Yash Bhalgat, Ruining Li, Victor Adrian Prisacariu|<http://arxiv.org/pdf/2506.19844v1>|提出了一种基于二维图像质量评估的快速准确主动视图选择方法，无需依赖特定三维表示，大幅提升性能和速度。|
|🆕 发布|NeRF-based CBCT Reconstruction needs Normalization and Initialization|基于NeRF的CBCT重建需要归一化和初始化|Zhuowei Xu, Han Li, Dai Sun, Zhicheng Li, Yujia Li, Qingpeng Kong, Zhiwei Cheng, Nassir Navab .etc.|<http://arxiv.org/pdf/2506.19742v1>|提出了一种归一化哈希编码和映射一致性初始化策略，有效解决了CBCT重建中的局部-全局训练不匹配问题，...|
|📝 更新|Light of Normals: Unified Feature Representation for Universal Photometric Stereo|“法线之光：用于通用光度立体成像的统一特征表示”|Hong Li, Houyuan Chen, Chongjie Ye, Zhaoxi Chen, Bohan Li, Shaocong Xu, Xianda Guo, Xuhui Liu .etc.|<http://arxiv.org/pdf/2506.18882v2>|提出了一种统一特征表示方法，解决了任意光照条件下表面法线恢复的难题，并保留了复杂表面的高频几何细节。|
|📝 更新|Super-Resolution with Structured Motion|具有结构化运动的超分辨率|Gabby Litterio, Juan-David Lizarazo-Ferro, Pedro Felzenszwalb, Rashid Zia|<http://arxiv.org/pdf/2505.15961v2>|利用高精度运动信息和稀疏图像先验，通过凸优化实现大幅提升图像分辨率。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Look to Locate: Vision-Based Multisensory Navigation with 3-D Digital Maps for GNSS-Challenged Environments|“看向定位：基于视觉的多感官导航与3D数字地图在GNSS受限环境中的应用”|Ola Elmaghraby, Eslam Mounier, Paulo Ricardo Marques de Araujo, Aboelmagd Noureldin|<http://arxiv.org/pdf/2506.19827v1>|提出一种利用单目视觉和3D地图集成的导航系统，在GNSS受限环境下实现高精度车辆定位。|
|📝 更新|Multimodal Fusion SLAM with Fourier Attention|多模态融合SLAM的傅里叶注意力方法|Youjie Zhou, Guofeng Mei, Yiming Wang, Yi Wan, Fabio Poiesi|<http://arxiv.org/pdf/2506.18204v2>|[代码](https://github.com/youjie-zhou/FMF-SLAM.git.); 提出了一种高效的傅里叶注意力多模态融合SLAM方法，通过结合RGB和深度信息，在噪声和多变光照条件下...|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RA-NeRF: Robust Neural Radiance Field Reconstruction with Accurate Camera Pose Estimation under Complex Trajectories|RA-NeRF：在复杂轨迹下具有精确相机位姿估计的稳健神经辐射场重建|Qingsong Yan, Qiang Wang, Kaiyong Zhao, Jie Chen, Bo Li, Xiaowen Chu, Fei Deng|<http://arxiv.org/pdf/2506.15242v2>|提出了一种RA-NeRF方法，通过改进相机位姿估计，在复杂轨迹下实现了高精度的神经辐射场重建。|
|🆕 发布|HOIverse: A Synthetic Scene Graph Dataset With Human Object Interactions|《HOIverse：一个包含人对象交互的合成场景图数据集》|Mrunmai Vivek Phatak, Julian Lorenz, Nico Hörmann, Jörg Hähner, Rainer Lienhart|<http://arxiv.org/pdf/2506.19639v1>|提出合成数据集HOIverse，为室内场景中人类与物体互动的视觉理解提供准确密集的关系标注。|
|📝 更新|SemGauss-SLAM: Dense Semantic Gaussian Splatting SLAM|语义高斯散点映射SLAM：稠密语义高斯溅射SLAM|Siting Zhu, Renjie Qin, Guangming Wang, Jiuming Liu, Hesheng Wang|<http://arxiv.org/pdf/2403.07494v4>|提出SemGauss-SLAM系统，融合3D高斯表示与语义信息，实现精确语义映射和稳健相机跟踪。|
|🆕 发布|Experimental Assessment of Neural 3D Reconstruction for Small UAV-based Applications|小型无人机应用中神经三维重建的实验评估|Genís Castillo Gómez-Raya, Álmos Veres-Vitályos, Filip Lemic, Pablo Royo, Mario Montagud, Sergi Fernández, Sergi Abadal, Xavier Costa-Pérez|<http://arxiv.org/pdf/2506.19491v1>|提出了一种结合神经网络三维重建技术的小型无人机系统，显著提升了室内及难以到达区域的三维映射精度。|
|🆕 发布|Online camera-pose-free stereo endoscopic tissue deformation recovery with tissue-invariant vision-biomechanics consistency|在线无相机姿态立体内镜组织形变恢复：基于组织不变性视觉生物力学一致性|Jiahe Chen, Naoki Tomii, Ichiro Sakuma, Etsuko Kobayashi|<http://arxiv.org/pdf/2506.19388v1>|提出了一种在线恢复立体内窥镜下组织变形的方法，无需相机位姿估计，实现了高精度变形建模。|
|🆕 发布|HoliGS: Holistic Gaussian Splatting for Embodied View Synthesis|《HoliGS：整体高斯散点绘制法用于具身视图合成》|Xiaoyuan Wang, Yizhou Zhao, Botao Ye, Xiaojun Shan, Weijie Lyu, Lu Qi, Kelvin C. K. Chan, Yinxiao Li .etc.|<http://arxiv.org/pdf/2506.19291v1>|提出了一种全局可逆的 Gaussian Splatting 框架，有效处理长视频中的动态场景重建问题...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MAMMA: Markerless & Automatic Multi-Person Motion Action Capture|无标记自动多人运动动作捕捉系统（MAMMA）|Hanz Cuevas-Velasquez, Anastasios Yiannakidis, Soyong Shin, Giorgio Becherini, Markus Höschle, Joachim Tesch, Taylor Obersat, Tsvetelina Alexiadis .etc.|<http://arxiv.org/pdf/2506.13040v2>|提出了一种无需标记的多人运动捕捉方法，通过预测密集二维表面标志，实现了高精度的人与人交互动作捕捉。|
|🆕 发布|Video Compression for Spatiotemporal Earth System Data|视频压缩在时空地球系统数据处理中的应用|Oscar J. Pellicer-Valero, Cesar Aybar, Gustau Camps Valls|<http://arxiv.org/pdf/2506.19656v1>|[代码](https://github.com/IPL-UV/xarrayvideo); 提出了一种利用视频压缩技术压缩地球系统数据的方法，实现了高达250倍的压缩比，同时保持数据质量。|
|📝 更新|DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs|DaMO：一种面向视频大型语言模型时序推理的数据高效多模态协调器|Bo-Cheng Chiu, Jen-Jee Chen, Yu-Chee Tseng, Feng-Chi Chen|<http://arxiv.org/pdf/2506.11558v2>|提出DaMO模型，通过双流架构和分阶段训练提升视频时序推理能力。|
|🆕 发布|Video-XL-2: Towards Very Long-Video Understanding Through Task-Aware KV Sparsification|视频XL-2：通过任务感知的键值稀疏化实现超长视频理解|Minghao Qin, Xiangrui Liu, Zhengyang Liang, Yan Shu, Huaying Yuan, Juenjie Zhou, Shitao Xiao, Bo Zhao .etc.|<http://arxiv.org/pdf/2506.19225v1>|提出了一种针对长视频理解的成本效益优化方法Video-XL-2，通过任务感知的关键-值稀疏化提升效率...|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VideoPCDNet: Video Parsing and Prediction with Phase Correlation Networks|视频解析与预测：基于相位相关性网络|Noel José Rodrigues Vicente, Enrique Lehner, Angel Villar-Corrales, Jan Nogga, Sven Behnke|<http://arxiv.org/pdf/2506.19621v1>|提出了一种无监督的视频解析与预测框架VideoPCDNet，通过频率域相位相关性技术实现对象跟踪和未...|
|🆕 发布|Trajectory Prediction in Dynamic Object Tracking: A Critical Study|动态目标跟踪中的轨迹预测：一项关键研究|Zhongping Dong, Liming Chen, Mohand Tahar Kechadi|<http://arxiv.org/pdf/2506.19341v1>|系统分析了动态对象跟踪和轨迹预测方法，指出未来研究方向以提升安全与效率。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Reconsidering Explicit Longitudinal Mammography Alignment for Enhanced Breast Cancer Risk Prediction|重新考虑显式纵向乳腺X线照片对齐以提高乳腺癌风险预测|Solveig Thrun, Stine Hansen, Zijun Sun, Nele Blum, Suaiba A. Salahuddin, Kristoffer Wickstrøm, Elisabeth Wetzer, Robert Jenssen .etc.|<http://arxiv.org/pdf/2506.19363v1>|[代码](https://github.com/sot176/Longitudinal_Mammogram_Alignment.git.); 探究了哺乳图像的显式对齐策略，提出在输入空间进行对齐可提升乳腺癌风险预测准确性。|
|🆕 发布|Airway Skill Assessment with Spatiotemporal Attention Mechanisms Using Human Gaze|使用时空注意力机制和人类注视进行气道技能评估|Jean-Paul Ainam, Rahul, Lora Cavuoto, Matthew Hackett, Jack Norfleet, Suvranu De|<http://arxiv.org/pdf/2506.19306v1>|提出了一种利用人类注视数据评估气管插管技能的机器学习方法，提高了评估的准确性和效率。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Comparative Study of NAFNet Baselines for Image Restoration|《图像复原中NAFNet基线方法的比较研究》|Vladislav Esaulov, M. Moein Esfahani|<http://arxiv.org/pdf/2506.19845v1>|比较NAFNet基线模型在图像恢复中的效果，证实其简化激活和注意力机制提升性能。|
|🆕 发布|Orthogonal Finetuning Made Scalable|正交微调的大规模实现|Zeju Qiu, Weiyang Liu, Adrian Weller, Bernhard Schölkopf|<http://arxiv.org/pdf/2506.19847v1>|提出了一种改进的Orthogonal finetuning方法OFTv2，通过输入中心计算和高效参数...|
|📝 更新|Two-Stream Spatial-Temporal Transformer Framework for Person Identification via Natural Conversational Keypoints|基于自然对话关键点的双流时空变换框架进行行人识别|Masoumeh Chapariniya, Hossein Ranjbar, Teodora Vukovic, Sarah Ebling, Volker Dellwo|<http://arxiv.org/pdf/2502.20803v2>|提出了一种双流时空变换框架，通过分析在线对话中身体关键点的空间结构和时间变化，有效提升了人物识别的准...|
|📝 更新|PicoSAM2: Low-Latency Segmentation In-Sensor for Edge Vision Applications|PicoSAM2：面向边缘视觉应用的低延迟传感器内分割|Pietro Bonazzi, Nicola Farronato, Stefan Zihlmann, Haotong Qin, Michele Magno|<http://arxiv.org/pdf/2506.18807v2>|提出了一种轻量级边缘视觉应用分割模型PicoSAM2，通过知识蒸馏和定点编码实现低延迟、隐私保护的实...|
|🆕 发布|Assessing Risk of Stealing Proprietary Models for Medical Imaging Tasks|评估医学成像任务中窃取专有模型的风险|Ankita Raj, Harsh Swaika, Deepankar Varma, Chetan Arora|<http://arxiv.org/pdf/2506.19464v1>|[代码](https://github.com/rajankita/QueryWise.); 探究了医疗影像模型在黑盒条件下的模型窃取风险，并提出了QueryWise方法以增强攻击效率。|
|🆕 发布|Mem4Nav: Boosting Vision-and-Language Navigation in Urban Environments with a Hierarchical Spatial-Cognition Long-Short Memory System|Mem4Nav：利用分层空间认知长短时记忆系统提升城市环境下的视觉-语言导航性能|Lixuan He, Haoyu Dong, Zhenxing Chen, Yangcheng Yu, Jie Feng, Yong Li|<http://arxiv.org/pdf/2506.19433v1>|[代码](https://github.com/tsinghua-fib-lab/Mem4Nav.); Mem4Nav通过引入层级空间认知长短期记忆系统，有效融合视觉与语言导航，增强大型城市环境中的实时避...|
|📝 更新|DivTrackee versus DynTracker: Promoting Diversity in Anti-Facial Recognition against Dynamic FR Strategy|《DivTrackee 与 DynTracker 对抗：在动态人脸识别策略下促进人脸反识别的多样性》|Wenshu Fan, Minxing Zhang, Hongwei Li, Wenbo Jiang, Hanxiao Chen, Xiangyu Yue, Michael Backes, Xiao Zhang|<http://arxiv.org/pdf/2501.06533v2>|提出动态人脸识别策略挑战现有反识别技术，并引入多样性增强的反识别方法DivTrackee以应对。|
|🆕 发布|Virtual Memory for 3D Gaussian Splatting|虚拟内存用于三维高斯散点绘制|Jonathan Haberl, Philipp Fleck, Clemens Arth|<http://arxiv.org/pdf/2506.19415v1>|提出了一种利用虚拟内存技术高效渲染大型复杂3D高斯散点场景的方法，显著降低内存使用并加速渲染速度。|
|🆕 发布|NAADA: A Noise-Aware Attention Denoising Autoencoder for Dental Panoramic Radiographs|噪声感知注意力去噪自动编码器用于牙科全景X射线成像|Khuram Naveed, Bruna Neves de Freitas, Ruben Pauwels|<http://arxiv.org/pdf/2506.19387v1>|提出了一种噪声感知注意力去噪自动编码器，有效恢复了牙科全景X光片中的细微解剖结构。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ReCoGNet: Recurrent Context-Guided Network for 3D MRI Prostate Segmentation|ReCoGNet：用于三维MRI前列腺分割的循环上下文引导网络|Ahmad Mustafa, Reza Rastegar, Ghassan AlRegib|<http://arxiv.org/pdf/2506.19687v1>|提出了一种结合2D和3D优势的混合网络，通过时间连续性提升MRI前列腺分割的准确性和鲁棒性。|
|🆕 发布|Identifying Physically Realizable Triggers for Backdoored Face Recognition Networks|识别用于后门人脸识别网络中物理可实现触发器的方法|Ankita Raj, Ambar Pal, Chetan Arora|<http://arxiv.org/pdf/2506.19533v1>|提出方法检测并识别面部识别网络中的自然触发器，有效发现并定位后门攻击。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Classification in Japanese Sign Language Based on Dynamic Facial Expressions|基于动态面部表情的日本手语分类|Yui Tatsumi, Shoko Tanaka, Shunsuke Akamatsu, Takahiro Shindo, Hiroshi Watanabe|<http://arxiv.org/pdf/2411.06347v2>|提出了一种基于神经网络分析面部特征，用于分类日语手语句子类型的方法，实现了96.05%的分类准确率。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FOCoOp: Enhancing Out-of-Distribution Robustness in Federated Prompt Learning for Vision-Language Models|FOCoOp：增强视觉语言模型联邦提示学习中分布外鲁棒性|Xinting Liao, Weiming Liu, Jiaming Qian, Pengyang Zhou, Jiahe Xu, Wenjie Wang, Chaochao Chen, Xiaolin Zheng .etc.|<http://arxiv.org/pdf/2506.16218v2>|提出FOCoOp框架，通过多级提示和分布优化增强联邦视觉语言模型在非分布内数据上的鲁棒性。|
|🆕 发布|Self-Paced Collaborative and Adversarial Network for Unsupervised Domain Adaptation|自适应步调协作对抗网络用于无监督领域自适应|Weichen Zhang, Dong Xu, Wanli Ouyang, Wen Li|<http://arxiv.org/pdf/2506.19267v1>|提出了一种自步调协作对抗网络，通过协作与对抗学习策略实现无监督领域自适应，达到当前最佳性能。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FusionForce: End-to-end Differentiable Neural-Symbolic Layer for Trajectory Prediction|融合力：端到端可微分神经符号层用于轨迹预测|Ruslan Agishev, Karel Zimmermann|<http://arxiv.org/pdf/2502.10156v4>|提出了一种预测机器人轨迹的端到端可微分模型，通过整合力学规律和快速物理引擎，缩小了仿真与现实的差距。|
|📝 更新|Improving Out-of-Distribution Detection via Dynamic Covariance Calibration|通过动态协方差校准提高分布外检测性能|Kaiyu Guo, Zijian Wang, Tan Pan, Brian C. Lovell, Mahsa Baktashmotlagh|<http://arxiv.org/pdf/2506.09399v3>|[代码](https://github.com/workerbcd/ooddcc.); 提出动态调整先验协方差矩阵的方法，有效改善样本分布不均导致的OOD检测问题。|
|🆕 发布|Stylized Structural Patterns for Improved Neural Network Pre-training|风格化结构模式用于改进神经网络预训练|Farnood Salehi, Vandit Sharma, Amirhossein Askari Farsangi, Tunç Ozan Aydın|<http://arxiv.org/pdf/2506.19465v1>|提出两步法生成合成数据，通过神经分形和逆向风格化缩小现实与合成数据差距，提升模型性能。|
|📝 更新|Exclusive Style Removal for Cross Domain Novel Class Discovery|跨域新颖类发现中的独有风格移除|Yicheng Wang, Feng Liu, Junmin Liu, Kai Sun|<http://arxiv.org/pdf/2406.18140v4>|提出了一种跨域新颖类发现中的独有风格移除模块，有效处理了不同分布的未标记数据。|
|🆕 发布|Progressive Modality Cooperation for Multi-Modality Domain Adaptation|渐进模态协作的多模态域自适应|Weichen Zhang, Dong Xu, Jing Zhang, Wanli Ouyang|<http://arxiv.org/pdf/2506.19316v1>|提出了一种渐进式多模态协作框架，有效实现了多模态数据在不同领域间的知识迁移。|
|📝 更新|Hadamard Attention Recurrent Transformer: A Strong Baseline for Stereo Matching Transformer|哈达玛注意力循环变换器：立体匹配变换器的强基线|Ziyang Chen, Wenting Li, Yongjun Zhang, Yabo Wu, Bingshu Wang, Yong Zhao, C. L. Philip Chen|<http://arxiv.org/pdf/2501.01023v3>|[代码](https://github.com/ZYangChen/HART.); 提出HART模型，通过创新的注意力机制提升立体匹配的非线性表达能力，有效应对反射等挑战性条件。|
|📝 更新|Dataset of soil images with corresponding particle size distributions for photogranulometry|土壤图像数据集及其对应粒度分布的光学粒度测量|Thomas Plante St-Cyr, François Duhaime, Jean-Sébastien Dubé, Simon Grenier|<http://arxiv.org/pdf/2506.17469v2>|构建了一个高分辨率土壤图像数据集，结合粒度分布分析，旨在简化并优化地质技术实验室中的颗粒大小分析流程...|
|🆕 发布|Automated Image Recognition Framework|自动化图像识别框架|Quang-Binh Nguyen, Trong-Vu Hoang, Ngoc-Do Tran, Tam V. Nguyen, Minh-Triet Tran, Trung-Nghia Le|<http://arxiv.org/pdf/2506.19261v1>|提出了一种自动图像识别框架，利用生成式AI生成高质量预标注数据集，无需手动标注，并自动训练性能稳健的...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality|知行强化学习：探索基于知识的真实性强化学习|Baochang Ren, Shuofei Qiao, Wenhao Yu, Huajun Chen, Ningyu Zhang|<http://arxiv.org/pdf/2506.19807v1>|[代码](https://github.com/zjunlp/KnowRL.); 提出方法KnowRL，通过引入事实性奖励，减少大型语言模型在推理过程中的虚构现象。|
|📝 更新|AI-based Multimodal Biometrics for Detecting Smartphone Distractions: Application to Online Learning|基于人工智能的多模态生物识别技术在检测智能手机干扰中的应用：在线学习的实践|Alvaro Becerra, Roberto Daza, Ruth Cobos, Aythami Morales, Mutlu Cukurova, Julian Fierrez|<http://arxiv.org/pdf/2506.17364v2>|提出了一种结合生理信号和头部姿态数据的AI方法，有效检测在线学习中手机干扰，提高了注意力监测的准确性...|
|🆕 发布|Learning from Anatomy: Supervised Anatomical Pretraining (SAP) for Improved Metastatic Bone Disease Segmentation in Whole-Body MRI|从解剖学学习：用于全身MRI转移性骨病分割的监督解剖预训练（SAP）|Joris Wuts, Jakub Ceranka, Nicolas Michoux, Frédéric Lecouvet, Jef Vandemeulebroucke|<http://arxiv.org/pdf/2506.19590v1>|提出了一种监督解剖预训练方法，通过学习有限解剖标签数据集，有效提高了全身MRI中骨转移病变的分割准确...|
|🆕 发布|ConCM: Consistency-Driven Calibration and Matching for Few-Shot Class-Incremental Learning|一致驱动校准与匹配：用于少量样本类别增量学习的ConCM方法|QinZhe Wang, Zixuan Chen, Keke Huang, Xiu Su, Chunhua Yang, Chang Xu|<http://arxiv.org/pdf/2506.19558v1>|提出一致性驱动的校准与匹配框架ConCM，有效解决少量样本增量学习中的知识冲突问题。|
|🆕 发布|ReMAR-DS: Recalibrated Feature Learning for Metal Artifact Reduction and CT Domain Transformation|重新调整特征学习以减少金属伪影和CT域转换的ReMAR-DS方法|Mubashara Rehman, Niki Martinel, Michele Avanzo, Riccardo Spizzo, Christian Micheloni|<http://arxiv.org/pdf/2506.19531v1>|提出了一种深度学习框架ReMAR-DS，通过特征重校准有效减少金属伪影并实现CT图像域转换。|
|🆕 发布|Memory-Augmented Incomplete Multimodal Survival Prediction via Cross-Slide and Gene-Attentive Hypergraph Learning|通过跨切片和基因关注超图学习实现的记忆增强不完全多模态生存预测|Mingcheng Qu, Guang Yang, Donglin Di, Yue Gao, Tonghua Su, Yang Song, Lei Fan|<http://arxiv.org/pdf/2506.19324v1>|[代码](https://github.com/MCPathology/M2Surv); 提出了一种利用超图学习和记忆机制的多模态生存预测框架，有效整合病理和基因组数据，并处理数据不完整问题...|
|📝 更新|LAuReL: Learned Augmented Residual Layer|LAuReL: 学习增强残差层|Gaurav Menghani, Ravi Kumar, Sanjiv Kumar|<http://arxiv.org/pdf/2411.07501v4>|提出LAuReL方法，优化传统残差连接，提升模型性能且减少参数增加。|
|📝 更新|Pro-AD: Learning Comprehensive Prototypes with Prototype-based Constraint for Multi-class Unsupervised Anomaly Detection|Pro-AD：基于原型约束学习综合原型进行多类无监督异常检测|Ziqing Zhou, Yurui Pan, Lidong Wang, Wenbing Zhu, Mingmin Chi, Dong Wu, Bo Peng|<http://arxiv.org/pdf/2506.13097v3>|提出Pro-AD方法，通过扩展原型集和动态双向解码器增强异常检测性能，并引入原型约束避免异常重构。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FineCLIPER: Multi-modal Fine-grained CLIP for Dynamic Facial Expression Recognition with AdaptERs|细粒度多模态CLIP with AdaptERs的动态面部表情识别|Haodong Chen, Haojian Huang, Junhao Dong, Mingzhe Zheng, Dian Shao|<http://arxiv.org/pdf/2407.02157v3>|[代码](https://haroldchen19.github.io/FineCLIPER-Page); 提出了一种多模态细粒度CLIP框架，通过融合文本描述和面部动态特征，有效提升了动态面部表情识别的准确...|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 目标导向视觉决策 (Goal-oriented Visual Decision Making)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Object-aware Sound Source Localization via Audio-Visual Scene Understanding|通过音频-视觉场景理解实现目标感知的声音源定位|Sung Jin Um, Dongjin Kim, Sangmin Lee, Jung Uk Kim|<http://arxiv.org/pdf/2506.18557v2>|[代码](https://github.com/VisualAIKHU/OA-SSL.); 提出了一种利用多模态大语言模型区分声源物体和背景物体的新声源定位框架，有效解决了复杂场景中的定位难题...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visual hallucination detection in large vision-language models via evidential conflict|通过证据冲突检测大规模视觉-语言模型中的视觉幻觉|Tao Huang, Zhekun Liu, Rui Wang, Yang Zhang, Liping Jing|<http://arxiv.org/pdf/2506.19513v1>|[代码](https://github.com/HT86159/Evidential-Conflict.); 提出首个基于Dempster-Shafer理论的视觉幻觉检测方法，有效识别大型视觉语言模型中的视觉-...|
|🆕 发布|Sampling Matters in Explanations: Towards Trustworthy Attribution Analysis Building Block in Visual Models through Maximizing Explanation Certainty|样本选择在解释中至关重要：通过最大化解释确定性构建视觉模型中值得信赖的归因分析基石|Róisín Luo, James McDermott, Colm O'Riordan|<http://arxiv.org/pdf/2506.19442v1>|提出通过抑制输入特征的新采样方法，以匹配自然图像分布，提高解释分析的可靠性。|
|📝 更新|VideoMathQA: Benchmarking Mathematical Reasoning via Multimodal Understanding in Videos|视频数学问答：通过视频中的多模态理解对数学推理进行基准测试|Hanoona Rasheed, Abdelrahman Shaker, Anqi Tang, Muhammad Maaz, Ming-Hsuan Yang, Salman Khan, Fahad Shahbaz Khan|<http://arxiv.org/pdf/2506.05349v2>|[代码](https://mbzuai-oryx.github.io/VideoMathQA); 提出了VideoMathQA基准，用于评估模型在视频中进行跨模态数学推理的能力。|
|📝 更新|ClimateIQA: A New Dataset and Benchmark to Advance Vision-Language Models in Meteorology Anomalies Analysis|气候图像质量评估：一种新的数据集和基准，用于推动视觉-语言模型在气象异常分析中的应用|Jian Chen, Peilin Zhou, Yining Hua, Dading Chong, Meng Cao, Yaowei Li, Zixuan Yuan, Bing Zhu .etc.|<http://arxiv.org/pdf/2406.09838v2>|提出SPOT算法并构建ClimateIQA数据集，提升视觉语言模型在气象异常分析中的准确性和描述能力...|
|📝 更新|FusionSAM: Visual Multi-Modal Learning with Segment Anything|融合SAM：基于Segment Anything的视觉多模态学习|Daixun Li, Weiying Xie, Mingxiang Cao, Yunke Wang, Yusi Zhang, Leyuan Fang, Yunsong Li, Chang Xu|<http://arxiv.org/pdf/2408.13980v2>|首次将Segment Anything Model引入多模态图像分割，提出结合Latent Spac...|
|🆕 发布|MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports|MedErr-CT：一种用于识别和纠正CT报告错误的视觉问答基准|Sunggu Kyung, Hyungbin Park, Jinyoung Seo, Jimin Sung, Jihyun Kim, Dongyeong Kim, Wooyoung Jo, Yoojin Nam .etc.|<http://arxiv.org/pdf/2506.19217v1>|[代码](https://github.com/babbu3682/MedErr-CT.); 提出MedErr-CT基准，通过视觉问答框架评估模型识别并纠正CT报告错误的能力。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Cross-Level Multi-Instance Distillation for Self-Supervised Fine-Grained Visual Categorization|跨级别多实例蒸馏用于自监督细粒度视觉分类|Qi Bi, Wei Ji, Jingjun Yi, Haolan Zhan, Gui-Song Xia|<http://arxiv.org/pdf/2401.08860v3>|提出了一种跨层次多实例蒸馏框架，通过重视图像关键区块在细粒度视觉分类中的作用，提升了无监督学习方法的...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Semantic Scene Graph for Ultrasound Image Explanation and Scanning Guidance|超声图像解释与扫描引导的语义场景图|Xuesong Li, Dianye Huang, Yameng Zhang, Nassir Navab, Zhongliang Jiang|<http://arxiv.org/pdf/2506.19683v1>|提出场景图解释超声图像内容，并通过大型语言模型增强指导非专业人士扫描。|
|🆕 发布|UltraAD: Fine-Grained Ultrasound Anomaly Classification via Few-Shot CLIP Adaptation|超细AD：通过少量样本CLIP适应进行细粒度超声异常分类|Yue Zhou, Yuan Bi, Wenjuan Tong, Wei Wang, Nassir Navab, Zhongliang Jiang|<http://arxiv.org/pdf/2506.19694v1>|提出UltraAD方法，通过少量超声样本实现病变定位和细粒度分类，提升医学图像异常检测精度。|
|📝 更新|crossMoDA Challenge: Evolution of Cross-Modality Domain Adaptation Techniques for Vestibular Schwannoma and Cochlea Segmentation from 2021 to 2023|跨模态域自适应技术在2021至2023年间针对前庭神经鞘瘤和耳蜗分割的演变：crossMoDA挑战赛|Navodini Wijethilake, Reuben Dorent, Marina Ivory, Aaron Kujawa, Stefan Cornelissen, Patrick Langenhuizen, Mohamed Okasha, Anna Oviedova .etc.|<http://arxiv.org/pdf/2506.12006v2>|该研究通过跨模态域自适应技术，提升了T2 MRI上前庭神经鞘瘤和耳蜗的自动化分割精度，增强了临床应用...|
|🆕 发布|Self-Supervised Multimodal NeRF for Autonomous Driving|自监督多模态神经辐射场技术在自动驾驶中的应用|Gaurav Sharma, Ravi Kothari, Josef Schmid|<http://arxiv.org/pdf/2506.19615v1>|[代码](https://github.com/gaurav00700/Selfsupervised-NVSF); 提出了一种自监督的多模态NeRF框架，无需3D标签即可学习静态和动态场景的时空表示。|
|🆕 发布|Filling of incomplete sinograms from sparse PET detector configurations using a residual U-Net|使用残差U-Net从稀疏PET探测器配置填充不完整正弦图|Klara Leffler, Luigi Tommaso Luppino, Samuel Kuttner, Karin Söderkvist, Jan Axelsson|<http://arxiv.org/pdf/2506.19600v1>|提出了一种深度学习网络，通过恢复缺失的sinogram数据，有效补偿稀疏PET探测器配置导致的图像质...|
|🆕 发布|SceneCrafter: Controllable Multi-View Driving Scene Editing|《SceneCrafter：可控多视角驾驶场景编辑》|Zehao Zhu, Yuliang Zou, Chiyu Max Jiang, Bo Sun, Vincent Casser, Xiukun Huang, Jiahao Wang, Zhenpei Yang .etc.|<http://arxiv.org/pdf/2506.19488v1>|提出SceneCrafter，一种多视角驾驶场景编辑器，实现3D一致性编辑并兼容多模态条件。|
|🆕 发布|Angio-Diff: Learning a Self-Supervised Adversarial Diffusion Model for Angiographic Geometry Generation|《Angio-Diff：用于血管造影几何生成的自监督对抗性扩散模型学习》|Zhifeng Wang, Renjiao Yi, Xin Wen, Chenyang Zhu, Kai Xu, Kunlun He|<http://arxiv.org/pdf/2506.19455v1>|[代码](https://github.com/zfw-cv/AngioDiff.); 提出了一种自监督扩散模型，用于将非血管造影X射线转换为高质量血管造影图像，提高了血管几何结构的合成精...|
|🆕 发布|AMF-MedIT: An Efficient Align-Modulation-Fusion Framework for Medical Image-Tabular Data|AMF-MedIT：面向医学图像-表格数据的高效对齐-调制-融合框架|Congjing Yu, Jing Ye, Yang Liu, Xiaodong Zhang, Zhiyong Zhang|<http://arxiv.org/pdf/2506.19439v1>|提出了一种高效的医疗图像与表格数据融合框架，通过自适应调制和融合模块优化模态特征整合，增强数据利用效...|
|🆕 发布|Image Segmentation using Chan-Vese Active Contours|基于Chan-Vese活动轮廓的图像分割|Pranav Shenoy K. P|<http://arxiv.org/pdf/2506.19344v1>|提出Chan-Vese主动轮廓模型，通过区域强度差异实现图像分割，有效应对噪声和弱边界问题。|
|📝 更新|VesselSAM: Leveraging SAM for Aortic Vessel Segmentation with AtrousLoRA|血管SAM：利用自适应门控卷积神经网络进行主动脉血管分割|Adnan Iltaf, Rayan Merghani Ahmed, Zhenxi Zhang, Bin Li, Shoujun Zhou|<http://arxiv.org/pdf/2502.18185v4>|[代码](https://github.com/Adnan-CAS/AtrousLora.); 提出VesselSAM模型，结合AtrousLoRA优化分割性能，实现高效准确的心脏血管分割。|
|📝 更新|MIFNet: Learning Modality-Invariant Features for Generalizable Multimodal Image Matching|MIFNet：学习模态不变特征以实现通用多模态图像匹配|Yepeng Liu, Zhichao Sun, Baosheng Yu, Yitian Zhao, Bo Du, Yongchao Xu, Jun Cheng|<http://arxiv.org/pdf/2501.11299v3>|[代码](https://github.com/lyp-deeplearning/MIFNet.); 提出了一种学习单一模态数据上的模态不变特征网络，实现了无需目标模态数据即可进行多模态图像匹配的方法。|
|🆕 发布|Deformable Medical Image Registration with Effective Anatomical Structure Representation and Divide-and-Conquer Network|具有有效解剖结构表示与分而治之网络的变形医学图像配准|Xinke Ma, Yongsheng Pan, Qingjie Zeng, Mengkang Lu, Bolysbek Murat Yerzhanuly, Bazargul Matkerim, Yong Xia|<http://arxiv.org/pdf/2506.19222v1>|提出了一种基于有效解剖结构表示和分而治之网络的变形医学图像配准方法，无需标签即可实现独立区域对齐，显...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Recurrent Visual Feature Extraction and Stereo Attentions for CT Report Generation|循环视觉特征提取与立体注意力机制在CT报告生成中的应用|Yuanhe Tian, Lei Mao, Yan Song|<http://arxiv.org/pdf/2506.19665v1>|提出了一种基于循环视觉特征提取和立体注意力机制的方法，用于提高CT报告生成的准确性和有效性。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PEVLM: Parallel Encoding for Vision-Language Models|并行编码用于视觉-语言模型（PEVLM）|Letian Kang, Shixian Luo, Yiqiang Li, Xiaoyang Yu, Shenxuan Zhou, Yong Wu|<http://arxiv.org/pdf/2506.19651v1>|提出PEVLM方法，通过并行编码降低长视频处理复杂度，提高效率和准确性。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MambaOutRS: A Hybrid CNN-Fourier Architecture for Remote Sensing Image Classification|MambaOutRS：一种用于遥感图像分类的混合卷积神经网络-傅里叶架构|Minjong Cheon, Changbae Mun|<http://arxiv.org/pdf/2506.19561v1>|提出了一种结合卷积神经网络与傅里叶变换的架构，有效提升遥感图像分类性能。|
|🆕 发布|A Global-Local Cross-Attention Network for Ultra-high Resolution Remote Sensing Image Semantic Segmentation|用于超高分遥感图像语义分割的全局-局部交叉注意力网络|Chen Yi, Shan LianLei|<http://arxiv.org/pdf/2506.19406v1>|提出了一种双流架构的GLCANet，有效融合全局语义与局部细节，提升超高分遥感图像分割的准确性与效率...|
|📝 更新|Temporal-Spectral-Spatial Unified Remote Sensing Dense Prediction|时间-光谱-空间统一遥感密集预测|Sijie Zhao, Feng Liu, Enzhuo Zhang, Yiqing Guo, Pengfeng Xiao, Lei Bai, Xueliang Zhang, Hao Chen .etc.|<http://arxiv.org/pdf/2505.12280v2>|提出了一种统一的远程感知预测网络，能适应多变的输入输出数据并整合多种任务，提升处理复杂遥感数据的性能...|
|🆕 发布|AirV2X: Unified Air-Ground Vehicle-to-Everything Collaboration|统一空地车联网协同系统：AirV2X|Xiangbo Gao, Yuheng Wu, Xuewen Luo, Keshu Wu, Xinghao Chen, Yuping Wang, Chenxi Liu, Yang Zhou .etc.|<http://arxiv.org/pdf/2506.19283v1>|[代码](https://github.com/taco-group/AirV2X-Perception.); 提出AirV2X-Perception大规模数据集，利用无人机辅助车辆感知，降低部署成本并提高覆盖范...|
|🆕 发布|3D-SSM: A Novel 3D Selective Scan Module for Remote Sensing Change Detection|三维选择扫描模块（3D-SSM）：用于遥感变化检测的一种新颖方法|Rui Huang, Jincheng Zeng, Sen Gao, Yan Xing|<http://arxiv.org/pdf/2506.19263v1>|[代码](https://github.com/VerdantMist/3D-SSM); 提出了3D-SSM模块，通过捕获全局信息增强遥感变化检测能力，提升了细微变化的识别效果。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Flopping for FLOPs: Leveraging equivariance for computational efficiency|“摆动以节省浮点运算：利用等方差性提升计算效率”|Georg Bökman, David Nordström, Fredrik Kahl|<http://arxiv.org/pdf/2502.05169v2>|引入等变神经网络以保持对称性，同时将计算量减半，实现高效计算与对称性结合。|
|📝 更新|Improved and Explainable Cervical Cancer Classification using Ensemble Pooling of Block Fused Descriptors|基于区块融合描述符集成池化的改进型可解释宫颈癌分类方法|Saurabh Saini, Kapil Ahuja, Akshat S. Chauhan|<http://arxiv.org/pdf/2405.01600v2>|提出了一种融合多级特征和新型组合策略的宫颈癌细胞分类方法，显著提升了分类准确率并引入了可解释性技术。|
|🆕 发布|Implementing blind navigation through multi-modal sensing and gait guidance|通过多模态感知与步态引导实现的盲人导航|Feifan Yan, Tianle Zeng, Meixi He|<http://arxiv.org/pdf/2506.19593v1>|提出了一种结合步态分析和多模态感知的导盲设备，实验证明其性能优于传统导盲杖。|
|🆕 发布|Convergent and divergent connectivity patterns of the arcuate fasciculus in macaques and humans|猕猴和人类弓状束的收敛和发散连接模式|Jiahao Huang, Ruifeng Li, Wenwen Yu, Anan Li, Xiangning Li, Mingchao Yan, Lei Xie, Qingrun Zeng .etc.|<http://arxiv.org/pdf/2506.19266v1>|揭示了人类与猕猴弧形束连接模式的差异，为理解语言网络进化特化提供了神经解剖学基础。|

