## [UPDATED!] **2025-06-25** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FluoroSAM: A Language-promptable Foundation Model for Flexible X-ray Image Segmentation|荧光SAM：一种语言提示型基础模型，用于灵活的X射线图像分割|Benjamin D. Killeen, Liam J. Wang, Blanca Inigo, Han Zhang, Mehran Armand, Russell H. Taylor, Greg Osgood, Mathias Unberath|<http://arxiv.org/pdf/2403.08059v3>|[代码](https://github.com/arcadelab/fluorosam.); 提出了一种基于自然语言提示的X射线图像分割基础模型FluoroSAM，实现了对多种解剖结构和工具的灵...|
|🆕 发布|A Novel Large Vision Foundation Model (LVFM)-based Approach for Generating High-Resolution Canopy Height Maps in Plantations for Precision Forestry Management|一种基于新颖的大型视觉基础模型（LVFM）生成高分辨率林冠高度图的方法，用于精准林业管理|Shen Tan, Xin Zhang, Liangxiu Han, Huaguo Huang, Han Wang|<http://arxiv.org/pdf/2506.20388v1>|提出了一种基于大型视觉基础模型的高分辨率树冠高度图生成方法，有效提升了植树造林碳汇监测的精度和成本效...|
|🆕 发布|Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement|《随时随地识别手术阶段：少量样本测试时适应与任务图引导的细化》|Kun Yuan, Tingxuan Chen, Shi Li, Joel L. Lavanchy, Christian Heiliger, Ege Özsoy, Yiming Huang, Long Bai .etc.|<http://arxiv.org/pdf/2506.20254v1>|[代码](https://github.com/CAMMA-public/SPA); 提出了一种轻量级框架SPA，通过少量样本适应和任务图引导，实现了跨机构手术阶段识别的精准度。|
|🆕 发布|UniCode$^2$: Cascaded Large-scale Codebooks for Unified Multimodal Understanding and Generation|统一编码器$^2$：级联大规模码本以实现统一的多模态理解和生成|Yanzhe Chen, Huasong Zhong, Yan Li, Zhenheng Yang|<http://arxiv.org/pdf/2506.20214v1>|提出了一种大规模级联视觉编码框架UniCode$^2$，通过保持视觉与语言对齐，实现了稳定的大规模视...|
|🆕 发布|EAR: Erasing Concepts from Unified Autoregressive Models|EAR：从统一自回归模型中擦除概念|Haipeng Fan, Shiyuan Zhang, Baohunesitu, Zihang Guo, Huaiwen Zhang|<http://arxiv.org/pdf/2506.20151v1>|[代码](https://github.com/immc-lab/ear); 提出了一种名为EAR的细调方法，有效移除AR模型中的不期望概念，同时保持图像生成质量。|
|🆕 发布|Towards Scalable and Generalizable Earth Observation Data Mining via Foundation Model Composition|通过基础模型组合实现可扩展和泛化的地球观测数据挖掘|Man Duc Chuc|<http://arxiv.org/pdf/2506.20174v1>|提出结合预训练模型特征级融合及知识蒸馏方法，提升地球观测数据挖掘性能与效率。|
|📝 更新|TIIF-Bench: How Does Your T2I Model Follow Your Instructions?|TIIF-Bench：您的文本到图像模型如何遵循您的指令？|Xinyu Wei, Jinrui Zhang, Zeqing Wang, Hongyang Wei, Zhen Guo, Lei Zhang|<http://arxiv.org/pdf/2506.02161v2>|[代码](https://a113n-w3i.github.io/TIIF_Bench); 提出了TIIF-Bench，一个全面的评估框架，用于衡量文本到图像模型对复杂指令的遵循能力。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models|“眼见为实？在多模态大型语言模型中减轻OCR幻觉”|Zhentao He, Can Zhang, Ziheng Wu, Zhenghao Chen, Yufei Zhan, Yifan Li, Zhao Zhang, Xian Wang .etc.|<http://arxiv.org/pdf/2506.20168v1>|提出首个评估OCR幻觉的KIE-HVQA基准，并引入GRPO框架减少模型在模糊视觉数据中的错误回答。|
|📝 更新|Robust Multimodal Learning for Ophthalmic Disease Grading via Disentangled Representation|通过解耦表示的稳健多模态学习进行眼科疾病分级|Xinkun Wang, Yifang Wang, Senwei Liang, Feilong Tang, Chengzhi Liu, Ming Hu, Chao Hu, Junjun He .etc.|<http://arxiv.org/pdf/2503.05319v2>|提出了一种增强特征选择和分离的EDRL策略，有效提升了眼科疾病分级的多模态学习鲁棒性。|
|🆕 发布|MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations|MIRAGE：面向农业专家引导对话中的多模态信息检索与推理的基准测试|Vardhan Dongre, Chi Gui, Shubham Garg, Hooshang Nayyeri, Gokhan Tur, Dilek Hakkani-Tür, Vikram S. Adve|<http://arxiv.org/pdf/2506.20100v1>|提出了MIRAGE基准，为农业领域专家级多模态推理和决策提供高保真度评估平台。|
|📝 更新|PP-DocBee2: Improved Baselines with Efficient Data for Multimodal Document Understanding|PP-DocBee2：基于高效数据的多模态文档理解改进基线|Kui Huang, Xinrong Chen, Wenyu Lv, Jincheng Liao, Guanzhong Wang, Yi Liu|<http://arxiv.org/pdf/2506.18023v2>|[代码](https://github.com/PaddlePaddle/PaddleMIX); PP-DocBee2通过优化数据质量和特征融合策略，提升了文档理解性能并减少了推理延迟。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Weighted Mean Frequencies: a handcraft Fourier feature for 4D Flow MRI segmentation|加权平均频率：一种用于四维流磁共振成像分割的手工傅里叶特征|Simon Perrin, Sébastien Levilly, Huajun Sun, Harold Mouchère, Jean-Michel Serfaty|<http://arxiv.org/pdf/2506.20614v1>|提出了一种新的手工特征Weighted Mean Frequencies，通过增强4D Flow M...|
|📝 更新|LPOSS: Label Propagation Over Patches and Pixels for Open-vocabulary Semantic Segmentation|LPOSS：基于斑块和像素的标签传播用于开放词汇语义分割|Vladan Stojnić, Yannis Kalantidis, Jiří Matas, Giorgos Tolias|<http://arxiv.org/pdf/2503.19777v2>|[代码](https://github.com/vladan-stojnic/LPOSS); 提出了一种无需训练的开放词汇语义分割方法LPOSS+，通过标签传播优化视觉语言模型预测，实现全图推理...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Feature Hallucination for Self-supervised Action Recognition|特征幻觉用于自监督动作识别|Lei Wang, Piotr Koniusz|<http://arxiv.org/pdf/2506.20342v1>|提出了一种自监督动作识别框架，通过预测动作概念和辅助特征增强识别准确度，实现了业界领先的多模态识别性...|
|📝 更新|KD-DETR: Knowledge Distillation for Detection Transformer with Consistent Distillation Points Sampling|知识蒸馏用于检测Transformer的一致性蒸馏点采样|Yu Wang, Xin Li, Shengzhao Weng, Gang Zhang, Haixiao Yue, Haocheng Feng, Junyu Han, Errui Ding|<http://arxiv.org/pdf/2211.08071v3>|[代码](https://github.com/wennyuhey/KD-DETR.); 提出KD-DETR方法，通过一致性蒸馏点采样解决DETR模型压缩中的挑战，提升学生模型性能。|
|📝 更新|EvDetMAV: Generalized MAV Detection from Moving Event Cameras|EvDetMAV：移动事件相机中通用微型空中车辆检测|Yin Zhang, Zian Ning, Xiaoyu Zhang, Shiliang Guo, Peidong Liu, Shiyu Zhao|<http://arxiv.org/pdf/2506.19416v2>|[代码](https://github.com/WindyLab/EvDetMAV.); 提出利用事件相机捕捉旋翼特征进行 MAV 检测的新方法，创建了首个相关数据集并显著提升检测性能。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Bounding-box Watermarking: Defense against Model Extraction Attacks on Object Detectors|边界框水印：防御对象检测模型提取攻击|Satoru Koda, Ikuya Morikawa|<http://arxiv.org/pdf/2411.13047v2>|提出了一种通过API修改对象检测模型边界框实现的水印技术，有效防御模型提取攻击。|
|🆕 发布|From Codicology to Code: A Comparative Study of Transformer and YOLO-based Detectors for Layout Analysis in Historical Documents|从文献学到编码：基于Transformer和YOLO检测器在历史文献布局分析中的比较研究|Sergio Torres Aguilar|<http://arxiv.org/pdf/2506.20326v1>|比较了Transformer和YOLO检测器在历史文献布局分析中的性能，发现Oriented Bou...|
|📝 更新|Toddlers' Active Gaze Behavior Supports Self-Supervised Object Learning|幼儿主动注视行为支持自监督物体学习|Zhengyang Yu, Arthur Aubret, Marcel C. Raabe, Jane Yang, Chen Yu, Jochen Triesch|<http://arxiv.org/pdf/2411.01969v3>|揭示了幼儿通过频繁的眼部和头部运动如何支持其发展视角不变的对象识别能力。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TDiR: Transformer based Diffusion for Image Restoration Tasks|基于Transformer的扩散算法在图像复原任务中的应用（TDiR）|Abbas Anwar, Mohammad Shullar, Ali Arshad Nasir, Mudassir Masood, Saeed Anwar|<http://arxiv.org/pdf/2506.20302v1>|提出基于变换器和扩散模型的图像复原方法，有效提升了退化图像质量。|
|🆕 发布|Hierarchical Mask-Enhanced Dual Reconstruction Network for Few-Shot Fine-Grained Image Classification|分层掩码增强双重建网络用于少量样本细粒度图像分类|Ning Luo, Meiyin Hu, Huan Wan, Yanyan Yang, Zhuohang Jiang, Xin Wei|<http://arxiv.org/pdf/2506.20263v1>|提出了一种分层掩码增强双重建网络，通过融合不同层次的特征和增强关键区域聚焦，有效提升了少量样本细粒度...|
|🆕 发布|A Transformer Based Handwriting Recognition System Jointly Using Online and Offline Features|基于Transformer的手写识别系统，联合使用在线和离线特征|Ayush Lodh, Ritabrata Chakraborty, Shivakumara Palaiahnakote, Umapada Pal|<http://arxiv.org/pdf/2506.20255v1>|融合在线笔迹轨迹与离线图像特征，提出了一种端到端的基于Transformer的手写体识别系统，实现最...|
|📝 更新|A Siamese Network to Detect If Two Iris Images Are Monozygotic|一种用于检测两张虹膜图像是否为单卵双生的Siamese网络|Yongle Yuan, Kevin W. Bowyer|<http://arxiv.org/pdf/2503.09749v3>|提出首个自动分类器，利用Siamese网络和对比学习区分同卵双胞胎的虹膜图像。|
|📝 更新|One Prototype Is Enough: Single-Prototype Activation for Interpretable Image Classification|一个原型足矣：单一原型激活的可解释图像分类|Yitao Peng, Lianghua He, Die Hu|<http://arxiv.org/pdf/2506.19808v2>|[代码](https://github.com/pyt19/ProtoSolo.); 提出了一种仅使用单个原型进行分类的新架构，简化了解释复杂度并提升了分类性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EditP23: 3D Editing via Propagation of Image Prompts to Multi-View|编辑P23：通过图像提示传播至多视角的3D编辑|Roi Bar-On, Dana Cohen-Bar, Daniel Cohen-Or|<http://arxiv.org/pdf/2506.20652v1>|EditP23通过将2D图像编辑传播到3D多视角表示，实现了无需掩膜的直观3D编辑。|
|📝 更新|OmniGen2: Exploration to Advanced Multimodal Generation|OmniGen2：探索高级多模态生成|Chenyuan Wu, Pengfei Zheng, Ruiran Yan, Shitao Xiao, Xin Luo, Yueze Wang, Wanli Li, Xiyan Jiang .etc.|<http://arxiv.org/pdf/2506.18871v2>|[代码](https://github.com/VectorSpaceLab/OmniGen2); OmniGen2通过双解码路径和专用数据构建，实现了多模态生成任务的高效统一处理。|
|🆕 发布|HiWave: Training-Free High-Resolution Image Generation via Wavelet-Based Diffusion Sampling|基于小波扩散采样的无训练高分辨率图像生成方法|Tobias Vontobel, Seyedmorteza Sadat, Farnood Salehi, Romann M. Weber|<http://arxiv.org/pdf/2506.20452v1>|HiWave通过无需训练的零样本方法，结合预训练扩散模型和波浪域增强，实现了超高分辨率图像合成的视觉...|
|🆕 发布|DreamAnywhere: Object-Centric Panoramic 3D Scene Generation|“DreamAnywhere：基于对象的全方位三维场景生成”|Edoardo Alberto Dominici, Jozef Hladky, Floor Verhoeven, Lukas Radl, Thomas Deixelberger, Stefan Ainetter, Philipp Drescher, Stefan Hauswiesner .etc.|<http://arxiv.org/pdf/2506.20367v1>|提出DreamAnywhere系统，通过文本生成360度全景3D场景，实现高效场景探索与编辑。|
|📝 更新|VICCA: Visual Interpretation and Comprehension of Chest X-ray Anomalies in Generated Report Without Human Feedback|VICCA：无需人工反馈生成的报告中胸部X射线异常的视觉解读与理解|Sayeh Gholipour Picha, Dawood Al Chanti, Alice Caplier|<http://arxiv.org/pdf/2501.17726v2>|提出了一种无需人工反馈的医学报告生成框架，通过图像与文本的联合训练，实现了病变定位和报告内容的一致性...|
|🆕 发布|Ctrl-Z Sampling: Diffusion Sampling with Controlled Random Zigzag Explorations|控制随机之字形探索的扩散采样：Ctrl-Z采样|Shunqi Mao, Wei Guo, Chaoyi Zhang, Weidong Cai|<http://arxiv.org/pdf/2506.20294v1>|提出了一种新型采样策略Ctrl-Z Sampling，通过动态前后探索改善生成质量，有效解决扩散模型...|
|📝 更新|World-Consistent Data Generation for Vision-and-Language Navigation|用于视觉与语言导航的世界一致性数据生成|Yu Zhong, Rui Zhang, Zihao Zhang, Shuo Wang, Chuan Fang, Xishan Zhang, Jiaming Guo, Shaohui Peng .etc.|<http://arxiv.org/pdf/2412.06413v2>|提出了一种生成具有多样性和世界一致性视觉导航数据的方法，显著增强了机器人在新环境中的泛化能力。|
|🆕 发布|From 2D to 3D Cognition: A Brief Survey of General World Models|从二维到三维认知：通用世界模型简述|Ningwei Xie, Zizi Tian, Lei Yang, Xiao-Ping Zhang, Meng Guo, Jie Li|<http://arxiv.org/pdf/2506.20134v1>|系统分析了从2D视觉感知到3D空间认知的转变，强调了3D表示和世界知识融合的关键作用。|
|📝 更新|Fine-Grained Perturbation Guidance via Attention Head Selection|通过注意力头部选择实现的细粒度扰动引导|Donghoon Ahn, Jiwon Kang, Sanghyun Lee, Minjae Kim, Jaewon Min, Wooseok Jang, Saungwu Lee, Sayak Paul .etc.|<http://arxiv.org/pdf/2506.10978v2>|提出HeadHunter框架，通过选择特定注意力头实现细粒度生成控制和风格调整。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Diffusion Models Through a Global Lens: Are They Culturally Inclusive?|通过全局视角的扩散模型：它们在文化上具有包容性吗？|Zahra Bayramli, Ayhan Suleymanzade, Na Min An, Huzama Ahmad, Eunsu Kim, Junyeong Park, James Thorne, Alice Oh|<http://arxiv.org/pdf/2502.08914v2>|评估了文本到图像生成模型的文化包容性，并提出了CultDiff基准和相似度度量方法。|
|🆕 发布|Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks|减少对欺骗性伪迹的关注：在线社交网络上压缩深度伪造的鲁棒检测|Manyi Li, Renshuai Tao, Yufan Liu, Chuangchuang Tan, Haotong Qin, Bing Li, Yunchao Wei, Yao Zhao|<http://arxiv.org/pdf/2506.20548v1>|[代码](https://github.com/ManyiLee/PLADA.); 提出PLADA框架，通过消除压缩导致的块效应，有效提升了社交媒体上深度伪造图像的检测准确性。|
|📝 更新|Cross-Frame Representation Alignment for Fine-Tuning Video Diffusion Models|跨帧表示对齐用于微调视频扩散模型|Sungwon Hwang, Hyojin Jang, Kinam Kim, Minho Park, Jaegul Choo|<http://arxiv.org/pdf/2506.09229v2>|提出了一种跨帧表示对齐技术，有效提升了视频扩散模型微调时的视觉保真度和帧间语义一致性。|
|📝 更新|MatSwap: Light-aware material transfers in images|《MatSwap：图像中的光感知材质转换》|Ivan Lopes, Valentin Deschaintre, Yannick Hold-Geoffroy, Raoul de Charette|<http://arxiv.org/pdf/2502.07784v2>|[代码](https://github.com/astra-vision/MatSwap); 提出了一种无需UV映射的直接学习材料与场景外观关系的图像材料转移方法，实现了逼真的材料替换效果。|
|📝 更新|TCDiff++: An End-to-end Trajectory-Controllable Diffusion Model for Harmonious Music-Driven Group Choreography|TCDiff++：一种端到端轨迹可控的扩散模型，用于和谐音乐驱动的群舞编排|Yuqin Dai, Wanlu Zhu, Ronghui Li, Xiu Li, Zhenyu Zhang, Jun Li, Jian Yang|<http://arxiv.org/pdf/2506.18671v2>|提出TCDiff++模型，通过定位嵌入和距离一致性损失解决多舞者碰撞和单舞者脚滑问题，优化音乐驱动的...|
|📝 更新|Image Super-Resolution with Guarantees via Conformalized Generative Models|通过共形化生成模型保证的图像超分辨率|Eduardo Adame, Daniel Csillag, Guilherme Tegoni Goedert|<http://arxiv.org/pdf/2502.09664v2>|提出了一种基于 conformal 预测技术的图像超分辨率方法，通过生成 '置信遮罩' 来可靠地传达...|
|🆕 发布|FundaQ-8: A Clinically-Inspired Scoring Framework for Automated Fundus Image Quality Assessment|FundaQ-8：一种基于临床启发的自动化眼底图像质量评估评分框架|Lee Qi Zun, Oscar Wong Jin Hao, Nor Anita Binti Che Omar, Zalifa Zakiah Binti Asnir, Mohamad Sabri bin Sinal Zainal, Goh Man Fye|<http://arxiv.org/pdf/2506.20303v1>|提出FundaQ-8评分框架，通过八项参数自动化评估眼底图像质量，并借助ResNet18模型预测质量...|
|📝 更新|Mamba Policy: Towards Efficient 3D Diffusion Policy with Hybrid Selective State Models|Mamba策略：面向高效三维扩散策略的混合选择性状态模型|Jiahang Cao, Qiang Zhang, Jingkai Sun, Jiaxu Wang, Hao Cheng, Yulin Li, Jun Ma, Kun Wu .etc.|<http://arxiv.org/pdf/2409.07163v2>|[代码](https://andycao1125.github.io/mamba_policy); 提出Mamba Policy，一种轻量级3D扩散策略，减少80%参数量，提升性能和长时序鲁棒性。|
|📝 更新|ReconX: Reconstruct Any Scene from Sparse Views with Video Diffusion Model|ReconX：利用视频扩散模型从稀疏视角重建任意场景|Fangfu Liu, Wenqiang Sun, Hanyang Wang, Yikai Wang, Haowen Sun, Junliang Ye, Jun Zhang, Yueqi Duan|<http://arxiv.org/pdf/2408.16767v4>|提出ReconX，利用视频扩散模型从稀疏视角重建高质量3D场景。|
|📝 更新|Morse: Dual-Sampling for Lossless Acceleration of Diffusion Models|莫尔斯：双向采样实现无损加速扩散模型|Chao Li, Jiawei Fan, Anbang Yao|<http://arxiv.org/pdf/2506.18251v2>|[代码](https://github.com/deep-optimization/Morse.); 提出了一种无需损失加速扩散模型的双采样框架Morse，通过快跳采样和自适应残差反馈策略提升图像生成效...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Shape2Animal: Creative Animal Generation from Natural Silhouettes|《Shape2Animal：从自然轮廓生成创意动物》|Quoc-Duy Tran, Anh-Tuan Vo, Dinh-Khoi Vo, Tam V. Nguyen, Minh-Triet Tran, Trung-Nghia Le|<http://arxiv.org/pdf/2506.20616v1>|提出Shape2Animal框架，将自然物体轮廓转化为动物形象，实现创意视觉合成。|
|🆕 发布|Video Perception Models for 3D Scene Synthesis|用于三维场景合成的视频感知模型|Rui Huang, Guangyao Zhai, Zuria Bauer, Marc Pollefeys, Federico Tombari, Leonidas Guibas, Gao Huang, Francis Engelmann|<http://arxiv.org/pdf/2506.20601v1>|提出了一种利用视频生成模型编码的常识知识进行3D场景合成的VIPScene框架，实现了高真实感和结构...|
|🆕 发布|WonderFree: Enhancing Novel View Quality and Cross-View Consistency for 3D Scene Exploration|“WonderFree：提升三维场景探索中新视角质量和跨视角一致性”|Chaojun Ni, Jie Li, Haoyun Li, Hengyu Liu, Xiaofeng Wang, Zheng Zhu, Guosheng Zhao, Boyuan Wang .etc.|<http://arxiv.org/pdf/2506.20590v1>|提出了一种交互式3D场景生成模型WonderFree，通过分离视觉质量和视角一致性两大问题，实现了自...|
|🆕 发布|Dense Video Captioning using Graph-based Sentence Summarization|基于图句摘要的密集视频标注|Zhiwang Zhang, Dong Xu, Wanli Ouyang, Luping Zhou|<http://arxiv.org/pdf/2506.20583v1>|提出图基分割与总结框架，通过细化视频片段和语义词图卷积，提升长视频事件描述的准确性。|
|📝 更新|ViStoryBench: Comprehensive Benchmark Suite for Story Visualization|ViStoryBench：故事可视化全面基准测试套件|Cailin Zhuang, Ailin Huang, Wei Cheng, Jingwei Wu, Yaoqi Hu, Jiaqi Liao, Zhewei Huang, Hongyuan Wang .etc.|<http://arxiv.org/pdf/2505.24862v2>|提出了ViStoryBench，一个全面的评估基准，用于测试故事可视化模型在不同故事类型和艺术风格上...|
|🆕 发布|Opportunistic Osteoporosis Diagnosis via Texture-Preserving Self-Supervision, Mixture of Experts and Multi-Task Integration|通过纹理保持自监督、专家混合和多任务融合的骨质疏松症机会性诊断|Jiaxing Huang, Heng Guo, Le Lu, Fan Yang, Minfeng Xu, Ge Yang, Wei Luo|<http://arxiv.org/pdf/2506.20282v1>|提出了一种利用纹理保持自监督学习、混合专家模型和多任务融合的深度学习框架，用于提高骨质疏松症的机遇性...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TRIM: A Self-Supervised Video Summarization Framework Maximizing Temporal Relative Information and Representativeness|TRIM：一种最大化时间相对信息与代表性的自监督视频摘要框架|Pritam Mishra, Coloma Ballester, Dimosthenis Karatzas|<http://arxiv.org/pdf/2506.20588v1>|提出了一种无需监督标注、基于马尔可夫过程的自我监督视频摘要框架，实现了时空依赖性的高效捕获并达到领先...|
|📝 更新|PanoWan: Lifting Diffusion Video Generation Models to 360° with Latitude/Longitude-aware Mechanisms|PanoWan：利用纬度/经度感知机制将扩散视频生成模型提升至360°全景|Yifei Xia, Shuchen Weng, Siqi Yang, Jingqi Liu, Chengxuan Zhu, Minggui Teng, Zijian Jia, Han Jiang .etc.|<http://arxiv.org/pdf/2505.22016v2>|提出PanoWan模型，将传统文本到视频生成模型扩展到360度全景视频领域，通过纬度采样和经度边界处...|
|📝 更新|MagicPose4D: Crafting Articulated Models with Appearance and Motion Control|《MagicPose4D：具有外观与运动控制的关节模型的构建》|Hao Zhang, Di Chang, Fang Li, Mohammad Soleymani, Narendra Ahuja|<http://arxiv.org/pdf/2405.14017v4>|提出MagicPose4D框架，通过视频或网格序列实现4D内容生成中更精确的运动控制。|
|🆕 发布|InvZW: Invariant Feature Learning via Noise-Adversarial Training for Robust Image Zero-Watermarking|InvZW：通过噪声对抗训练进行不变特征学习以实现鲁棒图像零水印|Abdullah All Tanvir, Xin Zhong|<http://arxiv.org/pdf/2506.20370v1>|提出了一种基于噪声对抗训练的图像零水印方法，实现了不变特征学习，提高了水印的鲁棒性和稳定性。|
|📝 更新|Skin Color Measurement from Dermatoscopic Images: An Evaluation on a Synthetic Dataset|皮肤颜色测量：基于合成数据集的皮肤显微镜图像评估|Marin Benčević, Robert Šojo, Irena Galić|<http://arxiv.org/pdf/2504.04494v2>|评估了多种皮肤颜色测量方法在合成数据集上的表现，提出基于分割和颜色量化方法以实现光照不变性。|
|🆕 发布|Towards Efficient Exemplar Based Image Editing with Multimodal VLMs|面向高效基于示例的图像编辑：多模态语言模型辅助方法|Avadhoot Jadhav, Ashutosh Srivastava, Abhinav Java, Silky Singh, Tarun Ram Menta, Surgan Jandial, Balaji Krishnamurthy|<http://arxiv.org/pdf/2506.20155v1>|利用预训练模型和 multimodal VLMs 实现高效示例图像编辑，无需优化即可超越基准。|
|🆕 发布|BrokenVideos: A Benchmark Dataset for Fine-Grained Artifact Localization in AI-Generated Videos|《BrokenVideos：一个用于AI生成视频中细粒度伪迹定位的基准数据集》|Jiahao Lin, Weixuan Peng, Bojia Zi, Yifeng Gao, Xianbiao Qi, Xingjun Ma, Yu-Gang Jiang|<http://arxiv.org/pdf/2506.20103v1>|[代码](https://broken-video-detection-datetsets.github.io/Broken-Video-Detection-Datasets.github.io); 提出了 BrokenVideos 数据集，为 AI 视频生成中的细粒度瑕疵定位提供了高质量标注基准。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects|联合姿态估计与非合作空间目标的3D神经重建|Clément Forray, Pauline Delporte, Nicolas Delaygue, Florence Genin, Dawa Derksen|<http://arxiv.org/pdf/2506.20638v1>|提出了一种结合姿态估计和神经辐射场的三维重建方法，有效处理了非合作空间物体的建模难题。|
|🆕 发布|Disentangled representations of microscopy images|显微镜图像的解耦表示|Jacopo Dapueto, Vito Paolo Pastore, Nicoletta Noceti, Francesca Odone|<http://arxiv.org/pdf/2506.20649v1>|提出了一种用于显微镜图像分类的解耦表示学习策略，通过合成数据迁移学习提高了准确性与可解释性。|
|📝 更新|Neural Graph Map: Dense Mapping with Efficient Loop Closure Integration|神经图映射：具有高效闭环集成的稠密映射|Leonard Bruns, Jun Zhang, Patric Jensfelt|<http://arxiv.org/pdf/2405.03633v2>|[代码](https://github.com/KTH-RPL/neural_graph_mapping.); 提出了一种基于多个轻量级神经场的RGB-D映射框架，有效整合大规模闭环约束并提升映射质量与效率。|
|📝 更新|Matching-Free Depth Recovery from Structured Light|从结构光中无需匹配的深度恢复|Zhuohang Yu, Kai Wang, Kun Huang, Juyong Zhang|<http://arxiv.org/pdf/2501.07113v2>|提出了一种无需匹配的深度估计方法，使用密度体素网格和自监督可微分体积渲染，实现了更快的收敛速度和高质...|
|📝 更新|USP-Gaussian: Unifying Spike-based Image Reconstruction, Pose Correction and Gaussian Splatting|统一基于尖峰的图像重建、姿态校正和高斯散布的USP-Gaussian方法|Kang Chen, Jiyuan Zhang, Zecheng Hao, Yajing Zheng, Tiejun Huang, Zhaofei Yu|<http://arxiv.org/pdf/2411.10504v2>|[代码](https://github.com/chenkang455/USP-Gaussian.); 提出了一个统一的优化框架USP-Gaussian，将基于脉冲的图像重建、姿态校正和 Gaussian...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning-Based Distance Estimation for 360° Single-Sensor Setups|基于学习的360°单传感器设置中的距离估计|Yitong Quan, Benjamin Kiefer, Martin Messmer, Andreas Zell|<http://arxiv.org/pdf/2506.20586v1>|提出了一种基于神经网络的单目360°鱼眼镜头距离估计方法，提高了准确性和适应性。|
|📝 更新|ULSR-GS: Ultra Large-scale Surface Reconstruction Gaussian Splatting with Multi-View Geometric Consistency|ULSR-GS: 超大规模表面重建多视角几何一致性高斯散点法|Zhuoxiao Li, Shanliang Yao, Taoyu Wu, Yong Yue, Wufan Zhao, Rongjun Qin, Angel F. Garcia-Fernandez, Andrew Levers .etc.|<http://arxiv.org/pdf/2412.01402v3>|提出ULSR-GS框架，通过多视角几何一致性优化大尺度场景表面重建精度。|
|📝 更新|TT3D: Table Tennis 3D Reconstruction|乒乓球三维重建：TT3D|Thomas Gossard, Andreas Ziegler, Andreas Zell|<http://arxiv.org/pdf/2504.10035v2>|提出了一种利用物理原理从乒乓球比赛视频重建精确3D球轨迹的新方法。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Dark Channel-Assisted Depth-from-Defocus from a Single Image|单幅图像中基于暗通道辅助的去焦深度估计|Moushumi Medhi, Rajiv Ranjan Sahay|<http://arxiv.org/pdf/2506.06643v2>|利用暗通道统计信息，提出单张模糊图像深度估计新方法，有效解决深度估计问题。|
|📝 更新|FGS-SLAM: Fourier-based Gaussian Splatting for Real-time SLAM with Sparse and Dense Map Fusion|基于傅里叶的高斯散布法实现稀疏与稠密地图融合的实时SLAM：FGS-SLAM|Yansong Xu, Junlin Li, Wei Zhang, Siyu Chen, Shengyong Zhang, Yuquan Leng, Weijia Zhou|<http://arxiv.org/pdf/2503.01109v2>|引入基于傅里叶分析的自适应密度方法，实现实时SLAM中高保真高斯映射。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VideoRFT: Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning|视频RFT：通过强化微调激励多模态大型语言模型中的视频推理能力|Qi Wang, Yanrui Yu, Ye Yuan, Rui Mao, Tianfei Zhou|<http://arxiv.org/pdf/2505.12434v2>|提出VIDEORFT方法，通过自动构建链式思维注释数据集增强多模态语言模型对视频的推理能力。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Predictive Modeling, Pattern Recognition, and Spatiotemporal Representations of Plant Growth in Simulated and Controlled Environments: A Comprehensive Review|植物生长在模拟和控制环境中的预测建模、模式识别与时空表征：全面综述|Mohamed Debbagh, Shangpeng Sun, Mark Lefsrud|<http://arxiv.org/pdf/2412.10538v3>|综述了植物生长预测模型与识别技术，强调结合环境动态与数据驱动方法的重要性。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Time-Aware Auto White Balance in Mobile Photography|时间感知自动白平衡在移动摄影中的应用|Mahmoud Afifi, Luxi Zhao, Abhijith Punnappurath, Mohammed A. Abdelsalam, Ran Zhang, Michael S. Brown|<http://arxiv.org/pdf/2504.05623v2>|利用手机摄影中的时间地理 metadata 改进自动白平衡，提出轻量级模型实现优于大型模型的性能。|
|🆕 发布|On the Burstiness of Faces in Set|论集合中面部图像的突发性|Jiong Wang|<http://arxiv.org/pdf/2506.20312v1>|提出策略检测并抑制人脸集合中的爆发性现象，有效提升集合式人脸识别性能。|
|🆕 发布|Radiomic fingerprints for knee MR images assessment|膝关节磁共振成像的放射组学指纹评估|Yaxi Chen, Simin Ni, Shaheer U. Saeed, Aleksandra Ivanova, Rikin Hargunani, Jie Huang, Chaozong Liu, Yipeng Hu|<http://arxiv.org/pdf/2506.20306v1>|提出了一种个性化的放射学特征选择框架，通过深度学习模型为每位患者动态构建特征集合，提高了膝关节MRI...|
|📝 更新|ZigzagPointMamba: Spatial-Semantic Mamba for Point Cloud Understanding|“之字形点魔霸：用于点云理解的空间语义魔霸”|Linshuang Diao, Dayong Ren, Sensen Song, Yurong Qian|<http://arxiv.org/pdf/2505.21381v4>|提出ZigzagPointMamba方法，通过优化点云序列和引入语义相似掩码，增强点云理解和下游任务...|
|🆕 发布|Dynamic Bandwidth Allocation for Hybrid Event-RGB Transmission|动态带宽分配用于混合事件-RGB传输|Pujing Yang, Guangyi Zhang, Yunlong Cai, Lei Yu, Guanding Yu|<http://arxiv.org/pdf/2506.20222v1>|提出了一种动态分配带宽的传输方案，通过消除事件和图像间的冗余信息，优化了混合事件-RGB系统的带宽利...|
|🆕 发布|Loss-Aware Automatic Selection of Structured Pruning Criteria for Deep Neural Network Acceleration|损失感知的深度神经网络加速中结构剪枝准则的自动选择|Deepak Ghimire, Kilho Lee, Seong-heum Kim|<http://arxiv.org/pdf/2506.20152v1>|[代码](https://github.com/ghimiredhikura/laasp.); 提出了一种自动选择结构剪枝标准的损失感知方法，有效压缩神经网络并提升边缘设备上的加速性能。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Practical insights on the effect of different encodings, ansätze and measurements in quantum and hybrid convolutional neural networks|不同编码、基组选择和测量方法对量子与混合卷积神经网络影响的实用见解|Jesús Lozano-Cruz, Albert Nieto-Morales, Oriol Balló-Gimbernat, Adan Garriga, Antón Rodríguez-Otero, Alejandro Borrallo-Rentero|<http://arxiv.org/pdf/2506.20355v1>|分析了量子与混合卷积神经网络的设计选择对卫星图像分类的影响，发现数据编码策略对性能影响最大。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Ideal to Real: Unified and Data-Efficient Dense Prediction for Real-World Scenarios|从理想到现实：面向实际场景的统一且数据高效稠密预测|Changliang Xia, Chengyou Jia, Zhuohang Dang, Minnan Luo|<http://arxiv.org/pdf/2506.20279v1>|[代码](https://xcltql666.github.io/DenseDiTProj); 提出DenseWorld基准和DenseDiT方法，通过统一策略和少量数据实现现实场景的高效密集预测...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Provably Improving Generalization of Few-Shot Models with Synthetic Data|用合成数据证明性改进少量样本模型的泛化能力|Lan-Cuong Nguyen, Quan Nguyen-Tri, Bang Tran Khanh, Dung D. Le, Long Tran-Thanh, Khoat Than|<http://arxiv.org/pdf/2505.24190v2>|提出理论框架量化合成数据对模型泛化影响，并设计算法优化数据划分与训练，提升少量样本学习性能。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Causal Representation Learning with Observational Grouping for CXR Classification|因果表示学习结合观测分组用于胸部X射线影像分类|Rajat Rasal, Avinash Kori, Ben Glocker|<http://arxiv.org/pdf/2506.20582v1>|引入观测分组学习因果表示，增强胸部X射线疾病分类的泛化性和鲁棒性。|
|🆕 发布|A Deep Learning Approach to Identify Rock Bolts in Complex 3D Point Clouds of Underground Mines Captured Using Mobile Laser Scanners|地下矿山移动激光扫描捕获的复杂三维点云中识别锚杆的深度学习方法|Dibyayan Patra, Pasindu Ranasinghe, Bikram Banerjee, Simit Raval|<http://arxiv.org/pdf/2506.20464v1>|提出DeepBolt方法，利用深度学习高效识别地下矿井复杂3D点云中的岩栓。|
|📝 更新|Learning Adaptive Lighting via Channel-Aware Guidance|通过通道感知引导学习自适应照明|Qirui Yang, Peng-Tao Jiang, Hao Zhang, Jinwei Chen, Bo Li, Huanjing Yue, Jingyu Yang|<http://arxiv.org/pdf/2412.01493v2>|[代码](https://xxxxxx2025.github.io/LALNet); 提出了一种多任务框架LALNet，通过颜色分离特征和光引导注意力，有效处理多种光照相关任务。|
|🆕 发布|Learning Moderately Input-Sensitive Functions: A Case Study in QR Code Decoding|学习适度输入敏感函数：以二维码解码为例的研究|Kazuki Yoda, Kazuhiko Kawamoto, Hiroshi Kera|<http://arxiv.org/pdf/2506.20305v1>|探究中等敏感度函数学习，利用Transformer成功解码QR码，超越传统错误纠正限制。|
|🆕 发布|FedBKD: Distilled Federated Learning to Embrace Gerneralization and Personalization on Non-IID Data|FedBKD：在非独立同分布数据上融合泛化与个性化的联邦学习知识蒸馏方法|Yushan Zhao, Jinyuan He, Donglai Chen, Weijie Luo, Chong Xie, Ri Zhang, Yonghong Chen, Yan Xu|<http://arxiv.org/pdf/2506.20245v1>|提出FedBKD框架，通过生成对抗网络和双向知识蒸馏同时提升联邦学习中的全局泛化与本地个性化性能。|
|🆕 发布|Progressive Alignment Degradation Learning for Pansharpening|渐进对齐退化学习用于全色锐化|Enzhe Zhao, Zhichang Guo, Yao Li, Fanghui Song, Boying Wu|<http://arxiv.org/pdf/2506.20179v1>|提出了一种自适应学习精确退化过程的 pansharpening 方法，显著提升了图像的空间清晰度和质...|
|📝 更新|BeltCrack: the First Sequential-image Industrial Conveyor Belt Crack Detection Dataset and Its Baseline with Triple-domain Feature Learning|“BeltCrack：首个基于序列图像的工业输送带裂纹检测数据集及其三域特征学习基线”|Jianghong Huang, Luping Ji, Xin Ma, Mao Ye|<http://arxiv.org/pdf/2506.17892v2>|[代码](https://github.com/UESTC-nnLab/BeltCrack.); 提出了首个顺序图像工业传送带裂纹检测数据集，并使用三域特征学习方法显著提升了检测效果。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VLN-R1: Vision-Language Navigation via Reinforcement Fine-Tuning|VLN-R1：通过强化微调的视觉-语言导航|Zhangyang Qi, Zhixiong Zhang, Yizhou Yu, Jiaqi Wang, Hengshuang Zhao|<http://arxiv.org/pdf/2506.17221v2>|提出VLN-R1框架，利用大型视觉语言模型直接将视频流转化为连续导航动作，并通过强化微调提升路径规划...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|IPFormer: Visual 3D Panoptic Scene Completion with Context-Adaptive Instance Proposals|IPFormer：基于上下文自适应实例提议的视觉3D全景场景补全|Markus Gross, Aya Fahmy, Danit Niwattananan, Dominik Muhle, Rui Song, Daniel Cremers, Henri Meeß|<http://arxiv.org/pdf/2506.20671v1>|IPFormer通过引入基于图像上下文的动态实例提议，实现了视觉3D全景场景完成的性能提升。|
|🆕 发布|HRIBench: Benchmarking Vision-Language Models for Real-Time Human Perception in Human-Robot Interaction|HRIBench：面向人机交互中实时人类感知的视觉-语言模型基准测试|Zhonghao Shi, Enyu Zhao, Nathaniel Dennler, Jingzhen Wang, Xinyang Xu, Kaleen Shrestha, Mengxue Fu, Daniel Seita .etc.|<http://arxiv.org/pdf/2506.20566v1>|[代码](https://github.com/interaction-lab/HRIBench.); 提出HRIBench基准，评估视觉语言模型在实时人机交互中的感知能力及性能延迟权衡。|
|🆕 发布|Exploiting Lightweight Hierarchical ViT and Dynamic Framework for Efficient Visual Tracking|利用轻量级分层ViT和动态框架进行高效视觉跟踪|Ben Kang, Xin Chen, Jie Zhao, Chunjuan Bo, Dong Wang, Huchuan Lu|<http://arxiv.org/pdf/2506.20381v1>|提出轻量级HiT模型和动态DyHiT跟踪器，提升视觉跟踪速度与准确性。|
|📝 更新|It's not you, it's me -- Global urban visual perception varies across demographics and personalities|“并非是你，而是我——全球城市视觉感知随人口统计特征和个人性格而变化”|Matias Quintana, Youlong Gu, Xiucheng Liang, Yujun Hou, Koichi Ito, Yihan Zhu, Mahmoud Abdelrahman, Filip Biljecki|<http://arxiv.org/pdf/2505.12758v2>|揭示了不同人口统计特征和个性特质对全球城市视觉感知的差异，提出考虑这些因素的 Street Perc...|
|📝 更新|Sampling Matters in Explanations: Towards Trustworthy Attribution Analysis Building Block in Visual Models through Maximizing Explanation Certainty|样本选择在解释中至关重要：通过最大化解释确定性构建视觉模型中值得信赖的归因分析基石|Róisín Luo, James McDermott, Colm O'Riordan|<http://arxiv.org/pdf/2506.19442v2>|提出通过特征抑制的半最优采样方法，以解决样本分布偏差问题，提升视觉模型解释的确定性。|
|📝 更新|Visual and Textual Prompts in VLLMs for Enhancing Emotion Recognition|视觉和文本提示在大型视觉语言模型中增强情感识别的应用|Zhifeng Wang, Qixuan Zhang, Peter Zhang, Wenjia Niu, Kaihao Zhang, Ramesh Sankaranarayana, Sabrina Caldwell, Tom Gedeon|<http://arxiv.org/pdf/2504.17224v2>|提出SoVTP框架，整合空间注释和情境线索，提升视觉语言模型在视频情感识别中的表现。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MMSearch-R1: Incentivizing LMMs to Search|MMSearch-R1：激励大型模型进行搜索|Jinming Wu, Zihao Deng, Wei Li, Yiding Liu, Bo You, Bo Li, Zejun Ma, Ziwei Liu|<http://arxiv.org/pdf/2506.20670v1>|首次提出端到端强化学习框架MMSearch-R1，使大型多模态模型在现实互联网环境中按需进行多轮搜索...|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Show, Tell and Summarize: Dense Video Captioning Using Visual Cue Aided Sentence Summarization|展示、描述与总结：基于视觉线索辅助的句子摘要进行密集视频标注|Zhiwang Zhang, Dong Xu, Wanli Ouyang, Chuanqi Tan|<http://arxiv.org/pdf/2506.20567v1>|提出分治总结框架，通过视觉线索辅助的句子摘要实现密集视频标注。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|From $\mathcal{O}(n^{2})$ to $\mathcal{O}(n)$ Parameters: Quantum Self-Attention in Vision Transformers for Biomedical Image Classification|从 $\mathcal{O}(n^{2})$ 到 $\mathcal{O}(n)$ 参数：量子自注意力在视觉变换器中的生物医学图像分类应用|Thomas Boucher, John Whittle, Evangelos B. Mazomenos|<http://arxiv.org/pdf/2503.07294v2>|提出量子自注意力机制，实现视变换器参数从平方级降至线性级，大幅提升生物医学图像分类效率。|
|🆕 发布|AI-assisted radiographic analysis in detecting alveolar bone-loss severity and patterns|基于人工智能的放射学图像分析在检测肺泡骨丢失严重程度及模式中的应用|Chathura Wimalasiri, Piumal Rathnayake, Shamod Wijerathne, Sumudu Rasnayaka, Dhanushka Leuke Bandara, Roshan Ragel, Vajira Thambawita, Isuru Nawinne|<http://arxiv.org/pdf/2506.20522v1>|提出了一种深度学习框架，自动检测和量化牙槽骨丢失程度及其模式，提高牙周病诊断和治疗计划的准确性。|
|🆕 发布|Lightweight Multi-Frame Integration for Robust YOLO Object Detection in Videos|轻量级多帧融合用于视频中鲁棒的YOLO目标检测|Yitong Quan, Benjamin Kiefer, Martin Messmer, Andreas Zell|<http://arxiv.org/pdf/2506.20550v1>|提出了一种简单有效的多帧集成策略，通过叠加连续帧增强YOLO检测模型的鲁棒性。|
|🆕 发布|AdvMIM: Adversarial Masked Image Modeling for Semi-Supervised Medical Image Segmentation|对抗性遮蔽图像建模AdvMIM：用于半监督医学图像分割|Lei Zhu, Jun Zhou, Rick Siow Mong Goh, Yong Liu|<http://arxiv.org/pdf/2506.20563v1>|[代码](https://github.com/zlheui/AdvMIM.); 提出了一种对抗性掩码图像建模方法，通过增加监督信号和减少域差距，有效提升半监督医疗图像分割性能。|
|📝 更新|CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation|《基于临床指导的LGE增强方法用于真实且多样化的心肌疤痕合成与分割》|Farheen Ramzan, Yusuf Kiberu, Nikesh Jathanna, Shahnaz Jamil-Copley, Richard H. Clayton, Chen Chen|<http://arxiv.org/pdf/2506.15549v2>|[代码](https://github.com/farheenjabeen/CLAIM-Scar-Synthesis.); 提出了一种临床指导的LGE图像增强框架，实现了真实且多样化的心肌疤痕合成与分割。|
|📝 更新|LVPNet: A Latent-variable-based Prediction-driven End-to-end Framework for Lossless Compression of Medical Images|LVPNet：一种基于潜在变量预测驱动的端到端框架，用于医学图像的无损压缩|Chenyue Song, Chen Hui, Qing Lin, Wei Zhang, Siqiao Li, Haiqi Zhu, Zhixuan Li, Shengping Zhang .etc.|<http://arxiv.org/pdf/2506.17983v2>|[代码](https://github.com/scy-Jackel/LVPNet.); 提出了一种基于全局变量预测的医学图像无损压缩方法LVPNet，有效解决了信息分布不均和量化损失问题。|
|🆕 发布|Med-Art: Diffusion Transformer for 2D Medical Text-to-Image Generation|医艺：二维医学文本到图像生成的扩散变换器|Changlu Guo, Anders Nymark Christensen, Morten Rieger Hannemose|<http://arxiv.org/pdf/2506.20449v1>|提出Med-Art框架，利用预训练模型和Hybrid-Level Diffusion Fine-tu...|
|🆕 发布|Fusing Radiomic Features with Deep Representations for Gestational Age Estimation in Fetal Ultrasound Images|融合放射组学特征与深度表示进行胎儿超声图像中孕龄估计|Fangyijie Wang, Yuan Liang, Sourav Bhattacharjee, Abey Campbell, Kathleen M. Curran, Guénolé Silvestre|<http://arxiv.org/pdf/2506.20407v1>|[代码](https://github.com/13204942/RadiomicsImageFusion_FetalUS); 提出了一种融合放射学特征与深度学习表示的新框架，有效估计胎儿孕周，提升了自动化计算的准确性和鲁棒性。|
|📝 更新|Self-Supervised Multimodal NeRF for Autonomous Driving|自监督多模态神经辐射场技术在自动驾驶中的应用|Gaurav Sharma, Ravi Kothari, Josef Schmid|<http://arxiv.org/pdf/2506.19615v2>|[代码](https://github.com/gaurav00700/Selfsupervised-NVSF); 提出了一种自监督的多模态NeRF框架，无需3D标签即可学习静态和动态场景的时空表示。|
|🆕 发布|EAGLE: An Efficient Global Attention Lesion Segmentation Model for Hepatic Echinococcosis|EAGLE：一种针对肝包虫病的高效全局注意力病变分割模型|Jiayan Chen, Kai Li, Yulu Zhao, Jianqiang Huang, Zhan Wang|<http://arxiv.org/pdf/2506.20333v1>|提出EAGLE模型，融合状态空间模型与卷积网络，高效准确分割肝包虫病病变。|
|📝 更新|MambaMorph: a Mamba-based Framework for Medical MR-CT Deformable Registration|基于Mamba的医疗MR-CT可变形配准框架：MambaMorph|Tao Guo, Yinuo Wang, Shihao Shu, Weimin Yuan, Diansheng Chen, Zhouping Tang, Cai Meng, Xiangzhi Bai|<http://arxiv.org/pdf/2401.13934v5>|[代码](https://github.com/Guo-Stone/MambaMorph.); 提出了MambaMorph框架，通过高效的长距离对应建模和高维特征学习，显著提升了多模态医学图像配准...|
|🆕 发布|Breaking Spatial Boundaries: Spectral-Domain Registration Guided Hyperspectral and Multispectral Blind Fusion|突破空间边界：基于频域注册引导的hyperspectral与multispectral盲融合|Kunjing Yang, Libin Zheng, Minru Bai, Ting Lu, Leyuan Fang|<http://arxiv.org/pdf/2506.20293v1>|提出了一种光谱域注册引导的融合方法，通过光谱特征提取和稀疏融合技术，有效解决了高光谱与多光谱图像盲融...|
|🆕 发布|X-SiT: Inherently Interpretable Surface Vision Transformers for Dementia Diagnosis|X-SiT：固有可解释性表面视觉变换器用于痴呆症诊断|Fabian Bongratz, Tom Nuno Wolf, Jaume Gual Ramon, Christian Wachinger|<http://arxiv.org/pdf/2506.20267v1>|提出X-SiT模型，通过可解释的皮质特征实现痴呆症诊断的高性能与可理解性。|
|📝 更新|WoundAmbit: Bridging State-of-the-Art Semantic Segmentation and Real-World Wound Care|《WoundAmbit：连接最先进的语义分割与实际伤口护理》|Vanessa Borst, Timo Dittus, Tassilo Dege, Astrid Schmieder, Samuel Kounev|<http://arxiv.org/pdf/2504.06185v2>|提出WoundAmbit框架，利用先进语义分割技术实现远程伤口监测与尺寸估计。|
|🆕 发布|MS-IQA: A Multi-Scale Feature Fusion Network for PET/CT Image Quality Assessment|MS-IQA：一种用于PET/CT图像质量评估的多尺度特征融合网络|Siqiao Li, Chen Hui, Wei Zhang, Rui Liang, Chenyue Song, Feng Jiang, Haiqi Zhu, Zhixuan Li .etc.|<http://arxiv.org/pdf/2506.20200v1>|[代码](https://github.com/MS-IQA/MS-IQA); 提出MS-IQA网络，融合多尺度特征以提升PET/CT图像质量评估准确性。|
|📝 更新|C3S3: Complementary Competition and Contrastive Selection for Semi-Supervised Medical Image Segmentation|C3S3：互补竞争与对比选择用于半监督医学图像分割|Jiaying He, Yitong Lin, Jiahe Chen, Honghui Xu, Jianwei Zheng|<http://arxiv.org/pdf/2506.07368v2>|[代码](https://github.com/Y-TARL/C3S3.); 提出C3S3模型，通过互补竞争和对比选择提升半监督医疗图像分割的边界精度。|
|📝 更新|Low-light Pedestrian Detection in Visible and Infrared Image Feeds: Issues and Challenges|可见光与红外图像流中低光照行人检测：问题与挑战|Thangarajah Akilan, Hrishikesh Vachhani|<http://arxiv.org/pdf/2311.08557v3>|系统分析了低光条件下行人检测的算法及其挑战，为夜间自动驾驶等应用提供了研究基础。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SFNet: Fusion of Spatial and Frequency-Domain Features for Remote Sensing Image Forgery Detection|SFNet：空间域与频域特征融合的遥感图像伪造检测|Ji Qi, Xinchang Zhang, Dingqi Ye, Yongjia Ruan, Xin Guo, Shaowen Wang, Haifeng Li|<http://arxiv.org/pdf/2506.20599v1>|[代码](https://github.com/GeoX-Lab/RSTI); 提出了一种融合空间域和频域特征的SFNet框架，有效提高了遥感图像伪造检测的准确性和泛化能力。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|An Agentic System for Rare Disease Diagnosis with Traceable Reasoning|用于罕见病诊断的可追踪推理的代理系统|Weike Zhao, Chaoyi Wu, Yanjie Fan, Xiaoman Zhang, Pengcheng Qiu, Yuze Sun, Xiao Zhou, Yanfeng Wang .etc.|<http://arxiv.org/pdf/2506.20430v1>|提出了一种基于大型语言模型的罕见病诊断系统DeepRare，实现了高准确率诊断并提供了可追踪的诊断推...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Forensic Study of Paintings Through the Comparison of Fabrics|绘画通过织物比较的法庭科学研究|Juan José Murillo-Fuentes, Pablo M. Olmos, Laura Alba-Carcelén|<http://arxiv.org/pdf/2506.20272v1>|利用深度学习评估织物相似性，为艺术品鉴定提供了一种无需依赖密度图的自动方法。|

