## [UPDATED!] **2025-06-27** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Vision Transformers Don't Need Trained Registers|视觉变换器无需训练寄存器|Nick Jiang, Amil Dravid, Alexei Efros, Yossi Gandelsman|<http://arxiv.org/pdf/2506.08010v4>|提出了一种无需重新训练的解决视觉变换器中异常注意力图的方法，通过转移高范数激活至未训练的额外令牌。|
|🆕 发布|Test-Time Consistency in Vision Language Models|视觉语言模型中的测试时一致性|Shih-Han Chou, Shivam Chandhok, James J. Little, Leonid Sigal|<http://arxiv.org/pdf/2506.22395v1>|提出了一种无需监督重训练的测试时一致性框架，通过两个互补目标增强了视觉语言模型在语义等效输入下的预测...|
|🆕 发布|From Ground to Air: Noise Robustness in Vision Transformers and CNNs for Event-Based Vehicle Classification with Potential UAV Applications|从地面到空中：基于事件的车辆分类中视觉变换器和卷积神经网络的噪声鲁棒性研究及其在潜在无人机应用中的探讨|Nouf Almesafri, Hector Figueiredo, Miguel Arana-Catania|<http://arxiv.org/pdf/2506.22360v1>|研究了基于事件相机的事件分类中CNN和Vision Transformer的噪声鲁棒性，ViT B1...|
|🆕 发布|Reasoning in machine vision: learning to think fast and slow|计算机视觉中的推理：学习快速与缓慢思考|Shaheer U. Saeed, Yipei Wang, Veeru Kasivisvanathan, Brian R. Davidson, Matthew J. Clarkson, Yipeng Hu, Daniel C. Alexander|<http://arxiv.org/pdf/2506.22075v1>|提出了一种模拟人类认知的机器视觉推理方法，通过增加推理时间提升性能，适用于数据稀缺场景。|
|🆕 发布|TASeg: Text-aware RGB-T Semantic Segmentation based on Fine-tuning Vision Foundation Models|基于微调视觉基础模型的文本感知RGB-T语义分割：TASeg|Meng Yu, Te Cui, Qitong Chu, Wenjie Song, Yi Yang, Yufeng Yue|<http://arxiv.org/pdf/2506.21975v1>|提出TASeg框架，通过融合文本信息和多模态视觉特征，提升RGB-T图像的语义分割准确性。|
|🆕 发布|Physical Degradation Model-Guided Interferometric Hyperspectral Reconstruction with Unfolding Transformer|基于物理退化模型引导的展开变换器干涉超光谱重建|Yuansheng Li, Yunhao Zou, Linwei Chen, Ying Fu|<http://arxiv.org/pdf/2506.21880v1>|提出了一种基于物理退化模型和展开变换器的干涉成像光谱重建方法，有效解决了数据缺乏和特定退化成分消除难...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Can Video Large Multimodal Models Think Like Doubters-or Double-Down: A Study on Defeasible Video Entailment|视频大型多模态模型能否像怀疑者一样思考或加倍下注：对可辩驳视频蕴含的研究|Yue Zhang, Jilei Sun, Yunhui Guo, Vibhav Gogate|<http://arxiv.org/pdf/2506.22385v1>|提出Defeasible Video Entailment任务，通过Chain of Counter...|
|🆕 发布|Exploiting Vision Language Model for Training-Free 3D Point Cloud OOD Detection via Graph Score Propagation|利用视觉语言模型进行无需训练的三维点云OOD检测通过图分数传播|Tiankai Chen, Yushu Li, Adam Goodge, Fei Teng, Xulei Yang, Tianrui Li, Xun Xu|<http://arxiv.org/pdf/2506.22375v1>|提出了一种无需训练、基于视觉语言模型的3D点云异常检测方法，通过图分数传播有效提升检测性能。|
|🆕 发布|EAMamba: Efficient All-Around Vision State Space Model for Image Restoration|EAMamba：面向图像修复的高效全方位视觉状态空间模型|Yu-Cheng Lin, Yu-Syuan Xu, Hao-Wei Chen, Hsien-Kai Kuo, Chun-Yi Lee|<http://arxiv.org/pdf/2506.22246v1>|提出EAMamba框架，通过多头部选择性扫描模块和全方位扫描策略，有效降低图像复原任务的计算复杂度并...|
|🆕 发布|Cardiovascular disease classification using radiomics and geometric features from cardiac CT|使用心脏CT的放射组学特征和几何特征进行心血管疾病分类|Ajay Mittal, Raghav Mehta, Omar Todd, Philipp Seeböck, Georg Langs, Ben Glocker|<http://arxiv.org/pdf/2506.22226v1>|[代码](https://github.com/biomedia-mira/grc-net); 提出三阶段心血管疾病分类方法，通过图像分割、注册提取特征，提高分类准确性至87.50%。|
|📝 更新|Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities|统一多模态理解与生成模型：进展、挑战与机遇|Xinjie Zhang, Jintao Guo, Shanshan Zhao, Minghao Fu, Lunhao Duan, Jiakui Hu, Yong Xien Chng, Guo-Hua Wang .etc.|<http://arxiv.org/pdf/2505.02567v4>|[代码](https://github.com/AIDC-AI/Awesome-Unified-Multimodal-Models); 系统梳理了统一多模态理解和生成模型的进展，分类了三种架构范式并探讨了挑战与机遇。|
|🆕 发布|SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model|场景扩散器++：基于生成世界模型的市区规模交通仿真|Shuhan Tan, John Lambert, Hong Jeon, Sakshum Kulshrestha, Yijing Bai, Jing Luo, Dragomir Anguelov, Mingxing Tan .etc.|<http://arxiv.org/pdf/2506.21976v1>|提出了一种端到端的生成世界模型SceneDiffuser++，实现城市规模下的点对点交通模拟。|
|📝 更新|Preemptive Hallucination Reduction: An Input-Level Approach for Multimodal Language Model|抢占式幻觉减少：一种多模态语言模型输入级别的处理方法|Nokimul Hasan Arif, Shadman Rabby, Md Hefzul Hossain Papon, Sabbir Ahmed|<http://arxiv.org/pdf/2505.24007v2>|提出了一种输入级预处理框架，通过自适应选择滤波方法减少大型语言模型中的视觉幻觉问题。|
|📝 更新|Foundation Model Insights and a Multi-Model Approach for Superior Fine-Grained One-shot Subset Selection|基础模型洞察与多模型方法相结合实现卓越的细粒度单次子集选择|Zhijing Wan, Zhixiang Wang, Zheng Wang, Xin Xu, Shin'ichi Satoh|<http://arxiv.org/pdf/2506.14473v2>|探究基础模型在细粒度数据集上的优势并提出RAM-APL多模型选择方法，实现了一致超越传统方法的性能。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|COOCO -- Common Objects Out-of-Context -- Semantic Violation in Scenes: Investigating Multimodal Context in Referential Communication|COOCO -- 上下文外常见物体 -- 场景中的语义违规：探讨指代通信中的多模态上下文|Filippo Merlo, Ece Takmaz, Wenkai Chen, Albert Gatt|<http://arxiv.org/pdf/2506.22274v1>|[代码](https://github.com/cs-nlp-uu/scenereg); 探究视觉语言模型如何依赖场景上下文进行对象引用，引入COOCO数据集评估模型在不同场景下的适应性。|
|🆕 发布|Towards Scalable and Robust White Matter Lesion Localization via Multimodal Deep Learning|面向可扩展和稳健的白质病变定位的多模态深度学习方法|Julia Machnio, Sebastian Nørgaard Llambias, Mads Nielsen, Mostafa Mehdipour Ghazi|<http://arxiv.org/pdf/2506.22041v1>|提出了一种多模态深度学习框架，实现了对白质病变的精确分割和定位，增强了处理缺失模态的灵活性。|
|📝 更新|ScienceBoard: Evaluating Multimodal Autonomous Agents in Realistic Scientific Workflows|科学工作流中评估多模态自主代理的ScienceBoard|Qiushi Sun, Zhoumianze Liu, Chang Ma, Zichen Ding, Fangzhi Xu, Zhangyue Yin, Haiteng Zhao, Zhenyu Wu .etc.|<http://arxiv.org/pdf/2505.19897v2>|[代码](https://qiushisun.github.io/ScienceBoard-Home); 提出ScienceBoard平台，为自动评估多模态智能体在真实科研工作流程中的表现提供了环境和基准。|
|📝 更新|Disentangled and Interpretable Multimodal Attention Fusion for Cancer Survival Prediction|解耦且可解释的多模态注意力融合用于癌症生存预测|Aniek Eijpe, Soufyan Lakbir, Melis Erdal Cesur, Sara P. Oliveira, Sanne Abeln, Wilson Silva|<http://arxiv.org/pdf/2503.16069v2>|提出了一种解耦且可解释的多模态注意力融合框架，有效提升了癌症生存预测的准确性和可解释性。|
|🆕 发布|Few-Shot Segmentation of Historical Maps via Linear Probing of Vision Foundation Models|通过线性探测视觉基础模型的少量样本历史地图分割|Rafael Sterzinger, Marco Peer, Robert Sablatnig|<http://arxiv.org/pdf/2506.21826v1>|[代码](https://github.com/RafaelSterzinger/few-shot-map-segmentation.); 提出了一种利用大型视觉基础模型语义嵌入和参数高效微调的少量样本历史地图分割方法，显著提升了分割性能并...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Bridging the Gap Between Saliency Prediction and Image Quality Assessment|弥合显著性预测与图像质量评估之间的差距|Kirillov Alexey, Andrey Moskalenko, Dmitriy Vatolin|<http://arxiv.org/pdf/2405.04997v2>|揭示了图像质量评估与视觉关注预测之间的关系，并引入了新的关注感知压缩图像数据集进行比较研究。|
|🆕 发布|Boosting Classification with Quantum-Inspired Augmentations|利用量子启发增强提升分类性能|Matthias Tschöpe, Vitor Fortes Rey, Sogo Pierre Sanon, Paul Lukowicz, Nikolaos Palaiodimopoulos, Maximilian Kiefer-Emmanouilidis|<http://arxiv.org/pdf/2506.22241v1>|探究量子启发式数据增强技术，提升图像分类性能。|
|📝 更新|DSAGL: Dual-Stream Attention-Guided Learning for Weakly Supervised Whole Slide Image Classification|双流注意力引导学习：用于弱监督全切片图像分类的方法|Daoxi Cao, Hangbei Cheng, Yijin Li, Ruolin Zhou, Xuehan Zhang, Xinyi Li, Binwei Li, Xuancheng Gu .etc.|<http://arxiv.org/pdf/2505.23341v2>|提出DSAGL框架，通过双流注意力和伪标签生成，有效处理弱监督全切片图像分类问题。|
|🆕 发布|SepFormer: Coarse-to-fine Separator Regression Network for Table Structure Recognition|SepFormer：用于表格结构识别的粗到细分离回归网络|Nam Quan Nguyen, Xuan Phong Pham, Tuan-Anh Tran|<http://arxiv.org/pdf/2506.21920v1>|提出SepFormer模型，通过单步分隔符回归实现表格结构识别，提升了速度和鲁棒性。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ProtoSeg: Interpretable Semantic Segmentation with Prototypical Parts|原型分割：基于原型部分的解释性语义分割|Mikołaj Sacha, Dawid Rymarczyk, Łukasz Struski, Jacek Tabor, Bartosz Zieliński|<http://arxiv.org/pdf/2301.12276v2>|提出ProtoSeg模型，通过训练集相似区块构建预测，增强语义分割的准确性与可解释性。|
|📝 更新|ReME: A Data-Centric Framework for Training-Free Open-Vocabulary Segmentation|ReME：一种无需训练的数据驱动开放词汇分割框架|Xiwei Xuan, Ziquan Deng, Kwan-Liu Ma|<http://arxiv.org/pdf/2506.21233v2>|[代码](https://github.com/xiweix/ReME); 提出数据质量导向框架，通过构建高质量参考集提升无训练开放词汇语义分割性能。|
|📝 更新|Split Matching for Inductive Zero-shot Semantic Segmentation|分裂匹配：用于归纳零样本语义分割的方法|Jialei Chen, Xu Zheng, Dongyue Li, Chong Yi, Seigo Ito, Danda Pani Paudel, Luc Van Gool, Hiroshi Murase .etc.|<http://arxiv.org/pdf/2505.05023v2>|提出Split Matching方法，通过解耦匹配策略提升零样本语义分割性能。|
|🆕 发布|Partial CLIP is Enough: Chimera-Seg for Zero-shot Semantic Segmentation|"部分CLIP足矣：Chimera-Seg用于零样本语义分割"|Jialei Chen, Xu Zheng, Danda Pani Paudel, Luc Van Gool, Hiroshi Murase, Daisuke Deguchi|<http://arxiv.org/pdf/2506.22032v1>|提出Chimera-Seg模型，融合分割模型与CLIP视觉语言对齐，通过选择性全局蒸馏和语义对齐提升...|
|📝 更新|Leveraging Semantic Asymmetry for Precise Gross Tumor Volume Segmentation of Nasopharyngeal Carcinoma in Planning CT|利用语义不对称性进行鼻咽癌计划性CT图像中精确肿瘤总体积分割|Zi Li, Ying Chen, Zeli Chen, Yanzhou Su, Tai Ma, Tony C. W. Mok, Yan-Jie Zhou, Yunhai Bai .etc.|<http://arxiv.org/pdf/2411.18290v3>|提出了一种利用语义不对称性的3D肿瘤分割方法，通过对比学习提高鼻咽癌GTV在规划CT图像中的分割精度...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Attention-disentangled Uniform Orthogonal Feature Space Optimization for Few-shot Object Detection|少量样本目标检测的注意力解耦统一正交特征空间优化|Taijin Zhao, Heqian Qiu, Yu Dai, Lanxiao Wang, Fanman Meng, Qingbo Wu, Hongliang Li|<http://arxiv.org/pdf/2506.22161v1>|提出了一种均匀正交特征空间优化框架，通过解耦特征空间来提升少量样本物体检测的准确性和泛化能力。|
|🆕 发布|CERBERUS: Crack Evaluation & Recognition Benchmark for Engineering Reliability & Urban Stability|“CERBERUS：工程可靠性与城市稳定性裂纹评估与识别基准”|Justin Reinman, Sunwoong Choi|<http://arxiv.org/pdf/2506.21909v1>|[代码](https://github.com/justinreinman/Cerberus-Defect-Generator.); 提出了CERBERUS合成基准，通过结合虚拟与现实数据，有效提升AI模型在基础设施缺陷检测的性能。|
|🆕 发布|Embodied Domain Adaptation for Object Detection|面向物体的具身域自适应检测|Xiangyu Shi, Yanyuan Qiao, Lingqiao Liu, Feras Dayoub|<http://arxiv.org/pdf/2506.21860v1>|提出无源域自适应方法，通过时序聚类和对比学习提升机器人室内环境物体检测性能。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Robust and Accurate Multi-view 2D/3D Image Registration with Differentiable X-ray Rendering and Dual Cross-view Constraints|具有可微分X射线渲染和双向跨视图约束的鲁棒精确多视角2D/3D图像配准|Yuxin Cui, Rui Song, Yibin Li, Max Q. -H. Meng, Zhe Min|<http://arxiv.org/pdf/2506.22191v1>|提出了一种结合可微分X射线渲染和双向跨视图约束的多视角2D/3D图像配准方法，提高了介入导航中模型与...|
|🆕 发布|Evaluating Pointing Gestures for Target Selection in Human-Robot Collaboration|评估面向人机协作目标选择的指点手势|Noora Sassali, Roel Pieters|<http://arxiv.org/pdf/2506.22116v1>|[代码](https://github.com/NMKsas/gesture_pointer.git.); 提出了一种定位平面工作空间中指点目标的方法，并通过多模态集成验证了其在人机协作中的应用效果。|
|🆕 发布|Single-Scanline Relative Pose Estimation for Rolling Shutter Cameras|单扫描线相对位姿估计方法用于滚动快门相机|Petr Hruby, Marc Pollefeys|<http://arxiv.org/pdf/2506.22069v1>|提出了一种利用单扫描线交点估计滚动快门相机相对姿态的新方法，无需显式建模相机运动。|
|🆕 发布|SODA: Out-of-Distribution Detection in Domain-Shifted Point Clouds via Neighborhood Propagation|SODA：通过邻域传播在域偏移点云中进行分布外检测|Adam Goodge, Xun Xu, Bryan Hooi, Wee Siong Ng, Jingyi Liao, Yongyi Su, Xulei Yang|<http://arxiv.org/pdf/2506.21892v1>|提出SODA方法，通过邻域传播提升点云数据在合成到现实场景中的异常检测性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dehazing Light Microscopy Images with Guided Conditional Flow Matching: finding a sweet spot between fidelity and realism|利用引导条件流匹配去雾化光学显微镜图像：在保真度与真实感之间寻找最佳平衡点|Anirban Ray, Ashesh, Florian Jug|<http://arxiv.org/pdf/2506.22397v1>|提出了一种平衡清晰度和真实感的去雾方法HazeMatching，适用于低成本显微镜图像。|
|🆕 发布|Shape-for-Motion: Precise and Consistent Video Editing with 3D Proxy|形状驱动的运动编辑：基于三维代理的精确与一致性视频编辑|Yuhao Liu, Tengfei Wang, Fang Liu, Zhenwei Wang, Rynson W. H. Lau|<http://arxiv.org/pdf/2506.22432v1>|提出Shape-for-Motion框架，通过3D代理实现精确且一致的视频编辑。|
|🆕 发布|Unfolding Generative Flows with Koopman Operators: Fast and Interpretable Sampling|用Koopman算子展开生成流：快速且可解释的采样|Erkan Turan, Aristotelis Siozopoulos, Maks Ovsjanikov|<http://arxiv.org/pdf/2506.22304v1>|通过整合Koopman算子理论，提出了一种加速生成流程并实现可解释动态的生成模型方法。|
|📝 更新|PhysRig: Differentiable Physics-Based Skinning and Rigging Framework for Realistic Articulated Object Modeling|PhysRig：基于可微分物理的皮肤和绑定框架，用于真实关节对象建模|Hao Zhang, Haolan Xu, Chun Feng, Varun Jampani, Narendra Ahuja|<http://arxiv.org/pdf/2506.20936v2>|提出了一种基于物理的差异化蒙皮与绑定框架PhysRig，通过模拟可变形软体结构，实现了更真实的关节对...|
|📝 更新|Boosting MLLM Reasoning with Text-Debiased Hint-GRPO|提升多模态语言模型推理：通过文本去偏提示增强的图推理策略|Qihan Huang, Weilong Dai, Jinlong Liu, Wanggui He, Hao Jiang, Mingli Song, Jingyuan Chen, Chang Yao .etc.|<http://arxiv.org/pdf/2503.23905v2>|[代码](https://github.com/hqhQAQ/Hint-GRPO.); 提出 Hint-GRPO 方法，通过自适应提示和文本偏置校准提升多模态大模型推理能力。|
|📝 更新|PatchDPO: Patch-level DPO for Finetuning-free Personalized Image Generation|PatchDPO：无需微调的个性化图像生成中的图块级DPO|Qihan Huang, Weilong Dai, Jinlong Liu, Wanggui He, Hao Jiang, Mingli Song, Jie Song|<http://arxiv.org/pdf/2412.03177v2>|[代码](https://github.com/hqhQAQ/PatchDPO.); 提出PatchDPO方法，通过评估图像局部块质量来优化无需微调的个性化图像生成模型，显著提升生成图像...|
|📝 更新|MimicMotion: High-Quality Human Motion Video Generation with Confidence-aware Pose Guidance|模仿运动：基于置信度感知姿态引导的高质量人体运动视频生成|Yuang Zhang, Jiaxi Gu, Li-Wen Wang, Han Wang, Junqi Cheng, Yuefeng Zhu, Fangyuan Zou|<http://arxiv.org/pdf/2406.19680v2>|[代码](https://tencent.github.io/MimicMotion); 提出了一种生成高质量人类运动视频的框架MimicMotion，通过置信度感知的姿态引导和区域损失增强...|
|📝 更新|DFVEdit: Conditional Delta Flow Vector for Zero-shot Video Editing|DFVEdit：零样本视频编辑的条件Delta流向量|Lingling Cai, Kang Zhao, Hangjie Yuan, Xiang Wang, Yingya Zhang, Kejie Huang|<http://arxiv.org/pdf/2506.20967v2>|提出DFVEdit方法，无需修改注意力或微调，通过流变换直接编辑视频，大幅提升效率和编辑质量。|
|📝 更新|OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis|OS-Genesis：通过逆向任务合成自动化构建GUI智能体轨迹|Qiushi Sun, Kanzhi Cheng, Zichen Ding, Chuanyang Jin, Yian Wang, Fangzhi Xu, Zhenyu Wu, Chengyou Jia .etc.|<http://arxiv.org/pdf/2412.19723v3>|[代码](https://qiushisun.github.io/OS-Genesis-Home); 提出OS-Genesis方法，通过逆向任务合成自动化构建GUI智能体轨迹，提高数据质量和多样性。|
|🆕 发布|RoboEnvision: A Long-Horizon Video Generation Model for Multi-Task Robot Manipulation|机器人视觉：一种面向多任务机器人操作的长时视频生成模型|Liudi Yang, Yang Bai, George Eskandar, Fengyi Shen, Mohammad Altillawi, Dong Chen, Soumajit Majumder, Ziyuan Liu .etc.|<http://arxiv.org/pdf/2506.22007v1>|提出了一种生成长时序机器人操作视频的新方法，通过分解任务和关键帧插值，提高了视频质量和执行精度。|
|📝 更新|Event Data Association via Robust Model Fitting for Event-based Object Tracking|基于鲁棒模型拟合的事件数据关联用于事件驱动的目标跟踪|Haosheng Chen, Yue Wu, Yidong Peng|<http://arxiv.org/pdf/2110.12962v3>|提出了一种新颖的事件数据关联方法EDA，通过模型拟合有效处理事件相机数据关联问题。|
|📝 更新|Step-by-Step Video-to-Audio Synthesis via Negative Audio Guidance|通过负音频引导的逐步视频到音频合成|Akio Hayakawa, Masato Ishii, Takashi Shibuya, Yuki Mitsufuji|<http://arxiv.org/pdf/2506.20995v2>|提出了一种逐步视频转音频合成方法，通过负向音频引导生成对应视频中的特定声音事件，实现高质量复合音频合...|
|📝 更新|A Wavelet Diffusion GAN for Image Super-Resolution|基于小波扩散的生成对抗网络用于图像超分辨率|Lorenzo Aloisi, Luigi Sigillo, Aurelio Uncini, Danilo Comminiello|<http://arxiv.org/pdf/2410.17966v2>|提出基于小波变换的扩散GAN方案，实现图像超分辨率实时处理。|
|🆕 发布|Generating Attribute-Aware Human Motions from Textual Prompt|从文本提示生成属性感知的人类运动|Xinghan Wang, Kun Xu, Fei Li, Cao Sheng, Jiazhong Yu, Yadong Mu|<http://arxiv.org/pdf/2506.21912v1>|提出了一种结合人类属性信息的文本驱动人体运动生成框架，实现了更真实、符合用户描述和属性的运动生成。|
|📝 更新|ShotBench: Expert-Level Cinematic Understanding in Vision-Language Models|《ShotBench：视觉语言模型中的专家级电影理解》|Hongbo Liu, Jingwen He, Yi Jin, Dian Zheng, Yuhao Dong, Fan Zhang, Ziqi Huang, Yinan He .etc.|<http://arxiv.org/pdf/2506.21356v2>|提出ShotBench基准和ShotQA数据集，通过细粒度电影语言理解提升了视觉语言模型的性能。|
|📝 更新|The Aging Multiverse: Generating Condition-Aware Facial Aging Tree via Training-Free Diffusion|《老龄化多元宇宙：通过无需训练的扩散生成条件感知面部老化树》|Bang Gong, Luchao Qi, Jiaye Wu, Zhicheng Fu, Chunbo Song, David W. Jacobs, John Nicholson, Roni Sengupta|<http://arxiv.org/pdf/2506.21008v2>|提出了一种无需训练的扩散方法，生成受环境、健康和生活方式影响的多样化面部老化轨迹。|
|📝 更新|Not All Frame Features Are Equal: Video-to-4D Generation via Decoupling Dynamic-Static Features|并非所有帧特征都平等：通过解耦动态-静态特征实现视频到4D生成|Liying Yang, Chen Liu, Zhenwei Zhu, Ajian Liu, Hui Ma, Jian Nong, Yanyan Liang|<http://arxiv.org/pdf/2502.08377v3>|提出动态静态特征解耦模块，通过分离视频中的动态与静态特征，提高了视频转4D模型的清晰度和准确性。|
|🆕 发布|GenEscape: Hierarchical Multi-Agent Generation of Escape Room Puzzles|《GenEscape：分层多智能体生成逃脱房间谜题》|Mengyi Shan, Brian Curless, Ira Kemelmacher-Shlizerman, Steve Seitz|<http://arxiv.org/pdf/2506.21839v1>|提出多智能体协作框架生成逃脱房间谜题图像，提升了解题可行性和视觉质量。|
|🆕 发布|TaleForge: Interactive Multimodal System for Personalized Story Creation|《TaleForge：个性化故事创作的交互式多模态系统》|Minh-Loi Nguyen, Quang-Khai Le, Tam V. Nguyen, Minh-Triet Tran, Trung-Nghia Le|<http://arxiv.org/pdf/2506.21832v1>|引入TaleForge系统，通过结合大型语言模型和图像生成技术，实现个性化的故事创作与用户形象融合。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MiCo: Multi-image Contrast for Reinforcement Visual Reasoning|多图像对比强化视觉推理|Xi Chen, Mingkang Zhu, Shaoteng Liu, Xiaoyang Wu, Xiaogang Xu, Yu Liu, Xiang Bai, Hengshuang Zhao|<http://arxiv.org/pdf/2506.22434v1>|提出了一种无需人工标注的视觉推理方法，通过构建图像 triplet 和规则强化学习，有效提升多图像推...|
|📝 更新|Enhancing Object Detection Robustness: Detecting and Restoring Confidence in the Presence of Adversarial Patch Attacks|增强目标检测鲁棒性：在对抗性贴片攻击存在下检测与恢复置信度|Roie Kazoom, Raz Birman, Ofer Hadar|<http://arxiv.org/pdf/2403.12988v2>|提出了一种针对YOLOv5模型对抗性攻击的防御策略，通过Latent Diffusion Model...|
|📝 更新|Scale-Aware Pre-Training for Human-Centric Visual Perception: Enabling Lightweight and Generalizable Models|面向以人为中心的视觉感知的尺度感知预训练：实现轻量级和泛化模型|Xuanhan Wang, Huimin Deng, Lianli Gao, Jingkuan Song|<http://arxiv.org/pdf/2503.08201v2>|提出Scale-Aware Image Pretraining方法，通过多尺度一致性学习，实现轻量级...|
|📝 更新|Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution|空间退化感知与时间一致性扩散模型用于压缩视频超分辨率|Hongyu An, Xinfeng Zhang, Shijie Zhao, Li Zhang, Ruiqin Xiong|<http://arxiv.org/pdf/2502.07381v3>|提出了一种针对压缩视频的超分辨率方法，通过引入空间降质感知和时序一致性扩散模型，有效恢复视频质量。|
|📝 更新|PartEdit: Fine-Grained Image Editing using Pre-Trained Diffusion Models|PartEdit：利用预训练扩散模型进行细粒度图像编辑|Aleksandar Cvejic, Abdelrahman Eldesokey, Peter Wonka|<http://arxiv.org/pdf/2502.04050v2>|提出了一种基于预训练扩散模型的对象部分文本编辑方法，通过学习特定文本标记实现精细图像编辑。|
|🆕 发布|Noise-Inspired Diffusion Model for Generalizable Low-Dose CT Reconstruction|基于噪声启发的扩散模型用于通用低剂量CT重建|Qi Gao, Zhihao Chen, Dong Zeng, Junping Zhang, Jianhua Ma, Hongming Shan|<http://arxiv.org/pdf/2506.22012v1>|[代码](https://github.com/qgao21/NEED.); 提出了一种噪声启发的扩散模型NEED，通过定制化处理适应不同剂量CT图像噪声，实现了更广泛的剂量泛化...|
|🆕 发布|StableCodec: Taming One-Step Diffusion for Extreme Image Compression|稳定编码器：驯服一步扩散以实现极致图像压缩|Tianyu Zhang, Xin Luo, Li Li, Dong Liu|<http://arxiv.org/pdf/2506.21977v1>|[代码](https://github.com/LuizScarlet/StableCodec.); 提出了一种高效的图像压缩方法StableCodec，通过单步扩散实现极低比特率下的高保真度图像重建。|
|🆕 发布|Exploring Semantic Masked Autoencoder for Self-supervised Point Cloud Understanding|探索语义遮蔽自编码器在自监督点云理解中的应用|Yixin Zha, Chuxin Wang, Wenfei Yang, Tianzhu Zhang|<http://arxiv.org/pdf/2506.21957v1>|提出了一种基于原型引导的语义掩码自编码器，通过增强掩码策略和提示调整，有效提升无监督点云理解的性能。|
|🆕 发布|ZeroReg3D: A Zero-shot Registration Pipeline for 3D Consecutive Histopathology Image Reconstruction|零样本配准3D：用于三维连续病理图像重建的零样本配准流程|Juming Xiong, Ruining Deng, Jialin Yue, Siqi Lu, Junlin Guo, Marilyn Lionts, Tianyuan Yao, Can Cui .etc.|<http://arxiv.org/pdf/2506.21923v1>|[代码](https://github.com/hrlblab/ZeroReg3D); 提出ZeroReg3D，一种无需训练数据即可准确重构3D组织切片的新方法。|
|🆕 发布|Do Vision-Language Models Have Internal World Models? Towards an Atomic Evaluation|视觉语言模型具有内部世界模型吗？迈向原子级评估|Qiyue Gao, Xinyu Pi, Kevin Liu, Junrong Chen, Ruolan Yang, Xinqi Huang, Xinyu Fang, Lu Sun .etc.|<http://arxiv.org/pdf/2506.21876v1>|提出原子评估框架WM-ABench，揭示现有视觉语言模型在世界模型基本能力上的局限。|
|📝 更新|DidSee: Diffusion-Based Depth Completion for Material-Agnostic Robotic Perception and Manipulation|DidSee：基于扩散的深度补全，用于材料不可知机器人感知与操作|Wenzhou Lyu, Jialing Lin, Wenqi Ren, Ruihao Xia, Feng Qian, Yang Tang|<http://arxiv.org/pdf/2506.21034v2>|提出了一种基于扩散模型的新型深度补全框架DidSee，有效解决了非朗伯物体深度图的不完整和噪声问题，...|
|🆕 发布|ProSAM: Enhancing the Robustness of SAM-based Visual Reference Segmentation with Probabilistic Prompts|ProSAM：基于SAM的视觉参考分割的鲁棒性增强与概率提示|Xiaoqi Wang, Clint Sebastian, Wenbin He, Liu Ren|<http://arxiv.org/pdf/2506.21835v1>|提出ProSAM方法，通过学习变分提示编码器预测多变量提示分布，增强视觉参考分割的稳定性。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RoomCraft: Controllable and Complete 3D Indoor Scene Generation|《RoomCraft：可控且完整的3D室内场景生成》|Mengqi Zhou, Xipeng Wang, Yuxi Wang, Zhaoxiang Zhang|<http://arxiv.org/pdf/2506.22291v1>|RoomCraft通过结合生成管道和约束优化框架，有效解决了3D室内场景生成中的布局一致性和完整性问...|
|🆕 发布|4D-VLA: Spatiotemporal Vision-Language-Action Pretraining with Cross-Scene Calibration|4D-VLA：跨场景校准的时空视觉-语言-动作预训练|Jiahui Zhang, Yurui Chen, Yueming Xu, Ze Huang, Yanpeng Zhou, Yu-Jie Yuan, Xinyue Cai, Guowei Huang .etc.|<http://arxiv.org/pdf/2506.22242v1>|提出4D-VLA方法，整合4D信息解决坐标和状态混乱问题，提升机器人预训练效率和性能。|
|📝 更新|Communication-Efficient Heterogeneous Federated Learning with Generalized Heavy-Ball Momentum|通信高效的全局异构联邦学习与广义重球动量|Riccardo Zaccone, Sai Praneeth Karimireddy, Carlo Masone, Marco Ciccone|<http://arxiv.org/pdf/2311.18578v3>|[代码](https://rickzack.github.io/GHBM.); 提出了一种改进的联邦学习方法GHBM，有效应对数据异质性和部分客户端参与问题，提升大规模场景下的学习...|
|📝 更新|VideoFusion: A Spatio-Temporal Collaborative Network for Multi-modal Video Fusion and Restoration|视频融合：一种用于多模态视频融合与恢复的时空协作网络|Linfeng Tang, Yeda Wang, Meiqi Gong, Zizhuo Li, Yuxin Deng, Xunpeng Yi, Chunyu Li, Han Xu .etc.|<http://arxiv.org/pdf/2503.23359v2>|提出了VideoFusion模型，通过融合多模态视频数据并利用时空一致性，解决了视频融合中的时空依赖...|
|📝 更新|VGAT: A Cancer Survival Analysis Framework Transitioning from Generative Visual Question Answering to Genomic Reconstruction|VGAT：从生成视觉问答到基因组重建的癌症生存分析框架|Zizhi Chen, Minghao Han, Xukun Zhang, Shuwei Ma, Tao Liu, Xing Wei, Lihua Zhang|<http://arxiv.org/pdf/2503.19367v3>|[代码](https://github.com/CZZZZZZZZZZZZZZZZZ/VGAT.); 提出VGAT框架，通过视觉问答技术实现仅用病理图像进行生存预测，无需基因测序。|
|🆕 发布|MirrorMe: Towards Realtime and High Fidelity Audio-Driven Halfbody Animation|《MirrorMe：迈向实时和高保真度音频驱动的半身动画》|Dechao Meng, Steven Xiao, Xindi Zhang, Guangyuan Wang, Peng Zhang, Qi Wang, Bang Zhang, Liefeng Bo|<http://arxiv.org/pdf/2506.22065v1>|提出实时高保真音频驱动半身动画框架MirrorMe，通过创新压缩视频的扩散变换器和训练策略，解决了动...|
|📝 更新|CAPM: Fast and Robust Verification on Maxpool-based CNN via Dual Network|CAPM：基于双网络的Maxpool-CNN快速稳健验证|Jia-Hau Bai, Chi-Ting Liu, Yu Wang, Fu-Chieh Chang, Pei-Yuan Wu|<http://arxiv.org/pdf/2407.09550v3>|提出CAPM方法，通过双网络结构有效提升验证边界，大幅降低计算成本。|
|🆕 发布|Exploring Task-Solving Paradigm for Generalized Cross-Domain Face Anti-Spoofing via Reinforcement Fine-Tuning|探索基于强化微调的广义跨域人脸防伪任务解决范式|Fangling Jiang, Qi Li, Weining Wang, Gang Wang, Bing Liu, Zhenan Sun|<http://arxiv.org/pdf/2506.21895v1>|提出了一种基于强化微调的跨域人脸防伪方法，通过模拟大语言模型的思考过程，实现了对未知攻击类型的高效泛...|
|📝 更新|FairyGen: Storied Cartoon Video from a Single Child-Drawn Character|《FairyGen：从单个儿童绘制的角色生成具有故事性的卡通视频》|Jiayi Zheng, Xiaodong Cun|<http://arxiv.org/pdf/2506.21272v2>|[代码](https://github.com/GVCLab/FairyGen); 提出FairyGen系统，通过单张儿童绘画自动生成具有故事性的卡通视频，同时保持独特艺术风格。|
|📝 更新|Shape2Animal: Creative Animal Generation from Natural Silhouettes|《Shape2Animal：从自然轮廓生成创意动物》|Quoc-Duy Tran, Anh-Tuan Vo, Dinh-Khoi Vo, Tam V. Nguyen, Minh-Triet Tran, Trung-Nghia Le|<http://arxiv.org/pdf/2506.20616v2>|提出Shape2Animal框架，将自然物体轮廓转化为动物形象，实现创意视觉合成。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OutDreamer: Video Outpainting with a Diffusion Transformer|《OutDreamer：基于扩散变换器的视频外绘技术》|Linhao Zhong, Fan Li, Yi Huang, Jianzhuang Liu, Renjing Pei, Fenglong Song|<http://arxiv.org/pdf/2506.22298v1>|提出OutDreamer框架，利用扩散变换器高效生成视频内容，实现时空一致性。|
|🆕 发布|Q-Frame: Query-aware Frame Selection and Multi-Resolution Adaptation for Video-LLMs|Q-Frame：查询感知的帧选择与多分辨率自适应方法用于视频语言模型|Shaojie Zhang, Jiahui Yang, Jianqin Yin, Zhenbo Luo, Jian Luan|<http://arxiv.org/pdf/2506.22139v1>|提出了一种自适应帧选择和多分辨率调整方法Q-Frame，有效提升视频理解模型对关键时空信息的捕获能力...|
|🆕 发布|Advancing Facial Stylization through Semantic Preservation Constraint and Pseudo-Paired Supervision|通过语义保持约束和伪成对监督推进面部风格化|Zhanyi Lu, Yue Zhou|<http://arxiv.org/pdf/2506.22022v1>|提出了一种结合语义保持约束和伪成对监督的面部风格化方法，有效提升了生成图像的保真度和风格化效果。|
|🆕 发布|CAL-RAG: Retrieval-Augmented Multi-Agent Generation for Content-Aware Layout Design|内容感知布局设计中的检索增强多代理生成：CAL-RAG|Najmeh Forouzandehmehr, Reza Yousefi Maragheh, Sriram Kollipara, Kai Zhao, Topojoy Biswas, Evren Korpeoglu, Kannan Achan|<http://arxiv.org/pdf/2506.21934v1>|提出了一种结合多模态检索和协作智能推理的内容感知布局生成框架，实现了高保真度自动布局设计。|
|🆕 发布|Quality Assessment and Distortion-aware Saliency Prediction for AI-Generated Omnidirectional Images|人工智能生成全向图像的质量评估与失真感知显著性预测|Liu Yang, Huiyu Duan, Jiarui Wang, Jing Liu, Menghan Hu, Xiongkuo Min, Guangtao Zhai, Patrick Le Callet|<http://arxiv.org/pdf/2506.21925v1>|[代码](https://github.com/IntMeGroup/AIGCOIQA); 提出质量评估与失真感知的显著性预测方法，优化AI生成的全向图像视觉质量。|
|🆕 发布|Visual Content Detection in Educational Videos with Transfer Learning and Dataset Enrichment|教育视频中视觉内容检测的迁移学习与数据集增强方法|Dipayan Biswas, Shishir Shah, Jaspal Subhlok|<http://arxiv.org/pdf/2506.21903v1>|利用迁移学习和数据集增强，提高了教育视频视觉内容检测的准确性和实用性。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DIGS: Dynamic CBCT Reconstruction using Deformation-Informed 4D Gaussian Splatting and a Low-Rank Free-Form Deformation Model|DIGS：基于形变指导的四维高斯散点绘制和低秩自由形式变形模型的动态CBCT重建|Yuliang Huang, Imraj Singh, Thomas Joyce, Kris Thielemans, Jamie R. McClelland|<http://arxiv.org/pdf/2506.22280v1>|[代码](https://github.com/Yuliang-Huang/DIGS.); 提出了一种基于变形信息的4D高斯散点法，实现了高效的运动补偿CBCT重建。|
|🆕 发布|Low-Rank Implicit Neural Representation via Schatten-p Quasi-Norm and Jacobian Regularization|通过Schatten-p准范数和雅可比正则化的低秩隐式神经表示|Zhengyun Cheng, Changhao Wang, Guanwen Zhang, Yi Xu, Wei Zhou, Xiangyang Ji|<http://arxiv.org/pdf/2506.22134v1>|提出了一种基于CP分解和神经网络的新型低秩隐式表示方法，实现了多维数据的高效恢复和去噪。|
|🆕 发布|Few-Shot Identity Adaptation for 3D Talking Heads via Global Gaussian Field|三维说话人头部的少量样本身份适应通过全局高斯场|Hong Nie, Fuyuan Cao, Lu Chen, Fengxin Chen, Yuefeng Zou, Jun Yu|<http://arxiv.org/pdf/2506.22044v1>|[代码](https://github.com/gme-hong/FIAG); 提出了一种基于少量训练样本的3D说话人头合成框架，通过全局高斯场实现快速身份适应。|
|🆕 发布|UnMix-NeRF: Spectral Unmixing Meets Neural Radiance Fields|光谱解混遇见神经辐射场：UnMix-NeRF|Fabian Perez, Sara Rojas, Carlos Hinojosa, Hoover Rueda-Chacón, Bernard Ghanem|<http://arxiv.org/pdf/2506.21884v1>|将光谱解混与神经辐射场结合，实现无需标注即可进行材料分割和高质量视图合成。|
|📝 更新|Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time Talking Head Synthesis|音频平面：基于音频分解平面的高斯散点绘制实现实时说话人头合成|Shuai Shen, Wanhua Li, Yunpeng Zhang, Yap-Peng Tan, Jiwen Lu|<http://arxiv.org/pdf/2503.22605v2>|提出了一种结合高斯散点和音频分解平面技术的实时说话人头合成方法，实现了高质量、音频同步的视觉效果。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Pipe Reconstruction from Point Cloud Data|从点云数据中重建管道|Antje Alex, Jannis Stoppe|<http://arxiv.org/pdf/2506.22118v1>|提出了一种自动化管道重建方法，从激光扫描数据中快速准确构建复杂管道网络的三维模型。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RAUM-Net: Regional Attention and Uncertainty-aware Mamba Network|区域关注与不确定性感知的曼巴网络：RAUM-Net|Mingquan Liu|<http://arxiv.org/pdf/2506.21905v1>|[代码](https://github.com/wxqnl/RAUM); 提出了一种半监督方法，结合区域注意力和贝叶斯不确定性，有效提升了少量标注数据下的细粒度视觉分类性能。|


## 时序视觉分析 (Temporal Visual Analysis)


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Frequency-Semantic Enhanced Variational Autoencoder for Zero-Shot Skeleton-based Action Recognition|频率-语义增强的变分自动编码器用于零样本骨骼基动作识别|Wenhan Wu, Zhishuai Guo, Chen Chen, Hongfei Xue, Aidong Lu|<http://arxiv.org/pdf/2506.22179v1>|提出了一种频率-语义增强的变分自编码器，通过频率分解探索骨架语义表示学习，有效提升零样本动作识别的鲁...|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Self-ReS: Self-Reflection in Large Vision-Language Models for Long Video Understanding|自反ReS：在大规模视觉语言模型中进行自我反思以实现长视频理解|Joao Pereira, Vasco Lopes, David Semedo, Joao Neves|<http://arxiv.org/pdf/2503.20362v2>|提出了一种动态选择关键视频片段的自反射采样方法SelfReS，有效提升长视频理解性能并加快推理速度。|
|🆕 发布|Towards Accurate Heart Rate Measurement from Ultra-Short Video Clips via Periodicity-Guided rPPG Estimation and Signal Reconstruction|通过周期性引导的rPPG估计和信号重建实现超短视频片段中心率测量的准确性|Pei-Kai Huanga, Ya-Ting Chan, Kuan-Wen Chen, Yen-Chun Chou, Shih-Yu Yang, Chiou-Ting Hsu|<http://arxiv.org/pdf/2506.22078v1>|提出了一种针对极短视频的心率测量方法，通过周期性引导和信号重构提高了准确性。|
|🆕 发布|DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025|DIVE：深度搜索迭代视频探索 —— CVRR挑战赛技术报告（2025年CVPR会议）|Umihiro Kamoto, Tatsuya Ishibashi, Noriyuki Kugo|<http://arxiv.org/pdf/2506.21891v1>|[代码](https://github.com/PanasonicConnect/DIVE); 提出迭代推理方法DIVE，通过逐步推理和渐进推断准确回答视频问题。|
|🆕 发布|LLaVA-Scissor: Token Compression with Semantic Connected Components for Video LLMs|剪刀LLaVA：面向视频大型语言模型的语义连通组件标记压缩|Boyuan Sun, Jiaxing Zhao, Xihan Wei, Qibin Hou|<http://arxiv.org/pdf/2506.21862v1>|[代码](https://github.com/HumanMLLM/LLaVA-Scissor.); 提出了一种基于语义连通分量的视频多模态大语言模型训练无关的token压缩策略，有效提高了视频理解的性...|
|🆕 发布|Periodic-MAE: Periodic Video Masked Autoencoder for rPPG Estimation|周期性-MAE：用于rPPG估计的周期性视频遮蔽自编码器|Jiho Choi, Sang Jun Lee|<http://arxiv.org/pdf/2506.21855v1>|[代码](https://github.com/ziiho08/Periodic-MAE.); 提出了一种基于视频掩码自编码器的rPPG估计方法，通过捕捉面部肤色细微变化学习通用周期信号表示，实现...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Self is the Best Learner: CT-free Ultra-Low-Dose PET Organ Segmentation via Collaborating Denoising and Segmentation Learning|"自我即是最佳学习者：无需CT的极低剂量PET器官分割通过协同降噪与分割学习"|Zanting Ye, Xiaolong Niu, Xu Han, Xuanbin Wu, Wantong Lu, Yijun Lu, Hao Sun, Yanchao Huang .etc.|<http://arxiv.org/pdf/2503.03786v2>|[代码](https://github.com/yezanting/LDOS.); 提出了一种无需CT的PET低剂量图像器官分割方法，通过联合去噪和分割学习显著提升了分割精度。|
|🆕 发布|SPADE: Spatial Transcriptomics and Pathology Alignment Using a Mixture of Data Experts for an Expressive Latent Space|SPADE：使用数据专家混合模型的空转录组学与病理学对齐，以实现富有表现力的潜在空间|Ekaterina Redekop, Mara Pleasure, Zichen Wang, Kimberly Flores, Anthony Sisk, William Speier, Corey W. Arnold|<http://arxiv.org/pdf/2506.21857v1>|整合病理图像与空间转录组数据，SPADE模型通过混合数据专家技术提升少量样本学习性能。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|KITAB-Bench: A Comprehensive Multi-Domain Benchmark for Arabic OCR and Document Understanding|KITAB-Bench：面向阿拉伯语OCR和文档理解的全面多领域基准测试|Ahmed Heakl, Abdullah Sohail, Mukul Ranjan, Rania Hossam, Ghazi Shazan Ahmad, Mohamed El-Geish, Omar Maher, Zhiqiang Shen .etc.|<http://arxiv.org/pdf/2502.14949v2>|提出了KITAB-Bench，一个全面的阿拉伯语OCR和文档理解基准，显著提升了字符识别准确率并揭示...|
|🆕 发布|Hardware acceleration for ultra-fast Neural Network training on FPGA for MRF map reconstruction|用于MRF图重建的超快速神经网络训练的FPGA硬件加速|Mattia Ricchi, Fabrizio Alfonsi, Camilla Marella, Marco Barbieri, Alessandra Retico, Leonardo Brizi, Alessandro Gabrielli, Claudia Testa|<http://arxiv.org/pdf/2506.22156v1>|提出了一种基于FPGA的神经网络加速方法，实现了MRF数据实时脑参数重建，训练速度比CPU快250倍...|
|🆕 发布|RetFiner: A Vision-Language Refinement Scheme for Retinal Foundation Models|视网膜基础模型的一种视觉-语言精炼方案：RetFiner|Ronald Fecso, José Morano, Ursula Schmidt-Erfurth, Hrvoje Bogunović|<http://arxiv.org/pdf/2506.22149v1>|[代码](https://github.com/ronnief1/RetFiner.); 提出RetFiner方法，通过结合视觉与文本数据提升模型对视网膜图像的理解，提高下游任务性能。|
|🆕 发布|BézierGS: Dynamic Urban Scene Reconstruction with Bézier Curve Gaussian Splatting|贝塞尔高斯散点法：动态城市场景重建与贝塞尔曲线高斯散点技术|Zipei Ma, Junzhe Jiang, Yurui Chen, Li Zhang|<http://arxiv.org/pdf/2506.22099v1>|提出了一种利用可学习贝塞尔曲线表示动态物体运动轨迹的方法，有效提升了城市场景的实时重建质量和精度。|
|🆕 发布|Towards Universal & Efficient Model Compression via Exponential Torque Pruning|面向通用与高效模型压缩的指数扭矩剪枝方法|Sarthak Ketanbhai Modi, Lim Zi Pong, Shourya Kuchhal, Yoshi Cao, Yupeng Cheng, Teo Yon Shin, Lin Shang-Wei, Zhiming Li|<http://arxiv.org/pdf/2506.22015v1>|提出指数扭矩剪枝法，高效压缩模型同时保持准确度。|
|🆕 发布|End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model|端到端RGB-IR联合图像压缩及通道-wise跨模态熵模型|Haofeng Wang, Fangtao Zhou, Qi Zhang, Zeyuan Chen, Enci Zhang, Zhao Wang, Xiaofeng Huang, Siwei Ma|<http://arxiv.org/pdf/2506.21851v1>|提出了一种RGB-IR图像对联合压缩框架，通过通道间跨模态熵模型显著降低了数据存储和传输成本。|
|📝 更新|QT-DoG: Quantization-aware Training for Domain Generalization|QT-DoG：面向域泛化的量化感知训练|Saqib Javed, Hieu Le, Mathieu Salzmann|<http://arxiv.org/pdf/2410.06020v2>|[代码](https://saqibjaved1.github.io/QT_DoG); 提出QT-DoG方法，通过权重量化引导优化过程至更平坦损失景观，增强跨域泛化能力。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EnLVAM: Enhanced Left Ventricle Linear Measurements Utilizing Anatomical Motion Mode|增强型左心室线性测量方法：利用解剖运动模式|Durgesh K. Singh, Ahcene Boubekki, Qing Cao, Svein Arne Aase, Robert Jenssen, Michael Kampffmeyer|<http://arxiv.org/pdf/2506.22063v1>|提出了一种利用解剖运动模式增强左心室线性测量的新框架，提高了测量的准确性和效率。|
|📝 更新|Mamba-FSCIL: Dynamic Adaptation with Selective State Space Model for Few-Shot Class-Incremental Learning|Mamba-FSCIL：基于选择性状态空间模型的少样本类别增量学习动态适应方法|Xiaojie Li, Yibo Yang, Jianlong Wu, Yue Yu, Ming-Hsuan Yang, Liqiang Nie, Min Zhang|<http://arxiv.org/pdf/2407.06136v3>|[代码](https://github.com/xiaojieli0903/Mamba-FSCIL.); 提出动态调整参数的Mamba-FSCIL模型，通过选择性状态空间模型实现少量样本新增类别的学习与已有...|
|📝 更新|SAMConvex: Fast Discrete Optimization for CT Registration using Self-supervised Anatomical Embedding and Correlation Pyramid|SAMConvex：基于自监督解剖嵌入和相关性金字塔的CT配准快速离散优化方法|Zi Li, Lin Tian, Tony C. W. Mok, Xiaoyu Bai, Puyang Wang, Jia Ge, Jingren Zhou, Le Lu .etc.|<http://arxiv.org/pdf/2307.09727v2>|提出了一种基于自监督解剖嵌入的快速离散优化方法，有效提升了CT图像配准的速度和精度。|
|🆕 发布|3D-Telepathy: Reconstructing 3D Objects from EEG Signals|“3D-心灵感应：从脑电图信号重建三维物体”|Yuxiang Ge, Jionghao Cheng, Ruiquan Ge, Zhaojie Fang, Gangyong Jia, Xiang Wan, Nannan Li, Ahmed Elazab .etc.|<http://arxiv.org/pdf/2506.21843v1>|提出了一种结合双自注意力机制的EEG编码器，通过混合训练策略和稳定扩散技术，实现了从EEG信号重建3...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|WarpRF: Multi-View Consistency for Training-Free Uncertainty Quantification and Applications in Radiance Fields|WarpRF：基于多视角一致性的无训练不确定性量化及其在辐射场中的应用|Sadra Safadoust, Fabio Tosi, Fatma Güney, Matteo Poggi|<http://arxiv.org/pdf/2506.22433v1>|提出了一种无需训练的多视角一致性框架WarpRF，用于量化辐射场的误差。|
|📝 更新|Cell Tracking according to Biological Needs -- Strong Mitosis-aware Multi-Hypothesis Tracker with Aleatoric Uncertainty|根据生物需求进行细胞追踪——具有分裂感知能力的多假设强跟踪器及随机不确定性分析|Timo Kaiser, Maximilian Schier, Bodo Rosenhahn|<http://arxiv.org/pdf/2403.15011v5>|提出了一种考虑细胞分裂的 multi-hypothesis 追踪框架，通过不确定性估计显著提升了长期...|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|StarFT: Robust Fine-tuning of Zero-shot Models via Spuriosity Alignment|StarFT：通过伪迹对齐实现零样本模型的稳健微调|Younghyun Kim, Jongheon Jeong, Sangkyung Kwak, Kyungmin Lee, Juho Lee, Jinwoo Shin|<http://arxiv.org/pdf/2505.13232v3>|提出了一种防止零样本模型学习无关特征的新框架StarFT，通过文本描述对齐增强模型的鲁棒性。|
|📝 更新|Releasing Inequality Phenomenon in $\ell_{\infty}$-norm Adversarial Training via Input Gradient Distillation|通过输入梯度蒸馏释放 $\ell_{\infty}$-范数对抗训练中的不平等现象|Junxi Chen, Junhao Dong, Xiaohua Xie, Jianhuang Lai|<http://arxiv.org/pdf/2305.09305v3>|[代码](https://github.com/fhdnskfbeuv/Inuput-Gradient-Distillation); 提出Input Gradient Distillation方法缓解$\ell_{\infty}$-范...|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|KNN-MMD: Cross Domain Wireless Sensing via Local Distribution Alignment|KNN-MMD: 基于局部分布对齐的跨域无线感知|Zijian Zhao, Zhijie Cai, Tingwei Chen, Xiaoyang Li, Hang Li, Qimei Chen, Guangxu Zhu|<http://arxiv.org/pdf/2412.04783v3>|[代码](https://github.com/RS2002/KNN-MMD); 提出KNN-MMD方法，通过局部分布对齐解决无线感知模型跨环境性能下降问题。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Single-shot HDR using conventional image sensor shutter functions and optical randomization|单次曝光HDR利用传统图像传感器快门功能与光学随机化|Xiang Dai, Kyrollos Yanny, Kristina Monakhova, Nicholas Antipa|<http://arxiv.org/pdf/2506.22426v1>|利用现成传感器和随机光学技术，实现了无需多曝光的单次拍摄高动态范围成像。|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Advanced Deep Learning Techniques for Automated Segmentation of Type B Aortic Dissections|深度学习技术在B型主动脉夹层自动分割中的高级应用|Hao Xu, Ruth Lim, Brian E. Chapman|<http://arxiv.org/pdf/2506.22222v1>|提出四种基于深度学习的主动脉夹层自动分割方法，显著提升了分割精度。|
|🆕 发布|ReF-LLE: Personalized Low-Light Enhancement via Reference-Guided Deep Reinforcement Learning|基于参考引导的深度强化学习的个性化低光照增强ReF-LLE|Ming Zhao, Pingping Liu, Tongshun Zhang, Zhe Zhang|<http://arxiv.org/pdf/2506.22216v1>|提出了一种结合深度强化学习和参考引导的个性化低光照图像增强方法，有效适应不同光照条件和用户偏好。|
|📝 更新|End-to-End Full-Page Optical Music Recognition for Pianoform Sheet Music|端到端全页乐谱光学音乐识别技术在钢琴曲谱中的应用|Antonio Ríos-Vila, Jorge Calvo-Zaragoza, David Rizo, Thierry Paquet|<http://arxiv.org/pdf/2405.12105v4>|首次实现了端到端的复杂布局全页乐谱识别，结合卷积层与自回归变换器，无需分阶段处理。|
|📝 更新|OTSurv: A Novel Multiple Instance Learning Framework for Survival Prediction with Heterogeneity-aware Optimal Transport|OTSurv：一种新颖的异质性感知最优传输生存预测多实例学习框架|Qin Ren, Yifan Wang, Ruogu Fang, Haibin Ling, Chenyu You|<http://arxiv.org/pdf/2506.20741v2>|[代码](https://github.com/Y-Research-SBU/OTSurv.); 提出了一种基于最优传输理论的异质性感知生存预测框架OTSurv，通过全局和局部约束显著提升了预测准确...|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GRASP-PsONet: Gradient-based Removal of Spurious Patterns for PsOriasis Severity Classification|基于梯度的伪模式移除网络：用于银屑病严重程度分类的GRASP-PsONet|Basudha Pal, Sharif Amit Kamran, Brendon Lutnick, Molly Lucas, Chaitanya Parmar, Asha Patel Shah, David Apfel, Steven Fakharzadeh .etc.|<http://arxiv.org/pdf/2506.21883v1>|提出了一种基于梯度追踪的框架，自动识别并移除影响银屑病严重程度分类模型泛化能力的伪相关图像，从而提升...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MM-R$^3$: On (In-)Consistency of Vision-Language Models (VLMs)|MM-R$^3$: 关于视觉语言模型（VLMs）的一致性与不一致性研究|Shih-Han Chou, Shivam Chandhok, James J. Little, Leonid Sigal|<http://arxiv.org/pdf/2410.04778v2>|提出MM-R3基准，分析视觉语言模型的一致性，并提出适配器模块提升模型一致性。|
|🆕 发布|Rethinking Visual Token Reduction in LVLMs under Cross-modal Misalignment|在跨模态失配下对轻量级视觉模型中的视觉标记缩减的再思考|Rui Xu, Yunke Wang, Yong Luo, Bo Du|<http://arxiv.org/pdf/2506.22283v1>|提出了一种视觉信息剪枝框架VisionDrop，通过视觉内部注意力实现高效视觉token选择，提升大...|
|🆕 发布|KnotDLO: Toward Interpretable Knot Tying|面向可解释的打结操作：KnotDLO|Holly Dinkel, Raghavendra Navaratna, Jingyi Xiang, Brian Coltin, Trey Smith, Timothy Bretl|<http://arxiv.org/pdf/2506.22176v1>|提出了一种无需人类示范或训练的KnotDLO方法，实现了对遮挡和不同初始配置的鲁棒一键结打法。|
|🆕 发布|Visual Structures Helps Visual Reasoning: Addressing the Binding Problem in VLMs|视觉结构助力视觉推理：解决视觉语言模型中的绑定问题|Amirmohammad Izadi, Mohammad Ali Banayeeanzade, Fatemeh Askari, Ali Rahimiakbar, Mohammad Mahdi Vahedi, Hosein Hasani, Mahdieh Soleymani Baghshah|<http://arxiv.org/pdf/2506.22146v1>|提出方法通过增强视觉输入的低级空间结构，有效解决了视觉语言模型中的绑定问题，显著提升了视觉推理性能。|
|📝 更新|VLM@school -- Evaluation of AI image understanding on German middle school knowledge|结果：  “VLM@学校 -- 德国中学知识上的AI图像理解评估”|René Peinl, Vincent Tischler|<http://arxiv.org/pdf/2506.11604v2>|提出德语中学知识背景下的视觉语言模型评估新基准，揭示了现有模型在真实世界任务中的不足。|
|📝 更新|MUPA: Towards Multi-Path Agentic Reasoning for Grounded Video Question Answering|MUPA：面向地面视频问答的多路径代理推理|Jisheng Dang, Huilin Song, Junbin Xiao, Bimei Wang, Han Peng, Haoxuan Li, Xun Yang, Meng Wang .etc.|<http://arxiv.org/pdf/2506.18071v2>|[代码](https://github.com/longmalongma/MUPA.); 提出MUPA方法，通过多路径协同代理推理，提升了视频问答的接地准确性和答案准确性。|
|🆕 发布|SPAZER: Spatial-Semantic Progressive Reasoning Agent for Zero-shot 3D Visual Grounding|SPAZER：用于零样本3D视觉定位的空间语义渐进推理代理|Zhao Jin, Rong-Cheng Tu, Jingyi Liao, Wenhao Sun, Xiao Luo, Shunyu Liu, Dacheng Tao|<http://arxiv.org/pdf/2506.21924v1>|提出了一种融合空间与语义推理的SPAZER模型，实现了无需3D标注数据的零样本3D视觉定位。|
|🆕 发布|Grounding-Aware Token Pruning: Recovering from Drastic Performance Drops in Visual Grounding Caused by Pruning|感知接地剪枝令牌：从剪枝引起的视觉定位性能急剧下降中恢复|Tzu-Chun Chien, Chieh-Kai Lin, Shiang-Feng Tsai, Ruei-Chi Lai, Hung-Jen Chen, Min Sun|<http://arxiv.org/pdf/2506.21873v1>|提出方法调整位置ID，有效恢复视觉定位性能下降问题，无需额外训练资源。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MatChA: Cross-Algorithm Matching with Feature Augmentation|MatChA：跨算法匹配与特征增强|Paula Carbó Cubero, Alberto Jaenal Gálvez, André Mateus, José Araújo, Patric Jensfelt|<http://arxiv.org/pdf/2506.22336v1>|提出了一种针对不同算法提取的特征进行增强匹配的方法，显著提升了跨特征检测器情况下的图像匹配和视觉定位...|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Secure Video Quality Assessment Resisting Adversarial Attacks|对抗攻击下的安全视频质量评估|Ao-Xiang Zhang, Yuan-Gen Wang, Yu Ran, Weixuan Tang, Qingxiao Guan, Chunsheng Yang|<http://arxiv.org/pdf/2410.06866v2>|提出SecureVQA框架，通过随机采样和像素随机化增强视频质量评估模型对抗攻击的鲁棒性。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|R1-Track: Direct Application of MLLMs to Visual Object Tracking via Reinforcement Learning|R1-Track：通过强化学习直接将多模态大型语言模型应用于视觉目标跟踪|Biao Wang, Wenwen Li|<http://arxiv.org/pdf/2506.21980v1>|通过强化学习微调多模态大语言模型，实现了灵活的视觉目标跟踪。|
|📝 更新|A Hyperdimensional One Place Signature to Represent Them All: Stackable Descriptors For Visual Place Recognition|《一种超维单一地点签名表征一切：用于视觉地点识别的可堆叠描述符》|Connor Malone, Somayeh Hussaini, Tobias Fischer, Michael Milford|<http://arxiv.org/pdf/2412.06153v2>|提出了一种融合多环境条件描述子的Hyperdimensional One Place Signatu...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|NSegment : Label-specific Deformations for Remote Sensing Image Segmentation|NSegment：面向特定标签的遥感图像分割形变方法|Yechan Kim, DongHo Yoon, SooYeon Kim, Moongu Jeon|<http://arxiv.org/pdf/2504.19634v3>|提出了一种针对遥感图像分割的数据增强方法NSegment，通过弹性变换标签来减少标注不一致性的影响。|
|📝 更新|Exploring Text-Guided Single Image Editing for Remote Sensing Images|探索基于文本引导的遥感图像单幅编辑方法|Fangzhou Han, Lingyu Si, Zhizhuo Jiang, Hongwei Dong, Lamei Zhang, Yu Liu, Hao Chen, Bo Du|<http://arxiv.org/pdf/2405.05769v3>|[代码](https://github.com/HIT-PhilipHan/remote_sensing_image_editing); 提出了一种基于单张遥感图像和文本指导的编辑方法，无需大型数据集即可实现多样化编辑任务。|
|🆕 发布|A Deep Learning framework for building damage assessment using VHR SAR and geospatial data: demonstration on the 2023 Turkiye Earthquake|基于高分辨率合成孔径雷达和地理空间数据的深度学习框架构建：2023年土耳其地震损害评估应用演示|Luigi Russo, Deodato Tapete, Silvia Liberata Ullo, Paolo Gamba|<http://arxiv.org/pdf/2506.22338v1>|提出了一种仅利用灾后数据，结合地理空间信息的深度学习框架，实现了快速准确的建筑损毁评估。|
|📝 更新|SegChange-R1: LLM-Augmented Remote Sensing Change Detection|SegChange-R1：基于大型语言模型增强的遥感变化检测|Fei Zhou|<http://arxiv.org/pdf/2506.17944v2>|[代码](https://github.com/Yu-Zhouz/SegChange-R1); 提出了一种融合大规模语言模型和空间变换模块的遥感变化检测方法，显著提升了检测准确性和效率。|
|📝 更新|Real-World Remote Sensing Image Dehazing: Benchmark and Baseline|现实世界遥感图像去雾：基准与基线|Zeng-Hui Zhu, Wei Lu, Si-Bao Chen, Chris H. Q. Ding, Jin Tang, Bin Luo|<http://arxiv.org/pdf/2503.17966v2>|[代码](https://github.com/lwCVer/RRSHID.); 提出了首个大规模真实世界遥感图像去雾数据集RRSHID和专门针对实际应用的MCAF-Net框架。|
|🆕 发布|SDRNET: Stacked Deep Residual Network for Accurate Semantic Segmentation of Fine-Resolution Remotely Sensed Images|SDRNET：用于高分辨率遥感图像精确语义分割的堆叠深度残差网络|Naftaly Wambugu, Ruisheng Wang, Bo Guo, Tianshu Yu, Sheng Xu, Mohammed Elhassan|<http://arxiv.org/pdf/2506.21945v1>|提出了一种堆叠深度残差网络，通过结合全局语义与空间信息，有效提升了细分辨率遥感图像的语义分割精度。|
|🆕 发布|Dual-Perspective United Transformer for Object Segmentation in Optical Remote Sensing Images|双视角联合变换器用于光学遥感图像中的目标分割|Yanguang Sun, Jiexi Yan, Jianjun Qian, Chunyan Xu, Jian Yang, Lei Luo|<http://arxiv.org/pdf/2506.21866v1>|[代码](https://github.com/CSYSI/DPU-Former.); 提出了一种融合卷积和Transformer优势的DPU-Former模型，有效整合长距离依赖和空间细...|
|🆕 发布|Remote Sensing Large Vision-Language Model: Semantic-augmented Multi-level Alignment and Semantic-aware Expert Modeling|结果： 遥感大规模视觉语言模型：语义增强的多级对齐与语义感知的专家建模|Sungjune Park, Yeongyun Kim, Se Yeon Kim, Yong Man Ro|<http://arxiv.org/pdf/2506.21863v1>|针对遥感图像理解挑战，提出了一种融合多级语义对齐和语义感知专家模型的新型视觉语言框架。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|No More Sliding Window: Efficient 3D Medical Image Segmentation with Differentiable Top-k Patch Sampling|“无需滑动窗口：基于可微分Top-k补丁采样的高效三维医学图像分割”|Young Seok Jeon, Hongfei Yang, Huazhu Fu, Mengling Feng|<http://arxiv.org/pdf/2501.10814v3>|[代码](https://github.com/Youngseok0001/open_nmsw.); 提出了一种无需滑动窗口的3D医疗图像分割框架，通过选择性采样关键区块大幅提升计算效率。|
|🆕 发布|Pedestrian Intention and Trajectory Prediction in Unstructured Traffic Using IDD-PeD|使用IDD-PeD进行无序交通中行人意图与轨迹预测|Ruthvik Bokkasam, Shankar Gangisetty, A. H. Abdul Hafez, C. V. Jawahar|<http://arxiv.org/pdf/2506.22111v1>|提出印度驾驶行人数据集IDD-PeD，提升复杂环境下行人行为预测模型的鲁棒性。|
|🆕 发布|Tied Prototype Model for Few-Shot Medical Image Segmentation|少量样本医学图像分割的绑定原型模型|Hyeongji Kim, Stine Hansen, Michael Kampffmeyer|<http://arxiv.org/pdf/2506.22101v1>|[代码](https://github.com/hjk92g/TPM-FSS.); 提出了一种改进的医学图像少量样本分割方法，通过联合前景和背景的绑定原型模型，提高了分割准确性和适应性...|
|🆕 发布|Cross-modal Ship Re-Identification via Optical and SAR Imagery: A Novel Dataset and Method|跨模态船舶重识别：基于光学与合成孔径雷达图像的新数据集与方法|Han Wang, Shengyang Li, Jian Yang, Yuxuan Liu, Yixuan Lv, Zhuang Zhou|<http://arxiv.org/pdf/2506.22027v1>|[代码](https://github.com/Alioth2000/Hoss-ReID.); 提出了一种基于光学和合成孔径雷达的跨模态船舶重识别方法，创建了适用于全天候船舶追踪的新数据集。|
|📝 更新|FSDA-DG: Improving Cross-Domain Generalizability of Medical Image Segmentation with Few Source Domain Annotations|FSDA-DG：利用少量源域注释提高医学图像分割的跨域泛化性|Zanting Ye, Ke Wang, Wenbing Lv, Qianjin Feng, Lijun Lu|<http://arxiv.org/pdf/2311.02583v2>|[代码](https://github.com/yezanting/FSDA-DG.); 提出了一种少量源域标注的医学图像分割方法FSDA-DG，通过语义引导的半监督数据增强和U-Net网络...|
|📝 更新|Med-LEGO: Editing and Adapting toward Generalist Medical Image Diagnosis|医-乐高：面向通用医疗图像诊断的编辑与适应|Yitao Zhu, Yuan Yin, Jiaming Li, Mengjie Xu, Zihao Zhao, Honglin Xiong, Sheng Wang, Qian Wang|<http://arxiv.org/pdf/2503.01164v2>|提出Med-LEGO框架，通过组合多个专家模型实现无需重训练即可更新或整合通用医疗诊断模型。|
|🆕 发布|PrefPaint: Enhancing Image Inpainting through Expert Human Feedback|PrefPaint：通过专家人类反馈增强图像修复|Duy-Bao Bui, Hoang-Khang Nguyen, Trung-Nghia Le|<http://arxiv.org/pdf/2506.21834v1>|PrefPaint通过整合专家反馈优化图像修复，提升医疗图像的准确性和可靠性。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Integrating Multi-Modal Sensors: A Review of Fusion Techniques for Intelligent Vehicles|集成多模态传感器：智能车辆融合技术的综述|Chuheng Wei, Ziye Qin, Ziyan Zhang, Guoyuan Wu, Matthew J. Barth|<http://arxiv.org/pdf/2506.21885v1>|系统综述了智能车辆多传感器融合策略及其在自动驾驶中的应用，强调了其在提升系统适应性和鲁棒性方面的潜力...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|QuKAN: A Quantum Circuit Born Machine approach to Quantum Kolmogorov Arnold Networks|QuKAN：一种基于量子电路生成机的量子科尔莫哥洛夫-阿诺德网络方法|Yannick Werner, Akash Malemath, Mengxi Liu, Vitor Fortes Rey, Nikolaos Palaiodimopoulos, Paul Lukowicz, Maximilian Kiefer-Emmanouilidis|<http://arxiv.org/pdf/2506.22340v1>|提出量子电路版Kolmogorov Arnold网络，融合量子计算提升神经网络表达复杂函数的能力。|
|🆕 发布|Closing the Performance Gap in Biometric Cryptosystems: A Deeper Analysis on Unlinkable Fuzzy Vaults|缩小生物识别密码系统性能差距：对不可链接模糊金库的深度分析|Hans Geißner, Christian Rathgeb|<http://arxiv.org/pdf/2506.22347v1>|提出一种基于等频间隔的特征量化方法，缩小了生物识别加密系统中性能差距。|

