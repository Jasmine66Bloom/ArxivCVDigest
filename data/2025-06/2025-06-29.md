## [UPDATED!] **2025-06-29** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Towards Cross-modal Backward-compatible Representation Learning for Vision-Language Models|面向视觉语言模型的跨模态向后兼容表征学习|Young Kyun Jang, Ser-nam Lim|<http://arxiv.org/pdf/2405.14715v2>|提出了一种投影模块，实现视觉语言模型间的向后兼容性，减少数据重计算需求。|
|📝 更新|I see what you mean: Co-Speech Gestures for Reference Resolution in Multimodal Dialogue|我明白你的意思：协同言语手势在多模态对话中的参考解析|Esam Ghaleb, Bulat Khaertdinov, Aslı Özyürek, Raquel Fernández|<http://arxiv.org/pdf/2503.00071v3>|引入基于代表性格手势的多模态参考解析任务，提出自监督预训练学习手势表征，提升参考解析准确性。|
|📝 更新|CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model|CountLLM：通过大规模语言模型实现通用性重复动作计数|Ziyu Yao, Xuxin Cheng, Zhiqi Huang, Lei Li|<http://arxiv.org/pdf/2503.17690v2>|提出CountLLM框架，利用大型语言模型和周期性文本提示进行视频重复动作计数，增强泛化能力。|
|🆕 发布|Token Activation Map to Visually Explain Multimodal LLMs|“用于视觉解释多模态大型语言模型的Token激活图”|Yi Li, Hualiang Wang, Xinpeng Ding, Haonan Wang, Xiaomeng Li|<http://arxiv.org/pdf/2506.23270v1>|[代码](https://github.com/xmed-lab/TAM.); 提出了一种Token Activation Map方法，通过降低上下文干扰，有效提升了多模态大语言模...|
|🆕 发布|Forget-MI: Machine Unlearning for Forgetting Multimodal Information in Healthcare Settings|忘记-多模态：医疗环境中忘记多模态信息的机器遗忘方法|Shahad Hardan, Darya Taratynova, Abdelmajid Essofi, Karthik Nandakumar, Mohammad Yaqub|<http://arxiv.org/pdf/2506.23145v1>|[代码](https://github.com/BioMedIA-MBZUAI/Forget-MI.git); 提出Forget-MI方法，用于医疗多模态数据中的信息遗忘，保护隐私同时保持模型性能。|
|🆕 发布|MoCa: Modality-aware Continual Pre-training Makes Better Bidirectional Multimodal Embeddings|MoCa：模态感知的持续预训练使双向多模态嵌入更加优秀|Haonan Chen, Hong Liu, Yuping Luo, Liang Wang, Nan Yang, Furu Wei, Zhicheng Dou|<http://arxiv.org/pdf/2506.23115v1>|提出MoCa方法，通过双向注意力和多样化数据提升多模态嵌入模型的性能和泛化能力。|
|📝 更新|MMInA: Benchmarking Multihop Multimodal Internet Agents|多跳多模态互联网代理基准测试：MMInA|Shulin Tian, Ziniu Zhang, Liangyu Chen, Ziwei Liu|<http://arxiv.org/pdf/2404.09992v2>|[代码](https://github.com/shulin16/MMInA.); 提出多跳多模态互联网代理基准MMInA，评估智能体在动态网站中完成复杂任务的能力，并引入记忆增强策略...|
|📝 更新|HyperPath: Knowledge-Guided Hyperbolic Semantic Hierarchy Modeling for WSI Analysis|超路径：基于知识引导的双曲语义层次建模用于全切片图像分析|Peixiang Huang, Yanyan Huang, Weiqin Zhao, Junjun He, Lequan Yu|<http://arxiv.org/pdf/2506.16398v3>|提出了一种利用文本知识引导在双曲空间建模WSI语义层次的方法，提升了WSI分类性能。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CycleVAR: Repurposing Autoregressive Model for Unsupervised One-Step Image Translation|循环向量自回归：将自回归模型重用于无监督一步图像转换|Yi Liu, Shengqian Li, Zuzeng Lin, Feng Wang, Si Liu|<http://arxiv.org/pdf/2506.23347v1>|提出Softmax Relaxed Quantization解决梯度中断问题，并引入CycleVAR...|
|🆕 发布|ReMem: Mutual Information-Aware Fine-tuning of Pretrained Vision Transformers for Effective Knowledge Distillation|ReMem：基于互信息的预训练视觉变换器微调以实现有效的知识蒸馏|Chengyu Dong, Huan Gui, Noveen Sachdeva, Long Jin, Ke Yin, Jingbo Shang, Lichan Hong, Ed H. Chi .etc.|<http://arxiv.org/pdf/2506.23041v1>|提出 mutual information-aware fine-tuning 方法优化 ViT 预...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Scaling Laws for Black box Adversarial Attacks|《黑盒对抗攻击的放缩法则》|Chuan Liu, Huanran Chen, Yichi Zhang, Yinpeng Dong, Jun Zhu|<http://arxiv.org/pdf/2411.16782v3>|揭示了增加代理模型数量可提升对抗样本的迁移性，实现了对黑盒模型的高效攻击。|
|🆕 发布|FastSeg: Efficient Training-Free Open-Vocabulary Segmentation via Hierarchical Attention Refinement Method|快速分割：通过层次化注意力精炼方法的无需训练的开词汇分割|Quang-Huy Che, Vinh-Tiep Nguyen|<http://arxiv.org/pdf/2506.23323v1>|提出FastSeg，一种无需训练的高效开放词汇分割框架，通过双提示机制和分层注意力精炼方法提升分割质...|
|🆕 发布|MoMa: Modulating Mamba for Adapting Image Foundation Models to Video Recognition|MoMa：调节蟒蛇模型以适应图像基础模型至视频识别|Yuhuan Yang, Chaofan Ma, Zhenjie Mao, Jiangchao Yao, Ya Zhang, Yanfeng Wang|<http://arxiv.org/pdf/2506.23283v1>|提出了一种整合时空信息的适配器框架MoMa，有效提升图像基础模型在视频理解上的性能。|
|🆕 发布|UrbanLLaVA: A Multi-modal Large Language Model for Urban Intelligence with Spatial Reasoning and Understanding|《UrbanLLaVA：一种具有空间推理和理解能力的城市智能多模态大型语言模型》|Jie Feng, Shengyuan Wang, Tianhui Liu, Yanxin Xi, Yong Li|<http://arxiv.org/pdf/2506.23219v1>|[代码](https://github.com/tsinghua-fib-lab/UrbanLLaVA.); 提出UrbanLLaVA模型，通过多模态大数据和分阶段训练，提升城市任务处理性能。|
|📝 更新|Time-R1: Post-Training Large Vision Language Model for Temporal Video Grounding|时间R1：面向时序视频定位的后训练大型视觉语言模型|Ye Wang, Ziheng Wang, Boshen Xu, Yang Du, Kejun Lin, Zihan Xiao, Zihao Yue, Jianzhong Ju .etc.|<http://arxiv.org/pdf/2503.13377v3>|提出了一种基于强化学习的后训练框架Time-R1，通过可验证的奖励机制增强大型视觉语言模型在视频定位...|
|🆕 发布|Dare to Plagiarize? Plagiarized Painting Recognition and Retrieval|敢于抄袭吗？抄袭绘画识别与检索|Sophie Zhou, Shu Kong|<http://arxiv.org/pdf/2506.23132v1>|提出了一种基于AI的绘画抄袭识别方法，通过细调视觉模型提高了检索精度。|
|🆕 发布|MedRegion-CT: Region-Focused Multimodal LLM for Comprehensive 3D CT Report Generation|MedRegion-CT：面向区域的多种模态大规模语言模型用于全面的三维CT报告生成|Sunggu Kyung, Jinyoung Seo, Hyunseok Lim, Dongyeong Kim, Hyungbin Park, Jimin Sung, Jihyun Kim, Wooyoung Jo .etc.|<http://arxiv.org/pdf/2506.23102v1>|提出了一种区域聚焦的多模态大规模语言模型MedRegion-CT，通过提取3D CT的区域特征，提高...|
|🆕 发布|Ovis-U1 Technical Report|Ovis-U1 技术报告|Guo-Hua Wang, Shanshan Zhao, Xinjie Zhang, Liangfu Cao, Pengxin Zhan, Lunhao Duan, Shiyin Lu, Minghao Fu .etc.|<http://arxiv.org/pdf/2506.23044v1>|介绍了Ovis-U1，一种融合多模态理解、文本到图像生成和图像编辑能力的30亿参数统一模型，实现性能...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BPD-Neo: An MRI Dataset for Lung-Trachea Segmentation with Clinical Data for Neonatal Bronchopulmonary Dysplasia|BPD-Neo：一种用于新生儿支气管肺发育不良的肺-气管分割的MRI数据集及临床数据|Rachit Saluja, Arzu Kovanlikaya, Candace Chien, Lauren Kathryn Blatt, Jeffrey M. Perlman, Stefan Worgall, Mert R. Sabuncu, Jonathan P. Dyke|<http://arxiv.org/pdf/2506.23305v1>|介绍了用于新生儿支气管肺发育不良的MRI数据集，助力无创诊断并提供了临床数据和基准分割模型。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DDL: A Dataset for Interpretable Deepfake Detection and Localization in Real-World Scenarios|DDL:面向现实场景的可解释深度伪造检测与定位数据集|Changtao Miao, Yi Zhang, Weize Gao, Man Luo, Weiwei Feng, Zhiya Tan, Jianshu Li, Ajian Liu .etc.|<http://arxiv.org/pdf/2506.23292v1>|[代码](https://deepfake-workshop-ijcai2025.github.io/main); 构建了一个大规模的DDL数据集，包含多样化伪造场景和细粒度注释，以提升深伪检测与解释性。|
|🆕 发布|DGE-YOLO: Dual-Branch Gathering and Attention for Accurate UAV Object Detection|DGE-YOLO：双分支聚合与注意力机制用于精确无人机目标检测|Kunwei Lv, Ping Lan|<http://arxiv.org/pdf/2506.23252v1>|提出DGE-YOLO框架，通过双分支架构和高效多尺度注意力机制，提升复杂环境下无人机多模态目标检测准...|
|📝 更新|Dense Feature Interaction Network for Image Inpainting Localization|图像修复定位的密集特征交互网络|Ye Yao, Tingfeng Han, Shan Jia, Siwei Lyu|<http://arxiv.org/pdf/2408.02191v2>|[代码](https://github.com/Boombb/DeFI-Net_Inpainting.); 提出了一种Dense Feature Interaction Network，通过增强特征级交互和自...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Aggregating Local Saliency Maps for Semi-Global Explainable Image Classification|聚合局部显著性图用于半全局可解释图像分类|James Hinns, David Martens|<http://arxiv.org/pdf/2506.23247v1>|提出Segment Attribution Tables方法，将局部解释汇总为全局图像分类的洞见。|
|🆕 发布|A Hierarchical Slice Attention Network for Appendicitis Classification in 3D CT Scans|用于三维CT扫描中阑尾炎分类的层次化切片注意力网络|Chia-Wen Huang, Haw Hwai, Chien-Chang Lee, Pei-Yuan Wu|<http://arxiv.org/pdf/2506.23209v1>|提出了一种结合3D CT扫描和2D数据引导的切片注意力机制，用于提高阑尾炎及其复杂性的诊断准确率。|
|🆕 发布|maneuverRecognition -- A Python package for Timeseries Classification in the domain of Vehicle Telematics|车辆远程信息处理领域中时间序列分类的Python包——机动识别|Jonathan Schuster, Fabian Transchel|<http://arxiv.org/pdf/2506.23147v1>|开发了maneuverRecognition包，简化了驾驶行为识别的数据处理和模型构建过程。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Improving Myocardial Infarction Detection via Synthetic ECG Pretraining|通过合成心电图预训练提高心肌梗死检测准确性|Lachin Naghashyar|<http://arxiv.org/pdf/2506.23259v1>|提出了一种生成合成ECG并使用自监督预训练的方法，有效提升了心肌梗死检测性能。|
|🆕 发布|High-quality Pseudo-labeling for Point Cloud Segmentation with Scene-level Annotation|高质量伪标签法用于场景级标注的点云分割|Lunhao Duan, Shanshan Zhao, Xingxing Weng, Jing Zhang, Gui-Song Xia|<http://arxiv.org/pdf/2506.23227v1>|[代码](https://github.com/LHDuan/WSegPC); 提出了一种利用多模态信息和区域点语义一致性生成高质量伪标签的方法，有效提升了室内点云语义分割的准确性...|
|🆕 发布|Transformer-Based Person Search with High-Frequency Augmentation and Multi-Wave Mixing|基于Transformer的人物搜索方法：高频增强与多波混合|Qilin Shu, Qixian Zhang, Qi Zhang, Hongyun Zhang, Duoqian Miao, Cairong Zhao|<http://arxiv.org/pdf/2506.23202v1>|提出了一种基于Transformer的高频增强与多尺度融合方法，提升了人物搜索的准确性和效率。|
|📝 更新|BST: Badminton Stroke-type Transformer for Skeleton-based Action Recognition in Racket Sports|羽毛球击球类型变换器：基于骨架的 racket sports 动作识别|Jing-Yuan Chang|<http://arxiv.org/pdf/2502.21085v2>|提出了一种针对羽毛球挥拍动作识别的Badminton Stroke-type Transformer...|
|📝 更新|Accelerate 3D Object Detection Models via Zero-Shot Attention Key Pruning|结果： 通过零样本注意力关键剪枝加速三维物体检测模型|Lizhen Xu, Xiuxiu Bai, Xiaojun Jia, Jianwu Fang, Shanmin Pang|<http://arxiv.org/pdf/2503.08101v3>|[代码](https://github.com/iseri27/tg_gbc.); 提出了一种无需重训练的零样本注意力键剪枝方法，显著提升了3D物体检测模型在边缘设备上的运行效率。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Unveiling and Mitigating Memorization in Text-to-image Diffusion Models through Cross Attention|通过交叉注意力揭示和减轻文本到图像扩散模型中的记忆效应|Jie Ren, Yaxin Li, Shenglai Zeng, Han Xu, Lingjuan Lyu, Yue Xing, Jiliang Tang|<http://arxiv.org/pdf/2403.11052v2>|[代码](https://github.com/renjie3/MemAttn); 揭示了文本到图像扩散模型中注意力机制导致的记忆现象，并提出了一种不影响训练和推理速度的缓解方法。|
|📝 更新|Meta-LoRA: Meta-Learning LoRA Components for Domain-Aware ID Personalization|元学习LoRA组件以实现面向领域的身份个性化|Barış Batuhan Topal, Umut Özyurt, Zafer Doğan Budak, Ramazan Gokberk Cinbis|<http://arxiv.org/pdf/2503.22352v3>|提出Meta-LoRA方法，通过元学习优化LoRA架构，实现快速且准确的身份个性化图像生成。|
|🆕 发布|Why Settle for Mid: A Probabilistic Viewpoint to Spatial Relationship Alignment in Text-to-image Models|为何满足于中等：文本到图像模型中空间关系对齐的概率视角|Parham Rezaei, Arash Marioriyad, Mahdieh Soleymani Baghshah, Mohammad Hossein Rohban|<http://arxiv.org/pdf/2506.23418v1>|提出概率优势框架PoS，通过新型评估指标和生成方法，提升文本到图像模型的空间关系对齐准确性。|
|🆕 发布|A High-Throughput Platform to Bench Test Smartphone-Based Heart Rate Measurements Derived From Video|一种高吞吐量平台，用于基准测试基于视频的智能手机心率测量|Ming-Zher Poh, Jonathan Wang, Jonathan Hsu, Lawrence Cai, Eric Teasley, James A. Taylor, Jameson K. Rogers, Anupam Pathak .etc.|<http://arxiv.org/pdf/2506.23414v1>|开发了一种高效率的测试平台，自动化评估智能手机心率监测应用的准确性和兼容性。|
|📝 更新|Efficient Diffusion Training through Parallelization with Truncated Karhunen-Loève Expansion|通过截断Karhunen-Loève展开的并行化进行高效扩散训练|Yumeng Ren, Yaofang Liu, Aitor Artola, Laurent Mertz, Raymond H. Chan, Jean-michel Morel|<http://arxiv.org/pdf/2503.17657v2>|通过截断Karhunen-Loève展开表示布朗运动，提出KL扩散方法，加速了扩散去噪模型的训练收敛...|
|📝 更新|Semantic-Aware Adaptive Video Streaming Using Latent Diffusion Models for Wireless Networks|基于潜在扩散模型的语义感知自适应视频流传输技术在无线网络中的应用|Zijiang Yan, Jianhua Pei, Hongda Wu, Hina Tabassum, Ping Wang|<http://arxiv.org/pdf/2502.05695v2>|提出语义感知的自适应视频流传输框架，通过融合潜在扩散模型减少带宽使用并提升观看体验。|
|🆕 发布|Score-based Diffusion Model for Unpaired Virtual Histology Staining|基于分数的扩散模型用于无配对虚拟组织学染色|Anran Liu, Xiaofei Wang, Jing Cai, Chao Li|<http://arxiv.org/pdf/2506.23184v1>|提出了一种基于互信息的分数扩散模型，实现了无配对虚拟组织学染色的精确控制和结构一致性。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OmniVCus: Feedforward Subject-driven Video Customization with Multimodal Control Conditions|全方位个性化视频定制：基于前馈主体驱动及多模态控制条件|Yuanhao Cai, He Zhang, Xi Chen, Jinbo Xing, Yiwei Hu, Yuqian Zhou, Kai Zhang, Zhifei Zhang .etc.|<http://arxiv.org/pdf/2506.23361v1>|[代码](https://github.com/caiyuanhao1998/Open-OmniVCus); 提出了一种生成多主体定制视频的方法OmniVCus，通过创新的数据构造和扩散Transformer框...|
|📝 更新|Composing Parts for Expressive Object Generation|“组合部件以实现富有表现力的物体生成”|Harsh Rangwani, Aishwarya Agarwal, Kuldeep Kulkarni, R. Venkatesh Babu, Srikrishna Karanam|<http://arxiv.org/pdf/2406.10197v2>|提出了一种无需训练的图像生成方法PartComposer，实现了基于细粒度部分属性的精确图像生成控制...|
|🆕 发布|SurgTPGS: Semantic 3D Surgical Scene Understanding with Text Promptable Gaussian Splatting|手术场景语义三维理解：基于文本提示的高斯散点模型|Yiming Huang, Long Bai, Beilei Cui, Kun Yuan, Guankun Wang, Mobarakol Islam, Nicolas Padoy, Nassir Navab .etc.|<http://arxiv.org/pdf/2506.23309v1>|[代码](https://github.com/lastbasket/SurgTPGS.); 提出SurgTPGS方法，通过文本提示实现实时三维手术场景理解和重建，提升手术精度与安全性。|
|🆕 发布|InfGen: Scenario Generation as Next Token Group Prediction|InfGen：场景生成作为下一个标记组预测|Zhenghao Peng, Yuxin Liu, Bolei Zhou|<http://arxiv.org/pdf/2506.23316v1>|[代码](https://metadriverse.github.io/infgen); 提出了一种无限场景生成框架InfGen，通过自回归方式模拟动态交通，提升自动驾驶系统的训练与评估效果...|
|🆕 发布|DiffFit: Disentangled Garment Warping and Texture Refinement for Virtual Try-On|DiffFit：解耦衣物扭曲与纹理细化用于虚拟试穿|Xiang Xu|<http://arxiv.org/pdf/2506.23295v1>|提出DiffFit，一种分两阶段的高保真虚拟试衣框架，通过解耦几何对齐与外观细化，提升了细节保留和视...|
|🆕 发布|Autoregressive Denoising Score Matching is a Good Video Anomaly Detector|自回归去噪得分匹配是一种优秀视频异常检测器|Hanwen Zhang, Congqi Cao, Qinyi Lv, Lingtong Min, Yanning Zhang|<http://arxiv.org/pdf/2506.23282v1>|提出了一种结合场景、运动和外观信息的自回归去噪得分匹配方法，有效检测视频异常。|
|📝 更新|FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait|FLOAT：音频驱动的说话肖像生成运动潜在流匹配|Taekyung Ki, Dongchan Min, Gyeongsu Chae|<http://arxiv.org/pdf/2412.01064v3>|提出了一种基于流匹配生成模型的音频驱动说话肖像视频生成方法，通过正交运动潜在空间实现高效、一致的运动...|
|🆕 发布|PixelBoost: Leveraging Brownian Motion for Realistic-Image Super-Resolution|像素增强：利用布朗运动实现真实图像的超分辨率|Aradhana Mishra, Bumshik Lee|<http://arxiv.org/pdf/2506.23254v1>|PixelBoost通过融合布朗运动的随机性，实现了高效且逼真的图像超分辨率，提升了纹理和边缘的清晰...|
|🆕 发布|Causal-Entity Reflected Egocentric Traffic Accident Video Synthesis|基于因果实体反射的第一人称交通事故视频合成|Lei-lei Li, Jianwu Fang, Junbin Xiao, Shanmin Pang, Hongkai Yu, Chen Lv, Jianru Xue, Tat-Seng Chua|<http://arxiv.org/pdf/2506.23263v1>|提出了一种新的扩散模型Causal-VidSyn，通过结合事故原因描述和驾驶员注视数据，合成反映因果...|
|🆕 发布|BridgeShape: Latent Diffusion Schrödinger Bridge for 3D Shape Completion|桥形：用于三维形状补全的潜在扩散薛定谔桥|Dequan Kong, Zhe Zhu, Honghua Chen, Mingqiang Wei|<http://arxiv.org/pdf/2506.23205v1>|提出了一种基于潜在扩散Schrödinger桥的3D形状补全框架，通过优化全局传输路径实现高效且高保...|
|📝 更新|Pretrained Reversible Generation as Unsupervised Visual Representation Learning|预训练可逆生成作为无监督视觉表征学习|Rongkun Xue, Jinouwen Zhang, Yazhe Niu, Dazhong Shen, Bingqi Ma, Yu Liu, Jing Yang|<http://arxiv.org/pdf/2412.01787v4>|[代码](https://github.com/opendilab/PRG.); 提出利用预训练生成模型逆向过程提取无监督视觉表征，实现多种任务上的性能提升。|
|🆕 发布|AlignCVC: Aligning Cross-View Consistency for Single-Image-to-3D Generation|AlignCVC：对单张图像到3D生成进行跨视角一致性对齐|Xinyue Liang, Zhiyuan Ma, Lingchen Sun, Yanjun Guo, Lei Zhang|<http://arxiv.org/pdf/2506.23150v1>|提出了一种基于分布对齐的框架AlignCVC，通过优化多视角一致性显著提升单张图像到3D模型生成的质...|
|🆕 发布|RoboScape: Physics-informed Embodied World Model|机器人景观：物理信息增强的具身世界模型|Yu Shang, Xin Zhang, Yinzhou Tang, Lei Jin, Chen Gao, Wei Wu, Yong Li|<http://arxiv.org/pdf/2506.23135v1>|[代码](https://github.com/tsinghua-fib-lab/RoboScape.); 提出RoboScape模型，融合物理知识提升机器人场景视频生成的真实感和物理一致性。|
|📝 更新|ZipAR: Parallel Auto-regressive Image Generation through Spatial Locality|ZipAR：通过空间局部性实现的并行自回归图像生成|Yefei He, Feng Chen, Yuanyu He, Shaoxuan He, Hong Zhou, Kaipeng Zhang, Bohan Zhuang|<http://arxiv.org/pdf/2412.04062v3>|[代码](https://github.com/ThisisBillhe/ZipAR.); 提出了一种无需训练、即插即用的并行解码框架ZipAR，通过利用图像的空间局部性加速自动回归视觉生成。|
|📝 更新|Incomplete Multi-view Clustering via Diffusion Contrastive Generation|通过扩散对比生成的不完整多视角聚类|Yuanyang Zhang, Yijie Lin, Weiqing Yan, Li Yao, Xinhang Wan, Guangyuan Li, Chao Zhang, Guanzhou Ke .etc.|<http://arxiv.org/pdf/2503.09185v2>|[代码](https://github.com/zhangyuanyang21/2025-AAAI-DCG.); 提出了一种名为Diffusion Contrastive Generation的算法，通过对比学习少...|
|📝 更新|Relating Events and Frames Based on Self-Supervised Learning and Uncorrelated Conditioning for Unsupervised Domain Adaptation|基于自监督学习和无关联条件的事件与帧关联用于无监督领域自适应|Mohammad Rostami, Dayuan Jian, Ruitong Sun|<http://arxiv.org/pdf/2401.01042v2>|提出了一种结合自监督学习和无关条件的方法，实现了从帧到事件的深度神经网络的无监督域自适应。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Super-Resolution Generative Adversarial Networks based Video Enhancement|基于超分辨率生成对抗网络的视频增强|Kağan Çetin, Hacer Akça, Ömer Nezih Gerek|<http://arxiv.org/pdf/2505.10589v4>|提出了一种结合3D非局部块的视频超分辨率方法，有效提升了视频质量和时序连贯性。|
|🆕 发布|VisualPrompter: Prompt Optimization with Visual Feedback for Text-to-Image Synthesis|视觉提示器：基于视觉反馈的文本到图像合成提示优化|Shiyu Wu, Mingzhen Sun, Weining Wang, Yequan Wang, Jing Liu|<http://arxiv.org/pdf/2506.23138v1>|提出VisualPrompter，一种无需训练的提示优化框架，通过视觉反馈精确调整用户描述，提升文本...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Why Settle for One? Text-to-ImageSet Generation and Evaluation|为何止步于一个？文本到图像集生成与评估|Chengyou Jia, Xin Shen, Zhuohang Dang, Zhuohang Dang, Changliang Xia, Weijia Wu, Xinyu Zhang, Hangwei Qian .etc.|<http://arxiv.org/pdf/2506.23275v1>|[代码](https://chengyou-jia.github.io/T2IS-Home.); 提出了一种生成满足多样化一致性要求的图像集合的方法，并通过新的评估框架和训练-free框架显著提升了...|
|🆕 发布|Single Image Inpainting and Super-Resolution with Simultaneous Uncertainty Guarantees by Universal Reproducing Kernels|单张图像修复与超分辨率重建的同时不确定性保证：通用再生核方法|Bálint Horváth, Balázs Csanád Csáji|<http://arxiv.org/pdf/2506.23221v1>|提出了一种基于统计学习的图像修复和超分辨率方法，同时提供对估计值的不确定性量化。|
|📝 更新|HumanGif: Single-View Human Diffusion with Generative Prior|《HumanGif：基于生成先验的单视角人体扩散》|Shoukang Hu, Takuya Narihira, Kazumi Fukuda, Ryosuke Sawata, Takashi Shibuya, Yuki Mitsufuji|<http://arxiv.org/pdf/2502.12080v3>|提出HumanGif模型，通过生成先验和3D扩散过程，从单张图片生成真实、一致的三维人类形象。|
|🆕 发布|CoreMark: Toward Robust and Universal Text Watermarking Technique|核心标记：迈向鲁棒且通用的文本水印技术|Jiale Meng, Yiming Li, Zheming Lu, Zewei He, Hao Luo, Tianwei Zhang|<http://arxiv.org/pdf/2506.23066v1>|提出CoreMark文本水印框架，通过调整字符核心黑像素段厚度嵌入数据，实现跨语言和字体的鲁棒性与隐...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Endo-4DGX: Robust Endoscopic Scene Reconstruction and Illumination Correction with Gaussian Splatting|内窥镜场景重建与光照校正的稳健方法：基于高斯散点投射|Yiming Huang, Long Bai, Beilei Cui, Yanheng Li, Tong Chen, Jie Wang, Jinlin Wu, Zhen Lei .etc.|<http://arxiv.org/pdf/2506.23308v1>|[代码](https://github.com/lastbasket/Endo-4DGX.); 提出了一种针对内镜场景不均匀光照的鲁棒重建方法Endo-4DGX，通过光照自适应高斯散点技术提升渲染...|
|🆕 发布|TVG-SLAM: Robust Gaussian Splatting SLAM with Tri-view Geometric Constraints|三视图几何约束下的鲁棒高斯散点SLAM|Zhen Tan, Xieyuanli Chen, Lei Feng, Yangbing Ge, Shuaifeng Zhi, Jiaxiong Liu, Dewen Hu|<http://arxiv.org/pdf/2506.23207v1>|提出TVG-SLAM系统，通过三视角几何约束增强RGB-only SLAM的跟踪稳定性和映射质量。|
|🆕 发布|STD-GS: Exploring Frame-Event Interaction for SpatioTemporal-Disentangled Gaussian Splatting to Reconstruct High-Dynamic Scene|STD-GS：探索帧事件交互以实现时空解耦高斯散点绘制，重构高动态场景|Hanyu Zhou, Haonan Wang, Haoyue Liu, Yuxing Duan, Luxin Yan, Gim Hee Lee|<http://arxiv.org/pdf/2506.23157v1>|提出了一种区分背景与动态物体时空特征的Gaussian splatting框架，实现高动态场景的精确...|
|🆕 发布|Unsupervised 3D Braided Hair Reconstruction from a Single-View Image|从单视角图像中无监督重建三维辫子头发|Jing Gao|<http://arxiv.org/pdf/2506.23072v1>|提出了一种无需监督的3D辫发重建方法，有效捕捉辫发的复杂交织结构。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CarGait: Cross-Attention based Re-ranking for Gait recognition|基于交叉注意力的步态识别重排算法CarGait|Gavriel Habib, Noa Barzilay, Or Shimshi, Rami Ben-Ari, Nir Darshan|<http://arxiv.org/pdf/2503.03501v2>|提出了一种基于交叉注意力的重排方法CarGait，通过分析细粒度动作关联提升步态识别准确性。|
|🆕 发布|Dynamic View Synthesis from Small Camera Motion Videos|从小摄像头运动视频中动态合成视角|Huiqiang Sun, Xingyi Li, Juewen Peng, Liao Shen, Zhiguo Cao, Ke Xian, Guosheng Lin|<http://arxiv.org/pdf/2506.23153v1>|提出了一种针对小范围相机运动视频的动态视图合成方法，通过分布式深度规律化和相机参数学习，有效解决了场...|
|🆕 发布|Hierarchical Corpus-View-Category Refinement for Carotid Plaque Risk Grading in Ultrasound|基于层次化语料库-视图-类别优化的颈动脉斑块风险分级超声图像分析|Zhiyuan Zhu, Jian Wang, Yong Jiang, Tong Han, Yuhao Huang, Ang Zhang, Kaiwen Yang, Mingyuan Luo .etc.|<http://arxiv.org/pdf/2506.23108v1>|提出了一种多级优化的超声图像处理框架，有效提升了颈动脉斑块风险分级精度。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Structure-Aware Radar-Camera Depth Estimation|结构感知的雷达-相机深度估计|Fuyi Zhang, Zhu Yu, Chunhao Li, Runmin Zhang, Xiaokai Bai, Zili Zhou, Si-Yuan Cao, Fang Wang .etc.|<http://arxiv.org/pdf/2506.05008v3>|[代码](https://github.com/FreyZhangYeh/SA-RCD.); 提出结构感知的雷达-相机深度估计框架，通过利用图像结构先验增强雷达数据，实现精确且结构详细的深度估计...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DEL: Dense Event Localization for Multi-modal Audio-Visual Understanding|DEL: 多模态音频视觉理解中的密集事件定位|Mona Ahmadian, Amir Shirian, Frank Guerin, Andrew Gilbert|<http://arxiv.org/pdf/2506.23196v1>|提出DEL框架，通过音频视觉特征对齐和多尺度交互 refinement，实现了视频中的密集语义动作定...|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MrTrack: Register Mamba for Needle Tracking with Rapid Reciprocating Motion during Ultrasound-Guided Aspiration Biopsy|"MrTrack：利用快速往复运动在超声引导下抽吸活检中注册Mamba进行针跟踪"|Yuelin Zhang, Qingpeng Ding, Long Lei, Yongxuan Feng, Raymond Shing-Yan Tang, Shing Shin Cheng|<http://arxiv.org/pdf/2505.09450v2>|[代码](https://github.com/PieceZhang/MrTrack); 提出了一种基于Mamba注册机制的针具追踪算法，有效应对了超声引导下快速往复运动中的追踪难题。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Fetuses Made Simple: Modeling and Tracking of Fetal Shape and Pose|胎儿形态与姿态建模及跟踪：化繁为简|Yingcheng Liu, Peiqi Wang, Sebastian Diaz, Esra Abaci Turk, Benjamin Billot, Patricia Ellen Grant, Polina Golland|<http://arxiv.org/pdf/2506.17858v2>|[代码](https://github.com/MedicalVisionGroup/fetal-smpl); 构建首个3D统计胎儿模型，通过迭代估计姿势和形状，提升MRI运动分析鲁棒性。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Enhancing Adversarial Robustness through Multi-Objective Representation Learning|通过多目标表征学习增强对抗性鲁棒性|Sedjro Salomon Hotegni, Sebastian Peitz|<http://arxiv.org/pdf/2410.01697v4>|[代码](https://github.com/salomonhotegni/MOREL); 提出多目标特征学习方法MOREL，通过相似性损失增强模型对对抗攻击的鲁棒性。|
|🆕 发布|Self-Supervised Contrastive Learning for Multi-Label Images|用于多标签图像的自监督对比学习|Jiale Chen|<http://arxiv.org/pdf/2506.23156v1>|提出了一种针对多标签图像的自监督对比学习方法，通过块状增强和图像感知对比损失，实现了在较少样本上的优...|
|🆕 发布|Dynamic Contrastive Learning for Hierarchical Retrieval: A Case Study of Distance-Aware Cross-View Geo-Localization|动态对比学习在层次检索中的应用：距离感知跨视图地理定位案例分析|Suofei Zhang, Xinxin Wang, Xiaofu Wu, Quan Zhou, Haifeng Hu|<http://arxiv.org/pdf/2506.23077v1>|[代码](https://github.com/anocodetest1/DyCL.); 提出动态对比学习框架，通过层次化空间边界的逐步对齐，提升跨视图地理定位的准确性和效率。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SIEDD: Shared-Implicit Encoder with Discrete Decoders|共享隐式编码器与离散解码器：SIEDD|Vikram Rangarajan, Shishira Maiya, Max Ehrlich, Abhinav Shrivastava|<http://arxiv.org/pdf/2506.23382v1>|[代码](https://github.com/VikramRangarajan/SIEDD); 提出SIEDD架构，通过共享隐式编码器和离散解码器加速视频压缩编码，大幅提升速度同时保持重建质量。|
|🆕 发布|Trident: Detecting Face Forgeries with Adversarial Triplet Learning|三头犬：利用对抗性三元组学习检测人脸伪造|Mustafa Hakan Kara, Aysegul Dundar, Uğur Güdükbay|<http://arxiv.org/pdf/2506.23189v1>|提出了一种利用对抗性三元组学习的面部伪造检测框架，增强了跨不同伪造技术的适应性。|
|🆕 发布|MEMFOF: High-Resolution Training for Memory-Efficient Multi-Frame Optical Flow Estimation|MEMFOF：用于内存高效多帧光流估计的高分辨率训练|Vladislav Bargatin, Egor Chistov, Alexander Yakovenko, Dmitriy Vatolin|<http://arxiv.org/pdf/2506.23151v1>|[代码](https://github.com/msu-video-group/memfof.); MEMFOF通过优化内存使用，实现了无需裁剪或降采样即可在原生1080p分辨率下训练的高效多帧光流估...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OmniEval: A Benchmark for Evaluating Omni-modal Models with Visual, Auditory, and Textual Inputs|OmniEval：一个用于评估具有视觉、听觉和文本输入的全模态模型的基准|Yiman Zhang, Ziheng Luo, Qiangyu Yan, Wei He, Borui Jiang, Xinghao Chen, Kai Han|<http://arxiv.org/pdf/2506.20960v2>|[代码](https://omnieval-benchmark.github.io/.); 提出了OmniEval基准，全面评估视觉、听觉和文本多模态模型的协作感知与理解能力。|
|🆕 发布|Computer-Aided Multi-Stroke Character Simplification by Stroke Removal|计算机辅助的多笔画字符简化通过笔画移除|Ryo Ishiyama, Shinnosuke Matsuo, Seiichi Uchida|<http://arxiv.org/pdf/2506.23106v1>|提出了一种通过选择性去除笔画简化多笔画字符的方法，以保持字符可识别性。|
|🆕 发布|Learning Counterfactually Decoupled Attention for Open-World Model Attribution|学习对抗性解耦注意力以实现开放世界模型归因|Yu Zheng, Boyang Gong, Fanye Kong, Yueqi Duan, Bingyao Yu, Wenzhao Zheng, Lei Chen, Jiwen Lu .etc.|<http://arxiv.org/pdf/2506.23074v1>|[代码](https://github.com/yzheng97/CDAL.); 提出了一种Counterfactually Decoupled Attention Learning...|
|🆕 发布|From Coarse to Fine: Learnable Discrete Wavelet Transforms for Efficient 3D Gaussian Splatting|从粗到细：用于高效三维高斯散点绘制的学习离散小波变换|Hung Nguyen, An Le, Runfa Li, Truong Nguyen|<http://arxiv.org/pdf/2506.23042v1>|提出了一种自动限制高斯分布增长的方法AutoOpti3DGS，通过可学习的小波变换优化3D Gaus...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VolumetricSMPL: A Neural Volumetric Body Model for Efficient Interactions, Contacts, and Collisions|体素SMPL：一种用于高效交互、接触和碰撞的神经体素人体模型|Marko Mihajlovic, Siwei Zhang, Gen Li, Kaifeng Zhao, Lea Müller, Siyu Tang|<http://arxiv.org/pdf/2506.23236v1>|提出VolumetricSMPL，一种高效的神经体积人体模型，通过神经混合权重技术提升计算效率并保持...|
|🆕 发布|Frequency-enhanced Multi-granularity Context Network for Efficient Vertebrae Segmentation|频率增强的多粒度上下文网络用于高效椎体分割|Jian Shi, Tianqi You, Pingping Zhang, Hongli Zhang, Rui Xu, Haojie Li|<http://arxiv.org/pdf/2506.23086v1>|[代码](https://github.com/anaanaa/FMCNet.); 提出了一种频率增强的多粒度上下文网络，有效提升了椎体分割的准确性并减轻了图像模糊影响。|
|🆕 发布|Empowering Small VLMs to Think with Dynamic Memorization and Exploration|赋予小型视觉语言模型动态记忆与探索能力以实现思考功能|Jiazhen Liu, Yuchuan Deng, Long Chen|<http://arxiv.org/pdf/2506.23061v1>|[代码](https://github.com/HKUST-LongGroup/DyME); 提出DyME训练范式，动态结合记忆与探索，提升小规模视觉语言模型的可靠思考能力。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mettle: Meta-Token Learning for Memory-Efficient Audio-Visual Adaptation|“Mettle：面向内存高效音频视觉适应的元标记学习”|Jinxing Zhou, Zhihui Li, Yongqiang Yu, Yanghao Zhou, Ruohao Guo, Guangyao Li, Yuxin Mao, Mingfei Han .etc.|<http://arxiv.org/pdf/2506.23271v1>|提出了一种内存高效的元学习策略Mettle，通过并行特征蒸馏实现大规模预训练模型在音频视觉任务上的快...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CalFuse: Feature Calibration Enhanced Parameter Fusion for Class-Continual Learning|"CalFuse：特征校准增强的参数融合用于类连续学习"|Juncen Guo, Yang Liu, Xiaoguang Zhu, Lianlong Sun, Liangyu Teng, Jingyi Wu, Di Li, Linxiao Gong .etc.|<http://arxiv.org/pdf/2503.18672v5>|提出CalFuse框架，通过特征校准增强参数融合，有效平衡新知识学习与旧知识保留。|
|🆕 发布|DC-TTA: Divide-and-Conquer Framework for Test-Time Adaptation of Interactive Segmentation|DC-TTA：分而治之框架用于交互式分割的测试时适应|Jihun Kim, Hoyong Kwon, Hyeokjun Kweon, Wooseong Jeong, Kuk-Jin Yoon|<http://arxiv.org/pdf/2506.23104v1>|提出DC-TTA框架，通过分而治之策略对交互式分割模型进行样本自适应，有效提升复杂场景下的分割准确性...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GeoProg3D: Compositional Visual Reasoning for City-Scale 3D Language Fields|GeoProg3D：面向城市规模三维语言场的组合视觉推理|Shunsuke Yasuki, Taiki Miyanishi, Nakamasa Inoue, Shuhei Kurita, Koya Sakamoto, Daichi Azuma, Masato Taki, Yutaka Matsuo|<http://arxiv.org/pdf/2506.23352v1>|[代码](https://snskysk.github.io/GeoProg3D); 提出GeoProg3D框架，实现自然语言驱动的城市规模3D场景交互与地理推理。|
|📝 更新|Ground-R1: Incentivizing Grounded Visual Reasoning via Reinforcement Learning|地面R1：通过强化学习激励 grounded 视觉推理|Meng Cao, Haoze Zhao, Can Zhang, Xiaojun Chang, Ian Reid, Xiaodan Liang|<http://arxiv.org/pdf/2505.20272v2>|提出了一种无需显式证据或解释标注的强化学习框架Ground-R1，实现了视觉推理的可解释性和可扩展性...|
|🆕 发布|Competitive Distillation: A Simple Learning Strategy for Improving Visual Classification|竞争蒸馏：一种用于提高视觉分类的简单学习策略|Daqian Shi, Xiaolei Diao, Xu Chen, Cédric M. John|<http://arxiv.org/pdf/2506.23285v1>|提出了一种竞争性蒸馏策略，通过网络间的竞争和随机扰动提升视觉分类性能。|
|🆕 发布|PCLVis: Visual Analytics of Process Communication Latency in Large-Scale Simulation|PCLVis：大规模模拟中进程通信延迟的可视化分析|Chongke Bi, Xin Gao, Baofeng Fu, Yuheng Zhao, Siming Chen, Ying Zhao, Yunhai Wang|<http://arxiv.org/pdf/2506.23257v1>|提出PCLVis框架，利用MPI通信数据帮助用户分析大规模模拟中的进程通信延迟问题。|
|🆕 发布|Enhancing Spatial Reasoning in Multimodal Large Language Models through Reasoning-based Segmentation|通过基于推理的分割增强多模态大型语言模型的空间推理能力|Zhenhua Ning, Zhuotao Tian, Shaoshuai Shi, Guangming Lu, Daojing He, Wenjie Pei, Li Jiang|<http://arxiv.org/pdf/2506.23120v1>|提出了一种基于推理的分割框架R$^2$S，通过分解空间推理过程，显著增强了大型多模态语言模型的空间推...|
|📝 更新|CHARTOM: A Visual Theory-of-Mind Benchmark for LLMs on Misleading Charts|CHARTOM：面向大型语言模型在误导性图表上的视觉心智理论基准测试|Shubham Bharti, Shiyun Cheng, Jihyun Rho, Jianrui Zhang, Mu Cai, Yong Jae Lee, Martina Rau, Xiaojin Zhu|<http://arxiv.org/pdf/2408.14419v3>|提出CHARTOM基准，评估大型语言模型理解和判断误导性图表的能力。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as Agentic Inverse Rendering|IR3D-Bench：评估视觉语言模型场景理解作为代理逆向渲染|Parker Liu, Chenxin Li, Zhengxin Li, Yipeng Wu, Wuyang Li, Zhiqin Yang, Zhenyuan Zhang, Yunlong Lin .etc.|<http://arxiv.org/pdf/2506.23329v1>|提出IR3D-Bench基准，通过要求视觉语言模型主动重构3D场景来评估其对场景的真正理解。|
|📝 更新|Neurons: Emulating the Human Visual Cortex Improves Fidelity and Interpretability in fMRI-to-Video Reconstruction|神经元：模拟人类视觉皮层提高fMRI至视频重建的保真度和可解释性|Haonan Wang, Qixiang Zhang, Lehan Wang, Xuanqi Huang, Xiaomeng Li|<http://arxiv.org/pdf/2503.11167v2>|[代码](https://github.com/xmed-lab/NEURONS.); 提出NEURONS框架，模拟人脑视觉皮层结构，提升fMRI视频重建的准确性和可解释性。|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SoMi-ToM: Evaluating Multi-Perspective Theory of Mind in Embodied Social Interactions|《SoMi-ToM：在具身社交互动中评估多视角心智理论》|Xianzhe Fan, Xuhui Zhou, Chuanyang Jin, Kolby Nottingham, Hao Zhu, Maarten Sap|<http://arxiv.org/pdf/2506.23046v1>|提出SoMi-ToM基准，通过多模态交互数据评估模型在复杂社会互动中的多视角心智理论能力。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Layer Decomposition and Morphological Reconstruction for Task-Oriented Infrared Image Enhancement|面向任务的层分解与形态重构红外图像增强|Siyuan Chai, Xiaodong Guo, Tong Liu|<http://arxiv.org/pdf/2506.23353v1>|提出了一种结合层分解和形态学重建的任务导向红外图像增强方法，有效提高了目标检测和语义分割的性能。|
|📝 更新|Improving Robustness and Reliability in Medical Image Classification with Latent-Guided Diffusion and Nested-Ensembles|利用潜在引导扩散和嵌套集成提高医学图像分类的鲁棒性和可靠性|Xing Shen, Hengguan Huang, Brennan Nichyporuk, Tal Arbel|<http://arxiv.org/pdf/2310.15952v5>|提出LaDiNE方法，融合Vision Transformers与扩散模型，增强医疗图像分类的鲁棒性...|
|🆕 发布|Federated Breast Cancer Detection Enhanced by Synthetic Ultrasound Image Augmentation|联邦乳腺癌检测通过合成超声图像增强得以提升|Hongyi Pan, Ziliang Hong, Gorkem Durak, Ziyue Xu, Ulas Bagci|<http://arxiv.org/pdf/2506.23334v1>|提出利用生成式AI数据增强框架，通过合成超声图像提升联邦学习在乳腺癌检测中的性能和泛化能力。|
|📝 更新|YOLO-LLTS: Real-Time Low-Light Traffic Sign Detection via Prior-Guided Enhancement and Multi-Branch Feature Interaction|YOLO-LLTS：基于先验引导增强和多分支特征交互的实时低光照交通标志检测|Ziyu Lin, Yunfan Wu, Yuhang Ma, Junzhou Chen, Ronghui Zhang, Jiaming Wu, Guodong Yin, Liang Lin|<http://arxiv.org/pdf/2503.13883v3>|提出YOLO-LLTS算法，通过增强特征图、多分支特征交互和先验引导增强，提升低光环境下交通标志实时...|
|📝 更新|Multi-encoder nnU-Net outperforms transformer models with self-supervised pretraining|多编码器nnU-Net在自监督预训练下超越变换器模型性能|Seyedeh Sahar Taheri Otaghsara, Reza Rahmanzadeh|<http://arxiv.org/pdf/2504.03474v2>|提出多编码器nnU-Net架构，通过独立处理多种MRI模态特征提升医学图像分割精度。|
|🆕 发布|Multi-Source COVID-19 Detection via Variance Risk Extrapolation|通过方差风险外推的多源COVID-19检测|Runtian Yuan, Qingqiu Li, Junlin Hou, Jilan Xu, Yuejie Zhang, Rui Feng, Hao Chen|<http://arxiv.org/pdf/2506.23208v1>|提出了一种结合方差风险外推和混合数据增强的COVID-19 CT影像分类方法，有效应对不同医院数据域...|
|📝 更新|Segment as You Wish -- Free-Form Language-Based Segmentation for Medical Images|“按需分割——基于自由形式语言的医学图像分割”|Longchao Da, Rui Wang, Xiaojian Xu, Parminder Bhatia, Taha Kass-Hout, Hua Wei, Cao Xiao|<http://arxiv.org/pdf/2410.12831v2>|提出了一种基于自然语言描述的医学图像分割模型FLanS，提高了语言理解和分割精度。|
|🆕 发布|CRISP-SAM2: SAM2 with Cross-Modal Interaction and Semantic Prompting for Multi-Organ Segmentation|CRISP-SAM2：具有跨模态交互和语义提示的SAM2用于多器官分割|Xinlei Yu, Chanmiao Wang, Hui Jin, Ahmed Elazab, Gangyong Jia, Xiang Wan, Changqing Zou, Ruiquan Ge|<http://arxiv.org/pdf/2506.23121v1>|[代码](https://github.com/YU-deep/CRISP); 引入CRISP-SAM2模型，通过跨模态交互和语义提示提升多器官分割的准确性和细节表现。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Where, What, Why: Towards Explainable Driver Attention Prediction|“在哪里，是什么，为什么：迈向可解释的驾驶员注意力预测”|Yuchen Zhou, Jiayu Tang, Xiaoyan Xiao, Yueyao Lin, Linkai Liu, Zipeng Guo, Hao Fei, Xiaobo Xia .etc.|<http://arxiv.org/pdf/2506.23088v1>|提出解释性驾驶员注意力预测方法，同时预测注意力区域、解析关注语义并提供认知推理。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Parameter-Efficient Fine-Tuning for Pre-Trained Vision Models: A Survey and Benchmark|参数高效的微调方法用于预训练视觉模型：综述与基准测试|Yi Xin, Jianjiang Yang, Siqi Luo, Yuntao Du, Qi Qin, Kangrui Cen, Yangfan He, Bin Fu .etc.|<http://arxiv.org/pdf/2402.02242v5>|[代码](https://github.com/synbol/Awesome-Parameter-Efficient-Transfer-Learning.); 概述了参数高效微调方法，为预训练视觉模型提供了一种降低计算和存储需求的替代方案。|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Low-Cost Infrared Vision Systems for Improved Safety of Emergency Vehicle Operations Under Low-Visibility Conditions|低成本红外视觉系统提高紧急车辆在低能见度条件下运行的安全性|M-Mahdi Naddaf-Sh, Andrew Lee, Kin Yen, Eemon Amini, Iman Soltani|<http://arxiv.org/pdf/2504.14078v2>|探究红外摄像头技术提升紧急车辆在低能见度条件下的驾驶安全性。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|3DRealCar: An In-the-wild RGB-D Car Dataset with 360-degree Views|《3DRealCar：一种野外环境下的360度视角RGB-D汽车数据集》|Xiaobiao Du, Yida Wang, Haiyang Sun, Zhuojie Wu, Hongwei Sheng, Shuyun Wang, Jiaying Ying, Ming Lu .etc.|<http://arxiv.org/pdf/2406.04875v2>|[代码](https://xiaobiaodu.github.io/3drealcar); 提出了首个大规模高质真实世界三维汽车数据集3DRealCar，包含2500辆汽车的高分辨率360度R...|
|🆕 发布|Detecting What Matters: A Novel Approach for Out-of-Distribution 3D Object Detection in Autonomous Vehicles|检测关键所在：一种面向自动驾驶车辆在分布外三维目标检测的新方法|Menna Taha, Aya Ahmed, Mohammed Karmoose, Yasser Gadallah|<http://arxiv.org/pdf/2506.23426v1>|提出了一种针对自动驾驶车辆的新型3D物体检测方法，通过判断物体对车辆的危害性来有效识别未知分布的物体...|

