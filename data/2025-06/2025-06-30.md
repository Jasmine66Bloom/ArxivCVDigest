## [UPDATED!] **2025-06-30** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Foundation Models for Zero-Shot Segmentation of Scientific Images without AI-Ready Data|无标注数据下科学图像零样本分割的基础模型|Shubhabrata Mukherjee, Jack Lang, Obeen Kwon, Iryna Zenyuk, Valerie Brogden, Adam Weber, Daniela Ushizima|<http://arxiv.org/pdf/2506.24039v1>|提出Zenesis平台，通过多模态适应技术和人工辅助，实现了无标注科学图像的零样本分割。|
|🆕 发布|Interpretable Zero-Shot Learning with Locally-Aligned Vision-Language Model|可解释的零样本学习：基于局部对齐的视觉语言模型|Shiming Chen, Bowen Duan, Salman Khan, Fahad Shahbaz Khan|<http://arxiv.org/pdf/2506.23822v1>|[代码](https://github.com/shiming-chen/LaZSL.); 提出了一种可解释的零样本学习方法LaZSL，通过局部视觉-语义对齐提升模型准确性和解释性。|
|📝 更新|Towards Vision-Language-Garment Models for Web Knowledge Garment Understanding and Generation|面向网络知识服饰理解与生成的视觉-语言-服饰模型研究|Jan Ackermann, Kiyohiro Nakayama, Guandao Yang, Tong Wu, Gordon Wetzstein|<http://arxiv.org/pdf/2506.05210v2>|提出了一种多模态基础模型VLG，实现了从文本描述和视觉图像合成服装，并在时尚设计领域展现了良好的迁移...|
|📝 更新|MSF: Efficient Diffusion Model Via Multi-Scale Latent Factorize|多尺度潜在因子分解的高效扩散模型（MSF）|Haohang Xu, Longyu Chen, Yichen Zhang, Shuangrui Ding, Zhipeng Zhang|<http://arxiv.org/pdf/2501.13349v2>|提出了一种多尺度潜在因子分解的扩散模型，通过分离基础信号和残差信号，有效降低了高分辨率图像生成的计算...|
|🆕 发布|On the Domain Robustness of Contrastive Vision-Language Models|关于对比视觉语言模型在领域稳健性方面的研究|Mario Koddenbrock, Rudolf Hoffmann, David Brodmann, Erik Rodner|<http://arxiv.org/pdf/2506.23663v1>|提出Deepbench框架，评估视觉语言模型在不同领域的鲁棒性，无需标签数据。|
|🆕 发布|PGOV3D: Open-Vocabulary 3D Semantic Segmentation with Partial-to-Global Curriculum|PGOV3D：基于部分到全局教学法的开放词汇三维语义分割|Shiqi Zhang, Sha Zhang, Jiajun Deng, Yedong Shen, Mingxiao MA, Yanyong Zhang|<http://arxiv.org/pdf/2506.23607v1>|提出了一种分阶段训练的PGOV3D框架，通过部分到全局的教学法提升三维场景的语义分割效果。|
|📝 更新|FedEx-LoRA: Exact Aggregation for Federated and Efficient Fine-Tuning of Foundation Models|FedEx-LoRA：联邦与高效基础模型微调的精确聚合方法|Raghav Singhal, Kaustubh Ponkshe, Praneeth Vepakomma|<http://arxiv.org/pdf/2410.09432v4>|[代码](https://github.com/RaghavSinghal10/fedex-lora.); 提出精确聚合的FedEx-LoRA方法，解决了联邦学习环境下LoRA适配器更新不准确的问题。|
|📝 更新|Generalizing vision-language models to novel domains: A comprehensive survey|《将视觉-语言模型泛化到新领域：全面综述》|Xinyao Li, Jingjing Li, Fengling Li, Lei Zhu, Yang Yang, Heng Tao Shen|<http://arxiv.org/pdf/2506.18504v2>|系统梳理了视觉语言模型在新型领域泛化的方法与挑战，为多模态研究提供了清晰的视角。|
|🆕 发布|Qwen-GUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding|Qwen-GUI-3B：一种用于跨分辨率GUI定位的轻量级视觉-语言模型|ZongHan Hsieh, Tzer-Jen Wei|<http://arxiv.org/pdf/2506.23491v1>|[代码](https://github.com/Han1018/Qwen-GUI-3B); 提出了一种轻量级视觉语言模型Qwen-GUI-3B，通过创新的数据集构建和两阶段训练策略，有效提升跨...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AQUA20: A Benchmark Dataset for Underwater Species Classification under Challenging Conditions|AQUA20：具有挑战性条件下水下物种分类的基准数据集|Taufikur Rahman Fuad, Sabbir Ahmed, Shahriar Ivan|<http://arxiv.org/pdf/2506.17455v2>|提出了AQUA20水下物种分类数据集，评估了多种模型在复杂水下环境下的性能。|
|🆕 发布|Low-latency vision transformers via large-scale multi-head attention|通过大规模多头注意力机制的低延迟视觉变换器|Ronit D. Gross, Tal Halevi, Ella Koresh, Yarden Tzach, Ido Kanter|<http://arxiv.org/pdf/2506.23832v1>|提出了一种通过大规模多头注意力机制优化视觉变压器架构的方法，实现了准确率提升和延迟降低。|
|🆕 发布|Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking|Mamba-FETrack V2：重新审视基于帧事件的视觉目标跟踪的状态空间模型|Shiao Wang, Ju Huang, Qingchuan Ma, Jinfeng Gao, Chunyi Xu, Xiao Wang, Lan Chen, Bo Jiang|<http://arxiv.org/pdf/2506.23783v1>|[代码](https://github.com/Event-AHU/Mamba_FETrack); 提出了一种基于Vision Mamba网络的RGB-Event对象跟踪框架，通过轻量级Prompt ...|
|📝 更新|Efficient Online Inference of Vision Transformers by Training-Free Tokenization|《通过无需训练的标记化实现视觉变换器的有效在线推理》|Leonidas Gee, Wing Yan Li, Viktoriia Sharmanska, Novi Quadrianto|<http://arxiv.org/pdf/2411.15397v3>|提出了一种无需训练的可视化词 tokenize 方法，减少能耗同时保持性能和运行效率。|
|📝 更新|Uncertainty-Aware Remaining Lifespan Prediction from Images|基于不确定性的图像剩余寿命预测|Tristan Kenneweg, Philip Kenneweg, Barbara Hammer|<http://arxiv.org/pdf/2506.13430v2>|提出了一种基于预训练视觉变换器模型预测剩余寿命并量化不确定性的方法，实现了最先进的误差表现。|
|📝 更新|HMSViT: A Hierarchical Masked Self-Supervised Vision Transformer for Corneal Nerve Segmentation and Diabetic Neuropathy Diagnosis|层次化掩码自监督视觉变换器HMSViT：用于角膜神经分割和糖尿病神经病变诊断|Xin Zhang, Liangxiu Han, Yue Shi, Yanlin Zheng, Uazman Alam, Maryam Ferdousi, Rayaz Malik|<http://arxiv.org/pdf/2506.19474v2>|提出HMSViT模型，通过层级特征提取和自监督学习提升角膜神经分割及糖尿病周围神经病变诊断精度。|
|🆕 发布|Revisiting Audio-Visual Segmentation with Vision-Centric Transformer|重新审视以视觉为中心的音频-视觉分割方法|Shaofei Huang, Rui Ling, Tianrui Hui, Hongyu Li, Xu Zhou, Shifeng Zhang, Si Liu, Richang Hong .etc.|<http://arxiv.org/pdf/2506.23623v1>|[代码](https://github.com/spyflying/VCT_AVS.); 提出了一种视觉中心的Transformer框架，通过视觉生成的查询迭代获取音视觉信息，提高了音视觉分...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MotionGPT3: Human Motion as a Second Modality|"MotionGPT3：将人类运动作为第二模态"|Bingfan Zhu, Biao Jiang, Sunyi Wang, Shixiang Tang, Tao Chen, Linjie Luo, Youyi Zheng, Xin Chen|<http://arxiv.org/pdf/2506.24086v1>|提出了一种将人类运动作为第二模态的统一运动-语言模型，有效解决了运动表示与语言智能保持的难题。|
|🆕 发布|Thinking with Images for Multimodal Reasoning: Foundations, Methods, and Future Frontiers|图像驱动多模态推理：基础、方法与未来前沿|Zhaochen Su, Peng Xia, Hangyu Guo, Zhenhua Liu, Yan Ma, Xiaoye Qu, Jiaqi Liu, Yanshu Li .etc.|<http://arxiv.org/pdf/2506.23918v1>|提出视觉推理新范式，将图像从静态输入转变为动态认知工作空间，推动多模态AI向更接近人类认知的方向发展...|
|📝 更新|Task Preference Optimization: Improving Multimodal Large Language Models with Vision Task Alignment|任务偏好优化：通过视觉任务对齐提升多模态大型语言模型|Ziang Yan, Zhilin Li, Yinan He, Chenting Wang, Kunchang Li, Xinhao Li, Xiangyu Zeng, Zilei Wang .etc.|<http://arxiv.org/pdf/2412.19326v2>|[代码](https://github.com/OpenGVLab/TPO); 提出Task Preference Optimization方法，通过任务偏好优化增强大型多模态语言...|
|📝 更新|FALCON: Resolving Visual Redundancy and Fragmentation in High-resolution Multimodal Large Language Models via Visual Registers|FALCON：通过视觉寄存器解决高分辨率多模态大型语言模型中的视觉冗余与碎片化问题|Renshan Zhang, Rui Shao, Gongwei Chen, Miao Zhang, Kaiwen Zhou, Weili Guan, Liqiang Nie|<http://arxiv.org/pdf/2501.16297v2>|提出FALCON模型，通过视觉寄存器技术减少冗余视觉编码，确保高分辨率图像编码的连续性和紧凑性。|
|🆕 发布|Unified Multimodal Understanding via Byte-Pair Visual Encoding|统一的多模态理解通过字节对视觉编码|Wanpeng Zhang, Yicheng Feng, Hao Luo, Yijiang Li, Zihao Yue, Sipeng Zheng, Zongqing Lu|<http://arxiv.org/pdf/2506.23639v1>|通过字节对视觉编码统一模态理解，提升跨模态关系捕捉和视觉信息推理能力。|
|📝 更新|TinyAlign: Boosting Lightweight Vision-Language Models by Mitigating Modal Alignment Bottlenecks|TinyAlign：通过缓解模态对齐瓶颈提升轻量级视觉语言模型性能|Yuanze Hu, Zhaoxin Fan, Xinyu Wang, Gen Li, Ye Qiu, Zhichao Yang, Wenjun Wu, Kejian Wu .etc.|<http://arxiv.org/pdf/2505.12884v2>|提出TinyAlign框架，通过检索增强多模态输入，有效缓解轻量级视觉语言模型对齐瓶颈。|
|📝 更新|CauSkelNet: Causal Representation Learning for Human Behaviour Analysis|因果骨架网络：用于人体行为分析的原因表示学习|Xingrui Gu, Chuyi Jiang, Erte Wang, Qiang Cui, Leimin Tian, Lianlong Wu, Siyang Song, Chuang Yu|<http://arxiv.org/pdf/2409.15564v4>|引入基于因果推断的表示学习框架，提高人类行为分析的可解释性和准确性。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Toward Simple and Robust Contrastive Explanations for Image Classification by Leveraging Instance Similarity and Concept Relevance|面向图像分类的简单且稳健的对比解释方法：利用实例相似性和概念相关性|Yuliia Kaidashova, Bettina Finzel, Ute Schmid|<http://arxiv.org/pdf/2506.23975v1>|提出基于实例相似性和概念相关性的图像分类对比解释方法，提高了解释简洁性和鲁棒性。|
|📝 更新|AEM: Attention Entropy Maximization for Multiple Instance Learning based Whole Slide Image Classification|注意熵最大化用于基于多实例学习的全切片图像分类|Yunlong Zhang, Honglin Li, Yunxuan Sun, Zhongyi Shui, Jingxiong Li, Chenglu Zhu, Lin Yang|<http://arxiv.org/pdf/2406.15303v3>|[代码](https://github.com/dazhangyu123/AEM.); 引入注意力熵最大化(AEM)正则化技术，有效缓解了多实例学习在全景切片图像分类中的过拟合问题。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Assessing workflow impact and clinical utility of AI-assisted brain aneurysm detection: a multi-reader study|评估人工智能辅助大脑动脉瘤检测的工作流影响和临床效用：多读者研究|Tommaso Di Noto, Sofyan Jankowski, Francesco Puccinelli, Guillaume Marie, Sebastien Tourbier, Yasser Aleman-Gomez, Oscar Esteban, Ricardo Corredor-Jerez .etc.|<http://arxiv.org/pdf/2503.17786v2>|评估AI辅助脑动脉瘤检测对临床工作流程的影响，发现AI辅助并未显著提升医生诊断性能。|
|🆕 发布|Deep Learning-Based Semantic Segmentation for Real-Time Kidney Imaging and Measurements with Augmented Reality-Assisted Ultrasound|基于深度学习的实时肾脏成像与测量语义分割及增强现实辅助超声应用|Gijs Luijten, Roberto Maria Scardigno, Lisle Faray de Paiva, Peter Hoyer, Jens Kleesiek, Domenico Buongiorno, Vitoantonio Bevilacqua, Jan Egger|<http://arxiv.org/pdf/2506.23721v1>|实现了基于深度学习的实时肾脏成像和测量，结合增强现实技术，提高了超声诊断的效率和准确性。|
|🆕 发布|MedSAM-CA: A CNN-Augmented ViT with Attention-Enhanced Multi-Scale Fusion for Medical Image Segmentation|MedSAM-CA：一种基于CNN增强的ViT，具有注意力增强的多尺度融合用于医学图像分割|Peiting Tian, Xi Chen, Haixia Bi, Fan Li|<http://arxiv.org/pdf/2506.23700v1>|MedSAM-CA通过结合卷积增强边界精炼网络和注意力增强特征融合，提高了医学图像分割精度，尤其适用...|
|🆕 发布|PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection|基于补丁合成的对抗训练以抵御物体检测中物理可实现攻击：PBCAT|Xiao Li, Yiming Zhu, Yifan Huang, Wei Zhang, Yingzhe He, Jie Shi, Xiaolin Hu|<http://arxiv.org/pdf/2506.23581v1>|提出了一种统一防御策略PBCAT，通过结合小区域梯度引导的对抗性贴图和全局不可察觉的对抗性扰动，增强...|
|🆕 发布|StackCLIP: Clustering-Driven Stacked Prompt in Zero-Shot Industrial Anomaly Detection|堆叠提示驱动的聚类：零样本工业异常检测中的无监督学习方法|Yanning Hou, Yanran Ruan, Junfa Li, Shanshan Wang, Jianfeng Qiu, Ke Xu|<http://arxiv.org/pdf/2506.23577v1>|提出了一种通过多类别名称叠加构建通用提示的StackCLIP模型，有效提升了零样本工业异常检测的泛化...|
|🆕 发布|Oneta: Multi-Style Image Enhancement Using Eigentransformation Functions|《Oneta：基于特征变换函数的多风格图像增强》|Jiwon Kim, Soohyun Hwang, Dong-O Kim, Changsu Han, Min Kyu Park, Chang-Su Kim|<http://arxiv.org/pdf/2506.23547v1>|提出了一种多风格图像增强算法Oneta，通过学习风格特定的变换函数和颜色校正矩阵实现高效图像处理。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AWF: Adaptive Weight Fusion for Enhanced Class Incremental Semantic Segmentation|自适应权重融合增强类别增量语义分割方法|Zechao Sun, Shuying Piao, Haolin Jin, Chang Dong, Lin Yue, Weitong Chen, Luping Zhou|<http://arxiv.org/pdf/2409.08516v2>|提出自适应权重融合方法，优化了类增量语义分割中旧知识保持与新知识学习平衡，显著提升性能。|
|🆕 发布|Interactive Interface For Semantic Segmentation Dataset Synthesis|交互式界面用于语义分割数据集合成|Ngoc-Do Tran, Minh-Tuan Huynh, Tam V. Nguyen, Minh-Triet Tran, Trung-Nghia Le|<http://arxiv.org/pdf/2506.23470v1>|提出SynthLab系统，通过模块化平台和互动界面简化语义分割数据集的合成过程。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Event-based Tiny Object Detection: A Benchmark Dataset and Baseline|基于事件的微小目标检测：一个基准数据集和基线|Nuo Chen, Chao Xiao, Yimian Dai, Shiman He, Miao Li, Wei An|<http://arxiv.org/pdf/2506.23575v1>|[代码](https://github.com/ChenYichen9527/Ev-UAV.); 提出了首个大规模、多样化的基于事件相机的小目标检测数据集EV-UAV，并设计了一种适用于小目标跟踪的...|
|🆕 发布|From Sight to Insight: Unleashing Eye-Tracking in Weakly Supervised Video Salient Object Detection|从视觉到洞察：在弱监督视频显著目标检测中释放眼动追踪技术的潜力|Qi Qin, Runmin Cong, Gen Zhan, Yiting Liao, Sam Kwong|<http://arxiv.org/pdf/2506.23519v1>|引入眼动信息以辅助弱监督视频显著目标检测，提出PSE模块和IIMC模型提升时空特征建模能力。|
|🆕 发布|Improve Underwater Object Detection through YOLOv12 Architecture and Physics-informed Augmentation|通过YOLOv12架构和物理信息增强改进水下目标检测|Tinh Nguyen|<http://arxiv.org/pdf/2506.23505v1>|通过结合YOLOv12架构与物理信息增强技术，本研究显著提升了水下目标检测在低能见度条件下的实时性能...|
|📝 更新|Multimodal Object Detection using Depth and Image Data for Manufacturing Parts|使用深度与图像数据的多模态目标检测在制造零件中的应用|Nazanin Mahjourian, Vinh Nguyen|<http://arxiv.org/pdf/2411.09062v3>|融合RGB图像与3D深度数据，提出的多模态检测方法显著提升了制造业部件检测的准确性和鲁棒性。|


## 生成式视觉模型 (Generative Visual Modeling)


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TextMesh4D: High-Quality Text-to-4D Mesh Generation|《TextMesh4D：高质量文本到四维网格生成》|Sisi Dai, Xinxin Su, Boyan Wan, Ruizhen Hu, Kai Xu|<http://arxiv.org/pdf/2506.24121v1>|TextMesh4D通过分阶段生成静态对象和动态运动，并引入稳定性优化，实现了基于文本的高质量4D网...|
|🆕 发布|RGC-VQA: An Exploration Database for Robotic-Generated Video Quality Assessment|机器人生成视频质量评估探索数据库：RGC-VQA|Jianing Jin, Jiangyong Ying, Huiyu Duan, Liu Yang, Sijing Wu, Yunhao Li, Yushuo Zheng, Xiongkuo Min .etc.|<http://arxiv.org/pdf/2506.23852v1>|[代码](https://github.com/IntMeGroup/RGC-VQA.); 提出首个针对机器人生成视频质量评估的数据库，揭示了现有视频质量评估模型的局限性。|
|🆕 发布|Can We Challenge Open-Vocabulary Object Detectors with Generated Content in Street Scenes?|我们能否用生成的街景内容挑战开放词汇对象检测器？|Annika Mütze, Sadia Ilyas, Christian Dörpelkus, Matthias Rottmann|<http://arxiv.org/pdf/2506.23751v1>|利用合成图像探索开放词汇对象检测器的局限性，发现其依赖对象位置而非语义。|
|🆕 发布|Towards an Automated Multimodal Approach for Video Summarization: Building a Bridge Between Text, Audio and Facial Cue-Based Summarization|迈向自动化的多模态视频摘要方法：构建基于文本、音频和面部线索摘要的桥梁|Md Moinul Islam, Sofoklis Kakouros, Janne Heikkilä, Mourad Oussalah|<http://arxiv.org/pdf/2506.23714v1>|提出了一种融合文本、音频和视觉线索的多模态视频摘要框架，显著提升了摘要的相关性和清晰度。|
|📝 更新|How to Move Your Dragon: Text-to-Motion Synthesis for Large-Vocabulary Objects|如何驱动您的龙：面向大规模词汇对象的语言到动作合成|Wonkwang Lee, Jongwon Jeong, Taehong Moon, Hyeon-Jong Kim, Jaehyeon Kim, Gunhee Kim, Byeong-Uk Lee|<http://arxiv.org/pdf/2503.04257v2>|提出了一种文本到动作合成的创新方法，通过增强数据集和改进模型，实现了对多种对象的高质量动作生成。|
|🆕 发布|CAI: Caption-Sensitive Attention Intervention for Mitigating Object Hallucination in Large Vision-Language Models|CAI：用于减轻大型视觉-语言模型中对象幻觉的标题敏感注意力干预|Qiming Li, Zekai Ye, Xiaocheng Feng, Weihong Zhong, Libo Qin, Ruihan Chen, Baohang Li, Kui Jiang .etc.|<http://arxiv.org/pdf/2506.23590v1>|提出了一种无需训练的Caption-sensitive Attention Intervention...|
|📝 更新|InstructionBench: An Instructional Video Understanding Benchmark|指令理解基准：一个教学视频理解评测集|Haiwan Wei, Yitian Yuan, Xiaohan Lan, Wei Ke, Lin Ma|<http://arxiv.org/pdf/2504.05040v2>|提出InstructionBench基准，挑战视频大语言模型在指导视频中的高级时序推理能力。|
|📝 更新|Advancing Facial Stylization through Semantic Preservation Constraint and Pseudo-Paired Supervision|通过语义保持约束和伪成对监督推进面部风格化|Zhanyi Lu, Yue Zhou|<http://arxiv.org/pdf/2506.22022v2>|提出了一种融合语义保持约束和伪成对监督的面部风格化方法，有效提升了生成图像的保真度和风格化效果。|
|📝 更新|Object Retrieval for Visual Question Answering with Outside Knowledge|物体检索在视觉问答中结合外部知识的应用|Shichao Kan, Yuhai Deng, Jiale Fu, Lihui Cen, Zhe Qu, Linna Zhang, Yixiong Liang, Yigang Cen|<http://arxiv.org/pdf/2403.10798v2>|提出对象检索任务与大型语言模型结合，解决视觉问答中的知识扩展问题，引入多尺度协同嵌入学习技术提升检索...|
|🆕 发布|TAG-WM: Tamper-Aware Generative Image Watermarking via Diffusion Inversion Sensitivity|TAG-WM：基于扩散逆敏感性的人工图像水印技术及其篡改感知能力|Yuzhuo Chen, Zehua Ma, Han Fang, Weiming Zhang, Nenghai Yu|<http://arxiv.org/pdf/2506.23484v1>|提出TAG-WM方法，通过在生成图像中嵌入版权与定位水印，增强抗篡改能力并实现篡改定位。|
|📝 更新|Grounding Creativity in Physics: A Brief Survey of Physical Priors in AIGC|将创造力植根于物理学：人工智能生成内容中物理先验的简要综述|Siwei Meng, Yawei Luo, Ping Liu|<http://arxiv.org/pdf/2502.07007v2>|综述了将物理先验融入生成模型的方法，以增强3D和4D内容生成的结构完整性和运动真实性。|
|🆕 发布|Time-variant Image Inpainting via Interactive Distribution Transition Estimation|时间变化的图像修复通过交互式分布转换估计|Yun Xing, Qing Guo, Xiaoguang Li, Yihao Huang, Xiaofeng Cao, Di Lin, Ivor Tsang, Lei Ma|<http://arxiv.org/pdf/2506.23461v1>|提出了一种交互式分布转换估计方法，有效解决了时变图像修复问题。|
|📝 更新|RefVSR++: Exploiting Reference Inputs for Reference-based Video Super-resolution|基于参考输入的参考式视频超分辨率增强方法RefVSR++|Han Zou, Masanori Suganuma, Takayuki Okatani|<http://arxiv.org/pdf/2307.02897v2>|提出了一种利用不同视角摄像头参考视频提升低分辨率视频超分辨率性能的方法RefVSR++，通过独立聚合...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Calligrapher: Freestyle Text Image Customization|《书法家：自由风格文本图像定制》|Yue Ma, Qingyan Bai, Hao Ouyang, Ka Leong Cheng, Qiuyu Wang, Hongyu Liu, Zichen Liu, Haofan Wang .etc.|<http://arxiv.org/pdf/2506.24123v1>|提出了一种创新的扩散框架Calligrapher，通过自我蒸馏和风格注入技术实现了数字书法和设计应用...|
|🆕 发布|Navigating with Annealing Guidance Scale in Diffusion Space|在扩散空间中利用退火引导尺度进行导航|Shai Yehezkel, Omer Dahary, Andrey Voynov, Daniel Cohen-Or|<http://arxiv.org/pdf/2506.24108v1>|提出了一种动态调整引导系数的调度策略，有效提升了文本到图像生成的质量和准确性。|
|🆕 发布|Continual Adaptation: Environment-Conditional Parameter Generation for Object Detection in Dynamic Scenarios|持续适应：动态场景中目标检测的环境条件参数生成|Deng Li, Aming Wu, Yang Li, Yaowei Wang, Yahong Han|<http://arxiv.org/pdf/2506.24063v1>|提出了一种针对动态场景的对象检测持续适应方法，通过特定参数生成保持模型泛化能力。|
|🆕 发布|EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations|具有结构化解释的可解释图像字幕评估指标EXPERT|Hyunjong Kim, Sangyeop Kim, Jongheon Jeong, Yeongjae Cho, Sungzoon Cho|<http://arxiv.org/pdf/2506.24016v1>|[代码](https://github.com/hjkim811/EXPERT.); 提出了一种新的图像描述评估指标EXPERT，通过三个标准生成高质量结构化解释，实现领先性能。|
|📝 更新|SP$^2$OT: Semantic-Regularized Progressive Partial Optimal Transport for Imbalanced Clustering|SP$^2$OT：语义正则化的渐进部分最优传输用于不平衡聚类|Chuyu Zhang, Hui Ren, Xuming He|<http://arxiv.org/pdf/2404.03446v2>|[代码](https://github.com/rhfeiyang/SPPOT); 提出了一种针对深度不平衡聚类问题的优化传输框架，通过逐步传输样本到不平衡聚类，生成高质量伪标签。|
|📝 更新|CBAGAN-RRT: Convolutional Block Attention Generative Adversarial Network for Sampling-Based Path Planning|卷积块注意力生成对抗网络CBAGAN-RRT：用于基于采样的路径规划的生成对抗网络|Abhinav Sagar, Sai Teja Gilukara|<http://arxiv.org/pdf/2305.10442v2>|提出CBAGAN-RRT算法，利用生成对抗网络优化路径规划，提升速度与路径质量。|
|📝 更新|WeatherEdit: Controllable Weather Editing with 4D Gaussian Field|《WeatherEdit：基于四维高斯场的可控天气编辑》|Chenghao Qian, Wenjing Li, Yuhu Guo, Gustav Markkula|<http://arxiv.org/pdf/2505.20471v2>|[代码](https://jumponthemoon.github.io/w-edit); WeatherEdit通过集成多种天气风格的适配器和动态4D高斯场，实现了三维场景中可控类型和强度的...|
|🆕 发布|A Closer Look at Conditional Prompt Tuning for Vision-Language Models|深入探讨视觉语言模型的条件提示微调|Ji Zhang, Shihan Wu, Lianli Gao, Jingkuan Song, Nicu Sebe, Heng Tao Shen|<http://arxiv.org/pdf/2506.23856v1>|[代码](https://github.com/Koorye/CaPT.); 提出Class-adaptive Prompt Tuning方法，通过学习文本类信息条件下的动态提示...|
|📝 更新|Dehazing Light Microscopy Images with Guided Conditional Flow Matching: finding a sweet spot between fidelity and realism|利用引导条件流匹配去雾化光学显微镜图像：在保真度与真实感之间寻找最佳平衡点|Anirban Ray, Ashesh, Florian Jug|<http://arxiv.org/pdf/2506.22397v2>|提出了一种平衡清晰度和真实感的去雾方法HazeMatching，适用于低成本显微镜图像。|
|📝 更新|USP: Unified Self-Supervised Pretraining for Image Generation and Understanding|统一自监督预训练：用于图像生成与理解|Xiangxiang Chu, Renda Li, Yong Wang|<http://arxiv.org/pdf/2503.06132v2>|[代码](https://github.com/AMAP-ML/USP.); 提出USP框架，通过在VAE潜在空间进行掩码潜在建模初始化扩散模型，提升图像生成质量和理解任务性能。|
|🆕 发布|SynMotion: Semantic-Visual Adaptation for Motion Customized Video Generation|"SynMotion：面向运动定制视频生成的语义-视觉适配方法"|Shuai Tan, Biao Gong, Yujie Wei, Shiwei Zhang, Zhuoxin Liu, Dandan Zheng, Jingdong Chen, Yan Wang .etc.|<http://arxiv.org/pdf/2506.23690v1>|[代码](https://lucaria-academy.github.io/SynMotion); 提出了一种融合语义引导和视觉适应的SynMotion模型，有效解决了视频生成中动作表示的语义和视觉复...|
|📝 更新|Grid: Omni Visual Generation|《网格：全向视觉生成》|Cong Wan, Xiangyang Luo, Hao Luo, Zijian Cai, Yiren Song, Yunlong Zhao, Yifan Bai, Fan Wang .etc.|<http://arxiv.org/pdf/2412.10718v5>|将视觉序列视为网格布局，GRID方法高效利用现有图像生成模型处理时序任务，大幅降低计算资源需求。|
|🆕 发布|A Unified Framework for Stealthy Adversarial Generation via Latent Optimization and Transferability Enhancement|通过潜在优化和迁移性增强的隐形对抗性生成统一框架|Gaozheng Pei, Ke Ma, Dongpeng Zhang, Chengzhi Sun, Qianqian Xu, Qingming Huang|<http://arxiv.org/pdf/2506.23676v1>|提出统一框架，结合传统策略提升基于扩散模型的对抗样本生成和迁移性，适用于更广泛的任务。|
|🆕 发布|TurboVSR: Fantastic Video Upscalers and Where to Find Them|《TurboVSR：卓越视频超分辨率技术及其应用探寻》|Zhongdao Wang, Guodongfang Zhao, Jingjing Ren, Bailan Feng, Shifeng Zhang, Wenbo Li|<http://arxiv.org/pdf/2506.23618v1>|提出了一种高效的扩散模型TurboVSR，通过压缩编码和条件学习实现视频超分辨率，速度超出现有方法1...|
|📝 更新|OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models|OmniHuman-1：重新思考一阶段条件化人体动画模型的规模扩展|Gaojie Lin, Jianwen Jiang, Jiaqi Yang, Zerong Zheng, Chao Liang|<http://arxiv.org/pdf/2502.01061v3>|提出OmniHuman框架，通过混合运动相关条件扩大数据规模，实现高度逼真的人类视频生成。|
|🆕 发布|SG-LDM: Semantic-Guided LiDAR Generation via Latent-Aligned Diffusion|SG-LDM：基于潜在对齐扩散的语义引导激光雷达生成|Zhengkang Xiang, Zizhao Li, Amir Khodabandeh, Kourosh Khoshelham|<http://arxiv.org/pdf/2506.23606v1>|提出SG-LDM模型，通过语义引导和潜在空间对齐，实现了高质量激光雷达点云的生成与跨域转换。|
|📝 更新|Edit360: 2D Image Edits to 3D Assets from Any Angle|Edit360：从任意角度将2D图像编辑为3D资产|Junchao Huang, Xinting Hu, Shaoshuai Shi, Zhuotao Tian, Li Jiang|<http://arxiv.org/pdf/2506.10507v2>|Edit360通过锚点视角编辑传播机制，实现了任意视角的2D图像编辑到3D资产的高效转换。|
|🆕 发布|JAM-Flow: Joint Audio-Motion Synthesis with Flow Matching|联合音频-运动生成与流匹配：JAM-Flow|Mingi Kwon, Joonghyuk Shin, Jaeseok Jung, Jaesik Park, Youngjung Uh|<http://arxiv.org/pdf/2506.23552v1>|提出了一种统一框架JAM-Flow，通过融合面部动作与语音合成，实现了高效的音频-视觉同步生成。|
|🆕 发布|Pyramidal Patchification Flow for Visual Generation|金字塔补丁流用于视觉生成|Hui Li, Baoyou Chen, Liwei Zhang, Jiaye Li, Jingdong Wang, Siyu Zhu|<http://arxiv.org/pdf/2506.23543v1>|[代码](https://github.com/fudan-generative-vision/PPFlow.); 提出了一种分层次调整贴图大小的生成模型优化方法，通过在不同噪声阶段使用不同贴图大小，提升了视觉生成的...|
|🆕 发布|WAVE: Warp-Based View Guidance for Consistent Novel View Synthesis Using a Single Image|基于扭曲的视图引导的单张图像一致性新视图合成方法WAVE|Jiwoo Park, Tae Eun Choi, Youngjun Jun, Seong Jae Hwang|<http://arxiv.org/pdf/2506.23518v1>|提出了一种无需额外模块的图像生成方法，通过视图引导的扭曲增强扩散模型，实现了视图一致性。|
|🆕 发布|ViewPoint: Panoramic Video Generation with Pretrained Diffusion Models|“视点：基于预训练扩散模型的全方位视频生成”|Zixun Fang, Kai Zhu, Zhiheng Liu, Yu Liu, Wei Zhai, Yang Cao, Zheng-Jun Zha|<http://arxiv.org/pdf/2506.23513v1>|提出ViewPoint框架，利用预训练的视角视频模型和Pano-Perspective注意力机制生成...|
|🆕 发布|LLM-enhanced Action-aware Multi-modal Prompt Tuning for Image-Text Matching|基于LLM增强的动作感知多模态提示微调用于图像-文本匹配|Mengxiao Tian, Xinxiao Wu, Shuo Yang|<http://arxiv.org/pdf/2506.23502v1>|引入LLM增强的多模态提示调优，使CLIP模型能理解动作级别的图像细节，提升图像文本匹配性能。|
|🆕 发布|UltraTwin: Towards Cardiac Anatomical Twin Generation from Multi-view 2D Ultrasound|超双生：从多视角二维超声向心脏解剖双胞胎生成迈进|Junxuan Yu, Yaofei Duan, Yuhao Huang, Yu Wang, Rongbo Ling, Weihao Luo, Ang Zhang, Jingxian Xu .etc.|<http://arxiv.org/pdf/2506.23490v1>|提出UltraTwin框架，通过稀疏多视角2D超声生成高质量心脏解剖双生模型，优化治疗规划和临床量化...|
|🆕 发布|PathDiff: Histopathology Image Synthesis with Unpaired Text and Mask Conditions|《PathDiff：基于未配对文本和掩膜条件的组织病理学图像合成》|Mahesh Bhosale, Abdul Wasi, Yuanhao Zhai, Yunjie Tian, Samuel Border, Nan Xi, Pinaki Sarder, Junsong Yuan .etc.|<http://arxiv.org/pdf/2506.23440v1>|提出PathDiff框架，利用未配对的文本和掩码数据生成高质量病理图像，实现结构细节与语义的精确控制...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Supervised Diffusion-Model-Based PET Image Reconstruction|基于监督扩散模型的PET图像重建|George Webber, Alexander Hammers, Andrew P King, Andrew J Reader|<http://arxiv.org/pdf/2506.24034v1>|提出了一种监督扩散模型算法，用于提高PET图像重建的准确性和不确定性估计。|
|🆕 发布|Imagine for Me: Creative Conceptual Blending of Real Images and Text via Blended Attention|为我想象：通过混合注意力实现真实图像与文本的创造性概念融合|Wonwoong Cho, Yanxia Zhang, Yan-Ying Chen, David I. Inouye|<http://arxiv.org/pdf/2506.24085v1>|提出了一种自动化的图像与文本概念混合方法IT-Blender，有效克服人类认知偏见并增强创造力。|
|📝 更新|Pixel super-resolved virtual staining of label-free tissue using diffusion models|像素级超分辨率虚拟染色无标记组织使用扩散模型|Yijie Zhang, Luzhe Huang, Nir Pillar, Yuzhu Li, Hanlong Chen, Aydogan Ozcan|<http://arxiv.org/pdf/2410.20073v2>|提出了一种基于扩散模型的超分辨率虚拟染色方法，显著提升了无标签组织图像的分辨率和染色准确性。|
|🆕 发布|GroundingDINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models|《GroundingDINO-US-SAM：基于文本提示的超声多器官分割及LoRA微调的视觉语言模型》|Hamza Rasaee, Taha Koleilat, Hassan Rivaz|<http://arxiv.org/pdf/2506.23903v1>|提出了一种结合文本提示的视觉语言模型，通过少量数据实现超声多器官精准分割。|
|🆕 发布|VMoBA: Mixture-of-Block Attention for Video Diffusion Models|视频扩散模型中的混合块注意力机制：VMoBA|Jianzong Wu, Liang Hou, Haotian Yang, Xin Tao, Ye Tian, Pengfei Wan, Di Zhang, Yunhai Tong|<http://arxiv.org/pdf/2506.23858v1>|提出VMoBA，一种针对视频生成优化的稀疏注意力机制，大幅提升长视频处理效率。|
|🆕 发布|Flash-VStream: Efficient Real-Time Understanding for Long Video Streams|《Flash-VStream：长视频流的高效实时理解》|Haoji Zhang, Yiqin Wang, Yansong Tang, Yong Liu, Jiashi Feng, Xiaojie Jin|<http://arxiv.org/pdf/2506.23825v1>|[代码](https://github.com/IVGSZ/Flash-VStream.); 提出了一种高效处理长视频流的方法Flash-VStream，通过双记忆模块优化了长视频理解和实时响应...|
|🆕 发布|Visual Textualization for Image Prompted Object Detection|图像提示对象检测的可视化文本转换|Yongjian Wu, Yang Zhou, Jiya Saiyin, Bingzheng Wei, Yan Xu|<http://arxiv.org/pdf/2506.23785v1>|[代码](https://github.com/WitGotFlg/VisTex-OVLM.); 提出 VisTex-OVLM 方法，通过视觉文本化增强模型对稀有对象的检测能力，实现少量样本学习下的...|
|🆕 发布|Radioactive Watermarks in Diffusion and Autoregressive Image Generative Models|放射性水印在扩散和自回归图像生成模型中的应用|Michel Meintz, Jan Dubiński, Franziska Boenisch, Adam Dziedzic|<http://arxiv.org/pdf/2506.23731v1>|提出针对自回归图像生成模型的首个具有放射性特性的水印方法，有效保护生成图像版权。|
|🆕 发布|Subjective Camera: Bridging Human Cognition and Visual Reconstruction through Sequence-Aware Sketch-Guided Diffusion|主观相机：通过序列感知草图引导扩散连接人类认知与视觉重建|Haoyang Chen, Dongfang Sun, Caoyuan Ma, Shiqin Wang, Kewei Zhang, Zheng Wang, Zhixiang Wang|<http://arxiv.org/pdf/2506.23711v1>|提出Subjective Camera方法，通过结合文字描述和草图序列，将主观感知转化为逼真图像，解...|
|📝 更新|Cluster and Predict Latent Patches for Improved Masked Image Modeling|用于改进遮罩图像建模的潜在区块聚类与预测|Timothée Darcet, Federico Baldassarre, Maxime Oquab, Julien Mairal, Piotr Bojanowski|<http://arxiv.org/pdf/2502.08769v3>|提出了一种基于聚类预测的纯MIM框架CAPI，显著提升了掩码图像建模的性能。|
|📝 更新|DepthART: Monocular Depth Estimation as Autoregressive Refinement Task|深度艺术：将单目深度估计作为自回归精炼任务|Bulat Gabdullin, Nina Konovalova, Nikolay Patakin, Dmitry Senushkin, Anton Konushin|<http://arxiv.org/pdf/2409.15010v3>|提出了一种动态目标训练方法DepthART，通过自 refinement 显著提升了单目深度估计性能...|
|🆕 发布|MDPG: Multi-domain Diffusion Prior Guidance for MRI Reconstruction|多域扩散先验引导的MRI重建方法：MDPG|Lingtong Zhang, Mengdie Song, Xiaohan Hao, Huayu Mai, Bensheng Qiu|<http://arxiv.org/pdf/2506.23701v1>|[代码](https://github.com/Zolento/MDPG.); 提出了一种多域扩散先验引导方法，通过预训练的潜在扩散模型增强MRI重建的数据一致性。|
|🆕 发布|Blending Concepts with Text-to-Image Diffusion Models|将概念与文本到图像扩散模型融合|Lorenzo Olearo, Giorgio Longari, Alessandro Raganato, Rafael Peñaloza, Simone Melzi|<http://arxiv.org/pdf/2506.23630v1>|探究了文本到图像扩散模型在零样本框架下融合不同概念生成新视觉实体的能力。|
|📝 更新|Visual Position Prompt for MLLM based Visual Grounding|基于多模态语言模型的视觉定位提示在视觉定位中的应用|Wei Tang, Yanpeng Sun, Qinying Gu, Zechao Li|<http://arxiv.org/pdf/2503.15426v3>|[代码](https://github.com/WayneTomas/VPP-LLaVA.); 提出视觉位置提示增强的多模态大语言模型，提升图像位置定位能力并实现最佳视觉接地效果。|
|🆕 发布|MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI|面向通用人工智能的多模态多步骤推理开放性基准MMReason：用于大型多模态语言模型的评估|Huanjin Yao, Jiaxing Huang, Yawen Qiu, Michael K. Chen, Wenzheng Liu, Wei Zhang, Wenjie Zeng, Xikun Zhang .etc.|<http://arxiv.org/pdf/2506.23563v1>|[代码](https://github.com/HJYao00/MMReason.); 提出MMReason基准，通过多样化、开放式问题全面评估多模态大语言模型的长链推理能力。|
|📝 更新|Disentangled Diffusion-Based 3D Human Pose Estimation with Hierarchical Spatial and Temporal Denoiser|分层时空去噪器的解耦扩散式三维人体姿态估计|Qingyuan Cai, Xuecai Hu, Saihui Hou, Li Yao, Yongzhen Huang|<http://arxiv.org/pdf/2403.04444v2>|[代码](https://github.com/Andyen512/DDHPose); 提出了一种分解3D人体姿态估计的方法，通过层级时空去噪器优化了姿态的建模精度。|
|📝 更新|StereoDiff: Stereo-Diffusion Synergy for Video Depth Estimation|立体差分：立体-扩散协同作用在视频深度估计中的应用|Haodong Li, Chen Wang, Jiahui Lei, Kostas Daniilidis, Lingjie Liu|<http://arxiv.org/pdf/2506.20756v2>|提出了一种融合立体匹配与视频深度扩散的 StereoDiff 方法，针对视频静态与动态区域的不同需求...|
|📝 更新|ProSAM: Enhancing the Robustness of SAM-based Visual Reference Segmentation with Probabilistic Prompts|ProSAM：基于SAM的视觉参考分割的鲁棒性增强与概率提示|Xiaoqi Wang, Clint Sebastian, Wenbin He, Liu Ren|<http://arxiv.org/pdf/2506.21835v2>|提出ProSAM方法，通过学习变分提示编码器预测多变量提示分布，增强视觉参考分割的稳定性。|
|📝 更新|Deblurring in the Wild: A Real-World Dataset from Smartphone High-Speed Videos|《野外去模糊：来自智能手机高速视频的实际世界数据集》|Mahdi Mohd Hossain Noki, Syed Mumtahin Mahmud, Prothito Shovon Majumder, Abdul Mohaimen Al Radi, Md. Haider Ali, Md. Mosaddek Khan|<http://arxiv.org/pdf/2506.19445v2>|构建了首个大规模真实世界图像去模糊数据集，推动去模糊模型性能显著提升。|
|📝 更新|DeOcc-1-to-3: 3D De-Occlusion from a Single Image via Self-Supervised Multi-View Diffusion|《DeOcc-1-to-3: 通过自监督多视角扩散从单张图像中进行三维去遮挡》|Yansong Qu, Shaohui Dai, Xinyang Li, Yuze Wang, You Shen, Liujuan Cao, Rongrong Ji|<http://arxiv.org/pdf/2506.21544v2>|提出了一种从单张遮挡图像生成六视图的框架，实现无需修复或手动标注的可靠三维重建。|
|🆕 发布|MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting|MTADiffusion：用于物体修复的掩码文本对齐扩散模型|Jun Huang, Ting Liu, Yihang Wu, Xiaochao Qu, Luoqi Liu, Xiaolin Hu|<http://arxiv.org/pdf/2506.23482v1>|提出MTADiffusion模型，通过自动标注和风格一致性损失解决图像修复中的对齐、结构及风格问题。|
|🆕 发布|FD-DiT: Frequency Domain-Directed Diffusion Transformer for Low-Dose CT Reconstruction|频率域指导的扩散变换器FD-DiT：用于低剂量CT重建|Qiqing Liu, Guoquan Wei, Zekun Zhou, Yiyang Wen, Liu Shi, Qiegen Liu|<http://arxiv.org/pdf/2506.23466v1>|提出了一种基于频率域和扩散变换器的低剂量CT重建方法，有效抑制噪声和图像伪影。|
|🆕 发布|Towards foundational LiDAR world models with efficient latent flow matching|面向基础激光雷达世界模型的高效潜在流匹配|Tianran Liu, Shengwen Zhao, Nicholas Rhinehart|<http://arxiv.org/pdf/2506.23434v1>|提出了一种高效的潜在条件流匹配框架，提升了LiDAR世界模型的跨领域迁移性和压缩效率。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Consistency Trajectory Matching for One-Step Generative Super-Resolution|一步生成超分辨率的一致性轨迹匹配|Weiyi You, Mingyang Zhang, Leheng Zhang, Xingyu Zhou, Kexuan Shi, Shuhang Gu|<http://arxiv.org/pdf/2503.20349v3>|提出了一种无需蒸馏的图像超分辨率方法，通过一致性轨迹匹配直接学习低分辨率到高分辨率的映射，实现了高效...|
|🆕 发布|Proteus-ID: ID-Consistent and Motion-Coherent Video Customization|普罗透斯-ID：身份一致性与运动连贯性视频定制化|Guiyu Zhang, Chen Shi, Zijian Jiang, Xunzhi Xiang, Jingjing Qian, Shaoshuai Shi, Li Jiang|<http://arxiv.org/pdf/2506.23729v1>|[代码](https://grenoble-zhang.github.io/Proteus-ID); Proteus-ID通过多模态身份融合和时间感知身份注入，以及自适应运动学习策略，实现了视频定制中的...|
|🆕 发布|AI-Generated Lecture Slides for Improving Slide Element Detection and Retrieval|用于提升幻灯片元素检测与检索的人工智能生成讲座幻灯片|Suyash Maniyar, Vishvesh Trivedi, Ajoy Mondal, Anand Mishra, C. V. Jawahar|<http://arxiv.org/pdf/2506.23605v1>|[代码](https://synslidegen.github.io/.); 提出了一种生成合成讲座幻灯片的方法，通过少量样本迁移学习显著提升了元素检测和检索性能。|
|🆕 发布|Dataset Distillation via Vision-Language Category Prototype|通过视觉-语言类别原型进行数据集蒸馏|Yawen Zou, Guang Li, Duo Su, Zi Wang, Jun Yu, Chao Zhang|<http://arxiv.org/pdf/2506.23580v1>|[代码](https://github.com/zou-yawen/Dataset-Distillation-via-Vision-Language-Category-Prototype); 整合视觉与语言原型，提出数据集蒸馏新方法，增强模型泛化能力并提升验证性能。|
|🆕 发布|Consistent Time-of-Flight Depth Denoising via Graph-Informed Geometric Attention|通过图信息引导的几何注意力实现一致的时间飞行深度去噪|Weida Wang, Changyong He, Jin Zeng, Di Qiu|<http://arxiv.org/pdf/2506.23542v1>|[代码](https://github.com/davidweidawang/GIGA-ToF); 提出了一种ToF深度图像去噪网络，通过运动不变图融合同时增强时间稳定性和空间清晰度。|
|🆕 发布|Instant GaussianImage: A Generalizable and Self-Adaptive Image Representation via 2D Gaussian Splatting|即时高斯图像：通过二维高斯绘制实现的通用性和自适应性图像表示|Zhaojie Zeng, Yuesong Wang, Chao Yang, Tao Guan, Lili Ju|<http://arxiv.org/pdf/2506.23479v1>|提出了一种自适应的二维高斯渲染框架，通过动态调整高斯点数量，大幅缩短训练时间并提升图像渲染质量。|
|📝 更新|ForgeLens: Data-Efficient Forgery Focus for Generalizable Forgery Image Detection|ForgeLens：高效伪造焦点数据用于泛化伪造图像检测|Yingjian Chen, Lei Zhang, Yakun Niu|<http://arxiv.org/pdf/2408.13697v2>|[代码](https://github.com/Yingjian-Chen/ForgeLens.); 提出ForgeLens框架，通过两个轻量级设计使冻结网络专注于伪造特征，实现高效训练与强大泛化能力。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|How to Design and Train Your Implicit Neural Representation for Video Compression|如何设计和训练您的隐式神经表示用于视频压缩|Matthew Gwilliam, Roy Zhang, Namitha Padmanabhan, Hongyang Du, Abhinav Shrivastava|<http://arxiv.org/pdf/2506.24127v1>|[代码](https://github.com/mgwillia/vinrb.); 提出视频隐式神经表示设计原则，实现更快编码速度和更高压缩质量。|
|🆕 发布|HiNeuS: High-fidelity Neural Surface Mitigating Low-texture and Reflective Ambiguity|HiNeuS：高保真神经表面减轻低纹理和反射模糊|Yida Wang, Xueyang Zhang, Kun Zhan, Peng Jia, Xianpeng Lang|<http://arxiv.org/pdf/2506.23854v1>|HiNeuS通过统一框架解决了多视角辐射不一致、无纹理区域关键点缺失和结构退化问题，实现了高保真神经...|
|🆕 发布|PointSSIM: A novel low dimensional resolution invariant image-to-image comparison metric|点结构相似性度量：一种新颖的低维分辨率不变图像间比较度量|Oscar Ovanger, Ragnar Hauge, Jacob Skauvold, Michael J. Pyrcz, Jo Eidsvik|<http://arxiv.org/pdf/2506.23833v1>|提出了一种分辨率不变的图像比较度量方法PointSSIM，通过提取关键特征点实现不同分辨率二值图像的...|
|🆕 发布|Spatio-Temporal Representation Decoupling and Enhancement for Federated Instrument Segmentation in Surgical Videos|手术视频中联邦器械分割的时空表示解耦与增强|Zheng Fang, Xiaoming Qi, Chun-Mei Feng, Jialun Pei, Weixin Si, Yueming Jin|<http://arxiv.org/pdf/2506.23759v1>|提出个性化联邦学习方案FedST，通过时空表示解耦与增强，提升手术器械分割准确性和适应性。|
|🆕 发布|AttentionGS: Towards Initialization-Free 3D Gaussian Splatting via Structural Attention|面向无需初始化的3D高斯散点绘制：基于结构注意力的方法|Ziao Liu, Zhenjia Li, Yifeng Shi, Xiangang Li|<http://arxiv.org/pdf/2506.23611v1>|提出AttentionGS方法，通过结构注意力实现无需高质量点云初始化的3D重建。|
|🆕 发布|LH2Face: Loss function for Hard High-quality Face|LH2Face：面向困难高质量人脸的损失函数|Fan Xie, Pan Cao|<http://arxiv.org/pdf/2506.23555v1>|提出了一种针对硬样本和高质量人脸的适应性边缘损失函数LH2Face，显著提升了人脸识别准确率。|
|📝 更新|Iterative approach to reconstructing neural disparity fields from light-field data|从光场数据重建神经视差场的迭代方法|Ligen Shi, Chang Liu, Xing Zhao, Jun Qiu|<http://arxiv.org/pdf/2407.15380v2>|提出迭代法从光场数据重建连续神经视差场，克服传统视差图采样误差和插值不准确问题。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MILo: Mesh-In-the-Loop Gaussian Splatting for Detailed and Efficient Surface Reconstruction|MILo：基于网格循环的高斯散点投射法用于详细且高效表面重建|Antoine Guédon, Diego Gomez, Nissim Maruani, Bingchen Gong, George Drettakis, Maks Ovsjanikov|<http://arxiv.org/pdf/2506.24096v1>|MILo通过将高斯分布直接转换为表面网格，实现了高效且细节丰富的三维场景重建。|
|🆕 发布|GaVS: 3D-Grounded Video Stabilization via Temporally-Consistent Local Reconstruction and Rendering|基于时间一致性的局部重建与渲染的3D定位视频稳定化方法GaVS|Zinuo You, Stamatios Georgoulis, Anpei Chen, Siyu Tang, Dengxin Dai|<http://arxiv.org/pdf/2506.23957v1>|提出了一种3D-Grounded视频稳定化方法，通过局部重建和渲染实现时间一致性，有效解决了现有方法...|
|🆕 发布|Puzzles: Unbounded Video-Depth Augmentation for Scalable End-to-End 3D Reconstruction|“谜题：无界视频深度增强用于可扩展的端到端三维重建”|Jiahao Ma, Lei Wang, Miaomiao liu, David Ahmedt-Aristizabal, Chuong Nguyen|<http://arxiv.org/pdf/2506.23863v1>|[代码](https://jiahao-ma.github.io/puzzles); 提出Puzzles数据增强策略，通过模拟多样化相机轨迹和真实场景几何，大幅提升3D重建性能。|
|🆕 发布|Refine Any Object in Any Scene|任意场景中任意对象的细化|Ziwei Chen, Ziling Liu, Zitong Huang, Mingqi Gao, Feng Zheng|<http://arxiv.org/pdf/2506.23835v1>|[代码](https://github.com/PolySummit/RAISE.); 提出了一种利用3D生成先验来恢复缺失视角下物体细节的RAISE框架，实现了高保真物体建模与场景一致性...|
|🆕 发布|AFUNet: Cross-Iterative Alignment-Fusion Synergy for HDR Reconstruction via Deep Unfolding Paradigm|AFUNet：基于深度展开范式的跨迭代对齐-融合协同作用用于高动态范围图像重建|Xinyue Li, Zhangkai Ni, Wenhan Yang|<http://arxiv.org/pdf/2506.23537v1>|[代码](https://github.com/eezkni/AFUNet); 提出了一种将HDR重建分解为对齐与融合两个子任务的AFUNet方法，通过交替优化实现子任务协同，提升...|
|📝 更新|GLS: Geometry-aware 3D Language Gaussian Splatting|几何感知的3D语言高斯散点绘制方法（GLS）|Jiaxiong Qiu, Liu Liu, Xinjie Wang, Tianwei Lin, Wei Sui, Zhizhong Su|<http://arxiv.org/pdf/2411.18066v2>|[代码](https://jiaxiongq.github.io/GLS_ProjectPage.); 提出GLS框架，通过引入几何线索优化三维表面重建和开放词汇分割的清晰度和平滑度。|
|🆕 发布|GeoCD: A Differential Local Approximation for Geodesic Chamfer Distance|GeoCD：测地线切比雪夫距离的微分局部近似方法|Pedro Alonso, Tianrui Li, Chongshou Li|<http://arxiv.org/pdf/2506.23478v1>|提出GeoCD，一种考虑拓扑结构且可微分的测地线Chamfer距离近似，提升3D点云学习中的重建质量...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|C3VDv2 -- Colonoscopy 3D video dataset with enhanced realism|C3VDv2 -- 结肠镜3D视频数据集增强现实性版本|Mayank V. Golhar, Lucas Sebastian Galeano Fretes, Loren Ayers, Venkata S. Akshintala, Taylor L. Bobrow, Nicholas J. Durr|<http://arxiv.org/pdf/2506.24074v1>|介绍了C3VDv2数据集，增强真实性以促进3D结肠重建算法的定量评估。|
|🆕 发布|MReg: A Novel Regression Model with MoE-based Video Feature Mining for Mitral Regurgitation Diagnosis|MReg：一种基于MoE的视频特征挖掘新型回归模型用于二尖瓣反流诊断|Zhe Liu, Yuhao Huang, Lian Liu, Chengrui Zhang, Haotian Lin, Tong Han, Zhiyuan Zhu, Yanlin Chen .etc.|<http://arxiv.org/pdf/2506.23648v1>|[代码](https://github.com/cskdstz/MReg.); 提出了一种基于混合专家网络的特征挖掘回归模型，用于更准确的心脏返流诊断。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Markerless Intraoperative Tracking of Deformable Spine Tissue|面向无标记术中可变形脊椎组织的跟踪|Connor Daly, Elettra Marconi, Marco Riva, Jinendra Ekanayake, Daniel S. Elson, Ferdinando Rodriguez y Baena|<http://arxiv.org/pdf/2506.23657v1>|首次提出用于脊柱手术的临床RGB-D数据集，并开发了一套捕捉术前术后脊柱变形的系统SpineAlig...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|D$^2$ST-Adapter: Disentangled-and-Deformable Spatio-Temporal Adapter for Few-shot Action Recognition|D$^2$ST-Adapter：解耦-可变形时空适配器用于少量样本动作识别|Wenjie Pei, Qizhong Tan, Guangming Lu, Jiandong Tian, Jun Yu|<http://arxiv.org/pdf/2312.01431v4>|[代码](https://github.com/qizhongtan/D2ST-Adapter.); 提出了一种轻量级视频适配器框架D$^2$ST-Adapter，通过解耦时空特征编码，有效提升少量样本...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Accurate and lightweight dehazing via multi-receptive-field non-local network and novel contrastive regularization|通过多感受野非局部网络与新颖对比正则化的精确轻量级去雾方法|Zewei He, Zixuan Chen, Jinlei Li, Ziqian Lu, Xuecheng Sun, Hao Luo, Zhe-Ming Lu, Evangelos K. Markakis|<http://arxiv.org/pdf/2309.16494v2>|提出了一种多感受野非局部网络和新型对比性正则化的轻量级去雾方法，有效提取丰富特征并增强图像去雾性能。|
|🆕 发布|Spatially Gene Expression Prediction using Dual-Scale Contrastive Learning|基于双尺度对比学习的空间基因表达预测|Mingcheng Qu, Yuncong Wu, Donglin Di, Yue Gao, Tonghua Su, Yang Song, Lei Fan|<http://arxiv.org/pdf/2506.23827v1>|[代码](https://github.com/MCPathology/NH2ST); 提出NH2ST框架，融合空间上下文和病理与基因模态，通过对比学习预测基因表达，提升预测准确度超20%...|
|🆕 发布|When Test-Time Adaptation Meets Self-Supervised Models|当测试时适应遇到自监督模型|Jisu Han, Jihee Park, Dongyoon Han, Wonjun Hwang|<http://arxiv.org/pdf/2506.23529v1>|提出了一种结合自监督学习和测试时适应的方法，有效提升了自监督模型在无源预训练情况下的性能。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FADRM: Fast and Accurate Data Residual Matching for Dataset Distillation|FADRM：快速准确的数据残差匹配用于数据集蒸馏|Jiacheng Cui, Xinyue Bi, Yaxin Luo, Xiaohan Zhao, Jiacheng Liu, Zhiqiang Shen|<http://arxiv.org/pdf/2506.24125v1>|[代码](https://github.com/Jiacheng8/FADRM.); 首次提出数据残差匹配方法，通过数据级跳连接优化数据生成，提升数据蒸馏效率和准确性。|
|🆕 发布|The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models|《进步的幻象？对视觉语言模型测试时适应性的批判性审视》|Lijun Sheng, Jian Liang, Ran He, Zilei Wang, Tieniu Tan|<http://arxiv.org/pdf/2506.24000v1>|提出统一框架TTA-VLM，全面评估视觉语言模型测试时适应方法，揭示现有方法效果有限且影响模型可信度...|
|🆕 发布|When Small Guides Large: Cross-Model Co-Learning for Test-Time Adaptation|当小引导大：测试时适应的跨模型协同学习|Chang'an Yi, Xiaohui Deng, Guohao Chen, Yan Zhou, Qinghua Lu, Shuaicheng Niu|<http://arxiv.org/pdf/2506.23724v1>|[代码](https://github.com/ycarobot/COCA.); 提出跨模型协同学习框架COCA，通过互补知识提升测试时适应性能。|
|🆕 发布|Pruning by Block Benefit: Exploring the Properties of Vision Transformer Blocks during Domain Adaptation|通过块效益进行剪枝：在域自适应过程中探索视觉变换器块的性质|Patrick Glandorf, Bodo Rosenhahn|<http://arxiv.org/pdf/2506.23675v1>|提出了一种按区块效益进行剪枝的方法，有效解决了视觉变换器模型在未见过数据域中的性能损失问题。|
|🆕 发布|Partial Forward Blocking: A Novel Data Pruning Paradigm for Lossless Training Acceleration|部分前向阻塞：一种用于无损训练加速的新型数据剪枝范式|Dongyue Wu, Zilin Guo, Jialong Zuo, Nong Sang, Changxin Gao|<http://arxiv.org/pdf/2506.23674v1>|提出了一种无需梯度回传或代理模型训练的数据剪枝方法 Partial Forward Blocking...|
|📝 更新|Emulating Self-attention with Convolution for Efficient Image Super-Resolution|用卷积模拟自注意力以提高图像超分辨率效率|Dongheon Lee, Seokju Yun, Youngmin Ro|<http://arxiv.org/pdf/2503.06671v2>|提出了一种卷积化注意力模块，通过模仿Transformer的远距离建模能力，实现了高效图像超分辨率处...|
|🆕 发布|FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization|FedWSQ：具有权重标准化和分布感知非均匀量化的高效联邦学习|Seung-Wook Kim, Seongyeol Kim, Jiah Kim, Seowon Ji, Se-Ho Lee|<http://arxiv.org/pdf/2506.23516v1>|提出FedWSQ框架，通过权重标准化和分布感知非均匀量化提升联邦学习性能，降低通信成本。|
|🆕 发布|NavMorph: A Self-Evolving World Model for Vision-and-Language Navigation in Continuous Environments|NavMorph：一种面向连续环境中视觉与语言导航的自演化世界模型|Xuan Yao, Junyu Gao, Changsheng Xu|<http://arxiv.org/pdf/2506.23468v1>|[代码](https://github.com/Feliciaxyao/NavMorph); NavMorph通过构建自我进化的世界模型，有效提升了复杂环境中视觉语言导航的适应性和决策能力。|
|🆕 发布|Sanitizing Manufacturing Dataset Labels Using Vision-Language Models|使用视觉语言模型清洗制造数据集标签|Nazanin Mahjourian, Vinh Nguyen|<http://arxiv.org/pdf/2506.23465v1>|提出了一种基于视觉语言模型的标签清洗和优化框架，有效提升了制造领域图像数据集的质量。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DenseWorld-1M: Towards Detailed Dense Grounded Caption in the Real World|面向真实世界详细密集地面标注的DenseWorld-1M|Xiangtai Li, Tao Zhang, Yanwei Li, Haobo Yuan, Shihao Chen, Yikang Zhou, Jiahao Meng, Yueyi Sun .etc.|<http://arxiv.org/pdf/2506.24102v1>|首次构建了大规模详细密集的现实世界图像标注数据集DenseWorld-1M，并设计了三阶段标注流程及...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ShapeKit|形状工具包|Junqi Liu, Dongli He, Wenxuan Li, Ningyu Wang, Alan L. Yuille, Zongwei Zhou|<http://arxiv.org/pdf/2506.24003v1>|提出ShapeKit工具包，通过优化解剖形状提高了医学分割精度超8%，无需模型重训练或微调。|
|🆕 发布|Evaluating the Impact of Khmer Font Types on Text Recognition|评估柬埔寨字体类型对文本识别的影响|Vannkinh Nom, Souhail Bakkali, Muhammad Muzzamil Luqman, Mickael Coustaty, Jean-Marc Ogier|<http://arxiv.org/pdf/2506.23963v1>|评估了19种Khmer字体对文字识别准确性的影响，指导优化OCR系统字体选择。|
|🆕 发布|Towards Efficient and Accurate Spiking Neural Networks via Adaptive Bit Allocation|通过自适应比特分配实现高效精确的脉冲神经网络|Xingting Yao, Qinghao Hu, Fei Zhou, Tielong Liu, Gang Li, Peisong Wang, Jian Cheng|<http://arxiv.org/pdf/2506.23717v1>|提出自适应比特分配策略，优化脉冲神经网络资源分配，提升效率和准确性。|
|🆕 发布|KiseKloset: Comprehensive System For Outfit Retrieval, Recommendation, And Try-On|“KiseKloset：一套全面的着装检索、推荐与试穿系统”|Thanh-Tung Phan-Nguyen, Khoi-Nguyen Nguyen-Ngoc, Tam V. Nguyen, Minh-Triet Tran, Trung-Nghia Le|<http://arxiv.org/pdf/2506.23471v1>|提出了一种集成 outfit 检索、推荐和虚拟试穿的综合系统，通过近似算法优化搜索并提升在线购物体验...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Benchmarking Spiking Neural Network Learning Methods with Varying Locality|结果： 使用不同局部性基准测试尖峰神经网络学习方法|Jiaqi Lin, Sen Lu, Malyaban Bal, Abhronil Sengupta|<http://arxiv.org/pdf/2402.01782v2>|比较了不同局部性学习方法的SNN训练效果，并证明了增加显式递归权重能增强SNN的鲁棒性。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spurious-Aware Prototype Refinement for Reliable Out-of-Distribution Detection|伪迹感知的原型精炼：用于可靠分布外检测|Reihaneh Zohrabi, Hosein Hasani, Mahdieh Soleymani Baghshah, Anna Rohrbach, Marcus Rohrbach, Mohammad Hossein Rohban|<http://arxiv.org/pdf/2506.23881v1>|提出SPROD方法，通过优化类原型以消除无关特征偏差，有效提升OOD检测的可靠性。|
|📝 更新|DisCoPatch: Taming Adversarially-driven Batch Statistics for Improved Out-of-Distribution Detection|“DisCoPatch：驯化对抗驱动批处理统计以提高分布外检测性能”|Francisco Caetano, Christiaan Viviers, Luis A. Zavala-Mondragón, Peter H. N. de With, Fons van der Sommen|<http://arxiv.org/pdf/2501.08005v4>|提出DisCoPatch框架，利用对抗性VAE和批统计区分细微分布变化，实现卓越的OOD检测性能。|
|📝 更新|Understanding and Reducing the Class-Dependent Effects of Data Augmentation with A Two-Player Game Approach|"理解并减少数据增强的类依赖效应：一种双玩家博弈方法"|Yunpeng Jiang, Yutong Ban, Paul Weng|<http://arxiv.org/pdf/2407.03146v5>|提出CLAM方法，通过对抗性双玩家游戏平衡数据增强对多类分类的影响。|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Finer Disentanglement of Aleatoric Uncertainty Can Accelerate Chemical Histopathology Imaging|《更精细的偶然不确定性解耦可以加速化学组织病理学成像》|Ji-Hun Oh, Kianoush Falahkheirkhah, Rohit Bhargava|<http://arxiv.org/pdf/2502.20532v2>|提出一种细粒度不确定性分离方法，通过高低信息成像优化，加速化学组织病理学成像流程。|
|🆕 发布|Sample Margin-Aware Recalibration of Temperature Scaling|样本边缘感知的温度缩放重新校准|Haolan Guo, Linwei Tao, Haoyang Luo, Minjing Dong, Chang Xu|<http://arxiv.org/pdf/2506.23492v1>|提出了一种基于样本间隔的轻量级温度缩放校准方法，有效平衡模型偏差和方差，实现高效准确的不确定性量化。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Three-dimensional end-to-end deep learning for brain MRI analysis|三维端到端深度学习在脑部磁共振成像分析中的应用|Radhika Juglan, Marta Ligero, Zunamys I. Carrero, Asier Rabasco, Tim Lenz, Leo Misera, Gregory Patrick Veldhuizen, Paul Kuntke .etc.|<http://arxiv.org/pdf/2506.23916v1>|证明了在脑部MRI分析中，简单卷积网络比复杂注意力机制网络具有更好的泛化性能。|
|📝 更新|Advancing Textual Prompt Learning with Anchored Attributes|文本提示学习的锚点属性增强方法|Zheng Li, Yibing Song, Ming-Ming Cheng, Xiang Li, Jian Yang|<http://arxiv.org/pdf/2412.09442v2>|提出了一种利用属性作为桥梁来增强图像与未知类别对齐的文本提示学习方法ATPrompt。|
|🆕 发布|Supercm: Revisiting Clustering for Semi-Supervised Learning|超厘米：对半监督学习中的聚类方法进行再探讨|Durgesh Singh, Ahcene Boubekki, Robert Jenssen, Michael C. Kampffmeyer|<http://arxiv.org/pdf/2506.23824v1>|提出了一种基于聚类假设的半监督学习方法，简化训练策略并提升模型性能。|
|📝 更新|Mitigating Knowledge Discrepancies among Multiple Datasets for Task-agnostic Unified Face Alignment|在多数据集间减轻知识差异以实现任务无关的统一人脸对齐|Jiahao Xia, Min Xu, Wenjian Huang, Jianguo Zhang, Haimin Zhang, Chunxia Xiao|<http://arxiv.org/pdf/2503.22359v2>|[代码](https://github.com/Jiahao-UTS/TUFA.); 提出了一种统一多数据集知识的方法，通过构建语义平面提升了人脸对齐模型的泛化能力和零样本定位性能。|
|📝 更新|Harnessing Shared Relations via Multimodal Mixup Contrastive Learning for Multimodal Classification|通过多模态Mixup对比学习利用共享关系进行多模态分类|Raja Kumar, Raghav Singhal, Pranamya Kulkarni, Deval Mehta, Kshitij Jadhav|<http://arxiv.org/pdf/2409.17777v4>|[代码](https://github.com/RaghavSinghal10/M3CoL.); 提出M3CoL方法，通过混合对比损失学习多模态数据中的共享关系，提升多模态分类性能。|
|📝 更新|LW2G: Learning Whether to Grow for Prompt-based Continual Learning|LW2G:面向基于提示的持续学习的“学习是否增长”策略|Qian Feng, Da-wei Zhou, Hanbin Zhao, Chao Zhang, Jiahua Dong, Dengxin Dai, Hui Qian|<http://arxiv.org/pdf/2409.18860v2>|[代码](https://github.com/RAIAN08/LW2G.); 提出了一种动态增长的prompt池管理策略，通过衡量任务间差异优化prompt选择，提升持续学习性能...|
|🆕 发布|Uncertainty-aware Diffusion and Reinforcement Learning for Joint Plane Localization and Anomaly Diagnosis in 3D Ultrasound|不确定性感知的扩散与强化学习在三维超声联合平面定位与异常诊断中的应用|Yuhao Huang, Yueyue Xu, Haoran Dou, Jiaxiao Deng, Xin Yang, Hongyu Zheng, Dong Ni|<http://arxiv.org/pdf/2506.23538v1>|[代码](https://github.com/yuhoo0302/CUA-US.); 提出了一种结合去噪扩散模型和强化学习的方法，用于三维超声图像中的平面定位和异常诊断。|
|📝 更新|Mesh-Learner: Texturing Mesh with Spherical Harmonics|球谐纹理学习器：使用球谐函数纹理化网格|Yunfei Wan, Jianheng Liu, Chunran Zheng, Jiarong Lin, Fu Zhang|<http://arxiv.org/pdf/2504.19938v2>|[代码](https://github.com/hku-mars/Mesh-Learner.); 提出了一种结合网格和球面谐波纹理的3D重建与渲染框架，实现了视图依赖的光照效果学习，兼容传统光栅化流...|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 目标导向视觉决策 (Goal-oriented Visual Decision Making)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Ella: Embodied Social Agents with Lifelong Memory|Ella: 具有终身记忆的具身社交智能体|Hongxin Zhang, Zheyuan Zhang, Zeyuan Wang, Zunzhe Zhang, Lixing Fang, Qinhong Zhou, Chuang Gan|<http://arxiv.org/pdf/2506.24019v1>|[代码](https://umass-embodied-agi.github.io/Ella); 提出了一种具有终身记忆能力的社交机器人Ella，通过结构化记忆系统与基础模型结合，实现了在开放世界中...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives|教会时间序列看与说：基于对齐的视觉与文本视角进行预测|Dong Sixun, Fan Wei, Teresa Wu, Fu Yanjie|<http://arxiv.org/pdf/2506.24124v1>|[代码](https://github.com/Ironieser/TimesCLIP.); 提出了一种将时间序列转化为视觉和文本双模态表示的方法，通过对比学习提升预测准确性。|
|📝 更新|GLIMPSE: Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation for Generative LVLMs|GLIMPSE：用于生成型LVLMs的提示视觉显著性解释的梯度层重要性映射|Guanxi Shen|<http://arxiv.org/pdf/2506.18985v2>|提出GLIMPSE框架，通过融合多模态信息提升大型视觉语言模型的可解释性。|
|📝 更新|ReferDINO: Referring Video Object Segmentation with Visual Grounding Foundations|ReferDINO：基于视觉定位基础的视频目标分割|Tianming Liang, Kun-Yu Lin, Chaolei Tan, Jianguo Zhang, Wei-Shi Zheng, Jian-Fang Hu|<http://arxiv.org/pdf/2501.14607v2>|提出ReferDINO模型，融合视觉 grounding 基础与时空推理，实现高效视频目标分割。|
|📝 更新|Visual Encoders for Data-Efficient Imitation Learning in Modern Video Games|现代电子游戏中的数据高效模仿学习视觉编码器|Lukas Schäfer, Logan Jones, Anssi Kanervisto, Yuhan Cao, Tabish Rashid, Raluca Georgescu, Dave Bignell, Siddhartha Sen .etc.|<http://arxiv.org/pdf/2312.02312v3>|探究视觉编码器在模仿学习中的作用，发现预训练编码器可提升决策效果并降低训练成本。|
|📝 更新|HalCECE: A Framework for Explainable Hallucination Detection through Conceptual Counterfactuals in Image Captioning|HalCECE：一种通过概念反事实进行图像描述中的可解释性幻觉检测框架|Maria Lymperaiou, Giorgos Filandrianos, Angeliki Dimitriou, Athanasios Voulodimos, Giorgos Stamou|<http://arxiv.org/pdf/2503.00436v2>|提出 HalCECE 框架，利用概念反事实解释检测并解释图像描述中的幻觉现象。|
|🆕 发布|GViT: Representing Images as Gaussians for Visual Recognition|高斯视觉识别：将图像表示为高斯分布进行视觉识别|Jefferson Hernandez, Ruozhen He, Guha Balakrishnan, Alexander C. Berg, Vicente Ordonez|<http://arxiv.org/pdf/2506.23532v1>|将图像表示为二维高斯分布，GVIT框架通过优化高斯参数实现视觉识别，性能接近传统ViT。|
|📝 更新|RCA: Region Conditioned Adaptation for Visual Abductive Reasoning|区域条件适应：用于视觉假设推理的方法|Hao Zhang, Yeo Keat Ee, Basura Fernando|<http://arxiv.org/pdf/2303.10428v6>|[代码](https://github.com/LUNAProject22/RPA.); 提出了一种区域条件适应方法，通过局部视觉线索增强CLIP模型的推理能力，显著提升视觉推理任务的准确性...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visual and Memory Dual Adapter for Multi-Modal Object Tracking|视觉与记忆双适配器用于多模态目标跟踪|Boyue Xu, Ruichao Hou, Tongwei Ren, Gangshan Wu|<http://arxiv.org/pdf/2506.23972v1>|[代码](https://github.com/xuboyue1999/mmtrack.git.); 提出了一种视觉与记忆双适配器方法，有效提升了多模态目标跟踪的鲁棒性和判别力。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Visual Re-Ranking with Non-Visual Side Information|基于非视觉辅助信息的视觉重排序|Gustav Hanning, Gabrielle Flood, Viktor Larsson|<http://arxiv.org/pdf/2504.11134v2>|提出了一种结合非视觉辅助信息的图像重排序方法GCSA，有效提升了视觉定位的准确性。|
|🆕 发布|Evaluation of Geolocation Capabilities of Multimodal Large Language Models and Analysis of Associated Privacy Risks|多模态大型语言模型地理定位能力的评估及隐私风险分析|Xian Zhang, Xiang Cheng|<http://arxiv.org/pdf/2506.23481v1>|[代码](https://github.com/zxyl1003/MLLM-Geolocation-Evaluation.); 评估了大型多模态语言模型的地缘定位能力并分析了相关隐私风险。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Epona: Autoregressive Diffusion World Model for Autonomous Driving|艾波娜：用于自动驾驶的自回归扩散世界模型|Kaiwen Zhang, Zhenyu Tang, Xiaotao Hu, Xingang Pan, Xiaoyang Guo, Yuan Liu, Jingwei Huang, Li Yuan .etc.|<http://arxiv.org/pdf/2506.24113v1>|[代码](https://github.com/Kevin-thu/Epona); 提出Epona模型，通过解耦时空因子化和模块化轨迹预测，实现自动驾驶中高分辨率、长时序的视觉建模与运...|
|🆕 发布|A Survey on Vision-Language-Action Models for Autonomous Driving|自动驾驶领域视觉-语言-动作模型研究综述|Sicong Jiang, Zilin Huang, Kangan Qian, Ziang Luo, Tianze Zhu, Yang Zhong, Yihong Tang, Menglin Kong .etc.|<http://arxiv.org/pdf/2506.24044v1>|[代码](https://github.com/JohnsonJiang1996/Awesome-VLA4AD); 系统梳理了自动驾驶领域的视觉语言行动模型，对比分析了20余种模型，并展望了未来发展挑战。|
|🆕 发布|StyleDrive: Towards Driving-Style Aware Benchmarking of End-To-End Autonomous Driving|《StyleDrive：面向驾驶风格感知的端到端自动驾驶基准测试》|Ruiyang Hao, Bowen Jing, Haibao Yu, Zaiqing Nie|<http://arxiv.org/pdf/2506.23982v1>|提出首个包含多样化驾驶偏好标注的大规模真实世界数据集，为个性化端到端自动驾驶系统奠定基础。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FlatFusion: Delving into Details of Sparse Transformer-based Camera-LiDAR Fusion for Autonomous Driving|FlatFusion：深入探究基于稀疏变换器的相机-激光雷达融合技术在自动驾驶中的应用细节|Yutao Zhu, Xiaosong Jia, Xinyu Yang, Junchi Yan|<http://arxiv.org/pdf/2408.06832v2>|提出了一种细致设计的稀疏Transformer-based相机-激光雷达融合框架FlatFusion...|
|📝 更新|INP-Former++: Advancing Universal Anomaly Detection via Intrinsic Normal Prototypes and Residual Learning|INP-Former++：通过内在正常原型和残差学习推进通用异常检测|Wei Luo, Haiming Yao, Yunkang Cao, Qiyu Chen, Ang Gao, Weiming Shen, Wenyong Yu|<http://arxiv.org/pdf/2506.03660v2>|提出了一种直接从测试图像中提取内在正常原型的方法，实现了各类异常检测任务中的性能提升。|
|🆕 发布|MadCLIP: Few-shot Medical Anomaly Detection with CLIP|MadCLIP：基于CLIP的少量样本医学异常检测|Mahshid Shiri, Cigdem Beyan, Vittorio Murino|<http://arxiv.org/pdf/2506.23810v1>|[代码](https://github.com/mahshid1998/MadCLIP.); 提出了一种基于预训练CLIP模型的双分支少样本医学异常检测方法，实现了图像级分类和像素级分割的优异性...|
|📝 更新|PerLDiff: Controllable Street View Synthesis Using Perspective-Layout Diffusion Models|《PerLDiff：基于透视-布局扩散模型的可控街景合成》|Jinhua Zhang, Hualian Sheng, Sijia Cai, Bing Deng, Qiao Liang, Wen Li, Ying Fu, Jieping Ye .etc.|<http://arxiv.org/pdf/2407.06109v4>|提出了一种利用透视三维几何信息指导街景图像生成的PerLDiff模型，实现了更精确的物体级控制。|
|🆕 发布|Single Image Test-Time Adaptation via Multi-View Co-Training|通过多视角协同训练实现单张图像测试时适应|Smriti Joshi, Richard Osuala, Lidia Garrucho, Kaisar Kushibar, Dimitri Kessler, Oliver Diaz, Karim Lekadir|<http://arxiv.org/pdf/2506.23705v1>|[代码](https://github.com/smriti-joshi/muvi.git.); 提出了一种针对单张图像测试时自适应的多视角协同训练方法，无需大量目标域数据即可实现高效的医学图像分割...|
|📝 更新|Methodology for an Analysis of Influencing Factors on 3D Object Detection Performance|三维目标检测性能影响因素分析方法|Anton Kuznietsov, Dirk Schweickard, Steven Peters|<http://arxiv.org/pdf/2411.08482v3>|提出了一种新方法分析物体和环境因素如何影响3D对象检测性能，助力更安全的系统开发。|
|🆕 发布|Diffusion Model-based Data Augmentation Method for Fetal Head Ultrasound Segmentation|基于扩散模型的数据增强方法用于胎儿头部超声图像分割|Fangyijie Wang, Kevin Whelan, Félix Balado, Guénolé Silvestre, Kathleen M. Curran|<http://arxiv.org/pdf/2506.23664v1>|提出了一种基于扩散模型的生成式AI方法，有效生成胎儿头部超声图像数据，提高了有限真实数据集的分割精度...|
|🆕 发布|VAP-Diffusion: Enriching Descriptions with MLLMs for Enhanced Medical Image Generation|VAP-Diffusion：利用多模态大型语言模型增强医学图像生成的描述丰富性|Peng Huang, Junhu Fu, Bowen Guo, Zeju Li, Yuanyuan Wang, Yi Guo|<http://arxiv.org/pdf/2506.23641v1>|利用预训练的多模态大语言模型丰富描述信息，提出VAP-Diffusion框架以增强医疗图像生成的质量...|
|🆕 发布|Brain Tumor Detection through Thermal Imaging and MobileNET|通过热成像和MobileNET进行脑肿瘤检测|Roham Maiti, Debasmita Bhoumik|<http://arxiv.org/pdf/2506.23627v1>|利用MobileNET模型和图像处理技术，实现了快速准确的脑肿瘤热成像检测。|
|🆕 发布|A Clinically-Grounded Two-Stage Framework for Renal CT Report Generation|基于临床的肾CT报告生成的两阶段框架|Renjie Liang, Zhengkang Fan, Jinqian Pan, Chenkun Sun, Russell Terry, Jie Xu|<http://arxiv.org/pdf/2506.23584v1>|提出了一种两阶段框架，通过提取结构化异常特征并融合图像与语言模型，生成符合临床发现的肾部CT报告。|
|🆕 发布|Metadata, Wavelet, and Time Aware Diffusion Models for Satellite Image Super Resolution|卫星图像超分辨率中的元数据、小波和时间感知扩散模型|Luigi Sigillo, Renato Giamba, Danilo Comminiello|<http://arxiv.org/pdf/2506.23566v1>|提出了一种结合元数据、小波变换和时序信息的卫星图像超分辨率框架，有效提升了图像重建质量。|
|📝 更新|Mono-Modalizing Extremely Heterogeneous Multi-Modal Medical Image Registration|单模态化极大异质多模态医学图像配准|Kyobin Choo, Hyunkyung Han, Jinyeong Kim, Chanyong Yoon, Seong Jae Hwang|<http://arxiv.org/pdf/2506.15596v2>|[代码](https://github.com/MICV-yonsei/M2M-Reg.); 提出了一种名为M2M-Reg的新框架，通过仅使用单模态相似性训练多模态图像配准模型，有效解决了高度异...|
|🆕 发布|OcRFDet: Object-Centric Radiance Fields for Multi-View 3D Object Detection in Autonomous Driving|面向自动驾驶的多视角三维目标检测：基于目标中心的辐射场检测|Mingqian Ji, Jian Yang, Shanshan Zhang|<http://arxiv.org/pdf/2506.23565v1>|[代码](https://github.com/Mingqj/OcRFDet.); 提出对象中心辐射场，专注于前景物体建模，显著提升自动驾驶中多视角3D物体检测性能。|
|📝 更新|Object detection in adverse weather conditions for autonomous vehicles using Instruct Pix2Pix|自动驾驶车辆在恶劣天气条件下使用Instruct Pix2Pix进行目标检测|Unai Gurbindo, Axel Brando, Jaume Abella, Caroline König|<http://arxiv.org/pdf/2505.08228v2>|提出利用Instruct Pix2Pix模型生成恶劣天气数据集以增强自动驾驶对象检测模型的鲁棒性。|
|🆕 发布|Lightweight Temporal Transformer Decomposition for Federated Autonomous Driving|轻量级时间变换器分解用于联邦自动驾驶|Tuong Do, Binh X. Nguyen, Quang D. Tran, Erman Tjiputra, Te-Chuan Chiu, Anh Nguyen|<http://arxiv.org/pdf/2506.23523v1>|提出轻量级时序变换分解方法，通过拆分注意力图提升自动驾驶系统在复杂环境下的实时性能和鲁棒性。|
|🆕 发布|Artificial Intelligence-assisted Pixel-level Lung (APL) Scoring for Fast and Accurate Quantification in Ultra-short Echo-time MRI|基于人工智能辅助的像素级肺部（APL）评分系统，用于超短回波时间磁共振成像的快速准确量化|Bowen Xin, Rohan Hickey, Tamara Blake, Jin Jin, Claire E Wainwright, Thomas Benkert, Alto Stemmer, Peter Sly .etc.|<http://arxiv.org/pdf/2506.23506v1>|提出了一种基于人工智能的像素级肺评分方法，快速准确量化超短回波时间MRI中的肺结构损伤。|
|🆕 发布|AdFair-CLIP: Adversarial Fair Contrastive Language-Image Pre-training for Chest X-rays|对抗公平对比语言-图像预训练用于胸部X射线：AdFair-CLIP|Chenlang Yi, Zizhan Xiong, Qi Qi, Xiyuan Wei, Girish Bathla, Ching-Long Lin, Bobak Jack Mortazavi, Tianbao Yang|<http://arxiv.org/pdf/2506.23467v1>|提出AdFair-CLIP框架，通过对抗性干预减少敏感属性影响，提升医学图像分类的公平性和准确性。|
|🆕 发布|Contrastive Learning with Diffusion Features for Weakly Supervised Medical Image Segmentation|对比学习结合扩散特征用于弱监督医学图像分割|Dewen Zeng, Xinrong Hu, Yu-Jen Chen, Yawen Wu, Xiaowei Xu, Yiyu Shi|<http://arxiv.org/pdf/2506.23460v1>|提出了一种基于对比学习和扩散特征的弱监督医学图像分割方法，有效解决了传统方法在对象边界定位上的不足。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Controllable Reference-Based Real-World Remote Sensing Image Super-Resolution with Generative Diffusion Priors|基于可控参考的生成扩散先验实时遥感图像超分辨率重建|Ce Wang, Wanjie Sun|<http://arxiv.org/pdf/2506.23801v1>|提出了一种控制参考图像影响的生成扩散模型CRefDiff，有效解决了遥感图像超分辨率中的欠生成和过度...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Initialization-free Calibrated Bundle Adjustment|面向无需初始化的校准束调整方法|Carl Olsson, Amanda Nilsson|<http://arxiv.org/pdf/2506.23808v1>|引入相对旋转估计以利用相机校准信息，实现无需初始化的精确三维重建。|
|📝 更新|OrderChain: Towards General Instruct-Tuning for Stimulating the Ordinal Understanding Ability of MLLM|《OrderChain：面向通用指令微调以激发大规模语言模型序数理解能力》|Jinhong Wang, Shuo Tong, Jian liu, Dongqi Tang, Weiqiang Wang, Wentong Li, Hongxia Xu, Danny Chen .etc.|<http://arxiv.org/pdf/2504.04801v2>|提出OrderChain方法，通过特定与通用提示提升多模态大语言模型在序数回归任务上的性能。|
|🆕 发布|PriOr-Flow: Enhancing Primitive Panoramic Optical Flow with Orthogonal View|“PriOr-Flow：通过正交视角增强基本全景光流”|Longliang Liu, Miaojie Feng, Junda Cheng, Jijun Xiang, Xuan Zhu, Xin Yang|<http://arxiv.org/pdf/2506.23897v1>|[代码](https://github.com/longliangLiu/PriOr-Flow.); 提出双分支框架PriOr-Flow，利用正交视图减少球面投影失真，提升全景光流估计性能。|

