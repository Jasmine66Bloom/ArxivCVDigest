## [UPDATED!] **2025-07-01** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning|GLM-4.1V-Thinking：面向可扩展强化学习的多模态推理|GLM-V Team, :, Wenyi Hong, Wenmeng Yu, Xiaotao Gu, Guo Wang, Guobing Gan, Haomiao Tang .etc.|<http://arxiv.org/pdf/2507.01006v2>|[代码](https://github.com/THUDM/GLM-4.1V-Thinking.); 提出GLM-4.1V-Thinking模型，通过大规模预训练和强化学习提升多模态理解和推理能力。|
|🆕 发布|UAVD-Mamba: Deformable Token Fusion Vision Mamba for Multimodal UAV Detection|"UAVD-Mamba：用于多模态无人机检测的可变形Token融合视觉Mamba"|Wei Li, Jiaman Tang, Yang Li, Beihao Xia, Ligang Tan, Hongmao Qin|<http://arxiv.org/pdf/2507.00849v1>|[代码](https://github.com/GreatPlum-hnu/UAVD-Mamba.git.); 提出了一种基于Mamba架构的UAVD-Mamba框架，通过引入可变形Token融合多模态特征，提高...|
|🆕 发布|World4Drive: End-to-End Autonomous Driving via Intention-aware Physical Latent World Model|《World4Drive：通过意图感知的物理潜在世界模型实现端到端自动驾驶》|Yupeng Zheng, Pengxuan Yang, Zebin Xing, Qichao Zhang, Yuhang Zheng, Yinfeng Gao, Pengfei Li, Teng Zhang .etc.|<http://arxiv.org/pdf/2507.00603v1>|[代码](https://github.com/ucaszyp/World4Drive.); 提出了一种无需标注感知信息的端到端自动驾驶框架，通过视觉基础模型构建潜在世界模型，实现自监督规划和轨...|
|🆕 发布|Bisecle: Binding and Separation in Continual Learning for Video Language Understanding|"Bisecle: 绑定与分离在视频语言理解中的持续学习"|Yue Tan, Xiaoqian Hu, Hao Xue, Celso De Melo, Flora D. Salim|<http://arxiv.org/pdf/2507.00469v1>|提出Bisecle方法，通过模拟人脑的海马体机制，有效解决视频语言模型在持续学习中的遗忘和冲突问题。|
|📝 更新|Thinking with Images for Multimodal Reasoning: Foundations, Methods, and Future Frontiers|图像驱动多模态推理：基础、方法与未来前沿|Zhaochen Su, Peng Xia, Hangyu Guo, Zhenhua Liu, Yan Ma, Xiaoye Qu, Jiaqi Liu, Yanshu Li .etc.|<http://arxiv.org/pdf/2506.23918v2>|提出视觉推理新范式，将图像从静态输入转变为动态认知工作区，提升多模态AI的认知自主性。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Just Noticeable Difference for Large Multimodal Models|大尺寸多模态模型下的最小可觉差异|Zijian Chen, Yuan Tian, Yuze Sun, Wei Sun, Zicheng Zhang, Weisi Lin, Guangtao Zhai, Wenjun Zhang|<http://arxiv.org/pdf/2507.00490v2>|[代码](https://github.com/zijianchen98/LMM-JND.); 提出LMM-JND概念及量化方法，揭示了大型多模态模型在视觉感知任务中的盲点。|
|📝 更新|Beyond Diagnostic Performance: Revealing and Quantifying Ethical Risks in Pathology Foundation Models|超越诊断性能：揭示和量化病理基础模型中的伦理风险|Weiping Lin, Shen Liu, Runchen Zhu, Yixuan Lin, Baoshun Wang, Liansheng Wang|<http://arxiv.org/pdf/2502.16889v2>|首次定量分析病理基础模型中的伦理风险，并提出了系统评估框架。|
|📝 更新|Ovis-U1 Technical Report|Ovis-U1 技术报告|Guo-Hua Wang, Shanshan Zhao, Xinjie Zhang, Liangfu Cao, Pengxin Zhan, Lunhao Duan, Shiyin Lu, Minghao Fu .etc.|<http://arxiv.org/pdf/2506.23044v2>|介绍了Ovis-U1，一种融合多模态理解、文本到图像生成和图像编辑能力的30亿参数统一模型，实现性能...|
|📝 更新|ZonUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding|ZonUI-3B：一种用于跨分辨率GUI定位的轻量级视觉-语言模型|ZongHan Hsieh, Tzer-Jen Wei, ShengJing Yang|<http://arxiv.org/pdf/2506.23491v2>|[代码](https://github.com/Han1018/ZonUI-3B); 提出轻量级视觉语言模型ZonUI-3B，通过创新数据集和多阶段训练策略，有效提升跨分辨率GUI定位性...|
|🆕 发布|Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding|进化-0：具有隐式空间理解的视觉-语言-动作模型|Tao Lin, Gen Li, Yilei Zhong, Yanwen Zou, Bo Zhao|<http://arxiv.org/pdf/2507.00416v1>|引入插件式模块，将三维几何特征隐式融入视觉语言行动模型，增强空间理解能力。|
|🆕 发布|MedDiff-FT: Data-Efficient Diffusion Model Fine-tuning with Structural Guidance for Controllable Medical Image Synthesis|MedDiff-FT：基于结构引导的可控医学图像生成的高效数据微调扩散模型|Jianhao Xie, Ziang Zhang, Zhenyu Weng, Yuesheng Zhu, Guibo Luo|<http://arxiv.org/pdf/2507.00377v1>|[代码](https://github.com/JianhaoXie1/MedDiff-FT.); MedDiff-FT通过结构引导的少量数据微调扩散模型，实现了可控的医疗图像生成，提升了分割性能。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Escaping Platos Cave: JAM for Aligning Independently Trained Vision and Language Models|逃离柏拉图的洞穴：用于对齐独立训练的视觉和语言模型的JAM方法|Hyoseo, Yoon, Yisong Yue, Been Kim|<http://arxiv.org/pdf/2507.01201v1>|提出了一种多目标优化的Joint Autoencoder Modulator框架，有效促进独立训练的...|
|🆕 发布|Language-Unlocked ViT (LUViT): Empowering Self-Supervised Vision Transformers with LLMs|语言解锁的ViT（LUViT）：利用大型语言模型赋能自监督视觉变换器|Selim Kuzucu, Muhammad Ferjad Naeem, Anna Kukleva, Federico Tombari, Bernt Schiele|<http://arxiv.org/pdf/2507.00754v1>|提出了一种融合大型语言模型与视觉变压器的协同预训练策略，有效桥接了模态不匹配问题，提升了视觉任务性能...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ExPaMoE: An Expandable Parallel Mixture of Experts for Continual Test-Time Adaptation|扩展并行专家混合模型：用于持续测试时适应的方法|JianChao Zhao, Chenhao Ding, Songlin Dong, Yuhang He, Yihong Gong|<http://arxiv.org/pdf/2507.00502v2>|提出了一种可扩展并行专家混合框架ExPaMoE，通过分离领域通用与特定知识，有效应对连续测试时适应中...|
|📝 更新|Jenga Stacking Based on 6D Pose Estimation for Architectural Form Finding Process|基于6D位姿估计的积木堆叠在建筑形态探索过程中的应用|Zixun Huang|<http://arxiv.org/pdf/2311.10918v2>|将6D姿态估计与建筑风环境评估结合，为建筑形态设计提供了创新方法。|
|📝 更新|Multi-person Physics-based Pose Estimation for Combat Sports|多人基于物理的姿势估计在格斗运动中的应用|Hossein Feiz, David Labbé, Thomas Romeas, Jocelyn Faubert, Sheldon Andrews|<http://arxiv.org/pdf/2504.08175v2>|提出了一种用于格斗体育中高精度3D人体姿态估计的多视角稀疏摄像头框架，结合了基于变换器的2D姿态跟踪...|
|📝 更新|Depth Matters: Exploring Deep Interactions of RGB-D for Semantic Segmentation in Traffic Scenes|深度至关重要：探索RGB-D在交通场景语义分割中的深度交互|Siyu Chen, Ting Han, Changshe Zhang, Weiquan Liu, Jinhe Su, Zongyue Wang, Guorong Cai|<http://arxiv.org/pdf/2409.07995v2>|提出深度感知优化和线性交叉注意力机制，有效融合RGB-D数据提升交通场景语义分割准确率。|
|🆕 发布|Research on Improving the High Precision and Lightweight Diabetic Retinopathy Detection of YOLOv8n|研究基于YOLOv8n提高糖尿病视网膜病变检测的高精度与轻量化|Fei Yuhuan, Sun Xufei, Zang Ran, Wang Gengchen, Su Meng, Liu Fenghao|<http://arxiv.org/pdf/2507.00780v1>|提出了一种改进的YOLOv8n模型YOLO-KFG，通过增强微病变感知能力和轻量化设计，提高了糖尿病...|
|🆕 发布|Towards Open-World Human Action Segmentation Using Graph Convolutional Networks|面向开放世界人体动作分割的图卷积网络方法|Hao Xing, Kai Zhe Boey, Gordon Cheng|<http://arxiv.org/pdf/2507.00756v1>|提出了一种基于图卷积网络的框架，用于在开放世界中检测和分割未见过的动作，无需手动标注。|
|🆕 发布|Multi-Modal Graph Convolutional Network with Sinusoidal Encoding for Robust Human Action Segmentation|用于稳健人体动作分割的带有正弦编码的多模态图卷积网络|Hao Xing, Kai Zhe Boey, Yuankai Wu, Darius Burschka, Gordon Cheng|<http://arxiv.org/pdf/2507.00752v1>|提出了一种多模态图卷积网络，通过正弦编码和模态融合策略，有效提升了人体动作分割的准确性和连贯性。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Rapid Salient Object Detection with Difference Convolutional Neural Networks|利用差分卷积神经网络实现的快速显著目标检测|Zhuo Su, Li Liu, Matthias Müller, Jiehua Zhang, Diana Wofk, Ming-Ming Cheng, Matti Pietikäinen|<http://arxiv.org/pdf/2507.01182v1>|[代码](https://github.com/hellozhuo/stdnet.git.); 提出了一种结合传统对比线索和现代卷积神经网络的快速显著目标检测方法，大幅提升了资源受限设备上的实时性...|
|🆕 发布|Deep learning-based segmentation of T1 and T2 cardiac MRI maps for automated disease detection|基于深度学习的T1和T2心脏磁共振成像分割方法用于自动化疾病检测|Andreea Bianca Popescu, Andreas Seitz, Heiko Mahrholdt, Jens Wetzl, Athira Jacob, Lucian Mihai Itu, Constantin Suciu, Teodora Chitiboi|<http://arxiv.org/pdf/2507.00903v1>|利用深度学习实现心脏MRI映射的高精度分割，结合多特征机器学习提升疾病检测准确性。|
|🆕 发布|GaussianVLM: Scene-centric 3D Vision-Language Models using Language-aligned Gaussian Splats for Embodied Reasoning and Beyond|高斯VLM：基于语言对齐高斯散点的场景中心3D视觉语言模型，用于具身推理等应用|Anna-Maria Halacheva, Jan-Nico Zaech, Xi Wang, Danda Pani Paudel, Luc Van Gool|<http://arxiv.org/pdf/2507.00886v1>|提出了一种基于3D高斯分布的场景中心视觉语言模型，通过语言关联实现早期模态对齐，显著提升了跨领域场景...|
|📝 更新|UAV-DETR: Efficient End-to-End Object Detection for Unmanned Aerial Vehicle Imagery|无人机影像的高效端到端目标检测：UAV-DETR|Huaxiang Zhang, Kai Liu, Zhongxue Gan, Guo-Niu Zhu|<http://arxiv.org/pdf/2501.01855v3>|[代码](https://github.com/ValiantDiligent/UAV-DETR); 提出了一种针对无人机影像的端到端检测框架UAV-DETR，通过多尺度特征融合和频率增强显著提升检测性...|
|🆕 发布|Robust Component Detection for Flexible Manufacturing: A Deep Learning Approach to Tray-Free Object Recognition under Variable Lighting|《面向柔性制造的鲁棒组件检测：一种基于深度学习的无托盘物体识别方法应对多变的照明条件》|Fatemeh Sadat Daneshmand|<http://arxiv.org/pdf/2507.00852v1>|提出了一种基于Mask R-CNN的视觉系统，实现了无托盘放置的零件检测，增强了工业机器人对极端光照...|
|🆕 发布|UPRE: Zero-Shot Domain Adaptation for Object Detection via Unified Prompt and Representation Enhancement|UPRE：通过统一提示和表征增强实现目标检测的零样本域自适应|Xiao Zhang, Fei Wei, Yong Wang, Wenda Zhao, Feiyi Li, Xiangxiang Chu|<http://arxiv.org/pdf/2507.00721v1>|[代码](https://github.com/AMAP-ML/UPRE.); 提出了一种统一提示和表征增强的框架，有效解决了零样本域自适应物体检测中的挑战。|
|📝 更新|CoCMT: Communication-Efficient Cross-Modal Transformer for Collaborative Perception|协同感知中通信高效的多模态Transformer：CoCMT|Rujia Wang, Xiangbo Gao, Hao Xiang, Runsheng Xu, Zhengzhong Tu|<http://arxiv.org/pdf/2503.13504v2>|提出CoCMT框架，通过选择性提取关键特征显著降低多代理协同感知的通信需求。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Rectifying Magnitude Neglect in Linear Attention|线性注意力中纠正幅度忽视|Qihang Fan, Huaibo Huang, Yuang Ai, ran He|<http://arxiv.org/pdf/2507.00698v1>|[代码](https://github.com/qhfan/MALA); 提出方法解决线性注意力忽视查询向量大小问题，提出 Magnitude-Aware Linear At...|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UniGlyph: Unified Segmentation-Conditioned Diffusion for Precise Visual Text Synthesis|统一字形：基于分割条件的扩散模型用于精确视觉文本生成|Yuanrui Wang, Cong Han, Yafei Li, Zhipeng Jin, Xiawei Li, SiNan Du, Wen Tao, Yi Yang .etc.|<http://arxiv.org/pdf/2507.00992v2>|提出了一种基于视觉文本掩膜的统一框架，通过精确提取和条件扩散显著提升了文本图像生成质量和风格保持。|
|📝 更新|Defensive Adversarial CAPTCHA: A Semantics-Driven Framework for Natural Adversarial Example Generation|防御性对抗验证码：一种基于语义驱动的自然对抗样本生成框架|Xia Du, Xiaoyuan Liu, Jizhe Zhou, Zheng Lin, Chi-man Pun, Cong Wu, Tao Li, Zhe Chen .etc.|<http://arxiv.org/pdf/2506.10685v3>|提出了一种生成高质量防御性对抗样本的框架，通过语义信息指导，有效增强了CAPTCHA的多样性和安全性...|
|🆕 发布|DAM-VSR: Disentanglement of Appearance and Motion for Video Super-Resolution|《DAM-VSR：视频超分辨率中外观与运动的解耦》|Zhe Kong, Le Li, Yong Zhang, Feng Gao, Shaoshu Yang, Tao Wang, Kaihao Zhang, Zhuoliang Kang .etc.|<http://arxiv.org/pdf/2507.01012v1>|提出DAM-VSR框架，通过分离视频超分辨率中的外观增强和运动控制问题，实现更精细的细节生成和时序一...|
|🆕 发布|Robotic Manipulation by Imitating Generated Videos Without Physical Demonstrations|无需物理演示的机器人操作：通过模仿生成视频进行操纵|Shivansh Patel, Shraddhaa Mohan, Hanlin Mai, Unnat Jain, Svetlana Lazebnik, Yunzhu Li|<http://arxiv.org/pdf/2507.00990v1>|提出了一种让机器人通过模仿AI生成的视频学习复杂操作任务的方法，无需物理示范或特定训练。|
|📝 更新|Prompt-Guided Latent Diffusion with Predictive Class Conditioning for 3D Prostate MRI Generation|基于预测性类别条件引导的潜在扩散模型用于三维前列腺MRI生成|Emerson P. Grabke, Masoom A. Haider, Babak Taati|<http://arxiv.org/pdf/2506.10230v2>|[代码](https://github.com/grabkeem/CCELLA); 提出了一种结合临床报告和分类信息的双头条件模型CCELLA，用于少量数据下的高质量3D前列腺MRI生...|
|🆕 发布|ONLY: One-Layer Intervention Sufficiently Mitigates Hallucinations in Large Vision-Language Models|仅一层干预足以减轻大型视觉-语言模型中的幻觉现象|Zifu Wan, Ce Zhang, Silong Yong, Martin Q. Ma, Simon Stepputtis, Louis-Philippe Morency, Deva Ramanan, Katia Sycara .etc.|<http://arxiv.org/pdf/2507.00898v1>|[代码](https://github.com/zifuwan/ONLY.); 提出了一种单层干预的解码方法ONLY，有效减少大型视觉语言模型中的幻觉现象，实现实时高效部署。|
|📝 更新|SurgTPGS: Semantic 3D Surgical Scene Understanding with Text Promptable Gaussian Splatting|手术场景语义三维理解：基于文本提示的高斯散点模型|Yiming Huang, Long Bai, Beilei Cui, Kun Yuan, Guankun Wang, Mobarak I. Hoque, Nicolas Padoy, Nassir Navab .etc.|<http://arxiv.org/pdf/2506.23309v2>|[代码](https://github.com/lastbasket/SurgTPGS.); 提出SurgTPGS方法，通过文本提示实现实时三维手术场景理解和重建，提升手术精度与安全性。|
|🆕 发布|Real-Time Inverse Kinematics for Generating Multi-Constrained Movements of Virtual Human Characters|虚拟人类角色的多约束运动实时逆运动学生成|Hendric Voss, Stefan Kopp|<http://arxiv.org/pdf/2507.00792v1>|[代码](https://github.com/hvoss-techfak/TF-JAX-IK); 提出了一种基于TensorFlow自动微分和即时编译的实时逆运动学求解器，有效应对多约束下虚拟人运动...|
|📝 更新|Edit Transfer: Learning Image Editing via Vision In-Context Relations|编辑迁移：通过视觉上下文关系学习图像编辑|Lan Chen, Qi Mao, Yuchao Gu, Mike Zheng Shou|<http://arxiv.org/pdf/2503.13327v2>|提出Edit Transfer方法，通过单对源目标示例学习转换并应用于新图像，解决了文本和外观中心方...|
|📝 更新|T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT|T2I-R1：通过协同语义级和标记级CoT强化图像生成|Dongzhi Jiang, Ziyu Guo, Renrui Zhang, Zhuofan Zong, Hao Li, Le Zhuo, Shilin Yan, Pheng-Ann Heng .etc.|<http://arxiv.org/pdf/2505.00703v2>|[代码](https://github.com/CaraJ7/T2I-R1); 引入双层面链式思维推理，T2I-R1模型通过强化学习显著提升文本到图像生成的性能。|
|🆕 发布|A Unified Transformer-Based Framework with Pretraining For Whole Body Grasping Motion Generation|用于全身抓握运动生成的统一预训练Transformer框架|Edward Effendy, Kuan-Wei Tseng, Rei Kawakami|<http://arxiv.org/pdf/2507.00676v1>|提出了一种基于统一Transformer的框架，通过预训练生成稳定且真实的全身抓取动作。|
|📝 更新|Dehazing Light Microscopy Images with Guided Conditional Flow Matching: finding a sweet spot between fidelity and realism|利用引导条件流匹配去雾化光学显微镜图像：在保真度与真实感之间寻找最佳平衡点|Anirban Ray, Ashesh, Florian Jug|<http://arxiv.org/pdf/2506.22397v3>|提出了一种平衡清晰度和真实感的去雾方法HazeMatching，适用于低成本显微镜图像。|
|🆕 发布|ARIG: Autoregressive Interactive Head Generation for Real-time Conversations|ARIG：用于实时对话的自回归交互式头部生成|Ying Guo, Xi Liu, Cheng Zhen, Pengfei Yan, Xiaoming Wei|<http://arxiv.org/pdf/2507.00472v1>|提出了一种基于自回归框架的实时交互式人头生成方法，提升了交互真实感和实时性。|
|📝 更新|Contrastive Conditional Latent Diffusion for Audio-visual Segmentation|对比条件潜在扩散用于音频视觉分割|Yuxin Mao, Jing Zhang, Mochu Xiang, Yunqiu Lv, Dong Li, Yiran Zhong, Yuchao Dai|<http://arxiv.org/pdf/2307.16579v2>|[代码](https://github.com/OpenNLPLab/DiffusionAVS.); 提出了一种基于对比学习的条件潜在扩散模型，通过优化密度比增强音频在音频视觉分割中的贡献。|
|🆕 发布|Learning Dense Feature Matching via Lifting Single 2D Image to 3D Space|通过将单个2D图像提升到3D空间学习密集特征匹配|Yingping Liang, Yutao Hu, Wenqi Shao, Ying Fu|<http://arxiv.org/pdf/2507.00392v1>|提出两阶段 Lift to Match (L2M) 框架，将单视角2D图像提升至3D空间进行特征匹配...|
|📝 更新|Da Yu: Towards USV-Based Image Captioning for Waterway Surveillance and Scene Understanding|面向水道监控与场景理解的无人船基图像标注方法研究|Runwei Guan, Ningwei Ouyang, Tianhao Xu, Shaofeng Liang, Wei Dai, Yafeng Sun, Shang Gao, Songning Lai .etc.|<http://arxiv.org/pdf/2506.19288v2>|提出WaterCaption数据集及Da Yu模型，通过图像captioning实现水面环境全局语义...|
|🆕 发布|Populate-A-Scene: Affordance-Aware Human Video Generation|“ Populate-A-Scene：面向 affordance 意识的人类视频生成”|Mengyi Shan, Zecheng He, Haoyu Ma, Felix Juefei-Xu, Peizhao Zhang, Tingbo Hou, Ching-Yao Chuang|<http://arxiv.org/pdf/2507.00334v1>|提出了一种利用文本提示在场景图像中生成与场景相协调的人类行为视频的方法。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Evolutionary Caching to Accelerate Your Off-the-Shelf Diffusion Model|《利用进化缓存加速您的现成扩散模型》|Anirud Aggarwal, Abhinav Shrivastava, Matthew Gwilliam|<http://arxiv.org/pdf/2506.15682v2>|[代码](https://github.com/aniaggarwal/ecad.); 提出了一种进化缓存策略ECAD，通过遗传算法优化扩散模型推理速度与质量，实现高效自适应加速。|
|📝 更新|ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features|概念注意力：扩散变换器学习高度可解释的特征|Alec Helbling, Tuna Han Salih Meral, Ben Hoover, Pinar Yanardag, Duen Horng Chau|<http://arxiv.org/pdf/2502.04320v2>|提出ConceptAttention方法，利用DiT注意力层生成高质量 saliency maps，...|
|🆕 发布|DMCIE: Diffusion Model with Concatenation of Inputs and Errors to Improve the Accuracy of the Segmentation of Brain Tumors in MRI Images|DMCIE：输入与误差连接的扩散模型，以提高MRI图像中脑肿瘤分割的准确性|Sara Yavari, Rahul Nitin Pandya, Jacob Furst|<http://arxiv.org/pdf/2507.00983v1>|提出了一种基于误差引导的DMCIE框架，通过结合原始MRI图像和误差图，显著提升了脑肿瘤分割的准确性...|
|📝 更新|Bridging SFT and DPO for Diffusion Model Alignment with Self-Sampling Preference Optimization|将SFT和DPO相结合用于扩散模型对齐的自采样偏好优化|Daoan Zhang, Guangchen Lan, Dong-Jun Han, Wenlin Yao, Xiaoman Pan, Hongming Zhang, Mingxiao Li, Pengcheng Chen .etc.|<http://arxiv.org/pdf/2410.05255v2>|提出了一种融合SFT和DPO优势的SSPO方法，通过自我采样优化提高了扩散模型的泛化能力和训练稳定性...|
|🆕 发布|OptiPrune: Boosting Prompt-Image Consistency with Attention-Guided Noise and Dynamic Token Selection|《OptiPrune：通过注意力引导的噪声和动态标记选择增强提示-图像一致性》|Ziji Lu|<http://arxiv.org/pdf/2507.00789v1>|提出OptiPrune框架，通过注意力引导的噪声优化和动态令牌选择，同时提升文本-图像生成模型的语义...|
|🆕 发布|LD-RPS: Zero-Shot Unified Image Restoration via Latent Diffusion Recurrent Posterior Sampling|LD-RPS：基于潜在扩散递归后验采样的零样本统一图像恢复|Huaqiu Li, Yong Wang, Tongwen Huang, Hailang Huang, Haoqian Wang, Xiangxiang Chu|<http://arxiv.org/pdf/2507.00790v1>|[代码](https://github.com/AMAP-ML/LD-RPS.); 提出了一种无需数据集、基于潜在扩散模型和后验采样的统一图像复原方法，有效克服了泛化性和闭集约束问题。|
|📝 更新|Listener-Rewarded Thinking in VLMs for Image Preferences|用于图像偏好选择的视觉语言模型中的听众奖励式思考|Alexander Gambashidze, Li Pengyi, Matvey Skripkin, Andrey Galichin, Anton Gusarov, Konstantin Sobolev, Andrey Kuznetsov, Ivan Oseledets|<http://arxiv.org/pdf/2506.22832v2>|引入 listener-augmented 强化学习框架，通过独立模型评估提高视觉语言模型对人类偏好...|
|🆕 发布|Prompt2SegCXR:Prompt to Segment All Organs and Diseases in Chest X-rays|Prompt2SegCXR：提示驱动的胸部X射线全器官与疾病分割|Abduz Zami, Shadman Sobhan, Rounaq Hossain, Md. Sawran Sorker, Mohiuddin Ahmed, Md. Redwan Hossain|<http://arxiv.org/pdf/2507.00673v1>|提出了一种基于提示的轻量级模型 Prompt2SegCXR，实现了胸部 X 光片中多器官和疾病的精准...|
|🆕 发布|Diffusion Classifier Guidance for Non-robust Classifiers|非鲁棒分类器的扩散分类器引导|Philipp Vaeth, Dibyanshu Kumar, Benjamin Paassen, Magda Gregorová|<http://arxiv.org/pdf/2507.00687v1>|扩展了分类器引导技术，使其适用于未经噪声训练的非鲁棒分类器，并通过稳定化技术提高了引导稳定性。|
|🆕 发布|Mind the Detail: Uncovering Clinically Relevant Image Details in Accelerated MRI with Semantically Diverse Reconstructions|关注细节：在加速MRI中通过语义多样化的重建揭示临床相关图像细节|Jan Nikolas Morshuis, Christian Schlarmann, Thomas Küstner, Christian F. Baumgartner, Matthias Hein|<http://arxiv.org/pdf/2507.00670v1>|[代码](https://github.com/NikolasMorshuis/SDR); 提出了一种增强语义多样性的重建方法，显著降低了假阴性诊断的风险并提高了诊断的准确性。|
|📝 更新|Identity Preserving 3D Head Stylization with Multiview Score Distillation|保持身份的3D头像风格化与多视角评分蒸馏|Bahri Batuhan Bilecen, Ahmet Berke Gokmen, Furkan Guzelant, Aysegul Dundar|<http://arxiv.org/pdf/2411.13536v2>|[代码](https://three-bee.github.io/head_stylization); 提出了一种多视角评分蒸馏框架，有效提升了3D头像风格化中身份特征的保持和图像质量。|
|🆕 发布|ADAptation: Reconstruction-based Unsupervised Active Learning for Breast Ultrasound Diagnosis|自适应：基于重建的无监督主动学习在乳腺超声诊断中的应用|Yaofei Duan, Yuhao Huang, Xin Yang, Luyi Han, Xinyu Xie, Zhiyuan Zhu, Ping He, Ka-Hou Chan .etc.|<http://arxiv.org/pdf/2507.00474v1>|[代码](https://github.com/miccai25-966/ADAptation.); 提出了一种用于乳腺超声诊断的域自适应无监督主动学习方法，通过高效选择信息样本，有效应对训练与测试域分...|
|🆕 发布|DiGA3D: Coarse-to-Fine Diffusional Propagation of Geometry and Appearance for Versatile 3D Inpainting|DiGA3D：用于多样化三维修复的粗到细几何与外观扩散传播|Jingyi Pan, Dan Xu, Qiong Luo|<http://arxiv.org/pdf/2507.00429v1>|[代码](https://rorisis.github.io/DiGA3D); 提出了一种基于扩散模型的粗到细3D修复流程，实现了多视角下几何与外观的一致性传播。|
|🆕 发布|Efficient Depth- and Spatially-Varying Image Simulation for Defocus Deblur|高效深度和空间变化的图像模拟用于去模糊处理|Xinge Yang, Chuong Nguyen, Wenbin Wang, Kaizhang Kang, Wolfgang Heidrich, Xiaoxing Li|<http://arxiv.org/pdf/2507.00372v1>|提出了一种高效的数据集合成方法，模拟深度依赖的散焦和空间变化的光学像差，有效解决了相机深度场浅导致的...|
|🆕 发布|PlantSegNeRF: A few-shot, cross-dataset method for plant 3D instance point cloud reconstruction via joint-channel NeRF with multi-view image instance matching|植物SegNeRF：一种基于联合通道NeRF与多视角图像实例匹配的少样本、跨数据集植物三维实例点云重建方法|Xin Yang, Ruiming Du, Hanyang Huang, Jiayang Xie, Pengyao Xie, Leisen Fang, Ziyue Guo, Nanjun Jiang .etc.|<http://arxiv.org/pdf/2507.00371v1>|提出了一种PlantSegNeRF方法，通过多视角图像匹配和神经辐射场，实现了植物器官的高精度3D点...|
|📝 更新|Lifelong Learning of Video Diffusion Models From a Single Video Stream|《从单一视频流中终身学习视频扩散模型》|Jason Yoo, Yingchen He, Saeid Naderiparizi, Dylan Green, Gido M. van de Ven, Geoff Pleiss, Frank Wood|<http://arxiv.org/pdf/2406.04814v3>|提出了一种从单一视频流中训练自回归视频扩散模型的方法，实现了与标准离线训练相当的效果。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|BusterX: MLLM-Powered AI-Generated Video Forgery Detection and Explanation|BusterX：基于MLLM的AI生成视频伪造检测与解释|Haiquan Wen, Yiwei He, Zhenglin Huang, Tianxiao Li, Zihan Yu, Xingru Huang, Lu Qi, Baoyuan Wu .etc.|<http://arxiv.org/pdf/2505.12620v3>|提出首个大规模高质量AI生成视频数据集GenBuster-200K，并开发BusterX框架，融合多...|
|📝 更新|Towards Generalized and Training-Free Text-Guided Semantic Manipulation|面向通用化和无需训练的文本引导语义操作|Yu Hong, Xiao Cai, Pengpeng Zeng, Shuai Zhang, Jingkuan Song, Lianli Gao, Heng Tao Shen|<http://arxiv.org/pdf/2504.17269v2>|提出了一种无需训练的通用文本引导语义操作方法，支持多种语义编辑并适用于不同模态。|
|🆕 发布|AI-Generated Video Detection via Perceptual Straightening|通过感知矫正的AI生成视频检测|Christian Internò, Robert Geirhos, Markus Olhofer, Sunny Liu, Barbara Hammer, David Klindt|<http://arxiv.org/pdf/2507.00583v1>|提出了一种基于神经表征几何的AI生成视频检测方法，有效区分真实与AI生成视频，实现领先性能。|
|📝 更新|ICME 2025 Grand Challenge on Video Super-Resolution for Video Conferencing|2025年国际多媒体与 Expo 大会视频会议超分辨率挑战赛|Babak Naderi, Ross Cutler, Juhee Cho, Nabakumar Khongbantabam, Dejan Ivkovic|<http://arxiv.org/pdf/2506.12269v2>|提出视频会议中超分辨率挑战，通过因果模型提升低分辨率视频的感知质量。|
|🆕 发布|MuteSwap: Silent Face-based Voice Conversion|静默换声：基于人脸的静音语音转换|Yifan Liu, Yu Fang, Zhouhan Lin|<http://arxiv.org/pdf/2507.00498v1>|提出了一种基于视觉输入的静音人脸声音转换方法MuteSwap，实现了无需音频输入即可转换说话者身份。|
|📝 更新|VideoCogQA: A Controllable Benchmark for Evaluating Cognitive Abilities in Video-Language Models|视频认知问答：一个用于评估视频-语言模型认知能力的可控基准|Chenglin Li, Qianglong Chen, Zhi Li, Feng Tao, Yin Zhang|<http://arxiv.org/pdf/2411.09105v2>|提出VideoCogQA，一个可控制的游戏世界环境基准，评估大型视频语言模型的认知能力。|
|📝 更新|Grounding Creativity in Physics: A Brief Survey of Physical Priors in AIGC|将创造力植根于物理学：人工智能生成内容中物理先验的简要综述|Siwei Meng, Yawei Luo, Ping Liu|<http://arxiv.org/pdf/2502.07007v3>|综述了将物理先验融入生成模型的方法，以增强3D和4D内容生成的结构完整性和运动真实性。|
|🆕 发布|Training for X-Ray Vision: Amodal Segmentation, Amodal Content Completion, and View-Invariant Object Representation from Multi-Camera Video|训练X射线视觉：从多摄像头视频中进行模态分割、模态内容补全及视图不变对象表征|Alexander Moore, Amar Saini, Kylie Cancilla, Doug Poland, Carmen Carrano|<http://arxiv.org/pdf/2507.00339v1>|提出MOVi-MC-AC数据集，利用多摄像头视角和重建任务提升物体遮挡处理能力。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|cp_measure: API-first feature extraction for image-based profiling workflows|cp_measure：面向图像分析工作流的API优先特征提取方法|Alán F. Muñoz, Tim Treis, Alexandr A. Kalinin, Shatavisha Dasgupta, Fabian Theis, Anne E. Carpenter, Shantanu Singh|<http://arxiv.org/pdf/2507.01163v1>|提出了一种模块化、API优先的图像特征提取工具cp_measure，简化了自动化和可重复的生物图像分...|
|🆕 发布|Geometry-aware 4D Video Generation for Robot Manipulation|面向机器人操作的几何感知4D视频生成|Zeyi Liu, Shuang Li, Eric Cousineau, Siyuan Feng, Benjamin Burchfiel, Shuran Song|<http://arxiv.org/pdf/2507.01099v1>|提出了一种4D视频生成模型，通过跨视图点图对齐训练实现几何一致性，增强了机器人操作中的预测和规划能力...|
|🆕 发布|VQ-VLA: Improving Vision-Language-Action Models via Scaling Vector-Quantized Action Tokenizers|VQ-VLA：通过扩展向量量化动作标记器来改进视觉-语言-动作模型|Yating Wang, Haoyi Zhu, Mingyu Liu, Jiange Yang, Hao-Shu Fang, Tong He|<http://arxiv.org/pdf/2507.01016v1>|[代码](https://xiaoxiao0406.github.io/vqvla.github.io); 提出了一种基于大规模动作轨迹数据集的向量量化动作标记器，实现了更平滑、连贯的动作输出并提高了多种任务...|
|📝 更新|The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering|《标记的隐秘生活：通过视觉信息引导减少大型视觉-语言模型的幻觉现象》|Zhuowei Li, Haizhou Shi, Yunhe Gao, Di Liu, Zhenting Wang, Yuxiao Chen, Ting Liu, Long Zhao .etc.|<http://arxiv.org/pdf/2502.03628v2>|[代码](https://github.com/LzVv123456/VISTA.); 提出方法VISTA，减少大型视觉语言模型生成过程中的虚构内容，增强真实信息表达。|
|🆕 发布|CAVALRY-V: A Large-Scale Generator Framework for Adversarial Attacks on Video MLLMs|CAVALRY-V：面向视频多模态语言模型的大规模生成对抗攻击框架|Jiaming Zhang, Rui Hu, Qing Guo, Wei Yang Bryan Lim|<http://arxiv.org/pdf/2507.00817v1>|提出了一种针对视频多模态大语言模型的对抗攻击框架，通过双目标语义-视觉损失函数和两阶段生成器结构，有...|
|📝 更新|Maximum Dispersion, Maximum Concentration: Enhancing the Quality of MOP Solutions|最大分散性，最大集中性：提升多目标优化解的质量|Gladston Moreira, Ivan Meneghini, Elizabeth Wanner|<http://arxiv.org/pdf/2506.22568v2>|提出了一种优化多目标问题解质量的方法，通过决策空间的均匀性度量增强解的分散性，同时在目标空间特定区域...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Active Scout: Multi-Target Tracking Using Neural Radiance Fields in Dense Urban Environments|"主动侦查者：在密集城市环境中使用神经辐射场进行多目标跟踪"|Christopher D. Hsu, Pratik Chaudhari|<http://arxiv.org/pdf/2406.07431v3>|[代码](https://github.com/grasp-lyrl/ActiveScout.); 提出了一种利用神经辐射场在线构建城市三维模型，实现动态目标主动追踪的方法。|
|🆕 发布|Surgical Neural Radiance Fields from One Image|单张图像驱动的手术神经辐射场|Alberto Neri, Maximilan Fehrentz, Veronica Penza, Leonardo S. Mattos, Nazim Haouchine|<http://arxiv.org/pdf/2507.00969v1>|利用单张手术图像和术前数据高效训练神经辐射场，实现手术场景的3D重建与视图合成。|
|🆕 发布|FreNBRDF: A Frequency-Rectified Neural Material Representation|频率矫正的神经材料表示方法：FreNBRDF|Chenliang Zhou, Zheyuan Hu, Cengiz Oztireli|<http://arxiv.org/pdf/2507.00476v1>|引入FreNBRDF，一种结合频率域分析的神经网络材料表示法，提升材料外观重建和编辑的准确性与鲁棒性...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RaGNNarok: A Light-Weight Graph Neural Network for Enhancing Radar Point Clouds on Unmanned Ground Vehicles|“RaGNNarok：一种用于无人机载雷达点云增强的轻量级图神经网络”|David Hunt, Shaocheng Luo, Spencer Hallyburton, Shafii Nillongo, Yi Li, Tingjun Chen, Miroslav Pajic|<http://arxiv.org/pdf/2507.00937v1>|提出了一种轻量级图神经网络框架RaGNNarok，有效增强雷达点云，提升低成本室内移动机器人定位与导...|
|🆕 发布|UMDATrack: Unified Multi-Domain Adaptive Tracking Under Adverse Weather Conditions|UMDATrack：统一多域自适应跟踪算法在恶劣天气条件下的应用|Siyuan Yao, Rui Zhu, Ziqi Wang, Wenqi Ren, Yanyang Yan, Xiaochun Cao|<http://arxiv.org/pdf/2507.00648v1>|[代码](https://github.com/Z-Z188/UMDATrack.); 提出UMDATrack，通过统一域自适应框架在恶劣天气条件下保持高质量目标预测。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SafeMap: Robust HD Map Construction from Incomplete Observations|安全映射：从不完整观测中构建鲁棒高清地图|Xiaoshuai Hao, Lingdong Kong, Rong Yin, Pengwei Wang, Jing Zhang, Yunfeng Diao, Shu Zhao|<http://arxiv.org/pdf/2507.00861v1>|提出SafeMap框架，通过优先处理关键视角和全景校正，实现了在不完整观测下的高精度HD地图构建。|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|2HandedAfforder: Learning Precise Actionable Bimanual Affordances from Human Videos|双手协同效应：从人类视频中学习精确的可操作双臂协同效应|Marvin Heidinger, Snehal Jauhri, Vignesh Prasad, Georgia Chalvatzaki|<http://arxiv.org/pdf/2503.09320v3>|提出了一种从人类活动视频中提取双臂协同操作可用性区域的数据框架，并训练出性能卓越的预测模型。|
|📝 更新|Towards Markerless Intraoperative Tracking of Deformable Spine Tissue|面向无标记术中可变形脊椎组织的跟踪|Connor Daly, Elettra Marconi, Marco Riva, Jinendra Ekanayake, Daniel S. Elson, Ferdinando Rodriguez y Baena|<http://arxiv.org/pdf/2506.23657v2>|首次提出用于脊柱手术的临床RGB-D数据集，并开发SpineAlign系统捕捉术前术后脊柱变形。|
|🆕 发布|Stable Tracking of Eye Gaze Direction During Ophthalmic Surgery|眼科手术中眼 gaze 方向的稳定追踪|Tinghe Hong, Shenlin Cai, Boyang Li, Kai Huang|<http://arxiv.org/pdf/2507.00635v1>|提出了一种结合机器学习和传统算法的眼睛定位与追踪方法，无需地标点，实现了稳定的眼部定位和注视方向估计...|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MVP: Winning Solution to SMP Challenge 2025 Video Track|MVP：SMP挑战2025视频赛道获胜解决方案|Liliang Ye, Yunyao Zhang, Yafeng Wu, Yi-Ping Phoebe Chen, Junqing Yu, Wei Yang, Zikai Song|<http://arxiv.org/pdf/2507.00950v1>|提出了一种融合视频特征、用户信息和上下文数据的预测模型，有效预测社交媒体视频的流行度。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Zero-shot Skeleton-based Action Recognition with Prototype-guided Feature Alignment|基于原型引导特征对齐的零样本骨架动作识别|Kai Zhou, Shuhai Zhang, Zeng You, Jinwu Hu, Mingkui Tan, Fei Liu|<http://arxiv.org/pdf/2507.00566v1>|提出了一种原型引导的特征对齐范式，通过端到端跨模态对比训练和文本特征对齐策略，提高了零样本骨骼基动作...|
|📝 更新|FreqDGT: Frequency-Adaptive Dynamic Graph Networks with Transformer for Cross-subject EEG Emotion Recognition|FreqDGT：基于变换器的频率自适应动态图网络用于跨被试 EEG 情绪识别|Yueyang Li, Shengyu Gong, Weiming Zeng, Nizhuan Wang, Wai Ting Siok|<http://arxiv.org/pdf/2506.22807v2>|[代码](https://github.com/NZWANG/FreqDGT.); 提出FreqDGT模型，通过频率自适应和时空动态学习显著提升跨个体 EEG 情感识别准确性。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 跨模态一致性学习 (Cross-modal Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MTCNet: Motion and Topology Consistency Guided Learning for Mitral Valve Segmentationin 4D Ultrasound|MTCNet：基于运动和拓扑一致性引导的4D超声二尖瓣分割学习|Rusi Chen, Yuanting Yang, Jiezhi Yao, Hongning Song, Ji Zhang, Yongsong Zhou, Yuhao Huang, Ronghao Yang .etc.|<http://arxiv.org/pdf/2507.00660v1>|[代码](https://github.com/crs524/MTCNet.); 提出MTCNet，通过运动和拓扑一致性引导学习，实现了4D超声心动图中的二尖瓣半监督精准分割。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Customizable ROI-Based Deep Image Compression|基于自定义感兴趣区域的深度图像压缩|Jian Jin, Fanxin Xia, Feng Ding, Xinfeng Zhang, Meiqin Liu, Yao Zhao, Weisi Lin, Lili Meng|<http://arxiv.org/pdf/2507.00373v2>|提出了一种可定制区域优先的深度图像压缩框架，通过文本控制、自定义价值分配和潜伏空间注意力优化，实现了...|
|📝 更新|GratNet: A Photorealistic Neural Shader for Diffractive Surfaces|GratNet：用于衍射表面的逼真神经网络着色器|Narayan Kandel, Daljit Singh J. S. Dhillon|<http://arxiv.org/pdf/2506.15815v2>|提出了一种基于多层感知器的数据驱动方法，高效准确渲染衍射表面，显著降低数据依赖和内存占用。|
|🆕 发布|Masks make discriminative models great again!|“遮罩让判别性模型再次伟大！”|Tianshi Cao, Marie-Julie Rakotosaona, Ben Poole, Federico Tombari, Michael Niemeyer|<http://arxiv.org/pdf/2507.00916v1>|提出了一种使用可见性掩码的3D场景重建方法，通过分离图像到3D模型的转换与内容虚构，显著提升了重建质...|
|🆕 发布|GANs Secretly Perform Approximate Bayesian Model Selection|生成对抗网络隐式执行近似贝叶斯模型选择|Maurizio Filippone, Marius P. Linhard|<http://arxiv.org/pdf/2507.00651v1>|将GANs视为概率生成模型，提出基于贝叶斯模型选择的正则化和优化策略，改善性能并促进泛化。|
|🆕 发布|Context-Aware Academic Emotion Dataset and Benchmark|上下文感知学术情感数据集与基准|Luming Zhao, Jingwen Xuan, Jiamin Lou, Yonghui Yu, Wenwu Yang|<http://arxiv.org/pdf/2507.00586v1>|[代码](https://zgsfer.github.io/CAER); 提出首个多样化自然学习场景的学术情感数据集，并利用CLIP模型提出了一种融合面部表情和上下文线索的学...|
|🆕 发布|LOD-GS: Level-of-Detail-Sensitive 3D Gaussian Splatting for Detail Conserved Anti-Aliasing|LOD-GS：细节保留的抗锯齿级别敏感的3D高斯绘制|Zhenya Yang, Bingchen Gong, Kai Chen, Qi Dou|<http://arxiv.org/pdf/2507.00554v1>|提出了一种根据采样率动态调整滤波强度的LOD-GS方法，有效解决了3D场景渲染中的走样问题。|
|🆕 发布|Twill: Scheduling Compound AI Systems on Heterogeneous Mobile Edge Platforms|《Twill：在异构移动边缘平台上调度复合人工智能系统》|Zain Taufique, Aman Vyas, Antonio Miele, Pasi Liljeberg, Anil Kanduri|<http://arxiv.org/pdf/2507.00491v1>|提出Twill框架，优化异构移动边缘平台上复合AI系统的并发任务调度，平均降低推理延迟54%。|
|📝 更新|BézierGS: Dynamic Urban Scene Reconstruction with Bézier Curve Gaussian Splatting|贝塞尔高斯散点法：动态城市场景重建与贝塞尔曲线高斯散点技术|Zipei Ma, Junzhe Jiang, Yurui Chen, Li Zhang|<http://arxiv.org/pdf/2506.22099v2>|提出了一种利用可学习贝塞尔曲线表示动态物体运动轨迹的方法，有效提升了城市场景的实时重建质量和精度。|
|🆕 发布|MFH: Marrying Frequency Domain with Handwritten Mathematical Expression Recognition|频率域与手写数学表达式识别的结合：MFH方法|Huanxin Yang, Qiwen Wang|<http://arxiv.org/pdf/2507.00430v1>|[代码](https://github.com/Hryxyhe/MFH.); 引入频率域分析提升手写数学表达式识别准确率，提出MFH方法融合DCT与识别技术。|
|🆕 发布|An Improved U-Net Model for Offline handwriting signature denoising|改进的U-Net模型用于离线手写签名去噪|Wanghui Xiao|<http://arxiv.org/pdf/2507.00365v1>|提出了一种改进的U-Net模型，有效去除手写签名中的噪声，提升识别系统的鲁棒性和图像清晰度。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Building Rome with Convex Optimization|用凸优化构建罗马|Haoyu Han, Heng Yang|<http://arxiv.org/pdf/2502.04640v4>|提出了一种利用深度预测和凸优化简化全局束调整的方法，实现了高质量、快速、可扩展的结构从运动重建。|
|🆕 发布|Automated anatomy-based post-processing reduces false positives and improved interpretability of deep learning intracranial aneurysm detection|基于解剖学的自动后处理降低深度学习颅内动脉瘤检测的假阳性并提高可解释性|Jisoo Kim, Chu-Hsuan Lin, Alberto Ceballos-Arroyo, Ping Liu, Huaizu Jiang, Shrikanth Yadav, Qi Wan, Lei Qin .etc.|<http://arxiv.org/pdf/2507.00832v1>|提出了一种基于解剖学原理的后处理方法，有效降低颅内动脉瘤检测的假阳性率并提高模型可解释性。|
|📝 更新|Fully Differentiable Lagrangian Convolutional Neural Network for Physics-Informed Precipitation Nowcasting|全微分拉格朗日卷积神经网络用于物理信息增强的降水预测|Peter Pavlík, Martin Výboh, Anna Bou Ezzeddine, Viera Rozinajová|<http://arxiv.org/pdf/2402.10747v2>|提出了一种结合数据驱动学习和物理知识指导的LUPIN模型，实现了降水预报的端到端训练与推理。|
|📝 更新|StreakNet-Arch: An Anti-scattering Network-based Architecture for Underwater Carrier LiDAR-Radar Imaging|条纹网架构：一种基于抗散射网络的水下载体激光雷达-雷达成像架构|Xuelong Li, Hongjun An, Haofei Zhao, Guangying Li, Bo Liu, Xing Wang, Guanghua Cheng, Guojun Wu .etc.|<http://arxiv.org/pdf/2404.09158v3>|[代码](https://github.com/BestAnHongjun/StreakNet); 提出StreakNet-Arch框架，利用自注意力与双分支交叉注意力抑制水下散射，实现实时高效成像。|
|🆕 发布|Biorthogonal Tunable Wavelet Unit with Lifting Scheme in Convolutional Neural Network|双正交可调小波单元与提升方案在卷积神经网络中的应用|An Le, Hung Nguyen, Sungbal Seo, You-Suk Bae, Truong Nguyen|<http://arxiv.org/pdf/2507.00739v1>|引入了一种灵活的二维可调双正交小波单元，提升卷积神经网络在图像分类和异常检测的性能。|
|🆕 发布|Tunable Wavelet Unit based Convolutional Neural Network in Optical Coherence Tomography Analysis Enhancement for Classifying Type of Epiretinal Membrane Surgery|基于可调小波单元的光学相干断层扫描分析增强卷积神经网络在分类视网膜前膜手术类型中的应用|An Le, Nehal Mehta, William Freeman, Ines Nagel, Melanie Tran, Anna Heinke, Akshay Agnihotri, Lingyun Cheng .etc.|<http://arxiv.org/pdf/2507.00743v1>|提出了一种结合可调波let单元的卷积神经网络，用于增强光学相干断层扫描图像分析，提高了ERM手术类型...|
|🆕 发布|MID-INFRARED (MIR) OCT-based inspection in industry|基于中红外光频域光学相干断层扫描的工业检测|N. P. García-de-la-Puente, Rocío del Amor, Fernando García-Torres, Niels Møller Israelsen, Coraline Lapre, Christian Rosenberg Petersen, Ole Bang, Dominik Brouczek .etc.|<http://arxiv.org/pdf/2507.01074v1>|评估并利用中红外光学相干断层扫描技术进行无损检测，增强工业生产过程中的异常检测能力。|
|🆕 发布|Laplace-Mamba: Laplace Frequency Prior-Guided Mamba-CNN Fusion Network for Image Dehazing|拉普拉斯-曼巴：基于拉普拉斯频率先验引导的曼巴-卷积神经网络融合网络用于图像去雾|Yongzhen Wang, Liangliang Chen, Bingwen Hu, Heng Liu, Xiao-Ping Zhang, Mingqiang Wei|<http://arxiv.org/pdf/2507.00501v1>|[代码](https://github.com/yz-wang/Laplace-Mamba.); 提出了一种融合Laplace频率先验和Mamba-CNN架构的框架，有效提升了图像去雾质量和效率。|
|🆕 发布|Accurate and Efficient Fetal Birth Weight Estimation from 3D Ultrasound|从三维超声图像中准确高效地估算胎儿出生体重|Jian Wang, Qiongying Ni, Hongkui Yu, Ruixuan Yao, Jinqiao Ying, Bin Zhang, Xingyi Yang, Jin Peng .etc.|<http://arxiv.org/pdf/2507.00398v1>|[代码](https://github.com/Qioy-i/EFW.); 提出首个基于3D超声体积直接估算胎儿出生体重的方法，融合多尺度特征网络和合成样本学习框架，实现高精度...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs|超越注意力或相似性：最大化条件多样性以优化多模态大型语言模型中的标记剪枝|Qizhe Zhang, Mengzhen Liu, Lichen Li, Ming Lu, Yuan Zhang, Junwen Pan, Qi She, Shanghang Zhang|<http://arxiv.org/pdf/2506.10967v2>|[代码](https://github.com/Theia-4869/CDPruner.); 提出了一种新的视觉token剪枝方法CDPruner，通过最大化条件多样性来优化多模态大语言模型性能...|
|🆕 发布|Topology-Constrained Learning for Efficient Laparoscopic Liver Landmark Detection|拓扑约束学习用于高效腹腔镜肝脏标志点检测|Ruize Cui, Jiaan Zhang, Jialun Pei, Kai Wang, Pheng-Ann Heng, Jing Qin|<http://arxiv.org/pdf/2507.00519v1>|[代码](https://github.com/cuiruize/TopoNet.); 提出了一种拓扑约束学习的Liver Landmark检测框架TopoNet，通过融合RGB-D特征和...|
|🆕 发布|SCING:Towards More Efficient and Robust Person Re-Identification through Selective Cross-modal Prompt Tuning|SCING：通过选择性跨模态提示调优实现更高效、更稳健的人体再识别|Yunfei Xie, Yuxuan Cheng, Juncheng Wu, Haoyu Zhang, Yuyin Zhou, Shoudong Han|<http://arxiv.org/pdf/2507.00506v1>|提出了一种简单有效的选择性跨模态提示调优框架SCING，通过动态融合视觉特征和文本提示以及一致性对齐...|
|📝 更新|Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation|指令-4DGS：基于四维高斯静态-动态分离的高效动态场景编辑|Joohyun Kwon, Hanbyel Cho, Junmo Kim|<http://arxiv.org/pdf/2502.02091v3>|提出了一种基于4D高斯表示的动态场景编辑方法Instruct-4DGS，通过分离静态和动态信息，大幅...|
|🆕 发布|GDGS: 3D Gaussian Splatting Via Geometry-Guided Initialization And Dynamic Density Control|GDGS：通过几何引导初始化和动态密度控制的三维高斯散点绘制|Xingjun Wang, Lianlei Shan|<http://arxiv.org/pdf/2507.00363v1>|提出了一种优化的3D高斯渲染技术，通过引导初始化和动态密度控制显著提升实时渲染质量和准确性。|
|📝 更新|DynaCLR: Contrastive Learning of Cellular Dynamics with Temporal Regularization|动态CLR：带有时间正则化的细胞动力学对比学习|Eduardo Hirata-Miyasaki, Soorya Pradeep, Ziwen Liu, Alishba Imran, Taylla Milena Theodoro, Ivan E. Ivanov, Sudip Khadka, See-Chi Lee .etc.|<http://arxiv.org/pdf/2410.11281v2>|[代码](https://github.com/mehta-lab/viscy); 提出DynaCLR方法，通过对比学习与时间正则化学习细胞动态的稳健表征。|
|📝 更新|Seamless Interaction: Dyadic Audiovisual Motion Modeling and Large-Scale Dataset|无缝交互：双音频视觉运动建模与大规模数据集|Vasu Agrawal, Akinniyi Akinyemi, Kathryn Alvero, Morteza Behrooz, Julia Buffalini, Fabio Maria Carlucci, Joy Chen, Junming Chen .etc.|<http://arxiv.org/pdf/2506.22554v2>|提出大规模互动数据集并建立模型，实现与人类语音同步的动态运动和表情生成。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Training Free Stylized Abstraction|训练免风格化抽象|Aimon Rahman, Kartik Narayan, Vishal M. Patel|<http://arxiv.org/pdf/2505.22663v2>|提出了一种无需训练的框架，通过视觉语言模型在推理时提取特征和新型跨域流反转策略生成风格化抽象图像。|
|📝 更新|SegAnyPET: Universal Promptable Segmentation from Positron Emission Tomography Images|SegAnyPET：从正电子发射断层扫描图像中进行通用提示性分割|Yichi Zhang, Le Xue, Wenbo Zhang, Lanlan Li, Yuchen Liu, Chen Jiang, Yuan Cheng, Yuan Qi|<http://arxiv.org/pdf/2502.14351v3>|定位PET影像通用分割难题，提出SegAnyPET模型及CPCL策略，实现高效精准分割。|
|🆕 发布|Instant Particle Size Distribution Measurement Using CNNs Trained on Synthetic Data|使用合成数据训练的卷积神经网络实现即时颗粒尺寸分布测量|Yasser El Jarida, Youssef Iraqi, Loubna Mekouar|<http://arxiv.org/pdf/2507.00822v1>|[代码](https://github.com/YasserElj/Synthetic-Granular-Gen); 利用合成数据训练CNN实现实时粒度分布测量，提高工业产品质量与效率。|
|🆕 发布|Latent Posterior-Mean Rectified Flow for Higher-Fidelity Perceptual Face Restoration|潜在后验均值修正流用于高保真感知人脸修复|Xin Luo, Menglin Zhang, Yunwei Lan, Tianyu Zhang, Rui Li, Chang Liu, Dong Liu|<http://arxiv.org/pdf/2507.00447v1>|提出在潜在空间优化流模型，实现更符合人类视觉的高保真人脸修复。|
|🆕 发布|Unleashing the Potential of All Test Samples: Mean-Shift Guided Test-Time Adaptation|释放所有测试样本的潜力：基于均值漂移的测试时适应方法|Jizhou Han, Chenhao Ding, SongLin Dong, Yuhang He, Xinyuan Gao, Yihong Gong|<http://arxiv.org/pdf/2507.00462v1>|提出了一种无需训练的测试时适应方法MS-TTA，通过改进特征表示提升视觉语言模型在分布偏移下的性能。|
|🆕 发布|Out-of-Distribution Detection with Adaptive Top-K Logits Integration|分布外检测中的自适应Top-K对数积分法|Hikaru Shijo, Yutaka Yoshihama, Kenichi Yadani, Norifumi Murata|<http://arxiv.org/pdf/2507.00368v1>|提出了一种自适应Top-k logits整合方法ATLI，有效降低OOD样本检测的误报率。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Cage-Based Deformation for Transferable and Undefendable Point Cloud Attack|基于笼子变形的迁移性和不可防御的点云攻击|Keke Tang, Ziyong Du, Weilong Peng, Xiaofei Wang, Peican Zhu, Ligang Liu, Zhihong Tian|<http://arxiv.org/pdf/2507.00690v1>|提出CageAttack方法，通过笼状变形生成自然且难以防御的对抗性点云。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ShapeEmbed: a self-supervised learning framework for 2D contour quantification|形状嵌入：一种用于二维轮廓量化的自监督学习框架|Anna Foix Romero, Craig Russell, Alexander Krull, Virginie Uhlmann|<http://arxiv.org/pdf/2507.01009v1>|提出ShapeEmbed框架，通过自监督学习实现2D轮廓量化，保持几何不变性并优于现有方法。|
|🆕 发布|Do Echo Top Heights Improve Deep Learning Nowcasts?|“回波顶高度是否提高了深度学习现在的预报？”|Peter Pavlík, Marc Schleiss, Anna Bou Ezzeddine, Viera Rozinajová|<http://arxiv.org/pdf/2507.00845v1>|探究使用雷达反射率及回波顶高辅助信息，提升深度学习降水预测准确性。|
|📝 更新|StruMamba3D: Exploring Structural Mamba for Self-supervised Point Cloud Representation Learning|StruMamba3D：探索结构化Mamba用于自监督点云表征学习|Chuxin Wang, Yixin Zha, Wenfei Yang, Tianzhu Zhang|<http://arxiv.org/pdf/2506.21541v2>|提出StruMamba3D方法，通过保持点云空间依赖和优化状态更新策略，提升了自监督点云表征学习性能...|
|🆕 发布|Improving the Reasoning of Multi-Image Grounding in MLLMs via Reinforcement Learning|通过强化学习提升多图像基础推理在多模态语言模型中的性能|Bob Zhang, Haoran Li, Tao Zhang, Cilin Yan, Jiayin Cai, Xiaolong Jiang, Yanbin Hao|<http://arxiv.org/pdf/2507.00748v1>|采用强化学习策略提升多图像场景下大型多模态语言模型的推理性能。|
|📝 更新|A Good Start Matters: Enhancing Continual Learning with Data-Driven Weight Initialization|一个好的开始至关重要：利用数据驱动权重初始化增强持续学习|Md Yousuf Harun, Christopher Kanan|<http://arxiv.org/pdf/2503.06385v2>|提出数据驱动权重初始化策略，减少训练初期损失波动，提升持续学习效率。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Box Pose and Shape Estimation and Domain Adaptation for Large-Scale Warehouse Automation|大规模仓库自动化中的框位姿与形状估计及域自适应|Xihang Yu, Rajat Talak, Jingnan Shi, Ulrich Viereck, Igor Gilitschenski, Luca Carlone|<http://arxiv.org/pdf/2507.00984v1>|提出了一种无需人工标注的自监督领域自适应流程，用于提高仓库自动化中盒子姿态和形状的感知模型性能。|
|📝 更新|OMNI-DC: Highly Robust Depth Completion with Multiresolution Depth Integration|OMNI-DC：具有多分辨率深度集成的鲁棒深度补全方法|Yiming Zuo, Willow Yang, Zeyu Ma, Jia Deng|<http://arxiv.org/pdf/2411.19278v2>|[代码](https://github.com/princeton-vl/OMNI-DC.); 提出了一种多分辨率深度融合的深度补全模型OMNI-DC，实现了跨数据集的零样本泛化能力。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Few-shot Classification as Multi-instance Verification: Effective Backbone-agnostic Transfer across Domains|少样本分类作为多实例验证：在跨域中的有效主干无关迁移|Xin Xu, Eibe Frank, Geoffrey Holmes|<http://arxiv.org/pdf/2507.00401v1>|[代码](https://github.com/xxweka/MIV-head.); 提出了一种无需微调主干网络的“MIV-head”方法，有效实现跨域少量样本分类。|
|🆕 发布|Scope Meets Screen: Lessons Learned in Designing Composite Visualizations for Marksmanship Training Across Skill Levels|“范围遇见屏幕：在设计面向不同技能水平射击训练的复合视觉化过程中的经验教训”|Emin Zerman, Jonas Carlsson, Mårten Sjöström|<http://arxiv.org/pdf/2507.00333v1>|提出了一种结合第一人称射击视频与视觉分析的系统，有效提升不同水平射击训练的教练效果。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RoboEval: Where Robotic Manipulation Meets Structured and Scalable Evaluation|机器人评估：机器人操作与结构化可扩展评估的交汇|Yi Ru Wang, Carter Ung, Grant Tannert, Jiafei Duan, Josephine Li, Amy Le, Rishabh Oswal, Markus Grotz .etc.|<http://arxiv.org/pdf/2507.00435v1>|提出RoboEval框架，通过细粒度评估揭示双臂操作策略的局限性。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Is Visual in-Context Learning for Compositional Medical Tasks within Reach?|“视觉在上下文学习在组合医学任务中是否可实现？”|Simon Reiß, Zdravko Marinov, Alexander Jaus, Constantin Seibold, M. Saquib Sarfraz, Erik Rodner, Rainer Stiefelhagen|<http://arxiv.org/pdf/2507.00868v2>|探索视觉在位学习以单一模型处理多任务和测试时适应新任务，通过合成任务生成引擎训练模型。|
|📝 更新|A Survey on Efficient Vision-Language Models|《高效视觉-语言模型综述》|Gaurav Shinde, Anuradha Ravi, Emon Dey, Shadman Sakib, Milind Rampure, Nirmalya Roy|<http://arxiv.org/pdf/2504.09724v3>|[代码](https://github.com/MPSCUMBC/Efficient-Vision-Language-Models-A-Survey); 综述了优化计算机视觉模型的关键技术，助力边缘设备实现高效视觉语言处理。|
|📝 更新|From Holistic to Localized: Local Enhanced Adapters for Efficient Visual Instruction Fine-Tuning|从全局到局部：用于高效视觉指令微调的局部增强适配器|Pengkun Jiao, Bin Zhu, Jingjing Chen, Chong-Wah Ngo, Yu-Gang Jiang|<http://arxiv.org/pdf/2411.12787v3>|提出了一种双低秩适配器框架，通过局部增强解决视觉指令微调中的数据冲突问题。|
|🆕 发布|Audio-3DVG: Unified Audio - Point Cloud Fusion for 3D Visual Grounding|音频-3DVG：统一音频-点云融合的三维视觉定位|Duc Cao-Dinh, Khai Le-Duc, Anh Dao, Bach Phan Tat, Chris Ngo, Duy M. H. Nguyen, Nguyen X. Khanh, Thanh Nguyen-Tang|<http://arxiv.org/pdf/2507.00669v1>|提出Audio-3DVG框架，融合音频与空间信息，提升3D视觉定位性能。|
|📝 更新|SMoLoRA: Exploring and Defying Dual Catastrophic Forgetting in Continual Visual Instruction Tuning|SMoLoRA：探索并克服连续视觉指令微调中的双重灾难性遗忘|Ziqi Wang, Chang Che, Qi Wang, Yangyang Li, Zenglin Shi, Meng Wang|<http://arxiv.org/pdf/2411.13949v2>|[代码](https://github.com/Minato-Zackie/SMoLoRA.); 提出SMoLoRA框架，有效解决视觉指令微调中的双重灾难性遗忘问题，提升模型对新任务泛化能力和指令跟...|
|🆕 发布|LoD-Loc v2: Aerial Visual Localization over Low Level-of-Detail City Models using Explicit Silhouette Alignment|LoD-Loc v2：基于显式轮廓对齐的低细节城市模型空中视觉定位|Juelin Zhu, Shuaibang Peng, Long Wang, Hanlin Tan, Yu Liu, Maojun Zhang, Shen Yan|<http://arxiv.org/pdf/2507.00659v1>|提出了一种 coarse-to-fine 策略和显式轮廓对齐方法，实现了在低细节城市模型上的高精度航...|
|🆕 发布|LLaVA-SP: Enhancing Visual Representation with Visual Spatial Tokens for MLLMs|LLaVA-SP：使用视觉空间标记增强多模态大型语言模型的视觉表征|Haoran Lou, Chunxiao Fan, Ziyan Liu, Yuexin Wu, Xinxiang Wang|<http://arxiv.org/pdf/2507.00505v1>|[代码](https://github.com/CnFaker/LLaVA-SP); 通过添加六个视觉空间标记增强视觉表示，提升多模态大语言模型的细节理解能力。|
|🆕 发布|Visual Anagrams Reveal Hidden Differences in Holistic Shape Processing Across Vision Models|视觉错位揭示不同视觉模型在整体形状处理中的隐藏差异|Fenil R. Doshi, Thomas Fel, Talia Konkle, George Alvarez|<http://arxiv.org/pdf/2507.00493v1>|提出了一种衡量视觉模型全局形状处理能力的Configural Shape Score，揭示了不同模型...|
|📝 更新|Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives|教会时间序列看与说：基于对齐的视觉与文本视角进行预测|Sixun Dong, Wei Fan, Teresa Wu, Yanjie Fu|<http://arxiv.org/pdf/2506.24124v2>|[代码](https://github.com/Ironieser/TimesCLIP.); 提出了一种将时间序列转化为视觉和文本双模态表示的方法，通过对比学习提升预测准确性。|
|📝 更新|Enabling Collaborative Parametric Knowledge Calibration for Retrieval-Augmented Vision Question Answering|实现用于检索增强视觉问答的协作参数知识校准|Jiaqi Deng, Kaize Shi, Zonghan Wu, Huan Huo, Dingxian Wang, Guandong Xu|<http://arxiv.org/pdf/2504.04065v2>|提出协同参数知识校准框架，提升视觉问答系统中知识检索与答案生成的互动性，实现性能显著提升。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Not All Attention Heads Are What You Need: Refining CLIP's Image Representation with Attention Ablation|不是所有的注意力头都是你所需要的：通过注意力消融精炼CLIP的图像表示|Feng Lin, Marco Chen, Haokui Zhang, Xiaotian Yu, Guangming Lu, Rong Xiao|<http://arxiv.org/pdf/2507.00537v1>|提出注意力消融技术，有效提升CLIP模型在下游任务的性能而不增加推理成本。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ATSTrack: Enhancing Visual-Language Tracking by Aligning Temporal and Spatial Scales|ATSTrack：通过对齐时间和空间尺度增强视觉-语言跟踪|Yihao Zhen, Qiang Wang, Yu Qiao, Liangqiong Qu, Huijie Fan|<http://arxiv.org/pdf/2507.00454v1>|提出了一种视觉语言跟踪方法ATSTrack，通过匹配时间和空间尺度差异，提高了视觉与语言输入的对齐性...|
|📝 更新|R1-Track: Direct Application of MLLMs to Visual Object Tracking via Reinforcement Learning|R1-Track：通过强化学习直接将多模态大型语言模型应用于视觉目标跟踪|Biao Wang, Wenwen Li|<http://arxiv.org/pdf/2506.21980v2>|通过强化学习微调多模态大语言模型，实现了灵活的视觉目标跟踪。|
|📝 更新|Seeking and Updating with Live Visual Knowledge|寻求与实时视觉知识的更新|Mingyang Fu, Yuyang Peng, Dongping Chen, Zetong Zhou, Benlin Liu, Yao Wan, Zhou Zhao, Philip S. Yu .etc.|<http://arxiv.org/pdf/2504.05288v2>|提出LiveVQA数据集，评估并提升多模态大语言模型处理实时视觉信息的能力。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Landslide Detection and Mapping Using Deep Learning Across Multi-Source Satellite Data and Geographic Regions|利用深度学习跨多源卫星数据及地理区域进行滑坡检测与制图|Rahul A. Burange, Harsh K. Shinde, Omkar Mutyalwar|<http://arxiv.org/pdf/2507.01123v1>|集成多源卫星数据和深度学习模型，提升滑坡检测与预测的准确性和实用性。|
|📝 更新|Exploring Text-Guided Single Image Editing for Remote Sensing Images|探索基于文本引导的遥感图像单幅编辑方法|Fangzhou Han, Lingyu Si, Zhizhuo Jiang, Hongwei Dong, Lamei Zhang, Yu Liu, Hao Chen, Bo Du|<http://arxiv.org/pdf/2405.05769v4>|[代码](https://github.com/HIT-PhilipHan/remote_sensing_image_editing.); 提出了一种基于单图像训练的文本引导遥感图像编辑方法，有效解决了数据集多样性和语义对应问题。|
|📝 更新|Semi-supervised Semantic Segmentation for Remote Sensing Images via Multi-scale Uncertainty Consistency and Cross-Teacher-Student Attention|通过多尺度不确定性一致性和跨师生注意力进行遥感图像的半监督语义分割|Shanwen Wang, Xin Sun, Changrui Chen, Danfeng Hong, Jungong Han|<http://arxiv.org/pdf/2501.10736v3>|提出MUCA模型，通过多尺度不确定性和跨师生注意力提升遥感图像半监督语义分割性能。|
|🆕 发布|TopoStreamer: Temporal Lane Segment Topology Reasoning in Autonomous Driving|"TopoStreamer：自动驾驶中的车道段落拓扑推理时序分析"|Yiming Yang, Yueru Luo, Bingkun He, Hongbin Lin, Suzhong Fu, Chao Yan, Kun Tang, Xinrui Yan .etc.|<http://arxiv.org/pdf/2507.00709v1>|提出TopoStreamer模型，通过动态位置编码和属性约束改进自动驾驶中的车道拓扑推理准确性。|
|🆕 发布|Overtake Detection in Trucks Using CAN Bus Signals: A Comparative Study of Machine Learning Methods|利用CAN总线信号进行卡车超车检测：机器学习方法的比较研究|Fernando Alonso-Fernandez, Talha Hanif Butt, Prayag Tiwari|<http://arxiv.org/pdf/2507.00593v1>|研究了利用CAN总线信号进行超车检测的多种机器学习方法，并通过数据融合提升了准确率。|
|📝 更新|AirV2X: Unified Air-Ground Vehicle-to-Everything Collaboration|统一空地车联网协同系统：AirV2X|Xiangbo Gao, Yuheng Wu, Xuewen Luo, Keshu Wu, Xinghao Chen, Yuping Wang, Chenxi Liu, Yang Zhou .etc.|<http://arxiv.org/pdf/2506.19283v2>|[代码](https://github.com/taco-group/AirV2X-Perception.); 提出AirV2X-Perception大规模数据集，利用无人机辅助车辆感知，降低部署成本并提高覆盖范...|
|🆕 发布|CGEarthEye:A High-Resolution Remote Sensing Vision Foundation Model Based on the Jilin-1 Satellite Constellation|“CGEarthEye：基于吉林一号卫星星座的高分辨率遥感视觉基础模型”|Zhiwei Yi, Xin Cheng, Jingyu Ma, Ruifei Zhu, Junwei Tian, Yuanxiu Zhou, Xinge Zhao, Hongzhe Li|<http://arxiv.org/pdf/2507.00356v1>|提出了CGEarthEye模型，利用Jilin-1卫星数据，提升了高分辨率遥感图像的基础模型性能。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AdaptoVision: A Multi-Resolution Image Recognition Model for Robust and Scalable Classification|自适应视觉：一种用于鲁棒和可扩展分类的多分辨率图像识别模型|Md. Sanaullah Chowdhury Lameya Sabrin|<http://arxiv.org/pdf/2504.12652v2>|提出了一种高效的卷积神经网络架构AdaptoVision，通过减少参数和计算需求实现了计算复杂度与分...|
|📝 更新|Realism in Action: Anomaly-Aware Diagnosis of Brain Tumors from Medical Images Using YOLOv8 and DeiT|《行动中的真实感：使用YOLOv8和DeiT进行医学图像的脑肿瘤异常感知诊断》|Seyed Mohammad Hossein Hashemi, Leila Safari, Mohsen Hooshmand, Amirhossein Dadashzadeh Taromi|<http://arxiv.org/pdf/2401.03302v4>|提出了一种针对脑肿瘤检测的稳健框架，通过YOLOv8和DeiT实现高准确性和低资源消耗的诊断。|
|🆕 发布|High-Frequency Semantics and Geometric Priors for End-to-End Detection Transformers in Challenging UAV Imagery|高频语义与几何先验在挑战性无人机图像中的端到端检测变换器应用|Hongxing Peng, Lide Chen, Hui Zhu, Yan Chen|<http://arxiv.org/pdf/2507.00825v1>|提出了一种针对无人机图像的实时检测变压器框架HEGS-DETR，通过增强高频语义和几何先验，有效提升...|
|🆕 发布|TRACE: Temporally Reliable Anatomically-Conditioned 3D CT Generation with Enhanced Efficiency|TRACE：基于时间可靠性和解剖条件的高效三维CT生成方法|Minye Shao, Xingyu Miao, Haoran Duan, Zeyu Wang, Jingkun Chen, Yawen Huang, Xian Wu, Jingjing Deng .etc.|<http://arxiv.org/pdf/2507.00802v1>|[代码](https://github.com/VinyehShaw/TRACE.); 提出TRACE框架，通过2D视频帧对生成高效、解剖学准确的3D医疗影像。|
|📝 更新|Exploring Intrinsic Normal Prototypes within a Single Image for Universal Anomaly Detection|在单张图像中探索内在法线原型以实现通用异常检测|Wei Luo, Yunkang Cao, Haiming Yao, Xiaotian Zhang, Jianan Lou, Yuqi Cheng, Weiming Shen, Wenyong Yu|<http://arxiv.org/pdf/2503.02424v2>|[代码](https://github.com/luow23/INP-Former.); 提出了一种直接从测试图像中提取内在正常原型的方法，实现了无需参考训练集的通用异常检测。|
|🆕 发布|BEV-VAE: Multi-view Image Generation with Spatial Consistency for Autonomous Driving|BEV-VAE：面向自动驾驶的多视角图像生成与空间一致性保持|Zeming Chen, Hang Zhao|<http://arxiv.org/pdf/2507.00707v1>|[代码](https://github.com/Czm369/bev-vae.); 提出BEV-VAE模型，通过结构化表征实现自动驾驶中多视角图像的一致性和可控性生成。|
|🆕 发布|Bridging Classical and Learning-based Iterative Registration through Deep Equilibrium Models|通过深度平衡模型连接经典与基于学习的迭代配准方法|Yi Zhang, Yidong Zhao, Qian Tao|<http://arxiv.org/pdf/2507.00582v1>|提出了一种基于深度平衡模型的医学图像配准框架，实现了理论无限迭代步骤且降低了内存消耗。|
|🆕 发布|Similarity Memory Prior is All You Need for Medical Image Segmentation|相似性记忆先验是进行医学图像分割的全部所需|Tang Hao, Guo ZhiQing, Wang LieJun, Liu Chao|<http://arxiv.org/pdf/2507.00585v1>|[代码](https://github.com/vpsg-research/Sim-MPNet.); 提出相似性记忆先验网络Sim-MPNet，通过动态记忆权重损失注意机制提升医疗图像分割性能。|
|🆕 发布|Out-of-distribution detection in 3D applications: a review|三维应用中的分布外检测：综述|Zizhao Li, Xueyang Kang, Joseph West, Kourosh Khoshelham|<http://arxiv.org/pdf/2507.00570v1>|综述了三维应用中的异常检测技术，为构建可靠、安全的AI系统提供了理论和实践指导。|
|📝 更新|Unsupervised contrastive analysis for anomaly detection in brain MRIs via conditional diffusion models|无监督对比分析通过条件扩散模型进行脑部MRI异常检测|Cristiano Patrício, Carlo Alberto Barbano, Attilio Fiandrotti, Riccardo Renzulli, Marco Grangetto, Luis F. Teixeira, João C. Neves|<http://arxiv.org/pdf/2406.00772v3>|提出无监督对比分析方法，通过训练自监督编码器提升脑部MRI重建质量，实现无需目标样本的异常检测。|
|📝 更新|Unleashing Diffusion and State Space Models for Medical Image Segmentation|释放扩散与状态空间模型在医学图像分割中的应用|Rong Wu, Ziqi Chen, Liming Zhong, Heng Li, Hai Shu|<http://arxiv.org/pdf/2506.12747v2>|[代码](https://github.com/Rows21/k-Means_Mask_Mamba.); 提出DSM框架，通过结合扩散与状态空间模型，实现了对训练数据外未见肿瘤类别的精准分割。|
|🆕 发布|Medical Image Segmentation Using Advanced Unet: VMSE-Unet and VM-Unet CBAM+|使用高级Unet的医疗图像分割：VMSE-Unet和VM-Unet CBAM+|Sayandeep Kanrar, Raja Piyush, Qaiser Razi, Debanshi Chakraborty, Vikas Hassija, GSS Chalapathi|<http://arxiv.org/pdf/2507.00511v1>|集成SE和CBAM技术的VMSE-Unet模型，提升了医疗图像分割精度与效率。|
|📝 更新|RadZero: Similarity-Based Cross-Attention for Explainable Vision-Language Alignment in Radiology with Zero-Shot Multi-Task Capability|RadZero：基于相似度的跨注意力机制用于放射学中具有零样本多任务能力的可解释视觉语言对齐|Jonggwon Park, Soobum Kim, Byungmu Yoon, Kyoyun Choi|<http://arxiv.org/pdf/2504.07416v2>|提出RadZero框架，通过相似度基础的跨注意力机制实现放射学领域零样本多任务的可解释视觉语言对齐。|
|📝 更新|De-LightSAM: Modality-Decoupled Lightweight SAM for Generalizable Medical Segmentation|《De-LightSAM：用于通用医学分割的模态解耦轻量级SAM》|Qing Xu, Jiaxuan Li, Xiangjian He, Chenxin Li, Fiseha B. Tesem, Wenting Duan, Zhen Chen, Rong Qu .etc.|<http://arxiv.org/pdf/2407.14153v5>|[代码](https://github.com/xq141839/De-LightSAM.); 提出了一种轻量级、跨模态的医学图像分割模型De-LightSAM，通过自动生成提示和独立解码通道，提...|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|De-Simplifying Pseudo Labels to Enhancing Domain Adaptive Object Detection|简化伪标签以增强域自适应目标检测|Zehua Fu, Chenguang Liu, Yuyu Chen, Jiaqi Zhou, Qingjie Liu, Yunhong Wang|<http://arxiv.org/pdf/2507.00608v1>|提出DeSimPL方法减轻自标注检测器中的简单样本偏差，提升无监督域自适应目标检测性能。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Box-QAymo: Box-Referring VQA Dataset for Autonomous Driving|自动驾驶中的框引用视觉问答数据集Box-QAymo|Djamahl Etchegaray, Yuxia Fu, Zi Huang, Yadan Luo|<http://arxiv.org/pdf/2507.00525v1>|[代码](https://djamahl99.github.io/qaymo-pages); 提出了Box-QAymo数据集，通过用户绘制的边界框评估和优化视觉语言模型在自动驾驶场景下的空间和时...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision Geometry Priors|从视频中学习三维世界：用三维视觉几何先验增强多模态语言模型|Duo Zheng, Shijia Huang, Yanyang Li, Liwei Wang|<http://arxiv.org/pdf/2505.24625v2>|提出了一种无需额外3D输入，直接从视频数据增强3D场景理解能力的语言模型。|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BadViM: Backdoor Attack against Vision Mamba|BadViM：针对Vision Mamba的的后门攻击|Yinghao Wu, Liyan Zhang|<http://arxiv.org/pdf/2507.00577v1>|提出BadViM框架，利用共振频率触发器攻击Vision Mamba模型，实现高效隐蔽的后门攻击。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PriOr-Flow: Enhancing Primitive Panoramic Optical Flow with Orthogonal View|“PriOr-Flow：通过正交视角增强基本全景光流”|Longliang Liu, Miaojie Feng, Junda Cheng, Jijun Xiang, Xuan Zhu, Xin Yang|<http://arxiv.org/pdf/2506.23897v2>|[代码](https://github.com/longliangLiu/PriOr-Flow.); 提出双分支框架PriOr-Flow，利用正交视图减少球面投影失真，提升全景光流估计性能。|
|📝 更新|Mixed Signals: A Diverse Point Cloud Dataset for Heterogeneous LiDAR V2X Collaboration|异质激光雷达V2X协作的多样化点云数据集：混合信号|Katie Z Luo, Minh-Quan Dao, Zhenzhen Liu, Mark Campbell, Wei-Lun Chao, Kilian Q. Weinberger, Ezio Malis, Vincent Fremont .etc.|<http://arxiv.org/pdf/2502.14156v2>|提出了Mixed Signals，一个多样化的点云数据集，通过多车协同感知解决了单一车辆感知系统的局...|
|🆕 发布|Advancing Lung Disease Diagnosis in 3D CT Scans|三维CT扫描中肺部疾病诊断的进展|Qingqiu Li, Runtian Yuan, Junlin Hou, Jilan Xu, Yuejie Zhang, Rui Feng, Hao Chen|<http://arxiv.org/pdf/2507.00993v1>|提出一种有效模型，通过去除非肺部区域并采用ResNeSt50提取特征，提高了3D CT扫描中肺部疾病...|
|🆕 发布|RTMap: Real-Time Recursive Mapping with Change Detection and Localization|RTMap：实时递归映射与变化检测及定位|Yuheng Du, Sheng Yang, Lingxuan Wang, Zhenghua Hou, Chengying Cai, Zhitao Tan, Mingxia Chen, Shi-Sheng Huang .etc.|<http://arxiv.org/pdf/2507.00980v1>|[代码](https://github.com/CN-ADLab/RTMap); 提出RTMap方法，通过众包多遍历高清地图，实现了实时定位与变化检测，提升了地图准确性和实时性。|
|🆕 发布|Evaluating Robustness of Monocular Depth Estimation with Procedural Scene Perturbations|评估单目深度估计在程序化场景扰动下的鲁棒性|Jack Nugent, Siyang Wu, Zeyu Ma, Beining Han, Meenal Parakh, Abhishek Joshi, Lingjie Mei, Alexander Raistrick .etc.|<http://arxiv.org/pdf/2507.00981v1>|[代码](https://github.com/princeton-vl/proc-depth-eval.); 提出了一种新的基准PDE，通过生成可控扰动三维场景，系统评估单目深度估计的鲁棒性。|

