## [UPDATED!] **2025-07-03** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MultiGen: Using Multimodal Generation in Simulation to Learn Multimodal Policies in Real|多模态生成在仿真中的应用以学习现实中的多模态策略|Renhao Wang, Haoran Geng, Tingle Li, Feishi Wang, Gopala Anumanchipalli, Philipp Wu, Trevor Darrell, Boyi Li .etc.|<http://arxiv.org/pdf/2507.02864v1>|引入MultiGen框架，利用生成模型增强仿真，实现多模态策略学习并成功应用于现实世界。|
|📝 更新|Thinking with Images for Multimodal Reasoning: Foundations, Methods, and Future Frontiers|图像驱动多模态推理：基础、方法与未来前沿|Zhaochen Su, Peng Xia, Hangyu Guo, Zhenhua Liu, Yan Ma, Xiaoye Qu, Jiaqi Liu, Yanshu Li .etc.|<http://arxiv.org/pdf/2506.23918v3>|提出视觉思维新范式，将图像从静态输入转变为动态认知工作区，推动多模态AI向更高认知自主性发展。|
|🆕 发布|Grounding Intelligence in Movement|将智能根植于运动|Melanie Segado, Felipe Parodi, Jordan K. Matelsky, Michael L. Platt, Eva B. Dyer, Konrad P. Kording|<http://arxiv.org/pdf/2507.02771v1>|将运动视为AI建模的主要目标，以提升生成建模和控制能力，并建立生物与人工系统行为理解的共享基础。|
|📝 更新|MaizeField3D: A Curated 3D Point Cloud and Procedural Model Dataset of Field-Grown Maize from a Diversity Panel|玉米田3D：来自多样性面板的田间生长玉米的三维点云和程序模型数据集|Elvis Kimara, Mozhgan Hadadi, Jackson Godbersen, Aditya Balu, Talukder Jubery, Yawei Li, Adarsh Krishnamurthy, Patrick S. Schnable .etc.|<http://arxiv.org/pdf/2503.07813v3>|[代码](https://baskargroup.github.io/MaizeField3D); 推出了MaizeField3D，一个包含多样遗传面板的田间玉米3D点云数据集，助力AI在农业研究中的...|
|📝 更新|LLaVA-KD: A Framework of Distilling Multimodal Large Language Models|LLaVA-KD：一种蒸馏多模态大型语言模型的框架|Yuxuan Cai, Jiangning Zhang, Haoyang He, Xinwei He, Ao Tong, Zhenye Gan, Chengjie Wang, Zhucun Xue .etc.|<http://arxiv.org/pdf/2410.16236v3>|[代码](https://github.com/Fantasyele/LLaVA-KD.); 提出了一种LLaVA-KD框架，通过多模态和关系蒸馏提升小规模多模态大语言模型的性能。|
|🆕 发布|LaCo: Efficient Layer-wise Compression of Visual Tokens for Multimodal Large Language Models|LaCo：用于多模态大型语言模型的视觉标记逐层高效压缩|Juntao Liu, Liqiang Niu, Wenchao Chen, Jie Zhou, Fandong Meng|<http://arxiv.org/pdf/2507.02279v1>|提出层内视觉token压缩框架LaCo，通过像素shuffle和残差学习提升多模大语言模型效率。|
|🆕 发布|Prompt Disentanglement via Language Guidance and Representation Alignment for Domain Generalization|通过语言引导和表征对齐实现提示解耦以进行域泛化|De Cheng, Zhipeng Xu, Xinyang Jiang, Dongsheng Li, Nannan Wang, Xinbo Gao|<http://arxiv.org/pdf/2507.02288v1>|提出利用语言引导和表征对齐进行提示解耦，有效提升模型在不同领域的一般化能力。|
|🆕 发布|SurgVisAgent: Multimodal Agentic Model for Versatile Surgical Visual Enhancement|《SurgVisAgent：多功能手术视觉增强的多模态主动模型》|Zeyu Lei, Hongyuan Yu, Jinlin Wu, Zhen Chen|<http://arxiv.org/pdf/2507.02252v1>|提出SurgVisAgent模型，利用多模态大语言模型动态处理多种手术图像增强任务，提升手术干预精准...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bootstrapping Grounded Chain-of-Thought in Multimodal LLMs for Data-Efficient Model Adaptation|"在多模态大规模语言模型中启动基于实体的链式思维进行数据高效模型适应"|Jiaer Xia, Bingkui Tong, Yuhang Zang, Rui Shao, Kaiyang Zhou|<http://arxiv.org/pdf/2507.02859v1>|提出了一种引导式链式思维方法，通过注入定位信息提升多模态大语言模型在数据有限条件下的视觉任务适应性。|
|🆕 发布|DexVLG: Dexterous Vision-Language-Grasp Model at Scale|灵巧视觉-语言-抓取模型的大规模实现：DexVLG|Jiawei He, Danshi Li, Xinqiang Yu, Zekun Qi, Wenyao Zhang, Jiayi Chen, Zhaoxiang Zhang, Zhizheng Zhang .etc.|<http://arxiv.org/pdf/2507.02747v1>|提出了一种大规模视觉-语言-抓取模型DexVLG，通过单视角RGBD输入预测灵巧抓取姿态以配合语言指...|
|🆕 发布|Reconstructing Close Human Interaction with Appearance and Proxemics Reasoning|利用外观和近体学推理重构近距离人际互动|Buzhen Huang, Chen Li, Chongyang Xu, Dongyue Lu, Jinnan Chen, Yangang Wang, Gim Hee Lee|<http://arxiv.org/pdf/2507.02565v1>|提出双分支优化框架，利用外观和社交空间推理重构复杂环境中的人体交互动作。|
|📝 更新|Privacy-Preserving Operating Room Workflow Analysis using Digital Twins|使用数字孪生的隐私保护手术室工作流程分析|Alejandra Perez, Han Zhang, Yu-Chun Ku, Lalithkumar Seenivasan, Roger Soberanis, Jose L. Porras, Richard Day, Jeff Jopling .etc.|<http://arxiv.org/pdf/2504.12552v2>|提出了一种保护隐私的手术室工作流分析技术，通过生成数字化手术室副本进行事件检测。|
|🆕 发布|SciGA: A Comprehensive Dataset for Designing Graphical Abstracts in Academic Papers|SciGA：学术论文中设计图形摘要的全面数据集|Takuro Kawada, Shunsuke Kitada, Sota Nemoto, Hitoshi Iyatomi|<http://arxiv.org/pdf/2507.02212v1>|介绍了SciGA-145k数据集，支持图形摘要选择与推荐，推动自动化生成研究，并提出了新的评估指标。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Stronger, Steadier & Superior: Geometric Consistency in Depth VFM Forges Domain Generalized Semantic Segmentation|更强、更稳定、更优越：深度VFM中的几何一致性锻造领域泛化的语义分割|Siyu Chen, Ting Han, Changshe Zhang, Xin Luo, Meiliu Wu, Guorong Cai, Jinhe Su|<http://arxiv.org/pdf/2504.12753v2>|[代码](https://github.com/anonymouse-xzrptkvyqc/DepthForge.); 提出融合深度信息与视觉基础模型的新框架，增强语义分割的几何一致性和泛化能力。|
|📝 更新|Skip-Vision: Efficient and Scalable Acceleration of Vision-Language Models via Adaptive Token Skipping|跳视：通过自适应标记跳过实现视觉语言模型的高效和可扩展加速|Weili Zeng, Ziyuan Huang, Kaixiang Ji, Yichao Yan|<http://arxiv.org/pdf/2503.21817v3>|Skip-Vision通过自适应跳过视觉token，有效减少计算成本，加速视觉语言模型的训练与推理过...|
|📝 更新|Escaping Platos Cave: JAM for Aligning Independently Trained Vision and Language Models|逃离柏拉图的洞穴：用于对齐独立训练的视觉和语言模型的JAM方法|Hyoseo, Yoon, Yisong Yue, Been Kim|<http://arxiv.org/pdf/2507.01201v2>|定位独立训练的视觉与语言模型间的对齐问题，提出JAM框架，通过联合训练实现模态间的结构共享。|
|🆕 发布|High-Fidelity Differential-information Driven Binary Vision Transformer|高保真差分信息驱动的二值视觉变换器|Tian Gao, Zhiyuan Zhang, Kaijie Yin, Xu-Cheng Zhong, Hui Kong|<http://arxiv.org/pdf/2507.02222v1>|提出了一种高效保持信息量的二值化视觉Transformer架构，通过差分信息增强和频率分解提升了边缘...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|No time to train! Training-Free Reference-Based Instance Segmentation|"无需训练！基于参考的无训练实例分割"|Miguel Espinosa, Chenhongyi Yang, Linus Ericsson, Steven McDonagh, Elliot J. Crowley|<http://arxiv.org/pdf/2507.02798v1>|提出了一种无需训练的基于参考图像的实例分割方法，利用预训练模型的语义先验实现自动生成高质量分割掩码。|
|📝 更新|TiCoSS: Tightening the Coupling between Semantic Segmentation and Stereo Matching within A Joint Learning Framework|TiCoSS：在联合学习框架内加强语义分割与立体匹配之间的耦合|Guanfeng Tang, Zhiyuan Wu, Jiahang Li, Ping Zhong, We Ye, Xieyuanli Chen, Huiming Lu, Rui Fan|<http://arxiv.org/pdf/2407.18038v4>|提出了一种紧密耦合的联合学习框架TiCoSS，通过特征融合策略和深度监督机制，有效提升了语义分割和立...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Pixels to Damage Severity: Estimating Earthquake Impacts Using Semantic Segmentation of Social Media Images|从像素到灾害严重性：利用社交媒体图像的语义分割估计地震影响|Danrong Zhang, Huili Huang, N. Simrill Smith, Nimisha Roy, J. David Frost|<http://arxiv.org/pdf/2507.02781v1>|将地震后社交媒体图像的损害评估转化为语义分割问题，实现了更客观的损害程度量化。|
|🆕 发布|Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis|持续多实例学习增强定位用于病理学全切片图像分析|Byung Hyun Lee, Wongi Jeong, Woojae Han, Kyoungbun Lee, Se Young Chun|<http://arxiv.org/pdf/2507.02395v1>|提出CoMEL框架，通过高效实例编码、可靠伪标签生成和遗忘减轻策略，提升了病理切片图像的持续多实例学...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Partial Weakly-Supervised Oriented Object Detection|部分弱监督定向目标检测|Mingxin Liu, Peiyuan Zhang, Yuan Liu, Wei Zhang, Yue Zhou, Ning Liao, Ziyang Gong, Junwei Luo .etc.|<http://arxiv.org/pdf/2507.02751v1>|提出了一种基于部分弱标注的面向对象检测框架，有效利用未标注数据，降低标注成本并提升性能。|
|🆕 发布|Red grape detection with accelerated artificial neural networks in the FPGA's programmable logic|基于FPGA可编程逻辑的加速人工神经网络实现的红色葡萄检测|Sandro Costa Magalhães, Marco Almeida, Filipe Neves dos Santos, António Paulo Moreira, Jorge Dias|<http://arxiv.org/pdf/2507.02443v1>|利用FPGA的PL加速神经网络，实现高效的红葡萄检测，显著提升机器人作业速度。|
|🆕 发布|Weakly-supervised Contrastive Learning with Quantity Prompts for Moving Infrared Small Target Detection|弱监督对比学习结合数量提示用于动态红外小目标检测|Weiwei Duan, Luping Ji, Shengjia Chen, Sicheng Zhu, Jianghong Huang, Mao Ye|<http://arxiv.org/pdf/2507.02454v1>|提出了一种基于弱监督对比学习的红外小目标检测方法，减少了对大量手动标注的依赖。|
|🆕 发布|Beyond Spatial Frequency: Pixel-wise Temporal Frequency-based Deepfake Video Detection|超越空间频率：基于像素级时间频率的深度伪造视频检测|Taehoon Kim, Jongwook Choi, Yonghyun Jeong, Haeun Noh, Jaejun Yoo, Seungryul Baek, Jongwon Choi|<http://arxiv.org/pdf/2507.02398v1>|提出了一种基于像素级时间频率的深度伪造视频检测方法，有效识别传统方法忽视的时域不一致性。|
|🆕 发布|Two-Steps Neural Networks for an Automated Cerebrovascular Landmark Detection|两步骤神经网络用于自动化脑血管标记检测|Rafic Nader, Vincent L'Allinec, Romain Bourcier, Florent Autrusseau|<http://arxiv.org/pdf/2507.02349v1>|提出了一种两步骤神经网络方法，自动检测大脑血管关键地标，有效解决了地标位置相近和视觉特征相似导致的问...|
|📝 更新|MV2DFusion: Leveraging Modality-Specific Object Semantics for Multi-Modal 3D Detection|MV2DFusion：利用特定模态的对象语义进行多模态三维检测|Zitian Wang, Zehao Huang, Yulu Gao, Naiyan Wang, Si Liu|<http://arxiv.org/pdf/2408.05945v2>|提出了一种多模态3D检测框架MV2DFusion，通过融合相机和LiDAR的优势，实现了高效准确的对...|
|🆕 发布|Perception Activator: An intuitive and portable framework for brain cognitive exploration|感知激活器：一种直观且便携的大脑认知探索框架|Le Xu, Qi Zhang, Qixian Zhang, Hongyun Zhang, Duoqian Miao, Cairong Zhao|<http://arxiv.org/pdf/2507.02311v1>|提出了一种利用fMRI信号增强视觉对象检测与分割准确性的新框架，通过跨注意力机制整合大脑视觉感知信息...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MEGANet-W: A Wavelet-Driven Edge-Guided Attention Framework for Weak Boundary Polyp Detection|MEGANet-W：一种基于小波驱动的边缘引导注意力框架用于弱边界息肉检测|Zhe Yee Tan|<http://arxiv.org/pdf/2507.02668v1>|提出了一种基于小波驱动的边缘引导注意力框架，有效提升了弱边界息肉检测的准确性。|
|🆕 发布|Automatic Labelling for Low-Light Pedestrian Detection|低光环境下行人的自动标注方法|Dimitrios Bouzoulas, Eerik Alamikkotervo, Risto Ojala|<http://arxiv.org/pdf/2507.02513v1>|[代码](https://github.com/BouzoulasDimitrios/IR-RGB-Automated-LowLight-Pedestrian-Labeling); 提出了一种自动红外-RGB标注流程，用于提升低光条件下行人检测的准确性。|
|📝 更新|Illuminant and light direction estimation using Wasserstein distance method|使用Wasserstein距离方法的照度和光线方向估计|Selcuk Yazar|<http://arxiv.org/pdf/2503.05802v2>|利用Wasserstein距离方法估计光照和光源方向，提升复杂光照环境下图像处理准确性。|
|🆕 发布|PLOT: Pseudo-Labeling via Video Object Tracking for Scalable Monocular 3D Object Detection|PLOT：通过视频对象跟踪进行伪标签标注以实现可扩展的单目3D对象检测|Seokyeong Lee, Sithu Aung, Junyong Choi, Seungryong Kim, Ig-Jae Kim, Junghyun Cho|<http://arxiv.org/pdf/2507.02393v1>|提出了一种仅使用视频数据且无需额外传感器或多视角设置的伪标签框架，有效提升了单目3D物体检测的准确性...|
|🆕 发布|Lightweight Shrimp Disease Detection Research Based on YOLOv8n|基于YOLOv8n的轻量级对虾病害检测研究|Fei Yuhuan, Wang Gengchen, Liu Fenghao, Zang Ran, Sun Xufei, Chang Hao|<http://arxiv.org/pdf/2507.02354v1>|提出了一种基于YOLOv8n的轻量级网络架构，通过优化检测头和引入自注意力机制，提高了虾病检测的准确...|
|🆕 发布|LMPNet for Weakly-supervised Keypoint Discovery|弱监督关键点发现中的LMPNet|Pei Guo, Ryan Farrell|<http://arxiv.org/pdf/2507.02308v1>|提出了一种基于弱监督学习的关键点发现方法LMPNet，通过特殊设计的池化层自动学习并检测对象关键点。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RefTok: Reference-Based Tokenization for Video Generation|基于参考的标记化方法用于视频生成：RefTok|Xiang Fan, Xiaohang Sun, Kushan Thakkar, Zhu Liu, Vimal Bhat, Ranjay Krishna, Xiang Hao|<http://arxiv.org/pdf/2507.02862v1>|提出了一种基于参考帧的编码方法RefTok，有效捕捉视频中的时间依赖性，显著提升了视频生成质量。|
|🆕 发布|AnyI2V: Animating Any Conditional Image with Motion Control|AnyI2V：用运动控制动画化任意条件图像|Ziye Li, Hao Luo, Xincheng Shuai, Henghui Ding|<http://arxiv.org/pdf/2507.02857v1>|提出了一种无需训练的AnyI2V框架，通过用户定义的运动轨迹为任意条件图像生成视频，扩展了视频生成的...|
|🆕 发布|RichControl: Structure- and Appearance-Rich Training-Free Spatial Control for Text-to-Image Generation|《RichControl：结构丰富和外观丰富的无训练空间控制用于文本到图像生成》|Liheng Zhang, Lexi Pang, Hang Ye, Xiaoxuan Ma, Yizhou Wang|<http://arxiv.org/pdf/2507.02792v1>|提出了一种解耦特征注入时序的框架，有效平衡了结构保持与域对齐，实现了无需训练的高质量图像生成。|
|🆕 发布|Prompt learning with bounding box constraints for medical image segmentation|带边界框约束的提示学习在医学图像分割中的应用|Mélanie Gaillochet, Mehrdad Noori, Sahar Dastani, Christian Desrosiers, Hervé Lombaert|<http://arxiv.org/pdf/2507.02743v1>|[代码](https://github.com/Minimel/box-prompt-learning-VFM.git); 提出利用边界框约束的弱监督医学图像分割方法，减少人工标注负担并提高Dice分数至84.90%。|
|📝 更新|CAD-Editor: A Locate-then-Infill Framework with Automated Training Data Synthesis for Text-Based CAD Editing|CAD编辑器：一种基于文本的CAD编辑自动化训练数据合成的定位-填充框架|Yu Yuan, Shizhao Sun, Qi Liu, Jiang Bian|<http://arxiv.org/pdf/2502.03997v2>|[代码](https://github.com/microsoft/CAD-Editor); 提出首个文本驱动的CAD编辑框架CAD-Editor，通过自动合成训练数据和分解编辑任务，实现高效C...|
|🆕 发布|FairHuman: Boosting Hand and Face Quality in Human Image Generation with Minimum Potential Delay Fairness in Diffusion Models|FairHuman：在扩散模型中通过最小潜在延迟公平性提升生成人类图像中的手部和面部质量|Yuxuan Wang, Tianwei Cao, Huayu Zhang, Zhongjiang He, Kongming Liang, Zhanyu Ma|<http://arxiv.org/pdf/2507.02714v1>|提出FairHuman方法，通过多目标微调和最小潜在延迟准则，均衡提升人像生成中手和脸部的细节质量。|
|🆕 发布|UniMC: Taming Diffusion Transformer for Unified Keypoint-Guided Multi-Class Image Generation|统一多类图像生成的关键点引导扩散变换器驯服方法：UniMC|Qin Guo, Ailing Zeng, Dongxu Yue, Ceyuan Yang, Yang Cao, Hanzhong Guo, Fei Shen, Wei Liu .etc.|<http://arxiv.org/pdf/2507.02713v1>|提出UniMC框架，实现基于关键点控制的统一多类图像生成，并构建了适用于此的大规模数据集HAIG-2...|
|🆕 发布|Embedding-Based Federated Data Sharing via Differentially Private Conditional VAEs|基于嵌入的差分隐私条件变分自编码器的联邦数据共享|Francesco Di Salvo, Hanh Huyen My Nguyen, Christian Ledig|<http://arxiv.org/pdf/2507.02671v1>|提出了一种基于差分隐私的生成模型进行联邦数据共享，通过提取紧凑的表征降低计算负担，同时保障隐私和提升...|
|🆕 发布|Addressing Camera Sensors Faults in Vision-Based Navigation: Simulation and Dataset Development|计算机视觉导航中处理摄像头传感器故障：仿真与数据集开发|Riccardo Gallon, Fabian Schiemenz, Alessandra Menicucci, Eberhard Gill|<http://arxiv.org/pdf/2507.02602v1>|开发了一个模拟框架和故障数据集，以训练AI检测视觉导航中的相机传感器故障。|
|📝 更新|Fairer Analysis and Demographically Balanced Face Generation for Fairer Face Verification|更公平的分析与人口统计平衡的人脸生成，以实现更公平的人脸验证|Alexandre Fournier-Montgieux, Michael Soumm, Adrian Popescu, Bertrand Luvison, Hervé Le Borgne|<http://arxiv.org/pdf/2412.03349v2>|提出了一种新的生成管道，通过深度统计分析和经典公平性指标，有效提升了人脸验证的公平性并略微提高了性能...|
|📝 更新|DeltaEdit: Exploring Text-free Training for Text-Driven Image Manipulation|DeltaEdit：探索无文本训练在文本驱动图像操作中的应用|Yueming Lyu, Tianwei Lin, Fu Li, Dongliang He, Jing Dong, Tieniu Tan|<http://arxiv.org/pdf/2303.06285v2>|提出DeltaEdit框架，通过无需文本的训练方式实现文本驱动的图像编辑。|
|📝 更新|RGE-GS: Reward-Guided Expansive Driving Scene Reconstruction via Diffusion Priors|RGE-GS：基于奖励引导的扩散先验的扩张驾驶场景重建|Sicong Du, Jiarun Liu, Qifeng Chen, Hao-Xiang Chen, Tai-Jiang Mu, Sheng Yang|<http://arxiv.org/pdf/2506.22800v2>|[代码](https://github.com/CN-ADLab/RGE-GS.); 提出了一种结合奖励引导和扩散先验的扩展重建框架RGE-GS，提高了驾驶场景重建的质量和稳定性。|
|🆕 发布|IGDNet: Zero-Shot Robust Underexposed Image Enhancement via Illumination-Guided and Denoising|IGDNet：基于光照引导和去噪的零样本稳健曝光不足图像增强|Hailong Yan, Junjian Huang, Tingwen Huang|<http://arxiv.org/pdf/2507.02445v1>|提出零样本学习框架IGDNet，无需成对训练数据，有效增强曝光不足图像并抑制噪声。|
|📝 更新|ZeroStereo: Zero-Shot Stereo Matching from Single Images|零样本立体匹配：从单张图像中实现无需成对样本的立体匹配|Xianqi Wang, Hao Yang, Gangwei Xu, Junda Cheng, Min Lin, Yong Deng, Jinliang Zang, Yurui Chen .etc.|<http://arxiv.org/pdf/2501.08654v3>|[代码](https://github.com/Windsrain/ZeroStereo.); 提出了一种无需标注数据即可生成高质量立体图像的零样本立体匹配方法。|
|🆕 发布|Mesh Silksong: Auto-Regressive Mesh Generation as Weaving Silk|《编织丝绸：作为编织丝绸的自动回归网格生成》|Gaochao Song, Zibo Zhao, Haohan Weng, Jingbo Zeng, Rongfei Jia, Shenghua Gao|<http://arxiv.org/pdf/2507.02477v1>|提出了一种高效的自动回归网格生成方法Mesh Silksong，减少序列冗余50%，实现了最优压缩率...|
|🆕 发布|Holistic Tokenizer for Autoregressive Image Generation|整体标记器用于自回归图像生成|Anlin Zheng, Haochen Wang, Yucheng Zhao, Weipeng Deng, Tiancai Wang, Xiangyu Zhang, Xiaojuan Qi|<http://arxiv.org/pdf/2507.02358v1>|[代码](https://github.com/CVMI-Lab/Hita); 提出了一种全局到局部的图像编码方法Hita，通过优先处理全局信息，提升了自回归图像生成模型的性能。|
|🆕 发布|Heeding the Inner Voice: Aligning ControlNet Training via Intermediate Features Feedback|关注内在声音：通过中间特征反馈对齐ControlNet训练|Nina Konovalova, Maxim Nikolaev, Andrey Kuznetsov, Aibek Alanov|<http://arxiv.org/pdf/2507.02321v1>|提出InnerControl训练策略，通过全程一致性损失提升生成图像的空间控制精度和质量。|
|🆕 发布|MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation|MAGIC：基于掩码引导的扩散修复与多级扰动及上下文感知对齐的少量样本异常生成|JaeHyuck Choi, MinJun Kim, JeHyeong Hong|<http://arxiv.org/pdf/2507.02314v1>|提出MAGIC方法，通过多级扰动和上下文感知对齐解决少样本异常生成中的背景破坏、对齐错误和多样性损失...|
|📝 更新|Self-Guidance: Boosting Flow and Diffusion Generation on Their Own|自引导：自主提升流和扩散生成的性能|Tiancheng Li, Weijian Luo, Zhiyang Chen, Liyuan Ma, Guo-Jun Qi|<http://arxiv.org/pdf/2412.05827v4>|提出Self-Guidance方法，通过抑制低质量样本生成，提升文本到图像生成模型的质量。|
|🆕 发布|DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation|DreamComposer++：利用多视角条件增强扩散模型以生成三维内容|Yunhan Yang, Shuo Chen, Yukun Huang, Xiaoyang Wu, Yuan-Chen Guo, Edmund Y. Lam, Hengshuang Zhao, Tong He .etc.|<http://arxiv.org/pdf/2507.02299v1>|超视距提升3D内容生成，DreamComposer++融合多视角信息增强扩散模型，实现可控视图生成。|
|🆕 发布|Spotlighting Partially Visible Cinematic Language for Video-to-Audio Generation via Self-distillation|通过自蒸馏凸显部分可见的电影语言以实现视频到音频的生成|Feizhen Huang, Yu Wu, Yutian Lin, Bo Du|<http://arxiv.org/pdf/2507.02271v1>|提出一种自蒸馏方法，使视频转音频模型能处理部分可见场景下的电影语言。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visual Contextual Attack: Jailbreaking MLLMs with Image-Driven Context Injection|视觉上下文攻击：利用图像驱动上下文注入破解大规模语言模型|Ziqi Miao, Yi Ding, Lijun Li, Jing Shao|<http://arxiv.org/pdf/2507.02844v1>|[代码](https://github.com/Dtc7w3PQ/Visco-Attack.); 提出了一种视觉驱动的攻击策略VisCo，通过构建完整的视觉语境实现高成功率的有害响应触发。|
|🆕 发布|Less is Enough: Training-Free Video Diffusion Acceleration via Runtime-Adaptive Caching|“少即是多：通过运行时自适应缓存实现无需训练的视频扩散加速”|Xin Zhou, Dingkang Liang, Kaijin Chen, Tianrui Feng, Xiwu Chen, Hongkai Lin, Yikang Ding, Feiyang Tan .etc.|<http://arxiv.org/pdf/2507.02860v1>|[代码](https://github.com/H-EmbodVis/EasyCache.); 提出EasyCache框架，通过运行时自适应缓存技术加速视频生成，无需训练且显著提升性能。|
|🆕 发布|LangScene-X: Reconstruct Generalizable 3D Language-Embedded Scenes with TriMap Video Diffusion|LangScene-X：利用TriMap视频扩散重构通用型三维语言内嵌场景|Fangfu Liu, Hao Li, Jiawei Chi, Hanyang Wang, Minghui Yang, Fudong Wang, Yueqi Duan|<http://arxiv.org/pdf/2507.02813v1>|[代码](https://liuff19.github.io/LangScene-X.); 提出LangScene-X框架，通过少量视角生成3D语言嵌入场景，实现跨场景泛化。|
|📝 更新|Modality-agnostic, patient-specific digital twins modeling temporally varying digestive motion|模态无关、患者特定的数字孪生模型，用于模拟时间变化的消化运动|Jorge Tapias Gomez, Nishant Nadkarni, Lando S. Bosma, Jue Jiang, Ergys D. Subashi, William P. Segars, James M. Balter, Mert R Sabuncu .etc.|<http://arxiv.org/pdf/2507.01909v2>|创建了患者特异性数字孪生模型以模拟消化运动，准确评估变形图像配准方法的性能。|
|🆕 发布|APT: Adaptive Personalized Training for Diffusion Models with Limited Data|APT：面向有限数据下扩散模型的自适应个性化训练|JungWoo Chae, Jiyoon Kim, JaeWoong Choi, Kyungyul Kim, Sangheum Hwang|<http://arxiv.org/pdf/2507.02687v1>|提出了一种自适应个性化训练框架APT，有效缓解了少量数据训练扩散模型时的过拟合问题，并保持了先验知识...|
|📝 更新|Enhancing Fetal Plane Classification Accuracy with Data Augmentation Using Diffusion Models|利用扩散模型进行数据增强以提高胎儿平面分类准确性|Yueying Tian, Elif Ucurum, Xudong Han, Rupert Young, Chris Chatwin, Philip Birch|<http://arxiv.org/pdf/2501.15248v2>|利用扩散模型生成合成超声图像，有效提升胎儿平面分类准确度，解决了数据稀缺问题。|
|🆕 发布|Learning few-step posterior samplers by unfolding and distillation of diffusion models|通过展开和扩散模型蒸馏学习少步后验采样器|Charlesquin Kemajou Mbakam, Jonathan Spence, Marcelo Pereyra|<http://arxiv.org/pdf/2507.02686v1>|提出了一种将深度展开与模型蒸馏结合的框架，将扩散模型转化为少步条件模型，提高了后验采样的准确性和效率...|
|📝 更新|HOI-Dyn: Learning Interaction Dynamics for Human-Object Motion Diffusion|人类-物体运动扩散的交互动态学习：HOI-Dyn|Lin Wu, Zhixiang Chen, Jianglin Lan|<http://arxiv.org/pdf/2507.01737v2>|提出了一种基于轻量级变压器的交互动力学模型，有效提升了3D人-物交互生成的真实性和一致性。|
|📝 更新|ARTalk: Speech-Driven 3D Head Animation via Autoregressive Model|ARTalk：基于自回归模型的语音驱动三维人头动画|Xuangeng Chu, Nabarun Goswami, Ziteng Cui, Hanqin Wang, Tatsuya Harada|<http://arxiv.org/pdf/2502.20323v4>|提出了一种基于自回归模型的实时语音驱动的3D头部动画生成方法，提高了唇同步准确性和动画质量。|
|🆕 发布|PosDiffAE: Position-aware Diffusion Auto-encoder For High-Resolution Brain Tissue Classification Incorporating Artifact Restoration|PosDiffAE：面向高分辨率脑组织分类的位姿感知扩散自动编码器，集成了伪迹恢复|Ayantika Das, Moitreya Chaudhuri, Koushik Bhat, Keerthi Ram, Mihail Bota, Mohanasankar Sivaprakasam|<http://arxiv.org/pdf/2507.02405v1>|整合扩散模型与编码器，创建了结构化潜空间以区分脑组织类型并实现无监督的图像修复。|
|📝 更新|MAD: Makeup All-in-One with Cross-Domain Diffusion Model|《MAD：跨域扩散模型实现妆容一体化》|Bo-Kai Ruan, Hong-Han Shuai|<http://arxiv.org/pdf/2504.02545v2>|首次提出单模型处理多种美妆任务，通过跨域扩散模型实现无参考图像的文本引导试妆。|
|📝 更新|Text-Aware Image Restoration with Diffusion Models|基于扩散模型的文本感知图像恢复|Jaewon Min, Jin Hyeon Kim, Paul Hyunbin Cho, Jaeeun Lee, Jihye Park, Minkyu Park, Sangpil Kim, Hyunhee Park .etc.|<http://arxiv.org/pdf/2506.09993v2>|[代码](https://cvlab-kaist.github.io/TAIR); 提出文本感知图像复原方法TAIR，通过集成文本特征提升复原图像中文本区域的准确性。|
|🆕 发布|Are Synthetic Videos Useful? A Benchmark for Retrieval-Centric Evaluation of Synthetic Videos|合成视频有用吗？面向检索中心评估的合成视频基准|Zecheng Zhao, Selena Song, Tong Chen, Zhi Chen, Shazia Sadiq, Yadan Luo|<http://arxiv.org/pdf/2507.02316v1>|[代码](https://jasoncodemaker.github.io/SynTVA); 提出SynTVA数据集与评估框架，专注于评价合成视频在文本到视频检索任务中的实际效用。|
|📝 更新|Non-rigid Motion Correction for MRI Reconstruction via Coarse-To-Fine Diffusion Models|通过粗到细扩散模型进行MRI重建的非刚性运动校正|Frederic Wang, Jonathan I. Tamir|<http://arxiv.org/pdf/2505.15057v3>|提出了一种基于粗到细扩散模型的方法，有效校正MRI中的非刚性运动伪迹并重建图像。|
|🆕 发布|FMOcc: TPV-Driven Flow Matching for 3D Occupancy Prediction with Selective State Space Model|FMOcc：基于TPV驱动的选择性状态空间模型的3D占据预测流匹配|Jiangxia Chen, Tongyuan Huang, Ke Song|<http://arxiv.org/pdf/2507.02250v1>|提出了一种基于流匹配和三视角选择的3D占位预测模型，有效提升了少量帧图像的预测精度和效率。|
|🆕 发布|MAC-Lookup: Multi-Axis Conditional Lookup Model for Underwater Image Enhancement|MAC-Lookup：多轴条件查找模型水下图像增强|Fanghai Yi, Zehong Zheng, Zexiao Liang, Yihang Dong, Xiyang Fang, Wangyu Wu, Xuhang Chen|<http://arxiv.org/pdf/2507.02270v1>|[代码](https://github.com/onlycatdoraemon/MAC-Lookup.); 提出了一种MAC-Lookup模型，通过多轴条件查找表技术有效提升了水下图像的颜色准确度、清晰度和对...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Long Videos to Engaging Clips: A Human-Inspired Video Editing Framework with Multimodal Narrative Understanding|从长视频到引人入胜的剪辑：一种基于多模态叙事理解的仿人视频编辑框架|Xiangfeng Wang, Xiao Li, Yadong Wei, Xueyu Song, Yang Song, Xiaoqiang Xia, Fangrui Zeng, Zaiyi Chen .etc.|<http://arxiv.org/pdf/2507.02790v1>|提出了一种基于多模态叙事理解的自动视频编辑框架，有效提升了长视频内容压缩后的连贯性和吸引力。|
|📝 更新|The Evolution of Dataset Distillation: Toward Scalable and Generalizable Solutions|数据集精炼的演变：迈向可扩展和普适性解决方案|Ping Liu, Jiawei Du|<http://arxiv.org/pdf/2502.05673v3>|系统综述了数据集精简的最新进展，提出高效有效的SRe2L框架及无损压缩技术，拓宽了应用领域。|
|📝 更新|Learning Traffic Anomalies from Generative Models on Real-Time Observations|从生成模型中学习实时观测下的交通异常|Fotis I. Giasemis, Alexandros Sopasakis|<http://arxiv.org/pdf/2502.01391v3>|利用生成对抗网络和图神经网络结合，有效检测实时交通异常并降低误报率。|
|🆕 发布|AvatarMakeup: Realistic Makeup Transfer for 3D Animatable Head Avatars|《AvatarMakeup：面向3D可动画化头像的真实感化妆迁移》|Yiming Zhong, Xiaolin Zhang, Ligang Liu, Yao Zhao, Yunchao Wei|<http://arxiv.org/pdf/2507.02419v1>|提出AvatarMakeup方法，通过预训练扩散模型实现3D头像的逼真化妆转移，确保动态表情中的一致...|
|🆕 发布|Flow-CDNet: A Novel Network for Detecting Both Slow and Fast Changes in Bitemporal Images|流-变化检测网络：一种用于检测双时态图像中慢速和快速变化的新型网络|Haoxuan Li, Chenxu Wei, Haodong Wang, Xiaomeng Hu, Boyuan An, Lingyan Ran, Baosen Zhang, Jin Jin .etc.|<http://arxiv.org/pdf/2507.02307v1>|提出了一种双分支网络Flow-CDNet，能同时检测图像中的缓慢和快速变化。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RGC-VQA: An Exploration Database for Robotic-Generated Video Quality Assessment|机器人生成视频质量评估探索数据库：RGC-VQA|Jianing Jin, Jiangyong Ying, Huiyu Duan, Liu Yang, Sijing Wu, Yunhao Li, Yushuo Zheng, Xiongkuo Min .etc.|<http://arxiv.org/pdf/2506.23852v2>|[代码](https://github.com/IntMeGroup/RGC-VQA.); 提出首个针对机器人生成视频质量评估的数据库，揭示了现有视频质量评估模型的局限性。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans|“LiteReality：从RGB-D扫描中重建图形就绪的3D场景”|Zhening Huang, Xiaoyang Wu, Fangcheng Zhong, Hengshuang Zhao, Matthias Nießner, Joan Lasenby|<http://arxiv.org/pdf/2507.02861v1>|提出LiteReality方法，将RGB-D扫描的室内环境转化为紧凑、逼真且互动的3D虚拟副本。|
|🆕 发布|Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory|点三维重建：具有显式空间指针记忆的流式三维重建|Yuqi Wu, Wenzhao Zheng, Jie Zhou, Jiwen Lu|<http://arxiv.org/pdf/2507.02863v1>|[代码](https://github.com/YkiWu/Point3R.); 提出Point3R框架，通过显式空间指针记忆实现流式密集3D重建，提升信息容量和处理效率。|
|🆕 发布|SIU3R: Simultaneous Scene Understanding and 3D Reconstruction Beyond Feature Alignment|SIU3R：超越特征对齐的同步场景理解与三维重建|Qi Xu, Dongxu Wei, Lingzhe Zhao, Wenpu Li, Zhangchi Huang, Shunping Ji, Peidong Liu|<http://arxiv.org/pdf/2507.02705v1>|提出了SIU3R，一种无需特征对齐的框架，实现了从无定位图像中进行通用性的同时场景理解和3D重建。|
|🆕 发布|MoGe-2: Accurate Monocular Geometry with Metric Scale and Sharp Details|MoGe-2:具有度量尺度和清晰细节的单目几何精确重建|Ruicheng Wang, Sicheng Xu, Yue Dong, Yu Deng, Jianfeng Xiang, Zelong Lv, Guangzhong Sun, Xin Tong .etc.|<http://arxiv.org/pdf/2507.02546v1>|提出MoGe-2模型，从单张图片恢复具有精确度量尺度和细节的3D点图。|
|🆕 发布|3D Heart Reconstruction from Sparse Pose-agnostic 2D Echocardiographic Slices|从稀疏姿态无关的二维超声心动图切片进行三维心脏重建|Zhurong Chen, Jinhua Chen, Wei Zhuo, Wufeng Xue, Dong Ni|<http://arxiv.org/pdf/2507.02411v1>|提出了一种从稀疏二维超声切片重建个性化三维心脏结构的新框架，显著提升了左心室体积估算的准确性。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HyperGaussians: High-Dimensional Gaussian Splatting for High-Fidelity Animatable Face Avatars|超高斯分布：用于高保真动画化人脸虚拟形象的高维高斯散点绘制|Gent Serifi, Marcel C. Bühler|<http://arxiv.org/pdf/2507.02803v1>|提出高维多变量高斯模型HyperGaussians，通过增加维度和特殊技巧提升面部动画真实感。|
|📝 更新|LUDO: Low-Latency Understanding of Deformable Objects using Point Cloud Occupancy Functions|LUDO：利用点云占用函数实现对可变形物体的低延迟理解|Pit Henrich, Franziska Mathis-Ullrich, Paul Maria Scheikl|<http://arxiv.org/pdf/2411.08777v5>|提出LUDO方法，快速准确重构可变形物体的形状及内部结构，提高医疗手术精准度。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Parametric shape models for vessels learned from segmentations via differentiable voxelization|参数化形状模型：通过可微分体素化从分割中学习血管|Alina F. Dima, Suprosanna Shit, Huaqi Qiu, Robbie Holland, Tamara T. Mueller, Fabio Antonio Musio, Kaiyuan Yang, Bjoern Menze .etc.|<http://arxiv.org/pdf/2507.02576v1>|提出了一种结合不同表示的血管参数化形状模型学习方法，通过可微分体素化直接从分割中学习形状参数。|
|🆕 发布|L-VAE: Variational Auto-Encoder with Learnable Beta for Disentangled Representation|L-VAE：具有可学习Beta的变分自动编码器用于解耦表示|Hazal Mogultay Ozcan, Sinan Kalkan, Fatos T. Yarman-Vural|<http://arxiv.org/pdf/2507.02619v1>|提出了一种学习型VAE模型，通过同时学习损失函数的权重和模型参数，有效平衡了重构保真度和特征解耦。|
|📝 更新|Stereo Any Video: Temporally Consistent Stereo Matching|立体任意视频：时间一致性的立体匹配|Junpeng Jing, Weixun Luo, Ye Mao, Krystian Mikolajczyk|<http://arxiv.org/pdf/2503.05549v2>|提出了一种无需辅助信息即可实现时空一致立体匹配的框架，通过创新架构显著提升性能。|
|🆕 发布|MC-INR: Efficient Encoding of Multivariate Scientific Simulation Data using Meta-Learning and Clustered Implicit Neural Representations|MC-INR：使用元学习和聚类隐式神经表示高效编码多变量科学模拟数据|Hyunsoo Son, Jeonghyun Noh, Suemin Jeon, Chaoli Wang, Won-Ki Jeong|<http://arxiv.org/pdf/2507.02494v1>|提出MC-INR框架，通过元学习和聚类处理复杂结构的多变量科学数据，提升数据编码效率。|
|🆕 发布|LocalDyGS: Multi-view Global Dynamic Scene Modeling via Adaptive Local Implicit Feature Decoupling|局部动态全局场景建模：通过自适应局部隐式特征解耦的多视角动态场景建模|Jiahao Wu, Rui Peng, Jianbo Jiao, Jiayu Yang, Luyang Tang, Kaiqiang Xiong, Jie Liang, Jinbo Yan .etc.|<http://arxiv.org/pdf/2507.02363v1>|[代码](https://wujh2001.github.io/LocalDyGS); 提出LocalDyGS方法，通过局部空间分解和时间特征解耦，实现了对大规模动态场景的建模。|


## 时序视觉分析 (Temporal Visual Analysis)


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|USAD: An Unsupervised Data Augmentation Spatio-Temporal Attention Diffusion Network|USAD：一种无监督数据增强时空注意力扩散网络|Ying Yu, Hang Xiao, Siyao Li, Jiarui Li, Haotian Tang, Hanyu Liu, Chao Li|<http://arxiv.org/pdf/2507.02827v1>|提出了一种无监督数据增强的时空注意力扩散网络，通过多尺度特征提取和注意力机制显著提升了人类活动识别的...|
|🆕 发布|Confidence-driven Gradient Modulation for Multimodal Human Activity Recognition: A Dynamic Contrastive Dual-Path Learning Approach|基于置信度的梯度调制用于多模态人体行为识别：动态对比双路径学习方法|Panpan Ji, Junni Song, Hang Xiao, Hanyu Liu, Chao Li|<http://arxiv.org/pdf/2507.02826v1>|提出动态对比双路径网络DCDP-HAR，通过信心驱动的梯度调制缓解多模态数据竞争问题。|
|📝 更新|CMD-HAR: Cross-Modal Disentanglement for Wearable Human Activity Recognition|CMD-HAR：基于跨模态解耦的穿戴式人体活动识别|Hanyu Liu, Siyao Li, Ying Yu, Yixuan Jiang, Hang Xiao, Jingxi Long, Haotian Tang, Chao Li|<http://arxiv.org/pdf/2503.21843v2>|提出一种多模态解耦策略，通过时空注意力分解融合处理传感器数据混合分布问题，提升可穿戴设备中人体活动识...|
|📝 更新|Task-Adapter++: Task-specific Adaptation with Order-aware Alignment for Few-shot Action Recognition|任务适配器++：面向少样本动作识别的顺序感知对齐任务特定适配方法|Congqi Cao, Peiheng Han, Yueran zhang, Yating Yu, Qinyi Lv, Lingtong Min, Yanning zhang|<http://arxiv.org/pdf/2505.06002v2>|[代码](https://github.com/Jaulin-Bage/Task-Adapter-pp.); Task-Adapter++通过任务特定适应和顺序感知对齐，提升了少量样本动作识别的准确性和泛化能力...|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CanonSwap: High-Fidelity and Consistent Video Face Swapping via Canonical Space Modulation|《CanonSwap：通过规范空间调制实现高保真且一致性的视频面部交换》|Xiangyang Luo, Ye Zhu, Yunfei Liu, Lijian Lin, Cong Wan, Zijian Cai, Shao-Lun Huang, Yu Li|<http://arxiv.org/pdf/2507.02691v1>|[代码](https://luoxyhappy.github.io/CanonSwap); 提出了一种解耦运动与外观信息的视频换脸框架CanonSwap，实现了高保真度和一致性的视频人脸替换。|
|🆕 发布|AuroraLong: Bringing RNNs Back to Efficient Open-Ended Video Understanding|极光长时：将循环神经网络重新带回高效开放式视频理解|Weili Xu, Enxin Song, Wenhao Chai, Xuexiang Wen, Tian Ye, Gaoang Wang|<http://arxiv.org/pdf/2507.02591v1>|提出线性RNN模型AuroraLong，以处理长视频理解的高计算复杂度和内存成本问题，实现高效开放视...|
|🆕 发布|UVLM: Benchmarking Video Language Model for Underwater World Understanding|水下世界理解的视频语言模型基准测试：UVLM|Xizhe Xue, Yang Zhou, Dawei Yan, Ying Li, Haokui Zhang, Rong Xiao|<http://arxiv.org/pdf/2507.02373v1>|提出UVLM水下观测基准，通过结合人类专家知识和AI模型，提升视频语言模型对水下世界的理解能力。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CrowdTrack: A Benchmark for Difficult Multiple Pedestrian Tracking in Real Scenarios|CrowdTrack：真实场景中困难多行人跟踪的基准测试|Teng Fu, Yuwen Chen, Zhuofan Chen, Mengyang Zhao, Bin Li, Xiangyang Xue|<http://arxiv.org/pdf/2507.02479v1>|[代码](https://github.com/loseevaya/CrowdTrack); 提出复杂场景下多行人跟踪的大型困难数据集CrowdTrack，促进算法在复杂环境中的有效性研究。|
|🆕 发布|A Novel Tuning Method for Real-time Multiple-Object Tracking Utilizing Thermal Sensor with Complexity Motion Pattern|一种利用热传感器针对复杂运动模式实现实时多目标跟踪的新型调整方法|Duong Nguyen-Ngoc Tran, Long Hoang Pham, Chi Dai Tran, Quoc Pham-Nam Ho, Huy-Hung Nguyen, Jae Wook Jeon|<http://arxiv.org/pdf/2507.02408v1>|提出了一种针对热成像中行人跟踪的新颖调参方法，有效处理复杂运动模式，提高实时跟踪准确性。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A robust and versatile deep learning model for prediction of the arterial input function in dynamic small animal $\left[^{18}\text{F}\right]$FDG PET imaging|一种稳健且多功能的深度学习模型，用于动态小动物 $\left[^{18}\text{F}\right]$FDG PET 成像中动脉输入函数的预测|Christian Salomonsen, Luigi Tommaso Luppino, Fredrik Aspheim, Kristoffer Wickstrøm, Elisabeth Wetzer, Michael Kampffmeyer, Rodrigo Berzaghi, Rune Sundset .etc.|<http://arxiv.org/pdf/2507.02367v1>|提出了一种基于深度学习的非侵入式方法，从PET成像直接预测动脉输入函数，无需进行血液采样。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MISCGrasp: Leveraging Multiple Integrated Scales and Contrastive Learning for Enhanced Volumetric Grasping|MISCGrasp：利用多尺度整合与对比学习增强立体抓取|Qingyu Fan, Yinghao Cai, Chao Li, Chunting Jiao, Xudong Zheng, Tao Lu, Bin Liang, Shuo Wang|<http://arxiv.org/pdf/2507.02672v1>|[代码](https://miscgrasp.github.io/.); 提出MISCGrasp方法，融合多尺度特征提取与对比学习，实现自适应抓取不同形状大小的物体。|
|🆕 发布|Temporally-Aware Supervised Contrastive Learning for Polyp Counting in Colonoscopy|时间感知的监督对比学习在肠镜检查中用于息肉计数|Luca Parolari, Andrea Cherubini, Lamberto Ballan, Carlo Biffi|<http://arxiv.org/pdf/2507.02493v1>|[代码](https://github.com/lparolari/temporally-aware-polyp-counting.); 引入监督对比损失结合时间感知软目标，提升结肠镜检查中息肉计数准确性和聚类鲁棒性。|
|📝 更新|Anatomical Foundation Models for Brain MRIs|脑部MRI的解剖基础模型|Carlo Alberto Barbano, Matteo Brunello, Benoit Dufumier, Marco Grangetto|<http://arxiv.org/pdf/2408.07079v4>|[代码](https://github.com/EIDOSLAB/AnatCL.); 提出AnatCL模型，利用解剖信息进行弱对比学习，提升脑部MRI图像在多种任务中的表现。|


### 跨模态一致性学习 (Cross-modal Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MTCNet: Motion and Topology Consistency Guided Learning for Mitral Valve Segmentationin 4D Ultrasound|MTCNet：基于运动和拓扑一致性引导的二维超声心动图中二尖瓣分割学习|Rusi Chen, Yuanting Yang, Jiezhi Yao, Hongning Song, Ji Zhang, Yongsong Zhou, Yuhao Huang, Ronghao Yang .etc.|<http://arxiv.org/pdf/2507.00660v2>|[代码](https://github.com/crs524/MTCNet.); 定位4D超声心动图中的二尖瓣，提出MTCNet网络，利用运动和拓扑一致性实现高效分割。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HAPI: A Model for Learning Robot Facial Expressions from Human Preferences|HAPI：一种从人类偏好中学习机器人面部表情的模型|Dongsheng Yang, Qianying Liu, Wataru Sato, Takashi Minato, Chaoran Liu, Shin'ya Nishida|<http://arxiv.org/pdf/2503.17046v2>|提出了一种利用人类反馈的排名学习框架，有效提升了机器人面部表情的自然度和社交共鸣。|
|📝 更新|Towards an Explainable Comparison and Alignment of Feature Embeddings|面向特征嵌入的可解释比较与对齐|Mohammad Jalali, Bahar Dibaei Nia, Farzan Farnia|<http://arxiv.org/pdf/2506.06231v2>|[代码](https://mjalali.github.io/SPEC); 提出了一种比较和校准特征嵌入的解释性框架，通过分析样本聚类差异来优化特征表示。|
|📝 更新|Sequence-aware Pre-training for Echocardiography Probe Movement Guidance|序列感知的超声心动图探头运动引导预训练|Haojun Jiang, Teng Wang, Zhenguo Sun, Yulin Wang, Yang Yue, Yu Sun, Ning Jia, Meng Li .etc.|<http://arxiv.org/pdf/2408.15026v2>|提出了一种序列感知的自监督预训练方法，用于个性化心脏结构学习，有效减少超声探头引导误差。|
|📝 更新|Towards Universal & Efficient Model Compression via Exponential Torque Pruning|面向通用与高效模型压缩的指数扭矩剪枝方法|Sarthak Ketanbhai Modi, Zi Pong Lim, Shourya Kuchhal, Yushi Cao, Yupeng Cheng, Yon Shin Teo, Shang-Wei Lin, Zhiming Li|<http://arxiv.org/pdf/2506.22015v3>|提出指数扭矩剪枝法，高效压缩模型同时保持准确度。|
|📝 更新|PAID: Pairwise Angular-Invariant Decomposition for Continual Test-Time Adaptation|PAID：成对角度不变分解用于持续测试时适应|Kunyu Wang, Xueyang Fu, Yuanfei Bao, Chengjie Ge, Chengzhi Cao, Wei Zhai, Zheng-Jun Zha|<http://arxiv.org/pdf/2506.02453v2>|提出了一种通过保持预训练权重间的角度结构来适应不断变化环境的连续测试时适应方法PAID。|
|🆕 发布|DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning|DoMIX：一种在微调中高效利用领域知识的框架|Dohoon Kim, Donghun Kang, Taesup Moon|<http://arxiv.org/pdf/2507.02302v1>|[代码](https://github.com/dohoonkim-ai/DoMIX.); 提出DoMIX方法，利用LoRA模块降低计算成本，实现高效并行且适应不同任务需求的域自适应预训练。|
|📝 更新|Customizable ROI-Based Deep Image Compression|基于自定义感兴趣区域的深度图像压缩|Jian Jin, Fanxin Xia, Feng Ding, Xinfeng Zhang, Meiqin Liu, Yao Zhao, Weisi Lin, Lili Meng|<http://arxiv.org/pdf/2507.00373v3>|提出了一种可定制区域优先的深度图像压缩框架，通过文本控制和灵活质量分配优化了感兴趣区域的压缩质量。|
|📝 更新|Uncertainty-Guided Coarse-to-Fine Tumor Segmentation with Anatomy-Aware Post-Processing|基于不确定性指导的粗到细肿瘤分割及解剖感知后处理|Ilkin Sevgi Isler, David Mohaisen, Curtis Lisle, Damla Turgut, Ulas Bagci|<http://arxiv.org/pdf/2504.12215v2>|提出了一种结合不确定性指导和解剖学知识优化的粗到细肿瘤分割框架，显著提升了分割准确性和边界定位。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AI Flow: Perspectives, Scenarios, and Approaches|人工智能流：视角、场景与方法|Hongjun An, Wenhan Hu, Sida Huang, Siqi Huang, Ruanjun Li, Yuanzhi Liang, Jiawei Shao, Yiliang Song .etc.|<http://arxiv.org/pdf/2506.12479v2>|提出AI Flow框架，整合设备-边缘-云资源，通过家族模型和增强连通性实现高效智能服务。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CineMyoPS: Segmenting Myocardial Pathologies from Cine Cardiac MR|电影心肌PS：从电影心脏磁共振中分割心肌病变|Wangbin Ding, Lei Li, Junyi Qiu, Bogen Lin, Mingjing Yang, Liqin Huang, Lianming Wu, Sihan Wang .etc.|<http://arxiv.org/pdf/2507.02289v1>|提出了一种深度学习模型CineMyoPS，仅通过无对比剂的心脏 cine MR图像准确分割心肌病变区...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Fair Deepfake Detectors Can Generalize|公平的深度伪造检测器能够泛化|Harry Cheng, Ming-Hui Liu, Yangyang Guo, Tianyi Wang, Liqiang Nie, Mohan Kankanhalli|<http://arxiv.org/pdf/2507.02645v1>|首次揭示公平性与泛化能力的因果关系，提出DAID框架实现检测性能的提升。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Real-time Image-based Lighting of Glints|基于实时图像的光照反光效果渲染|Tom Kneiphof, Reinhard Klein|<http://arxiv.org/pdf/2507.02674v1>|提出了一种实时基于图像的光照算法，用于高效渲染具有闪耀效果的物体表面。|
|📝 更新|Assessing the Uncertainty and Robustness of the Laptop Refurbishing Software|评估笔记本电脑翻新软件的不确定性和鲁棒性|Chengjie Lu, Jiahui Wu, Shaukat Ali, Mikkel Labori Olsen|<http://arxiv.org/pdf/2409.03782v2>|评估了笔记本电脑翻新软件中 sticker 检测模型的不确定性和鲁棒性，采用 Monte Carlo...|
|📝 更新|Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability|语义结构感知的生成攻击以提高对抗性迁移性|Jongoh Jeong, Hunmin Yang, Jaeseok Jeong, Kuk-Jin Yoon|<http://arxiv.org/pdf/2506.18248v2>|提出了一种语义结构感知的生成攻击框架，通过利用生成模型中的语义信息，有效提升了对抗性扰动在不同模型间...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Weakly Supervised Segmentation Framework for Thyroid Nodule Based on High-confidence Labels and High-rationality Losses|基于高置信度标签与高合理性损失的甲状腺结节弱监督分割框架|Jianning Chi, Zelan Li, Geng Lin, MingYang Sun, Xiaosheng Yu|<http://arxiv.org/pdf/2502.19707v2>|[代码](https://github.com/bluehenglee/MLI-MSC.); 提出了一种基于高置信度伪标签和合理损失函数的弱监督甲状腺结节分割框架，有效解决了低置信度伪标签和低合...|
|🆕 发布|Detecting Multiple Diseases in Multiple Crops Using Deep Learning|多作物中多种病害的检测方法研究：基于深度学习|Vivek Yadav, Anugrah Jain|<http://arxiv.org/pdf/2507.02517v1>|提出了一种深学习模型，用于检测多种作物的多种疾病，提高了准确性和作物疾病覆盖范围。|
|🆕 发布|Determination Of Structural Cracks Using Deep Learning Frameworks|基于深度学习框架的结构裂缝检测|Subhasis Dasgupta, Jaydip Sen, Tuhina Halder|<http://arxiv.org/pdf/2507.02416v1>|提出了一种结合残差U-Net和卷积块元模型的深度学习架构，显著提升了结构裂缝检测的准确性和效率。|
|🆕 发布|Wildlife Target Re-Identification Using Self-supervised Learning in Non-Urban Settings|使用非城市环境下自监督学习的野生动物目标重识别|Mufhumudzi Muthivhi, Terence L. van Zyl|<http://arxiv.org/pdf/2507.02403v1>|[代码](https://github.com/pxpana/SSLWildlife.); 提出了一种无监督学习框架，通过自监督学习实现野生动物目标重识别，无需依赖标注数据，提高了模型的鲁棒性...|
|🆕 发布|Holistic Continual Learning under Concept Drift with Adaptive Memory Realignment|在概念漂移下的整体持续学习与自适应记忆重排|Alif Ashrafee, Jedrzej Kozal, Michal Wozniak, Bartosz Krawczyk|<http://arxiv.org/pdf/2507.02310v1>|提出了一种应对概念漂移的持续学习方法，通过自适应记忆重排减少标注和计算需求。|
|📝 更新|Adapter-Enhanced Semantic Prompting for Continual Learning|适配器增强的语义提示用于持续学习|Baocai Yin, Ji Zhao, Huajie Jiang, Ningning Hou, Yongli Hu, Amin Beheshti, Ming-Hsuan Yang, Yuankai Qi|<http://arxiv.org/pdf/2412.11074v3>|提出了一种轻量级框架AESP，通过语义提示和适配器技术提高连续学习中的泛化能力和特征适应性。|
|📝 更新|Rejoining fragmented ancient bamboo slips with physics-driven deep learning|利用物理驱动的深度学习技术重组破碎的古竹简|Jinchi Zhu, Zhou Zhao, Hailong Lei, Xiaoguang Wang, Jialiang Lu, Jing Li, Qianqian Tang, Jiachen Shen .etc.|<http://arxiv.org/pdf/2505.08601v2>|提出WisePanda框架，利用物理原理生成数据，高效复原破碎竹简。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SURE-VQA: Systematic Understanding of Robustness Evaluation in Medical VQA Tasks|SURE-VQA：医学视觉问答任务中鲁棒性评估的系统理解|Kim-Celine Kahl, Selen Erkan, Jeremias Traub, Carsten T. Lüth, Klaus Maier-Hein, Lena Maier-Hein, Paul F. Jaeger|<http://arxiv.org/pdf/2411.19688v3>|[代码](https://github.com/IML-DKFZ/sure-vqa.); 提出SURE-VQA框架，系统评估医学视觉问答模型在真实世界数据分布偏移下的鲁棒性。|
|📝 更新|Lightweight Structure-Aware Attention for Visual Understanding|轻量级结构感知注意力机制用于视觉理解|Heeseung Kwon, Francisco M. Castro, Manuel J. Marin-Jimenez, Nicolas Guil, Karteek Alahari|<http://arxiv.org/pdf/2211.16289v2>|提出了一种结构感知的轻量级注意力机制，通过学习结构模式提升表示能力并降低计算复杂度。|
|📝 更新|Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs|标题翻译为：《跨越语言：评估多模态大型语言模型中跨语言一致性的基准》|Hao Wang, Pinzhi Huang, Jihan Yang, Saining Xie, Daisuke Kawahara|<http://arxiv.org/pdf/2505.15075v2>|提出两个新基准KnowRecall和VisRecall，评估多模态大语言模型在不同语言中的表现一致性...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|BANet: Bilateral Aggregation Network for Mobile Stereo Matching|BANet：用于移动立体匹配的双侧聚合网络|Gangwei Xu, Jiaxin Liu, Xianqi Wang, Junda Cheng, Yong Deng, Jinliang Zang, Yurui Chen, Xin Yang|<http://arxiv.org/pdf/2503.03259v2>|[代码](https://github.com/gangweix/BANet); 提出了一种双边聚合网络，通过分离细节和平滑信息，仅用2D卷积实现高质量立体匹配，提升了移动设备上的准...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Towards autonomous photogrammetric forest inventory using a lightweight under-canopy robotic drone|面向自主摄影测量森林清查的轻量级林下机器人无人机|Väinö Karjalainen, Niko Koivumäki, Teemu Hakala, Jesse Muhojoki, Eric Hyyppä, Anand George, Juha Suomalainen, Eija Honkavaara|<http://arxiv.org/pdf/2501.12073v2>|开发了一款轻量级机器人无人机，实现了森林下方自主飞行与高精度数据采集。|
|📝 更新|PAD: Phase-Amplitude Decoupling Fusion for Multi-Modal Land Cover Classification|PAD: 相位-幅度解耦融合用于多模态土地覆盖分类|Huiling Zheng, Xian Zhong, Bin Liu, Yi Xiao, Bihan Wen, Xiaofeng Li|<http://arxiv.org/pdf/2504.19136v2>|[代码](https://github.com/RanFeng2/PAD.); 提出了一种相位-幅度解耦融合方法，有效解决了多模态遥感图像融合中的信息损失问题。|
|📝 更新|RFWNet: A Lightweight Remote Sensing Object Detector Integrating Multiscale Receptive Fields and Foreground Focus Mechanism|RFWNet：一种集成多尺度感受野与前景聚焦机制的超轻量级遥感目标检测器|Yujie Lei, Wenjie Sun, Sen Jia, Qingquan Li, Jie Zhang|<http://arxiv.org/pdf/2503.00545v2>|提出了一种集成多尺度感受野和前景聚焦机制的轻量级遥感对象检测算法，有效提升了检测准确性和速度。|
|📝 更新|Good Representation, Better Explanation: Role of Convolutional Neural Networks in Transformer-Based Remote Sensing Image Captioning|好的表征，更好的解释：卷积神经网络在基于Transformer的遥感图像标注中的作用|Swadhin Das, Saarthak Gupta, Kamal Kumar, Raksha Sharma|<http://arxiv.org/pdf/2502.16095v2>|系统评估了不同卷积神经网络在遥感图像标注中的效果，证明了特定架构能显著提升描述质量。|
|🆕 发布|ViRefSAM: Visual Reference-Guided Segment Anything Model for Remote Sensing Segmentation|ViRefSAM：视觉参考引导的遥感分割一切模型|Hanbo Bi, Yulong Xu, Ya Li, Yongqiang Mao, Boyuan Tong, Chongyang Li, Chunbo Lang, Wenhui Diao .etc.|<http://arxiv.org/pdf/2507.02294v1>|提出ViRefSAM方法，利用少量参考图像自动指导SAM进行遥感图像分割，克服了手动构建提示和域适应...|
|🆕 发布|Cross-domain Hyperspectral Image Classification based on Bi-directional Domain Adaptation|基于双向域自适应的跨域高光谱图像分类|Yuxiang Zhang, Wei Li, Wen Jia, Mengmeng Zhang, Ran Tao, Shunlin Liang|<http://arxiv.org/pdf/2507.02268v1>|[代码](https://github.com/YuxiangZhang-BIT/IEEE_TCSVT_BiDA.); 提出双向域自适应框架，有效提升跨域高光谱图像分类的适应性和分离性。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AIGI-Holmes: Towards Explainable and Generalizable AI-Generated Image Detection via Multimodal Large Language Models|AIGI-Holmes：通过多模态大型语言模型实现可解释和泛化的AI生成图像检测|Ziyin Zhou, Yunpeng Luo, Yuanchen Wu, Ke Sun, Jiayi Ji, Ke Yan, Shouhong Ding, Xiaoshuai Sun .etc.|<http://arxiv.org/pdf/2507.02664v1>|提出了一种结合多模态大语言模型和三阶段训练框架的AI生成图像检测方法，实现了可验证的解释和更强的泛化...|
|📝 更新|Similarity Memory Prior is All You Need for Medical Image Segmentation|相似性记忆先验是进行医学图像分割的全部所需|Tang Hao, Guo ZhiQing, Wang LieJun, Liu Chao|<http://arxiv.org/pdf/2507.00585v2>|[代码](https://github.com/vpsg-research/Sim-MPNet.); 提出相似性记忆先验网络Sim-MPNet，通过动态记忆权重损失注意机制提升医疗图像分割性能。|
|🆕 发布|Structure-aware Semantic Discrepancy and Consistency for 3D Medical Image Self-supervised Learning|结构感知的语义差异与一致性在三维医学图像自监督学习中的应用|Tan Pan, Zhaorui Tan, Kaiyu Guo, Dongli Xu, Weidi Xu, Chen Jiang, Xin Guo, Yuan Qi .etc.|<http://arxiv.org/pdf/2507.02581v1>|提出结构感知的语义差异与一致性框架，提升3D医疗图像自监督学习的结构化表征效果。|
|📝 更新|Understanding-informed Bias Mitigation for Fair CMR Segmentation|基于理解信息的偏见缓解以实现公平的CMR分割|Tiarna Lee, Esther Puyol-Antón, Bram Ruijsink, Pier-Giorgio Masci, Louise Keehn, Phil Chowienczyk, Emily Haseler, Miaojing Shi .etc.|<http://arxiv.org/pdf/2503.17089v2>|提出了一种结合图像裁剪和过采样技术的公平CMR图像分割方法，有效缓解了种族偏见问题。|
|🆕 发布|MedFormer: Hierarchical Medical Vision Transformer with Content-Aware Dual Sparse Selection Attention|MedFormer：具有内容感知双稀疏选择注意力的分层医学视觉变换器|Zunhui Xia, Hongxing Li, Libin Lan|<http://arxiv.org/pdf/2507.02488v1>|[代码](https://github.com/XiaZunhui/MedFormer.); MedFormer通过金字塔结构和内容感知的双稀疏选择注意力，提升了医疗图像识别的通用性和效率。|
|📝 更新|Deep Transfer Learning for Kidney Cancer Diagnosis|深度迁移学习在肾脏癌诊断中的应用|Yassine Habchi, Hamza Kheddar, Yassine Himeur, Mohamed Chahine Ghanem, Abdelkrim Boukabou, Shadi Atalla, Wathiq Mansoor, Hussain Al-Ahmad|<http://arxiv.org/pdf/2408.04318v2>|提出深度迁移学习方法，提升肾癌诊断准确度并降低计算需求。|
|🆕 发布|F^2TTA: Free-Form Test-Time Adaptation on Cross-Domain Medical Image Classification via Image-Level Disentangled Prompt Tuning|F^2TTA:基于图像级解耦提示调谐的跨域医学图像分类自由形式测试时适应|Wei Li, Jingyang Zhang, Lihao Liu, Guoan Wang, Junjun He, Yang Chen, Lixu Gu|<http://arxiv.org/pdf/2507.02437v1>|[代码](https://github.com/mar-cry/F2TTA.); 提出了一种应对医疗图像领域片段随机变化的自适应方法，通过图像级解耦提示调整和知识重用提升分类准确性。|
|🆕 发布|TABNet: A Triplet Augmentation Self-Recovery Framework with Boundary-Aware Pseudo-Labels for Medical Image Segmentation|TABNet：一种具有边界感知伪标签的三元组增强自恢复框架用于医学图像分割|Peilin Zhang, Shaouxan Wua, Jun Feng, Zhuo Jin, Zhizezhang Gao, Jingkun Chen, Yaqiong Xing, Xiao Zhang|<http://arxiv.org/pdf/2507.02399v1>|提出TABNet框架，通过增强特征学习和边界建模，在弱监督医疗图像分割中取得显著性能提升。|
|🆕 发布|Neural Network-based Study for Rice Leaf Disease Recognition and Classification: A Comparative Analysis Between Feature-based Model and Direct Imaging Model|基于神经网络的稻叶病害识别与分类研究：基于特征模型与直接成像模型的比较分析|Farida Siddiqi Prity, Mirza Raquib, Saydul Akbar Murad, Md. Jubayar Alam Rafi, Md. Khairul Bashar Bhuiyan, Anupam Kumar Bairagi|<http://arxiv.org/pdf/2507.02322v1>|对比分析了基于特征提取和直接图像输入的神经网络模型在水稻叶片病害识别上的性能，证明了特征分析模型在分...|
|📝 更新|Bi-modality medical images synthesis by a bi-directional discrete process matching method|双向离散过程匹配法的双模态医学图像合成|Zhe Xiong, Qiaoqiao Ding, Xiaoqun Zhang|<http://arxiv.org/pdf/2409.03977v3>|提出了一种双向离散过程匹配的生成模型Bi-DPM，有效提升了双向医学图像合成的质量和效率。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Diffusion-Based Generative Models for 3D Occupancy Prediction in Autonomous Driving|基于扩散的生成模型在自动驾驶中的三维占据预测应用|Yunshen Wang, Yicheng Liu, Tianyuan Yuan, Yingshi Liang, Xiuyu Yang, Honggang Zhang, Hang Zhao|<http://arxiv.org/pdf/2505.23115v2>|将3D占用预测转化为生成模型任务，使用扩散模型提高预测一致性及对噪声的鲁棒性。|
|🆕 发布|Understanding Trade offs When Conditioning Synthetic Data|理解当调节合成数据时的权衡考量|Brandon Trabucco, Qasim Wani, Benjamin Pikus, Vasu Sharma|<http://arxiv.org/pdf/2507.02217v1>|探究合成数据条件策略对质量的影响，发现布局条件在多样性增加时更优，显著提升检测精度。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Linear Attention with Global Context: A Multipole Attention Mechanism for Vision and Physics|线性注意力与全局上下文：一种适用于视觉与物理的多极注意力机制|Alex Colagrande, Paul Caillon, Eva Feillet, Alexandre Allauzen|<http://arxiv.org/pdf/2507.02748v1>|[代码](https://github.com/AlexColagrande/MANO.); 提出了一种多极注意力机制MANO，以线性复杂度处理高分辨率输入，同时保持全局上下文。|
|🆕 发布|IMASHRIMP: Automatic White Shrimp (Penaeus vannamei) Biometrical Analysis from Laboratory Images Using Computer Vision and Deep Learning|IMASHRIMP：利用计算机视觉和深度学习对实验室图像中的白虾（凡纳对虾）进行自动生物特征分析|Abiam Remache González, Meriem Chagour, Timon Bijan Rüth, Raúl Trapiella Cañedo, Marina Martínez Soler, Álvaro Lorenzo Felipe, Hyun-Suk Shin, María-Jesús Zamorano Serrano .etc.|<http://arxiv.org/pdf/2507.02519v1>|[代码](https://github.com/AbiamRemacheGonzalez/ImaShrimp-public); 提出IMASHRIMP系统，利用深度学习和计算机视觉技术自动化分析白虾形态，减少人为误差并提高遗传选...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Towards a Novel Measure of User Trust in XAI Systems|面向可解释性人工智能系统中用户信任度的新型度量方法|Miquel Miró-Nicolau, Gabriel Moyà-Alcover, Antoni Jaume-i-Capó, Manuel González-Hidalgo, Adel Ghazel, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho|<http://arxiv.org/pdf/2405.05766v2>|提出了一种新的XAI系统信任度量方法，结合性能指标和信任指标，提高了系统决策解释的准确性。|
|🆕 发布|Privacy-preserving Preselection for Face Identification Based on Packing|基于打包的隐私保护的人脸识别预处理|Rundong Xin, Taotao Wang, Jin Wang, Chonghe Zhao, Jing Wang|<http://arxiv.org/pdf/2507.02414v1>|提出了一种高效的加密域人脸识别预选方案PFIP，通过创新预选机制和打包模块显著提升检索效率。|
|🆕 发布|Multi-Label Classification Framework for Hurricane Damage Assessment|多标签分类框架用于飓风损害评估|Zhangding Liu, Neda Mohammadi, John E. Taylor|<http://arxiv.org/pdf/2507.02265v1>|提出了一种基于ResNet和注意力机制的多标签分类框架，用于准确评估飓风后的多种损害类型。|
|📝 更新|TurboReg: TurboClique for Robust and Efficient Point Cloud Registration|TurboReg：基于TurboClique的鲁棒高效点云配准方法|Shaocheng Yan, Pengcheng Shi, Zhenjun Zhao, Kaixin Wang, Kuang Cao, Ji Wu, Jiayuan Li|<http://arxiv.org/pdf/2507.01439v2>|[代码](https://github.com/Laka-3DV/TurboReg); 提出了一种高效的点云配准方法TurboReg，通过创新的轻量级3-clique和线性时间复杂度的搜索...|
|📝 更新|PriOr-Flow: Enhancing Primitive Panoramic Optical Flow with Orthogonal View|“PriOr-Flow：通过正交视角增强基本全景光流”|Longliang Liu, Miaojie Feng, Junda Cheng, Jijun Xiang, Xuan Zhu, Xin Yang|<http://arxiv.org/pdf/2506.23897v3>|[代码](https://github.com/longliangLiu/PriOr-Flow.); 提出双分支框架PriOr-Flow，利用正交视图减少球面投影失真，提升全景光流估计性能。|

