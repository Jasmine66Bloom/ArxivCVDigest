## [UPDATED!] **2025-07-04** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Zero Memory Overhead Approach for Protecting Vision Transformer Parameters|零内存开销方法保护视觉变换器参数|Fereshteh Baradaran, Mohsen Raji, Azadeh Baradaran, Arezoo Baradaran, Reihaneh Akbarifard|<http://arxiv.org/pdf/2507.03816v1>|提出了一种无需额外内存开销的视觉变换器参数保护技术，通过利用参数最低有效位的奇偶校验实现故障检测，有...|
|🆕 发布|NOVO: Unlearning-Compliant Vision Transformers|NOVO：符合遗忘学习的视觉变换器|Soumya Roy, Soumya Banerjee, Vinay Verma, Soumik Dasgupta, Deepak Gupta, Piyush Rai|<http://arxiv.org/pdf/2507.03281v1>|提出了一种无需微调即可直接执行遗忘操作的视觉变换器架构，通过训练过程中模拟遗忘，实现了遗忘效率和性能...|
|🆕 发布|Investigating Redundancy in Multimodal Large Language Models with Multiple Vision Encoders|探究多模态大型语言模型中多视觉编码器的冗余性|Song Mao, Yang Chen, Pinglong Cai, Ding Wang, Guohang Yan, Zhi Yu, Botian Shi|<http://arxiv.org/pdf/2507.03262v1>|揭示了多视觉编码器在多模态大语言模型中的冗余问题，并提出了评估编码器贡献的指标。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FastDINOv2: Frequency Based Curriculum Learning Improves Robustness and Training Speed|快速DINOv2：基于频率的教程学习提高鲁棒性和训练速度|Jiaqi Zhang, Juntuo Wang, Zhixin Sun, John Zou, Randall Balestriero|<http://arxiv.org/pdf/2507.03779v1>|[代码](https://github.com/KevinZ0217/fast_dinov2); 提出频率滤波课程学习策略，加速DINOv2训练并增强模型鲁棒性。|
|📝 更新|Team RAS in 9th ABAW Competition: Multimodal Compound Expression Recognition Approach|第九届ABA竞赛RAS团队：多模态复合表情识别方法|Elena Ryumina, Maxim Markitantov, Alexandr Axyonov, Dmitry Ryumin, Mikhail Dolgushin, Alexey Karpov|<http://arxiv.org/pdf/2507.02205v2>|提出了一种零样本多模态方法，通过融合六种异构模态识别复杂情感状态，无需特定任务训练数据。|
|🆕 发布|Multimodal Alignment with Cross-Attentive GRUs for Fine-Grained Video Understanding|多模态对齐结合交叉注意力GRU用于细粒度视频理解|Namho Kim, Junhwa Kim|<http://arxiv.org/pdf/2507.03531v1>|融合视频、图像、文本的多模态框架，通过GRU序列编码和跨模态注意力显著提升细粒度视频理解性能。|
|🆕 发布|Beyond Accuracy: Metrics that Uncover What Makes a `Good' Visual Descriptor|超越准确性：揭示何为“良好”视觉描述符的度量指标|Ethan Lin, Linxi Zhao, Atharva Sehgal, Jennifer J. Sun|<http://arxiv.org/pdf/2507.03542v1>|提出两种新指标Global Alignment和CLIP Similarity，超越准确度评估视觉描...|
|📝 更新|TerraMind: Large-Scale Generative Multimodality for Earth Observation|“TerraMind：地球观测的大规模生成多模态”|Johannes Jakubik, Felix Yang, Benedikt Blumenstiel, Erik Scheurer, Rocco Sedona, Stefano Maurogiovanni, Jente Bosmans, Nikolaos Dionelis .etc.|<http://arxiv.org/pdf/2504.11171v3>|TerraMind通过双尺度表征预训练，实现了地球观测数据的零样本和少样本泛化，并引入了生成额外数据...|
|🆕 发布|Bridging Domain Generalization to Multimodal Domain Generalization via Unified Representations|通过统一表征将领域泛化桥接到多模态领域泛化|Hai Huang, Yan Xia, Sashuai Zhou, Hanting Wang, Shulei Wang, Zhou Zhao|<http://arxiv.org/pdf/2507.03304v1>|提出了一种利用统一表示法同步提升多模态数据泛化能力的方法，解决了多模态领域泛化问题。|
|🆕 发布|MolVision: Molecular Property Prediction with Vision Language Models|《MolVision：基于视觉语言模型的分子属性预测》|Deepan Adak, Yogesh Singh Rawat, Shruti Vyas|<http://arxiv.org/pdf/2507.03283v1>|[代码](https://molvision.github.io/MolVision); 提出了一种结合分子图像和文本描述的计算机视觉模型MolVision，提高了分子属性预测的准确性。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SEAL: Vision-Language Model-Based Safe End-to-End Cooperative Autonomous Driving with Adaptive Long-Tail Modeling|SEAL：基于视觉语言模型的适应性长尾建模安全端到端协同自动驾驶|Junwei You, Pei Li, Zhuoyu Jiang, Zilin Huang, Rui Gan, Haotian Shi, Bin Ran|<http://arxiv.org/pdf/2506.21041v2>|提出SEAL框架，通过自适应多模态学习提升自动驾驶在复杂环境下的安全性和鲁棒性。|
|🆕 发布|SAMed-2: Selective Memory Enhanced Medical Segment Anything Model|选择性记忆增强医疗分割一切模型SAMed-2|Zhiling Yan, Sifan Song, Dingjie Song, Yiwei Li, Rong Zhou, Weixiang Sun, Zhennong Chen, Sekeun Kim .etc.|<http://arxiv.org/pdf/2507.03698v1>|[代码](https://github.com/ZhilingYan/Medical-SAM-Bench.); 提出SAMed-2模型，通过引入时间适配器和置信度驱动的记忆机制，有效应对医学图像的复杂性和噪声，提...|
|📝 更新|ODE: Open-Set Evaluation of Hallucinations in Multimodal Large Language Models|开放集评估多模态大型语言模型中的幻觉现象|Yahan Tu, Rui Hu, Jitao Sang|<http://arxiv.org/pdf/2409.09318v4>|提出了ODE协议，动态评估大型多模态语言模型中的对象幻觉问题，减少数据污染风险。|
|🆕 发布|SciVid: Cross-Domain Evaluation of Video Models in Scientific Applications|科学视频：在科学应用中跨领域评估视频模型的性能|Yana Hasson, Pauline Luc, Liliane Momeni, Maks Ovsjanikov, Guillaume Le Moing, Alina Kuznetsova, Ira Ktena, Jennifer J. Sun .etc.|<http://arxiv.org/pdf/2507.03578v1>|[代码](https://github.com/google-deepmind/scivid); 提出SciVid基准，通过跨领域视频模型评估，证实了通用视频模型在科学应用中的有效迁移性。|
|🆕 发布|Foundation versus Domain-specific Models: Performance Comparison, Fusion, and Explainability in Face Recognition|基础模型与领域特定模型：人脸识别中的性能比较、融合与可解释性|Redwan Sony, Parisa Farmanifard, Arun Ross, Anil K. Jain|<http://arxiv.org/pdf/2507.03541v1>|比较通用基础模型与特定领域人脸识别模型性能，提出融合策略提升准确率并增强解释性。|
|📝 更新|High-resolution efficient image generation from WiFi CSI using a pretrained latent diffusion model|使用预训练潜在扩散模型从WiFi CSI生成高分辨率高效图像|Eshan Ramesh, Takayuki Nishio|<http://arxiv.org/pdf/2506.10605v2>|提出了一种利用预训练潜在扩散模型从WiFi CSI测量生成高分辨率图像的高效方法。|
|📝 更新|Specialized Foundation Models for Intelligent Operating Rooms|智能手术室专用基础模型|Ege Özsoy, Chantal Pellegrini, David Bani-Harouni, Kun Yuan, Matthias Keicher, Nassir Navab|<http://arxiv.org/pdf/2505.12890v2>|提出ORQA模型，融合视觉、听觉和结构化数据，全面理解手术室活动，提升智能手术系统性能。|
|📝 更新|CHIME: Conditional Hallucination and Integrated Multi-scale Enhancement for Time Series Diffusion Model|CHIME：条件虚化和多尺度增强的时间序列扩散模型|Yuxuan Chen, Haipeng Xie|<http://arxiv.org/pdf/2506.03502v2>|提出CHIME框架，通过多尺度分解与整合及条件生成增强，提升时间序列扩散模型生成效果和跨尺度特征传递...|
|🆕 发布|Leveraging Out-of-Distribution Unlabeled Images: Semi-Supervised Semantic Segmentation with an Open-Vocabulary Model|利用分布外未标记图像：基于开放词汇模型的半监督语义分割|Wooseok Shin, Jisu Kang, Hyeonki Jeong, Jin Sob Kim, Sung Won Han|<http://arxiv.org/pdf/2507.03302v1>|[代码](https://github.com/wooseok-shin/SemiOVS); 提出了一种利用开放词汇模型进行半监督语义分割的方法，有效利用了分布外的大量未标注图像。|
|🆕 发布|Zero-shot Inexact CAD Model Alignment from a Single Image|单张图像驱动的零样本非精确CAD模型对齐|Pattaramanee Arsomngern, Sasikarn Khwanmuang, Matthias Nießner, Supasorn Suwajanakorn|<http://arxiv.org/pdf/2507.03292v1>|提出了一种无需姿态标注的弱监督9自由度三维模型对齐方法，适用于未见类别且提升了准确度。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Deep Transformer Network for Monocular Pose Estimation of Shipborne Unmanned Aerial Vehicle|深度转换网络在单目船载无人机位姿估计中的应用|Maneesha Wickramasuriya, Taeyoung Lee, Murray Snyder|<http://arxiv.org/pdf/2406.09260v2>|提出了一种基于深度变换网络的船舶无人机单目6D姿态估计方法，实现了高精度定位。|
|🆕 发布|Cancer cytoplasm segmentation in hyperspectral cell image with data augmentation|超光谱细胞图像中癌细胞质分割及数据增强方法|Rebeka Sultana, Hibiki Horibe, Tomoaki Murakami, Ikuko Shimizu|<http://arxiv.org/pdf/2507.03325v1>|提出了一种利用数据增强处理hyperspectral图像以准确分割癌细胞质的方法。|
|📝 更新|CCi-YOLOv8n: Enhanced Fire Detection with CARAFE and Context-Guided Modules|CCi-YOLOv8n：基于CARAFE和上下文引导模块的火灾检测增强方法|Kunwei Lv, Ruobing Wu, Suyang Chen, Ping Lan|<http://arxiv.org/pdf/2411.11011v3>|提出了一种改进的YOLOv8模型CCi-YOLOv8n，通过集成CARAFE和上下文引导模块，有效提...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Efficient Event-Based Semantic Segmentation via Exploiting Frame-Event Fusion: A Hybrid Neural Network Approach|基于帧-事件融合的高效事件驱动的语义分割：一种混合神经网络方法|Hebei Li, Yansong Peng, Jiahui Yuan, Peixi Wu, Jin Wang, Yueyi Zhang, Xiaoyan Sun|<http://arxiv.org/pdf/2507.03765v1>|提出了一种融合帧与事件信息的混合神经网络框架，有效提升语义分割准确度并降低能耗。|
|🆕 发布|Segmentation of separated Lumens in 3D CTA images of Aortic Dissection|三维计算机断层扫描图像中主动脉夹层分离腔的分割|Christophe Lohou, Bruno Miguel|<http://arxiv.org/pdf/2507.03655v1>|首次利用填充撕裂的表面作为图像处理算子分离血管腔室，辅助医生诊断主动脉夹层。|
|🆕 发布|CLOT: Closed Loop Optimal Transport for Unsupervised Action Segmentation|CLOT：闭环最优传输用于无监督动作分割|Elena Bueno-Benito, Mariella Dimiccoli|<http://arxiv.org/pdf/2507.03539v1>|提出了一种引入多级循环特征学习机制的闭环最优传输框架，有效提升了无监督动作分割的效果。|
|📝 更新|ShareCMP: Polarization-Aware RGB-P Semantic Segmentation|《ShareCMP：极化感知的RGB-P语义分割》|Zhuoyan Liu, Bo Wang, Lizhi Wang, Chenyu Mao, Ye Li|<http://arxiv.org/pdf/2312.03430v3>|[代码](https://github.com/LEFTeyex/ShareCMP.); 提出ShareCMP框架，利用共享双分支结构和创新模块，提升RGB-P水下图像分割性能并减少参数量。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|3D PixBrush: Image-Guided Local Texture Synthesis|《3D PixBrush：基于图像引导的局部纹理合成》|Dale Decatur, Itai Lang, Kfir Aberman, Rana Hanocka|<http://arxiv.org/pdf/2507.03731v1>|3D PixBrush实现了无需用户输入即可对3D模型进行基于图像的局部纹理合成。|
|📝 更新|Cooperative Students: Navigating Unsupervised Domain Adaptation in Nighttime Object Detection|合作学生：在夜间目标检测中导航无监督领域适应|Jicheng Yuan, Anh Le-Tuan, Manfred Hauswirth, Danh Le-Phuoc|<http://arxiv.org/pdf/2404.01988v4>|[代码](https://github.com/jichengyuan/Cooperitive_Students.); 提出CoS框架，通过全局-局部变换和代理目标一致性机制，有效提升夜间物体检测的无监督域自适应性能。|
|🆕 发布|Radar Velocity Transformer: Single-scan Moving Object Segmentation in Noisy Radar Point Clouds|雷达速度转换器：噪声雷达点云中的单次扫描运动目标分割|Matthias Zeller, Vardeep S. Sandhu, Benedikt Mersch, Jens Behley, Michael Heidingsfeld, Cyrill Stachniss|<http://arxiv.org/pdf/2507.03463v1>|提出了一种基于雷达速度信息的单次扫描移动目标分割方法，实现了对稀疏雷达点云中移动和静止物体的精确区分...|
|🆕 发布|De-Fake: Style based Anomaly Deepfake Detection|“De-Fake：基于风格的异常深度伪造检测”|Sudev Kumar Padhi, Harshit Kumar, Umesh Kashyap, Sk. Subidh Ali|<http://arxiv.org/pdf/2507.03334v1>|提出了一种基于风格特征的Deepfake检测方法SafeVision，有效识别面部交换伪造图像且保护...|
|📝 更新|UnitModule: A Lightweight Joint Image Enhancement Module for Underwater Object Detection|《UnitModule：一种用于水下目标检测的轻量级联合图像增强模块》|Zhuoyan Liu, Bo Wang, Ye Li, Jiaxian He, Yunfeng Li|<http://arxiv.org/pdf/2309.04708v2>|[代码](https://github.com/LEFTeyex/UnitModule.); 提出了一种轻量级的水下图像增强模块UnitModule，无需额外数据集即可与检测器联合训练，显著提升...|
|📝 更新|MORDA: A Synthetic Dataset to Facilitate Adaptation of Object Detectors to Unseen Real-target Domain While Preserving Performance on Real-source Domain|MORDA：一种合成数据集，用于促进目标检测器在未见过的实际目标域中的适应，同时保持在实际源域的性能|Hojun Lim, Heecheol Yoo, Jinwoo Lee, Seungmin Jeon, Hyeongseok Jeon|<http://arxiv.org/pdf/2501.04950v2>|提出合成数据集MORDA，通过融合现实源域与合成域数据，有效提升对象检测器在未见现实目标域的性能。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Interpretable PolSAR Image Classification: Polarimetric Scattering Mechanism Informed Concept Bottleneck and Kolmogorov-Arnold Network|面向可解释极化合成孔径雷达图像分类：极化散射机制指导的概念瓶颈与科尔莫哥洛夫-阿尔诺德网络|Jinqi Zhang, Fangzhou Han, Di Zhuang, Lamei Zhang, Bin Zou, Li Yuan|<http://arxiv.org/pdf/2507.03315v1>|提出了一种基于极化散射机制的可解释性极化合成孔径雷达图像分类方法，通过构建极化概念标签和新型网络结构...|
|🆕 发布|Dual-frequency Selected Knowledge Distillation with Statistical-based Sample Rectification for PolSAR Image Classification|双频选择知识蒸馏与基于统计的样本校正方法在极化合成孔径雷达图像分类中的应用|Xinyue Xin, Ming Li, Yan Wu, Xiang Li, Peng Zhang, Dazhi Xu|<http://arxiv.org/pdf/2507.03268v1>|提出了一种结合统计样本修正的知识蒸馏网络，有效解决了双频PolSAR图像分类中的区域一致性问题，并优...|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Symmetry-Robust 3D Orientation Estimation|对称性鲁棒的3D姿态估计|Christopher Scarvelis, David Benhaim, Paul Zhang|<http://arxiv.org/pdf/2410.02101v4>|提出了一种对称性鲁棒的3D方向估计方法，有效解决了旋转对称形状的方向轴估计难题。|
|🆕 发布|Masked Temporal Interpolation Diffusion for Procedure Planning in Instructional Videos|《面向教学视频手术规划的面具时态插值扩散》|Yufan Zhou, Zhaobo Qi, Lingshuai Lin, Junqi Jing, Tingting Chai, Beichen Zhang, Shuhui Wang, Weigang Zhang|<http://arxiv.org/pdf/2507.03393v1>|[代码](https://github.com/WiserZhou/MTID.); 提出了一种基于扩散模型的动作规划方法，通过引入时间插值模块增强视觉监督，生成连贯的任务对齐动作序列。|
|📝 更新|Learning Traffic Anomalies from Generative Models on Real-Time Observations|从生成模型中学习实时观测数据下的交通异常|Fotis I. Giasemis, Alexandros Sopasakis|<http://arxiv.org/pdf/2502.01391v4>|利用生成对抗网络和图神经网络结合，有效检测实时交通异常并降低误报率。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Static Segmentation by Tracking: A Label-Efficient Approach for Fine-Grained Specimen Image Segmentation|静态分割通过跟踪：一种用于细粒度样本图像分割的标签高效方法|Zhenyang Feng, Zihe Wang, Jianyang Gu, Saul Ibaven Bueno, Tomasz Frelek, Advikaa Ramesh, Jingyan Bai, Lemeng Wang .etc.|<http://arxiv.org/pdf/2501.06749v2>|提出了一种基于跟踪的静态分割方法，只需少量标注即可高效实现生物样本图像的精细分割。|
|📝 更新|Hallucinatory Image Tokens: A Training-free EAZY Approach on Detecting and Mitigating Object Hallucinations in LVLMs|幻象图像标记：一种无需训练的EAZY方法用于检测和减轻LVLM中的对象幻象|Liwei Che, Tony Qingze Liu, Jing Jia, Weiyi Qin, Ruixiang Tang, Vladimir Pavlovic|<http://arxiv.org/pdf/2503.07772v2>|提出了一种无需训练的EAZY方法，通过消除特定图像标记显著减少大型视觉语言模型中的物体幻觉问题。|
|📝 更新|LD-RPS: Zero-Shot Unified Image Restoration via Latent Diffusion Recurrent Posterior Sampling|LD-RPS：基于潜在扩散递归后验采样的零样本统一图像恢复|Huaqiu Li, Yong Wang, Tongwen Huang, Hailang Huang, Haoqian Wang, Xiangxiang Chu|<http://arxiv.org/pdf/2507.00790v2>|[代码](https://github.com/AMAP-ML/LD-RPS.); 提出了一种无需数据集、基于潜在扩散模型和后验采样的统一图像复原方法，有效克服了泛化性和闭集约束问题。|
|📝 更新|Probabilistic Embeddings for Frozen Vision-Language Models: Uncertainty Quantification with Gaussian Process Latent Variable Models|概率嵌入用于冻结视觉-语言模型：高斯过程潜在变量模型的不确定性量化|Aishwarya Venkataramanan, Paul Bodesheim, Joachim Denzler|<http://arxiv.org/pdf/2505.05163v2>|提出了一种后处理方法GroVE，通过高斯过程潜变量模型从冻结的视觉语言模型中获取概率性嵌入，以量化视...|
|🆕 发布|Predicting Asphalt Pavement Friction Using Texture-Based Image Indicator|基于纹理图像指标预测沥青路面摩擦系数|Bingjie Lu, Zhengyang Lu, Yijiashun Qi, Hanzhe Guo, Tianyao Sun, Zunduo Zhao|<http://arxiv.org/pdf/2507.03559v1>|提出了一种基于纹理的图像指标预测路面摩擦，通过统计分析实现了高精度预测。|
|🆕 发布|PhenoBench: A Comprehensive Benchmark for Cell Phenotyping|PhenoBench：细胞表型分析的全面基准测试|Jerome Luescher, Nora Koreuber, Jannik Franzen, Fabian H. Reith, Claudia Winklmayr, Christian M. Schuerch, Dagmar Kainmueller, Josef Lorenz Rumberger|<http://arxiv.org/pdf/2507.03532v1>|提出PhenoBench，为细胞表型分析创建了全面基准及数据集，揭示了现有模型在新任务上的性能差距。|
|📝 更新|Neuroverse3D: Developing In-Context Learning Universal Model for Neuroimaging in 3D|神经宇宙3D：开发用于三维神经影像的情境学习通用模型|Jiesi Hu, Chenfei Ye, Yanwu Yang, Xutao Guo, Yang Shang, Pengcheng Shi, Hanyang Peng, Ting Ma|<http://arxiv.org/pdf/2503.02410v2>|[代码](https://github.com/jiesihu/Neuroverse3D.); 提出Neuroverse3D模型，通过自适应处理和优化损失函数，实现了3D神经影像多任务的高效处理。|
|📝 更新|MPG-SAM 2: Adapting SAM 2 with Mask Priors and Global Context for Referring Video Object Segmentation|MPG-SAM 2：利用掩膜先验和全局上下文适应SAM 2进行视频目标分割|Fu Rong, Meng Lan, Qian Zhang, Lefei Zhang|<http://arxiv.org/pdf/2501.13667v3>|[代码](https://github.com/rongfu-dsb/MPG-SAM2.); 提出MPG-SAM 2框架，融合掩膜先验和全局上下文，提升视频对象分割的准确性和一致性。|
|🆕 发布|CPKD: Clinical Prior Knowledge-Constrained Diffusion Models for Surgical Phase Recognition in Endoscopic Submucosal Dissection|CPKD：基于临床先验知识约束的扩散模型用于内镜下黏膜下剥离手术阶段识别|Xiangning Zhang, Jinnan Chen, Qingwei Zhang, Yaqi Wang, Chengfeng Zhou, Xiaobo Li, Dahong Qian|<http://arxiv.org/pdf/2507.03295v1>|提出了一种基于噪声扩散原理的手术阶段识别方法CPKD，利用临床先验知识增强逻辑错误修正能力，提升内镜...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Boundary Exploration of Next Best View Policy in 3D Robotic Scanning|三维机器人扫描中下一最佳视角策略的边界探索|Leihui Li, Lixuepiao Wan, Xuping Zhang|<http://arxiv.org/pdf/2412.10444v2>|[代码](https://github.com/leihui6/BENBV.); 提出了一种探索扫描物体边界的NBV策略，通过考虑视图重叠和灵活的扫描距离，提高了3D机器人扫描的效率...|
|🆕 发布|Flow-Anchored Consistency Models|基于流固定的一致性模型|Yansong Peng, Kai Zhu, Yu Liu, Pingyu Wu, Hebei Li, Xiaoyan Sun, Feng Wu|<http://arxiv.org/pdf/2507.03738v1>|[代码](https://github.com/ali-vilab/FACM.); 提出了一种稳定训练连续时间一致性模型的新策略，通过引入流匹配任务显著提升了生成图像的质量。|
|📝 更新|HOTS3D: Hyper-Spherical Optimal Transport for Semantic Alignment of Text-to-3D Generation|HOTS3D：超球面最优传输用于文本到三维生成的语义对齐|Zezeng Li, Weimin Wang, Yuming Zhao, Wenhai Li, Na Lei, Xianfeng Gu|<http://arxiv.org/pdf/2407.14419v2>|提出了一种基于超球面最优传输的文本到3D生成对齐方法，有效缩小了文本与图像特征间的差距。|
|📝 更新|Agentic 3D Scene Generation with Spatially Contextualized VLMs|具有空间上下文化的VLMs的代理性3D场景生成|Xinhang Liu, Yu-Wing Tai, Chi-Keung Tang|<http://arxiv.org/pdf/2505.20129v3>|[代码](https://spatctxvlm.github.io/project_page); 引入空间上下文机制，使视觉语言模型能够生成和理解复杂3D场景，提升其在空间智能任务中的应用。|
|📝 更新|Playing with Transformer at 30+ FPS via Next-Frame Diffusion|通过下一帧扩散实现30+ FPS的Transformer玩耍|Xinle Cheng, Tianyu He, Jiayi Xu, Junliang Guo, Di He, Jiang Bian|<http://arxiv.org/pdf/2506.01380v2>|提出了一种高效视频生成模型Next-Frame Diffusion，通过改进扩散采样和并行计算，实现...|
|🆕 发布|SecureT2I: No More Unauthorized Manipulation on AI Generated Images from Prompts|SecureT2I：禁止对提示生成的AI图像进行未授权操作|Xiaodong Wu, Xiangman Li, Qi Li, Jianbing Ni, Rongxing Lu|<http://arxiv.org/pdf/2507.03636v1>|提出SecureT2I框架，通过区分许可与禁止编辑的图像集合，有效阻止AI生成图像的未授权修改。|
|📝 更新|UniMC: Taming Diffusion Transformer for Unified Keypoint-Guided Multi-Class Image Generation|统一多类图像生成的关键点引导扩散变换器驯服方法：UniMC|Qin Guo, Ailing Zeng, Dongxu Yue, Ceyuan Yang, Yang Cao, Hanzhong Guo, Fei Shen, Wei Liu .etc.|<http://arxiv.org/pdf/2507.02713v2>|提出UniMC框架，实现了一键控制多类图像生成，并构建了大规模数据集HAIG-2.9M。|
|📝 更新|Robotic Manipulation by Imitating Generated Videos Without Physical Demonstrations|无需物理演示的机器人操作：通过模仿生成视频进行操纵|Shivansh Patel, Shraddhaa Mohan, Hanlin Mai, Unnat Jain, Svetlana Lazebnik, Yunzhu Li|<http://arxiv.org/pdf/2507.00990v2>|提出了一种让机器人通过模仿AI生成的视频学习复杂操作任务的方法，无需物理演示或特定训练。|
|📝 更新|Mesh Silksong: Auto-Regressive Mesh Generation as Weaving Silk|《编织丝绸：作为编织丝绸的自回归网格生成》|Gaochao Song, Zibo Zhao, Haohan Weng, Jingbo Zeng, Rongfei Jia, Shenghua Gao|<http://arxiv.org/pdf/2507.02477v2>|提出了一种高效的自动回归网格生成方法Mesh Silksong，减少序列冗余50%，实现了最优压缩率...|
|🆕 发布|Pose-Star: Anatomy-Aware Editing for Open-World Fashion Images|姿态星：面向开放世界时尚图像的解剖感知编辑|Yuran Dong, Mang Ye|<http://arxiv.org/pdf/2507.03402v1>|提出了一种解剖感知的图像编辑框架Pose-Star，通过动态重组身体结构，增强了复杂姿势下的编辑灵活...|
|📝 更新|MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation|MAGIC：基于掩码引导的扩散修复与多级扰动及上下文感知对齐的少量样本异常生成|JaeHyuck Choi, MinJun Kim, JeHyeong Hong|<http://arxiv.org/pdf/2507.02314v2>|提出MAGIC方法，通过多级扰动和上下文感知对齐解决少样本异常生成中的背景破坏、对齐不准确和多样性损...|
|🆕 发布|Personalized Image Generation from an Author Writing Style|个性化图像生成：基于作者写作风格|Sagar Gandhi, Vishal Gandhi|<http://arxiv.org/pdf/2507.03313v1>|提出了一种将作者写作风格转化为个性化图像生成的方法，实现了文本风格到视觉表现的映射。|
|🆕 发布|Mirror in the Model: Ad Banner Image Generation via Reflective Multi-LLM and Multi-modal Agents|模型中的镜子：通过反射多语言模型与多模态代理生成广告横幅图像|Zhao Wang, Bowen Chen, Yotaro Shimose, Sota Moriyama, Heng Wang, Shingo Takamatsu|<http://arxiv.org/pdf/2507.03326v1>|提出MIMO框架，通过多模态代理和协调循环自动生成高质量的广告横幅设计。|
|📝 更新|Learning Video Generation for Robotic Manipulation with Collaborative Trajectory Control|学习面向机器人操作的视频生成与协同轨迹控制|Xiao Fu, Xintao Wang, Xian Liu, Jianhong Bai, Runsen Xu, Pengfei Wan, Di Zhang, Dahua Lin|<http://arxiv.org/pdf/2506.01943v2>|提出了一种分解互动过程的新框架RoboMaster，通过协作轨迹控制提高了复杂机器人操作中多对象交互...|
|📝 更新|3DTrajMaster: Mastering 3D Trajectory for Multi-Entity Motion in Video Generation|《3DTrajMaster：掌握视频中多实体运动的3D轨迹生成》|Xiao Fu, Xian Liu, Xintao Wang, Sida Peng, Menghan Xia, Xiaoyu Shi, Ziyang Yuan, Pengfei Wan .etc.|<http://arxiv.org/pdf/2412.07759v3>|[代码](http://fuxiao0719.github.io/projects); 提出3DTrajMaster，通过6DoF姿态序列在3D空间控制多实体运动，实现视频生成的新突破。|
|🆕 发布|ConceptMix++: Leveling the Playing Field in Text-to-Image Benchmarking via Iterative Prompt Optimization|概念混合++：通过迭代提示优化在文本到图像基准测试中平衡竞争环境|Haosheng Gan, Berk Tinaz, Mohammad Shahab Sepehri, Zalan Fabian, Mahdi Soltanolkotabi|<http://arxiv.org/pdf/2507.03275v1>|提出迭代提示优化框架ConceptMix++，提升文本到图像生成性能并实现公平比较。|
|🆕 发布|LACONIC: A 3D Layout Adapter for Controllable Image Creation|“LACONIC：一种用于可控图像生成的三维布局适配器”|Léopold Maillard, Tom Durand, Adrien Ramanana Rahary, Maks Ovsjanikov|<http://arxiv.org/pdf/2507.03257v1>|提出了一种3D布局适配器，使文本到图像模型具备三维感知能力，实现场景中物体位置和形态的精确控制。|
|🆕 发布|MoDA: Multi-modal Diffusion Architecture for Talking Head Generation|多模态扩散架构用于说话人头生成|Xinyang Li, Gen Li, Zhihui Lin, Yichen Qian, GongXin Yao, Weinan Jia, Weihua Chen, Fan Wang|<http://arxiv.org/pdf/2507.03256v1>|提出了一种多模态扩散架构MoDA，通过融合运动生成和神经渲染，有效提升了数字人视频的多样性、真实感和...|
|📝 更新|HPPP: Halpern-type Preconditioned Proximal Point Algorithms and Applications to Image Restoration|HPPP：Halpern型预调条件近端点算法及其在图像复原中的应用|Shuchang Zhang, Hui Zhang, Hongxia Wang|<http://arxiv.org/pdf/2407.13120v5>|提出了一种改进的预处理 proximity 点算法，加速了图像复原过程中的收敛速度。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|StreamDiT: Real-Time Streaming Text-to-Video Generation|《StreamDiT：实时流式文本到视频生成》|Akio Kodaira, Tingbo Hou, Ji Hou, Masayoshi Tomizuka, Yue Zhao|<http://arxiv.org/pdf/2507.03745v1>|[代码](https://cumulo-autumn.github.io/StreamDiT); 提出实时流式文本到视频生成模型StreamDiT，通过流匹配训练和分块蒸馏实现16FPS的实时视频流...|
|📝 更新|VGMShield: Mitigating Misuse of Video Generative Models|视频生成模型滥用缓解：VGMShield方法|Yan Pang, Baicheng Chen, Yang Zhang, Tianhao Wang|<http://arxiv.org/pdf/2402.13126v2>|提出了一种多方位策略VGMShield，通过检测和追踪技术有效减轻视频生成模型滥用问题。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Outdoor Monocular SLAM with Global Scale-Consistent 3D Gaussian Pointmaps|室外单目SLAM与全局尺度一致的三维高斯点图|Chong Cheng, Sicheng Yu, Zijian Wang, Yifan Zhou, Hao Wang|<http://arxiv.org/pdf/2507.03737v1>|[代码](https://3dagentworld.github.io/S3PO-GS); 提出一种户外单目SLAM方法，通过引入几何先验和自一致跟踪模块，有效避免了尺度漂移，提升了跟踪精度和...|
|📝 更新|ArticulatedGS: Self-supervised Digital Twin Modeling of Articulated Objects using 3D Gaussian Splatting|关节GS：使用三维高斯散点绘制进行关节对象的自我监督数字孪生建模|Junfu Guo, Yu Xin, Gaoyi Liu, Kai Xu, Ligang Liu, Ruizhen Hu|<http://arxiv.org/pdf/2503.08135v2>|提出 ArticulatedGS 框架，通过 3D 高斯散点建模，无需监督信息实现关节对象的高精度重...|
|🆕 发布|MGSfM: Multi-Camera Geometry Driven Global Structure-from-Motion|多相机几何驱动的全局结构重建方法（MGSfM）|Peilin Tao, Hainan Cui, Diantao Tu, Shuhan Shen|<http://arxiv.org/pdf/2507.03306v1>|[代码](https://github.com/3dv-casia/MGSfM); 提出了一种针对多相机系统的全局运动平均框架，通过解耦的旋转平均和混合平移平均模块提高了SfM的鲁棒性...|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hybrid-View Attention for csPCa Classification in TRUS|“基于混合视角注意力机制的经直肠超声引导下前列腺癌分类”|Zetian Feng, Juan Fu, Xuebin Zou, Hongsheng Ye, Hong Wu, Jianhua Zhou, Yi Wang|<http://arxiv.org/pdf/2507.03421v1>|[代码](https://github.com/mock1ngbrd/HVAN.); 提出了一种结合横切面和矢状面信息的混合视角注意力网络，用于提高3D TRUS图像中临床显著前列腺癌的...|
|📝 更新|Neural Discrete Token Representation Learning for Extreme Token Reduction in Video Large Language Models|用于视频大型语言模型极简代币表示的神经离散代币表示学习|Haichao Zhang, Yun Fu|<http://arxiv.org/pdf/2503.16980v4>|提出极端短令牌缩减任务，通过神经离散令牌表示框架大幅压缩视频序列长度，同时保持模型准确性。|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Radar Tracker: Moving Instance Tracking in Sparse and Noisy Radar Point Clouds|雷达追踪者：在稀疏和噪声雷达点云中的移动实例追踪|Matthias Zeller, Daniel Casado Herraez, Jens Behley, Michael Heidingsfeld, Cyrill Stachniss|<http://arxiv.org/pdf/2507.03441v1>|提出了一种结合时间和外观特征的雷达点云移动实例跟踪方法，提升了场景解释能力和跟踪准确性。|
|🆕 发布|Exploring Object Status Recognition for Recipe Progress Tracking in Non-Visual Cooking|探索非视觉烹饪中菜谱进度跟踪的对象状态识别|Franklin Mingzhe Li, Kaitlyn Ng, Bin Zhu, Patrick Carrington|<http://arxiv.org/pdf/2507.03330v1>|提出了一种利用物体状态识别的辅助烹饪系统，通过分析烹饪过程中的物体变化来跟踪食谱进度，提高了视障人士...|
|🆕 发布|A Vision-Based Closed-Form Solution for Measuring the Rotation Rate of an Object by Tracking One Point|基于视觉的通过跟踪一个点测量物体旋转率的闭式解法|Daniel Raviv, Juan D. Yepes, Eiki M. Martinson|<http://arxiv.org/pdf/2507.03237v1>|提出了一种仅通过追踪物体上单一特征点即可测量其旋转率的方法，无需了解物体形状或场景信息。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Confidence-driven Gradient Modulation for Multimodal Human Activity Recognition: A Dynamic Contrastive Dual-Path Learning Approach|基于置信度的梯度调制用于多模态人体行为识别：动态对比双路径学习方法|Panpan Ji, Junni Song, Hang Xiao, Hanyu Liu, Chao Li|<http://arxiv.org/pdf/2507.02826v2>|提出动态对比双路径网络，通过信心驱动的梯度调制策略解决多模态人体活动识别中的模态竞争问题。|
|📝 更新|CMD-HAR: Cross-Modal Disentanglement for Wearable Human Activity Recognition|CMD-HAR：基于跨模态解耦的穿戴式人体活动识别|Hanyu Liu, Siyao Li, Ying Yu, Yixuan Jiang, Hang Xiao, Jingxi Long, Haotian Tang, Chao Li|<http://arxiv.org/pdf/2503.21843v3>|提出了一种跨模态解耦方法，有效解决了可穿戴设备中活动识别的数据混合和异质性问题。|
|🆕 发布|DESign: Dynamic Context-Aware Convolution and Efficient Subnet Regularization for Continuous Sign Language Recognition|动态上下文感知卷积与高效子网正则化设计：用于连续手语识别|Sheng Liu, Yiheng Yu, Yuan Feng, Min Xu, Zhelun Jin, Yining Jiang, Tiantian Yuan|<http://arxiv.org/pdf/2507.03339v1>|提出DESign框架，通过动态感知卷积和子网正则化提升连续手语识别的泛化能力和准确度。|
|🆕 发布|Subject Invariant Contrastive Learning for Human Activity Recognition|面向主体不变的对比学习的人类活动识别|Yavuz Yarici, Kiran Kokilepersaud, Mohit Prabhushankar, Ghassan AlRegib|<http://arxiv.org/pdf/2507.03250v1>|提出Subject-Invariant Contrastive Learning方法，通过抑制特定主...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|F-Hash: Feature-Based Hash Design for Time-Varying Volume Visualization via Multi-Resolution Tesseract Encoding|基于特征的时间变化体可视化哈希设计：通过多分辨率体素编码实现|Jianxin Sun, David Lenz, Hongfeng Yu, Tom Peterka|<http://arxiv.org/pdf/2507.03836v1>|提出F-Hash方法，通过特征基多分辨率编码加速时间变化体数据可视化训练收敛速度。|
|🆕 发布|Computationally efficient non-Intrusive pre-impact fall detection system|计算效率高的非侵入式撞击前跌倒检测系统|Praveen Jesudhas, Raghuveera T, Shiney Jeyaraj|<http://arxiv.org/pdf/2507.03705v1>|提出了一种非侵入式且计算效率高的跌倒预检测系统，通过视频数据和简化神经网络模型降低成本并提高准确性。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Less is More: Empowering GUI Agent with Context-Aware Simplification|“少即是多：赋予GUI智能体以情境感知简化的能力”|Gongwei Chen, Xurui Zhou, Rui Shao, Yibo Lyu, Kaiwen Zhou, Shuai Wang, Wentao Li, Yinchuan Li .etc.|<http://arxiv.org/pdf/2507.03730v1>|提出了一种针对GUI智能体的上下文感知简化框架，有效降低计算负担并提升导航性能。|
|🆕 发布|Sign Spotting Disambiguation using Large Language Models|使用大型语言模型进行标志定位消歧|JianHe Low, Ozge Mercanoglu Sincan, Richard Bowden|<http://arxiv.org/pdf/2507.03703v1>|利用大型语言模型提升手势识别准确性和灵活性，无需训练即可实现上下文感知的歧义消除。|
|📝 更新|Elevator, Escalator, or Neither? Classifying Conveyor State Using Smartphone under Arbitrary Pedestrian Behavior|电梯、扶梯还是都不是？在任意行人行为下使用智能手机分类输送机状态|Tianlang He, Zhiqiu Xia, S. -H. Gary Chan|<http://arxiv.org/pdf/2405.03218v3>|提出一种基于智能手机惯性导航系统的高准确度分类方法ELESON，能在任意行人行为下区分电梯、扶梯和普...|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Rectifying Adversarial Sample with Low Entropy Prior for Test-Time Defense|利用低熵先验修正对抗样本以进行测试时间防御|Lina Ma, Xiaowei Fu, Fuxiang Huang, Xinbo Gao, Lei Zhang|<http://arxiv.org/pdf/2507.03427v1>|提出利用低熵先验特性修复对抗样本，增强了测试阶段的通用对抗稳健性。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Gradient Short-Circuit: Efficient Out-of-Distribution Detection via Feature Intervention|梯度短路：通过特征干预实现高效的非分布检测|Jiawei Gu, Ziyue Qiao, Zechao Li|<http://arxiv.org/pdf/2507.01417v2>|提出了一种通过特征干预短路伪梯度来有效检测异常分布样本的方法，显著提升了模型在开放环境下的鲁棒性。|
|🆕 发布|Task-Specific Generative Dataset Distillation with Difficulty-Guided Sampling|基于难度指导采样的任务特定生成数据集蒸馏|Mingzhuo Li, Guang Li, Jiafeng Mao, Linfeng Ye, Takahiro Ogawa, Miki Haseyama|<http://arxiv.org/pdf/2507.03331v1>|提出了一种针对特定任务的生成数据集精简方法，通过难度指导采样优化了下游任务的性能。|
|📝 更新|QCResUNet: Joint Subject-level and Voxel-level Segmentation Quality Prediction|QCResUNet：联合体素级和个体级分割质量预测|Peijie Qiu, Satrajit Chakrabarty, Phuc Nguyen, Soumyendu Sekhar Ghosh, Aristeidis Sotiras|<http://arxiv.org/pdf/2412.07156v2>|提出了一种多任务深度学习架构QCResUNet，实现了对脑肿瘤和心脏MRI分割质量的主体级和体素级预...|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Evaluating the Evaluators: Trust in Adversarial Robustness Tests|评估评估者：对抗稳健性测试的可信度评估|Antonio Emanuele Cinà, Maura Pintor, Luca Demetrio, Ambra Demontis, Battista Biggio, Fabio Roli|<http://arxiv.org/pdf/2507.03450v1>|提出了一种标准化攻击评估框架AttackBench，以提升对抗稳健性测试的可靠性和一致性。|
|🆕 发布|UltraDfeGAN: Detail-Enhancing Generative Adversarial Networks for High-Fidelity Functional Ultrasound Synthesis|超细节增强生成对抗网络：用于高保真功能超声合成|Zhuo Li, Xuhang Chen, Shuqiang Wang|<http://arxiv.org/pdf/2507.03341v1>|提出了一种基于GAN的增强功能超声图像生成方法，有效提高了图像质量和临床应用潜力。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|IAP: Improving Continual Learning of Vision-Language Models via Instance-Aware Prompting|IAP：通过实例感知提示改进视觉语言模型的持续学习|Hao Fu, Hanbin Zhao, Jiahua Dong, Henghui Ding, Chao Zhang, Hui Qian|<http://arxiv.org/pdf/2503.20612v2>|[代码](https://github.com/FerdinandZJU/IAP.); 提出Instance-Aware Prompting框架，通过自适应实例级提示优化视觉语言模型在持续...|
|📝 更新|Finetuning CLIP to Reason about Pairwise Differences|微调CLIP以推理成对差异|Dylan Sam, Devin Willmott, Joao D. Semedo, J. Zico Kolter|<http://arxiv.org/pdf/2409.09721v2>|通过对比训练改进CLIP模型，使其能通过文本描述推理图像间的差异，增强分类和检索能力。|
|🆕 发布|Dynamic Multimodal Prototype Learning in Vision-Language Models|动态多模态原型学习在视觉-语言模型中的应用|Xingyu Zhu, Shuo Wang, Beier Zhu, Miaoge Li, Yunfan Li, Junfeng Fang, Zhicai Wang, Dongsheng Wang .etc.|<http://arxiv.org/pdf/2507.03657v1>|提出了一种动态多模态原型学习框架ProtoMM，通过结合文本描述和视觉粒子，提高了视觉语言模型在测试...|
|🆕 发布|An Advanced Deep Learning Framework for Ischemic and Hemorrhagic Brain Stroke Diagnosis Using Computed Tomography (CT) Images|基于计算机断层扫描（CT）图像的缺血性和出血性脑卒中诊断高级深度学习框架|Md. Sabbir Hossen, Eshat Ahmed Shuvo, Shibbir Ahmed Arif, Pabon Shaha, Md. Saiduzzaman, Mostofa Kamal Nasir|<http://arxiv.org/pdf/2507.03558v1>|提出了一种结合轻量级预训练模型和优化策略的脑卒中诊断框架，实现了97.93%的高分类准确率。|
|🆕 发布|Unlearning the Noisy Correspondence Makes CLIP More Robust|《消除噪声对应使CLIP更加鲁棒》|Haochen Han, Alex Jinpeng Wang, Peijun Ye, Fangming Liu|<http://arxiv.org/pdf/2507.03434v1>|提出了一种噪声对应消除框架，通过遗忘噪声知识显著增强视觉语言模型的鲁棒性。|
|🆕 发布|Learning Normals of Noisy Points by Local Gradient-Aware Surface Filtering|通过局部梯度感知表面滤波学习噪声点的法线|Qing Li, Huifang Feng, Xun Gong, Yu-Shen Liu|<http://arxiv.org/pdf/2507.03394v1>|[代码](https://github.com/LeoQLi/LGSF.); 提出了一种利用局部梯度感知表面滤波从噪声点云中学习法线的方法，有效解决了传统方法在处理噪声数据时的局...|
|📝 更新|TI-PREGO: Chain of Thought and In-Context Learning for Online Mistake Detection in PRocedural EGOcentric Videos|TI-PREGO：面向程序性主观视频在线错误检测的链式思维与情境学习|Leonardo Plini, Luca Scofano, Edoardo De Matteis, Guido Maria D'Amely di Melendugno, Alessandro Flaborea, Andrea Sanchietti, Giovanni Maria Farinella, Fabio Galasso .etc.|<http://arxiv.org/pdf/2411.02570v2>|提出了一种双分支架构，通过在线识别和预测步骤来实时检测开放集 procedural 错误。|
|🆕 发布|Source-Free Domain Adaptation via Multi-view Contrastive Learning|无源域自适应通过多视角对比学习|Amirfarhad Farhadi, Naser Mozayani, Azadeh Zamanifar|<http://arxiv.org/pdf/2507.03321v1>|提出无源域自适应新方法，通过可靠样本记忆和多视角对比学习提升样本质量和伪标签准确性。|
|📝 更新|Memory Storyboard: Leveraging Temporal Segmentation for Streaming Self-Supervised Learning from Egocentric Videos|《记忆故事板：利用时间分割进行自我监督学习，从第一视角视频流中学习》|Yanlai Yang, Mengye Ren|<http://arxiv.org/pdf/2501.12254v2>|提出“Memory Storyboard”方法，通过时间分割有效总结视觉流，提升 egocentri...|
|📝 更新|Anymate: A Dataset and Baselines for Learning 3D Object Rigging|“Anymate：用于学习三维对象绑定的数据集与基线”|Yufan Deng, Yuhao Zhang, Chen Geng, Shangzhe Wu, Jiajun Wu|<http://arxiv.org/pdf/2505.06227v2>|[代码](https://anymate3d.github.io/.); 提出大规模Anymate数据集及学习框架，实现自动3D对象绑定，显著优于现有方法。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Learning Differentiable Logic Programs for Abstract Visual Reasoning|学习用于抽象视觉推理的可微分逻辑程序|Hikaru Shindo, Viktor Pfanschilling, Devendra Singh Dhami, Kristian Kersting|<http://arxiv.org/pdf/2307.00928v2>|提出了一种图基础的微分推理方法NEUMANN，高效处理抽象视觉推理任务并学习复杂场景下的解释性程序。|
|🆕 发布|On the rankability of visual embeddings|论视觉嵌入的秩可分性|Ankit Sonthalia, Arnas Uselis, Seong Joon Oh|<http://arxiv.org/pdf/2507.03683v1>|[代码](https://github.com/aktsonthalia/rankable-vision-embeddings.); 发现视觉嵌入模型能自然捕捉连续属性，少量样本即可确定排序轴。|
|📝 更新|Pay Attention to the Keys: Visual Piano Transcription Using Transformers|关注关键音符：使用变换器的视觉钢琴转录|Uros Zivanovic, Ivan Pilkov, Carlos Eduardo Cancino-Chacón|<http://arxiv.org/pdf/2411.09037v2>|提出基于视觉变换器的钢琴视觉转录系统，实现了音符起始和结束预测的精度提升。|
|🆕 发布|From Video to EEG: Adapting Joint Embedding Predictive Architecture to Uncover Visual Concepts in Brain Signal Analysis|从视频到脑电图：调整联合嵌入预测架构以揭示视觉概念在脑信号分析中的应用|Amir Hojjati, Lu Li, Ibrahim Hameed, Anis Yazidi, Pedro G. Lind, Rabindra Khadka|<http://arxiv.org/pdf/2507.03633v1>|提出EEG-VJEPA模型，将EEG信号视作视频序列，通过联合嵌入和自适应掩码学习有意义的时空表征，...|
|📝 更新|LLaVA-SP: Enhancing Visual Representation with Visual Spatial Tokens for MLLMs|LLaVA-SP：使用视觉空间标记增强多模态大型语言模型的视觉表征|Haoran Lou, Chunxiao Fan, Ziyan Liu, Yuexin Wu, Xinliang Wang|<http://arxiv.org/pdf/2507.00505v3>|[代码](https://github.com/CnFaker/LLaVA-SP.); 提出增强多模态大语言模型视觉表征的新方法LLaVA-SP，通过添加六种空间视觉标记改善局部关系建模。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Query-Based Adaptive Aggregation for Multi-Dataset Joint Training Toward Universal Visual Place Recognition|面向通用视觉位置识别的多数据集联合训练中的基于查询的自适应聚合|Jiuhong Xiao, Yang Zhou, Giuseppe Loianno|<http://arxiv.org/pdf/2507.03831v1>|提出了一种基于查询的自适应聚合方法QAA，有效提升多数据集联合训练下视觉定位模型的泛化能力。|
|🆕 发布|Helping CLIP See Both the Forest and the Trees: A Decomposition and Description Approach|《帮助CLIP既见森林又见树木：一种分解与描述方法》|Leyan Xue, Zongbo Han, Guangyu Wang, Qinghua Hu, Mingyue Cheng, Changqing Zhang|<http://arxiv.org/pdf/2507.03458v1>|提出了一种通过随机多裁剪增强CLIP模型对局部视觉特征识别能力的方法，有效弥补了其全局模式偏好导致的...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Enhancing Satellite Object Localization with Dilated Convolutions and Attention-aided Spatial Pooling|利用扩张卷积和注意力辅助的空间池化增强卫星图像目标定位|Seraj Al Mahmud Mostafa, Chenxi Wang, Jia Yue, Yuta Hozumi, Jianwu Wang|<http://arxiv.org/pdf/2505.05599v2>|[代码](https://github.com/AI-4-atmosphere-remote-sensing/satellite-object-localization.); 提出YOLO-DCAP模型，通过多尺度膨胀卷积和注意力辅助空间池化提升卫星图像中物体定位准确性。|
|🆕 发布|Information-Bottleneck Driven Binary Neural Network for Change Detection|信息瓶颈驱动的二值神经网络用于变化检测|Kaijie Yin, Zhiyuan Zhang, Shu Kong, Tian Gao, Chengzhong Xu, Hui Kong|<http://arxiv.org/pdf/2507.03504v1>|首次提出专门针对变化检测的二值神经网络，通过信息瓶颈原理增强其表征能力和特征区分度。|
|🆕 发布|Be the Change You Want to See: Revisiting Remote Sensing Change Detection Practices|成为你希望看到的变化：重新审视遥感变化检测实践|Blaž Rolih, Matic Fučka, Filip Wolf, Luka Čehovin Zajc|<http://arxiv.org/pdf/2507.03367v1>|[代码](https://github.com/blaz-r/BTC-change-detection); 揭示了基础设计选择对遥感变化检测性能的重要性，通过优化现有模型结构实现超越现有技术的性能。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ChestGPT: Integrating Large Language Models and Vision Transformers for Disease Detection and Localization in Chest X-Rays|胸部GPT：融合大型语言模型与视觉变换器进行胸部X射线疾病检测与定位|Shehroz S. Khan, Petar Przulj, Ahmed Ashraf, Ali Abedi|<http://arxiv.org/pdf/2507.03739v1>|集成大型语言模型和视觉变压器以辅助放射科医生进行疾病分类和定位的深度学习框架。|
|🆕 发布|Dual-Alignment Knowledge Retention for Continual Medical Image Segmentation|双对齐知识保持用于连续医学图像分割|Yuxin Ye, Yan Liu, Shujian Yu|<http://arxiv.org/pdf/2507.03638v1>|提出了一种双对齐策略框架，有效减少医疗图像分割中的灾难性遗忘问题。|
|🆕 发布|Causal-SAM-LLM: Large Language Models as Causal Reasoners for Robust Medical Segmentation|因果-SAM-LLM：大型语言模型作为因果推理器用于稳健的医学分割|Tao Tang, Shijie Xu, Yiting Wu, Zhixiang Lu|<http://arxiv.org/pdf/2507.03585v1>|提出利用大型语言模型作为因果推理器，通过文本描述和实时干预提升医学图像分割的跨域泛化能力。|
|🆕 发布|2.5D Object Detection for Intelligent Roadside Infrastructure|智能路边基础设施的2.5D目标检测|Nikolai Polley, Yacin Boualili, Ferdinand Mütsch, Maximilian Zipfl, Tobias Fleck, J. Marius Zöllner|<http://arxiv.org/pdf/2507.03564v1>|提出了一种针对路边基础设施的2.5D物体检测框架，通过预测车辆在图像中的平行四边形地面位置，实现了高...|
|🆕 发布|PhotIQA: A photoacoustic image data set with image quality ratings|PhotIQA：一种带有图像质量评分的光声图像数据集|Anna Breger, Janek Gröhl, Clemens Karner, Thomas R Else, Ian Selby, Jonathan Weir-McCall, Carola-Bibiane Schönlieb|<http://arxiv.org/pdf/2507.03478v1>|构建了首个针对光声成像的图像质量评估数据集PhotIQA，验证了新型评估方法的有效性。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MRC-DETR: An Adaptive Multi-Residual Coupled Transformer for Bare Board PCB Defect Detection|MRC-DETR：用于裸板PCB缺陷检测的自适应多残差耦合变换器|Jiangzhong Cao, Huanqi Wu, Xu Zhang, Lianghong Tan, Huan Zhang|<http://arxiv.org/pdf/2507.03386v1>|提出MRC-DETR框架，通过增强特征表示和降低计算冗余，有效提升PCB缺陷检测的准确性和效率。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Inverse Synthetic Aperture Fourier Ptychography|反合成孔径傅里叶相衬成像术|Matthew A. Chan, Casey J. Pellizzari, Christopher A. Metzler|<http://arxiv.org/pdf/2507.03733v1>|提出了一种通过目标运动生成测量多样性并使用学习估计k空间坐标的逆合成孔径傅里叶错位成像技术，简化了成...|
|📝 更新|Many-Task Federated Fine-Tuning via Unified Task Vectors|通过统一任务向量进行多任务联邦微调|Vasileios Tsouvalas, Tanir Ozcelebi, Nirvana Meratnia|<http://arxiv.org/pdf/2502.06376v2>|提出了一种多任务联邦微调方法MaTU，通过联合学习任务向量，无需服务器管理个体模型，有效应对任务异质...|
|📝 更新|Orientation Scores should be a Piece of Cake|方向评分应该易如反掌|Finn M. Sherry, Chase van de Geijn, Erik J. Bekkers, Remco Duits|<http://arxiv.org/pdf/2504.00702v2>|提出了一种最小化位置-方向不确定性的新型cake波let，简化了(PDE-)G-CNN网络结构并提升...|
|🆕 发布|Event2Audio: Event-Based Optical Vibration Sensing|事件到音频：基于事件的 光学振动感知|Mingxuan Cai, Dekel Galor, Amit Pal Singh Kohli, Jacob L. Yates, Laura Waller|<http://arxiv.org/pdf/2507.03273v1>|利用事件相机捕捉振动，实现了快速恢复音频的高效方法。|

