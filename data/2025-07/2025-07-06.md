## [UPDATED!] **2025-07-06** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PAVLM: Advancing Point Cloud based Affordance Understanding Via Vision-Language Model|PAVLM：通过视觉语言模型提升基于点云的可用性理解|Shang-Ching Liu, Van Nhiem Tran, Wenkai Chen, Wei-Lun Cheng, Yen-Lin Huang, I-Bin Liao, Yung-Hui Li, Jianwei Zhang|<http://arxiv.org/pdf/2410.11564v2>|定位3D物体操作关键区域，PAVLM模型融合语言模型知识提升理解力。|
|🆕 发布|README: Robust Error-Aware Digital Signature Framework via Deep Watermarking Model|《通过深度水印模型实现的鲁棒错误感知数字签名框架》|Hyunwook Choi, Sangyun Won, Daeyeon Hwang, Junhyeok Choi|<http://arxiv.org/pdf/2507.04495v1>|提出了一种深水印模型，通过容量扩展和错误纠正技术，实现了图像中嵌入数字签名的稳健性和准确性。|
|🆕 发布|MVL-Loc: Leveraging Vision-Language Model for Generalizable Multi-Scene Camera Relocalization|MVL-Loc：利用视觉-语言模型实现通用多场景相机重定位|Zhendong Xiao, Wu Wei, Shujie Ji, Shan Yang, Changhao Chen|<http://arxiv.org/pdf/2507.04509v1>|提出了一种利用视觉语言模型进行多场景相机重定位的新框架，实现了室内外环境下的泛化能力和准确性提升。|
|🆕 发布|A Training-Free Style-Personalization via Scale-wise Autoregressive Model|无需训练的基于尺度自回归模型的风格个性化|Kyoungmin Lee, Jihun Park, Jongmin Gim, Wonhyeok Choi, Kyumin Hwang, Jaeyeul Kim, Sunghoon Im|<http://arxiv.org/pdf/2507.04482v1>|提出了一种无需训练的图像生成框架，通过逐尺度自回归模型实现内容和风格的灵活控制。|
|🆕 发布|Multimedia Verification Through Multi-Agent Deep Research Multimodal Large Language Models|多媒体验证通过多代理深度研究多模态大型语言模型|Huy Hoan Le, Van Sy Thinh Nguyen, Thi Le Chi Dang, Vo Thanh Khang Nguyen, Truong Thanh Hung Nguyen, Hung Cao|<http://arxiv.org/pdf/2507.04410v1>|提出多智能体系统结合大型多模态语言模型，有效识别并验证多媒体信息真伪。|
|🆕 发布|SeqTex: Generate Mesh Textures in Video Sequence|序列纹理生成：在视频序列中生成网格纹理|Ze Yuan, Xin Yu, Yangtian Sun, Yuan-Chen Guo, Yan-Pei Cao, Ding Liang, Xiaojuan Qi|<http://arxiv.org/pdf/2507.04285v1>|SeqTex通过将3D纹理生成视为序列生成问题，直接利用预训练视频模型生成高质量的UV纹理图，避免了...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge|梦幻VLA：一种融合全面世界知识的视觉-语言-动作模型|Wenyao Zhang, Hongsi Liu, Zekun Qi, Yunnan Wang, XinQiang Yu, Jiazhao Zhang, Runpei Dong, Jiawei He .etc.|<http://arxiv.org/pdf/2507.04447v1>|DreamVLA通过融合全面的世界知识预测，为机器人操作任务构建了感知-预测-行动循环。|
|📝 更新|DiT4SR: Taming Diffusion Transformer for Real-World Image Super-Resolution|DiT4SR：驯服扩散变换器以实现现实世界图像超分辨率|Zheng-Peng Duan, Jiawei Zhang, Xin Jin, Ziheng Zhang, Zheng Xiong, Dongqing Zou, Jimmy S. Ren, Chun-Le Guo .etc.|<http://arxiv.org/pdf/2503.23580v2>|[代码](https://adam-duan.github.io/projects); 提出DiT4SR模型，将低分辨率图像信息融入扩散变压器模型，提升真实世界图像超分辨率性能。|
|🆕 发布|Comprehensive Information Bottleneck for Unveiling Universal Attribution to Interpret Vision Transformers|全面信息瓶颈：揭示视觉变换器的通用归因解释|Jung-Ho Hong, Ho-Joong Kim, Kyu-Sung Jeon, Seong-Whan Lee|<http://arxiv.org/pdf/2507.04388v1>|提出了一种跨层共享信息的综合信息瓶颈方法，提高了计算机视觉模型决策解释的准确性。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Perception, Reason, Think, and Plan: A Survey on Large Multimodal Reasoning Models|感知、推理、思考与规划：大型多模态推理模型综述|Yunxin Li, Zhenyu Liu, Zitao Li, Xuanyu Zhang, Zhenran Xu, Xinyu Chen, Haoyuan Shi, Shenyuan Jiang .etc.|<http://arxiv.org/pdf/2505.04921v2>|系统梳理了大型多模态推理模型的发展脉络，提出了四阶段发展路线图以促进综合感知与深度推理。|
|🆕 发布|SFOOD: A Multimodal Benchmark for Comprehensive Food Attribute Analysis Beyond RGB with Spectral Insights|“SFOOD：一种超越RGB的全面食品属性分析多模态基准，具有光谱洞察力”|Zhenbo Xu, Jinghan Yang, Gong Huang, Jiqing Feng, Liu Liu, Ruihan Sun, Ajin Meng, Zhuo Zhang .etc.|<http://arxiv.org/pdf/2507.04412v1>|构建首个大规模光谱食品(SFOOD)基准集，利用光谱数据提升食品属性分析的准确性。|
|📝 更新|ISLES'24 -- A Real-World Longitudinal Multimodal Stroke Dataset|ISLES'24 -- 一个真实世界的纵向多模态卒中数据集|Evamaria Olga Riedel, Ezequiel de la Rosa, The Anh Baran, Moritz Hernandez Petzsche, Hakim Baazaoui, Kaiyuan Yang, Fabio Antonio Musio, Houjing Huang .etc.|<http://arxiv.org/pdf/2408.11142v2>|提供了首个包含多时间点影像和临床数据的脑卒中纵向多模态数据集，助力机器学习算法开发以优化临床决策。|
|📝 更新|Particle Trajectory Representation Learning with Masked Point Modeling|粒子轨迹表示学习：基于遮挡点建模的方法|Sam Young, Yeon-jae Jwa, Kazuhiro Terao|<http://arxiv.org/pdf/2502.02558v3>|提出了一种自监督学习方法PoLAr-MAE，通过掩码点建模直接从数据中学习物理意义显著的粒子轨迹表示...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DynOPETs: A Versatile Benchmark for Dynamic Object Pose Estimation and Tracking in Moving Camera Scenarios|动态目标姿态估计与跟踪移动摄像头场景的通用基准测试 DynOPETs|Xiangting Meng, Jiaqi Yang, Mingshu Chen, Chenxin Yan, Yujiao Shi, Wenchao Ding, Laurent Kneip|<http://arxiv.org/pdf/2503.19625v2>|提出 DynOPETs 数据集及高效标注流程，解决了动态场景中物体姿态估计与跟踪的数据不足问题。|
|📝 更新|mmEgoHand: Egocentric Hand Pose Estimation and Gesture Recognition with Head-mounted Millimeter-wave Radar and IMU|毫米波雷达与惯性测量单元融合的自主视角手部姿态估计与手势识别：mmEgoHand|Yizhe Lv, Tingting Zhang, Zhijian Wang, Yunpeng Song, Han Ding, Jinsong Han, Fei Wang|<http://arxiv.org/pdf/2501.13805v2>|[代码](https://github.com/WhisperYi/mmVR.); 引入头戴式毫米波雷达与IMU融合的mmEgoHand系统，实现了动态手部姿态估计和手势识别，大幅提升...|
|🆕 发布|DMAT: An End-to-End Framework for Joint Atmospheric Turbulence Mitigation and Object Detection|DMAT：一种用于联合大气湍流抑制和目标检测的端到端框架|Paul Hill, Alin Achim, Dave Bull, Nantheera Anantrasirichai|<http://arxiv.org/pdf/2507.04323v1>|提出了一种端到端框架DMAT，有效缓解大气湍流影响并提升目标检测性能。|
|🆕 发布|Grid-Reg: Grid-Based SAR and Optical Image Registration Across Platforms|基于网格的跨平台合成孔径雷达与光学图像配准方法|Xiaochen Wei, Weiwei Guo, Zenghui Zhang, Wenxian Yu|<http://arxiv.org/pdf/2507.04233v1>|提出了一种基于网格的跨平台合成孔径雷达与光学图像配准方法，有效应对几何和辐射差异挑战。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Street design and driving behavior: evidence from a large-scale study in Milan, Amsterdam, and Dubai|街道设计与驾驶行为：来自在米兰、阿姆斯特丹和迪拜的大规模研究的证据|Giacomo Orsi, Titus Venverloo, Andrea La Grotteria, Umberto Fugiglando, Fábio Duarte, Paolo Santi, Carlo Ratti|<http://arxiv.org/pdf/2507.04434v1>|利用计算机视觉分析街道设计如何影响驾驶行为，为城市规划提供速度限制遵守的预测模型。|
|🆕 发布|MambaFusion: Height-Fidelity Dense Global Fusion for Multi-modal 3D Object Detection|MambaFusion：用于多模态三维目标检测的高度保真稠密全局融合|Hanshi Wang, Jin Gao, Weiming Hu, Zhipeng Zhang|<http://arxiv.org/pdf/2507.04369v1>|提出高度保真度编码方法，通过混合Mamba块实现高效的多模态3D物体检测。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ViTaL: A Multimodality Dataset and Benchmark for Multi-pathological Ovarian Tumor Recognition|ViTaL：一种多模态数据集和多路径卵巢肿瘤识别基准|You Zhou, Lijiang Chen, Guangxia Cui, Wenpei Bai, Yu Guo, Shuchang Lyu, Guangliang Cheng, Qi Zhao|<http://arxiv.org/pdf/2507.04383v1>|[代码](https://github.com/GGbond-study/vitalnet.); 提出ViTaL多模态数据集及基于THOAM的ViTaL-Net，实现卵巢肿瘤多病理类型识别。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Investigating the diversity and stylization of contemporary user generated visual arts in the complexity entropy plane|探究当代用户生成视觉艺术在复杂度熵平面上的多样性与风格化|Seunghwan Kim, Byunghwee Lee, Wonjae Lee|<http://arxiv.org/pdf/2408.10356v3>|探究了当代用户生成视觉艺术风格多样性和风格化，通过复杂性-熵平面揭示了其演化过程。|
|🆕 发布|MambaVideo for Discrete Video Tokenization with Channel-Split Quantization|离散视频标记的MambaVideo：基于通道分割量化的实现|Dawit Mureja Argaw, Xian Liu, Joon Son Chung, Ming-Yu Liu, Fitsum Reda|<http://arxiv.org/pdf/2507.04559v1>|提出MambaVideo模型，通过创新编码架构和通道分割量化方法，提升视频生成效率和质量。|
|🆕 发布|Grounded Gesture Generation: Language, Motion, and Space|基于语言的动作生成：语言、运动与空间|Anna Deichler, Jim O'Regan, Teo Guichoux, David Johansson, Jonas Beskow|<http://arxiv.org/pdf/2507.04522v1>|提出了一种整合语言、动作和空间信息的多模态框架，为生成情境感知的接地手势提供了新方法和数据集。|
|🆕 发布|CoT-lized Diffusion: Let's Reinforce T2I Generation Step-by-step|逐步强化的CoT-lized扩散：让我们一步步加强文本到图像生成|Zheyuan Liu, Munan Ning, Qihui Zhang, Shuo Yang, Zhongrui Wang, Yiwei Yang, Xianzhe Xu, Yibing Song .etc.|<http://arxiv.org/pdf/2507.04451v1>|引入逐步推理的CoT-Diff框架，通过整合3D布局规划与扩散过程，大幅提升文本到图像生成中空间对齐...|
|📝 更新|MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation|记忆增强潜在变换器用于任意长度视频生成的MALT扩散|Sihyun Yu, Meera Hahn, Dan Kondratyuk, Jinwoo Shin, Agrim Gupta, José Lezama, Irfan Essa, David Ross .etc.|<http://arxiv.org/pdf/2502.12632v2>|提出了一种针对长视频生成的MALT Diffusion模型，通过分段自回归生成和记忆增强机制，实现了...|
|📝 更新|CMD: Controllable Multiview Diffusion for 3D Editing and Progressive Generation|CMD: 三维编辑与渐进生成可控多视角扩散|Peng Li, Suizhi Ma, Jialiang Chen, Yuan Liu, Congyi Zhang, Wei Xue, Wenhan Luo, Alla Sheffer .etc.|<http://arxiv.org/pdf/2505.07003v2>|提出了一种可控多视角扩散方法CMD，实现了3D模型的部分生成与灵活局部编辑。|
|🆕 发布|Multi-Modal Semantic Parsing for the Interpretation of Tombstone Inscriptions|多模态语义解析用于墓碑碑文解读|Xiao Zhang, Johan Bos|<http://arxiv.org/pdf/2507.04377v1>|提出了一种多模态语义解析框架，利用视觉语言模型提高墓碑内容的解析准确度，助力文化遗产保护。|
|📝 更新|Enhancing Neural Autoregressive Distribution Estimators for Image Reconstruction|增强神经自回归分布估计器用于图像重建|Ambrose Emmett-Iwaniw, Nathan Kirk|<http://arxiv.org/pdf/2506.05391v2>|提出了一种改进的卷积神经网络自回归分布估计模型，通过观察部分像素预测图像其余部分，提高了图像重建质量...|
|🆕 发布|Towards Lightest Low-Light Image Enhancement Architecture for Mobile Devices|面向移动设备的轻量级低光照图像增强架构研究|Guangrui Bai, Hailong Yan, Wenhai Liu, Yahui Deng, Erbao Dong|<http://arxiv.org/pdf/2507.04277v1>|提出了一种超轻量级无监督低光照图像增强框架，实现了在资源受限设备上的实时高效处理。|
|🆕 发布|AutoLayout: Closed-Loop Layout Synthesis via Slow-Fast Collaborative Reasoning|自动布局：通过慢快协同推理的闭环布局合成|Weixing Chen, Dafeng Chi, Yang Liu, Yuxi Yang, Yexin Zhang, Yuzheng Zhuang, Xingyue Quan, Jianye Hao .etc.|<http://arxiv.org/pdf/2507.04293v1>|提出AutoLayout方法，通过慢快协同推理和自适应关系库，有效生成物理合理且语义一致的布局。|
|📝 更新|EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language Models|易编辑2：一种用于编辑大型语言模型的易用型指导框架|Ziwen Xu, Shuxun Wang, Kewei Xu, Haoming Xu, Mengru Wang, Xinle Deng, Yunzhi Yao, Guozhou Zheng .etc.|<http://arxiv.org/pdf/2504.15133v2>|[代码](https://github.com/zjunlp/EasyEdit); 提出EasyEdit2框架，通过简单示例即可灵活调整大型语言模型的行为。|
|🆕 发布|MoReMouse: Monocular Reconstruction of Laboratory Mouse|单目重建实验室小鼠：MoReMouse|Yuan Zhong, Jingxiang Sun, Liang An, Yebin Liu|<http://arxiv.org/pdf/2507.04258v1>|[代码](https://zyyw-eric.github.io/MoreMouse-webpage); 首次提出针对实验鼠的单目密集3D重建网络，通过合成数据集和特殊网络架构显著提升重建精度和稳定性。|
|🆕 发布|DreamPoster: A Unified Framework for Image-Conditioned Generative Poster Design|《DreamPoster：一种用于图像条件生成海报设计的统一框架》|Xiwei Hu, Haokun Chen, Zhongqi Qi, Hui Zhang, Dexiang Hong, Jie Shao, Xinglong Wu|<http://arxiv.org/pdf/2507.04218v1>|DreamPoster通过结合文本和图像输入，智能生成高质量海报，实现了灵活的分辨率和布局输出。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DMesh++: An Efficient Differentiable Mesh for Complex Shapes|DMesh++：一种用于复杂形状的高效可微分网格|Sanghyun Son, Matheus Gadelha, Yang Zhou, Matthew Fisher, Zexiang Xu, Yi-Ling Qiao, Ming C. Lin, Yi Zhou|<http://arxiv.org/pdf/2412.16776v2>|[代码](https://sonsang.github.io/dmesh2-project); 提出了一种高效的可微分网格处理方法，将复杂形状的处理时间复杂度从O(N)降低至O(log N)。|
|📝 更新|Free-Mask: A Novel Paradigm of Integration Between the Segmentation Diffusion Model and Image Editing|自由遮罩：分割扩散模型与图像编辑之间的一种新颖融合范式|Bo Gao, Jianhui Wang, Xinyuan Song, Yangfan He, Fangxu Xing, Tianyu Shi|<http://arxiv.org/pdf/2411.01819v4>|提出Free-Mask框架，结合扩散模型与图像编辑，生成多实例合成数据以提升语义分割性能。|
|🆕 发布|CLIP-RL: Surgical Scene Segmentation Using Contrastive Language-Vision Pretraining & Reinforcement Learning|CLIP-RL：基于对比性语言-视觉预训练与强化学习的手术场景分割|Fatmaelzahraa Ali Ahmed, Muhammad Arsalan, Abdulaziz Al-Ali, Khalid Al-Jalham, Shidin Balakrishnan|<http://arxiv.org/pdf/2507.04317v1>|提出CLIP-RL模型，结合对比语言-视觉预训练和强化学习进行手术场景分割，实现高性能语义区分。|
|🆕 发布|Surg-SegFormer: A Dual Transformer-Based Model for Holistic Surgical Scene Segmentation|“Surg-SegFormer：一种基于双重变换器的全面手术场景分割模型”|Fatimaelzahraa Ahmed, Muraam Abdel-Ghani, Muhammad Arsalan, Mahmoud Ali, Abdulaziz Al-Ali, Shidin Balakrishnan|<http://arxiv.org/pdf/2507.04304v1>|提出了一种无需用户提示的全景手术场景分割模型Surg-SegFormer，实现了优于现有技术的分割性...|
|🆕 发布|Clustering via Self-Supervised Diffusion|通过自监督扩散进行聚类|Roy Uziel, Irit Chelly, Oren Freifeld, Ari Pakman|<http://arxiv.org/pdf/2507.04283v1>|提出了一种结合生成式扩散模型和预训练视觉特征的自我监督聚类框架，实现了高维数据下的精确聚类。|
|🆕 发布|ZERO: Multi-modal Prompt-based Visual Grounding|ZERO：多模态提示基础视觉定位|Sangbum Choi, Kyeongryeol Go|<http://arxiv.org/pdf/2507.04270v1>|提出了一种零样本多提示视觉定位模型ZERO，通过融合文本和视觉线索，实现了跨领域的高效物体检测。|
|🆕 发布|MPQ-DMv2: Flexible Residual Mixed Precision Quantization for Low-Bit Diffusion Models with Temporal Distillation|MPQ-DMv2：具有时间蒸馏的低位扩散模型的灵活残差混合精度量化|Weilun Feng, Chuanguang Yang, Haotong Qin, Yuqi Li, Xiangqi Li, Zhulin An, Libo Huang, Boyu Diao .etc.|<http://arxiv.org/pdf/2507.04290v1>|提出了一种针对极低比特位扩散模型的混合精度量化框架，有效解决了量化导致的性能下降问题。|
|🆕 发布|Quick Bypass Mechanism of Zero-Shot Diffusion-Based Image Restoration|零样本扩散基础图像复原的快速旁路机制|Yu-Shan Tai, An-Yeu, Wu|<http://arxiv.org/pdf/2507.04207v1>|提出快速旁路机制，通过中间近似初始化显著加速零样本扩散模型图像复原过程。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Data-Driven Novelty Score for Diverse In-Vehicle Data Recording|车内数据记录多样化驱动的新颖性评分方法|Philipp Reis, Joshua Ransiek, David Petri, Jacob Langner, Eric Sax|<http://arxiv.org/pdf/2507.04529v1>|提出了一种实时数据选择方法，通过动态均值漂移算法为图像帧分配新颖性得分，以构建更平衡和多样化的数据集...|
|📝 更新|ObjectAdd: Adding Objects into Image via a Training-Free Diffusion Modification Fashion|物体添加：通过无需训练的扩散修改方式将物体添加到图像中|Ziyue Zhang, Yuxin Zhang, Quanjian Song, Rongrong Ji|<http://arxiv.org/pdf/2404.17230v5>|提出了一种无需训练的扩散修改方法ObjectAdd，实现了在指定区域准确添加用户期望的对象。|
|📝 更新|AVTENet: A Human-Cognition-Inspired Audio-Visual Transformer-Based Ensemble Network for Video Deepfake Detection|AVTENet：一种受人类认知启发的新型音频-视觉Transformer基集成网络，用于视频深度伪造检测|Ammarah Hashmi, Sahibzada Adil Shahzad, Chia-Wen Lin, Yu Tsao, Hsin-Min Wang|<http://arxiv.org/pdf/2310.13103v2>|提出了一种融合音频和视觉信息的Transformer网络，显著提升了视频Deepfake检测的准确性...|
|🆕 发布|Domain Generalizable Portrait Style Transfer|域泛化的肖像风格迁移|Xinbo Wang, Wenju Xu, Qing Zhang, Wei-Shi Zheng|<http://arxiv.org/pdf/2507.04243v1>|[代码](https://github.com/wangxb29/DGPST.); 提出了一种跨域通用的人像风格迁移方法，通过建立密集语义对应和采用AdaIN-Wavelet变换实现高...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PIP-Net: Pedestrian Intention Prediction in the Wild|PIP-Net：野外行人意图预测网络|Mohsen Azarmi, Mahdi Rezaei, He Wang|<http://arxiv.org/pdf/2402.12810v3>|提出PIP-Net框架，通过融合动态数据和视觉特征，提前4秒预测行人横穿意图。|
|🆕 发布|A View-consistent Sampling Method for Regularized Training of Neural Radiance Fields|一种保持视点一致性的采样方法用于神经辐射场的正则化训练|Aoxiang Fan, Corentin Dumery, Nicolas Talabot, Pascal Fua|<http://arxiv.org/pdf/2507.04408v1>|提出了一种基于视图一致性分布的NeRF训练正则化方法，有效提高了真实世界场景的重建质量。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Towards Better Visualizing the Decision Basis of Networks via Unfold and Conquer Attribution Guidance|通过网络展开与征服归因引导实现决策基础的可视化改进|Jung-Ho Hong, Woo-Jeoung Nam, Kyu-Sung Jeon, Seong-Whan Lee|<http://arxiv.org/pdf/2312.14201v2>|提出了一种名为UCAG的框架，通过逐层分析图像特征来增强深度神经网络决策的可解释性。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DMesh: A Differentiable Mesh Representation|DMesh：可微分网格表示|Sanghyun Son, Matheus Gadelha, Yang Zhou, Zexiang Xu, Ming C. Lin, Yi Zhou|<http://arxiv.org/pdf/2404.13445v3>|[代码](https://sonsang.github.io/dmesh-project.); 提出了一种可微分的三维网格表示方法DMesh，能够通过梯度优化实现多种观测下的网格重建。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BiVM: Accurate Binarized Neural Network for Efficient Video Matting|BiVM：高效视频抠图的高精度二值化神经网络|Haotong Qin, Xianglong Liu, Xudong Ma, Lei Ke, Yulun Zhang, Jie Luo, Michele Magno|<http://arxiv.org/pdf/2507.04456v1>|提出了一种高效的二值化神经网络BiVM，通过优化编码器与解码器结构，实现了视频抠图的高准确性与低计算...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|BiECVC: Gated Diversification of Bidirectional Contexts for Learned Video Compression|双向上下文门控多样化用于学习视频压缩的BiECVC|Wei Jiang, Junru Li, Kai Zhang, Li Zhang|<http://arxiv.org/pdf/2505.09193v3>|[代码](https://github.com/JiangWeibeta/ECVC.); 提出了一种融合多样化和自适应门控的框架BiECVC，有效提升了双向视频压缩的性能。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Time2Agri: Temporal Pretext Tasks for Agricultural Monitoring|"Time2Agri：面向农业监测的时序性前置任务"|Moti Rattan Gupta, Anupam Sobti|<http://arxiv.org/pdf/2507.04366v1>|提出针对农业监测的三个新颖的自监督学习任务，有效利用时间特性提升作物映射和产量预测精度。|
|📝 更新|AMD: Adaptive Momentum and Decoupled Contrastive Learning Framework for Robust Long-Tail Trajectory Prediction|AMD：自适应动量与解耦对比学习框架用于稳健的长尾轨迹预测|Bin Rao, Haicheng Liao, Yanchen Guan, Chengyue Wang, Bonan Wang, Jiaxun Zhang, Zhenning Li|<http://arxiv.org/pdf/2507.01801v2>|提出AMD框架，通过自适应动量和解耦对比学习策略，有效提升长尾轨迹预测准确性。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Thousand-Brains Systems: Sensorimotor Intelligence for Rapid, Robust Learning and Inference|千脑系统：用于快速、稳健学习和推理的感知运动智能|Niels Leadholm, Viviane Clay, Scott Knudstrup, Hojae Lee, Jeff Hawkins|<http://arxiv.org/pdf/2507.04494v1>|提出“千脑系统”，模仿生物智能的快速学习与推理，通过模块化架构和sensorimotor学习实现高效...|
|🆕 发布|Adversarial Data Augmentation for Single Domain Generalization via Lyapunov Exponent-Guided Optimization|通过李雅普诺夫指数引导优化的单域泛化对抗性数据增强|Zuyu Zhang, Ning Chen, Yongshan Liu, Qinghua Zhang, Xu Zhang|<http://arxiv.org/pdf/2507.04302v1>|提出利用Lyapunov指数指导优化的方法，增强模型在单一领域泛化任务中的适应性和泛化能力。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Polarization Multi-Image Synthesis with Birefringent Metasurfaces|偏振多图像合成与双折射超表面|Dean Hazineh, Soon Wei Daniel Lim, Qi Guo, Federico Capasso, Todd Zickler|<http://arxiv.org/pdf/2307.08106v4>|[代码](https://deanhazineh.github.io/publications); 提出了一种利用双折射超表面和偏振器 mosaic 传感器单次曝光捕获四种光学编码测量的系统，实现了连...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|K Nearest Neighbor-Guided Trajectory Similarity Learning|基于K最近邻引导的轨迹相似性学习|Yanchuan Chang, Xu Cai, Christian S. Jensen, Jianzhong Qi|<http://arxiv.org/pdf/2502.00285v2>|提出TSMini模型，通过子视图机制和多粒度轨迹模式以及k近邻损失函数，提高了轨迹相似性近似准确性。|
|📝 更新|LOD-GS: Level-of-Detail-Sensitive 3D Gaussian Splatting for Detail Conserved Anti-Aliasing|LOD-GS：细节保留的抗锯齿级别敏感的3D高斯绘制|Zhenya Yang, Bingchen Gong, Kai Chen|<http://arxiv.org/pdf/2507.00554v2>|提出了一种根据采样率动态调整滤波强度的LOD-GS方法，有效解决了3D场景渲染中的走样问题。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FA: Forced Prompt Learning of Vision-Language Models for Out-of-Distribution Detection|FA：视觉语言模型在分布外检测中的强制提示学习|Xinhua Lu, Runhe Lai, Yanqi Wu, Kanghao Chen, Wei-Shi Zheng, Ruixuan Wang|<http://arxiv.org/pdf/2507.04511v1>|[代码](https://github.com/0xFAFA/FA.); 提出了一种基于强制提示学习的新框架，利用现有数据提升视觉模型对异常分布样本的检测能力。|
|📝 更新|FedAli: Personalized Federated Learning Alignment with Prototype Layers for Generalized Mobile Services|" FedAli：面向泛化移动服务的原型层个性化联邦学习对齐 "|Sannara Ek, Kaile Wang, François Portet, Philippe Lalanda, Jiannong Cao|<http://arxiv.org/pdf/2411.10595v2>|FedAli通过引入原型层强化客户端间一致性，同时增强个性化适应的鲁棒性，有效解决联邦学习中的客户端...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality|知行强化学习：探索基于知识的真实性强化学习|Baochang Ren, Shuofei Qiao, Wenhao Yu, Huajun Chen, Ningyu Zhang|<http://arxiv.org/pdf/2506.19807v2>|[代码](https://github.com/zjunlp/KnowRL.); 提出方法KnowRL，通过引入事实性奖励，减少大型语言模型在推理过程中的虚构现象。|
|🆕 发布|Efficient Training of Deep Networks using Guided Spectral Data Selection: A Step Toward Learning What You Need|使用引导光谱数据选择的高效深度网络训练：迈向按需学习的步骤|Mohammadreza Sharifi, Ahad Harati|<http://arxiv.org/pdf/2507.04269v1>|[代码](https://github.com/rezasharifi82/GSTDS.); 提出了一种基于光谱分析的动态数据选择算法，减少计算需求同时提升训练效率和模型准确性。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visual Hand Gesture Recognition with Deep Learning: A Comprehensive Review of Methods, Datasets, Challenges and Future Research Directions|深度学习视觉手势识别：方法、数据集、挑战与未来研究方向的综合综述|Konstantinos Foteinos, Jorgen Cani, Manousos Linardakis, Panagiotis Radoglou-Grammatikis, Vasileios Argyriou, Panagiotis Sarigiannidis, Iraklis Varlamis, Georgios Th. Papadopoulos|<http://arxiv.org/pdf/2507.04465v1>|系统梳理了深度学习在视觉手势识别中的应用，为研究者选择策略提供了指导。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Better Safe Than Sorry? Overreaction Problem of Vision Language Models in Visual Emergency Recognition|“宁可信其有？视觉语言模型在视觉紧急识别中的过度反应问题”|Dasol Choi, Seunghyun Lee, Youngsook Song|<http://arxiv.org/pdf/2505.15367v2>|揭示了视觉语言模型在紧急情况识别中的“过度反应”问题，并提出了针对性的诊断数据集VERI。|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Continual Visual Reinforcement Learning with A Life-Long World Model|终身视觉强化学习与一生世界模型|Minting Pan, Wendong Zhang, Geng Chen, Xiangming Zhu, Siyu Gao, Yunbo Wang, Xiaokang Yang|<http://arxiv.org/pdf/2303.06572v2>|提出了一种持续视觉强化学习方法，通过构建终身世界模型防止知识遗忘，有效提升了多任务视觉控制性能。|
|🆕 发布|Transferring Visual Explainability of Self-Explaining Models through Task Arithmetic|通过任务算术传递自解释模型的可视化解释性|Yuya Yoshikawa, Ryotaro Shimizu, Takahiro Kawashima, Yuki Saito|<http://arxiv.org/pdf/2507.04380v1>|提出了一种基于任务算术框架的视觉解释性迁移方法，有效将源域自解释模型的解释性转移到目标域，提升了目标...|
|🆕 发布|M$^3$-Med: A Benchmark for Multi-lingual, Multi-modal, and Multi-hop Reasoning in Medical Instructional Video Understanding|多语言多模态多跳推理在医学教学视频理解中的M$^3$-Med基准|Shenxi Liu, Kan Li, Mingyang Zhao, Yuhang Tian, Bin Li, Shoujun Zhou, Hongliang Li, Fuxia Yang|<http://arxiv.org/pdf/2507.04289v1>|提出了M3-Med多语言、多模态、多跳推理医疗教学视频理解基准，挑战模型深度跨模态理解能力。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FB-Diff: Fourier Basis-guided Diffusion for Temporal Interpolation of 4D Medical Imaging|FB-Diff：基于傅里叶基引导的扩散用于四维医学成像的时间插值|Xin You, Runze Yang, Chuyan Zhang, Zhongliang Jiang, Jie Yang, Nassir Navab|<http://arxiv.org/pdf/2507.04547v1>|提出基于傅里叶基引导的扩散模型FB-Diff，用于4D医疗影像的时间插值，实现更自然的呼吸运动模拟。|
|🆕 发布|Sat2City: 3D City Generation from A Single Satellite Image with Cascaded Latent Diffusion|Sat2City：从单张卫星图像生成三维城市的级联潜在扩散方法|Tongyan Hua, Lutao Jiang, Ying-Cong Chen, Wufan Zhao|<http://arxiv.org/pdf/2507.04403v1>|提出了一种结合稀疏体素网格与潜在扩散模型的新框架，从单张卫星图像生成详细的三维城市结构。|
|🆕 发布|An Explainable Transformer Model for Alzheimer's Disease Detection Using Retinal Imaging|利用视网膜成像的阿尔茨海默病检测可解释Transformer模型|Saeed Jamshidiha, Alireza Rezaee, Farshid Hajati, Mojtaba Golzan, Raymond Chiong|<http://arxiv.org/pdf/2507.04259v1>|提出了一种基于视网膜成像的Transformer模型，用于早期诊断阿尔茨海默病，并通过可视化关键特征...|
|🆕 发布|Deep-Learning-Assisted Highly-Accurate COVID-19 Diagnosis on Lung Computed Tomography Images|深度学习辅助的高精度COVID-19基于肺部CT影像诊断|Yinuo Wang, Juhyun Bae, Ka Ho Chow, Shenyang Chen, Shreyash Gupta|<http://arxiv.org/pdf/2507.04252v1>|提出了一种基于生成对抗网络和滑动窗口的CT图像质量控制方法，并采用敏感成本函数解决数据不平衡问题，实...|
|📝 更新|CRISP-SAM2: SAM2 with Cross-Modal Interaction and Semantic Prompting for Multi-Organ Segmentation|CRISP-SAM2：具有跨模态交互和语义提示的SAM2用于多器官分割|Xinlei Yu, Changmiao Wang, Hui Jin, Ahmed Elazab, Gangyong Jia, Xiang Wan, Changqing Zou, Ruiquan Ge|<http://arxiv.org/pdf/2506.23121v2>|[代码](https://github.com/YU-deep/CRISP_SAM2.git.); 引入CRISP-SAM2模型，通过跨模态交互和语义提示提升多器官分割的准确性和细节表现。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|U-ViLAR: Uncertainty-Aware Visual Localization for Autonomous Driving via Differentiable Association and Registration|U-ViLAR：基于微分关联与注册的自动驾驶不确定性感知视觉定位|Xiaofan Li, Zhihao Xu, Chenming Wu, Zhao Yang, Yumeng Zhang, Jiang-Jiang Liu, Haibao Yu, Fan Duan .etc.|<http://arxiv.org/pdf/2507.04503v1>|提出了一种视觉定位框架U-ViLAR，通过感知和定位不确定性引导，实现城市环境中高精度自适应定位。|
|🆕 发布|Computed Tomography Visual Question Answering with Cross-modal Feature Graphing|计算机断层扫描视觉问答中的跨模态特征图构建|Yuanhe Tian, Chen Su, Junwen Duan, Yan Song|<http://arxiv.org/pdf/2507.04333v1>|提出了一种结合图表示的跨模态特征融合方法，用于提升CT图像视觉问答的准确性和连贯性。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dynamic Frequency Feature Fusion Network for Multi-Source Remote Sensing Data Classification|多源遥感数据分类的动态频率特征融合网络|Yikang Zhao, Feng Gao, Xuepeng Jin, Junyu Dong, Qian Du|<http://arxiv.org/pdf/2507.04510v1>|[代码](https://github.com/oucailab/DFFNet.); 提出了一种动态频率特征融合网络，有效提升了多源遥感数据分类的适应性及准确性。|
|🆕 发布|RegistrationMamba: A Mamba-based Registration Framework Integrating Multi-Expert Feature Learning for Cross-Modal Remote Sensing Images|RegistrationMamba：一种基于Mamba的融合多专家特征学习的跨模态遥感图像配准框架|Wei Wang, Dou Quan, Chonghua Lv, Shuang Wang, Ning Huyan, Yunan Li, Licheng Jiao|<http://arxiv.org/pdf/2507.04397v1>|提出RegistrationMamba框架，利用多专家特征学习和状态空间模型，有效提升跨模态遥感图像...|
|🆕 发布|MVNet: Hyperspectral Remote Sensing Image Classification Based on Hybrid Mamba-Transformer Vision Backbone Architecture|MVNet：基于混合Mamba-Transformer视觉主干架构的高光谱遥感图像分类|Guandong Li, Mengxia Ye|<http://arxiv.org/pdf/2507.04409v1>|提出MVNet网络，融合3D-CNN、Transformer和Mamba优势，有效提取和融合高光谱图...|
|🆕 发布|Exploring Remote Physiological Signal Measurement under Dynamic Lighting Conditions at Night: Dataset, Experiment, and Analysis|探索夜间动态光照条件下远程生理信号测量的方法：数据集、实验与分析|Zhipeng Li, Kegang Wang, Hanguang Xiao, Xingyue Liu, Feizhong Zhou, Jiaxin Jiang, Tianqi Liu|<http://arxiv.org/pdf/2507.04306v1>|[代码](https://github.com/dalaoplan/Happp-rPPG-Toolkit.); 提出夜间动态光照条件下远程生理信号测量的新数据集，促进rPPG算法在复杂环境下的性能提升。|
|📝 更新|4D mmWave Radar for Sensing Enhancement in Adverse Environments: Advances and Challenges|四维毫米波雷达在恶劣环境中的感知增强：进展与挑战|Xiangyuan Peng, Miao Tang, Huawei Sun, Kay Bierzynski, Lorenzo Servadei, Robert Wille|<http://arxiv.org/pdf/2503.24091v3>|[代码](https://github.com/XiangyPeng/4D-mmWave-Radar-in-Adverse-Environments.); 系统综述了4D毫米波雷达在恶劣环境下增强感知性能的研究进展与挑战。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Co-VisiON: Co-Visibility ReasONing on Sparse Image Sets of Indoor Scenes|室内场景稀疏图像集上的共可视推理：Co-VisiON|Chao Chen, Nobel Dang, Juexiao Zhang, Wenkai Sun, Pengfei Zheng, Xuhang He, Yimeng Ye, Jiasheng Zhang .etc.|<http://arxiv.org/pdf/2506.16805v2>|[代码](https://ai4ce.github.io/CoVISION.); 提出Co-VisiON基准，并设计了Covis模型，提升视觉模型在稀疏室内场景中的空间推理能力。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Structured light with a million light planes per second|每秒百万光平面结构光|Dhawal Sirikonda, Praneeth Chakravarthula, Ioannis Gkioulekas, Adithya Pediredla|<http://arxiv.org/pdf/2411.18597v2>|实现了每秒两百万光平面投影的定制声光扫描设备，结合事件相机，大幅提升了结构光三维扫描速度。|

