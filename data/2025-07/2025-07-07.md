## [UPDATED!] **2025-07-07** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MedGemma Technical Report|《MedGemma技术报告》|Andrew Sellergren, Sahar Kazemzadeh, Tiam Jaroensri, Atilla Kiraly, Madeleine Traverse, Timo Kohlberger, Shawn Xu, Fayaz Jamil .etc.|<http://arxiv.org/pdf/2507.05201v1>|提出MedGemma医疗视觉语言模型，提升医疗任务理解和推理能力，减少特定任务调优数据需求。|
|📝 更新|Transfer Attack for Bad and Good: Explain and Boost Adversarial Transferability across Multimodal Large Language Models|跨多模态大型语言模型的解释与提升不良与良好样本的迁移攻击|Hao Cheng, Erjia Xiao, Jiayan Yang, Jinhao Duan, Yichi Wang, Jiahang Cao, Qiang Zhang, Le Yang .etc.|<http://arxiv.org/pdf/2405.20090v4>|分析了跨模态大型语言模型中对抗性样本的迁移性，并提出两种增强迁移性的语义级数据增强方法。|
|🆕 发布|Differential Attention for Multimodal Crisis Event Analysis|多模态危机事件分析中的差分注意力机制|Nusrat Munia, Junfeng Zhu, Olfa Nasraoui, Abdullah-Al-Zubaer Imran|<http://arxiv.org/pdf/2507.05165v1>|[代码](https://github.com/Munia03/Multimodal_Crisis_Event.); 提出了一种结合预训练视觉语言模型和自适应融合策略的方法，有效提升了危机事件数据分类的准确性和可靠性。|
|🆕 发布|ICAS: Detecting Training Data from Autoregressive Image Generative Models|ICAS：检测来自自回归图像生成模型的训练数据|Hongyao Yu, Yixiang Qiu, Yiheng Yang, Hao Fang, Tianqu Zhuang, Jiaxin Hong, Bin Chen, Hao Wu .etc.|<http://arxiv.org/pdf/2507.05068v1>|[代码](https://github.com/Chrisqcwx/ImageAR-MIA.); 提出了一种用于检测训练数据来源的适应性分数聚合策略，有效识别出自回归图像生成模型中的训练样本。|
|🆕 发布|EXPOTION: Facial Expression and Motion Control for Multimodal Music Generation|EXPOTION：面向多模态音乐生成的面部表情与运动控制|Fathinah Izzati, Xinyue Li, Gus Xia|<http://arxiv.org/pdf/2507.04955v1>|提出了一种结合面部表情和身体动作控制的多模态音乐生成模型，提高了音乐生成的表现力和时间同步性。|
|📝 更新|SwiftSeg: Efficient Training-Free Open-Vocabulary Segmentation via Hierarchical Attention Refinement Method|SwiftSeg：通过分层注意力精炼方法的无需训练的高效开放词汇分割|Quang-Huy Che, Vinh-Tiep Nguyen|<http://arxiv.org/pdf/2506.23323v2>|提出了一种无需训练的高效开放词汇分割框架，通过层级注意力精炼方法提升了分割质量和效率。|
|🆕 发布|Geometric-Guided Few-Shot Dental Landmark Detection with Human-Centric Foundation Model|以人为中心的基模型引导的几何引导少量样本牙齿标志点检测|Anbang Wang, Marawan Elbatel, Keyuan Liu, Lizhuo Lin, Meng Lan, Yanqi Yang, Xiaomeng Li|<http://arxiv.org/pdf/2507.04710v1>|[代码](https://github.com/xmed-lab/GeoSapiens.); 提出GeoSapiens框架，通过少量CBCT数据实现高精度牙科解剖标志检测。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CycleVAR: Repurposing Autoregressive Model for Unsupervised One-Step Image Translation|循环向量自回归：将自回归模型重用于无监督一步图像转换|Yi Liu, Shengqian Li, Zuzeng Lin, Feng Wang, Si Liu|<http://arxiv.org/pdf/2506.23347v2>|提出Softmax Relaxed Quantization解决梯度中断问题，并引入CycleVAR...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Adaptation of Multi-modal Representation Models for Multi-task Surgical Computer Vision|多模态表征模型在多任务手术计算机视觉中的适配研究|Soham Walimbe, Britty Baby, Vinkle Srivastav, Nicolas Padoy|<http://arxiv.org/pdf/2507.05020v1>|[代码](https://github.com/CAMMA-public/MML-SurgAdapt); 提出了一种多模态多任务学习框架MML-SurgAdapt，通过自然语言监督和SPML学习减少标注负担...|
|📝 更新|FUDOKI: Discrete Flow-based Unified Understanding and Generation via Kinetic-Optimal Velocities|FUDOKI：基于动能最优速度的离散流统一理解与生成|Jin Wang, Yao Lai, Aoxue Li, Shifeng Zhang, Jiacheng Sun, Ning Kang, Chengyue Wu, Zhenguo Li .etc.|<http://arxiv.org/pdf/2505.20147v2>|提出了基于离散流匹配的统一多模态模型FUDOKI，克服了自回归架构的限制，实现了视觉理解和图像生成的...|
|🆕 发布|MurreNet: Modeling Holistic Multimodal Interactions Between Histopathology and Genomic Profiles for Survival Prediction|MurreNet：建模组织病理学与传统基因组轮廓的整体多模态交互以预测生存率|Mingxin Liu, Chengfei Cai, Jun Li, Pengbo Xu, Jinze Li, Jiquan Ma, Jun Xu|<http://arxiv.org/pdf/2507.04891v1>|提出了一种新型网络MurreNet，通过分解和融合病理图像与基因数据，提高了癌症生存预测的准确性。|
|🆕 发布|SPATIA: Multimodal Model for Prediction and Generation of Spatial Cell Phenotypes|SPATIA：用于预测和生成空间细胞表型的多模态模型|Zhenglun Kong, Mufan Qiu, John Boesen, Xiang Lin, Sukwon Yun, Tianlong Chen, Manolis Kellis, Marinka Zitnik|<http://arxiv.org/pdf/2507.04704v1>|提出了SPATIA模型，整合细胞形态、基因表达和空间信息，提升了对生物组织功能的预测和生成能力。|
|🆕 发布|VectorLLM: Human-like Extraction of Structured Building Contours vis Multimodal LLMs|向量LLM：通过多模态LLM实现类似人类的结构化建筑轮廓提取|Tao Zhang, Shiqing Wei, Shihao Chen, Wenling Yu, Muying Luo, Shunping Ji|<http://arxiv.org/pdf/2507.04664v1>|首次利用多模态大语言模型VectorLLM直接回归建筑轮廓点，提升遥感图像向量提取准确性和泛化能力。|
|🆕 发布|Learning Robust Stereo Matching in the Wild with Selective Mixture-of-Experts|在野外环境中学习具有选择性专家混合的鲁棒立体匹配|Yun Wang, Longguang Wang, Chenghao Zhang, Yongjian Zhang, Zhanjie Zhang, Ao Ma, Chenyou Fan, Tin Lun Lam .etc.|<http://arxiv.org/pdf/2507.04631v1>|[代码](https://github.com/cocowy1/SMoE-Stereo); 提出了一种结合低秩适应和混合专家模块的立体匹配框架，有效提升了跨域稳健性和泛化能力。|
|🆕 发布|MODA: MOdular Duplex Attention for Multimodal Perception, Cognition, and Emotion Understanding|MODA：模块化双工注意力机制用于多模态感知、认知与情感理解|Zhicheng Zhang, Wuyou Xia, Chenxi Zhao, Zhou Yan, Xiaoqiang Liu, Yongjie Zhu, Wenyu Qin, Pengfei Wan .etc.|<http://arxiv.org/pdf/2507.04635v1>|提出MOdular Duplex Attention机制，解决多模态学习中的注意力缺失问题，提升认知...|
|🆕 发布|Learn 3D VQA Better with Active Selection and Reannotation|通过主动选择与重新标注更好地学习三维视觉问答|Shengli Zhou, Yang Liu, Feng Zheng|<http://arxiv.org/pdf/2507.04630v1>|[代码](https://github.com/fz-zsl/AQuA.); 提出了一种多轮互动式主动学习策略，通过模型语义不确定性选择数据并请求重新标注，有效提高3D视觉问答模...|
|📝 更新|Multimodal Latent Diffusion Model for Complex Sewing Pattern Generation|多模态潜在扩散模型用于复杂缝纫图案生成|Shengqi Liu, Yuhao Cheng, Zhuo Chen, Xingyu Ren, Wenhan Zhu, Lincheng Li, Mengxiao Bi, Xiaokang Yang .etc.|<http://arxiv.org/pdf/2412.14453v2>|[代码](https://shengqiliu1.github.io/SewingLDM.); 提出了一种多模态生成模型SewingLDM，通过文本提示、身体形状和服装草图控制生成复杂服装的裁剪图...|
|🆕 发布|VLM2Vec-V2: Advancing Multimodal Embedding for Videos, Images, and Visual Documents|视频、图像和视觉文档多模态嵌入的进步：VLM2Vec-V2|Rui Meng, Ziyan Jiang, Ye Liu, Mingyi Su, Xinyi Yang, Yuepeng Fu, Can Qin, Zeyuan Chen .etc.|<http://arxiv.org/pdf/2507.04590v1>|提出了一种统一框架VLM2Vec-V2，实现了对视频、图像和视觉文档的跨模态嵌入学习，提升了多模态任...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Beyond One Shot, Beyond One Perspective: Cross-View and Long-Horizon Distillation for Better LiDAR Representations|超越单次学习，超越单一视角：跨视角与长时序蒸馏以提高LiDAR表征质量|Xiang Xu, Lingdong Kong, Song Wang, Chuanwei Zhou, Qingshan Liu|<http://arxiv.org/pdf/2507.05260v1>|提出了一种融合跨视角和长时序信息的LiDAR表征学习框架，有效提升了LiDAR语义分割和3D物体检测...|
|📝 更新|DeepCS-TRD, a Deep Learning-based Cross-Section Tree Ring Detector|基于深度学习的横截面树轮检测器DeepCS-TRD|Henry Marichal, Verónica Casaravilla, Candice Power, Karolain Mello, Joaquín Mazarino, Christine Lucas, Ludmila Profumo, Diego Passarella .etc.|<http://arxiv.org/pdf/2504.16242v2>|[代码](https://github.com/hmarichal93/deepcstrd); 提出了一种基于深度学习的自动树轮检测算法，适用于不同图像和树种，性能优于现有方法。|
|🆕 发布|Latent Motion Profiling for Annotation-free Cardiac Phase Detection in Adult and Fetal Echocardiography Videos|成人及胎儿超声心动图视频中无需注释的心脏相位检测的潜在运动分析|Yingyu Yang, Qianye Yang, Kangning Cui, Can Peng, Elena D'Alberti, Netzahualcoyotl Hernandez-Cruz, Olga Patey, Aris T. Papageorghiou .etc.|<http://arxiv.org/pdf/2507.05154v1>|[代码](https://github.com/YingyuYyy/CardiacPhase.); 提出了一种无需标注的心脏周期检测方法，通过自监督学习从视频中提取潜在的心脏运动轨迹。|
|📝 更新|Multi-person Physics-based Pose Estimation for Combat Sports|多人基于物理的姿势估计在格斗运动中的应用|Hossein Feiz, David Labbé, Thomas Romeas, Jocelyn Faubert, Sheldon Andrews|<http://arxiv.org/pdf/2504.08175v3>|提出了一种用于格斗体育的多人物理基础三维姿态估计框架，通过多视角跟踪和优化处理，实现了对快速运动和遮...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-modal Representations for Fine-grained Multi-label Critical View of Safety Recognition|用于细粒度多标签关键安全识别的多模态表征|Britty Baby, Vinkle Srivastav, Pooja P. Jain, Kun Yuan, Pietro Mascagni, Nicolas Padoy|<http://arxiv.org/pdf/2507.05007v1>|[代码](https://github.com/CAMMA-public/CVS-AdaptNet); 提出了一种结合文本描述的多模态方法CVS-AdaptNet，用于精细化的多标签安全关键视角识别，提升...|
|📝 更新|Riemannian Complex Hermit Positive Definite Convolution Network for Polarimetric SAR Image Classification|黎曼复数埃尔米特正定卷积网络在极化合成孔径雷达图像分类中的应用|Junfei Shi, Yuke Li, Mengmeng Nie, Fang Liu, Haiyan Jin, Junhuai Li, Weisi Lin|<http://arxiv.org/pdf/2502.08137v2>|提出了一种直接在黎曼流形上处理复数Hermit正定矩阵的卷积网络，有效提升了极化合成孔径雷达图像分类...|
|📝 更新|Distilling High Diagnostic Value Patches for Whole Slide Image Classification Using Attention Mechanism|使用注意力机制对全切片图像分类提取高诊断价值斑块的方法|Tianhang Nan, Hao Quan, Yong Ding, Xingyu Li, Kai Yang, Xiaoyu Cui|<http://arxiv.org/pdf/2407.19821v3>|提出了一种基于注意力机制的特征蒸馏多实例学习方法，有效排除了干扰 patch，提高了全切片图像分类的...|
|🆕 发布|Bridging KAN and MLP: MJKAN, a Hybrid Architecture with Both Efficiency and Expressiveness|连接KAN与MLP：MJKAN，一种兼具效率与表达性的混合架构|Hanseon Joo, Hayoung Choi, Ook Lee, Minjong Cheon|<http://arxiv.org/pdf/2507.04690v1>|提出MJKAN网络结构，结合KAN的非线性表达能力和MLP的高效性，提升函数回归近似能力和分类任务性...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Rethinking Detecting Salient and Camouflaged Objects in Unconstrained Scenes|重新思考在无约束场景中检测显著和迷彩物体的方法|Zhangjun Zhou, Yiping Li, Chunlin Zhong, Jianuo Huang, Jialun Pei, Hua Li, He Tang|<http://arxiv.org/pdf/2412.10943v3>|[代码](https://github.com/ssecv/USCNet.); 提出了一种新型模型USCNet，通过构建大规模综合数据集USC12K和引入双prompt查询机制，有...|
|📝 更新|Stepwise Decomposition and Dual-stream Focus: A Novel Approach for Training-free Camouflaged Object Segmentation|逐步分解与双流聚焦：一种无需训练的伪装目标分割新方法|Chao Yin, Hao Li, Kequan Yang, Jide Li, Pinpin Zhu, Xiaoqiang Li|<http://arxiv.org/pdf/2506.06818v2>|[代码](https://github.com/ycyinchao/RDVP-MSD); 提出了一种无需训练的RDVP-MSD框架，通过分步骤解耦图像描述和空间约束视觉提示，解决了伪装物体分...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Uncertainty in Real-Time Semantic Segmentation on Embedded Systems|嵌入式系统实时语义分割中的不确定性|Ethan Goan, Clinton Fookes|<http://arxiv.org/pdf/2301.01201v5>|提出了一种结合深度特征提取和贝叶斯回归的方法，在嵌入式实时系统中实现具有不确定性感知的语义分割。|
|🆕 发布|Colorectal Cancer Tumor Grade Segmentation in Digital Histopathology Images: From Giga to Mini Challenge|数字病理图像中结直肠癌肿瘤分级分割：从Giga到Mini挑战|Alper Bahcekapili, Duygu Arslan, Umut Ozdemir, Berkay Ozkirli, Emre Akbas, Ahmet Acar, Gozde B. Akar, Bingdou He .etc.|<http://arxiv.org/pdf/2507.04681v1>|提出基于METU CCTGS数据集的CRC肿瘤分级与分割挑战，六队方法超越标准Swin Transf...|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Beyond Simple Edits: X-Planner for Complex Instruction-Based Image Editing|超越简单编辑：基于复杂指令的图像编辑X-规划器|Chun-Hsiao Yeh, Yilin Wang, Nanxuan Zhao, Richard Zhang, Yuheng Li, Yi Ma, Krishna Kumar Singh|<http://arxiv.org/pdf/2507.05259v1>|提出X-Planner系统，通过多模态大语言模型分解复杂指令，实现精确图像编辑并保持身份一致性。|
|🆕 发布|SegmentDreamer: Towards High-fidelity Text-to-3D Synthesis with Segmented Consistency Trajectory Distillation|SegmentDreamer：面向高保真文本到3D合成的一致性轨迹分割蒸馏方法|Jiahao Zhu, Zixuan Chen, Guangcong Wang, Xiaohua Xie, Yi Zhou|<http://arxiv.org/pdf/2507.05256v1>|SegmentDreamer通过创新的Segmented Consistency Trajector...|
|📝 更新|ISLES'24: Final Infarct Prediction with Multimodal Imaging and Clinical Data. Where Do We Stand?|ISLES'24：多模态成像与临床数据在最终梗死预测中的应用现状如何？|Ezequiel de la Rosa, Ruisheng Su, Mauricio Reyes, Evamaria O. Riedel, Hakim Baazaoui, Roland Wiest, Florian Kofler, Kaiyuan Yang .etc.|<http://arxiv.org/pdf/2408.10966v2>|提出ISLES'24挑战，为脑梗死后遗症预测建立标准化基准，并分析现有方法局限，指明未来研究方向。|
|📝 更新|OminiControl: Minimal and Universal Control for Diffusion Transformer|全方位控制：用于扩散变换器的最小化与通用控制|Zhenxiong Tan, Songhua Liu, Xingyi Yang, Qiaochu Xue, Xinchao Wang|<http://arxiv.org/pdf/2411.15098v6>|提出OminiControl方法，通过极少量参数实现了Diffusion Transformer的灵...|
|🆕 发布|LAID: Lightweight AI-Generated Image Detection in Spatial and Spectral Domains|LAID：空间与光谱域中的轻量级AI生成图像检测|Nicholas Chivaran, Jianbing Ni|<http://arxiv.org/pdf/2507.05162v1>|[代码](https://github.com/nchivar/LAID.); 提出LAID框架，使用轻量级神经网络有效检测AI生成图像，降低计算和存储成本。|
|🆕 发布|Semantic Frame Interpolation|语义帧插值|Yijia Hong, Jiangning Zhang, Ran Yi, Yuji Wang, Weijian Cao, Xiaobin Hu, Zhucun Xue, Yabiao Wang .etc.|<http://arxiv.org/pdf/2507.05173v1>|提出语义帧插值任务并设计SemFi模型，实现多帧率视频内容生成。|
|📝 更新|Holistic Tokenizer for Autoregressive Image Generation|整体标记器用于自回归图像生成|Anlin Zheng, Haochen Wang, Yucheng Zhao, Weipeng Deng, Tiancai Wang, Xiangyu Zhang, Xiaojuan Qi|<http://arxiv.org/pdf/2507.02358v2>|[代码](https://github.com/CVMI-Lab/Hita); 提出了一种全局到局部图像编码方法Hita，通过优先处理全局信息，提升了自回归图像生成模型的训练速度和...|
|🆕 发布|MoDiT: Learning Highly Consistent 3D Motion Coefficients with Diffusion Transformer for Talking Head Generation|MoDiT：使用扩散变换器学习高一致性三维运动系数以生成说话头部|Yucheng Wang, Dan Xu|<http://arxiv.org/pdf/2507.05092v1>|提出MoDiT框架，结合3D Morphable Model与Diffusion Transform...|
|📝 更新|Active Stereo in the Wild through Virtual Pattern Projection|野外通过虚拟模式投影的主动立体视觉|Luca Bartolomei, Matteo Poggi, Fabio Tosi, Andrea Conti, Stefano Mattoccia|<http://arxiv.org/pdf/2406.04345v2>|[代码](https://github.com/bartn8/vppstereo.); 利用深度传感器实现虚拟图案投影，增强了立体视觉的鲁棒性和准确性。|
|🆕 发布|Hear-Your-Click: Interactive Video-to-Audio Generation via Object-aware Contrastive Audio-Visual Fine-tuning|"听你所点：通过对象感知对比音频视觉微调的交互式视频转音频生成"|Yingshan Liang, Keyu Fan, Zhicheng Du, Yiran Wang, Qingyang Shi, Xinyu Zhang, Jiasheng Lu, Peiwu Qin|<http://arxiv.org/pdf/2507.04959v1>|[代码](https://github.com/SynapGrid/Hear-Your-Click); 提出互动式视频转音频生成框架Hear-Your-Click，通过点击视频对象实现精准音频生成。|
|🆕 发布|DC-AR: Efficient Masked Autoregressive Image Generation with Deep Compression Hybrid Tokenizer|深度压缩混合标记器驱动的有效遮蔽自回归图像生成：DC-AR|Yecheng Wu, Junyu Chen, Zhuoyang Zhang, Enze Xie, Jincheng Yu, Junsong Chen, Jinyi Hu, Yao Lu .etc.|<http://arxiv.org/pdf/2507.04947v1>|提出DC-AR框架，通过深度压缩混合 tokenizer 提升了图像生成质量与效率。|
|📝 更新|ReCAP: Recursive Cross Attention Network for Pseudo-Label Generation in Robotic Surgical Skill Assessment|递归交叉注意力网络用于机器人手术技能评估中的伪标签生成|Julien Quarez, Marc Modat, Sebastien Ourselin, Jonathan Shapey, Alejandro Granados|<http://arxiv.org/pdf/2407.05180v4>|提出了一种基于递归交叉注意力的弱监督模型，用于生成伪标签以评估机器人手术技能，性能优于现有方法。|
|📝 更新|PEVLM: Parallel Encoding for Vision-Language Models|并行编码用于视觉-语言模型（PEVLM）|Letian Kang, Shixian Luo, Yiqiang Li, Xiaoyang Yu, Shenxuan Zhou, Yong Wu|<http://arxiv.org/pdf/2506.19651v2>|提出PEVLM方法，通过并行编码降低长视频场景下的注意力计算复杂度，实现速度提升和准确性保持。|
|🆕 发布|GraphBrep: Learning B-Rep in Graph Structure for Efficient CAD Generation|图结构学习B-Rep以实现高效的CAD生成|Weilin Lai, Tie Xu, Hu Wang|<http://arxiv.org/pdf/2507.04765v1>|提出GraphBrep模型，通过显式学习紧凑拓扑结构，有效降低CAD生成中的计算成本。|
|📝 更新|Brain3D: Generating 3D Objects from fMRI|脑3D：从fMRI生成三维物体|Yuankun Yang, Li Zhang, Ziyang Xie, Zhiyuan Yuan, Jianfeng Feng, Xiatian Zhu, Yu-Gang Jiang|<http://arxiv.org/pdf/2405.15239v4>|[代码](https://brain-3d.github.io/.); 提出了一种将fMRI信号转化为3D物体的方法Brain3D，实现了对脑信号的高级语义解析和功能建模。|
|📝 更新|Event-based Photometric Bundle Adjustment|基于事件的光度束调整|Shuang Guo, Guillermo Gallego|<http://arxiv.org/pdf/2412.14111v2>|[代码](https://github.com/tub-rip/epba); 首次提出基于事件数据的直接亮度图 photometric bundle adjustment 方法，...|
|🆕 发布|TeethGenerator: A two-stage framework for paired pre- and post-orthodontic 3D dental data generation|《TeethGenerator：一种用于配对正畸前后三维牙科数据生成的两阶段框架》|Changsong Lei, Yaqian Liang, Shaofeng Wang, Jiajia Dai, Yong-Jin Liu|<http://arxiv.org/pdf/2507.04685v1>|[代码](https://github.com/lcshhh/teeth_generator.); 提出TeethGenerator两阶段框架，生成正畸前后配对3D牙齿模型，助力训练牙齿排列神经网络。|
|📝 更新|Enhancing Long Video Generation Consistency without Tuning|在不调整的情况下增强长视频生成的连贯性|Xingyao Li, Fengzhuo Zhang, Jiachun Pan, Yunlong Hou, Vincent Y. F. Tan, Zhuoran Yang|<http://arxiv.org/pdf/2412.17254v2>|提出基于时间-频率注意力重排算法和提示对齐技术，显著提升长视频生成的连贯性和场景过渡平滑性。|
|📝 更新|Self-Rectifying Diffusion Sampling with Perturbed-Attention Guidance|带有扰动注意力引导的自校正扩散采样|Donghoon Ahn, Hyoungwon Cho, Jaewon Min, Wooseok Jang, Jungwoo Kim, SeonHwa Kim, Hyun Hee Park, Kyong Hwan Jin .etc.|<http://arxiv.org/pdf/2403.17377v2>|提出了一种无需额外训练或外部模块的Perturbed-Attention Guidance方法，显著...|
|📝 更新|Spatial-Temporal Conditional Random Field for Human Trajectory Prediction|人体轨迹预测的空间时间条件随机场模型|Pengqian Han, Jiamou Liu, Jialing He, Zeyu Zhang, Song Yang, Yanni Tang|<http://arxiv.org/pdf/2311.18198v2>|提出了一种融合行人意图信息的S-T CRF模型，有效提升了轨迹预测的准确性。|
|🆕 发布|S$^2$Edit: Text-Guided Image Editing with Precise Semantic and Spatial Control|S$^2$Edit：基于精确语义和空间控制的文本引导图像编辑|Xudong Liu, Zikun Chen, Ruowei Jiang, Ziyi Wu, Kejia Yin, Han Zhao, Parham Aarabi, Igor Gilitschenski|<http://arxiv.org/pdf/2507.04584v1>|提出了S$^2$Edit方法，通过文本引导实现精确的图像语义和空间编辑，解决了现有技术在细节控制上的...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AniCrafter: Customizing Realistic Human-Centric Animation via Avatar-Background Conditioning in Video Diffusion Models|《AniCrafter：通过虚拟形象-背景调节在视频扩散模型中定制真实感中心化人物动画》|Muyao Niu, Mingdeng Cao, Yifan Zhan, Qingtian Zhu, Mingze Ma, Jiancheng Zhao, Yanhong Zeng, Zhihang Zhong .etc.|<http://arxiv.org/pdf/2505.20255v2>|[代码](https://github.com/MyNiuuu/AniCrafter.); 提出了一种基于视频扩散模型的Avatar-Background条件机制，实现了在动态背景中稳定且多样...|
|📝 更新|SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D Generation|《海狮：用于三维生成的语义部分感知潜在点扩散模型》|Dekai Zhu, Yan Di, Stefan Gavranovic, Slobodan Ilic|<http://arxiv.org/pdf/2505.17721v2>|提出了一种生成高质量、多样化点云及细粒度分割标签的语义部分感知潜在点扩散模型。|
|📝 更新|DynamicFace: High-Quality and Consistent Face Swapping for Image and Video using Composable 3D Facial Priors|动态人脸：使用组合三维面部先验的高质量且一致性的图像与视频人脸交换|Runqi Wang, Yang Chen, Sijie Xu, Tianyao He, Wei Zhu, Dejia Song, Nemo Chen, Xu Tang .etc.|<http://arxiv.org/pdf/2501.08553v2>|提出DynamicFace方法，利用3D面部先验和扩散模型实现高质量、一致性的图像和视频面部交换。|
|🆕 发布|EmbodieDreamer: Advancing Real2Sim2Real Transfer for Policy Training via Embodied World Modeling|EmbodieDreamer：通过具身世界建模推进策略训练的Real2Sim2Real迁移|Boyuan Wang, Xinpan Meng, Xiaofeng Wang, Zheng Zhu, Angen Ye, Yang Wang, Zhiqin Yang, Chaojun Ni .etc.|<http://arxiv.org/pdf/2507.05198v1>|提出EmbodieDreamer框架，通过物理和视觉对齐减少Real2Sim2Real差距，提升机器...|
|🆕 发布|VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting|轨迹集合投票的视觉-语言-动作优化：VOTE|Juyi Lin, Amir Taherin, Arash Akbari, Arman Akbari, Lei Lu, Guangyu Chen, Taskin Padir, Xiaomeng Yang .etc.|<http://arxiv.org/pdf/2507.05116v1>|提出了一种高效的VLA模型优化框架VOTE，通过无需token化的微调方法和集成投票策略，实现了35...|
|🆕 发布|AI for the Routine, Humans for the Complex: Accuracy-Driven Data Labelling with Mixed Integer Linear Programming|“人工智能处理常规任务，人类处理复杂任务：基于准确性的混合整数线性规划数据标注方法”|Mohammad Hossein Amini, Mehrdad Sabetzadeh, Shiva Nejati|<http://arxiv.org/pdf/2507.04990v1>|提出了一种基于混合整数线性规划的半自动标注方法OPAL，实现了高标注精度同时大幅减少人工标注工作量。|
|🆕 发布|TLB-VFI: Temporal-Aware Latent Brownian Bridge Diffusion for Video Frame Interpolation|TLB-VFI：时间感知潜在布朗桥扩散用于视频帧插值|Zonglin Lyu, Chen Chen|<http://arxiv.org/pdf/2507.04984v1>|[代码](https://zonglinl.github.io/tlbvfi_page.); 提出TLB-VFI模型，通过3D小波和自编码器提取时间信息，提升视频帧插值质量同时减少参数量和训练数...|
|🆕 发布|RainShift: A Benchmark for Precipitation Downscaling Across Geographies|RainShift：跨地理区域的降水降尺度基准|Paula Harder, Luca Schmidt, Francis Pelletier, Nicole Ludwig, Matthew Chantry, Christian Lessig, Alex Hernandez-Garcia, David Rolnick|<http://arxiv.org/pdf/2507.04930v1>|提出RainShift基准，评估气候模型在不同地区的数据降尺度泛化能力。|
|🆕 发布|Leveraging Self-Supervised Features for Efficient Flooded Region Identification in UAV Aerial Images|利用自监督特征进行无人机航拍图像中洪水区域的高效识别|Dibyabha Deb, Ujjwal Verma|<http://arxiv.org/pdf/2507.04915v1>|利用自监督特征提出两种编码器-解码器基 segmentation 方法，减少对人工标注的依赖，高效识...|
|🆕 发布|RIPE: Reinforcement Learning on Unlabeled Image Pairs for Robust Keypoint Extraction|RIPE：在未标记图像对上进行强化学习以实现鲁棒关键点提取|Johannes Künzel, Anna Hilsmann, Peter Eisert|<http://arxiv.org/pdf/2507.04839v1>|[代码](https://github.com/fraunhoferhhi/RIPE.); 提出了一种基于弱监督强化学习的关键点提取框架，仅需成对图像的二元标签，实现了高效泛化的关键点检测与描...|
|🆕 发布|Semantically Consistent Discrete Diffusion for 3D Biological Graph Modeling|语义一致的三维生物图离散扩散建模|Chinmay Prabhakar, Suprosanna Shit, Tamaz Amiranashvili, Hongwei Bran Li, Bjoern Menze|<http://arxiv.org/pdf/2507.04856v1>|提出了一种生成符合解剖结构及语义的3D生物图方法，通过创新采样操作和噪声处理提升了性能。|
|🆕 发布|MCFormer: A Multi-Cost-Volume Network and Comprehensive Benchmark for Particle Image Velocimetry|MCFormer：一种多代价体网络及粒子图像测速的全面基准|Zicheng Lin, Xiaoqiang Li, Yichao Wang, Chuan Zhu|<http://arxiv.org/pdf/2507.04750v1>|提出大规模合成PIV基准数据集并设计MCFormer网络，显著提升流体动力学粒子图像测速性能。|
|🆕 发布|From Imitation to Innovation: The Emergence of AI Unique Artistic Styles and the Challenge of Copyright Protection|从模仿到创新：AI独特艺术风格的涌现与版权保护的挑战|Zexi Jia, Chuanwei Huang, Yeshuang Zhu, Hongyan Fei, Ying Deng, Zhiqiang Yuan, Jiapei Zhang, Jinchao Zhang .etc.|<http://arxiv.org/pdf/2507.04769v1>|提出AI艺术版权判断框架ArtBulb及基准数据集AICD，为AI艺术版权评估提供可靠标准。|
|🆕 发布|An analysis of vision-language models for fabric retrieval|视觉语言模型在布料检索中的分析|Francesco Giuliari, Asif Khan Pattan, Mohamed Lamine Mekhalfi, Fabio Poiesi|<http://arxiv.org/pdf/2507.04735v1>|研究了视觉语言模型在细粒度领域零样本检索中的应用，发现结构化描述能显著提升检索准确性。|
|📝 更新|Seed Selection for Human-Oriented Image Reconstruction via Guided Diffusion|面向人类导向的图像重建的引导扩散种子选择|Yui Tatsumi, Ziyue Zeng, Hiroshi Watanabe|<http://arxiv.org/pdf/2506.05363v2>|提出了一种优化种子选择的方法，通过选择最佳种子改善图像质量而不增加比特率。|
|🆕 发布|Structure-Guided Diffusion Models for High-Fidelity Portrait Shadow Removal|结构引导的扩散模型用于高保真度人像阴影移除|Wanchang Yu, Qing Zhang, Rongjia Zheng, Wei-Shi Zheng|<http://arxiv.org/pdf/2507.04692v1>|[代码](https://github.com/wanchang-yu/Structure-Guided-Diffusion-for-Portrait-Shadow-Removal.); 提出结构引导的扩散模型，用于高保真度人像阴影去除，有效避免了面部特征扭曲等问题。|
|📝 更新|Toward Robust Hyper-Detailed Image Captioning: A Multiagent Approach and Dual Evaluation Metrics for Factuality and Coverage|面向鲁棒超细节图像标注：一种多智能体方法及事实性和覆盖度双重评价指标|Saehyung Lee, Seunghyun Yoon, Trung Bui, Jing Shi, Sungroh Yoon|<http://arxiv.org/pdf/2412.15484v4>|[代码](https://github.com/adobe-research/CapMAS.); 提出多代理协作方法纠正图像描述中的错误，引入双评价指标衡量事实性和完整性。|
|📝 更新|HOI-Diff: Text-Driven Synthesis of 3D Human-Object Interactions using Diffusion Models|基于扩散模型的文本驱动三维人-物交互合成：HOI-Diff|Xiaogang Peng, Yiming Xie, Zizhao Wu, Varun Jampani, Deqing Sun, Huaizu Jiang|<http://arxiv.org/pdf/2312.06553v3>|提出了一种基于文本提示的3D人类-物体交互生成方法，通过模块化设计和扩散模型实现了逼真的交互运动和接...|
|📝 更新|Label-free evaluation of lung and heart transplant biopsies using tissue autofluorescence-based virtual staining|无标签评估基于组织自荧光虚拟染色的肺和心脏移植活检|Yuzhu Li, Nir Pillar, Tairan Liu, Guangdong Ma, Yuxuan Qi, Kevin de Haan, Yijie Zhang, Xilin Yang .etc.|<http://arxiv.org/pdf/2409.05255v2>|提出了一种基于组织自荧光的虚拟染色神经网络，省略传统染色步骤，实现高质效的移植活检评估。|
|🆕 发布|Information-Guided Diffusion Sampling for Dataset Distillation|信息引导的扩散采样用于数据集精炼|Linfeng Ye, Shayan Mohajer Hamidi, Guang Li, Takahiro Ogawa, Miki Haseyama, Konstantinos N. Plataniotis|<http://arxiv.org/pdf/2507.04619v1>|提出信息引导扩散采样方法，通过平衡原型信息和上下文信息，有效提升低样本量条件下的数据集精简性能。|
|📝 更新|BS-LDM: Effective Bone Suppression in High-Resolution Chest X-Ray Images with Conditional Latent Diffusion Models|BS-LDM：基于条件潜在扩散模型的高分辨率胸部X射线图像有效骨骼抑制|Yifei Sun, Zhanghao Chen, Hao Zheng, Wenming Deng, Jin Liu, Wenwen Min, Ahmed Elazab, Xiang Wan .etc.|<http://arxiv.org/pdf/2412.15670v5>|[代码](https://github.com/diaoquesang/BS-LDM.); 提出BS-LDM框架，利用条件潜在扩散模型有效抑制高分辨率胸片中的骨骼结构，提升肺部疾病诊断准确性。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|StreamVLN: Streaming Vision-and-Language Navigation via SlowFast Context Modeling|流式视觉与语言导航：通过慢快上下文建模实现连续导航|Meng Wei, Chenyang Wan, Xiqian Yu, Tai Wang, Yuqiang Yang, Xiaohan Mao, Chenming Zhu, Wenzhe Cai .etc.|<http://arxiv.org/pdf/2507.05240v1>|提出了一种慢快上下文建模策略的流式视觉语言导航框架，实现了低延迟下的细粒度视觉理解和长时上下文建模。|
|📝 更新|Dynamic EventNeRF: Reconstructing General Dynamic Scenes from Multi-view RGB and Event Streams|动态事件NeRF：从多视角RGB和事件流重建通用动态场景|Viktor Rudnev, Gereon Fox, Mohamed Elgharib, Christian Theobalt, Vladislav Golyanik|<http://arxiv.org/pdf/2412.06770v3>|提出了一种结合事件相机与RGB相机数据的三维动态场景重建方法，实现了在低光照和快速运动条件下的高质量...|
|📝 更新|AvatarMakeup: Realistic Makeup Transfer for 3D Animatable Head Avatars|《AvatarMakeup：面向3D可动画化头像的真实感化妆迁移》|Yiming Zhong, Xiaolin Zhang, Ligang Liu, Yao Zhao, Yunchao Wei|<http://arxiv.org/pdf/2507.02419v2>|提出AvatarMakeup方法，通过预训练扩散模型实现3D头像的逼真化妆转移，保持动态一致性和身份...|
|🆕 发布|From Vision To Language through Graph of Events in Space and Time: An Explainable Self-supervised Approach|从视觉到语言：通过空间和时间事件图实现可解释的自监督方法|Mihai Masala, Marius Leordeanu|<http://arxiv.org/pdf/2507.04815v1>|提出了一种基于时空事件图的自我监督方法，通过解释性分析连接视觉与语言，生成丰富自然的视频描述。|
|🆕 发布|UDF-GMA: Uncertainty Disentanglement and Fusion for General Movement Assessment|UDF-GMA：不确定性解耦与融合用于通用运动评估|Zeqi Luo, Ali Gooya, Edmond S. L. Ho|<http://arxiv.org/pdf/2507.04814v1>|提出了一种用于自动运动评估的不确定性解耦与融合方法，有效提高了脑功能障碍早期检测的可靠性和泛化能力。|
|🆕 发布|FurniMAS: Language-Guided Furniture Decoration using Multi-Agent System|“FurniMAS：基于多智能体系统的语言引导家具装饰”|Toan Nguyen, Tri Le, Quang Nguyen, Anh Nguyen|<http://arxiv.org/pdf/2507.04770v1>|提出了一种基于多智能体系统的家具装饰自动化方法，通过语言指导实现高效美观的装饰效果。|
|🆕 发布|Unleashing the Power of Neural Collapse: Consistent Supervised-Unsupervised Alignment for Generalized Category Discovery|释放神经崩溃的力量：一致的监督-无监督对齐以实现泛化类别发现|Jizhou Han, Shaokun Wang, Yuhang He, Chenhao Ding, Qiang Wang, Xinyuan Gao, SongLin Dong, Yihong Gong|<http://arxiv.org/pdf/2507.04725v1>|提出了一种基于神经崩溃原理的统一优化框架，有效解决了类别混淆和特征重叠问题，提升了未知类别的发现准确...|
|🆕 发布|Identity-Preserving Text-to-Video Generation Guided by Simple yet Effective Spatial-Temporal Decoupled Representations|保持身份一致性的基于简单而有效的时空解耦表示的文本到视频生成|Yuji Wang, Moran Li, Xiaobin Hu, Ran Yi, Jiangning Zhang, Han Feng, Weijian Cao, Yabiao Wang .etc.|<http://arxiv.org/pdf/2507.04705v1>|提出了一种将空间与时间表示解耦的简单有效框架，解决了文本到视频生成中空间一致性与时间平滑性的矛盾。|
|🆕 发布|A Visual Leap in CLIP Compositionality Reasoning through Generation of Counterfactual Sets|通过生成反事实集合在CLIP组合性推理中实现视觉飞跃|Zexi Jia, Chuanwei Huang, Hongyan Fei, Yeshuang Zhu, Zhiqiang Yuan, Ying Deng, Jiapei Zhang, Jinchao Zhang .etc.|<http://arxiv.org/pdf/2507.04699v1>|提出了一种自动生成对比数据集的方法，通过块状扩散和语言模型提升视觉语言模型的组合推理能力。|
|📝 更新|GlaGAN: A Generative Unsupervised Model for High-Precision Segmentation of Retinal Main Vessels toward Early Detection of Glaucoma|《GlaGAN：一种用于高精度视网膜主要血管分割的生成无监督模型，旨在青光眼早期检测》|Cheng Huang, Weizheng Xie, Tsengdar J. Lee, Jui-Kai Wang, Karanjit Kooner, Ning Zhang, Jia Zhang|<http://arxiv.org/pdf/2503.06743v4>|[代码](https://github.com/VikiXie/SatMar8.); 提出了一种无监督生成模型GlaGAN，实现了高精度视网膜主要血管分割，无需标注数据或高性能计算资源。|
|📝 更新|Fine-Grained Captioning of Long Videos through Scene Graph Consolidation|通过场景图整合实现长视频的细粒度标注|Sanghyeok Chu, Seonguk Seo, Bohyung Han|<http://arxiv.org/pdf/2502.16427v2>|提出了一种基于图融合的长视频细粒度字幕生成框架，有效扩展了现有模型的时间理解能力。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SEE-2-SOUND: Zero-Shot Spatial Environment-to-Spatial Sound|从视觉到声音：零样本空间环境到空间声音的映射|Rishit Dagli, Shivesh Prakash, Robert Wu, Houman Khosravani|<http://arxiv.org/pdf/2406.06612v2>|提出了一种零样本方法SEE-2-SOUND，通过视觉元素识别与3D定位生成匹配的空间音频，增强沉浸式...|
|🆕 发布|VERITAS: Verification and Explanation of Realness in Images for Transparency in AI Systems|“VERITAS：图像真实性的验证与解释，以增强人工智能系统的透明度”|Aadi Srivastava, Vignesh Natarajkumar, Utkarsh Bheemanaboyna, Devisree Akashapu, Nagraj Gaonkar, Archit Joshi|<http://arxiv.org/pdf/2507.05146v1>|[代码](https://github.com/V-i-g-n-e-s-h-N/VERITAS); 提出VERITAS框架，准确检测小尺寸图像真伪并提供易懂的解释。|
|📝 更新|DriveX: Driving View Synthesis on Free-form Trajectories with Generative Prior|驱动X：基于生成先验的自由形式轨迹上的驾驶视图合成|Zeyu Yang, Zijie Pan, Yuankun Yang, Xiatian Zhu, Li Zhang|<http://arxiv.org/pdf/2412.01717v2>|提出DriveX框架，通过结合3D场景表示与生成先验，实现自由轨迹上的高质量驾驶视图合成。|
|🆕 发布|Can Video LLMs Refuse to Answer? Alignment for Answerability in Video Large Language Models|视频大型语言模型中的回答性对齐：视频LLM能否拒绝回答？|Eunseop Yoon, Hee Suk Yoon, Mark A. Hasegawa-Johnson, Chang D. Yoo|<http://arxiv.org/pdf/2507.04976v1>|提出方法使视频大语言模型能评估问题相关性，并在问题超范围时拒绝回答。|
|🆕 发布|Taming the Tri-Space Tension: ARC-Guided Hallucination Modeling and Control for Text-to-Image Generation|驯服三空间张力：基于ARC引导的文本到图像生成的幻觉建模与控制|Jianjiang Yang, Ziyan Huang|<http://arxiv.org/pdf/2507.04946v1>|提出三轴空间模型理解生成偏差，引入动态向量量化生成对齐风险，有效减少文本到图像生成中的幻觉现象。|
|📝 更新|UniForm: A Unified Multi-Task Diffusion Transformer for Audio-Video Generation|统一多任务扩散变压器：用于音频视频生成的UniForm模型|Lei Zhao, Linfeng Feng, Dongxu Ge, Rujin Chen, Fangqiu Yi, Chi Zhang, Xiao-Lei Zhang, Xuelong Li|<http://arxiv.org/pdf/2502.03897v5>|提出了一种统一的多任务扩散变压器UniForm，能在共享潜在空间中生成音频和视觉模态，实现多任务处理...|
|📝 更新|BiMa: Towards Biases Mitigation for Text-Video Retrieval via Scene Element Guidance|BiMa：面向场景元素引导的文本-视频检索偏差缓解方法|Huy Le, Nhat Chung, Tung Kieu, Anh Nguyen, Ngan Le|<http://arxiv.org/pdf/2506.03589v3>|提出BiMa框架，通过场景元素引导缓解文本-视频检索中的视觉与语言偏见。|
|🆕 发布|Losing Control: Data Poisoning Attack on Guided Diffusion via ControlNet|《失控：通过ControlNet对引导扩散进行数据污染攻击》|Raz Lapid, Almog Dubin|<http://arxiv.org/pdf/2507.04726v1>|揭示了ControlNet模型在数据污染攻击下的脆弱性，并提出了一种隐蔽的数据污染方法生成特定内容图...|
|📝 更新|Q-Frame: Query-aware Frame Selection and Multi-Resolution Adaptation for Video-LLMs|Q-Frame：查询感知的帧选择与多分辨率自适应方法用于视频语言模型|Shaojie Zhang, Jiahui Yang, Jianqin Yin, Zhenbo Luo, Jian Luan|<http://arxiv.org/pdf/2506.22139v2>|提出了一种自适应帧选择和多分辨率调整方法Q-Frame，有效提升视频理解模型对关键时空信息的捕捉能力...|
|🆕 发布|QR-LoRA: Efficient and Disentangled Fine-tuning via QR Decomposition for Customized Generation|QR-LoRA：通过QR分解实现的高效且解耦的微调，用于定制化生成|Jiahui Yang, Yongjia Ma, Donglin Di, Hao Li, Wei Chen, Yan Xie, Jianxun Cui, Xun Yang .etc.|<http://arxiv.org/pdf/2507.04599v1>|QR-LoRA通过QR分解实现参数更新，有效分离视觉属性，提高内容风格融合任务的解耦性。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Physics-Guided Dual Implicit Neural Representations for Source Separation|物理引导的双隐式神经表示用于源分离|Yuan Ni, Zhantao Chen, Alexander N. Petsch, Edmund Xu, Cheng Peng, Alexander I. Kolesnikov, Sugata Chowdhury, Arun Bansil .etc.|<http://arxiv.org/pdf/2507.05249v1>|提出了一种无需标签数据的双隐神经表示框架，实现了物理信号与背景噪声的有效分离。|
|📝 更新|UltraBoneUDF: Self-supervised Bone Surface Reconstruction from Ultrasound Based on Neural Unsigned Distance Functions|《UltraBoneUDF：基于神经无符号距离函数的超声自监督骨骼表面重建》|Luohong Wu, Matthias Seibold, Nicola A. Cavalcanti, Giuseppe Loggia, Lisa Reissner, Bastian Sigrist, Jonas Hein, Lilian Calvet .etc.|<http://arxiv.org/pdf/2505.17912v2>|提出了一种基于神经无符号距离函数的自监督框架UltraBoneUDF，用于从超声图像重建开放性骨表面...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|4DSloMo: 4D Reconstruction for High Speed Scene with Asynchronous Capture|四维慢动作：基于异步捕获的高速度场景四维重建|Yutian Chen, Shi Guo, Tianshuo Yang, Lihe Ding, Xiuyuan Yu, Jinwei Gu, Tianfan Xue|<http://arxiv.org/pdf/2507.05163v1>|提出了一种异步捕获方案和生成模型，实现了仅用低帧率相机进行高速场景的4D重建。|
|🆕 发布|MatDecompSDF: High-Fidelity 3D Shape and PBR Material Decomposition from Multi-View Images|MatDecompSDF：从多视角图像中高保真三维形状和PBR材料分解|Chengyu Wang, Isabella Bennett, Henry Scott, Liang Zhang, Mei Chen, Hao Li, Rui Zhao|<http://arxiv.org/pdf/2507.04749v1>|MatDecompSDF通过联合优化神经签距离函数、空间变化的神经场和MLP模型，实现了从多视角图像...|
|🆕 发布|SPIDER: Structure-Preferential Implicit Deep Network for Biplanar X-ray Reconstruction|SPIDER：面向结构优先的隐式深度网络用于双平面X射线重建|Tianqi Yu, Xuanyu Tian, Jiawen Yang, Dongming He, Jingyi Yu, Xudong Wang, Yuyao Zhang|<http://arxiv.org/pdf/2507.04684v1>|提出了一种结构优先的隐式深度网络框架SPIDER，通过将解剖结构先验嵌入到重建过程中，实现了从双平面...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Event-based Stereo Depth Estimation: A Survey|基于事件的立体深度估计：综述|Suman Ghosh, Guillermo Gallego|<http://arxiv.org/pdf/2409.17680v3>|系统梳理了基于事件相机立体深度估计的研究进展，首次全面回顾了深度学习方法及数据集，并提出了未来研究方...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spatio-Temporal LLM: Reasoning about Environments and Actions|空间时间语言模型：对环境和动作的推理|Haozhen Zheng, Beitong Tian, Mingyuan Wu, Zhenggang Tang, Klara Nahrstedt, Alex Schwing|<http://arxiv.org/pdf/2507.05258v1>|[代码](https://zoezheng126.github.io/STLLM-website); 提出新模型ST-LLM，增强大型语言模型对环境和动作的时空理解能力。|
|🆕 发布|HV-MMBench: Benchmarking MLLMs for Human-Centric Video Understanding|HV-MMBench：面向以人为中心的视频理解的多模态大型语言模型基准测试|Yuxuan Cai, Jiangning Zhang, Zhenye Gan, Qingdong He, Xiaobin Hu, Junwei Zhu, Yabiao Wang, Chengjie Wang .etc.|<http://arxiv.org/pdf/2507.04909v1>|提出了一种全面评估多模态大语言模型在以人为中心视频理解中的能力的 HV-MMBench，涵盖了多样任...|
|📝 更新|PVChat: Personalized Video Chat with One-Shot Learning|个性化单次学习视频聊天系统PVChat|Yufei Shi, Weilong Yan, Gang Xu, Yumeng Li, Yuchen Chen, Zhenxi Li, Fei Richard Yu, Ming Li .etc.|<http://arxiv.org/pdf/2503.17069v2>|提出PVChat，一种基于单视频片段实现个性化视频理解的one-shot学习框架，有效提升ViLLM...|
|🆕 发布|Tempo-R0: A Video-MLLM for Temporal Video Grounding through Efficient Temporal Sensing Reinforcement Learning|时间感知R0：一种通过高效时间感知强化学习进行时序视频定位的视频-MLLM方法|Feng Yue, Zhaoxing Zhang, Junming Jiao, Zhengyu Liang, Shiwen Cao, Feifei Zhang, Rong Shen|<http://arxiv.org/pdf/2507.04702v1>|提出了一种结合多模态感知和强化学习的视频时序定位方法，有效提升了基于语言查询的视频片段检索精度。|
|📝 更新|Domain Adaptation of VLM for Soccer Video Understanding|足球视频理解中视觉语言模型的域自适应|Tiancheng Jiang, Henry Wang, Md Sirajus Salekin, Parmida Atighehchian, Shinan Zhang|<http://arxiv.org/pdf/2505.13860v2>|探索了开源视觉语言模型在特定领域（足球）的适应性，并通过迭代微调和课程学习显著提升了模型在足球视频理...|
|📝 更新|AuroraLong: Bringing RNNs Back to Efficient Open-Ended Video Understanding|极光长时：将循环神经网络重新带回高效开放式视频理解|Weili Xu, Enxin Song, Wenhao Chai, Xuexiang Wen, Tian Ye, Gaoang Wang|<http://arxiv.org/pdf/2507.02591v2>|提出了一种基于线性RNN的模型AuroraLong，有效降低长视频理解的计算复杂度和内存成本。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Self-Supervised Real-Time Tracking of Military Vehicles in Low-FPS UAV Footage|低帧率无人机影像中军事车辆的自监督实时跟踪|Markiyan Kostiv, Anatolii Adamovskyi, Yevhen Cherniavskyi, Mykyta Varenyk, Ostap Viniavskyi, Igor Krashenyi, Oles Dobosevych|<http://arxiv.org/pdf/2507.05229v1>|提出了一种利用单帧注释进行实例关联学习的方法，有效解决了低帧率无人机视频中的军事车辆实时追踪问题。|
|📝 更新|EyeTrAES: Fine-grained, Low-Latency Eye Tracking via Adaptive Event Slicing|《EyeTrAES：通过自适应事件切片实现的细粒度、低延迟眼动追踪》|Argha Sen, Nuwan Bandara, Ila Gokarn, Thivya Kandappu, Archan Misra|<http://arxiv.org/pdf/2409.18813v2>|提出了一种基于新型自适应窗口算法的细粒度、低延迟眼动追踪技术，提高了跟踪精度并降低了处理延迟。|
|📝 更新|A Novel Automatic Real-time Motion Tracking Method in MRI-guided Radiotherapy Using Enhanced Tracking-Learning-Detection Framework with Automatic Segmentation|一种基于增强的跟踪-学习-检测框架和自动分割的MRI引导放疗中实时运动跟踪的新型自动方法|Shengqi Chen, Zilin Wang, Jianrong Dai, Shirui Qin, Ying Cao, Ruiao Zhao, Jiayun Chen, Guohua Wu .etc.|<http://arxiv.org/pdf/2411.07503v3>|提出了一种自动实时无标记运动跟踪方法，显著提升了MRI引导放疗的跟踪精度和适应性。|
|🆕 发布|Robustifying 3D Perception through Least-Squares Multi-Agent Graphs Object Tracking|通过最小二乘多智能体图进行三维感知的鲁棒化物体跟踪|Maria Damanaki, Ioulia Kapsali, Nikos Piperigkos, Alexandros Gkillas, Aris S. Lalos|<http://arxiv.org/pdf/2507.04762v1>|提出了一种基于多代理最小二乘图的三维感知稳健化框架，有效提升了对抗干扰下的物体跟踪准确性。|
|🆕 发布|What's Making That Sound Right Now? Video-centric Audio-Visual Localization|当前是什么声音？以视频为中心的音频视觉定位|Hahyeon Choi, Junhoo Lee, Nojun Kwak|<http://arxiv.org/pdf/2507.04667v1>|提出视频中心化的AVATAR基准和TAVLO模型，通过整合高分辨率时间信息，提升音频视觉定位的准确性...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|When Imitation Learning Outperforms Reinforcement Learning in Surgical Action Planning|当模仿学习在手术动作规划中超越强化学习|Maxence Boels, Harry Robertshaw, Alejandro Granados, Prokar Dasgupta, Sebastien Ourselin|<http://arxiv.org/pdf/2507.05011v1>|比较模仿学习和强化学习在手术动作规划中的效果，发现模仿学习在预测手术动作方面优于强化学习。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LTMSformer: A Local Trend-Aware Attention and Motion State Encoding Transformer for Multi-Agent Trajectory Prediction|LTMSformer：一种面向多智能体轨迹预测的局部趋势感知注意力和运动状态编码变压器模型|Yixin Yan, Yang Li, Yuanfan Wang, Xiaozhou Zhou, Beihao Xia, Manjiang Hu, Hongmao Qin|<http://arxiv.org/pdf/2507.04634v1>|提出了一种轻量级框架LTMSformer，通过局部趋势感知注意力和运动状态编码，有效提升了多智能体轨...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HiLa: Hierarchical Vision-Language Collaboration for Cancer Survival Prediction|分层视觉-语言协作网络HiLa用于癌症生存预测|Jiaqi Cui, Lu Wen, Yuchen Fei, Bo Liu, Luping Zhou, Dinggang Shen, Yan Wang|<http://arxiv.org/pdf/2507.04613v1>|提出 Hierarchical vision-Language collaboration (HiL...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Marginal to Joint Predictions: Evaluating Scene-Consistent Trajectory Prediction Approaches for Automated Driving|从边缘预测到联合预测：评估适用于自动驾驶的场景一致轨迹预测方法|Fabian Konstantinidis, Ariel Dallari Guerreiro, Raphael Trumpp, Moritz Sackmann, Ulrich Hofmann, Marco Caccamo, Christoph Stiller|<http://arxiv.org/pdf/2507.05254v1>|[代码](https://frommarginaltojointpred.github.io/.); 系统比较了不同联合轨迹预测方法，提升了自动驾驶中场景一致性的运动预测准确性。|
|🆕 发布|Neuralocks: Real-Time Dynamic Neural Hair Simulation|神经锁：实时动态神经毛发模拟|Gene Wei-Chin Lin, Egor Larionov, Hsiao-yu Chen, Doug Roble, Tuur Stuyck|<http://arxiv.org/pdf/2507.05191v1>|提出了一种高效的神经方法，实现了稳定且动态的实时头发模拟，无需手动干预或艺术家生成的训练数据。|
|🆕 发布|QMoE: A Quantum Mixture of Experts Framework for Scalable Quantum Neural Networks|量子混合专家框架：用于可扩展量子神经网络的QMoE|Hoang-Quan Nguyen, Xuan-Bac Nguyen, Sankalp Pandey, Samee U. Khan, Ilya Safro, Khoa Luu|<http://arxiv.org/pdf/2507.05190v1>|提出量子混合专家架构QMoE，通过参数化量子电路和量子路由机制提升量子神经网络的可扩展性和表达力。|
|🆕 发布|Critiques of World Models|《对世界模型的批判》|Eric Xing, Mingkai Deng, Jinyu Hou, Zhiting Hu|<http://arxiv.org/pdf/2507.05169v1>|批判现有世界模型理论，提出一种新型通用世界模型架构，以模拟现实世界可能性。|
|🆕 发布|Reviving Cultural Heritage: A Novel Approach for Comprehensive Historical Document Restoration|文化遗产复兴：一种全面历史文献修复的新方法|Yuyi Zhang, Peirong Zhang, Zhenhua Yang, Pengyu Yan, Yongxin Shi, Pengwei Liu, Fengjun Guo, Lianwen Jin|<http://arxiv.org/pdf/2507.05108v1>|[代码](https://github.com/SCUT-DLVCLab/AutoHDR.); 提出了一种全面的历史文献修复方法，通过模拟专家流程显著提升了OCR准确率和文档恢复效果。|
|📝 更新|When Does Pruning Benefit Vision Representations?|剪枝何时有益于视觉表征？|Enrico Cassano, Riccardo Renzulli, Andrea Bragagnolo, Marco Grangetto|<http://arxiv.org/pdf/2507.01722v2>|探究了剪枝如何影响视觉模型的解释性、无监督物体发现和与人感知的匹配度，发现了特定剪枝程度下的优势。|
|🆕 发布|Parameterized Diffusion Optimization enabled Autoregressive Ordinal Regression for Diabetic Retinopathy Grading|参数化扩散优化驱动的自回归序数回归在糖尿病视网膜病变分级中的应用|Qinkai Yu, Wei Zhou, Hantao Liu, Yanyu Xu, Meng Wang, Yitian Zhao, Huazhu Fu, Xujiong Ye .etc.|<http://arxiv.org/pdf/2507.04978v1>|[代码](https://github.com/Qinkaiyu/AOR-DR.); 提出了一种用于糖尿病视网膜病变分级的自回归序数回归方法，通过利用序数信息和扩散优化处理长尾分布和分类...|
|📝 更新|Open-Set Gait Recognition from Sparse mmWave Radar Point Clouds|稀疏毫米波雷达点云的开集步态识别|Riccardo Mazzieri, Jacopo Pegoraro, Michele Rossi|<http://arxiv.org/pdf/2503.07435v4>|首次提出针对稀疏毫米波雷达点云的开集步态识别方法，结合监督分类与无监督重构，有效识别未知个体。|
|🆕 发布|DANCE: Resource-Efficient Neural Architecture Search with Data-Aware and Continuous Adaptation|DANCE：数据感知与连续适应的资源高效神经架构搜索|Maolin Wang, Tianshuo Wei, Sheng Zhang, Ruocheng Guo, Wanyu Wang, Shanshan Ye, Lixin Zou, Xuetao Wei .etc.|<http://arxiv.org/pdf/2507.04671v1>|[代码](https://github.com/Applied-Machine-Learning-Lab/DANCE.); 提出DANCE方法，通过连续演化实现资源高效的神经架构搜索，适应不同硬件需求并降低搜索成本。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VideoLifter: Lifting Videos to 3D with Fast Hierarchical Stereo Alignment|VideoLifter：利用快速分层立体对齐将视频提升至三维空间|Wenyan Cong, Hanqing Zhu, Kevin Wang, Jiahui Lei, Colton Stearns, Yuanhao Cai, Leonidas Guibas, Zhangyang Wang .etc.|<http://arxiv.org/pdf/2501.01949v3>|VideoLifter通过局部使用可学习3D先验和全局树状层次合并，高效地将视频提升为3D场景。|
|🆕 发布|Boosting Temporal Sentence Grounding via Causal Inference|通过因果推断提升时间句子定位|Kefan Tang, Lihuo He, Jisheng Dang, Xinbo Gao|<http://arxiv.org/pdf/2507.04958v1>|[代码](https://github.com/Tangkfan/CICR.); 提出了一种基于因果推断的时序句子定位框架，有效消除了视频与文本查询间的伪相关，增强了模型的鲁棒性。|
|🆕 发布|Vision-Language Models Can't See the Obvious|视觉-语言模型无法看到明显的事物|Yasser Dahou, Ngoc Dung Huynh, Phuc H. Le-Khac, Wamiq Reyaz Para, Ankit Singh, Sanath Narayan|<http://arxiv.org/pdf/2507.04741v1>|提出SalBench基准，揭示了大型视觉语言模型在检测显著视觉特征方面的局限性。|
|🆕 发布|UGG-ReID: Uncertainty-Guided Graph Model for Multi-Modal Object Re-Identification|UGG-ReID：不确定性引导的图模型用于多模态目标重识别|Xixi Wan, Aihua Zheng, Bo Jiang, Beibei Wang, Chenglong Li, Jin Tang|<http://arxiv.org/pdf/2507.04638v1>|提出了一种基于不确定性的图模型UGG-ReID，有效缓解了多模态目标重识别中的噪声干扰，提升了融合性...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Satellite-based Rabi rice paddy field mapping in India: a case study on Telangana state|印度基于卫星的Rabi水稻田制图：以泰伦甘纳邦为例|Prashanth Reddy Putta, Fabio Dell'Acqua|<http://arxiv.org/pdf/2507.05189v1>|提出了一种针对印度泰伦甘纳州地区的小农户稻田监测的遥感分类框架，通过适应农生态变化显著提高了分类准确...|
|🆕 发布|Transcribing Spanish Texts from the Past: Experiments with Transkribus, Tesseract and Granite|从过去转录西班牙语文本：Transkribus、Tesseract 和 Granite 的实验研究|Yanco Amor Torterolo-Orta, Jaione Macicior-Mitxelena, Marina Miguez-Lamanuzzi, Ana García-Serrano|<http://arxiv.org/pdf/2507.04878v1>|对比三种OCR技术转录历史西班牙文本，提升转录准确度与效率。|
|🆕 发布|CMET: Clustering guided METric for quantifying embedding quality|CMET：聚类引导的度量方法用于量化嵌入质量|Sourav Ghosh, Chayan Maitra, Rajat K. De|<http://arxiv.org/pdf/2507.04840v1>|提出CMET指标，通过聚类指导评估嵌入质量，有效比较原始数据与嵌入数据的局部和全局结构保持。|
|🆕 发布|Model Compression using Progressive Channel Pruning|逐步通道剪枝的模型压缩|Jinyang Guo, Weichen Zhang, Wanli Ouyang, Dong Xu|<http://arxiv.org/pdf/2507.04792v1>|提出了一种逐步剪枝框架Progressive Channel Pruning，通过迭代剪枝多个层中的...|
|🆕 发布|PointGAC: Geometric-Aware Codebook for Masked Point Cloud Modeling|点感知码书：用于遮挡点云建模的几何感知方法|Abiao Li, Chenlei Lv, Yuming Fang, Yifan Zuo, Jian Zhang, Guofeng Mei|<http://arxiv.org/pdf/2507.04801v1>|[代码](https://github.com/LAB123-tech/PointGAC); 提出了一种基于在线聚类引导的几何感知方法，有效提升了对遮挡点云的泛化特征学习。|
|🆕 发布|Identify, Isolate, and Purge: Mitigating Hallucinations in LVLMs via Self-Evolving Distillation|识别、隔离与清除：通过自演化蒸馏减轻LVLMs中的幻觉现象|Wenhao Li, Xiu Su, Jingyi Wu, Feng Yang, Yang Liu, Yi Chen, Shan You, Chang Xu|<http://arxiv.org/pdf/2507.04680v1>|提出SEED方法，通过自我进化蒸馏净化大型视觉语言模型中的错误知识，有效减少幻觉现象。|
|🆕 发布|Comprehensive Modeling of Camera Spectral and Color Behavior|《相机光谱与颜色行为的全面建模》|Sanush K Abeysekera, Ye Chow Kuang, Melanie Po-Leen Ooi|<http://arxiv.org/pdf/2507.04617v1>|提出了一种全面模拟数码相机光谱响应和色彩行为的模型，提高了颜色保真度和光谱准确性。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EAP4EMSIG -- Enhancing Event-Driven Microscopy for Microfluidic Single-Cell Analysis|EAP4EMSIG -- 用于微流体单细胞分析的增强事件驱动显微术|Nils Friederich, Angelo Jovin Yamachui Sitcheu, Annika Nassal, Erenus Yildiz, Matthias Pesch, Maximilian Beichter, Lukas Scholtes, Bahar Akbaba .etc.|<http://arxiv.org/pdf/2504.00047v2>|提出实时显微镜自动化技术，通过MLP自动对焦和深度学习细胞分割，提升微生物单细胞分析效率。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CTA: Cross-Task Alignment for Better Test Time Training|跨任务对齐以提高测试时间训练效果|Samuel Barbeau, Pedram Fekri, David Osowiechi, Ali Bahri, Moslem YazdanpanahMasih Aminbeidokhti, Christian Desrosiers|<http://arxiv.org/pdf/2507.05221v1>|提出了一种新的测试时训练方法CTA，通过跨任务对齐提升模型在分布偏移下的鲁棒性和泛化能力。|
|📝 更新|Establishing Causal Relationship Between Whole Slide Image Predictions and Diagnostic Evidence Subregions in Deep Learning|建立深度学习全切片图像预测与诊断证据子区域之间的因果关系|Tianhang Nan, Yong Ding, Hao Quan, Deliang Li, Lisha Li, Guanghong Zhao, Xiaoyu Cui|<http://arxiv.org/pdf/2407.17157v3>|提出CI-MIL方法，通过特征重权和分布校正建立WSI诊断与证据子图像间的明确因果关系，提升预测准确...|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|UNSURF: Uncertainty Quantification for Cortical Surface Reconstruction of Clinical Brain MRIs|不确定性量化用于临床脑部MRI的皮质表面重建|Raghav Mehta, Karthik Gopinath, Ben Glocker, Juan Eugenio Iglesias|<http://arxiv.org/pdf/2506.00498v2>|提出了一种新的皮质表面重建不确定性量化方法UNSURF，提高了临床脑部MRI扫描表面重建的质量控制和...|


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Diffusion-based Adversarial Identity Manipulation for Facial Privacy Protection|基于扩散的对抗性身份操纵用于面部隐私保护|Liqin Wang, Qianyue Hu, Wei Lu, Xiangyang Luo|<http://arxiv.org/pdf/2504.21646v2>|提出DiffAIM方法，通过在低维潜空间操纵面部身份生成自然且具有强攻击迁移性的对抗脸，保护面部隐私...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|$\varphi$-Adapt: A Physics-Informed Adaptation Learning Approach to 2D Quantum Material Discovery|$\varphi$-适应：一种物理信息驱动的适应学习策略用于二维量子材料的发现|Hoang-Quan Nguyen, Xuan Bac Nguyen, Sankalp Pandey, Tim Faltermeier, Nicholas Borys, Hugh Churchill, Khoa Luu|<http://arxiv.org/pdf/2507.05184v1>|提出了一种物理信息驱动的自适应学习方法$\varphi$-Adapt，有效解决了量子材料识别中的数据...|
|📝 更新|GaussRender: Learning 3D Occupancy with Gaussian Rendering|高斯渲染：使用高斯渲染学习三维占据|Loïck Chambon, Eloi Zablocki, Alexandre Boulch, Mickaël Chen, Matthieu Cord|<http://arxiv.org/pdf/2502.05040v3>|[代码](https://github.com/valeoai/GaussRender.); 提出GaussRender方法，通过二维投影一致性增强三维占位学习，显著提升几何精度和表面定位准确性...|
|🆕 发布|InterGSEdit: Interactive 3D Gaussian Splatting Editing with 3D Geometry-Consistent Attention Prior|《InterGSEdit：具有三维几何一致性注意力先验的交互式三维高斯散点编辑》|Minghao Wen, Shengjie Wu, Kangkan Wang, Dong Liang|<http://arxiv.org/pdf/2507.04961v1>|提出了一种交互式选择关键视图的3D编辑框架，通过3D几何一致性注意力先验实现了高质量、高保真的三维高...|
|🆕 发布|ConBatch-BAL: Batch Bayesian Active Learning under Budget Constraints|批贝叶斯主动学习在预算约束下的ConBatch-BAL方法|Pablo G. Morato, Charalampos P. Andriotis, Seyran Khademi|<http://arxiv.org/pdf/2507.04929v1>|提出两种批量贝叶斯主动学习方法，有效应对预算约束下的数据标注成本问题。|
|🆕 发布|SeqGrowGraph: Learning Lane Topology as a Chain of Graph Expansions|序列生长图：学习车道拓扑作为图扩展的链条|Mengwei Xie, Shuang Zeng, Xinyuan Chang, Xinran Liu, Zheng Pan, Mu Xu, Xing Wei|<http://arxiv.org/pdf/2507.04822v1>|SeqGrowGraph通过模拟人类绘图过程，将车道拓扑学习为一系列图扩展，实现了对复杂车道结构的精...|
|📝 更新|Weakly Supervised Segmentation Framework for Thyroid Nodule Based on High-confidence Labels and High-rationality Losses|基于高置信度标签与高合理性损失的甲状腺结节弱监督分割框架|Jianning Chi, Zelan Li, Geng Lin, MingYang Sun, Xiaosheng Yu|<http://arxiv.org/pdf/2502.19707v3>|[代码](https://github.com/bluehenglee/MLI-MSC.); 提出了一种基于高置信度伪标签和合理损失函数的弱监督甲状腺结节分割框架，有效解决了低置信度伪标签和低合...|
|🆕 发布|A Deep Unfolding Framework for Diffractive Snapshot Spectral Imaging|深度展开框架用于衍射快照光谱成像|Zhengyue Zhuge, Jiahui Xu, Shiqi Chen, Hao Xu, Yueting Chen, Zhihai Xu, Huajun Feng|<http://arxiv.org/pdf/2507.04622v1>|提出了一种针对衍射快照光谱成像系统的深 unfolding 框架，有效提升了重建算法的效率和性能。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Judging the Judges: Can Large Vision-Language Models Fairly Evaluate Chart Comprehension and Reasoning?|评判评判者：大型视觉-语言模型能否公正评估图表理解和推理？|Md Tahmid Rahman Laskar, Mohammed Saidul Islam, Ridwan Mahbub, Ahmed Masry, Mizanur Rahman, Amran Bhuiyan, Mir Tafseer Nayeem, Shafiq Joty .etc.|<http://arxiv.org/pdf/2505.08468v2>|评估了开源大型视觉语言模型在图表理解和推理任务中的评判准确性，揭示了性能差异和存在的偏见。|
|🆕 发布|Open Vision Reasoner: Transferring Linguistic Cognitive Behavior for Visual Reasoning|开放视觉推理器：将语言认知行为转移至视觉推理|Yana Wei, Liang Zhao, Jianjian Sun, Kangheng Lin, Jisheng Yin, Jingcheng Hu, Yinmin Zhang, En Yu .etc.|<http://arxiv.org/pdf/2507.05255v1>|将大型语言模型的认知行为转移到多模态模型，实现先进的视觉推理，并达到推理任务的最先进性能。|
|🆕 发布|ReLoop: "Seeing Twice and Thinking Backwards" via Closed-loop Training to Mitigate Hallucinations in Multimodal understanding|ReLoop: 通过闭环训练缓解多模态理解中的幻觉现象 —— “看两次，逆向思考”|Jianjiang Yang, Ziyan Huang, Yanshu Li|<http://arxiv.org/pdf/2507.04943v1>|提出了一种闭环训练框架ReLoop，通过增强多模态一致性减少大型多模态语言模型中的虚构现象。|
|🆕 发布|Piggyback Camera: Easy-to-Deploy Visual Surveillance by Mobile Sensing on Commercial Robot Vacuums|移动感知 commercial robot vacuums  商用机器人吸尘器  背负式摄像头：基于商用机器人吸尘器移动感知的易部署视觉监控|Ryo Yonetani|<http://arxiv.org/pdf/2507.04910v1>|利用商用扫地机器人搭载智能手机进行视觉监控，提出旋转增强集成方法优化定位与建图精度。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|All in One: Visual-Description-Guided Unified Point Cloud Segmentation|一体化：视觉描述引导的统一点云分割|Zongyan Han, Mohamed El Amine Boudjoghra, Jiahua Dong, Jinhong Wang, Rao Muhammad Anwer|<http://arxiv.org/pdf/2507.05211v1>|[代码](https://github.com/Hanzy1996/VDG-Uni3DSeg.); 整合视觉描述与大型语言模型，提出VDG-Uni3DSeg框架，提升3D点云精细分割性能。|
|🆕 发布|INTER: Mitigating Hallucination in Large Vision-Language Models by Interaction Guidance Sampling|通过交互引导采样减轻大型视觉语言模型中的幻觉问题|Xin Dong, Shichao Dong, Jin Wang, Jing Huang, Li Zhou, Zenghui Sun, Lihua Jing, Jingsong Lan .etc.|<http://arxiv.org/pdf/2507.05056v1>|提出了一种无需额外训练数据的INTER算法，有效减少大型视觉语言模型中的虚构现象。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|NavigScene: Bridging Local Perception and Global Navigation for Beyond-Visual-Range Autonomous Driving|《NavigScene：将局部感知与全局导航相结合实现超视距自动驾驶》|Qucheng Peng, Chen Bai, Guoxiang Zhang, Bo Xu, Xiaotong Liu, Xiaoyin Zheng, Chen Chen, Cheng Lu|<http://arxiv.org/pdf/2507.05227v1>|提出了NavigScene，通过融合局部感知与全局导航信息，显著提升了自动驾驶系统在复杂环境中的导航...|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RAM-W600: A Multi-Task Wrist Dataset and Benchmark for Rheumatoid Arthritis|RAM-W600：一种多任务手腕数据集和类风湿性关节炎基准|Songxiao Yang, Haolin Wang, Yao Fu, Ye Tian, Tamotsu Kamishima, Masayuki Ikebe, Yafei Ou, Masatoshi Okutomi|<http://arxiv.org/pdf/2507.05193v1>|介绍了首个公开的腕部骨骼实例分割和多任务数据集，助力类风湿关节炎的计算机辅助诊断研究。|
|🆕 发布|SV-DRR: High-Fidelity Novel View X-Ray Synthesis Using Diffusion Model|SV-DRR：基于扩散模型的高保真度新颖视角X射线合成|Chun Xie, Yuichi Yoshii, Itaru Kitahara|<http://arxiv.org/pdf/2507.05148v1>|提出了一种基于扩散模型的高保真度X射线新视角合成方法，实现了从单一视角生成多角度X射线图像，提高了图...|
|🆕 发布|Sequential Attention-based Sampling for Histopathological Analysis|序列注意力机制驱动的病理学分析采样方法|Tarun G, Naman Malpani, Gugan Thoppe, Sridharan Devarajan|<http://arxiv.org/pdf/2507.05077v1>|提出了一种基于深度强化学习的智能采样模型SASHA，通过高效分析小部分高分辨率区域实现可靠病理诊断。|
|🆕 发布|AI-Driven Cytomorphology Image Synthesis for Medical Diagnostics|基于人工智能的细胞形态学图像合成技术在医学诊断中的应用|Jan Carreras Boada, Rao Muhammad Umer, Carsten Marr|<http://arxiv.org/pdf/2507.05063v1>|利用精细调整的稳定扩散模型生成合成图像，有效提升少量数据下白细胞分类器的准确率。|
|🆕 发布|Robust Incomplete-Modality Alignment for Ophthalmic Disease Grading and Diagnosis via Labeled Optimal Transport|眼病分级与诊断的鲁棒性不完全模态对齐方法：通过标记最优传输实现|Qinkai Yu, Jianyang Xie, Yitian Zhao, Cheng Chen, Lijun Zhang, Liming Chen, Jun Cheng, Lu Liu .etc.|<http://arxiv.org/pdf/2507.04999v1>|[代码](https://github.com/Qinkaiyu/RIMA); 提出了一种处理眼病诊断中多模态数据不完整性的新框架，通过最优传输实现跨模态特征对齐。|
|🆕 发布|HGNet: High-Order Spatial Awareness Hypergraph and Multi-Scale Context Attention Network for Colorectal Polyp Detection|HGNet：高阶空间感知超图与多尺度上下文注意力网络用于结直肠癌息肉检测|Xiaofang Liu, Lingling Sun, Xuqing Zhang, Yuannong Ye, Bin zhao|<http://arxiv.org/pdf/2507.04880v1>|提出HGNet模型，结合高阶空间感知超图和多层次上下文注意力，有效提升结直肠息肉检测的准确性和边界定...|
|📝 更新|Fairness Evolution in Continual Learning for Medical Imaging|《医学成像中持续学习公平性的演变》|Marina Ceccon, Davide Dalle Pezze, Alessandro Fabris, Gian Antonio Susto|<http://arxiv.org/pdf/2406.02480v2>|探究了连续学习在医疗影像中的公平性演变，发现Pseudo-Label策略在降低偏见方面表现更佳。|
|🆕 发布|Efficacy of Image Similarity as a Metric for Augmenting Small Dataset Retinal Image Segmentation|图像相似性作为增强小数据集视网膜图像分割度量的有效性|Thomas Wallace, Ik Siong Heng, Senad Subasic, Chris Messenger|<http://arxiv.org/pdf/2507.04862v1>|研究了图像相似度对提升小数据集视网膜图像分割性能的影响，发现更相似的合成图像（低FID）更有效。|
|📝 更新|Mind the Context: Attention-Guided Weak-to-Strong Consistency for Enhanced Semi-Supervised Medical Image Segmentation|注意上下文：基于注意力引导的从弱到强一致性增强的半监督医学图像分割|Yuxuan Cheng, Chenxi Shao, Jie Ma, Yunfei Xie, Guoliang Li|<http://arxiv.org/pdf/2410.12419v3>|提出了一种名为AIGCMatch的半监督学习框架，通过注意力引导的扰动策略增强医学图像分割性能。|
|📝 更新|Towards Practical Alzheimer's Disease Diagnosis: A Lightweight and Interpretable Spiking Neural Model|迈向实用性的阿尔茨海默病诊断：一种轻量级且可解释的尖峰神经网络模型|Changwei Wu, Yifei Chen, Yuxin Du, Jinying Zong, Jie Dong, Mingxuan Liu, Yong Peng, Jin Fan .etc.|<http://arxiv.org/pdf/2506.09695v2>|[代码](https://github.com/wuchangw/FasterSNN.); 提出了一种结合生物启发神经元与区域自适应卷积的轻量级模型，用于高效准确诊断阿尔茨海默病。|
|📝 更新|AIGI-Holmes: Towards Explainable and Generalizable AI-Generated Image Detection via Multimodal Large Language Models|AIGI-Holmes：通过多模态大型语言模型实现可解释和泛化的AI生成图像检测|Ziyin Zhou, Yunpeng Luo, Yuanchen Wu, Ke Sun, Jiayi Ji, Ke Yan, Shouhong Ding, Xiaoshuai Sun .etc.|<http://arxiv.org/pdf/2507.02664v2>|提出了一种结合多模态大语言模型的AI生成图像检测框架，增强了可解释性和泛化能力。|
|🆕 发布|CP-Dilatation: A Copy-and-Paste Augmentation Method for Preserving the Boundary Context Information of Histopathology Images|CP-膨胀：一种用于保留病理图像边界上下文信息的复制-粘贴增强方法|Sungrae Hong, Sol Lee, Mun Yong Yi|<http://arxiv.org/pdf/2507.04660v1>|提出CP-Dilatation数据增强方法，通过边界膨胀操作保持医学图像边界信息，提升病理图像分割性...|
|🆕 发布|Emerging Frameworks for Objective Task-based Evaluation of Quantitative Medical Imaging Methods|面向定量医学成像方法客观任务导向评估的新兴框架|Yan Liu, Huitian Xia, Nancy A. Obuchowski, Richard Laforest, Arman Rahmim, Barry A. Siegel, Abhinav K. Jha|<http://arxiv.org/pdf/2507.04591v1>|提出四种新框架，为定量医学成像方法在临床任务中的客观评估提供策略。|
|🆕 发布|CVFusion: Cross-View Fusion of 4D Radar and Camera for 3D Object Detection|CVFusion：四维雷达与摄像头跨视角融合的三维目标检测|Hanzhi Zhong, Zhiyu Xiang, Ruoyu Xu, Jingyun Fu, Peng Xu, Shaohong Wang, Zhihao Yang, Tianyu Pu .etc.|<http://arxiv.org/pdf/2507.04587v1>|提出了一种雷达引导的迭代BEV融合网络CVFusion，通过多视角特征聚合显著提升了3D物体检测性能...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Mask Approximation Net: A Novel Diffusion Model Approach for Remote Sensing Change Captioning|《掩模近似网：一种用于遥感变化标注的新型扩散模型方法》|Dongwei Sun, Jing Yao, Wu Xue, Changsheng Zhou, Pedram Ghamisi, Xiangyong Cao|<http://arxiv.org/pdf/2412.19179v3>|提出了一种基于扩散模型的数据分布学习方法，通过频率域噪声过滤优化遥感图像变化描述，提高了模型泛化能力...|
|🆕 发布|Efficient SAR Vessel Detection for FPGA-Based On-Satellite Sensing|基于FPGA卫星传感的SAR船舶检测效率优化|Colin Laganier, Liam Fletcher, Elim Kwan, Richard Walters, Victoria Nockles|<http://arxiv.org/pdf/2507.04842v1>|提出了一种针对FPGA优化的高效SAR船舶检测模型，大幅缩小模型尺寸同时保持高性能。|
|🆕 发布|ChangeBridge: Spatiotemporal Image Generation with Multimodal Controls for Remote Sensing|"ChangeBridge：用于遥感的多模态控制时空图像生成"|Zhenghui Zhao, Chen Wu, Di Wang, Hongruixuan Chen, Zhuo Zheng|<http://arxiv.org/pdf/2507.04678v1>|提出了一种多模态控制的时空图像生成模型ChangeBridge，能够根据给定场景图像模拟未来情景。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 可解释视觉智能 (Explainable Visual Intelligence)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LVM4CSI: Enabling Direct Application of Pre-Trained Large Vision Models for Wireless Channel Tasks|LVM4CSI: 面向无线信道任务的无监督预训练大规模视觉模型直接应用方法|Jiajia Guo, Peiwen Jiang, Chao-Kai Wen, Shi Jin, Jun Zhang|<http://arxiv.org/pdf/2507.05121v1>|提出了一种利用预训练大型视觉模型直接应用于无线信道任务的通用高效框架LVM4CSI，无需任务特定设计...|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Estimating Object Physical Properties from RGB-D Vision and Depth Robot Sensors Using Deep Learning|从RGB-D视觉和深度机器人传感器估计物体物理属性的一种深度学习方法|Ricardo Cardoso, Plinio Moreno|<http://arxiv.org/pdf/2507.05029v1>|[代码](https://github.com/RavineWindteer/ShapenetSem-to-RGBD); 提出了一种结合深度图像点云和RGB图像估计物体质量的方法，显著优于现有基准。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Mitigating Bias Using Model-Agnostic Data Attribution|使用模型无关数据归因缓解偏见|Sander De Coninck, Sam Leroux, Pieter Simoens|<http://arxiv.org/pdf/2405.05031v2>|提出了一种利用像素级图像归因来识别和规范含有偏见信息的图像区域，从而减少机器学习模型偏见的方法。|
|🆕 发布|Uncovering Neuroimaging Biomarkers of Brain Tumor Surgery with AI-Driven Methods|利用人工智能驱动方法揭示脑瘤手术的神经影像学生物标志物|Carmen Jimenez-Mesa, Yizhou Wan, Guilio Sansone, Francisco J. Martinez-Murcia, Javier Ramirez, Pietro Lio, Juan M. Gorriz, Stephen J. Price .etc.|<http://arxiv.org/pdf/2507.04881v1>|提出了一种结合可解释AI与神经影像特征工程的框架，优化了脑瘤手术生存率预测的准确性和可解释性。|
|🆕 发布|Interaction-Merged Motion Planning: Effectively Leveraging Diverse Motion Datasets for Robust Planning|交互融合运动规划：有效利用多样化运动数据集以实现鲁棒规划|Giwon Lee, Wooseong Jeong, Daehee Park, Jaewoo Jeong, Kuk-Jin Yoon|<http://arxiv.org/pdf/2507.04790v1>|提出了一种融合交互信息的运动规划方法，有效利用不同领域数据集提高自主驾驶机器人规划稳健性。|

