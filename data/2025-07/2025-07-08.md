## [UPDATED!] **2025-07-08** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RSRefSeg 2: Decoupling Referring Remote Sensing Image Segmentation with Foundation Models|RSRefSeg 2：基于基础模型的遥感图像参考分割解耦|Keyan Chen, Chenyang Liu, Bowen Chen, Jiafan Zhang, Zhengxia Zou, Zhenwei Shi|<http://arxiv.org/pdf/2507.06231v1>|[代码](https://github.com/KyanChen/RSRefSeg2.); 提出了一种解耦的遥感图像分割框架RSRefSeg 2，通过基础模型的协作，提高了复杂场景的分割精度和...|
|📝 更新|MedGemma Technical Report|《MedGemma技术报告》|Andrew Sellergren, Sahar Kazemzadeh, Tiam Jaroensri, Atilla Kiraly, Madeleine Traverse, Timo Kohlberger, Shawn Xu, Fayaz Jamil .etc.|<http://arxiv.org/pdf/2507.05201v2>|介绍了MedGemma医疗视觉语言基础模型，提升了医疗任务性能并减少了特定任务调优数据需求。|
|🆕 发布|TalkFashion: Intelligent Virtual Try-On Assistant Based on Multimodal Large Language Model|《TalkFashion：基于多模态大型语言模型的智能虚拟试穿助手》|Yujie Hu, Xuanyu Zhang, Weiqi Li, Jian Zhang|<http://arxiv.org/pdf/2507.05790v1>|提出了一种基于大型多模态语言模型的智能虚拟试穿助手，实现了根据文本指令进行多功能试穿和局部编辑。|
|📝 更新|Challenging Vision-Language Models with Surgical Data: A New Dataset and Broad Benchmarking Study|以手术数据挑战视觉-语言模型：一个新的数据集与广泛的基准研究|Leon Mayer, Tim Rädsch, Dominik Michael, Lucas Luttner, Amine Yamlahi, Evangelia Christodoulou, Patrick Godau, Marcel Knopp .etc.|<http://arxiv.org/pdf/2506.06232v2>|评估了视觉语言模型在腔镜手术任务中的表现，指出了医学专用模型相比通用模型的不足。|
|🆕 发布|Tissue Concepts v2: a Supervised Foundation Model for whole slide images|组织概念v2：用于全切片图像的监督基础模型|Till Nicke, Daniela Scharcherer, Jan Raphael Schäfer, Natalia Artysh, Antje Prasse, André Homeyer, Andrea Schenk, Henning Höfener .etc.|<http://arxiv.org/pdf/2507.05742v1>|提出了一种资源消耗更低的监督基础模型TCv2，用于全切片图像分析，实现了优于自监督训练的性能。|
|📝 更新|UniCode$^2$: Cascaded Large-scale Codebooks for Unified Multimodal Understanding and Generation|统一编码器$^2$：级联大规模码本以实现统一的多模态理解和生成|Yanzhe Chen, Huasong Zhong, Yan Li, Zhenheng Yang|<http://arxiv.org/pdf/2506.20214v2>|提出了一种大规模级联视觉编码框架UniCode$^2$，通过稳定和语义对齐的方式提升多模态理解和生成...|
|🆕 发布|R-VLM: Region-Aware Vision Language Model for Precise GUI Grounding|区域感知视觉语言模型 R-VLM：用于精确 GUI 定位|Joonhyung Park, Peng Tang, Sagnik Das, Srikar Appalaraju, Kunwar Yashraj Singh, R. Manmatha, Shabnam Ghadar|<http://arxiv.org/pdf/2507.05673v1>|提出精确GUI元素定位方法R-VLM，通过区域提议和IoU感知损失函数提升自动化界面操作准确性。|
|🆕 发布|MedGen: Unlocking Medical Video Generation by Scaling Granularly-annotated Medical Videos|MedGen：通过细化标注医学视频的规模扩展解锁医学视频生成|Rongsheng Wang, Junying Chen, Ke Ji, Zhenyang Cai, Shunian Chen, Yunjin Yang, Benyou Wang|<http://arxiv.org/pdf/2507.05675v1>|[代码](https://github.com/FreedomIntelligence/MedGen); 提出大规模医疗视频数据集MedVideoCap-55K及模型MedGen，提升医疗视频生成的视觉质量...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Omni-Video: Democratizing Unified Video Understanding and Generation|全方位视频：统一视频理解和生成的普及化|Zhiyu Tan, Hao Yang, Luozheng Qin, Jia Gong, Mengping Yang, Hao Li|<http://arxiv.org/pdf/2507.06119v1>|提出Omni-Video框架，利用大型多模态语言模型生成视觉线索，结合扩散解码器实现视频理解、生成与...|
|🆕 发布|Video Event Reasoning and Prediction by Fusing World Knowledge from LLMs with Vision Foundation Models|通过融合来自大型语言模型的世界知识与视觉基础模型进行视频事件推理与预测|L'ea Dubois, Klaus Schmidt, Chengyu Wang, Ji-Hoon Park, Lin Wang, Santiago Munoz|<http://arxiv.org/pdf/2507.05822v1>|融合视觉基础模型与大型语言模型，提升视频事件推理和预测能力。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Reflections Unlock: Geometry-Aware Reflection Disentanglement in 3D Gaussian Splatting for Photorealistic Scenes Rendering|“反光解锁：用于真实感场景渲染的三维高斯散点几何感知反光解耦”|Jiayi Song, Zihan Ye, Qingyuan Zhou, Weidong Yang, Ben Fei, Jingyi Xu, Ying He, Wanli Ouyang|<http://arxiv.org/pdf/2507.06103v1>|[代码](https://ref-unlock.github.io/.); 提出了一种基于3D Gaussian Splatting的几何感知反射解耦框架，有效解决了反射表面渲...|
|🆕 发布|Enhancing Synthetic CT from CBCT via Multimodal Fusion and End-To-End Registration|通过多模态融合和端到端配准增强从CBCT到合成CT的转换|Maximilian Tschuchnig, Lukas Lamminger, Philipp Steininger, Michael Gadermayr|<http://arxiv.org/pdf/2507.06067v1>|提出了一种结合多模态学习和端到端配准的合成CT生成方法，有效提升了图像质量和准确性。|
|📝 更新|Advancing Stroke Risk Prediction Using a Multi-modal Foundation Model|利用多模态基础模型提升中风风险预测|Camille Delgrange, Olga Demler, Samia Mora, Bjoern Menze, Ezequiel de la Rosa, Neda Davoudi|<http://arxiv.org/pdf/2411.09822v2>|提出了一种自监督多模态框架，融合3D脑成像、临床数据，提高了中风风险预测准确性。|
|📝 更新|GC-GAT: Multimodal Vehicular Trajectory Prediction using Graph Goal Conditioning and Cross-context Attention|基于图目标条件与跨上下文注意力的多模态车辆轨迹预测|Mahir Gulzar, Yar Muhammad, Naveed Muhammad|<http://arxiv.org/pdf/2504.11150v2>|提出了一种基于图目标条件和跨场景注意力的多模态车辆轨迹预测模型，实现了nuScenes数据集上的最佳...|
|🆕 发布|SenseShift6D: Multimodal RGB-D Benchmarking for Robust 6D Pose Estimation across Environment and Sensor Variations|SenseShift6D：跨环境和传感器变化的稳健6D姿态估计多模态RGB-D基准测试|Yegyu Han, Taegyoon Yoon, Dayeon Woo, Sojeong Kim, Hyung-Sin Kim|<http://arxiv.org/pdf/2507.05751v1>|[代码](https://github.com/yegyu-han/SenseShift6D); 引入SenseShift6D数据集，通过测试时传感器控制提升6D姿态估计在多变环境下的鲁棒性。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MaSS13K: A Matting-level Semantic Segmentation Benchmark|MaSS13K：一个基于细分的语义分割基准|Chenxi Xie, Minghan Li, Hui Zeng, Jun Luo, Lei Zhang|<http://arxiv.org/pdf/2503.18364v2>|[代码](https://github.com/xiechenxi99/MaSS13K.); 构建了高分辨率精细标注的MaSS13K数据集，并提出了适用于该数据集的高效语义分割模型MaSSFor...|
|🆕 发布|Beyond Appearance: Geometric Cues for Robust Video Instance Segmentation|超越外观：用于鲁棒视频实例分割的几何线索|Quanzhu Niu, Yikang Zhou, Shihao Chen, Tao Zhang, Shunping Ji|<http://arxiv.org/pdf/2507.05948v1>|引入几何感知增强视频实例分割的鲁棒性，通过深度估计有效应对遮挡和运动模糊等挑战。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|BoundMatch: Boundary detection applied to semi-supervised segmentation for urban-driving scenes|BoundMatch:应用于城市驾驶场景的半监督分割边界检测|Haruya Ishikawa, Yoshimitsu Aoki|<http://arxiv.org/pdf/2503.23519v2>|提出了一种结合边界检测的多任务半监督语义分割框架，有效提升了城市驾驶场景中的边界精度和整体性能。|
|🆕 发布|Empowering Bridge Digital Twins by Bridging the Data Gap with a Unified Synthesis Framework|通过统一合成框架桥接数据差距来赋能桥梁数字孪生|Wang Wang, Mingyu Shi, Jun Jiang, Wenqian Ma, Chong Liu, Yasutaka Narazaki, Xuguang Wang|<http://arxiv.org/pdf/2507.05814v1>|提出了一种生成3D桥梁数据的统一合成框架，有效解决了现实世界数据不完整的问题，提高了桥梁结构视觉分析...|
|🆕 发布|Event-RGB Fusion for Spacecraft Pose Estimation Under Harsh Lighting|恶劣光照条件下的事件-RGB融合航天器姿态估计|Mohsi Jawaid, Marcus Märtens, Tat-Jun Chin|<http://arxiv.org/pdf/2507.05698v1>|融合RGB与事件传感器数据，提出了一种在恶劣光照条件下提高航天器位姿估计准确性的新方法。|
|🆕 发布|OFFSET: Segmentation-based Focus Shift Revision for Composed Image Retrieval|OFFSET：基于分割的焦点偏移修正方法用于组合图像检索|Zhiwei Chen, Yupeng Hu, Zixu Li, Zhiheng Fu, Xuemeng Song, Liqiang Nie|<http://arxiv.org/pdf/2507.05631v1>|[代码](https://zivchen-ty.github.io/OFFSET.github.io); 提出基于分割的焦点偏移修正网络OFFSET，通过识别图像主要部分并利用文本指导视觉焦点调整，改善组合...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CFMW: Cross-modality Fusion Mamba for Robust Object Detection under Adverse Weather|CFMW：跨模态融合蟒蛇以提高恶劣天气下的鲁棒目标检测|Haoyuan Li, Qi Hu, Binjia Zhou, You Yao, Jiacheng Lin, Kailun Yang, Peng Chen|<http://arxiv.org/pdf/2404.16302v2>|[代码](https://github.com/lhy-zjut/CFMW.); 提出CFMW方法，通过跨模态融合和天气消除技术，增强恶劣天气下的目标检测稳定性和成本效益。|
|🆕 发布|Hyperspectral Anomaly Detection Methods: A Survey and Comparative Study|《高光谱异常检测方法：综述与比较研究》|Aayushma Pant, Arbind Agrahari Baniya, Tsz-Kwan Lee, Sunil Aryal|<http://arxiv.org/pdf/2507.05730v1>|对比分析了各类 hyperspectral 异常检测技术，指出深度学习模型准确性最高，统计模型速度最...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis|持续多实例学习增强定位用于病理学全切片图像分析|Byung Hyun Lee, Wongi Jeong, Woojae Han, Kyoungbun Lee, Se Young Chun|<http://arxiv.org/pdf/2507.02395v2>|提出CoMEL框架，通过高效实例编码、可靠伪标签和权重适应策略，提升病理图像的持续多实例定位性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|StreamDiffusion: A Pipeline-level Solution for Real-time Interactive Generation|流扩散：一种面向实时交互生成的管道级解决方案|Akio Kodaira, Chenfeng Xu, Toshiki Hazama, Takanori Yoshimoto, Kohei Ohno, Shogo Mitsuhori, Soichi Sugano, Hanying Cho .etc.|<http://arxiv.org/pdf/2312.12491v2>|提出实时互动图像生成方法StreamDiffusion，通过批处理降噪和优化算法显著提升处理速度和降...|
|📝 更新|Anatomical Similarity as a New Metric to Evaluate Brain Generative Models|解剖相似性作为一种新的评估大脑生成模型的度量标准|Bahram Jafrasteh, Wei Peng, Cheng Wan, Yimin Luo, Ehsan Adeli, Qingyu Zhao|<http://arxiv.org/pdf/2504.21771v2>|[代码](https://github.com/BahramJafrasteh/wasabi-mri.); 提出WASABI新指标，通过比较真实与合成脑部解剖结构，提高脑部生成模型评估的准确性。|
|🆕 发布|NeoBabel: A Multilingual Open Tower for Visual Generation|NeoBabel：用于视觉生成的多语言开放塔楼|Mohammad Mahdi Derakhshani, Dheeraj Varghese, Marzieh Fadaee, Cees G. M. Snoek|<http://arxiv.org/pdf/2507.06137v1>|提出了一种多语言视觉生成框架NeoBabel，通过大规模预训练和指令微调，实现了高效、包容的性能提升...|
|🆕 发布|OmniPart: Part-Aware 3D Generation with Semantic Decoupling and Structural Cohesion|全向部件：具有语义解耦与结构凝聚的部件感知三维生成|Yunhan Yang, Yufan Zhou, Yuan-Chen Guo, Zi-Xin Zou, Yukun Huang, Ying-Tian Liu, Hao Xu, Ding Liang .etc.|<http://arxiv.org/pdf/2507.06165v1>|OmniPart通过将3D对象生成分解为结构规划和部件合成两个阶段，实现了部件的高语义解耦与结构凝聚...|
|📝 更新|RichControl: Structure- and Appearance-Rich Training-Free Spatial Control for Text-to-Image Generation|《RichControl：结构和外观丰富的无训练空间控制用于文本到图像生成》|Liheng Zhang, Lexi Pang, Hang Ye, Xiaoxuan Ma, Yizhou Wang|<http://arxiv.org/pdf/2507.02792v2>|提出了一种解耦特征注入时序的框架，有效平衡了结构保持与域对齐，实现了无需训练的高质量图像生成。|
|📝 更新|TDRI: Two-Phase Dialogue Refinement and Co-Adaptation for Interactive Image Generation|TDRI：两阶段对话精炼与协同适应交互式图像生成|Yuheng Feng, Jianhui Wang, Kun Li, Sida Li, Tianyu Shi, Haoyue Han, Miao Zhang, Xueqian Wang|<http://arxiv.org/pdf/2503.17669v3>|提出TDRI框架，通过迭代用户交互优化图像生成，显著提升用户意图与模型输出的匹配度。|
|🆕 发布|ScoreAdv: Score-based Targeted Generation of Natural Adversarial Examples via Diffusion Models|基于分数的目标自然对抗样本生成：通过扩散模型的方法|Chihan Huang, Hao Tang|<http://arxiv.org/pdf/2507.06078v1>|提出了一种基于扩散模型的ScoreAdv方法，通过可解释的对抗引导机制生成自然且无限的对抗性示例，有...|
|📝 更新|Multimodal Integration Challenges in Emotionally Expressive Child Avatars for Training Applications|多模态融合在情感表达儿童虚拟角色训练应用中的挑战|Pegah Salehi, Sajad Amouei Sheshkal, Vajira Thambawita, Michael A. Riegler, Pål Halvorsen|<http://arxiv.org/pdf/2506.13477v2>|提出实时架构，结合虚幻引擎5和NVIDIA Omniverse技术，通过声音生成儿童角色的逼真面部表...|
|📝 更新|UniCombine: Unified Multi-Conditional Combination with Diffusion Transformer|统一多条件组合的扩散变换器：UniCombine|Haoxuan Wang, Jinlong Peng, Qingdong He, Hao Yang, Ying Jin, Jiafu Wu, Xiaobin Hu, Yanjie Pan .etc.|<http://arxiv.org/pdf/2503.09277v2>|提出UniCombine框架，有效融合多条件输入提升图像生成控制性和一致性。|
|🆕 发布|Automatic Synthesis of High-Quality Triplet Data for Composed Image Retrieval|自动合成高质量三元组数据以用于组合图像检索|Haiwen Li, Delong Liu, Zhaohui Hou, Zhicheng Zhao, Fei Su|<http://arxiv.org/pdf/2507.05970v1>|提出自动生成高质量三元组数据的方法，用于提升组合图像检索的扩展性和零样本能力。|
|🆕 发布|Tora2: Motion and Appearance Customized Diffusion Transformer for Multi-Entity Video Generation|Tora2：用于多实体视频生成的运动和外观定制扩散变换器|Zhenghao Zhang, Junchao Liao, Xiangyu Meng, Long Qin, Weizhi Wang|<http://arxiv.org/pdf/2507.05963v1>|[代码](https://github.com/alibaba/Tora); 提出了Tora2模型，实现了视频生成中多实体外观与运动的同步定制化。|
|📝 更新|Hita: Holistic Tokenizer for Autoregressive Image Generation|“Hita：用于自回归图像生成的整体标记器”|Anlin Zheng, Haochen Wang, Yucheng Zhao, Weipeng Deng, Tiancai Wang, Xiangyu Zhang, Xiaojuan Qi|<http://arxiv.org/pdf/2507.02358v3>|[代码](https://github.com/CVMI-Lab/Hita); 提出了一种新的图像生成模型Hita，通过先整体后局部的编码方式，有效捕捉图像全局信息并提升生成质量。|
|📝 更新|Viewpoint Consistency in 3D Generation via Attention and CLIP Guidance|通过注意力机制和CLIP引导保持三维生成中的视点一致性|Qing Zhang, Zehao Chen, Jinguang Tong, Jing Zhang, Jie Hong, Xuesong Li|<http://arxiv.org/pdf/2412.02287v2>|提出了一种无需要调参的ACG机制，通过自适应控制注意力图和CLIP引导，有效解决了3D生成中的视角不...|
|🆕 发布|Towards Solar Altitude Guided Scene Illumination|面向太阳高度引导的场景照明|Samed Doğan, Maximilian Hoh, Nico Leuze, Nicolas R. -Peña, Alfred Schöttl|<http://arxiv.org/pdf/2507.05812v1>|引入太阳高度角作为全局条件变量，以低成本生成模拟日间光照变化的传感器数据。|
|🆕 发布|2D Instance Editing in 3D Space|三维空间中的二维实例编辑|Yuhuan Xie, Aoxuan Pan, Ming-Xian Lin, Wei Huang, Yi-Hua Huang, Xiaojuan Qi|<http://arxiv.org/pdf/2507.05819v1>|提出“2D-3D-2D”框架，通过在3D空间中编辑2D对象，实现了更一致且保持对象身份的编辑效果。|
|🆕 发布|SPADE: Spatial-Aware Denoising Network for Open-vocabulary Panoptic Scene Graph Generation with Long- and Local-range Context Reasoning|SPADE：具有长程和局域上下文推理的开词汇全景场景图生成空间感知去噪网络|Xin Hu, Ke Qin, Guiduo Duan, Ming Li, Yuan-Fang Li, Tao He|<http://arxiv.org/pdf/2507.05798v1>|提出了一种空间感知的去噪网络SPADE，通过校准预训练模型并利用长短期上下文推理，有效提升了开放词汇...|
|📝 更新|Pretrained Reversible Generation as Unsupervised Visual Representation Learning|预训练可逆生成作为无监督视觉表征学习|Rongkun Xue, Jinouwen Zhang, Yazhe Niu, Dazhong Shen, Bingqi Ma, Yu Liu, Jing Yang|<http://arxiv.org/pdf/2412.01787v5>|[代码](https://github.com/opendilab/PRG.); 提出利用预训练生成模型逆向过程提取无监督视觉表征，实现多种任务上的性能提升。|
|📝 更新|Towards Stabilized and Efficient Diffusion Transformers through Long-Skip-Connections with Spectral Constraints|通过带谱约束的长跳接实现稳定且高效的扩散变换器|Guanjie Chen, Xinyu Zhao, Yucheng Zhou, Xiaoye Qu, Tianlong Chen, Yu Cheng|<http://arxiv.org/pdf/2411.17616v4>|[代码](https://github.com/OpenSparseLLMs/Skip-DiT.); 提出Skip-DiT方法，通过引入长跳连接稳定特征传播，加速图像视频生成训练与推理。|
|🆕 发布|LiON-LoRA: Rethinking LoRA Fusion to Unify Controllable Spatial and Temporal Generation for Video Diffusion|LiON-LoRA：重新思考LoRA融合以统一可控的空间与时间生成用于视频扩散|Yisu Zhang, Chenjie Cao, Chaohui Yu, Jianke Zhu|<http://arxiv.org/pdf/2507.05678v1>|[代码](https://fuchengsu.github.io/lionlora.github.io); 提出LiON-LoRA框架，通过线性可扩展性、正交性和范数一致性原则，实现了对视频生成中空间和时间运...|
|📝 更新|MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation|记忆增强潜在变换器用于任意长度视频生成的MALT扩散|Sihyun Yu, Meera Hahn, Dan Kondratyuk, Jinwoo Shin, Agrim Gupta, José Lezama, Irfan Essa, David Ross .etc.|<http://arxiv.org/pdf/2502.12632v3>|提出了一种针对长视频生成的MALT Diffusion模型，通过分段自回归生成和记忆增强机制，实现了...|
|📝 更新|FreqCross: A Multi-Modal Frequency-Spatial Fusion Network for Robust Detection of Stable Diffusion 3.5 Generated Images|FreqCross：一种用于稳健检测稳定扩散3.5生成图像的多模态频率-空间融合网络|Guang Yang|<http://arxiv.org/pdf/2507.02995v2>|提出FreqCross网络，融合空间特征、频域特征和径向能量分布，有效检测AI生成图像。|
|🆕 发布|Generative Head-Mounted Camera Captures for Photorealistic Avatars|生成式头戴摄像头捕捉技术实现逼真头像生成|Shaojie Bai, Seunghyeon Seo, Yida Wang, Chenghui Li, Owen Wang, Te-Li Wang, Tianyang Ma, Jason Saragih .etc.|<http://arxiv.org/pdf/2507.05620v1>|提出了一种生成式方法GenHMC，利用未配对的头戴式相机捕获数据直接生成高质量合成图像，实现面部表情...|
|🆕 发布|Rethinking Layered Graphic Design Generation with a Top-Down Approach|从顶层到底层重新思考分层图形设计生成方法|Jingye Chen, Zhaowen Wang, Nanxuan Zhao, Li Zhang, Difan Liu, Jimei Yang, Qifeng Chen|<http://arxiv.org/pdf/2507.05601v1>|提出了一种将AI生成的设计转换为可编辑分层设计的框架Accordion，通过视觉语言模型和多种视觉专...|
|📝 更新|RandAR: Decoder-only Autoregressive Visual Generation in Random Orders|随机顺序下的仅解码器自回归视觉生成：RandAR|Ziqi Pang, Tianyuan Zhang, Fujun Luan, Yunze Man, Hao Tan, Kai Zhang, William T. Freeman, Yu-Xiong Wang|<http://arxiv.org/pdf/2412.01827v2>|[代码](https://rand-ar.github.io/.); 提出RandAR模型，通过插入位置指令令牌实现解码器端自回归图像生成，无需固定生成顺序，提升生成效率...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CultureCLIP: Empowering CLIP with Cultural Awareness through Synthetic Images and Contextualized Captions|文化感知CLIP：通过合成图像与情境化标题增强CLIP的文化感知能力|Yuchen Huang, Zhiyuan Fan, Zhitao He, Sandeep Polisetty, Wenyan Li, Yi R. Fung|<http://arxiv.org/pdf/2507.06210v1>|通过构建合成文化数据集并微调CLIP，实现了对细微文化差异的更好识别。|
|🆕 发布|Normalizing Diffusion Kernels with Optimal Transport|最优传输归一化扩散核|Nathan Kessler, Robin Magnet, Jean Feydy|<http://arxiv.org/pdf/2507.06161v1>|引入基于 Sinkhorn 算法的扩散核归一化方法，实现不规则数据的拉普拉斯-like 平滑处理。|
|🆕 发布|Prompt-Free Conditional Diffusion for Multi-object Image Augmentation|无提示条件扩散用于多目标图像增强|Haoyu Wang, Lei Zhang, Wei Wei, Chen Ding, Yanning Zhang|<http://arxiv.org/pdf/2507.06146v1>|[代码](https://github.com/00why00/PFCD); 提出prompt-free条件扩散框架，通过融合图像语义和计数损失，有效解决多对象图像增强中的类别偏...|
|🆕 发布|LangMamba: A Language-driven Mamba Framework for Low-dose CT Denoising with Vision-language Models|LangMamba：一种基于视觉语言模型的语言驱动响尾蛇框架，用于低剂量CT去噪|Zhihao Chen, Tao Chen, Chenhui Wang, Qi Gao, Huidong Xie, Chuang Niu, Ge Wang, Hongming Shan|<http://arxiv.org/pdf/2507.06140v1>|[代码](https://github.com/hao1635/LangMamba.); 提出语言驱动的LangMamba框架，利用视觉语言模型提升低剂量CT图像去噪质量。|
|🆕 发布|Discontinuity-aware Normal Integration for Generic Central Camera Models|具有不连续性感知的通用中心相机模型法线积分|Francesco Milano, Manuel López-Antequera, Naina Dhingra, Roland Siegwart, Robert Thiel|<http://arxiv.org/pdf/2507.06075v1>|提出了一种显式处理深度不连续性和通用中央相机模型的表面法线积分新方法，实现了更准确的深度与表面法线关...|
|📝 更新|OMR-Diffusion:Optimizing Multi-Round Enhanced Training in Diffusion Models for Improved Intent Understanding|OMR-Diffusion：优化多轮增强训练在扩散模型中以提升意图理解能力|Kun Li, Jianhui Wang, Miao Zhang, Xueqian Wang|<http://arxiv.org/pdf/2503.17660v3>|提出了一种结合人类反馈的视觉协同适应框架，优化了扩散模型以更准确匹配用户意图和偏好。|
|🆕 发布|Ensemble-Based Deepfake Detection using State-of-the-Art Models with Robust Cross-Dataset Generalisation|基于集成学习的深度伪造检测方法：使用最新模型实现稳健的跨数据集泛化|Haroon Wahab, Hassan Ugail, Lujain Jaleel|<http://arxiv.org/pdf/2507.05996v1>|提出了一种基于模型集成的深度伪造检测方法，有效提升了跨数据集的泛化能力。|
|🆕 发布|T-LoRA: Single Image Diffusion Model Customization Without Overfitting|T-LoRA: 无过度拟合的单幅图像扩散模型定制|Vera Soboleva, Aibek Alanov, Andrey Kuznetsov, Konstantin Sobolev|<http://arxiv.org/pdf/2507.05964v1>|[代码](https://github.com/ControlGenAI/T-LoRA.); 提出T-LoRA框架，通过时间步长敏感的调整策略，实现单张图像对扩散模型的高效个性化定制，避免过拟合...|
|📝 更新|UVOSAM: A Mask-free Paradigm for Unsupervised Video Object Segmentation via Segment Anything Model|UVOSAM：基于Segment Anything模型的无需掩膜的无监督视频对象分割方法|Zhenghao Zhang, Shengfan Zhang, Zhichao Wei, Zuozhuo Dai, Siyu Zhu|<http://arxiv.org/pdf/2305.12659v3>|[代码](https://github.com/alibaba/UVOSAM.); 提出了一种无需掩膜标注的UVOSAM方法，利用STD-Net tracker和SAM模型，实现了高质...|
|📝 更新|Nonisotropic Gaussian Diffusion for Realistic 3D Human Motion Prediction|各向异性高斯扩散用于真实三维人体运动预测|Cecilia Curreli, Dominik Muhle, Abhishek Saroha, Zhenzhang Ye, Riccardo Marin, Daniel Cremers|<http://arxiv.org/pdf/2501.06035v3>|[代码](https://ceveloper.github.io/publications); 引入SkeletonDiffusion模型，通过非各向同性高斯扩散改进人体运动预测，生成更真实且无变...|
|📝 更新|PhenoBench: A Comprehensive Benchmark for Cell Phenotyping|PhenoBench：细胞表型分析的全面基准测试|Jerome Luescher, Nora Koreuber, Jannik Franzen, Fabian H. Reith, Claudia Winklmayr, Elias Baumann, Christian M. Schuerch, Dagmar Kainmueller .etc.|<http://arxiv.org/pdf/2507.03532v2>|提出PhenoBench，为细胞表型识别创建了全新数据集和评估框架，揭示了现有模型在泛化方面的挑战。|
|🆕 发布|Integrated Structural Prompt Learning for Vision-Language Models|集成结构提示学习用于视觉-语言模型|Jiahui Wang, Qin Xu, Bo Jiang, Bin Luo|<http://arxiv.org/pdf/2507.05677v1>|提出了一种集成结构提示学习法，通过增强文本与图像信息交互，提升了视觉语言模型的泛化能力和样本适应度。|
|📝 更新|ReviveDiff: A Universal Diffusion Model for Restoring Images in Adverse Weather Conditions|ReviveDiff：一种用于在恶劣天气条件下恢复图像的通用扩散模型|Wenfeng Huang, Guoan Xu, Wenjing Jia, Stuart Perry, Guangwei Gao|<http://arxiv.org/pdf/2409.18932v3>|提出了一种通用扩散模型ReviveDiff，有效恢复了恶劣天气条件下图像的质量。|
|🆕 发布|Modeling and Reversing Brain Lesions Using Diffusion Models|使用扩散模型对脑病变进行建模与逆向重构|Omar Zamzam, Haleh Akrami, Anand Joshi, Richard Leahy|<http://arxiv.org/pdf/2507.05670v1>|提出了一种基于扩散模型的方法，区分并逆转脑部损伤与变形，实现更精准的脑部病变分析。|
|🆕 发布|Knowledge-guided Complex Diffusion Model for PolSAR Image Classification in Contourlet Domain|基于知识引导的复扩散模型在Contourlet域的PolSAR图像分类|Junfei Shi, Yu Cheng, Haiyan Jin, Junhuai Li, Zhaolin Xiao, Maoguo Gong, Weisi Lin|<http://arxiv.org/pdf/2507.05666v1>|提出了一种基于Contourlet域的结构知识引导的复数扩散模型，有效提升了PolSAR图像分类的边...|
|🆕 发布|Diffusion-Based Limited-Angle CT Reconstruction under Noisy Conditions|基于扩散的有限角度CT重建在噪声条件下的研究|Jiaqi Guo, Santiago López-Tapia|<http://arxiv.org/pdf/2507.05647v1>|提出了一种基于扩散模型和噪声感知机制的有限角度CT重建方法，有效应对了噪声条件下的重建问题。|
|🆕 发布|Kernel Density Steering: Inference-Time Scaling via Mode Seeking for Image Restoration|核密度引导：通过模式搜索实现图像复原中的推理时间缩放|Yuyang Hu, Kangfu Mei, Mojtaba Sahraee-Ardakan, Ulugbek S. Kamilov, Peyman Milanfar, Mauricio Delbracio|<http://arxiv.org/pdf/2507.05604v1>|提出Kernel Density Steering方法，通过集体模式搜索提升图像修复质量，减少伪影。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Driving View Synthesis on Free-form Trajectories with Generative Prior|自由形式轨迹上的驾驶视图合成与生成先验|Zeyu Yang, Zijie Pan, Yuankun Yang, Xiatian Zhu, Li Zhang|<http://arxiv.org/pdf/2412.01717v3>|提出了一种新型驾驶视角合成框架DriveX，通过逐步引入生成先验，实现了自由轨迹上的高质量实时视图生...|
|🆕 发布|MEDTalk: Multimodal Controlled 3D Facial Animation with Dynamic Emotions by Disentangled Embedding|MEDTalk：通过解耦嵌入实现的具有动态情感的多模态可控三维面部动画|Chang Liu, Ye Pan, Chenyang Ding, Susanto Rahardja, Xiaokang Yang|<http://arxiv.org/pdf/2507.06071v1>|提出MEDTalk框架，通过解耦内容和情感嵌入空间实现细粒度和动态情感对话头的生成。|
|🆕 发布|TextPixs: Glyph-Conditioned Diffusion with Character-Aware Attention and OCR-Guided Supervision|文本像素：字符条件扩散与字符感知注意力及OCR引导监督|Syeda Anshrah Gillani, Mirza Samad Ahmed Baig, Osama Ahmed Khan, Shahid Munir Shah, Umema Mujeeb, Maheen Ali|<http://arxiv.org/pdf/2507.06033v1>|提出GCDA框架，通过字符感知注意力和OCR指导监督，实现生成图像中可读、有意义且正确拼写的文本。|
|📝 更新|An Optimal Transport Perspective on Unpaired Image Super-Resolution|无配对图像超分辨率的最优传输视角|Milena Gazdieva, Petr Mokrov, Litu Rout, Alexander Korotin, Andrey Kravchenko, Alexander Filippov, Evgeny Burnaev|<http://arxiv.org/pdf/2202.01116v3>|[代码](https://github.com/milenagazdieva/OT-Super-Resolution.); 提出基于最优传输理论的非配对图像超分辨率方法，解决了GANs训练中的偏差问题。|
|🆕 发布|USIGAN: Unbalanced Self-Information Feature Transport for Weakly Paired Image IHC Virtual Staining|USIGAN：弱配对图像IHC虚拟染色中的不平衡自信息特征传输|Yue Peng, Bing Xiong, Fuqiang Chen, De Eybo, RanRan Zhang, Wanming Hu, Jing Cai, Wenjian Qin|<http://arxiv.org/pdf/2507.05843v1>|定位弱配对图像的病理学一致性挑战，提出USIGAN方法，通过全局形态学语义提取和新型机制增强内容一致...|
|📝 更新|StreamDiT: Real-Time Streaming Text-to-Video Generation|《StreamDiT：实时流式文本到视频生成》|Akio Kodaira, Tingbo Hou, Ji Hou, Masayoshi Tomizuka, Yue Zhao|<http://arxiv.org/pdf/2507.03745v2>|[代码](https://cumulo-autumn.github.io/StreamDiT); 提出实时流式文本到视频生成模型StreamDiT，通过流匹配训练和分块蒸馏实现16FPS的512p视...|
|🆕 发布|AdaptaGen: Domain-Specific Image Generation through Hierarchical Semantic Optimization Framework|自适应生成器：通过分层语义优化框架实现领域特定图像生成|Suoxiang Zhang, Xiaxi Li, Hongrui Chang, Zhuoyan Hou, Guoxin Wu, Ronghua Ji|<http://arxiv.org/pdf/2507.05621v1>|提出AdaptaGen框架，通过整合语义优化和跨模态适应，生成符合特定领域语义和细节的高质量图像。|
|📝 更新|Domain Generalizable Portrait Style Transfer|域泛化的肖像风格迁移|Xinbo Wang, Wenju Xu, Qing Zhang, Wei-Shi Zheng|<http://arxiv.org/pdf/2507.04243v2>|[代码](https://github.com/wangxb29/DGPST.); 提出了一种跨域通用的人像风格转换方法，通过建立密集语义对应和采用AdaIN-Wavelet变换实现高...|
|🆕 发布|ReLayout: Integrating Relation Reasoning for Content-aware Layout Generation with Multi-modal Large Language Models|“ReLayout：结合关系推理与多模态大型语言模型进行内容感知布局生成”|Jiaxu Tian, Xuehui Yu, Yaoxing Wang, Pan Wang, Guangqian Guo, Shan Gao|<http://arxiv.org/pdf/2507.05568v1>|提出ReLayout方法，通过关系推理增强大语言模型生成更具结构性和审美一致性的内容感知布局。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LEHA-CVQAD: Dataset To Enable Generalized Video Quality Assessment of Compression Artifacts|LEHA-CVQAD：用于实现压缩伪迹通用视频质量评估的数据集|Aleksandr Gushchin, Maksim Smirnov, Dmitriy Vatolin, Anastasia Antsiferova|<http://arxiv.org/pdf/2507.03990v2>|[代码](https://aleksandrgushchin.github.io/lcvqad); 提出LEHA-CVQAD数据集，用于评估压缩视频质量，并引入RDAE指标衡量模型性能。|
|🆕 发布|DreamArt: Generating Interactable Articulated Objects from a Single Image|梦艺：从单张图像生成可交互的关节对象|Ruijie Lu, Yu Liu, Jiaxiang Tang, Junfeng Ni, Yuxiang Wang, Diwen Wan, Gang Zeng, Yixin Chen .etc.|<http://arxiv.org/pdf/2507.05763v1>|[代码](https://dream-art-0.github.io/DreamArt); DreamArt通过三阶段框架从单张图片生成高质量、可交互的关节对象，解决了现有方法在关节建模和部分...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Feed-Forward SceneDINO for Unsupervised Semantic Scene Completion|“前馈SceneDINO用于无监督语义场景补全”|Aleksandar Jevtić, Christoph Reich, Felix Wimbauer, Oliver Hahn, Christian Rupprecht, Stefan Roth, Daniel Cremers|<http://arxiv.org/pdf/2507.06230v1>|首次在无监督设置下实现语义场景补全，通过自监督学习技术推断3D几何和语义信息。|
|🆕 发布|LighthouseGS: Indoor Structure-aware 3D Gaussian Splatting for Panorama-Style Mobile Captures|灯塔GS：室内结构感知的3D高斯散点绘制方法用于全景风格的移动捕捉|Seungoh Han, Jaehoon Jang, Hyunsu Kim, Jaeheung Surh, Junhyung Kwak, Hyowon Ha, Kyungdon Joo|<http://arxiv.org/pdf/2507.06109v1>|提出LighthouseGS框架，通过利用室内场景的平面结构和简单的全景式移动，实现高质量的实时新型...|
|🆕 发布|D-FCGS: Feedforward Compression of Dynamic Gaussian Splatting for Free-Viewpoint Videos|D-FCGS: 动态高斯散点喷射的前馈压缩用于自由视角视频|Wenkang Zhang, Yan Zhao, Qiang Wang, Li Song, Zhengxue Cheng|<http://arxiv.org/pdf/2507.05859v1>|提出了一种高效压缩动态高斯点云序列的框架，通过帧间运动提取和双先验熵模型，实现了快速且保真的自由视角...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HyperGaussians: High-Dimensional Gaussian Splatting for High-Fidelity Animatable Face Avatars|超高斯分布：用于高保真动画化人脸虚拟形象的高维高斯散点绘制|Gent Serifi, Marcel C. Bühler|<http://arxiv.org/pdf/2507.02803v2>|提出高维多变量高斯模型HyperGaussians，通过增加维度和特殊技巧提升面部动画真实感。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MARS: Radio Map Super-resolution and Reconstruction Method under Sparse Channel Measurements|MARS：稀疏信道测量下的无线电地图超分辨率重建方法|Chuyun Deng, Na Liu, Wei Xie, Lianming Xu, Li Wang|<http://arxiv.org/pdf/2506.04682v3>|提出了一种多尺度感知的无线电图超分辨率重建方法MARS，结合CNN和Transformer，有效提升...|
|🆕 发布|High-Fidelity and Generalizable Neural Surface Reconstruction with Sparse Feature Volumes|高保真且通用性强的稀疏特征体神经曲面重建|Aoxiang Fan, Corentin Dumery, Nicolas Talabot, Hieu Le, Pascal Fua|<http://arxiv.org/pdf/2507.05952v1>|提出了一种高效的稀疏特征体表示方法，实现了更高分辨率的神经表面重建，同时降低存储需求。|
|🆕 发布|ADPv2: A Hierarchical Histological Tissue Type-Annotated Dataset for Potential Biomarker Discovery of Colorectal Disease|ADPv2：一种用于结直肠癌潜在生物标志物发现的分层组织学类型注释数据集|Zhiyuan Yang, Kai Li, Sophia Ghamoshi Ramandi, Patricia Brassard, Hakim Khellaf, Vincent Quoc-Huy Trinh, Jennifer Zhang, Lina Chen .etc.|<http://arxiv.org/pdf/2507.05656v1>|介绍了ADPv2数据集，通过细致的层级组织学标注，助力特定器官疾病生物标志物发现。|
|🆕 发布|GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field|基于二维高斯的视频表示：GSVR实现800+ FPS的混合形变场|Zhizhuo Pang, Zhihui Ke, Xiaobo Zhou, Tie Qiu|<http://arxiv.org/pdf/2507.05594v1>|提出GSVR方法，通过二维高斯基表示和混合形变场，实现800+ FPS的高效视频解码和快速训练。|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|What's Making That Sound Right Now? Video-centric Audio-Visual Localization|当前是什么声音？以视频为中心的音频视觉定位|Hahyeon Choi, Junhoo Lee, Nojun Kwak|<http://arxiv.org/pdf/2507.04667v2>|提出视频中心化的音频视觉定位新方法和评估标准，通过整合高分辨率时间信息显著提升定位准确性。|
|📝 更新|Future Slot Prediction for Unsupervised Object Discovery in Surgical Video|未来时间槽预测：用于手术视频的无监督目标发现|Guiqiu Liao, Matjaz Jogan, Marcel Hussing, Edward Zhang, Eric Eaton, Daniel A. Hashimoto|<http://arxiv.org/pdf/2507.01882v2>|提出动态时间槽变换模块，通过预测未来槽初始化，提升手术视频无监督对象发现的性能。|
|🆕 发布|What You Have is What You Track: Adaptive and Robust Multimodal Tracking|你所拥有即你所追踪：自适应且稳健的多模态跟踪|Yuedong Tan, Jiawei Shao, Eduard Zamfir, Ruanjun Li, Zhaochong An, Chao Ma, Danda Paudel, Luc Van Gool .etc.|<http://arxiv.org/pdf/2507.05899v1>|[代码](https://github.com/supertyd/FlexTrack); 提出了一种自适应的异构混合专家融合框架，有效应对多模态数据缺失问题，提升视觉跟踪鲁棒性。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Signal-SGN: A Spiking Graph Convolutional Network for Skeletal Action Recognition via Learning Temporal-Frequency Dynamics|信号SGN：通过学习时频动态进行骨骼动作识别的尖峰图卷积网络|Naichuan Zheng, Yuchen Du, Hailun Xia, Zeyu Liang|<http://arxiv.org/pdf/2408.01701v4>|提出Signal-SGN模型，通过结合时间维度和频率特性，提升骨骼动作识别的准确性与能效。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DFYP: A Dynamic Fusion Framework with Spectral Channel Attention and Adaptive Operator learning for Crop Yield Prediction|作物产量预测的动态融合框架：具有光谱通道注意力和自适应操作学习的DFYP|Juli Zhang, Zeyu Yan, Jing Zhang, Qiguang Miao, Quan Wang|<http://arxiv.org/pdf/2507.05849v1>|提出动态融合框架DFYP，通过光谱通道注意力和自适应操作学习增强作物产量预测的鲁棒性。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PVChat: Personalized Video Chat with One-Shot Learning|个性化单次学习视频聊天系统PVChat|Yufei Shi, Weilong Yan, Gang Xu, Yumeng Li, Yucheng Chen, Zhenxi Li, Fei Richard Yu, Ming Li .etc.|<http://arxiv.org/pdf/2503.17069v3>|提出了一种个性化视频聊天的一键学习框架PVChat，通过单视频实现主体感知问答，解决了传统视频大语言...|
|📝 更新|AnyAnomaly: Zero-Shot Customizable Video Anomaly Detection with LVLM|任何异常：基于LVLM的无样本自定义视频异常检测|Sunghyun Ahn, Youngwan Jo, Kijung Lee, Sein Kwon, Inpyo Hong, Sanghyun Park|<http://arxiv.org/pdf/2503.04504v2>|[代码](https://github.com/SkiddieAhn/Paper-AnyAnomaly.); 提出了一种无需重新训练即可适应不同环境的零样本视频异常检测方法AnyAnomaly。|
|📝 更新|IPFormer-VideoLLM: Enhancing Multi-modal Video Understanding for Multi-shot Scenes|IPFormer-VideoLLM：增强多模态视频理解以应对多镜头场景|Yujia Liang, Jile Jiao, Xuetao Feng, Zixuan Ye, Yuan Wang, Zhicheng Wang|<http://arxiv.org/pdf/2506.21116v2>|提出MultiClip-Bench数据集和IPFormer-VideoLLM模型，提升多镜头场景下的...|
|📝 更新|Low-Light Video Enhancement via Spatial-Temporal Consistent Decomposition|通过空间-时间一致性分解的低光照视频增强|Xiaogang Xu, Kun Zhou, Tao Hu, Jiafei Wu, Ruixing Wang, Hao Peng, Bei Yu|<http://arxiv.org/pdf/2405.15660v3>|提出了一种融合时空一致性的视频分解策略，通过双结构增强网络显著提升了低光视频增强效果。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CLOVER: Context-aware Long-term Object Viewpoint- and Environment- Invariant Representation Learning|CLOVER：面向上下文的长期目标视角和环境不变性表征学习|Dongmyeong Lee, Amanda Adkins, Joydeep Biswas|<http://arxiv.org/pdf/2407.09718v2>|提出了一种能够跨视角和环境变化识别物体实例的CLOVER方法，无需前景分割即可区分静态物体。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Benchmarking the CoW with the TopCoW Challenge: Topology-Aware Anatomical Segmentation of the Circle of Willis for CTA and MRA|《使用TopCoW挑战对CoW进行基准测试：针对CTA和MRA的拓扑感知威尔士环解剖分割》|Kaiyuan Yang, Fabio Musio, Yihui Ma, Norman Juchler, Johannes C. Paetzold, Rami Al-Maskari, Luciano Höher, Hongwei Bran Li .etc.|<http://arxiv.org/pdf/2312.17670v4>|提出首个针对大脑动脉环结构的高质量标注数据集TopCoW，推动了拓扑感知的解剖分割算法的发展。|
|📝 更新|When Does Pruning Benefit Vision Representations?|剪枝何时有益于视觉表征？|Enrico Cassano, Riccardo Renzulli, Andrea Bragagnolo, Marco Grangetto|<http://arxiv.org/pdf/2507.01722v3>|探究了剪枝如何影响视觉模型的解释性、无监督物体发现和与人感知的匹配度，发现了特定稀疏度下的优势。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CAST-Phys: Contactless Affective States Through Physiological signals Database|CAST-Phys：通过生理信号数据库实现的无接触情感状态检测|Joaquim Comas, Alexander Joel Vera, Xavier Vives, Eleonora De Filippi, Alexandre Pereda, Federico Sukno|<http://arxiv.org/pdf/2507.06080v1>|提出CAST-Phys数据库，通过无接触生理信号和面部视频实现远程情感识别。|
|📝 更新|A Cascading Cooperative Multi-agent Framework for On-ramp Merging Control Integrating Large Language Models|级联协同多智能体框架：结合大型语言模型进行高速公路入口合流控制|Miao Zhang, Zhenlong Fang, Tianyi Wang, Qian Zhang, Shuai Lu, Junfeng Jiao, Tianyu Shi|<http://arxiv.org/pdf/2503.08199v2>|提出了一种融合大型语言模型的级联协同多智能体框架，有效提升多车合并场景下的决策性能。|
|🆕 发布|Geo-Registration of Terrestrial LiDAR Point Clouds with Satellite Images without GNSS|无需GNSS的地面激光雷达点云与卫星图像的地理配准|Xinyu Wang, Muhammad Ibrahim, Atif Mansoor, Ajmal Mian|<http://arxiv.org/pdf/2507.05999v1>|提出了一种无需GNSS的LiDAR点云与卫星图像配准方法，通过提取道路特征实现高精度城市三维地图重建...|
|🆕 发布|ECORE: Energy-Conscious Optimized Routing for Deep Learning Models at the Edge|边缘计算中考虑能耗的深度学习模型优化路由算法（ECORE）|Daghash K. Alqahtani, Maria A. Rodriguez, Muhammad Aamir Cheema, Hamid Rezatofighi, Adel N. Toosi|<http://arxiv.org/pdf/2507.06011v1>|提出ECORE框架，动态平衡边缘计算中的能耗和检测精度，降低能耗和延迟近一半。|
|📝 更新|BézierGS: Dynamic Urban Scene Reconstruction with Bézier Curve Gaussian Splatting|贝塞尔高斯散点法：动态城市场景重建与贝塞尔曲线高斯散点技术|Zipei Ma, Junzhe Jiang, Yurui Chen, Li Zhang|<http://arxiv.org/pdf/2506.22099v3>|提出了一种利用可学习贝塞尔曲线表示动态物体运动轨迹的方法，有效提升了城市场景的实时重建质量和精度。|
|📝 更新|Composable Strategy Framework with Integrated Video-Text based Large Language Models for Heart Failure Assessment|用于心力衰竭评估的集成视频-文本大型语言模型的组合策略框架|Jianzhou Chen, Jinyang Sun, Xiumei Wang, Xi Chen, Heyu Chu, Guo Song, Yuji Luo, Xingping Zhou .etc.|<http://arxiv.org/pdf/2502.16548v2>|提出了一种多模态策略框架，整合视频和文本大数据模型，提高了心衰预后预测的准确性。|
|🆕 发布|DREAM: Document Reconstruction via End-to-end Autoregressive Model|文档重建通过端到端自回归模型：DREAM|Xin Li, Mingming Gong, Yunfei Wu, Jianxin Dai, Antai Guo, Xinghua Jiang, Haoyu Cao, Yinsong Liu .etc.|<http://arxiv.org/pdf/2507.05805v1>|提出了一种端到端的文档重构方法DREAM，通过保留文档元素布局信息，有效解决了误差传播问题。|
|📝 更新|Quantization without Tears|无泪量化|Minghao Fu, Hao Yu, Jie Shao, Junjie Zhou, Ke Zhu, Jianxin Wu|<http://arxiv.org/pdf/2411.13918v4>|[代码](https://github.com/wujx2001/QwT); 提出了一种简单高效的量化方法Quantization without Tears，通过引入轻量级结构...|
|📝 更新|PointGAC: Geometric-Aware Codebook for Masked Point Cloud Modeling|点感知码本：用于遮挡点云建模的几何感知码本|Abiao Li, Chenlei Lv, Yuming Fang, Yifan Zuo, Jian Zhang, Guofeng Mei|<http://arxiv.org/pdf/2507.04801v2>|[代码](https://github.com/LAB123-tech/PointGAC); 提出了一种基于在线聚类引导的框架，通过几何感知策略优化点云重建，实现更泛化的特征学习。|
|🆕 发布|Dynamic Rank Adaptation for Vision-Language Models|动态排名适应视觉-语言模型|Jiahui Wang, Qin Xu, Bo Jiang, Bin Luo|<http://arxiv.org/pdf/2507.05668v1>|提出动态排名适配方法，优化视觉语言模型对新类别的泛化能力。|
|📝 更新|AbdomenAtlas: A Large-Scale, Detailed-Annotated, & Multi-Center Dataset for Efficient Transfer Learning and Open Algorithmic Benchmarking|腹部图谱：一个大规模、详细注释、多中心的数据集，用于高效迁移学习和开放算法基准测试|Wenxuan Li, Chongyu Qu, Xiaoxi Chen, Pedro R. A. S. Bassi, Yijia Shi, Yuxiang Lai, Qian Yu, Huimin Xue .etc.|<http://arxiv.org/pdf/2407.16697v2>|构建大规模、详细注释的腹部CT数据集AbdomenAtlas，助力AI模型预训练和算法评测。|
|🆕 发布|PaddleOCR 3.0 Technical Report|PaddleOCR 3.0 技术报告|Cheng Cui, Ting Sun, Manhui Lin, Tingquan Gao, Yubo Zhang, Jiaxuan Liu, Xueqing Wang, Zelun Zhang .etc.|<http://arxiv.org/pdf/2507.05595v1>|PaddleOCR 3.0通过多语言识别、文档解析和关键信息提取技术，以少量参数实现高效准确的文档理...|
|📝 更新|AbdomenAtlas-8K: Annotating 8,000 CT Volumes for Multi-Organ Segmentation in Three Weeks|腹部图谱-8K：三周内标注8000个CT体积用于多器官分割|Chongyu Qu, Tiezheng Zhang, Hualin Qiao, Jie Liu, Yucheng Tang, Alan Yuille, Zongwei Zhou|<http://arxiv.org/pdf/2305.09666v3>|通过主动学习法，三周内完成8000个CT体积的八器官标注，大幅提升效率并保持高质量。|
|📝 更新|ZigzagPointMamba: Spatial-Semantic Mamba for Point Cloud Understanding|“之字形点魔霸：用于点云理解的空间语义魔霸”|Linshuang Diao, Dayong Ren, Sensen Song, Yurong Qian|<http://arxiv.org/pdf/2505.21381v5>|提出 zigzag 扫描路径与语义相似掩码策略，提升点云理解中的空间连续性和局部语义建模。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Concept-Based Mechanistic Interpretability Using Structured Knowledge Graphs|基于结构化知识图的原理性可解释性方法|Sofiia Chorna, Kateryna Tarelkina, Eloïse Berthier, Gianni Franchi|<http://arxiv.org/pdf/2507.05810v1>|提出了一种基于结构化知识图的机制解释性框架，全局解析模型行为并揭示概念间的交互与传播。|
|📝 更新|UGG-ReID: Uncertainty-Guided Graph Model for Multi-Modal Object Re-Identification|UGG-ReID：不确定性引导的图模型用于多模态目标重识别|Xixi Wan, Aihua Zheng, Bo Jiang, Beibei Wang, Chenglong Li, Jin Tang|<http://arxiv.org/pdf/2507.04638v2>|提出了一种基于不确定性的图模型UGG-ReID，有效缓解多模态目标重识别中的噪声干扰并增强模态间融合...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FA: Forced Prompt Learning of Vision-Language Models for Out-of-Distribution Detection|FA：视觉语言模型在分布外检测中的强制提示学习|Xinhua Lu, Runhe Lai, Yanqi Wu, Kanghao Chen, Wei-Shi Zheng, Ruixuan Wang|<http://arxiv.org/pdf/2507.04511v2>|[代码](https://github.com/0xFAFA/FA.); 提出了一种基于强制提示学习的新框架，利用现有数据提升视觉模型对非分布外样本的检测能力。|
|📝 更新|CTA: Cross-Task Alignment for Better Test Time Training|跨任务对齐以提高测试时间训练效果|Samuel Barbeau, Pedram Fekri, David Osowiechi, Ali Bahri, Moslem Yazdanpanah, Masih Aminbeidokhti, Christian Desrosiers|<http://arxiv.org/pdf/2507.05221v2>|提出了一种跨任务对齐方法CTA，通过结合监督和无监督学习，增强了模型在测试时的鲁棒性和泛化能力。|
|🆕 发布|Fair Domain Generalization: An Information-Theoretic View|公平领域泛化：信息论视角下的研究|Tangzheng Lian, Guanyu Hu, Dimitrios Kollias, Xinyu Yang, Oya Celiktutan|<http://arxiv.org/pdf/2507.05823v1>|提出FairDG方法，平衡域泛化与算法公平性，通过信息论视角优化效用-公平性权衡。|
|📝 更新|Differential Coding for Training-Free ANN-to-SNN Conversion|差分编码用于无需训练的ANN到SNN转换|Zihan Huang, Wei Fang, Tong Bu, Peng Xue, Zecheng Hao, Wenxuan Liu, Yuanhong Tang, Zhaofei Yu .etc.|<http://arxiv.org/pdf/2503.00301v3>|[代码](https://github.com/h-z-h-cell/ANN-to-SNN-DCGS.); 提出差分编码方法，减少转换中 spike 数量和能量消耗，提升 SNN 性能。|
|🆕 发布|Multi-Modal Face Anti-Spoofing via Cross-Modal Feature Transitions|通过跨模态特征转换的多模态人脸防伪|Jun-Xiong Chong, Fang-Yu Hsu, Ming-Tsung Hsu, Yi-Ting Lin, Kai-Heng Chien, Chiou-Ting Hsu, Pei-Kai Huang|<http://arxiv.org/pdf/2507.05575v1>|提出了一种跨模态特征转换网络，有效应对多模态人脸防伪中的分布差异和模态缺失挑战。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning to Track Any Points from Human Motion|学习跟踪人体运动中的任意点|Inès Hyeonsu Kim, Seokju Cho, Jahyeok Koo, Junghyun Park, Jiahui Huang, Joon-Young Lee, Seungryong Kim|<http://arxiv.org/pdf/2507.06233v1>|提出AnthroTAP方法，自动生成训练数据，实现高效点追踪，达到领先性能。|
|🆕 发布|Exploring Partial Multi-Label Learning via Integrating Semantic Co-occurrence Knowledge|通过整合语义共现知识探索部分多标签学习|Xin Wu, Fei Teng, Yue Feng, Kaibo Shi, Zhuosheng Lin, Ji Zhang, James Wang|<http://arxiv.org/pdf/2507.05992v1>|提出了一种利用语义共现知识增强的框架SCINet，有效解决了部分多标签学习中的标签实例关系识别问题。|
|📝 更新|Filter Like You Test: Data-Driven Data Filtering for CLIP Pretraining|像测试一样过滤：基于数据驱动的CLIP预训练数据过滤方法|Mikey Shechter, Yair Carmon|<http://arxiv.org/pdf/2503.08805v2>|提出数据驱动的数据筛选算法FLYT，通过学习每个数据点的预训练效用，有效提升大规模视觉语言数据集质量...|
|📝 更新|Riverbed litter monitoring using consumer-grade aerial-aquatic speedy scanner (AASS) and deep learning based super-resolution reconstruction and detection network|使用消费级空中-水下快速扫描仪（AASS）和基于深度学习的超分辨率重建与检测网络进行河床垃圾监测|Fan Zhao, Yongying Liu, Jiaqi Wang, Yijia Chen, Dianhan Xi, Xinlei Shao, Shigeru Tabeta, Katsunori Mizuno|<http://arxiv.org/pdf/2408.03564v3>|提出了一种结合空中和水下快速扫描与深度学习超分辨率重建的检测技术，有效监测水下垃圾。|
|🆕 发布|Learning Segmentation from Radiology Reports|从放射学报告中学习分割技术|Pedro R. A. S. Bassi, Wenxuan Li, Jieneng Chen, Zheren Zhu, Tianyu Lin, Sergio Decherchi, Andrea Cavalli, Kang Wang .etc.|<http://arxiv.org/pdf/2507.05582v1>|[代码](https://github.com/MrGiovanni/R-Super); 利用放射科报告生成监督信号，提出R-Super方法，大幅提升肿瘤分割AI性能。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Tile-Based ViT Inference with Visual-Cluster Priors for Zero-Shot Multi-Species Plant Identification|基于瓦片结构的视觉Transformer推理及结合视觉聚类先验的零样本多物种植物识别|Murilo Gustineli, Anthony Miyaguchi, Adrian Cheung, Divyansh Khattak|<http://arxiv.org/pdf/2507.06093v1>|[代码](https://github.com/dsgt-arc/plantclef-2025.); 提出了一种结合视觉聚类先验的瓦片式Vision Transformer推理方法，无需额外训练即可有效...|
|🆕 发布|I$^2$R: Inter and Intra-image Refinement in Few Shot Segmentation|I$^2$R: 图像间与图像内细化在少量样本分割中的应用|Ourui Fu, Hangzhou He, Xinliang Zhang, Lei Zhu, Shuang Zeng, ZhaoHeng Xie, Yanye Lu|<http://arxiv.org/pdf/2507.05838v1>|提出了一种解决少量样本分割中图像间和图像内差异问题的I$^2$R方法，通过聚合全局语义线索和方向性掩...|
|🆕 发布|DreamGrasp: Zero-Shot 3D Multi-Object Reconstruction from Partial-View Images for Robotic Manipulation|DreamGrasp：基于单视角图像的零样本3D多目标重建用于机器人操作|Young Hun Kim, Seungyeon Kim, Yonghyeon Lee, Frank Chongwoo Park|<http://arxiv.org/pdf/2507.05627v1>|提出DreamGrasp框架，利用预训练图像生成模型的想象能力实现部分视角下的三维多物体重建。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 目标导向视觉决策 (Goal-oriented Visual Decision Making)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VisualSpeaker: Visually-Guided 3D Avatar Lip Synthesis|视觉引导的3D虚拟人唇部同步合成|Alexandre Symeonidis-Herzig, Özge Mercanoğlu Sincan, Richard Bowden|<http://arxiv.org/pdf/2507.06060v1>|提出了一种结合视觉语音识别的3D面部动画方法VisualSpeaker，通过感知唇读损失提升了动画真...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhancing Scientific Visual Question Answering through Multimodal Reasoning and Ensemble Modeling|通过多模态推理和集成建模增强科学视觉问答|Prahitha Movva, Naga Harshita Marupaka|<http://arxiv.org/pdf/2507.06183v1>|提出多模态推理和模型融合策略，提升科学图表视觉问答精度与一致性。|
|📝 更新|Visual Imitation Enables Contextual Humanoid Control|视觉模仿实现情境化人形控制|Arthur Allshire, Hongsuk Choi, Junyi Zhang, David McAllister, Anthony Zhang, Chung Min Kim, Trevor Darrell, Pieter Abbeel .etc.|<http://arxiv.org/pdf/2505.03729v4>|提出了一种利用日常视频模仿人类动作的方法，实现了机器人对复杂环境的自适应控制。|
|🆕 发布|Skywork-R1V3 Technical Report|《Skywork-R1V3技术报告》|Wei Shen, Jiangbo Pei, Yi Peng, Xuchen Song, Yang Liu, Jian Peng, Haofeng Sun, Yunzhuo Hao .etc.|<http://arxiv.org/pdf/2507.06167v1>|提出了一种新型视觉语言模型Skywork-R1V3，通过独特的后训练强化学习框架，将文本大模型的推理...|
|🆕 发布|SoftReMish: A Novel Activation Function for Enhanced Convolutional Neural Networks for Visual Recognition Performance|软ReMish：一种用于提升卷积神经网络视觉识别性能的新型激活函数|Mustafa Bayram Gücen|<http://arxiv.org/pdf/2507.06148v1>|提出SoftReMish激活函数，提升卷积神经网络在图像分类任务中的表现。|
|📝 更新|CURVE: CLIP-Utilized Reinforcement Learning for Visual Image Enhancement via Simple Image Processing|CURVE：基于CLIP的强化学习用于通过简单图像处理进行视觉图像增强|Yuka Ogino, Takahiro Toizumi, Atsushi Ito|<http://arxiv.org/pdf/2505.23102v2>|提出 CURVE 方法，通过 CLIP 模型和强化学习实现无参考低光图像增强，提升图像质量且保持高效...|
|📝 更新|FastVAR: Linear Visual Autoregressive Modeling via Cached Token Pruning|快速VAR：通过缓存令牌剪枝的线性视觉自回归建模|Hang Guo, Yawei Li, Taolin Zhang, Jiangshan Wang, Tao Dai, Shu-Tao Xia, Luca Benini|<http://arxiv.org/pdf/2503.23367v3>|[代码](https://github.com/csguoh/FastVAR.); 提出了一种高效图像生成加速方法FastVAR，通过缓存关键像素减少计算量，实现高分辨率图像的快速生成...|
|🆕 发布|High-Resolution Visual Reasoning via Multi-Turn Grounding-Based Reinforcement Learning|通过多轮定位基础强化学习实现高分辨率视觉推理|Xinyu Huang, Yuhao Dong, Weiwei Tian, Bo Li, Rui Feng, Ziwei Liu|<http://arxiv.org/pdf/2507.05920v1>|[代码](https://github.com/EvolvingLMMs-Lab/MGPO.); 提出了一种多轮 grounding 基础的强化学习框架，通过自动裁剪关键视觉区域，显著提升了大型多模...|
|📝 更新|Fine-Grained Knowledge Structuring and Retrieval for Visual Question Answering|细粒度知识构建与检索在视觉问答中的应用|Zhengxuan Zhang, Yin Wu, Yuyu Luo, Nan Tang|<http://arxiv.org/pdf/2502.20964v3>|提出细粒度知识单元结构化方法，结合检索增强生成框架，提升视觉问答中特定领域知识利用效率。|
|📝 更新|From Video to EEG: Adapting Joint Embedding Predictive Architecture to Uncover Visual Concepts in Brain Signal Analysis|从视频到脑电图：调整联合嵌入预测架构以揭示视觉概念在脑信号分析中的应用|Amirabbas Hojjati, Lu Li, Ibrahim Hameed, Anis Yazidi, Pedro G. Lind, Rabindra Khadka|<http://arxiv.org/pdf/2507.03633v2>|提出EEG-VJEPA模型，将EEG信号视作视频序列，通过联合嵌入和自适应掩码学习有意义的时空表征，...|
|📝 更新|Visual Adaptive Prompting for Compositional Zero-Shot Learning|视觉自适应提示用于组合零样本学习|Kyle Stein, Arash Mahyari, Guillermo Francia, Eman El-Sheikh|<http://arxiv.org/pdf/2502.20292v5>|提出视觉自适应提示系统，通过视觉特征选择相关提示，提升零样本组合学习的泛化能力。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Enhancing Visual Re-ranking through Denoising Nearest Neighbor Graph via Continuous CRF|通过连续条件随机场降噪最近邻图以提高视觉重排序效果|Jaeyoon Kim, Yoonki Cho, Taeyoung Kim, Sung-Eui Yoon|<http://arxiv.org/pdf/2412.13875v2>|提出了一种基于连续条件随机场的降噪方法，有效解决了视觉重排中噪声边问题，显著提升了检索准确性。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Eyes on the Environment: AI-Driven Analysis for Fire and Smoke Classification, Segmentation, and Detection|环境之眼：基于人工智能的火灾与烟雾分类、分割与检测分析|Sayed Pedram Haeri Boroujeni, Niloufar Mehrabi, Fatemeh Afghah, Connor Peter McGrath, Danish Bhatkar, Mithilesh Anil Biradar, Abolfazl Razi|<http://arxiv.org/pdf/2503.14552v2>|系统评估了火烟数据集，并实验验证了先进算法在火烟分类、分割和检测中的应用效果。|
|📝 更新|Lightweight Medical Image Restoration via Integrating Reliable Lesion-Semantic Driven Prior|通过集成可靠病变语义驱动先验的轻量级医学图像恢复|Pengcheng Zheng, Kecheng Chen, Jiaxin Huang, Bohao Chen, Ju Liu, Yazhou Ren, Xiaorong Pu|<http://arxiv.org/pdf/2504.11286v2>|提出了一种基于轻量级Transformer的医疗图像复原方法，通过频率域中的可靠性引导学习显著提升了...|
|🆕 发布|TigAug: Data Augmentation for Testing Traffic Light Detection in Autonomous Driving Systems|《TigAug：自动驾驶系统中交通灯检测的数据增强方法》|You Lu, Dingji Wang, Kaifeng Huang, Bihuan Chen, Xin Peng|<http://arxiv.org/pdf/2507.05932v1>|提出TigAug自动增强交通灯图像方法，提升自动驾驶系统交通灯检测模型的可靠性和鲁棒性。|
|📝 更新|Physics-Driven Autoregressive State Space Models for Medical Image Reconstruction|基于物理驱动的自回归状态空间模型在医学图像重建中的应用|Bilal Kabas, Fuat Arslan, Valiyeh A. Nezhad, Saban Ozturk, Emine U. Saritas, Tolga Çukur|<http://arxiv.org/pdf/2412.09331v2>|提出了一种结合物理驱动和自回归状态空间模型的医学图像重建方法，有效提升了多尺度上下文感知能力。|
|📝 更新|Bridging Classical and Learning-based Iterative Registration through Deep Equilibrium Models|通过深度平衡模型连接经典与基于学习的迭代配准方法|Yi Zhang, Yidong Zhao, Qian Tao|<http://arxiv.org/pdf/2507.00582v2>|提出了一种基于深 equilibrium 模型的医学图像配准框架，实现了理论无限迭代步骤且降低了内存...|
|📝 更新|Are Vision xLSTM Embedded UNet More Reliable in Medical 3D Image Segmentation?|视觉xLSTM嵌入式UNet在医学3D图像分割中是否更加可靠？|Pallabi Dutta, Soham Bose, Swalpa Kumar Roy, Sushmita Mitra|<http://arxiv.org/pdf/2406.16993v3>|[代码](https://github.com/duttapallabi2907/U-VixLSTM); 探究CNN与Vision-xLSTM结合的U-VixLSTM模型，在降低计算成本的同时提升3D医疗图...|
|📝 更新|Enhanced hermit crabs detection using super-resolution reconstruction and improved YOLOv8 on UAV-captured imagery|利用超分辨率重建和改进的YOLOv8算法增强无人机捕获图像中的寄居蟹检测|Fan Zhao, Yijia Chen, Dianhan Xi, Yongying Liu, Jiaqi Wang, Shigeru Tabeta, Katsunori Mizuno|<http://arxiv.org/pdf/2408.03559v2>|结合无人机遥感和超分辨率重建技术，提出改进的YOLOv8网络，有效提升了寄居蟹检测准确性和效率。|
|🆕 发布|3DGS_LSR:Large_Scale Relocation for Autonomous Driving Based on 3D Gaussian Splatting|基于三维高斯散点绘制的大型场景重定位方法用于自动驾驶|Haitao Lu, Haijier Chen, Haoze Liu, Shoujian Zhang, Bo Xu, Ziao Liu|<http://arxiv.org/pdf/2507.05661v1>|提出了一种基于3D高斯散点的车辆定位框架，实现仅用单目RGB图像的厘米级定位精度。|
|🆕 发布|Semi-Supervised Defect Detection via Conditional Diffusion and CLIP-Guided Noise Filtering|通过条件扩散和CLIP引导的噪声过滤进行半监督缺陷检测|Shuai Li, Shihan Chen, Wanru Geng, Zhaohua Xu, Xiaolu Liu, Can Dong, Zhen Tian, Changlin Chen|<http://arxiv.org/pdf/2507.05588v1>|[代码](https://github.com/cLin-c/Semisupervised-DSYM.); 提出半监督缺陷检测框架，通过条件扩散和CLIP引导降噪，提高工业质量检测效率。|
|📝 更新|High-Frequency Semantics and Geometric Priors for End-to-End Detection Transformers in Challenging UAV Imagery|高频语义与几何先验在挑战性无人机图像中的端到端检测变换器应用|Hongxing Peng, Lide Chen, Hui Zhu, Yan Chen|<http://arxiv.org/pdf/2507.00825v2>|提出了一种针对无人机图像的实时检测变压器框架，通过增强高频语义和几何先验，提高了小目标和复杂场景的检...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MCAM: Multimodal Causal Analysis Model for Ego-Vehicle-Level Driving Video Understanding|MCAM：面向自我驾驶车辆级别的驾驶视频理解的多模态因果分析模型|Tongtong Cheng, Rongzhen Li, Yixin Xiong, Tao Zhang, Jing Wang, Kai Liu|<http://arxiv.org/pdf/2507.06072v1>|[代码](https://github.com/SixCorePeach/MCAM.); 提出了一种多模态因果分析模型MCAM，通过构建视觉与语言模态间的潜在因果结构，有效提升了驾驶行为识别...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|On the Effectiveness of Methods and Metrics for Explainable AI in Remote Sensing Image Scene Classification|关于遥感图像场景分类中可解释人工智能方法与评价指标有效性的研究|Jonas Klotz, Tom Burgert, Begüm Demir|<http://arxiv.org/pdf/2507.05916v1>|分析了遥感图像分类中解释性AI方法和评估指标的有效性，提出了选择方法和参数的指导原则。|
|🆕 发布|GeoMag: A Vision-Language Model for Pixel-level Fine-Grained Remote Sensing Image Parsing|GeoMag：一种用于像素级精细遥感图像解析的视觉-语言模型|Xianzhi Ma, Jianhui Li, Changhua Pei, Hao Liu|<http://arxiv.org/pdf/2507.05887v1>|提出GeoMag模型，通过动态调整分辨率和语义裁剪提升遥感图像解析精度，优化计算效率。|
|📝 更新|Enhancing Satellite Object Localization with Dilated Convolutions and Attention-aided Spatial Pooling|利用扩张卷积和注意力辅助的空间池化增强卫星图像目标定位|Seraj Al Mahmud Mostafa, Chenxi Wang, Jia Yue, Yuta Hozumi, Jianwu Wang|<http://arxiv.org/pdf/2505.05599v3>|[代码](https://github.com/AI-4-atmosphere-remote-sensing/satellite-object-localization.); 提出YOLO-DCAP模型，通过多尺度膨胀卷积和注意力辅助空间池化提升卫星图像中物体定位准确性。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 可解释视觉智能 (Explainable Visual Intelligence)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Challenges and Trends in Egocentric Vision: A Survey|《自我中心视觉的挑战与趋势：综述》|Xiang Li, Heqian Qiu, Lanxiao Wang, Hanwen Zhang, Chenghao Qi, Linfeng Han, Huiyu Xiong, Hongliang Li|<http://arxiv.org/pdf/2503.15275v3>|系统分析了第一人称视觉研究，归类了四大任务领域，并展望了未来发展趋势。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A novel framework for fully-automated co-registration of intravascular ultrasound and optical coherence tomography imaging data|一种用于血管内超声与光学相干断层扫描成像数据全自动配准的新型框架|Xingwei He, Kit Mills Bransby, Ahmet Emir Ulutas, Thamil Kumaran, Nathan Angelo Lecaros Yap, Gonul Zeren, Hesong Zeng, Yaojun Zhang .etc.|<http://arxiv.org/pdf/2507.05883v1>|开发了一种深度学习框架，实现血管内超声与光学相干断层扫描图像的自动化配准。|
|🆕 发布|Normal Patch Retinex Robust Alghoritm for White Balancing in Digital Microscopy|数字显微镜白平衡中的正常补丁Retinex鲁棒算法|Radoslaw Roszczyk, Artur Krupa, Izabella Antoniuk|<http://arxiv.org/pdf/2507.05757v1>|提出了一种自动化的正常补丁Retinex算法，有效平衡了数字显微镜中的白平衡问题。|

