## [UPDATED!] **2025-07-09** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Multimodal Understanding via Stable Diffusion as a Task-Aware Feature Extractor|通过稳定扩散作为任务感知特征提取器实现多模态理解|Vatsal Agarwal, Matthew Gwilliam, Gefen Kohavi, Eshan Verma, Daniel Ulbricht, Abhinav Shrivastava|<http://arxiv.org/pdf/2507.07106v1>|[代码](https://vatsalag99.github.io/mustafar); 提出利用预训练的文本到图像扩散模型作为视觉编码器，增强图像细粒度理解并有效融合至大型语言模型。|
|📝 更新|Scaling 4D Representations|扩展四维表示|João Carreira, Dilara Gokay, Michael King, Chuhan Zhang, Ignacio Rocco, Aravindh Mahendran, Thomas Albert Keck, Joseph Heyward .etc.|<http://arxiv.org/pdf/2412.15212v2>|[代码](https://github.com/google-deepmind/representations4d); 展示了通过大规模视频数据学习，自监督学习在4D任务上的性能随模型规模增大而提升。|
|🆕 发布|EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision|EXAONE路径2.0：具有端到端监督的病理基础模型|Myungjang Pyeon, Janghyeon Lee, Minsoo Lee, Juseung Yun, Hwanil Choi, Jonghyun Kim, Jiwon Kim, Yi Hu .etc.|<http://arxiv.org/pdf/2507.06639v1>|EXAONE Path 2.0通过直接在切片级别进行监督学习，提高了病理学图像特征学习的效率和准确性...|
|📝 更新|UniF$^2$ace: Fine-grained Face Understanding and Generation with Unified Multimodal Models|统一多模态模型下的细粒度人脸理解和生成：UniF$^2$ace|Junzhe Li, Xuerui Qiu, Linrui Xu, Liya Guo, Delin Qu, Tingting Long, Chun Fan, Ming Li|<http://arxiv.org/pdf/2503.08120v3>|提出了首个针对细粒度面部理解和生成的统一多模态模型UniF$^2$ace，通过特制数据集和优化技术显...|
|📝 更新|Beyond Accuracy: Metrics that Uncover What Makes a 'Good' Visual Descriptor|超越准确性：揭示何为“良好”视觉描述符的度量指标|Ethan Lin, Linxi Zhao, Atharva Sehgal, Jennifer J. Sun|<http://arxiv.org/pdf/2507.03542v2>|提出两种新指标，揭示视觉描述符质量与基础模型特性的关系，超越传统准确性评估。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Evaluating Large Multimodal Models for Nutrition Analysis: A Benchmark Enriched with Contextual Metadata|评估大型多模态模型在营养分析中的应用：一个富含上下文元数据的基准|Bruce Coburn, Jiangpeng He, Megan E. Rollo, Satvinder S. Dhaliwal, Deborah A. Kerr, Fengqing Zhu|<http://arxiv.org/pdf/2507.07048v1>|研究了如何利用上下文元数据提升大型多模态模型在营养分析中的性能。|
|🆕 发布|Integrating Pathology Foundation Models and Spatial Transcriptomics for Cellular Decomposition from Histology Images|将病理基础模型与空间转录组学结合用于从组织学图像中进行细胞分解|Yutong Sun, Sichen Zhu, Peng Qiu|<http://arxiv.org/pdf/2507.07013v1>|提出了一种利用病理基础模型高效预测细胞组成的轻量级方法，无需进行昂贵的空间转录组学实验。|
|📝 更新|CULTURE3D: A Large-Scale and Diverse Dataset of Cultural Landmarks and Terrains for Gaussian-Based Scene Rendering|文化三维：基于高斯场景渲染的大规模多样化文化地标与地形数据集|Xinyi Zheng, Steve Zhang, Weizhe Lin, Aaron Zhang, Walterio W. Mayol-Cuevas, Yunze Liu, Junxiao Shen|<http://arxiv.org/pdf/2501.06927v3>|构建了一个包含10亿个点的超大规模精细数据集，助力3D重建模型处理大型室外场景，并提供了新的基准用于...|
|📝 更新|Tissue Concepts v2: A Supervised Foundation Model For Whole Slide Images|组织概念v2：用于全切片图像的监督基础模型|Till Nicke, Daniela Schacherer, Jan Raphael Schäfer, Natalia Artysh, Antje Prasse, André Homeyer, Andrea Schenk, Henning Höfener .etc.|<http://arxiv.org/pdf/2507.05742v2>|提出了一种资源消耗更低的监督基础模型TCv2，用于全切片图像分析，实现了优于自监督训练的性能。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GNN-ViTCap: GNN-Enhanced Multiple Instance Learning with Vision Transformers for Whole Slide Image Classification and Captioning|图神经网络增强的多实例学习与视觉变换器融合方法：用于全幻灯片图像分类与标注|S M Taslim Uddin Raju, Md. Milon Islam, Md Rezwanul Haque, Hamdi Altaheri, Fakhri Karray|<http://arxiv.org/pdf/2507.07006v1>|提出了一种结合图神经网络和视觉变换器的框架，有效提升了病理图像分类和自动标注的准确性。|
|📝 更新|Omni-Video: Democratizing Unified Video Understanding and Generation|全方位视频：统一视频理解和生成的普及化|Zhiyu Tan, Hao Yang, Luozheng Qin, Jia Gong, Mengping Yang, Hao Li|<http://arxiv.org/pdf/2507.06119v2>|提出了一种结合大型多模态语言模型与扩散解码器的统一视频理解和生成框架，有效提升了视频处理性能。|
|📝 更新|Oscillation-Reduced MXFP4 Training for Vision Transformers|振荡减少的MXFP4训练方法用于视觉变换器|Yuxiang Chen, Haocheng Xi, Jun Zhu, Jianfei Chen|<http://arxiv.org/pdf/2502.20853v2>|[代码](https://github.com/thu-ml/TetraJet-MXFP4Training); 提出TetraJet训练方法，通过EMA量化器和自适应调节优化器减少振荡，显著提升FP4精度下的训练...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Deep Brain Net: An Optimized Deep Learning Model for Brain tumor Detection in MRI Images Using EfficientNetB0 and ResNet50 with Transfer Learning|深度脑网：一种基于EfficientNetB0和ResNet50结合迁移学习优化深度学习模型，用于MRI图像中的脑肿瘤检测|Daniel Onah, Ravish Desai|<http://arxiv.org/pdf/2507.07011v1>|提出Deep Brain Net模型，融合EfficientNetB0与ResNet50及迁移学习，...|
|📝 更新|PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection|基于补丁合成的对抗训练以抵御物体检测中的物理可实现攻击：PBCAT|Xiao Li, Yiming Zhu, Yifan Huang, Wei Zhang, Yingzhe He, Jie Shi, Xiaolin Hu|<http://arxiv.org/pdf/2506.23581v2>|提出了一种统一防御策略PBCAT，通过结合小区域梯度引导的对抗性补丁和全局不可见对抗性扰动，有效提高...|
|📝 更新|RapidPoseTriangulation: Multi-view Multi-person Whole-body Human Pose Triangulation in a Millisecond|快速姿态三角测量：毫秒级多视角多人全身姿态三角测量|Daniel Bermuth, Alexander Poeppel, Wolfgang Reif|<http://arxiv.org/pdf/2503.21692v3>|提出了一种快速多视角多人全身姿态估计算法，实现了毫秒级三角化速度和良好的泛化能力。|
|🆕 发布|HVI-CIDNet+: Beyond Extreme Darkness for Low-Light Image Enhancement|低光照图像增强：超越极端黑暗的HVI-CIDNet+方法|Qingsen Yan, Kangbiao Shi, Yixu Feng, Tao Hu, Peng Wu, Guansong Pang, Yanning Zhang|<http://arxiv.org/pdf/2507.06814v1>|提出HVI-CIDNet+方法，通过新型HVI色彩空间和先验引导注意力机制，有效改善低光图像增强中的...|
|📝 更新|Infrared and visible Image Fusion with Language-driven Loss in CLIP Embedding Space|基于CLIP嵌入空间的语言驱动损失的红外与可见光图像融合|Yuhao Wang, Lingjuan Miao, Zhiqiang Zhou, Lei Zhang, Yajun Qiao|<http://arxiv.org/pdf/2402.16267v2>|提出用自然语言指导损失函数，通过CLIP嵌入空间提升红外与可见光图像融合性能。|
|🆕 发布|Airway Segmentation Network for Enhanced Tubular Feature Extraction|气道分割网络增强管状特征提取|Qibiao Wu, Yagang Wang, Qian Zhang|<http://arxiv.org/pdf/2507.06581v1>|[代码](https://github.com/QibiaoWu/TfeNet.); 提出了一种针对气道特征提取的TfeNet网络，通过方向感知卷积和特征融合模块显著提升了气道分割的准确...|
|🆕 发布|A model-agnostic active learning approach for animal detection from camera traps|一种模型无关的主动学习方法用于从相机陷阱中检测动物|Thi Thu Thuy Nguyen, Duc Thanh Nguyen|<http://arxiv.org/pdf/2507.06537v1>|提出了一种模型无关的主动学习方法，通过优化标注数据量，提高了动物检测模型的性能。|
|📝 更新|Empowering Bridge Digital Twins by Bridging the Data Gap with a Unified Synthesis Framework|通过统一合成框架桥接数据差距来赋能桥梁数字孪生|Wang Wang, Mingyu Shi, Jun Jiang, Wenqian Ma, Chong Liu, Yasutaka Narazaki, Xuguang Wang|<http://arxiv.org/pdf/2507.05814v2>|提出了一种生成3D桥梁数据的统一合成框架，有效解决了现实世界数据不完整的问题，提高了桥梁结构视觉分析...|
|🆕 发布|Mask6D: Masked Pose Priors For 6D Object Pose Estimation|《Mask6D：用于6D物体姿态估计的遮罩姿态先验》|Yuechen Xie, Haobo Jiang, Jin Xie|<http://arxiv.org/pdf/2507.06486v1>|提出Mask6D方法，通过2D-3D对应图和可见掩码图增强单目6D物体位姿估计在复杂场景下的鲁棒性。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DenoiseCP-Net: Efficient Collective Perception in Adverse Weather via Joint LiDAR-Based 3D Object Detection and Denoising|去噪CP-Net：通过联合激光雷达三维目标检测与去噪实现恶劣天气下的高效集体感知|Sven Teufel, Dominique Mayer, Jörg Gamerdinger, Oliver Bringmann|<http://arxiv.org/pdf/2507.06976v1>|提出了一种集成三维物体检测与去噪的多任务架构，有效提升了恶劣天气下集体感知的准确性和效率。|
|🆕 发布|LOVON: Legged Open-Vocabulary Object Navigator|《LOVON：四足开放式词汇对象导航器》|Daojie Peng, Jiahang Cao, Qiang Zhang, Jun Ma|<http://arxiv.org/pdf/2507.06747v1>|提出了一种融合大型语言模型与开放词汇视觉检测模型的框架，实现了动态复杂环境中的长距离目标导航。|
|📝 更新|UWarp: A Whole Slide Image Registration Pipeline to Characterize Scanner-Induced Local Domain Shift|UWarp：一种用于表征扫描仪引起的局部域偏移的全幻灯片图像配准流程|Antoine Schieb, Bilal Hadjadji, Natalia Fernanda Valderrama, Daniel Tshokola Mweze, Valentin Derangère, Laurent Arnould, Sylvain Ladoire, Alain Lalande .etc.|<http://arxiv.org/pdf/2503.20653v2>|提出了一种精确对齐数字病理切片的UWarp工具，通过局部域移分析提升了深度学习模型在计算病理学中的鲁...|
|📝 更新|From Blurry to Brilliant Detection: YOLO-Based Aerial Object Detection with Super Resolution|从模糊到清晰检测：基于YOLO的超分辨率航空目标检测|Ragib Amin Nihal, Benjamin Yen, Takeshi Ashizawa, Katsutoshi Itoyama, Kazuhiro Nakadai|<http://arxiv.org/pdf/2401.14661v2>|提出两阶段框架，通过超分辨率恢复输入图像视觉信息，再用改进的YOLOv5进行检测，提升航拍物体识别准...|
|📝 更新|StixelNExT: Toward Monocular Low-Weight Perception for Object Segmentation and Free Space Detection|向单目轻量级感知发展：用于目标分割和自由空间检测的StixelNExT方法|Marcel Vosshans, Omar Ait-Aider, Youcef Mezouar, Markus Enzweiler|<http://arxiv.org/pdf/2407.08277v2>|提出了一种无需标注数据、仅依赖单目图像进行物体分割和自由空间检测的轻量级感知方法。|
|📝 更新|Hespi: A pipeline for automatically detecting information from hebarium specimen sheets|hespi:一种从植物标本纸上自动检测信息的流程|Robert Turnbull, Emily Fitzgerald, Karen Thompson, Joanne L. Birch|<http://arxiv.org/pdf/2410.08740v2>|提出了一种自动化提取植物标本信息的计算机视觉流程，通过对象检测和字符识别技术高效处理标本标签数据。|
|🆕 发布|Bilateral Collaboration with Large Vision-Language Models for Open Vocabulary Human-Object Interaction Detection|双边协作：利用大型视觉-语言模型进行开放词汇的人-物交互检测|Yupeng Hu, Changxing Ding, Chang Sun, Shaoli Huang, Xiangmin Xu|<http://arxiv.org/pdf/2507.06510v1>|提出双边协作框架BC-HOI，利用视觉语言模型生成细粒度交互特征，提升开放词汇人类-物体交互检测性能...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A multi-modal dataset for insect biodiversity with imagery and DNA at the trap and individual level|多模态昆虫生物多样性数据集：包含陷阱和个体水平的图像与DNA信息|Johanna Orsholm, John Quinto, Hannu Autto, Gaia Banelyte, Nicolas Chazot, Jeremy deWaard, Stephanie deWaard, Arielle Farrell .etc.|<http://arxiv.org/pdf/2507.06972v1>|创建了融合分子与成像数据的多模态昆虫多样性数据集，推动大规模昆虫群落快速鉴定。|
|🆕 发布|SemRaFiner: Panoptic Segmentation in Sparse and Noisy Radar Point Clouds|稀疏和噪声雷达点云的全景分割：SemRaFiner|Matthias Zeller, Daniel Casado Herraez, Bengisu Ayan, Jens Behley, Michael Heidingsfeld, Cyrill Stachniss|<http://arxiv.org/pdf/2507.06906v1>|提出SemRaFiner方法，优化雷达点云的稀疏和噪声环境下的全景分割准确性。|
|📝 更新|Transformer-Driven Active Transfer Learning for Cross-Hyperspectral Image Classification|Transformer驱动的跨高光谱图像分类的主动迁移学习|Muhammad Ahmad, Francesco Mauro, Manuel Mazzara, Salvatore Distefano, Adil Mehmood Khan, Silvia Liberata Ullo|<http://arxiv.org/pdf/2411.18115v2>|[代码](https://github.com/mahmad000/ATL-SST.); 提出了一种基于Transformer的主动迁移学习方法，有效应对高光谱图像分类中的数据不足和领域偏移...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Know Your Attention Maps: Class-specific Token Masking for Weakly Supervised Semantic Segmentation|《了解你的注意力图：用于弱监督语义分割的类特定标记遮蔽》|Joelle Hanna, Damian Borth|<http://arxiv.org/pdf/2507.06848v1>|利用Vision Transformer的注意力图实现弱监督语义分割，减少了对精细标注数据的依赖。|
|📝 更新|Label-Efficient LiDAR Panoptic Segmentation|激光雷达少量标注的全景分割|Ahmet Selim Çanakçı, Niclas Vödisch, Kürsat Petek, Wolfram Burgard, Abhinav Valada|<http://arxiv.org/pdf/2503.02372v2>|提出了一种仅需少量标注样本的LiDAR全景分割方法L3PS，通过2D网络和3D细化模块显著提升分割质...|
|📝 更新|CAVIS: Context-Aware Video Instance Segmentation|CAVIS：基于上下文的视频实例分割|Seunghun Lee, Jiwan Seo, Kiljoon Han, Minwoo Choi, Sunghoon Im|<http://arxiv.org/pdf/2407.03010v2>|[代码](https://seung-hun-lee.github.io/projects); 引入了CAVIS框架，通过整合对象周围上下文信息，提升了视频实例分割的跟踪准确性。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Reading a Ruler in the Wild|在野外读取尺子|Yimu Pan, Manas Mehta, Gwen Sincerbeaux, Jeffery A. Goldstein, Alison D. Gernand, James Z. Wang|<http://arxiv.org/pdf/2507.07077v1>|提出RulerNet，通过深度学习准确读取现实世界尺寸，实现通用测量工具的实时高效估计。|
|🆕 发布|Evaluating Attribute Confusion in Fashion Text-to-Image Generation|评估时尚文本到图像生成中的属性混淆|Ziyue Liu, Federico Girella, Yiming Wang, Davide Talon|<http://arxiv.org/pdf/2507.07079v1>|提出了一种针对时尚领域文本到图像生成中属性混淆问题的评价方法，通过结合视觉定位和VQA探测，提高了对...|
|🆕 发布|Go to Zero: Towards Zero-shot Motion Generation with Million-scale Data|走向零：利用百万级数据实现零样本运动生成|Ke Fan, Shunlin Lu, Minyue Dai, Runyi Yu, Lixing Xiao, Zhiyang Dou, Junting Dong, Lizhuang Ma .etc.|<http://arxiv.org/pdf/2507.07095v1>|[代码](https://github.com/VankouF/MotionMillion-Codes.); 提出大规模数据集MotionMillion，实现零样本文本到动作生成，并通过全面评估框架验证模型性能...|
|📝 更新|VQ-SGen: A Vector Quantized Stroke Representation for Creative Sketch Generation|VQ-SGen：一种面向创意素描生成的向量量化笔划表示方法|Jiawei Wang, Zhiming Cui, Changjian Li|<http://arxiv.org/pdf/2411.16446v3>|提出了一种基于向量量化笔划表示的生成算法，通过分离笔划形状与位置信息，提高了创意草图生成的质量和精度...|
|📝 更新|Beyond Complete Shapes: A Quantitative Evaluation of 3D Shape Matching Algorithms|超越完整形状：三维形状匹配算法的定量评估|Viktoria Ehm, Nafie El Amrani, Yizheng Xie, Lennart Bastian, Maolin Gao, Weikang Wang, Lu Sang, Dongliang Cao .etc.|<http://arxiv.org/pdf/2411.03511v2>|提出了一个生成挑战性部分形状匹配场景的框架，并创建了首个大规模部分形状匹配基准数据集。|
|📝 更新|LongAnimation: Long Animation Generation with Dynamic Global-Local Memory|《LongAnimation：动态全局-局部记忆的长动画生成》|Nan Chen, Mengqi Huang, Yihao Meng, Zhendong Mao|<http://arxiv.org/pdf/2507.01945v2>|[代码](https://cn-makers.github.io/long_animation_web); 提出动态全局-局部记忆框架LongAnimation，实现长视频动画自动着色，保持长期色彩一致性。|
|🆕 发布|MCA-RG: Enhancing LLMs with Medical Concept Alignment for Radiology Report Generation|MCA-RG：通过医学概念对齐增强大型语言模型进行放射科报告生成|Qilong Xing, Zikai Song, Youjia Zhang, Na Feng, Junqing Yu, Wei Yang|<http://arxiv.org/pdf/2507.06992v1>|提出了一种将视觉特征与医学概念对齐的知识驱动框架MCA-RG，以提高放射科报告生成的准确性。|
|🆕 发布|Democratizing High-Fidelity Co-Speech Gesture Video Generation|实现高保真协同语音手势视频生成的普及化|Xu Yang, Shaoli Huang, Shenbo Xie, Xuelin Chen, Yifei Liu, Changxing Ding|<http://arxiv.org/pdf/2507.06812v1>|提出了一种利用2D全身骨骼辅助的高保真同步手势视频生成框架，并创建了首个大规模公开数据集。|
|🆕 发布|Physics-Grounded Motion Forecasting via Equation Discovery for Trajectory-Guided Image-to-Video Generation|通过方程发现实现物理约束的运动预测以指导轨迹驱动的图像到视频生成|Tao Feng, Xianbing Zhao, Zhenhua Chen, Tien Tsin Wong, Hamid Rezatofighi, Gholamreza Haffari, Lizhen Qu|<http://arxiv.org/pdf/2507.06830v1>|引入结合符号回归和轨迹引导的框架，实现了基于物理规律的视频预测，提高了生成视频的物理准确性。|
|🆕 发布|Unlocking Thermal Aerial Imaging: Synthetic Enhancement of UAV Datasets|解锁热成像航空摄影：无人机数据集的合成增强|Antonella Barisic Kulas, Andreja Jurasovic, Stjepan Bogdan|<http://arxiv.org/pdf/2507.06797v1>|[代码](https://github.com/larics/thermal_aerial_synthetic.); 提出了一种生成合成热成像数据的方法，扩展了无人机热成像数据集，提高了模型在低光或隐蔽条件下的性能。|
|📝 更新|PR-ENDO: Physically Based Relightable Gaussian Splatting for Endoscopy|PR-ENDO：基于物理的用于内窥镜的重新照明高斯散点渲染|Joanna Kaleta, Weronika Smolak-Dyżewska, Dawid Malarz, Diego Dall'Alba, Przemysław Korzeniowski, Przemysław Spurek|<http://arxiv.org/pdf/2411.12510v2>|提出PR-ENDO方法，通过物理基于的可重光照高斯散点模型，提高了内窥镜3D重建质量并允许组织修改。|
|🆕 发布|PromptTea: Let Prompts Tell TeaCache the Optimal Threshold|PromptTea：让提示告诉TeaCache确定最佳阈值|Zishen Huang, Chunyu Yang, Mengyuan Ren|<http://arxiv.org/pdf/2507.06739v1>|提出了一种自适应缓存策略，根据场景复杂度自动调整重用阈值，实现视频生成速度提升同时保持视觉质量。|
|📝 更新|DynamicID: Zero-Shot Multi-ID Image Personalization with Flexible Facial Editability|动态ID：零样本多身份图像个性化与灵活面部编辑性|Xirui Hu, Jiahao Wang, Hao Chen, Weizhan Zhang, Benqi Wang, Yikun Li, Haishun Nan|<http://arxiv.org/pdf/2503.06505v2>|提出DynamicID框架，实现零样本多身份图像个性化生成，同时保持高保真度和面部编辑灵活性。|
|🆕 发布|Spatial-Temporal Graph Mamba for Music-Guided Dance Video Synthesis|基于时空图曼巴的音乐引导舞蹈视频合成|Hao Tang, Ling Shao, Zhenyu Zhang, Luc Van Gool, Nicu Sebe|<http://arxiv.org/pdf/2507.06689v1>|提出了一种基于时空图的音乐引导舞蹈视频生成方法，通过音乐到骨架和骨架到视频的映射显著提升了舞蹈视频合...|
|🆕 发布|MK-Pose: Category-Level Object Pose Estimation via Multimodal-Based Keypoint Learning|基于多模态关键点学习的类别级物体姿态估计：MK-Pose|Yifan Yang, Peili Song, Enfan Lan, Dong Liu, Jingtai Liu|<http://arxiv.org/pdf/2507.06662v1>|[代码](https://github.com/yangyifanYYF/MK-Pose); 提出了MK-Pose，一种融合图像、点云和文本描述的多模态关键点学习方法，有效提升物体姿态估计的准确...|
|🆕 发布|Diff$^2$I2P: Differentiable Image-to-Point Cloud Registration with Diffusion Prior|差分$^2$I2P：具有扩散先验的可微分图像到点云配准|Juncheng Mu, Chengwei Ren, Weixiang Zhang, Liang Pan, Xiao-Ping Zhang, Yue Gao|<http://arxiv.org/pdf/2507.06651v1>|提出了一种利用扩散先验的全微分图像到点云配准框架，有效桥接了图像与点云间的模态差距。|
|📝 更新|ReCamMaster: Camera-Controlled Generative Rendering from A Single Video|《ReCamMaster：从单个视频实现相机控制的生成渲染》|Jianhong Bai, Menghan Xia, Xiao Fu, Xintao Wang, Lianrui Mu, Jinwen Cao, Zuozhu Liu, Haoji Hu .etc.|<http://arxiv.org/pdf/2503.11647v2>|[代码](https://github.com/KwaiVGI/ReCamMaster.); 提出了一种基于预训练文本到视频模型的视频重渲染框架，实现了对给定视频在新型摄像机轨迹上的动态场景再现...|
|🆕 发布|Denoising Multi-Beta VAE: Representation Learning for Disentanglement and Generation|去噪多Beta变分自编码器：用于解耦和生成的表示学习|Anshuk Uppal, Yuhta Takida, Chieh-Hsin Lai, Yuki Mitsufuji|<http://arxiv.org/pdf/2507.06613v1>|提出多$\beta$值VAE框架，通过非线性扩散模型平衡解耦与重建质量，实现几乎无损的生成效果。|
|📝 更新|Tora2: Motion and Appearance Customized Diffusion Transformer for Multi-Entity Video Generation|Tora2：用于多实体视频生成的运动和外观定制扩散变换器|Zhenghao Zhang, Junchao Liao, Xiangyu Meng, Long Qin, Weizhi Wang|<http://arxiv.org/pdf/2507.05963v2>|[代码](https://ali-videoai.github.io/Tora2_page); 提出了Tora2模型，实现了视频生成中多实体外观与运动的同步定制化。|
|📝 更新|Semantic Augmentation in Images using Language|图像中基于语言的语义增强|Sahiti Yerramilli, Jayant Sravan Tamarapalli, Tanmay Girish Kulkarni, Jonathan Francis, Eric Nyberg|<http://arxiv.org/pdf/2404.02353v2>|提出利用文本驱动的扩散模型生成图像进行数据增强，以提高深度学习模型的泛化能力。|
|🆕 发布|3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds|《3D通用模型：用于构建三维世界的自提升视觉-语言-动作模型》|Fan-Yun Sun, Shengguang Wu, Christian Jacobsen, Thomas Yim, Haoming Zou, Alex Zook, Shangru Li, Yu-Hsin Chou .etc.|<http://arxiv.org/pdf/2507.06484v1>|提出了一种自我优化方法3D-Generalist，通过训练视觉语言模型生成高质量的3D环境，用于提升...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|TIP-I2V: A Million-Scale Real Text and Image Prompt Dataset for Image-to-Video Generation|TIP-I2V：百万级真实文本与图像提示数据集用于图像到视频生成|Wenhao Wang, Yi Yang|<http://arxiv.org/pdf/2411.04709v2>|介绍了首个百万级针对图像到视频生成的用户文本和图像提示数据集，推动图像到视频研究进展。|
|📝 更新|AI-GenBench: A New Ongoing Benchmark for AI-Generated Image Detection|AI-GenBench：人工智能生成图像检测新持续基准|Lorenzo Pellegrini, Davide Cozzolino, Serafino Pandolfini, Davide Maltoni, Matteo Ferrara, Luisa Verdoliva, Marco Prati, Marco Ramilli|<http://arxiv.org/pdf/2504.20865v2>|提出AI-GenBench基准，通过动态训练和评估，应对AI生成图像检测挑战。|
|🆕 发布|FIFA: Unified Faithfulness Evaluation Framework for Text-to-Video and Video-to-Text Generation|FIFA：文本到视频和视频到文本生成的一致性评估框架|Liqiang Jing, Viet Lai, Seunghyun Yoon, Trung Bui, Xinya Du|<http://arxiv.org/pdf/2507.06523v1>|提出统一真实性评估框架FIFA，有效检测并修正视频与文本生成中的虚假内容。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models|视觉-语言-视觉自动编码器：从扩散模型中进行可扩展知识蒸馏|Tiezheng Zhang, Yitong Li, Yu-cheng Chou, Jieneng Chen, Alan Yuille, Chen Wei, Junfei Xiao|<http://arxiv.org/pdf/2507.07104v1>|提出了一种高效的视觉语言模型训练框架，通过知识蒸馏和预训练模型结合，大幅降低了数据需求和训练成本。|
|📝 更新|Self-Calibrated Variance-Stabilizing Transformations for Real-World Image Denoising|自校准方差稳定变换用于现实世界图像去噪|Sébastien Herbreteau, Michael Unser|<http://arxiv.org/pdf/2407.17399v2>|提出了一种无需额外训练的算法Noise2VST，通过方差稳定变换提升现成高斯噪声去除网络对实际图像的...|
|📝 更新|Modality-agnostic, patient-specific digital twins modeling temporally varying digestive motion|模态无关、患者特定的数字孪生模型，用于模拟时间变化的消化运动|Jorge Tapias Gomez, Nishant Nadkarni, Lando S. Bosma, Jue Jiang, Ergys D. Subashi, William P. Segars, James M. Balter, Mert R Sabuncu .etc.|<http://arxiv.org/pdf/2507.01909v3>|创建了患者特异性数字孪生模型以模拟消化运动，准确评估变形图像配准方法的性能。|
|📝 更新|Multi-Modality Conditioned Variational U-Net for Field-of-View Extension in Brain Diffusion MRI|多模态条件变分U-Net用于脑部扩散MRI视野扩展|Zhiyuan Li, Chenyu Gao, Praitayini Kanakaraj, Shunxing Bao, Lianrui Zuo, Michael E. Kim, Nancy R. Newlin, Gaurav Rudravaram .etc.|<http://arxiv.org/pdf/2409.13846v2>|提出了一种多模态数据融合的U-Net框架，有效提高了脑部弥散MRI扫描的不完整视野重建质量和下游纤维...|
|📝 更新|Sparse Autoencoder as a Zero-Shot Classifier for Concept Erasing in Text-to-Image Diffusion Models|稀疏自动编码器作为零样本分类器用于文本到图像扩散模型中的概念擦除|Zhihua Tian, Sirun Nan, Ming Xu, Shengfang Zhai, Wenjie Qu, Jian Liu, Ruoxi Jia, Jiaheng Zhang|<http://arxiv.org/pdf/2503.09446v3>|[代码](https://github.com/NANSirun/Interpret-then-deactivate.); 提出了一种无需重新训练的框架，通过稀疏自动编码器实现精确的概念移除，同时保持文本到图像生成模型的性能...|
|🆕 发布|Speckle2Self: Self-Supervised Ultrasound Speckle Reduction Without Clean Data|Speckle2Self: 无需干净数据监督的超声散斑减少方法|Xuesong Li, Nassir Navab, Zhongliang Jiang|<http://arxiv.org/pdf/2507.06828v1>|提出 Speckle2Self 算法，通过单次噪声音像实现超声 speckle 噪声的自监督降低。|
|📝 更新|Revisiting Likelihood-Based Out-of-Distribution Detection by Modeling Representations|重新审视基于似然度的分布外检测：通过建模表征进行探索|Yifan Ding, Arturas Aleksandraus, Amirhossein Ahmadian, Jonas Unger, Fredrik Lindsten, Gabriel Eilertsen|<http://arxiv.org/pdf/2504.07793v2>|[代码](https://github.com/limchaos/Likelihood-OOD.git); 通过在预训练编码器的表示空间应用概率流扩散模型，证明了基于似然的异常检测方法可达到先进水平。|
|🆕 发布|Hierarchical Feature Alignment for Gloss-Free Sign Language Translation|层次化特征对准用于无光泽手语翻译|Sobhan Asasi, Mohamed Ilyes Lakhal, Richard Bowden|<http://arxiv.org/pdf/2507.06732v1>|提出了一种分层特征对齐策略，通过模仿手语结构，提高了无注解手语翻译的准确性和效率。|
|🆕 发布|DIFFUMA: High-Fidelity Spatio-Temporal Video Prediction via Dual-Path Mamba and Diffusion Enhancement|DIFFUMA：通过双路径 Mamba 和扩散增强实现高保真度时空视频预测|Xinyu Xie, Weifeng Cao, Jun Shi, Yangyang Hu, Hui Liang, Wanyong Liang, Xiaoliang Qian|<http://arxiv.org/pdf/2507.06738v1>|提出首个针对半导体晶圆切割过程的公共数据集，并设计出创新的DIFFUMA架构，显著提升视频预测精度。|
|🆕 发布|Residual Prior-driven Frequency-aware Network for Image Fusion|基于残差先验驱动的频率感知网络用于图像融合|Guan Zheng, Xue Wang, Wenhua Qian, Peng Liu, Runzhuo Ma|<http://arxiv.org/pdf/2507.06735v1>|提出了一种残差先验驱动的频率感知网络，有效融合多模态图像特征，提升高级视觉任务性能。|
|🆕 发布|Enhancing Diffusion Model Stability for Image Restoration via Gradient Management|通过梯度管理增强图像复原中扩散模型稳定性|Hongjie Wu, Mingqin Zhang, Linchao He, Ji-Zhe Zhou, Jiancheng Lv|<http://arxiv.org/pdf/2507.06656v1>|[代码](https://github.com/74587887/SPGD); 提出梯度管理技术SPGD，有效解决扩散模型在图像恢复中的稳定性问题，实现性能提升。|
|🆕 发布|MS-DPPs: Multi-Source Determinantal Point Processes for Contextual Diversity Refinement of Composite Attributes in Text to Image Retrieval|多源确定性点过程（MS-DPPs）：用于文本到图像检索中组合属性上下文多样性优化的方法|Naoya Sogi, Takashi Shibata, Makoto Terao, Masanori Suganuma, Takayuki Okatani|<http://arxiv.org/pdf/2507.06654v1>|[代码](https://github.com/NEC-N-SOGI/msdpp.); 提出了一种多源确定性点过程模型，根据应用上下文细化图像属性多样性。|
|🆕 发布|MOST: Motion Diffusion Model for Rare Text via Temporal Clip Banzhaf Interaction|MOST：通过时间片段Banzhaf交互实现稀有文本的运动扩散模型|Yin Wang, Mu li, Zhiying Leng, Frederick W. B. Li, Xiaohui Liang|<http://arxiv.org/pdf/2507.06590v1>|MOST通过创新的时序片段Banzhaf交互，解决了稀有语言提示生成人类运动的问题。|
|🆕 发布|Concept-TRAK: Understanding how diffusion models learn concepts through concept-level attribution|概念追踪：通过概念级归因理解扩散模型如何学习概念|Yonghyun Park, Chieh-Hsin Lai, Satoshi Hayakawa, Yuhta Takida, Naoki Murata, Wei-Hsiang Liao, Woosung Choi, Kin Wai Cheuk .etc.|<http://arxiv.org/pdf/2507.06547v1>|提出概念级归因方法Concept-TRAK，通过改进扩散模型训练和奖励函数，实现对特定元素如风格或对...|
|📝 更新|DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation|膨胀量化：通过权重膨胀实现精确且高效的扩散量化|Xuewen Liu, Zhikai Li, Minhao Jiang, Mengjuan Chen, Jianquan Li, Qingyi Gu|<http://arxiv.org/pdf/2409.14307v3>|[代码](http://github.com/BienLuky/DilateQuant); 提出了一种针对扩散模型的DilateQuant量化框架，通过权重膨胀和时序并行量化技术，有效提升低比...|
|📝 更新|Integrated Structural Prompt Learning for Vision-Language Models|集成结构提示学习用于视觉-语言模型|Jiahui Wang, Qin Xu, Bo Jiang, Bin Luo|<http://arxiv.org/pdf/2507.05677v2>|提出了一种集成结构提示学习的方法，通过建模文本和图像间的结构关系，提高了视觉语言模型的泛化能力和样本...|
|🆕 发布|Concept Unlearning by Modeling Key Steps of Diffusion Process|通过建模扩散过程的关键步骤实现概念遗忘|Chaoshuo Zhang, Chenhao Lin, Zhengyu Zhao, Le Yang, Qian Wang, Chao Shen|<http://arxiv.org/pdf/2507.06526v1>|提出 Key Step Concept Unlearning 方法，通过专注于关键步骤优化概念遗忘效...|
|📝 更新|CaO$_2$: Rectifying Inconsistencies in Diffusion-Based Dataset Distillation|CaO$_2$: 矫正基于扩散的数据集蒸馏中的不一致性|Haoxuan Wang, Zhenghao Zhao, Junyi Wu, Yuzhang Shang, Gaowen Liu, Yan Yan|<http://arxiv.org/pdf/2506.22637v2>|提出CaO$_2$方法，解决扩散模型数据集精炼中的目标偏差和条件不匹配问题，实现最优性能。|
|📝 更新|QuEST: Low-bit Diffusion Model Quantization via Efficient Selective Finetuning|QuEST：通过高效选择性微调的低比特扩散模型量化|Haoxuan Wang, Yuzhang Shang, Zhihang Yuan, Junyi Wu, Junchi Yan, Yan Yan|<http://arxiv.org/pdf/2402.03666v5>|提出了一种通过选择性微调优化低比特量化效率的方法，有效解决了扩散模型部署中的高内存和计算负担问题。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|IAP: Invisible Adversarial Patch Attack through Perceptibility-Aware Localization and Perturbation Optimization|隐式对抗贴片攻击：通过感知性感知定位和扰动优化|Subrat Kishore Dutta, Xiao Zhang|<http://arxiv.org/pdf/2507.06856v1>|提出了一种隐形的对抗性贴片攻击框架IAP，通过感知定位和扰动优化生成难以察觉的对抗性贴片。|
|🆕 发布|Edge-Boundary-Texture Loss: A Tri-Class Generalization of Weighted Binary Cross-Entropy for Enhanced Edge Detection|边缘-边界-纹理损失：加权二元交叉熵的三类泛化增强边缘检测|Hao Shu|<http://arxiv.org/pdf/2507.06569v1>|提出三分类的Edge-Boundary-Texture损失函数，提高了边缘检测的精度和边界定位能力。|
|📝 更新|CLIPDraw++: Text-to-Sketch Synthesis with Simple Primitives|CLIPDraw++：基于简单基元的文本到草图合成|Nityanand Mathur, Shyam Marjit, Abhra Chaudhuri, Anjan Dutta|<http://arxiv.org/pdf/2312.02345v2>|[代码](https://clipdrawx.github.io/.); 提出了一种使用简单几何原语如直线和圆的CLIPDraw++算法，通过线性变换实现文本到草图的高效合成...|
|📝 更新|Leveraging Local Patch Alignment to Seam-cutting for Large Parallax Image Stitching|利用局部斑块对齐进行无缝裁剪以实现大视差图像拼接|Tianli Liao, Chenyang Zhao, Lei Li, Heling Cao|<http://arxiv.org/pdf/2311.18564v3>|[代码](https://github.com/tlliao/LPAM_seam-cutting.); 提出了一种补偿初始对齐不准确性的方法，通过局部补丁对齐改善大视差图像拼接质量。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SimCortex: Collision-free Simultaneous Cortical Surfaces Reconstruction|"SimCortex：无碰撞的同时皮质表面重建"|Kaveh Moradkhani, R Jarrett Rushmore, Sylvain Bouix|<http://arxiv.org/pdf/2507.06955v1>|SimCortex通过深度学习框架同时重建大脑表面，避免了碰撞和拓扑缺陷，提高了几何精度。|
|📝 更新|Counting Stacked Objects|堆叠物体的计数|Corentin Dumery, Noa Etté, Aoxiang Fan, Ren Li, Jingyi Xu, Hieu Le, Pascal Fua|<http://arxiv.org/pdf/2411.19149v3>|提出了一种结合几何重建和深度学习的方法，准确计数容器内不规则堆叠的物体。|
|📝 更新|Reconstructing Satellites in 3D from Amateur Telescope Images|从业余望远镜图像中三维重建卫星|Zhiming Chang, Boyang Liu, Yifei Xia, Youming Guo, Boxin Shi, He Sun|<http://arxiv.org/pdf/2404.18394v4>|提出了一种集成图像预处理和联合位姿估计的3D卫星重建框架，有效克服了地面望远镜图像重建的挑战。|
|📝 更新|3DPortraitGAN: Learning One-Quarter Headshot 3D GANs from a Single-View Portrait Dataset with Diverse Body Poses|3DPortraitGAN：从单视角人像数据集学习具有多样化身体姿态的四分之三头部3D生成对抗网络|Yiqian Wu, Hao Xu, Xiangjun Tang, Yue Shangguan, Hongbo Fu, Xiaogang Jin|<http://arxiv.org/pdf/2307.14770v3>|首次提出3DPortraitGAN，通过自学习身体姿态从单视角生成完整几何结构的四分之三侧面3D肖像...|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ADPv2: A Hierarchical Histological Tissue Type-Annotated Dataset for Potential Biomarker Discovery of Colorectal Disease|ADPv2：一种用于结直肠癌潜在生物标志物发现的多层次组织学类型注释数据集|Zhiyuan Yang, Kai Li, Sophia Ghamoshi Ramandi, Patricia Brassard, Hakim Khellaf, Vincent Quoc-Huy Trinh, Jennifer Zhang, Lina Chen .etc.|<http://arxiv.org/pdf/2507.05656v2>|构建了ADPv2数据集，通过细粒度组织类型标注，助力特定器官疾病深入研究和潜在生物标志物发现。|
|🆕 发布|StixelNExT++: Lightweight Monocular Scene Segmentation and Representation for Collective Perception|StixelNExT++：轻量级单目场景分割与表示集体感知|Marcel Vosshans, Omar Ait-Aider, Youcef Mezouar, Markus Enzweiler|<http://arxiv.org/pdf/2507.06687v1>|提出了一种轻量级单目场景分割与表示方法StixelNExT++，通过聚类3D Stixel单元增强对...|
|📝 更新|Dynamic Reconstruction of Hand-Object Interaction with Distributed Force-aware Contact Representation|动态重建分布式力感知接触表示的手-对象交互|Zhenjun Yu, Wenqiang Xu, Pengfei Xie, Yutong Li, Brian W. Anthony, Zhuorui Zhang, Cewu Lu|<http://arxiv.org/pdf/2411.09572v2>|提出ViTaM-D框架，结合视觉与触觉感知，精确重构动态手物交互及形变。|
|📝 更新|GazeGaussian: High-Fidelity Gaze Redirection with 3D Gaussian Splatting|《 gazeGaussian：基于三维高斯散点的高保真视线重定向》|Xiaobao Wei, Peng Chen, Guangyu Li, Ming Lu, Hui Chen, Feng Tian|<http://arxiv.org/pdf/2411.12981v2>|[代码](https://ucwxb.github.io/GazeGaussian.); 提出了一种高效的3D Gaussian Splatting gaze redirection方法，通...|


## 时序视觉分析 (Temporal Visual Analysis)


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Cross-Modal Dual-Causal Learning for Long-Term Action Recognition|跨模态双因果学习用于长期行为识别|Xu Shaowu, Jia Xibin, Gao Junyu, Sun Qianmei, Chang Jing, Fan Chao|<http://arxiv.org/pdf/2507.06603v1>|[代码](https://github.com/xushaowu/CMDCL.); 提出了一种双因果干预的跨模态学习方法，有效解决了长期动作识别中的复杂关联和视觉干扰问题。|
|📝 更新|Signal-SGN: A Spiking Graph Convolutional Network for Skeletal Action Recognition via Learning Temporal-Frequency Dynamics|信号SGN：通过学习时频动态进行骨骼动作识别的尖峰图卷积网络|Naichuan Zheng, Yuchen Du, Hailun Xia, Zeyu Liang|<http://arxiv.org/pdf/2408.01701v5>|提出Signal-SGN模型，通过结合时间维度和频率特性，提升骨骼动作识别的准确性与能效。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Capturing Stable HDR Videos Using a Dual-Camera System|使用双摄像头系统捕捉稳定的HDR视频|Qianyu Zhang, Bolun Zheng, Hangjia Pan, Lingyu Zhu, Zunjie Zhu, Zongpeng Li, Shiqi Wang|<http://arxiv.org/pdf/2507.06593v1>|[代码](https://github.com/zqqqyu/DCS.); 提出了一种双摄像头系统结合曝光自适应融合网络，有效解决了HDR视频重建中的闪烁问题。|
|🆕 发布|Token Bottleneck: One Token to Remember Dynamics|“Token瓶颈：一个Token记住动态特性”|Taekyung Kim, Dongyoon Han, Byeongho Heo, Jeongeun Park, Sangdoo Yun|<http://arxiv.org/pdf/2507.06543v1>|提出Token Bottleneck方法，通过紧凑的视觉表示学习动态场景的时序理解。|
|🆕 发布|Video-RTS: Rethinking Reinforcement Learning and Test-Time Scaling for Efficient and Enhanced Video Reasoning|视频-RTS：重新思考强化学习与测试时缩放以实现高效和增强的视频推理|Ziyang Wang, Jaehong Yoon, Shoubin Yu, Md Mohaiminul Islam, Gedas Bertasius, Mohit Bansal|<http://arxiv.org/pdf/2507.06485v1>|提出了一种高效视频推理方法Video-RTS，通过结合数据高效的强化学习和自适应测试时扩展策略，大幅...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ILNet: Trajectory Prediction with Inverse Learning Attention for Enhancing Intention Capture|ILNet：利用逆学习注意力增强意图捕获的轨迹预测|Mingjin Zeng, Nan Ouyang, Wenkang Wan, Lei Ao, Qing Cai, Kai Sheng|<http://arxiv.org/pdf/2507.06531v1>|[代码](https://github.com/mjZeng11/ILNet.); 提出ILNet方法，通过逆学习注意力和动态锚点选择增强多智能体轨迹预测的交互意图捕捉能力。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DecoderTracker: Decoder-Only Method for Multiple-Object Tracking|解码器追踪器：仅解码器方法用于多目标跟踪|Liao Pan, Yang Feng, Zhao Wenhui, Yua Jinwen, Zhang Dingwen|<http://arxiv.org/pdf/2310.17170v6>|[代码](https://github.com/liaopan-lp/MO-YOLO.); 提出DecoderTracker方法，优化网络架构和训练策略，实现更快的多目标跟踪速度。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MST-Distill: Mixture of Specialized Teachers for Cross-Modal Knowledge Distillation|MST-蒸馏：跨模态知识蒸馏的专用教师混合模型|Hui Li, Pengfei Yang, Juanyang Chen, Le Dong, Yanxin Chen, Quan Wang|<http://arxiv.org/pdf/2507.07015v1>|[代码](https://github.com/Gray-OREO/MST-Distill.); 提出 MST-Distill 方法，通过混合专业教师模型解决跨模态知识蒸馏中的路径选择和知识漂移问题...|


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Cross-Modality Masked Learning for Survival Prediction in ICI Treated NSCLC Patients|跨模态掩码学习在ICI治疗非小细胞肺癌患者生存预测中的应用|Qilong Xing, Zikai Song, Bingxin Gong, Lian Yang, Junqing Yu, Wei Yang|<http://arxiv.org/pdf/2507.06994v1>|提出了一种跨模态掩码学习框架，通过3D图像和临床记录的融合，提高了非小细胞肺癌免疫治疗生存预测的准确...|
|🆕 发布|A Principled Framework for Multi-View Contrastive Learning|多视角对比学习的原理性框架|Panagiotis Koromilas, Efthymios Georgiou, Giorgos Bouritsas, Theodoros Giannakopoulos, Mihalis A. Nicolaou, Yannis Panagakis|<http://arxiv.org/pdf/2507.06979v1>|提出了一种多视角对比学习的原则性框架，通过两个新颖的损失函数优化了多视角间的交互和一致性。|
|🆕 发布|Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement|自适应部分学习用于细粒度广义类别发现：即插即用增强方法|Qiyuan Dai, Hanzhuo Huang, Yu Wu, Sibei Yang|<http://arxiv.org/pdf/2507.06928v1>|提出了一种自适应部分学习策略，通过增强图像局部特征的一致性和对比性，有效提升了细粒度类别发现的区分度...|
|📝 更新|SCMM: Calibrating Cross-modal Fusion for Text-Based Person Search|SCMM：校准基于文本的人物搜索中的跨模态融合|Jing Liu, Donglai Wei, Yang Liu, Sipeng Zhang, Tong Yang, Wei Zhou, Weiping Ding, Victor C. M. Leung|<http://arxiv.org/pdf/2304.02278v6>|提出SCMM框架，通过自适应约束和细粒度对应策略有效解决文本-based人物搜索中的跨模态融合挑战。|
|🆕 发布|Ambiguity-aware Point Cloud Segmentation by Adaptive Margin Contrastive Learning|基于自适应边缘对比学习的模糊感知点云分割|Yang Chen, Yueqi Duan, Haowen Sun, Jiwen Lu, Yap-Peng Tan|<http://arxiv.org/pdf/2507.06592v1>|[代码](https://github.com/YangChenApril/AMContrast3D.); 提出了一种自适应边缘对比学习法，用于处理点云中3D语义分割的模糊性问题，通过区分不同点的模糊度来优化...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|An AI Approach for Learning the Spectrum of the Laplace-Beltrami Operator|用于学习拉普拉斯-贝尔特拉米算子谱的人工智能方法|Yulin An, Enrique del Castillo|<http://arxiv.org/pdf/2507.07073v1>|提出了一种基于图神经网络的高效预测Laplace-Beltrami算子谱的方法，大幅降低了计算复杂度...|
|🆕 发布|Design and Implementation of an OCR-Powered Pipeline for Table Extraction from Invoices|发票表格提取的OCR驱动流程设计与实现|Parshva Dhilankumar Patel|<http://arxiv.org/pdf/2507.07029v1>|设计了一种基于OCR的发票表格提取流程，提高了数据提取的准确性和一致性。|
|📝 更新|Bayesian Multi-Scale Neural Network for Crowd Counting|贝叶斯多尺度神经网络用于人群计数|Abhinav Sagar|<http://arxiv.org/pdf/2007.14245v4>|提出了一种融合多尺度信息的神经网络架构，有效应对人群计数中的遮挡和尺度变化问题，并通过贝叶斯推理提供...|
|📝 更新|DArFace: Deformation Aware Robustness for Low Quality Face Recognition|《DArFace：面向低质量人脸识别的形变感知鲁棒性》|Sadaf Gulshad, Abdullah Aldahlawi Thakaa|<http://arxiv.org/pdf/2505.08423v2>|[代码](https://github.com/sadafgulshad1/DArFace); 提出DArFace框架，通过模拟全局和局部形变提升低质量人脸识别的鲁棒性。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ROCKET-2: Steering Visuomotor Policy via Cross-View Goal Alignment|ROCKET-2：通过跨视角目标对齐引导视觉运动策略|Shaofei Cai, Zhancun Mu, Anji Liu, Yitao Liang|<http://arxiv.org/pdf/2503.02505v2>|提出了一种跨视角目标对齐框架，通过用户相机视角的分割掩码指导3D环境中智能体交互，显著提升效率和零样...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhancing non-Rigid 3D Model Deformations Using Mesh-based Gaussian Splatting|使用基于网格的高斯散点增强非刚性三维模型形变|Wijayathunga W. M. R. D. B|<http://arxiv.org/pdf/2507.07000v1>|提出了一种结合网格表示与高斯散点投射的新框架，实现了非刚性3D模型变形的增强与直观编辑。|
|🆕 发布|Finetuning Vision-Language Models as OCR Systems for Low-Resource Languages: A Case Study of Manchu|将计算机视觉论文标题翻译成中文：  细粒度调整视觉-语言模型作为低资源语言的OCR系统：满语文案例研究|Yan Hon Michael Chung, Donghyeok Choi|<http://arxiv.org/pdf/2507.06761v1>|[代码](https://github.com/mic7ch1/ManchuAI-OCR.); 通过微调开源视觉语言模型，为低资源语言满文开发出高效的OCR系统，实现了从合成数据到实际手写文档的有...|
|🆕 发布|FlexGaussian: Flexible and Cost-Effective Training-Free Compression for 3D Gaussian Splatting|FlexGaussian：灵活且经济的无需训练的3D高斯散点压缩方法|Boyuan Tian, Qizhe Gao, Siran Xianyu, Xiaotong Cui, Minjia Zhang|<http://arxiv.org/pdf/2507.06671v1>|[代码](https://github.com/Supercomputing-System-AI-Lab/FlexGaussian); 提出了一种无需训练、灵活高效的3D高斯分布压缩方法FlexGaussian，大幅降低存储计算成本。|
|📝 更新|Non-Negative Reduced Biquaternion Matrix Factorization with Applications in Color Face Recognition|非负缩减双四元数矩阵分解及其在彩色人脸识别中的应用|Jifei Miao, Junjun Pan, Michael K. Ng|<http://arxiv.org/pdf/2408.05582v2>|提出非负降维双四元数矩阵分解模型，用于彩色人脸识别，提高了模型有效性和优越性。|
|📝 更新|Geo-Registration of Terrestrial LiDAR Point Clouds with Satellite Images without GNSS|无需GNSS的地面激光雷达点云与卫星图像的地理配准|Xinyu Wang, Muhammad Ibrahim, Haitian Wang, Atif Mansoor, Ajmal Mian|<http://arxiv.org/pdf/2507.05999v2>|提出了一种无需GNSS的LiDAR点云与卫星图像配准方法，通过提取道路特征实现高精度城市三维地图重建...|
|🆕 发布|Speak2Sign3D: A Multi-modal Pipeline for English Speech to American Sign Language Animation|《Speak2Sign3D：一种将英语语音转化为美国手语动画的多模态处理流程》|Kazi Mahathir Rahman, Naveed Imtiaz Nafis, Md. Farhan Sadik, Mohammad Al Rafi, Mehedi Hasan Shahed|<http://arxiv.org/pdf/2507.06530v1>|提出了一种多模态管道，将英语语音转化为流畅的3D美国手语动画。|
|📝 更新|EMD: Explicit Motion Modeling for High-Quality Street Gaussian Splatting|EMD：显式运动建模用于高质量街道高斯散点绘制|Xiaobao Wei, Qingpo Wuwu, Zhongyu Zhao, Zhuangzhe Wu, Nan Huang, Ming Lu, Ningning MA, Shanghang Zhang|<http://arxiv.org/pdf/2411.15582v2>|[代码](https://qingpowuwu.github.io/emd.); 引入可学习运动嵌入的显式运动分解方法，有效提升了复杂街道场景的动态对象运动建模和图像重建质量。|
|📝 更新|HyperGCT: A Dynamic Hyper-GNN-Learned Geometric Constraint for 3D Registration|超图GCT：一种用于三维配准的动态超图神经网络学习几何约束|Xiyu Zhang, Jiayi Ma, Jianwei Guo, Wei Hu, Zhaoshuai Qi, Fei Hui, Jiaqi Yang, Yanning Zhang|<http://arxiv.org/pdf/2503.02195v2>|提出了一种动态超图学习的几何约束方法HyperGCT，用于提高3D点云配准的准确性和鲁棒性。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CheXPO: Preference Optimization for Chest X-ray VLMs with Counterfactual Rationale|CheXPO：利用反事实解释优化胸部X射线大模型偏好|Xiao Liang, Jiawei Hu, Di Wang, Zhi Ma, Lin Zhao, Ronghan Li, Bo Wan, Quan Wang|<http://arxiv.org/pdf/2507.06959v1>|提出CheXPO方法，通过结合置信度-相似度挖掘和反事实推理优化医学图像VLMs，减少幻觉并提升性能...|
|📝 更新|AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model|AHCPTQ：面向Segment Anything模型的精确且硬件兼容的后训练量化方法|Wenlun Zhang, Yunshan Zhong, Shimpei Ando, Kentaro Yoshioka|<http://arxiv.org/pdf/2503.03088v2>|提出AHCPTQ方法，通过硬件兼容的混合对数均匀量化与通道感知分组，有效提升SAM模型量化精度和硬件...|
|🆕 发布|ClipGS: Clippable Gaussian Splatting for Interactive Cinematic Visualization of Volumetric Medical Data|ClipGS：可剪辑的高斯散点绘制法用于交互式电影级可视化体积医学数据|Chengkun Li, Yuqi Tong, Kai Chen, Zhenya Yang, Ruiyang Li, Shi Qiu, Jason Ying-Kuen Chan, Pheng-Ann Heng .etc.|<http://arxiv.org/pdf/2507.06647v1>|提出ClipGS方法，通过剪裁平面支持的高斯散布框架实现医学数据的高效交互式电影渲染。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM|"即飞即自由：通过在线EM算法增强测试时适应性的灵活性"|Qiyuan Dai, Sibei Yang|<http://arxiv.org/pdf/2507.06973v1>|提出FreeTTA方法，无需训练直接利用测试数据分布关系提升预测准确性。|
|🆕 发布|Pre-Columbian Settlements Shaped Palm Clusters in the Sierra Nevada de Santa Marta, Colombia|前哥伦布时期定居点塑造了哥伦比亚圣玛尔塔山脉棕榈树集群|Sebastian Fajardo, Sina Mohammadi, Jonas Gregorio de Souza, César Ardila, Alan Tapscott Baltar, Shaddai Heidgen, Maria Isabel Mayorga Hernández, Sylvia Mota de Oliveira .etc.|<http://arxiv.org/pdf/2507.06949v1>|提出利用卫星图像和深度学习模型识别棕榈树集群，揭示史前人类活动对植被的影响。|
|🆕 发布|Conformal Prediction for Long-Tailed Classification|长尾分类的保角预测|Tiffany Ding, Jean-Baptiste Fermanian, Joseph Salmon|<http://arxiv.org/pdf/2507.06867v1>|提出方法平衡长尾分布分类问题中的预测集大小和类条件覆盖率。|
|📝 更新|Batch Normalization in Cytometry Data by kNN-Graph Preservation|基于kNN图保留的细胞计量数据批量归一化|Muhammad S. Battikh, Artem Lensky|<http://arxiv.org/pdf/2304.00050v4>|提出了一种基于残差神经网络的批归一化方法，有效处理CyTOF数据中的批次效应并保持细胞群体拓扑结构。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GreenHyperSpectra: A multi-source hyperspectral dataset for global vegetation trait prediction|绿色超光谱：一种用于全球植被特性预测的多源超光谱数据集|Eya Cherif, Arthur Ouaknine, Luke A. Brown, Phuong D. Dao, Kyle R. Kovach, Bing Lu, Daniel Mederer, Hannes Feilhauer .etc.|<http://arxiv.org/pdf/2507.06806v1>|[代码](https://github.com/echerif18/HyspectraSSL.); 构建了GreenHyperSpectra数据集，通过半监督和自监督学习提升植物性状预测准确度，优于传...|
|📝 更新|Towards Adversarial Robustness via Debiased High-Confidence Logit Alignment|通过去偏高置信度对数校准实现对抗稳健性|Kejia Zhang, Juanjuan Weng, Shaozi Li, Zhiming Luo|<http://arxiv.org/pdf/2408.06079v2>|[代码](https://github.com/KejiaZhang-Robust/DHAT.); 提出了一种去偏正则化的对抗训练方法DHAT，有效提升了模型的鲁棒性和泛化能力。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Addressing Imbalanced Domain-Incremental Learning through Dual-Balance Collaborative Experts|通过双平衡协同专家解决不平衡域增量学习问题|Lan Li, Da-Wei Zhou, Han-Jia Ye, De-Chuan Zhan|<http://arxiv.org/pdf/2507.07100v1>|提出了一种Dual-Balance Collaborative Experts框架，有效解决领域增量...|
|🆕 发布|Learning Deliberately, Acting Intuitively: Unlocking Test-Time Reasoning in Multimodal LLMs|《刻意学习，直觉行动：解锁多模态大型语言模型在测试时的推理能力》|Yahan Yu, Yuyang Dong, Masafumi Oyamada|<http://arxiv.org/pdf/2507.06999v1>|提出了一种无需额外标注和复杂奖励的Deliberate-to-Intuitive框架，提升多模态大语...|
|🆕 发布|Segmentation Regularized Training for Multi-Domain Deep Learning Registration applied to MR-Guided Prostate Cancer Radiotherapy|多域深度学习配准的分割正则化训练在MR引导的前列腺癌放射治疗中的应用|Sudharsan Madhavan, Chengcheng Gui, Lando Bosma, Josiah Simeth, Jue Jiang, Nicolas Cote, Nima Hassan Rezaeian, Himanshu Nagar .etc.|<http://arxiv.org/pdf/2507.06966v1>|提出了一种多域深度学习配准方法ProRSeg，通过分割一致性损失训练，实现了前列腺癌放疗中MR-MR...|
|🆕 发布|Fast Equivariant Imaging: Acceleration for Unsupervised Learning via Augmented Lagrangian and Auxiliary PnP Denoisers|快速等变成像：通过增强拉格朗日方法和辅助PnP去噪器加速无监督学习|Guixian Xu, Jinglai Li, Junqi Tang|<http://arxiv.org/pdf/2507.06764v1>|提出Fast Equivariant Imaging框架，通过增强Lagrange乘数法和PnP去噪...|
|🆕 发布|Learning from Sparse Point Labels for Dense Carcinosis Localization in Advanced Ovarian Cancer Assessment|从稀疏点标签学习实现高级卵巢癌评估中的密集癌变定位|Farahdiba Zarin, Riccardo Oliva, Vinkle Srivastav, Armine Vardazaryan, Andrea Rosati, Alice Zampolini Faustini, Giovanni Scambia, Anna Fagotti .etc.|<http://arxiv.org/pdf/2507.06643v1>|提出了一种新的损失函数Crag and Tail loss，实现了从少量点标注学习密集的癌变关键点定...|
|🆕 发布|PointVDP: Learning View-Dependent Projection by Fireworks Rays for 3D Point Cloud Segmentation|点视图依赖投影学习：通过烟花射线进行三维点云分割|Yang Chen, Yueqi Duan, Haowen Sun, Ziwei Wang, Jiwen Lu, Yap-Peng Tan|<http://arxiv.org/pdf/2507.06618v1>|提出了一种动态适应视角变化的视图依赖投影方法，有效提升点云分割性能并降低计算负担。|
|🆕 发布|Divergence-Based Similarity Function for Multi-View Contrastive Learning|基于散度的多视角对比学习相似性函数|Jae Hyoung Jeon, Cheolsu Lim, Myungjoo Kang|<http://arxiv.org/pdf/2507.06560v1>|提出了一种基于分布差异的相似度函数，有效建模多视角间的联合结构并提升对比学习性能。|
|📝 更新|Geometric Constraints in Deep Learning Frameworks: A Survey|深度学习框架中的几何约束：综述|Vibhas K Vats, David J Crandall|<http://arxiv.org/pdf/2403.12431v2>|综述了几何约束在深度学习框架中的应用，并提出了新的分类法以指导未来研究。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Text-promptable Object Counting via Quantity Awareness Enhancement|通过数量感知增强的文本提示性目标计数|Miaojing Shi, Xiaowen Zhang, Zijie Yue, Yong Luo, Cairong Zhao, Li Li|<http://arxiv.org/pdf/2507.06679v1>|[代码](https://github.com/viscom-tongji/QUANet); 提出QUANet模型，通过引入数量感知的文本提示和双流解码器，提升模型对物体数量的识别能力。|
|📝 更新|DriveMRP: Enhancing Vision-Language Models with Synthetic Motion Data for Motion Risk Prediction|驱动MRP：利用合成运动数据增强视觉语言模型进行运动风险评估|Zhiyi Hou, Enhui Ma, Fang Li, Zhiyi Lai, Kalok Ho, Zhanqian Wu, Lijun Zhou, Long Chen .etc.|<http://arxiv.org/pdf/2507.02948v2>|通过合成高风险运动数据，本研究显著提升了视觉语言模型在运动风险预测方面的性能。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|From Video to EEG: Adapting Joint Embedding Predictive Architecture to Uncover Visual Concepts in Brain Signal Analysis|从视频到脑电图：调整联合嵌入预测架构以揭示视觉概念在脑信号分析中的应用|Amirabbas Hojjati, Lu Li, Ibrahim Hameed, Anis Yazidi, Pedro G. Lind, Rabindra Khadka|<http://arxiv.org/pdf/2507.03633v3>|提出EEG-VJEPA模型，利用视频处理技术分析脑电波，提升分类准确度并揭示视觉概念。|
|📝 更新|OpenThinkIMG: Learning to Think with Images via Visual Tool Reinforcement Learning|开放思考图像：通过视觉工具强化学习学会与图像一起思考|Zhaochen Su, Linjie Li, Mingyang Song, Yunzhuo Hao, Zhengyuan Yang, Jun Zhang, Guanjie Chen, Jiawei Gu .etc.|<http://arxiv.org/pdf/2505.08617v2>|提出OpenThinkIMG框架，通过视觉工具强化学习使大型视觉语言模型学会灵活使用图像进行复杂问题...|
|📝 更新|ROVER: A Multi-Season Dataset for Visual SLAM|ROVER：一个适用于视觉SLAM的多季节数据集|Fabian Schmidt, Julian Daubermann, Marcel Mitschke, Constantin Blessing, Stefan Meyer, Markus Enzweiler, Abhinav Valada|<http://arxiv.org/pdf/2412.02506v3>|[代码](https://iis-esslingen.github.io/rover.); 提出了ROVER多季节视觉SLAM数据集，为评估和改进户外复杂环境下视觉SLAM算法提供了全面基准。|
|🆕 发布|A Neural Representation Framework with LLM-Driven Spatial Reasoning for Open-Vocabulary 3D Visual Grounding|用于开放词汇三维视觉定位的LLM驱动空间推理的神经表示框架|Zhenyang Liu, Sixiao Zheng, Siyu Chen, Cairong Zhao, Longfei Liang, Xiangyang Xue, Yanwei Fu|<http://arxiv.org/pdf/2507.06719v1>|提出了一种结合大型语言模型驱动的空间推理的神经表示框架，有效提升了开放词汇3D视觉定位中空间关系的理...|
|📝 更新|Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning|多标签视觉提示微调中的相关性与判别性标签分组|LeiLei Ma, Shuo Xu, MingKun Xie, Lei Wang, Dengdi Sun, Haifeng Zhao|<http://arxiv.org/pdf/2504.09990v2>|提出了一种平衡标签相关性及区分性的多标签视觉提示调优框架，有效降低过拟合风险并提升模型性能。|
|📝 更新|Are They the Same? Exploring Visual Correspondence Shortcomings of Multimodal LLMs|它们是相同的吗？探讨多模态大型语言模型的视觉对应缺陷|Yikang Zhou, Tao Zhang, Shilin Xu, Shihao Chen, Qianyu Zhou, Yunhai Tong, Shunping Ji, Jiangning Zhang .etc.|<http://arxiv.org/pdf/2501.04670v3>|揭示了多模态大语言模型在视觉匹配上的不足，并提出了CoLVA模型及MMVM基准测试。|
|📝 更新|Animation Needs Attention: A Holistic Approach to Slides Animation Comprehension with Visual-Language Models|动画需要关注：一种结合视觉语言模型对幻灯片动画进行全面理解的方法|Yifan Jiang, Yibo Xue, Yukun Kang, Pin Zheng, Jian Peng, Feiran Wu, Changliang Xu|<http://arxiv.org/pdf/2507.03916v2>|提出首个用于幻灯片动画建模的公共数据集，并通过低秩适应提升了视觉语言模型的动画理解能力。|
|📝 更新|Refining Skewed Perceptions in Vision-Language Contrastive Models through Visual Representations|通过视觉表征精炼视觉语言对比模型中的倾斜感知|Haocheng Dai, Sarang Joshi|<http://arxiv.org/pdf/2405.14030v3>|通过视觉表示而非文本嵌入，有效纠正视觉语言对比模型中的偏差感知。|
|📝 更新|Skywork-R1V3 Technical Report|《Skywork-R1V3技术报告》|Wei Shen, Jiangbo Pei, Yi Peng, Xuchen Song, Yang Liu, Jian Peng, Haofeng Sun, Yunzhuo Hao .etc.|<http://arxiv.org/pdf/2507.06167v2>|Skywork-R1V3通过独特的后训练强化学习框架，将文本大模型的推理能力有效迁移至视觉任务，实现...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dual-Granularity Cross-Modal Identity Association for Weakly-Supervised Text-to-Person Image Matching|双粒度跨模态身份关联用于弱监督文本到人物图像匹配|Yafei Zhang, Yongle Shang, Huafeng Li|<http://arxiv.org/pdf/2507.06744v1>|提出双粒度身份关联机制，提升弱监督文本到人物图像匹配准确度。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|4KAgent: Agentic Any Image to 4K Super-Resolution|4KAgent：任意图像到4K超分辨率的代理生成模型|Yushen Zuo, Qi Zheng, Mingyang Wu, Xinrui Jiang, Renjie Li, Jian Wang, Yide Zhang, Gengchen Mai .etc.|<http://arxiv.org/pdf/2507.07105v1>|提出了一种通用型超分辨率系统4KAgent，能将任何图像升级至4K分辨率，通过定制化流程和递归优化实...|
|🆕 发布|Hallucinating 360°: Panoramic Street-View Generation via Local Scenes Diffusion and Probabilistic Prompting|通过局部场景扩散和概率提示生成全景街景：360°幻觉|Fei Teng, Kai Luo, Sheng Wu, Siyu Li, Pujun Guo, Jiale Wei, Kunyu Peng, Jiaming Zhang .etc.|<http://arxiv.org/pdf/2507.06971v1>|[代码](https://github.com/Bryant-Teng/Percep360.); 提出全景生成方法Percep360，通过局部场景扩散和概率提示实现自动驾驶中的高质量、可控全景数据生...|
|🆕 发布|FOLC-Net: A Federated-Optimized Lightweight Architecture for Enhanced MRI Disease Diagnosis across Axial, Coronal, and Sagittal Views|FOLC-Net：一种跨轴向、冠状和矢状视图增强MRI疾病诊断的联邦优化轻量级架构|Saif Ur Rehman Khan, Muhammad Nabeel Asim, Sebastian Vollmer, Andreas Dengel|<http://arxiv.org/pdf/2507.06763v1>|提出了一种优化的轻量级联邦学习框架FOLC-Net，提升不同视角MRI疾病诊断准确率。|
|🆕 发布|MADPOT: Medical Anomaly Detection with CLIP Adaptation and Partial Optimal Transport|MADPOT：基于CLIP适应与部分最优传输的医疗异常检测|Mahshid Shiri, Cigdem Beyan, Vittorio Murino|<http://arxiv.org/pdf/2507.06733v1>|[代码](https://github.com/mahshid1998/MADPOT.); 提出了一种结合视觉适配器和提示学习的方法，通过部分最优传输和对比学习增强CLIP对医学图像的适应性，...|
|🆕 发布|Omni-Fusion of Spatial and Spectral for Hyperspectral Image Segmentation|空间与光谱的全景融合在 Hyperspectral 图像分割中的应用|Qing Zhang, Guoquan Pei, Yan Wang|<http://arxiv.org/pdf/2507.06606v1>|[代码](https://github.com/DeepMed-Lab-ECNU/Omni-Fuse.); 提出了一种融合空间与光谱信息的全维度增强网络，显著提升了高光谱图像分割性能。|
|📝 更新|Medical Image Segmentation Using Advanced Unet: VMSE-Unet and VM-Unet CBAM+|使用高级Unet的医疗图像分割：VMSE-Unet和VM-Unet CBAM+|Sayandeep Kanrar, Raja Piyush, Qaiser Razi, Debanshi Chakraborty, Vikas Hassija, GSS Chalapathi|<http://arxiv.org/pdf/2507.00511v2>|集成SE和CBAM技术的VMSE-Unet模型，提升了医疗图像分割精度与效率。|
|📝 更新|Sequential Attention-based Sampling for Histopathological Analysis|序列注意力机制驱动的病理学分析采样方法|Tarun G, Naman Malpani, Gugan Thoppe, Sridharan Devarajan|<http://arxiv.org/pdf/2507.05077v2>|提出了一种基于顺序注意力的高效采样方法，用于分析病理切片，大幅降低了计算和内存成本。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|What Demands Attention in Urban Street Scenes? From Scene Understanding towards Road Safety: A Survey of Vision-driven Datasets and Studies|城市街道场景中哪些因素需要关注？从场景理解到道路安全：基于视觉的数据库和研究综述|Yaoqi Huang, Julie Stephany Berrio, Mao Shan, Stewart Worrall|<http://arxiv.org/pdf/2507.06513v1>|系统分类了城市街道场景中需关注的关键元素，并分析了相关视觉任务和数据集，为道路安全提供统一分析框架。|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EA: An Event Autoencoder for High-Speed Vision Sensing|事件自动编码器：用于高速视觉感知的事件自动编码器|Riadul Islam, Joey Mulé, Dhandeep Challagundla, Shahmir Rizvi, Sean Carson|<http://arxiv.org/pdf/2507.06459v1>|提出了一种事件自动编码器架构，有效压缩和重建事件数据，提升动态环境下的实时感知性能。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|The User-Centric Geo-Experience: An LLM-Powered Framework for Enhanced Planning, Navigation, and Dynamic Adaptation|以用户为中心的地理体验：一种基于大型语言模型的增强规划、导航与动态适应框架|Jieren Deng, Aleksandar Cvetkovic, Pak Kiu Chung, Dragomir Yankov, Chiqun Zhang|<http://arxiv.org/pdf/2507.06993v1>|提出用户中心地理体验框架，通过三个协作智能体提升旅行规划、精确导航和动态适应能力。|
|🆕 发布|MCCD: A Multi-Attribute Chinese Calligraphy Character Dataset Annotated with Script Styles, Dynasties, and Calligraphers|多属性中文书法字符数据集MCCD：带有书体、朝代和书法家标注|Yixin Zhao, Yuyi Zhang, Lianwen Jin|<http://arxiv.org/pdf/2507.06948v1>|[代码](https://github.com/SCUT-DLVCLab/MCCD.); 提出了一个包含丰富多属性标注的中文书法字符数据集MCCD，为书法识别和研究提供了宝贵资源。|
|🆕 发布|Longitudinal Study of Facial Biometrics at the BEZ: Temporal Variance Analysis|纵向研究：BEZ面部生物特征随时间变化分析|Mathias Schulz, Alexander Spenke, Pia Funk, Florian Blümel, Markus Rohde, Ralph Breithaupt, Gerd Nolden, Norbert Jung .etc.|<http://arxiv.org/pdf/2507.06858v1>|分析了长期面部生物特征变化，强调长期 controlled 测试对提高生物识别准确性的重要性。|

