## [UPDATED!] **2025-07-11** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Geo-ORBIT: A Federated Digital Twin Framework for Scene-Adaptive Lane Geometry Detection|Geo-ORBIT：一种用于场景自适应车道几何检测的联邦数字孪生框架|Rei Tamaru, Pei Li, Bin Ran|<http://arxiv.org/pdf/2507.08743v1>|[代码](https://github.com/raynbowy23/FedMeta-GeoLane.git.); 提出Geo-ORBIT框架，融合实时车道检测与联邦学习，提升交通系统数字孪生适应性和隐私保护。|
|🆕 发布|From One to More: Contextual Part Latents for 3D Generation|从一到多：用于三维生成的上下文部分潜在变量|Shaocong Dong, Lihe Ding, Xiao Chen, Yaokun Li, Yuxin Wang, Yucheng Wang, Qi Wang, Jaehyeok Kim .etc.|<http://arxiv.org/pdf/2507.08772v1>|提出了一种分解3D对象为上下文部分潜在变量的方法，增强了多部分生成和细粒度控制的准确性。|
|🆕 发布|Unreal is all you need: Multimodal ISAC Data Simulation with Only One Engine|“虚拟即是全部所需：仅用一个引擎实现多模态ISAC数据仿真”|Kongwu Huang, Shiyi Mu, Jun Jiang, Yuan Gao, Shugong Xu|<http://arxiv.org/pdf/2507.08716v1>|[代码](https://github.com/hkw-xg/Great-MCD.); 提出Great-X平台，实现单一引擎下的多模态数据高效同步模拟，构建大规模多模态感知数据集并验证算法...|
|🆕 发布|Occlusion-Guided Feature Purification Learning via Reinforced Knowledge Distillation for Occluded Person Re-Identification|遮挡引导的特征净化学习：通过强化知识蒸馏进行遮挡人物重识别|Yufei Zheng, Wenjun Wang, Wenjun Gan, Jiawei Liu|<http://arxiv.org/pdf/2507.08520v1>|提出了一种通过强化知识蒸馏进行遮挡人物重识别的方法，有效解决了遮挡场景下的特征污染问题。|
|🆕 发布|Vision Foundation Models as Effective Visual Tokenizers for Autoregressive Image Generation|视觉基础模型作为自回归图像生成的有效视觉标记器|Anlin Zheng, Xin Wen, Xuanyang Zhang, Chuofan Ma, Tiancai Wang, Gang Yu, Xiangyu Zhang, Xiaojuan Qi|<http://arxiv.org/pdf/2507.08441v1>|将预训练视觉基础模型转化为高效图像编码器，提出区域自适应量化框架和语义重建目标，显著提升图像生成质量...|
|🆕 发布|Single-Domain Generalization for Multimodal Cross-Cancer Prognosis via Dirac Rebalancer and Distribution Entanglement|通过Dirac平衡器和分布纠缠实现多模态跨癌症预后的单域泛化|Jia-Xuan Jiang, Jiashuai Liu, Hongtao Wu, Yifeng Wu, Zhong Wang, Qi Bi, Yefeng Zheng|<http://arxiv.org/pdf/2507.08340v1>|[代码](https://github.com/HopkinsKwong/MCCSDG); 提出跨癌种单域泛化任务，通过Dirac Rebalancer和分布纠缠提升多模态预后模型泛化性能。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Lumos-1: On Autoregressive Video Generation from a Unified Model Perspective|《Lumos-1：从统一模型视角论自回归视频生成》|Hangjie Yuan, Weihua Chen, Jun Cen, Hu Yu, Jingyun Liang, Shuning Chang, Zhihui Lin, Tao Feng .etc.|<http://arxiv.org/pdf/2507.08801v1>|[代码](https://github.com/alibaba-damo-academy/Lumos.); 提出了Lumos-1，一种基于统一语言模型架构的自动回归视频生成方法，通过改进模型结构和训练策略，有...|
|🆕 发布|Large Multi-modal Model Cartographic Map Comprehension for Textual Locality Georeferencing|大规模多模态模型在文本位置地理编码中的地图理解|Kalana Wijegunarathna, Kristin Stock, Christopher B. Jones|<http://arxiv.org/pdf/2507.08575v1>|利用大型多模态模型实现地图视觉理解，高效完成生物样本记录的地理编码任务。|
|🆕 发布|Advancing Multimodal LLMs by Large-Scale 3D Visual Instruction Dataset Generation|通过大规模三维视觉指令数据集生成推进多模态大型语言模型|Liu He, Xiao Zeng, Yizhi Song, Albert Y. C. Chen, Lu Xia, Shashwat Verma, Sankalp Dayal, Min Sun .etc.|<http://arxiv.org/pdf/2507.08513v1>|提出了一种生成大规模3D视觉指令数据集的方法，大幅提升了多模态大语言模型对相机-物体关系的理解能力。|
|🆕 发布|Raptor: Scalable Train-Free Embeddings for 3D Medical Volumes Leveraging Pretrained 2D Foundation Models|“Raptor：利用预训练二维基础模型的3D医学体积可扩展无训练嵌入”|Ulzee An, Moonseong Jeong, Simon A. Lee, Aditya Gorla, Yuzhe Yang, Sriram Sankararaman|<http://arxiv.org/pdf/2507.08254v1>|提出了一种无需训练的3D医疗体积数据嵌入方法Raptor，利用预训练的2D模型提取特征，降低计算复杂...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Generalizable 7T T1-map Synthesis from 1.5T and 3T T1 MRI with an Efficient Transformer Model|从1.5T和3T T1 MRI数据到通用7T T1图合成的有效Transformer模型|Zach Eidex, Mojtaba Safari, Tonghe Wang, Vanessa Wildman, David S. Yu, Hui Mao, Erik Middlebrooks, Aparna Kesewala .etc.|<http://arxiv.org/pdf/2507.08655v1>|提出了一种高效的Transformer模型，能够从1.5T或3T MRI图像合成7T质量的T1图，提...|
|📝 更新|A Decade of Deep Learning for Remote Sensing Spatiotemporal Fusion: Advances, Challenges, and Opportunities|深度学习在遥感时空融合领域的十年进展：成就、挑战与机遇|Enzhe Sun, Yongchuan Cui, Peng Liu, Jining Yan|<http://arxiv.org/pdf/2504.00901v2>|[代码](https://github.com/yc-cui/Deep-Learning-Spatiotemporal-Fusion-Survey.); 系统梳理了十年来深度学习在遥感时空融合领域的进展，揭示了不同架构的优缺点及未来发展方向。|
|📝 更新|SP$^2$T: Sparse Proxy Attention for Dual-stream Point Transformer|SP$^2$T: 双流点变换的稀疏代理注意力机制|Jiaxu Wan, Hong Zhang, Ziqi He, Yangyan Deng, Qishu Wang, Ding Yuan, Yifan Yang|<http://arxiv.org/pdf/2412.11540v2>|提出 Sparse Proxy Point Transformer，通过局部代理和双流架构优化点云处...|
|🆕 发布|F3-Net: Foundation Model for Full Abnormality Segmentation of Medical Images with Flexible Input Modality Requirement|F3-Net：面向全异常分割的医疗图像基础模型，具备灵活的输入模态要求|Seyedeh Sahar Taheri Otaghsara, Reza Rahmanzadeh|<http://arxiv.org/pdf/2507.08460v1>|F3-Net通过灵活的合成模态训练，实现了无需特定疾病微调即可进行多病种分割的医学图像基础模型。|
|🆕 发布|A document is worth a structured record: Principled inductive bias design for document recognition|一份文档等于一份结构化记录：文档识别中基于原则的归纳偏置设计|Benjamin Meyer, Lukas Tuggener, Sascha Hänzi, Daniel Schmid, Erdal Ayfer, Benjamin F. Grewe, Ahmed Abdulkadir, Thilo Stadelmann|<http://arxiv.org/pdf/2507.08458v1>|提出了一种针对文档识别的结构特定归纳偏置设计方法，有效提升了复杂文档类型的端到端转录准确性。|
|🆕 发布|MM-Gesture: Towards Precise Micro-Gesture Recognition through Multimodal Fusion|多模态融合实现精确微手势识别：MM-Gesture|Jihao Gu, Fei Wang, Kun Li, Yanyan Wei, Zhiliang Wu, Dan Guo|<http://arxiv.org/pdf/2507.08344v1>|提出了一种多模态融合框架MM-Gesture，用于精确识别微手势，通过整合多种模态信息显著提升了识别...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Quantifying Context Bias in Domain Adaptation for Object Detection|量化物体检测领域中域自适应的上下文偏差|Hojun Son, Asma Almutairi, Arpan Kusari|<http://arxiv.org/pdf/2409.14679v3>|揭示了前景-背景关联对物体检测模型跨域泛化能力的负面影响，并提出了衡量该影响的域关联梯度指标。|
|🆕 发布|OnlineBEV: Recurrent Temporal Fusion in Bird's Eye View Representations for Multi-Camera 3D Perception|在线鸟瞰图：多摄像头三维感知中鸟瞰图表示的循环时间融合|Junho Koh, Youngwoo Lee, Jungho Kim, Dongyoung Lee, Jun Won Choi|<http://arxiv.org/pdf/2507.08644v1>|提出OnlineBEV方法，通过递归结构结合鸟瞰图特征并使用运动引导网络进行特征对齐，提升多摄像头3...|
|🆕 发布|Smelly, dense, and spreaded: The Object Detection for Olfactory References (ODOR) dataset|嗅觉参照物检测数据集：气味浓烈、密集分布（Smelly, dense, and spreaded: The Object Detection for Olfactory References (ODOR) dataset）|Mathias Zinnen, Prathmesh Madhu, Inger Leemans, Peter Bell, Azhar Hussian, Hang Tran, Ali Hürriyetoğlu, Andreas Maier .etc.|<http://arxiv.org/pdf/2507.08384v1>|提出了ODOR数据集，为艺术品中的细粒度对象检测提供了丰富多样且具有挑战性的标注，推动视觉文化研究。|
|📝 更新|Hyperspectral Anomaly Detection Methods: A Survey and Comparative Study|《高光谱异常检测方法：综述与比较研究》|Aayushma Pant, Arbind Agrahari Baniya, Tsz-Kwan Lee, Sunil Aryal|<http://arxiv.org/pdf/2507.05730v2>|对比分析了各类 hyperspectral 异常检测技术，指出深度学习模型准确性最高，统计模型速度最...|
|📝 更新|Objectomaly: Objectness-Aware Refinement for OoD Segmentation with Structural Consistency and Boundary Precision|《Objectomaly：面向异常分割的对象感知细化方法，具有结构一致性和边界精度》|Jeonghoon Song, Sunghun Kim, Jaegyun Im, Byeongjoon Noh|<http://arxiv.org/pdf/2507.07460v2>|提出了一种针对异常目标检测的Objectomaly框架，通过结合物体级先验和结构一致性，显著提升了出...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DatasetAgent: A Novel Multi-Agent System for Auto-Constructing Datasets from Real-World Images|数据集构建者：一种用于从现实世界图像自动构建数据集的新型多智能体系统|Haoran Sun, Haoyu Bian, Shaoning Zeng, Yunbo Rao, Xu Xu, Lin Mei, Jianping Gou|<http://arxiv.org/pdf/2507.08648v1>|提出了一种自动构建高质量图像数据集的多代理协作系统DatasetAgent，有效解决了手动收集和标注...|
|🆕 发布|Deep Hashing with Semantic Hash Centers for Image Retrieval|基于语义哈希中心的深度哈希图像检索方法|Li Chen, Rui Liu, Yuxiang Zhou, Xudong Ma, Yong Chen, Dell Zhang|<http://arxiv.org/pdf/2507.08404v1>|提出基于语义哈希中心的三阶段框架，通过适应数据分布的相似性计算和优化算法，显著提升图像检索性能。|
|🆕 发布|Improving MLLM's Document Image Machine Translation via Synchronously Self-reviewing Its OCR Proficiency|通过同步自我评估其OCR熟练度来提高MLLM的文档图像机器翻译质量|Yupu Liang, Yaping Zhang, Zhiyang Zhang, Zhiyuan Chen, Yang Zhao, Lu Xiang, Chengqing Zong, Yu Zhou|<http://arxiv.org/pdf/2507.08309v1>|提出同步自评OCR能力的新范式，有效提升多模大语言模型在文档图像机器翻译中的性能。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Disentangling Instance and Scene Contexts for 3D Semantic Scene Completion|解耦实例和场景上下文以实现三维语义场景补全|Enyu Liu, En Yu, Sijia Chen, Wenbing Tao|<http://arxiv.org/pdf/2507.08555v1>|[代码](https://github.com/Enyu-Liu/DISC.); 提出了一种分离实例和场景上下文的新型双流范式，通过专用的解码模块和类特定查询优化3D场景语义完成。|
|📝 更新|AthletePose3D: A Benchmark Dataset for 3D Human Pose Estimation and Kinematic Validation in Athletic Movements|运动员姿态3D：一个用于三维人体姿态估计和运动学验证的体育动作基准数据集|Calvin Yeung, Tomohiro Suzuki, Ryota Tanaka, Zhuoer Yin, Keisuke Fujii|<http://arxiv.org/pdf/2503.07499v3>|[代码](https://github.com/calvinyeungck/AthletePose3D); 提出了AthletePose3D数据集，针对运动中高速度高加速度动作的3D人体姿态估计进行了优化。|
|📝 更新|EVT: Efficient View Transformation for Multi-Modal 3D Object Detection|EVT：多模态三维目标检测中的高效视图转换|Yongjin Lee, Hyeon-Mun Jeong, Yurim Jeon, Sanghyun Kim|<http://arxiv.org/pdf/2411.10715v4>|提出Efficient View Transformation框架，利用LiDAR引导优化BEV表示...|
|📝 更新|Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection|"绘制你的关键点：基于草图的少量样本关键点检测"|Subhajit Maity, Ayan Kumar Bhunia, Subhadeep Koley, Pinaki Nath Chowdhury, Aneeshan Sain, Yi-Zhe Song|<http://arxiv.org/pdf/2507.07994v2>|利用草图实现无需源数据分布匹配的少量样本关键点检测。|
|🆕 发布|Cross-Resolution SAR Target Detection Using Structural Hierarchy Adaptation and Reliable Adjacency Alignment|跨分辨率合成孔径雷达目标检测：基于结构层次适应与可靠邻接对齐方法|Jiang Qin, Bin Zou, Haolin Li, Lamei Zhang|<http://arxiv.org/pdf/2507.08290v1>|提出了一种跨分辨率SAR目标检测方法CR-Net，通过结构层次适应和可靠邻接对齐实现域自适应。|
|🆕 发布|Car Object Counting and Position Estimation via Extension of the CLIP-EBC Framework|基于CLIP-EBC框架扩展的车辆目标计数与位置估计|Seoik Jung, Taekyung Song|<http://arxiv.org/pdf/2507.08240v1>|将CLIP-EBC框架应用于车辆计数，并引入K-means聚类方法估计车辆位置。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SurfDist: Interpretable Three-Dimensional Instance Segmentation Using Curved Surface Patches|曲面距离：使用曲面块的可解释三维实例分割|Jackson Borchardt, Saul Kato|<http://arxiv.org/pdf/2507.08223v1>|提出SurfDist，一种改进的卷积神经网络架构，实现高分辨率的三维实例分割，通过平滑曲面片提高预测...|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|X-Dancer: Expressive Music to Human Dance Video Generation|《X-Dancer：表情丰富的音乐到人类舞蹈视频生成》|Zeyuan Chen, Hongyi Xu, Guoxian Song, You Xie, Chenxu Zhang, Xin Chen, Chao Wang, Di Chang .etc.|<http://arxiv.org/pdf/2502.17414v2>|提出X-Dancer，一种基于统一Transformer-Diffusion框架的零样本音乐驱动的图...|
|🆕 发布|Ensemble of Weak Spectral Total Variation Learners: a PET-CT Case Study|弱光谱总变分学习者的集成：PET-CT案例研究|Anna Rosenberg, John Kennedy, Zohar Keidar, Yehoshua Y. Zeevi, Guy Gilboa|<http://arxiv.org/pdf/2507.08735v1>|提出利用基于谱总变分特征的弱学习器集成，有效解决医学影像预测问题。|
|🆕 发布|Image Translation with Kernel Prediction Networks for Semantic Segmentation|基于核预测网络的图像翻译用于语义分割|Cristina Mata, Michael S. Ryoo, Henrik Turbell|<http://arxiv.org/pdf/2507.08554v1>|提出了一种确保语义匹配的图像翻译方法DA-KPN，通过预测像素级变换参数，有效缩小了合成数据与真实数...|
|📝 更新|Field Matching: an Electrostatic Paradigm to Generate and Transfer Data|场匹配：一种生成和传递数据的静电范式|Alexander Kolesov, Manukhov Stepan, Vladimir V. Palyulin, Alexander Korotin|<http://arxiv.org/pdf/2502.02367v2>|提出了一种基于电场模拟的数据生成与迁移方法，通过学习电场实现分布映射。|
|🆕 发布|M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning|M2-推理：赋予多模态大型语言模型统一的一般性与空间推理能力|Inclusion AI, :, Fudong Wang, Jiajia Liu, Jingdong Chen, Jun Zhou, Kaixiang Ji, Lixiang Ru .etc.|<http://arxiv.org/pdf/2507.08306v1>|提出M2-Reasoning-7B模型，结合高质量数据样本和动态多任务训练策略，提升通用与空间推理能...|
|📝 更新|KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos|关键点引导的视频中人重识别：基于部分感知表示的关键点重识别|Jinseong Kim, Junghoon Song, Gyeongseon Baek, Byeongjoon Noh|<http://arxiv.org/pdf/2507.07393v2>|提出KeyRe-ID框架，通过结合全局和局部分支以及人体关键点，提升视频行人重识别的时空表征。|
|📝 更新|Learning to Generate Vectorized Maps at Intersections with Multiple Roadside Cameras|学习使用多个路边摄像头在交叉路口生成矢量地图|Quanxin Zheng, Miao Fan, Shengtong Xu, Linghe Kong, Haoyi Xiong|<http://arxiv.org/pdf/2507.02899v3>|提出了一种利用路边摄像头生成高清矢量地图的神经网络，有效提升了复杂路口的地图构建精度和效率。|
|🆕 发布|FlowDrag: 3D-aware Drag-based Image Editing with Mesh-guided Deformation Vector Flow Fields|流拖拽：基于网格引导变形向量流场的3D感知拖拽式图像编辑|Gwanhyeong Koo, Sunjae Yoon, Younghwan Lee, Ji Woo Hong, Chang D. Yoo|<http://arxiv.org/pdf/2507.08285v1>|FlowDrag通过结合3D网格和能量函数引导变形，解决了传统拖拽编辑中的几何不一致问题，提升了编辑...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|NeuralOS: Towards Simulating Operating Systems via Neural Generative Models|神经操作系统：通过神经生成模型模拟操作系统的探索|Luke Rivard, Sun Sun, Hongyu Guo, Wenhu Chen, Yuntian Deng|<http://arxiv.org/pdf/2507.08800v1>|提出NeuralOS框架，通过预测屏幕帧模拟操作系统GUI，结合RNN和扩散式渲染提高交互准确性和状...|
|📝 更新|SpatialCrafter: Unleashing the Imagination of Video Diffusion Models for Scene Reconstruction from Limited Observations|《SpatialCrafter：从有限观测中释放视频扩散模型想象力进行场景重建》|Songchun Zhang, Huiyao Xu, Sitong Guo, Zhongwei Xie, Hujun Bao, Weiwei Xu, Changqing Zou|<http://arxiv.org/pdf/2505.11992v2>|提出 SpatialCrafter 框架，利用视频扩散模型生成额外观测，实现从稀疏或单视角输入重建逼...|
|📝 更新|Token Communications: A Unified Framework for Cross-modal Context-aware Semantic Communications|“令牌通信：一种用于跨模态上下文感知语义通信的统一框架”|Li Qiao, Mahdi Boloursaz Mashhadi, Zhen Gao, Rahim Tafazolli, Mehdi Bennis, Dusit Niyato|<http://arxiv.org/pdf/2502.12096v3>|提出了一种基于大型生成模型和跨模态语言模型的Token Communications框架，通过利用上...|
|📝 更新|MP-HSIR: A Multi-Prompt Framework for Universal Hyperspectral Image Restoration|多提示框架：用于通用高光谱图像恢复的MP-HSIR|Zhehui Wu, Yong Chen, Naoto Yokoya, Wei He|<http://arxiv.org/pdf/2503.09131v2>|[代码](https://github.com/ZhehuiWu/MP-HSIR.); 提出了一种多提示框架MP-HSIR，通过融合谱、文、视提示实现通用高光谱图像复原，有效应对多种退化类...|
|📝 更新|MGT: Extending Virtual Try-Off to Multi-Garment Scenarios|MGT：将虚拟试穿扩展到多服装场景|Riza Velioglu, Petra Bevandic, Robin Chan, Barbara Hammer|<http://arxiv.org/pdf/2504.13078v2>|[代码](https://rizavelioglu.github.io/tryoffdiff); 提出了一种多衣物虚拟脱衣模型MGT，通过特定嵌入处理不同衣物类型，提升虚拟试衣体验。|
|🆕 发布|Upsample What Matters: Region-Adaptive Latent Sampling for Accelerated Diffusion Transformers|"关注重点上采样：用于加速扩散变换器的区域自适应潜在采样"|Wongi Jeong, Kyungryeol Lee, Hoigi Seo, Se Young Chun|<http://arxiv.org/pdf/2507.08422v1>|提出了一种区域自适应的加速方法，通过在不同分辨率下智能采样，大幅提高了扩散变换器的推理速度并保持了图...|
|📝 更新|FreeScale: Unleashing the Resolution of Diffusion Models via Tuning-Free Scale Fusion|自由尺度：通过无调整尺度融合释放扩散模型的分辨率|Haonan Qiu, Shiwei Zhang, Yujie Wei, Ruihang Chu, Hangjie Yuan, Xiang Wang, Yingya Zhang, Ziwei Liu|<http://arxiv.org/pdf/2412.09626v2>|提出FreeScale方法，通过无调整的尺度融合实现更高分辨率视觉内容的生成。|
|📝 更新|GeoSplatting: Towards Geometry Guided Gaussian Splatting for Physically-based Inverse Rendering|面向几何引导的高斯绘制法在物理基础上逆向渲染的研究|Kai Ye, Chong Gao, Guanbin Li, Wenzheng Chen, Baoquan Chen|<http://arxiv.org/pdf/2410.24204v3>|[代码](https://pku-vcl-geometry.github.io/GeoSplatting); 提出GeoSplatting方法，通过显式几何引导改善光传输建模，实现精确材料分解和高效逆向渲染。|
|🆕 发布|Cycle Context Verification for In-Context Medical Image Segmentation|循环上下文验证用于上下文医疗图像分割|Shishuai Hu, Zehui Liao, Liangli Zhen, Huazhu Fu, Yong Xia|<http://arxiv.org/pdf/2507.08357v1>|[代码](https://github.com/ShishuaiHu/CCV.); 提出Cycle Context Verification框架，通过自我验证预测增强医学图像分割的上下...|
|📝 更新|Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models|视觉-语言-视觉自动编码器：从扩散模型中进行可扩展知识蒸馏|Tiezheng Zhang, Yitong Li, Yu-cheng Chou, Jieneng Chen, Alan Yuille, Chen Wei, Junfei Xiao|<http://arxiv.org/pdf/2507.07104v2>|提出了一种高效的视觉语言模型训练框架，通过知识蒸馏和预训练模型结合，大幅降低了数据需求和训练成本。|
|📝 更新|Amortized Posterior Sampling with Diffusion Prior Distillation|扩散先验蒸馏的摊销后验采样|Abbas Mammadov, Hyungjin Chung, Jong Chul Ye|<http://arxiv.org/pdf/2407.17907v2>|提出了一种无需成对训练数据、适用于多种领域的Amortized Posterior Sampling...|
|📝 更新|Single-Step Latent Diffusion for Underwater Image Restoration|单步潜在扩散 underwater 图像复原|Jiayi Wu, Tianfu Wang, Md Abu Bakr Siddique, Md Jahidul Islam, Cornelia Fermuller, Yiannis Aloimonos, Christopher A. Metzler|<http://arxiv.org/pdf/2507.07878v2>|[代码](https://tianfwang.github.io/slurpp); 提出了一种高效的单步潜在扩散算法，通过结合预训练模型和场景分解，大幅提升了水下图像恢复的速度和质量。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|InsViE-1M: Effective Instruction-based Video Editing with Elaborate Dataset Construction|基于细致数据集构建的有效指令式视频编辑：InsViE-1M|Yuhui Wu, Liyi Chen, Ruibin Li, Shihao Wang, Chenxi Xie, Lei Zhang|<http://arxiv.org/pdf/2503.20287v2>|[代码](https://github.com/langmanbusi/InsViE); 构建了高质量的大规模指令式视频编辑数据集InsViE-1M，并提出了分阶段学习策略提升编辑模型性能。|
|🆕 发布|Emergent Natural Language with Communication Games for Improving Image Captioning Capabilities without Additional Data|使用通讯游戏涌现的自然语言以提高图像标注能力而不需要额外数据|Parag Dutta, Ambedkar Dukkipati|<http://arxiv.org/pdf/2507.08610v1>|提出了一种通过多智能体强化学习游戏提升图像描述性能的方法，无需额外标注数据即可实现显著性能提升。|
|🆕 发布|Visual Semantic Description Generation with MLLMs for Image-Text Matching|基于多模态语言模型的视觉语义描述生成及其在图像-文本匹配中的应用|Junyu Chen, Yihua Gao, Mingyong Li|<http://arxiv.org/pdf/2507.08590v1>|[代码](https://github.com/Image-Text-Matching/VSD.); 提出利用多模态大语言模型作为视觉语义解析器，通过生成视觉语义描述来桥接图像和文本模态差异，提升图像文...|
|📝 更新|Lighting the Night with Generative Artificial Intelligence|用生成式人工智能照亮夜晚|Tingting Zhou, Feng Zhang, Haoyang Fu, Baoxiang Pan, Renhe Zhang, Feng Lu, Zhixin Yang|<http://arxiv.org/pdf/2506.22511v2>|本研究利用生成扩散模型，实现了夜间可见光反射率的生成，提高了气象观测和预报的连续性。|
|🆕 发布|Multi-modal Mutual-Guidance Conditional Prompt Learning for Vision-Language Models|多模态互导条件提示学习用于视觉-语言模型|Shijun Yang, Xiang Zhang, Wanqing Zhao, Hangzai Luo, Sheng Zhong, Jinye Peng, Jianping Fan|<http://arxiv.org/pdf/2507.08410v1>|提出MuGCP方法，通过多模态互导增强视觉语言模型在多任务中的泛化能力。|
|📝 更新|Hita: Holistic Tokenizer for Autoregressive Image Generation|“Hita：用于自回归图像生成的整体标记器”|Anlin Zheng, Haochen Wang, Yucheng Zhao, Weipeng Deng, Tiancai Wang, Xiangyu Zhang, Xiaojuan Qi|<http://arxiv.org/pdf/2507.02358v4>|[代码](https://github.com/CVMI-Lab/Hita); 提出了一种新的图像生成模型Hita，通过先整体后局部的编码方式，有效捕捉图像全局信息，提升生成图像质...|
|🆕 发布|Subject-Consistent and Pose-Diverse Text-to-Image Generation|主题一致性与姿态多样性文本到图像生成|Zhanxin Gao, Beier Zhu, Liang Yao, Jian Yang, Ying Tai|<http://arxiv.org/pdf/2507.08396v1>|[代码](https://github.com/NJU-PCALab/CoDi.); 提出两阶段框架CoDi，通过身份传输和身份细化实现文本到图像生成中主体一致性与姿态多样性。|
|🆕 发布|From Enhancement to Understanding: Build a Generalized Bridge for Low-light Vision via Semantically Consistent Unsupervised Fine-tuning|从增强到理解：通过语义一致的无监督微调构建低光视觉的通用桥梁|Sen Wang, Shao Zeng, Tianjun Gu, Zhizhong Zhang, Ruixin Zhang, Shouhong Ding, Jingyun Zhang, Jun Wang .etc.|<http://arxiv.org/pdf/2507.08380v1>|提出了一种结合低光增强与视觉理解的通用框架GEFU，通过语义一致性无监督微调显著提升了低光环境下图像...|
|🆕 发布|Towards Imperceptible JPEG Image Hiding: Multi-range Representations-driven Adversarial Stego Generation|面向不可感知的JPEG图像隐藏：多范围表示驱动的对抗性隐写生成|Junxue Yang, Xin Liao, Weixuan Tang, Jianhua Yang, Zheng Qin|<http://arxiv.org/pdf/2507.08343v1>|提出了一种多尺度表征驱动的对抗性隐写生成框架，有效提升了JPEG图像隐写的不可见性和秘密信息恢复能力...|
|🆕 发布|CoCo-Bot: Energy-based Composable Concept Bottlenecks for Interpretable Generative Models|CoCo-Bot：基于能量的可组合概念瓶颈，用于可解释生成模型|Sangwon Kim, In-su Jang, Pyongkun Kim, Kwang-Ju Kim|<http://arxiv.org/pdf/2507.08334v1>|提出CoCo-Bot模型，通过仅使用显式概念消除了辅助视觉线索需求，增强生成模型的控制性和可解释性。|
|🆕 发布|M2DAO-Talker: Harmonizing Multi-granular Motion Decoupling and Alternating Optimization for Talking-head Generation|M2DAO-Talker：结合多粒度运动解耦与交替优化生成说话人头像|Kui Jiang, Shiyu Liu, Junjun Jiang, Xin Yang, Hongxun Yang, Xiaopeng Fan|<http://arxiv.org/pdf/2507.08307v1>|[代码](https://m2dao-talker.github.io/M2DAO-Talk.github.io); 提出了一种多粒度运动解耦与交替优化方法，有效解决了说话人头生成中的运动模糊和局部穿透问题，实现了高质...|
|📝 更新|T-GVC: Trajectory-Guided Generative Video Coding at Ultra-Low Bitrates|T-GVC: 轨迹引导的超低比特率生成视频编码|Zhitao Wang, Hengyu Man, Wenrui Li, Xingtao Wang, Xiaopeng Fan, Debin Zhao|<http://arxiv.org/pdf/2507.07633v2>|提出了一种基于轨迹引导的生成视频编码框架，有效桥接低层运动跟踪与高层语义理解，实现超低比特率下的高质...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FonTS: Text Rendering with Typography and Style Controls|字体渲染：带有排版和风格控制的文本渲染|Wenda Shi, Yiren Song, Dengming Zhang, Jiaming Liu, Xingxing Zou|<http://arxiv.org/pdf/2412.00136v3>|提出了一种两阶段文本渲染方法，通过增强版字体和风格控制，实现了更精细的单词级排版和风格一致性。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning human-to-robot handovers through 3D scene reconstruction|通过三维场景重建学习人机手递过程|Yuekun Wu, Yik Lung Pang, Andrea Cavallaro, Changjae Oh|<http://arxiv.org/pdf/2507.08726v1>|提出了一种利用3D场景重建学习机器人交接策略的方法，无需真实机器人训练数据。|
|📝 更新|MonoMobility: Zero-Shot 3D Mobility Analysis from Monocular Videos|单目视频中的零样本三维移动性分析：MonoMobility|Hongyi Zhou, Yulan Guo, Xiaogang Wang, Kai Xu|<http://arxiv.org/pdf/2505.11868v3>|提出了一种无需标注数据即可从单目视频中分析三维移动性的创新框架。|
|🆕 发布|Review of Feed-forward 3D Reconstruction: From DUSt3R to VGGT|前馈三维重建综述：从DUSt3R到VGGT|Wei Zhang, Yihang Wu, Songhua Li, Wenjie Ma, Xin Ma, Qiang Li, Qi Wang|<http://arxiv.org/pdf/2507.08448v1>|定位并综述了基于深度学习的 feed-forward 3D 重构方法，实现单次前向传播直接从图像中推...|
|🆕 发布|Dual Dimensions Geometric Representation Learning Based Document Dewarping|基于双维度几何表示学习的文档去弯曲|Heng Li, Qingcai Chen, Xiangping Wu|<http://arxiv.org/pdf/2507.08492v1>|[代码](https://github.com/xiaomore/DocDewarpHV); 提出了一种双维度几何表征学习模型D2Dewarp，通过同时考虑文档的水平和垂直线条，有效改善了文档图...|
|🆕 发布|InstaScene: Towards Complete 3D Instance Decomposition and Reconstruction from Cluttered Scenes|面向杂乱场景的完整三维实例分解与重建：InstaScene|Zesong Yang, Bangbang Yang, Wenqi Dong, Chenxuan Cao, Liyuan Cui, Yuewen Ma, Zhaopeng Cui, Hujun Bao|<http://arxiv.org/pdf/2507.08416v1>|提出InstaScene方法，通过空间对比学习和在位生成技术，实现对复杂场景中任意实例的完整分解与重...|
|🆕 发布|CL3R: 3D Reconstruction and Contrastive Learning for Enhanced Robotic Manipulation Representations|CL3R：用于增强机器人操作表示的三维重建与对比学习|Wenbo Cui, Chengyang Zhao, Yuhui Chen, Haoran Li, Zhizheng Zhang, Dongbin Zhao, He Wang|<http://arxiv.org/pdf/2507.08262v1>|提出CL3R框架，通过3D重建和对比学习提升机器人操作的表现，增强空间感知和语义理解。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SEREP: Semantic Facial Expression Representation for Robust In-the-Wild Capture and Retargeting|SEREP：用于野外捕获和重定向的鲁棒性语义面部表情表示|Arthur Josi, Luiz Gustavo Hafemann, Abdallah Dib, Emeline Got, Rafael M. O. Cruz, Marc-Andre Carbonneau|<http://arxiv.org/pdf/2412.14371v3>|提出SEREP模型，通过语义层面解耦表情与身份，有效提升野外单目面部表情捕捉与重定向的鲁棒性。|
|📝 更新|Spline Deformation Field|样条变形场|Mingyang Song, Yang Zhang, Marko Mihajlovic, Siyu Tang, Markus Gross, Tunç Ozan Aydın|<http://arxiv.org/pdf/2507.07521v2>|提出了一种基于样条曲线的轨迹表示方法，有效解决了神经网络固有偏差问题，并提高了时空信号插值性能。|
|🆕 发布|RePaintGS: Reference-Guided Gaussian Splatting for Realistic and View-Consistent 3D Scene Inpainting|RePaintGS：基于参考引导的高斯散点绘制实现真实感和视点一致的三维场景修复|Ji Hyun Seo, Byounhyun Yoo, Gerard Jounghyun Kim|<http://arxiv.org/pdf/2507.08434v1>|提出了一种利用参考视图生成真实且视点一致的三维场景修复方法，解决了多视角不一致和细节丢失问题。|
|📝 更新|Improvement of Spiking Neural Network with Bit Planes and Color Models|基于比特平面和颜色模型的尖峰神经网络改进|Nhan T. Luu, Duong T. Luu, Nam N. Pham, Thang C. Truong|<http://arxiv.org/pdf/2410.08229v3>|提出了一种利用比特平面编码和颜色模型提升脉冲神经网络图像处理性能的方法。|
|🆕 发布|Cross-Domain Identity Representation for Skull to Face Matching with Benchmark DataSet|跨域身份表征：基于基准数据集的头骨到面部匹配|Ravi Shankar Prasad, Dinesh Singh|<http://arxiv.org/pdf/2507.08329v1>|提出了一种使用卷积Siamese网络的跨域身份表征框架，有效实现了头骨X光图像与面部图像的匹配识别。|


## 时序视觉分析 (Temporal Visual Analysis)


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GoalNet: Goal Areas Oriented Pedestrian Trajectory Prediction|目标区域导向的行人轨迹预测：GoalNet|Amar Fadillah, Ching-Lin Lee, Zhi-Xuan Wang, Kuan-Ting Lai|<http://arxiv.org/pdf/2402.19002v2>|提出基于目标区域预测行人轨迹的方法，通过利用场景上下文信息，显著提升了预测准确度。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RoundaboutHD: High-Resolution Real-World Urban Environment Benchmark for Multi-Camera Vehicle Tracking|《RoundaboutHD：用于多摄像头车辆跟踪的高分辨率现实世界城市环境基准》|Yuqiang Lin, Sam Lockyer, Mingxuan Sui, Li Gan, Florian Stanek, Markus Zarbock, Wenbin Li, Adrian Evans .etc.|<http://arxiv.org/pdf/2507.08729v1>|[代码](https://github.com/siri-rouser/RoundaboutHD.git); 提出了RoundaboutHD，一个高分辨率多摄像头车辆追踪基准数据集，以填补现实世界场景与学术研究...|
|🆕 发布|Unified People Tracking with Graph Neural Networks|统一使用图神经网络进行行人跟踪|Martin Engilberge, Ivan Vrkic, Friedrich Wilke Grosche, Julien Pilet, Engin Turetken, Pascal Fua|<http://arxiv.org/pdf/2507.08494v1>|提出了一种统一的基于图神经网络的多人物跟踪模型，无需预计算轨迹即可关联检测结果，实现了跨序列的信息传...|
|🆕 发布|Unsupervised Methods for Video Quality Improvement: A Survey of Restoration and Enhancement Techniques|无监督视频质量提升方法：恢复与增强技术的综述|Alexandra Malyugina, Yini Li, Joanne Lin, Nantheera Anantrasirichai|<http://arxiv.org/pdf/2507.08375v1>|系统梳理了无监督视频质量和增强技术，分类探讨了不同方法及其在提升视觉质量和预处理中的应用。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|USAD: End-to-End Human Activity Recognition via Diffusion Model with Spatiotemporal Attention|USAD：基于时空注意力扩散模型的端到端人体行为识别|Hang Xiao, Ying Yu, Jiarui Li, Zhifan Yang, Haotian Tang, Hanyu Liu, Chao Li|<http://arxiv.org/pdf/2507.02827v2>|提出了一种基于无监督数据增强和时空注意力的扩散网络，有效解决了数据稀缺和模型性能问题。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Compress Any Segment Anything Model (SAM)|任意压缩片段任意模型（SAM）|Juntong Fan, Zhiwei Hao, Jianqiang Shen, Shang-Ling Jui, Yi Zhang, Jing-Xiao Liao, Feng-Lei Fan|<http://arxiv.org/pdf/2507.08765v1>|提出无数据压缩算法Birkhoff，高效压缩Segment Anything模型，保持性能且加速推理...|
|🆕 发布|CLiFT: Compressive Light-Field Tokens for Compute-Efficient and Adaptive Neural Rendering|CLiFT：用于计算高效和自适应神经渲染的压缩光场标记|Zhengqing Wang, Yuefan Wu, Jiacheng Chen, Fuyang Zhang, Yasutaka Furukawa|<http://arxiv.org/pdf/2507.08776v1>|提出了一种压缩光场标记的神经渲染方法，通过调整标记数量实现计算效率与渲染质量的平衡。|
|🆕 发布|An Efficient Approach for Muscle Segmentation and 3D Reconstruction Using Keypoint Tracking in MRI Scan|基于关键点追踪的磁共振成像肌肉分割与三维重建高效方法|Mengyuan Liu, Jeongkyu Lee|<http://arxiv.org/pdf/2507.08690v1>|提出了一种无需训练、基于关键点追踪的肌肉分割方法，降低了计算需求并提高了可解释性。|
|📝 更新|EBAD-Gaussian: Event-driven Bundle Adjusted Deblur Gaussian Splatting|基于事件驱动的束调整去模糊高斯喷射算法（EBAD-Gaussian: Event-driven Bundle Adjusted Deblur Gaussian Splatting）|Yufei Deng, Yuanjian Wang, Rong Xiao, Chenwei Tang, Jizhe Zhou, Jiahao Fan, Deng Xiong, Jiancheng Lv .etc.|<http://arxiv.org/pdf/2504.10012v2>|提出了一种结合事件相机和图像去模糊技术的EBAD-Gaussian方法，有效提升了运动模糊条件下的3...|
|🆕 发布|Portable Biomechanics Laboratory: Clinically Accessible Movement Analysis from a Handheld Smartphone|便携式生物力学实验室：从手持智能手机进行临床可用的运动分析|J. D. Peiffer, Kunal Shah, Irina Djuraskovic, Shawana Anarwala, Kayan Abdou, Rujvee Patel, Prakash Jayabalan, Brenton Pennicooke .etc.|<http://arxiv.org/pdf/2507.08268v1>|[代码](https://intelligentsensingandrehabilitation.github.io/MonocularBiomechanics); 提出了一种基于智能手机视频的便携式生物力学实验室，实现了临床可用的全身运动分析。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Hybrid Multi-Well Hopfield-CNN with Feature Extraction and K-Means for MNIST Classification|一种融合多井Hopfield-CNN与特征提取及K-均值算法的MNIST分类器|Ahmed Farooq|<http://arxiv.org/pdf/2507.08766v1>|结合卷积神经网络特征提取与Hopfield网络分类的混合模型，有效提升了MNIST数据集手写数字识别...|
|📝 更新|DArFace: Deformation Aware Robustness for Low Quality Face Recognition|《DArFace：面向低质量人脸识别的形变感知鲁棒性》|Sadaf Gulshad, Abdullah Aldahlawi Thakaa|<http://arxiv.org/pdf/2505.08423v3>|提出DArFace框架，通过模拟全局和局部形变提升低质量人脸识别的鲁棒性。|
|📝 更新|Computationally Efficient Information-Driven Optical Design with Interchanging Optimization|计算效率化的信息驱动光学设计及交互优化方法|Eric Markley, Henry Pinkard, Leyla Kabuli, Nalini Singh, Laura Waller|<http://arxiv.org/pdf/2507.07789v2>|提出IDEAL-IO方法，通过交替优化模型拟合与光学参数更新，降低计算负担并提升成像系统设计质量。|
|📝 更新|Curriculum Dataset Distillation|课程数据集蒸馏|Zhiheng Ma, Anjia Cao, Funing Yang, Yihong Gong, Xing Wei|<http://arxiv.org/pdf/2405.09150v2>|[代码](https://github.com/MIV-XJTU/CUDD.); 提出了一种基于课程的图像数据集压缩方法，通过逐步处理从简单到复杂的图像，有效提升了大规模数据集的压缩...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BayesTTA: Continual-Temporal Test-Time Adaptation for Vision-Language Models via Gaussian Discriminant Analysis|贝叶斯TTA：通过高斯判别分析实现视觉语言模型的持续-时间测试时适应|Shuang Cui, Jinglin Xu, Yi Li, Xiongxin Tang, Jiangmeng Li, Jiahuan Zhou, Fanjiang Xu, Fuchun Sun .etc.|<http://arxiv.org/pdf/2507.08607v1>|[代码](https://github.com/cuishuang99/BayesTTA); 提出了一种针对视觉语言模型在时间演变分布偏移下的持续时序测试时适应方法BayesTTA，通过贝叶斯框...|
|🆕 发布|SAM2RL: Towards Reinforcement Learning Memory Control in Segment Anything Model 2|SAM2RL：面向Segment Anything模型2的强化学习内存控制|Alen Adamyan, Tomáš Čížek, Matej Straka, Klara Janouskova, Martin Schmid|<http://arxiv.org/pdf/2507.08548v1>|利用强化学习优化SAM2的记忆更新，大幅提升视觉对象跟踪性能。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SGPMIL: Sparse Gaussian Process Multiple Instance Learning|稀疏高斯过程多实例学习（SGPMIL）|Andreas Lolos, Stergios Christodoulidis, Maria Vakalopoulou, Jose Dolz, Aris Moustakas|<http://arxiv.org/pdf/2507.08711v1>|提出SGPMIL方法，通过稀疏高斯过程为多实例学习提供不确定性量化，提升实例级预测的可靠性和校准度。|


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Sim-to-Real: An Unsupervised Noise Layer for Screen-Camera Watermarking Robustness|从仿真到现实：一种用于屏幕-相机水印稳健性的无监督噪声层|Yufeng Wu, Xin Liao, Baowei Wang, Han Fang, Xiaoshuai Wu, Guiling Wang|<http://arxiv.org/pdf/2504.18906v2>|提出了一种无监督噪声层方法S2R，通过学习模拟噪声与真实屏幕摄像头噪声的分布差异，提高了水印的鲁棒性...|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025|《推动安全极限：ATLAS挑战2025技术报告》|Zonghao Ying, Siyang Wu, Run Hao, Peng Ying, Shixuan Sun, Pengyu Chen, Junze Chen, Hao Du .etc.|<http://arxiv.org/pdf/2506.12430v2>|[代码](https://github.com/NY1024/ATLAS_Challenge_2025.); 提出ATLAS挑战，通过对抗性攻击测试提升大型多模态语言模型的安全性。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PanMatch: Unleashing the Potential of Large Vision Models for Unified Matching Models|PanMatch：释放大型视觉模型在统一匹配模型中的潜力|Yongjian Zhang, Longguang Wang, Kunhong Li, Ye Zhang, Yun Wang, Liang Lin, Yulan Guo|<http://arxiv.org/pdf/2507.08400v1>|PanMatch通过通用模型和特征转换，实现了多任务匹配的零样本泛化能力。|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Embedding Space Allocation with Angle-Norm Joint Classifiers for Few-Shot Class-Incremental Learning|角度范数联合分类器的嵌入空间分配用于少量样本的新类增量学习|Dunwei Tu, Huiyu Yi, Tieyi Zhang, Ruotong Li, Furao Shen, Jian Zhao|<http://arxiv.org/pdf/2411.09250v2>|提出SAAN框架，通过划分特征子空间和角度-范数联合分类器解决少量样本增量学习中的空间分配和样本不平...|
|🆕 发布|Transfer Learning and Mixup for Fine-Grained Few-Shot Fungi Classification|迁移学习与Mixup方法在细粒度少量样本真菌分类中的应用|Jason Kahei Tam, Murilo Gustineli, Anthony Miyaguchi|<http://arxiv.org/pdf/2507.08248v1>|[代码](https://github.com/dsgt-arc/fungiclef-2025.); 提出了一种针对细粒度真菌分类的少量样本学习方法，通过特定领域预训练和平衡采样策略提高了识别准确性。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Synergistic Prompting for Robust Visual Recognition with Missing Modalities|协同提示以实现缺失模态下的稳健视觉识别|Zhihui Zhang, Luanyuan Dai, Qika Lin, Yunfeng Diao, Guangyin Jin, Yufei Guo, Jing Zhang, Xiaoshuai Hao|<http://arxiv.org/pdf/2507.07802v2>|提出动态适配器与协同提示策略，提升缺失模态下的视觉识别鲁棒性。|
|📝 更新|ViLU: Learning Vision-Language Uncertainties for Failure Prediction|ViLU：学习视觉-语言不确定性以预测失败|Marc Lafon, Yannis Karmim, Julio Silva-Rodríguez, Paul Couairon, Clément Rambour, Raphaël Fournier-Sniehotta, Ismail Ben Ayed, Jose Dolz .etc.|<http://arxiv.org/pdf/2507.07620v2>|[代码](https://github.com/ykrmm/ViLU.); 提出ViLU框架，通过结合文本和视觉信息，有效预测视觉语言模型的不确定性和错误，提升失败预测准确性。|
|📝 更新|GTR: Guided Thought Reinforcement Prevents Thought Collapse in RL-based VLM Agent Training|GTR：引导思维强化防止基于RL的VLM智能体训练中的思维崩溃|Tong Wei, Yijun Yang, Junliang Xing, Yuanchun Shi, Zongqing Lu, Deheng Ye|<http://arxiv.org/pdf/2503.08525v2>|提出方法GTR防止视觉语言模型训练中的思维崩溃，提升任务成功率3-5倍。|
|📝 更新|Visual and Textual Prompts in VLLMs for Enhancing Emotion Recognition|视觉和文本提示在大型视觉语言模型中增强情感识别的应用|Zhifeng Wang, Qixuan Zhang, Peter Zhang, Wenjia Niu, Kaihao Zhang, Ramesh Sankaranarayana, Sabrina Caldwell, Tom Gedeon|<http://arxiv.org/pdf/2504.17224v3>|提出SoVTP框架，通过融合视觉和文本提示增强VLLM对视频情感识别的准确性和鲁棒性。|
|📝 更新|Entity Re-identification in Visual Storytelling via Contrastive Reinforcement Learning|通过对比强化学习进行视觉故事讲述中的实体重识别|Daniel A. P. Oliveira, David Martins de Matos|<http://arxiv.org/pdf/2507.07340v2>|通过对比强化学习训练模型区分故事连贯性，有效提升了视觉叙事系统中实体跨帧识别的一致性。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|L-CLIPScore: a Lightweight Embedding-based Captioning Metric for Evaluating and Training|L-CLIPScore：一种轻量级基于嵌入的评论文本生成评价指标用于评估与训练|Li Li, Yingzhe Peng, Xu Yang, Ruoxi Cheng, Haiyang Xu, Ming Yan, Fei Huang|<http://arxiv.org/pdf/2507.08710v1>|提出了一种轻量级嵌入式评分指标L-CLIPScore，用于高效评估和训练图像描述模型。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HieraRS: A Hierarchical Segmentation Paradigm for Remote Sensing Enabling Multi-Granularity Interpretation and Cross-Domain Transfer|层次化遥感分割范式HieraRS：实现多粒度解释与跨域迁移|Tianlong Ai, Tianzhu Liu, Haochen Jiang, Yanfeng Gu|<http://arxiv.org/pdf/2507.08741v1>|[代码](https://github.com/AI-Tianlong/HieraRS.); 提出了一种分层解释范式HieraRS，实现多粒度预测并支持跨域任务中的异构层次转移。|
|🆕 发布|MoSAiC: Multi-Modal Multi-Label Supervision-Aware Contrastive Learning for Remote Sensing|MoSAiC:面向遥感的多模态多标签监督感知对比学习|Debashis Gupta, Aditi Golder, Rongkhun Zhu, Kangning Cui, Wei Tang, Fan Yang, Ovidiu Csillik, Sarra Alaqahtani .etc.|<http://arxiv.org/pdf/2507.08683v1>|提出了一种多模态多标签监督感知对比学习框架MoSAiC，有效应对遥感数据的高相似性和复杂性挑战。|
|📝 更新|DriveTransformer: Unified Transformer for Scalable End-to-End Autonomous Driving|驱动变压器：用于可扩展端到端自动驾驶的统一变压器|Xiaosong Jia, Junqi You, Zhiyuan Zhang, Junchi Yan|<http://arxiv.org/pdf/2503.07656v2>|提出DriveTransformer框架，通过任务并行、稀疏表示和流式处理，解决了端到端自动驾驶系统...|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Multi-Modal Fusion Framework for Brain Tumor Segmentation Based on 3D Spatial-Language-Vision Integration and Bidirectional Interactive Attention Mechanism|基于三维空间-语言-视觉融合与双向交互注意力机制的脑肿瘤分割多模态融合框架|Mingda Zhang, Kaiwen Pan|<http://arxiv.org/pdf/2507.08574v1>|提出了一种融合空间-语言-视觉信息的多模态脑肿瘤分割框架，通过双向互动注意力机制提升分割精度和边界描...|
|📝 更新|MedSegFactory: Text-Guided Generation of Medical Image-Mask Pairs|MedSegFactory：文本引导的医学图像-掩膜对生成|Jiawei Mao, Yuhan Wang, Yucheng Tang, Daguang Xu, Kang Wang, Yang Yang, Zongwei Zhou, Yuyin Zhou|<http://arxiv.org/pdf/2504.06897v2>|提出MedSegFactory框架，通过双向互动生成高质量医疗图像与分割掩码对，解决数据稀缺问题。|
|🆕 发布|RadiomicsRetrieval: A Customizable Framework for Medical Image Retrieval Using Radiomics Features|放射组学检索：一种利用放射组学特征进行医学图像检索的可定制框架|Inye Na, Nejung Rue, Jiwon Chung, Hyunjin Park|<http://arxiv.org/pdf/2507.08546v1>|[代码](https://github.com/nainye/RadiomicsRetrieval.); 提出了一种3D医疗图像检索框架，通过结合深度学习和放射学特征，实现了基于少量提示的高效检索。|
|📝 更新|Average Calibration Losses for Reliable Uncertainty in Medical Image Segmentation|可靠的医学图像分割不确定性估计的平均校准损失|Theodore Barfoot, Luis C. Garcia-Peraza-Herrera, Samet Akcay, Ben Glocker, Tom Vercauteren|<http://arxiv.org/pdf/2506.03942v2>|[代码](https://github.com/cai4cai/Average-Calibration-Losses); 提出了一种基于mL1-ACE的辅助损失函数，有效降低了医疗图像分割中的过拟合自信度问题，提高了预测的...|
|📝 更新|Average Calibration Error: A Differentiable Loss for Improved Reliability in Image Segmentation|平均校准误差：一种用于提高图像分割可靠性的可微分损失函数|Theodore Barfoot, Luis Garcia-Peraza-Herrera, Ben Glocker, Tom Vercauteren|<http://arxiv.org/pdf/2403.06759v3>|[代码](https://github.com/cai4cai/ACE-DLIRIS); 提出了一种新的损失函数mL1-ACE，有效改善医学图像分割的可靠性而不牺牲分割质量。|
|📝 更新|Understanding Dataset Bias in Medical Imaging: A Case Study on Chest X-rays|《理解医学成像数据集偏差：以胸部X射线为案例研究》|Ethan Dack, Chengliang Dai|<http://arxiv.org/pdf/2507.07722v2>|[代码](https://github.com/eedack01/x_ray_ds_bias.); 揭示了医学影像数据集中的偏见，并通过多种网络架构分析提出减少偏差的方法。|
|🆕 发布|Understanding Driving Risks using Large Language Models: Toward Elderly Driver Assessment|利用大型语言模型理解驾驶风险：面向老年驾驶员评估|Yuki Yoshihara, Linjing Jiang, Nihan Karatas, Hitoshi Kanamori, Asuka Harada, Takahiro Tanaka|<http://arxiv.org/pdf/2507.08367v1>|探究大语言模型对交通场景的解读能力，辅助评估老年驾驶员风险。|
|🆕 发布|Interpretability-Aware Pruning for Efficient Medical Image Analysis|面向解释性的高效医学图像分析剪枝方法|Nikita Malik, Pratinav Seth, Neeraj Kumar Singh, Chintan Chitroda, Vinay Kumar Sankarapu|<http://arxiv.org/pdf/2507.08330v1>|提出了一种基于可解释性的剪枝框架，实现了医疗图像分析模型的压缩与性能保持。|
|📝 更新|ClinKD: Cross-Modal Clinical Knowledge Distiller For Multi-Task Medical Images|ClinKD：面向多任务医学图像的跨模态临床知识蒸馏器|Hongyu Ge, Longkun Hao, Zihui Xu, Zhenxin Lin, Bin Li, Shoujun Zhou, Hongjin Zhao, Yihang Liu|<http://arxiv.org/pdf/2502.05928v4>|[代码](https://github.com/overloadedHenry/ClinKD.); 提出ClinKD框架，通过增强图像文本对齐和医学知识转化机制，提升多任务医学图像问答性能。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SDR-GAIN: A High Real-Time Occluded Pedestrian Pose Completion Method for Autonomous Driving|SDR-GAIN：一种面向自动驾驶的高实时性遮挡行人姿态补全方法|Honghao Fu, Yongli Gu, Yidong Yan, Yilang Shen, Yiwen Wu, Libo Sun|<http://arxiv.org/pdf/2306.03538v5>|提出了一种实时遮挡行人姿态补全方法SDR-GAIN，通过学习关键点坐标分布直接插补缺失位置，实现了高...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Normalized vs Diplomatic Annotation: A Case Study of Automatic Information Extraction from Handwritten Uruguayan Birth Certificates|归一化标注与外交标注之比较：手写乌拉圭出生证明自动信息提取的案例研究|Natalia Bottaioli, Solène Tarride, Jérémy Anger, Seginus Mowlavi, Marina Gardella, Antoine Tadros, Gabriele Facciolo, Rafael Grompone von Gioi .etc.|<http://arxiv.org/pdf/2507.08636v1>|研究了两种标注策略对提取手写文件信息的影响，发现标准化标注对可标准化字段更有效，而外交标注对不可标准...|
|🆕 发布|ByDeWay: Boost Your multimodal LLM with DEpth prompting in a Training-Free Way|《ByDeWay：以无需训练的方式通过深度提示增强您的多模态大型语言模型》|Rajarshi Roy, Devleena Das, Ankesh Banerjee, Arjya Bhattacharjee, Kousik Dasgupta, Subarna Tripathi|<http://arxiv.org/pdf/2507.08679v1>|提出了一种无需训练的深度提示框架ByDeWay，通过分层深度提示增强多模态大语言模型的性能。|

