## [UPDATED!] **2025-07-12** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MedGemma Technical Report|《MedGemma技术报告》|Andrew Sellergren, Sahar Kazemzadeh, Tiam Jaroensri, Atilla Kiraly, Madeleine Traverse, Timo Kohlberger, Shawn Xu, Fayaz Jamil .etc.|<http://arxiv.org/pdf/2507.05201v3>|提出MedGemma医疗视觉语言模型，提升医疗任务理解和推理能力，减少特定任务训练数据需求。|
|📝 更新|Pisces: An Auto-regressive Foundation Model for Image Understanding and Generation|双鱼座：一种用于图像理解和生成的自回归基础模型|Zhiyang Xu, Jiuhai Chen, Zhaojiang Lin, Xichen Pan, Lifu Huang, Tianyi Zhou, Madian Khabsa, Qifan Wang .etc.|<http://arxiv.org/pdf/2506.10395v2>|提出了一种解耦视觉编码架构的自动回归多模态基础模型Pisces，优化了图像理解和生成性能。|
|🆕 发布|Online Long-term Point Tracking in the Foundation Model Era|在线长期点跟踪：基础模型时代的方法|Görkay Aydemir|<http://arxiv.org/pdf/2507.09217v1>|提出在线长时点追踪方法Track-On，利用视觉基础模型增强空间特征，无需未来帧信息实现跟踪。|
|📝 更新|Many-for-Many: Unify the Training of Multiple Video and Image Generation and Manipulation Tasks|多对多：统一多个视频和图像生成与操作任务的训练|Tao Yang, Ruibin Li, Yangming Shi, Yuqi Zhang, Qide Dong, Haoran Cheng, Weiguo Feng, Shilei Wen .etc.|<http://arxiv.org/pdf/2506.01758v2>|[代码](https://github.com/leeruibin/MfM.git.); 提出了一种统一训练框架，通过多任务数据训练单一模型，提升视频生成性能并支持多种视觉任务。|
|📝 更新|MSVD-Indonesian: A Benchmark for Multimodal Video-Text Tasks in Indonesian|MSVD-Indonesian：印度尼西亚语多模态视频-文本任务的基准数据集|Willy Fitra Hendria|<http://arxiv.org/pdf/2306.11341v2>|介绍了首个公开的印度尼西亚语视频文本数据集，并通过跨语言迁移学习提升了多模态任务性能。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Simplifying Traffic Anomaly Detection with Video Foundation Models|利用视频基础模型简化交通异常检测|Svetlana Orlova, Tommie Kerssies, Brunó B. Englert, Gijs Dubbelman|<http://arxiv.org/pdf/2507.09338v1>|[代码](https://github.com/tue-mps/simple-tad.); 利用视频基础模型简化交通异常检测，通过预训练实现高效准确性能。|
|🆕 发布|Calibrated and Robust Foundation Models for Vision-Language and Medical Image Tasks Under Distribution Shift|分布偏移下视觉语言和医学图像任务的校准与鲁棒基础模型|Behraj Khan, Tahir Syed|<http://arxiv.org/pdf/2507.09222v1>|提出StaRFM框架，通过Fisher信息惩罚和置信度错位惩罚，有效应对视觉语言和医学图像任务中的分...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Novel Streamline-based diffusion MRI Tractography Registration Method with Probabilistic Keypoint Detection|一种基于流线的新型扩散MRI轨迹配准方法与概率关键点检测|Junyi Wang, Mubai Du, Ye Wu, Yijie Li, William M. Wells III, Lauren J. O'Donnell, Fan Zhang|<http://arxiv.org/pdf/2503.02481v2>|提出了一种基于深度学习的无监督方法，通过检测概率性关键点对实现扩散MRI轨迹图的精确空间对齐。|
|📝 更新|EECD-Net: Energy-Efficient Crack Detection with Spiking Neural Networks and Gated Attention|EECD-Net：基于尖峰神经网络和门控注意力的节能裂缝检测网络|Shuo Zhang|<http://arxiv.org/pdf/2506.04526v2>|提出了一种高效的路面裂缝检测方法EECD-Net，通过结合脉冲神经网络和注意力机制，实现了高准确性与...|
|📝 更新|HA-RDet: Hybrid Anchor Rotation Detector for Oriented Object Detection|HA-RDet：混合锚点旋转检测器用于定向目标检测|Phuc D. A. Nguyen|<http://arxiv.org/pdf/2412.14379v2>|提出HA-RDet方法，结合锚框和无需锚框的优势，提高旋转目标检测准确度同时降低计算资源消耗。|
|🆕 发布|PoseLLM: Enhancing Language-Guided Human Pose Estimation with MLP Alignment|姿态LLM：通过MLP对齐增强语言引导的人体姿态估计|Dewen Zhang, Tahir Hussain, Wangpeng An, Hayaru Shouno|<http://arxiv.org/pdf/2507.09139v1>|[代码](https://github.com/Ody-trek/PoseLLM.); 提出了一种基于大型语言模型和多层感知器的语言引导人体姿态估计方法，提高了定位精度并保持了零样本泛化能...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SAGE: Segment-Aware Gloss-Free Encoding for Token-Efficient Sign Language Translation|SAGE：面向分段感知的无光泽编码，实现高效符号语言翻译的标记效率|JianHe Low, Ozge Mercanoglu Sincan, Richard Bowden|<http://arxiv.org/pdf/2507.09266v1>|提出一种视觉符号化框架，通过分割手势减少输入序列长度，实现高效的签字语言翻译。|
|🆕 发布|360-Degree Full-view Image Segmentation by Spherical Convolution compatible with Large-scale Planar Pre-trained Models|球面卷积兼容的大规模平面预训练模型的360度全视角图像分割|Jingguo Liu, Han Yu, Shigang Li, Jianfeng Li|<http://arxiv.org/pdf/2507.09216v1>|提出了一种球形卷积方法，使二维预训练模型能直接用于全景图像分割，有效减少图像畸变。|
|📝 更新|Colorectal Cancer Tumor Grade Segmentation in Digital Histopathology Images: From Giga to Mini Challenge|数字病理图像中结直肠癌肿瘤分级分割：从Giga到Mini挑战|Alper Bahcekapili, Duygu Arslan, Umut Ozdemir, Berkay Ozkirli, Emre Akbas, Ahmet Acar, Gozde B. Akar, Bingdou He .etc.|<http://arxiv.org/pdf/2507.04681v2>|推动了结直肠癌组织分级自动化分割技术，通过挑战赛汇集创新方法超越传统基准。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ViT-ProtoNet for Few-Shot Image Classification: A Multi-Benchmark Evaluation|ViT-ProtoNet 用于少样本图像分类：多基准评估|Abdulvahap Mutlu, Şengül Doğan, Türker Tuncer|<http://arxiv.org/pdf/2507.09299v1>|提出ViT-ProtoNet方法，将Vision Transformers与原型网络结合，提升少量样...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RoHOI: Robustness Benchmark for Human-Object Interaction Detection|RoHOI：用于人类-物体交互检测的鲁棒性基准|Di Wen, Kunyu Peng, Kailun Yang, Yufan Chen, Ruiping Liu, Junwei Zheng, Alina Roitberg, Rainer Stiefelhagen|<http://arxiv.org/pdf/2507.09111v1>|[代码](https://github.com/Kratos-Wen/RoHOI.); 提出首个针对人-物交互检测的鲁棒性基准RoHOI，并提出SAMPL策略增强模型鲁棒性。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MPG-SAM 2: Adapting SAM 2 with Mask Priors and Global Context for Referring Video Object Segmentation|MPG-SAM 2：利用掩膜先验和全局上下文适应SAM 2进行视频目标分割|Fu Rong, Meng Lan, Qian Zhang, Lefei Zhang|<http://arxiv.org/pdf/2501.13667v4>|[代码](https://github.com/rongfu-dsb/MPG-SAM2.); 提出MPG-SAM 2框架，融合掩膜先验和全局上下文，提升视频对象分割的准确性和一致性。|
|🆕 发布|Prompt4Trust: A Reinforcement Learning Prompt Augmentation Framework for Clinically-Aligned Confidence Calibration in Multimodal Large Language Models|Prompt4Trust：面向临床对齐置信度校准的多模态大规模语言模型强化学习提示增强框架|Anita Kriz, Elizabeth Laura Janes, Xing Shen, Tal Arbel|<http://arxiv.org/pdf/2507.09279v1>|[代码](https://github.com/xingbpshen/vccrl-llm.); Prompt4Trust通过强化学习框架优化提示设计，提升多模态大语言模型在医疗应用中的准确性与可信...|
|🆕 发布|Generative Latent Kernel Modeling for Blind Motion Deblurring|生成潜在核建模用于盲运动去模糊|Chenhao Ding, Jiangtao Zhang, Zongsheng Yue, Hui Wang, Qian Zhao, Deyu Meng|<http://arxiv.org/pdf/2507.09285v1>|[代码](https://github.com/dch0319/GLKM-Deblur.); 提出利用生成模型优化初始估计，提高了盲运动去模糊的稳定性和性能。|
|🆕 发布|PanoDiff-SR: Synthesizing Dental Panoramic Radiographs using Diffusion and Super-resolution|全景差分超分辨率：使用扩散与超分辨率合成牙科全景X射线照片|Sanyam Jain, Bruna Neves de Freitas, Andreas Basse-OConnor, Alexandros Iosifidis, Ruben Pauwels|<http://arxiv.org/pdf/2507.09227v1>|提出了一种结合扩散生成和超分辨率技术的合成方法，用于生成高质量的合成牙科全景X光图像。|
|🆕 发布|Hybrid Autoregressive-Diffusion Model for Real-Time Streaming Sign Language Production|混合自回归-扩散模型用于实时流式手语生成|Maoxiao Ye, Xinfeng Ye, Mano Manoharan|<http://arxiv.org/pdf/2507.09105v1>|首次结合自回归和扩散模型，提出用于实时手语生成的多尺度姿态表示和置信度感知机制。|
|🆕 发布|Harnessing Text-to-Image Diffusion Models for Point Cloud Self-Supervised Learning|利用文本到图像扩散模型进行点云自监督学习|Yiyang Chen, Shanshan Zhao, Lunhao Duan, Changxing Ding, Dacheng Tao|<http://arxiv.org/pdf/2507.09102v1>|[代码](https://github.com/wdttt/PointSD.); 提出利用大规模文本到图像扩散模型提升三维点云自监督学习性能的方法。|
|📝 更新|Adaptive deep learning framework for robust unsupervised underwater image enhancement|自适应深度学习框架用于鲁棒的无监督水下图像增强|Alzayat Saleh, Marcus Sheaves, Dean Jerry, Mostafa Rahimi Azghadi|<http://arxiv.org/pdf/2212.08983v3>|[代码](https://github.com/alzayats/UDnet); 提出了一种无监督水下图像增强框架，通过概率自适应实例归一化和统计引导多色彩空间拉伸，无需高质量训练数...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AlphaVAE: Unified End-to-End RGBA Image Reconstruction and Generation with Alpha-Aware Representation Learning|AlphaVAE：具有Alpha感知表征学习的统一端到端RGBA图像重建与生成|Zile Wang, Hao Yu, Jiabo Zhan, Chun Yuan|<http://arxiv.org/pdf/2507.09308v1>|[代码](https://github.com/o0o0o00o0/AlphaVAE); 提出首个针对RGBA图像的全面基准ALPHA，并引入ALPHAVAE模型，实现端到端透明图像重建与生...|
|📝 更新|FlexEdit: Marrying Free-Shape Masks to VLLM for Flexible Image Editing|FlexEdit：将自由形状遮罩与VLLM结合进行灵活图像编辑|Tianshuo Yuan, Yuxiang Lin, Jue Wang, Zhi-Qi Cheng, Xiaolong Wang, Jiao GH, Wei Chen, Xiaojiang Peng|<http://arxiv.org/pdf/2408.12429v2>|[代码](https://github.com/A-new-b/flex_edit.); 提出FlexEdit方法，结合自由形状遮罩和语言指令进行灵活图像编辑，实现LLM-based图像编辑...|
|🆕 发布|Stable Score Distillation|稳定的分数蒸馏|Haiming Zhu, Yangyang Xu, Chenshu Xu, Tingrui Shen, Wenxi Liu, Yong Du, Jun Yu, Shengfeng He|<http://arxiv.org/pdf/2507.09168v1>|提出了Stable Score Distillation框架，通过简化结构和增强稳定性，实现了更精准...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EgoAnimate: Generating Human Animations from Egocentric top-down Views|自我动画：从主观俯视视角生成人类动画|G. Kutay Türkoglu, Julian Tanke, Iheb Belgacem, Lev Markhasin|<http://arxiv.org/pdf/2507.09230v1>|首次利用生成先验方法从第一视角重建可动画化虚拟形象，降低训练负担并增强泛化能力。|
|📝 更新|LLM-enhanced Action-aware Multi-modal Prompt Tuning for Image-Text Matching|基于LLM增强的动作感知多模态提示微调用于图像-文本匹配|Mengxiao Tian, Xinxiao Wu, Shuo Yang|<http://arxiv.org/pdf/2506.23502v2>|引入LLM增强的多模态提示调优，使CLIP模型具备理解动作细节的能力。|
|🆕 发布|Warm Starts Accelerate Generative Modelling|"预热启动加速生成模型训练"|Jonas Scholz, Richard E. Turner|<http://arxiv.org/pdf/2507.09212v1>|[代码](https://github.com/jonas-scholz123/warm-start-model.); 提出“暖启动”模型，通过提供更优的起始点，大幅加快生成模型条件生成速度。|
|📝 更新|Ophora: A Large-Scale Data-Driven Text-Guided Ophthalmic Surgical Video Generation Model|Ophora：一种大规模数据驱动、文本引导的眼科手术视频生成模型|Wei Li, Ming Hu, Guoan Wang, Lihao Liu, Kaijing Zhou, Junzhi Ning, Xin Guo, Zongyuan Ge .etc.|<http://arxiv.org/pdf/2505.07449v7>|[代码](https://github.com/uni-medical/Ophora.); 提出Ophora模型，通过自然语言指令生成高质量的眼科手术视频，解决了隐私和标注难题。|
|📝 更新|Understanding Pan-Sharpening via Generalized Inverse|通过广义逆理解全色锐化|Shiqi Liu, Yutong Bai, Xinyang Han, Alan Yuille|<http://arxiv.org/pdf/2310.02718v2>|提出泛逆矩阵理论描述Pan-sharpening问题，提高了图像的空间和光谱分辨率。|
|📝 更新|Making Images Real Again: A Comprehensive Survey on Deep Image Composition|《让图像重归真实：深度图像合成的全面综述》|Li Niu, Wenyan Cong, Liu Liu, Yan Hong, Bo Zhang, Jing Liang, Liqing Zhang|<http://arxiv.org/pdf/2106.14490v7>|系统梳理了图像合成子任务及组合任务，并推出了首个图像合成工具箱libcom。|
|📝 更新|Towards Open-World Generation of Stereo Images and Unsupervised Matching|面向开放世界立体图像生成和无监督匹配的研究|Feng Qiao, Zhexiao Xiong, Eric Xing, Nathan Jacobs|<http://arxiv.org/pdf/2503.12720v2>|[代码](https://qjizhi.github.io/genstereo.); 提出了一种基于扩散模型的方法GenStereo，同时提升了立体图像生成的视觉质量和几何匹配精度。|
|🆕 发布|$I^{2}$-World: Intra-Inter Tokenization for Efficient Dynamic 4D Scene Forecasting|$I^{2}$-世界：内外部符号化用于高效动态四维场景预测|Zhimin Liao, Ping Wei, Ruijie Zhang, Shuaijia Chen, Haoxuan Wang, Ziyang Ren|<http://arxiv.org/pdf/2507.09144v1>|[代码](https://github.com/lzzzzzm/II-World.); 提出$I^{2}$-World框架，将3D场景编码与时间依赖性分离，实现高效的4D场景预测。|
|🆕 发布|SnapMoGen: Human Motion Generation from Expressive Texts|SnapMoGen：从表现性文本生成人体运动|Chuan Guo, Inwoo Hwang, Jian Wang, Bing Zhou|<http://arxiv.org/pdf/2507.09122v1>|[代码](https://snap-research.github.io/SnapMoGen); 提出了SnapMoGen，通过高质量数据集和改进的生成模型，实现了从详细文本到精细人体动作的生成。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|THYME: Temporal Hierarchical-Cyclic Interactivity Modeling for Video Scene Graphs in Aerial Footage|THYME：面向空中影像视频场景图的时序层次循环交互建模|Trong-Thuan Nguyen, Pha Nguyen, Jackson Cothren, Alper Yilmaz, Minh-Triet Tran, Khoa Luu|<http://arxiv.org/pdf/2507.09200v1>|提出THYME方法，融合层级特征聚合与循环时间优化，提升动态场景图的准确性与连贯性。|
|📝 更新|Learning Traffic Anomalies from Generative Models on Real-Time Observations|从生成模型中学习实时观测数据下的交通异常|Fotis I. Giasemis, Alexandros Sopasakis|<http://arxiv.org/pdf/2502.01391v5>|利用生成对抗网络和图神经网络结合，有效检测实时交通异常并降低误报率。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Supercharging Floorplan Localization with Semantic Rays|利用语义射线增强平面图定位能力|Yuval Grader, Hadar Averbuch-Elor|<http://arxiv.org/pdf/2507.09291v1>|引入语义射线增强框架，融合深度与语义信息，显著提升建筑平面图定位精度。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Geo-RepNet: Geometry-Aware Representation Learning for Surgical Phase Recognition in Endoscopic Submucosal Dissection|Geo-RepNet：面向内镜下黏膜剥离手术阶段识别的几何感知表征学习|Rui Tang, Haochen Yin, Guankun Wang, Long Bai, An Wang, Huxin Gao, Jiazheng Wang, Hongliang Ren|<http://arxiv.org/pdf/2507.09294v1>|提出了一种融合RGB图像与深度信息的Geo-RepNet，有效提升了内窥镜手术阶段识别的准确性和效率...|
|📝 更新|Self-Supervised Monocular 4D Scene Reconstruction for Egocentric Videos|自监督单目4D场景重建方法用于第一视角视频|Chengbo Yuan, Geng Chen, Li Yi, Yang Gao|<http://arxiv.org/pdf/2411.09145v4>|提出了一种自监督的动态场景重建方法EgoMono4D，实现了快速、密集且通用的 egocentric...|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Enhancing Underwater Imaging with 4-D Light Fields: Dataset and Method|利用四维光场增强水下成像：数据集与方法|Yuji Lin, Junhui Hou, Xianqiang Lyu, Qian Zhao, Deyu Meng|<http://arxiv.org/pdf/2408.17339v2>|[代码](https://github.com/linlos1234/LFUIE.); 提出了一种基于4-D光场技术的水下成像增强框架，有效解决了水下成像中的光照吸收和散射问题。|
|📝 更新|A Practical Approach to Underwater Depth and Surface Normals Estimation|水下深度与表面法线估计的实用方法|Alzayat Saleh, Melanie Olsen, Bouchra Senadji, Mostafa Rahimi Azghadi|<http://arxiv.org/pdf/2410.02072v2>|提出了一种适用于水下环境的深度和表面法线估计混合深度学习模型，通过高效的数据处理方法实现了实时性能和...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ProactiveBench: A Comprehensive Benchmark Evaluating Proactive Interactions in Video Large Language Models|“ProactiveBench：一个全面评估视频大型语言模型中的主动交互的基准”|Yueqian Wang, Xiaojun Meng, Yifan Wang, Huishuai Zhang, Dongyan Zhao|<http://arxiv.org/pdf/2507.09313v1>|[代码](https://github.com/yellow-binary-tree/ProactiveBench); 提出了ProactiveBench，首个全面评估视频大型语言模型主动交互能力的基准，并引入PAUC指...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dynamic Inter-Class Confusion-Aware Encoder for Audio-Visual Fusion in Human Activity Recognition|动态跨类混淆感知编码器在人类活动识别中的音频-视觉融合|Kaixuan Cong, Yifan Wang, Rongkun Xue, Yuyang Jiang, Yiming Feng, Jing Yang|<http://arxiv.org/pdf/2507.09323v1>|提出了一种动态类间混淆感知编码器，通过调整混淆损失增强对相似活动区分的能力。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Domain Adaptation and Multi-view Attention for Learnable Landmark Tracking with Sparse Data|领域自适应与多视角注意力机制用于稀疏数据下的可学习地标跟踪|Timothy Chase Jr, Karthik Dantu|<http://arxiv.org/pdf/2507.09420v1>|提出了一种适用于航天器硬件的轻量级神经网络架构，通过域自适应和多视角注意力机制实现高效的地标检测与跟...|
|🆕 发布|Automated Multi-Class Crop Pathology Classification via Convolutional Neural Networks: A Deep Learning Approach for Real-Time Precision Agriculture|卷积神经网络实现的多类作物病理自动分类：面向实时精准农业的深度学习方法|Sourish Suri, Yifei Shao|<http://arxiv.org/pdf/2507.09375v1>|提出了一种基于卷积神经网络的作物病害自动识别与分类系统，实现了实时精准农业病害管理。|
|🆕 发布|Cross Knowledge Distillation between Artificial and Spiking Neural Networks|人工神经网络与脉冲神经网络之间的跨知识蒸馏|Shuhan Ye, Yuanbin Qian, Chong Wang, Sunqi Lin, Jiazhen Xu, Jiangbo Qian, Yuqi Li|<http://arxiv.org/pdf/2507.09269v1>|[代码](https://github.com/ShawnYE618/CKD); 提出跨知识蒸馏方法，利用RGB数据和成熟ANN提升SNN在DVS数据上的性能。|
|🆕 发布|PPJudge: Towards Human-Aligned Assessment of Artistic Painting Process|PPJudge：迈向与人类一致的艺术绘画过程评估|Shiqi Jiang, Xinpeng Li, Xi Mao, Changbo Wang, Chenhui Li|<http://arxiv.org/pdf/2507.09242v1>|提出了一种评估绘画过程的新框架PPJudge，通过结合专家注解的大型数据集，实现了与人类判断更一致的...|
|🆕 发布|Automatic Contouring of Spinal Vertebrae on X-Ray using a Novel Sandwich U-Net Architecture|基于 Sandwich U-Net 架构的 X 射线脊柱椎体自动轮廓提取|Sunil Munthumoduku Krishna Murthy, Kumar Rajamani, Srividya Tirunellai Rajamani, Yupei Li, Qiyang Sun, Bjoern W. Schuller|<http://arxiv.org/pdf/2507.09158v1>|提出了一种 Sandwich U-Net 结构，提高了X光片胸椎分割的准确性并降低了人工操作时间。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|When Small Guides Large: Cross-Model Co-Learning for Test-Time Adaptation|当小引导大：测试时适应的跨模型协同学习|Chang'an Yi, Xiaohui Deng, Guohao Chen, Yan Zhou, Qinghua Lu, Shuaicheng Niu|<http://arxiv.org/pdf/2506.23724v2>|[代码](https://github.com/ycarobot/COCA.); 提出跨模型协同学习框架COCA，通过互补知识提升测试时适应性能。|
|🆕 发布|Fast3D: Accelerating 3D Multi-modal Large Language Models for Efficient 3D Scene Understanding|快速3D：加速三维多模态大型语言模型以实现高效的三维场景理解|Wencan Huang, Daizong Liu, Wei Hu|<http://arxiv.org/pdf/2507.09334v1>|[代码](https://github.com/wencan25/Fast3D); 提出Fast3D框架，通过预测全局注意力分布和自适应视觉token剪枝，提升3D场景理解的效率。|
|📝 更新|Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting|利用分割任意模型通过双特征引导自动提示实现无需源域的领域自适应|Zheang Huai, Hui Tang, Yi Li, Zhuangzhuang Chen, Xiaomeng Li|<http://arxiv.org/pdf/2505.08527v3>|[代码](https://github.com/xmed-lab/DFG.); 提出了一种利用Segment Anything Model通过双特征引导自动寻找准确边界框的方法，有...|
|🆕 发布|AGCD-Net: Attention Guided Context Debiasing Network for Emotion Recognition|AGCD-Net：注意力引导的上下文去偏网络用于情感识别|Varsha Devi, Amine Bohi, Pardeep Kumar|<http://arxiv.org/pdf/2507.09248v1>|提出AGCD-Net模型，通过注意力引导和因果干预减轻背景偏见，提升情感识别准确性。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FieldNet: Efficient Real-Time Shadow Removal for Enhanced Vision in Field Robotics|FieldNet：田野机器人视觉增强中的高效实时阴影去除|Alzayat Saleh, Alex Olsen, Jake Wood, Bronson Philippa, Mostafa Rahimi Azghadi|<http://arxiv.org/pdf/2403.08142v3>|FieldNet通过创新的深度学习框架，实现了实时阴影移除，显著提升户外机器人视觉准确性和效率。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model|AHCPTQ：面向Segment Anything模型的精确且硬件兼容的后训练量化方法|Wenlun Zhang, Yunshan Zhong, Shimpei Ando, Kentaro Yoshioka|<http://arxiv.org/pdf/2503.03088v3>|提出AHCPTQ方法，通过硬件兼容的混合对数均匀量化与通道感知分组，有效优化SAM模型的量化精度和效...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Bidirectional Prototype-Reward co-Evolution for Test-Time Adaptation of Vision-Language Models|双向原型-奖励协同进化用于视觉语言模型测试时的适应调整|Xiaozhen Qiao, Peng Huang, Jiakang Yuan, Xianda Guo, Bowen Ye, Chaocan Xue, Ye Zheng, Zhe Sun .etc.|<http://arxiv.org/pdf/2503.09394v2>|提出双向原型-奖励协同进化框架BPRE，通过特征质量评估与原型演化的反馈循环，有效应对视觉语言模型在...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation|回声模仿V2：迈向高仿真、简化及半身人体动画|Rang Meng, Xingyu Zhang, Yuming Li, Chenguang Ma|<http://arxiv.org/pdf/2411.10061v2>|提出了一种简化条件以提高半身人体动画质量和表现力的新方法EchoMimicV2。|
|🆕 发布|Revisiting Pool-based Prompt Learning for Few-shot Class-incremental Learning|重新审视基于池的提示学习在少量样本类别增量学习中的应用|Yongwei Jiang, Yixiong Zou, Yuhua Li, Ruixuan Li|<http://arxiv.org/pdf/2507.09183v1>|[代码](https://github.com/Jywsuperman/LGSP.); 揭示了传统提示池方法在少量样本增量学习中的性能退化问题，并提出了一种基于空间维度的LGSP-Prom...|
|🆕 发布|Mind the Gap: Preserving and Compensating for the Modality Gap in CLIP-Based Continual Learning|关注差距：在基于CLIP的持续学习中保持和补偿模态差距|Linlan Huang, Xusheng Cao, Haori Lu, Yifan Meng, Fei Yang, Xialei Liu|<http://arxiv.org/pdf/2507.09118v1>|[代码](https://github.com/linlany/MindtheGap.); 提出方法MG-CLIP，通过保持和补偿模态间隙，提升CLIP模型在持续学习中的性能。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DAA*: Deep Angular A Star for Image-based Path Planning|深度角A星算法：基于图像的路径规划|Zhiwei Xu|<http://arxiv.org/pdf/2507.09305v1>|提出了一种结合路径角自由度的深度学习方法DAA*，通过自适应路径平滑性提高路径相似度，实现了路径规划...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Ambiguity-Aware and High-Order Relation Learning for Multi-Grained Image-Text Matching|"面向模糊性感知与高阶关系学习的多粒度图像-文本匹配"|Junyu Chen, Yihua Gao, Mingyuan Ge, Mingyong Li|<http://arxiv.org/pdf/2507.09256v1>|[代码](https://github.com/Image-Text-Matching/AAHR); 提出了一种Ambiguity-Aware and High-order Relation学习框架，有...|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Uncertainty-Driven Expert Control: Enhancing the Reliability of Medical Vision-Language Models|不确定性驱动的专家控制：提高医疗视觉语言模型的可靠性|Xiao Liang, Di Wang, Zhicheng Jiao, Ronghan Li, Pengfei Yang, Quan Wang, Tat-Seng Chua|<http://arxiv.org/pdf/2507.09209v1>|提出了一种无需额外训练的专家指导框架，通过不确定性估计和参考检索提升医疗视觉语言模型的可靠性和临床适...|
|🆕 发布|Visual Surface Wave Elastography: Revealing Subsurface Physical Properties via Visible Surface Waves|可视表面波弹性成像：通过可见表面波揭示次表面物理特性|Alexander C. Ogren, Berthy T. Feng, Jihoon Ahn, Katherine L. Bouman, Chiara Daraio|<http://arxiv.org/pdf/2507.09207v1>|提出了一种通过表面波视频推断材料厚度和硬度的方法，实现了对材料内部物理特性的可视化测量。|
|🆕 发布|Learning and Transferring Better with Depth Information in Visual Reinforcement Learning|在视觉强化学习中利用深度信息进行更好的学习和迁移|Zichun Xu, Yuntao Li, Zhaomin Wang, Lei Zhuang, Guocai Yang, Jingdong Zhao|<http://arxiv.org/pdf/2507.09180v1>|融合RGB与深度信息，提出视觉强化学习新架构，提升泛化能力与样本效率。|
|🆕 发布|MI CAM: Mutual Information Weighted Activation Mapping for Causal Visual Explanations of Convolutional Neural Networks|MI CAM：基于互信息加权的激活映射，用于卷积神经网络因果视觉解释|Ram S Iyer, Narayan S Iyer, Rugmini Ammal P|<http://arxiv.org/pdf/2507.09092v1>|提出了一种基于互信息加权的激活映射方法MI CAM，为卷积神经网络提供因果视觉解释。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Multi Source COVID-19 Detection via Kernel-Density-based Slice Sampling|基于核密度估计的切片采样多源COVID-19检测|Chia-Ming Lee, Bo-Cheng Qiu, Ting-Yao Chen, Ming-Han Sun, Fang-Ying Lin, Jung-Tse Tsai, I-An Tsai, Yu-Fan Lin .etc.|<http://arxiv.org/pdf/2507.01564v2>|提出了一种针对多源数据变异性的COVID-19检测方法，通过核密度切片采样优化特征学习，提高了跨机构...|
|📝 更新|WaveNet-SF: A Hybrid Network for Retinal Disease Detection Based on Wavelet Transform in the Spatial-Frequency Domain|基于小波变换的空间-频率域的视网膜疾病检测混合网络WaveNet-SF|Jilan Cheng, Guoli Long, Zeyu Zhang, Zhenjia Qi, Hanyu Wang, Libin Lu, Shuihua Wang, Yudong Zhang .etc.|<http://arxiv.org/pdf/2501.11854v2>|提出WaveNet-SF框架，结合空间域和频率域学习，通过小波变换提升视网膜疾病检测准确度。|
|🆕 发布|Stereo-based 3D Anomaly Object Detection for Autonomous Driving: A New Dataset and Baseline|基于立体视觉的自动驾驶三维异常目标检测：一个新的数据集和基线|Shiyi Mu, Zichong Gu, Hanqi Lyu, Yilin Gao, Shugong Xu|<http://arxiv.org/pdf/2507.09214v1>|[代码](https://github.com/xxxx/xxx); 提出了一种基于立体视觉的3D异常目标检测算法，通过解耦2D和3D训练策略，提高了对任意形状目标的泛化...|
|📝 更新|RadIR: A Scalable Framework for Multi-Grained Medical Image Retrieval via Radiology Report Mining|RadIR：通过放射学报告挖掘实现多粒度医学图像检索的可扩展框架|Tengfei Zhang, Ziheng Zhao, Chaoyi Wu, Xiao Zhou, Ya Zhang, Yanfeng Wang, Weidi Xie|<http://arxiv.org/pdf/2503.04653v2>|提出了一种利用密集放射学报告自动定义多粒度医学图像相似性的方法，构建了两个大型医学图像检索数据集，并...|
|🆕 发布|RadEyeVideo: Enhancing general-domain Large Vision Language Model for chest X-ray analysis with video representations of eye gaze|《RadEyeVideo：通过眼动视频表征增强通用领域大规模视觉语言模型进行胸部X射线分析》|Yunsoo Kim, Jinge Wu, Honghan Wu|<http://arxiv.org/pdf/2507.09097v1>|提出利用视频表示的放射科医师眼动数据增强大型视觉语言模型，显著提升胸部X光分析和报告生成的性能。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GreenCrossingAI: A Camera Trap/Computer Vision Pipeline for Environmental Science Research Groups|绿色交叉AI：一种面向环境科学研究团队的视频陷阱/计算机视觉处理流程|Bernie Boscoe, Shawn Johnson, Andrea Osborn, Chandler Campbell, Karen Mager|<http://arxiv.org/pdf/2507.09410v1>|提出了一种适用于资源有限研究小组的低成本相机陷阱数据处理流程，整合了定制化机器学习工具以提升数据解析...|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MCA-LLaVA: Manhattan Causal Attention for Reducing Hallucination in Large Vision-Language Models|曼哈顿因果注意力：用于减少大型视觉语言模型中的幻觉|Qiyan Zhao, Xiaofeng Zhang, Yiheng Li, Yun Xing, Xiaosong Yuan, Feilong Tang, Sinan Fan, Xuhang Chen .etc.|<http://arxiv.org/pdf/2507.09184v1>|[代码](https://github.com/ErikZ719/MCA-LLaVA.); 提出了一种基于曼哈顿距离的MCA-LLaVA方法，减少大型视觉语言模型中的幻觉现象，提高多模态对齐质...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Holistic White-light Polyp Classification via Alignment-free Dense Distillation of Auxiliary Optical Chromoendoscopy|通过无需对齐的辅助光学染色内镜密集蒸馏实现的全息白光息肉分类|Qiang Hu, Qimei Wang, Jia Chen, Xuantao Ji, Mei Liu, Qiang Li, Zhiwei Wang|<http://arxiv.org/pdf/2505.19319v3>|[代码](https://github.com/Huster-Hq/ADD.); 提出了一种无需对齐的全图白光结肠镜下息肉分类方法，通过像素级跨域亲和力学习显著提升诊断准确性。|

