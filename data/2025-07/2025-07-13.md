## [UPDATED!] **2025-07-13** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information|"VisOnlyQA：大型视觉语言模型在几何信息视觉感知上仍存在困难"|Ryo Kamoi, Yusen Zhang, Sarkar Snigdha Sarathi Das, Ranran Haoran Zhang, Rui Zhang|<http://arxiv.org/pdf/2412.00947v3>|[代码](https://github.com/psunlpgroup/VisOnlyQA.); 揭示了大型视觉语言模型在几何信息感知上的不足，并提出了相应的评估数据集VisOnlyQA。|
|🆕 发布|Prompt2DEM: High-Resolution DEMs for Urban and Open Environments from Global Prompts Using a Monocular Foundation Model|Prompt2DEM：利用单目基础模型从全球提示中为城市和开阔环境生成高分辨率数字高程模型|Osher Rafaeli, Tal Svoray, Ariel Nahlieli|<http://arxiv.org/pdf/2507.09681v1>|[代码](https://osherr1996.github.io/prompt2dem_propage); 提出了一种prompt-based框架，利用低分辨率数据提示，将单目图像的高分辨率数字高程模型精度提...|
|🆕 发布|MENTOR: Efficient Multimodal-Conditioned Tuning for Autoregressive Vision Generation Models|结果：导师：面向自回归视觉生成模型的多模态条件高效微调|Haozhe Zhao, Zefan Cai, Shuzheng Si, Liang Chen, Jiuxiang Gu, Wen Xiao, Junjie Hu|<http://arxiv.org/pdf/2507.09574v1>|[代码](https://github.com/HaozheZhao/MENTOR); 提出MENTOR框架，通过两阶段训练提升图像生成模型对多模态输入的精细控制和生成效率。|
|📝 更新|SpaCE-10: A Comprehensive Benchmark for Multimodal Large Language Models in Compositional Spatial Intelligence|空间智能组合性多模态大型语言模型的全面基准：SpaCE-10|Ziyang Gong, Wenhao Li, Oliver Ma, Songyuan Li, Jiayi Ji, Xue Yang, Gen Luo, Junchi Yan .etc.|<http://arxiv.org/pdf/2506.07966v2>|[代码](https://github.com/Cuzyoung/SpaCE-10.); 提出了SpaCE-10基准，全面评估多模态大语言模型在空间智能方面的原子与组合能力。|
|📝 更新|LLaVA-CoT: Let Vision Language Models Reason Step-by-Step|LLaVA-CoT：让视觉语言模型逐步推理|Guowei Xu, Peng Jin, Ziang Wu, Hao Li, Yibing Song, Lichao Sun, Li Yuan|<http://arxiv.org/pdf/2411.10440v5>|[代码](https://github.com/PKU-YuanGroup/LLaVA-CoT.); 提出LLaVA-CoT模型，通过分阶段推理显著提升视觉问答任务的性能。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MEGA-Bench: Scaling Multimodal Evaluation to over 500 Real-World Tasks|MEGA-Bench：将多模态评估扩展到超过500个现实世界任务|Jiacheng Chen, Tianhao Liang, Sherman Siu, Zhengqing Wang, Kai Wang, Yubo Wang, Yuansheng Ni, Wang Zhu .etc.|<http://arxiv.org/pdf/2410.10563v3>|提出MEGA-Bench，覆盖500余项真实世界任务，实现多样化模态任务的高效准确评估。|
|📝 更新|MIGE: Mutually Enhanced Multimodal Instruction-Based Image Generation and Editing|MIGE：基于相互增强的多模态指令图像生成与编辑|Xueyun Tian, Wei Li, Bingbing Xu, Yige Yuan, Yuanzhuo Wang, Huawei Shen|<http://arxiv.org/pdf/2502.21291v3>|[代码](https://github.com/Eureka-Maggie/MIGE); 提出了一种统一框架MIGE，通过多模态指令整合视觉生成与编辑任务，提升了任务执行一致性和泛化能力。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Universal Physics Simulation: A Foundational Diffusion Approach|通用物理仿真：基础扩散方法|Bradley Camburn|<http://arxiv.org/pdf/2507.09733v1>|提出了一种无需预先编码物理方程的通用物理模拟AI模型，通过边界条件数据直接学习物理规律。|
|🆕 发布|Token Compression Meets Compact Vision Transformers: A Survey and Comparative Evaluation for Edge AI|标记压缩遇见紧凑型视觉变换器：边缘AI的调研与比较评估|Phat Nguyen, Ngai-Man Cheung|<http://arxiv.org/pdf/2507.09702v1>|系统评估了Token压缩技术在标准与紧凑型Vision Transformer中的应用，指出了其在边...|
|🆕 发布|Brain Stroke Detection and Classification Using CT Imaging with Transformer Models and Explainable AI|基于CT成像的脑卒中检测与分类：使用Transformer模型与可解释人工智能|Shomukh Qari, Maha A. Thafar|<http://arxiv.org/pdf/2507.09630v1>|提出了一种基于Transformer的CT影像脑卒中检测与分类方法，通过集成解释性AI提高了诊断准确...|
|📝 更新|BreastDCEDL: A Comprehensive Breast Cancer DCE-MRI Dataset and Transformer Implementation for Treatment Response Prediction|乳腺癌动态对比增强磁共振成像（DCE-MRI）综合数据集及用于治疗响应预测的变换器实现：BreastDCEDL|Naomi Fridman, Bubby Solway, Tomer Fridman, Itamar Barnea, Anat Goldstein|<http://arxiv.org/pdf/2506.12190v3>|构建了首个深度学习专用乳腺癌DCE-MRI数据集，并利用Transformer模型实现了治疗响应预测...|
|🆕 发布|Self-supervised pretraining of vision transformers for animal behavioral analysis and neural encoding|计算机视觉变换器的自监督预训练在动物行为分析和神经编码中的应用|Yanchen Wang, Han Yu, Ari Blau, Yizi Zhang, The International Brain Laboratory, Liam Paninski, Cole Hurwitz, Matt Whiteway|<http://arxiv.org/pdf/2507.09513v1>|提出BEAST框架，通过自监督预训练视觉变换器，有效利用未标记视频数据提升神经行为分析性能。|
|📝 更新|High-Fidelity Differential-information Driven Binary Vision Transformer|高保真差分信息驱动的二值视觉变换器|Tian Gao, Zhiyuan Zhang, Kaijie Yin, Xu-Cheng Zhong, Hui Kong|<http://arxiv.org/pdf/2507.02222v2>|提出了一种高效保持信息量的二值化视觉Transformer架构，通过差分信息增强和频率分解显著提升了...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Comprehensive Evaluation of OCT-based Automated Segmentation of Retinal Layer, Fluid and Hyper-Reflective Foci: Impact on Clinical Assessment of Diabetic Retinopathy Severity|基于OCT的视网膜层、液性和高反射焦点的自动化分割综合评估：对糖尿病视网膜病变严重程度临床评估的影响|S. Chen, D. Ma, M. Raviselvan, S. Sundaramoorthy, K. Popuri, M. J. Ju, M. V. Sarunic, D. Ratra .etc.|<http://arxiv.org/pdf/2503.01248v4>|提出了一种基于主动学习的深度学习框架，用于自动分割视网膜层、液体积聚和强反射焦点，以辅助糖尿病视网膜...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VST-Pose: A Velocity-Integrated Spatiotem-poral Attention Network for Human WiFi Pose Estimation|人体WiFi姿态估计的基于速度集成的时空注意力网络：VST-Pose|Xinyu Zhang, Zhonghao Ye, Jingwei Zhang, Xiang Tian, Zhisheng Liang, Shipeng Yu|<http://arxiv.org/pdf/2507.09672v1>|[代码](https://github.com/CarmenQing/VST-Pose.); 提出VST-Pose框架，利用WiFi信号准确连续估计人体姿态，通过双流结构和速度建模提升运动捕捉精...|
|🆕 发布|EHPE: A Segmented Architecture for Enhanced Hand Pose Estimation|增强手部姿态估计的分段架构：EHPE|Bolun Zheng, Xinjie Liu, Qianyu Zhang, Canjin Wang, Fangni Chen, Mingen Xu|<http://arxiv.org/pdf/2507.09560v1>|[代码](https://github.com/SereinNout/EHPE.); 提出了一种分段架构EHPE，通过局部提取指尖和手腕关节，有效缓解了手势估计中的误差累积问题，实现了高...|
|📝 更新|MEGANet-W: A Wavelet-Driven Edge-Guided Attention Framework for Weak Boundary Polyp Detection|MEGANet-W：一种基于小波驱动的边缘引导注意力框架用于弱边界息肉检测|Zhe Yee Tan|<http://arxiv.org/pdf/2507.02668v2>|提出了一种利用小波驱动的边缘引导注意力框架，有效提升了弱边界息肉检测的准确性。|
|📝 更新|BoundMatch: Boundary detection applied to semi-supervised segmentation for urban-driving scenes|BoundMatch:应用于城市驾驶场景的半监督分割边界检测|Haruya Ishikawa, Yoshimitsu Aoki|<http://arxiv.org/pdf/2503.23519v3>|提出了一种结合边界检测的多任务半监督语义分割框架，有效提升了城市驾驶场景中的边界精度。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MLoRQ: Bridging Low-Rank and Quantization for Transformer Compression|MLoRQ：结合低秩和量化进行Transformer压缩|Ofir Gordon, Ariel Lapid, Elad Cohen, Yarden Yagil, Arnon Netzer, Hai Victor Habi|<http://arxiv.org/pdf/2507.09616v1>|整合低秩近似与混合精度量化，MLoRQ优化Transformer网络压缩，提升边缘设备性能。|
|🆕 发布|SegVec3D: A Method for Vector Embedding of 3D Objects Oriented Towards Robot manipulation|SegVec3D：面向机器人操作的三维物体向量嵌入方法|Zhihan Kang, Boyu Wang|<http://arxiv.org/pdf/2507.09459v1>|SegVec3D通过结合注意力机制和对比聚类，实现了3D物体实例分割和跨模态语义对齐。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SDTN and TRN: Adaptive Spectral-Spatial Feature Extraction for Hyperspectral Image Classification|SDTN和TRN：用于高光谱图像分类的自适应光谱-空间特征提取|Fuyin Ye, Erwen Yao, Jianyong Chen, Fengmei He, Junxiang Zhang, Lihao Ni|<http://arxiv.org/pdf/2507.09492v1>|提出自适应光谱-空间特征提取方法，通过张量分解和正则化提升高光谱图像分类准确率并降低计算复杂度。|
|📝 更新|CorrCLIP: Reconstructing Patch Correlations in CLIP for Open-Vocabulary Semantic Segmentation|CorrCLIP：在CLIP中重建补丁相关性以实现开放词汇语义分割|Dengke Zhang, Fagui Liu, Quan Tang|<http://arxiv.org/pdf/2411.10086v2>|[代码](https://github.com/zdk258/CorrCLIP.); 提出方法CorrCLIP，通过重构图像块相关性，提升CLIP在开放词汇语义分割的性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Pairwise Alignment & Compatibility for Arbitrarily Irregular Image Fragments|任意不规则图像片段的成对对齐与兼容性研究|Ofir Itzhak Shahar, Gur Elkin, Ohad Ben-Shahar|<http://arxiv.org/pdf/2507.09767v1>|提出了一种无需假设图像碎片形状、尺寸或内容的几何与图像混合方法，实现了高效的碎片对齐和兼容性计算。|
|📝 更新|Towards a Universal Image Degradation Model via Content-Degradation Disentanglement|面向内容-退化解耦的通用图像退化模型|Wenbo Yang, Zhongling Wang, Zhou Wang|<http://arxiv.org/pdf/2505.12860v2>|[代码](https://github.com/yangwenbo99/content-degradation-disentanglement.); 提出了一种通用图像退化模型，通过自动分离全局与空间变化的退化特征，实现了复杂退化效果的合成。|
|🆕 发布|ExpStar: Towards Automatic Commentary Generation for Multi-discipline Scientific Experiments|ExpStar：面向多学科科学实验的自动解说生成方法|Jiali Chen, Yujie Jia, Zihan Wu, Jinyu Yang, Jianpeng Chen, Xusen Hei, Jiayuan Xie, Yi Cai .etc.|<http://arxiv.org/pdf/2507.09693v1>|提出自动生成多学科科学实验解说的新任务，创建专用数据集并设计ExpStar模型，实现精准解说。|
|📝 更新|Relation-aware Hierarchical Prompt for Open-vocabulary Scene Graph Generation|关系感知的层次化提示用于开放词汇场景图生成|Tao Liu, Rongjie Li, Chongyu Wang, Xuming He|<http://arxiv.org/pdf/2412.19021v2>|[代码](https://github.com/Leon022/RAHP); 提出了一种增强文本表示的Relation-Aware Hierarchical Prompting框...|
|📝 更新|MEDTalk: Multimodal Controlled 3D Facial Animation with Dynamic Emotions by Disentangled Embedding|MEDTalk：通过解耦嵌入实现的具有动态情感的多模态可控三维面部动画|Chang Liu, Ye Pan, Chenyang Ding, Susanto Rahardja, Xiaokang Yang|<http://arxiv.org/pdf/2507.06071v2>|提出MEDTalk框架，通过解耦内容和情感嵌入空间实现细粒度和动态情感对话头的生成。|
|📝 更新|READoc: A Unified Benchmark for Realistic Document Structured Extraction|READoc：用于现实文档结构化提取的统一基准|Zichao Li, Aizier Abulaiti, Yaojie Lu, Xuanang Chen, Jia Zheng, Hongyu Lin, Xianpei Han, Le Sun|<http://arxiv.org/pdf/2409.05137v3>|提出统一基准READoc，首次全面评估文档结构提取系统，推动领域发展。|
|📝 更新|Auto-Regressively Generating Multi-View Consistent Images|自动回归生成多视角一致性图像|JiaKui Hu, Yuxiao Yang, Jialun Liu, Jinbo Wu, Chen Zhao, Yanye Lu|<http://arxiv.org/pdf/2506.18527v2>|[代码](https://github.com/MILab-PKU/MVAR.); 提出了一种多视角图像生成方法MV-AR，通过自回归模型逐步生成一致的多视角图像，有效应对多条件下的形...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Advancing Text-to-3D Generation with Linearized Lookahead Variational Score Distillation|线性化前向查看变分得分蒸馏在推进文本到3D生成中的应用|Yu Lei, Bingde Liu, Qingsong Xie, Haonan Lu, Zhijie Deng|<http://arxiv.org/pdf/2507.09748v1>|提出线性化前瞻性分数蒸馏方法，有效解决文本到3D生成中的收敛问题并提升生成质量。|
|🆕 发布|CADmium: Fine-Tuning Code Language Models for Text-Driven Sequential CAD Design|CADmium：为文本驱动的顺序CAD设计微调代码语言模型|Prashant Govindarajan, Davide Baldelli, Jay Pathak, Quentin Fournier, Sarath Chandar|<http://arxiv.org/pdf/2507.09792v1>|利用大型语言模型进行微调，实现了从自然语言描述到CAD设计的自动化转换。|
|📝 更新|CCDM: Continuous Conditional Diffusion Models for Image Generation|CCDM：用于图像生成的连续条件扩散模型|Xin Ding, Yongwei Wang, Kao Zhang, Z. Jane Wang|<http://arxiv.org/pdf/2405.03546v3>|[代码](https://github.com/UBCDingXin/CCDM.); 提出针对条件生成模型的连续扩散方法，通过优化扩散过程和损失函数，显著提升了图像生成质量。|
|🆕 发布|Demystifying Flux Architecture|揭开流架构的神秘面纱|Or Greenberg|<http://arxiv.org/pdf/2507.09595v1>|揭示了FLUX模型架构，助力其作为未来研究开发的基石。|
|🆕 发布|WordCraft: Interactive Artistic Typography with Attention Awareness and Noise Blending|《WordCraft：具有注意力感知与噪声融合的交互式艺术排版》|Zhe Wang, Jingbo Zhang, Tianyi Wei, Wanchao Su, Can Wang|<http://arxiv.org/pdf/2507.09573v1>|WordCraft通过集成扩散模型与区域注意力机制，实现了高互动性的艺术字体生成，支持局部编辑与迭代...|
|📝 更新|Hear-Your-Click: Interactive Object-Specific Video-to-Audio Generation|听见你的点击：交互式特定对象视频到音频生成|Yingshan Liang, Keyu Fan, Zhicheng Du, Yiran Wang, Qingyang Shi, Xinyu Zhang, Jiasheng Lu, Peiwu Qin|<http://arxiv.org/pdf/2507.04959v2>|[代码](https://github.com/SynapGrid/Hear-Your-Click); 提出互动式视频到音频生成框架Hear-Your-Click，通过点击指定对象生成声音，提升复杂场景下...|
|📝 更新|DH-FaceVid-1K: A Large-Scale High-Quality Dataset for Face Video Generation|DH-人脸视频-1K：用于人脸视频生成的大规模高质量数据集|Donglin Di, He Feng, Wenzhang Sun, Yongjia Ma, Hao Li, Wei Chen, Lei Fan, Tonghua Su .etc.|<http://arxiv.org/pdf/2410.07151v2>|[代码](https://luna-ai-lab.github.io/DH-FaceVid-1K); 介绍了DH-FaceVid-1K数据集，解决了高质量人脸视频数据缺乏问题，支持多模态人脸视频生成任务...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Compression-Aware One-Step Diffusion Model for JPEG Artifact Removal|JPEG压缩感知的一步扩散模型用于去除图像伪影|Jinpei Guo, Zheng Chen, Wenbo Li, Yong Guo, Yulun Zhang|<http://arxiv.org/pdf/2502.09873v3>|[代码](https://github.com/jp-guo/CODiff.); 提出了一种一步扩散模型CODiff，利用JPEG压缩先验知识去除压缩图像 artifact，实现高效...|
|📝 更新|AdaAugment: A Tuning-Free and Adaptive Approach to Enhance Data Augmentation|自适应增强：一种无需调参的自适应数据增强方法|Suorong Yang, Peijia Li, Xin Xiong, Furao Shen, Jian Zhao|<http://arxiv.org/pdf/2405.11467v3>|[代码](https://github.com/Jackbrocp/AdaAugment.); 提出了一种自适应数据增强方法AdaAugment，通过实时反馈调整增强强度，有效提升模型泛化性能。|
|🆕 发布|I2I-PR: Deep Iterative Refinement for Phase Retrieval using Image-to-Image Diffusion Models|基于图像到图像扩散模型的深度迭代优化相位恢复方法（I2I-PR）|Mehmet Onurcan Kaya, Figen S. Oktem|<http://arxiv.org/pdf/2507.09609v1>|提出了一种基于图像到图像扩散模型的迭代优化方法，有效提升了相位恢复的重建质量和训练效率。|
|🆕 发布|When Schrödinger Bridge Meets Real-World Image Dehazing with Unpaired Training|当薛定谔桥遇见无配对训练下的现实世界图像去雾|Yunwei Lan, Zhigao Cui, Xin Luo, Chang Liu, Nian Wang, Menglin Zhang, Yanzhao Su, Dong Liu|<http://arxiv.org/pdf/2507.09524v1>|[代码](https://github.com/ywxjm/DehazeSB.); 提出了一种基于Schrödinger桥和最优传输理论的去雾框架，通过分布直接桥接实现高效高质量图像去...|
|🆕 发布|RectifiedHR: High-Resolution Diffusion via Energy Profiling and Adaptive Guidance Scheduling|rectifiedHR：通过能量分析和自适应引导调度实现高分辨率扩散|Ankit Sanjyal|<http://arxiv.org/pdf/2507.09441v1>|提出自适应引导调度策略，通过调节引导力度随时间变化，有效解决了高分辨率图像合成中的能量不稳定和引导伪...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RealCam-I2V: Real-World Image-to-Video Generation with Interactive Complex Camera Control|RealCam-I2V：交互式复杂相机控制下的现实世界图像到视频生成|Teng Li, Guangcong Zheng, Rui Jiang, Shuigen Zhan, Tao Wu, Yehao Lu, Yining Lin, Chuanyun Deng .etc.|<http://arxiv.org/pdf/2502.10059v2>|[代码](https://zgctroy.github.io/RealCam-I2V.); 提出了一种结合单目深度估计的图像到视频生成框架，通过3D场景重建和直观的用户界面，实现了精确的相机控...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SEGS-SLAM: Structure-enhanced 3D Gaussian Splatting SLAM with Appearance Embedding|SEGS-SLAM：结构增强的三维高斯散点SLAM与外观嵌入|Tianci Wen, Zhiang Liu, Yongchun Fang|<http://arxiv.org/pdf/2501.05242v3>|[代码](https://segs-slam.github.io/.); SEGS-SLAM通过结构增强映射和外观运动嵌入，提升了SLAM系统中三维高斯散点映射的视觉质量和一...|
|📝 更新|VGLD: Visually-Guided Linguistic Disambiguation for Monocular Depth Scale Recovery|VGLD：基于视觉引导的语言消歧用于单目深度尺度恢复|Bojin Wu, Jing Chen|<http://arxiv.org/pdf/2505.02704v3>|提出了一种结合视觉语义的VGLD框架，有效解决文本描述中的歧义，提高了单目深度估计的准确性和稳定性。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Spiking Transformers Need High Frequency Information|尖峰变换器需要高频信息|Yuetong Fang, Deming Zhou, Ziqing Wang, Hongwei Ren, ZeCui Zeng, Lusong Li, Shibo Zhou, Renjing Xu|<http://arxiv.org/pdf/2505.18608v2>|[代码](https://github.com/bic-L/Spiking-Transformers-Need-High-Frequency-Information); 发现Spiking Transformers在处理低频信息上的偏好，并提出Max-Former方法增...|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|InternVideo2.5: Empowering Video MLLMs with Long and Rich Context Modeling|InternVideo2.5：赋予视频多模态语言模型以长且丰富的上下文建模能力|Yi Wang, Xinhao Li, Ziang Yan, Yinan He, Jiashuo Yu, Xiangyu Zeng, Chenting Wang, Changlian Ma .etc.|<http://arxiv.org/pdf/2501.12386v3>|[代码](https://github.com/OpenGVLab/InternVideo); 提出长丰富语境模型 InternVideo2.5，增强视频多模态大语言模型对细节感知和长时序结构捕捉...|
|🆕 发布|Memory-Augmented SAM2 for Training-Free Surgical Video Segmentation|内存增强的SAM2用于无需训练的手术视频分割|Ming Yin, Fu Wang, Xujiong Ye, Yanda Meng, Zeyu Fu|<http://arxiv.org/pdf/2507.09577v1>|提出了一种无需训练的内存增强SAM2方法，有效应对手术视频中的遮挡和复杂运动，提升分割准确度。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|High-Quality Live Video Streaming via Transcoding Time Prediction and Preset Selection|通过转码时间预测和预设选择实现高质量实时视频流传输|Zahra Nabizadeh Shahre-Babak, Nader Karimi, Krishna Rapaka, Tarek Amara, Shadrokh Samavi, Shahram Shirani|<http://arxiv.org/pdf/2312.05348v2>|提出了一种基于学习的视频转码时间预测框架，通过预测选择最佳预设，显著提升了直播视频质量。|
|📝 更新|VideoChat-Flash: Hierarchical Compression for Long-Context Video Modeling|视频聊天闪光：长上下文视频建模的分层压缩|Xinhao Li, Yi Wang, Jiashuo Yu, Xiangyu Zeng, Yuhan Zhu, Haian Huang, Jianfei Gao, Kunchang Li .etc.|<http://arxiv.org/pdf/2501.00574v4>|提出了一种视频分层压缩方法，大幅减少计算量同时保持细节，提升了长视频处理效率。|
|📝 更新|3D Reconstruction of the Human Colon from Capsule Endoscope Video|胶囊内镜视频的人体结肠三维重建|Pål Anders Floor, Ivar Farup, Marius Pedersen|<http://arxiv.org/pdf/2407.15228v2>|提出了一种利用胶囊内镜视频构建人体结肠三维模型的方法，以减轻胃肠病学家的工作负担。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|BiDepth: A Bidirectional-Depth Neural Network for Spatio-Temporal Prediction|双向深度神经网络：用于时空预测的BiDepth|Sina Ehsani, Fenglian Pan, Qingpei Hu, Jian Liu|<http://arxiv.org/pdf/2501.08411v3>|提出双向深度调制网络，有效预测动态系统中的时空变化，提升预测精度。|
|📝 更新|Online Dense Point Tracking with Streaming Memory|在线稠密点跟踪与流式内存管理|Qiaole Dong, Yanwei Fu|<http://arxiv.org/pdf/2503.06471v2>|[代码](https://dqiaole.github.io/SPOT); 提出了一种结合流式内存的在线密集点跟踪框架，实现了高效的信息传播和跟踪准确性。|
|🆕 发布|Efficient Multi-Person Motion Prediction by Lightweight Spatial and Temporal Interactions|轻量级空间与时间交互的高效多人运动预测|Yuanhong Zheng, Ruixuan Yu, Jian Sun|<http://arxiv.org/pdf/2507.09446v1>|[代码](https://github.com/Yuanhong-Zheng/EMPMP.); 提出了一种高效的多人运动预测模型，通过简化时空交互降低计算成本，实现领先性能。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Online Micro-gesture Recognition Using Data Augmentation and Spatial-Temporal Attention|在线微手势识别：基于数据增强与时空注意力机制|Pengyu Liu, Kun Li, Fei Wang, Yanyan Wei, Junhui She, Dan Guo|<http://arxiv.org/pdf/2507.09512v1>|提出手工程序数据增强和时空注意力机制，用于在线微手势识别，显著提升分类和定位准确性。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hierarchical Abstraction Enables Human-Like 3D Object Recognition in Deep Learning Models|分层抽象使深度学习模型实现类人3D物体识别|Shuhao Fu, Philip J. Kellman, Hongjing Lu|<http://arxiv.org/pdf/2507.09830v1>|揭示了通过层次抽象机制，深度学习模型可实现类似人类的3D物体识别能力。|
|📝 更新|Benchmarking Unified Face Attack Detection via Hierarchical Prompt Tuning|通过分层提示调谐进行统一人脸攻击检测的基准测试|Ajian Liu, Haocheng Yuan, Xiao Guo, Hui Ma, Wanyi Zhuang, Changtao Miao, Yan Hong, Chuanbiao Song .etc.|<http://arxiv.org/pdf/2505.13327v3>|提出了一种统一的人脸攻击检测框架，通过层级提示调优和大规模数据集，有效应对物理介质和数字编辑攻击。|
|🆕 发布|Lightweight Deep Learning-Based Channel Estimation for RIS-Aided Extremely Large-Scale MIMO Systems on Resource-Limited Edge Devices|基于轻量级深度学习的信道估计方法：面向资源受限边缘设备下RIS辅助的超大规模MIMO系统|Muhammad Kamran Saeed, Ashfaq Khokhar, Shakil Ahmed|<http://arxiv.org/pdf/2507.09627v1>|提出了一种轻量级深度学习框架，用于大规模MIMO系统的信道估计，降低计算复杂度并适应边缘设备。|
|📝 更新|WeGeFT: Weight-Generative Fine-Tuning for Multi-Faceted Efficient Adaptation of Large Models|《WeGeFT：面向大型模型多方面高效适应的权重生成微调》|Chinmay Savadikar, Xi Song, Tianfu Wu|<http://arxiv.org/pdf/2312.00700v5>|[代码](https://github.com/savadikarc/wegeft); 提出了一种生成微调权重的WeGeFT方法，实现了参数和表示效率的统一，提升了计算和内存效率。|
|🆕 发布|HMID-Net: An Exploration of Masked Image Modeling and Knowledge Distillation in Hyperbolic Space|HMID-Net：超空间中掩码图像建模与知识蒸馏的探索|Changli Wang, Fang Yin, Jiafeng Liu, Rui Wu|<http://arxiv.org/pdf/2507.09487v1>|首次在双曲空间中结合了掩码图像建模和知识蒸馏技术，有效提升模型训练效率和性能。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MEGA: Memory-Efficient 4D Gaussian Splatting for Dynamic Scenes|MEGA：动态场景的内存高效四维高斯散点喷射|Xinjie Zhang, Zhening Liu, Yifan Zhang, Xingtong Ge, Dailan He, Tongda Xu, Yan Wang, Zehong Lin .etc.|<http://arxiv.org/pdf/2410.13613v2>|[代码](https://github.com/Xinjie-Q/MEGA.); 提出了一种高效的4D高斯表示框架，通过参数分解和熵约束显著降低动态场景渲染的存储需求。|
|🆕 发布|SeqCSIST: Sequential Closely-Spaced Infrared Small Target Unmixing|序列近距离红外小目标解混：SeqCSIST|Ximeng Zhai, Bohan Xu, Yaohong Chen, Hao Wang, Kehua Guo, Yimian Dai|<http://arxiv.org/pdf/2507.09556v1>|[代码](https://github.com/GrokCV/SeqCSIST.); 提出了一种多帧范式下的红外小目标解混方法Deformable Refinement Network，...|
|🆕 发布|CKAA: Cross-subspace Knowledge Alignment and Aggregation for Robust Continual Learning|CKAA：跨子空间知识对齐与聚合用于稳健的持续学习|Lingfeng He, De Cheng, Zhiheng Ma, Huaijie Wang, Dingwen Zhang, Nannan Wang, Xinbo Gao|<http://arxiv.org/pdf/2507.09471v1>|提出CKAA框架，通过跨子空间知识对齐与聚合提升持续学习模型对误导性任务标识的鲁棒性。|
|🆕 发布|TRACER: Efficient Object Re-Identification in Networked Cameras through Adaptive Query Processing|TRACER：通过网络化相机中的自适应查询处理实现高效的对象重识别|Pramod Chunduri, Yao Lu, Joy Arulraj|<http://arxiv.org/pdf/2507.09448v1>|提出了一种自适应查询处理的VDBMS Tracer，通过训练循环网络和概率搜索模型，高效处理跨摄像头...|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Inter2Former: Dynamic Hybrid Attention for Efficient High-Precision Interactive|《Inter2Former：动态混合注意力机制用于高效高精度交互式计算》|You Huang, Lichao Chen, Jiayi Ji, Liujuan Cao, Shengchuan Zhang, Rongrong Ji|<http://arxiv.org/pdf/2507.09612v1>|Inter2Former通过动态混合注意力机制优化计算分配，实现了在CPU设备上高效且高精度的交互式...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GI-NAS: Boosting Gradient Inversion Attacks through Adaptive Neural Architecture Search|GI-NAS：通过自适应神经架构搜索提升梯度反转攻击|Wenbo Yu, Hao Fang, Bin Chen, Xiaohang Sui, Chuan Chen, Hao Wu, Shu-Tao Xia, Ke Xu|<http://arxiv.org/pdf/2405.20725v3>|提出了一种自适应神经架构搜索方法GI-NAS，有效提升梯度反转攻击性能，无需领域特定先验知识。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AI-Enhanced Pediatric Pneumonia Detection: A CNN-Based Approach Using Data Augmentation and Generative Adversarial Networks (GANs)|基于卷积神经网络的数据增强与生成对抗网络（GANs）的儿科肺炎检测方法研究|Abdul Manaf, Nimra Mughal|<http://arxiv.org/pdf/2507.09759v1>|[代码](https://github.com/AbdulManaf12/Pediatric-Chest-Pneumonia-Classification); 提出了一种基于CNN和GANs的儿童肺炎检测系统，通过数据增强和生成对抗网络提高了诊断准确性和效率。|
|📝 更新|Fair Domain Generalization: An Information-Theoretic View|公平领域泛化：信息论视角下的研究|Tangzheng Lian, Guanyu Hu, Dimitrios Kollias, Xinyu Yang, Oya Celiktutan|<http://arxiv.org/pdf/2507.05823v2>|提出FairDG方法，解决域泛化与算法公平性双重挑战，通过帕累托优化实现效用与公平性的最佳权衡。|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EyeSeg: An Uncertainty-Aware Eye Segmentation Framework for AR/VR|眼部分割：一种面向增强现实/虚拟现实的不确定性感知眼部分割框架|Zhengyuan Peng, Jianqing Xu, Shen Li, Jiazhen Ji, Yuge Huang, Jingyun Zhang, Jinmin Li, Shouhong Ding .etc.|<http://arxiv.org/pdf/2507.09649v1>|[代码](https://github.com/JethroPeng/EyeSeg.); 提出EyeSeg框架，通过不确定性感知的眼部分割技术，有效应对运动模糊和遮挡问题，提升AR/VR中的...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|NegRefine: Refining Negative Label-Based Zero-Shot OOD Detection|NegRefine：基于负标签精炼的零样本OOD检测|Amirhossein Ansari, Ke Wang, Pulei Xiong|<http://arxiv.org/pdf/2507.09795v1>|[代码](https://github.com/ah-ansari/NegRefine.); 提出了一种负标签精炼框架NegRefine，通过过滤子类别标签和专有名词并动态调整标签贡献，有效区分...|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DriveMRP: Enhancing Vision-Language Models with Synthetic Motion Data for Motion Risk Prediction|驱动MRP：利用合成运动数据增强视觉语言模型进行运动风险评估|Zhiyi Hou, Enhui Ma, Fang Li, Zhiyi Lai, Kalok Ho, Zhanqian Wu, Lijun Zhou, Long Chen .etc.|<http://arxiv.org/pdf/2507.02948v3>|通过合成高风险运动数据，本研究显著提升了视觉语言模型在运动风险预测方面的性能。|
|🆕 发布|VDInstruct: Zero-Shot Key Information Extraction via Content-Aware Vision Tokenization|VDInstruct：通过内容感知视觉标记化实现零样本关键信息提取|Son Nguyen, Giang Nguyen, Hung Dao, Thao Do, Daeyoung Kim|<http://arxiv.org/pdf/2507.09531v1>|VDInstruct通过内容感知的视觉标记化策略，优化了关键信息提取，减少计算冗余，实现文档理解性能...|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Fine-Grained Adaptation of CLIP via a Self-Trained Alignment Score|面向细粒度适应的CLIP通过自训练对齐分数|Eman Ali, Sathira Silva, Chetan Arora, Muhammad Haris Khan|<http://arxiv.org/pdf/2507.09615v1>|提出FAIR方法，通过动态对齐图像特征与文本描述，提升细粒度无监督适应性能。|
|📝 更新|CalFuse: Feature Calibration Enhanced Parameter Fusion for Class-Continual Learning|"CalFuse：特征校准增强的参数融合用于类连续学习"|Juncen Guo, Yang Liu, Xiaoguang Zhu, Lianlong Sun, Liangyu Teng, Jingyi Wu, Di Li, Linxiao Gong .etc.|<http://arxiv.org/pdf/2503.18672v6>|提出CalFuse框架，通过特征校准增强参数融合，有效平衡新知识学习与旧知识保留。|
|📝 更新|An Efficient Deep Learning Framework for Brain Stroke Diagnosis Using Computed Tomography (CT) Images|一种基于计算机断层扫描（CT）图像的脑卒中诊断高效深度学习框架|Md. Sabbir Hossen, Eshat Ahmed Shuvo, Shibbir Ahmed Arif, Pabon Shaha, Md. Saiduzzaman, Mostofa Kamal Nasir|<http://arxiv.org/pdf/2507.03558v2>|提出了一种结合轻量级预训练模型和优化策略的脑卒中诊断方法，实现了97.93%的高分类准确率。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VRU-Accident: A Vision-Language Benchmark for Video Question Answering and Dense Captioning for Accident Scene Understanding|VRU-Accident：面向事故场景理解的视频问答与密集标注视觉-语言基准|Younggun Kim, Ahmed S. Abdelrahman, Mohamed Abdel-Aty|<http://arxiv.org/pdf/2507.09815v1>|提出VRU-Accident基准，评估大型语言模型在理解高风险交通事故场景中的表现。|
|🆕 发布|Visual Homing in Outdoor Robots Using Mushroom Body Circuits and Learning Walks|利用蘑菇体电路和学习行走实现室外机器人的视觉归巢|Gabriel G. Gattaux, Julien R. Serres, Franck Ruffier, Antoine Wystrach|<http://arxiv.org/pdf/2507.09725v1>|首次实现基于蘑菇体电路的视觉归巢系统，通过学习行走实现自然户外环境下的自主导航。|
|🆕 发布|QuarterMap: Efficient Post-Training Token Pruning for Visual State Space Models|"QuarterMap：视觉状态空间模型的高效训练后标记剪枝"|Tien-Yu Chi, Hung-Yueh Chiang, Diana Marculescu, Kai-Chiang Wu|<http://arxiv.org/pdf/2507.09514v1>|提出QuarterMap方法，通过剪枝减少视觉状态空间模型的空间冗余，提升速度同时保持准确度。|
|📝 更新|Hierarchical Attention Fusion of Visual and Textual Representations for Cross-Domain Sequential Recommendation|跨域序列推荐中视觉与文本表征的层次化注意力融合|Wangyu Wu, Zhenhong Chen, Siqi Song, Xianglin Qiu, Xiaowei Huang, Fei Ma, Jimin Xiao|<http://arxiv.org/pdf/2504.15085v3>|提出了一种融合视觉和文本表征的层次化注意力模型，有效提升了跨域序列推荐中用户兴趣的捕捉能力。|
|🆕 发布|GLIMPSE: Do Large Vision-Language Models Truly Think With Videos or Just Glimpse at Them?|《GLIMPSE：大型视觉语言模型是否真正通过视频思考，还是仅仅一瞥而过？》|Yiyang Zhou, Linjie Li, Shi Qiu, Zhengyuan Yang, Yuyang Zhao, Siwei Han, Yangfan He, Kangqi Li .etc.|<http://arxiv.org/pdf/2507.09491v1>|提出GLIMPSE基准，专门评估大型视觉语言模型是否能够真正理解视频内容而不仅仅是扫描关键帧。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Advancing Reliable Test-Time Adaptation of Vision-Language Models under Visual Variations|在视觉变化下推进视觉语言模型测试时的可靠适应|Yiwen Liang, Hui Chen, Yizhe Xiong, Zihan Zhou, Mengyao Lyu, Zijia Lin, Shuaicheng Niu, Sicheng Zhao .etc.|<http://arxiv.org/pdf/2507.09500v1>|提出了一种增强视觉语言模型在视觉变化下的可靠测试时适应方法，通过一致性感知熵重权和多样性驱动的分布校...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|COVID-19 Pneumonia Diagnosis Using Medical Images: Deep Learning-Based Transfer Learning Approach|基于深度学习的迁移学习方法在医学影像中用于COVID-19肺炎诊断|Anjali Dharmik|<http://arxiv.org/pdf/2503.12642v3>|提出了一种基于深度迁移学习的COVID-19肺炎诊断系统，实现了98%的准确率和99.8%的AUC分...|
|🆕 发布|Pre-trained Under Noise: A Framework for Robust Bone Fracture Detection in Medical Imaging|在噪声下预训练：一种用于医学成像中稳健骨折检测的框架|Robby Hoover, Nelly Elsayed, Zag ElSayed, Chengcheng Li|<http://arxiv.org/pdf/2507.09731v1>|提出了一种在噪声环境下评估预训练模型鲁棒性的方法，提高了医学影像中骨折检测的准确性。|
|🆕 发布|Disentanglement and Assessment of Shortcuts in Ophthalmological Retinal Imaging Exams|视网膜成像检查中的解耦与捷径评估|Leonor Fernandes, Tiago Gonçalves, João Matos, Luis Filipe Nakayama, Jaime S. Cardoso|<http://arxiv.org/pdf/2507.09640v1>|评估了眼科图像中糖尿病视网膜病变预测模型的公平性，并探索了属性解耦作为减少偏见的策略。|
|🆕 发布|Prompt Engineering in Segment Anything Model: Methodologies, Applications, and Emerging Challenges|《Segment Anything模型中的提示工程：方法学、应用与新兴挑战》|Yidong Jiang|<http://arxiv.org/pdf/2507.09562v1>|系统梳理了SAM模型中prompt工程的方法和应用，为提升图像分割性能提供了新视角。|
|📝 更新|Brain Latent Progression: Individual-based Spatiotemporal Disease Progression on 3D Brain MRIs via Latent Diffusion|大脑潜在进展：基于个体的三维脑磁共振成像上的时空疾病进展通过潜在扩散|Lemuel Puglisi, Daniel C. Alexander, Daniele Ravì|<http://arxiv.org/pdf/2502.08560v2>|[代码](https://github.com/LemuelPuglisi/BrLP.); 提出Brain Latent Progression模型，通过低维空间和元数据集成预测个体脑部疾病进...|
|📝 更新|FuseUNet: A Multi-Scale Feature Fusion Method for U-like Networks|FuseUNet：用于U型网络的多尺度特征融合方法|Quansong He, Xiangde Min, Kaishen Wang, Tao He|<http://arxiv.org/pdf/2506.05821v2>|[代码](https://github.com/nayutayuki/FuseUNet.); 提出了一种将U-Net解码过程视为初值问题，通过自适应微分方程实现多尺度特征融合的方法，有效提升了医...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Generate Aligned Anomaly: Region-Guided Few-Shot Anomaly Image-Mask Pair Synthesis for Industrial Inspection|生成对齐异常：基于区域引导的少量样本异常图像-掩码对合成用于工业检测|Yilin Lu, Jianghang Lin, Linhuang Xie, Kai Zhao, Yansong Qu, Shengchuan Zhang, Liujuan Cao, Rongrong Ji|<http://arxiv.org/pdf/2507.09619v1>|提出了一种少量样本驱动的异常图像-掩码对生成框架，有效提升了工业检测中异常检测的准确性和泛化能力。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Is Intermediate Fusion All You Need for UAV-based Collaborative Perception?|您需要的中文翻译为：  “无人机协同感知，仅中间融合就足够了吗？”|Jiuwu Hao, Liguo Sun, Yuting Wan, Yueyang Wu, Ti Xiang, Haolin Song, Pin Lv|<http://arxiv.org/pdf/2504.21774v2>|[代码](https://github.com/uestchjw/LIF.); 提出了一种基于延迟中间融合的通信高效无人机协同感知框架，有效整合多无人机信息并降低通信负担。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Evaluating the Role of Training Data Origin for Country-Scale Cropland Mapping in Data-Scarce Regions: A Case Study of Nigeria|评估训练数据来源在数据匮乏区域国家尺度农作物映射中的作用：尼日利亚的案例研究|Joaquin Gajardo, Michele Volpi, Daniel Onwude, Thijs Defraeye|<http://arxiv.org/pdf/2312.10872v2>|评估不同来源训练数据对数据稀缺区域农作物映射的影响，发现本地数据显著提升模型性能。|
|🆕 发布|DRPCA-Net: Make Robust PCA Great Again for Infrared Small Target Detection|DRPCA-Net：利用稳健主成分分析再次提升红外小目标检测性能|Zihao Xiong, Fei Zhou, Fengyi Wu, Shuai Yuan, Maixia Fu, Zhenming Peng, Jian Yang, Yimian Dai|<http://arxiv.org/pdf/2507.09541v1>|[代码](https://github.com/GrokCV/DRPCA-Net.); 提出动态RPCA网络，通过自适应参数生成增强红外小目标检测的鲁棒性和泛化能力。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|prNet: Data-Driven Phase Retrieval via Stochastic Refinement|prNet：基于随机优化的数据驱动相位恢复|Mehmet Onurcan Kaya, Figen S. Oktem|<http://arxiv.org/pdf/2507.09608v1>|提出了一种利用朗之万动力学进行高效后验采样的相位恢复框架，平衡了失真和感知质量。|

