## [UPDATED!] **2025-07-14** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Test-Time Canonicalization by Foundation Models for Robust Perception|测试时通过基础模型进行规范化的稳健感知|Utkarsh Singhal, Ryan Feng, Stella X. Yu, Atul Prakash|<http://arxiv.org/pdf/2507.10375v1>|[代码](https://github.com/sutkarsh/focal.); 提出一种无需重训练或架构调整的FOCAL框架，利用大规模视觉先验提升视觉感知鲁棒性。|
|🆕 发布|DepViT-CAD: Deployable Vision Transformer-Based Cancer Diagnosis in Histopathology|可部署视觉变换器基础上的病理学癌症诊断DepViT-CAD|Ashkan Shakarami, Lorenzo Nicole, Rocco Cappellesso, Angelo Paolo Dei Tos, Stefano Ghidoni|<http://arxiv.org/pdf/2507.10250v1>|提出了一种基于多注意力视觉变换器的AI系统DepViT-CAD，用于病理切片的多类别癌症诊断，实现了...|
|📝 更新|Explaining the Impact of Training on Vision Models via Activation Clustering|通过激活聚类解释训练对视觉模型影响的研究|Ahcène Boubekki, Samuel G. Fadel, Sebastian Mair|<http://arxiv.org/pdf/2411.19700v4>|提出 Neuro-Activated Vision Explanations 方法，通过激活聚类分析...|
|📝 更新|Pathfinder for Low-altitude Aircraft with Binary Neural Network|低空飞行器用的二值神经网络导航器|Kaijie Yin, Tian Gao, Hui Kong|<http://arxiv.org/pdf/2409.08824v4>|[代码](https://github.com/IMRL/Pathfinder); 提出了一种基于二元神经网络的路径查找方法，通过集成机和相机数据，高效生成完整的地图以辅助自动驾驶。|
|🆕 发布|Cross-modal Associations in Vision and Language Models: Revisiting the bouba-kiki effect|视觉与语言模型中的跨模态关联：重新审视bouba-kiki效应|Tom Kouwenhoven, Kiana Shahrasbi, Tessa Verhoef|<http://arxiv.org/pdf/2507.10013v1>|揭示了视觉与语言模型在跨模态信息整合上的局限性，通过对比实验指出模型未能充分体现人类的“bouba-...|
|🆕 发布|Leveraging Swin Transformer for enhanced diagnosis of Alzheimer's disease using multi-shell diffusion MRI|利用Swin Transformer增强基于多壳扩散MRI的阿尔茨海默病诊断|Quentin Dessain, Nicolas Delinte, Bernard Hanseeuw, Laurence Dricot, Benoît Macq|<http://arxiv.org/pdf/2507.09996v1>|利用Swin Transformer模型分析扩散MRI数据，提高了阿尔茨海默病的早期诊断准确率。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FaceLLM: A Multimodal Large Language Model for Face Understanding|面向人脸理解的多模态大型语言模型：FaceLLM|Hatef Otroshi Shahreza, Sébastien Marcel|<http://arxiv.org/pdf/2507.10300v1>|提出了FaceLLM，一种专门针对面部图像理解训练的多模态大型语言模型，通过合成监督提升性能并实现最...|
|🆕 发布|Mind the Gap: Aligning Vision Foundation Models to Image Feature Matching|关注差距：将视觉基础模型与图像特征匹配对齐|Yuhan Liu, Jingwen Fu, Yang Wu, Kangyi Wu, Pengna Li, Jiayi Wu, Sanping Zhou, Jingmin Xin|<http://arxiv.org/pdf/2507.10318v1>|提出IMD框架，利用生成式扩散模型与提示机制，有效解决图像特征匹配中的不一致性问题。|
|🆕 发布|Synthesizing Near-Boundary OOD Samples for Out-of-Distribution Detection|合成近边界异常样本以进行分布外检测|Jinglun Li, Kaixun Jiang, Zhaoyu Chen, Bo Lin, Yao Tang, Weifeng Ge, Wenqiang Zhang|<http://arxiv.org/pdf/2507.10225v1>|[代码](https://github.com/Jarvisgivemeasuit/SynOOD.); 提出了一种利用基础模型生成边界附近OOD样本的方法，有效提高了CLIP模型对分布内外样本的区分能力。|
|🆕 发布|(Almost) Free Modality Stitching of Foundation Models|基础模型的（几乎）免费模态拼接|Jaisidh Singh, Diganta Misra, Boris Knyazev, Antonio Orvieto|<http://arxiv.org/pdf/2507.10015v1>|提出了一种利用超网络进行模态模型选择和连接训练的一体化方法，大幅降低了多模态模型构建的计算成本。|
|📝 更新|AGAV-Rater: Adapting Large Multimodal Model for AI-Generated Audio-Visual Quality Assessment|AGAV-Rater：自适应大型多模态模型进行人工智能生成音频-视觉质量评估|Yuqin Cao, Xiongkuo Min, Yixuan Gao, Wei Sun, Guangtao Zhai|<http://arxiv.org/pdf/2501.18314v2>|[代码](https://github.com/charlotte9524/AGAV-Rater.); 提出首个大规模AGAV质量评估数据集AGAVQA-3k，并设计AGAV-Rater模型，有效评估AI...|
|🆕 发布|A Survey on MLLM-based Visually Rich Document Understanding: Methods, Challenges, and Emerging Trends|《基于大规模语言模型的多模态文档理解综述：方法、挑战与新兴趋势》|Yihao Ding, Siwen Luo, Yue Dai, Yanbei Jiang, Zechuan Li, Geoffrey Martin, Yifan Peng|<http://arxiv.org/pdf/2507.09861v1>|概述了多模态大语言模型在视觉丰富文档理解中的应用，强调了特征融合方法、训练策略和数据集选择。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Improving Multimodal Learning via Imbalanced Learning|通过不平衡学习改进多模态学习|Shicai Wei, Chunbo Luo, Yang Luo|<http://arxiv.org/pdf/2507.10203v1>|[代码](https://github.com/shicaiwei123/ICCV2025-ARL); 提出了一种通过不平衡优化提升多模态学习性能的策略，通过调整模态依赖比例以适应模态方差差异。|
|🆕 发布|IGD: Instructional Graphic Design with Multimodal Layer Generation|IGD：带有多种模态层生成的指导性图形设计|Yadong Qu, Shancheng Fang, Yuxin Wang, Xiaorui Wang, Zhineng Chen, Hongtao Xie, Yongdong Zhang|<http://arxiv.org/pdf/2507.09910v1>|提出了一种基于自然语言指令的图形设计方法IGD，通过生成可编辑的多模态图层，实现了高效自动化图形设计...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BenchReAD: A systematic benchmark for retinal anomaly detection|视网膜异常检测的系统性能基准：BenchReAD|Chenyu Lian, Hong-Yu Zhou, Zhanli Hu, Jing Qin|<http://arxiv.org/pdf/2507.10492v1>|[代码](https://github.com/DopamineLcy/BenchReAD.); 提出全面系统视网膜异常检测基准，提出NFM-DRA方法提升未见异常性能。|
|🆕 发布|Kaleidoscopic Background Attack: Disrupting Pose Estimation with Multi-Fold Radial Symmetry Textures|万花筒背景攻击：利用多折径向对称纹理破坏姿态估计|Xinlong Ding, Hongwei Yu, Jiawei Li, Feifan Li, Yu Shang, Bochao Zou, Huimin Ma, Jiansheng Chen|<http://arxiv.org/pdf/2507.10265v1>|提出了一种利用多折径向对称纹理的背景攻击方法，有效干扰相机姿态估计。|
|📝 更新|Multispectral Detection Transformer with Infrared-Centric Feature Fusion|多光谱检测变换器与红外中心特征融合|Seongmin Hwang, Daeyoung Han, Moongu Jeon|<http://arxiv.org/pdf/2505.15137v2>|[代码](https://github.com/smin-hwang/IC-Fusion.); 提出了一种红外-centric的传感器融合方法，通过优先处理红外特征并整合RGB语义信息，提升了多光...|
|🆕 发布|Lightweight Model for Poultry Disease Detection from Fecal Images Using Multi-Color Space Feature Optimization and Machine Learning|基于多色彩空间特征优化及机器学习的家禽疾病粪便图像检测轻量级模型|A. K. M. Shoriful Islam, Md. Rakib Hassan, Macbah Uddin, Md. Shahidur Rahman|<http://arxiv.org/pdf/2507.10056v1>|提出了一种基于机器学习的轻量级家禽疾病检测方法，通过多色彩空间特征优化，实现了高准确性与低资源消耗。|
|📝 更新|Deflickering Vision-Based Occupancy Networks through Lightweight Spatio-Temporal Correlation|基于轻量级时空相关性的去闪烁视觉占用网络|Fengcheng Yu, Haoran Xu, Canming Xia, Ziyang Zong, Guang Tan|<http://arxiv.org/pdf/2502.15438v3>|提出了一种插件框架OccLinker，通过学习时空关联有效消除自动驾驶中3D重建的闪烁效应，同时保持...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Fine-Grained Zero-Shot Object Detection|细粒度零样本目标检测|Hongxu Ma, Chenbo Zhang, Lu Zhang, Jiaogen Zhou, Jihong Guan, Shuigeng Zhou|<http://arxiv.org/pdf/2507.10358v1>|提出并解决了细粒度零样本目标检测问题，通过多级语义感知嵌入对齐损失提升了检测精度。|
|📝 更新|SLGaussian: Fast Language Gaussian Splatting in Sparse Views|稀疏视角下的快速语言高斯喷洒算法：SLGaussian|Kangjie Chen, BingQuan Dai, Minghan Qin, Dongbin Zhang, Peihao Li, Yingshuang Zou, Haoqian Wang|<http://arxiv.org/pdf/2412.08331v2>|提出了一种高效构建3D语义场的方法SLGaussian，通过稀疏视角直接推断场景，提升了稀疏视图下的...|
|📝 更新|LIRA: Inferring Segmentation in Large Multi-modal Models with Local Interleaved Region Assistance|LIRA：利用局部交错区域辅助在大多模态模型中推断分割|Zhang Li, Biao Yang, Qiang Liu, Shuo Zhang, Zhiyin Ma, Shuo Zhang, Liang Yin, Linger Deng .etc.|<http://arxiv.org/pdf/2507.06272v2>|[代码](https://github.com/echo840/LIRA.); 提出LIRA框架，通过融合视觉理解和分割提升大模型准确性和细腻度。|
|📝 更新|Class-Aware PillarMix: Can Mixed Sample Data Augmentation Enhance 3D Object Detection with Radar Point Clouds?|类感知 PillarMix：混合样本数据增强能否提升雷达点云的3D目标检测性能？|Miao Zhang, Sherif Abdulatif, Benedikt Loesch, Marco Altmann, Bin Yang|<http://arxiv.org/pdf/2503.02687v2>|提出了一种针对雷达点云的类感知混合样本数据增强方法CAPMix，通过在支柱级别应用MixUp并考虑对...|
|🆕 发布|Graph-based Multi-Modal Interaction Lightweight Network for Brain Tumor Segmentation (GMLN-BTS) in Edge Iterative MRI Lesion Localization System (EdgeIMLocSys)|基于图的跨模态交互轻量级网络用于边缘迭代MRI病变定位系统中的脑肿瘤分割（GMLN-BTS）|Guohao Huo, Ruiting Dai, Hao Tang|<http://arxiv.org/pdf/2507.09995v1>|提出了一种轻量级脑肿瘤分割网络GMLN-BTS，通过模态感知编码器和图结构建模，实现了高效精准的分割...|
|📝 更新|De-Fake: Style based Anomaly Deepfake Detection|“De-Fake：基于风格的异常深度伪造检测”|Sudev Kumar Padhi, Harshit Kumar, Umesh Kashyap, Sk. Subidh Ali|<http://arxiv.org/pdf/2507.03334v2>|提出了一种基于风格特征的Deepfake检测方法SafeVision，有效识别面部交换伪造图像且保护...|
|🆕 发布|Measuring the Impact of Rotation Equivariance on Aerial Object Detection|测量旋转等方差性对航空目标检测的影响|Xiuyu Wu, Xinhao Wang, Xiubin Zhu, Lan Yang, Jiyuan Liu, Xingchen Hu|<http://arxiv.org/pdf/2507.09896v1>|研究了旋转等价性对空中目标检测的影响，提出了一种参数更少、准确性更高的多分支头旋转等价单阶段检测器。|
|🆕 发布|Advanced U-Net Architectures with CNN Backbones for Automated Lung Cancer Detection and Segmentation in Chest CT Images|具有卷积神经网络骨干的先进U-Net架构在胸部CT图像中自动检测和分割肺癌的研究|Alireza Golkarieha, Kiana Kiashemshakib, Sajjad Rezvani Boroujenic, Nasibeh Asadi Isakand|<http://arxiv.org/pdf/2507.09898v1>|提出了一种结合先进CNN背骨的U-Net架构，有效提升了肺癌检测与分割的准确性和效率。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FGSSNet: Feature-Guided Semantic Segmentation of Real World Floorplans|FGSSNet：特征引导的实际世界平面图语义分割|Hugo Norrby, Gabriel Färm, Kevin Hernandez-Diaz, Fernando Alonso-Fernandez|<http://arxiv.org/pdf/2507.10343v1>|提出FGSSNet模型，通过特定特征提取器增强U-Net网络，提升墙体质心线分割准确度。|
|📝 更新|Beyond Appearance: Geometric Cues for Robust Video Instance Segmentation|超越外观：用于鲁棒视频实例分割的几何线索|Quanzhu Niu, Yikang Zhou, Shihao Chen, Tao Zhang, Shunping Ji|<http://arxiv.org/pdf/2507.05948v2>|引入几何感知增强视频实例分割的鲁棒性，通过深度估计有效应对遮挡和运动模糊等挑战。|
|🆕 发布|CoSMo: A Multimodal Transformer for Page Stream Segmentation in Comic Books|《CoSMo：一种用于漫画书籍页面流分割的多模态Transformer》|Marc Serra Ortega, Emanuele Vivoli, Artemis Llabrés, Dimosthenis Karatzas|<http://arxiv.org/pdf/2507.10053v1>|提出CoSMo模型，通过多模态Transformer实现漫画书籍页面流分割，提升内容理解自动化水平。|
|🆕 发布|A Brain Tumor Segmentation Method Based on CLIP and 3D U-Net with Cross-Modal Semantic Guidance and Multi-Level Feature Fusion|基于CLIP和3D U-Net的脑肿瘤分割方法：跨模态语义引导与多层次特征融合|Mingda Zhang|<http://arxiv.org/pdf/2507.09966v1>|提出了一种融合CLIP模型与3D U-Net的脑肿瘤分割方法，通过多级特征融合和跨模态语义指导，显著...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Transferring Styles for Reduced Texture Bias and Improved Robustness in Semantic Segmentation Networks|迁移风格以减少纹理偏差并提高语义分割网络稳健性|Ben Hamscher, Edgar Heinert, Annika Mütze, Kira Maag, Matthias Rottmann|<http://arxiv.org/pdf/2507.10239v1>|提出利用风格迁移减少纹理偏见并增强语义分割网络对常见图像损坏和对抗性攻击的鲁棒性。|
|🆕 发布|DEARLi: Decoupled Enhancement of Recognition and Localization for Semi-supervised Panoptic Segmentation|DEARLi：面向半监督全景分割的识别与定位解耦增强|Ivan Martinović, Josip Šarić, Marin Oršić, Matej Kristan, Siniša Šegvić|<http://arxiv.org/pdf/2507.10118v1>|[代码](https://github.com/helen1c/DEARLi.); 提出了一种解耦识别与定位的半监督全景分割方法，有效利用少量标注数据和大量未标注数据，显著提升性能并降...|
|🆕 发布|ESG-Net: Event-Aware Semantic Guided Network for Dense Audio-Visual Event Localization|ESG-Net：面向事件的语义引导网络用于密集音频视觉事件定位|Huilai Li, Yonghao Dang, Ying Xing, Yiming Wang, Jianqin Yin|<http://arxiv.org/pdf/2507.09945v1>|[代码](https://github.com/uchiha99999/ESG-Net.); 提出了一种事件感知的语义引导网络ESG-Net，通过多阶段语义引导和事件关系建模，有效缩小模态语义差...|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ScaffoldAvatar: High-Fidelity Gaussian Avatars with Patch Expressions|"ScaffoldAvatar：高保真高斯化头像与贴片表情"|Shivangi Aneja, Sebastian Weiss, Irene Baeza, Prashanth Chandran, Gaspard Zoss, Matthias Nießner, Derek Bradley|<http://arxiv.org/pdf/2507.10542v1>|提出了一种基于局部 patch 表达的高保真实时 3D 头部 avatar 生成方法，实现了自然运动...|
|🆕 发布|Scene-Aware Conversational ADAS with Generative AI for Real-Time Driver Assistance|具有生成式人工智能的实时驾驶员辅助场景感知对话型高级驾驶辅助系统|Kyungtae Han, Yitao Chen, Rohit Gupta, Onur Altintas|<http://arxiv.org/pdf/2507.10500v1>|提出了一种结合生成式人工智能和视觉理解的场景感知对话型高级驾驶辅助系统，实现实时、自适应的驾驶辅助。|
|🆕 发布|Cameras as Relative Positional Encoding|摄像机作为相对位置编码|Ruilong Li, Brent Yi, Junchen Liu, Hang Gao, Yi Ma, Angjoo Kanazawa|<http://arxiv.org/pdf/2507.10496v1>|提出了一种新的相对位置编码方法PRoPE，利用相机内外参数提升多视角Transformer在3D感知...|
|🆕 发布|RefSTAR: Blind Facial Image Restoration with Reference Selection, Transfer, and Reconstruction|参考选择、迁移与重建的盲人脸图像复原：RefSTAR|Zhicun Yin, Junjie Chen, Ming Liu, Zhixin Wang, Fan Li, Renjing Pei, Xiaoming Li, Rynson W. H. Lau .etc.|<http://arxiv.org/pdf/2507.10470v1>|[代码](https://github.com/yinzhicun/RefSTAR.); 提出了一种考虑参考图像选择、特征转移和重建的盲人脸图像复原方法，有效解决了身份保持问题。|
|📝 更新|PrefixKV: Adaptive Prefix KV Cache is What Vision Instruction-Following Models Need for Efficient Generation|PrefixKV：自适应前缀键值缓存是视觉指令遵循模型实现高效生成所需的关键|Ao Wang, Hui Chen, Jiaxin Li, Jianchao Tan, Kefeng Zhang, Xunliang Cai, Zijia Lin, Jungong Han .etc.|<http://arxiv.org/pdf/2412.03409v3>|[代码](https://github.com/THU-MIG/PrefixKV.); 提出PrefixKV方法，通过自适应调整各层键值缓存大小，提升视觉指令跟随模型生成效率与质量。|
|📝 更新|WASABI: A Metric for Evaluating Morphometric Plausibility of Synthetic Brain MRIs|WASABI：一种用于评估合成脑部MRI形态计量合理性的度量方法|Bahram Jafrasteh, Wei Peng, Cheng Wan, Yimin Luo, Ehsan Adeli, Qingyu Zhao|<http://arxiv.org/pdf/2504.21771v3>|[代码](https://github.com/BahramJafrasteh/wasabi-mri.); 提出WASABI指标，通过比较真实与合成脑部MRI的解剖结构差异，提高了评估合成脑部MRI解剖真实性...|
|🆕 发布|Show and Polish: Reference-Guided Identity Preservation in Face Video Restoration|展示与抛光：基于参考的面向视频修复中的身份保持|Wenkang Han, Wang Lin, Yiyun Zhou, Qi Liu, Shulei Wang, Chang Yao, Jingyuan Chen|<http://arxiv.org/pdf/2507.10293v1>|提出了一种利用高质量参考人脸图像进行身份信息引导的去噪方法，有效解决了严重退化人脸视频恢复中的身份特...|
|🆕 发布|Navigating the Challenges of AI-Generated Image Detection in the Wild: What Truly Matters?|在野外环境中导航AI生成图像检测的挑战：真正重要的是什么？|Despina Konstantinidou, Dimitrios Karageorgiou, Christos Koutlis, Olga Papadopoulou, Emmanouil Schinas, Symeon Papadopoulos|<http://arxiv.org/pdf/2507.10236v1>|揭示了AI生成图像检测模型在现实世界中的不足，并提出改进策略，显著提升了检测性能。|
|🆕 发布|From Wardrobe to Canvas: Wardrobe Polyptych LoRA for Part-level Controllable Human Image Generation|从衣橱到画布：基于部件可控的人像生成 wardpoly 绘画 LoRA 方法|Jeongho Kim, Sunghyun Park, Hyoungwoo Park, Sungrack Yun, Jaegul Choo, Seokeon Cho|<http://arxiv.org/pdf/2507.10217v1>|提出了一种基于衣物的部分级可控模型Wardrobe Polyptych LoRA，无需推理时微调即可...|
|🆕 发布|A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images|无训练、任务无关的框架，用于提高多模态大型语言模型在高分辨率图像上的性能|Jaeseong Lee, Yeeun Choi, Heechan Choi, Hanjung Kim, Seonjoo Kim|<http://arxiv.org/pdf/2507.10202v1>|[代码](https://github.com/yenncye/ECP.); 提出了一种无需训练、任务无关的框架ECP，通过先识别候选区域再预测，有效提升MLLM在高分辨率图像上...|
|📝 更新|M2DAO-Talker: Harmonizing Multi-granular Motion Decoupling and Alternating Optimization for Talking-head Generation|M2DAO-Talker：结合多粒度运动解耦与交替优化生成说话人头像|Kui Jiang, Shiyu Liu, Junjun Jiang, Xin Yang, Hongxun Yao, Xiaopeng Fan|<http://arxiv.org/pdf/2507.08307v2>|[代码](https://m2dao-talker.github.io/M2DAO-Talk.github.io.); 提出了一种多粒度运动解耦与交替优化方法，有效解决了说话人头生成中的运动模糊和局部穿透问题，实现了更高...|
|📝 更新|Guided Neural Schrödinger bridge for Brain MR image synthesis with Limited Data|受限数据下基于引导神经薛定谔桥的脑部磁共振图像合成|Hanyeol Yang, Sunggyu Kim, Mi Kyung Kim, Yongseon Yoo, Yu-Mi Kim, Min-Ho Shin, Insung Chung, Sang Baek Koh .etc.|<http://arxiv.org/pdf/2501.14171v2>|定位：合成脑部磁共振成像，数据有限；方法：提出FGSB框架，实现高保真生成。|
|📝 更新|MG-Gen: Single Image to Motion Graphics Generation|MG-Gen：单张图像到动态图形生成|Takahiro Shirakawa, Tomoyuki Suzuki, Takuto Narumoto, Daichi Haraguchi|<http://arxiv.org/pdf/2504.02361v3>|[代码](https://github.com/CyberAgentAILab/MG-GEN.); 提出MG-Gen框架，直接将单张图像转化为动态运动图形，保持文本可读性和图像真实性。|
|📝 更新|Democratizing High-Fidelity Co-Speech Gesture Video Generation|实现高保真协同语音手势视频生成的普及化|Xu Yang, Shaoli Huang, Shenbo Xie, Xuelin Chen, Yifei Liu, Changxing Ding|<http://arxiv.org/pdf/2507.06812v2>|[代码](https://mpi-lab.github.io/Democratizing-CSG); 提出了一种高效框架，利用2D全身骨骼辅助生成与音频同步的高保真手势视频，并公开了首个大规模数据集。|
|📝 更新|HANDI: Hand-Centric Text-and-Image Conditioned Video Generation|HANDI：基于手部的文本和图像条件视频生成|Yayuan Li, Zhi Cao, Jason J. Corso|<http://arxiv.org/pdf/2412.04189v5>|[代码](https://excitedbutter.github.io/project_page); 提出了一种以手部动作为核心的文本和图像条件视频生成方法，通过自动确定动作区域和引入手部细化损失，显著...|
|🆕 发布|SpeakerVid-5M: A Large-Scale High-Quality Dataset for Audio-Visual Dyadic Interactive Human Generation|SpeakerVid-5M：一种大规模高质量音频-视觉双人互动人类生成数据集|Youliang Zhang, Zhaoyang Li, Duomin Wang, Jiahe Zhang, Deyu Zhou, Zixin Yin, Xili Dai, Gang Yu .etc.|<http://arxiv.org/pdf/2507.09862v1>|[代码](https://dorniwang.github.io/SpeakerVid-5M); 提出了首个大规模、高质量的数据集SpeakerVid-5M，用于生成音频视觉双向互动虚拟人类。|
|🆕 发布|Generative Audio Language Modeling with Continuous-valued Tokens and Masked Next-Token Prediction|基于连续值标记和遮蔽下一个标记预测的生成式音频语言建模|Shu-wen Yang, Byeonggeun Kim, Kuan-Po Huang, Qingming Tang, Huy Phan, Bo-Ru Lu, Harsha Sundar, Shalini Ghosh .etc.|<http://arxiv.org/pdf/2507.09834v1>|提出了一种连续值标记的生成性音频语言模型，通过掩码下一个标记预测实现了优于现有方法的音频生成质量。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Gamma: Toward Generic Image Assessment with Mixture of Assessment Experts|“Gamma：面向混合评估专家的通用图像评估方法”|Hantao Zhou, Rui Yang, Longxiang Tang, Guanyi Qin, Runze Hu, Xiu Li|<http://arxiv.org/pdf/2503.06678v2>|[代码](https://github.com/zht8506/Gamma.); 提出了一种通用图像评估模型Gamma，通过混合数据集训练和专家模块，有效覆盖多种评估场景。|
|🆕 发布|Text-Visual Semantic Constrained AI-Generated Image Quality Assessment|文本-视觉语义约束下AI生成图像质量评估|Qiang Li, Qingsen Yan, Haojian Huang, Peng Wu, Haokui Zhang, Yanning Zhang|<http://arxiv.org/pdf/2507.10432v1>|[代码](https://github.com/mozhu1/SC-AGIQA.); 提出了一种融合文本视觉语义约束的AI生成图像质量评估框架，有效解决了语义错位和细节感知缺失问题。|
|🆕 发布|4D-Animal: Freely Reconstructing Animatable 3D Animals from Videos|4D-Animal：从视频中自由重建可动画化的三维动物模型|Shanshan Zhong, Jiawei Peng, Zehan Zheng, Zhongzhan Huang, Wufei Ma, Guofeng Zhang, Qihao Liu, Alan Yuille .etc.|<http://arxiv.org/pdf/2507.10437v1>|[代码](https://github.com/zhongshsh/4D-Animal.); 提出了一种无需稀疏关键点标注，利用密集特征网络和分层对齐策略从视频重建可动画化3D动物的新框架。|
|📝 更新|A Survey on Future Frame Synthesis: Bridging Deterministic and Generative Approaches|未来帧合成综述：桥接确定性方法与生成性方法|Ruibo Ming, Zhewei Huang, Jingwei Wu, Zhuoxuan Ju, Daxin Jiang, Jianming Hu, Lihui Peng, Shuchang Zhou|<http://arxiv.org/pdf/2401.14718v8>|提出未来帧合成新分类法，桥接确定性算法与生成模型，推动视觉动态建模发展。|
|🆕 发布|Glance-MCMT: A General MCMT Framework with Glance Initialization and Progressive Association|《Glance-MCMT：一种具有快速初始化和逐步关联的通用多模态协同跟踪框架》|Hamidreza Hashempoor|<http://arxiv.org/pdf/2507.10115v1>|提出了一种多摄像头多目标跟踪框架，通过轨迹和外观线索实现全局身份一致性。|
|🆕 发布|Binomial Self-Compensation: Mechanism and Suppression of Motion Error in Phase-Shifting Profilometry|二项式自补偿：相移轮廓测量中运动误差的机制与抑制|Geyou Zhang, Kai Liu, Ce Zhu|<http://arxiv.org/pdf/2507.10009v1>|提出了一种相位序列和图像序列的二元自补偿方法，有效减少了运动误差并提高了计算效率。|
|🆕 发布|Resolution Revolution: A Physics-Guided Deep Learning Framework for Spatiotemporal Temperature Reconstruction|分辨率革命：一种基于物理引导的深度学习框架用于时空温度重建|Shengjie Liu, Lu Zhang, Siqin Wang|<http://arxiv.org/pdf/2507.09872v1>|提出了一种融合物理规律的深度学习框架，实现了高时空分辨率温度数据的重构。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|UniQA: Unified Vision-Language Pre-training for Image Quality and Aesthetic Assessment|统一视觉-语言预训练：用于图像质量和审美评估|Hantao Zhou, Longxiang Tang, Rui Yang, Guanyi Qin, Yan Zhang, Yutao Li, Xiu Li, Runze Hu .etc.|<http://arxiv.org/pdf/2406.01069v2>|[代码](https://github.com/zht8506/UniQA.); 提出了一种统一视觉-语言预训练模型UniQA，通过结合图像质量和美学评估任务，提升了评估准确性和泛化...|
|📝 更新|Structure-Guided Diffusion Models for High-Fidelity Portrait Shadow Removal|结构引导的扩散模型用于高保真度人像阴影移除|Wanchang Yu, Qing Zhang, Rongjia Zheng, Wei-Shi Zheng|<http://arxiv.org/pdf/2507.04692v2>|[代码](https://github.com/wanchang-yu/Structure-Guided-Diffusion-for-Portrait-Shadow-Removal.); 提出结构引导的扩散模型，用于高保真度人像阴影去除，有效避免了常见问题如面部特征扭曲和细节丢失。|
|🆕 发布|Text Embedding Knows How to Quantize Text-Guided Diffusion Models|文本嵌入知道如何量化文本引导的扩散模型|Hongjae Lee, Myungjun Son, Dongjea Kang, Seung-Won Jung|<http://arxiv.org/pdf/2507.10340v1>|提出QLIP方法，利用文本提示优化扩散模型量化，降低计算复杂度并提升图像质量。|
|📝 更新|RIPE: Reinforcement Learning on Unlabeled Image Pairs for Robust Keypoint Extraction|RIPE：在未标记图像对上进行强化学习以实现鲁棒关键点提取|Johannes Künzel, Anna Hilsmann, Peter Eisert|<http://arxiv.org/pdf/2507.04839v2>|[代码](https://github.com/fraunhoferhhi/RIPE.); 提出了一种基于弱监督强化学习的关键点提取框架，仅需成对图像的二元标签，实现了高效泛化的关键点检测与描...|
|📝 更新|Imagine for Me: Creative Conceptual Blending of Real Images and Text via Blended Attention|为我想象：通过混合注意力实现真实图像与文本的创造性概念融合|Wonwoong Cho, Yanxia Zhang, Yan-Ying Chen, David I. Inouye|<http://arxiv.org/pdf/2506.24085v2>|提出了一种自动化的图像与文本概念混合方法IT-Blender，有效克服人类认知偏见，增强创意设计。|
|📝 更新|Easi3R: Estimating Disentangled Motion from DUSt3R Without Training|Easi3R：无需训练从DUSt3R估计解耦运动|Xingyu Chen, Yue Chen, Yuliang Xiu, Andreas Geiger, Anpei Chen|<http://arxiv.org/pdf/2503.24391v2>|提出了一种无需训练的4D重建方法Easi3R，通过注意力机制自适应实现动态场景重建。|
|🆕 发布|Deep Recurrence for Dynamical Segmentation Models|深度递归用于动态分割模型|David Calhas, Arlindo L. Oliveira|<http://arxiv.org/pdf/2507.10143v1>|[代码](https://github.com/DCalhas/feedback_segmentation.); 引入反馈循环以迭代优化内部状态，提升视觉模型在噪声环境和少量监督下的性能与泛化能力。|
|🆕 发布|Frequency Regulation for Exposure Bias Mitigation in Diffusion Models|扩散模型中曝光偏差缓解的频率调节|Meng Yu, Kun Zhan|<http://arxiv.org/pdf/2507.10072v1>|[代码](https://github.com/kunzhan/wpp.); 提出了一种基于频率域调节的扩散模型曝光偏差缓解方法，通过独立调整低频高频子带，提升了生成质量。|
|📝 更新|VIVID-10M: A Dataset and Baseline for Versatile and Interactive Video Local Editing|VIVID-10M：一种用于多样化交互式视频局部编辑的数据集和基线|Jiahao Hu, Tianxiong Zhong, Xuebo Wang, Boyuan Jiang, Xingye Tian, Fei Yang, Pengfei Wan, Di Zhang|<http://arxiv.org/pdf/2411.15260v2>|[代码](https://kwaivgi.github.io/VIVID); 提出了VIVID-10M数据集和VIVID模型，实现了高效互动视频局部编辑。|
|📝 更新|Re-boosting Self-Collaboration Parallel Prompt GAN for Unsupervised Image Restoration|重新增强自协作并行提示生成对抗网络用于无监督图像恢复|Xin Lin, Yuyan Zhou, Jingtong Yue, Chao Ren, Kelvin C. K. Chan, Lu Qi, Ming-Hsuan Yang|<http://arxiv.org/pdf/2408.09241v2>|[代码](https://github.com/linxin0/RSCP2GAN.); 提出了一种自协作策略，通过迭代优化伪图像对，显著提升了无监督图像复原性能而不增加计算复杂度。|
|🆕 发布|Memory-Efficient Personalization of Text-to-Image Diffusion Models via Selective Optimization Strategies|通过选择性优化策略实现内存高效的文本到图像扩散模型的个性化|Seokeon Choi, Sunghyun Park, Hyoungwoo Park, Jeongho Kim, Sungrack Yun|<http://arxiv.org/pdf/2507.10029v1>|提出了一种选择性优化框架，通过结合低分辨率图像的回传传播和高分辨率图像的零阶优化，实现了内存高效的文...|
|🆕 发布|Latent Diffusion Models with Masked AutoEncoders|带有遮蔽自编码器的潜在扩散模型|Junho Lee, Jeongwoo Shin, Hyungwook Choi, Joonseok Lee|<http://arxiv.org/pdf/2507.09984v1>|提出Variational Masked AutoEncoders，提升了Latent Diffus...|
|📝 更新|DNF-Intrinsic: Deterministic Noise-Free Diffusion for Indoor Inverse Rendering|确定性无噪声扩散的室内逆向渲染：DNF-Intrinsic|Rongjia Zheng, Qing Zhang, Chengjiang Long, Wei-Shi Zheng|<http://arxiv.org/pdf/2507.03924v2>|提出了一种直接利用原图像而非噪声预测内在属性的高效室内逆向渲染方法，显著提升了渲染质量和物理真实性。|
|📝 更新|Unraveling the Connections between Flow Matching and Diffusion Probabilistic Models in Training-free Conditional Generation|解开无训练条件生成中流匹配与扩散概率模型之间的联系|Kaiyu Song, Hanjiang Lai|<http://arxiv.org/pdf/2411.07625v2>|提出Flow Matching-based Posterior Sampling方法，通过引入校正项...|
|📝 更新|A General Framework for Inference-time Scaling and Steering of Diffusion Models|用于推理时扩散模型缩放和控制的通用框架|Raghav Singhal, Zachary Horvitz, Ryan Teehan, Mengye Ren, Zhou Yu, Kathleen McKeown, Rajesh Ranganath|<http://arxiv.org/pdf/2501.06848v4>|[代码](https://github.com/zacharyhorvitz/Fk-Diffusion-Steering); 提出了一种在推理时控制扩散模型生成样本质量的方法，通过奖励函数实现高效且无需训练的样本优化。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Dual Data Alignment Makes AI-Generated Image Detector Easier Generalizable|双数据对齐使AI生成图像检测器更易于泛化|Ruoxin Chen, Junwei Xi, Zhiyuan Yan, Ke-Yue Zhang, Shuang Wu, Jingyi Xie, Xu Chen, Lei Xu .etc.|<http://arxiv.org/pdf/2505.14359v4>|提出双数据对齐方法，有效解决检测器在非偏置数据集上的性能退化问题，提升泛化能力。|
|📝 更新|Concept Steerers: Leveraging K-Sparse Autoencoders for Test-Time Controllable Generations|概念引导器：利用K稀疏自动编码器实现测试时可控生成|Dahye Kim, Deepti Ghadiyaram|<http://arxiv.org/pdf/2501.19066v2>|[代码](https://github.com/kim-dahye/steerers); 提出了一种利用k稀疏自动编码器的框架，有效控制生成图像中的特定概念，提升了安全性且不牺牲生成质量。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GaussianOcc: Fully Self-supervised and Efficient 3D Occupancy Estimation with Gaussian Splatting|高斯占用：基于高斯散点投影的全自监督且高效的三维占用估计|Wanshui Gan, Fang Liu, Hongbin Xu, Ningkai Mo, Naoto Yokoya|<http://arxiv.org/pdf/2408.11447v4>|[代码](https://github.com/GANWANSHUI/GaussianOcc.git.); 提出GaussianOcc方法，通过Gaussian splatting实现无需真实位姿的完全自监督...|
|📝 更新|BayesSDF: Surface-Based Laplacian Uncertainty Estimation for 3D Geometry with Neural Signed Distance Fields|贝叶斯SDF：基于表面的拉普拉斯不确定性估计用于三维几何的神经符号距离场|Rushil Desai|<http://arxiv.org/pdf/2507.06269v2>|提出了BayesSDF方法，通过Laplace近似为神经隐式SDF模型提供高效、基于表面的不确定性量...|
|📝 更新|Sparfels: Fast Reconstruction from Sparse Unposed Imagery|稀疏无定位图像的快速重建：Sparfels方法|Shubhendu Jena, Amine Ouasfi, Mae Younes, Adnane Boukhayma|<http://arxiv.org/pdf/2505.02178v2>|提出了一种高效的稀疏视角重建方法，利用3D基础模型和2D高斯溅射技术，在无需精确相机设置的条件下实现...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HGSLoc: 3DGS-based Heuristic Camera Pose Refinement|基于3DGS启发式的相机位姿精炼方法：HGSLoc|Zhongyan Niu, Zhen Tan, Jinpu Zhang, Xueliang Yang, Dewen Hu|<http://arxiv.org/pdf/2409.10925v3>|[代码](https://github.com/anchang699/HGSLoc.); 提出了一种结合3D重建和启发式优化策略的轻量级相机位姿精炼框架，提高了定位准确性并降低了噪声影响。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MoVieS: Motion-Aware 4D Dynamic View Synthesis in One Second|《MoVieS：一秒内实现运动感知的4D动态视图合成》|Chenguo Lin, Yuchen Lin, Panwang Pan, Yifan Yu, Honglei Yan, Katerina Fragkiadaki, Yadong Mu|<http://arxiv.org/pdf/2507.10065v1>|提出了一种快速合成立体动态视图的模型MoVieS，统一处理外观、几何和运动信息。|
|🆕 发布|MCGA: Mixture of Codebooks Hyperspectral Reconstruction via Grayscale-Aware Attention|基于灰度感知注意力的码本混合高光谱重建方法MCGA|Zhanjiang Yang, Lijun Sun, Jiawei Dong, Xiaoxin An, Yang Liu, Meng Li|<http://arxiv.org/pdf/2507.09885v1>|[代码](https://github.com/Fibonaccirabbit/MCGA); 提出了一种两阶段 hyperspectral 图像重构方法 MCGA，通过学习光谱模式并引入灰度感知...|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EmbRACE-3K: Embodied Reasoning and Action in Complex Environments|EmbRACE-3K：复杂环境中的具身推理与行动|Mingxian Lin, Wei Huang, Yitang Li, Chengjie Jiang, Kui Wu, Fangwei Zhong, Shengju Qian, Xin Wang .etc.|<http://arxiv.org/pdf/2507.10548v1>|提出了EmRACE-3K数据集，通过多样化任务和评估标准，提升了视觉语言模型在交互环境中的推理和行动...|
|🆕 发布|ProGait: A Multi-Purpose Video Dataset and Benchmark for Transfemoral Prosthesis Users|“ProGait：一种用于大腿假肢用户的多功能视频数据集和基准测试”|Xiangyu Yin, Boyuan Yang, Weichen Liu, Qiyao Xue, Abrar Alamri, Goeran Fiedler, Wei Gao|<http://arxiv.org/pdf/2507.10223v1>|[代码](https://github.com/pittisl/ProGait); 提出了ProGait多用途视频数据集，为假肢用户提供了基于视觉的步态分析解决方案。|
|🆕 发布|Probabilistic Human Intent Prediction for Mobile Manipulation: An Evaluation with Human-Inspired Constraints|移动操作中基于概率的人类意图预测：结合人类启发式约束的评价研究|Cesar Alan Contreras, Manolis Chiou, Alireza Rastegarpanah, Michal Szulik, Rustam Stolkin|<http://arxiv.org/pdf/2507.10131v1>|提出GUIDER框架，通过双阶段概率推理显著提升机器人对人类意图的准确预测。|
|🆕 发布|OpenHuman4D: Open-Vocabulary 4D Human Parsing|《OpenHuman4D：开放式词汇四维人体解析》|Keito Suzuki, Bang Du, Runfa Blark Li, Kunyao Chen, Lei Wang, Peng Liu, Ning Bi, Truong Nguyen|<http://arxiv.org/pdf/2507.09880v1>|首次提出开放词汇4D人体解析框架，通过减少推理时间和支持动态类别，解决了现有方法在虚拟现实应用中的限...|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ViTCoT: Video-Text Interleaved Chain-of-Thought for Boosting Video Understanding in Large Language Models|ViTCoT：视频-文本交织链式思维模型，用于提升大型语言模型中的视频理解能力|Yongheng Zhang, Xu Liu, Ruihan Tao, Qiguang Chen, Hao Fei, Wanxiang Che, Libo Qin|<http://arxiv.org/pdf/2507.09876v1>|提出ViTCoT方法，融合视频与文本信息，提升大型语言模型视频理解能力。|
|📝 更新|LVAgent: Long Video Understanding by Multi-Round Dynamical Collaboration of MLLM Agents|LVAgent：通过多轮动态协作的长视频理解MLLM代理|Boyu Chen, Zhengrong Yue, Siran Chen, Zikang Wang, Yang Liu, Peng Li, Yali Wang|<http://arxiv.org/pdf/2503.10200v3>|[代码](https://github.com/64327069/LVAgent.); 提出LVAgent框架，通过多轮动态协作的多语言模型代理改善长视频理解性能。|
|📝 更新|Video Individual Counting for Moving Drones|移动无人机的视频个体计数|Yaowu Fan, Jia Wan, Tao Han, Antoni B. Chan, Andy J. Ma|<http://arxiv.org/pdf/2503.10701v2>|提出 MovingDroneCrowd 数据集和 SDNet 方法，解决动态拥挤场景中个体计数问题。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Adversarial Augmentation Training Makes Action Recognition Models More Robust to Realistic Video Distribution Shifts|对抗性增强训练使动作识别模型对现实视频分布偏移更具鲁棒性|Kiyoon Kim, Shreyank N Gowda, Panagiotis Eustratiadis, Antreas Antoniou, Robert B Fisher|<http://arxiv.org/pdf/2401.11406v2>|提出对抗性增强训练方法，增强视频动作识别模型对实际视频分布偏移的鲁棒性。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FIX-CLIP: Dual-Branch Hierarchical Contrastive Learning via Synthetic Captions for Better Understanding of Long Text|FIX-CLIP：通过合成字幕进行双分支层次对比学习以更好地理解长文本|Bingchao Wang, Zhiwei Ning, Jianyu Ding, Xuanang Gao, Yin Li, Dongsheng Jiang, Jie Yang, Wei Liu|<http://arxiv.org/pdf/2507.10095v1>|提出FIX-CLIP模型，通过双分支训练和区域信息提取，有效提升长文本在CLIP中的表现。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Quantize-then-Rectify: Efficient VQ-VAE Training|量化后校正：高效VQ-VAE训练|Borui Zhang, Qihang Rao, Wenzhao Zheng, Jie Zhou, Jiwen Lu|<http://arxiv.org/pdf/2507.10547v1>|提出了一种高效的VQ-VAE训练框架ReVQ，通过利用预训练VAE和创新的量化策略，大幅降低了训练成...|
|📝 更新|Enabling Advanced Land Cover Analytics: An Integrated Data Extraction Pipeline for Predictive Modeling with the Dynamic World Dataset|实现高级土地覆盖分析：基于动态世界数据集的预测建模集成数据提取管道|Victor Radermecker, Andrea Zanon, Nancy Thomas, Annita Vapsi, Saba Rahimi, Rama Ramakrishnan, Daniel Borrajo|<http://arxiv.org/pdf/2410.09135v2>|提出了一种高效灵活的数据处理流程，使研究者能便捷利用Dynamic World数据集进行土地覆盖分析...|
|🆕 发布|The Power of Certainty: How Confident Models Lead to Better Segmentation|《确定性的力量：如何通过置信度高的模型实现更好的分割》|Tugberk Erol, Tuba Caglikantar, Duygu Sarikaya|<http://arxiv.org/pdf/2507.10490v1>|提出了一种基于自信度的自蒸馏方法，减少资源需求同时提升息肉分割性能和泛化能力。|
|🆕 发布|Spatial Lifting for Dense Prediction|空间提升用于密集预测|Mingzhi Xu, Yizhe Zhang|<http://arxiv.org/pdf/2507.10222v1>|提出空间提升方法，通过将图像升维至高维空间处理，降低模型参数和推理成本，提升密集预测任务性能。|
|📝 更新|CoMoGaussian: Continuous Motion-Aware Gaussian Splatting from Motion-Blurred Images|《CoMoGaussian：从运动模糊图像中连续运动感知高斯绘制》|Jungho Lee, Donghyeong Kim, Dogyoon Lee, Suhwan Cho, Minhyeok Lee, Wonjoon Lee, Taeoh Kim, Dongyoon Wee .etc.|<http://arxiv.org/pdf/2503.05332v2>|提出了一种连续运动感知的高斯渲染方法，从运动模糊图像中精确重建三维场景。|
|📝 更新|ECORE: Energy-Conscious Optimized Routing for Deep Learning Models at the Edge|边缘计算中考虑能耗的深度学习模型优化路由算法（ECORE）|Daghash K. Alqahtani, Maria A. Rodriguez, Muhammad Aamir Cheema, Hamid Rezatofighi, Adel N. Toosi|<http://arxiv.org/pdf/2507.06011v2>|提出ECORE框架，动态平衡边缘计算中的能耗和检测精度，实现高效的对象检测。|
|📝 更新|CLiFT: Compressive Light-Field Tokens for Compute-Efficient and Adaptive Neural Rendering|CLiFT：用于计算高效和自适应神经渲染的压缩光场标记|Zhengqing Wang, Yuefan Wu, Jiacheng Chen, Fuyang Zhang, Yasutaka Furukawa|<http://arxiv.org/pdf/2507.08776v2>|提出了一种压缩光场标记的神经渲染方法，通过调整标记数量实现计算效率与渲染质量的平衡。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Random Erasing vs. Model Inversion: A Promising Defense or a False Hope?|随机擦除与模型反转：一个有前景的防御策略还是一场空希望？|Viet-Hung Tran, Ngoc-Bao Nguyen, Son T. Mai, Hans Vandierendonck, Ira Assent, Alex Kot, Ngai-Man Cheung|<http://arxiv.org/pdf/2409.01062v2>|发现随机擦除能有效防御模型反转攻击，实现隐私保护与性能的平衡。|
|📝 更新|Alignment and Adversarial Robustness: Are More Human-Like Models More Secure?|《对齐与对抗鲁棒性：更接近人类的模型是否更安全？》|Blaine Hoak, Kunyang Li, Patrick McDaniel|<http://arxiv.org/pdf/2502.12377v2>|探究了模型与人眼视觉一致性对对抗性攻击鲁棒性的影响，发现特定一致性指标能有效预测鲁棒性。|
|🆕 发布|RAPNet: A Receptive-Field Adaptive Convolutional Neural Network for Pansharpening|RAPNet：一种适用于全色锐化的感受野自适应卷积神经网络|Tao Tang, Chengxu Yang|<http://arxiv.org/pdf/2507.10461v1>|RAPNet通过内容自适应卷积和注意力机制，有效融合高低分辨率图像，提升远程传感数据的空间细节提取精...|
|📝 更新|MGA-Net: A Novel Mask-Guided Attention Neural Network for Precision Neonatal Brain Imaging|MGA-Net：一种用于精确新生儿脑成像的新型掩模引导注意力神经网络|Bahram Jafrasteh, Simon Pedro Lubian-Lopez, Emiliano Trimarco, Macarena Roman Ruiz, Carmen Rodriguez Barrios, Yolanda Marin Almagro, Isabel Benavente-Fernandez|<http://arxiv.org/pdf/2406.17709v3>|[代码](https://github.com/BahramJafrasteh/MGA-Net); 提出MGA-Net，一种用于精确新生儿脑成像的掩模引导注意力神经网络，提升了脑部提取和重建的精度。|
|🆕 发布|Devanagari Handwritten Character Recognition using Convolutional Neural Network|使用卷积神经网络进行天城文手写字符识别|Diksha Mehta, Prateek Mehta|<http://arxiv.org/pdf/2507.10398v1>|提出了一种使用双层卷积神经网络识别手写Devanagari字符的方法，实现了高识别准确率。|
|🆕 发布|Straighten Viscous Rectified Flow via Noise Optimization|通过噪声优化拉直粘性修正流|Jimin Dai, Jiexi Yan, Jian Yang, Lei Luo|<http://arxiv.org/pdf/2507.10218v1>|提出了一种通过噪声优化整合编码器和神经速度场的VRFNO方法，有效解决了Reflow生成高质量图像速...|
|📝 更新|CVVNet: A Cross-Vertical-View Network for Gait Recognition|CVVNet：一种用于步态识别的跨垂直视角网络|Xiangru Li, Wei Song, Yingda Huang, Wei Meng, Le Chang|<http://arxiv.org/pdf/2505.01837v2>|提出CVVNet网络，通过多尺度特征提取和动态融合机制，有效应对不同视角下的步态识别挑战。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GT-Loc: Unifying When and Where in Images Through a Joint Embedding Space|GT-Loc：通过联合嵌入空间统一图像中的何时与何地|David G. Shatwell, Ishan Rajendrakumar Dave, Sirnam Swetha, Mubarak Shah|<http://arxiv.org/pdf/2507.10473v1>|提出了一种统一预测图像拍摄时间和地点的方法，通过共享特征空间提升了时间预测准确性。|
|🆕 发布|Numerically Computing Galois Groups of Minimal Problems|数值计算最小问题的高斯群|Timothy Duff|<http://arxiv.org/pdf/2507.10407v1>|提出测量解决参数化代数方程组困难度的方法，并推进实用解决策略。|
|🆕 发布|Beyond Graph Model: Reliable VLM Fine-Tuning via Random Graph Adapter|超越图模型：通过随机图适配器实现可靠的视觉语言模型微调|Bo Jiang, Xueyang Ze, Beibei Wang, Xixi Wang, Xixi Wan, Bin Luo|<http://arxiv.org/pdf/2507.10355v1>|提出随机图模型VRGAdapter，通过概率消息传播学习文本描述多样性，增强视觉模型微调效果。|
|📝 更新|On the development of an AI performance and behavioural measures for teaching and classroom management|关于开发用于教学和课堂管理的人工智能性能与行为度量方法|Andreea I. Niculescu, Jochen Ehnes, Chen Yi, Du Jiawei, Tay Chiat Pin, Joey Tianyi Zhou, Vigneshwaran Subbaraju, Teh Kah Kuan .etc.|<http://arxiv.org/pdf/2506.11143v2>|开发了一种AI驱动的课堂动态分析工具，通过多模态传感器数据支持教师发展和教学策略改进。|
|🆕 发布|Is Micro-expression Ethnic Leaning?|微表情是否存在种族倾向性？|Huai-Qian Khor, Yante Li, Xingxun Jiang, Guoying Zhao|<http://arxiv.org/pdf/2507.10209v1>|[代码](https://github.com/IcedDoggie/ICMEW2025_EthnicMER); 探讨了种族背景对微表情识别的影响，并提出了一个融入种族背景的情感特征学习框架。|
|📝 更新|MGVQ: Could VQ-VAE Beat VAE? A Generalizable Tokenizer with Multi-group Quantization|MGVQ：VQ-VAE能否超越VAE？具有多组量化的通用标记器|Mingkai Jia, Wei Yin, Xiaotao Hu, Jiaxin Guo, Xiaoyang Guo, Qian Zhang, Xiao-Xiao Long, Ping Tan|<http://arxiv.org/pdf/2507.07997v2>|[代码](https://github.com/MKJia/MGVQ.); 提出MGVQ方法，通过多组量化增强VQ-VAE的表现力，显著提升图像重建质量。|
|🆕 发布|IM-LUT: Interpolation Mixing Look-Up Tables for Image Super-Resolution|IM-LUT：图像超分辨率插值混合查找表|Sejin Park, Sangmin Lee, Kyong Hwan Jin, Seung-Won Jung|<http://arxiv.org/pdf/2507.09923v1>|提出IM-LUT框架，通过学习混合插值函数提升任意尺度图像超分辨率的质量和效率。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|On the Robustness Tradeoff in Fine-Tuning|关于微调中的鲁棒性权衡|Kunyang Li, Jean-Charles Noirot Ferrand, Ryan Sheatsley, Blaine Hoak, Yohan Beugin, Eric Pauley, Patrick McDaniel|<http://arxiv.org/pdf/2503.14836v2>|揭示了模型微调过程中鲁棒性与准确性之间的权衡关系，并提出了针对不同任务的有效微调策略。|
|📝 更新|SCOOTER: A Human Evaluation Framework for Unrestricted Adversarial Examples|SCOOTER：一种针对无限制对抗样本的人类评估框架|Dren Fazlija, Monty-Maximilian Zühlke, Johanna Schrader, Arkadij Orlov, Clara Stein, Iyiola E. Olatunji, Daniel Kudenko|<http://arxiv.org/pdf/2507.07776v2>|引入SCOOTER框架，通过大规模人类评估揭示了无限制对抗样本对人类视觉的不可见性不足。|
|🆕 发布|Learning Private Representations through Entropy-based Adversarial Training|通过基于熵的对抗训练学习私有表示|Tassilo Klein, Moin Nabi|<http://arxiv.org/pdf/2507.10194v1>|提出了一种通过熵值对抗训练学习隐私保护的表征方法，有效平衡了预测能力和隐私保护。|


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Minimizing the Pretraining Gap: Domain-aligned Text-Based Person Retrieval|缩小预训练差距：基于文本的人物检索领域对齐|Shuyu Yang, Yaxiong Wang, Yongrui Li, Li Zhu, Zhedong Zheng|<http://arxiv.org/pdf/2507.10195v1>|[代码](https://github.com/Shuyu-XJTU/MRA.); 提出了一种双级别域自适应方法，有效缩小了合成数据预训练与真实世界数据之间的差距，提升了文本基础的人物...|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Taming Modern Point Tracking for Speckle Tracking Echocardiography via Impartial Motion|通过公正运动驯服现代点追踪技术用于斑点追踪超声心动图|Md Abulkalam Azad, John Nyberg, Håvard Dalen, Bjørnar Grenne, Lasse Lovstakken, Andreas Østvik|<http://arxiv.org/pdf/2507.10127v1>|通过优化训练策略和提出轻量级网络，显著提升了点追踪技术在超声心动图中的运动估计准确性和泛化能力。|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Uncertainty Quantification for Incomplete Multi-View Data Using Divergence Measures|使用散度度量对不完整多视角数据的 uncertainty 定量分析|Zhipeng Xue, Yan Zhang, Ming Li, Chun Li, Yue Liu, Fei Yu|<http://arxiv.org/pdf/2507.09980v1>|提出基于Holder散度的KPHD-Net，融合Dempster-Shafer证据理论，提升多视角数...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Self-supervised Learning on Camera Trap Footage Yields a Strong Universal Face Embedder|基于相机陷阱视频的自监督学习产生了一种强大的通用面部嵌入器|Vladimir Iashin, Horace Lee, Dan Schofield, Andrew Zisserman|<http://arxiv.org/pdf/2507.10552v1>|利用无标签摄像头捕获数据，提出自监督学习法，实现强大的通用面部特征提取。|
|🆕 发布|Privacy-Preserving Multi-Stage Fall Detection Framework with Semi-supervised Federated Learning and Robotic Vision Confirmation|隐私保护的基于半监督联邦学习和机器人视觉确认的多阶段跌倒检测框架|Seyed Alireza Rahimi Azghadi, Truong-Thanh-Hung Nguyen, Helene Fournier, Monica Wachowicz, Rene Richard, Francis Palma, Hung Cao|<http://arxiv.org/pdf/2507.10474v1>|提出了一种结合半监督联邦学习和机器人视觉确认的隐私保护多阶段跌倒检测框架，实现了高准确性和隐私保护。|
|🆕 发布|CLA: Latent Alignment for Online Continual Self-Supervised Learning|CLA: 用于在线持续自监督学习的潜在对齐|Giacomo Cignoni, Andrea Cossu, Alexandra Gomez-Villa, Joost van de Weijer, Antonio Carta|<http://arxiv.org/pdf/2507.10434v1>|提出了一种在线连续自监督学习策略CLA，通过 latent representation 对齐减少遗...|
|🆕 发布|Boosting Multimodal Learning via Disentangled Gradient Learning|通过解耦梯度学习提升多模态学习|Shicai Wei, Chunbo Luo, Yang Luo|<http://arxiv.org/pdf/2507.10213v1>|[代码](https://github.com/shicaiwei123/ICCV2025-GDL); 提出了解决多模态学习优化冲突的方法，通过分离梯度学习提升了各模态性能。|
|📝 更新|A review of advancements in low-light image enhancement using deep learning|深度学习在低光照图像增强中的进展综述|Fangxue Liu, Lei Fan|<http://arxiv.org/pdf/2505.05759v2>|系统评估了深度学习在低光照图像增强中的应用，揭示了增强技术对视觉任务性能的影响。|
|📝 更新|Frenet-Serret Frame-based Decomposition for Part Segmentation of 3D Curvilinear Structures|基于Frenet-Serret帧的分解用于三维曲线结构的部分分割|Leslie Gu, Jason Ken Adhinarta, Mikhail Bessmeltsev, Jiancheng Yang, Yongjie Jessica Zhang, Wenjie Yin, Daniel Berger, Jeff Lichtman .etc.|<http://arxiv.org/pdf/2404.14435v3>|提出了一种基于Frenet-Serret框架的分解方法，实现了对3D曲线结构的精确分割并提高了学习效...|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Can GPT-4o mini and Gemini 2.0 Flash Predict Fine-Grained Fashion Product Attributes? A Zero-Shot Analysis|GPT-4o mini 和 Gemini 2.0 Flash 能否预测细粒度时尚产品属性？一种零样本分析|Shubham Shukla, Kunal Sonalkar|<http://arxiv.org/pdf/2507.09950v1>|[代码](https://github.com/yumingj/DeepFashion-MultiModal); 评估了GPT-4o-mini和Gemini 2.0 Flash在细粒度时尚属性识别中的零样本性能，G...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Visual Test-time Scaling for GUI Agent Grounding|视觉测试时缩放用于GUI智能体定位|Tiange Luo, Lajanugen Logeswaran, Justin Johnson, Honglak Lee|<http://arxiv.org/pdf/2505.00684v2>|[代码](https://github.com/tiangeluo/RegionFocus.); 提出视觉测试时缩放方法RegionFocus，动态聚焦关键区域提升界面理解准确度。|
|🆕 发布|CoralVQA: A Large-Scale Visual Question Answering Dataset for Coral Reef Image Understanding|珊瑚视觉问答：用于珊瑚礁图像理解的规模化视觉问答数据集|Hongyong Han, Wei Wang, Gaowei Zhang, Mingjie Li, Yi Wang|<http://arxiv.org/pdf/2507.10449v1>|介绍了CoralVQA，首个大规模针对珊瑚礁图像理解的视觉问答数据集，助力生态监测与保护。|
|📝 更新|AI-driven visual monitoring of industrial assembly tasks|基于人工智能的工业装配任务视觉监控|Mattia Nardon, Stefano Messelodi, Antonio Granata, Fabio Poiesi, Alberto Danese, Davide Boscaini|<http://arxiv.org/pdf/2506.15285v2>|[代码](https://tev-fbk.github.io/ViMAT); 提出ViMAT系统，无约束地实时监控工业装配任务，结合多视角视频感知与推理模块提升作业安全与效率。|
|🆕 发布|Contrastive Pretraining with Dual Visual Encoders for Gloss-Free Sign Language Translation|对比性预训练结合双视觉编码器实现无光泽手语翻译|Ozge Mercanoglu Sincan, Richard Bowden|<http://arxiv.org/pdf/2507.10306v1>|提出了一种无需注释的对比预训练双视觉编码器框架，实现了高效的签字语言翻译。|
|📝 更新|SpatialViz-Bench: Automatically Generated Spatial Visualization Reasoning Tasks for MLLMs|空间可视化基准：为机器学习大型语言模型自动生成的空间可视化推理任务|Siting Wang, Luoyang Sun, Cheng Deng, Kun Shao, Minnan Pei, Zheng Tian, Haifeng Zhang, Jun Wang|<http://arxiv.org/pdf/2507.07610v2>|提出了SpatialViz-Bench，自动生成空间可视化推理任务，揭示了现有多模态大语言模型在空间...|
|🆕 发布|Counterfactual Visual Explanation via Causally-Guided Adversarial Steering|通过因果引导对抗性舵向的逆向视觉解释|Yiran Qiao, Disheng Liu, Yiren Lu, Yu Yin, Mengnan Du, Jing Ma|<http://arxiv.org/pdf/2507.09881v1>|提出了一种新的视觉解释框架CECAS，通过引入因果指导减少无关干扰，生成更高质量的对抗性反事实解释。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DisCo: Towards Distinct and Coherent Visual Encapsulation in Video MLLMs|“DisCo：面向视频多模态语言模型的显著性与一致性视觉封装”|Jiahe Zhao, Rongkun Zheng, Yi Wang, Helin Wang, Hengshuang Zhao|<http://arxiv.org/pdf/2507.10302v1>|[代码](https://github.com/ZJHTerry18/DisCo.); 提出DisCo方法，通过视觉概念区分器和时间焦点校准器提升视频多模态大语言模型中视觉封装的区分度和一...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Adapting OpenAI's CLIP Model for Few-Shot Image Inspection in Manufacturing Quality Control: An Expository Case Study with Multiple Application Examples|《适应OpenAI的CLIP模型用于制造质量控制中的少量样本图像检测：一个带有多个应用例证的阐述性案例研究》|Fadel M. Megahed, Ying-Ju Chen, Bianca Maria Colosimo, Marco Luigi Giuseppe Grasso, L. Allison Jones-Farmer, Sven Knoth, Hongyue Sun, Inez Zwetsloot|<http://arxiv.org/pdf/2501.12596v2>|将OpenAI的CLIP模型适配为少量样本学习，实现制造业图像质检的高效准确。|
|📝 更新|Cross-modal Ship Re-Identification via Optical and SAR Imagery: A Novel Dataset and Method|跨模态船舶重识别：基于光学与合成孔径雷达图像的新数据集与方法|Han Wang, Shengyang Li, Jian Yang, Yuxuan Liu, Yixuan Lv, Zhuang Zhou|<http://arxiv.org/pdf/2506.22027v2>|[代码](https://github.com/Alioth2000/Hoss-ReID.); 提出了一种基于光学和合成孔径雷达的跨模态船舶重识别方法，创建了适用于全天候船舶追踪的新数据集。|
|📝 更新|Average Calibration Error: A Differentiable Loss for Improved Reliability in Image Segmentation|平均校准误差：一种用于提高图像分割可靠性的可微分损失函数|Theodore Barfoot, Luis Garcia-Peraza-Herrera, Ben Glocker, Tom Vercauteren|<http://arxiv.org/pdf/2403.06759v4>|[代码](https://github.com/cai4cai/ACE-DLIRIS); 提出了一种新的损失函数mL1-ACE，有效改善医学图像分割的可靠性而不牺牲分割质量。|
|🆕 发布|FTCFormer: Fuzzy Token Clustering Transformer for Image Classification|模糊令牌聚类变换器：用于图像分类的FTCFormer|Muyi Bao, Changyu Zeng, Yifan Wang, Zhengni Yang, Zimu Wang, Guangliang Cheng, Jun Qi, Wei Wang|<http://arxiv.org/pdf/2507.10283v1>|[代码](https://github.com/BaoBao0926/FTCFormer); 提出基于模糊聚类动态生成视觉token的FTCFormer，优化图像特征表示，提升分类效果。|
|🆕 发布|SlumpGuard: An AI-Powered Real-Time System for Automated Concrete Slump Prediction via Video Analysis|混凝土塌落预警：一种基于视频分析的自动化混凝土塌落预测人工智能实时系统|Youngmin Kim, Giyeong Oh, Kwangsoo Youm, Youngjae Yu|<http://arxiv.org/pdf/2507.10171v1>|提出SlumpGuard系统，通过视频分析自动预测混凝土流动性，实现实时质量控制。|
|📝 更新|Advancing Automatic Photovoltaic Defect Detection using Semi-Supervised Semantic Segmentation of Electroluminescence Images|利用半监督语义分割提升自动光伏缺陷检测技术在电致发光图像上的应用|Abhishek Jha, Yogesh Rawat, Shruti Vyas|<http://arxiv.org/pdf/2404.13693v4>|[代码](https://github.com/abj247/PV-S3.); 提出了一种半监督学习模型PV-S3，通过少量标注样本实现了高效的太阳能电池板缺陷检测。|
|📝 更新|Barriers in Integrating Medical Visual Question Answering into Radiology Workflows: A Scoping Review and Clinicians' Insights|《将医学视觉问答整合到放射科工作流程中的障碍：范围综述与临床医生见解》|Deepali Mishra, Chaklam Silpasuwanchai, Ashutosh Modi, Madhumita Sushil, Sorayouth Chumnanvej|<http://arxiv.org/pdf/2507.08036v2>|揭示了医疗视觉问答系统在临床应用中的局限性，并提出改进方向以满足实际需求。|
|🆕 发布|4D-MISR: A unified model for low-dose super-resolution imaging via feature fusion|4D-MISR：一种通过特征融合实现低剂量超分辨率成像的统一模型|Zifei Wang, Zian Mao, Xiaoya He, Xi Huang, Haoran Zhang, Chun Cheng, Shufen Chu, Tingzheng Hou .etc.|<http://arxiv.org/pdf/2507.09953v1>|提出了一种融合多角度观测特征的网络模型，实现了低剂量下电子显微成像的原子级超分辨率重建。|
|🆕 发布|Crucial-Diff: A Unified Diffusion Model for Crucial Image and Annotation Synthesis in Data-scarce Scenarios|关键-扩散：一种在数据匮乏场景下用于关键图像和注释合成的统一扩散模型|Siyue Yao, Mingjie Sun, Eng Gee Lim, Ran Yi, Baojiang Zhong, Moncef Gabbouj|<http://arxiv.org/pdf/2507.09915v1>|提出了一种生成关键样本的统一扩散模型Crucial-Diff，有效解决了数据稀缺场景下的模型过拟合和...|
|📝 更新|RealKeyMorph: Keypoints in Real-world Coordinates for Resolution-agnostic Image Registration|《RealKeyMorph：基于实际坐标的关键点用于分辨率无关的图像配准》|Mina C. Moghadam, Alan Q. Wang, Omer Taub, Martin R. Prince, Mert R. Sabuncu|<http://arxiv.org/pdf/2506.10344v2>|提出了一种无需固定分辨率重采样的图像配准方法RealKeyMorph，通过学习真实世界坐标中的关键点...|
|📝 更新|CRISP-SAM2: SAM2 with Cross-Modal Interaction and Semantic Prompting for Multi-Organ Segmentation|CRISP-SAM2：具有跨模态交互和语义提示的SAM2用于多器官分割|Xinlei Yu, Changmiao Wang, Hui Jin, Ahmed Elazab, Gangyong Jia, Xiang Wan, Changqing Zou, Ruiquan Ge|<http://arxiv.org/pdf/2506.23121v3>|[代码](https://github.com/YU-deep/CRISP_SAM2.git.); 引入CRISP-SAM2模型，通过跨模态交互和语义提示提升多器官分割的准确性和细节表现。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Text-to-Remote-Sensing-Image Retrieval beyond RGB Sources|超越RGB源的文字到遥感图像检索|Daniele Rege Cambrin, Lorenzo Vaiani, Giuseppe Gallipoli, Luca Cagliero, Paolo Garza|<http://arxiv.org/pdf/2507.10403v1>|提出了一种融合多源遥感数据与地理信息的新框架，显著提升了文本到遥感图像的检索性能。|
|🆕 发布|Improving Remote Sensing Classification using Topological Data Analysis and Convolutional Neural Networks|利用拓扑数据分析与卷积神经网络提高遥感分类精度|Aaryam Sharma|<http://arxiv.org/pdf/2507.10381v1>|结合拓扑数据分析与卷积神经网络，提升了遥感图像分类性能。|
|🆕 发布|A Transfer Learning-Based Method for Water Body Segmentation in Remote Sensing Imagery: A Case Study of the Zhada Tulin Area|基于迁移学习的水体分割方法在遥感影像中的应用：扎达土林区域案例分析|Haonan Chen, Xin Tong|<http://arxiv.org/pdf/2507.10084v1>|提出了一种基于迁移学习的两阶段策略，有效解决了遥感影像水体分割中的域偏移和小样本问题。|
|📝 更新|Information-Bottleneck Driven Binary Neural Network for Change Detection|信息瓶颈驱动的二值神经网络用于变化检测|Kaijie Yin, Zhiyuan Zhang, Shu Kong, Tian Gao, Chengzhong Xu, Hui Kong|<http://arxiv.org/pdf/2507.03504v2>|首次提出专为变化检测设计的二值神经网络，通过信息瓶颈原理增强其表征能力和特征区分度。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Following the Clues: Experiments on Person Re-ID using Cross-Modal Intelligence|遵循线索：利用跨模态智能进行行人重识别的实验研究|Robert Aufschläger, Youssef Shoeb, Azarm Nowzad, Michael Heigl, Fabian Bally, Martin Schramm|<http://arxiv.org/pdf/2507.01504v2>|[代码](https://github.com/RAufschlaeger/cRID.); 提出了一种结合大型视觉语言模型和图注意力网络的跨模态框架，用于检测个人身份信息的文本描述性线索并增强...|
|🆕 发布|LifelongPR: Lifelong knowledge fusion for point cloud place recognition based on replay and prompt learning|终身PR：基于重放和提示学习的点云场景识别终身知识融合|Xianghong Zou, Jianping Li, Zhe Chen, Zhen Cao, Zhen Dong, Qiegen Liu, Bisheng Yang|<http://arxiv.org/pdf/2507.10034v1>|[代码](https://github.com/zouxianghong/LifelongPR.); 提出了一种针对点云场景识别的持续学习框架LifelongPR，通过样本重放和提示学习有效融合知识，减...|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|3DGAA: Realistic and Robust 3D Gaussian-based Adversarial Attack for Autonomous Driving|三维高斯基础上的真实与鲁棒对抗攻击方法研究：面向自动驾驶|Yixun Zhang, Lizhi Wang, Junjun Zhao, Wending Zhao, Feng Zhou, Yonghao Dang, Jianqin Yin|<http://arxiv.org/pdf/2507.09993v1>|提出3DGAA方法，通过联合优化几何和外观属性，实现了物理真实且可转移的自动驾驶系统攻击。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LayLens: Improving Deepfake Understanding through Simplified Explanations|LayLens：通过简化的解释提高深度伪造理解|Abhijeet Narang, Parul Gupta, Liuyijia Su, Abhinav Dhall|<http://arxiv.org/pdf/2507.10066v1>|提出LayLens工具，通过三阶段流程简化技术解释，帮助各教育背景用户更易理解并识别deepfake...|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vision-Based Anti Unmanned Aerial Technology: Opportunities and Challenges|基于视觉的反无人机技术：机遇与挑战|Guanghai Ding, Yihua Ren, Yuting Liu, Qijun Zhao, Shuiwang Li|<http://arxiv.org/pdf/2507.10006v1>|概述了视觉基础的反无人机追踪技术，并分析了未来研究方向。|


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PyVision: Agentic Vision with Dynamic Tooling|PyVision：动态工具的代理视觉|Shitian Zhao, Haoquan Zhang, Shaoheng Lin, Ming Li, Qilong Wu, Kaipeng Zhang, Chen Wei|<http://arxiv.org/pdf/2507.07998v2>|PyVision实现了大模型自主生成和优化Python工具，提升了视觉推理的灵活性和解释性。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Screen Them All: High-Throughput Pan-Cancer Genetic and Phenotypic Biomarker Screening from H&E Whole Slide Images|对所有进行筛选：从H&E全切片图像中进行高通量全癌遗传和表型生物标志物筛选|Yi Kan Wang, Ludmila Tydlitatova, Jeremy D. Kunz, Gerard Oakley, Bonnie Kar Bo Chow, Ran A. Godrich, Matthew C. H. Lee, Hamed Aghdam .etc.|<http://arxiv.org/pdf/2408.09554v4>|提出了一种高效AI系统OmniScreen，通过分析病理图像预测多种癌症的分子生物标志物。|
|🆕 发布|National level satellite-based crop field inventories in smallholder landscapes|国家层面基于卫星的小农户景观作物田清查|Philippe Rufin, Pauline Lucie Hammer, Leon-Friedrich Thomas, Sá Nogueira Lisboa, Natasha Ribeiro, Almeida Sitoe, Patrick Hostert, Patrick Meyfroidt|<http://arxiv.org/pdf/2507.10499v1>|利用高分辨率卫星数据和深度迁移学习，实现了对小农户复杂农业系统中农作物田地边界的精确描绘。|

