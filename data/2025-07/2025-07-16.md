## [UPDATED!] **2025-07-16** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CytoSAE: Interpretable Cell Embeddings for Hematology|细胞分析自编码器：血液学可解释细胞嵌入|Muhammed Furkan Dasdelen, Hyesu Lim, Michele Buck, Katharina S. Götze, Carsten Marr, Steffen Schneider|<http://arxiv.org/pdf/2507.12464v1>|[代码](https://github.com/dynamical-inference/cytosae.); 提出CytoSAE模型，通过稀疏自编码器在血液学领域实现细胞图像的可解释性嵌入。|
|🆕 发布|Hybrid Ensemble Approaches: Optimal Deep Feature Fusion and Hyperparameter-Tuned Classifier Ensembling for Enhanced Brain Tumor Classification|混合集成方法：最优深度特征融合与超参数调优分类器集成用于增强脑肿瘤分类|Zahid Ullah, Dragan Pamucar, Jihie Kim|<http://arxiv.org/pdf/2507.12177v1>|提出双集成框架，融合预训练深度学习模型特征提取和微调超参数机器学习模型，提高了脑肿瘤分类精度。|
|🆕 发布|Block-based Symmetric Pruning and Fusion for Efficient Vision Transformers|基于块对称剪枝与融合的高效视觉变换器|Yi-Kuan Hsieh, Jun-Wei Hsieh, Xin Li, Yu-Ming Chang, Yu-Chee Tseng|<http://arxiv.org/pdf/2507.12125v1>|提出了一种对称剪枝与融合策略，有效降低Vision Transformer计算成本同时保持性能。|
|🆕 发布|PRISM: Distributed Inference for Foundation Models at Edge|边缘计算中基础模型的分布式推理：PRISM|Muhammad Azlan Qazi, Alexandros Iosifidis, Qi Zhang|<http://arxiv.org/pdf/2507.12145v1>|定位边缘设备上基础模型的部署挑战，提出PRISM策略，通过优化通信和计算效率实现高效分布式推理。|
|🆕 发布|Effective Fine-Tuning of Vision Transformers with Low-Rank Adaptation for Privacy-Preserving Image Classification|《面向隐私保护图像分类的低秩适应视觉变换器有效微调》|Haiwei Lin, Shoko Imaizumi, Hitoshi Kiya|<http://arxiv.org/pdf/2507.11943v1>|提出了一种低秩适应方法，通过在ViT模型中注入可训练的秩分解矩阵，实现了隐私保护的图像分类同时保持高...|
|📝 更新|Multimodal Fusion and Vision-Language Models: A Survey for Robot Vision|多模态融合与视觉-语言模型：机器人视觉的综述|Xiaofeng Han, Shunpeng Chen, Zenghuang Fu, Zhe Feng, Lue Fan, Dong An, Changwei Wang, Li Guo .etc.|<http://arxiv.org/pdf/2504.02477v2>|[代码](https://github.com/Xiaofeng-Han-Res/MF-RV.); 系统综述了多模态融合和视觉语言模型在机器人视觉任务中的应用，提出了未来研究方向。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unit-Based Histopathology Tissue Segmentation via Multi-Level Feature Representation|基于单元的病理组织分割方法：通过多层次特征表示|Ashkan Shakarami, Azade Farshad, Yousef Yeganeh, Lorenzo Nicole, Peter Schuffler, Stefano Ghidoni, Nassir Navab|<http://arxiv.org/pdf/2507.12427v1>|提出基于单元的病理组织分割框架，通过多级特征表示提高分割效率并保持准确度。|
|🆕 发布|FactorHD: A Hyperdimensional Computing Model for Multi-Object Multi-Class Representation and Factorization|因素HD：一种用于多对象多类表示和分解的超维度计算模型|Yifei Zhou, Xuchu Huang, Chenyu Ni, Min Zhou, Zheyu Yan, Xunzhao Yin, Cheng Zhuo|<http://arxiv.org/pdf/2507.12366v1>|提出FactorHD模型，有效表示和分解复杂类-子类关系，显著提升计算效率和准确性。|
|📝 更新|ViTally Consistent: Scaling Biological Representation Learning for Cell Microscopy|“ViTally一致：为细胞显微镜学扩展生物表征学习”|Kian Kenyon-Dean, Zitong Jerry Wang, John Urbanik, Konstantin Donhauser, Jason Hartford, Saber Saberian, Nil Sahin, Ihab Bendidi .etc.|<http://arxiv.org/pdf/2411.02572v2>|提出了一种大规模细胞显微镜数据的基础模型，通过训练多样化数据集和生物启发任务，提高了基因扰动线性分离...|
|📝 更新|HIS-GPT: Towards 3D Human-In-Scene Multimodal Understanding|面向场景中三维人体多模态理解的HIS-GPT方法|Jiahe Zhao, Ruibing Hou, Zejie Tian, Hong Chang, Shiguang Shan|<http://arxiv.org/pdf/2503.12955v2>|[代码](https://github.com/ZJHTerry18/HumanInScene.); 提出Human-In-Scene QA任务，并引入HIS-GPT模型，融合3D场景与人类动作理解。|
|🆕 发布|Open-Vocabulary Indoor Object Grounding with 3D Hierarchical Scene Graph|开放词汇室内物体定位与三维层次场景图|Sergey Linok, Gleb Naumov|<http://arxiv.org/pdf/2507.12123v1>|[代码](https://github.com/linukc/OVIGo-3DHSG.); 提出了一种结合3D层级场景图和大型语言模型的室内物体定位方法，有效提升了空间理解能力。|
|📝 更新|Incremental Joint Learning of Depth, Pose and Implicit Scene Representation on Monocular Camera in Large-scale Scenes|在大规模场景中基于单目摄像头的深度、姿态和隐式场景表示的增量联合学习|Tianchen Deng, Nailin Wang, Chongdi Wang, Shenghai Yuan, Jingchuan Wang, Hesheng Wang, Danwei Wang, Weidong Chen|<http://arxiv.org/pdf/2404.06050v3>|提出了一种增量式联合学习框架，通过视觉变换器网络和特征度量捆绑调整，实现了大规模场景中深度、姿态估计...|
|📝 更新|How does Watermarking Affect Visual Language Models in Document Understanding?|水印技术如何影响文档理解中的视觉语言模型？|Chunxue Xu, Yiwei Wang, Bryan Hooi, Yujun Cai, Songze Li|<http://arxiv.org/pdf/2504.01048v2>|研究了水印对视觉语言模型性能的影响，并提出了一个评估框架来分析不同类型水印的影响。|
|📝 更新|HiMTok: Learning Hierarchical Mask Tokens for Image Segmentation with Large Multimodal Model|HiMTok：使用大型多模态模型学习层次化掩码标记进行图像分割|Tao Wang, Changxu Cheng, Lingfeng Wang, Senda Chen, Wuyue Zhao|<http://arxiv.org/pdf/2503.13026v2>|提出HiMTok方法，用少量标记表示图像分割掩码，提升大型多模态模型在图像分割中的性能。|
|🆕 发布|Hyperphantasia: A Benchmark for Evaluating the Mental Visualization Capabilities of Multimodal LLMs|超幻想象：用于评估多模态大型语言模型心理可视化能力的数据集|Mohammad Shahab Sepehri, Berk Tinaz, Zalan Fabian, Mahdi Soltanolkotabi|<http://arxiv.org/pdf/2507.11932v1>|提出Hyperphantasia基准，评估多模态大语言模型在心理可视化方面的能力，揭示与人类认知的差...|
|📝 更新|GeoChain: Multimodal Chain-of-Thought for Geographic Reasoning|地理链：用于地理推理的多模态思维链|Sahiti Yerramilli, Nilay Pande, Rynaa Grover, Jayant Sravan Tamarapalli|<http://arxiv.org/pdf/2506.00785v2>|提出GeoChain大规模基准，评估多模态大语言模型在地理推理中的逐步思维过程。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Benchmarking Deep Learning and Vision Foundation Models for Atypical vs. Normal Mitosis Classification with Cross-Dataset Evaluation|针对典型与正常有丝分裂分类的深度学习与视觉基础模型跨数据集评估基准测试|Sweta Banerjee, Viktoria Weiss, Taryn A. Donovan, Rutger H. J. Fick, Thomas Conrad, Jonas Ammeling, Nils Porsche, Robert Klopfleisch .etc.|<http://arxiv.org/pdf/2506.21444v2>|[代码](https://github.com/DeepMicroscopy/AMi-Br_Benchmark.); 本研究通过跨数据集评估，展示了利用深度学习和基础模型在异常与正常有丝分裂分类中的高效性。|
|📝 更新|PointSeg: A Training-Free Paradigm for 3D Scene Segmentation via Foundation Models|点分割：一种基于基础模型的无需训练的三维场景分割范式|Qingdong He, Jinlong Peng, Zhengkai Jiang, Xiaobin Hu, Jiangning Zhang|<http://arxiv.org/pdf/2403.06403v5>|提出了一种无需训练的3D场景分割方法PointSeg，利用现成的视觉基础模型实现出色的分割性能。|
|🆕 发布|POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering|POLYCHARTQA：使用多语种图表问答对大型视觉-语言模型进行基准测试|Yichen Xu, Liangyu Chen, Liang Zhang, Wenxuan Wang, Qin Jin|<http://arxiv.org/pdf/2507.11939v1>|创建了首个大规模多语言图表问答基准PolyChartQA，促进了对全球包容性视觉语言模型的系统评估。|
|📝 更新|XRF V2: A Dataset for Action Summarization with Wi-Fi Signals, and IMUs in Phones, Watches, Earbuds, and Glasses|XRF V2：一种结合Wi-Fi信号与手机、手表、耳机和眼镜中IMU的动作摘要数据集|Bo Lan, Pei Li, Jiaxi Yin, Yunpeng Song, Ge Wang, Han Ding, Jinsong Han, Fei Wang|<http://arxiv.org/pdf/2501.19034v2>|[代码](https://github.com/aiotgroup/XRFV2.); 提出XRF V2多模态数据集，通过Wi-Fi和IMU信号实现室内活动定位与总结，提出XRFMamba...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OD-VIRAT: A Large-Scale Benchmark for Object Detection in Realistic Surveillance Environments|OD-VIRAT：面向现实监控环境的目标检测大规模基准数据集|Hayat Ullah, Abbas Khan, Arslan Munir, Hari Kalva|<http://arxiv.org/pdf/2507.12396v1>|提出了OD-VIRAT Large和OD-VIRAT Tiny两个大规模监控环境下的目标检测基准，为...|
|📝 更新|AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization|文档中非文本元素细粒度分类的数据集：AnnoPage数据集|Martin Kišš, Michal Hradiš, Martina Dvořáková, Václav Jiroušek, Filip Kersch|<http://arxiv.org/pdf/2503.22526v3>|介绍了AnnoPage数据集，包含历史文档的非文本元素精细分类，支持文档布局分析和对象检测研究。|
|📝 更新|SpikeDet: Better Firing Patterns for Accurate and Energy-Efficient Object Detection with Spiking Neuron Networks|基于尖峰神经元网络的精确与节能目标检测：SpikeDet优化的激发模式|Yimeng Fan, Changsong Liu, Mingyang Li, Dongze Liu, Yanyan Liu, Wei Zhang|<http://arxiv.org/pdf/2501.15151v3>|提出SpikeDet优化神经元放电模式，提升基于脉冲神经网络的对象检测准确性和能效。|
|🆕 发布|Stereo Sound Event Localization and Detection with Onscreen/offscreen Classification|屏幕内外立体声音事件定位与检测及分类|Kazuki Shimada, Archontis Politis, Iran R. Roman, Parthasaarathy Sudarsanam, David Diaz-Guerra, Ruchi Pandey, Kengo Uchida, Yuichiro Koyama .etc.|<http://arxiv.org/pdf/2507.12042v1>|提出了一种基于立体声数据的声事件定位与检测方法，并引入了屏幕内外分类任务以适应有限视角场景。|
|🆕 发布|SS-DC: Spatial-Spectral Decoupling and Coupling Across Visible-Infrared Gap for Domain Adaptive Object Detection|基于可见光-红外域自适应目标检测的空间-光谱解耦与耦合的SS-DC方法|Xiwei Zhang, Chunjin Yang, Yiming Xiao, Runtong Zhang, Fanman Meng|<http://arxiv.org/pdf/2507.12017v1>|提出了一种针对可见光到红外域自适应目标检测的解耦-耦合框架，有效提升了跨域检测性能。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Efficient Calisthenics Skills Classification through Foreground Instance Selection and Depth Estimation|通过前景实例选择与深度估计实现的高效健美操技能分类|Antonio Finocchiaro, Giovanni Maria Farinella, Antonino Furnari|<http://arxiv.org/pdf/2507.12292v1>|提出了一种利用深度估计和运动员区域选择直接识别健身技能的方法，提高了效率并减少了推理时间。|
|🆕 发布|Fine-Grained Image Recognition from Scratch with Teacher-Guided Data Augmentation|从零开始进行细粒度图像识别：基于教师引导的数据增强方法|Edwin Arkel Rios, Fernando Mikael, Oswin Gosal, Femiloye Oyerinde, Hao-Chun Liang, Bo-Cheng Lai, Min-Chun Hu|<http://arxiv.org/pdf/2507.12157v1>|提出了一种无需预训练、基于教师引导数据增强的细粒度图像识别方法，实现了性能与效率的双重提升。|
|🆕 发布|Out-of-distribution data supervision towards biomedical semantic segmentation|面向生物医学语义分割的分布外数据监督|Yiquan Gao, Duohui Xu|<http://arxiv.org/pdf/2507.12105v1>|[代码](https://github.com/StudioYG/Med-OoD.); 引入异常分布数据监督，提出Med-OoD框架，有效提升生物医学图像分割准确度。|
|📝 更新|Prototype-Based Multiple Instance Learning for Gigapixel Whole Slide Image Classification|基于原型的多实例学习用于吉字节级全切片图像分类|Susu Sun, Dominique van Midden, Geert Litjens, Christian F. Baumgartner|<http://arxiv.org/pdf/2503.08384v2>|[代码](https://github.com/ss-sun/ProtoMIL.); 提出ProtoMIL模型，通过稀疏自动编码器提取可解释概念，实现病理图像分类并提供直观解释与人为干预...|
|🆕 发布|Spatial Frequency Modulation for Semantic Segmentation|空间频率调制用于语义分割|Linwei Chen, Ying Fu, Lin Gu, Dezhi Zheng, Jifeng Dai|<http://arxiv.org/pdf/2507.11893v1>|[代码](https://github.com/Linwei-Chen/SFM); 提出了一种空间频率调制方法，通过在降采样前将高频特征调制到低频，并在上采样时恢复，有效保留了细节信息...|
|🆕 发布|ProtoConNet: Prototypical Augmentation and Alignment for Open-Set Few-Shot Image Classification|原型增强与对齐用于开放集少样本图像分类的ProtoConNet|Kexuan Shi, Zhuang Qi, Jingjing Zhu, Lei Meng, Yaochen Zhang, Haibei Huang, Xiangxu Meng|<http://arxiv.org/pdf/2507.11845v1>|提出了一种结合背景信息的原型增强与对齐方法ProtoConNet，提高了少量样本学习效果和开放集样本...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Patherea: Cell Detection and Classification for the 2020s|Patherea：面向2020年代的细胞检测与分类|Dejan Štepec, Maja Jerše, Snežana Đokić, Jera Jeruc, Nina Zidar, Danijel Skočaj|<http://arxiv.org/pdf/2412.16425v2>|Patherea提出了一种统一的点基细胞检测与分类框架，并引入大规模临床流程复制的挑战性数据集，实现...|
|📝 更新|Gazing Into Missteps: Leveraging Eye-Gaze for Unsupervised Mistake Detection in Egocentric Videos of Skilled Human Activities|《注视失误：利用眼神注视进行自我中心视频中熟练人类活动无监督错误检测》|Michele Mazzamuto, Antonino Furnari, Yoichi Sato, Giovanni Maria Farinella|<http://arxiv.org/pdf/2406.08379v5>|利用眼动信号分析，实现了无监督方式下技能动作视频中的错误检测。|
|🆕 发布|SGLoc: Semantic Localization System for Camera Pose Estimation from 3D Gaussian Splatting Representation|SGLoc：基于三维高斯散点表示的相机姿态估计语义定位系统|Beining Xu, Siting Zhu, Hesheng Wang|<http://arxiv.org/pdf/2507.12027v1>|[代码](https://github.com/IRMVLab/SGLoc.); 提出了一种利用3D高斯散点表示和语义信息直接回归相机位姿的定位系统，无需初始位姿先验。|
|🆕 发布|Frequency-Dynamic Attention Modulation for Dense Prediction|频率动态注意力调制用于密集预测|Linwei Chen, Lin Gu, Ying Fu|<http://arxiv.org/pdf/2507.12006v1>|[代码](https://github.com/Linwei-Chen/FDAM); 提出Frequency-Dynamic Attention Modulation方法，解决Visio...|
|🆕 发布|Unsupervised Part Discovery via Descriptor-Based Masked Image Restoration with Optimized Constraints|无监督的基于描述符的遮罩图像恢复优化约束下的部分发现|Jiahao Xia, Yike Wu, Wenjian Huang, Jianguo Zhang, Jian Zhang|<http://arxiv.org/pdf/2507.11985v1>|[代码](https://github.com/Jiahao-UTS/MPAE.); 提出了一种无监督的部件发现方法MPAE，通过学习部件描述符和特征图，实现了在多种场景下的鲁棒部件识别...|
|🆕 发布|Prototypical Progressive Alignment and Reweighting for Generalizable Semantic Segmentation|原型渐进对齐与重加权策略用于泛化语义分割|Yuhang Zhang, Zhengyu Zhang, Muxin Liao, Shishun Tian, Wenbin Zou, Lu Zhang, Chen Xu|<http://arxiv.org/pdf/2507.11955v1>|提出了一种渐进对齐和重加权策略，通过CLIP模型增强语义分割在未见领域的泛化能力。|
|📝 更新|InterLoc: LiDAR-based Intersection Localization using Road Segmentation with Automated Evaluation Method|《InterLoc：基于激光雷达的道路分割交点定位及自动化评估方法》|Nguyen Hoang Khoi Tran, Julie Stephany Berrio, Mao Shan, Zhenxing Ming, Stewart Worrall|<http://arxiv.org/pdf/2505.00512v3>|提出了一种基于LiDAR和道路分割的在线交叉口定位方法，提高了自主车辆定位的准确性和可靠性。|
|🆕 发布|SEPose: A Synthetic Event-based Human Pose Estimation Dataset for Pedestrian Monitoring|SEPose：面向行人监控的合成事件驱动的姿态估计数据集|Kaustav Chanda, Aayush Atul Verma, Arpitsinh Vaghela, Yezhou Yang, Bharatesh Chakravarthi|<http://arxiv.org/pdf/2507.11910v1>|提出了SEPose，一个用于行人监控的合成事件基人体姿态估计数据集，以填补现实场景数据不足的空白。|
|📝 更新|LUMINA-Net: Low-light Upgrade through Multi-stage Illumination and Noise Adaptation Network for Image Enhancement|LUMINA-Net：通过多阶段光照和噪声适应网络进行低光照升级的图像增强|Namrah Siddiqua, Kim Suneung, Seong-Whan Lee|<http://arxiv.org/pdf/2502.15186v2>|提出了一种无监督的深度学习框架LUMINA-Net，通过多阶段光照和噪声适应网络显著提升低光照图像质...|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PhysX: Physical-Grounded 3D Asset Generation|PhysX：基于物理的3D资源生成|Ziang Cao, Zhaoxi Chen, Linag Pan, Ziwei Liu|<http://arxiv.org/pdf/2507.12465v1>|提出了PhysX，一种结合物理属性的3D资产生成框架，通过引入物理知识增强模型的真实世界应用性。|
|📝 更新|MAMBO: High-Resolution Generative Approach for Mammography Images|MAMBO：用于乳腺X线照片图像的高分辨率生成方法|Milica Škipina, Nikola Jovišić, Nicola Dall'Asen, Vanja Švenda, Anil Osman Tur, Slobodan Ilić, Elisa Ricci, Dubravko Ćulibrk|<http://arxiv.org/pdf/2506.08677v2>|[代码](https://github.com/iai-rs/mambo.); 提出了一种生成高清哺乳图像的MAMBO模型，通过组合局部和全局信息，解决了隐私限制下数据获取难题。|
|📝 更新|Flow-GRPO: Training Flow Matching Models via Online RL|流-GRPO：通过在线强化学习训练流匹配模型|Jie Liu, Gongye Liu, Jiajun Liang, Yangguang Li, Jiaheng Liu, Xintao Wang, Pengfei Wan, Di Zhang .etc.|<http://arxiv.org/pdf/2505.05470v4>|首次将在线强化学习融入流匹配模型，通过转换策略和降噪简化，大幅提升文本到图像生成质量和效率。|
|📝 更新|FLUXSynID: A Framework for Identity-Controlled Synthetic Face Generation with Document and Live Images|FLUXSynID：一种基于文档和实时图像的身份控制的合成人脸生成框架|Raul Ismayilov, Dzemila Sero, Luuk Spreeuwers|<http://arxiv.org/pdf/2505.07530v3>|提出了FLUXSynID框架，实现了对合成人脸身份属性的精细控制，并生成了更符合现实世界分布的合成人...|
|📝 更新|Proactive Agents for Multi-Turn Text-to-Image Generation Under Uncertainty|不确定环境下多轮文本到图像生成的主动代理|Meera Hahn, Wenjun Zeng, Nithish Kannen, Rich Galt, Kartikeya Badola, Been Kim, Zi Wang|<http://arxiv.org/pdf/2412.06771v2>|[代码](https://github.com/google-deepmind/proactive_t2i_agents.); 提出了一种主动询问用户意图的文本到图像生成原型，通过展示不确定性信念图，有效提高了用户意图与模型理解...|
|🆕 发布|Learning Pixel-adaptive Multi-layer Perceptrons for Real-time Image Enhancement|学习像素自适应多层感知器以实现实时图像增强|Junyu Lou, Xiaorui Zhao, Kexuan Shi, Shuhang Gu|<http://arxiv.org/pdf/2507.12135v1>|提出了一种结合双边网格与像素自适应多层感知机的图像增强框架，实现了复杂颜色关系的建模和实时处理。|
|📝 更新|SeaS: Few-shot Industrial Anomaly Image Generation with Separation and Sharing Fine-tuning|《SeaS：基于分离与共享微调的少样本工业异常图像生成》|Zhewei Dai, Shilei Zeng, Haotian Liu, Xurui Li, Feng Xue, Yu Zhou|<http://arxiv.org/pdf/2410.14987v2>|[代码](https://github.com/HUST-SLOW/SeaS); 提出SeaS模型，通过分离和共享微调实现少量样本工业异常图像生成，提升生成能力和精度。|
|🆕 发布|Non-Adaptive Adversarial Face Generation|非自适应对抗性人脸生成|Sunpill Kim, Seunghun Paik, Chanwoo Hwang, Minsu Kim, Jae Hong Seo|<http://arxiv.org/pdf/2507.12107v1>|提出了一种非自适应对抗性人脸生成方法，通过利用人脸识别系统特征空间的属性子球，实现高成功率的无需迭代...|
|🆕 发布|LidarPainter: One-Step Away From Any Lidar View To Novel Guidance|《LidarPainter：从任意激光雷达视角到新颖引导的一步之遥》|Yuzhou Ji, Ke Ma, Hong Cai, Anchun Zhang, Lizhuang Ma, Xin Tan|<http://arxiv.org/pdf/2507.12114v1>|提出LidarPainter模型，实现实时从稀疏LiDAR数据恢复高质量驾驶场景，提升轨迹偏离下的重...|
|📝 更新|Boost 3D Reconstruction using Diffusion-based Monocular Camera Calibration|利用基于扩散的单目相机标定提升三维重建|Junyuan Deng, Wei Yin, Xiaoyang Guo, Qian Zhang, Xiaotao Hu, Weiqiang Ren, Xiaoxiao-Long, Ping Tan|<http://arxiv.org/pdf/2411.17240v2>|提出了一种基于稳定扩散模型的新方法，通过单张图片实现了高精度相机内参估计，提升了多种3D视觉任务性能...|
|🆕 发布|3D-MoRe: Unified Modal-Contextual Reasoning for Embodied Question Answering|3D-MoRe：统一模态-上下文推理用于具身问答|Rongtao Xu, Han Gao, Mingming Yu, Dong An, Shunpeng Chen, Changwei Wang, Li Guo, Xiaodan Liang .etc.|<http://arxiv.org/pdf/2507.12026v1>|提出3D-MoRe方法，利用基础模型生成大规模3D语言数据集，提升室内场景问答和描述性能。|
|🆕 发布|ID-EA: Identity-driven Text Enhancement and Adaptation with Textual Inversion for Personalized Text-to-Image Generation|ID-EA：基于身份驱动的文本增强与适应方法，结合文本反转实现个性化文本到图像生成|Hyun-Jun Jin, Young-Eun Kim, Seong-Whan Lee|<http://arxiv.org/pdf/2507.11990v1>|提出ID-EA框架，通过文本与视觉身份对齐增强个性化图像生成中的身份保持。|
|📝 更新|UAVDB: Point-Guided Masks for UAV Detection and Segmentation|无人机检测与分割的点引导掩码：UAVDB|Yu-Hsi Chen|<http://arxiv.org/pdf/2409.06490v6>|[代码](https://github.com/wish44165/UAVDB); 提出了一种基于轨迹点的高效标注方法PIC，构建了UAVDB数据集，提升了无人机检测与分割的准确性和效...|
|🆕 发布|RaDL: Relation-aware Disentangled Learning for Multi-Instance Text-to-Image Generation|关系感知解耦学习用于多实例文本到图像生成：RaDL|Geon Park, Seon Bin Kim, Gunho Jung, Seong-Whan Lee|<http://arxiv.org/pdf/2507.11947v1>|提出RaDL框架，通过关系注意力机制改善多实例图像生成中实例间关系和属性表达。|
|🆕 发布|MOSPA: Human Motion Generation Driven by Spatial Audio|空间音频驱动的运动生成：MOSPA|Shuyang Xu, Zhiyang Dou, Mingyi Shi, Liang Pan, Leo Ho, Jingbo Wang, Yuan Liu, Cheng Lin .etc.|<http://arxiv.org/pdf/2507.11949v1>|提出首个基于空间音频驱动的实时人类运动生成模型MOSPA，实现音频空间特征与运动的高效融合。|
|📝 更新|OpenLKA: An Open Dataset of Lane Keeping Assist from Recent Car Models under Real-world Driving Conditions|开放车道保持辅助数据集OpenLKA：基于最新车型在真实世界驾驶条件下的研究|Yuhang Wang, Abdulaziz Alhuraish, Shengming Yuan, Hao Zhou|<http://arxiv.org/pdf/2505.09092v2>|[代码](https://github.com/OpenLKA/OpenLKA.); 首次构建开放大规模数据集OpenLKA，用于评估和提升车道保持辅助系统在真实世界中的性能。|
|📝 更新|FlipConcept: Tuning-Free Multi-Concept Personalization for Text-to-Image Generation|FlipConcept：无需调整的多概念个性化生成模型用于文本到图像生成|Young Beom Woo, Sun Eung Kim, Seong-Whan Lee|<http://arxiv.org/pdf/2502.15203v2>|提出了一种无需额外调优的多概念个性化图像生成方法FlipConcept，通过增强视觉保真度和保护非个...|
|📝 更新|Understanding Pan-Sharpening via Generalized Inverse|通过广义逆理解全色锐化|Shiqi Liu, Yihua Tan, Yutong Bai, Alan Yuille|<http://arxiv.org/pdf/2310.02718v3>|提出基于广义逆矩阵理论描述的Pan-sharpening方法，提升了图像的空间和光谱分辨率。|
|🆕 发布|MNIST-Gen: A Modular MNIST-Style Dataset Generation Using Hierarchical Semantics, Reinforcement Learning, and Category Theory|MNIST-Gen：一种基于层次语义、强化学习和范畴论的模块化MNIST风格数据集生成方法|Pouya Shaeri, Arash Karimi, Ariane Middel|<http://arxiv.org/pdf/2507.11821v1>|提出MNIST-Gen框架，自动生成定制化MNIST风格数据集，结合语义理解和强化学习实现高效分类。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mitigating Object Hallucinations via Sentence-Level Early Intervention|通过句子级别的早期干预减轻对象幻觉|Shangpin Peng, Senqiao Yang, Li Jiang, Zhuotao Tian|<http://arxiv.org/pdf/2507.12455v1>|[代码](https://github.com/pspdada/SENTINEL.); 提出了一种框架消除视觉语言模型中的对象幻觉，通过早期干预和偏好学习显著减少错误内容生成。|
|📝 更新|CleAR: Robust Context-Guided Generative Lighting Estimation for Mobile Augmented Reality|清晰：面向移动增强现实的鲁棒上下文引导生成光照估计|Yiqin Zhao, Mallesham Dasari, Tian Guo|<http://arxiv.org/pdf/2411.02179v3>|提出CleAR系统，通过上下文引导的生成模型快速准确估算移动AR环境光照，提升渲染质量。|
|📝 更新|Text-Visual Semantic Constrained AI-Generated Image Quality Assessment|文本-视觉语义约束下AI生成图像质量评估|Qiang Li, Qingsen Yan, Haojian Huang, Peng Wu, Haokui Zhang, Yanning Zhang|<http://arxiv.org/pdf/2507.10432v3>|[代码](https://github.com/mozhu1/SC-AGIQA.); 提出了一种融合文本视觉语义约束的AI生成图像质量评估框架，有效解决了语义错位和细节感知缺失问题。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Describe Anything Model for Visual Question Answering on Text-rich Images|用于丰富文本图像的视觉问答的“描述任意事物”模型|Yen-Linh Vu, Dinh-Thang Duong, Truong-Binh Duong, Anh-Khoi Nguyen, Thanh-Huy Nguyen, Le Thien Phuc Nguyen, Jianhua Xing, Xingjian Li .etc.|<http://arxiv.org/pdf/2507.12441v1>|[代码](https://github.com/Linvyl/DAM-QA.git.); 提出DAM-QA框架，利用区域感知能力提升文本丰富图像的视觉问答性能。|
|🆕 发布|FADE: Adversarial Concept Erasure in Flow Models|FADE：流模型中的对抗性概念擦除|Zixuan Fu, Yan Ren, Finn Carter, Chenyue Wang, Ze Niu, Dacheng Yu, Emily Davis, Bo Zhang|<http://arxiv.org/pdf/2507.12283v1>|提出FADE方法，通过对抗性扩散擦除特定概念，同时保持模型生成质量。|
|🆕 发布|MS-DETR: Towards Effective Video Moment Retrieval and Highlight Detection by Joint Motion-Semantic Learning|MS-DETR：通过联合运动-语义学习实现高效视频瞬间检索与亮点检测|Hongxu Ma, Guanshuo Wang, Fufu Yu, Qiong Jia, Shouhong Ding|<http://arxiv.org/pdf/2507.12062v1>|[代码](https://github.com/snailma0229/MS-DETR.git.); 提出MS-DETR框架，通过联合学习视频中的运动和空间语义特征，有效提升视频时刻检索和亮点检测性能。|
|🆕 发布|InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing|指令FLIP：探索统一视觉-语言模型用于面部反欺骗|Kun-Hsiang Lin, Yu-Wen Tseng, Kang-Yang Huang, Jhih-Ciang Wu, Wen-Huang Cheng|<http://arxiv.org/pdf/2507.12060v1>|[代码](https://kunkunlin1221.github.io/InstructFLIP.); 提出InstructFLIP框架，利用视觉语言模型和元学习策略提升人脸防伪的跨域泛化能力。|
|📝 更新|Rethinking Data Protection in the (Generative) Artificial Intelligence Era|重新思考在（生成式）人工智能时代的数据保护问题|Yiming Li, Shuo Shao, Yu He, Junfeng Guo, Tianwei Zhang, Zhan Qin, Pin-Yu Chen, Michael Backes .etc.|<http://arxiv.org/pdf/2507.03034v2>|提出四级数据保护分类法，全面覆盖生成式AI模型和系统的多样化需求。|
|📝 更新|GIE-Bench: Towards Grounded Evaluation for Text-Guided Image Editing|面向文本引导图像编辑的地基评估方法：GIE-Bench|Yusu Qian, Jiasen Lu, Tsu-Jui Fu, Xinze Wang, Chen Chen, Yinfei Yang, Wenze Hu, Zhe Gan|<http://arxiv.org/pdf/2505.11493v2>|提出了GIE-Bench基准，通过功能正确性和图像内容保持两个维度，更精准地评估文本引导的图像编辑模...|
|🆕 发布|CompressedVQA-HDR: Generalized Full-reference and No-reference Quality Assessment Models for Compressed High Dynamic Range Videos|压缩VQA-HDR：用于压缩高动态范围视频的广义全参考和无参考质量评估模型|Wei Sun, Linhan Cao, Kang Fu, Dandan Zhu, Jun Jia, Menghan Hu, Xiongkuo Min, Guangtao Zhai|<http://arxiv.org/pdf/2507.11900v1>|[代码](https://github.com/sunwei925/CompressedVQA-HDR.); 提出了一种针对高动态范围视频压缩质量评估的有效框架，通过深度学习模型提高了全参考和无参考质量评估的泛...|
|📝 更新|TextDestroyer: A Training- and Annotation-Free Diffusion Method for Destroying Anomal Text from Images|文本毁灭者：一种无需训练和注释的扩散方法，用于从图像中销毁异常文本|Mengcheng Li, Fei Chao|<http://arxiv.org/pdf/2411.00355v3>|TextDestroyer提出了一种无需训练和标注的文本消除方法，通过预训练扩散模型彻底清除图像中的...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|QuRe: Query-Relevant Retrieval through Hard Negative Sampling in Composed Image Retrieval|查询相关检索：通过组合图像检索中的硬负样本采样|Jaehyun Kwak, Ramahdani Muhammad Izaaz Inhar, Se-Young Yun, Sung-Ju Lee|<http://arxiv.org/pdf/2507.12416v1>|[代码](https://github.com/jackwaky/QuRe.); 提出了一种优化奖励模型和硬负样本采样策略的查询相关检索方法，有效减少错误负样本，提升图像检索与用户偏...|
|🆕 发布|Unsupervised Monocular 3D Keypoint Discovery from Multi-View Diffusion Priors|无监督单目3D关键点发现：基于多视角扩散先验|Subin Jeon, In Cho, Junyoung Hong, Seon Joo Kim|<http://arxiv.org/pdf/2507.12336v1>|提出了一种无需标注或立体图像的3D关键点估计方法，利用预训练的多视角扩散模型学习几何先验。|
|🆕 发布|Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models|高保真、高效扩散模型的结构化离散潜在代码|Samuel Lavoie, Michael Noukhovitch, Aaron Courville|<http://arxiv.org/pdf/2507.12318v1>|提出离散潜在码表示，提升了扩散模型的无条件图像生成质量和灵活性。|
|📝 更新|LiDPM: Rethinking Point Diffusion for Lidar Scene Completion|LiDPM：重新思考激光雷达场景补全中的点扩散方法|Tetiana Martyniuk, Gilles Puy, Alexandre Boulch, Renaud Marlet, Raoul de Charette|<http://arxiv.org/pdf/2504.17791v2>|[代码](https://astra-vision.github.io/LiDPM); 提出了一种针对激光雷达场景的点扩散模型LiDPM，通过优化起始点实现更好的场景补全效果。|
|📝 更新|Visual Position Prompt for MLLM based Visual Grounding|基于多模态语言模型的视觉定位提示在视觉定位中的应用|Wei Tang, Yanpeng Sun, Qinying Gu, Zechao Li|<http://arxiv.org/pdf/2503.15426v4>|[代码](https://github.com/WayneTomas/VPP-LLaVA.); 提出视觉位置提示增强的多模态大语言模型，提升了图像中坐标与空间信息的对准精度。|
|🆕 发布|RODS: Robust Optimization Inspired Diffusion Sampling for Detecting and Reducing Hallucination in Generative Models|RODS：基于鲁棒优化启发的扩散采样方法用于检测和减少生成模型中的幻觉现象|Yiqi Tian, Pengfei Jin, Mingze Yuan, Na Li, Bo Zeng, Quanzheng Li|<http://arxiv.org/pdf/2507.12201v1>|提出RODS方法，通过优化视角检测并减少生成模型中的幻觉现象，提高采样质量和鲁棒性。|
|🆕 发布|Wavelet-based Decoupling Framework for low-light Stereo Image Enhancement|基于小波分解的低光照立体图像增强解耦框架|Shuangli Du, Siming Yan, Zhenghao Shi, Zhenzhen You, Lu Sun|<http://arxiv.org/pdf/2507.12188v1>|[代码](https://github.com/Cherisherr/WDCI-Net.git.); 提出了一种基于小波变换的低光照立体图像增强框架，通过特征空间解耦有效调整光照并恢复高频信息。|
|📝 更新|Bridging the Skeleton-Text Modality Gap: Diffusion-Powered Modality Alignment for Zero-shot Skeleton-based Action Recognition|跨越骨骼-文本模态差距：基于扩散的模态对齐为零样本骨骼行为识别|Jeonghyeok Do, Munchurl Kim|<http://arxiv.org/pdf/2411.10745v4>|提出了一种基于扩散模型的三元组扩散匹配框架，有效桥接了骨骼特征与文本特征间的模态差距，提升了零样本动...|
|📝 更新|DeltaDiff: Reality-Driven Diffusion with AnchorResiduals for Faithful SR|DeltaDiff：基于现实驱动的带有锚残差的忠实超分辨率扩散|Chao Yang, Yong Fan, Qichao Zhang, Cheng Lu, Zhijing Yang|<http://arxiv.org/pdf/2502.12567v2>|[代码](https://github.com/continueyang/DeltaDiff); 提出DeltaDiff框架，通过建立确定性映射路径提升超分辨率任务中的图像保真度。|
|🆕 发布|Dual form Complementary Masking for Domain-Adaptive Image Segmentation|双重形式互补遮罩用于域自适应图像分割|Jiawen Wang, Yinda Chen, Xiaoyu Liu, Che Liu, Dong Liu, Jianqing Gao, Zhiwei Xiong|<http://arxiv.org/pdf/2507.12008v1>|提出了一种新的域自适应图像分割框架MaskTwins，通过互补掩码的双形式增强特征提取，实现了跨域泛...|
|🆕 发布|GS-Bias: Global-Spatial Bias Learner for Single-Image Test-Time Adaptation of Vision-Language Models|GS-Bias：面向视觉语言模型单图像测试时适应的全局-空间偏差学习者|Zhaohong Huang, Yuxin Zhang, Jingjing Xie, Fei Chao, Rongrong Ji|<http://arxiv.org/pdf/2507.11969v1>|提出GS-Bias方法，通过学习图像的全局和空间偏差，高效提升视觉语言模型的测试时适应性能。|
|🆕 发布|Style Composition within Distinct LoRA modules for Traditional Art|“在区分的LoRA模块中实现传统艺术的风格组合”|Jaehyun Lee, Wonhark Park, Wonsik Shin, Hyunho Lee, Hyoung Min Na, Nojun Kwak|<http://arxiv.org/pdf/2507.11986v1>|提出了一种零样本扩散管道，通过在去噪过程中对特定风格模型进行风格组合，实现了精确的区域风格控制。|
|🆕 发布|EC-Diff: Fast and High-Quality Edge-Cloud Collaborative Inference for Diffusion Models|EC-Diff：用于扩散模型的高效高质量边缘-云协同推理|Jiajian Xie, Shengyu Zhang, Zhou Zhao, Fan Wu, Fei Wu|<http://arxiv.org/pdf/2507.11980v1>|[代码](https://ec-diff.github.io/.); 提出EC-Diff方法，通过云端梯度估计和边缘模型切换优化，实现扩散模型快速推理和高生成质量。|
|📝 更新|MapEx: Indoor Structure Exploration with Probabilistic Information Gain from Global Map Predictions|MapEx：基于全局地图预测的概率信息增益进行室内结构探索|Cherie Ho, Seungchan Kim, Brady Moon, Aditya Parandekar, Narek Harutyunyan, Chen Wang, Katia Sycara, Graeme Best .etc.|<http://arxiv.org/pdf/2409.15590v3>|提出了一种利用全局地图预测的机器人室内探索框架MapEx，通过结合观察和不确定性计算概率信息增益，提...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SpatialTrackerV2: 3D Point Tracking Made Easy|空间追踪器V2：轻松实现三维点追踪|Yuxi Xiao, Jianyuan Wang, Nan Xue, Nikita Karaev, Yuri Makarov, Bingyi Kang, Xing Zhu, Hujun Bao .etc.|<http://arxiv.org/pdf/2507.12462v1>|提出了SpatialTrackerV2，一种将点追踪、单目深度估计和相机位姿估计统一于一体的3D点追...|
|📝 更新|Dual Dimensions Geometric Representation Learning Based Document Dewarping|基于双维度几何表示学习的文档去弯曲|Heng Li, Qingcai Chen, Xiangping Wu|<http://arxiv.org/pdf/2507.08492v2>|[代码](https://github.com/xiaomore/DocDewarpHV); 提出了一种双维度几何表征学习模型D2Dewarp，通过同时考虑文档的水平和垂直线条，有效改善了文档去...|
|📝 更新|GS-I$^{3}$: Gaussian Splatting for Surface Reconstruction from Illumination-Inconsistent Images|GS-I$^{3}$: 高斯散点法用于从光照不一致图像中进行表面重建|Tengfei Wang, Xin Wang, Yongmao Hou, Zhaoning Zhang, Yiwei Xu, Zongqian Zhan|<http://arxiv.org/pdf/2503.12335v3>|[代码](https://github.com/TFwang-9527/GS-3I); 提出GS-3I方法，通过CNN进行色调映射校正和正常补偿机制，实现复杂光照下准确的表面重建。|
|📝 更新|TRAN-D: 2D Gaussian Splatting-based Sparse-view Transparent Object Depth Reconstruction via Physics Simulation for Scene Update|基于二维高斯散点法的稀疏视角透明物体深度重建：通过物理仿真实现场景更新中的TRAN-D|Jeongyun Kim, Seunghoon Jeong, Giseop Kim, Myung-Hwan Jeon, Eunji Jun, Ayoung Kim|<http://arxiv.org/pdf/2507.11069v2>|[代码](https://jeongyun0609.github.io/TRAN-D); 提出了一种基于2D高斯散点法的透明物体深度重建技术，通过物理仿真优化，实现了在稀疏视角和动态环境下的...|
|📝 更新|SurGSplat: Progressive Geometry-Constrained Gaussian Splatting for Surgical Scene Reconstruction|《SurGSplat：用于手术场景重建的渐进式几何约束高斯散点绘制方法》|Yuchao Zheng, Jianing Zhang, Guochen Ning, Hongen Liao|<http://arxiv.org/pdf/2506.05935v2>|[代码](https://surgsplat.github.io/.); 提出了一种用于手术场景重建的SurGSplat方法，通过逐步整合几何约束改进3D高斯散点技术，提高了...|
|🆕 发布|Intra-view and Inter-view Correlation Guided Multi-view Novel Class Discovery|视图内关联与视图间关联引导的多视角新类发现|Xinhang Wan, Jiyuan Liu, Qian Qu, Suyuan Liu, Chuyu Zhang, Fangdi Wang, Xinwang Liu, En Zhu .etc.|<http://arxiv.org/pdf/2507.12029v1>|提出首个多视角新类发现框架，利用内外视角相关性提高聚类稳定性和准确性。|
|🆕 发布|A Multi-Level Similarity Approach for Single-View Object Grasping: Matching, Planning, and Fine-Tuning|一种多级相似性方法用于单视角物体抓取：匹配、规划与微调|Hao Chen, Takuya Kiyokawa, Zhengtao Hu, Weiwei Wan, Kensuke Harada|<http://arxiv.org/pdf/2507.11938v1>|提出了一种基于相似性匹配的三步法，通过借鉴已知物体模型来稳健实现单视角未知物体的抓取。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spontaneous Spatial Cognition Emerges during Egocentric Video Viewing through Non-invasive BCI|"通过非侵入式脑机接口观看自我中心视频时自发空间认知的产生"|Weichen Dai, Yuxuan Huang, Li Zhu, Dongjun Liu, Yu Zhang, Qibin Zhao, Andrzej Cichocki, Fabio Babiloni .etc.|<http://arxiv.org/pdf/2507.12417v1>|首次展示非侵入式脑机接口能通过EEG解码观看第一视角视频时的自发6D位姿。|
|🆕 发布|CorrMoE: Mixture of Experts with De-stylization Learning for Cross-Scene and Cross-Domain Correspondence Pruning|CorrMoE：用于跨场景和跨域对应剪枝的去风格化学习混合专家模型|Peiwen Xia, Tangfei Liao, Wei Zhu, Danhuai Zhao, Jianjun Ke, Kaihao Zhang, Tong Lu, Tao Wang|<http://arxiv.org/pdf/2507.11834v1>|[代码](https://github.com/peiwenxia/CorrMoE.); 提出CorrMoE框架，通过去风格化学习和多专家混合应对跨场景和跨域对应关系修剪挑战。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DoRF: Doppler Radiance Fields for Robust Human Activity Recognition Using Wi-Fi|多普勒辐射场：利用Wi-Fi进行鲁棒人体活动识别|Navid Hasanzadeh, Shahrokh Valaee|<http://arxiv.org/pdf/2507.12132v1>|提出了一种基于Wi-Fi信号的三维运动重建方法，显著提升了人类活动识别的泛化准确性和环境适应性。|
|🆕 发布|BRUM: Robust 3D Vehicle Reconstruction from 360 Sparse Images|BRUM：从360度稀疏图像中稳健的3D车辆重建|Davide Di Nucci, Matteo Tomei, Guido Borghi, Luca Ciuffreda, Roberto Vezzani, Rita Cucchiara|<http://arxiv.org/pdf/2507.12095v1>|提出了一种从稀疏视角重建车辆的高效方法，通过深度图和稳健的姿态估计提升了重建质量。|
|🆕 发布|IDFace: Face Template Protection for Efficient and Secure Identification|IDFace：高效与安全识别的人脸模板保护|Sunpill Kim, Seunghun Paik, Chanwoo Hwang, Dongsoo Kim, Junbum Shin, Jae Hong Seo|<http://arxiv.org/pdf/2507.12050v1>|提出了一种高效安全的加密人脸识别方法IDFace，通过两项新技术显著降低识别成本。|
|🆕 发布|HPR3D: Hierarchical Proxy Representation for High-Fidelity 3D Reconstruction and Controllable Editing|层次化代理表示法用于高保真三维重建与可控编辑：HPR3D|Tielong Wang, Yuxuan Xiong, Jinfan Liu, Zhifan Zhang, Ye Chen, Yue Shi, Bingbing Ni|<http://arxiv.org/pdf/2507.11971v1>|提出了一种高效的3D重建与编辑方法，通过树状代理节点表示，实现了高保真度与易编辑性的平衡。|
|🆕 发布|Dark-EvGS: Event Camera as an Eye for Radiance Field in the Dark|《暗光环境下基于事件相机捕捉辐射场的Dark-EvGS方法》|Jingqian Wu, Peiqi Duan, Zongqiang Wang, Changwei Wang, Boxin Shi, Edmund Y. Lam|<http://arxiv.org/pdf/2507.11931v1>|提出Dark-EvGS框架，利用事件相机在低光环境下重建高质量亮帧。|
|📝 更新|Robust Low-light Scene Restoration via Illumination Transition|通过光照转换实现的稳健低光照场景恢复|Ze Li, Feng Zhang, Xiatian Zhu, Meng Zhang, Yanghong Zhou, P. Y. Mok|<http://arxiv.org/pdf/2507.03976v2>|[代码](https://pegasus2004.github.io/RoSe.); 提出了一种基于三维光照转换估计的鲁棒低光照场景恢复框架，有效提升了多视角低光照图像到正常光照图像的转...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MMHU: A Massive-Scale Multimodal Benchmark for Human Behavior Understanding|大规模多模态人类行为理解基准：MMHU|Renjie Li, Ruijie Ye, Mingyang Wu, Hao Frank Yang, Zhiwen Fan, Hezhen Hu, Zhengzhong Tu|<http://arxiv.org/pdf/2507.12463v1>|提出了MMHU大规模多模态人类行为理解基准，丰富了自动驾驶中人类行为分析的数据和评价体系。|
|🆕 发布|EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos|自我视角视觉-语言-动作模型：从第一人称人类视频学习|Ruihan Yang, Qinxi Yu, Yecheng Wu, Rui Yan, Borui Li, An-Chieh Cheng, Xueyan Zou, Yunhao Fang .etc.|<http://arxiv.org/pdf/2507.12440v1>|[代码](https://rchalyang.github.io/EgoVLA); 提出利用第一人称人类视频训练视觉-语言-动作模型，实现机器人动作模仿与优化。|
|🆕 发布|Calisthenics Skills Temporal Video Segmentation|"哑铃操技能时序视频分割"|Antonio Finocchiaro, Giovanni Maria Farinella, Antonino Furnari|<http://arxiv.org/pdf/2507.12245v1>|提出首个针对静态健身技巧的时序视频分割方法，助力运动员训练与评委评分。|
|📝 更新|Vamba: Understanding Hour-Long Videos with Hybrid Mamba-Transformers|《Vamba：利用混合Mamba-Transformer理解长达一小时的视频》|Weiming Ren, Wentao Ma, Huan Yang, Cong Wei, Ge Zhang, Wenhu Chen|<http://arxiv.org/pdf/2503.11579v2>|提出了一种混合Mamba-Transformer模型Vamba，有效处理小时长视频，降低计算成本并提...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Traffic-Aware Pedestrian Intention Prediction|交通感知的行人意图预测|Fahimeh Orvati Nia, Hai Lin|<http://arxiv.org/pdf/2507.12433v1>|提出了一种融合交通信号和场景信息的行人意图预测模型，显著提升了预测准确性。|
|🆕 发布|Foresight in Motion: Reinforcing Trajectory Prediction with Reward Heuristics|运动中的远见：用奖励启发式强化轨迹预测|Muleilan Pei, Shaoshuai Shi, Xuesong Chen, Xu Liu, Shaojie Shen|<http://arxiv.org/pdf/2507.12083v1>|提出“先推理后预测”策略，用奖励驱动的意图推理改进自动驾驶中的轨迹预测准确性。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DVFL-Net: A Lightweight Distilled Video Focal Modulation Network for Spatio-Temporal Action Recognition|DVFL-Net：一种轻量级蒸馏视频焦点调制网络用于时空动作识别|Hayat Ullah, Muhammad Ali Shafique, Abbas Khan, Arslan Munir|<http://arxiv.org/pdf/2507.12426v1>|提出了一种轻量级视频识别网络DVFL-Net，通过知识蒸馏和特征调制实现了高效的人体动作识别。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|YOLOv8-SMOT: An Efficient and Robust Framework for Real-Time Small Object Tracking via Slice-Assisted Training and Adaptive Association|YOLOv8-SMOT：通过切片辅助训练和自适应关联实现实时小目标跟踪的高效鲁棒框架|Xiang Yu, Xinyao Liu, Guang Liang|<http://arxiv.org/pdf/2507.12087v1>|[代码](https://github.com/Salvatore-Love/YOLOv8-SMOT.); 提出了一种针对实时小目标跟踪的高效鲁棒框架，通过切片辅助训练和自适应关联策略显著提升了跟踪性能。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Distilling Invariant Representations with Dual Augmentation|用双重增强蒸馏不变表征|Nikolaos Giakoumoglou, Tania Stathaki|<http://arxiv.org/pdf/2410.09474v4>|引入双增强策略以促进教师和学生模型中不变特征的学习，提升知识蒸馏中学习到的表征的稳定性和迁移性。|


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CultureCLIP: Empowering CLIP with Cultural Awareness through Synthetic Images and Contextualized Captions|文化感知CLIP：通过合成图像与情境化标题增强CLIP的文化意识|Yuchen Huang, Zhiyuan Fan, Zhitao He, Sandeep Polisetty, Wenyan Li, Yi R. Fung|<http://arxiv.org/pdf/2507.06210v2>|通过构建合成文化数据集并微调CLIP模型，有效提升了其对细微文化差异的理解能力。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vision-based Perception for Autonomous Vehicles in Obstacle Avoidance Scenarios|基于视觉的自动驾驶车辆在避障场景中的感知|Van-Hoang-Anh Phan, Chi-Tam Nguyen, Doan-Trung Au, Thanh-Danh Phan, Minh-Thien Duong, My-Ha Le|<http://arxiv.org/pdf/2507.12449v1>|提出了一种仅用摄像头感知的障碍物避障系统，结合YOLOv11和Depth Anything V2模型...|
|🆕 发布|RegCL: Continual Adaptation of Segment Anything Model via Model Merging|RegCL：通过模型融合实现Segment Anything模型的持续适应|Yuan-Chen Shu, Zhiwei Lin, Yongtao Wang|<http://arxiv.org/pdf/2507.12297v1>|提出RegCL框架，通过模型合并实现多领域知识整合，有效解决Segment Anything Mod...|
|🆕 发布|Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants|基于逐层冻结的站点级微调：面向在极早早产儿第一天胸部X射线中稳健预测支气管肺发育不良|Sybelle Goedicke-Fritz, Michelle Bous, Annika Engel, Matthias Flotho, Pascal Hirsch, Hannah Wittig, Dino Milanovic, Dominik Mohr .etc.|<http://arxiv.org/pdf/2507.12269v1>|提出了一种针对极低出生体重婴儿的BPD预测方法，通过特定领域预训练和渐进式层冻结提升准确度。|
|🆕 发布|Dataset Ownership Verification for Pre-trained Masked Models|预训练遮蔽模型的数据集所有权验证|Yuechen Xie, Jie Song, Yicheng Shan, Xiaoyan Zhang, Yuanyu Wan, Shengxuming Zhang, Jiarui Duan, Mingli Song|<http://arxiv.org/pdf/2507.12022v1>|[代码](https://github.com/xieyc99/DOV4MM.); 提出首个针对预训练遮蔽模型的数据集所有权验证方法，有效保护数据集所有者权益。|
|🆕 发布|A Spatial-Physics Informed Model for 3D Spiral Sample Scanned by SQUID Microscopy|一种基于空间物理信息的三维螺旋样本SQUID显微镜扫描模型|J. Senthilnath, Jayasanker Jayabalan, Zhuoyi Lin, Aye Phyu Phyu Aung, Chen Hao, Kaixin Xu, Yeow Kheng Lim, F. C. Wellstood|<http://arxiv.org/pdf/2507.11853v1>|提出了一种融合空间分析和物理模型的SPIM方法，有效提升了磁图像质量和减少了扫描误差，用于半导体行业...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|InterpIoU: Rethinking Bounding Box Regression with Interpolation-Based IoU Optimization|基于插值优化的交并比（IoU）重新思考边界框回归：InterpIoU|Haoyuan Liu, Hiroshi Watanabe|<http://arxiv.org/pdf/2507.12420v1>|提出InterpIoU损失函数，通过插值优化IoU，有效解决了传统IoU损失在非重叠情况下的优化问题...|
|🆕 发布|Neural Human Pose Prior|神经人体姿态先验|Michal Heker, Sefy Kararlitsky, David Tolpin|<http://arxiv.org/pdf/2507.12138v1>|提出了一种基于归一化流的神经人体姿态先验建模方法，稳定学习有效6D旋转分布，增强姿态重建效果。|
|🆕 发布|MVAR: MultiVariate AutoRegressive Air Pollutants Forecasting Model|多变量自回归空气污染物预测模型（MVAR）|Xu Fan, Zhihao Wang, Yuetan Lin, Yan Zhang, Yang Xiang, Hao Li|<http://arxiv.org/pdf/2507.12023v1>|提出MVAR模型，实现多变量空气污染物长期精准预测，提升数据利用效率。|
|🆕 发布|Deep Neural Encoder-Decoder Model to Relate fMRI Brain Activity with Naturalistic Stimuli|深度神经网络编码-解码模型关联fMRI脑活动与自然istic刺激|Florian David, Michael Chan, Elenor Morgenroth, Patrik Vuilleumier, Dimitri Van De Ville|<http://arxiv.org/pdf/2507.12009v1>|提出了一种深度神经网络编码-解码模型，利用时间相关的电影帧输入，实现了fMRI数据与自然刺激的脑活动...|
|📝 更新|StreakNet-Arch: An Anti-scattering Network-based Architecture for Underwater Carrier LiDAR-Radar Imaging|条纹网架构：一种基于抗散射网络的水下载体激光雷达-雷达成像架构|Xuelong Li, Hongjun An, Haofei Zhao, Guangying Li, Bo Liu, Xing Wang, Guanghua Cheng, Guojun Wu .etc.|<http://arxiv.org/pdf/2404.09158v4>|[代码](https://github.com/BestAnHongjun/StreakNet); 提出StreakNet-Arch框架，利用自注意力与双分支交叉注意力抑制水下散射，实现实时高效成像。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Improving Lightweight Weed Detection via Knowledge Distillation|通过知识蒸馏改进轻量级杂草检测|Ahmet Oğuz Saltık, Max Voigt, Sourav Modak, Mike Beckworth, Anthony Stein|<http://arxiv.org/pdf/2507.12344v1>|通过知识蒸馏技术提升轻量级杂草检测模型性能，实现更精准的实时智能喷雾。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Watch, Listen, Understand, Mislead: Tri-modal Adversarial Attacks on Short Videos for Content Appropriateness Evaluation|观看、倾听、理解、误导：针对短视频内容适宜性评估的三模态对抗攻击|Sahid Hossain Mustakim, S M Jishanul Islam, Ummay Maria Muna, Montasir Chowdhury, Mohammed Jawwadul Islam, Sadia Ahmmed, Tashfia Sikder, Syed Tasdid Azam Dhrubo .etc.|<http://arxiv.org/pdf/2507.11968v1>|提出三模态攻击策略ChimeraBreak和SVMA数据集，揭示了MLLMs在短视频内容审核中的安全...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DUNIA: Pixel-Sized Embeddings via Cross-Modal Alignment for Earth Observation Applications|DUNIA：通过跨模态对齐实现像素级嵌入的地球观测应用|Ibrahim Fayad, Max Zimmer, Martin Schwartz, Fabian Gieseke, Philippe Ciais, Gabriel Belouze, Sarah Brood, Aurelien De Truchis .etc.|<http://arxiv.org/pdf/2502.17066v2>|提出了一种通过跨模态对齐学习像素级嵌入的方法，有效提升了地球观测应用中的多任务性能。|
|🆕 发布|PROL : Rehearsal Free Continual Learning in Streaming Data via Prompt Online Learning|PROL：通过提示在线学习在流数据中实现无需复习的持续学习|M. Anwar Ma'sum, Mahardhika Pratama, Savitha Ramasamy, Lin Liu, Habibullah Habibullah, Ryszard Kowalczyk|<http://arxiv.org/pdf/2507.12305v1>|[代码](https://github.com/anwarmaxsum/PROL.); 提出了一种无需复习的在线连续学习方法，通过创新的prompt生成机制有效解决了数据隐私约束下的灾难性...|
|📝 更新|SPOT: Scalable 3D Pre-training via Occupancy Prediction for Learning Transferable 3D Representations|SPOT：通过占用预测进行可扩展的3D预训练，以学习迁移性3D表征|Xiangchao Yan, Runjian Chen, Bo Zhang, Hancheng Ye, Renqiu Xia, Jiakang Yuan, Hongbin Zhou, Xinyu Cai .etc.|<http://arxiv.org/pdf/2309.10527v4>|提出SPOT方法，通过占用预测进行三维表示预训练，减少标注负担并提升泛化性能。|
|📝 更新|PATCH: a deep learning method to assess heterogeneity of artistic practice in historical paintings|PATCH：一种用于评估历史绘画艺术实践异质性的深度学习方法|Andrew Van Horn, Lauryn Smith, Mahamad Mahmoud, Michael McMaster, Clara Pinchbeck, Ina Martin, Andrew Lininger, Anthony Ingrisano .etc.|<http://arxiv.org/pdf/2502.01912v3>|提出了一种无需外部训练数据识别艺术家创作风格的机器学习方法PATCH。|
|🆕 发布|A Survey of Deep Learning for Geometry Problem Solving|深度学习在几何问题解决中的研究综述|Jianzhe Ma, Wenxuan Wang, Qin Jin|<http://arxiv.org/pdf/2507.11936v1>|[代码](https://github.com/majianz/dl4gps.); 概述了深度学习在几何问题解决中的应用，总结了任务、方法、评价指标，并探讨了未来发展方向。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AU-Blendshape for Fine-grained Stylized 3D Facial Expression Manipulation|基于AU-Blendshape的细粒度风格化三维面部表情操纵|Hao Li, Ju Dai, Feng Zhou, Kaida Ning, Lei Li, Junjun Pan|<http://arxiv.org/pdf/2507.12001v1>|[代码](https://github.com/wslh852/AUBlendNet.git.); 提出AUBlendSet和AUBlendNet，实现跨身份的细粒度风格化3D面部表情操纵。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Cluster Contrast for Unsupervised Visual Representation Learning|无监督视觉表征学习中的簇对比|Nikolaos Giakoumoglou, Tania Stathaki|<http://arxiv.org/pdf/2507.12359v1>|提出Cluster Contrast方法，结合对比学习和聚类技术，提升无监督视觉表征学习性能。|
|🆕 发布|MGFFD-VLM: Multi-Granularity Prompt Learning for Face Forgery Detection with VLM|多粒度提示学习结合视觉语言模型用于人脸伪造检测的MGFFD-VLM|Tao Chen, Jingyi Zhang, Decheng Liu, Chunlei Peng|<http://arxiv.org/pdf/2507.12232v1>|提出多粒度提示学习框架MGFFD-VLM，增强视觉大语言模型在人脸伪造检测与解释能力。|
|📝 更新|From Objects to Events: Unlocking Complex Visual Understanding in Object Detectors via LLM-guided Symbolic Reasoning|从对象到事件：通过大型语言模型引导的符号推理解锁对象检测器中的复杂视觉理解|Yuhui Zeng, Haoxiang Wu, Wenjie Nie, Xiawu Zheng, Guangyao Chen, Yunhang Shen, Jun Peng, Yonghong Tian .etc.|<http://arxiv.org/pdf/2502.05843v4>|[代码](https://github.com/MAC-AutoML/SymbolicDet); 提出了一种利用LLM引导的符号推理框架，将标准对象检测扩展到复杂事件理解，无需特定任务训练。|
|🆕 发布|MoViAD: Modular Visual Anomaly Detection|模块化视觉异常检测|Manuel Barusco, Francesco Borsatti, Arianna Stropeni, Davide Dalle Pezze, Gian Antonio Susto|<http://arxiv.org/pdf/2507.12049v1>|提出MoViAD库，加速视觉异常检测研究，提供多样化模型和工具，支持边缘计算和物联网部署。|
|📝 更新|HueManity: Probing Fine-Grained Visual Perception in MLLMs|《HueManity：在多模态大型语言模型中探究细粒度视觉感知》|Rynaa Grover, Jayant Sravan Tamarapalli, Sahiti Yerramilli, Nilay Pande|<http://arxiv.org/pdf/2506.03194v2>|定位了大型多模态语言模型在细微视觉感知任务上的不足，并提出了HueManity基准测试来评估其视觉感...|
|📝 更新|DRISHTIKON: Visual Grounding at Multiple Granularities in Documents|《DRISHTIKON：文档中多粒度视觉定位》|Badri Vishal Kasuba, Parag Chaudhuri, Ganesh Ramakrishnan|<http://arxiv.org/pdf/2506.21316v2>|提出多粒度视觉定位框架DRISHTIKON，提升复杂文档VQA系统的解释性和准确性。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Neurons: Emulating the Human Visual Cortex Improves Fidelity and Interpretability in fMRI-to-Video Reconstruction|神经元：模拟人类视觉皮层提高fMRI至视频重建的保真度和可解释性|Haonan Wang, Qixiang Zhang, Lehan Wang, Xuanqi Huang, Xiaomeng Li|<http://arxiv.org/pdf/2503.11167v3>|[代码](https://github.com/xmed-lab/NEURONS.); 提出NEURONS框架，模拟人脑视觉皮层结构，提升fMRI视频重建的准确性和连贯性。|
|🆕 发布|From Coarse to Nuanced: Cross-Modal Alignment of Fine-Grained Linguistic Cues and Visual Salient Regions for Dynamic Emotion Recognition|从粗略到细微：细粒度语言线索与视觉显著区域的跨模态对齐用于动态情感识别|Yu Liu, Leyuan Qu, Hanlei Shi, Di Gao, Yuhua Zheng, Taihao Li|<http://arxiv.org/pdf/2507.11892v1>|提出了一种融合动态运动建模、语义文本精炼和跨模态对齐的GRACE方法，有效提升了动态表情识别的准确性...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Language-Guided Contrastive Audio-Visual Masked Autoencoder with Automatically Generated Audio-Visual-Text Triplets from Videos|语言引导的对比音频视觉掩码自编码器：从视频中自动生成的音频-视觉-文本三元组|Yuchi Ishikawa, Shota Nakada, Hokuto Munakata, Kazuhiro Saito, Tatsuya Komatsu, Yoshimitsu Aoki|<http://arxiv.org/pdf/2507.11967v1>|提出了一种结合文本引导的对比音频视觉掩码自编码器，通过自动生成音视频文本三元组，有效提升了音视频表征...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Interpreting Radiologist's Intention from Eye Movements in Chest X-ray Diagnosis|从胸片诊断中眼动解读放射科医生的意图|Trong-Thang Pham, Anh Nguyen, Zhigang Deng, Carol C. Wu, Hien Van Nguyen, Ngan Le|<http://arxiv.org/pdf/2507.12461v1>|提出了一种基于深度学习的RadGazeIntent方法，能够理解和预测放射科医生在X光诊断中的诊断意...|
|📝 更新|4D-MISR: A unified model for low-dose super-resolution imaging via feature fusion|4D-MISR：一种通过特征融合实现低剂量超分辨率成像的统一模型|Zifei Wang, Zian Mao, Xiaoya He, Xi Huang, Haoran Zhang, Chun Cheng, Shufen Chu, Tingzheng Hou .etc.|<http://arxiv.org/pdf/2507.09953v2>|提出了一种融合多角度观测特征的网络模型，实现了低剂量下电子显微成像的原子级超分辨率重建。|
|🆕 发布|Text-driven Multiplanar Visual Interaction for Semi-supervised Medical Image Segmentation|基于文本驱动的多平面视觉交互用于半监督医学图像分割|Kaiwen Huang, Yi Zhou, Huazhu Fu, Yizhe Zhang, Chen Gong, Tao Zhou|<http://arxiv.org/pdf/2507.12382v1>|[代码](https://github.com/taozh2017/Text-SemiSeg.); 提出了一种融合文本信息的半监督医疗图像分割框架，有效提升视觉特征并减少标注成本。|
|📝 更新|SPA: Efficient User-Preference Alignment against Uncertainty in Medical Image Segmentation|SPA：针对医学图像分割中不确定性的高效用户偏好对齐|Jiayuan Zhu, Junde Wu, Cheng Ouyang, Konstantinos Kamnitsas, J. Alison Noble|<http://arxiv.org/pdf/2411.15513v2>|提出SPA框架，通过少量候选分割适应不同用户偏好，减少人力负担并提升医学图像分割效率。|
|🆕 发布|Comparative Analysis of CNN Performance in Keras, PyTorch and JAX on PathMNIST|《Keras、PyTorch和JAX在PathMNIST数据集上卷积神经网络性能的比较分析》|Anida Nezović, Jalal Romano, Nada Marić, Medina Kapo, Amila Akagić|<http://arxiv.org/pdf/2507.12248v1>|比较了Keras、PyTorch和JAX中CNN在医疗图像分类的性能，揭示了计算速度与模型精度间的权...|
|🆕 发布|Generate to Ground: Multimodal Text Conditioning Boosts Phrase Grounding in Medical Vision-Language Models|从生成到定位：多模态文本条件增强医学视觉语言模型中的短语定位|Felix Nützel, Mischa Dombrowski, Bernhard Kainz|<http://arxiv.org/pdf/2507.12236v1>|[代码](https://github.com/Felix-012/generate_to_ground.); 提出生成式模型结合跨注意力机制，实现医学影像短语定位性能显著提升。|
|📝 更新|2.5D Object Detection for Intelligent Roadside Infrastructure|智能路边基础设施的2.5D目标检测|Nikolai Polley, Yacin Boualili, Ferdinand Mütsch, Maximilian Zipfl, Tobias Fleck, J. Marius Zöllner|<http://arxiv.org/pdf/2507.03564v2>|提出了一种针对路边基础设施的2.5D物体检测框架，通过预测车辆在图像中的平行四边形地面位置，实现了高...|
|📝 更新|LHU-Net: a Lean Hybrid U-Net for Cost-efficient, High-performance Volumetric Segmentation|LHU-Net：一种面向成本效益高、性能优越的体积分割的精简混合U-Net|Yousef Sadegheih, Afshin Bozorgpour, Pratibha Kumari, Reza Azad, Dorit Merhof|<http://arxiv.org/pdf/2404.05102v3>|[代码](https://github.com/xmindflow/LHUNet); 提出了一种高效的 Lean Hybrid U-Net 结构，通过优化空间和通道特征提取，实现了高精度...|
|🆕 发布|DeepShade: Enable Shade Simulation by Text-conditioned Image Generation|深度遮荫：通过文本条件图像生成实现遮荫模拟|Longchao Da, Xiangrui Liu, Mithun Shivakoti, Thirulogasankar Pranav Kutralingam, Yezhou Yang, Hua Wei|<http://arxiv.org/pdf/2507.12103v1>|提出了一种结合文本描述的扩散模型DeepShade，用于生成不同时间和条件下的城市阴影，助力极端天气...|
|🆕 发布|Benchmarking and Explaining Deep Learning Cortical Lesion MRI Segmentation in Multiple Sclerosis|多发性硬化症深层学习皮质病变MRI分割的基准测试与解释|Nataliia Molchanova, Alessandro Cagol, Mario Ocampo-Pineda, Po-Jui Lu, Matthias Weigel, Xinjie Chen, Erin Beck, Charidimos Tsagkas .etc.|<http://arxiv.org/pdf/2507.12092v1>|提出了一种多中心基准的皮质病变MRI分割方法，通过自适应nnU-Net框架和模型分析，提高了多发性硬...|
|📝 更新|CFFormer: Cross CNN-Transformer Channel Attention and Spatial Feature Fusion for Improved Segmentation of Heterogeneous Medical Images|CFFormer：跨卷积神经网络-变换器通道注意力与空间特征融合用于异质医学图像的改进分割|Jiaxuan Li, Qing Xu, Xiangjian He, Ziyu Liu, Daokun Zhang, Ruili Wang, Rong Qu, Guoping Qiu|<http://arxiv.org/pdf/2501.03629v2>|[代码](https://github.com/JiaxuanFelix/CFFormer.); 提出了一种结合CNN和Transformer的模型CFFormer，通过跨通道注意力和空间特征融合显...|
|📝 更新|Alleviating Textual Reliance in Medical Language-guided Segmentation via Prototype-driven Semantic Approximation|通过原型驱动的语义近似减轻医学语言引导分割中的文本依赖性|Shuchang Ye, Usman Naseem, Mingyuan Meng, Jinman Kim|<http://arxiv.org/pdf/2507.11055v2>|提出ProLearn框架，通过原型驱动的语义近似减轻医学图像分割对文本的依赖。|
|🆕 发布|Identifying Signatures of Image Phenotypes to Track Treatment Response in Liver Disease|识别图像表型的特征以追踪肝病患者治疗反应|Matthias Perkonigg, Nina Bastati, Ahmed Ba-Ssalamah, Peter Mesenbrink, Alexander Goehler, Miljen Martic, Xiaofei Zhou, Michael Trauner .etc.|<http://arxiv.org/pdf/2507.12012v1>|利用无监督机器学习从肝脏磁共振图像中识别出与治疗响应相关的图像模式，以量化弥漫性肝病治疗效果。|
|📝 更新|Position Prediction Self-Supervised Learning for Multimodal Satellite Imagery Semantic Segmentation|多模态卫星影像语义分割中的位置预测自监督学习|John Waithaka, Moise Busogi|<http://arxiv.org/pdf/2506.06852v2>|提出位置预测自监督学习方法，用于多模态卫星图像语义分割，优于传统重建方法。|
|📝 更新|Cross-modal Ship Re-Identification via Optical and SAR Imagery: A Novel Dataset and Method|跨模态船舶重识别：基于光学与合成孔径雷达图像的新数据集与方法|Han Wang, Shengyang Li, Jian Yang, Yuxuan Liu, Yixuan Lv, Zhuang Zhou|<http://arxiv.org/pdf/2506.22027v3>|[代码](https://github.com/Alioth2000/Hoss-ReID.); 提出了一种基于光学和合成孔径雷达的跨模态船舶重识别方法，创建了适用于全天候船舶追踪的新数据集。|
|📝 更新|Boosting Memory Efficiency in Transfer Learning for High-Resolution Medical Image Classification|提高迁移学习在高分辨率医学图像分类中的内存效率|Yijin Huang, Pujin Cheng, Roger Tam, Xiaoying Tang|<http://arxiv.org/pdf/2408.02426v3>|[代码](https://github.com/YijinHuang/FPT.); 提出了一种高效的参数高效迁移学习策略FPT+，通过轻量级网络和细粒度提示减少高分辨率医疗图像分类的训...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SAMST: A Transformer framework based on SAM pseudo label filtering for remote sensing semi-supervised semantic segmentation|SAMST：基于SAM伪标签过滤的遥感半监督语义分割Transformer框架|Jun Yin, Fei Wu, Yupeng Ren, Jisheng Huang, Qiankun Li, Heng jin, Jianhai Fu, Chanjie Cui|<http://arxiv.org/pdf/2507.11994v1>|提出SAMST方法，通过迭代优化伪标签，利用大型模型泛化能力和小型模型训练效率，提升遥感图像半监督语...|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Autonomous Riding: A Review of Perception, Planning, and Control in Intelligent Two-Wheelers|面向自主骑行：智能两轮车感知、规划与控制综述|Mohammed Hassanin, Mohammad Abu Alsheikh, Carlos C. N. Kuhn, Damith Herath, Dinh Thai Hoang, Ibrahim Radwan|<http://arxiv.org/pdf/2507.11852v1>|系统分析了两轮车自主骑行技术的感知、规划和控制挑战，指出了研究空白和未来方向。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AutoVDC: Automated Vision Data Cleaning Using Vision-Language Models|自动视觉数据清洗：基于视觉-语言模型的自动化方法|Santosh Vasa, Aditi Ramadwar, Jnana Rama Krishna Darabattula, Md Zafar Anwar, Stanislaw Antol, Andrei Vatavu, Thomas Monninger, Sihao Ding|<http://arxiv.org/pdf/2507.12414v1>|提出了一种自动视觉数据清洗框架AutoVDC，利用视觉语言模型自动识别并清除数据集中的错误标注，提升...|


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Revealing the Ancient Beauty: Digital Reconstruction of Temple Tiles using Computer Vision|揭示古老之美：利用计算机视觉进行寺庙瓦片的数字重建|Arkaprabha Basu|<http://arxiv.org/pdf/2507.12195v1>|提出三种先进技术实现印度古迹瓷砖的高效数字化重构与修复，保持传统与创新平衡。|
|📝 更新|Jumpstarting Surgical Computer Vision|启动手术计算机视觉|Deepak Alapatt, Aditya Murali, Vinkle Srivastav, Pietro Mascagni, AI4SafeChole Consortium, Nicolas Padoy|<http://arxiv.org/pdf/2312.05968v2>|提出利用自监督学习初始化减少对大规模标注数据集的依赖，优化了手术数据科学领域的模型训练。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AD-GS: Object-Aware B-Spline Gaussian Splatting for Self-Supervised Autonomous Driving|AD-GS：面向对象的自监督自动驾驶B样条高斯散点绘制方法|Jiawei Xu, Kai Deng, Zexin Fan, Shenlong Wang, Jin Xie, Jian Yang|<http://arxiv.org/pdf/2507.12137v1>|提出了一种无需标注的高质量自监督框架AD-GS，通过结合局部B样条曲线和全局三角函数建模动态物体运动...|
|📝 更新|KISS-Matcher: Fast and Robust Point Cloud Registration Revisited|KISS-Matcher：重新审视快速且稳健的点云配准|Hyungtae Lim, Daebeom Kim, Gunhee Shin, Jingnan Shi, Ignacio Vizzo, Hyun Myung, Jaesik Park, Luca Carlone|<http://arxiv.org/pdf/2409.15615v3>|[代码](https://github.com/MIT-SPARK/KISS-Matcher.); 提出了一种全面的点云配准方法KISS-Matcher，通过改进特征检测和图论剪枝技术，实现了快速且鲁...|

