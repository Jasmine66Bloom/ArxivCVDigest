## [UPDATED!] **2025-07-17** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VisionThink: Smart and Efficient Vision Language Model via Reinforcement Learning|《VisionThink：通过强化学习实现的智能高效视觉语言模型》|Senqiao Yang, Junyi Li, Xin Lai, Bei Yu, Hengshuang Zhao, Jiaya Jia|<http://arxiv.org/pdf/2507.13348v1>|[代码](https://github.com/dvlab-research/VisionThink.); 提出动态调整图像分辨率的方法VisionThink，通过智能判断和 reinforcement le...|
|🆕 发布|SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models|基于多模态大型语言模型的自我进化视觉-语言导航框架：SE-VLN|Xiangyu Dong, Haoran Zhao, Jiang Gao, Haozhou Li, Xiaoguang Ma, Yaoming Zhou, Fuhai Chen, Juan Liu|<http://arxiv.org/pdf/2507.13152v1>|提出了一种自进化的视觉语言导航框架SE-VLN，通过持续学习提升未知环境中的导航成功率。|
|📝 更新|(Almost) Free Modality Stitching of Foundation Models|基础模型的（几乎）免费模态拼接|Jaisidh Singh, Diganta Misra, Boris Knyazev, Antonio Orvieto|<http://arxiv.org/pdf/2507.10015v3>|提出了一种利用超网络进行模态模型选择和连接训练的方法，大幅降低了多模态基础模型构建的计算成本。|
|🆕 发布|Domain-Enhanced Dual-Branch Model for Efficient and Interpretable Accident Anticipation|域增强双分支模型用于高效和可解释的事故预判|Yanchen Guan, Haicheng Liao, Chengyue Wang, Bonan Wang, Jiaxun Zhang, Jia Hu, Zhenning Li|<http://arxiv.org/pdf/2507.12755v1>|提出双分支架构模型，融合视觉与文本数据，高效准确预测交通事故。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|$S^2M^2$: Scalable Stereo Matching Model for Reliable Depth Estimation|"S^2M^2": 可扩展立体匹配模型用于可靠深度估计|Junhong Min, Youngpil Jeon, Jimin Kim, Minyong Choi|<http://arxiv.org/pdf/2507.13229v1>|提出全局匹配架构$S^2M^2$，平衡了立体匹配的准确性与效率，无需特定数据集微调即可实现高质量深度...|
|🆕 发布|DINO-VO: A Feature-based Visual Odometry Leveraging a Visual Foundation Model|DINO-VO：一种基于特征的可视化里程计，利用视觉基础模型|Maulana Bisyir Azhari, David Hyunchul Shim|<http://arxiv.org/pdf/2507.13145v1>|提出DINO-VO系统，利用视觉基础模型提升视觉里程计的鲁棒性和泛化能力。|
|🆕 发布|DASViT: Differentiable Architecture Search for Vision Transformer|DASViT：用于视觉变换器的可微分架构搜索|Pengjin Wu, Ferrante Neri, Zhenhua Feng|<http://arxiv.org/pdf/2507.13079v1>|提出了一种用于自动发现创新Vision Transformer架构的微分搜索方法DASViT，提升了...|
|🆕 发布|Unleashing Vision Foundation Models for Coronary Artery Segmentation: Parallel ViT-CNN Encoding and Variational Fusion|释放视觉基础模型用于冠状动脉分割：并行ViT-CNN编码与变分融合|Caixia Dong, Duwei Dai, Xinyi Han, Fan Liu, Xu Yang, Zongfang Li, Songhua Xu|<http://arxiv.org/pdf/2507.12938v1>|[代码](https://github.com/d1c2x3/CAseg.); 提出了一种结合视觉变换器和卷积神经网络的新型框架，通过自适应融合和不确定性优化显著提升了冠状动脉分割...|
|📝 更新|DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge|梦幻VLA：一种融合全面世界知识的视觉-语言-动作模型|Wenyao Zhang, Hongsi Liu, Zekun Qi, Yunnan Wang, Xinqiang Yu, Jiazhao Zhang, Runpei Dong, Jiawei He .etc.|<http://arxiv.org/pdf/2507.04447v2>|DreamVLA通过融合全面的世界知识预测，优化了机器人操作任务中的感知-预测-行动循环。|
|🆕 发布|Compact Vision Transformer by Reduction of Kernel Complexity|通过降低核复杂性实现的紧凑视觉变换器|Yancheng Wang, Yingzhen Yang|<http://arxiv.org/pdf/2507.12780v1>|提出了一种降低计算复杂度的紧凑视觉Transformer结构，通过输入输出通道选择减少计算量同时保持...|
|🆕 发布|Transformer-based Spatial Grounding: A Comprehensive Survey|基于Transformer的空间定位：全面综述|Ijazul Haq, Muhammad Saqib, Yingjie Zhang|<http://arxiv.org/pdf/2507.12739v1>|系统综述了基于Transformer的视觉定位方法，揭示了关键架构、数据集和评估指标，推动领域发展。|
|🆕 发布|Pixel Perfect MegaMed: A Megapixel-Scale Vision-Language Foundation Model for Generating High Resolution Medical Images|像素级完美MegaMed：一种用于生成高分辨率医学图像的兆像素级视觉-语言基础模型|Zahra TehraniNasab, Amar Kumar, Tal Arbel|<http://arxiv.org/pdf/2507.12698v1>|[代码](https://tehraninasab.github.io/pixelperfect-megamed.); Pixel Perfect MegaMed通过多尺度变换器架构和视觉语言对齐技术，首次实现了生成10...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Argus: Leveraging Multiview Images for Improved 3-D Scene Understanding With Large Language Models|“Argus：利用多视角图像结合大型语言模型提升三维场景理解”|Yifan Xu, Chao Zhang, Hanqi Jiang, Xiaoyan Wang, Ruifei Ma, Yiwei Li, Zihao Wu, Zeju Li .etc.|<http://arxiv.org/pdf/2507.12916v1>|提出Argus框架，利用多视角图像增强大型语言模型对3D场景的理解能力。|
|🆕 发布|Semantic-guided Fine-tuning of Foundation Model for Long-tailed Visual Recognition|面向长尾视觉识别的基础模型语义引导微调|Yufei Peng, Yonggang Zhang, Yiu-ming Cheung|<http://arxiv.org/pdf/2507.12807v1>|提出了一种融合文本语义指导的视觉模型微调方法，有效提升了长尾分布下的识别性能。|
|🆕 发布|City-VLM: Towards Multidomain Perception Scene Understanding via Multimodal Incomplete Learning|城市视觉语言模型：通过多模态不完整学习实现跨领域感知场景理解|Penglei Sun, Yaoxian Song, Xiangru Zhu, Xiang Liu, Qiang Wang, Yue Liu, Changqun Xia, Tiefeng Li .etc.|<http://arxiv.org/pdf/2507.12795v1>|提出首个面向多域感知的户外场景理解数据集SVM-City，并设计City-VLM模型融合多模态信息，...|
|🆕 发布|Multimodal-Guided Dynamic Dataset Pruning for Robust and Efficient Data-Centric Learning|多模态引导的动态数据集剪枝，用于稳健且高效的数据驱动学习|Suorong Yang, Peijia Li, Yujie Liu, Zhiming Xu, Peng Ye, Wanli Ouyang, Furao Shen, Dongzhan Zhou|<http://arxiv.org/pdf/2507.12750v1>|提出了一种自适应选择训练样本的动态数据集剪枝框架，结合任务难度和跨模态语义一致性，提升数据驱动学习的...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Real-Time System for Egocentric Hand-Object Interaction Detection in Industrial Domains|面向工业领域的实时自我中心手-对象交互检测系统|Antonio Finocchiaro, Alessandro Sebastiano Catinello, Michele Mazzamuto, Rosario Leonardi, Antonino Furnari, Giovanni Maria Farinella|<http://arxiv.org/pdf/2507.13326v1>|提出了一种实时系统，通过结合动作识别和物体检测模块，有效实现了工业领域中第一视角手-物交互的检测。|
|🆕 发布|Decoupled PROB: Decoupled Query Initialization Tasks and Objectness-Class Learning for Open World Object Detection|解耦PROB：解耦查询初始化任务与开放世界目标检测中的对象性-类别学习|Riku Inoue, Masamitsu Tsuchiya, Yuji Yasui|<http://arxiv.org/pdf/2507.13085v1>|提出了一种解决学习冲突问题的Decoupled PROB模型，通过Early Termination...|
|📝 更新|Uncertainty quantification for White Matter Hyperintensity segmentation detects silent failures and improves automated Fazekas quantification|白质高信号分割的不确定性量化检测沉默性失败并提高自动化Fazekas量化的准确性|Ben Philps, Maria del C. Valdes Hernandez, Chen Qin, Una Clancy, Eleni Sakka, Susana Munoz Maniega, Mark E. Bastin, Angela C. C. Jochems .etc.|<http://arxiv.org/pdf/2411.17571v2>|提出不确定性量化方法，降低脑部白质高信号区段失败率，并提升临床 Fazekas 评分分类性能。|
|🆕 发布|Beyond Fully Supervised Pixel Annotations: Scribble-Driven Weakly-Supervised Framework for Image Manipulation Localization|超越完全监督像素标注：基于涂抹驱动的弱监督图像操作定位框架|Songlin Li, Guofeng Yu, Zhiqing Guo, Yunfeng Diao, Dan Ma, Gaobo Yang, Liejun Wang|<http://arxiv.org/pdf/2507.13018v1>|提出了一种基于涂鸦标注的弱监督图像篡改定位框架，通过结构一致性损失和自适应特征调制模块提高了检测性能...|
|🆕 发布|SOD-YOLO: Enhancing YOLO-Based Detection of Small Objects in UAV Imagery|SOD-YOLO：增强基于YOLO的小型目标在无人机影像中的检测|Peijun Wang, Jinhua Zhao|<http://arxiv.org/pdf/2507.12727v1>|[代码](https://github.com/iamwangxiaobai/SOD-YOLO.); 提出了一种改进的YOLOv8模型SOD-YOLO，通过增强多尺度特征融合和引入专门的小目标检测层，显...|
|📝 更新|USIS16K: High-Quality Dataset for Underwater Salient Instance Segmentation|USIS16K：水下显著实例分割的高质量数据集|Lin Hong, Xin Wang, Yihao Li, Xia Wang|<http://arxiv.org/pdf/2506.19472v2>|提出USIS16K数据集，为水下显著实例分割提供大规模高质量标注图像，推动领域研究发展。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Revisiting Reliability in the Reasoning-based Pose Estimation Benchmark|重新审视基于推理的姿势估计基准中的可靠性问题|Junsu Kim, Naeun Kim, Jaeho Lee, Incheol Park, Dongyoon Han, Seungryul Baek|<http://arxiv.org/pdf/2507.13314v1>|指出现有姿态估计基准存在的问题，并通过精确匹配和开源 refined 注解改进了重现性和评估一致性。|
|📝 更新|Salvaging the Overlooked: Leveraging Class-Aware Contrastive Learning for Multi-Class Anomaly Detection|《挽救被忽视的：利用类别感知对比学习进行多类异常检测》|Lei Fan, Junjie Huang, Donglin Di, Anyang Su, Tianyou Song, Maurice Pagnucco, Yang Song|<http://arxiv.org/pdf/2412.04769v2>|提出了一种针对多类异常检测的性能退化问题，通过引入类感知对比学习显著提升了模型性能。|
|🆕 发布|Leveraging Language Prior for Infrared Small Target Detection|利用语言先验知识进行红外小目标检测|Pranav Singh, Pravendra Singh|<http://arxiv.org/pdf/2507.13113v1>|引入语言先验知识，提出了一种多模态红外小目标检测框架，有效提升了检测精度。|
|🆕 发布|Channel-wise Motion Features for Efficient Motion Segmentation|逐通道运动特征用于高效运动分割|Riku Inoue, Masamitsu Tsuchiya, Yuji Yasui|<http://arxiv.org/pdf/2507.13082v1>|提出了一种高效的通道运动特征表示方法，通过仅使用姿态网络大幅提升运动分割的实时性能和准确性。|
|🆕 发布|Label-Consistent Dataset Distillation with Detector-Guided Refinement|标签一致性数据集蒸馏与检测器引导的细化|Yawen Zou, Guang Li, Zi Wang, Chunzhi Gu, Chao Zhang|<http://arxiv.org/pdf/2507.13074v1>|提出了一种利用预训练检测器确保标签一致性和提升图像质量的探测器引导数据集精炼方法。|
|🆕 发布|LanePerf: a Performance Estimation Framework for Lane Detection|车道性能评估框架：LanePerf：用于车道检测的性能估计框架|Yin Wu, Daniel Slieter, Ahmed Abouelazm, Christian Hubschneider, J. Marius Zöllner|<http://arxiv.org/pdf/2507.12894v1>|提出了一种新的无标签性能评估框架LanePerf，有效应对车道检测模型在不同环境下的性能估计问题。|
|🆕 发布|AthleticsPose: Authentic Sports Motion Dataset on Athletic Field and Evaluation of Monocular 3D Pose Estimation Ability|《AthleticsPose：运动场上真实的体育动作数据集及单目3D姿态估计能力的评估》|Tomohiro Suzuki, Ryota Tanaka, Calvin Yeung, Keisuke Fujii|<http://arxiv.org/pdf/2507.12905v1>|[代码](https://github.com/SZucchini/AthleticsPose.); 提出了AthleticsPose数据集，通过真实运动数据显著提升了单目3D姿态估计模型在体育分析中的...|
|🆕 发布|From Neck to Head: Bio-Impedance Sensing for Head Pose Estimation|从颈部到头部：基于生物阻抗感知的头部姿态估计|Mengxi Liu, Lala Shakti Swarup Ray, Sizhen Bian, Ko Watanabe, Ankur Bhatt, Joanna Sorysz, Russel Torah, Bo Zhou .etc.|<http://arxiv.org/pdf/2507.12884v1>|提出了一种利用颈部生物阻抗感应的穿戴系统，通过深度学习框架实现精准的头姿估计。|
|🆕 发布|FAR-Net: Multi-Stage Fusion Network with Enhanced Semantic Alignment and Adaptive Reconciliation for Composed Image Retrieval|FAR-Net：具有增强语义对齐和自适应协调的多阶段融合网络，用于组合图像检索|Jeong-Woo Park, Young-Eun Kim, Seong-Whan Lee|<http://arxiv.org/pdf/2507.12823v1>|提出多阶段融合的FAR-Net，通过增强语义对齐和自适应协调，有效提升组合图像检索性能。|
|📝 更新|Cascaded Multi-Scale Attention for Enhanced Multi-Scale Feature Extraction and Interaction with Low-Resolution Images|级联多尺度注意力增强多尺度特征提取与低分辨率图像交互|Xiangyong Lu, Masanori Suganuma, Takayuki Okatani|<http://arxiv.org/pdf/2412.02197v2>|[代码](https://github.com/xyongLu/CMSA.); 提出了一种针对低分辨率图像的级联多尺度注意力机制，有效提升了多尺度特征提取和融合能力。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SIDDA: SInkhorn Dynamic Domain Adaptation for Image Classification with Equivariant Neural Networks|SIDDA：基于等变神经网络的Sinkhorn动态域自适应图像分类|Sneh Pandya, Purvik Patel, Brian D. Nord, Mike Walmsley, Aleksandra Ćiprijanović|<http://arxiv.org/pdf/2501.14048v2>|提出了SIDDA算法，通过Sinkhorn散度实现最小化超参数调整和计算开销的域自适应，有效提升神经...|
|📝 更新|Color Image Set Recognition Based on Quaternionic Grassmannians|基于四元数Grassmannian的色彩图像集识别|Xiang Xiang Wang, Tin-Yau Tam|<http://arxiv.org/pdf/2505.23629v2>|提出了一种基于四元数Grassmannians的色彩图像集识别方法，有效提升了识别准确度。|
|🆕 发布|Federated Learning for Commercial Image Sources|联邦学习在商业图像源中的应用|Shreyansh Jain, Koteswar Rao Jerripothula|<http://arxiv.org/pdf/2507.12903v1>|首次为联邦学习设计图像分类数据集，并提出两种新算法Fed-Cyclic和Fed-Star以提升性能。|
|🆕 发布|Feature-Enhanced TResNet for Fine-Grained Food Image Classification|特征增强的TResNet用于细粒度食品图像分类|Lulu Liu, Zhiyong Xiao|<http://arxiv.org/pdf/2507.12828v1>|提出Feature-Enhanced TResNet模型，通过集成StyleRM和DCA技术，有效提...|
|📝 更新|OscNet v1.5: Energy Efficient Hopfield Network on CMOS Oscillators for Image Classification|振荡网v1.5：基于CMOS振荡器的能量高效Hopfield网络用于图像分类|Wenxiao Cai, Zongru Li, Iris Wang, Yu-Neng Wang, Thomas H. Lee|<http://arxiv.org/pdf/2506.12610v2>|[代码](https://github.com/RussRobin/OscNet); 提出了一种基于CMOS振荡器的Hopfield网络，实现了低能耗的图像分类。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|BPD-Neo: An MRI Dataset for Lung-Trachea Segmentation with Clinical Data for Neonatal Bronchopulmonary Dysplasia|BPD-Neo：一种用于新生儿支气管肺发育不良的肺-气管分割的MRI数据集及临床数据|Rachit Saluja, Arzu Kovanlikaya, Candace Chien, Lauren Kathryn Blatt, Jeffrey M. Perlman, Stefan Worgall, Mert R. Sabuncu, Jonathan P. Dyke|<http://arxiv.org/pdf/2506.23305v2>|构建了一个用于新生儿支气管肺发育不良的MRI图像数据集，助力无创诊断与精准医疗研究。|
|📝 更新|A Brain Tumor Segmentation Method Based on CLIP and 3D U-Net with Cross-Modal Semantic Guidance and Multi-Level Feature Fusion|基于CLIP和3D U-Net的脑肿瘤分割方法：跨模态语义引导与多层次特征融合|Mingda Zhang|<http://arxiv.org/pdf/2507.09966v2>|提出了一种融合CLIP模型与3D U-Net的脑肿瘤分割方法，通过多模态语义引导和多层次特征融合提升...|
|🆕 发布|A Privacy-Preserving Semantic-Segmentation Method Using Domain-Adaptation Technique|一种使用域适应技术的隐私保护语义分割方法|Homare Sueyoshi, Kiyoshi Nishikawa, Hitoshi Kiya|<http://arxiv.org/pdf/2507.12730v1>|提出了一种保护隐私的语义分割方法，通过在训练和测试图像上应用感知加密，并采用域适应技术保持模型精度。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Diffuman4D: 4D Consistent Human View Synthesis from Sparse-View Videos with Spatio-Temporal Diffusion Models|Diffuman4D：基于时空扩散模型的稀疏视角视频四维一致人体视图合成|Yudong Jin, Sida Peng, Xuan Wang, Tao Xie, Zhen Xu, Yifan Yang, Yujun Shen, Hujun Bao .etc.|<http://arxiv.org/pdf/2507.13344v1>|提出滑动迭代去噪流程增强4D扩散模型时空一致性，实现高质量人类视角视频合成。|
|🆕 发布|DiffClean: Diffusion-based Makeup Removal for Accurate Age Estimation|扩散去妆：基于扩散的精准年龄估计化妆去除方法|Ekta Balkrishna Gavas, Chinmay Hegde, Nasir Memon, Sudipta Banerjee|<http://arxiv.org/pdf/2507.13292v1>|提出DiffClean方法，利用文本引导的扩散模型消除妆容干扰，有效提升年龄估算和面部验证准确性。|
|📝 更新|Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models|高保真、高效扩散模型的结构化离散潜在代码|Samuel Lavoie, Michael Noukhovitch, Aaron Courville|<http://arxiv.org/pdf/2507.12318v2>|提出离散潜在码表示法，提升扩散模型生成图像的清晰度并实现跨训练分布的样本生成。|
|🆕 发布|fastWDM3D: Fast and Accurate 3D Healthy Tissue Inpainting|快速WDM3D：快速精确的三维健康组织修复|Alicia Durrer, Florentin Bieder, Paul Friedrich, Bjoern Menze, Philippe C. Cattin, Florian Kofler|<http://arxiv.org/pdf/2507.13146v1>|[代码](https://github.com/AliciaDurrer/fastWDM3D.); 提出了一种结合DDPM和特定噪声调度策略的3D健康组织修复方法，大幅提升了修复速度和准确性。|
|🆕 发布|Deep Learning-Based Fetal Lung Segmentation from Diffusion-weighted MRI Images and Lung Maturity Evaluation for Fetal Growth Restriction|基于深度学习的胎儿肺部分割从扩散加权磁共振成像中及胎儿生长受限的肺成熟度评估|Zhennan Xiao, Katharine Brudkiewicz, Zhen Yuan, Rosalind Aughwane, Magdalena Sokolska, Joanna Chappell, Trevor Gaunt, Anna L. David .etc.|<http://arxiv.org/pdf/2507.13106v1>|提出了一种基于深度学习的胎儿肺部自动分割方法，实现了无创评估胎儿肺部成熟度。|
|📝 更新|Uni-Instruct: One-step Diffusion Model through Unified Diffusion Divergence Instruction|统一指令一步扩散模型：通过统一扩散发散指令|Yifei Wang, Weimin Bai, Colin Zhang, Debing Zhang, Weijian Luo, He Sun|<http://arxiv.org/pdf/2505.20755v2>|统一了超过10种一步扩散蒸馏方法，提出扩散扩展理论，实现了扩散模型的高效训练和性能提升。|
|🆕 发布|RGB Pre-Training Enhanced Unobservable Feature Latent Diffusion Model for Spectral Reconstruction|RGB预训练增强不可观测特征潜在扩散模型用于光谱重建|Keli Deng, Jie Nie, Yuntao Qian|<http://arxiv.org/pdf/2507.12967v1>|提出了一种利用RGB预训练模型增强不可观测特征学习的光谱重建方法，实现了光谱重建任务中的性能提升。|
|🆕 发布|From Variability To Accuracy: Conditional Bernoulli Diffusion Models with Consensus-Driven Correction for Thin Structure Segmentation|从变异性到准确性：基于共识驱动的修正条件伯努利扩散模型用于薄结构分割|Jinseo An, Min Jin Lee, Kyu Won Shim, Helen Hong|<http://arxiv.org/pdf/2507.12985v1>|提出了一种利用多个扩散模型输出共识来纠正分割结果的创新框架，有效改善了薄结构区域的分割准确性。|
|🆕 发布|FantasyPortrait: Enhancing Multi-Character Portrait Animation with Expression-Augmented Diffusion Transformers|《FantasyPortrait：利用表情增强扩散变换器提升多角色肖像动画》|Qiang Wang, Mengchao Wang, Fan Jiang, Yaqi Fan, Yonggang Qi, Mu Xu|<http://arxiv.org/pdf/2507.12956v1>|[代码](https://fantasy-amap.github.io/fantasy-portrait); 提出 FantasyPortrait 框架，通过扩散变换器和表情增强学习策略，实现高保真、情感丰富的...|
|🆕 发布|Analysis of Image-and-Text Uncertainty Propagation in Multimodal Large Language Models with Cardiac MR-Based Applications|图像与文本不确定性在多模态大型语言模型中的传播分析及基于心脏磁共振成像的应用|Yucheng Tang, Yunguan Fu, Weixi Yi, Yipei Wang, Daniel C. Alexander, Rhodri Davies, Yipeng Hu|<http://arxiv.org/pdf/2507.12945v1>|[代码](https://github.com/yucheng722/MUPM.); 提出了一种多模态不确定性传播模型，有效量化了图像和文本输入在大型多模态语言模型中的不确定性关系，并实...|
|📝 更新|MMOne: Representing Multiple Modalities in One Scene|MMOne：一种在单场景中表征多模态的方法|Zhifeng Gu, Bing Wang|<http://arxiv.org/pdf/2507.11129v2>|[代码](https://github.com/Neal2020GitHub/MMOne.); 提出MMOne框架，通过分离多模态信息，有效解决多模态场景表示中的冲突问题。|
|🆕 发布|DMQ: Dissecting Outliers of Diffusion Models for Post-Training Quantization|DMQ：剖析扩散模型异常值以优化训练后量化|Dongyeun Lee, Jiwan Hur, Hyounguk Shon, Jae Young Lee, Junmo Kim|<http://arxiv.org/pdf/2507.12933v1>|[代码](https://github.com/LeeDongYeun/dmq.); 提出了一种针对扩散模型后训练量化的方法DMQ，通过优化通道缩放因子和自适应时间步长权重，显著提升了低...|
|🆕 发布|MCoT-RE: Multi-Faceted Chain-of-Thought and Re-Ranking for Training-Free Zero-Shot Composed Image Retrieval|MCoT-RE: 多维度思维链与重排用于无需训练的零样本组合图像检索|Jeong-Woo Park, Seong-Whan Lee|<http://arxiv.org/pdf/2507.12819v1>|提出了一种多维度思维链和重排的零样本图像检索框架，有效平衡了修改指示和视觉上下文信息。|
|📝 更新|PhenoBench: A Comprehensive Benchmark for Cell Phenotyping|PhenoBench：细胞表型分析的全面基准测试|Nora Koreuber, Jannik Franzen, Fabian H. Reith, Claudia Winklmayr, Jerome Luescher, Elias Baumann, Christian M. Schuerch, Dagmar Kainmueller .etc.|<http://arxiv.org/pdf/2507.03532v3>|提出PhenoBench，为细胞表型识别提供全面基准及新数据集，揭示现有模型在医学领域迁移中的挑战。|
|🆕 发布|DeQA-Doc: Adapting DeQA-Score to Document Image Quality Assessment|将DeQA-Score适配于文档图像质量评估的DeQA-Doc方法|Junjie Gao, Runze Liu, Yingzhe Peng, Shujian Yang, Jin Zhang, Kai Yang, Zhiyuan You|<http://arxiv.org/pdf/2507.12796v1>|[代码](https://github.com/Junjie-Gao19/DeQA-Doc.); 将先进的MLLM图像质量评分方法DeQA-Score适配至文档领域，提出DeQA-Doc框架，有效提...|
|📝 更新|Fine-grained Image Retrieval via Dual-Vision Adaptation|通过双视觉适配的细粒度图像检索|Xin Jiang, Meiqi Cao, Hao Tang, Fei Shen, Zechao Li|<http://arxiv.org/pdf/2506.16273v2>|提出了一种双视觉适应方法，通过样本和特征适应提升细粒度图像检索的泛化能力。|
|📝 更新|Golden Noise for Diffusion Models: A Learning Framework|金噪声用于扩散模型：一种学习框架|Zikai Zhou, Shitong Shao, Lichen Bai, Shufei Zhang, Zhiqiang Xu, Bo Han, Zeke Xie|<http://arxiv.org/pdf/2411.09502v5>|提出噪声提示概念，通过学习将随机噪声转化为优质合成图像的“黄金噪声”。|
|🆕 发布|NeuraLeaf: Neural Parametric Leaf Models with Shape and Deformation Disentanglement|神经叶：具有形状与形变解耦的神经参数化叶片模型|Yang Yang, Dongni Mao, Hiroaki Santo, Yasuyuki Matsushita, Fumio Okura|<http://arxiv.org/pdf/2507.12714v1>|[代码](https://neuraleaf-yang.github.io/.); 提出NeuraLeaf模型，将叶子形状和变形分离，实现精确的3D叶建模与重构。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VideoITG: Multimodal Video Understanding with Instructed Temporal Grounding|视频ITG：基于指导时间定位的多模态视频理解|Shihao Wang, Guo Chen, De-an Huang, Zhiqi Li, Minghan Li, Guilin Li, Jose M. Alvarez, Lei Zhang .etc.|<http://arxiv.org/pdf/2507.13353v1>|提出了一种指导性时间定位方法VideoITG，通过模拟人类标注过程自动选择视频关键帧，显著提升长视频...|
|🆕 发布|AutoPartGen: Autogressive 3D Part Generation and Discovery|自动部件生成与发现：渐进式三维部件生成|Minghao Chen, Jianyuan Wang, Roman Shapovalov, Tom Monnier, Hyunyoung Jung, Dilin Wang, Rakesh Ranjan, Iro Laina .etc.|<http://arxiv.org/pdf/2507.13346v1>|提出AutoPartGen模型，通过自回归方式生成3D物体部件并自动确定部件类型和数量。|
|🆕 发布|Imbalance in Balance: Online Concept Balancing in Generation Models|《平衡中的不平衡：生成模型中的在线概念平衡》|Yukai Shi, Jiarong Ou, Rui Chen, Haotian Yang, Jiahao Wang, Xin Tao, Pengfei Wan, Di Zhang .etc.|<http://arxiv.org/pdf/2507.13345v1>|提出在线平衡概念响应的方法，通过设计概念均衡损失函数改善生成模型稳定性。|
|🆕 发布|Taming Diffusion Transformer for Real-Time Mobile Video Generation|驯服扩散变换器以实现实时移动视频生成|Yushu Wu, Yanyu Li, Anil Kag, Ivan Skorokhodov, Willi Menapace, Ke Ma, Arpit Sahni, Ju Hu .etc.|<http://arxiv.org/pdf/2507.13343v1>|优化了Diffusion Transformers，实现了在移动设备上实时生成高质量视频。|
|🆕 发布|FashionPose: Text to Pose to Relight Image Generation for Personalized Fashion Visualization|《FashionPose：从文本到姿态再到重光照的个性化时尚可视化图像生成》|Chuancheng Shi, Yixiang Chen, Burong Lei, Jichao Chen|<http://arxiv.org/pdf/2507.13311v1>|首次提出统一文本到姿态到重照明的生成框架，实现个性化服装预览的精准姿态预测、高保真图像生成和灵活光照...|
|🆕 发布|VITA: Vision-to-Action Flow Matching Policy|VITA：视觉到动作流匹配策略|Dechen Gao, Boqi Zhao, Andrew Lee, Ian Chuang, Hanchu Zhou, Hang Wang, Zhe Zhao, Junshan Zhang .etc.|<http://arxiv.org/pdf/2507.13231v1>|提出VITA方法，将视觉信息直接转化为动作，简化了传统动作生成中的条件机制，提高了效率。|
|🆕 发布|Orbis: Overcoming Challenges of Long-Horizon Prediction in Driving World Models|“Orbis：克服驾驶世界模型中长周期预测的挑战”|Arian Mousakhan, Sudhanshu Mittal, Silvio Galesso, Karim Farid, Thomas Brox|<http://arxiv.org/pdf/2507.13162v1>|[代码](https://lmb-freiburg.github.io/orbis.github.io); 提出了一种简单设计的模型，有效克服了自动驾驶中长距离预测的挑战，优于现有模型。|
|📝 更新|Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID|通过增强生成合成数据以提升DreamBooth和InstantID中的面部相似度|Koray Ulusan, Benjamin Kiefer|<http://arxiv.org/pdf/2505.03557v2>|提出利用InstantID生成合成数据增强训练，有效提升面部相似度并保持专业肖像生成质量。|
|📝 更新|A Controllable Appearance Representation for Flexible Transfer and Editing|可控外观表征实现灵活迁移与编辑|Santiago Jimenez-Navarro, Julia Guerrero-Viu, Belen Masia|<http://arxiv.org/pdf/2504.15028v2>|提出了一种自监督学习的高效材料外观表示方法，实现了无监督下的精细编辑和灵活迁移。|
|📝 更新|DWIM: Towards Tool-aware Visual Reasoning via Discrepancy-aware Workflow Generation & Instruct-Masking Tuning|DWIM：通过差异感知工作流生成与指令遮蔽调整实现面向工具的视觉推理|Fucai Ke, Vijay Kumar B G, Xingjian Leng, Zhixi Cai, Zaid Khan, Weiqing Wang, Pari Delir Haghighi, Hamid Rezatofighi .etc.|<http://arxiv.org/pdf/2503.19263v3>|提出DWIM方法，通过工具感知的工作流生成和指令掩码微调，提升视觉推理性能。|
|📝 更新|SeaS: Few-shot Industrial Anomaly Image Generation with Separation and Sharing Fine-tuning|《SeaS：基于分离与共享微调的少样本工业异常图像生成》|Zhewei Dai, Shilei Zeng, Haotian Liu, Xurui Li, Feng Xue, Yu Zhou|<http://arxiv.org/pdf/2410.14987v3>|[代码](https://github.com/HUST-SLOW/SeaS); 提出SeaS模型，通过分离与共享微调，实现了少量样本下工业异常图像的生成。|
|📝 更新|Real-Time Inverse Kinematics for Generating Multi-Constrained Movements of Virtual Human Characters|Characters虚拟人类角色的多约束运动实时逆运动学生成|Hendric Voss, Stefan Kopp|<http://arxiv.org/pdf/2507.00792v2>|[代码](https://github.com/hvoss-techfak/TF-JAX-IK); 提出了一种基于TensorFlow自动微分和即时编译的实时逆运动学求解器，有效应对多约束下的人体运动...|
|🆕 发布|Resurrect Mask AutoRegressive Modeling for Efficient and Scalable Image Generation|《复活掩码自回归建模以实现高效和可扩展的图像生成》|Yi Xin, Le Zhuo, Qi Qin, Siqi Luo, Yuewen Cao, Bin Fu, Yangfan He, Hongsheng Li .etc.|<http://arxiv.org/pdf/2507.13032v1>|[代码](https://github.com/synbol/MaskGIL.); 提出改进的MaskGIL模型，通过双向注意力和2D RoPE提升图像生成质量，仅需8步推理即可达到A...|
|📝 更新|MIDI: Multi-Instance Diffusion for Single Image to 3D Scene Generation|多实例扩散：从单张图像到三维场景生成的算法|Zehuan Huang, Yuan-Chen Guo, Xingqiao An, Yunhan Yang, Yangguang Li, Zi-Xin Zou, Ding Liang, Xihui Liu .etc.|<http://arxiv.org/pdf/2412.03558v3>|提出了一种基于预训练模型的MIDI方法，通过多实例扩散和注意力机制直接生成具有准确空间关系的3D场景...|
|📝 更新|Physical Annotation for Automated Optical Inspection: A Concept for In-Situ, Pointer-Based Training Data Generation|物理标注在自动光学检测中的应用：一种在位、指针式训练数据生成方法|Oliver Krumpek, Oliver Heimann, Jörg Krüger|<http://arxiv.org/pdf/2506.05026v2>|提出了一种物理标注系统，通过指针式现场交互将专家经验直接转化为机器学习训练数据，提高了标注效率和准确...|
|🆕 发布|ATL-Diff: Audio-Driven Talking Head Generation with Early Landmarks-Guide Noise Diffusion|音频驱动的早期特征点引导噪声扩散 talking head 生成：ATL-Diff|Hoang-Son Vo, Quang-Vinh Nguyen, Seungwon Kim, Hyung-Jeong Yang, Soonja Yeom, Soo-Hyung Kim|<http://arxiv.org/pdf/2507.12804v1>|[代码](https://github.com/sonvth/ATL-Diff); 提出了一种音频驱动的说话人头生成方法ATL-Diff，通过早期面部标记引导噪声扩散，实现了面部动画与...|
|📝 更新|PhysX: Physical-Grounded 3D Asset Generation|PhysX：基于物理的3D资源生成|Ziang Cao, Zhaoxi Chen, Liang Pan, Ziwei Liu|<http://arxiv.org/pdf/2507.12465v2>|提出了PhysX，一种结合物理属性的3D资产生成框架，通过引入物理知识提升模型在现实应用中的表现。|
|🆕 发布|Local Representative Token Guided Merging for Text-to-Image Generation|局部代表性标记引导的融合策略用于文本到图像生成|Min-Jeong Lee, Hee-Dong Kim, Seong-Whan Lee|<http://arxiv.org/pdf/2507.12771v1>|提出了一种高效的图像生成合并策略ReToM，通过局部代表令牌减少计算量，同时保持图像质量。|
|🆕 发布|Think-Before-Draw: Decomposing Emotion Semantics & Fine-Grained Controllable Expressive Talking Head Generation|思考再绘制：分解情感语义与细粒度可控表情说话人头生成|Hanlei Shi, Leyuan Qu, Yu Liu, Di Gao, Yuhua Zheng, Taihao Li|<http://arxiv.org/pdf/2507.12761v1>|提出Think-Before-Draw框架，通过深度语义解析和细粒度表达优化，实现更自然的情感表达视...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Synthesizing Reality: Leveraging the Generative AI-Powered Platform Midjourney for Construction Worker Detection|合成现实：利用生成式人工智能平台Midjourney进行建筑工人检测|Hongyang Zhao, Tianyu Liang, Sina Davari, Daeho Kim|<http://arxiv.org/pdf/2507.13221v1>|利用生成式AI平台Midjourney创建合成图像，有效解决了建筑工人检测数据不足的问题。|
|🆕 发布|LoViC: Efficient Long Video Generation with Context Compression|LoViC：基于上下文压缩的高效长视频生成|Jiaxiu Jiang, Wenbo Li, Jingjing Ren, Yuping Qiu, Yong Guo, Xiaogang Xu, Han Wu, Wangmeng Zuo|<http://arxiv.org/pdf/2507.12952v1>|提出LoViC框架，通过段式生成和FlexFormer编码，实现长视频的高效生成与连贯性。|
|📝 更新|KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos|关键点引导的视频中人重识别：基于部分感知表示的关键点重识别|Jinseong Kim, Jeonghoon Song, Gyeongseon Baek, Byeongjoon Noh|<http://arxiv.org/pdf/2507.07393v3>|提出KeyRe-ID框架，通过结合全局和局部分支以及人体关键点，提升视频行人重识别的时空表征。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Leveraging Pre-Trained Visual Models for AI-Generated Video Detection|利用预训练视觉模型进行人工智能生成视频检测|Keerthi Veeramachaneni, Praveen Tirupattur, Amrit Singh Bedi, Mubarak Shah|<http://arxiv.org/pdf/2507.13224v1>|提出了一种利用预训练视觉模型区分真实与AI生成视频的新方法，实现高检测准确率。|
|📝 更新|Unified Triplet-Level Hallucination Evaluation for Large Vision-Language Models|统一的三元组级别幻觉评估方法用于大规模视觉-语言模型|Junjie Wu, Tsz Ting Chung, Kai Chen, Dit-Yan Yeung|<http://arxiv.org/pdf/2410.23114v4>|[代码](https://github.com/wujunjie1998/Tri-HE.); 提出统一框架评估大型视觉语言模型中的对象和关系幻觉问题，并设计无训练缓解方法。|
|🆕 发布|AnyCap Project: A Unified Framework, Dataset, and Benchmark for Controllable Omni-modal Captioning|AnyCap项目：可控全模态字幕生成的统一框架、数据集和基准|Yiming Ren, Zhiqiang Lin, Yu Li, Gao Meng, Weiyun Wang, Junjie Wang, Zicheng Lin, Jifeng Dai .etc.|<http://arxiv.org/pdf/2507.12841v1>|提出AnyCap Project，通过轻量级框架增强多模态字幕生成控制性，构建专用数据集和评估指标。|
|🆕 发布|FIQ: Fundamental Question Generation with the Integration of Question Embeddings for Video Question Answering|FIQ：融合问题嵌入的视频问答基础问题生成|Ju-Young Oh, Ho-Joong Kim, Seong-Whan Lee|<http://arxiv.org/pdf/2507.12816v1>|提出了一种增强视频理解能力的FIQ方法，通过生成描述性Q&A对提升模型泛化与推理能力。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|An Event-based Algorithm for Simultaneous 6-DOF Camera Pose Tracking and Mapping|基于事件的六自由度相机位姿同时跟踪与建图算法|Masoud Dayani Najafabadi, Mohammad Reza Ahmadzadeh|<http://arxiv.org/pdf/2301.00618v4>|提出了一种基于事件相机和惯性传感器的6-DOF相机位姿跟踪与建图算法，实现了与现有技术相当或更准确的...|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|cIDIR: Conditioned Implicit Neural Representation for Regularized Deformable Image Registration|条件隐式神经表示用于正则化可变形图像配准：cIDIR|Sidaty El Hadramy, Oumeymah Cherkaoui, Philippe C. Cattin|<http://arxiv.org/pdf/2507.12953v1>|提出了基于隐式神经表示的cIDIR框架，通过条件化超参数实现高效且灵活的图像配准。|
|🆕 发布|Tensor-Tensor Products, Group Representations, and Semidefinite Programming|张量-张量积、群表示与半定规划|Alex Dunbar, Elizabeth Newman|<http://arxiv.org/pdf/2507.12729v1>|提出M-SDP框架，利用矩阵积和群表示理论解决不变半定规划问题，实现低秩张量完成。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos|自我视角视觉-语言-动作模型：从第一人称人类视频学习|Ruihan Yang, Qinxi Yu, Yecheng Wu, Rui Yan, Borui Li, An-Chieh Cheng, Xueyan Zou, Yunhao Fang .etc.|<http://arxiv.org/pdf/2507.12440v2>|[代码](https://rchalyang.github.io/EgoVLA); 提出利用第一人称人类视频训练视觉-语言-动作模型，实现机器人动作模仿与优化。|
|📝 更新|ProDisc-VAD: An Efficient System for Weakly-Supervised Anomaly Detection in Video Surveillance Applications|ProDisc-VAD：一种面向视频监控应用的高效弱监督异常检测系统|Tao Zhu, Qi Yu, Xinru Dong, Shiyu Li, Yue Liu, Jinlong Jiang, Lei Shu|<http://arxiv.org/pdf/2505.02179v3>|[代码](https://github.com/modadundun/ProDisc-VAD.); 提出ProDisc-VAD框架，通过原型交互层和伪实例判别增强损失解决弱监督视频异常检测中的标签模糊...|
|📝 更新|LVAgent: Long Video Understanding by Multi-Round Dynamical Collaboration of MLLM Agents|LVAgent：通过多轮动态协作的长视频理解MLLM代理|Boyu Chen, Zhengrong Yue, Siran Chen, Zikang Wang, Yang Liu, Peng Li, Yali Wang|<http://arxiv.org/pdf/2503.10200v4>|[代码](https://github.com/64327069/LVAgent.); 提出LVAgent框架，实现多轮动态协作的多语言模型代理，提升长视频理解准确度至80%。|
|🆕 发布|HairShifter: Consistent and High-Fidelity Video Hair Transfer via Anchor-Guided Animation|《HairShifter：通过锚点引导动画实现一致性和高保真度的视频头发转移》|Wangzheng Shi, Yinglin Zheng, Yuxin Lin, Jianmin Bao, Ming Zeng, Dong Chen|<http://arxiv.org/pdf/2507.12758v1>|提出HairShifter方法，通过“关键帧+动画”框架实现视频中高保真度和一致性的头发转移。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MVA 2025 Small Multi-Object Tracking for Spotting Birds Challenge: Dataset, Methods, and Results|《MVA 2025 小型多目标跟踪用于鸟类监测挑战：数据集、方法与结果》|Yuki Kondo, Norimichi Ukita, Riku Kanayama, Yuki Yoshida, Takayuki Yamaguchi, Xiang Yu, Guang Liang, Xinyao Liu .etc.|<http://arxiv.org/pdf/2507.12832v1>|引入SMOT4SB挑战和SO-HOTA指标，为小型目标多对象跟踪在无人机场景中提供了高效数据集和评估...|
|🆕 发布|Continuous Marine Tracking via Autonomous UAV Handoff|通过自主无人机交接实现连续海洋追踪|Heegyeong Kim, Alice James, Avishkar Seth, Endrowednes Kuantama, Jane Williamson, Yimeng Feng, Richard Han|<http://arxiv.org/pdf/2507.12763v1>|实现无人机间无缝接力跟踪海洋动物，突破单机续航限制，提升实时监测能力。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Fetuses Made Simple: Modeling and Tracking of Fetal Shape and Pose|胎儿形态与姿态建模及跟踪：化繁为简|Yingcheng Liu, Peiqi Wang, Sebastian Diaz, Esra Abaci Turk, Benjamin Billot, P. Ellen Grant, Polina Golland|<http://arxiv.org/pdf/2506.17858v3>|[代码](https://github.com/MedicalVisionGroup/fetal-smpl); 构建首个3D统计胎儿模型，融合形状与姿态估计，提升MRI运动分析鲁棒性。|
|📝 更新|STF: Spatial Temporal Fusion for Trajectory Prediction|STF：时空融合轨迹预测|Pengqian Han, Jiamou Liu, Tianzhe Bao, Yifei Wang|<http://arxiv.org/pdf/2311.18149v2>|提出了一种融合时空信息的三维图模型，通过STF模型同时捕获历史轨迹的空间与时间信息，有效提升了长时间...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Prompt-driven Transferable Adversarial Attack on Person Re-Identification with Attribute-aware Textual Inversion|基于属性感知文本反转的提示驱动迁移性对抗攻击在行人重识别中的应用|Yuan Bian, Min Liu, Yunqi Yi, Xueping Wang, Yaonan Wang|<http://arxiv.org/pdf/2502.19697v3>|提出了一种利用视觉语言模型破坏行人图像细粒度特征的攻击方法，显著提升了对抗样本的迁移性。|
|🆕 发布|Differential-informed Sample Selection Accelerates Multimodal Contrastive Learning|差分指导样本选择加速多模态对比学习|Zihua Zhao, Feng Hong, Mengxi Chen, Pengyi Chen, Benyuan Liu, Jiangchao Yao, Ya Zhang, Yanfeng Wang|<http://arxiv.org/pdf/2507.12998v1>|[代码](https://github.com/MediaBrain-SJTU/DISSect.); 提出了一种基于差异信息的样本选择方法DISSect，有效区分噪声对应关系以加速多模态对比学习训练。|
|📝 更新|SCMM: Calibrating Cross-modal Representations for Text-Based Person Search|SCMM：校准基于文本的人物搜索的跨模态表征|Jing Liu, Donglai Wei, Yang Liu, Sipeng Zhang, Tong Yang, Wei Zhou, Weiping Ding, Victor C. M. Leung|<http://arxiv.org/pdf/2304.02278v7>|提出SCMM框架，通过自适应边距约束和细粒度跨模态对应策略，有效解决文本基人物搜索中的模态融合挑战。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|R^2MoE: Redundancy-Removal Mixture of Experts for Lifelong Concept Learning|R^2MoE：终身概念学习中的冗余移除混合专家模型|Xiaohan Guo, Yusong Cai, Zejia Liu, Zhengning Wang, Lili Pan, Hongliang Li|<http://arxiv.org/pdf/2507.13107v1>|[代码](https://github.com/learninginvision/R2MoE); 提出了一种参数高效的终身视觉概念学习框架R^2MoE，通过消除冗余和优化注意力机制有效学习新概念且减...|
|🆕 发布|Camera-based implicit mind reading by capturing higher-order semantic dynamics of human gaze within environmental context|基于摄像头的隐式读心技术：通过捕捉环境背景下人眼注视的高阶语义动态|Mengke Song, Yuge Xie, Qi Cui, Luming Li, Xinyu Liu, Guotao Wang, Chenglizhao Chen, Shanchen Pang|<http://arxiv.org/pdf/2507.12889v1>|提出了一种利用普通高清摄像头捕捉视线轨迹和环境语义的方法，实现了无需用户参与的自然情境下实时情绪识别...|
|🆕 发布|WhoFi: Deep Person Re-Identification via Wi-Fi Channel Signal Encoding|WhoFi：通过Wi-Fi信道信号编码实现深度行人重识别|Danilo Avola, Daniele Pannone, Dario Montagnini, Emad Emam|<http://arxiv.org/pdf/2507.12869v1>|利用Wi-Fi信号提取生物特征并通过深度学习进行人物重识别，有效解决了视觉数据受限的问题。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GLAD: Generalizable Tuning for Vision-Language Models|GLAD：视觉语言模型通用调整方法|Yuqi Peng, Pengfei Wang, Jianzhuang Liu, Shifeng Chen|<http://arxiv.org/pdf/2507.13089v1>|提出了一种简化且通用的GLAD框架，通过LoRA和梯度正则化技术有效缓解了小样本学习中的过拟合问题，...|
|🆕 发布|WaveletInception Networks for Drive-by Vibration-Based Infrastructure Health Monitoring|基于行驶中振动信号的WaveletInception网络用于基础设施健康监测|Reza Riahi Samani, Alfredo Nunez, Bart De Schutter|<http://arxiv.org/pdf/2507.12969v1>|提出了一种基于深度学习的框架，利用行驶中振动信号进行基础设施健康监测，通过WaveletIncept...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Variance-Based Pruning for Accelerating and Compressing Trained Networks|基于方差的剪枝方法以加速和压缩训练网络|Uranik Berisha, Jens Mehnert, Alexandru Paul Condurache|<http://arxiv.org/pdf/2507.12988v1>|提出了一种基于方差统计的剪枝方法，有效压缩网络模型，仅需少量微调即可恢复大部分性能。|
|📝 更新|Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants|基于逐层冻结的站点级微调：面向在极早早产儿出生第一天胸部X射线图像中稳健预测支气管肺发育不良|Sybelle Goedicke-Fritz, Michelle Bous, Annika Engel, Matthias Flotho, Pascal Hirsch, Hannah Wittig, Dino Milanovic, Dominik Mohr .etc.|<http://arxiv.org/pdf/2507.12269v2>|提出了一种针对极低出生体重婴儿的BPD预测方法，通过特定领域预训练和渐进式层冻结提升准确度。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hierarchical Rectified Flow Matching with Mini-Batch Couplings|分层矫正流匹配与迷你批次耦合|Yichi Zhang, Yici Yan, Alex Schwing, Zhizhen Zhao|<http://arxiv.org/pdf/2507.13350v1>|[代码](https://riccizz.github.io/HRF_coupling.); 引入了通过逐级调整复杂度的mini-batch couplings改进的层级 rectified f...|
|🆕 发布|Simulate, Refocus and Ensemble: An Attention-Refocusing Scheme for Domain Generalization|模拟、重聚焦与集成：一种用于域泛化的注意力重聚焦方案|Ziyi Wang, Zhi Gao, Jin Chen, Qingjie Zhao, Xinxiao Wu, Jiebo Luo|<http://arxiv.org/pdf/2507.12851v1>|[代码](https://github.com/bitPrincy/SRE-DG.); 提出了一种Simulate, Refocus and Ensemble方法，通过模拟域偏移和注意力重...|
|📝 更新|Task-Specific Generative Dataset Distillation with Difficulty-Guided Sampling|基于难度指导采样的任务特定生成数据集蒸馏|Mingzhuo Li, Guang Li, Jiafeng Mao, Linfeng Ye, Takahiro Ogawa, Miki Haseyama|<http://arxiv.org/pdf/2507.03331v2>|[代码](https://github.com/SumomoTaku/DiffGuideSamp.); 提出了一种针对特定任务的生成数据集精简方法，通过难度指导采样优化了下游任务性能。|
|🆕 发布|AnyPos: Automated Task-Agnostic Actions for Bimanual Manipulation|AnyPos：面向双臂操作的任务无关自动化行为|Hengkai Tan, Yao Feng, Xinyi Mao, Shuhe Huang, Guodong Liu, Zhongkai Hao, Hang Su, Jun Zhu|<http://arxiv.org/pdf/2507.12768v1>|[代码](https://embodiedfoundation.github.io/vidar_anypos); 提出了一种任务无关的动作范式，通过分离动作执行与任务特定条件，提高了双臂操作的泛化性、效率和成本效益...|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Model-Agnostic, Temperature-Informed Sampling Enhances Cross-Year Crop Mapping with Deep Learning|模型无关、温度指导的采样增强深度学习在跨年度作物映射中的应用|Mehmet Ozgur Turkoglu, Selene Ledain, Helge Aasen|<http://arxiv.org/pdf/2506.12885v3>|提出了一种基于热时间采样策略的方法，有效提升了跨年度作物分类准确性和不确定性估计。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability|语义结构感知的生成攻击以提高对抗性迁移性|Jongoh Jeong, Hunmin Yang, Jaeseok Jeong, Kuk-Jin Yoon|<http://arxiv.org/pdf/2506.18248v3>|提出了一种利用生成模型语义信息增强对抗迁移性的攻击框架，通过特征蒸馏提升了对对象显著区域的攻击效果。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Weakly Supervised Visible-Infrared Person Re-Identification via Heterogeneous Expert Collaborative Consistency Learning|通过异质专家协同一致性学习的弱监督可见光-红外行人重识别|Yafei Zhang, Lingqi Kong, Huafeng Li, Jie Wen|<http://arxiv.org/pdf/2507.12942v1>|提出了一种弱监督跨模态行人重识别方法，通过异质专家协作一致性学习框架，有效提升了无交叉模态标签下的识...|
|📝 更新|Learning Lens Blur Fields|学习镜头模糊场|Esther Y. H. Lin, Zhecheng Wang, Rebecca Lin, Daniel Miau, Florian Kainz, Jiawen Chen, Xuaner Cecilia Zhang, David B. Lindell .etc.|<http://arxiv.org/pdf/2310.11535v2>|提出了一种高维神经网络表示——镜头模糊场，通过少量焦距堆栈直接优化MLP权重，精确捕捉相机镜头的模糊...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|$π^3$: Scalable Permutation-Equivariant Visual Geometry Learning|$π^3$：可扩展的置换等价视觉几何学习|Yifan Wang, Jianjun Zhou, Haoyi Zhu, Wenzheng Chang, Yang Zhou, Zizun Li, Junyi Chen, Jiangmiao Pang .etc.|<http://arxiv.org/pdf/2507.13347v1>|提出了一种无需固定参考视角的视觉几何重建方法，通过全排列等变架构实现了高鲁棒性和可扩展性。|
|🆕 发布|Rethinking the Embodied Gap in Vision-and-Language Navigation: A Holistic Study of Physical and Visual Disparities|重新思考视觉与语言导航中的具身差距：物理与视觉差异的全面研究|Liuyi Wang, Xinyuan Xia, Hui Zhao, Hanqing Wang, Tai Wang, Yilun Chen, Chengju Liu, Qijun Chen .etc.|<http://arxiv.org/pdf/2507.13019v1>|[代码](https://crystalsixone.github.io/vln_pe.github.io); 提出了一种物理真实的VLN平台VLN-PE，揭示了现有方法在实体部署中的性能退化问题，并提供了改进适...|
|📝 更新|Global urban visual perception varies across demographics and personalities|全球城市视觉感知在不同人口统计学特征与个性之间存在差异|Matias Quintana, Youlong Gu, Xiucheng Liang, Yujun Hou, Koichi Ito, Yihan Zhu, Mahmoud Abdelrahman, Filip Biljecki|<http://arxiv.org/pdf/2505.12758v3>|揭示了不同人口统计特征和性格特质如何影响全球街景视觉感知的差异。|
|🆕 发布|HRSeg: High-Resolution Visual Perception and Enhancement for Reasoning Segmentation|HRSeg：用于推理分割的高分辨率视觉感知与增强|Weihuang Lin, Yiwei Ma, Xiaoshuai Sun, Shuting He, Jiayi Ji, Liujuan Cao, Rongrong Ji|<http://arxiv.org/pdf/2507.12883v1>|HRSeg通过高分辨率视觉感知与增强，有效提升了推理分割任务的准确性和效率。|
|📝 更新|RetinaLogos: Fine-Grained Synthesis of High-Resolution Retinal Images Through Captions|视网膜标志：通过标题实现高分辨率视网膜图像的细粒度合成|Junzhi Ning, Cheng Tang, Kaijing Zhou, Diping Song, Lihao Liu, Ming Hu, Wei Li, Huihui Xu .etc.|<http://arxiv.org/pdf/2505.12887v3>|[代码](https://github.com/uni-medical/retina-text2cfp.); 提出了一种通过文本描述生成高质量视网膜图像的新框架，有效解决了数据稀缺问题并提高了病变检测准确性。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Aligning Information Capacity Between Vision and Language via Dense-to-Sparse Feature Distillation for Image-Text Matching|通过密集到稀疏特征蒸馏对图像文本匹配进行视觉与语言信息容量对齐|Yang Liu, Wentao Feng, Zhuoyao Liu, Shudong Huang, Jiancheng Lv|<http://arxiv.org/pdf/2503.14953v2>|提出D2S-VSE模型，通过稠密文本蒸馏增强稀疏文本嵌入的信息容量，有效处理多视角描述匹配挑战。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SpectraLift: Physics-Guided Spectral-Inversion Network for Self-Supervised Hyperspectral Image Super-Resolution|光谱提升：基于物理引导的谱反演网络用于自监督高光谱图像超分辨率|Ritik Shah, Marco F. Duarte|<http://arxiv.org/pdf/2507.13339v1>|提出了一种无需PSF校准或HR-HSI的物理引导自监督超分辨率框架，通过融合LR-HSI和HR-MS...|
|📝 更新|4D-MISR: A unified model for low-dose super-resolution imaging via feature fusion|4D-MISR：一种通过特征融合实现低剂量超分辨率成像的统一模型|Zifei Wang, Zian Mao, Xiaoya He, Xi Huang, Haoran Zhang, Chun Cheng, Shufen Chu, Tingzheng Hou .etc.|<http://arxiv.org/pdf/2507.09953v3>|提出了一种融合多角度观测特征的网络模型，实现了低剂量下电子显微成像的原子级超分辨率重建。|
|🆕 发布|DiffOSeg: Omni Medical Image Segmentation via Multi-Expert Collaboration Diffusion Model|DiffOSeg：通过多专家协作扩散模型实现全医学图像分割|Han Zhang, Xiangde Luo, Yong Chen, Kang Li|<http://arxiv.org/pdf/2507.13087v1>|[代码](https://github.com/string-ellipses/DiffOSeg); 提出DiffOSeg模型，通过多专家协作扩散模型同时实现共识驱动和偏好驱动的医疗图像分割。|
|🆕 发布|MUPAX: Multidimensional Problem Agnostic eXplainable AI|MUPAX：多维问题无关的可解释人工智能|Vincenzo Dentamaro, Felice Franchini, Giuseppe Pirlo, Irina Voiculescu|<http://arxiv.org/pdf/2507.13090v1>|提出了一种多维问题无关的可解释AI技术MUPAX，实现了确定性、模型无关性和收敛性保证，有效提升模型...|
|🆕 发布|Dual LiDAR-Based Traffic Movement Count Estimation at a Signalized Intersection: Deployment, Data Collection, and Preliminary Analysis|基于双线激光雷达的信号交叉口交通流动计数估计：部署、数据采集与初步分析|Saswat Priyadarshi Nayak, Guoyuan Wu, Kanok Boriboonsomsin, Matthew Barth|<http://arxiv.org/pdf/2507.13073v1>|提出了一种基于双LiDAR的交叉路口车辆计数方法，提高了夜间和恶劣天气下的计数准确性。|
|🆕 发布|Demographic-aware fine-grained classification of pediatric wrist fractures|人口统计学感知的儿科手腕骨折细粒度分类|Ammar Ahmed, Ali Shariq Imran, Zenun Kastrati, Sher Muhammad Daudpota|<http://arxiv.org/pdf/2507.12964v1>|提出了一种结合患者元数据和细粒度识别策略的方法，提高了儿童手腕骨折诊断的准确性。|
|🆕 发布|Improving Diagnostic Accuracy of Pigmented Skin Lesions With CNNs: an Application on the DermaMNIST Dataset|利用卷积神经网络提高色素性皮肤病变的诊断准确性：在DermaMNIST数据集上的应用|Nerma Kadric, Amila Akagic, Medina Kapo|<http://arxiv.org/pdf/2507.12961v1>|利用CNN模型优化了皮肤病变诊断的准确性，通过转移学习和特定层配置达到领先水平。|
|📝 更新|Exploring the Collaborative Advantage of Low-level Information on Generalizable AI-Generated Image Detection|探究低层次信息在通用人工智能生成图像检测中的协作优势|Ziyin Zhou, Ke Sun, Zhongxi Chen, Xianming Lin, Yunpeng Luo, Ke Yan, Shouhong Ding, Xiaoshuai Sun|<http://arxiv.org/pdf/2504.00463v2>|提出了一种融合多类型低级信息的自适应框架，有效提升生成图像检测的泛化能力。|
|📝 更新|MRGen: Segmentation Data Engine for Underrepresented MRI Modalities|MRGen：代表性不足的MRI模态的分割数据引擎|Haoning Wu, Ziheng Zhao, Ya Zhang, Yanfeng Wang, Weidi Xie|<http://arxiv.org/pdf/2412.04106v3>|[代码](https://haoningwu3639.github.io/MRGen); 提出MRGen数据引擎，利用生成模型合成稀缺MRI模态的训练数据，显著提升无标注模态的分割性能。|
|🆕 发布|Unified Medical Image Segmentation with State Space Modeling Snake|统一医学图像分割：基于状态空间建模的Snake模型|Ruicheng Zhang, Haowei Guo, Kanghui Tian, Jun Zhou, Mingliang Yan, Zeyu Zhang, Shen Zhao|<http://arxiv.org/pdf/2507.12760v1>|提出了一种结合状态空间模型和深度蛇框架的医疗图像分割方法，有效应对结构异质性和形态复杂性挑战。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RS-TinyNet: Stage-wise Feature Fusion Network for Detecting Tiny Objects in Remote Sensing Images|RS-TinyNet：分阶段特征融合网络用于遥感图像中的微小目标检测|Xiaozheng Jiang, Wei Zhang, Xuerui Mao|<http://arxiv.org/pdf/2507.13120v1>|提出了一种针对遥感图像微小目标检测的多阶段特征融合网络RS-TinyNet，有效提升了检测准确性。|
|📝 更新|A Progressive Image Restoration Network for High-order Degradation Imaging in Remote Sensing|一种用于远程传感高阶退化成像的渐进图像恢复网络|Yujie Feng, Yin Yang, Xiaohong Fan, Zhengpeng Zhang, Lijing Bu, Jianping Zhang|<http://arxiv.org/pdf/2412.07195v2>|提出了一种渐进式图像复原网络，有效应对远程传感高阶退化成像问题，提升了图像复原质量。|
|🆕 发布|A Deep-Learning Framework for Land-Sliding Classification from Remote Sensing Image|遥感图像滑坡分类的深度学习框架|Hieu Tang, Truong Vo, Dong Pham, Toan Nguyen, Lam Pham, Truong Nguyen|<http://arxiv.org/pdf/2507.12939v1>|提出一种深度学习框架，通过EfficientNet_Large模型及SVM后处理，有效解决遥感图像滑...|
|🆕 发布|SEMT: Static-Expansion-Mesh Transformer Network Architecture for Remote Sensing Image Captioning|静态扩展网格变换器网络架构用于遥感图像标注：SEMT|Khang Truong, Lam Pham, Hieu Tang, Jasmin Lampert, Martin Boyer, Son Phan, Truong Nguyen|<http://arxiv.org/pdf/2507.12845v1>|提出了一种基于Transformer的远程遥感图像自动描述网络，通过多种技术集成提升了性能。|
|🆕 发布|SCORE: Scene Context Matters in Open-Vocabulary Remote Sensing Instance Segmentation|SCORE：场景上下文在开放词汇遥感实例分割中至关重要|Shiqi Huang, Shuting He, Huaiyuan Qin, Bihan Wen|<http://arxiv.org/pdf/2507.12857v1>|[代码](https://github.com/HuangShiqi128/SCORE.); 提出了一种融合场景上下文的开放词汇遥感实例分割框架，提升了模型对新颖类别和不同数据集的泛化能力。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|3DKeyAD: High-Resolution 3D Point Cloud Anomaly Detection via Keypoint-Guided Point Clustering|3D关键点引导的高分辨率三维点云异常检测：基于关键点的点聚类方法|Zi Wang, Katsuya Hotta, Koichiro Kamide, Yawen Zou, Chao Zhang, Jun Yu|<http://arxiv.org/pdf/2507.13110v1>|提出了一种结合多原型对齐和聚类分析的高分辨率3D点云异常检测方法，通过关键点引导的聚类实现精确的局部...|
|📝 更新|STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World Understanding?|STI-Bench：多模态语言模型是否准备好进行精确的时空世界理解？|Yun Li, Yiming Zhang, Tao Lin, Xiangrui Liu, Wenxiao Cai, Zheng Liu, Bo Zhao|<http://arxiv.org/pdf/2503.23765v6>|提出STI-Bench基准，评估多模态大语言模型在现实世界中的精确时空理解能力。|
|🆕 发布|World Model-Based End-to-End Scene Generation for Accident Anticipation in Autonomous Driving|基于世界模型的端到端场景生成用于自动驾驶的事故预测|Yanchen Guan, Haicheng Liao, Chengyue Wang, Xingcheng Liu, Jiaxun Zhang, Zhenning Li|<http://arxiv.org/pdf/2507.12762v1>|提出了一种结合生成场景增强和自适应时间推理的框架，以应对自动驾驶事故预测中的数据不足和模型局限性问题...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Efficient Adaptation of Pre-trained Vision Transformer underpinned by Approximately Orthogonal Fine-Tuning Strategy|基于近似正交微调策略的预训练视觉变换器的有效适应|Yiting Yang, Hao Luo, Yuan Sun, Qingsen Yan, Haokui Zhang, Wei Dong, Guoqing Wang, Peng Wang .etc.|<http://arxiv.org/pdf/2507.13260v1>|提出近似正交微调策略，增强预训练视觉变换器的泛化能力。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Advancing Complex Wide-Area Scene Understanding with Hierarchical Coresets Selection|利用分层核心集选择推进复杂广域场景理解|Jingyao Wang, Yiming Chen, Lingyu Si, Changwen Zheng|<http://arxiv.org/pdf/2507.13061v1>|提出了一种Hierarchical Coresets Selection机制，通过选择关键区域增强视...|
|📝 更新|Intriguing Properties of Robust Classification|《稳健分类的有趣特性》|Bernd Prach, Christoph H. Lampert|<http://arxiv.org/pdf/2412.04245v2>|[代码](https://github.com/berndprach/IntriguingProperties.); 揭示了在有限数据下实现稳健分类的困难，指出大量数据是提高稳健性能的关键因素。|
|📝 更新|Creating a Historical Migration Dataset from Finnish Church Records, 1800-1920|从芬兰教堂记录创建历史移民数据集，1800-1920|Ari Vesalainen, Jenna Kanerva, Aida Nitsch, Kiia Korsu, Ilari Larkiola, Laura Ruotsalainen, Filip Ginter|<http://arxiv.org/pdf/2506.07960v2>|利用深度学习自动化处理，将芬兰历史教会迁移记录转化为结构化数据集。|

