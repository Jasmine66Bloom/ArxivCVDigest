## [UPDATED!] **2025-07-19** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CXR-TFT: Multi-Modal Temporal Fusion Transformer for Predicting Chest X-ray Trajectories|胸部X射线轨迹预测的多模态时间融合变换器：CXR-TFT|Mehak Arora, Ayman Ali, Kaiyuan Wu, Carolyn Davis, Takashi Shimazui, Mahmoud Alwakeel, Victor Moas, Philip Yang .etc.|<http://arxiv.org/pdf/2507.14766v1>|提出了一种多模态时间融合变换器模型CXR-TFT，通过整合胸部X光片和临床数据，提前预测危重病人病情...|
|🆕 发布|The Origin of Self-Attention: From Pairwise Affinity Matrices to Transformers|自注意力机制的起源：从成对亲和矩阵到Transformer模型|Giorgio Roffo|<http://arxiv.org/pdf/2507.14560v1>|揭示了自注意力机制背后的亲和矩阵原理，统一了多种机器学习领域的计算方法。|
|🆕 发布|DFQ-ViT: Data-Free Quantization for Vision Transformers without Fine-tuning|无监督量化 Vision Transformers 的数据无关方法：无需微调的 DFQ-ViT|Yujia Tong, Jingling Yuan, Tian Zhang, Jianquan Liu, Chuang Hu|<http://arxiv.org/pdf/2507.14481v1>|提出DFQ-ViT方法，通过合成难度递增的样本和激活校正矩阵，实现无需数据量化的Vision Tra...|
|📝 更新|Sports Re-ID: Improving Re-Identification Of Players In Broadcast Videos Of Team Sports|体育重识别：提高团队运动赛事视频中的运动员重识别效果|Bharath Comandur|<http://arxiv.org/pdf/2206.02373v2>|提出了一种针对团队运动比赛视频中的球员重识别方法，通过分层数据采样和质心损失函数提高了识别准确度。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MultiRetNet: A Multimodal Vision Model and Deferral System for Staging Diabetic Retinopathy|多模态视觉模型与糖尿病视网膜病变分期延迟系统：MultiRetNet|Jeannie She, Katie Spivakovsky|<http://arxiv.org/pdf/2507.14738v1>|提出MultiRetNet模型，融合视网膜影像与社会经济数据，提高糖尿病视网膜病变早期诊断准确性。|
|🆕 发布|Exp-Graph: How Connections Learn Facial Attributes in Graph-based Expression Recognition|Exp-Graph：图基表情识别中连接如何学习面部属性|Nandani Sharma, Dinesh Singh|<http://arxiv.org/pdf/2507.14608v1>|提出Exp-Graph模型，通过图模型捕捉面部特征结构关系，提升面部表情识别准确性。|
|🆕 发布|Multimodal AI for Gastrointestinal Diagnostics: Tackling VQA in MEDVQA-GI 2025|多模态人工智能在胃肠道诊断中的应用：应对MEDVQA-GI 2025中的视觉问答挑战|Sujata Gaihre, Amir Thapa Magar, Prasuna Pokharel, Laxmi Tiwari|<http://arxiv.org/pdf/2507.14544v1>|[代码](https://github.com/TiwariLaxuu/VQA-Florence.git); 利用大规模多模态模型Florence，实现了胃肠内窥镜图像的视觉问答，并通过特定领域增强提高了泛化能...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Semantics, Scene to Instance-awareness: Distilling Foundation Model for Open-vocabulary Situation Recognition|从语义、场景到实例感知：为开放词汇情境识别提炼基础模型|Chen Cai, Tianyi Liu, Jianjun Gao, Wenyang Liu, Kejun Wu, Ruoyu Wang, Yi Wang, Soo Chin Liew|<http://arxiv.org/pdf/2507.14686v1>|提出了一种多模态交互提示蒸馏方法，通过从大型语言模型迁移知识，提升了小模型在开放词汇情境识别中的泛化...|
|🆕 发布|Docopilot: Improving Multimodal Models for Document-Level Understanding|文档协驾者：提升多模态模型在文档级别理解上的性能|Yuchen Duan, Zhe Chen, Yusong Hu, Weiyun Wang, Shenglong Ye, Botian Shi, Lewei Lu, Qibin Hou .etc.|<http://arxiv.org/pdf/2507.14675v1>|[代码](https://github.com/OpenGVLab/Docopilot); 提出高质量文档级数据集Doc-750K和模型Docopilot，提升多模态文档理解准确性与效率。|
|📝 更新|EgoM2P: Egocentric Multimodal Multitask Pretraining|自我中心多模态多任务预训练：EgoM2P|Gen Li, Yutong Chen, Yiqian Wu, Kaifeng Zhao, Marc Pollefeys, Siyu Tang|<http://arxiv.org/pdf/2506.07886v3>|[代码](https://egom2p.github.io/.); 提出了EgoM2P框架，通过高效时间编码和多模态掩码建模，解决了 egocentric 视觉中的多模...|
|🆕 发布|LEAD: Exploring Logit Space Evolution for Model Selection|LEAD：探索模型选择中的Logit空间演化|Zixuan Hu, Xiaotong Li, Shixiang Tang, Jun Liu, Yichun Hu, Ling-Yu Duan|<http://arxiv.org/pdf/2507.14559v1>|提出了一种基于日志空间优化的模型选择方法，有效预测预训练模型的迁移性，简化了下游任务的模型选择过程。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SemiOccam: A Robust Semi-Supervised Image Recognition Network Using Sparse Labels|半监督稀疏标签图像识别网络的稳健性研究：SemiOccam|Rui Yann, Tianshuo Zhang, Xianglei Xing|<http://arxiv.org/pdf/2506.03582v3>|[代码](https://github.com/Shu1L0n9/SemiOccam.); 提出了一种高效的半监督图像识别网络SemiOccam，通过优化特征表示与目标类的互信息，在极少量标注...|
|📝 更新|Texture or Semantics? Vision-Language Models Get Lost in Font Recognition|纹理还是语义？视觉-语言模型在字体识别中迷失|Zhecheng Li, Guoxian Song, Yujun Cai, Zhen Xiong, Junsong Yuan, Yiwei Wang|<http://arxiv.org/pdf/2503.23768v2>|发现现代视觉语言模型在字体识别任务上表现有限，引入了专门的字体识别基准数据集进行评估。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Fourier Domain Adaptation for Traffic Light Detection in Adverse Weather|傅里叶域自适应用于恶劣天气下的交通灯检测|Ishaan Gakhar, Aryesh Guha, Aryaman Gupta, Amit Agarwal, Ujjwal Verma|<http://arxiv.org/pdf/2411.07901v2>|提出Fourier域自适应方法，有效提升恶劣天气下交通灯检测性能。|
|📝 更新|EHPE: A Segmented Architecture for Enhanced Hand Pose Estimation|增强手部姿态估计的分段架构：EHPE|Bolun Zheng, Xinjie Liu, Qianyu Zhang, Canjin Wang, Fangni Chen, Mingen Xu|<http://arxiv.org/pdf/2507.09560v2>|[代码](https://github.com/SereinNout/EHPE.); 提出了一种分段架构EHPE，通过局部提取指尖和手腕关节，有效减少误差累积，提高了手部姿态估计的准确性...|
|📝 更新|TruthLens: Explainable DeepFake Detection for Face Manipulated and Fully Synthetic Data|“真相透镜：面向面部操纵与全合成数据的可解释深度伪造检测”|Rohit Kundu, Shan Jia, Vishal Mohanty, Athula Balachandran, Amit K. Roy-Chowdhury|<http://arxiv.org/pdf/2503.15867v2>|提出TruthLens框架，实现DeepFake检测并提供详细解释，提升准确性和可解释性。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multispectral State-Space Feature Fusion: Bridging Shared and Cross-Parametric Interactions for Object Detection|多光谱状态空间特征融合：桥接共享与交叉参数交互以实现目标检测|Jifeng Shen, Haibo Zhan, Shaohua Dong, Xin Zuo, Wankou Yang, Haibin Ling|<http://arxiv.org/pdf/2507.14643v1>|[代码](https://github.com/61s61min/MS2Fusion.git.); 提出MS2Fusion框架，通过双路径参数交互机制有效融合多光谱特征，提升物体检测性能。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DiSCO-3D : Discovering and segmenting Sub-Concepts from Open-vocabulary queries in NeRF|DiSCO-3D : 从开放词汇查询中发掘和分割NeRF中的子概念|Doriand Petit, Steve Bourgeois, Vincent Gay-Bellile, Florian Chabot, Loïc Barthe|<http://arxiv.org/pdf/2507.14596v1>|提出DiSCO-3D方法，结合神经场表征与弱开放词汇指导，实现适应场景与用户查询的3D语义分割。|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ChartQA-X: Generating Explanations for Visual Chart Reasoning|图表问答-X：为视觉图表推理生成解释|Shamanthak Hegde, Pooyan Fazli, Hasti Seifi|<http://arxiv.org/pdf/2504.13275v2>|提出了一种生成详细解释的ChartQA-X模型，显著提升了图表问题回答的准确性和解释质量。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RACR-MIL: Rank-aware contextual reasoning for weakly supervised grading of squamous cell carcinoma using whole slide images|RACR-MIL：基于排名感知的上下文推理的弱监督分级鳞状细胞癌的全幻灯片图像研究|Anirudh Choudhary, Mosbah Aouad, Krishnakant Saboo, Angelina Hwang, Jacob Kechter, Blake Bordeaux, Puneet Bhullar, David DiCaudo .etc.|<http://arxiv.org/pdf/2308.15618v2>|提出了一种弱监督学习框架RACR-MIL，通过结合全局与局部上下文信息，有效提升了SCC分级准确性和...|
|📝 更新|OSCAR: One-Step Diffusion Codec Across Multiple Bit-rates|OSCAR：一步扩散编解码器跨多比特率|Jinpei Guo, Yifei Ji, Zheng Chen, Kai Liu, Min Liu, Wang Rao, Wenbo Li, Yong Guo .etc.|<http://arxiv.org/pdf/2505.16091v4>|[代码](https://github.com/jp-guo/OSCAR.); 提出了一种多码率下的一步扩散编解码器OSCAR，通过单次去噪替代迭代采样，大幅提升图像压缩的推理效率...|
|📝 更新|Contour Flow Constraint: Preserving Global Shape Similarity for Deep Learning based Image Segmentation|轮廓流约束：保留全局形状相似性用于基于深度学习的图像分割|Shengzhe Chen, Zhaoxuan Dong, Jun Liu|<http://arxiv.org/pdf/2504.09384v2>|提出基于轮廓流约束的图像分割方法，通过保持全局形状相似性显著提升分割准确度。|
|🆕 发布|Gene-DML: Dual-Pathway Multi-Level Discrimination for Gene Expression Prediction from Histopathology Images|基因-双路径多层次判别模型：基于病理组织图像的基因表达预测|Yaxuan Song, Jianan Fan, Hang Chang, Weidong Cai|<http://arxiv.org/pdf/2507.14670v1>|提出了一种双路径多级判别框架Gene-DML，通过跨模态表示对齐提升病理图像基因表达预测准确性。|
|📝 更新|Towards Cross-modal Retrieval in Chinese Cultural Heritage Documents: Dataset and Solution|面向中文文化遗产文档的跨模态检索：数据集与解决方案|Junyi Yuan, Jian Zhang, Fangyu Wu, Dongming Lu, Huanda Lu, Qiufeng Wang|<http://arxiv.org/pdf/2505.10921v2>|提出针对中国文化遗产文档的跨模态检索方法，构建专用数据集并提升检索准确性。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|QUTCC: Quantile Uncertainty Training and Conformal Calibration for Imaging Inverse Problems|QUTCC：分位数不确定性训练与符合校准成像逆问题|Cassandra Tong Ye, Shamus Li, Tyler King, Kristina Monakhova|<http://arxiv.org/pdf/2507.14760v1>|提出了一种非线性量纲不确定性训练与校准方法，有效缩小了图像重建任务中的不确定性区间。|
|📝 更新|AutoPartGen: Autogressive 3D Part Generation and Discovery|自动部件生成与发现：渐进式三维部件生成|Minghao Chen, Jianyuan Wang, Roman Shapovalov, Tom Monnier, Hyunyoung Jung, Dilin Wang, Rakesh Ranjan, Iro Laina .etc.|<http://arxiv.org/pdf/2507.13346v2>|提出AutoPartGen模型，通过自回归方式生成3D物体部件并自动确定部件类型和数量，实现高质量3...|
|📝 更新|Vulnerability-Aware Spatio-Temporal Learning for Generalizable Deepfake Video Detection|面向漏洞感知的时空学习用于泛化的深度伪造视频检测|Dat Nguyen, Marcella Astrid, Anis Kacem, Enjie Ghorbel, Djamila Aouada|<http://arxiv.org/pdf/2501.01184v3>|[代码](https://github.com/10Ring/FakeSTormer.); 提出了一种细粒度的深度伪造视频检测方法FakeSTormer，通过多任务学习和视频级数据合成策略，有...|
|📝 更新|Once-for-All: Controllable Generative Image Compression with Dynamic Granularity Adaptation|一旦完成：具有动态粒度适应性的可控生成图像压缩|Anqi Li, Feng Li, Yuxi Liu, Runmin Cong, Yao Zhao, Huihui Bai|<http://arxiv.org/pdf/2406.00758v4>|[代码](https://github.com/lianqi1008/Control-GIC.); 提出了一种可控生成图像压缩框架Control-GIC，实现细粒度比特率调整，提升压缩质量和灵活性。|
|🆕 发布|Benefit from Reference: Retrieval-Augmented Cross-modal Point Cloud Completion|得益于参考：检索增强的跨模态点云补全|Hongye Hou, Liu Zhan, Yang Yang|<http://arxiv.org/pdf/2507.14485v1>|提出了一种结合跨模态检索的3D点云补全框架，通过借鉴相似样本的结构信息，有效提高了点云的生成质量和泛...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BusterX++: Towards Unified Cross-Modal AI-Generated Content Detection and Explanation with MLLM|BusterX++：面向统一跨模态AI生成内容检测与解释的多模态语言模型|Haiquan Wen, Tianxiao Li, Zhenglin Huang, Yiwei He, Guangliang Cheng|<http://arxiv.org/pdf/2507.14632v1>|提出了BusterX++框架，通过多模态检测和解释，有效识别和解释合成媒体内容。|
|🆕 发布|ArtiMuse: Fine-Grained Image Aesthetics Assessment with Joint Scoring and Expert-Level Understanding|“ArtiMuse：结合评分与专家级理解进行细粒度图像美学评估”|Shuo Cao, Nan Ma, Jiayang Li, Xiaohui Li, Lihao Shao, Kaiwen Zhu, Yu Zhou, Yuandong Pu .etc.|<http://arxiv.org/pdf/2507.14533v1>|提出ArtiMuse模型，融合评分与专家级理解，提升图像美学评估的精细度与专业度。|
|📝 更新|Rethinking Data Protection in the (Generative) Artificial Intelligence Era|重新思考在（生成式）人工智能时代的数据保护问题|Yiming Li, Shuo Shao, Yu He, Junfeng Guo, Tianwei Zhang, Zhan Qin, Pin-Yu Chen, Michael Backes .etc.|<http://arxiv.org/pdf/2507.03034v3>|提出四级数据保护分类法，全面覆盖生成式AI模型和系统的多样化需求。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PerspectiveNet: Multi-View Perception for Dynamic Scene Understanding|“PerspectiveNet：动态场景理解的多视角感知”|Vinh Nguyen|<http://arxiv.org/pdf/2410.16824v2>|提出PerspectiveNet模型，通过多视角视觉特征转换和大型语言模型结合，高效生成动态场景详细...|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CD-NGP: A Fast Scalable Continual Representation for Dynamic Scenes|CD-NGP：动态场景的快速可扩展连续表示|Zhenhuan Liu, Shuai Liu, Zhiwei Ning, Jie Yang, Yifan Zuo, Yuming Fang, Wei Liu|<http://arxiv.org/pdf/2409.05166v6>|提出了一种参数复用的持续学习框架CD-NGP，通过时空哈希编码提升动态场景的渲染质量和模型可扩展性。|
|🆕 发布|Real-Time Scene Reconstruction using Light Field Probes|使用光场探针进行实时场景重建|Yaru Liu, Derek Nowrouzezahri, Morgan Mcguire|<http://arxiv.org/pdf/2507.14624v1>|提出了一种利用探针数据结构的高效场景重建方法，无需显式依赖场景几何，适用于大规模复杂场景的实时渲染。|
|🆕 发布|Synthesizing Images on Perceptual Boundaries of ANNs for Uncovering Human Perceptual Variability on Facial Expressions|在神经网络的感知边界上合成图像以揭示人类对面部表情的感知变异性|Haotian Deng, Chi Zhang, Chen Wei, Quanying Liu|<http://arxiv.org/pdf/2507.14549v1>|通过生成位于ANN决策边界的面部表情样本，揭示了ANN分类模糊性与人类感知差异之间的系统性关联。|
|🆕 发布|Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey|《前馈三维重建与视图合成进展综述》|Jiahui Zhang, Yuelei Li, Anpei Chen, Muyu Xu, Kunhao Liu, Jianyuan Wang, Xiao-Xiao Long, Hanxue Liang .etc.|<http://arxiv.org/pdf/2507.14501v1>|系统梳理了基于深度学习的快速3D重建与视图合成技术，推动了计算机视觉领域的发展。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Self-supervised Learning of Hybrid Part-aware 3D Representations of 2D Gaussians and Superquadrics|自监督学习二维高斯分布与超二次曲面混合的局部感知三维表示|Zhirui Gao, Renjiao Yi, Yuhang Huang, Wei Chen, Chenyang Zhu, Kai Xu|<http://arxiv.org/pdf/2408.10789v4>|提出了一种自监督的部件感知三维重建框架，结合二维高斯分布和超二次曲面，实现了对物体和场景的高解释性结...|
|🆕 发布|Motion Segmentation and Egomotion Estimation from Event-Based Normal Flow|基于事件驱动的法向流运动分割与自我运动估计|Zhiyuan Hua, Dehao Yuan, Cornelia Fermüller|<http://arxiv.org/pdf/2507.14500v1>|提出了一种利用事件驱动的法向流进行运动分割和自我运动估计的框架，无需完整的光流计算即可实现准确分割和...|
|📝 更新|SpatialTrackerV2: 3D Point Tracking Made Easy|空间追踪器V2：轻松实现三维点追踪|Yuxi Xiao, Jianyuan Wang, Nan Xue, Nikita Karaev, Yuri Makarov, Bingyi Kang, Xing Zhu, Hujun Bao .etc.|<http://arxiv.org/pdf/2507.12462v2>|提出了SpatialTrackerV2，一种将点追踪、单目深度估计和相机位姿估计统一于一体的3D点追...|


## 时序视觉分析 (Temporal Visual Analysis)


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AI-Powered Precision in Sport Taekwondo: Enhancing Fairness, Speed, and Trust in Competition (FST.ai)|《AI赋能的体育跆拳道精准度：提升比赛的公平性、速度与信任（FST.ai）》|Keivan Shariatmadar, Ahmad Osman|<http://arxiv.org/pdf/2507.14657v1>|提出FST.ai框架，利用计算机视觉和深度学习实现体育赛事中动作的快速准确识别与评分。|
|📝 更新|EgoEvGesture: Gesture Recognition Based on Egocentric Event Camera|自我事件相机基础上的手势识别：EgoEvGesture|Luming Wang, Hao Shi, Xiaoting Yin, Kailun Yang, Kaiwei Wang, Jian Bai|<http://arxiv.org/pdf/2503.12419v3>|[代码](https://github.com/3190105222/EgoEv_Gesture.); 提出了一种针对事件相机数据的轻量级网络架构，有效分离头部运动和手势动态，提高了 egocentric...|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Real Time Captioning of Sign Language Gestures in Video Meetings|视频会议中实时手语手势字幕生成|Sharanya Mukherjee, Md Hishaam Akhtar, Kannadasan R|<http://arxiv.org/pdf/2507.14543v1>|提出了一种浏览器扩展，自动将视频会议中的手语手势实时转换为字幕，助力听障人士与健全人士的无障碍沟通。|
|🆕 发布|Adaptive 3D Gaussian Splatting Video Streaming|自适应三维高斯散点视频流传输|Han Gong, Qiyue Li, Zhi Liu, Hao Zhou, Peng Yuan Zhou, Zhu Li, Jie Li|<http://arxiv.org/pdf/2507.14432v1>|提出了一种基于高斯变形场的3DGS视频流构建方法，通过混合显著性分块和差异化质量建模，实现了高效压缩...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GTPBD: A Fine-Grained Global Terraced Parcel and Boundary Dataset|GTPBD：一种细粒度全局梯田地块与边界数据集|Zhiwei Zhang, Zi Ye, Yibin Wen, Shuai Yuan, Haohuan Fu, Jianxi Huang, Juepeng Zheng|<http://arxiv.org/pdf/2507.14697v1>|提出首个细粒度全球梯田地块与边界数据集GTPBD，为复杂梯田地形的高精度农业分析提供了基础数据支持。|


### 跨模态一致性学习 (Cross-modal Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GPI-Net: Gestalt-Guided Parallel Interaction Network via Orthogonal Geometric Consistency for Robust Point Cloud Registration|GPI-Net：基于格式塔引导的正交几何一致性稳健点云配准并行交互网络|Weikang Gu, Mingyue Han, Li Xue, Heng Dong, Changcai Yang, Riqing Chen, Lifang Wei|<http://arxiv.org/pdf/2507.14452v1>|[代码](https://github.com/gwk/GPI-Net.); 提出了一种结合格式塔原理的GPI-Net网络，通过优化信息融合策略提高了点云配准的准确性和鲁棒性。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Resource-Efficient Affordance Grounding with Complementary Depth and Semantic Prompts|具有互补深度和语义提示的资源高效 affordance 地面定位|Yizhou Huang, Fan Yang, Guoliang Zhu, Gen Li, Hao Shi, Yukun Zuo, Wenrui Chen, Zhiyong Li .etc.|<http://arxiv.org/pdf/2503.02600v2>|[代码](https://github.com/DAWDSE/BiT-Align.); 提出了一种融合深度和语义提示的轻量级 affordance 地图框架，提升了性能并大幅减少了模型参数...|
|📝 更新|Growing a Twig to Accelerate Large Vision-Language Models|"生长一根枝条以加速大型视觉-语言模型"|Zhenwei Shao, Mingyang Wang, Zhou Yu, Wenwen Pan, Yan Yang, Tao Wei, Hongyuan Zhang, Ning Mao .etc.|<http://arxiv.org/pdf/2503.14075v2>|提出TwigVLM方法，通过生长轻量级枝条和引导性剪枝，大幅提升大型视觉语言模型的准确性和生成速度。|
|🆕 发布|DCHM: Depth-Consistent Human Modeling for Multiview Detection|多视角检测中的深度一致性人体建模：DCHM|Jiahao Ma, Tianyu Wang, Miaomiao Liu, David Ahmedt-Aristizabal, Chuong Nguyen|<http://arxiv.org/pdf/2507.14505v1>|[代码](https://jiahao-ma.github.io/DCHM); 提出深度一致性人体建模方法DCHM，通过多视角融合实现精确行人定位，无需依赖人工标注。|
|📝 更新|WMNav: Integrating Vision-Language Models into World Models for Object Goal Navigation|WMNav：将视觉语言模型融入世界模型进行目标物体导航|Dujun Nie, Xianda Guo, Yiqun Duan, Ruijun Zhang, Long Chen|<http://arxiv.org/pdf/2503.02247v5>|[代码](https://b0b8k1ng.github.io/WMNav); 提出WMNav框架，融合视觉语言模型预测环境状态，提升物体导航的成功率和效率。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards a Proactive Autoscaling Framework for Data Stream Processing at the Edge using GRU and Transfer Learning|面向边缘数据流处理的基于GRU和迁移学习的主动自动扩展框架|Eugene Armah, Linda Amoako Bannning|<http://arxiv.org/pdf/2507.14597v1>|提出三步骤主动边缘流处理自动扩展框架，使用GRU和迁移学习预测负载并动态调整资源。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Uncertainty-aware Probabilistic 3D Human Motion Forecasting via Invertible Networks|通过可逆网络的不确定性感知概率性三维人体运动预测|Yue Ma, Kanglei Zhou, Fuyang Yu, Frederick W. B. Li, Xiaohui Liang|<http://arxiv.org/pdf/2507.14694v1>|提出了一种基于可逆网络的3D人体运动预测方法，实现了对预测结果不确定性的有效量化。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Generative Distribution Distillation|生成分布蒸馏|Jiequan Cui, Beier Zhu, Qingshan Xu, Xiaogang Xu, Pengguang Chen, Xiaojuan Qi, Bei Yu, Hanwang Zhang .etc.|<http://arxiv.org/pdf/2507.14503v1>|提出生成分布蒸馏框架，通过分割策略和分布收缩技术实现高效无监督知识蒸馏。|


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VisGuard: Securing Visualization Dissemination through Tamper-Resistant Data Retrieval|VisGuard：通过抗篡改数据检索确保可视化传播安全|Huayuan Ye, Juntong Chen, Shenzhuo Zhang, Yipeng Zhang, Changbo Wang, Chenhui Li|<http://arxiv.org/pdf/2507.14459v1>|提出VisGuard框架，通过增强数据嵌入的鲁棒性，有效保护图像信息免受篡改。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Composed Multi-modal Retrieval: A Survey of Approaches and Applications|组合多模态检索：方法与应用综述|Kun Zhang, Jingyu Li, Zhe Li, Jingjing Zhang, Fan Li, Yandong Liu, Rui Yan, Zihang Jiang .etc.|<http://arxiv.org/pdf/2503.01334v2>|[代码](https://github.com/kkzhang95/Awesome-Composed-Multi-modal-Retrieval); 系统梳理了组合多模态检索技术，展示了其在多领域的应用潜力及未来研究方向。|
|📝 更新|Advancing Textual Prompt Learning with Anchored Attributes|《利用锚定属性推进文本提示学习》|Zheng Li, Yibing Song, Ming-Ming Cheng, Xiang Li, Jian Yang|<http://arxiv.org/pdf/2412.09442v4>|[代码](https://github.com/zhengli97/ATPrompt.); 提出利用属性作为桥梁，通过属性锚定文本提示学习，扩展了视觉语言模型对未知类别的学习能力。|
|📝 更新|Learning Granularity-Aware Affordances from Human-Object Interaction for Tool-Based Functional Dexterous Grasping|从人-物交互中学习粒度感知的可用性以实现基于工具的功能灵巧抓取|Fan Yang, Wenrui Chen, Kailun Yang, Haoran Lin, Dongsheng Luo, Conghui Tang, Zhiyong Li, Yaonan Wang|<http://arxiv.org/pdf/2407.00614v2>|[代码](https://github.com/yangfan293/GAAF-DEX.); 提出了一种基于人类手物互动学习粗细度感知功效特征的方法，用于实现灵巧手工具化功能抓取。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Point'n Move: Interactive Scene Object Manipulation on Gaussian Splatting Radiance Fields|“点动”：基于高斯散点辐射场的交互式场景物体操作|Jiajun Huang, Hongchuan Yu|<http://arxiv.org/pdf/2311.16737v2>|提出Point'n Move方法，实现实时交互式场景物体操作与修复，提升编辑效率和画面质量。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Influence of High-Performance Image-to-Image Translation Networks on Clinical Visual Assessment and Outcome Prediction: Utilizing Ultrasound to MRI Translation in Prostate Cancer|高性能图像到图像转换网络对临床视觉评估和预后预测的影响：利用超声到磁共振成像转换在前列腺癌中的应用|Mohammad R. Salmanpour, Amin Mousavi, Yixi Xu, William B Weeks, Ilker Hacihaliloglu|<http://arxiv.org/pdf/2501.18109v2>|探究图像翻译网络在临床评估中的应用，发现2D-Pix2Pix网络在特征识别和分类准确性上具有优势。|
|📝 更新|MoViAD: A Modular Library for Visual Anomaly Detection|MoViAD：一个用于视觉异常检测的模块化库|Manuel Barusco, Francesco Borsatti, Arianna Stropeni, Davide Dalle Pezze, Gian Antonio Susto|<http://arxiv.org/pdf/2507.12049v2>|介绍了MoViAD库，加速视觉异常检测研究，提供多样化模型和工具，支持边缘计算和物联网部署。|
|📝 更新|CVPT: Cross Visual Prompt Tuning|CVPT：跨视觉提示调谐|Lingyun Huang, Jianxu Mao, Junfei Yi, Ziming Tao, Yaonan Wang|<http://arxiv.org/pdf/2408.14961v2>|[代码](https://github.com/Lingyun0419/CVPT); 提出CVPT方法，通过引入交叉注意力模块优化视觉提示微调，提升模型性能与效率。|
|🆕 发布|Descrip3D: Enhancing Large Language Model-based 3D Scene Understanding with Object-Level Text Descriptions|Descrip3D：利用对象级文本描述增强大型语言模型基础的3D场景理解|Jintang Xue, Ganning Zhao, Jie-En Yao, Hong-En Chen, Yue Hu, Meida Chen, Suya You, C. -C. Jay Kuo|<http://arxiv.org/pdf/2507.14555v1>|提出了一种结合自然语言描述的3D场景理解框架，通过文本描述增强对象关系理解，提升了多任务性能。|
|🆕 发布|Efficient Whole Slide Pathology VQA via Token Compression|通过标记压缩实现高效的全幻灯片病理学视觉问答|Weimin Lyu, Qingqiao Hu, Kehan Qi, Zhan Shi, Wentao Huang, Saumya Gupta, Chao Chen|<http://arxiv.org/pdf/2507.14497v1>|提出了一种基于压缩 tokens 的方法TCP-LLaVA，用于处理大规模病理图像的视觉问答，大幅降...|
|📝 更新|VisualToolAgent (VisTA): A Reinforcement Learning Framework for Visual Tool Selection|视觉工具代理（VisTA）：一种用于视觉工具选择的强化学习框架|Zeyi Huang, Yuyang Ji, Anirudh Sundara Rajan, Zefan Cai, Wen Xiao, Haohan Wang, Junjie Hu, Yong Jae Lee|<http://arxiv.org/pdf/2505.20289v2>|提出VisTA框架，通过强化学习实现视觉代理的动态工具选择与组合，提升任务性能和泛化能力。|
|🆕 发布|Adaptive 3D Gaussian Splatting Video Streaming: Visual Saliency-Aware Tiling and Meta-Learning-Based Bitrate Adaptation|自适应三维高斯散点视频流传输：视觉显著性感知的分块与基于元学习的比特率适配|Han Gong, Qiyue Li, Jie Li, Zhi Liu|<http://arxiv.org/pdf/2507.14454v1>|提出视觉显著性引导的3D视频分块和元学习自适应码率技术，显著提升沉浸式3D视频流的质量和适应性。|
|🆕 发布|CRAFT: A Neuro-Symbolic Framework for Visual Functional Affordance Grounding|CRAFT：一种用于视觉功能性可用性基础的神经符号框架|Zhou Chen, Joe Lin, Sathyanarayanan N. Aakur|<http://arxiv.org/pdf/2507.14426v1>|提出CRAFT框架，融合常识性先验和视觉证据，实现动作相关的物体识别并提升解释性。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OptiCorNet: Optimizing Sequence-Based Context Correlation for Visual Place Recognition|OptiCorNet：优化基于序列的上下文相关性以实现视觉场景识别|Zhenyu Li, Tianyi Shang, Pengjie Xu, Ruirui Zhang, Fanchen Kong|<http://arxiv.org/pdf/2507.14477v1>|提出了一种结合时空信息的视觉定位框架OptiCorNet，通过端到端学习显著提升了动态环境下的定位准...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|IRGPT: Understanding Real-world Infrared Image with Bi-cross-modal Curriculum on Large-scale Benchmark|红外图像理解：基于大规模基准的双向跨模态课程学习|Zhe Cao, Jin Zhang, Ruiheng Zhang|<http://arxiv.org/pdf/2507.14449v1>|提出首个面向真实红外图像的多模态大语言模型IRGPT，通过大规模红外-文本数据集和双向跨模态课程迁移...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CABLD: Contrast-Agnostic Brain Landmark Detection with Consistency-Based Regularization|CABLD：基于一致性正则化的对比度无关脑部地标检测|Soorena Salari, Arash Harirpoush, Hassan Rivaz, Yiming Xiao|<http://arxiv.org/pdf/2411.17845v3>|[代码](https://github.com/HealthX-Lab/CABLD.); 提出了一种自监督的3D脑部地标检测框架，仅需单个参考样例即可准确检测不同对比度的未标注扫描，减少了对...|
|🆕 发布|WSI-Agents: A Collaborative Multi-Agent System for Multi-Modal Whole Slide Image Analysis|WSI-Agent：用于多模态全切片图像分析的合作多智能体系统|Xinheng Lyu, Yuci Liang, Wenting Chen, Meidan Ding, Jiaqi Yang, Guolin Huang, Daokun Zhang, Xiangjian He .etc.|<http://arxiv.org/pdf/2507.14680v1>|提出了一种协作多代理系统WSI-Agents，通过整合专业代理和任务分配机制，提升了全切片图像多模态...|
|🆕 发布|Depthwise-Dilated Convolutional Adapters for Medical Object Tracking and Segmentation Using the Segment Anything Model 2|使用Segment Anything模型2进行医学目标跟踪与分割的深度可分离膨胀卷积适配器|Guoping Xu, Christopher Kabat, You Zhang|<http://arxiv.org/pdf/2507.14613v1>|[代码](https://github.com/apple1986/DD-SAM2.); 提出DD-SAM2框架，通过Depthwise-Dilated Adapter提升医疗视频对象追踪与...|
|🆕 发布|Performance comparison of medical image classification systems using TensorFlow Keras, PyTorch, and JAX|使用TensorFlow Keras、PyTorch和JAX的医疗图像分类系统性能比较|Merjem Bećirović, Amina Kurtović, Nordin Smajlović, Medina Kapo, Amila Akagić|<http://arxiv.org/pdf/2507.14587v1>|比较了TensorFlow Keras、PyTorch和JAX在血细胞图像分类中的性能，发现JAX和...|
|🆕 发布|Benchmarking GANs, Diffusion Models, and Flow Matching for T1w-to-T2w MRI Translation|对比评估生成对抗网络、扩散模型和流匹配在T1w到T2w MRI转换中的性能|Andrea Moschetto, Lemuel Puglisi, Alec Sargood, Pierluigi Dell'Acqua, Francesco Guarnera, Sebastiano Battiato, Daniele Ravì|<http://arxiv.org/pdf/2507.14575v1>|[代码](https://github.com/AndreaMoschetto/medical-I2I-benchmark.); 对比了GANs、扩散模型和流匹配技术，发现GAN在MRI图像转换中效果更佳。|
|🆕 发布|Clutter Detection and Removal by Multi-Objective Analysis for Photographic Guidance|基于多目标分析的杂乱检测与移除方法用于摄影引导|Xiaoran Wu|<http://arxiv.org/pdf/2507.14553v1>|提出了一种摄影指导系统，通过评估物体美学贡献和迭代图像修复算法，帮助用户识别和移除照片杂乱元素。|
|📝 更新|Alleviating Textual Reliance in Medical Language-guided Segmentation via Prototype-driven Semantic Approximation|通过原型驱动的语义近似减轻医学语言引导分割中的文本依赖性|Shuchang Ye, Usman Naseem, Mingyuan Meng, Jinman Kim|<http://arxiv.org/pdf/2507.11055v3>|提出ProLearn框架，通过原型驱动的语义近似减轻医学图像分割对文本的依赖。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|InterAct-Video: Reasoning-Rich Video QA for Urban Traffic|《InterAct-Video：面向城市交通的富推理视频问答》|Joseph Raj Vishal, Rutuja Patil, Manas Srinivas Gowda, Katha Naik, Yezhou Yang, Bharatesh Chakravarthi|<http://arxiv.org/pdf/2507.14743v1>|[代码](https://github.com/joe-rabbit/InterAct_VideoQA); 提出InterAct VideoQA数据集，提升了视频问答模型在处理复杂交通场景的性能。|
|🆕 发布|GEMINUS: Dual-aware Global and Scene-Adaptive Mixture-of-Experts for End-to-End Autonomous Driving|GEMINUS：端到端自动驾驶中的双感知全局与场景自适应专家混合模型|Chi Wan, Yixin Cui, Jiatong Du, Shuo Yang, Yulong Bai, Yanjun Huang|<http://arxiv.org/pdf/2507.14456v1>|[代码](https://github.com/newbrains1/GEMINUS.); 提出了一种结合全局和场景自适应专家的自动驾驶框架，有效应对复杂交通环境，实现自适应和稳健的驾驶性能。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|3DGAA: Realistic and Robust 3D Gaussian-based Adversarial Attack for Autonomous Driving|三维高斯基础上的真实与鲁棒对抗攻击方法研究：面向自动驾驶|Yixun Zhang, Lizhi Wang, Junjun Zhao, Wending Zhao, Feng Zhou, Yonghao Dang, Jianqin Yin|<http://arxiv.org/pdf/2507.09993v2>|提出3DGAA方法，通过联合优化几何与外观属性，实现了物理真实且高效的自动驾驶系统对抗攻击。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Artificial Intelligence in the Food Industry: Food Waste Estimation based on Computer Vision, a Brief Case Study in a University Dining Hall|食品工业中的人工智能：基于计算机视觉的食物浪费估算——大学食堂的简要案例研究|Shayan Rokhva, Babak Teimourpour|<http://arxiv.org/pdf/2507.14662v1>|提出了一种基于计算机视觉的框架，通过图像分割估计大学食堂餐后食物浪费，实现实时监测。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Self-Supervised Distillation of Legacy Rule-Based Methods for Enhanced EEG-Based Decision-Making|自监督蒸馏传统基于规则方法以提升基于EEG的决策制定性能|Yipeng Zhang, Yuanyi Ding, Chenda Duan, Atsuro Daida, Hiroki Nariai, Vwani Roychowdhury|<http://arxiv.org/pdf/2507.14542v1>|提出了一种自监督学习框架，通过利用传统检测器捕获的信号，有效精炼病理高频振荡的识别。|

