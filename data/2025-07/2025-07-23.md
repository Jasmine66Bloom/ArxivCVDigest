## [UPDATED!] **2025-07-23** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Advancing Multimodal LLMs by Large-Scale 3D Visual Instruction Dataset Generation|通过大规模三维视觉指令数据集生成推进多模态大型语言模型|Liu He, Xiao Zeng, Yizhi Song, Albert Y. C. Chen, Lu Xia, Shashwat Verma, Sankalp Dayal, Min Sun .etc.|<http://arxiv.org/pdf/2507.08513v2>|提出了一种生成大规模3D视觉指令数据集的方法，大幅提升了多模态大语言模型对相机-物体关系的理解能力。|
|🆕 发布|Multimodal Recurrent Ensembles for Predicting Brain Responses to Naturalistic Movies (Algonauts 2025)|多模态循环集成模型用于预测大脑对自然场景电影反应的研究（Algonauts 2025）|Semih Eren, Deniz Kucukahmetler, Nico Scherf|<http://arxiv.org/pdf/2507.17897v1>|提出了一种融合视觉、听觉和语义信息的多模态循环集成模型，用于预测大脑对自然场景的反应，实现了竞赛第三...|
|🆕 发布|FishDet-M: A Unified Large-Scale Benchmark for Robust Fish Detection and CLIP-Guided Model Selection in Diverse Aquatic Visual Domains|FishDet-M：一个用于稳健鱼类检测和多样化水生视觉领域中CLIP引导的模型选择的统一大规模基准|Muayad Abujabal, Lyes Saad Saoud, Irfan Hussain|<http://arxiv.org/pdf/2507.17859v1>|提出FishDet-M统一基准，提升水下鱼类检测准确度，引入CLIP指导模型选择。|
|🆕 发布|SV3.3B: A Sports Video Understanding Model for Action Recognition|SV3.3B：用于动作识别的体育视频理解模型|Sai Varun Kodathala, Yashwanth Reddy Vutukoori, Rakesh Vunnam|<http://arxiv.org/pdf/2507.17844v1>|提出了一种轻量级体育视频分析模型SV3.3B，通过高效的时间运动差异采样和自监督学习，实现了对体育动...|
|🆕 发布|Lumina-mGPT 2.0: Stand-Alone AutoRegressive Image Modeling|Lumina-mGPT 2.0：独立自回归图像建模|Yi Xin, Juncheng Yan, Qi Qin, Zhen Li, Dongyang Liu, Shicheng Li, Victor Shea-Jay Huang, Yupeng Zhou .etc.|<http://arxiv.org/pdf/2507.17801v1>|[代码](https://github.com/Alpha-VLLM/Lumina-mGPT-2.0.); Lumina-mGPT 2.0实现了从零开始训练的纯自回归图像生成模型，达到顶级扩散模型质量，同时保...|
|📝 更新|AirCache: Activating Inter-modal Relevancy KV Cache Compression for Efficient Large Vision-Language Model Inference|"AirCache：激活模态相关性键值缓存压缩以提高大规模视觉语言模型推理效率"|Kai Huang, Hao Zou, Bochen Wang, Ye Xi, Zhen Xie, Hao Wang|<http://arxiv.org/pdf/2503.23956v3>|提出AirCache方法，通过压缩视觉键值缓存，提高大型视觉语言模型推理效率。|
|📝 更新|How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks|GPT-4o对视觉的理解程度如何？在标准计算机视觉任务上评估多模态基础模型|Rahul Ramachandran, Ali Garjani, Roman Bachmann, Andrei Atanov, Oğuzhan Fatih Kar, Amir Zamir|<http://arxiv.org/pdf/2507.01955v2>|评估了多模态基础模型在标准计算机视觉任务上的表现，通过文本提示链构建标准化基准框架。|
|🆕 发布|A Versatile Pathology Co-pilot via Reasoning Enhanced Multimodal Large Language Model|一种通过推理增强的多模态大型语言模型实现的通用病理学协作驾驶员|Zhe Xu, Ziyi Liu, Junlin Hou, Jiabo Ma, Cheng Jin, Yihui Wang, Zhixuan Chen, Zhengyu Zhang .etc.|<http://arxiv.org/pdf/2507.17303v1>|提出了一种多模态大规模语言模型SmartPath-R1，通过增强推理能力同时处理ROI和WSI级任务...|
|🆕 发布|PIG-Nav: Key Insights for Pretrained Image Goal Navigation Models|PIG-Nav：预训练图像目标导航模型的关键洞察|Jiansong Wan, Chengming Zhou, Jinkua Liu, Xiangge Huang, Xiaoyu Chen, Xiaohan Yi, Qisen Yang, Baiting Zhu .etc.|<http://arxiv.org/pdf/2507.17220v1>|PIG-Nav通过融合视觉观测与目标图像的早期融合网络结构和引入辅助任务，显著提升了预训练视觉导航模...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mammo-Mamba: A Hybrid State-Space and Transformer Architecture with Sequential Mixture of Experts for Multi-View Mammography|《Mammo-Mamba：一种结合状态空间和变换器架构的序列混合专家多视角乳腺X线摄影解析方法》|Farnoush Bayatmakou, Reza Taleei, Nicole Simone, Arash Mohammadi|<http://arxiv.org/pdf/2507.17662v1>|提出了一种集成选择性状态空间模型和变换器架构的Mammo-Mamba框架，通过动态专家门控提升多视角...|
|🆕 发布|Vision Transformer attention alignment with human visual perception in aesthetic object evaluation|计算机视觉Transformer注意力对齐与人类视觉感知在审美对象评价中的研究|Miguel Carrasco, César González-Martín, José Aranda, Luis Oliveros|<http://arxiv.org/pdf/2507.17616v1>|探究了Vision Transformer与人类视觉注意力的匹配性，发现特定注意力头能近似人类视觉行...|
|🆕 发布|DNT: a Deeply Normalized Transformer that can be trained by Momentum SGD|DNT：一种可通过动量随机梯度下降法训练的深度归一化变换器|Xianbiao Qi, Marco Chen, Wenjie Xiao, Jiaquan Ye, Yelin He, Chun-Guang Li, Zhouchen Lin|<http://arxiv.org/pdf/2507.17501v1>|提出了一种深度归一化Transformer架构，通过在关键位置集成归一化技术，使模型可用传统动量SG...|
|📝 更新|Transformer-Based Auxiliary Loss for Face Recognition Across Age Variations|基于Transformer的辅助损失函数用于跨年龄变化的人脸识别|Pritesh Prakash, S Umamaheswaran|<http://arxiv.org/pdf/2412.02198v3>|提出了一种结合Transformer网络与标准度量损失的辅助损失方法，有效提升了跨年龄人脸识别的准确...|
|📝 更新|SurgXBench: Explainable Vision-Language Model Benchmark for Surgery|手术解释性视觉-语言模型基准测试：SurgXBench|Jiajun Cheng, Xianwu Zhao, Sainan Liu, Xiaofan Yu, Ravi Prakash, Patrick J. Codd, Jonathan Elliott Katz, Shan Lin|<http://arxiv.org/pdf/2505.10764v3>|提出SurgXBench基准，评估视觉语言模型在手术场景中的零样本性能，并通过可解释AI分析预测可靠...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Principled Multimodal Representation Learning|原则性多模态表征学习|Xiaohao Liu, Xiaobo Xia, See-Kiong Ng, Tat-Seng Chua|<http://arxiv.org/pdf/2507.17343v1>|提出了一种无需依赖锚点的稳定多模态表征学习框架，通过优化主导奇异值实现各模态在共享方向上的对齐。|
|🆕 发布|CartoonAlive: Towards Expressive Live2D Modeling from Single Portraits|《CartoonAlive：从单张肖像迈向表现力强的实时2D建模》|Chao He, Jianqiang Ren, Jianjing Xiang, Xiejie Shen|<http://arxiv.org/pdf/2507.17327v1>|[代码](https://human3daigc.github.io/CartoonAlive_webpage); 提出了一种快速生成高质量Live2D数字人类的方法，通过单张肖像图像实现高效、互动的2D卡通角色创建...|
|📝 更新|Advancing Multimodal Reasoning via Reinforcement Learning with Cold Start|通过冷启动的强化学习推进多模态推理|Lai Wei, Yuting Li, Kaipeng Zheng, Chen Wang, Yue Wang, Linghe Kong, Lichao Sun, Weiran Huang|<http://arxiv.org/pdf/2505.22334v2>|[代码](https://github.com/waltonfuture/RL-with-Cold-Start.); 提出两阶段方法，结合监督微调与强化学习，提升多模态推理性能至开源模型最佳水平。|
|📝 更新|RoBridge: A Hierarchical Architecture Bridging Cognition and Execution for General Robotic Manipulation|RoBridge：一种连接认知与执行用于通用机器人操作的层次化架构|Kaidong Zhang, Rongtao Xu, Pengzhen Ren, Junfan Lin, Hefeng Wu, Liang Lin, Xiaodan Liang|<http://arxiv.org/pdf/2505.01709v3>|提出RoBridge架构，结合认知规划与执行能力，提升机器人通用操作性能。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bearded Dragon Activity Recognition Pipeline: An AI-Based Approach to Behavioural Monitoring|beard 胡须  dragon 龙  activity 活动  recognition 识别  pipeline 管道，这里指“流程”  AI-based 基于人工智能的  approach 方法  behavioural 行为的  monitoring 监控  胡须龙活动识别流程：一种基于人工智能的行为监控方法|Arsen Yermukan, Pedro Machado, Feliciano Domingos, Isibor Kennedy Ihianle, Jordan J. Bird, Stefano S. K. Kaburu, Samantha J. Ward|<http://arxiv.org/pdf/2507.17987v1>|提出了一种基于YOLO模型的自动监控系统，用于实时监测鬣蜥行为，提高了研究效率和数据质量。|
|🆕 发布|AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic Segmentation|AFRDA：用于域自适应语义分割的注意力特征精炼|Md. Al-Masrur Khan, Durgakant Pushp, Lantao Liu|<http://arxiv.org/pdf/2507.17957v1>|[代码](https://github.com/Masrur02/AFRDA); 提出自适应特征细化模块，通过融合高低分辨率信息并平衡局部与全局特征，提升了无监督领域自适应语义分割精...|
|📝 更新|DMS-Net:Dual-Modal Multi-Scale Siamese Network for Binocular Fundus Image Classification|DMS-Net：双模多尺度Siamese网络用于双眼底图像分类|Guohao Huo, Zibo Lin, Zitong Wang, Ruiting Dai, Hao Tang|<http://arxiv.org/pdf/2504.18046v2>|提出DMS-Net网络，通过双模态多尺度特征融合，提高了双眼眼底图像分类的准确性。|
|📝 更新|Spatial Frequency Modulation for Semantic Segmentation|空间频率调制用于语义分割|Linwei Chen, Ying Fu, Lin Gu, Dezhi Zheng, Jifeng Dai|<http://arxiv.org/pdf/2507.11893v2>|[代码](https://github.com/Linwei-Chen/SFM.); 提出了一种空间频率调制方法，通过在降采样前将高频特征调制到低频，并在升采样时恢复，有效保留了细节信息...|
|📝 更新|Feature-Enhanced TResNet for Fine-Grained Food Image Classification|特征增强的TResNet用于细粒度食品图像分类|Lulu Liu, Zhiyong Xiao|<http://arxiv.org/pdf/2507.12828v2>|提出Feature-Enhanced TResNet模型，通过风格重校准和深度通道注意力提升细粒度食...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Robust Real-Time Lane Detection Method with Fog-Enhanced Feature Fusion for Foggy Conditions|雾天条件下的鲁棒实时车道检测方法：基于雾增强特征融合|Ronghui Zhang, Yuhang Ma, Tengfei Li, Ziyu Lin, Yueying Wu, Junzhou Chen, Lin Zhang, Jia Hu .etc.|<http://arxiv.org/pdf/2504.06121v8>|提出了一种针对雾天环境的高效车道检测方法，通过特征融合网络显著提升了雾天条件下的检测性能和实时性。|
|📝 更新|BoxFusion: Reconstruction-Free Open-Vocabulary 3D Object Detection via Real-Time Multi-View Box Fusion|BoxFusion：无需重建的实时多视角框融合开放词汇三维物体检测|Yuqing Lan, Chenyang Zhu, Zhirui Gao, Jiazhao Zhang, Yihan Cao, Renjiao Yi, Yijie Wang, Kai Xu|<http://arxiv.org/pdf/2506.15610v2>|提出了无需重建的实时多视角框融合方法，实现了内存高效且实时的三维物体检测。|
|🆕 发布|Physics-based Human Pose Estimation from a Single Moving RGB Camera|基于物理原理的单移动RGB相机人体姿态估计|Ayce Idil Aytekin, Chuqiao Li, Diogo Luvizon, Rishabh Dabral, Martin Oswald, Marc Habermann, Christian Theobalt|<http://arxiv.org/pdf/2507.17406v1>|提出首个包含真实移动相机轨迹和场景几何的基准数据集，并引入结合物理约束的跟踪方法，提升非平坦场景下动...|
|🆕 发布|SFUOD: Source-Free Unknown Object Detection|无源未知目标检测|Keon-Hee Park, Seun-An Choe, Gyeong-Moon Park|<http://arxiv.org/pdf/2507.17373v1>|提出了一种无需源数据标注的未知物体检测方法，通过跨域注意力和主轴投影实现已知与未知物体的识别。|
|🆕 发布|Temporal Point-Supervised Signal Reconstruction: A Human-Annotation-Free Framework for Weak Moving Target Detection|时间点监督信号重建：一种无需人工标注的弱移动目标检测框架|Weihua Gao, Chunxu Ren, Wenlong Niu, Xiaodong Peng|<http://arxiv.org/pdf/2507.17334v1>|提出了一种无需人工标注的 Temporal Point-Supervised 框架，通过像素级时间信...|
|🆕 发布|A Low-Cost Machine Learning Approach for Timber Diameter Estimation|一种低成本机器学习方法用于木材直径估计|Fatemeh Hasanzadeh Fard, Sanaz Hasanzadeh Fard, Mehdi Jonoobi|<http://arxiv.org/pdf/2507.17219v1>|提出了一种基于YOLOv5的低成本机器学习框架，通过标准RGB图像自动化估算木材直径，提高木材加工效...|
|🆕 发布|DesignLab: Designing Slides Through Iterative Detection and Correction|设计实验室：通过迭代检测与修正进行幻灯片设计|Jooyeol Yun, Heng Wang, Yotaro Shimose, Jaegul Choo, Shingo Takamatsu|<http://arxiv.org/pdf/2507.17202v1>|提出了一种迭代检测与修正的设计方法DesignLab，通过分工合作提升非专业人士制作高质量幻灯片的能...|
|🆕 发布|Asymmetric Lesion Detection with Geometric Patterns and CNN-SVM Classification|基于几何图案和CNN-SVM分类的不对称病变检测|M. A. Rasel, Sameem Abdul Kareem, Zhenli Kwan, Nik Aimee Azizah Faheem, Winn Hui Han, Rebecca Kai Jan Choong, Shin Shen Yong, Unaizah Obaidellah|<http://arxiv.org/pdf/2507.17185v1>|提出了一种结合几何图案分析和CNN-SVM分类的皮肤病变不对称检测技术，实现了高准确率的诊断性能。|
|🆕 发布|ScSAM: Debiasing Morphology and Distributional Variability in Subcellular Semantic Segmentation|ScSAM：在亚细胞语义分割中消除形态和分布变异带来的偏差|Bo Fang, Jianan Fan, Dongnan Liu, Hang Chang, Gerald J. Shami, Filip Braet, Weidong Cai|<http://arxiv.org/pdf/2507.17149v1>|提出ScSAM方法，融合预训练特征与细胞先验知识，减轻子细胞分割中的特征学习偏差。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Perspective-Invariant 3D Object Detection|视点不变的三维物体检测|Ao Liang, Lingdong Kong, Dongyue Lu, Youquan Liu, Jian Fang, Huaici Zhao, Wei Tsang Ooi|<http://arxiv.org/pdf/2507.17665v1>|提出首个多平台LiDAR数据集Pi3DET，并引入跨平台适应框架，实现视角不变的三维物体检测。|
|🆕 发布|Constructing Ophthalmic MLLM for Positioning-diagnosis Collaboration Through Clinical Cognitive Chain Reasoning|构建眼科多模态语言模型以实现定位-诊断协作的临床认知链推理|Xinyao Liu, Diping Song|<http://arxiv.org/pdf/2507.17539v1>|[代码](https://github.com/MeteorElf/FundusExpert.); 提出 FundusExpert，一种集成定位-诊断推理的专用眼科大语言模型，通过临床认知链提升跨模态...|
|📝 更新|RGBX-DiffusionDet: A Framework for Multi-Modal RGB-X Object Detection Using DiffusionDet|RGBX-DiffusionDet：一种基于DiffusionDet的多模态RGB-X目标检测框架|Eliraz Orfaig, Inna Stainvas, Igal Bilik|<http://arxiv.org/pdf/2505.02586v3>|提出了一种融合多模态数据的RGBX-DiffusionDet检测框架，通过自适应编码器和特色模块显著...|
|🆕 发布|Dynamic-DINO: Fine-Grained Mixture of Experts Tuning for Real-time Open-Vocabulary Object Detection|动态-DINO：实时开放词汇目标检测的细粒度专家混合调优|Yehao Lu, Minghe Weng, Zekang Xiao, Rui Jiang, Wei Su, Guangcong Zheng, Ping Lu, Xi Li|<http://arxiv.org/pdf/2507.17436v1>|提出了一种动态推理框架Dynamic-DINO，通过高效的MoE-Tuning策略和细粒度分解机制，...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Diffusion-Guided Knowledge Distillation for Weakly-Supervised Low-Light Semantic Segmentation|弱监督低光照语义分割的扩散引导知识蒸馏|Chunyan Wang, Dong Zhang, Jinhui Tang|<http://arxiv.org/pdf/2507.07578v2>|[代码](https://github.com/ChunyanWang1/DGKD-WLSS.); 提出了一种结合扩散引导知识蒸馏和深度引导特征融合的方法，有效提升了弱监督低光照语义分割的性能。|
|📝 更新|Rethinking Range-View LiDAR Segmentation in Adverse Weather|在恶劣天气下重新思考范围视图激光雷达分割|Longyu Yang, Lu Zhang, Jun Liu, Yap-Peng Tan, Heng Tao Shen, Xiaofeng Zhu, Ping Hu|<http://arxiv.org/pdf/2506.08979v2>|提出了一种改进的LiDAR segmentation框架，通过分离处理几何属性和反射强度，有效增强了...|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Swin-TUNA : A Novel PEFT Approach for Accurate Food Image Segmentation|Swin-TUNA：一种新颖的PEFT方法用于精确的食物图像分割|Haotian Chen, Zhiyong Xiao|<http://arxiv.org/pdf/2507.17347v2>|提出了一种高效的参数优化方法Swin-TUNA，通过仅调整4%的参数实现了高精度食品图像分割。|
|🆕 发布|PolarAnything: Diffusion-based Polarimetric Image Synthesis|《PolarAnything：基于扩散的偏振图像合成》|Kailong Zhang, Youwei Lyu, Heng Guo, Si Li, Zhanyu Ma, Boxin Shi|<http://arxiv.org/pdf/2507.17268v2>|提出了一种基于扩散模型的方法PolarAnything，能够从单张RGB图像生成高质量的极化图像，无...|
|🆕 发布|Hierarchical Diffusion Framework for Pseudo-Healthy Brain MRI Inpainting with Enhanced 3D Consistency|分层扩散框架用于增强三维一致性的伪健康脑部MRI图像修复|Dou Hoon Kwark, Shirui Luo, Xiyue Zhu, Yudu Li, Zhi-Pei Liang, Volodymyr Kindratenko|<http://arxiv.org/pdf/2507.17911v1>|[代码](https://github.com/dou0000/3dMRI-Consistent-Inpaint.); 提出了一种分级扩散框架，通过两个垂直的二维阶段实现高效的三维脑MRI修复，提高了图像逼真度和体积一致...|
|📝 更新|PALADIN : Robust Neural Fingerprinting for Text-to-Image Diffusion Models|PALADIN：用于文本到图像扩散模型的鲁棒神经指纹识别|Murthy L, Subarna Tripathi|<http://arxiv.org/pdf/2506.03170v2>|提出了一种利用循环纠错码原理的神经指纹技术，实现了对文本到图像生成模型的准确归因。|
|🆕 发布|Detail++: Training-Free Detail Enhancer for Text-to-Image Diffusion Models|《Detail++：无需训练的文本到图像扩散模型细节增强器》|Lifeng Chen, Jiner Wang, Zihao Pan, Beier Zhu, Xiaofeng Yang, Chi Zhang|<http://arxiv.org/pdf/2507.17853v1>|提出了一种无需训练的Detail++框架，通过分阶段细化生成过程，显著提升了多主体复杂场景的文本到图...|
|🆕 发布|CNS-Bench: Benchmarking Image Classifier Robustness Under Continuous Nuisance Shifts|CNS-Bench：在连续干扰变换下图像分类器鲁棒性的基准测试|Olaf Dünkel, Artur Jesslen, Jiahao Xie, Christian Theobalt, Christian Rupprecht, Adam Kortylewski|<http://arxiv.org/pdf/2507.17651v1>|[代码](https://genintel.github.io/CNS.); 提出CNS-Bench，通过连续性干扰生成量化图像分类器在真实世界干扰下的稳健性。|
|🆕 发布|Dual-branch Prompting for Multimodal Machine Translation|双分支提示在多模态机器翻译中的应用|Jie Wang, Zhendong Yang, Liansong Zong, Xiaobo Zhang, Dexian Wang, Ji Zhang|<http://arxiv.org/pdf/2507.17588v1>|提出D2P-MMT框架，通过重建图像和双分支提示策略提升多模态机器翻译的鲁棒性和实用性。|
|📝 更新|ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction|ORL-LDM：离线强化学习引导的潜在扩散模型超分辨率重建|Shijie Lyu|<http://arxiv.org/pdf/2505.10027v2>|提出了一种基于强化学习的潜在扩散模型微调方法，有效提升了遥感图像超分辨率重建的质量和适应性。|
|🆕 发布|Accelerating Parallel Diffusion Model Serving with Residual Compression|利用残差压缩加速并行扩散模型服务|Jiajun Luo, Yicheng Xiao, Jianru Xu, Yangxiu You, Rongwei Lu, Chen Tang, Jingyan Jiang, Zhi Wang|<http://arxiv.org/pdf/2507.17511v1>|[代码](https://github.com/Cobalt-27/CompactFusion); 提出了一种残差压缩框架CompactFusion，减少并行扩散模型推理中的通信开销，提高了生成质量和...|
|🆕 发布|Dynamic Scoring with Enhanced Semantics for Training-Free Human-Object Interaction Detection|动态评分结合增强语义的无训练人类-物体交互检测|Francesco Tonini, Lorenzo Vaquero, Alessandro Conti, Cigdem Beyan, Elisa Ricci|<http://arxiv.org/pdf/2507.17456v1>|[代码](https://github.com/francescotonini/dysco.); 提出了一种无需训练的动态评分框架DYSCO，利用视觉和文本交互表征提升对人类-物体交互的理解能力。|
|📝 更新|JEDI: The Force of Jensen-Shannon Divergence in Disentangling Diffusion Models|JEDI: 解耦扩散模型中的Jensen-Shannon散度之力|Eric Tillmann Bill, Enis Simsar, Thomas Hofmann|<http://arxiv.org/pdf/2505.19166v2>|[代码](https://ericbill21.github.io/JEDI); 提出JEDI方法，通过对抗优化和Jensen-Shannon散度减少扩散模型中的语义纠缠，无需重训练...|
|📝 更新|Visual-Language Model Knowledge Distillation Method for Image Quality Assessment|视觉语言模型知识蒸馏方法在图像质量评估中的应用|Yongkang Hou, Jiarun Song|<http://arxiv.org/pdf/2507.15680v3>|提出视觉语言模型知识蒸馏方法，以CLIP知识指导训练具有结构优势的模型，降低复杂度同时提升图像质量评...|
|📝 更新|SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models|SegQuant：面向扩散模型的可感知语义与通用量化框架|Jiaji Zhang, Ruichao Sun, Hailiang Zhao, Jiaju Wu, Peng Chen, Hao Li, Yuying Liu, Xinkui Zhao .etc.|<http://arxiv.org/pdf/2507.14811v2>|SegQuant提出了一种自适应的量化框架，通过结合结构语义和空间异质性，有效降低扩散模型的计算负担...|
|📝 更新|Latent Diffusion Models with Masked AutoEncoders|带有遮蔽自编码器的潜在扩散模型|Junho Lee, Jeongwoo Shin, Hyungwook Choi, Joonseok Lee|<http://arxiv.org/pdf/2507.09984v2>|提出新型Variational Masked AutoEncoders，优化了Latent Diff...|
|📝 更新|FE-UNet: Frequency Domain Enhanced U-Net for Low-Frequency Information-Rich Image Segmentation|频率域增强的U-Net：用于低频信息丰富图像分割的方法|Guohao Huo, Ruiting Dai, Ling Shao, Jinliang Liu, Hao Tang|<http://arxiv.org/pdf/2502.03829v2>|提出了一种增强低频信息提取的FE-UNet模型，有效应对光照和分辨率限制导致的特征衰减问题。|
|🆕 发布|Unsupervised Exposure Correction|无监督曝光校正|Ruodai Cui, Li Niu, Guosheng Hu|<http://arxiv.org/pdf/2507.17252v1>|[代码](https://github.com/BeyondHeaven/uec_code.); 提出了一种无需手动标注的_unsupervised_曝光校正方法，提高了泛化能力和低级视觉任务性能。|
|🆕 发布|UNICE: Training A Universal Image Contrast Enhancer|UNICE：训练一种通用图像对比度增强器|Ruodai Cui, Lei Zhang|<http://arxiv.org/pdf/2507.17157v1>|[代码](https://github.com/BeyondHeaven/UNICE.); 提出了一种无需人工标注、适用于多种对比度增强任务的通用模型UNICE，显著提升了图像增强的泛化性能。|
|📝 更新|Parasite: A Steganography-based Backdoor Attack Framework for Diffusion Models|寄生物：一种基于隐写术的用于扩散模型的后门攻击框架|Jiahao Chen, Yu Pan, Yi Du, Chunkai Wu, Lin Wang|<http://arxiv.org/pdf/2504.05815v2>|提出了一种利用隐写术隐藏触发器的图像到图像任务后门攻击方法“Parasite”，提高了攻击的隐蔽性和...|
|📝 更新|Gungnir: Exploiting Stylistic Features in Images for Backdoor Attacks on Diffusion Models|冈尼尔：利用图像风格特征对扩散模型进行后门攻击|Yu Pan, Jiahao Chen, Bingrong Dai, Lin Wang, Yi Du, Jiao Liu|<http://arxiv.org/pdf/2502.20650v4>|[代码](https://github.com/paoche11/Gungnir.); 提出利用图像风格特征作为触发器进行扩散模型的后门攻击新方法，有效绕过现有防御策略。|
|🆕 发布|SADA: Stability-guided Adaptive Diffusion Acceleration|稳定性引导的自适应扩散加速方法（SADA）|Ting Jiang, Yixiao Wang, Hancheng Ye, Zishan Shao, Jingwei Sun, Jingyang Zhang, Zekai Chen, Jianyi Zhang .etc.|<http://arxiv.org/pdf/2507.17135v1>|提出稳定性引导自适应扩散加速方法，大幅提升生成模型采样效率并保持高保真度。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PARTE: Part-Guided Texturing for 3D Human Reconstruction from a Single Image|PARTE：基于部分引导的三维人体重建的单图像纹理处理|Hyeongjin Nam, Donghwan Kim, Gyeongsik Moon, Kyoung Mu Lee|<http://arxiv.org/pdf/2507.17332v2>|[代码](https://hygenie1228.github.io/PARTE); 利用3D人体部位信息引导纹理重建，解决了单张图片3D人体重建中纹理错位问题。|
|🆕 发布|Benchmarking of Deep Learning Methods for Generic MRI Multi-OrganAbdominal Segmentation|深度学习技术在腹部多器官磁共振成像通用分割中的性能基准测试|Deepa Krishnaswamy, Cosmin Ciausu, Steve Pieper, Ron Kikinis, Benjamin Billot, Andrey Fedorov|<http://arxiv.org/pdf/2507.17971v1>|[代码](https://github.com/deepakri201/AbdoBench); 对比评估了三种先进MRI腹部分割模型，并引入了基于CT数据训练的替代模型ABDSynth。|
|🆕 发布|Yume: An Interactive World Generation Model|《Yume：一种交互式世界生成模型》|Xiaofeng Mao, Shaoheng Lin, Zhen Li, Chuanhao Li, Wenshuo Peng, Tong He, Jiangmiao Pang, Mingmin Chi .etc.|<http://arxiv.org/pdf/2507.17744v1>|[代码](https://github.com/stdstu12/YUME.); 提出了一种生成互动、真实、动态世界的模型Yume，通过键盘操作实现世界探索，并引入了创新的框架和算法...|
|📝 更新|Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step|我们能否用CoT生成图像？让我们逐步验证和加强图像生成过程|Ziyu Guo, Renrui Zhang, Chengzhuo Tong, Zhizheng Zhao, Rui Huang, Haoquan Zhang, Manyuan Zhang, Jiaming Liu .etc.|<http://arxiv.org/pdf/2501.13926v2>|[代码](https://github.com/ZiyuGuo99/Image-Generation-CoT); 探究了链式思维推理增强自回归图像生成的潜力，提出了自适应评估奖励模型，实现了性能显著提升。|
|🆕 发布|From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding|从扫描到行动：利用真实扫描数据进行具身场景理解|Anna-Maria Halacheva, Jan-Nico Zaech, Sombit Dey, Luc Van Gool, Danda Pani Paudel|<http://arxiv.org/pdf/2507.17585v1>|利用统一场景描述格式USD整合真实世界扫描数据，提升机器学习和机器人模拟的性能。|
|📝 更新|Text2Stereo: Repurposing Stable Diffusion for Stereo Generation with Consistency Rewards|《Text2Stereo：利用稳定性扩散进行立体生成并引入一致性奖励》|Aakash Garg, Libing Zeng, Andrii Tsarov, Nima Khademi Kalantari|<http://arxiv.org/pdf/2506.05367v2>|提出了一种利用预训练的Stable Diffusion模型并通过一致性奖励函数微调生成立体图像的新方...|
|📝 更新|Context Diffusion: In-Context Aware Image Generation|上下文扩散：上下文感知图像生成|Ivona Najdenkoska, Animesh Sinha, Abhimanyu Dubey, Dhruv Mahajan, Vignesh Ramanathan, Filip Radenovic|<http://arxiv.org/pdf/2312.03584v2>|提出Context Diffusion框架，通过分离视觉上下文编码和图像布局保持，实现了仅凭视觉上下...|
|🆕 发布|URPO: A Unified Reward & Policy Optimization Framework for Large Language Models|统一奖励与策略优化框架URPO用于大规模语言模型|Songshuo Lu, Hua Wang, Zhi Chen, Yaohua Tang|<http://arxiv.org/pdf/2507.17515v1>|提出了一种统一奖励与策略优化的框架，消除了独立奖励模型的需求，显著提升了大型语言模型的性能和效率。|
|🆕 发布|ERMV: Editing 4D Robotic Multi-view images to enhance embodied agents|ERMV：编辑四维机器人多视角图像以增强具身智能体|Chang Nie, Guangming Wang, Zhe Lie, Hesheng Wang|<http://arxiv.org/pdf/2507.17462v1>|提出ERMV框架，通过单帧编辑和机器人状态条件高效编辑4D多视图序列，增强视觉语言动作模型的鲁棒性和...|
|🆕 发布|A Conditional Probability Framework for Compositional Zero-shot Learning|条件概率框架下的组合零样本学习|Peng Wu, Qiuxia Lai, Hao Fang, Guo-Sen Xie, Yilong Yin, Xiankai Lu, Wenguan Wang|<http://arxiv.org/pdf/2507.17377v1>|提出了一种条件概率框架，通过建模属性与对象的依赖关系，有效提升组合零样本学习的泛化能力。|
|📝 更新|Qffusion: Controllable Portrait Video Editing via Quadrant-Grid Attention Learning|四分格注意力学习驱动的可控肖像视频编辑：Qffusion|Maomao Li, Lijian Lin, Yunfei Liu, Ye Zhu, Yu Li|<http://arxiv.org/pdf/2501.06438v2>|[代码](https://qffusion.github.io/page); 提出Qffusion框架，通过四象限网格注意力学习实现可控的人像视频编辑。|
|📝 更新|MoDA: Multi-modal Diffusion Architecture for Talking Head Generation|多模态扩散架构用于说话人头生成|Xinyang Li, Gen Li, Zhihui Lin, Yichen Qian, GongXin Yao, Weinan Jia, Aowen Wang, Weihua Chen .etc.|<http://arxiv.org/pdf/2507.03256v2>|[代码](https://lixinyyang.github.io/MoDA.github.io); 提出了一种多模态扩散架构MoDA，有效融合动作、音频等多模态信息，提升了虚拟说话人头部的生成质量和效...|
|🆕 发布|Vec2Face+ for Face Dataset Generation|面向人脸数据集生成的Vec2Face+方法|Haiyu Wu, Jaskirat Singh, Sicong Tian, Liang Zheng, Kevin W. Bowyer|<http://arxiv.org/pdf/2507.17192v1>|提出了一种生成模型Vec2Face+，通过控制身份和属性一致性生成高质量人脸数据集。|
|🆕 发布|DOOMGAN:High-Fidelity Dynamic Identity Obfuscation Ocular Generative Morphing|DOOMGAN：高保真动态身份混淆眼动生成形变|Bharath Krishnamurthy, Ajita Rattani|<http://arxiv.org/pdf/2507.17158v1>|提出DOOMGAN方法，通过编码眼部特征和注意力引导生成，有效应对可见光光谱眼部生物识别的合成攻击问...|
|📝 更新|EarthCrafter: Scalable 3D Earth Generation via Dual-Sparse Latent Diffusion|地球工匠：通过双稀疏潜在扩散实现可扩展的3D地球生成|Shang Liu, Chenjie Cao, Chaohui Yu, Wen Qian, Jing Wang, Fan Wang|<http://arxiv.org/pdf/2507.16535v2>|[代码](https://whiteinblue.github.io/earthcrafter); 提出了一种针对大规模地球表面生成的框架 EarthCrafter，通过分离结构和纹理生成，大幅降低了...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Zero-Shot Dynamic Concept Personalization with Grid-Based LoRA|基于网格的LoRA实现的零样本动态概念个性化|Rameen Abdal, Or Patashnik, Ekaterina Deyneka, Hao Chen, Aliaksandr Siarohin, Sergey Tulyakov, Daniel Cohen-Or, Kfir Aberman|<http://arxiv.org/pdf/2507.17963v1>|提出了一种无需逐个微调的零样本动态概念个性化框架，通过结构化视频网格和轻量级Grid-LoRA适配器...|
|🆕 发布|Improving Multislice Electron Ptychography with a Generative Prior|利用生成先验改进多切片电子衍射术|Christian K. Belardi, Chia-Hao Lee, Yingheng Wang, Justin Lovelace, Kilian Q. Weinberger, David A. Muller, Carla P. Gomes|<http://arxiv.org/pdf/2507.17800v1>|提出了一种结合生成先验的扩散模型MEP-Diffusion，显著提高了电子衍射成像的重建质量。|
|🆕 发布|An h-space Based Adversarial Attack for Protection Against Few-shot Personalization|基于h空间的对抗攻击方法以防御少量样本个性化|Xide Xu, Sandesh Kamath, Muhammad Atif Butt, Bogdan Raducanu|<http://arxiv.org/pdf/2507.17554v1>|提出HAAD方法，通过h空间生成扰动，有效防御少量样本个性化攻击。|
|📝 更新|Fractal Signatures: Securing AI-Generated Pollock-Style Art via Intrinsic Watermarking and Blockchain|分形签名：通过内在水印和区块链保护AI生成的波洛克风格艺术作品|Yiquan Wang|<http://arxiv.org/pdf/2410.20519v4>|提出了一种结合神经风格迁移、分形分析和区块链技术的框架，通过在艺术作品中嵌入不可见的水印来确保数字艺...|
|🆕 发布|VBCD: A Voxel-Based Framework for Personalized Dental Crown Design|基于体素的三维个性化牙冠设计框架|Linda Wei, Chang Liu, Wenran Zhang, Zengji Zhang, Shaoting Zhang, Hongsheng Li|<http://arxiv.org/pdf/2507.17205v1>|提出了一种基于体素框架的自动化个性化牙冠设计方法，提高了牙冠设计的效率和准确性。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Ultra3D: Efficient and High-Fidelity 3D Generation with Part Attention|Ultra3D：基于部分注意力的高效高保真三维生成|Yiwen Chen, Zhihao Li, Yikai Wang, Hu Zhang, Qin Li, Chi Zhang, Guosheng Lin|<http://arxiv.org/pdf/2507.17745v1>|提出Ultra3D框架，通过部分注意力机制提升3D生成效率，保持高分辨率质量。|
|📝 更新|PoemTale Diffusion: Minimising Information Loss in Poem to Image Generation with Multi-Stage Prompt Refinement|《PoemTale扩散：通过多阶段提示精炼最小化诗歌到图像生成中的信息损失》|Sofia Jamil, Bollampalli Areen Reddy, Raghvendra Kumar, Sriparna Saha, Koustava Goswami, K. J. Joseph|<http://arxiv.org/pdf/2507.13708v2>|提出了一种多阶段提示精炼方法PoemTale Diffusion，减少诗歌转图像过程中的信息损失，增...|
|📝 更新|Human-Activity AGV Quality Assessment: A Benchmark Dataset and an Objective Evaluation Metric|人类活动自动导引车质量评估：一个基准数据集和一个客观评价指标|Zhichao Zhang, Wei Sun, Xinyue Li, Yunhao Li, Qihang Ge, Jun Jia, Zicheng Zhang, Zhongpeng Ji .etc.|<http://arxiv.org/pdf/2411.16619v3>|[代码](https://github.com/zczhang-sjtu/GHVQ.git.); 提出人类活动AI视频质量评估基准数据集和客观评价指标，提升AI生成视频质量检测准确性。|
|📝 更新|UniCUE: Unified Recognition and Generation Framework for Chinese Cued Speech Video-to-Speech Generation|统一识别与生成框架：面向汉语提示言语视频到语音生成的UniCUE|Jinting Wang, Shan Yang, Li Liu|<http://arxiv.org/pdf/2506.04134v2>|提出了一种不依赖文本中介的直接从中文手势语视频生成语音的统一框架UniCUE，实现了视觉特征与语音内...|
|🆕 发布|Perceptual Classifiers: Detecting Generative Images using Perceptual Features|感知分类器：利用感知特征检测生成图像|Krishna Srikar Durbha, Asvin Kumar Venkataramanan, Rajesh Sureddi, Alan C. Bovik|<http://arxiv.org/pdf/2507.17240v1>|利用图像质量评估模型特征，提出了一种检测生成图像的新方法，实现了检测生成图像的最佳性能并保持了抗图像...|
|🆕 发布|Hierarchical Fusion and Joint Aggregation: A Multi-Level Feature Representation Method for AIGC Image Quality Assessment|层次化融合与联合聚合：面向AIGC图像质量评估的多级特征表示方法|Linghe Meng, Jiarun Song|<http://arxiv.org/pdf/2507.17182v1>|提出多级视觉表征方法，融合全局与局部特征，提升AI生成内容图像质量评估效果。|
|📝 更新|Rethinking Cross-Modal Interaction in Multimodal Diffusion Transformers|重新思考多模态扩散变换器中的跨模态交互|Zhengyao Lv, Tianlin Pan, Chenyang Si, Zhaoxi Chen, Wangmeng Zuo, Ziwei Liu, Kwan-Yee K. Wong|<http://arxiv.org/pdf/2506.07986v3>|[代码](https://github.com/Vchitect/TACA); 提出温度调整的跨模态注意力机制，有效改善文本和图像的对齐精度。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 单视图三维推理 (Single-view 3D Inference)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Monocular Semantic Scene Completion via Masked Recurrent Networks|通过遮蔽循环网络实现的单目语义场景补全|Xuzhi Wang, Xinran Wu, Song Wang, Lingdong Kong, Ziping Zhao|<http://arxiv.org/pdf/2507.17661v1>|提出了一种两阶段框架，通过Masked Sparse Gated Recurrent Unit和距离...|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RemixFusion: Residual-based Mixed Representation for Large-scale Online RGB-D Reconstruction|混合残差表示：面向大规模在线RGB-D重建的融合方法|Yuqing Lan, Chenyang Zhu, Shuaifeng Zhi, Jiazhao Zhang, Zhoufeng Wang, Renjiao Yi, Yijie Wang, Kai Xu|<http://arxiv.org/pdf/2507.17594v1>|提出混合残差映射方法RemixFusion，结合显式TSDF网格与隐式神经模块，实现高质量大规模RG...|
|🆕 发布|Exploring Active Learning for Label-Efficient Training of Semantic Neural Radiance Field|探索主动学习在语义神经辐射场高效训练标签中的应用|Yuzhe Zhu, Lile Cai, Kangkang Lu, Fayao Liu, Xulei Yang|<http://arxiv.org/pdf/2507.17351v1>|提出利用主动学习策略减少语义神经辐射场训练中的标注成本，实现了标注效率超过两倍提升。|
|📝 更新|NVS-SQA: Exploring Self-Supervised Quality Representation Learning for Neurally Synthesized Scenes without References|NVS-SQA：无参考神经合成场景中的自监督质量表征学习探索|Qiang Qu, Yiran Shen, Xiaoming Chen, Yuk Ying Chung, Weidong Cai, Tongliang Liu|<http://arxiv.org/pdf/2501.06488v2>|提出无参考神经合成场景质量评估方法NVS-SQA，通过自监督学习无需人类标注实现质量表征。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TransLPRNet: Lite Vision-Language Network for Single/Dual-line Chinese License Plate Recognition|《TransLPRNet：面向单/双行中文车牌识别的轻量级视觉-语言网络》|Guangzhu Xu, Zhi Ke, Pengcheng Zuo, Bangjun Lei|<http://arxiv.org/pdf/2507.17335v1>|提出了一种轻量级视觉编码器与文本解码器结合的统一解决方案，提高了单双行中文车牌识别的准确性和速度。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Deep Video Discovery: Agentic Search with Tool Use for Long-form Video Understanding|深度视频发现：利用工具的代理搜索进行长视频理解|Xiaoyi Zhang, Zhaoyang Jia, Zongyu Guo, Jiahao Li, Bin Li, Houqiang Li, Yan Lu|<http://arxiv.org/pdf/2505.18079v3>|[代码](https://github.com/microsoft/DeepVideoDiscovery.); 提出了一种自主搜索策略的Deep Video Discovery方法，用于理解和分析长视频内容，实现...|
|📝 更新|Infinite Video Understanding|无限视频理解|Dell Zhang, Xiangyu Chen, Jixiang Luo, Mengxi Jia, Changzhi Sun, Ruilong Ren, Jingren Liu, Hao Sun .etc.|<http://arxiv.org/pdf/2507.09068v2>|提出无限视频理解概念，旨在连续处理任意时长视频数据，推动多媒体和AI研究创新。|
|🆕 发布|HLFormer: Enhancing Partially Relevant Video Retrieval with Hyperbolic Learning|HLFormer：利用双曲学习增强部分相关视频检索|Li Jun, Wang Jinpeng, Tan Chaolei, Lian Niu, Chen Long, Zhang Min, Wang Yaowei, Xia Shu-Tao .etc.|<http://arxiv.org/pdf/2507.17402v1>|[代码](https://github.com/lijun2005/ICCV25-HLFormer.); 提出首个用于部分相关视频检索的伪黎曼几何模型HLFormer，通过混合空间编码和交互模块提升检索性能...|
|🆕 发布|HiProbe-VAD: Video Anomaly Detection via Hidden States Probing in Tuning-Free Multimodal LLMs|HiProbe-VAD：通过在免调多模态大语言模型中探测隐藏状态进行视频异常检测|Zhaolin Cai, Fan Li, Ziwei Zheng, Yanjun Qin|<http://arxiv.org/pdf/2507.17394v1>|提出HiProbe-VAD框架，利用无需微调的多模态大语言模型进行视频异常检测，通过探测隐藏状态提升...|
|📝 更新|AuroraLong: Bringing RNNs Back to Efficient Open-Ended Video Understanding|极光长时：将循环神经网络重新带回高效开放式视频理解|Weili Xu, Enxin Song, Wenhao Chai, Xuexiang Wen, Tian Ye, Gaoang Wang|<http://arxiv.org/pdf/2507.02591v3>|提出线性RNN模型AuroraLong，解决长视频理解的高计算复杂度和内存成本问题，实现高效开放端视...|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MCM: Mamba-based Cardiac Motion Tracking using Sequential Images in MRI|基于Mamba的心脏运动跟踪：利用MRI序列图像的MCM方法|Jiahui Yin, Xinxing Cheng, Jinming Duan, Yan Pang, Declan O'Regan, Hadrien Reynaud, Qingjie Meng|<http://arxiv.org/pdf/2507.17678v1>|[代码](https://github.com/yjh-0104/MCM.); 提出了一种基于序列MRI图像的Mamba网络，实现了平滑且时间一致的心肌运动跟踪。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Prompt Guidance and Human Proximal Perception for HOT Prediction with Regional Joint Loss|基于提示引导与人类近似感知的HOT预测：区域联合损失方法|Yuxiao Wang, Yu Lei, Zhenao Wei, Weiying Xue, Xinyu Jiang, Nan Zhuang, Qi Liu|<http://arxiv.org/pdf/2507.01630v2>|[代码](https://github.com/YuxiaoWang-AI/P3HOT.); 提出P3HOT框架，融合文本驱动的提示指导和人类近似感知机制，有效提升HOT检测准确性和抑制异常类别...|
|📝 更新|BadHMP: Backdoor Attack against Human Motion Prediction|人体运动预测的的后门攻击：BadHMP|Chaohui Xu, Si Wang, Chip-Hong Chang|<http://arxiv.org/pdf/2409.19638v2>|提出了一种针对人体运动预测任务的隐蔽后门攻击方法BadHMP，通过在训练样本中嵌入触发器实现特定关节...|
|🆕 发布|IONext: Unlocking the Next Era of Inertial Odometry|IONext：解锁惯性里程计的新时代|Shanshan Zhang, Siyue Wang, Tianshui Wen, Qi Zhang, Ziheng Zhou, Lingxiang Zheng, Yu Yang|<http://arxiv.org/pdf/2507.17089v1>|提出了一种新的CNN模块，有效融合全局运动模式与局部细节，提升了惯性导航的定位精度和泛化能力。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-modal Multi-task Pre-training for Improved Point Cloud Understanding|多模态多任务预训练以提升点云理解能力|Liwen Liu, Weidong Yang, Lipeng Ma, Ben Fei|<http://arxiv.org/pdf/2507.17533v1>|提出多模态多任务预训练框架MMPT，通过三种任务增强点云理解能力，无需3D标注即可提升下游任务表现。|
|🆕 发布|MaskedCLIP: Bridging the Masked and CLIP Space for Semi-Supervised Medical Vision-Language Pre-training|《MaskedCLIP：连接遮蔽空间与CLIP空间，用于半监督医疗视觉-语言预训练》|Lei Zhu, Jun Zhou, Rick Siow Mong Goh, Yong Liu|<http://arxiv.org/pdf/2507.17239v1>|提出了一种结合遮蔽图像建模和对比语言图像预训练的半监督视觉语言预训练框架，有效融合配对和非配对图像数...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DiNAT-IR: Exploring Dilated Neighborhood Attention for High-Quality Image Restoration|探索扩张邻域注意力以实现高质量图像恢复的DiNAT-IR方法|Hanzhou Liu, Binghan Li, Chengkai Liu, Mi Lu|<http://arxiv.org/pdf/2507.17892v1>|提出了一种结合 Dilated Neighborhood Attention 和通道感知模块的 Di...|
|🆕 发布|DFDNet: Dynamic Frequency-Guided De-Flare Network|动态频率引导去眩光网络|Minglong Xue, Aoxiang Ning, Shivakumara Palaiahnakote, Mingliang Zhou|<http://arxiv.org/pdf/2507.17489v1>|[代码](https://github.com/AXNing/DFDNet); 提出了一种动态频率引导的去眩光网络，有效分离并去除夜间摄影中的大规模眩光 artifacts。|
|🆕 发布|Learning-based Stage Verification System in Manual Assembly Scenarios|基于学习的手动装配场景中的阶段验证系统|Xingjian Zhang, Yutong Duan, Zaishu Chen|<http://arxiv.org/pdf/2507.17304v1>|提出了一种基于机器学习的装配阶段验证系统，通过少量视觉传感器实现精确监控，提高装配效率并降低成本。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Reusing Attention for One-stage Lane Topology Understanding|重用注意力机制进行一阶段车道拓扑理解|Yang Li, Zongzheng Zhang, Xuchong Qiu, Xinrun Li, Ziming Liu, Leichen Wang, Ruikai Li, Zhenxin Zhu .etc.|<http://arxiv.org/pdf/2507.17617v1>|[代码](https://github.com/Yang-Li-2000/one-stage.git.); 提出一种一阶段架构，通过重用注意力资源提高自动驾驶中车道拓扑理解的准确性和速度。|
|🆕 发布|The Early Bird Identifies the Worm: You Can't Beat a Head Start in Long-Term Body Re-ID (ECHO-BID)|“先发制人：在长期人体重识别中先行一步的优势（ECHO-BID）”|Thomas M. Metz, Matthew Q. Hill, Alice J. O'Toole|<http://arxiv.org/pdf/2507.17640v1>|提出ECHO-BID模型，通过特定预训练和迁移学习，在长期人体重识别上取得领先性能。|
|📝 更新|InceptionMamba: An Efficient Hybrid Network with Large Band Convolution and Bottleneck Mamba|“_inceptionMamba：一种具有大带宽卷积和瓶颈Mamba的高效混合网络_”|Yuhang Wang, Jun Li, Zhijian Wu, Jifeng Shen, Jianhua Xu, Wankou Yang|<http://arxiv.org/pdf/2506.08735v3>|[代码](https://github.com/Wake1021/InceptionMamba.); 提出InceptionMamba架构，通过正交带卷积和瓶颈Mamba模块提升空间建模和全局上下文建模...|
|🆕 发布|PointLAMA: Latent Attention meets Mamba for Efficient Point Cloud Pretraining|点云预训练中的潜在注意力与Mamba结合：PointLAMA高效实现|Xuanyu Lin, Xiaona Zeng, Xianwei Zheng, Xutao Li|<http://arxiv.org/pdf/2507.17296v1>|PointLAMA通过结合局部注意力与Mamba模型，有效提升点云数据的精细结构捕捉能力。|
|📝 更新|APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation|APTx神经元：一种集激活与计算于一体的统一可训练神经元架构|Ravin Kumar|<http://arxiv.org/pdf/2507.14270v2>|提出了一种统一可训练的神经元架构APTx Neuron，整合了非线性激活和线性变换，提升了表达能力和...|
|🆕 发布|Robust Five-Class and binary Diabetic Retinopathy Classification Using Transfer Learning and Data Augmentation|使用迁移学习和数据增强的稳健五类及二分类糖尿病视网膜病变识别|Faisal Ahmed, Mohammad Alfrad Nobel Bhuiyan|<http://arxiv.org/pdf/2507.17121v1>|提出了一种结合迁移学习和数据增强的深度学习框架，有效提升了糖尿病视网膜病变自动诊断的准确性和鲁棒性。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|InvRGB+L: Inverse Rendering of Complex Scenes with Unified Color and LiDAR Reflectance Modeling|_invRGB+L:逆向渲染复杂场景的统一颜色与激光雷达反射率建模_|Xiaoxue Chen, Bhargav Chandaka, Chih-Hao Lin, Ya-Qin Zhang, David Forsyth, Hao Zhao, Shenlong Wang|<http://arxiv.org/pdf/2507.17613v1>|提出了一种结合RGB和LiDAR反射率建模的逆向渲染方法，有效提高了复杂场景的材料估计准确性。|
|🆕 发布|STQE: Spatial-Temporal Quality Enhancement for G-PCC Compressed Dynamic Point Clouds|STQE：用于G-PCC压缩动态点云的时空质量增强|Tian Guo, Hui Yuan, Xiaolong Mao, Shiqi Jiang, Raouf Hamzaoui, Sam Kwong|<http://arxiv.org/pdf/2507.17522v1>|提出了一种利用时空相关性的STQE网络，有效提升了G-PCC压缩动态点云的视觉质量。|
|📝 更新|Mapping of Weed Management Methods in Orchards using Sentinel-2 and PlanetScope Data|果园杂草管理方法映射研究：基于Sentinel-2和PlanetScope数据|Ioannis Kontogiorgakis, Iason Tsardanidis, Dimitrios Bormpoudakis, Ilias Tsoumas, Dimitra A. Loka, Christos Noulas, Alexandros Tsitouras, Charalampos Kontoes|<http://arxiv.org/pdf/2504.19991v2>|利用卫星数据和机器学习，实现了果园杂草管理方法的精准映射。|
|📝 更新|MolX: Enhancing Large Language Models for Molecular Understanding With A Multi-Modal Extension|MolX：通过多模态扩展增强大型语言模型对分子的理解能力|Khiem Le, Zhichun Guo, Kaiwen Dong, Xiaobao Huang, Bozhao Nan, Roshni Iyer, Xiangliang Zhang, Olaf Wiest .etc.|<http://arxiv.org/pdf/2406.06777v8>|提出多模态扩展MolX，增强大型语言模型对分子的理解能力，提升化学领域任务表现。|
|🆕 发布|CasP: Improving Semi-Dense Feature Matching Pipeline Leveraging Cascaded Correspondence Priors for Guidance|级联对应先验引导的半稠密特征匹配流程改进：CasP|Peiqi Chen, Lei Yu, Yi Wan, Yingying Pei, Xinyi Liu, Yongxiang Yao, Yingying Zhang, Lixiang Ru .etc.|<http://arxiv.org/pdf/2507.17312v1>|[代码](https://github.com/pq-chen/CasP.); 提出CasP方法，通过级联对应先验指导分解匹配阶段，提升半稠密特征匹配的准确性和效率。|
|📝 更新|SpiLiFormer: Enhancing Spiking Transformers with Lateral Inhibition|SpiLiFormer：利用侧抑制增强脉冲Transformer|Zeqi Zheng, Yanchen Huang, Yingchao Yu, Zizheng Zhu, Junfeng Tang, Zhaofei Yu, Yaochu Jin|<http://arxiv.org/pdf/2503.15986v2>|[代码](https://github.com/KirinZheng/SpiLiFormer.); 提出SpiLiFormer模型，通过模拟大脑侧抑制机制优化 spike-based Transfor...|
|🆕 发布|Dataset Distillation as Data Compression: A Rate-Utility Perspective|数据集蒸馏作为数据压缩：速率-效用视角|Youneng Bao, Yiping Liu, Zhuo Chen, Yongsheng Liang, Mu Li, Kede Ma|<http://arxiv.org/pdf/2507.17221v1>|提出了一种数据压缩方法，通过优化数据集压缩率和效用，实现了高效率的存储与性能平衡。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation|指令VLA：从理解到操作的视觉-语言-动作指令微调|Shuai Yang, Hao Li, Yilun Chen, Bin Wang, Yang Tian, Tai Wang, Hanqing Wang, Feng Zhao .etc.|<http://arxiv.org/pdf/2507.17520v1>|提出InstructVLA模型，通过指令微调实现视觉语言模型与动作生成的有效结合，提升机器人操作性能...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CA-Cut: Crop-Aligned Cutout for Data Augmentation to Learn More Robust Under-Canopy Navigation|CA-Cut：针对学习更稳健的树荫下导航的数据增强的裁剪对齐切割法|Robel Mamo, Taeyeong Choi|<http://arxiv.org/pdf/2507.17727v2>|提出了一种针对作物下方导航的 Crop-Aligned Cutout 数据增强方法，通过在作物行附近...|
|🆕 发布|On the Interaction of Compressibility and Adversarial Robustness|论压缩性与对抗性鲁棒性之间的相互作用|Melih Barsbey, Antônio H. Ribeiro, Umut Şimşekli, Tolga Birdal|<http://arxiv.org/pdf/2507.17725v1>|揭示了压缩性与对抗稳健性之间的相互作用，提出了分析压缩性如何影响对抗稳健性的框架。|
|🆕 发布|Boosting Ray Search Procedure of Hard-label Attacks with Transfer-based Priors|基于迁移先验的硬标签攻击射线搜索过程增强|Chen Ma, Xinjie Xu, Shuyu Cheng, Qi Xuan|<http://arxiv.org/pdf/2507.17577v1>|利用迁移先验提升硬标签攻击中射线搜索效率，减少查询次数。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VIBE: Video-Input Brain Encoder for fMRI Response Modeling|VIBE：基于视频输入的脑编码器用于fMRI响应建模|Daniel Carlstrom Schad, Shrey Dixit, Janis Keck, Viktor Studenyak, Aleksandr Shpilevoi, Andrej Bicanski|<http://arxiv.org/pdf/2507.17958v1>|提出VIBE模型，融合视频、音频和文本多模态特征预测fMRI活动，提升预测相关性。|
|📝 更新|Flexible Coded Distributed Convolution Computing for Enhanced Straggler Resilience and Numerical Stability in Distributed CNNs|分布式卷积神经网络中增强弱者容忍性和数值稳定性的灵活编码分布式卷积计算|Shuo Tan, Rui Liu, Xuesong Han, XianLei Long, Kai Wan, Linqi Song, Yong Li|<http://arxiv.org/pdf/2411.01579v2>|提出了一种增强分布式卷积神经网络计算效率与稳定性的编码分布式卷积计算框架。|


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Unsupervised Feature Disentanglement and Augmentation Network for One-class Face Anti-spoofing|无监督特征解耦与增强网络用于单类人脸防伪|Pei-Kai Huang, Jun-Xiong Chong, Ming-Tsung Hsu, Fang-Yu Hsu, Yi-Ting Lin, Kai-Heng Chien, Hao-Chiang Shao, Chiou-Ting Hsu|<http://arxiv.org/pdf/2503.22929v2>|提出了一种用于单类活体人脸检测的UFDANet，通过解耦特征增强泛化能力，有效应对未见攻击。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OPEN: A Benchmark Dataset and Baseline for Older Adult Patient Engagement Recognition in Virtual Rehabilitation Learning Environments|开放：虚拟康复学习环境中老年人患者参与度识别的基准数据集和基线|Ali Abedi, Sadaf Safa, Tracey J. F. Colella, Shehroz S. Khan|<http://arxiv.org/pdf/2507.17959v1>|提出面向老年患者虚拟康复学习环境的 Engagement 识别基准数据集 OPEN，通过 AI 模型...|
|🆕 发布|Integrating Feature Selection and Machine Learning for Nitrogen Assessment in Grapevine Leaves using In-Field Hyperspectral Imaging|利用现场高光谱成像技术集成特征选择与机器学习对葡萄叶氮含量进行评估|Atif Bilal Asad, Achyut Paudel, Safal Kshetri, Chenchen Kang, Salik Ram Khanal, Nataliya Shcherbatyuk, Pierre Davadant, R. Paul Schreiner .etc.|<http://arxiv.org/pdf/2507.17869v1>|提出了一种结合特征选择和机器学习的方法，利用现场高光谱图像准确预测葡萄叶片氮含量。|
|📝 更新|Choosing Public Datasets for Private Machine Learning via Gradient Subspace Distance|通过梯度子空间距离选择私有机器学习的公共数据集|Xin Gu, Gautam Kamath, Zhiwei Steven Wu|<http://arxiv.org/pdf/2303.01256v2>|提出了一种选择公共数据集以降低私有权重机器学习噪声的方法，通过测量梯度子空间距离来优化数据集选择。|
|🆕 发布|Large Learning Rates Simultaneously Achieve Robustness to Spurious Correlations and Compressibility|大学习率同时实现对抗伪相关性的鲁棒性和可压缩性|Melih Barsbey, Lucas Prieto, Stefanos Zafeiriou, Tolga Birdal|<http://arxiv.org/pdf/2507.17748v1>|揭示了高学习率可同时实现模型对伪相关性的鲁棒性和网络压缩性，优于其他超参数和正则化方法。|
|🆕 发布|Joint Asymmetric Loss for Learning with Noisy Labels|联合非对称损失学习算法用于带噪声标签的学习|Jialiang Wang, Xianming Liu, Xiong Zhou, Gangfeng Hu, Deming Zhai, Junjun Jiang, Xiangyang Ji|<http://arxiv.org/pdf/2507.17692v1>|[代码](https://github.com/cswjl/joint-asymmetric-loss); 提出了一种新型不对称损失函数Asymetric Mean Square Error，通过结合主动和被...|
|🆕 发布|Audio-Vision Contrastive Learning for Phonological Class Recognition|音视觉对比学习在音韵类别识别中的应用|Daiqi Liu, Tomás Arias-Vergara, Jana Hutter, Andreas Maier, Paula Andrea Pérez-Toro|<http://arxiv.org/pdf/2507.17682v1>|[代码](https://github.com/DaE-plz/AC_Contrastive_Phonology); 提出了一种结合实时磁共振成像与语音信号的多模态对比学习框架，用于准确分类语音发音特征，实现了优于单模...|
|📝 更新|Improving the Reasoning of Multi-Image Grounding in MLLMs via Reinforcement Learning|通过强化学习提升多图像基础推理在多模态语言模型中的性能|Bob Zhang, Haoran Li, Tao Zhang, Cilin Yan, Jiayin Cai, Yanbin Hao|<http://arxiv.org/pdf/2507.00748v2>|采用强化学习后训练策略，提升多模态大语言模型在多图像场景下的推理能力。|
|🆕 发布|Exploring Spatial Diversity for Region-based Active Learning|探索基于区域主动学习的空间多样性|Lile Cai, Xun Xu, Lining Zhang, Chuan-Sheng Foo|<http://arxiv.org/pdf/2507.17367v1>|提出利用区域基于的空间多样性强化策略，有效降低语义分割标注成本同时保持高性能。|
|🆕 发布|Exploring Active Learning for Semiconductor Defect Segmentation|探索主动学习在半导体缺陷分割中的应用|Lile Cai, Ramanpreet Singh Pahwa, Xun Xu, Jie Wang, Richard Chang, Lining Zhang, Chuan-Sheng Foo|<http://arxiv.org/pdf/2507.17359v1>|提出利用主动学习策略减轻半导体缺陷分割标注负担，通过对比预训练和关注稀有类别的采样函数提升性能。|
|🆕 发布|FedVLM: Scalable Personalized Vision-Language Models through Federated Learning|联邦视觉语言模型：通过联邦学习实现可扩展的个性化视觉语言模型|Arkajyoti Mitra, Afia Anjum, Paul Agbaje, Mert Pesé, Habeeb Olufowobi|<http://arxiv.org/pdf/2507.17088v1>|提出FedVLM框架，通过个性化LoRA优化联邦学习环境下视觉语言模型的适应性。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Attention (as Discrete-Time Markov) Chains|注意力（作为离散时间马尔可夫）链|Yotam Erel, Olaf Dünkel, Rishabh Dabral, Vladislav Golyanik, Christian Theobalt, Amit H. Bermano|<http://arxiv.org/pdf/2507.17657v1>|将注意力矩阵重新解释为离散时间马尔可夫链，为图像分割和生成任务提供了新的视角和改进效果。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Cross-domain Multi-step Thinking: Zero-shot Fine-grained Traffic Sign Recognition in the Wild|跨域多步骤思考：野外零样本细粒度交通标志识别|Yaozong Gan, Guang Li, Ren Togo, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama|<http://arxiv.org/pdf/2409.01534v2>|提出Cross-domain Multi-step Thinking方法，通过多步骤推理提升野外零样...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding|《PerceptionLM：用于详细视觉理解的开放获取数据与模型》|Jang Hyun Cho, Andrea Madotto, Effrosyni Mavroudi, Triantafyllos Afouras, Tushar Nagarajan, Muhammad Maaz, Yale Song, Tengyu Ma .etc.|<http://arxiv.org/pdf/2504.13180v3>|[代码](https://github.com/facebookresearch/perception_models); 提出全开放框架的PerceptionLM模型，通过大规模数据集和视频理解评测套件推动视觉理解研究的透...|
|🆕 发布|See the Forest and the Trees: A Synergistic Reasoning Framework for Knowledge-Based Visual Question Answering|看到森林与树木：基于知识的视觉问答协同推理框架|Junjie Wang, Yunhan Tang, Yijie Wang, Zhihao Yuan, Huan Wang, Yangfan He, Bin Li|<http://arxiv.org/pdf/2507.17659v1>|提出协同推理框架Synergos-VQA，通过融合全局、结构和因果证据，提升知识驱动视觉问答的推理全...|
|🆕 发布|Probing Vision-Language Understanding through the Visual Entailment Task: promises and pitfalls|通过视觉推理任务探究视觉-语言理解：机遇与挑战|Elena Pitta, Tom Kouwenhoven, Tessa Verhoef|<http://arxiv.org/pdf/2507.17467v1>|探究视觉推论任务在多模态语言模型中的效果，发现模型易受语言先验影响且视觉信息对性能至关重要。|
|🆕 发布|VisionTrap: Unanswerable Questions On Visual Data|视觉陷阱：关于视觉数据无法回答的问题|Asir Saadat, Syem Aziz, Shahriar Mahmud, Abdullah Ibne Masud Mahi, Sabbir Ahmed|<http://arxiv.org/pdf/2507.17262v1>|探究视觉问答模型面对无法回答问题的处理能力，并提出 VisionTrap 数据集以评估模型的知识局限...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VLM-Guided Visual Place Recognition for Planet-Scale Geo-Localization|面向星球级地理定位的VLM引导视觉位置识别|Sania Waheed, Na Min An, Michael Milford, Sarvapali D. Ramchurn, Shoaib Ehsan|<http://arxiv.org/pdf/2507.17455v1>|提出了一种结合视觉语言模型和视觉位置识别的地理定位框架，大幅提升了定位准确性和鲁棒性。|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LEGO Co-builder: Exploring Fine-Grained Vision-Language Modeling for Multimodal LEGO Assembly Assistants|乐高共建者：探索细粒度视觉-语言建模以实现多模态乐高组装助手|Haochen Huang, Jiahuan Pei, Mohammad Aliannejadi, Xin Sun, Moonisa Ahsan, Chuang Yu, Zhaochun Ren, Pablo Cesar .etc.|<http://arxiv.org/pdf/2507.05515v2>|提出LEGO Co-builder，一种结合现实乐高组装逻辑与多模态场景的统一框架，评估了先进VLM...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PRIX: Learning to Plan from Raw Pixels for End-to-End Autonomous Driving|PRIX：从原始像素学习规划以实现端到端自动驾驶|Maciej K. Wozniak, Lianhang Liu, Yixi Cai, Patric Jensfelt|<http://arxiv.org/pdf/2507.17596v2>|[代码](https://maxiuw.github.io/prix.); 提出PRIX模型，仅用摄像头数据实现高效端到端驾驶规划，无需LiDAR和BEV表示。|
|🆕 发布|SRMambaV2: Biomimetic Attention for Sparse Point Cloud Upsampling in Autonomous Driving|SRMambaV2：仿生注意力用于自动驾驶中的稀疏点云上采样|Chuang Chen, Xiaolin Qin, Jing Hu, Wenyi Ge|<http://arxiv.org/pdf/2507.17479v1>|提出了一种仿生注意力机制，用于提升自动驾驶场景中稀疏激光雷达点云的上采样精度和几何重建质量。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ODES: Domain Adaptation with Expert Guidance for Online Medical Image Segmentation|在线医疗图像分割中的专家指导域自适应：ODES|Md Shazid Islam, Sayak Nag, Arindam Dutta, Miraj Ahmed, Fahim Faisal Niloy, Amit K. Roy-Chowdhury|<http://arxiv.org/pdf/2312.05407v3>|提出利用专家指导的域自适应方法ODES，通过主动学习优化在线医疗图像分割的准确性和效率。|
|📝 更新|MAD-AD: Masked Diffusion for Unsupervised Brain Anomaly Detection|MAD-AD：无监督脑异常检测中的掩码扩散方法|Farzad Beizaee, Gregory Lodygensky, Christian Desrosiers, Jose Dolz|<http://arxiv.org/pdf/2502.16943v3>|[代码](https://github.com/farzad-bz/MAD-AD.); 定位脑部异常无需标签，提出用掩码扩散模型学习正常脑部结构，通过噪声区分异常。|
|🆕 发布|Towards Facilitated Fairness Assessment of AI-based Skin Lesion Classifiers Through GenAI-based Image Synthesis|基于生成式AI图像合成的AI皮肤病变分类器公平性评估便捷化方法研究|Ko Watanabe. Stanislav Frolov. Adriano Lucieri. Andreas Dengel|<http://arxiv.org/pdf/2507.17860v1>|利用生成式AI创建合成图像以评估皮肤病变分类器的公平性，提出新方法增强医疗成像系统的公平性评估。|
|🆕 发布|BetterCheck: Towards Safeguarding VLMs for Automotive Perception Systems|“BetterCheck：面向汽车感知系统的虚拟生命周期模型安全保护”|Malsha Ashani Mahawatta Dona, Beatriz Cabrero-Daniel, Yinan Yu, Christian Berger|<http://arxiv.org/pdf/2507.17722v1>|提出了一种检测大型语言模型在汽车感知系统中幻觉现象的方法BetterCheck，以保障自动驾驶系统的...|
|🆕 发布|Illicit object detection in X-ray imaging using deep learning techniques: A comparative evaluation|使用深度学习技术在X射线成像中进行非法物品检测：比较评估|Jorgen Cani, Christos Diou, Spyridon Evangelatos, Vasileios Argyriou, Panagiotis Radoglou-Grammatikis, Panagiotis Sarigiannidis, Iraklis Varlamis, Georgios Th. Papadopoulos|<http://arxiv.org/pdf/2507.17508v1>|[代码](https://github.com/jgenc/xray-comparative-evaluation.); 系统比较了深度学习在X射线非法物品检测中的应用，提升了检测准确性和效率。|
|🆕 发布|Unsupervised anomaly detection using Bayesian flow networks: application to brain FDG PET in the context of Alzheimer's disease|使用贝叶斯流网络的无监督异常检测：在阿尔茨海默病背景下对大脑FDG PET的应用|Hugues Roy, Reuben Dorent, Ninon Burgos|<http://arxiv.org/pdf/2507.17486v1>|提出AnoBFN模型，利用贝叶斯流网络进行无监督异常检测，有效识别阿尔茨海默病PET图像中的异常。|
|📝 更新|RALAD: Bridging the Real-to-Sim Domain Gap in Autonomous Driving with Retrieval-Augmented Learning|RALAD：利用检索增强学习在自动驾驶中缩小现实至模拟领域的差距|Jiacheng Zuo, Haibo Hu, Zikang Zhou, Yufei Cui, Ziquan Liu, Jianping Wang, Nan Guan, Jin Wang .etc.|<http://arxiv.org/pdf/2501.12296v3>|[代码](https://github.com/JiachengZuo/RALAD.git.); RALAD通过增强最优传输方法和统一框架，低成本地缩小了自动驾驶中现实与模拟环境间的差距。|
|📝 更新|A Deep Learning Approach for Augmenting Perceptional Understanding of Histopathology Images|深度学习方法增强病理图像的感知理解|Xiaoqian Hu|<http://arxiv.org/pdf/2503.06894v3>|提出了一种结合视觉变换器和语言模型的多模态方法，通过为病理图像生成精确的描述性字幕，增强医疗专业人士...|
|🆕 发布|Content-based 3D Image Retrieval and a ColBERT-inspired Re-ranking for Tumor Flagging and Staging|基于内容的3D图像检索及受ColBERT启发的重要性重排用于肿瘤标记与分期|Farnaz Khun Jush, Steffen Vogler, Matthias Lenga|<http://arxiv.org/pdf/2507.17412v1>|提出了一种适应3D医疗图像的ColBERT启发式重排方法C-MIR，无需预分割即可有效定位肿瘤区域，...|
|🆕 发布|CAPRI-CT: Causal Analysis and Predictive Reasoning for Image Quality Optimization in Computed Tomography|CAPRI-CT：计算机断层扫描图像质量优化的因果分析与预测推理|Sneha George Gnanakalavathy, Hairil Abdul Razak, Robert Meertens, Jonathan E. Fieldsend, Xujiong Ye, Mohammed M. Abdelsamea|<http://arxiv.org/pdf/2507.17420v1>|[代码](https://github.com/SnehaGeorge22/capri-ct.); 提出了一种深度学习框架CAPRI-CT，通过分析图像数据和扫描参数的因果关系，优化CT图像质量并减少...|
|🆕 发布|EndoGen: Conditional Autoregressive Endoscopic Video Generation|内源生成：条件自回归内镜视频生成|Xinyu Liu, Hengyu Liu, Cheng Wang, Tianming Liu, Yixuan Yuan|<http://arxiv.org/pdf/2507.17388v1>|[代码](https://github.com/CUHK-AIM-Group/EndoGen.); 提出了一种条件式内窥镜视频生成框架EndoGen，通过时空网格帧模式与语义感知掩码机制，有效生成高质...|
|📝 更新|Vascular Segmentation of Functional Ultrasound Images using Deep Learning|基于深度学习的功能超声图像血管分割|Hana Sebia, Thomas Guyet, Mickaël Pereira, Marco Valdebenito, Hugues Berry, Benjamin Vidal|<http://arxiv.org/pdf/2410.22365v2>|首次开发出基于深度学习的功能性超声图像血管分割工具，实现了对动脉和静脉信号的高效区分。|
|📝 更新|Monitoring digestate application on agricultural crops using Sentinel-2 Satellite imagery|利用Sentinel-2卫星影像监测农业作物中污泥施用情况|Andreas Kalogeras, Dimitrios Bormpoudakis, Iason Tsardanidis, Dimitra A. Loka, Charalampos Kontoes|<http://arxiv.org/pdf/2504.19996v2>|利用Sentinel-2卫星图像和机器学习模型监测有机物施用，实现农业可持续发展的低成本监测。|
|🆕 发布|Fully Automated SAM for Single-source Domain Generalization in Medical Image Segmentation|单源域泛化在医学图像分割中的完全自动化空间自适应匹配方法|Huanli Zhuo, Leilei Ma, Haifeng Zhao, Shiwei Zhou, Dengdi Sun, Yanping Fu|<http://arxiv.org/pdf/2507.17281v1>|提出FA-SAM框架，通过自动生成提示和融合多尺度信息，实现无需专家标注的医学图像自动分割。|
|🆕 发布|MyGO: Make your Goals Obvious, Avoiding Semantic Confusion in Prostate Cancer Lesion Region Segmentation|我的目标：使目标明确，避免前列腺癌病变区域分割中的语义混淆|Zhengcheng Lin, Zuobin Ying, Zhenyu Li, Zhenyu Liu, Jian Lu, Weiping Ding|<http://arxiv.org/pdf/2507.17269v1>|提出Pixel Anchor Module和Top_k策略，解决了前列腺癌语义混淆问题，提升病变区域...|
|📝 更新|DeepShade: Enable Shade Simulation by Text-conditioned Image Generation|深度遮荫：通过文本条件图像生成实现遮荫模拟|Longchao Da, Xiangrui Liu, Mithun Shivakoti, Thirulogasankar Pranav Kutralingam, Yezhou Yang, Hua Wei|<http://arxiv.org/pdf/2507.12103v2>|提出了一种结合文本描述的扩散模型DeepShade，用于生成不同时间和条件下的阴影效果，助力城市高温...|
|📝 更新|SFNet: A Spatial-Frequency Domain Deep Learning Network for Efficient Alzheimer's Disease Diagnosis|SFNet：一种用于高效阿尔茨海默病诊断的空间-频率域深度学习网络|Xinyue Yang, Meiliang Liu, Yunfang Xu, Xiaoxiao Yang, Zhengye Si, Zijin Li, Zhiwen Zhao|<http://arxiv.org/pdf/2507.16267v2>|提出了一种融合空间域和频域信息的3D MRI诊断网络SFNet，提高了阿尔茨海默症诊断的准确性和效率...|
|🆕 发布|Multi-Scale PCB Defect Detection with YOLOv8 Network Improved via Pruning and Lightweight Network|基于YOLOv8网络并通过剪枝与轻量化网络改进的多尺度PCB缺陷检测|Li Pingzhen, Xu Sheng, Chen Jing, Su Chengyue|<http://arxiv.org/pdf/2507.17176v1>|提出了一种基于YOLOv8的PCB缺陷检测方法，通过剪枝和轻量化网络提升了检测速度和准确性。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Application of YOLOv8 in monocular downward multiple Car Target detection|单目向下视角多车辆目标检测中YOLOv8的应用|Shijie Lyu|<http://arxiv.org/pdf/2505.10016v2>|提出基于YOLOv8的改进目标检测网络，通过结构重参数化等技术提升小目标检测精度，有效解决自动驾驶中...|
|📝 更新|GEMINUS: Dual-aware Global and Scene-Adaptive Mixture-of-Experts for End-to-End Autonomous Driving|GEMINUS：端到端自动驾驶中的双感知全局与场景自适应专家混合模型|Chi Wan, Yixin Cui, Jiatong Du, Shuo Yang, Yulong Bai, Yanjun Huang|<http://arxiv.org/pdf/2507.14456v3>|[代码](https://github.com/newbrains1/GEMINUS.); 提出了一种结合全局和场景自适应的混合专家系统，有效提升自动驾驶的适应性和鲁棒性。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DeMo++: Motion Decoupling for Autonomous Driving|DeMo++：自动驾驶中的运动解耦|Bozhou Zhang, Nan Song, Xiatian Zhu, Li Zhang|<http://arxiv.org/pdf/2507.17342v1>|提出了一种解耦运动估计的DeMo++框架，通过综合捕捉运动意图的多样性和轨迹的时空演化，提升自动驾驶...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 可解释视觉智能 (Explainable Visual Intelligence)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Explainable AI for Collaborative Assessment of 2D/3D Registration Quality|协同评估2D/3D配准质量的可解释人工智能|Sue Min Cho, Alexander Do, Russell H. Taylor, Mathias Unberath|<http://arxiv.org/pdf/2507.17597v1>|提出首个用于2D/3D注册质量验证的可解释AI框架，辅助人类操作者决策。|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MCA-LLaVA: Manhattan Causal Attention for Reducing Hallucination in Large Vision-Language Models|曼哈顿因果注意力：用于减少大型视觉语言模型中的幻觉现象|Qiyan Zhao, Xiaofeng Zhang, Yiheng Li, Yun Xing, Xiaosong Yuan, Feilong Tang, Sinan Fan, Xuhang Chen .etc.|<http://arxiv.org/pdf/2507.09184v2>|[代码](https://github.com/ErikZ719/MCA-LLaVA.); 提出了一种基于曼哈顿距离的MCA-LLaVA方法，减少大型视觉语言模型中的幻觉现象，提高多模态对齐质...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Comprehensive Evaluation Framework for the Study of the Effects of Facial Filters on Face Recognition Accuracy|面向研究面部过滤器对人脸识别精度影响的全维度评估框架|Kagan Ozturk, Louisa Conwill, Jacob Gutierrez, Kevin Bowyer, Walter J. Scheirer|<http://arxiv.org/pdf/2507.17729v1>|构建了一套全面评估体系，研究社交媒体面部滤镜对自动人脸识别准确性的影响。|
|🆕 发布|Talk2Event: Grounded Understanding of Dynamic Scenes from Event Cameras|《Talk2Event：从事件相机中对动态场景进行 grounded 理解》|Lingdong Kong, Dongyue Lu, Ao Liang, Rong Li, Yuhao Dong, Tianshuai Hu, Lai Xing Ng, Wei Tsang Ooi .etc.|<http://arxiv.org/pdf/2507.17664v1>|提出首个大规模基准Talk2Event，通过属性感知框架EventRefer实现事件相机与自然语言的...|
|📝 更新|TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting|“TaoAvatar：通过三维高斯散点法实现增强现实中的实时逼真全身对话虚拟化身”|Jianchuan Chen, Jingchuan Hu, Gaige Wang, Zhonghua Jiang, Tiansong Zhou, Zhiwen Chen, Chengfei Lv|<http://arxiv.org/pdf/2503.17032v2>|提出TaoAvatar，通过3D Gaussian Splatting和轻量级网络实现实时全身谈话A...|

