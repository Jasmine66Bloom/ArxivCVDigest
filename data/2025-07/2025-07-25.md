## [UPDATED!] **2025-07-25** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Efficient Learning for Product Attributes with Compact Multimodal Models|产品属性的高效学习与紧凑多模态模型的构建|Mandar Kulkarni|<http://arxiv.org/pdf/2507.19679v1>|提出了一种利用未标注产品信息通过直接偏好优化进行半监督微调的紧凑多模态模型，有效提升了产品属性预测效...|
|🆕 发布|MCIF: Multimodal Crosslingual Instruction-Following Benchmark from Scientific Talks|多模态跨语言指令遵循基准：从科学讲座中构建|Sara Papi, Maike Züfle, Marco Gaido, Beatrice Savoldi, Danni Liu, Ioannis Douros, Luisa Bentivogli, Jan Niehues|<http://arxiv.org/pdf/2507.19634v1>|提出了MCIF基准，用于评估多模态大型语言模型在不同语言和模态下的指令跟随能力。|
|📝 更新|ReSem3D: Refinable 3D Spatial Constraints via Fine-Grained Semantic Grounding for Generalizable Robotic Manipulation|ReSem3D：通过细粒度语义定位进行可细化三维空间约束以实现通用机器人操作|Chenyu Su, Weiwei Shang, Chen Qian, Fei Zhang, Shuang Cong|<http://arxiv.org/pdf/2507.18262v2>|[代码](https://github.com/scy-v/ReSem3D); 提出ReSem3D框架，结合大语言模型与视觉基础模型，实现细粒度视觉定位与动态构建三维空间约束，提升...|
|🆕 发布|PRE-MAP: Personalized Reinforced Eye-tracking Multimodal LLM for High-Resolution Multi-Attribute Point Prediction|个性化强化眼动多模态大规模语言模型用于高分辨率多属性点预测：PRE-MAP|Hanbing Wu, Ping Jiang, Anyang Su, Chenxu Zhao, Tianyu Fu, Minghui Wu, Beiping Tan, Huiying Li|<http://arxiv.org/pdf/2507.19213v1>|[代码](https://github.com/mininglamp-MLLM/PRE-MAP); 提出个性化多模态模型PRE-MAP，通过强化学习优化眼动追踪，预测高分辨率多属性关注点。|
|🆕 发布|PhysDrive: A Multimodal Remote Physiological Measurement Dataset for In-vehicle Driver Monitoring|PhysDrive：一种用于车内驾驶员监测的多模态远程生理测量数据集|Jiyao Wang, Xiao Yang, Qingyong Hu, Jiankai Tang, Can Liu, Dengbo He, Yuntao Wang, Yingcong Chen .etc.|<http://arxiv.org/pdf/2507.19172v1>|介绍了PhysDrive，首个大规模多模态车内生理监测数据集，助力无接触式驾驶生理状态监测研究。|
|🆕 发布|Probing Multimodal Fusion in the Brain: The Dominance of Audiovisual Streams in Naturalistic Encoding|在脑中探测多模态融合：自然编码中视听流的统治性|Hamid Abdollahi, Amir Hossein Mansouri Majoumerd, Amir Hossein Bagheri Baboukani, Amir Abolfazl Suratgar, Mohammad Bagher Menhaj|<http://arxiv.org/pdf/2507.19052v1>|探究自然情境下脑活动编码，发现简单模型在泛化能力上优于复杂模型，视觉和听觉信息主导神经编码。|
|📝 更新|A Multimodal Seq2Seq Transformer for Predicting Brain Responses to Naturalistic Stimuli|一种用于预测大脑对自然场景刺激响应的多模态Seq2Seq变压器模型|Qianyi He, Yuan Chang Leong|<http://arxiv.org/pdf/2507.18104v2>|[代码](https://github.com/Angelneer926/Algonauts_challenge.); 提出了一种多模态Seq2Seq Transformer模型，通过整合视觉、听觉和语言信息，预测大脑对...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Back to the Features: DINO as a Foundation for Video World Models|回归特征：DINO作为视频世界模型的基础|Federico Baldassarre, Marc Szafraniec, Basile Terver, Vasil Khalidov, Francisco Massa, Yann LeCun, Patrick Labatut, Maximilian Seitzer .etc.|<http://arxiv.org/pdf/2507.19468v1>|提出DINO-world模型，通过预训练图像编码器和大规模视频数据训练预测器，实现高效视频预测和物理...|
|📝 更新|Multimodal Recurrent Ensembles for Predicting Brain Responses to Naturalistic Movies (Algonauts 2025)|多模态循环集成模型用于预测大脑对自然场景电影反应的研究（Algonauts 2025）|Semih Eren, Deniz Kucukahmetler, Nico Scherf|<http://arxiv.org/pdf/2507.17897v2>|提出了一种融合视觉、听觉和语义信息的多模态递归集成模型，用于预测大脑对自然场景的反应。|
|📝 更新|SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models|基于多模态大型语言模型的自我进化视觉-语言导航框架：SE-VLN|Xiangyu Dong, Haoran Zhao, Jiang Gao, Haozhou Li, Xiaoguang Ma, Yaoming Zhou, Fuhai Chen, Juan Liu|<http://arxiv.org/pdf/2507.13152v2>|提出了一种自进化的视觉语言导航框架SE-VLN，通过持续学习提升未知环境中的导航成功率。|
|🆕 发布|Joint Holistic and Lesion Controllable Mammogram Synthesis via Gated Conditional Diffusion Model|通过门控条件扩散模型实现的联合整体和病变可控的乳腺X线照片合成|Xin Li, Kaixiang Yang, Qiang Li, Zhiwei Wang|<http://arxiv.org/pdf/2507.19201v1>|[代码](https://github.com/lixinHUST/Gated-Conditional-Diffusion-Model); 提出了一种新型Gated Conditional Diffusion Model，实现了整体乳腺图像...|
|🆕 发布|MedIQA: A Scalable Foundation Model for Prompt-Driven Medical Image Quality Assessment|MedIQA：一种用于提示驱动的医学图像质量评估的可扩展基础模型|Siyi Xun, Yue Sun, Jingkun Chen, Zitong Yu, Tong Tong, Xiaohong Liu, Mingxiang Wu, Tao Tan|<http://arxiv.org/pdf/2507.19004v1>|提出首个全面的基础模型MedIQA，实现跨模态医疗图像质量自动评估，提升诊断准确性。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Unraveling the geometry of visual relational reasoning|揭开视觉关系推理的几何学特征|Jiaqi Shang, Gabriel Kreiman, Haim Sompolinsky|<http://arxiv.org/pdf/2502.17382v2>|提出SimplifiedRPM基准和SNRloss损失函数，通过几何分析提升视觉关系推理能力。|
|🆕 发布|Review of Deep Learning Applications to Structural Proteomics Enabled by Cryogenic Electron Microscopy and Tomography|深度学习在低温电子显微镜与断层扫描技术赋能的结构蛋白质组学应用综述|Brady K. Zhou, Jason J. Hu, Jane K. J. Lee, Z. Hong Zhou, Demetri Terzopoulos|<http://arxiv.org/pdf/2507.19565v1>|整合深度学习技术显著提升了冷冻电镜结构生物学的效率和分辨率。|
|📝 更新|$S^2M^2$: Scalable Stereo Matching Model for Reliable Depth Estimation|"S^2M^2": 可扩展立体匹配模型用于可靠深度估计|Junhong Min, Youngpil Jeon, Jimin Kim, Minyong Choi|<http://arxiv.org/pdf/2507.13229v2>|提出全局匹配架构$S^2M^2$，实现高效准确深度估计，无需特定数据集微调。|
|🆕 发布|EA-ViT: Efficient Adaptation for Elastic Vision Transformer|EA-ViT：弹性视觉变换器的有效适应|Chen Zhu, Wangbo Zhao, Huiwen Zhang, Samir Khaki, Yuhao Zhou, Weidong Tang, Shuo Wang, Zhihang Yuan .etc.|<http://arxiv.org/pdf/2507.19360v1>|[代码](https://github.com/zcxcf/EA-ViT.); 提出了一种高效的Vision Transformer适应框架，通过单一适应过程生成多种尺寸的模型，满...|
|🆕 发布|Patch Pruning Strategy Based on Robust Statistical Measures of Attention Weight Diversity in Vision Transformers|基于稳健统计量测度的注意力权重多样性在视觉变换器中的修补剪枝策略|Yuki Igaue, Hiroaki Aizawa|<http://arxiv.org/pdf/2507.19175v1>|提出一种基于注意力权重多样性的 patch 裁剪策略，通过评估每个 patch 的重要性来提升计算效...|
|🆕 发布|MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective|混合精度量化视角下重新审视视觉变换器的激活稀疏性：MixA-Q|Weitian Wang, Rai Shubham, Cecilia De La Parra, Akash Kumar|<http://arxiv.org/pdf/2507.19131v1>|提出混合精度激活量化框架MixA-Q，利用层内激活稀疏性提升量化视觉变压器的性能与效率。|
|🆕 发布|PGKET: A Photonic Gaussian Kernel Enhanced Transformer|PGKET：一种光子高斯核增强的变压器模型|Ren-Xin Zhao|<http://arxiv.org/pdf/2507.19041v1>|提出了一种基于光子技术的PGKET模型，通过并行处理提升长序列效率，优于现有变压器模型。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Synthetic-to-Real Camouflaged Object Detection|合成到现实场景中的迷彩目标检测|Zhihao Luo, Luojun Lin, Zheng Lin|<http://arxiv.org/pdf/2507.18911v2>|[代码](https://github.com/Muscape/S2R-COD.); 提出了一种基于学生-教师模型的CSRDA框架，通过伪标签和一致性正则化将分类信息从标注的合成数据域传...|
|🆕 发布|Multistream Network for LiDAR and Camera-based 3D Object Detection in Outdoor Scenes|户外场景中基于LiDAR和相机的多流网络三维目标检测|Muhammad Ibrahim, Naveed Akhtar, Haitian Wang, Saeed Anwar, Ajmal Mian|<http://arxiv.org/pdf/2507.19304v1>|[代码](https://github.com/IbrahimUWA/MuStD.git); 提出了一种三流结构的MuStD网络，融合激光雷达和相机数据，显著提升了户外场景三维物体检测精度。|
|🆕 发布|Revisiting DETR for Small Object Detection via Noise-Resilient Query Optimization|通过噪声鲁棒查询优化重新审视DETR进行小目标检测|Xiaocheng Fang, Jieyi Cai, Huanyu Liu, Wenxiu Cai, Yishu Liu, Bingzhi Chen|<http://arxiv.org/pdf/2507.19059v1>|提出了一种针对小目标检测的噪声鲁棒查询优化方法，通过改进特征融合和锚点匹配策略，有效提高了检测性能。|
|📝 更新|Style-Adaptive Detection Transformer for Single-Source Domain Generalized Object Detection|单源域泛化目标检测的样式自适应检测变换器|Jianhong Han, Yupei Wang, Liang Chen|<http://arxiv.org/pdf/2504.20498v2>|提出了一种基于检测变换器的风格自适应方法，通过在线领域风格适配和对象感知对比学习，有效提升了单源域泛...|
|🆕 发布|Underwater Waste Detection Using Deep Learning A Performance Comparison of YOLOv7 to 10 and Faster RCNN|水下垃圾检测使用深度学习：YOLOv7至YOLOv10与Faster RCNN性能比较|UMMPK Nawarathne, HMNS Kumari, HMLS Kumari|<http://arxiv.org/pdf/2507.18967v1>|比较了多种深度学习模型在 underwater waste detection 上的表现，发现 YO...|
|🆕 发布|WiSE-OD: Benchmarking Robustness in Infrared Object Detection|WiSE-OD：红外目标检测鲁棒性基准测试|Heitor R. Medeiros, Atif Belal, Masih Aminbeidokhti, Eric Granger, Marco Pedersoli|<http://arxiv.org/pdf/2507.18925v1>|提出WiSE-OD方法，通过跨模态权重融合提升红外目标检测的鲁棒性。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SurgPIS: Surgical-instrument-level Instances and Part-level Semantics for Weakly-supervised Part-aware Instance Segmentation|手术器械级实例与部分级语义的弱监督部分感知实例分割：SurgPIS|Meng Wei, Charlie Budd, Oluwatosin Alabi, Miaojing Shi, Tom Vercauteren|<http://arxiv.org/pdf/2507.19592v1>|提出了一种统一处理手术器械实例和部分级别语义分割的模型SurgPIS，通过弱监督学习实现精确分割。|
|🆕 发布|CXR-CML: Improved zero-shot classification of long-tailed multi-label diseases in Chest X-Rays|CXR-CML：胸部X射线中长尾多标签疾病零样本分类的改进|Rajesh Madhipati, Sheethal Bhat, Lukas Buess, Andreas Maier|<http://arxiv.org/pdf/2507.19398v1>|提出了一种针对 chest X-ray 长尾多标签分类问题的类权重机制，通过 Gaussian Mi...|
|🆕 发布|YOLO for Knowledge Extraction from Vehicle Images: A Baseline Study|车辆图像知识提取的YOLO应用：基线研究|Saraa Al-Saddik, Manna Elizabeth Philip, Ali Haidar|<http://arxiv.org/pdf/2507.18966v1>|本研究通过多视角推理方法提升了YOLO模型在车辆图像属性识别中的准确性，为实时车辆数据提取提供了高效...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|T-MPEDNet: Unveiling the Synergy of Transformer-aware Multiscale Progressive Encoder-Decoder Network with Feature Recalibration for Tumor and Liver Segmentation|T-MPEDNet：揭示基于Transformer感知的多尺度渐进式编码器-解码器网络与特征重校准在肿瘤和肝脏分割中的协同作用|Chandravardhan Singh Raghaw, Jasmer Singh Sanjotra, Mohammad Zia Ur Rehman, Shubhi Bansal, Shahid Shafi Dar, Nagendra Kumar|<http://arxiv.org/pdf/2507.19590v1>|提出T-MPEDNet网络，融合多尺度特征与注意力机制，实现精确的肿瘤和肝脏CT图像分割。|
|🆕 发布|Dealing with Segmentation Errors in Needle Reconstruction for MRI-Guided Brachytherapy|处理磁共振引导近距离放射治疗中针重建的分割错误|Vangelis Kostoulas, Arthur Guijt, Ellen M. Kerkhof, Bradley R. Pieters, Peter A. N. Bosman, Tanja Alderliesten|<http://arxiv.org/pdf/2507.18895v1>|提出改进的后处理技术以应对针重建中的分割错误，显著提升了定位精度。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Efficient Lines Detection for Robot Soccer|机器人足球中的高效线条检测|João G. Melo, João P. Mafaldo, Edna Barros|<http://arxiv.org/pdf/2507.19469v1>|提出了一种高效检测足球场线条的方法，通过ELSED算法和RGB颜色过渡分析，实现快速准确的自定位。|
|📝 更新|GVCCS: A Dataset for Contrail Identification and Tracking on Visible Whole Sky Camera Sequences|“GVCCS：一种用于可见全天空摄像头序列中尾迹识别与跟踪的数据集”|Gabriel Jarry, Ramon Dalmau, Philippe Very, Franck Ballerini, Stefania-Denisa Bocu|<http://arxiv.org/pdf/2507.18330v2>|提出GVCCS数据集，通过地面全天空相机记录并跟踪气溶胶轨迹，为物理模型校准提供观测数据支持。|
|🆕 发布|BridgeNet: A Unified Multimodal Framework for Bridging 2D and 3D Industrial Anomaly Detection|BridgeNet：一种统一的多模态框架，用于连接二维和三维工业异常检测|An Xiang, Zixuan Huang, Xitong Gao, Kejiang Ye, Cheng-zhong Xu|<http://arxiv.org/pdf/2507.19253v1>|[代码](https://github.com/Xantastic/BridgeNet); 提出了一种统一的多模态框架BridgeNet，通过分离深度与外观信息并共享参数，有效桥接2D与3D工...|
|🆕 发布|PerioDet: Large-Scale Panoramic Radiograph Benchmark for Clinical-Oriented Apical Periodontitis Detection|牙周炎检测的大规模全景X光片基准数据集：PerioDet|Xiaocheng Fang, Jieyi Cai, Huanyu Liu, Chengju Zhou, Minhua Lu, Bingzhi Chen|<http://arxiv.org/pdf/2507.18958v1>|提出首个大规模牙片数据集，并设计用于牙尖周炎检测的模型，提升自动诊断准确性。|
|🆕 发布|Structure Matters: Revisiting Boundary Refinement in Video Object Segmentation|结构至关重要：重新审视视频对象分割中的边界细化|Guanyi Qin, Ziyue Wang, Daiyun Shen, Haofeng Liu, Hantao Zhou, Junde Wu, Runze Hu, Yueming Jin|<http://arxiv.org/pdf/2507.18944v1>|提出了一种结构优化的视频对象分割方法OASIS，通过边缘特征强化和不确定性估计提升了遮挡场景下的分割...|
|📝 更新|BGM: Background Mixup for X-ray Prohibited Items Detection|BGM：X射线违禁品检测中的背景混合技术|Weizhe Liu, Renshuai Tao, Hongguang Zhu, Yunda Sun, Yao Zhao, Yunchao Wei|<http://arxiv.org/pdf/2412.00460v3>|提出背景混叠技术BGM，增强X射线禁品检测模型处理复杂背景的能力。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SynPAIN: A Synthetic Dataset of Pain and Non-Pain Facial Expressions|SynPAIN：疼痛与非疼痛面部表情的合成数据集|Babak Taati, Muhammad Muzammil, Yasamin Zarghami, Abhishek Moturu, Airhossein Kazerouni, Hailey Reimer, Alex Mihailidis, Thomas Hadjistavropoulos|<http://arxiv.org/pdf/2507.19673v1>|提出了SynPAIN，一个针对老年人疼痛检测的多样化合成数据集，以减少评估偏差并提高模型性能。|
|📝 更新|Handcrafted vs. Deep Radiomics vs. Fusion vs. Deep Learning: A Comprehensive Review of Machine Learning -Based Cancer Outcome Prediction in PET and SPECT Imaging|手工特征与深度放射组学对比融合方法与深度学习：基于机器学习的PET和SPECT成像中癌症预后预测的全面回顾|Mohammad R. Salmanpour, Somayeh Sadat Mehrnia, Sajad Jabarzadeh Ghandilu, Zhino Safahi, Sonya Falahati, Shahram Taeb, Ghazal Mousavi, Mehdi Maghsoudi .etc.|<http://arxiv.org/pdf/2507.16065v2>|系统评估了机器学习在PET和SPECT成像中预测癌症结局的性能，发现深度放射组学特征和融合模型效果最...|
|🆕 发布|Object-centric Video Question Answering with Visual Grounding and Referring|基于视觉定位和指示的以对象为中心的视频问答|Haochen Wang, Qirui Chen, Cilin Yan, Jiayin Cai, Xiaolong Jiang, Yao Hu, Weidi Xie, Stratis Gavves|<http://arxiv.org/pdf/2507.19599v1>|[代码](https://qirui-chen.github.io/RGA3-release); 引入VideoLLM模型，提出STOM和VideoInfer，增强视频理解中的对象中心交互和视觉输出...|
|🆕 发布|SAM2-Aug: Prior knowledge-based Augmentation for Target Volume Auto-Segmentation in Adaptive Radiation Therapy Using Segment Anything Model 2|SAM2-Aug：基于先验知识的增强方法用于自适应放射治疗中目标体积自动分割的Segment Anything Model 2|Guoping Xu, Yan Dai, Hengrui Zhao, Ying Zhang, Jie Deng, Weiguo Lu, You Zhang|<http://arxiv.org/pdf/2507.19282v1>|[代码](https://github.com/apple1986/SAM2-Aug.); 提出基于先验知识的增强策略，提升SAM2模型在自适应放疗中肿瘤自动分割的准确性和泛化能力。|
|🆕 发布|Relaxed Total Generalized Variation Regularized Piecewise Smooth Mumford-Shah Model for Triangulated Surface Segmentation|基于放松总广义变分正则化的分块平滑Mumford-Shah模型用于三角剖分表面分割|Huayan Zhang, Shanqiang Wang, Xiaochao Wang|<http://arxiv.org/pdf/2507.19284v1>|提出了一种基于放松总广义变分正则化的分段平滑Mumford-Shah模型，有效改善不规则网格结构的三...|
|🆕 发布|Video Self-Distillation for Single-Image Encoders: A Step Toward Physically Plausible Perception|视频自蒸馏用于单图像编码器：迈向物理可信感知的一步|Marcel Simon, Tae-Ho Kim, Seul-Ki Yeom|<http://arxiv.org/pdf/2507.19272v1>|引入视频自蒸馏训练单张图像编码器，提升了对物理世界的感知能力。|
|🆕 发布|Event-Driven Storytelling with Multiple Lifelike Humans in a 3D Scene|基于三维场景中多个逼真人类的逐事件叙述|Donggeun Lim, Jinseok Bae, Inwoo Hwang, Seungmin Lee, Hwanhee Lee, Young Min Kim|<http://arxiv.org/pdf/2507.19232v1>|[代码](https://rms0329.github.io/Event-Driven-Storytelling); 提出了一种利用大型语言模型处理多人物动态场景的框架，实现了事件驱动的生动故事叙述。|
|🆕 发布|OVFact: Measuring and Improving Open-Vocabulary Factuality for Long Caption Models|《OVFact：测量并提升长标题模型的开词汇事实性》|Monika Wysoczańska, Shyamal Buch, Anurag Arnab, Cordelia Schmid|<http://arxiv.org/pdf/2507.19262v1>|提出OV-Fact方法，通过开放词汇视觉定位和工具验证测量长字幕的事实性，无需人工标注。|
|🆕 发布|RealisVSR: Detail-enhanced Diffusion for Real-World 4K Video Super-Resolution|RealisVSR：面向真实世界4K视频超分辨率的细节增强扩散方法|Weisong Zhao, Jingkai Zhou, Xiangyu Zhu, Weihua Chen, Xiao-Yu Zhang, Zhen Lei, Fan Wang|<http://arxiv.org/pdf/2507.19138v1>|提出RealisVSR模型，通过控制网和特定损失函数增强视频超分辨率中的细节恢复，并创建首个4K视频...|
|📝 更新|Enhancing Frequency for Single Image Super-Resolution with Learnable Separable Kernels|使用可学习分离核增强单图像超分辨率频率|Heng Tian|<http://arxiv.org/pdf/2506.04555v2>|提出了一种可学习的分离核模块，直接增强图像频率成分，减少参数和计算需求，提升超分辨率性能。|
|🆕 发布|Cross-Subject Mind Decoding from Inaccurate Representations|跨主体从不准确表征中的心智解码|Yangyang Xu, Bangzhen Liu, Wenqi Shao, Yong Du, Shengfeng He, Tingting Zhu|<http://arxiv.org/pdf/2507.19071v1>|提出双向自动编码器纠缠框架，通过主体偏差调节模块和视觉一致性模块，有效解决跨主体fMRI信号解码中的...|
|🆕 发布|Closing the Modality Gap for Mixed Modality Search|弥合混合模态搜索中的模态差距|Binxu Li, Yuhui Zhang, Xiaohan Wang, Weixin Liang, Ludwig Schmidt, Serena Yeung-Levy|<http://arxiv.org/pdf/2507.19054v1>|提出方法GR-CLIP消除模态间隔，提升混合模态搜索性能。|
|🆕 发布|GPSMamba: A Global Phase and Spectral Prompt-guided Mamba for Infrared Image Super-Resolution|全球相位与光谱提示引导的Mamba：用于红外图像超分辨率|Yongsong Huang, Tomo Miyazaki, Xiaofeng Liu, Shinichiro Omachi|<http://arxiv.org/pdf/2507.18998v1>|[代码](https://github.com/yongsongH/GPSMamba.); 提出了一种融合全局相位和频谱提示的Mamba框架，有效提升了红外图像超分辨率性能。|
|📝 更新|Do Existing Testing Tools Really Uncover Gender Bias in Text-to-Image Models?|现有测试工具真的能揭示文本到图像模型中的性别偏见吗？|Yunbo Lyu, Zhou Yang, Yuqing Niu, Jing Jiang, David Lo|<http://arxiv.org/pdf/2501.15775v2>|评估现有性别偏见探测器在文本到图像模型中的准确性，并提出了一种改进的探测器。|
|📝 更新|Concept-TRAK: Understanding how diffusion models learn concepts through concept-level attribution|概念追踪：通过概念级归因理解扩散模型如何学习概念|Yonghyun Park, Chieh-Hsin Lai, Satoshi Hayakawa, Yuhta Takida, Naoki Murata, Wei-Hsiang Liao, Woosung Choi, Kin Wai Cheuk .etc.|<http://arxiv.org/pdf/2507.06547v2>|提出概念级归因方法Concept-TRAK，通过改进扩散模型训练和奖励函数，实现对特定元素如风格或对...|
|📝 更新|SceneMI: Motion In-betweening for Modeling Human-Scene Interactions|场景MI：建模人与场景交互的运动插值|Inwoo Hwang, Bing Zhou, Young Min Kim, Jian Wang, Chuan Guo|<http://arxiv.org/pdf/2503.16289v2>|提出SceneMI框架，通过场景感知运动插值改善人类与场景交互的建模控制性和灵活性。|
|🆕 发布|PDT: Point Distribution Transformation with Diffusion Models|点分布变换与扩散模型|Jionghao Wang, Cheng Lin, Yuan Liu, Rui Xu, Zhiyang Dou, Xiao-Xiao Long, Hao-Xiang Guo, Taku Komura .etc.|<http://arxiv.org/pdf/2507.18939v1>|[代码](https://github.com/shanemankiw/PDT.); 提出了一种基于扩散模型的新型框架PDT，将无序点云转化为有意义的结构化分布。|
|📝 更新|Towards Robust and Controllable Text-to-Motion via Masked Autoregressive Diffusion|面向鲁棒性与可控性的基于遮蔽自回归扩散的文本到动作生成方法|Zongye Zhang, Bohan Kong, Qingjie Liu, Yunhong Wang|<http://arxiv.org/pdf/2505.11013v2>|[代码](https://github.com/zzysteve/MoMADiff); 提出了一种结合掩码建模与扩散过程的MoMADiff框架，实现了对3D人体运动从文本描述的稳健生成与精...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|BadVideo: Stealthy Backdoor Attack against Text-to-Video Generation|《BadVideo：针对文本到视频生成的隐蔽后门攻击》|Ruotong Wang, Mingli Zhu, Jiarong Ou, Rui Chen, Xin Tao, Pengfei Wan, Baoyuan Wu|<http://arxiv.org/pdf/2504.16907v2>|[代码](https://wrt2000.github.io/BadVideo2025); 提出针对文本到视频生成模型的隐蔽后门攻击框架BadVideo，利用视频冗余信息实现恶意内容嵌入。|
|📝 更新|Blind Spot Navigation: Evolutionary Discovery of Sensitive Semantic Concepts for LVLMs|盲区导航：利用进化算法发现LVLMs敏感语义概念的发现|Zihao Pan, Yu Tong, Weibin Wu, Jingyi Wang, Lifeng Chen, Zhe Zhao, Jiajia Wei, Yitong Qiao .etc.|<http://arxiv.org/pdf/2505.15265v2>|提出了一种语义进化框架，通过大语言模型和文本转图像模型搜索影响大型视觉语言模型性能的敏感语义概念。|
|📝 更新|GIE-Bench: Towards Grounded Evaluation for Text-Guided Image Editing|面向文本引导图像编辑的地基评估方法：GIE-Bench|Yusu Qian, Jiasen Lu, Tsu-Jui Fu, Xinze Wang, Chen Chen, Yinfei Yang, Wenze Hu, Zhe Gan|<http://arxiv.org/pdf/2505.11493v3>|提出了GIE-Bench基准，通过功能正确性和图像内容保持两个维度，更精准地评估文本引导的图像编辑模...|
|🆕 发布|A Survey of Multimodal Hallucination Evaluation and Detection|多模态幻觉评估与检测综述|Zhiyuan Chen, Yuecong Min, Jie Zhang, Bei Yan, Jiahao Wang, Xiaozhen Wang, Shiguang Shan|<http://arxiv.org/pdf/2507.19024v1>|系统梳理了多模态生成任务中幻觉现象的评价标准和检测方法，提出了分类框架并指出未来研究方向。|
|🆕 发布|Enhancing Reward Models for High-quality Image Generation: Beyond Text-Image Alignment|提升高质量图像生成中的奖励模型：超越文本-图像对齐|Ying Ba, Tianyu Zhang, Yalong Bai, Wenyi Mo, Tao Liang, Bing Su, Ji-Rong Wen|<http://arxiv.org/pdf/2507.19002v1>|[代码](https://github.com/BarretBa/ICTHP.); 提出新评价方法ICT和HP模型，优化图像生成质量，提升与人类审美偏好的一致性。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HairCUP: Hair Compositional Universal Prior for 3D Gaussian Avatars|《HairCUP：用于三维高斯虚拟形象的头发组合通用先验》|Byungjun Kim, Shunsuke Saito, Giljoo Nam, Tomas Simon, Jason Saragih, Hanbyul Joo, Junxuan Li|<http://arxiv.org/pdf/2507.19481v1>|提出了一种分解3D头像中面部与头发表示的方法，通过独立学习两者的潜在空间，实现了灵活且可控的头发与面...|
|📝 更新|Vid2Coach: Transforming How-To Videos into Task Assistants|《Vid2Coach：将教学视频转化为任务助手》|Mina Huh, Zihui Xue, Ujjaini Das, Kumar Ashutosh, Kristen Grauman, Amy Pavel|<http://arxiv.org/pdf/2506.00717v2>|提出Vid2Coach系统，将教学视频转化为可穿戴相机辅助工具，帮助视障人士学习并完成任务。|
|🆕 发布|PINO: Person-Interaction Noise Optimization for Long-Duration and Customizable Motion Generation of Arbitrary-Sized Groups|PINO：面向任意规模群体长时间定制化运动生成的交互噪声优化|Sakuya Ota, Qing Yu, Kent Fujiwara, Satoshi Ikehata, Ikuro Sato|<http://arxiv.org/pdf/2507.19292v1>|提出了一种无需训练的Person-Interaction Noise Optimization框架，...|
|📝 更新|Benchmarking of Deep Learning Methods for Generic MRI Multi-Organ Abdominal Segmentation|深度学习技术在腹部多器官磁共振成像通用分割中的基准测试|Deepa Krishnaswamy, Cosmin Ciausu, Steve Pieper, Ron Kikinis, Benjamin Billot, Andrey Fedorov|<http://arxiv.org/pdf/2507.17971v2>|[代码](https://github.com/deepakri201/AbdoBench); 对比评估了三种先进的MRI腹部分割模型，并引入了一种基于CT数据训练的替代模型，提高了腹部MRI分割...|
|🆕 发布|Face2VoiceSync: Lightweight Face-Voice Consistency for Text-Driven Talking Face Generation|《Face2VoiceSync：面向文本驱动的说话人脸生成的轻量级人脸-声音一致性》|Fang Kang, Yin Cao, Haoyu Chen|<http://arxiv.org/pdf/2507.19225v1>|提出Face2VoiceSync框架，通过语音-面部对齐和轻量级训练生成匹配的面部动画和语音。|
|📝 更新|RoCo-Sim: Enhancing Roadside Collaborative Perception through Foreground Simulation|RoCo-Sim：通过前景模拟增强路边协同感知|Yuwen Du, Anning Hu, Zichen Chao, Yifan Lu, Junhao Ge, Genjia Liu, Weitao Wu, Lanjun Wang .etc.|<http://arxiv.org/pdf/2503.10410v2>|[代码](https://github.com/duyuwen-duen/RoCo-Sim); 提出RoCo-Sim框架，通过动态前景编辑和全场景风格转换生成高质量路边协同感知数据，显著提升三维物...|
|📝 更新|MaskControl: Spatio-Temporal Control for Masked Motion Synthesis|《MaskControl：用于遮罩运动合成的时空控制》|Ekkasit Pinyoanuntapong, Muhammad Usama Saleem, Korrawe Karunratanakul, Pu Wang, Hongfei Xue, Chen Chen, Chuan Guo, Junli Cao .etc.|<http://arxiv.org/pdf/2410.10780v3>|引入Logits Regularizer和Logit Optimization，MaskContro...|
|📝 更新|FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features for Highly Controllable Text-Driven Image Translation|FBSDiff：用于高度可控的文本驱动图像转换的即插即用频率带替换扩散特征|Xiang Gao, Jiaying Liu|<http://arxiv.org/pdf/2408.00998v5>|[代码](https://github.com/XiangGao1102/FBSDiff.); 提出了一种无需训练的图像到图像翻译方法，通过频率带替换实现文本驱动的图像编辑，提高了生成图像的质量和...|
|📝 更新|Preserve Anything: Controllable Image Synthesis with Object Preservation|保留一切：具有对象保留功能的可控图像合成|Prasen Kumar Sharma, Neeraj Matiyali, Siddharth Srivastava, Gaurav Sharma|<http://arxiv.org/pdf/2506.22531v2>|提出了一种可控图像合成方法Preserve Anything，通过N通道ControlNet实现了对...|
|🆕 发布|AEDR: Training-Free AI-Generated Image Attribution via Autoencoder Double-Reconstruction|AEDR：无需训练的自动编码器双向重建AI生成图像归因|Chao Wang, Kejiang Chen, Zijin Yang, Yaofei Wang, Weiming Zhang|<http://arxiv.org/pdf/2507.18988v1>|提出了一种无需训练的AI生成图像归因方法AEDR，通过双重建过程和图像一致性度量提高了归因准确度并降...|
|📝 更新|Motion Synthesis with Sparse and Flexible Keyjoint Control|稀疏且灵活的关键关节控制运动合成|Inwoo Hwang, Jinseok Bae, Donggeun Lim, Young Min Kim|<http://arxiv.org/pdf/2503.15557v2>|提出了一种基于稀疏灵活关键关节信号的动画生成框架，简化了动画制作过程并增强了控制灵活性。|
|🆕 发布|Mining Contextualized Visual Associations from Images for Creativity Understanding|从图像中挖掘上下文视觉关联以理解创造力|Ananya Sahu, Amith Ananthram, Kathleen McKeown|<http://arxiv.org/pdf/2507.18915v1>|提出了一种挖掘图像中显著视觉元素上下文关联的方法，用于生成高质量的创意性描述。|
|📝 更新|TeEFusion: Blending Text Embeddings to Distill Classifier-Free Guidance|TeEFusion：融合文本嵌入以提炼无分类器指导|Minghao Fu, Guo-Hua Wang, Xiaohao Chen, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang|<http://arxiv.org/pdf/2507.18192v2>|[代码](https://github.com/AIDC-AI/TeEFusion.); 提出了一种高效的文本嵌入融合方法TeEFusion，将指导幅度直接融入文本嵌入中，以简化采样策略并提...|
|📝 更新|RGE-GS: Reward-Guided Expansive Driving Scene Reconstruction via Diffusion Priors|RGE-GS：基于奖励引导的扩散先验的扩张驾驶场景重建|Sicong Du, Jiarun Liu, Qifeng Chen, Hao-Xiang Chen, Tai-Jiang Mu, Sheng Yang|<http://arxiv.org/pdf/2506.22800v3>|[代码](https://github.com/CN-ADLab/RGE-GS.); 提出了一种融合扩散先验和奖励引导的高效道路场景重建框架，显著提升了重建质量与稳定性。|
|📝 更新|Towards Generalized Range-View LiDAR Segmentation in Adverse Weather|面向恶劣天气下广义范围视图激光雷达分割|Longyu Yang, Lu Zhang, Jun Liu, Yap-Peng Tan, Heng Tao Shen, Xiaofeng Zhu, Ping Hu|<http://arxiv.org/pdf/2506.08979v3>|提出了一种模块化轻量级框架，通过分离处理几何属性和反射强度，有效增强了恶劣天气下LiDAR段落的泛化...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SemGes: Semantics-aware Co-Speech Gesture Generation using Semantic Coherence and Relevance Learning|语义感知的协同口语手势生成：基于语义连贯性和相关性学习|Lanmiao Liu, Esam Ghaleb, Aslı Özyürek, Zerrin Yumak|<http://arxiv.org/pdf/2507.19359v1>|[代码](https://semgesture.github.io/.); 提出了一种结合细粒度和全局语义信息生成与言语同步的语义手势的新方法，提升了手势的真实感和一致性。|
|🆕 发布|OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?|OS-MAP：计算机使用代理在广度和深度上能走多远？|Xuetian Chen, Yinghao Chen, Xinfeng Yuan, Zhuo Peng, Lu Chen, Yuekeng Li, Zhoujia Zhang, Yingqian Huang .etc.|<http://arxiv.org/pdf/2507.19132v1>|[代码](https://github.com/OS-Copilot/OS-Map.); 提出OS-MAP基准，针对计算机使用代理的异质任务和实际需求，评估自动化水平和泛化能力。|
|📝 更新|Bilateral Reference for High-Resolution Dichotomous Image Segmentation|双边参考的高分辨率二值图像分割|Peng Zheng, Dehong Gao, Deng-Ping Fan, Li Liu, Jorma Laaksonen, Wanli Ouyang, Nicu Sebe|<http://arxiv.org/pdf/2401.03407v7>|[代码](https://github.com/ZhengPeng7/BiRefNet.); 提出了一种双边参考框架BiRefNet，用于高分辨率二值图像分割，通过定位和重建模块以及辅助梯度监督...|
|🆕 发布|ScenePainter: Semantically Consistent Perpetual 3D Scene Generation with Concept Relation Alignment|《ScenePainter：具有概念关系对齐的语义一致永久性三维场景生成》|Chong Xia, Shengjun Zhang, Fangfu Liu, Chang Liu, Khodchaphun Hirunyaratsameewong, Yueqi Duan|<http://arxiv.org/pdf/2507.19058v1>|[代码](https://xiac20.github.io/ScenePainter); 提出ScenePainter框架，通过概念关系对齐解决3D场景生成中的语义漂移问题，实现连贯的3D视...|
|📝 更新|Registration beyond Points: General Affine Subspace Alignment via Geodesic Distance on Grassmann Manifold|《超越点：基于 Grassmann 流形测地线距离的广义仿射子空间对齐》|Jaeho Shin, Hyeonjae Gil, Junwoo Jang, Maani Ghaffari, Ayoung Kim|<http://arxiv.org/pdf/2507.17998v2>|[代码](https://github.com/joomeok/GrassmannRegistration.); 首次提出显式优化代价函数，实现任意仿射子空间的精确对齐，提升计算机视觉任务中的配准性能。|
|📝 更新|Improving Multislice Electron Ptychography with a Generative Prior|利用生成先验改进多切片电子衍射术|Christian K. Belardi, Chia-Hao Lee, Yingheng Wang, Justin Lovelace, Kilian Q. Weinberger, David A. Muller, Carla P. Gomes|<http://arxiv.org/pdf/2507.17800v2>|提出了一种结合生成先验的扩散模型MEP-Diffusion，显著提高了电子衍射成像的重建质量。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DINO-SLAM: DINO-informed RGB-D SLAM for Neural Implicit and Explicit Representations|DINO-SLAM：基于DINO的RGB-D SLAM用于神经隐式和显式表征|Ziren Gong, Xiaohan Li, Fabio Tosi, Youmin Zhang, Stefano Mattoccia, Jun Wu, Matteo Poggi|<http://arxiv.org/pdf/2507.19474v1>|提出DINO-SLAM方法，通过增强场景表示提升SLAM系统中神经隐式和显式表达的准确性。|
|🆕 发布|Fast Learning of Non-Cooperative Spacecraft 3D Models through Primitive Initialization|通过基元初始化快速学习非协作航天器三维模型|Pol Francesch Huc, Emily Bates, Simone D'Amico|<http://arxiv.org/pdf/2507.19459v1>|提出了一种基于单张图像的卷积神经网络初始化方法，大幅降低了训练3D模型所需的迭代次数和图像数量。|
|🆕 发布|NerT-CA: Efficient Dynamic Reconstruction from Sparse-view X-ray Coronary Angiography|NerT-CA：从稀疏视角X射线冠状动脉造影进行高效动态重建|Kirsten W. H. Maas, Danny Ruijters, Nicola Pezzotti, Anna Vilanova|<http://arxiv.org/pdf/2507.19328v1>|提出了一种结合神经和张量表示的NerT-CA方法，加速了稀疏视角下冠状动脉的4D重建并提高了准确性。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Feed-Forward SceneDINO for Unsupervised Semantic Scene Completion|“前馈SceneDINO用于无监督语义场景补全”|Aleksandar Jevtić, Christoph Reich, Felix Wimbauer, Oliver Hahn, Christian Rupprecht, Stefan Roth, Daniel Cremers|<http://arxiv.org/pdf/2507.06230v2>|该论文提出了一种无监督的语义场景补全方法SceneDINO，通过自监督学习实现了对场景的3D几何和语...|
|🆕 发布|VisHall3D: Monocular Semantic Scene Completion from Reconstructing the Visible Regions to Hallucinating the Invisible Regions|VisHall3D：从重建可见区域到想象不可见区域的单目语义场景补全|Haoang Lu, Yuanqi Su, Xiaoning Zhang, Longjun Gao, Yu Xue, Le Wang|<http://arxiv.org/pdf/2507.19188v1>|提出VisHall3D两阶段框架，分解视觉场景重建与不可见区域推断，有效解决特征纠缠和几何不一致问题...|
|🆕 发布|Gaussian Set Surface Reconstruction through Per-Gaussian Optimization|通过逐高斯优化进行高斯集表面重建|Zhentao Huang, Di Wu, Zhenbang He, Minglun Gong|<http://arxiv.org/pdf/2507.18923v1>|提出了一种优化的高斯集合表面重建方法，通过均匀分布高斯点和保持法线一致性显著提升了几何精度。|


## 时序视觉分析 (Temporal Visual Analysis)


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PatchTraj: Dynamic Patch Representation Learning for Time-Frequency Trajectory Prediction|"PatchTraj：时间-频率轨迹预测的动态补丁表示学习"|Yanghong Liu, Xingping Dong, Ming Li, Weixing Zhang, Yidong Lou|<http://arxiv.org/pdf/2507.19119v2>|提出PatchTraj框架，融合时间和频率域表示，通过动态分块和Transformer编码解码预测行...|
|📝 更新|EmbodiedOcc++: Boosting Embodied 3D Occupancy Prediction with Plane Regularization and Uncertainty Sampler|具身Occ++：利用平面正则化和不确定性采样提升具身三维占据预测|Hao Wang, Xiaobao Wei, Xiaoan Zhang, Jianing Li, Chengyu Bai, Ying Li, Ming Lu, Wenzhao Zheng .etc.|<http://arxiv.org/pdf/2504.09540v2>|[代码](https://github.com/PKUHaoWang/EmbodiedOcc2.); 引入几何约束和不确定性采样，提升三维空间预测准确性及效率。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Tell Me What to Track: Infusing Robust Language Guidance for Enhanced Referring Multi-Object Tracking|告诉我跟踪什么：注入鲁棒性语言指导以增强指示多目标跟踪|Wenjun Huang, Yang Ni, Hanning Chen, Yirui He, Ian Bryant, Yezi Liu, Mohsen Imani|<http://arxiv.org/pdf/2412.12561v3>|提出协同匹配策略和增强的跨模态融合技术，有效解决多目标跟踪中的数据不平衡和新生目标检测问题。|
|🆕 发布|HQ-SMem: Video Segmentation and Tracking Using Memory Efficient Object Embedding With Selective Update and Self-Supervised Distillation Feedback|HQ-SMem：使用具有选择性更新和自监督蒸馏反馈的高效内存对象嵌入进行视频分割与跟踪|Elham Soltani Kazemi, Imad Eddine Toubal, Gani Rahmon, Jaired Collins, K. Palaniappan|<http://arxiv.org/pdf/2507.18921v1>|提出HQ-SMem方法，通过智能内存管理和动态更新，提升视频对象分割的精度和效率。|
|📝 更新|High Performance Space Debris Tracking in Complex Skylight Backgrounds with a Large-Scale Dataset|在复杂天空背景下利用大规模数据集实现高性能空间碎片跟踪|Guohang Zhuang, Weixi Song, Jinyang Huang, Chenwei Yang, Wanli OuYang, Yan Lu|<http://arxiv.org/pdf/2506.02614v4>|提出了一种基于深度学习的空间碎片跟踪网络SDT-Net，有效处理复杂背景下的空间碎片跟踪问题。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-Task Dense Prediction Fine-Tuning with Mixture of Fine-Grained Experts|多任务密集预测微调：基于细粒度专家混合模型|Yangyang Xu, Xi Ye, Duo Su|<http://arxiv.org/pdf/2507.19077v1>|引入细粒度专家混合架构FGMoE，通过任务内专家、共享专家和全局专家实现高效的多任务学习与知识共享。|


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MGHFT: Multi-Granularity Hierarchical Fusion Transformer for Cross-Modal Sticker Emotion Recognition|多粒度层次融合变换器用于跨模态贴纸情感识别|Jian Chen, Yuxuan Hu, Haifeng Lu, Wei Wang, Min Yang, Chengming Li, Xiping Hu|<http://arxiv.org/pdf/2507.18929v1>|[代码](https://github.com/cccccj-03/MGHFT_ACMMM2025.); 提出了一种多粒度层级融合变换器，通过多模态大语言模型和金字塔视觉变换器，有效提升了表情贴纸的情绪识别...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GT-Loc: Unifying When and Where in Images Through a Joint Embedding Space|GT-Loc：通过联合嵌入空间统一图像中的何时与何地|David G. Shatwell, Ishan Rajendrakumar Dave, Sirnam Swetha, Mubarak Shah|<http://arxiv.org/pdf/2507.10473v2>|提出了一种统一预测图像拍摄时间和地点的方法，通过共享特征空间提升了时间预测准确性。|
|📝 更新|Latent Space Analysis for Melanoma Prevention|黑色素瘤预防的潜在空间分析|Ciro Listone, Aniello Murano|<http://arxiv.org/pdf/2506.18414v2>|通过条件变分自编码器学习结构化潜在空间，实现了皮肤病变风险的可解释性建模与连续评估。|
|🆕 发布|DASH: 4D Hash Encoding with Self-Supervised Decomposition for Real-Time Dynamic Scene Rendering|DASH：用于实时动态场景渲染的自监督分解4D哈希编码|Jie Chen, Zhangchi Hu, Peixi Wu, Huyue Zhu, Hebei Li, Xiaoyan Sun|<http://arxiv.org/pdf/2507.19141v1>|[代码](https://github.com/chenj02/DASH.); 提出DASH框架，通过自监督分解和4D哈希编码实现实时动态场景渲染，提升视觉质量并避免特征重叠。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Modality Agnostic Efficient Long Range Encoder|模态无关高效长距离编码器|Toufiq Parag, Ahmed Elgammal|<http://arxiv.org/pdf/2507.19409v1>|提出了一种适用于多种模态的长距离编码架构MAELRE，通过结合token合并和注意力近似，有效降低计...|
|🆕 发布|EffiComm: Bandwidth Efficient Multi Agent Communication|EffiComm：带宽高效的多智能体通信|Melih Yazgan, Allen Xavier Arasan, J. Marius Zöllner|<http://arxiv.org/pdf/2507.19354v1>|EffiComm通过选择性传输和自适应网格缩减，减少了40%的数据传输量，同时保持3D物体检测精度。|
|🆕 发布|Preserving Topological and Geometric Embeddings for Point Cloud Recovery|保持拓扑与几何嵌入的点云恢复|Kaiyue Zhou, Zelong Tan, Hongxiao Wang, Ya-li Li, Shengjin Wang|<http://arxiv.org/pdf/2507.19121v1>|提出了一种TopGeoFormer架构，通过整合拓扑和几何特征，有效提升了点云恢复质量。|
|📝 更新|Level-Set Parameters: Novel Representation for 3D Shape Analysis|水平集参数：三维形状分析的新表示方法|Huan Lei, Hongdong Li, Andreas Geiger, Anthony Dick|<http://arxiv.org/pdf/2412.13502v2>|提出用连续的级集参数表示法分析3D形状，通过伪正态分布学习形状关系，简化了姿态相关的形状分析。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unstable Prompts, Unreliable Segmentations: A Challenge for Longitudinal Lesion Analysis|不稳定的提示，不可靠的分割：纵向病变分析的一项挑战|Niels Rocholl, Ewoud Smit, Mathias Prokop, Alessa Hering|<http://arxiv.org/pdf/2507.19230v1>|揭示了单时间点病变分割模型在纵向分析中的局限性，并倡导开发针对时间序列数据的端到端模型。|
|🆕 发布|Extreme Cardiac MRI Analysis under Respiratory Motion: Results of the CMRxMotion Challenge|极端呼吸运动下心脏磁共振成像分析：CMRxMotion挑战赛结果|Kang Wang, Chen Qin, Zhang Shi, Haoran Wang, Xiwen Zhang, Chen Chen, Cheng Ouyang, Chengliang Dai .etc.|<http://arxiv.org/pdf/2507.19165v1>|[代码](https://code are publicly available at: https://github.com/CMRxMotion); 通过组织CMRxMotion挑战，推进了深学习模型在呼吸运动影响下的心脏磁共振成像分析研究。|
|🆕 发布|Learned Image Compression with Hierarchical Progressive Context Modeling|分层渐进上下文建模的图像压缩学习|Yuqi Li, Haotian Zhang, Li Li, Dong Liu|<http://arxiv.org/pdf/2507.19125v1>|[代码](https://github.com/lyq133/LIC-HPCM.); 提出了一种分层渐进式上下文建模方法，有效提升了图像压缩的性能与效率。|
|🆕 发布|A Self-training Framework for Semi-supervised Pulmonary Vessel Segmentation and Its Application in COPD|一个用于半监督肺血管分割的自训练框架及其在慢性阻塞性肺疾病中的应用|Shuiqing Zhao, Meihuan Wang, Jiaxuan Xu, Jie Feng, Wei Qian, Rongchang Chen, Zhenyu Liang, Shouliang Qi .etc.|<http://arxiv.org/pdf/2507.19074v1>|[代码](https://github.com/wuyanan513/semi-supervised-learning-for-vessel-segmentation.); 提出了一种半监督自训练框架，通过教师-学生模型提高了肺血管分割的精度。|
|📝 更新|Stella Nera: A Differentiable Maddness-Based Hardware Accelerator for Efficient Approximate Matrix Multiplication|“Stella Nera：一种基于差异化疯狂理论的硬件加速器，用于高效近似矩阵乘法”|Jannis Schönleber, Lukas Cavigelli, Matteo Perotti, Luca Benini, Renzo Andri|<http://arxiv.org/pdf/2311.10207v2>|提出了一种基于Maddness的硬件加速器Stella Nera，通过消除乘法操作显著提升近似矩阵乘...|
|🆕 发布|UPP: Unified Point-Level Prompting for Robust Point Cloud Analysis|统一点级提示：用于鲁棒点云分析的统一点级提示|Zixiang Ai, Zhenyu Cui, Yuxin Peng, Jiahuan Zhou|<http://arxiv.org/pdf/2507.18997v1>|[代码](https://github.com/zhoujiahuan1991/ICCV2025-UPP.); 提出了一种统一点级提示方法，通过预测修正向量提示和生成辅助点提示，有效处理噪声和不完整点云数据。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DEFNet: Multitasks-based Deep Evidential Fusion Network for Blind Image Quality Assessment|DEFNet：基于多任务深度证据融合网络的盲图像质量评估|Yiwei Lou, Yuanpeng He, Rongchao Zhang, Yongzhi Cao, Hanpin Wang, Yu Huang|<http://arxiv.org/pdf/2507.19418v1>|提出了一种多任务深度证据融合网络DEFNet，通过任务协同和可信信息融合策略，有效提升了盲图像质量评...|
|🆕 发布|Enhancing Diabetic Retinopathy Classification Accuracy through Dual Attention Mechanism in Deep Learning|通过深度学习中的双注意力机制提高糖尿病视网膜病变分类准确性|Abdul Hannan, Zahid Mahmood, Rizwan Qureshi, Hazrat Ali|<http://arxiv.org/pdf/2507.19199v1>|通过融合全局和类别注意力机制，提升了糖尿病视网膜病变分类的准确性和模型泛化能力。|
|🆕 发布|Negation-Aware Test-Time Adaptation for Vision-Language Models|负样本感知的测试时适应方法用于视觉语言模型|Haochen Han, Alex Jinpeng Wang, Fangming Liu|<http://arxiv.org/pdf/2507.19064v1>|[代码](https://github.com/hhc1997/NEAT.); 提出了一种针对视觉语言模型中否定理解问题的 Negation-Aware 测试时适应方法，有效调整分...|
|📝 更新|VIBE: Video-Input Brain Encoder for fMRI Response Modeling|VIBE：基于视频输入的脑编码器用于fMRI响应建模|Daniel Carlström Schad, Shrey Dixit, Janis Keck, Viktor Studenyak, Aleksandr Shpilevoi, Andrej Bicanski|<http://arxiv.org/pdf/2507.17958v2>|提出VIBE模型，融合视频、音频和文本特征预测fMRI活动，提升预测相关性。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Transferable and Undefendable Point Cloud Attacks via Medial Axis Transform|通过中轴变换实现的迁移性和不可防御的点云攻击|Keke Tang, Yuze Gao, Weilong Peng, Xiaofei Wang, Meie Fang, Peican Zhu|<http://arxiv.org/pdf/2507.18870v1>|提出了一种增强点云攻击的转移性和不可防御性的新框架，通过扰动点云的中轴变换表示实现。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DeepJIVE: Learning Joint and Individual Variation Explained from Multimodal Data Using Deep Learning|深度JIVE：利用深度学习从多模态数据中学习联合与个体变异解释|Matthew Drexler, Benjamin Risk, James J Lah, Suprateek Kundu, Deqiang Qiu|<http://arxiv.org/pdf/2507.19682v1>|提出DeepJIVE方法，利用深度学习处理多模态数据，有效揭示共同和个体变异。|
|🆕 发布|CoopTrack: Exploring End-to-End Learning for Efficient Cooperative Sequential Perception|合作追踪：探索端到端学习以实现高效合作序列感知|Jiaru Zhong, Jiahao Wang, Jiahui Xu, Xiaofan Li, Zaiqing Nie, Haibao Yu|<http://arxiv.org/pdf/2507.19239v1>|[代码](https://github.com/zhongjiaru/CoopTrack.); 提出CoopTrack框架，通过端到端学习实现高效协同序列感知，提升多车辆系统追踪性能。|
|📝 更新|Verbalized Representation Learning for Interpretable Few-Shot Generalization|用于可解释少样本泛化的口头化表征学习|Cheng-Fu Yang, Da Yin, Wenbo Hu, Nanyun Peng, Bolei Zhou, Kai-Wei Chang|<http://arxiv.org/pdf/2411.18651v2>|[代码](https://github.com/joeyy5588/VRL); 提出了一种基于自然语言理解的少样本学习新方法，显著提升了模型泛化能力并减少了对数据的需求。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ObjectRelator: Enabling Cross-View Object Relation Understanding Across Ego-Centric and Exo-Centric Perspectives|《ObjectRelator：实现自我中心与外部中心视角下的跨视角物体关系理解》|Yuqian Fu, Runze Wang, Bin Ren, Guolei Sun, Biao Gong, Yanwei Fu, Danda Pani Paudel, Xuanjing Huang .etc.|<http://arxiv.org/pdf/2411.19083v2>|提出ObjectRelator方法，融合视觉与语言线索并利用自监督学习实现跨视角物体关联理解。|
|🆕 发布|Balancing Conservatism and Aggressiveness: Prototype-Affinity Hybrid Network for Few-Shot Segmentation|保守性与进取性平衡：原型亲和混合网络用于少样本分割|Tianyu Zou, Shengwu Xiong, Ruilin Yao, Yi Rong|<http://arxiv.org/pdf/2507.19140v1>|[代码](https://github.com/tianyu-zou/PAHNet); 提出了一种平衡保守性和激进性的原型-亲和混合网络，有效提升少量样本条件下的图像分割精度。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 交互式感知 (Interactive Perception)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Salsa as a Nonverbal Embodied Language -- The CoMPAS3D Dataset and Benchmarks|"Salsa作为一种非言语具身语言——CoMPAS3D数据集与基准测试"|Bermet Burkanova, Payam Jome Yazdian, Chuxuan Zhang, Trinity Evans, Paige Tuttösí, Angelica Lim|<http://arxiv.org/pdf/2507.19684v1>|提出CoMPAS3D数据集，为研究交互式、表现性人形机器人运动生成提供了多样化和挑战性的测试平台。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Survey on Hand Gesture Recognition from Visual Input|视觉输入下的手势识别研究综述|Manousos Linardakis, Iraklis Varlamis, Georgios Th. Papadopoulos|<http://arxiv.org/pdf/2501.11992v2>|系统梳理了手势识别的最新研究进展、解决方案和标准数据集，指出了未来研究方向。|
|📝 更新|Long-Form Answers to Visual Questions from Blind and Low Vision People|盲人和低视力人群针对视觉问题的长篇回答|Mina Huh, Fangyuan Xu, Yi-Hao Peng, Chongyan Chen, Hansika Murugu, Danna Gurari, Eunsol Choi, Amy Pavel|<http://arxiv.org/pdf/2408.06303v2>|构建了VizWiz-LF数据集，评估了视觉问答模型生成盲人可用长篇回答的能力，并探讨了减少错误细节生...|
|🆕 发布|CircuitProbe: Dissecting Spatiotemporal Visual Semantics with Circuit Tracing|电路探针：利用电路追踪解析时空视觉语义|Yiming Zhang, Chengzhang Yu, Zhuokai Zhao, Kun Wang, Qiankun Li, Zihan Chen, Yang Liu, Zenghui Ding .etc.|<http://arxiv.org/pdf/2507.19420v1>|提出了一种基于电路追踪的框架，揭示了大型视觉语言模型中时空视觉语义的处理机制。|
|📝 更新|Label Anything: Multi-Class Few-Shot Semantic Segmentation with Visual Prompts|任意标注：基于视觉提示的多类少量样本语义分割|Pasquale De Marinis, Nicola Fanelli, Raffaele Scaringi, Emanuele Colonna, Giuseppe Fiameni, Gennaro Vessio, Giovanna Castellano|<http://arxiv.org/pdf/2407.02075v3>|[代码](https://github.com/pasqualedem/LabelAnything.); 提出了一种基于transformer的多元视觉提示的多类少量样本语义分割方法，实现了标注负担大幅降低...|
|📝 更新|Accelerating Multimodal Large Language Models via Dynamic Visual-Token Exit and the Empirical Findings|通过动态视觉标记退出策略加速多模态大型语言模型及实证发现|Qiong Wu, Wenhao Lin, Yiyi Zhou, Weihao Ye, Zhanpeng Zen, Xiaoshuai Sun, Rongrong Ji|<http://arxiv.org/pdf/2411.19628v2>|[代码](https://github.com/DoubtedSteam/DyVTE.); 提出动态视觉令牌退出策略，减少冗余计算，提升多模态大语言模型效率。|
|📝 更新|Geometric Origins of Bias in Deep Neural Networks: A Human Visual System Perspective|深度神经网络中偏见的几何起源：从人眼视觉系统视角出发|Yanbiao Ma, Bowei Liu, Andi Zhang|<http://arxiv.org/pdf/2502.11809v4>|提出几何分析框架，关联DNN中感知流形的几何复杂性与其偏见形成。|
|🆕 发布|Perspective from a Higher Dimension: Can 3D Geometric Priors Help Visual Floorplan Localization?|从一个更高维度的视角：三维几何先验能帮助视觉平面图定位吗？|Bolei Chen, Jiaxu Kang, Haonan Yang, Ping Zhong, Jianxin Wang|<http://arxiv.org/pdf/2507.18881v1>|引入3D几何先验知识以增强视觉定位准确性，减少视觉变化和遮挡带来的误差。|
|🆕 发布|Phoneme-Level Visual Speech Recognition via Point-Visual Fusion and Language Model Reconstruction|通过点视觉融合和语言模型重建的音素级视觉语音识别|Matthew Kit Khinn Teng, Haibo Zhang, Takeshi Saitoh|<http://arxiv.org/pdf/2507.18863v1>|提出了一种融合视觉和面部特征的两阶段框架，通过语言模型重建显著降低了视觉语音识别的错误率。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MMBench-GUI: Hierarchical Multi-Platform Evaluation Framework for GUI Agents|MMBench-GUI：面向GUI智能体的分层多平台评估框架|Xuehui Wang, Zhenyu Wu, JingJing Xie, Zichen Ding, Bowen Yang, Zehao Li, Zhaoyang Liu, Qingyun Li .etc.|<http://arxiv.org/pdf/2507.19478v1>|[代码](https://github.com/open-compass/MMBench-GUI.); 提出MMBench-GUI，跨平台评估GUI自动化代理性能，引入EQA效率质量指标。|
|🆕 发布|LOTUS: A Leaderboard for Detailed Image Captioning from Quality to Societal Bias and User Preferences|LOTUS：从质量到社会偏见及用户偏好详细图像描述的排行榜|Yusuke Hirota, Boyi Li, Ryo Hachiuma, Yueh-Hua Wu, Boris Ivanovic, Yuta Nakashima, Marco Pavone, Yejin Choi .etc.|<http://arxiv.org/pdf/2507.19362v1>|提出LOTUS排行榜，全面评估详细图像描述的质量、偏见和用户偏好。|
|📝 更新|All in One: Visual-Description-Guided Unified Point Cloud Segmentation|一体化：视觉描述引导的统一点云分割|Zongyan Han, Mohamed El Amine Boudjoghra, Jiahua Dong, Jinhong Wang, Rao Muhammad Anwer|<http://arxiv.org/pdf/2507.05211v2>|[代码](https://github.com/Hanzy1996/VDG-Uni3DSeg.); 整合视觉描述与大型语言模型，提出VDG-Uni3DSeg框架，提升3D点云精细分割性能。|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LISA: A Layer-wise Integration and Suppression Approach for Hallucination Mitigation in Multimodal Large Language Models|LISA：一种用于多模态大型语言模型中减少幻觉的逐层整合与抑制方法|Zhihui Guo, Xin Man, Hui Xu, Jie Shao|<http://arxiv.org/pdf/2507.19110v1>|提出了一种层级整合与抑制方法LISA，有效减少大型多模态语言模型在图像描述中的物体虚造现象。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bias Analysis for Synthetic Face Detection: A Case Study of the Impact of Facial Attribute|合成人脸检测的偏见分析：面部属性影响的案例研究|Asmae Lamsaf, Lucia Cascone, Hugo Proença, João Neves|<http://arxiv.org/pdf/2507.19705v1>|提出了一种评估框架，揭示了合成人脸检测器在不同面部属性上的偏见，并分析了偏见来源。|
|🆕 发布|Pre- and Post-Treatment Glioma Segmentation with the Medical Imaging Segmentation Toolkit|治疗前后的胶质瘤分割：基于医学影像分割工具包的方法|Adrian Celaya, Tucker Netherton, Dawid Schellingerhout, Caroline Chung, Beatrice Riviere, David Fuentes|<http://arxiv.org/pdf/2507.19626v1>|介绍了Medical Imaging Segmentation Toolkit (MIST)，其模块...|
|🆕 发布|Exemplar Med-DETR: Toward Generalized and Robust Lesion Detection in Mammogram Images and beyond|示例中介-DETR：面向乳腺X线照片图像及以外的通用和稳健病变检测|Sheethal Bhat, Bogdan Georgescu, Adarsh Bhandary Panambur, Mathias Zinnen, Tri-Thien Nguyen, Awais Mansoor, Karim Khalifa Elbarbary, Siming Bayer .etc.|<http://arxiv.org/pdf/2507.19621v1>|提出了一种多模态对比检测器Exemplar Med-DETR，通过使用直观的类特定样本特征，显著提升...|
|📝 更新|MLRU++: Multiscale Lightweight Residual UNETR++ with Attention for Efficient 3D Medical Image Segmentation|MLRU++：用于高效三维医学图像分割的多尺度轻量级残差UNETR++注意力模型|Nand Kumar Yadav, Rodrigue Rizk, William CW Chen, KC Santosh|<http://arxiv.org/pdf/2507.16122v3>|[代码](https://github.com/1027865/MLRUPP); 提出MLRU++架构，通过轻量级注意力和多尺度聚合提升3D医疗图像分割精度与效率。|
|🆕 发布|Tuning adaptive gamma correction (TAGC) for enhancing images in low ligh|调整自适应伽马校正（TAGC）以增强低光照下的图像|Ghufran Abualhail Alhamzawi, Ali Saeed Alfoudi, Ali Hakem Alsaeedi, Suha Mohammed Hadi, Amjed Abbas Ahmed, Md. Riad Hassan, Nurhizam Safie Mohd Satar, Waeel Yahya Yasseen|<http://arxiv.org/pdf/2507.19574v1>|提出了一种自动调整伽马值的图像增强模型TAGC，有效改善低光照条件下图像质量。|
|🆕 发布|Is Exchangeability better than I.I.D to handle Data Distribution Shifts while Pooling Data for Data-scarce Medical image segmentation?|“在数据匮乏的医疗图像分割中，交换性是否比独立同分布（I.I.D）更能有效处理数据分布偏移？”|Ayush Roy, Samin Enam, Jun Xia, Vishnu Suresh Lokhande, Won Hwa Kim|<http://arxiv.org/pdf/2507.19575v1>|提出了一种利用交换性假设处理多源数据分布偏移的医疗图像分割方法，实现了优于传统独立同分布的分割性能。|
|🆕 发布|ABCD: Automatic Blood Cell Detection via Attention-Guided Improved YOLOX|ABCD: 基于注意力引导改进的YOLOX的自动血细胞检测|Ahmed Endris Hasen, Yang Shangming, Chiagoziem C. Ukwuoma, Biniyam Gashaw, Abel Zenebe Yutra|<http://arxiv.org/pdf/2507.19296v1>|提出了一种基于改进YOLOX的自动血细胞检测方法，通过引入CBAM和ASFF提升检测性能，并使用CI...|
|🆕 发布|SimMLM: A Simple Framework for Multi-modal Learning with Missing Modality|SimMLM：一种用于处理缺失模态的多模态学习简单框架|Sijie Li, Chen Chen, Jungong Han|<http://arxiv.org/pdf/2507.19264v1>|提出SimMLM框架，通过动态调整模态贡献提升缺失模态下的多模态学习准确性和鲁棒性。|
|📝 更新|Framework of a multiscale data-driven DT of the musculoskeletal system|多尺度数据驱动肌肉骨骼系统动态树框架|Martina Paccini, Simone Cammarasana, Giuseppe Patanè|<http://arxiv.org/pdf/2506.11821v2>|提出了一种集成多尺度生物力学数据的肌肉骨骼数字孪生框架，用于精确监测和个性化治疗肌肉骨骼疾病。|
|🆕 发布|Reconstruct or Generate: Exploring the Spectrum of Generative Modeling for Cardiac MRI|重建还是生成：探索心脏磁共振成像生成模型的光谱范围|Niklas Bubeck, Yundi Zhang, Suprosanna Shit, Daniel Rueckert, Jiazhen Pan|<http://arxiv.org/pdf/2507.19186v1>|分析了生成模型在心脏磁共振成像任务中的重建与生成能力，发现扩散模型在无条件生成中表现更佳，而自回归模...|
|🆕 发布|Continual Learning-Based Unified Model for Unpaired Image Restoration Tasks|基于持续学习的统一模型用于无配对图像修复任务|Kotha Kartheek, Lingamaneni Gnanesh Chowdary, Snehasis Mukherjee|<http://arxiv.org/pdf/2507.19184v1>|提出了一种基于持续学习的统一模型，有效应对多种天气条件下的图像复原挑战。|
|📝 更新|ViCTr: Vital Consistency Transfer for Pathology Aware Image Synthesis|ViCTr：病理感知图像合成中的关键一致性迁移|Onkar Susladkar, Gayatri Deshmukh, Yalcin Tur, Gorkhem Durak, Ulas Bagci|<http://arxiv.org/pdf/2505.04963v3>|提出ViCTr框架，通过两阶段流程实现高保真度、病理特征明显的医学图像合成。|
|🆕 发布|MedSymmFlow: Bridging Generative Modeling and Classification in Medical Imaging through Symmetrical Flow Matching|MedSymmFlow：通过对称流匹配在医学成像中连接生成模型与分类|Francisco Caetano, Lemar Abdi, Christiaan Viviers, Amaan Valiuddin, Fons van der Sommen|<http://arxiv.org/pdf/2507.19098v1>|提出了一种融合生成模型与分类模型的MedSymmFlow方法，通过对称流匹配在医疗影像中实现分类、生...|
|🆕 发布|SP-Mamba: Spatial-Perception State Space Model for Unsupervised Medical Anomaly Detection|SP-Mamba：用于无监督医学异常检测的空间感知状态空间模型|Rui Pan, Ruiying Lu|<http://arxiv.org/pdf/2507.19076v1>|[代码](https://github.com/Ray-RuiPan/SP-Mamba.); 提出SP-Mamba模型，利用医学图像的结构规律性进行无监督异常检测，提升检测性能。|
|🆕 发布|Dual Path Learning -- learning from noise and context for medical image denoising|双路径学习——从噪声和上下文中学习用于医学图像去噪|Jitindra Fartiyal, Pedro Freire, Yasmeen Whayeb, James S. Wolffsohn, Sergei K. Turitsyn, Sergei G. Sokolov|<http://arxiv.org/pdf/2507.19035v1>|提出了一种双路径学习模型，通过结合噪声特征和图像上下文信息，有效提升医学图像去噪质量和泛化能力。|
|🆕 发布|A New One-Shot Federated Learning Framework for Medical Imaging Classification with Feature-Guided Rectified Flow and Knowledge Distillation|一种基于特征引导修正流和知识蒸馏的新单次联邦学习框架用于医学影像分类|Yufei Ma, Hanwen Zhang, Qiya Yang, Guibo Luo, Yuesheng Zhu|<http://arxiv.org/pdf/2507.19045v1>|提出了一种改进的一回合联邦学习框架，通过特征引导的修正流模型和双层知识蒸馏，有效解决了医疗影像分类中...|
|📝 更新|MagicDrive3D: Controllable 3D Generation for Any-View Rendering in Street Scenes|MagicDrive3D：面向街道场景任意视角渲染的可控3D生成|Ruiyuan Gao, Kai Chen, Zhihao Li, Lanqing Hong, Zhenguo Li, Qiang Xu|<http://arxiv.org/pdf/2405.14475v4>|MagicDrive3D通过结合视频视图合成与3D场景生成，实现了对街道场景的灵活控制和高质量任意视...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Co-Win: Joint Object Detection and Instance Segmentation in LiDAR Point Clouds via Collaborative Window Processing|协同窗口处理下的激光雷达点云联合目标检测与实例分割：Co-Win|Haichuan Li, Tomi Westerlund|<http://arxiv.org/pdf/2507.19691v1>|提出了一种集成点云编码与窗口特征提取的BEV感知框架，通过可解释的实例分割提升自动驾驶系统在复杂环境...|
|📝 更新|TARS: Traffic-Aware Radar Scene Flow Estimation|TARS：交通感知雷达场景流估计|Jialong Wu, Marco Braun, Dominic Spata, Matthias Rottmann|<http://arxiv.org/pdf/2503.10210v2>|提出了一种交通感知的雷达场景流估计方法TARS，通过结合物体检测与场景流估计，提升了雷达点云场景流估...|
|🆕 发布|SIDE: Sparse Information Disentanglement for Explainable Artificial Intelligence|SIDE：可解释人工智能的稀疏信息解耦|Viktar Dubovik, Łukasz Struski, Jacek Tabor, Dawid Rymarczyk|<http://arxiv.org/pdf/2507.19321v1>|提出Sparse Information Disentanglement方法，通过训练和剪枝增强原型...|
|🆕 发布|RemoteReasoner: Towards Unifying Geospatial Reasoning Workflow|RemoteReasoner：迈向统一地理空间推理工作流程|Liang Yao, Fan Liu, Hongbo Lu, Chuanyi Zhang, Rui Min, Shengxiang Xu, Shimin Di, Pai Peng|<http://arxiv.org/pdf/2507.19280v1>|提出了一种灵活且强大的远程感知推理工作流RemoteReasoner，通过强化学习实现自主推理，支持...|
|🆕 发布|Querying Autonomous Vehicle Point Clouds: Enhanced by 3D Object Counting with CounterNet|查询自动驾驶车辆点云：通过CounterNet增强的3D目标计数|Xiaoyu Zhang, Zhifeng Bao, Hai Dong, Ziwei Wang, Jiajun Liu|<http://arxiv.org/pdf/2507.19209v1>|提出CounterNet网络，通过检测对象中心提高大规模点云数据中的对象计数准确性。|
|🆕 发布|Cross Spatial Temporal Fusion Attention for Remote Sensing Object Detection via Image Feature Matching|通过图像特征匹配的远程遥感目标检测跨时空融合注意力方法|Abu Sadat Mohammad Salehin Amit, Xiaoli Zhang, Md Masum Billa Shagar, Zhaojun Liu, Xiongfei Li, Fanlong Meng|<http://arxiv.org/pdf/2507.19118v1>|提出了一种跨时空融合注意机制，通过独立检测并整合多模态遥感图像的尺度不变关键点，有效提升了特征匹配和...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Event-Based De-Snowing for Autonomous Driving|基于事件的自动驾驶去雪技术|Manasi Muglikar, Nico Messikommer, Marco Cannici, Davide Scaramuzza|<http://arxiv.org/pdf/2507.20901v1>|提出了一种基于事件相机和注意力模块的除雪方法，有效提升了恶劣天气下自动驾驶视觉系统的可靠性和安全性。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GS-Occ3D: Scaling Vision-only Occupancy Reconstruction for Autonomous Driving with Gaussian Splatting|GS-Occ3D：利用高斯散点绘制扩展仅视觉占用重建在自动驾驶中的应用|Baijun Ye, Minghui Qin, Saining Zhang, Moonjun Gong, Shaoting Zhu, Zebang Shen, Luan Zhang, Lu Zhang .etc.|<http://arxiv.org/pdf/2507.19451v1>|提出了一种无需激光雷达标注的视觉占用重建框架GS-Occ3D，通过优化显式占用表示，实现了高效的大规...|
|🆕 发布|BEV-LLM: Leveraging Multimodal BEV Maps for Scene Captioning in Autonomous Driving|BEV-LLM：利用多模态BEV地图进行自动驾驶场景描述|Felix Brandstaetter, Erik Schuetz, Katharina Winter, Fabian Flohr|<http://arxiv.org/pdf/2507.19370v1>|提出BEV-LLM模型，融合3D数据和图像，提升自动驾驶场景描述的准确性和透明度。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Fine-Grained Traffic Inference from Road to Lane via Spatio-Temporal Graph Node Generation|从道路到车道的细粒度交通推理：基于时空图节点生成方法|Shuhao Li, Weidong Yang, Yue Cui, Xiaoxing Liu, Lingkai Meng, Lipeng Ma, Fan Zhang|<http://arxiv.org/pdf/2507.19089v1>|[代码](https://github.com/ShuhaoLii/RoadDiff.); 提出Fine-Grained Road Traffic Inference任务，通过RoadDiff...|
|📝 更新|MagicDrive-V2: High-Resolution Long Video Generation for Autonomous Driving with Adaptive Control|MagicDrive-V2：自适应控制下的自动驾驶高分辨率长视频生成|Ruiyuan Gao, Kai Chen, Bo Xiao, Lanqing Hong, Zhenguo Li, Qiang Xu|<http://arxiv.org/pdf/2411.13807v4>|MagicDrive-V2通过集成MVDiT模块和时空条件编码，实现了高分辨率长视频生成及精确几何控...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Information Extraction from Unstructured data using Augmented-AI and Computer Vision|利用增强人工智能和计算机视觉从非结构化数据中提取信息|Aditya Parikh|<http://arxiv.org/pdf/2312.09880v2>|提出了一种结合增强智能与计算机视觉技术的信息提取框架，有效提升了处理大规模非结构化文档的准确性和效率...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|WACA-UNet: Weakness-Aware Channel Attention for Static IR Drop Prediction in Integrated Circuit Design|WACA-UNet：面向静态红外下降预测的弱点感知通道注意力网络，用于集成电路设计|Youngmin Seo, Yunhyeong Kwon, Younghun Park, HwiRyong Kim, Seungho Eum, Jinha Kim, Taigon Song, Juho Kim .etc.|<http://arxiv.org/pdf/2507.19197v1>|定位IR降预测难题，提出WACA-UNet方法，通过弱特征通道增强显著提升预测精度。|
|📝 更新|Interaction-Merged Motion Planning: Effectively Leveraging Diverse Motion Datasets for Robust Planning|交互融合运动规划：有效利用多样化运动数据集以实现鲁棒规划|Giwon Lee, Wooseong Jeong, Daehee Park, Jaewoo Jeong, Kuk-Jin Yoon|<http://arxiv.org/pdf/2507.04790v3>|提出了一种融合交互信息的运动规划方法，有效利用不同领域数据集提升自主机器人驾驶的稳健性。|
|📝 更新|Multispectral Demosaicing via Dual Cameras|通过双摄像头实现的多光谱去马赛克处理|SaiKiran Tedla, Junyong Lee, Beixuan Yang, Mahmoud Afifi, Michael S. Brown|<http://arxiv.org/pdf/2503.22026v3>|利用双摄像头系统，通过高精度RGB图像引导，实现了多光谱图像的高效去马赛克处理。|
|📝 更新|Tuned Reverse Distillation: Enhancing Multimodal Industrial Anomaly Detection with Crossmodal Tuners|调谐反向蒸馏：利用跨模态调谐器增强多模态工业异常检测|Xinyue Liu, Jianyuan Wang, Biao Leng, Shuo Zhang|<http://arxiv.org/pdf/2412.08949v3>|[代码](https://github.com/hito2448/TRD.); 提出了一种多模态工业异常检测方法Tuned Reverse Distillation，通过独立分支和...|

