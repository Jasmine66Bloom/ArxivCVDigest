## [UPDATED!] **2025-07-26** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MemeBLIP2: A novel lightweight multimodal system to detect harmful memes|MemeBLIP2：一种用于检测有害表情包的新型轻量级多模态系统|Jiaqi Liu, Ran Tong, Aowei Shen, Shuzheng Li, Changlin Yang, Lisha Xu|<http://arxiv.org/pdf/2504.21226v3>|提出了一种轻量级的多模态系统MemeBLIP2，有效结合图像与文本特征以检测有害表情包。|
|📝 更新|Generative AI in Agriculture: Creating Image Datasets Using DALL.E's Advanced Large Language Model Capabilities|农业中的生成式人工智能：利用DALL.E高级大型语言模型能力创建图像数据集|Ranjan Sapkota, Manoj Karkee|<http://arxiv.org/pdf/2307.08789v6>|利用DALL.E模型生成逼真农业图像数据集，提升精准农业成像技术发展。|
|📝 更新|Unreal is all you need: Multimodal ISAC Data Simulation with Only One Engine|“虚拟即是全部所需：仅用一个引擎实现多模态ISAC数据仿真”|Kongwu Huang, Shiyi Mu, Jun Jiang, Yuan Gao, Shugong Xu|<http://arxiv.org/pdf/2507.08716v3>|[代码](https://github.com/hkw-xg/Great-MCD.); 提出Great-X平台，实现单引擎多模态数据仿真，构建大规模多模态无人机感知数据集并验证算法可行性。|
|🆕 发布|Predicting Brain Responses To Natural Movies With Multimodal LLMs|用多模态大型语言模型预测大脑对自然电影的反应|Cesar Kadir Torrico Villanueva, Jiaxin Cindy Tu, Mihir Tripathy, Connor Lane, Rishab Iyer, Paul S. Scotti|<http://arxiv.org/pdf/2507.19956v1>|融合多模态预训练模型特征，采用共享与个体定制轻量级编码器，提升了脑响应预测模型的泛化能力。|
|📝 更新|TextSAM-EUS: Text Prompt Learning for SAM to Accurately Segment Pancreatic Tumor in Endoscopic Ultrasound|文本SAM-EUS：用于内窥镜超声下准确分割胰腺肿瘤的SAM文本提示学习|Pascal Spiegler, Taha Koleilat, Arash Harirpoush, Corey S. Miller, Hassan Rivaz, Marta Kersten-Oertel, Yiming Xiao|<http://arxiv.org/pdf/2507.18082v2>|提出了一种基于文本提示的胰腺肿瘤内窥超声图像自动分割方法，提升了准确度且减少了依赖大量标注数据的需求...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Activator: GLU Activation Function as the Core Component of a Vision Transformer|激活器：GLU激活函数作为视觉变换器的核心组件|Abdullah Nazhat Abdullah, Tarkan Aydin|<http://arxiv.org/pdf/2405.15953v3>|提出了一种基于门控线性单元（GLU）的视觉Transformer架构，降低了计算复杂度同时保持性能。|
|📝 更新|A Memory-Efficient Framework for Deformable Transformer with Neural Architecture Search|《一种基于神经架构搜索的内存高效可变形Transformer框架》|Wendong Mao, Mingfan Zhao, Jianfeng Guan, Qiwei Dong, Zhongfeng Wang|<http://arxiv.org/pdf/2507.11549v2>|提出硬件友好的优化框架，通过神经架构搜索降低变形变换器的内存访问冲突，实现高效硬件部署。|
|🆕 发布|Smaller, Faster, Cheaper: Architectural Designs for Efficient Machine Learning|更小、更快、更经济：高效机器学习的架构设计|Steven Walton|<http://arxiv.org/pdf/2507.19795v1>|提出高效神经网络架构设计，实现机器学习模型性能提升同时降低计算需求。|
|📝 更新|MTCAE-DFER: Multi-Task Cascaded Autoencoder for Dynamic Facial Expression Recognition|多任务级联自动编码器用于动态面部表情识别（MTCAE-DFER）|Peihao Xiang, Kaida Wu, Ou Bai|<http://arxiv.org/pdf/2412.18988v2>|提出了一种多任务级联自动编码器，通过全局与局部特征互动提升动态面部表情识别的泛化能力。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VAMPIRE: Uncovering Vessel Directional and Morphological Information from OCTA Images for Cardiovascular Disease Risk Factor Prediction|吸血鬼：从OCTA图像中挖掘血管方向和形态信息以预测心血管疾病风险因素|Lehan Wang, Hualiang Wang, Chubin Ou, Lushi Chen, Yunyi Liang, Xiaomeng Li|<http://arxiv.org/pdf/2507.20017v1>|[代码](https://github.com/xmed-lab/VAMPIRE.); 提出了一种基于OCTA图像的VAMPIRE模型，用于心血管疾病风险及其相关条件的联合预测。|
|📝 更新|From General to Specialized: The Need for Foundational Models in Agriculture|从通用到专用：农业领域基础模型的必要性|Vishal Nedungadi, Xingguo Xiong, Aike Potze, Ron Van Bree, Tao Lin, Marc Rußwurm, Ioannis N. Athanasiadis|<http://arxiv.org/pdf/2507.05390v2>|提出农业领域专用基础模型框架，并实证评估现有模型在农业任务中的效果。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PaRCE: Probabilistic and Reconstruction-based Competency Estimation for CNN-based Image Classification|PaRCE：基于概率和重建的卷积神经网络图像分类能力估计|Sara Pohland, Claire Tomlin|<http://arxiv.org/pdf/2411.16715v3>|提出了一种名为PaRCE的方法，通过概率和重建估计CNN图像分类模型的置信度，有效区分正确、错误分类...|
|🆕 发布|ForCenNet: Foreground-Centric Network for Document Image Rectification|ForCenNet：面向前景的文档图像矫正网络|Peng Cai, Qiang Li, Kaicheng Yang, Dong Guo, Jia Li, Nan Zhou, Xiang An, Ninghua Yang .etc.|<http://arxiv.org/pdf/2507.19804v1>|[代码](https://github.com/caipeng328/ForCenNet.); 提出 foreground-centric 网络矫正文档图像几何变形，通过增强前景元素区分度实现更精...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Interpretable Open-Vocabulary Referring Object Detection with Reverse Contrast Attention|具有反向对比注意力的可解释开放词汇指引用对象检测|Drandreb Earl O. Juanico, Rowel O. Atienza, Jeffrey Kenneth Go|<http://arxiv.org/pdf/2507.19891v1>|提出Reverse Contrast Attention方法，提升视觉语言模型在开放词汇指引用对象检...|
|🆕 发布|DS-Det: Single-Query Paradigm and Attention Disentangled Learning for Flexible Object Detection|DS-Det: 单查询范式与注意力解耦学习用于灵活的目标检测|Guiping Cao, Xiangyuan Lan, Wenjian Huang, Jianguo Zhang, Dongmei Jiang, Yaowei Wang|<http://arxiv.org/pdf/2507.19807v1>|[代码](https://github.com/Med-Process/DS-Det); 提出单查询范式和注意力解耦学习，实现灵活物体检测并提升解码器效率。|
|📝 更新|Find First, Track Next: Decoupling Identification and Propagation in Referring Video Object Segmentation|“先找到，再跟踪：在视频目标分割中解耦识别与传播”|Suhwan Cho, Seunghoon Lee, Minhyeok Lee, Jungho Lee, Sangyoun Lee|<http://arxiv.org/pdf/2503.03492v2>|提出了一种分离目标识别与掩膜传播的FindTrack框架，有效解决了视频对象分割中的目标识别模糊和掩...|
|🆕 发布|Latest Object Memory Management for Temporally Consistent Video Instance Segmentation|时间一致性的视频实例分割中的最新对象记忆管理|Seunghun Lee, Jiwan Seo, Minwoo Choi, Kiljoon Han, Jaehoon Jeong, Zane Durante, Ehsan Adeli, Sang Hyun Park .etc.|<http://arxiv.org/pdf/2507.19754v1>|[代码](https://seung-hun-lee.github.io/projects); 提出Latest Object Memory Management方法，通过持续更新对象状态，实现了...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ConSeg: Contextual Backdoor Attack Against Semantic Segmentation|ConSeg: 面向语义分割的上下文后门攻击|Bilal Hussain Abbasi, Zirui Gong, Yanjun Zhang, Shang Gao, Antonio Robles-Kelly, Leo Zhang|<http://arxiv.org/pdf/2507.19905v1>|提出了一种利用上下文信息的ConSeg攻击方法，有效提高了语义分割模型中的后门攻击成功率。|
|🆕 发布|A Structure-aware and Motion-adaptive Framework for 3D Human Pose Estimation with Mamba|一个基于结构感知和运动自适应的框架：使用Mamba进行三维人体姿态估计|Ye Lu, Jie Wang, Jianjun Gao, Rui Gong, Chen Cai, Kim-Hui Yap|<http://arxiv.org/pdf/2507.19852v1>|提出结构感知与运动自适应框架，提升三维人体姿态估计准确性并降低计算成本。|
|🆕 发布|Knowledge Regularized Negative Feature Tuning for Out-of-Distribution Detection with Vision-Language Models|知识正则化的负特征调整用于视觉语言模型在分布外检测|Wenjie Zhu, Yabin Zhang, Xin Jin, Wenjun Zeng, Lei Zhang|<http://arxiv.org/pdf/2507.19847v1>|[代码](https://github.com/ZhuWenjie98/KRNFT); 提出知识正则化的负特征调整方法，提升视觉语言模型在未见过分布数据上的检测性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|The Devil is in the EOS: Sequence Training for Detailed Image Captioning|《细节图像标注的序列训练：魔鬼藏在EOS中》|Abdelrahman Mohamed, Yova Kementchedjhieva|<http://arxiv.org/pdf/2507.20077v1>|提出了一种无监督方法减轻模型对结束符的偏见，生成更长更详细的图像描述。|
|📝 更新|A Lesson in Splats: Teacher-Guided Diffusion for 3D Gaussian Splats Generation with 2D Supervision|《散斑教学：在二维监督下用于生成三维高斯散斑的教师引导扩散方法》|Chensheng Peng, Ido Sobol, Masayoshi Tomizuka, Kurt Keutzer, Chenfeng Xu, Or Litany|<http://arxiv.org/pdf/2412.00623v3>|提出了一种仅使用2D监督训练3D图像生成模型的框架，通过教师指导的扩散方法提高了生成质量。|
|🆕 发布|KB-DMGen: Knowledge-Based Global Guidance and Dynamic Pose Masking for Human Image Generation|基于知识的全局指导与动态姿态遮罩的人像生成方法：KB-DMGen|Shibang Liu, Xuemei Xie, Guangming Shi|<http://arxiv.org/pdf/2507.20083v1>|提出KB-DMGen方法，通过知识库全局引导和动态姿态遮蔽，同时确保图像质量和姿态准确性。|
|📝 更新|Multi-Person Interaction Generation from Two-Person Motion Priors|从两人运动先验生成多人交互行为|Wenning Xu, Shiyu Fan, Paul Henderson, Edmond S. L. Ho|<http://arxiv.org/pdf/2505.17860v2>|提出了一种基于图结构分解两人运动模型生成多样化且真实的多人在交互运动的方法。|
|🆕 发布|FROSS: Faster-than-Real-Time Online 3D Semantic Scene Graph Generation from RGB-D Images|FROSS：从RGB-D图像实现实时更快的在线三维语义场景图生成|Hao-Yu Hou, Chun-Yi Lee, Motoharu Sonogashira, Yasutomo Kawanishi|<http://arxiv.org/pdf/2507.19993v1>|[代码](https://github.com/Howardkhh/FROSS.); 提出FROSS方法，实现实时3D场景图生成，提升速度并降低计算需求。|
|📝 更新|VisualCloze: A Universal Image Generation Framework via Visual In-Context Learning|视觉Cloze：通过视觉情境学习实现的通用图像生成框架|Zhong-Yu Li, Ruoyi Du, Juncheng Yan, Le Zhuo, Zhen Li, Peng Gao, Zhanyu Ma, Ming-Ming Cheng|<http://arxiv.org/pdf/2504.07960v2>|提出VisualCloze框架，通过视觉演示学习支持多种图像生成任务，增强通用性和泛化能力。|
|📝 更新|BadPatch: Diffusion-Based Generation of Physical Adversarial Patches|BadPatch：基于扩散的物理对抗性补丁生成|Zhixiang Wang, Xingjun Ma, Yu-Gang Jiang|<http://arxiv.org/pdf/2412.01440v4>|提出BadPatch框架，通过扩散模型生成自然且可定制的对抗性补丁，平衡攻击效果与隐蔽性。|
|🆕 发布|SCALAR: Scale-wise Controllable Visual Autoregressive Learning|SCALAR：尺度可控的视觉自回归学习|Ryan Xu, Dongyang Jin, Yancheng Bai, Rui Lan, Xu Duan, Lei Sun, Xiangxiang Chu|<http://arxiv.org/pdf/2507.19946v1>|提出了一种基于视觉自回归模型的细粒度可控图像生成方法SCALAR，通过创新的尺度条件解码机制提高了生...|
|🆕 发布|LLMControl: Grounded Control of Text-to-Image Diffusion-based Synthesis with Multimodal LLMs|LLMControl：基于多模态LLM的文本到图像扩散合成 grounded 控制|Jiaze Wang, Rui Chen, Haowang Cui|<http://arxiv.org/pdf/2507.19939v1>|提出LLM_Control框架，利用多模态语言模型精确控制文本到图像生成，提升复杂场景下的合成质量。|
|🆕 发布|FineMotion: A Dataset and Benchmark with both Spatial and Temporal Annotation for Fine-grained Motion Generation and Editing|细粒度运动生成与编辑的空间和时间标注数据集及基准：FineMotion|Bizhu Wu, Jinheng Xie, Meidan Ding, Zhe Kong, Jianfeng Ren, Ruibin Bai, Rong Qu, Linlin Shen|<http://arxiv.org/pdf/2507.19850v1>|提出FineMotion数据集，通过详细描述增强文本驱动的细粒度人体运动生成与编辑。|
|🆕 发布|ChoreoMuse: Robust Music-to-Dance Video Generation with Style Transfer and Beat-Adherent Motion|ChoreoMuse：具有风格迁移和节拍适应运动的鲁棒音乐舞动视频生成|Xuanchen Wang, Heng Wang, Weidong Cai|<http://arxiv.org/pdf/2507.19836v1>|ChoreoMuse通过结合音乐编码与风格控制的扩散框架，实现了与音乐节奏和舞蹈风格高度协调的高保真...|
|📝 更新|Qffusion: Controllable Portrait Video Editing via Quadrant-Grid Attention Learning|四分格注意力学习驱动的可控人像视频编辑：Qffusion|Maomao Li, Lijian Lin, Yunfei Liu, Ye Zhu, Yu Li|<http://arxiv.org/pdf/2501.06438v3>|[代码](https://qffusion.github.io/page); 提出Qffusion框架，通过四象限网格注意力学习实现可控的人像视频编辑。|
|📝 更新|Text-to-Image Generation Via Energy-Based CLIP|基于能量CLIP的文本到图像生成|Roy Ganz, Michael Elad|<http://arxiv.org/pdf/2408.17046v2>|提出CLIP-JEM方法，利用CLIP将图像生成扩展到多模态领域，实现文本到真实图像的高效生成。|
|🆕 发布|SeeDiff: Off-the-Shelf Seeded Mask Generation from Diffusion Models|SeeDiff：基于扩散模型的现成种子掩码生成|Joon Hyun Park, Kumju Jo, Sungyong Baik|<http://arxiv.org/pdf/2507.19808v1>|提出了一种无需人工标注的图像分割方法SeeDiff，利用Stable Diffusion模型自动生成...|
|📝 更新|MaterialPicker: Multi-Modal DiT-Based Material Generation|材料选择器：基于多模态DiT的材料生成|Xiaohe Ma, Valentin Deschaintre, Miloš Hašan, Fujun Luan, Kun Zhou, Hongzhi Wu, Yiwei Hu|<http://arxiv.org/pdf/2412.03225v3>|提出MaterialPicker，一种基于扩散变换架构的多模态材料生成方法，通过文本提示或照片简化高...|
|🆕 发布|DepthFlow: Exploiting Depth-Flow Structural Correlations for Unsupervised Video Object Segmentation|深度流：利用深度-流结构相关性进行无监督视频对象分割|Suhwan Cho, Minhyeok Lee, Jungho Lee, Donghyeong Kim, Sangyoun Lee|<http://arxiv.org/pdf/2507.19790v1>|提出了一种利用深度-光流结构关联的DepthFlow方法，通过合成光流数据解决无监督视频对象分割训练...|
|📝 更新|Generalizable Targeted Data Poisoning against Varying Physical Objects|《针对变化物理对象的可泛化目标数据投毒攻击》|Zhizhen Chen, Zhengyu Zhao, Subrat Kishore Dutta, Chenhao Lin, Chao Shen, Xiao Zhang|<http://arxiv.org/pdf/2412.03908v2>|提出方法优化梯度方向与幅度，提高针对不同物理条件下的数据投毒泛化能力。|
|📝 更新|StrandHead: Text to Hair-Disentangled 3D Head Avatars Using Human-Centric Priors|《StrandHead：基于以人为本先验知识的文本到头发解耦的3D头像生成》|Xiaokun Sun, Zeyu Cai, Ying Tai, Jian Yang, Zhenyu Zhang|<http://arxiv.org/pdf/2412.11586v3>|[代码](https://xiaokunsun.github.io/StrandHead.github.io); 提出了一种基于文本驱动的3D头发生成方法，实现了头发与头部解耦的3D头像建模。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|The DeepSpeak Dataset|深度语音数据集|Sarah Barrington, Matyas Bohacek, Hany Farid|<http://arxiv.org/pdf/2408.05366v4>|构建了大规模多模态DeepSpeak数据集，包含真实与高质量深伪音视频，提升深伪检测模型泛化能力。|
|📝 更新|Chimera: Improving Generalist Model with Domain-Specific Experts|“奇美拉：通过领域特定专家改进通用模型”|Tianshuo Peng, Mingsheng Li, Jiakang Yuan, Hongbin Zhou, Renqiu Xia, Renrui Zhang, Lei Bai, Song Mao .etc.|<http://arxiv.org/pdf/2412.05983v3>|提出Chimera方法，融合领域专家模型提升通用模型在特定领域的性能。|
|🆕 发布|ATCTrack: Aligning Target-Context Cues with Dynamic Target States for Robust Vision-Language Tracking|ATCTrack：通过动态目标状态对齐目标-上下文线索以实现稳健的视觉-语言跟踪|X. Feng, S. Hu, X. Li, D. Zhang, M. Wu, J. Zhang, X. Chen, K. Huang|<http://arxiv.org/pdf/2507.19875v1>|[代码](https://github.com/XiaokunFeng/ATCTrack.); 提出了一种动态调整目标与上下文线索对齐的多模态跟踪方法，有效提升了复杂场景下的视觉语言跟踪鲁棒性。|
|📝 更新|End-to-End Fine-Tuning of 3D Texture Generation using Differentiable Rewards|使用可微分奖励的3D纹理生成端到端微调|AmirHossein Zamani, Tianhao Xie, Amir G. Aghdam, Tiberiu Popa, Eugene Belilovsky|<http://arxiv.org/pdf/2506.18331v2>|提出了一种将人类反馈嵌入3D纹理生成的端到端可微分框架，有效结合了3D几何结构和特定偏好。|
|📝 更新|Efficient Physics Simulation for 3D Scenes via MLLM-Guided Gaussian Splatting|通过MLLM引导的高斯绘制实现三维场景的高效物理仿真|Haoyu Zhao, Hao Wang, Xingyue Zhao, Hao Fei, Hongqiu Wang, Chengjiang Long, Hua Zou|<http://arxiv.org/pdf/2411.12789v3>|提出了一种利用多模态大语言模型指导的物理模拟方法，通过概率分布估计降低计算成本，实现高效的3D场景动...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Mitigating Object Hallucinations via Sentence-Level Early Intervention|通过句子级别的早期干预减轻对象幻觉|Shangpin Peng, Senqiao Yang, Li Jiang, Zhuotao Tian|<http://arxiv.org/pdf/2507.12455v2>|[代码](https://github.com/pspdada/SENTINEL.); 提出了一种早期干预框架，通过偏好学习减少大型多模态语言模型生成文本中的视觉输入偏差。|
|🆕 发布|Text2Vis: A Challenging and Diverse Benchmark for Generating Multimodal Visualizations from Text|文本到视觉：一个用于生成多模态文本可视化的大型挑战性基准数据集|Mizanur Rahman, Md Tahmid Rahman Laskar, Shafiq Joty, Enamul Hoque|<http://arxiv.org/pdf/2507.19969v1>|[代码](https://github.com/vis-nlp/Text2Vis.); 提出Text2Vis基准，评估文本到可视化模型，并提出跨模态框架提升性能和评估效率。|
|🆕 发布|LAVA: Language Driven Scalable and Versatile Traffic Video Analytics|LAVA：语言驱动的可扩展与多功能的交通视频分析系统|Yanrui Yu, Tianfei Zhou, Jiaxin Sun, Lianpeng Qiao, Lizhong Ding, Ye Yuan, Guoren Wang|<http://arxiv.org/pdf/2507.19821v1>|提出了一种基于自然语言驱动的视频分析系统LAVA，实现了对大规模交通视频数据的高效灵活查询。|
|🆕 发布|A Machine Learning Framework for Predicting Microphysical Properties of Ice Crystals from Cloud Particle Imagery|机器学习框架：从云粒子图像预测冰晶微物理特性|Joseph Ko, Jerry Harrington, Kara Sulia, Vanessa Przybylo, Marcus van Lier-Walqui, Kara Lamb|<http://arxiv.org/pdf/2507.19759v1>|提出了一种机器学习框架，通过二维云粒子图像预测冰晶的三维微物理特性，实现了高精度预测。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|The Origin of Self-Attention: Pairwise Affinity Matrices in Feature Selection and the Emergence of Self-Attention|自注意力起源：特征选择中的成对亲和矩阵与自注意力的涌现|Giorgio Roffo|<http://arxiv.org/pdf/2507.14560v2>|揭示了自注意力机制起源于特征选择中的成对亲和矩阵，并统一了多种机器学习研究。|
|📝 更新|Model Reveals What to Cache: Profiling-Based Feature Reuse for Video Diffusion Models|模型揭示缓存内容：基于分析的视觉特征重用策略用于视频扩散模型|Xuran Ma, Yexin Liu, Yaofu Liu, Xianfeng Wu, Mingzhe Zheng, Zihao Wang, Ser-Nam Lim, Harry Yang|<http://arxiv.org/pdf/2504.03140v2>|提出了一种自适应缓存策略ProfilingDiT，通过区分前景和背景块，有效降低视频生成模型的计算负...|
|🆕 发布|RARE: Refine Any Registration of Pairwise Point Clouds via Zero-Shot Learning|RARE：通过零样本学习精炼任意点云配对注册|Chengyu Zheng, Jin Huang, Honghua Chen, Mingqiang Wei|<http://arxiv.org/pdf/2507.19950v1>|[代码](https://github.com/zhengcy-lambo/RARE.git.); 提出了一种零样本学习方法，通过深度图像和预训练扩散模型增强点云配准精度。|
|📝 更新|Mcity Data Engine: Iterative Model Improvement Through Open-Vocabulary Data Selection|“Mcity 数据引擎：通过开放词汇数据选择实现迭代模型改进”|Daniel Bogdoll, Rajanikant Patnaik Ananta, Abeyankar Giridharan, Isabel Moore, Gregory Stevens, Henry X. Liu|<http://arxiv.org/pdf/2504.21614v2>|[代码](https://github.com/mcity/mcity_data_engine); 提出Mcity Data Engine，通过开放词汇数据选择迭代优化模型，专注于识别稀有和新型类别。|
|📝 更新|TriDi: Trilateral Diffusion of 3D Humans, Objects, and Interactions|三角扩散：三维人体、物体及交互的三角扩散|Ilya A. Petrov, Riccardo Marin, Julian Chibane, Gerard Pons-Moll|<http://arxiv.org/pdf/2412.06334v3>|首次提出统一的三向扩散模型TriDi，实现3D人类-物体交互的全方位生成，提升多样性和质量。|
|🆕 发布|TransFlow: Motion Knowledge Transfer from Video Diffusion Models to Video Salient Object Detection|"TransFlow：从视频扩散模型到视频显著目标检测的运动知识迁移"|Suhwan Cho, Minhyeok Lee, Jungho Lee, Sunghun Yang, Sangyoun Lee|<http://arxiv.org/pdf/2507.19789v1>|提出了一种利用预训练视频扩散模型生成真实训练数据的方法，有效提升了视频显著目标检测性能。|
|🆕 发布|MoFRR: Mixture of Diffusion Models for Face Retouching Restoration|MoFRR: 用于人脸修饰恢复的扩散模型混合|Jiaxin Liu, Qichao Ying, Zhenxing Qian, Sheng Li, Runqi Zhang, Jian Liu, Xinpeng Zhang|<http://arxiv.org/pdf/2507.19770v1>|提出了一种混合扩散模型MoFRR，用于从修饰过的脸部图像中恢复原始面貌。|
|📝 更新|Predicting Neoadjuvant Chemotherapy Response in Triple-Negative Breast Cancer Using Pre-Treatment Histopathologic Images|使用治疗前病理图像预测三阴性乳腺癌新辅助化疗反应|Hikmat Khan, Ziyu Su, Huina Zhang, Yihong Wang, Bohan Ning, Shi Wei, Hua Guo, Zaibo Li .etc.|<http://arxiv.org/pdf/2505.14730v2>|提出了一种基于注意力机制的模型，利用术前病理图像预测三阴性乳腺癌对化疗的反应，实现了较高的预测准确性...|
|🆕 发布|Quaternion-Based Robust PCA for Efficient Moving Target Detection and Background Recovery in Color Videos|基于四元数的鲁棒主成分分析在彩色视频中的高效运动目标检测与背景恢复|Liyang Wang, Shiqian Wu, Shun Fang, Qile Zhu, Jiaxin Wu, Sos Again|<http://arxiv.org/pdf/2507.19730v1>|[代码](https://github.com/Ruchtech/uQRPCA); 提出了一种基于四元数的鲁棒PCA框架，有效平衡了运动目标检测与背景恢复，实现了SOTA性能。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DeSiRe-GS: 4D Street Gaussians for Static-Dynamic Decomposition and Surface Reconstruction for Urban Driving Scenes|DeSiRe-GS：用于城市驾驶场景的静态-动态分解和表面重建的4D街道高斯分布|Chensheng Peng, Chengwei Zhang, Yixiao Wang, Chenfeng Xu, Yichen Xie, Wenzhao Zheng, Kurt Keutzer, Masayoshi Tomizuka .etc.|<http://arxiv.org/pdf/2411.11921v2>|[代码](https://github.com/chengweialan/DeSiRe-GS); 提出DeSiRe-GS方法，通过高斯分布实现城市驾驶场景的静态动态分解和表面重建。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UniCT Depth: Event-Image Fusion Based Monocular Depth Estimation with Convolution-Compensated ViT Dual SA Block|单目深度估计：基于事件-图像融合和卷积补偿ViT双注意力块的UniCT Depth方法|Luoxi Jing, Dianxi Shi, Zhe Liu, Songchang Jin, Chunping Qiu, Ziteng Qiao, Yuxian Li, Jianqiang Xia|<http://arxiv.org/pdf/2507.19948v1>|提出了一种融合事件和图像数据的方法UniCT Depth，通过结合CNN和Transformer优势...|
|🆕 发布|Taking Language Embedded 3D Gaussian Splatting into the Wild|将自然语言嵌入的3D高斯散点绘制技术应用于野外环境|Yuze Wang, Yue Qi|<http://arxiv.org/pdf/2507.19830v1>|提出了一种结合自然语言处理与3D重建技术的新框架，实现了对建筑元素的三维理解和开放词汇场景分割。|


## 时序视觉分析 (Temporal Visual Analysis)


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Egocentric Action-aware Inertial Localization in Point Clouds with Vision-Language Guidance|以视觉-语言引导的点云中自我中心动作感知惯性定位|Mingfang Zhang, Ryo Yonetani, Yifei Huang, Liangyang Ouyang, Ruicong Liu, Yoichi Sato|<http://arxiv.org/pdf/2505.14346v2>|提出了一种利用头戴IMU动作线索与视觉语言指导相结合的三维点云中个体定位方法，有效补偿了IMU传感器...|
|📝 更新|Learning from Heterogeneity: Generalizing Dynamic Facial Expression Recognition via Distributionally Robust Optimization|从异质性学习：通过分布鲁棒优化泛化动态面部表情识别|Feng-Qi Cui, Anyang Tong, Jinyang Huang, Jie Zhang, Dan Guo, Zhi Liu, Meng Wang|<http://arxiv.org/pdf/2507.15765v2>|[代码](https://github.com/QIcita/HDF_DFER.); 提出异质性感知分布框架HDF，通过时间频率分布注意模块和自适应优化模块提升动态面部表情识别的准确性和...|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HumanSAM: Classifying Human-centric Forgery Videos in Human Spatial, Appearance, and Motion Anomaly|《HumanSAM：基于人类空间、外观和运动异常分类以人为中心的伪造视频》|Chang Liu, Yunfan Ye, Fan Zhang, Qingyang Zhou, Yuchuan Luo, Zhiping Cai|<http://arxiv.org/pdf/2507.19924v1>|提出HumanSAM框架，通过空间、外观和运动异常分类，提升了对人类中心伪造视频的细粒度识别能力。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TrackAny3D: Transferring Pretrained 3D Models for Category-unified 3D Point Cloud Tracking|TrackAny3D：迁移预训练的3D模型实现统一类别的3D点云跟踪|Mengmeng Wang, Haonan Wang, Yulong Li, Xiangjie Kong, Jiaxin Du, Guojiang Shen, Feng Xia|<http://arxiv.org/pdf/2507.19908v1>|首次提出利用大规模预训练3D模型进行类别无关的3D点云跟踪，通过适配器和混合几何专家架构提升泛化能力...|
|📝 更新|SDTrack: A Baseline for Event-based Tracking via Spiking Neural Networks|基于尖峰神经网络的_event-based_跟踪基线：SDTrack|Yimeng Shan, Zhenbang Ren, Haodi Wu, Wenjie Wei, Rui-Jie Zhu, Shuai Wang, Dehao Zhang, Yichen Xiao .etc.|<http://arxiv.org/pdf/2503.08703v3>|提出首个基于Transformer的 spike-driven 跟踪方法SDTrack，通过全局轨迹...|
|📝 更新|OpenHuman4D: Open-Vocabulary 4D Human Parsing|《OpenHuman4D：开放式词汇四维人体解析》|Keito Suzuki, Bang Du, Runfa Blark Li, Kunyao Chen, Lei Wang, Peng Liu, Ning Bi, Truong Nguyen|<http://arxiv.org/pdf/2507.09880v2>|首次提出开放词汇4D人体解析框架，通过减少推理时间和支持动态类别，提升了虚拟现实应用中的人体解析效率...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning|GLC++：通过全局-局部聚类和对比亲和学习的无源通用域自适应|Sanqing Qu, Tianpei Zou, Florian Röhrbein, Cewu Lu, Guang Chen, Dacheng Tao, Changjun Jiang|<http://arxiv.org/pdf/2403.14410v2>|[代码](https://github.com/ispc-lab/GLC-plus.); 提出全局局部聚类方法GLC++，实现无源域自适应，有效区分已知与未知数据类别。|
|🆕 发布|A mini-batch training strategy for deep subspace clustering networks|用于深度子空间聚类网络的迷你批次训练策略|Yuxuan Jiang, Chenwei Yu, Zhi Lin, Xiaolan Liu|<http://arxiv.org/pdf/2507.19917v1>|提出了一种结合记忆银行的 mini-batch 训练策略，实现高效深子空间聚类。|
|🆕 发布|GNSP: Gradient Null Space Projection for Preserving Cross-Modal Alignment in VLMs Continual Learning|梯度零空间投影：用于保持大型语言模型中跨模态对齐的持续学习|Tiantian Peng, Yuyang Liu, Shuo Yang, Qiuhe Hong, YongHong Tian|<http://arxiv.org/pdf/2507.19839v1>|提出了一种正交投影的持续学习方法GNSP，有效防止视觉语言模型在任务学习中遗忘和性能退化。|


### 掩码自编码 (Masked Autoencoding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Self-Guided Masked Autoencoder|自引导遮蔽自编码器|Jeongwoo Shin, Inseo Lee, Junho Lee, Joonseok Lee|<http://arxiv.org/pdf/2507.19773v1>|提出了一种自引导的掩码自编码器，通过内部生成有信息的掩码来加速学习过程，无需依赖外部模型或额外信息。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Histogram Layers for Neural Engineered Features|直方图层用于神经工程特征提取|Joshua Peeples, Salim Al Kharsa, Luke Saleh, Alina Zare|<http://arxiv.org/pdf/2403.17176v2>|提出将传统直方图特征嵌入神经网络，通过学习增强图像分类特征表示。|
|📝 更新|MTMamba++: Enhancing Multi-Task Dense Scene Understanding via Mamba-Based Decoders|基于Mamba解码器的多任务密集场景理解增强方法：MTMamba++|Baijiong Lin, Weisen Jiang, Pengguang Chen, Shu Liu, Ying-Cong Chen|<http://arxiv.org/pdf/2408.15101v2>|[代码](https://github.com/EnVision-Research/MTMamba.); MTMamba++通过引入基于Mamba解码器的STM和CTM模块，有效提升了多任务密集场景理解中的...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Pic2Diagnosis: A Method for Diagnosis of Cardiovascular Diseases from the Printed ECG Pictures|《Pic2Diagnosis：一种基于打印心电图图片的心血管疾病诊断方法》|Oğuzhan Büyüksolak, İlkay Öksüz|<http://arxiv.org/pdf/2507.19961v1>|提出了一种基于图像的ECG心血管疾病诊断方法，通过两阶段学习框架显著提升诊断准确性。|
|📝 更新|Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report|《前沿人工智能风险管理框架实践：风险评估技术报告》|Shanghai AI Lab, :, Xiaoyang Chen, Yunhao Chen, Zeren Chen, Zhiyun Chen, Hanyun Cui, Yawen Duan .etc.|<http://arxiv.org/pdf/2507.16534v2>|提出AI风险管理体系，划分风险等级以评估和管理前沿AI模型风险。|
|🆕 发布|AutoSign: Direct Pose-to-Text Translation for Continuous Sign Language Recognition|自动签名：直接从姿态到文本翻译的连续手语识别|Samuel Ebimobowei Johnny, Blessed Guda, Andrew Blayama Stephen, Assane Gueye|<http://arxiv.org/pdf/2507.19840v1>|提出了一种直接将姿态序列转化为自然语言文本的方法AutoSign，避免了传统对齐机制的限制，大幅提升...|
|🆕 发布|FM-LC: A Hierarchical Framework for Urban Flood Mapping by Land Cover Identification Models|FM-LC：基于土地覆盖识别模型的城市洪水制图分层框架|Xin Hong, Longchao Da, Hua Wei|<http://arxiv.org/pdf/2507.19818v1>|提出了一种分层框架FM-LC，通过土地覆盖识别模型显著提升了城市洪水映射的精确度。|
|🆕 发布|HydraMamba: Multi-Head State Space Model for Global Point Cloud Learning|HydraMamba：全局点云学习的多头状态空间模型|Kanglin Qu, Pan Gao, Qun Dai, Yuanhao Sun|<http://arxiv.org/pdf/2507.19778v1>|[代码](https://github.com/Point-Cloud-Learning/HydraMamba.); 提出HydraMamba模型，通过多头部状态空间模型和特定层结构，有效解决点云学习中的长距离依赖和局...|
|🆕 发布|A Metabolic-Imaging Integrated Model for Prognostic Prediction in Colorectal Liver Metastases|结直肠癌肝转移预后预测的代谢成像集成模型|Qinlong Li, Pu Sun, Guanlin Zhu, Tianjiao Liang, Honggang QI|<http://arxiv.org/pdf/2507.19734v1>|开发了一种预测结直肠癌肝转移术后复发风险的机器学习模型，强调了数据泄露风险并提出解决框架。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CLoRA: Parameter-Efficient Continual Learning with Low-Rank Adaptation|CLoRA：参数高效的无秩适应持续学习|Shishir Muralidhara, Didier Stricker, René Schuster|<http://arxiv.org/pdf/2507.19887v1>|提出CLoRA方法，通过低秩适应实现参数高效的连续学习，降低资源受限环境下的训练需求。|
|🆕 发布|Efficient Self-Supervised Neuro-Analytic Visual Servoing for Real-time Quadrotor Control|高效自监督神经分析视觉伺服系统在实时四旋翼飞行器控制中的应用|Sebastian Mocanu, Sebastian-Ion Nae, Mihai-Eugen Barbu, Marius Leordeanu|<http://arxiv.org/pdf/2507.19878v1>|提出了一种自监督神经分析视觉伺服方法，通过知识蒸馏实现快速准确的四旋翼飞行器控制。|
|🆕 发布|JDATT: A Joint Distillation Framework for Atmospheric Turbulence Mitigation and Target Detection|JDATT：一种用于大气湍流缓解与目标检测的联合蒸馏框架|Zhiming Liu, Paul Hill, Nantheera Anantrasirichai|<http://arxiv.org/pdf/2507.19780v1>|提出了一种集成大气湍流抑制和目标检测的联合蒸馏框架，实现了高精度和实时性能的平衡。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TAPS : Frustratingly Simple Test Time Active Learning for VLMs|TAPS：令人沮丧简单的测试时主动学习策略用于大型视觉语言模型|Dhruv Sarkar, Aprameyo Chakrabartty, Bibhudatta Bhanja|<http://arxiv.org/pdf/2507.20028v1>|提出实时流数据下的测试时主动学习框架，动态更新提示以提升视觉语言模型性能。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Digital and Robotic Twinning for Validation of Proximity Operations and Formation Flying|数字与机器人双胞胎技术用于验证近距离操作与编队飞行|Aviad Golan, Gregory Zin, Zahra Ahmed, Emily Bates, Toby Bell, Pol Francesch Huc, Samuel Y. W. Low, Juergen Bosse .etc.|<http://arxiv.org/pdf/2507.20034v1>|提出了一种数字与机器人双胞胎框架，实现了 Guidance Navigation and Contr...|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Competency-Aware Planning for Probabilistically Safe Navigation Under Perception Uncertainty|在感知不确定性下的概率安全导航中的能力感知规划|Sara Pohland, Claire Tomlin|<http://arxiv.org/pdf/2409.06111v5>|提出了一种在感知不确定性下，通过概率性和重建基础的竞争力评估方法来确保无人地面车辆安全导航的方案。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|iSEARLE: Improving Textual Inversion for Zero-Shot Composed Image Retrieval|iSEARLE：改进文本反转以实现零样本组合图像检索|Lorenzo Agnolucci, Alberto Baldrati, Alberto Del Bimbo, Marco Bertini|<http://arxiv.org/pdf/2405.02951v2>|[代码](https://github.com/miccunifi/SEARLE.); 提出零样本图像组合检索任务，并引入iSEARLE方法，无需标注数据集即可实现图像与文本的匹配检索。|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hybrid Deep Learning and Handcrafted Feature Fusion for Mammographic Breast Cancer Classification|混合深度学习与手工特征融合在乳腺X线摄影中乳腺癌分类的应用|Maximilian Tschuchnig, Michael Gadermayr, Khalifa Djemal|<http://arxiv.org/pdf/2507.19843v1>|融合深度学习与手工特征提升了乳腺X线照片中乳腺癌分类的准确性。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Region-based Cluster Discrimination for Visual Representation Learning|基于区域的聚类区分用于视觉表征学习|Yin Xie, Kaicheng Yang, Xiang An, Kun Wu, Yongle Zhao, Weimo Deng, Zimin Ran, Yumeng Wang .etc.|<http://arxiv.org/pdf/2507.20025v1>|[代码](https://github.com/deepglint/MVT.); 提出了一种增强区域级视觉和OCR能力的方法RICE，通过区域变换层和统一区域聚类判别损失，提升了对下...|
|📝 更新|Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs|跨语言旅行：在多模态大型语言模型中衡量跨语言一致性的基准测试|Hao Wang, Pinzhi Huang, Jihan Yang, Saining Xie, Daisuke Kawahara|<http://arxiv.org/pdf/2505.15075v4>|提出两个新基准KnowRecall和VisRecall，评估多模态大语言模型在不同语言中的表现一致性...|
|📝 更新|Animation Needs Attention: A Holistic Approach to Slides Animation Comprehension with Visual-Language Models|动画需要关注：一种结合视觉语言模型的幻灯片动画理解的全面方法|Yifan Jiang, Yibo Xue, Yukun Kang, Pin Zheng, Jian Peng, Feiran Wu, Changliang Xu|<http://arxiv.org/pdf/2507.03916v3>|提出了首个用于幻灯片动画建模的公共数据集，并通过低秩适应提升了视觉语言模型的动画理解能力。|
|🆕 发布|OW-CLIP: Data-Efficient Visual Supervision for Open-World Object Detection via Human-AI Collaboration|OW-CLIP：通过人机协作实现开放世界目标检测的数据高效视觉监督|Junwen Duan, Wei Xue, Ziyao Kang, Shixia Liu, Jiazhi Xia|<http://arxiv.org/pdf/2507.19870v1>|OW-CLIP通过人机协作实现高效开放世界目标检测，减少对大量标注数据的依赖并缓解特征过拟合问题。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FaRMamba: Frequency-based learning and Reconstruction aided Mamba for Medical Segmentation|基于频率学习的重建辅助Mamba算法用于医学分割|Ze Rong, ZiYue Zhao, Zhaoxin Wang, Lei Ma|<http://arxiv.org/pdf/2507.20056v1>|FaRMamba通过多尺度频率变换和自监督重建增强了医疗图像分割的细节和结构准确性。|
|🆕 发布|SkinDualGen: Prompt-Driven Diffusion for Simultaneous Image-Mask Generation in Skin Lesions|《SkinDualGen：基于提示驱动的扩散算法在皮肤病变中实现图像-掩膜同步生成的应用》|Zhaobin Xu|<http://arxiv.org/pdf/2507.19970v1>|提出了一种利用预训练模型生成高质量合成皮肤病变图像及对应分割掩模的方法，有效增强了分类和分割模型的性...|
|🆕 发布|MambaVesselNet++: A Hybrid CNN-Mamba Architecture for Medical Image Segmentation|MambaVesselNet++：一种用于医学图像分割的混合CNN-Mamba架构|Qing Xu, Yanming Chen, Yue Li, Ziyu Liu, Zhenye Lou, Yixuan Zhang, Xiangjian He|<http://arxiv.org/pdf/2507.19931v1>|[代码](https://github.com/CC0117/MambaVesselNet.); 提出了一种结合CNN与Mamba模型的Hybrid CNN-Mamba框架，有效提升医疗图像分割的准...|
|🆕 发布|DriveIndia: An Object Detection Dataset for Diverse Indian Traffic Scenes|"DriveIndia：多样化印度交通场景的对象检测数据集"|Rishav Kumar, D. Santhosh Reddy, P. Rajalakshmi|<http://arxiv.org/pdf/2507.19912v1>|介绍了DriveIndia数据集，为复杂多变的印度交通环境提供全面的对象检测基准。|
|🆕 发布|FedS2R: One-Shot Federated Domain Generalization for Synthetic-to-Real Semantic Segmentation in Autonomous Driving|FedS2R：面向自动驾驶的合成到现实语义分割的一键式联邦域泛化|Tao Lian, Jose L. Gómez, Antonio M. López|<http://arxiv.org/pdf/2507.19881v1>|首次提出面向自动驾驶的合成到现实语义分割的一键式联邦域泛化框架FedS2R。|
|🆕 发布|Taming Domain Shift in Multi-source CT-Scan Classification via Input-Space Standardization|通过输入空间标准化驯服多源CT扫描分类中的域偏移|Chia-Ming Lee, Bo-Cheng Qiu, Ting-Yao Chen, Ming-Han Sun, Fang-Ying Lin, Jung-Tse Tsai, I-An Tsai, Yu-Fan Lin .etc.|<http://arxiv.org/pdf/2507.19858v1>|通过输入空间标准化策略，有效缓解多源CT扫描分类中的域偏移问题，提升跨源泛化能力。|
|🆕 发布|RaGS: Unleashing 3D Gaussian Splatting from 4D Radar and Monocular Cues for 3D Object Detection|RaGS：从4D雷达和单目线索释放三维高斯散点绘制以进行三维目标检测|Xiaokai Bai, Chenxu Zhou, Lianqing Zheng, Si-Yuan Cao, Jianan Liu, Xiaohan Zhang, Zhengzhuang Zhang, Hui-liang Shen|<http://arxiv.org/pdf/2507.19856v1>|提出首个利用3D高斯散点表示融合4D雷达和单目图像线索的3D物体检测框架，实现高效资源分配和精确检测...|
|🆕 发布|All-in-One Medical Image Restoration with Latent Diffusion-Enhanced Vector-Quantized Codebook Prior|一站式医学图像恢复：潜在扩散增强向量量化码书先验|Haowei Chen, Zhiwen Yang, Haotian Hou, Hui Zhang, Bingzheng Wei, Gang Zhou, Yan Xu|<http://arxiv.org/pdf/2507.19874v1>|提出了一种统一模型DiffCode，通过任务自适应码本库和潜在扩散策略，有效处理多种医学图像恢复任务...|
|📝 更新|Evaluating Self-Supervised Learning in Medical Imaging: A Benchmark for Robustness, Generalizability, and Multi-Domain Impact|评估医学成像中的自监督学习：一个用于鲁棒性、泛化性和跨域影响的基准|Valay Bundele, Karahan Sarıtaş, Bora Kargi, Oğuz Ata Çal, Kıvanç Tezören, Zohreh Ghaderi, Hendrik Lensch|<http://arxiv.org/pdf/2412.19124v2>|提出了一种全面的医学图像自监督学习方法评估框架，专注于模型的鲁棒性和泛化能力。|
|📝 更新|An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image|一种基于特征交互与融合的有效UNet网络在医学图像器官分割中的应用|Xiaolin Gou, Chuanlin Liao, Jizhe Zhou, Fengshuo Ye, Yi Lin|<http://arxiv.org/pdf/2409.05324v2>|提出了一种U型网络结构，通过特征交互和融合提升了医学图像器官分割的准确性和效率。|
|📝 更新|OrthoInsight: Rib Fracture Diagnosis and Report Generation Based on Multi-Modal Large Models|“OrthoInsight：基于多模态大型模型的肋骨骨折诊断与报告生成”|Ningyong Wu, Jinzhi Wang, Wenhong Zhao, Chenzhan Yu, Zhigang Xiu, Duwei Dai|<http://arxiv.org/pdf/2507.13993v2>|提出OrthoInsight多模态框架，融合深度学习与医学知识图，实现高效肋骨骨折诊断及报告生成。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AF-CLIP: Zero-Shot Anomaly Detection via Anomaly-Focused CLIP Adaptation|AF-CLIP：基于异常聚焦CLIP适应的零样本异常检测|Qingqing Fang, Wenxi Lv, Qinliang Su|<http://arxiv.org/pdf/2507.19949v1>|[代码](https://github.com/Faustinaqq/AF-CLIP.); 提出AF-CLIP方法，通过增强视觉特征聚焦局部异常，实现零样本异常检测。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Hydra-NeXt: Robust Closed-Loop Driving with Open-Loop Training|Hydra-NeXt：基于开环训练的鲁棒闭环驾驶|Zhenxin Li, Shihao Wang, Shiyi Lan, Zhiding Yu, Zuxuan Wu, Jose M. Alvarez|<http://arxiv.org/pdf/2503.12030v2>|[代码](https://github.com/woxihuanjiangguo/Hydra-NeXt.); 提出Hydra-NeXt框架，通过统一轨迹预测、控制预测和轨迹优化，提升了自动驾驶在动态环境下的响应...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RS2-SAM2: Customized SAM2 for Referring Remote Sensing Image Segmentation|RS2-SAM2：面向指引用户遥感图像分割的定制化SAM2|Fu Rong, Meng Lan, Qian Zhang, Lefei Zhang|<http://arxiv.org/pdf/2503.07266v3>|针对遥感图像目标描述分割难题，提出RS2-SAM2框架，融合视觉与文本特征，实现精准目标提示。|
|🆕 发布|SpecBPP: A Self-Supervised Learning Approach for Hyperspectral Representation and Soil Organic Carbon Estimation|SpecBPP：一种用于高光谱表征和土壤有机碳估算的自监督学习方法|Daniel La'ah Ayuba, Jean-Yves Guillemaut, Belen Marti-Cardona, Oscar Mendez Maldonado|<http://arxiv.org/pdf/2507.19781v1>|提出SpecBPP方法，通过预测光谱顺序提升高光谱图像表示和土壤有机碳估算性能。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Fast Parallel Median Filtering Algorithm Using Hierarchical Tiling|一种基于层次瓦片结构的快速并行中值滤波算法|Louis Sugy|<http://arxiv.org/pdf/2507.19926v1>|提出了一种高效的并行中值滤波算法，通过分层瓦片技术降低计算量，实现速度大幅提升。|
|🆕 发布|Leveraging Sparse LiDAR for RAFT-Stereo: A Depth Pre-Fill Perspective|利用稀疏LiDAR进行RAFT-Stereo：一种深度预填充视角|Jinsu Yoo, Sooyoung Jeon, Zanming Huang, Tai-Yu Pan, Wei-Lun Chao|<http://arxiv.org/pdf/2507.19738v1>|利用稀疏LiDAR数据，提出预填充策略提升RAFT-Stereo匹配精度。|
|📝 更新|Spatiotemporal Multi-Camera Calibration using Freely Moving People|自由移动人群的时空多摄像头标定|Sang-Eun Lee, Ko Nishino, Shohei Nobuhara|<http://arxiv.org/pdf/2502.12546v3>|提出了一种利用动态多人场景中人体运动进行时空多摄像头标定的方法，实现了无需标记的精确校准。|

