## [UPDATED!] **2025-07-29** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MetaCLIP 2: A Worldwide Scaling Recipe|元CLIP 2：一种全球规模扩展方案|Yung-Sung Chuang, Yang Li, Dong Wang, Ching-Feng Yeh, Kehan Lyu, Ramya Raghavendra, James Glass, Lifei Huang .etc.|<http://arxiv.org/pdf/2507.22062v1>|MetaCLIP 2首次从全球网络规模图像-文本对训练CLIP，克服多语言诅咒，提升多语言基准测试性...|
|🆕 发布|From Seeing to Experiencing: Scaling Navigation Foundation Models with Reinforcement Learning|从观察至体验：利用强化学习扩展导航基础模型|Honglin He, Yukai Ma, Wayne Wu, Bolei Zhou|<http://arxiv.org/pdf/2507.22028v1>|提出 Seeing-to-Experiencing 框架，结合视频预训练与强化学习，增强导航基础模型...|
|📝 更新|From Semantics, Scene to Instance-awareness: Distilling Foundation Model for Open-vocabulary Situation Recognition|从语义、场景到实例感知：为开放词汇情境识别提炼基础模型|Chen Cai, Tianyi Liu, Jianjun Gao, Wenyang Liu, Kejun Wu, Ruoyu Wang, Yi Wang, Soo Chin Liew|<http://arxiv.org/pdf/2507.14686v2>|提出了一种多模态交互提示蒸馏方法，通过从大型语言模型转移知识，提高了小模型在开放词汇情境识别中的泛化...|
|📝 更新|A Survey on Wi-Fi Sensing Generalizability: Taxonomy, Techniques, Datasets, and Future Research Prospects|关于Wi-Fi感知泛化性的综述：分类、技术、数据集及未来研究方向|Fei Wang, Tingting Zhang, Wei Xi, Han Ding, Ge Wang, Di Zhang, Yuanhao Cui, Fan Liu .etc.|<http://arxiv.org/pdf/2503.08008v2>|系统梳理了Wi-Fi感知泛化技术，提升系统对新用户、设备和环境的适应力。|
|📝 更新|UncertainSAM: Fast and Efficient Uncertainty Quantification of the Segment Anything Model|不确定SAM：快速高效的对Segment Anything模型进行不确定性量化|Timo Kaiser, Thomas Norrenbrock, Bodo Rosenhahn|<http://arxiv.org/pdf/2505.05049v4>|提出了一种基于贝叶斯熵的轻量级不确定性量化方法USAM，有效应对了Segment Anything ...|
|🆕 发布|Semantic Segmentation of iPS Cells: Case Study on Model Complexity in Biomedical Imaging|人多能干细胞（iPS细胞）的语义分割：生物医学成像中模型复杂性的案例研究|Maoquan Zhang, Bisser Raytchev, Xiujuan Sun|<http://arxiv.org/pdf/2507.21608v1>|通过精细配置DeepLabv3模型，实现了对iPS细胞的高效分割，证明简化模型在特定生物医学任务中可...|
|📝 更新|ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts|零：具备多模态提示的工业级视觉基础模型|Sangbum Choi, Kyeongryeol Go, Taewoong Jang|<http://arxiv.org/pdf/2507.04270v3>|提出ZERO模型，通过多模态提示实现工业场景零样本部署，无需重训练即可泛化。|
|📝 更新|SurgiSR4K: A High-Resolution Endoscopic Video Dataset for Robotic-Assisted Minimally Invasive Procedures|手术超分辨率4K：一种用于机器人辅助微创手术的高分辨率内窥镜视频数据集|Fengyi Jiang, Xiaorui Zhang, Lingbo Jin, Ruixing Liang, Yuxin Chen, Adi Chola Venkatesh, Jason Culman, Tiantian Wu .etc.|<http://arxiv.org/pdf/2507.00209v3>|介绍了首个公开的4K分辨率手术视频数据集，助力高分辨率手术成像研究。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Cardiac-CLIP: A Vision-Language Foundation Model for 3D Cardiac CT Images|心脏-CLIP：用于三维心脏CT图像的视觉-语言基础模型|Yutao Hu, Ying Zheng, Shumei Miao, Xiaolei Zhang, Jiahao Xia, Yaolei Qi, Yiyang Zhang, Yuting He .etc.|<http://arxiv.org/pdf/2507.22024v1>|提出了一种针对3D心脏CT图像的多模态基础模型Cardiac-CLIP，通过自监督学习和对比学习提升...|
|🆕 发布|MMAT-1M: A Large Reasoning Dataset for Multimodal Agent Tuning|MMAT-1M：用于多模态智能体调优的大规模推理数据集|Tianhong Gao, Yannian Fu, Weiqun Wu, Haixiao Yue, Shanshan Liu, Gang Zhang|<http://arxiv.org/pdf/2507.21924v1>|[代码](https://github.com/VIS-MPU-Agent/MMAT-1M.); 介绍了首个百万级的多模态代理调优数据集MMAT-1M，通过多阶段数据引擎增强模型的多模态推理和工具使...|
|🆕 发布|Aether Weaver: Multimodal Affective Narrative Co-Generation with Dynamic Scene Graphs|“以太编织者：基于动态场景图的跨模态情感叙事协同生成”|Saeed Ghorbani|<http://arxiv.org/pdf/2507.21893v1>|提出了一种集成框架Aether Weaver，实现了文本、视觉和声音的情感化叙事共生成，提升了故事的...|
|🆕 发布|MAGE: Multimodal Alignment and Generation Enhancement via Bridging Visual and Semantic Spaces|MAGE：通过桥接视觉与语义空间实现多模态对齐与生成增强|Shaojun E, Yuchen Yang, Jiaheng Wu, Yan Zhang, Tiejun Zhao, Ziyan Chen|<http://arxiv.org/pdf/2507.21741v1>|[代码](https://github.com/GTCOM-NLP/MAGE.); 提出MAGE框架，通过智能对齐网络桥接视觉与文本语义空间，有效减少信息损失并提升多模态模型性能。|
|📝 更新|C2-Evo: Co-Evolving Multimodal Data and Model for Self-Improving Reasoning|C2-Evo：协同进化多模态数据与模型以实现自我提升推理|Xiuwei Chen, Wentao Hu, Hanhui Li, Jun Zhou, Zisheng Chen, Meng Cao, Yihan Zeng, Kui Zhang .etc.|<http://arxiv.org/pdf/2507.16518v2>|提出了一种自动闭环自我提升框架C2-Evo，协同进化训练数据和模型能力，有效解决多模态大语言模型推理...|
|🆕 发布|MoHoBench: Assessing Honesty of Multimodal Large Language Models via Unanswerable Visual Questions|《MoHoBench：通过不可回答的视觉问题评估多模态大型语言模型的诚实性》|Yanxu Zhu, Shitong Duan, Xiangxu Zhang, Jitao Sang, Peng Zhang, Tun Lu, Xiao Zhou, Jing Yao .etc.|<http://arxiv.org/pdf/2507.21503v1>|[代码](https://github.com/DSTTSD/MoHoBench.); 提出首个大规模多模态大语言模型诚实性评估基准MoHoBench，并探讨了视觉信息对模型诚实性的影响。|
|📝 更新|One-stage Modality Distillation for Incomplete Multimodal Learning|单阶段模态蒸馏用于不完整的多模态学习|Shicai Wei, Yang Luo, Chunbo Luo|<http://arxiv.org/pdf/2309.08204v2>|提出一种一站式模态迁移框架，通过多任务学习同时进行特权知识转移和模态信息融合，有效解决不完全模态输入...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MOR-VIT: Efficient Vision Transformer with Mixture-of-Recursions|MOR-VIT：具有递归混合的效率化视觉变换器|YiZhou Li|<http://arxiv.org/pdf/2507.21761v1>|引入动态递归机制以自适应调整计算深度，MOR-VIT实现参数减少70%和推理加速2.5倍。|
|📝 更新|RANa: Retrieval-Augmented Navigation|检索增强导航|Gianluca Monaci, Rafael S. Rezende, Romain Deffayet, Gabriela Csurka, Guillaume Bono, Hervé Déjean, Stéphane Clinchant, Christian Wolf|<http://arxiv.org/pdf/2504.03524v2>|提出了一种结合检索功能的强化学习导航方法，利用历史数据提升未知环境中的导航性能。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MOVE: Motion-Guided Few-Shot Video Object Segmentation|MOVE：运动引导的少量样本视频对象分割|Kaining Ying, Hengrui Hu, Henghui Ding|<http://arxiv.org/pdf/2507.22061v1>|提出针对动态物体视频分割的MOVE方法和DMA网络，提升少量样本下的运动理解性能。|
|🆕 发布|Unleashing the Power of Motion and Depth: A Selective Fusion Strategy for RGB-D Video Salient Object Detection|释放运动与深度力量：基于RGB-D视频的显著目标检测选择性融合策略|Jiahao He, Daerji Suolang, Keren Fu, Qijun Zhao|<http://arxiv.org/pdf/2507.21857v1>|[代码](https://github.com/Jia-hao999/SMFNet.); 提出了一种选择性跨模态融合框架，通过像素级选择性融合策略和多维选择性注意力模块，优化了RGB-D视频...|
|🆕 发布|AU-LLM: Micro-Expression Action Unit Detection via Enhanced LLM-Based Feature Fusion|AU-LLM：基于增强LLM特征融合的微表情动作单元检测|Zhishu Liu, Kaishen Yuan, Bo Zhao, Yong Xu, Zitong Yu|<http://arxiv.org/pdf/2507.21778v1>|[代码](https://github.com/ZS-liu-JLU/AU-LLMs.); 首次应用大型语言模型于微表情动作单元检测，通过增强融合投影器有效融合视觉特征，实现精准识别。|
|📝 更新|YOLO-PRO: Enhancing Instance-Specific Object Detection with Full-Channel Global Self-Attention|YOLO-PRO：利用全通道全局自注意力增强实例特定目标检测|Lin Huang, Yujuan Tan, Weisheng Li, Shitai Shan, Liu Liu, Linlin Shen, Jing Yu, Yue Niu|<http://arxiv.org/pdf/2503.02348v3>|YOLO-PRO通过引入实例特定瓶颈和不对称解耦头部结构，提升了对象检测的准确性和效率。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MetaLab: Few-Shot Game Changer for Image Recognition|MetaLab：图像识别领域的少样本游戏规则改变者|Chaofei Qi, Zhitai Liu, Jianbin Qiu|<http://arxiv.org/pdf/2507.22057v1>|提出了一种名为MetaLab的少样本图像识别方法，通过协同神经网络实现高效特征提取和泛化能力。|
|🆕 发布|Supervised Quantum Image Processing|监督量子图像处理|Marco Parigi, Mehran Khosrojerdi, Filippo Caruso, Leonardo Banchi|<http://arxiv.org/pdf/2507.22039v1>|探究量子图像表示法的压缩性能，发现FRQI压缩效果最佳，量子核在分类任务中表现与传统方法相当但存储需...|
|🆕 发布|XAI for Point Cloud Data using Perturbations based on Meaningful Segmentation|基于有意义分割的扰动XAI方法在点云数据上的应用|Raju Ningappa Mulawade, Christoph Garth, Alexander Wiebel|<http://arxiv.org/pdf/2507.22020v1>|提出了一种基于有意义分割的扰动方法，为点云分类神经网络生成易于人类理解的解释。|
|📝 更新|Semantic segmentation of SEM images of lower bainitic and tempered martensitic steels|扫描电镜下低碳贝氏体和回火马氏体钢图像的语义分割|Xiaohan Bie, Manoj Arthanari, Evelin Barbosa de Melo, Baihua Ren, Juancheng Li, Stephen Yue, Salim Brahimi, Jun Song|<http://arxiv.org/pdf/2312.17251v2>|利用深度学习技术实现扫描电镜图像的语义分割，为定量分析不同钢材中碳化物沉淀提供高效AI工作流程。|
|📝 更新|VLM-CPL: Consensus Pseudo Labels from Vision-Language Models for Annotation-Free Pathological Image Classification|VLM-CPL：基于视觉语言模型的共识伪标签用于无需标注的病理图像分类|Lanfeng Zhong, Zongyao Huang, Yang Liu, Wenjun Liao, Shichuan Zhang, Guotai Wang, Shaoting Zhang|<http://arxiv.org/pdf/2403.15836v3>|[代码](https://github.com/HiLab-git/VLM-CPL.); 提出了一种无需人工标注的病理图像分类方法，通过预训练的视觉语言模型生成伪标签并进行半监督学习，有效提...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EIFNet: Leveraging Event-Image Fusion for Robust Semantic Segmentation|EIFNet：利用事件-图像融合进行鲁棒语义分割|Zhijiang Li, Haoran He|<http://arxiv.org/pdf/2507.21971v1>|提出EIFNet网络，通过多模态融合和特征优化提升事件相机在困难环境下的语义分割性能。|
|🆕 发布|Mitigating Spurious Correlations in Weakly Supervised Semantic Segmentation via Cross-architecture Consistency Regularization|通过跨架构一致性正则化减轻弱监督语义分割中的伪相关|Zheyuan Zhang, Yen-chia Hsu|<http://arxiv.org/pdf/2507.21959v1>|提出了一种无需外部监督，通过跨架构一致性正则化减轻弱监督语义分割中伪相关性的新框架。|
|🆕 发布|Emerging Trends in Pseudo-Label Refinement for Weakly Supervised Semantic Segmentation with Image-Level Supervision|弱监督语义分割中基于图像级监督的伪标签精炼新兴趋势|Zheyuan Zhang, Wang Zhang|<http://arxiv.org/pdf/2507.21587v1>|系统梳理了图像级标注的弱监督语义分割领域最新进展，分类现有方法并探讨了未来研究方向。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Texture, Shape, Order, and Relation Matter: A New Transformer Design for Sequential DeepFake Detection|纹理、形状、顺序与关系至关重要：面向序列深度伪造检测的新型Transformer设计|Yunfei Li, Yuezun Li, Baoyuan Wu, Junyu Dong, Guopu Zhu, Siwei Lyu|<http://arxiv.org/pdf/2404.13873v5>|[代码](https://github.com/OUC-VAS/TSOM.); 提出了一种针对序列DeepFake检测的新Transformer设计，通过纹理、形状、操作顺序和关系...|
|📝 更新|Category-level Meta-learned NeRF Priors for Efficient Object Mapping|用于高效物体映射的类别级元学习NeRF先验|Saad Ejaz, Hriday Bavle, Laura Ribeiro, Holger Voos, Jose Luis Sanchez-Lopez|<http://arxiv.org/pdf/2503.01582v3>|[代码](https://github.com/snt-arg/PRENOM); 提出了一种结合类别级先验和神经辐射场的映射方法，提高了3D物体重建效率和准确性。|
|📝 更新|Knowledge Regularized Negative Feature Tuning of Vision-Language Models for Out-of-Distribution Detection|知识正则化的视觉语言模型负特征调整用于分布外检测|Wenjie Zhu, Yabin Zhang, Xin Jin, Wenjun Zeng, Lei Zhang|<http://arxiv.org/pdf/2507.19847v2>|[代码](https://github.com/ZhuWenjie98/KRNFT); 提出了一种结合知识正则化的负特征调整方法，有效提升了视觉语言模型在未见过分布数据上的检测性能。|
|🆕 发布|Detection Transformers Under the Knife: A Neuroscience-Inspired Approach to Ablations|《检测变换器剖析：一种受神经科学启发的消融研究方法》|Nils Hütten, Florian Hölken, Hasan Tercan, Tobias Meisen|<http://arxiv.org/pdf/2507.21723v1>|通过神经科学启发的方法，研究了检测变换器模型内部组件的作用，揭示了优化模型性能与透明度的途径。|
|🆕 发布|Automated Detection of Antarctic Benthic Organisms in High-Resolution In Situ Imagery to Aid Biodiversity Monitoring|南极底栖生物在高分辨率原位图像中的自动检测助力生物多样性监测|Cameron Trotter, Huw Griffiths, Tasnuva Ming Khan, Rowan Whittle|<http://arxiv.org/pdf/2507.21665v1>|提出了一种针对南极海底生物自动检测的框架，提升了大数据量下的监测效率。|
|🆕 发布|EMIT: Enhancing MLLMs for Industrial Anomaly Detection via Difficulty-Aware GRPO|EMIT：通过难度感知GRPO增强多模态语言模型进行工业异常检测|Wei Guan, Jun Lan, Jian Cao, Hao Tan, Huijia Zhu, Weiqiang Wang|<http://arxiv.org/pdf/2507.21619v1>|提出EMIT框架，通过困难感知的相对策略优化增强多模态大语言模型在工业异常检测中的性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|X-Omni: Reinforcement Learning Makes Discrete Autoregressive Image Generative Models Great Again|X-全向：强化学习使离散自回归图像生成模型再次伟大|Zigang Geng, Yibing Wang, Yeyao Ma, Chen Li, Yongming Rao, Shuyang Gu, Zhao Zhong, Qinglin Lu .etc.|<http://arxiv.org/pdf/2507.22058v1>|利用强化学习显著提升离散自回归图像生成模型的质量，实现图像与语言生成的无缝整合。|
|📝 更新|NarrLV: Towards a Comprehensive Narrative-Centric Evaluation for Long Video Generation Models|NarrLV：面向长视频生成模型的全景叙事中心评估方法|X. Feng, H. Yu, M. Wu, S. Hu, J. Chen, C. Zhu, J. Wu, X. Chu .etc.|<http://arxiv.org/pdf/2507.11245v2>|提出NarrLV基准，首次全面评估长视频生成模型在叙事表达方面的能力。|
|🆕 发布|See Different, Think Better: Visual Variations Mitigating Hallucinations in LVLMs|《看见不同，思考更佳：视觉变体减轻LVLMs中的幻觉现象》|Ziyun Dai, Xiaoqiang Li, Shaohua Zhang, Yuanchen Wu, Jide Li|<http://arxiv.org/pdf/2507.22003v1>|[代码](https://github.com/oliviadzy/ViHallu.); 提出ViHallu框架，通过生成视觉变体图像和构建视觉指令，减少大型视觉语言模型中的幻觉现象，提高视...|
|🆕 发布|ZIUM: Zero-Shot Intent-Aware Adversarial Attack on Unlearned Models|零样本意图感知对抗攻击：针对未学习模型的攻击方法|Hyun Jun Yook, Ga San Jhun, Jae Hyun Cho, Min Jeon, Donghyun Kim, Tae Hyung Kim, Youn Kyu Lee|<http://arxiv.org/pdf/2507.21985v1>|提出ZIUM方法，实现针对未学习模型的零样本意图感知对抗攻击，提高攻击效率和成功率。|
|🆕 发布|Anyone Can Jailbreak: Prompt-Based Attacks on LLMs and T2Is|“任何人都能越狱：基于提示的攻击方法对大型语言模型和文本到图像模型的攻击”|Ahmed B Mustafa, Zihan Ye, Yang Lu, Michael P Pound, Shreyank N Gowda|<http://arxiv.org/pdf/2507.21820v1>|揭示了非专家如何通过巧妙构造的提示绕过大型语言模型和文本转图像系统的安全机制，并提出了统一的策略分类...|
|📝 更新|T2I-Copilot: A Training-Free Multi-Agent Text-to-Image System for Enhanced Prompt Interpretation and Interactive Generation|T2I-Copilot：一种无需训练的多智能体文本到图像系统，用于增强提示解释和交互式生成|Chieh-Yun Chen, Min Shi, Gong Zhang, Humphrey Shi|<http://arxiv.org/pdf/2507.20536v2>|[代码](https://github.com/SHI-Labs/T2I-Copilot.); 提出了一种无需训练的多代理Text-to-Image系统T2I-Copilot，通过自动优化提示词和...|
|📝 更新|Generative Ghost: Investigating Ranking Bias Hidden in AI-Generated Videos|生成幽灵：探究AI生成视频中的排名偏见|Haowen Gao, Liang Pang, Shicheng Xu, Leigang Qu, Tat-Seng Chua, Huawei Shen, Xueqi Cheng|<http://arxiv.org/pdf/2502.07327v2>|揭示了AI生成视频在检索系统中的偏见，并提出了对比学习法来减轻这种偏见。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|IRASim: A Fine-Grained World Model for Robot Manipulation|IRASim：一种用于机器人操作的细粒度世界模型|Fangqi Zhu, Hongtao Wu, Song Guo, Yuxiao Liu, Chilam Cheang, Tao Kong|<http://arxiv.org/pdf/2406.14540v2>|提出了一种细粒度机器人操作世界模型IRASim，通过强化动作与帧的对应关系，提高了机器人操作模拟的准...|
|📝 更新|Diffusion Beats Autoregressive in Data-Constrained Settings|在数据约束环境下，扩散模型优于自回归模型|Mihir Prabhudesai, Mengning Wu, Amir Zadeh, Katerina Fragkiadaki, Deepak Pathak|<http://arxiv.org/pdf/2507.15857v3>|在数据有限的情况下，扩散模型通过更有效地利用重复数据，优于自回归模型。|
|🆕 发布|Contrast-Prior Enhanced Duality for Mask-Free Shadow Removal|对比优先增强的对偶性用于无需遮罩的阴影移除|Jiyu Wu, Yifan Liu, Jiancheng Huang, Mingfu Yan, Shifeng Chen|<http://arxiv.org/pdf/2507.21949v1>|提出AGBA机制和FCFN网络，实现了无需阴影掩膜的图像阴影去除，达到业界领先水平。|
|📝 更新|Motion Diffusion Autoencoders: Enabling Attribute Manipulation in Human Motion Demonstrated on Karate Techniques|运动扩散自动编码器：在空手道技术演示中实现人体运动属性操纵|Anthony Richardson, Felix Putze|<http://arxiv.org/pdf/2501.18729v2>|首次实现了人类运动数据属性的精确操控，通过创新的连续旋转姿态表示和结合变换编码器与扩散模型的方法。|
|📝 更新|Image Captioning via Compact Bidirectional Architecture|通过紧凑双向架构实现图像字幕生成|Zijie Song, Yuanen Zhou, Zhenzhen Hu, Daqing Liu, Huixia Ben, Richang Hong, Meng Wang|<http://arxiv.org/pdf/2201.01984v2>|[代码](https://github.com/YuanEZhou/cbtic.); 提出了一种紧凑双向架构的图像字幕生成模型，通过并行处理左右向信息，提高了上下文利用效率并达到了新的最...|
|🆕 发布|GuidPaint: Class-Guided Image Inpainting with Diffusion Models|类引导的扩散模型图像修复方法 GuidPaint|Qimin Wang, Xinda Liu, Guohua Geng|<http://arxiv.org/pdf/2507.21627v1>|提出GuidPaint框架，通过分类器引导实现无需训练的高质量图像修复。|
|🆕 发布|TARS: MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs|TARS：用于减少大规模语言模型幻觉的MinMax标记自适应偏好策略|Kejia Zhang, Keda Tao, Zhiming Luo, Chang Liu, Jiasheng Tang, Huan Wang|<http://arxiv.org/pdf/2507.21584v1>|提出了一种Token-Adaptive偏好策略TARS，通过MinMax优化减少多模态大语言模型中的...|
|🆕 发布|Locally Controlled Face Aging with Latent Diffusion Models|局部控制的基于潜在扩散模型的面部老化|Lais Isabelle Alves dos Santos, Julien Despois, Thibaut Chauffier, Sileye O. Ba, Giovanni Palma|<http://arxiv.org/pdf/2507.21600v1>|提出了一种利用局部老化特征控制面部老化的新方法，实现了更真实和个性化的面部老化效果。|
|🆕 发布|Describe, Adapt and Combine: Empowering CLIP Encoders for Open-set 3D Object Retrieval|描述、适应与组合：赋予CLIP编码器开集三维物体检索能力|Zhichuan Wang, Yang Zhou, Zhe Liu, Rui Yu, Song Bai, Yulong Wang, Xinwei He, Xiang Bai|<http://arxiv.org/pdf/2507.21489v1>|[代码](https://github.com/wangzhichuan123/DAC.); 提出了一种 Describe, Adapt and Combine 框架，利用 CLIP 模型和多模...|
|📝 更新|LoRA-Loop: Closing the Synthetic Replay Cycle for Continual VLM Learning|LoRA-Loop：为持续VLM学习闭合合成重放周期|Kaihong Wang, Donghyun Kim, Margrit Betke|<http://arxiv.org/pdf/2507.13568v2>|提出了一种通过LoRA增强的合成重放框架，有效解决视觉语言模型在持续学习中的知识保留问题。|
|📝 更新|SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models|SegQuant：面向扩散模型的可感知语义与通用量化框架|Jiaji Zhang, Ruichao Sun, Hailiang Zhao, Jiaju Wu, Peng Chen, Hao Li, Yuying Liu, Kingsum Chow .etc.|<http://arxiv.org/pdf/2507.14811v3>|SegQuant提出了一种自适应的量化框架，通过结合结构语义和空间异质性技术，有效降低扩散模型的计算...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PanoSplatt3R: Leveraging Perspective Pretraining for Generalized Unposed Wide-Baseline Panorama Reconstruction|“PanoSplatt3R：利用透视预训练进行广义非定位宽基线全景重建”|Jiahui Ren, Mochu Xiang, Jiajun Zhu, Yuchao Dai|<http://arxiv.org/pdf/2507.21960v1>|[代码](https://npucvr.github.io/PanoSplatt3R); 提出了一种无需准确姿态信息，通过视角域预训练迁移至全景域的PanoSplatt3R方法，实现了高质量...|
|🆕 发布|Enhancing Generalization in Data-free Quantization via Mixup-class Prompting|通过Mixup类提示增强无数据量化中的泛化能力|Jiwoong Park, Chaeun Lee, Yongseok Choi, Sein Park, Deokki Hong, Jungwook Choi|<http://arxiv.org/pdf/2507.21947v1>|定位数据免费量化中合成图像与模型泛化性的关系，提出mixup-class prompt增强泛化性和优...|
|📝 更新|DIVE: Taming DINO for Subject-Driven Video Editing|DIVE：驯服DINO以实现主体驱动的视频编辑|Yi Huang, Wei Xiong, He Zhang, Chaoqi Chen, Jianzhuang Liu, Mingfu Yan, Shifeng Chen|<http://arxiv.org/pdf/2412.03347v2>|提出DIVE框架，利用DINO模型特征实现视频编辑中的动作一致性和主体精确编辑。|
|📝 更新|DreamScene: 3D Gaussian-based End-to-end Text-to-3D Scene Generation|梦境场景：基于3D高斯的端到端文本到三维场景生成|Haoran Li, Yuli Tian, Kun Lan, Yong Liao, Lin Wang, Pan Hui, Peng Yuan Zhou|<http://arxiv.org/pdf/2507.13985v2>|[代码](https://jahnsonblack.github.io/DreamScene-Full); 定位自然语言驱动的3D场景生成挑战，提出DreamScene框架，实现高质量、可编辑的场景自动构建。|
|🆕 发布|MixGRPO: Unlocking Flow-based GRPO Efficiency with Mixed ODE-SDE|混合GRPO：通过混合常微分方程-随机微分方程解锁基于流的GRPO效率|Junzhe Li, Yutao Cui, Tao Huang, Yinping Ma, Chun Fan, Miles Yang, Zhao Zhong|<http://arxiv.org/pdf/2507.21802v1>|[代码](https://github.com/Tencent-Hunyuan/MixGRPO); 提出MixGRPO框架，通过结合SDE和ODE优化采样策略，大幅提升图像生成模型效率。|
|🆕 发布|APT: Improving Diffusion Models for High Resolution Image Generation with Adaptive Path Tracing|APT：自适应路径追踪提高高分辨率图像生成的扩散模型性能|Sangmin Han, Jinho Jeong, Jinwoo Kim, Seon Joo Kim|<http://arxiv.org/pdf/2507.21690v1>|提出了一种自适应路径追踪框架APT，有效解决高分辨率图像生成中的分布偏移和单调性问题，提升图像清晰度...|
|📝 更新|ZeroStereo: Zero-shot Stereo Matching from Single Images|零样本立体匹配：从单张图像中实现立体匹配|Xianqi Wang, Hao Yang, Gangwei Xu, Junda Cheng, Min Lin, Yong Deng, Jinliang Zang, Yurui Chen .etc.|<http://arxiv.org/pdf/2501.08654v4>|[代码](https://github.com/Windsrain/ZeroStereo.); 提出了一种无需标注数据即可生成高质量立体图像的零样本立体匹配方法。|
|📝 更新|PEVLM: Parallel Encoding for Vision-Language Models|并行编码用于视觉-语言模型（PEVLM）|Letian Kang, Shixian Luo, Yiqiang Li, Yuxin Yin, Shenxuan Zhou, Xiaoyang Yu, Jin Yang, Yong Wu|<http://arxiv.org/pdf/2506.19651v3>|提出PEVLM方法，通过并行编码降低长视频场景下的注意力计算复杂度，提升处理效率。|
|📝 更新|Fine-Grained Perturbation Guidance via Attention Head Selection|通过注意力头部选择实现的细粒度扰动引导|Donghoon Ahn, Jiwon Kang, Sanghyun Lee, Minjae Kim, Jaewon Min, Wooseok Jang, Sangwu Lee, Sayak Paul .etc.|<http://arxiv.org/pdf/2506.10978v3>|提出HeadHunter框架，通过选择特定注意力头实现细粒度图像生成控制和质量提升。|
|📝 更新|Signs as Tokens: A Retrieval-Enhanced Multilingual Sign Language Generator|"标记为符号：一种检索增强的多语种手语生成器"|Ronglai Zuo, Rolandos Alexandros Potamias, Evangelos Ververas, Jiankang Deng, Stefanos Zafeiriou|<http://arxiv.org/pdf/2411.17799v3>|提出了一种多语言手语生成模型，通过预训练语言模型和检索增强技术，实现了从文本到3D手语动画的高效转换...|
|📝 更新|Latent Swap Joint Diffusion for 2D Long-Form Latent Generation|潜空间交换联合扩散用于二维长格式潜空间生成|Yusheng Dai, Chenxi Wang, Chang Li, Chen Wang, Jun Du, Kewei Li, Ruoyu Wang, Jiefeng Ma .etc.|<http://arxiv.org/pdf/2502.05130v3>|提出Swap Forward方法，通过帧级双向和单向潜变量交换，有效生成无缝长谱和全景图。|
|📝 更新|JWB-DH-V1: Benchmark for Joint Whole-Body Talking Avatar and Speech Generation Version 1|JWB-DH-V1：联合全身对话头像与语音生成基准版本1|Xinhan Di, Kristin Qi, Pengqian Yu|<http://arxiv.org/pdf/2507.20987v2>|[代码](https://github.com/deepreasonings/WholeBodyBenchmark.); 提出首个全面评估全身动作与自然语音同步生成的多模态数据集及评估协议。|
|📝 更新|LinkTo-Anime: A 2D Animation Optical Flow Dataset from 3D Model Rendering|“LinkTo-Anime：基于3D模型渲染的2D动画光流数据集”|Xiaoyi Feng, Kaifeng Zou, Caichun Cen, Tao Huang, Hui Guo, Zizhou Huang, Yingli Zhao, Mingqing Zhang .etc.|<http://arxiv.org/pdf/2506.02733v2>|介绍了首个专为Cel动画角色运动设计的3D渲染光学流数据集LinkTo-Anime，促进了光学流估计...|
|📝 更新|SCALAR: Scale-wise Controllable Visual Autoregressive Learning|SCALAR：尺度可控的视觉自回归学习|Ryan Xu, Dongyang Jin, Yancheng Bai, Rui Lan, Xu Duan, Lei Sun, Xiangxiang Chu|<http://arxiv.org/pdf/2507.19946v2>|提出了一种基于视觉自回归模型的生成方法SCALAR，通过尺度条件解码机制有效提升了图像合成的可控性和...|
|📝 更新|InfiniteYou: Flexible Photo Recrafting While Preserving Your Identity|无限我：在保持身份的同时实现灵活的照片重构|Liming Jiang, Qing Yan, Yumin Jia, Zichuan Liu, Hao Kang, Xin Lu|<http://arxiv.org/pdf/2503.16418v2>|提出InfiniteYou框架，利用Diffusion Transformers增强身份相似度并提升...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HunyuanWorld 1.0: Generating Immersive, Explorable, and Interactive 3D Worlds from Words or Pixels|《HunyuanWorld 1.0：从文字或像素生成沉浸式、可探索和交互式三维世界》|HunyuanWorld Team, Zhenwei Wang, Yuhao Liu, Junta Wu, Zixiao Gu, Haoyuan Wang, Xuhui Zuo, Tianyu Huang .etc.|<http://arxiv.org/pdf/2507.21809v1>|提出了HunyuanWorld 1.0框架，融合视频和3D技术优势，生成沉浸式、可探索、互动性3D世...|
|🆕 发布|PRISM: Programmatic Reasoning with Image Sequence Manipulation for LVLM Jailbreaking|PRISM：用于LVLM越狱的图像序列操作程序化推理|Quanchen Zou, Zonghao Ying, Moyang Chen, Wenzhuo Xu, Yisong Xiao, Yakai Li, Deyue Zhang, Dongdong Yang .etc.|<http://arxiv.org/pdf/2507.21540v1>|提出了一种利用图像序列操纵的编程推理框架，有效突破大型视觉语言模型的安全防护。|
|🆕 发布|Chain-of-Cooking:Cooking Process Visualization via Bidirectional Chain-of-Thought Guidance|"链式烹饪：通过双向思维链引导的烹饪过程可视化"|Mengling Xu, Ming Tao, Bing-Kun Bao|<http://arxiv.org/pdf/2507.21529v1>|提出Chain-of-Cooking模型，通过动态选取图像片段和双向思维链指导，实现了烹饪过程图像的...|
|🆕 发布|Suppressing Gradient Conflict for Generalizable Deepfake Detection|结果为：“抑制梯度冲突以实现通用深度伪造检测”|Ming-Hui Liu, Harry Cheng, Xin Luo, Xin-Shun Xu|<http://arxiv.org/pdf/2507.21530v1>|提出方法缓解梯度冲突，提升深度伪造检测模型的泛化能力。|
|📝 更新|Generalizable Neural Electromagnetic Inverse Scattering|通用神经网络电磁逆散射|Yizhe Cheng, Chunxun Tian, Haoru Wang, Wentao Zhu, Xiaoxuan Ma, Yizhou Wang|<http://arxiv.org/pdf/2506.21349v3>|提出了一种物理驱动的电磁逆散射通用框架，通过学习诱导电流作为中间表示，提高了重建准确性和对稀疏发射器...|
|📝 更新|Humanoid Occupancy: Enabling A Generalized Multimodal Occupancy Perception System on Humanoid Robots|人形占位：在仿人机器人上实现广义多模态占位感知系统|Wei Cui, Haoyu Wang, Wenkang Qin, Yijie Guo, Gang Han, Wen Zhao, Jiahang Cao, Zhang Zhang .etc.|<http://arxiv.org/pdf/2507.20217v2>|提出了一种集成软硬件和数据采集的通用多模态占位感知系统，增强人形机器人环境理解能力。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VidFuncta: Towards Generalizable Neural Representations for Ultrasound Videos|《VidFuncta：面向超声视频的通用神经表征研究》|Julia Wolleb, Florentin Bieder, Paul Friedrich, Hemant D. Tagare, Xenophon Papademetris|<http://arxiv.org/pdf/2507.21863v1>|[代码](https://github.com/JuliaWolleb/VidFuncta_public.); 提出VidFuncta框架，利用隐式神经表示处理超声波视频，实现高效视频编码和下游任务性能提升。|
|📝 更新|Probabilistic Directed Distance Fields for Ray-Based Shape Representations|基于射线形表示的概率导向距离场|Tristan Aumentado-Armstrong, Stavros Tsogkas, Sven Dickinson, Allan Jepson|<http://arxiv.org/pdf/2404.09081v2>|提出了一种新型神经网络形状表示方法——导向距离场，实现了高效的微分渲染和几何量提取。|
|📝 更新|LookCloser: Frequency-aware Radiance Field for Tiny-Detail Scene|《LookCloser：面向微小细节场景的频率感知辐射场》|Xiaoyu Zhang, Weihong Pan, Chong Bao, Xiyu Zhang, Xiaojun Xiang, Hanqing Jiang, Hujun Bao|<http://arxiv.org/pdf/2503.18513v3>|[代码](https://coscatter.github.io/LookCloser); 提出了一种频率感知的NeRF框架，同时捕捉场景整体结构和高清细节。|
|📝 更新|Sparfels: Fast Reconstruction from Sparse Unposed Imagery|稀疏无定位图像的快速重建：Sparfels方法|Shubhendu Jena, Amine Ouasfi, Mae Younes, Adnane Boukhayma|<http://arxiv.org/pdf/2505.02178v3>|提出了一种高效的稀疏视角重建方法，利用3D基础模型和2D高斯泼洒技术，在无需精确相机设置的条件下实现...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CAPE: A CLIP-Aware Pointing Ensemble of Complementary Heatmap Cues for Embodied Reference Understanding|CAPE：一种面向具身参考理解的CLIP感知互补热图线索指针集成方法|Fevziye Irem Eyiokur, Dogucan Yaman, Hazım Kemal Ekenel, Alexander Waibel|<http://arxiv.org/pdf/2507.21888v1>|提出了一种结合头部和手腕指向线索的模型框架，通过CLIP感知的集成方法显著提升了实体引用理解准确性。|
|🆕 发布|Adversarial Reconstruction Feedback for Robust Fine-grained Generalization|对抗性重建反馈用于稳健的细粒度泛化|Shijie Wang, Jian Shi, Haojie Li|<http://arxiv.org/pdf/2507.21742v1>|提出AdvRF框架，通过对抗性重建反馈学习类别无关的表征，增强细粒度图像检索的泛化能力。|
|🆕 发布|Decoupled Spatio-Temporal Consistency Learning for Self-Supervised Tracking|解耦的时空一致性学习用于自监督跟踪|Yaozong Zheng, Bineng Zhong, Qihua Liang, Ning Li, Shuxiang Song|<http://arxiv.org/pdf/2507.21606v1>|[代码](https://github.com/GXNU-ZhongLab/SSTrack.); 提出了一种无需框标注的自监督跟踪框架，通过解耦时空一致性学习有效提升跟踪表现。|
|📝 更新|DEPTHOR: Depth Enhancement from a Practical Light-Weight dToF Sensor and RGB Image|深度增强：从实用轻量级直接飞行时间(dToF)传感器与RGB图像出发|Jijun Xiang, Xuan Zhu, Xianqi Wang, Yu Wang, Hong Zhang, Fei Guo, Xin Yang|<http://arxiv.org/pdf/2504.01596v2>|[代码](https://github.com/ShadowBbBb/Depthor); 提出了一种基于合成数据模拟和深度学习的新型方法DEPTHOR，有效提升了dToF传感器与RGB图像融...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GS-SDF: LiDAR-Augmented Gaussian Splatting and Neural SDF for Geometrically Consistent Rendering and Reconstruction|GS-SDF：激光雷达增强的高斯泼洒与神经SDF用于几何一致性的渲染与重建|Jianheng Liu, Yunfei Wan, Bowen Wang, Chunran Zheng, Jiarong Lin, Fu Zhang|<http://arxiv.org/pdf/2503.10170v2>|[代码](https://github.com/hku-mars/GS-SDF.); 整合LiDAR与视觉数据，提出基于神经符号距离场的 Gaussian splatting 方法，实现...|
|🆕 发布|Multi-View Reconstruction with Global Context for 3D Anomaly Detection|多视角重建结合全局上下文的三维异常检测|Yihan Sun, Yuqi Cheng, Yunkang Cao, Yuxin Zhang, Weiming Shen|<http://arxiv.org/pdf/2507.21555v1>|提出了一种通过多视角重建增强全局信息学习的方法，显著提高了三维异常检测的精度。|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Ov3R: Open-Vocabulary Semantic 3D Reconstruction from RGB Videos|《Ov3R：从RGB视频中进行开放词汇语义三维重建》|Ziren Gong, Xiaohan Li, Fabio Tosi, Jiawei Han, Stefano Mattoccia, Jianfei Cai, Matteo Poggi|<http://arxiv.org/pdf/2507.22052v1>|提出Ov3R框架，融合CLIP语义实现精准的3D重建与语义分割。|
|🆕 发布|Low-Cost Test-Time Adaptation for Robust Video Editing|低成本测试时适应以提高视频编辑的鲁棒性|Jianhui Wang, Yinda Chen, Yangfan He, Xinyuan Song, Yi Xin, Dapeng Zhang, Zhongwei Wan, Bin Li .etc.|<http://arxiv.org/pdf/2507.21858v1>|提出了一种轻量级视频编辑优化框架，通过测试时自适应显著提升了编辑质量和模型鲁棒性。|
|🆕 发布|The Evolution of Video Anomaly Detection: A Unified Framework from DNN to MLLM|视频异常检测的演变：从深度神经网络到多模态大型语言模型的统一框架|Shibo Gao, Peipei Yang, Haiyang Guo, Yangyang Liu, Yi Chen, Shuai Li, Han Zhu, Jian Xu .etc.|<http://arxiv.org/pdf/2507.21649v1>|系统分析了基于大型语言模型视频异常检测方法，构建了统一框架并展望了未来研究方向。|
|📝 更新|From Gallery to Wrist: Realistic 3D Bracelet Insertion in Videos|从图库到手腕：视频中真实的三维手镯插入|Chenjian Gao, Lihe Ding, Rui Han, Zhanpeng Huang, Zibin Wang, Tianfan Xue|<http://arxiv.org/pdf/2507.20331v2>|[代码](https://cjeen.github.io/BraceletPaper); 提出了一种结合3D渲染与2D扩散模型的方法，实现了视频中动态场景下3D手镯插入的时空一致性与真实光照...|
|🆕 发布|An Angular-Temporal Interaction Network for Light Field Object Tracking in Low-Light Scenes|低光场景下光场目标跟踪的角时交互网络|Mianzhao Wang, Fan Shi, Xu Cheng, Feifei Zhang, Shengyong Chen|<http://arxiv.org/pdf/2507.21460v1>|提出了一种新型角时交互网络，用于低光场景下的光场目标跟踪，通过学习角度感知表征实现跟踪性能的提升。|
|📝 更新|SAM2Long: Enhancing SAM 2 for Long Video Segmentation with a Training-Free Memory Tree|SAM2Long：使用无需训练的记忆树增强SAM 2进行长视频分割|Shuangrui Ding, Rui Qian, Xiaoyi Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Yuwei Guo, Dahua Lin .etc.|<http://arxiv.org/pdf/2410.16268v3>|[代码](https://github.com/Mark12Ding/SAM2Long.); 提出了一种无训练记忆树策略，通过多路径选择优化长视频对象分割，有效解决了误差累积问题。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Motion Matters: Motion-guided Modulation Network for Skeleton-based Micro-Action Recognition|运动至关重要：基于运动的调制网络用于基于骨架的微动作识别|Jihao Gu, Kun Li, Fei Wang, Yanyan Wei, Zhiliang Wu, Hehe Fan, Meng Wang|<http://arxiv.org/pdf/2507.21977v1>|[代码](https://github.com/momiji-bit/MMN.); 提出了一种基于运动引导的调节网络，有效捕捉并增强微动作中的细微运动特征，提升了微动作识别的准确性。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|When Tokens Talk Too Much: A Survey of Multimodal Long-Context Token Compression across Images, Videos, and Audios|当标记说过多话语：跨图像、视频和音频的多模态长上下文标记压缩综述|Kele Shao, Keda Tao, Kejia Zhang, Sicheng Feng, Mu Cai, Yuzhang Shang, Haoxuan You, Can Qin .etc.|<http://arxiv.org/pdf/2507.20198v2>|系统综述了多模态长上下文中的token压缩技术，分类并分析了图像、视频和音频数据压缩方法。|
|🆕 发布|Attention-Driven Multimodal Alignment for Long-term Action Quality Assessment|基于注意力驱动的多模态对齐用于长期动作质量评估|Xin Wang, Peng-Jie Li, Yuan-Yuan Shen|<http://arxiv.org/pdf/2507.21945v1>|提出了一种用于长期动作质量评估的多模态对齐方法，通过注意力机制稳定融合视觉与音频信息，提升了性能评估...|
|📝 更新|UniPaint: Unified Space-time Video Inpainting via Mixture-of-Experts|统一时空视频修复：基于专家混合模型的方法|Zhen Wan, Chenyang Qi, Zhiheng Liu, Tao Gui, Yue Ma|<http://arxiv.org/pdf/2412.06340v2>|[代码](https://github.com/mmmmm-w/UniPaint); 提出了统一时空视频修复框架UniPaint，通过混合专家注意力机制同时实现视频修复和插值，相互促进提...|
|🆕 发布|VAGU & GtS: LLM-Based Benchmark and Framework for Joint Video Anomaly Grounding and Understanding|视频异常定位与理解联合的LLM基础上的基准与框架：VAGU与GtS|Shibo Gao, Peipei Yang, Yangyang Liu, Yi Chen, Han Zhu, Xuyao Zhang, Linlin Huang|<http://arxiv.org/pdf/2507.21507v1>|提出首个整合异常定位与理解的计算机视觉基准，并设计了一种基于文本提示的框架。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Unified 3D MRI Representations via Sequence-Invariant Contrastive Learning|通过序列不变性对比学习统一三维MRI表征|Liam Chalcroft, Jenny Crinion, Cathy J. Price, John Ashburner|<http://arxiv.org/pdf/2501.12057v3>|[代码](https://github.com/liamchalcroft/contrast-squared); 提出了一种序列不变的自监督学习方法，通过模拟单一3D qMRI扫描的多种MRI对比，学习到适用于多种...|
|📝 更新|FIX-CLIP: Dual-Branch Hierarchical Contrastive Learning via Synthetic Captions for Better Understanding of Long Text|FIX-CLIP：通过合成字幕进行双分支层次对比学习以更好地理解长文本|Bingchao Wang, Zhiwei Ning, Jianyu Ding, Xuanang Gao, Yin Li, Dongsheng Jiang, Jie Yang, Wei Liu|<http://arxiv.org/pdf/2507.10095v2>|[代码](https://github.com/bcwang-sjtu/Fix-CLIP.); 提出FIX-CLIP模型，通过双分支训练和区域信息提取，有效提升长文本在视觉任务中的表现。|


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Cross-Architecture Distillation Made Simple with Redundancy Suppression|结果为：“跨架构蒸馏通过冗余抑制简化实现”|Weijia Zhang, Yuehao Liu, Wu Ran, Chao Ma|<http://arxiv.org/pdf/2507.21844v1>|提出了一种简化的跨架构知识蒸馏方法，通过抑制冗余信息提升效率和适用性。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Predict Patient Self-reported Race from Skin Histological Images|从皮肤组织学图像预测患者自报种族|Shengjia Chen, Ruchika Verma, Kevin Clare, Jannes Jegminat, Kuan-lin Huang, Brandon Veremis, Thomas Fuchs, Gabriele Campanella|<http://arxiv.org/pdf/2507.21912v1>|[代码](https://github.com/sinai-computational-pathology/CPath_SAIF.); 探究深度学习模型预测患者自报种族，发现皮肤组织图像中的种族相关形态学特征。|
|🆕 发布|Evaluating Deepfake Detectors in the Wild|在野外评估深度伪造检测器|Viacheslav Pirogov, Maksim Artemev|<http://arxiv.org/pdf/2507.21905v1>|[代码](https://github.com/messlav/Deepfake-Detectors-in-the-Wild.); 评估现代深度伪造检测器在现实世界数据中的效果，发现多数检测器性能不足且易受基本图像处理影响。|
|📝 更新|RobustSplat: Decoupling Densification and Dynamics for Transient-Free 3DGS|稳健散点: 解耦细化与动态特性以实现无瞬态的三维网格简化|Chuanyu Fu, Yuqi Zhang, Kunbin Yao, Guanying Chen, Yuan Xiong, Chuan Huang, Shuguang Cui, Xiaochun Cao|<http://arxiv.org/pdf/2506.02751v3>|[代码](https://fcyycf.github.io/RobustSplat); 提出了一种延缓高斯增长和级联掩码引导的策略，有效解决了3D场景中动态物体带来的渲染伪影问题。|
|🆕 发布|LinDeps: A Fine-tuning Free Post-Pruning Method to Remove Layer-Wise Linear Dependencies with Guaranteed Performance Preservation|LinDeps：一种无需微调的剪枝方法，用于移除层间线性依赖性，并确保性能保持|Maxim Henry, Adrien Deliège, Anthony Cioppa, Marc Van Droogenbroeck|<http://arxiv.org/pdf/2507.21573v1>|提出了一种无需微调的剪枝后处理方法LinDeps，通过线性依赖分析提高神经网络压缩率同时保持性能。|
|🆕 发布|Sun sensor calibration algorithms: A systematic mapping and survey|太阳传感器校准算法：系统性映射与综述|Michael Herman, Olivia J. Pinon Fischer, Dimitri N. Mavris|<http://arxiv.org/pdf/2507.21541v1>|系统梳理了太阳传感器建模与校准算法，为减少不确定性提供了全面方法与未来研究方向。|
|📝 更新|A Multi-Agent System Enables Versatile Information Extraction from the Chemical Literature|多代理系统实现从化学文献中提取多样化信息|Yufan Chen, Ching Ting Leung, Bowen Yu, Jianwei Sun, Yong Huang, Linyan Li, Hao Chen, Hanyu Gao|<http://arxiv.org/pdf/2507.20230v2>|开发了一种多模态大语言模型驱动的多代理系统，实现了对化学文献中复杂信息的高效自动提取。|
|🆕 发布|ReGATE: Learning Faster and Better with Fewer Tokens in MLLMs|ReGATE：在多模态大型语言模型中用更少的标记实现更快和更好的学习|Chaoyu Li, Yogesh Kulkarni, Pooyan Fazli|<http://arxiv.org/pdf/2507.21420v1>|提出了一种自适应的少量标记训练方法ReGATE，通过选择性处理关键标记，加速多模态大语言模型训练效率...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MSGCoOp: Multiple Semantic-Guided Context Optimization for Few-Shot Learning|MSGCoOp：基于多语义引导的上下文优化用于少样本学习|Zhaolong Wang, Tongfeng Sun, Mingzheng Du, Yachao Huang|<http://arxiv.org/pdf/2507.21786v1>|[代码](https://github.com/Rain-Bus/MSGCoOp); 提出了一种高效的 MSGCoOp 框架，通过多语义引导优化提升少量样本学习泛化能力。|
|📝 更新|Fuse Before Transfer: Knowledge Fusion for Heterogeneous Distillation|"融合后再迁移：异构知识蒸馏中的知识融合"|Guopeng Li, Qiang Wang, Ke Yan, Shouhong Ding, Yuan Gao, Gui-Song Xia|<http://arxiv.org/pdf/2410.12342v2>|提出了一种融合异构模型知识的方法，通过辅助模型桥接不同架构，提升了异构知识蒸馏的效果。|
|🆕 发布|Optimizing Active Learning in Vision-Language Models via Parameter-Efficient Uncertainty Calibration|通过参数高效的不确定性校准优化视觉语言模型中的主动学习|Athmanarayanan Lakshmi Narayanan, Amrutha Machireddy, Ranganath Krishnan|<http://arxiv.org/pdf/2507.21521v1>|提出了一种参数高效的主动学习方法，通过引入不确定性校准损失，有效选择少量最有信息的数据样本进行微调。|
|📝 更新|PPJudge: Towards Human-Aligned Assessment of Artistic Painting Process|PPJudge：面向与人类一致的艺术绘画过程评估|Shiqi Jiang, Xinpeng Li, Xi Mao, Changbo Wang, Chenhui Li|<http://arxiv.org/pdf/2507.09242v2>|提出了一种评估绘画过程的框架PPJudge，通过结合专家标注的大型数据集，实现了与人类判断更一致的动...|
|🆕 发布|Boost Self-Supervised Dataset Distillation via Parameterization, Predefined Augmentation, and Approximation|通过参数化、预定义增强和近似提升自监督数据集蒸馏|Sheng-Feng Yu, Jia-Jiun Yao, Wei-Chen Chiu|<http://arxiv.org/pdf/2507.21455v1>|提出了一种自监督数据集蒸馏方法，通过参数化、预定义增强和近似，提高了数据集压缩效率和模型泛化能力。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AIM: Adaptive Inference of Multi-Modal LLMs via Token Merging and Pruning|自适应多模态大规模语言模型通过标记合并与剪枝的推理方法|Yiwu Zhong, Zhuoming Liu, Yin Li, Liwei Wang|<http://arxiv.org/pdf/2412.03248v2>|[代码](https://github.com/LaVi-Lab/AIM.); 提出了一种自适应推理方法，通过迭代合并和逐步剪枝视觉标记，有效降低多模态大语言模型的计算负担同时保持...|
|📝 更新|Beyond Class Tokens: LLM-guided Dominant Property Mining for Few-shot Classification|超越类别标记：基于大语言模型引导的主导属性挖掘用于少样本分类|Wei Zhuo, Runjie Luo, Wufeng Xue, Linlin Shen|<http://arxiv.org/pdf/2507.20511v2>|提出了一种利用大语言模型引导的对比学习新方法，通过挖掘图像的支配属性，有效提升了少量样本学习中的分类...|
|📝 更新|DASH: 4D Hash Encoding with Self-Supervised Decomposition for Real-Time Dynamic Scene Rendering|DASH：用于实时动态场景渲染的自监督分解4D哈希编码|Jie Chen, Zhangchi Hu, Peixi Wu, Huyue Zhu, Hebei Li, Xiaoyan Sun|<http://arxiv.org/pdf/2507.19141v2>|[代码](https://github.com/chenj02/DASH.); 提出DASH框架，通过自监督分解和4D哈希编码实现实时动态场景渲染，提升视觉质量。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Posture-Driven Action Intent Inference for Playing style and Fatigue Assessment|基于姿态驱动的动作意图推断：用于演奏风格与疲劳度评估|Abhishek Jaiswal, Nisheeth Srivastava|<http://arxiv.org/pdf/2507.11642v2>|提出了一种基于姿态分析的运动意图推断方法，有效区分运动中的攻击性和防御性意图。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Puzzle Similarity: A Perceptually-guided Cross-Reference Metric for Artifact Detection in 3D Scene Reconstructions|拼图相似性：一种基于感知引导的跨参考度量，用于三维场景重建中的文物检测|Nicolai Hermann, Jorge Condor, Piotr Didyk|<http://arxiv.org/pdf/2411.17489v3>|[代码](https://nihermann.github.io/puzzlesim); 提出了一种新的Puzzle Similarity度量方法，通过分析图像块统计来准确检测3D场景重建中...|
|📝 更新|Incentivizing Reasoning for Advanced Instruction-Following of Large Language Models|激励推理以提高大型语言模型的高级指令遵循能力|Yulei Qin, Gang Li, Zongyi Li, Zihan Xu, Yuchen Shi, Zhekai Lin, Xiao Cui, Ke Li .etc.|<http://arxiv.org/pdf/2506.01413v5>|[代码](https://github.com/yuleiqin/RAIF.); 提出RAIF方法，通过激励推理增强大型语言模型处理复杂指令的能力，实现性能显著提升。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|StepAL: Step-aware Active Learning for Cataract Surgical Videos|步进感知主动学习法在白内障手术视频中的应用|Nisarg A. Shah, Bardia Safaei, Shameema Sikder, S. Swaroop Vedula, Vishal M. Patel|<http://arxiv.org/pdf/2507.22059v1>|提出StepAL框架，通过视频级选择和步态感知特征，优化手术视频步骤识别的主动学习过程。|
|🆕 发布|Shallow Deep Learning Can Still Excel in Fine-Grained Few-Shot Learning|浅层深度学习依然能在细粒度少样本学习中表现卓越|Chaofei Qi, Chao Ye, Zhitai Liu, Weiyang Lin, Jianbin Qiu|<http://arxiv.org/pdf/2507.22041v1>|提出位置感知网络LCN-4，通过特征聚类与位置编码提升浅层网络在细粒度少样本学习中的性能。|
|🆕 发布|VeS: Teaching Pixels to Listen Without Supervision|VeS：在无监督条件下教像素“听”声|Sajay Raj|<http://arxiv.org/pdf/2507.22008v1>|提出了一种适用于低资源多语言环境的密集音频视觉模型，通过优化聚合函数显著提升了检索和定位性能。|
|🆕 发布|Cyst-X: AI-Powered Pancreatic Cancer Risk Prediction from Multicenter MRI in Centralized and Federated Learning|cyst-X：基于人工智能的多中心磁共振成像在集中式和联邦学习中的胰腺癌风险预测|Hongyi Pan, Gorkem Durak, Elif Keles, Deniz Seyithanoglu, Zheyuan Zhang, Alpay Medetalibeyoglu, Halil Ertugrul Aktas, Andrea Mia Bejar .etc.|<http://arxiv.org/pdf/2507.22017v1>|提出Cyst-X框架，利用多中心MRI数据预测胰腺癌风险，性能超越传统指南和放射专家。|
|🆕 发布|UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding|UI-AGILE：利用有效的强化学习和精确的推理时间定位推进图形界面代理的发展|Shuquan Lian, Yuhang Wu, Jia Ma, Zihan Song, Bingqi Chen, Xiawu Zheng, Hui Li|<http://arxiv.org/pdf/2507.22025v1>|UI-AGILE通过创新的训练奖励机制和精确的推理时定位方法，提升了图形界面代理的训练效果和性能。|
|🆕 发布|A Deep Learning Pipeline Using Synthetic Data to Improve Interpretation of Paper ECG Images|使用合成数据改进纸质心电图图像解读的深度学习管道|Xiaoyu Wang, Ramesh Nadarajah, Zhiqiang Zhang, David Wong|<http://arxiv.org/pdf/2507.21968v1>|提出了一种深度学习框架，利用合成数据预处理和两阶段微调策略，有效识别纸质心电图图像中的心血管疾病特征...|
|🆕 发布|LiteFat: Lightweight Spatio-Temporal Graph Learning for Real-Time Driver Fatigue Detection|LiteFat：实时驾驶员疲劳检测的轻量级时空图学习|Jing Ren, Suyu Ma, Hong Jia, Xiwei Xu, Ivan Lee, Haytham Fayek, Xiaodong Li, Feng Xia|<http://arxiv.org/pdf/2507.21756v1>|提出了一种轻量级时空图学习模型LiteFat，用于实时高效地检测驾驶员疲劳，降低计算复杂度和延迟。|
|📝 更新|Geometric Algebra Meets Large Language Models: Instruction-Based Transformations of Separate Meshes in 3D, Interactive and Controllable Scenes|几何代数遇见大型语言模型：基于指令的三维独立网格在交互式可控场景中的变换|Prodromos Kolyvakis, Manos Kamarianakis, George Papagiannakis|<http://arxiv.org/pdf/2408.02275v2>|集成大型语言模型与共形几何代数，实现了无需专业训练即可精确控制三维场景中物体位置的创新编辑方法。|
|📝 更新|Language Driven Occupancy Prediction|语言驱动的占用预测|Zhu Yu, Bowen Pang, Lizhe Liu, Runmin Zhang, Qiang Li, Si-Yuan Cao, Maochun Luo, Mingxia Chen .etc.|<http://arxiv.org/pdf/2411.16072v2>|提出了一种语义传递标注流程，通过精确的体素到文本对应关系，有效指导三维语言体积学习，优于现有零样本占...|
|🆕 发布|Wind Turbine Feature Detection Using Deep Learning and Synthetic Data|使用深度学习和合成数据的风力涡轮机特征检测|Arash Shahirpour, Jakob Gebler, Manuel Sanders, Tim Reuscher|<http://arxiv.org/pdf/2507.21611v1>|提出了一种利用深度学习和合成数据生成技术，有效提高了风力涡轮机特征检测准确性和训练数据多样性。|
|🆕 发布|Progressive Homeostatic and Plastic Prompt Tuning for Audio-Visual Multi-Task Incremental Learning|渐进性稳态与塑性提示调优用于音频-视觉多任务增量学习|Jiong Yin, Liang Li, Jiehua Zhang, Yuhan Gao, Chenggang Yan, Xichun Sheng|<http://arxiv.org/pdf/2507.21588v1>|[代码](https://github.com/ENJOY-Yin-jiong/PHP.); 提出三阶段PHP方法，通过任务共享和特定适配器平衡多任务增量学习中的知识保留与适应。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bridging Synthetic and Real-World Domains: A Human-in-the-Loop Weakly-Supervised Framework for Industrial Toxic Emission Segmentation|连接合成与真实世界领域：一种面向工业毒性排放分割的带有人机交互的弱监督框架|Yida Tao, Yen-Chia Hsu|<http://arxiv.org/pdf/2507.22002v1>|提出了CEDANet框架，通过结合人类反馈和弱监督学习，有效提升了工业烟雾分割的准确性。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ST-DAI: Single-shot 2.5D Spatial Transcriptomics with Intra-Sample Domain Adaptive Imputation for Cost-efficient 3D Reconstruction|ST-DAI：基于样本内域自适应插值的单次2.5D空间转录组学技术，用于高效三维重建|Jiahe Qian, Yaoyu Fang, Xinkun Wang, Lee A. Cooper, Bo Zhou|<http://arxiv.org/pdf/2507.21516v1>|提出ST-DAI方法，通过2.5D采样和样本内域自适应插值，以低成本实现3D空间转录组重建。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|An Integrated Approach to Robotic Object Grasping and Manipulation|机器人对象抓取与操作的一体化方法|Owais Ahmed, M Huzaifa, M Areeb, Hamza Ali Khan|<http://arxiv.org/pdf/2411.13205v3>|开发了一种能自主适应不确定物品位置的机器人系统，高效完成货架物品的挑选任务。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GLIMPSE: Holistic Cross-Modal Explainability for Large Vision-Language Models|《GLIMPSE：大型视觉语言模型的整体跨模态解释性》|Guanxi Shen|<http://arxiv.org/pdf/2506.18985v3>|提出GLIMPSE框架，通过融合多模态信号提升大型视觉语言模型的可解释性。|
|🆕 发布|ArtSeek: Deep artwork understanding via multimodal in-context reasoning and late interaction retrieval|艺术探寻：通过多模态上下文推理和延迟交互检索进行深度艺术品理解|Nicola Fanelli, Gennaro Vessio, Giovanna Castellano|<http://arxiv.org/pdf/2507.21917v1>|[代码](https://github.com/cilabuniba/artseek.); 提出ArtSeek框架，融合多模态大语言模型与检索增强生成，提升艺术品分析与理解能力。|
|🆕 发布|SAMITE: Position Prompted SAM2 with Calibrated Memory for Visual Object Tracking|SAMITE：基于位置提示的SAM2与校准内存的视觉目标跟踪|Qianxiong Xu, Lanyun Zhu, Chenxi Liu, Guosheng Lin, Cheng Long, Ziyue Li, Rui Zhao|<http://arxiv.org/pdf/2507.21732v1>|[代码](https://github.com/Sam1224/SAMITE.); 提出SAMITE模型，通过原型记忆库和位置提示生成器提升视觉目标跟踪的准确性和鲁棒性。|
|📝 更新|Improving Visual Place Recognition with Sequence-Matching Receptiveness Prediction|利用序列匹配响应性预测提高视觉场景识别性能|Somayeh Hussaini, Tobias Fischer, Michael Milford|<http://arxiv.org/pdf/2503.06840v2>|提出了一种预测序列匹配适应性的学习方法，有效提升了多种视觉定位技术的性能。|
|🆕 发布|Recursive Visual Imagination and Adaptive Linguistic Grounding for Vision Language Navigation|递归视觉想象与自适应语言定位的视觉语言导航|Bolei Chen, Jiaxu Kang, Yifei Wang, Ping Zhong, Qi Wu, Jianxin Wang|<http://arxiv.org/pdf/2507.21450v1>|提出了一种递归视觉想象和自适应语言定位策略，有效提升了视觉语言导航任务的准确性和效率。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Impact of Underwater Image Enhancement on Feature Matching|水下图像增强对特征匹配的影响|Jason M. Summers, Mark W. Jones|<http://arxiv.org/pdf/2507.21715v1>|提出了一种评估水下图像增强对特征匹配影响的框架，提高了水下导航算法的鲁棒性。|
|📝 更新|Fast Globally Optimal and Geometrically Consistent 3D Shape Matching|快速全局最优且几何一致的三维形状匹配|Paul Roetzer, Florian Bernard|<http://arxiv.org/pdf/2504.06385v3>|提出了一种计算全局最优且几何一致性的3D形状匹配方法，通过构建超图并解决最小成本流问题实现高效匹配。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ReXGroundingCT: A 3D Chest CT Dataset for Segmentation of Findings from Free-Text Reports|“ReXGroundingCT：一种用于从自由文本报告中分割发现的3D胸部CT数据集”|Mohammed Baharoon, Luyang Luo, Michael Moritz, Abhinav Kumar, Sung Eun Kim, Xiaoman Zhang, Miao Zhu, Mahmoud Hussain Alabbad .etc.|<http://arxiv.org/pdf/2507.22030v1>|创建了ReXGroundingCT数据集，将自由文本放射学发现与3D胸部CT扫描的像素级分割关联，填...|
|📝 更新|Ensuring Medical AI Safety: Interpretability-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data|确保医疗AI安全：基于可解释性的检测与缓解模型异常行为及其相关数据|Frederik Pahde, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek|<http://arxiv.org/pdf/2501.13818v2>|[代码](https://github.com/frederikpahde/medical-ai-safety.); 提出Reveal2Revise框架，结合半自动化解释性标注，有效检测和减轻医学AI中的偏差问题。|
|🆕 发布|SwinECAT: A Transformer-based fundus disease classification model with Shifted Window Attention and Efficient Channel Attention|SwinECAT：一种基于移窗注意力与高效通道注意力的Transformer基金眼底疾病分类模型|Peiran Gu, Teng Yao, Mengshen He, Fuhao Duan, Feiyan Liu, RenYuan Peng, Bao Ge|<http://arxiv.org/pdf/2507.21922v1>|提出SwinECAT模型，结合Shifted Window Attention与Efficient ...|
|📝 更新|Bias Analysis for Synthetic Face Detection: A Case Study of the Impact of Facial Attributes|合成人脸检测的偏差分析：面部属性影响的研究案例|Asmae Lamsaf, Lucia Cascone, Hugo Proença, João Neves|<http://arxiv.org/pdf/2507.19705v2>|提出了一种评估框架，揭示了合成人脸检测器在不同面部属性上的偏见问题。|
|🆕 发布|Distribution-Based Masked Medical Vision-Language Model Using Structured Reports|基于分布的掩码医疗视觉-语言模型使用结构化报告|Shreyank N Gowda, Ruichi Zhang, Xiao Gu, Ying Weng, Lu Yang|<http://arxiv.org/pdf/2507.21794v1>|提出了一种基于结构化报告的不确定性感知医疗图像-文本预训练模型，提高了医学图像分析泛化能力并取得下游...|
|🆕 发布|Few-Shot Vision-Language Reasoning for Satellite Imagery via Verifiable Rewards|通过可验证奖励进行卫星图像的少量样本视觉语言推理|Aybora Koksal, A. Aydin Alatan|<http://arxiv.org/pdf/2507.21745v1>|提出了一种基于少量样本和可验证奖励的卫星图像视觉语言推理框架，有效解决了专业领域数据稀缺问题。|
|📝 更新|Differential-UMamba: Rethinking Tumor Segmentation Under Limited Data Scenarios|差分-UMamba：在数据有限场景下对肿瘤分割的再思考|Dhruv Jain, Romain Modzelewski, Romain Herault, Clement Chatelain, Eva Torfeh, Sebastien Thureau|<http://arxiv.org/pdf/2507.18177v2>|提出Diff-UMamba模型，结合UNet与mamba机制，通过信号差分策略提升少量数据下的肿瘤分...|
|📝 更新|Efficacy of Image Similarity as a Metric for Augmenting Small Dataset Retinal Image Segmentation|图像相似性作为增强小数据集视网膜图像分割度量的有效性|Thomas Wallace, Ik Siong Heng, Senad Subasic, Chris Messenger|<http://arxiv.org/pdf/2507.04862v3>|研究显示，更相似的合成图像（低FID）更有效提升U-Net模型性能。|
|📝 更新|Few-shot Online Anomaly Detection and Segmentation|少量样本在线异常检测与分割|Shenxing Wei, Xing Wei, Zhiheng Ma, Songlin Dong, Shaochen Zhang, Yihong Gong|<http://arxiv.org/pdf/2403.18201v2>|提出了一种基于少量样本的在线异常检测与分割方法，通过神经网络和增量更新提升模型性能。|
|📝 更新|AI-ming backwards: Vanishing archaeological landscapes in Mesopotamia and automatic detection of sites on CORONA imagery|《倒退的智能：美索不达米亚消失的考古景观与CORONA影像中遗址的自动检测》|Alessandro Pistola, Valentina Orru', Nicolo' Marchetti, Marco Roccetti|<http://arxiv.org/pdf/2507.13420v2>|利用历史CORONA卫星图像训练深度学习模型，有效识别已消失考古遗址，实现90%检测准确率。|
|📝 更新|Towards Facilitated Fairness Assessment of AI-based Skin Lesion Classifiers Through GenAI-based Image Synthesis|基于生成式AI图像合成的AI皮肤病变分类器公平性评估便捷化方法研究|Ko Watanabe, Stanislav Frolov, Adriano Lucieri, Andreas Dengel|<http://arxiv.org/pdf/2507.17860v2>|利用生成式AI创建合成图像以评估皮肤病变分类器的公平性，提出新方法增强医疗成像系统的公平性评估。|
|🆕 发布|Dual Cross-image Semantic Consistency with Self-aware Pseudo Labeling for Semi-supervised Medical Image Segmentation|双图像间语义一致性结合自感知伪标签标注用于半监督医学图像分割|Han Wu, Chong Wang, Zhiming Cui|<http://arxiv.org/pdf/2507.21440v1>|[代码](https://github.com/ShanghaiTech-IMPACT/DuCiSC); 提出了一种双图像语义一致性框架，通过自感知伪标签策略，有效解决了半监督医学图像分割中标签数据不足和特...|
|📝 更新|MedViT V2: Medical Image Classification with KAN-Integrated Transformers and Dilated Neighborhood Attention|MedViT V2：基于集成KAN的变换器和扩张邻域注意力的医学图像分类|Omid Nejati Manzari, Hojat Asgariandehkordi, Taha Koleilat, Yiming Xiao, Hassan Rivaz|<http://arxiv.org/pdf/2502.13693v2>|MedViTV2通过集成KAN层和改进的注意力机制，提升了医疗图像分类的泛化能力和准确性。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Research Challenges and Progress in the End-to-End V2X Cooperative Autonomous Driving Competition|端到端车联网协同自动驾驶竞赛的研究挑战与进展|Ruiyang Hao, Haibao Yu, Jiaru Zhong, Chuanye Wang, Jiahao Wang, Yiming Kan, Wenxian Yang, Siqi Fan .etc.|<http://arxiv.org/pdf/2507.21610v1>|介绍了端到端V2X合作自动驾驶竞赛的设计与成果，推动了可靠自动驾驶系统的发展。|
|📝 更新|SCORE: Scene Context Matters in Open-Vocabulary Remote Sensing Instance Segmentation|结果：  SCORE：场景上下文在开放词汇遥感实例分割中至关重要|Shiqi Huang, Shuting He, Huaiyuan Qin, Bihan Wen|<http://arxiv.org/pdf/2507.12857v2>|[代码](https://github.com/HuangShiqi128/SCORE.); 提出了一种融合场景上下文的开放词汇遥感实例分割框架，提升了模型对新颖类别和不同数据集的泛化能力。|
|📝 更新|RISEE: A Highly Interactive Naturalistic Driving Trajectories Dataset with Human Subjective Risk Perception and Eye-tracking Information|RISEE：一种具有高度交互性的自然驾驶轨迹数据集，包含人类主观风险感知与眼动信息|Xinzheng Wu, Junyi Chen, Peiyi Wang, Shunxiang Chen, Haolan Meng, Yong Shen|<http://arxiv.org/pdf/2507.19490v2>|构建了集成人类主观风险感知和眼动数据的自然驾驶轨迹数据集RISEE，结合无人机和模拟数据采集优势。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RelMap: Enhancing Online Map Construction with Class-Aware Spatial Relation and Semantic Priors|《RelMap：利用类别感知空间关系和语义先验增强在线地图构建》|Tianhui Cai, Yun Zhang, Zewei Zhou, Zhiyu Huang, Jiaqi Ma|<http://arxiv.org/pdf/2507.21567v1>|提出了一种融合位置关系和语义先验的在线高精度地图构建框架，提升了自动驾驶系统的地图构建准确性和泛化能...|
|🆕 发布|MapDiffusion: Generative Diffusion for Vectorized Online HD Map Construction and Uncertainty Estimation in Autonomous Driving|结果： 地图扩散：面向自动驾驶的矢量在线高清地图构建与不确定性估计的生成扩散方法|Thomas Monninger, Zihan Zhang, Zhipeng Mo, Md Zafar Anwar, Steffen Staab, Sihao Ding|<http://arxiv.org/pdf/2507.21423v1>|提出MapDiffusion方法，通过迭代 refine 初始化查询，生成多可能地图样本，提升自动驾...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Enhancing Glass Defect Detection with Diffusion Models: Addressing Imbalanced Datasets in Manufacturing Quality Control|利用扩散模型增强玻璃缺陷检测：解决制造质量控制中的数据集不平衡问题|Sajjad Rezvani Boroujeni, Hossein Abedi, Tom Bush|<http://arxiv.org/pdf/2505.03134v3>|利用去噪扩散概率模型生成合成缺陷图像，有效解决玻璃制造视觉检测中的数据不平衡问题。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Staining and locking computer vision models without retraining|染色与锁定计算机视觉模型而不需要重新训练|Oliver J. Sutton, Qinghua Zhou, George Leete, Alexander N. Gorban, Ivan Y. Tyukin|<http://arxiv.org/pdf/2507.22000v1>|提出无需重新训练的水印和锁定技术，保护预训练模型知识产权且不影响性能。|
|📝 更新|Back Home: A Computer Vision Solution to Seashell Identification for Ecological Restoration|《回归家园：利用计算机视觉技术进行贝壳识别的生态恢复解决方案》|Alexander Valverde, Luis Solano, André Montoya|<http://arxiv.org/pdf/2501.04873v4>|提出首个大规模海洋贝壳图像库并开发实时识别系统，助力生态恢复。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Very High-Resolution Bridge Deformation Monitoring Using UAV-based Photogrammetry|基于无人机摄影测量的超高分辨率桥梁形变监测|Mehdi Maboudi, Jan Backhaus, Inka Mai, Yahya Ghassoun, Yogesh Khedar, Dirk Lowke, Bjoern Riedel, Ulf Bestmann .etc.|<http://arxiv.org/pdf/2410.18984v2>|利用无人机摄影测量技术实现了高精度桥梁变形监测，降低了传统检测方法成本和风险。|

