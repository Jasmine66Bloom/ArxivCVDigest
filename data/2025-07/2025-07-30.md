## [UPDATED!] **2025-07-30** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Application of Vision-Language Model to Pedestrians Behavior and Scene Understanding in Autonomous Driving|自动驾驶中视觉-语言模型在行人行为与场景理解中的应用|Haoxiang Gao, Li Zhang, Yu Zhao, Zhou Yang, Jinghan Cao|<http://arxiv.org/pdf/2501.06680v2>|提出知识蒸馏方法，将大规模视觉语言模型知识迁移至高效视觉网络，提升自动驾驶中行人与场景理解性能。|
|🆕 发布|Zero-Shot Image Anomaly Detection Using Generative Foundation Models|使用生成基础模型的零样本图像异常检测|Lemar Abdi, Amaan Valiuddin, Francisco Caetano, Christiaan Viviers, Fons van der Sommen|<http://arxiv.org/pdf/2507.22692v1>|提出利用生成基础模型进行无监督异常检测，通过分析去噪轨迹和Stein得分误差，实现跨数据集的零样本异...|
|🆕 发布|ShortFT: Diffusion Model Alignment via Shortcut-based Fine-Tuning|短路径微调：基于捷径的扩散模型对齐|Xiefan Guo, Miaomiao Cui, Liefeng Bo, Di Huang|<http://arxiv.org/pdf/2507.22604v1>|提出了一种基于捷径的微调策略ShortFT，有效缩短了梯度回传链，提升了扩散模型与奖励函数的对齐效率...|
|🆕 发布|Towards Blind Bitstream-corrupted Video Recovery via a Visual Foundation Model-driven Framework|面向视觉基础模型驱动的盲目比特流损坏视频恢复方法|Tianyi Liu, Kejun Wu, Chen Cai, Yi Wang, Kim-Hui Yap, Lap-Pui Chau|<http://arxiv.org/pdf/2507.22481v1>|提出首个无需手动标注的盲比特流损坏视频恢复框架，融合视觉基础模型和恢复模型以增强定位和盲恢复能力。|
|🆕 发布|HQ-CLIP: Leveraging Large Vision-Language Models to Create High-Quality Image-Text Datasets and CLIP Models|HQ-CLIP：利用大型视觉-语言模型创建高质量图像-文本数据集和CLIP模型|Zhixiang Wei, Guangting Wang, Xiaoxiao Ma, Ke Mei, Huaian Chen, Yi Jin, Fengyun Rao|<http://arxiv.org/pdf/2507.22431v1>|提出LVLM驱动的数据精炼流程，通过多粒度注释提升CLIP模型性能。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|TextSAM-EUS: Text Prompt Learning for SAM to Accurately Segment Pancreatic Tumor in Endoscopic Ultrasound|文本SAM-EUS：用于内窥镜超声下准确分割胰腺肿瘤的SAM文本提示学习|Pascal Spiegler, Taha Koleilat, Arash Harirpoush, Corey S. Miller, Hassan Rivaz, Marta Kersten-Oertel, Yiming Xiao|<http://arxiv.org/pdf/2507.18082v3>|[代码](https://github.com/HealthX-Lab/TextSAM-EUS); 提出了一种基于文本提示的胰腺肿瘤内窥超声图像自动分割方法，提升了准确度且减少了依赖大量标注数据的需求...|
|🆕 发布|ScreenCoder: Advancing Visual-to-Code Generation for Front-End Automation via Modular Multimodal Agents|屏幕编码器：通过模块化多模态智能体推进前端自动化中的视觉到代码生成|Yilei Jiang, Yaozhi Zheng, Yuxuan Wan, Jiaming Han, Qunzhong Wang, Michael R. Lyu, Xiangyu Yue|<http://arxiv.org/pdf/2507.22827v1>|[代码](https://github.com/leigest519/ScreenCoder.); 提出了一种多模态代理框架ScreenCoder，通过分阶段处理将UI设计自动转化为前端代码，提升了生...|
|🆕 发布|MergeSAM: Unsupervised change detection of remote sensing images based on the Segment Anything Model|MergeSAM：基于Segment Anything模型的遥感图像无监督变化检测|Meiqi Hu, Lingzhi Lu, Chengxi Han, Xiaoping Liu|<http://arxiv.org/pdf/2507.22675v1>|提出了一种基于Segment Anything Model的远程遥感图像无监督变化检测方法，通过Ma...|
|📝 更新|The Cooperative Network Architecture: Learning Structured Networks as Representation of Sensory Patterns|合作网络架构：学习结构化网络作为感官模式的表征|Pascal J. Sager, Jan M. Deriu, Benjamin F. Grewe, Thilo Stadelmann, Christoph von der Malsburg|<http://arxiv.org/pdf/2407.05650v4>|提出了一种结构化神经网络的协同网络架构，通过学习感官信号的统计规律，增强视觉系统对噪声和变形的鲁棒性...|
|📝 更新|CLIP-HandID: Vision-Language Model for Hand-Based Person Identification|基于手的视觉-语言模型CLIP-HandID：用于手部识别人物身份|Nathanael L. Baisa, Babu Pallam, Amudhavel Jayavel|<http://arxiv.org/pdf/2506.12447v3>|提出了一种利用预训练的CLIP模型通过文本提示进行手部图像识别的新方法，显著提升了犯罪调查中的身份识...|
|📝 更新|ChartM$^3$: Benchmarking Chart Editing with Multimodal Instructions|图表M$^3$：基于多模态指令的图表编辑基准测试|Donglu Yang, Liang Zhang, Zihao Yue, Liangyu Chen, Yichen Xu, Wenxuan Wang, Qin Jin|<http://arxiv.org/pdf/2507.21167v2>|[代码](https://github.com/MLrollIT/ChartM3.); 提出了结合自然语言和视觉指示器的多模态图表编辑方法，并创建了相应的评估基准和数据集。|
|📝 更新|Multimodal LLMs as Customized Reward Models for Text-to-Image Generation|多模态大型语言模型作为定制化奖励模型用于文本到图像生成|Shijie Zhou, Ruiyi Zhang, Huaisheng Zhu, Branislav Kveton, Yufan Zhou, Jiuxiang Gu, Jian Chen, Changyou Chen|<http://arxiv.org/pdf/2507.21391v2>|提出了一种利用预训练的多模态大语言模型直接评估文本到图像生成的效率化奖励模型，通过增强视觉与文本的交...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|$S^2M^2$: Scalable Stereo Matching Model for Reliable Depth Estimation|"S^2M^2": 可扩展立体匹配模型用于可靠深度估计|Junhong Min, Youngpil Jeon, Jimin Kim, Minyong Choi|<http://arxiv.org/pdf/2507.13229v3>|提出全局匹配架构$S^2M^2$，无需特定数据集微调，实现高效准确深度估计。|
|🆕 发布|Segment Anything for Video: A Comprehensive Review of Video Object Segmentation and Tracking from Past to Future|视频任意分割：从过去到未来的视频目标分割与跟踪全面回顾|Guoping Xu, Jayaram K. Udupa, Yajun Yu, Hua-Chieh Shao, Songlin Zhao, Wei Liu, You Zhang|<http://arxiv.org/pdf/2507.22792v1>|系统梳理了基于Segment Anything模型及其继承者视频对象分割与跟踪的发展脉络，强调了实时...|
|🆕 发布|Advancing Fetal Ultrasound Image Quality Assessment in Low-Resource Settings|在资源匮乏环境中提升胎儿超声图像质量评估|Dongli He, Hu Wang, Mohammad Yaqub|<http://arxiv.org/pdf/2507.22802v1>|[代码](https://github.com/donglihe-hub/FetalCLIP-IQA.); 提出基于预训练的FetalCLIP模型，通过参数高效微调，实现了自动化胎儿超声图像质量评估，提升低资...|
|🆕 发布|trAIce3D: A Prompt-Driven Transformer Based U-Net for Semantic Segmentation of Microglial Cells from Large-Scale 3D Microscopy Images|“trAIce3D：一种基于提示驱动的Transformer U-Net，用于从大规模三维显微图像中对微胶质细胞进行语义分割”|MohammadAmin Alamalhoda, Arsalan Firoozi, Alessandro Venturino, Sandra Siegert|<http://arxiv.org/pdf/2507.22635v1>|提出了一种基于Transformer的U-Net架构，通过滑动窗口和提示驱动的两阶段训练，实现了对微...|
|🆕 发布|LIDAR: Lightweight Adaptive Cue-Aware Fusion Vision Mamba for Multimodal Segmentation of Structural Cracks|激光雷达：轻量级自适应提示感知融合视觉蟒蛇，用于结构裂缝的多模态分割|Hui Liu, Chen Jia, Fan Shi, Xu Cheng, Mengfei Shi, Xia Xie, Shengyong Chen|<http://arxiv.org/pdf/2507.22477v1>|[代码](https://github.com/Karl1109/LIDAR-Mamba.); 提出了一种轻量级网络LIDAR，通过自适应感知和多模态特征融合，实现了结构裂缝的高效像素级分割。|
|🆕 发布|Gems: Group Emotion Profiling Through Multimodal Situational Understanding|通过多模态情境理解进行群体情感剖析的宝石方法|Anubhav Kataria, Surbhi Madan, Shreya Ghosh, Tom Gedeon, Abhinav Dhall|<http://arxiv.org/pdf/2507.22393v1>|[代码](https://github.com/katariaak579/GEMS); 提出了一种多模态情感理解框架GEMS，通过联合处理场景、群组成员和上下文信息，实现了个体、群组和事件...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AstroLoc: Robust Space to Ground Image Localizer|天体定位：稳健的天地图像定位器|Gabriele Berton, Alex Stoken, Carlo Masone|<http://arxiv.org/pdf/2502.07003v2>|首次利用宇航员照片训练的AstroLoc模型，大幅提升地球表面定位精度。|
|🆕 发布|COOkeD: Ensemble-based OOD detection in the era of zero-shot CLIP|COOkeD：零样本CLIP时代的基于集成学习的OOD检测|Galadrielle Humblot-Renaux, Gianni Franchi, Sergio Escalera, Thomas B. Moeslund|<http://arxiv.org/pdf/2507.22576v1>|[代码](https://github.com/glhr/COOkeD); 提出了一种异质集成方法COOkeD，结合封闭世界分类器、零样本CLIP分类器和线性探针分类器，实现了...|
|🆕 发布|AlphaDent: A dataset for automated tooth pathology detection|AlphaDent：自动化牙齿病理检测数据集|Evgeniy I. Sosnin, Yuriy L. Vasilev, Roman A. Solovyev, Aleksandr L. Stempkovskiy, Dmitry V. Telpukhov, Artem A. Vasilev, Aleksandr A. Amerikanov, Aleksandr Y. Romanov|<http://arxiv.org/pdf/2507.22512v1>|介绍了AlphaDent数据集，用于牙齿病变自动检测的实例分割问题，并通过神经网络训练取得了高质量预...|
|📝 更新|Interpretable Open-Vocabulary Referring Object Detection with Reverse Contrast Attention|具有反向对比注意力的可解释开放词汇指引用对象检测|Drandreb Earl O. Juanico, Rowel O. Atienza, Jeffrey Kenneth Go|<http://arxiv.org/pdf/2507.19891v2>|[代码](https://github.com/earl-juanico/rca); 提出Reverse Contrast Attention方法，提升视觉语言模型在开放词汇指引用对象检...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FLOSS: Free Lunch in Open-vocabulary Semantic Segmentation|FLOSS: 开放词汇语义分割中的免费午餐|Yasser Benigmim, Mohammad Fahes, Tuan-Hung Vu, Andrei Bursuc, Raoul de Charette|<http://arxiv.org/pdf/2504.10487v2>|[代码](https://github.com/yasserben/FLOSS); 提出了一种无需额外训练数据，通过特定模板的类专家提升开放词汇语义分割性能的方法。|
|🆕 发布|Graph-Guided Dual-Level Augmentation for 3D Scene Segmentation|图引导的双层增强用于三维场景分割|Hongbin Lin, Yifan Jiang, Juangui Xu, Jesse Jiaxi Xu, Yi Lu, Zhengyu Hu, Ying-Cong Chen, Hao Wang|<http://arxiv.org/pdf/2507.22668v1>|提出图引导的双层级增强框架，通过学习真实世界数据中的物体关系统计，实现了高质量的3D场景合成与分割性...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SpectraSentinel: LightWeight Dual-Stream Real-Time Drone Detection, Tracking and Payload Identification|光谱哨兵：轻量级双流实时无人机检测、跟踪及载荷识别|Shahriar Kabir, Istiak Ahmmed Rifti, H. M. Shadman Tabib, Mushfiqur Rahman, Sadatul Islam Sadi, Hasnaen Adil, Ahmed Mahir Sultan Rumi, Ch Md Rakin Haider|<http://arxiv.org/pdf/2507.22650v1>|提出了一种双流监控框架，通过独立优化红外与可见光数据流，实现了高效准确的无人机实时监测与识别。|
|🆕 发布|Robust Deepfake Detection for Electronic Know Your Customer Systems Using Registered Images|使用注册图像对电子客户身份识别系统进行稳健的深度伪造检测|Takuma Amada, Kazuya Kakizaki, Taiki Miyagawa, Akinori F. Ebihara, Kaede Shiohara, Toshihiko Yamasaki|<http://arxiv.org/pdf/2507.22601v1>|[代码](https://github.com/TaikiMiyagawa/DeepfakeDetection4eKYC.); 提出了一种针对电子身份验证系统的深度伪造检测算法，通过检测视频中的身份向量时序不一致性和利用注册图像...|
|📝 更新|Co-AttenDWG: Co-Attentive Dimension-Wise Gating and Expert Fusion for Multi-Modal Offensive Content Detection|《协同注意维度逐门控与专家融合用于多模态攻击性内容检测》|Md. Mithun Hossain, Md. Shakil Hossain, Sudipto Chaki, M. F. Mridha|<http://arxiv.org/pdf/2505.19010v2>|提出了一种融合维度注意力与专家融合策略的多模态攻击性内容检测方法，有效提升了跨模态交互和融合效果。|
|🆕 发布|From Sharp to Blur: Unsupervised Domain Adaptation for 2D Human Pose Estimation Under Extreme Motion Blur Using Event Cameras|从清晰到模糊：使用事件相机进行二维人体姿态估计在极端运动模糊下的无监督域自适应|Youngho Kim, Hoonhee Cho, Kuk-Jin Yoon|<http://arxiv.org/pdf/2507.22438v1>|[代码](https://github.com/kmax2001/EvSharp2Blur.); 提出了一种利用事件相机进行无监督领域自适应的方法，有效解决了运动模糊下的人体姿态估计问题。|
|📝 更新|FloPE: Flower Pose Estimation for Precision Pollination|《FloPE：用于精确授粉的花朵姿态估计》|Rashik Shrestha, Madhav Rijal, Trevor Smith, Yu Gu|<http://arxiv.org/pdf/2503.11692v2>|提出 FloPE 框架，通过3D Gaussian Splatting生成数据集，实现高精度实时花朵...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Metric Convolutions: A Unifying Theory to Adaptive Image Convolutions|《度量化卷积：自适应图像卷积的统一理论》|Thomas Dagès, Michael Lindenbaum, Alfred M. Bruckstein|<http://arxiv.org/pdf/2406.05400v2>|提出了一种基于图像局部和测地距离的metric convolutions方法，增强了卷积核的适应性并...|
|🆕 发布|RainbowPrompt: Diversity-Enhanced Prompt-Evolving for Continual Learning|彩虹提示：增强多样性的提示进化用于持续学习|Kiseong Hong, Gyeong-hyeon Kim, Eunwoo Kim|<http://arxiv.org/pdf/2507.22553v1>|提出了一种多样性增强的提示进化机制，通过自适应聚合任务特定提示，有效提高了连续学习中的性能表现。|
|🆕 发布|Object Recognition Datasets and Challenges: A Review|对象识别数据集与挑战：综述|Aria Salari, Abtin Djavadifar, Xiangrui Liu, Homayoun Najjaran|<http://arxiv.org/pdf/2507.22361v1>|[代码](https://github.com/AbtinDjavadifar/ORDC.); 系统分析了160余个物体识别数据集，概述了主要基准和竞赛，促进了计算机视觉研究的发展。|
|🆕 发布|A Segmentation Framework for Accurate Diagnosis of Amyloid Positivity without Structural Images|无结构影像下准确诊断淀粉样蛋白阳性的分割框架|Penghan Zhu, Shurui Mei, Shushan Chen, Xiaobo Chu, Shanbo He, Ziyi Liu|<http://arxiv.org/pdf/2507.22336v1>|提出了一种无需结构影像的深度学习框架，通过PET图像自动分割脑区并准确判断淀粉样蛋白阳性。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mesh based segmentation for automated margin line generation on incisors receiving crown treatment|基于网格的分割方法用于接受冠修复治疗的门齿自动边缘线生成|Ammar Alsheghri, Ying Zhang, Farnoosh Ghadiri, Julia Keren, Farida Cheriet, Francois Guibault|<http://arxiv.org/pdf/2507.22859v1>|提出了一种基于深度学习和网格分割的自动确定牙冠边缘线的方法，提高了准确性和效率。|
|📝 更新|Scaling RL to Long Videos|将强化学习扩展到长视频处理|Yukang Chen, Wei Huang, Baifeng Shi, Qinghao Hu, Hanrong Ye, Ligeng Zhu, Zhijian Liu, Pavlo Molchanov .etc.|<http://arxiv.org/pdf/2507.07966v3>|提出了一种全栈框架，通过结合大规模数据集、两阶段训练流程和高效训练基础设施，将视觉语言模型的长视频推...|
|🆕 发布|Wall Shear Stress Estimation in Abdominal Aortic Aneurysms: Towards Generalisable Neural Surrogate Models|腹主动脉瘤壁面剪切应力估计：迈向通用神经替代模型|Patryk Rygiel, Julian Suk, Christoph Brune, Kak Khee Yeung, Jelmer M. Wolterink|<http://arxiv.org/pdf/2507.22817v1>|提出了一种基于几何深度学习的模型，快速准确估算腹主动脉瘤的壁面剪切应力，具有良好的泛化能力。|
|📝 更新|Generalized and Efficient 2D Gaussian Splatting for Arbitrary-scale Super-Resolution|任意尺度超分辨率的一般化与高效二维高斯散点绘制|Du Chen, Liyi Chen, Zhengqiang Zhang, Lei Zhang|<http://arxiv.org/pdf/2501.06838v5>|[代码](https://github.com/ChrisDud0257/GSASR.); 提出了一种基于高斯散点法的任意尺度超分辨率方法，通过预测条件高斯分布和高效的GPU渲染，实现了泛化能...|
|🆕 发布|A Dual-Feature Extractor Framework for Accurate Back Depth and Spine Morphology Estimation from Monocular RGB Images|单目RGB图像精确估计背部深度与脊椎形态的双特征提取器框架|Yuxin Wei, Yue Zhang, Moxin Zhao, Chang Shi, Jason P. Y. Cheung, Teng Zhang, Nan Meng|<http://arxiv.org/pdf/2507.22691v1>|提出了一种双特征提取框架，通过结合深度和表面信息，提高了从单目RGB图像准确估计背部深度和脊柱形态的...|
|📝 更新|Fine-Tuning Visual Autoregressive Models for Subject-Driven Generation|为面向主题生成的视觉自回归模型进行微调|Jiwoo Chung, Sangeek Hyun, Hyunjun Kim, Eunseo Koh, MinKyu Lee, Jae-Pil Heo|<http://arxiv.org/pdf/2504.02612v2>|首次提出基于视觉自回归模型的主体驱动生成方法，通过选择性层调整和先验蒸馏减少计算负担和语言漂移。|
|🆕 发布|LOTS of Fashion! Multi-Conditioning for Image Generation via Sketch-Text Pairing|《LOTS of Fashion! 通过草图-文本配对的图像生成多条件训练》|Federico Girella, Davide Talon, Ziyue Liu, Zanxi Ruan, Yiming Wang, Marco Cristani|<http://arxiv.org/pdf/2507.22627v1>|提出LOTS方法，通过结合草图和文本信息生成时尚图像，实现设计定制化。|
|📝 更新|Beyond Image Prior: Embedding Noise Prior into Conditional Denoising Transformer|超越图像先验：将噪声先验嵌入条件去噪变换器中|Yuanfei Huang, Hua Huang|<http://arxiv.org/pdf/2407.09094v2>|[代码](https://github.com/YuanfeiHuang/Condformer.); 提出了一种将噪声先验嵌入条件去噪变换器的框架，通过分离噪声和图像先验提高了去噪模型的泛化能力和灵活性...|
|📝 更新|Learning Only with Images: Visual Reinforcement Learning with Reasoning, Rendering, and Visual Feedback|仅通过图像学习：具有推理、渲染和视觉反馈的视觉强化学习|Yang Chen, Yufan Shen, Wenxuan Huang, Sheng Zhou, Qunshu Lin, Xinyu Cai, Zhi Yu, Jiajun Bu .etc.|<http://arxiv.org/pdf/2507.20766v2>|[代码](https://github.com/L-O-I/RRVF.); 提出了一种无需图像-文本监督的视觉强化学习框架，通过推理、渲染和视觉反馈实现复杂视觉推理学习。|
|🆕 发布|Robust Adverse Weather Removal via Spectral-based Spatial Grouping|基于光谱的空间分组实现的鲁棒恶劣天气去除|Yuhwan Jeong, Yunseo Yang, Youngjo Yoon, Kuk-Jin Yoon|<http://arxiv.org/pdf/2507.22498v1>|提出基于频谱分解和分组注意力的SSGformer，有效应对复杂天气条件下的图像退化问题。|
|📝 更新|PARTE: Part-Guided Texturing for 3D Human Reconstruction from a Single Image|PARTE：基于部分引导的三维人体重建的单图像纹理处理|Hyeongjin Nam, Donghwan Kim, Gyeongsik Moon, Kyoung Mu Lee|<http://arxiv.org/pdf/2507.17332v4>|[代码](https://hygenie1228.github.io/PARTE); 利用人体部位信息引导纹理重建，显著提升了单张图片3D人体重建的纹理对齐质量。|
|🆕 发布|Exploiting Diffusion Prior for Task-driven Image Restoration|利用扩散先验进行任务驱动的图像恢复|Jaeha Kim, Junghun Oh, Kyoung Mu Lee|<http://arxiv.org/pdf/2507.22459v1>|提出了一种利用扩散先验进行任务驱动的图像复原方法，有效恢复了任务相关细节并提升了图像质量。|
|🆕 发布|TopoLiDM: Topology-Aware LiDAR Diffusion Models for Interpretable and Realistic LiDAR Point Cloud Generation|拓扑感知的LiDAR扩散模型TopoLiDM：用于可解释和逼真的LiDAR点云生成|Jiuming Liu, Zheng Huang, Mengmeng Liu, Tianchen Deng, Francesco Nex, Hao Cheng, Hesheng Wang|<http://arxiv.org/pdf/2507.22454v1>|[代码](https://github.com/IRMVLab/TopoLiDM.); 提出了一种结合图神经网络与扩散模型的方法TopoLiDM，通过拓扑正则化生成高保真度LiDAR点云，...|
|📝 更新|MAVFlow: Preserving Paralinguistic Elements with Conditional Flow Matching for Zero-Shot AV2AV Multilingual Translation|MAVFlow：使用条件流匹配保留副语言元素的无样本视听到视听多语种翻译|Sungwoo Cho, Jeongsoo Choi, Sungnyun Kim, Se-Young Yun|<http://arxiv.org/pdf/2503.11026v2>|[代码](https://github.com/Peter-SungwooCho/MAVFlow.); 提出了一种零样本音频视觉翻译方法，通过条件流匹配保持说话人一致性，提升了跨语言翻译质量。|
|📝 更新|SteerX: Creating Any Camera-Free 3D and 4D Scenes with Geometric Steering|SteerX：利用几何引导创建任意无相机3D和4D场景|Byeongjun Park, Hyojun Go, Hyelin Nam, Byung-Hoon Kim, Hyungjin Chung, Changick Kim|<http://arxiv.org/pdf/2503.12024v2>|提出了一种统一场景重建与生成过程的SteerX方法，通过几何奖励函数显著提升3D/4D场景生成的几何...|
|📝 更新|MaterialMVP: Illumination-Invariant Material Generation via Multi-view PBR Diffusion|MaterialMVP：通过多视角PBR扩散实现光照不变的材料生成|Zebin He, Mingxin Yang, Shuhui Yang, Yixuan Tang, Tao Wang, Kaihao Zhang, Guanying Chen, Yuhong Liu .etc.|<http://arxiv.org/pdf/2503.10289v2>|提出了MaterialMVP模型，通过多视角PBR扩散生成光照不变的材料纹理，实现了一致性和质量的双...|
|🆕 发布|FaceGCD: Generalized Face Discovery via Dynamic Prefix Generation|《FaceGCD: 通过动态前缀生成实现广义人脸发现》|Yunseok Oh, Dong-Wan Choi|<http://arxiv.org/pdf/2507.22353v1>|提出了一种动态构建特定实例特征提取器的方法FaceGCD，通过轻量级前缀实现高精度开放世界人脸识别。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DepR: Depth Guided Single-view Scene Reconstruction with Instance-level Diffusion|深度引导的单视角场景重建：基于实例级别的扩散|Qingcheng Zhao, Xiang Zhang, Haiyang Xu, Zeyuan Chen, Jianwen Xie, Yuan Gao, Zhuowen Tu|<http://arxiv.org/pdf/2507.22825v1>|提出DepR方法，通过深度引导和实例级扩散实现单视角场景重建，提升性能并增强图像与重建的对应。|
|🆕 发布|Image-Guided Shape-from-Template Using Mesh Inextensibility Constraints|基于图像引导的模板形状重建方法：利用网格不可延展性约束|Thuy Tran, Ruochen Chen, Shaifali Parashar|<http://arxiv.org/pdf/2507.22699v1>|[代码](https://github.com/dvttran/nsft.); 提出了一种无需对应点、利用图像特征和网格不可伸缩性约束的Shape-from-Template方法，...|
|📝 更新|StoryTeller: Improving Long Video Description through Global Audio-Visual Character Identification|《StoryTeller：通过全局音频-视觉角色识别提高长视频描述质量》|Yichen He, Yuan Lin, Jianchao Wu, Hanchong Zhang, Yuchen Zhang, Ruicheng Le|<http://arxiv.org/pdf/2411.07076v3>|提出StoryTeller系统，通过音频视觉角色识别增强长视频描述的一致性。|
|🆕 发布|Shallow Features Matter: Hierarchical Memory with Heterogeneous Interaction for Unsupervised Video Object Segmentation|浅层特征至关重要：用于无监督视频对象分割的异质交互层次化内存|Zheng Xiangyu, He Songcheng, Li Wanyun, Li Xiaoqiang, Zhang Wei|<http://arxiv.org/pdf/2507.22465v1>|[代码](https://github.com/ZhengxyFlow/HMHI-Net); 提出了一种结合浅层和高层特征的新型层级记忆架构，通过异质交互机制提升无监督视频对象分割的精度。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DISTIL: Data-Free Inversion of Suspicious Trojan Inputs via Latent Diffusion|DISTIL：通过潜在扩散的无数据逆向可疑木马输入|Hossein Mirzaei, Zeinab Taghavi, Sepehr Rezaee, Masoud Hadi, Moein Madadi, Mackenzie W. Mathis|<http://arxiv.org/pdf/2507.22813v1>|[代码](https://github.com/AdaptiveMotorControlLab/DISTIL.); 提出了一种无需数据、零样本的 Trojan 触发器逆向策略，通过限制搜索空间并避免对触发器外观的强假...|
|🆕 发布|HOLA: Enhancing Audio-visual Deepfake Detection via Hierarchical Contextual Aggregations and Efficient Pre-training|HOLA：通过分层上下文聚合和高效预训练增强音视频深度伪造检测|Xuecheng Wu, Danlei Huang, Heli Sun, Xinyi Yin, Yifan Wang, Hao Wang, Jia Zhang, Fei Wang .etc.|<http://arxiv.org/pdf/2507.22781v1>|提出了一种大规模预训练的音频视觉深度伪造检测框架，通过迭代式跨模态学习和层次化上下文建模显著提升了检...|
|📝 更新|Addressing Representation Collapse in Vector Quantized Models with One Linear Layer|在向量量化模型中使用单一线性层解决表征崩溃问题|Yongxin Zhu, Bocheng Li, Yifei Xin, Zhihua Xia, Linli Xu|<http://arxiv.org/pdf/2411.02038v2>|提出了一种简单线性层优化的向量量化方法，有效解决了表示坍缩问题并提高了模型泛化能力。|
|🆕 发布|Generative Active Learning for Long-tail Trajectory Prediction via Controllable Diffusion Model|通过可控扩散模型的生成主动学习用于长尾轨迹预测|Daehee Park, Monu Surana, Pranav Desai, Ashish Mehta, Reuben MV John, Kuk-Jin Yoon|<http://arxiv.org/pdf/2507.22615v1>|提出了一种生成性主动学习方法GALTraj，通过识别并增强尾样本，有效提升了长尾轨迹预测的准确性。|
|🆕 发布|DACA-Net: A Degradation-Aware Conditional Diffusion Network for Underwater Image Enhancement|DACA-Net：一种退化感知条件扩散网络用于水下图像增强|Chang Huang, Jiahang Cao, Jun Ma, Kieren Yu, Cong Li, Huayong Yang, Kaishun Wu|<http://arxiv.org/pdf/2507.22501v1>|提出了一种自适应且鲁棒的退化感知条件扩散网络，有效提升了水下图像的视觉质量。|
|📝 更新|Learning to See in the Extremely Dark|在极暗条件下学习看见|Hai Jiang, Binhao Guan, Zhen Liu, Xiaohong Liu, Jian Yu, Zheng Liu, Songchen Han, Shuaicheng Liu|<http://arxiv.org/pdf/2506.21132v2>|[代码](https://github.com/JianghaiSCU/SIED.); 提出了一种生成极低光照数据集和扩散模型框架，有效提升了极暗环境下的图像增强质量。|
|🆕 发布|RCR-AF: Enhancing Model Generalization via Rademacher Complexity Reduction Activation Function|RCR-AF：通过拉德马赫复杂性降低激活函数增强模型泛化能力|Yunrui Yu, Kafeng Wang, Hang Su, Jun Zhu|<http://arxiv.org/pdf/2507.22446v1>|提出了一种新型激活函数RCR-AF，通过控制模型复杂度增强模型的泛化能力和对抗性鲁棒性。|
|📝 更新|Anti-Inpainting: A Proactive Defense Approach against Malicious Diffusion-based Inpainters under Unknown Conditions|反修复：一种在未知条件下针对恶意扩散基于修复器的主动防御方法|Yimao Guo, Zuomin Qu, Wei Lu, Xiangyang Luo|<http://arxiv.org/pdf/2505.13023v2>|提出了一种针对未知条件下扩散基于恶意图像篡改的主动防御方法Anti-Inpainting，通过多级特...|
|📝 更新|Exploring Textual Semantics Diversity for Image Transmission in Semantic Communication Systems using Visual Language Model|探索文本语义多样性在视觉语言模型辅助的语义通信系统中用于图像传输|Peishan Huang, Dong Li|<http://arxiv.org/pdf/2503.19386v2>|提出了一种利用视觉语言模型提升图像传输重建精度的多文本语义通信系统。|
|🆕 发布|MINR: Implicit Neural Representations with Masked Image Modelling|MINR：带掩模图像建模的隐式神经表示|Sua Lee, Joonhun Lee, Myungjoo Kang|<http://arxiv.org/pdf/2507.22404v1>|引入了MINR框架，结合隐式神经表示与掩码图像建模，提高了图像重建的鲁棒性和泛化能力。|
|📝 更新|Seed Selection for Human-Oriented Image Reconstruction via Guided Diffusion|面向人类导向的图像重建的引导扩散种子选择|Yui Tatsumi, Ziyue Zeng, Hiroshi Watanabe|<http://arxiv.org/pdf/2506.05363v3>|提出了一种优化种子选择的方法，通过选择最佳种子改善图像质量而不增加比特率。|
|🆕 发布|GVD: Guiding Video Diffusion Model for Scalable Video Distillation|GVD：用于可扩展视频精炼的引导视频扩散模型|Kunyang Li, Jeffrey A Chan Santiago, Sarinda Dhanesh Samarasinghe, Gaowen Liu, Mubarak Shah|<http://arxiv.org/pdf/2507.22360v1>|提出了一种基于扩散模型的高效视频压缩方法GVD，实现了用极少量帧数达到接近原始视频数据集的训练性能。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Ultra3D: Efficient and High-Fidelity 3D Generation with Part Attention|Ultra3D：基于部分注意力的高效高保真三维生成|Yiwen Chen, Zhihao Li, Yikai Wang, Hu Zhang, Qin Li, Chi Zhang, Guosheng Lin|<http://arxiv.org/pdf/2507.17745v2>|提出了一种高效的3D生成框架Ultra3D，通过部分注意力机制加速稀疏体素建模，保持生成质量的同时提...|
|🆕 发布|Hate in Plain Sight: On the Risks of Moderating AI-Generated Hateful Illusions|《显而易见的仇恨：关于审查AI生成的仇恨幻觉的风险》|Yiting Qu, Ziqing Yang, Yihan Ma, Michael Backes, Savvas Zannettou, Yang Zhang|<http://arxiv.org/pdf/2507.22617v1>|探讨了AI生成仇恨幻觉的风险，并提出了识别和缓解这些幻觉的策略。|
|📝 更新|VistaDepth: Frequency Modulation with Bias Reweighting for Enhanced Far-range Depth Estimation|“VistaDepth：基于频率调制与偏差重量的增强远距离深度估计”|Mingxia Zhan, Li Zhang, Xiaomeng Chu, Beibei Wang, Yanyong Zhang|<http://arxiv.org/pdf/2504.15095v4>|提出VistaDepth框架，通过频率调制和偏差重加权增强远距离深度估计准确性。|
|📝 更新|See Different, Think Better: Visual Variations Mitigating Hallucinations in LVLMs|《看见不同，思考更佳：视觉变体减轻LVLMs中的幻觉现象》|Ziyun Dai, Xiaoqiang Li, Shaohua Zhang, Yuanchen Wu, Jide Li|<http://arxiv.org/pdf/2507.22003v2>|[代码](https://github.com/oliviadzy/ViHallu.); 提出ViHallu框架，通过生成视觉变体图像和构建视觉指令，减少大型视觉语言模型中的幻觉现象，提高视...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Distance and Collision Probability Estimation from Gaussian Surface Models|从高斯表面模型估计距离和碰撞概率|Kshitij Goel, Wennie Tabib|<http://arxiv.org/pdf/2402.00186v3>|提出了一种利用高斯表面模型估计椭球机器人与环境的碰撞概率和距离的方法，提高了狭窄空间的导航效率。|
|📝 更新|Counting Stacked Objects|堆叠物体的计数|Corentin Dumery, Noa Etté, Aoxiang Fan, Ren Li, Jingyi Xu, Hieu Le, Pascal Fua|<http://arxiv.org/pdf/2411.19149v4>|提出了一种结合几何重建和深度学习的方法，准确计数容器内不规则堆叠的物体。|
|📝 更新|STaR: Seamless Spatial-Temporal Aware Motion Retargeting with Penetration and Consistency Constraints|STaR: 基于穿透性和一致性约束的无缝时空感知运动重定向|Xiaohang Yang, Qing Wang, Jiahao Yang, Gregory Slabaugh, Shanxin Yuan|<http://arxiv.org/pdf/2504.06504v2>|[代码](https://github.com/XiaohangYang829/STaR.); 提出了一种结合空间和时间约束的无缝运动重定向方法，有效平衡了运动语义、几何合理性和时间一致性。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Tapping into the Black Box: Uncovering Aligned Representations in Pretrained Neural Networks|深入黑箱：揭示预训练神经网络中的对齐表示|Maciej Satkiewicz|<http://arxiv.org/pdf/2507.22832v1>|揭示了预训练神经网络中的隐线性模型，并提出了一种方法将其决策边界近似映射回输入空间，发现高度对齐的感...|
|📝 更新|RecConv: Efficient Recursive Convolutions for Multi-Frequency Representations|递归卷积：用于多频率表示的高效递归卷积|Mingshu Zhao, Yi Luo, Yong Ouyang|<http://arxiv.org/pdf/2412.19628v3>|[代码](https://github.com/suous/RecNeXt.); 提出了一种递归卷积策略RecConv，通过小核卷积构建多频表示，实现了参数和计算复杂度的线性增长，提...|
|📝 更新|TartanGround: A Large-Scale Dataset for Ground Robot Perception and Navigation|《TartanGround：一个用于地面机器人感知与导航的大规模数据集》|Manthan Patel, Fan Yang, Yuheng Qiu, Cesar Cadena, Sebastian Scherer, Marco Hutter, Wenshan Wang|<http://arxiv.org/pdf/2505.10696v2>|介绍了TartanGround大规模多模态数据集，助力地面机器人感知与导航在多样化环境中的泛化能力。|
|📝 更新|Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey|《前馈三维重建与视图合成进展综述》|Jiahui Zhang, Yuelei Li, Anpei Chen, Muyu Xu, Kunhao Liu, Jianyuan Wang, Xiao-Xiao Long, Hanxue Liang .etc.|<http://arxiv.org/pdf/2507.14501v2>|系统梳理了基于深度学习的快速3D重建与视图合成技术，推动了计算机视觉领域的发展。|
|📝 更新|FOF-X: Towards Real-time Detailed Human Reconstruction from a Single Image|面向单张图像的实时详细人体重建：FOF-X|Qiao Feng, Yuanwang Yang, Yebin Liu, Yu-Kun Lai, Jingyu Yang, Kun Li|<http://arxiv.org/pdf/2412.05961v2>|提出FOF-X方法，通过学习傅里叶级数实现单张图片实时重建高质量人体几何结构。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UAVScenes: A Multi-Modal Dataset for UAVs|"UAVScenes：一种用于无人机的多模态数据集"|Sijie Wang, Siqi Li, Yawei Zhang, Shangshu Yu, Shenghai Yuan, Rui She, Quanjiang Guo, JinXuan Zheng .etc.|<http://arxiv.org/pdf/2507.22412v1>|[代码](https://github.com/sijieaaa/UAVScenes); 介绍了UAVScenes多模态数据集，为UAV的高级场景理解任务提供了全面的标注支持。|


## 时序视觉分析 (Temporal Visual Analysis)


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Social-Pose: Enhancing Trajectory Prediction with Human Body Pose|社交姿态：利用人体姿态增强轨迹预测|Yang Gao, Saeed Saadatnejad, Alexandre Alahi|<http://arxiv.org/pdf/2507.22742v1>|提出利用人体姿态预测人类轨迹的新方法，通过注意力机制编码器提升预测准确性。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HRVVS: A High-resolution Video Vasculature Segmentation Network via Hierarchical Autoregressive Residual Priors|高分辨率视频血管分割网络：基于层次自回归残差先验的方法（HRVVS）|Xincheng Yao, Yijun Yang, Kangwei Guo, Ruiqiang Xiao, Haipeng Zhou, Haisu Tao, Jian Yang, Lei Zhu|<http://arxiv.org/pdf/2507.22530v1>|[代码](https://github.com/scott-yjyang/xx); 提出了一种用于高分辨率手术视频血管分割的网络，通过层级自回归残差先验减少了信息降解。|
|📝 更新|When Tokens Talk Too Much: A Survey of Multimodal Long-Context Token Compression across Images, Videos, and Audios|当标记说过多话语：跨图像、视频和音频的多模态长上下文标记压缩综述|Kele Shao, Keda Tao, Kejia Zhang, Sicheng Feng, Mu Cai, Yuzhang Shang, Haoxuan You, Can Qin .etc.|<http://arxiv.org/pdf/2507.20198v3>|系统梳理了多模态长上下文token压缩技术，分类现有方法以应对不同模态数据冗余问题。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|I2VControl: Disentangled and Unified Video Motion Synthesis Control|"I2VControl: 解耦与统一视频运动合成控制"|Wanquan Feng, Tianhao Qi, Jiawei Liu, Mingzhen Sun, Pengqi Tu, Tianxiang Ma, Fei Dai, Songtao Zhao .etc.|<http://arxiv.org/pdf/2411.17765v3>|[代码](https://wanquanf.github.io/I2VControl); 提出了一种解耦和统一的视频运动合成控制框架I2VControl，有效解决了控制类型组合的逻辑冲突问题...|
|🆕 发布|Efficient Spatial-Temporal Modeling for Real-Time Video Analysis: A Unified Framework for Action Recognition and Object Tracking|实时视频分析的高效时空建模：动作识别与目标跟踪的统一框架|Shahla John|<http://arxiv.org/pdf/2507.22421v1>|提出了一种统一的时空建模框架，实现了实时视频分析中的动作识别和目标跟踪，提升了准确性和速度。|
|📝 更新|FastTrackTr:Towards Fast Multi-Object Tracking with Transformers|《FastTrackTr：面向快速多目标跟踪的Transformer方法》|Pan Liao, Feng Yang, Di Wu, Jinwen Yu, Wenhui Zhao, Dingwen Zhang|<http://arxiv.org/pdf/2411.15811v4>|提出了一种高效的基于Transformer的多目标跟踪框架FastTrackTr，通过优化信息传递显...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Recognizing Actions from Robotic View for Natural Human-Robot Interaction|从机器人视角识别动作以实现自然的人机交互|Ziyi Wang, Peiming Li, Hong Liu, Zhichao Deng, Can Wang, Jun Liu, Junsong Yuan, Mengyuan Liu|<http://arxiv.org/pdf/2507.22522v1>|[代码](https://github.com/wangzy01/ACTIVE-Action-from-Robotic-View.); 提出ACTIVE数据集及ACTIVE-PC方法，为自然人与机器人交互中的动作识别提供大规模多样化和长...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Differential Contrastive Training for Gaze Estimation|差分对比训练用于 gaze 估计|Lin Zhang, Yi Tian, XiYun Wang, Wanru Xu, Yi Jin, Yaping Huang|<http://arxiv.org/pdf/2502.20128v3>|[代码](https://github.com/LinZhang-bjtu/DCGaze.); 提出了一种结合CLIP预训练模型的微分对比训练策略，显著提升了 gaze 估计的准确性和泛化能力。|


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Whole-brain Transferable Representations from Large-Scale fMRI Data Improve Task-Evoked Brain Activity Decoding|从大规模fMRI数据中学习的全脑迁移性表征提高了任务诱发的脑活动解码性能|Yueh-Po Peng, Vincent K. M. Cheung, Li Su|<http://arxiv.org/pdf/2507.22378v1>|利用计算机视觉技术，提出STDA-SwiFT模型，通过学习大规模fMRI数据中的转移性表征，显著提升...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LCS: An AI-based Low-Complexity Scaler for Power-Efficient Super-Resolution of Game Content|LCS：一种基于人工智能的低复杂度放大器，用于游戏内容的高效超分辨率处理|Simon Pochinda, Momen K. Tageldeen, Mark Thompson, Tony Rinaldi, Troy Giorshev, Keith Lee, Jie Zhou, Frederick Walls|<http://arxiv.org/pdf/2507.22873v1>|提出了一种基于AI的低复杂度缩放器，用于在低功耗设备上进行高效的游戏内容超分辨率处理。|
|🆕 发布|TR-PTS: Task-Relevant Parameter and Token Selection for Efficient Tuning|TR-PTS：面向高效微调的任务相关参数与标记选择|Siqi Luo, Haoran Yang, Yi Xin, Mingyang Yi, Guangyang Wu, Guangtao Zhai, Xiaohong Liu|<http://arxiv.org/pdf/2507.22872v1>|[代码](https://github.com/synbol/TR-PTS.); 提出任务相关参数与标记选择框架TR-PTS，通过优化关键参数和标记提升模型效率和准确性。|
|📝 更新|UI-E2I-Synth: Advancing GUI Grounding with Large-Scale Instruction Synthesis|UI-E2I-Synth：利用大规模指令合成推进图形界面定位技术|Xinyi Liu, Xiaoyi Zhang, Ziyun Zhang, Yan Lu|<http://arxiv.org/pdf/2504.11257v4>|[代码](https://microsoft.github.io/FIVE-UI-Evol); 提出了一种大规模数据合成方法UI-E2I-Synth，通过GPT-4o生成复杂指令数据集，显著提升了...|
|🆕 发布|Hydra-Bench: A Benchmark for Multi-Modal Leaf Wetness Sensing|Hydra-Bench：一种多模态叶面湿度感知基准|Yimeng Liu, Maolin Gan, Yidong Ren, Gen Li, Jingkai Lin, Younsuk Dong, Zhichao Cao|<http://arxiv.org/pdf/2507.22685v1>|提出了一种多模态叶湿检测基准，通过集成毫米波、合成孔径雷达和RGB图像数据，提高了农业监测中的准确性...|
|🆕 发布|FGFP: A Fractional Gaussian Filter and Pruning for Deep Neural Networks Compression|FGFP：一种基于分数高斯滤波和剪枝的深度神经网络压缩方法|Kuan-Ting Tu, Po-Hsien Yu, Yu-Syuan Tseng, Shao-Yi Chien|<http://arxiv.org/pdf/2507.22527v1>|提出FGFP框架，结合分数阶微积分和 Gaussian 函数压缩神经网络，实现高压缩比和低精度损失。|
|📝 更新|Predict Patient Self-reported Race from Skin Histological Images|从皮肤组织学图像预测患者自报种族|Shengjia Chen, Ruchika Verma, Kevin Clare, Jannes Jegminat, Eugenia Alleva, Kuan-lin Huang, Brandon Veremis, Thomas Fuchs .etc.|<http://arxiv.org/pdf/2507.21912v2>|[代码](https://github.com/sinai-computational-pathology/CPath_SAIF.); 定位皮肤组织切片中的种族相关特征，通过注意力机制模型预测患者自报种族。|
|🆕 发布|UFV-Splatter: Pose-Free Feed-Forward 3D Gaussian Splatting Adapted to Unfavorable Views|UFV-Splatter：面向不利视角的无姿态前馈3D高斯喷洒适应方法|Yuki Fujimura, Takahiro Kushida, Kazuya Kitano, Takuya Funatomi, Yasuhiro Mukaigawa|<http://arxiv.org/pdf/2507.22342v1>|提出了一种适应不利视角的3D高斯渲染框架，通过增强模型对相机姿态变化的适应性。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bi-Level Optimization for Self-Supervised AI-Generated Face Detection|双水平优化用于自监督AI生成人脸检测|Mian Zou, Nan Zhong, Baosheng Yu, Yibing Zhan, Kede Ma|<http://arxiv.org/pdf/2507.22824v1>|引入双层次优化自我监督方法，提高AI生成人脸检测的泛化能力。|
|📝 更新|Gaussian On-the-Fly Splatting: A Progressive Framework for Robust Near Real-Time 3DGS Optimization|"在线高斯散点绘制：一种用于稳健近实时三维形状优化渐进框架"|Yiwei Xu, Yifei Yu, Wentian Gan, Tengfei Wang, Zongqian Zhan, Hao Cheng, Xin Wang|<http://arxiv.org/pdf/2503.13086v2>|提出了一种实时优化的3D高斯渲染框架，通过逐帧更新和自适应学习率显著减少了训练时间。|
|🆕 发布|Moiré Zero: An Efficient and High-Performance Neural Architecture for Moiré Removal|摩尔零：一种高效高性能的摩尔纹去除神经网络架构|Seungryong Lee, Woojeong Baek, Younghyun Kim, Eunwoo Kim, Haru Moon, Donggon Yoo, Eunbyung Park|<http://arxiv.org/pdf/2507.22407v1>|[代码](https://sngryonglee.github.io/MoireZero); 提出了一种U形网络MZNet，通过多尺度特性和多样化结构捕捉，有效去除摩尔纹，实现图像的“摩尔零”状...|
|🆕 发布|LAMA-Net: A Convergent Network Architecture for Dual-Domain Reconstruction|LAMA-Net：一种用于双域重建的收敛网络架构|Chi Ding, Qingchao Zhang, Ge Wang, Xiaojing Ye, Yunmei Chen|<http://arxiv.org/pdf/2507.22316v1>|提出了一种可学习变分模型LAMA-Net，利用图像和测量域的互补信息进行图像重建，并证明了其收敛性和...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Eyepiece-free pupil-optimized holographic near-eye displays|无需目镜的瞳孔优化全息近眼显示系统|Jie Zhou, Shuyang Xie, Yang Wu, Lei Jiang, Yimou Luo, Jun Wang|<http://arxiv.org/pdf/2507.22420v1>|提出了一种无需传统光学元件的 pupil-optimized 近眼全息显示技术，显著提升了图像质量并...|
|📝 更新|PolyPose: Localizing Deformable Anatomy in 3D from Sparse 2D X-ray Images using Polyrigid Transforms|PolyPose：使用多项刚体变换从稀疏二维X射线图像中定位三维可变形解剖结构|Vivek Gopalakrishnan, Neel Dey, Polina Golland|<http://arxiv.org/pdf/2505.19256v3>|提出PolyPose方法，通过将复杂3D变形场分解为多个刚体变换，实现了仅用少量X射线图像对病人解剖...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FOCoOp: Enhancing Out-of-Distribution Robustness in Federated Prompt Learning for Vision-Language Models|FOCoOp：增强视觉语言模型联邦提示学习中分布外鲁棒性|Xinting Liao, Weiming Liu, Jiaming Qian, Pengyang Zhou, Jiahe Xu, Wenjie Wang, Chaochao Chen, Xiaolin Zheng .etc.|<http://arxiv.org/pdf/2506.16218v3>|提出FOCoOp框架，通过多级提示和分布优化提升联邦视觉语言模型在非分布内数据上的鲁棒性。|
|🆕 发布|Theoretical Analysis of Relative Errors in Gradient Computations for Adversarial Attacks with CE Loss|对抗攻击中基于交叉熵损失函数的梯度计算相对误差的理论分析|Yunrui Yu, Hang Su, Cheng-zhong Xu, Zhizhong Su, Jun Zhu|<http://arxiv.org/pdf/2507.22428v1>|分析了梯度计算中的相对误差问题，并提出了一种优化损失函数以减少浮点运算误差，提升攻击效果。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Equivariant Flow Matching for Point Cloud Assembly|等变流匹配用于点云组装|Ziming Wang, Nan Xue, Rebecka Jörnsten|<http://arxiv.org/pdf/2505.21539v2>|提出了一种基于流匹配的等变求解器Eda，有效组装非重叠的点云片段以重构完整3D形状。|
|🆕 发布|Subtyping Breast Lesions via Generative Augmentation based Long-tailed Recognition in Ultrasound|通过基于生成增强的长尾识别在超声中细分乳腺病变类型|Shijing Chen, Xinrui Zhou, Yuhao Wang, Yuhao Huang, Ao Chang, Dong Ni, Ruobing Huang|<http://arxiv.org/pdf/2507.22568v1>|[代码](https://github.com/Stinalalala/Breast-LT-GenAug.); 提出了一种双阶段框架，通过生成增强缓解数据分布偏差，提高了超声图像中乳腺病变亚型的识别准确性。|
|🆕 发布|Estimating 2D Camera Motion with Hybrid Motion Basis|用混合运动基估计二维相机运动|Haipeng Li, Tianhao Zhou, Zhanglei Yang, Yi Wu, Yan Chen, Zijing Mao, Shen Cheng, Bing Zeng .etc.|<http://arxiv.org/pdf/2507.22480v1>|[代码](https://lhaippp.github.io/CamFlow); 提出了一种结合物理和随机基础的运动表示框架CamFlow，提高了2D相机运动估计的鲁棒性和泛化能力。|


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Diffusion-based Adversarial Identity Manipulation for Facial Privacy Protection|基于扩散的对抗性身份操纵用于面部隐私保护|Liqin Wang, Qianyue Hu, Wei Lu, Xiangyang Luo|<http://arxiv.org/pdf/2504.21646v3>|提出DiffAIM方法，通过在低维潜在空间内操纵面部身份生成自然且具有强攻击迁移性的对抗人脸，保护面...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VL-Cogito: Progressive Curriculum Reinforcement Learning for Advanced Multimodal Reasoning|结果： VL-Cogito：高级多模态推理的渐进式课程强化学习|Ruifeng Yuan, Chenghao Xiao, Sicong Leng, Jianyu Wang, Long Li, Weiwen Xu, Hou Pong Chan, Deli Zhao .etc.|<http://arxiv.org/pdf/2507.22607v1>|提出VL-Cogito模型，通过分阶段递增难度强化学习，提升多模态推理能力。|
|📝 更新|UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding|UI-AGILE：利用有效的强化学习和精确的推理时间定位推进图形界面代理的研究|Shuquan Lian, Yuhang Wu, Jia Ma, Zihan Song, Bingqi Chen, Xiawu Zheng, Hui Li|<http://arxiv.org/pdf/2507.22025v2>|UI-AGILE通过创新的训练奖励机制和精确的推理时定位方法，提升了图形界面代理的训练效果和性能。|
|📝 更新|Language Driven Occupancy Prediction|语言驱动的占用预测|Zhu Yu, Bowen Pang, Lizhe Liu, Runmin Zhang, Qiang Li, Si-Yuan Cao, Maochun Luo, Mingxia Chen .etc.|<http://arxiv.org/pdf/2411.16072v3>|提出了一种语义传递标注流程，通过精确的体素到文本对应关系，有效指导三维语言体积学习，优于现有零样本占...|
|📝 更新|StruMamba3D: Exploring Structural Mamba for Self-supervised Point Cloud Representation Learning|StruMamba3D：探索结构化Mamba用于自监督点云表征学习|Chuxin Wang, Yixin Zha, Wenfei Yang, Tianzhu Zhang|<http://arxiv.org/pdf/2506.21541v3>|提出StruMamba3D方法，通过保持点云空间依赖和优化状态更新策略，提升了自监督点云表征学习性能...|
|🆕 发布|Learning from Heterogeneous Structural MRI via Collaborative Domain Adaptation for Late-Life Depression Assessment|通过协作域自适应从异质结构MRI中学习用于晚年抑郁评估|Yuzhen Gao, Qianqian Wang, Yongheng Sun, Cui Wang, Yongquan Liang, Mingxia Liu|<http://arxiv.org/pdf/2507.22321v1>|提出了一种协同域自适应框架，通过结合全局和局部特征提取，有效提升了晚年抑郁症的MRI检测准确性和泛化...|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Can GPT-4o mini and Gemini 2.0 Flash Predict Fine-Grained Fashion Product Attributes? A Zero-Shot Analysis|GPT-4o mini 与 Gemini 2.0 Flash 能否预测细粒度时尚产品属性？一种零样本分析|Shubham Shukla, Kunal Sonalkar|<http://arxiv.org/pdf/2507.09950v2>|[代码](https://github.com/yumingj/DeepFashion-MultiModal); 评估了GPT-4o-mini和Gemini 2.0 Flash在细粒度时尚属性识别中的零样本性能，G...|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 目标导向视觉决策 (Goal-oriented Visual Decision Making)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|R-LiViT: A LiDAR-Visual-Thermal Dataset Enabling Vulnerable Road User Focused Roadside Perception|R-LiViT：一种使能关注易受伤害道路使用者路边感知的激光雷达-视觉-热成像数据集|Jonas Mirlach, Lei Wan, Andreas Wiedholz, Hannan Ejaz Keen, Andreas Eich|<http://arxiv.org/pdf/2503.17122v3>|首次整合LiDAR、RGB和热成像数据，专注提升自动驾驶中对弱势道路用户的路边感知能力。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Omnimodal Expressions and Reasoning in Referring Audio-Visual Segmentation|面向全模态表达与推理的指示音频视觉分割|Kaining Ying, Henghui Ding, Guanquan Jie, Yu-Gang Jiang|<http://arxiv.org/pdf/2507.22886v1>|提出Omnimodal Referring Audio-Visual Segmentation数据集...|
|🆕 发布|On the Reliability of Vision-Language Models Under Adversarial Frequency-Domain Perturbations|《在对抗性频率域扰动下视觉-语言模型的可靠性研究》|Jordan Vice, Naveed Akhtar, Yansong Gao, Richard Hartley, Ajmal Mian|<http://arxiv.org/pdf/2507.22398v1>|揭示了视觉语言模型在对抗性频率域扰动下的脆弱性，并设计了针对性的图像变换方法。|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ViM-VQ: Efficient Post-Training Vector Quantization for Visual Mamba|ViM-VQ：视觉Mamba的高效后训练向量量化|Juncan Deng, Shuaiting Li, Zeyu Wang, Kedong Xu, Hong Gu, Kejie Huang|<http://arxiv.org/pdf/2503.09509v2>|提出ViM-VQ方法，针对Visual Mamba网络进行高效后训练向量量化，提升低比特量化下的视觉...|
|📝 更新|SpatialViz-Bench: Automatically Generated Spatial Visualization Reasoning Tasks for MLLMs|空间可视化基准：为机器学习大型语言模型自动生成的空间可视化推理任务|Siting Wang, Luoyang Sun, Cheng Deng, Kun Shao, Minnan Pei, Zheng Tian, Haifeng Zhang, Jun Wang|<http://arxiv.org/pdf/2507.07610v3>|提出SpatialViz-Bench，自动生成空间可视化任务，揭示MLLMs在空间推理上的不足。|
|📝 更新|Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions|探索视觉语言模型的边界：当前方法综述与未来方向|Akash Ghosh, Arkadeep Acharya, Sriparna Saha, Vinija Jain, Aman Chadha|<http://arxiv.org/pdf/2404.07214v3>|系统梳理了视觉语言模型的发展，分类并分析了各类模型的优缺点及未来研究方向。|
|📝 更新|Move to Understand a 3D Scene: Bridging Visual Grounding and Exploration for Efficient and Versatile Embodied Navigation|迈向理解三维场景：将视觉定位与探索相结合实现高效灵活的具身导航|Ziyu Zhu, Xilin Wang, Yixuan Li, Zhuofan Zhang, Xiaojian Ma, Yixin Chen, Baoxiong Jia, Wei Liang .etc.|<http://arxiv.org/pdf/2507.04047v2>|提出了一种集成主动感知与3D视觉语言学习的统一框架，实现了高效灵活的机器人探索与环境理解。|
|🆕 发布|Visual Language Models as Zero-Shot Deepfake Detectors|视觉语言模型作为零样本深度伪造检测器|Viacheslav Pirogov|<http://arxiv.org/pdf/2507.22469v1>|提出了一种基于视觉语言模型的零样本检测方法，用于识别深伪图像，性能优于传统分类器。|
|🆕 发布|Exploring the Application of Visual Question Answering (VQA) for Classroom Activity Monitoring|探索视觉问答（VQA）在课堂活动监控中的应用|Sinh Trong Vu, Hieu Trung Pham, Dung Manh Nguyen, Hieu Minh Hoang, Nhu Hoang Le, Thu Ha Pham, Tai Tan Mai|<http://arxiv.org/pdf/2507.22369v1>|探究了视觉问答模型在课堂行为分析中的应用，并构建了BAV-Classroom-VQA数据集进行性能评...|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ComicsPAP: understanding comic strips by picking the correct panel|《ComicsPAP：通过选择正确面板来理解漫画》|Emanuele Vivoli, Artemis Llabrés, Mohamed Ali Souibgui, Marco Bertini, Ernest Valveny Llobet, Dimosthenis Karatzas|<http://arxiv.org/pdf/2503.08561v3>|提出ComicsPAP基准，通过挑选正确漫画格推动大型多模态模型理解漫画序列的能力。|
|📝 更新|Enhancing Multimodal In-Context Learning for Image Classification through Coreset Optimization|通过核心集优化增强图像分类中的多模态上下文学习|Huiyi Chen, Jiawei Peng, Kaihua Tang, Xin Geng, Xu Yang|<http://arxiv.org/pdf/2504.14200v2>|提出Key-based Coreset Optimization方法，通过优化示例集提升图像分类在c...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GS-Occ3D: Scaling Vision-only Occupancy Reconstruction for Autonomous Driving with Gaussian Splatting|GS-Occ3D：利用高斯散点绘制扩展仅视觉占用重建在自动驾驶中的应用|Baijun Ye, Minghui Qin, Saining Zhang, Moonjun Gong, Shaoting Zhu, Zebang Shen, Luan Zhang, Lu Zhang .etc.|<http://arxiv.org/pdf/2507.19451v2>|提出了一种无需激光雷达标注的视觉占用重建框架GS-Occ3D，通过高斯散点优化显式占用表示，实现高效...|
|📝 更新|Collaborative Perceiver: Elevating Vision-based 3D Object Detection via Local Density-Aware Spatial Occupancy|协同感知器：通过局部密度感知空间占有率提升基于视觉的3D目标检测|Jicheng Yuan, Manh Nguyen Duc, Qian Liu, Manfred Hauswirth, Danh Le Phuoc|<http://arxiv.org/pdf/2507.21358v2>|[代码](https://github.com/jichengyuan/Collaborative-Perceiver.); 提出了一种多任务学习框架 Collaborative Perceiver，通过利用空间占有率信息增强...|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Modality-Aware Feature Matching: A Comprehensive Review of Single- and Cross-Modality Techniques|模态感知特征匹配：单模态与跨模态技术综合综述|Weide Liu, Wei Zhou, Jun Liu, Ping Hu, Jun Cheng, Jungong Han, Weisi Lin|<http://arxiv.org/pdf/2507.22791v1>|系统综述了模态感知特征匹配技术，强调了深度学习方法在跨模态匹配中的鲁棒性和适应性提升。|
|🆕 发布|Bridging the Gap in Missing Modalities: Leveraging Knowledge Distillation and Style Matching for Brain Tumor Segmentation|填补缺失模态的差距：利用知识蒸馏和风格匹配进行脑肿瘤分割|Shenghao Zhu, Yifei Chen, Weihong Chen, Yuanhan Wang, Chang Liu, Shuo Jiang, Feiwei Qin, Changmiao Wang|<http://arxiv.org/pdf/2507.22626v1>|[代码](https://github.com/Quanato607/MST-KDNet.); 提出MST-KDNet模型，利用多尺度变换器知识蒸馏和全局风格匹配，有效应对脑肿瘤分割中关键成像模态...|
|📝 更新|Skull-stripping induces shortcut learning in MRI-based Alzheimer's disease classification|颅骨剥离在基于MRI的阿尔茨海默病分类中引发捷径学习|Christian Tinauer, Maximilian Sackl, Rudolf Stollberger, Reinhold Schmidt, Stefan Ropele, Christian Langkammer|<http://arxiv.org/pdf/2501.15831v3>|揭示了颅骨剥离预处理在MRI图像中引入的轮廓特征导致阿尔茨海默病分类的捷径学习现象。|
|📝 更新|Automated MRI Tumor Segmentation using hybrid U-Net with Transformer and Efficient Attention|使用混合U-Net结合Transformer和高效注意力机制的自动MRI肿瘤分割|Syed Haider Ali, Asrar Ahmad, Muhammad Ali, Asifullah Khan, Nadeem Shaukat|<http://arxiv.org/pdf/2506.15562v2>|提出了一种结合U-Net与Transformer的混合网络，用于本地MRI数据集的肿瘤自动分割，提高...|
|🆕 发布|Learned Off-aperture Encoding for Wide Field-of-view RGBD Imaging|宽视场RGBD成像的学得非孔径编码|Haoyu Wei, Xin Liu, Yuhui Liu, Qiang Fu, Wolfgang Heidrich, Edmund Y. Lam, Yifan Peng|<http://arxiv.org/pdf/2507.22523v1>|提出了一种离轴光学编码方法，通过在非瞳面位置放置衍射光学元件，实现了对波前局部控制，显著提升了广角R...|
|📝 更新|SMAFormer: Synergistic Multi-Attention Transformer for Medical Image Segmentation|协同多注意力变换器用于医学图像分割：SMAFormer|Fuchen Zheng, Xuhang Chen, Weihuang Liu, Haolun Li, Yingtie Lei, Jiahui He, Chi-Man Pun, Shounjun Zhou|<http://arxiv.org/pdf/2409.00346v4>|[代码](https://github.com/CXH-Research/SMAFormer.); 提出SMAFormer，一种融合多注意力机制的Transformer架构，有效提升小肿瘤和器官的医学...|
|🆕 发布|Aleatoric Uncertainty Medical Image Segmentation Estimation via Flow Matching|通过流匹配估计医学图像分割的随机不确定性|Phi Van Nguyen, Ngoc Huynh Trinh, Duy Minh Lam Nguyen, Phu Loc Nguyen, Quoc Long Tran|<http://arxiv.org/pdf/2507.22418v1>|[代码](https://github.com/huynhspm/Data-Uncertainty); 提出了一种基于条件流匹配的医疗图像分割不确定性估计方法，提高了准确性并可靠地反映了专家间差异。|
|📝 更新|RaGS: Unleashing 3D Gaussian Splatting from 4D Radar and Monocular Cues for 3D Object Detection|RaGS：从4D雷达和单目线索释放三维高斯散点绘制以进行三维目标检测|Xiaokai Bai, Chenxu Zhou, Lianqing Zheng, Si-Yuan Cao, Jianan Liu, Xiaohan Zhang, Zhengzhuang Zhang, Hui-liang Shen|<http://arxiv.org/pdf/2507.19856v2>|提出了一种利用3D高斯散点表示融合4D雷达和单目图像线索的3D物体检测框架，实现了高效资源分配和场景...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OpenEarthSensing: Large-Scale Fine-Grained Benchmark for Open-World Remote Sensing|开放地球感知：面向开放世界遥感的大规模细粒度基准|Xiang Xiang, Zhuo Xu, Yao Deng, Qinhao Zhou, Yifan Liang, Ke Chen, Qingfang Zheng, Yaowei Wang .etc.|<http://arxiv.org/pdf/2502.20668v2>|[代码](https://haiv-lab.github.io/OES.); 提出了OpenEarthSensing，一个大规模细粒度基准，用于评估开放世界遥感任务中的模型泛化性...|
|🆕 发布|DeltaVLM: Interactive Remote Sensing Image Change Analysis via Instruction-guided Difference Perception|DeltaVLM：基于指令引导的差异感知的交互式遥感图像变化分析|Pei Deng, Wenqian Zhou, Hanlin Wu|<http://arxiv.org/pdf/2507.22346v1>|[代码](https://github.com/hanlinwu/DeltaVLM.); 提出了一种结合变化检测与视觉问答的DeltaVLM模型，实现多轮指令引导的遥感图像变化交互分析。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CapRecover: A Cross-Modality Feature Inversion Attack Framework on Vision Language Models|CapRecover：一种面向视觉语言模型的跨模态特征逆向攻击框架|Kedong Xiu, Saiqian Zhang|<http://arxiv.org/pdf/2507.22828v1>|提出CapRecover框架，直接从视觉模型中间特征恢复高级语义内容，无需图像重建。|
|🆕 发布|MoCHA: Advanced Vision-Language Reasoning with MoE Connector and Hierarchical Group Attention|MoCHA：使用MoE连接器和层次化组注意力进行高级视觉-语言推理|Yuqi Pang, Bowen Yang, Yun Cao, Fan Rong, Xiaoyu Li, Chen He|<http://arxiv.org/pdf/2507.22805v1>|提出MoCHA框架，通过混合专家连接器和分层组注意力提升视觉语言推理性能。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Viser: Imperative, Web-based 3D Visualization in Python|“Viser：Python中的命令式、基于Web的3D可视化”|Brent Yi, Chung Min Kim, Justin Kerr, Gina Wu, Rebecca Feng, Anthony Zhang, Jonas Kulhanek, Hongsuk Choi .etc.|<http://arxiv.org/pdf/2507.22885v1>|Viser实现了Python中简单易用的3D可视化，通过命令式API和基于网页的查看器提升现代编程兼...|
|🆕 发布|Exploration of Low-Cost but Accurate Radar-Based Human Motion Direction Determination|低成本但精确的雷达基人体运动方向探测研究|Weicheng Gao|<http://arxiv.org/pdf/2507.22567v1>|[代码](https://github.com/JoeyBGOfficial/Low-Cost-Accurate-Radar-Based-Human-Motion-Direction-Determination.); 提出了一种低成本但精确的雷达技术，结合轻量级神经网络模型，有效确定人体运动方向。|
|📝 更新|TurboReg: TurboClique for Robust and Efficient Point Cloud Registration|TurboReg：用于鲁棒和高效点云配准的TurboClique方法|Shaocheng Yan, Pengcheng Shi, Zhenjun Zhao, Kaixin Wang, Kuang Cao, Ji Wu, Jiayuan Li|<http://arxiv.org/pdf/2507.01439v3>|[代码](https://github.com/Laka-3DV/TurboReg); 提出了一种高效的点云配准方法TurboReg，通过创新的TurboClique和线性时间复杂度的算法...|
|📝 更新|RTMap: Real-Time Recursive Mapping with Change Detection and Localization|RTMap：实时递归映射与变化检测及定位|Yuheng Du, Sheng Yang, Lingxuan Wang, Zhenghua Hou, Chengying Cai, Zhitao Tan, Mingxia Chen, Shi-Sheng Huang .etc.|<http://arxiv.org/pdf/2507.00980v2>|[代码](https://github.com/CN-ADLab/RTMap.); 提出RTMap方法，通过众包多遍历高清地图和实时变化检测，提升了地图准确性和实时定位能力。|
|🆕 发布|A Linear N-Point Solver for Structure and Motion from Asynchronous Tracks|异步轨迹下的线性N点解算器用于结构和运动估计|Hang Su, Yunlong Feng, Daniel Gehrig, Panfeng Jiang, Ling Gao, Xavier Lagorce, Laurent Kneip|<http://arxiv.org/pdf/2507.22733v1>|[代码](https://github.com/suhang99/AsyncTrack-Motion-Solver.); 提出了一种适用于异步时间戳点对应关系的线性求解器，实现了从任意视图的二维点对应中高效估计结构和运动。|

