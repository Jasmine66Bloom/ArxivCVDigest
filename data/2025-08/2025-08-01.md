## [UPDATED!] **2025-08-01** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AudioGen-Omni: A Unified Multimodal Diffusion Transformer for Video-Synchronized Audio, Speech, and Song Generation|音频生成全景：一种用于视频同步音频、语音和歌曲生成的统一多模态扩散变压器模型|Le Wang, Jun Wang, Feng Deng, Chen Zhang, Kun Gai, Di Zhang|<http://arxiv.org/pdf/2508.00733v1>|提出了AudioGen-Omni模型，通过统一的多模态训练生成与视频同步的高保真音频、语音和歌曲。|
|📝 更新|TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data|" TerraMesh：多模态地球观测数据行星级镶嵌图"|Benedikt Blumenstiel, Paolo Fraccaro, Valerio Marsocci, Johannes Jakubik, Stefano Maurogiovanni, Mikolaj Czerkawski, Rocco Sedona, Gabriele Cavallaro .etc.|<http://arxiv.org/pdf/2504.11172v2>|构建了全球多样、多模态的TerraMesh数据集，支持大规模预训练并提升模型性能。|
|📝 更新|DINO-R1: Incentivizing Reasoning Capability in Vision Foundation Models|DINO-R1：激励视觉基础模型中的推理能力|Chenbin Pan, Wenbin He, Zhengzhong Tu, Liu Ren|<http://arxiv.org/pdf/2505.24025v2>|首次利用强化学习激励视觉基础模型实现视觉推理能力，提出了一种新的训练策略。|
|🆕 发布|CLIPTime: Time-Aware Multimodal Representation Learning from Images and Text|CLIPTime：从图像和文本中学习时间感知的多模态表征|Anju Rani, Daniel Ortiz-Arroyo, Petar Durdevic|<http://arxiv.org/pdf/2508.00447v1>|提出CLIPTime模型，通过联合视觉文本嵌入预测真菌生长阶段和时间戳，增强生物生长动态理解。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GECO: Geometrically Consistent Embedding with Lightspeed Inference|几何一致嵌入的GECO：光速推理|Regine Hartwig, Dominik Muhle, Riccardo Marin, Daniel Cremers|<http://arxiv.org/pdf/2508.00746v1>|[代码](https://reginehartwig.github.io/publications); GECO通过结合几何一致性嵌入和最优传输训练框架，提升了视觉特征学习的几何感知能力并实现了快速推理。|
|📝 更新|FakeIDet: Exploring Patches for Privacy-Preserving Fake ID Detection|《FakeIDet：探索用于隐私保护的假身份证检测的补丁方法》|Javier Muñoz-Haro, Ruben Tolosana, Ruben Vera-Rodriguez, Aythami Morales, Julian Fierrez|<http://arxiv.org/pdf/2504.07761v2>|提出了一种隐私保护的假身份证检测方法FakeIDet，通过 patch-based 策略平衡隐私与性...|
|🆕 发布|LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer|usion Transformer的可扩展性》|Yuzhuo Chen, Zehua Ma, Jianhua Wang, Kai Kang, Shunyu Yao, Weiming Zhang|<http://arxiv.org/pdf/2508.00477v1>|[代码](https://github.com/Suchenl/LAMIC.); 首次提出无训练需求的布局感知多图像合成框架LAMIC，通过增强实体解耦和布局感知生成，实现多图像合成...|
|🆕 发布|Sortblock: Similarity-Aware Feature Reuse for Diffusion Model|排序块：相似性感知特征重用扩散模型|Hanqi Chen, Xu Zhang, Xiaoliu Guan, Lielin Jiang, Guanzhong Wang, Zeyu Chen, Yi Liu|<http://arxiv.org/pdf/2508.00412v1>|提出了一种基于相似性感知的特征重用框架Sortblock，有效加速了扩散模型的推理速度且保持了生成质...|
|🆕 发布|$MV_{Hybrid}$: Improving Spatial Transcriptomics Prediction with Hybrid State Space-Vision Transformer Backbone in Pathology Vision Foundation Models|$MV_{Hybrid}$：利用混合状态空间-视觉Transformer骨干网络提升病理视觉基础模型中的空间转录组学预测|Won June Cho, Hongjun Yoon, Daeky Jeong, Hyeongyeol Lim, Yosep Chong|<http://arxiv.org/pdf/2508.00383v1>|[代码](https://github.com/deepnoid-ai/MVHybrid.); 提出$MV_{Hybrid}$模型，融合状态空间模型与视觉变换器，提升病理视觉基础模型对空间基因表达...|
|📝 更新|Lossless Token Merging Even Without Fine-Tuning in Vision Transformers|无损失标记合并：即使不进行微调也在视觉变换器中有效|Jaeyeon Lee, Dong-Wan Choi|<http://arxiv.org/pdf/2505.15160v2>|提出无训练需求的Adaptive Token Merging方法，实现视觉变换器中无损的token压...|
|📝 更新|H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation|H-RDT: 人类操作增强的双臂机器人操作|Hongzhe Bi, Lingxuan Wu, Tianwei Lin, Hengkai Tan, Zhizhong Su, Hang Su, Jun Zhu|<http://arxiv.org/pdf/2507.23523v2>|利用人类操作数据，H-RDT方法显著提升双臂机器人操作能力。|
|🆕 发布|AniMer+: Unified Pose and Shape Estimation Across Mammalia and Aves via Family-Aware Transformer|跨哺乳动物和鸟类的家族感知统一姿态与形状估计方法AniMer+：基于家族感知变换器|Jin Lyu, Liang An, Li Lin, Pujin Cheng, Yebin Liu, Xiaoying Tang|<http://arxiv.org/pdf/2508.00298v1>|提出了一种统一估计哺乳动物和鸟类姿态与形状的家族感知Transformer模型，通过专有与共享组件结...|
|🆕 发布|Multimodal Referring Segmentation: A Survey|多模态指引用分割：综述|Henghui Ding, Song Tang, Shuting He, Chang Liu, Zuxuan Wu, Yu-Gang Jiang|<http://arxiv.org/pdf/2508.00265v1>|[代码](https://github.com/henghuiding/Awesome-Multimodal-Referring-Segmentation.); 系统梳理了多模态指引用分割领域的发展，提出了统一的元架构，并对比了不同场景下的代表性方法。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FMPlug: Plug-In Foundation Flow-Matching Priors for Inverse Problems|FMPlug：用于逆问题的即插即用基础流匹配先验|Yuxiang Wan, Ryan Devera, Wenjie Zhang, Ju Sun|<http://arxiv.org/pdf/2508.00721v1>|提出FMPlug框架，通过自适应预热和尖锐高斯性正则化，提升基础流匹配先验解决逆问题性能。|
|📝 更新|Meta CLIP 2: A Worldwide Scaling Recipe|元CLIP 2：全球规模扩展方案|Yung-Sung Chuang, Yang Li, Dong Wang, Ching-Feng Yeh, Kehan Lyu, Ramya Raghavendra, James Glass, Lifei Huang .etc.|<http://arxiv.org/pdf/2507.22062v3>|Meta CLIP 2首次实现了在全球化网络规模上从零开始训练CLIP模型，有效解决了多语言数据训练...|
|📝 更新|Long-LRM: Long-sequence Large Reconstruction Model for Wide-coverage Gaussian Splats|长序列大规模重建模型Long-LRM：用于宽覆盖高斯散点的模型|Chen Ziwen, Hao Tan, Kai Zhang, Sai Bi, Fujun Luan, Yicong Hong, Li Fuxin, Zexiang Xu|<http://arxiv.org/pdf/2410.12781v2>|[代码](https://arthurhero.github.io/projects); 提出了一种高效的3D场景重建模型Long-LRM，通过结合Mamba2和变压器块，实现了对大范围场景...|
|🆕 发布|Towards Robust Semantic Correspondence: A Benchmark and Insights|面向鲁棒语义对应：一个基准和洞见|Wenyue Chong|<http://arxiv.org/pdf/2508.00272v1>|提出新型基准测试集，揭示了语义对应技术在恶劣条件下的鲁棒性不足问题及改善策略。|
|📝 更新|HumaniBench: A Human-Centric Framework for Large Multimodal Models Evaluation|《HumaniBench：一种面向大型多模态模型评估的人本中心框架》|Shaina Raza, Aravind Narayanan, Vahid Reza Khazaie, Ashmal Vayani, Mukund S. Chettiar, Amandeep Singh, Mubarak Shah, Deval Pandya|<http://arxiv.org/pdf/2505.11454v3>|提出HumaniBench基准，评估大型多模态模型在公平性、伦理等人类中心价值方面的表现。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Cross-Dataset Semantic Segmentation Performance Analysis: Unifying NIST Point Cloud City Datasets for 3D Deep Learning|跨数据集语义分割性能分析：统一NIST点云城市数据集以用于三维深度学习|Alexander Nikitas Dimopoulos, Joseph Grasso|<http://arxiv.org/pdf/2508.00822v1>|分析了不同标注的点云数据集在语义分割中的表现，提出统一标注方法和改进策略以提升公共安全相关特征识别。|
|🆕 发布|AI-Driven Collaborative Satellite Object Detection for Space Sustainability|基于人工智能的协作卫星目标检测技术以支持空间可持续性|Peng Hu, Wenxuan Zhang|<http://arxiv.org/pdf/2508.00755v1>|提出卫星聚类框架，实现多卫星协作进行深度学习空间目标检测，提升低地球轨道空间可持续性。|
|🆕 发布|Revisiting Adversarial Patch Defenses on Object Detectors: Unified Evaluation, Large-Scale Dataset, and New Insights|重新审视对抗性补丁在目标检测器上的防御：统一评估、大规模数据集与新见解|Junhao Zheng, Jiahao Sun, Chenhao Lin, Zhengyu Zhao, Chen Ma, Chong Zhang, Cong Wang, Qian Wang .etc.|<http://arxiv.org/pdf/2508.00649v1>|[代码](https://github.com/Gandolfczjh/APDE); 构建首个全面评估框架和大规模数据集，揭示了对抗性补丁防御的新见解。|
|🆕 发布|EPANet: Efficient Path Aggregation Network for Underwater Fish Detection|EPANet：水下鱼检测的高效路径聚合网络|Jinsong Yang, Zeyuan Hu, Yichen Li|<http://arxiv.org/pdf/2508.00528v1>|提出了一种高效的路径聚合网络EPANet，通过互补特征整合提升水下鱼检测的准确性和效率。|
|🆕 发布|UIS-Mamba: Exploring Mamba for Underwater Instance Segmentation via Dynamic Tree Scan and Hidden State Weaken|UIS-Mamba：通过动态树扫描和隐藏状态弱化探索水下实例分割中的Mamba方法|Runmin Cong, Zongji Yu, Hao Fang, Haoyan Sun, Sam Kwong|<http://arxiv.org/pdf/2508.00421v1>|[代码](https://github.com/Maricalce/UIS-Mamba.); 提出UIS-Mamba模型，通过动态树扫描和隐藏状态削弱技术，有效应对水下场景实例分割挑战。|
|🆕 发布|PointGauss: Point Cloud-Guided Multi-Object Segmentation for Gaussian Splatting|点高斯：基于点云引导的多目标分割用于高斯绘制|Wentao Sun, Hanqing Xu, Quanyun Wu, Dedong Zhang, Yiping Chen, Lingfei Ma, John S. Zelek, Jonathan Li|<http://arxiv.org/pdf/2508.00259v1>|PointGauss通过点云引导实现实时多对象分割，大幅提升3D分割效率和多视角一致性。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Backdoor Attacks on Deep Learning Face Detection|深度学习人脸检测算法的后门攻击研究|Quentin Le Roux, Yannick Teglia, Teddy Furon, Philippe Loubet-Moundi|<http://arxiv.org/pdf/2508.00620v1>|首次提出针对人脸检测的生成攻击和坐标偏移攻击，并提出了相应的防御策略。|
|🆕 发布|Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images|弱监督病毒壳体检测：在电子显微镜图像中使用图像级标注|Hannah Kniesel, Leon Sick, Tristan Payer, Tim Bergner, Kavitha Shaga Devan, Clarissa Read, Paul Walther, Timo Ropinski|<http://arxiv.org/pdf/2508.00563v1>|提出了一种仅依赖图像级标注的弱监督病毒壳体检测算法，减少了对专家标注的依赖并优于现有弱标注方法。|
|🆕 发布|Training-Free Class Purification for Open-Vocabulary Semantic Segmentation|无训练的开放词汇语义分割类别净化方法|Qi Chen, Lingxiao Yang, Yun Chen, Nailong Zhao, Jianhuang Lai, Jie Shao, Xiaohua Xie|<http://arxiv.org/pdf/2508.00557v1>|提出了一种无需训练的类别净化框架FreeCP，有效解决了类别冗余和视觉语言歧义问题，提升开放词汇语义...|
|🆕 发布|HyPCV-Former: Hyperbolic Spatio-Temporal Transformer for 3D Point Cloud Video Anomaly Detection|HyPCV-Former：双曲时空变换器用于三维点云视频异常检测|Jiaping Cao, Kangkang Zhou, Juan Du|<http://arxiv.org/pdf/2508.00473v1>|提出了一种基于双曲空间的三维点云视频异常检测方法，通过捕捉事件潜在层次结构，实现了性能显著提升。|
|📝 更新|Detection, Pose Estimation and Segmentation for Multiple Bodies: Closing the Virtuous Circle|多人体检测、姿态估计与分割：构建良性循环|Miroslav Purkrabek, Jiri Matas|<http://arxiv.org/pdf/2412.01562v3>|[代码](https://MiraPurkrabek.github.io/BBox-Mask-Pose.); 提出了一种迭代增强框、掩膜和姿态一致性的BBox-Mask-Pose方法，显著提升了多人场景的检测、...|
|📝 更新|YOLO-FireAD: Efficient Fire Detection via Attention-Guided Inverted Residual Learning and Dual-Pooling Feature Preservation|基于注意力引导的倒置残差学习和双重池化特征保留的高效火灾检测YOLO-FireAD|Weichao Pan, Bohan Xu, Xu Wang, Chengze Lv, Shuoyang Wang, Zhenke Duan, Zhen Tian|<http://arxiv.org/pdf/2505.20884v3>|[代码](https://github.com/JEFfersusu/YOLO-FireAD); 提出YOLO-FireAD模型，通过注意力引导残差学习和双池化融合，提升动态环境下火灾检测的准确性与...|
|🆕 发布|Weakly Supervised Intracranial Aneurysm Detection and Segmentation in MR angiography via Multi-task UNet with Vesselness Prior|通过具有血管先验的多任务UNet在MR血管造影中实现弱监督颅内动脉瘤检测与分割|Erin Rainville, Amirhossein Rasoulian, Hassan Rivaz, Yiming Xiao|<http://arxiv.org/pdf/2508.00235v1>|提出了一种结合血管先验知识的三维多任务UNet网络，实现了颅内动脉瘤的弱监督检测与分割。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Learning Zero-Shot Material States Segmentation, by Implanting Natural Image Patterns in Synthetic Data|学习零样本材料状态分割：通过在合成数据中植入自然图像模式|Sagi Eppel, Jolina Li, Manuel Drehwald, Alan Aspuru-Guzik|<http://arxiv.org/pdf/2403.03309v6>|利用真实图像模式增强合成数据，实现了零样本材料状态分割的精确性与多样性。|
|📝 更新|Core-Set Selection for Data-efficient Land Cover Segmentation|数据高效土地覆盖分割的核心集选择|Keiller Nogueira, Akram Zaytar, Wanli Ma, Ribana Roscher, Ronny Hänsch, Caleb Robinson, Anthony Ortiz, Simone Nsutezo .etc.|<http://arxiv.org/pdf/2505.01225v2>|[代码](https://github.com/keillernogueira/data-centric-rs-classification); 提出六种核心样本选择方法，用于高效利用遥感图像数据训练深度学习模型。|
|📝 更新|CorrCLIP: Reconstructing Patch Correlations in CLIP for Open-Vocabulary Semantic Segmentation|CorrCLIP：在CLIP中重建补丁相关性以实现开放词汇语义分割|Dengke Zhang, Fagui Liu, Quan Tang|<http://arxiv.org/pdf/2411.10086v3>|[代码](https://github.com/zdk258/CorrCLIP.); 提出CorrCLIP方法，通过重构图像块相关性，提升CLIP在开放词汇语义分割的性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LLaVA-Video: Video Instruction Tuning With Synthetic Data|LLaVA-视频：基于合成数据的视频指令微调|Yuanhan Zhang, Jinming Wu, Wei Li, Bo Li, Zejun Ma, Ziwei Liu, Chunyuan Li|<http://arxiv.org/pdf/2410.02713v3>|提出利用合成数据集LLaVA-Video-178K进行视频指令微调，有效提升了大型多模态模型在视频任...|
|🆕 发布|SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation|空间听觉线索驱动的音频驱动的空间感知视频生成方法SpA2V|Kien T. Pham, Yingqing He, Yazhou Xing, Qifeng Chen, Long Chen|<http://arxiv.org/pdf/2508.00782v1>|提出了一种利用音频中的空间听觉线索生成与输入音频在语义和空间上高度对应视频的新框架SpA2V。|
|🆕 发布|YOLO-Count: Differentiable Object Counting for Text-to-Image Generation|YOLO-Count：用于文本到图像生成的可微分对象计数|Guanning Zeng, Xiang Zhang, Zirui Wang, Haiyang Xu, Zeyuan Chen, Bingnan Li, Zhuowen Tu|<http://arxiv.org/pdf/2508.00728v1>|提出YOLO-Count模型，通过'cardinality'地图实现对象计数与图像生成数量控制。|
|📝 更新|The Silent Assistant: NoiseQuery as Implicit Guidance for Goal-Driven Image Generation|《沉默的助手：NoiseQuery 作为目标驱动图像生成的隐式引导》|Ruoyu Wang, Huayang Huang, Ye Zhu, Olga Russakovsky, Yu Wu|<http://arxiv.org/pdf/2412.05101v3>|引入NoiseQuery作为隐式引导，通过初始化噪声提升文本到图像生成的质量和控制性。|
|📝 更新|Aesthetics is Cheap, Show me the Text: An Empirical Evaluation of State-of-the-Art Generative Models for OCR|美学无关紧要，展示给我文字：对当前最先进的生成模型进行OCR的实证评估|Peirong Zhang, Haowei Xu, Jiaxin Zhang, Guitao Xu, Xuhan Zheng, Zhenhua Yang, Junle Liu, Yuyi Zhang .etc.|<http://arxiv.org/pdf/2507.15085v2>|评估了现有生成模型在OCR任务中的表现，倡导将文本图像生成和编辑作为通用生成模型的基础技能。|
|🆕 发布|Medical Reasoning in the Era of LLMs: A Systematic Review of Enhancement Techniques and Applications|《大型语言模型时代下的医疗推理：增强技术与应用的系统综述》|Wenxuan Wang, Zizhan Ma, Meidan Ding, Shiyi Zheng, Shengyuan Liu, Jie Liu, Jiaming Ji, Wenting Chen .etc.|<http://arxiv.org/pdf/2508.00669v1>|系统综述了大型语言模型在医学推理中的应用与提升策略，提出了分类框架并分析了临床应用。|
|📝 更新|ReAlign: Bilingual Text-to-Motion Generation via Step-Aware Reward-Guided Alignment|“ReAlign：通过步进感知的奖励引导对齐实现双语文本到动作生成”|Wanjiang Weng, Xiaofeng Tan, Hongsong Wang, Pan Zhou|<http://arxiv.org/pdf/2505.04974v2>|[代码](https://wengwanjiang.github.io/ReAlign-page); 提出BiHumanML3D数据集和ReAlign方法，通过奖励引导的采样对齐，显著提升双语文本到动作...|
|🆕 发布|Guiding Diffusion-Based Articulated Object Generation by Partial Point Cloud Alignment and Physical Plausibility Constraints|通过部分点云对齐和物理可行性约束引导基于扩散的关节对象生成|Jens U. Kreber, Joerg Stueckler|<http://arxiv.org/pdf/2508.00558v1>|提出PhysNAP方法，通过部分点云对齐和物理合理性约束生成更真实的关节对象。|
|🆕 发布|Video Color Grading via Look-Up Table Generation|通过查找表生成实现视频色彩分级|Seunghyun Shin, Dongmin Shin, Jisu Shin, Hae-Gon Jeon, Joon-Young Lee|<http://arxiv.org/pdf/2508.00548v1>|[代码](https://github.com/seunghyuns98/VideoColorGrading.); 提出了一种基于生成查找表的参考视频色彩分级框架，通过扩散模型实现色彩属性对齐，无需专业编辑技能即可调...|
|📝 更新|FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait|FLOAT：音频驱动的说话肖像生成运动潜在流匹配|Taekyung Ki, Dongchan Min, Gyeongsu Chae|<http://arxiv.org/pdf/2412.01064v4>|提出了一种基于流匹配生成模型的音频驱动说话肖像视频生成方法，通过正交运动潜在空间实现高效且时间一致的...|
|🆕 发布|Reducing the gap between general purpose data and aerial images in concentrated solar power plants|缩小通用数据与集中太阳能发电厂航拍图像之间的差距|M. A. Pérez-Cutiño, J. Valverde, J. Capitán, J. M. Díaz-Báñez|<http://arxiv.org/pdf/2508.00440v1>|[代码](https://mpcutino.github.io/aerialcsp); 提出虚拟数据集AerialCSP，通过模拟真实环境减少太阳能发电场图像数据标注需求。|
|🆕 发布|Steering Guidance for Personalized Text-to-Image Diffusion Models|个人化文本到图像扩散模型的驾驶引导|Sunghyun Park, Seokeon Choi, Hyoungwoo Park, Sungrack Yun|<http://arxiv.org/pdf/2508.00319v1>|提出了一种个性化引导策略，通过动态调整弱模型权重，有效平衡文本对齐和目标分布保真度。|
|🆕 发布|GV-VAD : Exploring Video Generation for Weakly-Supervised Video Anomaly Detection|GV-VAD：探索基于弱监督视频生成的视频异常检测|Suhang Cai, Xiaohao Peng, Chong Wang, Xiaojie Cai, Jiangbo Qian|<http://arxiv.org/pdf/2508.00312v1>|[代码](https://github.com/Sumutan/GV-VAD.git.); 提出了一种利用文本条件生成模型低成本扩充训练数据的弱监督视频异常检测框架，显著提升了检测性能。|
|📝 更新|ForestFormer3D: A Unified Framework for End-to-End Segmentation of Forest LiDAR 3D Point Clouds|森林形变器3D：一种用于森林激光雷达三维点云端到端分割的统一框架|Binbin Xiang, Maciej Wielgosz, Stefano Puliti, Kamil Král, Martin Krůček, Azim Missarov, Rasmus Astrup|<http://arxiv.org/pdf/2506.16991v2>|[代码](https://bxiang233.github.io/FF3D); 提出ForestFormer3D框架，实现了森林LiDAR 3D点云的精确分割，提升了复杂森林环境的...|
|📝 更新|AttnMod: Attention-Based New Art Styles|基于注意力机制的新艺术风格生成模型|Shih-Chieh Su|<http://arxiv.org/pdf/2409.10028v2>|提出了一种无需训练的AttnMod技术，通过调节预训练扩散模型中的跨注意力生成新颖且不可预测的艺术风...|
|📝 更新|FaceLift: Learning Generalizable Single Image 3D Face Reconstruction from Synthetic Heads|《FaceLift：从合成人头学习泛化的单张图像三维人脸重建》|Weijie Lyu, Yi Zhou, Ming-Hsuan Yang, Zhixin Shu|<http://arxiv.org/pdf/2412.17812v2>|FaceLift通过合成人头数据集和多视角生成技术，实现了从单张图片重建高质量360度3D人脸。|
|🆕 发布|Jet Image Generation in High Energy Physics Using Diffusion Models|高能物理中的喷注图像生成：基于扩散模型的方法|Victor D. Martinez, Vidya Manian, Sudhir Malik|<http://arxiv.org/pdf/2508.00250v1>|首次将扩散模型应用于生成大型强子对撞机质子-质子碰撞事件的喷注图像，提升了生成准确性和计算效率。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SynPAIN: A Synthetic Dataset of Pain and Non-Pain Facial Expressions|SynPAIN：疼痛与非疼痛面部表情的合成数据集|Babak Taati, Muhammad Muzammil, Yasamin Zarghami, Abhishek Moturu, Amirhossein Kazerouni, Hailey Reimer, Alex Mihailidis, Thomas Hadjistavropoulos|<http://arxiv.org/pdf/2507.19673v2>|提出SynPAIN，首个针对老年人疼痛检测的多样化合成数据集，减少算法偏见并提升性能。|
|🆕 发布|On-Device Diffusion Transformer Policy for Efficient Robot Manipulation|设备端扩散变换器策略以实现高效的机器人操作|Yiming Wu, Huan Wang, Zhenghao Chen, Jianxin Pang, Dong Xu|<http://arxiv.org/pdf/2508.00697v1>|提出LightDP框架，通过压缩网络和减少采样步骤，实现移动设备上实时高效的机器人操作。|
|🆕 发布|Can Large Pretrained Depth Estimation Models Help With Image Dehazing?|大预训练深度估计模型能否助力图像去雾？|Hongfei Zhang, Kun Zhou, Ruizheng Wu, Jiangbo Lu|<http://arxiv.org/pdf/2508.00698v1>|探究预训练深度估计模型在图像去雾中的应用，提出了一种通用性强的RGB-D融合模块。|
|📝 更新|Semantic-Aware Adaptive Video Streaming Using Latent Diffusion Models for Wireless Networks|基于潜在扩散模型的语义感知自适应视频流传输技术在无线网络中的应用|Zijiang Yan, Jianhua Pei, Hongda Wu, Hina Tabassum, Ping Wang|<http://arxiv.org/pdf/2502.05695v3>|提出语义感知的自适应视频流传输框架，通过融合潜在扩散模型减少带宽使用并提升观看体验。|
|📝 更新|Novel computational workflows for natural and biomedical image processing based on hypercomplex algebras|基于超复数代数的天然与生物医学图像处理的新型计算工作流程|Nektarios A. Valous, Eckhard Hitzer, Dragoş Duşe, Rodrigo Rojas Moraleda, Ferdinand Popp, Meggy Suarez-Carmona, Anna Berthel, Ismini Papageorgiou .etc.|<http://arxiv.org/pdf/2502.07758v7>|利用四元数及二维正交平面分割框架，实现了自然与生物医学图像处理的多种高效计算流程。|
|🆕 发布|DPoser-X: Diffusion Model as Robust 3D Whole-body Human Pose Prior|DPoser-X：扩散模型作为鲁棒的全身三维人体姿态先验|Junzhe Lu, Jing Lin, Hongkun Dou, Ailing Zeng, Yue Deng, Xian Liu, Zhongang Cai, Lei Yang .etc.|<http://arxiv.org/pdf/2508.00599v1>|提出了一种基于扩散模型的全身体态先验方法DPoser-X，通过变分扩散采样统一处理多种姿态相关任务，...|
|📝 更新|Training-free Geometric Image Editing on Diffusion Models|无训练几何图像编辑在扩散模型上|Hanshen Zhu, Zhen Zhu, Kaile Zhang, Yiming Gong, Yuliang Liu, Xiang Bai|<http://arxiv.org/pdf/2507.23300v2>|[代码](https://github.com/CIawevy/FreeFine); 提出了一种无需训练的图像编辑方法，通过解耦处理实现高保真度的几何变换。|
|🆕 发布|DBLP: Noise Bridge Consistency Distillation For Efficient And Reliable Adversarial Purification|噪声桥一致性蒸馏用于高效可靠的反向攻击净化|Chihan Huang, Belal Alsinglawi, Islam Al-qudah|<http://arxiv.org/pdf/2508.00552v1>|提出了一种高效的扩散桥蒸馏方法DBLP，通过构建噪声桥蒸馏目标，实现实时对抗性净化并提升模型鲁棒性。|
|📝 更新|SIDE: Surrogate Conditional Data Extraction from Diffusion Models|SIDE：从扩散模型中提取替代条件数据|Yunhao Chen, Shujie Wang, Difan Zou, Xingjun Ma|<http://arxiv.org/pdf/2410.02467v7>|提出了一种数据驱动条件构造框架SIDE，实现了从无条件生成模型中提取训练数据，挑战了无条件模型安全性...|
|🆕 发布|PIF-Net: Ill-Posed Prior Guided Multispectral and Hyperspectral Image Fusion via Invertible Mamba and Fusion-Aware LoRA|PIF-Net：通过可逆Mamba和融合感知LoRA引导的病态先验指导多光谱与高光谱图像融合|Baisong Li, Xingwang Wang, Haixiao Xu|<http://arxiv.org/pdf/2508.00453v1>|提出PIF-Net框架，通过引入不适定先验和可逆架构，有效融合多光谱与高光谱图像。|
|📝 更新|CPCL: Cross-Modal Prototypical Contrastive Learning for Weakly Supervised Text-based Person Retrieval|CPCL：跨模态原型对比学习用于弱监督文本基础的人物检索|Xinpeng Zhao, Yanwei Zheng, Chuanlin Lan, Xiaowei Zhang, Bowen Huang, Jibin Yang, Dongxiao Yu|<http://arxiv.org/pdf/2401.10011v2>|提出了一种跨模态原型对比学习方法CPCL，通过映射视觉和文本实例至共享空间并挖掘模态间关联，有效提升...|
|🆕 发布|AutoDebias: Automated Framework for Debiasing Text-to-Image Models|自动去偏框架：用于文本到图像模型去偏的自动化框架|Hongyi Cai, Mohammad Mahdinur Rahman, Mingkang Dong, Jie Li, Muxin Pu, Zhili Fang, Yinan Peng, Hanjun Luo .etc.|<http://arxiv.org/pdf/2508.00445v1>|提出AutoDebias框架，自动识别并减轻文本到图像模型中的有害偏见，无需预先了解具体偏见类型。|
|🆕 发布|SDMatte: Grafting Diffusion Models for Interactive Matting|SDMatte：嫁接扩散模型以实现交互式抠图|Longfei Huang, Yu Liang, Hao Zhang, Jinwei Chen, Wei Dong, Lunde Chen, Wanyu Liu, Bo Li .etc.|<http://arxiv.org/pdf/2508.00443v1>|[代码](https://github.com/vivoCameraResearch/SDMatte.); 将扩散模型应用于交互式抠图，通过视觉提示增强边缘细节提取能力，实现了更精细的图像分割效果。|
|🆕 发布|Contact-Aware Amodal Completion for Human-Object Interaction via Multi-Regional Inpainting|接触感知的人物体交互的局部遮挡恢复通过多区域修复|Seunggeun Chi, Enna Sachdeva, Pin-Hao Huang, Kwonjoon Lee|<http://arxiv.org/pdf/2508.00427v1>|提出了一种结合物理先验知识和多区域修复技术的动态人-物交互场景下的非模态补全方法，显著提升了生成图像...|
|🆕 发布|Occlusion-robust Stylization for Drawing-based 3D Animation|遮挡鲁棒性风格化方法在基于绘画的3D动画中的应用|Sunjae Yoon, Gwanhyeong Koo, Younghwan Lee, Ji Woo Hong, Chang D. Yoo|<http://arxiv.org/pdf/2508.00398v1>|提出了一种针对遮挡问题的稳健风格化框架，通过使用光流实现边缘引导，提高了绘制基三维动画中风格保持的一...|
|🆕 发布|DC-AE 1.5: Accelerating Diffusion Model Convergence with Structured Latent Space|DC-AE 1.5：利用结构化潜在空间加速扩散模型收敛|Junyu Chen, Dongyun Zou, Wenkun He, Junsong Chen, Enze Xie, Song Han, Han Cai|<http://arxiv.org/pdf/2508.00413v1>|[代码](https://github.com/dc-ai-projects/DC-Gen.); 通过结构化潜在空间和增强扩散训练，有效提升高分辨率扩散模型的收敛速度和生成质量。|
|📝 更新|Learn2Synth: Learning Optimal Data Synthesis Using Hypergradients for Brain Image Segmentation|“Learn2Synth：利用超梯度学习最优数据合成进行脑影像分割”|Xiaoling Hu, Xiangrui Zeng, Oula Puonti, Juan Eugenio Iglesias, Bruce Fischl, Yael Balbastre|<http://arxiv.org/pdf/2411.16719v3>|[代码](https://github.com/HuXiaoling/Learn2Synth.); Learn2Synth通过学习合成参数而非手动调整，优化了脑部图像分割网络的泛化能力。|
|📝 更新|Rethinking Pan-sharpening: Principled Design, Unified Training, and a Universal Loss Surpass Brute-Force Scaling|重新思考全色锐化：原理性设计、统一训练与通用损失超越暴力缩放|Ran Zhang, Xuanhua He, Li Xueheng, Ke Cao, Liu Liu, Wenbo Xu, Fang Jiabin, Yang Qize .etc.|<http://arxiv.org/pdf/2507.15059v2>|[代码](https://github.com/Zirconium233/PanTiny); 提出了一种高效的PanTiny框架，通过统一训练和通用损失函数，实现了优于大型专用模型的性能效率平衡...|
|🆕 发布|TITAN-Guide: Taming Inference-Time AligNment for Guided Text-to-Video Diffusion Models|TITAN-Guide：驯服推理时对齐以指导文本到视频扩散模型|Christian Simon, Masato Ishii, Akio Hayakawa, Zhi Zhong, Shusuke Takahashi, Takashi Shibuya, Yuki Mitsufuji|<http://arxiv.org/pdf/2508.00289v1>|提出了一种优化文本到视频扩散模型引导过程的方法，减少内存需求并提升控制效果。|
|📝 更新|Retinex-MEF: Retinex-based Glare Effects Aware Unsupervised Multi-Exposure Image Fusion|基于Retinex的感知炫光效应的无监督多曝光图像融合|Haowen Bai, Jiangshe Zhang, Zixiang Zhao, Lilun Deng, Yukun Cui, Shuang Xu|<http://arxiv.org/pdf/2503.07235v2>|[代码](https://github.com/HaowenBai/Retinex-MEF); 提出了一种基于Retinex理论的无需监督的多曝光图像融合方法，有效解决了过曝光导致的眩光问题。|
|🆕 发布|Guided Depth Map Super-Resolution via Multi-Scale Fusion U-shaped Mamba Network|通过多尺度融合U形Mamba网络引导的深度图超分辨率|Chenggang Guo, Hao Xu, XianMing Wan|<http://arxiv.org/pdf/2508.00248v1>|提出了一种多尺度融合U形Mamba网络，通过融合卷积层和状态空间模型，有效提升了深度图超分辨率重建的...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GUAVA: Generalizable Upper Body 3D Gaussian Avatar|GUAVA：通用上半身3D高斯化虚拟形象|Dongbin Zhang, Yunfei Liu, Lijian Lin, Ye Zhu, Yang Li, Minghan Qin, Yu Li, Haoqian Wang|<http://arxiv.org/pdf/2505.03351v2>|提出EHM模型和GUAVA框架，实现了从单张图片快速重建高质量、可动画化的上半身3D Gaussia...|
|📝 更新|PanoLlama: Generating Endless and Coherent Panoramas with Next-Token-Prediction LLMs|PanoLlama：使用下一代标记预测语言模型生成无限且连贯的全景图|Teng Zhou, Xiaoyu Zhang, Yongchuan Tang|<http://arxiv.org/pdf/2411.15867v3>|[代码](https://github.com/0606zt/PanoLlama.); 提出了一种基于自回归范式的全景图像生成框架PanoLlama，实现了无限且连贯的全景图生成。|
|🆕 发布|IN2OUT: Fine-Tuning Video Inpainting Model for Video Outpainting Using Hierarchical Discriminator|IN2OUT：使用分层判别器对视频修复模型进行微调以实现视频外绘|Sangwoo Youn, Minji Lee, Nokap Tony Park, Yeonggyoo Jeon, Taeyoung Na|<http://arxiv.org/pdf/2508.00418v1>|提出了一种利用视频修复模型和层级判别器进行视频延展的新方法，有效提升了延展区域的视觉质量和全局一致性...|
|🆕 发布|Video Forgery Detection with Optical Flow Residuals and Spatial-Temporal Consistency|视频伪造检测：基于光流残差与时空一致性|Xi Xue, Kunio Suzuki, Nabarun Goswami, Takuya Shintate|<http://arxiv.org/pdf/2508.00397v1>|提出了一种结合RGB外观特征与光流残差的方法，有效检测高视觉保真度AI生成视频中的微小运动异常。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|D3: Training-Free AI-Generated Video Detection Using Second-Order Features|D3：基于二阶特征的无训练AI生成视频检测|Chende Zheng, Ruiqi suo, Chenhao Lin, Zhengyu Zhao, Le Yang, Shuai Liu, Minghui Yang, Cong Wang .etc.|<http://arxiv.org/pdf/2508.00701v1>|[代码](https://github.com/Zig-HS/D3.); 提出了一种无需训练的基于二阶特征的视频检测方法D3，有效识别AI生成视频与真实视频的差异。|
|🆕 发布|Wukong Framework for Not Safe For Work Detection in Text-to-Image systems|悟空框架：文本到图像系统中的不宜工作内容检测|Mingrui Liu, Sixiao Zhang, Cheng Long|<http://arxiv.org/pdf/2508.00591v1>|提出Wukong框架，通过利用扩散模型早期输出和预训练参数，高效准确检测文本到图像系统中的不安全内容...|
|🆕 发布|Semantic and Temporal Integration in Latent Diffusion Space for High-Fidelity Video Super-Resolution|在潜在扩散空间中进行语义与时间整合的高保真视频超分辨率|Yiwen Wang, Xinning Chai, Yuhong Zhang, Zhengxue Cheng, Jun Zhao, Rong Xie, Li Song|<http://arxiv.org/pdf/2508.00471v1>|提出SeTe-VSR方法，融合语义与时空引导，实现视频超分辨率的高保真度与连贯性。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation|IGL-Nav：基于递增三维高斯定位的图像目标导航|Wenxuan Guo, Xiuwei Xu, Hang Yin, Ziwei Wang, Jianjiang Feng, Jie Zhou, Jiwen Lu|<http://arxiv.org/pdf/2508.00823v1>|[代码](https://gwxuan.github.io/IGL-Nav); 提出了一种基于递增3D高斯定位的视觉导航框架，有效提升了图像目标在三维空间中的定位效率和准确性。|
|📝 更新|A Physical Model-Guided Framework for Underwater Image Enhancement and Depth Estimation|基于物理模型引导的水下图像增强与深度估计框架|Dazhao Du, Lingyu Si, Fanjiang Xu, Jianwei Niu, Fuchun Sun|<http://arxiv.org/pdf/2407.04230v2>|提出了一种物理模型引导的框架，结合深度学习网络，有效提升了水下图像质量和深度估计准确性。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GeoMoE: Divide-and-Conquer Motion Field Modeling with Mixture-of-Experts for Two-View Geometry|GeoMoE：基于专家混合模型的分而治之运动场建模方法用于双视图几何分析|Jiajun Le, Jiayi Ma|<http://arxiv.org/pdf/2508.00592v1>|[代码](https://github.com/JiajunLe/GeoMoE.); 提出GeoMoE方法，通过混合专家模型针对性建模，有效处理复杂场景中异质运动场问题。|
|📝 更新|Simultaneous Motion And Noise Estimation with Event Cameras|同时运动与噪声估计的事件相机方法|Shintaro Shiba, Yoshimitsu Aoki, Guillermo Gallego|<http://arxiv.org/pdf/2504.04029v2>|[代码](https://github.com/tub-rip/ESMD); 首次提出一种同时估计运动和噪声的方法，显著提升了事件相机数据去噪效果。|
|🆕 发布|SparseRecon: Neural Implicit Surface Reconstruction from Sparse Views with Feature and Depth Consistencies|稀疏重建：基于稀疏视角的神经隐式表面重建，具有特征与深度一致性|Liang Han, Xu Zhang, Haichuan Song, Kanle Shi, Yu-Shen Liu, Zhizhong Han|<http://arxiv.org/pdf/2508.00366v1>|[代码](https://hanl2010.github.io/SparseRecon); 提出SparseRecon方法，通过特征一致性和深度约束提高稀疏视角下的三维形状重建质量。|
|🆕 发布|Exploring Fourier Prior and Event Collaboration for Low-Light Image Enhancement|探索傅里叶先验与事件协作的低光图像增强方法|Chunyan She, Fujun Han, Chengyu Fang, Shukai Duan, Lidan Wang|<http://arxiv.org/pdf/2508.00308v1>|提出了一种分阶段利用事件相机与傅里叶先验的低光照图像增强方法，有效提升了图像质量和结构细节。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Accurate Cross-modal Reconstruction of Vehicle Target from Sparse-aspect Multi-baseline SAR data|车辆目标从稀疏视角多基线合成孔径雷达数据的精确跨模态重建|Da Li, Guoqiang Zhao, Chen Yao, Kaiqiang Zhu, Houjun Sun, Jiacheng Bao, Maokun Li|<http://arxiv.org/pdf/2406.04158v5>|提出了一种融合多模态信息的CMAR-Net，显著提升了车辆目标的稀疏合成孔径雷达数据三维重建精度。|
|📝 更新|LargeMvC-Net: Anchor-based Deep Unfolding Network for Large-scale Multi-view Clustering|大规模多视角聚类的大规模MvC-Net：基于锚点的深度展开网络|Shide Du, Chunming Wu, Zihan Fang, Wendi Zhao, Yilin Wu, Changwei Wang, Shiping Wang|<http://arxiv.org/pdf/2507.20980v2>|提出了一种针对大规模多视角聚类的深度展开网络LargeMvC-Net，通过优化锚点结构提高了聚类效果...|
|📝 更新|C-DOG: Multi-View Multi-instance Feature Association Using Connected δ-Overlap Graphs|基于连通δ-重叠图的多元多实例特征关联：C-DOG|Yung-Hong Sun, Ting-Hung Lin, Jiangang Chen, Hongrui Jiang, Yu Hen Hu|<http://arxiv.org/pdf/2507.14095v2>|提出了一种基于几何约束的C-DOG算法，有效解决了多视角下相同物体特征匹配的模糊问题。|
|📝 更新|Multi-Cali Anything: Dense Feature Multi-Frame Structure-from-Motion for Large-Scale Camera Array Calibration|多校准任意对象：用于大规模相机阵列校准的密集特征多帧结构从运动法|Jinjiang You, Hewei Wang, Yijie Li, Mingxiao Huo, Long Van Tran Ha, Mingyuan Ma, Jinfeng Xu, Jiayi Zhang .etc.|<http://arxiv.org/pdf/2503.00737v2>|[代码](https://github.com/YJJfish/Multi-Cali-Anything); 提出了一种无需额外校准图像的密集特征多帧校准方法，提高了大规模相机阵列的内参精度和3D重建准确性。|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Gaga: Group Any Gaussians via 3D-aware Memory Bank|“Gaga：通过三维感知内存库任意组合高斯分布”|Weijie Lyu, Xueting Li, Abhijit Kundu, Yi-Hsuan Tsai, Ming-Hsuan Yang|<http://arxiv.org/pdf/2404.07977v3>|提出Gaga框架，利用3D感知记忆库关联不同视角下的二维掩码，实现开放世界三维场景的重构与分割。|
|🆕 发布|Stable at Any Speed: Speed-Driven Multi-Object Tracking with Learnable Kalman Filtering|任意速度下稳定：基于可学习卡尔曼滤波的速度驱动多目标跟踪|Yan Gong, Mengjun Chen, Hao Liu, Gao Yongsheng, Lei Yang, Naibang Wang, Ziying Song, Haoqun Ma|<http://arxiv.org/pdf/2508.00358v1>|提出了一种速度驱动的可学习卡尔曼滤波器，通过适应车辆速度优化不确定性建模，显著提升了动态场景下的多目...|
|📝 更新|YOLOO: You Only Learn from Others Once|《YOLOO：仅需一次学习他人》|Lipeng Gu, Mingqiang Wei, Xuefeng Yan, Dingkun Zhu, Wei Zhao, Haoran Xie|<http://arxiv.org/pdf/2409.00618v2>|提出了一种高效的3D多目标跟踪方法YOLOO，通过在训练阶段学习多模态信息，实现了仅使用点云编码器进...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DONUT: A Decoder-Only Model for Trajectory Prediction|DONUT：一种仅解码器模型用于轨迹预测|Markus Knoche, Daan de Geus, Bastian Leibe|<http://arxiv.org/pdf/2506.06854v2>|提出了一种基于解码器仅有的模型来预测轨迹，通过迭代预测和“超预测”策略，实现了更精准的未来轨迹预测。|
|🆕 发布|LesiOnTime -- Joint Temporal and Clinical Modeling for Small Breast Lesion Segmentation in Longitudinal DCE-MRI|LesiOnTime -- 长期动态对比增强磁共振成像中微小乳腺病变分割的联合时间与临床建模|Mohammed Kamran, Maria Bernathova, Raoul Varga, Christian Singer, Zsuzsanna Bago-Horvath, Thomas Helbich, Georg Langs, Philipp Seeböck|<http://arxiv.org/pdf/2508.00496v1>|[代码](https://github.com/cirmuw/LesiOnTime); 提出LesiOnTime方法，结合时间序列影像和BI-RADS评分，提高了小乳腺癌灶的精准分割。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HumanSAM: Classifying Human-centric Forgery Videos in Human Spatial, Appearance, and Motion Anomaly|《HumanSAM：基于人类空间、外观和运动异常分类以人为中心的伪造视频》|Chang Liu, Yunfan Ye, Fan Zhang, Qingyang Zhou, Yuchuan Luo, Zhiping Cai|<http://arxiv.org/pdf/2507.19924v2>|提出HumanSAM框架，通过融合视频理解和空间深度特征，分类人类伪造视频的三种常见异常类型。|
|🆕 发布|Fine-grained Spatiotemporal Grounding on Egocentric Videos|基于第一人称视频的细粒度时空定位|Shuo Liang, Yiwu Zhong, Zi-Yuan Hu, Yeyao Tao, Liwei Wang|<http://arxiv.org/pdf/2508.00518v1>|[代码](https://github.com/LaVi-Lab/EgoMask); 提出首个针对第一视角视频的像素级时空定位基准EgoMask，并构建大规模训练集促进模型性能提升。|
|📝 更新|SkillFormer: Unified Multi-View Video Understanding for Proficiency Estimation|技能形成者：统一多视角视频理解以进行熟练度估计|Edoardo Bianchi, Antonio Liotta|<http://arxiv.org/pdf/2505.08665v3>|提出SkillFormer架构，通过多视角融合显著提升技能评估准确度并降低训练成本。|
|🆕 发布|iSafetyBench: A video-language benchmark for safety in industrial environment|工业环境安全性的视频-语言评估基准：iSafetyBench|Raiyaan Abdullah, Yogesh Singh Rawat, Shruti Vyas|<http://arxiv.org/pdf/2508.00399v1>|[代码](https://github.com/raiyaan-abdullah/iSafety-Bench.); 提出了iSafetyBench，一个针对工业环境安全评估的视频语言基准，揭示了现有模型在危险活动识别...|
|🆕 发布|Bidirectional Action Sequence Learning for Long-term Action Anticipation with Large Language Models|基于大型语言模型的长期动作预测双向动作序列学习|Yuji Sato, Yasunori Ishii, Takayoshi Yamashita|<http://arxiv.org/pdf/2508.00374v1>|提出双向动作序列学习方法BiAnt，结合大型语言模型进行前后预测，提升长期动作预测性能。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Cross-Modal Dual-Causal Learning for Long-Term Action Recognition|跨模态双因果学习用于长期行为识别|Xu Shaowu, Jia Xibin, Gao Junyu, Sun Qianmei, Chang Jing, Fan Chao|<http://arxiv.org/pdf/2507.06603v2>|[代码](https://github.com/xushaowu/CMDCL.); 提出了一种结构因果模型CMDCL，通过跨模态双因果干预解决长期动作识别中的复杂问题。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Model Stock: All we need is just a few fine-tuned models|模型库存：我们所需的仅是少数几个微调后的模型|Dong-Hwan Jang, Sangdoo Yun, Dongyoon Han|<http://arxiv.org/pdf/2403.19522v2>|[代码](https://github.com/naver-ai/model-stock.); 提出了一种仅需少量微调模型的方法，以高效逼近最优平均权重，实现卓越的分布内外性能。|
|🆕 发布|Is It Really You? Exploring Biometric Verification Scenarios in Photorealistic Talking-Head Avatar Videos|《真的是你吗？探讨逼真说话人头像视频中的生物识别验证场景》|Laura Pedrouzo-Rodriguez, Pedro Delgado-DeRobles, Luis F. Gomez, Ruben Tolosana, Ruben Vera-Rodriguez, Aythami Morales, Julian Fierrez|<http://arxiv.org/pdf/2508.00748v1>|提出了一种基于面部运动模式的生物识别验证方法，有效应对 photorealistic 虚拟头像的仿冒...|
|🆕 发布|The Repeated-Stimulus Confound in Electroencephalography|重复刺激混淆在脑电图中的影响|Jack A. Kilgallen, Barak A. Pearlmutter, Jeffrey Mark Siskind|<http://arxiv.org/pdf/2508.00531v1>|揭示了重复刺激在脑解码研究中导致的准确性高估问题，并提出了相应的解决方案。|
|📝 更新|FFGAF-SNN: The Forward-Forward Based Gradient Approximation Free Training Framework for Spiking Neural Networks|基于前向-前向的梯度近似自由训练框架FFGAF-SNN用于尖峰神经网络|Changqing Xu, Ziqiang Yang, Yi Liu, Xinfang Liao, Guiqi Mo, Hao Zeng, Yintang Yang|<http://arxiv.org/pdf/2507.23643v2>|提出了一种无需梯度近似、计算复杂度低的训练框架，有效提升了尖峰神经网络的训练效率和准确度。|
|📝 更新|Enhanced Vision-Language Models for Diverse Sensor Understanding: Cost-Efficient Optimization and Benchmarking|用于多样化传感器理解的增强型视觉-语言模型：高效优化与基准测试|Sangyun Chung, Youngjoon Yu, Se Yeon Kim, Youngchae Chee, Yong Man Ro|<http://arxiv.org/pdf/2412.20750v2>|提出Sensor-Aware Attributes Fine-Tuning (SAFT)方法，有效提...|
|🆕 发布|DocTron-Formula: Generalized Formula Recognition in Complex and Structured Scenarios|DocTron-公式：复杂与结构化场景下的通用公式识别|Yufeng Zhong, Zhixiong Zeng, Lei Chen, Longrong Yang, Liming Zheng, Jing Huang, Siqi Yang, Lin Ma|<http://arxiv.org/pdf/2508.00311v1>|提出DocTron-Formula框架，通过统一视觉语言模型处理复杂科学文献中的公式识别挑战。|
|📝 更新|Three-dimentional reconstruction of complex, dynamic population canopy architecture for crops with a novel point cloud completion model: A case study in Brassica napus rapeseed|作物复杂动态群体冠层结构的三维重建：一种新颖的点云补全模型在油菜中的应用研究|Ziyue Guo, Xin Yang, Yutao Shen, Yang Zhu, Lixi Jiang, Haiyan Cen|<http://arxiv.org/pdf/2506.18292v2>|提出了一种创新的点云补全模型，实现了油菜复杂动态群体冠层结构的高精度三维重建。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|From Press to Pixels: Evolving Urdu Text Recognition|从印刷到像素：乌尔都文字识别的演变|Samee Arif, Sualeha Farid|<http://arxiv.org/pdf/2505.13943v2>|提出了一种针对乌尔都语报纸的OCR系统，通过文章和列分割以及图像超分辨率技术，显著提升了文本识别准确...|
|📝 更新|ShadowMamba: State-Space Model with Boundary-Region Selective Scan for Shadow Removal|阴影魔巴：具有边界区域选择扫描的状态空间模型用于阴影去除|Xiujin Zhu, Chee-Onn Chow, Joon Huang Chuah|<http://arxiv.org/pdf/2411.03260v3>|提出了一种边界区域选择性扫描的ShadowMamba模型，有效提升了阴影去除的准确性和计算效率。|
|📝 更新|Sign Spotting Disambiguation using Large Language Models|使用大型语言模型进行标志检测消歧|JianHe Low, Ozge Mercanoglu Sincan, Richard Bowden|<http://arxiv.org/pdf/2507.03703v2>|利用大型语言模型提升手势识别准确度，实现无需训练的手势词汇灵活匹配与歧义消除。|
|🆕 发布|PMR: Physical Model-Driven Multi-Stage Restoration of Turbulent Dynamic Videos|PMR：基于物理模型驱动的多阶段湍流动态视频复原|Tao Wu, Jingyuan Ye, Ying Fu|<http://arxiv.org/pdf/2508.00406v1>|提出了一种物理模型驱动的多阶段视频复原框架，有效解决了强湍流动态场景视频的几何失真和模糊问题。|
|🆕 发布|Representation Shift: Unifying Token Compression with FlashAttention|表示偏移：统一令牌压缩与FlashAttention|Joonmyung Choi, Sanghyeok Lee, Byungoh Ko, Eunseo Kim, Jihyung Kil, Hyunwoo J. Kim|<http://arxiv.org/pdf/2508.00367v1>|[代码](https://github.com/mlvlab/Representation-Shift.); 提出了一种无需训练的表示偏移方法，整合了令牌压缩与FlashAttention，有效降低计算成本并提...|
|📝 更新|CasP: Improving Semi-Dense Feature Matching Pipeline Leveraging Cascaded Correspondence Priors for Guidance|级联对应先验引导的半稠密特征匹配管道改进：CasP|Peiqi Chen, Lei Yu, Yi Wan, Yingying Pei, Xinyi Liu, Yongxiang Yao, Yingying Zhang, Lixiang Ru .etc.|<http://arxiv.org/pdf/2507.17312v2>|[代码](https://github.com/pq-chen/CasP.); 提出CasP方法，通过级联对应先验指导分解匹配阶段，提升半稠密特征匹配的准确性和效率。|
|📝 更新|GUIOdyssey: A Comprehensive Dataset for Cross-App GUI Navigation on Mobile Devices|GUI奥德赛：面向移动设备跨应用GUI导航的全面数据集|Quanfeng Lu, Wenqi Shao, Zitao Liu, Lingxiao Du, Fanqing Meng, Boxuan Li, Botong Chen, Siyuan Huang .etc.|<http://arxiv.org/pdf/2406.08451v2>|提出了GUIOdyssey数据集，支持跨应用GUI导航，增强了移动设备上智能代理的推理和导航能力。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Cued-Agent: A Collaborative Multi-Agent System for Automatic Cued Speech Recognition|提示-代理：一种用于自动提示性言语识别的协作多代理系统|Guanjie Huang, Danny H. K. Tsang, Shan Yang, Guangzhi Lei, Li Liu|<http://arxiv.org/pdf/2508.00391v1>|[代码](https://github.com/DennisHgj/Cued-Agent.); 提出首个用于自动手势和唇读识别的协作多代理系统Cued-Agent，通过专精子代理实现高效的多模态融...|
|🆕 发布|Omni-Scan: Creating Visually-Accurate Digital Twin Object Models Using a Bimanual Robot with Handover and Gaussian Splat Merging|全方位扫描：利用双臂机器人及交接与高斯散斑合并技术创建视觉精确的数字孪生对象模型|Tianshuang Qiu, Zehan Ma, Karim El-Refai, Hiya Shah, Chung Min Kim, Justin Kerr, Ken Goldberg|<http://arxiv.org/pdf/2508.00354v1>|[代码](https://berkeleyautomation.github.io/omni-scan); 提出了一种使用双臂机器人及高斯泼洒合并技术创建全方位高精度数字孪生三维模型的方法。|
|🆕 发布|Spectral Sensitivity Estimation with an Uncalibrated Diffraction Grating|用未校准衍射光栅进行光谱灵敏度估计|Lilika Makabe, Hiroaki Santo, Fumio Okura, Michael S. Brown, Yasuyuki Matsushita|<http://arxiv.org/pdf/2508.00330v1>|提出了一种利用未校准衍射光栅准确估算相机光谱灵敏度的方法，无需特殊设备即可实现高效校准。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TopoTTA: Topology-Enhanced Test-Time Adaptation for Tubular Structure Segmentation|拓扑增强的测试时适应方法用于管状结构分割：TopoTTA|Jiale Zhou, Wenhan Wang, Shikun Li, Xiaolei Qu, Xin Guo, Yizhong Liu, Wenzhong Tang, Xun Lin .etc.|<http://arxiv.org/pdf/2508.00442v1>|提出了一种针对管状结构分割的测试时适应框架TopoTTA，通过增强拓扑表示和连续性处理，有效应对领域...|
|📝 更新|AAA-Gaussians: Anti-Aliased and Artifact-Free 3D Gaussian Rendering|AAA-高斯函数：抗锯齿和无伪迹的三维高斯渲染|Michael Steiner, Thomas Köhler, Lukas Radl, Felix Windisch, Dieter Schmalstieg, Markus Steinberger|<http://arxiv.org/pdf/2504.12811v2>|引入3D高斯评估技术，有效解决3D重建中的走样和伪影问题，实现无瑕疵实时渲染。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|STF: Shallow-Level Temporal Feedback to Enhance Spiking Transformers|STF：浅层时间反馈以增强脉冲Transformer|Zeqi Zheng, Zizheng Zhu, Yingchao Yu, Yanchen Huang, Changze Lv, Junfeng Tang, Zhaofei Yu, Yaochu Jin|<http://arxiv.org/pdf/2508.00387v1>|提出轻量级模块STF，通过增强脉冲模式多样性提升Spiking Transformers性能。|
|📝 更新|Boosting Adversarial Transferability with Low-Cost Optimization via Maximin Expected Flatness|通过最大化期望平坦度的低成本优化提升对抗性迁移性|Chunlin Qiu, Ang Li, Yiheng Duan, Shenyi Zhang, Yuanjie Zhang, Lingchen Zhao, Qian Wang|<http://arxiv.org/pdf/2405.16181v2>|[代码](https://github.com/SignedQiu/MEFAttack.); 提出平衡探索与利用的优化框架，通过增强零阶平均情况平坦度提高对抗性样本迁移性。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Zero-Shot Anomaly Detection with Dual-Branch Prompt Learning|双分支提示学习驱动的零样本异常检测|Zihan Wang, Samira Ebrahimi Kahou, Narges Armanfard|<http://arxiv.org/pdf/2508.00777v1>|提出了一种双分支提示学习框架PILOT，通过动态整合可学习提示和结构化语义属性，有效应对领域偏移问题...|
|📝 更新|MR-CLIP: Efficient Metadata-Guided Learning of MRI Contrast Representations|MR-CLIP：基于元数据指导的MRI对比表示高效学习|Mehmet Yigit Avci, Pedro Borges, Paul Wright, Mehmet Yigitsoy, Sebastien Ourselin, Jorge Cardoso|<http://arxiv.org/pdf/2507.00043v2>|[代码](https://github.com/myigitavci/MR-CLIP.); 提出MR-CLIP，通过将MR图像与DICOM元数据对齐，无需手动标签学习对比感知表征。|
|📝 更新|Gradient Leakage Defense with Key-Lock Module for Federated Learning|梯度泄漏防御：面向联邦学习的键-锁模块方法|Hanchi Ren, Jingjing Deng, Xianghua Xie|<http://arxiv.org/pdf/2305.04095v3>|提出了一种使用私钥锁模块的梯度泄露防御技术，保护联邦学习中的隐私信息不被泄露。|
|🆕 发布|Honey Classification using Hyperspectral Imaging and Machine Learning|利用高光谱成像和机器学习进行蜂蜜分类|Mokhtar A. Al-Awadhi, Ratnadeep R. Deshmukh|<http://arxiv.org/pdf/2508.00361v1>|提出了一种基于机器学习的蜂蜜植物源自动分类方法，通过特征提取和模型分类实现了高准确率的分类效果。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 目标导向视觉决策 (Goal-oriented Visual Decision Making)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Diffusion-Based User-Guided Data Augmentation for Coronary Stenosis Detection|基于扩散的用户指导数据增强方法在冠状动脉狭窄检测中的应用|Sumin Seo, In Kyu Lee, Hyun-Woo Kim, Jaesik Min, Chung-Hwan Jung|<http://arxiv.org/pdf/2508.00438v1>|提出了一种基于扩散模型的数据增强方法，有效解决了冠脉狭窄检测中数据不足和类别不平衡问题。|


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Sari Sandbox: A Virtual Retail Store Environment for Embodied AI Agents|“Sari沙盒：一种面向具身AI代理的虚拟零售商店环境”|Janika Deborah Gajo, Gerarld Paul Merales, Jerome Escarcha, Brenden Ashley Molina, Gian Nartea, Emmanuel G. Maminta, Juan Carlos Roldan, Rowel O. Atienza|<http://arxiv.org/pdf/2508.00400v1>|[代码](https://github.com/upeee/sari-sandbox-env.); 提出高保真3D虚拟零售店环境Sari Sandbox，为训练具身智能体提供基准，并引入SariBen...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MIHBench: Benchmarking and Mitigating Multi-Image Hallucinations in Multimodal Large Language Models|MIHBench：多模态大型语言模型中多图像幻觉的基准测试与缓解|Jiale Li, Mingrui Wu, Zixiang Jin, Hao Chen, Jiayi Ji, Xiaoshuai Sun, Liujuan Cao, Rongrong Ji|<http://arxiv.org/pdf/2508.00726v1>|提出首个针对多图像场景的幻觉现象评估基准MIHBench，并设计动态注意力平衡机制减少幻觉发生。|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CoProU-VO: Combining Projected Uncertainty for End-to-End Unsupervised Monocular Visual Odometry|CoProU-VO：结合投影不确定性实现端到端无监督单目视觉里程计|Jingchao Xie, Oussema Dhaouadi, Weirong Chen, Johannes Meier, Jacques Kaiser, Daniel Cremers|<http://arxiv.org/pdf/2508.00568v1>|提出了一种融合跨帧不确定性的视觉里程计方法，有效处理动态场景中的误差。|
|🆕 发布|HiPrune: Training-Free Visual Token Pruning via Hierarchical Attention in Vision-Language Models|HiPrune：基于视觉语言模型中的层次注意力无需训练的视觉标记剪枝|Jizhihui Liu, Feiyi Du, Guangdao Zhu, Niu Lian, Jun Li, Bin Chen|<http://arxiv.org/pdf/2508.00553v1>|[代码](https://github.com/Danielement321/HiPrune.); 提出HiPrune，一种无需训练、适用于多种视觉语言模型的视觉token剪枝方法，大幅提升效率并保持...|
|📝 更新|OpenSeg-R: Improving Open-Vocabulary Segmentation via Step-by-Step Visual Reasoning|开放分割R：通过逐步视觉推理提升开放词汇分割性能|Zongyan Han, Jiale Cao, Shuo Chen, Tong Wang, Jorma Laaksonen, Rao Muhammad Anwer|<http://arxiv.org/pdf/2505.16974v2>|[代码](https://github.com/Hanzy1996/OpenSeg-R.); 引入逐步视觉推理框架OpenSeg-R，提升开放词汇分割的准确性和可解释性。|
|🆕 发布|Decouple before Align: Visual Disentanglement Enhances Prompt Tuning|解耦后再对齐：视觉解耦增强提示调优|Fei Zhang, Tianfei Zhou, Jiangchao Yao, Ya Zhang, Ivor W. Tsang, Yanfeng Wang|<http://arxiv.org/pdf/2508.00395v1>|[代码](https://github.com/Ferenas/DAPT.); 提出解耦视觉模态前后景再对齐的新策略，有效解决prompt tuning中的信息不对称问题。|
|🆕 发布|CoRGI: Verified Chain-of-Thought Reasoning with Visual Grounding|CoRGI：具有视觉定位的验证链式思维推理|Shixin Yi, Lin Shang|<http://arxiv.org/pdf/2508.00378v1>|引入视觉验证机制以增强视觉语言模型推理过程的准确性。|
|🆕 发布|Analyze-Prompt-Reason: A Collaborative Agent-Based Framework for Multi-Image Vision-Language Reasoning|分析-提示-推理：一种基于协作代理的的多图像视觉语言推理框架|Angelos Vlachos, Giorgos Filandrianos, Maria Lymperaiou, Nikolaos Spanos, Ilias Mitsouras, Vasileios Karampinis, Athanasios Voulodimos|<http://arxiv.org/pdf/2508.00356v1>|提出了一种基于双代理系统的多图像视觉语言推理框架，通过任务特定提示显著提升了大型视觉语言模型的推理性...|
|🆕 发布|UAV-ON: A Benchmark for Open-World Object Goal Navigation with Aerial Agents|无人机开放世界目标物体导航基准：基于空中智能体的UAV-ON|Jianqiang Xiao, Yuexuan Sun, Yixin Shao, Boxi Gan, Rongqiang Liu, Yanjing Wu, Weili Gua, Xiang Deng|<http://arxiv.org/pdf/2508.00288v1>|提出了UAV-ON基准，通过高空代理在开放世界环境中进行无详细指令的物体目标导航。|
|🆕 发布|Instruction-Grounded Visual Projectors for Continual Learning of Generative Vision-Language Models|基于指令的视觉投影器用于生成视觉语言模型的持续学习|Hyundong Jin, Hyung Jin Chang, Eunwoo Kim|<http://arxiv.org/pdf/2508.00260v1>|提出了一种基于指令的视觉投影器框架，通过专化的视觉-语言翻译专家和推荐策略，有效提升了生成视觉语言模...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Sample-Aware Test-Time Adaptation for Medical Image-to-Image Translation|样本感知的测试时适应方法用于医学图像到图像的转换|Irene Iele, Francesco Di Feola, Valerio Guarrasi, Paolo Soda|<http://arxiv.org/pdf/2508.00766v1>|[代码](https://github.com/cosbidev/Sample-Aware_TTA.); 提出了一种针对医学图像翻译的样本感知测试时适应框架，通过动态调整内部特征有效应对样本分布偏移问题。|
|🆕 发布|SU-ESRGAN: Semantic and Uncertainty-Aware ESRGAN for Super-Resolution of Satellite and Drone Imagery with Fine-Tuning for Cross Domain Evaluation|SU-ESRGAN：面向卫星和无人机影像的超分辨率重建的语义感知与不确定性感知ESRGAN及其跨域评估的微调方法|Prerana Ramkumar|<http://arxiv.org/pdf/2508.00750v1>|提出SU-ESRGAN模型，融合语义细节保持与不确定性估计，提升卫星和无人机影像超分辨率处理的准确性...|
|📝 更新|Navigating Distribution Shifts in Medical Image Analysis: A Survey|《在医学图像分析中导航分布偏移：综述》|Zixian Su, Jingwei Guo, Xi Yang, Qiufeng Wang, Frans Coenen, Kaizhu Huang|<http://arxiv.org/pdf/2411.05824v2>|系统综述了应对医疗影像分析中分布偏移的深度学习策略，分类为联合训练、联邦学习、微调和域泛化。|
|🆕 发布|Minimum Data, Maximum Impact: 20 annotated samples for explainable lung nodule classification|最小数据，最大影响：20个注释样本用于可解释的肺结节分类|Luisa Gallée, Catharina Silvia Lisson, Christoph Gerhard Lisson, Daniela Drees, Felix Weig, Daniel Vogele, Meinrad Beer, Michael Götz|<http://arxiv.org/pdf/2508.00639v1>|利用生成模型合成属性标注数据，仅用20个样本显著提升了解释性肺结节分类模型的性能。|
|🆕 发布|Context-based Motion Retrieval using Open Vocabulary Methods for Autonomous Driving|基于上下文的运动检索：使用开放词汇方法进行自动驾驶|Stefan Englmeier, Max A. Büttner, Katharina Winter, Fabian B. Flohr|<http://arxiv.org/pdf/2508.00589v1>|提出了一种基于自然语言查询的上下文感知运动检索框架，用于自动驾驶系统在复杂场景中的针对性评估。|
|🆕 发布|A Novel Modeling Framework and Data Product for Extended VIIRS-like Artificial Nighttime Light Image Reconstruction (1986-2024)|一种新颖的建模框架与数据产品：扩展VIIRS-like人工夜间灯光图像重建（1986-2024）|Yihe Tian, Kwan Man Cheng, Zhengbo Zhang, Tao Zhang, Suju Li, Dongmei Yan, Bing Xu|<http://arxiv.org/pdf/2508.00590v1>|提出了一种两阶段重构框架，通过Hierarchical Fusion Decoder和Dual Fe...|
|🆕 发布|Your other Left! Vision-Language Models Fail to Identify Relative Positions in Medical Images|“你的另一个左侧！视觉语言模型在识别医学图像中的相对位置时失败”|Daniel Wolf, Heiko Hillenhagen, Billurvan Taskin, Alex Bäuerle, Meinrad Beer, Michael Götz, Timo Ropinski|<http://arxiv.org/pdf/2508.00549v1>|发现现有视觉语言模型在识别医学图像中解剖结构相对位置上的不足，并提出了视觉提示增强方法和相关评估数据...|
|🆕 发布|SAMSA 2.0: Prompting Segment Anything with Spectral Angles for Hyperspectral Interactive Medical Image Segmentation|SAMSA 2.0：利用光谱角提示 Segment Anything 进行高光谱交互式医学图像分割|Alfie Roddan, Tobias Czempiel, Chi Xu, Daniel S. Elson, Stamatia Giannarou|<http://arxiv.org/pdf/2508.00493v1>|引入光谱角度提示，提升 Segment Anything 模型在医学高光谱图像分割的准确性和鲁棒性。|
|🆕 发布|Advancing Welding Defect Detection in Maritime Operations via Adapt-WeldNet and Defect Detection Interpretability Analysis|通过Adapt-WeldNet和缺陷检测可解释性分析提升海上作业焊接缺陷检测|Kamal Basha S, Athira Nambiar|<http://arxiv.org/pdf/2508.00381v1>|提出自适应框架Adapt-WeldNet优化焊接缺陷检测，并通过Defect Detection I...|
|📝 更新|TopoRec: Point Cloud Recognition Using Topological Data Analysis|拓扑识别：利用拓扑数据分析的点云识别|Anirban Ghosh, Iliya Kulbaka, Ian Dahlin, Ayan Dutta|<http://arxiv.org/pdf/2506.18725v2>|提出TopoRec方法，利用拓扑数据分析提取点云局部描述符，无需大量训练即可实现高效的对象/场景识别...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Querying Autonomous Vehicle Point Clouds: Enhanced by 3D Object Counting with CounterNet|查询自动驾驶车辆点云：通过CounterNet增强的3D目标计数|Xiaoyu Zhang, Zhifeng Bao, Hai Dong, Ziwei Wang, Jiajun Liu|<http://arxiv.org/pdf/2507.19209v2>|提出CounterNet网络，通过检测对象中心提高点云数据中的对象计数精度，增强自动驾驶车辆点云查询...|
|🆕 发布|Leveraging Convolutional and Graph Networks for an Unsupervised Remote Sensing Labelling Tool|利用卷积网络和图网络的无监督遥感标注工具|Tulsi Patel, Mark W. Jones, Thomas Redfern|<http://arxiv.org/pdf/2508.00506v1>|提出了一种无监督的遥感图像标记工具，利用卷积和图神经网络进行图像分割和特征编码，无需预标记数据即可准...|
|📝 更新|Spatial-Temporal-Spectral Unified Modeling for Remote Sensing Dense Prediction|遥感密集预测的空间-时间-光谱统一建模|Sijie Zhao, Feng Liu, Enzhuo Zhang, Yiqing Guo, Pengfeng Xiao, Lei Bai, Xueliang Zhang, Hao Chen|<http://arxiv.org/pdf/2505.12280v3>|提出了一种统一的远程感知密集预测模型，能够灵活适应多源数据的时空谱异质性并统一多种预测任务。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Controllable Pedestrian Video Editing for Multi-View Driving Scenarios via Motion Sequence|通过运动序列实现多视角驾驶场景下的可控行人视频编辑|Danzhen Fu, Jiagao Hu, Daiguo Zhou, Fei Wang, Zepeng Wang, Wenhua Liao|<http://arxiv.org/pdf/2508.00299v1>|提出了一种多视角行人视频编辑框架，通过整合视频修复和人体运动控制技术，增强了自动驾驶系统对危险行人场...|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Privacy-Preserving Driver Drowsiness Detection with Spatial Self-Attention and Federated Learning|隐私保护的基于空间自注意力和联邦学习的驾驶员疲劳检测|Tran Viet Khoa, Do Hai Son, Mohammad Abu Alsheikh, Yibeltal F Alem, Dinh Thai Hoang|<http://arxiv.org/pdf/2508.00287v1>|提出了一种结合空间自注意力和联邦学习的隐私保护驾驶员疲劳检测框架，提高了检测准确性和模型鲁棒性。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Higher Effective Rank in Parameter-efficient Fine-tuning using Khatri--Rao Product|面向使用Khatri-Rao乘积的高效参数微调中有效秩的提升|Paul Albert, Frederic Z. Zhang, Hemanth Saratchandran, Anton van den Hengel, Ehsan Abbasnejad|<http://arxiv.org/pdf/2508.00230v1>|提出KRAdapter算法，通过Khatri-Rao积提升参数高效微调的有效秩，增强大型模型在多模态...|
|🆕 发布|CoST: Efficient Collaborative Perception From Unified Spatiotemporal Perspective|统一时空视角下的高效协同感知：CoST|Zongheng Tang, Yi Liu, Yifan Sun, Yulu Gao, Jinyu Chen, Runsheng Xu, Si Liu|<http://arxiv.org/pdf/2508.00359v1>|提出了一种统一时空视角的协作感知方法CoST，通过同时聚合多智能体和多时间观测，提升了效率和感知准确...|
|🆕 发布|Rethinking Backbone Design for Lightweight 3D Object Detection in LiDAR|重新思考轻量级激光雷达三维目标检测中的主干网络设计|Adwait Chandorkar, Hasan Tercan, Tobias Meisen|<http://arxiv.org/pdf/2508.00744v1>|提出轻量级Dense Backbone，用于3D物体检测，降低计算复杂度同时保持准确度。|
|🆕 发布|Uncertainty-Aware Likelihood Ratio Estimation for Pixel-Wise Out-of-Distribution Detection|像素级异常检测的不确定性感知似然比估计|Marc Hölle, Walter Kellermann, Vasileios Belagiannis|<http://arxiv.org/pdf/2508.00587v1>|[代码](https://github.com/glasbruch/ULRE.); 提出了一种考虑不确定性的像素级异常检测方法，有效区分已知与未知对象并降低误报率。|

