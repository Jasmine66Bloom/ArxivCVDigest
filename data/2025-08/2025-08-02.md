## [UPDATED!] **2025-08-02** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EfficientGFormer: Multimodal Brain Tumor Segmentation via Pruned Graph-Augmented Transformer|高效Gformer：通过剪枝图增强变换器的多模态脑肿瘤分割|Fatemeh Ziaeetabar|<http://arxiv.org/pdf/2508.01465v1>|提出EfficientGFormer，结合图推理和轻量级机制，实现高效准确的3D脑肿瘤分割。|
|📝 更新|Segment Any Architectural Facades (SAAF):An automatic segmentation model for building facades, walls and windows based on multimodal semantics guidance|任意建筑立面的分割（SAAF）：一种基于多模态语义引导的建筑立面、墙体和窗户自动分割模型|Peilin Li, Jun Yin, Jing Zhong, Ran Luo, Pengyu Zeng, Miao Zhang|<http://arxiv.org/pdf/2506.09071v2>|提出了一种基于多模态语义引导的建筑立面自动分割模型SAAF，提高了墙窗分割的准确性和泛化能力。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|TKG-DM: Training-free Chroma Key Content Generation Diffusion Model|无训练色彩键内容生成扩散模型（TKG-DM）|Ryugo Morita, Stanislav Frolov, Brian Bernhard Moser, Takahiro Shirakawa, Ko Watanabe, Andreas Dengel, Jinjia Zhou|<http://arxiv.org/pdf/2411.15580v3>|提出了一种无需训练的扩散模型，通过优化初始随机噪声实现前景物体与指定颜色背景的精确分离。|
|📝 更新|Safety at Scale: A Comprehensive Survey of Large Model and Agent Safety|大规模安全性：大型模型与智能体安全性的全面调研|Xingjun Ma, Yifeng Gao, Yixu Wang, Ruofan Wang, Xin Wang, Ye Sun, Yifan Ding, Hengyuan Xu .etc.|<http://arxiv.org/pdf/2502.05206v5>|系统梳理大型模型安全性威胁及防御策略，强调全面安全评估和国际合作的重要性。|
|🆕 发布|Predicting EGFR Mutation in LUAD from Histopathological Whole-Slide Images Using Pretrained Foundation Model and Transfer Learning: An Indian Cohort Study|利用预训练基础模型和迁移学习从LUAD组织病理学全切片图像预测EGFR突变：一项印度队列研究|Sagar Singh Gwal, Rajan, Suyash Devgan, Shraddhanjali Satapathy, Abhishek Goyal, Nuruddin Mohammad Iqbal, Vivaan Jain, Prabhat Singh Mallik .etc.|<http://arxiv.org/pdf/2508.01352v1>|定位EGFR突变状态，本研究提出基于视觉变换器和多实例学习的深度学习框架，实现高效准确预测。|
|📝 更新|PRIMAL: Physically Reactive and Interactive Motor Model for Avatar Learning|“PRIMAL：用于虚拟角色学习的物理响应与交互式运动模型”|Yan Zhang, Yao Feng, Alpár Cseke, Nitin Saini, Nathan Bajandas, Nicolas Heron, Michael J. Black|<http://arxiv.org/pdf/2503.17544v2>|[代码](https://yz-cnsdqz.github.io/eigenmotion); 提出PRIMAL模型，通过预训练和适应阶段实现虚拟角色动作的自然生成与实时响应。|
|🆕 发布|Mitigating Information Loss under High Pruning Rates for Efficient Large Vision Language Models|在高剪枝率下减轻信息损失以实现高效大型视觉语言模型|Mingyu Fu, Wei Suo, Ji Ma, Lin Yuanbo Wu, Peng Wang, Yanning Zhang|<http://arxiv.org/pdf/2508.01236v1>|提出自适应内容补偿方法，通过图像描述减少高效大型视觉语言模型在高剪枝率下的信息损失。|
|🆕 发布|Point-wise Diffusion Models for Physical Systems with Shape Variations: Application to Spatio-temporal and Large-scale system|点扩散模型用于具有形状变化的物理系统：应用于时空和大尺度系统|Jiyong Kim, Sunwoong Yang, Namwoo Kang|<http://arxiv.org/pdf/2508.01230v1>|提出了一种点级扩散模型，独立处理时空点以高效预测形状变化的复杂物理系统，大幅提升了预测速度和准确度。|
|🆕 发布|RoadMamba: A Dual Branch Visual State Space Model for Road Surface Classification|RoadMamba：一种用于道路表面分类的双分支视觉状态空间模型|Tianze Wang, Zhang Zhang, Chao Yue, Nuoran Li, Chao Sun|<http://arxiv.org/pdf/2508.01210v1>|提出RoadMamba方法，结合全局感知与局部纹理提取，提升道路表面分类性能。|
|🆕 发布|UniEgoMotion: A Unified Model for Egocentric Motion Reconstruction, Forecasting, and Generation|《UniEgoMotion：一种用于自我中心运动重建、预测和生成的统一模型》|Chaitanya Patel, Hiroki Nakamura, Yuta Kyuragi, Kazuki Kozuka, Juan Carlos Niebles, Ehsan Adeli|<http://arxiv.org/pdf/2508.01126v1>|提出UniEgoMotion模型，通过提取第一视角图像的场景语义实现自我运动重建、预测与生成。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multimodal Attention-Aware Fusion for Diagnosing Distal Myopathy: Evaluating Model Interpretability and Clinician Trust|多模态注意力感知融合技术在诊断远端肌病中的应用：评估模型可解释性与临床医生信任度|Mohsen Abbaspour Onari, Lucie Charlotte Magister, Yaoxin Wu, Amalia Lupi, Dario Creazzo, Mattia Tordin, Luigi Di Donatantonio, Emilio Quaia .etc.|<http://arxiv.org/pdf/2508.01316v1>|提出了一种多模态注意力感知融合架构，结合全局和局部特征，通过注意力门机制提升诊断准确性和解释性。|
|📝 更新|MCA-Bench: A Multimodal Benchmark for Evaluating CAPTCHA Robustness Against VLM-based Attacks|MCA-Bench：一种用于评估基于VLM攻击的验证码鲁棒性的多模态基准|Zonglin Wu, Yule Xue, Xin Wei, Yiren Song|<http://arxiv.org/pdf/2506.05982v3>|提出了MCA-Bench，一个统一的多模态评测基准，用于评估验证码在基于视觉语言模型的攻击下的安全性...|
|📝 更新|Scaling Laws for Native Multimodal Models|《原生多模态模型的缩放规律》|Mustafa Shukor, Enrico Fini, Victor Guilherme Turrisi da Costa, Matthieu Cord, Joshua Susskind, Alaaeldin El-Nouby|<http://arxiv.org/pdf/2504.07951v3>|发现早期融合架构在参数较少时性能更强，且训练更高效，易于部署。|
|🆕 发布|Self-Enhanced Image Clustering with Cross-Modal Semantic Consistency|跨模态语义一致性驱动的自增强图像聚类|Zihan Li, Wei Sun, Jing Hu, Jianhua Yin, Jianlong Wu, Liqiang Nie|<http://arxiv.org/pdf/2508.01254v1>|提出了一种结合跨模态语义一致性的自增强图像聚类框架，大幅提升了聚类性能。|
|📝 更新|AtomThink: Multimodal Slow Thinking with Atomic Step Reasoning|原子思考：基于原子步骤推理的多模态慢思考|Kun Xiang, Zhili Liu, Terry Jingchen Zhang, Yinya Huang, Yunshuang Nie, Kaixin Cai, Yiyang Yin, Runhui Huang .etc.|<http://arxiv.org/pdf/2411.11930v4>|[代码](https://github.com/Quinn777/AtomThink.); 引入“慢思考”理念，提出Self-structured Chain of Thought方法，提升多...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MoKD: Multi-Task Optimization for Knowledge Distillation|多任务优化用于知识蒸馏的MoKD|Zeeshan Hayder, Ali Cheraghian, Lars Petersson, Mehrtash Harandi|<http://arxiv.org/pdf/2505.08170v2>|提出MoKD方法，通过多任务优化解决知识蒸馏中的梯度冲突和梯度主导问题，提升模型效率和性能。|
|🆕 发布|A Full-Stage Refined Proposal Algorithm for Suppressing False Positives in Two-Stage CNN-Based Detection Methods|两阶段卷积神经网络检测方法中抑制假阳性的全阶段细化提案算法|Qiang Guo, Rubo Zhang, Bingbing Zhang, Junjie Liu, Jianqing Liu|<http://arxiv.org/pdf/2508.01382v1>|提出了一种全阶段精炼提案算法，有效抑制了两阶段卷积神经网络行人检测中的误报问题。|
|📝 更新|OmniPose6D: Towards Short-Term Object Pose Tracking in Dynamic Scenes from Monocular RGB|OmniPose6D：面向单目RGB在动态场景中的短期目标姿态跟踪|Yunzhi Lin, Yipu Zhao, Fu-Jen Chu, Xingyu Chen, Weiyao Wang, Hao Tang, Patricio A. Vela, Matt Feiszli .etc.|<http://arxiv.org/pdf/2410.06694v2>|提出OmniPose6D方法，通过合成数据集和不确定性关键点精炼网络，提升动态场景中短期物体姿态跟踪...|
|🆕 发布|SWAN: Synergistic Wavelet-Attention Network for Infrared Small Target Detection|SWAN：红外小目标检测的协同小波-注意力网络|Yuxin Jing, Jufeng Zhao, Tianpei Zhang, Yiming Zhu|<http://arxiv.org/pdf/2508.01322v1>|提出SWAN网络，融合频域和空域特征，提升红外小目标检测准确性和鲁棒性。|
|🆕 发布|C3D-AD: Toward Continual 3D Anomaly Detection via Kernel Attention with Learnable Advisor|面向连续三维异常检测的基于可学习顾问的核注意力C3D-AD方法|Haoquan Lu, Hanzhe Liang, Jie Zhang, Chenxi Hu, Jinbao Wang, Can Gao|<http://arxiv.org/pdf/2508.01311v1>|提出了一种持续学习框架C3D-AD，通过核注意力机制有效处理多类别点云数据并适应新类别出现。|
|📝 更新|IV-tuning: Parameter-Efficient Transfer Learning for Infrared-Visible Tasks|IV-tuning：面向红外-可见光任务的参数高效迁移学习|Yaming Zhang, Chenqiang Gao, Fangcen Liu, Junjie Guo, Lan Wang, Xinggan Peng, Deyu Meng|<http://arxiv.org/pdf/2412.16654v3>|[代码](https://github.com/Yummy198913/IV-tuning.); 提出IV-tuning方法，通过高效参数利用改善红外与可见光任务学习，减少过拟合。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spatial-Frequency Aware for Object Detection in RAW Image|空间频率感知的RAW图像目标检测|Zhuohua Ye, Liming Zhang, Hongru Han|<http://arxiv.org/pdf/2508.01396v1>|提出空间频率感知框架SFAE，融合空间与频率域特征，增强RAW图像物体检测细节。|
|🆕 发布|ODOV: Towards Open-Domain Open-Vocabulary Object Detection|面向开放域开放词汇的对象检测：ODOV|Yupeng Zhang, Ruize Han, Fangnan Zhou, Song Wang, Wei Feng, Liang Wan|<http://arxiv.org/pdf/2508.01253v1>|提出了一种面向开放域开放词汇的对象检测方法，通过结合语言模型和图像嵌入应对现实世界中的变化。|
|🆕 发布|OpenGS-Fusion: Open-Vocabulary Dense Mapping with Hybrid 3D Gaussian Splatting for Refined Object-Level Understanding|OpenGS-Fusion：基于混合三维高斯散点绘制的开词汇密集映射以提高对象级理解精度|Dianyi Yang, Xihan Wang, Yu Gao, Shiyang Liu, Bohan Ren, Yufeng Yue, Yi Yang|<http://arxiv.org/pdf/2508.01150v1>|[代码](https://young-bit.github.io/opengs-fusion.github.io); 提出OpenGS-Fusion框架，融合3D高斯表示与语言指导策略，提升开放词汇密集建图和对象级理解...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Object Affordance Recognition and Grounding via Multi-scale Cross-modal Representation Learning|通过多尺度跨模态表征学习进行物体可用性识别与定位|Xinhang Wan, Dongqiang Gou, Xinwang Liu, En Zhu, Xuming He|<http://arxiv.org/pdf/2508.01184v1>|提出了一种结合多尺度跨模态表征学习的三维对象可用性识别与定位方法，有效耦合了定位与分类任务，提高了可...|
|📝 更新|Rectifying Magnitude Neglect in Linear Attention|线性注意力中矫正幅度忽视|Qihang Fan, Huaibo Huang, Yuang Ai, Ran He|<http://arxiv.org/pdf/2507.00698v3>|[代码](https://github.com/qhfan/MALA); 提出方法解决线性注意力忽视查询向量大小问题，提出 Magnitude-Aware Linear At...|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Progressive Growing of Video Tokenizers for Temporally Compact Latent Spaces|视频标记器的渐进生长以实现时间紧凑的潜在空间|Aniruddha Mahapatra, Long Mai, David Bourgin, Yitian Zhang, Feng Liu|<http://arxiv.org/pdf/2501.05442v2>|提出了一种分阶段训练的高时空压缩视频编码方法，显著提升了视频重建质量并减少了训练所需的代币数量。|
|🆕 发布|Can3Tok: Canonical 3D Tokenization and Latent Modeling of Scene-Level 3D Gaussians|Can3Tok：规范三维标记化与场景级三维高斯分布的潜在建模|Quankai Gao, Iliyan Georgiev, Tuanfeng Y. Wang, Krishna Kumar Singh, Ulrich Neumann, Jae Shin Yoon|<http://arxiv.org/pdf/2508.01464v1>|提出了一种首个能够对大规模3D场景数据进行编码的VAE模型，有效解决了3D场景生成中的尺度不一致性问...|
|📝 更新|$I^{2}$-World: Intra-Inter Tokenization for Efficient Dynamic 4D Scene Forecasting|$I^{2}$-世界：内外部符号化用于高效动态四维场景预测|Zhimin Liao, Ping Wei, Ruijie Zhang, Shuaijia Chen, Haoxuan Wang, Ziyang Ren|<http://arxiv.org/pdf/2507.09144v2>|[代码](https://github.com/lzzzzzm/II-World.); 提出$I^{2}$-World框架，通过分离内外场景的编码方式，高效预测四维场景的动态变化。|
|📝 更新|VoiceCloak: A Multi-Dimensional Defense Framework against Unauthorized Diffusion-based Voice Cloning|《VoiceCloak：一种针对未授权扩散型声音克隆的多维度防御框架》|Qianyue Hu, Junyan Wu, Wei Lu, Xiangyang Luo|<http://arxiv.org/pdf/2505.12332v3>|[代码](https://voice-cloak.github.io/VoiceCloak); 提出了VoiceCloak框架，通过多维防御策略有效对抗基于扩散模型的非法语音克隆。|
|🆕 发布|Effective Damage Data Generation by Fusing Imagery with Human Knowledge Using Vision-Language Models|利用视觉语言模型融合图像与人类知识进行有效损伤数据生成|Jie Wei, Erika Ardiles-Cruz, Aleksey Panasyuk, Erik Blasch|<http://arxiv.org/pdf/2508.01380v1>|利用视觉语言模型融合图像与人类知识，有效生成多样化损坏数据以提升灾后损害评估准确率。|
|🆕 发布|Zero-shot Segmentation of Skin Conditions: Erythema with Edit-Friendly Inversion|零样本皮肤状况分割：带有编辑友好逆向的红斑分割|Konstantinos Moutselos, Ilias Maglogiannis|<http://arxiv.org/pdf/2508.01334v1>|提出了一种无需标注数据，利用生成编辑和颜色空间分析的零样本皮肤病症分割方法。|
|🆕 发布|CoCoLIT: ControlNet-Conditioned Latent Image Translation for MRI to Amyloid PET Synthesis|CoCoLIT：基于ControlNet条件的潜在图像转换用于MRI到淀粉样PET合成|Alec Sargood, Lemuel Puglisi, James H. Cole, Neil P. Oxtoby, Daniele Ravì, Daniel C. Alexander|<http://arxiv.org/pdf/2508.01292v1>|[代码](https://github.com/brAIn-science/CoCoLIT.); 提出CoCoLIT方法，通过控制网络和改进的生成框架实现MRI到PET的高效转换，显著提升阿尔茨海默...|
|🆕 发布|MeshLLM: Empowering Large Language Models to Progressively Understand and Generate 3D Mesh|《MeshLLM：赋予大型语言模型逐步理解和生成三维网格的能力》|Shuangkang Fang, I-Chao Shen, Yufeng Wang, Yi-Hsuan Tsai, Yi Yang, Shuchang Zhou, Wenrui Ding, Takeo Igarashi .etc.|<http://arxiv.org/pdf/2508.01242v1>|提出MeshLLM框架，利用大型语言模型理解和生成3D网格，通过分解策略和训练方法提升模型性能。|
|📝 更新|Joint Generative Modeling of Grounded Scene Graphs and Images via Diffusion Models|通过扩散模型对 grounded 场景图和图像的联合生成建模|Bicheng Xu, Qi Yan, Renjie Liao, Lele Wang, Leonid Sigal|<http://arxiv.org/pdf/2401.01130v2>|提出了一种基于扩散模型的方法，有效生成场景图和图像，提升了场景图生成性能并增强了下游任务表现。|
|📝 更新|Early Timestep Zero-Shot Candidate Selection for Instruction-Guided Image Editing|早期时间步零样本候选选择用于指令引导的图像编辑|Joowon Kim, Ziseok Lee, Donghyeon Cho, Sanghyun Jo, Yeonsung Jung, Kyungsu Kim, Eunho Yang|<http://arxiv.org/pdf/2504.13490v2>|提出了一种无需监督的零样本框架ELECT，通过早期步骤评估背景一致性来选择可靠种子，提升指令引导图像...|
|📝 更新|LACONIC: A 3D Layout Adapter for Controllable Image Creation|“LACONIC：一种用于可控图像生成的三维布局适配器”|Léopold Maillard, Tom Durand, Adrien Ramanana Rahary, Maks Ovsjanikov|<http://arxiv.org/pdf/2507.03257v2>|提出了一种3D布局适配器，使文本到图像模型具备三维感知能力，实现场景中物体位置和形态的精确控制。|
|🆕 发布|LawDIS: Language-Window-based Controllable Dichotomous Image Segmentation|基于语言窗口的可控二值图像分割方法LawDIS|Xinyu Yan, Meijun Sun, Ge-Peng Ji, Fahad Shahbaz Khan, Salman Khan, Deng-Ping Fan|<http://arxiv.org/pdf/2508.01152v1>|[代码](https://github.com/XinyuYanTJU/LawDIS.); 提出了一种语言和窗口联合控制的二值图像分割框架，实现了高质量对象遮罩的生成与精确调整。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Describe Anything Model for Visual Question Answering on Text-rich Images|用于丰富文本图像的视觉问答的“描述任意事物”模型|Yen-Linh Vu, Dinh-Thang Duong, Truong-Binh Duong, Anh-Khoi Nguyen, Thanh-Huy Nguyen, Le Thien Phuc Nguyen, Jianhua Xing, Xingjian Li .etc.|<http://arxiv.org/pdf/2507.12441v2>|[代码](https://github.com/Linvyl/DAM-QA.git.); 提出DAM-QA框架，利用区域感知能力提升文本丰富图像的视觉问答性能。|
|🆕 发布|PromptSafe: Gated Prompt Tuning for Safe Text-to-Image Generation|PromptSafe：安全文本到图像生成的门控提示微调|Zonglei Jing, Xiao Yang, Xiaoqian Li, Siyuan Liang, Aishan Liu, Mingchuan Zhang, Xianglong Liu|<http://arxiv.org/pdf/2508.01272v1>|PromptSafe通过轻量级文本嵌入和自适应门控机制，有效避免了文本到图像生成中的不安全内容，同时...|
|📝 更新|Voyaging into Perpetual Dynamic Scenes from a Single View|《从单一视角探索永恒动态场景》|Fengrui Tian, Tianjiao Ding, Jinqi Luo, Hancheng Min, René Vidal|<http://arxiv.org/pdf/2507.04183v2>|[代码](https://tianfr.github.io/DynamicVoyager.); 提出了一种从单视角生成持续动态场景的方法，通过将3D运动信息融入2D像素，实现了3D一致的动态场景生...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Action2Dialogue: Generating Character-Centric Narratives from Scene-Level Prompts|《Action2Dialogue：从场景级提示生成以角色为中心的叙事》|Taewon Kang, Ming C. Lin|<http://arxiv.org/pdf/2505.16819v2>|提出了一种将动作提示转化为具有情感和角色一致性的视觉和听觉叙事对话的模块化流程。|
|📝 更新|Text2Story: Advancing Video Storytelling with Text Guidance|《文本引导下的视频故事讲述进展：Text2Story》|Taewon Kang, Divya Kothandaraman, Ming C. Lin|<http://arxiv.org/pdf/2503.06310v2>|提出了一种AI驱动的框架，通过文本引导生成具有自然动作过渡和结构化叙事的长视频序列。|
|📝 更新|LAVA: Language Driven Scalable and Versatile Traffic Video Analytics|LAVA：语言驱动的可扩展与多功能的交通视频分析系统|Yanrui Yu, Tianfei Zhou, Jiaxin Sun, Lianpeng Qiao, Lizhong Ding, Ye Yuan, Guoren Wang|<http://arxiv.org/pdf/2507.19821v2>|[代码](https://github.com/yuyanrui/LAVA.); 提出了一种基于自然语言驱动的视频分析系统LAVA，实现了对大规模交通视频数据的高效和灵活查询。|
|🆕 发布|Domain Generalized Stereo Matching with Uncertainty-guided Data Augmentation|基于不确定性指导的数据增强的域泛化立体匹配|Shuangli Du, Jing Wang, Minghua Zhao, Zhenyu Xu, Jie Li|<http://arxiv.org/pdf/2508.01303v1>|提出了一种基于不确定性的数据增强方法，有效提升了立体匹配模型在不同数据域间的泛化性能。|
|📝 更新|UltraVSR: Achieving Ultra-Realistic Video Super-Resolution with Efficient One-Step Diffusion Space|超分辨率视频超真实还原：通过高效单步扩散空间实现|Yong Liu, Jinshan Pan, Yinchuan Li, Qingji Dong, Chao Zhu, Yu Guo, Fei Wang|<http://arxiv.org/pdf/2505.19958v2>|[代码](https://github.com/yongliuy/UltraVSR.); 提出了一种高效的单一步骤扩散空间框架UltraVSR，通过感知退化的重建调度和时间异步推理，实现了超...|
|📝 更新|MoGA: 3D Generative Avatar Prior for Monocular Gaussian Avatar Reconstruction|单目高斯虚拟人重建的3D生成虚拟人先验MoGA|Zijian Dong, Longteng Duan, Jie Song, Michael J. Black, Andreas Geiger|<http://arxiv.org/pdf/2507.23597v2>|提出了一种利用3D生成模型和2D扩散模型结合的方法，实现了从单视角图像重建高质量3D虚拟形象。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DiffSSC: Semantic LiDAR Scan Completion using Denoising Diffusion Probabilistic Models|差分语义激光雷达扫描补全：基于去噪扩散概率模型的方法|Helin Cao, Sven Behnke|<http://arxiv.org/pdf/2409.18092v3>|提出利用去噪扩散概率模型完成LiDAR扫描的语义补全，实现场景表示的完整性并达到最佳性能。|
|🆕 发布|ForenX: Towards Explainable AI-Generated Image Detection with Multimodal Large Language Models|ForenX：面向可解释的AI生成图像检测的多模态大型语言模型|Chuangchuang Tan, Jinglu Wang, Xiang Ming, Renshuai Tao, Yunchao Wei, Yao Zhao, Yan Lu|<http://arxiv.org/pdf/2508.01402v1>|ForenX利用大型多模态语言模型分析图像并提供类似人类思维的解释，以检测并解释AI生成图像的真伪。|
|📝 更新|Multi-Object Sketch Animation by Scene Decomposition and Motion Planning|通过场景分解和运动规划实现的多目标草图动画|Jingyu Liu, Zijie Xin, Yuhan Fu, Ruixiang Zhao, Bangxiang Lan, Xirong Li|<http://arxiv.org/pdf/2503.19351v2>|提出了一种基于迭代优化的MoSketch方法，实现了无需训练数据的多人对象草图动画生成。|
|🆕 发布|StyleSentinel: Reliable Artistic Copyright Verification via Stylistic Fingerprints|风格哨兵：通过风格指纹进行可靠的艺术版权验证|Lingxiao Chen, Liqin Wang, Wei Lu|<http://arxiv.org/pdf/2508.01335v1>|提出StyleSentinel方法，通过验证艺术作品中的固有风格指纹进行版权保护，提高了 artwo...|
|📝 更新|Anti-Inpainting: A Proactive Defense Approach against Malicious Diffusion-based Inpainters under Unknown Conditions|反修复：一种在未知条件下针对恶意扩散基于修复器的主动防御方法|Yimao Guo, Zuomin Qu, Wei Lu, Xiangyang Luo|<http://arxiv.org/pdf/2505.13023v3>|提出了一种针对未知条件下扩散基于恶意图像篡改的主动防御方法Anti-Inpainting，通过多级特...|
|📝 更新|Safeguarding Vision-Language Models: Mitigating Vulnerabilities to Gaussian Noise in Perturbation-based Attacks|确保视觉-语言模型的安全性：基于扰动攻击中减轻高斯噪声的脆弱性|Jiawei Wang, Yushen Zuo, Yuanjun Chai, Zhendong Liu, Yicheng Fu, Yichun Feng, Kin-Man Lam|<http://arxiv.org/pdf/2504.01308v3>|[代码](https://github.com/JarvisUSTC/DiffPure-RobustVLM.); 提出方法增强视觉语言模型对高斯噪声攻击的鲁棒性，通过噪声增广数据集和扩散模型优化防御策略。|
|🆕 发布|SGCap: Decoding Semantic Group for Zero-shot Video Captioning|SGCap: 零样本视频标注的语义组解码|Zeyu Pan, Ping Li, Wenxiao Wang|<http://arxiv.org/pdf/2508.01270v1>|[代码](https://github.com/mlvccn/SGCap_Video.); 提出SGCap方法，通过多帧信息建模和句子组策略，实现零样本视频字幕生成。|
|🆕 发布|Enhancing Diffusion-based Dataset Distillation via Adversary-Guided Curriculum Sampling|通过对抗引导的 curriculum 采样增强基于扩散的数据集蒸馏|Lexiao Zou, Gongwei Chen, Yanda Chen, Miao Zhang|<http://arxiv.org/pdf/2508.01264v1>|提出Adversary-guided Curriculum Sampling方法，通过对抗训练和分阶...|
|📝 更新|Democratizing Text-to-Image Masked Generative Models with Compact Text-Aware One-Dimensional Tokens|用紧凑的文本感知一维标记普及文本到图像遮罩生成模型|Dongwon Kim, Ju He, Qihang Yu, Chenglin Yang, Xiaohui Shen, Suha Kwak, Liang-Chieh Chen|<http://arxiv.org/pdf/2501.07730v2>|提出了一种高效的文本感知一维图像标记器TA-TiTok，简化训练过程并实现了开放数据训练的文本到图像...|
|🆕 发布|StyDeco: Unsupervised Style Transfer with Distilling Priors and Semantic Decoupling|《StyDeco：基于蒸馏先验和语义解耦的无监督风格迁移》|Yuanlin Yang, Quanjian Song, Zhexian Gao, Ge Wang, Shanshan Li, Xiaoyan Zhang|<http://arxiv.org/pdf/2508.01215v1>|[代码](https://github.com/QuanjianSong/StyDeco.); StyDeco通过学习定制化文本表示和采用无监督知识蒸馏与对比语义解耦策略，有效提升了风格迁移中的语...|
|🆕 发布|Personalized Safety Alignment for Text-to-Image Diffusion Models|个性化安全对齐的文本到图像扩散模型|Yu Lei, Jinbin Bai, Qingyu Shi, Aosong Feng, Kaidong Yu|<http://arxiv.org/pdf/2508.01151v1>|[代码](https://torpedo2648.github.io/PSAlign); 提出个性化安全对齐框架，根据用户偏好调整生成模型，有效抑制有害内容。|
|📝 更新|$\textit{Revelio}$: Interpreting and leveraging semantic information in diffusion models|《Revelio》：在扩散模型中解释和利用语义信息|Dahye Kim, Xavier Thomas, Deepti Ghadiyaram|<http://arxiv.org/pdf/2411.16725v3>|[代码](https://github.com/revelio-diffusion/revelio); 揭示了扩散模型中视觉语义信息的分布，并利用k稀疏自动编码器提取可解释特征以增强表征学习效果。|
|🆕 发布|Dataset Condensation with Color Compensation|数据集浓缩与颜色补偿|Huyu Wu, Duo Su, Junjie Hou, Guang Li|<http://arxiv.org/pdf/2508.01139v1>|提出颜色补偿的图像压缩方法DC3，提升数据集压缩效率和图像质量。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VAEmo: Efficient Representation Learning for Visual-Audio Emotion with Knowledge Injection|VAEmo：基于知识注入的视觉-音频情感高效表征学习|Hao Cheng, Zhiwei Zhao, Yichao He, Zhenzhen Hu, Jia Li, Meng Wang, Richang Hong|<http://arxiv.org/pdf/2505.02331v2>|VAEmo通过统一轻量级网络和知识注入，有效提升了视觉音频情感识别的细粒度语义建模。|
|📝 更新|pySLAM: An Open-Source, Modular, and Extensible Framework for SLAM|pySLAM：一个开源、模块化、可扩展的SLAM框架|Luigi Freda|<http://arxiv.org/pdf/2502.11955v3>|pySLAM是一个开源、模块化、可扩展的视觉SLAM框架，支持多种相机输入，整合了传统与深度学习方法...|
|🆕 发布|ReMu: Reconstructing Multi-layer 3D Clothed Human from Image Layers|ReMu：从图像层重建多层三维着装人体|Onat Vuran, Hsuan-I Ho|<http://arxiv.org/pdf/2508.01381v1>|[代码](https://eth-ait.github.io/ReMu); 提出了一种单 RGB 相机捕获的图像层设置下重建多层 3D 衣物的无模板、通用方法。|
|🆕 发布|SpatioTemporal Difference Network for Video Depth Super-Resolution|视频深度超分辨率的空间时间差分网络|Zhengxue Wang, Yuan Wu, Xiang Li, Zhiqiang Yan, Jian Yang|<http://arxiv.org/pdf/2508.01259v1>|提出了一种SpatioTemporal Difference Network，通过空间和时间差异分支...|
|📝 更新|SpINRv2: Implicit Neural Representation for Passband FMCW Radars|SpINRv2：用于通带调频连续波雷达的隐式神经表示|Harshvardhan Takawale, Nirupam Roy|<http://arxiv.org/pdf/2506.08163v2>|提出了一种用于高保真度体积重建的神经框架SpINRv2，通过频率域的闭合形式合成和隐式神经表示，解决...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|3DRot: 3D Rotation Augmentation for RGB-Based 3D Tasks|三维旋转增强：基于RGB的三维任务中的三维旋转增强|Shitian Yang, Deyu Li, Xiaoke Jiang, Lei Zhang|<http://arxiv.org/pdf/2508.01423v1>|提出了3DRot方法，通过保持几何一致性旋转和反射图像，有效提升了RGB-based 3D任务的性能...|
|📝 更新|GS-Occ3D: Scaling Vision-only Occupancy Reconstruction with Gaussian Splatting|GS-Occ3D：使用高斯散点绘制扩展仅视觉占用重建|Baijun Ye, Minghui Qin, Saining Zhang, Moonjun Gong, Shaoting Zhu, Zebang Shen, Luan Zhang, Lu Zhang .etc.|<http://arxiv.org/pdf/2507.19451v3>|提出了一种无需激光雷达标注的视觉占用重建框架GS-Occ3D，通过高斯散点优化显式占用表示，实现高效...|
|🆕 发布|Integrating Disparity Confidence Estimation into Relative Depth Prior-Guided Unsupervised Stereo Matching|将深度置信度估计整合到相对深度先验引导的无监督立体匹配中|Chuang-Wei Liu, Mingjian Sun, Cairong Zhao, Hanli Wang, Alexander Dvorkovich, Rui Fan|<http://arxiv.org/pdf/2508.01275v1>|引入 disparity confidence 估算，提出深度先验引导的无监督立体匹配框架，提升匹配...|
|🆕 发布|MoGaFace: Momentum-Guided and Texture-Aware Gaussian Avatars for Consistent Facial Geometry|MoGaFace：动量引导与纹理感知的高斯化身，用于保持一致的面部几何结构|Yujian Liu, Linlang Cao, Chuang Chen, Fanyu Geng, Dongxu Shen, Peng Cao, Shidang Xu, Xiaoli Liu|<http://arxiv.org/pdf/2508.01218v1>|提出了一种持续优化面部几何和纹理属性的3D头像建模框架，通过引入动量引导和纹理感知机制，提高了渲染质...|
|📝 更新|Momentum-GS: Momentum Gaussian Self-Distillation for High-Quality Large Scene Reconstruction|动量-GS：动量高斯自蒸馏用于高质量大场景重建|Jixuan Fan, Wanhua Li, Yifei Han, Tianru Dai, Yansong Tang|<http://arxiv.org/pdf/2412.04887v2>|[代码](https://jixuan-fan.github.io/Momentum-GS_Page); 提出了一种基于动量自蒸馏的3D场景重建方法，通过保持全局一致性显著提升了重建质量并减少了所需的GPU...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Embracing Dynamics: Dynamics-aware 4D Gaussian Splatting SLAM|拥抱动态：动态感知的四维高斯散点SLAM|Zhicong Sun, Jacqueline Lo, Jinxing Hu|<http://arxiv.org/pdf/2504.04844v2>|提出首个基于四维高斯散点表示的SLAM方法，有效应对动态环境下的定位与建图挑战。|
|🆕 发布|A Coarse-to-Fine Approach to Multi-Modality 3D Occupancy Grounding|从粗到细的多模态三维占据定位方法|Zhan Shi, Song Wang, Junbo Chen, Jianke Zhu|<http://arxiv.org/pdf/2508.01197v1>|[代码](https://github.com/RONINGOD/GroundingOcc.); 提出了一种从粗到细的多模态学习方法，通过结合视觉、文本和点云特征，实现了更精确的3D空间对象定位与占...|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Predicting Video Slot Attention Queries from Random Slot-Feature Pairs|从随机槽-特征对预测视频槽注意力查询|Rongzhen Zhao, Jian Li, Juho Kannala, Joni Pajarinen|<http://arxiv.org/pdf/2508.01345v1>|提出新方法RandSF.Q，利用随机槽特征对预测视频注意力查询，学习过渡动力学，提升物体中心学习性能...|
|📝 更新|Associate Everything Detected: Facilitating Tracking-by-Detection to the Unknown|将未知关联起来：使检测跟踪扩展到未知对象|Zimeng Fang, Chao Liang, Xue Zhou, Shuyuan Zhu, Xi Li|<http://arxiv.org/pdf/2409.09293v2>|[代码](https://github.com/balabooooo/AED.); 提出了一种统一框架AED，整合了CV-MOT与OV-MOT，通过特征学习处理复杂轨迹并跟踪未知类别。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VideoLLaMB: Long Streaming Video Understanding with Recurrent Memory Bridges|视频LLaMB：基于循环记忆桥的长时间流视频理解|Yuxuan Wang, Yiqi Song, Cihang Xie, Yang Liu, Zilong Zheng|<http://arxiv.org/pdf/2409.01071v2>|提出VideoLLaMB框架，通过循环记忆桥和时态记忆令牌高效理解长视频，实现性能与成本平衡。|
|🆕 发布|DELTAv2: Accelerating Dense 3D Tracking|DELTAv2：加速稠密三维跟踪|Tuan Duc Ngo, Ashkan Mirzaei, Guocheng Qian, Hanwen Liang, Chuang Gan, Evangelos Kalogerakis, Peter Wonka, Chaoyang Wang|<http://arxiv.org/pdf/2508.01170v1>|提出了一种加速密集三维点长期跟踪的新算法，通过粗到细策略和优化相关性特征计算降低计算成本。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TEACH: Text Encoding as Curriculum Hints for Scene Text Recognition|TEACH：将文本编码作为场景文本识别的课程提示|Xiahan Yang, Hui Zheng|<http://arxiv.org/pdf/2508.01153v1>|提出TEACH方法，通过将真实文本作为辅助输入并逐步减少其影响，提升场景文本识别准确性和鲁棒性。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SuPerPM: A Surgical Perception Framework Based on Deep Point Matching Learned from Physical Constrained Simulation Data|SuPerPM：基于物理约束模拟数据学习的深度点匹配手术感知框架|Shan Lin, Albert J. Miao, Ali Alabiad, Fei Liu, Kaiyuan Wang, Jingpei Lu, Florian Richter, Michael C. Yip|<http://arxiv.org/pdf/2309.13863v3>|提出了一种基于深度点匹配学习的手术感知框架SuPerPM，通过物理约束模拟数据训练，有效处理内镜下软...|
|🆕 发布|Hyperspectral Image Recovery Constrained by Multi-Granularity Non-Local Self-Similarity Priors|多粒度非局部自相似性先验约束下的高光谱图像恢复|Zhuoran Peng, Yiqing Shen|<http://arxiv.org/pdf/2508.01435v1>|首次引入粒度概念，提出一种基于多粒度非局部自相似性先验的 Hyperspectral 图像恢复模型。|
|📝 更新|A Comprohensive Review of Domain Adaptation Techniques for Agricultural Image Analysis in Precision Agriculture|《精准农业中农业图像分析领域自适应技术的全面回顾》|Xing Hu, Siyuan Chen, Xuming Huang, Qianqian Duan, LingKun Luo, Ruijiao Li, Huiliang Shang, Linhua Jiang .etc.|<http://arxiv.org/pdf/2506.05972v3>|系统总结了域自适应技术在精准农业图像分析中的应用，提升了模型在不同环境下的迁移性。|
|🆕 发布|SBP-YOLO:A Lightweight Real-Time Model for Detecting Speed Bumps and Potholes|SBP-YOLO：一种轻量级实时检测减速带和坑洞的模型|Chuanqi Liang, Jie Fu, Lei Luo, Miao Yu|<http://arxiv.org/pdf/2508.01339v1>|提出了一种基于YOLOv11的轻量级模型SBP-YOLO，用于实时检测道路上的减速带和坑洼，提高了检...|
|📝 更新|Spatial Transcriptomics Analysis of Spatially Dense Gene Expression Prediction|空间转录组学分析：空间密集基因表达预测|Ruikun Zhang, Yan Yang, Liyuan Pan|<http://arxiv.org/pdf/2503.01347v2>|提出 PixNet 网络直接从病理切片预测高分辨率基因表达图，优于传统方法。|
|🆕 发布|ModelNet40-E: An Uncertainty-Aware Benchmark for Point Cloud Classification|点云分类的不确定性感知基准ModelNet40-E|Pedro Alonso, Tianrui Li, Chongshou Li|<http://arxiv.org/pdf/2508.01269v1>|提出了ModelNet40-E基准，通过提供噪声污染的点云和不确定性标注，评估了点云分类模型在噪声下...|
|📝 更新|GLDesigner: Leveraging Multi-Modal LLMs as Designer for Enhanced Aesthetic Text Glyph Layouts|GLDesigner：利用多模态大型语言模型作为设计师以增强审美文本符号布局|Junwen He, Yifan Wang, Lijun Wang, Huchuan Lu, Jun-Yan He, Chenyang Li, Hanyuan Chen, Jin-Peng Lan .etc.|<http://arxiv.org/pdf/2411.11435v2>|提出了一种基于视觉语言模型的框架，通过结合多模态输入和用户定义约束生成美观的文本标志布局。|
|🆕 发布|No Pose at All: Self-Supervised Pose-Free 3D Gaussian Splatting from Sparse Views|无需姿态：从稀疏视角进行自监督无姿态3D高斯散点绘制|Ranran Huang, Krystian Mikolajczyk|<http://arxiv.org/pdf/2508.01171v1>|[代码](https://ranrhuang.github.io/spfsplat); 提出了一种无需真实位姿信息的3D高斯分布重建框架，实现了高效的单步前向传播多视角图像处理。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Geo-NI: Geometry-aware Neural Interpolation for Light Field Rendering|Geo-NI：面向几何感知的神经插值用于光场渲染|Gaochang Wu, Yuemei Zhou, Yebin Liu, Lu Fang, Tianyou Chai|<http://arxiv.org/pdf/2206.09736v2>|提出了一种结合神经插值和深度图像渲染的Geo-NI框架，利用场景几何实现高质量光场渲染。|
|🆕 发布|ParaRevSNN: A Parallel Reversible Spiking Neural Network for Efficient Training and Inference|ParaRevSNN：一种用于高效训练和推理的并行可逆脉冲神经网络|Changqing Xu, Guoqing Sun, Yi Liu, Xinfang Liao, Yintang Yang|<http://arxiv.org/pdf/2508.01223v1>|提出ParaRevSNN，一种并行可逆脉冲神经网络架构，实现高效训练与推理同时保持内存节省。|
|🆕 发布|Eigen Neural Network: Unlocking Generalizable Vision with Eigenbasis|特征神经网络：利用特征基解锁通用视觉|Anzhe Cheng, Chenzhong Yin, Mingxi Cheng, Shukai Duan, Shahin Nazarian, Paul Bogdan|<http://arxiv.org/pdf/2508.01219v1>|提出Eigen Neural Network，通过正交基重新参数化权重，提升特征表示结构性和泛化能力...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Lightweight Backbone Networks Only Require Adaptive Lightweight Self-Attention Mechanisms|轻量级骨干网络仅需自适应轻量级自注意力机制|Fengyun Li, Chao Zheng, Yangyang Fang, Jialiang Lan, Jianhua Liang, Luhao Zhang, Fa Si|<http://arxiv.org/pdf/2508.01385v1>|提出自适应轻量级SoftMax注意力机制，实现全局与局部特征融合，提升轻量级网络性能。|
|🆕 发布|P3P Made Easy|P3P轻松实现|Seong Hun Lee, Patrick Vandewalle, Javier Civera|<http://arxiv.org/pdf/2508.01312v1>|提出了一种简洁高效的代数解法，解决了从三个二维三维对应点恢复相机绝对姿态的P3P问题。|
|📝 更新|FastDriveVLA: Efficient End-to-End Driving via Plug-and-Play Reconstruction-based Token Pruning|FastDriveVLA：基于即插即用重建的标记剪枝实现的端到端高效驾驶|Jiajun Cao, Qizhe Zhang, Peidong Jia, Xuhui Zhao, Bo Lan, Xiaoan Zhang, Xiaobao Wei, Sixiang Chen .etc.|<http://arxiv.org/pdf/2507.23318v2>|提出了一种针对自动驾驶的视觉token剪枝框架FastDriveVLA，通过重建策略优化 foreg...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-Cache Enhanced Prototype Learning for Test-Time Generalization of Vision-Language Models|多缓存增强原型学习：用于视觉语言模型测试时泛化的方法|Xinyu Chen, Haotian Zhai, Can Zhang, Xiupeng Shi, Ruirui Li|<http://arxiv.org/pdf/2508.01225v1>|提出多缓存增强原型学习法，通过三种缓存优化视觉语言模型在测试时的泛化性能。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Zero-Shot Vision Encoder Grafting via LLM Surrogates|通过大型语言模型代理进行零样本视觉编码器嫁接|Kaiyu Yue, Vasu Singla, Menglin Jia, John Kirchenbauer, Rifaa Qadri, Zikui Cai, Abhinav Bhatele, Furong Huang .etc.|<http://arxiv.org/pdf/2505.22664v2>|[代码](https://github.com/facebookresearch/zero.); 提出了一种使用小型语言模型训练视觉编码器后直接迁移至大型模型的方法，实现了成本降低45%的零样本嫁接...|
|📝 更新|InstructLayout: Instruction-Driven 2D and 3D Layout Synthesis with Semantic Graph Prior|指令驱动下的二维与三维布局合成及语义图先验|Chenguo Lin, Yuchen Lin, Panwang Pan, Xuanyang Zhang, Yadong Mu|<http://arxiv.org/pdf/2407.07580v3>|引入InstructLayout，一种结合语义图先验和布局解码器的生成框架，提高了2D和3D布局合成...|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Large-Scale Benchmark of Cross-Modal Learning for Histology and Gene Expression in Spatial Transcriptomics|跨模态学习在空间转录组学中用于组织病理学与基因表达的大规模基准测试|Rushin H. Gindra, Giovanni Palla, Mathias Nguyen, Sophia J. Wagner, Manuel Tran, Fabian J Theis, Dieter Saur, Lorin Crawford .etc.|<http://arxiv.org/pdf/2508.01490v1>|构建了跨模态学习的大规模空间转录组学基准，揭示了基因表达编码器对表征对齐的影响。|
|🆕 发布|Uncertainty-Aware Segmentation Quality Prediction via Deep Learning Bayesian Modeling: Comprehensive Evaluation and Interpretation on Skin Cancer and Liver Segmentation|深度学习贝叶斯建模下的不确定性感知分割质量预测：皮肤癌和肝脏分割的全面评估与解读|Sikha O K, Meritxell Riera-Marín, Adrian Galdran, Javier García Lopez, Julia Rodríguez-Comas, Gemma Piella, Miguel A. González Ballester|<http://arxiv.org/pdf/2508.01460v1>|提出了一种无需真实标注即可预测图像分割质量的新框架，通过深度学习贝叶斯建模量化不确定性。|
|🆕 发布|Capturing More: Learning Multi-Domain Representations for Robust Online Handwriting Verification|捕捉更多：学习多域表示以实现鲁棒的在线手写验证|Peirong Zhang, Kai Ding, Lianwen Jin|<http://arxiv.org/pdf/2508.01427v1>|[代码](https://github.com/NiceRingNode/SPECTRUM.); 提出SPECTRUM模型，融合时间-频率多域表征，显著提升在线手写验证的准确性。|
|🆕 发布|Classification of Brain Tumors using Hybrid Deep Learning Models|基于混合深度学习模型的脑肿瘤分类|Neerav Nemchand Gala|<http://arxiv.org/pdf/2508.01350v1>|本研究通过应用迁移学习，使用较少的训练样本实现了对脑肿瘤类型的准确分类，并发现EfficientNe...|
|🆕 发布|DisFaceRep: Representation Disentanglement for Co-occurring Facial Components in Weakly Supervised Face Parsing|《DisFaceRep：弱监督人脸解析中协同出现面部组件的表征解耦》|Xiaoqin Wang, Xianxu Hou, Meidan Ding, Junliang Chen, Kaijun Deng, Jinheng Xie, Linlin Shen|<http://arxiv.org/pdf/2508.01250v1>|[代码](https://github.com/CVI-SZU/DisFaceRep); 提出弱监督人脸解析新任务，通过DisFaceRep框架分离面部组件，提升了解析性能。|
|🆕 发布|Enhancing Multi-view Open-set Learning via Ambiguity Uncertainty Calibration and View-wise Debiasing|通过模糊性不确定性校准和视图特异性去偏增强多视角开放集学习|Zihan Fang, Zhiyong Xu, Lan Du, Shide Du, Zhiling Cai, Shiping Wang|<http://arxiv.org/pdf/2508.01227v1>|提出了一种通过模糊度校准和视图去偏策略增强多视角开放集学习性能的方法。|
|🆕 发布|Semi-Supervised Anomaly Detection in Brain MRI Using a Domain-Agnostic Deep Reinforcement Learning Approach|基于域无关深度强化学习的脑磁共振成像半监督异常检测|Zeduo Zhang, Yalda Mohsenzadeh|<http://arxiv.org/pdf/2508.01137v1>|提出了一种基于深度强化学习的半监督异常检测框架，有效解决了医学影像数据量庞大、标签稀缺和过拟合问题。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CityNav: A Large-Scale Dataset for Real-World Aerial Navigation|城市导航：面向现实世界空中导航的大规模数据集|Jungdae Lee, Taiki Miyanishi, Shuhei Kurita, Koya Sakamoto, Daichi Azuma, Yutaka Matsuo, Nakamasa Inoue|<http://arxiv.org/pdf/2406.14240v3>|介绍了首个大规模真实世界城市空中导航数据集CityNav，并提出了结合地理语义地图的方法，显著提升了...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Reinforcing VLMs to Use Tools for Detailed Visual Reasoning Under Resource Constraints|在资源受限条件下强化视觉语言模型使用工具进行详细视觉推理|Sunil Kumar, Bowen Zhao, Leo Dirac, Paulina Varshavskaya|<http://arxiv.org/pdf/2506.14821v2>|通过训练小规模视觉语言模型使用外部工具进行详细视觉推理，提高了资源受限下的VQA性能。|
|📝 更新|CLIP Brings Better Features to Visual Aesthetics Learners|CLIP为视觉美学学习者带来了更好的特征|Liwu Xu, Jinjin Xu, Yuzhe Yang, Xilu Wang, Yijie Huang, Yaqian Li|<http://arxiv.org/pdf/2307.15640v2>|提出了一种基于CLIP的半监督知识蒸馏方法，有效利用预训练模型提升视觉美学评估性能。|
|🆕 发布|Weakly-Supervised Image Forgery Localization via Vision-Language Collaborative Reasoning Framework|通过视觉-语言协同推理框架的弱监督图像伪造定位|Ziqi Sheng, Junyan Wu, Wei Lu, Jiantao Zhou|<http://arxiv.org/pdf/2508.01338v1>|提出ViLaCo框架，利用预训练视觉语言模型提供语义指导，实现了仅用图像级标签进行精确像素级伪造定位...|
|🆕 发布|Perspective from a Broader Context: Can Room Style Knowledge Help Visual Floorplan Localization?|从更广泛的角度来看：房间风格知识能否帮助视觉平面图定位？|Bolei Chen, Shengsheng Yan, Yongzheng Cui, Jiaxu Kang, Ping Zhong, Jianxin Wang|<http://arxiv.org/pdf/2508.01216v1>|利用场景布局先验知识，提出了一种通过房间风格识别增强视觉平面定位鲁棒性和准确性的方法。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Construction of Digital Terrain Maps from Multi-view Satellite Imagery using Neural Volume Rendering|利用神经体积渲染从多视角卫星图像构建数字地形图|Josef X. Biberstein, Guilherme Cavalheiro, Juyeop Han, Sertac Karaman|<http://arxiv.org/pdf/2508.01386v1>|利用神经体积渲染技术直接从卫星图像学习纹理数字地形图，简化了地形图的制作过程。|
|🆕 发布|GMAT: Grounded Multi-Agent Clinical Description Generation for Text Encoder in Vision-Language MIL for Whole Slide Image Classification|GMAT：面向视觉语言MIL的整张切片图像分类中基于地面实体的多代理临床描述生成文本编码器|Ngoc Bui Lam Quang, Nam Le Nguyen Binh, Thanh-Huy Nguyen, Le Thien Phuc Nguyen, Quan Nguyen, Ulas Bagci|<http://arxiv.org/pdf/2508.01293v1>|提出了一种结合专业病理教材和多样化描述生成的计算机视觉框架，提高了医学图像分类的准确性和细致度。|
|🆕 发布|NS-Net: Decoupling CLIP Semantic Information through NULL-Space for Generalizable AI-Generated Image Detection|NS-Net：通过NULL空间解耦CLIP语义信息以实现通用人工智能生成图像检测|Jiazhen Yan, Fan Wang, Weiwei Jiang, Ziqiang Li, Zhangjie Fu|<http://arxiv.org/pdf/2508.01248v1>|提出NS-Net框架，通过NULL-Space投影分离CLIP语义信息，增强AI生成图像检测的泛化能...|
|📝 更新|MEGANet-W: A Wavelet-Driven Edge-Guided Attention Framework for Weak Boundary Polyp Detection|MEGANet-W：一种基于小波驱动的边缘引导注意力框架用于弱边界息肉检测|Zhe Yee Tan, Ashwaq Qasem|<http://arxiv.org/pdf/2507.02668v3>|提出MEGANet-W模型，利用Haar小波边缘图增强边缘细节，提升弱边界息肉检测准确性。|
|🆕 发布|Deep Learning for Pavement Condition Evaluation Using Satellite Imagery|基于卫星图像的路面状况评估深度学习方法|Prathyush Kumar Reddy Lebaku, Lu Gao, Pan Lu, Jingran Sun|<http://arxiv.org/pdf/2508.01206v1>|利用深度学习分析卫星图像，实现高效评估路面状况，准确率超90%。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Video-based Vehicle Surveillance in the Wild: License Plate, Make, and Model Recognition with Self Reflective Vision-Language Models|野外视频车辆监控：基于自反思视觉语言模型的牌照、品牌和型号识别|Pouya Parsa, Keya Li, Kara M. Kockelman, Seongjin Choi|<http://arxiv.org/pdf/2508.01387v1>|提出利用自反思视觉语言模型，有效提升移动设备捕捉的车辆监控准确度。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Referring Remote Sensing Image Segmentation with Cross-view Semantics Interaction Network|基于跨视图语义交互网络的引用遥感图像分割|Jiaxing Yang, Lihe Zhang, Huchuan Lu|<http://arxiv.org/pdf/2508.01331v1>|提出了一种并行统一的分割框架CSINet，通过融合远程和近距离视觉线索，有效处理遥感图像中细微和模糊...|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DuET: Dual Incremental Object Detection via Exemplar-Free Task Arithmetic|DuET: 基于无样例任务算术的双增量目标检测|Munish Monga, Vishal Chudasama, Pankaj Wasnik, Biplab Banerjee|<http://arxiv.org/pdf/2506.21260v2>|提出了一种同时处理类别和领域变化的增量检测方法DuET，通过任务算术框架和方向一致性损失稳定学习并减...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ArchiLense: A Framework for Quantitative Analysis of Architectural Styles Based on Vision Large Language Models|《ArchiLense：基于视觉大型语言模型的建筑风格定量分析框架》|Jing Zhong, Jun Yin, Peilin Li, Pengyu Zeng, Miao Zang, Ran Luo, Shuai Lu|<http://arxiv.org/pdf/2506.07739v3>|提出ArchDiffBench数据集和ArchiLense框架，利用视觉语言模型自动识别和分析建筑风...|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Vision Calorimeter for Anti-neutron Reconstruction: A Baseline|抗中子重建的视觉热量计：基线|Hongtian Yu, Yangu Li, Mingrui Wu, Letian Shen, Yue Liu, Yunxuan Song, Qixiang Ye, Xiao-Rui Lyu .etc.|<http://arxiv.org/pdf/2408.10599v3>|[代码](https://github.com/yuhongtian17/ViC.); 提出Vision Calorimeter方法，利用深度学习分析能量分布图像，实现高能物理中反中子位置...|
|📝 更新|AutoOcc: Automatic Open-Ended Semantic Occupancy Annotation via Vision-Language Guided Gaussian Splatting|自动开放式语义占据标注：基于视觉-语言引导的高斯散点绘制方法|Xiaoyu Zhou, Jingqi Wang, Yongtao Wang, Yufei Wei, Nan Dong, Ming-Hsuan Yang|<http://arxiv.org/pdf/2502.04981v3>|提出了一种自动化的视觉中心语义占用标注方法AutoOcc，通过结合视觉语言模型和基础视觉模型自动生成...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Open-Attribute Recognition for Person Retrieval: Finding People Through Distinctive and Novel Attributes|开放属性识别用于人物检索：通过独特和新型属性寻找人物|Minjeong Park, Hongbeen Park, Sangwon Lee, Yoonha Jang, Jinkyu Kim|<http://arxiv.org/pdf/2508.01389v1>|提出开放属性识别任务，通过学习泛化的身体部位表征，实现基于新颖属性的人物检索。|
|🆕 发布|OCSplats: Observation Completeness Quantification and Label Noise Separation in 3DGS|观测完整性量化与三维几何标注中标签噪声分离的OCSplats方法|Han Ling, Xian Xu, Yinghui Sun, Quansen Sun|<http://arxiv.org/pdf/2508.01239v1>|提出了一种新的3D重建抗噪框架OCSplats，通过动态锚点分类噪声，无需调参即可适应不同噪声比例场...|

