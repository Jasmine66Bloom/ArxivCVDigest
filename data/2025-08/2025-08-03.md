## [UPDATED!] **2025-08-03** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LEMON: A Large Endoscopic MONocular Dataset and Foundation Model for Perception in Surgical Settings|LEMON：一种大型内窥镜单目数据集及手术环境下感知的基础模型|Chengan Che, Chao Wang, Tom Vercauteren, Sophia Tsoka, Luis C. Garcia-Peraza-Herrera|<http://arxiv.org/pdf/2503.19740v3>|构建大型内镜单目视频数据集LEMON，提出基础模型LemonFM，提升手术场景感知性能。|
|📝 更新|More than Memes: A Multimodal Topic Modeling Approach to Conspiracy Theories on Telegram|超越梗图：一种多模态主题建模方法研究Telegram上的阴谋论|Elisabeth Steffen|<http://arxiv.org/pdf/2410.08642v3>|提出多模态话题模型分析社交媒体上的阴谋论，结合文本与图像数据揭示传播策略。|
|📝 更新|DanceGRPO: Unleashing GRPO on Visual Generation|舞动GRPO：在视觉生成中释放GRPO的力量|Zeyue Xue, Jie Wu, Yu Gao, Fangyuan Kong, Lingting Zhu, Mengzhao Chen, Zhiheng Liu, Wei Liu .etc.|<http://arxiv.org/pdf/2505.07818v2>|首次提出DanceGRPO框架，统一应用强化学习优化视觉生成任务，显著提升多种生成模型和任务的表现。|
|🆕 发布|Rein++: Efficient Generalization and Adaptation for Semantic Segmentation with Vision Foundation Models|“Rein++：基于视觉基础模型的语义分割高效泛化和适应方法”|Zhixiang Wei, Xiaoxiao Ma, Ruishen Yan, Tao Tu, Huaian Chen, Jinjin Zheng, Yi Jin, Enhong Chen|<http://arxiv.org/pdf/2508.01667v1>|[代码](https://github.com/wloves/Rein.); Rein++通过引入可训练的实例感知标记和自适应策略，有效提升了视觉基础模型在语义分割中的泛化与适应...|
|🆕 发布|Set Pivot Learning: Redefining Generalized Segmentation with Vision Foundation Models|“设置枢轴学习：利用视觉基础模型重新定义广义分割”|Xinhui Li, Xinyu He, Qiming Hu, Xiaojie Guo|<http://arxiv.org/pdf/2508.01582v1>|提出Set Pivot Learning方法，利用预训练视觉基础模型实现动态适应和跨域稳健性，优化广...|
|🆕 发布|EvoVLMA: Evolutionary Vision-Language Model Adaptation|进化视觉-语言模型适应|Kun Ding, Ying Wang, Shiming Xiang|<http://arxiv.org/pdf/2508.01558v1>|[代码](https://github.com/kding1225/EvoVLMA); 提出了一种自动搜索训练无关的高效适应算法的方法，通过进化算法优化视觉语言模型适应关键功能。|
|🆕 发布|ReasonAct: Progressive Training for Fine-Grained Video Reasoning in Small Models|《ReasonAct：面向小模型的细粒度视频推理的渐进式训练》|Jiaxin Liu, Zhaolu Kang|<http://arxiv.org/pdf/2508.01533v1>|提出了一种三阶段训练方法ReasonAct，通过文本推理、视频微调和时间感知强化学习，提升了小规模模...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vision transformer-based multi-camera multi-object tracking framework for dairy cow monitoring|基于视觉变换器的多摄像头多目标跟踪框架，用于奶牛监测|Kumail Abbas, Zeeshan Afzal, Aqeel Raza, Taha Mansouri, Andrew W. Dowsey, Chaidate Inchaisri, Ali Alameer|<http://arxiv.org/pdf/2508.01752v1>|开发了一种多摄像头实时监控系统，利用计算机视觉技术精准监测奶牛活动，提高疾病识别和农场生产效率。|
|🆕 发布|LetheViT: Selective Machine Unlearning for Vision Transformers via Attention-Guided Contrastive Learning|莱瑟维特：基于注意力引导对比学习的视觉变换器选择性机器遗忘|Yujia Tong, Tian Zhang, Jingling Yuan, Yuze Wang, Chuang Hu|<http://arxiv.org/pdf/2508.01569v1>|提出了一种针对视觉变换器的选择性机器遗忘方法LetheViT，通过注意力引导对比学习实现数据隐私保护...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Multimodal 3D Reasoning Segmentation with Complex Scenes|多模态三维推理分割技术在复杂场景中的应用|Xueying Jiang, Lewei Lu, Ling Shao, Shijian Lu|<http://arxiv.org/pdf/2411.13927v4>|提出3D推理分割任务及MORE3D网络，处理复杂场景中多物体交互与空间关系理解问题。|
|🆕 发布|MAP: Mitigating Hallucinations in Large Vision-Language Models with Map-Level Attention Processing|MAP：通过地图级注意力处理减轻大型视觉-语言模型中的幻觉现象|Chenxi Li, Yichen Guo, Benfang Qian, Jinhao You, Kai Tang, Yaosong Du, Zonghao Zhang, Xiande Huang|<http://arxiv.org/pdf/2508.01653v1>|提出了一种基于地图级别注意力处理的方法，有效减少大型视觉语言模型中的虚构现象，提高事实一致性。|
|🆕 发布|DMTrack: Spatio-Temporal Multimodal Tracking via Dual-Adapter|DMTrack：通过双适配器实现的空间时间多模态跟踪|Weihong Li, Shaohua Dong, Haonan Lu, Yanhao Zhang, Heng Fan, Libo Zhang|<http://arxiv.org/pdf/2508.01592v1>|提出双适配器架构DMTrack，通过自提示和渐进式融合实现高效多模态跟踪。|
|🆕 发布|MiraGe: Multimodal Discriminative Representation Learning for Generalizable AI-Generated Image Detection|MiraGe：用于通用人工智能生成图像检测的多模态判别性表征学习|Kuo Shi, Jie Lu, Shanshan Ye, Guangquan Zhang, Zhen Fang|<http://arxiv.org/pdf/2508.01525v1>|提出了一种学习生成模型不变特征的方法MiraGe，通过多模态提示学习增强特征辨识度，有效提高了AI生...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|InspectVLM: Unified in Theory, Unreliable in Practice|理论统一，实践中不可靠的InspectVLM|Conor Wallace, Isaac Corley, Jonathan Lwowski|<http://arxiv.org/pdf/2508.01921v1>|揭示了统一视觉语言模型在精确度要求高的工业检测中的局限性，发现其性能不如传统模型。|
|📝 更新|Collaborative Novel Object Discovery and Box-Guided Cross-Modal Alignment for Open-Vocabulary 3D Object Detection|协同新颖目标发现与框引导的跨模态对准用于开放词汇三维目标检测|Yang Cao, Yihan Zeng, Hang Xu, Dan Xu|<http://arxiv.org/pdf/2406.00830v2>|提出CoDAv2框架，通过3D几何与2D语义先验发现新物体，并实现3D与2D/文本模态的特征对齐，提...|
|🆕 发布|AG$^2$aussian: Anchor-Graph Structured Gaussian Splatting for Instance-Level 3D Scene Understanding and Editing|AG$^2$aussian：基于锚点图结构的高斯散点法用于实例级三维场景理解和编辑|Zhaonan Wang, Manyi Li, Changhe Tu|<http://arxiv.org/pdf/2508.01740v1>|引入了AG$^2$aussian框架，通过锚点图结构优化高斯分布，实现精确的实例级3D场景理解和编辑...|
|📝 更新|A Decade of You Only Look Once (YOLO) for Object Detection: A Review|《物体检测领域十年回顾：你只需看一眼（YOLO）》|Leo Thomas Ramos, Angel D. Sappa|<http://arxiv.org/pdf/2504.18586v2>|系统梳理了YOLO系列架构的十年发展，强调了其高效设计、模块化扩展和跨领域适应性。|
|🆕 发布|Adaptive LiDAR Scanning: Harnessing Temporal Cues for Efficient 3D Object Detection via Multi-Modal Fusion|自适应激光雷达扫描：通过多模态融合利用时间线索实现高效的三维目标检测|Sara Shoouri, Morteza Tavakoli Taba, Hun-Seok Kim|<http://arxiv.org/pdf/2508.01562v1>|提出了一种自适应LiDAR扫描框架，通过多模态融合和时间线索减少数据采集，降低能耗同时保持或提升3D...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EgoTrigger: Toward Audio-Driven Image Capture for Human Memory Enhancement in All-Day Energy-Efficient Smart Glasses|自我触发器：面向全天候节能智能眼镜中的人类记忆增强的音频驱动图像捕捉|Akshay Paruchuri, Sinan Hersek, Lavisha Aggarwal, Qiao Yang, Xin Liu, Achin Kulshrestha, Andrea Colaco, Henry Fuchs .etc.|<http://arxiv.org/pdf/2508.01915v1>|提出EgoTrigger方法，利用音频线索智能激活相机，实现智能眼镜全天候节能与记忆增强。|
|🆕 发布|Large Kernel MedNeXt for Breast Tumor Segmentation and Self-Normalizing Network for pCR Classification in Magnetic Resonance Images|《用于乳腺肿瘤分割的大核MedNeXt网络与用于磁共振图像病理完全缓解分类的自归一化网络》|Toufiq Musah|<http://arxiv.org/pdf/2508.01831v1>|[代码](https://github.com/toufiqmusah/caladan-mama-mia.git); 提出了一种大核MedNeXt架构和自归一化网络，用于乳腺肿瘤分割和病理完全缓解分类，提升了MRI图像...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PLGS: Robust Panoptic Lifting with 3D Gaussian Splatting|全局语义分割：基于三维高斯散点法的鲁棒全景提升|Yu Wang, Xiaobao Wei, Ming Lu, Guoliang Kang|<http://arxiv.org/pdf/2410.17505v2>|提出PLGS方法，通过构建结构化3D高斯模型和噪声减少策略，从噪声2D分割掩码生成一致3D全景分割，...|
|🆕 发布|Self-Navigated Residual Mamba for Universal Industrial Anomaly Detection|自导航残差蟒蛇网络用于通用工业异常检测|Hanxi Li, Jingqi Wu, Lin Yuanbo Wu, Mingliang Li, Deyin Liu, Jialie Shen, Chunhua Shen|<http://arxiv.org/pdf/2508.01591v1>|提出了一种自适应参考选择的工业异常检测框架，通过内部残差比较提升异常识别准确性。|
|📝 更新|CA-W3D: Leveraging Context-Aware Knowledge for Weakly Supervised Monocular 3D Detection|基于上下文感知知识的弱监督单目3D检测：CA-W3D|Chupeng Liu, Runkai Zhao, Weidong Cai|<http://arxiv.org/pdf/2503.04154v2>|提出了一种利用上下文知识的弱监督单目3D检测方法，通过对比匹配和伪标签训练显著提升了检测准确性。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dynamic Robot-Assisted Surgery with Hierarchical Class-Incremental Semantic Segmentation|动态机器人辅助手术中的分层类别增量语义分割|Julia Hindel, Ema Mekic, Enamundram Naga Karthik, Rohit Mohan, Daniele Cattaneo, Maria Kalweit, Abhinav Valada|<http://arxiv.org/pdf/2508.01713v1>|提出了一种针对动态机器人辅助手术环境的层级类别增量语义分割方法，有效应对手术场景中的动态变化和类别增...|
|🆕 发布|Single Point, Full Mask: Velocity-Guided Level Set Evolution for End-to-End Amodal Segmentation|单点全掩码：基于速度引导的级联演化用于端到端隐式分割|Zhixuan Li, Yujia Liu, Chen Hui, Weisi Lin|<http://arxiv.org/pdf/2508.01661v1>|提出了一种基于单点提示和速度引导的几何建模方法VELA，实现了对被遮挡物体形状的完整恢复。|
|🆕 发布|Glass Surface Segmentation with an RGB-D Camera via Weighted Feature Fusion for Service Robots|基于RGB-D相机的加权特征融合服务机器人玻璃表面分割|Henghong Lin, Zihan Zhu, Tao Wang, Anastasia Ioannou, Yuanshui Huang|<http://arxiv.org/pdf/2508.01639v1>|提出了一种动态融合RGB和深度信息的加权特征融合模块，显著提升了玻璃表面分割准确性和鲁棒性。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Multi-Modal Semantic Parsing for the Interpretation of Tombstone Inscriptions|多模态语义解析用于墓碑碑文解读|Xiao Zhang, Johan Bos|<http://arxiv.org/pdf/2507.04377v2>|提出了一种多模态语义解析框架，利用视觉语言模型将墓碑图像转化为结构化表示，大幅提升了解析精度。|
|📝 更新|Conditional Balance: Improving Multi-Conditioning Trade-Offs in Image Generation|条件平衡：改进图像生成中多条件权衡|Nadav Z. Cohen, Oron Nir, Ariel Shamir|<http://arxiv.org/pdf/2412.19853v2>|提出了一种针对图像生成中内容与风格平衡问题的方法，通过识别并调整DDPM模型中的敏感层，实现了更精细...|
|📝 更新|SegmentDreamer: Towards High-fidelity Text-to-3D Synthesis with Segmented Consistency Trajectory Distillation|SegmentDreamer：面向高保真文本到3D合成的一致性轨迹分割蒸馏方法|Jiahao Zhu, Zixuan Chen, Guangcong Wang, Xiaohua Xie, Yi Zhou|<http://arxiv.org/pdf/2507.05256v2>|SegmentDreamer通过创新的Segmented Consistency Trajector...|
|🆕 发布|Imbalance-Robust and Sampling-Efficient Continuous Conditional GANs via Adaptive Vicinity and Auxiliary Regularization|通过自适应邻域和辅助正则化实现的平衡鲁棒且采样高效的条件生成对抗网络|Xin Ding, Yun Chen, Yongwei Wang, Kao Zhang, Sen Zhang, Peibei Cao, Xiangxue Wang|<http://arxiv.org/pdf/2508.01725v1>|提出了一种改进的CcGAN框架，通过自适应邻域和辅助正则化解决了数据不平衡和采样效率问题。|
|🆕 发布|SURE-Med: Systematic Uncertainty Reduction for Enhanced Reliability in Medical Report Generation|SURE-Med：医学报告生成中增强可靠性的系统不确定性降低方法|Yuhang Gu, Xingyu Hu, Yuyu Fan, Xulin Yan, Longhuan Xu, Peng peng|<http://arxiv.org/pdf/2508.01693v1>|SURE-Med通过统一框架系统降低视觉、分布和语境不确定性，提升医疗报告生成系统的可靠性和临床可信...|
|🆕 发布|Versatile Transition Generation with Image-to-Video Diffusion|多功能的过渡生成：基于图像到视频的扩散模型|Zuhao Yang, Jiahui Zhang, Yingchen Yu, Shijian Lu, Song Bai|<http://arxiv.org/pdf/2508.01698v1>|提出了一种生成平滑、高保真、语义连贯视频过渡的VTG框架，通过初始化插值和双向运动微调解决了视频生成...|
|🆕 发布|TimeExpert: An Expert-Guided Video LLM for Video Temporal Grounding|时间专家：一种专家引导的视频大型语言模型用于视频时间定位|Zuhao Yang, Yingchen Yu, Yunqing Zhao, Shijian Lu, Song Bai|<http://arxiv.org/pdf/2508.01699v1>|TimeExpert通过引入混合专家模型，针对视频时序定位任务动态分配计算资源，提升了事件建模的精确...|
|🆕 发布|DisCo3D: Distilling Multi-View Consistency for 3D Scene Editing|《DisCo3D：三维场景编辑中的多视角一致性蒸馏》|Yufeng Chi, Huimin Ma, Kafeng Wang, Jianmin Li|<http://arxiv.org/pdf/2508.01684v1>|提出DisCo3D框架，通过二维编辑器蒸馏三维一致性先验，实现稳定的三维场景编辑和多视角一致性。|
|🆕 发布|StrandDesigner: Towards Practical Strand Generation with Sketch Guidance|《StrandDesigner：基于草图指导的实用型纤维生成方法》|Na Zhang, Moran Li, Chengming Xu, Han Feng, Xiaobin Hu, Jiangning Zhang, Weijian Cao, Chengjie Wang .etc.|<http://arxiv.org/pdf/2508.01650v1>|[代码](https://github.com/fighting-Zhang/StrandDesigner); 提出首个基于草图指导的头发丝生成模型，通过多尺度编码和自适应条件机制实现精细控制和真实感。|
|📝 更新|KinMo: Kinematic-aware Human Motion Understanding and Generation|运动感知的人体运动理解与生成：KinMo|Pengfei Zhang, Pinxin Liu, Pablo Garrido, Hyeongwoo Kim, Bindita Chaudhuri|<http://arxiv.org/pdf/2411.15472v3>|[代码](https://andypinxinliu.github.io/KinMo); 提出 KinMo 框架，通过层级运动描述和动力学细节，提升了运动理解和生成精度。|
|🆕 发布|Towards Generalizable AI-Generated Image Detection via Image-Adaptive Prompt Learning|面向通用的人工智能生成图像检测：基于图像自适应提示学习|Yiheng Li, Zichang Tan, Zhen Lei, Xu Zhou, Yang Yang|<http://arxiv.org/pdf/2508.01603v1>|提出了一种自适应图像提示学习方法，有效提高了AI生成图像检测的泛化能力。|
|📝 更新|Fair Generation without Unfair Distortions: Debiasing Text-to-Image Generation with Entanglement-Free Attention|无偏见生成，无扭曲：使用无纠缠注意力去偏文本到图像生成|Jeonghoon Park, Juyoung Lee, Chaeyeon Chung, Jaeseong Lee, Jaegul Choo, Jindong Gu|<http://arxiv.org/pdf/2506.13298v2>|提出了一种无纠缠注意机制，有效减少文本到图像生成中的偏见，同时保持图像质量不受影响。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RAISE: Realness Assessment for Image Synthesis and Evaluation|RAISE：图像合成与评估的真实性评估|Aniruddha Mukherjee, Spriha Dubey, Somdyuti Paul|<http://arxiv.org/pdf/2505.19233v2>|提出了一种新数据集RAISE，通过人类研究评估AI生成图像的真实感，并训练模型预测图像真实感。|
|📝 更新|MuteSwap: Visual-informed Silent Video Identity Conversion|《MuteSwap：视觉信息指导的静音视频身份转换》|Yifan Liu, Yu Fang, Zhouhan Lin|<http://arxiv.org/pdf/2507.00498v3>|提出了一种视觉驱动的静音视频身份转换方法MuteSwap，实现了无需音频输入的语音转换。|
|📝 更新|Individual Content and Motion Dynamics Preserved Pruning for Video Diffusion Models|个体内容与运动动态保持的剪枝策略用于视频扩散模型|Yiming Wu, Huan Wang, Zhenghao Chen, Dong Xu|<http://arxiv.org/pdf/2411.18375v2>|提出一种视频扩散模型压缩方法，通过保留内容和运动动态实现快速高质量视频生成。|
|📝 更新|Efficient4D: Fast Dynamic 3D Object Generation from a Single-view Video|高效4D：从单视角视频快速生成动态三维物体|Zijie Pan, Zeyu Yang, Xiatian Zhu, Li Zhang|<http://arxiv.org/pdf/2401.08742v4>|提出Efficient4D框架，通过视频生成4D对象，实现实时渲染并提高建模速度10倍。|
|🆕 发布|E-VRAG: Enhancing Long Video Understanding with Resource-Efficient Retrieval Augmented Generation|E-VRAG：利用资源高效检索增强的长视频理解|Zeyu Xu, Junkang Zhang, Qiang Wang, Yi Liu|<http://arxiv.org/pdf/2508.01546v1>|提出E-VRAG框架，通过高效检索增强长视频理解，减少计算成本并提高准确度。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DiffusionFF: Face Forgery Detection via Diffusion-based Artifact Localization|扩散FF：基于扩散的伪造痕迹定位的人脸伪造检测|Siran Peng, Haoyuan Zhang, Li Gao, Tianshuo Zhang, Bao Li, Zhen Lei|<http://arxiv.org/pdf/2508.01873v1>|提出DiffusionFF框架，通过扩散模型定位伪造痕迹，提升人脸伪造检测准确性和可解释性。|
|🆕 发布|Context Guided Transformer Entropy Modeling for Video Compression|视频压缩中基于上下文的变换器熵模型指导|Junlong Tong, Wei Zhang, Yaohui Jin, Xiaoyu Shen|<http://arxiv.org/pdf/2508.01852v1>|提出了一种结合时空上下文的Context Guided Transformer熵模型，有效降低视频冗...|
|🆕 发布|Sonify Anything: Towards Context-Aware Sonic Interactions in AR|“将任何事物声音化：面向增强现实中的上下文感知声音交互”|Laura Schütz, Sasan Matinfar, Ulrich Eck, Daniel Roth, Nassir Navab|<http://arxiv.org/pdf/2508.01789v1>|提出实时物理建模合成方法，通过识别真实物体材料生成逼真声音，增强AR交互体验。|
|🆕 发布|SpectralX: Parameter-efficient Domain Generalization for Spectral Remote Sensing Foundation Models|《SpectralX：面向光谱遥感基础模型的参数高效域泛化》|Yuxiang Zhang, Wei Li, Mengmeng Zhang, Jiawei Han, Ran Tao, Shunlin Liang|<http://arxiv.org/pdf/2508.01731v1>|提出SpectralX框架，通过两阶段训练有效适应多光谱数据，提升遥感基础模型的域泛化性能。|
|🆕 发布|Simulated Ensemble Attack: Transferring Jailbreaks Across Fine-tuned Vision-Language Models|模拟集成攻击：在微调的视觉-语言模型间转移破解能力|Ruofan Wang, Xin Wang, Yang Yao, Xuan Tong, Xingjun Ma|<http://arxiv.org/pdf/2508.01741v1>|提出了一种模拟集成攻击方法，通过模拟参数变化和文本引导，有效提升了对抗性攻击在微调视觉语言模型间的迁...|
|🆕 发布|Tracking the Unstable: Appearance-Guided Motion Modeling for Robust Multi-Object Tracking in UAV-Captured Videos|"追踪不稳定目标：基于外观引导的运动建模以实现无人机捕获视频中的稳健多目标跟踪"|Jianbo Ma, Hui Luo, Qi Chen, Yuankai Qi, Yumei Sun, Amin Beheshti, Jianlin Zhang, Ming-Hsuan Yang|<http://arxiv.org/pdf/2508.01730v1>|提出了一种结合外观和运动线索的稳健多目标跟踪方法，有效应对无人机视频中的视角变化和运动动态挑战。|
|📝 更新|RedDiffuser: Red Teaming Vision-Language Models for Toxic Continuation via Reinforced Stable Diffusion|红色扩散器：通过强化稳定扩散对有毒延续进行视觉-语言模型的红队测试|Ruofan Wang, Xiang Zheng, Xiaosen Wang, Cong Wang, Xingjun Ma|<http://arxiv.org/pdf/2503.06223v3>|提出RedDiffuser框架，通过强化学习微调扩散模型生成诱使有毒输出的自然图像。|
|🆕 发布|DAG: Unleash the Potential of Diffusion Model for Open-Vocabulary 3D Affordance Grounding|DAG：释放扩散模型在开放词汇三维功效定位中的潜力|Hanqing Wang, Zhenhao Zhang, Kaiyang Ji, Mingyu Liu, Wenti Yin, Yuchao Chen, Zhirui Liu, Xiangyu Zeng .etc.|<http://arxiv.org/pdf/2508.01651v1>|提出利用文本到图像的扩散模型提取通用 affordance 知识，实现3D物体可接触区域预测的框架 ...|
|📝 更新|ProSAM: Enhancing the Robustness of SAM-based Visual Reference Segmentation with Probabilistic Prompts|ProSAM：基于SAM的视觉参考分割的鲁棒性增强与概率提示|Xiaoqi Wang, Clint Sebastian, Wenbin He, Liu Ren|<http://arxiv.org/pdf/2506.21835v3>|提出ProSAM方法，通过学习变分提示编码器预测多变量提示分布，增强了视觉参考分割的稳定性。|
|🆕 发布|LLaDA-MedV: Exploring Large Language Diffusion Models for Biomedical Image Understanding|探索大规模语言扩散模型在生物医学图像理解中的应用|Xuanzhao Dong, Wenhui Zhu, Xiwen Chen, Zhipeng Wang, Peijie Qiu, Shao Tang, Xin Li, Yalin Wang|<http://arxiv.org/pdf/2508.01617v1>|[代码](https://github.com/LLM-VLM-GSL/LLaDA-MedV.); 首次将大型语言扩散模型应用于生物医学图像理解，通过视觉指令调整实现了性能提升。|
|📝 更新|Scendi Score: Prompt-Aware Diversity Evaluation via Schur Complement of CLIP Embeddings|Scendi评分：通过CLIP嵌入的Schur补进行提示感知的多样性评估|Azim Ospanov, Mohammad Jalali, Farzan Farnia|<http://arxiv.org/pdf/2412.18645v3>|[代码](https://github.com/aziksh-ospanov/scendi-score.); 提出Scendi Score方法，利用CLIP嵌入评估文本到图像生成模型的内在多样性。|
|🆕 发布|From Pixels to Places: A Systematic Benchmark for Evaluating Image Geolocalization Ability in Large Language Models|从像素到地点：用于评估大型语言模型图像地理定位能力的系统性基准|Lingyao Li, Runlong Yu, Qikai Hu, Bowei Li, Min Deng, Yang Zhou, Xiaowei Jia|<http://arxiv.org/pdf/2508.01608v1>|提出IMAGEO-Bench基准，系统评估大型语言模型在图像地理定位任务中的性能和偏见。|
|🆕 发布|A Plug-and-Play Multi-Criteria Guidance for Diverse In-Betweening Human Motion Generation|“一种即插即用的多标准引导策略用于多样化的人体运动生成中插值”|Hua Yu, Jiao Liu, Xu Gui, Melvin Wong, Yaqing Hou, Yew-Soon Ong|<http://arxiv.org/pdf/2508.01590v1>|提出了一种增强预训练模型生成运动多样性的插件式多标准引导方法，有效提升了中间帧人类运动生成的多样性。|
|📝 更新|Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models|逆向DPO：用于扩散模型的精确与高效后训练方法|Zejian Li, Yize Li, Chenye Meng, Zhongni Liu, Yang Ling, Shengyuan Zhang, Guang Yang, Changyuan Yang .etc.|<http://arxiv.org/pdf/2507.11554v4>|[代码](https://github.com/MIGHTYEZ/Inversion-DPO); 提出Inversion-DPO方法，通过确定性反演优化扩散模型训练，无需奖励模型，提高了生成图像的精...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Diffusion-based 3D Hand Motion Recovery with Intuitive Physics|基于扩散的直观物理三维手部运动恢复|Yufei Zhang, Zijun Cui, Jeffrey O. Kephart, Qiang Ji|<http://arxiv.org/pdf/2508.01835v1>|提出了一种基于扩散和物理增强的3D手部运动恢复框架，通过迭代去噪提升单目视频中的运动估计准确性。|
|📝 更新|GAS: Generative Avatar Synthesis from a Single Image|单张图像生成的生成式头像合成方法（GAS）|Yixing Lu, Junting Dong, Youngjoong Kwon, Qin Zhao, Bo Dai, Fernando De la Torre|<http://arxiv.org/pdf/2502.06957v2>|提出了一种结合3D重建与扩散模型的方法，实现了从单张图片生成视角一致和时序连贯的虚拟形象。|
|📝 更新|GestureLSM: Latent Shortcut based Co-Speech Gesture Generation with Spatial-Temporal Modeling|手势LSM：基于潜在捷径的协同语音手势生成与时空建模|Pinxin Liu, Luchuan Song, Junhua Huang, Haiyang Liu, Chenliang Xu|<http://arxiv.org/pdf/2501.18898v3>|[代码](https://andypinxinliu.github.io/GestureLSM); 提出了一种基于时空建模和流匹配的GestureLSM方法，通过显式建模身体部位间的交互和优化采样效率...|
|📝 更新|DreamFrame: Enhancing Video Understanding via Automatically Generated QA and Style-Consistent Keyframes|梦境框架：通过自动生成的问答和风格一致的关键帧增强视频理解|Zhende Song, Chenchen Wang, Jiamu Sheng, Chi Zhang, Shengji Tang, Jiayuan Fan, Tao Chen|<http://arxiv.org/pdf/2403.01422v4>|提出DreamFrame框架，自动生成风格一致的关键帧和QA对，有效支持视觉语言模型微调。|
|📝 更新|NeuFlow v2: Push High-Efficiency Optical Flow To the Limit|NeuFlow v2：将高效率光流推向极致|Zhiyong Zhang, Aniket Gupta, Huaizu Jiang, Hanumant Singh|<http://arxiv.org/pdf/2408.10161v3>|[代码](https://github.com/neufieldrobotics/NeuFlow_v2.); 提出了一种高效的光流估计方法NeuFlow-V2，实现了高准确度与低计算成本的平衡。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Surgical Gaussian Surfels: Highly Accurate Real-time Surgical Scene Rendering using Gaussian Surfels|高精度实时手术场景渲染：采用高斯曲面元的手术高斯曲面元|Idris O. Sunmola, Zhenjun Zhao, Samuel Schmidgall, Yumeng Wang, Paul Maria Scheikl, Viet Pham, Axel Krieger|<http://arxiv.org/pdf/2503.04079v2>|[代码](https://github.com/aloma85/SurgicalGaussianSurfels); 提出Surgical Gaussian Surfels方法，通过约束高斯协方差矩阵和引入新型神经网络...|
|📝 更新|Reconstructing 4D Spatial Intelligence: A Survey|重构四维空间智能：综述|Yukang Cao, Jiahao Lu, Zhisheng Huang, Zhuowen Shen, Chengfeng Zhao, Fangzhou Hong, Zhaoxi Chen, Xin Li .etc.|<http://arxiv.org/pdf/2507.21045v2>|[代码](https://github.com/yukangcao/Awesome-4D-Spatial-Intelligence.); 系统化地将4D空间智能重建方法分为五个层次，为未来研究提供了清晰的发展框架。|
|🆕 发布|Granular Concept Circuits: Toward a Fine-Grained Circuit Discovery for Concept Representations|细粒度概念电路：迈向概念表示的精细电路发现|Dahee Kwon, Sehyun Lee, Jaesik Choi|<http://arxiv.org/pdf/2508.01728v1>|提出了一种细粒度的电路发现方法GCC，实现了对深度模型中具体视觉概念的精准定位和解释。|
|🆕 发布|Minimal High-Resolution Patches Are Sufficient for Whole Slide Image Representation via Cascaded Dual-Scale Reconstruction|通过级联双尺度重建，最小高分辨率补丁足以表示整张切片图像|Yujian Liu, Yuechuan Lin, Dongxu Shen, Haoran Li, Yutong Wang, Xiaoli Liu, Shidang Xu|<http://arxiv.org/pdf/2508.01641v1>|提出了一种高效的双尺度重建框架，仅用9个高分辨率图像块即可准确表示全玻片图像。|
|🆕 发布|Deeply Supervised Multi-Task Autoencoder for Biological Brain Age estimation using three dimensional T$_1$-weighted magnetic resonance imaging|深度监督多任务自动编码器用于基于三维T$_1$加权磁共振成像的生物大脑年龄估计|Mehreen Kanwal, Yunsik Son|<http://arxiv.org/pdf/2508.01565v1>|提出了一种多任务深度监督自编码器框架，通过同时优化脑龄预测、性别分类和图像重建任务，提高了脑龄预测的...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CVD-SfM: A Cross-View Deep Front-end Structure-from-Motion System for Sparse Localization in Multi-Altitude Scenes|跨视图深度前端结构从运动系统（CVD-SfM）：用于多高度场景中的稀疏定位|Yaxuan Li, Yewei Huang, Bijay Gaudel, Hamidreza Jafarnejadsani, Brendan Englot|<http://arxiv.org/pdf/2508.01936v1>|提出了一种集成跨视图变换器、深度特征和结构从运动技术的系统，实现了多高度场景下稀疏输入的鲁棒准确定位...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SoccerTrack v2: A Full-Pitch Multi-View Soccer Dataset for Game State Reconstruction|足球追踪v2：一种全场多视角足球数据集，用于比赛状态重建|Atom Scott, Ikuma Uchida, Kento Kuroda, Yufi Kim, Keisuke Fujii|<http://arxiv.org/pdf/2508.01802v1>|提出了全景式4K足球比赛数据集SoccerTrack v2，全面支持多目标追踪和比赛状态重建。|
|📝 更新|TSGS: Improving Gaussian Splatting for Transparent Surface Reconstruction via Normal and De-lighting Priors|TSGS：通过法线和去光照先验改进高斯散点绘制算法以实现透明表面重建|Mingwei Li, Pu Pang, Hehe Fan, Hua Huang, Yi Yang|<http://arxiv.org/pdf/2504.12799v2>|[代码](https://longxiang-ai.github.io/TSGS); 提出了一种改进的透明表面重建方法TSGS，通过分离几何学习和外观优化，实现了精确的几何重建和逼真的渲...|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Implicit Search Intent Recognition using EEG and Eye Tracking: Novel Dataset and Cross-User Prediction|使用EEG和眼动追踪的隐式搜索意图识别：新型数据集与跨用户预测|Mansi Sharma, Shuang Chen, Philipp Müller, Maurice Rekrut, Antonio Krüger|<http://arxiv.org/pdf/2508.01860v1>|提出首个用于搜索意图识别的EEG和眼动数据集，并实现了跨用户预测方法，达到与用户内预测相当的准确度。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|StreamAgent: Towards Anticipatory Agents for Streaming Video Understanding|面向流视频理解的预测性智能体：StreamAgent|Haolin Yang, Feilong Tang, Linxiao Zhao, Xiang An, Ming Hu, Huifa Li, Xinlin Zhuang, Boqian Wang .etc.|<http://arxiv.org/pdf/2508.01875v1>|提出了一种面向实时视频理解的预测性智能体StreamAgent，通过预测关键事件的时间和空间信息，提...|
|🆕 发布|Intention-Guided Cognitive Reasoning for Egocentric Long-Term Action Anticipation|以意图为导向的认知推理用于自我中心视角下的长期动作预测|Qiaohui Chu, Haoyu Zhang, Meng Liu, Yisen Feng, Haoxiang Shi, Liqiang Nie|<http://arxiv.org/pdf/2508.01742v1>|提出两阶段框架INSIGHT，利用手物交互细节和语义依赖性，通过模拟认知推理提高长期动作预测能力。|
|🆕 发布|HateClipSeg: A Segment-Level Annotated Dataset for Fine-Grained Hate Video Detection|"HateClipSeg：一种用于细粒度仇恨视频检测的片段级注释数据集"|Han Wang, Zhuoran Wang, Roy Ka-Wei Lee|<http://arxiv.org/pdf/2508.01712v1>|[代码](https://github.com/Social-AI-Studio/HateClipSeg.git.); 提出HateClipSeg数据集，包含细粒度标注，用于提升视频仇恨言论检测准确度。|
|📝 更新|CoT-Vid: Dynamic Chain-of-Thought Routing with Self Verification for Training-Free Video Reasoning|《CoT-Vid：基于自我验证的无训练视频推理动态思维链路由》|Hongbo Jin, Ruyang Liu, Wenhao Zhang, Guibo Luo, Ge Li|<http://arxiv.org/pdf/2505.11830v2>|提出了CoT-Vid，一种无需训练的视频推理新范式，通过动态推理路径路由和自我验证实现出色性能，超越...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Spatio-temporal Continuous Network for Stochastic 3D Human Motion Prediction|用于随机三维人体运动预测的时空连续网络|Hua Yu, Yaqing Hou, Xu Gui, Shanshan Feng, Dongsheng Zhou, Qiang Zhang|<http://arxiv.org/pdf/2508.01585v1>|提出STCN方法，通过引入锚点集预测平滑且多样化的3D人体运动序列。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|From Age Estimation to Age-Invariant Face Recognition: Generalized Age Feature Extraction Using Order-Enhanced Contrastive Learning|从年龄估计到年龄不变的人脸识别：基于增强对比学习的泛化年龄特征提取|Haoyi Wang, Victor Sanchez, Chang-Tsun Li, Nathan Clarke|<http://arxiv.org/pdf/2501.01760v2>|提出了一种新框架Order-Enhanced Contrastive Learning，通过模拟自然...|
|🆕 发布|OmniEvent: Unified Event Representation Learning|OmniEvent: 统一事件表示学习|Weiqi Yan, Chenlu Lin, Youbiao Wang, Zhipeng Cai, Xiuhong Lin, Yangyang Shi, Weiquan Liu, Yu Zang|<http://arxiv.org/pdf/2508.01842v1>|[代码](https://github.com/Wickyan/OmniEvent); 提出了首个统一的动态事件表示学习框架OmniEvent，无需特定任务设计，实现了跨多种任务的最先进性...|
|📝 更新|Scaling Vision Pre-Training to 4K Resolution|将计算机视觉论文标题“Scaling Vision Pre-Training to 4K Resolution”翻译成中文为：“将视觉预训练扩展到4K分辨率”。|Baifeng Shi, Boyi Li, Han Cai, Yao Lu, Sifei Liu, Marco Pavone, Jan Kautz, Song Han .etc.|<http://arxiv.org/pdf/2503.19903v2>|将视觉预训练扩展到4K分辨率，通过局部处理和对比学习，提高了高分辨率视觉感知效率。|


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Harnessing Textual Semantic Priors for Knowledge Transfer and Refinement in CLIP-Driven Continual Learning|利用文本语义先验进行CLIP驱动的持续学习中的知识迁移与细化|Lingfeng He, De Cheng, Huaijie Wang, Nannan Wang|<http://arxiv.org/pdf/2508.01579v1>|利用文本语义先验引导CLIP驱动的持续学习，提出统一框架SECA增强知识迁移和视觉分类器语义结构。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SSVQ: Unleashing the Potential of Vector Quantization with Sign-Splitting|SSVQ：利用符号分割释放向量量化的潜力|Shuaiting Li, Juncan Deng, Chenxuan Wang, Kedong Xu, Rongtao Deng, Hong Gu, Haibin Shen, Kejie Huang|<http://arxiv.org/pdf/2503.08668v2>|[代码](https://github.com/list0830/SSVQ.); 提出Sign-Splitting VQ方法，通过分离权重符号位和码本来改善向量量化在微调阶段的限制，...|
|🆕 发布|Skip priors and add graph-based anatomical information, for point-based Couinaud segmentation|跳过先验并添加基于图的解剖信息，用于基于点的Couinaud分段|Xiaotong Zhang, Alexander Broersen, Gonnie CM van Erp, Silvia L. Pintea, Jouke Dijkstra|<http://arxiv.org/pdf/2508.01785v1>|[代码](https://github.com/ZhangXiaotong015/GrPn.); 提出了一种无需显式提供肝脏血管结构的点基Couinaud分段方法，通过图推理模块增强模型对解剖信息的...|
|📝 更新|LanternNet: A Hub-and-Spoke System to Seek and Suppress Spotted Lanternfly Populations|灯笼网：一种用于寻找和抑制斑灯蛾种群的中转站-辐射式系统|Vinil Polepalli|<http://arxiv.org/pdf/2507.20800v2>|提出了一种利用YOLOv8模型的Hub-and-Spoke机器人系统LanternNet，有效检测并...|
|🆕 发布|Improving Noise Efficiency in Privacy-preserving Dataset Distillation|提高隐私保护数据集精炼中的噪声效率|Runkai Zheng, Vishnu Asutosh Dasu, Yinong Oliver Wang, Haohan Wang, Fernando De la Torre|<http://arxiv.org/pdf/2508.01749v1>|提出新框架改善隐私保护数据精炼中噪声效率，实现更优性能与更小数据集。|
|📝 更新|Shifting AI Efficiency From Model-Centric to Data-Centric Compression|从以模型为中心到以数据为中心的AI效率转变与压缩|Xuyang Liu, Zichen Wen, Shaobo Wang, Junjie Chen, Zhishan Tao, Yubo Wang, Xiangqi Jin, Chang Zou .etc.|<http://arxiv.org/pdf/2505.19147v2>|主张将AI效率研究的重点从模型中心压缩转向数据中心压缩，通过减少训练或推理中的标记数量来提升效率。|
|🆕 发布|Rate-distortion Optimized Point Cloud Preprocessing for Geometry-based Point Cloud Compression|基于率失真优化的点云预处理方法用于几何基点云压缩|Wanhao Ma, Wei Zhang, Shuai Wan, Fuzheng Yang|<http://arxiv.org/pdf/2508.01633v1>|提出了一种结合深度学习的预处理框架，有效提升了传统几何点云压缩标准的效率。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CSLRConformer: A Data-Centric Conformer Approach for Continuous Arabic Sign Language Recognition on the Isharah Datase|CSLRConformer：基于数据驱动的Conformer方法在Isharah数据集上实现连续阿拉伯手语识别|Fatimah Mohamed Emad Elden|<http://arxiv.org/pdf/2508.01791v1>|提出了一种针对连续阿拉伯手语识别的数据驱动方法，通过特征工程和优化的模型架构显著提升了识别准确度。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OccamVTS: Distilling Vision Models to 1% Parameters for Time Series Forecasting|奥卡姆VTS：将视觉模型压缩至1%参数以进行时间序列预测|Sisuo Lyu, Siru Zhong, Weilin Ruan, Qingxiang Liu, Qingsong Wen, Hui Xiong, Yuxuan Liang|<http://arxiv.org/pdf/2508.01727v1>|提出了一种知识蒸馏框架OccamVTS，将大型视觉模型压缩至1%参数，有效提升时间序列预测准确性。|
|🆕 发布|Register Anything: Estimating "Corresponding Prompts" for Segment Anything Model|"注册一切：为 Segment Anything 模型估计“对应提示”"|Shiqi Huang, Tingfa Xu, Wen Yan, Dean Barratt, Yipeng Hu|<http://arxiv.org/pdf/2508.01697v1>|提出了一种无需训练的直接搜索对应提示的图像配准方法，通过预训练模型实现高效区域匹配。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EchoMimicV3: 1.3B Parameters are All You Need for Unified Multi-Modal and Multi-Task Human Animation|EchoMimicV3：1.3亿参数足以实现统一的多模态和多任务人类动画|Rang Meng, Yan Wang, Weipeng Wu, Ruobing Zheng, Yuming Li, Chenguang Ma|<http://arxiv.org/pdf/2507.03905v2>|EchoMimicV3通过1.3B参数的统一多模态和多任务框架，解决了传统动画生成的高计算需求和分离...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Continual Adversarial Defense|持续对抗性防御|Qian Wang, Hefei Ling, Yingwei Li, Qihao Liu, Ruoxi Jia, Ning Yu|<http://arxiv.org/pdf/2312.09481v6>|提出了一种持续适应性对抗防御框架CAD，有效应对动态演化的攻击策略。|
|🆕 发布|Beyond Vulnerabilities: A Survey of Adversarial Attacks as Both Threats and Defenses in Computer Vision Systems|超越漏洞：计算机视觉系统中对抗性攻击作为威胁与防御手段的综述|Zhongliang Guo, Yifei Qian, Yanli Li, Weiye Li, Chun Tong Lei, Shuai Zhao, Lei Fang, Ognjen Arandjelović .etc.|<http://arxiv.org/pdf/2508.01845v1>|系统分析了对抗性攻击的多样性和应用，为构建更稳健的计算机视觉系统指明研究方向。|
|🆕 发布|Benchmarking Adversarial Patch Selection and Location|对抗性补丁选择与定位基准测试|Shai Kimhi, Avi Mendlson, Moshe Kimhi|<http://arxiv.org/pdf/2508.01676v1>|构建首个全面空间基准PatchMap，提升对抗性贴片攻击的成功率。|
|📝 更新|Long-tailed Adversarial Training with Self-Distillation|长尾对抗训练与自蒸馏|Seungju Cho, Hongsin Lee, Changick Kim|<http://arxiv.org/pdf/2503.06461v2>|提出了一种针对长尾分布数据集的自蒸馏对抗训练方法，有效提升了尾类别的对抗稳健性。|


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Proactive Disentangled Modeling of Trigger-Object Pairings for Backdoor Defense|主动解耦建模触发-对象对以防御后门攻击|Kyle Stein, Andrew A. Mahyari, Guillermo Francia III, Eman El-Sheikh|<http://arxiv.org/pdf/2508.01932v1>|提出了一种主动解耦建模框架DBOM，通过视觉语言模型分离触发器和对象特征，有效防御已知和未知后门攻击...|
|🆕 发布|Lifelong Person Re-identification via Privacy-Preserving Data Replay|终身隐私保护的人物重识别通过数据重放|Mingyu Wang, Haojie Liu, Zhiyong Li, Wei Jiang|<http://arxiv.org/pdf/2508.01587v1>|提出了一种保护隐私的终身人物重识别方法，通过像素级信息浓缩和风格对齐，有效提升了跨域任务性能。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Shape Distribution Matters: Shape-specific Mixture-of-Experts for Amodal Segmentation under Diverse Occlusions|形状分布至关重要：针对多样化遮挡下的非模态分割的形状特定混合专家模型|Zhixuan Li, Yujia Liu, Chen Hui, Jeonghaeng Lee, Sanghoon Lee, Weisi Lin|<http://arxiv.org/pdf/2508.01664v1>|提出针对不同形状的稀疏混合专家模型，优化了遮挡下的完整物体分割效果。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RoboGSim: A Real2Sim2Real Robotic Gaussian Splatting Simulator|机器人高斯绘制仿真器RoboGSim：实现现实到仿真再到现实的转换|Xinhai Li, Jialin Li, Ziheng Zhang, Rui Zhang, Fan Jia, Tiancai Wang, Haoqiang Fan, Kuo-Kun Tseng .etc.|<http://arxiv.org/pdf/2411.11839v2>|[代码](https://robogsim.github.io/.); 提出RoboGSim模拟器，通过3D高斯散布和物理引擎，缩小仿真与现实的差距，提升机器人数据采集效率...|
|🆕 发布|IMU: Influence-guided Machine Unlearning|IMU：影响引导的机器遗忘|Xindi Fan, Jing Wu, Mingyi Zhou, Pengwei Liang, Dinh Phung|<http://arxiv.org/pdf/2508.01620v1>|提出了一种无需保留数据集的机器遗忘方法IMU，通过动态调整遗忘强度显著提升遗忘效果并保持模型性能。|
|🆕 发布|CLIMD: A Curriculum Learning Framework for Imbalanced Multimodal Diagnosis|CLIMD：面向不平衡多模态诊断的 curriculum 学习框架|Kai Han, Chongwen Lyu, Lele Ma, Chengxuan Qian, Siqi Ma, Zheng Pang, Jun Chen, Zhe Liu|<http://arxiv.org/pdf/2508.01594v1>|[代码](https://github.com/KHan-UJS/CLIMD.); 提出了一种针对多模态医学数据分类不平衡问题的课程学习框架，有效提高了模型对少数类的特征学习。|
|🆕 发布|Tractography-Guided Dual-Label Collaborative Learning for Multi-Modal Cranial Nerves Parcellation|基于纤维束追踪的双标签协同学习用于多模态颅神经分割|Lei Xie, Junxiong Huang, Yuanjing Feng, Qingrun Zeng|<http://arxiv.org/pdf/2508.01577v1>|提出了一种基于tractography引导的双标签协同学习网络，有效融合多模态MRI数据，提高了颅神...|
|📝 更新|Learning Disentangled Stain and Structural Representations for Semi-Supervised Histopathology Segmentation|学习分离的染色和结构表示用于半监督组织病理学分割|Ha-Hieu Pham, Nguyen Lan Vi Vu, Thanh-Huy Nguyen, Ulas Bagci, Min Xu, Trung-Nghia Le, Huy-Hieu Pham|<http://arxiv.org/pdf/2507.03923v2>|[代码](https://github.com/hieuphamha19/CSDS.); 提出了一种半监督分割框架，通过学习分离的染色和结构表示，有效应对了组织病理学图像的分割挑战。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhancing Zero-Shot Brain Tumor Subtype Classification via Fine-Grained Patch-Text Alignment|通过细粒度斑块-文本对齐增强零样本脑肿瘤亚型分类|Lubin Gan, Jing Zhang, Linhao Qu, Yijun Wang, Siying Wu, Xiaoyan Sun|<http://arxiv.org/pdf/2508.01602v1>|提出FG-PAN框架，通过精细视觉特征强化和文本描述生成提升零样本脑肿瘤亚型分类性能。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Exploring 3D Reasoning-Driven Planning: From Implicit Human Intentions to Route-Aware Activity Planning|探索三维推理驱动规划：从隐式人类意图到路径感知的活动规划|Xueying Jiang, Wenhao Li, Xiaoqin Zhang, Ling Shao, Shijian Lu|<http://arxiv.org/pdf/2503.12974v3>|提出3D Reasoning-Driven Planning方法，从隐式人类意图推理活动并生成含路径...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ROVER: Recursive Reasoning Over Videos with Vision-Language Models for Embodied Tasks|ROVER：基于视觉语言模型的视频递归推理在具身任务中的应用|Philip Schroeder, Ondrej Biza, Thomas Weng, Hongyin Luo, James Glass|<http://arxiv.org/pdf/2508.01943v1>|提出ROVER框架，通过递归分解视频轨迹，提升视觉语言模型在长视频序列推理中的准确性和效率。|
|🆕 发布|Distinguishing Target and Non-Target Fixations with EEG and Eye Tracking in Realistic Visual Scenes|在真实视觉场景中利用EEG和眼动追踪区分目标和非目标注视点|Mansi Sharma, Camilo Andrés Martínez Martínez, Benedikt Emanuel Wirth, Antonio Krüger, Philipp Müller|<http://arxiv.org/pdf/2508.01853v1>|首次利用眼动和脑电数据在真实场景中区分目标与非目标注视点，实现了83.6%的准确率。|
|🆕 发布|VPN: Visual Prompt Navigation|视觉提示导航|Shuo Feng, Zihan Wang, Yuchen Li, Rui Kong, Hengyi Cai, Shuaiqiang Wang, Gim Hee Lee, Piji Li .etc.|<http://arxiv.org/pdf/2508.01766v1>|[代码](https://github.com/farlit/VPN.); 提出视觉提示导航方法，通过在2D地图上标记轨迹指导导航，减少语言指令的模糊性。|
|📝 更新|Rethinking Visual Token Reduction in LVLMs under Cross-modal Misalignment|在跨模态失配下对轻量级视觉模型中的视觉标记缩减的再思考|Rui Xu, Yunke Wang, Yong Luo, Bo Du|<http://arxiv.org/pdf/2506.22283v2>|提出了一种视觉信息剪枝框架VisionDrop，通过视觉内部注意力实现高效视觉token选择，减少计...|
|🆕 发布|Measuring and Predicting Where and When Pathologists Focus their Visual Attention while Grading Whole Slide Images of Cancer|测量和预测病理学家在评估癌症全切片图像时视觉注意力的聚焦位置与时间|Souradeep Chakraborty, Ruoyu Xue, Rajarsi Gupta, Oksana Yaskiv, Constantin Friedman, Natallia Sheuka, Dana Perez, Paul Friedman .etc.|<http://arxiv.org/pdf/2508.01668v1>|提出了一种预测病理学家在观察癌症切片时视觉注意动态分布的方法，通过两阶段模型有效预测了注意力轨迹。|
|🆕 发布|A Glimpse to Compress: Dynamic Visual Token Pruning for Large Vision-Language Models|一瞥即压缩：大型视觉语言模型的动态视觉标记剪枝|Quan-Sheng Zeng, Yunheng Li, Qilong Wang, Peng-Tao Jiang, Zuxuan Wu, Ming-Ming Cheng, Qibin Hou|<http://arxiv.org/pdf/2508.01548v1>|提出动态视觉标记剪枝框架GlimpsePrune，适应不同复杂场景，大幅提升大型视觉语言模型效率。|
|🆕 发布|MagicVL-2B: Empowering Vision-Language Models on Mobile Devices with Lightweight Visual Encoders via Curriculum Learning|MagicVL-2B：通过课程学习使用轻量级视觉编码器在移动设备上增强视觉语言模型|Yi Liu, Xiao Xu, Zeyu Xu, Meng Zhang, Yibo Li, Haoyu Chen, Junkang Zhang, Qiang Wang .etc.|<http://arxiv.org/pdf/2508.01540v1>|提出轻量级视觉编码器MagicVL-2B及多模态课程学习策略，实现移动设备上高效视觉语言模型。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GAID: Frame-Level Gated Audio-Visual Integration with Directional Perturbation for Text-Video Retrieval|GAID：基于帧级别的带方向扰动门的音频视觉集成用于文本-视频检索|Bowen Yang, Yun Cao, Chen He, Xiaosu Su|<http://arxiv.org/pdf/2508.01711v1>|[代码](https://github.com/YangBowenn/GAID.); 提出了一种融合音频视觉信息的GAID框架，通过帧级融合和方向性扰动提升文本视频检索的准确性和效率。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Cure or Poison? Embedding Instructions Visually Alters Hallucination in Vision-Language Models|“治愈还是毒药？视觉嵌入指令改变视觉语言模型中的幻觉”|Zhaochen Wang, Yiwei Wang, Yujun Cai|<http://arxiv.org/pdf/2508.01678v1>|提出Prompt-in-Image方法，通过将文本指令嵌入图像，减少视觉语言模型 hallucina...|
|📝 更新|Beyond Images: Adaptive Fusion of Visual and Textual Data for Food Classification|超越图像：视觉与文本数据的自适应融合在食品分类中的应用|Prateek Mittal, Puneet Goyal, Joohi Chauhan|<http://arxiv.org/pdf/2308.02562v3>|提出了一种自适应融合视觉和文本数据的多模态食品识别框架，显著提升了分类准确性和鲁棒性。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Collaborative Perceiver: Elevating Vision-based 3D Object Detection via Local Density-Aware Spatial Occupancy|协同感知器：通过局部密度感知空间占有率提升基于视觉的3D目标检测|Jicheng Yuan, Manh Nguyen Duc, Qian Liu, Manfred Hauswirth, Danh Le Phuoc|<http://arxiv.org/pdf/2507.21358v4>|[代码](https://github.com/jichengyuan/Collaborative-Perceiver.); 提出了一种多任务学习框架 Collaborative Perceiver，利用空间占有率信息增强视觉...|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Less is More: AMBER-AFNO -- a New Benchmark for Lightweight 3D Medical Image Segmentation|少即是多：AMBER-AFNO -- 一种轻量级三维医学图像分割新基准|Andrea Dosi, Semanto Mondal, Rajib Chandra Ghosh, Massimo Brescia, Giuseppe Longo|<http://arxiv.org/pdf/2508.01941v1>|提出了一种基于频率域操作的轻量级3D医疗图像分割方法，大幅降低模型复杂度同时保持高性能。|
|🆕 发布|IAUNet: Instance-Aware U-Net|实例感知U-Net：IAUNet|Yaroslav Prytula, Illia Tsiporenko, Ali Zeynalli, Dmytro Fishman|<http://arxiv.org/pdf/2508.01928v1>|[代码](https://github.com/SlavkoPrytula/IAUNet); 提出IAUNet模型，结合U-Net与Transformer解码器，提升生物医学图像实例分割性能。|
|🆕 发布|Medical Image De-Identification Resources: Synthetic DICOM Data and Tools for Validation|医疗图像去识别资源：合成DICOM数据与验证工具|Michael W. Rutherford, Tracy Nolan, Linmin Pei, Ulrike Wagner, Qinyan Pan, Phillip Farmer, Kirk Smith, Benjamin Kopchick .etc.|<http://arxiv.org/pdf/2508.01889v1>|开发了含合成隐私信息的DICOM数据集及评估框架，以客观评估医学图像去识别工作流程的有效性。|
|📝 更新|CheXalign: Preference fine-tuning in chest X-ray interpretation models without human feedback|CheXalign：无需人工反馈的胸片解读模型偏好微调|Dennis Hein, Zhihong Chen, Sophie Ostmeier, Justin Xu, Maya Varma, Eduardo Pontes Reis, Arne Edward Michalson, Christian Bluethgen .etc.|<http://arxiv.org/pdf/2410.07025v3>|提出了一种无需人工反馈的自动化偏好微调方法，提升了胸部X光报告生成模型的准确性。|
|🆕 发布|Joint Lossless Compression and Steganography for Medical Images via Large Language Models|通过大型语言模型实现医学图像的联合无损压缩与隐写|Pengcheng Zheng, Xiaorong Pu, Kecheng Chen, Jiaxin Huang, Meng Yang, Bai Feng, Yazhou Ren, Jianan Jiang|<http://arxiv.org/pdf/2508.01782v1>|提出了一种结合无损压缩和信息隐藏的医疗图像处理框架，通过自适应分解和分段信息隐藏算法提升压缩效率和安...|
|🆕 发布|LoRA-based methods on Unet for transfer learning in Subarachnoid Hematoma Segmentation|基于LoRA的Unet迁移学习方法在蛛网膜下腔出血分割中的应用|Cristian Minoccheri, Matthew Hodgman, Haoyuan Ma, Rameez Merchant, Emily Wittrup, Craig Williamson, Kayvan Najarian|<http://arxiv.org/pdf/2508.01772v1>|提出基于LoRA的Unet迁移学习方法，显著提升亚急性硬膜下血肿分割性能。|
|📝 更新|Probabilistic Domain Adaptation for Biomedical Image Segmentation|生物医学图像分割的概率域自适应方法|Anwai Archit, Constantin Pape|<http://arxiv.org/pdf/2303.11790v2>|[代码](https://github.com/computational-cell-analytics/Probabilistic-Domain-Adaptation.); 提出了一种概率性域自适应方法，通过采样多个分割假设来改善生物医学图像分割的泛化能力。|
|📝 更新|StyleDrive: Towards Driving-Style Aware Benchmarking of End-To-End Autonomous Driving|《StyleDrive：面向驾驶风格感知的端到端自动驾驶基准测试》|Ruiyang Hao, Bowen Jing, Haibao Yu, Zaiqing Nie|<http://arxiv.org/pdf/2506.23982v2>|首次提出针对个性化端到端自动驾驶的大规模真实世界数据集和评估基准，提升模型与人类驾驶行为的一致性。|
|📝 更新|Adaptive Label Correction for Robust Medical Image Segmentation with Noisy Labels|自适应标签校正用于带有噪声标签的稳健医学图像分割|Chengxuan Qian, Kai Han, Jianxia Ding, Lei Liu, Chongwen Lyu, Zhenlong Yuan, Jun Chen, Zhe Liu|<http://arxiv.org/pdf/2503.12218v2>|提出自适应标签校正方法，利用均值教师架构提升医学图像分割在噪声标签下的鲁棒性。|
|🆕 发布|TopoImages: Incorporating Local Topology Encoding into Deep Learning Models for Medical Image Classification|《TopoImages：将局部拓扑编码融入深度学习模型进行医学图像分类》|Pengfei Gu, Hongxiao Wang, Yejia Zhang, Huimin Li, Chaoli Wang, Danny Chen|<http://arxiv.org/pdf/2508.01574v1>|提出TopoImages方法，通过编码图像局部拓扑结构提升医学图像分类准确度。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DiffSemanticFusion: Semantic Raster BEV Fusion for Autonomous Driving via Online HD Map Diffusion|差分语义融合：通过在线高精度地图扩散实现自动驾驶的语义栅格鸟瞰图融合|Zhigang Sun, Yiru Wang, Anqing Jiang, Shuo Wang, Yu Gao, Yuwen Heng, Shouyi Zhang, An He .etc.|<http://arxiv.org/pdf/2508.01778v1>|[代码](https://github.com/SunZhigang7/DiffSemanticFusion.); 提出DiffSemanticFusion框架，融合语义栅格BEV与地图扩散，提升自动驾驶场景理解与预...|
|🆕 发布|LT-Gaussian: Long-Term Map Update Using 3D Gaussian Splatting for Autonomous Driving|LT-高斯：使用三维高斯散点法进行自动驾驶中的长期地图更新|Luqi Cheng, Zhangshuo Qi, Zijie Zhou, Chao Lu, Guangming Xiong|<http://arxiv.org/pdf/2508.01704v1>|[代码](https://github.com/ChengLuqi/LT-gaussian.); 提出了一种高效更新三维高斯地图的方法，通过融合新旧场景信息，提升了地图更新的速度和质量。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CapRecover: A Cross-Modality Feature Inversion Attack Framework on Vision Language Models|CapRecover：一种面向视觉语言模型的跨模态特征逆向攻击框架|Kedong Xiu, Sai Qian Zhang|<http://arxiv.org/pdf/2507.22828v2>|提出CapRecover框架，直接从视觉模型中间特征恢复高级语义内容，无需图像重建。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Simple Algebraic Solution for Estimating the Pose of a Camera from Planar Point Features|一种简单的代数方法用于从平面点特征估计相机姿态|Tarek Bouazza, Tarek Hamel, Claude Samson|<http://arxiv.org/pdf/2508.01836v1>|提出了一种简单的代数方法，通过平面目标上的已知点和相机测量数据估计相机姿态，增强了准确性及抗噪性。|

