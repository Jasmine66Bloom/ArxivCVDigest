## [UPDATED!] **2025-08-05** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Prior2Former -- Evidential Modeling of Mask Transformers for Assumption-Free Open-World Panoptic Segmentation|Prior2Former -- 无假设开放世界全景分割中掩膜变换器的证据建模|Sebastian Schmidt, Julius Körner, Dominik Fuchsgruber, Stefano Gasperini, Federico Tombari, Stephan Günnemann|<http://arxiv.org/pdf/2504.04841v2>|提出了一种基于证据学习的Prior2Former方法，实现了无需已知类别信息的开放世界全景分割。|
|📝 更新|Physical Degradation Model-Guided Interferometric Hyperspectral Reconstruction with Unfolding Transformer|基于物理退化模型引导的展开变换器干涉超光谱重建|Yuansheng Li, Yunhao Zou, Linwei Chen, Ying Fu|<http://arxiv.org/pdf/2506.21880v2>|[代码](https://github.com/bit1120203554/IHRUT.); 提出了一种基于物理退化模型和展开变换器的干涉成像高光谱重建方法，有效解决了数据缺乏和退化成分消除难题...|
|🆕 发布|R2GenKG: Hierarchical Multi-modal Knowledge Graph for LLM-based Radiology Report Generation|R2GenKG：基于大规模语言模型的层次化多模态知识图谱在放射科报告生成中的应用|Futian Wang, Yuhan Qiao, Xiao Wang, Fuling Wang, Yuxiang Zhang, Dengdi Sun|<http://arxiv.org/pdf/2508.03426v1>|[代码](https://github.com/Event-AHU/Medical_Image_Analysis.); 提出了一种基于大规模多模态知识图谱和深度学习模型的X光报告生成方法，有效减少了错误诊断和虚构信息的问...|
|📝 更新|Multimodal Referring Segmentation: A Survey|多模态指引用分割：综述|Henghui Ding, Song Tang, Shuting He, Chang Liu, Zuxuan Wu, Yu-Gang Jiang|<http://arxiv.org/pdf/2508.00265v2>|[代码](https://github.com/henghuiding/Awesome-Multimodal-Referring-Segmentation.); 系统梳理了多模态指引用分割领域的发展，对比了不同场景下的代表性方法。|
|📝 更新|MM-Gesture: Towards Precise Micro-Gesture Recognition through Multimodal Fusion|多模态融合实现精确微手势识别：MM-Gesture|Jihao Gu, Fei Wang, Kun Li, Yanyan Wei, Zhiliang Wu, Dan Guo|<http://arxiv.org/pdf/2507.08344v2>|[代码](https://github.com/momiji-bit/MM-Gesture.); 提出了一种多模态融合框架MM-Gesture，有效识别微手势并提升分类准确性至73.213%。|
|📝 更新|Glioblastoma Overall Survival Prediction With Vision Transformers|基于视觉变换器的胶质oblastoma总体生存预测|Yin Lin, Riccardo Barbieri, Domenico Aquino, Giuseppe Lauria, Marina Grisoli, Elena De Momi, Alberto Redaelli, Simona Ferrante|<http://arxiv.org/pdf/2508.02439v2>|利用Vision Transformers直接从MRI图像提取特征，简化了胶质oblastoma总体...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Can Large Vision-Language Models Understand Multimodal Sarcasm?|大型视觉-语言模型能理解多模态讽刺吗？|Xinyu Wang, Yue Zhang, Liqiang Jing|<http://arxiv.org/pdf/2508.03654v1>|[代码](https://github.com/cp-cp/LVLM-MSA.); 探究大型视觉语言模型在多模态讽刺分析中的表现，提出整合深度物体提取和外部概念知识的训练无关框架。|
|🆕 发布|ParticleSAM: Small Particle Segmentation for Material Quality Monitoring in Recycling Processes|粒子SAM：回收过程中材料质量监测的小粒子分割|Yu Zhou, Pelle Thielmann, Ayush Chamoli, Bruno Mirbach, Didier Stricker, Jason Rambach|<http://arxiv.org/pdf/2508.03490v1>|提出ParticleSAM模型，针对小颗粒图像进行高效分割，以自动化监测回收建筑材料质量。|
|📝 更新|WSI-LLaVA: A Multimodal Large Language Model for Whole Slide Image|全切片图像的多模态大型语言模型：WSI-LLaVA|Yuci Liang, Xinheng Lyu, Meidan Ding, Wenting Chen, Jipeng Zhang, Yuexiang Ren, Xiangjian He, Song Wu .etc.|<http://arxiv.org/pdf/2412.02141v3>|提出WSI-Bench基准和WSI-LLaVA框架，提升多模态大语言模型对全玻片图像的形态学特征理解...|
|🆕 发布|Zero-shot Shape Classification of Nanoparticles in SEM Images using Vision Foundation Models|零样本纳米颗粒SEM图像形状分类使用视觉基础模型|Freida Barnatan, Emunah Goldstein, Einav Kalimian, Orchen Madar, Avi Huri, David Zitoun, Ya'akov Mandelbaum, Moshe Amitay|<http://arxiv.org/pdf/2508.03235v1>|提出了一种无需大量标注数据的高效纳米粒子形状分类方法，结合了基础视觉模型进行精确分类。|
|📝 更新|Predicting EGFR Mutation in LUAD from Histopathological Whole-Slide Images Using Pretrained Foundation Model and Transfer Learning: An Indian Cohort Study|利用预训练基础模型和迁移学习从LUAD组织病理学全切片图像预测EGFR突变：一项印度队列研究|Sagar Singh Gwal, Rajan, Suyash Devgan, Shraddhanjali Satapathy, Abhishek Goyal, Nuruddin Mohammad Iqbal, Vivaan Jain, Prabhat Singh Mallik .etc.|<http://arxiv.org/pdf/2508.01352v2>|提出了一种基于视觉变换器和多实例学习的框架，用于从病理切片预测EGFR突变状态，实现高准确率。|
|🆕 发布|Multi-Granularity Feature Calibration via VFM for Domain Generalized Semantic Segmentation|通过VFM进行多粒度特征校准以实现域泛化语义分割|Xinhui Li, Xiaojie Guo|<http://arxiv.org/pdf/2508.03007v1>|提出多粒度特征校准框架，通过逐层优化视觉基础模型特征，提升跨域语义分割的泛化能力。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Franca: Nested Matryoshka Clustering for Scalable Visual Representation Learning|“Franca: 可扩展视觉表征学习的嵌套套娃聚类算法”|Shashanka Venkataramanan, Valentinos Pariza, Mohammadreza Salehi, Lukas Knobel, Spyros Gidaris, Elias Ramzi, Andrei Bursuc, Yuki M. Asano|<http://arxiv.org/pdf/2507.14137v2>|[代码](https://github.com/valeoai/Franca.); 提出 Franca 模型，通过嵌套 Matryoshka 聚类优化视觉特征学习，提升模型性能与效率。|
|🆕 发布|Speech-to-LaTeX: New Models and Datasets for Converting Spoken Equations and Sentences|语音转LaTeX：用于将口头方程和句子转换为LaTeX的新模型和数据集|Dmitrii Korzh, Dmitrii Tarasov, Artyom Iudin, Elvir Karimov, Matvey Skripkin, Nikita Kuzmin, Andrey Kuznetsov, Oleg Y. Rogov .etc.|<http://arxiv.org/pdf/2508.03542v1>|提出首个大规模开源数据集，并利用音频语言模型显著提升将口头数学表达式转换为LaTeX的准确率。|
|🆕 发布|Semantic Mosaicing of Histo-Pathology Image Fragments using Visual Foundation Models|使用视觉基础模型对组织病理学图像片段进行语义马赛克处理|Stefan Brandstätter, Maximilian Köller, Philipp Seeböck, Alissa Blessing, Felicitas Oberndorfer, Svitlana Pochepnia, Helmut Prosch, Georg Langs|<http://arxiv.org/pdf/2508.03524v1>|提出了一种基于视觉基础模型的语义拼接方法，有效解决了组织病理学图像碎片自动拼接的难题。|
|📝 更新|Aether Weaver: Multimodal Affective Narrative Co-Generation with Dynamic Scene Graphs|“以太编织者：基于动态场景图的跨模态情感叙事协同生成”|Saeed Ghorbani|<http://arxiv.org/pdf/2507.21893v2>|提出了一种集成框架Aether Weaver，实现了文本、视觉和声音的同步生成，提升了叙事深度、视觉...|
|🆕 发布|FedPromo: Federated Lightweight Proxy Models at the Edge Bring New Domains to Foundation Models|联邦轻量级代理模型在边缘带来新领域的基础模型：FedPromo|Matteo Caligiuri, Francesco Barbato, Donald Shenaj, Umberto Michieli, Pietro Zanuttigh|<http://arxiv.org/pdf/2508.03356v1>|提出FedPromo框架，通过在边缘设备上训练轻量级代理模型，有效适应远程客户端的新领域，降低计算负...|
|📝 更新|LMME3DHF: Benchmarking and Evaluating Multimodal 3D Human Face Generation with LMMs|LMME3DHF：基于LMMs的多模态三维人脸生成基准测试与评估|Woo Yi Yang, Jiarui Wang, Sijing Wu, Huiyu Duan, Yuxin Zhu, Liu Yang, Kang Fu, Guangtao Zhai .etc.|<http://arxiv.org/pdf/2504.20466v3>|提出了一种基于大型多模态模型的3D人脸质量评估方法，实现了高精度评分预测和视觉问题解答。|
|📝 更新|AudioGen-Omni: A Unified Multimodal Diffusion Transformer for Video-Synchronized Audio, Speech, and Song Generation|音频生成全景：一种用于视频同步音频、语音和歌曲生成的统一多模态扩散变压器模型|Le Wang, Jun Wang, Feng Deng, Chen Zhang, Di Zhang, Kun Gai|<http://arxiv.org/pdf/2508.00733v3>|提出了一种统一的多模态扩散变换器AudioGen-Omni，实现了与视频同步的高保真音频、语音和歌曲...|
|📝 更新|CutPaste&Find: Efficient Multimodal Hallucination Detector with Visual-aid Knowledge Base|剪贴寻踪：基于视觉辅助知识库的高效多模态幻觉检测器|Cong-Duy Nguyen, Xiaobao Wu, Duc Anh Vu, Shuai Zhao, Thong Nguyen, Anh Tuan Luu|<http://arxiv.org/pdf/2502.12591v2>|提出了一种高效的无需训练的CutPaste&Find框架，利用视觉和语言模块检测大型视觉语言模型中的...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OmniShape: Zero-Shot Multi-Hypothesis Shape and Pose Estimation in the Real World|全方位形状：现实世界中的零样本多假设形状与姿态估计|Katherine Liu, Sergey Zakharov, Dian Chen, Takuya Ikeda, Greg Shakhnarovich, Adrien Gaidon, Rares Ambrus|<http://arxiv.org/pdf/2508.03669v1>|[代码](https://tri-ml.github.io/omnishape); 提出了一种无需已知3D模型或类别的零样本多假设形状与姿态估计方法OmniShape，实现了概率性姿态...|
|🆕 发布|FPG-NAS: FLOPs-Aware Gated Differentiable Neural Architecture Search for Efficient 6DoF Pose Estimation|FPG-NAS：面向效率的6自由度位姿估计的FLOPs感知门控可微分神经架构搜索|Nassim Ali Ousalah, Peyman Rostami, Anis Kacem, Enjie Ghorbel, Emmanuel Koumandakis, Djamila Aouada|<http://arxiv.org/pdf/2508.03618v1>|提出FPG-NAS，一种针对6DoF位姿估计的高效可微分神经架构搜索框架，平衡了准确性与计算效率。|
|🆕 发布|RadProPoser: A Framework for Human Pose Estimation with Uncertainty Quantification from Raw Radar Data|雷达数据驱动的含不确定性量化的姿态估计框架：RadProPoser|Jonas Leo Mueller, Lukas Engel, Eva Dorschky, Daniel Krauss, Ingrid Ullmann, Martin Vossiek, Bjoern M. Eskofier|<http://arxiv.org/pdf/2508.03578v1>|RadProPoser通过概率编码器-解码器架构处理雷达数据，实现了高精度的人体姿态估计并量化了每关...|
|🆕 发布|CoPS: Conditional Prompt Synthesis for Zero-Shot Anomaly Detection|CoPS：零样本异常检测的条件提示合成|Qiyu Chen, Zhen Qu, Wei Luo, Haiming Yao, Yunkang Cao, Yuxin Jiang, Yinan Duan, Huiyuan Luo .etc.|<http://arxiv.org/pdf/2508.03447v1>|[代码](https://github.com/cqylunlun/CoPS.); 提出动态生成提示的CoPS框架，通过视觉特征适应性地增强零样本异常检测性能。|
|🆕 发布|Beyond Illumination: Fine-Grained Detail Preservation in Extreme Dark Image Restoration|超越光照：极端暗图像恢复中的细粒度细节保持|Tongshun Zhang, Pingping Liu, Zixuan Zhong, Zijian Zhang, Qiuzhan Zhou|<http://arxiv.org/pdf/2508.03336v1>|[代码](https://github.com/bywlzts/RFGM.); 提出了一种双阶段图像恢复方法，通过残差傅里叶引导模块和Mamba模块有效恢复暗图中精细细节。|
|🆕 发布|MVTOP: Multi-View Transformer-based Object Pose-Estimation|多视角Transformer基础上的目标位姿估计：MVTOP|Lukas Ranftl, Felix Brendel, Bertram Drost, Carsten Steger|<http://arxiv.org/pdf/2508.03243v1>|提出了一种基于多视角Transformer的物体姿态估计方法，通过早期融合视图特定特征解决了单视角无...|
|🆕 发布|Open-Vocabulary HOI Detection with Interaction-aware Prompt and Concept Calibration|开放词汇的交互行为检测：基于交互感知提示与概念校准|Ting Lei, Shaofeng Yin, Qingchao Chen, Yuxin Peng, Yang Liu|<http://arxiv.org/pdf/2508.03207v1>|[代码](https://github.com/ltttpku/INP-CC.); 提出了一种结合交互感知提示和概念校准的开放词汇人类-物体交互检测方法，有效提升了对新颖交互类别的检测...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Causal Framework for Aligning Image Quality Metrics and Deep Neural Network Robustness|一个用于对齐图像质量指标与深度神经网络鲁棒性的因果框架|Nathan Drenkow, Mathias Unberath|<http://arxiv.org/pdf/2503.02797v2>|提出了一种新框架，将图像质量评估与深度神经网络性能紧密结合，提高了对图像数据集质量分布的预测准确性。|
|📝 更新|Learning Interpretable Queries for Explainable Image Classification with Information Pursuit|学习可解释查询以实现基于信息追踪的可解释图像分类|Stefan Kolek, Aditya Chattopadhyay, Kwan Ho Ryan Chan, Hector Andrade-Loarca, Gitta Kutyniok, Réne Vidal|<http://arxiv.org/pdf/2312.11548v2>|学习数据集直接生成的可解释查询字典，显著优于专家或大型语言模型构建的手工查询字典。|
|🆕 发布|Contrastive Cross-Bag Augmentation for Multiple Instance Learning-based Whole Slide Image Classification|对比跨包增强的多实例学习基于全切片图像分类|Bo Zhang, Xu Xinan, Shuo Yan, Yu Bai, Zheng Zhang, Wufan Wang, Wendong Wang|<http://arxiv.org/pdf/2508.03081v1>|提出了一种增强多样性的对比跨包增强方法，通过提高特征区分度来提升全切片图像分类性能。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Talking to DINO: Bridging Self-Supervised Vision Backbones with Language for Open-Vocabulary Segmentation|与DINO对话：将自监督视觉主干网络与语言结合实现开放词汇分割|Luca Barsellotti, Lorenzo Bianchi, Nicola Messina, Fabio Carrara, Marcella Cornia, Lorenzo Baraldi, Fabrizio Falchi, Rita Cucchiara|<http://arxiv.org/pdf/2411.19331v2>|[代码](https://lorebianchi98.github.io/Talk2DINO); 提出了一种结合DINOv2视觉模型与CLIP语言理解的Talk2DINO方法，实现了无需微调的开放词...|
|🆕 发布|Trace3D: Consistent Segmentation Lifting via Gaussian Instance Tracing|Trace3D：通过高斯实例追踪的一致性分割提升|Hongyu Shen, Junfeng Ni, Yixin Chen, Weishuo Li, Mingtao Pei, Siyuan Huang|<http://arxiv.org/pdf/2508.03227v1>|提出了一种通过Gaussian Instance Tracing实现2D到3D视觉分割一致性提升的方...|
|📝 更新|SemiSegECG: A Multi-Dataset Benchmark for Semi-Supervised Semantic Segmentation in ECG Delineation|半监督心电图语义分割的多数据集基准：SemiSegECG|Minje Park, Jeonghwa Lim, Taehyung Yu, Sunghoon Joo|<http://arxiv.org/pdf/2507.18323v2>|提出了SemiSegECG，首个针对心电信号半监督语义分割的统一基准，提升了ECG波形特征分割的性能...|
|🆕 发布|Neovascularization Segmentation via a Multilateral Interaction-Enhanced Graph Convolutional Network|通过多边交互增强图卷积网络进行新生血管分割|Tao Chen, Dan Zhang, Da Chen, Huazhu Fu, Kai Jin, Shanshan Wang, Laurent D. Cohen, Yitian Zhao .etc.|<http://arxiv.org/pdf/2508.03197v1>|提出首个公开可用的CNV数据集，并设计了一种结合多边交互的图卷积网络，有效提升了脉络膜新生血管的分割...|
|🆕 发布|CHARM: Collaborative Harmonization across Arbitrary Modalities for Modality-agnostic Semantic Segmentation|CHARM：跨任意模态的协作谐调以实现模态无关的语义分割|Lekang Wen, Jing Xiao, Liang Liao, Jiajun Chen, Mi Wang|<http://arxiv.org/pdf/2508.03060v1>|提出CHARM框架，通过互补学习实现跨模态协同，而非同质化，提升模态无关语义分割性能。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LRDDv2: Enhanced Long-Range Drone Detection Dataset with Range Information and Comprehensive Real-World Challenges|LRDDv2：增强型长距离无人机检测数据集，包含距离信息与全面现实世界挑战|Amirreza Rouhi, Sneh Patel, Noah McCarthy, Siddiqa Khan, Hadi Khorsand, Kaleb Lefkowitz, David K. Han|<http://arxiv.org/pdf/2508.03331v1>|提出了LRDDv2数据集，包含39,516张图像和8,000张图像的距离信息，助力无人机远距离检测与...|
|🆕 发布|Architectural Insights into Knowledge Distillation for Object Detection: A Comprehensive Review|对象检测中知识蒸馏的架构洞察：全面回顾|Mahdi Golizadeh, Nassibeh Golizadeh, Mohammad Ali Keyvanrad, Hossein Shirazi|<http://arxiv.org/pdf/2508.03317v1>|提出架构中心的知识蒸馏分类法，优化对象检测在资源受限设备上的效率和准确性。|
|🆕 发布|Unifying Locality of KANs and Feature Drift Compensation for Data-free Continual Face Forgery Detection|统一KANs的局部性和特征漂移补偿以实现无需数据的面部伪造持续检测|Tianshuo Zhang, Siran Peng, Li Gao, Haoyuan Zhang, Xiangyu Zhu, Zhen Lei|<http://arxiv.org/pdf/2508.03189v1>|提出了一种基于KAN的持续人脸伪造检测框架，通过域分组和特征分离策略有效解决了灾难性遗忘问题。|
|🆕 发布|Uint: Building Uint Detection Dataset|构建Uint检测数据集|Haozhou Zhai, Yanzhe Gao, Tianjiang Hu|<http://arxiv.org/pdf/2508.03139v1>|[代码](https://github.com/boilermakerr/FireUnitData.); 构建了首个针对建筑单元的无人机采集火灾数据集，增强模型泛化能力并降低数据采集风险成本。|
|🆕 发布|Adversarial Attention Perturbations for Large Object Detection Transformers|对抗性注意力扰动用于大型目标检测变换器|Zachary Yahn, Selim Furkan Tekin, Fatih Ilhan, Sihao Hu, Tiansheng Huang, Yichang Xu, Margaret Loper, Ling Liu|<http://arxiv.org/pdf/2508.02987v1>|[代码](https://github.com/zacharyyahn/AFOG.); 提出了一种针对大型对象检测变换器的注意力聚焦攻击方法，有效提升了攻击性能并保持了视觉不可见性。|
|📝 更新|UniDet-D: A Unified Dynamic Spectral Attention Model for Object Detection under Adverse Weathers|统一动态光谱注意力模型UniDet-D：用于恶劣天气下的目标检测|Wei Zhang, Yuantao Wang, Haowei Yang, Yin Zhuang, Shijian Lu, Xuerui Mao|<http://arxiv.org/pdf/2506.12324v2>|提出UniDet-D模型，通过动态光谱注意力机制提升各种恶劣天气条件下目标检测的准确性和泛化能力。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LongVie: Multimodal-Guided Controllable Ultra-Long Video Generation|《LongVie：多模态引导的可控超长视频生成》|Jianxiong Gao, Zhaoxi Chen, Xian Liu, Jianfeng Feng, Chenyang Si, Yanwei Fu, Yu Qiao, Ziwei Liu|<http://arxiv.org/pdf/2508.03694v1>|提出了一种用于可控超长视频生成的端到端框架，通过多模态引导和一致性策略解决了时间一致性和视觉退化问题...|
|🆕 发布|LiDARCrafter: Dynamic 4D World Modeling from LiDAR Sequences|LiDARCrafter：从LiDAR序列中动态构建四维世界模型|Ao Liang, Youquan Liu, Yu Yang, Dongyue Lu, Linfeng Li, Lingdong Kong, Huaici Zhao, Wei Tsang Ooi|<http://arxiv.org/pdf/2508.03692v1>|提出LiDARCrafter框架，通过自然语言输入生成动态4D LiDAR模型，实现高精度场景建模与...|
|🆕 发布|La La LiDAR: Large-Scale Layout Generation from LiDAR Data|《拉拉激光雷达：从激光雷达数据生成大规模布局》|Youquan Liu, Lingdong Kong, Weidong Yang, Xin Li, Ao Liang, Runnan Chen, Ben Fei, Tongliang Liu|<http://arxiv.org/pdf/2508.03691v1>|提出La La LiDAR模型，通过场景图引导生成结构化LiDAR场景，实现对象放置的定制化控制。|
|🆕 发布|Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?|我们是否在正确评估文档检索增强生成的道路上？|Wenxuan Shen, Mingjia Wang, Yaochen Wang, Dongping Chen, Junjie Yang, Yao Wan, Weiwei Lin|<http://arxiv.org/pdf/2508.03644v1>|提出全面评估文档检索增强生成系统的Double-Bench框架，解决了现有评价方法不足的问题。|
|📝 更新|TextMaster: A Unified Framework for Realistic Text Editing via Glyph-Style Dual-Control|文本大师：通过字形风格双控实现真实文本编辑的统一框架|Zhenyu Yan, Jian Wang, Aoqiang Wang, Yuhan Li, Wenxiang Shang, Ran Lin|<http://arxiv.org/pdf/2410.09879v2>|提出TextMaster框架，实现高精度文本编辑与可控风格转换，提升复杂文本编辑准确性和风格控制能力...|
|🆕 发布|MAUP: Training-free Multi-center Adaptive Uncertainty-aware Prompting for Cross-domain Few-shot Medical Image Segmentation|MAUP：无需训练的多中心自适应不确定性感知提示用于跨域少样本医学图像分割|Yazhou Zhu, Haofeng Zhang|<http://arxiv.org/pdf/2508.03511v1>|[代码](https://github.com/YazhouZhu19/MAUP.); 提出了一种无需训练的多中心自适应不确定性感知提示方法，实现了跨域少量样本医学图像的精确分割。|
|🆕 发布|EditGarment: An Instruction-Based Garment Editing Dataset Constructed with Automated MLLM Synthesis and Semantic-Aware Evaluation|编辑服饰：一种基于指令的服饰编辑数据集，采用自动化多模态语言模型合成与语义感知评估构建|Deqiang Yin, Junyi Guo, Huanda Lu, Fangyu Wu, Dongming Lu|<http://arxiv.org/pdf/2508.03497v1>|[代码](https://yindq99.github.io/EditGarment-project); 构建首个面向服装编辑的指令型数据集EditGarment，通过自动化合成与语义感知评估提升数据质量。|
|🆕 发布|Draw Your Mind: Personalized Generation via Condition-Level Modeling in Text-to-Image Diffusion Models|《绘制你的思维：通过条件级建模在文本到图像扩散模型中进行个性化生成》|Hyungjin Kim, Seokho Ahn, Young-Duk Seo|<http://arxiv.org/pdf/2508.03481v1>|提出DrUM方法，通过在潜在空间进行条件级建模，实现少量用户干预下的个性化图像生成。|
|🆕 发布|LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Text-to-Image Generation|LRQ-DiT：对文本到图像生成扩散变换器的对数-旋转后训练量化|Lianwei Yang, Haokun Lin, Tianchen Zhao, Yichen Wu, Hongyu Zhu, Ruiqi Xie, Zhenan Sun, Yu Wang .etc.|<http://arxiv.org/pdf/2508.03485v1>|提出了一种针对DiT模型的高效准确的后训练量化框架LRQ-DiT，通过双对数量化和自适应旋转策略减少...|
|🆕 发布|RAAG: Ratio Aware Adaptive Guidance|比例感知自适应引导|Shangwen Zhu, Qianyu Peng, Yuting Hu, Zhantao Yang, Han Zhang, Zhao Pu, Ruili Feng, Fan Cheng|<http://arxiv.org/pdf/2508.03442v1>|提出了一种针对生成模型采样过程中的指导不稳定性问题，自动调整指导强度的方法，实现了更快采样同时保持或...|
|🆕 发布|READ: Real-time and Efficient Asynchronous Diffusion for Audio-driven Talking Head Generation|《READ：面向音频驱动说话人头生成的实时高效异步扩散》|Haotian Wang, Yuzhe Weng, Jun Du, Haoran Xu, Xiaoyan Wu, Shan He, Bing Yin, Cong Liu .etc.|<http://arxiv.org/pdf/2508.03457v1>|提出了一种实时高效的异步扩散方法，通过压缩视频和语音潜在空间，实现了快速生成高质量的音频驱动谈话头部...|
|📝 更新|FLUX-Text: A Simple and Advanced Diffusion Transformer Baseline for Scene Text Editing|FLUX-Text：一种简单且先进的用于场景文本编辑的扩散变换器基线|Rui Lan, Yancheng Bai, Xu Duan, Mingxing Li, Dongyang Jin, Ryan Xu, Lei Sun, Xiangxiang Chu|<http://arxiv.org/pdf/2505.03329v2>|[代码](https://github.com/AMAP-ML/FluxText.); FLUX-Text通过轻量级视觉与文本嵌入模块，有效提升了对复杂文字结构的理解和生成，大幅减少训练样...|
|🆕 发布|Skywork UniPic: Unified Autoregressive Modeling for Visual Understanding and Generation|天工统一图片：用于视觉理解和生成的统一自回归建模|Peiyu Wang, Yi Peng, Yimeng Gan, Liang Hu, Tianyidan Xie, Xiaokun Wang, Yichen Wei, Chuanxin Tang .etc.|<http://arxiv.org/pdf/2508.03320v1>|提出了Skywork UniPic模型，统一了图像理解、文本到图像生成和图像编辑，无需特定任务适配器...|
|🆕 发布|Zero Shot Domain Adaptive Semantic Segmentation by Synthetic Data Generation and Progressive Adaptation|合成数据生成与渐进式适应的零样本域自适应语义分割|Jun Luo, Zijing Zhao, Yang Liu|<http://arxiv.org/pdf/2508.03300v1>|[代码](https://github.com/ROUJINN/SDGPA); 提出了一种生成合成数据并进行逐步适应的方法，实现了无需目标域图像的零样本域自适应语义分割。|
|📝 更新|Causally Steered Diffusion for Automated Video Counterfactual Generation|因果引导的扩散算法用于自动视频反事实生成|Nikos Spyrou, Athanasios Vlontzos, Paraskevas Pegios, Thomas Melistas, Nefeli Gkouti, Yannis Panagakis, Giorgos Papanastasiou, Sotirios A. Tsaftaris|<http://arxiv.org/pdf/2506.14404v2>|提出了一种基于文本提示的因果引导方法，实现了自动视频反事实生成的因果忠实性和视觉质量。|
|📝 更新|Personalize Your Gaussian: Consistent 3D Scene Personalization from a Single Image|个性化你的高斯：从单张图像实现一致的3D场景个性化|Yuxuan Wang, Xuanyu Yi, Qingshan Xu, Yuan Zhou, Long Chen, Hanwang Zhang|<http://arxiv.org/pdf/2505.14537v2>|[代码](https://github.com/Yuxuan-W/CP-GS.); 提出了一种框架CP-GS，通过扩展单视角信息，有效解决了3D场景个性化中的视角偏差问题。|
|📝 更新|GOBench: Benchmarking Geometric Optics Generation and Understanding of MLLMs|GOBench：几何光学生成与理解的大规模语言模型基准测试|Xiaorong Zhu, Ziheng Jia, Jiarui Wang, Xiangyu Zhao, Haodong Duan, Xiongkuo Min, Jia Wang, Zicheng Zhang .etc.|<http://arxiv.org/pdf/2506.00991v2>|[代码](https://github.com/aiben-ch/GOBench.); 提出GOBench基准，首次全面评估大型多模态语言模型在几何光学生成与理解方面的能力。|
|🆕 发布|FFHQ-Makeup: Paired Synthetic Makeup Dataset with Facial Consistency Across Multiple Styles|FFHQ-化妆：具有面部一致性跨多种风格的配对合成化妆数据集|Xingchao Yang, Shiori Ueda, Yuantian Huang, Tomoya Akiyama, Takafumi Taketomi|<http://arxiv.org/pdf/2508.03241v1>|构建了FFHQ-Makeup数据集，通过改进的妆容迁移技术保持了面部一致性，解决了高质量妆容配对图像...|
|📝 更新|NAMI: Efficient Image Generation via Bridged Progressive Rectified Flow Transformers|NAMI：通过桥接渐进修正流变换器实现的高效图像生成|Yuhang Ma, Bo Cheng, Shanyuan Liu, Hongyi Zhou, Liebucha Wu, Xiaoyu Wu, Dawei Leng, Yuhui Yin|<http://arxiv.org/pdf/2503.09242v2>|提出NAMI模型，通过多分辨率训练和BridgeFlow模块提高图像生成效率并保持质量。|
|📝 更新|Zero-shot Segmentation of Skin Conditions: Erythema with Edit-Friendly Inversion|零样本皮肤状况分割：带有编辑友好逆向的红斑分割|Konstantinos Moutselos, Ilias Maglogiannis|<http://arxiv.org/pdf/2508.01334v2>|提出了一种无需标注数据，利用生成编辑和颜色空间分析的零样本皮肤红肿检测方法。|
|📝 更新|Imbalance-Robust and Sampling-Efficient Continuous Conditional GANs via Adaptive Vicinity and Auxiliary Regularization|通过自适应邻域和辅助正则化实现的平衡鲁棒且采样高效的条件生成对抗网络|Xin Ding, Yun Chen, Yongwei Wang, Kao Zhang, Sen Zhang, Peibei Cao, Xiangxue Wang|<http://arxiv.org/pdf/2508.01725v2>|提出CcGAN-AVAR框架，通过自适应邻域和辅助正则化解决数据不平衡和采样效率问题。|
|📝 更新|Learning Only with Images: Visual Reinforcement Learning with Reasoning, Rendering, and Visual Feedback|仅通过图像学习：具有推理、渲染和视觉反馈的视觉强化学习|Yang Chen, Yufan Shen, Wenxuan Huang, Sheng Zhou, Qunshu Lin, Xinyu Cai, Zhi Yu, Jiajun Bu .etc.|<http://arxiv.org/pdf/2507.20766v3>|[代码](https://github.com/L-O-I/RRVF.); 提出了一种框架，通过纯图像输入实现复杂视觉推理，减少对图像-文本监督的依赖。|
|📝 更新|Towards Imperceptible JPEG Image Hiding: Multi-range Representations-driven Adversarial Stego Generation|面向不可感知的JPEG图像隐藏：多范围表示驱动的对抗性隐写生成|Junxue Yang, Xin Liao, Weixuan Tang, Jianhua Yang, Zheng Qin|<http://arxiv.org/pdf/2507.08343v2>|提出了一种多尺度特征驱动的JPEG图像隐写方法，有效对抗了传统检测手段，实现了视觉和隐写分析上的双重...|
|📝 更新|Long-term Traffic Simulation with Interleaved Autoregressive Motion and Scenario Generation|长时交通模拟：交织自回归运动与场景生成|Xiuyu Yang, Shuhan Tan, Philipp Krähenbühl|<http://arxiv.org/pdf/2506.17213v2>|[代码](https://orangesodahub.github.io/InfGen); 提出InfGen模型，实现闭环运动模拟与场景生成交替，显著提升长期交通模拟稳定性。|
|🆕 发布|UniEdit-I: Training-free Image Editing for Unified VLM via Iterative Understanding, Editing and Verifying|统一语言模型迭代理解、编辑与验证的无训练图像编辑：UniEdit-I|Chengyu Bai, Jintao Chen, Xiang Bai, Yilong Chen, Qi She, Ming Lu, Shanghang Zhang|<http://arxiv.org/pdf/2508.03142v1>|提出了一种无需训练的图像编辑框架UniEdit-I，通过迭代理解、编辑和验证实现了统一视觉语言模型的...|
|📝 更新|The Curse of Conditions: Analyzing and Improving Optimal Transport for Conditional Flow-Based Generation|条件的诅咒：分析并改进条件流生成中的最优传输|Ho Kei Cheng, Alexander Schwing|<http://arxiv.org/pdf/2503.10636v3>|[代码](https://hkchengrex.github.io/C2OT); 提出条件最优传输C^2OT解决无条件设置下路径直化不足问题，提高生成模型在不同条件下的性能。|
|📝 更新|Gradient as Conditions: Rethinking HOG for All-in-one Image Restoration|梯度作为条件：重新思考用于一体化图像恢复的HOG|Jiawei Wu, Zhifei Yang, Zhe Wang, Zhi Jin|<http://arxiv.org/pdf/2504.09377v2>|[代码](https://github.com/Fire-friend/HOGformer.); 提出HOGformer模型，利用HOG特征引导图像复原，提升复杂退化场景下的性能和泛化能力。|
|📝 更新|Towards Optimal Aggregation of Varying Range Dependencies in Haze Removal|面向最优聚合不同范围依赖性的雾霾去除方法|Xiaozhe Zhang, Fengying Xie, Haidong Ding, Linpeng Pan, Zhenwei Shi|<http://arxiv.org/pdf/2408.12317v3>|提出DehazeMatic模型，通过双流设计同时捕捉短程和远程依赖，优化了图像去雾中的细节和全局上下...|
|📝 更新|MeshLLM: Empowering Large Language Models to Progressively Understand and Generate 3D Mesh|《MeshLLM：赋予大型语言模型逐步理解和生成三维网格的能力》|Shuangkang Fang, I-Chao Shen, Yufeng Wang, Yi-Hsuan Tsai, Yi Yang, Shuchang Zhou, Wenrui Ding, Takeo Igarashi .etc.|<http://arxiv.org/pdf/2508.01242v2>|提出MeshLLM框架，利用大型语言模型理解和生成3D网格，通过分解策略和训练方法提升模型对3D结构...|
|📝 更新|Breaking Imitation Bottlenecks: Reinforced Diffusion Powers Diverse Trajectory Generation|打破模仿瓶颈：强化扩散助力多样化轨迹生成|Ziying Song, Lin Liu, Hongyu Pan, Bencheng Liao, Mingzhe Guo, Lei Yang, Yongchang Zhang, Shaoqing Xu .etc.|<http://arxiv.org/pdf/2507.04049v2>|提出DIVER框架，结合强化学习与扩散生成，生成多样化且可行的驾驶轨迹，解决单一示范导致的局限性。|
|📝 更新|The Promise of RL for Autoregressive Image Editing|强化学习在自回归图像编辑中的潜力|Saba Ahmadi, Rabiul Awal, Ankur Sikarwar, Amirhossein Kazemnejad, Ge Ya Luo, Juan A. Rodriguez, Sai Rajeswar, Siva Reddy .etc.|<http://arxiv.org/pdf/2508.01119v2>|[代码](https://github.com/mair-lab/EARL.); 提出了一种结合强化学习和大型多模态语言模型的图像编辑策略，实现了少量数据下的高效编辑性能。|
|🆕 发布|Multi-human Interactive Talking Dataset|多人互动对话数据集|Zeyu Zhu, Weijia Wu, Mike Zheng Shou|<http://arxiv.org/pdf/2508.03050v1>|[代码](https://github.com/showlab/Multi-human-Talking-Video-Dataset.); 构建了多人物对话视频生成的大规模数据集MIT，并提出了CovOG模型以捕捉自然对话动态。|
|🆕 发布|MoCA: Identity-Preserving Text-to-Video Generation via Mixture of Cross Attention|MoCA：通过混合交叉注意力实现身份保持的文本到视频生成|Qi Xie, Yongjia Ma, Donglin Di, Xuehao Gao, Xun Yang|<http://arxiv.org/pdf/2508.03034v1>|提出MoCA模型，通过混合交叉注意力机制增强文本到视频生成的身份一致性和细节表现。|
|📝 更新|PositionIC: Unified Position and Identity Consistency for Image Customization|《PositionIC：图像定制中的统一位置与身份一致性》|Junjie Hu, Tianyang Han, Kai Ma, Jialin Gao, Hao Dou, Song Yang, Xianhua He, Jianhui Zhang .etc.|<http://arxiv.org/pdf/2507.13861v3>|引入了PositionIC框架，通过位置和身份一致性实现多主体图像定制的高精度空间控制。|
|📝 更新|Video Is Worth a Thousand Images: Exploring the Latest Trends in Long Video Generation|视频胜过千张图片：探讨长视频生成的最新趋势|Faraz Waseem, Muhammad Shahzad|<http://arxiv.org/pdf/2412.18688v2>|探讨了长视频生成现状，提出结合生成式AI与分而治之策略以提升视频长度和制作控制。|
|🆕 发布|Towards Robust Image Denoising with Scale Equivariance|面向尺度等价性的鲁棒图像去噪|Dawei Zhang, Xiaojie Guo|<http://arxiv.org/pdf/2508.02967v1>|提出利用尺度等方差性核心偏置提升模型对非均匀噪声的泛化能力，设计了异质归一化模块和交互门控模块的图像...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Uni3R: Unified 3D Reconstruction and Semantic Understanding via Generalizable Gaussian Splatting from Unposed Multi-View Images|统一三维重建与语义理解：通过未定位多视角图像的泛化高斯散点绘制方法|Xiangyu Sun, Haoyi jiang, Liu Liu, Seungtae Nam, Gyeongjin Kang, Xinjie wang, Wei Sui, Zhizhong Su .etc.|<http://arxiv.org/pdf/2508.03643v1>|[代码](https://github.com/HorizonRobotics/Uni3R.); Uni3R通过一种创新的统一框架，直接从无定位多视角图像中实现了高效的3D场景重建和语义理解。|
|🆕 发布|CoEmoGen: Towards Semantically-Coherent and Scalable Emotional Image Content Generation|面向语义一致且可扩展的情感图像内容生成：CoEmoGen|Kaishen Yuan, Yuting Zhang, Shang Gao, Yijie Zhu, Wenshuo Chen, Yutao Yue|<http://arxiv.org/pdf/2508.03535v1>|[代码](https://github.com/yuankaishen2001/CoEmoGen.); 提出CoEmoGen模型，利用多模态大语言模型和HiLoRA模块生成语义一致且可扩展的情感图像。|
|🆕 发布|Quality Versus Sparsity in Image Recovery by Dictionary Learning Using Iterative Shrinkage|图像恢复中基于迭代收缩的字典学习质量与稀疏性比较|Mohammadsadegh Khoshghiaferezaee, Moritz Krauth, Shima Shabani, Michael Breuß|<http://arxiv.org/pdf/2508.03492v1>|探讨了稀疏字典学习在图像恢复中的最佳稀疏度，发现高稀疏度不牺牲恢复质量。|
|📝 更新|T-GVC: Trajectory-Guided Generative Video Coding at Ultra-Low Bitrates|T-GVC: 轨迹引导的超低比特率生成视频编码|Zhitao Wang, Hengyu Man, Wenrui Li, Xingtao Wang, Xiaopeng Fan, Debin Zhao|<http://arxiv.org/pdf/2507.07633v3>|提出T-GVC方法，结合低级运动跟踪与高级语义理解，实现超低比特率下视频生成与编码。|
|🆕 发布|T2UE: Generating Unlearnable Examples from Text Descriptions|T2UE: 从文本描述生成不可学习示例|Xingjun Ma, Hanxun Huang, Tianwei Song, Ye Sun, Yifeng Gao, Yu-Gang Jiang|<http://arxiv.org/pdf/2508.03091v1>|提出了一种基于文本描述生成不可学习样本的新框架，实现了无需直接暴露数据即可保护隐私。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DiWA: Diffusion Policy Adaptation with World Models|DiWA：基于世界模型的扩散策略适应|Akshay L Chandra, Iman Nematollahi, Chenguang Huang, Tim Welschehold, Wolfram Burgard, Abhinav Valada|<http://arxiv.org/pdf/2508.03645v1>|提出DiWA框架，通过使用世界模型进行离线强化学习，高效优化了扩散策略的微调过程。|
|📝 更新|FEB-Cache: Frequency-Guided Exposure Bias Reduction for Enhancing Diffusion Transformer Caching|频率引导曝光偏差减少以增强扩散变换器缓存的FEB-Cache方法|Zhen Zou, Feng Zhao|<http://arxiv.org/pdf/2503.07120v2>|提出频率指导的缓存策略FEB-Cache，减少扩散变换器中的曝光偏差，提升生成质量并加速训练。|
|🆕 发布|Advancing Wildlife Monitoring: Drone-Based Sampling for Roe Deer Density Estimation|推进野生动物监测：基于无人机的抽样方法用于估算赤鹿密度|Stephanie Wohlfahrt, Christoph Praschl, Horst Leitner, Wolfram Jantsch, Julia Konic, Silvio Schueler, Andreas Stöckl, David C. Schedl|<http://arxiv.org/pdf/2508.03545v1>|利用无人机红外与RGB影像高效估算野生动物密度，与传统方法相比具有显著优势。|
|🆕 发布|SAM2-UNeXT: An Improved High-Resolution Baseline for Adapting Foundation Models to Downstream Segmentation Tasks|SAM2-UNeXT：一种改进的高分辨率基线，用于将基础模型适配到下游分割任务|Xinyu Xiong, Zihuang Wu, Lei Zhang, Lei Lu, Ming Li, Guanbin Li|<http://arxiv.org/pdf/2508.03566v1>|[代码](https://github.com/WZH0120/SAM2-UNeXT.); 提出了一种集成辅助DINOv2编码器的高分辨率基线模型，通过双分辨率策略和密集粘合层提升了下游分割任...|
|📝 更新|Differentially Private Adaptation of Diffusion Models via Noisy Aggregated Embeddings|通过带噪声的聚合嵌入进行差分隐私自适应的扩散模型|Pura Peetathawatchai, Wei-Ning Chen, Berivan Isik, Sanmi Koyejo, Albert No|<http://arxiv.org/pdf/2411.14639v3>|提出了一种利用文本反转技术保护隐私的模型适应方法，有效提升了小数据集上的模型性能和隐私保护。|
|📝 更新|IDEATOR: Jailbreaking and Benchmarking Large Vision-Language Models Using Themselves|IDEATOR：使用自身破解和评估大型视觉-语言模型的标准基准|Ruofan Wang, Juncheng Li, Yixu Wang, Bo Wang, Xiaosen Wang, Yan Teng, Yingchun Wang, Xingjun Ma .etc.|<http://arxiv.org/pdf/2411.00827v4>|提出IDEATOR方法，自动生成恶意图像-文本对以攻击大型视觉语言模型，并构建了安全基准VLJail...|
|🆕 发布|When Cars Have Stereotypes: Auditing Demographic Bias in Objects from Text-to-Image Models|当汽车拥有刻板印象：在文本到图像模型的对象中审查人口统计偏见|Dasol Choi Jihwan Lee, Minjae Lee, Minsuk Kahng|<http://arxiv.org/pdf/2508.03483v1>|提出SODA框架，用于系统测量生成对象中的 demographic 偏见，揭示并测试了AI模型中的视...|
|🆕 发布|AVPDN: Learning Motion-Robust and Scale-Adaptive Representations for Video-Based Polyp Detection|AVPDN：用于基于视频的息肉检测的运动鲁棒和尺度自适应表征学习|Zilin Chen, Shengnan Lu|<http://arxiv.org/pdf/2508.03458v1>|提出了一种用于动态结肠镜视频的多尺度息肉检测框架，通过自适应特征交互增强和尺度感知上下文整合提高了检...|
|🆕 发布|Diffusion Once and Done: Degradation-Aware LoRA for Efficient All-in-One Image Restoration|扩散一次即可：面向高效一体化图像恢复的退化感知LoRA方法|Ni Tang, Xiaotong Luo, Zihan Cheng, Liangtai Zhou, Dongxiao Zhang, Yanyun Qu|<http://arxiv.org/pdf/2508.03373v1>|超高效的单步采样方法Diffusion Once and Done，通过特征调制与低秩适应，提升图像...|
|🆕 发布|GL-LCM: Global-Local Latent Consistency Models for Fast High-Resolution Bone Suppression in Chest X-Ray Images|全局-局部潜在一致性模型（GL-LCM）用于胸部X射线图像中快速高分辨率骨骼抑制|Yifei Sun, Zhanghao Chen, Hao Zheng, Yuqing Lu, Lixin Duan, Fenglei Fan, Ahmed Elazab, Xiang Wan .etc.|<http://arxiv.org/pdf/2508.03357v1>|[代码](https://github.com/diaoquesang/GL-LCM.); 提出GL-LCM模型，通过全局-局部融合实现胸片快速高分辨率骨抑制，提升诊断清晰度与效率。|
|🆕 发布|UniFucGrasp: Human-Hand-Inspired Unified Functional Grasp Annotation Strategy and Dataset for Diverse Dexterous Hands|统一功能性抓握标注策略与数据集：模仿人手的多样化灵巧手抓握|Haoran Lin, Wenrui Chen, Xianchi Chen, Fan Yang, Qiang Diao, Wenxin Xie, Sijie Wu, Kailun Yang .etc.|<http://arxiv.org/pdf/2508.03339v1>|[代码](https://haochen611.github.io/UFG.); 提出了UniFucGrasp策略和数据集，通过模仿人手机制提升多类型机械手的抓握功能和稳定性。|
|📝 更新|Knowledge Distillation for Underwater Feature Extraction and Matching via GAN-synthesized Images|通过GAN合成的图像进行水下特征提取与匹配的知识蒸馏|Jinghe Yang, Mingming Gong, Ye Pu|<http://arxiv.org/pdf/2504.08253v2>|[代码](https://github.com/Jinghe-mel/UFEN-GAN.); 利用生成对抗网络合成的图像，通过知识蒸馏方法将空中特征提取模型迁移至水下环境，增强了水下特征提取与匹...|
|🆕 发布|Investigation on deep learning-based galaxy image translation models|基于深度学习的星系图像转换模型研究|Hengxin Ruan, Qiufan Lin, Shupei Chen, Yang Wang, Wei Zhang|<http://arxiv.org/pdf/2508.03291v1>|探究了深度学习在保留星系高阶物理信息方面的效果，对比了四种模型在保留光谱红移信息上的差异。|
|📝 更新|Decouple and Track: Benchmarking and Improving Video Diffusion Transformers for Motion Transfer|解耦与跟踪：视频扩散变换器用于运动迁移的基准测试与改进|Qingyu Shi, Jianzong Wu, Jinbin Bai, Jiangning Zhang, Lu Qi, Yunhai Tong, Xiangtai Li|<http://arxiv.org/pdf/2503.17350v2>|提出了一种改进视频扩散变换器的方法DeT，通过引入时间核和显式轨迹监督，有效分离运动与外观，提升运动...|
|📝 更新|PhenoBench: A Comprehensive Benchmark for Cell Phenotyping|PhenoBench：细胞表型分析的全面基准测试|Claudia Winklmayr, Jerome Luescher, Nora Koreuber, Jannik Franzen, Fabian H. Reith, Elias Baumann, Christian M. Schuerch, Dagmar Kainmueller .etc.|<http://arxiv.org/pdf/2507.03532v6>|提出PhenoBench，为细胞表型分析创建了全面基准及新数据集，揭示了现有模型在泛化方面的挑战。|
|🆕 发布|Robust Single-Stage Fully Sparse 3D Object Detection via Detachable Latent Diffusion|通过可分离潜在扩散实现的鲁棒单阶段全稀疏三维目标检测|Wentao Qu, Guofeng Mei, Jing Wang, Yujiao Wu, Xiaoshui Huang, Liang Xiao|<http://arxiv.org/pdf/2508.03252v1>|提出了一种高效的3D物体检测方法RSDNet，通过单阶段稀疏特征学习和去噪机制，实现了鲁棒性和实时性...|
|🆕 发布|V.I.P. : Iterative Online Preference Distillation for Efficient Video Diffusion Models|V.I.P.：迭代在线偏好蒸馏以提高视频扩散模型效率|Jisoo Kim, Wooseok Seo, Junwan Kim, Seungho Park, Sooyeon Park, Youngjae Yu|<http://arxiv.org/pdf/2508.03254v1>|[代码](https://jiiiisoo.github.io/VIP.github.io); 提出迭代在线偏好蒸馏方法ReDPO和框架V.I.P.，减少视频生成模型参数同时保持性能。|
|🆕 发布|BadBlocks: Low-Cost and Stealthy Backdoor Attacks Tailored for Text-to-Image Diffusion Models|BadBlocks：针对文本到图像扩散模型的低成本且隐蔽的后门攻击|Yu Pan, Jiahao Chen, Lin Wang, Bingrong Dai, Yi Du|<http://arxiv.org/pdf/2508.03221v1>|提出了一种名为BadBlocks的轻量级且隐蔽的后门攻击方法，能在有限资源下有效注入后门并绕过现有防...|
|📝 更新|JointDiT: Enhancing RGB-Depth Joint Modeling with Diffusion Transformers|联合DiT：利用扩散变换器增强RGB-深度联合建模|Kwon Byung-Ki, Qi Dai, Lee Hyoseok, Chong Luo, Tae-Hyun Oh|<http://arxiv.org/pdf/2505.00482v3>|[代码](https://byungki-k.github.io/JointDiT); 提出JointDiT模型，通过自适应调度权重和不等步长采样策略，有效建模RGB与深度联合分布，实现高...|
|📝 更新|PRE-Mamba: A 4D State Space Model for Ultra-High-Frequent Event Camera Deraining|预Mamba：一种用于超高频事件相机去雨的4D状态空间模型|Ciyu Ruan, Ruishan Guo, Zihang Gong, Jingao Xu, Wenhan Yang, Xinlei Chen|<http://arxiv.org/pdf/2505.05307v2>|提出了一种4D状态空间模型，通过双时间尺度整合和时空解耦策略，有效提升了事件相机去雨技术。|
|🆕 发布|ChartCap: Mitigating Hallucination of Dense Chart Captioning|ChartCap：减轻密集图表标注的虚构现象|Junyoung Lim, Jaewoo Ahn, Gunhee Kim|<http://arxiv.org/pdf/2508.03164v1>|提出了ChartCap数据集和视觉一致性评分，有效减少了图表标注中的虚构信息。|
|🆕 发布|SARD: Segmentation-Aware Anomaly Synthesis via Region-Constrained Diffusion with Discriminative Mask Guidance|基于区域约束扩散和判别性掩膜引导的分割感知异常合成方法（SARD）|Yanshu Wang, Xichen Xu, Xiaoning Lei, Guoyang Xie|<http://arxiv.org/pdf/2508.03143v1>|提出了一种通过区域约束扩散和判别性掩膜引导的异常合成方法，有效提高了工业异常检测系统的稳健性和视觉质...|
|📝 更新|IntroStyle: Training-Free Introspective Style Attribution using Diffusion Features|《IntroStyle：基于扩散特征的无训练内省风格归因》|Anand Kumar, Jiteng Mu, Nuno Vasconcelos|<http://arxiv.org/pdf/2412.14432v2>|提出了一种无需训练的IntroStyle框架，利用扩散模型特征直接进行风格归属，性能优于现有方法。|
|📝 更新|Style Composition within Distinct LoRA modules for Traditional Art|“在区分的LoRA模块中实现传统艺术的风格组合”|Jaehyun Lee, Wonhark Park, Wonsik Shin, Hyunho Lee, Hyoung Min Na, Nojun Kwak|<http://arxiv.org/pdf/2507.11986v2>|提出了一种零样本扩散管道，通过在去噪过程中对特定风格模型进行风格组合，实现了精确的区域风格控制。|
|📝 更新|Forecasting When to Forecast: Accelerating Diffusion Models with Confidence-Gated Taylor|“预测何时进行预测：使用置信门控泰勒方法加速扩散模型”|Xiaoliu Guan, Lielin Jiang, Hanqi Chen, Xu Zhang, Jiaxing Yan, Guanzhong Wang, Yi Liu, Zetao Zhang .etc.|<http://arxiv.org/pdf/2508.02240v2>|[代码](https://cg-taylor-acce.github.io/CG-Taylor); 提出动态缓存策略，通过误差估计优化泰勒展开预测，加速扩散模型推理速度。|
|🆕 发布|Diffusion Models with Adaptive Negative Sampling Without External Resources|自适应负采样无需外部资源的扩散模型|Alakh Desai, Nuno Vasconcelos|<http://arxiv.org/pdf/2508.02973v1>|提出了一种无需外部资源的自适应负采样方法ANSWER，通过内部理解否定，提高了扩散模型对提示的忠实度...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VideoGuard: Protecting Video Content from Unauthorized Editing|视频守护者：保护视频内容免受未授权编辑|Junjie Cao, Kaizhou Li, Xinchun Yu, Hongxiang Li, Xiaoping Zhang|<http://arxiv.org/pdf/2508.03480v1>|提出VideoGuard方法，通过微调视频帧间的扰动有效抵御恶意编辑，保护视频内容不被篡改。|
|📝 更新|Individual Content and Motion Dynamics Preserved Pruning for Video Diffusion Models|个体内容与运动动态保持的剪枝策略用于视频扩散模型|Yiming Wu, Zhenghao Chen, Huan Wang, Dong Xu|<http://arxiv.org/pdf/2411.18375v3>|提出了一种基于个体内容和运动动态保留的剪枝方法，加速了视频生成模型的推理时间同时保持了视频质量。|
|📝 更新|TextCrafter: Accurately Rendering Multiple Texts in Complex Visual Scenes|《TextCrafter：在复杂视觉场景中精确渲染多个文本》|Nikai Du, Zhennan Chen, Shan Gao, Zhizhou Chen, Xi Chen, Zhengkai Jiang, Jian Yang, Ying Tai|<http://arxiv.org/pdf/2503.23461v5>|提出TextCrafter方法，通过分步渲染和增强焦点，解决了复杂场景中文字生成扭曲、遗漏的问题。|
|🆕 发布|SCFlow: Implicitly Learning Style and Content Disentanglement with Flow Models|SCFlow：使用流模型隐式学习风格与内容解耦|Pingchuan Ma, Xiaopei Yang, Yusong Li, Ming Gui, Felix Krause, Johannes Schusterbauer, Björn Ommer|<http://arxiv.org/pdf/2508.03402v1>|SCFlow通过可逆学习合并风格与内容，实现无需显式监督的自然分离。|
|🆕 发布|CIVQLLIE: Causal Intervention with Vector Quantization for Low-Light Image Enhancement|"CIVQLLIE：基于向量量化的低光图像增强因果干预"|Tongshun Zhang, Pingping Liu, Zhe Zhang, Qiuzhan Zhou|<http://arxiv.org/pdf/2508.03338v1>|提出了一种利用离散表示学习和因果推理的低光照图像增强框架，通过多级干预有效校正亮度与颜色分布偏差。|
|🆕 发布|Macro-from-Micro Planning for High-Quality and Parallelized Autoregressive Long Video Generation|从微观到宏观规划：实现高质量并行化自回归长视频生成|Xunzhi Xiang, Yabo Chen, Guiyu Zhang, Zhongyu Wang, Zhe Gao, Quanming Xiang, Gonghu Shang, Junqi Liu .etc.|<http://arxiv.org/pdf/2508.03334v1>|提出了一种长视频生成框架MMPL，通过分阶段规划关键帧实现高质量且可并行化的自动回归视频生成。|
|🆕 发布|Beyond Isolated Words: Diffusion Brush for Handwritten Text-Line Generation|超越孤立单词：用于手写文本行生成的扩散刷|Gang Dai, Yifan Zhang, Yutao Qin, Qiangya Guo, Shuangping Huang, Shuicheng Yan|<http://arxiv.org/pdf/2508.03256v1>|[代码](https://github.com/dailenson/DiffBrush.); 提出了一种基于扩散模型的手写文本行生成方法，通过解耦内容和风格学习，提高了手写文本的风格模仿和内容准...|
|📝 更新|UniCUE: Unified Recognition and Generation Framework for Chinese Cued Speech Video-to-Speech Generation|统一识别与生成框架：面向汉语提示言语视频到语音生成的UniCUE|Jinting Wang, Shan Yang, Chenxing Li, Dong Yu, Li Liu|<http://arxiv.org/pdf/2506.04134v3>|提出UniCUE框架，直接将中文手势语视频转化为语音，避免了文本中介带来的误差和时序错位问题。|
|🆕 发布|LORE: Latent Optimization for Precise Semantic Control in Rectified Flow-based Image Editing|LORE：基于校正流图像编辑的精确语义控制潜在优化|Liangyang Ouyang, Jiafeng Mao|<http://arxiv.org/pdf/2508.03144v1>|提出了一种无需训练、直接优化 inverted noise 的图像编辑方法LORE，解决了现有方法在...|
|📝 更新|D3: Training-Free AI-Generated Video Detection Using Second-Order Features|D3：基于二阶特征的无训练AI生成视频检测|Chende Zheng, Ruiqi suo, Chenhao Lin, Zhengyu Zhao, Le Yang, Shuai Liu, Minghui Yang, Cong Wang .etc.|<http://arxiv.org/pdf/2508.00701v2>|[代码](https://github.com/Zig-HS/D3.); 提出了一种无需训练的基于二阶特征的视频检测方法D3，有效区分真实与AI生成视频。|
|🆕 发布|Seeing It Before It Happens: In-Generation NSFW Detection for Diffusion-Based Text-to-Image Models|“预见未来：基于生成过程中的NSFW检测用于扩散型文本到图像模型”|Fan Yang, Yihao Huang, Jiayi Zhu, Ling Shi, Geguang Pu, Jin Song Dong, Kailong Wang|<http://arxiv.org/pdf/2508.03006v1>|提出了一种在生成过程中的NSFW内容检测方法，通过分析扩散过程中的预测噪声，实现了91.32%的平均...|
|📝 更新|Understanding and Benchmarking the Trustworthiness in Multimodal LLMs for Video Understanding|理解和评估多模态大型语言模型在视频理解中的可信度|Youze Wang, Zijun Chen, Ruoyu Chen, Shishen Gu, Wenbo Hu, Jiayang Liu, Yinpeng Dong, Hang Su .etc.|<http://arxiv.org/pdf/2506.12336v2>|提出Trust-videoLLMs，首个全面评估视频理解大型多模态语言模型可靠性的基准。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Graph Attention-Driven Bayesian Deep Unrolling for Dual-Peak Single-Photon Lidar Imaging|图注意力驱动的贝叶斯深度展开算法用于双峰单光子雷达成像|Kyungmin Choi, JaKeoung Koo, Stephen McLaughlin, Abderrahim Halimi|<http://arxiv.org/pdf/2504.02480v2>|提出了一种结合图注意力与贝叶斯深度展开的算法，用于提高双峰单光子雷达成像在复杂场景下的准确性和不确定...|
|📝 更新|Low-Frequency First: Eliminating Floating Artifacts in 3D Gaussian Splatting|先从低频开始：在三维高斯散点绘制中消除浮动物体瑕疵|Jianchao Wang, Peng Zhou, Cen Li, Rong Quan, Jie Qin|<http://arxiv.org/pdf/2508.02493v2>|[代码](https://jcwang-gh.github.io/EFA-GS.); 提出了一种消除3D重建中漂浮伪影的方法，通过优化高斯分布学习低频信息，显著提升了视觉质量。|
|📝 更新|3DRot: 3D Rotation Augmentation for RGB-Based 3D Tasks|三维旋转增强：基于RGB的三维任务中的三维旋转增强|Shitian Yang, Deyu Li, Xiaoke Jiang, Lei Zhang|<http://arxiv.org/pdf/2508.01423v2>|提出了3DRot方法，通过保持几何一致性旋转和反射图像，有效解决了RGB-based 3D任务中的数...|
|🆕 发布|H3R: Hybrid Multi-view Correspondence for Generalizable 3D Reconstruction|H3R：混合多视角对应关系用于通用三维重建|Heng Jia, Linchao Zhu, Na Zhao|<http://arxiv.org/pdf/2508.03118v1>|[代码](https://github.com/JiaHeng-DLUT/H3R.); 提出了一种融合显式和隐式重建优点的H3R框架，通过结合体积潜融合和基于注意力的特征聚合，实现了更快的...|
|🆕 发布|RobustGS: Unified Boosting of Feedforward 3D Gaussian Splatting under Low-Quality Conditions|鲁棒GS：在低质量条件下统一增强前馈3D高斯散点绘制|Anran Wu, Long Peng, Xin Di, Xueyuan Dai, Chen Wu, Yang Wang, Xueyang Fu, Yang Cao .etc.|<http://arxiv.org/pdf/2508.03077v1>|提出RobustGS模块，增强3D重建在低质量图像条件下的鲁棒性，实现高质量三维重构。|
|📝 更新|Unifying Appearance Codes and Bilateral Grids for Driving Scene Gaussian Splatting|统一外观码与双边网格进行驾驶场景高斯散点绘制|Nan Wang, Yuantao Chen, Lixing Xiao, Weiqing Xiao, Bohan Li, Zhaoxi Chen, Chongjie Ye, Shaocong Xu .etc.|<http://arxiv.org/pdf/2506.05280v3>|提出了一种统一外观码和双边网格的多尺度方法，显著提升了动态驾驶场景重建的几何精度。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Dynamic 2D Gaussians: Geometrically Accurate Radiance Fields for Dynamic Objects|动态二维高斯分布：动态物体的几何精确辐射场|Shuai Zhang, Guanjun Wu, Zhoufeng Xie, Xinggang Wang, Bin Feng, Wenyu Liu|<http://arxiv.org/pdf/2409.14072v2>|[代码](https://github.com/hustvl/Dynamic-2DGS.); 提出了一种名为Dynamic 2D Gaussians的新方法，能从稀疏图像输入重建高质量动态对象网...|
|🆕 发布|DepthGait: Multi-Scale Cross-Level Feature Fusion of RGB-Derived Depth and Silhouette Sequences for Robust Gait Recognition|深度步态：基于RGB-D导出的深度与轮廓序列的多尺度跨层级特征融合用于鲁棒步态识别|Xinzhu Li, Juepeng Zheng, Yikun Chen, Xudong Mao, Guanghui Yue, Wei Zhou, Chenlei Lv, Ruomei Wang .etc.|<http://arxiv.org/pdf/2508.03397v1>|提出DepthGait框架，融合RGB图像生成的深度图和轮廓，提升步态识别的准确性和鲁棒性。|
|📝 更新|Taking Language Embedded 3D Gaussian Splatting into the Wild|将自然语言嵌入的3D高斯散点绘制技术应用于野外环境|Yuze Wang, Yue Qi|<http://arxiv.org/pdf/2507.19830v2>|提出了一种结合自然语言处理与3D重建技术的新框架，实现了对建筑元素三维结构的开放式理解。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Monocular Depth Estimation with Global-Aware Discretization and Local Context Modeling|单目深度估计：全局感知离散化与局部上下文建模|Heng Wu, Qian Zhang, Guixu Zhang|<http://arxiv.org/pdf/2508.03186v1>|提出了一种结合全局感知与局部信息捕捉的深度估计方法，有效提升了单目深度估计的准确性。|


## 时序视觉分析 (Temporal Visual Analysis)


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Trokens: Semantic-Aware Relational Trajectory Tokens for Few-Shot Action Recognition|“Trokens：面向少样本动作识别的语义感知关系轨迹标记”|Pulkit Kumar, Shuaiyi Huang, Matthew Walmer, Sai Saketh Rambhatla, Abhinav Shrivastava|<http://arxiv.org/pdf/2508.03695v1>|提出了一种将轨迹点转化为语义感知关系性标记的方法，有效结合运动与外观信息，提升少量样本动作识别性能。|
|🆕 发布|EgoPrompt: Prompt Pool Learning for Egocentric Action Recognition|自我提示：用于自我中心动作识别的提示池学习|Huaihai Lyu, Chaofan Chen, Yuheng Ji, Changsheng Xu|<http://arxiv.org/pdf/2508.03266v1>|提出了一种基于prompt学习的框架EgoPrompt，通过构建统一Prompt池空间增强动作识别的...|
|📝 更新|Motion Matters: Motion-guided Modulation Network for Skeleton-based Micro-Action Recognition|运动至关重要：基于运动的调制网络用于基于骨架的微动作识别|Jihao Gu, Kun Li, Fei Wang, Yanyan Wei, Zhiliang Wu, Hehe Fan, Meng Wang|<http://arxiv.org/pdf/2507.21977v2>|[代码](https://github.com/momiji-bit/MMN.); 提出了一种Motion-guided Modulation Network，通过捕捉和调制微妙动作变...|
|🆕 发布|MoExDA: Domain Adaptation for Edge-based Action Recognition|MoExDA：基于边缘的动作识别领域自适应|Takuya Sugimoto, Ning Ding, Toru Tamaki|<http://arxiv.org/pdf/2508.02981v1>|提出MoExDA方法，通过融合RGB与边缘信息，有效减轻动作识别中的静态偏差问题。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning|“发生了什么以及可能发生了什么？面向过程感知视频表征学习的状态变化反事实”|Chi-Hsi Kung, Frangil Ramirez, Juhyung Ha, Yi-Ting Chen, David Crandall, Yi-Hsuan Tsai|<http://arxiv.org/pdf/2503.21055v5>|引入状态变化描述和反事实推理，提升视频表示学习对程序性活动的理解和错误预测能力。|
|🆕 发布|Video Demoireing using Focused-Defocused Dual-Camera System|使用聚焦-散焦双摄像头系统的视频去摩尔纹处理|Xuan Dong, Xiangyuan Sun, Xia Wang, Jian Song, Ya Li, Weixin Li|<http://arxiv.org/pdf/2508.03449v1>|提出了一种双摄像头系统，通过一个聚焦和一个散焦视频联合去摩尔纹，有效区分摩尔纹和真实纹理，并保持图像...|
|🆕 发布|AVATAR: Reinforcement Learning to See, Hear, and Reason Over Video|AVATAR：通过强化学习对视频进行观察、听辨和推理|Yogesh Kulkarni, Pooyan Fazli|<http://arxiv.org/pdf/2508.03100v1>|提出了一种多模态视频推理框架AVATAR，通过离策略训练和时序优势塑造解决了数据效率低和信用分配问题...|
|🆕 发布|Enhancing Long Video Question Answering with Scene-Localized Frame Grouping|增强长视频问答的场景定位帧分组方法|Xuyi Yang, Wenhao Zhang, Hongbo Jin, Lin Liu, Hongbo Xu, Yongwei Nie, Fei Yu, Fei Ma|<http://arxiv.org/pdf/2508.03009v1>|提出场景感知的帧组合方法SLFG，提升长视频理解能力。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Evaluating the Predictive Value of Preoperative MRI for Erectile Dysfunction Following Radical Prostatectomy|评估术前MRI对根治性前列腺切除术后勃起功能障碍预测价值的研究|Gideon N. L. Rouwendaal, Daniël Boeke, Inge L. Cox, Henk G. van der Poel, Margriet C. van Dijk-de Haan, Regina G. H. Beets-Tan, Thierry N. Boellaard, Wilson Silva|<http://arxiv.org/pdf/2508.03461v1>|探究MRI对术后勃起功能障碍预测的额外价值，融合临床特征与成像数据模型仅带来边际提升。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SlotMatch: Distilling Temporally Consistent Object-Centric Representations for Unsupervised Video Segmentation|槽匹配：为无监督视频分割提取时间一致性的以对象为中心的表征|Diana-Nicoleta Grigore, Neelu Madan, Andreas Mogelmose, Thomas B. Moeslund, Radu Tudor Ionescu|<http://arxiv.org/pdf/2508.03411v1>|提出了一种基于知识蒸馏的轻量级无监督视频分割框架SlotMatch，实现了参数减少和性能提升。|
|🆕 发布|BaroPoser: Real-time Human Motion Tracking from IMUs and Barometers in Everyday Devices|《BaroPoser：利用惯性测量单元和气压计在日常设备中实现实时人体运动跟踪》|Libo Zhang, Xinyu Yi, Feng Xu|<http://arxiv.org/pdf/2508.03313v1>|融合IMU与气压计数据，BaroPoser实现了实时人体运动跟踪，提升了非平坦地形下的姿态估计精度。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|evTransFER: A Transfer Learning Framework for Event-based Facial Expression Recognition|基于事件的表情识别迁移学习框架：evTransFER|Rodrigo Verschae, Ignacio Bugueno-Cordova|<http://arxiv.org/pdf/2508.03609v1>|提出evTransFER框架，通过迁移学习显著提升基于事件相机的人脸表情识别准确率。|
|📝 更新|Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs|打破模态壁垒：基于多模态大型语言模型的通用嵌入学习|Tiancheng Gu, Kaicheng Yang, Ziyong Feng, Xingjun Wang, Yanzhao Zhang, Dingkun Long, Yingda Chen, Weidong Cai .etc.|<http://arxiv.org/pdf/2504.17432v2>|提出UniME框架，利用大型语言模型提升多模态表征学习，增强下游任务性能。|
|📝 更新|RealSyn: An Effective and Scalable Multimodal Interleaved Document Transformation Paradigm|“RealSyn：一种有效且可扩展的多模态交错文档转换范式”|Tiancheng Gu, Kaicheng Yang, Chaoyi Zhang, Yin Xie, Xiang An, Ziyong Feng, Dongnan Liu, Weidong Cai .etc.|<http://arxiv.org/pdf/2502.12513v3>|[代码](https://github.com/deepglint/RealSyn.); 提出了一种利用现实与合成文本结合的RealSyn数据集，提升了对比视觉语言表示学习的性能和可扩展性。|


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Distribution-aware Knowledge Unification and Association for Non-exemplar Lifelong Person Re-identification|分布感知的知识统一与关联用于非范例终身行人重识别|Shiben Liu, Mingyue Xu, Huijie Fan, Qiang Wang, Yandong Tang, Zhi Han|<http://arxiv.org/pdf/2508.03516v1>|提出了一种分布感知的知识统一与关联框架，有效平衡了终身行人重识别中的旧知识保持与新信息适应。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Consistency-based Abductive Reasoning over Perceptual Errors of Multiple Pre-trained Models in Novel Environments|基于一致性的多预训练模型在新型环境感知错误上的溯因推理|Mario Leiva, Noel Ngu, Joshua Shay Kricheli, Aditya Taparia, Ransalu Senanayake, Paulo Shakarian, Nathaniel Bastian, John Corcoran .etc.|<http://arxiv.org/pdf/2505.19361v2>|提出了一种基于一致性的推理方法，有效整合多个预训练模型以应对新环境中的感知误差，显著提升了预测准确性...|
|📝 更新|CMIC: Content-Adaptive Mamba for Learned Image Compression|内容自适应曼巴：用于学习图像压缩的方法|Yunuo Chen, Zezheng Lyu, Bing He, Hongwei Hu, Qi Wang, Yuan Tian, Li Song, Wenjun Zhang .etc.|<http://arxiv.org/pdf/2508.02192v2>|引入内容自适应Mamba模型，优化了图像压缩的率失真性能，实现了更高效的全球依赖捕获。|
|🆕 发布|Sparsity and Total Variation Constrained Multilayer Linear Unmixing for Hyperspectral Imagery|稀疏性和总变分约束的多层线性解混算法用于高光谱图像|Gang Yang|<http://arxiv.org/pdf/2508.03403v1>|提出了一种结合稀疏性和总变分约束的多层线性解混方法，提高了高光谱图像解混的准确性。|
|📝 更新|FCDM: A Physics-Guided Bidirectional Frequency Aware Convolution and Diffusion-Based Model for Sinogram Inpainting|FCDM：一种基于物理引导的双向频率感知卷积与扩散模型用于正弦图修复|Jiaze E, Srutarshi Banerjee, Tekin Bicer, Guannan Wang, Yanfu Zhang, Bin Ren|<http://arxiv.org/pdf/2409.06714v4>|提出了一种针对sinogram修复的物理引导双向频率感知卷积和扩散模型，有效恢复了图像全局结构并保持...|
|🆕 发布|VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation|VLMQ：通过Hessian增强的大视觉-语言模型高效后训练量化|Yufei Xue, Yushi Huang, Jiawei Shao, Jun Zhang|<http://arxiv.org/pdf/2508.03351v1>|提出针对视觉语言模型的重要性感知量化方法VLMQ，通过增强Hessian矩阵和轻量级后向传播，有效提...|
|🆕 发布|Ultralight Polarity-Split Neuromorphic SNN for Event-Stream Super-Resolution|超轻极性分离类神经形态SNN用于事件流超分辨率|Chuanzhi Xu, Haoxian Zhou, Langyi Chen, Yuk Ying Chung, Qiang Qu|<http://arxiv.org/pdf/2508.03244v1>|提出了一种基于事件流的轻量级超分辨率方法，通过分离正负事件并引入自适应损失函数，实现了模型尺寸和推理...|
|📝 更新|Identifying actionable driver mutations in lung cancer using an efficient Asymmetric Transformer Decoder|利用高效的非对称Transformer解码器识别肺癌中的驱动性驾驶员突变|Biagio Brattoli, Jack Shi, Jongchan Park, Taebum Lee, Donggeun Yoo, Sergio Pereira|<http://arxiv.org/pdf/2508.02431v2>|提出了一种不对称变换器解码器模型，用于高效识别肺癌驱动突变，提升了机器学习在计算病理学中的应用价值。|
|📝 更新|After the Party: Navigating the Mapping From Color to Ambient Lighting|派对之后：从颜色到环境照明的映射导航|Florin-Alexandru Vasluianu, Tim Seizinger, Zongwei Wu, Radu Timofte|<http://arxiv.org/pdf/2508.02168v2>|[代码](https://github.com/fvasluianu97/RLN2.); 提出首个大规模高分辨率多色光源图像数据集CL3AN，并利用显式色度-亮度指导学习框架，有效分解复杂光...|
|📝 更新|LumiNet: Perception-Driven Knowledge Distillation via Statistical Logit Calibration|“LumiNet：通过统计逻辑校准的感知驱动知识蒸馏”|Md. Ismail Hossain, M M Lutfe Elahi, Sameera Ramasinghe, Ali Cheraghian, Fuad Rahman, Nabeel Mohammed, Shafin Rahman|<http://arxiv.org/pdf/2310.03669v3>|[代码](https://github.com/ismail31416/LumiNet.); 提出了一种基于统计logit校准的感知驱动知识蒸馏方法LumiNet，有效提升了logit-base...|
|📝 更新|CHIRP: A Fine-Grained Benchmark for Open-Ended Response Evaluation in Vision-Language Models|CHIRP：用于视觉语言模型开放式响应评估的细粒度基准|Alexis Roger, Prateek Humane, Daniel Z. Kaplan, Kshitij Gupta, Qi Sun, George Adamopoulos, Jonathan Siu Chi Lim, Quentin Anthony .etc.|<http://arxiv.org/pdf/2501.09672v3>|提出全新Robin VLMs和CHIRP长形式响应基准，以改进视觉语言模型评估方法。|
|🆕 发布|SA-3DGS: A Self-Adaptive Compression Method for 3D Gaussian Splatting|SA-3DGS：一种用于三维高斯散点绘制的自适应压缩方法|Liheng Zhang, Weihao Yu, Zubo Lu, Haozhi Gu, Jin Huang|<http://arxiv.org/pdf/2508.03017v1>|提出了一种自适应压缩方法SA-3DGS，通过智能识别和修剪不重要的高斯点，有效降低3D场景存储需求同...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MetaScope: Optics-Driven Neural Network for Ultra-Micro Metalens Endoscopy|元视野：光学驱动的超微金属透镜内窥镜神经网络|Wuyang Li, Wentao Pan, Xiaoyuan Liu, Zhendong Luo, Chenxin Li, Hengyu Liu, Din Ping Tsai, Mu Ku Chen .etc.|<http://arxiv.org/pdf/2508.03596v1>|提出MetaScope，一种针对超微型金属透镜内窥镜的物理光学驱动的神经网络，有效解决数据获取与算法...|
|📝 更新|4D Scaffold Gaussian Splatting with Dynamic-Aware Anchor Growing for Efficient and High-Fidelity Dynamic Scene Reconstruction|四维支架高斯散点投射结合动态感知锚点生长技术实现高效高保真动态场景重建|Woong Oh Cho, In Cho, Seoha Kim, Jeongmin Bae, Youngjung Uh, Seon Joo Kim|<http://arxiv.org/pdf/2411.17044v2>|提出动态感知锚点增长策略，通过4D锚点特征和神经网络高效压缩存储，实现动态场景的高保真重建。|
|🆕 发布|Less is More: Token-Efficient Video-QA via Adaptive Frame-Pruning and Semantic Graph Integration|更少即是更多：通过自适应帧剪枝和语义图集成的低标记效率视频问答|Shaoguang Wang, Jianxiang He, Yijie Xu, Ziyang Chen, Weiyu Guo, Hui Xiong|<http://arxiv.org/pdf/2508.03337v1>|提出自适应帧剪枝和语义图集成方法，减少视频问答所需帧数和输入令牌，提升效率和准确度。|
|📝 更新|BSMamba: Brightness and Semantic Modeling for Long-Range Interaction in Low-Light Image Enhancement|BSMamba：低光图像增强中长距离交互的亮度和语义建模|Tongshun Zhang, Pingping Liu, Mengen Cai, Zijian Zhang, Yubing Lu, Qiuzhan Zhou|<http://arxiv.org/pdf/2506.18346v2>|[代码](https://github.com/bywlzts/BSMamba.); BSMamba通过亮度与语义建模优化了低光图像增强，实现了亮度和语义一致性的双重提升。|
|📝 更新|Entropy-Lens: The Information Signature of Transformer Computations|熵透镜：Transformer计算的 信息特征签名|Riccardo Ali, Francesco Caso, Christopher Irwin, Pietro Liò|<http://arxiv.org/pdf/2502.16570v2>|提出Entropy-Lens框架，通过计算Shannon熵分析Transformer模型计算过程，揭...|
|📝 更新|Unveiling the Potential of iMarkers: Invisible Fiducial Markers for Advanced Robotics|揭示iMarkers的潜力：用于先进机器人学的隐形基准标记|Ali Tourani, Deniz Isinsu Avsar, Hriday Bavle, Jose Luis Sanchez-Lopez, Jan Lagerwall, Holger Voos|<http://arxiv.org/pdf/2501.15505v3>|提出隐形标记iMarkers，使机器人能在不干扰视觉美观的情况下进行精确导航和识别。|
|🆕 发布|Duplex-GS: Proxy-Guided Weighted Blending for Real-Time Order-Independent Gaussian Splatting|Duplex-GS：代理引导的加权混合用于实时顺序无关高斯喷绘|Weihang Liu, Yuke Li, Yuxuan Li, Jingyi Yu, Xin Lou|<http://arxiv.org/pdf/2508.03180v1>|提出了一种高效的 Duplex-GS 方法，通过代理引导和顺序无关技术优化高斯溅射渲染，实现实时高质...|
|🆕 发布|Uncertainty-Guided Face Matting for Occlusion-Aware Face Transformation|遮挡感知人脸变换的不确定性引导人脸抠图|Hyebin Cho, Jaehyup Lee|<http://arxiv.org/pdf/2508.03055v1>|[代码](https://github.com/hyebin-c/FaceMat.git); 提出了一种无需额外输入的实时面部遮挡处理方法，通过不确定性指导的细化alpha matte分离技术，...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DyCAF-Net: Dynamic Class-Aware Fusion Network|动态类别感知融合网络|Md Abrar Jahin, Shahriar Soudeep, M. F. Mridha, Nafiz Fahad, Md. Jakir Hossen|<http://arxiv.org/pdf/2508.03598v1>|引入动态类感知融合网络DyCAF-Net，通过自适应调整多尺度特征和注意力机制，有效应对动态场景中的...|
|🆕 发布|Retinal Lipidomics Associations as Candidate Biomarkers for Cardiovascular Health|视网膜脂质组学关联作为心血管健康的潜在生物标志物|Inamullah, Imran Razzak, Shoaib Jameel|<http://arxiv.org/pdf/2508.03538v1>|首次结合深度学习与脂质组学分析，揭示视网膜血管特征与血脂水平关联，为心血管健康提供非侵入性生物标志物...|
|📝 更新|Training Multi-Layer Binary Neural Networks With Local Binary Error Signals|多层二值神经网络训练中的局部二值误差信号|Luca Colombo, Fabrizio Pittorino, Manuel Roveri|<http://arxiv.org/pdf/2412.00119v4>|首次提出了一种全二值、无梯度的多层二值神经网络训练算法，显著提升准确度并大幅降低计算成本。|
|🆕 发布|GRASPing Anatomy to Improve Pathology Segmentation|把握解剖结构以提高病理分割精度|Keyi Li, Alexander Jaus, Jens Kleesiek, Rainer Stiefelhagen|<http://arxiv.org/pdf/2508.03374v1>|提出GRASP框架，通过整合解剖学知识提升病理分割精度。|
|🆕 发布|Live Demonstration: Neuromorphic Radar for Gesture Recognition|实时演示：类神经形态雷达的手势识别|Satyapreet Singh Yadav, Chandra Sekhar Seelamantula, Chetan Singh Thakur|<http://arxiv.org/pdf/2508.03324v1>|提出了一种基于生物启发的异步sigma-delta编码和事件驱动架构的雷达手势识别系统，实现了低功耗...|
|📝 更新|Boost Self-Supervised Dataset Distillation via Parameterization, Predefined Augmentation, and Approximation|通过参数化、预定义增强和近似提升自监督数据集蒸馏|Sheng-Feng Yu, Jia-Jiun Yao, Wei-Chen Chiu|<http://arxiv.org/pdf/2507.21455v2>|提出了一种自监督数据集蒸馏方法，通过参数化、预定义增强和近似，提高了数据集压缩效率和跨架构泛化能力。|
|🆕 发布|COFFEE: A Shadow-Resilient Real-Time Pose Estimator for Unknown Tumbling Asteroids using Sparse Neural Networks|“COFFEE：一种使用稀疏神经网络针对未知翻滚小行星的阴影鲁棒实时姿态估计器”|Arion Zimmermann, Soon-Jo Chung, Fred Hadaegh|<http://arxiv.org/pdf/2508.03132v1>|提出了一种针对未知翻滚小行星的实时位姿估计方法COFFEE，利用稀疏神经网络在保持高准确度的同时显著...|
|🆕 发布|CORE-ReID: Comprehensive Optimization and Refinement through Ensemble fusion in Domain Adaptation for person re-identification|CORE-ReID：基于集成融合在行人重识别领域自适应中的全面优化与精炼|Trinh Quoc Nguyen, Oky Dicky Ardiansyah Prima, Katsuyoshi Hotta|<http://arxiv.org/pdf/2508.03064v1>|[代码](https://github.com/TrinhQuocNguyen/CORE-ReID.); 提出了一种用于无人监督领域自适应的人体重识别框架，通过集成融合优化和细化多视角特征，实现了显著的性能...|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Neutralizing Token Aggregation via Information Augmentation for Efficient Test-Time Adaptation|通过信息增强实现测试时适应的中性化标记聚合|Yizhe Xiong, Zihan Zhou, Yiwen Liang, Hui Chen, Zijia Lin, Tianxiang Hao, Fan Zhang, Jungong Han .etc.|<http://arxiv.org/pdf/2508.03388v1>|提出方法NAVIA，通过信息增强中和聚合带来的信息损失，实现高效的测试时适应。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spatial Imputation Drives Cross-Domain Alignment for EEG Classification|空间插值驱动跨域对齐以实现脑电图分类|Hongjun Liu, Chao Yao, Yalan Zhang, Xiaokun wang, Xiaojuan Ban|<http://arxiv.org/pdf/2508.03437v1>|提出IMAC框架，通过空间时间序列插补任务实现跨域EEG数据对齐，提升分类准确性。|
|🆕 发布|The Power of Many: Synergistic Unification of Diverse Augmentations for Efficient Adversarial Robustness|众多之力的融合：多样化增强的协同统一，实现高效对抗稳健性|Wang Yu-Hang, Shiwei Li, Jianxiang Liao, Li Bohan, Jian Liu, Wenfei Yin|<http://arxiv.org/pdf/2508.03213v1>|提出了一种高效的对抗性防御框架UAA，通过预计算通用转换提升模型鲁棒性而不牺牲训练效率。|
|🆕 发布|GeoShield: Safeguarding Geolocation Privacy from Vision-Language Models via Adversarial Perturbations|GeoShield：通过对抗扰动保护视觉-语言模型中的地理位置隐私|Xinwei Liu, Xiaojun Jia, Yuan Xun, Simeng Qin, Xiaochun Cao|<http://arxiv.org/pdf/2508.03209v1>|提出GeoShield框架，通过对抗性扰动保护地理位置隐私，有效应对高分辨率图像和低扰动预算挑战。|
|📝 更新|Long-tailed Adversarial Training with Self-Distillation|长尾对抗训练与自蒸馏|Seungju Cho, Hongsin Lee, Changick Kim|<http://arxiv.org/pdf/2503.06461v3>|提出了一种针对长尾分布数据集的自蒸馏对抗训练方法，有效提升了尾类别的对抗稳健性。|
|📝 更新|Attack Anything: Blind DNNs via Universal Background Adversarial Attack|"攻击一切：通过通用背景对抗攻击实现盲目深度神经网络"|Jiawei Lian, Shaohui Mei, Xiaofei Wang, Yi Wang, Lefan Wang, Yingjie Lu, Mingyang Ma, Lap-Pui Chau|<http://arxiv.org/pdf/2409.00029v3>|[代码](https://github.com/JiaweiLian/Attack_Anything); 提出背景对抗攻击框架，无需针对目标对象即可实现广泛有效的攻击。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Negation-Aware Test-Time Adaptation for Vision-Language Models|负样本感知的测试时适应方法用于视觉语言模型|Haochen Han, Alex Jinpeng Wang, Fangming Liu, Jun Zhu|<http://arxiv.org/pdf/2507.19064v2>|[代码](https://github.com/hhc1997/NEAT.); 提出了一种低资源消耗的Negation-Aware Test-Time Adaptation方法，有...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Large Learning Rates Simultaneously Achieve Robustness to Spurious Correlations and Compressibility|大学习率同时实现对抗伪相关性的鲁棒性和可压缩性|Melih Barsbey, Lucas Prieto, Stefanos Zafeiriou, Tolga Birdal|<http://arxiv.org/pdf/2507.17748v2>|发现高学习率可同时提升模型对干扰相关性鲁棒性和压缩性。|
|🆕 发布|A Scalable Machine Learning Pipeline for Building Footprint Detection in Historical Maps|构建历史地图建筑足迹检测的可扩展机器学习管道|Annemarie McCarthy|<http://arxiv.org/pdf/2508.03564v1>|提出了一种针对稀疏建筑分布的乡村地图的 scalable 机器学习管道，通过分层 CNN 分类和分割...|
|🆕 发布|GaitAdapt: Continual Learning for Evolving Gait Recognition|《GaitAdapt：面向演化步态识别的持续学习》|Jingjie Wang, Shunli Zhang, Xiang Wei, Senmao Tian|<http://arxiv.org/pdf/2508.03375v1>|提出了一种持续学习框架GaitAdapter，通过图神经网络和距离稳定性方法保持跨任务步伐识别知识，...|
|📝 更新|Information Bottleneck-Guided Heterogeneous Graph Learning for Interpretable Neurodevelopmental Disorder Diagnosis|信息瓶颈引导的异质图学习用于可解释的神经发育障碍诊断|Yueyang Li, Lei Chen, Wenhao Dong, Shengyu Gong, Zijian Kang, Boyang Wei, Weiming Zeng, Hongjie Yan .etc.|<http://arxiv.org/pdf/2502.20769v2>|提出了一种结合信息瓶颈原理的异质图学习框架，有效提升了神经发育障碍诊断的准确性和可解释性。|
|🆕 发布|Causal Disentanglement and Cross-Modal Alignment for Enhanced Few-Shot Learning|因果解耦与跨模态对齐增强少样本学习|Tianjiao Jiang, Zhen Zhang, Yuhang Liu, Javen Qinfeng Shi|<http://arxiv.org/pdf/2508.03102v1>|[代码](https://github.com/tianjiao-j/CCA.); 提出了一种利用独立成分分析和跨模态对齐的Causal CLIP Adapter框架，有效提升少量样本...|
|📝 更新|KAN or MLP? Point Cloud Shows the Way Forward|“KAN还是MLP？点云指明前进之路”|Yan Shi, Qingdong He, Yijun Liu, Xiaoyu Liu, Jingyong Su|<http://arxiv.org/pdf/2504.13593v3>|提出PointKAN方法，利用KAN网络优化点云分析，提升特征表示能力并降低参数需求。|
|🆕 发布|Separating Shared and Domain-Specific LoRAs for Multi-Domain Learning|《分离多域学习中的共享和域特定LoRAs》|Yusaku Takama, Ning Ding, Tatsuya Yokota, Toru Tamaki|<http://arxiv.org/pdf/2508.02978v1>|提出方法确保多域学习中的共享和特定域LoRAs存在于不同子空间，提升了动作识别任务的效果。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ActionSink: Toward Precise Robot Manipulation with Dynamic Integration of Action Flow|动态集成动作流的精确机器人操作：ActionSink|Shanshan Guo, Xiwen Liang, Junfan Lin, Yuzheng Zhuang, Liang Lin, Xiaodan Liang|<http://arxiv.org/pdf/2508.03218v1>|提出ActionSink框架，通过动态整合动作流提高机器人操作精度。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AttZoom: Attention Zoom for Better Visual Features|AttZoom：用于优化视觉特征的关注力缩放|Daniel DeAlcala, Aythami Morales, Julian Fierrez, Ruben Tolosana|<http://arxiv.org/pdf/2508.03625v1>|提出了一种模块化、模型无关的注意力机制AttZoom，通过独立层增强卷积神经网络的特征提取能力，提升...|
|📝 更新|Leveraging Vision-Language Models for Visual Grounding and Analysis of Automotive UI|利用视觉-语言模型进行车辆用户界面视觉定位与分析|Benjamin Raphael Ernhofer, Daniil Prokhorov, Jannica Langner, Dominik Bollmann|<http://arxiv.org/pdf/2505.05895v3>|提出了一种融合视觉与语言模型的框架，用于理解和交互汽车用户界面，实现了跨设计领域的自适应。|
|📝 更新|Neuro-3D: Towards 3D Visual Decoding from EEG Signals|神经三维：面向从脑电图信号的三维视觉解码|Zhanqiang Guo, Jiamin Wu, Yonghao Song, Jiahui Bu, Weijian Mai, Qihao Zheng, Wanli Ouyang, Chunfeng Song|<http://arxiv.org/pdf/2411.12248v3>|首次实现基于EEG信号的3D视觉解码，提出自适应集成框架准确重构彩色3D物体。|
|🆕 发布|IKOD: Mitigating Visual Attention Degradation in Large Vision-Language Models|IKOD：减轻大型视觉-语言模型中视觉注意力退化|Jiabing Yang, Chenhang Cui, Yiyang Zhou, Yixiang Chen, Peng Xia, Ying Wei, Tao Yu, Yan Huang .etc.|<http://arxiv.org/pdf/2508.03469v1>|提出IKOD策略，通过增强视觉注意力，有效减少大型视觉语言模型中的“虚构”现象。|
|🆕 发布|Visual Document Understanding and Question Answering: A Multi-Agent Collaboration Framework with Test-Time Scaling|视觉文档理解与问题回答：一种测试时放缩的多代理协作框架|Xinlei Yu, Zhangquan Chen, Yudong Zhang, Shilin Lu, Ruolin Shen, Jiangning Zhang, Xiaobin Hu, Yanwei Fu .etc.|<http://arxiv.org/pdf/2508.03404v1>|[代码](https://github.com/YU-deep/MACT.git.); 提出多代理协作框架MACT，通过测试时缩放提升视觉文档理解和问题回答性能。|
|🆕 发布|AlignCAT: Visual-Linguistic Alignment of Category and Attributefor Weakly Supervised Visual Grounding|AlignCAT：类别与属性视觉-语言对齐的弱监督视觉定位|Yidan Wang, Chenyi Zhuang, Wutao Liu, Pan Gao, Nicu Sebe|<http://arxiv.org/pdf/2508.03201v1>|[代码](https://github.com/I2-Multimedia-Lab/AlignCAT.); 提出 AlignCAT 方法，通过细粒度语义匹配提升弱监督视觉定位的准确性和效率。|
|🆕 发布|SAVER: Mitigating Hallucinations in Large Vision-Language Models via Style-Aware Visual Early Revision|SAVER：通过样式感知视觉早期修正减轻大型视觉语言模型中的幻觉现象|Zhaoxu Li, Chenqi Kong, Yi Yu, Qiangqiang Wu, Xinghao Jiang, Ngai-Man Cheung, Bihan Wen, Alex Kot .etc.|<http://arxiv.org/pdf/2508.03177v1>|提出SAVER方法，通过视觉早期反馈调整大型视觉语言模型输出，有效减少风格化图像导致的幻觉问题。|
|📝 更新|VPN: Visual Prompt Navigation|视觉提示导航|Shuo Feng, Zihan Wang, Yuchen Li, Rui Kong, Hengyi Cai, Shuaiqiang Wang, Gim Hee Lee, Piji Li .etc.|<http://arxiv.org/pdf/2508.01766v2>|[代码](https://github.com/farlit/VPN.); 提出视觉提示导航方法，通过在2D俯视图上标记导航轨迹，减少语言引导的模糊性并提高非专家用户的导航效率...|
|📝 更新|How Can Objects Help Video-Language Understanding?|对象如何助力视频-语言理解？|Zitian Tang, Shijie Wang, Junho Cho, Jaewook Yoo, Chen Sun|<http://arxiv.org/pdf/2504.07454v2>|[代码](https://github.com/brown-palm/ObjectMLLM.); 提出ObjectMLLM框架，通过显式整合物体中心表示，提升多模态大语言模型对视频理解的能力。|
|📝 更新|Reinforcing VLMs to Use Tools for Detailed Visual Reasoning Under Resource Constraints|在资源受限条件下强化视觉语言模型使用工具进行详细视觉推理|Sunil Kumar, Bowen Zhao, Leo Dirac, Paulina Varshavskaya|<http://arxiv.org/pdf/2506.14821v3>|通过训练小规模视觉语言模型使用外部工具进行详细视觉推理，提升了资源受限下的VQA性能。|
|🆕 发布|VideoForest: Person-Anchored Hierarchical Reasoning for Cross-Video Question Answering|视频森林：基于人物锚点的层次推理用于跨视频问答|Yiran Meng, Junhong Ye, Wei Zhou, Guanghui Yue, Xudong Mao, Ruomei Wang, Baoquan Zhao|<http://arxiv.org/pdf/2508.03039v1>|引入VideoForest框架，通过人物级特征实现跨视频理解和问答，提升复杂视频内容解析效率。|
|🆕 发布|VCNet: Recreating High-Level Visual Cortex Principles for Robust Artificial Vision|VCNet：重现高级视觉皮层原理以实现稳健的人工视觉|Brennen A. Hill, Zhang Xinyu, Timothy Putra Prasetio|<http://arxiv.org/pdf/2508.02995v1>|提出VCNet网络，借鉴灵长类视觉皮层结构，提升视觉模型的效率和鲁棒性。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Beyond Meme Templates: Limitations of Visual Similarity Measures in Meme Matching|超越模因模板：视觉相似度测量在模因匹配中的局限性|Muzhaffar Hazman, Susan McKeever, Josephine Griffith|<http://arxiv.org/pdf/2508.03562v1>|提出了一种超越传统模板匹配的广义 meme 匹配方法，有效应对非模板型 meme 的匹配挑战。|
|📝 更新|Beyond Images: Adaptive Fusion of Visual and Textual Data for Food Classification|超越图像：视觉与文本数据的自适应融合用于食品分类|Prateek Mittal, Puneet Goyal, Joohi Chauhan|<http://arxiv.org/pdf/2308.02562v4>|提出了一种自适应融合视觉和文本数据的多模态食品分类框架，显著提升了分类准确性和鲁棒性。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Veila: Panoramic LiDAR Generation from a Monocular RGB Image|Veila：从单目RGB图像生成全景LiDAR|Youquan Liu, Lingdong Kong, Weidong Yang, Ao Liang, Jianxiong Gao, Yang Wu, Xiang Xu, Xin Li .etc.|<http://arxiv.org/pdf/2508.03690v1>|Veila通过引入自适应平衡语义和深度线索的置信度感知条件机制、几何跨模态对齐和全景特征一致性，实现...|
|🆕 发布|CADD: Context aware disease deviations via restoration of brain images using normative conditional diffusion models|基于规范条件扩散模型恢复脑图像的上下文感知疾病偏差检测（CADD）|Ana Lawry Aguila, Ayodeji Ijishakin, Juan Eugenio Iglesias, Tomomi Takenaga, Yukihiro Nomura, Takeharu Yoshikawa, Osamu Abe, Shouhei Hanaoka|<http://arxiv.org/pdf/2508.03594v1>|提出CADD模型，利用条件扩散模型结合临床信息进行3D脑图像的规范建模和疾病异常检测。|
|🆕 发布|Quality-Aware Language-Conditioned Local Auto-Regressive Anomaly Synthesis and Detection|质量感知的语言条件局部自回归异常生成与检测|Long Qian, Bingke Zhu, Yingying Chen, Ming Tang, Jinqiao Wang|<http://arxiv.org/pdf/2508.03539v1>|提出了一种结合语言条件的局部自回归异常合成方法，大幅提升了异常检测的准确性和效率。|
|🆕 发布|Prototype-Enhanced Confidence Modeling for Cross-Modal Medical Image-Report Retrieval|跨模态医疗图像-报告检索的原型增强置信建模|Shreyank N Gowda, Xiaobo Jin, Christian Wagner|<http://arxiv.org/pdf/2508.03494v1>|提出了一种原型增强的置信度建模框架，有效提升了医学图像与文本报告的跨模态检索精度和可靠性。|
|📝 更新|Uncertainty-aware Medical Diagnostic Phrase Identification and Grounding|不确定性感知的医疗诊断短语识别与定位|Ke Zou, Yang Bai, Zhihao Chen, Yang Zhou, Yidi Chen, Kai Ren, Meng Wang, Xuedong Yuan .etc.|<http://arxiv.org/pdf/2404.06798v2>|提出了一种端到端的医疗报告 grounding 方法 uMedGround，通过嵌入特殊 token...|
|📝 更新|FedSemiDG: Domain Generalized Federated Semi-supervised Medical Image Segmentation|联邦半监督医学图像分割的领域泛化：FedSemiDG|Zhipeng Deng, Zhe Xu, Tsuyoshi Isshiki, Yefeng Zheng|<http://arxiv.org/pdf/2501.07378v2>|提出了一种面向医学图像分割的联邦半监督学习方法，通过自适应权重聚合和伪标签优化有效解决了跨域泛化问题...|
|🆕 发布|MedCAL-Bench: A Comprehensive Benchmark on Cold-Start Active Learning with Foundation Models for Medical Image Analysis|MedCAL-Bench：基于基础模型的医学图像分析冷启动主动学习全面基准测试|Ning Zhu, Xiaochuan Ma, Shaoting Zhang, Guotai Wang|<http://arxiv.org/pdf/2508.03441v1>|[代码](https://github.com/HiLab-git/MedCAL-Bench.); 提出MedCAL-Bench，首个针对医疗图像分析的基于预训练模型的全流程冷启动主动学习基准。|
|🆕 发布|Learning Latent Representations for Image Translation using Frequency Distributed CycleGAN|使用频率分布循环生成对抗网络学习图像转换的潜在表征|Shivangi Nigam, Adarsh Prasad Behera, Shekhar Verma, P. Nagabhushan|<http://arxiv.org/pdf/2508.03415v1>|提出了一种频率分布引导的CycleGAN框架，通过增强潜在表征学习，提高了图像翻译的质量和泛化能力。|
|📝 更新|Topology Optimization in Medical Image Segmentation with Fast Euler Characteristic|医学图像分割中的拓扑优化及快速欧拉特性计算|Liu Li, Qiang Ma, Cheng Ouyang, Johannes C. Paetzold, Daniel Rueckert, Bernhard Kainz|<http://arxiv.org/pdf/2507.23763v2>|提出了一种基于欧拉特征的高效医学图像分割优化方法，通过拓扑约束显著提升了分割结果的准确性。|
|🆕 发布|Efficient Multi-Slide Visual-Language Feature Fusion for Placental Disease Classification|胎盘疾病分类的高效多幻灯片视觉-语言特征融合|Hang Guo, Qing Zhang, Zixuan Gao, Siyuan Yang, Shulin Peng, Xiang Tao, Ting Yu, Yan Wang .etc.|<http://arxiv.org/pdf/2508.03277v1>|[代码](https://github.com/ECNU-MultiDimLab/EmmPD.); 提出了一种高效的多模态融合框架EmmPD，通过自适应图学习和文本报告整合，优化了胎盘疾病诊断的准确性...|
|🆕 发布|Landsat30-AU: A Vision-Language Dataset for Australian Landsat Imagery|澳大利亚Landsat影像的视觉-语言数据集Landsat30-AU|Sai Ma, Zhuang Li, John A Taylor|<http://arxiv.org/pdf/2508.03127v1>|[代码](https://github.com/papersubmit1/landsat30-au.); 构建了Landsat30-AU数据集，提升卫星图像与自然语言交互的性能。|
|🆕 发布|Nexus-INR: Diverse Knowledge-guided Arbitrary-Scale Multimodal Medical Image Super-Resolution|Nexus-INR：多样化知识引导的任意尺度多模态医学图像超分辨率|Bo Zhang, JianFei Huo, Zheng Zhang, Wufan Wang, Hui Gao, Xiangyang Gong, Wendong Wang|<http://arxiv.org/pdf/2508.03073v1>|提出Nexus-INR框架，通过多模态知识和下游任务指导，实现了自适应分辨率的医学图像超分辨率重建。|
|📝 更新|Clinical Expert Uncertainty Guided Generalized Label Smoothing for Medical Noisy Label Learning|临床专家不确定性指导的广义标签平滑在医学噪声标签学习中的应用|Kunyu Zhang, Lin Gu, Liangchen Liu, Yingke Chen, Binyang Wang, Jin Yan, Yingying Zhu|<http://arxiv.org/pdf/2508.02495v2>|提出了一种将临床专家不确定性融入医疗图像分析的方法，通过标签平滑显著提升了性能。|
|🆕 发布|SSFMamba: Symmetry-driven Spatial-Frequency Feature Fusion for 3D Medical Image Segmentation|对称驱动的空间频率特征融合用于三维医学图像分割的SSFMamba方法|Bo Zhang, Yifan Zhang, Shuo Yan, Yu Bai, Zheng Zhang, Wu Liu, Xiuzhuang Zhou, Wendong Wang|<http://arxiv.org/pdf/2508.03069v1>|提出了一种结合空间域和频域特征融合的3D医疗图像分割方法，通过利用对称性和双向扫描强化全局与局部信息...|
|🆕 发布|A Survey of Medical Point Cloud Shape Learning: Registration, Reconstruction and Variation|医学点云形状学习综述：配准、重建与变体分析|Tongxu Zhang, Zhiming Liang, Bei Wang|<http://arxiv.org/pdf/2508.03057v1>|系统综述了基于点云的医疗形状学习，涵盖配准、重建和变体建模三大任务，展望未来发展。|
|📝 更新|MedFormer: Hierarchical Medical Vision Transformer with Content-Aware Dual Sparse Selection Attention|MedFormer：具有内容感知双稀疏选择注意力的分层医学视觉变换器|Zunhui Xia, Hongxing Li, Libin Lan|<http://arxiv.org/pdf/2507.02488v2>|MedFormer通过金字塔结构和内容感知的双稀疏选择注意力，提升了医疗图像识别的通用性和效率。|
|📝 更新|Vision-Language Fusion for Real-Time Autonomous Driving: Goal-Centered Cross-Attention of Camera, HD-Map, & Waypoints|面向实时自动驾驶的视觉-语言融合：以目标为中心的摄像头、高精度地图与航点交叉注意力机制|Santosh Patapati, Trisanth Srinivasan, Murari Ambati|<http://arxiv.org/pdf/2507.23064v2>|提出了一种融合视觉、地图和导航目标的实时自动驾驶方法，通过目标中心注意力机制提升驾驶准确性和效率。|
|🆕 发布|ClinicalFMamba: Advancing Clinical Assessment using Mamba-based Multimodal Neuroimaging Fusion|《ClinicalFMamba：基于Mamba的多模态神经影像融合在临床评估中的应用》|Meng Zhou, Farzad Khalvati|<http://arxiv.org/pdf/2508.03008v1>|提出了一种结合CNN与Mamba的混合架构ClinicalFMamba，实现了高效的多模态医学图像融...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CloudBreaker: Breaking the Cloud Covers of Sentinel-2 Images using Multi-Stage Trained Conditional Flow Matching on Sentinel-1|“CloudBreaker：利用多阶段训练的条件流匹配技术破解Sentinel-2图像云层覆盖问题”|Saleh Sakib Ahmed, Sara Nowreen, M. Sohel Rahman|<http://arxiv.org/pdf/2508.03608v1>|提出CloudBreaker框架，利用Sentinel-1数据生成高质量Sentinel-2多光谱信...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Advancing Precision in Multi-Point Cloud Fusion Environments|提高多点云融合环境中的精度|Ulugbek Alibekov, Vanessa Staderini, Philipp Schneider, Doris Antensteiner|<http://arxiv.org/pdf/2508.03179v1>|提出了一种新型CloudCompare插件，通过合并多点云并可视化表面缺陷，提高了工业视觉检测的准确...|
|🆕 发布|Augmenting Continual Learning of Diseases with LLM-Generated Visual Concepts|增强疾病连续学习：利用大型语言模型生成的视觉概念|Jiantao Tan, Peixian Ma, Kanghao Chen, Zhiming Dai, Ruixuan Wang|<http://arxiv.org/pdf/2508.03094v1>|利用大型语言模型生成的视觉概念增强医疗图像分类系统的持续学习能力。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MoCHA: Advanced Vision-Language Reasoning with MoE Connector and Hierarchical Group Attention|MoCHA：使用MoE连接器和层次化组注意力进行高级视觉-语言推理|Yuqi Pang, Bowen Yang, Yun Cao, Rong Fan, Xiaoyu Li, Chen He|<http://arxiv.org/pdf/2507.22805v2>|提出MoCHA框架，通过混合专家连接器和分层组注意力提升视觉语言推理效率与效果。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Open-Attribute Recognition for Person Retrieval: Finding People Through Distinctive and Novel Attributes|开放属性识别用于人物检索：通过独特和新型属性寻找人物|Minjeong Park, Hongbeen Park, Sangwon Lee, Yoonha Jang, Jinkyu Kim|<http://arxiv.org/pdf/2508.01389v2>|提出开放属性识别任务，通过学习泛化的身体部位表征，实现基于新颖属性的人物检索。|
|🆕 发布|WaMo: Wavelet-Enhanced Multi-Frequency Trajectory Analysis for Fine-Grained Text-Motion Retrieval|瓦莫：基于小波增强的多频率轨迹分析用于细粒度文本-运动检索|Junlong Ren, Gangjian Zhang, Honghao Fu, Pengcheng Wu, Hao Wang|<http://arxiv.org/pdf/2508.03343v1>|提出了一种基于小波变换的多频轨迹分析方法，实现了对文本描述的3D运动序列的精细对齐。|
|📝 更新|ADS-Edit: A Multimodal Knowledge Editing Dataset for Autonomous Driving Systems|ADS-Edit：面向自动驾驶系统的多模态知识编辑数据集|Chenxi Wang, Jizhan Fang, Xiang Chen, Bozhong Tian, Ziwen Xu, Huajun Chen, Ningyu Zhang|<http://arxiv.org/pdf/2503.20756v3>|[代码](https://github.com/zjunlp/EasyEdit); 提出知识编辑方法并创建ADS-Edit数据集，优化自动驾驶系统对交通知识的理解和应对复杂路况。|
|📝 更新|AD-GS: Object-Aware B-Spline Gaussian Splatting for Self-Supervised Autonomous Driving|AD-GS：面向对象的自监督自动驾驶B样条高斯散点绘制方法|Jiawei Xu, Kai Deng, Zexin Fan, Shenlong Wang, Jin Xie, Jian Yang|<http://arxiv.org/pdf/2507.12137v3>|提出了一种无需标注的高质量自监督框架AD-GS，通过结合B样条曲线和三角函数建模动态驾驶场景。|
|🆕 发布|Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models|在大规模视觉-语言模型中探索细粒度属性的公平性|Zaiying Zhao, Toshihiko Yamasaki|<http://arxiv.org/pdf/2508.03079v1>|探究大型视觉语言模型在细粒度属性上的公平性，发现文化、环境和行为因素影响大于传统人口属性。|

