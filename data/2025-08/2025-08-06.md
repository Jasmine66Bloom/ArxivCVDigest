## [UPDATED!] **2025-08-06** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Adaptive Audio-Visual Speech Recognition via Matryoshka-Based Multimodal LLMs|基于套娃式多模态大语言模型的适应性音频-视觉语音识别|Umberto Cappellazzo, Minsu Kim, Stavros Petridis|<http://arxiv.org/pdf/2503.06362v2>|提出了一种基于Matryoshka表示学习的自适应多模态语言模型，有效平衡了计算效率和识别精度。|
|📝 更新|ChartM$^3$: Benchmarking Chart Editing with Multimodal Instructions|图表M$^3$：使用多模态指令进行图表编辑的基准测试|Donglu Yang, Liang Zhang, Zihao Yue, Liangyu Chen, Yichen Xu, Wenxuan Wang, Qin Jin|<http://arxiv.org/pdf/2507.21167v3>|[代码](https://github.com/MLrollIT/ChartM3.); 提出了结合自然语言和视觉指示器的多模态图表编辑方法，并创建了相应的评估基准和数据集。|
|📝 更新|VISO-Grasp: Vision-Language Informed Spatial Object-centric 6-DoF Active View Planning and Grasping in Clutter and Invisibility|视觉-语言指导的空间目标中心6自由度主动视图规划与抓取：在杂乱与不可见环境中的VISO-Grasp方法|Yitian Shi, Di Wen, Guanqi Chen, Edgar Welte, Sheng Liu, Kunyu Peng, Rainer Stiefelhagen, Rania Rayyes|<http://arxiv.org/pdf/2503.12609v2>|[代码](https://github.com/YitianShi/vMF-Contact); 提出VISO-Grasp系统，利用视觉语言模型优化遮挡环境下的主动视图规划和抓取策略。|
|🆕 发布|From Learning to Unlearning: Biomedical Security Protection in Multimodal Large Language Models|从学习到遗忘：多模态大型语言模型中的生物医学安全保护|Dunyuan Xu, Xikai Yang, Yaoqian Li, Jinpeng Li, Pheng-Ann Heng|<http://arxiv.org/pdf/2508.04192v1>|提出首个针对生物医学多模态大语言模型安全保护的机器遗忘基准，并评估了五种遗忘方法的效果。|
|🆕 发布|UniFGVC: Universal Training-Free Few-Shot Fine-Grained Vision Classification via Attribute-Aware Multimodal Retrieval|《UniFGVC：通过属性感知多模态检索实现的通用无训练少样本细粒度视觉分类》|Hongyu Guo, Kuan Zhu, Xiangzhao Hao, Haiyun Guo, Ming Tang, Jinqiao Wang|<http://arxiv.org/pdf/2508.04136v1>|提出了一种无需训练的通用框架UniFGVC，通过属性感知的多模态检索实现少量样本的细粒度视觉分类。|
|📝 更新|CMT: A Cascade MAR with Topology Predictor for Multimodal Conditional CAD Generation|级联马尔可夫随机场与拓扑预测器用于多模态条件CAD生成的CMT方法|Jianyu Wu, Yizhou Wang, Xiangyu Yue, Xinzhu Ma, Jingyang Guo, Dongzhan Zhou, Wanli Ouyang, Shixiang Tang|<http://arxiv.org/pdf/2504.20830v2>|提出了一种基于边界表示的级联马尔可夫随机场与拓扑预测器框架，用于多模态条件CAD生成，大幅提升了生成...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|YOLOv8-Based Deep Learning Model for Automated Poultry Disease Detection and Health Monitoring paper|基于YOLOv8的深度学习模型在自动化家禽疾病检测与健康监控中的应用论文|Akhil Saketh Reddy Sabbella, Ch. Lakshmi Prachothan, Eswar Kumar Panta|<http://arxiv.org/pdf/2508.04658v1>|提出了一种基于YOLOv8的深度学习模型，实现鸡只疾病的自动化检测与实时健康监控。|
|🆕 发布|Zero-Residual Concept Erasure via Progressive Alignment in Text-to-Image Model|通过逐步对齐在文本到图像模型中实现零残差概念擦除|Hongxu Chen, Zhen Wang, Taoran Mei, Lin Li, Bowei Zhu, Runshi Li, Long Chen|<http://arxiv.org/pdf/2508.04472v1>|提出了一种新的零残差概念擦除方法ErasePro，通过逐步对齐策略更完全地擦除有害概念并保持生成质量...|
|🆕 发布|TotalRegistrator: Towards a Lightweight Foundation Model for CT Image Registration|《TotalRegistrator：面向CT图像配准的轻量级基础模型》|Xuan Loc Pham, Gwendolyn Vuurberg, Marjan Doppen, Joey Roosen, Tip Stille, Thi Quynh Ha, Thuy Duong Quach, Quoc Vu Dang .etc.|<http://arxiv.org/pdf/2508.04450v1>|[代码](https://github.com/DIAGNijmegen/oncology_image_registration.git.); 提出了一种轻量级的多器官CT图像配准框架TotalRegistrator，实现了高通用性和较强性能。|
|📝 更新|3DTTNet: Multimodal Fusion-Based 3D Traversable Terrain Modeling for Off-Road Environments|三维 traversable 地形建模：基于多模态融合的越野环境三维可通行地形建模网络|Zitong Chen, Chao Sun, Shida Nie, Chen Min, Changjiu Ning, Haoyu Li, Bo Wang|<http://arxiv.org/pdf/2412.08195v2>|提出了一种融合激光雷达和单目摄像头数据的多模态方法3DTTNet，显著提升了复杂地形下的可通行区域识...|
|📝 更新|OccLE: Label-Efficient 3D Semantic Occupancy Prediction|Occupancy-Efficient 3D Semantic Labeling|Naiyu Fang, Zheyuan Zhou, Fayao Liu, Xulei Yang, Jiacheng Wei, Lemiao Qiu, Guosheng Lin|<http://arxiv.org/pdf/2505.20617v2>|提出了一种高效利用少量标注进行3D语义占据预测的方法，通过分离语义和几何学习任务并融合两者的特征网格...|
|🆕 发布|Chain of Questions: Guiding Multimodal Curiosity in Language Models|“问题链：引导语言模型中的多模态好奇心”|Nima Iji, Kia Dashtipour|<http://arxiv.org/pdf/2508.04350v1>|提出Chain of Questions框架，通过好奇心驱动的推理方法，增强多模态语言模型在复杂环境...|
|🆕 发布|A Foundation Model for DAS Signal Recognition and Visual Prompt Tuning of the Pre-trained Model for Downstream Tasks|用于DAS信号识别的基础模型及预训练模型在下游任务中的视觉提示微调|Kun Gui, Hongliang Ren, Shang Shi, Jin Lu, Changqiu Yu, Quanjun Cao, Guomin Gu, Qi Xuan|<http://arxiv.org/pdf/2508.04316v1>|提出了一种基于Masked Autoencoder的DAS信号识别基础模型MAEPD，并采用视觉Pr...|
|🆕 发布|Segment Any Vehicle: Semantic and Visual Context Driven SAM and A Benchmark|任意车辆分割：基于语义和视觉上下文的SAM及基准测试|Xiao Wang, Ziwen Wang, Wentao Wu, Anjie Wang, Jiashu Wu, Yantao Pan, Chenglong Li|<http://arxiv.org/pdf/2508.04260v1>|[代码](https://github.com/Event-AHU/SAV); 提出SAV框架，结合知识图谱和视觉上下文，提升车辆部件分割性能，并构建大规模车辆分割数据集。|
|🆕 发布|Intention Enhanced Diffusion Model for Multimodal Pedestrian Trajectory Prediction|意图增强的多模态行人轨迹预测扩散模型|Yu Liu, Zhijie Liu, Xiao Ren, You-Fu Li, He Kong|<http://arxiv.org/pdf/2508.04229v1>|提出了一种融合行人运动意图识别的扩散模型，有效提升了多模态行人轨迹预测的准确性和解释性。|
|📝 更新|Synthesizing Near-Boundary OOD Samples for Out-of-Distribution Detection|合成近边界异常样本以进行分布外检测|Jinglun Li, Kaixun Jiang, Zhaoyu Chen, Bo Lin, Yao Tang, Weifeng Ge, Wenqiang Zhang|<http://arxiv.org/pdf/2507.10225v2>|[代码](https://github.com/Jarvisgivemeasuit/SynOOD.); 提出SynOOD方法，利用基础模型生成边界OOD样本，增强CLIP模型对分布内外样本的区分能力。|
|🆕 发布|Beyond the Visible: Benchmarking Occlusion Perception in Multimodal Large Language Models|超越可见性：在多模态大型语言模型中对遮挡感知的基准测试|Zhaochen Liu, Kaiwen Gao, Shuyi Liang, Bin Xiao, Limeng Qiao, Lin Ma, Tingting Jiang|<http://arxiv.org/pdf/2508.04059v1>|提出首个针对遮挡感知的视觉问答基准O-Bench，揭示了大型多模态语言模型在此领域的性能差距。|
|📝 更新|Probabilistic Modeling of Jailbreak on Multimodal LLMs: From Quantification to Application|《多模态大规模语言模型中越狱的概率建模：从量化到应用》|Wenzhuo Xu, Zhipeng Wei, Xiongtao Sun, Zonghao Ying, Deyue Zhang, Dongdong Yang, Xiangzheng Zhang, Quanchen Zou|<http://arxiv.org/pdf/2503.06989v3>|提出用概率模型量化多模态大语言模型的安全风险，并设计了优化攻击与防御策略。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|p-MoD: Building Mixture-of-Depths MLLMs via Progressive Ratio Decay|p-MoD：通过渐进比例衰减构建深度混合的多模态语言模型|Jun Zhang, Desen Meng, Zhengming Zhang, Zhenpeng Huang, Tao Wu, Limin Wang|<http://arxiv.org/pdf/2412.04449v2>|提出p-MoD架构，通过选择性处理视觉token降低多模态大语言模型的训练与推理成本，同时保持性能。|
|📝 更新|CreatiLayout: Siamese Multimodal Diffusion Transformer for Creative Layout-to-Image Generation|创意布局生成：基于Siamese多模态扩散变换器的图像布局到图像生成|Hui Zhang, Dexiang Hong, Yitong Wang, Jie Shao, Xinglong Wu, Zuxuan Wu, Yu-Gang Jiang|<http://arxiv.org/pdf/2412.03859v3>|提出了一种融合多模态扩散变换器的布局到图像生成方法，通过独立的网络权重处理布局并优化模态竞争，提高了...|
|🆕 发布|Benchmarking Foundation Models for Mitotic Figure Classification|用于有丝分裂图像分类的基础模型基准测试|Jonas Ammeling, Jonathan Ganz, Emely Rosbach, Ludwig Lausser, Christof A. Bertram, Katharina Breininger, Marc Aubreville|<http://arxiv.org/pdf/2508.04441v1>|探究了基于自监督学习的基础模型在细胞分裂图像分类中的应用，提出使用低秩适应方法提升模型性能。|
|🆕 发布|Efficient Inter-Task Attention for Multitask Transformer Models|多任务变换器模型中的高效任务间注意力机制|Christian Bohn, Thomas Kurbiel, Klaus Friedrichs, Hasan Tercan, Tobias Meisen|<http://arxiv.org/pdf/2508.04422v1>|提出了一种高效的跨任务注意力机制，大幅降低了多任务学习中的计算复杂度并提升了预测质量。|
|🆕 发布|VisionTS++: Cross-Modal Time Series Foundation Model with Continual Pre-trained Visual Backbones|《VisionTS++：具有持续预训练视觉骨干的跨模态时间序列基础模型》|Lefei Shen, Mouxiang Chen, Xu Liu, Han Fu, Xiaoxue Ren, Jianling Sun, Zhuo Li, Chenghao Liu|<http://arxiv.org/pdf/2508.04379v1>|提出VisionTS++模型，通过视觉模型连续预训练解决时间序列预测中的跨模态、多变量和概率预测问题...|
|🆕 发布|Length Matters: Length-Aware Transformer for Temporal Sentence Grounding|《长度至关重要：面向时序句子定位的长度感知变换器》|Yifan Wang, Ziyi Liu, Xiaolong Sun, Jiawei Wang, Hongmin Liu|<http://arxiv.org/pdf/2508.04299v1>|提出了一种长度感知的Transformer模型，通过分配不同查询处理不同时长视频段，提升了时间句子定...|
|📝 更新|AVG-LLaVA: An Efficient Large Multimodal Model with Adaptive Visual Granularity|AVG-LLaVA：一种具有自适应视觉粒度的高效大型多模态模型|Zhibin Lan, Liqiang Niu, Fandong Meng, Wenbo Li, Jie Zhou, Jinsong Su|<http://arxiv.org/pdf/2410.02745v3>|提出了一种自适应视觉粒度的多模态模型，有效减少视觉标记数量并加快推理速度。|
|🆕 发布|VisualTrans: A Benchmark for Real-World Visual Transformation Reasoning|《VisualTrans：面向现实世界的视觉转换推理基准》|Yuheng Ji, Yipu Wang, Yuyang Liu, Xiaoshuai Hao, Yue Liu, Yuting Zhao, Huaihai Lyu, Xiaolong Zheng|<http://arxiv.org/pdf/2508.04043v1>|[代码](https://github.com/WangYipu2002/VisualTrans.); 提出了VisualTrans，一个针对真实世界视觉变换推理的全面基准，弥补了现有基准的不足，并揭示了...|
|🆕 发布|Investigating the Impact of Large-Scale Pre-training on Nutritional Content Estimation from 2D Images|探究大规模预训练对从二维图像估计营养成分含量的影响|Michele Andrade, Guilherme A. L. Silva, Valéria Santos, Gladston Moreira, Eduardo Luz|<http://arxiv.org/pdf/2508.03996v1>|研究了大规模预训练数据集对2D图像营养含量估算深度学习模型性能的影响。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|X-SAM: From Segment Anything to Any Segmentation|X-SAM：从任意分割到任意语义分割|Hao Wang, Limeng Qiao, Zequn Jie, Zhijian Huang, Chengjian Feng, Qingfang Zheng, Lin Ma, Xiangyuan Lan .etc.|<http://arxiv.org/pdf/2508.04655v1>|[代码](https://github.com/wanghao9610/X-SAM.); 提出X-SAM框架，通过扩展视觉提示能力，实现了多模态大语言模型在像素级视觉理解上的突破，提升了多掩...|
|🆕 发布|LA-CaRe-CNN: Cascading Refinement CNN for Left Atrial Scar Segmentation|LA-CaRe-CNN：左心房疤痕分割的级联细化卷积神经网络|Franz Thaler, Darko Stern, Gernot Plank, Martin Urschler|<http://arxiv.org/pdf/2508.04553v1>|提出LA-CaRe-CNN模型，通过级联 refinement CNN 精确分割左心房及疤痕组织，助...|
|📝 更新|CHARM: Collaborative Harmonization across Arbitrary Modalities for Modality-agnostic Semantic Segmentation|CHARM：跨任意模态的协作谐调以实现模态无关的语义分割|Lekang Wen, Jing Xiao, Liang Liao, Jiajun Chen, Mi Wang|<http://arxiv.org/pdf/2508.03060v2>|提出CHARM框架，通过互补学习实现跨模态协同，保持各模态特性进行语义分割。|
|📝 更新|Upsampling DINOv2 features for unsupervised vision tasks and weakly supervised materials segmentation|为无监督视觉任务和弱监督材料分割上采样DINOv2特征|Ronan Docherty, Antonis Vamvakeros, Samuel J. Cooper|<http://arxiv.org/pdf/2410.19836v2>|利用自监督视觉变换器特征进行上采样，有效提升无监督视觉任务和弱监督材料分割性能。|
|📝 更新|ESA: Annotation-Efficient Active Learning for Semantic Segmentation|ESA：面向语义分割的标注高效主动学习|Jinchao Ge, Zeyu Zhang, Minh Hieu Phan, Bowen Zhang, Akide Liu, Yang Zhao, Shuwen Zhao|<http://arxiv.org/pdf/2408.13491v2>|提出了一种高效的主动学习策略Entity-Superpixel Annotation，通过利用图像结...|
|🆕 发布|Unlocking the Potential of MLLMs in Referring Expression Segmentation via a Light-weight Mask Decode|通过轻量级掩码解码解锁大规模语言模型在指代表达式分割中的潜力|Jingchao Wang, Zhijian Wu, Dingjiang Huang, Yefeng Zheng, Hong Wang|<http://arxiv.org/pdf/2508.04107v1>|[代码](https://github.com/jcwang0602/MLLMSeg.); 提出了一种轻量级框架MLLMSeg，通过融合视觉细节和语义特征，实现了高效的指代表达式分割。|
|🆕 发布|UNISELF: A Unified Network with Instance Normalization and Self-Ensembled Lesion Fusion for Multiple Sclerosis Lesion Segmentation|UNISELF：一种具有实例归一化和自集成病变融合的统一网络，用于多发性硬化症病变分割|Jinwei Zhang, Lianrui Zuo, Blake E. Dewey, Samuel W. Remedios, Yihao Liu, Savannah P. Hays, Dzung L. Pham, Ellen M. Mowry .etc.|<http://arxiv.org/pdf/2508.03982v1>|[代码](https://code is available at https://github.com/uponacceptance.); 提出UNISELF方法，通过自融合技术和特征归一化提升多发性硬化症病变分割的准确性和跨数据集泛化能力...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CostFilter-AD: Enhancing Anomaly Detection through Matching Cost Filtering|通过匹配代价过滤增强异常检测的CostFilter-AD方法|Zhe Zhang, Mingxiu Cai, Hanxiao Wang, Gaochang Wu, Tianyou Chai, Xiatian Zhu|<http://arxiv.org/pdf/2505.01476v3>|[代码](https://github.com/ZHE-SAPI/CostFilter-AD.); 引入成本滤波概念，提高无监督异常检测的准确性，通过抑制匹配噪声并保留边缘结构。|
|🆕 发布|Revisiting Continual Semantic Segmentation with Pre-trained Vision Models|重新审视基于预训练视觉模型的持续语义分割|Duzhen Zhang, Yong Ren, Wei Cong, Junhao Zheng, Qiaoyi Su, Shuncheng Jia, Zhong-Zhi Li, Xuanle Zhao .etc.|<http://arxiv.org/pdf/2508.04267v1>|揭示了预训练视觉模型固有的抗遗忘能力，并提出了简单有效的DFT*方法以提升持续语义分割性能。|
|📝 更新|Quaternion Sparse Decomposition for Multi-focus Color Image Fusion|四元数稀疏分解在多焦点彩色图像融合中的应用|Weihua Yang, Yicong Zhou|<http://arxiv.org/pdf/2505.02365v2>|提出了一种基于四元数的彩色图像融合框架，通过迭代学习图像细节和结构信息，实现了高质量的彩色图像融合。|
|🆕 发布|Excavate the potential of Single-Scale Features: A Decomposition Network for Water-Related Optical Image Enhancement|挖掘单尺度特征潜力：一种面向水相关光学图像增强的分解网络|Zheng Cheng, Wenri Wang, Guangyong Chen, Yakun Ju, Yihua Cheng, Zhisong Liu, Yanda Meng, Jintao Song|<http://arxiv.org/pdf/2508.04123v1>|提出单尺度特征分解网络，通过分离干净层和退化层，实现水下图像增强，无需多尺度特征融合。|
|📝 更新|ProbRadarM3F: mmWave Radar based Human Skeletal Pose Estimation with Probability Map Guided Multi-Format Feature Fusion|基于概率图引导的多格式特征融合的毫米波雷达人体骨骼姿态估计：ProbRadarM3F|Bing Zhu, Zixin He, Weiyi Xiong, Guanhua Ding, Tao Huang, Wei Xiang|<http://arxiv.org/pdf/2405.05164v4>|提出概率图引导的多格式特征融合模型ProbRadarM3F，利用毫米波雷达提高人体姿态估计准确性。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Drone Detection with Event Cameras|事件相机无人机检测|Gabriele Magrini, Lorenzo Berlincioni, Luca Cultrera, Federico Becattini, Pietro Pala|<http://arxiv.org/pdf/2508.04564v1>|利用事件相机技术，有效解决了传统监控在检测小型、高速移动无人机时的模糊和低效问题。|
|📝 更新|CapsoNet: A CNN-Transformer Ensemble for Multi-Class Abnormality Detection in Video Capsule Endoscopy|CapsoNet：一种用于视频胶囊内镜多类异常检测的卷积神经网络-Transformer集成方法|Arnav Samal, Ranya Batsyas|<http://arxiv.org/pdf/2410.18879v3>|[代码](http://github.com/arnavs04/capsule-vision-2024); 提出CapsoNet模型，融合CNN与Transformer架构，有效提升视频胶囊内镜多类异常检测准...|
|📝 更新|Spatial-Frequency Aware for Object Detection in RAW Image|空间频率感知的RAW图像目标检测|Zhuohua Ye, Liming Zhang, Hongru Han|<http://arxiv.org/pdf/2508.01396v2>|定位RAW图像中对象的新框架，通过结合空间与频率域特征，增强对象细节。|
|🆕 发布|Composed Object Retrieval: Object-level Retrieval via Composed Expressions|组合对象检索：通过组合表达式实现的对象级检索|Tong Wang, Guanyu Yang, Nian Liu, Zongyan Han, Jinxing Zhou, Salman Khan, Fahad Shahbaz Khan|<http://arxiv.org/pdf/2508.04424v1>|提出Composed Object Retrieval任务，通过结合参考物体和检索文本实现对象级检索...|
|🆕 发布|Think Before You Segment: An Object-aware Reasoning Agent for Referring Audio-Visual Segmentation|在分割之前思考：一种面向对象的推理代理用于指示性音频视觉分割|Jinxing Zhou, Yanghao Zhou, Mingfei Han, Tong Wang, Xiaojun Chang, Hisham Cholakkal, Rao Muhammad Anwer|<http://arxiv.org/pdf/2508.04418v1>|[代码](https://github.com/jasongief/TGS-Agent.); 提出了一种分步骤推理的音频视觉分割方法TGS-Agent，通过显式理解参考信息实现无需像素级监督的高...|
|📝 更新|AURA: A Hybrid Spatiotemporal-Chromatic Framework for Robust, Real-Time Detection of Industrial Smoke Emissions|AURA：一种用于稳健实时检测工业烟雾排放的混合时空-彩色框架|Mikhail Bychkov, Matey Yordanov, Andrei Kuchma|<http://arxiv.org/pdf/2508.01095v2>|提出了一种融合时空和色彩特征的框架，实现了对工业烟雾排放的实时准确检测与分类。|
|🆕 发布|RPCANet++: Deep Interpretable Robust PCA for Sparse Object Segmentation|RPCANet++：深度可解释稳健主成分分析网络用于稀疏目标分割|Fengyi Wu, Yimian Dai, Tianfang Zhang, Yixuan Ding, Jian Yang, Ming-Ming Cheng, Zhenming Peng|<http://arxiv.org/pdf/2508.04190v1>|[代码](https://fengyiwu98.github.io/rpcanetx.); 提出了一种融合RPCA可解释性与深度架构的高效稀疏目标分割框架RPCANet++，提升了计算效率和适...|
|🆕 发布|SVC 2025: the First Multimodal Deception Detection Challenge|SVC 2025：首届多模态欺骗检测挑战赛|Xun Lin, Xiaobao Guo, Taorui Wang, Yingjie Ma, Jiajian Huang, Jiayu Zhang, Junzhe Cao, Zitong Yu|<http://arxiv.org/pdf/2508.04129v1>|提出首个多模态欺骗检测挑战，旨在促进跨领域泛化的音频视觉欺骗检测模型开发。|
|🆕 发布|Learning Using Privileged Information for Litter Detection|利用特权信息进行垃圾检测的学习|Matthias Bartolo, Konstantinos Makantasis, Dylan Seychell|<http://arxiv.org/pdf/2508.04124v1>|首次结合特权信息与深度学习进行垃圾检测，提升准确性的同时保持模型效率。|
|🆕 发布|DOMR: Establishing Cross-View Segmentation via Dense Object Matching|DOMR: 通过密集对象匹配建立跨视图分割|Jitong Liao, Yulu Gao, Shaofei Huang, Jialin Gao, Jie Lei, Ronghua Liang, Si Liu|<http://arxiv.org/pdf/2508.04050v1>|提出DOMR框架，通过密集对象匹配和细化实现第一人称与第三人称视角下的对象对应。|
|🆕 发布|CORE-ReID V2: Advancing the Domain Adaptation for Object Re-Identification with Optimized Training and Ensemble Fusion|CORE-ReID V2：通过优化训练和集成融合推进对象重识别的域自适应|Trinh Quoc Nguyen, Oky Dicky Ardiansyah Prima, Syahid Al Irfan, Hindriyanto Dwi Purnomo, Radius Tanone|<http://arxiv.org/pdf/2508.04036v1>|[代码](https://github.com/TrinhQuocNguyen/CORE-ReID-V2.); 提出了一种优化训练和集成融合的域自适应框架，显著提升了各类目标重识别的准确性和效率。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A machine learning approach for image classification in synthetic aperture RADAR|合成孔径雷达图像分类的机器学习方法|Romina Gaburro, Patrick Healy, Shraddha Naidu, Clifford Nolan|<http://arxiv.org/pdf/2508.04234v1>|利用卷积神经网络对合成孔径雷达图像进行分类，实现了75%以上的高准确率。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HierarchicalPrune: Position-Aware Compression for Large-Scale Diffusion Models|层次剪枝：面向大规模扩散模型的位置感知压缩|Young D. Kwon, Rui Li, Sijia Li, Da Li, Sourav Bhattacharya, Stylianos I. Venieris|<http://arxiv.org/pdf/2508.04663v1>|提出HierarchicalPrune压缩框架，针对文本到图像模型进行位置感知压缩，实现内存和延迟显...|
|🆕 发布|TAlignDiff: Automatic Tooth Alignment assisted by Diffusion-based Transformation Learning|TAlignDiff：基于扩散变换学习的自动牙齿对齐辅助方法|Yunbi Liu, Enqi Tang, Shiyu Li, Lei Ma, Juncheng Li, Shu Lou, Yongchu Pan, Qingshan Liu|<http://arxiv.org/pdf/2508.04565v1>|提出了一种基于扩散学习的自动牙齿对齐方法，通过学习变换矩阵的潜在分布，提高了正畸治疗的精确性和效率。|
|🆕 发布|DDTracking: A Deep Generative Framework for Diffusion MRI Tractography with Streamline Local-Global Spatiotemporal Modeling|DDTracking：一种具有纤维局部-全局时空建模的深度生成框架用于扩散MRI追踪术|Yijie Li, Wei Zhang, Xi Zhu, Ye Wu, Yogesh Rathi, Lauren J. O'Donnell, Fan Zhang|<http://arxiv.org/pdf/2508.04568v1>|[代码](https://github.com/yishengpoxiao/DDtracking.git); 提出了一种深度生成框架DDTracking，通过局部-全局时空建模显著提升了扩散MRI追踪的准确性和...|
|🆕 发布|One Model For All: Partial Diffusion for Unified Try-On and Try-Off in Any Pose|《一模型通用：任意姿态下的统一试穿与脱卸的局部扩散方法》|Jinxi Liu, Zijian He, Guangrun Wang, Guanbin Li, Liang Lin|<http://arxiv.org/pdf/2508.04559v1>|[代码](https://onemodelforall.github.io/.); 提出了一种无需展品衣物和分割掩膜的统一扩散框架，实现了任意姿态下的虚拟试穿和脱衣。|
|🆕 发布|Two-Way Garment Transfer: Unified Diffusion Framework for Dressing and Undressing Synthesis|双向衣物转移：统一的扩散框架实现穿衣与脱衣合成|Angang Zhang, Fang Deng, Hao Chen, Zhongjian Chen, Junyan Li|<http://arxiv.org/pdf/2508.04551v1>|提出了一种统一框架，双向解决虚拟穿衣与脱衣合成问题，通过特征解耦和分阶段训练实现高效转换。|
|📝 更新|Nonlocal Retinex-Based Variational Model and its Deep Unfolding Twin for Low-Light Image Enhancement|基于非局部Retinex的变分模型及其深度展开双胞胎网络用于低光照图像增强|Daniel Torres, Joan Duran, Julia Navarro, Catalina Sbert|<http://arxiv.org/pdf/2504.07810v2>|提出了一种基于Retinex分解和深度学习的低光照图像增强方法，有效保留了图像细节并提高了视觉效果。|
|🆕 发布|Deep Learning-based Scalable Image-to-3D Facade Parser for Generating Thermal 3D Building Models|基于深度学习的可扩展图像到3D立面解析器：用于生成热3D建筑模型|Yinan Yu, Alex Gonzalez-Caceres, Samuel Scheidegger, Sanjay Somanath, Alexander Hollberg|<http://arxiv.org/pdf/2508.04406v1>|提出了一种基于深度学习的图像到3D建筑立面解析方法，实现了高精度热能模型的快速生成。|
|📝 更新|Bidirectional Likelihood Estimation with Multi-Modal Large Language Models for Text-Video Retrieval|基于多模态大型语言模型的文本-视频检索双向似然估计|Dohwan Ko, Ji Soo Lee, Minhyuk Choi, Zihang Meng, Hyunwoo J. Kim|<http://arxiv.org/pdf/2507.23284v2>|[代码](https://github.com/mlvlab/BLiM.); 提出双向概率估计框架BLiM和候选先验归一化方法，有效减轻文本视频检索中的先验偏差，提升查询-候选相...|
|🆕 发布|TSPO: Temporal Sampling Policy Optimization for Long-form Video Language Understanding|TSPO：长视频语言理解的时间采样策略优化|Canhui Tang, Zifan Han, Hongbo Sun, Sanping Zhou, Xuchong Zhang, Xin Wei, Ye Yuan, Jinglin Xu .etc.|<http://arxiv.org/pdf/2508.04369v1>|提出了一种基于强化学习的视频采样策略优化方法，有效提升长视频语言理解能力。|
|📝 更新|PiT: Progressive Diffusion Transformer|渐进式扩散变换器：PiT|Jiafu Wu, Yabiao Wang, Jian Li, Jinlong Peng, Yun Cao, Chengjie Wang, Jiangning Zhang|<http://arxiv.org/pdf/2505.13219v3>|提出 PiT 方法，通过优化注意力机制降低计算成本，提升图像生成性能。|
|🆕 发布|DocVCE: Diffusion-based Visual Counterfactual Explanations for Document Image Classification|DocVCE：基于扩散的文档图像分类视觉反事实解释|Saifullah Saifullah, Stefan Agne, Andreas Dengel, Sheraz Ahmed|<http://arxiv.org/pdf/2508.04233v1>|定位文档图像分类模型的不透明性，提出DocVCE方法，通过生成性对抗示例提供直观解释。|
|📝 更新|Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise|"随流而行：使用实时扭曲噪声的运动可控视频扩散模型"|Ryan Burgert, Yuancheng Xu, Wenqi Xian, Oliver Pilarski, Pascal Clausen, Mingming He, Li Ma, Yitong Deng .etc.|<http://arxiv.org/pdf/2501.08331v5>|[代码](https://github.com/Eyeline-Labs/Go-with-the-Flow.); 提出了一种实时控制视频生成中运动的算法，通过结构化噪声采样实现高效的运动控制。|
|📝 更新|Modality and Task Adaptation for Enhanced Zero-shot Composed Image Retrieval|模态与任务自适应增强零样本组合图像检索|Haiwen Li, Fei Su, Zhicheng Zhao|<http://arxiv.org/pdf/2410.23736v2>|提出了一种轻量级后处理框架，通过构建文本锚定的三元组数据集和参数高效的适配器，有效解决了零样本组合图...|
|📝 更新|Risk-Based Thresholding for Reliable Anomaly Detection in Concentrated Solar Power Plants|基于风险的阈值设定以实现集中太阳能发电站可靠异常检测|Yorick Estievenart, Sukanya Patra, Souhaib Ben Taieb|<http://arxiv.org/pdf/2503.19146v2>|提出风险控制框架优化太阳能发电站异常检测阈值，确保有限样本覆盖和高效运维决策。|
|🆕 发布|Conditional Latent Diffusion Models for Zero-Shot Instance Segmentation|条件潜在扩散模型用于零样本实例分割|Maximilian Ulmer, Wout Boerdijk, Rudolph Triebel, Maximilian Durner|<http://arxiv.org/pdf/2508.04122v1>|提出了一种基于扩散模型的无监督实例分割方法，通过对象模板和图像特征实现精准的对象分离。|
|🆕 发布|Bridging Diffusion Models and 3D Representations: A 3D Consistent Super-Resolution Framework|构建扩散模型与3D表示的桥梁：一个3D一致性超分辨率框架|Yi-Ting Chen, Ting-Hsuan Liao, Pengsheng Guo, Alexander Schwing, Jia-Bin Huang|<http://arxiv.org/pdf/2508.04090v1>|提出了一种基于3D高斯投影的超级分辨率框架，通过显式保持三维一致性，提升了视觉质量和结构一致性。|
|🆕 发布|RLGS: Reinforcement Learning-Based Adaptive Hyperparameter Tuning for Gaussian Splatting|基于强化学习的自适应超参数调整方法用于高斯散点绘制：RLGS|Zhan Li, Huangying Zhan, Changyang Li, Qingan Yan, Yi Xu|<http://arxiv.org/pdf/2508.04078v1>|提出了一种基于强化学习的自适应超参数调整方法RLGS，自动化优化3D Gaussian Splatt...|
|🆕 发布|SPJFNet: Self-Mining Prior-Guided Joint Frequency Enhancement for Ultra-Efficient Dark Image Restoration|SPJFNet：自挖掘先验引导联合频率增强的超高效暗图像恢复|Tongshun Zhang, Pingling Liu, Zijian Zhang, Qiuzhan Zhou|<http://arxiv.org/pdf/2508.04041v1>|[代码](https://github.com/bywlzts/SPJFNet.); 提出了一种高效的暗光图像复原网络，通过内生指导模块和双频处理框架，大幅提升了效率和性能。|
|🆕 发布|Uni-DocDiff: A Unified Document Restoration Model Based on Diffusion|统一文档恢复模型：基于扩散的Uni-DocDiff|Fangmin Zhao, Weichao Zeng, Zhenhang Li, Dongbao Yang, Binbin Li, Xiaojun Bi, Yu Zhou|<http://arxiv.org/pdf/2508.04055v1>|提出了一种基于扩散模型的统一文档修复方法，实现了多任务的高效处理和无缝扩展。|
|📝 更新|Understanding Flatness in Generative Models: Its Role and Benefits|生成模型中平坦性的理解：其作用与优势|Taehwan Lee, Kyeongkook Seo, Jaejun Yoo, Sung Whan Yoon|<http://arxiv.org/pdf/2503.11078v2>|探究生成模型中损失表面平坦性的作用，提出Sharpness-Aware Minimization增强...|
|🆕 发布|$\text{S}^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation|$\text{S}^2$Q-VDiT：精确量化视频扩散变换器，采用显著数据与稀疏令牌蒸馏|Weilun Feng, Haotong Qin, Chuanguang Yang, Xiangqi Li, Han Yang, Yuqi Li, Zhulin An, Libo Huang .etc.|<http://arxiv.org/pdf/2508.04016v1>|[代码](https://github.com/wlfeng0509/s2q-vdit); 提出$\text{S}^2$Q-VDiT框架，通过关键数据选择和稀疏注意力蒸馏，实现视频生成模型的量...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|The Aging Multiverse: Generating Condition-Aware Facial Aging Tree via Training-Free Diffusion|《老龄化多元宇宙：通过无需训练的扩散生成条件感知面部老化树》|Bang Gong, Luchao Qi, Jiaye Wu, Zhicheng Fu, Chunbo Song, David W. Jacobs, John Nicholson, Roni Sengupta|<http://arxiv.org/pdf/2506.21008v3>|提出了一种无需训练的扩散方法，生成受环境、健康和生活方式影响的多样化面部老化轨迹。|
|📝 更新|JointTuner: Appearance-Motion Adaptive Joint Training for Customized Video Generation|《JointTuner：面向定制视频生成的外观-运动自适应联合训练》|Fangda Chen, Shanshan Zhao, Chuanfu Xu, Long Lan|<http://arxiv.org/pdf/2503.23951v2>|[代码](https://fdchen24.github.io/JointTuner-Website.); 提出了一种联合优化外观与动作的JointTuner框架，通过创新技术减少干扰，生成更高质量的定制视频...|
|📝 更新|AgentSense: Virtual Sensor Data Generation Using LLM Agents in Simulated Home Environments|AgentSense：使用大型语言模型代理在模拟家庭环境中生成虚拟传感器数据|Zikang Leng, Megha Thukral, Yaqi Liu, Hrudhai Rajasekhar, Shruthi K. Hiremath, Jiaman He, Thomas Plötz|<http://arxiv.org/pdf/2506.11773v3>|提出利用大型语言模型指导虚拟智能体在模拟环境中生成多样化、隐私保护的虚拟传感器数据，有效提升智能行为...|
|🆕 发布|RAIDX: A Retrieval-Augmented Generation and GRPO Reinforcement Learning Framework for Explainable Deepfake Detection|RAIDX：一种用于可解释深度伪造检测的检索增强生成与GRPO强化学习框架|Tianxiao Li, Zhenglin Huang, Haiquan Wen, Yiwei He, Shuchang Lyu, Baoyuan Wu, Guangliang Cheng|<http://arxiv.org/pdf/2508.04524v1>|提出RAIDX框架，结合检索增强生成与强化学习，提升深伪检测准确性和解释性。|
|🆕 发布|Conditional Fetal Brain Atlas Learning for Automatic Tissue Segmentation|条件性胎儿大脑图谱学习用于自动组织分割|Johannes Tischer, Patric Kienast, Marlene Stümpflen, Gregor Kasprian, Georg Langs, Roxane Licandro|<http://arxiv.org/pdf/2508.04522v1>|[代码](https://github.com/cirmuw/fetal-brain-atlas); 定位胎脑发育，提出深度学习框架，实现实时精准组织分割。|
|📝 更新|FFHQ-Makeup: Paired Synthetic Makeup Dataset with Facial Consistency Across Multiple Styles|FFHQ-化妆：具有面部一致性跨多种风格的配对合成化妆数据集|Xingchao Yang, Shiori Ueda, Yuantian Huang, Tomoya Akiyama, Takafumi Taketomi|<http://arxiv.org/pdf/2508.03241v2>|构建了FFHQ-Makeup数据集，通过改进的妆容转移技术保持了面部一致性和多样性。|
|📝 更新|T2VEval: Benchmark Dataset and Objective Evaluation Method for T2V-generated Videos|T2VEval：用于T2V生成视频的基准数据集和客观评估方法|Zelu Qi, Ping Shi, Shuqi Wang, Chaoyang Zhang, Fei Zhao, Zefeng Ying, Da Pan, Xi Yang .etc.|<http://arxiv.org/pdf/2501.08545v7>|提出T2VEval-Bench数据集和T2VEval评价方法，全面评估文本到视频生成质量。|
|📝 更新|Ctrl-Z Sampling: Diffusion Sampling with Controlled Random Zigzag Explorations|控制随机之字形探索的扩散采样：Ctrl-Z采样|Shunqi Mao, Wei Guo, Chaoyi Zhang, Jieting Long, Ke Xie, Weidong Cai|<http://arxiv.org/pdf/2506.20294v2>|提出了一种自适应的Ctrl-Z Sampling方法，通过控制随机之字形探索有效逃离扩散模型中的局部...|
|📝 更新|MARRS: Masked Autoregressive Unit-based Reaction Synthesis|遮蔽自回归单元基础的反应合成：MARRS|Yabiao Wang, Shuo Wang, Jiangning Zhang, Jiafu Wu, Qingdong He, Yong Liu|<http://arxiv.org/pdf/2505.11334v2>|提出了一种生成协同精细反应动作的框架MARRS，通过连续表示和单元区分编码独立处理身体与手部动作。|
|📝 更新|READ: Real-time and Efficient Asynchronous Diffusion for Audio-driven Talking Head Generation|《READ：面向音频驱动说话人头生成的实时高效异步扩散》|Haotian Wang, Yuzhe Weng, Jun Du, Haoran Xu, Xiaoyan Wu, Shan He, Bing Yin, Cong Liu .etc.|<http://arxiv.org/pdf/2508.03457v2>|提出实时高效的异步扩散框架READ，通过压缩视频潜空间和异步调度，加速音频驱动的说话人头生成。|
|🆕 发布|TempFlow-GRPO: When Timing Matters for GRPO in Flow Models|时间敏感的GRPO：在流模型中时间因素对GRPO的重要性|Xiaoxuan He, Siming Fu, Yuke Zhao, Wanli Li, Jian Yang, Dacheng Yin, Fengyun Rao, Bo Zhang|<http://arxiv.org/pdf/2508.04324v1>|提出了一种针对生成模型的新型时序优化框架TempFlow-GRPO，通过轨迹分支机制和噪声感知权重方...|
|📝 更新|XSpecMesh: Quality-Preserving Auto-Regressive Mesh Generation Acceleration via Multi-Head Speculative Decoding|XSpecMesh：通过多头投机解码保持质量的自回归网格生成加速|Dian Chen, Yansong Qu, Xinyang Li, Ming Li, Shengchuan Zhang|<http://arxiv.org/pdf/2507.23777v2>|提出了一种加速自动回归网格生成的方法XSpecMesh，通过多头投机解码并行预测，大幅提高了生成速度...|
|🆕 发布|PIS3R: Very Large Parallax Image Stitching via Deep 3D Reconstruction|PIS3R：通过深度三维重建实现超大幅视差图像拼接|Muhua Zhu, Xinhao Jin, Chengbo Wang, Yongcong Zhang, Yifei Xue, Tie Ji, Yizhen Lao|<http://arxiv.org/pdf/2508.04236v1>|提出了一种基于深度三维重建的大视差图像拼接方法，有效处理了场景深度变化和相机基线引起的视差问题。|
|📝 更新|Pinco: Position-induced Consistent Adapter for Diffusion Transformer in Foreground-conditioned Inpainting|Pinco：前景条件下扩散变换中的位置诱导一致性适配器|Guangben Lu, Yuzhen Du, Zhimin Sun, Ran Yi, Yifan Qi, Yizhe Tang, Tianyi Wang, Lizhuang Ma .etc.|<http://arxiv.org/pdf/2412.03812v2>|提出Pinco，一种创新的适配器，通过整合前景特征和布局注意力，有效解决了前景条件图像修复中的形状保...|
|📝 更新|CCStereo: Audio-Visual Contextual and Contrastive Learning for Binaural Audio Generation|CCStereo：基于音频-视觉上下文和对比学习的双耳音频生成|Yuanhong Chen, Kazuki Shimada, Christian Simon, Yukara Ikemiya, Takashi Shibuya, Yuki Mitsufuji|<http://arxiv.org/pdf/2501.02786v2>|提出了一种结合音频视觉条件和对比学习的立体声生成模型，提高了空间细节的准确捕捉能力。|
|📝 更新|WAVE: Warp-Based View Guidance for Consistent Novel View Synthesis Using a Single Image|基于扭曲的视图引导的单张图像一致性新视图合成方法WAVE|Jiwoo Park, Tae Eun Choi, Youngjun Jun, Seong Jae Hwang|<http://arxiv.org/pdf/2506.23518v2>|提出了一种无需额外模块的图像生成方法，通过视图引导的扭曲增强扩散模型，实现了高质量的新视角合成的一致...|
|🆕 发布|Deeper Inside Deep ViT|深入探究深度视觉变换器（Deep ViT）|Sungrae Hong|<http://arxiv.org/pdf/2508.04181v1>|探究了大规模视觉模型ViT-22B的实用性并优化其训练稳定性，同时提出基于ViT的图像生成架构。|
|🆕 发布|Uncertainty-Aware Spatial Color Correlation for Low-Light Image Enhancement|低光照图像增强的不确定性感知空间颜色相关性|Jin Kuang, Dong Liu, Yukuang Zhang, Shengsheng Wang|<http://arxiv.org/pdf/2508.04176v1>|提出了一种考虑不确定性的图像增强框架，通过抑制噪声和建立因果关系显著提升低光图像质量。|
|📝 更新|Automatic Synthesis of High-Quality Triplet Data for Composed Image Retrieval|自动合成高质量三元组数据以用于组合图像检索|Haiwen Li, Delong Liu, Zhaohui Hou, Zhicheng Zhao, Fei Su|<http://arxiv.org/pdf/2507.05970v2>|提出自动生成高质量三元组数据的方案，实现零样本图像检索，并引入Hybrid Contextual A...|
|🆕 发布|IDCNet: Guided Video Diffusion for Metric-Consistent RGBD Scene Generation with Precise Camera Control|IDCNet：具有精确相机控制的度量一致RGBD场景生成的引导视频扩散|Lijuan Liu, Wenfa Li, Dongbo Zhang, Shuo Wang, Shaohui Jiao|<http://arxiv.org/pdf/2508.04147v1>|IDC-Net通过统一框架联合生成RGB图像和深度图，实现了精确相机控制和高几何一致性的RGB-D场...|
|🆕 发布|FLAT: Latent-Driven Arbitrary-Target Backdoor Attacks in Federated Learning|FLAT: 联邦学习中基于潜在驱动的任意目标后门攻击|Tuan Nguyen, Khoa D Doan, Kok-Seng Wong|<http://arxiv.org/pdf/2508.04064v1>|提出FLAT方法，利用潜在代码生成多样化后门触发器，实现联邦学习中灵活的多目标攻击。|
|📝 更新|Disentangle Identity, Cooperate Emotion: Correlation-Aware Emotional Talking Portrait Generation|解耦身份，协同情感：相关感知的情感对话肖像生成|Weipeng Tan, Chuming Lin, Chengming Xu, FeiFan Xu, Xiaobin Hu, Xiaozhong Ji, Junwei Zhu, Chengjie Wang .etc.|<http://arxiv.org/pdf/2504.18087v2>|提出了一种解耦身份与情感并增强情感相关性的方法，有效生成保持身份特征的情感化动态肖像。|
|🆕 发布|PET2Rep: Towards Vision-Language Model-Drived Automated Radiology Report Generation for Positron Emission Tomography|PET2Rep: 面向正电子发射断层扫描的视觉-语言模型驱动的自动化放射学报告生成方法|Yichi Zhang, Wenbo Zhang, Zehui Ling, Gang Feng, Sisi Peng, Deshu Chen, Yuchen Liu, Hongwei Zhang .etc.|<http://arxiv.org/pdf/2508.04062v1>|提出PET2Rep，首个针对PET影像报告生成的大规模数据集，并引入临床效率指标评估模型性能。|
|📝 更新|Dual-Expert Consistency Model for Efficient and High-Quality Video Generation|双专家一致性模型用于高效和高品质视频生成|Zhengyao Lv, Chenyang Si, Tianlin Pan, Zhaoxi Chen, Kwan-Yee K. Wong, Yu Qiao, Ziwei Liu|<http://arxiv.org/pdf/2506.03123v2>|[代码](https://github.com/Vchitect/DCM); 提出双专家一致性模型，通过专家分工优化视频生成质量和效率。|
|🆕 发布|CAD-Judge: Toward Efficient Morphological Grading and Verification for Text-to-CAD Generation|CAD-Judge：面向文本到CAD生成的形态学分级与验证高效方法|Zheyuan Zhou, Jiayi Han, Liang Du, Naiyu Fang, Lemiao Qiu, Shuyou Zhang|<http://arxiv.org/pdf/2508.04002v1>|提出CAD-Judge系统，通过编译器模块优化奖励信号，高效评估和验证文本到CAD模型的生成。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MSC: A Marine Wildlife Video Dataset with Grounded Segmentation and Clip-Level Captioning|海洋野生动物视频数据集：带有地面分割和片段级标注的MSC|Quang-Trung Truong, Yuk-Kwan Wong, Vo Hoang Kim Tuyen Dang, Rinaldi Gotama, Duc Thanh Nguyen, Sai-Kit Yeung|<http://arxiv.org/pdf/2508.04549v1>|提出了一种针对海洋生物视频的理解和生成方法，通过结合视频、文本和分割掩膜提升视觉定位和字幕生成效果。|
|🆕 发布|4DVD: Cascaded Dense-view Video Diffusion Model for High-quality 4D Content Generation|级联密集视角视频扩散模型4DVD：用于高质量四维内容生成的级联密集视角视频扩散模型|Shuzhou Yang, Xiaodong Cun, Xiaoyu Li, Yaowei Li, Jian Zhang|<http://arxiv.org/pdf/2508.04467v1>|提出了一种分步骤生成的4D内容创建模型4DVD，通过解耦多视角布局生成与结构感知条件生成，实现了高质...|
|🆕 发布|Gather and Trace: Rethinking Video TextVQA from an Instance-oriented Perspective|“收集与追踪：从实例导向的角度重新思考视频文本视觉问答”|Yan Zhang, Gangyan Zeng, Daiqing Wu, Huawen Shen, Binbin Li, Yu Zhou, Can Ma, Xiaojun Bi|<http://arxiv.org/pdf/2508.04197v1>|[代码](https://github.com/zhangyan-ucas/GAT.); 提出实例导向的Video TextVQA模型GAT，通过聚合视觉特征和动态追踪文本轨迹，提升准确性和...|
|📝 更新|Macro-from-Micro Planning for High-Quality and Parallelized Autoregressive Long Video Generation|从微观到宏观规划实现高质量并行化自回归长视频生成|Xunzhi Xiang, Yabo Chen, Guiyu Zhang, Zhongyu Wang, Zhe Gao, Quanming Xiang, Gonghu Shang, Junqi Liu .etc.|<http://arxiv.org/pdf/2508.03334v2>|提出了一种长视频生成的新框架Macro-from-Micro Planning，通过分阶段规划和并行...|
|📝 更新|Beyond Wide-Angle Images: Structure-to-Detail Video Portrait Correction via Unsupervised Spatiotemporal Adaptation|超越广角图像：通过无监督时空适应的结构到细节视频人像校正|Wenbo Nie, Lang Nie, Chunyu Lin, Jingwen Chen, Ke Xing, Jiyuan Wang, Kang Liao|<http://arxiv.org/pdf/2504.00401v2>|提出了一种无需标注的时空自适应方法，用于修正广角视频中面部拉伸变形，实现高质量且稳定自然的肖像修正。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Uni3R: Unified 3D Reconstruction and Semantic Understanding via Generalizable Gaussian Splatting from Unposed Multi-View Images|统一三维重建与语义理解：通过未定位多视角图像的泛化高斯散点绘制方法|Xiangyu Sun, Haoyi jiang, Liu Liu, Seungtae Nam, Gyeongjin Kang, Xinjie wang, Wei Sui, Zhizhong Su .etc.|<http://arxiv.org/pdf/2508.03643v2>|[代码](https://github.com/HorizonRobotics/Uni3R.); Uni3R通过一种创新的统一框架，直接从无定位多视角图像中实现了高效的3D场景重建和语义理解。|
|🆕 发布|OS Agents: A Survey on MLLM-based Agents for General Computing Devices Use|操作系统智能体：面向通用计算设备使用的基于大规模语言模型智能体的综述|Xueyu Hu, Tao Xiong, Biao Yi, Zishu Wei, Ruixuan Xiao, Yurun Chen, Jiasheng Ye, Meiling Tao .etc.|<http://arxiv.org/pdf/2508.04482v1>|系统梳理了基于大型语言模型的操作系统代理研究，展望了未来发展方向。|
|📝 更新|OpenScan: A Benchmark for Generalized Open-Vocabulary 3D Scene Understanding|开放扫描：一种用于广义开放词汇三维场景理解的基础数据集|Youjun Zhao, Jiaying Lin, Shuquan Ye, Qianshi Pang, Rynson W. H. Lau|<http://arxiv.org/pdf/2408.11030v3>|提出广义开放词汇三维场景理解任务，并创建OpenScan基准，挑战现有模型对抽象属性的理解。|
|🆕 发布|MuGS: Multi-Baseline Generalizable Gaussian Splatting Reconstruction|多基线泛化高斯散点重建方法（MuGS）|Yaopeng Lou, Liao Shen, Tianqi Liu, Jiaqi Li, Zihao Huang, Huiqiang Sun, Zhiguo Cao|<http://arxiv.org/pdf/2508.04297v1>|提出了一种通用的新型视图合成方法MuRF，融合多视角和单目深度估计特征，有效处理不同基线设置下的重建...|
|🆕 发布|PKSS-Align: Robust Point Cloud Registration on Pre-Kendall Shape Space|PKSS-Align：预-肯德尔形状空间上的鲁棒点云配准|Chenlei Lv, Hui Huang|<http://arxiv.org/pdf/2508.04286v1>|提出了一种鲁棒的点云配准方法PKSS-Align，有效应对相似变换、非均匀密度、随机噪声和残缺部分的...|
|🆕 发布|LayerT2V: Interactive Multi-Object Trajectory Layering for Video Generation|《LayerT2V：用于视频生成的交互式多目标轨迹分层》|Kangrui Cen, Baixuan Zhao, Yi Xin, Siqi Luo, Guangtao Zhai, Xiaohong Liu|<http://arxiv.org/pdf/2508.04228v1>|[代码](https://kr-panghu.github.io/LayerT2V); 提出了一种分层生成视频的方法LayerT2V，有效解决了多物体运动轨迹控制问题，提高了复杂场景的生成...|
|📝 更新|Consistent and Invariant Generalization Learning for Short-video Misinformation Detection|一致性与不变性泛化学习在短视频虚假信息检测中的应用|Hanghui Guo, Weijie Shi, Mengze Li, Juncheng Li, Hao Chen, Yue Cui, Jiajie Xu, Jia Zhu .etc.|<http://arxiv.org/pdf/2507.04061v2>|[代码](https://github.com/ghh1125/DOCTOR.); 提出了一种通过跨模态特征插值和扩散模型增强域泛化能力的短视频 misinformation 检测方法...|
|📝 更新|CLIP-AGIQA: Boosting the Performance of AI-Generated Image Quality Assessment with CLIP|CLIP-AGIQA：利用CLIP提升人工智能生成图像质量评估的性能|Zhenchen Tang, Zichuan Wang, Bo Peng, Jing Dong|<http://arxiv.org/pdf/2408.15098v3>|提出CLIP-AGIQA模型，利用CLIP的视觉与文本知识评估生成图像质量，超越现有评估技术。|
|🆕 发布|Motion is the Choreographer: Learning Latent Pose Dynamics for Seamless Sign Language Generation|“运动是编舞者：学习潜在姿态动力学以实现无缝手语生成”|Jiayi He, Xu Wang, Shengeng Tang, Yaxiong Wang, Lechao Cheng, Dan Guo|<http://arxiv.org/pdf/2508.04049v1>|提出两阶段生成框架，将手语动作与特定打签者分离，实现高质量且个性化的手语视频生成。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PixCuboid: Room Layout Estimation from Multi-view Featuremetric Alignment|《PixCuboid：基于多视角特征度量对齐的房间布局估计》|Gustav Hanning, Kalle Åström, Viktor Larsson|<http://arxiv.org/pdf/2508.04659v1>|[代码](https://github.com/ghanning/PixCuboid.); 提出基于多视角特征匹配的优化方法PixCuboid，用于估计房间布局，实现优于现有方法的准确度。|
|🆕 发布|Pseudo Depth Meets Gaussian: A Feed-forward RGB SLAM Baseline|伪深度与高斯相遇：一种前向传播RGB SLAM基线|Linqing Zhao, Xiuwei Xu, Yirui Wang, Hao Wang, Wenzhao Zheng, Yansong Tang, Haibin Yan, Jiwen Lu|<http://arxiv.org/pdf/2508.04597v1>|提出了一种结合3D高斯映射和前馈网络的RGB SLAM方法，大幅提升追踪速度并保持重建精度。|
|🆕 发布|OmniDepth: Bridging Monocular and Stereo Reasoning with Latent Alignment|全方位深度：通过潜在对齐桥接单目与立体推理|Tongfan Guan, Jiaxin Guo, Chen Wang, Yun-Hui Liu|<http://arxiv.org/pdf/2508.04611v1>|[代码](https://github.com/aeolusguan/OmniDepth.); OmniDepth通过迭代双向对齐单目和立体视觉的潜在表征，有效融合两者的优势，实现了更准确的深度估...|
|📝 更新|GR-Gaussian: Graph-Based Radiative Gaussian Splatting for Sparse-View CT Reconstruction|基于图辐射高斯散点法的稀疏视角CT重建|Yikuang Yuluo, Yue Ma, Kuan Shen, Tongtong Jin, Wang Liao, Yangpu Ma, Fuquan Wang|<http://arxiv.org/pdf/2508.02408v2>|提出了一种基于图的GR-Gaussian方法，有效抑制了稀疏视角下的针状伪影并提升了CT重建精度。|
|🆕 发布|MonoCloth: Reconstruction and Animation of Cloth-Decoupled Human Avatars from Monocular Videos|单目视频中的布料解耦人体模型的重建与动画制作|Daisheng Jin, Ying He|<http://arxiv.org/pdf/2508.04505v1>|MonoCloth通过分部件重建与专门模拟服装变形，从单目视频实现高质量人体Avatar的重建与动画...|
|🆕 发布|Surf3R: Rapid Surface Reconstruction from Sparse RGB Views in Seconds|Surf3R：秒级速度从稀疏RGB视角进行快速表面重建|Haodong Zhu, Changbai Li, Yangyang Ren, Zichao Feng, Xuhui Liu, Hanlin Chen, Xiantong Zhen, Baochang Zhang|<http://arxiv.org/pdf/2508.04508v1>|Surf3R通过无需相机校准的端到端方法，实现了从稀疏RGB视角在数秒内快速重建3D表面。|
|🆕 发布|RotatedMVPS: Multi-view Photometric Stereo with Rotated Natural Light|旋转多视角光度立体法：利用旋转自然光的多视角光度立体技术|Songyun Yang, Yufei Han, Jilong Zhang, Kongming Liang, Peng Yu, Zhaowei Qu, Heng Guo|<http://arxiv.org/pdf/2508.04366v1>|提出了一种在旋转自然光条件下实现形状和反射率恢复的多视角光度立体方法RotatedMVPS，通过确保...|
|🆕 发布|DET-GS: Depth- and Edge-Aware Regularization for High-Fidelity 3D Gaussian Splatting|DET-GS：深度与边缘感知的正则化方法用于高保真三维高斯散点绘制|Zexu Huang, Min Xu, Stuart Perry|<http://arxiv.org/pdf/2508.04099v1>|提出了一种深度和边缘感知的正则化框架，提高了三维高斯散点法的几何准确性和视觉保真度。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DivCon-NeRF: Diverse and Consistent Ray Augmentation for Few-Shot NeRF|DivCon-NeRF：多样化与一致性射线增强用于少量样本的NeRF|Ingyun Lee, Jae Won Jang, Seunghyeon Seo, Nojun Kwak|<http://arxiv.org/pdf/2503.12947v2>|提出DivCon-NeRF方法，通过球形射线增强提高少量样本下NeRF的多样性和一致性。|
|📝 更新|UnMix-NeRF: Spectral Unmixing Meets Neural Radiance Fields|光谱解混遇见神经辐射场：UnMix-NeRF|Fabian Perez, Sara Rojas, Carlos Hinojosa, Hoover Rueda-Chacón, Bernard Ghanem|<http://arxiv.org/pdf/2506.21884v2>|将光谱解混与神经辐射场结合，实现无需标注的材质分割和超光谱视图合成。|
|📝 更新|AtmosMJ: Revisiting Gating Mechanism for AI Weather Forecasting Beyond the Year Scale|大气MJ：重新审视AI天气预报中的门控机制，超越年度尺度|Minjong Cheon|<http://arxiv.org/pdf/2506.09733v2>|提出了一种新型Gated Residual Fusion机制，实现了标准网格上稳定的长达500天的天...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Radar-Based NLoS Pedestrian Localization for Darting-Out Scenarios Near Parked Vehicles with Camera-Assisted Point Cloud Interpretation|雷达辅助下基于相机辅助点云解释的非视距行人定位方法，用于停车场附近突然穿出行人的场景|Hee-Yeun Kim, Byeonggyu Park, Byonghyok Choi, Hansang Cho, Byungkwan Kim, Soomok Lee, Mingu Jeon, Seung-Woo Seo .etc.|<http://arxiv.org/pdf/2508.04033v1>|[代码](https://hiyeun.github.io/NLoS); 提出了一种融合单目相机图像与雷达点云数据的方法，用于精确定位非视线区域突然出现的行人，提高道路安全。|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Perceiving and Acting in First-Person: A Dataset and Benchmark for Egocentric Human-Object-Human Interactions|第一人称视角下的感知与行动：一个面向自我中心人-物-人交互的数据库和基准测试|Liang Xu, Chengqun Yang, Zili Lin, Fei Xu, Yifan Liu, Congsheng Xu, Yiyi Zhang, Jie Qin .etc.|<http://arxiv.org/pdf/2508.04681v1>|构建首个大规模第一视角人-物-人交互数据集InterVLA，推动AI助手在现实世界中的应用与发展。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hierarchical Event Memory for Accurate and Low-latency Online Video Temporal Grounding|分层事件记忆用于实现高准确性和低延迟在线视频时间定位|Minghang Zheng, Yuxin Peng, Benyuan Sun, Yi Yang, Yang Liu|<http://arxiv.org/pdf/2508.04546v1>|[代码](https://github.com/minghangz/OnVTG.); 提出了一种分层事件记忆机制，通过事件提案和未来预测分支，实现了在线视频时间定位的高准确性和低延迟。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OpenDCVCs: A PyTorch Open Source Implementation and Performance Evaluation of the DCVC series Video Codecs|"OpenDCVCs：基于PyTorch的开源实现与DCVC系列视频编解码器性能评估"|Yichi Zhang, Fengqing Zhu|<http://arxiv.org/pdf/2508.04491v1>|提供了开源的PyTorch实现，统一了四种DCVC视频压缩模型，促进了可复现的视频压缩研究。|
|🆕 发布|QuantVSR: Low-Bit Post-Training Quantization for Real-World Video Super-Resolution|《QuantVSR：面向实际应用的视频超分辨率任务的低比特位后训练量化方法》|Bowen Chai, Zheng Chen, Libo Zhu, Wenbo Li, Yong Guo, Yulun Zhang|<http://arxiv.org/pdf/2508.04485v1>|[代码](https://github.com/bowenchai/QuantVSR.); 提出了一种针对实际视频超分辨率任务的低比特量化方法QuantVSR，通过时空复杂性感知机制和可学习偏...|
|🆕 发布|Audio Does Matter: Importance-Aware Multi-Granularity Fusion for Video Moment Retrieval|音频确实重要：基于重要性感知的多粒度融合视频瞬间检索|Junan Lin, Daizong Liu, Xianke Chen, Xiaoye Qu, Xun Yang, Jixiang Zhu, Sanyuan Zhang, Jianfeng Dong|<http://arxiv.org/pdf/2508.04273v1>|[代码](https://github.com/HuiGuanLab/IMG.); 提出了一种重视音频的多粒度融合模型，有效利用音频信息提升视频瞬间检索性能。|
|🆕 发布|Audio-Assisted Face Video Restoration with Temporal and Identity Complementary Learning|音频辅助下的基于时间和身份互补学习的面部视频恢复|Yuqin Cao, Yixuan Gao, Wei Sun, Xiaohong Liu, Yulun Zhang, Xiongkuo Min|<http://arxiv.org/pdf/2508.04161v1>|提出了一种结合音频和视觉特征的脸部视频修复网络，有效改善了多种视频失真问题。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 掩码自编码 (Masked Autoencoding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unmasking Interstitial Lung Diseases: Leveraging Masked Autoencoders for Diagnosis|揭示间质性肺病：利用掩码自编码器进行诊断|Ethan Dack, Lorenzo Brigato, Vasilis Dedousis, Janine Gote-Schniering, Cheryl, Hanno Hoppe, Aristomenis Exadaktylos, Manuela Funke-Chambour .etc.|<http://arxiv.org/pdf/2508.04429v1>|[代码](https://github.com/eedack01/lung_masked_autoencoder.); 利用掩码自编码器学习无标签数据，提高弥漫性肺病诊断准确率。|


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs|打破模态壁垒：基于多模态大型语言模型的通用嵌入学习|Tiancheng Gu, Kaicheng Yang, Ziyong Feng, Xingjun Wang, Yanzhao Zhang, Dingkun Long, Yingda Chen, Weidong Cai .etc.|<http://arxiv.org/pdf/2504.17432v3>|提出UniME框架，利用大型语言模型提升多模态表征学习，增强下游任务表现。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MienCap: Realtime Performance-Based Facial Animation with Live Mood Dynamics|《MienCap：基于实时性能的面部动画与实时情绪动态》|Ye Pan, Ruisi Zhang, Jingying Wang, Nengfu Chen, Yilin Qiu, Yu Ding, Kenny Mitchell|<http://arxiv.org/pdf/2508.04687v1>|提出实时面部动画新方法，结合机器学习实现风格化角色表情的自然传递与高效生成。|
|🆕 发布|FinMMR: Make Financial Numerical Reasoning More Multimodal, Comprehensive, and Challenging|金融数值推理的多元化、全面化与挑战性提升：FinMMR|Zichen Tang, Haihong E, Jiacheng Liu, Zhongjun Yang, Rongjin Li, Zihua Rong, Haoyang He, Zhuodi Hao .etc.|<http://arxiv.org/pdf/2508.04625v1>|提出FinMMR，一种评估大型多模态语言模型在金融数值推理任务中的新基准，实现多模态、全面性和高挑战...|
|🆕 发布|Skeleton Motion Words for Unsupervised Skeleton-Based Temporal Action Segmentation|无监督骨骼行为时间分割的骨骼运动词汇|Uzay Gökay, Federico Spurio, Dominik R. Bach, Juergen Gall|<http://arxiv.org/pdf/2508.04513v1>|[代码](https://github.com/bachlab/SMQ); 提出了一种无监督的基于骨架的时序动作分割方法，通过序列到序列的时序自动编码器保持关节信息分离，实现动...|
|🆕 发布|FrEVL: Leveraging Frozen Pretrained Embeddings for Efficient Vision-Language Understanding|FrEVL：利用冻结预训练嵌入进行高效视觉-语言理解|Emmanuelle Bourigault, Pauline Bourigault|<http://arxiv.org/pdf/2508.04469v1>|提出FrEVL框架，使用冻结预训练嵌入实现高效的视觉语言理解，大幅提升速度并降低能耗。|
|📝 更新|UFV-Splatter: Pose-Free Feed-Forward 3D Gaussian Splatting Adapted to Unfavorable Views|UFV-Splatter：面向不利视角的无姿态前馈3D高斯喷洒适应方法|Yuki Fujimura, Takahiro Kushida, Kazuya Kitano, Takuya Funatomi, Yasuhiro Mukaigawa|<http://arxiv.org/pdf/2507.22342v2>|提出了一种适应不利视角的3D高斯渲染框架，通过增强模型对相机姿态的适应性来扩展其应用范围。|
|📝 更新|Sign Spotting Disambiguation using Large Language Models|使用大型语言模型进行标志检测消歧|JianHe Low, Ozge Mercanoglu Sincan, Richard Bowden|<http://arxiv.org/pdf/2507.03703v3>|利用大型语言模型提升手势识别准确性和灵活性，无需训练即可实现上下文感知的歧义消除。|
|🆕 发布|Beyond the Leaderboard: Rethinking Medical Benchmarks for Large Language Models|超越排行榜：对大型语言模型医学基准的再思考|Zizhan Ma, Wenxuan Wang, Guo Yu, Yiu-Fai Cheung, Meidan Ding, Jie Liu, Wenting Chen, Linlin Shen|<http://arxiv.org/pdf/2508.04325v1>|提出MedCheck评估框架，针对医疗领域大型语言模型基准测试的不足进行 lifecycle-ori...|
|📝 更新|Hulk: A Universal Knowledge Translator for Human-Centric Tasks|“Hulk：面向以人为中心的任务的通用知识翻译器”|Yizhou Wang, Yixuan Wu, Weizhen He, Xun Guo, Feng Zhu, Lei Bai, Rui Zhao, Jian Wu .etc.|<http://arxiv.org/pdf/2312.01697v5>|[代码](https://github.com/OpenGVLab/Hulk.); 提出了一种通用的人类中心模型Hulk，无需特定任务微调即可处理多种2D和3D视觉任务。|
|📝 更新|A Comprohensive Review of Domain Adaptation Techniques for Agricultural Image Analysis in Precision Agriculture|《精准农业中农业图像分析领域自适应技术的全面回顾》|Xing Hu, Siyuan Chen, Xuming Huang, Qianqian Duan, Huiliang Shang, Dawei Zhang|<http://arxiv.org/pdf/2506.05972v4>|系统总结了域自适应技术在精准农业图像分析中的应用，提升了模型在不同环境下的迁移性。|
|📝 更新|3DGraphLLM: Combining Semantic Graphs and Large Language Models for 3D Scene Understanding|三维图形语言模型融合：结合语义图与大型语言模型进行三维场景理解|Tatiana Zemskova, Dmitry Yudin|<http://arxiv.org/pdf/2412.18450v3>|[代码](https://github.com/CognitiveAISystems/3DGraphLLM.); 提出3DGraphLLM方法，结合语义图和大型语言模型，提升机器人对三维场景的理解和自然语言交互能力...|
|🆕 发布|Towards Globally Predictable k-Space Interpolation: A White-box Transformer Approach|面向全局可预测的k空间插值：白盒变换器方法|Chen Luo, Qiyu Jin, Taofeng Xie, Xuemei Wang, Huayu Wang, Congcong Liu, Liming Tang, Guoqing Chen .etc.|<http://arxiv.org/pdf/2508.04051v1>|提出了一种基于白盒Transformer的k空间插值方法，利用全局依赖性提高MRI成像速度与准确性。|
|🆕 发布|ZARA: Zero-shot Motion Time-Series Analysis via Knowledge and Retrieval Driven LLM Agents|ZARA：通过知识与检索驱动的LLM智能体进行零样本运动时间序列分析|Zechen Li, Baiyu Chen, Hao Xue, Flora D. Salim|<http://arxiv.org/pdf/2508.04038v1>|[代码](https://github.com/zechenli03/ZARA.); 提出了一种零样本、可解释的运动时间序列分析框架，无需任务特定训练即可灵活识别活动。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Super Resolved Imaging with Adaptive Optics|自适应光学超分辨率成像|Robin Swanson, Esther Y. H. Lin, Masen Lamb, Suresh Sivanandam, Kiriakos N. Kutulakos|<http://arxiv.org/pdf/2508.04648v1>|利用现有自适应光学系统，通过精确控制的镜面畸变实现天文望远镜视场与分辨率 tradeoff 的突破。|
|🆕 发布|CONVERGE: A Multi-Agent Vision-Radio Architecture for xApps|“CONVERGE：一种面向xApps的多智能体视觉-无线电架构”|Filipe B. Teixeira, Carolina Simões, Paulo Fidalgo, Wagner Pedrosa, André Coelho, Manuel Ricardo, Luis M. Pessoa|<http://arxiv.org/pdf/2508.04556v1>|提出了一种多代理架构，通过融合计算机视觉与无线通信，实现实时感知信息传递以优化5G/6G网络性能。|
|🆕 发布|InceptoFormer: A Multi-Signal Neural Framework for Parkinson's Disease Severity Evaluation from Gait|InceptoFormer：一种用于帕金森病严重程度评估的步态多信号神经框架|Safwen Naimi, Arij Said, Wassim Bouachir, Guillaume-Alexandre Bilodeau|<http://arxiv.org/pdf/2508.04540v1>|[代码](https://github.com/SafwenNaimi/InceptoFormer); 提出InceptoFormer模型，融合1D Inception和Transformer，准确评估帕...|
|🆕 发布|TopKD: Top-scaled Knowledge Distillation|TopKD: 顶部缩放知识蒸馏|Qi Wang, Jinjia Zhou|<http://arxiv.org/pdf/2508.04539v1>|提出TopKD方法，通过放大关键logit提升知识蒸馏效果，适用于多种网络结构。|
|📝 更新|NACHOS: Neural Architecture Search for Hardware Constrained Early Exit Neural Networks|NACHOS：面向硬件约束的早期退出神经网络的神经架构搜索|Matteo Gambella, Jary Pomponi, Simone Scardapane, Manuel Roveri|<http://arxiv.org/pdf/2401.13330v3>|提出了一种自动化设计满足硬件约束的早期退出神经网络的架构搜索方法，实现了准确度与计算效率的优化平衡。|
|🆕 发布|ProtoN: Prototype Node Graph Neural Network for Unconstrained Multi-Impression Ear Recognition|原型节点图神经网络：用于无约束多印象耳部识别|Santhoshkumar Peddi, Sadhvik Bathini, Arun Balasubramanian, Monalisa Sarma, Debasis Samanta|<http://arxiv.org/pdf/2508.04381v1>|提出了一种基于图神经网络的少量样本学习框架ProtoN，有效提升了耳朵识别的准确性和鲁棒性。|
|🆕 发布|RiemanLine: Riemannian Manifold Representation of 3D Lines for Factor Graph Optimization|黎曼线：三维直线的黎曼流形表示用于因子图优化|Yanyan Li, Ze Yang, Keisuke Tateno, Federico Tombari Liang Zhao, Gim Hee Lee|<http://arxiv.org/pdf/2508.04335v1>|提出了一种基于黎曼流形的3D线表示方法，有效压缩参数维度并提升相机定位和结构重建的准确性。|
|📝 更新|GRILL: Gradient Signal Restoration in Ill-Conditioned Layers to Enhance Adversarial Attacks on Autoencoders|GRILL:在条件不佳的层中恢复梯度信号以增强对自动编码器的对抗攻击|Chethan Krishnamurthy Ramanaik, Arjun Roy, Tobias Callies, Eirini Ntoutsi|<http://arxiv.org/pdf/2505.03646v3>|提出方法GRILL恢复梯度信号，增强对自动编码器的对抗攻击效果。|
|📝 更新|PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs|优先减少乘法运算而非降低位宽以实现高效的卷积神经网络|Lukas Meiner, Jens Mehnert, Alexandru Paul Condurache|<http://arxiv.org/pdf/2505.03254v2>|提出了一种针对深度可分离卷积网络的量化策略，通过区分使用 ternary 和 8-bit 权重显著降...|
|📝 更新|Zero-Shot Neural Architecture Search with Weighted Response Correlation|零样本神经架构搜索加权响应相关性方法|Kun Jing, Luoyu Chen, Jungang Xu, Jianwei Tai, Yiyu Wang, Shuaimin Li|<http://arxiv.org/pdf/2507.08841v2>|[代码](https://github.com/kunjing96/ZSNAS-WRCor.git.); 提出了一种无需训练的加权响应相关性方法，有效加速了神经架构搜索且性能优于现有算法。|
|🆕 发布|Bootstrap Deep Spectral Clustering with Optimal Transport|"使用最优传输的引导深度谱聚类"|Wengang Guo, Wei Ye, Chunchun Chen, Xin Sun, Christian Böhm, Claudia Plant, Susanto Rahardja|<http://arxiv.org/pdf/2508.04200v1>|[代码](https://github.com/spdj2271/BootSC.); 提出了一种深度谱聚类模型BootSC，通过端到端学习提高聚类性能并引入正交重参数化技术增强判别力。|
|🆕 发布|ICM-Fusion: In-Context Meta-Optimized LoRA Fusion for Multi-Task Adaptation|ICM-Fusion：基于上下文的元优化LoRA融合的多任务适应方法|Yihua Shao, Xiaofeng Lin, Xinwei Long, Siyu Chen, Minxi Yan, Yang Liu, Ziyang Yan, Ao Ma .etc.|<http://arxiv.org/pdf/2508.04153v1>|提出ICM-Fusion方法，通过任务向量运算动态平衡优化方向，减少多任务学习中的冲突和遗忘问题。|
|📝 更新|Random Erasing vs. Model Inversion: A Promising Defense or a False Hope?|随机擦除与模型反转：一个有前景的防御策略还是一场空希望？|Viet-Hung Tran, Ngoc-Bao Nguyen, Son T. Mai, Hans Vandierendonck, Ira Assent, Alex Kot, Ngai-Man Cheung|<http://arxiv.org/pdf/2409.01062v3>|发现随机擦除能有效防御模型反转攻击，实现隐私保护与性能的平衡。|
|📝 更新|Live Demonstration: Neuromorphic Radar for Gesture Recognition|实时演示：类神经形态雷达的手势识别|Satyapreet Singh Yadav, Akash K S, Chandra Sekhar Seelamantula, Chetan Singh Thakur|<http://arxiv.org/pdf/2508.03324v2>|提出了一种基于生物启发的异步sigma-delta编码和事件驱动处理框架，实现了低功耗实时雷达手势识...|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Neutralizing Token Aggregation via Information Augmentation for Efficient Test-Time Adaptation|通过信息增强实现测试时自适应的中性化标记聚合|Yizhe Xiong, Zihan Zhou, Yiwen Liang, Hui Chen, Zijia Lin, Tianxiang Hao, Fan Zhang, Jungong Han .etc.|<http://arxiv.org/pdf/2508.03388v2>|提出方法 NAVIA 通过信息增强中和聚合带来的信息损失，实现高效的测试时适应。|
|📝 更新|EchoMimicV3: 1.3B Parameters are All You Need for Unified Multi-Modal and Multi-Task Human Animation|EchoMimicV3：1.3亿参数足以实现统一的多模态和多任务人类动画|Rang Meng, Yan Wang, Weipeng Wu, Ruobing Zheng, Yuming Li, Chenguang Ma|<http://arxiv.org/pdf/2507.03905v3>|EchoMimicV3通过1.3B参数的统一多模态和多任务框架，解决了传统动画生成的高计算需求和分离...|
|📝 更新|DSOcc: Leveraging Depth Awareness and Semantic Aid to Boost Camera-Based 3D Semantic Occupancy Prediction|DSOcc：利用深度感知与语义辅助提升基于相机的三维语义占据预测|Naiyu Fang, Zheyuan Zhou, Kang Wang, Ruibo Li, Lemiao Qiu, Shuyou Zhang, Zhe Wang, Guosheng Lin|<http://arxiv.org/pdf/2505.20951v2>|提出深度感知与语义辅助相结合的方法，提升基于相机三维语义占据预测的准确性和鲁棒性。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Face-voice Association in Multilingual Environments (FAME) 2026 Challenge Evaluation Plan|多语种环境中人脸-语音关联（FAME）2026挑战评估计划|Marta Moscati, Ahmed Abdullah, Muhammad Saad Saeed, Shah Nawaz, Rohan Kumar Das, Muhammad Zaigham Zaheer, Junaid Mir, Muhammad Haroon Yousaf .etc.|<http://arxiv.org/pdf/2508.04592v1>|提出了一种针对多语言环境的 face-voice 关联挑战及相应的评估计划，使用特定数据集探索 fa...|
|🆕 发布|Analyzing and Mitigating Object Hallucination: A Training Bias Perspective|分析与缓解物体幻觉：训练偏差视角|Yifan Li, Kun Zhou, Wayne Xin Zhao, Lei Fang, Ji-Rong Wen|<http://arxiv.org/pdf/2508.04567v1>|提出了一种减轻大型视觉语言模型对象幻觉问题的训练偏差消除方法 Obliviate。|
|📝 更新|Less is More: Token-Efficient Video-QA via Adaptive Frame-Pruning and Semantic Graph Integration|少即是多：通过自适应帧剪枝和语义图集成的低标记效率视频问答|Shaoguang Wang, Jianxiang He, Yijie Xu, Ziyang Chen, Weiyu Guo, Hui Xiong|<http://arxiv.org/pdf/2508.03337v2>|提出了一种自适应帧剪枝和语义图集成方法，大幅降低视频问答所需的帧数和输入令牌，提升效率和准确性。|
|🆕 发布|DRIVE-T: A Methodology for Discriminative and Representative Data Viz Item Selection for Literacy Construct and Assessment|驱动-T：一种用于识别和代表性数据可视化项目选择的方法，以促进文化素养构建与评估|Angela Locoro, Silvia Golia, Davide Falessi|<http://arxiv.org/pdf/2508.04160v1>|提出DRIVE-T方法，通过任务项的区分度和代表性来优化数据可视化素养的测量与评估。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning Robust Intervention Representations with Delta Embeddings|学习具有Delta嵌入的鲁棒干预表示|Panagiotis Alimisis, Christos Diou|<http://arxiv.org/pdf/2508.04492v1>|提出通过学习干预的因果Delta嵌入，有效提升了模型在非分布内数据上的鲁棒性。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience|SEAgent：从经验中自主学习的自演化计算机使用代理|Zeyi Sun, Ziyu Liu, Yuhang Zang, Yuhang Cao, Xiaoyi Dong, Tong Wu, Dahua Lin, Jiaqi Wang|<http://arxiv.org/pdf/2508.04700v1>|SEAgent通过自主经验学习，使计算机使用代理能自我进化以掌握新软件，大幅提升任务成功率。|
|🆕 发布|TurboTrain: Towards Efficient and Balanced Multi-Task Learning for Multi-Agent Perception and Prediction|涡轮训练：面向多智能体感知与预测的高效平衡多任务学习|Zewei Zhou, Seth Z. Zhao, Tianhui Cai, Zhiyu Huang, Bolei Zhou, Jiaqi Ma|<http://arxiv.org/pdf/2508.04682v1>|提出了 TurboTrain 框架，通过预训练和平衡多任务学习优化多智能体感知与预测的训练效率和性能...|
|🆕 发布|Occupancy Learning with Spatiotemporal Memory|空间时间记忆的占用学习|Ziyang Leng, Jiawei Yang, Wenlong Yi, Bolei Zhou|<http://arxiv.org/pdf/2508.04705v1>|提出ST-Occ框架，通过时空记忆和记忆注意力有效学习3D占位表示的时空特征，提升自动驾驶环境感知。|
|🆕 发布|BEVCon: Advancing Bird's Eye View Perception with Contrastive Learning|鸟瞰对比学习：提升鸟瞰视角感知能力|Ziyang Leng, Jiawei Yang, Zhicheng Ren, Bolei Zhou|<http://arxiv.org/pdf/2508.04702v1>|提出BEVCon框架，通过对比学习增强自动驾驶中的鸟瞰图感知能力。|
|📝 更新|COBRA: A Continual Learning Approach to Vision-Brain Understanding|COBRA：一种面向视觉-大脑理解的持续学习方法|Xuan-Bac Nguyen, Manuel Serna-Aguilera, Arabinda Kumar Choudhary, Pawan Sinha, Xin Li, Khoa Luu|<http://arxiv.org/pdf/2411.17475v3>|提出COBRA框架，通过区分个体共性和特性学习，有效解决视觉-大脑理解中的持续学习问题。|
|🆕 发布|From eye to AI: studying rodent social behavior in the era of machine Learning|从眼睛到人工智能：在机器学习时代研究啮齿动物的社会行为|Giuseppe Chindemi, Camilla Bellone, Benoit Girard|<http://arxiv.org/pdf/2508.04255v1>|利用人工智能技术分析鼠类社交行为，减少传统观察偏差，提升研究深度。|
|🆕 发布|Continual Learning for VLMs: A Survey and Taxonomy Beyond Forgetting|持续学习用于大型视觉语言模型：超越遗忘的综述与分类|Yuyang Liu, Qiuhe Hong, Linlan Huang, Alexandra Gomez-Villa, Dipam Goswami, Xialei Liu, Joost van de Weijer, Yonghong Tian|<http://arxiv.org/pdf/2508.04227v1>|[代码](https://github.com/YuyangSunshine/Awesome-Continual-learning-of-Vision-Language-Models.); 系统综述了视觉语言模型在持续学习中的挑战，提出了针对性的解决策略和未来研究方向。|
|📝 更新|Confounder-Free Continual Learning via Recursive Feature Normalization|无混淆因子的递归特征归一化连续学习|Yash Shah, Camila Gonzalez, Mohammad H. Abbasi, Qingyu Zhao, Kilian M. Pohl, Ehsan Adeli|<http://arxiv.org/pdf/2507.09031v2>|提出了一种递归特征归一化方法R-MDN，有效消除连续学习中混淆因素的影响，保持模型公平性并减少灾难性...|
|📝 更新|BlurryScope enables compact, cost-effective scanning microscopy for HER2 scoring using deep learning on blurry images|“BlurryScope 实现基于深度学习对模糊图像的HER2评分的紧凑型、经济型扫描显微镜”|Michael John Fanous, Christopher Michael Seybold, Hanlong Chen, Nir Pillar, Aydogan Ozcan|<http://arxiv.org/pdf/2410.17557v2>|开发了一种低成本、紧凑型扫描显微镜BlurryScope，结合深度学习对模糊图像进行HER2评分自动...|
|📝 更新|Enhancing Multi-view Open-set Learning via Ambiguity Uncertainty Calibration and View-wise Debiasing|通过模糊性不确定性校准和视图特异性去偏增强多视角开放集学习|Zihan Fang, Zhiyong Xu, Lan Du, Shide Du, Zhiling Cai, Shiping Wang|<http://arxiv.org/pdf/2508.01227v2>|提出了一种通过不确定性校准和视图去偏策略增强多视角开放集学习性能的方法。|
|📝 更新|Mjölnir: A Deep Learning Parametrization Framework for Global Lightning Flash Density|“mjölnir：一种用于全球闪电闪光密度参数化的深度学习框架”|Minjong Cheon|<http://arxiv.org/pdf/2504.19822v2>|提出Mjolnir框架，利用深度学习模拟全球闪电密度，实现高精度预测。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Enhancing Zero-Shot Brain Tumor Subtype Classification via Fine-Grained Patch-Text Alignment|通过细粒度斑块-文本对齐增强零样本脑肿瘤亚型分类|Lubin Gan, Jing Zhang, Linhao Qu, Yijun Wang, Siying Wu, Xiaoyan Sun|<http://arxiv.org/pdf/2508.01602v2>|提出FG-PAN框架，通过精细视觉特征强化和文本描述生成提升零样本脑肿瘤亚型分类性能。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 交互式感知 (Interactive Perception)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|IS-Bench: Evaluating Interactive Safety of VLM-Driven Embodied Agents in Daily Household Tasks|IS-Bench：评估日常家务任务中VLM驱动的具身智能体的交互安全性|Xiaoya Lu, Zeren Chen, Xuhao Hu, Yijin Zhou, Weichen Zhang, Dongrui Liu, Lu Sheng, Jing Shao|<http://arxiv.org/pdf/2506.16402v2>|[代码](https://github.com/AI45Lab/IS-Bench); 提出IS-Bench，首个针对交互式安全的跨模态基准，评估AI在动态环境中的风险感知与应对能力。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EncQA: Benchmarking Vision-Language Models on Visual Encodings for Charts|图表编码的视觉问答：在视觉编码上对视觉-语言模型进行基准测试|Kushin Mukherjee, Donghao Ren, Dominik Moritz, Yannick Assogba|<http://arxiv.org/pdf/2508.04650v1>|提出EncQA基准，全面评估视觉编码对图表理解的贡献，揭示模型性能与任务和编码类型的关系。|
|🆕 发布|Knowledge to Sight: Reasoning over Visual Attributes via Knowledge Decomposition for Abnormality Grounding|知识见微：通过知识分解对视觉属性进行推理以实现异常定位|Jun Li, Che Liu, Wenjia Bai, Mingxuan Liu, Rossella Arcucci, Cosmin I. Bercea, Julia A. Schnabel|<http://arxiv.org/pdf/2508.04572v1>|[代码](https://lijunrio.github.io/K2Sight); 提出了一种名为“Knowledge to Sight”的框架，通过将临床概念分解为可解释的视觉属性，...|
|🆕 发布|CLASP: Cross-modal Salient Anchor-based Semantic Propagation for Weakly-supervised Dense Audio-Visual Event Localization|CLASP:基于跨模态显著锚点的弱监督密集音视频事件定位语义传播|Jinxing Zhou, Ziheng Zhou, Yanghao Zhou, Yuxin Mao, Zhangling Duan, Dan Guo|<http://arxiv.org/pdf/2508.04566v1>|提出了一种基于跨模态显著锚点的语义传播方法，用于弱监督下密集音视频事件定位。|
|🆕 发布|Boosting Visual Knowledge-Intensive Training for LVLMs Through Causality-Driven Visual Object Completion|通过因果驱动的视觉对象补全增强LVLMs的视觉知识密集型训练|Qingguo Hu, Ante Wang, Jia Song, Delai Qiu, Qingsong Liu, Jinsong Su|<http://arxiv.org/pdf/2508.04453v1>|[代码](https://github.com/XMUDeepLIT/CVC.); 提出了一种因果驱动的视觉对象补全任务，有效提升大型视觉语言模型的视觉感知和推理能力。|
|📝 更新|Through the Magnifying Glass: Adaptive Perception Magnification for Hallucination-Free VLM Decoding|通过放大镜：用于无幻觉大型语言模型解码的自适应感知放大|Shunqi Mao, Chaoyi Zhang, Weidong Cai|<http://arxiv.org/pdf/2503.10183v3>|提出了一种 Perception Magnifier 方法，通过放大关键视觉区域来减少视觉 hall...|
|🆕 发布|Thinking With Videos: Multimodal Tool-Augmented Reinforcement Learning for Long Video Reasoning|思考与视频：多模态工具增强的强化学习在长视频推理中的应用|Haoji Zhang, Xin Gu, Jiawen Li, Chixiang Ma, Sule Bai, Chubin Zhang, Bowen Zhang, Zhichao Zhou .etc.|<http://arxiv.org/pdf/2508.04416v1>|提出了一种结合工具增强学习的视频理解框架VITAL，有效提升了长视频推理能力。|
|🆕 发布|TDSNNs: Competitive Topographic Deep Spiking Neural Networks for Visual Cortex Modeling|TDSNNs：用于视觉皮层建模的竞争性拓扑深度尖峰神经网络|Deming Zhou, Yuetong Fang, Zhaorui Wang, Renjing Xu|<http://arxiv.org/pdf/2508.04270v1>|提出了一种结合时空约束的深度尖峰神经网络模型，有效模拟了视觉皮层的拓扑结构并提升了模型鲁棒性。|
|📝 更新|True Multimodal In-Context Learning Needs Attention to the Visual Context|"真正多模态情境学习需要关注视觉上下文"|Shuo Chen, Jianzhe Liu, Zhen Han, Yan Xia, Daniel Cremers, Philip Torr, Volker Tresp, Jindong Gu|<http://arxiv.org/pdf/2507.15807v2>|[代码](https://chenxshuo.github.io/true-micl-colm); 提出Dynamic Attention Reallocation策略和TrueMICL数据集，提升多...|
|🆕 发布|SplitGaussian: Reconstructing Dynamic Scenes via Visual Geometry Decomposition|通过视觉几何分解重构动态场景的SplitGaussian方法|Jiahui Li, Shengeng Tang, Jingxuan He, Gang Huang, Zhangye Wang, Yantao Pan, Lechao Cheng|<http://arxiv.org/pdf/2508.04224v1>|提出SplitGaussian框架，通过分离静态和动态场景成分，提高了动态3D场景重建的稳定性和准确...|
|📝 更新|HiPrune: Training-Free Visual Token Pruning via Hierarchical Attention in Vision-Language Models|HiPrune：基于视觉语言模型中的层次注意力无需训练的视觉标记剪枝|Jizhihui Liu, Feiyi Du, Guangdao Zhu, Niu Lian, Jun Li, Bin Chen|<http://arxiv.org/pdf/2508.00553v2>|[代码](https://github.com/Danielement321/HiPrune.); 提出HiPrune，一种无需训练、适用于多种视觉语言模型的视觉token高效剪枝方法，大幅减少计算负...|
|🆕 发布|ViFP: A Framework for Visual False Positive Detection to Enhance Reasoning Reliability in VLMs|ViFP：一种用于视觉假阳性检测的框架，以提高大语言模型中的推理可靠性|Ben Zhang, LuLu Yu, Lei Gao, Jing Liu, QuanJiang Guo, Hui Gao|<http://arxiv.org/pdf/2508.04201v1>|提出ViFP框架，通过检测错误推理路径提升视觉语言模型的推理可靠性。|
|🆕 发布|AD-FM: Multimodal LLMs for Anomaly Detection via Multi-Stage Reasoning and Fine-Grained Reward Optimization|AD-FM：通过多阶段推理和细粒度奖励优化进行异常检测的多模态大型语言模型|Jingyi Liao, Yongyi Su, Rong-Cheng Tu, Zhao Jin, Wenhao Sun, Yiting Li, Dacheng Tao, Xun Xu .etc.|<http://arxiv.org/pdf/2508.04175v1>|提出了一种多阶段推理和细粒度奖励优化的框架，有效提升多模态大语言模型在异常检测领域的适应性和准确性。|
|📝 更新|Learning to Inference Adaptively for Multimodal Large Language Models|学习自适应推理以优化多模态大型语言模型|Zhuoyan Xu, Khoi Duc Nguyen, Preeti Mukherjee, Saurabh Bagchi, Somali Chaterji, Yingyu Liang, Yin Li|<http://arxiv.org/pdf/2503.10905v3>|[代码](https://zhuoyan-xu.github.io/ada-llava); 提出自适应推理框架AdaLLaVA，动态调整MLLMs推理过程中的操作以适应变化的资源限制和输入数据...|
|🆕 发布|AR as an Evaluation Playground: Bridging Metrics and Visual Perception of Computer Vision Models|“增强现实作为评估游乐场：连接计算机视觉模型的指标与视觉感知”|Ashkan Ganj, Yiqin Zhao, Tian Guo|<http://arxiv.org/pdf/2508.04102v1>|利用增强现实技术，设计ARCADE平台，简化计算机视觉模型的人类感知评估过程。|
|🆕 发布|Can Large Multimodal Models Actively Recognize Faulty Inputs? A Systematic Evaluation Framework of Their Input Scrutiny Ability|大型多模态模型能否主动识别错误输入？其输入审查能力的系统性评估框架|Haiqi Yang, Jinzhe Li, Gengxu Li, Yi Chang, Yuan Wu|<http://arxiv.org/pdf/2508.04017v1>|[代码](https://github.com/MLGroupJLU/LMM_ISEval.); 提出输入审查能力评估框架ISEval，揭示了大型多模态模型在识别错误输入方面的不足。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Long-Term Visual Object Tracking with Event Cameras: An Associative Memory Augmented Tracker and A Benchmark Dataset|基于事件相机的长期视觉目标跟踪：一种关联记忆增强跟踪器和一个基准数据集|Xiao Wang, Xufeng Lou, Shiao Wang, Ju Huang, Lan Chen, Bo Jiang|<http://arxiv.org/pdf/2403.05839v3>|[代码](https://github.com/Event-AHU/FELT_SOT_Benchmark); 提出了一种结合事件相机和关联记忆的长期视觉目标跟踪方法，并构建了相应的大型数据集。|
|🆕 发布|Dual Prompt Learning for Adapting Vision-Language Models to Downstream Image-Text Retrieval|双提示学习：用于将视觉-语言模型适应于下游图像-文本检索任务|Yifan Wang, Tao Wang, Chenwei Tang, Caiyang Yu, Zhengqing Zang, Mengmi Zhang, Shudong Huang, Jiancheng Lv|<http://arxiv.org/pdf/2508.04028v1>|提出双提示学习框架DCAR，通过联合优化属性和类别特征，提升图像文本检索的细粒度表现。|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DOGR: Towards Versatile Visual Document Grounding and Referring|面向多功能的视觉文档定位与指引用户研究|Yinan Zhou, Yuxin Chen, Haokun Lin, Yichen Wu, Shuyu Yang, Zhongang Qi, Chen Ma, Li Zhu .etc.|<http://arxiv.org/pdf/2411.17125v3>|提出DOGR-Engine生成细粒度文档数据，构建DOGR-Bench，并开发DOGR模型，提升文档...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Beyond Adapter Retrieval: Latent Geometry-Preserving Composition via Sparse Task Projection|超越适配器检索：通过稀疏任务投影实现保持潜在几何结构的组合|Pengfei Jin, Peng Shu, Sifan Song, Sekeun Kim, Qing Xiao, Cheng Chen, Tianming Liu, Xiang Li .etc.|<http://arxiv.org/pdf/2410.09908v2>|提出了一种基于任务关系几何结构的稀疏重建方法，通过优化组合预训练适配器，实现了更好的零样本泛化性能。|
|🆕 发布|RoboTron-Sim: Improving Real-World Driving via Simulated Hard-Case|RoboTron-Sim：通过模拟困难案例提升真实世界驾驶性能|Baihui Xiao, Chengjian Feng, Zhijian Huang, Feng yan, Yujie Zhong, Lin Ma|<http://arxiv.org/pdf/2508.04642v1>|[代码](https://stars79689.github.io/RoboTron-Sim); 通过模拟高难度场景数据，RoboTron-Sim显著提升了自动驾驶系统在关键情况下的驾驶性能。|
|📝 更新|SimMLM: A Simple Framework for Multi-modal Learning with Missing Modality|SimMLM：一种用于处理缺失模态的多模态学习简单框架|Sijie Li, Chen Chen, Jungong Han|<http://arxiv.org/pdf/2507.19264v2>|提出SimMLM框架，通过动态调整模态贡献提升缺失模态下的多模态学习准确性和鲁棒性。|
|📝 更新|False Promises in Medical Imaging AI? Assessing Validity of Outperformance Claims|医学成像AI中的虚假承诺？评估超越性能主张的有效性|Evangelia Christodoulou, Annika Reinke, Pascaline Andrè, Patrick Godau, Piotr Kalinowski, Rola Houhou, Selen Erkan, Carole H. Sudre .etc.|<http://arxiv.org/pdf/2505.04720v2>|揭示了医学成像AI领域超80%的超越现有技术水平宣称未经充分验证，提出用贝叶斯方法评估宣称真实性。|
|🆕 发布|Visual Bias and Interpretability in Deep Learning for Dermatological Image Analysis|深度学习在皮肤科图像分析中的视觉偏差与可解释性|Enam Ahmed Taufik, Abdullah Khondoker, Antara Firoz Parsa, Seraj Al Mahmud Mostafa|<http://arxiv.org/pdf/2508.04573v1>|提出了一种深度学习框架，通过优化图像预处理和模型选择，提高了皮肤疾病分类的准确性和可解释性。|
|🆕 发布|Augmentation-based Domain Generalization and Joint Training from Multiple Source Domains for Whole Heart Segmentation|基于增强的域泛化与多源域联合训练的心脏整体分割|Franz Thaler, Darko Stern, Gernot Plank, Martin Urschler|<http://arxiv.org/pdf/2508.04552v1>|提出了一种结合多源域平衡训练与强数据增强的心脏全结构分割方法，有效应对了领域迁移问题并提高了分割精度...|
|🆕 发布|No Masks Needed: Explainable AI for Deriving Segmentation from Classification|无需口罩：用于从分类中导出分割的可解释人工智能|Mosong Ma, Tania Stathaki, Michalis Lazarou|<http://arxiv.org/pdf/2508.04534v1>|提出了一种针对医疗图像的预训练模型微调方法，结合可解释AI生成相关性得分，实现了准确高效的图像分割。|
|🆕 发布|Small Lesions-aware Bidirectional Multimodal Multiscale Fusion Network for Lung Disease Classification|小病灶感知双向多模态多尺度融合网络用于肺部疾病分类|Jianxun Yu, Ruiquan Ge, Zhipeng Wang, Cheng Yang, Chenyu Lin, Xianjun Fu, Jikui Liu, Ahmed Elazab .etc.|<http://arxiv.org/pdf/2508.04205v1>|[代码](https://github.com/yjx1234/MMCAF-Net); 提出了一种多模态多尺度融合网络，有效提取并整合肺部小病变特征，显著提升疾病诊断准确率。|
|📝 更新|BrainSegDMlF: A Dynamic Fusion-enhanced SAM for Brain Lesion Segmentation|脑部病变分割的动态融合增强型自注意力模块：BrainSegDMlF|Hongming Wang, Yifeng Wu, Huimin Huang, Hongtao Wu, Jia-Xuan Jiang, Xiaodong Zhang, Hao Zheng, Xian Wu .etc.|<http://arxiv.org/pdf/2505.06133v2>|提出了一种自动化的脑部病变分割模型BrainSegDMLF，通过动态模态交互融合模块和逐层上采样解码...|
|🆕 发布|DS$^2$Net: Detail-Semantic Deep Supervision Network for Medical Image Segmentation|DS$^2$Net：用于医学图像分割的细节-语义深度监督网络|Zhaohong Huang, Yuxin Zhang, Mingbao Lin, Taojian Zhou, Guorong Cai, Rongrong Ji|<http://arxiv.org/pdf/2508.04131v1>|提出了一种多视角深度监督网络DS$^2$Net，通过同时强化细节和语义特征监督，提升了医疗图像分割的...|
|🆕 发布|NEARL-CLIP: Interacted Query Adaptation with Orthogonal Regularization for Medical Vision-Language Understanding|NEARL-CLIP：基于正交正则化的医学视觉-语言理解交互式查询适应|Zelin Peng, Yichen Zhao, Yu Huang, Piao Yang, Feilong Tang, Zhengqin Xu, Xiaokang Yang, Wei Shen|<http://arxiv.org/pdf/2508.04101v1>|提出了一种促进医学视觉语言模型跨模态交互的方法NEARL-CLIP，通过动态生成查询和正交调节增强多...|
|🆕 发布|TCSAFormer: Efficient Vision Transformer with Token Compression and Sparse Attention for Medical Image Segmentation|Analysis and Improvement of Token-based Vision Transformer for Medical Image Segmentation  TCSAFormer：用于医学图像分割的具有标记压缩和稀疏注意力的高效视觉Transformer|Zunhui Xia, Hongxing Li, Libin Lan|<http://arxiv.org/pdf/2508.04058v1>|提出TCSAFormer网络，通过压缩注意力和双分支前馈网络提升医疗图像分割的效率和准确性。|
|🆕 发布|Iterative pseudo-labeling based adaptive copy-paste supervision for semi-supervised tumor segmentation|基于迭代伪标签的适应性复制-粘贴监督用于半监督肿瘤分割|Qiangguo Jin, Hui Cui, Junbo Wang, Changming Sun, Yimiao He, Ping Xuan, Linlin Wang, Cong Cong .etc.|<http://arxiv.org/pdf/2508.04044v1>|提出了一种迭代伪标签和自适应复制粘贴监督相结合的方法，用于半监督肿瘤分割，提高了小体积或众多肿瘤的分...|
|📝 更新|Uncertainty-aware Medical Diagnostic Phrase Identification and Grounding|不确定性感知的医疗诊断短语识别与定位|Ke Zou, Yang Bai, Bo Liu, Yidi Chen, Zhihao Chen, Yang Zhou, Xuedong Yuan, Meng Wang .etc.|<http://arxiv.org/pdf/2404.06798v3>|提出了一种端到端的医疗报告 grounding 方法，通过嵌入特殊 token 和不确定性感知模型，...|
|📝 更新|Expert-Like Reparameterization of Heterogeneous Pyramid Receptive Fields in Efficient CNNs for Fair Medical Image Classification|异质金字塔感受野在高效卷积神经网络中的专家级重参数化以实现公平的医疗图像分类|Xiao Wu, Xiaoqing Zhang, Zunjie Xiao, Lingxi Hu, Risa Higashita, Jiang Liu|<http://arxiv.org/pdf/2505.13039v2>|[代码](https://github.com/XiaoLing12138/Expert-Like-Reparameterization-of-Heterogeneous-Pyramid-Receptive-Fields.); 提出了一种模仿多专家会诊的ERoHPRF方法，通过异质金字塔感受野提升医疗图像分类性能和公平性。|
|🆕 发布|JanusNet: Hierarchical Slice-Block Shuffle and Displacement for Semi-Supervised 3D Multi-Organ Segmentation|JanusNet：分层切片-块洗牌与位移用于半监督三维多器官分割|Zheng Zhang, Tianzhuzi Tan, Guanchun Yin, Bo Zhang, Xiuzhuang Zhou|<http://arxiv.org/pdf/2508.03997v1>|提出了JanusNet，一种通过保持解剖连续性并增强难区分区域的数据增强框架，显著提升了半监督3D多...|
|📝 更新|Landsat30-AU: A Vision-Language Dataset for Australian Landsat Imagery|澳大利亚Landsat影像的视觉-语言数据集Landsat30-AU|Sai Ma, Zhuang Li, John A Taylor|<http://arxiv.org/pdf/2508.03127v2>|[代码](https://github.com/papersubmit1/landsat30-au.); 构建了Landsat30-AU数据集，提升卫星图像与自然语言交互的性能。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RoboTron-Drive: All-in-One Large Multimodal Model for Autonomous Driving|RoboTron-Drive：面向自动驾驶的全能大型多模态模型|Zhijian Huang, Chengjian Feng, Feng Yan, Baihui Xiao, Zequn Jie, Yujie Zhong, Xiaodan Liang, Lin Ma|<http://arxiv.org/pdf/2412.07689v4>|[代码](https://github.com/zhijian11/RoboTron-Drive.); 提出了一种全面的自动驾驶大型多模态模型RoboTron-Drive，通过多样化数据输入处理和任务执行...|
|📝 更新|MultiADS: Defect-aware Supervision for Multi-type Anomaly Detection and Segmentation in Zero-Shot Learning|多类型异常检测与分割的零样本学习中的缺陷感知监督方法（MultiADS）|Ylli Sadikaj, Hongkuan Zhou, Lavdim Halilaj, Stefan Schmid, Steffen Staab, Claudia Plant|<http://arxiv.org/pdf/2504.06740v2>|提出了一种零样本学习框架MultiADS，实现了工业产品中多类型缺陷检测与分割，提升了缺陷识别准确性...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TNet: Terrace Convolutional Decoder Network for Remote Sensing Image Semantic Segmentation|TNet：用于遥感图像语义分割的梯形卷积解码网络|Chengqian Dai, Yonghong Guo, Hongzhao Xiang, Yigui Luo|<http://arxiv.org/pdf/2508.04061v1>|提出了一种新的远程传感图像语义分割网络TNet，通过逐步融合不同分辨率下的特征，有效结合全局和局部信...|
|📝 更新|DeMo++: Motion Decoupling for Autonomous Driving|DeMo++：自动驾驶中的运动解耦|Bozhou Zhang, Nan Song, Xiatian Zhu, Li Zhang|<http://arxiv.org/pdf/2507.17342v2>|提出了一种解耦运动估计的DeMo++框架，通过结合整体运动意图和精细时空状态建模，提高了自动驾驶系统...|
|🆕 发布|Prototype-Driven Structure Synergy Network for Remote Sensing Images Segmentation|原型驱动的结构协同网络用于遥感图像分割|Junyi Wang, Jinjiang Li, Guodong Fan, Yakun Ju, Xiang Fang, Alex C. Kot|<http://arxiv.org/pdf/2508.04022v1>|[代码](https://github.com/wangjunyi-1/PDSSNet.); 提出了一种Prototype-Driven结构协同网络，通过结合类语义和空间结构，有效解决了遥感图像...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ANPrompt: Anti-noise Prompt Tuning for Vision-Language Models|ANPrompt：面向视觉语言模型的抗噪声提示微调|Yansheng Gao, Yufei Zheng, Jinghan Qu, Zixi Zhu, Yukuan Zhang, Shengsheng Wang|<http://arxiv.org/pdf/2508.04677v1>|提出ANPrompt方法，增强视觉语言模型对噪声的鲁棒性，提升未见类别泛化能力。|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|egoPPG: Heart Rate Estimation from Eye-Tracking Cameras in Egocentric Systems to Benefit Downstream Vision Tasks|egoPPG：基于第一视角系统中眼动跟踪相机的心率估计以促进下游视觉任务|Björn Braun, Rayan Armani, Manuel Meier, Max Moebus, Christian Holz|<http://arxiv.org/pdf/2502.20879v2>|提出egoPPG方法，利用眼动相机从第一视角系统中估计心率，增强对用户情境感知的视觉任务。|
|🆕 发布|CLIPVehicle: A Unified Framework for Vision-based Vehicle Search|CLIPVehicle：一种基于视觉的车辆搜索统一框架|Likai Wang, Ruize Han, Xiangqun Zhang, Wei Feng|<http://arxiv.org/pdf/2508.04120v1>|提出了一种统一框架CLIPVehicle，通过双粒度语义区域对齐和多级识别策略，实现了车辆检测与重识...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|How Does Bilateral Ear Symmetry Affect Deep Ear Features?|双边耳朵对称性如何影响深度耳朵特征？|Kagan Ozturk, Deeksha Arun, Kevin W. Bowyer, Patrick Flynn|<http://arxiv.org/pdf/2508.04614v1>|探究了双边耳对称性对深度学习耳部特征的影响，并证实分别处理左右耳数据可显著提升识别性能。|
|📝 更新|RGB-Event based Pedestrian Attribute Recognition: A Benchmark Dataset and An Asymmetric RWKV Fusion Framework|基于RGB-事件融合的行人属性识别：一个基准数据集与一种非对称RWKV融合框架|Xiao Wang, Haiyang Wang, Shiao Wang, Qiang Chen, Jiandong Jin, Haoyu Song, Bo Jiang, Chenglong Li|<http://arxiv.org/pdf/2504.10018v2>|[代码](https://github.com/Event-AHU/OpenPAR); 提出首个大规模多模态RGB-Event行人属性识别数据集，并设计了一种RWKV融合框架提升识别性能。|
|🆕 发布|ToxicTAGS: Decoding Toxic Memes with Rich Tag Annotations|《ToxicTAGS：利用丰富标签注释解码有毒梗图》|Subhankar Swain, Naquee Rizwan, Nayandeep Deb, Vishwajeet Singh Solanki, Vishwa Gangadhar S, Animesh Mukherjee|<http://arxiv.org/pdf/2508.04166v1>|提出首个带丰富标签注解的毒性表情包数据集，通过添加社会相关标签提升内容审核性能。|
|🆕 发布|Continual Multiple Instance Learning for Hematologic Disease Diagnosis|连续多实例学习在血液病诊断中的应用|Zahra Ebrahimi, Raheleh Salehi, Nassir Navab, Carsten Marr, Ario Sadafi|<http://arxiv.org/pdf/2508.04368v1>|首次提出针对多重实例学习的连续学习策略，有效适应数据分布变化，提升血液病诊断模型性能。|
|🆕 发布|What Holds Back Open-Vocabulary Segmentation?|什么阻碍了开放词汇分割？|Josip Šarić, Ivan Martinović, Matej Kristan, Siniša Šegvić|<http://arxiv.org/pdf/2508.04211v1>|揭示了开放词汇分割模型的性能瓶颈，并提出新型验证实验方法来解锁未来研究。|

