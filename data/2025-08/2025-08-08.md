## [UPDATED!] **2025-08-08** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Can Test-Time Scaling Improve World Foundation Model?|测试时缩放能提高世界基础模型的表现吗？|Wenyan Cong, Hanqing Zhu, Peihao Wang, Bangya Liu, Dejia Xu, Kevin Wang, David Z. Pan, Yan Wang .etc.|<http://arxiv.org/pdf/2503.24320v2>|[代码](https://scalingwfm.github.io/.); 提出SWIFT框架，通过测试时缩放提升物理世界模拟模型效率，无需重训练或增大模型。|
|📝 更新|ATM: Improving Model Merging by Alternating Tuning and Merging|ATM：通过交替调整和合并提高模型合并效果|Luca Zhou, Daniele Solombrino, Donato Crisostomi, Maria Sofia Bucarelli, Fabrizio Silvestri, Emanuele Rodolà|<http://arxiv.org/pdf/2411.03055v4>|提出迭代调整与合并策略ATM，有效提升模型合并效率和精度。|
|📝 更新|Can Multimodal Large Language Models Understand Spatial Relations?|多模态大型语言模型能理解空间关系吗？|Jingping Liu, Ziyan Liu, Zhedong Cen, Yan Zhou, Yinan Zou, Weiyan Zhang, Haiyun Jiang, Tong Ruan|<http://arxiv.org/pdf/2505.19015v2>|[代码](https://github.com/ziyan-xiaoyu/SpatialMQA.git.); 提出 SpatialMQA 标准，提升多模态大语言模型对空间关系的理解能力。|
|🆕 发布|SDEval: Safety Dynamic Evaluation for Multimodal Large Language Models|多模态大型语言模型的安全性动态评估：SDEval|Hanqing Wang, Yuan Tian, Mingyu Liu, Zhenhao Zhang, Xiangyang Zhu|<http://arxiv.org/pdf/2508.06142v1>|[代码](https://github.com/hq-King/SDEval); 提出SDEval框架，动态调整安全评估标准，有效应对大型多模态语言模型输出安全问题。|
|🆕 发布|SAM Encoder Breach by Adversarial Simplicial Complex Triggers Downstream Model Failures|对抗性单纯复形攻击导致SAM编码器泄露，触发下游模型故障|Yi Qin, Rui Wang, Tao Huang, Tong Xiao, Liping Jing|<http://arxiv.org/pdf/2508.06127v1>|提出VeSCA方法，通过攻击SAM编码器生成高转移性的对抗样本，提升了对下游模型的安全性。|
|📝 更新|DanceGRPO: Unleashing GRPO on Visual Generation|舞动GRPO：在视觉生成中释放GRPO的力量|Zeyue Xue, Jie Wu, Yu Gao, Fangyuan Kong, Lingting Zhu, Mengzhao Chen, Zhiheng Liu, Wei Liu .etc.|<http://arxiv.org/pdf/2505.07818v3>|提出DanceGRPO框架，利用GRPO稳定性优化视觉生成任务，提升模型适应性和多样性。|
|📝 更新|CARE: Enhancing Safety of Visual Navigation through Collision Avoidance via Repulsive Estimation|CARE：通过排斥估计实现避障以提高视觉导航的安全性|Joonkyung Kim, Joonyeol Sim, Woojun Kim, Katia Sycara, Changjoo Nam|<http://arxiv.org/pdf/2506.03834v4>|[代码](https://airlab-sogang.github.io/CARE); 提出CARE方法，通过估计排斥力动态调整机器人轨迹，显著提高视觉导航的安全性并减少碰撞。|
|🆕 发布|AdaptInfer: Adaptive Token Pruning for Vision-Language Model Inference with Dynamical Text Guidance|自适应推断：动态文本引导下的视觉语言模型推理中的自适应标记剪枝|Weichen Zhang, Zhui Zhu, Ningbo Li, Kebin Liu, Yunhao Liu|<http://arxiv.org/pdf/2508.06084v1>|提出自适应剪枝框架AdaptInfer，通过动态文本指导优化视觉token处理，降低推理成本同时保持...|
|📝 更新|AVA-Bench: Atomic Visual Ability Benchmark for Vision Foundation Models|原子视觉能力基准测试：面向视觉基础模型的AVA-Bench|Zheda Mai, Arpita Chowdhury, Zihe Wang, Sooyoung Jeon, Lemeng Wang, Jiacheng Hou, Wei-Lun Chao|<http://arxiv.org/pdf/2506.09082v2>|提出AVA-Bench，通过分离14种基础视觉能力，精确评估视觉基础模型的性能。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ShadowMamba: State-Space Model with Boundary-Region Selective Scan for Shadow Removal|阴影魔巴：具有边界区域选择扫描的状态空间模型用于阴影去除|Xiujin Zhu, Chee-Onn Chow, Joon Huang Chuah|<http://arxiv.org/pdf/2411.03260v4>|[代码](https://github.com/ZHUXIUJINChris/ShadowMamba); 提出边界区域选择性扫描机制，ShadowMamba模型高效去除图像阴影，提升视觉任务性能。|
|📝 更新|MOR-VIT: Efficient Vision Transformer with Mixture-of-Recursions|MOR-VIT：具有递归混合的效率化视觉变换器|YiZhou Li|<http://arxiv.org/pdf/2507.21761v2>|引入动态递归机制以自适应调整计算深度，MOR-VIT实现参数减少70%和推理加速2.5倍。|
|🆕 发布|Depth Jitter: Seeing through the Depth|深度抖动：透过深度看世界|Md Sazidur Rahman, David Cabecinhas, Ricard Marxer|<http://arxiv.org/pdf/2508.06227v1>|[代码](https://github.com/mim-team/Depth-Jitter); 提出深度抖动技术，通过模拟自然深度变化提升模型在真实世界深度条件下的稳定性和泛化能力。|
|🆕 发布|Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models|傅里叶-视觉语言模型：在频域中压缩视觉标记以用于大型视觉语言模型|Huanyu Wang, Jushi Kai, Haoli Bai, Lu Hou, Bo Jiang, Ziwei He, Zhouhan Lin|<http://arxiv.org/pdf/2508.06038v1>|提出了一种在频率域压缩视觉表示的方法Fourier-VLM，有效减少计算负担并提升推理速度。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|M$^2$IV: Towards Efficient and Fine-grained Multimodal In-Context Learning via Representation Engineering|M$^2$IV：通过表征工程实现高效和细粒度的多模态情境学习|Yanshu Li, Yi Cao, Hongyang He, Qisen Cheng, Xiang Fu, Xi Xiao, Tianyang Wang, Ruixiang Tang|<http://arxiv.org/pdf/2504.04633v2>|提出M$^2$IV方法，通过注入多模态向量提升大型视觉语言模型在少量样本学习中的效率和精确度。|
|🆕 发布|Affordance-R1: Reinforcement Learning for Generalizable Affordance Reasoning in Multimodal Large Language Model|《Affordance-R1：面向多模态大型语言模型中泛化功效推理的强化学习》|Hanqing Wang, Shaoyang Wang, Yiming Zhong, Zemin Yang, Jiamin Wang, Zhiqing Cui, Jiahao Yuan, Yifan Han .etc.|<http://arxiv.org/pdf/2508.06206v1>|[代码](https://github.com/hq-King/Affordance-R1.); 提出Affordance-R1框架，通过强化学习与认知推理结合，实现通用性物体可用性推理的零样本泛化...|
|🆕 发布|ECMF: Enhanced Cross-Modal Fusion for Multimodal Emotion Recognition in MER-SEMI Challenge|ECMF：增强型跨模态融合用于MER-SEMI挑战中的多模态情感识别|Juewen Hu, Yexin Li, Jiulin Li, Shuo Chen, Pring Wong|<http://arxiv.org/pdf/2508.05991v1>|提出了一种多模态情感识别框架，通过双分支视觉编码器和上下文增强文本处理，结合自注意力机制和残差连接，...|
|🆕 发布|Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents|“Bifrost-1：使用图块级CLIP潜在变量连接多模态大型语言模型与扩散模型”|Han Lin, Jaemin Cho, Amir Zadeh, Chuan Li, Mohit Bansal|<http://arxiv.org/pdf/2508.05954v1>|提出了Bifrost-1框架，利用CLIP图像嵌入桥接多模态语言模型与扩散模型，实现高效高保真图像生...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Text Embedded Swin-UMamba for DeepLesion Segmentation|文本嵌入Swin-UMamba用于深度病变分割|Ruida Cheng, Tejas Sudharshan Mathai, Pritam Mukherjee, Benjamin Hou, Qingqing Zhu, Zhiyong Lu, Matthew McAuliffe, Ronald M. Summers|<http://arxiv.org/pdf/2508.06453v1>|[代码](https://github.com/ruida/LLM-Swin-UMamba); 集成大型语言模型与Swin-UMamba架构，实现了病变分割性能的显著提升。|
|🆕 发布|An Implemention of Two-Phase Image Segmentation using the Split Bregman Method|基于分裂Bregman方法的二阶段图像分割实现|Olakunle S. Abawonse, Günay Doğan|<http://arxiv.org/pdf/2508.06351v1>|实现了基于Split Bregman方法的二相图像分割算法，有效划分图像前景与背景。|
|🆕 发布|XAG-Net: A Cross-Slice Attention and Skip Gating Network for 2.5D Femur MRI Segmentation|XAG-Net：一种用于2.5D股骨MRI分割的跨切片注意力和跳跃门控网络|Byunghyun Ko, Anning Tian, Jeongkyu Lee|<http://arxiv.org/pdf/2508.06258v1>|提出XAG-Net，一种结合像素级跨切片注意力和跳级门控的2.5D网络，提升股骨MRI分割精度与效率...|
|🆕 发布|SynSeg: Feature Synergy for Multi-Category Contrastive Learning in Open-Vocabulary Semantic Segmentation|SynSeg：开放式词汇语义分割中多类别对比学习的特征协同|Weichen Zhang, Kebin Liu, Fan Dang, Zhui Zhu, Xikai Sun, Yunhao Liu|<http://arxiv.org/pdf/2508.06115v1>|提出了一种名为SynSeg的弱监督学习方法，通过多类别对比学习和特征协同结构，有效提升了开放词汇场景...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Are you In or Out (of gallery)? Wisdom from the Same-Identity Crowd|你是圈内人还是圈外人？来自同身份群体的智慧|Aman Bhatta, Maria Dhakal, Michael C. King, Kevin W. Bowyer|<http://arxiv.org/pdf/2508.06357v1>|提出了一种利用同一身份的多张图片特征预测是否在库中的新方法，有效降低了一对多人脸识别的误识别率。|
|🆕 发布|PA-HOI: A Physics-Aware Human and Object Interaction Dataset|PA-HOI：一种具有物理感知能力的人类与物体交互数据集|Ruiyan Wang, Lin Zuo, Zonghao Lin, Qiang Wang, Zhengxue Cheng, Rong Xie, Jun Ling, Li Song|<http://arxiv.org/pdf/2508.06205v1>|提出PA-HOI数据集，通过物理属性分析人类互动，扩展了HOI任务对物体影响人类动作的理解。|
|🆕 发布|Distribution-Specific Learning for Joint Salient and Camouflaged Object Detection|分布特定学习用于联合显著和迷彩目标检测|Chao Hao, Zitong Yu, Xin Liu, Yuhao Wang, Weicheng Xie, Jingang Shi, Huanjing Yue, Jingyu Yang|<http://arxiv.org/pdf/2508.06063v1>|[代码](https://github.com/linuxsino/JoNet.); 提出了一种分布特定学习的联合显著和伪装目标检测方法，通过在共享网络中引入任务特定参数，有效解耦了两个...|
|📝 更新|COIN: Confidence Score-Guided Distillation for Annotation-Free Cell Segmentation|COIN：置信度分数引导的无标注细胞分割蒸馏方法|Sanghyun Jo, Seo Jin Lee, Seungwoo Lee, Seohyung Hong, Hyungseok Seo, Kyungsu Kim|<http://arxiv.org/pdf/2503.11439v4>|[代码](https://github.com/shjo-april/COIN.); 提出了一种无需标注的细胞分割框架COIN，通过置信度评分引导蒸馏，提高了无监督细胞实例分割的准确性。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MambaEviScrib: Mamba and Evidence-Guided Consistency Enhance CNN Robustness for Scribble-Based Weakly Supervised Ultrasound Image Segmentation|MambaEviScrib：Mamba与证据引导一致性增强卷积神经网络在基于涂抹弱监督超声图像分割中的鲁棒性|Xiaoxiang Han, Xinyu Li, Jiang Shang, Yiman Liu, Keyan Chen, Shugong Xu, Qiaohong Liu, Qi Zhang|<http://arxiv.org/pdf/2409.19370v3>|[代码](https://github.com/GtLinyer/MambaEviScrib.); 提出了一种结合Dempster-Shafer证据理论和Visual Mamba框架的方法，增强CNN...|
|🆕 发布|Advanced Deep Learning Techniques for Accurate Lung Cancer Detection and Classification|深度学习技术在精确肺 cancer 检测与分类中的高级应用|Mobarak Abumohsen, Enrique Costa-Montenegro, Silvia García-Méndez, Amani Yousef Owda, Majdi Owda|<http://arxiv.org/pdf/2508.06287v1>|提出了一种基于DenseNet201模型结合Focal Loss、数据增强和正则化的肺癌检测与分类方...|
|📝 更新|Hybrid-TTA: Continual Test-time Adaptation via Dynamic Domain Shift Detection|混合-TTA：通过动态域偏移检测实现的持续测试时适应|Hyewon Park, Hyejin Park, Jueun Ko, Dongbo Min|<http://arxiv.org/pdf/2409.08566v2>|提出Hybrid-TTA方法，通过动态领域偏移检测优化实时适应不同领域变化，提升模型适应性和鲁棒性。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Effective Training Data Synthesis for Improving MLLM Chart Understanding|有效的训练数据合成以提高多模态语言模型图表理解能力|Yuwei Yang, Zeyu Zhang, Yunzhong Hou, Zhuowan Li, Gaowen Liu, Ali Payani, Yuan-Sen Ting, Liang Zheng|<http://arxiv.org/pdf/2508.06492v1>|[代码](https://github.com/yuweiyang-anu/ECD.); 提出了一种模块化图表生成和多样化视觉细节的数据合成方法，显著提升了多模态大语言模型对复杂图表的理解能...|
|📝 更新|Generative Video Bi-flow|生成视频双向流|Chen Liu, Tobias Ritschel|<http://arxiv.org/pdf/2503.06364v2>|提出了一种新的生成视频模型，通过结合直接映射过去至未来帧和消除累积误差的方法，实现了高效稳定的视频生...|
|🆕 发布|WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion|弱监督生成网络：通过时空融合估计日常10米地表温度|Sofiane Bouaziz, Adel Hafiane, Raphael Canals, Rachid Nedjai|<http://arxiv.org/pdf/2508.06485v1>|[代码](https://github.com/Sofianebouaziz1/WGAST.git.); 提出了一种用于每日10米地表温度估算的弱监督生成网络，通过时空融合显著提升了精度和稳定性。|
|🆕 发布|Aligning Effective Tokens with Video Anomaly in Large Language Models|在大语言模型中将对异常视频有效标记对齐|Yingxian Chen, Jiahui Liu, Ruifan Di, Yanwei Li, Chirui Chang, Shizhen Zhao, Wilton W. T. Fok, Xiaojuan Qi .etc.|<http://arxiv.org/pdf/2508.06350v1>|提出VA-GPT模型，通过高效选择和生成有效视觉语言 tokens，提升多模态大模型对视频异常事件的...|
|📝 更新|MoDA: Multi-modal Diffusion Architecture for Talking Head Generation|多模态扩散架构用于说话人头生成|Xinyang Li, Gen Li, Zhihui Lin, Yichen Qian, GongXin Yao, Weinan Jia, Aowen Wang, Weihua Chen .etc.|<http://arxiv.org/pdf/2507.03256v3>|[代码](https://lixinyyang.github.io/MoDA.github.io); 提出了一种多模态扩散架构MoDA，有效融合动作、音频等多模态信息，提升了虚拟人头生成的多样性和真实感...|
|🆕 发布|SIFThinker: Spatially-Aware Image Focus for Visual Reasoning|"SIFThinker：空间感知图像聚焦视觉推理"|Zhangquan Chen, Ruihui Zhao, Chuwei Luo, Mingze Sun, Xinlei Yu, Yangyang Kang, Ruqi Huang|<http://arxiv.org/pdf/2508.06259v1>|提出SIFThinker框架，通过结合深度信息和自然语言实现图像区域的空间感知注意力校正，提升视觉推...|
|🆕 发布|Towards Unified Image Deblurring using a Mixture-of-Experts Decoder|面向统一图像去模糊的混合专家解码器方法|Daniel Feijoo, Paula Garrido-Mellado, Jaesung Rim, Alvaro Garcia, Marcos V. Conde|<http://arxiv.org/pdf/2508.06228v1>|提出了一种统一的图像去模糊方法，使用混合专家解码器处理多种模糊类型，实现了高效精准的图像恢复。|
|🆕 发布|Text-guided Visual Prompt DINO for Generic Segmentation|文本引导的视觉提示DINO用于通用分割|Yuchen Guan, Chong Sun, Canmiao Fu, Zhipeng Huang, Chun Yuan, Chen Li|<http://arxiv.org/pdf/2508.06146v1>|[代码](https://github.com/WeChatCV/WeVisionOne.); 提出Prompt-DINO框架，通过早期融合、优化查询选择和生成式数据引擎，解决了多模态视觉模型在开...|
|🆕 发布|Synthetic Data-Driven Multi-Architecture Framework for Automated Polyp Segmentation Through Integrated Detection and Mask Generation|合成数据驱动的多架构框架：通过集成检测与掩膜生成实现自动化息肉分割|Ojonugwa Oluwafemi Ejiga Peter, Akingbola Oluwapemiisin, Amalahu Chetachi, Adeniran Opeyemi, Fahmi Khalifa, Md Mahmudur Rahman|<http://arxiv.org/pdf/2508.06170v1>|提出了一种合成数据驱动的多架构框架，通过集成检测和掩膜生成自动化息肉分割，有效解决了数据集规模有限和...|
|🆕 发布|DiffCap: Diffusion-based Real-time Human Motion Capture using Sparse IMUs and a Monocular Camera|扩散捕捉：基于稀疏惯性测量单元和单目相机实现的实时人体运动捕捉|Shaohua Pan, Xinyu Yi, Yan Zhou, Weihua Jian, Yuan Zhang, Pengfei Wan, Feng Xu|<http://arxiv.org/pdf/2508.06139v1>|[代码](https://shaohua-pan.github.io/diffcap-page.); 提出了一种基于扩散模型的方法，融合稀疏IMU和单目相机信号，实现了实时人体运动捕捉。|
|📝 更新|Neural-Driven Image Editing|神经驱动的图像编辑|Pengfei Zhou, Jie Xia, Xiaopeng Peng, Wangbo Zhao, Zilong Ye, Zekai Li, Suorong Yang, Jiadong Pan .etc.|<http://arxiv.org/pdf/2507.05397v2>|提出了一种基于神经信号的无需手动操作的新型图像编辑方法，实现了直观便捷的图像编辑体验。|
|🆕 发布|E-React: Towards Emotionally Controlled Synthesis of Human Reactions|情感控制的虚拟人类反应生成方法E-React|Chen Zhu, Buzhen Huang, Zijing Wu, Binghui Zuo, Yangang Wang|<http://arxiv.org/pdf/2508.06093v1>|引入情感驱动的反应动作生成框架，通过半监督学习提升动作的自然度和多样性。|
|🆕 发布|DreamVE: Unified Instruction-based Image and Video Editing|梦幻VE：基于统一指令的图像与视频编辑|Bin Xia, Jiyang Liu, Yuechen Zhang, Bohao Peng, Ruihang Chu, Yitong Wang, Xinglong Wu, Bei Yu .etc.|<http://arxiv.org/pdf/2508.06080v1>|提出了一种统一模型DreamVE，通过分阶段训练和综合数据合成策略，实现了基于指令的图像与视频编辑。|
|🆕 发布|Towards MR-Based Trochleoplasty Planning|面向基于MR的髌骨沟成形术规划|Michael Wehrli, Alicia Durrer, Paul Friedrich, Sidaty El Hadramy, Edwin Li, Luana Brahaj, Carol C. Hasler, Philippe C. Cattin|<http://arxiv.org/pdf/2508.06076v1>|[代码](https://wehrlimi.github.io/sr-3d-planning); 提出了一种基于深度学习的方案，从常规临床MR扫描生成高分辨率的3D健康形态，用于治疗股骨滑车发育不良...|
|🆕 发布|SwiftVideo: A Unified Framework for Few-Step Video Generation through Trajectory-Distribution Alignment|SwiftVideo：通过轨迹分布对齐实现少步视频生成的统一框架|Yanxiao Sun, Jiafu Wu, Yun Cao, Chengming Xu, Yabiao Wang, Weijian Cao, Donghao Luo, Chengjie Wang .etc.|<http://arxiv.org/pdf/2508.06082v1>|提出了一种结合轨迹保持和分布匹配的统一框架SwiftVideo，大幅减少了视频生成所需的推断步骤，同...|
|🆕 发布|ThematicPlane: Bridging Tacit User Intent and Latent Spaces for Image Generation|主题平面：桥接隐含用户意图与潜在空间进行图像生成|Daniel Lee, Nikhil Sharma, Donghoon Shin, DaEun Choi, Harsh Sharma, Jeonghwan Kim, Heng Ji|<http://arxiv.org/pdf/2508.06065v1>|提出ThematicPlane系统，通过交互式设计平面桥接用户隐含意图与生成模型，增强图像创作的直观...|
|🆕 发布|NEP: Autoregressive Image Editing via Next Editing Token Prediction|下一代编辑标记：通过下一编辑标记预测的自回归图像编辑|Huimin Wu, Xiaojian Ma, Haozhe Zhao, Yanpeng Zhao, Qing Li|<http://arxiv.org/pdf/2508.06044v1>|提出了一种基于自回归生成模型的图像编辑方法，仅编辑指定区域，减少计算成本并提高编辑质量。|
|🆕 发布|InstantEdit: Text-Guided Few-Step Image Editing with Piecewise Rectified Flow|即时编辑：基于文本引导的少步骤图像编辑与分段修正流|Yiming Gong, Zhen Zhu, Minjia Zhang|<http://arxiv.org/pdf/2508.06033v1>|提出了一种快速文本引导的图像编辑方法InstantEdit，通过分步编辑和特殊策略保持了内容关键性，...|
|📝 更新|FLUX-Text: A Simple and Advanced Diffusion Transformer Baseline for Scene Text Editing|FLUX-Text：一种简单且先进的用于场景文本编辑的扩散变换器基线|Rui Lan, Yancheng Bai, Xu Duan, Mingxing Li, Dongyang Jin, Ryan Xu, Lei Sun, Xiangxiang Chu|<http://arxiv.org/pdf/2505.03329v3>|[代码](https://github.com/AMAP-ML/FluxText.); FLUX-Text通过轻量级视觉与文本嵌入模块，有效提升了对复杂文字结构的理解和生成，大幅减少训练样...|
|🆕 发布|EvoMakeup: High-Fidelity and Controllable Makeup Editing with MakeupQuad|《EvoMakeup：基于 MakeupQuad 的高保真度和可控制性化妆编辑》|Huadong Wu, Yi Fu, Yunhao Li, Yuan Gao, Kang Du|<http://arxiv.org/pdf/2508.05994v1>|提出了一种高保真、可控的妆容编辑框架EvoMakeup，通过大规模数据集和迭代优化，实现了高质量妆容...|
|📝 更新|MetaOcc: Spatio-Temporal Fusion of Surround-View 4D Radar and Camera for 3D Occupancy Prediction with Dual Training Strategies|元占用预测：采用双训练策略的环视4D雷达与相机时空融合进行三维占用预测|Long Yang, Lianqing Zheng, Wenjin Ai, Minghao Liu, Sen Li, Qunshu Lin, Shengyu Yan, Jie Bai .etc.|<http://arxiv.org/pdf/2501.15384v3>|[代码](https://github.com/LucasYang567/MetaOcc.); 提出了一种融合4D雷达和相机数据的多模态框架MetaOcc，通过双训练策略实现了高效的3D占用预测。|
|🆕 发布|A 3DGS-Diffusion Self-Supervised Framework for Normal Estimation from a Single Image|一种基于3DGS-Diffusion自监督框架的单张图像法线估计方法|Yanxing Liang, Yinghui Wang, Jinlong Yang, Wei Li|<http://arxiv.org/pdf/2508.05950v1>|提出了一种基于3D高斯散点引导扩散的自监督框架，通过物理驱动的光交互模型和可微分渲染重投影策略，解决...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multivariate Fields of Experts|多变量专家场|Stanislas Ducotterd, Michael Unser|<http://arxiv.org/pdf/2508.06490v1>|提出多变量场专家模型，通过构建新型潜在函数学习图像先验，实现多种图像处理任务的高效性能。|
|🆕 发布|LightSwitch: Multi-view Relighting with Material-guided Diffusion|《LightSwitch：基于材料引导扩散的多视角重光照》|Yehonathan Litman, Fernando De la Torre, Shubham Tulsiani|<http://arxiv.org/pdf/2508.06494v1>|提出LightSwitch，一种结合材质引导和多云视角数据的扩散框架，高效实现多视角图像的重光照效果...|
|📝 更新|Vision-Language Model-Based Semantic-Guided Imaging Biomarker for Lung Nodule Malignancy Prediction|基于视觉-语言模型的语义引导成像生物标志物在肺结节恶性预测中的应用|Luoting Zhuang, Seyed Mohammad Hossein Tabatabaei, Ramin Salehi-Rad, Linh M. Tran, Denise R. Aberle, Ashley E. Prosper, William Hsu|<http://arxiv.org/pdf/2504.21344v2>|[代码](https://github.com/luotingzhuang/CLIP_nodule.); 集成语义特征与预训练模型，提出预测肺结节恶性的高效可解释方法。|
|🆕 发布|MotionSwap|运动转换|Om Patil, Jinesh Modi, Suryabha Mukhopadhyay, Meghaditya Giri, Chhavi Malhotra|<http://arxiv.org/pdf/2508.06430v1>|提出改进的SimSwap框架，通过引入自注意力与交叉注意力机制等优化，显著提升了面部交换技术的身份保...|
|🆕 发布|FVGen: Accelerating Novel-View Synthesis with Adversarial Video Diffusion Distillation|FVGen：利用对抗视频扩散蒸馏加速新视角合成|Wenbin Teng, Gonglin Chen, Haiwei Chen, Yajie Zhao|<http://arxiv.org/pdf/2508.06392v1>|FVGen通过对抗视频扩散蒸馏技术，将多步去噪模型压缩至仅需四步采样，大幅提升稀疏视角下的视图合成速...|
|🆕 发布|Can Diffusion Models Bridge the Domain Gap in Cardiac MR Imaging?|扩散模型能否弥合心脏磁共振成像的域差距？|Xin Ci Wong, Duygu Sarikaya, Kieran Zucker, Marc De Kamps, Nishant Ravikumar|<http://arxiv.org/pdf/2508.06327v1>|提出了一种基于扩散模型的生成方法，通过生成与源域相似的心脏MR图像，有效缓解了领域迁移问题。|
|📝 更新|CDI: Blind Image Restoration Fidelity Evaluation based on Consistency with Degraded Image|基于退化图像一致性的盲目图像恢复保真度评估方法CDI|Xiaojun Tang, Jingru Wang, Guangwei Huang, Guannan Chen, Rui Zheng, Lian Huai, Yuyu Liu, Xingqun Jiang|<http://arxiv.org/pdf/2501.14264v2>|提出了一种基于图像退化一致性的盲图像复原质量评估方法，无需参考图像即可准确评价复原质量。|
|📝 更新|MPG-SAM 2: Adapting SAM 2 with Mask Priors and Global Context for Referring Video Object Segmentation|MPG-SAM 2：利用掩膜先验和全局上下文适应SAM 2进行视频目标分割|Fu Rong, Meng Lan, Qian Zhang, Lefei Zhang|<http://arxiv.org/pdf/2501.13667v5>|[代码](https://github.com/rongfu-dsb/MPG-SAM2.); 提出MPG-SAM 2框架，融合掩膜先验和全局上下文，提升视频对象分割的准确性和一致性。|
|🆕 发布|Improving Diagnostic Accuracy for Oral Cancer with inpainting Synthesis Lesions Generated Using Diffusion Models|利用扩散模型生成修复合成病变以提高口腔癌诊断准确性|Yong Oh Lee, JeeEun Kim, Jung Woo Lee|<http://arxiv.org/pdf/2508.06151v1>|利用扩散模型生成逼真口腔癌病变图像，显著提升诊断模型准确率。|
|🆕 发布|VISTAR:A User-Centric and Role-Driven Benchmark for Text-to-Image Evaluation|VISTAR：一种以用户为中心、角色驱动的文本到图像评估基准|Kaiyuan Jiang, Ruoxi Sun, Ying Cao, Yuqi Xu, Xinran Zhang, Junyan Guo, ChengSheng Deng|<http://arxiv.org/pdf/2508.06152v1>|提出VISTAR基准，结合确定性指标与新型语义评估方案，全面优化文本到图像的评价方法。|
|🆕 发布|Fewer Denoising Steps or Cheaper Per-Step Inference: Towards Compute-Optimal Diffusion Model Deployment|更少的去噪步骤或每步更经济的推理：迈向计算最优的扩散模型部署|Zhenbang Du, Yonggan Fu, Lifu Wang, Jiayi Qian, Xiao Luo, Yingyan, Lin|<http://arxiv.org/pdf/2508.06160v1>|[代码](https://github.com/GATECH-EIC/PostDiff.); 提出了一种无需训练的PostDiff框架，通过减少每步推理成本而非简化步骤数量，优化了扩散模型的效率...|
|🆕 发布|SC-Captioner: Improving Image Captioning with Self-Correction by Reinforcement Learning|SC-标注器：通过强化学习的自我校正提高图像标注性能|Lin Zhang, Xianfang Zeng, Kangcong Li, Gang Yu, Tao Chen|<http://arxiv.org/pdf/2508.06125v1>|提出SC-Captioner框架，通过强化学习实现图像字幕模型的自我修正功能，优化了字幕准确性。|
|🆕 发布|AGI for the Earth, the path, possibilities and how to evaluate intelligence of models that work with Earth Observation Data?|面向地球的通用人工智能：路径、可能性及如何评估处理地球观测数据模型的智能|Mojtaba Valipour, Kelly Zheng, James Lowman, Spencer Szabados, Mike Gartner, Bobby Braswell|<http://arxiv.org/pdf/2508.06057v1>|提出地球观测数据对智能模型的重要性，并提议一套全面任务集以评估模型理解力。|
|🆕 发布|Learning 3D Texture-Aware Representations for Parsing Diverse Human Clothing and Body Parts|学习三维纹理感知表征以解析多样化人体着装与身体部位|Kiran Chhatre, Christopher Peters, Srikrishna Karanam|<http://arxiv.org/pdf/2508.06032v1>|提出了一种结合3D纹理生成的图像解析方法，有效区分人体部位和多样服装类型。|
|🆕 发布|ExploreGS: Explorable 3D Scene Reconstruction with Virtual Camera Samplings and Diffusion Priors|探索GS：基于虚拟相机采样和扩散先验的可探索三维场景重建|Minsu Kim, Subin Jeon, In Cho, Mijin Yoo, Seon Joo Kim|<http://arxiv.org/pdf/2508.06014v1>|提出了一种增强3D场景重建质量的方法，通过虚拟相机采样和信息增益驱动策略，结合视频扩散先验，实现了高...|
|🆕 发布|KnapFormer: An Online Load Balancer for Efficient Diffusion Transformers Training|KnapFormer：一种用于高效扩散变换器训练的在线负载均衡器|Kai Zhang, Peng Wang, Sai Bi, Jianming Zhang, Yuanjun Xiong|<http://arxiv.org/pdf/2508.06001v1>|[代码](https://github.com/Kai-46/KnapFormer); 提出KnapFormer框架，平衡分布式训练中序列并行性与负载不均问题，实现高效扩散变换器训练。|
|📝 更新|Can Large Pretrained Depth Estimation Models Help With Image Dehazing?|大型预训练深度估计模型能否助力图像去雾？|Hongfei Zhang, Kun Zhou, Ruizheng Wu, Jiangbo Lu|<http://arxiv.org/pdf/2508.00698v2>|探究预训练深度估计模型在图像去雾中的应用，提出了一种通用性强的RGB-D融合模块。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Deepfake Detection that Generalizes Across Benchmarks|跨基准测试的深度伪造检测泛化方法|Andrii Yermakov, Jan Cech, Jiri Matas, Mario Fritz|<http://arxiv.org/pdf/2508.06248v1>|提出了一种高效的深度伪造检测方法，通过微调预训练CLIP模型的少量参数实现跨数据集的泛化性能。|
|📝 更新|Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation|细粒度图像-文本对应关系结合代价聚合的开词汇部件分割|Jiho Choi, Seonho Lee, Minhyun Lee, Seungho Lee, Hyunjung Shim|<http://arxiv.org/pdf/2501.09688v2>|提出PartCATSeg框架，通过分离对象和部分级别的成本聚合，提高了开放词汇部分分割的精度和泛化能...|
|📝 更新|MESAHA-Net: Multi-Encoders based Self-Adaptive Hard Attention Network with Maximum Intensity Projections for Lung Nodule Segmentation in CT Scan|MESAHA-Net：基于多编码器的自适应硬注意力网络与最大强度投影在CT扫描中用于肺结节分割|Muhammad Usman, Azka Rehman, Abd Ur Rehman, Abdullah Shahid, Tariq Mahmood Khan, Imran Razzak, Minyoung Chung, Yeong Gil Shin|<http://arxiv.org/pdf/2304.01576v2>|提出MESAHA-Net，一种多编码器自适应硬注意力网络，用于精确的肺结节三维分割，提升了准确性和计...|
|🆕 发布|VQAThinker: Exploring Generalizable and Explainable Video Quality Assessment via Reinforcement Learning|VQAThinker：通过强化学习探索泛化和可解释的视频质量评估|Linhan Cao, Wei Sun, Weixia Zhang, Xiangyang Zhu, Jun Jia, Kaiwei Zhang, Dandan Zhu, Guangtao Zhai .etc.|<http://arxiv.org/pdf/2508.06051v1>|提出VQAThinker框架，利用强化学习模仿人类决策，提升视频质量评估的泛化能力和解释性。|
|📝 更新|RetinexDual: Retinex-based Dual Nature Approach for Generalized Ultra-High-Definition Image Restoration|基于Retinex的双特性方法用于广义超高清图像复原：RetinexDual|Mohab Kishawy, Ali Abdellatif Hussein, Jun Chen|<http://arxiv.org/pdf/2508.04797v2>|提出了一种基于Retinex理论的UHD图像复原框架RetinexDual，通过双分支网络有效克服了...|
|🆕 发布|AnimateScene: Camera-controllable Animation in Any Scene|任意场景中的相机可控动画：AnimateScene|Qingyang Liu, Bingjie Gao, Weiheng Huang, Jun Zhang, Zhongqian Sun, Yang Wei, Zelin Peng, Qianli Ma .etc.|<http://arxiv.org/pdf/2508.05982v1>|AnimateScene通过统一框架精确放置人物、匹配风格和插入相机轨迹，实现了场景与4D动画的自然...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UGD-IML: A Unified Generative Diffusion-based Framework for Constrained and Unconstrained Image Manipulation Localization|统一生成扩散框架UGD-IML：用于约束和无约束图像操作定位|Yachun Mi, Xingyang He, Shixin Sun, Yu Li, Yanting Li, Zhixuan Li, Jian Jin, Chen Hui .etc.|<http://arxiv.org/pdf/2508.06101v1>|提出了一种基于生成扩散模型的统一框架UGD-IML，首次将图像操纵定位与约束图像操纵定位任务合并，减...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Event2Vec: Processing neuromorphic events directly by representations in vector space|事件向量：通过向量空间中的表示直接处理类神经形态事件|Wei Fang, Priyadarshini Panda|<http://arxiv.org/pdf/2504.15371v2>|[代码](https://github.com/fangwei123456/event2vec.); 提出Event2Vec方法，将异步稀疏事件转换为向量表示，提升 neuromorphic 事件相机图...|
|📝 更新|MBA-SLAM: Motion Blur Aware Gaussian Splatting SLAM|MBA-SLAM：运动模糊感知高斯散斑SLAM|Peng Wang, Lingzhe Zhao, Yin Zhang, Shiyu Zhao, Peidong Liu|<http://arxiv.org/pdf/2411.08279v2>|[代码](https://github.com/WU-CVGL/MBA-SLAM.); 提出了一种针对运动模糊的MBA-SLAM方法，通过同时学习3D场景表示和估计相机轨迹，有效提升了SL...|
|📝 更新|TD3Net: A Temporal Densely Connected Multi-Dilated Convolutional Network for Lipreading|TD3Net：一种用于唇读的时序密集连接多膨胀卷积网络|Byung Hoon Lee, Wooseok Shin, Sung Won Han|<http://arxiv.org/pdf/2506.16073v2>|[代码](https://github.com/Leebh-kor/TD3Net-A-Temporal-Densely-Connected-Multi-dilated-Convolutional-Network-for-Lipreading); 提出了一种结合密集跳跃连接和多尺度扩张卷积的网络结构TD3Net，有效提升了唇读任务的准确性和效率。|
|🆕 发布|UW-3DGS: Underwater 3D Reconstruction with Physics-Aware Gaussian Splatting|水下三维重建：基于物理感知的高斯散点建模|Wenpeng Xing, Jie Chen, Zaifeng Yang, Changting Lin, Jianfeng Dong, Chaochao Chen, Xun Zhou, Meng Han|<http://arxiv.org/pdf/2508.06169v1>|提出了一种水下三维重建的新框架UW-3DGS，通过物理感知的高斯散射和不确定性修剪，有效提升了重建质...|
|🆕 发布|Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation|《眼球转动：通过显式三维眼球旋转实现视线重定向》|YoungChan Choi, HengFei Wang, YiHua Cheng, Boeun Kim, Hyung Jin Chang, YoungGeun Choi, Sang-Il Choi|<http://arxiv.org/pdf/2508.06136v1>|提出了一种利用显式3D眼球结构的 gaze 重定向框架，通过精确的眼球旋转和位移生成高质量图像。|
|🆕 发布|Neural Field Representations of Mobile Computational Photography|移动计算摄影的神经场表征|Ilya Chugunov|<http://arxiv.org/pdf/2508.05907v1>|提出利用精心设计的神经场模型直接从手机摄影数据中实现深度估计等应用，无需复杂预处理或标注数据。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Graph-based Robot Localization Using a Graph Neural Network with a Floor Camera and a Feature Rich Industrial Floor|基于图神经网络的机器人定位方法：利用地面相机和特征丰富的工业地面|Dominik Brämer, Diana Kleingarn, Oliver Urbann|<http://arxiv.org/pdf/2508.06177v1>|提出利用地面特征和图卷积网络进行机器人定位的新框架，实现高精度定位并解决机器人绑架问题。|
|🆕 发布|Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention|《遮蔽与匹配：使用自监督注意力学习识别手写数学公式》|Shree Mitra, Ritabrata Chakraborty, Nilkanta Sahu|<http://arxiv.org/pdf/2508.06107v1>|提出了一种无需标注数据，通过自监督学习和渐进式遮蔽策略训练的注意力网络，有效识别手写数学表达式。|
|📝 更新|Extending Foundational Monocular Depth Estimators to Fisheye Cameras with Calibration Tokens|将基础单目深度估计器扩展到鱼眼相机：使用校准标记物进行标定|Suchisrit Gangopadhyay, Jung-Hee Kim, Xien Chen, Patrick Rim, Hyoungseob Park, Alex Wong|<http://arxiv.org/pdf/2508.04928v2>|[代码](https://github.com/JungHeeKim29/calibration-token.); 提出了一种利用校准标记调整鱼眼相机图像分布的方法，使传统单目深度估计器直接适用于鱼眼相机。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|POMATO: Marrying Pointmap Matching with Temporal Motion for Dynamic 3D Reconstruction|POMATO：将点图匹配与时间运动结合进行动态三维重建|Songyan Zhang, Yongtao Ge, Jinyuan Tian, Guangkai Xu, Hao Chen, Chen Lv, Chunhua Shen|<http://arxiv.org/pdf/2504.05692v2>|[代码](https://github.com/wyddmw/POMATO.); 提出了一种结合点图匹配与时间运动信息的动态三维重建框架，有效提升了动态场景中的几何估计和目标跟踪性能...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ViPro-2: Unsupervised State Estimation via Integrated Dynamics for Guiding Video Prediction|ViPro-2：通过集成动力学进行无监督状态估计以指导视频预测|Patrick Takenaka, Johannes Maucher, Marco F. Huber|<http://arxiv.org/pdf/2508.06335v1>|提出了一种无需完整初始状态，通过集成动力学进行无监督状态估计的视频预测方法。|
|🆕 发布|Mixture of Experts Guided by Gaussian Splatters Matters: A new Approach to Weakly-Supervised Video Anomaly Detection|由高斯散点引导的专家混合至关重要：一种新的弱监督视频异常检测方法|Giacomo D'Amicantonio, Snehashis Majhi, Quan Kong, Lorenzo Garattoni, Gianpiero Francesca, François Bremond, Egor Bondarev|<http://arxiv.org/pdf/2508.06318v1>|提出了一种利用高斯散点引导的混合专家模型，通过类别特定专长和时序引导提升弱监督视频异常检测性能。|
|🆕 发布|Fast Motion Estimation and Context-Aware Refinement for Efficient Bayer-Domain Video Vision|快速运动估计与上下文感知细化以提高拜耳域视频视觉效率|Haichao Wang, Xinyue Xi, Jiangtao Wen, Yuxing Han|<http://arxiv.org/pdf/2508.05990v1>|提出了一种高效的无需图像信号处理器的视频视觉系统，通过快速块匹配运动估计和上下文感知细化显著提升效率...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ART: Adaptive Relation Tuning for Generalized Relation Prediction|自适应关系调整：用于泛化关系预测的方法|Gopika Sudhakaran, Hikaru Shindo, Patrick Schramowski, Simone Schaub-Meyer, Kristian Kersting, Stefan Roth|<http://arxiv.org/pdf/2507.23543v2>|提出了一种自适应关系调整框架ART，通过指令微调和策略性样本选择，提升视觉关系检测模型的泛化能力。|
|🆕 发布|MA-CBP: A Criminal Behavior Prediction Framework Based on Multi-Agent Asynchronous Collaboration|多智能体异步协作的犯罪行为预测框架：MA-CBP|Cheng Liu, Daou Zhang, Tingxu Liu, Yuhan Wang, Jinyang Chen, Yuexuan Li, Xinying Xiao, Chenbo Xin .etc.|<http://arxiv.org/pdf/2508.06189v1>|提出了一种基于多智能体异步协作的犯罪行为预测框架，有效融合实时视频流和历史信息，实现潜在犯罪活动的早...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|More Is Better: A MoE-Based Emotion Recognition Framework with Human Preference Alignment|更多即是更好：基于MoE的情感识别框架与人类偏好对齐|Jun Xie, Yingjian Zhu, Feng Chen, Zhenghao Zhang, Xiaohui Fan, Hongzhu Yi, Xinming Wang, Chen Yu .etc.|<http://arxiv.org/pdf/2508.06036v1>|[代码](https://github.com/zhuyjan/MER2025-MRAC25.); 提出了一种融合多模态信息的MoE情感识别框架，通过共识伪标签策略和偏好对齐提升了预测准确性和人类偏好...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CLIPin: A Non-contrastive Plug-in to CLIP for Multimodal Semantic Alignment|CLIPin：一种用于多模态语义对齐的无对比性插件式CLIP方法|Shengzhu Yang, Jiawei Du, Shuai Lu, Weihang Zhang, Ningli Wang, Huiqi Li|<http://arxiv.org/pdf/2508.06434v1>|[代码](https://github.com/T6Yang/CLIPin.); 提出CLIPin方法，通过非对比学习增强CLIP模型的多模态语义对齐能力，提升监督质量和对齐鲁棒性。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Feature-Space Oversampling for Addressing Class Imbalance in SAR Ship Classification|特征空间过采样用于解决合成孔径雷达船舶分类中的类别不平衡问题|Ch Muhammad Awais, Marco Reggiannini, Davide Moroni, Oktay Karakus|<http://arxiv.org/pdf/2508.06420v1>|提出两种特征空间过采样算法，有效解决SAR船舶分类中的数据不平衡问题，提升平均F1分数。|
|📝 更新|Building Age Estimation: A New Multi-Modal Benchmark Dataset and Community Challenge|建筑年代估计：一个新的多模态基准数据集和社区挑战|Nikolaos Dionelis, Alessandra Feliciotti, Mattia Marconcini, Devis Peressutti, Nika Oman Kadunc, JaeWan Park, Hagai Raja Sinulingga, Steve Andreas Immanuel .etc.|<http://arxiv.org/pdf/2502.13818v3>|提出MapYourCity多模态数据集，通过卫星和街景图像实现建筑年代估算，助力可持续城市规划。|
|🆕 发布|Street View Sociability: Interpretable Analysis of Urban Social Behavior Across 15 Cities|“街景社交性：跨15个城市城市社交行为的可解释性分析”|Kieran Elrod, Katherine Flanigan, Mario Bergés|<http://arxiv.org/pdf/2508.06342v1>|利用街景图像和语言模型分析城市社交行为，关联环境因素与社交质量。|
|📝 更新|CMIC: Content-Adaptive Mamba for Learned Image Compression|内容自适应曼巴：用于学习图像压缩的方法|Yunuo Chen, Zezheng Lyu, Bing He, Hongwei Hu, Qi Wang, Yuan Tian, Li Song, Wenjun Zhang .etc.|<http://arxiv.org/pdf/2508.02192v3>|引入内容自适应Mamba模型，优化了图像压缩的率失真性能，实现了更高效的全球依赖捕获。|
|📝 更新|Survival Modeling from Whole Slide Images via Patch-Level Graph Clustering and Mixture Density Experts|通过图像块级图聚类和混合密度专家从全切片图像进行生存建模|Ardhendu Sekhar, Vasu Soni, Keshav Aske, Garima Jain, Pranav Jeevan, Amit Sethi|<http://arxiv.org/pdf/2507.16476v2>|分类|
|🆕 发布|Lightweight Quad Bayer HybridEVS Demosaicing via State Space Augmented Cross-Attention|轻量级四拜耳混合EVS去马赛克算法：基于状态空间增强的交叉注意力机制|Shiyang Zhou, Haijin Zeng, Yunfan Lu, Yongyong Chen, Jie Liu, Jingyong Su|<http://arxiv.org/pdf/2508.06058v1>|提出了一种轻量级网络TSANet，通过分离处理事件像素修复和去马赛克任务，有效提升了HybridEV...|
|🆕 发布|LV-Net: Anatomy-aware lateral ventricle shape modeling with a case study on Alzheimer's disease, the Australian Imaging Biomarkers and Lifestyle flagship study of ageing|LV-Net：基于解剖意识的侧脑室形状建模及其在阿尔茨海默病研究中的应用——以澳大利亚成像生物标志物与生活方式旗舰研究中的老龄化研究为例|Wonjung Park, Suhyun Ahn, Jinah Park|<http://arxiv.org/pdf/2508.06055v1>|[代码](https://github.com/PWonjung/LV_Shape_Modeling.); 提出LV-Net框架，通过解剖感知模板变形提高脑室形状建模精度，助力阿尔茨海默病分析。|
|📝 更新|Trustworthy Pedestrian Trajectory Prediction via Pattern-Aware Interaction Modeling|通过模式感知交互建模的可靠行人轨迹预测|Kaiyuan Zhai, Juan Chen, Chao Wang, Zeyi Xu, Guoming Tang|<http://arxiv.org/pdf/2507.13397v2>|提出InSyn模型，通过显式捕捉行人互动模式提高轨迹预测的准确性和可靠性。|
|📝 更新|CF3: Compact and Fast 3D Feature Fields|CF3：紧凑且快速的三维特征场|Hyunjoon Lee, Joonkyu Min, Jaesik Park|<http://arxiv.org/pdf/2508.05254v2>|提出了一种高效的3D特征场构建方法CF3，通过融合2D特征和预训练高斯函数，实现特征场的紧凑表示和快...|
|🆕 发布|Enhancing Construction Site Analysis and Understanding with 3D Segmentation|利用三维分割增强建筑工地分析与理解|Sri Ramana Saketh Vasanthawada, Pengkun Liu, Pingbo Tang|<http://arxiv.org/pdf/2508.05922v1>|评估并改进3D分割模型在建筑工地监测中的应用，提升自动化与精确度。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FedMeNF: Privacy-Preserving Federated Meta-Learning for Neural Fields|联邦元学习用于神经场的隐私保护：FedMeNF|Junhyeog Yun, Minui Hong, Gunhee Kim|<http://arxiv.org/pdf/2508.06301v1>|提出了FedMeNF方法，通过隐私保护的损失函数实现联邦元学习，保护客户端数据隐私同时加快优化速度。|
|🆕 发布|DSConv: Dynamic Splitting Convolution for Pansharpening|动态分割卷积：用于全色锐化的DSConv|Xuanyu Liu, Bonan An|<http://arxiv.org/pdf/2508.06147v1>|提出动态分割卷积核策略DSConv，通过注意力机制优化遥感图像特征提取，提升 pansharpeni...|
|🆕 发布|FMCE-Net++: Feature Map Convergence Evaluation and Training|特征图收敛性评估与训练网络FMCE-Net++|Zhibo Zhu, Renyu Huang, Lei He|<http://arxiv.org/pdf/2508.06109v1>|提出FMCE-Net++训练框架，通过融合特征图收敛评分和任务标签，有效提升模型性能。|
|📝 更新|Localized Gaussians as Self-Attention Weights for Point Clouds Correspondence|点云对应中局部高斯函数作为自注意力权重的应用|Alessandro Riva, Alessandro Raganato, Simone Melzi|<http://arxiv.org/pdf/2409.13291v2>|将高斯函数作为固定注意力权重应用于点云匹配，加快训练速度并增强优化稳定性。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Study of Gender Classification Techniques Based on Iris Images: A Deep Survey and Analysis|基于虹膜图像的性别分类技术研究：深度调研与分析|Basna Mohammed Salih Hasan, Ramadhan J. Mstafa|<http://arxiv.org/pdf/2508.05246v2>|系统分析了基于虹膜图像的性别分类技术，揭示了现有方法的优缺点及未来改进方向。|
|🆕 发布|Can Large Models Fool the Eye? A New Turing Test for Biological Animation|大型模型能欺骗人眼吗？一种生物动画的新图灵测试|Zijian Chen, Lirong Deng, Zhengyu Chen, Kaiwei Zhang, Qi Jia, Yuan Tian, Yucheng Zhu, Guangtao Zhai|<http://arxiv.org/pdf/2508.06072v1>|提出BioMotion Arena框架，通过视觉动画评估大型模型性能，揭示模型在生物运动模拟上的不足...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TRUST: Leveraging Text Robustness for Unsupervised Domain Adaptation|TRUST：利用文本鲁棒性进行无监督领域自适应|Mattia Litrico, Mario Valerio Giuffrida, Sebastiano Battiato, Devis Tuia|<http://arxiv.org/pdf/2508.06452v1>|利用文本稳健性引导视觉模型适应复杂领域迁移，提出了一种新的无监督领域自适应方法TRUST。|
|🆕 发布|ETA: Energy-based Test-time Adaptation for Depth Completion|基于能量的测试时适应法用于深度补全|Younjoon Chung, Hyoungseob Park, Patrick Rim, Xiaoran Zhang, Jihe He, Ziyao Zeng, Safa Cicek, Byung-Woo Hong .etc.|<http://arxiv.org/pdf/2508.05989v1>|[代码](https://fuzzythecat.github.io/eta.); 提出了一种测试时自适应方法，通过能量模型优化预训练深度补全模型，有效应对数据分布偏移问题。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation|《通用机器人策略中的捷径学习：数据集多样性和碎片化的作用》|Youguang Xing, Xu Luo, Junlin Xie, Lianli Gao, Hengtao Shen, Jingkuan Song|<http://arxiv.org/pdf/2508.06426v1>|[代码](https://lucky-light-sun.github.io/proj); 揭示了数据集多样性和碎片化对通用机器人策略泛化能力的影响，并提出相应数据收集和增强策略以减少捷径学习...|
|📝 更新|Rethinking the Bias of Foundation Model under Long-tailed Distribution|重新思考基础模型在长尾分布下的偏置问题|Jiahao Chen, Bin Qin, Jiangmeng Li, Hao Chen, Bing Su|<http://arxiv.org/pdf/2501.15955v3>|[代码](https://github.com/JiahaoChen1/Pre-train-Imbalance); 揭示了基础模型在长尾分布下的偏差，并提出了一种基于因果学习的方法同时解决参数与数据不平衡问题。|
|📝 更新|SPA++: Generalized Graph Spectral Alignment for Versatile Domain Adaptation|SPA++：广义图谱对齐用于多功能的领域自适应|Zhiqing Xiao, Haobo Wang, Xu Lu, Wentao Ye, Gang Chen, Junbo Zhao|<http://arxiv.org/pdf/2508.05182v2>|提出了一种图谱对齐框架SPA++，通过粗粒度图对齐和细粒度邻居感知传播，有效平衡了域自适应中的迁移性...|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Uncertainty-quantified Rollout Policy Adaptation for Unlabelled Cross-domain Temporal Grounding|不确定性量化的无标签跨域时序定位滚动策略自适应|Jian Hu, Zixu Cheng, Shaogang Gong, Isabel Guan, Jianye Hao, Jun Wang, Kun Shao|<http://arxiv.org/pdf/2508.06317v1>|提出了一种无需标注数据的跨域视频时间定位方法，通过不确定性量化的策略适应实现实时高效的模型迁移。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Crop Pest Classification Using Deep Learning Techniques: A Review|基于深度学习技术的农作物害虫分类研究综述|Muhammad Hassam Ejaz, Muhammad Bilal, Usman Habib, Muhammad Attique, Tae-Sun Chung|<http://arxiv.org/pdf/2507.01494v3>|概述了深度学习在作物害虫分类中的应用进展，强调了向混合和基于变体的模型转变以提升准确性和理解能力。|
|📝 更新|Two-stage deep learning framework for the restoration of incomplete-ring PET images|双阶段深度学习框架用于不完整环形PET图像的重建|Yeqi Fang, Rong Zhou|<http://arxiv.org/pdf/2504.00816v4>|提出两阶段深度学习框架，有效恢复不完整环状PET图像，提升图像质量和处理速度。|
|📝 更新|X-VFL: A New Vertical Federated Learning Framework with Cross Completion and Decision Subspace Alignment|X-VFL：一种具有交叉补全与决策子空间对齐的新垂直联邦学习框架|Qinghua Yao, Xiangrui Xu, Zhize Li|<http://arxiv.org/pdf/2508.05568v2>|提出X-VFL框架，通过特征补全和决策子空间对齐解决垂直联邦学习中数据样本不齐和局部独立推理问题。|
|🆕 发布|Interpretable Rheumatoid Arthritis Scoring via Anatomy-aware Multiple Instance Learning|通过解剖感知的多实例学习实现的类风湿关节炎可解释评分|Zhiyan Bo, Laura C. Coates, Bartlomiej W. Papiez|<http://arxiv.org/pdf/2508.06218v1>|提出了一种基于解剖感知的多实例学习方法，用于可解释的风湿性关节炎评分，达到与经验丰富的放射科医生相当...|
|🆕 发布|Learning Representations of Satellite Images with Evaluations on Synoptic Weather Events|卫星图像表征学习及其在天气形势事件评估中的应用|Ting-Shuo Yo, Shih-Hao Su, Chien-Ming Wu, Wei-Ting Chen, Jung-Lien Chu, Chiao-Wei Chang, Hung-Chi Kuo|<http://arxiv.org/pdf/2508.06122v1>|探究了卫星图像表示学习算法，发现卷积自动编码器在天气事件分类中表现最优。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Text as Any-Modality for Zero-Shot Classification by Consistent Prompt Tuning|文本作为任意模态的零样本分类方法：通过一致性提示调谐|Xiangyu Wu, Feng Yu, Yang Yang, Jianfeng Lu|<http://arxiv.org/pdf/2508.06382v1>|[代码](https://github.com/Jinx630/TaAM-CPT.); 提出了一种仅使用文本数据构建通用表示模型的TaAM-CPT方法，实现了跨模态零样本分类的领先性能。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Embodied Intelligence for 3D Understanding: A Survey on 3D Scene Question Answering|三维理解中的具身智能：三维场景问答研究综述|Zechuan Li, Hongshan Yu, Yihao Ding, Yan Li, Yong He, Naveed Akhtar|<http://arxiv.org/pdf/2502.00342v2>|系统综述了3D场景问答领域，提出了统一评价协议等未来研究方向。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CANVAS: Commonsense-Aware Navigation System for Intuitive Human-Robot Interaction|CANVAS：具有常识感知的导航系统，实现直观的人机交互|Suhwan Choi, Yongjun Cho, Minchan Kim, Jaeyoon Jung, Myunchul Joe, Yubeen Park, Minseo Kim, Sungwoong Kim .etc.|<http://arxiv.org/pdf/2410.01273v3>|提出CANVAS框架，融合视觉与语言指令，实现符合人类直觉的机器人导航。|


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PASG: A Closed-Loop Framework for Automated Geometric Primitive Extraction and Semantic Anchoring in Robotic Manipulation|PASG：一种用于机器人操作中自动几何基元提取和语义锚定的闭环框架|Zhihao Zhu, Yifan Zheng, Siyu Pan, Yaohui Jin, Yao Mu|<http://arxiv.org/pdf/2508.05976v1>|提出了一种自动提取几何基元并进行语义定位的闭环框架，有效桥接了机器人操作中的任务语义与低级几何特征。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LoRA in LoRA: Towards Parameter-Efficient Architecture Expansion for Continual Visual Instruction Tuning|《LoRA中的LoRA：面向持续视觉指令微调的参数高效架构扩展》|Chang Che, Ziqi Wang, Pengwan Yang, Qi Wang, Hui Ma, Zenglin Shi|<http://arxiv.org/pdf/2508.06202v1>|提出了一种高效架构扩展方法LiLoRA，通过共享参数和低秩分解减少冗余，有效解决了持续视觉指令微调中...|
|📝 更新|DAVSP: Safety Alignment for Large Vision-Language Models via Deep Aligned Visual Safety Prompt|DAVSP：通过深度对齐视觉安全提示实现大型视觉-语言模型的安全对齐|Yitong Zhang, Jia Li, Liyi Cai, Ge Li|<http://arxiv.org/pdf/2506.09353v2>|[代码](https://github.com/zhangyitonggg/DAVSP.); 提出DAVSP方法，通过视觉安全提示和深度对齐训练，增强大型视觉语言模型对恶意查询的抵抗力。|
|🆕 发布|MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models|数学真实：我们保持真实！一种用于评估多模态大型语言模型中数学推理能力的真实场景基准|Jun Feng, Zixin Wang, Zhentao Zhang, Yue Guo, Zhihan Zhou, Xiuyi Chen, Zhenyang Li, Dawei Yin|<http://arxiv.org/pdf/2508.06009v1>|[代码](https://github.com/junfeng0288/MathReal.); 提出MathReal数据集，评估大型多模态语言模型在真实场景下的数学推理能力。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MCA: 2D-3D Retrieval with Noisy Labels via Multi-level Adaptive Correction and Alignment|多级自适应校正与对齐的带噪声标签的2D-3D检索：MCA方法|Gui Zou, Chaofan Gan, Chern Hong Lim, Supavadee Aramvith, Weiyao Lin|<http://arxiv.org/pdf/2508.06104v1>|提出了一种用于2D-3D检索的MCA框架，通过多级自适应校正和校准处理噪声标签问题，实现可靠的标签修...|
|🆕 发布|Q-CLIP: Unleashing the Power of Vision-Language Models for Video Quality Assessment through Unified Cross-Modal Adaptation|Q-CLIP：通过统一跨模态适配释放视觉-语言模型在视频质量评估中的力量|Yachun Mi, Yu Li, Yanting Li, Shixin Sun, Chen Hui, Tong Zhang, Yuanyuan Liu, Chenyue Song .etc.|<http://arxiv.org/pdf/2508.06092v1>|提出首个基于视觉语言模型的视频质量评估框架Q-CLIP，通过跨模态适配器降低计算成本并增强质量感知能...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Conditional Diffusion Models are Medical Image Classifiers that Provide Explainability and Uncertainty for Free|条件扩散模型是医学图像分类器，能够免费提供可解释性和不确定性|Gian Mario Favero, Parham Saremi, Emily Kaczmarek, Brennan Nichyporuk, Tal Arbel|<http://arxiv.org/pdf/2502.03687v2>|[代码](https://faverogian.github.io/med-diffusion-classifier.github.io); 首次探索条件扩散模型在2D医疗图像分类中的应用，实现竞争性性能并提供自解释性和不确定性量化。|
|🆕 发布|SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation|稀疏数据，丰富结果：通过类别条件图像转换实现少样本半监督学习|Guido Manni, Clemente Lauretti, Loredana Zollo, Paolo Soda|<http://arxiv.org/pdf/2508.06429v1>|[代码](https://github.com/GuidoManni/SPARSE.); 提出了一种针对少量标注数据的医学影像半监督学习方法，通过图像翻译和集成伪标签技术显著提升了分类性能。|
|🆕 发布|A Classification-Aware Super-Resolution Framework for Ship Targets in SAR Imagery|面向合成孔径雷达图像中船舶目标分类的感知分类超分辨率框架|Ch Muhammad Awais, Marco Reggiannini, Davide Moroni, Oktay Karakus|<http://arxiv.org/pdf/2508.06407v1>|提出了一种集成分类目标的超分辨率框架，通过优化损失函数同时提升合成孔径雷达图像质量和分类精度。|
|📝 更新|Soft Dice Confidence: A Near-Optimal Confidence Estimator for Selective Prediction in Semantic Segmentation|软Dice置信度：用于语义分割中选择性预测的近似最优置信度估计器|Bruno Laboissiere Camargos Borges, Bruno Machado Pacheco, Danilo Silva|<http://arxiv.org/pdf/2402.10665v4>|提出Soft Dice Confidence方法，为语义分割中的选择性预测提供近最优置信度估计。|
|📝 更新|Your other Left! Vision-Language Models Fail to Identify Relative Positions in Medical Images|“你的另一个左侧！视觉语言模型在识别医学图像中的相对位置时失败”|Daniel Wolf, Heiko Hillenhagen, Billurvan Taskin, Alex Bäuerle, Meinrad Beer, Michael Götz, Timo Ropinski|<http://arxiv.org/pdf/2508.00549v2>|发现现有视觉语言模型在识别医学图像中解剖结构相对位置上的不足，并提出了视觉提示方法及专用评估数据集。|
|📝 更新|Advancing Welding Defect Detection in Maritime Operations via Adapt-WeldNet and Defect Detection Interpretability Analysis|通过Adapt-WeldNet和缺陷检测可解释性分析提升海上作业焊接缺陷检测|Kamal Basha S, Athira Nambiar|<http://arxiv.org/pdf/2508.00381v2>|提出自适应框架Adapt-WeldNet优化焊接缺陷检测，并通过Defect Detection I...|
|📝 更新|CPT-Interp: Continuous sPatial and Temporal Motion Modeling for 4D Medical Image Interpolation|CPT-Interp：四维医学图像插值的连续空间与时间运动建模|Xia Li, Runzhao Yang, Xiangtai Li, Antony Lomax, Ye Zhang, Joachim Buhmann|<http://arxiv.org/pdf/2405.15385v2>|提出了一种基于流体力学原理的连续时空运动建模方法，实现了高效准确的4D医疗图像插值。|
|🆕 发布|A Semantic Segmentation Algorithm for Pleural Effusion Based on DBIF-AUNet|基于DBIF-AUNet的胸水语义分割算法|Ruixiang Tang, Jianglong Qin, Mingda Zhang, Yan Song, Yi Wu, Wei Wu|<http://arxiv.org/pdf/2508.06191v1>|提出DBIF-AUNet算法，通过双分支交互融合注意力和特征解耦，提高了复杂肺积液CT图像的分割准确...|
|🆕 发布|Clinically-guided Data Synthesis for Laryngeal Lesion Detection|临床指导的数据合成在喉部病变检测中的应用|Chiara Baldini, Kaisar Kushibar, Richard Osuala, Simone Balocco, Oliver Diaz, Karim Lekadir, Leonardo S. Mattos|<http://arxiv.org/pdf/2508.06182v1>|利用临床观察指导的生成模型，有效解决喉部病变检测数据稀缺问题，提升病变检测准确率。|
|🆕 发布|Transformer-Based Explainable Deep Learning for Breast Cancer Detection in Mammography: The MammoFormer Framework|基于Transformer的可解释深度学习在乳腺X线摄影中用于乳腺癌检测：MammoFormer框架|Ojonugwa Oluwafemi Ejiga Peter, Daniel Emakporuena, Bamidele Dayo Tunde, Maryam Abdulkarim, Abdullahi Bn Umar|<http://arxiv.org/pdf/2508.06137v1>|提出MammoFormer框架，结合Transformer架构与多特征增强及可解释AI，提升乳腺摄影...|
|🆕 发布|Improved Sub-Visible Particle Classification in Flow Imaging Microscopy via Generative AI-Based Image Synthesis|基于生成式人工智能图像合成的流成像显微镜下亚可见粒子分类改进|Utku Ozbulak, Michaela Cohrs, Hristo L. Svilenov, Joris Vankerschaver, Wesley De Neve|<http://arxiv.org/pdf/2508.06021v1>|[代码](https://github.com/utkuozbulak/svp-generative-ai.); 利用生成式AI模型生成高质量图像，有效解决数据不平衡问题，提升亚可见粒子分类准确性。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|WildSAT: Learning Satellite Image Representations from Wildlife Observations|《WildSAT：从野生动物观测中学习卫星图像表征》|Rangel Daroya, Elijah Cole, Oisin Mac Aodha, Grant Van Horn, Subhransu Maji|<http://arxiv.org/pdf/2412.14428v2>|提出利用野生动物观测数据学习卫星图像表征，通过对比学习提升图像识别性能并实现零样本检索。|
|📝 更新|SAR Strikes Back: A New Hope for RSVQA|合成孔径雷达反击：远程敏感视觉问答的新希望|Lucrezia Tosato, Flora Weissgerber, Laurent Wendling, Sylvain Lobry|<http://arxiv.org/pdf/2501.08131v2>|提出融合策略将合成孔径雷达图像与光学图像结合，显著提升遥感视觉问答任务的准确率。|
|🆕 发布|FedX: Explanation-Guided Pruning for Communication-Efficient Federated Learning in Remote Sensing|FedX：远程感知中通信高效联邦学习的解释引导剪枝|Barış Büyüktaş, Jonas Klotz, Begüm Demir|<http://arxiv.org/pdf/2508.06256v1>|提出了一种基于解释引导的剪枝策略FedX，通过减少模型参数传输降低联邦学习中的通信负担。|
|🆕 发布|TEFormer: Texture-Aware and Edge-Guided Transformer for Semantic Segmentation of Urban Remote Sensing Images|TEFormer：面向城市遥感图像语义分割的纹理感知与边缘引导的Transformer模型|Guoyu Zhou, Jing Zhang, Yi Yan, Hui Zhang, Li Zhuo|<http://arxiv.org/pdf/2508.06224v1>|提出了一种结合纹理感知和边缘引导的Transformer模型，有效提升了城市遥感图像的语义分割精度。|
|🆕 发布|An Interpretable Multi-Plane Fusion Framework With Kolmogorov-Arnold Network Guided Attention Enhancement for Alzheimer's Disease Diagnosis|具有科尔莫哥洛夫-阿尔诺德网络引导注意力增强的可解释多平面融合框架用于阿尔茨海默病诊断|Xiaoxiao Yang, Meiliang Liu, Yunfang Xu, Zijin Li, Zhengye Si, Xinyue Yang, Zhiwen Zhao|<http://arxiv.org/pdf/2508.06157v1>|提出了一种多平面融合框架，结合科尔莫哥洛夫-阿诺德网络引导的注意力增强，用于阿尔茨海默病诊断，提高了...|
|🆕 发布|GMF-Drive: Gated Mamba Fusion with Spatial-Aware BEV Representation for End-to-End Autonomous Driving|GMF-Drive：具有空间感知BEV表示的门控Mamba融合端到端自动驾驶|Jian Wang, Chaokang Jiang, Haitao Xu|<http://arxiv.org/pdf/2508.06113v1>|提出了一种高效的GMF-Drive框架，通过几何增强的柱状表示和空间感知的状态空间模型，提升了自动驾...|
|📝 更新|Dome-DETR: DETR with Density-Oriented Feature-Query Manipulation for Efficient Tiny Object Detection|圆顶DETR：具有密度导向特征查询操作的高效小目标检测DETR|Zhangchi Hu, Peixi Wu, Jie Chen, Huyue Zhu, Yijun Wang, Yansong Peng, Hebei Li, Xiaoyan Sun|<http://arxiv.org/pdf/2505.05741v2>|[代码](https://github.com/RicePasteM/Dome-DETR.); 提出Dome-DETR，通过密度导向的特征查询调整优化小目标检测，提升性能同时降低计算复杂度。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AnomalyMoE: Towards a Language-free Generalist Model for Unified Visual Anomaly Detection|《AnomalyMoE：迈向无语言限制的通用模型以实现统一视觉异常检测》|Zhaopeng Gu, Bingke Zhu, Guibo Zhu, Yingying Chen, Wei Ge, Ming Tang, Jinqiao Wang|<http://arxiv.org/pdf/2508.06203v1>|提出了一种通用视觉异常检测框架AnomalyMoE，通过分解为三个语义层次，实现了跨领域的高效异常检...|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|InterAct-Video: Reasoning-Rich Video QA for Urban Traffic|《InterAct-Video：面向城市交通的富推理视频问答》|Joseph Raj Vishal, Rutuja Patil, Manas Srinivas Gowda, Katha Naik, Yezhou Yang, Bharatesh Chakravarthi|<http://arxiv.org/pdf/2507.14743v2>|[代码](https://github.com/joe-rabbit/InterAct_VideoQA); 提出InterAct VideoQA数据集，提升了视频问答模型在处理复杂交通场景的能力。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Calibration Tool for Refractive Underwater Vision|折射水下视觉校准工具|Felix Seegräber, Mengkun She, Felix Woelk, Kevin Köser|<http://arxiv.org/pdf/2405.18018v2>|开发了首个开源水下折射相机校准工具箱，实现了包括相机、立体和外壳在内的端到端校准。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Direct Robot Configuration Space Construction using Convolutional Encoder-Decoders|使用卷积编码器-解码器直接构建机器人配置空间|Christopher Benka, Judah Goldfeder, Carl Gross, Riya Gupta, Hod Lipson|<http://arxiv.org/pdf/2303.05653v2>|首次使用卷积编码器-解码器框架精确构建机器人配置空间，实现高效实时运动规划。|
|📝 更新|A dataset of primary nasopharyngeal carcinoma MRI with multi-modalities segmentation|一种基于多模态分割的初诊鼻咽癌MRI数据集|Yin Li, Qi Chen, Kai Wang, Meige Li, Liping Si, Yingwei Guo, Yu Xiong, Qixing Wang .etc.|<http://arxiv.org/pdf/2404.03253v3>|介绍了首个全面的鼻咽癌MRI数据集，助力早期诊断和治疗规划。|

