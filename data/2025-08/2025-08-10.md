## [UPDATED!] **2025-08-10** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MathScape: Benchmarking Multimodal Large Language Models in Real-World Mathematical Contexts|数学景观：在现实世界数学背景下对多模态大型语言模型进行基准测试|Hao Liang, Linzhuang Sun, Minxuan Zhou, Zirong Chen, Meiyi Qiang, Mingan Lin, Tianpeng Li, Fan Yang .etc.|<http://arxiv.org/pdf/2408.07543v5>|提出MathScape基准，评估大型多模态语言模型在真实世界数学场景中的推理能力。|
|📝 更新|MusiXQA: Advancing Visual Music Understanding in Multimodal Large Language Models|音乐视觉理解：在多模态大型语言模型中推进视觉音乐理解|Jian Chen, Wenye Ma, Penghang Liu, Wei Wang, Tengwei Song, Ming Li, Chenguang Wang, Jiayu Qin .etc.|<http://arxiv.org/pdf/2506.23009v2>|提出了MusiXQA，首个用于评估和提升大型多模态语言模型在乐谱理解能力的综合数据集，并开发了Phi...|
|📝 更新|Interpreting the linear structure of vision-language model embedding spaces|解读视觉语言模型嵌入空间的线性结构|Isabel Papadimitriou, Huangyuan Su, Thomas Fel, Sham Kakade, Stephanie Gil|<http://arxiv.org/pdf/2504.11695v3>|揭示了视觉语言模型嵌入空间的稀疏线性结构，通过潜在桥梁促进跨模态语义融合。|
|📝 更新|Engagement Prediction of Short Videos with Large Multimodal Models|短视频与大规模多模态模型参与度预测|Wei Sun, Linhan Cao, Yuqin Cao, Weixia Zhang, Wen Wen, Kaiwei Zhang, Zijian Chen, Fangfang Lu .etc.|<http://arxiv.org/pdf/2508.02516v2>|[代码](https://github.com/sunwei925/LMM-EVQA.git.); 探究大型多模态模型在短视频互动预测中的应用，以音频特征增强预测准确性。|
|🆕 发布|MobileViCLIP: An Efficient Video-Text Model for Mobile Devices|移动端高效视频-文本模型：MobileViCLIP|Min Yang, Zihan Jia, Zhilin Dai, Sheng Guo, Limin Wang|<http://arxiv.org/pdf/2508.07312v1>|[代码](https://github.com/MCG-NJU/MobileViCLIP.); 提出了一种适用于移动设备的轻量级视频文本模型MobileViCLIP，实现了快速推理和强大的零样本分...|
|📝 更新|VFM-UDA++: Improving Network Architectures and Data Strategies for Unsupervised Domain Adaptive Semantic Segmentation|无监督域自适应语义分割中网络架构和数据策略的改进：VFM-UDA++|Brunó B. Englert, Gijs Dubbelman|<http://arxiv.org/pdf/2503.10685v2>|提出VFM-UDA++方法，通过优化网络架构和数据策略，提升了无监督领域自适应语义分割的性能。|
|📝 更新|MQuant: Unleashing the Inference Potential of Multimodal Large Language Models via Full Static Quantization|MQuant：通过完全静态量化释放多模态大型语言模型的推理潜力|JiangYong Yu, Sifan Zhou, Dawei Yang, Shuo Wang, Shuoyu Li, Xing Hu, Chen Xu, Zukang Xu .etc.|<http://arxiv.org/pdf/2502.00425v2>|[代码](https://github.com/StiphyJay/MQuant.); 提出MQuant框架，通过模态特定量化等方法优化多模态大语言模型推理性能，显著降低延迟并保持高准确度...|
|🆕 发布|Dynamic Pattern Alignment Learning for Pretraining Lightweight Human-Centric Vision Models|动态模式对齐学习：用于预训练轻量级以人为中心的视觉模型|Xuanhan Wang, Huimin Deng, Ke Liu, Jun Wang, Lianli Gao, Jingkuan Song|<http://arxiv.org/pdf/2508.07144v1>|提出了一种基于动态模式对齐的轻量级人类视觉模型预训练框架，有效缩小了大小模型间的泛化差距。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MCITlib: Multimodal Continual Instruction Tuning Library and Benchmark|MCITlib：多模态持续指令微调库与基准|Haiyang Guo, Fei Zhu, Hongbo Zhao, Fanhu Zeng, Wenzhuo Liu, Shijie Ma, Da-Han Wang, Xu-Yao Zhang|<http://arxiv.org/pdf/2508.07307v1>|[代码](https://github.com/Ghy0501/MCITlib.); 提出MCITlib库，支持多模态大型语言模型在持续学习中的指令微调，包含八种算法和两个评估基准。|
|🆕 发布|Representation Understanding via Activation Maximization|通过激活最大化实现表征理解|Hongbo Zhu, Angelo Cangelosi|<http://arxiv.org/pdf/2508.07281v1>|提出统一特征可视化框架，深入探索深度神经网络中间层特征，增强模型可解释性。|
|📝 更新|Multimodal Deception in Explainable AI: Concept-Level Backdoor Attacks on Concept Bottleneck Models|多模态可解释人工智能中的欺骗：概念级后门攻击对概念瓶颈模型的攻击|Songning Lai, Jiayu Yang, Yu Huang, Lijie Hu, Tianlang Xue, Zhangyi Hu, Jiaxu Li, Haicheng Liao .etc.|<http://arxiv.org/pdf/2410.04823v2>|提出针对可解释AI系统的新型概念级后门攻击方法，有效注入触发器而不影响正常性能。|
|🆕 发布|Intention-Aware Diffusion Model for Pedestrian Trajectory Prediction|意图感知的行人轨迹预测扩散模型|Yu Liu, Zhijie Liu, Xiao Ren, You-Fu Li, He Kong|<http://arxiv.org/pdf/2508.07146v1>|提出了一种融合短期和长期运动意图的扩散模型，提高了行人轨迹预测的准确性。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BEVANet: Bilateral Efficient Visual Attention Network for Real-Time Semantic Segmentation|BEVANet：用于实时语义分割的双向高效视觉注意力网络|Ping-Mao Huang, I-Tien Chao, Ping-Chia Huang, Jia-Wei Liao, Yung-Yu Chuang|<http://arxiv.org/pdf/2508.07300v1>|[代码](https://github.com/maomao0819/BEVANet.); 提出了一种结合大核注意力和双边架构的实时语义分割网络，通过动态调整接收场和边界引导融合，实现了高效准...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FunGraph: Functionality Aware 3D Scene Graphs for Language-Prompted Scene Interaction|功能感知的语言提示场景交互三维场景图：FunGraph|Dennis Rotondi, Fabio Scaparro, Hermann Blum, Kai O. Arras|<http://arxiv.org/pdf/2503.07909v2>|提出了一种细粒度3D场景图表示方法，使机器人能够识别并理解环境中的功能交互元素。|
|🆕 发布|ForensicsSAM: Toward Robust and Unified Image Forgery Detection and Localization Resisting to Adversarial Attack|法医SAM：面向对抗攻击下的鲁棒统一图像伪造检测与定位|Rongxuan Peng, Shunquan Tan, Chenqi Kong, Anwei Luo, Alex C. Kot, Jiwu Huang|<http://arxiv.org/pdf/2508.07402v1>|[代码](https://github.com/siriusPRX/ForensicsSAM.); 提出ForensicsSAM框架，增强图像伪造检测与定位的对抗攻击鲁棒性。|
|📝 更新|Unbiased Region-Language Alignment for Open-Vocabulary Dense Prediction|无偏区域-语言对齐的开词汇密集预测|Yunheng Li, Yuxuan Li, Quansheng Zeng, Wenhai Wang, Qibin Hou, Ming-Ming Cheng|<http://arxiv.org/pdf/2412.06244v3>|[代码](https://github.com/HVision-NKU/DenseVLM.); 提出DenseVLM框架，通过学习无偏见的区域-语言对齐，改善视觉语言模型在密集预测任务中的性能。|
|🆕 发布|EventRR: Event Referential Reasoning for Referring Video Object Segmentation|事件指引用理推理用于视频目标分割的EventRR|Huihui Xu, Jiashi Lin, Haoyu Chen, Junjun He, Lei Zhu|<http://arxiv.org/pdf/2508.07171v1>|[代码](https://github.com/bio-mlhui/EventRR); 提出EventRR框架，通过事件引用推理和对象总结分离，提升视频对象分割的准确性和效率。|
|🆕 发布|Lightweight Multi-Scale Feature Extraction with Fully Connected LMF Layer for Salient Object Detection|轻量级多尺度特征提取：使用全连接LMF层进行显著目标检测|Yunpeng Shi, Lei Chen, Xiaolu Shen, Yanju Guo|<http://arxiv.org/pdf/2508.07170v1>|[代码](https://github.com/Shi-Yun-peng/LMFNet); 提出了一种轻量级多尺度特征提取层LMF，通过深度可分离膨胀卷积实现高效显著物体检测。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Dynamic Robot-Assisted Surgery with Hierarchical Class-Incremental Semantic Segmentation|动态机器人辅助手术中的分层类别增量语义分割|Julia Hindel, Ema Mekic, Enamundram Naga Karthik, Rohit Mohan, Daniele Cattaneo, Maria Kalweit, Abhinav Valada|<http://arxiv.org/pdf/2508.01713v2>|提出了一种针对动态机器人辅助手术环境的层级类别增量语义分割方法，有效应对手术场景中的动态变化和类别增...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EA-KD: Entropy-based Adaptive Knowledge Distillation|基于熵的自适应知识蒸馏EA-KD|Chi-Ping Su, Ching-Hsun Tseng, Bin Pu, Lei Zhao, Jiewen Yang, Zhuangzhuang Chen, Shin-Jye Lee|<http://arxiv.org/pdf/2311.13621v3>|[代码](https://github.com/cpsu00/EA-KD); 提出了一种基于熵的自适应知识蒸馏方法，通过重视价值样本提升学习效率，实现了更优的性能。|
|📝 更新|Self-Navigated Residual Mamba for Universal Industrial Anomaly Detection|自导航残差蟒蛇网络用于通用工业异常检测|Hanxi Li, Jingqi Wu, Lin Yuanbo Wu, Mingliang Li, Deyin Liu, Jialie Shen, Chunhua Shen|<http://arxiv.org/pdf/2508.01591v2>|定位工业异常检测，提出SNARM框架，通过自参考学习动态增强异常辨识能力。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Less is More: Skim Transformer for Light Field Image Super-resolution|“少即是多：轻量级光场图像超分辨率的光场Transformer”|Zeke Zexi Hu, Haodong Chen, Hui Ye, Xiaoming Chen, Vera Yuk Ying Chung, Yiran Shen, Weidong Cai|<http://arxiv.org/pdf/2407.15329v2>|提出了一种针对光场图像超分辨率任务的Skim Transformer，通过选择性地关注关键视差范围，...|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding|“VisR-Bench：多语言长文档理解中视觉检索增强生成的实证研究”|Jian Chen, Ming Li, Jihyung Kil, Chenguang Wang, Tong Yu, Ryan Rossi, Tianyi Zhou, Changyou Chen .etc.|<http://arxiv.org/pdf/2508.07493v1>|提出VisR-Bench多语言长文档视觉检索基准，提升多模态检索细粒度评估能力。|
|📝 更新|LoRA.rar: Learning to Merge LoRAs via Hypernetworks for Subject-Style Conditioned Image Generation|《LoRA.rar：通过超网络学习合并LoRAs实现主题风格条件图像生成》|Donald Shenaj, Ondrej Bohdal, Mete Ozay, Pietro Zanuttigh, Umberto Michieli|<http://arxiv.org/pdf/2412.05148v2>|提出了一种高效合并低秩适配器的方法，通过预训练超网络实现快速个性化图像生成。|
|🆕 发布|CoAR: Concept Injection into Autoregressive Models for Personalized Text-to-Image Generation|概念注入自回归模型以实现个性化文本到图像生成：CoAR|Fangtai Wu, Mushui Liu, Weijie He, Wanggui He, Hao Jiang, Zhao Wang, Yunlong Yu|<http://arxiv.org/pdf/2508.07341v1>|[代码](https://github.com/KZF-kzf/CoAR); 提出了CoAR框架，通过最小参数调整将用户概念注入预训练的统一自回归模型，实现高效个性化文本到图像生...|
|🆕 发布|RORPCap: Retrieval-based Objects and Relations Prompt for Image Captioning|基于检索的对象与关系提示的图像标注方法：RORPCap|Jinjing Gu, Tianbao Qin, Yuanyuan Pu, Zhengpeng Zhao|<http://arxiv.org/pdf/2508.07318v1>|提出了一种基于图像-文本检索的图像描述生成方法RORPCap，通过提取对象和关系词并融入预定义模板，...|
|📝 更新|FROSS: Faster-than-Real-Time Online 3D Semantic Scene Graph Generation from RGB-D Images|FROSS：从RGB-D图像实现实时更快的在线三维语义场景图生成|Hao-Yu Hou, Chun-Yi Lee, Motoharu Sonogashira, Yasutomo Kawanishi|<http://arxiv.org/pdf/2507.19993v2>|[代码](https://github.com/Howardkhh/FROSS.); 提出FROSS方法，实现实时3D场景图生成，提升速度并减少计算依赖。|
|📝 更新|FancyVideo: Towards Dynamic and Consistent Video Generation via Cross-frame Textual Guidance|《FancyVideo：通过跨帧文本引导实现动态一致的视频生成》|Jiasong Feng, Ao Ma, Jing Wang, Ke Cao, Zhanjie Zhang|<http://arxiv.org/pdf/2408.08189v3>|提出了一种创新的视频生成方法FancyVideo，通过跨帧文本引导模块增强文本控制，实现了动态且一致...|
|🆕 发布|Consistent and Controllable Image Animation with Motion Linear Diffusion Transformers|具有一致性和可控性的图像动画：运动线性扩散变换器|Xin Ma, Yaohui Wang, Genyun Jia, Xinyuan Chen, Tien-Tsin Wong, Cunjian Chen|<http://arxiv.org/pdf/2508.07246v1>|提出MiraMo框架，通过线性注意力、运动残差学习和噪声细化策略，实现高效、一致且平滑的图像动画生成...|
|📝 更新|LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer|层追踪器：通过扩散变换器实现与认知对齐的分层SVG合成|Yiren Song, Danze Chen, Mike Zheng Shou|<http://arxiv.org/pdf/2502.01105v2>|提出LayerTracer框架，通过模拟设计师创作过程生成高质量、易编辑的分层SVG图像。|
|🆕 发布|HaDM-ST: Histology-Assisted Differential Modeling for Spatial Transcriptomics Generation|辅助组织学差异建模用于空间转录组学生成的HaDM-ST方法|Xuepeng Liu, Zheng Jiang, Pinan Zhu, Hanyu Liu, Chao Li|<http://arxiv.org/pdf/2508.07225v1>|提出HaDM-ST框架，利用H&E图像和低分辨率ST数据生成高分辨率的空间转录组，提升了空间精确度和...|
|🆕 发布|Large-scale Multi-sequence Pretraining for Generalizable MRI Analysis in Versatile Clinical Applications|大规模多序列预训练以实现多变的临床应用中通用性磁共振成像分析|Zelin Qiu, Xi Wang, Zhuoyao Xie, Juan Zhou, Yu Wang, Lingjie Yang, Xinrui Jiang, Juyoung Bae .etc.|<http://arxiv.org/pdf/2508.07165v1>|提出了一种大规模多序列MRI预训练模型PRISM，有效提升了跨不同成像协议的泛化性能。|
|📝 更新|BadPatch: Diffusion-Based Generation of Physical Adversarial Patches|BadPatch：基于扩散的物理对抗性补丁生成|Zhixiang Wang, Xingjun Ma, Yu-Gang Jiang|<http://arxiv.org/pdf/2412.01440v5>|提出BadPatch框架，通过扩散模型生成自然且可定制的对抗性补丁，平衡攻击效果与隐蔽性。|
|🆕 发布|CoopDiff: Anticipating 3D Human-object Interactions via Contact-consistent Decoupled Diffusion|通过接触一致性解耦扩散预测三维人-物交互的CoopDiff方法|Xiaotong Lin, Tianming Liang, Jian-Fang Hu, Kun-Yu Lin, Yulei Kang, Chunwei Tian, Jianhuang Lai, Wei-Shi Zheng|<http://arxiv.org/pdf/2508.07162v1>|定位人类与物体运动差异，提出CoopDiff框架，分模块预测，提升3D人-物交互预测准确度。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|When Cars Have Stereotypes: Auditing Demographic Bias in Objects from Text-to-Image Models|当汽车拥有刻板印象：在文本到图像模型的对象中审查人口统计偏见|Dasol Choi, Jihwan Lee, Minjae Lee, Minsuk Kahng|<http://arxiv.org/pdf/2508.03483v2>|提出SODA框架，系统测量生成对象中的 demographic 偏见，揭示并测试了AI模型中的视觉属...|
|🆕 发布|CLUE: Leveraging Low-Rank Adaptation to Capture Latent Uncovered Evidence for Image Forgery Localization|CLUE: 利用低秩适应捕获潜在未揭露证据进行图像伪造定位|Youqi Wang, Shunquan Tan, Rongxuan Peng, Bin Li, Jiwu Huang|<http://arxiv.org/pdf/2508.07413v1>|[代码](https://github.com/SZAISEC/CLUE.); 提出CLUE框架，利用低秩适应技术高效转换文本到图像模型为图像伪造定位工具，显著提升检测性能。|
|📝 更新|TSPO: Temporal Sampling Policy Optimization for Long-form Video Language Understanding|TSPO：长视频语言理解的时间采样策略优化|Canhui Tang, Zifan Han, Hongbo Sun, Sanping Zhou, Xuchong Zhang, Xin Wei, Ye Yuan, Huayu Zhang .etc.|<http://arxiv.org/pdf/2508.04369v3>|[代码](https://github.com/Hui-design/TSPO); 提出了一种基于强化学习的视频采样策略优化方法，有效提升了长视频语言理解能力。|
|🆕 发布|DIP-GS: Deep Image Prior For Gaussian Splatting Sparse View Recovery|DIP-GS：用于高斯散点稀疏视图恢复的深度图像先验|Rajaei Khatib, Raja Giryes|<http://arxiv.org/pdf/2508.07372v1>|提出DIP-GS方法，利用深度图像先验改进3D高斯散点场景重建，在稀疏视角下实现高质量重建。|
|📝 更新|Speckle2Self: Self-Supervised Ultrasound Speckle Reduction Without Clean Data|Speckle2Self: 无需干净数据监督的超声散斑减少方法|Xuesong Li, Nassir Navab, Zhongliang Jiang|<http://arxiv.org/pdf/2507.06828v2>|[代码](https://noseefood.github.io/us-speckle2self); 提出了一种无需干净数据，基于单次噪声观测的自监督超声散斑降噪方法Speckle2Self。|
|🆕 发布|SODiff: Semantic-Oriented Diffusion Model for JPEG Compression Artifacts Removal|面向语义的扩散模型SODiff：用于JPEG压缩伪影去除|Tingyu Yang, Jue Gong, Jinpei Guo, Wenbo Li, Yong Guo, Yulun Zhang|<http://arxiv.org/pdf/2508.07346v1>|[代码](https://github.com/frakenation/SODiff); 提出了一种语义导向的扩散模型SODiff，有效去除JPEG压缩伪影并恢复复杂纹理细节。|
|📝 更新|Efficient Face Image Quality Assessment via Self-training and Knowledge Distillation|通过自训练和知识蒸馏进行高效人脸图像质量评估|Wei Sun, Weixia Zhang, Linhan Cao, Jun Jia, Xiangyang Zhu, Dandan Zhu, Xiongkuo Min, Guangtao Zhai|<http://arxiv.org/pdf/2507.15709v2>|[代码](https://github.com/sunwei925/Efficient-FIQA.git.); 提出了一种结合自训练和知识蒸馏的高效人脸图像质量评估方法，实现了与教师模型相当的性能，同时大幅降低了...|
|🆕 发布|DocR1: Evidence Page-Guided GRPO for Multi-Page Document Understanding|多页文档理解中的证据页面引导的GRPO方法|Junyu Xiong, Yonghui Wang, Weichao Zhao, Chenyu Liu, Bing Yin, Wengang Zhou, Houqiang Li|<http://arxiv.org/pdf/2508.07313v1>|提出了一种基于强化学习的多页文档理解框架，通过粗到细的证据引导推理策略，提高了多页文档的解析性能。|
|📝 更新|HiGarment: Cross-modal Harmony Based Diffusion Model for Flat Sketch to Realistic Garment Image|HiGarment：基于跨模态和谐性的扩散模型，用于平面草图到真实服装图像的转换|Junyi Guo, Jingxuan Zhang, Fangyu Wu, Huanda Lu, Qiufeng Wang, Wenmian Yang, Eng Gee Lim, Dongming Lu|<http://arxiv.org/pdf/2505.23186v2>|[代码](https://github.com/Maple498/HiGarment.); 提出FS2RG任务，并通过HiGarment框架融合文本和视觉信息生成逼真服装图像。|
|📝 更新|Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned Concepts|《元-遗忘在扩散模型中的应用：防止重学习已遗忘概念》|Hongcheng Gao, Tianyu Pang, Chao Du, Taihang Hu, Zhijie Deng, Min Lin|<http://arxiv.org/pdf/2410.12777v2>|[代码](https://github.com/sail-sg/Meta-Unlearning.); 提出了一种元学习策略防止扩散模型在恶意微调后重新学习已移除的概念。|
|🆕 发布|Small-Large Collaboration: Training-efficient Concept Personalization for Large VLM using a Meta Personalized Small VLM|小-大协作：使用元个性化小视觉语言模型对大型视觉语言模型进行高效训练的概念个性化|Sihan Yang, Huitong Ji, Shaolin Lu, Jiayi Chen, Binxiao Xu, Ming Lu, Yuanxing Zhang, Wenhui Dong .etc.|<http://arxiv.org/pdf/2508.07260v1>|[代码](https://github.com/Hhankyangg/SLC.); 提出了一种高效的框架，通过小模型生成个性化信息，大模型整合这些信息，实现了对大型视觉语言模型的低成本...|
|📝 更新|DuoCast: Duo-Probabilistic Diffusion for Precipitation Nowcasting|双概率扩散模型DuoCast：用于降水预报|Penghui Wen, Mengwei He, Patrick Filippi, Na Zhao, Feng Zhang, Thomas Francis Bishop, Zhiyong Wang, Kun Hu|<http://arxiv.org/pdf/2412.01091v3>|提出DuoCast模型，通过分解低频和高频分量，提高了降水预测的准确性和细节表现。|
|🆕 发布|SketchAnimator: Animate Sketch via Motion Customization of Text-to-Video Diffusion Models|“SketchAnimator：通过文本到视频扩散模型的运动定制实现草图动画化”|Ruolin Yang, Da Li, Honggang Zhang, Yi-Zhe Song|<http://arxiv.org/pdf/2508.07149v1>|提出了一种利用文本到视频扩散模型实现草图动画化的新方法，简化了动画制作过程。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Simple Radiology VLLM Test-time Scaling with Thought Graph Traversal|简单的放射学VLLM测试时间扩展与思维图遍历|Yue Yao, Zelin Wen, Yan Tong, Xinyu Tian, Xuqing Li, Xiao Ma, Dongliang Xu, Tom Gedeon|<http://arxiv.org/pdf/2506.11989v2>|[代码](https://github.com/glerium/Thought-Graph-Traversal.); 提出了一种通过Thought Graph Traversal框架引导模型进行医学逻辑推理的测试时扩展...|
|🆕 发布|Generic Calibration: Pose Ambiguity/Linear Solution and Parametric-hybrid Pipeline|通用校准：位姿模糊性/线性解及参数-混合管道|Yuqi Han, Qi Cai, Yuanxin Wu|<http://arxiv.org/pdf/2508.07217v1>|提出了一种解决通用校准方法中位姿模糊问题的线性求解器和全局优化混合校准方法。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bridging Semantic Logic Gaps: A Cognition-Inspired Multimodal Boundary-Preserving Network for Image Manipulation Localization|桥接语义逻辑间隙：一种认知启发式多模态边界保持网络用于图像操作定位|Songlin Li, Zhiqing Guo, Yuanman Li, Zeyu Li, Yunfeng Diao, Gaobo Yang, Liejun Wang|<http://arxiv.org/pdf/2508.07216v1>|提出了一种认知启发式多模态边界保持网络，通过结合大语言模型和图像特征交互，有效补偿图像操纵中的语义逻...|
|🆕 发布|Similarity Matters: A Novel Depth-guided Network for Image Restoration and A New Dataset|相似性至关重要：一种新颖的深度引导网络用于图像恢复及一个新的数据集|Junyi He, Liuling Chen, Hongyang Zhou, Zhang xiaoxing, Xiaobin Zhu, Shengxiang Yu, Jingyan Qin, Xu-Cheng Yin|<http://arxiv.org/pdf/2508.07211v1>|提出深度引导网络以利用深度信息提升图像修复质量，并引入大规模高分辨率图像数据集。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|NeRF: Neural Radiance Field in 3D Vision: A Comprehensive Review (Updated Post-Gaussian Splatting)|神经辐射场在三维视觉中：全面回顾（高斯散点更新后）|Kyle Gao, Yina Gao, Hongjie He, Dening Lu, Linlin Xu, Jonathan Li|<http://arxiv.org/pdf/2210.00379v7>|系统梳理了NeRF在计算机视觉领域的应用与发展，对比了其与传统方法及后继技术Gaussian Spl...|
|📝 更新|SVarM: Linear Support Varifold Machines for Classification and Regression on Geometric Data|线性支持Varifold机：用于几何数据分类和回归的SVarM|Emmanuel Hartman, Nicolas Charon|<http://arxiv.org/pdf/2506.01189v2>|提出SVarM方法，利用形状的varifold表示，实现了适用于非欧几里得形状空间的分类与回归。|
|📝 更新|NEXT: Multi-Grained Mixture of Experts via Text-Modulation for Multi-Modal Object Re-Identification|NEXT：通过文本调制实现多粒度专家混合的多模态目标重识别|Shihao Li, Aihua Zheng, Andong Lu, Jin Tang, Jixin Ma|<http://arxiv.org/pdf/2505.20001v4>|提出NEXT框架，通过文本调制多粒度专家模型，有效提升多模态目标重识别准确性。|
|📝 更新|Spatio-Temporal Representation Decoupling and Enhancement for Federated Instrument Segmentation in Surgical Videos|手术视频中联邦器械分割的时空表示解耦与增强|Zheng Fang, Xiaoming Qi, Chun-Mei Feng, Jialun Pei, Weixin Si, Yueming Jin|<http://arxiv.org/pdf/2506.23759v2>|提出个性化联邦学习方案FedST，通过时空表示解耦与增强，提升手术器械分割准确性和适应性。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LET-US: Long Event-Text Understanding of Scenes|LET-US：场景的长事件文本理解|Rui Chen, Xingyu Chen, Shaoan Wang, Shihan Kong, Junzhi Yu|<http://arxiv.org/pdf/2508.07401v1>|提出了一种长事件流与文本理解的框架LET-US，通过自适应压缩和两阶段优化，有效桥接事件流与文本的模...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Learning Multi-view Anomaly Detection with Efficient Adaptive Selection|学习基于高效自适应选择的多视角异常检测|Haoyang He, Jiangning Zhang, Guanzhong Tian, Chengjie Wang, Lei Xie|<http://arxiv.org/pdf/2407.11935v2>|[代码](https://github.com/lewandofskee/MVAD.); 提出了一种多视角异常检测方法，通过自适应选择融合多视角特征，提升了检测准确性和效率。|
|🆕 发布|GS4Buildings: Prior-Guided Gaussian Splatting for 3D Building Reconstruction|GS4Buildings：基于先验引导的高斯散点法用于三维建筑重建|Qilin Zhang, Olaf Wysocki, Boris Jutzi|<http://arxiv.org/pdf/2508.07355v1>|[代码](https://github.com/zqlin0521/GS4Buildings.); 提出了一种利用语义3D建筑模型引导的Gaussian Splatting方法，显著提升了城市建筑表面...|
|📝 更新|QuickSplat: Fast 3D Surface Reconstruction via Learned Gaussian Initialization|快速散点法：通过学习高斯初始化实现快速三维表面重建|Yueh-Cheng Liu, Lukas Höllein, Matthias Nießner, Angela Dai|<http://arxiv.org/pdf/2505.05591v2>|QuickSplat通过学习数据驱动先验加速了三维表面重建，提高了优化收敛速度和几何建模精度。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Scene Summarization: Clustering Scene Videos into Spatially Diverse Frames|场景摘要：将场景视频聚类为空间上多样化的帧|Chao Chen, Mingzhi Zhu, Ankush Pratap Singh, Yu Yan, Felix Juefei Xu, Chen Feng|<http://arxiv.org/pdf/2311.17940v2>|提出场景摘要任务，通过两阶段自监督流程将长视频压缩为空间多样化的关键帧集。|
|📝 更新|EF-VI: Enhancing End-Frame Injection for Video Inbetweening|EF-VI：增强末端帧注入以实现视频插帧|Liuhan Chen, Xiaodong Cun, Xiaoyu Li, Xianyi He, Shenghai Yuan, Jie Chen, Ying Shan, Li Yuan|<http://arxiv.org/pdf/2505.21205v2>|提出EF-VI框架，通过增强注入策略提升视频插帧的末帧约束力，实现更优性能。|
|📝 更新|Learning 3D-Gaussian Simulators from RGB Videos|从RGB视频学习三维高斯模拟器|Mikel Zhobro, Andreas René Geist, Georg Martius|<http://arxiv.org/pdf/2503.24009v2>|提出了一种从多视角RGB视频直接学习物理交互的3D模拟器，统一了场景重建、粒子动力学预测和视频合成。|
|📝 更新|Alignment-free Raw Video Demoireing|无需对齐的原始视频去摩尔纹处理|Shuning Xu, Xina Liu, Binbin Song, Xiangyu Chen, Qiubo Chen, Jiantao Zhou|<http://arxiv.org/pdf/2408.10679v3>|提出了一种无需对齐的原始视频去摩尔纹方法，通过频率辅助的时空Mamba网络提升了去摩尔纹性能并保持了...|
|🆕 发布|Understanding Dynamic Scenes in Ego Centric 4D Point Clouds|理解以自我为中心的4D点云中的动态场景|Junsheng Huang, Shengyu Hao, Bocheng Hu, Gaoang Wang|<http://arxiv.org/pdf/2508.07251v1>|提出EgoDynamic4D基准，整合动态场景的4D数据与推理任务，提出端到端时空推理框架，提升 e...|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|When Trackers Date Fish: A Benchmark and Framework for Underwater Multiple Fish Tracking|当追踪器与鱼儿“约会”：水下多鱼追踪的基准与框架|Weiran Li, Yeqiang Liu, Qiannan Guo, Yijie Wei, Hwa Liang Leo, Zhenbo Li|<http://arxiv.org/pdf/2507.06400v2>|[代码](https://vranlee.github.io/SU-T); 提出了首个水下多鱼追踪专用数据集MFT25及Scale-aware and Unscented Tr...|
|🆕 发布|Planner-Refiner: Dynamic Space-Time Refinement for Vision-Language Alignment in Videos|规划-细化：视频中视觉-语言对齐的动态时空细化|Tuyen Tran, Thao Minh Le, Quang-Hung Le, Truyen Tran|<http://arxiv.org/pdf/2508.07330v1>|提出Planner-Refiner框架，通过语言指导的视觉元素迭代细化，有效解决视频与语言语义对齐的...|
|🆕 发布|SUIT: Spatial-Spectral Union-Intersection Interaction Network for Hyperspectral Object Tracking|SUIT：用于高光谱目标跟踪的空间-光谱联合-交集交互网络|Fengchao Xiong, Zhenxing Wu, Sen Jia, Yuntao Qian|<http://arxiv.org/pdf/2508.07250v1>|[代码](https://github.com/bearshng/suit); 提出了一种融合空间与光谱交互作用的长距离跟踪网络，提升了复杂场景下的目标跟踪性能。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SPRMamba: Surgical Phase Recognition for Endoscopic Submucosal Dissection with Mamba|SPRMamba：使用Mamba进行内镜下黏膜剥离手术阶段识别|Xiangning Zhang, Qingwei Zhang, Jinnan Chen, Chengfeng Zhou, Yaqi Wang, Zhengjie Zhang, Xiaobo Li, Dahong Qian|<http://arxiv.org/pdf/2409.12108v3>|[代码](https://github.com/Zxnyyyyy/SPRMamba.); 提出SPRMamba框架，结合Mamba架构与SRTM块，优化了内镜下手术阶段识别的实时性与准确性。|
|📝 更新|Zero-shot Compositional Action Recognition with Neural Logic Constraints|零样本组合动作识别与神经逻辑约束|Gefan Ye, Lin Li, Kexin Li, Jun Xiao, Long Chen|<http://arxiv.org/pdf/2508.02320v2>|提出逻辑驱动的零样本组合动作识别框架LogicCAR，通过显式建模组合和层次结构抽象解决现有挑战。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|On Representation Learning with Feedback|《带有反馈的表征学习研究》|Hao Li|<http://arxiv.org/pdf/2202.07572v3>|阐述了反馈机制在表示学习中的作用，为单张图像去雨技术提供了理论解释。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FormCoach: Lift Smarter, Not Harder|FormCoach：更智能地举重，而非更努力地举重|Xiaoye Zuo, Nikos Athanasiou, Ginger Delmas, Yiming Huang, Xingyu Fu, Lingjie Liu|<http://arxiv.org/pdf/2508.07501v1>|FormCoach利用视觉语言模型将普通摄像头转变为实时互动的AI训练伙伴，帮助健身爱好者纠正动作姿...|
|🆕 发布|Novel View Synthesis with Gaussian Splatting: Impact on Photogrammetry Model Accuracy and Resolution|高斯散点绘制的新型视角合成：对摄影测量模型精度和分辨率的影响|Pranav Chougule|<http://arxiv.org/pdf/2508.07483v1>|[代码](https://github.com/pranavc2255/gaussian-splatting-novel-view-render.git.); 本研究通过改进高斯散点技术，有效提升了三维模型重建和新型视角生成的质量和精度。|
|📝 更新|Dual-domain Modulation Network for Lightweight Image Super-Resolution|双域调制网络用于轻量级图像超分辨率|Wenjie Li, Heng Guo, Yuefeng Hou, Guangwei Gao, Zhanyu Ma|<http://arxiv.org/pdf/2503.10047v2>|[代码](https://github.com/24wenjie-li/DMNet); 提出了一种融合小波和傅里叶信息的双域调制网络，实现了高效轻量级的图像超分辨率重建。|
|🆕 发布|AgriVLN: Vision-and-Language Navigation for Agricultural Robots|农业视觉与语言导航：面向农业机器人的视觉与语言导航|Xiaobei Zhao, Xingqi Lyu, Xiang Li|<http://arxiv.org/pdf/2508.07406v1>|提出AgriVLN方法，使农业机器人能根据自然语言指令在农业环境中导航，提升成功率至47%。|
|🆕 发布|Unsupervised Real-World Super-Resolution via Rectified Flow Degradation Modelling|基于校正流退化模型的无监督真实世界超分辨率|Hongyang Zhou, Xiaobin Zhu, Liuling Chen, Junyi He, Jingyan Qin, Xu-Cheng Yin, Zhang xiaoxing|<http://arxiv.org/pdf/2508.07214v1>|提出了一种无监督真实世界超分辨率方法，通过修正流模型捕捉实际退化，生成更真实的低分辨率图像训练对。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Unveiling the Potential of iMarkers: Invisible Fiducial Markers for Advanced Robotics|揭示iMarkers的潜力：用于先进机器人学的隐形基准标记|Ali Tourani, Deniz Isinsu Avsar, Hriday Bavle, Jose Luis Sanchez-Lopez, Jan Lagerwall, Holger Voos|<http://arxiv.org/pdf/2501.15505v4>|提出了一种隐形标记技术iMarkers，使机器人能在不干扰视觉美观的前提下实现精准定位与识别。|
|🆕 发布|Fading the Digital Ink: A Universal Black-Box Attack Framework for 3DGS Watermarking Systems|消褪数字墨水：一种针对3DGS水印系统的通用黑盒攻击框架|Qingyuan Zeng, Shu Jiang, Jiajing Lin, Zhenzhong Wang, Kay Chen Tan, Min Jiang|<http://arxiv.org/pdf/2508.07263v1>|提出了一种通用黑盒攻击框架GMEA，有效移除3DGS数字水印，同时保持视觉质量。|
|📝 更新|Less is More: Token-Efficient Video-QA via Adaptive Frame-Pruning and Semantic Graph Integration|少即是多：通过自适应帧剪枝和语义图集成的低标记效率视频问答|Shaoguang Wang, Jianxiang He, Yijie Xu, Ziyang Chen, Weiyu Guo, Hui Xiong|<http://arxiv.org/pdf/2508.03337v3>|提出了一种自适应帧剪枝和语义图集成方法，大幅降低了视频问答所需的帧数和输入令牌，同时提高准确率。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Extracting Overlapping Microservices from Monolithic Code via Deep Semantic Embeddings and Graph Neural Network-Based Soft Clustering|通过深度语义嵌入和基于图神经网络软聚类的单体代码中提取重叠微服务|Morteza Ziabakhsh, Kiyan Rezaee, Sadegh Eskandari, Seyed Amir Hossein Tabatabaei, Mohammad M. Ghassemi|<http://arxiv.org/pdf/2508.07486v1>|提出软聚类框架Mo2oM，利用深度语义嵌入和图神经网络从单体代码提取重叠微服务，提升模块性和降低通信...|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Training and Inference within 1 Second -- Tackle Cross-Sensor Degradation of Real-World Pansharpening with Efficient Residual Feature Tailoring|在1秒内完成训练与推理——利用高效残差特征剪裁应对实际场景全色锐化的跨传感器退化问题|Tianyu Xin, Jin-Liang Xiao, Zeyu Xia, Shan Yin, Liang-Jian Deng|<http://arxiv.org/pdf/2508.07369v1>|提出了一种高效的特征调整方法，实现了跨传感器 pansharpening 的快速训练与推理，显著提升...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Robustness to Geographic Distribution Shift Using Location Encoders|使用位置编码器应对地理分布偏移的鲁棒性|Ruth Crasto|<http://arxiv.org/pdf/2503.02036v2>|[代码](https://github.com/crastoru/wilds-geoshift.); 提出使用位置编码器建模连续可学习的域分配，有效应对地理分布偏移问题，实现遥感数据集上的新最佳性能。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Health Care Waste Classification Using Deep Learning Aligned with Nepal's Bin Color Guidelines|基于深度学习的医疗废物分类方法，符合尼泊尔垃圾桶颜色指南|Suman Kunwar, Prabesh Rai|<http://arxiv.org/pdf/2508.07450v1>|提出基于深度学习的医疗废物分类方法，符合尼泊尔垃圾桶颜色规范，实现95.06%准确率。|
|🆕 发布|Levarging Learning Bias for Noisy Anomaly Detection|利用学习偏差进行噪声异常检测|Yuxin Zhang, Yunkang Cao, Yuqi Cheng, Yihan Sun, Weiming Shen|<http://arxiv.org/pdf/2508.07441v1>|[代码](https://github.com/hustzhangyuxin/LLBNAD.); 提出两阶段框架利用学习偏差进行异常检测，有效应对含噪声的训练数据问题。|
|🆕 发布|OpenHAIV: A Framework Towards Practical Open-World Learning|面向实用开放式世界学习的OpenHAIV框架|Xiang Xiang, Qinhao Zhou, Zhuo Xu, Jing Ma, Jiaxin Dai, Yifan Liang, Hanlin Li|<http://arxiv.org/pdf/2508.07270v1>|[代码](https://haiv-lab.github.io/openhaiv); 提出OpenHAIV框架，整合OOD检测、新类发现与增量学习，实现开放世界环境下的自主知识获取与更新...|
|📝 更新|CARP: Visuomotor Policy Learning via Coarse-to-Fine Autoregressive Prediction|CARP：通过粗到细自回归预测的视觉运动策略学习|Zhefei Gong, Pengxiang Ding, Shangke Lyu, Siteng Huang, Mingyang Sun, Wei Zhao, Zhaoxin Fan, Donglin Wang|<http://arxiv.org/pdf/2412.06782v3>|提出了一种分阶段细化的自回归策略学习方法，实现了高效准确的机器人动作生成。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CharacterShot: Controllable and Consistent 4D Character Animation|角色镜头：可控且一致的4D角色动画|Junyao Gao, Jiaxing Li, Wenran Liu, Yanhong Zeng, Fei Shen, Kai Chen, Yanan Sun, Cairong Zhao|<http://arxiv.org/pdf/2508.07409v1>|[代码](https://github.com/Jeoyal/CharacterShot.); 提出CharacterShot框架，通过单张参考图像和2D姿态序列生成动态3D角色动画。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Semantic Mapping in Indoor Embodied AI -- A Survey on Advances, Challenges, and Future Directions|室内具身人工智能中的语义映射——进展、挑战与未来方向综述|Sonia Raychaudhuri, Angel X. Chang|<http://arxiv.org/pdf/2501.05750v3>|系统梳理了室内环境中智能体构建语义地图的方法，指出开放词汇、可查询、任务无关的地图表示是发展趋势。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AURA: A Fine-Grained Benchmark and Decomposed Metric for Audio-Visual Reasoning|AURA：一种用于音频视觉推理的细粒度基准和分解度量|Siminfar Samakoush Galougah, Rishie Raj, Sanjoy Chowdhury, Sayan Nag, Ramani Duraiswami|<http://arxiv.org/pdf/2508.07470v1>|提出音频视觉推理基准AURA及AuraScore评估法，揭示模型逻辑推理缺陷。|
|📝 更新|Deep Neural Networks Can Learn Generalizable Same-Different Visual Relations|深度神经网络能够学习普适性的同异视觉关系|Alexa R. Tartaglini, Sheridan Feucht, Michael A. Lepori, Wai Keen Vong, Charles Lovering, Brenden M. Lake, Ellie Pavlick|<http://arxiv.org/pdf/2310.09612v2>|证明了深度神经网络能够学习并在不同分布上泛化“相同-不同”的视觉关系。|
|🆕 发布|KLASSify to Verify: Audio-Visual Deepfake Detection Using SSL-based Audio and Handcrafted Visual Features|基于SSL的音频和手工视觉特征的KLASSify验证：音频-视觉深度伪造检测|Ivan Kukanov, Jun Wah Ng|<http://arxiv.org/pdf/2508.07337v1>|提出了一种结合自监督学习和手工艺视觉特征的多模态方法，有效提高了深伪检测的鲁棒性和可解释性。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Landmark Guided Visual Feature Extractor for Visual Speech Recognition with Limited Resource|基于地标引导的视觉特征提取器用于资源受限的视觉语音识别|Lei Yang, Junshan Jin, Mingyuan Zhang, Yi He, Bofan Chen, Shilin Wang|<http://arxiv.org/pdf/2508.07233v1>|提出了一种基于面部标志的视觉特征提取方法，以少量数据提升视觉语音识别的准确性和鲁棒性。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Fractured Glass, Failing Cameras: Simulating Physics-Based Adversarial Samples for Autonomous Driving Systems|破碎的玻璃，失效的相机：为自动驾驶系统模拟基于物理的对抗样本|Manav Prabhakar, Jwalandhar Girnar, Arpan Kusari|<http://arxiv.org/pdf/2405.15033v2>|提出物理故障导致的摄像头损坏模拟方法，生成现实物理对抗样本以评估自动驾驶系统安全性。|
|📝 更新|Unleashing the Potential of Large Language Models for Text-to-Image Generation through Autoregressive Representation Alignment|通过自回归表示对齐释放大型语言模型在文本到图像生成中的潜力|Xing Xie, Jiawei Liu, Ziyue Lin, Huijie Fan, Zhi Han, Yandong Tang, Liangqiong Qu|<http://arxiv.org/pdf/2503.07334v3>|[代码](https://github.com/xiexing0916/ARRA.); 提出了一种无需修改原始架构的自动回归表示对齐方法，实现了全局一致的文本到图像生成。|
|📝 更新|DS$^2$Net: Detail-Semantic Deep Supervision Network for Medical Image Segmentation|DS$^2$Net：用于医学图像分割的细节-语义深度监督网络|Zhaohong Huang, Yuxin Zhang, Taojian Zhou, Guorong Cai, Rongrong Ji|<http://arxiv.org/pdf/2508.04131v2>|提出了一种多视角深度监督网络DS$^2$Net，通过结合细粒度细节和粗粒度语义特征监督，提升了医疗图...|
|🆕 发布|DragonFruitQualityNet: A Lightweight Convolutional Neural Network for Real-Time Dragon Fruit Quality Inspection on Mobile Devices|龙眼质量检测轻量级卷积神经网络：面向移动设备实时检测|Md Zahurul Haquea, Yeahyea Sarker, Muhammed Farhan Sadique Mahi, Syed Jubayer Jaman, Md Robiul Islam|<http://arxiv.org/pdf/2508.07306v1>|提出轻量级CNN模型DragonFruitQualityNet，实现移动设备上实时检测火龙果质量。|
|🆕 发布|SynMatch: Rethinking Consistency in Medical Image Segmentation with Sparse Annotations|SynMatch：在稀疏注释下重新思考医学图像分割的一致性|Zhiqiang Shen, Peng Cao, Xiaoli Liu, Jinzhu Yang, Osmar R. Zaiane|<http://arxiv.org/pdf/2508.07298v1>|[代码](https://github.com/Senyh/SynMatch.); 提出SynMatch框架，通过合成匹配图像而非改进伪标签来解决医学图像分割中的标注稀缺问题。|
|📝 更新|Advancing AI-Powered Medical Image Synthesis: Insights from MedVQA-GI Challenge Using CLIP, Fine-Tuned Stable Diffusion, and Dream-Booth + LoRA|推进人工智能驱动的医学图像合成：基于MedVQA-GI挑战的CLIP、微调稳定扩散和Dream-Booth + LoRA的洞察|Ojonugwa Oluwafemi Ejiga Peter, Md Mahmudur Rahman, Fahmi Khalifa|<http://arxiv.org/pdf/2502.20667v2>|提出了一种基于文本描述生成高质量医疗图像的新方法，融合了细调的生成模型和低秩适应技术。|
|🆕 发布|ASM-UNet: Adaptive Scan Mamba Integrating Group Commonalities and Individual Variations for Fine-Grained Segmentation|ASM-UNet：自适应扫描蟒蛇融合群体共性和个体差异进行细粒度分割|Bo Wang, Mengyuan Xu, Yue Yan, Yuqun Yang, Kechen Shu, Wei Ping, Xu Tang, Wei Jiang .etc.|<http://arxiv.org/pdf/2508.07237v1>|[代码](https://github.com/YqunYang/ASM-UNet.); 提出ASM-UNet模型，通过自适应扫描分数动态调整扫描顺序，有效结合群体共性和个体差异，提升精细结...|
|🆕 发布|Perceptual Evaluation of GANs and Diffusion Models for Generating X-rays|《生成X射线的生成对抗网络和扩散模型知觉评估》|Gregory Schuit, Denis Parra, Cecilia Besa|<http://arxiv.org/pdf/2508.07128v1>|评估了GANs和扩散模型生成X射线图像的效果，指出了各自优缺点及对AI诊断系统的潜在影响。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|From Time-series Generation, Model Selection to Transfer Learning: A Comparative Review of Pixel-wise Approaches for Large-scale Crop Mapping|从时间序列生成、模型选择到迁移学习：大规模作物制图像素级方法的比较综述|Judy Long, Tao Liu, Sean Alexander Woznicki, Miljana Marković, Oskar Marko, Molly Sears|<http://arxiv.org/pdf/2507.12590v2>|系统评估了像素级作物映射方法，发现细粒度预处理与Transformer模型表现最优。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Co-VisiON: Co-Visibility ReasONing on Sparse Image Sets of Indoor Scenes|室内场景稀疏图像集上的共可视推理：Co-VisiON|Chao Chen, Nobel Dang, Juexiao Zhang, Wenkai Sun, Pengfei Zheng, Xuhang He, Yimeng Ye, Jiasheng Zhang .etc.|<http://arxiv.org/pdf/2506.16805v3>|[代码](https://ai4ce.github.io/CoVISION.); 提出Co-VisiON基准，并设计了Covis模型，提升稀疏室内场景共视性推理性能。|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Freeze and Reveal: Exposing Modality Bias in Vision-Language Models|“冻结与揭示：在视觉-语言模型中暴露模态偏见”|Vivek Hruday Kavuri, Vysishtya Karanam, Venkata Jahnavi Venkamsetty, Kriti Madumadukala, Lakshmipathi Balaji Darur, Ponnurangam Kumaraguru|<http://arxiv.org/pdf/2508.07432v1>|提出新方法DAUDoS减少视觉语言模型中的性别偏见，实验显示视觉编码器偏见更明显。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Confidence-Based Annotation Of Brain Tumours In Ultrasound|基于置信度的超声脑肿瘤标注|Alistair Weld, Luke Dixon, Alfie Roddan, Giulio Anichini, Sophie Camp, Stamatia Giannarou|<http://arxiv.org/pdf/2502.15484v2>|提出了一种基于置信度的脑肿瘤超声图像标注方法，减少了标注的主观性并提高了观察者间的一致性。|
|🆕 发布|CMAMRNet: A Contextual Mask-Aware Network Enhancing Mural Restoration Through Comprehensive Mask Guidance|CMAMRNet：一种通过综合掩码引导增强壁画修复的上下文掩码感知网络|Yingtie Lei, Fanghai Yi, Yihang Dong, Weihuang Liu, Xiaofeng Zhang, Zimeng Li, Chi-Man Pun, Xuhang Chen|<http://arxiv.org/pdf/2508.07140v1>|[代码](https://github.com/CXH-Research/CMAMRNet); 提出CMAMRNet网络，通过全面遮罩引导和多尺度特征提取，有效提升壁画修复质量和细节保留。|

