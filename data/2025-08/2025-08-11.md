## [UPDATED!] **2025-08-11** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning User Preferences for Image Generation Model|学习用户偏好以优化图像生成模型|Wenyi Mo, Ying Ba, Tianyu Zhang, Yalong Bai, Biye Li|<http://arxiv.org/pdf/2508.08220v1>|提出了一种基于多模态大语言模型的个性化用户偏好学习方法，有效区分用户喜好并生成符合个人风格的图像。|
|🆕 发布|TBAC-UniImage: Unified Understanding and Generation by Ladder-Side Diffusion Tuning|TBAC-UniImage：通过梯边扩散调整实现统一理解与生成|Junzhe Xu, Yuyang Yin, Xi Chen|<http://arxiv.org/pdf/2508.08098v1>|提出了一种融合多层次语言模型理解的统一图像生成模型，有效克服了传统模型连接浅层和训练成本高的局限。|
|🆕 发布|MDD-Net: Multimodal Depression Detection through Mutual Transformer|多模态抑郁检测互变网络（MDD-Net）|Md Rezwanul Haque, Md. Milon Islam, S M Taslim Uddin Raju, Hamdi Altaheri, Lobna Nassar, Fakhri Karray|<http://arxiv.org/pdf/2508.08093v1>|[代码](https://github.com/rezwanh001/Multimodal-Depression-Detection.); 提出了一种融合声视觉数据的多模态抑郁检测网络MDD-Net，通过互注意力变压器提升检测准确率。|
|🆕 发布|MIMIC: Multimodal Inversion for Model Interpretation and Conceptualization|MIMIC：模型解释与概念化的多模态逆向映射|Animesh Jain, Alexandros Stergiou|<http://arxiv.org/pdf/2508.07833v1>|提出MIMIC框架，通过合成视觉概念可视化VLM内部表征，增强模型解释性和可信度。|
|🆕 发布|Architectural Co-Design for Zero-Shot Anomaly Detection: Decoupling Representation and Dynamically Fusing Features in CLIP|零样本异常检测的架构协同设计：解耦表示与动态融合CLIP特征|Ke Ma, Jun Long, Hongxiao Fei, Liujie Hua, Yueyi Luo|<http://arxiv.org/pdf/2508.07819v1>|提出架构协同设计框架，通过注入局部归纳偏置和动态融合特征，有效提升预训练模型在零样本异常检测中的准确...|
|📝 更新|Crane: Context-Guided Prompt Learning and Attention Refinement for Zero-Shot Anomaly Detection|《Crane：基于上下文的提示学习与注意力精炼的无监督异常检测》|Alireza Salehi, Mohammadreza Salehi, Reshad Hosseini, Cees G. M. Snoek, Makoto Yamada, Mohammad Sabokrou|<http://arxiv.org/pdf/2504.11055v2>|[代码](https://github.com/AlirezaSalehy/Crane.); 提出Crane方法，通过结合上下文引导的提示学习和注意力细化，实现了无需训练样本的零样本异常检测。|
|🆕 发布|UniSVG: A Unified Dataset for Vector Graphic Understanding and Generation with Multimodal Large Language Models|统一向量图形理解与生成数据集：基于多模态大型语言模型|Jinke Li, Jiarui Yu, Chenxing Wei, Hande Dong, Qiang Lin, Liangjing Yang, Zhicai Wang, Yanbin Hao|<http://arxiv.org/pdf/2508.07766v1>|[代码](https://ryanlijinke.github.io/.); 提出了UniSVG数据集，首次实现了统一训练和评估多模态大语言模型在SVG理解和生成任务上的性能。|
|📝 更新|Zoom-Refine: Boosting High-Resolution Multimodal Understanding via Localized Zoom and Self-Refinement|“Zoom-Refine：通过局部放大和自我精炼提升高分辨率多模态理解”|Xuan Yu, Dayan Guan, Yanfeng Gu|<http://arxiv.org/pdf/2506.01663v2>|[代码](https://github.com/xavier-yu114/Zoom-Refine); 提出了一种无需额外训练的Zoom-Refine方法，通过局部放大和自我优化增强大型多模态语言模型对高...|
|📝 更新|Griffon v2: Advancing Multimodal Perception with High-Resolution Scaling and Visual-Language Co-Referring|Griffon v2：通过高分辨率缩放和视觉-语言共引用提升多模态感知|Yufei Zhan, Shurong Zheng, Yousong Zhu, Hongyin Zhao, Fan Yang, Ming Tang, Jinqiao Wang|<http://arxiv.org/pdf/2403.09333v2>|[代码](https://github.com/jefferyZhan/Griffon.); 提出了一种高分辨率通用模型Griffon v2，通过视觉和文本提示实现灵活的对象引用，并具备视觉语言...|
|📝 更新|Affordance-R1: Reinforcement Learning for Generalizable Affordance Reasoning in Multimodal Large Language Model|《Affordance-R1：面向多模态大型语言模型中泛化功效推理的强化学习》|Hanqing Wang, Shaoyang Wang, Yiming Zhong, Zemin Yang, Jiamin Wang, Zhiqing Cui, Jiahao Yuan, Yifan Han .etc.|<http://arxiv.org/pdf/2508.06206v2>|[代码](https://github.com/hq-King/Affordance-R1.); 提出Affordance-R1框架，通过强化学习与认知链式推理相结合，实现通用性物体可用性推理的零样...|
|📝 更新|Multimodal Visual Transformer for Sim2real Transfer in Visual Reinforcement Learning|用于视觉强化学习中Sim2real迁移的多模态视觉Transformer|Zichun Xu, Yuntao Li, Zhaomin Wang, Lei Zhuang, Guocai Yang, Jingdong Zhao|<http://arxiv.org/pdf/2507.09180v3>|提出了一种融合RGB和深度信息的视觉变换器，通过对比学习增强视觉强化学习的泛化能力。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RedDino: A foundation model for red blood cell analysis|红细胞分析的基础模型：RedDino|Luca Zedda, Andrea Loddo, Cecilia Di Ruberto, Carsten Marr|<http://arxiv.org/pdf/2508.08180v1>|[代码](https://github.com/Snarci/RedDino); 提出RedDino，一种针对红细胞分析的自我监督基础模型，显著提升形态分类性能。|
|🆕 发布|Investigating the Design Space of Visual Grounding in Multimodal Large Language Model|探究多模态大型语言模型中视觉定位的设计空间|Weitai Kang, Weiming Zhuang, Zhizhong Li, Yan Yan, Lingjuan Lyu|<http://arxiv.org/pdf/2508.08066v1>|系统研究了多模态大型语言模型中视觉定位的设计选择，优化了模型性能并实现了显著提升。|
|📝 更新|B-VLLM: A Vision Large Language Model with Balanced Spatio-Temporal Tokens|B-VLLM：一种具有平衡时空标记的视觉大语言模型|Zhuqiang Lu, Zhenfei Yin, Mengwei He, Zhihui Wang, Zicheng Liu, Zhiyong Wang, Kun Hu|<http://arxiv.org/pdf/2412.09919v2>|[代码](https://github.com/zhuqiangLu/B-VLLM.); 提出了一种平衡时空线索的视觉大语言模型B-VLLM，通过自适应帧选择和视觉token采样优化视频理解...|
|📝 更新|SynthVLM: Towards High-Quality and Efficient Synthesis of Image-Caption Datasets for Vision-Language Models|面向视觉语言模型的高质量与高效图像-字幕数据集合成方法：SynthVLM|Zheng Liu, Hao Liang, Bozhou Li, Wentao Xiong, Chong Chen, Conghui He, Wentao Zhang, Bin Cui|<http://arxiv.org/pdf/2407.20756v5>|提出了一种高效生成高质量图像-文本对的方法SynthVLM，并构建了SynthVLM-100K数据集...|
|📝 更新|CLGRPO: Reasoning Ability Enhancement for Small VLMs|CLGRPO：小型语言模型推理能力增强|Fanyi Wang, Binzhi Dong, Haotian Hu, Jinjin Xu, Zhiwang Zhang|<http://arxiv.org/pdf/2506.18048v2>|提出增量训练策略CLGRPO，显著增强小规模视觉语言模型的推理能力。|
|🆕 发布|FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis|FEAT：一种具有领域自适应大型语言模型的多人智能侦查系统，用于自动化死因分析|Chen Shen, Wanqing Zhang, Kehan Li, Erwen Huang, Haitao Bi, Aiying Fan, Yiwen Shen, Hongmei Dong .etc.|<http://arxiv.org/pdf/2508.07950v1>|提出FEAT系统，利用领域自适应的大型语言模型自动化法医死因分析，提升效率和准确性。|
|📝 更新|CoherenDream: Boosting Holistic Text Coherence in 3D Generation via Multimodal Large Language Models Feedback|通过多模态大型语言模型反馈增强3D生成中的整体文本连贯性：CoherenDream|Chenhan Jiang, Yihan Zeng, Dit-Yan Yeung|<http://arxiv.org/pdf/2504.19860v2>|提出了一种融合大型多模态语言模型反馈的优化目标，有效提升了文本与3D内容的一致性。|
|📝 更新|Universally Unfiltered and Unseen:Input-Agnostic Multimodal Jailbreaks against Text-to-Image Model Safeguards|《通用无过滤与未见：针对文本到图像模型安全措施的输入无关多模态破解》|Song Yan, Hui Wei, Jinlong Fei, Guoliang Yang, Zhengyu Zhao, Zheng Wang|<http://arxiv.org/pdf/2508.05658v2>|提出了一种通用攻击方法U3-Attack，有效绕过文本到图像模型的安全防护，提升攻击成功率。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|THAT: Token-wise High-frequency Augmentation Transformer for Hyperspectral Pansharpening|基于逐 token 高频增强的变换器网络用于高光谱 pansharpening 的 THAT 方法|Hongkun Jin, Hongcheng Jiang, Zejun Zhang, Yuan Zhang, Jia Fu, Tingfeng Li, Kai Luo|<http://arxiv.org/pdf/2508.08183v1>|[代码](https://github.com/kailuo93/THAT.); 提出THAT框架，通过选择性关注关键信息和增强高频细节学习，提升高光谱图像重建质量与效率。|
|🆕 发布|Hyperspectral Imaging|超光谱成像|Danfeng Hong, Chenyu Li, Naoto Yokoya, Bing Zhang, Xiuping Jia, Antonio Plaza, Paolo Gamba, Jon Atli Benediktsson .etc.|<http://arxiv.org/pdf/2508.08107v1>|系统介绍了 hyperspectral imaging 技术，探讨了其在多领域应用及未来发展方向。|
|🆕 发布|Prompt-Guided Relational Reasoning for Social Behavior Understanding with Vision Foundation Models|基于视觉基础模型的Prompt引导关系推理在社会行为理解中的应用|Thinesh Thiyakesan Ponbagavathi, Chengzheng Yang, Alina Roitberg|<http://arxiv.org/pdf/2508.07996v1>|提出ProGraD方法，通过可学习群体提示和轻量级Transformer增强视觉基础模型对社交行为的...|
|🆕 发布|Being-M0.5: A Real-Time Controllable Vision-Language-Motion Model|实时可控视觉-语言-运动模型：Being-M0.5|Bin Cao, Sipeng Zheng, Ye Wang, Lujie Xia, Qianshan Wei, Qin Jin, Jing Liu, Zongqing Lu|<http://arxiv.org/pdf/2508.07863v1>|[代码](https://beingbeyond.github.io/Being-M0.5.); 提出首个实时可控的视觉-语言-动作模型Being-M0.5，解决现有模型在多样指令响应、动作初始化、...|
|📝 更新|Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models|傅里叶-视觉语言模型：在频域中压缩视觉标记以用于大型视觉语言模型|Huanyu Wang, Jushi Kai, Haoli Bai, Lu Hou, Bo Jiang, Ziwei He, Zhouhan Lin|<http://arxiv.org/pdf/2508.06038v2>|提出了一种在频率域压缩视觉表示的方法Fourier-VLM，有效减少计算负担并提升推理速度。|
|🆕 发布|Exploiting Layer Normalization Fine-tuning in Visual Transformer Foundation Models for Classification|利用层归一化微调在视觉Transformer基础模型中进行分类|Zhaorui Tan, Tan Pan, Kaizhu Huang, Weimiao Yu, Kai Yao, Chen Jiang, Qiufeng Wang, Anh Nguyen .etc.|<http://arxiv.org/pdf/2508.07577v1>|提出了一种利用层归一化微调策略，通过调整参数适应不同数据分布，提升视觉Transformer模型分类...|
|🆕 发布|Exploring Multimodal Diffusion Transformers for Enhanced Prompt-based Image Editing|探索多模态扩散变换器以增强基于提示的图像编辑|Joonghyuk Shin, Alchan Hwang, Yujin Kim, Daneul Kim, Jaesik Park|<http://arxiv.org/pdf/2508.07519v1>|提出了一种统一注意力机制的图像编辑方法，实现了文本与图像间的双向信息流动，增强了多模态扩散变换器的编...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ReferSplat: Referring Segmentation in 3D Gaussian Splatting|“ReferSplat：三维高斯散点中的指引用分割”|Shuting He, Guangquan Jie, Changshuo Wang, Yun Zhou, Shuming Hu, Guanbin Li, Henghui Ding|<http://arxiv.org/pdf/2508.08252v1>|[代码](https://github.com/heshuting555/ReferSplat.); 提出Referring 3D Gaussian Splatting Segmentation任务，并...|
|🆕 发布|GRASPTrack: Geometry-Reasoned Association via Segmentation and Projection for Multi-Object Tracking|基于分割和投影的几何推理关联用于多目标跟踪的GRASPTrack|Xudong Han, Pengcheng Fang, Yueying Tian, Jianhui Yu, Xiaohao Cai, Daniel Roggen, Philip Birch|<http://arxiv.org/pdf/2508.08117v1>|引入了深度感知的多目标跟踪框架GRASPTrack，通过融合深度估计和实例分割，增强了遮挡和深度模糊...|
|🆕 发布|Sample-aware RandAugment: Search-free Automatic Data Augmentation for Effective Image Recognition|样本感知的RandAugment：无需搜索的自动数据增强以提高图像识别效率|Anqi Xiao, Weichen Yu, Hongyuan Yu|<http://arxiv.org/pdf/2508.08004v1>|[代码](https://github.com/ainieli/Sample-awareRandAugment); 提出了一种无需搜索的自动数据增强方法Sample-aware RandAugment，通过动态调整增...|
|🆕 发布|Towards Human-AI Collaboration System for the Detection of Invasive Ductal Carcinoma in Histopathology Images|面向人机协作系统在病理图像中检测浸润性导管癌的研究|Shuo Han, Ahmed Karam Eldaly, Solomon Sunday Oyelere|<http://arxiv.org/pdf/2508.07875v1>|提出了一种结合人工反馈的深度学习系统，通过人机协作提高了乳腺癌诊断的准确性和效率。|
|🆕 发布|Autonomous Navigation of Cloud-Controlled Quadcopters in Confined Spaces Using Multi-Modal Perception and LLM-Driven High Semantic Reasoning|云控四旋翼无人机在受限空间中的自主导航：采用多模态感知与基于LLM的高语义推理|Shoaib Ahmmad, Zubayer Ahmed Aditto, Md Mehrab Hossain, Noushin Yeasmin, Shorower Hossain|<http://arxiv.org/pdf/2508.07885v1>|提出一种基于云计算和多种传感器融合的无人机室内自主导航系统，实现高精度感知与决策。|
|📝 更新|Towards Customized Knowledge Distillation for Chip-Level Dense Image Predictions|面向芯片级密集图像预测的定制化知识蒸馏方法|Dong Zhang, Pingcheng Dong, Long Chen, Kwang-Ting Cheng|<http://arxiv.org/pdf/2401.13174v5>|提出了一种针对芯片级密集图像预测的定制化知识蒸馏方法，通过边界和上下文蒸馏提升了小模型在边界完整性和...|
|🆕 发布|Voice Pathology Detection Using Phonation|使用发音语音的声带病变检测|Sri Raksha Siva, Nived Suthahar, Prakash Boominathan, Uma Ranjan|<http://arxiv.org/pdf/2508.07587v1>|提出了一种无创的基于机器学习的嗓音病理检测框架，利用声学特征和循环神经网络进行早期诊断。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|3D Plant Root Skeleton Detection and Extraction|三维植物根系骨架检测与提取|Jiakai Lin, Jinchang Zhang, Ge Jin, Wenzhan Song, Tianming Liu, Guoyu Lu|<http://arxiv.org/pdf/2508.08094v1>|提出了一种从少量图像中高效提取植物根部三维骨架的方法，有助于自动化育种机器人精确分析植物根部结构。|
|🆕 发布|DoorDet: Semi-Automated Multi-Class Door Detection Dataset via Object Detection and Large Language Models|门检测：通过目标检测与大型语言模型实现半自动化多类别门检测数据集|Licheng Zhang, Bach Le, Naveed Akhtar, Tuan Ngo|<http://arxiv.org/pdf/2508.07714v1>|提出了一种半自动化流程，结合物体检测和大型语言模型构建多类门检测数据集，大幅降低标注成本。|
|🆕 发布|Enhancing Egocentric Object Detection in Static Environments using Graph-based Spatial Anomaly Detection and Correction|使用基于图的空域异常检测与校正增强静态环境中的自我中心物体检测|Vishakha Lall, Yisi Liu|<http://arxiv.org/pdf/2508.07624v1>|提出了一种基于图神经网络的检测后处理方法，通过显式建模物体间空间关系，有效纠正了第一人称视角中的检测...|
|🆕 发布|GAPNet: A Lightweight Framework for Image and Video Salient Object Detection via Granularity-Aware Paradigm|GAPNet：基于粒度感知范式的图像与视频显著目标检测轻量级框架|Yu-Huan Wu, Wei Liu, Zi-Xuan Zhu, Zizhou Wang, Yong Liu, Liangli Zhen|<http://arxiv.org/pdf/2508.07585v1>|[代码](https://github.com/yuhuan-wu/GAPNet.); 提出了一种基于细粒度感知范式的轻量级网络GAPNet，通过优化特征利用和语义解释，实现了图像和视频显...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Compact and De-biased Negative Instance Embedding for Multi-Instance Learning on Whole-Slide Image Classification|用于全切片图像分类的多实例学习紧凑且去偏负样本嵌入|Joohyung Lee, Heejeong Nam, Kwanhyung Lee, Sangchul Hahn|<http://arxiv.org/pdf/2402.10595v2>|[代码](https://github.com/AITRICS/pathology_mil.); 提出了一种半监督信号方法，利用正常切片的免费注释减少偏差，显著提升全切片图像分类的预测性能。|
|📝 更新|Goldilocks Test Sets for Face Verification|金发女孩测试集用于人脸验证|Haiyu Wu, Sicong Tian, Aman Bhatta, Jacob Gutierrez, Grace Bezold, Genesis Argueta, Karl Ricanek Jr., Michael C. King .etc.|<http://arxiv.org/pdf/2405.15965v2>|[代码](https://github.com/HaiyuWu/SOTA-Face-Recognition-Train-and-Test.); 提出了三个高难度但图像质量高的测试集，揭示了现有面部识别算法在处理不同人脸属性变化和相似个体识别上的...|
|🆕 发布|From Field to Drone: Domain Drift Tolerant Automated Multi-Species and Damage Plant Semantic Segmentation for Herbicide Trials|从田间到无人机：面向除草剂试验的域漂移容忍自动多物种及损伤植物语义分割|Artzai Picon, Itziar Eguskiza, Daniel Mugica, Javier Romero, Carlos Javier Jimenez, Eric White, Gabriel Do-Lago-Junqueira, Christian Klukas .etc.|<http://arxiv.org/pdf/2508.07514v1>|提出了一种结合自监督视觉模型和植物分类学层次推理的植物种类和损伤自动识别方法，有效应对了领域迁移挑战...|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|StableAvatar: Infinite-Length Audio-Driven Avatar Video Generation|《StableAvatar：无限长度音频驱动的虚拟形象视频生成》|Shuyuan Tu, Yueming Pan, Yinming Huang, Xintong Han, Zhen Xing, Qi Dai, Chong Luo, Zuxuan Wu .etc.|<http://arxiv.org/pdf/2508.08248v1>|StableAvatar通过创新的音频适配器和引导机制，实现了无限制长度的音画同步高质量视频生成。|
|🆕 发布|SAGOnline: Segment Any Gaussians Online|在线任意高斯分段：SAGOnline|Wentao Sun, Quanyun Wu, Hanqing Xu, Kyle Gao, Zhengsen Xu, Yiping Chen, Dedong Zhang, Lingfei Ma .etc.|<http://arxiv.org/pdf/2508.08219v1>|提出了一种轻量级、零样本的实时3D高斯场景分割框架，通过结合2D视频基础模型和GPU加速算法，实现了...|
|🆕 发布|Cut2Next: Generating Next Shot via In-Context Tuning|Cut2Next：通过上下文调整生成下一帧图像|Jingwen He, Hongbo Liu, Jiajun Li, Ziqi Huang, Yu Qiao, Wanli Ouyang, Ziwei Liu|<http://arxiv.org/pdf/2508.08244v1>|提出了一种基于Diffusion Transformer的Next Shot Generation框...|
|🆕 发布|PP-Motion: Physical-Perceptual Fidelity Evaluation for Human Motion Generation|人体运动生成的物理感知保真度评估：PP-Motion|Sihan Zhao, Zixuan Wang, Tianyu Luan, Jia Jia, Wentao Zhu, Jiebo Luo, Junsong Yuan, Nan Xi|<http://arxiv.org/pdf/2508.08179v1>|提出了一种新的数据驱动指标PP-Motion，结合物理规律与人类感知评价人体运动生成真实性。|
|🆕 发布|Matrix-3D: Omnidirectional Explorable 3D World Generation|矩阵-3D：全方位可探索的三维世界生成|Zhongqi Yang, Wenhang Ge, Yuqi Li, Jiaqi Chen, Haoyuan Li, Mengyin An, Fei Kang, Hua Xue .etc.|<http://arxiv.org/pdf/2508.08086v1>|提出Matrix-3D框架，利用全景表示实现广覆盖的全向可探索3D世界生成。|
|📝 更新|BonnBeetClouds3D: A Dataset Towards Point Cloud-based Organ-level Phenotyping of Sugar Beet Plants under Field Conditions|博恩甜菜云3D：面向田间条件下基于点云的甜菜植物器官水平表型鉴定的数据集|Elias Marks, Jonas Bömer, Federico Magistri, Anurag Sah, Jens Behley, Cyrill Stachniss|<http://arxiv.org/pdf/2312.14706v2>|提出了一个用于精确植物表型分析的新型高分辨率点云数据集，以支持自动化表型特征识别。|
|📝 更新|DanceChat: Large Language Model-Guided Music-to-Dance Generation|舞语者：大型语言模型引导的音乐到舞蹈生成|Qing Wang, Xiaohang Yang, Yilan Dong, Naveen Raj Govindaraj, Gregory Slabaugh, Shanxin Yuan|<http://arxiv.org/pdf/2506.10574v2>|提出了一种大型语言模型指导的音乐驱动的舞蹈生成方法，通过文本指令提高了舞蹈的多样性和与音乐风格的契合...|
|🆕 发布|TRIDE: A Text-assisted Radar-Image weather-aware fusion network for Depth Estimation|TRIDE：一种基于文本辅助的雷达图像天气感知融合网络用于深度估计|Huawei Sun, Zixu Wang, Hao Feng, Julius Ott, Lorenzo Servadei, Robert Wille|<http://arxiv.org/pdf/2508.08038v1>|[代码](https://github.com/harborsarah/TRIDE); 提出了一种融合雷达和文本描述的深度估计方法，通过适应天气条件显著提升了准确性。|
|📝 更新|SOPHY: Learning to Generate Simulation-Ready Objects with Physical Materials|SOPHY：学习生成具有物理材料的仿真就绪对象|Junyi Cao, Evangelos Kalogerakis|<http://arxiv.org/pdf/2504.12684v3>|提出了一种生成物理感知的3D形状的模型，结合形状、纹理和物理材料属性，提高了生成物体的真实感和动态环...|
|🆕 发布|Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation|全方位效应：统一且空间可控的视觉效果生成|Fangyuan Mao, Aiming Hao, Jintao Chen, Dongxia Liu, Xiaokun Feng, Jiashu Zhu, Meiqi Wu, Chubin Chen .etc.|<http://arxiv.org/pdf/2508.07981v1>|提出了Omni-Effects框架，通过混合专家模型和空间感知提示，实现了统一且空间可控的视觉效果生...|
|🆕 发布|Generative Video Matting|生成视频抠像|Yongtao Ge, Kangyang Xie, Guangkai Xu, Mingyu Liu, Li Ke, Longtao Huang, Hui Xue, Hao Chen .etc.|<http://arxiv.org/pdf/2508.07905v1>|[代码](https://github.com/aim-uofa/GVM.); 通过大规模预训练和视频扩散模型，实现了视频抠图的高效泛化与时间一致性。|
|🆕 发布|Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation|“Stand-In：一种轻量级且即插即用的视频生成身份控制方法”|Bowen Xue, Qixin Yan, Wenjing Wang, Hao Liu, Chen Li|<http://arxiv.org/pdf/2508.07901v1>|提出了一种轻量级视频生成框架Stand-In，通过少量参数实现高效的身份保持和兼容性。|
|🆕 发布|TAP: Parameter-efficient Task-Aware Prompting for Adverse Weather Removal|TAP：面向任务感知的参数高效提示用于恶劣天气去除|Hanting Wang, Shengpeng Ji, Shulei Wang, Hai Huang, Xiao Jin, Qifei Zhang, Tao Jin|<http://arxiv.org/pdf/2508.07878v1>|提出了一种参数高效的图像复原框架，通过任务感知增强提示应对不同恶劣天气退化，实现了性能提升和参数减少...|
|📝 更新|Multi-Modal Semantic Parsing for the Interpretation of Tombstone Inscriptions|多模态语义解析用于墓碑碑文解读|Xiao Zhang, Johan Bos|<http://arxiv.org/pdf/2507.04377v3>|提出了一种多模态语义解析框架，利用视觉语言模型将墓碑图像转化为结构化表示，大幅提升了解析精度。|
|📝 更新|EDiT: Efficient Diffusion Transformers with Linear Compressed Attention|EDiT：具有线性压缩注意力的高效扩散变换器|Philipp Becker, Abhinav Mehrotra, Ruchika Chavhan, Malcolm Chadwick, Luca Morreale, Mehdi Noroozi, Alberto Gil Ramos, Sourav Bhattacharya|<http://arxiv.org/pdf/2503.16726v2>|提出了一种线性压缩注意力的EDiT架构，有效提升了高分辨率图像生成效率并保持了图像质量。|
|🆕 发布|Pose-RFT: Enhancing MLLMs for 3D Pose Generation via Hybrid Action Reinforcement Fine-Tuning|姿态RFT：通过混合动作强化微调增强多模态语言模型的三维姿态生成|Bao Li, Xiaomei Zhang, Miao Xu, Zhaoxin Fan, Xiangyu Zhu, Zhen Lei|<http://arxiv.org/pdf/2508.07804v1>|提出了一种混合动作强化微调框架Pose-RFT，通过优化语言预测和姿态生成，显著提升了3D人体姿态生...|
|🆕 发布|Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion|通过对比反转实现定制化图像生成：比较揭示共性|Minseo Kim, Minchan Kwon, Dongyeun Lee, Yunho Jeon, Junmo Kim|<http://arxiv.org/pdf/2508.07755v1>|提出了一种无需额外指导的对比反转方法，通过比较输入图像有效提取目标概念，提升了定制图像生成的质量和概...|
|🆕 发布|Grouped Speculative Decoding for Autoregressive Image Generation|分组预测解码用于自回归图像生成|Junhyuk So, Juncheol Shin, Hyunho Kook, Eunhyeok Park|<http://arxiv.org/pdf/2508.07747v1>|[代码](https://github.com/junhyukso/GSD); 提出了一种无需额外训练的加速方法Grouped Speculative Decoding，通过评估有...|
|🆕 发布|Enhancing Small-Scale Dataset Expansion with Triplet-Connection-based Sample Re-Weighting|基于三元组连接的样本重加权增强小规模数据集扩展|Ting Xiang, Changjian Chen, Zhuo Tang, Qifeng Zhang, Fei Lyu, Li Yang, Jiapeng Zhang, Kenli Li|<http://arxiv.org/pdf/2508.07723v1>|提出了一种基于三元组连接的样本重加权方法TriReWeight，有效提升小规模数据集扩充质量，平均性...|
|📝 更新|How Far Are We from Generating Missing Modalities with Foundation Models?|我们离用基础模型生成缺失模态还有多远？|Guanzhou Ke, Bo Wang, Guoqing Chao, Weiming Hu, Shengfeng He|<http://arxiv.org/pdf/2506.03530v2>|[代码](https://github.com/Guanzhou-Ke/AFM2.); 提出了一种针对缺失模态重建的智能框架，通过动态策略和自我优化机制显著提升了重建质量。|
|🆕 发布|LaRender: Training-Free Occlusion Control in Image Generation via Latent Rendering|LaRender：通过潜在渲染实现图像生成中的无训练遮挡控制|Xiaohang Zhan, Dingming Liu|<http://arxiv.org/pdf/2508.07647v1>|提出了一种无需训练的图像生成算法，通过在潜在空间中利用体积渲染原理精确控制图像中物体遮挡关系。|
|🆕 发布|ShoulderShot: Generating Over-the-Shoulder Dialogue Videos|《肩上对话：生成肩上视角对话视频》|Yuang Zhang, Junqi Cheng, Haoyu Zhao, Jiaxi Gu, Fangyuan Zou, Zenghui Lu, Peng Shu|<http://arxiv.org/pdf/2508.07597v1>|提出 ShoulderShot 框架，结合双镜头生成与循环视频，实现长对话场景的连贯生成与角色一致性...|
|🆕 发布|X2Edit: Revisiting Arbitrary-Instruction Image Editing through Self-Constructed Data and Task-Aware Representation Learning|X2Edit：通过自构建数据与任务感知表征学习重新审视任意指令图像编辑|Jian Ma, Xujie Zhu, Zihao Pan, Qirong Peng, Xu Guo, Chen Chen, Haonan Lu|<http://arxiv.org/pdf/2508.07607v1>|[代码](https://github.com/OPPO-Mente-Lab/X2Edit.); 提出了X2Edit数据集和任务感知的MoE-LoRA模型，有效提升了任意指令图像编辑的性能并解决了兼...|
|🆕 发布|MSPT: A Lightweight Face Image Quality Assessment Method with Multi-stage Progressive Training|MSPT：一种基于多阶段渐进训练的轻量级人脸图像质量评估方法|Xiongwei Xiao, Baoying Chen, Jishen Zeng, Jianquan Yang|<http://arxiv.org/pdf/2508.07590v1>|提出了一种多阶段渐进训练的轻量级人脸图像质量评估方法，有效学习质量特征且降低遗忘问题，实现了高效评估...|
|📝 更新|Toward Patient-specific Partial Point Cloud to Surface Completion for Pre- to Intra-operative Registration in Image-guided Liver Interventions|面向图像引导肝脏干预术前至术中注册的患者特异性部分点云到表面补全|Nakul Poudel, Zixin Yang, Kelly Merrell, Richard Simon, Cristian A. Linte|<http://arxiv.org/pdf/2505.19518v2>|提出了一种针对手术中部分点云的个性化表面补全方法，以改善图像引导肝脏手术中的术前与术中数据配准。|
|🆕 发布|CoT-Pose: Chain-of-Thought Reasoning for 3D Pose Generation from Abstract Prompts|“CoT-Pose：基于抽象提示的3D姿态生成链式思维推理”|Junuk Cha, Jihyeon Kim|<http://arxiv.org/pdf/2508.07540v1>|引入CoT推理框架，实现从抽象文本到精确3D姿态的生成。|
|📝 更新|GenEscape: Hierarchical Multi-Agent Generation of Escape Room Puzzles|《GenEscape：分层多智能体生成逃脱房间谜题》|Mengyi Shan, Brian Curless, Ira Kemelmacher-Shlizerman, Steve Seitz|<http://arxiv.org/pdf/2506.21839v2>|提出多智能体协作框架生成视觉吸引、逻辑严密、智力挑战的逃脱房间谜题图像。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning an Implicit Physics Model for Image-based Fluid Simulation|学习基于图像的流体模拟的隐式物理模型|Emily Yue-Ting Jia, Jiageng Mao, Zhiyuan Gao, Yajie Zhao, Yue Wang|<http://arxiv.org/pdf/2508.08254v1>|提出了一种基于物理原理的神经网络方法，从单张图像生成符合物理规律的4D流体动画。|
|🆕 发布|OMGSR: You Only Need One Mid-timestep Guidance for Real-World Image Super-Resolution|OMGSR：仅需一个中间时间步指导进行现实世界图像超分辨率|Zhiqiang Wu, Zhaomang Sun, Tong Zhou, Bingtao Fu, Ji Cong, Yitong Dong, Huaqi Zhang, Xuan Tang .etc.|<http://arxiv.org/pdf/2508.08227v1>|提出了一种利用中间时间步长引导的图像超分辨率方法，有效缩小了低质量图像与噪声先验之间的分布差距。|
|🆕 发布|Spatial-ORMLLM: Improve Spatial Relation Understanding in the Operating Room with Multimodal Large Language Model|手术室中基于多模态大型语言模型的空间关系理解提升方法：Spatial-ORMLLM|Peiqi He, Zhenhao Zhang, Yixiang Zhang, Xiongjun Zhao, Shaoliang Peng|<http://arxiv.org/pdf/2508.08199v1>|提出了一种利用RGB模态进行3D空间推理的视觉语言模型，解决了手术室空间关系理解难题。|
|🆕 发布|CD-TVD: Contrastive Diffusion for 3D Super-Resolution with Scarce High-Resolution Time-Varying Data|CD-TVD：基于稀缺高分辨率时变数据的对比扩散三维超分辨率|Chongke Bi, Xin Gao, Jiangkang Deng, Guan|<http://arxiv.org/pdf/2508.08173v1>|[代码](https://github.com/Xin-Gao-private/CD-TVD.); 提出CD-TVD框架，利用对比学习和改进的扩散模型，从少量高分辨率时变数据实现精确的3D超分辨率。|
|🆕 发布|ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction|ReconDreamer-RL：通过基于扩散的场景重建增强强化学习|Chaojun Ni, Guosheng Zhao, Xiaofeng Wang, Zheng Zhu, Wenkang Qin, Xinze Chen, Guanghong Jia, Guan Huang .etc.|<http://arxiv.org/pdf/2508.08170v1>|提出ReconDreamer-RL框架，通过整合视频扩散先验和物理模型，缩小仿真与现实的差距，提升自...|
|🆕 发布|Learned Regularization for Microwave Tomography|微波断层扫描学习的正则化方法|Bowen Tong, Hao Chen, Shaorui Guo, Dong Liu|<http://arxiv.org/pdf/2508.08114v1>|提出了一种结合物理信息的混合框架，通过学习正则化改善微波断层成像的重建质量，无需配对数据即可恢复复杂...|
|📝 更新|From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers|从复用到预测：利用TaylorSeers加速扩散模型|Jiacheng Liu, Chang Zou, Yuanhuiyi Lyu, Junjie Chen, Linfeng Zhang|<http://arxiv.org/pdf/2503.06923v2>|[代码](https://github.com/Shenyi-Z/TaylorSeer); 提出了一种通过泰勒级数预测未来时间步特征的方法TaylorSeer，大幅加速了扩散模型而保持了生成质...|
|📝 更新|Spotter+GPT: Turning Sign Spottings into Sentences with LLMs|“Spotter+GPT：利用大规模语言模型将标志检测转化为句子”|Ozge Mercanoglu Sincan, Richard Bowden|<http://arxiv.org/pdf/2403.10434v3>|提出了一种利用大型语言模型简化手语视频转文字的Spotter+GPT框架，降低计算成本和时间。|
|🆕 发布|Diffusing the Blind Spot: Uterine MRI Synthesis with Diffusion Models|《消除盲区：基于扩散模型的子宫MRI合成》|Johanna P. Müller, Anika Knupfer, Pedro Blöss, Edoardo Berardi Vittur, Bernhard Kainz, Jana Hutter|<http://arxiv.org/pdf/2508.07903v1>|提出了一种基于扩散模型的新框架，生成高保真度、解剖结构清晰的子宫MRI图像，解决了妇科成像领域的数据...|
|🆕 发布|NeeCo: Image Synthesis of Novel Instrument States Based on Dynamic and Deformable 3D Gaussian Reconstruction|“NeeCo：基于动态可变形三维高斯重建的新型乐器状态图像合成”|Tianle Zeng, Junlei Hu, Gerardo Loza Galindo, Sharib Ali, Duygu Sarikaya, Pietro Valdastri, Dominic Jones|<http://arxiv.org/pdf/2508.07897v1>|提出了一种动态高斯散点技术，通过生成高质量标注图像数据集，解决了手术图像数据稀缺问题。|
|📝 更新|DAViD: Modeling Dynamic Affordance of 3D Objects Using Pre-trained Video Diffusion Models|DAViD：使用预训练视频扩散模型建模三维物体的动态可达性|Hyeonwoo Kim, Sangwon Baik, Hanbyul Joo|<http://arxiv.org/pdf/2501.08333v3>|提出了一种新框架，通过预训练视频扩散模型学习3D物体的动态可用性，以生成和模仿动态人-物交互。|
|📝 更新|Learning 3D Object Spatial Relationships from Pre-trained 2D Diffusion Models|从预训练二维扩散模型中学习三维物体空间关系|Sangwon Baik, Hyeonwoo Kim, Hanbyul Joo|<http://arxiv.org/pdf/2503.19914v2>|提出了一种利用预训练二维扩散模型生成合成图像以学习三维物体空间关系的方法。|
|🆕 发布|DiTVR: Zero-Shot Diffusion Transformer for Video Restoration|零样本扩散变换器用于视频修复：DiTVR|Sicheng Gao, Nancy Mehta, Zongwei Wu, Radu Timofte|<http://arxiv.org/pdf/2508.07811v1>|提出零样本视频修复框架DiTVR，通过轨迹感知注意力和波动引导采样，实现高质量视频重建。|
|🆕 发布|MambaTrans: Multimodal Fusion Image Translation via Large Language Model Priors for Downstream Visual Tasks|MambaTrans：基于大型语言模型先验的多模态融合图像翻译方法，用于下游视觉任务|Yushen Xu, Xiaosong Li, Zhenyu Kuang, Xiaoqi Cheng, Haishu Tan, Huafeng Li|<http://arxiv.org/pdf/2508.07803v1>|提出MambaTrans模型，通过大语言模型描述和语义分割遮罩，优化多模态图像融合，提升下游视觉任务...|
|🆕 发布|Sea-Undistort: A Dataset for Through-Water Image Restoration in High Resolution Airborne Bathymetric Mapping|《Sea-Undistort：高分辨率机载测深 mapping 中水面下图像复原的数据集》|Maximilian Kromer, Panagiotis Agrafiotis, Begüm Demir|<http://arxiv.org/pdf/2508.07760v1>|介绍了Sea-Undistort数据集，通过模拟水下图像，提升了浅水区 bathymetric Ma...|
|🆕 发布|Correspondence as Video: Test-Time Adaption on SAM2 for Reference Segmentation in the Wild|将参考分割中的对应关系视为视频：在SAM2上进行测试时适应以应对野外环境|Haoran Wang, Zekun Li, Jian Zhang, Lei Qi, Yinghuan Shi|<http://arxiv.org/pdf/2508.07759v1>|提出将参考图像与目标图像间的对应关系视为伪视频，通过轻量级适配提升了SAM2模型在野外环境下的分割性...|
|📝 更新|CPKD: Clinical Prior Knowledge-Constrained Diffusion Models for Surgical Phase Recognition in Endoscopic Submucosal Dissection|CPKD：基于临床先验知识约束的扩散模型用于内镜下黏膜下剥离手术阶段识别|Xiangning Zhang, Jinnan Chen, Qingwei Zhang, Yaqi Wang, Chengfeng Zhou, Xiaobo Li, Dahong Qian|<http://arxiv.org/pdf/2507.03295v2>|提出了一种基于噪声扩散原理的手术阶段识别方法CPKD，利用临床先验知识增强逻辑错误修正能力，提升内镜...|
|🆕 发布|DiffVC-OSD: One-Step Diffusion-based Perceptual Neural Video Compression Framework|DiffVC-OSD：一步扩散基于感知神经视频压缩框架|Wenzhuo Ma, Zhenzhong Chen|<http://arxiv.org/pdf/2508.07682v1>|提出了一种单步扩散模型DiffVC-OSD，通过融合时间和潜在特征，实现了视频压缩性能的提升和速度的...|
|🆕 发布|Undress to Redress: A Training-Free Framework for Virtual Try-On|《脱衣以正衣：一种无需训练的虚拟试穿框架》|Zhiying Li, Junhao Wu, Yeying Jin, Daiheng Gao, Yun Ji, Kaichuan Kong, Lei Yu, Hao Xu .etc.|<http://arxiv.org/pdf/2508.07680v1>|提出了一种无需训练的虚拟试衣框架UR-VTON，通过分解长袖变短袖过程并优化细节处理，解决了现有方法...|
|🆕 发布|LaVieID: Local Autoregressive Diffusion Transformers for Identity-Preserving Video Creation|LaVieID：用于身份保持视频创作的局部自回归扩散变换器|Wenhui Song, Hanhui Li, Jiehui Huang, Panwen Hu, Yuhao Cheng, Long Chen, Yiqiang Yan, Xiaodan Liang|<http://arxiv.org/pdf/2508.07603v1>|[代码](https://github.com/ssugarwh/LaVieID.); 提出了一种局部自回归视频生成框架LaVieID，通过时空视角保持身份信息，生成高保真个性化视频。|
|📝 更新|FQGA-single: Towards Fewer Training Epochs and Fewer Model Parameters for Image-to-Image Translation Tasks|面向图像到图像转换任务的少训练轮次与少模型参数的FQGA-single方法|Cho Yang|<http://arxiv.org/pdf/2408.09218v4>|提出FQGA-single模型，仅需少量训练轮次和参数即可高效生成高质量医学合成CT图像。|
|📝 更新|PainDiffusion: Learning to Express Pain|疼痛扩散：学习表达疼痛|Quang Tien Dam, Tri Tung Nguyen Nguyen, Yuki Endo, Dinh Tuan Tran, Joo-Ho Lee|<http://arxiv.org/pdf/2409.11635v3>|[代码](https://damtien444.github.io/paindf); 提出 PainDiffusion 生成模型，合成逼真的疼痛面部表情，提升临床训练和机器人交互效果。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Reinforcement Learning in Vision: A Survey|计算机视觉中的强化学习：综述|Weijia Wu, Chen Gao, Joya Chen, Kevin Qinghong Lin, Qingwei Meng, Yiming Zhang, Yuke Qiu, Hong Zhou .etc.|<http://arxiv.org/pdf/2508.08189v1>|[代码](https://github.com/weijiawu/Awesome-Visual-Reinforcement-Learning.); 梳理了视觉强化学习领域的最新进展，系统总结了问题定义、策略优化及四大主题框架，指明了未来研究方向。|
|🆕 发布|A Physics-Driven Neural Network with Parameter Embedding for Generating Quantitative MR Maps from Weighted Images|基于物理驱动的参数内嵌神经网络，用于从加权图像生成定量磁共振映射|Lingjing Chen, Chengxiu Zhang, Yinqiao Yi, Yida Wang, Yang Song, Xu Yan, Shengfang Xu, Dalin Zhu .etc.|<http://arxiv.org/pdf/2508.08123v1>|提出了一种融合MRI序列参数的物理驱动神经网络，通过参数嵌入提高了定量MR图像合成的准确性和泛化能力...|
|📝 更新|DreamFrame: Enhancing Video Understanding via Automatically Generated QA and Style-Consistent Keyframes|梦境框架：通过自动生成的问答和风格一致的关键帧增强视频理解|Zhende Song, Chenchen Wang, Jiamu Sheng, Chi Zhang, Shengji Tang, Jiayuan Fan, Tao Chen|<http://arxiv.org/pdf/2403.01422v5>|自动生成风格一致的关键帧和QA对，支持LVLM指令微调，提高视频理解能力。|
|🆕 发布|Dream4D: Lifting Camera-Controlled I2V towards Spatiotemporally Consistent 4D Generation|Dream4D：将相机控制的I2V提升至时空一致的4D生成|Xiaoyan Liu, Kangrui Li, Jiaxin Liu|<http://arxiv.org/pdf/2508.07769v1>|Dream4D通过结合视频生成和神经4D重建，实现了时空一致的4D内容生成。|
|📝 更新|Uni3R: Unified 3D Reconstruction and Semantic Understanding via Generalizable Gaussian Splatting from Unposed Multi-View Images|统一三维重建与语义理解：通过未定位多视角图像的通用高斯散点绘制方法|Xiangyu Sun, Haoyi Jiang, Liu Liu, Seungtae Nam, Gyeongjin Kang, Xinjie Wang, Wei Sui, Zhizhong Su .etc.|<http://arxiv.org/pdf/2508.03643v3>|[代码](https://github.com/HorizonRobotics/Uni3R.); Uni3R通过一种创新的统一框架，直接从无定位多视角图像中实现了高效的3D场景重建和语义理解。|
|🆕 发布|Domain Generalization of Pathological Image Segmentation by Patch-Level and WSI-Level Contrastive Learning|病理图像分割的斑块级别和全切片级别对比学习的域泛化|Yuki Shigeyasu, Shota Harada, Akihiko Yoshizawa, Kazuhiro Terada, Naoki Nakazima, Mariyo Kurata, Hiroyuki Abe, Tetsuo Ushiku .etc.|<http://arxiv.org/pdf/2508.07539v1>|通过聚类WSI特征并应用两级对比学习，有效解决病理图像分割中的域偏移问题。|
|🆕 发布|Enhanced Generative Structure Prior for Chinese Text Image Super-resolution|增强型生成结构先验用于中文文本图像超分辨率|Xiaoming Li, Wangmeng Zuo, Chen Change Loy|<http://arxiv.org/pdf/2508.07537v1>|[代码](https://github.com/csxmli2016/MARCONetPlusPlus); 提出了一种针对中文文本图像超分辨率恢复的结构先验方法，有效提升了字符结构的恢复精度和视觉质量。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control|“遵循你的形状：通过轨迹引导的区域控制实现形状感知图像编辑”|Zeqian Long, Mingzhe Zheng, Kunyu Feng, Xinhua Zhang, Hongyu Liu, Harry Yang, Linfeng Zhang, Qifeng Chen .etc.|<http://arxiv.org/pdf/2508.08134v1>|提出了一种无需训练和遮罩的图像编辑框架，通过轨迹引导精确控制对象形状变换，同时保护非目标内容。|
|🆕 发布|FantasyStyle: Controllable Stylized Distillation for 3D Gaussian Splatting|《FantasyStyle：用于3D高斯散点绘制的可控风格化蒸馏》|Yitong Yang, Yinglin Wang, Changshuo Wang, Huajie Wang, Shuting He|<http://arxiv.org/pdf/2508.08136v1>|FantasyStyle通过3D滤波和多视图频率一致性解决了风格迁移中的不一致性和内容泄露问题，提出...|
|🆕 发布|S^2VG: 3D Stereoscopic and Spatial Video Generation via Denoising Frame Matrix|S^2VG: 通过去噪帧矩阵实现的3D立体与空间视频生成|Peng Dai, Feitong Tan, Qiangeng Xu, Yihua Huang, David Futschik, Ruofei Du, Sean Fanello, Yinda Zhang .etc.|<http://arxiv.org/pdf/2508.08048v1>|[代码](https://daipengwa.github.io/S-2VG_ProjectPage); 提出了一种无需训练和姿态估计的方法，通过帧矩阵修复生成沉浸式3D立体和空间视频。|
|📝 更新|A Plug-and-Play Method for Guided Multi-contrast MRI Reconstruction based on Content/Style Modeling|基于内容/风格建模的引导多对比度MRI重建的即插即用方法|Chinmay Rao, Matthias van Osch, Nicola Pezzotti, Jeroen de Bresser, Mark van Buchem, Laurens Beljaards, Jakob Meineke, Elwin de Weerdt .etc.|<http://arxiv.org/pdf/2409.13477v4>|提出了一种无需大量配对训练数据的模块化两阶段MRI重建方法，通过内容/风格模型分离对比无关和对比特定...|
|🆕 发布|Segmenting and Understanding: Region-aware Semantic Attention for Fine-grained Image Quality Assessment with Large Language Models|区域感知的语义注意力用于细粒度图像质量评估的大语言模型分割与理解|Chenyue Song, Chen Hui, Haiqi Zhu, Feng Jiang, Yachun Mi, Wei Zhang, Shaohui Liu|<http://arxiv.org/pdf/2508.07818v1>|提出了一种区域感知的语义注意力模型RSFIQA，通过细化图像质量评估中的区域特征，提高了质量预测的准...|
|📝 更新|D-Judge: How Far Are We? Assessing the Discrepancies Between AI-synthesized and Natural Images through Multimodal Guidance|D-Judge：我们离目标还有多远？通过多模态引导评估AI合成图像与自然图像之间的差异|Renyang Liu, Ziyu Lyu, Wei Zhou, See-Kiong Ng|<http://arxiv.org/pdf/2412.17632v4>|[代码](https://github.com/ryliu68/DJudge); 提出D-Judge评估基准，通过多模态指导量化AI生成图像与自然图像的差异。|
|🆕 发布|Make Your MoVe: Make Your 3D Contents by Adapting Multi-View Diffusion Models to External Editing|《打造您的MoVe：通过适应外部编辑的多视角扩散模型制作您的3D内容》|Weitao Wang, Haoran Xu, Jun Meng, Haoqian Wang|<http://arxiv.org/pdf/2508.07700v1>|提出了一种无需调整的即插即用方案，通过保持原始几何结构，有效提升了编辑后3D内容的多视角一致性和网格...|
|🆕 发布|TAR-TVG: Enhancing VLMs with Timestamp Anchor-Constrained Reasoning for Temporal Video Grounding|时间戳锚点约束推理增强的视觉语言模型：用于视频时序定位的TAR-TVG方法|Chaohong Guo, Xun Mo, Yongwei Nie, Xuemiao Xu, Chao Xu, Fei Yu, Chengjiang Long|<http://arxiv.org/pdf/2508.07683v1>|提出了一种引入时间戳锚点以增强推理质量的时序视频定位框架，实现了更精确的预测和可解释的推理链。|
|📝 更新|AU-IQA: A Benchmark Dataset for Perceptual Quality Assessment of AI-Enhanced User-Generated Content|AU-IQA：人工智能增强的用户生成内容感知质量评估基准数据集|Shushi Wang, Chunyi Li, Zicheng Zhang, Han Zhou, Wei Dong, Jun Chen, Guangtao Zhai, Xiaohong Liu|<http://arxiv.org/pdf/2508.05016v2>|[代码](https://github.com/WNNGGU/AU-IQA-Dataset.); 构建了AU-IQA数据集，评估了现有图像质量评估模型在AI增强用户生成内容上的有效性。|
|📝 更新|ArtiMuse: Fine-Grained Image Aesthetics Assessment with Joint Scoring and Expert-Level Understanding|“ArtiMuse：结合评分与专家级理解进行细粒度图像美学评估”|Shuo Cao, Nan Ma, Jiayang Li, Xiaohui Li, Lihao Shao, Kaiwen Zhu, Yu Zhou, Yuandong Pu .etc.|<http://arxiv.org/pdf/2507.14533v2>|提出ArtiMuse模型，融合评分与专家级理解，提升图像美学评估的精细度和专业度。|
|🆕 发布|Splat4D: Diffusion-Enhanced 4D Gaussian Splatting for Temporally and Spatially Consistent Content Creation|“Splat4D：用于时间和空间一致性内容创建的扩散增强4D高斯散点绘制”|Minghao Yin, Yukang Cao, Songyou Peng, Kai Han|<http://arxiv.org/pdf/2508.07557v1>|提出Splat4D框架，通过多视角渲染和视频扩散模型实现从单目视频生成高质量4D内容，确保时空一致性...|
|🆕 发布|Commentary Generation for Soccer Highlights|足球精彩瞬间解说生成|Chidaksh Ravuru|<http://arxiv.org/pdf/2508.07543v1>|[代码](https://github.com/chidaksh/SoccerCommentary.); 提出了一种针对足球精彩瞬间自动生成解说的新方法，通过细化视频与解说的时间对齐，提升了描述的准确性。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 单视图三维推理 (Single-view 3D Inference)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|3D Human Mesh Estimation from Single View RGBD|从单视角RGBD图像估计三维人体网格|Ozhan Suat, Bedirhan Uguz, Batuhan Karagoz, Muhammed Can Keles, Emre Akbas|<http://arxiv.org/pdf/2508.08178v1>|提出了一种利用RGBD相机深度数据估计3D人体网格的方法，通过masked autoencoder有...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mitigating Biases in Surgical Operating Rooms with Geometry|利用几何学减轻手术室中的偏见|Tony Danjun Wang, Tobias Czempiel, Nassir Navab, Lennart Bastian|<http://arxiv.org/pdf/2508.08028v1>|提出3D点云序列编码方法，减少手术室中人物识别的偏见，提高模型准确度。|
|🆕 发布|Mem4D: Decoupling Static and Dynamic Memory for Dynamic Scene Reconstruction|《Mem4D：解耦静态与动态内存以实现动态场景重建》|Xudong Cai, Shuo Wang, Peng Wang, Yongcai Wang, Zhaoxin Fan, Wanting Li, Tianbao Zhang, Jianrong Tao .etc.|<http://arxiv.org/pdf/2508.07908v1>|提出了一种分离静态和动态记忆的框架Mem4D，有效解决了动态场景重建中的稳定性与细节保留的矛盾。|
|📝 更新|Is Single-View Mesh Reconstruction Ready for Robotics?|单视图网格重建在机器人领域是否已经准备就绪？|Frederik Nolte, Andreas Geiger, Bernhard Schölkopf, Ingmar Posner|<http://arxiv.org/pdf/2505.17966v2>|评估了单视角网格重建模型在机器人实时规划和动态预测中的应用潜力，并提出了针对机器人特有的性能评估标准...|
|🆕 发布|Multi-view Normal and Distance Guidance Gaussian Splatting for Surface Reconstruction|多视角法向量和距离引导的高斯散点绘制法用于表面重建|Bo Jia, Yanan Guo, Ying Chang, Benkui Zhang, Ying Xie, Kangning Du, Lin Cao|<http://arxiv.org/pdf/2508.07701v1>|提出了一种多视角正常向量和距离引导的高斯散点法，有效解决了多视角场景中的几何匹配和深度统一问题，提高...|
|📝 更新|Quadratic Gaussian Splatting: High Quality Surface Reconstruction with Second-order Geometric Primitives|二次高斯散点绘制：基于二阶几何原语的高质量表面重建|Ziyu Zhang, Binbin Huang, Hanqing Jiang, Liyang Zhou, Xiaojun Xiang, Shunhan Shen|<http://arxiv.org/pdf/2411.16392v3>|提出了一种变形二次曲面表示法，通过使用测地距离优化密度分布，实现了高质量表面重建。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PrIINeR: Towards Prior-Informed Implicit Neural Representations for Accelerated MRI|PrIINeR：面向先验信息指导的隐式神经表示用于加速磁共振成像|Ziad Al-Haj Hemidi, Eytan Kats, Mattias P. Heinrich|<http://arxiv.org/pdf/2508.08058v1>|[代码](https://github.com/multimodallearning/PrIINeR.); 提出了一种融合预训练深度学习模型知识的隐式神经表示方法PrIINeR，有效提升了高速MRI重建的质量...|
|🆕 发布|An Iterative Reconstruction Method for Dental Cone-Beam Computed Tomography with a Truncated Field of View|一种适用于截断视场口腔锥形束计算机断层成像的迭代重建方法|Hyoung Suk Park, Kiwan Jeon|<http://arxiv.org/pdf/2508.07618v1>|提出了一种两阶段迭代重建方法，有效减轻牙科CBCT中的截断视野伪影，提升图像质量。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AD-AVSR: Asymmetric Dual-stream Enhancement for Robust Audio-Visual Speech Recognition|AD-AVSR：基于非对称双流增强的鲁棒音频视觉语音识别|Junxiao Xue, Xiaozhen Liu, Xuecheng Wu, Xinyi Yin, Danlei Huang, Fei Yu|<http://arxiv.org/pdf/2508.07608v1>|提出了一种不对称双向增强的音频视觉语音识别框架AD-AVSR，有效提升了噪声环境下的识别性能和鲁棒性...|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TrackOR: Towards Personalized Intelligent Operating Rooms Through Robust Tracking|“TrackOR：通过鲁棒跟踪实现个性化智能手术室”|Tony Danjun Wang, Christian Heiliger, Nassir Navab, Lennart Bastian|<http://arxiv.org/pdf/2508.07968v1>|提出TrackOR框架，利用3D几何信息实现手术室内长期多人跟踪与重识别，提升个性化智能支持。|
|🆕 发布|Tracking Any Point Methods for Markerless 3D Tissue Tracking in Endoscopic Stereo Images|标记无关的内窥镜立体图像中三维组织跟踪的任意点跟踪方法|Konrad Reuter, Suresh Guttikonda, Sarah Latus, Lennart Maack, Christian Betz, Tobias Maurer, Alexander Schlaefer|<http://arxiv.org/pdf/2508.07851v1>|提出了一种基于Tracking Any Point网络的 markerless 3D组织跟踪方法，用...|
|📝 更新|SparseTem: Boosting the Efficiency of CNN-Based Video Encoders by Exploiting Temporal Continuity|利用时间连续性提升基于CNN视频编码器效率的SparseTem方法|Kunyun Wang, Shuo Yang, Jieru Zhao, Wenchao Ding, Quan Chen, Jingwen Leng, Minyi Guo|<http://arxiv.org/pdf/2410.20790v2>|提出利用视频帧间连续性减少计算量的SparseTem方法，显著提升了CNN视频编码器的效率。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TAG: A Simple Yet Effective Temporal-Aware Approach for Zero-Shot Video Temporal Grounding|零样本视频时间定位的一种简单而有效的时间感知方法：TAG|Jin-Seop Lee, SungJoon Lee, Jaehan Ahn, YunSeok Choi, Jee-Hyong Lee|<http://arxiv.org/pdf/2508.07925v1>|[代码](https://github.com/Nuetee/TAG); 提出了一种简单有效的零样本视频时间定位方法TAG，通过整合时间池化和一致性聚类解决语义碎片化问题，无...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Inference-Time Gaze Refinement for Micro-Expression Recognition: Enhancing Event-Based Eye Tracking with Motion-Aware Post-Processing|微表情识别中的推理时注视细化：通过运动感知后处理增强基于事件的眼睛追踪|Nuwan Bandara, Thivya Kandappu, Archan Misra|<http://arxiv.org/pdf/2506.12524v3>|[代码](https://github.com/eye-tracking-for-physiological-sensing/EyeLoRiN.); 提出了一种增强事件驱动眼动估计模型输出的后处理框架，通过运动感知滤波和光流对预测进行细化，提高了微表...|
|🆕 发布|GaitSnippet: Gait Recognition Beyond Unordered Sets and Ordered Sequences|步态片段：超越无序集合与有序序列的步态识别|Saihui Hou, Chenye Wang, Wenpeng Lang, Zhengxiang Lan, Yongzhen Huang|<http://arxiv.org/pdf/2508.07782v1>|提出了一种基于“片段”概念的新方法，有效融合了多尺度时间上下文，提高了步态识别的准确性。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Deep Space Weather Model: Long-Range Solar Flare Prediction from Multi-Wavelength Images|深度空间天气模型：基于多波长图像的长期太阳耀斑预测|Shunya Nagashima, Komei Sugiura|<http://arxiv.org/pdf/2508.07847v1>|[代码](https://keio-smilab25.github.io/DeepSWM.); 提出Deep Space Weather Model，利用多深度状态空间模型和稀疏掩码自编码器预测太...|
|📝 更新|MomentMix Augmentation with Length-Aware DETR for Temporally Robust Moment Retrieval|基于长度感知的DETR的MomentMix增强方法用于时间稳健的瞬间检索|Seojeong Park, Jiho Choi, Kyungjune Baek, Hyunjung Shim|<http://arxiv.org/pdf/2412.20816v2>|[代码](https://github.com/sjpark5800/LA-DETR.); 提出MomentMix增强策略和Length-Aware DETR，有效提升视频短时刻定位准确性。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|From Limited Labels to Open Domains:An Efficient Learning Method for Drone-view Geo-Localization|从有限标签到开放域：一种高效的无人机视角地理定位学习方法|Zhongwei Chen, Zhao-Xu Yang, Hai-Jun Rong, Jiawei Lang, Guoqi Li|<http://arxiv.org/pdf/2503.07520v2>|提出了一种新颖的跨域不变知识迁移网络，通过少量监督学习，有效解决了无人机视角地理定位中的跨视图关联和...|
|🆕 发布|Anatomy-Aware Low-Dose CT Denoising via Pretrained Vision Models and Semantic-Guided Contrastive Learning|基于预训练视觉模型和语义引导对比学习的解剖感知低剂量CT去噪|Runze Wang, Zeli Chen, Zhiyun Song, Wei Fang, Jiajin Zhang, Danyang Tu, Yuxing Tang, Minfeng Xu .etc.|<http://arxiv.org/pdf/2508.07788v1>|提出了一种结合预训练视觉模型和语义引导对比学习的低剂量CT去噪方法，有效保留了人体组织解剖结构。|
|🆕 发布|Prototype-Guided Curriculum Learning for Zero-Shot Learning|原型引导的零样本学习课程学习|Lei Wang, Shiming Chen, Guo-Sen Xie, Ziming Hong, Chaojian Yu, Qinmu Peng, Xinge You|<http://arxiv.org/pdf/2508.07771v1>|提出了一种引导性课程学习框架，通过动态更新类级语义原型和优先处理高相似度样本，提高了零样本学习的视觉...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|KARMA: Efficient Structural Defect Segmentation via Kolmogorov-Arnold Representation Learning|KARMA：基于科尔莫哥洛夫-阿尔诺德表示学习的结构缺陷高效分割|Md Meftahul Ferdaus, Mahdi Abdelguerfi, Elias Ioup, Steven Sloan, Kendall N. Niles, Ken Pathak|<http://arxiv.org/pdf/2508.08186v1>|[代码](https://github.com/faeyelab/karma.); 提出KARMA框架，通过一维函数组合实现高效结构缺陷分割，大幅减少参数需求并提升实时检测性能。|
|🆕 发布|Vision-Based Localization and LLM-based Navigation for Indoor Environments|基于视觉的室内环境定位与基于大型语言模型导航|Keyan Rahimi, Md. Wasiul Haque, Sagar Dasgupta, Mizanur Rahman|<http://arxiv.org/pdf/2508.08120v1>|融合视觉定位与大型语言模型导航，实现高精度室内定位与指引。|
|🆕 发布|ME-TST+: Micro-expression Analysis via Temporal State Transition with ROI Relationship Awareness|基于时态状态转移及感兴趣区域关联的微表情分析ME-TST+|Zizheng Guo, Bochao Zou, Junbao Zhuo, Huimin Ma|<http://arxiv.org/pdf/2508.08082v1>|[代码](https://github.com/zizheng-guo/ME-TST.); 提出了一种基于状态空间模型的微表情分析框架，通过视频级回归和时间状态转换机制，提高了微表情检测和识别...|
|📝 更新|RAPNet: A Receptive-Field Adaptive Convolutional Neural Network for Pansharpening|RAPNet：一种适用于全色锐化的感受野自适应卷积神经网络|Tao Tang, Chengxu Yang|<http://arxiv.org/pdf/2507.10461v2>|RAPNet通过内容自适应卷积和注意力机制，有效提升了图像融合的精度和细节表现。|
|📝 更新|GaussianFlowOcc: Sparse and Weakly Supervised Occupancy Estimation using Gaussian Splatting and Temporal Flow|高斯流占用估计：使用高斯散布和时序流进行稀疏和弱监督占用预测|Simon Boeder, Fabian Gigengack, Benjamin Risse|<http://arxiv.org/pdf/2502.17288v3>|提出了一种高效的稀疏三维高斯表示方法GaussianFlowOcc，通过估计高斯分布的时序流动，实现...|
|📝 更新|MambaFlow: A Mamba-Centric Architecture for End-to-End Optical Flow Estimation|MambaFlow：一种以Mamba为中心的端到端光流估计架构|Juntian Du, Yuan Sun, Zhihu Zhou, Pinyi Chen, Runzhe Zhang, Keji Mao|<http://arxiv.org/pdf/2503.07046v3>|首次将Mamba架构应用于光流估计，提出MambaFlow框架，通过PolyMamba和PulseM...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Sparsity Outperforms Low-Rank Projections in Few-Shot Adaptation|稀疏性在少量样本适应中超越低秩投影|Nairouz Mrabah, Nicolas Richet, Ismail Ben Ayed, Éric Granger|<http://arxiv.org/pdf/2504.12436v2>|提出稀疏优化框架，通过动态调整极少量参数，在少量样本适应新领域时减少过拟合并提高泛化能力。|
|🆕 发布|CTC Transcription Alignment of the Bullinger Letters: Automatic Improvement of Annotation Quality|《布尔linger信件的CTC转录对齐：注释质量的自动提升》|Marco Peer, Anna Scius-Bertrand, Andreas Fischer|<http://arxiv.org/pdf/2508.07904v1>|[代码](https://github.com/andreas-fischer-unifr/nntp.); 提出了一种基于CTC alignment的自训练方法，有效提升了历史手写文献的标注质量和识别性能。|
|🆕 发布|Forecasting Continuous Non-Conservative Dynamical Systems in SO(3)|预测SO(3)中的连续非保守动力系统|Lennart Bastian, Mohammad Rashed, Nassir Navab, Tolga Birdal|<http://arxiv.org/pdf/2508.07775v1>|[代码](https://github.com/bastianlb/forecasting-rotational-dynamics); 提出了一种基于神经控制微分方程的3D旋转轨迹预测方法，适用于包含非保守力的复杂动态系统。|
|🆕 发布|A Registration-Based Star-Shape Segmentation Model and Fast Algorithms|基于注册的星形分割模型与快速算法|Daoping Zhang, Xue-Cheng Tai, Lok Ming Lui|<http://arxiv.org/pdf/2508.07721v1>|提出了一种基于注册框架的星形分割模型，通过结合水平集表示和约束变形函数，实现了准确高效的星形目标提取...|
|📝 更新|Retuve: Automated Multi-Modality Analysis of Hip Dysplasia with Open Source AI|Retuve：基于开源人工智能的髋关节发育不良自动化多模态分析|Adam McArthur, Stephanie Wichuk, Stephen Burnside, Andrew Kirby, Alexander Scammon, Damian Sol, Abhilash Hareendranathan, Jacob L. Jaremko|<http://arxiv.org/pdf/2504.06422v2>|[代码](https://github.com/radoss-org/retuve); 提出开源框架Retuve，实现髋关节发育不良的自动化多模态分析，促进早期诊断与干预。|
|📝 更新|Global Compression Commander: Plug-and-Play Inference Acceleration for High-Resolution Large Vision-Language Models|全球压缩指挥官：用于高分辨率大型视觉-语言模型的无缝推理加速|Xuyang Liu, Ziming Wang, Junjie Chen, Yuhang Han, Yingyao Wang, Jiale Yuan, Jun Song, Linfeng Zhang .etc.|<http://arxiv.org/pdf/2501.05179v5>|[代码](https://github.com/xuyang-liu16/GlobalCom2.); 提出了一种利用全局缩略图指导局部裁剪压缩的高分辨率视觉语言模型加速方法，大幅降低了计算复杂度同时保持...|
|📝 更新|3D Gaussian Splatting Data Compression with Mixture of Priors|三维高斯散点数据压缩结合先验混合模型|Lei Liu, Zhenghao Chen, Dong Xu|<http://arxiv.org/pdf/2505.03310v2>|提出了一种结合超先验信息的混合先验策略，显著提升了3D场景建模数据的压缩效率。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|The Escalator Problem: Identifying Implicit Motion Blindness in AI for Accessibility|《自动扶梯问题：在人工智能无障碍性中识别隐性行动盲区》|Xiantao Zhang|<http://arxiv.org/pdf/2508.07989v1>|揭示了AI在识别连续运动方面的盲点，呼吁从语义识别转向物理感知，并提倡开发以用户安全为中心的新基准。|
|📝 更新|In-Situ Fine-Tuning of Wildlife Models in IoT-Enabled Camera Traps for Efficient Adaptation|物联网启用摄像头陷阱中的野生动物模型现场微调以实现高效适应|Mohammad Mehdi Rastikerdar, Jin Huang, Hui Guan, Deepak Ganesan|<http://arxiv.org/pdf/2409.07796v3>|提出了一种在资源受限的物联网设备上自主进行野生动物模型微调的方法，通过背景感知合成和漂移感知微调有效...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Evaluating structural uncertainty in accelerated MRI: are voxelwise measures useful surrogates?|评估加速MRI中的结构不确定性：像素级测量是否是有用的替代指标？|Luca L. C. Trautmann, Peter A. Wijeratne, Itamar Ronen, Ivor J. A. Simpson|<http://arxiv.org/pdf/2503.10527v2>|论文揭示了传统基于像素强度变化的MRI重建不确定性度量无法准确反映形态学变化，提出使用重建模式集合来...|
|📝 更新|L-FUSION: Laplacian Fetal Ultrasound Segmentation & Uncertainty Estimation|L-FUSION：拉普拉斯胎儿超声分割与不确定性估计|Johanna P. Müller, Robert Wright, Thomas G. Day, Lorenzo Venturini, Samuel F. Budd, Hadrien Reynaud, Joseph V. Hajnal, Reza Razavi .etc.|<http://arxiv.org/pdf/2503.05245v4>|提出L-FUSION框架，通过集成学习与基础模型实现胎儿超声精准分割及不确定性估计。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|IPBA: Imperceptible Perturbation Backdoor Attack in Federated Self-Supervised Learning|IPBA：联邦自监督学习中的不可感知扰动后门攻击|Jiayao Wang, Yang Song, Zhendong Zhao, Jiale Zhang, Qilin Wu, Junwu Zhu, Dongfang Zhao|<http://arxiv.org/pdf/2508.08031v1>|提出了一种针对联邦自监督学习的隐形后门攻击方法IPBA，有效克服了现有攻击方法的局限，增强了攻击性能...|
|🆕 发布|Adaptive Cache Enhancement for Test-Time Adaptation of Vision-Language Models|自适应缓存增强用于视觉语言模型测试时适应|Khanh-Binh Nguyen, Phuoc-Nguyen Bui, Hyunseung Choo, Duc Thanh Nguyen|<http://arxiv.org/pdf/2508.07570v1>|提出了一种自适应缓存增强框架，通过动态调整类别特定阈值，提高了视觉语言模型在分布偏移下的适应性和准确...|


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VOIDFace: A Privacy-Preserving Multi-Network Face Recognition With Enhanced Security|VOIDFace：一种具有增强安全性的隐私保护多网络人脸识别方法|Ajnas Muhammed, Iurri Medvedev, Nuno Gonçalves|<http://arxiv.org/pdf/2508.07960v1>|[代码](https://github.com/ajnasmuhammed89/VOIDFace); 提出了一种隐私保护的多人脸识别框架VOIDFace，通过视觉秘密共享技术消除数据复制需求并增强数据安...|
|📝 更新|Ethical Challenges in Computer Vision: Ensuring Privacy and Mitigating Bias in Publicly Available Datasets|计算机视觉中的伦理挑战：确保隐私和减轻公开可用数据集中的偏见|Ghalib Ahmed Tahir|<http://arxiv.org/pdf/2409.10533v4>|提出伦理框架，解决计算机视觉数据集隐私和偏见问题，促进符合社会价值观的AI发展。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Boosting Active Defense Persistence: A Two-Stage Defense Framework Combining Interruption and Poisoning Against Deepfake|增强主动防御持久性：一种结合中断与投毒的两阶段对抗深度伪造的防御框架|Hongrui Zheng, Yuezun Li, Liejun Wang, Yunfeng Diao, Zhiqing Guo|<http://arxiv.org/pdf/2508.07795v1>|[代码](https://github.com/vpsg-research/TSDF.); 提出双阶段防御框架TSDF，结合干扰和毒化策略，增强对抗深度伪造的持久防御能力。|
|🆕 发布|A Trustworthy Method for Multimodal Emotion Recognition|一种可靠的多模态情感识别方法|Junxiao Xue, Xiaozhen Liu, Jie Wang, Xuecheng Wu, Bin Wu|<http://arxiv.org/pdf/2508.07625v1>|提出了一种可靠的跨模态情感识别方法，通过不确定性估计提高预测置信度，实现了更准确和鲁棒的性能。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MedReasoner: Reinforcement Learning Drives Reasoning Grounding from Clinical Thought to Pixel-Level Precision|MedReasoner：强化学习驱动从临床思维到像素级精度的推理定位|Zhonghao Yan, Muxi Diao, Yuxuan Yang, Jiayuan Xu, Kaizhou Zhang, Ruoyan Jing, Lele Yang, Yanxi Liu .etc.|<http://arxiv.org/pdf/2508.08177v1>|提出UMRG任务和U-MRG-14K数据集，并引入MedReasoner框架，通过强化学习优化临床推...|
|🆕 发布|Integrating Task-Specific and Universal Adapters for Pre-Trained Model-based Class-Incremental Learning|将特定任务适配器和通用适配器集成到预训练模型基础的类增量学习中|Yan Wang, Da-Wei Zhou, Han-Jia Ye|<http://arxiv.org/pdf/2508.08165v1>|[代码](https://github.com/LAMDA-CL/ICCV2025-TUNA); 提出了一种结合任务特定和通用适配器的预训练模型增量学习方法，有效解决了新类学习与遗忘问题。|
|📝 更新|Decoupled Global-Local Alignment for Improving Compositional Understanding|解耦全局-局部对齐以提升组合理解能力|Xiaoxing Hu, Kaicheng Yang, Jun Wang, Haoran Xu, Ziyong Feng, Yupei Wang|<http://arxiv.org/pdf/2504.16801v2>|[代码](https://github.com/xiaoxing2001/DeGLA); 提出了一种解耦全局-局部对齐的框架DeGLA，通过自我蒸馏和新型对比损失提升了视觉语言模型的组合理解...|
|🆕 发布|Selective Contrastive Learning for Weakly Supervised Affordance Grounding|选择性对比学习用于弱监督功效性接地|WonJun Moon, Hyun Seok Seong, Jae-Pil Heo|<http://arxiv.org/pdf/2508.07877v1>|[代码](https://github.com/hynnsk/SelectiveCL.); 引入选择性原型和像素对比目标，自适应学习与功能相关的线索，提高了弱监督功能接地任务的准确性。|
|📝 更新|Learning Phonetic Context-Dependent Viseme for Enhancing Speech-Driven 3D Facial Animation|学习音素上下文相关视觉单元以增强基于语音驱动的三维面部动画|Hyung Kyu Kim, Hak Gu Kim|<http://arxiv.org/pdf/2507.20568v2>|[代码](https://cau-irislab.github.io/interspeech25); 提出了一种考虑语音上下文的损失函数，通过动态调整面部运动的重要性，实现了更平滑自然的3D面部动画。|
|🆕 发布|Collaborative Learning of Scattering and Deep Features for SAR Target Recognition with Noisy Labels|散射特征与深度特征协同学习在噪声标签下合成孔径雷达目标识别中的应用|Yimin Fu, Zhunga Liu, Dongxiu Guo, Longfei Wang|<http://arxiv.org/pdf/2508.07656v1>|提出了一种融合散射特征与深度特征的多模型学习框架，有效应对合成孔径雷达数据中的噪声标签问题。|
|🆕 发布|SOFA: Deep Learning Framework for Simulating and Optimizing Atrial Fibrillation Ablation|SOFA：模拟与优化心房颤动消融的深度学习框架|Yunsung Chung, Chanho Lim, Ghassan Bidaoui, Christian Massad, Nassir Marrouche, Jihun Hamm|<http://arxiv.org/pdf/2508.07621v1>|提出SOFA框架，通过模拟和优化消融策略预测并减少心房颤动复发风险。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks|《ODYSSEY：面向长周期任务的开源四足机器人探索与操作》|Kaijun Wang, Liqin Lu, Mingyu Liu, Jianuo Jiang, Zeju Li, Bolin Zhang, Wancai Zheng, Xinyi Yu .etc.|<http://arxiv.org/pdf/2508.08240v1>|[代码](https://kaijwang.github.io/odyssey.github.io); 提出了一种统一框架ODYSSEY，通过结合高级行动规划和低级全身控制，使四足机器人能在复杂环境中执行...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|TextInPlace: Indoor Visual Place Recognition in Repetitive Structures with Scene Text Spotting and Verification|《TextInPlace：在重复结构中利用场景文本检测与验证进行室内视觉场所识别》|Huaqi Tao, Bingxi Liu, Calvin Chen, Tingjun Huang, He Li, Jinqiang Cui, Hong Zhang|<http://arxiv.org/pdf/2503.06501v2>|[代码](https://github.com/HqiTao/TextInPlace.); 提出TextInPlace框架，利用场景文字识别改善室内重复结构中的视觉定位问题。|
|🆕 发布|Pindrop it! Audio and Visual Deepfake Countermeasures for Robust Detection and Fine Grained-Localization|“滴答声定位！音频与视觉深度伪造对策用于鲁棒检测与细微粒度定位”|Nicholas Klein, Hemlata Tak, James Fullwood, Krishna Regmi, Leonidas Spinoulas, Ganesh Sivaraman, Tianxiang Chen, Elie Khoury|<http://arxiv.org/pdf/2508.08141v1>|提出音频与视觉深度伪造检测与定位方法，在分类与时间定位任务中均取得优异表现。|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PCLVis: Visual Analytics of Process Communication Latency in Large-Scale Simulation|PCLVis：大规模模拟中进程通信延迟的可视化分析|Chongke Bi, Xin Gao, Baofeng Fu, Yuheng Zhao, Siming Chen, Ying Zhao, Lu Yang|<http://arxiv.org/pdf/2506.23257v2>|提出PCLVis框架，利用MPI通信数据帮助用户分析大规模模拟中的进程通信延迟问题。|
|📝 更新|Solving Zero-Shot 3D Visual Grounding as Constraint Satisfaction Problems|将零样本三维视觉定位问题视为约束满足问题求解|Qihao Yuan, Kailai Li, Jiaming Zhang|<http://arxiv.org/pdf/2411.14594v2>|[代码](https://asig-x.github.io/csvg_web.); 将3D视觉定位任务转化为约束满足问题，实现了无需监督学习的零样本定位，提升了准确性。|
|🆕 发布|AR-VRM: Imitating Human Motions for Visual Robot Manipulation with Analogical Reasoning|AR-VRM：利用类比推理模仿人类运动进行视觉机器人操控|Dejie Yang, Zijing Zhao, Yang Liu|<http://arxiv.org/pdf/2508.07626v1>|提出通过模仿人类动作关键点的方法，显著提升了视觉机器人操作在少量数据下的泛化能力。|
|🆕 发布|InterChart: Benchmarking Visual Reasoning Across Decomposed and Distributed Chart Information|InterChart：在分解和分布式图表信息上的视觉推理基准测试|Anirudh Iyengar Kaniyar Narayana Iyengar, Srija Mukhopadhyay, Adnan Qidwai, Shubhankar Singh, Dan Roth, Vivek Gupta|<http://arxiv.org/pdf/2508.07630v1>|提出InterChart基准，评估视觉语言模型在处理多个相关图表时的推理能力，揭示模型在复杂图表整合...|
|🆕 发布|Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents|“分解与构建：基于技能的视觉与语言导航代理的混合”|Tianyi Ma, Yue Zhang, Zehao Wang, Parisa Kordjamshidi|<http://arxiv.org/pdf/2508.07642v1>|提出SkillNav框架，通过分解导航为原子技能并动态选择适用技能，提升视觉语言导航在复杂环境下的泛...|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CATP: Contextually Adaptive Token Pruning for Efficient and Enhanced Multimodal In-Context Learning|CATP：上下文自适应标记剪枝以提高多模态即时学习的效率和效果|Yanshu Li, Jianjiang Yang, Zhennan Shen, Ligong Han, Haoyan Xu, Ruixiang Tang|<http://arxiv.org/pdf/2508.07871v1>|提出了一种针对多模态情境学习的无训练剪枝方法CATP，减少图像 tokens 的冗余，提升了模型效率...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Effortless Vision-Language Model Specialization in Histopathology without Annotation|无需标注的病理学中轻松实现视觉-语言模型专业化|Jingna Qiu, Nishanth Jain, Jonas Ammeling, Marc Aubreville, Katharina Breininger|<http://arxiv.org/pdf/2508.07835v1>|[代码](https://github.com/DeepMicroscopy/Annotation-free-VLM-specialization.); 提出了一种无需标注的视觉语言模型自适应方法，通过在特定领域继续预训练，有效提升了病理图像任务的性能。|
|🆕 发布|Semi-supervised Multiscale Matching for SAR-Optical Image|半监督多尺度匹配算法用于合成孔径雷达与光学图像融合|Jingze Gai, Changchun Li|<http://arxiv.org/pdf/2508.07812v1>|提出了一种半监督多尺度匹配方法，有效利用少量标注和大量未标注数据提升SAR-光学图像匹配性能。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Information Bottleneck-based Causal Attention for Multi-label Medical Image Recognition|基于信息瓶颈的因果注意力机制在多标签医学图像识别中的应用|Xiaoxiao Cui, Yiran Li, Kai He, Shanzhi Jiang, Mengli Xue, Wentao Li, Junhong Leng, Zhi Liu .etc.|<http://arxiv.org/pdf/2508.08069v1>|提出了一种基于信息瓶颈原理的因果注意力模型，有效过滤无关信息并提升多标签医学图像识别准确度。|
|📝 更新|Unintended Bias in 2D+ Image Segmentation and Its Effect on Attention Asymmetry|二维加图像分割中的无意偏见及其对注意力不对称性的影响|Zsófia Molnár, Gergely Szabó, András Horváth|<http://arxiv.org/pdf/2505.14105v2>|揭示了预训练模型在特定数据集上的无意偏见问题，并提出策略减轻这些偏见以提升模型解释性和可靠性。|
|🆕 发布|Safeguarding Generative AI Applications in Preclinical Imaging through Hybrid Anomaly Detection|通过混合异常检测保护临床前成像中的生成式人工智能应用|Jakub Binda, Valentina Paneta, Vasileios Eleftheriadis, Hongkyou Chung, Panagiotis Papadimitroulas, Neo Christopher Chung|<http://arxiv.org/pdf/2508.07923v1>|提出了一种混合异常检测框架，增强生成式AI在生物医学成像中的鲁棒性和实时质量控制。|
|🆕 发布|MIND: A Noise-Adaptive Denoising Framework for Medical Images Integrating Multi-Scale Transformer|《MIND：一种集成多尺度变换器的医学图像噪声自适应去噪框架》|Tao Tang, Chengxu Yang|<http://arxiv.org/pdf/2508.07817v1>|提出了一种融合多尺度卷积和Transformer架构的医疗图像自适应降噪模型，有效提升了图像质量和诊...|
|📝 更新|UltraAD: Fine-Grained Ultrasound Anomaly Classification via Few-Shot CLIP Adaptation|超细AD：通过少量样本CLIP适应进行细粒度超声异常分类|Yue Zhou, Yuan Bi, Wenjuan Tong, Wei Wang, Nassir Navab, Zhongliang Jiang|<http://arxiv.org/pdf/2506.19694v2>|提出UltraAD方法，通过少量超声样本实现病变定位与细粒度分类，提升医学图像异常检测精度。|
|📝 更新|A Steel Surface Defect Detection Method Based on Lightweight Convolution Optimization|基于轻量级卷积优化的钢铁表面缺陷检测方法|Cong Chen, Ming Chen, Hoileong Lee, Yan Li, Jiyang Yu|<http://arxiv.org/pdf/2507.15476v2>|提出了一种基于YOLOv9s和优化模块的钢表面缺陷检测框架，提高了小缺陷检测的准确性和模型效率。|
|🆕 发布|Adaptive Pseudo Label Selection for Individual Unlabeled Data by Positive and Unlabeled Learning|通过正样本和无标签学习对单个无标签数据的自适应伪标签选择|Takehiro Yamane, Itaru Tsuge, Susumu Saito, Ryoma Bise|<http://arxiv.org/pdf/2508.07548v1>|提出了一种自适应伪标签选择方法，通过正负样本学习有效选择医疗图像分割中的伪标签。|
|📝 更新|A New One-Shot Federated Learning Framework for Medical Imaging Classification with Feature-Guided Rectified Flow and Knowledge Distillation|一种基于特征引导修正流和知识蒸馏的新单次联邦学习框架用于医学影像分类|Yufei Ma, Hanwen Zhang, Qiya Yang, Guibo Luo, Yuesheng Zhu|<http://arxiv.org/pdf/2507.19045v2>|[代码](https://github.com/LMIAPC/one-shot-fl-medical.); 提出了一种改进的一回合联邦学习框架，通过特征引导的修正流模型和双层知识蒸馏，有效应对医疗影像分类中的...|
|🆕 发布|A DICOM Image De-identification Algorithm in the MIDI-B Challenge|MIDI-B挑战中的DICOM图像去识别算法|Hongzhu Jiang, Sihan Xie, Zhiyu Wan|<http://arxiv.org/pdf/2508.07538v1>|提出了一种DICOM图像去识别算法，通过多种方法有效移除个人识别信息，保护患者隐私同时保持数据实用性...|
|🆕 发布|Enhancing Reliability of Medical Image Diagnosis through Top-rank Learning with Rejection Module|通过带有拒绝模块的顶级学习增强医学影像诊断的可靠性|Xiaotong Ji, Ryoma Bise, Seiichi Uchida|<http://arxiv.org/pdf/2508.07528v1>|提出了一种集成拒绝模块的顶尖排名学习方法，有效识别并减轻异常值影响，提升医疗图像诊断的可靠性和准确性...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RSVLM-QA: A Benchmark Dataset for Remote Sensing Vision Language Model-based Question Answering|遥感视觉语言模型基础上的问题回答基准数据集：RSVLM-QA|Xing Zi, Jinghao Xiao, Yunxiao Shi, Xian Tao, Jun Li, Ali Braytee, Mukesh Prasad|<http://arxiv.org/pdf/2508.07918v1>|提出了RSVLM-QA数据集，通过双轨注释生成流程，提升了遥感视觉问答的标注丰富度和问题多样性。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CBDES MoE: Hierarchically Decoupled Mixture-of-Experts for Functional Modules in Autonomous Driving|CBDES混合专家模型：面向自动驾驶功能模块的层次解耦混合专家模型|Qi Xiang, Kunsong Shi, Zhigui Lin, Lei He|<http://arxiv.org/pdf/2508.07838v1>|提出了一种分层解耦的混合专家架构，有效提升了自动驾驶中多模态鸟瞰图感知的适应性和泛化能力。|
|🆕 发布|Decoupled Functional Evaluation of Autonomous Driving Models via Feature Map Quality Scoring|通过特征图质量评分实现自动驾驶模型解耦功能评估|Ludan Zhang, Sihan Wang, Yuqi Dai, Shuofei Qiao, Lei He|<http://arxiv.org/pdf/2508.07552v1>|提出了一种基于特征图质量评分的独立评估方法，有效提升了自动驾驶模型中功能模块的特征表示质量和整体性能...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Power Battery Detection|动力电池检测|Xiaoqi Zhao, Peiqian Cao, Lihe Zhang, Zonglei Feng, Hanqi Liu, Jiaming Zuo, Youwei Pang, Weisi Lin .etc.|<http://arxiv.org/pdf/2508.07797v1>|[代码](https://github.com/Xiaoqi-Zhao-DLUT/X-ray-PBD); 提出首个大规模电池检测基准PBD5K，并设计MDCNeXt模型，有效定位电池电极板端点，提升X射线图...|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Progressive Bird's Eye View Perception for Safety-Critical Autonomous Driving: A Comprehensive Survey|面向安全关键自动驾驶的渐进式鸟瞰感知：全面综述|Yan Gong, Naibang Wang, Jianli Lu, Xinyu Zhang, Yongsheng Gao, Jie Zhao, Zifan Huang, Haozhi Bai .etc.|<http://arxiv.org/pdf/2508.07560v1>|系统综述了鸟瞰视角感知在自动驾驶中的安全关键应用，并提出了未来研究方向。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 可解释视觉智能 (Explainable Visual Intelligence)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Prediction to Explanation: Multimodal, Explainable, and Interactive Deepfake Detection Framework for Non-Expert Users|从预测到解释：面向非专业人士的多模态、可解释、交互式深度伪造检测框架|Shahroz Tariq, Simon S. Woo, Priyanka Singh, Irena Irmalasari, Saakshi Gupta, Dev Gupta|<http://arxiv.org/pdf/2508.07596v1>|提出了一种多模态、可解释的深度伪造检测框架，通过集成视觉、语义和叙述层解释，提高了非专家用户在现实世...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PCA-Guided Autoencoding for Structured Dimensionality Reduction in Active Infrared Thermography|主成分分析引导的自编码网络用于主动红外热成像中的结构化降维|Mohammed Salah, Numan Saeed, Davor Svetinovic, Stefano Sfarra, Mohammed Omar, Yusra Abdulrahman|<http://arxiv.org/pdf/2508.07773v1>|引入PCA指导的自动编码框架，提升红外热成像数据降维的结构性，增强缺陷特征表现。|
|🆕 发布|Morphological Analysis of Semiconductor Microstructures using Skeleton Graphs|利用骨架图对半导体微结构进行形态学分析|Noriko Nitta, Rei Miyata, Naoto Oishi|<http://arxiv.org/pdf/2508.07850v1>|利用图卷积网络分析骨架图提取的拓扑特征，揭示了辐照角度对Ge表面形貌的显著影响。|

