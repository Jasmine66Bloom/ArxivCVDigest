## [UPDATED!] **2025-08-12** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OpenCUA: Open Foundations for Computer-Use Agents|开放CUA：计算机使用代理的开放基础|Xinyuan Wang, Bowen Wang, Dunjie Lu, Junlin Yang, Tianbao Xie, Junli Wang, Jiaqi Deng, Xiaole Guo .etc.|<http://arxiv.org/pdf/2508.09123v1>|提出OpenCUA框架，开放源代码以提升计算机使用代理的研究与性能。|
|📝 更新|LM-MCVT: A Lightweight Multi-modal Multi-view Convolutional-Vision Transformer Approach for 3D Object Recognition|LM-MCVT：一种用于三维物体识别的轻量级多模态多视角卷积-视觉变换器方法|Songsong Xiong, Hamidreza Kasaei|<http://arxiv.org/pdf/2504.19256v2>|提出了一种轻量级多模态多视角卷积视觉变换器网络，有效提升了机器人环境中的三维物体识别准确率。|
|🆕 发布|Calibration Attention: Instance-wise Temperature Scaling for Vision Transformers|校准注意力：实例级温度缩放用于视觉变换器|Wenhao Liang, Wei Emma Zhang, Lin Yue, Miao Xu, Olaf Maennel, Weitong Chen|<http://arxiv.org/pdf/2508.08547v1>|[代码](https://github.com/EagleAdelaide/CalibrationAttention-CalAttn-); 提出Calibration Attention方法，通过自适应实例温度缩放改善Vision Tran...|
|📝 更新|FUTransUNet-GradCAM: A Hybrid Transformer-U-Net with Self-Attention and Explainable Visualizations for Foot Ulcer Segmentation|FUTransUNet-GradCAM：一种结合自注意力机制和可解释视觉化的混合Transformer-U-Net用于足部溃疡分割|Akwasi Asare, Mary Sagoe, Justice Williams Asare|<http://arxiv.org/pdf/2508.03758v2>|提出了一种融合Transformer和U-Net的架构，用于精确分割足部溃疡，并通过Grad-CAM...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Argus Inspection: Do Multimodal Large Language Models Possess the Eye of Panoptes?|《阿尔戈斯之眼：多模态大型语言模型具备全景之眼吗？》|Yang Yao, Lingyu Li, Jiaxin Song, Chiyu Chen, Zhenqi He, Yixu Wang, Xin Wang, Tianle Gu .etc.|<http://arxiv.org/pdf/2506.14805v2>|提出Argus Inspection基准和Eye of Panoptes框架，评估MLLMs在细粒度...|
|🆕 发布|ColorGPT: Leveraging Large Language Models for Multimodal Color Recommendation|《ColorGPT：利用大型语言模型进行多模态色彩推荐》|Ding Xia, Naoto Inoue, Qianru Qiu, Kotaro Kikuchi|<http://arxiv.org/pdf/2508.08987v1>|利用大型语言模型的推理能力，ColorGPT在多模态色彩推荐任务中实现了高准确度和多样性。|
|🆕 发布|3DFroMLLM: 3D Prototype Generation only from Pretrained Multimodal LLMs|从预训练的多模态语言模型仅生成三维原型：3DFroMLLM|Noor Ahmed, Cameron Braunstein, Steffen Eger, Eddy Ilg|<http://arxiv.org/pdf/2508.08821v1>|提出了一种从预训练的多模态大语言模型直接生成3D对象原型的框架，无需额外训练数据或详细用户指导。|
|🆕 发布|SafeFix: Targeted Model Repair via Controlled Image Generation|SafeFix：通过控制图像生成进行定向模型修复|Ouyang Xu, Baoming Zhang, Ruiyu Mao, Yunhui Guo|<http://arxiv.org/pdf/2508.08701v1>|[代码](https://github.com/oxu2/SafeFix); 提出了一种生成针对性图像进行模型修复的方法，有效减少了深度学习模型在视觉识别中的系统性错误。|
|📝 更新|Zero-shot Emotion Annotation in Facial Images Using Large Multimodal Models: Benchmarking and Prospects for Multi-Class, Multi-Frame Approaches|使用大型多模态模型进行面部图像的零样本情感标注：多类、多帧方法的基准测试与展望|He Zhang, Xinyi Fu|<http://arxiv.org/pdf/2502.12454v2>|探索大模型零样本标注日常场景中面部情感，提升标注效率和准确度。|
|📝 更新|IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model|IRL-VLA：通过奖励世界模型训练视觉-语言-动作策略|Anqing Jiang, Yu Gao, Yiru Wang, Zhigang Sun, Shuo Wang, Yuwen Heng, Hao Sun, Shichen Tang .etc.|<http://arxiv.org/pdf/2508.06571v2>|提出了一种结合逆强化学习和自我指导的视觉语言动作模型，解决了自动驾驶中的性能局限和训练效率问题。|
|📝 更新|WSI-LLaVA: A Multimodal Large Language Model for Whole Slide Image|全切片图像的多模态大型语言模型：WSI-LLaVA|Yuci Liang, Xinheng Lyu, Wenting Chen, Meidan Ding, Jipeng Zhang, Xiangjian He, Song Wu, Xiaohan Xing .etc.|<http://arxiv.org/pdf/2412.02141v5>|提出WSI-LLaVA框架，通过三阶段训练提升全切片图像的形态学分析能力，显著提高病理诊断准确性。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Unsupervised Document and Template Clustering using Multimodal Embeddings|无监督文档与模板聚类：基于多模态嵌入的方法|Phillipe R. Sampaio, Helene Maxcici|<http://arxiv.org/pdf/2506.12116v2>|提出了一种利用多模态嵌入进行无监督文档和模板聚类的新方法，提高了文档分类的精细度。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OE3DIS: Open-Ended 3D Point Cloud Instance Segmentation|开放端三维点云实例分割：OE3DIS|Phuc D. A. Nguyen, Minh Luu, Anh Tran, Cuong Pham, Khoi Nguyen|<http://arxiv.org/pdf/2408.11747v2>|提出开放端3D点云实例分割方法，无需预定义类别名，提升自主性并引入新评价指标。|
|🆕 发布|Adaptive Confidence-Wise Loss for Improved Lens Structure Segmentation in AS-OCT|自适应置信度损失以提高光学相干断层扫描中的透镜结构分割精度|Zunjie Xiao, Xiao Wu, Tianhang Liu, Lingxi Hu, Yinling Zhang, Xiaoqing Zhang, Risa Higashita, Jiang Liu|<http://arxiv.org/pdf/2508.08705v1>|[代码](https://github.com/XiaoLing12138/Adaptive-Confidence-Wise-Loss.); 提出自适应置信度加权损失函数，优化了眼科手术中晶状体结构分割的精度和边界校准。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SCB-Dataset: A Dataset for Detecting Student and Teacher Classroom Behavior|学生与教师课堂行为检测数据集：SCB数据集|Fan Yang|<http://arxiv.org/pdf/2304.02488v7>|[代码](https://github.com/Whiffe/SCB-dataset); 构建了SCB-Dataset，包含学生和教师课堂行为数据，为人工智能在教育应用提供坚实基础。|
|🆕 发布|MADPromptS: Unlocking Zero-Shot Morphing Attack Detection with Multiple Prompt Aggregation|多提示聚合解锁零样本变形攻击检测：MADPromptS|Eduarda Caldeira, Fadi Boutros, Naser Damer|<http://arxiv.org/pdf/2508.08939v1>|提出了一种利用CLIP模型和多重文本提示聚合的零样本攻击检测方法，显著提升了对面部合成攻击的识别能力...|
|📝 更新|PAD-F: Prior-Aware Debiasing Framework for Long-Tailed X-ray Prohibited Item Detection|PAD-F：先验感知去偏框架用于长尾X射线禁运物品检测|Haoyu Wang, Renshuai Tao, Wei Wang, Yunchao Wei|<http://arxiv.org/pdf/2411.18078v3>|提出了一种针对X射线禁品检测的长尾分布问题，利用先验知识的Prior-Aware Debiasing...|
|🆕 发布|SHREC 2025: Retrieval of Optimal Objects for Multi-modal Enhanced Language and Spatial Assistance (ROOMELSA)|SHREC 2025：多模态增强语言与空间辅助下的最优对象检索（ROOMELSA）|Trong-Thuan Nguyen, Viet-Tham Huynh, Quang-Thuc Nguyen, Hoang-Phuc Nguyen, Long Le Bao, Thai Hoang Minh, Minh Nguyen Anh, Thang Nguyen Tien .etc.|<http://arxiv.org/pdf/2508.08781v1>|提出ROOMELSA基准，通过自然语言理解在复杂场景中精确检索3D模型。|
|📝 更新|From Pixels to Tokens: Revisiting Object Hallucinations in Large Vision-Language Models|从像素到标记：重新审视大型视觉语言模型中的对象幻觉问题|Yuying Shang, Xinyi Zeng, Yutao Zhu, Xiao Yang, Zhengwei Fang, Jingyuan Zhang, Jiawei Chen, Zinan Liu .etc.|<http://arxiv.org/pdf/2410.06795v2>|提出了一种名为PATCH的novel tuning策略，通过使用自适应虚拟token提取对象特征，有...|
|🆕 发布|ROD: RGB-Only Fast and Efficient Off-road Freespace Detection|ROD: 基于RGB的快速高效越野自由空间检测|Tong Sun, Hongliang Ye, Jilin Mei, Liang Chen, Fangzhou Zhao, Leiqiang Zong, Yu Hu|<http://arxiv.org/pdf/2508.08697v1>|提出了一种仅使用RGB图像的ROD方法，无需依赖LiDAR数据，实现了高效的离路自由空间检测。|
|🆕 发布|QueryCraft: Transformer-Guided Query Initialization for Enhanced Human-Object Interaction Detection|《QueryCraft：基于Transformer的查询初始化方法用于增强人-物交互检测》|Yuxiao Wang, Wolin Liang, Yu Lei, Weiying Xue, Nan Zhuang, Qi Liu|<http://arxiv.org/pdf/2508.08590v1>|提出了一种利用Transformer进行查询初始化的方法QueryCraft，通过语义先验和特征学习...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Masked Clustering Prediction for Unsupervised Point Cloud Pre-training|掩码聚类预测用于无监督点云预训练|Bin Ren, Xiaoshui Huang, Mengyuan Liu, Hong Liu, Fabio Poiesi, Nicu Sebe, Guofeng Mei|<http://arxiv.org/pdf/2508.08910v1>|[代码](https://github.com/Amazingren/maskclu.); 提出了一种结合遮蔽建模和聚类学习的无监督点云预训练方法MaskClu，有效学习丰富的点云语义特征。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Parametric Bi-Directional Curvature-Based Framework for Image Artifact Classification and Quantification|参数化双向曲率基础上的图像伪迹分类与量化框架|Diego Frias|<http://arxiv.org/pdf/2508.08824v1>|提出了一种基于图像方向曲率的评估框架，用于准确分类和量化图像退化类型。|
|🆕 发布|Revisiting Efficient Semantic Segmentation: Learning Offsets for Better Spatial and Class Feature Alignment|重新审视高效语义分割：学习偏移量以实现更好的空间和类特征对齐|Shi-Chen Zhang, Yunheng Li, Yu-Huan Wu, Qibin Hou, Ming-Ming Cheng|<http://arxiv.org/pdf/2508.08811v1>|提出了一种学习特征和类别偏移的双分支网络，有效解决了像素级分类中的特征与类别表示不匹配问题。|
|📝 更新|SynFER: Towards Boosting Facial Expression Recognition with Synthetic Data|合成数据增强的面部表情识别：SynFER方法研究|Xilin He, Cheng Luo, Xiaole Xian, Bing Li, Muhammad Haris Khan, Zongyuan Ge, Weicheng Xie, Siyang Song .etc.|<http://arxiv.org/pdf/2410.09865v3>|提出了一种生成合成面部表情图像数据的新框架，通过语义引导和伪标签生成技术，有效提升了面部表情识别模型...|
|🆕 发布|Training Kindai OCR with parallel textline images and self-attention feature distance-based loss|利用并行文本行图像和基于自注意力特征距离的损失训练Kindai OCR|Anh Le, Asanobu Kitamoto|<http://arxiv.org/pdf/2508.08537v1>|利用并行文本行图像和基于自注意力特征的距离损失函数，有效提升历史文档OCR识别准确率。|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ViStoryBench: Comprehensive Benchmark Suite for Story Visualization|ViStoryBench：故事可视化全面基准测试套件|Cailin Zhuang, Ailin Huang, Wei Cheng, Jingwei Wu, Yaoqi Hu, Jiaqi Liao, Hongyuan Wang, Xinyao Liao .etc.|<http://arxiv.org/pdf/2505.24862v3>|提出ViStoryBench，全面评估故事可视化模型的多样叙事结构、视觉风格和角色设置。|
|📝 更新|Un-EVIMO: Unsupervised Event-Based Independent Motion Segmentation|无监督事件驱动的独立运动分割：Un-EVIMO|Ziyun Wang, Jinyuan Guo, Kostas Daniilidis|<http://arxiv.org/pdf/2312.00114v2>|提出了一种无监督的事件相机独立运动分割框架，通过几何约束生成伪标签，无需标注数据即可有效处理多个运动...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Euclid Quick Data Release (Q1). Active galactic nuclei identification using diffusion-based inpainting of Euclid VIS images|欧几里得快速数据发布（Q1）。基于扩散填充的欧几里得可见光图像活动星系核识别|Euclid Collaboration, G. Stevens, S. Fotopoulou, M. N. Bremer, T. Matamoro Zatarain, K. Jahnke, B. Margalef-Bentabol, M. Huertas-Company .etc.|<http://arxiv.org/pdf/2503.15321v2>|提出了一种利用扩散模型从单张Euclid VIS图像中识别AGN和QSO的新方法，通过重建中心光分布...|
|🆕 发布|Turbo-VAED: Fast and Stable Transfer of Video-VAEs to Mobile Devices|"Turbo-VAED：视频变分自编码器在移动设备上的快速与稳定迁移"|Ya Zou, Jingfeng Yao, Siyuan Yu, Shuai Zhang, Wenyu Liu, Xinggang Wang|<http://arxiv.org/pdf/2508.09136v1>|[代码](https://github.com/hustvl/Turbo-VAED.); 提出了一种高效的移动设备视频VAE解码器 Turbo-VAED，通过优化网络结构和训练方法，显著提升...|
|🆕 发布|Towards Perfection: Building Inter-component Mutual Correction for Retinex-based Low-light Image Enhancement|迈向完美：为基于Retinex的弱光图像增强构建组件间相互校正机制|Luyang Cao, Han Xu, Jian Zhang, Lei Qi, Jiayi Ma, Yinghuan Shi, Yang Gao|<http://arxiv.org/pdf/2508.09009v1>|提出了一种新型Inter-correction Retinex模型，有效减少分解残差，提升低光照图像...|
|🆕 发布|DiffPhysCam: Differentiable Physics-Based Camera Simulation for Inverse Rendering and Embodied AI|DiffPhysCam：基于可微分物理的相机模拟技术在逆向渲染与具身人工智能中的应用|Bo-Hsun Chen, Nevindu M. Batagoda, Dan Negrut|<http://arxiv.org/pdf/2508.08831v1>|DiffPhysCam通过模拟真实相机成像过程并支持梯度优化，提升了机器人视觉感知和场景重建的性能。|
|🆕 发布|TARA: Token-Aware LoRA for Composable Personalization in Diffusion Models|TARA：面向扩散模型组合个性化中的标记感知LoRA方法|Yuqi Peng, Lingtao Zheng, Yufeng Yang, Yi Huang, Mingfu Yan, Jianzhuang Liu, Shifeng Chen|<http://arxiv.org/pdf/2508.08812v1>|[代码](https://github.com/YuqiPeng77/TARA.); 提出Token-Aware LoRA解决多概念生成中的视觉特征干扰问题，通过独立训练模块实现无训练组...|
|🆕 发布|Exploring Palette based Color Guidance in Diffusion Models|探索基于调色板的颜色引导在扩散模型中的应用|Qianru Qiu, Jiafeng Mao, Xueting Wang|<http://arxiv.org/pdf/2508.08754v1>|引入颜色调色板指导机制，提升了对图像整体色彩方案的精确控制能力。|
|🆕 发布|Subjective and Objective Quality Assessment of Banding Artifacts on Compressed Videos|压缩视频条带伪影的主观与客观质量评估|Qi Zheng, Li-Heng Chen, Chenlong He, Neil Berkbeck, Yilin Wang, Balu Adsumilli, Alan C. Bovik, Yibo Fan .etc.|<http://arxiv.org/pdf/2508.08700v1>|[代码](https://github.com/uniqzheng/CBAND.); 提出首个开放视频数据集LIVE-YT-Banding，并引入高效无参考视频质量评估模型CBAND，显...|
|📝 更新|From Slow Bidirectional to Fast Autoregressive Video Diffusion Models|从慢速双向到快速自回归视频扩散模型|Tianwei Yin, Qiang Zhang, Richard Zhang, William T. Freeman, Fredo Durand, Eli Shechtman, Xun Huang|<http://arxiv.org/pdf/2412.07772v3>|将双向注意力依赖的视频扩散模型改造为即时生成帧的自回归模型，并通过改进的蒸馏技术提升生成速度与质量。|
|📝 更新|GPSMamba: A Global Phase and Spectral Prompt-guided Mamba for Infrared Image Super-Resolution|全局相位与光谱提示引导的Mamba：用于红外图像超分辨率|Yongsong Huang, Tomo Miyazaki, Xiaofeng Liu, Shinichiro Omachi|<http://arxiv.org/pdf/2507.18998v3>|[代码](https://github.com/yongsongH/GPSMamba.); 提出了一种融合全局相位和频谱提示的Mamba框架，有效提升了红外图像超分辨率性能。|
|📝 更新|A Survey on All-in-One Image Restoration: Taxonomy, Evaluation and Future Trends|《一体化图像修复综述：分类、评估与未来趋势》|Junjun Jiang, Zengyuan Zuo, Gang Wu, Kui Jiang, Xianming Liu|<http://arxiv.org/pdf/2410.15067v3>|[代码](https://github.com/Harbinzzy/All-in-One-Image-Restoration-Survey.); 系统梳理了统一框架下的全功能图像复原方法，分类现有技术并指导未来研究方向。|
|🆕 发布|Unlocking the Potential of Diffusion Priors in Blind Face Restoration|解锁扩散先验在盲目人脸修复中的潜力|Yunqi Miao, Zhiyu Qu, Mingqi Gao, Changrui Chen, Jifei Song, Jungong Han, Jiankang Deng|<http://arxiv.org/pdf/2508.08556v1>|提出FLIPNET网络，通过双模式训练解决盲人脸复原中扩散先验模型与实际退化图像间的差距问题。|
|🆕 发布|Hybrid Long and Short Range Flows for Point Cloud Filtering|混合长短期流用于点云滤波|Dasith de Silva Edirimuni, Xuequan Lu, Ajmal Saeed Mian, Lei Wei, Gang Li, Scott Schaefer, Ying He|<http://arxiv.org/pdf/2508.08542v1>|提出了一种结合短程和长程信息过滤轨迹的点云去噪方法，有效解决了点云去噪中的聚类和噪声保留问题。|
|📝 更新|A Data-driven Loss Weighting Scheme across Heterogeneous Tasks for Image Denoising|异构任务间的数据驱动损失加权方案用于图像去噪|Xiangyu Rui, Xiangyong Cao, Xile Zhao, Deyu Meng, Michael K. NG|<http://arxiv.org/pdf/2301.06081v3>|提出了一种数据驱动的损失加权方案，通过训练参数化的权重函数优化异质任务下的图像去噪效果。|
|📝 更新|Enhancing Wide-Angle Image Using Narrow-Angle View of the Same Scene|使用同一场景的窄角视图增强广角图像|Hussain Md. Safwan, Mahbub Islam Mahim|<http://arxiv.org/pdf/2504.09455v3>|提出了一种结合窄角镜头细节的宽角图像增强方法，通过GAN模型和注意力机制实现图像质量参数的迁移。|
|📝 更新|SPIE: Semantic and Structural Post-Training of Image Editing Diffusion Models with AI feedback|SPIE：基于AI反馈的图像编辑扩散模型语义与结构后训练|Elior Benarous, Yilun Du, Heng Yang|<http://arxiv.org/pdf/2504.12833v2>|提出SPIE方法，通过在线强化学习使图像编辑模型更符合用户指令和输入图像一致性。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer|无训练的文本引导颜色编辑：基于多模态扩散变换器|Zixin Yin, Xili Dai, Ling-Hao Chen, Deyu Zhou, Jianan Wang, Duomin Wang, Gang Yu, Lionel M. Ni .etc.|<http://arxiv.org/pdf/2508.09131v1>|提出了一种无需训练的文本引导色彩编辑方法，通过多模态扩散变换器实现了精确且一致的色彩调整。|
|🆕 发布|VertexRegen: Mesh Generation with Continuous Level of Detail|顶点再生：具有连续细节级别的网格生成|Xiang Zhang, Yawar Siddiqui, Armen Avetisyan, Chris Xie, Jakob Engel, Henry Howard-Jenkins|<http://arxiv.org/pdf/2508.09062v1>|VertexRegen通过逆向边坍缩学习生成连续细节级别的网格，实现任意时刻生成有效网格。|
|📝 更新|TIDE : Temporal-Aware Sparse Autoencoders for Interpretable Diffusion Transformers in Image Generation|TIDE：面向图像生成的时序感知稀疏自动编码器解释性扩散变换器|Victor Shea-Jay Huang, Le Zhuo, Yi Xin, Zhaokai Wang, Fu-Yun Wang, Yuchi Wang, Renrui Zhang, Peng Gao .etc.|<http://arxiv.org/pdf/2503.07050v2>|提出TIDE框架，通过提取 interpretable 特征增强DiTs模型的生成质量和控制性。|
|🆕 发布|Spatial-Temporal Multi-Scale Quantization for Flexible Motion Generation|空间时间多尺度量化用于灵活运动生成|Zan Wang, Jingze Zhang, Yixin Chen, Baoxiong Jia, Wei Liang, Siyuan Huang|<http://arxiv.org/pdf/2508.08991v1>|提出多尺度量化方法MSQ，通过时空维度压缩运动序列，增强复杂运动建模与生成灵活性。|
|📝 更新|Fancy123: One Image to High-Quality 3D Mesh Generation via Plug-and-Play Deformation|Fancy123：通过即插即用形变实现单张图像到高质量三维网格生成的技术|Qiao Yu, Xianzhi Li, Yuan Tang, Xu Han, Long Hu, Yixue Hao, Min Chen|<http://arxiv.org/pdf/2411.16185v2>|[代码](https://github.com/YuQiao0303/Fancy123); 提出Fancy123方法，通过增强模块和反投影技术，从单张图片生成高质量3D网格。|
|📝 更新|3DFacePolicy: Audio-Driven 3D Facial Animation Based on Action Control|基于动作控制的音频驱动三维面部动画：3DFacePolicy|Xuanmeng Sha, Liyun Zhang, Tomohiro Mashita, Naoya Chiba, Yuki Uranishi|<http://arxiv.org/pdf/2409.10848v2>|提出了一种基于“动作”控制的三维面部动画生成方法，通过预测动作序列实现自然流畅的动画效果。|
|🆕 发布|Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering|基于文本条件的状态空间模型用于域泛化的变化检测视觉问答|Elman Ghazaei, Erchan Aptoula|<http://arxiv.org/pdf/2508.08974v1>|[代码](https://github.com/Elman295/TCSSM.); 提出了一种融合文本信息的统一状态空间模型，有效解决了视觉问答中的领域迁移问题。|
|🆕 发布|TaoCache: Structure-Maintained Video Generation Acceleration|TaoCache：结构保持的视频生成加速|Zhentao Fan, Zongzuo Wang, Weiwei Zhang|<http://arxiv.org/pdf/2508.08978v1>|提出了一种无需训练的缓存策略TaoCache，通过预测模型噪声输出在保持高分辨率结构的同时实现视频生...|
|🆕 发布|Lay2Story: Extending Diffusion Transformers for Layout-Togglable Story Generation|《Lay2Story：扩展扩散变换器以实现布局切换式故事生成》|Ao Ma, Jiasong Feng, Ke Cao, Jing Wang, Yun Wang, Quanwei Zhang, Zhanjie Zhang|<http://arxiv.org/pdf/2508.08949v1>|提出Layout-Togglable Storytelling任务，通过布局条件增强故事生成的一致性...|
|📝 更新|PointDreamer: Zero-shot 3D Textured Mesh Reconstruction from Colored Point Cloud|《PointDreamer：从彩色点云进行零样本3D纹理网格重建》|Qiao Yu, Xianzhi Li, Yuan Tang, Xu Han, Jinfeng Xu, Long Hu, Min Chen|<http://arxiv.org/pdf/2406.15811v3>|[代码](https://github.com/YuQiao0303/PointDreamer.); PointDreamer通过创新的2D扩散模型和Non-Border-First策略，实现了从彩色点...|
|📝 更新|Cut2Next: Generating Next Shot via In-Context Tuning|Cut2Next：通过上下文调整生成下一帧图像|Jingwen He, Hongbo Liu, Jiajun Li, Ziqi Huang, Yu Qiao, Wanli Ouyang, Ziwei Liu|<http://arxiv.org/pdf/2508.08244v2>|提出了一种基于Diffusion Transformer的Next Shot Generation框...|
|🆕 发布|Preview WB-DH: Towards Whole Body Digital Human Bench for the Generation of Whole-body Talking Avatar Videos|面向全身数字人类基准的预览WB-DH：全身对话头像视频生成的探索|Chaoyi Wang, Yifan Yang, Jun Pei, Lijie Xia, Jianpo Liu, Xiaobing Yuan, Xinhan Di|<http://arxiv.org/pdf/2508.08891v1>|[代码](https://github.com/deepreasonings/WholeBodyBenchmark.); 提出了WB-DH全身体数字人基准数据集，用于评估全身动画化虚拟形象的生成质量。|
|🆕 发布|Identity-Preserving Aging and De-Aging of Faces in the StyleGAN Latent Space|保持身份特征的面部老化与逆老化：在StyleGAN潜在空间中的研究|Luis S. Luevano, Pavel Korshunov, Sebastien Marcel|<http://arxiv.org/pdf/2508.08808v1>|提出了一种在StyleGAN2潜空间中通过简单向量模型编辑实现面部年龄变换，同时保持身份特征的方法。|
|📝 更新|Style transfer between Microscopy and Magnetic Resonance Imaging via Generative Adversarial Network in small sample size settings|通过小样本设置下的生成对抗网络实现显微镜图像与磁共振成像的风格迁移|Monika Pytlarz, Adrian Onicas, Alessandro Crimi|<http://arxiv.org/pdf/2310.10414v3>|首次利用条件生成对抗网络实现脑部MRI到显微组织图像的跨模态转换，无需活检即可进行病理分析。|
|🆕 发布|DiffPose-Animal: A Language-Conditioned Diffusion Framework for Animal Pose Estimation|动物姿态估计的语言条件扩散框架：DiffPose-Animal|Tianyu Xiong, Dayi Tan, Wei Tian|<http://arxiv.org/pdf/2508.08783v1>|提出了一种基于扩散模型和大型语言模型的动物姿态估计方法，通过语义引导和逐步细化提高了多样物种下的估计...|
|📝 更新|Gotta Hear Them All: Towards Sound Source Aware Audio Generation|" gotta hear them all:面向声源感知的音频生成方法探究"|Wei Guo, Heng Wang, Jianbo Ma, Weidong Cai|<http://arxiv.org/pdf/2411.15447v4>|提出Sound Source-Aware Audio生成器，通过视觉检测和跨模态翻译感知局部声源，实...|
|🆕 发布|Yan: Foundational Interactive Video Generation|《基础交互式视频生成》|Yan Team|<http://arxiv.org/pdf/2508.08601v1>|[代码](https://greatx3.github.io/Yan); 提出Yan框架，实现实时互动视频生成与编辑，融合多模态生成与细粒度控制。|
|📝 更新|Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation|全方位效应：统一且空间可控的视觉效果生成|Fangyuan Mao, Aiming Hao, Jintao Chen, Dongxia Liu, Xiaokun Feng, Jiashu Zhu, Meiqi Wu, Chubin Chen .etc.|<http://arxiv.org/pdf/2508.07981v2>|提出了Omni-Effects框架，实现了统一且空间可控的视觉效果生成，解决了多效果集成和空间控制难...|
|📝 更新|Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation|“Stand-In：一种轻量级且即插即用的视频生成身份控制方法”|Bowen Xue, Qixin Yan, Wenjing Wang, Hao Liu, Chen Li|<http://arxiv.org/pdf/2508.07901v2>|提出了一种轻量级视频生成框架Stand-In，通过少量参数实现高效的身份控制。|
|📝 更新|Context as Memory: Scene-Consistent Interactive Long Video Generation with Memory Retrieval|"上下文即记忆：基于记忆检索的场景一致交互式长视频生成"|Jiwen Yu, Jianhong Bai, Yiran Qin, Quande Liu, Xintao Wang, Pengfei Wan, Di Zhang, Xihui Liu|<http://arxiv.org/pdf/2506.03141v2>|[代码](https://context-as-memory.github.io/.); 提出Context-as-Memory方法，利用历史上下文作为视频生成的记忆，通过选取相关帧显著提升...|
|🆕 发布|RealisMotion: Decomposed Human Motion Control and Video Generation in the World Space|《RealisMotion：世界空间中的人体运动分解控制与视频生成》|Jingyun Liang, Jingkai Zhou, Shikai Li, Chenjie Cao, Lei Sun, Yichen Qian, Weihua Chen, Fan Wang|<http://arxiv.org/pdf/2508.08588v1>|提出了一种分解人类运动控制和视频生成的框架，实现了对人物、背景、轨迹和动作的独立控制，提高了视频质量...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CulturalFrames: Assessing Cultural Expectation Alignment in Text-to-Image Models and Evaluation Metrics|文化框架：评估文本到图像模型及其评价指标中的文化期望一致性|Shravan Nayak, Mehar Bhatia, Xiaofeng Zhang, Verena Rieser, Lisa Anne Hendricks, Sjoerd van Steenkiste, Yash Goyal, Karolina Stańczak .etc.|<http://arxiv.org/pdf/2506.08835v2>|提出CulturalFrames基准，首次量化文本到图像模型在文化预期一致性上的表现，揭示现有评价标...|
|🆕 发布|Efficient motion-based metrics for video frame interpolation|基于运动的高效视频帧插值度量方法|Conall Daly, Darren Ramsook, Anil Kokaram|<http://arxiv.org/pdf/2508.09078v1>|提出了一种基于运动场变化的视频帧插值质量评估指标，提高了评估效率和与人类视觉感知的契合度。|
|🆕 发布|When Deepfakes Look Real: Detecting AI-Generated Faces with Unlabeled Data due to Annotation Challenges|当深度伪造看起来真实：由于标注挑战，使用无标签数据检测AI生成的面部|Zhiqiang Yang, Renshuai Tao, Xiaolong Zheng, Guodong Yang, Chunjie Zhang|<http://arxiv.org/pdf/2508.09022v1>|提出DPGNet方法，利用无标签数据解决深度伪造人脸检测的标注难题。|
|📝 更新|HiMat: DiT-based Ultra-High Resolution SVBRDF Generation|HiMat：基于DiT的超高分辨率SVBRDF生成|Zixiong Wang, Jian Yang, Yiwei Hu, Milos Hasan, Beibei Wang|<http://arxiv.org/pdf/2508.07011v2>|提出HiMat框架，通过轻量级CrossStitch模块高效生成4K分辨率SVBRDF，保持不同地图...|
|🆕 发布|Learning Generalizable and Efficient Image Watermarking via Hierarchical Two-Stage Optimization|通过分层两阶段优化学习泛化性和高效性的图像水印技术|Ke Liu, Xuanhan Wang, Qilong Zhang, Lianli Gao, Jingkuan Song|<http://arxiv.org/pdf/2508.08667v1>|提出了一种分层两阶段优化方法HiWL，实现了图像水印的不可见性、鲁棒性和广泛应用性。|
|📝 更新|REDUCIO! Generating 1K Video within 16 Seconds using Extremely Compressed Motion Latents|"REDUCIO! 在16秒内使用极度压缩的运动潜在变量生成1K视频"|Rui Tian, Qi Dai, Jianmin Bao, Kai Qiu, Yifan Yang, Chong Luo, Zuxuan Wu, Yu-Gang Jiang|<http://arxiv.org/pdf/2411.13552v3>|[代码](https://github.com/microsoft/Reducio-VAE); 提出了一种高效压缩运动潜在空间的视频生成方法，大幅提升了视频生成模型的训练和推理效率。|
|📝 更新|Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control|“遵循你的形状：通过轨迹引导的区域控制实现形状感知图像编辑”|Zeqian Long, Mingzhe Zheng, Kunyu Feng, Xinhua Zhang, Hongyu Liu, Harry Yang, Linfeng Zhang, Qifeng Chen .etc.|<http://arxiv.org/pdf/2508.08134v2>|提出了一种无需训练和遮罩的图像编辑框架，通过轨迹引导精确控制对象形状变换，同时保护非目标内容。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HumanOLAT: A Large-Scale Dataset for Full-Body Human Relighting and Novel-View Synthesis|人体全息重光照与新颖视角合成的大规模数据集HumanOLAT|Timo Teufel, Pulkit Gera, Xilong Zhou, Umar Iqbal, Pramod Rao, Jan Kautz, Vladislav Golyanik, Christian Theobalt|<http://arxiv.org/pdf/2508.09137v1>|介绍了HumanOLAT数据集，助力全身体数字人重光照与新颖视角渲染研究。|
|🆕 发布|Accelerated Volumetric Compression without Hierarchies: A Fourier Feature Based Implicit Neural Representation Approach|无需层次结构的加速体积压缩：基于傅里叶特征隐式神经表示方法|Leona Žůrková, Petr Strakoš, Michal Kravčenko, Tomáš Brzobohatý, Lubomír Říha|<http://arxiv.org/pdf/2508.08937v1>|提出了一种无需层次结构的傅里叶特征编码神经压缩方法，实现了体积数据的快速压缩和高效表示。|
|🆕 发布|A Robust Epipolar-Domain Regularization Algorithm for Light Field Depth Estimation|一种稳健的极线域正则化算法用于光场深度估计|Noor Islam S. Mohammad|<http://arxiv.org/pdf/2508.08900v1>|提出了一种结合光场视差信息和随机游走算法的轻量级深度估计方法，在保持低计算复杂度的同时实现竞争力准确...|
|🆕 发布|GaussianUpdate: Continual 3D Gaussian Splatting Update for Changing Environments|高斯更新：面向变化环境的连续三维高斯散点更新|Lin Zeng, Boming Zhao, Jiarui Hu, Xujie Shen, Ziqiang Dang, Hujun Bao, Zhaopeng Cui|<http://arxiv.org/pdf/2508.08867v1>|提出了一种结合3D高斯表示和持续学习的GaussianUpdate方法，有效更新场景变化并保持历史信...|
|🆕 发布|MonoPartNeRF:Human Reconstruction from Monocular Video via Part-Based Neural Radiance Fields|单目视频通过基于部位神经辐射场的人体重建：MonoPartNeRF|Yao Lu, Jiawei Li, Ming Jiang|<http://arxiv.org/pdf/2508.08798v1>|MonoPartNeRF通过结合部件分解和神经辐射场，实现了单目视频下人物重建的平滑过渡和遮挡恢复。|
|📝 更新|Deblur4DGS: 4D Gaussian Splatting from Blurry Monocular Video|《Deblur4DGS：从模糊的单目视频中实现四维高斯散点绘制》|Renlong Wu, Zhilu Zhang, Mingyang Chen, Zifei Yan, Wangmeng Zuo|<http://arxiv.org/pdf/2412.06424v2>|[代码](https://github.com/ZcsrenlongZ/Deblur4DGS.); 提出了一种基于3D Gaussian Splatting的高质量4D模型重建方法，有效解决了运动模糊...|
|🆕 发布|Superclass-Guided Representation Disentanglement for Spurious Correlation Mitigation|超类引导的表示解耦以减轻伪相关性的影响|Chenruo Liu, Hongjun Liu, Zeyu Lai, Yiqiu Shen, Chen Zhao, Qi Lei|<http://arxiv.org/pdf/2508.08570v1>|利用 superclass 信息的梯度引导注意力模型减少对伪特征的依赖，提升域泛化任务的鲁棒性。|


### 单视图三维推理 (Single-view 3D Inference)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|3D Human Mesh Estimation from Single View RGBD|从单视角RGBD图像估计三维人体网格|Ozhan Suat, Bedirhan Uguz, Batuhan Karagoz, Muhammed Can Keles, Emre Akbas|<http://arxiv.org/pdf/2508.08178v2>|提出了一种利用RGBD摄像头深度信息的三维人体网格估计方法，通过masked autoencoder...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Mem4D: Decoupling Static and Dynamic Memory for Dynamic Scene Reconstruction|《Mem4D：解耦静态与动态内存以实现动态场景重建》|Xudong Cai, Shuo Wang, Peng Wang, Yongcai Wang, Zhaoxin Fan, Wanting Li, Tianbao Zhang, Jianrong Tao .etc.|<http://arxiv.org/pdf/2508.07908v2>|提出 Mem4D 框架，分离静态与动态记忆，实现动态场景的高效精确重建。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Multi-Keypoint Affordance Representation for Functional Dexterous Grasping|多功能灵巧抓取的多关键点可用性表征|Fan Yang, Dongsheng Luo, Wenrui Chen, Jiacheng Lin, Junjie Cai, Kailun Yang, Zhiyong Li, Yaonan Wang|<http://arxiv.org/pdf/2502.20018v2>|[代码](https://github.com/PopeyePxx/MKA.); 提出多关键点亲和性表示方法，通过定位功能接触点直接编码任务驱动的抓握配置，实现视觉感知与灵巧抓握的紧...|
|🆕 发布|Think as Cardiac Sonographers: Marrying SAM with Left Ventricular Indicators Measurements According to Clinical Guidelines|按照临床指南将SAM与左心室指标测量相结合：像心脏超声医师一样思考|Tuo Liu, Qinghan Yang, Yu Zhang, Rongjun Ge, Yang Chen, Guangquan Zhou|<http://arxiv.org/pdf/2508.08566v1>|[代码](https://github.com/QC-LIU-1997/AutoSAME.); 提出AutoSAME框架，结合视觉基础模型与分割定位技术，提升心脏超声图像指标测量精度。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MUG: Pseudo Labeling Augmented Audio-Visual Mamba Network for Audio-Visual Video Parsing|多模态伪标签增强音频视觉Mamba网络用于音频视觉视频解析|Langyu Wang, Bingke Zhu, Yingying Chen, Yiyuan Zhang, Ming Tang, Jinqiao Wang|<http://arxiv.org/pdf/2507.01384v2>|[代码](https://github.com/WangLY136/MUG.); 提出了一种基于伪标签增强的音频视觉Mamba网络，有效提升了视频解析的段级和事件级预测准确性。|
|📝 更新|From Lab to Field: Real-World Evaluation of an AI-Driven Smart Video Solution to Enhance Community Safety|从实验室到现场：人工智能驱动的智能视频解决方案在提升社区安全性方面的实际评估|Shanle Yao, Babak Rahimi Ardabili, Armin Danesh Pazho, Ghazal Alinezhad Noghre, Christopher Neff, Lauren Bourque, Hamed Tabkhi|<http://arxiv.org/pdf/2312.02078v3>|该论文通过实际部署和评估AI智能视频解决方案，实现了将复杂计算机视觉输出转化为社区安全管理的实时可操...|
|🆕 发布|KFFocus: Highlighting Keyframes for Enhanced Video Understanding|关键帧聚焦：增强视频理解的关键帧凸显方法|Ming Nie, Chunwei Wang, Hang Xu, Li Zhang|<http://arxiv.org/pdf/2508.08989v1>|提出了一种视频理解增强方法KFFocus，通过智能识别关键帧降低计算需求同时保留关键信息。|
|📝 更新|Understanding Dynamic Scenes in Ego Centric 4D Point Clouds|理解以自我为中心的4D点云中的动态场景|Junsheng Huang, Shengyu Hao, Bocheng Hu, Gaoang Wang|<http://arxiv.org/pdf/2508.07251v2>|提出EgoDynamic4D基准，整合动态场景的4D数据与推理任务，提出端到端时空推理框架，提升 e...|
|🆕 发布|Frequency-Assisted Adaptive Sharpening Scheme Considering Bitrate and Quality Tradeoff|频率辅助的自适应锐化方案，考虑比特率和质量折衷|Yingxue Pang, Shijie Zhao, Haiqiang Wang, Gen Zhan, Junlin Li, Li Zhang|<http://arxiv.org/pdf/2508.08854v1>|提出了一种频率辅助的自适应锐化方案，平衡视频质量和比特率，有效预测最优锐化水平。|
|🆕 发布|Adaptive High-Frequency Preprocessing for Video Coding|自适应高频预处理视频编码|Yingxue Pang, Shijie Zhao, Junlin Li, Li Zhang|<http://arxiv.org/pdf/2508.08849v1>|提出了一种自适应高频预处理框架，通过学习优化视频编码中的比特率和画质平衡。|
|🆕 发布|Region-Adaptive Video Sharpening via Rate-Perception Optimization|基于率感知优化的区域自适应视频锐化|Yingxue Pang, Shijie Zhao, Mengxi Guo, Junlin Li, Li Zhang|<http://arxiv.org/pdf/2508.08794v1>|提出了一种区域自适应的视频锐化方法，通过感知优化实现视觉增强和比特率节省。|
|🆕 发布|Bridging the Gap: A Framework for Real-World Video Deepfake Detection via Social Network Compression Emulation|弥合差距：通过社交网络压缩仿真实现现实世界视频深度伪造检测的框架|Andrea Montibeller, Dasara Shullani, Daniele Baracchi, Alessandro Piva, Giulia Boato|<http://arxiv.org/pdf/2508.08765v1>|提出了一种模拟社交网络视频压缩的框架，有效提升了深伪检测器在现实世界场景下的泛化性能。|
|📝 更新|Adversarial Video Promotion Against Text-to-Video Retrieval|对抗性视频推广对抗文本到视频检索|Qiwei Tian, Chenhao Lin, Zhengyu Zhao, Qian Li, Shuai Liu, Chao Shen|<http://arxiv.org/pdf/2508.06964v2>|[代码](https://github.com/michaeltian108/ViPro.); 提出对抗性视频推广攻击方法ViPro，增强文本到视频检索的模态交互，提升攻击转移性。|
|📝 更新|What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning|“发生了什么以及可能发生了什么？面向过程感知视频表征学习的状态变化反事实”|Chi-Hsi Kung, Frangil Ramirez, Juhyung Ha, Yi-Ting Chen, David Crandall, Yi-Hsuan Tsai|<http://arxiv.org/pdf/2503.21055v6>|引入状态变化描述和状态变化反事实推理，提升视频表示学习对程序性活动的理解和预测能力。|
|🆕 发布|SelfHVD: Self-Supervised Handheld Video Deblurring for Mobile Phones|自监督手持视频去模糊方法：面向移动电话|Honglei Xu, Zhilu Zhang, Junjie Fan, Xiaohe Wu, Wangmeng Zuo|<http://arxiv.org/pdf/2508.08605v1>|[代码](https://github.com/cshonglei/SelfHVD.); 提出了一种自监督手持视频去模糊方法，通过视频中的清晰线索提高去模糊效果并减少训练与测试数据间的差距。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spatial Traces: Enhancing VLA Models with Spatial-Temporal Understanding|空间轨迹：通过空间-时间理解增强VLA模型|Maxim A. Patratskiy, Alexey K. Kovalev, Aleksandr I. Panov|<http://arxiv.org/pdf/2508.09032v1>|[代码](https://ampiromax.github.io/ST-VLA.); 整合空间与时间理解，通过视觉提示增强VLA模型在预测虚拟环境和现实世界中的智能体运动。|
|📝 更新|Box2Poly: Memory-Efficient Polygon Prediction of Arbitrarily Shaped and Rotated Text|Box2Poly：任意形状和旋转文本的内存高效多边形预测|Xuyang Chen, Dong Wang, Konrad Schindler, Mingwei Sun, Yongliang Wang, Nicolo Savioli, Liqiu Meng|<http://arxiv.org/pdf/2309.11248v2>|Box2Poly提出了一种高效的级联解码管道，通过迭代优化多边形预测，大幅提升内存效率并减少推理时间...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UniSTFormer: Unified Spatio-Temporal Lightweight Transformer for Efficient Skeleton-Based Action Recognition|统一时空轻量级Transformer：用于高效基于骨架的动作识别|Wenhan Wu, Zhishuai Guo, Chen Chen, Aidong Lu|<http://arxiv.org/pdf/2508.08944v1>|提出了一种统一的时空轻量级Transformer框架，通过整合注意力模块实现高效骨架动作识别，大幅降...|
|🆕 发布|Silicon Minds versus Human Hearts: The Wisdom of Crowds Beats the Wisdom of AI in Emotion Recognition|硅基思维与人心智慧：群体智慧在情感识别上胜过人工智能|Mustafa Akben, Vinayaka Gude, Haya Ajjan|<http://arxiv.org/pdf/2508.08830v1>|该研究显示集体智慧在情感识别上超越了个别大型语言模型，并证实了人机协作的潜力。|
|📝 更新|When Imitation Learning Outperforms Reinforcement Learning in Surgical Action Planning|当模仿学习在手术动作规划中超越强化学习|Maxence Boels, Harry Robertshaw, Thomas C Booth, Prokar Dasgupta, Alejandro Granados, Sebastien Ourselin|<http://arxiv.org/pdf/2507.05011v2>|比较模仿学习和强化学习在手术动作规划中的表现，发现模仿学习在预测手术动作方面优于强化学习。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AME: Aligned Manifold Entropy for Robust Vision-Language Distillation|AME：对齐流形熵用于稳健的视觉-语言蒸馏|Guiming Cao, Yuming Ou|<http://arxiv.org/pdf/2508.08644v1>|提出AME方法，通过在共享 manifold 上进行熵最小化，实现低数据条件下的稳健视觉语言知识蒸馏...|


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Neural Artistic Style and Color Transfer Using Deep Learning|使用深度学习的神经艺术风格与色彩迁移|Justin London|<http://arxiv.org/pdf/2508.08608v1>|提出了一种结合神经艺术风格与颜色迁移的方法，通过KL散度评估算法，优化图像风格与色彩匹配。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Half-Physics: Enabling Kinematic 3D Human Model with Physical Interactions|半物理：实现具有物理交互的动力学三维人体模型|Li Siyao, Yao Feng, Omid Taheri, Chen Change Loy, Michael J. Black|<http://arxiv.org/pdf/2507.23778v2>|引入“半物理”机制，将3D人体运动转化为物理仿真，实现无穿透和真实物体动态的实时物理交互。|
|🆕 发布|Deep Learning Models for Robust Facial Liveness Detection|深度学习模型在鲁棒面部活体检测中的应用|Oleksandr Kuznetsov, Emanuele Frontoni, Luca Romeo, Riccardo Rosati, Andrea Maranesi, Alessandro Muscatello|<http://arxiv.org/pdf/2508.09094v1>|提出深度学习模型通过纹理分析和反射性质识别真实人脸，有效抵御高级仿冒攻击。|
|🆕 发布|Scaling Learned Image Compression Models up to 1 Billion|将学习到的图像压缩模型扩展至十亿参数量级|Yuqi Li, Haotian Zhang, Li Li, Dong Liu, Feng Wu|<http://arxiv.org/pdf/2508.09075v1>|探索大规模图像压缩模型，提出 scaling 规律，实现最优压缩性能。|
|📝 更新|OSMa-Bench: Evaluating Open Semantic Mapping Under Varying Lighting Conditions|OSMa-Bench：在不同光照条件下评估开放语义映射|Maxim Popov, Regina Kurkova, Mikhail Iumanov, Jaafar Mahmoud, Sergey Kolyubin|<http://arxiv.org/pdf/2503.10331v2>|[代码](https://be2rlab.github.io/OSMa-Bench); 提出OSMa-Bench评估框架，针对室内不同光照条件下的语义映射算法进行性能分析。|
|🆕 发布|Multi-level Collaborative Distillation Meets Global Workspace Model: A Unified Framework for OCIL|多层次协作蒸馏遇见全局工作空间模型：面向OCIL的统一框架|Shibin Su, Guoqiang Liang, De Cheng, Shizhou Zhang, Lingyan Ran, Yanning Zhang|<http://arxiv.org/pdf/2508.08677v1>|提出了一种结合全局工作空间模型的多人协同蒸馏方法，有效平衡在线增量学习中的稳定性和适应性。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Achieving More with Less: Additive Prompt Tuning for Rehearsal-Free Class-Incremental Learning|以少胜多：无需复习的类增量学习中的加性提示调谐|Haoran Chen, Ping Wang, Zihan Zhou, Xu Zhang, Zuxuan Wu, Yu-Gang Jiang|<http://arxiv.org/pdf/2503.07979v2>|提出了一种高效的prompt-based类增量学习方法，通过直接修改注意力计算减少计算负担，无需优化...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Automatic and standardized surgical reporting for central nervous system tumors|中枢神经系统肿瘤的自动和标准化手术报告|David Bouget, Mathilde Gajda Faanes, Asgeir Store Jakola, Frederik Barkhof, Hilko Ardon, Lorenzo Bello, Mitchel S. Berger, Shawn L. Hervey-Jumper .etc.|<http://arxiv.org/pdf/2508.08916v1>|提出了一种基于深度学习的标准化术后中枢神经系统肿瘤报告流程，提高了术后评估和临床决策的效率。|
|📝 更新|Efficient Annotation of Medieval Charters|中世纪特许状的高效标注|Anguelos Nicolaou, Daniel Luger, Franziska Decker, Nicolas Renet, Vincent Christlein, Georg Vogeler|<http://arxiv.org/pdf/2306.14071v2>|提出了一种高效的注释方法，将中世纪文件分割简化为对象检测，优化了专家工作效率并提升了标注质量。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Automated Muscle and Fat Segmentation in Computed Tomography for Comprehensive Body Composition Analysis|计算机断层扫描中肌肉与脂肪自动分割技术用于全面身体成分分析|Yaqian Chen, Hanxue Gu, Yuwen Chen, Jichen Yang, Haoyu Dong, Joseph Y. Cao, Adrian Camarena, Christopher Mantyh .etc.|<http://arxiv.org/pdf/2502.09779v3>|提出了一种公开可用的全身组织自动分割模型，用于精确计算CT图像中的肌肉和脂肪含量。|
|🆕 发布|Transferable Model-agnostic Vision-Language Model Adaptation for Efficient Weak-to-Strong Generalization|迁移性模型无关的视觉-语言模型适配：用于高效弱到强泛化|Jihwan Park, Taehoon song, Sanghyeok Lee, Miso Choi, Hyunwoo J. Kim|<http://arxiv.org/pdf/2508.08604v1>|提出了一种轻量级适配器TransMiter，无需反向传播即可高效迁移视觉语言模型的适应知识。|
|📝 更新|StyleTailor: Towards Personalized Fashion Styling via Hierarchical Negative Feedback|《StyleTailor：通过分层负反馈实现个性化时尚搭配》|Hongbo Ma, Fei Shen, Hongbin Xu, Xiaoce Wang, Gang Xu, Jinkai Zheng, Liangqiong Qu, Ming Li|<http://arxiv.org/pdf/2508.06555v2>|提出StyleTailor框架，通过多级负反馈迭代优化，实现个性化时尚搭配与虚拟试穿。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UniConvNet: Expanding Effective Receptive Field while Maintaining Asymptotically Gaussian Distribution for ConvNets of Any Scale|UniConvNet：在保持渐近高斯分布的同时扩展任意尺度卷积网络的有效感受野|Yuhao Wang, Wei Xi|<http://arxiv.org/pdf/2508.09000v1>|[代码](https://github.com/ai-paperwithcode/UniConvNet.); 提出了一种通过组合小尺寸卷积核扩展有效感受野同时保持高斯分布的UniConvNet模型，实现了高效能...|
|📝 更新|Multiple Stochastic Prompt Tuning for Few-shot Adaptation under Extreme Domain Shift|多随机提示微调：在极域偏移下的少样本适应|Debarshi Brahma, Soma Biswas|<http://arxiv.org/pdf/2506.03926v2>|提出了一种针对极端领域偏移下少样本适应性的多随机提示调优框架MIST，有效提升CLIP模型在少量标注...|
|📝 更新|AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance|AMFT：通过元学习优化模仿-探索平衡来对齐大型语言模型推理器|Lixuan He, Jie Feng, Yong Li|<http://arxiv.org/pdf/2508.06944v2>|[代码](https://github.com/hlxtsyj/AMFT.); 提出了一种自适应元微调算法，动态平衡语言模型训练中的模仿与探索，实现了推理任务的新突破。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PC-SRGAN: Physically Consistent Super-Resolution Generative Adversarial Network for General Transient Simulations|PC-SRGAN：面向通用瞬时模拟的物理一致性超分辨率生成对抗网络|Md Rakibul Hasan, Pouria Behnoudfar, Dan MacKinlay, Thomas Poulet|<http://arxiv.org/pdf/2505.06502v3>|[代码](https://github.com/hasan-rakibul/PC-SRGAN.); 提出PC-SRGAN方法，通过确保物理一致性提升图像分辨率，适用于科学模拟。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Addressing Bias in VLMs for Glaucoma Detection Without Protected Attribute Supervision|《在无需保护属性监督的情况下解决用于青光眼检测的视觉语言模型的偏见问题》|Ahsan Habib Akash, Greg Murray, Annahita Amireskandari, Joel Palko, Carol Laxson, Binod Bhattarai, Prashnna Gyawali|<http://arxiv.org/pdf/2508.09087v1>|提出了一种无标签的属性无关去偏方法，通过自适应针对最难样本，减少自动青光眼筛查中的群体差异。|
|🆕 发布|ALFred: An Active Learning Framework for Real-world Semi-supervised Anomaly Detection with Adaptive Thresholds|ALFred：一种面向现实世界自适应阈值半监督异常检测的主动学习框架|Shanle Yao, Ghazal Alinezhad Noghre, Armin Danesh Pazho, Hamed Tabkhi|<http://arxiv.org/pdf/2508.09058v1>|提出了一种自适应阈值的主动学习框架，通过实时选择关键数据进行标注，提高了视频异常检测在动态环境中的适...|
|📝 更新|SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience|SEAgent：具有自主经验学习能力的自演化计算机使用代理|Zeyi Sun, Ziyu Liu, Yuhang Zang, Yuhang Cao, Xiaoyi Dong, Tong Wu, Dahua Lin, Jiaqi Wang|<http://arxiv.org/pdf/2508.04700v2>|SEAgent通过自主经验学习，使计算机使用代理能自我进化以掌握新软件，大幅提升任务成功率。|
|📝 更新|Mjölnir: A Deep Learning Parametrization Framework for Global Lightning Flash Density|“mjölnir：一种用于全球闪电闪光密度参数化的深度学习框架”|Minjong Cheon|<http://arxiv.org/pdf/2504.19822v3>|提出Mjolnir框架，利用深度学习模拟全球闪电密度，实现高精度预测。|
|🆕 发布|DocThinker: Explainable Multimodal Large Language Models with Rule-based Reinforcement Learning for Document Understanding|DocThinker：基于规则强化学习的可解释多模态大型语言模型在文档理解中的应用|Wenwen Yu, Zhibo Yang, Yuliang Liu, Xiang Bai|<http://arxiv.org/pdf/2508.08589v1>|[代码](https://github.com/wenwenyu/DocThinker.); 提出DocThinker，通过规则强化学习实现文档理解的动态推理和可解释性。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|UnrealZoo: Enriching Photo-realistic Virtual Worlds for Embodied AI|《UnrealZoo：为具身人工智能丰富照片级真实感的虚拟世界》|Fangwei Zhong, Kui Wu, Churan Wang, Hao Chen, Hai Ci, Zhoujun Li, Yizhou Wang|<http://arxiv.org/pdf/2412.20977v2>|提出UnrealZoo，构建超百个逼真3D虚拟世界，提升Embodied AI在复杂环境中的泛化能力...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Per-Query Visual Concept Learning|逐查询视觉概念学习|Ori Malca, Dvir Samuel, Gal Chechik|<http://arxiv.org/pdf/2508.09045v1>|提出针对提示和噪声种子的个性化步骤，通过自我和交叉注意力损失提升视觉概念学习效果。|
|🆕 发布|VLM-3D:End-to-End Vision-Language Models for Open-World 3D Perception|端到端视觉语言模型VLM-3D：面向开放世界三维感知|Fuhao Chang, Shuxin Li, Yabei Li, Lei He|<http://arxiv.org/pdf/2508.09061v1>|提出首个端到端视觉语言模型VLM-3D，通过联合语义几何损失提升自动驾驶场景下的三维感知精度。|
|📝 更新|See the Forest and the Trees: A Synergistic Reasoning Framework for Knowledge-Based Visual Question Answering|看到森林与树木：基于知识的视觉问答协同推理框架|Junjie Wang, Yunhan Tang, Yijie Wang, Zhihao Yuan, Huan Wang, Yangfan He, Bin Li|<http://arxiv.org/pdf/2507.17659v2>|提出协同推理框架Synergos-VQA，通过融合全局、结构和因果证据，提升知识驱动视觉问答的推理全...|
|📝 更新|Triad: Empowering LMM-based Anomaly Detection with Vision Expert-guided Visual Tokenizer and Manufacturing Process|三元组：通过视觉专家引导的视觉标记器和制造流程增强基于LMM的异常检测|Yuanze Li, Shihao Yuan, Haolin Wang, Qizhang Li, Ming Liu, Chen Xu, Guangming Shi, Wangmeng Zuo|<http://arxiv.org/pdf/2503.13184v2>|[代码](https://github.com/tzjtatata/Triad.); 提出Triad方法，结合视觉专家指导的感兴趣区域 tokenizer 和制造过程，提升工业异常检测的...|
|🆕 发布|Hierarchical Visual Prompt Learning for Continual Video Instance Segmentation|层次化视觉提示学习用于持续视频实例分割|Jiahua Dong, Hui Yin, Wenqi Liang, Hanbin Zhao, Henghui Ding, Nicu Sebe, Salman Khan, Fahad Shahbaz Khan|<http://arxiv.org/pdf/2508.08612v1>|[代码](https://github.com/JiahuaDong/HVPL.); 提出了一种分层视觉提示学习方法，有效解决了视频实例分割中的灾难性遗忘问题。|
|📝 更新|SoftHGNN: Soft Hypergraph Neural Networks for General Visual Recognition|软超图神经网络：用于通用视觉识别的SoftHGNN|Mengqi Lei, Yihong Wu, Siqi Li, Xinhu Zheng, Juan Wang, Yue Gao, Shaoyi Du|<http://arxiv.org/pdf/2505.15325v2>|提出SoftHGNN方法，通过软超边和稀疏选择机制高效捕捉视觉场景的高阶关联。|
|📝 更新|Task-Oriented Feature Compression for Multimodal Understanding via Device-Edge Co-Inference|面向任务的特性压缩：通过设备边缘协同推理实现多模态理解|Cheng Yuan, Zhening Liu, Jiashu Lv, Jiawei Shao, Yufei Jiang, Jun Zhang, Xuelong Li|<http://arxiv.org/pdf/2503.12926v2>|提出任务导向的特征压缩方法，减少数据传输和计算复杂度，提升多模态理解在边缘设备上的效率。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HypeVPR: Exploring Hyperbolic Space for Perspective to Equirectangular Visual Place Recognition|超双曲空间探索：从透视到等角圆柱视觉位置识别|Suhan Woo, Seongwon Lee, Jinwoo Jang, Euntai Kim|<http://arxiv.org/pdf/2506.04764v2>|[代码](https://github.com/suhan-woo/HypeVPR.git.); 提出了一种在双曲空间中的层次化嵌入框架HypeVPR，用于提升全景图像与普通图像间的视觉定位效率。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|On the Reliability of Vision-Language Models Under Adversarial Frequency-Domain Perturbations|《在对抗性频率域扰动下视觉-语言模型的可靠性研究》|Jordan Vice, Naveed Akhtar, Yansong Gao, Richard Hartley, Ajmal Mian|<http://arxiv.org/pdf/2507.22398v2>|揭示了视觉语言模型在对抗性频率域扰动下的脆弱性，并设计了针对性的图像变换方法。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Uncertainty-aware Cross-training for Semi-supervised Medical Image Segmentation|不确定性感知的半监督医学图像分割交叉训练|Kaiwen Huang, Tao Zhou, Huazhu Fu, Yizhe Zhang, Yi Zhou, Xiao-Jun Wu|<http://arxiv.org/pdf/2508.09014v1>|[代码](https://github.com/taozh2017/UCSeg.); 提出了一种减轻模型认知偏见的半监督医学图像分割框架，通过双子网协作和不确定性感知伪标签生成，提升了分...|
|📝 更新|Learning to Harmonize Cross-vendor X-ray Images by Non-linear Image Dynamics Correction|通过非线性图像动力学校正学习协调跨厂商X射线图像|Yucheng Lu, Shunxin Wang, Dovile Juodelyte, Veronika Cheplygina|<http://arxiv.org/pdf/2504.10080v2>|提出了一种全局深度曲线估计方法GDCE，通过非线性图像动态修正解决不同厂商X射线图像间的域特异性曝光...|
|📝 更新|Masked Autoencoder Self Pre-Training for Defect Detection in Microelectronics|微电子缺陷检测中的遮蔽自编码器自我预训练|Nikolai Röhrich, Alwin Hoffmann, Richard Nordsieck, Emilio Zarbali, Alireza Javanmardi|<http://arxiv.org/pdf/2504.10021v2>|提出基于masked autoencoders的自预训练方法，有效提升微电子缺陷检测性能。|
|📝 更新|Context-based Motion Retrieval using Open Vocabulary Methods for Autonomous Driving|基于开放词汇方法的上下文运动检索在自动驾驶中的应用|Stefan Englmeier, Max A. Büttner, Katharina Winter, Fabian B. Flohr|<http://arxiv.org/pdf/2508.00589v2>|提出了一种基于自然语言查询的上下文感知运动检索框架，用于在自动驾驶系统中识别和处理边缘情况。|
|📝 更新|SSPFusion: A Semantic Structure-Preserving Approach for Infrared and Visible Image Fusion|SSPFusion：一种保持语义结构的红外与可见光图像融合方法|Qiao Yang, Yu Zhang, Yutong Chen, Jian Zhang, Shunli Zhang|<http://arxiv.org/pdf/2309.14745v3>|[代码](https://github.com/QiaoYang-CV/SSPFUSION.); 精度提升的多模态图像融合方法，通过结构特征提取和自监督信号保持语义结构一致性。|
|📝 更新|DriveIndia: An Object Detection Dataset for Diverse Indian Traffic Scenes|"DriveIndia：多样化印度交通场景的对象检测数据集"|Rishav Kumar, D. Santhosh Reddy, P. Rajalakshmi|<http://arxiv.org/pdf/2507.19912v3>|介绍了DriveIndia数据集，为复杂多变的印度交通环境提供全面的对象检测基准。|
|🆕 发布|MMIF-AMIN: Adaptive Loss-Driven Multi-Scale Invertible Dense Network for Multimodal Medical Image Fusion|MMIF-AMIN：自适应损失驱动多尺度可逆密集网络用于多模态医学图像融合|Tao Luo, Weihua Xu|<http://arxiv.org/pdf/2508.08679v1>|提出了一种自适应损失驱动的多尺度可逆密集网络，有效融合多模态医学图像信息。|
|🆕 发布|Unified and Semantically Grounded Domain Adaptation for Medical Image Segmentation|统一且语义固化的医学图像分割领域自适应方法|Xin Wang, Yin Guo, Jiamin Xia, Kaiyu Zhang, Niranjan Balu, Mahmud Mossa-Basha, Linda Shapiro, Chun Yuan|<http://arxiv.org/pdf/2508.08660v1>|提出了一种统一且基于语义的医学图像分割域自适应框架，有效桥接了有源和无源适应设置的差异。|
|🆕 发布|Boosting Generic Semi-Supervised Medical Image Segmentation via Diverse Teaching and Label Propagation|通过多样化教学和标签传播提升通用半监督医学图像分割性能|Wei Li, Pengcheng Zhou, Linye Ma, Wenyi Zhao, Huihua Yang|<http://arxiv.org/pdf/2508.08549v1>|提出了一种通用半监督医学图像分割框架，通过多样教学和标签传播网络提高无标签数据的利用率和模型多样性。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GMF-Drive: Gated Mamba Fusion with Spatial-Aware BEV Representation for End-to-End Autonomous Driving|GMF-Drive：具有空间感知BEV表示的门控Mamba融合端到端自动驾驶|Jian Wang, Chaokang Jiang, Haitao Xu|<http://arxiv.org/pdf/2508.06113v2>|GMF-Drive通过创新的几何增强柱状表示和高效的空间感知状态空间模型，解决了传统自动驾驶模型计算...|
|📝 更新|RemoteReasoner: Towards Unifying Geospatial Reasoning Workflow|RemoteReasoner：迈向统一地理空间推理工作流程|Liang Yao, Fan Liu, Hongbo Lu, Chuanyi Zhang, Rui Min, Shengxiang Xu, Shimin Di, Pai Peng|<http://arxiv.org/pdf/2507.19280v2>|提出了一种统一的地空推理工作流RemoteReasoner，通过强化学习实现自主推理，无需任务特定解...|


### 生物特征识别 (Biometric Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Pseudo Global Fusion Paradigm-Based Cross-View Network for LiDAR-Based Place Recognition|基于伪全局融合范式的跨视角网络用于激光雷达定位识别|Jintao Cheng, Jiehao Luo, Xieyuanli Chen, Jin Wu, Rui Fan, Xiaoyu Tang, Wei Zhang|<http://arxiv.org/pdf/2508.08917v1>|提出了一种伪全局融合范式，通过协同多模态分支在统一语义空间进行特征学习，提升了LiDAR-based...|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Decoupled Functional Evaluation of Autonomous Driving Models via Feature Map Quality Scoring|通过特征图质量评分实现自动驾驶模型解耦功能评估|Ludan Zhang, Sihan Wang, Yuqi Dai, Shuofei Qiao, Qinyue Luo, Lei He|<http://arxiv.org/pdf/2508.07552v2>|提出了一种基于特征图质量评分的独立评估方法，有效提升了自动驾驶模型中功能模块的特征表示质量和整体性能...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LayLens: Improving Deepfake Understanding through Simplified Explanations|《LayLens：通过简化的解释提高深度伪造理解》|Abhijeet Narang, Parul Gupta, Liuyijia Su, Abhinav Dhall|<http://arxiv.org/pdf/2507.10066v2>|提出LayLens工具，通过三阶段流程简化技术解释，帮助各教育背景用户更易理解并识别deepfake...|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|STELAR-VISION: Self-Topology-Aware Efficient Learning for Aligned Reasoning in Vision|STELAR-VISION：面向对齐推理的自拓扑感知高效学习视觉方法|Chen Li, Han Zhang, Zhantao Yang, Fangyi Chen, Zihan Wang, Anudeepsekhar Bolimera, Marios Savvides|<http://arxiv.org/pdf/2508.08688v1>|STELAR-Vision通过引入拓扑感知训练框架和输出长度缩减技术，提升了视觉语言模型在复杂任务和...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|How Does Bilateral Ear Symmetry Affect Deep Ear Features?|双边耳朵对称性如何影响深度耳朵特征？|Kagan Ozturk, Deeksha Arun, Kevin W. Bowyer, Patrick Flynn|<http://arxiv.org/pdf/2508.04614v2>|探究了双边耳朵对称性对深度学习耳部特征的影响，并证实区分左右耳训练可提升识别性能。|
|🆕 发布|Shape Completion and Real-Time Visualization in Robotic Ultrasound Spine Acquisitions|机器人超声脊椎扫描中的形状补全与实时可视化|Miruna-Alexandra Gafencu, Reem Shaban, Yordanka Velikova, Mohammad Farid Azampour, Nassir Navab|<http://arxiv.org/pdf/2508.08923v1>|提出了一种集成机器人超声与实时形状补全的系统，提高了脊柱超声成像的可视化和一致性。|
|📝 更新|Investigating the Relationship between the Weighted Figure of Merit and Rosin's Measure|探究加权性能指标与Rosin测度之间的关系|Bimal Kumar Ray|<http://arxiv.org/pdf/2506.05749v2>|分析了加权性能指标与Rosin度量之间的关系，证明了两者理论上的独立性。|
|🆕 发布|PADReg: Physics-Aware Deformable Registration Guided by Contact Force for Ultrasound Sequences|PADReg：基于接触力的物理感知可变形配准方法用于超声序列|Yimeng Geng, Mingyang Zhao, Fan Xu, Guanglin Cao, Gaofeng Meng, Hongbin Liu|<http://arxiv.org/pdf/2508.08685v1>|[代码](https://github.com/evelynskip/PADReg.); 提出了一种利用接触力引导的物理感知可变形配准方法，有效解决了超声图像配准中的大形变挑战，提高了解剖结...|
|📝 更新|A Fast Unsupervised Scheme for Polygonal Approximation|一种快速的无监督多边形逼近方案|Bimal Kumar Ray|<http://arxiv.org/pdf/2506.04664v2>|提出了一种快速无监督的多边形逼近方案，通过分阶段处理提高逼近速度和美学质量。|
|🆕 发布|A new dataset and comparison for multi-camera frame synthesis|多摄像头帧合成的新数据集与比较|Conall Daly, Anil Kokaram|<http://arxiv.org/pdf/2508.09068v1>|构建多相机数据集，首次公平比较帧插值与视图合成方法，发现实际场景中传统方法优于深度学习。|

