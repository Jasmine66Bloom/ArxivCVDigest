## [UPDATED!] **2025-08-13** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CellSymphony: Deciphering the molecular and phenotypic orchestration of cells with single-cell pathomics|细胞交响曲：利用单细胞病理组学解码细胞的分子与表型协同作用|Paul H. Acosta, Pingjun Chen, Simon P. Castillo, Maria Esther Salvatierra, Yinyin Yuan, Xiaoxi Pan|<http://arxiv.org/pdf/2508.10232v1>|提出CellSymphony框架，融合转录组与组织学图像数据，实现单细胞级别的细胞类型标注和微环境分...|
|🆕 发布|DINOv3|DINOv3  《动态交互对象检测与分割的第三版》|Oriane Siméoni, Huy V. Vo, Maximilian Seitzer, Federico Baldassarre, Maxime Oquab, Cijo Jose, Vasil Khalidov, Marc Szafraniec .etc.|<http://arxiv.org/pdf/2508.10104v1>|DINOv3通过大规模数据与模型优化及创新的Gram anchoring方法，实现了无需标注数据的通...|
|🆕 发布|January Food Benchmark (JFB): A Public Benchmark Dataset and Evaluation Suite for Multimodal Food Analysis|《一月食品基准（JFB）：用于多模态食品分析的开源基准数据集与评估套件》|Amir Hosseinian, Ashkan Dehghani Zahedani, Umer Mansoor, Noosheen Hashemi, Mark Woodward|<http://arxiv.org/pdf/2508.09966v1>|提出 January Food Benchmark 数据集和评估框架，提升了自动化营养分析模型的性能...|
|🆕 发布|IPG: Incremental Patch Generation for Generalized Adversarial Patch Training|IPG：用于泛化对抗性补丁训练的增量补丁生成|Wonho Lee, Hyunsik Na, Jisu Lee, Daeseon Choi|<http://arxiv.org/pdf/2508.10946v1>|提出了一种高效生成通用对抗性补丁的方法IPG，能显著提升攻击效率并增强模型鲁棒性。|
|📝 更新|Analyzing Finetuning Representation Shift for Multimodal LLMs Steering|分析多模态大规模语言模型微调表示偏移的引导|Pegah Khayatan, Mustafa Shukor, Jayneel Parekh, Arnaud Dapogny, Matthieu Cord|<http://arxiv.org/pdf/2501.03012v2>|提出了一种映射隐藏状态到可解释视觉和文本概念的框架，用于分析多模态LLM的微调行为和概念偏移。|
|📝 更新|Pediatric brain tumor classification using digital histopathology and deep learning: evaluation of SOTA methods on a multi-center Swedish cohort|使用数字病理学及深度学习进行儿童脑肿瘤分类：基于瑞典多中心队列对最新方法的评估|Iulian Emil Tampu, Per Nyman, Christoforos Spyretos, Ida Blystad, Alia Shamikh, Gabriela Prochazka, Teresita Díaz de Ståhl, Johanna Sandgren .etc.|<http://arxiv.org/pdf/2409.01330v2>|利用深度学习对瑞典多中心儿童脑肿瘤数字病理图像进行分类，提升了诊断准确性和模型泛化能力。|
|🆕 发布|Multimodal Sheaf-based Network for Glioblastoma Molecular Subtype Prediction|多模态束状网络用于胶质oblastoma分子亚型预测|Shekhnaz Idrissova, Islem Rekik|<http://arxiv.org/pdf/2508.09717v1>|[代码](https://github.com/basiralab/MMSN); 提出了一种基于束状结构的新型框架，实现了MRI和病理图像的结构感知与一致性融合，提高了胶质oblas...|
|📝 更新|ViCToR: Improving Visual Comprehension via Token Reconstruction for Pretraining LMMs|ViCToR：通过标记重建提升预训练语言模型的视觉理解能力|Yin Xie, Kaicheng Yang, Peirou Liang, Xiang An, Yongle Zhao, Yumeng Wang, Ziyong Feng, Roy Miles .etc.|<http://arxiv.org/pdf/2410.14332v4>|[代码](https://github.com/deepglint/Victor.); 提出ViCToR框架，通过视觉token池和匹配算法提升大型多模态模型对视觉信息的理解。|
|📝 更新|Emotion-Qwen: A Unified Framework for Emotion and Vision Understanding|情感-视觉问答统一框架：Emotion-Qwen|Dawei Huang, Qing Li, Chuan Yan, Zebang Cheng, Zihao Han, Yurong Huang, Xiang Li, Bin Li .etc.|<http://arxiv.org/pdf/2505.06685v3>|提出了一种统一的多模态框架Emotion-Qwen，通过混合专家架构和三阶段预训练，有效平衡情感理解...|
|📝 更新|Improving Multimodal Large Language Models Using Continual Learning|使用持续学习改进多模态大型语言模型|Shikhar Srivastava, Md Yousuf Harun, Robik Shrestha, Christopher Kanan|<http://arxiv.org/pdf/2410.19925v2>|[代码](https://shikhar-srivastava.github.io/cl-for-improving-mllms); 提出了一种针对多模态大语言模型融合的持续学习方法，有效减少语言性能损失同时增强视觉理解能力。|
|📝 更新|Simulating the Real World: A Unified Survey of Multimodal Generative Models|模拟现实世界：多模态生成模型的统一综述|Yuqi Hu, Longguang Wang, Xian Liu, Ling-Hao Chen, Yuwei Guo, Yukai Shi, Ce Liu, Anyi Rao .etc.|<http://arxiv.org/pdf/2503.04641v2>|系统整合了2D至4D多模态生成模型的研究，为真实世界仿真提供了统一框架。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Understanding Transformer-based Vision Models through Inversion|通过逆向工程理解基于Transformer的视觉模型|Jan Rathjens, Shirin Reyhanian, David Kappel, Laurenz Wiskott|<http://arxiv.org/pdf/2412.06534v4>|[代码](https://github.com/wiskott-lab/inverse-tvm.); 提出了一种模块化特征反转方法，有效解析了大型Transformer视觉模型内部特征表示机制。|
|🆕 发布|Perceptual Reality Transformer: Neural Architectures for Simulating Neurological Perception Conditions|感知现实转换器：模拟神经感知条件的神经网络架构|Baihan Lin|<http://arxiv.org/pdf/2508.09852v1>|提出Perceptual Reality Transformer框架，通过模拟神经感知条件，帮助体验...|
|🆕 发布|Do Vision Transformers See Like Humans? Evaluating their Perceptual Alignment|《视觉变压器是否像人类一样观察？评估其感知对齐》|Pablo Hernández-Cámara, Jose Manuel Jaén-Lorites, Jorge Vila-Tomás, Valero Laparra, Jesus Malo|<http://arxiv.org/pdf/2508.09850v1>|系统分析了ViT模型与人类视觉感知的契合度，揭示了模型大小、数据多样性和训练策略对契合度的影响。|
|🆕 发布|Speed Always Wins: A Survey on Efficient Architectures for Large Language Models|速度总是制胜：大规模语言模型高效架构综述|Weigao Sun, Jiaxi Hu, Yucheng Zhou, Jusen Du, Disen Lan, Kexin Wang, Tong Zhu, Xiaoye Qu .etc.|<http://arxiv.org/pdf/2508.09834v1>|系统考察了创新的大型语言模型架构，提升了Transformer模型的训练和部署效率。|
|📝 更新|LM-MCVT: A Lightweight Multi-modal Multi-view Convolutional-Vision Transformer Approach for 3D Object Recognition|LM-MCVT：一种用于三维物体识别的轻量级多模态多视角卷积-视觉变换器方法|Songsong Xiong, Hamidreza Kasaei|<http://arxiv.org/pdf/2504.19256v3>|提出了一种轻量级多模态多视角卷积-视觉变换器网络，有效提升了机器人环境中3D物体识别的准确性。|
|📝 更新|Joint multi-dimensional dynamic attention and transformer for general image restoration|联合多维动态注意力与变换器用于通用图像恢复|Huan Zhang, Xu Zhang, Nian Cai, Jianglei Di, Yun Zhang|<http://arxiv.org/pdf/2411.07893v2>|[代码](https://github.com/House-yuyu/MDDA-former.); 提出了一种结合多维动态注意力和自注意力机制的图像复原架构，有效平衡了性能与计算复杂度。|
|🆕 发布|MoIIE: Mixture of Intra- and Inter-Modality Experts for Large Vision Language Models|《MoIIE：面向大型视觉语言模型的模态内与模态间专家混合》|Dianyi Wang, Siyuan Wang, Zejun Li, Yikun Wang, Yitong Li, Duyu Tang, Xiaoyu Shen, Xuanjing Huang .etc.|<http://arxiv.org/pdf/2508.09779v1>|[代码](https://github.com/AlenjandroWang/MoIIE.); 提出了一种混合内外模态专家的模型结构，有效提升了大规模视觉语言模型的效率和性能。|
|🆕 发布|Learning Spatial Decay for Vision Transformers|学习视觉变换器中的空间衰减|Yuxin Mao, Zhen Qin, Jinxing Zhou, Bin Fan, Jing Zhang, Yiran Zhong, Yuchao Dai|<http://arxiv.org/pdf/2508.09525v1>|引入了基于内容感知的动态空间衰减机制，提升视觉变压器在空间结构任务上的性能。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Empowering Morphing Attack Detection using Interpretable Image-Text Foundation Model|使用可解释图像-文本基础模型增强变形攻击检测能力|Sushrut Patwardhan, Raghavendra Ramachandra, Sushma Venkatesh|<http://arxiv.org/pdf/2508.10110v1>|提出了一种结合图像和文本的多模态学习方法，通过文本描述增强面部识别系统中的图像变形攻击检测能力。|
|🆕 发布|LLMC+: Benchmarking Vision-Language Model Compression with a Plug-and-play Toolkit|LLMC+：使用即插即用工具包对视觉语言模型压缩进行基准测试|Chengtao Lv, Bilang Zhang, Yang Yong, Ruihao Gong, Yushi Huang, Shiqiao Gu, Jiajun Wu, Yumeng Shi .etc.|<http://arxiv.org/pdf/2508.09981v1>|[代码](https://github.com/ModelTC/LightCompress.); 提出LLMC+工具包，系统评估视觉语言模型压缩技术，实现高效压缩与性能保持。|
|📝 更新|SpaCE-10: A Comprehensive Benchmark for Multimodal Large Language Models in Compositional Spatial Intelligence|空间智能组合性多模态大型语言模型的全面基准：SpaCE-10|Ziyang Gong, Wenhao Li, Oliver Ma, Songyuan Li, Jiayi Ji, Xue Yang, Gen Luo, Junchi Yan .etc.|<http://arxiv.org/pdf/2506.07966v3>|[代码](https://github.com/Cuzyoung/SpaCE-10.); 提出了SpaCE-10基准，全面评估多模态大语言模型在空间智能方面的原子与组合能力。|
|🆕 发布|VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models|VisCodex：通过融合视觉与编码模型实现统一的多模态代码生成|Lingjie Jiang, Shaohan Huang, Xun Wu, Yixia Li, Dongdong Zhang, Furu Wei|<http://arxiv.org/pdf/2508.09945v1>|VisCodex通过融合视觉和编码模型，增强了大型多模态语言模型生成代码的能力。|
|🆕 发布|Physical Autoregressive Model for Robotic Manipulation without Action Pretraining|物理自回归模型：无需动作预训练的机器人操作|Zijian Song, Sihan Qin, Tianshui Chen, Liang Lin, Guangrun Wang|<http://arxiv.org/pdf/2508.09822v1>|提出物理自回归模型，无需动作预训练即可理解物理动态，实现精确视频预测和一致动作轨迹。|
|🆕 发布|Describe What You See with Multimodal Large Language Models to Enhance Video Recommendations|使用多模态大型语言模型描述您所看到的以增强视频推荐|Marco De Nadai, Andreas Damianou, Mounia Lalmas|<http://arxiv.org/pdf/2508.09789v1>|通过使用大型多模态语言模型生成视频描述，增强了推荐系统的语义理解和个性化水平。|
|📝 更新|SpectralEarth: Training Hyperspectral Foundation Models at Scale|《大规模训练高光谱基础模型的SpectralEarth》|Nassim Ait Ali Braham, Conrad M Albrecht, Julien Mairal, Jocelyn Chanussot, Yi Wang, Xiao Xiang Zhu|<http://arxiv.org/pdf/2408.08447v2>|构建了大规模的SpectralEarth数据集，并利用自监督学习预训练了适用于高光谱图像的基础模型，...|
|📝 更新|CoherenDream: Boosting Holistic Text Coherence in 3D Generation via Multimodal Large Language Models Feedback|通过多模态大型语言模型反馈增强3D生成中的整体文本连贯性：CoherenDream|Chenhan Jiang, Yihan Zeng, Dit-Yan Yeung|<http://arxiv.org/pdf/2504.19860v3>|提出了一种融合大型多模态语言模型反馈的优化策略，有效提升了文本与3D生成内容的整体一致性。|
|📝 更新|Can Large Multimodal Models Understand Agricultural Scenes? Benchmarking with AgroMind|大型多模态模型能理解农业场景吗？基于AgroMind的基准测试|Qingmei Li, Yang Zhang, Zurong Mai, Yuhang Chen, Shuohong Lou, Henglian Huang, Jiarui Zhang, Zhiwei Zhang .etc.|<http://arxiv.org/pdf/2505.12207v3>|[代码](https://rssysu.github.io/AgroMind); 提出AgroMind基准，评估大型多模态模型在农业遥感任务中的表现，揭示了其在领域知识和细粒度识别上...|
|🆕 发布|CitySeg: A 3D Open Vocabulary Semantic Segmentation Foundation Model in City-scale Scenarios|城市级场景中的CitySeg：一种三维开放词汇语义分割基础模型|Jialei Xu, Zizhuang Wei, Weikang You, Linyun Li, Weijian Sun|<http://arxiv.org/pdf/2508.09470v1>|提出CitySeg模型，利用文本模态实现城市规模点云的开放词汇语义分割和零样本推理。|
|🆕 发布|Distilling LLM Prior to Flow Model for Generalizable Agent's Imagination in Object Goal Navigation|将大型语言模型先验知识蒸馏到流模型中以实现物体目标导航中代理的泛化想象力|Badi Li, Ren-jie Lu, Yu Zhou, Jingke Meng, Wei-shi Zheng|<http://arxiv.org/pdf/2508.09423v1>|[代码](https://github.com/Badi-Li/GOAL.); 提出GOAL框架，通过融合大语言模型的空间先验知识，提升物体导航任务中场景想象的泛化能力。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Detection and Tracking of MAVs Using a Rosette Scanning Pattern LiDAR|使用玫瑰扫描模式激光雷达进行微型无人机的检测与跟踪|Sándor Gazdag, Tom Möller, Anita Keszler, András L. Majdik|<http://arxiv.org/pdf/2408.08555v3>|利用非重复玫瑰扫描模式LiDAR，实现了无人机检测距离显著提升的自动检测与跟踪系统。|
|📝 更新|EventRR: Event Referential Reasoning for Referring Video Object Segmentation|事件参照推理用于视频目标分割的EventRR|Huihui Xu, Jiashi Lin, Haoyu Chen, Junjun He, Lei Zhu|<http://arxiv.org/pdf/2508.07171v2>|[代码](https://github.com/bio-mlhui/EventRR); 提出EventRR框架，通过事件参照推理和对象总结，提升视频对象分割的准确性和效率。|
|🆕 发布|Explainable AI Technique in Lung Cancer Detection Using Convolutional Neural Networks|卷积神经网络在肺癌检测中的可解释人工智能技术|Nishan Rai, Sujan Khatri, Devendra Risal|<http://arxiv.org/pdf/2508.10196v1>|提出了一种结合解释性的深度学习框架，通过CNN从胸部CT图像自动检测肺癌，提高了检测准确性和临床透明...|
|📝 更新|RoHOI: Robustness Benchmark for Human-Object Interaction Detection|RoHOI：用于人类-物体交互检测的鲁棒性基准|Di Wen, Kunyu Peng, Kailun Yang, Yufan Chen, Ruiping Liu, Junwei Zheng, Alina Roitberg, Danda Pani Paudel .etc.|<http://arxiv.org/pdf/2507.09111v2>|[代码](https://github.com/Kratos-Wen/RoHOI.); 提出首个针对人-物交互检测的鲁棒性基准RoHOI，并提出SAMPL策略增强模型鲁棒性。|
|📝 更新|MGDFIS: Multi-scale Global-detail Feature Integration Strategy for Small Object Detection|多尺度全局-细节特征融合策略用于小目标检测（MGDFIS）|Yuxiang Wang, Xuecheng Bai, Boyu Hu, Chuanzhi Xu, Haodong Chen, Vera Chung, Tingxue Li, Xiaoming Chen|<http://arxiv.org/pdf/2506.12697v2>|提出了一种多尺度全局细节特征融合策略，有效提升了无人机影像中微小目标检测的准确性和效率。|
|📝 更新|OC-SOP: Enhancing Vision-Based 3D Semantic Occupancy Prediction by Object-Centric Awareness|OC-SOP：通过物体中心感知增强基于视觉的3D语义占据预测|Helin Cao, Sven Behnke|<http://arxiv.org/pdf/2506.18798v2>|提出OC-SOP框架，通过融合物体中心的高层次线索，显著提升动态前景物体的3D语义占据预测准确性。|
|📝 更新|A Simple yet Powerful Instance-Aware Prompting Framework for Training-free Camouflaged Object Segmentation|一种简单而强大的实例感知提示框架，用于无需训练的迷彩目标分割|Chao Yin, Jide Li, Xiaoqiang Li|<http://arxiv.org/pdf/2508.06904v2>|提出了一种无需训练的实例感知提示框架，实现了对伪装物体的精细分割。|
|🆕 发布|COXNet: Cross-Layer Fusion with Adaptive Alignment and Scale Integration for RGBT Tiny Object Detection|COXNet：基于自适应对齐与尺度集成的跨层融合用于RGBT微小目标检测|Peiran Peng, Tingfa Xu, Liqiang Song, Mengqi Zhu, Yuqiang Fang, Jianan Li|<http://arxiv.org/pdf/2508.09533v1>|提出COXNet框架，通过跨层融合与自适应对齐提升RGBT微小目标检测性能。|
|📝 更新|Scaling Vision Mamba Across Resolutions via Fractal Traversal|通过分形遍历在多种分辨率下扩展视觉Mamba模型|Bo Li, Haoke Xiao, Lv Tang|<http://arxiv.org/pdf/2505.14062v2>|提出FractalMamba++模型，通过 Hilbert 曲线和新型机制改善视觉输入处理和分辨率适...|
|📝 更新|PAD-F: Prior-Aware Debiasing Framework for Long-Tailed X-ray Prohibited Item Detection|PAD-F：先验感知去偏框架用于长尾X射线禁运物品检测|Haoyu Wang, Renshuai Tao, Wei Wang, Yunchao Wei|<http://arxiv.org/pdf/2411.18078v4>|提出了一种针对X射线禁品检测的长尾分布问题，利用先验知识的Prior-Aware Debiasing...|
|🆕 发布|RampNet: A Two-Stage Pipeline for Bootstrapping Curb Ramp Detection in Streetscape Images from Open Government Metadata|RampNet：一种基于开放政府元数据的街景图像引导式路缘坡检测的两阶段管道|John S. O'Meara, Jared Hwang, Zeyu Wang, Michael Saugstad, Jon E. Froehlich|<http://arxiv.org/pdf/2508.09415v1>|提出两阶段RampNet方案，利用政府数据生成大规模高质量数据集，实现路缘坡道检测性能突破。|
|🆕 发布|Skyshield: Event-Driven Submillimetre Thin Obstacle Detection for Drone Flight Safety|天盾：面向无人机飞行安全的基于事件驱动的亚毫米级薄障碍物检测|Zhengli Zhang, Xinyu Luo, Yuchen Sun, Wenhua Ding, Dongyu Huang, Xinlei Chen|<http://arxiv.org/pdf/2508.09397v1>|提出了一种基于事件驱动的框架SkyShield，用于精准检测亚毫米级细小障碍物，显著提升无人机飞行安...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SynSpill: Improved Industrial Spill Detection With Synthetic Data|合成数据增强的工业泄漏检测：SynSpill方法|Aaditya Baranwal, Abdul Mueez, Jason Voelker, Guneet Bhatia, Shruti Vyas|<http://arxiv.org/pdf/2508.10171v1>|利用高质量合成数据生成框架，有效提升工业泄漏检测性能。|
|📝 更新|ProbRadarM3F: mmWave Radar based Human Skeletal Pose Estimation with Probability Map Guided Multi-Format Feature Fusion|ProbRadarM3F：基于概率图引导的多格式特征融合的毫米波雷达人体骨骼姿态估计|Bing Zhu, Zixin He, Weiyi Xiong, Guanhua Ding, Tao Huang, Wei Xiang|<http://arxiv.org/pdf/2405.05164v5>|提出概率图引导的多格式特征融合模型ProbRadarM3F，利用雷达信号中的位置信息，提高了人体骨骼...|
|🆕 发布|iWatchRoad: Scalable Detection and Geospatial Visualization of Potholes for Smart Cities|iWatchRoad：面向智能城市的坑洞可扩展检测与地理空间可视化|Rishi Raj Sahoo, Surbhi Saswati Mohanty, Subhankar Mishra|<http://arxiv.org/pdf/2508.10945v1>|提出iWatchRoad系统，自动检测道路坑洼并通过GPS定位与实时地图可视化，提升道路安全管理效率...|
|🆕 发布|ARI3D: A Software for Interactive Quantification of Regions in X-Ray CT 3D Images|ARI3D：一种用于X射线CT三维图像区域交互式定量的软件|Jan Phillipp Albrecht, Jose R. A. Godinho, Christina Hübers, Deborah Schmidt|<http://arxiv.org/pdf/2508.09849v1>|提出ARI3D软件，交互式辅助用户在X射线CT三维图像中精确分类和量化微结构。|
|🆕 发布|Predictive Uncertainty for Runtime Assurance of a Real-Time Computer Vision-Based Landing System|实时计算机视觉着陆系统的预测不确定性与运行时保障|Romeo Valentin, Sydney M. Katz, Artur B. Carneiro, Don Walker, Mykel J. Kochenderfer|<http://arxiv.org/pdf/2508.09732v1>|提出了一种实时飞机姿态估计系统，通过概率关键点回归和残差监测确保了高精度和故障检测能力。|
|🆕 发布|Topological Structure Description for Artcode Detection Using the Shape of Orientation Histogram|使用方向直方图形状进行艺术码检测的拓扑结构描述|Liming Xu, Dave Towey, Andrew P. French, Steve Benford|<http://arxiv.org/pdf/2508.10942v1>|提出了一种新的特征描述符——形状方向直方图，用于识别具有自由形态拓扑结构的装饰性标记Artcodes...|
|📝 更新|MultiFormer: A Multi-Person Pose Estimation System Based on CSI and Attention Mechanism|基于CSI和注意力机制的多人姿态估计系统：MultiFormer|Yanyi Qu, Haoyang Ma, Wenhui Xiong|<http://arxiv.org/pdf/2505.22555v2>|提出了一种基于CSI和时间频率双token的Transformer模型MultiFormer，实现了...|
|🆕 发布|CLIP-Flow: A Universal Discriminator for AI-Generated Images Inspired by Anomaly Detection|CLIP-Flow：受异常检测启发的一种通用AI生成图像判别器|Zhipeng Yuan, Kai Wang, Weize Quan, Dong-Ming Yan, Tieru Wu|<http://arxiv.org/pdf/2508.09477v1>|提出了一种基于异常检测的通用AI生成图像识别方法，无需使用AI生成图像即可学习泛化特征表示。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|S2-UniSeg: Fast Universal Agglomerative Pooling for Scalable Segment Anything without Supervision|S2-UniSeg：无需监督的可扩展任意分割的快速通用聚合池化方法|Huihui Xu, Jin Ye, Hongqiu Wang, Changkai Ji, Jiashi Lin, Ming Hu, Ziyan Huang, Ying Chen .etc.|<http://arxiv.org/pdf/2508.06995v2>|[代码](https://github.com/bio-mlhui/S2-UniSeg); 提出Fast Universal Agglomerative Pooling算法，实现快速无监督图像...|
|📝 更新|SLTNet: Efficient Event-based Semantic Segmentation with Spike-driven Lightweight Transformer-based Networks|SLTNet：基于脉冲驱动的轻量级Transformer网络的效率事件语义分割|Xianlei Long, Xiaxin Zhu, Fangming Guo, Wanyi Zhang, Qingyi Gu, Chao Chen, Fuqiang Gu|<http://arxiv.org/pdf/2412.12843v3>|[代码](https://github.com/longxianlei/SLTNet-v1.0.); 提出SLTNet，一种高效的基于事件相机和轻量级变换网络的语义分割方法，大幅降低能耗并提升处理速度。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MOC: Meta-Optimized Classifier for Few-Shot Whole Slide Image Classification|MOC：少量样本全切片图像分类的元优化分类器|Tianqi Xiang, Yi Li, Qixiang Zhang, Xiaomeng Li|<http://arxiv.org/pdf/2508.09967v1>|[代码](https://github.com/xmed-lab/MOC.); 提出了一种元优化分类器MOC，通过自动优化候选分类器配置，显著提升了少量样本下的全切片图像分类性能。|
|🆕 发布|NIRMAL Pooling: An Adaptive Max Pooling Approach with Non-linear Activation for Enhanced Image Classification|非线性激活增强图像分类的自适应最大池化方法：NIRMAL池化|Nirmal Gaud, Krishna Kumar Jha, Jhimli Adhikari, Adhini Nasarin P S, Joydeep Das, Samarth S Deshpande, Nitasha Barara, Vaduguru Venkata Ramya .etc.|<http://arxiv.org/pdf/2508.10940v1>|提出NIRMAL Pooling方法，结合自适应最大池化和非线性激活，提升图像分类准确性和特征表现。|
|🆕 发布|Multi-Contrast Fusion Module: An attention mechanism integrating multi-contrast features for fetal torso plane classification|多对比融合模块：一种集成多对比特征的关注机制用于胎儿躯干平面分类|Shengjun Zhu, Siyu Liu, Runqing Xiong, Liping Zheng, Duo Ma, Rongshang Chen, Jiaxin Cai|<http://arxiv.org/pdf/2508.09644v1>|[代码](https://github.com/sysll/MCFM.); 提出了一种多对比度融合模块，通过增强特征表示显著提高了胎儿躯干平面识别的准确性和可靠性。|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Preacher: Paper-to-Video Agentic System|布道者：从论文到视频的代理系统|Jingwei Liu, Ling Yang, Hao Luo, Fan Wang, Hongyan Li, Mengdi Wang|<http://arxiv.org/pdf/2508.09632v4>|[代码](https://github.com/GenVerse/Paper2Video); 提出Preacher系统，通过上下结合的方法将学术论文转化为结构化视频摘要，克服了现有模型局限性。|
|🆕 发布|From Large Angles to Consistent Faces: Identity-Preserving Video Generation via Mixture of Facial Experts|从大角度到一致的面孔：通过面部专家混合实现身份保持的视频生成|Yuji Wang, Moran Li, Xiaobin Hu, Ran Yi, Jiangning Zhang, Chengming Xu, Weijian Cao, Yabiao Wang .etc.|<http://arxiv.org/pdf/2508.09476v2>|[代码](https://github.com/rain152/LFA-Video-Generation.); 提出了一种结合面部专家混合模型和专门数据集的方法，有效解决了视频生成中面部角度变化导致的身份保持问题...|
|🆕 发布|Data-Efficient Learning for Generalizable Surgical Video Understanding|数据高效学习以实现普适性手术视频理解|Sahar Nasirihaghighi|<http://arxiv.org/pdf/2508.10215v1>|提出数据高效学习方法，通过半监督框架和新型架构提升手术视频分析性能。|
|📝 更新|MyTimeMachine: Personalized Facial Age Transformation|我的时光机：个性化面部年龄转换|Luchao Qi, Jiaye Wu, Bang Gong, Annie N. Wang, David W. Jacobs, Roni Sengupta|<http://arxiv.org/pdf/2411.14521v2>|提出了一种结合全局老化先验和个人照片集的个性化面部年龄转换方法，通过新型Adapter网络和三个损失...|
|🆕 发布|Story2Board: A Training-Free Approach for Expressive Storyboard Generation|《Story2Board：一种无需训练的表达性故事板生成方法》|David Dinkevich, Matan Levy, Omri Avrahami, Dvir Samuel, Dani Lischinski|<http://arxiv.org/pdf/2508.09983v1>|Story2Board提出了一种无需训练的故事板生成框架，通过保持角色一致性和视觉特征混合，生成动态...|
|🆕 发布|HumanGenesis: Agent-Based Geometric and Generative Modeling for Synthetic Human Dynamics|人类起源：基于代理的几何与生成建模用于合成人类动态模拟|Weiqi Li, Zehao Zhang, Liang Lin, Guangrun Wang|<http://arxiv.org/pdf/2508.09858v1>|HumanGenesis通过结合几何建模与生成模型，有效解决了合成人类动态中的几何不一致性和运动泛化...|
|🆕 发布|RayletDF: Raylet Distance Fields for Generalizable 3D Surface Reconstruction from Point Clouds or Gaussians|射线光斑距离场：用于从点云或高斯分布进行泛化三维表面重建的射线光斑距离场|Shenxing Wei, Jinxi Li, Yafei Yang, Siyuan Zhou, Bo Yang|<http://arxiv.org/pdf/2508.09830v1>|提出了一种名为RayletDF的新方法，通过预测射线上的表面点，实现了从点云或高斯分布中高效重建3D...|
|🆕 发布|The Role of Radiographic Knee Alignment in Knee Replacement Outcomes and Opportunities for Artificial Intelligence-Driven Assessment|膝关节置换结果中X射线膝关节对齐的作用及人工智能驱动评估的机会|Zhisen Hu, David S. Johnson, Aleksei Tiulpin, Timothy F. Cootes, Claudia Lindner|<http://arxiv.org/pdf/2508.10941v1>|探讨了利用人工智能评估膝关节置换结果与放射学膝关节对齐的关系。|
|🆕 发布|The Brain Resection Multimodal Image Registration (ReMIND2Reg) 2025 Challenge|脑切除多模态图像配准（ReMIND2Reg）2025挑战赛|Reuben Dorent, Laura Rigolo, Colin P. Galvin, Junyu Chen, Mattias P. Heinrich, Aaron Carass, Olivier Colliot, Demian Wassermann .etc.|<http://arxiv.org/pdf/2508.09649v1>|提出了最大化的脑肿瘤安全切除术中导航准确性的挑战，通过构建首个大规模多模态图像配准基准促进算法发展。|
|📝 更新|HunyuanWorld 1.0: Generating Immersive, Explorable, and Interactive 3D Worlds from Words or Pixels|《HunyuanWorld 1.0：从文字或像素生成沉浸式、可探索和交互式三维世界》|HunyuanWorld Team, Zhenwei Wang, Yuhao Liu, Junta Wu, Zixiao Gu, Haoyuan Wang, Xuhui Zuo, Tianyu Huang .etc.|<http://arxiv.org/pdf/2507.21809v2>|提出了HunyuanWorld 1.0框架，融合视频和3D技术优势，生成沉浸式、可探索、互动性3D世...|
|🆕 发布|SkySplat: Generalizable 3D Gaussian Splatting from Multi-Temporal Sparse Satellite Images|天空散点：从多时序稀疏卫星图像中生成通用三维高斯散点|Xuejun Huang, Xinyi Liu, Yi Wan, Zhi Zheng, Bin Zhang, Mingtao Xiong, Yingying Pei, Yongjun Zhang|<http://arxiv.org/pdf/2508.09479v1>|提出SkySplat框架，融合RPC模型和自监督学习，提升卫星图像三维重建效率与准确性。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Intent to Execution: Multimodal Chain-of-Thought Reinforcement Learning for Precise CAD Code Generation|从意图到执行：用于精确CAD代码生成的多模态思维链强化学习|Ke Niu, Haiyang Yu, Zhuofan Chen, Mengyang Zhao, Teng Fu, Bin Li, Xiangyang Xue|<http://arxiv.org/pdf/2508.10118v2>|提出了一种结合多模态链式思维和强化学习的框架，用于精确生成CAD代码，显著提升了代码执行性和几何精度...|
|🆕 发布|SVG-Head: Hybrid Surface-Volumetric Gaussians for High-Fidelity Head Reconstruction and Real-Time Editing|SVG-Head：混合表面-体积高斯分布用于高保真头部重建与实时编辑|Heyi Sun, Cong Wang, Tian-Xing Xu, Jingwei Huang, Di Kang, Chunchao Guo, Song-Hai Zhang|<http://arxiv.org/pdf/2508.09597v2>|提出了一种混合表面-体积高斯模型SVG-Head，实现了高保真头部重建和实时编辑。|
|🆕 发布|Deep Learning Enables Large-Scale Shape and Appearance Modeling in Total-Body DXA Imaging|深度学习助力全身DXA成像中大规模形状与外观建模|Arianna Bunnell, Devon Cataldi, Yannik Glaser, Thomas K. Wolfgruber, Steven Heymsfield, Alan B. Zonderman, Thomas L. Kelly, Peter Sadowski .etc.|<http://arxiv.org/pdf/2508.10132v1>|[代码](https://github.com/hawaii-ai/dxa-pointplacement.); 利用深度学习实现全身DXA成像中自动标记关键点，用于大规模形状和外观建模，关联健康生物标志物。|
|🆕 发布|A Survey on 3D Gaussian Splatting Applications: Segmentation, Editing, and Generation|三维高斯散点应用综述：分割、编辑与生成|Shuting He, Peilin Ji, Yitong Yang, Changshuo Wang, Jiayi Ji, Yinglin Wang, Henghui Ding|<http://arxiv.org/pdf/2508.09977v1>|[代码](https://github.com/heshuting555/Awesome-3DGS-Applications.); 概述了3D Gaussian Splatting在场景表示中的应用，实现实时高质量渲染并拓展至分割、...|
|📝 更新|LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer|层追踪器：通过扩散变换器实现与认知对齐的分层SVG合成|Yiren Song, Danze Chen, Mike Zheng Shou|<http://arxiv.org/pdf/2502.01105v3>|提出LayerTracer框架，通过模拟设计师创作过程生成高质量、易编辑的分层SVG图像。|
|🆕 发布|Quo Vadis Handwritten Text Generation for Handwritten Text Recognition?|“手写文本识别中的手写文本生成之路在何方？”|Vittorio Pippi, Konstantina Nikolaidou, Silvia Cascianelli, George Retsinas, Giorgos Sfikas, Rita Cucchiara, Marcus Liwicki|<http://arxiv.org/pdf/2508.09936v1>|系统评估了三种先进手写文本生成模型对提升低资源手写文本识别性能的影响。|
|📝 更新|Pretrained Reversible Generation as Unsupervised Visual Representation Learning|预训练可逆生成作为无监督视觉表征学习|Rongkun Xue, Jinouwen Zhang, Yazhe Niu, Dazhong Shen, Bingqi Ma, Yu Liu, Jing Yang|<http://arxiv.org/pdf/2412.01787v6>|[代码](https://github.com/opendilab/PRG.); 提出利用预训练生成模型逆向过程提取无监督视觉表征，实现多种任务上的性能提升。|
|📝 更新|ViewDelta: Scaling Scene Change Detection through Text-Conditioning|视图差分：通过文本条件化扩展场景变化检测|Subin Varghese, Joshua Gao, Vedhus Hoskere|<http://arxiv.org/pdf/2412.07612v3>|[代码](https://joshuakgao.github.io/viewdelta); 提出了一种基于文本条件的场景变化检测框架ViewDelta，解决了不同领域中“相关”与“干扰”变化的...|
|📝 更新|RAGAR: Retrieval Augmented Personalized Image Generation Guided by Recommendation|基于推荐引导的检索增强个性化图像生成：RAGAR|Run Ling, Wenji Wang, Yuting Liu, Guibing Guo, Haowei Liu, Jian Lu, Quanwei Zhang, Yexing Xu .etc.|<http://arxiv.org/pdf/2505.01657v2>|提出了一种基于检索机制和推荐系统的个性化图像生成方法，有效解决了传统方法在用户偏好提取和个性化优化方...|
|🆕 发布|Enhancing Diffusion Face Generation with Contrastive Embeddings and SegFormer Guidance|增强对比嵌入和SegFormer引导的扩散人脸生成|Dhruvraj Singh Rawat, Enggen Sherpa, Rishikesan Kirupanantha, Tin Hoang|<http://arxiv.org/pdf/2508.09847v1>|引入对比嵌入和SegFormer指导，提升了少量数据下属性引导的人脸生成质量和控制性。|
|🆕 发布|Region-to-Region: Enhancing Generative Image Harmonization with Adaptive Regional Injection|区域到区域：通过自适应区域注入增强生成图像调和|Zhiqiu Zhang, Dongqi Fan, Mingjie Wang, Qiang Tang, Jian Yang, Zili Yi|<http://arxiv.org/pdf/2508.09746v1>|提出Region-to-Region方法，通过自适应区域信息注入增强图像和谐化效果并保留细节。|
|📝 更新|Cyc3D: Fine-grained Controllable 3D Generation via Cycle Consistency Regularization|循环一致性正则化下的细粒度可控三维生成：Cyc3D|Hongbin Xu, Chaohui Yu, Feng Xiao, Jiazheng Xing, Hai Ci, Weitao Chen, Fan Wang, Ming Li|<http://arxiv.org/pdf/2504.14975v2>|提出了一种通过循环一致性正则化增强可控3D生成的框架，有效保持了生成内容与输入条件的一致性。|
|🆕 发布|NegFaceDiff: The Power of Negative Context in Identity-Conditioned Diffusion for Synthetic Face Generation|NegFaceDiff：负向上下文在身份条件扩散合成人脸中的力量|Eduarda Caldeira, Naser Damer, Fadi Boutros|<http://arxiv.org/pdf/2508.09661v1>|引入NegFaceDiff方法，通过加入负向条件增强身份分离度，提升合成人脸数据在识别任务中的性能。|
|📝 更新|HERMES: A Unified Self-Driving World Model for Simultaneous 3D Scene Understanding and Generation|赫耳墨斯：一种用于同时实现三维场景理解与生成的统一自动驾驶世界模型|Xin Zhou, Dingkang Liang, Sifan Tu, Xiwu Chen, Yikang Ding, Dingyuan Zhang, Feiyang Tan, Hengshuang Zhao .etc.|<http://arxiv.org/pdf/2501.14729v3>|[代码](https://github.com/LMD0311/HERMES.); HERMES通过统一框架整合3D场景理解和生成，利用鸟瞰图和世界知识查询提升自动驾驶环境感知能力。|
|📝 更新|Towards Synthesized and Editable Motion In-Betweening Through Part-Wise Phase Representation|面向基于部分相位表示的合成与可编辑运动插值|Minyue Dai, Ke Fan, Bin Ji, Haoran Xu, Haoyu Zhao, Junting Dong, Jingbo Wang, Bo Dai|<http://arxiv.org/pdf/2503.08180v3>|提出了一种基于身体部位级别的运动风格建模方法，提高了动画中运动插入的多样性和可控性。|
|🆕 发布|Images Speak Louder Than Scores: Failure Mode Escape for Enhancing Generative Quality|图像胜于分数：逃逸失败模式以提高生成质量|Jie Shao, Ke Zhu, Minghao Fu, Guo-hua Wang, Jianxin Wu|<http://arxiv.org/pdf/2508.09598v1>|提出了一种无需训练且推理高效的方法FaME，通过识别和避免低质量生成，显著提升图像的视觉质量。|
|🆕 发布|A Chain of Diagnosis Framework for Accurate and Explainable Radiology Report Generation|用于精确且可解释的放射学报告生成的诊断框架链条|Haibo Jin, Haoxuan Che, Sunan He, Hao Chen|<http://arxiv.org/pdf/2508.09566v1>|提出了一种链式诊断框架，通过问答对和诊断定位提升放射报告的准确性和可解释性。|
|🆕 发布|Dual Recursive Feedback on Generation and Appearance Latents for Pose-Robust Text-to-Image Diffusion|用于姿态稳健的文本到图像扩散的生成与外观潜在变量的双向递归反馈|Jiwon Kim, Pureum Kim, SeonHwa Kim, Soobin Park, Eunju Cha, Kyong Hwan Jin|<http://arxiv.org/pdf/2508.09575v1>|[代码](https://github.com/jwonkm/DRF.); 提出了一种无需训练的Dual Recursive Feedback系统，通过递归优化中间潜在变量，实...|
|📝 更新|MoCA: Identity-Preserving Text-to-Video Generation via Mixture of Cross Attention|MoCA：通过混合交叉注意力实现身份保持的文本到视频生成|Qi Xie, Yongjia Ma, Donglin Di, Xuehao Gao, Xun Yang|<http://arxiv.org/pdf/2508.03034v2>|提出了一种基于混合交叉注意力的视频生成模型MoCA，有效保持了文本到视频生成的身份一致性和细节表现。|
|🆕 发布|GoViG: Goal-Conditioned Visual Navigation Instruction Generation|目标条件视觉导航指令生成：GoViG|Fengyi Wu, Yifei Dong, Zhi-Qi Cheng, Yilong Dai, Guangyu Chen, Hang Wang, Qi Dai, Alexander G. Hauptmann|<http://arxiv.org/pdf/2508.09547v1>|提出了一种不依赖结构化输入的视觉导航指令生成方法，通过预测中间视觉状态和生成语言指令，实现了在无结构...|
|📝 更新|SpargeAttention: Accurate and Training-free Sparse Attention Accelerating Any Model Inference|SpargeAttention：准确且无需训练的稀疏注意力加速任意模型推理|Jintao Zhang, Chendong Xiang, Haofeng Huang, Jia Wei, Haocheng Xi, Jun Zhu, Jianfei Chen|<http://arxiv.org/pdf/2502.18137v6>|[代码](https://github.com/thu-ml/SpargeAttn.); 提出了一种通用的高效稀疏注意力机制，无需训练即可加速各类模型推理，同时保持性能不变。|
|🆕 发布|Generation of Indian Sign Language Letters, Numbers, and Words|印度手语字母、数字和单词的生成|Ajeet Kumar Yadav, Nishant Kumar, Rathna G N|<http://arxiv.org/pdf/2508.09522v1>|提出了一种结合ProGAN和SAGAN的GAN变体，生成高质量、高分辨率的印度手语字母、数字和词汇图...|
|🆕 发布|Gen-AFFECT: Generation of Avatar Fine-grained Facial Expressions with Consistent identiTy|《Gen-AFFECT：具有一致性身份的虚拟人精细面部表情生成》|Hao Yu, Rupayan Mallick, Margrit Betke, Sarah Adel Bargal|<http://arxiv.org/pdf/2508.09461v1>|提出了一种生成个性化且表情丰富、身份一致性的2D虚拟形象的新框架。|
|🆕 发布|RASR: Retrieval-Augmented Super Resolution for Practical Reference-based Image Restoration|基于检索增强的超分辨率：面向实用参考图像复原|Jiaqi Yan, Shuning Xu, Xiangyu Chen, Dell Zhang, Jie Tang, Gangshan Wu, Jie Liu|<http://arxiv.org/pdf/2508.09449v1>|提出了一种自动检索参考图像的超级分辨率方法，有效提升了实际场景中的图像恢复质量和实用性。|
|🆕 发布|DAgger Diffusion Navigation: DAgger Boosted Diffusion Policy for Vision-Language Navigation|DAgger扩散导航：DAgger增强的扩散策略在视觉-语言导航中的应用|Haoxiang Shi, Xiang Deng, Zaijing Li, Gongwei Chen, Yaowei Wang, Liqiang Nie|<http://arxiv.org/pdf/2508.09444v1>|[代码](https://github.com/Tokishx/DifNav.); 提出了一种端到端的视觉语言导航策略，通过整合规划阶段，提高了长距离导航的鲁棒性和误差恢复能力。|
|📝 更新|Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer|无训练的文本引导颜色编辑：基于多模态扩散变换器|Zixin Yin, Xili Dai, Ling-Hao Chen, Deyu Zhou, Jianan Wang, Duomin Wang, Gang Yu, Lionel M. Ni .etc.|<http://arxiv.org/pdf/2508.09131v2>|提出了一种无需训练的文本引导色彩编辑方法，通过多模态扩散变换器实现了精确且一致的颜色调整。|
|📝 更新|3D Gaussian Splatting Driven Multi-View Robust Physical Adversarial Camouflage Generation|三维高斯散点投影驱动的多视角鲁棒物理对抗性迷彩生成|Tianrui Lou, Xiaojun Jia, Siyuan Liang, Jiawei Liang, Ming Zhang, Yanjun Xiao, Xiaochun Cao|<http://arxiv.org/pdf/2507.01367v2>|[代码](https://github.com/TRLou/PGA.); 提出了一种基于3D高斯散点的物理攻击框架，实现了快速精确的重建和跨视角稳健的对抗性伪装生成。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SHALE: A Scalable Benchmark for Fine-grained Hallucination Evaluation in LVLMs|SHALE：用于LVLMs中细粒度幻觉评估的可扩展基准|Bei Yan, Zhiyuan Chen, Yuecong Min, Jie Zhang, Jiahao Wang, Xiaozhen Wang, Shiguang Shan|<http://arxiv.org/pdf/2508.09584v2>|提出了一种自动构建的细粒度幻觉评估基准SHALE，用于评估大型视觉语言模型在真实场景中的忠实性和事实...|
|🆕 发布|Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation|回声-4o：利用GPT-4o合成图像的力量以提高图像生成质量|Junyan Ye, Dongzhi Jiang, Zihao Wang, Leqi Zhu, Zhenghao Hu, Zilong Huang, Jun He, Zhiyuan Yan .etc.|<http://arxiv.org/pdf/2508.09987v1>|利用GPT-4o生成的合成图像增强开源模型，解决现实数据集覆盖盲区，提升文本到图像对齐精度。|
|🆕 发布|GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors|GS修复器：利用参考引导的视频扩散先验改进三维高斯散点绘制|Xingyilang Yin, Qi Zhang, Jiahao Chang, Ying Feng, Qingnan Fan, Xi Yang, Chi-Man Pun, Huaqi Zhang .etc.|<http://arxiv.org/pdf/2508.09667v1>|[代码](https://github.com/GVCLab/GSFixer.); 提出GSFixer框架，利用参考引导的视频扩散模型修复3D场景重建中的瑕疵，提升重建质量。|
|🆕 发布|SARE: Semantic-Aware Reconstruction Error for Generalizable Diffusion-Generated Image Detection|语义感知重建误差：用于通用扩散生成图像检测的方法|Ju Yeon Kang, Jaehong Park, Semin Kim, Ji Won Yoon, Nam Soo Kim|<http://arxiv.org/pdf/2508.09487v1>|提出了一种衡量图像与标题指导重建之间语义差异的SARE方法，有效提升了检测未见生成模型生成的伪造图像...|
|🆕 发布|RelayFormer: A Unified Local-Global Attention Framework for Scalable Image and Video Manipulation Localization|RelayFormer：一种用于可扩展图像与视频操作定位的统一局部-全局注意力框架|Wen Huang, Jiarui Yang, Tao Dai, Jiawei Li, Shaoxiong Zhan, Bin Wang, Shu-Tao Xia|<http://arxiv.org/pdf/2508.09459v1>|[代码](https://github.com/WenOOI/RelayFormer.); 提出RelayFormer框架，通过全局-局部注意力机制实现图像和视频篡改区域的精准定位，提升跨模态...|
|📝 更新|When Deepfakes Look Real: Detecting AI-Generated Faces with Unlabeled Data due to Annotation Challenges|当深度伪造看起来真实：由于标注挑战，使用无标签数据检测AI生成的面部|Zhiqiang Yang, Renshuai Tao, Xiaolong Zheng, Guodong Yang, Chunjie Zhang|<http://arxiv.org/pdf/2508.09022v2>|提出DPGNet方法，利用无标签数据解决深度伪造人脸检测标注难题。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Promise to Practical Reality: Transforming Diffusion MRI Analysis with Fast Deep Learning Enhancement|从期望到现实：利用快速深度学习增强转化扩散磁共振成像分析|Xinyi Wang, Michael Barnett, Frederique Boonstra, Yael Barnett, Mariano Cabezas, Arkiev D'Souza, Matthew C. Kiernan, Kain Kyle .etc.|<http://arxiv.org/pdf/2508.10950v1>|该研究提出FastFOD-Net，一种高效的深度学习框架，显著提升了扩散MRI数据分析的速度和准确性...|
|📝 更新|GenAI Confessions: Black-box Membership Inference for Generative Image Models|生成式图像模型的黑箱成员推断研究|Matyas Bohacek, Hany Farid|<http://arxiv.org/pdf/2501.06399v2>|提出了一种无需了解模型架构或权重，能判断图像是否被用于训练的黑盒成员推断方法。|
|🆕 发布|PERSONA: Personalized Whole-Body 3D Avatar with Pose-Driven Deformations from a Single Image|“PERSONA：从单张图像生成具有姿态驱动变形的个性化全身3D虚拟化身”|Geonhee Sim, Gyeongsik Moon|<http://arxiv.org/pdf/2508.09973v1>|提出了一种结合扩散和3D优化技术的PERSONA框架，从单张图片创建具有姿态驱动的个性化全身3D虚拟...|
|🆕 发布|Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models|噪声超网络：在扩散模型中摊销测试时的计算成本|Luca Eyring, Shyamgopal Karthik, Alexey Dosovitskiy, Nataniel Ruiz, Zeynep Akata|<http://arxiv.org/pdf/2508.09968v1>|[代码](https://github.com/ExplainableML/HyperNoise); 提出了一种Noise Hypernetwork方法，通过优化初始输入噪声，以较低计算成本恢复测试时优...|
|🆕 发布|Stable Diffusion Models are Secretly Good at Visual In-Context Learning|稳定的扩散模型在视觉情境学习中默默表现出色|Trevine Oorloff, Vishwanath Sindagi, Wele Gedara Chaminda Bandara, Ali Shafahi, Amin Ghiasi, Charan Prakash, Reza Ardekani|<http://arxiv.org/pdf/2508.09949v1>|展示了现成的Stable Diffusion模型通过内注意力机制改进，无需额外训练即可适应多种视觉任...|
|🆕 发布|AST-n: A Fast Sampling Approach for Low-Dose CT Reconstruction using Diffusion Models|AST-n：基于扩散模型的低剂量CT重建快速采样方法|Tomás de la Sotta, José M. Saavedra, Héctor Henríquez, Violeta Chang, Aline Xavier|<http://arxiv.org/pdf/2508.09943v1>|提出AST-n方法，通过加速扩散模型推理，实现低剂量CT快速重建且图像质量损失小。|
|📝 更新|CAS-IQA: Teaching Vision-Language Models for Synthetic Angiography Quality Assessment|CAS-IQA：用于合成血管造影质量评估的视觉-语言模型教学|Bo Wang, De-Xing Huang, Xiao-Hu Zhou, Mei-Jiang Gui, Nu-Fang Xiao, Jian-Long Hao, Ming-Yuan Liu, Zeng-Guang Hou|<http://arxiv.org/pdf/2505.17619v2>|提出CAS-IQA框架，利用视觉语言模型和辅助图像信息，显著提升合成血管造影图像质量评估准确性。|
|📝 更新|Cryo-em images are intrinsically low dimensional|冷冻电镜图像本质上是低维的|Luke Evans, Octavian-Vlad Murad, Lars Dingeldein, Pilar Cossio, Roberto Covino, Marina Meila|<http://arxiv.org/pdf/2504.11249v2>|揭示了冷冻电镜数据内在的低维结构，为提高生物分子构象推断提供了新策略。|
|🆕 发布|Hierarchical Graph Attention Network for No-Reference Omnidirectional Image Quality Assessment|层次化图注意力网络用于无需参考的全景图像质量评估|Hao Yang, Xu Zhang, Jiaqi Ma, Linwei Zhu, Yun Zhang, Huan Zhang|<http://arxiv.org/pdf/2508.09843v1>|提出了一种基于图神经网络的OIQA框架，通过建模视口间结构关系，有效提升了空间非均匀失真的评估能力。|
|🆕 发布|Automated Segmentation of Coronal Brain Tissue Slabs for 3D Neuropathology|冠状脑组织切片的自动化分割用于三维神经病理学分析|Jonathan Williams Ramirez, Dina Zemlyanker, Lucas Deden-Binder, Rogeny Herisse, Erendira Garcia Pallares, Karthik Gopinath, Harshvardhan Gazula, Christopher Mount .etc.|<http://arxiv.org/pdf/2508.09805v1>|分割脑组织切片照片，提出基于U-Net的自动分割模型，实现接近人工标注的准确度。|
|📝 更新|DRWKV: Focusing on Object Edges for Low-Light Image Enhancement|DRWKV：关注物体边缘的低光图像增强|Xuecheng Bai, Yuxiang Wang, Boyu Hu, Qinyuan Jie, Chuanzhi Xu, Hongru Xiao, Kechen Li, Vera Chung|<http://arxiv.org/pdf/2507.18594v2>|提出DRWKV模型，通过分离光照与边缘结构并增强边缘连续性，有效提升低光图像质量和细节。|
|🆕 发布|MUJICA: Reforming SISR Models for PBR Material Super-Resolution via Cross-Map Attention|MUJICA：通过交叉图注意力改进SISR模型以实现PBR材料超分辨率|Xin Du, Maoyuan Xu, Zhi Ying|<http://arxiv.org/pdf/2508.09802v1>|提出MUJICA方法，通过跨图注意力改进预训练SISR模型，提升PBR材质超分辨率性能。|
|📝 更新|CD-TVD: Contrastive Diffusion for 3D Super-Resolution with Scarce High-Resolution Time-Varying Data|CD-TVD：基于稀缺高分辨率时变数据的对比扩散三维超分辨率|Chongke Bi, Xin Gao, Jiangkang Deng, Guan Li, Jun Han|<http://arxiv.org/pdf/2508.08173v2>|[代码](https://github.com/Xin-Gao-private/CD-TVD.); 提出CD-TVD框架，结合对比学习和改进的扩散模型，实现少量高分辨率时变数据下的精确3D超分辨率。|
|📝 更新|Image Intrinsic Scale Assessment: Bridging the Gap Between Quality and Resolution|图像固有尺度评估：桥接质量与分辨率之间的差距|Vlad Hosu, Lorenzo Agnolucci, Daisuke Iso, Dietmar Saupe|<http://arxiv.org/pdf/2502.06476v3>|[代码](https://github.com/SonyResearch/IISA.); 提出图像固有尺度概念及评估方法，通过弱标签策略提升图像质量评估准确性。|
|🆕 发布|MangaDiT: Reference-Guided Line Art Colorization with Hierarchical Attention in Diffusion Transformers|《MangaDiT：基于参考引导的层次注意力扩散变换器的线艺术着色》|Qianru Qiu, Jiafeng Mao, Kento Masui, Xueting Wang|<http://arxiv.org/pdf/2508.09709v1>|提出了一种基于扩散变换器的 hierarchical attention 机制，用于改善参考引导的线...|
|📝 更新|LUMA: A Benchmark Dataset for Learning from Uncertain and Multimodal Data|LUMA：一个用于从不确定性和多模态数据中学习的基准数据集|Grigor Bezirganyan, Sana Sellami, Laure Berti-Équille, Sébastien Fournier|<http://arxiv.org/pdf/2406.09864v3>|[代码](https://github.com/bezirganyan/LUMA); 提出了LUMA多模态数据集，为研究不确定性对多模态深度学习模型影响提供了可控实验环境。|
|📝 更新|UltraRay: Introducing Full-Path Ray Tracing in Physics-Based Ultrasound Simulation|《UltraRay：在基于物理的超声模拟中引入全路径光线追踪》|Felix Duelmer, Mohammad Farid Azampour, Magdalena Wysocki, Nassir Navab|<http://arxiv.org/pdf/2501.05828v2>|提出了一种全路径光线追踪的超声波仿真方法，提高了图像真实性和减少了人工伪影。|
|📝 更新|Human Motion Capture from Loose and Sparse Inertial Sensors with Garment-aware Diffusion Models|基于宽松稀疏惯性传感器和衣物感知扩散模型的人体运动捕捉|Andela Ilic, Jiaxi Jiang, Paul Streli, Xintong Liu, Christian Holz|<http://arxiv.org/pdf/2506.15290v2>|提出了一种基于扩散模型的方法，能够从松散佩戴的稀疏惯性传感器估计全身姿态。|
|📝 更新|Towards Black-Box Membership Inference Attack for Diffusion Models|面向扩散模型的黑箱成员推断攻击方法研究|Jingwei Li, Jing Dong, Tianxing He, Jingzhao Zhang|<http://arxiv.org/pdf/2405.20771v5>|提出了一种无需访问模型内部结构的黑盒成员推断攻击方法，有效识别图像是否用于训练扩散模型。|
|🆕 发布|Episodic Memory Representation for Long-form Video Understanding|长视频理解中的情景记忆表征|Yun Wang, Long Zhang, Jingren Liu, Jiaqi Yan, Zhanjie Zhang, Jiahao Zheng, Xun Yang, Dapeng Wu .etc.|<http://arxiv.org/pdf/2508.09486v1>|提出了一种基于人类情景记忆原理的Video-EM框架，通过建模关键帧的时空关系，增强长视频理解和问答...|
|🆕 发布|Event-driven Robust Fitting on Neuromorphic Hardware|基于类神经形态硬件的事件驱动鲁棒拟合|Tam Ngoc-Bang Nguyen, Anh-Dzung Doan, Zhipeng Cai, Tat-Jun Chin|<http://arxiv.org/pdf/2508.09466v1>|提出了一种基于神经形态硬件的节能稳健拟合方法，大幅降低了能耗。|
|🆕 发布|Animate-X++: Universal Character Image Animation with Dynamic Backgrounds|动态背景下的通用角色图像动画：Animate-X++|Shuai Tan, Biao Gong, Zhuoxin Liu, Yan Wang, Xi Chen, Yifan Feng, Hengshuang Zhao|<http://arxiv.org/pdf/2508.09454v1>|提出Animate-X++框架，实现多种角色图像动画，并引入动态背景增强真实感。|
|🆕 发布|Personalized Face Super-Resolution with Identity Decoupling and Fitting|个性化人脸超分辨率：身份解耦与适配|Jiarui Yang, Hang Guo, Wen Huang, Tao Dai, Shutao Xia|<http://arxiv.org/pdf/2508.10937v1>|提出了一种在极端退化场景下通过身份解耦与适配提升面部超分辨率重建的方法。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|T-CACE: A Time-Conditioned Autoregressive Contrast Enhancement Multi-Task Framework for Contrast-Free Liver MRI Synthesis, Segmentation, and Diagnosis|T-CACE:一种基于时间条件的自回归对比增强多任务框架，用于无对比剂肝脏磁共振成像的合成、分割和诊断|Xiaojiao Xiao, Jianfeng Zhao, Qinmin Vivian Hu, Guanghui Wang|<http://arxiv.org/pdf/2508.09919v1>|[代码](https://github.com/xiaojiao929/T-CACE.); 提出T-CACE框架，通过无对比剂MRI直接合成多相位对比增强图像，提升肝脏病变诊断的安全性和效率。|
|🆕 发布|SpeechForensics: Audio-Visual Speech Representation Learning for Face Forgery Detection|语音法医学：基于音频-视觉语音表征学习的面部伪造检测|Yachao Liang, Min Yu, Gang Li, Jianguo Jiang, Boquan Li, Feng Yu, Ning Zhang, Xiang Meng .etc.|<http://arxiv.org/pdf/2508.09913v1>|[代码](https://github.com/Eleven4AI/SpeechForensics.); 利用音频与视觉语音元素的协同作用，提出了一种新的音频-视觉语音表征学习法，有效提高了面部伪造视频检测...|
|🆕 发布|Evolution of Low-Level and Texture Human-CLIP Alignment|低层次和纹理人类-CLIP对齐的演变|Pablo Hernández-Cámara, Jose Manuel Jaén-Lorites, Jorge Vila-Tomás, Jesus Malo, Valero Laparra|<http://arxiv.org/pdf/2508.09814v1>|揭示了CLIP模型在训练初期与人类低级视觉感知高度一致的现象，并探讨了其背后的学习机制。|
|🆕 发布|Surg-InvNeRF: Invertible NeRF for 3D tracking and reconstruction in surgical vision|手术视觉中的3D跟踪与重建：可逆神经辐射场(Surg-InvNeRF)|Gerardo Loza, Junlei Hu, Dominic Jones, Sharib Ali, Pietro Valdastri|<http://arxiv.org/pdf/2508.09681v1>|提出了一种基于NeRF架构的测试时优化方法，实现了手术场景中长期的2D和3D点跟踪。|
|📝 更新|FROST-BRDF: A Fast and Robust Optimal Sampling Technique for BRDF Acquisition|FROST-BRDF：一种快速且稳健的BRDF获取最优采样技术|Ehsan Miandji, Tanaboon Tongbuasirilai, Saghi Hajisharif, Behnaz Kavoosighafi, Jonas Unger|<http://arxiv.org/pdf/2401.07283v2>|提出了一种快速稳健的BRDF获取最优采样技术，将BRDF采集转化为压缩感知问题，大幅提升重构质量和效...|
|🆕 发布|Physics-guided Deep Unfolding Network for Enhanced Kronecker Compressive sensing|基于物理引导的深度展开网络以增强Kronecker压缩感知|Gang Qu, Ping Wang, Siming Zheng, Xin Yuan|<http://arxiv.org/pdf/2508.09528v1>|提出了一种物理引导的深度展开网络，通过增强测量相干性和学习测量表示，提高了图像压缩感知的性能。|
|📝 更新|NeuralGS: Bridging Neural Fields and 3D Gaussian Splatting for Compact 3D Representations|神经场与三维高斯散点绘制结合的紧凑三维表示方法：NeuralGS|Zhenyu Tang, Chaoran Feng, Xinhua Cheng, Wangbo Yu, Junwu Zhang, Yuan Liu, Xiaoxiao Long, Wenping Wang .etc.|<http://arxiv.org/pdf/2503.23162v2>|提出了一种紧凑型3D表示方法NeuralGS，用神经网络压缩3D高斯分布，大幅减少存储需求而不损失视...|
|🆕 发布|MPT: Motion Prompt Tuning for Micro-Expression Recognition|MPT：微表情识别的运动提示调优|Jiateng Liu, Hengcan Shi, Feng Chen, Zhiwen Shao, Yaonan Wang, Jianfei Cai, Wenming Zheng|<http://arxiv.org/pdf/2508.09446v1>|提出Motion Prompt Tuning方法，通过微动作提示增强大型预训练模型对微表情的识别能力...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|E-4DGS: High-Fidelity Dynamic Reconstruction from the Multi-view Event Cameras|E-4DGS：基于多视角事件相机的高保真动态重建|Chaoran Feng, Zhenyu Tang, Wangbo Yu, Yatian Pang, Yian Zhao, Jianbin Zhao, Li Yuan, Yonghong Tian|<http://arxiv.org/pdf/2508.09912v1>|提出了一种基于事件相机的高保真动态重建方法E-4DGS，解决了高速运动和低光照场景下的重建挑战。|
|📝 更新|Multi-view Normal and Distance Guidance Gaussian Splatting for Surface Reconstruction|多视角法向量和距离引导的高斯散点绘制法用于表面重建|Bo Jia, Yanan Guo, Ying Chang, Benkui Zhang, Ying Xie, Kangning Du, Lin Cao|<http://arxiv.org/pdf/2508.07701v2>|[代码](https://github.com/Bistu3DV/MND-GS); 引入多视角正常向量和距离引导的约束，提升了三维表面重建的准确性和一致性。|
|📝 更新|BridgeDepth: Bridging Monocular and Stereo Reasoning with Latent Alignment|桥接深度：通过潜在对齐融合单目与立体推理|Tongfan Guan, Jiaxin Guo, Chen Wang, Yun-Hui Liu|<http://arxiv.org/pdf/2508.04611v2>|[代码](https://github.com/aeolusguan/BridgeDepth.); 提出了一种统一框架，通过双向对齐显式融合单目和双目深度估计的优势，显著提升了三维感知的鲁棒性。|
|🆕 发布|Enhancing Monocular 3D Hand Reconstruction with Learned Texture Priors|利用学习到的纹理先验增强单目3D手部重建|Giorgos Karvounas, Nikolaos Kyriazis, Iason Oikonomidis, Georgios Pavlakos, Antonis A. Argyros|<http://arxiv.org/pdf/2508.09629v1>|提出利用纹理先验增强单目3D手部重建，通过密集纹理对齐提升姿态与形状估计的准确性和真实性。|
|🆕 发布|CWFBind: Geometry-Awareness for Fast and Accurate Protein-Ligand Docking|CWFBind：面向快速准确蛋白质-配体对接的几何感知|Liyan Jia, Chuan-Xian Ren, Hong Yan|<http://arxiv.org/pdf/2508.09499v1>|引入CWFBind，一种融合局部曲率特征以提升蛋白质-配体对接准确性和速度的方法。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|What-Meets-Where: Unified Learning of Action and Contact Localization in a New Dataset|“所见即所得：在一个新数据集中对动作和接触定位的统一学习”|Yuxiao Wang, Yu Lei, Wolin Liang, Weiying Xue, Zhenao Wei, Nan Zhuang, Qi Liu|<http://arxiv.org/pdf/2508.09428v1>|提出了一种统一学习动作和接触定位的新任务和框架PaIR-Net，有效桥接了动作语义与场景空间上下文的...|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SOI is the Root of All Evil: Quantifying and Breaking Similar Object Interference in Single Object Tracking|“SOI是万恶之源：量化并打破单目标跟踪中的相似物体干扰”|Yipei Wang, Shiyu Hu, Shukun Jia, Panxi Xu, Hongfei Ma, Yiping Ma, Jing Zhang, Xiaobo Lu .etc.|<http://arxiv.org/pdf/2508.09524v2>|揭示了相似物体干扰的问题，并提出了使用大规模视觉语言模型作为外部认知引擎的新范式。|
|📝 更新|Follow-Your-Motion: Video Motion Transfer via Efficient Spatial-Temporal Decoupled Finetuning|“跟随你的动作：通过高效时空解耦微调实现视频运动迁移”|Yue Ma, Yulong Liu, Qiyuan Zhu, Ayden Yang, Kunyu Feng, Xinhua Zhang, Zhifeng Li, Sirui Han .etc.|<http://arxiv.org/pdf/2506.05207v2>|提出了一种高效的视频运动转移框架，通过解耦空间和时间处理，提高了运动一致性和微调效率。|
|📝 更新|STAC: Leveraging Spatio-Temporal Data Associations For Efficient Cross-Camera Streaming and Analytics|STAC：利用时空数据关联实现高效的跨摄像头流传输与分析|Ragini Gupta, Lingzhi Zhao, Jiaxi Li, Volodymyr Vakhniuk, Claudiu Danilov, Josh Eckhardt, Keyshla Bernard, Klara Nahrstedt|<http://arxiv.org/pdf/2401.15288v2>|提出STAC系统，通过利用时空数据关联实现分布式摄像头网络中高效的对象跟踪与数据压缩。|
|🆕 发布|MeMoSORT: Memory-Assisted Filtering and Motion-Adaptive Association Metric for Multi-Person Tracking|MeMoSORT：基于内存辅助过滤和运动自适应关联度量的多人跟踪|Yingjie Wang, Zhixing Wang, Le Zheng, Tianxiao Liu, Roujing Li, Xueyao Hu|<http://arxiv.org/pdf/2508.09796v1>|提出MeMoSORT算法，通过记忆辅助滤波和自适应运动匹配，有效解决多目标跟踪中的动态误差和遮挡问题...|
|📝 更新|PrAViC: Probabilistic Adaptation Framework for Real-Time Video Classification|PrAViC：实时视频分类的概率适应框架|Magdalena Trędowicz, Marcin Mazur, Szymon Janusz, Arkadiusz Lewicki, Jacek Tabor, Łukasz Struski|<http://arxiv.org/pdf/2406.11443v2>|提出了一种实时视频分类的概率适应框架PrAViC，通过早期决策和模型适应，大幅缩短了分类时间并保持或...|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|iSafetyBench: A video-language benchmark for safety in industrial environment|工业环境安全性的视频-语言评估基准：iSafetyBench|Raiyaan Abdullah, Yogesh Singh Rawat, Shruti Vyas|<http://arxiv.org/pdf/2508.00399v2>|[代码](https://github.com/iSafetyBench/data.); 提出iSafetyBench，专为评估工业环境下视觉语言模型在正常与危险场景的性能的基准测试。|
|📝 更新|Video SimpleQA: Towards Factuality Evaluation in Large Video Language Models|视频简单问答：面向大型视频语言模型的事实性评估|Meng Cao, Pengfei Hu, Yingyao Wang, Jihao Gu, Haoran Tang, Haoze Zhao, Chen Wang, Jiahua Dong .etc.|<http://arxiv.org/pdf/2503.18923v2>|提出Video SimpleQA基准，用于评估大型视频语言模型在视频情境中的事实性准确性。|
|📝 更新|Are you Struggling? Dataset and Baselines for Struggle Determination in Assembly Videos|你在挣扎吗？装配视频中的挣扎判定数据集与基线|Shijia Feng, Michael Wray, Brian Sullivan, Youngkyoon Jang, Casimir Ludwig, Iain Gilchrist, Walterio Mayol-Cuevas|<http://arxiv.org/pdf/2402.11057v5>|提出首个挣扎识别数据集，并对比了多种深度学习模型，为挣扎分类任务建立了基线结果。|
|🆕 发布|OneVAE: Joint Discrete and Continuous Optimization Helps Discrete Video VAE Train Better|《OneVAE：联合离散与连续优化助力离散视频VAE训练更佳》|Yupeng Zhou, Zhen Li, Ziheng Ouyang, Yuming Chen, Ruoyi Du, Daquan Zhou, Bin Fu, Yihao Liu .etc.|<http://arxiv.org/pdf/2508.09857v1>|提出了一种融合连续和离散优化的OneVAE方法，有效解决了视频VAE训练不稳定和重建质量差的问题。|
|🆕 发布|ViMoNet: A Multimodal Vision-Language Framework for Human Behavior Understanding from Motion and Video|ViMoNet：一种基于运动和视频理解人类行为的多模态视觉-语言框架|Rajan Das Gupta, Md Yeasin Rahat, Nafiz Fahad, Abir Ahmed, Liew Tze Hui|<http://arxiv.org/pdf/2508.09818v1>|提出了一种融合动作与视频数据的多模态语言模型框架ViMoNet，有效提升了人类行为理解能力。|
|🆕 发布|TOTNet: Occlusion-Aware Temporal Tracking for Robust Ball Detection in Sports Videos|TOTNet：面向遮挡感知的体育视频鲁棒球检测的时序跟踪网络|Hao Xu, Arbind Agrahari Baniya, Sam Wells, Mohamed Reda Bouadjenek, Richard Dazely, Sunil Aryal|<http://arxiv.org/pdf/2508.09650v1>|[代码](https://github.com/AugustRushG/TOTNet); 提出TOTNet，通过3D卷积和可见性加权损失提升遮挡下的运动球体追踪性能。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Learning Adaptive Node Selection with External Attention for Human Interaction Recognition|学习自适应节点选择与外部注意力机制用于人体交互识别|Chen Pang, Xuequan Lu, Qianyu Zhou, Lei Lyu|<http://arxiv.org/pdf/2507.03936v2>|提出了一种动态捕捉人际互动关系的方法ASEA，通过外部注意力网络自适应选择关键节点，提升了人类互动识...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hierarchical Brain Structure Modeling for Predicting Genotype of Glioma|基于层次化大脑结构建模预测胶质瘤基因型|Haotian Tang, Jianwei Chen, Xinrui Tang, Yunjia Wu, Zhengyang Miao, Chao Li|<http://arxiv.org/pdf/2508.09593v1>|提出Hi-SMGNN模型，通过融合脑部结构信息预测胶质瘤基因型，提升预测准确性和鲁棒性。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PaCo-FR: Patch-Pixel Aligned End-to-End Codebook Learning for Facial Representation Pre-training|PaCo-FR：基于贴图-像素对齐的端到端码本学习用于面部表征预训练|Yin Xie, Zhichao Chen, Xiaoze Yu, Yongle Zhao, Xiang An, Kaicheng Yang, Zimin Ran, Jia Guo .etc.|<http://arxiv.org/pdf/2508.09691v1>|提出了一种结合掩码图像建模与贴图像素对齐的PaCo-FR框架，有效提升面部特征表示学习在少量无标注数...|


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BridgeTA: Bridging the Representation Gap in Knowledge Distillation via Teacher Assistant for Bird's Eye View Map Segmentation|BridgeTA：通过教师助手在鸟瞰图分割中缩小知识蒸馏的表征差距|Beomjun Kim, Suhan Woo, Sejong Heo, Euntai Kim|<http://arxiv.org/pdf/2508.09599v1>|提出BridgeTA框架，通过引入教师助手网络缩小LC融合与仅相机方法的表现差距，无需改变学生模型架...|
|🆕 发布|HyperKD: Distilling Cross-Spectral Knowledge in Masked Autoencoders via Inverse Domain Shift with Spatial-Aware Masking and Specialized Loss|《HyperKD：通过逆域转换及空间感知掩码与专用损失在掩码自编码器中蒸馏跨谱知识》|Abdul Matin, Tanjim Bin Faruk, Shrideep Pallickara, Sangmi Lee Pallickara|<http://arxiv.org/pdf/2508.09453v1>|提出HyperKD框架，通过逆向域转移和特定损失函数，有效提升 hyperspectral 图像的表...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Reverse Convolution and Its Applications to Image Restoration|逆向卷积及其在图像复原中的应用|Xuhong Huang, Shiqi Liu, Kai Zhang, Ying Tai, Jian Yang, Hui Zeng, Lei Zhang|<http://arxiv.org/pdf/2508.09824v2>|提出了一种深度反向卷积操作，有效逆转卷积效果并构建了新型网络结构ConverseNet，用于图像复原...|
|🆕 发布|Improving watermelon (Citrullus lanatus) disease classification with generative artificial intelligence (GenAI)-based synthetic and real-field images via a custom EfficientNetV2-L model|通过定制EfficientNetV2-L模型利用生成人工智能（GenAI）基于合成与实际田地图像改进西瓜（Citrullus lanatus）病害分类|Nitin Rai, Nathan S. Boyd, Gary E. Vallad, Arnold W. Schumann|<http://arxiv.org/pdf/2508.10156v1>|利用生成式人工智能合成图像与少量真实图像结合，提升了水melon疾病分类模型的准确性和泛化能力。|
|📝 更新|Explaining Caption-Image Interactions in CLIP Models with Second-Order Attributions|《使用二阶属性解释CLIP模型中的标题-图像交互》|Lucas Möller, Pascal Tilli, Ngoc Thang Vu, Sebastian Padó|<http://arxiv.org/pdf/2408.14153v4>|[代码](https://github.com/lucasmllr/exCLIP); 提出了一种新的二阶归因方法，揭示了CLIP模型如何通过特征间交互比较图像和标题。|
|🆕 发布|Combating Noisy Labels via Dynamic Connection Masking|通过动态连接掩码对抗噪声标签|Xinlei Zhang, Fan Liu, Chuanyi Zhang, Fan Cheng, Yuhui Zheng|<http://arxiv.org/pdf/2508.09697v1>|提出动态连接掩码机制，增强模型对噪声标签的鲁棒性，优于现有方法。|
|🆕 发布|Noise-adapted Neural Operator for Robust Non-Line-of-Sight Imaging|噪声适应的神经算子用于稳健的非视线成像|Lianfang Wang, Kuilin Qin, Xueying Liu, Huibin Chang, Yong Wang, Yuping Duan|<http://arxiv.org/pdf/2508.09655v1>|提出了一种适应噪声的神经运算符框架，用于三维非视距成像的快速准确重建。|
|🆕 发布|Deep Learning for Automated Identification of Vietnamese Timber Species: A Tool for Ecological Monitoring and Conservation|深度学习在自动识别越南木材种类中的应用：生态监测与保护的工具|Tianyu Song, Van-Doan Duong, Thi-Phuong Le, Ton Viet Ta|<http://arxiv.org/pdf/2508.10938v1>|利用深度学习实现越南木材种类自动化识别，提升生态监测与保护效率。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Semantic-aware DropSplat: Adaptive Pruning of Redundant Gaussians for 3D Aerial-View Segmentation|语义感知的DropSplat：三维空中视图分割中冗余高斯分布的自适应剪枝|Xu Tang, Junan Jia, Yijing Wang, Jingjing Ma, Xiangrong Zhang|<http://arxiv.org/pdf/2508.09626v2>|提出了一种自适应精简高斯点的3D空中场景分割方法，通过消除冗余和语义模糊点，提高了分割准确性和表示紧...|
|🆕 发布|EntropyGS: An Efficient Entropy Coding on 3D Gaussian Splatting|熵GS：三维高斯散点上的高效熵编码|Yuning Huang, Jiahao Pang, Fengqing Zhu, Dong Tian|<http://arxiv.org/pdf/2508.10227v1>|提出熵编码方法EntropyGS，针对3D Gaussian Splatting的高效存储与传输问题...|
|📝 更新|Leveraging AI to Accelerate Medical Data Cleaning: A Comparative Study of AI-Assisted vs. Traditional Methods|利用人工智能加速医疗数据清洗：人工智能辅助与传统方法的比较研究|Matthew Purri, Amit Patel, Erik Deurrell|<http://arxiv.org/pdf/2508.05519v2>|提出AI辅助平台Octozi，提高医疗数据清洗效率6倍以上并显著降低错误率。|
|🆕 发布|LIA-X: Interpretable Latent Portrait Animator|LIA-X：可解释的潜在肖像动画器|Yaohui Wang, Di Yang, Xinyuan Chen, Francois Bremond, Yu Qiao, Antitza Dantcheva|<http://arxiv.org/pdf/2508.09959v1>|提出LIA-X，通过稀疏运动字典实现面部动态的细粒度可控转移和编辑。|
|🆕 发布|Combinative Matching for Geometric Shape Assembly|组合匹配在几何形状装配中的应用|Nahyuk Lee, Juhong Min, Junhong Lee, Chunghyun Park, Minsu Cho|<http://arxiv.org/pdf/2508.09780v1>|[代码](https://nahyuklee.github.io/cmnet.); 引入组合匹配方法，通过建模互锁形状的独特属性，实现几何形状组装的精确对应。|
|🆕 发布|Analysis of the Compaction Behavior of Textile Reinforcements in Low-Resolution In-Situ CT Scans via Machine-Learning and Descriptor-Based Methods|通过机器学习和基于描述符的方法对低分辨率现场CT扫描中纺织增强材料的压实行为分析|Christian Düreth, Jan Condé-Wolter, Marek Danczak, Karsten Tittmann, Jörn Jaschinski, Andreas Hornig, Maik Gude|<http://arxiv.org/pdf/2508.10943v1>|提出了一种基于机器学习和描述符的方法，通过低分辨率CT扫描量化纺织增强材料的层叠行为。|
|🆕 发布|Plane Detection and Ranking via Model Information Optimization|通过模型信息优化进行平面检测与排序|Daoxin Zhong, Jun Li, Meng Yee Michael Chuah|<http://arxiv.org/pdf/2508.09625v1>|提出了一种基于模型信息优化的平面检测框架，减少了深度图像平面检测中的误报问题。|
|📝 更新|GranQ: Granular Zero-Shot Quantization with Channel-Wise Activation Scaling in QAT|粒度零样本量化：在QAT中基于通道激活缩放的GranQ|Inpyo Hong, Youngwan Jo, Hyojeong Lee, Sunghyun Ahn, Kijung Lee, Sanghyun Park|<http://arxiv.org/pdf/2503.18339v5>|[代码](https://github.com/anonymus-orange/GranQ.); 提出了一种高效的预缩放策略GranQ，通过向量化的计算减少量化过程中的计算负担，提升低比特量化下的模...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Transferable Model-agnostic Vision-Language Model Adaptation for Efficient Weak-to-Strong Generalization|迁移性模型无关的视觉-语言模型适配：用于高效弱到强泛化|Jihwan Park, Taehoon song, Sanghyeok Lee, Miso Choi, Hyunwoo J. Kim|<http://arxiv.org/pdf/2508.08604v2>|提出了一种轻量级适配器TransMiter，无需反向传播即可高效迁移视觉语言模型的适应知识。|
|📝 更新|Integrating Clinical Knowledge Graphs and Gradient-Based Neural Systems for Enhanced Melanoma Diagnosis via the 7-Point Checklist|通过整合临床知识图谱和基于梯度的神经网络，利用7点清单增强黑色素瘤诊断|Yuheng Wang, Tianze Yu, Jiayue Cai, Sunil Kalia, Harvey Lui, Z. Jane Wang, Tim K. Lee|<http://arxiv.org/pdf/2407.16822v2>|整合临床知识图谱与梯度诊断策略，提升黑色素瘤诊断准确性和特征预测能力。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Comprehensive Cellular Characterisation of H&E slides|迈向全面细胞特征描述的H&E切片研究|Benjamin Adjadj, Pierre-Antoine Bannier, Guillaume Horent, Sebastien Mandela, Aurore Lyon, Kathryn Schutte, Ulysse Marteau, Valentin Gaury .etc.|<http://arxiv.org/pdf/2508.09926v2>|[代码](https://github.com/owkin/histoplus); 提出HistoPLUS模型，通过新型泛癌数据集提升了对罕见细胞类型的检测与分类性能。|
|🆕 发布|Iterative Volume Fusion for Asymmetric Stereo Matching|迭代体积融合用于非对称立体匹配|Yuanting Gao, Linghao Shen|<http://arxiv.org/pdf/2508.09543v2>|提出迭代体积融合网络解决非对称立体匹配问题，有效融合两种成本体积信息，提升匹配精度。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|COME: Dual Structure-Semantic Learning with Collaborative MoE for Universal Lesion Detection Across Heterogeneous Ultrasound Datasets|COME：基于协作MoE的双结构-语义学习，实现异质超声数据集的通用病变检测|Lingyu Chen, Yawen Zeng, Yue Wang, Peng Wan, Guo-chen Ning, Hongen Liao, Daoqiang Zhang, Fang Chen|<http://arxiv.org/pdf/2508.09886v1>|[代码](https://universalcome.github.io/UniversalCOME); 提出了一种跨异质超声数据集的混合专家协同学习框架COME，通过结构-语义共享专家和特定源专家的互补特...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Interpretable Oracle Bone Script Decipherment through Radical and Pictographic Analysis with LVLMs|通过部首和象形分析以及LVLMs的可解释甲骨文解读|Kaixin Peng, Mengyang Zhao, Haiyang Yu, Teng Fu, Bin Li|<http://arxiv.org/pdf/2508.10113v2>|[代码](https://github.com/PKXX1943/PD-OBS.); 提出了一种基于大型视觉语言模型的甲骨文解读方法，结合部首和图形语义分析，提高了零样本情况下的解读性能...|
|🆕 发布|MANGO: Multimodal Attention-based Normalizing Flow Approach to Fusion Learning|MANGO：多模态注意力驱动的归一化流融合学习方法|Thanh-Dat Truong, Christophe Bobda, Nitin Agarwal, Khoa Luu|<http://arxiv.org/pdf/2508.10133v1>|提出了一种显式、可解释且可处理的Multimodal Attention-based Normali...|
|📝 更新|Improved Regularization and Robustness for Fine-tuning in Neural Networks|神经网络微调中的改进正则化和鲁棒性|Dongyue Li, Hongyang R. Zhang|<http://arxiv.org/pdf/2111.04578v2>|提出了一种正则化自我标注方法，有效提升了迁移学习中的泛化能力和抗噪声性。|
|🆕 发布|TRACE: Learning 3D Gaussian Physical Dynamics from Multi-view Videos|TRACE：从多视角视频中学习三维高斯物理动力学|Jinxi Li, Ziyang Song, Bo Yang|<http://arxiv.org/pdf/2508.09811v1>|提出了一种新框架TRACE，通过直接学习每个粒子的运动物理参数，实现了无需标签即可从多视角视频学习复...|
|🆕 发布|DSS-Prompt: Dynamic-Static Synergistic Prompting for Few-Shot Class-Incremental Learning|DSS-Prompt: 动静协同提示式少样本类别增量学习|Linpu He, Yanan Li, Bingze Li, Elvis Han Cui, Donghui Wang|<http://arxiv.org/pdf/2508.09785v1>|提出DSS-Prompt方法，通过结合静态和动态提示，有效提升少量样本增量学习性能。|
|📝 更新|LiteFat: Lightweight Spatio-Temporal Graph Learning for Real-Time Driver Fatigue Detection|LiteFat：实时驾驶员疲劳检测的轻量级时空图学习|Jing Ren, Suyu Ma, Hong Jia, Xiwei Xu, Ivan Lee, Haytham Fayek, Xiaodong Li, Feng Xia|<http://arxiv.org/pdf/2507.21756v2>|提出了一种轻量级时空图学习模型 LiteFat，用于实时高效地检测驾驶员疲劳，降低计算复杂度和延迟。|
|🆕 发布|Stochastic-based Patch Filtering for Few-Shot Learning|基于随机性的图块过滤算法用于少样本学习|Javier Rodenas, Eduardo Aguilar, Petia Radeva|<http://arxiv.org/pdf/2508.10066v1>|提出基于随机滤波的少次学习 patch 处理方法，有效突出食物特征并过滤干扰信息。|
|🆕 发布|Slot Attention-based Feature Filtering for Few-Shot Learning|基于槽注意力机制的少量样本学习特征筛选方法|Javier Rodenas, Eduardo Aguilar, Petia Radeva|<http://arxiv.org/pdf/2508.09699v1>|提出基于槽注意力机制的特征过滤方法，有效筛选弱特征提升少量样本学习分类性能。|
|📝 更新|Modulate and Reconstruct: Learning Hyperspectral Imaging from Misaligned Smartphone Views|调制与重建：从失配智能手机视角学习高光谱成像|Daniil Reutsky, Daniil Vladimirov, Yasin Mamedov, Georgy Perevozchikov, Nancy Mehta, Egor Ershov, Radu Timofte|<http://arxiv.org/pdf/2507.01835v2>|利用三摄像头智能手机系统及特定光谱滤波器，实现了比传统单摄像头更准确的 hyperspectral ...|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Debiased Fine-Tuning for Vision-language Models by Prompt Regularization|通过提示正则化进行视觉-语言模型的无偏微调|Beier Zhu, Yulei Niu, Saeil Lee, Minhoe Hur, Hanwang Zhang|<http://arxiv.org/pdf/2301.12429v3>|提出了一种通过提示正则化避免下游任务数据过拟合的视觉语言模型微调新范式。|
|📝 更新|Prompt-aligned Gradient for Prompt Tuning|"提示对齐的梯度用于提示微调"|Beier Zhu, Yulei Niu, Yucheng Han, Yue Wu, Hanwang Zhang|<http://arxiv.org/pdf/2205.14865v4>|[代码](https://github.com/BeierZhu/Prompt-align.); 提出ProGrad方法，通过保持梯度一致性防止prompt调优遗忘预训练模型的一般知识，增强少样本泛...|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HVL: Semi-Supervised Segmentation leveraging Hierarchical Vision-Language Synergy with Dynamic Text-Spatial Query Alignment|HVL: 利用动态文本-空间查询对齐的分层视觉-语言协同作用的半监督分割|Numair Nadeem, Saeed Anwar, Muhammad Hamza Asad, Abdul Bais|<http://arxiv.org/pdf/2506.13925v2>|提出了一种利用视觉语言模型文本嵌入的半监督语义分割方法，通过文本查询和视觉特征对齐显著提升了少量标注...|
|🆕 发布|Leveraging Failed Samples: A Few-Shot and Training-Free Framework for Generalized Deepfake Detection|利用失败样本：一种无需训练的少样本泛化深度伪造检测框架|Shibo Yao, Renshuai Tao, Xiaolong Zheng, Chao Liang, Chunjie Zhang|<http://arxiv.org/pdf/2508.09475v1>|提出了一种无需大规模训练数据、仅利用少量样本进行深度伪造检测的新框架FTNet，实现了性能显著提升。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Toward Human-Robot Teaming: Learning Handover Behaviors from 3D Scenes|面向人机协作：从三维场景中学习交接行为|Yuekun Wu, Yik Lung Pang, Andrea Cavallaro, Changjae Oh|<http://arxiv.org/pdf/2508.09855v1>|提出了一种不依赖真实机器人训练数据，仅通过RGB图像学习人机交接行为的方法，实现了更流畅和稳健的人机...|
|📝 更新|MoSE: Skill-by-Skill Mixture-of-Experts Learning for Embodied Autonomous Machines|MoSE：基于技能的混合专家学习，用于Embodied Autonomous Machines（具身自主机器）|Lu Xu, Jiaqian Yu, Xiongfeng Peng, Yiwei Chen, Weiming Li, Jaewook Yoo, Sunghyun Chunag, Dongwook Lee .etc.|<http://arxiv.org/pdf/2507.07818v2>|提出了一种分技能学习的混合专家模型MoSE，通过模仿人类学习过程，提高了自主机器的推理和学习效率。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory|“观察、聆听、记忆与推理：具有长期记忆的多模态智能体”|Lin Long, Yichen He, Wentao Ye, Yiyuan Pan, Yuan Lin, Hang Li, Junbo Zhao, Wei Li|<http://arxiv.org/pdf/2508.09736v2>|[代码](https://github.com/bytedance-seed/m3-agent); 提出M3-Agent框架，融合视觉与听觉输入，构建长期记忆以提升多模态智能体的理解与推理能力。|
|🆕 发布|WeatherPrompt: Multi-modality Representation Learning for All-Weather Drone Visual Geo-Localization|《WeatherPrompt：全天候无人机视觉地理定位的多模态表征学习》|Jiahao Wen, Hang Yu, Zhedong Zheng|<http://arxiv.org/pdf/2508.09560v2>|提出WeatherPrompt方法，通过多模态学习融合图像与文本，实现全天候无人机视觉地理定位。|
|📝 更新|Grounding Emotion Recognition with Visual Prototypes: VEGA -- Revisiting CLIP in MERC|将情感识别与视觉原型进行关联：VEGA -- 重新审视MERC中的CLIP|Guanyu Hu, Dimitrios Kollias, Xinyu Yang|<http://arxiv.org/pdf/2508.06564v2>|[代码](https://github.com/dkollias/VEGA.); 提出VEGA机制，利用视觉原型引导多模态情感识别，提升模型性能。|
|📝 更新|See the Forest and the Trees: A Synergistic Reasoning Framework for Knowledge-Based Visual Question Answering|看到森林与树木：基于知识的视觉问答协同推理框架|Junjie Wang, Yunhan Tang, Yijie Wang, Zhihao Yuan, Huan Wang, Yangfan He, Bin Li|<http://arxiv.org/pdf/2507.17659v3>|提出协同推理框架Synergos-VQA，通过融合全局、结构和因果证据，提升知识驱动视觉问答的推理全...|
|📝 更新|HRSeg: High-Resolution Visual Perception and Enhancement for Reasoning Segmentation|HRSeg：用于推理分割的高分辨率视觉感知与增强|Weihuang Lin, Yiwei Ma, Xiaoshuai Sun, Shuting He, Jiayi Ji, Liujuan Cao, Rongrong Ji|<http://arxiv.org/pdf/2507.12883v2>|HRSeg通过高分辨率视觉感知与增强，有效提升了推理分割的精细度和准确性。|
|🆕 发布|GazeLT: Visual attention-guided long-tailed disease classification in chest radiographs|gazeLT：视觉注意力引导的长尾疾病分类在胸片影像中|Moinak Bhattacharya, Gagandeep Singh, Shubham Jain, Prateek Prasanna|<http://arxiv.org/pdf/2508.09478v1>|[代码](https://github.com/lordmoinak1/gazelt.); 提出了一种融合人类视觉注意力的方法GazeLT，用于提升胸部X射线影像中长尾疾病分类的准确性。|
|📝 更新|Audio-3DVG: Unified Audio -- Point Cloud Fusion for 3D Visual Grounding|音频-3DVG：统一音频与点云融合的三维视觉定位|Duc Cao-Dinh, Khai Le-Duc, Anh Dao, Bach Phan Tat, Chris Ngo, Duy M. H. Nguyen, Nguyen X. Khanh, Thanh Nguyen-Tang|<http://arxiv.org/pdf/2507.00669v2>|提出Audio-3DVG框架，融合音频与空间信息，提升3D视觉定位性能。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Towards flexible perception with visual memory|面向视觉记忆的灵活感知|Robert Geirhos, Priyank Jaini, Austin Stone, Sourabh Medapati, Xi Yi, George Toderici, Abhijit Ogale, Jonathon Shlens|<http://arxiv.org/pdf/2408.08172v3>|提出了一种结合深度神经网络与数据库灵活性的视觉记忆系统，实现了灵活的数据增删和可解释的决策机制。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|WEC-DG: Multi-Exposure Wavelet Correction Method Guided by Degradation Description|基于退化描述的多曝光小波校正方法WEC-DG|Ming Zhao, Pingping Liu, Tongshun Zhang, Zhe Zhang|<http://arxiv.org/pdf/2508.09565v1>|提出了一种基于小波变换和退化描述引导的多曝光校正方法，有效解决了复杂成像条件下曝光异常的问题。|
|📝 更新|Advancing Reliable Test-Time Adaptation of Vision-Language Models under Visual Variations|在视觉变化下推进视觉语言模型测试时的可靠适应|Yiwen Liang, Hui Chen, Yizhe Xiong, Zihan Zhou, Mengyao Lyu, Zijia Lin, Shuaicheng Niu, Sicheng Zhao .etc.|<http://arxiv.org/pdf/2507.09500v2>|[代码](https://github.com/Evelyn1ywliang/ReTA.); 提出了一种 Reliable Test-time Adaptation 方法，通过改进样本选择和决策...|
|🆕 发布|IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding|输入感知的视觉语言模型视觉定位后门攻击方法|Junxian Li, Beining Xu, Di Zhang|<http://arxiv.org/pdf/2508.09456v1>|提出了一种针对视觉语言模型的输入感知后门攻击方法IAG，可操控模型在视觉定位任务中忽略用户查询而固定...|
|📝 更新|On the Reliability of Vision-Language Models Under Adversarial Frequency-Domain Perturbations|《在对抗性频率域扰动下视觉-语言模型的可靠性研究》|Jordan Vice, Naveed Akhtar, Yansong Gao, Richard Hartley, Ajmal Mian|<http://arxiv.org/pdf/2507.22398v3>|揭示了视觉语言模型在对抗性频率域扰动下的脆弱性，并设计了针对性的图像变换方法。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AI-Driven Detection and Analysis of Handwriting on Seized Ivory: A Tool to Uncover Criminal Networks in the Illicit Wildlife Trade|人工智能驱动的查获象牙上手写体检测与分析：揭示非法野生动物贸易犯罪网络的工具|Will Fein, Ryan J. Horwitz, John E. Brown III, Amit Misra, Felipe Oviedo, Kevin White, Juan M. Lavista Ferres, Samuel K. Wasser|<http://arxiv.org/pdf/2508.10219v2>|提出了一种利用AI分析象牙上手写标记的新方法，为打击野生动物犯罪提供了低成本、高效的证据来源。|
|🆕 发布|MedAtlas: Evaluating LLMs for Multi-Round, Multi-Task Medical Reasoning Across Diverse Imaging Modalities and Clinical Text|MedAtlas：评估大型语言模型在多轮、多任务医疗推理中跨多种成像模态和临床文本的应用|Ronghao Xu, Zhen Huang, Yangbo Wei, Xiaoqian Zhou, Zikang Xu, Ting Liu, Zihang Jiang, S. Kevin Zhou|<http://arxiv.org/pdf/2508.10947v1>|提出MedAtlas基准框架，评估大型语言模型在真实医疗推理任务中的多轮对话、多模态交互和多任务处理...|
|📝 更新|MIND: A Noise-Adaptive Denoising Framework for Medical Images Integrating Multi-Scale Transformer|《MIND：一种集成多尺度变换器的医学图像噪声自适应去噪框架》|Tao Tang, Chengxu Yang|<http://arxiv.org/pdf/2508.07817v2>|提出了一种融合多尺度卷积和Transformer架构的医疗图像自适应降噪模型，有效提升了图像质量和诊...|
|🆕 发布|Robustness analysis of Deep Sky Objects detection models on HPC|高性能计算环境下深空目标检测模型的鲁棒性分析|Olivier Parisot, Diogo Ramalho Fernandes|<http://arxiv.org/pdf/2508.09831v1>|分析了不同天体检测模型在智能望远镜图像上的鲁棒性，利用高性能计算加速模型训练与测试。|
|🆕 发布|KonfAI: A Modular and Fully Configurable Framework for Deep Learning in Medical Imaging|KonfAI：用于医学成像中深度学习的模块化和完全可配置框架|Valentin Boussot, Jean-Louis Dillenseger|<http://arxiv.org/pdf/2508.09823v1>|[代码](https://github.com/vboussot/KonfAI); KonfAI提供了一个模块化、可扩展且完全可配置的深度学习框架，通过配置文件简化医疗影像任务的工作流...|
|🆕 发布|Poaching Hotspot Identification Using Satellite Imagery|利用卫星图像进行盗猎热点识别|Aryan Pandhi, Shrey Baid, Sanjali Jha|<http://arxiv.org/pdf/2508.09812v1>|提出了一种利用卫星图像识别非洲盗猎热点的方法，有效监测并预防大象盗猎问题。|
|📝 更新|Calibrated Self-supervised Vision Transformers Improve Intracranial Arterial Calcification Segmentation from Clinical CT Head Scans|校准的自监督视觉变换器提高临床CT头部扫描中颅内动脉钙化分割的性能|Benjamin Jin, Grant Mair, Joanna M. Wardlaw, Maria del C. Valdés Hernández|<http://arxiv.org/pdf/2507.01744v2>|首次将自监督预训练的视觉变换器应用于颅内动脉钙化分割，提升了临床风险分组准确性。|
|📝 更新|Revisiting 3D Medical Scribble Supervision: Benchmarking Beyond Cardiac Segmentation|重新审视三维医学涂鸦监督：超越心脏分割的基准测试|Karol Gotkowski, Klaus H. Maier-Hein, Fabian Isensee|<http://arxiv.org/pdf/2403.12834v2>|提出全面基准ScribbleBench，揭示了3D医疗图像 scribble 监督方法在泛化性上的不...|
|🆕 发布|NEURAL: Attention-Guided Pruning for Unified Multimodal Resource-Constrained Clinical Evaluation|神经网络：基于注意力引导的统一多模态资源受限临床评估的剪枝方法|Devvrat Joshi, Islem Rekik|<http://arxiv.org/pdf/2508.09715v1>|[代码](https://github.com/basiralab/NEURAL.); 提出NEURAL框架，通过语义引导的数据压缩，实现医学影像的高效压缩与诊断性能保持。|
|🆕 发布|Multi-Sequence Parotid Gland Lesion Segmentation via Expert Text-Guided Segment Anything Model|通过专家文本引导的Segment Anything模型进行多序列腮腺病变分割|Zhongyuan Wu, Chuan-Xian Ren, Yu Wang, Xiaohua Ban, Jianning Xiao, Xiaohui Duan|<http://arxiv.org/pdf/2508.09645v1>|提出了一种融合专家诊断文本指导的分割模型PG-SAM，实现了跨序列的腮腺病变精准分割。|
|🆕 发布|MInDI-3D: Iterative Deep Learning in 3D for Sparse-view Cone Beam Computed Tomography|MInDI-3D：用于稀疏视角锥形束计算机断层扫描的三维迭代深度学习|Daniel Barco, Marc Stadelmann, Martin Oswald, Ivo Herzig, Lukas Lichtensteiger, Pascal Paysan, Igor Peterlik, Michal Walczak .etc.|<http://arxiv.org/pdf/2508.09616v1>|首次将3D条件扩散模型应用于CBCT图像去噪，显著降低辐射暴露并提升图像质量。|
|🆕 发布|Topological Invariant-Based Iris Identification via Digital Homology and Machine Learning|基于数字同伦与机器学习的拓扑不变量虹膜识别|Ahmet Öztel, İsmet Karaca|<http://arxiv.org/pdf/2508.09555v1>|利用数字同调拓扑不变量进行虹膜识别，提高了准确性和可解释性。|
|🆕 发布|Exploring the Equivalence of Closed-Set Generative and Real Data Augmentation in Image Classification|探讨闭集生成数据与真实数据增强在图像分类中的等效性|Haowen Wang, Guowei Zhang, Xiang Zhang, Zeyuan Chen, Haiyang Xu, Dou Hoon Kwark, Zhuowen Tu|<http://arxiv.org/pdf/2508.09550v1>|探讨了闭合集生成数据增强与真实数据增强在图像分类中的等效性，并提出了量化合成数据增强规模的方法。|
|📝 更新|Ear-Keeper: A Cross-Platform AI System for Rapid and Accurate Ear Disease Diagnosis|耳守者：一种跨平台的快速准确耳病诊断人工智能系统|Feiyan Lu, Yubiao Yue, Zhenzhang Li, Meiping Zhang, Wen Luo, Fan Zhang, Tong Liu, Jingyong Shi .etc.|<http://arxiv.org/pdf/2308.10610v5>|提出了一种跨平台AI系统Ear-Keeper，通过大规模数据集和高效模型实现了耳病快速准确诊断。|
|📝 更新|From Few to More: Scribble-based Medical Image Segmentation via Masked Context Modeling and Continuous Pseudo Labels|从少到多：基于scribble的医学图像分割通过掩码上下文建模和连续伪标签|Zhisong Wang, Yiwen Ye, Ziyang Chen, Minglei Shu, Yanning Zhang, Yong Xia|<http://arxiv.org/pdf/2408.12814v2>|提出MaCo模型，通过Masked Context Modeling和Continuous Pseu...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SWA-SOP: Spatially-aware Window Attention for Semantic Occupancy Prediction in Autonomous Driving|空间感知窗口注意力用于自动驾驶中的语义占用预测：SWA-SOP|Helin Cao, Rafael Materla, Sven Behnke|<http://arxiv.org/pdf/2506.18785v2>|提出SWA-SOP方法，通过引入空间感知窗口注意力，提高了自动驾驶中语义占用预测的准确性和鲁棒性。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting|CAPTURe：通过遮挡物体计数评估视觉语言模型中的空间推理能力|Atin Pothiraj, Elias Stengel-Eskin, Jaemin Cho, Mohit Bansal|<http://arxiv.org/pdf/2504.15485v2>|[代码](https://github.com/atinpothiraj/CAPTURe); 提出CAPTURe任务，评估视觉语言模型对遮挡物体的空间推理能力。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Invisible Watermarks, Visible Gains: Steering Machine Unlearning with Bi-Level Watermarking Design|隐形水印，可见增益：基于双层水印设计的机器遗忘引导|Yuhao Sun, Yihua Zhang, Gaowen Liu, Hongtao Xie, Sijia Liu|<http://arxiv.org/pdf/2508.10065v1>|提出利用数字水印技术优化机器遗忘过程，通过双层优化框架有效提升敏感数据移除的精度和模型效用。|
|🆕 发布|Autonomous AI Bird Feeder for Backyard Biodiversity Monitoring|backyard backyard autonomous AI bird feeder for biodiversity monitoring   backyard 后院  backyard biodiversity 后院生物多样性  autonomous AI bird feeder 自主式AI鸟类喂食器  monitoring 监测  因此，该论文标题的中文翻译为：  “后院生物多样性监测用自主式AI鸟类喂食器”|El Mustapha Mansouri|<http://arxiv.org/pdf/2508.09398v1>|开发了一种低成本、离线的自动鸟类监测系统，通过检测和分类提高 backyard 生物多样性监测的准确...|
|🆕 发布|Offline Auto Labeling: BAAS|离线自动标注：基于人工智能的服务（BAAS）|Stefan Haag, Bharanidhar Duraisamy, Felix Govaers, Wolfgang Koch, Martin Fritzsche, Juergen Dickmann|<http://arxiv.org/pdf/2508.09585v1>|提出了一种基于贝叶斯追踪和融合技术的自动标注框架，用于提高自动驾驶中雷达检测的标注精度和追踪性能。|
|🆕 发布|Waymo-3DSkelMo: A Multi-Agent 3D Skeletal Motion Dataset for Pedestrian Interaction Modeling in Autonomous Driving|Waymo-3DSkelMo：面向自动驾驶中行人交互建模的多智能体三维骨骼运动数据集|Guangxun Zhu, Shiyu Fan, Hang Dai, Edmond S. L. Ho|<http://arxiv.org/pdf/2508.09404v1>|[代码](https://github.com/GuangxunZhu/Waymo-3DSkelMo); 介绍了Waymo-3DSkelMo数据集，通过3D人体形状和运动先验提升自动驾驶中行人交互理解的准确...|
|📝 更新|DualMap: Online Open-Vocabulary Semantic Mapping for Natural Language Navigation in Dynamic Changing Scenes|双映射：动态变化场景中自然语言导航的在线开放词汇语义映射|Jiajun Jiang, Yiming Zhu, Zirui Wu, Jie Song|<http://arxiv.org/pdf/2506.01950v3>|[代码](https://eku127.github.io/DualMap); 提出DualMap系统，通过自然语言指令实现动态场景下的在线语义映射，提升机器人导航效率与适应性。|

