## [UPDATED!] **2025-08-13** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LLMC+: Benchmarking Vision-Language Model Compression with a Plug-and-play Toolkit|LLMC+：使用即插即用工具包对视觉语言模型压缩进行基准测试|Chengtao Lv, Bilang Zhang, Yang Yong, Ruihao Gong, Yushi Huang, Shiqiao Gu, Jiajun Wu, Yumeng Shi .etc.|<http://arxiv.org/pdf/2508.09981v1>|[代码](https://github.com/ModelTC/LightCompress.); 提出LLMC+工具包，系统评估视觉语言模型压缩技术，实现高效压缩与性能保持。|
|📝 更新|SpaCE-10: A Comprehensive Benchmark for Multimodal Large Language Models in Compositional Spatial Intelligence|空间智能组合性多模态大型语言模型的全面基准：SpaCE-10|Ziyang Gong, Wenhao Li, Oliver Ma, Songyuan Li, Jiayi Ji, Xue Yang, Gen Luo, Junchi Yan .etc.|<http://arxiv.org/pdf/2506.07966v3>|[代码](https://github.com/Cuzyoung/SpaCE-10.); 提出了SpaCE-10基准，全面评估多模态大语言模型在空间智能方面的原子与组合能力。|
|🆕 发布|VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models|VisCodex：通过融合视觉与编码模型实现统一的多模态代码生成|Lingjie Jiang, Shaohan Huang, Xun Wu, Yixia Li, Dongdong Zhang, Furu Wei|<http://arxiv.org/pdf/2508.09945v1>|VisCodex融合视觉与编码模型，增强多模态代码生成能力，提出新数据集和评估标准。|
|🆕 发布|Physical Autoregressive Model for Robotic Manipulation without Action Pretraining|物理自回归模型：无需动作预训练的机器人操作|Zijian Song, Sihan Qin, Tianshui Chen, Liang Lin, Guangrun Wang|<http://arxiv.org/pdf/2508.09822v1>|提出物理自回归模型，无需动作预训练即可理解物理动态，实现精确视频预测和一致动作轨迹。|
|🆕 发布|Describe What You See with Multimodal Large Language Models to Enhance Video Recommendations|使用多模态大型语言模型描述您所看到的以增强视频推荐|Marco De Nadai, Andreas Damianou, Mounia Lalmas|<http://arxiv.org/pdf/2508.09789v1>|通过使用大型多模态语言模型生成视频描述，提高了视频推荐系统的语义理解能力。|
|📝 更新|SpectralEarth: Training Hyperspectral Foundation Models at Scale|《大规模训练高光谱基础模型的SpectralEarth》|Nassim Ait Ali Braham, Conrad M Albrecht, Julien Mairal, Jocelyn Chanussot, Yi Wang, Xiao Xiang Zhu|<http://arxiv.org/pdf/2408.08447v2>|构建了大规模的SpectralEarth数据集，并利用自监督学习预训练了适用于高光谱图像的基础模型，...|
|📝 更新|CoherenDream: Boosting Holistic Text Coherence in 3D Generation via Multimodal Large Language Models Feedback|通过多模态大型语言模型反馈增强3D生成中的整体文本连贯性：CoherenDream|Chenhan Jiang, Yihan Zeng, Dit-Yan Yeung|<http://arxiv.org/pdf/2504.19860v3>|提出了一种融合大型多模态语言模型反馈的优化策略，有效提升了文本与3D生成内容的整体一致性。|
|📝 更新|Can Large Multimodal Models Understand Agricultural Scenes? Benchmarking with AgroMind|大型多模态模型能理解农业场景吗？基于AgroMind的基准测试|Qingmei Li, Yang Zhang, Zurong Mai, Yuhang Chen, Shuohong Lou, Henglian Huang, Jiarui Zhang, Zhiwei Zhang .etc.|<http://arxiv.org/pdf/2505.12207v3>|[代码](https://rssysu.github.io/AgroMind); 提出AgroMind基准，评估大型多模态模型在农业遥感任务上的表现，揭示了其在领域知识和细粒度识别上...|
|🆕 发布|CitySeg: A 3D Open Vocabulary Semantic Segmentation Foundation Model in City-scale Scenarios|城市级场景中的CitySeg：一种三维开放词汇语义分割基础模型|Jialei Xu, Zizhuang Wei, Weikang You, Linyun Li, Weijian Sun|<http://arxiv.org/pdf/2508.09470v1>|提出CitySeg模型，利用文本模态实现城市规模点云的开放词汇语义分割和零样本推理。|
|🆕 发布|Distilling LLM Prior to Flow Model for Generalizable Agent's Imagination in Object Goal Navigation|将大型语言模型先验知识蒸馏到流模型中以实现物体目标导航中代理的泛化想象力|Badi Li, Ren-jie Lu, Yu Zhou, Jingke Meng, Wei-shi Zheng|<http://arxiv.org/pdf/2508.09423v1>|[代码](https://github.com/Badi-Li/GOAL.); 提出GOAL框架，通过融合大语言模型的空间先验知识，提高物体导航任务中场景想象的泛化能力。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|January Food Benchmark (JFB): A Public Benchmark Dataset and Evaluation Suite for Multimodal Food Analysis|《一月食品基准（JFB）：用于多模态食品分析的开源基准数据集与评估套件》|Amir Hosseinian, Ashkan Dehghani Zahedani, Umer Mansoor, Noosheen Hashemi, Mark Woodward|<http://arxiv.org/pdf/2508.09966v1>|提出 January Food Benchmark 数据集和评估框架，提升自动化营养分析模型的性能评...|
|📝 更新|GLM-4.1V-Thinking and GLM-4.5V: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning|GLM-4.1V-Thinking与GLM-4.5V：迈向可扩展强化学习支持的通用多模态推理|GLM-V Team, :, Wenyi Hong, Wenmeng Yu, Xiaotao Gu, Guo Wang, Guobing Gan, Haomiao Tang .etc.|<http://arxiv.org/pdf/2507.01006v3>|[代码](https://github.com/zai-org/GLM-V.); 提出GLM-4系列模型，通过大规模预训练和强化学习提升多模态理解和推理能力。|
|📝 更新|Analyzing Finetuning Representation Shift for Multimodal LLMs Steering|分析多模态大规模语言模型微调表示偏移的引导|Pegah Khayatan, Mustafa Shukor, Jayneel Parekh, Arnaud Dapogny, Matthieu Cord|<http://arxiv.org/pdf/2501.03012v2>|提出了一种映射隐藏状态到可解释视觉和文本概念的框架，有效揭示了多模态LLM微调过程中的概念变化和潜在...|
|📝 更新|Pediatric brain tumor classification using digital histopathology and deep learning: evaluation of SOTA methods on a multi-center Swedish cohort|使用数字病理学及深度学习进行儿童脑肿瘤分类：基于瑞典多中心队列对SOTA方法的评估|Iulian Emil Tampu, Per Nyman, Christoforos Spyretos, Ida Blystad, Alia Shamikh, Gabriela Prochazka, Teresita Díaz de Ståhl, Johanna Sandgren .etc.|<http://arxiv.org/pdf/2409.01330v2>|利用深度学习对瑞典多中心儿童脑肿瘤数字病理图像进行分类，提升了诊断准确性和模型泛化能力。|
|🆕 发布|Multimodal Sheaf-based Network for Glioblastoma Molecular Subtype Prediction|多模态束状网络用于胶质oblastoma分子亚型预测|Shekhnaz Idrissova, Islem Rekik|<http://arxiv.org/pdf/2508.09717v1>|[代码](https://github.com/basiralab/MMSN); 提出了一种基于束状结构的新型框架，实现了MRI与组织病理学数据的结构感知和一致性融合，提高了脑胶质瘤...|
|📝 更新|ViCToR: Improving Visual Comprehension via Token Reconstruction for Pretraining LMMs|ViCToR：通过标记重建提升预训练语言模型的视觉理解能力|Yin Xie, Kaicheng Yang, Peirou Liang, Xiang An, Yongle Zhao, Yumeng Wang, Ziyong Feng, Roy Miles .etc.|<http://arxiv.org/pdf/2410.14332v4>|[代码](https://github.com/deepglint/Victor.); 提出ViCToR框架，通过视觉token池和匹配算法提升大型多模态模型对视觉信息的理解。|
|📝 更新|Emotion-Qwen: A Unified Framework for Emotion and Vision Understanding|情感-视觉问答统一框架：Emotion-Qwen|Dawei Huang, Qing Li, Chuan Yan, Zebang Cheng, Zihao Han, Yurong Huang, Xiang Li, Bin Li .etc.|<http://arxiv.org/pdf/2505.06685v3>|提出了一种统一的多模态框架Emotion-Qwen，通过混合专家架构和三阶段预训练，有效平衡情感理解...|
|📝 更新|Improving Multimodal Large Language Models Using Continual Learning|使用持续学习改进多模态大型语言模型|Shikhar Srivastava, Md Yousuf Harun, Robik Shrestha, Christopher Kanan|<http://arxiv.org/pdf/2410.19925v2>|[代码](https://shikhar-srivastava.github.io/cl-for-improving-mllms); 提出了一种针对多模态大语言模型的持续学习方法，有效减少语言性能损失同时增强视觉理解能力。|
|📝 更新|Simulating the Real World: A Unified Survey of Multimodal Generative Models|模拟现实世界：多模态生成模型的统一综述|Yuqi Hu, Longguang Wang, Xian Liu, Ling-Hao Chen, Yuwei Guo, Yukai Shi, Ce Liu, Anyi Rao .etc.|<http://arxiv.org/pdf/2503.04641v2>|系统整合了2D至4D多模态生成模型的研究，为真实世界仿真提供了统一框架。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Perceptual Reality Transformer: Neural Architectures for Simulating Neurological Perception Conditions|感知现实转换器：模拟神经感知条件的神经网络架构|Baihan Lin|<http://arxiv.org/pdf/2508.09852v1>|提出Perceptual Reality Transformer框架，通过模拟神经感知条件，帮助人们...|
|🆕 发布|Do Vision Transformers See Like Humans? Evaluating their Perceptual Alignment|《视觉变压器是否像人类一样观察？评估其感知对齐》|Pablo Hernández-Cámara, Jose Manuel Jaén-Lorites, Jorge Vila-Tomás, Valero Laparra, Jesus Malo|<http://arxiv.org/pdf/2508.09850v1>|系统分析了ViT模型与人类视觉感知的契合度，揭示了模型大小、数据多样性和训练策略对契合度的影响。|
|🆕 发布|Speed Always Wins: A Survey on Efficient Architectures for Large Language Models|速度总是制胜：大规模语言模型高效架构综述|Weigao Sun, Jiaxi Hu, Yucheng Zhou, Jusen Du, Disen Lan, Kexin Wang, Tong Zhu, Xiaoye Qu .etc.|<http://arxiv.org/pdf/2508.09834v1>|系统考察了提升大型语言模型效率的创新架构，旨在克服传统变压器模型的计算障碍。|
|📝 更新|LM-MCVT: A Lightweight Multi-modal Multi-view Convolutional-Vision Transformer Approach for 3D Object Recognition|LM-MCVT：一种用于三维物体识别的轻量级多模态多视角卷积-视觉变换器方法|Songsong Xiong, Hamidreza Kasaei|<http://arxiv.org/pdf/2504.19256v3>|提出了一种轻量级多模态多视角卷积视觉变换器网络，有效提升了机器人环境中的3D物体识别准确率。|
|📝 更新|Joint multi-dimensional dynamic attention and transformer for general image restoration|联合多维动态注意力与变换器用于通用图像恢复|Huan Zhang, Xu Zhang, Nian Cai, Jianglei Di, Yun Zhang|<http://arxiv.org/pdf/2411.07893v2>|[代码](https://github.com/House-yuyu/MDDA-former.); 提出了一种结合多维动态注意力和自注意力机制的图像复原架构，有效平衡了性能与计算复杂度。|
|🆕 发布|MoIIE: Mixture of Intra- and Inter-Modality Experts for Large Vision Language Models|《MoIIE：面向大型视觉语言模型的模态内与模态间专家混合》|Dianyi Wang, Siyuan Wang, Zejun Li, Yikun Wang, Yitong Li, Duyu Tang, Xiaoyu Shen, Xuanjing Huang .etc.|<http://arxiv.org/pdf/2508.09779v1>|[代码](https://github.com/AlenjandroWang/MoIIE.); 提出了一种混合内外模态专家的模型MoIIE，有效提升大规模视觉语言模型的效率和泛化能力。|
|🆕 发布|Learning Spatial Decay for Vision Transformers|学习视觉变换器中的空间衰减|Yuxin Mao, Zhen Qin, Jinxing Zhou, Bin Fan, Jing Zhang, Yiran Zhong, Yuchao Dai|<http://arxiv.org/pdf/2508.09525v1>|引入了基于内容感知的空间衰减机制，提升了视觉变压器在空间结构任务上的性能。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MOC: Meta-Optimized Classifier for Few-Shot Whole Slide Image Classification|MOC：少量样本全切片图像分类的元优化分类器|Tianqi Xiang, Yi Li, Qixiang Zhang, Xiaomeng Li|<http://arxiv.org/pdf/2508.09967v1>|[代码](https://github.com/xmed-lab/MOC.); 提出了一种元优化分类器MOC，通过自动优化候选分类器配置，显著提升了少量样本下的全切片图像分类性能。|
|🆕 发布|Multi-Contrast Fusion Module: An attention mechanism integrating multi-contrast features for fetal torso plane classification|多对比融合模块：一种集成多对比特征的关注机制，用于胎儿躯干平面分类|Shengjun Zhu, Siyu Liu, Runqing Xiong, Liping Zheng, Duo Ma, Rongshang Chen, Jiaxin Cai|<http://arxiv.org/pdf/2508.09644v1>|[代码](https://github.com/sysll/MCFM.); 提出了一种多对比度融合模块，通过增强特征表示显著提高了胎儿躯干平面识别的准确性和临床可靠性。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RoHOI: Robustness Benchmark for Human-Object Interaction Detection|RoHOI：用于人类-物体交互检测的鲁棒性基准|Di Wen, Kunyu Peng, Kailun Yang, Yufan Chen, Ruiping Liu, Junwei Zheng, Alina Roitberg, Danda Pani Paudel .etc.|<http://arxiv.org/pdf/2507.09111v2>|[代码](https://github.com/Kratos-Wen/RoHOI.); 提出首个针对人-物交互检测的鲁棒性基准RoHOI，并引入基于语义感知的掩码渐进学习策略提升模型鲁棒性...|
|📝 更新|MGDFIS: Multi-scale Global-detail Feature Integration Strategy for Small Object Detection|多尺度全局-细节特征融合策略用于小目标检测（MGDFIS）|Yuxiang Wang, Xuecheng Bai, Boyu Hu, Chuanzhi Xu, Haodong Chen, Vera Chung, Tingxue Li, Xiaoming Chen|<http://arxiv.org/pdf/2506.12697v2>|提出了一种多尺度全局细节特征融合策略，有效提升了无人机影像中微小目标检测的准确性和效率。|
|📝 更新|OC-SOP: Enhancing Vision-Based 3D Semantic Occupancy Prediction by Object-Centric Awareness|OC-SOP：通过物体中心感知增强基于视觉的3D语义占据预测|Helin Cao, Sven Behnke|<http://arxiv.org/pdf/2506.18798v2>|提出OC-SOP框架，通过融合物体中心的高层次线索，提高了动态前景物体的预测准确性。|
|📝 更新|A Simple yet Powerful Instance-Aware Prompting Framework for Training-free Camouflaged Object Segmentation|一种简单而强大的实例感知提示框架，用于无需训练的迷彩目标分割|Chao Yin, Jide Li, Xiaoqiang Li|<http://arxiv.org/pdf/2508.06904v2>|提出了一种无需训练的实例感知提示框架，实现了对伪装物体的精细分割。|
|🆕 发布|COXNet: Cross-Layer Fusion with Adaptive Alignment and Scale Integration for RGBT Tiny Object Detection|COXNet：基于自适应对齐与尺度集成的跨层融合用于RGBT微小目标检测|Peiran Peng, Tingfa Xu, Liqiang Song, Mengqi Zhu, Yuqiang Fang, Jianan Li|<http://arxiv.org/pdf/2508.09533v1>|提出COXNet框架，通过跨层融合与自适应对齐提升RGBT微小目标检测准确性和鲁棒性。|
|📝 更新|Scaling Vision Mamba Across Resolutions via Fractal Traversal|通过分形遍历在多种分辨率下扩展视觉Mamba模型|Bo Li, Haoke Xiao, Lv Tang|<http://arxiv.org/pdf/2505.14062v2>|提出FractalMamba++，通过 Hilbert 曲线保持空间局部性并实现跨分辨率适应性，增强...|
|📝 更新|PAD-F: Prior-Aware Debiasing Framework for Long-Tailed X-ray Prohibited Item Detection|PAD-F：先验感知去偏框架用于长尾X射线禁运物品检测|Haoyu Wang, Renshuai Tao, Wei Wang, Yunchao Wei|<http://arxiv.org/pdf/2411.18078v4>|提出了一种针对X射线安检图像长尾分布问题的Prior-Aware Debiasing Framewo...|
|🆕 发布|Skyshield: Event-Driven Submillimetre Thin Obstacle Detection for Drone Flight Safety|天盾：面向无人机飞行安全的基于事件驱动的亚毫米级薄障碍物检测|Zhengli Zhang, Xinyu Luo, Yuchen Sun, Wenhua Ding, Dongyu Huang, Xinlei Chen|<http://arxiv.org/pdf/2508.09397v1>|提出了一种基于事件驱动的框架SkyShield，有效检测无人机面临的亚毫米级细小障碍物。|
|🆕 发布|RampNet: A Two-Stage Pipeline for Bootstrapping Curb Ramp Detection in Streetscape Images from Open Government Metadata|RampNet：一种基于开放政府元数据的街景图像引导式路缘坡检测的两阶段管道|John S. O'Meara, Jared Hwang, Zeyu Wang, Michael Saugstad, Jon E. Froehlich|<http://arxiv.org/pdf/2508.09415v1>|提出两阶段RampNet方案，利用政府数据生成大规模高质量数据集，实现路缘坡道检测性能突破。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ProbRadarM3F: mmWave Radar based Human Skeletal Pose Estimation with Probability Map Guided Multi-Format Feature Fusion|基于概率图引导的多格式特征融合的毫米波雷达人体骨骼姿态估计：ProbRadarM3F|Bing Zhu, Zixin He, Weiyi Xiong, Guanhua Ding, Tao Huang, Wei Xiang|<http://arxiv.org/pdf/2405.05164v5>|提出概率图引导的多格式特征融合模型ProbRadarM3F，利用雷达信号中的位置信息，提高了人体骨骼...|
|🆕 发布|ARI3D: A Software for Interactive Quantification of Regions in X-Ray CT 3D Images|ARI3D：一种用于X射线CT三维图像区域交互式定量的软件|Jan Phillipp Albrecht, Jose R. A. Godinho, Christina Hübers, Deborah Schmidt|<http://arxiv.org/pdf/2508.09849v1>|提出ARI3D软件，交互式辅助用户在X射线CT三维图像中分类和量化微结构，提升识别准确性和分析效率。|
|🆕 发布|Predictive Uncertainty for Runtime Assurance of a Real-Time Computer Vision-Based Landing System|实时计算机视觉着陆系统的预测不确定性与运行时保障|Romeo Valentin, Sydney M. Katz, Artur B. Carneiro, Don Walker, Mykel J. Kochenderfer|<http://arxiv.org/pdf/2508.09732v1>|提出了一种实时飞机姿态估计系统，通过概率关键点回归和残差监测确保了视觉导航系统的安全性和鲁棒性。|
|📝 更新|MultiFormer: A Multi-Person Pose Estimation System Based on CSI and Attention Mechanism|基于CSI和注意力机制的多人姿态估计系统：MultiFormer|Yanyi Qu, Haoyang Ma, Wenhui Xiong|<http://arxiv.org/pdf/2505.22555v2>|提出了一种基于CSI和时间频率双token的Transformer模型MultiFormer，实现了...|
|📝 更新|GraspClutter6D: A Large-scale Real-world Dataset for Robust Perception and Grasping in Cluttered Scenes|抓取杂乱6D：一个用于在杂乱场景中进行鲁棒感知和抓取的大规模真实世界数据集|Seunghyeok Back, Joosoon Lee, Kangmin Kim, Heeseon Rho, Geonhyup Lee, Raeyoung Kang, Sangbeom Lee, Sangjun Noh .etc.|<http://arxiv.org/pdf/2504.06866v2>|提出了GraspClutter6D大规模真实世界抓取数据集，助力提升复杂环境下机器人抓取性能。|
|🆕 发布|CLIP-Flow: A Universal Discriminator for AI-Generated Images Inspired by Anomaly Detection|CLIP-Flow：受异常检测启发的一种通用AI生成图像判别器|Zhipeng Yuan, Kai Wang, Weize Quan, Dong-Ming Yan, Tieru Wu|<http://arxiv.org/pdf/2508.09477v1>|提出了一种基于异常检测的通用AI生成图像检测器，无需访问AI生成图像，通过预训练的CLIP编码器和规...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SLTNet: Efficient Event-based Semantic Segmentation with Spike-driven Lightweight Transformer-based Networks|SLTNet：基于脉冲驱动的轻量级Transformer网络的效率事件语义分割|Xianlei Long, Xiaxin Zhu, Fangming Guo, Wanyi Zhang, Qingyi Gu, Chao Chen, Fuqiang Gu|<http://arxiv.org/pdf/2412.12843v3>|[代码](https://github.com/longxianlei/SLTNet-v1.0.); 提出SLTNet，一种高效的基于事件相机和轻量级变换网络的语义分割方法，大幅降低能耗并提升处理速度。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Survey on 3D Gaussian Splatting Applications: Segmentation, Editing, and Generation|三维高斯散点应用综述：分割、编辑与生成|Shuting He, Peilin Ji, Yitong Yang, Changshuo Wang, Jiayi Ji, Yinglin Wang, Henghui Ding|<http://arxiv.org/pdf/2508.09977v1>|[代码](https://github.com/heshuting555/Awesome-3DGS-Applications.); 概述了3D Gaussian Splatting在场景表示中的应用，实现实时高质量渲染并拓展至多种任...|
|📝 更新|LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer|层追踪器：通过扩散变换实现与认知对齐的分层SVG合成|Yiren Song, Danze Chen, Mike Zheng Shou|<http://arxiv.org/pdf/2502.01105v3>|提出LayerTracer框架，通过模拟设计师创作过程生成高质量、易编辑的分层SVG图像。|
|📝 更新|ViewDelta: Scaling Scene Change Detection through Text-Conditioning|视图差分：通过文本条件化扩展场景变化检测|Subin Varghese, Joshua Gao, Vedhus Hoskere|<http://arxiv.org/pdf/2412.07612v3>|[代码](https://joshuakgao.github.io/viewdelta); 提出了一种基于文本条件的场景变化检测框架ViewDelta，解决了不同领域中“相关”与“干扰”变化的...|
|🆕 发布|Quo Vadis Handwritten Text Generation for Handwritten Text Recognition?|“手写文本识别中的手写文本生成之路在何方？”|Vittorio Pippi, Konstantina Nikolaidou, Silvia Cascianelli, George Retsinas, Giorgos Sfikas, Rita Cucchiara, Marcus Liwicki|<http://arxiv.org/pdf/2508.09936v1>|系统评估了三种先进手写文本生成模型对提升低资源手写文本识别性能的影响。|
|📝 更新|Yan: Foundational Interactive Video Generation|《基础交互式视频生成》|Deheng Ye, Fangyun Zhou, Jiacheng Lv, Jianqi Ma, Jun Zhang, Junyan Lv, Junyou Li, Minwen Deng .etc.|<http://arxiv.org/pdf/2508.08601v2>|[代码](https://greatx3.github.io/Yan); 提出了Yan框架，实现了实时交互式视频生成，支持从模拟到编辑的全流程，并具备跨领域风格和机制灵活融合...|
|📝 更新|Pretrained Reversible Generation as Unsupervised Visual Representation Learning|预训练可逆生成作为无监督视觉表征学习|Rongkun Xue, Jinouwen Zhang, Yazhe Niu, Dazhong Shen, Bingqi Ma, Yu Liu, Jing Yang|<http://arxiv.org/pdf/2412.01787v6>|[代码](https://github.com/opendilab/PRG.); 提出了一种利用预训练生成模型逆向过程提取无监督视觉表征的方法，实现了生成模型在判别任务中的高性能表现...|
|📝 更新|RAGAR: Retrieval Augmented Personalized Image Generation Guided by Recommendation|基于推荐引导的检索增强个性化图像生成：RAGAR|Run Ling, Wenji Wang, Yuting Liu, Guibing Guo, Haowei Liu, Jian Lu, Quanwei Zhang, Yexing Xu .etc.|<http://arxiv.org/pdf/2505.01657v2>|提出了一种基于检索机制和推荐系统的个性化图像生成方法，有效解决了传统方法在用户偏好提取和个性化优化方...|
|🆕 发布|Enhancing Diffusion Face Generation with Contrastive Embeddings and SegFormer Guidance|增强对比嵌入和SegFormer引导的扩散人脸生成|Dhruvraj Singh Rawat, Enggen Sherpa, Rishikesan Kirupanantha, Tin Hoang|<http://arxiv.org/pdf/2508.09847v1>|引入对比嵌入和SegFormer指导，提升了少量数据下人脸生成的语义对齐和属性控制。|
|🆕 发布|Region-to-Region: Enhancing Generative Image Harmonization with Adaptive Regional Injection|区域到区域：通过自适应区域注入增强生成图像调和|Zhiqiu Zhang, Dongqi Fan, Mingjie Wang, Qiang Tang, Jian Yang, Zili Yi|<http://arxiv.org/pdf/2508.09746v1>|提出Region-to-Region方法，通过自适应区域信息注入增强图像和谐化效果并保留细节。|
|📝 更新|Cyc3D: Fine-grained Controllable 3D Generation via Cycle Consistency Regularization|循环一致性正则化实现的细粒度可控三维生成：Cyc3D|Hongbin Xu, Chaohui Yu, Feng Xiao, Jiazheng Xing, Hai Ci, Weitao Chen, Fan Wang, Ming Li|<http://arxiv.org/pdf/2504.14975v2>|提出了一种通过循环一致性正则化增强可控3D生成的框架，有效保持了生成内容与输入条件的一致性。|
|🆕 发布|NegFaceDiff: The Power of Negative Context in Identity-Conditioned Diffusion for Synthetic Face Generation|NegFaceDiff：负向上下文在身份条件扩散合成人脸中的力量|Eduarda Caldeira, Naser Damer, Fadi Boutros|<http://arxiv.org/pdf/2508.09661v1>|引入NegFaceDiff方法，通过加入负向条件增强身份分离度，提升合成人脸数据在识别任务中的性能。|
|📝 更新|Towards Synthesized and Editable Motion In-Betweening Through Part-Wise Phase Representation|面向基于部分相位表示的合成与可编辑运动插值|Minyue Dai, Ke Fan, Bin Ji, Haoran Xu, Haoyu Zhao, Junting Dong, Jingbo Wang, Bo Dai|<http://arxiv.org/pdf/2503.08180v3>|提出了一种基于身体部位级别的运动风格建模方法，提高了动画中运动插入的多样性和可控性。|
|📝 更新|HERMES: A Unified Self-Driving World Model for Simultaneous 3D Scene Understanding and Generation|赫耳墨斯：一种用于同时实现三维场景理解和生成的统一自动驾驶世界模型|Xin Zhou, Dingkang Liang, Sifan Tu, Xiwu Chen, Yikang Ding, Dingyuan Zhang, Feiyang Tan, Hengshuang Zhao .etc.|<http://arxiv.org/pdf/2501.14729v3>|[代码](https://github.com/LMD0311/HERMES.); HERMES通过统一框架整合3D场景理解和生成，利用鸟瞰图和世界知识查询提升自动驾驶环境感知能力。|
|🆕 发布|SVG-Head: Hybrid Surface-Volumetric Gaussians for High-Fidelity Head Reconstruction and Real-Time Editing|SVG-Head：混合表面-体积高斯分布用于高保真头部重建与实时编辑|Heyi Sun, Cong Wang, Tian-Xing Xu, Jingwei Huang, Di Kang, Chunchao Guo, Song-Hai Zhang|<http://arxiv.org/pdf/2508.09597v1>|提出了一种混合表面-体积高斯模型SVG-Head，实现了高保真头部重建和实时编辑。|
|🆕 发布|Images Speak Louder Than Scores: Failure Mode Escape for Enhancing Generative Quality|图像胜于分数：逃逸失败模式以提高生成质量|Jie Shao, Ke Zhu, Minghao Fu, Guo-hua Wang, Jianxin Wu|<http://arxiv.org/pdf/2508.09598v1>|提出了一种无需训练且推理高效的方法FaME，通过识别和避免低质量图像生成，显著提升生成图像的视觉质量...|
|🆕 发布|Dual Recursive Feedback on Generation and Appearance Latents for Pose-Robust Text-to-Image Diffusion|用于姿态稳健的文本到图像扩散的生成与外观潜在变量的双向递归反馈|Jiwon Kim, Pureum Kim, SeonHwa Kim, Soobin Park, Eunju Cha, Kyong Hwan Jin|<http://arxiv.org/pdf/2508.09575v1>|[代码](https://github.com/jwonkm/DRF.); 提出了一种无需训练的Dual Recursive Feedback系统，通过递归优化中间潜在变量，实...|
|📝 更新|MoCA: Identity-Preserving Text-to-Video Generation via Mixture of Cross Attention|MoCA：通过混合交叉注意力实现身份保持的文本到视频生成|Qi Xie, Yongjia Ma, Donglin Di, Xuehao Gao, Xun Yang|<http://arxiv.org/pdf/2508.03034v2>|提出了一种基于混合交叉注意力的视频生成模型MoCA，有效保持了文本到视频生成中身份的一致性。|
|🆕 发布|A Chain of Diagnosis Framework for Accurate and Explainable Radiology Report Generation|用于精确且可解释的放射学报告生成的诊断框架链条|Haibo Jin, Haoxuan Che, Sunan He, Hao Chen|<http://arxiv.org/pdf/2508.09566v1>|提出了一种链式诊断框架，通过问答对和诊断定位提升放射学报告的准确性和可解释性。|
|🆕 发布|GoViG: Goal-Conditioned Visual Navigation Instruction Generation|目标条件视觉导航指令生成：GoViG|Fengyi Wu, Yifei Dong, Zhi-Qi Cheng, Yilong Dai, Guangyu Chen, Hang Wang, Qi Dai, Alexander G. Hauptmann|<http://arxiv.org/pdf/2508.09547v1>|提出了一种不依赖结构化输入，仅通过第一视角视觉数据生成精确导航指令的新方法，实现了跨领域泛化能力的显...|
|📝 更新|SpargeAttention: Accurate and Training-free Sparse Attention Accelerating Any Model Inference|SpargeAttention：准确且无需训练的稀疏注意力加速任意模型推理|Jintao Zhang, Chendong Xiang, Haofeng Huang, Jia Wei, Haocheng Xi, Jun Zhu, Jianfei Chen|<http://arxiv.org/pdf/2502.18137v6>|[代码](https://github.com/thu-ml/SpargeAttn.); 提出了一种通用的高效稀疏注意力机制，无需训练即可加速各类模型推理，同时保持性能不变。|
|🆕 发布|Generation of Indian Sign Language Letters, Numbers, and Words|印度手语字母、数字和单词的生成|Ajeet Kumar Yadav, Nishant Kumar, Rathna G N|<http://arxiv.org/pdf/2508.09522v1>|提出了一种结合ProGAN和SAGAN的GAN变体，生成高质量的印度手语字母、数字和词汇图像，并发布...|
|🆕 发布|Gen-AFFECT: Generation of Avatar Fine-grained Facial Expressions with Consistent identiTy|《Gen-AFFECT：具有一致性身份的虚拟人精细面部表情生成》|Hao Yu, Rupayan Mallick, Margrit Betke, Sarah Adel Bargal|<http://arxiv.org/pdf/2508.09461v1>|提出了一种生成个性化且表情丰富、身份一致性的2D虚拟形象的新框架。|
|🆕 发布|RASR: Retrieval-Augmented Super Resolution for Practical Reference-based Image Restoration|基于检索增强的超分辨率：面向实用参考图像复原的方法|Jiaqi Yan, Shuning Xu, Xiangyu Chen, Dell Zhang, Jie Tang, Gangshan Wu, Jie Liu|<http://arxiv.org/pdf/2508.09449v1>|提出了一种自动检索参考图像的超级分辨率方法，有效提升了真实场景下的图像恢复质量和实用性。|
|🆕 发布|DAgger Diffusion Navigation: DAgger Boosted Diffusion Policy for Vision-Language Navigation|"DAgger扩散导航：基于DAgger增强的扩散策略在视觉-语言导航中的应用"|Haoxiang Shi, Xiang Deng, Zaijing Li, Gongwei Chen, Yaowei Wang, Liqiang Nie|<http://arxiv.org/pdf/2508.09444v1>|[代码](https://github.com/Tokishx/DifNav.); 提出了一种端到端的导航策略DifNav，通过整合传统两阶段框架，提高了自然语言导航的鲁棒性和性能。|
|📝 更新|3D Gaussian Splatting Driven Multi-View Robust Physical Adversarial Camouflage Generation|三维高斯散点投影驱动的多视角鲁棒物理对抗性迷彩生成|Tianrui Lou, Xiaojun Jia, Siyuan Liang, Jiawei Liang, Ming Zhang, Yanjun Xiao, Xiaochun Cao|<http://arxiv.org/pdf/2507.01367v2>|[代码](https://github.com/TRLou/PGA.); 提出了一种基于3D高斯散点的物理攻击框架，实现了快速精确的重建和跨视角稳健的对抗性伪装生成。|
|📝 更新|Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer|无训练的文本引导颜色编辑：基于多模态扩散变换器|Zixin Yin, Xili Dai, Ling-Hao Chen, Deyu Zhou, Jianan Wang, Duomin Wang, Gang Yu, Lionel M. Ni .etc.|<http://arxiv.org/pdf/2508.09131v2>|提出了一种无需训练的文本引导色彩编辑方法，通过多模态扩散变换器实现了精确且一致的色彩调整。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Story2Board: A Training-Free Approach for Expressive Storyboard Generation|《Story2Board：一种无需训练的表达性故事板生成方法》|David Dinkevich, Matan Levy, Omri Avrahami, Dvir Samuel, Dani Lischinski|<http://arxiv.org/pdf/2508.09983v1>|Story2Board提出了一种无需训练的故事板生成框架，通过保持角色一致性和视觉特征混合，生成动态...|
|🆕 发布|HumanGenesis: Agent-Based Geometric and Generative Modeling for Synthetic Human Dynamics|人类起源：基于代理的几何与生成建模用于合成人类动态模拟|Weiqi Li, Zehao Zhang, Liang Lin, Guangrun Wang|<http://arxiv.org/pdf/2508.09858v1>|HumanGenesis通过结合几何建模与生成模型，有效解决了合成人类动态中的几何不一致性和运动泛化...|
|🆕 发布|RayletDF: Raylet Distance Fields for Generalizable 3D Surface Reconstruction from Point Clouds or Gaussians|射线光斑距离场：用于从点云或高斯分布进行通用三维表面重建的射线光斑距离场|Shenxing Wei, Jinxi Li, Yafei Yang, Siyuan Zhou, Bo Yang|<http://arxiv.org/pdf/2508.09830v1>|提出了一种名为RayletDF的方法，通过预测射线上的表面点，实现了从点云或高斯分布中高效重建3D表...|
|🆕 发布|The Brain Resection Multimodal Image Registration (ReMIND2Reg) 2025 Challenge|脑切除多模态图像配准（ReMIND2Reg）2025挑战赛|Reuben Dorent, Laura Rigolo, Colin P. Galvin, Junyu Chen, Mattias P. Heinrich, Aaron Carass, Olivier Colliot, Demian Wassermann .etc.|<http://arxiv.org/pdf/2508.09649v1>|提出了最大化的脑肿瘤安全切除术中导航准确性的挑战，通过构建首个大规模多模态图像配准基准促进算法发展。|
|📝 更新|HunyuanWorld 1.0: Generating Immersive, Explorable, and Interactive 3D Worlds from Words or Pixels|《HunyuanWorld 1.0：从文字或像素生成沉浸式、可探索和交互式三维世界》|HunyuanWorld Team, Zhenwei Wang, Yuhao Liu, Junta Wu, Zixiao Gu, Haoyuan Wang, Xuhui Zuo, Tianyu Huang .etc.|<http://arxiv.org/pdf/2507.21809v2>|提出了HunyuanWorld 1.0框架，融合视频和3D技术优势，生成沉浸式、可探索、互动性3D世...|
|🆕 发布|Preacher: Paper-to-Video Agentic System|布道者：从论文到视频的代理系统|Jingwei Liu, Ling Yang, Hao Luo, Fan Wang Hongyan Li, Mengdi Wang|<http://arxiv.org/pdf/2508.09632v1>|[代码](https://github.com/GenVerse/Paper2Video); 提出Preacher系统，通过上下结合的方式将研究论文转化为结构化视频摘要，克服了现有模型局限性。|
|🆕 发布|SkySplat: Generalizable 3D Gaussian Splatting from Multi-Temporal Sparse Satellite Images|天空散点：从多时序稀疏卫星图像中生成通用三维高斯散点|Xuejun Huang, Xinyi Liu, Yi Wan, Zhi Zheng, Bin Zhang, Mingtao Xiong, Yingying Pei, Yongjun Zhang|<http://arxiv.org/pdf/2508.09479v1>|提出SkySplat框架，整合RPC模型和自监督学习，提升卫星图像三维重建效率与准确性。|
|🆕 发布|From Large Angles to Consistent Faces: Identity-Preserving Video Generation via Mixture of Facial Experts|从大角度到一致的面孔：通过面部专家混合实现身份保持的视频生成|Yuji Wang, Moran Li, Xiaobin Hu, Ran Yi, Jiangning Zhang, Chengming Xu, Weijian Cao, Yabiao Wang .etc.|<http://arxiv.org/pdf/2508.09476v1>|[代码](https://github.com/rain152/LFA-Video-Generation.); 提出了一种多专家混合模型MoFE，通过专门设计的专家网络和定制数据集，有效解决了视频生成中面部角度变...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models|噪声超网络：在扩散模型中摊销测试时的计算成本|Luca Eyring, Shyamgopal Karthik, Alexey Dosovitskiy, Nataniel Ruiz, Zeynep Akata|<http://arxiv.org/pdf/2508.09968v1>|[代码](https://github.com/ExplainableML/HyperNoise); 提出了一种Noise Hypernetwork方法，通过优化初始输入噪声，以较低计算成本恢复测试时优...|
|🆕 发布|PERSONA: Personalized Whole-Body 3D Avatar with Pose-Driven Deformations from a Single Image|“PERSONA：从单张图像中生成具有姿态驱动变形的个人化全身3D虚拟形象”|Geonhee Sim, Gyeongsik Moon|<http://arxiv.org/pdf/2508.09973v1>|PERSONA通过结合3D建模与扩散方法，从单张图片创建具有姿态驱动的个性化全身3D虚拟形象。|
|📝 更新|GenAI Confessions: Black-box Membership Inference for Generative Image Models|生成式图像模型的黑箱成员推断研究|Matyas Bohacek, Hany Farid|<http://arxiv.org/pdf/2501.06399v2>|提出了一种无需了解模型架构或参数的黑盒成员推断方法，用以检测生成图像模型是否使用了特定图像进行训练。|
|🆕 发布|Stable Diffusion Models are Secretly Good at Visual In-Context Learning|稳定的扩散模型在视觉情境学习中默默表现出色|Trevine Oorloff, Vishwanath Sindagi, Wele Gedara Chaminda Bandara, Ali Shafahi, Amin Ghiasi, Charan Prakash, Reza Ardekani|<http://arxiv.org/pdf/2508.09949v1>|展示了现成的Stable Diffusion模型通过内注意力机制重计算，无需额外训练即可实现视觉任务...|
|🆕 发布|AST-n: A Fast Sampling Approach for Low-Dose CT Reconstruction using Diffusion Models|AST-n：基于扩散模型的低剂量CT重建快速采样方法|Tomás de la Sotta, José M. Saavedra, Héctor Henríquez, Violeta Chang, Aline Xavier|<http://arxiv.org/pdf/2508.09943v1>|提出AST-n方法，利用高阶微分方程求解器加速低剂量CT重建，保持图像质量的同时大幅减少处理时间。|
|📝 更新|CAS-IQA: Teaching Vision-Language Models for Synthetic Angiography Quality Assessment|CAS-IQA：用于合成血管造影质量评估的视觉-语言模型教学|Bo Wang, De-Xing Huang, Xiao-Hu Zhou, Mei-Jiang Gui, Nu-Fang Xiao, Jian-Long Hao, Ming-Yuan Liu, Zeng-Guang Hou|<http://arxiv.org/pdf/2505.17619v2>|提出CAS-IQA框架，利用视觉语言模型和辅助图像信息，显著提升合成血管造影图像质量评估准确性。|
|📝 更新|Cryo-em images are intrinsically low dimensional|冷冻电镜图像本质上是低维的|Luke Evans, Octavian-Vlad Murad, Lars Dingeldein, Pilar Cossio, Roberto Covino, Marina Meila|<http://arxiv.org/pdf/2504.11249v2>|揭示了冷冻电镜数据内在的低维结构，为提高生物分子构象推断提供了新视角。|
|🆕 发布|Hierarchical Graph Attention Network for No-Reference Omnidirectional Image Quality Assessment|层次化图注意力网络用于无需参考的全景图像质量评估|Hao Yang, Xu Zhang, Jiaqi Ma, Linwei Zhu, Yun Zhang, Huan Zhang|<http://arxiv.org/pdf/2508.09843v1>|提出了一种基于图神经网络的OIQA框架，通过建模视口间结构关系增强空间失真非均匀性的感知。|
|📝 更新|PiT: Progressive Diffusion Transformer|渐进式扩散变换器：PiT|Jiafu Wu, Yabiao Wang, Jian Li, Jinlong Peng, Yun Cao, Chengjie Wang, Jiangning Zhang|<http://arxiv.org/pdf/2505.13219v4>|提出PSWA和PCCA策略，通过减少全局计算冗余提升图像生成效率与性能。|
|🆕 发布|Automated Segmentation of Coronal Brain Tissue Slabs for 3D Neuropathology|冠状脑组织切片的自动化分割用于三维神经病理学分析|Jonathan Williams Ramirez, Dina Zemlyanker, Lucas Deden-Binder, Rogeny Herisse, Erendira Garcia Pallares, Karthik Gopinath, Harshvardhan Gazula, Christopher Mount .etc.|<http://arxiv.org/pdf/2508.09805v1>|提出了一种基于U-Net架构的自动脑组织切片分割模型，减少了人工干预需求并提高了分割精度。|
|🆕 发布|MUJICA: Reforming SISR Models for PBR Material Super-Resolution via Cross-Map Attention|MUJICA：通过交叉图注意力改进SISR模型以实现PBR材料超分辨率|Xin Du, Maoyuan Xu, Zhi Ying|<http://arxiv.org/pdf/2508.09802v1>|提出MUJICA方法，通过跨图注意力改进预训练SISR模型，提升PBR材料超分辨率性能。|
|📝 更新|DRWKV: Focusing on Object Edges for Low-Light Image Enhancement|DRWKV：关注物体边缘的低光图像增强|Xuecheng Bai, Yuxiang Wang, Boyu Hu, Qinyuan Jie, Chuanzhi Xu, Hongru Xiao, Kechen Li, Vera Chung|<http://arxiv.org/pdf/2507.18594v2>|提出DRWKV模型，通过分离光照与边缘结构并增强边缘连续性，有效提升低光图像增强质量。|
|📝 更新|CD-TVD: Contrastive Diffusion for 3D Super-Resolution with Scarce High-Resolution Time-Varying Data|CD-TVD：基于稀缺高分辨率时变数据的对比扩散三维超分辨率|Chongke Bi, Xin Gao, Jiangkang Deng, Guan Li, Jun Han|<http://arxiv.org/pdf/2508.08173v2>|[代码](https://github.com/Xin-Gao-private/CD-TVD.); 提出CD-TVD框架，利用对比学习和改进的扩散模型，从少量高分辨率时变数据实现精确的3D超分辨率。|
|📝 更新|Image Intrinsic Scale Assessment: Bridging the Gap Between Quality and Resolution|图像固有尺度评估：桥接质量与分辨率之间的差距|Vlad Hosu, Lorenzo Agnolucci, Daisuke Iso, Dietmar Saupe|<http://arxiv.org/pdf/2502.06476v3>|[代码](https://github.com/SonyResearch/IISA.); 提出图像固有尺度概念及评估任务，通过弱标签策略提升图像质量评估性能。|
|🆕 发布|MangaDiT: Reference-Guided Line Art Colorization with Hierarchical Attention in Diffusion Transformers|《MangaDiT：基于参考引导的层次注意力扩散变换器的线艺术着色》|Qianru Qiu, Jiafeng Mao, Kento Masui, Xueting Wang|<http://arxiv.org/pdf/2508.09709v1>|提出了基于扩散变换器和分层注意力机制的MangaDiT模型，通过内部注意力机制隐式发现语义对应关系，...|
|📝 更新|LUMA: A Benchmark Dataset for Learning from Uncertain and Multimodal Data|LUMA：一个用于从不确定性和多模态数据中学习的基准数据集|Grigor Bezirganyan, Sana Sellami, Laure Berti-Équille, Sébastien Fournier|<http://arxiv.org/pdf/2406.09864v3>|[代码](https://github.com/bezirganyan/LUMA); 提出了LUMA多模态数据集，为研究不确定性对多模态深度学习模型影响提供了可控实验环境。|
|📝 更新|UltraRay: Introducing Full-Path Ray Tracing in Physics-Based Ultrasound Simulation|《UltraRay：在基于物理的超声模拟中引入全路径光线追踪》|Felix Duelmer, Mohammad Farid Azampour, Magdalena Wysocki, Nassir Navab|<http://arxiv.org/pdf/2501.05828v2>|提出了一种全路径光线追踪的超声波仿真方法，提高了图像真实性和减少了人工伪影。|
|📝 更新|Human Motion Capture from Loose and Sparse Inertial Sensors with Garment-aware Diffusion Models|基于宽松稀疏惯性传感器和衣物感知扩散模型的人体运动捕捉|Andela Ilic, Jiaxi Jiang, Paul Streli, Xintong Liu, Christian Holz|<http://arxiv.org/pdf/2506.15290v2>|提出了一种基于扩散模型的方法，能够从松散佩戴的稀疏惯性传感器估计全身姿态。|
|📝 更新|Towards Black-Box Membership Inference Attack for Diffusion Models|面向扩散模型的黑盒成员推断攻击方法研究|Jingwei Li, Jing Dong, Tianxing He, Jingzhao Zhang|<http://arxiv.org/pdf/2405.20771v5>|提出了一种无需访问模型内部结构的黑盒成员推断攻击方法，通过图像变异API准确判断图像是否用于训练扩散...|
|🆕 发布|Episodic Memory Representation for Long-form Video Understanding|长视频理解中的情景记忆表征|Yun Wang, Long Zhang, Jingren Liu, Jiaqi Yan, Zhanjie Zhang, Jiahao Zheng, Xun Yang, Dapeng Wu .etc.|<http://arxiv.org/pdf/2508.09486v1>|提出了一种基于人类情景记忆原理的Video-EM框架，通过高效建模关键帧的时空关系，显著提升了长视频...|
|🆕 发布|Event-driven Robust Fitting on Neuromorphic Hardware|基于类神经形态硬件的事件驱动鲁棒拟合|Tam Ngoc-Bang Nguyen, Anh-Dzung Doan, Zhipeng Cai, Tat-Jun Chin|<http://arxiv.org/pdf/2508.09466v1>|提出了一种基于神经形态硬件的节能稳健拟合方法，大幅降低了能耗。|
|🆕 发布|Animate-X++: Universal Character Image Animation with Dynamic Backgrounds|动态背景下的通用角色图像动画：Animate-X++|Shuai Tan, Biao Gong, Zhuoxin Liu, Yan Wang, Xi Chen, Yifan Feng, Hengshuang Zhao|<http://arxiv.org/pdf/2508.09454v1>|提出了一种通用字符图像动画框架Animate-X++，支持不同类型角色动画及动态背景生成，提高了视频...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation|回声-4o：利用GPT-4o合成图像的力量以提高图像生成质量|Junyan Ye, Dongzhi Jiang, Zihao Wang, Leqi Zhu, Zhenghao Hu, Zilong Huang, Jun He, Zhiyuan Yan .etc.|<http://arxiv.org/pdf/2508.09987v1>|利用GPT-4o生成的合成图像增强开源模型，解决现实数据集覆盖盲区，提升文本到图像对齐精度。|
|🆕 发布|GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors|GS修复器：利用参考引导的视频扩散先验改进三维高斯散点绘制|Xingyilang Yin, Qi Zhang, Jiahao Chang, Ying Feng, Qingnan Fan, Xi Yang, Chi-Man Pun, Huaqi Zhang .etc.|<http://arxiv.org/pdf/2508.09667v1>|[代码](https://github.com/GVCLab/GSFixer.); 提出GSFixer框架，利用参考引导的视频扩散模型修复3D场景重建中的瑕疵，提升重建质量。|
|🆕 发布|SHALE: A Scalable Benchmark for Fine-grained Hallucination Evaluation in LVLMs|SHALE：用于LVLMs中细粒度幻觉评估的可扩展基准|Bei Yan, Zhiyuan Chen, Yuecong Min, Jie Zhang, Jiahao Wang, Xiaozhen Wang, Shiguang Shan|<http://arxiv.org/pdf/2508.09584v1>|提出自动化数据构建流程，构建了SHALE基准，细粒度评估LVLM的忠实性和事实性幻觉问题。|
|🆕 发布|SARE: Semantic-Aware Reconstruction Error for Generalizable Diffusion-Generated Image Detection|语义感知重建误差：用于通用扩散生成图像检测的方法|Ju Yeon Kang, Jaehong Park, Semin Kim, Ji Won Yoon, Nam Soo Kim|<http://arxiv.org/pdf/2508.09487v1>|提出了一种衡量图像与标题指导重建之间语义差异的SARE方法，有效提升了检测未见生成模型生成的假图像的...|
|🆕 发布|RelayFormer: A Unified Local-Global Attention Framework for Scalable Image and Video Manipulation Localization|RelayFormer：一种用于可扩展图像与视频操作定位的统一局部-全局注意力框架|Wen Huang, Jiarui Yang, Tao Dai, Jiawei Li, Shaoxiong Zhan, Bin Wang, Shu-Tao Xia|<http://arxiv.org/pdf/2508.09459v1>|[代码](https://github.com/WenOOI/RelayFormer.); 提出了一种统一局部-全局注意力框架RelayFormer，实现了高效的可扩展图像和视频篡改定位。|
|📝 更新|When Deepfakes Look Real: Detecting AI-Generated Faces with Unlabeled Data due to Annotation Challenges|当深度伪造看起来真实：由于标注挑战，使用无标签数据检测AI生成的面部|Zhiqiang Yang, Renshuai Tao, Xiaolong Zheng, Guodong Yang, Chunjie Zhang|<http://arxiv.org/pdf/2508.09022v2>|提出DPGNet方法，利用无标签数据解决深度伪造人脸检测难题，提升检测准确率。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|T-CACE: A Time-Conditioned Autoregressive Contrast Enhancement Multi-Task Framework for Contrast-Free Liver MRI Synthesis, Segmentation, and Diagnosis|T-CACE:一种基于时间条件的自回归对比增强多任务框架，用于无对比剂肝脏磁共振成像的合成、分割和诊断|Xiaojiao Xiao, Jianfeng Zhao, Qinmin Vivian Hu, Guanghui Wang|<http://arxiv.org/pdf/2508.09919v1>|[代码](https://github.com/xiaojiao929/T-CACE.); 提出T-CACE框架，通过无对比剂MRI直接合成多相位对比增强图像，提升肝脏病变诊断的安全性和效率。|
|🆕 发布|SpeechForensics: Audio-Visual Speech Representation Learning for Face Forgery Detection|语音法医学：基于音频-视觉语音表征学习的面部伪造检测|Yachao Liang, Min Yu, Gang Li, Jianguo Jiang, Boquan Li, Feng Yu, Ning Zhang, Xiang Meng .etc.|<http://arxiv.org/pdf/2508.09913v1>|[代码](https://github.com/Eleven4AI/SpeechForensics.); 提出了一种结合音频与视觉语音元素的学习方法，有效提高了面部伪造视频检测的跨数据集泛化能力和鲁棒性。|
|🆕 发布|Evolution of Low-Level and Texture Human-CLIP Alignment|低层次和纹理人类-CLIP对齐的演变|Pablo Hernández-Cámara, Jose Manuel Jaén-Lorites, Jorge Vila-Tomás, Jesus Malo, Valero Laparra|<http://arxiv.org/pdf/2508.09814v1>|揭示了CLIP模型在训练初期与人类低级视觉感知高度一致的现象，并探讨了其背后的学习机制。|
|📝 更新|FROST-BRDF: A Fast and Robust Optimal Sampling Technique for BRDF Acquisition|FROST-BRDF：一种快速且稳健的BRDF获取最优采样技术|Ehsan Miandji, Tanaboon Tongbuasirilai, Saghi Hajisharif, Behnaz Kavoosighafi, Jonas Unger|<http://arxiv.org/pdf/2401.07283v2>|提出了一种快速稳健的BRDF获取最优采样技术，将BRDF采集问题转化为压缩感知问题，大幅提升了重建质...|
|🆕 发布|Surg-InvNeRF: Invertible NeRF for 3D tracking and reconstruction in surgical vision|手术视觉中的三维跟踪与重建：可逆神经辐射场（Surg-InvNeRF）|Gerardo Loza, Junlei Hu, Dominic Jones, Sharib Ali, Pietro Valdastri|<http://arxiv.org/pdf/2508.09681v1>|提出了一种基于NeRF架构的测试时优化方法，实现了手术场景中的长期3D点跟踪。|
|📝 更新|NeuralGS: Bridging Neural Fields and 3D Gaussian Splatting for Compact 3D Representations|神经场与三维高斯散点绘制结合的紧凑三维表示方法：NeuralGS|Zhenyu Tang, Chaoran Feng, Xinhua Cheng, Wangbo Yu, Junwu Zhang, Yuan Liu, Xiaoxiao Long, Wenping Wang .etc.|<http://arxiv.org/pdf/2503.23162v2>|提出了一种将3D高斯分布与神经网络结合的紧凑3D表示方法NeuralGS，大幅减小模型大小而不损失视...|
|🆕 发布|Physics-guided Deep Unfolding Network for Enhanced Kronecker Compressive sensing|基于物理引导的深度展开网络以增强Kronecker压缩感知|Gang Qu, Ping Wang, Siming Zheng, Xin Yuan|<http://arxiv.org/pdf/2508.09528v1>|提出了一种改进的物理引导的深度展开网络，通过优化测量相干性和学习测量表示，提升了图像压缩感知的性能。|
|🆕 发布|MPT: Motion Prompt Tuning for Micro-Expression Recognition|MPT：微表情识别的运动提示调优|Jiateng Liu, Hengcan Shi, Feng Chen, Zhiwen Shao, Yaonan Wang, Jianfei Cai, Wenming Zheng|<http://arxiv.org/pdf/2508.09446v1>|提出Motion Prompt Tuning方法，通过微动作提示增强大型预训练模型对微表情的识别能力...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|E-4DGS: High-Fidelity Dynamic Reconstruction from the Multi-view Event Cameras|E-4DGS：基于多视角事件相机的高保真动态重建|Chaoran Feng, Zhenyu Tang, Wangbo Yu, Yatian Pang, Yian Zhao, Jianbin Zhao, Li Yuan, Yonghong Tian|<http://arxiv.org/pdf/2508.09912v1>|提出了一种基于事件相机的高保真动态重建方法E-4DGS，解决了高速运动和低光环境下场景重建的挑战。|
|📝 更新|Multi-view Normal and Distance Guidance Gaussian Splatting for Surface Reconstruction|多视角法向量和距离引导的高斯散点绘制法用于表面重建|Bo Jia, Yanan Guo, Ying Chang, Benkui Zhang, Ying Xie, Kangning Du, Lin Cao|<http://arxiv.org/pdf/2508.07701v2>|[代码](https://github.com/Bistu3DV/MND-GS); 引入多视角正常向量和距离引导的约束，提高了3D表面重建的精度和一致性。|
|📝 更新|BridgeDepth: Bridging Monocular and Stereo Reasoning with Latent Alignment|桥接深度：通过潜在对齐融合单目与立体推理|Tongfan Guan, Jiaxin Guo, Chen Wang, Yun-Hui Liu|<http://arxiv.org/pdf/2508.04611v2>|[代码](https://github.com/aeolusguan/BridgeDepth.); 提出了一种统一框架，通过双向对齐显式融合单目和立体深度估计的优势，显著提升了三维感知的鲁棒性。|
|🆕 发布|Enhancing Monocular 3D Hand Reconstruction with Learned Texture Priors|利用学习到的纹理先验增强单目3D手部重建|Giorgos Karvounas, Nikolaos Kyriazis, Iason Oikonomidis, Georgios Pavlakos, Antonis A. Argyros|<http://arxiv.org/pdf/2508.09629v1>|提出利用纹理先验增强单目3D手部重建，通过密集纹理对齐提升姿态与形状估计的准确性和真实性。|
|🆕 发布|CWFBind: Geometry-Awareness for Fast and Accurate Protein-Ligand Docking|CWFBind：面向快速准确蛋白质-配体对接的几何感知|Liyan Jia, Chuan-Xian Ren, Hong Yan|<http://arxiv.org/pdf/2508.09499v1>|引入CWFBind方法，通过融合局部曲率特征和度感知加权机制，提升蛋白质-配体对接的准确性和速度。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|What-Meets-Where: Unified Learning of Action and Contact Localization in a New Dataset|“所见即所得：在一个新数据集中对动作和接触定位的统一学习”|Yuxiao Wang, Yu Lei, Wolin Liang, Weiying Xue, Zhenao Wei, Nan Zhuang, Qi Liu|<http://arxiv.org/pdf/2508.09428v1>|提出了一种统一学习动作和接触定位的新任务和框架PaIR-Net，有效桥接了动作语义与场景空间上下文的...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Video SimpleQA: Towards Factuality Evaluation in Large Video Language Models|视频简单问答：面向大型视频语言模型的事实性评估|Meng Cao, Pengfei Hu, Yingyao Wang, Jihao Gu, Haoran Tang, Haoze Zhao, Chen Wang, Jiahua Dong .etc.|<http://arxiv.org/pdf/2503.18923v2>|提出Video SimpleQA基准，针对视频语言模型的事实性评估，要求多跳事实查找和严格的事实依据...|
|📝 更新|Are you Struggling? Dataset and Baselines for Struggle Determination in Assembly Videos|你在挣扎吗？装配视频中的挣扎判定数据集与基线|Shijia Feng, Michael Wray, Brian Sullivan, Youngkyoon Jang, Casimir Ludwig, Iain Gilchrist, Walterio Mayol-Cuevas|<http://arxiv.org/pdf/2402.11057v5>|提出首个挣扎识别数据集，并对比了多种深度学习模型，为挣扎分类任务建立了基线结果。|
|🆕 发布|OneVAE: Joint Discrete and Continuous Optimization Helps Discrete Video VAE Train Better|《OneVAE：联合离散与连续优化助力离散视频VAE训练更佳》|Yupeng Zhou, Zhen Li, Ziheng Ouyang, Yuming Chen, Ruoyi Du, Daquan Zhou, Bin Fu, Yihao Liu .etc.|<http://arxiv.org/pdf/2508.09857v1>|提出了一种融合连续和离散优化的OneVAE方法，有效解决了视频VAE训练不稳定和重建质量差的问题。|
|🆕 发布|ViMoNet: A Multimodal Vision-Language Framework for Human Behavior Understanding from Motion and Video|ViMoNet：一种基于运动和视频理解人类行为的多模态视觉-语言框架|Rajan Das Gupta, Md Yeasin Rahat, Nafiz Fahad, Abir Ahmed, Liew Tze Hui|<http://arxiv.org/pdf/2508.09818v1>|提出了一种融合动作和视频数据的多模态视觉语言框架ViMoNet，有效提升了人类行为理解能力。|
|🆕 发布|TOTNet: Occlusion-Aware Temporal Tracking for Robust Ball Detection in Sports Videos|TOTNet：面向遮挡感知的体育视频鲁棒球检测的时序跟踪网络|Hao Xu, Arbind Agrahari Baniya, Sam Wells, Mohamed Reda Bouadjenek, Richard Dazely, Sunil Aryal|<http://arxiv.org/pdf/2508.09650v1>|[代码](https://github.com/AugustRushG/TOTNet); 提出TOTNet，通过3D卷积和可见性加权损失增强运动视频中球在遮挡下的追踪鲁棒性。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Follow-Your-Motion: Video Motion Transfer via Efficient Spatial-Temporal Decoupled Finetuning|“跟随你的动作：通过高效时空解耦微调实现视频运动迁移”|Yue Ma, Yulong Liu, Qiyuan Zhu, Ayden Yang, Kunyu Feng, Xinhua Zhang, Zhifeng Li, Sirui Han .etc.|<http://arxiv.org/pdf/2506.05207v2>|提出了一种高效的视频运动转移框架，通过解耦空间和时间处理，提高了运动一致性和微调效率。|
|📝 更新|STAC: Leveraging Spatio-Temporal Data Associations For Efficient Cross-Camera Streaming and Analytics|STAC：利用时空数据关联实现高效跨摄像头流传输与分析|Ragini Gupta, Lingzhi Zhao, Jiaxi Li, Volodymyr Vakhniuk, Claudiu Danilov, Josh Eckhardt, Keyshla Bernard, Klara Nahrstedt|<http://arxiv.org/pdf/2401.15288v2>|提出STAC系统，通过利用时空数据关联实现高效跨摄像头视频流分析和对象跟踪，减少网络负担同时保持模型...|
|🆕 发布|MeMoSORT: Memory-Assisted Filtering and Motion-Adaptive Association Metric for Multi-Person Tracking|MeMoSORT：基于内存辅助过滤和运动自适应关联度量的多人跟踪|Yingjie Wang, Zhixing Wang, Le Zheng, Tianxiao Liu, Roujing Li, Xueyao Hu|<http://arxiv.org/pdf/2508.09796v1>|提出MeMoSORT算法，通过记忆辅助滤波和自适应运动匹配改进多目标跟踪，实现领先性能。|
|📝 更新|PrAViC: Probabilistic Adaptation Framework for Real-Time Video Classification|PrAViC：实时视频分类的概率适应框架|Magdalena Trędowicz, Marcin Mazur, Szymon Janusz, Arkadiusz Lewicki, Jacek Tabor, Łukasz Struski|<http://arxiv.org/pdf/2406.11443v2>|提出了一种实时视频分类的概率适应框架PrAViC，通过早期决策和模型适应，加快了分类速度并保持或提升...|
|🆕 发布|SOI is the Root of All Evil: Quantifying and Breaking Similar Object Interference in Single Object Tracking|“SOI是万恶之源：量化并打破单目标跟踪中的相似物体干扰”|Yipei Wang, Shiyu Hu, Shukun Jia, Panxi Xu, Hongfei Ma, Yiping Ma, Jing Zhang, Xiaobo Lu .etc.|<http://arxiv.org/pdf/2508.09524v1>|揭示了相似物体干扰对单目标跟踪的影响，并提出了利用大规模视觉语言模型进行外部认知引导的新方法。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Learning Adaptive Node Selection with External Attention for Human Interaction Recognition|学习自适应节点选择与外部注意力机制用于人体交互识别|Chen Pang, Xuequan Lu, Qianyu Zhou, Lei Lyu|<http://arxiv.org/pdf/2507.03936v2>|提出了一种动态捕捉人际互动关系的方法ASEA，通过自适应节点选择和外部注意力机制，有效提升人类互动识...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hierarchical Brain Structure Modeling for Predicting Genotype of Glioma|基于层次化大脑结构建模预测胶质瘤基因型|Haotian Tang, Jianwei Chen, Xinrui Tang, Yunjia Wu, Zhengyang Miao, Chao Li|<http://arxiv.org/pdf/2508.09593v1>|提出Hi-SMGNN模型，通过融合脑部结构信息预测胶质瘤基因型，提升预测准确性和鲁棒性。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PaCo-FR: Patch-Pixel Aligned End-to-End Codebook Learning for Facial Representation Pre-training|PaCo-FR：基于贴图-像素对齐的端到端码本学习用于面部表征预训练|Yin Xie, Zhichao Chen, Xiaoze Yu, Yongle Zhao, Xiang An, Kaicheng Yang, Zimin Ran, Jia Guo .etc.|<http://arxiv.org/pdf/2508.09691v1>|提出了一种结合掩码图像建模与 patch-pixel 对齐的无监督面部表征预训练框架 PaCo-FR...|


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BridgeTA: Bridging the Representation Gap in Knowledge Distillation via Teacher Assistant for Bird's Eye View Map Segmentation|BridgeTA：通过教师助手在鸟瞰图分割中缩小知识蒸馏的表征差距|Beomjun Kim, Suhan Woo, Sejong Heo, Euntai Kim|<http://arxiv.org/pdf/2508.09599v1>|提出BridgeTA框架，通过引入教师助手网络在不增加学生模型复杂度的前提下，有效缩小了LiDAR-...|
|🆕 发布|HyperKD: Distilling Cross-Spectral Knowledge in Masked Autoencoders via Inverse Domain Shift with Spatial-Aware Masking and Specialized Loss|《HyperKD：通过空间感知掩码和专用损失在掩码自编码器中通过逆域转换蒸馏跨谱知识》|Abdul Matin, Tanjim Bin Faruk, Shrideep Pallickara, Sangmi Lee Pallickara|<http://arxiv.org/pdf/2508.09453v1>|提出HyperKD框架，通过逆向域转移和特性增强策略，有效提升 hyperspectral 图像的表...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LIA-X: Interpretable Latent Portrait Animator|LIA-X：可解释的潜在肖像动画器|Yaohui Wang, Di Yang, Xinyuan Chen, Francois Bremond, Yu Qiao, Antitza Dantcheva|<http://arxiv.org/pdf/2508.09959v1>|提出LIA-X，通过稀疏运动字典实现面部动态的细粒度可控转移和编辑。|
|🆕 发布|Combinative Matching for Geometric Shape Assembly|组合匹配在几何形状装配中的应用|Nahyuk Lee, Juhong Min, Junhong Lee, Chunghyun Park, Minsu Cho|<http://arxiv.org/pdf/2508.09780v1>|[代码](https://nahyuklee.github.io/cmnet.); 引入组合匹配方法，通过建模互锁形状的独特属性，实现了几何形状组装的精确对应。|
|🆕 发布|Plane Detection and Ranking via Model Information Optimization|通过模型信息优化进行平面检测与排序|Daoxin Zhong, Jun Li, Meng Yee Michael Chuah|<http://arxiv.org/pdf/2508.09625v1>|提出了一种基于模型信息优化的平面检测框架，减少了深度图像平面检测中的误报问题。|
|🆕 发布|Semantic-aware DropSplat: Adaptive Pruning of Redundant Gaussians for 3D Aerial-View Segmentation|语义感知的DropSplat：三维空中视图分割中冗余高斯分布的自适应剪枝|Xu Tang, Junan Jia, Yijing Wang, Jingjing Ma, Xiangrong Zhang|<http://arxiv.org/pdf/2508.09626v1>|提出了一种自适应剪枝冗余高斯点的3D空中场景分割方法，通过语义置信度估计和稀疏性机制提升分割准确性和...|
|📝 更新|GranQ: Granular Zero-Shot Quantization with Channel-Wise Activation Scaling in QAT|粒度零样本量化：在QAT中基于通道激活缩放的粒度量化方法|Inpyo Hong, Youngwan Jo, Hyojeong Lee, Sunghyun Ahn, Kijung Lee, Sanghyun Park|<http://arxiv.org/pdf/2503.18339v5>|[代码](https://github.com/anonymus-orange/GranQ.); 提出了一种高效的预缩放策略GranQ，通过向量化的计算减少量化过程中的计算负担，提升低比特量化下的模...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Explaining Caption-Image Interactions in CLIP Models with Second-Order Attributions|《使用二阶属性解释CLIP模型中的标题-图像交互》|Lucas Möller, Pascal Tilli, Ngoc Thang Vu, Sebastian Padó|<http://arxiv.org/pdf/2408.14153v4>|[代码](https://github.com/lucasmllr/exCLIP); 提出了一种新的二阶归因方法，揭示了CLIP模型如何通过特征间交互比较图像和标题。|
|🆕 发布|Reverse Convolution and Its Applications to Image Restoration|逆向卷积及其在图像复原中的应用|Xuhong Huang, Shiqi Liu, Kai Zhang, Ying Tai, Jian Yang, Hui Zeng, Lei Zhang|<http://arxiv.org/pdf/2508.09824v1>|提出了一种深度反向卷积操作，有效逆转卷积效果并构建了新型网络结构ConverseNet，用于图像复原...|
|🆕 发布|Combating Noisy Labels via Dynamic Connection Masking|通过动态连接掩码对抗噪声标签|Xinlei Zhang, Fan Liu, Chuanyi Zhang, Fan Cheng, Yuhui Zheng|<http://arxiv.org/pdf/2508.09697v1>|提出动态连接掩码机制，增强模型对噪声标签的鲁棒性，优于现有方法。|
|🆕 发布|Noise-adapted Neural Operator for Robust Non-Line-of-Sight Imaging|噪声适应的神经算子用于稳健的非视线成像|Lianfang Wang, Kuilin Qin, Xueying Liu, Huibin Chang, Yong Wang, Yuping Duan|<http://arxiv.org/pdf/2508.09655v1>|提出了一种适应噪声的神经算子框架，用于三维非视距成像的快速准确重建。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Transferable Model-agnostic Vision-Language Model Adaptation for Efficient Weak-to-Strong Generalization|迁移性模型无关的视觉-语言模型适配：用于高效弱到强泛化|Jihwan Park, Taehoon song, Sanghyeok Lee, Miso Choi, Hyunwoo J. Kim|<http://arxiv.org/pdf/2508.08604v2>|提出了一种轻量级适配器TransMiter，无需反向传播即可高效迁移视觉语言模型的适应知识。|
|📝 更新|Integrating Clinical Knowledge Graphs and Gradient-Based Neural Systems for Enhanced Melanoma Diagnosis via the 7-Point Checklist|通过整合临床知识图谱和基于梯度的神经网络，利用7点清单增强黑色素瘤诊断|Yuheng Wang, Tianze Yu, Jiayue Cai, Sunil Kalia, Harvey Lui, Z. Jane Wang, Tim K. Lee|<http://arxiv.org/pdf/2407.16822v2>|整合临床知识图谱与梯度诊断策略，提升黑色素瘤诊断准确性和特征预测能力。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Comprehensive Cellular Characterisation of H&E slides|迈向全面细胞特征描述的H&E切片研究|Benjamin Adjadj, Pierre-Antoine Bannier, Guillaume Horent, Sebastien Mandela, Aurore Lyon, Kathryn Schutte, Ulysse Marteau, Valentin Gaury .etc.|<http://arxiv.org/pdf/2508.09926v1>|[代码](https://github.com/owkin/histoplus); 提出HistoPLUS模型，通过新型泛癌数据集提升了对罕见细胞类型的检测与分类性能。|
|🆕 发布|Iterative Volume Fusion for Asymmetric Stereo Matching|迭代体积融合用于非对称立体匹配|Yuanting Gao, Linghao Shen|<http://arxiv.org/pdf/2508.09543v1>|提出迭代体积融合网络解决非对称立体匹配问题，有效融合两种成本体积信息，提升匹配精度。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|COME: Dual Structure-Semantic Learning with Collaborative MoE for Universal Lesion Detection Across Heterogeneous Ultrasound Datasets|COME：基于协作MoE的双结构-语义学习，实现异质超声数据集的通用病变检测|Lingyu Chen, Yawen Zeng, Yue Wang, Peng Wan, Guo-chen Ning, Hongen Liao, Daoqiang Zhang, Fang Chen|<http://arxiv.org/pdf/2508.09886v1>|[代码](https://universalcome.github.io/UniversalCOME); 提出了一种跨异质超声数据集的混合专家协同学习框架COME，有效缓解数据集间干扰并保持区分度特征，提升...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Debiased Fine-Tuning for Vision-language Models by Prompt Regularization|通过提示正则化进行视觉-语言模型的无偏微调|Beier Zhu, Yulei Niu, Saeil Lee, Minhoe Hur, Hanwang Zhang|<http://arxiv.org/pdf/2301.12429v3>|提出了一种通过提示正则化避免下游任务数据过拟合的视觉语言模型微调新范式。|
|📝 更新|Prompt-aligned Gradient for Prompt Tuning|"提示对齐梯度：用于提示调优的方法"|Beier Zhu, Yulei Niu, Yucheng Han, Yue Wu, Hanwang Zhang|<http://arxiv.org/pdf/2205.14865v4>|[代码](https://github.com/BeierZhu/Prompt-align.); 提出ProGrad方法，通过保持梯度一致性防止prompt调优遗忘预训练模型的一般知识，增强少样本泛...|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TRACE: Learning 3D Gaussian Physical Dynamics from Multi-view Videos|TRACE：从多视角视频中学习三维高斯物理动力学|Jinxi Li, Ziyang Song, Bo Yang|<http://arxiv.org/pdf/2508.09811v1>|提出了一种新框架TRACE，直接学习3D场景中每个粒子的运动物理，无需额外标签即可预测未来帧。|
|🆕 发布|DSS-Prompt: Dynamic-Static Synergistic Prompting for Few-Shot Class-Incremental Learning|DSS-Prompt: 动静协同提示式少样本类别增量学习|Linpu He, Yanan Li, Bingze Li, Elvis Han Cui, Donghui Wang|<http://arxiv.org/pdf/2508.09785v1>|提出DSS-Prompt方法，通过结合静态和动态提示，有效提升少量样本增量学习性能。|
|📝 更新|LiteFat: Lightweight Spatio-Temporal Graph Learning for Real-Time Driver Fatigue Detection|LiteFat：实时驾驶员疲劳检测的轻量级时空图学习|Jing Ren, Suyu Ma, Hong Jia, Xiwei Xu, Ivan Lee, Haytham Fayek, Xiaodong Li, Feng Xia|<http://arxiv.org/pdf/2507.21756v2>|提出了一种轻量级时空图学习模型LiteFat，用于实时高效检测驾驶员疲劳。|
|🆕 发布|Slot Attention-based Feature Filtering for Few-Shot Learning|基于槽注意力机制的少量样本学习特征筛选方法|Javier Rodenas, Eduardo Aguilar, Petia Radeva|<http://arxiv.org/pdf/2508.09699v1>|提出基于槽注意力机制的特征过滤方法，有效筛选弱特征提升少量样本学习分类性能。|
|📝 更新|Modulate and Reconstruct: Learning Hyperspectral Imaging from Misaligned Smartphone Views|调制与重建：从失配智能手机视角学习高光谱成像|Daniil Reutsky, Daniil Vladimirov, Yasin Mamedov, Georgy Perevozchikov, Nancy Mehta, Egor Ershov, Radu Timofte|<http://arxiv.org/pdf/2507.01835v2>|利用三摄像头智能手机系统及特定光谱滤波器，实现了比传统单摄像头更准确的 hyperspectral ...|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HVL: Semi-Supervised Segmentation leveraging Hierarchical Vision-Language Synergy with Dynamic Text-Spatial Query Alignment|HVL: 利用分层视觉-语言协同及动态文本-空间查询对齐的半监督分割|Numair Nadeem, Saeed Anwar, Muhammad Hamza Asad, Abdul Bais|<http://arxiv.org/pdf/2506.13925v2>|提出了一种利用视觉语言模型文本嵌入的半监督语义分割方法，通过层级视觉语言协同和动态文本空间对齐，显著...|
|🆕 发布|Leveraging Failed Samples: A Few-Shot and Training-Free Framework for Generalized Deepfake Detection|利用失败样本：一种无需训练的少样本泛化深度伪造检测框架|Shibo Yao, Renshuai Tao, Xiaolong Zheng, Chao Liang, Chunjie Zhang|<http://arxiv.org/pdf/2508.09475v1>|提出了一种无需大规模训练数据、仅利用少量样本进行深度伪造检测的新框架FTNet，实现了性能显著提升。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Toward Human-Robot Teaming: Learning Handover Behaviors from 3D Scenes|面向人机协作：从三维场景中学习交接行为|Yuekun Wu, Yik Lung Pang, Andrea Cavallaro, Changjae Oh|<http://arxiv.org/pdf/2508.09855v1>|提出了一种利用3D场景重建训练机器人交接行为的方法，无需实际机器人试验，实现更流畅的人机协作。|
|📝 更新|MoSE: Skill-by-Skill Mixture-of-Experts Learning for Embodied Autonomous Machines|MoSE：基于技能的混合专家学习，用于Embodied Autonomous Machines（具身自主机器）|Lu Xu, Jiaqian Yu, Xiongfeng Peng, Yiwei Chen, Weiming Li, Jaewook Yoo, Sunghyun Chunag, Dongwook Lee .etc.|<http://arxiv.org/pdf/2507.07818v2>|提出了一种分技能学习的混合专家模型MoSE，通过模仿人类学习过程，提高了自主系统推理和学习效率。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Grounding Emotion Recognition with Visual Prototypes: VEGA -- Revisiting CLIP in MERC|将情感识别与视觉原型进行结合：VEGA -- 重新审视CLIP在MERC中的应用|Guanyu Hu, Dimitrios Kollias, Xinyu Yang|<http://arxiv.org/pdf/2508.06564v2>|[代码](https://github.com/dkollias/VEGA.); 提出VEGA机制，利用视觉原型引导多模态情感识别，提升模型心理意义和性能。|
|🆕 发布|Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory|“观察、聆听、记忆与推理：具有长期记忆的多模态智能体”|Lin Long, Yichen He, Wentao Ye, Yiyuan Pan, Yuan Lin, Hang Li, Junbo Zhao, Wei Li|<http://arxiv.org/pdf/2508.09736v1>|[代码](https://github.com/bytedance-seed/m3-agent); 提出M3-Agent框架，融合视觉与听觉输入，构建长期记忆以提升多模态智能体的理解与推理能力。|
|📝 更新|See the Forest and the Trees: A Synergistic Reasoning Framework for Knowledge-Based Visual Question Answering|看到森林与树木：基于知识的视觉问答协同推理框架|Junjie Wang, Yunhan Tang, Yijie Wang, Zhihao Yuan, Huan Wang, Yangfan He, Bin Li|<http://arxiv.org/pdf/2507.17659v3>|提出协同推理框架Synergos-VQA，通过融合全局、结构和因果证据，提升知识驱动视觉问答的推理全...|
|🆕 发布|WeatherPrompt: Multi-modality Representation Learning for All-Weather Drone Visual Geo-Localization|《WeatherPrompt：全天候无人机视觉地理定位的多模态表征学习》|Jiahao Wen, Hang Yu, Zhedong Zheng|<http://arxiv.org/pdf/2508.09560v1>|提出WeatherPrompt方法，通过多模态学习融合图像与文本，实现全天候无人机视觉地理定位。|
|📝 更新|HRSeg: High-Resolution Visual Perception and Enhancement for Reasoning Segmentation|HRSeg：用于推理分割的高分辨率视觉感知与增强|Weihuang Lin, Yiwei Ma, Xiaoshuai Sun, Shuting He, Jiayi Ji, Liujuan Cao, Rongrong Ji|<http://arxiv.org/pdf/2507.12883v2>|HRSeg通过高分辨率视觉感知与增强，有效提升了推理分割任务的准确性和效率。|
|🆕 发布|GazeLT: Visual attention-guided long-tailed disease classification in chest radiographs|gazeLT：视觉注意力引导的长尾疾病分类在胸片影像中|Moinak Bhattacharya, Gagandeep Singh, Shubham Jain, Prateek Prasanna|<http://arxiv.org/pdf/2508.09478v1>|[代码](https://github.com/lordmoinak1/gazelt.); 提出了一种融合人类视觉注意力的方法GazeLT，用于提高胸部X射线影像中长尾疾病分类的准确性。|
|📝 更新|Audio-3DVG: Unified Audio -- Point Cloud Fusion for 3D Visual Grounding|音频-3DVG：统一音频与点云融合的三维视觉定位|Duc Cao-Dinh, Khai Le-Duc, Anh Dao, Bach Phan Tat, Chris Ngo, Duy M. H. Nguyen, Nguyen X. Khanh, Thanh Nguyen-Tang|<http://arxiv.org/pdf/2507.00669v2>|提出Audio-3DVG框架，融合音频与空间信息，提升3D视觉定位性能。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Towards flexible perception with visual memory|面向视觉记忆的灵活感知|Robert Geirhos, Priyank Jaini, Austin Stone, Sourabh Medapati, Xi Yi, George Toderici, Abhijit Ogale, Jonathon Shlens|<http://arxiv.org/pdf/2408.08172v3>|提出了一种结合深度神经网络与数据库灵活性的视觉记忆系统，实现了灵活的数据增删和可解释的决策机制。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|WEC-DG: Multi-Exposure Wavelet Correction Method Guided by Degradation Description|基于退化描述的多曝光小波校正方法WEC-DG|Ming Zhao, Pingping Liu, Tongshun Zhang, Zhe Zhang|<http://arxiv.org/pdf/2508.09565v1>|提出了一种基于小波变换和退化描述指导的多曝光校正方法，有效解决了复杂成像条件下曝光异常的问题。|
|📝 更新|Advancing Reliable Test-Time Adaptation of Vision-Language Models under Visual Variations|在视觉变化下推进视觉语言模型测试时的可靠适应|Yiwen Liang, Hui Chen, Yizhe Xiong, Zihan Zhou, Mengyao Lyu, Zijia Lin, Shuaicheng Niu, Sicheng Zhao .etc.|<http://arxiv.org/pdf/2507.09500v2>|[代码](https://github.com/Evelyn1ywliang/ReTA.); 提出了一种 Reliable Test-time Adaptation 方法，通过改进样本选择和决策...|
|🆕 发布|IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding|输入感知的视觉语言模型视觉定位后门攻击方法|Junxian Li, Beining Xu, Di Zhang|<http://arxiv.org/pdf/2508.09456v1>|提出了一种针对视觉语言模型的输入感知后门攻击方法IAG，能操控模型将特定目标对象作为任何查询的视觉定...|
|📝 更新|On the Reliability of Vision-Language Models Under Adversarial Frequency-Domain Perturbations|《在对抗性频率域扰动下视觉-语言模型的可靠性研究》|Jordan Vice, Naveed Akhtar, Yansong Gao, Richard Hartley, Ajmal Mian|<http://arxiv.org/pdf/2507.22398v3>|揭示了视觉语言模型在对抗性频率域扰动下的脆弱性，并设计了针对性的图像变换方法。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MIND: A Noise-Adaptive Denoising Framework for Medical Images Integrating Multi-Scale Transformer|《MIND：一种集成多尺度变换器的医学图像噪声自适应去噪框架》|Tao Tang, Chengxu Yang|<http://arxiv.org/pdf/2508.07817v2>|提出了一种结合多尺度卷积和Transformer架构的医疗图像自适应降噪模型，有效提升了图像质量和诊...|
|🆕 发布|Robustness analysis of Deep Sky Objects detection models on HPC|高性能计算环境下深空目标检测模型的鲁棒性分析|Olivier Parisot, Diogo Ramalho Fernandes|<http://arxiv.org/pdf/2508.09831v1>|分析了不同深度学习模型在智能望远镜图像上的鲁棒性，利用高性能计算加速模型训练与测试。|
|🆕 发布|KonfAI: A Modular and Fully Configurable Framework for Deep Learning in Medical Imaging|KonfAI：用于医学成像中深度学习的模块化和完全可配置框架|Valentin Boussot, Jean-Louis Dillenseger|<http://arxiv.org/pdf/2508.09823v1>|[代码](https://github.com/vboussot/KonfAI); KonfAI是一个模块化、可扩展且完全可配置的深度学习框架，通过YAML配置文件定义医疗影像任务的工...|
|🆕 发布|Poaching Hotspot Identification Using Satellite Imagery|利用卫星图像进行盗猎热点识别|Aryan Pandhi, Shrey Baid, Sanjali Jha|<http://arxiv.org/pdf/2508.09812v1>|提出了一种利用卫星图像识别非洲盗猎热点的方法，有效监测并预防大象盗猎问题。|
|📝 更新|Calibrated Self-supervised Vision Transformers Improve Intracranial Arterial Calcification Segmentation from Clinical CT Head Scans|校准的自监督视觉变换器提高临床CT头部扫描中颅内动脉钙化分割的效果|Benjamin Jin, Grant Mair, Joanna M. Wardlaw, Maria del C. Valdés Hernández|<http://arxiv.org/pdf/2507.01744v2>|首次将自监督预训练的视觉变换器应用于颅内动脉钙化分割，提升了临床风险分组准确性。|
|🆕 发布|NEURAL: Attention-Guided Pruning for Unified Multimodal Resource-Constrained Clinical Evaluation|神经网络：基于注意力引导的统一多模态资源受限临床评估的剪枝方法|Devvrat Joshi, Islem Rekik|<http://arxiv.org/pdf/2508.09715v1>|[代码](https://github.com/basiralab/NEURAL.); 提出NEURAL框架，通过语义引导的数据压缩和统一图表示，实现医学图像的高效存储与传输。|
|📝 更新|Revisiting 3D Medical Scribble Supervision: Benchmarking Beyond Cardiac Segmentation|重新审视三维医学涂鸦监督：超越心脏分割的基准测试|Karol Gotkowski, Klaus H. Maier-Hein, Fabian Isensee|<http://arxiv.org/pdf/2403.12834v2>|提出全面基准ScribbleBench，揭示了3D医疗图像 scribble 监督方法在泛化性上的不...|
|🆕 发布|Multi-Sequence Parotid Gland Lesion Segmentation via Expert Text-Guided Segment Anything Model|通过专家文本引导的Segment Anything模型进行多序列腮腺病变分割|Zhongyuan Wu, Chuan-Xian Ren, Yu Wang, Xiaohua Ban, Jianning Xiao, Xiaohui Duan|<http://arxiv.org/pdf/2508.09645v1>|提出了一种融合专家诊断文本指导的分割模型PG-SAM，实现了跨序列的腮腺病变精准分割。|
|🆕 发布|MInDI-3D: Iterative Deep Learning in 3D for Sparse-view Cone Beam Computed Tomography|MInDI-3D：用于稀疏视角锥形束计算机断层扫描的三维迭代深度学习|Daniel Barco, Marc Stadelmann, Martin Oswald, Ivo Herzig, Lukas Lichtensteiger, Pascal Paysan, Igor Peterlik, Michal Walczak .etc.|<http://arxiv.org/pdf/2508.09616v1>|首次将3D条件扩散模型应用于CBCT图像去噪，大幅降低辐射暴露同时保持临床适用性。|
|🆕 发布|Topological Invariant-Based Iris Identification via Digital Homology and Machine Learning|基于数字同伦与机器学习的拓扑不变量虹膜识别|Ahmet Öztel, İsmet Karaca|<http://arxiv.org/pdf/2508.09555v1>|利用数字同调拓扑不变量进行虹膜识别，提高了准确性和可解释性。|
|🆕 发布|Exploring the Equivalence of Closed-Set Generative and Real Data Augmentation in Image Classification|探讨闭集生成数据与真实数据增强在图像分类中的等效性|Haowen Wang, Guowei Zhang, Xiang Zhang, Zeyuan Chen, Haiyang Xu, Dou Hoon Kwark, Zhuowen Tu|<http://arxiv.org/pdf/2508.09550v1>|探讨了闭合集生成数据增强与真实数据增强在图像分类中的等效性，并提出了量化合成数据增强规模的方法。|
|📝 更新|Ear-Keeper: A Cross-Platform AI System for Rapid and Accurate Ear Disease Diagnosis|耳守者：一种跨平台的快速准确耳病诊断人工智能系统|Feiyan Lu, Yubiao Yue, Zhenzhang Li, Meiping Zhang, Wen Luo, Fan Zhang, Tong Liu, Jingyong Shi .etc.|<http://arxiv.org/pdf/2308.10610v5>|提出了一种跨平台AI系统Ear-Keeper，通过大规模数据集和高效模型实现了耳病快速准确诊断。|
|📝 更新|From Few to More: Scribble-based Medical Image Segmentation via Masked Context Modeling and Continuous Pseudo Labels|从少到多：基于scribble的医学图像分割通过掩码上下文建模和连续伪标签|Zhisong Wang, Yiwen Ye, Ziyang Chen, Minglei Shu, Yanning Zhang, Yong Xia|<http://arxiv.org/pdf/2408.12814v2>|提出MaCo模型，通过Masked Context Modeling和Continuous Pseu...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SWA-SOP: Spatially-aware Window Attention for Semantic Occupancy Prediction in Autonomous Driving|空间感知窗口注意力用于自动驾驶中的语义占用预测：SWA-SOP|Helin Cao, Rafael Materla, Sven Behnke|<http://arxiv.org/pdf/2506.18785v2>|提出SWA-SOP方法，通过引入空间感知窗口注意力，提高了自动驾驶中语义占用预测的准确性和鲁棒性。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Autonomous AI Bird Feeder for Backyard Biodiversity Monitoring|backyard backyard autonomous AI bird feeder for biodiversity monitoring   backyard 后院  backyard biodiversity 后院生物多样性  autonomous AI bird feeder 自主式AI鸟类喂食器  monitoring 监测  因此，该论文标题的中文翻译为：  “后院生物多样性监测用自主式AI鸟类喂食器”|El Mustapha Mansouri|<http://arxiv.org/pdf/2508.09398v1>|开发了一种低成本、离线的AI鸟类喂食器，通过检测和分类提高 backyard 生物多样性监测的准确性...|
|🆕 发布|Offline Auto Labeling: BAAS|离线自动标注：基于人工智能的服务（BAAS）|Stefan Haag, Bharanidhar Duraisamy, Felix Govaers, Wolfgang Koch, Martin Fritzsche, Juergen Dickmann|<http://arxiv.org/pdf/2508.09585v1>|提出了一种融合雷达检测的自动标注框架BAAS，通过贝叶斯追踪和融合技术精确标注自动驾驶中的物体轨迹和...|
|🆕 发布|Waymo-3DSkelMo: A Multi-Agent 3D Skeletal Motion Dataset for Pedestrian Interaction Modeling in Autonomous Driving|Waymo-3DSkelMo：面向自动驾驶中行人交互建模的多智能体三维骨骼运动数据集|Guangxun Zhu, Shiyu Fan, Hang Dai, Edmond S. L. Ho|<http://arxiv.org/pdf/2508.09404v1>|[代码](https://github.com/GuangxunZhu/Waymo-3DSkelMo); 介绍了Waymo-3DSkelMo数据集，通过3D人体形状和运动先验提高了动态城市环境中行人交互理解...|
|📝 更新|DualMap: Online Open-Vocabulary Semantic Mapping for Natural Language Navigation in Dynamic Changing Scenes|双映射：动态变化场景中自然语言导航的在线开放词汇语义映射|Jiajun Jiang, Yiming Zhu, Zirui Wu, Jie Song|<http://arxiv.org/pdf/2506.01950v3>|[代码](https://eku127.github.io/DualMap); 提出DualMap系统，通过自然语言指令实现动态场景下的在线语义映射和导航。|

