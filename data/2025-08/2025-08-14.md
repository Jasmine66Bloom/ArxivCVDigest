## [UPDATED!] **2025-08-14** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Closer Look at Multimodal Representation Collapse|深入探讨多模态表征坍缩问题|Abhra Chaudhuri, Anjan Dutta, Tu Bui, Serban Georgescu|<http://arxiv.org/pdf/2505.22483v2>|[代码](https://abhrac.github.io/mmcollapse); 揭示了多模态融合中模态崩溃现象的原因，并提出了一种通过显式基重新分配防止模态崩溃的算法。|
|📝 更新|MedVLThinker: Simple Baselines for Multimodal Medical Reasoning|MedVLThinker：多模态医疗推理的简单基线|Xiaoke Huang, Juncheng Wu, Hui Liu, Xianfeng Tang, Yuyin Zhou|<http://arxiv.org/pdf/2508.02669v2>|提出简单有效的MedVLThinker基线，通过强化学习提升多模态医疗推理性能。|
|📝 更新|TBAC-UniImage: Unified Understanding and Generation by Ladder-Side Diffusion Tuning|TBAC-UniImage：通过梯边扩散调整实现统一理解与生成|Junzhe Xu, Yuyang Yin, Xi Chen|<http://arxiv.org/pdf/2508.08098v2>|提出了一种融合多层次语言模型理解的统一图像生成模型，有效克服了传统模型连接浅层和训练成本高的局限。|
|🆕 发布|EgoCross: Benchmarking Multimodal Large Language Models for Cross-Domain Egocentric Video Question Answering|自我交叉：评估多模态大型语言模型在跨领域第一视角视频问答的性能|Yanjun Li, Yuqian Fu, Tianwen Qian, Qi'ao Xu, Silong Dai, Danda Pani Paudel, Luc Van Gool, Xiaoling Wang|<http://arxiv.org/pdf/2508.10729v1>|[代码](https://github.com/MyUniverse0726/EgoCross); 提出了EgoCross基准，用于评估多模态大型语言模型在跨域第一视角视频问答任务中的泛化能力。|
|🆕 发布|MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents|多模态浏览代理的全面基准：MM-BrowseComp|Shilong Li, Xingyuan Bu, Wenjie Wang, Jiaheng Liu, Jun Dong, Haoyang He, Hao Lu, Haozhe Zhang .etc.|<http://arxiv.org/pdf/2508.13186v1>|提出了MM-BrowseComp基准，评估AI代理在处理包含图像和视频的网页搜索中的多模态检索与推理...|
|🆕 发布|HumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs|"HumanSense：从多模态感知到通过推理MLLMs实现共情情境感知响应"|Zheng Qin, Ruobing Zheng, Yabing Wang, Tianqi Li, Yi Yuan, Jingdong Chen, Le Wang|<http://arxiv.org/pdf/2508.10576v1>|[代码](https://digital-avatar.github.io/ai); 提出HumanSense基准，评估多模态大语言模型在理解复杂人类意图和提供同理心响应的能力，并采用多...|
|🆕 发布|Towards Agentic AI for Multimodal-Guided Video Object Segmentation|面向多模态引导视频对象分割的代理型人工智能研究|Tuyen Tran, Thao Minh Le, Truyen Tran|<http://arxiv.org/pdf/2508.10572v1>|提出了一种自适应的多模态代理系统，通过大语言模型动态生成工作流，有效提升多模态视频对象分割的灵活性和...|
|🆕 发布|MM-Food-100K: A 100,000-Sample Multimodal Food Intelligence Dataset with Verifiable Provenance|MM-食品100K：一个具有可验证来源的10万样本多模态食品智能数据集|Yi Dong, Yusuke Muraoka, Scott Shi, Yi Zhang|<http://arxiv.org/pdf/2508.10429v1>|构建了一个包含10万样本的多模态食物智能数据集，通过社区众包和AI辅助确保数据质量与可追溯性。|
|🆕 发布|Contrast Sensitivity Function of Multimodal Vision-Language Models|多模态视觉语言模型的对比敏感度函数|Pablo Hernández-Cámara, Alexandra Gomez-Villa, Jose Manuel Jaén-Lorites, Jorge Vila-Tomás, Jesus Malo, Valero Laparra|<http://arxiv.org/pdf/2508.10367v1>|提出了一种评估多模态视觉语言模型与人类视觉感知一致性的新方法，揭示了模型在视觉敏感度方面的差距。|
|📝 更新|EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision|EXAONE路径2.0：具有端到端监督的病理基础模型|Myeongjang Pyeon, Janghyeon Lee, Minsoo Lee, Juseung Yun, Hwanil Choi, Jonghyun Kim, Jiwon Kim, Yi Hu .etc.|<http://arxiv.org/pdf/2507.06639v2>|EXAONE Path 2.0通过直接在幻灯片级别进行监督学习，有效提升了数字病理学中生物标志物预测...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Can Multi-modal (reasoning) LLMs detect document manipulation?|多模态（推理）大型语言模型能否检测文档操纵？|Zisheng Liang, Kidus Zewde, Rudra Pratap Singh, Disha Patil, Zexi Chen, Jiayu Xue, Yao Yao, Yifei Chen .etc.|<http://arxiv.org/pdf/2508.11021v1>|探究了多模态大语言模型在检测文档篡改中的效果，发现其具有优越的零样本泛化能力。|
|🆕 发布|Match & Choose: Model Selection Framework for Fine-tuning Text-to-Image Diffusion Models|匹配与选择：用于微调文本到图像扩散模型的模型选择框架|Basile Lewandowski, Robert Birke, Lydia Y. Chen|<http://arxiv.org/pdf/2508.10993v1>|提出首个模型选择框架M&C，通过匹配图预测最佳预训练T2I模型以微调特定数据域。|
|📝 更新|Quantitative Comparison of Fine-Tuning Techniques for Pretrained Latent Diffusion Models in the Generation of Unseen SAR Images|《预训练潜在扩散模型在生成未见SAR图像中微调技术的定量比较》|Solène Debuysère, Nicolas Trouvé, Nathan Letheule, Olivier Lévêque, Elise Colin|<http://arxiv.org/pdf/2506.13307v2>|提出了一种适应预训练扩散模型生成高分辨率合成孔径雷达图像的方法，通过混合调整策略有效保持了图像几何和...|
|🆕 发布|From Diagnosis to Improvement: Probing Spatio-Physical Reasoning in Vision Language Models|从诊断到改进：在视觉语言模型中探究空间物理推理|Tiancheng Han, Yunfei Gao, Yong Li, Wuzhou Yu, Qiaosheng Zhang, Wenqi Shao|<http://arxiv.org/pdf/2508.10770v1>|诊断并改进视觉语言模型在空间物理推理上的不足，通过监督微调及规则强化学习显著提升性能。|
|🆕 发布|ChatENV: An Interactive Vision-Language Model for Sensor-Guided Environmental Monitoring and Scenario Simulation|ChatENV：一种用于传感器引导的环境监测与场景模拟的交互式视觉-语言模型|Hosam Elgendy, Ahmed Sharshar, Ahmed Aboeitta, Mohsen Guizani|<http://arxiv.org/pdf/2508.10635v1>|提出首个结合卫星图像与传感器数据的交互式视觉语言模型ChatENV，实现环境监测与情景模拟。|
|📝 更新|Debiasing Multimodal Large Language Models via Penalization of Language Priors|通过惩罚语言先验来纠偏多模态大型语言模型|YiFan Zhang, Yang Shi, Weichen Yu, Qingsong Wen, Xue Wang, Wenjing Yang, Zhang Zhang, Liang Wang .etc.|<http://arxiv.org/pdf/2403.05262v3>|提出两种无需训练的策略，有效减轻多模态大语言模型依赖先验知识的偏差，提升视觉信息处理的准确性。|
|📝 更新|CapeLLM: Support-Free Category-Agnostic Pose Estimation with Multimodal Large Language Models|无支架类别无关姿态估计的多模态大型语言模型：CapeLLM|Junho Kim, Hyungjin Chung, Byung-Hoon Kim|<http://arxiv.org/pdf/2411.06869v2>|[代码](https://github.com/Junhojuno/CapeLLM.); 提出了CapeLLM，一种无需支持图像的多模态大语言模型，通过文本描述和查询图像直接估计类别无关的关...|
|📝 更新|MusiXQA: Advancing Visual Music Understanding in Multimodal Large Language Models|音乐视觉理解：在多模态大型语言模型中推进视觉音乐理解|Jian Chen, Wenye Ma, Penghang Liu, Wei Wang, Tengwei Song, Ming Li, Chenguang Wang, Jiayu Qin .etc.|<http://arxiv.org/pdf/2506.23009v3>|提出MusiXQA，首个评估和提升大型多模态语言模型在乐谱理解能力的综合数据集及相应模型Phi-3-...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OpenCUA: Open Foundations for Computer-Use Agents|开放CUA：计算机使用代理的开放基础|Xinyuan Wang, Bowen Wang, Dunjie Lu, Junlin Yang, Tianbao Xie, Junli Wang, Jiaqi Deng, Xiaole Guo .etc.|<http://arxiv.org/pdf/2508.09123v2>|提出OpenCUA框架，开放源代码以提升计算机使用代理的研究与性能。|
|📝 更新|Vision Transformers in Precision Agriculture: A Comprehensive Survey|精准农业中的视觉变换器：全面综述|Saber Mehdipour, Seyed Abolghasem Mirroshandel, Seyed Amirhossein Tabatabaei|<http://arxiv.org/pdf/2504.21706v4>|系统评估了Vision Transformers在精准农业中的应用，揭示了其在植物病害检测中的优势。|
|🆕 发布|Multi-Label Plant Species Prediction with Metadata-Enhanced Multi-Head Vision Transformers|多标签植物种类预测：基于元数据增强的多头视觉变换器|Hanna Herasimchyk, Robin Labryga, Tomislav Prusina|<http://arxiv.org/pdf/2508.10457v1>|[代码](https://github.com/geranium12/plant-clef-2025); 提出了一种多尺度图像处理和动态阈值优化的多标签植物种类预测方法，有效应对了领域迁移挑战并提高了预测性...|
|📝 更新|A Lightweight Transformer with Phase-Only Cross-Attention for Illumination-Invariant Biometric Authentication|一种具有相位仅交叉注意的轻量级Transformer，用于光照不变生物特征认证|Arun K. Sharma, Shubhobrata Bhattacharya, Motahar Reza, Bishakh Bhattacharya|<http://arxiv.org/pdf/2412.19160v3>|提出了一种结合额头和眼周特征的轻量级Transformer模型，有效应对口罩遮挡和光照变化，实现高准...|
|🆕 发布|ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver|Navigation-based Vision-Language-Action Model作为有效的机器人感知器|Wenxuan Song, Ziyang Zhou, Han Zhao, Jiayi Chen, Pengxiang Ding, Haodong Yan, Yuxin Huang, Feilong Tang .etc.|<http://arxiv.org/pdf/2508.10333v1>|[代码](https://zionchow.github.io/ReconVLA); 提出ReconVLA模型，通过视觉输出重建引导视觉注意力，提升机器人精准操作和泛化能力。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks|PTQAT：面向三维感知任务的混合参数高效量化算法|Xinhao Wang, Zhiwei Lin, Zhongyu Xia, Yongtao Wang|<http://arxiv.org/pdf/2508.10557v2>|提出PTQAT算法，结合PTQ与QAT优势，高效优化3D感知网络量化性能。|
|📝 更新|Part Segmentation of Human Meshes via Multi-View Human Parsing|通过多视角人体解析实现人体网格的部位分割|James Dickens, Kamyar Hamad|<http://arxiv.org/pdf/2507.18655v3>|[代码](https://github.com/JamesMcCullochDickens/Human3DParsing); 提出了一种结合多视角解析和几何变换的人类网格模型分块技术，实现了无需纹理信息的精确语义分割。|
|🆕 发布|Privacy-Aware Detection of Fake Identity Documents: Methodology, Benchmark, and Improved Detection Methods (FakeIDet2)|隐私感知的伪造身份证明文件检测：方法论、基准与改进检测方法（FakeIDet2）|Javier Muñoz-Haro, Ruben Tolosana, Ruben Vera-Rodriguez, Aythami Morales, Julian Fierrez|<http://arxiv.org/pdf/2508.11716v1>|提出隐私保护的伪造身份证检测方法，创建了大型数据库和标准基准，提升了对AI生成假证的识别能力。|
|🆕 发布|Cooperative Face Liveness Detection from Optical Flow|基于光流合作的活体人脸检测|Artem Sokolov, Mikhail Nikitin, Anton Konushin|<http://arxiv.org/pdf/2508.10786v1>|提出了一种基于用户互动和光流分析的活体检测方法，通过特定面部移动模式显著提高了真脸与攻击样本的区分能...|
|🆕 发布|Lightweight CNNs for Embedded SAR Ship Target Detection and Classification|轻量级卷积神经网络用于嵌入式合成孔径雷达船舶目标检测与分类|Fabian Kresse, Georgios Pilikos, Mario Azcueta, Nicolas Floury|<http://arxiv.org/pdf/2508.10712v1>|提出轻量级卷积神经网络，实现嵌入式合成孔径雷达数据船上实时船舶检测与分类。|
|🆕 发布|Axis-level Symmetry Detection with Group-Equivariant Representation|轴级别对称性检测与群等变表示|Wongyun Yu, Ahyun Seo, Minsu Cho|<http://arxiv.org/pdf/2508.10740v1>|提出了一种对偶分支架构，利用群等变特征精确检测反射和旋转对称轴，实现了计算机视觉中对称性检测的最新突...|
|🆕 发布|HyperTea: A Hypergraph-based Temporal Enhancement and Alignment Network for Moving Infrared Small Target Detection|超图基时序增强与对齐网络HyperTea：用于动态红外小目标检测|Zhaoyuan Qi, Weihua Gao, Wenlong Niu, Jie Tang, Yun Li, Xiaodong Peng|<http://arxiv.org/pdf/2508.10678v1>|[代码](https://github.com/Lurenjia-LRJ/HyperTea.); 提出HyperTea模型，融合全局与局部时序视角，利用超图学习提升动态红外小目标检测性能。|
|🆕 发布|Lameness detection in dairy cows using pose estimation and bidirectional LSTMs|使用姿态估计和双向长短时记忆网络检测奶牛跛行|Helena Russello, Rik van der Tol, Eldert J. van Henten, Gert Kootstra|<http://arxiv.org/pdf/2508.10643v1>|提出了一种结合姿态估计和双向长短时记忆网络的奶牛跛行检测方法，提高了分类准确率和数据处理效率。|
|📝 更新|Video-based automatic lameness detection of dairy cows using pose estimation and multiple locomotion traits|基于姿态估计和多种运动特征的奶牛自动跛行检测视频方法|Helena Russello, Rik van der Tol, Menno Holzhauer, Eldert J. van Henten, Gert Kootstra|<http://arxiv.org/pdf/2401.05202v2>|提出了一种基于视频和姿态估计的自动化奶牛跛行检测系统，通过分析多个运动特征提高了分类准确性。|
|🆕 发布|Fourier-Guided Attention Upsampling for Image Super-Resolution|基于傅里叶引导的注意力上采样图像超分辨率方法|Daejune Choi, Youchan No, Jinhyung Lee, Duksu Kim|<http://arxiv.org/pdf/2508.10616v1>|提出了一种轻量级图像超分辨率上采样模块，通过频率编码和自适应空间对齐显著减少了失真并增强了高频细节。|
|🆕 发布|Retrieval-Augmented Prompt for OOD Detection|异常检测的检索增强提示方法|Ruisong Han, Zongbo Han, Jiahao Zhang, Mingyue Cheng, Changqing Zhang|<http://arxiv.org/pdf/2508.10556v1>|提出了一种增强预训练模型语义监督的OOD检测方法Retrieval-Augmented Prompt...|
|🆕 发布|SkeySpot: Automating Service Key Detection for Digital Electrical Layout Plans in the Construction Industry|“SkeySpot：建筑行业中数字电气布局图服务密钥检测的自动化”|Dhruv Dosi, Rohit Meena, Param Rajpura, Yogesh Kumar Meena|<http://arxiv.org/pdf/2508.10449v1>|提出了一种基于YOLOv8的自动化服务关键符号检测方法，提升了建筑行业电气布局数字化处理的效率和准确...|
|🆕 发布|SC-Lane: Slope-aware and Consistent Road Height Estimation Framework for 3D Lane Detection|SC-Lane：面向3D车道检测的斜率感知与一致性道路高度估计框架|Chaesong Park, Eunbin Seo, Jihyeon Hwang, Jongwoo Lim|<http://arxiv.org/pdf/2508.10411v1>|[代码](https://parkchaesong.github.io/sclane); 提出了一种考虑坡度自适应和时序一致性的3D车道检测框架，有效提升了道路高度估计的准确性和鲁棒性。|
|📝 更新|Scaling Open-Vocabulary Action Detection|开放词汇动作检测的扩展|Zhen Hao Sia, Yogesh Singh Rawat|<http://arxiv.org/pdf/2504.03096v4>|[代码](https://siatheindochinese.github.io/sia_act_page); 提出了一种简洁的多模态模型和弱监督训练策略，解决了开放词汇动作检测的参数负担和数据不足问题。|
|📝 更新|EvRWKV: A Continuous Interactive RWKV Framework for Effective Event-Guided Low-Light Image Enhancement|EvRWKV：一种连续交互式RWKV框架，用于有效的事件引导低光图像增强|Wenjie Cai, Qingguo Meng, Zhenyu Wang, Xingbo Dong, Zhe Jin|<http://arxiv.org/pdf/2507.03184v2>|提出了一种连续交互的EvRWKV框架，通过双域处理有效融合事件相机与低光图像，实现了噪声抑制和细节恢...|
|📝 更新|Leveraging Motion Estimation for Efficient Bayer-Domain Computer Vision|利用运动估计提高拜耳域计算机视觉效率|Haichao Wang, Xinyue Xi, Jiangtao Wen, Yuxing Han|<http://arxiv.org/pdf/2501.15119v2>|提出利用运动估计直接在拜耳域加速视频视觉任务，减少计算量超70%且准确度损失微小。|
|🆕 发布|VIFSS: View-Invariant and Figure Skating-Specific Pose Representation Learning for Temporal Action Segmentation|VIFSS：视图不变且针对花样滑冰的姿态表示学习用于时间动作分割|Ryota Tanaka, Tomohiro Suzuki, Keisuke Fujii|<http://arxiv.org/pdf/2508.10281v1>|提出了一种专用于花样滑冰跳跃的三维动作识别框架，通过对比学习和细粒度标注提升了动作分割的准确性和鲁棒...|
|📝 更新|GraspClutter6D: A Large-scale Real-world Dataset for Robust Perception and Grasping in Cluttered Scenes|抓取杂乱6D：一个用于在杂乱场景中进行鲁棒感知和抓取的大规模真实世界数据集|Seunghyeok Back, Joosoon Lee, Kangmin Kim, Heeseon Rho, Geonhyup Lee, Raeyoung Kang, Sangbeom Lee, Sangjun Noh .etc.|<http://arxiv.org/pdf/2504.06866v3>|提出了GraspClutter6D大规模真实世界抓取数据集，提升了 cluttered 环境下的机器...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Colon Polyps Detection from Colonoscopy Images Using Deep Learning|使用深度学习从肠镜图像中检测结肠息肉|Md Al Amin, Bikash Kumar Paul|<http://arxiv.org/pdf/2508.13188v1>|提出了一种基于YOLOv5l架构的结肠息肉检测方法，提高了早期大肠癌筛查的准确性。|
|📝 更新|Stepwise Decomposition and Dual-stream Focus: A Novel Approach for Training-free Camouflaged Object Segmentation|逐步分解与双流聚焦：一种无需训练的伪装目标分割新方法|Chao Yin, Hao Li, Kequan Yang, Jide Li, Pinpin Zhu, Xiaoqiang Li|<http://arxiv.org/pdf/2506.06818v3>|[代码](https://github.com/ycyinchao/RDVP-MSD); 提出了一种无需训练的RDVP-MSD框架，通过逐步分解和双流视觉提示解决伪装物体分割中的语义模糊和空...|
|🆕 发布|Beyond conventional vision: RGB-event fusion for robust object detection in dynamic traffic scenarios|超越传统视觉：RGB-事件融合用于动态交通场景中的鲁棒目标检测|Zhanwen Liu, Yujing Sun, Yang Wang, Nan Yang, Shengbo Eben Li, Xiangmo Zhao|<http://arxiv.org/pdf/2508.10704v1>|[代码](https://github.com/Charm11492/MCFNet.); 整合RGB与事件相机，提出MCFNet网络，实现动态交通场景下的稳健目标检测。|
|📝 更新|Unifying Locality of KANs and Feature Drift Compensation Projection for Data-free Replay based Continual Face Forgery Detection|统一KANs的局部性与特征漂移补偿投影，用于无数据重放基础上的持续人脸伪造检测|Tianshuo Zhang, Siran Peng, Li Gao, Haoyuan Zhang, Xiangyu Zhu, Zhen Lei|<http://arxiv.org/pdf/2508.03189v2>|提出了一种基于KAN的持续人脸伪造检测框架，通过域分组检测器和数据无关特征分离策略，有效解决了灾难性...|
|🆕 发布|DOD-SA: Infrared-Visible Decoupled Object Detection with Single-Modality Annotations|DOD-SA：基于单模态注释的红外-可见光解耦目标检测|Hang Jin, Chenqiang Gao, Junjie Guo, Fangcen Liu, Kanghui Tian, Qinyao Chang|<http://arxiv.org/pdf/2508.10445v1>|提出了一种红外-可见解耦对象检测框架DOD-SA，通过单模态标注实现双模态检测，降低标注成本并提升性...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VasoMIM: Vascular Anatomy-Aware Masked Image Modeling for Vessel Segmentation|VasoMIM：面向血管解剖感知的遮蔽图像建模方法用于血管分割|De-Xing Huang, Xiao-Hu Zhou, Mei-Jiang Gui, Xiao-Liang Xie, Shi-Qi Liu, Shuang-Yi Wang, Tian-Yu Xiang, Rui-Ze Ma .etc.|<http://arxiv.org/pdf/2508.10794v1>|提出VasoMIM方法，利用解剖知识增强X射线血管图像的自监督学习，实现血管分割性能的提升。|
|🆕 发布|When Experts Disagree: Characterizing Annotator Variability for Vessel Segmentation in DSA Images|当专家意见不一：DSA图像血管分割中标注者变异性的表征|M. Geshvadi, G. So, D. D. Chlorogiannis, C. Galvin, E. Torio, A. Azimi, Y. Tachie-Baffour, N. Haouchine .etc.|<http://arxiv.org/pdf/2508.10797v1>|分析颅脑DSA图像中专家标注差异，量化分割不确定性，指导自动分割方法发展。|
|🆕 发布|Unlocking Robust Semantic Segmentation Performance via Label-only Elastic Deformations against Implicit Label Noise|通过仅标签的弹性形变应对隐式标签噪声解锁鲁棒语义分割性能|Yechan Kim, Dongho Yoon, Younkwan Lee, Unse Fatima, Hong Kook Kim, Songjae Lee, Sanga Park, Jeong Ho Park .etc.|<http://arxiv.org/pdf/2508.10383v1>|提出了一种针对隐含标签噪声的图像分割增强框架NSegment+，通过仅对标签进行弹性变形，提高了模型...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CRISP: Contrastive Residual Injection and Semantic Prompting for Continual Video Instance Segmentation|CRISP：对比残差注入与语义提示用于持续视频实例分割|Baichen Liu, Qi Lyu, Xudong Wang, Jiahua Dong, Lianqing Liu, Zhi Han|<http://arxiv.org/pdf/2508.10432v1>|[代码](https://github.com/01upup10/CRISP.); 提出CRISP方法，通过对比残差注入和语义提示解决视频实例分割的持续学习问题，有效避免遗忘并提升性能...|
|🆕 发布|Improving OCR for Historical Texts of Multiple Languages|提高多语言历史文本的光学字符识别效果|Hylke Westerdijk, Ben Blankenborg, Khondoker Ittehadul Islam|<http://arxiv.org/pdf/2508.10356v1>|提出多语言历史文本OCR改进方法，结合深度学习技术与数据增强提升字符识别准确率。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale|迈向大规模使用连续标记的自回归图像生成：NextStep-1|NextStep Team, Chunrui Han, Guopeng Li, Jingwei Wu, Quan Sun, Yan Cai, Yuang Peng, Zheng Ge .etc.|<http://arxiv.org/pdf/2508.10711v2>|提出NextStep-1模型，结合离散文本和连续图像token进行高效图像生成。|
|🆕 发布|Hybrid Generative Fusion for Efficient and Privacy-Preserving Face Recognition Dataset Generation|混合生成融合方法用于高效且保护隐私的人脸识别数据集生成|Feiran Li, Qianqian Xu, Shilong Bao, Boyu Han, Zhiyong Yang, Qingming Huang|<http://arxiv.org/pdf/2508.10672v2>|[代码](https://github.com/Ferry-Li/datacv_fr.); 提出了一种混合生成融合方法，通过合成新身份构建高质量且隐私安全的 face recognition ...|
|🆕 发布|HierOctFusion: Multi-scale Octree-based 3D Shape Generation via Part-Whole-Hierarchy Message Passing|HierOctFusion：基于多尺度八叉树的通过部分-整体-层次消息传递的三维形状生成|Xinjie Gao, Bi'an Du, Wei Hu|<http://arxiv.org/pdf/2508.11106v1>|提出HierOctFusion模型，通过多尺度八叉树和部件-整体层次消息传递生成高质量且高效的3D形...|
|🆕 发布|LD-LAudio-V1: Video-to-Long-Form-Audio Generation Extension with Dual Lightweight Adapters|LD-LAudio-V1：具有双向轻量级适配器的视频到长格式音频生成扩展|Haomin Zhang, Kristin Qi, Shuxin Yang, Zihao Chen, Chaofan Ding, Xinhan Di|<http://arxiv.org/pdf/2508.11074v1>|[代码](https://github.com/deepreasonings/long-form-video2audio.); 提出了一种双轻量级适配器扩展模型LD-LAudio-V1，用于生成高质量、时间同步的长格式音频，显著...|
|🆕 发布|GenFlowRL: Shaping Rewards with Generative Object-Centric Flow in Visual Reinforcement Learning|GenFlowRL：利用生成式以对象为中心的流在视觉强化学习中塑造奖励|Kelin Yu, Sheng Zhang, Harshit Soora, Furong Huang, Heng Huang, Pratap Tokekar, Ruohan Gao|<http://arxiv.org/pdf/2508.11049v1>|[代码](https://colinyu1.github.io/genflowrl); 提出GenFlowRL方法，通过生成对象中心流来形成奖励，提升视觉强化学习中的操作精度和泛化能力。|
|🆕 发布|TexVerse: A Universe of 3D Objects with High-Resolution Textures|《TexVerse：具有高分辨率纹理的3D对象宇宙》|Yibo Zhang, Li Zhang, Rui Ma, Nan Cao|<http://arxiv.org/pdf/2508.10868v1>|提出了TexVerse，一个包含超高清纹理的大规模3D模型数据集，解决了高分辨率纹理生成的研究空白。|
|📝 更新|MinD-3D++: Advancing fMRI-Based 3D Reconstruction with High-Quality Textured Mesh Generation and a Comprehensive Dataset|MinD-3D++：利用高质量纹理网格生成与全面数据集推进基于fMRI的3D重建|Jianxiong Gao, Yanwei Fu, Yuqian Fu, Yun Wang, Xuelin Qian, Jianfeng Feng|<http://arxiv.org/pdf/2409.11315v3>|[代码](https://jianxgao.github.io/MinD-3D.); 提出MinD-3D++框架，从fMRI信号解码生成高质量纹理的3D视觉信息。|
|🆕 发布|Generalizable Federated Learning using Client Adaptive Focal Modulation|使用客户端自适应焦点调节的通用联邦学习|Tajamul Ashraf, Iqra Altaf Gillani|<http://arxiv.org/pdf/2508.10840v1>|[代码](http://github.com/Tajamul21/TransFed); 提出AdaptFED方法，通过任务感知的客户端嵌入和低秩调节，提升联邦学习的泛化能力和效率。|
|🆕 发布|Privacy-enhancing Sclera Segmentation Benchmarking Competition: SSBC 2025|隐私增强巩膜分割基准竞赛：SSBC 2025|Matej Vitek, Darian Tomašević, Abhijit Das, Sabari Nathan, Gökhan Özbulak, Gözde Ayşe Tataroğlu Özbulak, Jean-Paul Calbimonte, André Anjos .etc.|<http://arxiv.org/pdf/2508.10737v1>|[代码](https://github.com/dariant/SSBC_2025.); 介绍了隐私增强的巩膜分割基准竞赛，证明了基于合成数据的模型在性能上可与传统数据训练的模型相媲美。|
|🆕 发布|Exploiting Discriminative Codebook Prior for Autoregressive Image Generation|利用区分性码书先验进行自回归图像生成|Longxiang Tang, Ruihang Chu, Xiang Wang, Yujin Han, Pingyu Wu, Chunming He, Yingya Zhang, Shiwei Zhang .etc.|<http://arxiv.org/pdf/2508.10719v1>|提出了一种新的代码簿先验提取器DCPE，有效利用代码簿中的相似性信息，加速了自回归图像生成模型的训练...|
|🆕 发布|CountCluster: Training-Free Object Quantity Guidance with Cross-Attention Map Clustering for Text-to-Image Generation|CountCluster：基于交叉注意力图聚类的无需训练的目标数量引导用于文本到图像生成|Joohyeon Lee, Jin-Seop Lee, Jee-Hyong Lee|<http://arxiv.org/pdf/2508.10710v1>|[代码](https://github.com/JoohyeonL22/CountCluster); 提出CountCluster方法，通过无需训练的注意力图聚类指导，提高文本到图像生成中对象数量的准确...|
|🆕 发布|EVCtrl: Efficient Control Adapter for Visual Generation|EVCtrl：视觉生成的效率控制适配器|Zixiang Yang, Yue Ma, Yinhan Zhang, Shanhui Mo, Dongrui Liu, Linfeng Zhang|<http://arxiv.org/pdf/2508.10963v1>|提出EVCtrl，一种无需重训练即可有效降低视觉生成模型控制开销的轻量级适配器。|
|🆕 发布|AddressVLM: Cross-view Alignment Tuning for Image Address Localization using Large Vision-Language Models|《AddressVLM：使用大规模视觉-语言模型进行图像地址定位的跨视角对齐调整》|Shixiong Xu, Chenghao Zhang, Lubin Fan, Yuan Zhou, Bin Fan, Shiming Xiang, Gaofeng Meng, Jieping Ye|<http://arxiv.org/pdf/2508.10667v1>|提出 AddressVLM 模型，通过融合卫星图像和街景图像进行跨视角对齐，提升了细粒度地址定位的准...|
|📝 更新|VMem: Consistent Interactive Video Scene Generation with Surfel-Indexed View Memory|VMem：基于微元索引视图内存的一致性交互式视频场景生成|Runjia Li, Philip Torr, Andrea Vedaldi, Tomas Jakab|<http://arxiv.org/pdf/2506.18903v3>|提出了一种基于3D表面元素的内存模块VMem，实现了高效且一致性的视频场景生成与探索。|
|🆕 发布|Increasing the Utility of Synthetic Images through Chamfer Guidance|通过Chamfer引导提高合成图像的实用性|Nicola Dall'Asen, Xiaofeng Zhang, Reyhane Askari Hemmat, Melissa Hall, Jakob Verbeek, Adriana Romero-Soriano, Michal Drozdzal|<http://arxiv.org/pdf/2508.10631v1>|提出了一种名为Chamfer Guidance的无训练指导方法，通过少量真实图像提高合成图像的多样性...|
|🆕 发布|A Segmentation-driven Editing Method for Bolt Defect Augmentation and Detection|一种基于分割驱动的螺栓缺陷增强与检测方法|Yangjie Xiao, Ke Zhang, Jiacun Wang, Xin Sheng, Yurong Guo, Meijuan Chen, Zehua Ren, Zhaoye Zheng .etc.|<http://arxiv.org/pdf/2508.10509v1>|[代码](https://github.com/Jay-xyj/SBDE.); 提出了一种基于分割的螺栓缺陷编辑方法，通过属性编辑和数据增强显著提升缺陷检测性能。|
|📝 更新|SIFThinker: Spatially-Aware Image Focus for Visual Reasoning|"SIFThinker：空间感知图像聚焦视觉推理"|Zhangquan Chen, Ruihui Zhao, Chuwei Luo, Mingze Sun, Xinlei Yu, Yangyang Kang, Ruqi Huang|<http://arxiv.org/pdf/2508.06259v2>|[代码](https://github.com/zhangquanchen/SIFThinker.); 提出SIFThinker框架，通过结合深度信息和自然语言实现图像区域的空间感知注意力校正，提升视觉推...|
|📝 更新|Yan: Foundational Interactive Video Generation|《基础交互式视频生成》|Deheng Ye, Fangyun Zhou, Jiacheng Lv, Jianqi Ma, Jun Zhang, Junyan Lv, Junyou Li, Minwen Deng .etc.|<http://arxiv.org/pdf/2508.08601v3>|[代码](https://greatx3.github.io/Yan); 提出了Yan框架，实现了实时交互式视频生成，支持从模拟到编辑的全流程，并具备跨领域风格和机制灵活融合...|
|📝 更新|TikZero: Zero-Shot Text-Guided Graphics Program Synthesis|“TikZero：零样本文本引导的图形程序合成”|Jonas Belouadi, Eddy Ilg, Margret Keuper, Hideki Tanaka, Masao Utiyama, Raj Dabre, Steffen Eger, Simone Paolo Ponzetto|<http://arxiv.org/pdf/2503.11509v3>|提出了一种利用未对齐数据实现零样本文本引导的图形程序合成方法，大幅超越了仅能处理对齐数据的基线。|
|🆕 发布|TweezeEdit: Consistent and Efficient Image Editing with Path Regularization|TweezeEdit：具有路径正则化的连贯高效图像编辑|Jianda Mao, Kaibo Wang, Yang Xiang, Kani Chen|<http://arxiv.org/pdf/2508.10498v1>|提出了一种无需调整和反转的图像编辑框架TweezeEdit，通过路径正则化实现高效一致的编辑效果，同...|
|📝 更新|M2DAO-Talker: Harmonizing Multi-granular Motion Decoupling and Alternating Optimization for Talking-head Generation|M2DAO-Talker：结合多粒度运动解耦与交替优化生成说话人头像|Kui Jiang, Shiyu Liu, Junjun Jiang, Hongxun Yao, Xiaopeng Fan|<http://arxiv.org/pdf/2507.08307v3>|[代码](https://m2dao-talker.github.io/M2DAO-Talk.github.io.); 提出了一种多粒度运动解耦与交替优化策略，有效解决了说话人头生成中的运动模糊和局部穿透问题，实现了高质...|
|📝 更新|Nautilus: Locality-aware Autoencoder for Scalable Mesh Generation|鹦鹉螺：面向可扩展网格生成的局部感知自动编码器|Yuxuan Wang, Xuanyu Yi, Haohan Weng, Qingshan Xu, Xiaokang Wei, Xianghui Yang, Chunchao Guo, Long Chen .etc.|<http://arxiv.org/pdf/2501.14317v5>|提出Nautilus，一种利用局部特性的高效自动编码器，实现大规模高质量网格生成。|
|🆕 发布|NanoControl: A Lightweight Framework for Precise and Efficient Control in Diffusion Transformer|纳米控制：一种用于精确高效控制的轻量级扩散变换器框架|Shanyuan Liu, Jian Zhu, Junda Lu, Yue Gong, Liuzhuozheng Li, Bo Cheng, Yuhang Ma, Liebucha Wu .etc.|<http://arxiv.org/pdf/2508.10424v1>|提出NanoControl框架，通过LoRA-style控制模块和KV-Context增强，实现了高...|
|🆕 发布|Towards Spatially Consistent Image Generation: On Incorporating Intrinsic Scene Properties into Diffusion Models|迈向空间一致性的图像生成：关于将场景固有属性融入扩散模型的研究|Hyundo Lee, Suhyung Choi, Byoung-Tak Zhang, Inwoo Hwang|<http://arxiv.org/pdf/2508.10382v1>|提出了一种结合场景内在属性生成图像的方法，通过协同生成图像和其内在属性，显著提升了图像的空间一致性和...|
|📝 更新|EditGarment: An Instruction-Based Garment Editing Dataset Constructed with Automated MLLM Synthesis and Semantic-Aware Evaluation|编辑服饰：一种基于指令的服饰编辑数据集，采用自动化大规模语言模型合成与语义感知评估构建|Deqiang Yin, Junyi Guo, Huanda Lu, Fangyu Wu, Dongming Lu|<http://arxiv.org/pdf/2508.03497v2>|[代码](https://yindq99.github.io/EditGarment-project); 构建首个面向服装编辑的指令型数据集EditGarment，通过自动化合成与语义感知评估提升编辑精度。|
|📝 更新|Improving Viewpoint Consistency in 3D Generation via Structure Feature and CLIP Guidance|通过结构特征与CLIP引导提升三维生成中的视点一致性|Qing Zhang, Jinguang Tong, Jing Zhang, Jie Hong, Xuesong Li|<http://arxiv.org/pdf/2412.02287v4>|提出了一种无调参的ACG机制，通过自适应控制注意力和CLIP引导，有效解决了3D生成中的视角一致性难...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PSScreen: Partially Supervised Multiple Retinal Disease Screening|PSScreen：部分监督的多视网膜疾病筛查|Boyi Zheng, Qing Liu|<http://arxiv.org/pdf/2508.10549v2>|[代码](https://github.com/boyiZheng99/PSScreen.); 提出PSScreen模型，通过半监督学习与特征蒸馏应对多视网膜疾病筛查中的标注不足和数据域差异挑战。|
|📝 更新|An Analytical Theory of Spectral Bias in the Learning Dynamics of Diffusion Models|《扩散模型学习动力学中的光谱偏差分析理论》|Binxu Wang, Cengiz Pehlevan|<http://arxiv.org/pdf/2503.03206v2>|揭示了扩散模型训练中数据协方差如何影响学习顺序和速度，提出了一个解析框架来理解生成分布的演变。|
|📝 更新|HepatoGEN: Generating Hepatobiliary Phase MRI with Perceptual and Adversarial Models|肝胆相生：利用感知与对抗模型生成肝胆期磁共振成像|Jens Hooge, Gerard Sanroma-Guell, Faidra Stavropoulou, Alexander Ullmann, Gesine Knobloch, Mark Klemens, Carola Schmidt, Sabine Weckbach .etc.|<http://arxiv.org/pdf/2504.18405v2>|[代码](https://jhooge.github.io/hepatogen); 提出了一种基于深度学习的肝脏MRI动态对比增强方法，通过早期相位图像生成 hepatobiliary...|
|🆕 发布|Human-in-Context: Unified Cross-Domain 3D Human Motion Modeling via In-Context Learning|《情境中的人：通过情境学习实现的统一跨领域三维人体运动建模》|Mengyuan Liu, Xinshun Wang, Zhongbin Fang, Deheng Ye, Xia Li, Tao Tang, Songtao Wu, Xiangtai Li .etc.|<http://arxiv.org/pdf/2508.10897v1>|[代码](https://github.com/BradleyWang0416/Human-in-Context.); 提出Human-in-Context模型，通过单次训练统一处理多模态、任务和数据集的3D人体运动。|
|🆕 发布|Ultra-High-Definition Reference-Based Landmark Image Super-Resolution with Generative Diffusion Prior|基于超高清参考基准的地标图像超分辨率重建与生成扩散先验方法|Zhenning Shi, Zizheng Yan, Yuhang Yu, Clara Xue, Jingyu Zhuang, Qi Zhang, Jinwei Chen, Tao Li .etc.|<http://arxiv.org/pdf/2508.10779v1>|[代码](https://github.com/nkicsl/TriFlowSR.); 提出了一种用于超高清地标场景的参考图像超分辨率框架TriFlowSR，有效提升了低分辨率图像与参考高...|
|📝 更新|Deblurring in the Wild: A Real-World Dataset from Smartphone High-Speed Videos|《野外去模糊：来自智能手机高速视频的实际世界数据集》|Mahdi Mohd Hossain Noki, Syed Mumtahin Mahmud, Prothito Shovon Majumder, Abdul Mohaimen Al Radi, Sudipto Das Sukanto, Afia Lubaina, Md. Mosaddek Khan|<http://arxiv.org/pdf/2506.19445v3>|构建了首个大规模真实世界图像去模糊数据集，推动了去模糊算法的鲁棒性和泛化能力。|
|🆕 发布|Novel View Synthesis using DDIM Inversion|基于DDIM逆过程的创新视角合成|Sehajdeep SIngh, A V Subramanyam|<http://arxiv.org/pdf/2508.10688v1>|提出了一种利用预训练扩散模型的高保真生成能力，通过轻量级视图转换框架实现清晰新颖视图合成的技术。|
|🆕 发布|IADGPT: Unified LVLM for Few-Shot Industrial Anomaly Detection, Localization, and Reasoning via In-Context Learning|IADGPT：通过上下文学习实现少量样本工业异常检测、定位与推理的统一LVLM模型|Mengyang Zhao, Teng Fu, Haiyang Yu, Ke Niu, Bin Li|<http://arxiv.org/pdf/2508.10681v1>|提出了一种模仿人类学习方式的统一框架IADGPT，用于少量样本工业异常检测、定位和推理，有效提升了对...|
|🆕 发布|Geospatial Diffusion for Land Cover Imperviousness Change Forecasting|地理空间扩散用于土地覆盖不透水性变化预测|Debvrat Varshney, Vibhas Vats, Bhartendu Pandey, Christa Brelsford, Philipe Dias|<http://arxiv.org/pdf/2508.10649v1>|提出利用生成式人工智能进行土地覆盖变化预测的新方法，通过历史数据训练扩散模型以准确预测不透水表面的未...|
|🆕 发布|EgoMusic-driven Human Dance Motion Estimation with Skeleton Mamba|以EgoMusic驱动的基于骨架Mamba的人体舞蹈动作估计|Quang Nguyen, Nhat Le, Baoru Huang, Minh Nhat Vu, Chengcheng Tang, Van Nguyen, Ngan Le, Thieu Vo .etc.|<http://arxiv.org/pdf/2508.10522v1>|提出了一种结合第一视角视频和音乐输入的人体舞蹈动作预测方法，通过骨骼结构建模显著提升了动作估计准确性...|
|📝 更新|MIDAS: Modeling Ground-Truth Distributions with Dark Knowledge for Domain Generalized Stereo Matching|MIDAS：利用暗知识建模真实分布以进行域泛化立体匹配|Peng Xu, Zhiyu Xiang, Jingyun Fu, Tianyu Pu, Hanzhi Zhong, Eryun Liu|<http://arxiv.org/pdf/2503.04376v2>|提出利用暗知识建模多模态真实分布，有效提升立体匹配在多域场景的泛化性能。|
|🆕 发布|Empowering Multimodal LLMs with External Tools: A Comprehensive Survey|《赋予多模态大型语言模型以外部工具能力：全面综述》|Wenbin An, Jiahao Nie, Yaqiang Wu, Feng Tian, Shijian Lu, Qinghua Zheng|<http://arxiv.org/pdf/2508.10955v1>|[代码](https://github.com/Lackel/Awesome-Tools-for-MLLMs.); 探讨了如何通过集成外部工具提升多模态大型语言模型的性能，以应对数据质量和复杂任务挑战。|
|🆕 发布|AtomDiffuser: Time-Aware Degradation Modeling for Drift and Beam Damage in STEM Imaging|原子扩散器：面向STEM成像中漂移与束损伤的时间感知退化建模|Hao Wang, Hongkui Zheng, Kai He, Abolfazl Razi|<http://arxiv.org/pdf/2508.10359v1>|提出了一种时间感知退化建模框架AtomDiffuser，有效分离STEM成像中的漂移和辐射损伤效应，...|
|📝 更新|PiT: Progressive Diffusion Transformer|渐进式扩散变换器：PiT|Jiafu Wu, Yabiao Wang, Jian Li, Jinlong Peng, Yun Cao, Chengjie Wang, Jiangning Zhang|<http://arxiv.org/pdf/2505.13219v5>|提出PSWA和PCCA策略，通过减少全局计算冗余提升图像生成效率，PiT模型性能优于传统DiTs。|
|🆕 发布|MRFD: Multi-Region Fusion Decoding with Self-Consistency for Mitigating Hallucinations in LVLMs|MRFD：基于自一致性多区域融合解码减轻LVLMs中的幻觉现象|Haonan Ge, Yiwei Wang, Ming-Hsuan Yang, Yujun Cai|<http://arxiv.org/pdf/2508.10264v1>|提出了一种无需训练的解码方法MRFD，通过建模区域间一致性减少大型视觉语言模型中的幻觉现象。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Translation of Text Embedding via Delta Vector to Suppress Strongly Entangled Content in Text-to-Image Diffusion Models|通过增量向量翻译文本嵌入以抑制文本到图像扩散模型中的强纠缠内容|Eunseo Koh, Seunghoo Hong, Tae-Young Kim, Simon S. Woo, Jae-Pil Heo|<http://arxiv.org/pdf/2508.10407v2>|提出了一种通过引入修正文本嵌入空间的差分向量方法，有效抑制文本图像生成中强烈关联的冗余内容。|
|🆕 发布|Failures to Surface Harmful Contents in Video Large Language Models|视频大规模语言模型中揭示有害内容失败的探讨|Yuxin Cao, Wei Song, Derui Wang, Jingling Xue, Jin Song Dong|<http://arxiv.org/pdf/2508.10974v1>|揭示了视频大语言模型在检测有害内容中的缺陷，并设计了针对性攻击策略以提高内容安全性。|
|🆕 发布|Hierarchical Fine-grained Preference Optimization for Physically Plausible Video Generation|层次化细粒度偏好优化用于物理可信视频生成|Harold Haodong Chen, Haojian Huang, Qifeng Chen, Harry Yang, Ser-Nam Lim|<http://arxiv.org/pdf/2508.10858v1>|提出PhysHPO框架，通过细粒度偏好对齐和自动化数据选择，显著提升物理可信视频生成质量。|
|🆕 发布|AEGIS: Authenticity Evaluation Benchmark for AI-Generated Video Sequences|AEGIS：人工智能生成视频序列真实性评估基准|Jieyu Li, Xin Zhang, Joey Tianyi Zhou|<http://arxiv.org/pdf/2508.10771v1>|提出了AEGIS大规模基准，针对检测超逼真AI生成视频，提高了评估现代视觉语言模型的复杂性和真实性。|
|🆕 发布|Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation|视频-BLADE：块稀疏注意力与步进蒸馏相遇，实现高效视频生成|Youping Gu, Xiaolong Li, Yuhao Hu, Bohan Zhuang|<http://arxiv.org/pdf/2508.10774v1>|提出Video-BLADE框架，通过自适应块稀疏注意力和轨迹分布匹配的步进蒸馏，高效生成高质量视频并...|
|🆕 发布|DIVA-VQA: Detecting Inter-frame Variations in UGC Video Quality|DIVA-VQA：检测用户生成内容视频中帧间差异的质量评估方法|Xinyi Wang, Angeliki Katsenou, David Bull|<http://arxiv.org/pdf/2508.10605v1>|[代码](https://github.com/xinyiW915/DIVA-VQA.); 提出了一种基于帧间差异的无需参考视频质量评估模型，通过多级分析显著提升了UGC视频质量监测准确性。|
|📝 更新|SHALE: A Scalable Benchmark for Fine-grained Hallucination Evaluation in LVLMs|SHALE：用于LVLMs中细粒度幻觉评估的可扩展基准|Bei Yan, Zhiyuan Chen, Yuecong Min, Jie Zhang, Jiahao Wang, Xiaozhen Wang, Shiguang Shan|<http://arxiv.org/pdf/2508.09584v2>|提出了一种自动化构建方法，创建了SHALE基准，用于细粒度评估大型视觉语言模型中的事实性和忠实性幻觉...|
|📝 更新|MEDTalk: Multimodal Controlled 3D Facial Animation with Dynamic Emotions by Disentangled Embedding|MEDTalk：通过解耦嵌入实现的具有动态情感的多模态可控三维面部动画|Chang Liu, Ye Pan, Chenyang Ding, Susanto Rahardja, Xiaokang Yang|<http://arxiv.org/pdf/2507.06071v4>|[代码](https://github.com/SJTU-Lucy/MEDTalk.); 提出MEDTalk框架，通过解耦内容和情感嵌入空间实现细粒度和动态情绪的3D面部动画生成。|
|📝 更新|MSC: A Marine Wildlife Video Dataset with Grounded Segmentation and Clip-Level Captioning|海洋野生动物视频数据集：带有地面分割和片段级标注的MSC|Quang-Trung Truong, Yuk-Kwan Wong, Vo Hoang Kim Tuyen Dang, Rinaldi Gotama, Duc Thanh Nguyen, Sai-Kit Yeung|<http://arxiv.org/pdf/2508.04549v2>|提出了一种针对海洋生物视频的理解和生成方法，通过结合视频、文本和分割掩模的基准，提升了海洋视频的解析...|
|🆕 发布|Integrating Reinforcement Learning with Visual Generative Models: Foundations and Advances|将强化学习与视觉生成模型相结合：基础与进展|Yuanzhi Liang, Yijie Fang, Rui Li, Ziqi Ni, Ruijie Su, Chi Zhang, Xuelong Li|<http://arxiv.org/pdf/2508.10316v1>|整合强化学习与视觉生成模型，提升生成内容的控制性、一致性和人类匹配度。|
|📝 更新|PromptSafe: Gated Prompt Tuning for Safe Text-to-Image Generation|PromptSafe：安全文本到图像生成的门控提示微调|Zonglei Jing, Xiao Yang, Xiaoqian Li, Siyuan Liang, Aishan Liu, Mingchuan Zhang, Xianglong Liu|<http://arxiv.org/pdf/2508.01272v2>|提出PromptSafe框架，通过轻量级文本嵌入和自适应门控机制，有效抑制不安全内容生成，同时保持良...|
|🆕 发布|High Fidelity Text to Image Generation with Contrastive Alignment and Structural Guidance|高质量文本到图像生成：基于对比对齐与结构引导的方法|Danyi Gao|<http://arxiv.org/pdf/2508.10280v1>|提出了一种结合对比对齐和结构引导的高保真文本到图像生成方法，提升了语义对齐准确性和结构一致性。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Puppeteer: Rig and Animate Your 3D Models|木偶操作者：绑定并动画化你的3D模型|Chaoyue Song, Xiu Li, Fan Yang, Zhongcong Xu, Jiacheng Wei, Fayao Liu, Jiashi Feng, Guosheng Lin .etc.|<http://arxiv.org/pdf/2508.10898v1>|提出了Puppeteer框架，自动实现3D模型的绑定与动画，提高了生成效率和动画质量。|
|🆕 发布|ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing|《ToonComposer：利用生成式后关键帧优化卡通制作流程》|Lingen Li, Guangzhi Wang, Zhaoyang Zhang, Yaowei Li, Xiaoyu Li, Qi Dou, Jinwei Gu, Tianfan Xue .etc.|<http://arxiv.org/pdf/2508.10881v1>|ToonComposer统一了动画制作中的中间帧生成和着色步骤，通过稀疏草图注入机制提高了生产效率和...|
|📝 更新|From Large Angles to Consistent Faces: Identity-Preserving Video Generation via Mixture of Facial Experts|从大角度到一致的面孔：通过面部专家混合实现身份保持的视频生成|Yuji Wang, Moran Li, Xiaobin Hu, Ran Yi, Jiangning Zhang, Chengming Xu, Weijian Cao, Yabiao Wang .etc.|<http://arxiv.org/pdf/2508.09476v2>|[代码](https://github.com/rain152/LFA-Video-Generation.); 提出了一种混合面部专家模型，通过专门化处理和定制数据集，有效解决了大角度下身份保持问题。|
|🆕 发布|Dissecting Generalized Category Discovery: Multiplex Consensus under Self-Deconstruction|剖析泛化类别发现：自我解构下的多路共识|Luyao Tang, Kunze Huang, Chaoqi Chen, Yuxuan Yuan, Chenxin Li, Xiaotong Tu, Xinghao Ding, Yue Huang|<http://arxiv.org/pdf/2508.10731v1>|[代码](https://github.com/lytang63/ConGCD.); 提出了一种模仿人类认知的视觉学习框架ConGCD，通过分解对象并建立多级共识来增强跨类别识别能力。|
|📝 更新|Reinforcement Learning in Vision: A Survey|计算机视觉中的强化学习：综述|Weijia Wu, Chen Gao, Joya Chen, Kevin Qinghong Lin, Qingwei Meng, Yiming Zhang, Yuke Qiu, Hong Zhou .etc.|<http://arxiv.org/pdf/2508.08189v2>|[代码](https://github.com/weijiawu/Awesome-Visual-Reinforcement-Learning.); 系统梳理了视觉强化学习领域的发展，分类总结了算法设计、奖励工程等关键进展。|
|🆕 发布|SemPT: Semantic Prompt Tuning for Vision-Language Models|语义提示调优：面向视觉-语言模型的SemPT|Xiao Shi, Yangjun Ou, Zhenzhong Chen|<http://arxiv.org/pdf/2508.10645v1>|提出利用共享属性级知识提升视觉迁移学习性能的语义提示调优方法SemPT。|
|🆕 发布|HM-Talker: Hybrid Motion Modeling for High-Fidelity Talking Head Synthesis|HM-说话人：高保真说话人头合成中的混合运动建模|Shiyu Liu, Kui Jiang, Xianming Liu, Hongxun Yao, Xiaocheng Feng|<http://arxiv.org/pdf/2508.10566v1>|提出了一种结合显式和隐式运动线索的混合运动建模框架，有效解决了说话人头合成中的运动模糊和唇部颤动问题...|
|🆕 发布|STRIDE-QA: Visual Question Answering Dataset for Spatiotemporal Reasoning in Urban Driving Scenes|STRIDE-QA：面向城市驾驶场景中的时空推理视觉问答数据集|Keishi Ishihara, Kento Sasaki, Tsubasa Takahashi, Daiki Shiono, Yu Yamaguchi|<http://arxiv.org/pdf/2508.10427v1>|提出STRIDE-QA数据集，通过大规模视觉问答促进自动驾驶中的时空推理能力。|
|📝 更新|Point or Line? Using Line-based Representation for Panoptic Symbol Spotting in CAD Drawings|点还是线？在CAD图纸中使用基于线的表示进行全场景符号检测|Xingguang Wei, Haomin Wang, Shenglong Ye, Ruifeng Luo, Yanting Zhang, Lixin Gu, Jifeng Dai, Yu Qiao .etc.|<http://arxiv.org/pdf/2505.23395v2>|提出了一种基于线条表示的VecFormer方法，提高了CAD图纸的全景符号检测准确性和效率。|
|🆕 发布|Efficient Image Denoising Using Global and Local Circulant Representation|使用全局和局部循环表示的高效图像去噪|Zhaoming Kong, Jiahuan Zhang, Xiaowei Yang|<http://arxiv.org/pdf/2508.10307v1>|[代码](https://github.com/ZhaomingKong/Haar-tSVD.); 提出了一种高效的图像去噪算法Haar-tSVD，通过统一张量奇异值分解和Haar变换捕捉全局与局部相...|
|🆕 发布|Pose-Robust Calibration Strategy for Point-of-Gaze Estimation on Mobile Phones|面向移动手机的姿态鲁棒校准策略用于 gaze 点估计|Yujie Zhao, Jiabei Zeng, Shiguang Shan|<http://arxiv.org/pdf/2508.10268v1>|提出动态校准策略以应对头部姿势变化，提高移动设备上 gaze 估计的准确性。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SynBrain: Enhancing Visual-to-fMRI Synthesis via Probabilistic Representation Learning|“SynBrain：通过概率表征学习增强视觉至fMRI合成”|Weijian Mai, Jiamin Wu, Yu Zhu, Zhouheng Yao, Dongzhan Zhou, Andrew F. Luo, Qihao Zheng, Wanli Ouyang .etc.|<http://arxiv.org/pdf/2508.10298v2>|提出了一种概率性视觉到fMRI合成框架SynBrain，有效模拟视觉刺激到神经反应的映射并适应不同个...|
|📝 更新|Wild2Avatar: Rendering Humans Behind Occlusions|《Wild2Avatar：渲染被遮挡后人像》|Tiange Xiang, Adam Sun, Scott Delp, Kazuki Kozuka, Li Fei-Fei, Ehsan Adeli|<http://arxiv.org/pdf/2401.00431v2>|提出了一种针对遮挡条件下单目视频的神经渲染方法Wild2Avatar，实现了在现实场景中渲染被遮挡的...|
|📝 更新|ViFusionTST: Deep Fusion of Time-Series Image Representations from Load Signals for Early Bed-Exit Prediction|基于负载信号的时间序列图像表示深度融合的ViFusionTST：用于早期离床预测|Hao Liu, Yu Hu, Rakiba Rayhana, Ling Bai, Zheng Liu|<http://arxiv.org/pdf/2506.22498v2>|提出了一种利用图像转换和双流Swin Transformer融合负载信号的方法，用于实时预测患者离床...|
|🆕 发布|Physics-Informed Joint Multi-TE Super-Resolution with Implicit Neural Representation for Robust Fetal T2 Mapping|基于物理信息约束的隐式神经表示联合多TE超分辨率胎儿T2映射|Busra Bulut, Maik Dannecker, Thomas Sanchez, Sara Neves Silva, Vladyslav Zalevskyi, Steven Jia, Jean-Baptiste Ledoux, Guillaume Auzias .etc.|<http://arxiv.org/pdf/2508.10680v1>|提出了一种结合物理信息正则化的隐式神经表示方法，实现了跨多个TE的胎儿脑部T2映射超分辨率重建，有效...|
|📝 更新|TD3Net: A temporal densely connected multi-dilated convolutional network for lipreading|TD3Net：一种基于时间密集连接的多扩张卷积网络用于唇读|Byung Hoon Lee, Wooseok Shin, Sung Won Han|<http://arxiv.org/pdf/2506.16073v3>|[代码](https://github.com/Leebh-kor/TD3Net); 提出了一种结合密集跳跃连接和多尺度膨胀卷积的TD3Net网络，有效提升了唇读的准确性和参数效率。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Advancing 3D Scene Understanding with MV-ScanQA Multi-View Reasoning Evaluation and TripAlign Pre-training Dataset|使用MV-ScanQA多视角推理评估和TripAlign预训练数据集推进三维场景理解|Wentao Mo, Qingchao Chen, Yuxin Peng, Siyuan Huang, Yang Liu|<http://arxiv.org/pdf/2508.11058v1>|[代码](https://matthewdm0816.github.io/tripalign-mvscanqa.); 提出MV-ScanQA多视角推理评估和TripAlign预训练数据集，增强3D场景理解能力。|
|🆕 发布|STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer|STream3R：基于因果变换的可扩展序列三维重建|Yushi Lan, Yihang Luo, Fangzhou Hong, Shangchen Zhou, Honghua Chen, Zhaoyang Lyu, Shuai Yang, Bo Dai .etc.|<http://arxiv.org/pdf/2508.10893v1>|[代码](https://nirvanalan.github.io/projects); STream3R通过将点图预测转化为解码器Transformer问题，实现了高效处理图像序列的3D重...|
|📝 更新|DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction|双姿态-规范点映射（DualPM）：用于三维形状与姿态重建的双重映射方法|Ben Kaye, Tomas Jakab, Shangzhe Wu, Christian Rupprecht, Andrea Vedaldi|<http://arxiv.org/pdf/2412.04464v5>|提出了一种双位置映射方法，通过预测像素与物体三维位置及其标准姿态的对应关系，实现了可变形物体三维形状...|
|📝 更新|DGNS: Deformable Gaussian Splatting and Dynamic Neural Surface for Monocular Dynamic 3D Reconstruction|DGNS：可变形高斯散点投射与动态神经曲面用于单目动态三维重建|Xuesong Li, Jinguang Tong, Jie Hong, Vivien Rolland, Lars Petersson|<http://arxiv.org/pdf/2412.03910v3>|提出DGNS框架，融合可变形高斯散点和动态神经表面技术，实现单目视频动态三维重建与高质量新视角合成。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ESSENTIAL: Episodic and Semantic Memory Integration for Video Class-Incremental Learning|ESSENTIAL：视频类别增量学习中的偶发记忆与语义记忆融合|Jongseo Lee, Kyungho Bae, Kyle Min, Gyeong-Moon Park, Jinwoo Choi|<http://arxiv.org/pdf/2508.10896v1>|提出ESSENTIAL方法，整合稀疏特征和泛化知识，解决视频类增量学习中的记忆效率与性能平衡问题。|
|🆕 发布|Trajectory-aware Shifted State Space Models for Online Video Super-Resolution|轨迹感知的移位状态空间模型用于在线视频超分辨率|Qiang Zhu, Xiandong Meng, Yuxian Jiang, Fan Zhang, David Bull, Shuyuan Zhu, Bing Zeng|<http://arxiv.org/pdf/2508.10453v1>|提出了一种基于轨迹感知的位移状态空间模型，实现了视频超分辨率处理的高效时空信息聚合。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Motion Matters: Motion-guided Modulation Network for Skeleton-based Micro-Action Recognition|运动至关重要：基于运动的调制网络用于基于骨架的微动作识别|Jihao Gu, Kun Li, Fei Wang, Yanyan Wei, Zhiliang Wu, Hehe Fan, Meng Wang|<http://arxiv.org/pdf/2507.21977v3>|[代码](https://github.com/momiji-bit/MMN.); 提出了一种基于运动引导的调节网络，通过捕捉和调制微妙运动线索，提高了基于骨架的微动作识别准确性。|
|🆕 发布|Enhanced Sparse Point Cloud Data Processing for Privacy-aware Human Action Recognition|增强型稀疏点云数据处理用于隐私感知的人体动作识别|Maimunatu Tunau, Vincent Gbouna Zakka, Zhuangzhuang Dai|<http://arxiv.org/pdf/2508.10469v1>|提出了一种针对毫米波雷达数据稀疏性和噪声的改进处理方法，提升了隐私保护的人体动作识别准确性和计算效率...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Reinforcement Learning meets Masked Video Modeling : Trajectory-Guided Adaptive Token Selection|强化学习遇见遮挡视频建模：轨迹引导的自适应标记选择|Ayush K. Rai, Kyle Min, Tarun Krishna, Feiyan Hu, Alan F. Smeaton, Noel E. O'Connor|<http://arxiv.org/pdf/2505.08561v2>|提出了一种自适应轨迹感知的采样器，通过强化学习优化视频遮蔽策略，提升动作识别性能同时保持内存效率。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SOI is the Root of All Evil: Quantifying and Breaking Similar Object Interference in Single Object Tracking|“SOI是万恶之源：量化并打破单目标跟踪中的相似物体干扰”|Yipei Wang, Shiyu Hu, Shukun Jia, Panxi Xu, Hongfei Ma, Yiping Ma, Jing Zhang, Xiaobo Lu .etc.|<http://arxiv.org/pdf/2508.09524v2>|首次量化相似物体干扰问题，并提出使用大规模视觉语言模型提升单目标跟踪性能的新方法。|
|📝 更新|Just Functioning as a Hook for Two-Stage Referring Multi-Object Tracking|仅作为两阶段引用多目标跟踪的钩子函数|Weize Li, Yunhao Du, Qixiang Yin, Zhicheng Zhao, Fei Su, Daqi Liu|<http://arxiv.org/pdf/2503.07516v3>|提出了一种新的两阶段跟踪框架JustHook，通过Hook模块和Parallel Combined ...|
|📝 更新|VPOcc: Exploiting Vanishing Point for 3D Semantic Occupancy Prediction|VPOcc：利用消失点进行三维语义占据预测|Junsu Kim, Junhee Lee, Ukcheol Shin, Jean Oh, Kyungdon Joo|<http://arxiv.org/pdf/2408.03551v2>|[代码](https://vision3d-lab.github.io/vpocc); 利用消失点减少2D-3D视差，VPOcc框架通过像素级图像校正和特征级注意力提升3D语义占用预测准确...|
|🆕 发布|DINOMotion: advanced robust tissue motion tracking with DINOv2 in 2D-Cine MRI-guided radiotherapy|DINOMotion：基于DINOv2的二维 cine MRI引导放射治疗中的高级稳健组织运动跟踪|Soorena Salari, Catherine Spino, Laurie-Anne Pharand, Fabienne Lathuiliere, Hassan Rivaz, Silvain Beriault, Yiming Xiao|<http://arxiv.org/pdf/2508.10260v1>|提出DINOMotion框架，利用DINOv2和LoRA层实现高效、稳健且可解释的二维 cine M...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 掩码自编码 (Masked Autoencoding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data|MAESTRO：用于多模态、多时相、多光谱地球观测数据的掩码自编码器|Antoine Labatie, Michael Vaccaro, Nina Lardiere, Anatol Garioud, Nicolas Gonthier|<http://arxiv.org/pdf/2508.10894v1>|[代码](https://github.com/ignf/maestro.); 提出了一种针对地球观测数据的MAESTRO方法，融合多模态信息并引入光谱先验，提升了对多时态变化的处...|


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Self-Supervised Stereo Matching with Multi-Baseline Contrastive Learning|多基线对比学习的自监督立体匹配|Peng Xu, Zhiyu Xiang, Jingyun Fu, Tianyu Pu, Kai Wang, Chaojie Ji, Tingming Bai, Eryun Liu|<http://arxiv.org/pdf/2508.10838v1>|提出了一种基于多基线对比学习的自监督立体匹配框架，有效解决了遮挡区域匹配问题。|
|📝 更新|CCL-LGS: Contrastive Codebook Learning for 3D Language Gaussian Splatting|对比编码本学习用于三维语言高斯散点绘制的方法|Lei Tian, Xiaomin Li, Liqian Ma, Hao Yin, Zirui Zheng, Hefei Huang, Taiqing Li, Huchuan Lu .etc.|<http://arxiv.org/pdf/2505.20469v2>|[代码](https://epsilontl.github.io/CCL-LGS); 提出了一种对比编码学习方法，通过多视角语义线索实现3D语义理解的一致性，有效解决了视角差异导致的语义...|
|📝 更新|Hierarchical Cross-modal Prompt Learning for Vision-Language Models|层次化跨模态提示学习用于视觉-语言模型|Hao Zheng, Shunzhi Yang, Zhuoxin He, Jinfeng Yang, Zhenhua Huang|<http://arxiv.org/pdf/2507.14976v2>|[代码](https://github.com/zzeoZheng/HiCroPL.); 提出HiCroPL框架，通过双向知识流增强视觉语言模型在下游任务中的泛化能力。|
|🆕 发布|Improving Learning of New Diseases through Knowledge-Enhanced Initialization for Federated Adapter Tuning|通过知识增强初始化改进新疾病学习以实现联邦适配器调谐|Danni Peng, Yuan Wang, Kangning Cai, Peiyan Ning, Jiming Xu, Yong Liu, Rick Siow Mong Goh, Qingsong Wei .etc.|<http://arxiv.org/pdf/2508.10299v1>|提出FedKEI框架，通过跨客户端和跨任务的知识迁移优化初始化，加速新疾病的学习。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AR Surgical Navigation with Surface Tracing: Comparing In-Situ Visualization with Tool-Tracking Guidance for Neurosurgical Applications|基于表面追踪的增强现实手术导航：神经外科应用中就地可视化与工具追踪引导的比较|Marc J. Fischer, Jeffrey Potts, Gabriel Urreola, Dax Jones, Paolo Palmisciano, E. Bradley Strong, Branden Cord, Andrew D. Hernandez .etc.|<http://arxiv.org/pdf/2508.10554v2>|本研究提出了一种利用表面追踪的增强现实手术导航方法，通过实时工具跟踪提高了神经外科手术的精准度和用户...|
|🆕 发布|UWB-PostureGuard: A Privacy-Preserving RF Sensing System for Continuous Ergonomic Sitting Posture Monitoring|"UWB-PostureGuard：一种保护隐私的射频感知系统，用于持续监测符合人体工程学的坐姿"|Haotang Li, Zhenyu Qi, Sen He, Kebin Peng, Sheng Tan, Yili Ren, Tomas Cerny, Jiyue Zhao .etc.|<http://arxiv.org/pdf/2508.11115v1>|提出了一种利用超宽带技术的无接触式坐姿监测系统，实现了高精度且保护隐私的坐姿健康管理。|
|📝 更新|Evaluation of Cultural Competence of Vision-Language Models|计算机视觉模型文化素养评估|Srishti Yadav, Lauren Tilton, Maria Antoniak, Taylor Arnold, Jiaang Li, Siddhesh Milind Pawar, Antonia Karamolegkou, Stella Frank .etc.|<http://arxiv.org/pdf/2505.22793v2>|提出五个文化维度框架，为全面评估视觉语言模型的文化素养提供方法论支持。|
|🆕 发布|FIND-Net -- Fourier-Integrated Network with Dictionary Kernels for Metal Artifact Reduction|FIND-Net -- 基于傅里叶积分与字典核的金属伪影减少网络|Farid Tasharofi, Fuxin Fan, Melika Qahqaie, Mareike Thies, Andreas Maier|<http://arxiv.org/pdf/2508.10617v1>|[代码](https://github.com/Farid-Tasharofi/FIND-Net); 提出FIND-Net，融合频域与空域处理，有效减少金属伪影同时保持结构细节。|
|📝 更新|Speedy-Splat: Fast 3D Gaussian Splatting with Sparse Pixels and Sparse Primitives|快速散点绘制：基于稀疏像素和稀疏基元的快速三维高斯散点绘制|Alex Hanson, Allen Tu, Geng Lin, Vasu Singla, Matthias Zwicker, Tom Goldstein|<http://arxiv.org/pdf/2412.00578v3>|优化3D Gaussian Splatting技术，通过精确定位和新型剪枝提高渲染速度并减小模型大小...|
|🆕 发布|Concepts or Skills? Rethinking Instruction Selection for Multi-modal Models|“概念还是技能？对多模态模型指令选择的再思考”|Andrew Bai, Justin Cui, Ruochen Wang, Cho-Jui Hsieh|<http://arxiv.org/pdf/2508.10339v1>|提出针对多模态模型指令选择的新策略，通过优化训练数据以提升视觉概念与技能学习效果。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Data-Driven Abdominal Phenotypes of Type 2 Diabetes in Lean, Overweight, and Obese Cohorts|基于数据的2型糖尿病在瘦型、超重和肥胖队列中的腹部表型特征|Lucas W. Remedios, Chloe Choe, Trent M. Schwartz, Dingjie Su, Gaurav Rudravaram, Chenyu Gao, Aravind R. Krishnan, Adam M. Saunders .etc.|<http://arxiv.org/pdf/2508.11063v1>|利用AI从临床影像中提取身体组成数据，识别出与2型糖尿病风险相关的一致腹部特征。|
|📝 更新|Robotic Ultrasound-Guided Femoral Artery Reconstruction of Anatomically-Representative Phantoms|机器人超声引导下解剖代表性 phantom 的股动脉重建|Lidia Al-Zogbi, Deepak Raina, Vinciya Pandian, Thorsten Fleiter, Axel Krieger|<http://arxiv.org/pdf/2503.06795v2>|本研究开发了一种自主机器人超声扫描方法，用于精确重建患者特异性的股动脉模型，并通过深度学习网络提升了...|
|🆕 发布|Insights from the Algonauts 2025 Winners|《来自2025年Algonauts竞赛获奖者的洞察》|Paul S. Scotti, Mihir Tripathy|<http://arxiv.org/pdf/2508.10784v1>|利用长段多模态电影，成功预测了观看者的大脑活动，推动了脑编码模型的发展。|
|📝 更新|Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method|个性化特征迁移用于表情识别：一种高效的无源域自适应方法|Masoumeh Sharafi, Soufiane Belharbi, Houssem Ben Salem, Ali Etemad, Alessandro Lameiras Koerich, Marco Pedersoli, Simon Bacon, Eric Granger|<http://arxiv.org/pdf/2508.09202v2>|提出了一种在无源数据情况下，通过在潜在空间进行个性化特征转换来优化表情识别的方法。|
|🆕 发布|EvTurb: Event Camera Guided Turbulence Removal|事件相机引导的湍流去除方法EvTurb|Yixing Liu, Minggui Teng, Yifei Xia, Peiqi Duan, Boxin Shi|<http://arxiv.org/pdf/2508.10582v1>|提出EvTurb框架，利用事件相机分解并消除大气湍流引起的模糊和倾斜，实现高效图像质量提升。|
|📝 更新|Semantic-aware DropSplat: Adaptive Pruning of Redundant Gaussians for 3D Aerial-View Segmentation|语义感知的DropSplat：三维空中视图分割中冗余高斯分布的自适应剪枝|Xu Tang, Junan Jia, Yijing Wang, Jingjing Ma, Xiangrong Zhang|<http://arxiv.org/pdf/2508.09626v2>|提出了一种自适应精简高斯点的3D空中场景分割方法，通过消除冗余和语义模糊点，提高了分割准确性和表示紧...|
|🆕 发布|CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model|《CorrectNav：自校正飞轮赋能视觉-语言-行动导航模型》|Zhuoyuan Yu, Yuxing Long, Zihan Yang, Chengyan Zeng, Hongwei Fan, Jiyao Zhang, Hao Dong|<http://arxiv.org/pdf/2508.10416v1>|提出自修正飞轮策略，通过利用模型错误轨迹生成自修正数据，显著提升视觉语言行动导航模型的准确性和鲁棒性...|
|📝 更新|Data Pruning by Information Maximization|信息最大化驱动的数据剪枝|Haoru Tan, Sitong Wu, Wei Huang, Shizhen Zhao, Xiaojuan Qi|<http://arxiv.org/pdf/2506.01701v2>|[代码](https://github.com/hrtan/InfoMax.); 提出InfoMax数据剪枝方法，通过最大化信息含量和最小化冗余，提升核心样本集的总体信息性。|
|🆕 发布|Glo-DMU: A Deep Morphometry Framework of Ultrastructural Characterization in Glomerular Electron Microscopic Images|全局-DMU：肾小球电子显微镜图像超微结构特征深度形态计量框架|Zhentai Zhang, Danyi Weng, Guibin Zhang, Xiang Chen, Kaixing Long, Jian Geng, Yanmeng Lu, Lei Zhang .etc.|<http://arxiv.org/pdf/2508.10351v1>|提出了一种全自动化、高精度、高通量的肾小球超结构量化框架Glo-DMU，满足临床诊断需求。|
|📝 更新|Warehouse Spatial Question Answering with LLM Agent|基于大型语言模型的仓库空间问答代理|Hsiang-Wei Huang, Jen-Hao Cheng, Kuang-Ming Chen, Cheng-Yen Yang, Bahaa Alattar, Yi-Ru Lin, Pyongkun Kim, Sangwon Kim .etc.|<http://arxiv.org/pdf/2507.10778v2>|[代码](https://github.com/hsiangwei0903/SpatialAgent); 提出了一种高效的数据方法，通过LLM代理系统增强空间推理能力，解决复杂仓库场景中的空间问题回答挑战。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Quantum-Brain: Quantum-Inspired Neural Network Approach to Vision-Brain Understanding|量子-大脑：量子启发神经网络方法在视觉-大脑理解中的应用|Hoang-Quan Nguyen, Xuan-Bac Nguyen, Hugh Churchill, Arabinda Kumar Choudhary, Pawan Sinha, Samee U. Khan, Khoa Luu|<http://arxiv.org/pdf/2411.13378v2>|提出量子-脑方法，利用量子计算原理学习脑信号连通性，提升视觉-脑理解准确度。|
|📝 更新|Tuning-Free Online Robust Principal Component Analysis through Implicit Regularization|无调整参数的在线稳健主成分分析：通过隐式正则化实现|Lakshmi Jayalal, Gokularam Muthukrishnan, Sheetal Kalyani|<http://arxiv.org/pdf/2409.07275v2>|提出了一种无需调参的在线稳健主成分分析方法，通过隐式正则化提升性能并适用于大数据集。|
|📝 更新|Bootstrapping, Autonomous Testing, and Initialization System for Si/SiGe Multi-quantum Dot Devices|硅/硅锗多量子点设备的引导、自主测试与初始化系统|Tyler J. Kovach, Daniel Schug, M. A. Wolfe, E. R. MacQuarrie, Patrick J. Walsh, Owen M. Eskandari, Jared Benson, Mark Friesen .etc.|<http://arxiv.org/pdf/2412.07676v3>|提出了一种自动化的量子点设备校准系统，有效解决了高维电压空间中的设备评估和调校难题。|
|🆕 发布|Multi-Sample Anti-Aliasing and Constrained Optimization for 3D Gaussian Splatting|多样本抗锯齿与约束优化在三维高斯散点绘制中的应用|Zheng Zhou, Jia-Chen Zhang, Yu-Jie Xiong, Chun-Ming Xia|<http://arxiv.org/pdf/2508.10507v1>|整合多采样抗锯齿与双重几何约束优化，显著提升三维高斯绘制中细节保留与实时渲染性能。|
|🆕 发布|From Images to Perception: Emergence of Perceptual Properties by Reconstructing Images|从图像到感知：通过重建图像呈现感知属性的涌现|Pablo Hernández-Cámara, Jesus Malo, Valero Laparra|<http://arxiv.org/pdf/2508.10450v1>|提出了一种生物启发架构PerceptNet，通过图像重构任务学习到与人类视觉感知高度相关的特性。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UI-Venus Technical Report: Building High-performance UI Agents with RFT|《UI-Venus技术报告：利用RFT构建高性能用户界面代理》|Zhangxuan Gu, Zhengwen Zeng, Zhenyu Xu, Xingran Zhou, Shuheng Shen, Yunfei Liu, Beitong Zhou, Changhua Meng .etc.|<http://arxiv.org/pdf/2508.10833v2>|[代码](https://github.com/inclusionAI/UI-Venus.); UI-Venus通过使用少量高质量训练样本和强化微调，实现了UI识别与导航任务的性能突破。|
|📝 更新|Mastering Collaborative Multi-modal Data Selection: A Focus on Informativeness, Uniqueness, and Representativeness|掌握协作多模态数据选择：关注信息性、独特性和代表性|Qifan Yu, Zhebei Shen, Zhongqi Yue, Yang Wu, Bosheng Qin, Wenqiao Zhang, Yunfei Li, Juncheng Li .etc.|<http://arxiv.org/pdf/2412.06293v2>|[代码](https://github.com/Yuqifan1117/DataTailor); 提出DataTailor框架，通过三原则高效筛选数据，实现用15%数据达到全数据训练101.3%的性...|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example|JMA：一种生成几乎最优针对性对抗样本的通用算法|Benedetta Tondi, Wei Guo, Niccolò Pancino, Mauro Barni|<http://arxiv.org/pdf/2401.01199v2>|提出了一种更通用、理论扎实的生成针对性对抗样本的算法JMA，通过最小化雅可比诱导的马氏距离，有效应对...|
|📝 更新|Iterative Volume Fusion for Asymmetric Stereo Matching|迭代体积融合用于非对称立体匹配|Yuanting Gao, Linghao Shen|<http://arxiv.org/pdf/2508.09543v2>|提出迭代体积融合网络解决非对称立体匹配问题，有效融合两种成本体积信息，提升匹配精度。|
|📝 更新|Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability|语义结构感知的生成攻击以提高对抗性迁移性|Jongoh Jeong, Hunmin Yang, Jaeseok Jeong, Kuk-Jin Yoon|<http://arxiv.org/pdf/2506.18248v4>|提出了一种语义结构感知的生成攻击框架，通过利用生成模型中的语义信息，有效提升了对抗性扰动在黑盒模型间...|


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Pixel to Mask: A Survey of Out-of-Distribution Segmentation|从像素到掩模：异常分布下的分割研究综述|Wenjie Zhao, Jia Li, Yunhui Guo|<http://arxiv.org/pdf/2508.10309v1>|系统综述了应对AI安全问题的异常目标像素级定位技术，助力自动驾驶安全性提升。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mobile-Friendly Deep Learning for Plant Disease Detection: A Lightweight CNN Benchmark Across 101 Classes of 33 Crops|移动端友好的植物病害检测深度学习：基于101类33种作物的轻量级卷积神经网络基准|Anand Kumar, Harminder Pal Monga, Tapasi Brahma, Satyam Kalra, Navas Sherif|<http://arxiv.org/pdf/2508.10817v1>|提出了一种适用于移动设备的轻量级深度学习模型，准确检测101种植物病害，实现高效分类。|
|🆕 发布|Forgery Guided Learning Strategy with Dual Perception Network for Deepfake Cross-domain Detection|伪造引导的学习策略与双感知网络用于深度伪造跨域检测|Lixin Jia, Zhiqing Guo, Gaobo Yang, Liejun Wang, Keqin Li|<http://arxiv.org/pdf/2508.10741v1>|[代码](https://github.com/vpsg-research/FGL.); 提出了一种 Forgery Guided Learning 策略和 Dual Perception ...|
|📝 更新|Unifying Self-Supervised Clustering and Energy-Based Models|统一自监督聚类与基于能量的模型|Emanuele Sansone, Robin Manhaeve|<http://arxiv.org/pdf/2401.00873v5>|[代码](https://github.com/emsansone/GEDI.); 提出了一种统一自监督聚类和基于能量的模型的方法，实现了在聚类、生成和异常检测上的性能显著提升。|
|🆕 发布|STAMP: Multi-pattern Attention-aware Multiple Instance Learning for STAS Diagnosis in Multi-center Histopathology Images|STAMP：多模式注意力感知的多实例学习用于多中心病理图像中的STAS诊断|Liangrui Pan, xiaoyu Li, Guang Zhu, Guanting Li, Ruixin Wang, Jiadi Luo, Yaning Yang, Liang qingchun .etc.|<http://arxiv.org/pdf/2508.10473v1>|提出了一种多模式注意力感知的多实例学习方法STAMP，用于跨中心病理图像中的STAS诊断，提高了诊断...|
|🆕 发布|SingleStrip: learning skull-stripping from a single labeled example|单样本学习：从单个标记样本学习颅骨剥离|Bella Specktor-Fadida, Malte Hoffmann|<http://arxiv.org/pdf/2508.10464v1>|利用单个标注样本，结合领域随机化和自训练，实现了高效的三维脑部去颅骨分割。|
|📝 更新|Common Data Properties Limit Object-Attribute Binding in CLIP|"常见数据属性限制了CLIP中的对象-属性绑定"|Bijay Gurung, David T. Hoffmann, Thomas Brox|<http://arxiv.org/pdf/2507.07985v2>|揭示了常见数据属性限制CLIP模型学习对象属性绑定的问题，并指出仅当数据表现出特定属性时CLIP才能...|
|🆕 发布|InterSyn: Interleaved Learning for Dynamic Motion Synthesis in the Wild|交错学习：野外动态运动合成的实现|Yiyi Ma, Yuanzhi Liang, Xiu Li, Chi Zhang, Xuelong Li|<http://arxiv.org/pdf/2508.10297v1>|提出了一种交织学习框架InterSyn，通过整合单人及多人动态生成真实互动动作，提升了运动合成的自然...|
|🆕 发布|Deep Learning for Crack Detection: A Review of Learning Paradigms, Generalizability, and Datasets|深度学习在裂缝检测中的应用：学习范式、泛化能力与数据集综述|Xinan Zhang, Haolin Wang, Yung-An Hsieh, Zhongyu Yang, Anthony Yezzi, Yi-Chang Tsai|<http://arxiv.org/pdf/2508.10256v1>|[代码](https://github.com/nantonzhang/Awesome-Crack-Detection); 系统综述了深度学习在裂缝检测中的应用趋势，并引入了新的3D数据集以促进研究。|
|📝 更新|Continual Learning for Multiple Modalities|多模态的持续学习|Hyundong Jin, Eunwoo Kim|<http://arxiv.org/pdf/2503.08064v2>|提出了一种多模态连续学习框架，通过调节内部模态知识和整合相关跨模态信息，有效缓解了知识遗忘和模态间干...|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Improved GUI Grounding via Iterative Narrowing|通过迭代缩窄改进的GUI定位方法|Anthony Nguyen|<http://arxiv.org/pdf/2411.13591v6>|提出了一种迭代缩小区间的视觉提示框架，有效提升了视觉语言模型在GUI定位任务中的表现。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|JRDB-Reasoning: A Difficulty-Graded Benchmark for Visual Reasoning in Robotics|JRDB-推理：一个用于机器人视觉推理的难度分级基准|Simindokht Jahangard, Mehrzad Mohammadi, Yi Shen, Zhixi Cai, Hamid Rezatofighi|<http://arxiv.org/pdf/2508.10287v2>|提出了一种分级难度的视觉推理基准JRDB-Reasoning，通过自适应查询引擎生成不同难度的问题并...|
|🆕 发布|Are Large Pre-trained Vision Language Models Effective Construction Safety Inspectors?|大型预训练视觉语言模型在建筑安全检查中的有效性如何？|Xuezheng Chen, Zhengbo Zou|<http://arxiv.org/pdf/2508.11011v1>|提出 ConstructionSite 10k 数据集，验证了大型预训练视觉语言模型在建筑安全检查中...|
|🆕 发布|Quantum Visual Fields with Neural Amplitude Encoding|量子视觉场与神经幅度编码|Shuteng Wang, Christian Theobalt, Vladislav Golyanik|<http://arxiv.org/pdf/2508.10900v1>|引入量子视觉场（QVF），通过神经幅度编码实现高效稳定的2D图像和3D几何场学习。|
|🆕 发布|Performance of GPT-5 in Brain Tumor MRI Reasoning|GPT-5在脑肿瘤MRI推理中的性能表现|Mojtaba Safari, Shansong Wang, Mingzhe Hu, Zach Eidex, Qiang Li, Xiaofeng Yang|<http://arxiv.org/pdf/2508.10865v1>|评估GPT-5家族模型在脑肿瘤MRI视觉问答中的表现，发现GPT-5-mini准确度最高但未达临床使...|
|🆕 发布|Not There Yet: Evaluating Vision Language Models in Simulating the Visual Perception of People with Low Vision|尚未达到：评估视觉语言模型在模拟低视力人群视觉感知方面的表现|Rosiana Natalie, Wenqian Xu, Ruei-Che Chang, Rada Mihalcea, Anhong Guo|<http://arxiv.org/pdf/2508.10972v1>|评估了视觉语言模型模拟低视力人群视觉感知的能力，并构建了专用数据集以提高模型准确性。|
|🆕 发布|Serial Over Parallel: Learning Continual Unification for Multi-Modal Visual Object Tracking and Benchmarking|串行胜过并行：学习多模态视觉目标跟踪的持续统一方法及基准测试|Zhangyong Tang, Tianyang Xu, Xuefeng Zhu, Chunyang Cheng, Tao Zhou, Xiaojun Wu, Josef Kittler|<http://arxiv.org/pdf/2508.10655v1>|[代码](https://github.com/Zhangyong-Tang/UniBench300); 提出统一基准UniBench300并采用连续学习策略，有效解决了多模态视觉跟踪任务训练与测试不一致问...|
|🆕 发布|Processing and acquisition traces in visual encoders: What does CLIP know about your camera?|视觉编码器中的处理与获取轨迹：CLIP对你的相机了解多少？|Ryan Ramos, Vladan Stojnić, Giorgos Kordopatis-Zilos, Yuta Nakashima, Giorgos Tolias, Noa Garcia|<http://arxiv.org/pdf/2508.10637v1>|[代码](https://github.com/ryan-caesar-ramos/visual-encoder-traces); 揭示了视觉编码器如何编码图像获取和处理痕迹，影响语义预测的准确性。|
|📝 更新|NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning|NAVER：一种具有显式逻辑推理的神经符号组合自动机，用于视觉定位|Zhixi Cai, Fucai Ke, Simindokht Jahangard, Maria Garcia de la Banda, Reza Haffari, Peter J. Stuckey, Hamid Rezatofighi|<http://arxiv.org/pdf/2502.00372v3>|[代码](https://github.com/ControlNet/NAVER); 提出了一种结合显式概率逻辑推理的视觉定位方法NAVER，提升了复杂推理任务中的鲁棒性和可解释性。|
|🆕 发布|ORBIT: An Object Property Reasoning Benchmark for Visual Inference Tasks|ORBIT：面向视觉推理任务的对象属性推理基准|Abhishek Kolari, Mohammadhossein Khojasteh, Yifan Jiang, Floris den Hengst, Filip Ilievski|<http://arxiv.org/pdf/2508.10956v1>|提出ORBIT多级推理VQA基准，评估视觉模型对物体属性的理解和推理能力。|
|📝 更新|Exploring the Application of Visual Question Answering (VQA) for Classroom Activity Monitoring|探索视觉问答（VQA）在课堂活动监控中的应用|Sinh Trong Vu, Hieu Trung Pham, Dung Manh Nguyen, Hieu Minh Hoang, Nhu Hoang Le, Thu Ha Pham, Tai Tan Mai|<http://arxiv.org/pdf/2507.22369v2>|探究视觉问答模型在课堂行为分析中的应用，并创建BAV-Classroom-VQA数据集进行性能评估。|
|🆕 发布|We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning|We-Math 2.0：一种激励视觉数学推理的通用数学书籍系统|Runqi Qiao, Qiuna Tan, Peiqing Yang, Yanzi Wang, Xiaowan Wang, Enhui Wan, Sitong Zhou, Guanting Dong .etc.|<http://arxiv.org/pdf/2508.10433v1>|提出了一种整合结构化数学知识系统、模型中心数据空间建模和强化学习训练范式的系统，显著增强了大规模语言...|
|📝 更新|Visual SLAMMOT Considering Multiple Motion Models|考虑多运动模型的视觉SLAMMOT|Peilin Tian, Hao Li|<http://arxiv.org/pdf/2411.19134v2>|提出了一种融合多个运动模型的视觉SLAMMOT方法，有效解决了动态环境下同时定位与建图和目标跟踪的挑...|
|📝 更新|WeatherPrompt: Multi-modality Representation Learning for All-Weather Drone Visual Geo-Localization|《WeatherPrompt：全天候无人机视觉地理定位的多模态表征学习》|Jiahao Wen, Hang Yu, Zhedong Zheng|<http://arxiv.org/pdf/2508.09560v2>|提出WeatherPrompt方法，通过多模态学习融合图像与文本，实现全天气条件下的无人机视觉地理定...|
|🆕 发布|BERT-VQA: Visual Question Answering on Plots|BERT-VQA：基于情节的视觉问答|Tai Vu, Robert Yang|<http://arxiv.org/pdf/2508.13184v1>|提出BERT-VQA模型，结合预训练视觉和语言编码器，挑战图表视觉问答任务，发现跨模态交互并非必要。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Object Fidelity Diffusion for Remote Sensing Image Generation|遥感图像生成的目标保真度扩散|Ziqi Ye, Shuran Ma, Jie Yang, Xiaoyi Yang, Ziyang Gong, Xue Yang, Haipeng Wang|<http://arxiv.org/pdf/2508.10801v2>|提出Object Fidelity Diffusion方法，通过提取对象先验形状和双分支扩散模型，提...|
|🆕 发布|GCRPNet: Graph-Enhanced Contextual and Regional Perception Network For Salient Object Detection in Optical Remote Sensing Images|GCRPNet：图增强的上下文与区域感知网络用于光学遥感图像中的显著目标检测|Mengyu Ren, Yutong Li, Hua Li, Runmin Cong, Sam Kwong|<http://arxiv.org/pdf/2508.10542v1>|提出了一种图增强的感知网络GCRPNet，有效整合全局与局部特征，提升光学遥感图像中的显著目标检测性...|
|🆕 发布|Adapting SAM via Cross-Entropy Masking for Class Imbalance in Remote Sensing Change Detection|通过交叉熵掩码调整 SAM 以应对遥感变化检测中的类别不平衡问题|Humza Naveed, Xina Zeng, Mitch Bryson, Nagita Mehrseresht|<http://arxiv.org/pdf/2508.10568v1>|[代码](https://github.com/humza909/SAM-CEM-CD); 通过改进SAM模型并引入交叉熵掩码损失函数，有效解决了遥感变化检测中的类别不平衡问题。|
|🆕 发布|A Sub-Pixel Multimodal Optical Remote Sensing Images Matching Method|亚像素多模态光学遥感图像匹配方法|Tao Huang, Hongbo Pan, Nanxi Zhou, Shun Zhou|<http://arxiv.org/pdf/2508.10294v1>|[代码](https://github.com/huangtaocsu/PCWLAD.); 提出了一种基于相位一致性加权最小绝对偏差的亚像素匹配方法，有效提升了多模态光学遥感图像的匹配精度。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Deep Learning-Based Automated Segmentation of Uterine Myomas|基于深度学习的子宫肌瘤自动分割方法|Tausifa Jan Saleem, Mohammad Yaqub|<http://arxiv.org/pdf/2508.11010v1>|利用公开数据集，提出了一种基于深度学习的自动化子宫肌瘤分割方法，提高了诊断效率和准确性。|
|🆕 发布|MedSAMix: A Training-Free Model Merging Approach for Medical Image Segmentation|MedSAMix：一种无需训练的医学图像分割模型融合方法|Yanwu Yang, Guinan Su, Jiesi Hu, Francesco Sammarco, Jonas Geiping, Thomas Wolfers|<http://arxiv.org/pdf/2508.11032v1>|提出了一种无需训练的模型融合方法MedSAMix，有效整合通用模型与专业模型优势，提升医学图像分割性...|
|🆕 发布|Medico 2025: Visual Question Answering for Gastrointestinal Imaging|Medico 2025：胃肠成像的视觉问答|Sushant Gautam, Vajira Thambawita, Michael Riegler, Pål Halvorsen, Steven Hicks|<http://arxiv.org/pdf/2508.10869v1>|[代码](https://github.com/simula/MediaEval-Medico-2025); 提出Medico 2025挑战，通过 Explainable AI 模型对胃肠道成像进行视觉问答并生...|
|📝 更新|UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving|"UniOcc：一种用于自动驾驶中占用预测与预报的统一基准"|Yuping Wang, Xiangyu Huang, Xiaokang Sun, Mingxuan Yan, Shuo Xing, Zhengzhong Tu, Jiachen Li|<http://arxiv.org/pdf/2503.24381v2>|[代码](https://uniocc.github.io/.); 提出了UniOcc，一个统一基准和工具包，整合多源数据，提升自动驾驶中的占用预测准确性和性能。|
|🆕 发布|An Efficient Model-Driven Groupwise Approach for Atlas Construction|一种高效模型驱动的全局方法用于图谱构建|Ziwei Zou, Bei Zou, Xiaoyan Kui, Wenqi Lu, Haoran Dou, Arezoo Zakeri, Timothy Cootes, Alejandro F Frangi .etc.|<http://arxiv.org/pdf/2508.10743v1>|提出了一种高效的模型驱动群组方法DARC，用于构建具有高解剖保真度的 atlas，无需大量训练数据且...|
|🆕 发布|Revisiting Cross-View Localization from Image Matching|重新审视基于图像匹配的跨视角定位|Panwang Xia, Qiong Wu, Lei Yu, Yi Liu, Mingtao Xiong, Lei Liang, Yongjun Zhang, Yi Wan|<http://arxiv.org/pdf/2508.10716v1>|提出了一种新的跨视角图像匹配框架，通过表面模型和SimRefiner模块显著提升了定位准确性和匹配质...|
|🆕 发布|CSNR and JMIM Based Spectral Band Selection for Reducing Metamerism in Urban Driving|基于CSNR和JMIM的谱带选择方法用于减少城市驾驶中的同色异谱现象|Jiarong Li, Imad Ali Shah, Diarmaid Geever, Fiachra Collins, Enda Ward, Martin Glavin, Edward Jones, Brian Deegan|<http://arxiv.org/pdf/2508.10962v1>|提出了一种基于信息理论和图像质量度量的光谱波段选择策略，有效降低城市驾驶中的同色异谱现象，提升道路用...|
|📝 更新|INSIGHT: Explainable Weakly-Supervised Medical Image Analysis|“洞察：可解释的弱监督医学图像分析”|Wenbo Zhang, Junyu Chen, Christopher Kanan|<http://arxiv.org/pdf/2412.02012v3>|[代码](https://zhangdylan83.github.io/ewsmia); 提出了一种集成 heatmap 生成作为内置偏置的弱监督聚合器 INSIGHT，有效定位医学图像中的...|
|🆕 发布|Towards Powerful and Practical Patch Attacks for 2D Object Detection in Autonomous Driving|面向自动驾驶中二维目标检测的高效实用补丁攻击方法研究|Yuxin Cao, Yedi Zhang, Wentao He, Yifan Liao, Yan Xiao, Chang Li, Zhiyong Huang, Jin Song Dong|<http://arxiv.org/pdf/2508.10600v1>|提出P$^3$A框架，通过新指标和优化策略提升自动驾驶中2D对象检测的攻击效果和转移性。|
|🆕 发布|Med-GLIP: Advancing Medical Language-Image Pre-training with Large-scale Grounded Dataset|医-GLIP：利用大规模实例化数据集推进医学语言-图像预训练|Ziye Deng, Ruihan He, Jiaxiang Liu, Yuan Wang, Zijie Meng, Songtao Jiang, Yong Xie, Zuozhu Liu|<http://arxiv.org/pdf/2508.10528v1>|提出大规模医疗图像标注数据集Med-GLIP-5M，并设计相应框架提升多模态医疗图像理解。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|IAD-R1: Reinforcing Consistent Reasoning in Industrial Anomaly Detection|工业异常检测中强化一致性推理的IAD-R1方法|Yanhui Li, Yunkang Cao, Chengliang Liu, Yuan Xiong, Xinghui Dong, Chao Huang|<http://arxiv.org/pdf/2508.09178v2>|[代码](https://github.com/Yanhui-Lee/IAD-R1.); 提出IAD-R1框架，通过双阶段训练增强视觉语言模型在工业异常检测中的泛化能力。|
|🆕 发布|Reasoning in Computer Vision: Taxonomy, Models, Tasks, and Methodologies|计算机视觉中的推理：分类、模型、任务与方法论|Ayushman Sarkar, Mohd Yamani Idna Idris, Zhenyu Yu|<http://arxiv.org/pdf/2508.10523v1>|系统分类视觉推理类型并分析评价方法，为构建透明可信的AI系统提供研究方向。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SpaRC-AD: A Baseline for Radar-Camera Fusion in End-to-End Autonomous Driving|SpaRC-AD：端到端自动驾驶中雷达-相机融合的基线|Philipp Wolters, Johannes Gilg, Torben Teepe, Gerhard Rigoll|<http://arxiv.org/pdf/2508.10567v1>|[代码](https://phi-wol.github.io/sparcad); 提出SpaRC-AD框架，融合雷达与摄像头数据，提升自动驾驶系统在复杂环境下的感知与规划性能。|
|🆕 发布|PQ-DAF: Pose-driven Quality-controlled Data Augmentation for Data-scarce Driver Distraction Detection|PQ-DAF：基于姿态驱动的质量控制数据增强方法用于数据稀缺的驾驶员分心检测|Haibin Sun, Xinghui Song|<http://arxiv.org/pdf/2508.10397v1>|提出了一种基于姿态驱动和数据质量控制的增强训练数据方法，有效提升了少量样本下驾驶员分心检测的性能和泛...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Neurosymbolic Framework for Interpretable Cognitive Attack Detection in Augmented Reality|神经符号框架用于增强现实中的可解释认知攻击检测|Rongqian Chen, Allison Andreyev, Yanming Xiu, Mahdi Imani, Bin Li, Maria Gorlatova, Gang Tan, Tian Lan|<http://arxiv.org/pdf/2508.09185v2>|提出了一种神经符号框架CADAR，融合视觉与语言信息进行认知攻击检测，提高了准确性和可解释性。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View Stereo|GC-MVSNet：多视角、多尺度、几何一致的多视角立体匹配网络|Vibhas K. Vats, Sripad Joshi, David J. Crandall, Md. Alimoor Reza, Soon-heung Jung|<http://arxiv.org/pdf/2310.19583v4>|引入几何一致性损失，GC-MVSNet在多尺度多视角下提升多视图立体匹配精度与学习效率。|
|🆕 发布|Agentic Design Review System|代理性设计审查系统|Sayan Nag, K J Joseph, Koustava Goswami, Vlad I Morariu, Balaji Vasan Srinivasan|<http://arxiv.org/pdf/2508.10745v1>|提出了一种多代理协作的图形设计评估系统，通过图匹配和提示扩展实现高效设计评价与反馈。|
|🆕 发布|On Spectral Properties of Gradient-based Explanation Methods|基于梯度的解释方法的谱特性研究|Amir Mehrpanah, Erik Englesson, Hossein Azizpour|<http://arxiv.org/pdf/2508.10595v1>|揭示了梯度解释方法中的普遍性频谱偏差，并提出基于概率和频谱视角的改进措施。|
|📝 更新|OrderChain: Towards General Instruct-Tuning for Stimulating the Ordinal Understanding Ability of MLLM|《OrderChain：面向通用指令微调以激发大规模语言模型序数理解能力》|Jinhong Wang, Shuo Tong, Jian liu, Dongqi Tang, Weiqiang Wang, Wentong Li, Hongxia Xu, Danny Chen .etc.|<http://arxiv.org/pdf/2504.04801v3>|[代码](https://order-chain.github.io/.); 提出OrderChain方法，增强多模态大语言模型对序数回归任务的理解能力。|
|🆕 发布|On the Complexity-Faithfulness Trade-off of Gradient-Based Explanations|关于基于梯度的解释中的复杂度-保真度权衡|Amir Mehrpanah, Matteo Gamba, Kevin Smith, Hossein Azizpour|<http://arxiv.org/pdf/2508.10490v1>|提出统一谱框架分析梯度解释的平滑度与忠实度权衡，减少了ReLU网络解释的噪声。|
|📝 更新|Seeing and Seeing Through the Glass: Real and Synthetic Data for Multi-Layer Depth Estimation|《透过玻璃看与看见：多层深度估计的真实与合成数据》|Hongyu Wen, Yiming Zuo, Venkat Subramanian, Patrick Chen, Jia Deng|<http://arxiv.org/pdf/2503.11633v2>|提出LayeredDepth数据集，包含多层级深度标注，助力透明物体深度估计任务。|
|📝 更新|A Linear N-Point Solver for Structure and Motion from Asynchronous Tracks|异步轨迹下的线性N点解算器用于结构和运动估计|Hang Su, Yunlong Feng, Daniel Gehrig, Panfeng Jiang, Ling Gao, Xavier Lagorce, Laurent Kneip|<http://arxiv.org/pdf/2507.22733v2>|[代码](https://github.com/suhang99/AsyncTrack-Motion-Solver.); 提出了一种适用于异步时间戳点对应关系的线性求解器，实现了从任意视图的二维点对应关系中高效估计结构和连...|

