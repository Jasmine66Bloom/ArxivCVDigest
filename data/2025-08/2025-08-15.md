## [UPDATED!] **2025-08-15** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visual Perception Engine: Fast and Flexible Multi-Head Inference for Robotic Vision Tasks|视觉感知引擎：面向机器人视觉任务的快速灵活多头部推理|Jakub Łucki, Jonathan Becktor, Georgios Georgakis, Rob Royce, Shehryar Khattak|<http://arxiv.org/pdf/2508.11584v2>|提出了一种模块化视觉感知引擎，通过共享基础模型减少计算冗余，实现机器人视觉任务的快速并行处理。|
|📝 更新|STORM: Token-Efficient Long Video Understanding for Multimodal LLMs|STORM：面向多模态大语言模型的低Token消耗长视频理解|Jindong Jiang, Xiuyu Li, Zhijian Liu, Muyang Li, Guo Chen, Zhiqi Li, De-An Huang, Guilin Liu .etc.|<http://arxiv.org/pdf/2503.04130v2>|STORM通过引入专用的时空编码器，有效整合视频帧间动态信息，提升长视频理解能力并降低计算成本。|
|📝 更新|Mammo-SAE: Interpreting Breast Cancer Concept Learning with Sparse Autoencoders|《Mammo-SAE：使用稀疏自动编码器解释乳腺癌概念学习》|Krishna Kanth Nakka|<http://arxiv.org/pdf/2507.15227v2>|[代码](https://krishnakanthnakka.github.io/MammoSAE); 引入稀疏自动编码器解释性方法，揭示乳腺影像模型如何学习关键病变特征。|
|🆕 发布|Scalable Geospatial Data Generation Using AlphaEarth Foundations Model|使用AlphaEarth基础模型进行可扩展地理空间数据生成|Luc Houriez, Sebastian Pilarski, Behzad Vahedi, Ali Ahmadalipour, Teo Honda Scully, Nicholas Aflitto, David Andre, Caroline Jaffe .etc.|<http://arxiv.org/pdf/2508.11739v1>|利用AlphaEarth Foundations模型扩展地理空间数据集，实现全球范围的数据增强。|
|🆕 发布|TrajSV: A Trajectory-based Model for Sports Video Representations and Applications|轨迹基础模型：用于运动视频表征与应用|Zheng Wang, Shihao Xu, Wei Shi|<http://arxiv.org/pdf/2508.11569v1>|提出了一种基于轨迹的体育视频表示框架TrajSV，通过数据预处理、轨迹增强的Transformer模...|
|📝 更新|GLM-4.5V and GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning|GLM-4.5V与GLM-4.1V-思考：迈向具有可扩展强化学习的多模态推理通用性|GLM-V Team, :, Wenyi Hong, Wenmeng Yu, Xiaotao Gu, Guo Wang, Guobing Gan, Haomiao Tang .etc.|<http://arxiv.org/pdf/2507.01006v5>|[代码](https://github.com/zai-org/GLM-V.); 提出GLM-4系列模型，通过大规模预训练和强化学习提升多模态理解和推理能力。|
|🆕 发布|MM-R1: Unleashing the Power of Unified Multimodal Large Language Models for Personalized Image Generation|MM-R1：释放统一多模态大型语言模型在个性化图像生成中的力量|Qian Liang, Yujia Wu, Kuncheng Li, Jiwei Wei, Shiyuan He, Jinyu Guo, Ning Xie|<http://arxiv.org/pdf/2508.11433v1>|引入MM-R1框架，通过跨模态推理策略提升统一多模大语言模型在个性化图像生成中的性能。|
|📝 更新|MCA-Bench: A Multimodal Benchmark for Evaluating CAPTCHA Robustness Against VLM-based Attacks|MCA-Bench：一种用于评估基于VLM攻击的验证码鲁棒性的多模态基准|Zonglin Wu, Yule Xue, Yaoyao Feng, Xiaolong Wang, Yiren Song|<http://arxiv.org/pdf/2506.05982v4>|提出首个多模态验证码安全性评估基准MCA-Bench，统一评估各类验证码对抗基于视觉语言模型的攻击的...|
|🆕 发布|HOID-R1: Reinforcement Learning for Open-World Human-Object Interaction Detection Reasoning with Multimodal Large Language Model|HOID-R1：基于多模态大型语言模型的开放世界人-物交互检测推理的强化学习|Zhenhao Zhang, Hanqing Wang, Xiangyu Zeng, Ziyu Cheng, Jiaxin Liu, Haoyu Yan, Zhirui Liu, Kaiyang Ji .etc.|<http://arxiv.org/pdf/2508.11350v1>|提出首个结合强化学习和多模态大语言模型的HOI检测框架，提升开放世界场景下的泛化能力。|
|🆕 发布|Probing the Representational Power of Sparse Autoencoders in Vision Models|探究稀疏自动编码器在视觉模型中的表征能力|Matthew Lyle Olson, Musashi Hinck, Neale Ratzlaff, Changbai Li, Phillip Howard, Vasudev Lal, Shao-Yen Tseng|<http://arxiv.org/pdf/2508.11277v1>|探究稀疏自编码器在视觉模型中的表征能力，提升了解释性、泛化能力和控制性。|
|🆕 发布|Generalized Decoupled Learning for Enhancing Open-Vocabulary Dense Perception|广义解耦学习以增强开放词汇密集感知|Junjie Wang, Keyu Chen, Yulin Li, Bin Chen, Hengshuang Zhao, Xiaojuan Qi, Zhuotao Tian|<http://arxiv.org/pdf/2508.11256v1>|[代码](https://github.com/xiaomoguhz/DeCLIP); 提出了一种增强CLIP模型的方法DeCLIP，通过分离内容和上下文特征，提升开放词汇密集视觉感知任务...|
|📝 更新|Efficient High-Resolution Visual Representation Learning with State Space Model for Human Pose Estimation|高效高分辨率视觉表征学习：基于状态空间模型的人体姿态估计|Hao Zhang, Yongqiang Ma, Wenqi Shao, Ping Luo, Nanning Zheng, Kaipeng Zhang|<http://arxiv.org/pdf/2410.03174v2>|[代码](https://github.com/zhanghao5201/PoseVMamba.); 提出了一种结合多尺度卷积的动态视觉状态空间模型，有效提升了高分辨率视觉表示学习的效率和精度。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Recent Advances in Transformer and Large Language Models for UAV Applications|Transformer与大型语言模型在无人机应用中的最新进展|Hamza Kheddar, Yassine Habchi, Mohamed Chahine Ghanem, Mustapha Hemis, Dusit Niyato|<http://arxiv.org/pdf/2508.11834v1>|系统梳理了Transformer架构在无人机领域的应用，提出了统一的分类法并分析了性能表现。|
|🆕 发布|Ovis2.5 Technical Report|《Ovis2.5技术报告》|Shiyin Lu, Yang Li, Yu Xia, Yuwei Hu, Shanshan Zhao, Yanqing Ma, Zhichao Wei, Yinglun Li .etc.|<http://arxiv.org/pdf/2508.11737v1>|Ovis2.5通过原生分辨率视觉感知和多模态推理，实现了复杂图表的高效分析和推理能力提升。|
|📝 更新|LVFace: Progressive Cluster Optimization for Large Vision Models in Face Recognition|LVFace：面向人脸识别中大规模视觉模型的渐进式聚类优化|Jinghan You, Shanglin Li, Yuanrui Sun, Jiangchuan Wei, Mingyu Guo, Chao Feng, Jiao Ran|<http://arxiv.org/pdf/2501.13420v3>|[代码](https://github.com/bytedance/LVFace.); 提出LVFace模型，通过渐进式聚类优化提升视觉Transformer在人脸识别中的性能和稳定性。|
|📝 更新|TokLIP: Marry Visual Tokens to CLIP for Multimodal Comprehension and Generation|《TokLIP：将视觉标记与CLIP结合进行多模态理解和生成》|Haokun Lin, Teng Wang, Yixiao Ge, Yuying Ge, Zhichao Lu, Ying Wei, Qingfu Zhang, Zhenan Sun .etc.|<http://arxiv.org/pdf/2505.05422v2>|[代码](https://github.com/TencentARC/TokLIP.); 提出TokLIP方法，通过结合视觉编码与CLIP语义，提升多模态理解和生成效率。|
|📝 更新|Learning an Adaptive and View-Invariant Vision Transformer for Real-Time UAV Tracking|学习自适应且视点不变的计算视觉变换器以实现实时无人机跟踪|You Wu, Yongxin Li, Mengyuan Liu, Xucheng Wang, Xiangyang Yang, Hengzhou Ye, Dan Zeng, Qijun Zhao .etc.|<http://arxiv.org/pdf/2412.20002v3>|[代码](https://github.com/wuyou3474/AVTrack.); 提出AVTrack框架，通过自适应激活Transformer块和视角不变性学习，实现实时无人机视觉跟...|
|🆕 发布|HistoViT: Vision Transformer for Accurate and Scalable Histopathological Cancer Diagnosis|"HistoViT：用于精确和可扩展的病理学癌症诊断的视觉Transformer"|Faisal Ahmed|<http://arxiv.org/pdf/2508.11181v1>|提出了一种基于Vision Transformer的框架，实现了对多种癌症类型的高精度病理图像分类。|
|🆕 发布|VFM-Guided Semi-Supervised Detection Transformer for Source-Free Object Detection in Remote Sensing Images|基于VFM引导的半监督检测变换器用于无源遥感图像目标检测|Jianhong Han, Yupei Wang, Liang Chen|<http://arxiv.org/pdf/2508.11167v1>|提出了一种半监督检测变压器，利用视觉基础模型提高无源域目标检测的准确性和鲁棒性。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GeoSAM: Fine-tuning SAM with Multi-Modal Prompts for Mobility Infrastructure Segmentation|GeoSAM：使用多模态提示微调SAM进行移动基础设施分割|Rafi Ibn Sultan, Chengyin Li, Hui Zhu, Prashant Khanduri, Marco Brocanelli, Dongxiao Zhu|<http://arxiv.org/pdf/2311.11319v4>|[代码](https://github.com/rafiibnsultan/GeoSAM.); 提出GeoSAM框架，通过多模态提示微调SAM模型，有效提升地理图像中交通基础设施的分割性能。|
|🆕 发布|Artificial Intelligence in Rural Healthcare Delivery: Bridging Gaps and Enhancing Equity through Innovation|人工智能在农村医疗服务中的应用：通过创新弥合差距并提升公平性|Kiruthika Balakrishnan, Durgadevi Velusamy, Hana E. Hinkle, Zhi Li, Karthikeyan Ramasamy, Hikmat Khan, Srini Ramaswamy, Pir Masoom Shah|<http://arxiv.org/pdf/2508.11738v1>|探究人工智能在改善农村医疗服务中的潜力，提出利用先进模型增强决策与接入。|
|🆕 发布|Leveraging the RETFound foundation model for optic disc segmentation in retinal images|利用RETFound基础模型进行视网膜图像视盘分割|Zhenyi Zhao, Muthu Rama Krishnan Mookiah, Emanuele Trucco|<http://arxiv.org/pdf/2508.11354v1>|首次将RETFound基础模型适配用于视盘分割，实现了仅需少量任务特定样本训练的高性能分割效果。|
|🆕 发布|Semantically Guided Adversarial Testing of Vision Models Using Language Models|基于语言模型指导的视觉模型语义对抗性测试|Katarzyna Filus, Jorge M. Cruz-Duarte|<http://arxiv.org/pdf/2508.11341v1>|提出了一种基于语言模型指导的对抗性测试框架，有效提升了视觉模型攻击目标的选取准确性和灵活性。|
|🆕 发布|UniDCF: A Foundation Model for Comprehensive Dentocraniofacial Hard Tissue Reconstruction|统一牙颅面硬组织重建基础模型：UniDCF|Chunxia Ren, Ning Zhu, Yue Lai, Gui Chen, Ruijie Wang, Yangyi Hu, Suyao Liu, Shuwen Mao .etc.|<http://arxiv.org/pdf/2508.11728v1>|UniDCF通过多模态融合编码实现了牙颅面硬组织的全面重建，大幅提升精确度和临床效率。|
|📝 更新|IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model|IRL-VLA：通过奖励世界模型训练视觉-语言-动作策略|Anqing Jiang, Yu Gao, Yiru Wang, Zhigang Sun, Shuo Wang, Yuwen Heng, Hao Sun, Shichen Tang .etc.|<http://arxiv.org/pdf/2508.06571v3>|提出了一种结合逆强化学习和自我指导的视觉语言动作模型，解决了自动驾驶中的性能局限和训练效率问题。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Pixels to Graphs: Deep Graph-Level Anomaly Detection on Dermoscopic Images|从像素到图：皮肤镜图像的深度图级异常检测|Dehn Xu, Tim Katzke, Emmanuel Müller|<http://arxiv.org/pdf/2508.11826v1>|系统评估了多种图像到图转换方法，提出了一种高效的图级异常检测框架，显著提升了皮肤镜图像的异常检测性能...|
|🆕 发布|Index-Aligned Query Distillation for Transformer-based Incremental Object Detection|索引对齐的查询蒸馏用于基于Transformer的增量目标检测|Mingxiao Ma, Shunyao Zhu, Guoliang Kang|<http://arxiv.org/pdf/2508.11339v1>|提出了一种名为Index-Aligned Query Distillation的新方法，通过固定索引...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Reinforcing Video Reasoning Segmentation to Think Before It Segments|强化视频推理分割：在分割之前思考|Sitong Gong, Lu Zhang, Yunzhi Zhuge, Xu Jia, Pingping Zhang, Huchuan Lu|<http://arxiv.org/pdf/2508.11538v1>|引入Veason-R1模型，通过强化学习优化视频推理分割，提升了解释性和性能。|
|📝 更新|Synthetic Data for Robust Stroke Segmentation|合成数据用于稳健的笔画分割|Liam Chalcroft, Ioannis Pappas, Cathy J. Price, John Ashburner|<http://arxiv.org/pdf/2404.01946v3>|[代码](https://github.com/liamchalcroft/SynthStroke); 提出了一种利用合成数据框架进行脑卒中病变分割的方法，减少对大量标注数据的依赖并提高跨序列适用性。|
|🆕 发布|SelfAdapt: Unsupervised Domain Adaptation of Cell Segmentation Models|《SelfAdapt：细胞分割模型的无监督领域自适应》|Fabian H. Reith, Jannik Franzen, Dinesh R. Palli, J. Lorenz Rumberger, Dagmar Kainmueller|<http://arxiv.org/pdf/2508.11411v1>|[代码](https://github.com/Kainmueller-Lab/self_adapt.); 提出SelfAdapt方法，无需标注数据即可优化细胞分割模型，提升模型适应不同数据域的能力。|
|📝 更新|Automatic brain tumor segmentation in 2D intra-operative ultrasound images using magnetic resonance imaging tumor annotations|二维术中超声图像中基于磁共振成像肿瘤标注的自动脑肿瘤分割|Mathilde Faanes, Ragnhild Holden Helland, Ole Solheim, Sébastien Muller, Ingerid Reinertsen|<http://arxiv.org/pdf/2411.14017v3>|[代码](https://github.com/mathildefaanes/us_brain_tumor_segmentation); 利用MRI肿瘤标注训练深度学习模型，实现了2D术中超声图像的自动脑肿瘤分割。|
|🆕 发布|Hyperspectral vs. RGB for Pedestrian Segmentation in Urban Driving Scenes: A Comparative Study|《在城区驾驶场景中行人分割的 hyperspectral 与 RGB 对比研究》|Jiarong Li, Imad Ali Shah, Enda Ward, Martin Glavin, Edward Jones, Brian Deegan|<http://arxiv.org/pdf/2508.11301v1>|通过最优选取的hyperspectral图像波段，本研究显著提升了城市驾驶场景中行人的分割准确度。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Real-time Concrete Crack Detection and Segmentation Model Based on YOLOv11|基于YOLOv11的实时混凝土裂缝检测与分割模型|Shaoze Huang, Qi Liu, Chao Chen, Yuhang Chen|<http://arxiv.org/pdf/2508.11517v1>|提出实时混凝土裂缝检测与分割模型，通过动态内核共享和三重注意力机制提升检测准确性。|
|🆕 发布|TACR-YOLO: A Real-time Detection Framework for Abnormal Human Behaviors Enhanced with Coordinate and Task-Aware Representations|TACR-YOLO：一种基于坐标和任务感知表征的实时异常人类行为检测框架|Xinyi Yin, Wenbo Yuan, Xuecheng Wu, Liangyu Fu, Danlei Huang|<http://arxiv.org/pdf/2508.11478v1>|提出TACR-YOLO框架，通过坐标和任务感知表征增强异常行为实时检测能力。|
|🆕 发布|Data-Driven Deepfake Image Detection Method -- The 2024 Global Deepfake Image Detection Challenge|数据驱动的深度伪造图像检测方法 -- 2024全球深度伪造图像检测挑战|Xiaoya Zhu, Yibing Nan, Shiguo Lian|<http://arxiv.org/pdf/2508.11464v1>|提出了一种基于Swin Transformer V2-B网络的深伪图像检测方法，通过数据增强显著提升...|
|🆕 发布|LKFMixer: Exploring Large Kernel Feature For Efficient Image Super-Resolution|LKFMixer：探索大核特征以实现高效图像超分辨率|Yinggan Tang, Quanwei Hu|<http://arxiv.org/pdf/2508.11391v1>|[代码](https://github.com/Supereeeee/LKFMixer.); 提出了一种利用大卷积核模拟自注意力捕获非局部特征的轻量级图像超分辨率模型LKFMixer，实现了性能...|
|🆕 发布|Unifying Scale-Aware Depth Prediction and Perceptual Priors for Monocular Endoscope Pose Estimation and Tissue Reconstruction|统一尺度感知深度预测与感知先验知识以实现单目内窥镜位姿估计与组织重建|Muzammil Khan, Enzo Kerkhof, Matteo Fusaglia, Koert Kuhlmann, Theo Ruers, Françoise J. Siepel|<http://arxiv.org/pdf/2508.11282v1>|整合尺度感知深度预测与感知先验，提出了一种用于单目内窥镜位姿估计和三维组织重建的统一框架。|
|📝 更新|PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks|PTQAT：面向三维感知任务的混合参数高效量化算法|Xinhao Wang, Zhiwei Lin, Zhongyu Xia, Yongtao Wang|<http://arxiv.org/pdf/2508.10557v2>|提出PTQAT算法，结合PTQ与QAT优势，优化3D感知网络量化效率与性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TimeMachine: Fine-Grained Facial Age Editing with Identity Preservation|时间机器：具有身份保持的细粒度面部年龄编辑|Yilin Mi, Qixin Yan, Zheng-Peng Duan, Chunle Guo, Hubery Yin, Hao Liu, Chen Li, Chongyi Li|<http://arxiv.org/pdf/2508.11284v2>|提出TimeMachine框架，通过分离年龄和身份特征实现精确的面部年龄微调。|
|🆕 发布|Thyme: Think Beyond Images|《Thyme：超越图像思考》|Yi-Fan Zhang, Xingyu Lu, Shukang Yin, Chaoyou Fu, Wei Chen, Xiao Hu, Bin Wen, Kaiyu Jiang .etc.|<http://arxiv.org/pdf/2508.11630v1>|提出了一种新型范式Thyme，通过自主生成和执行代码实现图像处理和计算操作，增强模型在感知和推理任务...|
|🆕 发布|Subcortical Masks Generation in CT Images via Ensemble-Based Cross-Domain Label Transfer|基于集成学习的跨域标签传递在CT图像中生成皮层下掩膜|Augustine X. W. Lee, Pak-Hei Yeung, Jagath C. Rajapakse|<http://arxiv.org/pdf/2508.11450v1>|[代码](https://github.com/SCSE-Biomedical-Computing-Group/CT-Subcortical-Segmentation); 提出了一种利用已有MRI模型自动生成高质量CT图像亚皮质分割标签的集成框架。|
|🆕 发布|Inside Knowledge: Graph-based Path Generation with Explainable Data Augmentation and Curriculum Learning for Visual Indoor Navigation|《内部知识：基于图的路径生成结合可解释数据增强与课程学习用于视觉室内导航》|Daniel Airinei, Elena Burceanu, Marius Leordeanu|<http://arxiv.org/pdf/2508.11446v1>|提出了一种仅依赖视觉输入的实时、易部署的深度学习方法，通过图生成和自动数据增强技术实现室内导航。|
|📝 更新|FancyVideo: Towards Dynamic and Consistent Video Generation via Cross-frame Textual Guidance|《FancyVideo：通过跨帧文本引导实现动态一致的视频生成》|Jiasong Feng, Ao Ma, Jing Wang, Ke Cao, Zhanjie Zhang|<http://arxiv.org/pdf/2408.08189v4>|提出了一种创新的视频生成框架FancyVideo，通过跨帧文本引导模块增强文本控制，实现了动态且一致...|
|📝 更新|SVG-Head: Hybrid Surface-Volumetric Gaussians for High-Fidelity Head Reconstruction and Real-Time Editing|SVG-Head：混合表面-体积高斯分布用于高保真头部重建与实时编辑|Heyi Sun, Cong Wang, Tian-Xing Xu, Jingwei Huang, Di Kang, Chunchao Guo, Song-Hai Zhang|<http://arxiv.org/pdf/2508.09597v2>|提出了一种混合表面-体积高斯模型SVG-Head，实现了高保真头部重建和实时编辑。|
|📝 更新|Scanpath Prediction in Panoramic Videos via Expected Code Length Minimization|通过期望编码长度最小化在全景视频中预测扫视路径|Mu Li, Kanglong Fan, Kede Ma|<http://arxiv.org/pdf/2305.02536v3>|提出了一种基于数据压缩原理的扫描路径预测方法，通过最小化量化扫描路径的预期码长，提高了预测准确性和感...|
|📝 更新|Visual-RAG: Benchmarking Text-to-Image Retrieval Augmented Generation for Visual Knowledge Intensive Queries|视觉RAG：针对视觉知识密集型查询的文本到图像检索增强生成基准测试|Yin Wu, Quanyu Long, Jing Li, Jianfei Yu, Wenya Wang|<http://arxiv.org/pdf/2502.16636v2>|提出Visual-RAG基准，评估模型如何利用图像证据回答视觉知识密集型问题。|
|📝 更新|ShoulderShot: Generating Over-the-Shoulder Dialogue Videos|《肩上对话：生成肩上视角对话视频》|Yuang Zhang, Junqi Cheng, Haoyu Zhao, Jiaxi Gu, Fangyuan Zou, Zenghui Lu, Peng Shu|<http://arxiv.org/pdf/2508.07597v2>|提出 ShoulderShot 框架，结合双镜头生成与循环视频，实现长对话场景的连贯生成与角色一致性...|
|🆕 发布|GANDiff FR: Hybrid GAN Diffusion Synthesis for Causal Bias Attribution in Face Recognition|《GANDiff FR：混合生成对抗网络扩散合成技术在人脸识别中的因果偏差归因》|Md Asgor Hossain Reaj, Rajan Das Gupta, Md Yeasin Rahat, Nafiz Fahad, Md Jawadul Hasan, Tze Hui Liew|<http://arxiv.org/pdf/2508.11334v1>|提出了一种控制面部识别中人口和环境因素的合成框架，以精确测量、解释和减少偏见。|
|🆕 发布|Logic Unseen: Revealing the Logical Blindspots of Vision-Language Models|《逻辑盲区：揭示视觉-语言模型的逻辑盲点》|Yuchen Zhou, Jiayu Tang, Shuo Yang, Xiaoyan Xiao, Yuqin Dai, Wenhao Yang, Chao Gou, Xiaobo Xia .etc.|<http://arxiv.org/pdf/2508.11317v1>|揭示了视觉语言模型在逻辑理解上的盲点，并提出了LogicCLIP框架提升其逻辑敏感性。|
|🆕 发布|Denoise-then-Retrieve: Text-Conditioned Video Denoising for Video Moment Retrieval|去噪后检索：基于文本条件的视频去噪用于视频时刻检索|Weijia Liu, Jiuxin Cao, Bo Miao, Zhiheng Fu, Xuelin Zhu, Jiawei Ge, Bo Liu, Mehwish Nasim .etc.|<http://arxiv.org/pdf/2508.11313v1>|提出了一种先去噪后检索的新范式，通过过滤无关视频片段并使用净化后的多模态表征来提高视频时刻检索的准确...|
|📝 更新|GBR: Generative Bundle Refinement for High-fidelity Gaussian Splatting with Enhanced Mesh Reconstruction|GBR：用于高保真高斯散点绘制及增强网格重构的生成束精炼|Jianing Zhang, Yuchao Zheng, Ziwei Li, Qionghai Dai, Xiaoyun Yuan|<http://arxiv.org/pdf/2412.05908v2>|提出GBR方法，通过神经束调整和生成深度细化，实现了仅用4-6视图的高保真三维重建。|
|🆕 发布|A Coarse-to-Fine Human Pose Estimation Method based on Two-stage Distillation and Progressive Graph Neural Network|基于两阶段蒸馏和渐进图神经网络的粗到细人体姿态估计方法|Zhangjian Ji, Wenjin Zhang, Shaotong Qiao, Kai Feng, Yuhua Qian|<http://arxiv.org/pdf/2508.11212v1>|提出了一种基于两阶段蒸馏和渐进图神经网络的粗到细人体姿态估计方法，实现了准确性与计算效率的平衡。|
|📝 更新|MUNBa: Machine Unlearning via Nash Bargaining|MUNBa: 通过纳什谈判的机器遗忘|Jing Wu, Mehrtash Harandi|<http://arxiv.org/pdf/2411.15537v3>|提出基于纳什博弈理论的机器遗忘新方法，平衡遗忘特定数据与保持模型性能的冲突，实现更优的遗忘与保持平衡...|
|📝 更新|Marmot: Object-Level Self-Correction via Multi-Agent Reasoning|“Marmot：通过多智能体推理实现对象级自校正”|Jiayang Sun, Hongbo Wang, Jie Cao, Huaibo Huang, Ran He|<http://arxiv.org/pdf/2504.20054v3>|提出Marmot框架，通过多智能体推理实现图像中多对象级别的自我校正，提升图像生成中计数、属性和空间...|
|🆕 发布|Residual-based Efficient Bidirectional Diffusion Model for Image Dehazing and Haze Generation|基于残差的高效双向扩散模型用于图像去雾和雾生成|Bing Liu, Le Wang, Hao Liu, Mingming Liu|<http://arxiv.org/pdf/2508.11134v1>|提出了一种基于残差的高效双向扩散模型，实现了去雾和雾化图像间的转换，提升了小数据集上的性能和计算效率...|
|🆕 发布|LEARN: A Story-Driven Layout-to-Image Generation Framework for STEM Instruction|“LEARN：一种面向STEM教学的基于故事驱动的布局到图像生成框架”|Maoquan Zhang, Bisser Raytchev, Xiujuan Sun|<http://arxiv.org/pdf/2508.11153v1>|LEARN通过结合布局感知扩散、视觉语义训练和提示调节，为STEM教育生成语义对齐的连贯视觉序列。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Labels or Input? Rethinking Augmentation in Multimodal Hate Detection|“标签还是输入？重新思考多模态仇恨检测中的增强方法”|Sahajpreet Singh, Rongxin Ouyang, Subhayan Mukerjee, Kokil Jaidka|<http://arxiv.org/pdf/2508.11808v1>|提出双管齐下的策略提升多模态仇恨检测，通过优化提示结构和数据增广减少错误关联。|
|📝 更新|ImpliHateVid: A Benchmark Dataset and Two-stage Contrastive Learning Framework for Implicit Hate Speech Detection in Videos|隐式视频仇恨言论检测：一个基准数据集和两阶段对比学习框架|Mohammad Zia Ur Rehman, Anukriti Bhatnagar, Omkar Kabde, Shubhi Bansal, Nagendra Kumar|<http://arxiv.org/pdf/2508.06570v2>|提出首个大规模视频隐含仇恨言论检测数据集ImpliHateVid，并采用两阶段对比学习框架提升检测效...|
|🆕 发布|SPG: Style-Prompting Guidance for Style-Specific Content Creation|SPG：风格提示引导用于特定风格内容创作|Qian Liang, Zichong Chen, Yang Zhou, Hui Huang|<http://arxiv.org/pdf/2508.11476v1>|[代码](https://github.com/Rumbling281441/SPG.); 提出了一种指导风格特定图像生成的策略，通过构建风格噪声向量提升输出图像的风格一致性。|
|🆕 发布|Guiding WaveMamba with Frequency Maps for Image Debanding|利用频率图引导WaveMamba进行图像去噪带处理|Xinyi Wang, Smaranda Tasmoc, Nantheera Anantrasirichai, Angeliki Katsenou|<http://arxiv.org/pdf/2508.11331v1>|[代码](https://github.com/xinyiW915/Debanding-PCS2025.); 提出了一种结合频率掩模图的波姆巴去带状伪影方法，有效抑制了图像压缩产生的带状 artifacts。|
|📝 更新|FairT2I: Mitigating Social Bias in Text-to-Image Generation via Large Language Model-Assisted Detection and Attribute Rebalancing|公平T2I：通过大型语言模型辅助检测与属性重平衡减轻文本到图像生成中的社会偏见|Jinya Sakurai, Issei Sato|<http://arxiv.org/pdf/2502.03826v2>|提出FairT2I框架，利用大型语言模型检测并减少文本到图像生成中的社会偏见。|
|🆕 发布|A Cross-Modal Rumor Detection Scheme via Contrastive Learning by Exploring Text and Image internal Correlations|一种通过探索文本与图像内部相关性进行对比学习的跨模态谣言检测方案|Bin Ma, Yifei Zhang, Yongjin Xian, Qi Li, Linna Zhou, Gongxun Miao|<http://arxiv.org/pdf/2508.11141v1>|提出了一种基于对比学习的跨模态谣言检测方法，通过探索文本和图像内部关联来提升谣言识别准确性。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Improving Diffusion Inverse Problem Solving with Decoupled Noise Annealing|解耦噪声退火在扩散逆问题求解中的改进作用|Bingliang Zhang, Wenda Chu, Julius Berner, Chenlin Meng, Anima Anandkumar, Yang Song|<http://arxiv.org/pdf/2407.01521v3>|提出了一种新的噪声退火过程，通过解耦扩散采样步骤来提高复杂非线性逆问题的重构准确率。|
|📝 更新|Diffusion Beats Autoregressive in Data-Constrained Settings|在数据约束环境下，扩散模型优于自回归模型|Mihir Prabhudesai, Mengning Wu, Amir Zadeh, Katerina Fragkiadaki, Deepak Pathak|<http://arxiv.org/pdf/2507.15857v6>|在数据有限的情况下，扩散模型比自回归模型表现更佳，有效利用重复数据降低验证损失。|
|🆕 发布|CoreEditor: Consistent 3D Editing via Correspondence-constrained Diffusion|《CoreEditor：通过对应约束扩散实现一致的3D编辑》|Zhe Zhu, Honghua Chen, Peng Li, Mingqiang Wei|<http://arxiv.org/pdf/2508.11603v1>|CoreEditor通过引入对应约束注意力机制，实现了基于文本的3D场景编辑，确保了多视角一致性并提...|
|🆕 发布|LoRAtorio: An intrinsic approach to LoRA Skill Composition|《LoRAtorio：一种内在的LoRA技能组合方法》|Niki Foteinopoulou, Ignas Budvytis, Stephan Liwicki|<http://arxiv.org/pdf/2508.11624v1>|提出了一种无需训练的多LoRA适配器组合框架LoRAtorio，通过内在模型行为优化了开放环境下的视...|
|🆕 发布|Does the Skeleton-Recall Loss Really Work?|骨骼召回损失真的有效吗？|Devansh Arora, Nitin Kumar, Sukrit Gupta|<http://arxiv.org/pdf/2508.11374v1>|质疑了 Skeleton-Recall Loss 的有效性，发现其性能并未超越传统模型。|
|🆕 发布|Efficient Image-to-Image Schrödinger Bridge for CT Field of View Extension|高效的图像到图像薛定谔桥算法用于CT视野扩展|Zhenhao Li, Long Yang, Xiaojie Yin, Haijun Yu, Jiazhou Wang, Hongbin Han, Weigang Hu, Yixing Huang|<http://arxiv.org/pdf/2508.11211v1>|提出了一种高效的基于图像到图像薛定谔桥的CT视野扩展方法，实现了700倍以上的速度提升和更准确的重建...|
|🆕 发布|StyleMM: Stylized 3D Morphable Face Model via Text-Driven Aligned Image Translation|基于文本驱动的对齐图像转换的样式化三维可变形人脸模型（StyleMM）|Seungmi Lee, Kwan Yun, Junyong Noh|<http://arxiv.org/pdf/2508.11203v1>|提出了一种基于文本描述的3D人脸模型风格化方法，通过保持面部特征实现风格与身份的分离。|
|🆕 发布|Semi-supervised Image Dehazing via Expectation-Maximization and Bidirectional Brownian Bridge Diffusion Models|基于期望最大化与双向布朗运动桥扩散模型的半监督图像去雾方法|Bing Liu, Le Wang, Mingming Liu, Hao Liu, Rui Yao, Yong Zhou, Peng Liu, Tongqiang Xia|<http://arxiv.org/pdf/2508.11165v1>|提出了一种半监督图像去雾方法，通过期望最大化与双向布朗桥扩散模型有效处理厚雾场景。|
|📝 更新|Physics-Guided Image Dehazing Diffusion|物理引导的图像去雾扩散|Shijun Zhou, Baojie Fan, Jiandong Tian|<http://arxiv.org/pdf/2504.21385v2>|提出了一种融合大气散射模型的图像去雾扩散模型，有效桥接了合成与真实世界数据间的域差距。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Training-Free Anomaly Generation via Dual-Attention Enhancement in Diffusion Model|通过双注意力增强在扩散模型中的无需训练异常生成|Zuo Zuo, Jiahao Dong, Yanyun Qu, Zongze Wu|<http://arxiv.org/pdf/2508.11550v1>|提出了一种无需训练的异常生成框架AAG，通过增强注意力机制在特定区域生成逼真的异常图像。|
|🆕 发布|CineTrans: Learning to Generate Videos with Cinematic Transitions via Masked Diffusion Models|电影转换：通过遮蔽扩散模型学习生成带有电影式过渡的视频|Xiaoxue Wu, Bingjie Gao, Yu Qiao, Yaohui Wang, Xinyuan Chen|<http://arxiv.org/pdf/2508.11484v1>|提出了一种生成具有电影风格过渡的多镜头视频的新框架CineTrans，通过遮罩机制实现了稳定且风格一...|
|🆕 发布|Scalable FPGA Framework for Real-Time Denoising in High-Throughput Imaging: A DRAM-Optimized Pipeline using High-Level Synthesis|可扩展的FPGA框架用于高吞吐量成像中的实时去噪：一种基于高阶综合的DRAM优化管道|Weichien Liao|<http://arxiv.org/pdf/2508.14917v1>|实现了一种可扩展的FPGA预处理框架，通过高级行为合成和DRAM优化，实现了实时图像去噪。|
|🆕 发布|Temporally-Similar Structure-Aware Spatiotemporal Fusion of Satellite Images|时间相似结构感知的卫星图像时空融合|Ryosuke Isono, Shunsuke Ono|<http://arxiv.org/pdf/2508.11259v1>|提出了一种针对卫星图像的噪声鲁棒时空融合框架TSSTF，通过引入时空引导的总变分和边缘约束机制，有效...|
|🆕 发布|Generating Dialogues from Egocentric Instructional Videos for Task Assistance: Dataset, Method and Benchmark|《从自我中心教学视频生成对话以辅助任务执行：数据集、方法与基准》|Lavisha Aggarwal, Vikas Bahirwani, Lin Li, Andrea Colaco|<http://arxiv.org/pdf/2508.11192v1>|将单人教学视频转化为两人对话形式，为任务指导提供大规模对话-视频数据集及基准测试。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DashCam Video: A complementary low-cost data stream for on-demand forest-infrastructure system monitoring|行车记录仪视频：一种用于按需森林基础设施系统监控的补充低成本数据流|Durga Joshi, Chandi Witharana, Robert Fahey, Thomas Worthley, Zhe Zhu, Diego Cerrai|<http://arxiv.org/pdf/2508.11591v1>|提出了一种利用常见但未被充分利用的行车记录仪视频数据，进行实时路边植被和基础设施评估与定位的低成本框...|
|📝 更新|Introducing Unbiased Depth into 2D Gaussian Splatting for High-accuracy Surface Reconstruction|将无偏深度引入二维高斯绘制以提高高精度表面重建质量|Yixin Yang, Yang Zhou, Hui Huang|<http://arxiv.org/pdf/2503.06587v3>|[代码](https://github.com/XiaoXinyyx/Unbiased_Surfel.); 引入深度偏差优化，提高了二维高斯绘制在光滑表面重建的完整性和准确性。|
|🆕 发布|Remove360: Benchmarking Residuals After Object Removal in 3D Gaussian Splatting|移除360：在三维高斯散点绘制中对象移除后残差的基准测试|Simona Kocour, Assia Benbihi, Torsten Sattler|<http://arxiv.org/pdf/2508.11431v1>|[代码](https://github.com/spatial-intelligence-ai/Remove360.git.); 提出了一种新型基准和评估框架，用于测量3D高斯散点法中对象移除后遗留的语义信息。|
|📝 更新|Reconstructing Satellites in 3D from Amateur Telescope Images|从业余望远镜图像中三维重建卫星|Zhiming Chang, Boyang Liu, Yifei Xia, Youming Guo, Boxin Shi, He Sun|<http://arxiv.org/pdf/2404.18394v5>|提出了一种集成图像预处理和联合位姿估计的3D卫星重建框架，有效克服了地面望远镜图像重建的挑战。|
|🆕 发布|G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration|引导的三维重建：相机与深度先验信息融合方法|Ramil Khafizov, Artem Komarichev, Ruslan Rakhimov, Peter Wonka, Evgeny Burnaev|<http://arxiv.org/pdf/2508.11379v1>|引入G-CUT3R方法，通过融合深度和相机先验信息，提升了3D场景重建性能。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Tapping into the Black Box: Uncovering Aligned Representations in Pretrained Neural Networks|深入黑箱：揭示预训练神经网络中的对齐表示|Maciej Satkiewicz|<http://arxiv.org/pdf/2507.22832v2>|提出软性反向传播门控方法，提高预训练神经网络表示对齐度，实现直观的解释效果。|
|📝 更新|SynBrain: Enhancing Visual-to-fMRI Synthesis via Probabilistic Representation Learning|“SynBrain：通过概率表征学习增强视觉至fMRI合成”|Weijian Mai, Jiamin Wu, Yu Zhu, Zhouheng Yao, Dongzhan Zhou, Andrew F. Luo, Qihao Zheng, Wanli Ouyang .etc.|<http://arxiv.org/pdf/2508.10298v2>|提出了一种概率性生成框架SynBrain，通过连续概率分布和视觉语义约束模拟视觉刺激到神经反应的映射...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SKALD: Learning-Based Shot Assembly for Coherent Multi-Shot Video Creation|SKALD：基于学习的镜头组装方法以实现连贯的多镜头视频创作|Chen Yi Lu, Md Mehrab Tanjim, Ishita Dasgupta, Somdeb Sarkhel, Gang Wu, Saayan Mitra, Somali Chaterji|<http://arxiv.org/pdf/2503.08010v2>|提出了一种基于学习的方法SKALD，通过测量镜头间的时序和语义关系来创建连贯的多镜头视频。|
|🆕 发布|VideoAVE: A Multi-Attribute Video-to-Text Attribute Value Extraction Dataset and Benchmark Models|视频AVE：一种多属性视频到文本属性值提取数据集及基准模型|Ming Cheng, Tong Wu, Jiazhen Hu, Jiaying Gong, Hoda Eldardiry|<http://arxiv.org/pdf/2508.11801v1>|[代码](https://github.com/gjiaying/VideoAVE); 首次构建了面向电商的多属性视频到文本属性值提取数据集，并提出了数据清洗方法与性能评估基准。|
|🆕 发布|Causality Matters: How Temporal Information Emerges in Video Language Models|因果关系至关重要：视频语言模型中时间信息如何浮现|Yumeng Shi, Quanyu Long, Yin Wu, Wenya Wang|<http://arxiv.org/pdf/2508.11576v1>|揭示了视频语言模型中时间信息如何通过帧间注意力机制而非位置编码自然涌现，并提出了两种效率优化策略。|
|📝 更新|HateClipSeg: A Segment-Level Annotated Dataset for Fine-Grained Hate Video Detection|"HateClipSeg：一种用于细粒度仇恨视频检测的片段级注释数据集"|Han Wang, Zhuoran Wang, Roy Ka-Wei Lee|<http://arxiv.org/pdf/2508.01712v2>|[代码](https://github.com/Social-AI-Studio/HateClipSeg.git.); 提出HateClipSeg数据集，包含细粒度标注，用于提升视频仇恨言论检测准确度。|
|🆕 发布|Versatile Video Tokenization with Generative 2D Gaussian Splatting|多功能的视频标记化：基于生成二维高斯散点绘制方法|Zhenghao Chen, Zicong Chen, Lei Liu, Yiming Wu, Dong Xu|<http://arxiv.org/pdf/2508.11183v1>|提出了一种基于生成二维高斯散点的视频编码方法，有效提升了视频处理任务的灵活性和性能。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-State Tracker: Enhancing Efficient Object Tracking via Multi-State Specialization and Interaction|多状态跟踪器：通过多状态专业化与交互提升高效目标跟踪|Shilei Wang, Gong Cheng, Pujian Lai, Dong Gao, Junwei Han|<http://arxiv.org/pdf/2508.11531v1>|[代码](https://github.com/wsumel/MST.); 提出了一种多状态跟踪器，通过特化增强和多状态互动显著提升跟踪准确性和鲁棒性。|
|🆕 发布|Delving into Dynamic Scene Cue-Consistency for Robust 3D Multi-Object Tracking|深入探究动态场景线索一致性以实现鲁棒的3D多目标跟踪|Haonan Zhang, Xinyao Wang, Boxi Wu, Tu Zheng, Wang Yunhua, Zheng Yang|<http://arxiv.org/pdf/2508.11323v1>|提出了一种基于动态场景线索一致性的3D多目标跟踪方法，有效应对复杂环境下的跟踪挑战。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Relative Position Matters: Trajectory Prediction and Planning with Polar Representation|相对位置至关重要：基于极坐标表示的轨迹预测与规划|Bozhou Zhang, Nan Song, Bingzhao Gao, Li Zhang|<http://arxiv.org/pdf/2508.11492v1>|采用极坐标系统，提出Polaris方法，优化了自动驾驶中的轨迹预测和规划。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|On Delta-Homology Analogy: Memory as Structured Trajectories|论Δ-同伦类比：记忆作为结构化轨迹|Xin Li|<http://arxiv.org/pdf/2303.04203v2>|提出了一种基于拓扑学的记忆模型，将记忆视为认知状态潜在空间中的不可约吸引子集合，通过循环轨迹实现记忆...|
|📝 更新|D-Attn: Decomposed Attention for Large Vision-and-Language Models|D-Attn: 针对大型视觉-语言模型的分解注意力机制|Chia-Wen Kuo, Sijie Zhu, Fan Chen, Xiaohui Shen, Longyin Wen|<http://arxiv.org/pdf/2502.01906v2>|[代码](https://github.com/bytedance/DecomposedAttention.); 提出分解注意力机制D-Attn，优化视觉处理并提升大型视觉与语言模型的性能与效率。|
|🆕 发布|An MLP Baseline for Handwriting Recognition Using Planar Curvature and Gradient Orientation|基于平面曲率和梯度方向的多层感知器基准模型用于手写体识别|Azam Nouri|<http://arxiv.org/pdf/2508.11803v1>|探究仅使用几何特征驱动MLP进行手写识别，实现高准确率，证实了深度学习也可利用可解释特征。|
|🆕 发布|CoFi: A Fast Coarse-to-Fine Few-Shot Pipeline for Glomerular Basement Membrane Segmentation|CoFi：一种快速从粗到细的少样本肾小球基底膜分割管道|Hongjin Fang, Daniel Reisenbüchler, Kenji Ikemura, Mert R. Sabuncu, Yihe Yang, Ruining Deng|<http://arxiv.org/pdf/2508.11469v1>|[代码](https://github.com/ddrrnn123/CoFi.); 提出了一种高效的粗到细少样本学习方法CoFi，仅需少量标注即可实现电子显微镜下肾小球基底膜的高效准确...|
|🆕 发布|Training-free Dimensionality Reduction via Feature Truncation: Enhancing Efficiency in Privacy-preserving Multi-Biometric Systems|基于特征截断的无训练降维：提升隐私保护多生物识别系统的效率|Florian Bayer, Maximilian Russo, Christian Rathgeb|<http://arxiv.org/pdf/2508.11419v1>|提出了一种无需训练的特征截断维度降低方法，有效提升了隐私保护的多生物识别系统效率。|
|🆕 发布|Model Interpretability and Rationale Extraction by Input Mask Optimization|通过输入掩码优化实现模型可解释性与解释提取|Marc Brinner, Sina Zarriess|<http://arxiv.org/pdf/2508.11388v1>|提出了一种基于输入遮罩优化的方法，通过遮蔽模型不考虑的输入部分，生成神经网络的解释性说明。|
|🆕 发布|Allen: Rethinking MAS Design through Step-Level Policy Autonomy|艾伦：通过步级策略自主性重新思考多智能体系统设计|Qiangong Zhou, Zhiting Wang, Mingyou Yao, Zongyang Liu|<http://arxiv.org/pdf/2508.11294v1>|[代码](https://github.com/motern88/Allen); 提出新型多代理系统Allen，通过执行单元自主组合优化协作策略与监督平衡。|
|📝 更新|DSConv: Dynamic Splitting Convolution for Pansharpening|动态分割卷积：用于全色锐化的DSConv|Xuanyu Liu, Bonan An|<http://arxiv.org/pdf/2508.06147v2>|提出动态分割卷积核策略DSConv，通过注意力机制优化特征提取，提升 pansharpening 任...|
|📝 更新|Effective Message Hiding with Order-Preserving Mechanisms|具有顺序保持机制的有效信息隐藏|Gao Yu, Qiu Xuchong, Ye Zihan|<http://arxiv.org/pdf/2402.19160v5>|提出了一种基于MLP的StegaFormer框架，通过顺序保持编码器和解码器以及跨模态融合机制，有效...|
|📝 更新|Reverse Convolution and Its Applications to Image Restoration|逆向卷积及其在图像复原中的应用|Xuhong Huang, Shiqi Liu, Kai Zhang, Ying Tai, Jian Yang, Hui Zeng, Lei Zhang|<http://arxiv.org/pdf/2508.09824v2>|提出了一种深度反向卷积操作，有效逆转卷积效果，并构建了新型网络结构ConverseNet用于图像复原...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Machine Learning-Based Automated Assessment of Intracorporeal Suturing in Laparoscopic Fundoplication|基于机器学习的腹腔镜胃底折叠术中体内缝合自动评估|Shekhar Madhav Khairnar, Huu Phong Nguyen, Alexis Desir, Carla Holcomb, Daniel J. Scott, Ganesh Sankaranarayanan|<http://arxiv.org/pdf/2412.16195v3>|利用Segment Anything模型实现自动化工具追踪，无需人工标注，准确评估腔镜下缝合技能。|
|📝 更新|Lightweight Attribute Localizing Models for Pedestrian Attribute Recognition|轻量级属性定位模型用于行人属性识别|Ashish Jha, Dimitrii Ermilov, Konstantin Sobolev, Anh Huy Phan, Salman Ahmadi-Asl, Naveed Ahmed, Imran Junejo, Zaher AL Aghbari .etc.|<http://arxiv.org/pdf/2306.09822v2>|提出了一种轻量级属性定位模型，通过优化低秩层压缩，实现了行人属性识别的高效压缩与性能保持。|
|🆕 发布|Semi-Supervised Learning with Online Knowledge Distillation for Skin Lesion Classification|基于在线知识蒸馏的半监督学习在皮肤病变分类中的应用|Siyamalan Manivannan|<http://arxiv.org/pdf/2508.11511v1>|提出了一种结合在线知识蒸馏的半监督学习方法，减少了对大量标注数据的依赖，提升了皮肤病变分类的性能。|
|🆕 发布|Automated Building Heritage Assessment Using Street-Level Imagery|使用街景图像的自动化建筑遗产评估|Kristina Dabrock, Tim Johansson, Anna Donarelli, Mikael Mangold, Noah Pflugradt, Jann Michael Weinand, Jochen Linßen|<http://arxiv.org/pdf/2508.11486v1>|利用大型语言模型GPT识别建筑文化遗产价值，结合注册数据提升建筑能效评估效率。|
|🆕 发布|Unified Knowledge Distillation Framework: Fine-Grained Alignment and Geometric Relationship Preservation for Deep Face Recognition|统一知识蒸馏框架：细粒度对齐与几何关系保持用于深度人脸识别|Durgesh Mishra, Rishabh Uikey|<http://arxiv.org/pdf/2508.11376v1>|提出统一知识蒸馏框架，通过细粒度对齐和几何关系保持提升深度人脸识别性能。|
|📝 更新|HealthiVert-GAN: A Novel Framework of Pseudo-Healthy Vertebral Image Synthesis for Interpretable Compression Fracture Grading|健康脊椎图像合成新框架：HealthiVert-GAN 用于可解释性压缩骨折分级|Qi Zhang, Cheng Chuang, Shunan Zhang, Ziqi Zhao, Kun Wang, Jun Xu, Jianqi Sun|<http://arxiv.org/pdf/2503.05990v2>|提出了一种生成模拟健康脊椎图像的框架，通过相对高度损失量化法精确评估脊椎压缩骨折程度。|
|📝 更新|Pathology-Guided AI System for Accurate Segmentation and Diagnosis of Cervical Spondylosis|病理学引导的AI系统用于颈椎病的精确分割与诊断|Qi Zhang, Xiuyuan Chen, Ziyi He, Lianming Wu, Kun Wang, Jianqi Sun, Hongxing Shen|<http://arxiv.org/pdf/2503.06114v2>|提出了一种病理指导的AI系统，实现了颈椎病的高效分割与诊断。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RMFAT: Recurrent Multi-scale Feature Atmospheric Turbulence Mitigator|递归多尺度特征大气湍流缓解器：RMFAT|Zhiming Liu, Nantheera Anantrasirichai|<http://arxiv.org/pdf/2508.11409v1>|提出了一种轻量级循环框架RMFAT，通过多尺度特征和时空编码有效抑制大气湍流影响，提升视频清晰度并加...|
|🆕 发布|FantasyTalking2: Timestep-Layer Adaptive Preference Optimization for Audio-Driven Portrait Animation|《FantasyTalking2：时间步长层自适应偏好优化用于音频驱动的肖像动画》|MengChao Wang, Qiang Wang, Fan Jiang, Mu Xu|<http://arxiv.org/pdf/2508.11255v1>|[代码](https://fantasy-amap.github.io/fantasy-talking2); 提出了一种多维度偏好优化的新型框架，有效提升了音频驱动人像动画的自然度、口型同步准确性和视觉质量。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|UI-Venus Technical Report: Building High-performance UI Agents with RFT|《UI-Venus技术报告：利用RFT构建高性能用户界面代理》|Zhangxuan Gu, Zhengwen Zeng, Zhenyu Xu, Xingran Zhou, Shuheng Shen, Yunfei Liu, Beitong Zhou, Changhua Meng .etc.|<http://arxiv.org/pdf/2508.10833v2>|[代码](https://github.com/inclusionAI/UI-Venus.); UI-Venus通过使用少量高质量训练样本和强化微调，实现了UI识别与导航任务的性能突破。|
|🆕 发布|AIM: Amending Inherent Interpretability via Self-Supervised Masking|通过自监督遮蔽修正内在可解释性|Eyad Alshami, Shashank Agnihotri, Bernt Schiele, Margret Keuper|<http://arxiv.org/pdf/2508.11502v1>|提出AIM方法，通过自我监督遮蔽促进神经网络使用真实特征，提高模型的可解释性和准确性。|
|🆕 发布|Domain-aware Category-level Geometry Learning Segmentation for 3D Point Clouds|面向领域的类别级几何学习分割在三维点云中的应用|Pei He, Lingling Li, Licheng Jiao, Ronghua Shang, Fang Liu, Shuang Wang, Xu Liu, Wenping Ma|<http://arxiv.org/pdf/2508.11265v1>|提出了一种针对3D点云的域泛化分割方法，通过学习类别级几何特征来提高模型在不同环境下的泛化能力。|
|📝 更新|Towards Generalizable Forgery Detection and Reasoning|面向通用伪造检测与推理|Yueying Gao, Dongliang Chang, Bingyao Yu, Haotian Qin, Muxi Diao, Lei Chen, Kongming Liang, Zhanyu Ma|<http://arxiv.org/pdf/2503.21210v2>|提出统一 Forgery Detection and Reasoning 任务，利用多模态大语言模型...|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Robust Convolution Neural ODEs via Contractivity-promoting regularization|通过促进收缩性正则化的鲁棒卷积神经网络常微分方程|Muhammad Zakwan, Liang Xu, Giancarlo Ferrari-Trecate|<http://arxiv.org/pdf/2508.11432v1>|提出利用收缩性促进正则化提升卷积神经网络ODE的鲁棒性，有效应对输入噪声和对抗攻击。|
|🆕 发布|Boosting the Robustness-Accuracy Trade-off of SNNs by Robust Temporal Self-Ensemble|通过稳健时间自集成提升SNN的鲁棒性与准确性权衡|Jihang Wang, Dongcheng Zhao, Ruolin Chen, Qian Zhang, Yi Zeng|<http://arxiv.org/pdf/2508.11279v1>|提出了一种Robust Temporal self-Ensemble框架，增强了SNN在对抗攻击下的...|
|📝 更新|Towards Physically Realizable Adversarial Attacks in Embodied Vision Navigation|面向具身视觉导航的物理可实现对抗攻击方法|Meng Chen, Jiawei Tu, Chao Qi, Yonghao Dang, Feng Zhou, Wei Wei, Jianqin Yin|<http://arxiv.org/pdf/2409.10071v5>|[代码](https://github.com/chen37058/Physical-Attacks-in-Embodied-Nav); 提出了一种在实体导航中实现物理可行对抗攻击的方法，通过优化贴图的不透明度和纹理，有效降低了导航成功率...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Omni-DPO: A Dual-Perspective Paradigm for Dynamic Preference Learning of LLMs|全方位动态偏好学习双视角范式：面向大型语言模型|Shangpin Peng, Weinong Wang, Zhuotao Tian, Senqiao Yang, Xing Wu, Haotian Xu, Chengquan Zhang, Takashi Isobe .etc.|<http://arxiv.org/pdf/2506.10054v2>|[代码](https://github.com/pspdada/Omni-DPO.); 提出Omni-DPO方法，通过考虑数据质量和模型学习动态，优化了偏好学习，提升了大型语言模型性能。|
|🆕 发布|Vision-Language Models display a strong gender bias|计算机视觉与语言模型表现出显著的性别偏见|Aiswarya Konavoor, Raj Abhijit Dandekar, Rajat Dandekar, Sreedath Panat|<http://arxiv.org/pdf/2508.11262v1>|揭示了视觉语言模型中的性别偏见，并建立了评估框架。|
|🆕 发布|BeeNet: Reconstructing Flower Shapes from Electric Fields using Deep Learning|蜜蜂网：利用深度学习从电场重构花朵形状|Jake Turley, Ryan A. Palmer, Isaac V. Chenchiah, Daniel Robert|<http://arxiv.org/pdf/2508.11724v1>|利用电场信息，通过深度学习算法重构花朵形状。|
|📝 更新|Compositional Zero-shot Learning via Progressive Language-based Observations|基于渐进式语言观察的组合零样本学习|Lin Li, Guikun Chen, Zhen Wang, Jun Xiao, Long Chen|<http://arxiv.org/pdf/2311.14749v2>|提出Progressive Language-based Observations方法，通过动态确定...|
|📝 更新|IMU: Influence-guided Machine Unlearning|IMU：影响引导的机器遗忘|Xindi Fan, Jing Wu, Mingyi Zhou, Pengwei Liang, Dinh Phung|<http://arxiv.org/pdf/2508.01620v2>|提出了一种无需保留数据集的机器遗忘方法IMU，通过动态调整遗忘强度显著提高遗忘效果并保持模型性能。|
|🆕 发布|Fine-Grained VLM Fine-tuning via Latent Hierarchical Adapter Learning|通过潜在层次适配器学习进行细粒度视觉语言模型的微调|Yumiao Zhao, Bo Jiang, Yuhe Ding, Xiao Wang, Jin Tang, Bin Luo|<http://arxiv.org/pdf/2508.11176v1>|提出了一种新型Latent Hierarchical Adapter，通过利用潜在语义层次结构提升少...|
|📝 更新|Learning Camera-Agnostic White-Balance Preferences|学习无关相机的白平衡偏好|Luxi Zhao, Mahmoud Afifi, Michael S. Brown|<http://arxiv.org/pdf/2507.01342v2>|学习后处理映射以在相机无关空间中实现跨相机一致且具有审美偏好的白平衡。|
|📝 更新|Zero-Shot Anomaly Detection with Dual-Branch Prompt Selection|双分支提示选择的无监督异常检测|Zihan Wang, Samira Ebrahimi Kahou, Narges Armanfard|<http://arxiv.org/pdf/2508.00777v2>|提出了一种自适应双分支提示学习框架PILOT，有效应对领域迁移挑战，实现无标签异常检测与定位。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Noise Matters: Optimizing Matching Noise for Diffusion Classifiers|噪声至关重要：为扩散分类器优化匹配噪声|Yanghao Wang, Long Chen|<http://arxiv.org/pdf/2508.11330v1>|优化了扩散分类器中的噪声匹配，通过学习特定数据集和图像的噪声，提高了分类稳定性。|
|📝 更新|SORT3D: Spatial Object-centric Reasoning Toolbox for Zero-Shot 3D Grounding Using Large Language Models|SORT3D：基于大型语言模型的零样本三维目标定位空间对象中心推理工具箱|Nader Zantout, Haochen Zhang, Pujith Kachana, Jinkai Qiu, Guofei Chen, Ji Zhang, Wenshan Wang|<http://arxiv.org/pdf/2504.18684v2>|[代码](https://github.com/nzantout/SORT3D.); 提出SORT3D方法，利用二维数据中的丰富对象属性和大型语言模型的顺序推理能力，实现零样本三维场景中...|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Scene Graph-Guided Proactive Replanning for Failure-Resilient Embodied Agent|基于场景图引导的主动重规划以实现故障弹性化具身智能体|Che Rin Yu, Daewon Chae, Dabin Seo, Sangwon Lee, Hyeongwoo Im, Jinkyu Kim|<http://arxiv.org/pdf/2508.11286v1>|提出了一种基于场景图的主动重规划框架，通过比较当前与参考场景图预防性调整机器人行为，提高任务成功率与...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Is ChatGPT-5 Ready for Mammogram VQA?|ChatGPT-5 是否准备好用于乳腺X射线照片视觉问答？|Qiang Li, Shansong Wang, Mingzhe Hu, Mojtaba Safari, Zachary Eidex, Xiaofeng Yang|<http://arxiv.org/pdf/2508.11628v1>|评估GPT-5在乳腺影像VQA任务中的表现，显示潜力但需领域优化以达临床应用标准。|
|📝 更新|PhysLab: A Benchmark Dataset for Multi-Granularity Visual Parsing of Physics Experiments|物理实验室：一种用于物理实验多粒度视觉解析的基准数据集|Minghao Zou, Qingtian Zeng, Yongping Miao, Shangkun Liu, Zilong Wang, Hantao Liu, Wei Zhou|<http://arxiv.org/pdf/2506.06631v2>|[代码](https://github.com/ZMH-SDUST/PhysLab.); 提出了PhysLab数据集，为多粒度视觉解析教育视频提供了全面标注和基准测试。|
|🆕 发布|Hierarchical Graph Feature Enhancement with Adaptive Frequency Modulation for Visual Recognition|基于自适应频率调制的层次化图特征增强视觉识别方法|Feiyue Zhao, Zhichao Zhang|<http://arxiv.org/pdf/2508.11497v1>|提出了一种结合图推理的CNN框架HGFE，通过自适应频率调制增强图像的结构感知和特征表示。|
|📝 更新|Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory|“观察、聆听、记忆与推理：具有长期记忆的多模态智能体”|Lin Long, Yichen He, Wentao Ye, Yiyuan Pan, Yuan Lin, Hang Li, Junbo Zhao, Wei Li|<http://arxiv.org/pdf/2508.09736v2>|[代码](https://github.com/bytedance-seed/m3-agent); 提出M3-Agent框架，融合视觉与听觉输入，实现类似人类的长期记忆与推理能力。|
|🆕 发布|OpenConstruction: A Systematic Synthesis of Open Visual Datasets for Data-Centric Artificial Intelligence in Construction Monitoring|开放建设：面向建筑监控数据为中心人工智能的开源视觉数据集系统整合|Ruoxin Xiong, Yanyu Wang, Jiannan Cai, Kaijian Liu, Yuansheng Zhu, Pingbo Tang, Nora El-Gohary|<http://arxiv.org/pdf/2508.11482v1>|系统整合了建筑监控领域的开放视觉数据集，推动数据驱动方法的发展并提出了未来数据基础设施的改进方向。|
|🆕 发布|UAV-VL-R1: Generalizing Vision-Language Models via Supervised Fine-Tuning and Multi-Stage GRPO for UAV Visual Reasoning|无人机视觉推理中的视觉-语言模型泛化：通过监督微调和多阶段广义推理规划优化|Jiajin Guan, Haibo Mei, Bonan Zhang, Dan Liu, Yuanshuang Fu, Yue Zhang|<http://arxiv.org/pdf/2508.11196v1>|提出UAV-VL-R1模型，结合监督微调和多阶段强化学习，提升无人机视觉推理性能。|
|📝 更新|Refine-IQA: Multi-Stage Reinforcement Finetuning for Perceptual Image Quality Assessment|精细图像质量评估：多阶段强化微调|Ziheng Jia, Jiaying Qian, Zicheng Zhang, Zijian Chen, Xiongkuo Min|<http://arxiv.org/pdf/2508.03763v2>|提出多阶段强化微调框架Refine-IQA，增强模型视觉质量感知并提升图像质量评估性能。|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Controlling Multimodal LLMs via Reward-guided Decoding|通过奖励引导解码控制多模态大型语言模型|Oscar Mañas, Pierluca D'Oro, Koustuv Sinha, Adriana Romero-Soriano, Michal Drozdzal, Aishwarya Agrawal|<http://arxiv.org/pdf/2508.11616v1>|首次提出奖励引导解码方法，实现了对多模态大型语言模型输出视觉定位的精确控制。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhancing Supervised Composed Image Retrieval via Reasoning-Augmented Representation Engineering|通过推理增强表征工程提升监督组合图像检索|Jun Li, Kai Li, Shaoguo Liu, Tingting Gao|<http://arxiv.org/pdf/2508.11272v1>|提出了一种无需额外训练的 Pyramid Matching Model with Training-...|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LSVG: Language-Guided Scene Graphs with 2D-Assisted Multi-Modal Encoding for 3D Visual Grounding|LSVG：基于语言指导的场景图与二维辅助多模态编码的3D视觉定位|Feng Xiao, Hongbin Xu, Guocan Zhao, Wenxiong Kang|<http://arxiv.org/pdf/2505.04058v3>|提出了一种语言引导的场景图框架，通过结合二维语义增强三维视觉与文本的关联，有效区分相似物体。|
|🆕 发布|Better Supervised Fine-tuning for VQA: Integer-Only Loss|计算机视觉问答中的改进监督微调：仅整数损失函数|Baihong Qian, Haotian Fan, Wenjie Liao, Yunqiu Wang, Tao Li, Junhui Cui|<http://arxiv.org/pdf/2508.11170v1>|提出整数标签约束和目标掩码策略，提升视觉语言模型在视频质量评估中的准确性和一致性。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Statistical analysis of multivariate planar curves and applications to X-ray classification|多变量平面曲线的统计分析及其在X射线分类中的应用|Issam-Ali Moindjié, Marie-Hélène Descary, Cédric Beaulac|<http://arxiv.org/pdf/2508.11780v2>|提出了一种多变量平面曲线统计分析方法，用于通过图像轮廓进行X射线分类。|
|📝 更新|AI-Driven Detection and Analysis of Handwriting on Seized Ivory: A Tool to Uncover Criminal Networks in the Illicit Wildlife Trade|人工智能驱动的查获象牙上手写体检测与分析：揭示非法野生动物贸易犯罪网络的工具|Will Fein, Ryan J. Horwitz, John E. Brown III, Amit Misra, Felipe Oviedo, Kevin White, Juan M. Lavista Ferres, Samuel K. Wasser|<http://arxiv.org/pdf/2508.10219v2>|提出了一种利用AI分析象牙上手写标记的新方法，为打击非法野生动物贸易提供了低成本、可扩展的取证证据。|
|🆕 发布|Benchmarking GPT-5 for Zero-Shot Multimodal Medical Reasoning in Radiology and Radiation Oncology|在放射学和放射肿瘤学中进行零样本多模态医学推理的GPT-5基准测试|Mingzhe Hu, Zach Eidex, Shansong Wang, Mojtaba Safari, Qiang Li, Xiaofeng Yang|<http://arxiv.org/pdf/2508.13192v1>|评估GPT-5在医学影像领域的零样本多模态推理性能，显著优于GPT-4o。|
|🆕 发布|An Efficient Medical Image Classification Method Based on a Lightweight Improved ConvNeXt-Tiny Architecture|基于轻量级改进的ConvNeXt-Tiny架构的高效医学图像分类方法|Jingsong Xia, Yue Yin, Xiuhan Li|<http://arxiv.org/pdf/2508.11532v1>|提出了一种基于改进ConvNeXt-Tiny架构的医疗图像分类方法，通过结构优化和损失函数设计提升性...|
|📝 更新|Image-to-Text for Medical Reports Using Adaptive Co-Attention and Triple-LSTM Module|使用自适应协同注意力和三重长短期记忆模块的医学报告图像到文本转换|Yishen Liu, Shengda Luo, Zishao Zhong, Hudan Pan|<http://arxiv.org/pdf/2503.18297v3>|提出了一种结合视觉和文本的深度学习模型CA-TriNet，通过协同注意力和三重LSTM网络提升医疗报...|
|📝 更新|Med3DVLM: An Efficient Vision-Language Model for 3D Medical Image Analysis|Med3DVLM：一种用于三维医学图像分析的高效视觉-语言模型|Yu Xin, Gorkem Can Ates, Kuang Gong, Wei Shao|<http://arxiv.org/pdf/2503.20047v2>|[代码](https://github.com/mirthAI/Med3DVLM.); Med3DVLM通过创新的3D卷积编码器、对比学习策略和特征融合技术，有效提升了三维医疗图像与文本的...|
|🆕 发布|ImagiDrive: A Unified Imagination-and-Planning Framework for Autonomous Driving|《ImagiDrive：一种统一想象与规划框架的自动驾驶系统》|Jingyu Li, Bozhou Zhang, Xin Jin, Jiankang Deng, Xiatian Zhu, Li Zhang|<http://arxiv.org/pdf/2508.11428v1>|提出了一种融合视觉语言模型和驾驶世界模型的自动驾驶框架ImagiDrive，通过想象与规划循环提升驾...|
|🆕 发布|AnatoMaskGAN: GNN-Driven Slice Feature Fusion and Noise Augmentation for Medical Semantic Image Synthesis|解剖掩码生成对抗网络：基于图神经网络驱动的切片特征融合与噪声增强用于医学语义图像合成|Zonglin Wu, Yule Xue, Qianxiang Hu, Yaoyao Feng, Yuqi Ma, Shanxiong Chen|<http://arxiv.org/pdf/2508.11375v1>|提出AnatoMaskGAN框架，利用图神经网络融合切片特征并增强图像多样性，显著提升医疗图像重建精...|
|🆕 发布|Fluid Dynamics and Domain Reconstruction from Noisy Flow Images Using Physics-Informed Neural Networks and Quasi-Conformal Mapping|利用物理信息神经网络和准共形映射从噪声流图像中重建流体动力学和域|Han Zhang, Xue-Cheng Tai, Jean-Michel Morel, Raymond H. Chan|<http://arxiv.org/pdf/2508.11216v1>|利用物理信息神经网络和准共形映射从噪声流图像中重建流体动力学和域。|
|📝 更新|From Explainable to Explained AI: Ideas for Falsifying and Quantifying Explanations|从可解释到解释性AI：对证伪和量化解释的想法|Yoni Schirris, Eric Marcus, Jonas Teuwen, Hugo Horlings, Efstratios Gavves|<http://arxiv.org/pdf/2508.09205v2>|[代码](https://github.com/nki-ai/x2x.); 提出了一种结合人类与机器的互动系统，用于验证和量化深度学习模型在医学图像分析中的解释性。|
|📝 更新|PRS-Med: Position Reasoning Segmentation with Vision-Language Model in Medical Imaging|PRS-Med：基于视觉语言模型的医学成像位置推理分割|Quoc-Huy Trinh, Minh-Van Nguyen, Jung Zeng, Ulas Bagci, Debesh Jha|<http://arxiv.org/pdf/2505.11872v3>|提出PRS-Med框架，结合视觉语言模型与分割技术，提升医学影像分割精度及空间位置推理能力。|
|🆕 发布|FusionFM: Fusing Eye-specific Foundational Models for Optimized Ophthalmic Diagnosis|融合FM：针对优化眼科诊断的眼特定基础模型融合|Ke Zou, Jocelyn Hui Lin Goh, Yukun Zhou, Tian Lin, Samantha Min Er Yew, Sahana Srinivasan, Meng Wang, Rui Santos .etc.|<http://arxiv.org/pdf/2508.11721v1>|系统评估了眼科基础模型，提出融合策略提升疾病诊断性能。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Perception in Plan: Coupled Perception and Planning for End-to-End Autonomous Driving|“规划中的感知：端到端自动驾驶中的耦合感知与规划”|Bozhou Zhang, Jingyu Li, Nan Song, Li Zhang|<http://arxiv.org/pdf/2508.11488v1>|集成感知与规划流程，提出VeteranAD框架，提升自动驾驶路径规划的准确性和可靠性。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GDSR: Global-Detail Integration through Dual-Branch Network with Wavelet Losses for Remote Sensing Image Super-Resolution|全局-细节融合通过双分支网络与波浪损失进行遥感图像超分辨率重建|Qiwei Zhu, Kai Li, Guojing Zhang, Xiaoying Wang, Jianqiang Huang, Xilai Li|<http://arxiv.org/pdf/2501.01460v4>|提出了一种全局-细节双分支网络结构GDSR，结合RWKV和卷积操作，以及波let损失，有效平衡遥感图...|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A CLIP-based Uncertainty Modal Modeling (UMM) Framework for Pedestrian Re-Identification in Autonomous Driving|基于CLIP的不确定性模态建模（UMM）框架用于自动驾驶中的行人重识别|Jialin Li, Shuqi Wu, Ning Wang|<http://arxiv.org/pdf/2508.11218v1>|提出了一种基于CLIP的轻量级框架，有效应对自动驾驶中行人重识别的不确定模态挑战。|
|📝 更新|RL-MoE: An Image-Based Privacy Preserving Approach In Intelligent Transportation System|基于图像的智能交通系统中隐私保护的RL-MoE方法|Abdolazim Rezaei, Mehdi Sookhak, Mahboobeh Haghparast|<http://arxiv.org/pdf/2508.09186v2>|提出RL-MoE框架，将视觉数据转化为隐私保护的文本描述，平衡了隐私与数据效用。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Understanding 3D Vision: the Role of Gaussian Curvature|面向理解三维视觉：高斯曲率的作用|Sherlon Almeida da Silva, Davi Geiger, Luiz Velho, Moacir Antonelli Ponti|<http://arxiv.org/pdf/2508.11825v1>|探究高斯曲率在3D视觉中的作用，提升表面建模精度与立体方法性能。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Handwritten Text Recognition of Historical Manuscripts Using Transformer-Based Models|基于变换器模型的历史手稿手写文本识别|Erez Meoded|<http://arxiv.org/pdf/2508.11499v1>|提出四种新型数据增强方法，结合Transformer模型，显著提升了历史手稿识别准确率。|
|🆕 发布|Cost-Effective Active Labeling for Data-Efficient Cervical Cell Classification|高效成本的活动标注在数据高效型宫颈细胞分类中的应用|Yuanlin Liu, Zhihan Zhou, Mingqiang Wei, Youyi Song|<http://arxiv.org/pdf/2508.11340v1>|提出了一种经济高效的活动标注方法，以低成本构建代表性训练数据集，实现高效宫颈癌细胞分类。|
|🆕 发布|Exploring the Tradeoff Between Diversity and Discrimination for Continuous Category Discovery|探索连续类别发现中多样性与区分性的权衡|Ruobing Jiang, Yang Liu, Haobing Liu, Yanwei Yu, Chunyang Wang|<http://arxiv.org/pdf/2508.11173v1>|提出IDOD方法，平衡连续性类别发现中的多样性与判别性，减少错误累积和存储空间需求。|
|🆕 发布|CHARM3R: Towards Unseen Camera Height Robust Monocular 3D Detector|CHARM3R：面向未见相机高度稳健的单目3D检测器|Abhinav Kumar, Yuliang Guo, Zhihao Zhang, Xinyu Huang, Liu Ren, Xiaoming Liu|<http://arxiv.org/pdf/2508.11185v1>|[代码](https://github.com/abhi1kumar/CHARM3R); 提出了一种新的单目3D检测模型CHARM3R，通过融合深度估计来增强对相机高度变化的鲁棒性。|

