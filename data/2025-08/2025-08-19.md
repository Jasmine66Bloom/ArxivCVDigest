## [UPDATED!] **2025-08-19** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vision Transformers for Kidney Stone Image Classification: A Comparative Study with CNNs|《用于肾结石图像分类的视觉变换器：与卷积神经网络的比较研究》|Ivan Reyes-Amezcua, Francisco Lopez-Tiro, Clement Larose, Andres Mendez-Vazquez, Gilberto Ochoa-Ruiz, Christian Daul|<http://arxiv.org/pdf/2508.13461v2>|对比传统卷积神经网络，研究证明了基于Vision Transformers的模型在肾结石图像分类任务...|
|🆕 发布|A Systematic Study of Deep Learning Models and xAI Methods for Region-of-Interest Detection in MRI Scans|深度学习模型及其在MRI扫描中感兴趣区域检测的可解释性方法系统研究|Justin Yiu, Kushank Arora, Daniel Steinberg, Rohit Ghiya|<http://arxiv.org/pdf/2508.14151v2>|系统评估了深度学习模型结合解释性AI技术在MRI扫描中自动检测兴趣区域的效果，发现CNN模型表现最优...|
|🆕 发布|ViT-FIQA: Assessing Face Image Quality using Vision Transformers|ViT-FIQA：使用视觉变换器评估人脸图像质量|Andrea Atzori, Fadi Boutros, Naser Damer|<http://arxiv.org/pdf/2508.13957v2>|提出ViT-FIQA，利用Vision Transformer架构评估人脸图像质量，实现高效的人脸识...|
|🆕 发布|Pixels to Play: A Foundation Model for 3D Gameplay|像素至游玩：三维游戏的基础模型|Yuguang Yue, Chris Green, Samuel Hunt, Irakli Salia, Wenzhe Shi, Jonathan J Hunt|<http://arxiv.org/pdf/2508.14295v1>|提出了一个能够模仿人类行为玩多种3D游戏的端到端训练基础模型。|
|🆕 发布|RynnEC: Bringing MLLMs into Embodied World|RynnEC：将多模态大型语言模型引入具身世界|Ronghao Dang, Yuqian Yuan, Yunxuan Mao, Kehan Li, Jiangpin Liu, Zhikai Wang, Xin Li, Fan Wang .etc.|<http://arxiv.org/pdf/2508.14160v1>|[代码](https://github.com/alibaba-damo-academy/RynnEC); 提出RynnEC模型，结合视觉语言基础模型与区域编码器，提升机器人对物理世界的精细感知与互动能力。|
|🆕 发布|STAS: Spatio-Temporal Adaptive Computation Time for Spiking Transformers|STAS：时空自适应计算时间用于脉冲变压器|Donghwa Kang, Doohyun Kim, Sang-Ki Ko, Jinkyu Lee, Brent ByungHoon Kang, Hyeongboo Baek|<http://arxiv.org/pdf/2508.14138v1>|提出STAS框架，通过整合时空自适应计算时间解决脉冲神经网络高延迟问题，提升视觉Transforme...|
|🆕 发布|A Fully Transformer Based Multimodal Framework for Explainable Cancer Image Segmentation Using Radiology Reports|基于全变换器的多模态框架：利用放射学报告进行可解释的癌症图像分割|Enobong Adahada, Isabel Sassoon, Kate Hone, Yongmin Li|<http://arxiv.org/pdf/2508.13796v1>|提出了一种融合临床报告的全新Transformer框架，实现了高精度且可解释的乳腺癌超声图像分割。|
|🆕 发布|Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency|通过跨域几何一致性校准VFM衍生潜在空间中的偏置分布|Yanbiao Ma, Wei Dai, Bowei Liu, Jiayi Chen, Wenke Huang, Guancheng Wan, Zhiwu Lu, Junchi Yan|<http://arxiv.org/pdf/2508.13518v1>|提出了一种利用跨域几何一致性校准视觉基础模型特征分布偏差的方法，有效克服数据异质性和样本不平衡带来的...|
|📝 更新|Always Skip Attention|始终跳过注意力机制|Yiping Ji, Hemanth Saratchandran, Peyman Moghadam, Simon Lucey|<http://arxiv.org/pdf/2505.01996v3>|发现Vision Transformers中的自注意力机制需依赖跳连进行正则化，提出Token Gr...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ExpVG: Investigating the Design Space of Visual Grounding in Multimodal Large Language Model|ExpVG: 探究多模态大型语言模型中视觉定位的设计空间|Weitai Kang, Weiming Zhuang, Zhizhong Li, Yan Yan, Lingjuan Lyu|<http://arxiv.org/pdf/2508.08066v2>|系统研究了多模态大语言模型中视觉定位的设计选择，提升了模型在视觉定位任务上的表现。|
|🆕 发布|UNICON: UNIfied CONtinual Learning for Medical Foundational Models|统一连续学习用于医学基础模型的UNICON|Mohammad Areeb Qazi, Munachiso S Nwadike, Ibrahim Almakky, Mohammad Yaqub, Numan Saeed|<http://arxiv.org/pdf/2508.14024v1>|提出UNICON框架，实现医疗基础模型在多领域、任务和模态的无缝适应与持续学习。|
|🆕 发布|MME-SCI: A Comprehensive and Challenging Science Benchmark for Multimodal Large Language Models|多模态大型语言模型的全面与挑战性科学基准：MME-SCI|Jiacheng Ruan, Dan Jiang, Xian Gao, Ting Liu, Yuzhuo Fu, Yangyang Kang|<http://arxiv.org/pdf/2508.13938v1>|[代码](https://github.com/JCruan519/MME-SCI.); 提出MME-SCI基准，全面评估多模态大语言模型在多语言科学领域的推理能力和知识覆盖。|
|🆕 发布|RED.AI Id-Pattern: First Results of Stone Deterioration Patterns with Multi-Agent Systems|RED.AI Id-Pattern：基于多智能体的石质文物风化模式初步研究成果|Daniele Corradetti, José Delgado Rodrigues|<http://arxiv.org/pdf/2508.13872v1>|提出了一种模拟专家协作的多智能体AI系统，用于自动化识别石材病变模式，大幅提升了诊断效率和准确性。|
|🆕 发布|subCellSAM: Zero-Shot (Sub-)Cellular Segmentation for Hit Validation in Drug Discovery|亚细胞SAM：药物发现中击中验证的零样本（亚）细胞分割|Jacob Hanimann, Daniel Siegismund, Mario Wieser, Stephan Steigele|<http://arxiv.org/pdf/2508.13701v1>|提出了一种无需手动参数调整或模型微调的零样本细胞分割方法，通过自提示机制实现精确的生物结构分割。|
|📝 更新|A Versatile Pathology Co-pilot via Reasoning Enhanced Multimodal Large Language Model|一种通过推理增强的多模态大型语言模型实现的通用病理学协作驾驶员|Zhe Xu, Ziyi Liu, Junlin Hou, Jiabo Ma, Cheng Jin, Yihui Wang, Zhixuan Chen, Zhengyu Zhang .etc.|<http://arxiv.org/pdf/2507.17303v2>|提出了一种多模态大规模语言模型SmartPath-R1，通过增强推理能力同时处理ROI和WSI级任务...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AutoComPose: Automatic Generation of Pose Transition Descriptions for Composed Pose Retrieval Using Multimodal LLMs|自动生成姿态转换描述以利用多模态大型语言模型进行组合姿态检索：AutoComPose|Yi-Ting Shen, Sungmin Eum, Doheon Lee, Rohit Shete, Chiao-Yi Wang, Heesung Kwon, Shuvra S. Bhattacharyya|<http://arxiv.org/pdf/2503.22884v2>|自动生成丰富且结构化的姿态转换描述，降低姿态检索标注成本并提升检索质量。|
|🆕 发布|Multimodal Data Storage and Retrieval for Embodied AI: A Survey|《具身人工智能的多模态数据存储与检索：综述》|Yihao Lu, Hao Tang|<http://arxiv.org/pdf/2508.13901v1>|系统评估了多种存储架构和检索方法，为Embodied AI的数据管理提供了全面的研究路线图。|
|🆕 发布|MMIS-Net for Retinal Fluid Segmentation and Detection|用于视网膜液体检分割与检测的MMIS-Net网络|Nchongmaje Ndipenocha, Alina Mirona, Kezhi Wanga, Yongmin Li|<http://arxiv.org/pdf/2508.13936v1>|提出MMIS-Net算法，通过多模态数据融合和标签空间优化，提升视网膜液体分割与检测性能。|
|🆕 发布|PhysGM: Large Physical Gaussian Model for Feed-Forward 4D Synthesis|PhysGM：用于前向4D合成的广义物理高斯模型|Chunji Lv, Zequn Chen, Donglin Di, Weinan Zhang, Hao Li, Wei Chen, Changsheng Li|<http://arxiv.org/pdf/2508.13911v1>|[代码](https://hihixiaolv.github.io/PhysGM.github.io); 提出了一种新的图像到4D物理模拟的快速生成方法PhysGM，通过单张图像直接预测高保真度的物理属性和...|
|📝 更新|Vector-Quantized Vision Foundation Models for Object-Centric Learning|面向以对象为中心学习的矢量量化视觉基础模型|Rongzhen Zhao, Vivienne Wang, Juho Kannala, Joni Pajarinen|<http://arxiv.org/pdf/2502.20263v5>|[代码](https://github.com/Genera1Z/VQ-VFM-OCL.); 提出了一种统一的向量量化视觉基础模型架构，通过共享量化表示增强对象中心学习，提升了对象发现和识别性能...|
|🆕 发布|Breaking the SFT Plateau: Multimodal Structured Reinforcement Learning for Chart-to-Code Generation|打破SFT平台期：用于图表到代码生成的多模态结构化强化学习|Lei Chen, Xuanle Zhao, Zhixiong Zeng, Jing Huang, Liming Zheng, Yufeng Zhong, Lin Ma|<http://arxiv.org/pdf/2508.13587v1>|提出多模态结构化强化学习策略MSRL，突破图表到代码生成任务中的监督微调性能瓶颈。|
|📝 更新|MCN-SLAM: Multi-Agent Collaborative Neural SLAM with Hybrid Implicit Neural Scene Representation|多智能体协同神经SLAM：基于混合隐式神经场景表示|Tianchen Deng, Guole Shen, Xun Chen, Shenghai Yuan, Hongming Shen, Guohao Peng, Zhenyu Wu, Jingchuan Wang .etc.|<http://arxiv.org/pdf/2506.18678v2>|[代码](https://github.com/dtc111111/mcnslam.); 提出首个分布式多智能体协同神经SLAM框架，通过混合场景表示和在线蒸馏实现大规模场景的高效建图与跟踪...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OccluNet: Spatio-Temporal Deep Learning for Occlusion Detection on DSA|OccluNet：基于时空深度学习的DSA遮挡检测|Anushka A. Kore, Frank G. te Nijenhuis, Matthijs van der Sluijs, Wim van Zwam, Charles Majoie, Geert Lycklama à Nijeholt, Danny Ruijters, Frans Vos .etc.|<http://arxiv.org/pdf/2508.14286v1>|[代码](https://github.com/anushka-kore/OccluNet.git); 提出OccluNet模型，结合单阶段检测器和时空注意力机制，用于DSA序列中的血管阻塞自动检测。|
|🆕 发布|CLIPSym: Delving into Symmetry Detection with CLIP|CLIPSym：深入对称性检测的CLIP探索|Tinghan Yang, Md Ashiqur Rahman, Raymond A. Yeh|<http://arxiv.org/pdf/2508.14197v1>|[代码](https://github.com/timyoung2333/CLIPSym.); 提出CLIPSym方法，利用CLIP模型和语义提示技术提升对称性检测性能。|
|🆕 发布|Heatmap Regression without Soft-Argmax for Facial Landmark Detection|面部特征点检测中的热图回归无需软-最大值操作|Chiao-An Yang, Raymond A. Yeh|<http://arxiv.org/pdf/2508.14929v1>|[代码](https://github.com/ca-joe-yang/regression-without-softarg.); 提出了一种不使用Soft-Argmax的heatmap回归新方法，实现了面部标志检测任务的更快收敛和...|
|🆕 发布|LongSplat: Robust Unposed 3D Gaussian Splatting for Casual Long Videos|长段视频中的稳健无姿态三维高斯散点绘制方法|Chin-Yang Lin, Cheng Sun, Fu-En Yang, Min-Hung Chen, Yen-Yu Lin, Yu-Lun Liu|<http://arxiv.org/pdf/2508.14041v1>|[代码](https://linjohnss.github.io/longsplat); 提出了一种针对长视频的稳健三维高斯散点框架，通过增量联合优化和高效的空间锚点机制，有效解决了视角合成...|
|📝 更新|Vehicle detection from GSV imagery: Predicting travel behaviour for cycling and motorcycling using Computer Vision|从GSV图像中进行车辆检测：使用计算机视觉预测骑行和摩托车驾驶行为|Kyriaki, Kokka, Rahul Goel, Ali Abbas, Kerry A. Nice, Luca Martial, SM Labib, Rihuan Ke .etc.|<http://arxiv.org/pdf/2508.12794v2>|利用深度学习分析街景图像，准确预测全球城市自行车与摩托车使用情况。|
|🆕 发布|MR6D: Benchmarking 6D Pose Estimation for Mobile Robots|MR6D：移动机器人六自由度位姿估计基准测试|Anas Gouda, Shrutarv Awasthi, Christian Blesing, Lokeshwaran Manohar, Frank Hoffmann, Alice Kirchheim|<http://arxiv.org/pdf/2508.13775v1>|提出MR6D数据集，针对移动机器人在工业环境中的6D位姿估计挑战。|
|🆕 发布|RCGNet: RGB-based Category-Level 6D Object Pose Estimation with Geometric Guidance|基于RGB的类别级6D物体姿态估计的RCGNet：几何引导方法|Sheng Yu, Di-Hua Zhai, Yuanqing Xia|<http://arxiv.org/pdf/2508.13623v1>|提出了一种仅依赖RGB图像的物体位姿估计方法，通过几何特征引导提升精度，无需深度信息即可实现高效准确...|
|📝 更新|ContrastAlign: Toward Robust BEV Feature Alignment via Contrastive Learning for Multi-Modal 3D Object Detection|对比对齐：通过对比学习实现多模态三维目标检测中的鲁棒鸟瞰特征对齐|Ziying Song, Hongyu Pan, Feiyang Jia, Yongchang Zhang, Lin Liu, Lei Yang, Shaoqing Xu, Peiliang Wu .etc.|<http://arxiv.org/pdf/2405.16873v3>|提出了一种基于对比学习的特征对齐方法ContrastAlign，有效解决了多模态3D目标检测中LiD...|
|📝 更新|MR-EEGWaveNet: Multiresolutional EEGWaveNet for Seizure Detection from Long EEG Recordings|MR-EEGWaveNet：基于多分辨率EEGWaveNet的长时间脑电图记录中的癫痫发作检测|Kazi Mahmudul Hassan, Xuyang Zhao, Hidenori Sugano, Toshihisa Tanaka|<http://arxiv.org/pdf/2505.17972v2>|提出了一种多尺度EEGWaveNet模型，有效区分脑电图中的癫痫事件与噪声，显著提升了检测准确性和减...|
|📝 更新|Refinement Module based on Parse Graph for Human Pose Estimation|基于解析图的人体姿态估计细化模块|Shibang Liu, Xuemei Xie, Guangming Shi|<http://arxiv.org/pdf/2501.11069v7>|提出了一种基于解析图的精炼模块，通过隐式构建层级结构和上下文关系，提高了人体姿态估计的准确性和模型集...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-Rationale Explainable Object Recognition via Contrastive Conditional Inference|通过对比条件推理的多理由可解释对象识别|Ali Rasekh, Sepehr Kazemi Ranjbar, Simon Gottschalk|<http://arxiv.org/pdf/2508.14280v1>|提出多理由解释性对象识别新框架，通过对比条件推理提升分类准确性和理由质量。|
|🆕 发布|Accelerating Image Classification with Graph Convolutional Neural Networks using Voronoi Diagrams|利用 Voronoi 图的图卷积神经网络加速图像分类|Mustafa Mohammadi Gharasuie, Luis Rueda|<http://arxiv.org/pdf/2508.14218v1>|利用 Voronoi 图与图卷积神经网络结合，提出 NVGCN 方法，加快图像分类速度并提升准确率。|
|📝 更新|Vision Backbone Efficient Selection for Image Classification in Low-Data Regimes|低数据环境下图像分类的视觉主干网络高效选择|Joris Guerin, Shray Bansal, Amirreza Shaban, Paulo Mann, Harshvardhan Gazula|<http://arxiv.org/pdf/2410.08592v2>|提出针对小数据集的特定数据集 backbone 选择方法，实现高效低数据图像分类。|
|📝 更新|ReservoirTTA: Prolonged Test-time Adaptation for Evolving and Recurring Domains|水库TTA：针对演化和周期性领域的时间延长测试时适应|Guillaume Vray, Devavrat Tomar, Xufeng Gao, Jean-Philippe Thiran, Evan Shelhamer, Behzad Bozorgtabar|<http://arxiv.org/pdf/2505.14511v2>|[代码](https://github.com/LTS5/ReservoirTTA.); 提出ReservoirTTA框架，通过在线聚类与多模型策略应对持续变化的测试域，有效提升适应性和稳定...|
|📝 更新|Boosting Adversarial Transferability for Hyperspectral Image Classification Using 3D Structure-invariant Transformation and Weighted Intermediate Feature Divergence|利用三维结构不变变换和加权中间特征散度提升对抗性迁移性用于高光谱图像分类|Chun Liu, Bingqian Zhu, Tao Xu, Zheng Zheng, Zheng Li, Wei Yang, Zhigang Han, Jiayao Wang|<http://arxiv.org/pdf/2506.10459v2>|提出了一种增强高光谱图像分类对抗样本迁移性的方法，通过三维结构不变变换和加权中间特征散度。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Self-Supervised Sparse Sensor Fusion for Long Range Perception|自监督稀疏传感器融合用于远程感知|Edoardo Palladin, Samuel Brucker, Filippo Ghilotti, Praveen Narayanan, Mario Bijelic, Felix Heide|<http://arxiv.org/pdf/2508.13995v1>|提出了一种自监督稀疏传感器融合方法，将自动驾驶车辆感知距离扩展至250米，显著提升物体检测和LiDA...|
|🆕 发布|Augmenting cobots for sheet-metal SMEs with 3D object recognition and localisation|为金属板材中小企业协作机器人增强三维物体识别与定位功能|Martijn Cramer, Yanming Wu, David De Schepper, Eric Demeester|<http://arxiv.org/pdf/2508.13964v1>|将3D对象识别与定位技术集成至协作机器人，提升金属板材中小企业生产自动化水平。|
|📝 更新|SBP-YOLO:A Lightweight Real-Time Model for Detecting Speed Bumps and Potholes|SBP-YOLO：一种轻量级实时检测减速带和坑洞的模型|Chuanqi Liang, Jie Fu, Miao Yu, Lei Luo|<http://arxiv.org/pdf/2508.01339v2>|提出了一种轻量级实时检测框架SBP-YOLO，用于准确识别道路上的减速带和坑洼，提升了嵌入式平台的检...|
|🆕 发布|OmniTry: Virtual Try-On Anything without Masks|全方位试穿：无需遮挡的虚拟试穿一切|Yutong Feng, Linlin Zhang, Hengyuan Cao, Yiming Chen, Xiaoduan Feng, Jian Cao, Yuxiong Wu, Bin Wang|<http://arxiv.org/pdf/2508.13632v1>|[代码](https://omnitry.github.io/.); 提出OmniTry框架，实现无需遮挡的任意穿戴物品虚拟试穿，通过两阶段训练提升定位与一致性。|
|📝 更新|SRMA-Mamba: Spatial Reverse Mamba Attention Network for Pathological Liver Segmentation in MRI Volumes|SRMA-Mamba：用于MRI体积中病理肝脏分割的空间反向Mamba注意力网络|Jun Zeng, Yannan Huang, Elif Keles, Halil Ertugrul Aktas, Gorkem Durak, Nikhil Kumar Tomar, Quoc-Huy Trinh, Deepak Ranjan Nayak .etc.|<http://arxiv.org/pdf/2508.12410v2>|[代码](https://github.com/JunZengz/SRMA-Mamba.); 提出了一种新型网络SRMA-Mamba，通过建模MRI体积数据中的空间关系，实现了高效的病理性肝脏结...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Unlocking the Potential of MLLMs in Referring Expression Segmentation via a Light-weight Mask Decoder|通过轻量级掩膜解码器解锁大规模语言模型在指代表达式分割中的潜力|Jingchao Wang, Zhijian Wu, Dingjiang Huang, Yefeng Zheng, Hong Wang|<http://arxiv.org/pdf/2508.04107v3>|[代码](https://github.com/jcwang0602/MLLMSeg.); 提出了一种轻量级框架MLLMSeg，通过融合多模态大模型视觉细节和语义信息，实现了高效准确的指代表达...|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Latent Interpolation Learning Using Diffusion Models for Cardiac Volume Reconstruction|利用扩散模型进行心脏体积重建的潜在插值学习|Niklas Bubeck, Suprosanna Shit, Chen Chen, Can Zhao, Pengfei Guo, Dong Yang, Georg Zitzlsberger, Daguang Xu .etc.|<http://arxiv.org/pdf/2508.13826v3>|提出基于扩散模型的数据驱动插值方法，高效实现心脏3D重建，无需额外辅助信息。|
|🆕 发布|DiffIER: Optimizing Diffusion Models with Iterative Error Reduction|差分优化迭代误差降低模型：通过迭代误差降低优化扩散模型|Ao Chen, Lihe Ding, Tianfan Xue|<http://arxiv.org/pdf/2508.13628v2>|提出迭代误差减少方法DiffIER，优化扩散模型生成质量，减少训练与推理间的差距。|
|📝 更新|A Novel Image Similarity Metric for Scene Composition Structure|一种用于场景组合结构的新型图像相似性度量方法|Md Redwanul Haque, Manzur Murshed, Manoranjan Paul, Tsz-Kwan Lee|<http://arxiv.org/pdf/2508.05037v2>|提出了一种无需训练的SCSSIM指标，通过统计图像的立方体层次划分，有效评估生成图像场景结构完整性。|
|🆕 发布|Directed-Tokens: A Robust Multi-Modality Alignment Approach to Large Language-Vision Models|“导向令牌：面向大规模语言-视觉模型的一种稳健多模态对齐方法”|Thanh-Dat Truong, Huu-Thien Tran, Tran Thai Son, Bhiksha Raj, Khoa Luu|<http://arxiv.org/pdf/2508.14264v1>|提出了一种新机制，通过重构图像和文本顺序任务增强大规模多模态模型的鲁棒对齐和视觉理解能力。|
|📝 更新|Assessment of Using Synthetic Data in Brain Tumor Segmentation|合成数据在脑肿瘤分割中应用的评估|Aditi Jahagirdar, Sameer Joshi|<http://arxiv.org/pdf/2508.11922v2>|探究了合成数据在脑肿瘤分割中的应用，提高了数据集多样性并优化了肿瘤边界描绘。|
|📝 更新|HouseCrafter: Lifting Floorplans to 3D Scenes with 2D Diffusion Model|《HouseCrafter：利用二维扩散模型将平面图提升至三维场景》|Hieu T. Nguyen, Yiwen Chen, Vikram Voleti, Varun Jampani, Huaizu Jiang|<http://arxiv.org/pdf/2406.20077v2>|[代码](https://neu-vi.github.io/houseCrafter); 提出HouseCrafter方法，将平面图转化为高质量的3D室内场景。|
|🆕 发布|Comparing Conditional Diffusion Models for Synthesizing Contrast-Enhanced Breast MRI from Pre-Contrast Images|比较条件扩散模型在从预处理图像合成对比增强乳腺MRI中的应用|Sebastian Ibarra, Javier del Riego, Alessandro Catanese, Julian Cuba, Julian Cardona, Nataly Leon, Jonathan Infante, Karim Lekadir .etc.|<http://arxiv.org/pdf/2508.13776v1>|[代码](https://github.com/sebastibar/conditional-diffusion-breast-MRI.); 提出了一种基于条件去噪扩散模型的对比增强乳腺MRI合成方法，提高了图像质量并减少了对比剂使用。|
|🆕 发布|Mitigating Cross-Image Information Leakage in LVLMs for Multi-Image Tasks|降低多图像任务中轻量级视觉模型间的跨图像信息泄露|Yeji Park, Minyoung Lee, Sanghyuk Chun, Junsuk Choe|<http://arxiv.org/pdf/2508.13744v1>|提出了一种无训练需求的解码策略FOCUS，有效解决了多图像任务中大型视觉语言模型的信息泄露问题。|
|🆕 发布|HumanPCR: Probing MLLM Capabilities in Diverse Human-Centric Scenes|人类PCR：在多样化以人为中心的场景中探测大规模语言模型的能力|Keliang Li, Hongze Shen, Hao Shi, Ruibing Hou, Hong Chang, Jie Huang, Chenghao Jia, Wen Wang .etc.|<http://arxiv.org/pdf/2508.13692v1>|提出HumanPCR评估套件，通过三个层次全面探测多模态模型在以人为中心场景的理解能力。|
|🆕 发布|State of Abdominal CT Datasets: A Critical Review of Bias, Clinical Relevance, and Real-world Applicability|腹部CT数据集现状：对偏差、临床相关性和实际应用性的批判性回顾|Saeide Danaei, Zahra Dehghanian, Elahe Meftah, Nariman Naderi, Seyed Amir Ahmad Safavi-Naini, Faeze Khorasanizade, Hamid R. Rabiee|<http://arxiv.org/pdf/2508.13626v1>|系统评估腹部CT数据集，提出改进策略以增强AI模型的公平性和临床适用性。|
|🆕 发布|TalkVid: A Large-Scale Diversified Dataset for Audio-Driven Talking Head Synthesis|“TalkVid：一种用于音频驱动说话人头合成的规模化多样化数据集”|Shunian Chen, Hejin Huang, Yexin Liu, Zihan Ye, Pengcheng Chen, Chenghao Zhu, Michael Guan, Rongsheng Wang .etc.|<http://arxiv.org/pdf/2508.13618v1>|[代码](https://github.com/FreedomIntelligence/TalkVid); 提出了TalkVid数据集，增强音频驱动说话人头合成模型的多样性和泛化能力。|
|🆕 发布|Temporal-Conditional Referring Video Object Segmentation with Noise-Free Text-to-Video Diffusion Model|基于无噪声文本到视频扩散模型的时态条件型视频对象分割|Ruixin Zhang, Jiaqing Fan, Yifan Liao, Qian Qiao, Fanzhang Li|<http://arxiv.org/pdf/2508.13584v1>|提出了一种创新的视频对象分割模型，通过集成现有分割方法和文本到视频扩散模型，提升了边界分割能力并简化...|
|📝 更新|Upsample What Matters: Region-Adaptive Latent Sampling for Accelerated Diffusion Transformers|"关注重点上采样：用于加速扩散变换器的区域自适应潜在采样"|Wongi Jeong, Kyungryeol Lee, Hoigi Seo, Se Young Chun|<http://arxiv.org/pdf/2507.08422v2>|提出了一种区域自适应的加速方法，通过在不同分辨率下智能采样，大幅提高了扩散变换器的推理速度并保持了图...|
|📝 更新|Segment Anything in Pathology Images with Natural Language|病理图像中的任意分割与自然语言处理|Zhixuan Chen, Junlin Hou, Liqi Lin, Yihui Wang, Yequan Bie, Xi Wang, Yanning Zhou, Ronald Cheong Kin Chan .etc.|<http://arxiv.org/pdf/2506.20988v2>|提出PathSegmentor模型，利用自然语言提示进行病理图像分割，大幅提升准确性和泛化能力。|
|📝 更新|Dataset Condensation with Color Compensation|数据集浓缩与颜色补偿|Huyu Wu, Duo Su, Junjie Hou, Guang Li|<http://arxiv.org/pdf/2508.01139v2>|[代码](https://github.com/528why/Dataset-Condensation-with-Color-Compensation.); 提出了一种色彩补偿的图像数据集压缩方法，有效提升了压缩后图像的质量和泛化能力。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DictAS: A Framework for Class-Generalizable Few-Shot Anomaly Segmentation via Dictionary Lookup|DictAS：通过字典查找实现类别泛化的少样本异常分割框架|Zhen Qu, Xian Tao, Xinyi Gong, ShiChen Qu, Xiaopei Zhang, Xingang Wang, Fei Shen, Zhengtao Zhang .etc.|<http://arxiv.org/pdf/2508.13560v2>|提出了一种无需目标数据重训练，通过自监督学习实现未见类别异常检测的DictAS框架。|
|🆕 发布|2D Gaussians Meet Visual Tokenizer|二维高斯分布遇见视觉标记器|Yiang Shi, Xiaoyang Guo, Wei Yin, Mingkai Jia, Qian Zhang, Xiaolin Hu, Wenyu Liu, Xinggang Wang|<http://arxiv.org/pdf/2508.13515v2>|提出Visual Gaussian Quantization方法，通过2D高斯分布增强结构化信息建模...|
|📝 更新|UnZipLoRA: Separating Content and Style from a Single Image|《UnZipLoRA：从单张图像中分离内容与风格》|Chang Liu, Viraj Shah, Aiyu Cui, Svetlana Lazebnik|<http://arxiv.org/pdf/2412.04465v2>|提出了一种同时从单一图像中分离主题和风格的方法UnZipLoRA，实现了独立操控和重组图像元素。|
|📝 更新|Natural Language Generation from Visual Events: State-of-the-Art and Key Open Questions|视觉事件的自然语言生成：最新进展与关键开放性问题|Aditya K Surikuchi, Raquel Fernández, Sandro Pezzelle|<http://arxiv.org/pdf/2502.13034v3>|探讨了视觉事件与自然语言生成之间的复杂关系，并提出了未来研究的开放性问题及方向。|
|📝 更新|LoRA-Edit: Controllable First-Frame-Guided Video Editing via Mask-Aware LoRA Fine-Tuning|LoRA-Edit：通过遮罩感知的LoRA微调实现可控的首帧引导视频编辑|Chenjian Gao, Lihe Ding, Xin Cai, Zhanpeng Huang, Zibin Wang, Tianfan Xue|<http://arxiv.org/pdf/2506.10082v5>|[代码](https://cjeen.github.io/LoRAEdit); 提出了一种基于时空掩码的LoRA微调方法，实现了对视频编辑的灵活控制。|
|🆕 发布|Sketch3DVE: Sketch-based 3D-Aware Scene Video Editing|基于草图的三维感知场景视频编辑|Feng-Lin Liu, Shi-Yang Li, Yan-Pei Cao, Hongbo Fu, Lin Gao|<http://arxiv.org/pdf/2508.13797v1>|提出了一种基于草图的三维感知视频编辑方法，能够处理视角变化大的视频结构内容编辑。|
|🆕 发布|PersonaVlog: Personalized Multimodal Vlog Generation with Multi-Agent Collaboration and Iterative Self-Correction|《个性化多模态Vlog生成：多智能体协作与迭代自我校正》|Xiaolu Hou, Bing Ma, Jiaxiang Cheng, Xuhua Ren, Kai Yu, Wenyue Li, Tianxiang Zheng, Qinglin Lu|<http://arxiv.org/pdf/2508.13602v1>|提出了一种自动化的个性化多模态Vlog生成框架，通过多智能体协作和迭代自我修正，提高了内容创造效率和...|
|🆕 发布|Color Spike Data Generation via Bio-inspired Neuron-like Encoding with an Artificial Photoreceptor Layer|通过生物启发神经元编码及人工感光层实现的彩色尖峰数据生成|Hsieh Ching-Teng, Wang Yuan-Kai|<http://arxiv.org/pdf/2508.13558v1>|提出了一种生物启发的神经元编码方法，通过人工感光层生成富含色彩和亮度信息的脉冲数据，有效提升了脉冲神...|
|📝 更新|Diffusion Noise Feature: Accurate and Fast Generated Image Detection|扩散噪声特征：精确且快速的生成图像检测|Yichi Zhang, Xiaogang Xu|<http://arxiv.org/pdf/2312.02625v3>|[代码](https://github.com/YichiCS/Diffusion-Noise-Feature.); 提出Diffusion Noise Feature，通过放大生成图像的高频特征，实现了对生成图像的高...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds|《3D通用模型：用于构建三维世界的自提升视觉-语言-动作模型》|Fan-Yun Sun, Shengguang Wu, Christian Jacobsen, Thomas Yim, Haoming Zou, Alex Zook, Shangru Li, Yu-Hsin Chou .etc.|<http://arxiv.org/pdf/2507.06484v2>|提出了一种自动生成高质量3D环境的3D-Generalist框架，通过自我优化训练提升模型的空间推理...|
|🆕 发布|InfiniteTalk: Audio-driven Video Generation for Sparse-Frame Video Dubbing|无限对话：基于音频驱动的稀疏帧视频配音视频生成|Shaoshu Yang, Zhe Kong, Feng Gao, Meng Cheng, Xiangyu Liu, Yong Zhang, Zhuoliang Kang, Wenhan Luo .etc.|<http://arxiv.org/pdf/2508.14033v1>|提出稀疏帧视频配音新范式，通过 InfiniteTalk 模型实现音频驱动的全身动作同步，提升视觉真...|
|📝 更新|RadGPT: Constructing 3D Image-Text Tumor Datasets|RadGPT：构建三维图像-文本肿瘤数据集|Pedro R. A. S. Bassi, Mehmet Can Yavuz, Kang Wang, Xiaoxi Chen, Wenxuan Li, Sergio Decherchi, Andrea Cavalli, Yang Yang .etc.|<http://arxiv.org/pdf/2501.04678v2>|构建首个带有详细放射学报告的高质量腹部CT数据集，提出RadGPT框架自动生成标准化报告。|
|🆕 发布|ResPlan: A Large-Scale Vector-Graph Dataset of 17,000 Residential Floor Plans|住宅平面图的大规模向量图数据集 ResPlan：17000个住宅平面图|Mohamed Abouagour, Eleftherios Garyfallidis|<http://arxiv.org/pdf/2508.14006v1>|介绍了ResPlan，一个包含17000个详细、结构丰富、真实的住宅平面图的大规模数据集，提升了视觉...|
|🆕 发布|ROVR-Open-Dataset: A Large-Scale Depth Dataset for Autonomous Driving|ROVR-Open-Dataset：面向自动驾驶的大规模深度数据集|Xianda Guo, Ruijun Zhang, Yiqun Duan, Ruilin Wang, Keyuan Zhou, Wenzhao Zheng, Wenke Huang, Gangwei Xu .etc.|<http://arxiv.org/pdf/2508.13977v1>|介绍了大规模、多样化的深度估计数据集ROVR-Open-Dataset，助力自动驾驶领域深度学习模型...|
|🆕 发布|Physics-Based 3D Simulation for Synthetic Data Generation and Failure Analysis in Packaging Stability Assessment|基于物理的3D模拟用于合成数据生成与包装稳定性评估中的故障分析|Samuel Seligardi, Pietro Musoni, Eleonora Iotti, Gianluca Contesso, Alessandro Dal Palù|<http://arxiv.org/pdf/2508.13989v1>|开发了一个物理基础的3D模拟系统，通过生成合成数据和训练神经网络，降低物理测试需求，提高包装稳定性评...|
|🆕 发布|DIME-Net: A Dual-Illumination Adaptive Enhancement Network Based on Retinex and Mixture-of-Experts|DIME-Net：基于Retinex和专家混合的双光照自适应增强网络|Ziang Wang, Xiaoqin Wang, Dingyi Wang, Qiang Li, Shushan Qiao|<http://arxiv.org/pdf/2508.13921v1>|提出了一种统一处理复杂光照条件下图像退化的方法DIME-Net，通过自适应增强框架显著提升图像质量。|
|🆕 发布|SAGA: Learning Signal-Aligned Distributions for Improved Text-to-Image Generation|SAGA：学习信号对齐分布以改进文本到图像生成|Paul Grimal, Michaël Soumm, Hervé Le Borgne, Olivier Ferret, Akihiro Sugimoto|<http://arxiv.org/pdf/2508.13866v1>|[代码](https://github.com/grimalPaul/gsn-factory.); 提出了一种学习信号对齐分布的方法，提高了文本到图像生成的准确性和忠实度。|
|🆕 发布|Bridging Clear and Adverse Driving Conditions|连接清晰与恶劣驾驶条件的环境|Yoel Shapiro, Yahia Showgan, Koustav Mullick|<http://arxiv.org/pdf/2508.13592v1>|提出了一种将晴朗天气图像转换为恶劣环境图像的域自适应方法，有效提升了自动驾驶系统在恶劣条件下的性能。|
|🆕 发布|The 9th AI City Challenge|第九届 AI 城市挑战赛|Zheng Tang, Shuo Wang, David C. Anastasiu, Ming-Ching Chang, Anuj Sharma, Quan Kong, Norimasa Kobori, Munkhjargal Gochoo .etc.|<http://arxiv.org/pdf/2508.13564v1>|推动计算机视觉在交通、工业自动化和公共安全领域的应用，通过四项竞赛任务提升多模态感知与理解能力。|
|📝 更新|VoiceCloak: A Multi-Dimensional Defense Framework against Unauthorized Diffusion-based Voice Cloning|《VoiceCloak：一种针对未授权扩散型声音克隆的多维度防御框架》|Qianyue Hu, Junyan Wu, Wei Lu, Xiangyang Luo|<http://arxiv.org/pdf/2505.12332v4>|[代码](https://voice-cloak.github.io/VoiceCloak); 提出VoiceCloak框架，通过多维防御策略对抗扩散模型实现的非法语音克隆。|
|📝 更新|Enhancing Visual Reliance in Text Generation: A Bayesian Perspective on Mitigating Hallucination in Large Vision-Language Models|增强文本生成中的视觉依赖性：从贝叶斯视角减轻大型视觉-语言模型中的虚构现象|Nanxing Hu, Xiaoyue Duan, Jinchao Zhang, Guoliang Kang|<http://arxiv.org/pdf/2505.19498v2>|提出三方面策略增强大型视觉语言模型在文本生成中对视觉内容的依赖，有效减少无中生有的现象。|
|📝 更新|A Study of the Framework and Real-World Applications of Language Embedding for 3D Scene Understanding|《三维场景理解中语言嵌入框架及其现实应用研究》|Mahmoud Chick Zaouali, Todd Charter, Yehor Karpichev, Brandon Haworth, Homayoun Najjaran|<http://arxiv.org/pdf/2508.05064v2>|整合语言嵌入与3D场景理解技术，拓展了实时三维场景渲染与语义理解的应用范围。|
|📝 更新|Hyperspectral Image Generation with Unmixing Guided Diffusion Model|超光谱图像生成：基于解混引导的扩散模型|Shiyu Shen, Bin Pan, Ziye Zhang, Zhenwei Shi|<http://arxiv.org/pdf/2506.02601v3>|提出了一种基于 hyperspectral unmixing 的扩散模型，有效提升了高光谱图像生成的...|
|📝 更新|Benchmarking Federated Learning for Semantic Datasets: Federated Scene Graph Generation|联邦学习在语义数据集上的基准测试：联邦场景图生成|SeungBum Ha, Taehwan Lee, Jiyoun Lim, Sung Whan Yoon|<http://arxiv.org/pdf/2412.10436v3>|[代码](https://github.com/Seung-B/FL-PSG.); 提出了一种构建联邦学习基准的方法，用于处理复杂语义信息的视觉任务，并通过可控的语义异质性提升了学习性...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Geo4D: Leveraging Video Generators for Geometric 4D Scene Reconstruction|Geo4D：利用视频生成器进行几何四维场景重建|Zeren Jiang, Chuanxia Zheng, Iro Laina, Diane Larlus, Andrea Vedaldi|<http://arxiv.org/pdf/2504.07961v2>|利用预训练视频模型，Geo4D实现了仅用合成数据训练即可准确重构动态场景的4D几何结构。|
|🆕 发布|Shape-from-Template with Generalised Camera|基于广义相机的模板匹配形状重建|Agniva Sengupta, Stefan Zachow|<http://arxiv.org/pdf/2508.13791v1>|提出了一种利用多相机广义模型进行3D形状非刚性配准的新方法，提高了配准准确度。|
|📝 更新|EmoSEM: Segment and Explain Emotion Stimuli in Visual Art|《EmoSEM：在视觉艺术中分割和解释情感刺激》|Jing Zhang, Dan Guo, Zhangbin Li, Meng Wang|<http://arxiv.org/pdf/2504.14658v3>|提出EmoSEM模型，通过情感提示和投影器实现艺术图像情感区域的精准分割与解释。|
|🆕 发布|Deep Biomechanically-Guided Interpolation for Keypoint-Based Brain Shift Registration|深度生物力学引导的插值方法用于基于关键点的脑移位注册|Tiago Assis, Ines P. Machado, Benjamin Zwick, Nuno C. Garcia, Reuben Dorent|<http://arxiv.org/pdf/2508.13762v1>|[代码](https://github.com/tiago-assis/Deep-Biomechanical-Interpolator); 提出了一种基于深度学习的脑移位补偿方法，通过稀疏关键点生成符合生物力学特性的密集位移场，显著提高了准...|
|🆕 发布|A Lightweight Dual-Mode Optimization for Generative Face Video Coding|用于生成人脸视频编码的轻量级双模优化|Zihan Zhang, Shanzhi Yin, Bolin Chen, Ru-Ling Liao, Shiqi Wang, Yan Ye|<http://arxiv.org/pdf/2508.13547v1>|提出了一种结合架构重构和操作优化的轻量级生成人脸视频编码框架，实现了参数和计算量的显著降低。|
|🆕 发布|EAvatar: Expression-Aware Head Avatar Reconstruction with Generative Geometry Priors|表情感知的生成几何先验头部虚拟形象重建：EAvatar|Shikun Zhang, Cunjian Chen, Yiqun Wang, Qiuhong Ke, Yong Li|<http://arxiv.org/pdf/2508.13537v1>|提出EAvatar框架，通过稀疏表情控制和高质三维先验，实现高保真且表情自然的头部重建。|
|📝 更新|Image Augmentation Agent for Weakly Supervised Semantic Segmentation|弱监督语义分割的图像增强智能体|Wangyu Wu, Xianglin Qiu, Siqi Song, Zhenhong Chen, Xiaowei Huang, Fei Ma, Jimin Xiao|<http://arxiv.org/pdf/2412.20439v3>|提出了一种利用大型语言模型和扩散模型自动生成训练图像的方法，显著提升了弱监督语义分割的性能。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GeoSAM2: Unleashing the Power of SAM2 for 3D Part Segmentation|GeoSAM2：释放SAM2在三维部件分割中的力量|Ken Deng, Yunhan Yang, Jingxiang Sun, Xihui Liu, Yebin Liu, Ding Liang, Yan-Pei Cao|<http://arxiv.org/pdf/2508.14036v1>|提出了一种通过数据依赖流在潜在空间建模粗到细转换的方法，有效增强3D形状几何细节。|
|🆕 发布|Online 3D Gaussian Splatting Modeling with Novel View Selection|在线三维高斯散点建模与新颖视角选择|Byeonggwon Lee, Junkyu Park, Khang Truong Giang, Soohwan Song|<http://arxiv.org/pdf/2508.14014v1>|提出了一种自适应视角选择的高质量在线3D建模方法，通过结合关键帧和精选非关键帧，显著提升了模型完整性...|
|🆕 发布|Unleashing Semantic and Geometric Priors for 3D Scene Completion|释放语义和几何先验信息以实现三维场景补全|Shiyuan Chen, Wei Sui, Bohao Zhang, Zeyd Boukhers, John See, Cong Yang|<http://arxiv.org/pdf/2508.13601v1>|提出了一种双解耦框架FoundationSSC，通过分离语义和几何特征，提升了3D场景完成的性能。|
|🆕 发布|Multi-view Clustering via Bi-level Decoupling and Consistency Learning|通过双层解耦和一致性学习的多视角聚类|Shihao Dong, Yuhui Zheng, Huiying Xu, Xinzhong Zhu|<http://arxiv.org/pdf/2508.13499v1>|[代码](https://github.com/LouisDong95/BDCL.); 提出了一种双级解耦与一致性学习的多视角聚类框架，增强了特征间的区分度和紧凑性。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DNF-Avatar: Distilling Neural Fields for Real-time Animatable Avatar Relighting|DNF-Avatar：实时可动画化角色重照明的神经场蒸馏方法|Zeren Jiang, Shaofei Wang, Siyu Tang|<http://arxiv.org/pdf/2504.10486v2>|提出了一种将神经场知识蒸馏到二维高斯散点表示的方法，实现实时高质动画角色重光照。|
|🆕 发布|Is-NeRF: In-scattering Neural Radiance Field for Blurred Images|散射内神经网络辐射场：用于模糊图像的去模糊|Nan Luo, Chenglin Ye, Jiaxu Li, Gang Liu, Bo Wan, Di Wang, Lupeng Liu, Jun Xiao|<http://arxiv.org/pdf/2508.13808v1>|提出了一种显式光路建模的Is-NeRF方法，有效处理运动模糊图像，恢复高保真度场景细节。|
|📝 更新|Spatially-guided Temporal Aggregation for Robust Event-RGB Optical Flow Estimation|空间引导的时间聚合用于鲁棒的事件-RGB光流估计|Qianang Zhou, Junhui Hou, Meiyi Yang, Yongjian Deng, Youfu Li, Junlin Xiong|<http://arxiv.org/pdf/2501.00838v2>|提出了一种利用帧数据引导事件数据聚合的方法，有效融合两种模态的优势，提升了光流估计的准确性。|
|🆕 发布|Enhancing Robustness of Implicit Neural Representations Against Weight Perturbations|增强隐式神经表示对权重扰动的鲁棒性|Wenyong Zhou, Yuxin Cheng, Zhengwu Liu, Taiqiang Wu, Chen Zhang, Ngai Wong|<http://arxiv.org/pdf/2508.13481v1>|首次研究了隐式神经表示的鲁棒性，并提出了一种新损失函数以增强其在权重扰动下的信号重建质量。|
|🆕 发布|Distribution-Aware Hadamard Quantization for Hardware-Efficient Implicit Neural Representations|分布感知的哈达玛量化用于硬件高效隐式神经表示|Wenyong Zhou, Jiachen Ren, Taiqiang Wu, Yuxin Cheng, Zhengwu Liu, Ngai Wong|<http://arxiv.org/pdf/2508.13478v1>|提出了一种分布感知的哈达玛量化方法，同时针对权重和激活函数进行量化，显著提升了隐式神经表示的硬件效率...|
|🆕 发布|MINR: Efficient Implicit Neural Representations for Multi-Image Encoding|多图像编码的高效隐式神经表示：MINR|Wenyong Zhou, Taiqiang Wu, Zhengwu Liu, Yuxin Cheng, Chen Zhang, Ngai Wong|<http://arxiv.org/pdf/2508.13471v1>|提出MINR方法，通过共享中间层高效编码多图像，节省参数达60%且性能相当。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FLAIR: Frequency- and Locality-Aware Implicit Neural Representations|FLAIR：频率和位置感知的隐式神经表示|Sukhun Ko, Dahyeon Kye, Kyle Min, Chanho Eom, Jihyong Oh|<http://arxiv.org/pdf/2508.13544v1>|提出FLAIR方法，通过新型激活函数和波能量引导编码，改善神经表示在频率选择性和空间定位上的不足。|
|🆕 发布|ROVER: Robust Loop Closure Verification with Trajectory Prior in Repetitive Environments|ROVER：在重复环境中利用轨迹先验的鲁棒闭环验证|Jingwen Yu, Jiayi Yang, Anjun Hu, Jiankun Wang, Ping Tan, Hong Zhang|<http://arxiv.org/pdf/2508.13488v1>|[代码](https://github.com/jarvisyjw/ROVER.); 利用历史轨迹作为先验约束，提出ROVER方法以在重复环境中稳健地验证闭环检测。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Survey on Video Anomaly Detection via Deep Learning: Human, Vehicle, and Environment|深度学习在视频异常检测中的研究综述：人类、车辆与环境|Ghazal Alinezhad Noghre, Armin Danesh Pazho, Hamed Tabkhi|<http://arxiv.org/pdf/2508.14203v1>|系统梳理了深度学习在视频异常检测中的应用，分类探讨了人、车、环境三大场景下的方法与挑战。|
|🆕 发布|OmViD: Omni-supervised active learning for video action detection|OmViD：全方位监督主动学习用于视频动作检测|Aayush Rana, Akash Kumar, Vibhav Vineet, Yogesh S Rawat|<http://arxiv.org/pdf/2508.13983v1>|提出了一种自适应标注和伪标签生成的视频动作检测方法，有效降低标注成本同时保持性能。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Forecasting Smog Events Using ConvLSTM: A Spatio-Temporal Approach for Aerosol Index Prediction in South Asia|利用卷积长短时记忆网络预测雾霾事件：南亚气溶胶指数预测的空间时间方法|Taimur Khan|<http://arxiv.org/pdf/2508.13891v1>|利用ConvLSTM神经网络，实现了对南亚地区烟雾事件的五天预测，提高了颗粒物浓度预报准确性。|
|📝 更新|MA-CBP: A Criminal Behavior Prediction Framework Based on Multi-Agent Asynchronous Collaboration|多智能体异步协作的犯罪行为预测框架：MA-CBP|Cheng Liu, Daou Zhang, Tingxu Liu, Yuhan Wang, Jinyang Chen, Yuexuan Li, Xinying Xiao, Chenbo Xin .etc.|<http://arxiv.org/pdf/2508.06189v2>|提出了一种基于多智能体异步协作的犯罪行为预测框架，有效融合实时视频流和历史信息，提前预警公共场景中的...|
|🆕 发布|GazeProphet: Software-Only Gaze Prediction for VR Foveated Rendering|《GazeProphet：仅软件实现的虚拟现实注视点预测技术用于注视点渲染》|Farhaan Ebadulla, Chiraag Mudlapur, Gaurav BV|<http://arxiv.org/pdf/2508.13546v1>|提出了一种不依赖硬件的眼动预测方法GazeProphet，通过软件算法实现VR场景中的注视点预测，降...|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SlotMatch: Distilling Temporally Consistent Object-Centric Representations for Unsupervised Video Segmentation|槽匹配：为无监督视频分割提取时间一致性的以对象为中心的表征|Diana-Nicoleta Grigore, Neelu Madan, Andreas Mogelmose, Thomas B. Moeslund, Radu Tudor Ionescu|<http://arxiv.org/pdf/2508.03411v2>|提出了一种基于知识蒸馏的轻量级无监督视频分割框架SlotMatch，实现了参数减少和性能提升。|
|📝 更新|LEGO: Learning and Graph-Optimized Modular Tracker for Online Multi-Object Tracking with Point Clouds|LEGO：基于学习与图优化模块的在线多目标跟踪点云追踪器|Zhenrong Zhang, Jianan Liu, Yuxuan Xia, Tao Huang, Qing-Long Han, Hongbin Liu|<http://arxiv.org/pdf/2308.09908v5>|提出了一种结合图优化和自注意力机制的模块化追踪器，有效提升了在线多目标追踪中的数据关联性能。|
|🆕 发布|MimicFunc: Imitating Tool Manipulation from a Single Human Video via Functional Correspondence|通过功能对应模仿单一人类视频中的工具操作：MimicFunc|Chao Tang, Anxing Xiao, Yuhong Deng, Tianrun Hu, Wenlong Dong, Hanbo Zhang, David Hsu, Hong Zhang|<http://arxiv.org/pdf/2508.13534v1>|提出MimicFunc框架，通过功能对应关系实现机器人从单个人类视频模仿工具操作并泛化至新工具。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FreqDGT: Frequency-Adaptive Dynamic Graph Networks with Transformer for Cross-subject EEG Emotion Recognition|FreqDGT：基于变换器的频率自适应动态图网络用于跨被试 EEG 情绪识别|Yueyang Li, Shengyu Gong, Weiming Zeng, Nizhuan Wang, Wai Ting Siok|<http://arxiv.org/pdf/2506.22807v3>|[代码](https://github.com/NZWANG/FreqDGT.); 提出FreqDGT模型，通过频率自适应和时空动态学习显著提升跨个体情绪识别准确度。|
|📝 更新|Beyond the Horizon: Decoupling Multi-View UAV Action Recognition via Partial Order Transfer|《超越地平线：通过部分顺序转移解耦多视角无人机动作识别》|Wenxuan Liu, Zhuo Zhou, Xuemei Jia, Siyuan Yang, Wenxin Huang, Xian Zhong, Chia-Wen Lin|<http://arxiv.org/pdf/2504.20530v2>|提出了一种针对不同高度无人机视角变化的分解多视角动作识别方法，通过部分顺序转移显著提升了识别性能。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GALA: Guided Attention with Language Alignment for Open Vocabulary Gaussian Splatting|GALA：基于语言对齐的引导注意力开放词汇高斯散点绘制|Elena Alegret, Kunyi Li, Sen Wang, Siyun Liang, Michael Niemeyer, Stefano Gasperini, Nassir Navab, Federico Tombari|<http://arxiv.org/pdf/2508.14278v2>|提出GALA框架，通过自监督学习和跨注意力模块实现从2D图像到细粒度、语言感知的3D场景理解。|
|📝 更新|Disentangled Representation Learning with the Gromov-Monge Gap|《利用Gromov-Monge差距进行解耦表示学习》|Théo Uscidda, Luca Eyring, Karsten Roth, Fabian Theis, Zeynep Akata, Marco Cuturi|<http://arxiv.org/pdf/2407.07829v3>|提出了一种基于二次最优传输的解耦表示学习方法，通过Gromov-Monge Gap量化几何特征保持，...|


### 掩码自编码 (Masked Autoencoding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Mask and Restore: Blind Backdoor Defense at Test Time with Masked Autoencoder|《遮蔽与恢复：测试时使用遮蔽自动编码器的盲后门防御》|Tao Sun, Lu Pang, Weimin Lyu, Chao Chen, Haibin Ling|<http://arxiv.org/pdf/2303.15564v3>|提出了一种在测试时无需访问验证数据和模型参数的盲后门防御方法，利用掩码自编码器实现图像净化。|


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Understanding and Harnessing the Transferability of Prognostic Knowledge in Computational Pathology|迈向理解与利用计算病理学中预后知识的迁移性|Pei Liu, Luping Ji, Jiaxiang Gou, Xiangxiang Zeng|<http://arxiv.org/pdf/2508.13482v1>|[代码](https://github.com/liupei101/Path-PKT.); 首次研究了病理学中预后知识的迁移性，并提出了一种利用通用预后知识的新方法。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OmniSense: Towards Edge-Assisted Online Analytics for 360-Degree Videos|全方位感知：面向边缘辅助的360度视频在线分析|Miao Zhang, Yifei Zhu, Linfeng Shen, Fangxin Wang, Jiangchuan Liu|<http://arxiv.org/pdf/2508.14237v1>|提出OmniSense框架，通过边缘辅助实现360度视频的低延迟在线分析，提高准确度并优化资源利用。|
|📝 更新|Fluorescence molecular optomic signatures improve identification of tumors in head and neck specimens|荧光分子光学子签名提高头颈标本肿瘤的识别|Yao Chen, Samuel S. Streeter, Brady Hunt, Hira S. Sardar, Jason R. Gunn, Laura J. Tafe, Joseph A. Paydarfar, Brian W. Pogue .etc.|<http://arxiv.org/pdf/2208.13314v2>|提出“optomics”方法，通过分析荧光分子成像数据中的纹理模式差异，提高了头颈肿瘤的识别准确性。|
|🆕 发布|Real-Time, Population-Based Reconstruction of 3D Bone Models via Very-Low-Dose Protocols|通过非常低剂量协议实现实时、基于人群的3D骨骼模型重建|Yiqun Lin, Haoran Sun, Yongqing Li, Rabia Aslam, Lung Fung Tse, Tiange Cheng, Chun Sing Chui, Wing Fung Yau .etc.|<http://arxiv.org/pdf/2508.13947v1>|提出了一种基于低剂量X射线的快速、准确AI框架，实现30秒内重建高质量骨模型，降低辐射并提高临床实用...|
|🆕 发布|A Novel Attention-Augmented Wavelet YOLO System for Real-time Brain Vessel Segmentation on Transcranial Color-coded Doppler|一种用于经颅彩色多普勒实时脑血管分割的新型注意力增强小波YOLO系统|Wenxuan Zhang, Shuai Li, Xinyi Wang, Yu Sun, Hongyu Kang, Pui Yuk Chryste Wan, Yong-Ping Zheng, Sai-Kit Lam|<http://arxiv.org/pdf/2508.13875v1>|提出了一种实时脑血管分割系统，通过注意力增强的波let YOLO网络提高TCCD图像分析精度和速度。|
|🆕 发布|Timestep-Compressed Attack on Spiking Neural Networks through Timestep-Level Backpropagation|通过时间步级别反向传播的时步压缩攻击针对尖峰神经网络|Donghwa Kang, Doohyun Kim, Sang-Ki Ko, Jinkyu Lee, Hyeongboo Baek, Brent ByungHoon Kang|<http://arxiv.org/pdf/2508.13812v1>|提出了一种针对尖峰神经网络的时步压缩攻击方法，大幅降低了攻击延迟。|
|🆕 发布|Automated surgical planning with nnU-Net: delineation of the anatomy in hepatobiliary phase MRI|基于nnU-Net的自动化手术规划：肝胆期MRI中解剖结构的勾画|Karin A. Olthof, Matteo Fusagli, Bianca Güttner, Tiziano Natali, Bram Westerink, Stefanie Speidel, Theo J. M. Ruers, Koert F. D. Kuhlmann .etc.|<http://arxiv.org/pdf/2508.14133v1>|提出了一种基于nnU-Net的自动分割方法，实现了高效准确的肝脏解剖结构勾画，助力术前规划。|
|🆕 发布|DeH4R: A Decoupled and Hybrid Method for Road Network Graph Extraction|道路网络图提取的解耦与混合方法：DeH4R|Dengxian Gong, Shunping Ji|<http://arxiv.org/pdf/2508.13669v1>|[代码](https://github.com/7777777FAN/DeH4R.); 提出了一种结合图生成效率和图增长动态的混合模型DeH4R，实现了动态顶点插入与快速推理，提升了路网提...|
|🆕 发布|Two-Factor Authentication Smart Entryway Using Modified LBPH Algorithm|使用改进的LBPH算法的双因素认证智能入口系统|Zakiah Ayop, Wan Mohamad Hariz Bin Wan Mohamad Rosdi, Looi Wei Hua, Syarulnaziah Anawar, Nur Fadzilah Othman|<http://arxiv.org/pdf/2508.13617v1>|提出了一种结合面部识别和密码验证的两因素认证系统，通过改良的LBPH算法实现口罩检测与智能门禁控制。|
|📝 更新|Identify, Isolate, and Purge: Mitigating Hallucinations in LVLMs via Self-Evolving Distillation|识别、隔离与清除：通过自演化蒸馏减轻LVLMs中的幻觉现象|Wenhao Li, Xiu Su, Jingyi Wu, Feng Yang, Yang Liu, Yi Chen, Shan You, Chang Xu|<http://arxiv.org/pdf/2507.04680v2>|提出SEED方法，通过自我进化蒸馏技术识别并消除大型视觉语言模型中的幻觉问题。|
|🆕 发布|MF-LPR$^2$: Multi-Frame License Plate Image Restoration and Recognition using Optical Flow|多帧车牌图像恢复与识别：基于光流法的MF-LPR$^2$|Kihyun Na, Junseok Oh, Youngkwan Cho, Bumjin Kim, Sungmin Cho, Jinyoung Choi, Injung Kim|<http://arxiv.org/pdf/2508.14797v1>|提出了一种多帧车牌图像恢复与识别框架MF-LPR$^2$，通过帧间对齐和聚合改善图像质量并提升识别准...|
|🆕 发布|Bridging the Gap: Doubles Badminton Analysis with Singles-Trained Models|《缩小差距：使用单打训练模型进行双打羽毛球分析》|Seungheon Baek, Jinhyuk Yun|<http://arxiv.org/pdf/2508.13507v1>|将单人训练的模型迁移至双打羽毛球分析，提高了快速运动中多人物追踪的稳定性和识别精度。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Slot Attention with Re-Initialization and Self-Distillation|带有重初始化和自蒸馏的槽注意力机制|Rongzhen Zhao, Yi Zhao, Juho Kannala, Joni Pajarinen|<http://arxiv.org/pdf/2507.23755v2>|[代码](https://github.com/Genera1Z/DIAS.); 提出方法DIAS，通过重初始化和自蒸馏减少冗余，提升视觉任务中的对象表示准确性。|
|🆕 发布|Fusing Structural Phenotypes with Functional Data for Early Prediction of Primary Angle Closure Glaucoma Progression|融合结构表型与功能数据以实现对原发性闭角型青光眼进展的早期预测|Swati Sharma, Thanadet Chuangsuwanich, Royston K. Y. Tan, Shimna C. Prasad, Tin A. Tun, Shamira A. Perera, Martin L. Buist, Tin Aung .etc.|<http://arxiv.org/pdf/2508.14922v1>|提出了一种结合视神经头结构和视野功能参数的方法，有效预测了原发型闭角青光眼进展速度。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Fully Automated Segmentation of Fiber Bundles in Anatomic Tracing Data|纤维束在解剖追踪数据中的完全自动化分割|Kyriaki-Margarita Bintsi, Yaël Balbastre, Jingjing Wu, Julia F. Lehman, Suzanne N. Haber, Anastasia Yendiki|<http://arxiv.org/pdf/2508.12942v2>|提出了一种基于U-Net架构的自动化纤维束分割方法，提高了稀疏纤维束的检测率和准确性，简化了数据分析...|
|📝 更新|Rethinking Weight-Averaged Model-merging|重新思考加权平均模型合并|Hu Wang, Congbo Ma, Ibrahim Almakky, Ian Reid, Gustavo Carneiro, Mohammad Yaqub|<http://arxiv.org/pdf/2411.09263v5>|[代码](https://github.com/billhhh/Rethink-Merge.); 揭示了权重平均模型合并的内在机制，为无训练模型组合方法的安全性和可靠性提供了透明和系统的理解。|
|📝 更新|RAPNet: A Receptive-Field Adaptive Convolutional Neural Network for Pansharpening|RAPNet：一种适用于全色锐化的感受野自适应卷积神经网络|Tao Tang, Chengxu Yang|<http://arxiv.org/pdf/2507.10461v3>|RAPNet通过内容自适应卷积和注意力机制，优化了高分辨率图像与多光谱图像融合的精度和细节。|
|📝 更新|Rethinking Transformer-Based Blind-Spot Network for Self-Supervised Image Denoising|重新思考基于变换器的盲点网络用于自监督图像去噪|Junyi Li, Zhilu Zhang, Wangmeng Zuo|<http://arxiv.org/pdf/2404.07846v4>|提出了一种改进的基于变压器的盲区网络，通过重新设计注意机制，有效提升了自监督图像去噪的性能。|
|🆕 发布|Learnable SMPLify: A Neural Solution for Optimization-Free Human Pose Inverse Kinematics|可学习SMPLify：一种无需优化的基于神经网络的逆向运动学人体姿态解算方法|Yuchen Yang, Linfeng Dong, Wei Wang, Zhihang Zhong, Xiao Sun|<http://arxiv.org/pdf/2508.13562v1>|[代码](https://github.com/Charrrrrlie/Learnable-SMPLify.); Learnable SMPLify通过单次回归模型替代迭代优化，实现200倍速度提升且保持精度。|
|🆕 发布|AdaptiveAE: An Adaptive Exposure Strategy for HDR Capturing in Dynamic Scenes|自适应曝光策略AdaptiveAE：动态场景下高动态范围成像的HDR捕获|Tianyi Xu, Fan Zhang, Boxin Shi, Tianfan Xue, Yujin Wang|<http://arxiv.org/pdf/2508.13503v1>|提出了一种基于强化学习的自适应曝光策略AdaptiveAE，优化动态场景下HDR成像质量。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ResFlow: Fine-tuning Residual Optical Flow for Event-based High Temporal Resolution Motion Estimation|残差光流微调：面向事件驱动高时间分辨率运动估计|Qianang Zhou, Zhiyu Zhu, Junhui Hou, Yongjian Deng, Youfu Li, Junlin Xiong|<http://arxiv.org/pdf/2412.09105v2>|提出了一种基于残差优化的光学流估计方法，有效解决了事件相机高时间分辨率运动估计中的数据稀疏和缺乏真实...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Effect of Data Augmentation on Conformal Prediction for Diabetic Retinopathy|糖尿病视网膜病变中数据增强对符合预测的影响|Rizwan Ahamed, Annahita Amireskandari, Joel Palko, Carol Laxson, Binod Bhattarai, Prashnna Gyawali|<http://arxiv.org/pdf/2508.14266v1>|研究了数据增强对糖尿病视网膜病变分级中不确定性量化的影响，发现样本混合策略可提高预测准确性和可靠性。|
|🆕 发布|Distilled-3DGS:Distilled 3D Gaussian Splatting|Distilled-3DGS：蒸馏三维高斯散点绘制|Lintao Xiang, Xinkai Chen, Jianhuang Lai, Guangcong Wang|<http://arxiv.org/pdf/2508.14037v1>|[代码](https://github.com/lt-xiang/Distilled-3DGS); 提出首个3D Gaussian Splatting知识蒸馏框架，减少内存消耗，提升渲染效率。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|UltraDfeGAN: Detail-Enhancing Generative Adversarial Networks for High-Fidelity Functional Ultrasound Synthesis|超细节增强生成对抗网络：用于高保真功能超声合成|Zhuo Li, Xuhang Chen, Shuqiang Wang, Bin Yuan, Nou Sotheany, Ngeth Rithea|<http://arxiv.org/pdf/2507.03341v2>|提出了一种GAN框架，通过增强特征模块和归一化技术，有效生成高质量功能超声图像，解决了数据稀缺问题。|
|📝 更新|Automatic Image Colorization with Convolutional Neural Networks and Generative Adversarial Networks|卷积神经网络与生成对抗网络实现的自动图像着色|Changyuan Qiu, Hangrui Cao, Qihan Ren, Ruiyu Li, Yuqing Qiu|<http://arxiv.org/pdf/2508.05068v2>|提出了一种结合卷积神经网络和生成对抗网络的自动图像着色方法，通过分类和对抗学习处理颜色预测的多模态特...|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Rapid Urban Visibility Hotspots: Quantifying Building Vertex Visibility from Connected Vehicle Trajectories using Spatial Indexing|快速城市可视热点：利用空间索引从连接车辆轨迹量化建筑顶点可视性|Artur Grigorev, Adriana-Simona Mihaita|<http://arxiv.org/pdf/2506.03365v2>|提出了一种基于车辆轨迹数据的城市建筑顶点可见性量化方法，通过构建BallTree空间索引高效计算视觉...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LENS: Learning to Segment Anything with Unified Reinforced Reasoning|LENS：使用统一强化推理学习任意分割|Lianghui Zhu, Bin Ouyang, Yuxuan Zhang, Tianheng Cheng, Rui Hu, Haocheng Shen, Longjin Ran, Xiaoxin Chen .etc.|<http://arxiv.org/pdf/2508.14153v1>|[代码](https://github.com/hustvl/LENS.); 引入LENS框架，通过强化学习优化推理过程和分割质量，提升文本提示图像分割的泛化能力。|
|🆕 发布|Backdooring Self-Supervised Contrastive Learning by Noisy Alignment|通过噪声对齐对自监督对比学习的后门攻击|Tuo Chen, Jie Gui, Minjing Dong, Ju Jia, Lanting Fang, Jian Liu|<http://arxiv.org/pdf/2508.14015v1>|[代码](https://github.com/jsrdcht/Noisy-Alignment.); 提出了一种抑制噪声成分的Noisy Alignment方法，提高了自监督对比学习的抗数据投毒攻击能力...|
|🆕 发布|Learning to See Through Flare|通过辉光学习看见透明|Xiaopeng Peng, Heath Gemar, Erin Fleet, Kyle Novak, Abbie Watnik, Grover Swartzlander|<http://arxiv.org/pdf/2508.13907v1>|提出NeuSee系统，通过学习衍射光学元件和图像复原网络，有效抑制激光炫光并提升图像质量。|
|📝 更新|Blending 3D Geometry and Machine Learning for Multi-View Stereopsis|将三维几何与机器学习融合用于多视角立体视觉|Vibhas Vats, Md. Alimoor Reza, David Crandall, Soon-heung Jung|<http://arxiv.org/pdf/2505.03470v3>|集成几何一致性检查的深度学习方法，加速了多视角立体匹配学习过程，实现了新的准确度水平。|
|📝 更新|Enhancing Cost Efficiency in Active Learning with Candidate Set Query|主动学习中通过候选集查询提高成本效率|Yeho Gwon, Sehyun Hwang, Hoyoung Kim, Jungseul Ok, Suha Kwak|<http://arxiv.org/pdf/2502.06209v2>|[代码](https://yehogwon.github.io/csq-al.); 提出了一种高效主动学习方法，通过缩小候选类别集减少标注成本，实现更经济的模型训练。|
|📝 更新|Regional quality estimation for echocardiography using deep learning|使用深度学习进行超声心动图区域质量估计|Gilles Van De Vyver, Svein-Erik Måsøy, Håvard Dalen, Bjørnar Leangen Grenne, Espen Holte, Sindre Hellum Olaisen, John Nyberg, Andreas Østvik .etc.|<http://arxiv.org/pdf/2408.00591v5>|[代码](https://github.com/GillesVanDeVyver/arqee.); 提出了一种区域性的心脏超声图像质量评估方法，通过深度学习显著提升了评估准确性。|
|🆕 发布|FAMNet: Integrating 2D and 3D Features for Micro-expression Recognition via Multi-task Learning and Hierarchical Attention|FAMNet：通过多任务学习和层次化注意力整合2D和3D特征进行微表情识别|Liangyu Fu, Xuecheng Wu, Danlei Huang, Xinyi Yin|<http://arxiv.org/pdf/2508.13483v1>|融合2D与3D卷积网络，通过多任务学习和层次化注意力机制，有效提取微表情的细粒度时空特征。|
|📝 更新|Advancing Toward Robust and Scalable Fingerprint Orientation Estimation: From Gradients to Deep Learning|迈向稳健和可扩展的指纹方向估计：从梯度到深度学习|Amit Kumar Trivedi, Jasvinder Pal Singh|<http://arxiv.org/pdf/2010.11563v2>|提出结合梯度技术和机器学习的混合方法，提升指纹识别系统的准确性和可靠性。|
|🆕 发布|Hierarchy-Consistent Learning and Adaptive Loss Balancing for Hierarchical Multi-Label Classification|层次一致的学习与自适应损失平衡的层次多标签分类|Ruobing Jiang, Mengzhe Liu, Haobing Liu, Yanwei Yu|<http://arxiv.org/pdf/2508.13452v1>|提出HCAL分类器，通过原型对比学习和自适应任务权重机制，解决了层次多标签分类中的结构一致性和损失平...|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EDTalk++: Full Disentanglement for Controllable Talking Head Synthesis|EDTalk++：可控说话人头合成中的完全解耦|Shuai Tan, Bin Ji|<http://arxiv.org/pdf/2508.13442v1>|提出了一种全面解耦的框架EDTalk++，实现了对说话头部合成的独立控制与多模态输入适配。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RotBench: Evaluating Multimodal Large Language Models on Identifying Image Rotation|《RotBench：评估多模态大型语言模型在识别图像旋转方面的性能》|Tianyi Niu, Jaemin Cho, Elias Stengel-Eskin, Mohit Bansal|<http://arxiv.org/pdf/2508.13968v2>|提出RotBench基准，揭示了多模态大语言模型在图像旋转识别任务上的不足。|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unsupervised Urban Tree Biodiversity Mapping from Street-Level Imagery Using Spatially-Aware Visual Clustering|基于空间感知视觉聚类的无需监督城市树木生物多样性制图——利用街景图像|Diaa Addeen Abuhani, Marco Seccaroni, Martina Mazzarello, Imran Zualkernan, Fabio Duarte, Carlo Ratti|<http://arxiv.org/pdf/2508.13814v2>|提出了一种无监督视觉聚类框架，利用街景图像和空间种植模式估计城市树木 biodiversity，无需...|
|📝 更新|WeTok: Powerful Discrete Tokenization for High-Fidelity Visual Reconstruction|我们通：用于高保真视觉重建的强大离散标记化方法|Shaobin Zhuang, Yiwei Guo, Canmiao Fu, Zhipeng Huang, Zeyue Tian, Fangyikang Wang, Ying Zhang, Chen Li .etc.|<http://arxiv.org/pdf/2508.05599v2>|[代码](https://github.com/zhuangshaobin/WeTok.); 提出了一种高效的视觉重建离散标记化方法WeTok，通过分组无查找量化与生成解码，实现了高压缩比下的高...|
|🆕 发布|VisionLaw: Inferring Interpretable Intrinsic Dynamics from Visual Observations via Bilevel Optimization|《VisionLaw：通过双水平优化从视觉观测中推断可解释的内在动态》|Jiajing Lin, Shu Jiang, Qingyuan Zeng, Zhenzhong Wang, Min Jiang|<http://arxiv.org/pdf/2508.13792v1>|提出VisionLaw框架，通过双层优化从视觉观测中推断可解释的内在动力学表达，解决了传统方法在泛化...|
|🆕 发布|Enhancing Targeted Adversarial Attacks on Large Vision-Language Models through Intermediate Projector Guidance|通过中间投影器指导增强对大型视觉-语言模型的有针对性的对抗攻击|Yiming Cao, Yanjie Li, Kaisheng Liang, Yuni Lai, Bin Xiao|<http://arxiv.org/pdf/2508.13739v1>|提出了一种利用中间投影器指导的攻击方法，精确控制对抗性扰动以提升大型视觉语言模型的安全性。|
|🆕 发布|Model-based Multi-object Visual Tracking: Identification and Standard Model Limitations|基于模型的多人视觉跟踪：识别与标准模型局限性|Jan Krejčí, Oliver Kost, Yuxuan Xia, Lennart Svensson, Ondřej Straka|<http://arxiv.org/pdf/2508.13647v1>|将雷达跟踪领域的多目标跟踪方法应用于行人跟踪，揭示了标准点对象模型局限性。|
|📝 更新|WIPES: Wavelet-based Visual Primitives|基于小波的可视基本元素：WIPES|Wenhao Zhang, Hao Zhu, Delong Wu, Di Kang, Linchao Bao, Xun Cao, Zhan Ma|<http://arxiv.org/pdf/2508.12615v2>|提出WIPES，一种基于小波的视觉基元，实现高质量渲染与快速推断，优于现有方法。|
|🆕 发布|Revisiting MLLM Token Technology through the Lens of Classical Visual Coding|重新审视通过经典视觉编码视角的MLLM标记技术|Jinming Liu, Junyan Lin, Yuntao Wei, Kele Shao, Keda Tao, Jianguo Huang, Xudong Yang, Zhibo Chen .etc.|<http://arxiv.org/pdf/2508.13460v1>|将多模态大语言模型token技术与经典视觉编码原理相结合，首次系统比较并促进双方技术提升，为更高效的...|
|🆕 发布|Mitigating Easy Option Bias in Multiple-Choice Question Answering|减轻多选问题回答中的易选项偏差|Hao Zhang, Chen Li, Basura Fernando|<http://arxiv.org/pdf/2508.13428v1>|揭示了视觉问答中的“易选项偏差”问题，并提出工具 GroundAttack 生成难负样本以增强模型评...|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Beyond Simple Edits: Composed Video Retrieval with Dense Modifications|超越简单编辑：具有密集修改的复合视频检索|Omkar Thawakar, Dmitry Demidov, Ritesh Thawkar, Rao Muhammad Anwer, Mubarak Shah, Fahad Shahbaz Khan, Salman Khan|<http://arxiv.org/pdf/2508.14039v1>|[代码](https://github.com/OmkarThawakar/BSE-CoVR); 提出了一种结合视觉和文本信息的新模型，通过密集修改文本实现精细的视频内容检索，达到领先水平。|
|🆕 发布|Hierarchical Vision-Language Retrieval of Educational Metaverse Content in Agriculture|农业教育元宇宙内容的分层视觉-语言检索|Ali Abdari, Alex Falcon, Giuseppe Serra|<http://arxiv.org/pdf/2508.13713v1>|[代码](https://github.com/aliabdari/Agricultural_Metaverse_Retrieval); 提出了一种分层视觉-语言模型，用于表示和检索农业元宇宙教育内容，提高了相关场景的检索效果。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Tooth-Diffusion: Guided 3D CBCT Synthesis with Fine-Grained Tooth Conditioning|《Tooth-Diffusion：在细粒度牙齿条件下引导的三维CBCT合成》|Said Djafar Said, Torkan Gholamalizadeh, Mostafa Mehdipour Ghazi|<http://arxiv.org/pdf/2508.14276v1>|[代码](https://github.com/djafar1/tooth-diffusion.); 提出了一种基于条件扩散框架的3D牙科体积生成方法，通过牙齿级别的二值属性实现精细控制。|
|🆕 发布|SCRNet: Spatial-Channel Regulation Network for Medical Ultrasound Image Segmentation|SCRNet：用于医学超声图像分割的空间-通道调控网络|Weixin Xu, Ziliang Wang|<http://arxiv.org/pdf/2508.13899v1>|提出了一种融合卷积和交叉注意力的SCRNet，有效结合长距离依赖和局部信息，提升医学超声图像分割性能...|
|🆕 发布|RICO: Two Realistic Benchmarks and an In-Depth Analysis for Incremental Learning in Object Detection|RICO：面向目标检测增量学习的两个真实基准与深入分析|Matthias Neuwirth-Trapp, Maarten Bieshaar, Danda Pani Paudel, Luc Van Gool|<http://arxiv.org/pdf/2508.13878v1>|提出两个现实增量学习对象检测基准，揭示了现有方法在适应性和保留旧知识方面的不足。|
|🆕 发布|In-hoc Concept Representations to Regularise Deep Learning in Medical Imaging|"使用自适应概念表示来规范医学成像中的深度学习"|Valentina Corbetta, Floris Six Dijkstra, Regina Beets-Tan, Hoel Kervadec, Kristoffer Wickstrøm, Wilson Silva|<http://arxiv.org/pdf/2508.13880v1>|[代码](https://github.com/Trustworthy-AI-UU-NKI/lcr); 提出LCRReg正则化方法，利用潜在概念表征引导模型学习语义基础特征，增强医学影像模型的鲁棒性。|
|📝 更新|BRISC: Annotated Dataset for Brain Tumor Segmentation and Classification with Swin-HAFNet|BRISC: 用于脑肿瘤分割与分类的Swin-HAFNet标注数据集|Amirreza Fateh, Yasin Rezvani, Sara Moayedi, Sadjad Rezvani, Fatemeh Fateh, Mansoor Fateh|<http://arxiv.org/pdf/2506.14318v2>|提出BRISC MRI数据集并设计基于Swin Transformer的模型，实现脑肿瘤精准分割与分...|
|🆕 发布|Diversity-enhanced Collaborative Mamba for Semi-supervised Medical Image Segmentation|多样性增强的协同Mamba算法用于半监督医学图像分割|Shumeng Li, Jian Zhang, Lei Qi, Luping Zhou, Yinghuan Shi, Yang Gao|<http://arxiv.org/pdf/2508.13712v1>|提出了一种增强多样性的协同Mamba框架，有效提升了半监督医疗图像分割的性能。|
|🆕 发布|Generative Model-Based Feature Attention Module for Video Action Analysis|基于生成模型的特征注意力模块用于视频动作分析|Guiqin Wang, Peng Zhao, Cong Zhao, Jing Huang, Siyan Guo, Shusen Yang|<http://arxiv.org/pdf/2508.13565v1>|[代码](https://github.com/Generative-Feature-Model/GAF.); 提出了一种生成模型注意力模块，通过学习特征语义关系，有效提升视频动作分析的精度和适用性。|
|📝 更新|Stereo-based 3D Anomaly Object Detection for Autonomous Driving: A New Dataset and Baseline|基于立体视觉的自动驾驶三维异常目标检测：一个新的数据集和基线|Shiyi Mu, Zichong Gu, Hanqi Lyu, Yilin Gao, Shugong Xu|<http://arxiv.org/pdf/2507.09214v2>|[代码](https://github.com/shiyi-mu/S3AD-Code); 提出了一种基于立体视觉的3D异常目标检测算法，通过解耦2D和3D训练策略，提高了对任意形状目标的泛化...|
|🆕 发布|Fracture Detection and Localisation in Wrist and Hand Radiographs using Detection Transformer Variants|手腕和手部X射线照片中的骨折检测与定位：采用检测变压器变体的方法|Aditya Bagri, Vasanthakumar Venugopal, Anandakumar D, Revathi Ezhumalai, Kalyan Sivasailam, Bargava Subramanian, VarshiniPriya, Meenakumari K S .etc.|<http://arxiv.org/pdf/2508.14129v1>|本研究利用检测变压器变种模型，提高了手腕和手部X光片骨折检测的准确性和效率。|
|📝 更新|MedVisionLlama: Leveraging Pre-Trained Large Language Model Layers to Enhance Medical Image Segmentation|MedVisionLlama：利用预训练大型语言模型层增强医学图像分割|Gurucharan Marthi Krishna Kumar, Aman Chadha, Janine Mendola, Amir Shmuel|<http://arxiv.org/pdf/2410.02458v3>|[代码](https://github.com/AS-Lab/Marthi-et-al-2025-MedVisionLlama-Pre-Trained-LLM-Layers-to-Enhance-Medical-Image-Segmentation); 集成预训练大型语言模型层提升医学图像分割精度，提出混合注意力机制和多尺度融合块。|
|📝 更新|C2PSA-Enhanced YOLOv11 Architecture: A Novel Approach for Small Target Detection in Cotton Disease Diagnosis|C2PSA增强的YOLOv11架构：一种用于棉花病害诊断中的小目标检测新方法|Kaiyuan Wang, Jixing Liu, Xiaobo Cai|<http://arxiv.org/pdf/2508.12219v2>|提出C2PSA模块优化YOLOv11，提升棉花病害小目标检测精度和速度。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Self-Aware Adaptive Alignment: Enabling Accurate Perception for Intelligent Transportation Systems|自我感知自适应对齐：为智能交通系统实现精确感知|Tong Xiang, Hongxia Zhao, Fenghua Zhu, Yuanyuan Chen, Yisheng Lv|<http://arxiv.org/pdf/2508.13823v1>|提出自感知自适应对齐方法SA3，通过领域自适应提升智能交通系统检测准确度。|
|🆕 发布|Structured Prompting and Multi-Agent Knowledge Distillation for Traffic Video Interpretation and Risk Inference|结构化提示与多智能体知识蒸馏在交通视频解读与风险推理中的应用|Yunxiang Yang, Ningning Xu, Jidong J. Yang|<http://arxiv.org/pdf/2508.13439v1>|提出结构化提示和多智能体知识蒸馏框架，实现高效交通视频解读与风险推断。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|WHALES: A Multi-Agent Scheduling Dataset for Enhanced Cooperation in Autonomous Driving|鲸鱼：一种用于增强自动驾驶中多智能体协作的调度数据集|Yinsong Wang, Siwei Chen, Ziyi Song, Sheng Zhou|<http://arxiv.org/pdf/2411.13340v3>|[代码](https://github.com/chensiweiTHU/WHALES.); 提出首个大规模V2X交互数据集WHALES，引入通信感知调度基准，提升自动驾驶合作感知性能。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CORENet: Cross-Modal 4D Radar Denoising Network with LiDAR Supervision for Autonomous Driving|CORENet：面向自动驾驶的具有激光雷达监督的跨模态四维雷达去噪网络|Fuyang Liu, Jilin Mei, Fangyuan Mao, Chen Min, Yan Xing, Yu Hu|<http://arxiv.org/pdf/2508.13485v1>|提出了一种利用激光雷达监督的跨模态4D雷达去噪网络，有效提高了自动驾驶中雷达点云的检测准确性。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|STER-VLM: Spatio-Temporal With Enhanced Reference Vision-Language Models|STER-VLM：增强参考时空视觉语言模型|Tinh-Anh Nguyen-Nhu, Triet Dao Hoang Minh, Dat To-Thanh, Phuc Le-Gia, Tuan Vo-Lan, Tien-Huy Nguyen|<http://arxiv.org/pdf/2508.13470v1>|STER-VLM通过分解描述、优化帧选择和参考驱动理解，提升了视觉语言模型在交通分析中的细粒度时空理...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AdaRing: Towards Ultra-Light Vision-Language Adaptation via Cross-Layer Tensor Ring Decomposition|AdaRing：通过跨层张量环分解实现超轻量级视觉-语言适应|Ying Huang, Yuanbin Man, Wenqi Jia, Zhengzhong Tu, Junzhou Huang, Miao Yin|<http://arxiv.org/pdf/2508.11870v2>|提出AdaRing框架，通过跨层张量环分解实现大型视觉语言模型的高效轻量级适配。|
|🆕 发布|Towards Efficient Vision State Space Models via Token Merging|通过标记合并实现高效的视觉状态空间模型|Jinyoung Park, Minseok Son, Changick Kim|<http://arxiv.org/pdf/2508.13599v1>|提出了一种针对视觉状态空间模型的token-merging策略，有效提升了计算效率并保持了性能。|


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Evaluating Open-Source Vision Language Models for Facial Emotion Recognition against Traditional Deep Learning Models|评估开源视觉语言模型在面部情感识别中与传统深度学习模型的对比表现|Vamsi Krishna Mulukutla, Sai Supriya Pavarala, Srinivasa Raju Rudraraju, Sridevi Bonthu|<http://arxiv.org/pdf/2508.13524v1>|对比了开源视觉语言模型与传统深度学习模型在面部表情识别上的性能，并提出了结合图像修复的评估流程。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Local Scale Equivariance with Latent Deep Equilibrium Canonicalizer|局部尺度等价性及其与潜在深度平衡规范化的关联|Md Ashiqur Rahman, Chiao-An Yang, Michael N. Cheng, Lim Jun Hao, Jeremiah Jiang, Teck-Yian Lim, Raymond A. Yeh|<http://arxiv.org/pdf/2508.14187v1>|[代码](https://github.com/ashiq24/local-scale-equivariance.); 提出了一种深层平衡规范化器 DEC，有效提升了模型对局部尺度变化的适应性。|
|📝 更新|Cherenkov Imaged Bio-morphological Features Verify Patient Positioning with Deformable Tissue Translocation in Breast Radiotherapy|切伦科夫成像生物形态学特征验证乳腺癌放射治疗中可变形组织移位下的患者定位|Yao Chen, Savannah M. Decker, Petr Bruza, David J. Gladstone, Lesley A. Jarvis, Brian W. Pogue, Kimberley S. Samkoe, Rongxiao Zhang|<http://arxiv.org/pdf/2409.05680v2>|提出了一种基于Cherenkov图像分析的新方法，用于精确量化乳腺癌放疗中组织的全局与局部定位变化。|
|🆕 发布|A Comprehensive Re-Evaluation of Biometric Modality Properties in the Modern Era|现代时期生物识别模态特性的全面重新评估|Rouqaiah Al-Refai, Pankaja Priya Ramasamy, Ragini Ramesh, Patricia Arias-Cabarcos, Philipp Terhörst|<http://arxiv.org/pdf/2508.13874v1>|重新评估生物识别特性，结合专家意见与实证数据，揭示现代生物识别系统的新趋势和挑战。|
|🆕 发布|AIM 2025 challenge on Inverse Tone Mapping Report: Methods and Results|AIM 2025挑战赛：逆向色调映射研究报告——方法与结果|Chao Wang, Francesco Banterle, Bin Ren, Radu Timofte, Xin Lu, Yufeng Peng, Chengjie Ge, Zhijing Sun .etc.|<http://arxiv.org/pdf/2508.13479v1>|本论文综述了AIM 2025挑战赛中67个团队针对从单张标准动态范围图像重建高动态范围图像的逆向色调...|

