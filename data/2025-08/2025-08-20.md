## [UPDATED!] **2025-08-20** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EgoDex: Learning Dexterous Manipulation from Large-Scale Egocentric Video|自我中心视频中的灵巧操作学习：基于大规模数据集的训练方法|Ryan Hoque, Peide Huang, David J. Yoon, Mouli Sivapurapu, Jian Zhang|<http://arxiv.org/pdf/2505.11709v2>|[代码](https://github.com/apple/ml-egodex.); 利用第一视角视频，创建了最大规模的灵巧操作数据集，并通过模仿学习提升了手部轨迹预测。|
|📝 更新|Handle-based Mesh Deformation Guided By Vision Language Model|基于视觉语言模型的把手引导网格变形|Xingpeng Sun, Shiyang Jia, Zherong Pan, Kui Wu, Aniket Bera|<http://arxiv.org/pdf/2506.04562v2>|提出了一种无需训练、基于视觉语言模型的柄部操作网格变形方法，提高了变形质量和自动化程度。|
|📝 更新|Endo-FASt3r: Endoscopic Foundation model Adaptation for Structure from motion|内镜基础模型适应运动结构重建：Endo-FASt3r|Mona Sheikh Zeinoddin, Mobarak I. Hoque, Zafer Tandogdu, Greg Shaw, Matthew J. Clarkson, Evangelos Mazomenos, Danail Stoyanov|<http://arxiv.org/pdf/2503.07204v4>|提出了一种用于内窥镜场景的深度和姿态估计框架Endo-FASt3r，通过改进基础模型和自适应技术，实...|
|🆕 发布|ShizhenGPT: Towards Multimodal LLMs for Traditional Chinese Medicine|《ShizhenGPT：面向传统中医药的多模态大型语言模型》|Junying Chen, Zhenyang Cai, Zhiheng Liu, Yunjin Yang, Rongsheng Wang, Qingying Xiao, Xiangyi Feng, Zhan Su .etc.|<http://arxiv.org/pdf/2508.14706v1>|首次提出针对中医领域的多模态大规模语言模型ShizhenGPT，通过整合大量数据突破数据稀缺性，实现...|
|🆕 发布|Seeing Further on the Shoulders of Giants: Knowledge Inheritance for Vision Foundation Models|站在巨人的肩膀上看得更远：视觉基础模型的知识继承|Jiabo Huang, Chen Chen, Lingjuan Lyu|<http://arxiv.org/pdf/2508.14707v1>|通过联合知识转移与保留，本文提出了一种利用预训练模型构建高效视觉基础模型的新方法。|
|🆕 发布|Virtual Multiplex Staining for Histological Images using a Marker-wise Conditioned Diffusion Model|基于标记条件扩散模型的虚拟多重染色技术在组织学图像中的应用|Hyun-Jic Oh, Junsik Kim, Zhiyi Shi, Yichen Wu, Yu-An Chen, Peter K. Sorger, Hanspeter Pfister, Won-Ki Jeong|<http://arxiv.org/pdf/2508.14681v1>|提出了一种基于预训练潜在扩散模型的虚拟多重染色框架，实现了从H&E图像生成多达18种不同生物标记的彩...|
|📝 更新|Interpreting the linear structure of vision-language model embedding spaces|解读视觉语言模型嵌入空间的线性结构|Isabel Papadimitriou, Huangyuan Su, Thomas Fel, Sham Kakade, Stephanie Gil|<http://arxiv.org/pdf/2504.11695v4>|揭示了视觉语言模型嵌入空间的稀疏线性结构，通过潜在桥梁促进跨模态语义整合。|
|🆕 发布|Locality-aware Concept Bottleneck Model|局部感知概念瓶颈模型|Sujin Jeon, Hyundo Lee, Eungseo Kim, Sanghack Lee, Byoung-Tak Zhang, Inwoo Hwang|<http://arxiv.org/pdf/2508.14562v1>|提出Locality-aware Concept Bottleneck Model，通过原型学习确保...|
|📝 更新|Impact of Clinical Image Quality on Efficient Foundation Model Finetuning|临床图像质量对高效基础模型微调的影响|Yucheng Tang, Pawel Rajwa, Alexander Ng, Yipei Wang, Wen Yan, Natasha Thorley, Aqua Asif, Clare Allen .etc.|<http://arxiv.org/pdf/2508.11864v2>|研究了图像质量对医疗影像基础模型微调的影响，发现高质量图像比例对模型性能至关重要。|
|📝 更新|DuCos: Duality Constrained Depth Super-Resolution via Foundation Model|双性约束深度超分辨率：基于基础模型的实现|Zhiqiang Yan, Zhengxue Wang, Haoye Dong, Jun Li, Jian Yang, Gim Hee Lee|<http://arxiv.org/pdf/2503.04171v2>|提出DuCos框架，利用拉格朗日对偶理论整合约束，结合基础模型提示，提升深度超分辨率精度和泛化能力。|
|🆕 发布|PB-IAD: Utilizing multimodal foundation models for semantic industrial anomaly detection in dynamic manufacturing environments|PB-IAD：利用多模态基础模型进行动态制造环境中的语义工业异常检测|Bernd Hofmann, Albert Scheck, Joerg Franke, Patrick Bruendl|<http://arxiv.org/pdf/2508.14504v1>|提出PB-IAD框架，利用多模态基础模型进行工业异常检测，适应动态生产环境的数据稀疏性和快速适应性需...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|When Better Eyes Lead to Blindness: A Diagnostic Study of the Information Bottleneck in CNN-LSTM Image Captioning Models|当更好的视野导致失明：CNN-LSTM图像字幕模型中信息瓶颈的诊断研究|Hitesh Kumar Gupta|<http://arxiv.org/pdf/2507.18788v2>|发现仅增强视觉基础网络而不配合注意力机制反而降低性能，验证了注意力机制的重要性。|
|🆕 发布|GasTwinFormer: A Hybrid Vision Transformer for Livestock Methane Emission Segmentation and Dietary Classification in Optical Gas Imaging|气体双元变换器：一种用于光学气体成像中牲畜甲烷排放分割与饮食分类的混合视觉变换器|Toqi Tahamid Sarker, Mohamed Embaby, Taminul Islam, Amer AbuGhazaleh, Khaled R Ahmed|<http://arxiv.org/pdf/2508.15057v1>|提出GasTwinFormer模型，实现实时甲烷排放分割与饮食分类，提升效率并首次构建全面牛肉 ca...|
|📝 更新|Efficient Long-duration Talking Video Synthesis with Linear Diffusion Transformer under Multimodal Guidance|基于多模态引导的线性扩散变换器实现的长时间对话视频高效合成|Haojie Zhang, Zhihao Liang, Ruibo Fu, Bingyan Liu, Zhengqi Wen, Xuefei Liu, Jianhua Tao, Yaling Liang|<http://arxiv.org/pdf/2411.16748v3>|提出了一种结合多模态指导和记忆库机制的扩散变换器框架，实现了高质量、高效率的长时 talking 视...|
|🆕 发布|Vivid-VR: Distilling Concepts from Text-to-Video Diffusion Transformer for Photorealistic Video Restoration|生动-VR：从文本到视频扩散变换器中提炼概念以实现逼真视频修复|Haoran Bai, Xiaoxu Chen, Canqian Yang, Zongyao He, Sibin Deng, Ying Chen|<http://arxiv.org/pdf/2508.14483v1>|[代码](https://github.com/csbhr/Vivid-VR.); Vivid-VR通过概念蒸馏训练策略和改进的控制架构，解决了视频修复中的分布偏移问题，实现了高质量的...|
|🆕 发布|Taming Transformer for Emotion-Controllable Talking Face Generation|驯服Transformer以实现情感可控的说话面部生成|Ziqi Zhang, Cheng Deng|<http://arxiv.org/pdf/2508.14359v1>|提出了一种利用情感锚点表示和自回归变换器的方法，实现了基于特定音频的情感可控说话面部生成。|
|📝 更新|MMHMER:Multi-viewer and Multi-task for Handwritten Mathematical Expression Recognition|多视角与多任务手写数学表达式识别：MMHMER|Kehua Chen, Haoyang Shen, Lifan Zhong, Mingyi Chen|<http://arxiv.org/pdf/2502.05557v3>|提出了一种融合CNN与Transformer的多视角、多任务框架，有效提升手写数学表达式识别性能。|
|📝 更新|ViT-FIQA: Assessing Face Image Quality using Vision Transformers|ViT-FIQA:基于视觉变换器的面部图像质量评估|Andrea Atzori, Fadi Boutros, Naser Damer|<http://arxiv.org/pdf/2508.13957v2>|提出ViT-FIQA，利用Vision Transformer架构评估人脸图像质量，实现高效的人脸识...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ABC: Achieving Better Control of Multimodal Embeddings using VLMs|ABC: 利用大型语言模型实现多模态嵌入的更好控制|Benjamin Schneider, Florian Kerschbaum, Wenhu Chen|<http://arxiv.org/pdf/2503.00329v2>|[代码](https://tiger-ai-lab.github.io/ABC); 提出ABC模型，利用视觉语言模型深度整合图像特征与自然语言指令，提升多模态嵌入表示的性能和用户控制力...|
|📝 更新|MetaWild: A Multimodal Dataset for Animal Re-Identification with Environmental Metadata|《MetaWild：一种结合环境元数据的动物重识别多模态数据集》|Yuzhuo Li, Di Zhao, Tingrui Qiao, Yihao Wu, Bo Pang, Yun Sing Koh|<http://arxiv.org/pdf/2501.13368v2>|提出MetaWild数据集，结合环境元数据提升动物重识别性能。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|BoostTrack++: using tracklet information to detect more objects in multiple object tracking|BoostTrack++：利用轨迹信息在多目标跟踪中检测更多对象|Vukašin Stanojević, Branimir Todorović|<http://arxiv.org/pdf/2408.13003v2>|[代码](https://github.com/vukasin-stanojevic/BoostTrack); 利用跟踪信息提升多目标跟踪中低置信度检测的准确性，提出结合形状、距离和软BIoU相似度的置信度增强技...|
|📝 更新|AlphaDent: A dataset for automated tooth pathology detection|AlphaDent：自动化牙齿病理检测数据集|Evgeniy I. Sosnin, Yuriy L. Vasilev, Roman A. Solovyev, Aleksandr L. Stempkovskiy, Dmitry V. Telpukhov, Artem A. Vasilev, Aleksandr A. Amerikanov, Aleksandr Y. Romanov|<http://arxiv.org/pdf/2507.22512v2>|介绍了AlphaDent数据集，用于牙齿病变自动检测的实例分割任务，并通过实验验证了其预测的高质量。|
|🆕 发布|SMTrack: End-to-End Trained Spiking Neural Networks for Multi-Object Tracking in RGB Videos|SMTrack：用于RGB视频中多目标跟踪的端到端训练尖峰神经网络|Pengzhi Zhong, Xinzhe Wang, Dan Zeng, Qihua Zhou, Feixiang He, Shuiwang Li|<http://arxiv.org/pdf/2508.14607v1>|首次提出基于直接训练的脉冲神经网络进行标准RGB视频中的多目标跟踪，引入自适应归一化Wasserst...|
|🆕 发布|Incremental Object Detection with Prompt-based Methods|基于提示方法的增量目标检测|Matthias Neuwirth-Trapp, Maarten Bieshaar, Danda Pani Paudel, Luc Van Gool|<http://arxiv.org/pdf/2508.14599v1>|首次将视觉提示方法应用于增量目标检测，并通过结合数据重放技术实现了最佳性能。|
|🆕 发布|Inter-Class Relational Loss for Small Object Detection: A Case Study on License Plates|小目标检测中的类间关系损失：以车牌为例的研究|Dian Ning, Dong Seog Han|<http://arxiv.org/pdf/2508.14343v1>|提出了一种基于对象间关系的损失函数，有效提升了小目标检测性能。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Revisiting Out-of-Distribution Detection in Real-time Object Detection: From Benchmark Pitfalls to a New Mitigation Paradigm|重新审视实时目标检测中的分布外检测：从基准测试陷阱到新的缓解范式|Changshun Wu, Weicheng He, Chih-Hong Cheng, Xiaowei Huang, Saddek Bensalem|<http://arxiv.org/pdf/2503.07330v3>|揭示了现有OoD检测基准的缺陷，并提出了一种通过训练时合成数据集来减少检测模型幻觉误差的新方法。|
|📝 更新|CaLiV: LiDAR-to-Vehicle Calibration of Arbitrary Sensor Setups|任意传感器设置的激光雷达至车辆标定：CaLiV|Ilir Tahiraj, Markus Edinger, Dominik Kulmer, Markus Lienkamp|<http://arxiv.org/pdf/2504.01987v2>|[代码](https://github.com/TUMFTM/CaLiV.); 提出了一种无需外部设备和视场重叠的多LiDAR系统Sensor-to-Sensor和Sensor-t...|
|🆕 发布|You Only Pose Once: A Minimalist's Detection Transformer for Monocular RGB Category-level 9D Multi-Object Pose Estimation|您只需定位一次：单目RGB类别级9D多目标姿态估计的极简主义检测变换器|Hakjin Lee, Junghoon Seo, Jaehoon Sim|<http://arxiv.org/pdf/2508.14965v1>|提出了一种简单高效的检测变压器框架YOPO，实现了仅用RGB图像进行类别级9D多目标姿态估计。|
|🆕 发布|Paired-Sampling Contrastive Framework for Joint Physical-Digital Face Attack Detection|联合物理-数字人脸攻击检测的配对采样对比框架|Andrei Balykin, Anvar Ganiev, Denis Kondranin, Kirill Polevoda, Nikolai Liudkevich, Artem Petrov|<http://arxiv.org/pdf/2508.14980v1>|[代码](https://github.com/xPONYx/iccv2025_deepfake_challenge.); 提出了一种统一的活体检测框架，通过自动匹配真实与攻击样本对学习通用活体特征，提高了对抗物理与数字攻击...|
|🆕 发布|EventSSEG: Event-driven Self-Supervised Segmentation with Probabilistic Attention|事件驱动自监督分割的概率注意力模型(EventSSEG: Event-driven Self-Supervised Segmentation with Probabilistic Attention)|Lakshmi Annamalai, Chetan Singh Thakur|<http://arxiv.org/pdf/2508.14856v1>|提出EventSSEG方法，利用事件相机和概率注意力机制实现无需大量标注数据的道路分割。|
|🆕 发布|6-DoF Object Tracking with Event-based Optical Flow and Frames|基于事件光流和帧的六自由度目标跟踪|Zhichao Li, Arren Glover, Chiara Bartolozzi, Lorenzo Natale|<http://arxiv.org/pdf/2508.14776v1>|提出了一种结合事件相机光流与RGB图像全局位姿估计的高速物体六自由度跟踪方法。|
|📝 更新|MoE-FFD: Mixture of Experts for Generalized and Parameter-Efficient Face Forgery Detection|MoE-FFD：用于泛化和参数高效的人脸伪造检测的专家混合模型|Chenqi Kong, Anwei Luo, Peijun Bao, Yi Yu, Haoliang Li, Zengwei Zheng, Shiqi Wang, Alex C. Kot|<http://arxiv.org/pdf/2404.08452v3>|[代码](https://github.com/LoveSiameseCat/MoE-FFD.); 提出了一种参数高效的混合专家模型MoE-FFD，结合全局与局部特征，提升人脸伪造检测性能并降低资源需...|
|🆕 发布|Towards PerSense++: Advancing Training-Free Personalized Instance Segmentation in Dense Images|面向PerSense++：在密集图像中推进无需训练的个性化实例分割|Muhammad Ibraheem Siddiqui, Muhammad Umer Sheikh, Hassan Abid, Kevin Henry, Muhammad Haris Khan|<http://arxiv.org/pdf/2508.14660v1>|提出了一种无需训练的个性化实例分割框架PerSense++，通过密度图和多种策略有效应对复杂场景中的...|
|📝 更新|CoT-Segmenter: Enhancing OOD Detection in Dense Road Scenes via Chain-of-Thought Reasoning|CoT-Segmenter：通过链式思维推理增强密集道路场景中的OOD检测|Jeonghyo Song, Kimin Yun, DaeUng Jo, Jinyoung Kim, Youngjoon Yoo|<http://arxiv.org/pdf/2507.03984v2>|提出了一种基于Chain-of-Thought推理的OOD检测框架，有效提升了复杂道路场景中异常目标...|
|📝 更新|Self-supervised Learning of LiDAR 3D Point Clouds via 2D-3D Neural Calibration|结果： 通过2D-3D神经校准的自监督学习LiDAR三维点云|Yifan Zhang, Junhui Hou, Siyu Ren, Jinjian Wu, Yixuan Yuan, Guangming Shi|<http://arxiv.org/pdf/2401.12452v5>|[代码](https://github.com/Eaphan/NCLR.); 引入了一种自监督学习框架NCLR，通过2D-3D神经校准提升自动驾驶场景中3D感知能力。|
|🆕 发布|Learning Point Cloud Representations with Pose Continuity for Depth-Based Category-Level 6D Object Pose Estimation|学习具有姿态连续性的点云表示用于基于深度的类别级6D物体姿态估计|Zhujun Li, Shuo Zhang, Ioannis Stamos|<http://arxiv.org/pdf/2508.14358v1>|[代码](https://github.com/zhujunli1993/HRC-Pose.); 提出了一种深度学习框架HRC-Pose，通过对比学习保持6D姿态连续性，提高了姿态估计的准确性和泛化...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Fast Graph Neural Network for Image Classification|快速图神经网络在图像分类中的应用|Mustafa Mohammadi Gharasuie, Luis Rueda|<http://arxiv.org/pdf/2508.14958v1>|结合图卷积网络与Voronoi图，提出高效图像分类方法，提升预处理效率和分类准确度。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Side Effects of Erasing Concepts from Diffusion Models|《从扩散模型中擦除概念的副作用》|Shaswati Saha, Sourajit Saha, Manas Gaur, Tejas Gokhale|<http://arxiv.org/pdf/2508.15124v1>|揭示了概念擦除技术在防止目标概念生成方面的不足，并提出了相应的副作用评估方法。|
|🆕 发布|Squeezed Diffusion Models|压缩扩散模型|Jyotirmai Singh, Samar Khanna, James Burgess|<http://arxiv.org/pdf/2508.14871v1>|引入了Squeezed Diffusion Models，通过数据依赖方式调整噪声，提高了生成模型的...|
|📝 更新|What Makes for Good Image Captions?|什么构成了好的图像标题？|Delong Chen, Samuel Cahyawijaya, Etsuko Ishii, Ho Shu Chan, Yejin Bang, Pascale Fung|<http://arxiv.org/pdf/2405.00485v3>|提出信息论框架优化图像字幕，平衡信息充分性、最小冗余和易读性，并通过Pyramid of Capti...|
|🆕 发布|Fusing Monocular RGB Images with AIS Data to Create a 6D Pose Estimation Dataset for Marine Vessels|将单目RGB图像与AIS数据融合创建船舶六自由度位姿估计数据集|Fabian Holst, Emre Gülsoylu, Simone Frintrop|<http://arxiv.org/pdf/2508.14767v1>|提出了一种融合单目RGB图像与AIS数据生成船舶6D姿态估计数据集的新方法，提高了定位精度。|
|📝 更新|Neural Restoration of Greening Defects in Historical Autochrome Photographs Based on Purely Synthetic Data|基于纯合成数据的神经修复历史自动着色照片中的绿化缺陷|Saptarshi Neil Sinha, P. Julius Kuehn, Johannes Koppe, Arjan Kuijper, Michael Weinmann|<http://arxiv.org/pdf/2505.22291v2>|首次提出利用合成数据训练生成式AI模型，自动修复历史彩色照片中的绿色缺陷问题。|
|📝 更新|Identity Preserving 3D Head Stylization with Multiview Score Distillation|保持身份的3D头像风格化与多视角评分蒸馏|Bahri Batuhan Bilecen, Ahmet Berke Gokmen, Furkan Guzelant, Aysegul Dundar|<http://arxiv.org/pdf/2411.13536v3>|[代码](https://three-bee.github.io/head_stylization); 提出了一种多视角评分蒸馏框架，有效提升了3D头像风格化中身份特征的保持和风格化质量。|
|🆕 发布|GSFix3D: Diffusion-Guided Repair of Novel Views in Gaussian Splatting|GSFix3D：高斯散点法中新颖视角的扩散引导修复|Jiaxin Wei, Stefan Leutenegger, Simon Schaefer|<http://arxiv.org/pdf/2508.14717v1>|提出GSFix3D框架，利用扩散模型提升三维场景渲染质量，尤其针对极端视角和部分观测区域。|
|📝 更新|DiffIER: Optimizing Diffusion Models with Iterative Error Reduction|差分优化迭代误差降低模型：通过迭代误差降低优化扩散模型|Ao Chen, Lihe Ding, Tianfan Xue|<http://arxiv.org/pdf/2508.13628v2>|提出迭代误差减少方法DiffIER，优化扩散模型生成质量，减少训练与推理间的差距。|
|🆕 发布|Reliable Smoke Detection via Optical Flow-Guided Feature Fusion and Transformer-Based Uncertainty Modeling|通过光流引导的特征融合与基于变换器的 uncertainty 模型进行可靠的烟雾检测|Nitish Kumar Mahala, Muzammil Khan, Pushpendra Kumar|<http://arxiv.org/pdf/2508.14597v1>|提出了一种融合光流引导特征和基于Transformer的不确定性建模的烟雾检测方法，提高了火灾早期预...|
|📝 更新|Reconstruction-Free Anomaly Detection with Diffusion Models|基于扩散模型的无需重构异常检测|Shunsuke Sakai, Xiangteng He, Chunzhi Gu, Leonid Sigal, Tatsuhito Hasegawa|<http://arxiv.org/pdf/2504.05662v2>|提出了一种无需重构的异常检测方法，通过在潜在空间中添加噪声直接推断图像的潜在变量，提高了检测效率和准...|
|🆕 发布|Improving OCR using internal document redundancy|利用文档内部冗余性提高光学字符识别精度|Diego Belzarena, Seginus Mowlavi, Aitor Artola, Camilo Mariño, Marina Gardella, Ignacio Ramírez, Antoine Tadros, Roy He .etc.|<http://arxiv.org/pdf/2508.14557v1>|利用文档内部字符形状冗余性，提出了一种无监督的OCR校正方法，提高了低质量数据的识别准确度。|
|📝 更新|BadBlocks: Low-Cost and Stealthy Backdoor Attacks Tailored for Text-to-Image Diffusion Models|BadBlocks：针对文本到图像扩散模型的低成本且隐蔽的后门攻击|Yu Pan, Jiahao Chen, Lin Wang, Bingrong Dai, Yi Du|<http://arxiv.org/pdf/2508.03221v3>|提出了一种低成本且隐蔽的后门攻击方法BadBlocks，专门针对文本到图像的扩散模型，能在有限资源下...|
|📝 更新|Consistent and Optimal Solution to Camera Motion Estimation|相机运动估计的一致性和最优解法|Guangyang Zeng, Qingcheng Zeng, Xinghan Li, Biqiang Mu, Jiming Chen, Ling Shi, Junfeng Wu|<http://arxiv.org/pdf/2403.01174v2>|提出了一种新的相机运动估计算法，通过最大似然准则和两步优化方法，实现了高精度和线性时间复杂度。|
|🆕 发布|Fine-grained Image Quality Assessment for Perceptual Image Restoration|细粒度图像质量评估用于感知图像恢复|Xiangfei Sheng, Xiaofeng Pan, Zhichao Yang, Pengfei Chen, Leida Li|<http://arxiv.org/pdf/2508.14475v1>|[代码](https://pxf0429.github.io/FGResQ); 提出了首个针对图像修复的细粒度图像质量评估数据集和模型，显著提升了质量评估准确性。|
|🆕 发布|Ouroboros: Single-step Diffusion Models for Cycle-consistent Forward and Inverse Rendering|《乌洛波洛斯：用于循环一致的正向和逆向渲染的单步扩散模型》|Shanlin Sun, Yifan Wang, Hanwen Zhang, Yifeng Xiong, Qin Ren, Ruogu Fang, Xiaohui Xie, Chenyu You|<http://arxiv.org/pdf/2508.14461v1>|提出了一种双向互强化的单步扩散模型框架Ouroboros，实现了快速且具有循环一致性的正向和逆向渲染...|
|📝 更新|Marrying Autoregressive Transformer and Diffusion with Multi-Reference Autoregression|将自回归变换器与扩散结合的多参考自回归方法|Dingcheng Zhen, Qian Qiao, Xu Zheng, Tan Yu, Kangxi Wu, Ziwei Zhang, Siyuan Liu, Shunshun Yin .etc.|<http://arxiv.org/pdf/2506.09482v3>|结合自回归变换器和扩散模型，提出了一种新的图像生成方法，大幅提升了生成图像质量和效率。|
|📝 更新|Six-CD: Benchmarking Concept Removals for Benign Text-to-image Diffusion Models|六重消解：针对良性文本到图像扩散模型的概念移除基准测试|Jie Ren, Kangrui Chen, Yingqian Cui, Shenglai Zeng, Hui Liu, Yue Xing, Jiliang Tang, Lingjuan Lyu|<http://arxiv.org/pdf/2406.14855v3>|提出Six-CD数据集和评价指标，全面评估文本到图像模型中的概念移除效果。|
|🆕 发布|HyperDiff: Hypergraph Guided Diffusion Model for 3D Human Pose Estimation|超图引导扩散模型 HyperDiff：用于三维人体姿态估计|Bing Han, Yuhua Huang, Pan Gao|<http://arxiv.org/pdf/2508.14431v1>|提出HyperDiff方法，结合扩散模型与HyperGCN，有效解决3D人体姿态估计中的深度模糊和遮...|
|🆕 发布|FOCUS: Frequency-Optimized Conditioning of DiffUSion Models for mitigating catastrophic forgetting during Test-Time Adaptation|FOCUS：频率优化条件扩散模型以减轻测试时适应过程中的灾难性遗忘|Gabriel Tjio, Jie Zhang, Xulei Yang, Yun Xing, Nhat Chung, Xiaofeng Cao, Ivor W. Tsang, Chee Keong Kwoh .etc.|<http://arxiv.org/pdf/2508.14437v1>|提出了一种基于频率优化的条件扩散模型FOCUS，有效缓解了测试时适应中的灾难性遗忘问题。|
|🆕 发布|Disentanglement in T-space for Faster and Distributed Training of Diffusion Models with Fewer Latent-states|T空间中的解耦以提高少量潜在状态扩散模型的训练速度和分布式训练|Samarth Gupta, Raghudeep Gadde, Rui Chen, Aleix M. Martinez|<http://arxiv.org/pdf/2508.14413v1>|提出减少潜在状态数量以加速训练扩散模型，实现单潜在状态下的高质量样本生成。|
|📝 更新|Improving Token-based Object Detection with Video|基于令牌的对象检测通过视频进行改进|Abhineet Singh, Nilanjan Ray|<http://arxiv.org/pdf/2506.22562v2>|提出了一种基于可变长度离散令牌序列的视频对象检测方法，通过输出完整的3D盒子或轨迹，避免了传统检测器...|
|🆕 发布|Physics-Constrained Diffusion Reconstruction with Posterior Correction for Quantitative and Fast PET Imaging|基于物理约束的扩散重建及后验校正用于定量和快速PET成像|Yucun Hou, Fenglin Zhan, Chenxi Li, Ziquan Yuan, Haoyu Lu, Yue Chen, Yihao Chen, Kexin Wang .etc.|<http://arxiv.org/pdf/2508.14364v1>|提出了一种结合物理约束和后验校正的扩散模型，实现了快速准确的PET图像重建。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CurveFlow: Curvature-Guided Flow Matching for Image Generation|曲线流：基于曲率引导的流匹配图像生成方法|Yan Luo, Drake Du, Hao Huang, Yi Fang, Mengyu Wang|<http://arxiv.org/pdf/2508.15093v1>|[代码](https://github.com/Harvard-AI-and-Robotics-Lab/CurveFlow.); 引入CurveFlow，通过曲率指导优化轨迹，提升文本到图像生成的语义一致性及图像质量。|
|🆕 发布|HiRQA: Hierarchical Ranking and Quality Alignment for Opinion-Unaware Image Quality Assessment|HiRQA：层次化排序与质量对准的无观点图像质量评估|Vaishnav Ramesh, Haining Wang, Md Jahidul Islam|<http://arxiv.org/pdf/2508.15130v1>|提出HiRQA框架，通过自监督学习和对比学习实现无参考图像质量评估，无需原始参考图像即可预测质量分数...|
|🆕 发布|TAIGen: Training-Free Adversarial Image Generation via Diffusion Models|TAIGen：基于扩散模型的无需训练的对抗性图像生成|Susim Roy, Anubhooti Jain, Mayank Vatsa, Richa Singh|<http://arxiv.org/pdf/2508.15020v1>|提出了一种无需训练的TAIGen方法，通过少量采样步骤实现高效的对抗图像生成。|
|📝 更新|Translating Images to Road Network: A Sequence-to-Sequence Perspective|将图像转化为道路网络：一种序列到序列的视角|Jiachen Lu, Ming Nie, Bozhou Zhang, Reyuan Peng, Xinyue Cai, Hang Xu, Feng Wen, Wei Zhang .etc.|<http://arxiv.org/pdf/2402.08207v3>|提出了一种将图像转换为道路网络的序列到序列方法，有效整合了欧几里得和非欧几里得结构，提升了道路网络提...|
|📝 更新|Evaluation Agent: Efficient and Promptable Evaluation Framework for Visual Generative Models|评估代理：面向视觉生成模型的高效且可提示的评估框架|Fan Zhang, Shulin Tian, Ziqi Huang, Yu Qiao, Ziwei Liu|<http://arxiv.org/pdf/2412.09645v3>|提出了一种高效的视觉生成模型评估框架Evaluation Agent，通过少量样本实现动态多轮评估，...|
|🆕 发布|Virtual Community: An Open World for Humans, Robots, and Society|虚拟社区：人类、机器人与社会的开放世界|Qinhong Zhou, Hongxin Zhang, Xiangye Lin, Zheyuan Zhang, Yutian Chen, Wenjun Liu, Zunzhe Zhang, Sunli Chen .etc.|<http://arxiv.org/pdf/2508.14893v1>|构建开放世界虚拟社区平台，研究人机协作与共存的新模式。|
|🆕 发布|MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds|网格编码器：基于大规模语言模型的点云到结构化网格代码生成|Bingquan Dai, Li Ray Luo, Qihong Tang, Jie Wang, Xinyu Lian, Hao Xu, Minghan Qin, Xudong Xu .etc.|<http://arxiv.org/pdf/2508.14879v1>|提出MeshCoder框架，利用大型语言模型将点云转换为可编辑的Blender Python脚本，实...|
|🆕 发布|Tinker: Diffusion's Gift to 3D--Multi-View Consistent Editing From Sparse Inputs without Per-Scene Optimization|“Tinker：扩散赋予3D的礼物——无需逐场景优化的稀疏输入下的多视角一致性编辑”|Canyu Zhao, Xiaoman Li, Tianjian Feng, Zhiyue Zhao, Hao Chen, Chunhua Shen|<http://arxiv.org/pdf/2508.14811v1>|[代码](https://aim-uofa.github.io/Tinker); 提出了Tinker框架，利用预训练扩散模型实现无需逐场景优化的高效3D多视角编辑。|
|📝 更新|MAViS: A Multi-Agent Framework for Long-Sequence Video Storytelling|多智能体框架：用于长序列视频故事讲述的MAViS|Qian Wang, Ziqi Huang, Ruoxi Jia, Paul Debevec, Ning Yu|<http://arxiv.org/pdf/2508.08487v3>|提出MAViS框架，通过多智能体协作实现高质量、高表达性的长序列视频生成。|
|📝 更新|Dark Miner: Defend against undesirable generation for text-to-image diffusion models|《暗矿工：针对文本到图像扩散模型的不期望生成进行防御》|Zheling Meng, Bo Peng, Xiaochuan Jin, Yue Jiang, Wei Wang, Jing Dong, Tieniu Tan|<http://arxiv.org/pdf/2409.17682v3>|提出Dark Miner方法，通过三阶段循环流程有效减少文本到图像模型生成不当内容的风险。|
|🆕 发布|Controllable Latent Space Augmentation for Digital Pathology|数字病理学中的可控潜在空间增强|Sofiène Boutaj, Marin Scalbert, Pierre Marza, Florent Couzinie-Devy, Maria Vakalopoulou, Stergios Christodoulidis|<http://arxiv.org/pdf/2508.14588v1>|[代码](https://github.com/MICS-Lab/HistAug.); 提出了一种高效生成模型HistAug，通过在潜在空间进行可控增强，有效提升数字病理学中WSI分析的模...|
|🆕 发布|Adversarial Generation and Collaborative Evolution of Safety-Critical Scenarios for Autonomous Vehicles|自动驾驶车辆安全关键场景的对抗性生成与协同演化|Jiangfan Liu, Yongkang Guo, Fangzhi Zhong, Tianyuan Zhang, Zonglei Jing, Siyuan Liang, Jiakai Wang, Mingchuan Zhang .etc.|<http://arxiv.org/pdf/2508.14527v1>|提出ScenGE框架，通过推理新型对抗案例并融入复杂车流，生成多样化关键安全场景以提升自动驾驶车辆的...|
|🆕 发布|SATURN: Autoregressive Image Generation Guided by Scene Graphs|SATURN：由场景图引导的自回归图像生成|Thanh-Nhan Vo, Trong-Thuan Nguyen, Tam V. Nguyen, Minh-Triet Tran|<http://arxiv.org/pdf/2508.14502v1>|提出SATURN方法，通过场景图指导，提升图像生成中对象布局和关系的准确性。|
|📝 更新|SketchDNN: Joint Continuous-Discrete Diffusion for CAD Sketch Generation|草图生成中的联合连续-离散扩散：SketchDNN|Sathvik Chereddy, John Femiani|<http://arxiv.org/pdf/2507.11579v2>|提出SketchDNN模型，通过融合连续和离散参数的扩散过程生成CAD草图，解决了参数异质性和排列不...|
|🆕 发布|DreamSwapV: Mask-guided Subject Swapping for Any Customized Video Editing|梦境置换V：基于遮罩的任意定制视频编辑主体置换方法|Weitao Wang, Zichen Wang, Hongdeng Shen, Yulei Lu, Xirui Fan, Suhui Wu, Jun Zhang, Haoqian Wang .etc.|<http://arxiv.org/pdf/2508.14465v1>|提出DreamSwapV，一种端到端视频编辑框架，通过用户指定遮罩和参考图像实现任意视频主体替换。|
|🆕 发布|Generalizable Engagement Estimation in Conversation via Domain Prompting and Parallel Attention|通过领域提示和并行注意力机制实现对话中通用参与度估计|Yangche Yu, Yin Chen, Jia Li, Peng Jia, Yu Zhang, Li Dai, Zhenzhen Hu, Meng Wang .etc.|<http://arxiv.org/pdf/2508.14448v1>|提出DAPA框架，通过领域提示和并行注意力机制提升跨领域对话参与度估计的泛化能力。|
|🆕 发布|CTA-Flux: Integrating Chinese Cultural Semantics into High-Quality English Text-to-Image Communities|CTA-Flux：将中国文化语义融入高质量英文文本到图像社区|Yue Gong, Shanyuan Liu, Liuzhuozheng Li, Jian Zhu, Bo Cheng, Liebucha Wu, Xiaoyu Wu, Yuhang Ma .etc.|<http://arxiv.org/pdf/2508.14405v1>|提出了一种融合中文语义理解的适配方法，有效提升了英文文本到图像生成模型对中文输入的处理质量和文化准确...|
|🆕 发布|MUSE: Multi-Subject Unified Synthesis via Explicit Layout Semantic Expansion|通过显式布局语义扩展实现的多主体统一合成：MUSE|Fei Peng, Junqiang Wu, Yan Li, Tingting Gao, Di Zhang, Huiyuan Fu|<http://arxiv.org/pdf/2508.14440v1>|[代码](https://github.com/pf0607/MUSE.); 提出了一种统一的合成框架MUSE，通过显式语义空间扩展和双向模态对齐，实现了精确布局控制的多主体合成...|
|🆕 发布|HandCraft: Dynamic Sign Generation for Synthetic Data Augmentation|手工艺：合成数据增强的动态标志生成|Gaston Gustavo Rios|<http://arxiv.org/pdf/2508.14345v1>|提出了一种基于CMLPe的轻量级手语生成模型，通过合成数据预训练显著提升识别准确度。|
|🆕 发布|MoVieDrive: Multi-Modal Multi-View Urban Scene Video Generation|《MoVieDrive：多模态多视角城市场景视频生成》|Guile Wu, David Huang, Dongfeng Bai, Bingbing Liu|<http://arxiv.org/pdf/2508.14327v1>|提出了一种统一框架下的多模态多视角城市场景视频生成方法，提高了生成视频的保真度和可控性。|
|📝 更新|RNDiff: Rainfall nowcasting with Condition Diffusion Model|《RNDiff：基于条件扩散模型的降雨即时预报》|Xudong Ling, Chaorong Li, Fengqing Qin, Peng Yang, Yuanyuan Huang|<http://arxiv.org/pdf/2402.13737v2>|引入扩散模型进行短期降水预测，通过条件解码器提升预测准确性。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Reversible Unfolding Network for Concealed Visual Perception with Generative Refinement|可逆展开网络用于隐藏视觉感知与生成细化|Chunming He, Fengyang Xiao, Rihan Zhang, Chengyu Fang, Deng-Ping Fan, Sina Farsiu|<http://arxiv.org/pdf/2508.15027v1>|提出了一种融合可逆建模与生成精炼的视觉感知网络，有效处理了隐蔽视觉感知中的不确定性问题。|
|📝 更新|VBench-2.0: Advancing Video Generation Benchmark Suite for Intrinsic Faithfulness|VBench-2.0：推进视频生成基准套件以实现内在保真度|Dian Zheng, Ziqi Huang, Hongbo Liu, Kai Zou, Yinan He, Fan Zhang, Lulu Gu, Yuanhan Zhang .etc.|<http://arxiv.org/pdf/2503.21755v2>|提出VBench-2.0基准，自动评估视频生成模型在物理规律和常识推理等方面的内在真实性。|
|🆕 发布|Img2ST-Net: Efficient High-Resolution Spatial Omics Prediction from Whole Slide Histology Images via Fully Convolutional Image-to-Image Learning|Img2ST-Net：通过全卷积图像到图像学习从全切片组织学图像进行高效高分辨率空间组学预测|Junchao Zhu, Ruining Deng, Junlin Guo, Tianyuan Yao, Juming Xiong, Chongyu Qu, Mengmeng Yin, Yu Wang .etc.|<http://arxiv.org/pdf/2508.14393v1>|[代码](https://github.com/hrlblab/Img2ST-Net.); 提出Img2ST-Net，通过全卷积网络并行预测高分辨率空间转录组数据，提升计算效率和空间组织保持。|
|🆕 发布|Organ-Agents: Virtual Human Physiology Simulator via LLMs|器官代理：通过大型语言模型实现的虚拟人体生理学模拟器|Rihao Chang, He Jiao, Weizhi Nie, Honglin Guo, Keliang Xie, Zhenhua Wu, Lina Zhao, Yunpeng Bai .etc.|<http://arxiv.org/pdf/2508.14357v1>|提出Organ-Agents多代理框架，利用大型语言模型模拟人类生理系统，实现高精度仿真和治疗方案模...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TransLight: Image-Guided Customized Lighting Control with Generative Decoupling|《TransLight：基于图像引导的定制光照控制与生成解耦》|Zongming Li, Lianghui Zhu, Haocheng Shen, Longjin Ran, Wenyu Liu, Xinggang Wang|<http://arxiv.org/pdf/2508.14814v1>|提出了一种高保真、高自由度的图像光照效果迁移框架TransLight，通过生成解耦策略实现了复杂光照...|
|📝 更新|Dynamic watermarks in images generated by diffusion models|图像中由扩散模型生成的动态水印|Yunzhuo Chen, Naveed Akhtar, Nur Al Hasan Haldar, Ajmal Mian|<http://arxiv.org/pdf/2502.08927v2>|提出了一种多阶段水印框架，为扩散模型生成的图像嵌入固定和动态水印，以实现版权保护和来源追踪。|
|📝 更新|2D Gaussians Meet Visual Tokenizer|二维高斯分布遇见视觉标记器|Yiang Shi, Xiaoyang Guo, Wei Yin, Mingkai Jia, Qian Zhang, Xiaolin Hu, Wenyu Liu, Xinggang Wang|<http://arxiv.org/pdf/2508.13515v2>|提出Visual Gaussian Quantization方法，通过2D高斯分布增强结构化信息编码...|
|📝 更新|VSF: Simple, Efficient, and Effective Negative Guidance in Few-Step Image Generation Models By Value Sign Flip|VSF：基于值符号翻转的简单、高效、高效且有效的少量步骤图像生成模型中的负向引导|Wenqi Guo, Shan Du|<http://arxiv.org/pdf/2508.10931v3>|[代码](https://github.com/weathon/VSF); 提出了一种简单高效的方法VSF，通过翻转负向提示的注意力值，有效抑制生成图像中的不期望内容。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GaussianArt: Unified Modeling of Geometry and Motion for Articulated Objects|高斯艺术：关节对象的几何与运动统一建模|Licheng Shen, Saining Zhang, Honghan Li, Peilin Yang, Zihao Huang, Zongzheng Zhang, Hao Zhao|<http://arxiv.org/pdf/2508.14891v1>|提出了一种统一建模几何和运动的关节对象方法，通过使用关节3D高斯函数，提高了重建准确性和扩展性。|
|🆕 发布|GOGS: High-Fidelity Geometry and Relighting for Glossy Objects via Gaussian Surfels|高保真几何与高光物体重光照通过高斯微面元的方法|Xingyuan Yang, Min Wei|<http://arxiv.org/pdf/2508.14563v1>|提出了一种基于二维高斯粒子的两阶段框架GOGS，有效解决了高光物体逆向渲染中的模糊性和效率问题。|
|🆕 发布|Reconstruction Using the Invisible: Intuition from NIR and Metadata for Enhanced 3D Gaussian Splatting|利用不可见信息进行重建：从近红外与元数据中获取直觉以增强三维高斯散点绘制|Gyusam Chang, Tuan-Anh Vu, Vivek Alumootil, Harris Song, Deanna Pham, Sangpil Kim, M. Khalid Jawed|<http://arxiv.org/pdf/2508.14443v1>|[代码](https://github.com/StructuresComp/3D-Reconstruction-NIR); 利用近红外图像和文本元数据增强3D重建，提出了一种新的多模态架构以应对农业场景挑战。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Superpixel-informed Continuous Low-Rank Tensor Representation for Multi-Dimensional Data Recovery|超像素引导的连续低秩张量表示用于多维数据恢复|Zhizhou Wang, Jianli Wang, Ruijing Zheng, Zhenyu Wu|<http://arxiv.org/pdf/2508.12261v2>|提出了一种基于超像素的连续低秩张量表征框架，通过不对称低秩张量分解有效克服了传统方法在多维数据恢复中...|
|🆕 发布|QuadINR: Hardware-Efficient Implicit Neural Representations Through Quadratic Activation|二次激活的硬件高效隐式神经表示：QuadINR|Wenyong Zhou, Boyu Li, Jiachen Ren, Taiqiang Wu, Zhilin Ai, Zhengwu Liu, Ngai Wong|<http://arxiv.org/pdf/2508.14374v1>|提出了一种硬件高效的隐式神经表示方法QuadINR，通过使用分段二次激活函数减少硬件消耗并提升性能。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Extending Foundational Monocular Depth Estimators to Fisheye Cameras with Calibration Tokens|将基础单目深度估计器扩展到鱼眼相机：使用校准标记物进行标定|Suchisrit Gangopadhyay, Jung-Hee Kim, Xien Chen, Patrick Rim, Hyoungseob Park, Alex Wong|<http://arxiv.org/pdf/2508.04928v3>|[代码](https://github.com/JungHeeKim29/calibration-token.); 定位 fisheye 图像深度估计问题，提出 Calibration Tokens 方法，实现无需重...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MoCHA-former: Moiré-Conditioned Hybrid Adaptive Transformer for Video Demoiréing|莫尔纹理条件混合自适应变换器：用于视频去莫尔纹理的莫尔纹理条件混合自适应变换器|Jeahun Sung, Changhyun Roh, Chanho Eom, Jihyong Oh|<http://arxiv.org/pdf/2508.14423v2>|提出了一种针对视频去摩尔纹的MoCHA-former方法，通过分离摩尔纹和内容以及引入时空自适应机制...|
|🆕 发布|Scalable Event-Based Video Streaming for Machines with MoQ|基于MoQ的机器可扩展事件驱动视频流传输|Andrew C. Freeman|<http://arxiv.org/pdf/2508.15003v1>|提出了一种基于MoQ协议的低延迟事件流格式，优化了事件传感器视频数据的传输效率。|
|🆕 发布|\textit{adder-viz}: Real-Time Visualization Software for Transcoding Event Video|"adder-viz：实时事件视频转码可视化软件"|Andrew C. Freeman, Luke Reinkensmeyer|<http://arxiv.org/pdf/2508.14996v1>|[代码](https://github.com/ac-freeman/adder-codec-rs); 介绍了改进的实时事件视频转码可视化软件adder-viz，提升了灵活性、速度和压缩性。|
|📝 更新|Seeing More with Less: Video Capsule Endoscopy with Multi-Task Learning|“用少看更多：基于多任务学习的视频胶囊内窥镜检查”|Julia Werner, Oliver Bause, Julius Oexle, Maxime Le Floch, Franz Brinkmann, Jochen Hampe, Oliver Bringmann|<http://arxiv.org/pdf/2507.23479v2>|提出了一种多任务学习神经网络，实现精确的自我定位和小肠异常检测，显著提升胶囊内镜的能效和性能。|
|🆕 发布|AnchorSync: Global Consistency Optimization for Long Video Editing|锚点同步：长视频编辑的全局一致性优化|Zichi Liu, Yinggui Wang, Tao Wei, Chao Ma|<http://arxiv.org/pdf/2508.14609v1>|提出了一种AnchorSync框架，通过分离关键帧编辑和中间帧插值，实现了高质量的长视频编辑并保持了...|
|📝 更新|MMAD: Multi-label Micro-Action Detection in Videos|多标签微动作视频检测：MMAD|Kun Li, Pengyu Liu, Dan Guo, Fei Wang, Zhiliang Wu, Hehe Fan, Meng Wang|<http://arxiv.org/pdf/2407.05311v3>|[代码](https://github.com/VUT-HFUT/Micro-Action.); 提出多标签微动作检测任务MMAD，并引入MMA-52数据集及双路径时空适配器模型。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MS-CLR: Multi-Skeleton Contrastive Learning for Human Action Recognition|多骨架对比学习用于人体动作识别：MS-CLR|Mert Kiray, Alvaro Ritter, Nassir Navab, Benjamin Busam|<http://arxiv.org/pdf/2508.14889v1>|提出多骨骼对比学习框架MS-CLR，通过跨骨骼约定对齐提升动作识别的泛化性和表现力。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Repeating Words for Video-Language Retrieval with Coarse-to-Fine Objectives|使用粗到细目标进行视频-语言检索的重词策略|Haoyu Zhao, Jiaxi Gu, Shicong Wang, Xing Zhang, Hang Xu, Zuxuan Wu, Yu-Gang Jiang|<http://arxiv.org/pdf/2508.14812v1>|提出细粒度特征学习框架并引入重复关键词推理管道，有效提升视频文本检索性能。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UST-SSM: Unified Spatio-Temporal State Space Models for Point Cloud Video Modeling|UST-SSM：统一时空状态空间模型用于点云视频建模|Peiming Li, Ziyi Wang, Yulin Yuan, Hong Liu, Xiangming Meng, Junsong Yuan, Mengyuan Liu|<http://arxiv.org/pdf/2508.14604v1>|[代码](https://github.com/wangzy01/UST-SSM.); 提出UST-SSM模型，通过重新组织点云视频中的点序列和聚合时空特征，有效建模点云视频中的动态三维运...|
|📝 更新|FlightPatchNet: Multi-Scale Patch Network with Differential Coding for Flight Trajectory Prediction|飞行路径补丁网络：用于飞行轨迹预测的多尺度补丁网络与差分编码|Lan Wu, Xuebin Wang, Ruijuan Chu, Guangyi Liu, Jing Zhang, Linyu Wang|<http://arxiv.org/pdf/2405.16200v3>|提出FlightPatchNet模型，通过多尺度网络和差分编码解决飞行轨迹预测中的尺度差异和时序依赖...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Is Contrastive Distillation Enough for Learning Comprehensive 3D Representations?|对比蒸馏是否足以学习全面的三维表示？|Yifan Zhang, Junhui Hou|<http://arxiv.org/pdf/2412.08973v2>|[代码](https://github.com/Eaphan/CMCR.); 提出新框架CMCR，融合模态共有与特有特征，提升3D表示学习效果。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Snap-Snap: Taking Two Images to Reconstruct 3D Human Gaussians in Milliseconds|"Snap-Snap：在毫秒内通过两张图像重建三维人体高斯分布"|Jia Lu, Taoran Yi, Jiemin Fang, Chen Yang, Chuiyun Wu, Wei Shen, Wenyu Liu, Qi Tian .etc.|<http://arxiv.org/pdf/2508.14892v1>|[代码](https://hustvl.github.io/Snap-Snap); 提出了一种仅需前后两张图片即可快速重建3D人体模型的方法，大幅降低了用户创建3D数字人的难度。|
|🆕 发布|Understanding Data Influence with Differential Approximation|《利用微分近似理解数据影响力》|Haoru Tan, Sitong Wu, Xiuzhe Wu, Wang Wang, Bo Zhao, Zeke Xie, Gui-Song Xia, Xiaojuan Qi|<http://arxiv.org/pdf/2508.14648v1>|提出了一种高效近似样本影响的新方法Diff-In，通过累积连续训练步骤中的差异，无需模型凸性，提高了...|
|🆕 发布|Making Pose Representations More Expressive and Disentangled via Residual Vector Quantization|通过残差向量量化使姿态表示更具表现力和解耦|Sukhyun Jeong, Hong-Gi Shin, Yong-Hoon Choi|<http://arxiv.org/pdf/2508.14561v1>|通过残差向量量化融合连续运动特征，增强了姿态编码的表现力和解耦性。|
|🆕 发布|From Slices to Structures: Unsupervised 3D Reconstruction of Female Pelvic Anatomy from Freehand Transvaginal Ultrasound|从切片到结构：基于自由手式经阴道超声的无监督女性盆腔解剖结构三维重建|Max Krähenmann, Sergio Tascon-Morales, Fabian Laumer, Julia E. Vogt, Ece Ozkan|<http://arxiv.org/pdf/2508.14552v1>|提出了一种无需外部追踪或学习位姿估计器的无监督框架，通过自由手2D经阴道超声扫描重建3D解剖结构。|
|🆕 发布|WISE-FUSE: Efficient Whole Slide Image Encoding via Coarse-to-Fine Patch Selection with VLM and LLM Knowledge Fusion|WISE-FUSE：通过粗到细斑块选择与VLM和LLM知识融合的高效全玻片图像编码|Yonghan Shin, SeungKyu Kim, Won-Ki Jeong|<http://arxiv.org/pdf/2508.14537v1>|提出WISE-FUSE框架，通过选择性处理关键区域，大幅缩短全玻片图像编码时间并保持诊断性能。|
|🆕 发布|LookOut: Real-World Humanoid Egocentric Navigation|《LookOut：现实世界中的仿人视角自主导航》|Boxiao Pan, Adam W. Harley, C. Karen Liu, Leonidas J. Guibas|<http://arxiv.org/pdf/2508.14466v1>|提出方法预测未来头部运动轨迹，解决机器人与VR导航问题，并贡献了新数据集。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Improved Mapping Between Illuminations and Sensors for RAW Images|改进RAW图像光照与传感器之间的映射关系|Abhijith Punnappurath, Luxi Zhao, Hoang Le, Abdelrahman Abdelhamed, SaiKiran Kumar Tedla, Michael S. Brown|<http://arxiv.org/pdf/2508.14730v1>|[代码](https://github.com/SamsungLabs/illum-sensor-mapping.); 提出首个跨传感器和光照映射的专门数据集，并设计了一种高效神经网络方法以优化图像处理。|
|🆕 发布|GeMS: Efficient Gaussian Splatting for Extreme Motion Blur|《GeMS：用于极端运动模糊的高效高斯散点技术》|Gopi Raju Matta, Trisha Reddypalli, Vemunuri Divya Madhuri, Kaushik Mitra|<http://arxiv.org/pdf/2508.14682v1>|提出GeMS框架，直接从严重模糊的图像中重建场景，无需依赖清晰图像进行相机位姿估计和点云生成。|
|📝 更新|Real-time Neural Rendering of LiDAR Point Clouds|激光雷达点云的实时神经渲染|Joni Vanherck, Brent Zoomers, Tom Mertens, Lode Jorissen, Nick Michiels|<http://arxiv.org/pdf/2502.11618v2>|提出了一种实时渲染LiDAR点云的深度学习方法，有效解决了背景干扰和视觉失真问题。|
|📝 更新|Hands-On: Segmenting Individual Signs from Continuous Sequences|动手实践：从连续序列中分割单个标志|JianHe Low, Harry Walsh, Ozge Mercanoglu Sincan, Richard Bowden|<http://arxiv.org/pdf/2504.08593v4>|提出了一种基于变换器的连续手语分割方法，利用手部特征和3D角度，实现了领先性能。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Lifespan Pancreas Morphology for Control vs Type 2 Diabetes using AI on Largescale Clinical Imaging|使用大规模临床影像的AI对对照组与2型糖尿病患者进行寿命胰腺形态学研究|Lucas W. Remedios, Chloe Cho, Trent M. Schwartz, Dingjie Su, Gaurav Rudravaram, Chenyu Gao, Aravind R. Krishnan, Adam M. Saunders .etc.|<http://arxiv.org/pdf/2508.14878v1>|揭示了2型糖尿病患者胰腺形态随年龄变化的趋势，并建立了基于AI的大规模临床影像数据胰腺形态学参考标准...|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Adversarial Hospital-Invariant Feature Learning for WSI Patch Classification|对抗性医院不变特征学习用于全切片图像片段分类|Mengliang Zhang, Jacob M. Luber|<http://arxiv.org/pdf/2508.14779v1>|提出了一种对抗性学习框架，有效消除病理图像中的医院特定特征，提高跨医院数据集的疾病分类性能。|
|📝 更新|ETA: Energy-based Test-time Adaptation for Depth Completion|基于能量的测试时适应法用于深度补全|Younjoon Chung, Hyoungseob Park, Patrick Rim, Xiaoran Zhang, Jihe He, Ziyao Zeng, Safa Cicek, Byung-Woo Hong .etc.|<http://arxiv.org/pdf/2508.05989v2>|[代码](https://fuzzythecat.github.io/eta.); 提出了一种测试时自适应方法，通过能量模型优化预训练深度补全模型，有效应对数据分布偏移问题。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GLOV: Guided Large Language Models as Implicit Optimizers for Vision Language Models|GLOV：引导大型语言模型作为视觉语言模型的隐式优化器|M. Jehanzeb Mirza, Mengjie Zhao, Zhuoyuan Mao, Sivan Doveh, Wei Lin, Paul Gavrikov, Michael Dorkenwald, Shiqi Yang .etc.|<http://arxiv.org/pdf/2410.06154v6>|提出GLOV方法，利用大型语言模型作为视觉语言模型的隐式优化器，提升下游视觉任务性能。|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Enhanced Anomaly Detection for Capsule Endoscopy Using Ensemble Learning Strategies|使用集成学习策略增强胶囊内镜异常检测|Julia Werner, Christoph Gerum, Jorg Nick, Maxime Le Floch, Franz Brinkmann, Jochen Hampe, Oliver Bringmann|<http://arxiv.org/pdf/2504.06039v2>|提出了一种结合多种损失函数的集成学习策略，用于胶囊内窥镜异常检测，实现了更高效的准确性和鲁棒性。|
|🆕 发布|Safety-Critical Learning for Long-Tail Events: The TUM Traffic Accident Dataset|长尾事件的安全关键学习：慕尼黑工业大学交通事故数据集|Walter Zimmer, Ross Greer, Xingcheng Zhou, Rui Song, Marc Pavel, Daniel Lehmberg, Ahmed Ghita, Akshay Gopalkrishnan .etc.|<http://arxiv.org/pdf/2508.14567v1>|[代码](https://tum-traffic-dataset.github.io/tumtraf-a.); 提出TUM Traffic Accident数据集并设计Accid3nD模型，结合规则与学习检测交通...|
|🆕 发布|WeedSense: Multi-Task Learning for Weed Segmentation, Height Estimation, and Growth Stage Classification|杂草感知：多任务学习用于杂草分割、高度估计和生长阶段分类|Toqi Tahamid Sarker, Khaled R Ahmed, Taminul Islam, Cristiana Bernardi Rankrape, Karla Gage|<http://arxiv.org/pdf/2508.14486v1>|提出WeedSense多任务学习架构，实现杂草分割、高度估计和生长阶段分类，提升农业监测效率。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|D^3-Talker: Dual-Branch Decoupled Deformation Fields for Few-Shot 3D Talking Head Synthesis|D^3-说话人：双分支解耦形变场用于少量样本的三维说话人头合成|Yuhang Guo, Kaijun Deng, Siyang Song, Jindong Xie, Wenhui Ma, Linlin Shen|<http://arxiv.org/pdf/2508.14449v1>|提出了一种独立控制音频和面部运动信号的双分支解耦形变场方法，有效提高了少量数据下的3D说话人头合成质...|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Vision-Based Shared-Control Teleoperation Scheme for Controlling the Robotic Arm of a Four-Legged Robot|基于视觉的共享控制遥操作方案：用于控制四足机器人机械臂|Murilo Vinicius da Silva, Matheus Hipolito Carvalho, Juliano Negri, Thiago Segreto, Gustavo J. G. Lahr, Ricardo V. Godoy, Marcelo Becker|<http://arxiv.org/pdf/2508.14994v1>|提出了一种基于视觉的共享控制远程操作方案，将人类手臂动作映射到四足机器人机械臂，实现直观且安全的实时...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RotBench: Evaluating Multimodal Large Language Models on Identifying Image Rotation|《RotBench：评估多模态大型语言模型在识别图像旋转方面的性能》|Tianyi Niu, Jaemin Cho, Elias Stengel-Eskin, Mohit Bansal|<http://arxiv.org/pdf/2508.13968v2>|介绍了RotBench基准，揭示了大型多模态语言模型在图像旋转识别任务上的不足。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CoMatcher: Multi-View Collaborative Feature Matching|协同匹配器：多视角协同特征匹配|Jintao Zhang, Zimin Xia, Mingyue Dong, Shuhan Shen, Linwei Yue, Xianwei Zheng|<http://arxiv.org/pdf/2504.01872v2>|提出了一种多视角协同匹配策略CoMatcher，通过利用不同视角的互补信息，解决了复杂场景下跟踪构建...|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Unsupervised Urban Tree Biodiversity Mapping from Street-Level Imagery Using Spatially-Aware Visual Clustering|基于空间感知视觉聚类的无需监督城市树木生物多样性制图——利用街道级图像|Diaa Addeen Abuhani, Marco Seccaroni, Martina Mazzarello, Imran Zualkernan, Fabio Duarte, Carlo Ratti|<http://arxiv.org/pdf/2508.13814v2>|提出了一种无需标签的视觉聚类框架，利用街景图像和空间种植模式估计城市树木 biodiversity。|
|📝 更新|VisioPhysioENet: Visual Physiological Engagement Detection Network|视生理参与检测网络：VisioPhysioENet|Alakhsimar Singh, Kanav Goyal, Nischay Verma, Puneet Kumar, Xiaobai Li, Amritpal Singh|<http://arxiv.org/pdf/2409.16126v3>|提出了一种融合视觉与生理信号的 learner engagement 检测系统，提高了识别学习者参与...|
|📝 更新|JRDB-Reasoning: A Difficulty-Graded Benchmark for Visual Reasoning in Robotics|JRDB-推理：一个用于机器人视觉推理的难度分级基准|Simindokht Jahangard, Mehrzad Mohammadi, Yi Shen, Zhixi Cai, Hamid Rezatofighi|<http://arxiv.org/pdf/2508.10287v2>|提出了一种分级难度的视觉推理基准JRDB-Reasoning，通过自适应查询引擎生成不同难度的问题，...|
|📝 更新|Explicit Context Reasoning with Supervision for Visual Tracking|显式上下文推理与监督视觉跟踪|Fansheng Zeng, Bineng Zhong, Haiying Xia, Yufei Tan, Xiantao Hu, Liangtao Shi, Shuxiang Song|<http://arxiv.org/pdf/2507.16191v2>|[代码](https://github.com/GXNU-ZhongLab/RSTrack.); 提出显式上下文推理与监督方法，增强视觉跟踪时序一致性，实现实时高性能跟踪。|
|🆕 发布|FastTracker: Real-Time and Accurate Visual Tracking|快速跟踪器：实时与精确的视觉跟踪|Hamidreza Hashempoor, Yu Dong Hwang|<http://arxiv.org/pdf/2508.14370v1>|[代码](https://github.com/Hamidreza-Hashempoor/FastTracker); 提出了一种通用的多目标跟踪框架，通过考虑遮挡和道路结构，实现了车辆等不同对象在复杂场景中的实时准确跟...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Physics-Driven Autoregressive State Space Models for Medical Image Reconstruction|基于物理驱动的自回归状态空间模型在医学图像重建中的应用|Bilal Kabas, Fuat Arslan, Valiyeh A. Nezhad, Saban Ozturk, Emine U. Saritas, Tolga Çukur|<http://arxiv.org/pdf/2412.09331v3>|提出了一种物理驱动自回归状态空间模型，实现了高效高保真的医学图像重建。|
|🆕 发布|DINOv3 with Test-Time Training for Medical Image Registration|《基于测试时训练的DINOv3用于医学图像配准》|Shansong Wang, Mojtaba Safari, Mingzhe Hu, Qiang Li, Chih-Wei Chang, Richard LJ Qiu, Xiaofeng Yang|<http://arxiv.org/pdf/2508.14809v1>|提出了一种无需训练数据的医学图像配准方法，通过测试时优化特征空间的变形场，实现了高精度和规则变形。|
|🆕 发布|Rule-based Key-Point Extraction for MR-Guided Biomechanical Digital Twins of the Spine|基于规则的脊柱生物力学数字孪生中MR引导的关键点提取|Robert Graf, Tanja Lerchl, Kati Nispel, Hendrik Möller, Matan Atad, Julian McGinnis, Julius Maria Watrinet, Johannes Paetzold .etc.|<http://arxiv.org/pdf/2508.14708v1>|提出了一种基于规则的MRI亚像素级关键点提取方法，实现了精确的个体解剖建模，支持个性化的脊柱生物力学...|
|🆕 发布|Deep Skin Lesion Segmentation with Transformer-CNN Fusion: Toward Intelligent Skin Cancer Analysis|深度皮肤病变分割的Transformer-CNN融合方法：迈向智能皮肤癌分析|Xin Wang, Xiaopei Zhang, Xingang Wang|<http://arxiv.org/pdf/2508.14509v1>|提出了一种融合Transformer和CNN的皮肤病变精准分割方法，有效应对病变结构复杂和边界模糊的...|
|🆕 发布|TCFNet: Bidirectional face-bone transformation via a Transformer-based coarse-to-fine point movement network|TCFNet：基于Transformer的粗到细点移动网络实现双向面部骨骼变换|Runshi Zhang, Bimeng Jie, Yang He, Junchen Wang|<http://arxiv.org/pdf/2508.14373v1>|[代码](https://github.com/Runshi-Zhang/TCFNet.); 提出了一种基于Transformer的粗到细点移动网络，用于精确模拟面部骨骼变换，提高了手术模拟的效...|
|🆕 发布|Deep Learning for Taxol Exposure Analysis: A New Cell Image Dataset and Attention-Based Baseline Model|《用于紫杉醇暴露分析的深度学习：一种新的细胞图像数据集与基于注意力的基线模型》|Sean Fletcher, Gabby Scott, Douglas Currie, Xin Zhang, Yuqi Song, Bruce MacLeod|<http://arxiv.org/pdf/2508.14349v1>|提出了一种基于深度学习的Taxol浓度分类方法，并创建了首个公开的Taxol细胞图像数据集。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multiscale Video Transformers for Class Agnostic Segmentation in Autonomous Driving|多尺度视频变换器用于自动驾驶中的无类别分割|Leila Cheshmi, Mennatullah Siam|<http://arxiv.org/pdf/2508.14729v1>|提出了一种无需已知类别信息的视频变换器，实现高效无类别分割，提升自动驾驶安全性。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Comprehensive Review of Agricultural Parcel and Boundary Delineation from Remote Sensing Images: Recent Progress and Future Perspectives|《遥感图像中农田地块与边界划分的全面回顾：近期进展与未来展望》|Juepeng Zheng, Zi Ye, Yibin Wen, Jianxi Huang, Zhiwei Zhang, Qingmei Li, Qiong Hu, Baodong Xu .etc.|<http://arxiv.org/pdf/2508.14558v1>|系统综述了农业地块和边界划分的遥感图像方法，分类并讨论了传统与深度学习方法的发展趋势。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Bench2ADVLM: A Closed-Loop Benchmark for Vision-language Models in Autonomous Driving|闭环自动驾驶中视觉-语言模型的Bench2ADVLM基准|Tianyuan Zhang, Ting Jin, Lu Wang, Jiangfan Liu, Siyuan Liang, Mingchuan Zhang, Aishan Liu, Xianglong Liu|<http://arxiv.org/pdf/2508.02028v2>|提出了 Bench2ADVLM，一个用于自动驾驶视觉语言模型闭环评估的统一框架，以实现实时、交互式评...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Decentralized Vision-Based Autonomous Aerial Wildlife Monitoring|基于视觉的分布式自主空中野生动物监测|Makram Chahine, William Yang, Alaa Maalouf, Justin Siriska, Ninad Jadhav, Daniel Vogt, Stephanie Gil, Robert Wood .etc.|<http://arxiv.org/pdf/2508.15038v1>|提出了一种去中心化的基于视觉的多旋翼无人机系统，实现了对野生动物的 scalable 监测和跟踪。|
|🆕 发布|A Real-world Display Inverse Rendering Dataset|现实世界显示逆向渲染数据集|Seokjun Choi, Hoon-Gyu Chung, Yujin Jeon, Giljoo Nam, Seung-Hwan Baek|<http://arxiv.org/pdf/2508.14411v1>|[代码](https://michaelcsj.github.io/DIR); 首次构建了用于显示逆向渲染的实景数据集，推动相关方法性能评估与提升。|

