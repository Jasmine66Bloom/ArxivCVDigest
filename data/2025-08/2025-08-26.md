## [UPDATED!] **2025-08-26** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Autoregressive Universal Video Segmentation Model|自回归通用视频分割模型|Miran Heo, Sukjun Hwang, Min-Hung Chen, Yu-Chiang Frank Wang, Albert Gu, Seon Joo Kim, Ryo Hachiuma|<http://arxiv.org/pdf/2508.19242v1>|提出了一种统一处理提示和非提示视频分割任务的Autoregressive Universal Seg...|
|📝 更新|Project-Probe-Aggregate: Efficient Fine-Tuning for Group Robustness|项目探测聚合：面向群体鲁棒性的高效微调|Beier Zhu, Jiequan Cui, Hanwang Zhang, Chi Zhang|<http://arxiv.org/pdf/2503.09487v3>|提出了一种无需群体标注的Project-Probe-Aggregate方法，有效提升基础模型在细粒度...|
|📝 更新|Video CLIP Model for Multi-View Echocardiography Interpretation|多视角超声心动图解读的视频CLIP模型|Ryo Takizawa, Satoshi Kodera, Tempei Kabayama, Ryo Matsuoka, Yuta Ando, Yuto Nakamura, Haruki Settai, Norihiko Takeda|<http://arxiv.org/pdf/2504.18800v2>|提出了一种处理多视角超声心动图视频的语言模型，提高了心脏疾病诊断的准确性。|
|🆕 发布|Deep Pre-trained Time Series Features for Tree Species Classification in the Dutch Forest Inventory|深度预训练时间序列特征在荷兰森林清查中的树木种类分类应用|Takayuki Ishikawa, Carmelo Bonannella, Bas J. W. Lerink, Marc Rußwurm|<http://arxiv.org/pdf/2508.18829v1>|利用预训练的深度时间序列特征显著提升了荷兰森林树种分类精度。|
|📝 更新|Deshadow-Anything: When Segment Anything Model Meets Zero-shot shadow removal|去影万物：当Segment Anything模型遇见零样本阴影移除|Xiao Feng Zhang, Tian Yi Song, Jia Wei Yao|<http://arxiv.org/pdf/2309.11715v4>|提出Deshadow-Anything模型，结合Segment Anything和扩散模型，有效实现...|
|📝 更新|Inspiring the Next Generation of Segment Anything Models: Comprehensively Evaluate SAM and SAM 2 with Diverse Prompts Towards Context-Dependent Concepts under Different Scenes|激发下一代任意分割模型：在不同场景下，利用多样化提示全面评估SAM和SAM 2对上下文相关概念的处理能力|Xiaoqi Zhao, Youwei Pang, Shijie Chang, Yuan Zhao, Lihe Zhang, Chenyang Yu, Hanqi Liu, Jiaming Zuo .etc.|<http://arxiv.org/pdf/2412.01240v3>|全面评估SAM和SAM 2在处理复杂上下文依赖概念的分割能力，并提出了统一的评价框架和prompt稳...|
|📝 更新|SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models|基于多模态大型语言模型的自我进化视觉-语言导航框架：SE-VLN|Xiangyu Dong, Haoran Zhao, Jiang Gao, Haozhou Li, Xiaoguang Ma, Yaoming Zhou, Fuhai Chen, Juan Liu|<http://arxiv.org/pdf/2507.13152v3>|提出了一种自进化的视觉语言导航框架SE-VLN，通过持续学习提升未知环境中的导航成功率。|
|🆕 发布|EMind: A Foundation Model for Multi-task Electromagnetic Signals Understanding|电磁信号理解多任务基础模型：EMind|Luqing Luo, Wenjin Gui, Yunfei Liu, Ziyue Zhang, Yunxi Zhang, Fengxiang Wang, Zonghao Guo, Zizhi Ma .etc.|<http://arxiv.org/pdf/2508.18785v1>|[代码](https://github.com/GabrielleTse/EMind.); 提出EMind模型，通过大规模预训练和特有的信号处理方法，实现了电磁信号多任务理解和广泛泛化。|
|🆕 发布|Feature-Space Planes Searcher: A Universal Domain Adaptation Framework for Interpretability and Computational Efficiency|特征空间平面搜索器：一种用于解释性和计算效率的通用域自适应框架|Zhitong Cheng, Yiran Jiang, Yulong Ge, Yufeng Li, Zhongheng Qin, Rongzhi Lin, Jianwei Ma|<http://arxiv.org/pdf/2508.18693v1>|提出了一种优化决策边界的域自适应框架FPS，通过保持特征编码器冻结来提高解释性和计算效率。|
|📝 更新|Physical Autoregressive Model for Robotic Manipulation without Action Pretraining|物理自回归模型：无需动作预训练的机器人操作|Zijian Song, Sihan Qin, Tianshui Chen, Liang Lin, Guangrun Wang|<http://arxiv.org/pdf/2508.09822v3>|[代码](https://hcplab-sysu.github.io/PhysicalAutoregressiveModel); 提出物理自回归模型，无需动作预训练即可理解物理动态，实现精确视频预测和一致动作轨迹。|
|📝 更新|ZoomEye: Enhancing Multimodal LLMs with Human-Like Zooming Capabilities through Tree-Based Image Exploration|“ZoomEye：通过基于树的图像探索增强多模态大型语言模型的人类似缩放能力”|Haozhan Shen, Kangjia Zhao, Tiancheng Zhao, Ruochen Xu, Zilun Zhang, Mingwei Zhu, Jianwei Yin|<http://arxiv.org/pdf/2411.16044v2>|[代码](https://github.com/om-ai-lab/ZoomEye); 提出了一种名为Zoom Eye的算法，通过模拟人类缩放观察图像的方式，帮助大型多模态语言模型更好地识...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Beyond flattening: a geometrically principled positional encoding for vision transformers with Weierstrass elliptic functions|超越展平：基于魏尔斯特拉斯椭圆函数的几何原理位置编码在视觉变换器中的应用|Zhihang Xin, Xitong Hu, Rui Wang|<http://arxiv.org/pdf/2508.19167v1>|提出了一种基于韦伊尔斯特拉斯椭圆函数的二维位置编码方法，有效解决了传统视觉变换模型中位置信息丢失的问...|
|🆕 发布|Enhancing compact convolutional transformers with super attention|增强紧凑卷积变换器与超级注意力|Simpenzwe Honore Leandre, Natenaile Asmamaw Shiferaw, Dillip Rout|<http://arxiv.org/pdf/2508.18960v1>|提出了一种高效的视觉模型，通过采用混合令牌、序列池化和卷积令牌化技术，在固定上下文长度任务中实现领先...|
|📝 更新|VFM-Guided Semi-Supervised Detection Transformer under Source-Free Constraints for Remote Sensing Object Detection|基于VFM引导的无源约束下遥感目标检测的半监督检测变换器|Jianhong Han, Yupei Wang, Liang Chen|<http://arxiv.org/pdf/2508.11167v2>|提出了一种半监督检测变压器方法，利用视觉基础模型提高遥感图像中源自由目标检测的准确性和鲁棒性。|
|📝 更新|DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge|梦幻VLA：一种融合全面世界知识的视觉-语言-动作模型|Wenyao Zhang, Hongsi Liu, Zekun Qi, Yunnan Wang, Xinqiang Yu, Jiazhao Zhang, Runpei Dong, Jiawei He .etc.|<http://arxiv.org/pdf/2507.04447v3>|DreamVLA通过融合全面的世界知识预测，建立了感知-预测-行动循环，提高了机器人操作任务的泛化与...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RDDM: Practicing RAW Domain Diffusion Model for Real-world Image Restoration|RDDM：实践原始域扩散模型以实现现实世界图像恢复|Yan Chen, Yi Wen, Wei Li, Junchao Liu, Yong Guo, Jie Hu, Xinghao Chen|<http://arxiv.org/pdf/2508.19154v1>|提出RDDM模型，直接在RAW域从传感器数据恢复逼真图像，解决了传统方法在图像质量和真实性之间的矛盾...|
|📝 更新|MergeSAM: Unsupervised change detection of remote sensing images based on the Segment Anything Model|MergeSAM：基于Segment Anything模型的遥感图像无监督变化检测|Meiqi Hu, Lingzhi Lu, Chengxi Han, Xiaoping Liu|<http://arxiv.org/pdf/2507.22675v2>|提出了一种基于Segment Anything Model的远程遥感图像无监督变化检测方法，通过Ma...|
|📝 更新|Egocentric Human-Object Interaction Detection: A New Benchmark and Method|自我中心的人-物交互检测：一个新的基准与方法|Kunyuan Deng, Yi Wang, Lap-Pui Chau|<http://arxiv.org/pdf/2506.14189v2>|[代码](https://dengkunyuan.github.io/EgoHOIBench); 提出Ego-HOI任务和Ego-HOIBench数据集，提出HGIR方法提升 egocentric ...|
|📝 更新|M$^2$IV: Towards Efficient and Fine-grained Multimodal In-Context Learning via Representation Engineering|M$^2$IV：通过表征工程实现高效和细粒度的多模态情境学习|Yanshu Li, Yi Cao, Hongyang He, Qisen Cheng, Xiang Fu, Xi Xiao, Tianyang Wang, Ruixiang Tang|<http://arxiv.org/pdf/2504.04633v3>|提出M$^2$IV方法，通过注入多模态向量提升大型视觉语言模型在少量样本学习中的效率和精细度。|
|📝 更新|OpenEvents V1: Large-Scale Benchmark Dataset for Multimodal Event Grounding|OpenEvents V1：大规模多模态事件定位基准数据集|Hieu Nguyen, Phuc-Tan Nguyen, Thien-Phuc Tran, Minh-Quang Nguyen, Tam V. Nguyen, Minh-Triet Tran, Trung-Nghia Le|<http://arxiv.org/pdf/2506.18372v2>|[代码](https://ltnghia.github.io/eventa); 构建OpenEvents V1大规模多模态事件定位数据集，推动事件中心视觉语言理解发展。|
|📝 更新|MM-R1: Unleashing the Power of Unified Multimodal Large Language Models for Personalized Image Generation|MM-R1: 统一多模态大型语言模型赋能个性化图像生成|Qian Liang, Yujia Wu, Kuncheng Li, Jiwei Wei, Shiyuan He, Jinyu Guo, Ning Xie|<http://arxiv.org/pdf/2508.11433v2>|引入MM-R1框架，通过跨模态推理策略提升统一多模态大语言模型在个性化图像生成方面的性能。|
|🆕 发布|Decouple, Reorganize, and Fuse: A Multimodal Framework for Cancer Survival Prediction|解耦、重组与融合：一种用于癌症生存预测的多模态框架|Huayi Wang, Haochao Ying, Yuyang Xu, Qibo Qiu, Cheng Zhang, Danny Z. Chen, Ying Sun, Jian Wu|<http://arxiv.org/pdf/2508.18632v1>|提出了一种解耦-重组-融合的多模态框架，有效提升了癌症生存预测的泛化能力和信息捕捉。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Image Coding for Machines via Feature-Preserving Rate-Distortion Optimization|通过特征保持率失真优化实现机器图像编码|Samuel Fernández-Menduiña, Eduardo Pavez, Antonio Ortega|<http://arxiv.org/pdf/2504.02216v2>|提出了一种通过特征保持率失真优化进行图像编码的方法，有效平衡了视觉质量和计算机视觉任务性能。|
|🆕 发布|The point is the mask: scaling coral reef segmentation with weak supervision|"关键在于掩模：利用弱监督扩展珊瑚礁分割规模"|Matteo Contini, Victor Illien, Sylvain Poulain, Serge Bernard, Julien Barde, Sylvain Bonhommeau, Alexis Joly|<http://arxiv.org/pdf/2508.18958v1>|提出了一种利用弱监督学习从无人机影像进行大规模珊瑚礁分割的方法，降低了对人工标注的依赖。|
|🆕 发布|Class-wise Flooding Regularization for Imbalanced Image Classification|类别平衡的洪水正则化方法用于不平衡图像分类|Hiroaki Aizawa, Yuta Naito, Kohei Fukuda|<http://arxiv.org/pdf/2508.18723v1>|提出了一种基于类别的洪水正则化方法，有效解决了不平衡数据集上的分类问题，提升了少数类的识别性能。|
|🆕 发布|Natural Image Classification via Quasi-Cyclic Graph Ensembles and Random-Bond Ising Models at the Nishimori Temperature|通过准循环图集合和inishimori温度下的随机键Ising模型进行自然图像分类|V. S. Usatyuk, D. A. Sapoznikov, S. I. Egorov|<http://arxiv.org/pdf/2508.18717v1>|提出了一种结合统计物理、编码理论和代数拓扑的统一框架，通过准循环图集合和随机键伊辛模型在Nishim...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MonoCoP: Chain-of-Prediction for Monocular 3D Object Detection|单目3D目标检测中的链式预测方法MonoCoP|Zhihao Zhang, Abhinav Kumar, Girish Chandar Ganesan, Xiaoming Liu|<http://arxiv.org/pdf/2505.04594v5>|MonoCoP通过构建预测链，顺序且条件性地预测3D物体属性，实现了单目3D检测的精度提升。|
|🆕 发布|RoofSeg: An edge-aware transformer-based network for end-to-end roof plane segmentation|RoofSeg：一种基于边缘感知的Transformer网络用于端到端屋顶平面分割|Siyuan You, Guozheng Xu, Pengwei Zhou, Qiwen Jin, Jian Yao, Li Li|<http://arxiv.org/pdf/2508.19003v1>|提出了一种边缘感知的Transformer网络RoofSeg，实现了端到端的屋顶平面分割，并通过引入...|
|📝 更新|Emerging Semantic Segmentation from Positive and Negative Coarse Label Learning|从正负粗标签学习中涌现的语义分割|Le Zhang, Fuping Wu, Arun Thirunavukarasu, Kevin Bronik, Thomas Nichols, Bartlomiej W. Papiez|<http://arxiv.org/pdf/2508.18186v2>|利用正负粗略标注训练CNN进行语义分割，提出双CNN耦合学习法，提升标注效率和模型性能。|
|🆕 发布|Robust and Label-Efficient Deep Waste Detection|稳健且标注高效的深度废品检测|Hassan Abid, Khan Muhammad, Muhammad Haris Khan|<http://arxiv.org/pdf/2508.18799v1>|[代码](https://github.com/h-abid97/robust-waste-detection.); 提出了一种半监督学习框架，通过集成预测和软伪标签策略，有效提升了废物检测的准确性和标注效率。|
|🆕 发布|A Closer Look at Edema Area Segmentation in SD-OCT Images Using Adversarial Framework|《利用对抗性框架对SD-OCT图像中水肿区域分割的深入探讨》|Yuhui Tao, Yizhe Zhang, Qiang Chen|<http://arxiv.org/pdf/2508.18790v1>|提出了一种结合视网膜层信息的对抗框架和测试时适应策略，提高了弱监督学习在视网膜水肿区域分割的准确性和...|
|🆕 发布|Enhancing Video-Based Robot Failure Detection Using Task Knowledge|利用任务知识增强基于视频的机器人故障检测|Santosh Thoduka, Sebastian Houben, Juergen Gall, Paul G. Plöger|<http://arxiv.org/pdf/2508.18705v1>|利用机器人执行动作和任务相关物体的时空知识，提出了一种视频基础上的机器人故障检测方法，提高了故障检测...|
|🆕 发布|Hierarchical Spatio-temporal Segmentation Network for Ejection Fraction Estimation in Echocardiography Videos|分层时空分割网络在超声心动图视频中射血分数估计的应用|Dongfang Wang, Jian Yang, Yizhe Zhang, Tao Zhou|<http://arxiv.org/pdf/2508.18681v1>|提出了一种分层时空分割网络，通过融合局部细节建模与全局动态感知，提高了心射血分数估算的准确性。|
|🆕 发布|SFormer: SNR-guided Transformer for Underwater Image Enhancement from the Frequency Domain|SFormer：基于信噪比的频域水下图像增强Transformer模型|Xin Tian, Yingtie Lei, Xiujun Zhang, Zimeng Li, Chi-Man Pun, Xuhang Chen|<http://arxiv.org/pdf/2508.18664v1>|提出利用频域中的信噪比指导的Transformer模型，有效提升了水下图像增强的质量。|
|📝 更新|PersPose: 3D Human Pose Estimation with Perspective Encoding and Perspective Rotation|透视编码与透视旋转的3D人体姿态估计方法（PersPose）|Xiaoyang Hao, Han Li|<http://arxiv.org/pdf/2508.17239v2>|[代码](https://github.com/KenAdamsJoseph/PersPose.); 引入视角编码和视角旋转技术，提出PersPose框架，显著提升单目3D人体姿态估计精度。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Random forest-based out-of-distribution detection for robust lung cancer segmentation|基于随机森林的异常分布检测用于稳健的肺癌分割|Aneesh Rangnekar, Harini Veeraraghavan|<http://arxiv.org/pdf/2508.19112v1>|提出RF-Deep方法，利用随机森林和预训练的深度特征检测异常CT扫描，提升肺癌分割可靠性。|
|📝 更新|Single-Domain Generalized Object Detection by Balancing Domain Diversity and Invariance|单域泛化目标检测：平衡域多样性与不变性|Zhenwei He, Hongsu Ni|<http://arxiv.org/pdf/2502.03835v2>|提出了一种平衡领域多样性和不变性的检测模型，有效整合了领域特性与通用性，提升了单领域对象检测的泛化能...|
|🆕 发布|DQEN: Dual Query Enhancement Network for DETR-based HOI Detection|DQEN：基于DETR的交互动作检测的双查询增强网络|Zhehao Li, Chong Wang, Yi Chen, Yinghao Lu, Jiangbo Qian, Jiong Wang, Jiafei Wu|<http://arxiv.org/pdf/2508.18896v1>|[代码](https://github.com/lzzhhh1019/DQEN.); 提出了一种双查询增强网络，通过对象感知特性和交互语义融合，提高了基于DETR的交互检测模型的准确性。|
|🆕 发布|Are All Marine Species Created Equal? Performance Disparities in Underwater Object Detection|Image 所有海洋物种都是平等的？水下目标检测的性能差异|Melanie Wille, Tobias Fischer, Scarlett Raine|<http://arxiv.org/pdf/2508.18729v1>|揭示了水下物体检测中不同物种检测性能的差异，并提出了针对性的数据分布优化和算法改进策略。|
|📝 更新|Finding Outliers in a Haystack: Anomaly Detection for Large Pointcloud Scenes|在干草堆中寻找异常：大型点云场景的异常检测|Ryan Faulkner, Luke Haub, Simon Ratcliffe, Tat-Jun Chin|<http://arxiv.org/pdf/2508.17634v2>|提出了一种结合Mamba架构和重建方法的开集分割新策略，有效提升大型点云场景异常检测性能。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Understanding Benefits and Pitfalls of Current Methods for the Segmentation of Undersampled MRI Data|理解当前方法在分割欠采样MRI数据中的优势和陷阱|Jan Nikolas Morshuis, Matthias Hein, Christian F. Baumgartner|<http://arxiv.org/pdf/2508.18975v1>|对比了七种加速MRI数据分割方法，发现简单两阶段方法在性能上超越专门为此任务开发的方法。|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space|“VoxHammer：无需训练的精确且连贯的本土三维空间中的三维编辑”|Lin Li, Zehuan Huang, Haoran Feng, Gengxiong Zhuang, Rui Chen, Chunchao Guo, Lu Sheng|<http://arxiv.org/pdf/2508.19247v1>|[代码](https://huanngzh.github.io/VoxHammer-Page); 提出了VoxHammer方法，在无需训练的情况下实现精确且连贯的3D模型局部编辑。|
|🆕 发布|OmniHuman-1.5: Instilling an Active Mind in Avatars via Cognitive Simulation|全方位人类1.5：通过认知模拟赋予虚拟化身活跃思维|Jianwen Jiang, Weihong Zeng, Zerong Zheng, Jiaqi Yang, Chao Liang, Wang Liao, Han Liang, Yuan Zhang .etc.|<http://arxiv.org/pdf/2508.19209v1>|[代码](https://omnihuman-lab.github.io/v1_5); 引入认知模拟以生成具有深层语义理解和情感表达的个性化虚拟角色动画。|
|📝 更新|CAD-Assistant: Tool-Augmented VLLMs as Generic CAD Task Solvers|CAD辅助工具：工具增强型VLLM作为通用CAD任务解决者|Dimitrios Mallis, Ahmet Serdar Karadeniz, Sebastian Cavada, Danila Rukhovich, Niki Foteinopoulou, Kseniya Cherenkova, Anis Kacem, Djamila Aouada|<http://arxiv.org/pdf/2412.13810v3>|提出CAD-Assistant，利用大型视觉和语言模型及CAD工具，解决通用CAD设计问题。|
|🆕 发布|Beyond the Textual: Generating Coherent Visual Options for MCQs|超越文本：为选择题生成连贯的视觉选项|Wanqiang Wang, Longzhu He, Wei Zheng|<http://arxiv.org/pdf/2508.18772v1>|提出了一种生成含视觉选项的教育选择题的新框架，有效解决了高质量视觉干扰项生成难题。|
|🆕 发布|OwlCap: Harmonizing Motion-Detail for Video Captioning via HMD-270K and Caption Set Equivalence Reward|猫头鹰帽：通过HMD-270K和字幕集等价奖励协调运动细节进行视频字幕生成|Chunlin Zhong, Qiuxia Hou, Zhangjun Zhou, Shuang Hao, Haonan Lu, Yanhao Zhang, He Tang, Xiang Bai|<http://arxiv.org/pdf/2508.18634v1>|提出平衡运动与细节的视频字幕生成方法，通过构建HMD-270K数据集和CSER奖励机制提升字幕完整性...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LSD-3D: Large-Scale 3D Driving Scene Generation with Geometry Grounding|大规模三维驾驶场景生成与几何接地|Julian Ost, Andrea Ramazzina, Amogh Joshi, Maximilian Bömer, Mario Bijelic, Felix Heide|<http://arxiv.org/pdf/2508.19204v1>|提出了一种生成具有精确几何结构的大规模3D驾驶场景的方法，结合代理几何与环境表示以及从2D图像先验中...|
|🆕 发布|FastMesh:Efficient Artistic Mesh Generation via Component Decoupling|快速网格：通过组件解耦实现高效艺术网格生成|Jeonghwan Kim, Yushi Lan, Armando Fortes, Yongwei Chen, Xingang Pan|<http://arxiv.org/pdf/2508.19188v1>|通过分离顶点和面来减少冗余，FastMesh使用自回归模型生成顶点并利用双向变换器一步构建网格，实现...|
|📝 更新|mRAG: Elucidating the Design Space of Multi-modal Retrieval-Augmented Generation|多模态检索增强生成的设计空间解析：mRAG方法|Chan-Wei Hu, Yueqi Wang, Shuo Xing, Chia-Ju Chen, Suofei Feng, Ryan Rossi, Zhengzhong Tu|<http://arxiv.org/pdf/2505.24073v2>|系统解析了多模态检索增强生成框架，提升了大型视觉语言模型在动态应用中的性能。|
|🆕 发布|VibES: Induced Vibration for Persistent Event-Based Sensing|振动诱导：用于持续事件驱动的感知|Vincenzo Polizzi, Stephen Yang, Quentin Clark, Jonathan Kelly, Igor Gilitschenski, David B. Lindell|<http://arxiv.org/pdf/2508.19094v1>|通过引入旋转不平衡质量产生振动，实现了持续事件生成，提高了事件相机在静态或低运动场景下的感知能力。|
|📝 更新|ForgetMe: Evaluating Selective Forgetting in Generative Models|《ForgetMe：评估生成模型中的选择性遗忘》|Zhenyu Yu, Mohd Yamani Inda Idris, Pei Wang|<http://arxiv.org/pdf/2504.12574v3>|提出了一种自动数据集构建框架和评估指标，用于提高生成模型中的选择性遗忘效果并保护隐私。|
|🆕 发布|Enhancing Document VQA Models via Retrieval-Augmented Generation|通过检索增强的生成方式提升文档视觉问答模型|Eric López, Artemis Llabrés, Ernest Valveny|<http://arxiv.org/pdf/2508.18984v1>|提出了一种基于检索增强生成的文档视觉问答方法，有效提升了长文档处理性能。|
|📝 更新|MultiRef: Controllable Image Generation with Multiple Visual References|多参考可控图像生成方法：基于多个视觉参考|Ruoxi Chen, Dongping Chen, Siyuan Wu, Sinan Wang, Shiyun Lang, Petr Sushko, Gaoyang Jiang, Yao Wan .etc.|<http://arxiv.org/pdf/2508.06905v3>|[代码](https://multiref.github.io/.); 提出多视觉参考可控图像生成方法，构建评价框架和高质量图像数据集，提升生成图像的多样性和准确性。|
|📝 更新|Solar Altitude Guided Scene Illumination|太阳高度引导的场景照明|Samed Doğan, Maximilian Hoh, Nico Leuze, Nicolas Rodriguez Peña, Alfred Schöttl|<http://arxiv.org/pdf/2507.05812v2>|引入太阳高度角作为全局条件变量，无需手动标注，有效生成日间光照变化的合成图像数据。|
|🆕 发布|Generative AI in Map-Making: A Technical Exploration and Its Implications for Cartographers|地图绘制中的生成式人工智能：技术探索及其对制图师的影响|Claudio Affolter, Sidi Wu, Yizi Chen, Lorenz Hurni|<http://arxiv.org/pdf/2508.18959v1>|提出利用生成式AI结合向量数据指导地图生成，实现了风格可控的高精度地图自动化制作。|
|📝 更新|Waver: Wave Your Way to Lifelike Video Generation|波动：以波动方式迈向逼真视频生成|Yifu Zhang, Hao Yang, Yuqi Zhang, Yifei Hu, Fengda Zhu, Chuang Lin, Xiaofeng Mei, Yi Jiang .etc.|<http://arxiv.org/pdf/2508.15761v2>|[代码](https://github.com/FoundationVision/Waver.); 提出Waver模型，实现了一体化图像与视频生成，通过Hybrid Stream DiT架构提升模态对...|
|🆕 发布|Quantum-Circuit-Based Visual Fractal Image Generation in Qiskit and Analytics|基于量子电路的Qiskit视觉分形图像生成与分析|Hillol Biswas|<http://arxiv.org/pdf/2508.18835v1>|探索量子计算在分形图像生成中的应用，利用量子电路生成Julia集数据集。|
|🆕 发布|Embedding Font Impression Word Tags Based on Co-occurrence|基于共现关系的字体印象词语标签嵌入|Yugo Kubota, Seiichi Uchida|<http://arxiv.org/pdf/2508.18825v1>|提出了一种基于字体形状与印象标签共现关系的嵌入方法，有效提升了印象引导的字体生成和检索性能。|
|📝 更新|Visual-CoG: Stage-Aware Reinforcement Learning with Chain of Guidance for Text-to-Image Generation|视觉-认知图：面向文本到图像生成的阶段感知引导链强化学习|Yaqi Li, Peng Chen, Mingyang Han, Pi Bu, Haoxiang Shi, Runzhou Zhao, Yang Yao, Xuan Zhang .etc.|<http://arxiv.org/pdf/2508.18032v2>|提出Visual-CoG方法，通过分阶段奖励提升文本到图像生成中多属性和模糊提示的处理能力。|
|🆕 发布|Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vectorized Drawings|从矢量绘图到CAD生成的序列到序列学习：Drawing2CAD|Feiwei Qin, Shichao Lu, Junhao Hou, Changmiao Wang, Meie Fang, Ligang Liu|<http://arxiv.org/pdf/2508.18733v1>|[代码](https://github.com/lllssc/Drawing2CAD.); 将2D工程图纸自动转换为参数化CAD模型的序列到序列学习框架，提高了几何精度和设计意图的保持。|
|📝 更新|Prompting with Sign Parameters for Low-resource Sign Language Instruction Generation|使用符号参数提示进行低资源手语教学生成|Md Tariquzzaman, Md Farhan Ishmam, Saiyma Sittul Muna, Md Kamrul Hasan, Hasan Mahmud|<http://arxiv.org/pdf/2508.16076v2>|提出SPI prompting方法，通过整合标准手语参数提升低资源手语教学指导生成性能。|
|🆕 发布|ROSE: Remove Objects with Side Effects in Videos|ROSE: 视频中移除具有副作用的对象|Chenxuan Miao, Yutong Feng, Jianshu Zeng, Zixiang Gao, Hantang Liu, Yunfeng Yan, Donglian Qi, Xi Chen .etc.|<http://arxiv.org/pdf/2508.18633v1>|[代码](https://rose2025-inpaint.github.io/.); 提出ROSE框架，通过3D渲染合成数据，有效去除视频中的对象及其副作用如阴影和反射。|
|🆕 发布|Wan-S2V: Audio-Driven Cinematic Video Generation|《Wan-S2V：音频驱动的电影级视频生成》|Xin Gao, Li Hu, Siqi Hu, Mingyang Huang, Chaonan Ji, Dechao Meng, Jinwei Qi, Penchong Qiao .etc.|<http://arxiv.org/pdf/2508.18621v1>|提出Wan-S2V模型，通过音频驱动实现电影级角色动画，大幅提升表达性和逼真度。|
|🆕 发布|The Mind's Eye: A Multi-Faceted Reward Framework for Guiding Visual Metaphor Generation|《心智之眼：一种多面向的奖励框架，用于指导视觉隐喻生成》|Girish A. Koushik, Fatemeh Nazarieh, Katherine Birch, Shenbin Qian, Diptesh Kanojia|<http://arxiv.org/pdf/2508.18569v1>|提出了一种自评估的视觉隐喻生成框架，通过源-目标-意义映射和轻量级强化学习实现隐喻对齐。|
|🆕 发布|SemLayoutDiff: Semantic Layout Generation with Diffusion Model for Indoor Scene Synthesis|语义布局差异：基于扩散模型的室内场景合成语义布局生成|Xiaohao Sun, Divyam Goel, Angle X. Chang|<http://arxiv.org/pdf/2508.18597v1>|提出了一种结合扩散模型和语义图的室内场景合成方法，实现了在建筑约束下的多样化三维室内场景生成。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|All-in-One Slider for Attribute Manipulation in Diffusion Models|"用于扩散模型属性操作的全方位滑块"|Weixin Ye, Hongguang Zhu, Wei Wang, Yahui Liu, Mengyu Wang|<http://arxiv.org/pdf/2508.19195v1>|[代码](https://github.com/ywxsuperstar/KSAE-FaceSteer.); 提出了一种通用型All-in-One Slider模块，实现了对图像属性的精细连续控制，无需为每个新...|
|📝 更新|Enhancing Underwater Images via Deep Learning: A Comparative Study of VGG19 and ResNet50-Based Approaches|基于深度学习的 underwater 图像增强：基于 VGG19 和 ResNet50 的方法比较研究|Aoqi Li, Yanghui Song, Jichao Dao, Chengfu Yang|<http://arxiv.org/pdf/2508.17397v2>|提出了一种融合VGG19和ResNet50的深度学习方法，有效提升了复杂水下场景图像的增强效果。|
|📝 更新|DiffBlender: Composable and Versatile Multimodal Text-to-Image Diffusion Models|DiffBlender：可组合且多功能的文本到图像扩散模型|Sungnyun Kim, Junsoo Lee, Kibeom Hong, Daesik Kim, Namhyuk Ahn|<http://arxiv.org/pdf/2305.15194v3>|[代码](https://github.com/sungnyun/diffblender.); 提出了一种统一框架下的多模态文本到图像生成模型，有效整合结构、布局和属性信息，提升了图像合成的多样性...|
|📝 更新|LATex: Leveraging Attribute-based Text Knowledge for Aerial-Ground Person Re-Identification|LATex：利用基于属性的文字知识进行天地人重识别|Xiang Hu, Yuhao Wang, Pingping Zhang, Huchuan Lu|<http://arxiv.org/pdf/2503.23722v2>|利用属性文本知识，提出prompt-tuning策略的AG-ReID框架，提升识别性能。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Generative Data Augmentation for Object Point Cloud Segmentation|生成数据增强在目标点云分割中的应用|Dekai Zhu, Stefan Gavranovic, Flavien Boussuge, Benjamin Busam, Slobodan Ilic|<http://arxiv.org/pdf/2505.17783v2>|提出了一种基于生成模型的点云分割数据增强方法，通过少量标注样本生成多样化训练数据，提升了模型性能。|
|🆕 发布|USO: Unified Style and Subject-Driven Generation via Disentangled and Reward Learning|统一风格与主题驱动的解耦与奖励学习生成模型：USO|Shaojin Wu, Mengqi Huang, Yufeng Cheng, Wenxu Wu, Jiahe Tian, Yiming Luo, Fei Ding, Qian He|<http://arxiv.org/pdf/2508.18966v1>|[代码](https://github.com/bytedance/USO); 提出统一风格与主题生成框架USO，通过解耦学习与奖励学习实现风格与主题的协同优化。|
|🆕 发布|Harnessing Meta-Learning for Controllable Full-Frame Video Stabilization|利用元学习实现可控的全帧视频稳定化|Muhammad Kashif Ali, Eun Woo Im, Dongjin Kim, Tae Hyun Kim, Vivek Gupta, Haonan Luo, Tianrui Li|<http://arxiv.org/pdf/2508.18859v1>|利用元学习快速适应每个视频，提出针对性的稳定化策略，显著提升全帧视频稳定性和视觉质量。|
|🆕 发布|Hidden Tail: Adversarial Image Causing Stealthy Resource Consumption in Vision-Language Models|《隐藏尾巴：在视觉-语言模型中引起隐秘资源消耗的对抗性图像》|Rui Zhang, Zihan Wang, Tianli Yang, Hongwei Li, Wenbo Jiang, Qingchuan Zhao, Yang Liu, Guowen Xu|<http://arxiv.org/pdf/2508.18805v1>|[代码](https://github.com/zhangrui4041/Hidden_Tail.); 提出了一种隐秘的资源消耗攻击方法Hidden Tail，通过生成特殊标记诱导视觉语言模型产生最大长度...|
|📝 更新|Generative Feature Imputing -- A Technique for Error-resilient Semantic Communication|生成特征填充 -- 一种用于错误鲁棒性语义通信的技术|Jianhao Huang, Qunsong Zeng, Hongyang Du, Kaibin Huang|<http://arxiv.org/pdf/2508.17957v2>|提出了一种生成特征填充框架，通过集中特征误差和利用扩散模型重建丢失特征，提高了语义通信的鲁棒性和效率...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SoccerNet 2025 Challenges Results|"SoccerNet 2025挑战赛结果"|Silvio Giancola, Anthony Cioppa, Marc Gutiérrez-Pérez, Jan Held, Carlos Hinojosa, Victor Joos, Arnaud Leduc, Floriane Magera .etc.|<http://arxiv.org/pdf/2508.19182v1>|推动足球视频理解的计算机视觉研究，通过四项任务挑战提升技术进展。|
|🆕 发布|GReAT: leveraging geometric artery data to improve wall shear stress assessment|GReAT：利用几何动脉数据提高壁面剪切应力评估|Julian Suk, Jolanda J. Wentzel, Patryk Rygiel, Joost Daemen, Daniel Rueckert, Jelmer M. Wolterink|<http://arxiv.org/pdf/2508.19030v1>|利用自监督预训练和基础模型从几何动脉大数据中学习表征，提升冠状动脉模型壁面剪切应力评估准确性。|
|📝 更新|Survey on Monocular Metric Depth Estimation|单目测距深度估计综述|Jiuling Zhang|<http://arxiv.org/pdf/2501.11841v4>|综述了单目绝对尺度深度估计的发展，强调了高质量数据集的重要性并指出未来挑战。|
|🆕 发布|ColorGS: High-fidelity Surgical Scene Reconstruction with Colored Gaussian Splatting|彩色高斯散点法实现的高保真手术场景重建|Qun Ji, Peng Li, Mingqiang Wei|<http://arxiv.org/pdf/2508.18696v1>|提出ColorGS框架，通过自适应颜色编码和增强形变模型，实现了高清手术场景重建。|
|📝 更新|TRAN-D: 2D Gaussian Splatting-based Sparse-view Transparent Object Depth Reconstruction via Physics Simulation for Scene Update|基于二维高斯散点法的稀疏视角透明物体深度重建：通过物理仿真实现场景更新中的TRAN-D|Jeongyun Kim, Seunghoon Jeong, Giseop Kim, Myung-Hwan Jeon, Eunji Jun, Ayoung Kim|<http://arxiv.org/pdf/2507.11069v3>|[代码](https://jeongyun0609.github.io/TRAN-D); 提出了一种基于2D高斯散点法的透明物体深度重建技术，通过物理仿真实现场景动态更新，显著提升了重建精度...|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MCGS: Multiview Consistency Enhancement for Sparse-View 3D Gaussian Radiance Fields|多视角一致性增强用于稀疏视图三维高斯辐射场：MCGS|Yuru Xiao, Deming Zhai, Wenbo Zhao, Kui Jiang, Junjun Jiang, Xianming Liu|<http://arxiv.org/pdf/2410.11394v2>|提出了一种基于3D高斯散点的多视角一致性增强框架MCGS，用于从稀疏视角重建逼真场景。|
|📝 更新|Incremental Multi-Scene Modeling via Continual Neural Graphics Primitives|通过持续神经图形基元实现的增量多场景建模|Prajwal Singh, Ashish Tiwari, Gautam Vashishtha, Shanmuganathan Raman|<http://arxiv.org/pdf/2411.19903v4>|提出了一种持续学习框架C-NGP，将多个3D场景逐步整合到一个NeRF模型中，无需重访旧数据即可适应...|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Automated Feature Tracking for Real-Time Kinematic Analysis and Shape Estimation of Carbon Nanotube Growth|碳纳米管生长的实时运动分析和形状估计自动化特征跟踪|Kaveh Safavigerdini, Ramakrishna Surya, Jaired Collins, Prasad Calyam, Filiz Bunyak, Matthew R. Maschmann, Kannappan Palaniappan|<http://arxiv.org/pdf/2508.19232v1>|提出了一种自动特征跟踪框架VFTrack，实现了碳纳米管生长过程中实时动态分析及形态估计。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ProPy: Building Interactive Prompt Pyramids upon CLIP for Partially Relevant Video Retrieval|ProPy：基于CLIP构建部分相关视频检索的交互式提示金字塔|Yi Pan, Yujia Zhang, Michael Kampffmeyer, Xiaoguang Zhao|<http://arxiv.org/pdf/2508.19024v1>|[代码](https://github.com/BUAAPY/ProPy.); 提出ProPy模型，通过Prompt Pyramid结构和Ancestor-Descendant交互...|
|📝 更新|Fast Motion Estimation and Context-Aware Refinement for Efficient Bayer-Domain Video Vision|快速运动估计与上下文感知细化以提高拜耳域视频视觉效率|Haichao Wang, Xinyue Xi, Jiangtao Wen, Yuxing Han|<http://arxiv.org/pdf/2508.05990v2>|提出高效视频视觉系统，采用快速块匹配运动估计和上下文感知细化，减少计算负担并提升效率。|
|📝 更新|Neuro Symbolic Knowledge Reasoning for Procedural Video Question Answering|神经符号知识推理在程序性视频问答中的应用|Thanh-Son Nguyen, Hong Yang, Tzeh Yuan Neoh, Hao Zhang, Ee Yeo Keat, Basura Fernando|<http://arxiv.org/pdf/2503.14957v3>|[代码](https://github.com/LUNAProject22/KML.); 提出PKR-QA基准和知识模块学习法，提升 procedural video question an...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Online Micro-gesture Recognition Using Data Augmentation and Spatial-Temporal Attention|在线微手势识别：基于数据增强与时空注意力机制|Pengyu Liu, Kun Li, Fei Wang, Yanyan Wei, Junhui She, Dan Guo|<http://arxiv.org/pdf/2507.09512v2>|提出手工程序数据增强和时空注意力机制，用于在线微手势识别，显著提升分类和定位准确性。|
|🆕 发布|A Novel Deep Hybrid Framework with Ensemble-Based Feature Optimization for Robust Real-Time Human Activity Recognition|一种基于集成特征优化的新颖深度混合框架，用于稳健的实时人体行为识别|Wasi Ullah, Yasir Noman Khalid, Saddam Hussain Khan|<http://arxiv.org/pdf/2508.18695v1>|提出了一种集成优化的深度学习框架，通过特征选择策略提升实时人体活动识别的准确性和效率。|
|📝 更新|Confidence-driven Gradient Modulation for Multimodal Human Activity Recognition: A Dynamic Contrastive Dual-Path Learning Approach|基于置信度的梯度调制用于多模态人体行为识别：动态对比双路径学习方法|Panpan Ji, Junni Song, Yifan Lu, Hang Xiao, Hanyu Liu, Chao Li|<http://arxiv.org/pdf/2507.02826v3>|提出动态对比双路径网络，通过信心驱动的梯度调制策略解决多模态人体行为识别中的模态竞争问题。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Style4D-Bench: A Benchmark Suite for 4D Stylization|Style4D-Bench：四维风格化基准测试套件|Beiqi Chen, Shuai Shao, Haitang Feng, Jianhuang Lai, Jianlou Si, Guangcong Wang|<http://arxiv.org/pdf/2508.19243v1>|[代码](https://github.com/Becky-catherine/Style4D-Bench); 提出了Style4D-Bench基准套件，为4D风格化提供标准化评估，并通过Style4D框架实现时...|
|📝 更新|PhysioSync: Temporal and Cross-Modal Contrastive Learning Inspired by Physiological Synchronization for EEG-Based Emotion Recognition|生理同步启发的时序与跨模态对比学习用于基于EEG的情感识别：PhysioSync|Kai Cui, Jia Li, Yu Liu, Xuesong Zhang, Zhenzhen Hu, Meng Wang|<http://arxiv.org/pdf/2504.17163v2>|提出PhysioSync框架，通过时序和跨模态对比学习，提升基于EEG的情绪识别准确度。|
|📝 更新|Memory augment is All You Need for image restoration|记忆增强是图像恢复的全部所需|Xiao Feng Zhang, Chao Chen Gu, Shan Ying Zhu|<http://arxiv.org/pdf/2309.01377v2>|[代码](https://github.com/zhangbaijin/MemoryNet); 提出三粒度记忆层和对比学习框架MemoryNet，有效提升图像复原质量和感知真实性。|
|🆕 发布|Clustering-based Feature Representation Learning for Oracle Bone Inscriptions Detection|基于聚类的特征表示学习在甲骨文检测中的应用|Ye Tao, Xinran Fu, Honglin Pang, Xi Yang, Chuntao Li|<http://arxiv.org/pdf/2508.18641v1>|提出了一种基于聚类学习的特征表示方法，利用甲骨文字库增强检测网络性能，显著提升了甲骨文自动检测的准确...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Pixie: Fast and Generalizable Supervised Learning of 3D Physics from Pixels|《Pixie：从像素中快速且通用监督学习三维物理》|Long Le, Ryan Lucas, Chen Wang, Chuhao Chen, Dinesh Jayaraman, Eric Eaton, Lingjie Liu|<http://arxiv.org/pdf/2508.17437v2>|提出了一种快速且可泛化的方法PIXIE，通过监督学习预测3D场景物理属性，大幅超越传统优化方法的速度...|
|📝 更新|MicroMIL: Graph-Based Multiple Instance Learning for Context-Aware Diagnosis with Microscopic Images|微米级MIL：基于图的多个实例学习，用于微观图像的上下文感知诊断|Jongwoo Kim, Bryan Wong, Huazhu Fu, Willmer Rafell Quiñones, Youngsin Ko, Mun Yong Yi|<http://arxiv.org/pdf/2407.21604v4>|[代码](https://github.com/kimjongwoo-cell/MicroMIL); 提出MicroMIL框架，通过弱监督学习提升传统显微镜图像的癌症诊断准确性和鲁棒性。|
|📝 更新|Less is More: Token-Efficient Video-QA via Adaptive Frame-Pruning and Semantic Graph Integration|少即是多：通过自适应帧剪枝和语义图集成的低标记效率视频问答|Shaoguang Wang, Ziyang Chen, Yijie Xu, Weiyu Guo, Hui Xiong|<http://arxiv.org/pdf/2508.03337v4>|提出自适应帧剪枝和语义图集成方法，减少视频问答中的帧数和输入token，提高效率和准确度。|
|📝 更新|WetCat: Enabling Automated Skill Assessment in Wet-Lab Cataract Surgery Videos|《湿猫：实现湿实验室白内障手术视频中的自动化技能评估》|Negin Ghamsarian, Raphael Sznitman, Klaus Schoeffmann, Jens Kowal|<http://arxiv.org/pdf/2506.08896v3>|介绍了WetCat数据集，通过高分辨率视频和详细标注，实现了白内障手术技能的自动化评估。|
|🆕 发布|PanoHair: Detailed Hair Strand Synthesis on Volumetric Heads|全景毛发：体素人头上的详细毛发丝合成|Shashikant Verma, Shanmuganathan Raman|<http://arxiv.org/pdf/2508.18944v1>|提出了一种高效生成真实感头发的方法PanoHair，通过预训练模型简化数据采集并快速生成多样发型。|
|📝 更新|Uncertainty-Guided Face Matting for Occlusion-Aware Face Transformation|遮挡感知人脸变换的不确定性引导人脸抠图|Hyebin Cho, Jaehyup Lee|<http://arxiv.org/pdf/2508.03055v2>|[代码](https://github.com/hyebin-c/FaceMat.git); 提出了一种无需额外输入的实时面部遮挡处理方法，通过不确定性指导的精细alpha matte估计，提高...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Bag of Tricks for Efficient Implicit Neural Point Clouds|《高效隐式神经点云的技巧集》|Florian Hahlbohm, Linus Franke, Leon Overkämping, Paula Wespe, Susana Castillo, Martin Eisemann, Marcus Magnor|<http://arxiv.org/pdf/2508.19140v1>|提出一系列优化策略，显著提升了隐式神经点云的渲染效率和质量。|
|🆕 发布|Time Series Analysis of Spiking Neural Systems via Transfer Entropy and Directed Persistent Homology|通过转移熵和有向持久同调对尖峰神经系统的时序分析|Dylan Peek, Siddharth Pritam, Matthew P. Skerritt, Stephan Chalup|<http://arxiv.org/pdf/2508.19048v1>|整合转移熵与有向持久同调分析神经时间序列，揭示复杂神经系统的全局组织模式。|
|🆕 发布|Automated Classification of Normal and Atypical Mitotic Figures Using ConvNeXt V2: MIDOG 2025 Track 2|使用ConvNeXt V2自动分类正常和异常有丝分裂图像：MIDOG 2025第2赛道|Yosuke Yamagishi, Shouhei Hanaoka|<http://arxiv.org/pdf/2508.18831v1>|利用ConvNeXt V2模型和中心裁剪预处理，有效区分正常与异常有丝分裂图像。|
|🆕 发布|Design, Implementation and Evaluation of a Real-Time Remote Photoplethysmography (rPPG) Acquisition System for Non-Invasive Vital Sign Monitoring|设计、实现与评估一种用于无创生命体征监测的实时远程光电容积描记图（rPPG）采集系统|Constantino Álvarez Casado, Sasan Sharifipour, Manuel Lage Cañellas, Nhi Nguyen, Le Nguyen, Miguel Bordallo López|<http://arxiv.org/pdf/2508.18787v1>|设计并实现了一种面向低功耗设备的实时远程光电容积描记术(rPPG)系统，用于从面部视频流中提取生理信...|
|🆕 发布|Stabilizing Open-Set Test-Time Adaptation via Primary-Auxiliary Filtering and Knowledge-Integrated Prediction|通过主辅滤波和知识集成预测稳定开放集测试时适应|Byung-Joon Lee, Jin-Seop Lee, Jee-Hyong Lee|<http://arxiv.org/pdf/2508.18751v1>|[代码](https://github.com/powerpowe/PAF-KIP-OSTTA); 提出了一种用于稳定开放集测试时适应性的主辅滤波和知识集成预测方法，有效提升了闭集准确性和开放集辨识度...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|TimeFlow: Temporal Conditioning for Longitudinal Brain MRI Registration and Aging Analysis|时间流：用于纵向脑部MRI配准与衰老分析的时间条件设定|Bailiang Jian, Jiazhen Pan, Yitong Li, Fabian Bongratz, Ruochen Li, Daniel Rueckert, Benedikt Wiestler, Christian Wachinger|<http://arxiv.org/pdf/2501.08667v3>|TimeFlow通过引入基于年龄的连续神经解剖模型，实现了仅需两张扫描图的精准脑部MRI配准和未来状...|
|📝 更新|Meta-Learned Modality-Weighted Knowledge Distillation for Robust Multi-Modal Learning with Missing Data|元学习模态加权知识蒸馏用于具有缺失数据的数据稳健多模态学习|Hu Wang, Salma Hassan, Yuyuan Liu, Congbo Ma, Yuanhong Chen, Qing Li, Jiahui Geng, Bingjie Wang .etc.|<http://arxiv.org/pdf/2405.07155v4>|[代码](https://github.com/billhhh/MetaKD.); 提出了一种自适应估计模态重要性的元学习知识蒸馏方法，有效提升缺失数据下的多模态学习鲁棒性。|
|🆕 发布|Preliminary Study on Space Utilization and Emergent Behaviors of Group vs. Single Pedestrians in Real-World Trajectories|现实世界轨迹中群组与单个行人在空间利用与涌现行为方面的初步研究|Amartaivan Sanjjamts, Morita Hiroshi|<http://arxiv.org/pdf/2508.18939v1>|提出了一种基于轨迹数据和Transformer模型的框架，区分群体与单独行人，并分析其空间利用与行为...|
|🆕 发布|Boosting Micro-Expression Analysis via Prior-Guided Video-Level Regression|通过先验引导的视频级回归增强微表情分析|Zizheng Guo, Bochao Zou, Yinuo Jia, Xiangyu Li, Huimin Ma|<http://arxiv.org/pdf/2508.18834v1>|[代码](https://github.com/zizheng-guo/BoostingVRME.); 提出了一种基于先验引导的视频级回归方法，有效捕捉微表情的复杂时间动态并提升识别精度。|
|🆕 发布|Quantitative Outcome-Oriented Assessment of Microsurgical Anastomosis|定量导向评估显微外科吻合术结果|Luyin Hu, Soheil Gholami, George Dindelegan, Torstein R. Meling, Aude Billard|<http://arxiv.org/pdf/2508.18836v1>|提出了一种基于图像处理的客观评估框架，提高了微手术吻合技术评估的效率和可靠性。|
|📝 更新|Benchmarking XAI Explanations with Human-Aligned Evaluations|以人类对齐评估对XAI解释进行基准测试|Rémi Kazmierczak, Steve Azzolin, Eloïse Berthier, Anna Hedström, Patricia Delhomme, David Filliat, Nicolas Bousquet, Goran Frehse .etc.|<http://arxiv.org/pdf/2411.02470v2>|提出了一种以人类为中心的XAI评估框架，创建了首个大规模多模型和多方法类型的PASTA-datase...|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Faster Parameter-Efficient Tuning with Token Redundancy Reduction|更高效的参数调整加速：通过减少标记冗余|Kwonyoung Kim, Jungin Park, Jin Kim, Hyeongjun Kwon, Kwanghoon Sohn|<http://arxiv.org/pdf/2503.20282v2>|提出FPET方法，通过减少token冗余提升参数高效微调的速度和存储效率。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Is Uncertainty Quantification a Viable Alternative to Learned Deferral?|不确定性量化是否是学习延迟的可行替代方案？|Anna M. Wundram, Christian F. Baumgartner|<http://arxiv.org/pdf/2508.02319v2>|探究了不确定性量化方法作为AI决策延期的替代方案，发现其在处理分布外数据时更具鲁棒性。|
|📝 更新|Quantifying and Alleviating Co-Adaptation in Sparse-View 3D Gaussian Splatting|量化并减轻稀疏视图三维高斯散点绘制中的共适应现象|Kangjie Chen, Yingji Zhong, Zhihao Li, Jiaqi Lin, Youyu Chen, Minghan Qin, Haoqian Wang|<http://arxiv.org/pdf/2508.12720v2>|提出量化方法揭示3D Gaussian Splatting在稀疏视角下的自适应问题，并提出两种策略减...|
|🆕 发布|Uncertainty Awareness on Unsupervised Domain Adaptation for Time Series Data|时间序列数据无监督域自适应中的不确定性感知|Weide Liu, Xiaoyang Zhong, Lu Wang, Jingwen Hou, Yuemei Luo, Jiebin Yan, Yuming Fang|<http://arxiv.org/pdf/2508.18630v1>|引入多尺度特征提取和不确定性估计机制，提升时间序列数据无监督域自适应模型的泛化能力和鲁棒性。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SWiFT: Soft-Mask Weight Fine-tuning for Bias Mitigation|SWiFT：软掩码权重微调以减轻偏差|Junyu Yan, Feng Chen, Yuyang Xue, Yuning Du, Konstantinos Vilouras, Sotirios A. Tsaftaris, Steven McDonagh|<http://arxiv.org/pdf/2508.18826v1>|提出SWiFT框架，通过少量外部数据集和参数贡献区分的微调，有效降低模型偏见并保持性能。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Flatness-aware Curriculum Learning via Adversarial Difficulty|通过对抗性难度实现的平面性感知课程学习|Hiroaki Aizawa, Yoshikazu Hayashi|<http://arxiv.org/pdf/2508.18726v1>|提出了一种基于对抗性难度度量的平坦度感知课程学习策略，有效提升了模型的泛化能力和鲁棒性。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Articulate3D: Zero-Shot Text-Driven 3D Object Posing|Articulate3D：零样本文本驱动的三维物体姿态估计|Oishi Deb, Anjun Hu, Ashkan Khakzar, Philip Torr, Christian Rupprecht|<http://arxiv.org/pdf/2508.19244v1>|[代码](https://odeb1.github.io/articulate3d_page_deb); 提出了一种无需训练、基于文本指令控制的三维物体姿态调整方法 Articulate3D，通过图像生成和...|
|🆕 发布|ZeST: an LLM-based Zero-Shot Traversability Navigation for Unknown Environments|ZeST：一种基于大规模语言模型的未知环境零样本 traversal 导航方法|Shreya Gummadi, Mateus V. Gasparino, Gianluca Capezzuto, Marcelo Becker, Girish Chowdhary|<http://arxiv.org/pdf/2508.19131v1>|提出零样本地形通过性导航方法ZeST，利用大型语言模型视觉推理能力，无需危险环境即可实时生成通过性地...|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Few-Shot Connectivity-Aware Text Line Segmentation in Historical Documents|少量样本下的连通性感知文本行分割在历史文档中的应用|Rafael Sterzinger, Tingyu Lin, Robert Sablatnig|<http://arxiv.org/pdf/2508.19162v1>|[代码](https://github.com/RafaelSterzinger/acpr_few_shot_hist.); 提出了一种少量样本学习策略，通过轻量级网络结构和拓扑感知损失函数，有效提升历史文档文本行分割准确性和...|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning Binary Sampling Patterns for Single-Pixel Imaging using Bilevel Optimisation|使用双水平优化学习单像素成像的二值采样模式|Serban C. Tudosie, Alexander Denker, Zeljko Kereta, Simon Arridge|<http://arxiv.org/pdf/2508.19068v1>|提出了一种 bilevel 优化方法，学习特定任务的二值照明模式，以提升单像素成像的重建性能。|
|📝 更新|PointFix: Learning to Fix Domain Bias for Robust Online Stereo Adaptation|点修复：学习修正领域偏差以实现鲁棒的在线立体适配|Kwonyoung Kim, Jungin Park, Jiyoung Lee, Dongbo Min, Kwanghoon Sohn|<http://arxiv.org/pdf/2207.13340v2>|提出PointFix方法，通过辅助点选择网络解决在线立体匹配中的领域偏移问题，实现鲁棒初始化。|
|🆕 发布|C-Flat++: Towards a More Efficient and Powerful Framework for Continual Learning|C-Flat++：迈向更高效、更强大的持续学习框架|Wei Li, Hangjie Yuan, Zixiang Zhao, Yifan Zhu, Aojun Lu, Tao Feng, Yanan Sun|<http://arxiv.org/pdf/2508.18860v1>|[代码](https://github.com/WanNaa/C-Flat.); 提出C-Flat++框架，通过优化损失景观平坦度提升持续学习性能与效率。|
|🆕 发布|PseudoMapTrainer: Learning Online Mapping without HD Maps|伪图训练器：无需高精度地图的在线映射学习|Christian Löwens, Thorben Funke, Jingchao Xie, Alexandru Paul Condurache|<http://arxiv.org/pdf/2508.18788v1>|[代码](https://github.com/boschresearch/PseudoMapTrainer.); 提出了PseudoMapTrainer方法，通过使用伪标签进行在线地图学习，无需依赖高精度地图训练。|
|📝 更新|Curvature Learning for Generalization of Hyperbolic Neural Networks|用于双曲神经网络泛化的曲率学习|Xiaomeng Fan, Yuwei Wu, Zhi Gao, Mehrtash Harandi, Yunde Jia|<http://arxiv.org/pdf/2508.17232v2>|提出了一种基于PAC-Bayesian理论的 curvature learning方法，通过优化损失...|
|📝 更新|Decoupled Global-Local Alignment for Improving Compositional Understanding|解耦全局-局部对齐以提升组合理解能力|Xiaoxing Hu, Kaicheng Yang, Jun Wang, Haoran Xu, Ziyong Feng, Yupei Wang|<http://arxiv.org/pdf/2504.16801v3>|[代码](https://github.com/xiaoxing2001/DeGLA); 提出了一种解耦全局-局部对齐的框架DeGLA，通过自我蒸馏机制和新型对比损失，提升了视觉语言模型的组...|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models for Robotic Manipulation|《MemoryVLA：面向机器人操作的视觉-语言-动作模型中的感知-认知记忆》|Hao Shi, Bin Xie, Yingfei Liu, Lin Sun, Fengrong Liu, Tiancai Wang, Erjin Zhou, Haoqiang Fan .etc.|<http://arxiv.org/pdf/2508.19236v1>|[代码](https://shihao1895.github.io/MemoryVLA); 提出了一种结合认知科学与记忆机制的MemoryVLA框架，有效提升了机器人操作在长时序任务中的表现。|
|📝 更新|Enhancing Reusability of Learned Skills for Robot Manipulation via Gaze Information and Motion Bottlenecks|通过视线信息与运动瓶颈增强机器人操作学习技能的复用性|Ryo Takizawa, Izumi Karino, Koki Nakagawa, Yoshiyuki Ohmura, Yasuo Kuniyoshi|<http://arxiv.org/pdf/2502.18121v3>|[代码](https://crumbyrobotics.github.io/gazebot.); 提出GazeBot算法，通过利用视线信息和动作瓶颈提高机器人操作技能的复用性。|


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhanced UAV Path Planning Using the Tangent Intersection Guidance (TIG) Algorithm|使用切线交点引导（TIG）算法增强无人机路径规划|Hichem Cheriet, Khellat Kihel Badra, Chouraqui Samira|<http://arxiv.org/pdf/2508.18967v1>|提出Tangent Intersection Guidance算法，实现无人机在静态和动态环境下的高...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dual Enhancement on 3D Vision-Language Perception for Monocular 3D Visual Grounding|单目3D视觉定位中3D视觉-语言感知的双增强|Yuzhen Li, Min Liu, Yuan Bian, Xueping Wang, Zhaoyang Li, Gen Li, Yaonan Wang|<http://arxiv.org/pdf/2508.19165v1>|提出方法增强文本与几何特征在3D视觉定位中的协同作用，提升模型对三维空间的理解能力。|
|📝 更新|FUSELOC: Fusing Global and Local Descriptors to Disambiguate 2D-3D Matching in Visual Localization|FUSELOC：融合全局和局部描述符以消除视觉定位中2D-3D匹配的模糊性|Son Tung Nguyen, Alejandro Fontan, Michael Milford, Tobias Fischer|<http://arxiv.org/pdf/2408.12037v2>|[代码](https://github.com/sontung/descriptor-disambiguation); 融合全局和局部描述符以提高视觉定位中2D-3D匹配准确度，减少内存需求并提升效率。|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Ask Me Again Differently: GRAS for Measuring Bias in Vision Language Models on Gender, Race, Age, and Skin Tone|“再次以不同方式询问我：用于衡量视觉语言模型在性别、种族、年龄和肤色上的偏见的GRAS方法”|Shaivi Malik, Hasnat Md Abdullah, Sriparna Saha, Amit Sheth|<http://arxiv.org/pdf/2508.18989v1>|提出GRAS基准和GRAS偏置评分，用于全面评估视觉语言模型在性别、种族、年龄和肤色上的偏见。|
|🆕 发布|Can we make NeRF-based visual localization privacy-preserving?|我们能否使基于NeRF的视觉定位保持隐私保护？|Maxime Pietrantoni, Martin Humenberger, Torsten Sattler, Gabriela Csurka|<http://arxiv.org/pdf/2508.18971v1>|提出隐私保护的ppNeSF方法，通过神经分段场训练，实现视觉定位而不泄露敏感信息。|
|📝 更新|Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization|高斯散点特征场用于隐私保护的视觉定位|Maxime Pietrantoni, Gabriela Csurka, Torsten Sattler|<http://arxiv.org/pdf/2507.23569v2>|提出了一种结合3D几何模型与特征场的视觉定位方法，实现了高精度和隐私保护的定位效果。|
|📝 更新|Mind the (Language) Gap: Towards Probing Numerical and Cross-Lingual Limits of LVLMs|关注（语言）鸿沟：探讨大型视觉语言模型的数值和跨语言极限|Somraj Gautam, Abhirama Subramanyam Penamakuri, Abhishek Bhandari, Gaurav Harit|<http://arxiv.org/pdf/2508.17334v2>|提出MMCRICBENCH-3K基准，评估大型视觉语言模型在复杂数值和跨语言推理上的限制。|
|📝 更新|Weakly-Supervised 3D Visual Grounding based on Visual Language Alignment|基于视觉语言对齐的弱监督三维视觉定位|Xiaoxu Xu, Yitian Yuan, Qiudan Zhang, Wenhui Wu, Zequn Jie, Lin Ma, Xu Wang|<http://arxiv.org/pdf/2312.09625v5>|提出了一种基于大规模视觉语言模型的弱监督3D视觉定位方法，无需精细标注即可实现文本到3D点云的对应。|
|🆕 发布|Improving Noise Robust Audio-Visual Speech Recognition via Router-Gated Cross-Modal Feature Fusion|通过路由器门控跨模态特征融合提高噪声稳健的音频视觉语音识别|DongHoon Lim, YoungChae Kim, Dong-Hyun Kim, Da-Hee Yang, Joon-Hyuk Chang|<http://arxiv.org/pdf/2508.18734v1>|提出了一种自适应重加权音频和视觉特征的音频视觉语音识别框架，有效应对噪声环境下的识别挑战。|
|🆕 发布|Rethinking Human-Object Interaction Evaluation for both Vision-Language Models and HOI-Specific Methods|重新思考面向视觉语言模型和特定于人对象交互的方法的评价|Qinqian Lei, Bo Wang, Robby T. Tan|<http://arxiv.org/pdf/2508.18753v1>|提出新基准，将人机交互检测作为多选任务，以适应视觉语言模型和特定方法，避免误罚有效预测。|
|📝 更新|FastTracker: Real-Time and Accurate Visual Tracking|快速跟踪器：实时与精确的视觉跟踪|Hamidreza Hashempoor, Yu Dong Hwang|<http://arxiv.org/pdf/2508.14370v3>|[代码](https://github.com/Hamidreza-Hashempoor/FastTracker); 提出了一种通用的多目标跟踪框架，通过考虑遮挡和道路结构，实现了车辆等不同对象在复杂场景中的实时准确跟...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Prompt-based Dynamic Token Pruning for Efficient Segmentation of Medical Images|基于提示的动态标记剪枝用于医学图像的高效分割|Pallabi Dutta, Anubhab Maity, Sushmita Mitra|<http://arxiv.org/pdf/2506.16369v2>|提出了一种基于提示的动态令牌剪枝方法，有效降低医学图像处理中的计算需求并提升分割精度。|
|🆕 发布|MicroDetect-Net (MDN): Leveraging Deep Learning to Detect Microplastics in Clam Blood, a Step Towards Human Blood Analysis|微检测网络（MDN）：利用深度学习检测扇贝血液中的微塑料，迈向人类血液分析的一步|Riju Marwah, Riya Arora, Navneet Yadav, Himank Arora|<http://arxiv.org/pdf/2508.19021v1>|提出了一种利用深度学习结合荧光显微镜技术检测血液中微塑料的新方法，实现了高准确率的微塑料识别。|
|📝 更新|A Hybrid Fully Convolutional CNN-Transformer Model for Inherently Interpretable Disease Detection from Retinal Fundus Images|一种基于混合全卷积卷积神经网络-变换器模型的视网膜底片图像内在可解释性疾病检测方法|Kerol Djoumessi, Samuel Ofosu Mensah, Philipp Berens|<http://arxiv.org/pdf/2504.08481v2>|[代码](https://github.com/kdjoumessi/Self-Explainable-CNN-Transformer.); 提出了一种结合CNN与Transformer的模型，用于视网膜疾病检测，实现了高性能预测并提供直观解...|
|🆕 发布|Interpretable Decision-Making for End-to-End Autonomous Driving|端到端自动驾驶的可解释决策制定|Mona Mirzaie, Bodo Rosenhahn|<http://arxiv.org/pdf/2508.18898v1>|提出方法优化自动驾驶控制命令的同时增强模型可解释性，降低违规行为，提升安全性。|
|📝 更新|EVM-Fusion: An Explainable Vision Mamba Architecture with Neural Algorithmic Fusion|EVM-Fusion：一种具有神经算法融合的可解释视觉眼镜蛇架构|Zichuan Yang, Yongzhi Wang|<http://arxiv.org/pdf/2505.17367v4>|提出EVM-Fusion架构，通过神经算法融合提升多器官医学图像分类的准确性和解释性。|
|📝 更新|Uni-AIMS: AI-Powered Microscopy Image Analysis|"Uni-AIMS：基于人工智能的显微镜图像分析系统"|Yanhui Hong, Nan Wang, Zhiyi Xia, Haoyi Tao, Xi Fang, Yiming Li, Jiankun Wang, Peng Jin .etc.|<http://arxiv.org/pdf/2505.06918v2>|提出了一种集成数据引擎和分割模型的智能显微镜图像分析系统，实现了高效识别和自动分析。|
|🆕 发布|Toward Robust Medical Fairness: Debiased Dual-Modal Alignment via Text-Guided Attribute-Disentangled Prompt Learning for Vision-Language Models|面向稳健的医学公平性：基于文本引导的属性解耦提示学习的视觉-语言模型无偏双重模态对齐|Yuexuan Xia, Benteng Ma, Jiang He, Zhiyong Wang, Qi Dou, Yong Xia|<http://arxiv.org/pdf/2508.18886v1>|提出了一种跨模态公平性优化的DualFairVL框架，通过分离敏感属性和目标属性实现医疗影像模型的公...|
|📝 更新|MOSformer: Momentum encoder-based inter-slice fusion transformer for medical image segmentation|基于动量编码器的切片间融合变换器用于医学图像分割的MOSformer|De-Xing Huang, Xiao-Hu Zhou, Mei-Jiang Gui, Xiao-Liang Xie, Shi-Qi Liu, Shuang-Yi Wang, Zhen-Qiu Feng, Zhi-Chao Lai .etc.|<http://arxiv.org/pdf/2401.11856v3>|提出MOSformer模型，通过多尺度特征图和动量编码器增强2.5D医疗图像分割的切片间信息融合，实...|
|📝 更新|DriveIndia: An Object Detection Dataset for Diverse Indian Traffic Scenes|"DriveIndia：多样化印度交通场景的对象检测数据集"|Rishav Kumar, D. Santhosh Reddy, P. Rajalakshmi|<http://arxiv.org/pdf/2507.19912v4>|介绍了DriveIndia数据集，为复杂多变的印度交通环境提供全面的对象检测基准。|
|📝 更新|Rethinking the Detail-Preserved Completion of Complex Tubular Structures based on Point Cloud: a Dataset and a Benchmark|基于点云的复杂管状结构细节保持性修复的再思考：一个数据集与基准测试|Yaolei Qi, Yikai Yang, Wenbo Peng, Shumei Miao, Yutao Hu, Guanyu Yang|<http://arxiv.org/pdf/2508.17658v2>|[代码](https://github.com/YaoleiQi/PCCAC.); 首次提出基于点云的管状结构重建方法TSRNet，解决了医学成像中复杂管状结构不连续的问题。|
|📝 更新|Towards Optimal Convolutional Transfer Learning Architectures for Breast Lesion Classification and ACL Tear Detection|面向乳腺病变分类和ACL撕裂检测的最优卷积迁移学习架构|Daniel Frees, Moritz Bolling, Aditri Bhagirath|<http://arxiv.org/pdf/2508.17567v2>|探究最优卷积迁移学习架构，提升乳腺病变和ACL撕裂检测性能。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|No Label Left Behind: A Unified Surface Defect Detection Model for all Supervision Regimes|《不遗漏任何标签：一种适用于所有监督制度的统一表面缺陷检测模型》|Blaž Rolih, Matic Fučka, Danijel Skočaj|<http://arxiv.org/pdf/2508.19060v1>|[代码](https://github.com/blaz-r/SuperSimpleNet); 提出了一种统一的表面缺陷检测模型SuperSimpleNet，能够高效适应各种监督设置，提升工业制造...|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|An Agentic System for Rare Disease Diagnosis with Traceable Reasoning|用于罕见病诊断的可追踪推理的代理系统|Weike Zhao, Chaoyi Wu, Yanjie Fan, Xiaoman Zhang, Pengcheng Qiu, Yuze Sun, Xiao Zhou, Yanfeng Wang .etc.|<http://arxiv.org/pdf/2506.20430v2>|提出了一种基于大型语言模型的诊断系统DeepRare，用于罕见病诊断并提供可追踪的推理链。|
|📝 更新|StreetCrafter: Street View Synthesis with Controllable Video Diffusion Models|《StreetCrafter：具有可控视频扩散模型的街景合成》|Yunzhi Yan, Zhen Xu, Haotong Lin, Haian Jin, Haoyu Guo, Yida Wang, Kun Zhan, Xianpeng Lang .etc.|<http://arxiv.org/pdf/2412.13188v3>|提出StreetCrafter模型，利用LiDAR点云实现可控的视频扩散，解决视角偏离问题，实现高质...|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SocialTrack: Multi-Object Tracking in Complex Urban Traffic Scenes Inspired by Social Behavior|社会轨迹：基于社会行为启发的复杂城市交通场景多目标跟踪|Wenguang Tao, Xiaotian Wang, Tian Yan, Jie Yan, Guodong Li, Kun Bai|<http://arxiv.org/pdf/2508.12777v2>|提出SocialTrack框架，通过多尺度特征增强、动态建模和社交行为先验，提升复杂城市交通场景中多...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Learning county from pixels: corn yield prediction with attention-weighted multiple instance learning|从像素中学习县域信息：基于注意力加权多实例学习的玉米产量预测|Xiaoyu Wang, Yuchi Ma, Qunying Huang, Zhengwei Yang, Zhou Zhang|<http://arxiv.org/pdf/2312.01001v4>|利用像素级分析和注意力加权的多实例学习，提高了玉米产量预测的准确性。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Human Vision Constrained Super-Resolution|人眼视觉约束下的超分辨率|Volodymyr Karpenko, Taimoor Tariq, Jorge Condor, Piotr Didyk|<http://arxiv.org/pdf/2411.17513v2>|提出了一种基于人眼视觉特性的超分辨率优化方法，有效降低计算复杂度同时保持图像质量。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Event-Enriched Image Analysis Grand Challenge at ACM Multimedia 2025|2025年ACM多媒体会议事件增强图像分析大奖赛|Thien-Phuc Tran, Minh-Quang Nguyen, Minh-Triet Tran, Tam V. Nguyen, Trong-Le Do, Duy-Nam Ly, Viet-Tham Huynh, Khanh-Duy Le .etc.|<http://arxiv.org/pdf/2508.18904v1>|[代码](https://ltnghia.github.io/eventa); 提出首个大规模事件级多模态理解基准，整合上下文、时间和语义信息以深入理解图像背后的真实事件。|

