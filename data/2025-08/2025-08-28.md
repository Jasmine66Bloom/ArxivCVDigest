## [UPDATED!] **2025-08-28** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification|认知对齐的视觉-语言-动作模型：通过指令驱动的路由选择与稀疏化|Wei Li, Renshan Zhang, Rui Shao, Jie He, Liqiang Nie|<http://arxiv.org/pdf/2508.21046v1>|[代码](https://github.com/JiuTian-VL/CogVLA.); 提出CogVLA框架，通过指令驱动的路由和稀疏化提升视觉语言动作模型的效率和性能。|
|📝 更新|A multimodal dataset for understanding the impact of mobile phones on remote online virtual education|多模态数据集：用于理解手机对远程在线虚拟教育影响的研究|Roberto Daza, Alvaro Becerra, Ruth Cobos, Julian Fierrez, Aythami Morales|<http://arxiv.org/pdf/2412.14195v3>|构建多模态IMPROVE数据集，分析手机使用对在线教育学习者影响。|
|🆕 发布|"Humor, Art, or Misinformation?": A Multimodal Dataset for Intent-Aware Synthetic Image Detection|“幽默、艺术还是误导？”：一个用于意图感知合成图像检测的多模态数据集|Anastasios Skoularikis, Stefanos-Iordanis Papadopoulos, Symeon Papadopoulos, Panagiotis C. Petrantonakis|<http://arxiv.org/pdf/2508.20670v1>|提出了一个用于识别AI生成图像意图的多模态数据集，并研究了三种合成训练数据策略。|
|📝 更新|MIDAS: Multimodal Interactive Digital-humAn Synthesis via Real-time Autoregressive Video Generation|MIDAS：通过实时自回归视频生成实现多模态交互数字人合成|Ming Chen, Liyuan Cui, Wenyuan Zhang, Haoxian Zhang, Yan Zhou, Xiaohan Li, Songlin Tang, Jiwen Liu .etc.|<http://arxiv.org/pdf/2508.19320v2>|提出了实时自回归视频生成框架MIDAS，实现了低延迟和细粒度多模态交互控制。|
|🆕 发布|Enhancing Pseudo-Boxes via Data-Level LiDAR-Camera Fusion for Unsupervised 3D Object Detection|通过数据级激光雷达-相机融合增强伪盒用于无监督三维目标检测|Mingqian Ji, Jian Yang, Shanshan Zhang|<http://arxiv.org/pdf/2508.20530v1>|提出了一种数据级融合策略，通过早期融合RGB图像和LiDAR数据，显著提升了无监督3D目标检测的定位...|
|📝 更新|LatentExplainer: Explaining Latent Representations in Deep Generative Models with Multimodal Large Language Models|《LatentExplainer：使用多模态大型语言模型解释深度生成模型中的潜在表示》|Mengdan Zhu, Raasikh Kanjiani, Jiahui Lu, Andrew Choi, Qirui Ye, Liang Zhao|<http://arxiv.org/pdf/2406.14862v7>|提出LatentExplainer框架，通过扰动生成模型中的潜在变量并利用大型多模态语言模型自动生成...|
|🆕 发布|Prediction of Distant Metastasis for Head and Neck Cancer Patients Using Multi-Modal Tumor and Peritumoral Feature Fusion Network|基于多模态肿瘤及其周围特征融合网络的头颈癌患者远处转移预测|Zizhao Tang, Changhao Liu, Nuo Tong, Shuiping Gou, Mei Shi|<http://arxiv.org/pdf/2508.20469v1>|提出了一种融合CT影像、放射组学特征和临床数据的多模态深度学习框架，有效预测头颈癌患者远处转移风险。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DanceGRPO: Unleashing GRPO on Visual Generation|舞动GRPO：在视觉生成中释放GRPO的力量|Zeyue Xue, Jie Wu, Yu Gao, Fangyuan Kong, Lingting Zhu, Mengzhao Chen, Zhiheng Liu, Wei Liu .etc.|<http://arxiv.org/pdf/2505.07818v4>|提出DanceGRPO框架，利用GRPO稳定性优化视觉生成任务，提升模型适应性和多样性。|
|🆕 发布|Dino U-Net: Exploiting High-Fidelity Dense Features from Foundation Models for Medical Image Segmentation|Dino U-Net：利用基础模型中的高保真密集特征进行医学图像分割|Yifan Gao, Haoyue Li, Feng Yuan, Xiaosong Wang, Xin Gao|<http://arxiv.org/pdf/2508.20909v1>|[代码](https://github.com/yifangao112/DinoUNet.); 提出Dino U-Net架构，利用预训练的DINOv3模型提取高保真特征，提升医学图像分割精度。|
|🆕 发布|Adapting Foundation Model for Dental Caries Detection with Dual-View Co-Training|将基础模型适配用于双视角协同训练的龋齿检测|Tao Luo, Han Wu, Tong Yang, Dinggang Shen, Zhiming Cui|<http://arxiv.org/pdf/2508.20813v1>|[代码](https://github.com/ShanghaiTech-IMPACT/DVCTNet.); 提出双视角协同训练网络DVCTNet，通过全局与局部视图融合提升牙釉质腐蚀检测准确性。|
|🆕 发布|ArtFace: Towards Historical Portrait Face Identification via Model Adaptation|《ArtFace：通过模型适配实现历史肖像面部识别》|Francois Poh, Anjith George, Sébastien Marcel|<http://arxiv.org/pdf/2508.20626v1>|利用基础模型微调及融合传统面部识别技术，有效提升历史肖像画中人物识别准确度。|
|📝 更新|Probabilistic Modeling of Jailbreak on Multimodal LLMs: From Quantification to Application|《多模态大规模语言模型中越狱的概率建模：从量化到应用》|Wenzhuo Xu, Zhipeng Wei, Xiongtao Sun, Zonghao Ying, Deyue Zhang, Dongdong Yang, Xiangzheng Zhang, Quanchen Zou|<http://arxiv.org/pdf/2503.06989v4>|提出用概率模型量化多模态大语言模型的安全风险，并设计了优化攻击与防御策略。|
|🆕 发布|IAENet: An Importance-Aware Ensemble Model for 3D Point Cloud-Based Anomaly Detection|IAENet：一种基于三维点云的重要性感知集成模型用于异常检测|Xuanming Cao, Chengyu Tao, Yifeng Cheng, Juan Du|<http://arxiv.org/pdf/2508.20492v1>|提出了一种融合2D和3D专家模型的异常检测框架IAENet，通过动态评估源贡献优化了预测准确性。|
|📝 更新|CogNav: Cognitive Process Modeling for Object Goal Navigation with LLMs|认知导航：使用大型语言模型进行目标物体导航的认知过程建模|Yihan Cao, Jiazhao Zhang, Zhinan Yu, Shuzhen Liu, Zheng Qin, Qin Zou, Bo Du, Kai Xu|<http://arxiv.org/pdf/2412.10439v3>|提出CogNav框架，利用大型语言模型模拟人类认知过程，显著提升物体目标导航的成功率。|
|🆕 发布|MedFoundationHub: A Lightweight and Secure Toolkit for Deploying Medical Vision Language Foundation Models|MedFoundationHub：一种轻量级且安全的医疗视觉语言基础模型部署工具包|Xiao Li, Yanfan Zhu, Ruining Deng, Wei-Qi Wei, Yu Wang, Shilin Zhao, Yaohong Wang, Haichun Yang .etc.|<http://arxiv.org/pdf/2508.20345v1>|提出MedFoundationHub工具包，为医疗视觉语言模型部署提供简便操作和隐私保护。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Safer Skin Lesion Classification with Global Class Activation Probability Map Evaluation and SafeML|全局类别激活概率图评估与SafeML的更安全的皮肤病变分类|Kuniko Paxton, Koorosh Aslansefat, Amila Akagić, Dhavalkumar Thakker, Yiannis Papadopoulos|<http://arxiv.org/pdf/2508.20776v1>|提出全局类激活概率图评估方法，结合SafeML提升皮肤病变分类模型的诊断可靠性和患者安全。|
|📝 更新|Escaping Plato's Cave: JAM for Aligning Independently Trained Vision and Language Models|逃离柏拉图的洞穴：用于对齐独立训练的视觉和语言模型的JAM方法|Lauren Hyoseo Yoon, Yisong Yue, Been Kim|<http://arxiv.org/pdf/2507.01201v5>|提出了一种新的方法JAM，通过协同训练特定模态的自编码器实现独立训练的视觉和语言模型的显式对齐。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Estimating 2D Keypoints of Surgical Tools Using Vision-Language Models with Low-Rank Adaptation|使用具有低秩适应性的视觉-语言模型估计手术工具的二维关键点|Krit Duangprom, Tryphon Lambrou, Binod Bhattarai|<http://arxiv.org/pdf/2508.20830v1>|利用低秩调整技术微调视觉语言模型，有效提升小规模医疗数据集中手术工具二维关键点估计性能。|
|🆕 发布|FusionCounting: Robust visible-infrared image fusion guided by crowd counting via multi-task learning|《FusionCounting：通过多任务学习引导的稳健可见光-红外图像融合人群计数》|He Li, Xinyu Liu, Weihang Kong, Xingchen Zhang|<http://arxiv.org/pdf/2508.20817v1>|提出了一种融合可见光与红外图像的多任务学习框架，通过引入人群计数指导，有效提升了图像融合质量和计数性...|
|📝 更新|Privacy-Aware Detection of Fake Identity Documents: Methodology, Benchmark, and Improved Algorithms (FakeIDet2)|隐私感知的伪造身份证明文件检测：方法论、基准与改进算法（FakeIDet2）|Javier Muñoz-Haro, Ruben Tolosana, Julian Fierrez, Ruben Vera-Rodriguez, Aythami Morales|<http://arxiv.org/pdf/2508.11716v2>|提出隐私保护的伪造身份证检测方法，创建了大型数据库并设立标准基准，提升了对AI生成伪证的识别能力。|
|📝 更新|InterCLIP-MEP: Interactive CLIP and Memory-Enhanced Predictor for Multi-modal Sarcasm Detection|《InterCLIP-MEP：交互式CLIP与记忆增强预测器用于多模态讽刺检测》|Junjie Chen, Hang Yu, Subin Huang, Sanmin Liu, Linfeng Zhang|<http://arxiv.org/pdf/2406.16464v6>|[代码](https://github.com/CoderChen01/InterCLIP-MEP.); 提出了一种结合交互式CLIP和记忆增强预测器的多模态讽刺检测方法，有效提升了准确性和F1分数。|
|📝 更新|Leadership Assessment in Pediatric Intensive Care Unit Team Training|儿科重症监护室团队培训中的领导力评估|Liangyang Ouyang, Yuki Sakai, Ryosuke Furuta, Hisataka Nozawa, Hikoro Matsui, Yoichi Sato|<http://arxiv.org/pdf/2505.24389v2>|提出了一种基于第一视角视频和多种传感器数据的PICU团队领导力评估框架，实现了自动化分析。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Contrastive Learning through Auxiliary Branch for Video Object Detection|对比学习通过辅助分支进行视频目标检测|Lucas Rakotoarivony|<http://arxiv.org/pdf/2508.20551v1>|提出了一种对比学习辅助分支方法，增强了视频目标检测的鲁棒性，无需额外计算负荷即实现最优性能。|
|🆕 发布|Graph-Based Uncertainty Modeling and Multimodal Fusion for Salient Object Detection|基于图的 uncertainty 建模与多模态融合的显著目标检测|Yuqi Xiong, Wuzhen Shi, Yang Wen, Ruhan Liu|<http://arxiv.org/pdf/2508.20415v1>|[代码](https://github.com/YukiBear426/DUP-MCRNet.); 提出了一种结合图不确定性传播和多模态融合的显著目标检测方法，提高了复杂场景下的细节保持和边缘清晰度。|
|🆕 发布|Ultra-Low-Latency Spiking Neural Networks with Temporal-Dependent Integrate-and-Fire Neuron Model for Objects Detection|超低延迟的基于时间依赖积分放电神经元模型的脉冲神经网络用于目标检测|Chengjun Zhang, Yuhao Zhang, Jie Yang, Mohamad Sawan|<http://arxiv.org/pdf/2508.20392v1>|提出了一种基于tdIF神经元模型的SNN，实现了在极低延迟下的高精度目标检测。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dress&Dance: Dress up and Dance as You Like It - Technical Preview|《 Dress&Dance：随心所欲地装扮和跳舞 - 技术预览》|Jun-Kun Chen, Aayush Bansal, Minh Phuoc Vo, Yu-Xiong Wang|<http://arxiv.org/pdf/2508.21070v1>|提出Dress&Dance框架，通过单张用户图片生成高质量虚拟试衣视频，实现动作同步与多模态输入融合...|
|🆕 发布|OneReward: Unified Mask-Guided Image Generation via Multi-Task Human Preference Learning|OneReward：通过多任务人类偏好学习实现统一遮罩引导的图像生成|Yuan Gong, Xionghui Wang, Jie Wu, Shiyin Wang, Yitong Wang, Xinglong Wu|<http://arxiv.org/pdf/2508.21066v1>|提出OneReward框架，通过多任务强化学习提升图像生成能力，无需任务特定训练即可实现高效泛化。|
|🆕 发布|Reusing Computation in Text-to-Image Diffusion for Efficient Generation of Image Sets|在文本到图像扩散中重用计算以高效生成图像集|Dale Decatur, Thibault Groueix, Wang Yifan, Rana Hanocka, Vladimir Kim, Matheus Gadelha|<http://arxiv.org/pdf/2508.21032v1>|[代码](https://ddecatur.github.io/hierarchical-diffusion); 提出了一种通过聚类语义相似提示来共享扩散步骤计算的方法，有效降低文本到图像生成模型的计算成本并提升图...|
|🆕 发布|ExpertSim: Fast Particle Detector Simulation Using Mixture-of-Generative-Experts|专家模拟器：使用生成专家混合模型的快速粒子检测器模拟|Patryk Będkowski, Jan Dubiński, Filip Szatkowski, Kamil Deja, Przemysław Rokita, Tomasz Trzciński|<http://arxiv.org/pdf/2508.20991v1>|[代码](https://github.com/patrick-bedkowski/expertsim-mix-of-generative-experts.); 提出了一种基于专家混合模型的粒子探测器模拟方法，大幅提升了模拟精度并减少了计算时间。|
|🆕 发布|Webly-Supervised Image Manipulation Localization via Category-Aware Auto-Annotation|通过网络监督的类别感知自动标注进行图像操作定位|Chenfan Qu, Yiwu Zhong, Bin Li, Lianwen Jin|<http://arxiv.org/pdf/2508.20987v1>|[代码](https://github.com/qcf-568/MIML.); 利用网络数据自动标注技术，构建大规模数据集，提出Web-IML模型，显著提升图像篡改定位性能。|
|🆕 发布|DrivingGaussian++: Towards Realistic Reconstruction and Editable Simulation for Surrounding Dynamic Driving Scenes|驱动高斯++：面向周围动态驾驶场景的逼真重建与可编辑仿真|Yajiao Xiong, Xiaoyu Zhou, Yongtao Wan, Deqing Sun, Ming-Hsuan Yang|<http://arxiv.org/pdf/2508.20965v1>|[代码](https://xiong-creator.github.io/DrivingGaussian_plus.github.io); 提出 DrivingGaussian++ 框架，实现动态驾驶场景的逼真重建和可控编辑。|
|📝 更新|Exploring Typographic Visual Prompts Injection Threats in Cross-Modality Generation Models|探索跨模态生成模型中印刷视觉提示注入威胁|Hao Cheng, Erjia Xiao, Yichi Wang, Lingfeng Zhang, Qiang Zhang, Jiahang Cao, Kaidi Xu, Mengshu Sun .etc.|<http://arxiv.org/pdf/2503.11519v3>|揭示了视觉提示对跨模态生成模型的安全性威胁，并构建了专用数据集进行评估。|
|🆕 发布|Understanding and evaluating computer vision models through the lens of counterfactuals|通过反事实视角理解和评估计算机视觉模型|Pushkar Shukla|<http://arxiv.org/pdf/2508.20881v1>|利用反事实推理框架解释、审计和减轻计算机视觉模型中的偏见，增强模型鲁棒性。|
|🆕 发布|Unleashing Uncertainty: Efficient Machine Unlearning for Generative AI|释放不确定性：生成式人工智能的高效机器遗忘|Christoforos N. Spartalis, Theodoros Semertzidis, Petros Daras, Efstratios Gavves|<http://arxiv.org/pdf/2508.20773v1>|提出SAFEMax方法，通过最大化生成图像熵实现高效机器遗忘，显著提升生成模型处理禁用类别时的效率。|
|🆕 发布|Pref-GRPO: Pairwise Preference Reward-based GRPO for Stable Text-to-Image Reinforcement Learning|偏好引导的成对奖励GRPO：用于稳定的文本到图像强化学习|Yibin Wang, Zhimin Li, Yuhang Zang, Yujie Zhou, Jiazi Bu, Chunyu Wang, Qinglin Lu, Cheng Jin .etc.|<http://arxiv.org/pdf/2508.20751v1>|提出了一种基于偏好奖励的GRPO方法Pref-GRPO，通过优化偏好拟合而非分数最大化，有效解决了文...|
|📝 更新|Enhancing Document VQA Models via Retrieval-Augmented Generation|通过检索增强的生成方式提升文档视觉问答模型|Eric López, Artemis Llabrés, Ernest Valveny|<http://arxiv.org/pdf/2508.18984v2>|提出了一种基于检索增强生成的文档视觉问答方法，有效提升了长文档处理性能。|
|🆕 发布|AvatarBack: Back-Head Generation for Complete 3D Avatars from Front-View Images|“AvatarBack：从正面视图图像生成完整3D虚拟形象的背面头部”|Shiqi Xin, Xiaolin Zhang, Yanbin Liu, Peng Zhang, Caifeng Shan|<http://arxiv.org/pdf/2508.20623v1>|提出了一种生成完整3D头像的框架AvatarBack，通过合成背面视图和自适应对齐策略，解决了背面头...|
|🆕 发布|Embracing Aleatoric Uncertainty: Generating Diverse 3D Human Motion|拥抱随机不确定性：生成多样化的三维人体运动|Zheng Qin, Yabing Wang, Minghui Yang, Sanping Zhou, Ming Yang, Le Wang|<http://arxiv.org/pdf/2508.20604v1>|引入不确定性机制以生成多样化且语义一致的三维人体运动。|
|🆕 发布|Describe, Don't Dictate: Semantic Image Editing with Natural Language Intent|“描述而非规定：基于自然语言意图的语义图像编辑”|En Ci, Shanyan Guan, Yanhao Ge, Yilin Zhang, Wei Li, Zhenyu Zhang, Jian Yang, Ying Tai|<http://arxiv.org/pdf/2508.20505v1>|提出了一种基于描述性提示的图像编辑框架DescriptiveEdit，通过参考图像和文本提示生成编辑...|
|📝 更新|Ego-centric Predictive Model Conditioned on Hand Trajectories|以手部轨迹为条件的自我中心预测模型|Binjie Zhang, Mike Zheng Shou|<http://arxiv.org/pdf/2508.19852v2>|提出了一种两阶段预测框架，结合手部轨迹预测 egocentric 场景中的动作和视觉未来。|
|🆕 发布|Enhancing Corpus Callosum Segmentation in Fetal MRI via Pathology-Informed Domain Randomization|通过病理学指导的域随机化增强胎儿MRI中胼胝体分割|Marina Grifell i Plana, Vladyslav Zalevskyi, Léa Schmidt, Yvan Gomez, Thomas Sanchez, Vincent Dunet, Mériam Koob, Vanessa Siffredi .etc.|<http://arxiv.org/pdf/2508.20475v1>|提出了一种病理知识指导的合成数据生成策略，有效解决了胎儿脑部罕见疾病数据不足的问题。|
|📝 更新|GeoTexBuild: 3D Building Model Generation from Map Footprints|GeoTexBuild：从地图足迹生成三维建筑模型|Ruizhe Wang, Junyan Yang, Qiao Wang|<http://arxiv.org/pdf/2504.08419v2>|提出GeoTexBuild框架，通过三阶段流程从地图足迹生成详细准确的3D建筑模型。|
|📝 更新|T-Stars-Poster: A Framework for Product-Centric Advertising Image Design|T-Stars-Poster：面向产品中心化广告图像设计的框架|Hongyu Chen, Min Zhou, Jing Jiang, Jiale Chen, Yang Lu, Zihang Lin, Bo Xiao, Tiezheng Ge .etc.|<http://arxiv.org/pdf/2501.14316v3>|提出了一种全面的产品中心化广告图像设计框架T-Stars-Poster，自动生成具有高视觉吸引力的广...|
|📝 更新|When Memory Becomes a Vulnerability: Towards Multi-turn Jailbreak Attacks against Text-to-Image Generation Systems|当记忆成为漏洞：面向文本到图像生成系统的多轮越狱攻击|Shiqian Zhao, Jiayang Liu, Yiming Li, Runyi Hu, Xiaojun Jia, Wenshu Fan, Xinfeng Li, Jie Zhang .etc.|<http://arxiv.org/pdf/2504.20376v2>|提出多轮“记忆机制”攻击方法Inception，有效突破文本到图像生成系统的安全防护。|
|📝 更新|ZIM: Zero-Shot Image Matting for Anything|ZIM：零样本图像抠图通用方法|Beomyoung Kim, Chanyong Shin, Joonhyun Jeong, Hyungsik Jung, Se-Yun Lee, Sewhan Chun, Dong-Hyun Hwang, Joonsang Yu|<http://arxiv.org/pdf/2411.00626v2>|[代码](https://github.com/naver-ai/ZIM.); 提出了一种零样本图像抠图方法ZIM，通过转换标注和增强模型结构，实现了精细mask的生成和零样本泛化...|
|🆕 发布|Audio-Guided Visual Editing with Complex Multi-Modal Prompts|音频引导的视觉编辑：基于复杂多模态提示|Hyeonyu Kim, Seokhoon Jeong, Seonghee Han, Chanhyuk Choi, Taehwan Kim|<http://arxiv.org/pdf/2508.20379v1>|提出了一种音频引导的视觉编辑框架，通过结合文本和音频提示，有效处理复杂编辑任务。|
|📝 更新|Puppet-Master: Scaling Interactive Video Generation as a Motion Prior for Part-Level Dynamics|木偶大师：将交互式视频生成规模化为部件级动态的先验运动|Ruining Li, Chuanxia Zheng, Christian Rupprecht, Andrea Vedaldi|<http://arxiv.org/pdf/2408.04631v2>|提出Puppet-Master模型，通过捕捉物体内部部分级别的运动，实现了交互式视频生成，有效模拟物...|
|🆕 发布|GUARD: Guideline Upholding Test through Adaptive Role-play and Jailbreak Diagnostics for LLMs|GUARD：通过自适应角色扮演和越狱诊断来维护指导原则的测试方法针对大型语言模型|Haibo Jin, Ruoxi Chen, Peiyan Zhang, Andy Zhou, Yang Zhang, Haohan Wang|<http://arxiv.org/pdf/2508.20325v1>|提出GUARD方法，将伦理指南转化为具体测试问题，以评估大型语言模型对指南的遵守程度。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FakeParts: a New Family of AI-Generated DeepFakes|伪造部件：一种新型人工智能生成的深度伪造系列|Gaetan Brison, Soobash Daiboo, Samy Aimeur, Awais Hussain Sani, Xi Wang, Gianni Franchi, Vicky Kalogeiton|<http://arxiv.org/pdf/2508.21052v1>|提出了一种针对局部视频篡改的检测方法，创建了首个大规模部分深伪检测数据集，显著降低了人类和现有模型的...|
|🆕 发布|First-Place Solution to NeurIPS 2024 Invisible Watermark Removal Challenge|《NeurIPS 2024 隐形水印移除挑战赛一等奖解决方案》|Fahad Shamshad, Tameem Bakr, Yahia Shaaban, Noor Hussein, Karthik Nandakumar, Nils Lukas|<http://arxiv.org/pdf/2508.21072v1>|提出了一种结合自适应VAE攻击和图像到图像扩散模型的方法，实现了高达95.7%的水印移除率同时保持图...|
|🆕 发布|Veritas: Generalizable Deepfake Detection via Pattern-Aware Reasoning|“Veritas：通过模式感知推理实现泛化的深度伪造检测”|Hao Tan, Jun Lan, Zichang Tan, Ajian Liu, Chuanbiao Song, Senyuan Shi, Huijia Zhu, Weiqiang Wang .etc.|<http://arxiv.org/pdf/2508.21048v1>|提出了一种基于大规模语言模型的Deepfake检测方法Veritas，通过模拟人类推理模式提升了对未...|
|🆕 发布|Mixture of Contexts for Long Video Generation|长视频生成中的上下文混合模型|Shengqu Cai, Ceyuan Yang, Lvmin Zhang, Yuwei Guo, Junfei Xiao, Ziyan Yang, Yinghao Xu, Zhenheng Yang .etc.|<http://arxiv.org/pdf/2508.21058v1>|提出了一种稀疏注意力路由模块MoC，有效解决了长视频生成中的长时记忆问题。|
|📝 更新|Robust ID-Specific Face Restoration via Alignment Learning|通过对齐学习实现的鲁棒特定ID人脸恢复|Yushun Fang, Lu Liu, Xiang Gao, Qiang Hu, Ning Cao, Jianghe Cui, Gang Chen, Xiaoyun Zhang|<http://arxiv.org/pdf/2507.10943v2>|提出了一种基于扩散模型的ID特定人脸恢复框架，通过身份对齐学习抑制无关身份语义干扰，实现了高保真度的...|
|🆕 发布|Droplet3D: Commonsense Priors from Videos Facilitate 3D Generation|滴状3D：来自视频的常识先验促进3D生成|Xiaochuan Li, Guoguang Du, Runze Zhang, Liang Jin, Qi Jia, Lihua Lu, Zhenhua Guo, Yaqian Zhao .etc.|<http://arxiv.org/pdf/2508.20470v1>|[代码](https://dropletx.github.io/.); 利用视频中的常识先验，提出Droplet3D模型，有效促进3D内容生成。|
|🆕 发布|A Spatial-Frequency Aware Multi-Scale Fusion Network for Real-Time Deepfake Detection|一种考虑空间频率的多尺度融合网络用于实时深度伪造检测|Libo Lv, Tianyi Wang, Mengxiao Huang, Ruixia Liu, Yinglong Wang|<http://arxiv.org/pdf/2508.20449v1>|提出了一种轻量级网络SFMFNet，通过融合空间纹理和频率特征，实现了实时高效的deepfake检测...|
|📝 更新|TAG-WM: Tamper-Aware Generative Image Watermarking via Diffusion Inversion Sensitivity|TAG-WM：基于扩散逆敏感性的人工图像水印技术及其篡改感知能力|Yuzhuo Chen, Zehua Ma, Han Fang, Weiming Zhang, Nenghai Yu|<http://arxiv.org/pdf/2506.23484v2>|[代码](https://github.com/Suchenl/TAG-WM.); 提出了一种抗篡改生成图像水印方法TAG-WM，通过在潜在空间嵌入水印并检测篡改区域，实现了高鲁棒性和...|
|📝 更新|Interact-Custom: Customized Human Object Interaction Image Generation|交互定制：定制化人对象交互图像生成|Zhu Xu, Zhaowen Wang, Yuxin Peng, Yang Liu|<http://arxiv.org/pdf/2508.19575v2>|提出了一种两阶段模型Interact-Custom，实现了人物与物体互动的定制化生成并保持个体身份特...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|POSE: Phased One-Step Adversarial Equilibrium for Video Diffusion Models|POSE：视频扩散模型中的分相一步对抗平衡|Jiaxiang Cheng, Bing Ma, Xuhua Ren, Hongyi Jin, Kai Yu, Peng Zhang, Wenyue Li, Yuan Zhou .etc.|<http://arxiv.org/pdf/2508.21019v1>|POSE通过双阶段蒸馏框架减少视频扩散模型采样步骤，实现高效生成高质量视频。|
|📝 更新|From Promise to Practical Reality: Transforming Diffusion MRI Analysis with Fast Deep Learning Enhancement|从期望到现实：利用快速深度学习增强转化扩散磁共振成像分析|Xinyi Wang, Michael Barnett, Frederique Boonstra, Yael Barnett, Mariano Cabezas, Arkiev D'Souza, Matthew C. Kiernan, Kain Kyle .etc.|<http://arxiv.org/pdf/2508.10950v2>|该研究提出FastFOD-Net，一种加速扩散MRI分析的深度学习框架，提高FOD质量并促进临床应用...|
|📝 更新|Improving Fine-Grained Control via Aggregation of Multiple Diffusion Models|通过多扩散模型聚合提升细粒度控制|Conghan Yue, Zhengwei Peng, Shiyan Du, Zhi Ji, Chuangjian Cai, Le Wan, Dongyu Zhang|<http://arxiv.org/pdf/2410.01262v4>|[代码](https://github.com/Hammour-steak/AMDM.); 提出了一种无需训练的算法AMDM，通过聚合多个扩散模型实现细粒度控制，提高了生成质量与一致性。|
|📝 更新|Pixel Motion as Universal Representation for Robot Control|像素运动作为机器人控制的通用表示|Kanchana Ranasinghe, Xiang Li, E-Ro Nguyen, Cristina Mata, Jongwoo Park, Michael S Ryoo|<http://arxiv.org/pdf/2505.07817v2>|[代码](https://kahnchana.github.io/LangToMo); 提出LangToMo框架，使用像素运动预测作为通用表示，实现语言到机器人动作的转换。|
|🆕 发布|Evaluating Compositional Generalisation in VLMs and Diffusion Models|评估大型语言模型与扩散模型中的组合泛化能力|Beth Pearson, Bilal Boulbarss, Michael Wray, Martha Lewis|<http://arxiv.org/pdf/2508.20783v1>|[代码](https://github.com/otmive/diffusion_classifier_clip); 探究了扩散分类器在视觉语言模型中提升组合泛化能力的潜力。|
|📝 更新|Diffusion Models for Image Restoration and Enhancement: A Comprehensive Survey|图像修复与增强的扩散模型：全面综述|Xin Li, Yulin Ren, Xin Jin, Cuiling Lan, Xingrui Wang, Wenjun Zeng, Xinchao Wang, Zhibo Chen|<http://arxiv.org/pdf/2308.09388v2>|系统梳理了基于扩散模型的图像修复方法，展示了其在性能上的优势及未来研究方向。|
|🆕 发布|EmoCAST: Emotional Talking Portrait via Emotive Text Description|情感对话肖像：通过情感文本描述实现情感对话肖像|Yiguo Jiang, Xiaodong Cun, Yong Zhang, Yudian Zheng, Fan Tang, Chi-Man Pun|<http://arxiv.org/pdf/2508.20615v1>|[代码](https://github.com/GVCLab/EmoCAST); 提出EmoCAST框架，通过文本引导的情感建模和音频关注机制，生成真实、情感丰富且口型同步的动态人头...|
|🆕 发布|CraftGraffiti: Exploring Human Identity with Custom Graffiti Art via Facial-Preserving Diffusion Models|CraftGraffiti：通过保面子部扩散模型探索定制涂鸦艺术中的人类身份|Ayan Banerjee, Fernando Vilariño, Josep Lladós|<http://arxiv.org/pdf/2508.20640v1>|提出了一种以面部特征保留为核心的 graffiti 生成框架，通过先风格转换后保持身份一致性的方法，...|
|🆕 发布|FastFit: Accelerating Multi-Reference Virtual Try-On via Cacheable Diffusion Models|快速适配：通过可缓存扩散模型加速多参考虚拟试穿|Zheng Chong, Yanwei Lei, Shiyue Zhang, Zhuandi He, Zhen Wang, Xujie Zhang, Xiao Dong, Yiling Wu .etc.|<http://arxiv.org/pdf/2508.20586v1>|提出FastFit框架，通过创新的缓存扩散模型，实现多参考虚拟试衣的高效处理。|
|🆕 发布|Digital Scale: Open-Source On-Device BMI Estimation from Smartphone Camera Images Trained on a Large-Scale Real-World Dataset|数字尺度：基于智能手机相机图像的大规模现实世界数据集训练的开源设备端BMI估算|Frederik Rajiv Manichand, Robin Deuber, Robert Jakob, Steve Swerling, Jamie Rosen, Elgar Fleisch, Patrick Langer|<http://arxiv.org/pdf/2508.20534v1>|提出了一种基于深度学习的BMI估算方法，使用大规模真实世界数据集，实现了业界最低的误差率。|
|📝 更新|Relative Drawing Identification Complexity is Invariant to Modality in Vision-Language Models|相对绘图识别复杂度在视觉-语言模型中不随模态变化而变化|Diogo Freitas, Brigt Håvardstun, Cèsar Ferri, Darío Garigliotti, Jan Arne Telle, José Hernández-Orallo|<http://arxiv.org/pdf/2505.10583v2>|探究了视觉语言模型中不同模态表征的教学复杂性，发现概念简单性不受模态影响。|
|📝 更新|Visual Perturbation and Adaptive Hard Negative Contrastive Learning for Compositional Reasoning in Vision-Language Models|视觉扰动与自适应硬负对比学习在视觉语言模型中的组合推理应用|Xin Huang, Ruibin Li, Tong Jia, Wei Zheng, Ya Wang|<http://arxiv.org/pdf/2505.15576v2>|[代码](https://github.com/nynu-BDAI/AHNPL.); 提出了一种视觉扰动和自适应难负样本对比学习方法，通过图像域的负样本生成和动态对比边界优化，提高了视觉...|
|📝 更新|Unlearning Concepts from Text-to-Video Diffusion Models|从文本到视频扩散模型中遗忘概念|Shiqi Liu, Yihua Tan|<http://arxiv.org/pdf/2407.14209v2>|提出了一种高效的概念遗忘方法，使文本到视频生成模型能够快速去除特定内容。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ChainReaction! Structured Approach with Causal Chains as Intermediate Representations for Improved and Explainable Causal Video Question Answering|“链式反应！利用因果链作为中间表示的有序方法，用于改进和可解释的因果视频问答”|Paritosh Parmar, Eric Peh, Basura Fernando|<http://arxiv.org/pdf/2508.21010v1>|[代码](https://paritoshparmar.github.io/chainreaction); 提出了一种将因果链作为中介表示的模块化框架，有效提升了因果视频问答的性能和可解释性。|
|🆕 发布|To New Beginnings: A Survey of Unified Perception in Autonomous Vehicle Software|《开创新篇章：自动驾驶车辆软件中统一感知的综述》|Loïc Stratil, Felix Fent, Esteban Rivera, Markus Lienkamp|<http://arxiv.org/pdf/2508.20892v1>|概述了自动驾驶车辆统一感知框架，提出了三种整合范式，为未来研究提供了系统指导。|
|🆕 发布|${C}^{3}$-GS: Learning Context-aware, Cross-dimension, Cross-scale Feature for Generalizable Gaussian Splatting|${C}^{3}$-GS: 用于泛化高斯散点绘制的学习上下文感知、跨维度、跨尺度特征|Yuxi Hu, Jun Zhang, Kuangyi Chen, Zhe Zhang, Friedrich Fraundorfer|<http://arxiv.org/pdf/2508.20754v1>|[代码](https://github.com/YuhsiHu/C3-GS.); 提出了一种融合上下文感知、跨维度和跨尺度特征的框架，显著提升了未见场景的高质量视图合成能力。|
|📝 更新|WikiAutoGen: Towards Multi-Modal Wikipedia-Style Article Generation|《WikiAutoGen：迈向多模态维基风格文章生成》|Zhongyu Yang, Jun Chen, Dannong Xu, Junjie Fei, Xiaoqian Shen, Liangbing Zhao, Chun-Mei Feng, Mohamed Elhoseiny|<http://arxiv.org/pdf/2503.19065v2>|分类|
|🆕 发布|MSMVD: Exploiting Multi-scale Image Features via Multi-scale BEV Features for Multi-view Pedestrian Detection|多尺度图像特征通过多尺度鸟瞰图特征进行利用以实现多视角行人检测：MSMVD|Taiga Yamane, Satoshi Suzuki, Ryo Masumura, Shota Orihashi, Tomohiro Tanaka, Mana Ihori, Naoki Makishima, Naotaka Kawata|<http://arxiv.org/pdf/2508.20447v1>|提出MSMVD方法，通过多尺度BEV特征融合多视角图像，提升多尺度行人检测准确性。|
|📝 更新|DSO: Aligning 3D Generators with Simulation Feedback for Physical Soundness|DSO：通过模拟反馈对齐三维生成器以确保物理合理性|Ruining Li, Chuanxia Zheng, Christian Rupprecht, Andrea Vedaldi|<http://arxiv.org/pdf/2503.22677v2>|提出DSO方法，通过模拟反馈优化3D生成器，直接生成稳定物体，提高生成效率。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-View 3D Point Tracking|多视角三维点跟踪|Frano Rajič, Haofei Xu, Marko Mihajlovic, Siyuan Li, Irem Demir, Emircan Gündoğdu, Lei Ke, Sergey Prokudin .etc.|<http://arxiv.org/pdf/2508.21060v1>|[代码](https://ethz-vlg.github.io/mvtracker.); 首次提出基于数据驱动的多视角3D点跟踪方法，通过少量相机实现动态场景中任意点的准确追踪。|
|🆕 发布|Revisiting the Privacy Risks of Split Inference: A GAN-Based Data Reconstruction Attack via Progressive Feature Optimization|重新审视分割推理的隐私风险：基于生成对抗网络的数据重建攻击与渐进特征优化方法|Yixiang Qiu, Yanhan Liu, Hongyao Yu, Hao Fang, Bin Chen, Shu-Tao Xia, Ke Xu|<http://arxiv.org/pdf/2508.20613v1>|提出一种基于生成对抗网络和逐层特征优化的数据重构攻击方法，有效恢复敏感输入数据，提升重构图像质量。|
|🆕 发布|Adam SLAM - the last mile of camera calibration with 3DGS|Adam SLAM - 利用3DGS完成相机校准的最后一公里|Matthieu Gendrin, Stéphane Pateux, Xiaoran Jiang, Théo Ladune, Luce Morin|<http://arxiv.org/pdf/2508.20526v1>|利用3DGS模型通过颜色损失反向传播微调相机校准，平均提升0.4 dB PSNR的图像质量。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Optimization-Based Calibration for Intravascular Ultrasound Volume Reconstruction|基于优化的血管内超声体积重建校准方法|Karl-Philippe Beaudet, Sidaty El Hadramy, Philippe C Cattin, Juan Verde, Stéphane Cotin|<http://arxiv.org/pdf/2508.20605v1>|提出了一种基于优化的校准方法，通过3D打印 phantom实现精确的IVUS体积重建，提高了术中导航...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MMG-Vid: Maximizing Marginal Gains at Segment-level and Token-level for Efficient Video LLMs|MMG-Vid：在段级别和标记级别最大化边际增益以提高视频大型语言模型效率|Junpeng Ma, Qizhe Zhang, Ming Lu, Zhibin Wang, Qiang Zhou, Jun Song, Shanghang Zhang|<http://arxiv.org/pdf/2508.21044v1>|提出了一种无需训练的视觉token剪枝框架MMG-Vid，通过段级和token级最大化边际增益，提高...|
|📝 更新|Disentangled World Models: Learning to Transfer Semantic Knowledge from Distracting Videos for Reinforcement Learning|解耦的世界模型：从分散注意力的视频中学到语义知识以用于强化学习|Qi Wang, Zhipeng Zhang, Baao Xie, Xin Jin, Yunbo Wang, Shiyu Wang, Liaomo Zheng, Xiaokang Yang .etc.|<http://arxiv.org/pdf/2503.08751v2>|提出了一种通过离线视频预训练和在线知识迁移的解耦世界模型，有效提升视觉强化学习在多变环境中的样本效率...|
|🆕 发布|Learned Rate Control for Frame-Level Adaptive Neural Video Compression via Dynamic Neural Network|基于动态神经网络的帧级自适应神经视频压缩学习率控制|Chenhao Zhang, Wei Gao|<http://arxiv.org/pdf/2508.20709v1>|提出动态视频压缩框架，通过动态调整编码路径实现精确的比特率控制，优化了视频压缩的率失真性能。|
|📝 更新|Video-LevelGauge: Investigating Contextual Positional Bias in Large Video Language Models|视频级量规：探究大型视频语言模型中的上下文位置偏见|Hou Xia, Zheren Fu, Fangcan Ling, Jiajun Li, Yi Tu, Zhendong Mao, Yongdong Zhang|<http://arxiv.org/pdf/2508.19650v2>|[代码](https://github.com/Cola-any/Video-LevelGauge); 提出Video-LevelGauge基准，系统评估大型视频语言模型中的位置偏见，揭示并指导减轻偏见的...|
|📝 更新|When Tokens Talk Too Much: A Survey of Multimodal Long-Context Token Compression across Images, Videos, and Audios|当标记说过多话语：跨图像、视频和音频的多模态长上下文标记压缩综述|Kele Shao, Keda Tao, Kejia Zhang, Sicheng Feng, Mu Cai, Yuzhang Shang, Haoxuan You, Can Qin .etc.|<http://arxiv.org/pdf/2507.20198v4>|系统综述了多模态长上下文中的token压缩技术，分类并分析了图像、视频和音频数据压缩方法。|
|📝 更新|SpecVLM: Enhancing Speculative Decoding of Video LLMs via Verifier-Guided Token Pruning|SpecVLM：通过验证器引导的标记剪枝增强视频大型语言模型的投机解码|Yicheng Ji, Jun Zhang, Heming Xia, Jinpeng Chen, Lidan Shou, Gang Chen, Huan Li|<http://arxiv.org/pdf/2508.16201v2>|[代码](https://github.com/zju-jiyicheng/SpecVLM.); 提出SpecVLM框架，通过两阶段视频令牌剪枝加速大型视频语言模型解码，不牺牲准确度。|
|🆕 发布|Video-MTR: Reinforced Multi-Turn Reasoning for Long Video Understanding|视频多轮推理：增强型长视频理解多轮推理方法|Yuan Xie, Tianshui Chen, Zheng Ge, Lionel Ni|<http://arxiv.org/pdf/2508.20478v1>|提出了一种迭代的多轮推理框架Video-MTR，通过逐步选择视频片段并理解问题，提高了长视频理解的准...|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|COMETH: Convex Optimization for Multiview Estimation and Tracking of Humans|COMETH：用于多视角人体估计与跟踪的凸优化方法|Enrico Martini, Ho Jin Choi, Nadia Figueroa, Nicola Bombieri|<http://arxiv.org/pdf/2508.20920v1>|[代码](https://github.com/PARCO-LAB/COMETH.); 提出COMETH算法，通过整合生物力学约束和凸优化实现多视角实时人体姿态融合，提升定位与追踪准确性。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Sobel-Gradient MLP Baseline for Handwritten Character Recognition|基于Sobel梯度多层感知器的手写字符识别基线|Azam Nouri|<http://arxiv.org/pdf/2508.11902v3>|使用一阶Sobel梯度作为输入，训练MLP实现手写字符识别，达到接近CNN的性能，同时降低内存占用并...|
|🆕 发布|Looking Beyond the Obvious: A Survey on Abstract Concept Recognition for Video Understanding|《超越表象：视频理解中抽象概念识别的综述》|Gowreesh Mago, Pascal Mettes, Stevan Rudinac|<http://arxiv.org/pdf/2508.20765v1>|探讨了视频内容中抽象概念理解的方法，强调利用基础模型实现与人类认知更贴近的智能。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CardioMorphNet: Cardiac Motion Prediction Using a Shape-Guided Bayesian Recurrent Deep Network|心形网：基于形状引导的贝叶斯循环深度网络的心脏运动预测|Reza Akbari Movahed, Abuzar Rezaee, Arezoo Zakeri, Colin Berry, Edmond S. L. Ho, Ali Gooya|<http://arxiv.org/pdf/2508.20734v1>|提出CardioMorphNet模型，利用形状引导的贝叶斯循环深度网络准确预测心脏运动。|
|📝 更新|VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models|VLMEvalKit：一个用于评估大型多模态模型的开源工具包|Haodong Duan, Xinyu Fang, Junming Yang, Xiangyu Zhao, Yuxuan Qiao, Mo Li, Amit Agarwal, Zhe Chen .etc.|<http://arxiv.org/pdf/2407.11691v4>|[代码](https://github.com/open-compass/VLMEvalKit); VLMEvalKit是一个开源工具包，用于评估大型多模态模型，实现了200+模型和80+基准，简化了...|
|🆕 发布|Enhancing Mamba Decoder with Bidirectional Interaction in Multi-Task Dense Prediction|增强Mamba解码器：在多任务密集预测中的双向交互|Mang Cao, Sanping Zhou, Yizhe Li, Ye Deng, Wenli Huang, Le Wang|<http://arxiv.org/pdf/2508.20376v1>|提出了一种高效的Bidirectional Interaction Mamba模型，通过创新的扫描机...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 跨模态一致性学习 (Cross-modal Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DCFS: Continual Test-Time Adaptation via Dual Consistency of Feature and Sample|DCFS：通过特征与样本的双重一致性实现持续测试时适应|Wenting Yin, Han Sun, Xinru Meng, Ningzhong Liu, Huiyu Zhou|<http://arxiv.org/pdf/2508.20516v1>|提出DCFS框架，通过双路径特征一致性和置信度感知样本学习解决持续测试时适应中的误差累积问题。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A multi-task neural network for atypical mitosis recognition under domain shift|一种面向域偏移下非典型有丝分裂识别的多任务神经网络|Gennaro Percannella, Mattia Sarno, Francesco Tortorella, Mario Vento|<http://arxiv.org/pdf/2508.21035v1>|提出了一种多任务学习策略，通过辅助任务帮助模型在领域偏移下准确识别异常有丝分裂图像。|
|📝 更新|An MLP Baseline for Handwriting Recognition Using Planar Curvature and Gradient Orientation|基于平面曲率和梯度方向的多层感知器基准模型用于手写体识别|Azam Nouri|<http://arxiv.org/pdf/2508.11803v3>|探究使用平面曲率和梯度方向作为特征，实现97%准确率的 MLP 手写识别模型。|
|🆕 发布|SKGE-SWIN: End-To-End Autonomous Vehicle Waypoint Prediction and Navigation Using Skip Stage Swin Transformer|SKGE-SWIN：使用跳阶段Swin变换器的端到端自动驾驶车辆航点预测与导航|Fachri Najm Noer Kartiman, Rasim, Yaya Wihardi, Nurul Hasanah, Oskar Natan, Bambang Wahono, Taufik Ibnu Salim|<http://arxiv.org/pdf/2508.20762v1>|提出SKGE-Swin架构，通过Swin Transformer和跳级机制增强自动驾驶车辆对环境的理...|
|🆕 发布|MobileCLIP2: Improving Multi-Modal Reinforced Training|移动CLIP2：改进多模态强化训练|Fartash Faghri, Pavan Kumar Anasosalu Vasu, Cem Koc, Vaishaal Shankar, Alexander Toshev, Oncel Tuzel, Hadi Pouransari|<http://arxiv.org/pdf/2508.20691v1>|[代码](https://github.com/apple/ml-mobileclip); MobileCLIP2通过优化多模态强化训练，提升了图像文本模型的零样本准确性和效率。|
|🆕 发布|Masked Autoencoders for Ultrasound Signals: Robust Representation Learning for Downstream Applications|《用于超声信号的面罩自编码器：面向下游应用的鲁棒表征学习》|Immanuel Roßteutscher, Klaus S. Drese, Thorsten Uphues|<http://arxiv.org/pdf/2508.20622v1>|提出利用Masked Autoencoders进行超声信号的自监督学习，有效提升下游任务性能。|
|🆕 发布|GENRE-CMR: Generalizable Deep Learning for Diverse Multi-Domain Cardiac MRI Reconstruction|GENRE-CMR：多样化多域心脏磁共振成像重建的泛化深度学习|Kian Anvari Hamedani, Narges Razizadeh, Shahabedin Nabavi, Mohsen Ebrahimi Moghaddam|<http://arxiv.org/pdf/2508.20600v1>|提出了一种GAN增强的深度学习框架GENRE-CMR，有效提升了多领域心脏磁共振成像的重建质量和泛化...|
|🆕 发布|Towards Inclusive Communication: A Unified LLM-Based Framework for Sign Language, Lip Movements, and Audio Understanding|面向包容性通信：一种基于统一大型语言模型的 sign language、唇部运动和音频理解框架|Jeong Hun Yeo, Hyeongseop Rha, Sungjune Park, Junil Won, Yong Man Ro|<http://arxiv.org/pdf/2508.20476v1>|首次提出统一框架，整合手语、唇动和音频信息，提升无障碍通信性能。|
|📝 更新|DANCE: Resource-Efficient Neural Architecture Search with Data-Aware and Continuous Adaptation|DANCE：数据感知与连续适应的资源高效神经架构搜索|Maolin Wang, Tianshuo Wei, Sheng Zhang, Ruocheng Guo, Wanyu Wang, Shanshan Ye, Lixin Zou, Xuetao Wei .etc.|<http://arxiv.org/pdf/2507.04671v2>|[代码](https://github.com/Applied-Machine-Learning-Lab/DANCE.); 提出DANCE方法，通过连续演化实现资源高效的神经网络架构搜索，提升适应性和降低搜索成本。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OLKAVS: An Open Large-Scale Korean Audio-Visual Speech Dataset|OLKAVS：一个开放的大型韩国音频-视觉语音数据集|Jeongkyun Park, Jung-Wook Hwang, Kwanghee Choi, Seung-Hyun Lee, Jun Hwan Ahn, Rae-Hong Park, Hyung-Min Park|<http://arxiv.org/pdf/2301.06375v2>|构建了最大的公开韩语音频视觉语音数据集OLKAVS，支持多模态和多视角训练。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|E-ConvNeXt: A Lightweight and Efficient ConvNeXt Variant with Cross-Stage Partial Connections|E-ConvNeXt：一种具有跨阶段部分连接的轻量级高效ConvNeXt变体|Fang Wang, Huitao Li, Wenhan Chao, Zheng Zhuo, Yiran Ji, Chang Peng, Yupeng Sun|<http://arxiv.org/pdf/2508.20955v1>|提出E-ConvNeXt网络，通过跨阶段部分连接和结构优化显著降低ConvNeXt复杂度，实现高准确...|
|📝 更新|RSRNav: Reasoning Spatial Relationship for Image-Goal Navigation|RSRNav：基于空间关系推理的图像目标导航|Zheng Qin, Le Wang, Yabing Wang, Sanping Zhou, Gang Hua, Wei Tang|<http://arxiv.org/pdf/2504.17991v2>|RSRNav通过构建目标与当前观测之间的空间关系模型，有效指导导航动作，提升了图像目标导航的准确性和...|
|🆕 发布|SPGrasp: Spatiotemporal Prompt-driven Grasp Synthesis in Dynamic Scenes|动态场景中基于时空提示驱动的抓取合成：SPGrasp|Yunpeng Mei, Hongjie Cao, Yinqiu Xia, Wei Xiao, Zhaohan Feng, Gang Wang, Jie Chen|<http://arxiv.org/pdf/2508.20547v1>|[代码](https://github.com/sejmoonwei/SPGrasp.); 提出SPGrasp方法，结合时空上下文与用户提示，实现动态场景中实时交互抓取合成。|
|🆕 发布|Towards Mechanistic Defenses Against Typographic Attacks in CLIP|面向CLIP中印刷攻击的机制性防御方法研究|Lorenz Hufe, Constantin Venhoff, Maximilian Dreyer, Sebastian Lapuschkin, Wojciech Samek|<http://arxiv.org/pdf/2508.20570v1>|提出了一种无需训练的防御策略，通过消除特定注意力机制来增强CLIP模型对印刷攻击的鲁棒性。|
|🆕 发布|Re-Densification Meets Cross-Scale Propagation: Real-Time Compression of LiDAR Point Clouds|激光雷达点云的再密集化与跨尺度传播相遇：实时压缩|Pengpeng Yu, Haoran Li, Dingquan Li, Runqing Jiang, Jing Wang, Liang Lin, Yulan Guo|<http://arxiv.org/pdf/2508.20466v1>|[代码](https://github.com/pengpeng-yu/FastPCC.); 提出了一种结合几何重密化和跨尺度特征传播的LiDAR点云实时压缩方法，实现了高效压缩比和实时性能。|
|📝 更新|MTS-Net: Dual-Enhanced Positional Multi-Head Self-Attention for 3D CT Diagnosis of May-Thurner Syndrome|MTS-Net：双增强位置多头部自注意力机制用于梅-蒂综合征的三维CT诊断|Yixin Huang, Yiqi Jin, Ke Tao, Kaijian Xia, Jianfeng Gu, Lei Yu, Haojie Li, Lan Du .etc.|<http://arxiv.org/pdf/2406.04680v3>|[代码](https://github.com/Nutingnon/MTS_dep_mhsa.); 提出MTS-Net，利用双增强位置多头痛自注意力模块准确诊断May-Thurner综合征的3D CT...|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mix, Align, Distil: Reliable Cross-Domain Atypical Mitosis Classification|混合、对齐、蒸馏：可靠的跨域非典型有丝分裂分类|Kaustubh Atey, Sameer Anand Jha, Gouranga Bala, Amit Sethi|<http://arxiv.org/pdf/2508.20745v1>|提出了一种应对域迁移问题的可靠异常有丝分裂分类方法，通过特征多样化、跨域特征对齐和模型蒸馏提高了分类...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FW-GAN: Frequency-Driven Handwriting Synthesis with Wave-Modulated MLP Generator|FW-GAN：基于频率驱动的波调制MLP生成器的手写合成|Huynh Tong Dang Khoa, Dang Hoai Nam, Vo Nguyen Le Duy|<http://arxiv.org/pdf/2508.21040v1>|[代码](https://github.com/DAIR-Group/FW-GAN); 提出了一种基于频率驱动的生成模型FW-GAN，用于生成风格一致的高质量手写文本，有效解决了手写数据稀...|
|🆕 发布|PointDGRWKV: Generalizing RWKV-like Architecture to Unseen Domains for Point Cloud Classification|点DGRWKV：将RWKV类架构泛化至未见领域以进行点云分类|Hao Yang, Qianyu Zhou, Haijia Sun, Xiangtai Li, Xuequan Lu, Lizhuang Ma, Shuicheng Yan|<http://arxiv.org/pdf/2508.20835v1>|提出PointDGRWKV框架，通过改进RWKV模型，有效提升了点云分类在未见领域的泛化性能。|


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|L2RW+: A Comprehensive Benchmark Towards Privacy-Preserved Visible-Infrared Person Re-Identification|L2RW+：面向隐私保护的可见光-红外人体再识别全面基准|Yan Jiang, Hao Yu, Mengting Wei, Zhaodong Sun, Haoyu Chen, Xu Cheng, Guoying Zhao|<http://arxiv.org/pdf/2503.12232v2>|[代码](https://github.com/Joey623/L2RW.); 提出了一种面向隐私保护的分布式训练基准L2RW+，解决了可见光-红外行人重识别中的隐私问题。|
|🆕 发布|Disruptive Attacks on Face Swapping via Low-Frequency Perceptual Perturbations|通过对低频感知扰动的人脸交换破坏性攻击|Mengxiao Huang, Minglei Shu, Shuwang Zhou, Zhaoyang Liu|<http://arxiv.org/pdf/2508.20595v1>|提出主动防御策略，通过低频感知扰动干扰人脸交换过程，有效降低Deepfake生成内容的真实性和自然度...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ActLoc: Learning to Localize on the Move via Active Viewpoint Selection|动态定位学习：通过主动视角选择实现移动中的定位|Jiajie Li, Boyang Sun, Luca Di Giammarino, Hermann Blum, Marc Pollefeys|<http://arxiv.org/pdf/2508.20981v1>|提出了一种主动视角选择框架ActLoc，通过预测不同视角的定位准确性，增强了机器人导航中的定位可靠性...|
|🆕 发布|Classifying Mitotic Figures in the MIDOG25 Challenge with Deep Ensemble Learning and Rule Based Refinement|在MIDOG25挑战中使用深度集成学习和基于规则的细化对有丝分裂图像进行分类|Sara Krauss, Ellena Spieß, Daniel Hieber, Frank Kramer, Johannes Schobel, Dominik Müller|<http://arxiv.org/pdf/2508.20919v1>|提出了一种深度学习集成方法结合规则细化模块，有效区分了典型与不典型有丝分裂图像。|
|📝 更新|SMARTe-VR: Student Monitoring and Adaptive Response Technology for e-Learning in Virtual Reality|SMARTe-VR：虚拟现实电子学习中学生监控与自适应响应技术|Roberto Daza, Lin Shengkai, Aythami Morales, Julian Fierrez, Katashi Nagao|<http://arxiv.org/pdf/2501.10977v3>|提出SMARTe-VR平台，通过监测虚拟现实学习环境中的学生面部生物特征和学习数据，实现个性化教学反...|
|🆕 发布|CaddieSet: A Golf Swing Dataset with Human Joint Features and Ball Information|球童集：一个包含人体关节特征和球信息的高尔夫挥杆数据集|Seunghyeon Jung, Seoyoung Hong, Jiwoo Jeong, Seungwon Jeong, Jaerim Choi, Hoki Kim, Woojin Lee|<http://arxiv.org/pdf/2508.20491v1>|提出CaddieSet数据集，结合人体关节特征与球信息，定量分析高尔夫挥杆与球轨迹关系。|
|🆕 发布|More Reliable Pseudo-labels, Better Performance: A Generalized Approach to Single Positive Multi-label Learning|更可靠的伪标签，更好的性能：一种广义的单正多标签学习方法|Luong Tran, Thieu Vo, Anh Nguyen, Sang Dinh, Van Nguyen|<http://arxiv.org/pdf/2508.20381v1>|提出了一种新颖的损失函数和伪标签技术，有效提升了单正多标签学习性能。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Occlusion Robustness of CLIP for Military Vehicle Classification|CLIP在军事车辆分类中的遮挡鲁棒性研究|Jan Erik van Woerden, Gertjan Burghouts, Lotte Nijskens, Alma M. Liezenga, Sabina van Rooij, Frank Ruis, Hugo J. Kuijf|<http://arxiv.org/pdf/2508.20760v1>|研究了CLIP模型在军事车辆分类中的遮挡鲁棒性，发现细粒度遮挡影响大，模型微调可提升鲁棒性。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PathMR: Multimodal Visual Reasoning for Interpretable Pathology Diagnosis|PathMR：可解释病理诊断的多模态视觉推理|Ye Zhang, Yu Zhou, Jingwen Qi, Yongbing Zhang, Simon Puettmann, Finn Wichmann, Larissa Pereira Ferreira, Lara Sichward .etc.|<http://arxiv.org/pdf/2508.20851v1>|[代码](https://github.com/zhangye-zoe/PathMR.); PathMR通过细胞级多模态视觉推理，为病理图像分析提供了透明且可解释的诊断解释和细胞分布预测。|
|📝 更新|CVBench: Evaluating Cross-Video Synergies for Complex Multimodal Understanding and Reasoning|CVBench：评估复杂多模态理解和推理中的跨视频协同作用|Nannan Zhu, Yonghao Dong, Teng Wang, Xueqian Li, Shengjun Deng, Yijia Wang, Zheng Hong, Tiantian Geng .etc.|<http://arxiv.org/pdf/2508.19542v2>|[代码](https://github.com/Hokhim2/CVBench.); 提出CVBench基准，首次评估多视频间关联推理能力，揭示现有模型缺陷。|
|🆕 发布|SeqVLM: Proposal-Guided Multi-View Sequences Reasoning via VLM for Zero-Shot 3D Visual Grounding|SeqVLM：通过VLM进行提案引导的多视角序列推理实现零样本三维视觉定位|Jiawen Lin, Shiran Bian, Yihang Zhu, Wenbin Tan, Yachao Zhang, Yuan Xie, Yanyun Qu|<http://arxiv.org/pdf/2508.20758v1>|[代码](https://github.com/JiawLin/SeqVLM.); SeqVLM通过多视角图像和3D提案引导，实现了无需特定场景训练的零样本3D视觉定位。|
|📝 更新|TGOSPA Metric Parameters Selection and Evaluation for Visual Multi-object Tracking|视觉多目标跟踪中TGOSPA度量参数选择与评估|Jan Krejčí, Oliver Kost, Ondřej Straka, Yuxuan Xia, Lennart Svensson, Ángel F. García-Fernández|<http://arxiv.org/pdf/2412.08321v3>|提出TGOSPA指标用于评估多目标跟踪性能，指导算法针对特定应用进行优化。|
|📝 更新|Model-based Multi-object Visual Tracking: Identification and Standard Model Limitations|基于模型的多人视觉跟踪：识别与标准模型局限性|Jan Krejčí, Oliver Kost, Yuxuan Xia, Lennart Svensson, Ondřej Straka|<http://arxiv.org/pdf/2508.13647v2>|将雷达跟踪技术应用于行人跟踪，揭示了标准模型局限性并指出了改进方向。|
|📝 更新|Language-to-Space Programming for Training-Free 3D Visual Grounding|用于无需训练的3D视觉定位的语言到空间编程|Boyu Mi, Hanqing Wang, Tai Wang, Yilun Chen, Jiangmiao Pang|<http://arxiv.org/pdf/2502.01401v4>|提出了一种无需训练的3D视觉定位方法LaSP，通过LLM生成的代码分析物体间的空间关系，实现了性能与...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mitosis detection in domain shift scenarios: a Mamba-based approach|在域偏移场景下的有丝分裂检测：基于Mamba的方法|Gennaro Percannella, Mattia Sarno, Francesco Tortorella, Mario Vento|<http://arxiv.org/pdf/2508.21033v1>|提出了一种基于Mamba的VM-UNet架构，增强了对病理图像领域迁移的鲁棒性，提高了分裂检测准确性...|
|🆕 发布|Olive Tree Satellite Image Segmentation Based On SAM and Multi-Phase Refinement|基于SAM和多层次细化的大橄榄树卫星图像分割|Amir Jmal, Chaima Chtourou, Mahdi Louati, Abdelaziz Kallel, Houda Khmila|<http://arxiv.org/pdf/2508.20954v1>|提出了一种结合SAM模型和多阶段优化的卫星图像橄榄树分割方法，实现了98%的准确率。|
|📝 更新|ODES: Domain Adaptation with Expert Guidance for Online Medical Image Segmentation|在线医疗图像分割中的专家指导域自适应：ODES|Md Shazid Islam, Sayak Nag, Arindam Dutta, Miraj Ahmed, Fahim Faisal Niloy, Shreyangshu Bera, Amit K. Roy-Chowdhury|<http://arxiv.org/pdf/2312.05407v4>|提出利用专家指导的域自适应方法ODES，通过主动学习和图像筛选优化在线医疗图像分割。|
|🆕 发布|Deep Learning Framework for Early Detection of Pancreatic Cancer Using Multi-Modal Medical Imaging Analysis|基于多模态医学影像分析的胰腺癌早期检测深度学习框架|Dennis Slobodzian, Karissa Tilbury, Amir Kordijazi|<http://arxiv.org/pdf/2508.20877v1>|开发了一种深度学习框架，通过双模态影像分析实现胰腺癌早期检测，准确率超90%，优于传统方法。|
|📝 更新|Federated nnU-Net for Privacy-Preserving Medical Image Segmentation|联邦nnU-Net用于隐私保护的医学图像分割|Grzegorz Skorupko, Fotios Avgoustidis, Carlos Martín-Isla, Lidia Garrucho, Dimitri A. Kessler, Esmeralda Ruiz Pujadas, Oliver Díaz, Maciej Bobowicz .etc.|<http://arxiv.org/pdf/2503.02549v2>|[代码](https://github.com/faildeny/FednnUNet); 提出 FednnU-Net，通过联邦学习保护隐私的医学图像分割方法，确保数据不集中存储。|
|🆕 发布|Physics Informed Generative Models for Magnetic Field Images|物理信息驱动的磁场图像生成模型|Aye Phyu Phyu Aung, Lucas Lum, Zhansen Shi, Wen Qiu, Bernice Zee, JM Chin, Yeow Kheng Lim, J. Senthilnath|<http://arxiv.org/pdf/2508.20612v1>|提出物理信息驱动的生成模型，有效生成磁场图像数据以优化半导体缺陷定位。|
|🆕 发布|Domain Adaptation Techniques for Natural and Medical Image Classification|自然与医学图像分类的域自适应技术|Ahmad Chaddad, Yihang Wu, Reem Kateb, Christian Desrosiers|<http://arxiv.org/pdf/2508.20537v1>|评估了七种域自适应技术在自然和医学图像分类中的应用，发现Deep Subdomain Adaptat...|
|🆕 发布|Learning What is Worth Learning: Active and Sequential Domain Adaptation for Multi-modal Gross Tumor Volume Segmentation|学习值得学习的内容：多模态肿瘤大体体积分割的主动和顺序域自适应|Jingyun Yang, Guoqing Zhang, Jingge Wang, Yang Li|<http://arxiv.org/pdf/2508.20528v1>|[代码](https://github.com/Hiyoochan/mmActS); 提出了一种针对多模态医疗数据动态样本选择的主动顺序域自适应框架，有效提升肿瘤体积分割性能。|
|🆕 发布|Dual-Model Weight Selection and Self-Knowledge Distillation for Medical Image Classification|双模型权重选择与自知识蒸馏在医学图像分类中的应用|Ayaka Tsutsumi, Guang Li, Ren Togo, Takahiro Ogawa, Satoshi Kondo, Miki Haseyama|<http://arxiv.org/pdf/2508.20461v1>|提出了一种结合双模型权重选择与自我知识蒸馏的医疗图像分类方法，实现了高效计算与高性能的平衡。|
|🆕 发布|Federated Learning for Large Models in Medical Imaging: A Comprehensive Review|联邦学习在医学成像大模型中的应用：全面回顾|Mengyu Sun, Ziyuan Yang, Yongqiang Huang, Hui Yu, Yingyu Chen, Shuren Qi, Andrew Beng Jin Teoh, Yi Zhang|<http://arxiv.org/pdf/2508.20414v1>|这篇论文综述了联邦学习在保护医疗影像数据隐私的同时，如何促进大型模型开发和持续训练的创新方法。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|InterAct-Video: Reasoning-Rich Video QA for Urban Traffic|《InterAct-Video：面向城市交通的富推理视频问答》|Joseph Raj Vishal, Divesh Basina, Rutuja Patil, Manas Srinivas Gowda, Katha Naik, Yezhou Yang, Bharatesh Chakravarthi|<http://arxiv.org/pdf/2507.14743v3>|[代码](https://github.com/joe-rabbit/InterAct_VideoQA); 提出InterAct VideoQA数据集，提升了视频问答模型在处理复杂交通场景的性能。|
|🆕 发布|UTA-Sign: Unsupervised Thermal Video Augmentation via Event-Assisted Traffic Signage Sketching|UTA-Sign: 基于事件辅助的交通标志草图的无监督热视频增强|Yuqi Han, Songqian Zhang, Weijian Su, Ke Li, Jiayu Yang, Jinli Suo, Qiang Zhang|<http://arxiv.org/pdf/2508.20594v1>|提出了一种结合热成像和事件相机的不监督视频增强方法，有效解决了低光照下交通标志识别问题。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Surfel-based 3D Registration with Equivariant SE(3) Features|基于Surfel的等变SE(3)特征的三维配准|Xueyang Kang, Hang Zhao, Kourosh Khoshelham, Patrick Vandewalle|<http://arxiv.org/pdf/2508.20789v1>|提出了一种基于Surfel和等变SE(3)特征的点云配准方法，有效应对噪声和输入旋转问题，提升配准准...|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Adaptive Dual Uncertainty Optimization: Boosting Monocular 3D Object Detection under Test-Time Shifts|自适应双不确定性优化：在测试时间偏移下提升单目3D目标检测性能|Zixuan Hu, Dongxiao Li, Xinzhu Ma, Shixiang Tang, Xiaotong Li, Wenhan Yang, Ling-Yu Duan|<http://arxiv.org/pdf/2508.20488v1>|提出了一种双不确定性优化框架，有效应对自动驾驶中单目3D物体检测面临的实时环境变化挑战。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Realistic and Controllable 3D Gaussian-Guided Object Editing for Driving Video Generation|驾驶视频生成中的真实感和可控性三维高斯引导对象编辑|Jiusi Li, Jackson Jiang, Jinyu Miao, Miao Long, Tuopu Wen, Peijin Jia, Shengxiang Liu, Chunlei Yu .etc.|<http://arxiv.org/pdf/2508.20471v1>|提出G^2Editor框架，通过3D高斯引导实现驾驶视频中对象的精确编辑和视觉效果提升。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|See then Tell: Enhancing Key Information Extraction with Vision Grounding|“_seen_then_tell：通过视觉定位增强关键信息提取_”|Shuhang Liu, Zhenrong Zhang, Pengfei Hu, Jiefeng Ma, Jun Du, Qing Wang, Jianshu Zhang, Chenyu Liu|<http://arxiv.org/pdf/2409.19573v2>|提出STNet模型，通过视觉定位提升关键信息提取准确度，实现文本与图像的深度结合。|
|🆕 发布|GLaRE: A Graph-based Landmark Region Embedding Network for Emotion Recognition|基于图的地标区域嵌入网络用于情感识别：GLaRE|Debasis Maji, Debaditya Barman|<http://arxiv.org/pdf/2508.20579v1>|提出了一种基于图神经网络的情感识别方法GLaRE，通过构建面部特征图实现了高准确率和可解释性。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Improving Alignment in LVLMs with Debiased Self-Judgment|在LVLMs中通过去偏自我判断改进对齐|Sihan Yang, Chenhang Cui, Zihao Zhao, Yiyang Zhou, Weilong Yan, Ying Wei, Huaxiu Yao|<http://arxiv.org/pdf/2508.20655v1>|提出内部生成去偏自我评判分数的方法，自主提升大型视觉语言模型中视觉与语言模态的对齐效果。|
|🆕 发布|Efficient Fine-Tuning of DINOv3 Pretrained on Natural Images for Atypical Mitotic Figure Classification in MIDOG 2025|基于自然图像预训练的DINOv3的高效微调用于MIDOG 2025中的非典型有丝分裂图像分类|Guillaume Balezo, Raphaël Bourgade, Thomas Walter|<http://arxiv.org/pdf/2508.21041v1>|利用低秩适应和增强技术，有效微调DINOv3模型以识别异常有丝分裂图像。|
|🆕 发布|Mask-Guided Multi-Channel SwinUNETR Framework for Robust MRI Classification|基于掩膜引导的多通道SwinUNETR框架用于稳健的MRI分类|Smriti Joshi, Lidia Garrucho, Richard Osuala, Oliver Diaz, Karim Lekadir|<http://arxiv.org/pdf/2508.20621v1>|[代码](https://github.com/smriti-joshi/bcnaim-odelia-challenge.git.); 提出了一种结合区域掩模和数据增强的SwinUNETR框架，有效提升了MRI乳腺癌分类的准确性和泛化能...|

