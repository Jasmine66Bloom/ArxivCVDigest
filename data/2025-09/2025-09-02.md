## [UPDATED!] **2025-09-02** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HydroVision: Predicting Optically Active Parameters in Surface Water Using Computer Vision|《HydroVision：利用计算机视觉预测表层水中的光学活性参数》|Shubham Laxmikant Deshmukh, Matthew Wilchek, Feras A. Batarseh|<http://arxiv.org/pdf/2509.01882v2>|提出HydroVision框架，利用深度学习从RGB图像估计水质参数，提高水质监测效率。|
|🆕 发布|FastVGGT: Training-Free Acceleration of Visual Geometry Transformer|快速VGGT：无需训练的视觉几何变换器加速|You Shen, Zhipeng Zhang, Yansong Qu, Liujuan Cao|<http://arxiv.org/pdf/2509.02560v1>|[代码](https://mystorm16.github.io/fastvggt); 首次提出无需训练的token合并机制FastVGGT，加速3D视觉模型处理长序列图像。|
|🆕 发布|Fake & Square: Training Self-Supervised Vision Transformers with Synthetic Data and Synthetic Hard Negatives|伪造与平方：使用合成数据与合成硬负样本训练自监督视觉变换器|Nikolaos Giakoumoglou, Andreas Floros, Kleanthis Marios Papadopoulos, Tania Stathaki|<http://arxiv.org/pdf/2509.02029v1>|利用生成模型和合成硬负样本来增强视觉表示学习的多样性和鲁棒性。|
|🆕 发布|Vision-Based Embedded System for Noncontact Monitoring of Preterm Infant Behavior in Low-Resource Care Settings|基于视觉的嵌入式系统：在资源匮乏环境下对早产儿行为进行非接触式监测|Stanley Mugisha, Rashid Kisitu, Francis Komakech, Excellence Favor|<http://arxiv.org/pdf/2509.02018v1>|提出了一种基于轻量级卷积神经网络的嵌入式监控系统，用于无接触监测早产婴儿行为，实现高效准确的行为状态...|
|🆕 发布|Unsupervised Training of Vision Transformers with Synthetic Negatives|无监督视觉变换器训练：使用合成负样本|Nikolaos Giakoumoglou, Andreas Floros, Kleanthis Marios Papadopoulos, Tania Stathaki|<http://arxiv.org/pdf/2509.02024v1>|利用合成硬负样本增强视觉变换器无监督训练，显著提升表征判别力。|
|🆕 发布|AI-Driven Marine Robotics: Emerging Trends in Underwater Perception and Ecosystem Monitoring|基于人工智能的海洋机器人：水下感知与生态系统监测的新兴趋势|Scarlett Raine, Tobias Fischer|<http://arxiv.org/pdf/2509.01878v1>|揭示了水下环境挑战推动计算机视觉基础技术进步，促进AI在海洋监测中的靶向干预能力。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MedDINOv3: How to adapt vision foundation models for medical image segmentation?|MedDINOv3：如何将视觉基础模型适配于医学图像分割？|Yuheng Li, Yizhou Wu, Yuxiang Lai, Mingzhe Hu, Xiaofeng Yang|<http://arxiv.org/pdf/2509.02379v2>|[代码](https://github.com/ricklisz/MedDINOv3.); 提出MedDINOv3框架，通过多尺度聚合和域自适应预训练，提升基础视觉模型在医学图像分割的性能。|
|🆕 发布|Toward a robust lesion detection model in breast DCE-MRI: adapting foundation models to high-risk women|面向乳腺DCE-MRI稳健病变检测模型：将基础模型适配于高风险女性|Gabriel A. B. do Nascimento, Vincent Dong, Guilherme J. Cavalcante, Alex Nguyen, Thaís G. do Rêgo, Yuri Malheiros, Telmo M. Silva Filho, Carla R. Zeballos Torrez .etc.|<http://arxiv.org/pdf/2509.02710v1>|该研究通过自适应预训练模型和先进分类器，提高了高风险女性乳腺MRI病变检测的准确性和可解释性。|
|🆕 发布|AppCopilot: Toward General, Accurate, Long-Horizon, and Efficient Mobile Agent|《AppCopilot：迈向通用、精确、远距离、高效移动智能体》|Jingru Fan, Yufan Dang, Jingyao Wu, Huatao Li, Runde Yang, Xiyuan Yang, Yuheng Wang, Zhong Zhang .etc.|<http://arxiv.org/pdf/2509.02444v1>|提出了一种全栈式、跨应用的移动助手AppCopilot，实现了跨任务、模态、应用和设备的泛化能力，精...|
|🆕 发布|A Multimodal Cross-View Model for Predicting Postoperative Neck Pain in Cervical Spondylosis Patients|一种多模态跨视角模型用于预测颈椎病术后患者颈部疼痛|Jingyang Shan, Qishuai Yu, Jiacen Liu, Shaolin Zhang, Wen Shen, Yanxiao Zhao, Tianyi Wang, Xiaolin Qin .etc.|<http://arxiv.org/pdf/2509.02256v1>|提出了一种自适应双向金字塔差分卷积模块和特征金字塔配准辅助网络，有效预测颈椎病术后颈痛恢复。|
|📝 更新|DT-UFC: Universal Large Model Feature Coding via Peaky-to-Balanced Distribution Transformation|DT-UFC：通过峰值到平衡分布转换实现通用大模型特征编码|Changsheng Gao, Zijie Liu, Li Li, Dong Liu, Xiaoyan Sun, Weisi Lin|<http://arxiv.org/pdf/2506.16495v2>|[代码](https://github.com/chansongoal/DT-UFC.); 提出了一种通用的大模型特征编码方法，通过学习分布转换提高压缩效率和跨模型泛化能力。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FedMVP: Federated Multimodal Visual Prompt Tuning for Vision-Language Models|联邦多模态视觉提示微调用于视觉语言模型的方法|Mainak Singha, Subhankar Roy, Sarthak Mehrotra, Ankit Jha, Moloud Abdar, Biplab Banerjee, Elisa Ricci|<http://arxiv.org/pdf/2504.20860v2>|[代码](https://github.com/mainaksingha01/FedMVP.); 提出FedMVP方法，通过结合图像和文本属性特征生成多模态视觉提示，有效提升视觉语言模型对未见概念的...|
|🆕 发布|Scale, Don't Fine-tune: Guiding Multimodal LLMs for Efficient Visual Place Recognition at Test-Time|“规模扩展，无需微调：在测试时引导多模态大规模语言模型进行高效视觉场景识别”|Jintao Cheng, Weibin Li, Jiehao Luo, Xiaoyu Tang, Zhijian He, Jin Wu, Yao Zou, Wei Zhang|<http://arxiv.org/pdf/2509.02129v1>|提出了一种无需微调的零样本框架，通过测试时缩放和引导方法，实现了高效的视觉场景识别。|
|🆕 发布|Structure-aware Contrastive Learning for Diagram Understanding of Multimodal Models|结构感知对比学习用于多模态模型的图理解|Hiroshi Sasaki|<http://arxiv.org/pdf/2509.01959v1>|提出针对图表理解的对比学习新范式，通过利用图表结构特性提升视觉语言模型的性能。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-Scale Deep Learning for Colon Histopathology: A Hybrid Graph-Transformer Approach|多尺度深度学习在结肠组织病理学中的应用：一种混合图-变换器方法|Sadra Saremi, Amirhossein Ahmadkhan Kordbacheh|<http://arxiv.org/pdf/2509.02851v1>|提出了一种融合胶囊网络、图注意力机制和变换器模块的多尺度深度学习架构，用于提升结直肠癌病理图像的分类...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Open-Set LiDAR Panoptic Segmentation Guided by Uncertainty-Aware Learning|开集激光雷达全景分割：基于不确定性感知学习引导|Rohit Mohan, Julia Hindel, Florian Drews, Claudius Gläser, Daniele Cattaneo, Abhinav Valada|<http://arxiv.org/pdf/2506.13265v3>|提出ULOPS框架，通过不确定性学习区分已知和未知物体，提升激光雷达全景分割在开放环境下的性能。|
|🆕 发布|SALAD -- Semantics-Aware Logical Anomaly Detection|语义感知的逻辑异常检测|Matic Fučka, Vitjan Zavrtanik, Danijel Skočaj|<http://arxiv.org/pdf/2509.02101v1>|[代码](https://github.com/MaticFuc/SALAD); 提出了一种显式建模对象组成分布的语义感知逻辑异常检测方法，大幅提升了检测性能。|
|🆕 发布|2D Gaussian Splatting with Semantic Alignment for Image Inpainting|二维高斯散点绘制与语义对齐的图像修复方法|Hongyu Li, Chaofeng Chen, Xiaoming Li, Guangming Lu|<http://arxiv.org/pdf/2509.01964v1>|提出首个基于二维高斯散点法的图像修复框架，实现像素级连贯性和全局语义一致性。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AstroClearNet: Deep image prior for multi-frame astronomical image restoration|天体清晰网：用于多帧天文图像恢复的深度图像先验|Yashil Sukurdeep, Fausto Navarro, Tamás Budavári|<http://arxiv.org/pdf/2504.06463v2>|提出了一种基于深度图像先验的自监督多帧方法，有效恢复了地面观测的天文图像质量。|
|📝 更新|Net2Brain: A Toolbox to compare artificial vision models with human brain responses|Net2Brain：一种比较人工视觉模型与人类大脑反应的工具箱|Domenic Bersch, Kshitij Dwivedi, Martina Vilas, Radoslaw M. Cichy, Gemma Roig|<http://arxiv.org/pdf/2208.09677v3>|Net2Brain工具箱通过比较人工神经网络与人类大脑反应，实现了视觉模型与大脑活动的高效对比分析。|
|🆕 发布|Ordinal Adaptive Correction: A Data-Centric Approach to Ordinal Image Classification with Noisy Labels|序数自适应校正：面向带噪声标签的序数图像分类的数据中心方法|Alireza Sedighi Moghaddam, Mohammad Reza Mohammadi|<http://arxiv.org/pdf/2509.02351v1>|提出了一种自适应修正噪声标签的数据驱动方法，有效提升了有序图像分类模型的鲁棒性和准确性。|
|📝 更新|A Multi-Stage Auto-Context Deep Learning Framework for Tissue and Nuclei Segmentation and Classification in H&E-Stained Histological Images of Advanced Melanoma|高级黑色素瘤H&E染色组织学图像中组织和细胞核分割与分类的多阶段自动上下文深度学习框架|Nima Torbati, Anastasia Meshcheryakova, Ramona Woitek, Sepideh Hatamikia, Diana Mechtcheriakova, Amirreza Mahbod|<http://arxiv.org/pdf/2503.23958v2>|[代码](https://github.com/NimaTorbati/PumaSubmit); 提出了一种多阶段深度学习框架，将组织和细胞核信息融合，实现了高级黑色素瘤H&E染色组织图像的精确分割...|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hues and Cues: Human vs. CLIP|色相与线索：人类与CLIP对比|Nuria Alabau-Bosque, Jorge Vila-Tomás, Paula Daudén-Oliver, Pablo Hernández-Cámara, Jose Manuel Jaén-Lorites, Valero Laparra, Jesús Malo|<http://arxiv.org/pdf/2509.02305v2>|通过桌游Hues & Cues评估CLIP模型，揭示了其在颜色感知和命名上的与人类认知的契合度及文化...|
|🆕 发布|GenCompositor: Generative Video Compositing with Diffusion Transformer|生成合成器：基于扩散变换器的生成视频合成|Shuzhou Yang, Xiaoyu Li, Xiaodong Cun, Guangzhi Wang, Lingen Li, Ying Shan, Jian Zhang|<http://arxiv.org/pdf/2509.02460v1>|提出了一种基于扩散变换器的生成视频合成方法，自动化了传统需要大量劳动和专家协作的视频制作过程。|
|📝 更新|So-Fake: Benchmarking and Explaining Social Media Image Forgery Detection|“伪影识别：社交媒体图像伪造检测的基准测试与解释”|Zhenglin Huang, Tianxiao Li, Xiangtai Li, Haiquan Wen, Yiwei He, Jiangning Zhang, Hao Fei, Xi Yang .etc.|<http://arxiv.org/pdf/2505.18660v2>|提出大规模社交媒体伪造图像数据集和强化学习检测框架，提升伪造图像检测准确性和解释性。|
|📝 更新|A Large-scale Benchmark on Geological Fault Delineation Models: Domain Shift, Training Dynamics, Generalizability, Evaluation and Inferential Behavior|地质断层划分模型的大规模基准测试：域迁移、训练动态、泛化性、评估与推理行为|Jorge Quesada, Chen Zhou, Prithwijit Chowdhury, Mohammad Alotaibi, Ahmad Mustafa, Yusufjon Kumakov, Mohit Prabhushankar, Ghassan AlRegib|<http://arxiv.org/pdf/2505.08585v2>|构建首个大规模地质断层划分模型基准，指导领域迁移策略以提升模型泛化能力。|
|📝 更新|NOCTIS: Novel Object Cyclic Threshold based Instance Segmentation|NOCTIS：基于新颖对象循环阈值实例分割|Max Gandyra, Alessandro Santonicola, Michael Beetz|<http://arxiv.org/pdf/2507.01463v2>|提出了一种无需训练的NOCTIS框架，通过结合预训练模型和新型循环阈值机制，实现了对未见对象实例的高...|
|📝 更新|Learning Visual Proxy for Compositional Zero-Shot Learning|学习视觉代理以实现组合零样本学习|Shiyu Zhang, Cheng Yan, Yang Liu, Chenchen Jing, Lei Zhou, Wenjun Wang|<http://arxiv.org/pdf/2501.13859v4>|提出Visual Proxy Learning方法，通过优化视觉空间和跨模态联合学习，提升零样本组合...|
|📝 更新|Fine-grained Image Quality Assessment for Perceptual Image Restoration|细粒度图像质量评估用于感知图像恢复|Xiangfei Sheng, Xiaofeng Pan, Zhichao Yang, Pengfei Chen, Leida Li|<http://arxiv.org/pdf/2508.14475v2>|[代码](https://pxf0429.github.io/FGResQ); 提出首个针对图像复原的细粒度图像质量评估数据集，并设计了一种新的评估模型FGResQ，显著优于现有指...|
|🆕 发布|DroneSR: Rethinking Few-shot Thermal Image Super-Resolution from Drone-based Perspective|"DroneSR：从无人机视角重新思考少样本热图像超分辨率"|Zhipeng Weng, Xiaopeng Liu, Ce Liu, Xingyuan Guo, Yukai Shi, Liang Lin|<http://arxiv.org/pdf/2509.01898v1>|[代码](https://github.com/wengzp1/GARLSR.); 提出针对无人机红外图像的少量样本超分辨率问题，采用高斯量化表示学习减轻过拟合，增强模型鲁棒性。|
|🆕 发布|Latent Gene Diffusion for Spatial Transcriptomics Completion|潜在基因扩散用于空间转录组学完整性修复|Paula Cárdenas, Leonardo Manrique, Daniela Vega, Daniela Ruiz, Pablo Arbeláez|<http://arxiv.org/pdf/2509.01864v1>|提出了一种无需参考的基因扩散模型LGDiST，有效解决了空间转录组数据缺失问题。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Faster and Better: Reinforced Collaborative Distillation and Self-Learning for Infrared-Visible Image Fusion|更快更优：强化协作蒸馏与自学习用于红外-可见光图像融合|Yuhao Wang, Lingjuan Miao, Zhiqiang Zhou, Yajun Qiao, Lei Zhang|<http://arxiv.org/pdf/2509.02424v2>|提出了一种结合强化学习驱动的协作蒸馏与自我学习的框架，有效提升了轻量型模型在红外与可见光图像融合中的...|
|🆕 发布|Discrete Noise Inversion for Next-scale Autoregressive Text-based Image Editing|下一代自回归文本基础图像编辑的离散噪声反演|Quan Dao, Xiaoxiao He, Ligong Han, Ngan Hoai Nguyen, Amin Heyrani Nobar, Faez Ahmed, Han Zhang, Viet Anh Nguyen .etc.|<http://arxiv.org/pdf/2509.01984v2>|提出了一种针对视觉自回归模型的噪声逆变换编辑技术，实现了基于文本提示的精准图像编辑。|
|📝 更新|Deeply Supervised Flow-Based Generative Models|深度监督流式生成模型|Inkyu Shin, Chenglin Yang, Liang-Chieh Chen|<http://arxiv.org/pdf/2503.14494v2>|通过引入深层监督和VeRA块增强速度表示，DeepFlow模型加快了图像生成任务的收敛速度并提升了性...|
|🆕 发布|Unifi3D: A Study on 3D Representations for Generation and Reconstruction in a Common Framework|统一三维：在一个通用框架下对生成与重建的三维表示进行研究|Nina Wiedemann, Sainan Liu, Quentin Leboutet, Katelyn Gao, Benjamin Ummenhofer, Michael Paulitsch, Kai Yuan|<http://arxiv.org/pdf/2509.02474v1>|[代码](https://github.com/isl-org/unifi3d.); 提出了统一评估框架Unifi3D，比较了多种3D表示方法在生成和重建中的性能，提供了选择适用3D模型...|
|🆕 发布|TeRA: Rethinking Text-driven Realistic 3D Avatar Generation|TeRA：重新思考基于文本驱动的真实感三维头像生成|Yanwen Wang, Yiyu Zhuang, Jiawei Zhang, Li Wang, Yifei Zeng, Xun Cao, Xinxin Zuo, Hao Zhu|<http://arxiv.org/pdf/2509.02466v1>|提出两阶段训练策略的TeRA模型，通过文本控制生成高质量3D human avatar，优于传统模型...|
|🆕 发布|OmniActor: A Generalist GUI and Embodied Agent for 2D&3D Worlds|全方位执行者：一种面向2D与3D世界的通用图形用户界面与具身智能体|Longrong Yang, Zhixiong Zeng, Yufeng Zhong, Jing Huang, Liming Zheng, Lei Chen, Haibo Qiu, Zequn Qin .etc.|<http://arxiv.org/pdf/2509.02322v1>|提出了一种结合GUI与3D环境交互的通用智能体OmniActor，通过分层异构模型有效融合数据优势。|
|🆕 发布|Data-Driven Loss Functions for Inference-Time Optimization in Text-to-Image Generation|数据驱动的损失函数用于文本到图像生成中的推理时间优化|Sapir Esther Yiflach, Yuval Atzmon, Gal Chechik|<http://arxiv.org/pdf/2509.02295v1>|提出了一种学习驱动的损失函数，通过训练轻量级分类器优化生成图像中的空间关系，显著提升了文本到图像生成...|
|🆕 发布|Understanding Space Is Rocket Science - Only Top Reasoning Models Can Solve Spatial Understanding Tasks|理解空间是火箭科学——只有顶级推理模型才能解决空间理解任务|Nils Hoehing, Mayug Maniparambil, Ellen Rushe, Noel E. O'Connor, Anthony Ventresque|<http://arxiv.org/pdf/2509.02175v1>|[代码](https://github.com/nilshoehing/rocketscience); 提出RocketScience基准，揭示了当前视觉语言模型在空间关系理解上的不足，并强调了推理模型的...|
|📝 更新|CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features for a Disentangled, Interpretable, and Controllable Text-Guided Face Manipulation|CLIP-PAE：投影增强嵌入以提取用于解耦、可解释和可控的文本引导面部操作的相关特征|Chenliang Zhou, Fangcheng Zhong, Cengiz Oztireli|<http://arxiv.org/pdf/2210.03919v6>|[代码](https://chenliang-zhou.github.io/CLIP-PAE); 提出了一种优化文本引导图像操纵的方法CLIP-PAE，通过定义相关提示子空间提高了操纵的解耦性、可解...|
|🆕 发布|Enhancing Zero-Shot Pedestrian Attribute Recognition with Synthetic Data Generation: A Comparative Study with Image-To-Image Diffusion Models|利用合成数据生成增强零样本行人属性识别：与图像到图像扩散模型的比较研究|Pablo Ayuso-Albizu, Juan C. SanMiguel, Pablo Carballeira|<http://arxiv.org/pdf/2509.02161v1>|本研究通过生成合成数据扩展零样本行人属性识别数据集，提升了模型在复杂场景下的识别性能。|
|🆕 发布|Conditional-$t^3$VAE: Equitable Latent Space Allocation for Fair Generation|条件-t^3VAE：公平生成的等价潜在空间分配|Aymene Mohammed Bouayed, Samuel Deslauriers-Gauthier, Adrian Iaccovelli, David Naccache|<http://arxiv.org/pdf/2509.02154v1>|提出了一种Conditional-$t^3$VAE方法，通过为不同类别分配公平的潜在空间，提高了生成...|
|📝 更新|Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vector Drawings|从矢量绘图到CAD生成的序列到序列学习：Drawing2CAD|Feiwei Qin, Shichao Lu, Junhao Hou, Changmiao Wang, Meie Fang, Ligang Liu|<http://arxiv.org/pdf/2508.18733v2>|[代码](https://github.com/lllssc/Drawing2CAD.); 将2D工程图纸自动转化为参数化CAD模型的序列到序列学习方法。|
|📝 更新|Removing Averaging: Personalized Lip-Sync Driven Characters Based on Identity Adapter|去除平均化：基于身份适配器的个性化唇同步驱动角色|Yanyu Zhu, Lichen Bai, Jintao Xu, Hai-tao Zheng|<http://arxiv.org/pdf/2503.06397v2>|提出了一种新方法UnAvgLip，通过提取面部特征嵌入解决唇部同步生成中面部细节丢失问题。|
|📝 更新|Multimodal Conditional 3D Face Geometry Generation|多模态条件三维人脸几何生成|Christopher Otto, Prashanth Chandran, Sebastian Weiss, Markus Gross, Gaspard Zoss, Derek Bradley|<http://arxiv.org/pdf/2407.01074v2>|提出了一种多模态条件生成方法，通过不同信号控制输出身份和表情，生成高质量的3D人脸模型。|
|🆕 发布|Palette Aligned Image Diffusion|调色板对齐的图像扩散|Elad Aharoni, Noy Porat, Dani Lischinski, Ariel Shamir|<http://arxiv.org/pdf/2509.02000v1>|提出Palette-Adapter方法，通过控制参数稳定地将用户指定的颜色样板应用于图像生成。|
|🆕 发布|MOSAIC: Multi-Subject Personalized Generation via Correspondence-Aware Alignment and Disentanglement|通过对应感知对齐与解耦实现多主体个性化生成：MOSAIC|Dong She, Siming Fu, Mushui Liu, Qiaoqiao Jin, Hualiang Wang, Mu Liu, Jidong Jiang|<http://arxiv.org/pdf/2509.01977v1>|生成多人个性化图像时，MOSAIC通过精确的语义对应和特征解耦，解决了身份混合和属性泄露问题。|
|🆕 发布|Draw-In-Mind: Learning Precise Image Editing via Chain-of-Thought Imagination|《心中描绘：通过链式思维想象学习精确图像编辑》|Ziyun Zeng, Junhao Zhang, Wei Li, Mike Zheng Shou|<http://arxiv.org/pdf/2509.01986v1>|[代码](https://github.com/showlab/DIM.); 提出了一种通过链式思维想象实现精确图像编辑的新方法，通过明确分工提升编辑性能。|
|🆕 发布|A Diffusion-Based Framework for Configurable and Realistic Multi-Storage Trace Generation|基于扩散的框架用于配置化和真实的多存储轨迹生成|Seohyun Kim, Junyoung Lee, Jongho Park, Jinhyung Koo, Sungjin Lee, Yeseong Kim|<http://arxiv.org/pdf/2509.01919v1>|提出DiTTO框架，利用扩散技术生成高保真、可配置的多设备存储轨迹。|
|📝 更新|A Vision-Language Agent System for Compositional Reasoning with VLM-assisted Script and Executable Generation|用于组合推理的视觉-语言智能体系统：基于大语言模型辅助的脚本与可执行代码生成|Yichang Xu, Gaowen Liu, Ramana Rao Kompella, Sihao Hu, Tiansheng Huang, Fatih Ilhan, Selim Furkan Tekin, Zachary Yahn .etc.|<http://arxiv.org/pdf/2506.07778v2>|提出VLAgent系统，利用大型语言模型和视觉模型进行视觉文本的组合推理，通过生成和优化执行脚本来提...|
|📝 更新|Exploiting Diffusion Prior for Task-driven Image Restoration|利用扩散先验进行任务驱动的图像恢复|Jaeha Kim, Junghun Oh, Kyoung Mu Lee|<http://arxiv.org/pdf/2507.22459v2>|提出了一种利用扩散先验进行任务驱动的图像复原方法，有效恢复了任务相关细节并提升了图像质量。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PixFoundation 2.0: Do Video Multi-Modal LLMs Use Motion in Visual Grounding?|PixFoundation 2.0：视频多模态LLM在视觉定位中是否利用了运动信息？|Mennatullah Siam|<http://arxiv.org/pdf/2509.02807v1>|[代码](https://github.com/MSiam/PixFoundation-2.0.git.); 探究视频多模态大语言模型在像素级视觉定位中如何利用运动信息，并提出了针对性的评估基准。|
|🆕 发布|Towards High-Fidelity, Identity-Preserving Real-Time Makeup Transfer: Decoupling Style Generation|面向高保真、身份保持的实时妆容迁移：解耦风格生成|Lydia Kin Ching Chau, Zhi Yu, Ruo Wei Jiang|<http://arxiv.org/pdf/2509.02445v1>|提出两步骤解耦方法实现实时高保真度且身份保持的虚拟化妆试戴。|
|🆕 发布|Category-Aware 3D Object Composition with Disentangled Texture and Shape Multi-view Diffusion|解耦纹理与形状的多视角扩散实现的类别感知三维物体组合|Zeren Xiong, Zikun Chen, Zedong Zhang, Xiang Li, Ying Tai, Jian Yang, Jun Li|<http://arxiv.org/pdf/2509.02357v1>|[代码](https://xzr52.github.io/C33D); 提出了一种生成新颖3D模型的方法，通过分离纹理和形状的多视角扩散，有效整合不同类别对象。|
|📝 更新|Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference|迈向人类级别的三维相对位姿估计：通用性，无需训练，单参考帧|Yuan Gao, Yajing Luo, Junhong Wang, Kui Jia, Gui-Song Xia|<http://arxiv.org/pdf/2406.18453v2>|提出了一种无需训练、仅需单参考图像即可实现人类水平的三维相对位姿估计的新方法。|
|🆕 发布|SynthGenNet: a self-supervised approach for test-time generalization using synthetic multi-source domain mixing of street view images|SynthGenNet：一种利用合成多源领域混合街景图像进行测试时泛化的自监督方法|Pushpendra Dhakara, Prachi Chachodhia, Vaibhav Kumar|<http://arxiv.org/pdf/2509.02287v1>|提出SynthGenNet，通过合成多源图像的自监督学习实现测试时的域泛化，有效应对城市环境复杂性挑...|
|📝 更新|Generative Frame Sampler for Long Video Understanding|长视频理解用的生成性帧采样器|Linli Yao, Haoning Wu, Kun Ouyang, Yuanxing Zhang, Caiming Xiong, Bei Chen, Xu Sun, Junnan Li|<http://arxiv.org/pdf/2503.09146v2>|提出了一种生成帧采样器GenS，有效提升长视频理解效率并取得最先进性能。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|TriPSS: A Tri-Modal Keyframe Extraction Framework Using Perceptual, Structural, and Semantic Representations|TriPSS：一种基于感知、结构和语义表征的三模态关键帧提取框架|Mert Can Cakmak, Nitin Agarwal, Diwash Poudel|<http://arxiv.org/pdf/2506.05395v2>|TriPSS通过融合感知、结构和语义三种模态特征，实现了高效的关键帧提取，领先现有方法。|
|📝 更新|ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding|长视频理解中语义聚合幻觉的基准测试：ELV-Halluc|Hao Lu, Jiahao Wang, Yaolun Zhang, Ruohui Wang, Xuanyu Zheng, Yepeng Tang, Dahua Lin, Lewei Lu|<http://arxiv.org/pdf/2508.21496v2>|提出首个针对长视频的语义聚合幻觉基准ELV-Halluc，并探讨了缓解策略。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Motion-Refined DINOSAUR for Unsupervised Multi-Object Discovery|无监督多目标发现中的运动细化DINOSAUR|Xinrui Gong, Oliver Hahn, Christoph Reich, Krishnakant Singh, Simone Schaub-Meyer, Daniel Cremers, Stefan Roth|<http://arxiv.org/pdf/2509.02545v1>|提出了一种无需监督的物体发现方法MR-DINOSAUR，通过视频运动信息和自监督学习改进物体检测。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Decoupling Bidirectional Geometric Representations of 4D cost volume with 2D convolution|解耦四维代价体中双向几何表示的二维卷积|Xiaobao Wei, Changyong Shu, Zhaokun Yue, Chang Huang, Weiwei Liu, Shuai Yang, Lirong Yang, Peng Gao .etc.|<http://arxiv.org/pdf/2509.02415v1>|[代码](https://github.com/happydummy/DBStereo); 提出了一种基于纯2D卷积的4D成本聚合网络，实现了实时性能与高准确度的平衡。|
|📝 更新|StylizedGS: Controllable Stylization for 3D Gaussian Splatting|风格化GS：用于三维高斯散点绘制的可控风格化|Dingxi Zhang, Yu-Jie Yuan, Zhuoxun Chen, Fang-Lue Zhang, Zhenliang He, Shiguang Shan, Lin Gao|<http://arxiv.org/pdf/2404.05220v3>|提出了一种基于3D高斯散点的神经风格迁移框架，实现了高效的3D模型风格化并允许用户灵活控制感知因素。|
|🆕 发布|Doctoral Thesis: Geometric Deep Learning For Camera Pose Prediction, Registration, Depth Estimation, and 3D Reconstruction|博士学位论文：几何深度学习在相机位姿预测、注册、深度估计与三维重建中的应用|Xueyang Kang|<http://arxiv.org/pdf/2509.01873v1>|提出结合几何约束的深度学习方法，解决了3D视觉任务中的关键挑战，提升了模型准确性和鲁棒性。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Can NeRFs See without Cameras?|“神经辐射场（NeRF）无需相机能否实现视觉？”|Chaitanya Amballa, Sattwik Basu, Yu-Lin Wei, Zhijian Yang, Mehmet Ergezer, Romit Roy Choudhury|<http://arxiv.org/pdf/2505.22441v2>|提出利用NeRFs从多径信号中学习，实现无相机环境感知。|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|See No Evil: Adversarial Attacks Against Linguistic-Visual Association in Referring Multi-Object Tracking Systems|《不见恶：针对指代多目标跟踪系统中语言-视觉关联的对抗性攻击》|Halima Bouzidi, Haoyu Liu, Mohammad Abdullah Al Faruque|<http://arxiv.org/pdf/2509.02028v2>|揭示了多目标跟踪系统中语言-视觉关联的对抗性漏洞，并提出了VEIL框架来破坏其跟踪逻辑可靠性。|
|🆕 发布|NOOUGAT: Towards Unified Online and Offline Multi-Object Tracking|“NOOUGAT：迈向统一在线与离线多目标跟踪”|Benjamin Missaoui, Orcun Cetintas, Guillem Brasó, Tim Meinhardt, Laura Leal-Taixé|<http://arxiv.org/pdf/2509.02111v1>|提出了NOOUGAT，一种结合在线与离线优势的多目标跟踪方法，通过统一图神经网络框架和自回归长期跟踪...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhancing Fitness Movement Recognition with Attention Mechanism and Pre-Trained Feature Extractors|使用注意力机制和预训练特征提取器增强健身动作识别|Shanjid Hasan Nishat, Srabonti Deb, Mohiuddin Ahmed|<http://arxiv.org/pdf/2509.02511v1>|提出了一种结合预训练2D CNN和LSTM的轻量级框架，通过注意力机制提升健身动作识别准确性和效率。|
|📝 更新|SequencePAR: Understanding Pedestrian Attributes via A Sequence Generation Paradigm|序列PAR：通过序列生成范式理解行人属性|Jiandong Jin, Xiao Wang, Yin Lin, Chenglong Li, Lili Huang, Aihua Zheng, Jin Tang|<http://arxiv.org/pdf/2312.01640v2>|[代码](https://github.com/Event-AHU/OpenPAR.); 提出了一种基于生成模型的行人属性识别方法SequencePAR，通过序列生成范式有效解决了数据不平衡...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EventTracer: Fast Path Tracing-based Event Stream Rendering|事件追踪器：基于快速路径追踪的事件流渲染|Zhenyang Li, Xiaoyang Bai, Jinfan Lu, Pengfei Shen, Edmund Y. Lam, Yifan Peng|<http://arxiv.org/pdf/2508.18071v2>|提出EventTracer，一种基于路径追踪的高效模拟器，快速生成高保真事件序列，缩小了虚拟与现实的...|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VSRM: A Robust Mamba-Based Framework for Video Super-Resolution|视频超分辨率稳健的Mamba基础框架：VSRM|Dinh Phu Tran, Dao Duy Hung, Daeyoung Kim|<http://arxiv.org/pdf/2506.22762v2>|提出VSRM框架，利用Mamba提取长距离时空特征，实现视频超分辨率处理。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PRECISE-AS: Personalized Reinforcement Learning for Efficient Point-of-Care Echocardiography in Aortic Stenosis Diagnosis|个性化强化学习辅助的主动脉狭窄诊断高效床边超声心动图技术|Armin Saadat, Nima Hashemi, Hooman Vaseli, Michael Y. Tsang, Christina Luong, Michiel Van de Panne, Teresa S. M. Tsang, Purang Abolmaesumi|<http://arxiv.org/pdf/2509.02898v1>|[代码](https://github.com/Armin-Saadat/PRECISE-AS.); 提出了一种个性化的强化学习框架，动态选择最有信息的超声心动图视频，提高主动脉狭窄诊断的效率和准确性。|
|📝 更新|DeepTopoNet: A Framework for Subglacial Topography Estimation on the Greenland Ice Sheets|深度地形网：格陵兰冰盖下地形估计的框架|Bayu Adhi Tama, Mansa Krishna, Homayra Alam, Mostafa Cham, Omar Faruque, Gong Cheng, Jianwu Wang, Mathieu Morlighem .etc.|<http://arxiv.org/pdf/2505.23980v2>|提出了一种深度学习框架DeepTopoNet，通过动态损失平衡机制整合雷达和BedMachine数据...|
|📝 更新|Muzzle-Based Cattle Identification System Using Artificial Intelligence (AI)|基于人工智能（AI）的枪口识别牛只系统|Hasan Zohirul Islam, Safayet Khan, Sanjib Kumar Paul, Sheikh Imtiaz Rahi, Fahim Hossain Sifat, Md. Mahadi Hasan Sany, Md. Shahjahan Ali Sarker, Tareq Anam .etc.|<http://arxiv.org/pdf/2407.06096v3>|开发了一种基于牛鼻 muzzle 的识别系统，利用机器学习提高牲畜保险理赔效率和精度。|
|🆕 发布|Why Do MLLMs Struggle with Spatial Understanding? A Systematic Analysis from Data to Architecture|为什么大规模语言模型在空间理解上遇到困难？从数据到架构的系统分析|Wanyue Zhang, Yibin Huang, Yangbin Xu, JingJing Huang, Helu Zhi, Shuo Ren, Wang Xu, Jiajun Zhang|<http://arxiv.org/pdf/2509.02359v1>|系统分析了多模态大语言模型在空间理解上的局限，并提出了相应的评估基准和改进方向。|
|🆕 发布|SegFormer Fine-Tuning with Dropout: Advancing Hair Artifact Removal in Skin Lesion Analysis|《带有Dropout的SegFormer微调：推进皮肤病变分析中的毛发伪影去除》|Asif Mohammed Saad, Umme Niraj Mahi|<http://arxiv.org/pdf/2509.02156v1>|提出了一种改进的SegFormer模型，通过加入dropout正则化，有效提高了皮肤病变分析中毛发伪...|
|📝 更新|Micro-splatting: Multistage Isotropy-informed Covariance Regularization Optimization for High-Fidelity 3D Gaussian Splatting|微散点法：多阶段各向同性指导协方差正则化优化，用于高保真三维高斯散点渲染|Jee Won Lee, Hansol Lim, Sooyeun Yang, Jongseong Brad Choi|<http://arxiv.org/pdf/2504.05740v2>|提出了一种高效的3D Gaussian Splatting优化方法，通过自适应生长与精炼两阶段减少了...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Full-Head Segmentation of MRI with Abnormal Brain Anatomy: Model and Data Release|异常脑解剖结构的MRI全头部分割：模型与数据发布|Andrew M Birnbaum, Adam Buchwald, Peter Turkeltaub, Adam Jacks, George Carra, Shreya Kannana, Yu Huang, Abhisheck Datta .etc.|<http://arxiv.org/pdf/2501.18716v2>|提出了一种多平面独立操作的深度网络，实现了包含异常解剖结构的全头部分割，并发布了首个公开的数据集。|
|🆕 发布|GRMM: Real-Time High-Fidelity Gaussian Morphable Head Model with Learned Residuals|GRMM：具有学习残差的实时高保真高斯形变人头模型|Mohit Mendiratta, Mayur Deshmukh, Kartik Teotia, Vladislav Golyanik, Adam Kortylewski, Christian Theobalt|<http://arxiv.org/pdf/2509.02141v1>|提出高保真实时渲染的GRMM模型，通过学习残差提升面部细节和表情精度。|
|📝 更新|Compressed Feature Quality Assessment: Dataset and Baselines|压缩特征质量评估：数据集与基线|Changsheng Gao, Wei Zhou, Guosheng Lin, Weisi Lin|<http://arxiv.org/pdf/2506.07412v2>|[代码](https://github.com/chansongoal/Compressed-Feature-Quality-Assessment.); 提出压缩特征质量评估问题并构建首个相关基准数据集，评估了现有度量方法对语义退化的捕捉能力。|
|📝 更新|CF3: Compact and Fast 3D Feature Fields|CF3：紧凑且快速的三维特征场|Hyunjoon Lee, Joonkyu Min, Jaesik Park|<http://arxiv.org/pdf/2508.05254v3>|提出了一种高效的3D特征场构建方法CF3，通过融合预训练高斯函数和自适应稀疏化，大幅减少计算量同时保...|
|🆕 发布|Automated Wildfire Damage Assessment from Multi view Ground level Imagery Via Vision Language Models|通过视觉语言模型的多视角地面图像自动化评估野火损害|Miguel Esparza, Archit Gupta, Ali Mostafavi, Kai Yin, Yiming Xiao|<http://arxiv.org/pdf/2509.01895v1>|提出零样本框架，利用预训练视觉语言模型从多视角地面图像中评估野火损害，大幅提升分类准确度。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Reconstructing Tornadoes in 3D with Gaussian Splatting|三维高斯散点重建龙卷风|Adam Yang, Nadula Kadawedduwa, Tianfu Wang, Sunny Sharma, Emily F. Wisinski, Jhayron S. Pérez-Carrasquilla, Kyle J. C. Hall, Dean Calhoun .etc.|<http://arxiv.org/pdf/2506.18677v2>|提出了一种利用3D高斯散点法重构小型实验室龙卷风三维结构的新方法。|
|🆕 发布|Efficient Pyramidal Analysis of Gigapixel Images on a Decentralized Modest Computer Cluster|分布式小型计算机集群上的高效金字塔分析超大像素图像|Marie Reinbigler, Rishi Sharma, Rafael Pires, Elisabeth Brunet, Anne-Marie Kermarrec, Catalin Fetita|<http://arxiv.org/pdf/2509.02440v1>|提出渐进式分析的PyramidAI方法，减少2.65倍数据处理量，实现快速高效分析吉字节图像。|
|🆕 发布|Ensemble-Based Event Camera Place Recognition Under Varying Illumination|基于集成的事件相机在变化光照条件下的位置识别|Therese Joseph, Tobias Fischer, Michael Milford|<http://arxiv.org/pdf/2509.01968v1>|提出了一种集成方法，通过融合多个重建、特征提取器和时间分辨率，显著提高了事件相机在光照变化下的场景识...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Towards Comprehensive Cellular Characterisation of H&E slides|迈向全面细胞特征描述的H&E切片研究|Benjamin Adjadj, Pierre-Antoine Bannier, Guillaume Horent, Sebastien Mandela, Aurore Lyon, Kathryn Schutte, Ulysse Marteau, Valentin Gaury .etc.|<http://arxiv.org/pdf/2508.09926v3>|[代码](https://github.com/owkin/histoplus); 提出HistoPLUS模型，通过新型泛癌数据集提升了对罕见细胞类型的识别与分类性能。|
|🆕 发布|ADVMEM: Adversarial Memory Initialization for Realistic Test-Time Adaptation via Tracklet-Based Benchmarking|ADVMEM：基于轨迹集基准测试的实时适应现实场景的对抗性内存初始化|Shyma Alhuwaider, Motasem Alfarra, Juan C. Perez, Merey Ramazanova, Bernard Ghanem|<http://arxiv.org/pdf/2509.02182v1>|提出基于轨迹的测试时适应新基准，并引入对抗性内存初始化策略提升性能。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DSGC-Net: A Dual-Stream Graph Convolutional Network for Crowd Counting via Feature Correlation Mining|DSGC-Net：一种通过特征相关性挖掘进行人群计数的双流图卷积网络|Yihong Wu, Jinqiao Wei, Xionghui Zhao, Yidi Li, Shaoyi Du, Bin Ren, Nicu Sebe|<http://arxiv.org/pdf/2509.02261v1>|[代码](https://github.com/Wu-eon/CrowdCounting-DSGCNet.); 提出DSGC-Net模型，通过双流图卷积网络和特征相关性挖掘，有效应对复杂场景下人群计数问题。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning|《UI-TARS-2技术报告：利用多轮强化学习推进图形用户界面代理的发展》|Haoming Wang, Haoyang Zou, Huatong Song, Jiazhan Feng, Junjie Fang, Junting Lu, Longxiang Liu, Qinyu Luo .etc.|<http://arxiv.org/pdf/2509.02544v1>|提出UI-TARS-2模型，通过创新训练方法提升GUI智能体多轮强化学习性能及环境适应性。|
|📝 更新|R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning|R-4B: 通过双模退火和强化学习激励多模态大型语言模型中的通用自动思维能力|Qi Yang, Bolin Ni, Shiming Xiang, Han Hu, Houwen Peng, Jie Jiang|<http://arxiv.org/pdf/2508.21113v2>|提出R-4B模型，通过双模退火和强化学习激励通用自动思维，自适应决定是否进行复杂推理，提升多模大语言...|
|🆕 发布|Palmistry-Informed Feature Extraction and Analysis using Machine Learning|利用机器学习进行掌相特征提取与分析|Shweta Patil|<http://arxiv.org/pdf/2509.02248v1>|提出了一种基于机器学习的掌纹特征提取与分析方法，实现了对掌部特征的自动化识别和预测模型的训练。|
|🆕 发布|ContextFusion and Bootstrap: An Effective Approach to Improve Slot Attention-Based Object-Centric Learning|entric学习的有效方法|Pinzhuo Tian, Shengjie Yang, Hang Yu, Alex C. Kot|<http://arxiv.org/pdf/2509.02032v1>|提出方法解决对象注意力模型对低级特征过度敏感问题，通过融合上下文信息和引入自适应训练策略提升对象理解...|
|📝 更新|Bridging Synthetic-to-Real Gaps: Frequency-Aware Perturbation and Selection for Single-shot Multi-Parametric Mapping Reconstruction|桥接合成到现实差距：频率感知扰动与选择用于单次多参数映射重建|Linyu Fan, Che Wang, Ming Ye, Qizhi Yang, Zejun Wu, Xinghao Ding, Yue Huang, Jianfeng Bao .etc.|<http://arxiv.org/pdf/2503.03475v2>|[代码](https://github.com/flyannie/FPS.); 提出了一种频率感知扰动与选择方法，有效桥接合成数据与真实数据间的差距，提升多参数映射重建质量。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Occlusion Robustness of CLIP for Military Vehicle Classification|CLIP在军事车辆分类中的遮挡鲁棒性研究|Jan Erik van Woerden, Gertjan Burghouts, Lotte Nijskens, Alma M. Liezenga, Sabina van Rooij, Frank Ruis, Hugo J. Kuijf|<http://arxiv.org/pdf/2508.20760v2>|研究了CLIP模型在军事车辆分类中的遮挡鲁棒性，发现细粒度遮挡影响大，通过模型微调可提升鲁棒性。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Data-Centric Approach to Pedestrian Attribute Recognition: Synthetic Augmentation via Prompt-driven Diffusion Models|基于数据中心的行人属性识别方法：通过提示驱动的扩散模型进行合成增强|Alejandro Alonso, Sawaiz A. Chaudhry, Juan C. SanMiguel, Álvaro García-Martín, Pablo Ayuso-Albizu, Pablo Carballeira|<http://arxiv.org/pdf/2509.02099v1>|提出数据驱动方法，通过文本提示生成合成数据增强，提升行人属性识别性能。|
|📝 更新|Multimodal LLMs Can Reason about Aesthetics in Zero-Shot|多模态大型语言模型能在零样本情况下对美学进行推理|Ruixiang Jiang, Changwen Chen|<http://arxiv.org/pdf/2501.09012v3>|[代码](https://github.com/songrise/MLLM4Art.); 提出方法利用多模态LLM进行审美判断，减少主观偏差，提高与人类审美一致性。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 目标导向视觉决策 (Goal-oriented Visual Decision Making)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SpatialViz-Bench: An MLLM Benchmark for Spatial Visualization|空间可视化基准：面向多模态语言模型的空间可视化MLLM基准|Siting Wang, Minnan Pei, Luoyang Sun, Cheng Deng, Kun Shao, Zheng Tian, Haifeng Zhang, Jun Wang|<http://arxiv.org/pdf/2507.07610v4>|提出SpatialViz-Bench，针对多模态大语言模型在空间可视化任务上的不足，创建了包含12个...|


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Manipulation as in Simulation: Enabling Accurate Geometry Perception in Robots|模拟式操作：使机器人具备精确几何感知能力|Minghuan Liu, Zhengbang Zhu, Xiaoshen Han, Peng Hu, Haotong Lin, Xinyao Li, Jingxiao Chen, Jiafeng Xu .etc.|<http://arxiv.org/pdf/2509.02530v1>|提出Camera Depth Models，通过模拟数据训练深度相机，实现接近仿真精度的深度预测，显...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|JARVIS: A Neuro-Symbolic Commonsense Reasoning Framework for Conversational Embodied Agents|JARVIS：一种用于会话型具身代理的神经符号常识推理框架|Kaizhi Zheng, Kaiwen Zhou, Jing Gu, Yue Fan, Jialu Wang, Zonglin Di, Xuehai He, Xin Eric Wang|<http://arxiv.org/pdf/2208.13266v4>|提出JARVIS框架，结合神经符号推理，提升对话型机器人执行真实任务的性能与可解释性。|
|📝 更新|BRACTIVE: A Brain Activation Approach to Human Visual Brain Learning|脑激活法：一种人类视觉大脑学习的新方法|Xuan-Bac Nguyen, Hojin Jang, Xin Li, Samee U. Khan, Pawan Sinha, Khoa Luu|<http://arxiv.org/pdf/2405.18808v3>|提出了一种基于大脑激活的视觉学习框架，实现了多受试者视觉脑区自动识别并提升深度网络性能。|
|🆕 发布|Omnidirectional Spatial Modeling from Correlated Panoramas|全方位空间建模：从相关全景图中获取|Xinshen Zhang, Tongxi Fu, Xu Zheng|<http://arxiv.org/pdf/2509.02164v1>|提出首个跨帧全景视觉问答数据集CFpano，并开发出基于多模态大语言模型的\methodname方法...|
|📝 更新|Exploring Primitive Visual Measurement Understanding and the Role of Output Format in Learning in Vision-Language Models|探索视觉测量理解基础与输出格式在视觉语言模型学习中的作用|Ankit Yadav, Lingqiao Liu, Yuankai Qi|<http://arxiv.org/pdf/2501.15144v2>|探究了视觉语言模型在基本形状视觉理解和属性测量上的能力，并发现输出格式和损失计算策略对性能有显著影响...|
|📝 更新|ViEEG: Hierarchical Visual Neural Representation for EEG Brain Decoding|ViEEG：用于EEG脑解码的分层视觉神经表征|Minxu Liu, Donghai Guan, Chuhang Zheng, Chunwei Tian, Jie Wen, Qi Zhu|<http://arxiv.org/pdf/2505.12408v3>|提出ViEEG框架，通过模拟大脑视觉处理层次，提升EEG视觉解码性能。|
|📝 更新|VIKSER: Visual Knowledge-Driven Self-Reinforcing Reasoning Framework|VIKSER：视觉知识驱动自强化推理框架|Chao Wang, Chunbai Zhang, Yongxiao Tian, Yang Zhou, Yan Peng|<http://arxiv.org/pdf/2502.00711v2>|提出VIKSER框架，通过细粒度视觉知识与自我强化推理，提升视觉推理任务的准确性与解释性。|
|📝 更新|Exploring the Application of Visual Question Answering (VQA) for Classroom Activity Monitoring|探索视觉问答（VQA）在课堂活动监控中的应用|Sinh Trong Vu, Hieu Trung Pham, Dung Manh Nguyen, Hieu Minh Hoang, Nhu Hoang Le, Thu Ha Pham, Tai Tan Mai|<http://arxiv.org/pdf/2507.22369v3>|探究了视觉问答模型在课堂行为分析中的应用，并构建了专用数据集以评估模型性能。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Detecting Visual Information Manipulation Attacks in Augmented Reality: A Multimodal Semantic Reasoning Approach|增强现实中的视觉信息操纵攻击检测：一种多模态语义推理方法|Yanming Xiu, Maria Gorlatova|<http://arxiv.org/pdf/2507.20356v4>|提出了一种多模态语义推理框架VIM-Sense，有效检测增强现实中的视觉信息操纵攻击。|
|📝 更新|DesCLIP: Robust Continual Learning via General Attribute Descriptions for VLM-Based Visual Recognition|DesCLIP：基于属性描述的稳健连续学习，用于VLM基础上的视觉识别|Chiyuan He, Zihuan Qiu, Fanman Meng, Linfeng Xu, Qingbo Wu, Hongliang Li|<http://arxiv.org/pdf/2502.00618v2>|提出了一种利用通用属性描述引导视觉语言模型学习的方法DesCLIP，有效缓解了模型在持续学习中的遗忘...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model|2024年CVPR端到端挑战赛二等奖解决方案：使用视觉语言模型的端到端自动驾驶|Zilong Guo, Yi Luo, Long Sha, Dongxu Wang, Panqu Wang, Chenyang Xu, Yi Yang|<http://arxiv.org/pdf/2509.02659v1>|展示了结合端到端架构与知识丰富的视觉语言模型在自动驾驶任务中的显著性能提升。|
|🆕 发布|AutoDrive-R$^2$: Incentivizing Reasoning and Self-Reflection Capacity for VLA Model in Autonomous Driving|自动驾驶中的AutoDrive-R$^2$：激励推理与自我反思能力以提高自动驾驶车辆模型的表现|Zhenlong Yuan, Jing Tang, Jinguo Luo, Rui Chen, Chengxuan Qian, Lei Sun, Xiangxiang Chu, Yujun Cai .etc.|<http://arxiv.org/pdf/2509.01944v1>|提出AutoDrive-R$^2$框架，结合链式思考和强化学习提升自动驾驶系统的推理和自我反思能力。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Anisotropic Fourier Features for Positional Encoding in Medical Imaging|各向异性傅里叶特征在医学成像中的位置编码应用|Nabil Jabareen, Dongsheng Yuan, Dingming Liu, Foo-Wei Ten, Sören Lukassen|<http://arxiv.org/pdf/2509.02488v1>|提出适用于医学成像的各向异性傅里叶特征位置编码方法，提升了模型在异构数据上的性能。|
|🆕 发布|Mix-modal Federated Learning for MRI Image Segmentation|多模态联邦学习在MRI图像分割中的应用|Guyue Hu, Siyuan Song, Jingpeng Sun, Zhe Jin, Chenglong Li, Jin Tang|<http://arxiv.org/pdf/2509.02541v1>|提出了一种新的联邦学习范式MixMFL及MDM-MixMFL框架，用于处理分布式医疗场景下的MRI图...|
|🆕 发布|RiverScope: High-Resolution River Masking Dataset|河流视野：高分辨率河流遮罩数据集|Rangel Daroya, Taylor Rowley, Jonathan Flores, Elisa Friedmann, Fiona Bennitt, Heejin An, Travis Simmons, Marissa Jean Hughes .etc.|<http://arxiv.org/pdf/2509.02451v1>|介绍了RiverScope高分辨率河流掩膜数据集，为精确监测河流提供了首个全球高分辨率基准，并显著提...|
|🆕 发布|From Noisy Labels to Intrinsic Structure: A Geometric-Structural Dual-Guided Framework for Noise-Robust Medical Image Segmentation|从噪声标签到内在结构：一种基于几何结构双引导的噪声稳健医学图像分割框架|Tao Wang, Zhenxuan Zhang, Yuanbo Zhou, Xinlin Zhang, Yuanbin Chen, Tao Tan, Guang Yang, Tong Tong|<http://arxiv.org/pdf/2509.02419v1>|[代码](https://github.com/ortonwang/GSD-Net.); 提出了一种结合几何和结构线索的网络，有效提升了噪声标注下的医学图像分割性能。|
|📝 更新|XVertNet: Unsupervised Contrast Enhancement of Vertebral Structures with Dynamic Self-Tuning Guidance and Multi-Stage Analysis|XVertNet：基于动态自调指导与多阶段分析的脊椎结构无监督对比增强|Ella Eidlin, Assaf Hoogi, Hila Rozen, Mohammad Badarne, Nathan S. Netanyahu|<http://arxiv.org/pdf/2306.03983v3>|提出XVertNet，通过无监督学习和动态自调机制增强X光片中脊椎结构可视化，提高诊断准确性。|
|📝 更新|Shadow Erosion and Nighttime Adaptability for Camera-Based Automated Driving Applications|阴影侵蚀与夜间适应性研究：面向基于摄像头的自动驾驶应用|Mohamed Sabry, Gregory Schroeder, Joshua Varughese, Cristina Olaverri-Monreal|<http://arxiv.org/pdf/2504.08551v2>|提出了一种图像处理新方法，通过阴影侵蚀和夜间适应性增强，显著提升了自动驾驶中图像质量和夜间驾驶性能。|
|🆕 发布|Explaining What Machines See: XAI Strategies in Deep Object Detection Models|《解释机器所见：深度目标检测模型中的可解释性人工智能策略》|FatemehSadat Seyedmomeni, Mohammad Ali Keyvanrad|<http://arxiv.org/pdf/2509.01991v1>|系统分析了深度目标检测模型的可解释性方法，助力提升AI决策的透明度和可信度。|
|📝 更新|Demographic-aware fine-grained classification of pediatric wrist fractures|人口统计信息感知的儿科手腕骨折细粒度分类|Ammar Ahmed, Ali Shariq Imran, Zenun Kastrati, Sher Muhammad Daudpota|<http://arxiv.org/pdf/2507.12964v4>|提出了一种结合患者信息和细粒度识别的骨折诊断方法，提高了诊断准确率。|
|📝 更新|Pathology-Aware Adaptive Watermarking for Text-Driven Medical Image Synthesis|病理感知自适应水印技术用于基于文本驱动的医学图像合成|Chanyoung Kim, Dayun Ju, Jinyeong Kim, Woojung Han, Roberto Alcover-Couso, Seong Jae Hwang|<http://arxiv.org/pdf/2503.08346v2>|提出MedSign框架，通过自适应调整水印强度保护医疗图像诊断完整性，同时确保水印 robustne...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RS-OOD: A Vision-Language Augmented Framework for Out-of-Distribution Detection in Remote Sensing|遥感中的异常检测：一种视觉-语言增强框架RS-OOD|Yingrui Ji, Jiansheng Chen, Jingbo Chen, Anzhi Yue, Chenhao Wang, Kai Li, Yao Zhu|<http://arxiv.org/pdf/2509.02273v1>|提出RS-OOD框架，利用视觉语言模型实现遥感图像的少样本异常检测。|
|📝 更新|Vehicle-to-Everything Cooperative Perception for Autonomous Driving|车辆与万物协同感知的自动驾驶技术|Tao Huang, Jianan Liu, Xi Zhou, Dinh C. Nguyen, Mostafa Rahimi Azghadi, Yuxuan Xia, Qing-Long Han, Sumei Sun|<http://arxiv.org/pdf/2310.03525v5>|提出全面调研车辆万物协同感知技术，增强自动驾驶的安全与效率。|
|📝 更新|TNet: Terrace Convolutional Decoder Network for Remote Sensing Image Semantic Segmentation|TNet：用于遥感图像语义分割的梯形卷积解码网络|Chengqian Dai, Yonghong Guo, Hongzhao Xiang, Yigui Luo|<http://arxiv.org/pdf/2508.04061v2>|提出了一种新的远程传感图像语义分割网络TNet，通过逐步融合不同分辨率下的特征，有效结合全局和局部信...|
|🆕 发布|RSCC: A Large-Scale Remote Sensing Change Caption Dataset for Disaster Events|遥感变化标注数据集：面向灾害事件的大规模遥感变化标注数据集|Zhenyuan Chen, Chenxi Wang, Ningyu Zhang, Feng Zhang|<http://arxiv.org/pdf/2509.01907v1>|[代码](https://github.com/Bili-Sakura/RSCC.); 构建了大规模遥感变化标注数据集RSCC，助力灾难监测的时序图像理解和分析。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Vision without Images: End-to-End Computer Vision from Single Compressive Measurements|无需图像的视觉：从单一压缩测量到端到端的计算机视觉|Fengpu Pan, Heting Gao, Jiangtao Wen, Yuxing Han|<http://arxiv.org/pdf/2501.15122v3>|提出了一种基于小型伪随机二值掩码的压缩感知框架，通过压缩去噪自动编码器直接从噪声压缩数据完成视觉任务...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Interpretable Geo-localization: a Concept-Aware Global Image-GPS Alignment Framework|面向可解释地理定位：一个概念感知的全局图像-GPS对齐框架|Furong Jia, Lanxin Liu, Ce Hou, Fan Zhang, Xinyan Liu, Yu Liu|<http://arxiv.org/pdf/2509.01910v1>|提出首个将概念感知性引入地理定位的框架，通过地理概念银行增强模型解释性和定位精度。|
|📝 更新|Multi-Agent System for Comprehensive Soccer Understanding|多智能体系统用于全面理解足球|Jiayuan Rao, Zifeng Li, Haoning Wu, Ya Zhang, Yanfeng Wang, Weidi Xie|<http://arxiv.org/pdf/2505.03735v2>|提出全面框架实现足球理解的multi-agent系统，构建知识库和大规模基准测试，提升问题解答能力。|
|🆕 发布|Enabling Federated Object Detection for Connected Autonomous Vehicles: A Deployment-Oriented Evaluation|面向连接自动驾驶车辆的联邦目标检测：一种部署导向的评价方法|Komala Subramanyam Cherukuri, Kewei Sha, Zhenhua Huang|<http://arxiv.org/pdf/2509.01868v1>|首次全面评估了面向部署的联邦学习在自动驾驶车辆对象检测中的应用，优化了性能与资源使用的平衡。|

