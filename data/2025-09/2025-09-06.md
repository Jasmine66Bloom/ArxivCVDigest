## [UPDATED!] **2025-09-06** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HumaniBench: A Human-Centric Framework for Large Multimodal Models Evaluation|《HumaniBench：一种面向大型多模态模型评估的人本中心框架》|Shaina Raza, Aravind Narayanan, Vahid Reza Khazaie, Ashmal Vayani, Mukund S. Chettiar, Amandeep Singh, Mubarak Shah, Deval Pandya|<http://arxiv.org/pdf/2505.11454v4>|提出HumaniBench基准，评估大型多模态模型在公平性、伦理等人类中心价值方面的表现。|
|📝 更新|ShapeSplat: A Large-scale Dataset of Gaussian Splats and Their Self-Supervised Pretraining|形状泼洒：高斯泼洒及其自监督预训练的大规模数据集|Qi Ma, Yue Li, Bin Ren, Nicu Sebe, Ender Konukoglu, Theo Gevers, Luc Van Gool, Danda Pani Paudel|<http://arxiv.org/pdf/2408.10906v2>|构建大规模ShapeSplat数据集，引入Gaussian-MAE方法，提升3D表示学习的分类与分割...|
|📝 更新|ER-LoRA: Effective-Rank Guided Adaptation for Weather-Generalized Depth Estimation|ER-LoRA：有效秩引导的适应方法用于天气泛化的深度估计|Weilong Yan, Xin Zhang, Robby T. Tan|<http://arxiv.org/pdf/2509.00665v2>|提出了一种基于有效秩指导的参数高效微调策略，实现了在各种天气条件下有效的深度估计。|
|🆕 发布|ProfilingAgent: Profiling-Guided Agentic Reasoning for Adaptive Model Optimization|ProfilingAgent：基于分析引导的代理推理以实现自适应模型优化|Sadegh Jafari, Aishwarya Sarkar, Mohiuddin Bilwal, Ali Jannesari|<http://arxiv.org/pdf/2509.05584v1>|提出了一种基于大型语言模型自动化压缩的ProfilingAgent方法，针对不同架构优化模型性能和资...|
|📝 更新|Efficient Alignment of Unconditioned Action Prior for Language-conditioned Pick and Place in Clutter|无先验条件动作对齐在杂乱环境下的语言条件抓取与放置中的高效应用|Kechun Xu, Xunlong Xia, Kaixuan Wang, Yifei Yang, Yunxuan Mao, Bing Deng, Jieping Ye, Rong Xiong .etc.|<http://arxiv.org/pdf/2503.09423v3>|[代码](https://xukechun.github.io/papers); 提出了一种整合视觉、语言和动作先验的A^2方法，有效提升了机器人执行语言指令下的拾取和放置任务的成功...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Dita: Scaling Diffusion Transformer for Generalist Vision-Language-Action Policy|"Dita: 针对通用视觉-语言-动作策略的扩散变换器扩展"|Zhi Hou, Tianyi Zhang, Yuwen Xiong, Haonan Duan, Hengjun Pu, Ronglei Tong, Chengyang Zhao, Xizhou Zhu .etc.|<http://arxiv.org/pdf/2503.19757v2>|提出了一种可扩展的框架Dita，利用Transformer架构直接通过统一的多模态扩散过程去噪连续动...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Unsupervised cell segmentation by fast Gaussian Processes|无监督细胞分割：基于快速高斯过程的方法|Laura Baracaldo, Blythe King, Haoran Yan, Yizi Lin, Nina Miolane, Mengyang Gu|<http://arxiv.org/pdf/2505.18902v2>|提出了一种无需参数调整和形状假设的无监督细胞分割算法，通过自适应阈值和流域分割处理噪声显微图像。|
|🆕 发布|MeshMetrics: A Precise Implementation of Distance-Based Image Segmentation Metrics|《网格度量：基于距离的图像分割度量的精确实现》|Gašper Podobnik, Tomaž Vrtovec|<http://arxiv.org/pdf/2509.05670v1>|[代码](https://github.com/gasperpodobnik/MeshMetrics.); 提出了一种基于网格的MeshMetrics框架，提高了距离基础图像分割度量的精度和可靠性。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Brain Tumor Detection Through Diverse CNN Architectures in IoT Healthcare Industries: Fast R-CNN, U-Net, Transfer Learning-Based CNN, and Fully Connected CNN|通过物联网医疗行业中的多种卷积神经网络架构进行脑肿瘤检测：快速R-CNN、U-Net、基于迁移学习的CNN和全连接CNN|Mohsen Asghari Ilani, Yaser M. Banad|<http://arxiv.org/pdf/2509.05821v1>|探究物联网医疗系统中脑肿瘤检测，融合多种CNN架构提升诊断准确性和效率。|
|🆕 发布|3DPillars: Pillar-based two-stage 3D object detection|基于柱状结构的两阶段三维物体检测方法：3DPillars|Jongyoun Noh, Junghyup Lee, Hyekang Park, Bumsub Ham|<http://arxiv.org/pdf/2509.05780v1>|提出了一种基于伪图像表示的两阶段3D物体检测框架3DPillars，通过分离的体素特征模块和稀疏场景...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unleashing Hierarchical Reasoning: An LLM-Driven Framework for Training-Free Referring Video Object Segmentation|释放层级推理：一种基于大型语言模型的无训练指引用视频对象分割框架|Bingrui Zhao, Lin Yuanbo Wu, Xiangtian Fan, Deyin Liu, Lu Zhang, Ruyi He, Jialie Shen, Ximing Li|<http://arxiv.org/pdf/2509.05751v1>|提出了一种无需训练、基于大型语言模型的分层推理框架PARSE-VOS，实现了对视频中的目标对象进行精...|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Diffusion-Based Image-to-Brain Signal Generation with Cross-Attention Mechanisms for Visual Prostheses|基于扩散的图像到大脑信号生成方法：用于视觉假体的交叉注意力机制|Ganxi Xu, Jinyi Long, Jia Zhang|<http://arxiv.org/pdf/2509.00787v2>|提出首个基于去噪扩散模型和交叉注意力机制的图像到脑信号生成框架，用于视觉假体的脑编码阶段。|
|📝 更新|4D Visual Pre-training for Robot Learning|机器人学习的4D视觉预训练|Chengkai Hou, Yanjie Ze, Yankai Fu, Zeyu Gao, Songbo Hu, Yue Yu, Shanghang Zhang, Huazhe Xu|<http://arxiv.org/pdf/2508.17230v2>|提出4D视觉预训练框架，通过预测下一个点云提升机器人操作成功率，实现模仿学习最佳性能。|
|🆕 发布|SuMa: A Subspace Mapping Approach for Robust and Effective Concept Erasure in Text-to-Image Diffusion Models|SuMa：一种用于文本到图像扩散模型中鲁棒且有效的概念擦除的子空间映射方法|Kien Nguyen, Anh Tran, Cuong Pham|<http://arxiv.org/pdf/2509.05625v1>|提出了一种名为Subspace Mapping的方法，有效解决了细粒度概念擦除中的鲁棒性和图像质量问...|
|📝 更新|PractiLight: Practical Light Control Using Foundational Diffusion Models|PractiLight：基于基础扩散模型的实用光照控制|Yotam Erel, Rishabh Dabral, Vladislav Golyanik, Amit H. Bermano, Christian Theobalt|<http://arxiv.org/pdf/2509.01837v2>|提出了一种利用生成模型基础理解进行高效灯光控制的PractiLight方法，实现了一般化和参数效率的...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SemLayoutDiff: Semantic Layout Generation with Diffusion Model for Indoor Scene Synthesis|语义布局差异：基于扩散模型的室内场景合成语义布局生成|Xiaohao Sun, Divyam Goel, Angel X. Chang|<http://arxiv.org/pdf/2508.18597v2>|提出了一种结合扩散模型和语义图的室内场景合成方法，实现了在建筑约束下的多样化三维室内场景生成。|
|🆕 发布|CRAB: Camera-Radar Fusion for Reducing Depth Ambiguity in Backward Projection based View Transformation|CRAB：基于向后投影视图变换的摄像头-雷达融合减少深度模糊|In-Jae Lee, Sihwan Hwang, Youngseok Kim, Wonjune Kim, Sanmin Kim, Dongsuk Kum|<http://arxiv.org/pdf/2509.05785v1>|提出CRAB模型，通过融合雷达与相机数据减少向后投影中的深度模糊问题，提升3D物体检测准确性。|
|🆕 发布|Depth-Aware Super-Resolution via Distance-Adaptive Variational Formulation|基于距离自适应变分公式的深度感知超分辨率|Tianhao Guo, Bingjie Lu, Feng Wang, Zhengyang Lu|<http://arxiv.org/pdf/2509.05746v1>|提出了一种深度感知的超级分辨率方法，通过距离自适应的变分框架显著提升了深度变化场景的重建性能。|
|📝 更新|Diagram-Driven Course Questions Generation|图驱动的课程问题生成|Xinyu Zhang, Lingling Zhang, Yanrui Wu, Muye Huang, Wenjun Wu, Bo Li, Shaowei Wang, Basura Fernando .etc.|<http://arxiv.org/pdf/2411.17771v5>|提出 Diagram-Driven Course Questions Generation 任务，并...|
|🆕 发布|Towards Meta-Cognitive Knowledge Editing for Multimodal LLMs|面向多模态大型语言模型的元认知知识编辑|Zhaoyu Fan, Kaihang Pan, Mingze Zhou, Bosheng Qin, Juncheng Li, Shengyu Zhang, Wenqiao Zhang, Siliang Tang .etc.|<http://arxiv.org/pdf/2509.05714v1>|提出CogEdit基准和MIND框架，提升多模态大语言模型在元认知层面的知识编辑能力。|
|🆕 发布|EditIDv2: Editable ID Customization with Data-Lubricated ID Feature Integration for Text-to-Image Generation|编辑IDv2：基于数据润滑的ID特征融合实现文本到图像生成的可编辑ID定制化|Guandong Li, Zhaobin Chu|<http://arxiv.org/pdf/2509.05659v1>|EditIDv2通过少量数据增强，实现了复杂场景长文本输入下的身份一致性与深度多级语义编辑。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Tell-Tale Watermarks for Explanatory Reasoning in Synthetic Media Forensics|《用于合成媒体取证解释性推理的暗示性水印》|Ching-Chun Chang, Isao Echizen|<http://arxiv.org/pdf/2509.05753v1>|提出了一种可解释的水印系统，用于追踪合成媒体生成链并揭示其变换过程。|
|📝 更新|VSI: Visual Subtitle Integration for Keyframe Selection to enhance Long Video Understanding|视觉字幕集成：用于关键帧选择以增强长视频理解的VSI方法|Jianxiang He, Meisheng Hong, Jungang Li, Yijie Xu, Ziyang Chen, Weiyu Guo, Hui Xiong|<http://arxiv.org/pdf/2508.06869v2>|提出了一种融合字幕、时间戳和场景边界的多模态关键帧搜索方法VSI，有效提升了长视频理解和视频问答任务...|
|🆕 发布|Language-guided Recursive Spatiotemporal Graph Modeling for Video Summarization|基于语言指导的递归时空图建模视频摘要方法|Jungin Park, Jiyoung Lee, Kwanghoon Sohn|<http://arxiv.org/pdf/2509.05604v1>|[代码](https://github.com/park-jungin/videograph.); 提出语言引导的递归时空图模型，通过结合视觉与语义信息优化视频摘要选择关键帧。|
|🆕 发布|MFFI: Multi-Dimensional Face Forgery Image Dataset for Real-World Scenarios|多维度人脸伪造图像数据集：面向现实场景的MFFI|Changtao Miao, Yi Zhang, Man Luo, Weiwei Feng, Kaiyuan Zheng, Qi Chu, Tao Gong, Jianshu Li .etc.|<http://arxiv.org/pdf/2509.05592v1>|[代码](https://github.com/inclusionConf/MFFI); 提出了MFFI数据集，通过涵盖多种伪造技术、面部场景、真实数据多样性及不同退化级别，有效提升了对现实...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|JRN-Geo: A Joint Perception Network based on RGB and Normal images for Cross-view Geo-localization|基于RGB和法线图像的联合感知网络JRN-Geo：用于跨视角地理定位|Hongyu Zhou, Yunzhou Zhang, Tingsong Huang, Fawei Ge, Man Qi, Xichen Zhang, Yizhong Zhang|<http://arxiv.org/pdf/2509.05696v1>|融合RGB与法线图像信息，提出JRN-Geo网络，有效应对视角差异挑战，实现交叉视角地理定位。|
|🆕 发布|Context-Aware Multi-Turn Visual-Textual Reasoning in LVLMs via Dynamic Memory and Adaptive Visual Guidance|通过动态内存和自适应视觉引导在LVLM中进行上下文感知的多轮视觉-文本推理|Weijie Shen, Xinrui Wang, Yuanqi Nie, Apiradee Boonmee|<http://arxiv.org/pdf/2509.05669v1>|提出了一种增强大型视觉语言模型的多轮视觉文本推理能力的方法，通过动态记忆和自适应视觉引导保持上下文连...|
|🆕 发布|Stereovision Image Processing for Planetary Navigation Maps with Semi-Global Matching and Superpixel Segmentation|行星导航地图的立体视觉图像处理：半全局匹配与超像素分割|Yan-Shan Lu, Miguel Arana-Catania, Saurabh Upadhyay, Leonard Felicetti|<http://arxiv.org/pdf/2509.05645v1>|提出了一种结合半全局匹配和超像素分割的立体视觉方法，提高了火星地形图的精度和一致性，优化了自主导航的...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LiDAR-BIND-T: Improving SLAM with Temporally Consistent Cross-Modal LiDAR Reconstruction|激光雷达绑定T：通过时间一致性的跨模态激光雷达重建改进SLAM|Niels Balemans, Ali Anwar, Jan Steckel, Siegfried Mercelis|<http://arxiv.org/pdf/2509.05728v1>|通过引入时间一致性机制，改进了多模态融合框架，提升了SLAM的时空一致性和准确性。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-LVI-SAM: A Robust LiDAR-Visual-Inertial Odometry for Multiple Fisheye Cameras|多视角鱼眼相机稳健的激光雷达-视觉-惯性里程计：Multi-LVI-SAM|Xinyu Zhang, Kai Huang, Junqiao Zhao, Zihan Yuan, Tiantian Feng|<http://arxiv.org/pdf/2509.05740v1>|提出了一种融合多鱼眼相机、LiDAR和惯性传感器的全景视觉特征模型，提高了多相机LiDAR-视觉-惯...|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RED: Robust Event-Guided Motion Deblurring with Modality-Specific Disentangled Representation|RED：基于模态特定解耦表示的鲁棒事件引导运动去模糊|Yihong Leng, Siming Zheng, Jinwei Chen, Bo Li, Jiaojiao Li, Peng-Tao Jiang|<http://arxiv.org/pdf/2509.05554v1>|提出了一种RED网络，通过模态特定解耦表示增强事件相机运动去模糊的鲁棒性。|


## 时序视觉分析 (Temporal Visual Analysis)


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Leveraging Vision-Language Large Models for Interpretable Video Action Recognition with Semantic Tokenization|利用视觉-语言大型模型进行语义标记的可解释视频动作识别|Jingwei Peng, Zhixuan Qiu, Boyu Jin, Surasakdi Siripong|<http://arxiv.org/pdf/2509.05695v1>|提出利用预训练的视觉语言大模型进行视频动作识别，通过将视频转化为语义动作标记，实现了高准确性和可解释...|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OOTSM: A Decoupled Linguistic Framework for Effective Scene Graph Anticipation|OOTSM：一种用于有效场景图预测的解耦语言框架|Xiaomeng Zhu, Changwei Wang, Haozhe Wang, Xinyu Liu, Fangzhen Lin|<http://arxiv.org/pdf/2509.05661v1>|[代码](https://github.com/ZhuXMMM/OOTSM.); 提出OOTSM方法，通过分离视觉捕捉和文本预测步骤，有效利用常识知识提升场景图预测准确性。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Patch-level Kernel Alignment for Self-Supervised Dense Representation Learning|patch-level 核对齐用于自监督密集表示学习|Juan Yeo, Ijun Jang, Taesup Kim|<http://arxiv.org/pdf/2509.05606v1>|提出了一种通过 patch-level kernel alignment 进行自监督学习的框架，有效...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Exploring the Landscape of Non-Equilibrium Memories with Neural Cellular Automata|探索神经网络细胞自动机中的非平衡记忆景观|Ehsan Pajouheshgar, Aditya Bhardwaj, Nathaniel Selub, Ethan Lake|<http://arxiv.org/pdf/2508.15726v2>|[代码](https://memorynca.github.io/2D.); 揭示了二维空间中非平衡记忆的多样性，通过严格证明和机器学习发现了新的记忆模式。|
|🆕 发布|Knowledge-Augmented Vision Language Models for Underwater Bioacoustic Spectrogram Analysis|知识增强的视觉语言模型用于水下生物声谱图分析|Ragib Amin Nihal, Benjamin Yen, Takeshi Ashizawa, Kazuhiro Nakadai|<http://arxiv.org/pdf/2509.05703v1>|提出了一种结合视觉语言模型和语言模型的知识增强方法，实现了无需人工标注或模型重训练的水下生物声谱图分...|
|📝 更新|A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence|模式分析与机器智能领域文献综述的文献综述|Penghai Zhao, Xin Zhang, Jiayue Cao, Ming-Ming Cheng, Jian Yang, Xiang Li|<http://arxiv.org/pdf/2402.12928v6>|系统分析了模式分析与机器智能领域的文献综述，提出导航策略并评估了AI生成综述的发展前景。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Motion-enhanced Cardiac Anatomy Segmentation via an Insertable Temporal Attention Module|通过可插入时间注意力模块增强的心脏解剖结构分割|Md. Kamrul Hasan, Guang Yang, Choon Hwai Yap|<http://arxiv.org/pdf/2501.14929v2>|提出了一种轻量级时间注意力模块，有效增强运动信息用于心脏解剖结构分割，易于集成至多种网络结构中。|
|🆕 发布|Posterior shape models revisited: Improving 3D reconstructions from partial data using target specific models|后验形状模型再探：利用特定目标模型改善基于部分数据的3D重建|Jonathan Aellen, Florian Burkhardt, Thomas Vetter, Marcel Lüthi|<http://arxiv.org/pdf/2509.05776v1>|提出了一种针对姿态差异的调整方法，显著提高了部分数据三维重建的准确性和预测方差。|
|🆕 发布|InterAct: A Large-Scale Dataset of Dynamic, Expressive and Interactive Activities between Two People in Daily Scenarios|《InterAct：一个大规模的日常场景中两人之间动态、表情丰富、互动活动的数据集》|Leo Ho, Yinghao Huang, Dafei Qin, Mingyi Shi, Wangpok Tse, Wei Liu, Junichi Yamagishi, Taku Komura|<http://arxiv.org/pdf/2509.05747v1>|[代码](https://hku-cg.github.io/interact); 提出了一种新方法捕捉两人互动行为，创建了包含动态表情和动作的InterAct数据集，并实现了基于语音...|
|🆕 发布|SpecPrune-VLA: Accelerating Vision-Language-Action Models via Action-Aware Self-Speculative Pruning|SpecPrune-VLA：通过动作感知自 speculative 裁剪加速视觉-语言-动作模型|Hanzhen Wang, Jiaming Xu, Jiayi Pan, Yongkang Zhou, Guohao Dai|<http://arxiv.org/pdf/2509.05614v1>|提出利用动作感知的自 speculative 裁剪技术加速视觉语言动作模型，通过结合局部和全局信息实...|
|🆕 发布|Sensitivity-Aware Post-Training Quantization for Deep Neural Networks|深度神经网络敏感性感知的后训练量化方法|Zekang Zheng, Haokun Li, Yaofo Chen, Mingkui Tan, Qing Du|<http://arxiv.org/pdf/2509.05576v1>|提出了一种敏感度感知的后训练量化方法，通过优先量化敏感度低的参数，实现了高压缩比下的准确度保持。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|WIPUNet: A Physics-inspired Network with Weighted Inductive Biases for Image Denoising|WIPUNet：一种具有加权归纳偏置的物理启发图像去噪网络|Wasikul Islam|<http://arxiv.org/pdf/2509.05662v1>|提出基于物理启发原理的WIPUNet，通过内置加权归纳偏置提升图像去噪在强干扰下的鲁棒性。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Reconstruction and Reenactment Separated Method for Realistic Gaussian Head|高斯头像的重建与再现分离方法|Zhiling Ye, Cong Zhou, Xiubao Zhang, Haifeng Shen, Weihong Deng, Quan Lu|<http://arxiv.org/pdf/2509.05582v1>|提出了一种分离的重构与再现框架，仅用单张人像生成可控3D头像，实现了高效渲染和性能提升。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Performance of Conformal Prediction in Capturing Aleatoric Uncertainty|《共形预测在捕捉偶然不确定性的性能表现》|Misgina Tsighe Hagos, Claes Lundström|<http://arxiv.org/pdf/2509.05826v1>|研究表明，基于模型的预测集大小在量化由类重叠引起的固有模糊性方面效果有限。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Making Rotation Averaging Fast and Robust with Anisotropic Coordinate Descent|利用各向异性坐标下降法加速并增强旋转平均的鲁棒性|Yaroslava Lochman, Carl Olsson, Christopher Zach|<http://arxiv.org/pdf/2506.01940v2>|[代码](https://ylochman.github.io/acd); 提出了一种高效的各向异性旋转平均算法，平衡了最优化、鲁棒性和效率，实现了结构从运动数据集上的最佳性能...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AIM: Adaptive Intra-Network Modulation for Balanced Multimodal Learning|自适应内部网络调制：平衡多模态学习的策略|Shu Shen, C. L. Philip Chen, Tong Zhang|<http://arxiv.org/pdf/2508.19769v2>|提出AIM方法，平衡多模态学习中的优化偏差，首次实现不抑制任一模态的均衡学习。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PictOBI-20k: Unveiling Large Multimodal Models in Visual Decipherment for Pictographic Oracle Bone Characters|PictOBI-20k：揭示用于图形甲骨文视觉解读的大型多模态模型|Zijian Chen, Wenjie Hua, Jinhao Li, Lirong Deng, Fan Du, Tingzhu Chen, Guangtao Zhai|<http://arxiv.org/pdf/2509.05773v1>|[代码](https://github.com/OBI-Future/PictOBI-20k.); 提出PictOBI-20k数据集，利用大型多模态模型初步实现甲骨文视觉解读能力。|
|📝 更新|Parameter-Efficient Adaptation of mPLUG-Owl2 via Pixel-Level Visual Prompts for NR-IQA|通过像素级视觉提示对mPLUG-Owl2进行参数高效适配以实现无参考图像质量评估|Yahya Benmahane, Mohammed El Hassouni|<http://arxiv.org/pdf/2509.03494v2>|提出了一种使用像素级视觉提示的低参量适应方法，有效提升无参考图像质量评估性能。|
|📝 更新|Osprey: Pixel Understanding with Visual Instruction Tuning|“Osprey：通过视觉指令微调实现像素级理解”|Yuqian Yuan, Wentong Li, Jian Liu, Dongqi Tang, Xinjie Luo, Chi Qin, Lei Zhang, Jianke Zhu|<http://arxiv.org/pdf/2312.10032v4>|[代码](https://github.com/CircleRadon/Osprey.); 提出Osprey方法，通过将细粒度遮罩区域融入语言指令，实现像素级视觉理解。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dual-Mode Deep Anomaly Detection for Medical Manufacturing: Structural Similarity and Feature Distance|双模态深度异常检测在医疗制造中的应用：结构相似性与特征距离|Julio Zanon Diaz, Georgios Siogkas, Peter Corcoran|<http://arxiv.org/pdf/2509.05796v1>|提出双模态深度异常检测方法，结合结构相似性和特征距离，提升医疗设备制造中的视觉检测准确性和效率。|
|🆕 发布|A Probabilistic Segment Anything Model for Ambiguity-Aware Medical Image Segmentation|用于模糊感知医学图像分割的概率性Segment Anything模型|Tyler Ward, Abdullah Imran|<http://arxiv.org/pdf/2509.05809v1>|[代码](https://github.com/tbwa233/Probabilistic-SAM); 提出概率化Segment Anything模型，处理医学影像分割中的不确定性，生成多样化且合理的分割...|
|📝 更新|Hessian-Based Lightweight Neural Network HessNet for State-of-the-Art Brain Vessel Segmentation on a Minimal Training Dataset|基于Hessian矩阵的轻量级神经网络HessNet：在极小训练数据集上实现脑血管分割的最新技术水平|Alexandra Bernadotte, Elfimov Nikita, Mikhail Shutov, Ivan Menshikov|<http://arxiv.org/pdf/2508.15660v3>|提出基于Hessian矩阵的轻量级神经网络HessNet，实现少量数据下脑血管精准分割。|
|🆕 发布|Self-supervised Learning for Hyperspectral Images of Trees|树木高光谱图像的自监督学习|Moqsadur Rahman, Saurav Kumar, Santosh S. Palmate, M. Shahriar Hossain|<http://arxiv.org/pdf/2509.05630v1>|利用自监督学习从航拍高光谱图像中提取树木植被特性，有效提升了无标签数据的机器学习任务表现。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Evaluating YOLO Architectures: Implications for Real-Time Vehicle Detection in Urban Environments of Bangladesh|评估YOLO架构：孟加拉国城市环境中实时车辆检测的影响|Ha Meem Hossain, Pritam Nath, Mahitun Nesa Mahi, Imtiaz Uddin, Ishrat Jahan Eiste, Syed Nasibur Rahman Ratul, Md Naim Uddin Mozumdar, Asif Mohammed Saad|<http://arxiv.org/pdf/2509.05652v1>|评估了六种YOLO模型在孟加拉国定制数据集上的表现，为开发地区车辆检测提供了适应本地环境的解决方案。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Pushing Trade-Off Boundaries: Compact yet Effective Remote Sensing Change Detection|推动权衡边界：紧凑而有效的遥感变化检测|Luosheng Xu, Dalin Zhang, Zhaohui Song|<http://arxiv.org/pdf/2506.21109v2>|[代码](https://github.com/xulsh8/FlickCD.); 提出轻量级模型FlickCD，通过增强差异模块和融合块优化遥感变化检测，实现资源消耗降低与性能提升。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VisBias: Measuring Explicit and Implicit Social Biases in Vision Language Models|《VisBias：在视觉语言模型中测量显性和隐性社会偏见》|Jen-tse Huang, Jiantong Qin, Jianping Zhang, Youliang Yuan, Wenxuan Wang, Jieyu Zhao|<http://arxiv.org/pdf/2503.07575v3>|[代码](https://github.com/uscnlp-lime/VisBias.); 提出了一种测量视觉语言模型中显性和隐性社会偏见的方法，通过设计针对性的任务揭示了模型在不同人群描述中...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AI Sees Your Location, But With A Bias Toward The Wealthy World|人工智能能识别你的位置，但倾向于偏向富裕世界|Jingyuan Huang, Jen-tse Huang, Ziyi Liu, Xiaoyuan Liu, Wenxuan Wang, Jieyu Zhao|<http://arxiv.org/pdf/2502.11163v3>|[代码](https://github.com/uscnlp-lime/FairLocator.); 揭示了视觉语言模型在地理信息识别中的区域偏见，并提出了用于评估这些偏见的基准数据集。|

