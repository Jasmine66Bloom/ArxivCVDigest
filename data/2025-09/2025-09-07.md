## [UPDATED!] **2025-09-07** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|O$^3$Afford: One-Shot 3D Object-to-Object Affordance Grounding for Generalizable Robotic Manipulation|单次三维物体到物体功效性定位：面向泛化机器人操作|Tongxuan Tian, Xuhui Kang, Yen-Ling Kuo|<http://arxiv.org/pdf/2509.06233v1>|提出了一种基于少量数据的一键3D对象间功效性学习策略，有效提升了机器人操作的泛化能力。|
|🆕 发布|MedSeqFT: Sequential Fine-tuning Foundation Models for 3D Medical Image Segmentation|MedSeqFT：三维医学图像分割的序列微调基础模型|Yiwen Ye, Yicheng Wu, Xiangde Luo, He Zhang, Ziyang Chen, Ting Dang, Yanning Zhang, Yong Xia|<http://arxiv.org/pdf/2509.06096v1>|提出MedSeqFT框架，顺序微调预训练模型以适应新任务，同时保留原有知识，提升3D医疗图像分割性能...|
|🆕 发布|Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge|多模态推理用于科学：技术报告及2025年ICML SeePhys挑战赛一等奖解决方案|Hao Liang, Ruitao Wu, Bohan Zeng, Junbo Niu, Wentao Zhang, Bin Dong|<http://arxiv.org/pdf/2509.06079v1>|[代码](https://github.com/OpenDCAI/SciReasoner.); 提出了一种融合视觉与文本的推理框架，有效提升了多模态场景下的性能并赢得国际竞赛。|
|📝 更新|LMM4Edit: Benchmarking and Evaluating Multimodal Image Editing with LMMs|LMM4Edit：基于LMM的多模态图像编辑基准测试与评估|Zitong Xu, Huiyu Duan, Bingnan Liu, Guangji Ma, Jiarui Wang, Liu Yang, Shiqi Gao, Xiaoyu Wang .etc.|<http://arxiv.org/pdf/2507.16193v2>|[代码](https://github.com/IntMeGroup/LMM4Edit.); 提出EBench-18K大规模图像编辑基准，提出LMM4Edit指标全面评估图像编辑质量与人类偏好一...|
|🆕 发布|Compression Beyond Pixels: Semantic Compression with Multimodal Foundation Models|像素之外的压缩：基于多模态基础模型的语义压缩|Ruiqi Shen, Haotian Wu, Wenjing Zhang, Jiangjing Hu, Deniz Gunduz|<http://arxiv.org/pdf/2509.05925v1>|提出了一种基于CLIP模型的语义压缩方法，实现了极低比特率下的语义信息保持。|
|🆕 发布|A Fine-Grained Attention and Geometric Correspondence Model for Musculoskeletal Risk Classification in Athletes Using Multimodal Visual and Skeletal Features|用于运动员肌肉骨骼风险分类的多模态视觉与骨骼特征精细化注意力与几何对应模型|Md. Abdur Rahman, Mohaimenul Azam Khan Raiaan, Tamanna Shermin, Md Rafiqul Islam, Mukhtar Hussain, Sami Azam|<http://arxiv.org/pdf/2509.05913v1>|提出了一种结合视觉和骨骼特征的多模态深度学习框架ViSK-GAT，用于精确评估运动员的肌肉骨骼风险。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|S-LAM3D: Segmentation-Guided Monocular 3D Object Detection via Feature Space Fusion|基于分割引导的单目3D目标检测：通过特征空间融合的S-LAM3D方法|Diana-Alexandra Sas, Florin Oniga|<http://arxiv.org/pdf/2509.05999v1>|引入预计算分割信息直接融合特征空间，提升单目3D物体检测准确性。|
|🆕 发布|Challenges in Deep Learning-Based Small Organ Segmentation: A Benchmarking Perspective for Medical Research with Limited Datasets|深度学习在小器官分割中的挑战：面向数据集有限的医学研究的基准视角|Phongsakon Mark Konrad, Andrei-Alexandru Popa, Yaser Sabzehmeidani, Liang Zhong, Elisa A. Liehn, Serkan Ayvaz|<http://arxiv.org/pdf/2509.05892v1>|揭示了在有限数据集下，深度学习模型性能对数据划分高度敏感，挑战了传统基准测试在低数据临床场景的有效性...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Imagining Alternatives: Towards High-Resolution 3D Counterfactual Medical Image Generation via Language Guidance|想象替代方案：通过语言引导实现高分辨率三维反事实医学图像生成|Mohamed Mohamed, Brennan Nichyporuk, Douglas L. Arnold, Tal Arbel|<http://arxiv.org/pdf/2509.05978v1>|提出了一种语言引导的高分辨率3D医疗影像生成框架，实现了基于自然语言描述的医学反事实图像生成。|
|📝 更新|Leveraging Out-of-Distribution Unlabeled Images: Semi-Supervised Semantic Segmentation with an Open-Vocabulary Model|利用分布外未标记图像：基于开放词汇模型的半监督语义分割|Wooseok Shin, Jisu Kang, Hyeonki Jeong, Jin Sob Kim, Sung Won Han|<http://arxiv.org/pdf/2507.03302v2>|[代码](https://github.com/wooseok-shin/SemiOVS); 提出了一种利用开放词汇模型进行半监督语义分割的方法，有效利用了分布外的大量未标注图像。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Exploring Light-Weight Object Recognition for Real-Time Document Detection|探索轻量级物体识别在实时文档检测中的应用|Lucas Wojcik, Luiz Coelho, Roger Granada, David Menotti|<http://arxiv.org/pdf/2509.06246v1>|[代码](https://github.com/BOVIFOCR/iwpod-doc-corners.git); 提出了一种轻量级对象识别模型，用于快速检测和矫正文档，实现了高效的实时信息检索。|
|🆕 发布|StripDet: Strip Attention-Based Lightweight 3D Object Detection from Point Cloud|条带注意力基础上的轻量级三维目标检测算法 StripDet：基于点云的数据|Weichao Wang, Wendong Mao, Zhongfeng Wang|<http://arxiv.org/pdf/2509.05954v1>|提出 StripDet，一种基于条带注意力的高效轻量级点云三维物体检测框架，实现了参数减少7倍的优异...|
|🆕 发布|Near Real-Time Dust Aerosol Detection with 3D Convolutional Neural Networks on MODIS Data|基于三维卷积神经网络对MODIS数据的准实时尘埃气溶胶检测|Caleb Gates, Patrick Moorhead, Jayden Ferguson, Omar Darwish, Conner Stallman, Pablo Rivas, Paapa Quansah|<http://arxiv.org/pdf/2509.05887v1>|提出了一种基于3D卷积神经网络的近实时卫星图像尘霾检测系统，实现了高准确度且快速处理。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FASL-Seg: Anatomy and Tool Segmentation of Surgical Scenes|FASL-Seg：手术场景的解剖结构与工具分割|Muraam Abdel-Ghani, Mahmoud Ali, Mohamed Ali, Fatmaelzahraa Ahmed, Mohamed Arsalan, Abdulaziz Al-Ali, Shidin Balakrishnan|<http://arxiv.org/pdf/2509.06159v1>|提出了一种双流特征处理模型FASL-Seg，有效提升了手术场景中解剖结构和工具的精细分割性能。|
|📝 更新|WMKA-Net: A Weighted Multi-Kernel Attention Network for Retinal Vessel Segmentation|WMKA-Net：一种用于视网膜血管分割的加权多核注意力网络|Xinran Xu, Yuliang Ma, Sifu Cai, Ming Meng, Qiang Lv, Ruoyan Shi|<http://arxiv.org/pdf/2504.14888v3>|提出双阶段加权多核注意力网络，有效融合多尺度特征并建模血管连续性，显著提升视网膜血管分割准确性。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CARDIE: clustering algorithm on relevant descriptors for image enhancement|CARDIE：基于相关描述子的图像增强聚类算法|Giulia Bonino, Luca Alberto Rizzo|<http://arxiv.org/pdf/2509.06116v1>|提出CARDIE算法，通过颜色和亮度聚类优化图像增强效果，并改进了性能评估方法。|
|📝 更新|MESTI-MEGANet: Micro-expression Spatio-Temporal Image and Micro-expression Gradient Attention Networks for Micro-expression Recognition|微表情时空图像与微表情梯度注意力网络（MESTI-MEGANet）用于微表情识别|Luu Tu Nguyen, Vu Tram Anh Khuong, Thanh Ha Le, Thi Duyen Ngo|<http://arxiv.org/pdf/2509.00056v2>|提出MESTI动态输入模态和MEGANet网络，提高了微表情识别的准确性和效率。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Efficient and Accurate Pneumonia Detection Using a Novel Multi-Scale Transformer Approach|使用新颖多尺度变换器方法的高效准确肺炎检测|Alireza Saber, Pouria Parhami, Alimohammad Siahkarzadeh, Mansoor Fateh, Amirreza Fateh|<http://arxiv.org/pdf/2408.04290v5>|[代码](https://github.com/amirrezafateh/Multi-Scale-Transformer-Pneumonia); 提出了一种结合多尺度特征提取和轻量级变换器的 pneumonia 检测方法，提高了诊断准确性且计算效...|
|🆕 发布|Motion Aware ViT-based Framework for Monocular 6-DoF Spacecraft Pose Estimation|单目6自由度航天器位姿估计的运动感知ViT基础框架|Jose Sosa, Dan Pineau, Arunkumar Rathinam, Abdelrahman Shabayek, Djamila Aouada|<http://arxiv.org/pdf/2509.06000v1>|提出了一种融合视觉变换器和运动感知技术的单目6自由度航天器位姿估计框架，提升了定位精度和泛化能力。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RetinaGuard: Obfuscating Retinal Age in Fundus Images for Biometric Privacy Preserving|视网膜保护：在眼底图像中混淆视网膜年龄以保护生物识别隐私|Zhengquan Luo, Chi Liu, Dongfu Xiao, Zhen Yu, Yueye Wang, Tianqing Zhu|<http://arxiv.org/pdf/2509.06142v1>|提出了一种新的隐私增强框架RetinaGuard，通过生成对抗遮蔽机制隐藏视网膜年龄，同时保持图像质...|
|🆕 发布|Learning in ImaginationLand: Omnidirectional Policies through 3D Generative Models (OP-Gen)|《在想象之地学习：通过三维生成模型实现全方位策略（OP-Gen）》|Yifei Ren, Edward Johns|<http://arxiv.org/pdf/2509.06191v1>|利用3D生成模型扩展数据集，使机器人能在远离演示的初始状态下完成任务，减少学习所需演示次数。|
|🆕 发布|Home-made Diffusion Model from Scratch to Hatch|从零开始构建 homemade 扩散模型以实现孵化|Shih-Ying Yeh|<http://arxiv.org/pdf/2509.06068v1>|提出Home-made Diffusion Model，通过创新架构和训练策略在低成本硬件上实现高质...|
|🆕 发布|BranchGRPO: Stable and Efficient GRPO with Structured Branching in Diffusion Models|分支GRPO：在扩散模型中具有结构分支的稳定高效GRPO|Yuming Li, Yikai Wang, Yuying Zhu, Zhongyu Zhao, Ming Lu, Qi She, Shanghang Zhang|<http://arxiv.org/pdf/2509.06040v1>|提出BranchGRPO方法，通过分支采样降低计算成本并提升探索多样性，有效解决了图像和视频生成模型...|
|🆕 发布|Multi-Strategy Guided Diffusion via Sparse Masking Temporal Reweighting Distribution Correction|通过稀疏遮罩时间重加权分布校正的多策略引导扩散|Zekun Zhou, Yanru Gong, Liu Shi, Qiegen Liu|<http://arxiv.org/pdf/2509.05992v1>|提出了一种基于稀疏条件概率和时变权重调整的扩散模型，有效提升了稀疏视角CT图像重建的质量。|
|📝 更新|Separate Motion from Appearance: Customizing Motion via Customizing Text-to-Video Diffusion Models|将运动与外观分离：通过定制文本到视频扩散模型定制运动|Huijie Liu, Jingyun Wang, Shuai Ma, Jie Hu, Xiaoming Wei, Guoliang Kang|<http://arxiv.org/pdf/2501.16714v2>|提出方法分离运动与外观，通过优化LoRA和注意力机制，增强视频生成模型对指定运动的表现而不牺牲外观多...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UNO: Unifying One-stage Video Scene Graph Generation via Object-Centric Visual Representation Learning|UNO：通过以对象为中心的视觉表征学习统一一步式视频场景图生成|Huy Le, Nhat Chung, Tung Kieu, Jingkang Yang, Ngan Le|<http://arxiv.org/pdf/2509.06165v1>|提出了一种统一的一阶段视频场景图生成框架UNO，通过对象中心表示学习同时处理粗粒度和细粒度任务，提高...|
|🆕 发布|UniVerse-1: Unified Audio-Video Generation via Stitching of Experts|"UniVerse-1：通过专家拼接实现统一音频-视频生成"|Duomin Wang, Wei Zuo, Aojie Li, Ling-Hao Chen, Xinyao Liao, Deyu Zhou, Zixin Yin, Xili Dai .etc.|<http://arxiv.org/pdf/2509.06155v1>|[代码](https://dorniwang.github.io/UniVerse-1); 提出了一种融合预训练模型和在线标注流程的音频视频生成方法，有效提升了音视频同步质量和训练效率。|
|📝 更新|Kwai Keye-VL 1.5 Technical Report|《Kwai Keye-VL 1.5 技术报告》|Biao Yang, Bin Wen, Boyang Ding, Changyi Liu, Chenglong Chu, Chengru Song, Chongling Rao, Chuan Yi .etc.|<http://arxiv.org/pdf/2509.01563v3>|提出了一种动态计算资源分配的视频理解模型Keye-VL-1.5，通过慢快编码、分阶段预训练和后训练推...|
|🆕 发布|OmniStyle2: Scalable and High Quality Artistic Style Transfer Data Generation via Destylization|全方位风格迁移2：通过去风格化实现可扩展且高质量的艺术风格迁移数据生成|Ye Wang, Zili Yi, Yibo Zhang, Peng Zheng, Xuping Xie, Jiang Lin, Yilin Wang, Rui Ma|<http://arxiv.org/pdf/2509.05970v1>|通过去风格化技术生成大规模数据集，OmniStyle2模型在艺术风格迁移任务中实现了高质量和可扩展性...|
|📝 更新|ComplicitSplat: Downstream Models are Vulnerable to Blackbox Attacks by 3D Gaussian Splat Camouflages|共谋喷溅：下游模型易受3D高斯喷溅迷彩的黑箱攻击|Matthew Hull, Haoyang Yang, Pratham Mehta, Mansi Phute, Aeree Cho, Haorang Wang, Matthew Lau, Wenke Lee .etc.|<http://arxiv.org/pdf/2508.11854v2>|提出了一种利用3D高斯散点遮蔽的攻击方法，实现对特定视角下的对象检测模型的黑盒攻击。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SpecSwin3D: Generating Hyperspectral Imagery from Multispectral Data via Transformer Networks|SpecSwin3D：通过Transformer网络从多光谱数据生成高光谱图像|Tang Sui, Songxi Yang, Qunying Huang|<http://arxiv.org/pdf/2509.06122v1>|提出SpecSwin3D模型，利用Transformer网络从多光谱数据生成高空间分辨率和高光谱分辨...|
|📝 更新|Semantic Discrepancy-aware Detector for Image Forgery Identification|图像伪造识别中的语义差异感知检测器|Ziye Wang, Minghang Yu, Chunyan Xu, Zhen Cui|<http://arxiv.org/pdf/2508.12341v2>|[代码](https://github.com/wzy1111111/SSD.); 提出了一种细粒度视觉对齐的语义差异感知检测器，通过重建学习有效识别图像伪造。|
|📝 更新|ADIR: Adaptive Diffusion for Image Reconstruction|自适应扩散用于图像重建：ADIR|Shady Abu-Hussein, Tom Tirer, Raja Giryes|<http://arxiv.org/pdf/2212.03221v2>|提出了一种自适应扩散的图像重建方法，通过结合预训练模型和特定退化图像的微调，显著提升了图像重建质量。|
|🆕 发布|Coefficients-Preserving Sampling for Reinforcement Learning with Flow Matching|保持系数的流匹配强化学习采样方法|Feng Wang, Zihao Yu|<http://arxiv.org/pdf/2509.05952v1>|[代码](https://github.com/IamCreateAI/FlowCPS); 提出方法消除生成图像噪声，加速强化学习稳定收敛。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|StreamMind: Unlocking Full Frame Rate Streaming Video Dialogue through Event-Gated Cognition|“StreamMind：通过事件门控认知解锁全帧率流视频对话”|Xin Ding, Hao Wu, Yifan Yang, Shiqi Jiang, Donglin Bai, Zhibo Chen, Ting Cao|<http://arxiv.org/pdf/2503.06220v3>|提出了一种事件驱动的视频处理框架StreamMind，实现了全帧率视频流处理和实时响应。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FAAGC: Feature Augmentation on Adaptive Geodesic Curve Based on the shape space theory|基于形状空间理论的自适应测地线上的特征增强：FAAGC|Yuexing Han, Ruijie Li|<http://arxiv.org/pdf/2501.18619v2>|提出了一种基于自适应测地线的特征增强方法，有效提升了数据稀缺条件下的分类准确率。|
|📝 更新|Self-Supervised Continuous Colormap Recovery from a 2D Scalar Field Visualization without a Legend|无图例情况下，从二维标量场可视化中自监督恢复连续色彩映射|Hongxu Liu, Xinyu Chen, Haoyang Zheng, Manyi Li, Zhenfan Liu, Fumeng Yang, Yunhai Wang, Changhe Tu .etc.|<http://arxiv.org/pdf/2507.20632v2>|提出了一种无需颜色图例即可从2D标量场可视化中恢复连续颜色图的自监督方法。|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|eKalibr-Inertial: Continuous-Time Spatiotemporal Calibration for Event-Based Visual-Inertial Systems|基于事件的视觉-惯性系统的连续时间时空校准：eKalibr-Inertial|Shuolong Chen, Xingxing Li, Liu Yuan|<http://arxiv.org/pdf/2509.05923v1>|[代码](https://github.com/Unsigned-Long/eKalibr); 提出了一种针对事件相机与惯性测量单元融合系统的连续时间空间时间校准方法，实现了精确的事件视觉惯性融合...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AI-Based Applied Innovation for Fracture Detection in X-rays Using Custom CNN and Transfer Learning Models|基于人工智能的定制卷积神经网络和迁移学习模型在X射线骨折检测中的应用创新|Amna Hassan, Ilsa Afzaal, Nouman Muneeb, Aneeqa Batool, Hamail Noor|<http://arxiv.org/pdf/2509.06228v1>|提出了一种基于定制卷积神经网络和迁移学习的X射线骨折自动检测方法，实现了高准确性和临床应用潜力。|
|🆕 发布|PathoHR: Hierarchical Reasoning for Vision-Language Models in Pathology|病理HR：病理学中视觉-语言模型分层推理|Yating Huang, Ziyan Huang, Lintao Xiang, Qijun Yang, Hujun Yin|<http://arxiv.org/pdf/2509.06105v1>|提出PathoHR-Bench基准和特定训练方案，提升病理领域视觉语言模型的理解和推理能力。|
|🆕 发布|AttriPrompt: Dynamic Prompt Composition Learning for CLIP|属性提示：用于CLIP的动态提示组合学习|Qiqi Zhan, Shiwei Li, Qingjie Liu, Yunhong Wang|<http://arxiv.org/pdf/2509.05949v1>|提出AttriPrompt框架，通过视觉特征引导动态文本提示，实现细粒度语义对齐和避免过拟合。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EdgeSAM: Prompt-In-the-Loop Distillation for SAM|边缘SAM：循环提示蒸馏法用于SAM|Chong Zhou, Xiangtai Li, Chen Change Loy, Bo Dai|<http://arxiv.org/pdf/2312.06660v3>|提出EdgeSAM，通过在边缘设备上优化Segment Anything Model，实现了37倍速...|
|🆕 发布|High-Quality Tomographic Image Reconstruction Integrating Neural Networks and Mathematical Optimization|高质量结合神经网络和数学优化的断层图像重建|Anuraag Mishra, Andrea Gilch, Benjamin Apeleo Zubiri, Jan Rolfes, Frauke Liers|<http://arxiv.org/pdf/2509.06082v1>|提出了一种结合神经网络和数学优化的方法，显著提升了纳米及微米层析成像的重建质量。|
|🆕 发布|Multi-Stage Graph Neural Networks for Data-Driven Prediction of Natural Convection in Enclosed Cavities|多阶段图神经网络用于数据驱动预测封闭腔体内的自然对流|Mohammad Ahangarkiasari, Hassan Pouraria|<http://arxiv.org/pdf/2509.06041v1>|提出多级图神经网络预测封闭空间自然对流，提升预测精度和训练效率。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DVLO4D: Deep Visual-Lidar Odometry with Sparse Spatial-temporal Fusion|深度视觉-激光雷达里程计：基于稀疏时空融合|Mengmeng Liu, Michael Ying Yang, Jiuming Liu, Yunpeng Zhang, Jiangtao Li, Sander Oude Elberink, George Vosselman, Hao Cheng|<http://arxiv.org/pdf/2509.06023v1>|提出了一种视觉-LiDAR里程计框架，通过稀疏时空融合技术提高了定位准确性和鲁棒性。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Khana: A Comprehensive Indian Cuisine Dataset|“Khana：一个全面的印度菜系数据集”|Omkar Prabhu|<http://arxiv.org/pdf/2509.06006v1>|提出了Khana数据集，填补了印度菜系在图像分类、分割和检索领域的综合数据集空白。|
|📝 更新|Support or Refute: Analyzing the Stance of Evidence to Detect Out-of-Context Mis- and Disinformation|支持或反驳：分析证据立场以检测脱离上下文的误信息和虚假信息|Xin Yuan, Jie Guo, Weidong Qiu, Zheng Huang, Shujun Li|<http://arxiv.org/pdf/2311.01766v5>|[代码](https://github.com/yx3266/SEN.); 提出了一种提取证据立场的网络，有效识别了脱离语境的误导信息。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ConstStyle: Robust Domain Generalization with Unified Style Transformation|《ConstStyle：基于统一风格转换的鲁棒域泛化》|Nam Duong Tran, Nam Nguyen Phuong, Hieu H. Pham, Phi Le Nguyen, My T. Thai|<http://arxiv.org/pdf/2509.05975v1>|提出ConstStyle方法，通过统一风格转换增强模型在多领域间的泛化能力，有效减少领域差异带来的性...|
|📝 更新|Flexible Coded Distributed Convolution Computing for Enhanced Straggler Resilience and Numerical Stability in Distributed CNNs|分布式卷积神经网络中增强弱者鲁棒性和数值稳定性的灵活编码分布式卷积计算|Shuo Tan, Rui Liu, Xuesong Han, XianLei Long, Kai Wan, Linqi Song, Yong Li|<http://arxiv.org/pdf/2411.01579v3>|提出了一种增强分布式卷积神经网络计算效率与稳定性的编码分布式卷积计算框架。|
|📝 更新|LD-SDM: Language-Driven Hierarchical Species Distribution Modeling|LD-SDM：语言驱动的层次物种分布建模|Srikumar Sastry, Xin Xing, Aayush Dhakal, Subash Khanal, Adeel Ahmad, Nathan Jacobs|<http://arxiv.org/pdf/2312.08334v2>|提出了一种融合大型语言模型来提取物种分类潜在表示的方法，实现了无需额外监督即可预测物种分布范围。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Neural Bloom: A Deep Learning Approach to Real-Time Lighting|神经绽放：一种实时照明效果的深度学习方法|Rafal Karp, Dawid Gruszka, Tomasz Trzcinski|<http://arxiv.org/pdf/2509.05963v1>|提出实时生成高质量辉光效果的神经网络方法，大幅提升渲染速度并节省计算资源。|
|📝 更新|NoisyNN: Exploring the Impact of Information Entropy Change in Learning Systems|噪声神经网络：探究学习系统中信息熵变化的影响|Xiaowei Yu, Zhe Huang, Minheng Chen, Lu Zhang, Tianming Liu, Dajiang Zhu|<http://arxiv.org/pdf/2309.10625v5>|探究噪声注入对深度学习系统熵变的影响，提出正噪声概念，实现了ImageNet上的前所未有的95%准确...|
|📝 更新|QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning|四足机器人运动控制：通过端到端强化学习增强的KAN方法|Yinuo Wang, Gavin Tao|<http://arxiv.org/pdf/2508.19153v2>|提出QuadKAN方法，结合本体感知与视觉，通过强化学习实现稳健的四足机器人运动控制。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MovieCORE: COgnitive REasoning in Movies|《MovieCORE：电影中的认知推理》|Gueter Josmy Faure, Min-Hung Chen, Jia-Fong Yeh, Ying Cheng, Hung-Ting Su, Yung-Hao Tang, Shang-Hong Lai, Winston H. Hsu|<http://arxiv.org/pdf/2508.19026v2>|[代码](https://joslefaure.github.io/assets); 提出MovieCORE数据集，利用多语言模型生成深度认知问题，并通过Agentic Choice E...|
|🆕 发布|BLaVe-CoT: Consistency-Aware Visual Question Answering for Blind and Low Vision Users|盲人和低视力用户的一致性感知视觉问答：BLaVe-CoT|Wanyin Cheng, Zanxi Ruan|<http://arxiv.org/pdf/2509.06010v1>|[代码](https://github.com/Accecwan/BLaVe-CoT.); 提出了BLaVe-CoT框架，通过多候选答案和空间定位应对盲人和低视力用户视觉问答中的不确定性。|
|📝 更新|ElectroVizQA: How well do Multi-modal LLMs perform in Electronics Visual Question Answering?|ElectroVizQA：多模态大型语言模型在电子视觉问答中的表现如何？|Pragati Shuddhodhan Meshram, Swetha Karthikeyan, Bhavya Bhavya, Suma Bhat|<http://arxiv.org/pdf/2412.00102v2>|提出ElectroVizQA基准数据集，评估多模态大语言模型在电子电路视觉问答任务中的表现。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Analysis of Blood Report Images Using General Purpose Vision-Language Models|使用通用视觉-语言模型分析血液报告图像|Nadia Bakhsheshi, Hamid Beigy|<http://arxiv.org/pdf/2509.06033v1>|探究通用视觉语言模型在自动分析血液报告图像上的潜力，为初步解读复杂医疗信息提供实用工具。|
|📝 更新|DiffOSeg: Omni Medical Image Segmentation via Multi-Expert Collaboration Diffusion Model|DiffOSeg：通过多专家协作扩散模型实现全医学图像分割|Han Zhang, Xiangde Luo, Yong Chen, Kang Li|<http://arxiv.org/pdf/2507.13087v2>|[代码](https://github.com/string-ellipses/DiffOSeg); 提出DiffOSeg模型，通过多专家协作扩散模型同时实现共识驱动和偏好驱动的医疗图像分割。|
|🆕 发布|Dual Interaction Network with Cross-Image Attention for Medical Image Segmentation|用于医学图像分割的带有跨图像注意力的双交互网络|Jeonghyun Noh, Wangsu Jeon, Jinsun Park|<http://arxiv.org/pdf/2509.05953v1>|[代码](https://github.com/JJeong-Gari/DIN); 提出了一种双交互融合模块，通过跨图像注意力机制有效整合原始与增强图像信息，提高了医学图像分割的准确性...|
|🆕 发布|Spatial-Aware Self-Supervision for Medical 3D Imaging with Multi-Granularity Observable Tasks|具有多粒度可观测任务的医学三维成像空间感知自监督方法|Yiqin Zhang, Meiling Chen, Zhengjie Zhang|<http://arxiv.org/pdf/2509.05967v1>|提出了一种空间感知的自监督学习方法，通过多粒度任务捕捉3D医疗影像的空间语义，增强模型的可解释性。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Cross-Modal Enhancement and Benchmark for UAV-based Open-Vocabulary Object Detection|跨模态增强与基于无人机开放词汇目标检测基准|Zhenhai Weng, Zhongliang Yu|<http://arxiv.org/pdf/2509.06011v1>|提出了一种针对无人机影像的跨模态增强方法，构建了两个大规模数据集，有效缩小了领域差距并提升了检测性能...|
|🆕 发布|TinyDef-DETR:An Enhanced DETR Detector for UAV Power Line Defect Detection|TinyDef-DETR：面向无人机电力线路缺陷检测的增强型DETR检测器|Jiaming Cui|<http://arxiv.org/pdf/2509.06035v1>|提出了一种针对无人机巡检输电线路小缺陷检测的TinyDef-DETR框架，通过保留细节、增强边界敏感...|
|🆕 发布|BTCChat: Advancing Remote Sensing Bi-temporal Change Captioning with Multimodal Large Language Model|BTCChat：利用多模态大型语言模型推进遥感双时相变化标注|Yujie Li, Wenjia Xu, Yuanben Zhang, Zhiwei Wei, Mugen Peng|<http://arxiv.org/pdf/2509.05895v1>|提出BTCChat模型，通过新增Change Extraction模块和Prompt Augment...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Can Machines Imitate Humans? Integrative Turing-like tests for Language and Vision Demonstrate a Narrowing Gap|机器能否模仿人类？语言与视觉的综合图灵式测试显示差距正在缩小|Mengmi Zhang, Elisa Pavarino, Xiao Liu, Giorgia Dellaferrera, Ankur Sikarwar, Caishun Chen, Marcelo Armendariz, Noga Mudrik .etc.|<http://arxiv.org/pdf/2211.13087v3>|通过大规模图灵测试，展示了AI在语言和视觉任务中模仿人类的进步，突显了人类相似度作为独立评价标准的重...|
|📝 更新|Bridging the Sim2Real Gap: Vision Encoder Pre-Training for Visuomotor Policy Transfer|跨越仿真与现实的鸿沟：视觉编码器预训练用于视觉运动策略迁移|Yash Yardi, Samuel Biruduganti, Lars Ankile|<http://arxiv.org/pdf/2501.16389v2>|提出了一种使用大规模预训练视觉编码器减少虚拟到现实环境差距的框架，提高了机器人控制特征提取和领域不变...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Micro-Expression Recognition via Fine-Grained Dynamic Perception|通过细粒度动态感知的微表情识别|Zhiwen Shao, Yifan Cheng, Fan Zhang, Xuehuai Shi, Canlin Li, Lizhuang Ma, Dit-yan Yeung|<http://arxiv.org/pdf/2509.06015v1>|[代码](https://github.com/CYF-cuber/FDP.); 提出了一种细粒度动态感知框架，通过排序帧级特征并捕获动态表示，有效提升了微表情识别的准确率。|

