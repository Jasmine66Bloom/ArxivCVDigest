## [UPDATED!] **2025-09-09** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Feature Space Analysis by Guided Diffusion Model|特征空间分析通过引导扩散模型|Kimiaki Shirahama, Miki Yanobu, Kaduki Yamashita, Miho Ohsaki|<http://arxiv.org/pdf/2509.07936v1>|提出了一种引导扩散模型解码器，能生成特征接近用户指定的特征图像，揭示了深度神经网络特征空间的属性。|
|🆕 发布|Active Membership Inference Test (aMINT): Enhancing Model Auditability with Multi-Task Learning|主动成员推断测试（aMINT）：利用多任务学习增强模型可审计性|Daniel DeAlcala, Aythami Morales, Julian Fierrez, Gonzalo Mancera, Ruben Tolosana, Javier Ortega-Garcia|<http://arxiv.org/pdf/2509.07879v1>|提出了一种多任务学习框架aMINT，通过同时训练审计模型和MINT模型提高数据训练来源的可识别性，实...|
|📝 更新|SPACE-iT: Spatial-Aware Curriculum Exploration and Feedback-Driven Adaptive Augmentation for Vision Transformer Distillation|SPACE-iT：面向视觉变换器蒸馏的空间感知课程探索与反馈驱动自适应增强|Jihyeon Seong, Hyunkyung Han|<http://arxiv.org/pdf/2506.10582v2>|提出了一种考虑空间变化的自信度图来动态调整视觉Transformer的知识蒸馏方法，有效提升了学习复...|
|📝 更新|A Decade of Wheat Mapping for Lebanon|《黎巴嫩小麦制图十年研究》|Hasan Wehbi, Hasan Nasrallah, Mohamad Hasan Zahweh, Zeinab Takach, Veera Ganesh Yalla, Ali J. Ghandour|<http://arxiv.org/pdf/2504.11366v3>|提出了一种结合时空视觉变换器和参数高效微调的 wheat 地块映射方法，提高了边界划分精度和地块识别...|
|📝 更新|F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions|F1：一种将视觉-语言-动作模型桥接理解与生成至动作的方法|Qi Lv, Weijie Kong, Hao Li, Jia Zeng, Zherui Qiu, Delin Qu, Haoming Song, Qizhi Chen .etc.|<http://arxiv.org/pdf/2509.06951v2>|引入F1模型，通过集成视觉预判生成决策流程，提升动态环境中语言条件任务的执行效率和鲁棒性。|
|📝 更新|Efficient Deep Learning-based Forward Solvers for Brain Tumor Growth Models|基于高效深度学习的脑肿瘤生长模型前向求解器|Zeineb Haouari, Jonas Weidner, Yeray Martin-Ruisanchez, Ivan Ezhov, Aswathi Varma, Daniel Rueckert, Bjoern Menze, Benedikt Wiestler|<http://arxiv.org/pdf/2501.08226v2>|提出基于深度学习的肿瘤生长模型前向解算方法，显著缩短模型校准时间并提升预测精度。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visual Representation Alignment for Multimodal Large Language Models|多模态大型语言模型的视觉表征对齐|Heeji Yoon, Jaewoo Jung, Junwan Kim, Hyungyu Choi, Heeseong Shin, Sangbeom Lim, Honggyu An, Chaehyun Kim .etc.|<http://arxiv.org/pdf/2509.07979v1>|提出VIRAL方法，通过视觉表示对齐提升多模态大语言模型处理视觉任务的能力。|
|🆕 发布|Multimodal Contrastive Pretraining of CBCT and IOS for Enhanced Tooth Segmentation|多模态对比预训练CBCT与IOS以增强牙齿分割|Moo Hyun Son, Juyoung Bae, Zelin Qiu, Jiale Peng, Kai Xin Li, Yifan Lin, Hao Chen|<http://arxiv.org/pdf/2509.07923v1>|首次提出多模态对比预训练框架 ToothMCL，融合 CBCT 和 IOS 数据，显著提升牙齿分割精...|
|📝 更新|Robust Adaptation of Large Multimodal Models for Retrieval Augmented Hateful Meme Detection|大型多模态模型在检索增强的仇恨表情检测中的鲁棒适应|Jingbiao Mei, Jinghong Chen, Guangyu Yang, Weizhe Lin, Bill Byrne|<http://arxiv.org/pdf/2502.13061v3>|[代码](https://github.com/JingbiaoMei/RGCL); 提出了一种增强大型多模态模型在仇恨表情检测中的域内准确性和跨域泛化能力的稳健适应框架。|
|🆕 发布|Deep Learning-Based Burned Area Mapping Using Bi-Temporal Siamese Networks and AlphaEarth Foundation Datasets|基于深度学习的火烧区域制图：使用双时序Siamese网络和AlphaEarth基础数据集|Seyd Teymoor Seydi|<http://arxiv.org/pdf/2509.07852v1>|提出了一种基于深度学习的双时序Siamese网络方法，利用AlphaEarth数据集实现了高精度火烧...|
|🆕 发布|Point Linguist Model: Segment Any Object via Bridged Large 3D-Language Model|点语言学模型：通过桥接大型三维-语言模型分割任意对象|Zhuoxu Huang, Mingqi Gao, Jungong Han|<http://arxiv.org/pdf/2509.07825v1>|提出Point Linguist Model框架，通过学习对象中心表示和几何重激活解码器，有效桥接语...|
|📝 更新|Interleaving Reasoning for Better Text-to-Image Generation|“交错推理以实现更优的文本到图像生成”|Wenxuan Huang, Shuang Chen, Zheyong Xie, Shaosheng Cao, Shixiang Tang, Yufan Shen, Qingyu Yin, Wenbo Hu .etc.|<http://arxiv.org/pdf/2509.06945v2>|[代码](https://github.com/Osilly/Interleaving-Reasoning-Generation); 提出了一种交替文本推理与图像生成的IRG框架，有效提升了文本到图像生成的细节保持和指令遵循能力。|
|📝 更新|SAMba-UNet: SAM2-Mamba UNet for Cardiac MRI in Medical Robotic Perception|SAMba-UNet：基于SAM2-Mamba UNet的心脏磁共振成像在医疗机器人感知中的应用|Guohao Huo, Ruiting Dai, Ling Shao, Hao Tang|<http://arxiv.org/pdf/2505.16304v2>|提出SAMba-UNet模型，结合视觉基础模型和状态空间模型，增强心脏MRI复杂特征提取，显著提升分...|
|📝 更新|"Humor, Art, or Misinformation?": A Multimodal Dataset for Intent-Aware Synthetic Image Detection|“幽默、艺术还是误导？”：一个用于意图感知合成图像检测的多模态数据集|Anastasios Skoularikis, Stefanos-Iordanis Papadopoulos, Symeon Papadopoulos, Panagiotis C. Petrantonakis|<http://arxiv.org/pdf/2508.20670v2>|提出了一个用于识别AI生成图像意图的多模态数据集，并研究了三种合成训练数据策略。|
|📝 更新|PIN: A Knowledge-Intensive Dataset for Paired and Interleaved Multimodal Documents|PIN：一种用于配对和交错多模态文档的知识密集型数据集|Junjie Wang, Yuxiang Zhang, Minghao Liu, Yin Zhang, Yatai Ji, Weihao Xuan, Nie Lin, Kang Zhu .etc.|<http://arxiv.org/pdf/2406.13923v3>|介绍了PIN数据格式，通过结合丰富的文本和整体图像，助力大型多模态模型深入融合视觉与文本知识。|
|📝 更新|GeoChain: Multimodal Chain-of-Thought for Geographic Reasoning|地理链：用于地理推理的多模态思维链|Sahiti Yerramilli, Nilay Pande, Rynaa Grover, Jayant Sravan Tamarapalli|<http://arxiv.org/pdf/2506.00785v3>|提出GeoChain大规模基准，评估多模态大语言模型在地理推理中的逐步思维过程。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bias in Gender Bias Benchmarks: How Spurious Features Distort Evaluation|性别偏见基准中的偏见：如何伪特征扭曲评估|Yusuke Hirota, Ryo Hachiuma, Boyi Li, Ximing Lu, Michael Ross Boone, Boris Ivanovic, Yejin Choi, Marco Pavone .etc.|<http://arxiv.org/pdf/2509.07596v1>|揭示了现有性别偏见评估基准中非性别特征对评估结果的扭曲，建议结合特征敏感性度量以提高评估可靠性。|
|🆕 发布|PanoLAM: Large Avatar Model for Gaussian Full-Head Synthesis from One-shot Unposed Image|全景LAM：从单张非摆姿势图像实现高斯全头合成的超大头像模型|Peng Li, Yisheng He, Yingdong Hu, Yuan Dong, Weihao Yuan, Yuan Liu, Zilong Dong, Yike Guo|<http://arxiv.org/pdf/2509.07552v1>|提出了单张非摆姿势图像快速生成高保真高斯全头模型的框架，通过粗到细的生成流程和双分支结构有效聚合特征...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Object-level Correlation for Few-Shot Segmentation|对象级相关性用于少量样本分割|Chunlin Wen, Yu Zhang, Jie Fan, Hongyuan Zhu, Xiu-Shen Wei, Yijun Wang, Zhiqiang Kou, Shuzhou Sun|<http://arxiv.org/pdf/2509.07917v1>|提出了一种基于对象级关联的少样本分割网络，有效抑制背景噪声并提高目标识别准确性。|
|🆕 发布|XSRD-Net: EXplainable Stroke Relapse Detection|XSRD-Net：可解释性笔画复发检测网络|Christian Gapp, Elias Tappeiner, Martin Welk, Karl Fritscher, Stephanie Mangesius, Constantin Eisenschink, Philipp Deisl, Michael Knoflach .etc.|<http://arxiv.org/pdf/2509.07772v1>|提出了一种基于深度学习的多模态模型XSRD-Net，用于早期识别脑卒中复发风险，并实现了对复发时间的...|
|📝 更新|BuzzSet v1.0: A Dataset for Pollinator Detection in Field Conditions|“BuzzSet v1.0：一个用于田间条件下传粉者检测的数据集”|Ahmed Emam, Mohamed Elbassiouny, Julius Miller, Patrick Donworth, Sabine Seidel, Ribana Roscher|<http://arxiv.org/pdf/2508.19762v4>|提出BuzzSet v1.0数据集，助力田间条件下授粉昆虫的高效自动监测。|
|🆕 发布|Beyond Motion Cues and Structural Sparsity: Revisiting Small Moving Target Detection|超越运动线索与结构稀疏性：重新审视小移动目标检测|Guoyi Zhang, Siyang Chen, Guangsheng Xu, Zhihua Shen, Han Wang, Xiaohu Zhang|<http://arxiv.org/pdf/2509.07654v1>|提出了一种基于张量分解和自注意力机制的深度学习框架TenRPCANet，用于小移动目标检测，无需依赖...|
|📝 更新|Ultra-Low-Latency Spiking Neural Networks with Temporal-Dependent Integrate-and-Fire Neuron Model for Objects Detection|超低延迟的基于时间依赖积分放电神经元模型的脉冲神经网络用于目标检测|Chengjun Zhang, Yuhao Zhang, Jie Yang, Mohamad Sawan|<http://arxiv.org/pdf/2508.20392v2>|提出了一种基于tdIF神经元模型的SNN，实现了在极低延迟下的高精度目标检测。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|P3-SAM: Native 3D Part Segmentation|P3-SAM：原生三维部件分割|Changfeng Ma, Yang Li, Xinhao Yan, Jiachen Xu, Yunhan Yang, Chunshi Wang, Zibo Zhao, Yanwen Guo .etc.|<http://arxiv.org/pdf/2509.06784v2>|提出了一种自动化3D物体部件分割模型P3-SAM，实现了对复杂物体的精确分割并达到领先性能。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spectral and Rhythm Feature Performance Evaluation for Category and Class Level Audio Classification with Deep Convolutional Neural Networks|基于深度卷积神经网络的音频分类在类别和级别上的光谱与节奏特征性能评估|Friedrich Wolf-Monheim|<http://arxiv.org/pdf/2509.07756v1>|评估了多种音频特征在深度卷积神经网络中的分类性能，发现mel-scaled光谱图和MFCC效果最佳。|
|🆕 发布|Nearest Neighbor Projection Removal Adversarial Training|最近邻投影移除对抗训练|Himanshu Singh, A. V. Subramanyam, Shivank Rajput, Mohan Kankanhalli|<http://arxiv.org/pdf/2509.07673v1>|提出了一种通过投影消除类间依赖的对抗训练框架，有效增强了深度神经网络的鲁棒性。|
|📝 更新|MSCPT: Few-shot Whole Slide Image Classification with Multi-scale and Context-focused Prompt Tuning|MSCPT：基于多尺度与上下文聚焦提示调优的少量样本全切片图像分类|Minghao Han, Linhao Qu, Dingkang Yang, Xukun Zhang, Xiaoying Wang, Lihua Zhang|<http://arxiv.org/pdf/2408.11505v3>|[代码](https://github.com/Hanminghao/MSCPT.); 提出了一种针对少量标注数据的病理全切片图像分类方法MSCPT，通过多尺度视觉语言先验和图上下文信息提...|
|📝 更新|Interpretable Text-Guided Image Clustering via Iterative Search|通过迭代搜索的可解释文本引导图像聚类|Bingchen Zhao, Oisin Mac Aodha|<http://arxiv.org/pdf/2506.12514v2>|提出了一种迭代搜索的文本引导图像聚类方法，通过用户指令生成更符合用户意图的可解释视觉概念。|
|🆕 发布|Attention Maps in 3D Shape Classification for Dental Stage Estimation with Class Node Graph Attention Networks|三维形状分类中的注意力图在牙科阶段估计中的应用：基于类节点图注意力网络|Barkin Buyukcakir, Rocharles Cavalcante Fontenele, Reinhilde Jacobs, Jannick De Tobel, Patrick Thevissen, Dirk Vandermeulen, Peter Claes|<http://arxiv.org/pdf/2509.07581v1>|引入Class Node Graph Attention Network（CGAT）架构，通过注意力...|
|📝 更新|DMS-Net:Dual-Modal Multi-Scale Siamese Network for Binocular Fundus Image Classification|DMS-Net：双模多尺度Siamese网络用于双眼底图像分类|Guohao Huo, Zibo Lin, Zitong Wang, Ruiting Dai, Hao Tang|<http://arxiv.org/pdf/2504.18046v3>|提出了一种双模多尺度Siamese网络，通过联合提取双眼视网膜图像的深度语义特征，提高了眼科疾病诊断...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SEEC: Segmentation-Assisted Multi-Entropy Models for Learned Lossless Image Compression|SEEC：基于分割辅助的多熵模型学习无损图像压缩|Chunhang Zheng, Zichang Ren, Dou Li|<http://arxiv.org/pdf/2509.07704v1>|[代码](https://github.com/chunbaobao/SEEC.); 提出多熵模型与语义分割结合的图像压缩方法，针对不同区域精准建模，实现高效无损压缩。|
|🆕 发布|Temporal Image Forensics: A Review and Critical Evaluation|时间图像取证：综述与批判性评估|Robert Jöchl, Andreas Uhl|<http://arxiv.org/pdf/2509.07591v1>|系统综述了基于图像采集管道时间依赖性痕迹的图像时序取证技术，并揭示了内容偏见问题及XAI方法在验证技...|
|🆕 发布|MVAT: Multi-View Aware Teacher for Weakly Supervised 3D Object Detection|多视角感知教师网络：用于弱监督三维目标检测|Saad Lahlali, Alexandre Fournier Montgieux, Nicolas Granger, Hervé Le Borgne, Quoc Cuong Pham|<http://arxiv.org/pdf/2509.07507v1>|[代码](https://github.com/CEA-LIST/MVAT); 提出了一种利用多视角时序数据生成高质量伪标签的方法，显著提升了弱监督三维物体检测的性能。|
|📝 更新|Texture- and Shape-based Adversarial Attacks for Overhead Image Vehicle Detection|基于纹理和形状的对抗性攻击在俯视图像车辆检测中的应用|Mikael Yeghiazaryan, Sai Abhishek Siddhartha Namburu, Emily Kim, Stanislav Panev, Celso de Melo, Fernando De la Torre, Jessica K. Hodgins|<http://arxiv.org/pdf/2412.16358v2>|[代码](https://github.com/humansensinglab/texture-shape-adversarial-attacks.); 提出了一种考虑实际约束的纹理和形状对抗攻击方法，提高了车辆检测的攻击效率和实用性。|
|📝 更新|Detect Changes like Humans: Incorporating Semantic Priors for Improved Change Detection|像人类一样检测变化：融合语义先验以提高变化检测性能|Yuhang Gan, Wenjie Xuan, Zhiming Luo, Lei Fang, Zengmao Wang, Juhua Liu, Bo Du|<http://arxiv.org/pdf/2412.16918v2>|[代码](https://github.com/DREAMXFAR/SA-CDNet); 引入视觉基础模型的语义先验，提出双流特征解码的SA-CDNet网络，提升变化检测准确性。|
|🆕 发布|Parse Graph-Based Visual-Language Interaction for Human Pose Estimation|基于解析图的视觉语言交互用于人体姿态估计|Shibang Liu, Xuemei Xie, Guangming Shi|<http://arxiv.org/pdf/2509.07385v1>|提出Parse Graph-based Visual-Language Interaction方法，...|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|One View, Many Worlds: Single-Image to 3D Object Meets Generative Domain Randomization for One-Shot 6D Pose Estimation|一种视角，多个世界：单张图像到三维物体的转换与生成域随机化相遇，实现单次6D姿态估计|Zheng Geng, Nan Wang, Shaocong Xu, Chongjie Ye, Bohan Li, Zhaoxi Chen, Sida Peng, Hao Zhao|<http://arxiv.org/pdf/2509.07978v1>|[代码](https://gzwsama.github.io/OnePoseviaGen.github.io); 提出了一种结合多视角特征匹配与生成域随机化的方法，实现了基于单张图片的精确6D姿态估计。|
|🆕 发布|Enhanced SegNet with Integrated Grad-CAM for Interpretable Retinal Layer Segmentation in OCT Images|增强型SegNet与集成Grad-CAM相结合的视网膜层分割解释性研究在OCT图像中的应用|S M Asiful Islam Saky, Ugyen Tshering|<http://arxiv.org/pdf/2509.07795v1>|提出了一种改进的SegNet框架结合Grad-CAM，实现了高准确性和可解释性的视网膜层自动分割。|
|📝 更新|Coefficients-Preserving Sampling for Reinforcement Learning with Flow Matching|保持系数的流匹配强化学习采样方法|Feng Wang, Zihao Yu|<http://arxiv.org/pdf/2509.05952v2>|[代码](https://github.com/IamCreateAI/FlowCPS); 提出方法消除生成图像噪声，加速强化学习稳定收敛。|
|📝 更新|Large-scale Pre-training for Grounded Video Caption Generation|大规模预训练用于基于视频的自动字幕生成|Evangelos Kazakos, Cordelia Schmid, Josef Sivic|<http://arxiv.org/pdf/2503.10781v3>|[代码](https://ekazakos.github.io/grounded_video_caption_generation); 提出了一种大规模预训练方法，通过自动标注构建HowToGround1M数据集，并训练GROVE模型，...|
|📝 更新|Light-Weight Cross-Modal Enhancement Method with Benchmark Construction for UAV-based Open-Vocabulary Object Detection|基于轻量级跨模态增强方法的无人机开放词汇目标检测及其基准构建|Zhenhai Weng, Xinjie Li, Can Wu, Weijie He, Jianfeng Lv, Dong Zhou, Zhongliang Yu|<http://arxiv.org/pdf/2509.06011v2>|提出了一种针对无人机影像的轻量级跨模态增强方法，构建了两个新数据集，显著提升了开放词汇物体检测性能。|
|📝 更新|Conditional Video Generation for High-Efficiency Video Compression|条件视频生成用于高效视频压缩|Fangqiu Yi, Jingyu Xu, Jiawei Shao, Chi Zhang, Xuelong Li|<http://arxiv.org/pdf/2507.15269v3>|提出利用条件扩散模型进行视频压缩，通过多粒度条件化和模态训练提升感知质量。|
|🆕 发布|Semantic Watermarking Reinvented: Enhancing Robustness and Generation Quality with Fourier Integrity|语义水印技术革新：利用傅里叶完整性增强鲁棒性和生成质量|Sung Ju Lee, Nam Ik Cho|<http://arxiv.org/pdf/2509.07647v1>|[代码](https://github.com/thomas11809/SFWMark); 提出了一种Hermitian对称傅里叶水印方法，通过保持频率完整性和引入中心感知嵌入策略，增强了语义...|
|📝 更新|LiDARCrafter: Dynamic 4D World Modeling from LiDAR Sequences|LiDARCrafter：从LiDAR序列中动态构建四维世界模型|Ao Liang, Youquan Liu, Yu Yang, Dongyue Lu, Linfeng Li, Lingdong Kong, Huaici Zhao, Wei Tsang Ooi|<http://arxiv.org/pdf/2508.03692v2>|提出LiDARCrafter框架，通过自然语言输入生成动态4D LiDAR模型，实现高精度场景建模与...|
|📝 更新|C-DiffDet+: Fusing Global Scene Context with Generative Denoising for High-Fidelity Object Detection|全局场景上下文与生成去噪融合的高保真目标检测|Abdellah Zakaria Sellam, Ilyes Benaissa, Salah Eddine Bekhouche, Abdenour Hadid, Vito Renó, Cosimo Distante|<http://arxiv.org/pdf/2509.00578v3>|引入上下文感知融合机制，结合全局场景上下文和生成去噪，提升细粒度目标检测准确性。|
|🆕 发布|DepthVision: Robust Vision-Language Understanding through GAN-Based LiDAR-to-RGB Synthesis|深度视觉：基于生成对抗网络的激光雷达到 RGB 合成实现的鲁棒视觉-语言理解|Sven Kirchner, Nils Purschke, Ross Greer, Alois C. Knoll|<http://arxiv.org/pdf/2509.07463v1>|DepthVision通过GAN合成RGB图像结合LiDAR数据，增强了机器人低光照条件下的视觉理解...|
|📝 更新|CountQA: How Well Do MLLMs Count in the Wild?|CountQA: 面向野外的多模态语言模型计数性能评估|Jayant Sravan Tamarapalli, Rynaa Grover, Nilay Pande, Sahiti Yerramilli|<http://arxiv.org/pdf/2508.06585v2>|提出CountQA基准，揭示了多模态大语言模型在复杂场景中计数能力的不足。|
|🆕 发布|DreamLifting: A Plug-in Module Lifting MV Diffusion Models for 3D Asset Generation|“DreamLifting：用于3D资产生成的提升多视图扩散模型插件模块”|Ze-Xin Yin, Jiaxiong Qiu, Liu Liu, Xinjie Wang, Wei Sui, Zhizhong Su, Jian Yang, Jin Xie|<http://arxiv.org/pdf/2509.07435v1>|[代码](https://zx-yin.github.io/dreamlifting); 提出了一种统一建模几何和PBR材料的框架，通过利用多视角扩散先验实现高效端到端3D资产生成。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ScoreHOI: Physically Plausible Reconstruction of Human-Object Interaction via Score-Guided Diffusion|分数驱动的扩散引导下的人-物交互物理可信重建：ScoreHOI|Ao Li, Jinpeng Liu, Yixuan Zhu, Yansong Tang|<http://arxiv.org/pdf/2509.07920v1>|引入了ScoreHOI方法，通过扩散先验和迭代优化，实现了更精确的人物-物体交互重建效果。|
|📝 更新|Closed-Loop Unsupervised Representation Disentanglement with $β$-VAE Distillation and Diffusion Probabilistic Feedback|闭环无监督表示解耦：基于$β$-VAE蒸馏与扩散概率反馈方法|Xin Jin, Bohan Li, BAAO Xie, Wenyao Zhang, Jinming Liu, Ziqiang Li, Tao Yang, Wenjun Zeng|<http://arxiv.org/pdf/2402.02346v2>|提出了一种闭环无监督表示解耦方法，通过VAE蒸馏和扩散概率反馈，有效解决了依赖标签和合成数据、解耦约...|
|📝 更新|BEAM: Bridging Physically-based Rendering and Gaussian Modeling for Relightable Volumetric Video|BEAM：基于物理渲染与高斯建模的桥接用于可重光照的体视频|Yu Hong, Yize Wu, Zhehao Shen, Chengcheng Guo, Yuheng Jiang, Yingliang Zhang, Jingyi Yu, Lan Xu|<http://arxiv.org/pdf/2502.08297v2>|提出了一种结合4D高斯表示与物理渲染的BEAM方法，实现了高质量、可重光照的体视频制作。|
|📝 更新|BranchGRPO: Stable and Efficient GRPO with Structured Branching in Diffusion Models|分支GRPO：在扩散模型中具有结构分支的稳定高效GRPO|Yuming Li, Yikai Wang, Yuying Zhu, Zhongyu Zhao, Ming Lu, Qi She, Shanghang Zhang|<http://arxiv.org/pdf/2509.06040v2>|BranchGRPO通过引入分支采样策略优化了GRPO的采样过程，降低计算成本并提升探索多样性。|
|📝 更新|DIP: Unsupervised Dense In-Context Post-training of Visual Representations|DIP：视觉表征的无监督密集式上下文后训练|Sophia Sirko-Galouchenko, Spyros Gidaris, Antonin Vobecky, Andrei Bursuc, Nicolas Thome|<http://arxiv.org/pdf/2506.18463v3>|[代码](https://github.com/sirkosophia/DIP); 提出了一种无监督的视觉表征后训练方法DIP，通过模拟实际场景的伪任务来增强预训练视觉编码器的密集表征...|
|📝 更新|Generalizable Humanoid Manipulation with 3D Diffusion Policies|具有三维扩散策略的通用化人形操纵|Yanjie Ze, Zixuan Chen, Wenhao Wang, Tianyi Chen, Xialin He, Ying Yuan, Xue Bin Peng, Jiajun Wu|<http://arxiv.org/pdf/2410.10803v3>|提出了一种集成人类操作数据的3D扩散策略学习算法，实现了人形机器人在多样化环境中的自主操作技能。|
|📝 更新|Frequency Domain Enhanced U-Net for Low-Frequency Information-Rich Image Segmentation in Surgical and Deep-Sea Exploration Robots|频域增强U-Net：用于手术和深海探测机器人中低频信息丰富图像分割的方法|Guohao Huo, Ruiting Dai, Jinliang Liu, Ling Shao, Hao Tang|<http://arxiv.org/pdf/2502.03829v3>|提出一种增强低频信息提取的FE-UNet模型，通过波适应谱融合和感知频率块提升手术和深海机器人图像分...|
|📝 更新|Decoupled Sparse Priors Guided Diffusion Compression Model for Point Clouds|解耦稀疏先验引导的点云扩散压缩模型|Xiaoge Zhang, Zijie Wu, Mehwish Nasim, Mingtao Feng, Ajmal Mian|<http://arxiv.org/pdf/2411.13860v2>|提出了一种高效的点云压缩方法，通过分离稀疏先验和潜在点，实现了高压缩率下的高质量重建。|
|🆕 发布|Universal Few-Shot Spatial Control for Diffusion Models|通用少样本空间控制扩散模型|Kiet T. Nguyen, Chanhuyk Lee, Donggyun Kim, Dong Hoon Lee, Seunghoon Hong|<http://arxiv.org/pdf/2509.07530v1>|[代码](https://github.com/kietngt00/UFC.); 提出了一种通用的少量样本空间控制方法UFC，有效应对了新型空间条件下的适应性和训练成本问题。|
|📝 更新|PromptEnhancer: A Simple Approach to Enhance Text-to-Image Models via Chain-of-Thought Prompt Rewriting|PromptEnhancer：通过链式思维提示重写提升文本到图像模型的一种简单方法|Linqing Wang, Ximing Xing, Yiji Cheng, Zhiyuan Zhao, Jiale Tao, Qixun Wang, Ruihuang Li, Xin Li .etc.|<http://arxiv.org/pdf/2509.04545v2>|提出了一种PromptEnhancer框架，通过Chain-of-Thought重写提示，有效提升了...|
|📝 更新|Evaluation of Alignment-Regularity Characteristics in Deformable Image Registration|《可变形图像配准中对应-正则性特征的评估》|Vasiliki Sideri-Lampretsa, Daniel Rueckert, Huaqi Qiu|<http://arxiv.org/pdf/2503.07185v2>|提出了一种基于ARC曲线的评价方案，有效平衡了图像配准的准确性和变形规律性。|
|📝 更新|PnP-Flow: Plug-and-Play Image Restoration with Flow Matching|PnP-Flow：基于流匹配的即插即用图像复原|Ségolène Martin, Anne Gagneux, Paul Hagemann, Gabriele Steidl|<http://arxiv.org/pdf/2410.02423v3>|提出了一种结合预训练生成模型Flow Matching的PnP图像修复算法，提升了多种成像逆问题的性...|
|📝 更新|A Novel Image Similarity Metric for Scene Composition Structure|一种用于场景组合结构的新型图像相似性度量方法|Md Redwanul Haque, Manzur Murshed, Manoranjan Paul, Tsz-Kwan Lee|<http://arxiv.org/pdf/2508.05037v4>|提出了一种无需训练的SCSSIM指标，通过统计分析图像结构，有效评估生成模型中场景组合结构的保真度。|
|📝 更新|TractGraphFormer: Anatomically Informed Hybrid Graph CNN-Transformer Network for Interpretable Sex and Age Prediction from Diffusion MRI Tractography|《TractGraphFormer：一种基于解剖信息指导的混合图卷积神经网络-Transformer网络，用于从扩散MRI追踪数据中进行可解释的性别和年龄预测》|Yuqian Chen, Fan Zhang, Meng Wang, Leo R. Zekelman, Suheyla Cetin-Karayumak, Tengfei Xue, Chaoyi Zhang, Yang Song .etc.|<http://arxiv.org/pdf/2407.08883v2>|提出了一种结合局部解剖特征和全局特征依赖的TractGraphFormer模型，用于从扩散MRI轨迹...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EDFFDNet: Towards Accurate and Efficient Unsupervised Multi-Grid Image Registration|EDFFDNet：面向精确且高效的无监督多网格图像配准|Haokai Zhu, Bo Qu, Si-Yuan Cao, Runmin Zhang, Shujie Chen, Bailin Yang, Hui-Liang Shen|<http://arxiv.org/pdf/2509.07662v1>|提出了一种高效准确的图像配准方法EDFFDNet，通过引入指数衰减基函数和自适应稀疏运动聚合器，提升...|
|📝 更新|POEv2: a flexible and robust framework for generic line segment detection and wireframe line segment detection|POEv2：一种灵活且健壮的通用线段检测与线框线段检测框架|Chenguang Liu, Chisheng Wang, Yuhua Cai, Chuanhua Zhu, Qingquan Li|<http://arxiv.org/pdf/2508.19742v2>|提出了一种通用且鲁棒的方法POEv2，可同时用于通用线段和线框线段检测，实现业界领先性能。|
|📝 更新|InteractPro: A Unified Framework for Motion-Aware Image Composition|《InteractPro：一种统一框架，用于运动感知图像合成》|Weijing Tao, Xiaofeng Yang, Miaomiao Cui, Guosheng Lin|<http://arxiv.org/pdf/2409.10090v3>|提出了一种统一的动态运动感知图像合成框架InteractPro，通过智能规划器和模拟-扩散结合方法，...|
|🆕 发布|ANYPORTAL: Zero-Shot Consistent Video Background Replacement|ANYPORTAL：零样本一致性视频背景替换|Wenshuo Gao, Xicheng Lan, Shuai Yang|<http://arxiv.org/pdf/2509.07472v1>|提出ANYPORTAL框架，利用预训练扩散模型实现无需训练的高质量视频背景替换。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RealRep: Generalized SDR-to-HDR Conversion via Attribute-Disentangled Representation Learning|《RealRep：通过属性解耦表征学习实现的通用SDR至HDR转换》|Gang He, Siqi Wang, Kepeng Xu, Lin Zhang, Li Xu, Weiran Wang, Yu-Wing Tai|<http://arxiv.org/pdf/2505.07322v2>|提出了一种学习属性解耦表示的通用SDR转HDR框架，有效应对不同SDR内容的多样性和退化问题。|
|📝 更新|Aesthetic Image Captioning with Saliency Enhanced MLLMs|美学图像标注：基于显著性增强的多模态语言模型的图像描述生成|Yilin Tao, Jiashui Huang, Huaze Xu, Ling Shao|<http://arxiv.org/pdf/2509.04378v3>|提出ASE-MLLM框架，融合图像美学显著性，提升美学图像描述生成效果。|
|🆕 发布|LINR Bridge: Vector Graphic Animation via Neural Implicits and Video Diffusion Priors|LINR桥：通过神经隐式表示和视频扩散先验实现矢量图形动画|Wenshuo Gao, Xicheng Lan, Luyao Zhang, Shuai Yang|<http://arxiv.org/pdf/2509.07484v1>|提出了一种结合隐式神经表示和文本到视频扩散模型的方法，自动化生成高质量的矢量图形动画。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HairGS: Hair Strand Reconstruction based on 3D Gaussian Splatting|基于三维高斯散点化的发丝重建方法HairGS|Yimin Pan, Matthias Nießner, Tobias Kirschstein|<http://arxiv.org/pdf/2509.07774v1>|[代码](https://yimin-pan.github.io/hair-gs); 提出了一种基于3D高斯散点的新方法，实现了从多视角图像重建头发细节和连贯的毛发束。|
|🆕 发布|SplatFill: 3D Scene Inpainting via Depth-Guided Gaussian Splatting|“SplatFill：基于深度引导的高斯散点填充的3D场景修复”|Mahtab Dahaghin, Milind G. Padalkar, Matteo Toso, Alessio Del Bue|<http://arxiv.org/pdf/2509.07809v1>|提出了一种深度引导的3D场景修复方法SplatFill，实现了更高质量的视觉效果和效率提升。|
|🆕 发布|Faster, Self-Supervised Super-Resolution for Anisotropic Multi-View MRI Using a Sparse Coordinate Loss|使用稀疏坐标损失进行各向异性多视角MRI的更快、自监督超分辨率重建|Maja Schlereth, Moritz Schillinger, Katharina Breininger|<http://arxiv.org/pdf/2509.07798v1>|[代码](https://github.com/MajaSchle/tripleSR.); 提出了一种无需对应高分辨率数据的自监督超分辨率方法，通过融合两个正交的低分辨率MRI图像并引入稀疏坐...|
|🆕 发布|DiGS: Accurate and Complete Surface Reconstruction from 3D Gaussians via Direct SDF Learning|DiGS：通过直接学习SDF从三维高斯函数进行精确和完整的表面重建|Wenzhi Guo, Bing Wang|<http://arxiv.org/pdf/2509.07493v1>|提出DiGS框架，将符号距离场学习融入3D高斯分布，实现精确且完整的表面重建。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PINGS: Gaussian Splatting Meets Distance Fields within a Point-Based Implicit Neural Map|PINGS：高斯散点喷射与点基隐神经地图中的距离场结合|Yue Pan, Xingguang Zhong, Liren Jin, Louis Wiesmann, Marija Popović, Jens Behley, Cyrill Stachniss|<http://arxiv.org/pdf/2502.05752v2>|[代码](https://github.com/PRBonn/PINGS.); 提出了一种统一连续距离场和高斯散点辐射场的点基隐式神经图表示，实现了高质量增量式建图。|
|📝 更新|SGCNeRF: Few-Shot Neural Rendering via Sparse Geometric Consistency Guidance|SGCNeRF：通过稀疏几何一致性引导的少量样本神经渲染|Yuru Xiao, Xianming Liu, Deming Zhai, Kui Jiang, Junjun Jiang, Xiangyang Ji|<http://arxiv.org/pdf/2404.00992v3>|提出了一种基于特征匹配的稀疏几何一致性引导方法，有效解决了NeRF在少量视角下的过拟合问题并保留了高...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VIM-GS: Visual-Inertial Monocular Gaussian Splatting via Object-level Guidance in Large Scenes|VIM-GS：基于对象级引导的大场景视觉-惯性单目高斯散点映射|Shengkai Zhang, Yuhe Liu, Guanjun Wu, Jianhua He, Xinggang Wang, Mozi Chen, Kezhong Liu|<http://arxiv.org/pdf/2509.06685v2>|提出了一种结合视觉-惯性SfM和大型基础模型深度估计的方法，实现了大型场景中高精度单目图像深度估计和...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Audio-centric Video Understanding Benchmark without Text Shortcut|以音频为中心的无文本捷径视频理解基准|Yudong Yang, Jimin Zhuang, Guangzhi Sun, Changli Tang, Yixuan Li, Peihan Li, Yifan Jiang, Wei Li .etc.|<http://arxiv.org/pdf/2503.19951v2>|[代码](https://github.com/lark-png/AVUT.); 提出音频中心的视频理解基准，解决文本捷径问题，全面评估多模态模型对音视频内容的理解能力。|
|📝 更新|SkillFormer: Unified Multi-View Video Understanding for Proficiency Estimation|技能形成者：统一多视角视频理解以进行熟练度估计|Edoardo Bianchi, Antonio Liotta|<http://arxiv.org/pdf/2505.08665v4>|提出SkillFormer架构，通过多视角融合显著提升技能评估准确度并降低训练成本。|
|📝 更新|Seeing More, Saying More: Lightweight Language Experts are Dynamic Video Token Compressors|“看得更多，说得更多：轻量级语言专家是动态视频标记压缩器”|Xiangchen Wang, Jinrui Zhang, Teng Wang, Haigang Zhang, Feng Zheng|<http://arxiv.org/pdf/2509.00969v2>|提出了一种动态调整视频帧表示的轻量级语言模型，根据场景复杂度自适应压缩，提升效率同时保持性能。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EHWGesture -- A dataset for multimodal understanding of clinical gestures|EHWGesture -- 用于临床手势多模态理解的数据库|Gianluca Amprimo, Alberto Ancilotto, Alessandro Savino, Fabio Quazzolo, Claudia Ferraris, Gabriella Olmo, Elisabetta Farella, Stefano Di Carlo|<http://arxiv.org/pdf/2509.07525v1>|介绍了EHWGesture多模态视频数据集，为临床手势理解和手部灵巧度评估提供了精确基准。|
|🆕 发布|G3CN: Gaussian Topology Refinement Gated Graph Convolutional Network for Skeleton-Based Action Recognition|高斯拓扑细化门控图卷积网络（G3CN）用于基于骨架的动作识别|Haiqing Ren, Zhongkai Luo, Heng Fan, Xiaohui Yuan, Guanchen Wang, Libo Zhang|<http://arxiv.org/pdf/2509.07335v1>|提出了一种利用高斯滤波细化骨骼拓扑图和门控循环单元增强信息传播的图卷积网络方法，有效区分了骨骼动作识...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Enhancing Traffic Incident Response through Sub-Second Temporal Localization with HybridMamba|通过混合Mamba实现毫秒级时间定位以增强交通事故应急响应|Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma|<http://arxiv.org/pdf/2504.03235v2>|提出HybridMamba架构，融合视觉变换器和状态空间时间建模，实现高精度交通事故时间定位。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|IntuiTF: MLLM-Guided Transfer Function Optimization for Direct Volume Rendering|直觉TF：基于多模态大型语言模型引导的传输函数优化用于直接体渲染|Yiyao Wang, Bo Pan, Ke Wang, Han Liu, Jinyuan Mao, Yuxin Liu, Minfeng Zhu, Xiuqi Huang .etc.|<http://arxiv.org/pdf/2506.18407v2>|[代码](https://github.com/wyysteelhead/IntuiTF); 提出了一种利用多模态大语言模型指导直接体渲染中传输函数优化的新框架，有效缩小了用户意图与传输函数参数...|


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MIRROR: Multi-Modal Pathological Self-Supervised Representation Learning via Modality Alignment and Retention|MIRROR：通过模态对齐与保留的多模态病理自监督表征学习|Tianyi Wang, Jianan Fan, Dingxin Zhang, Dongnan Liu, Yong Xia, Heng Huang, Weidong Cai|<http://arxiv.org/pdf/2503.00374v3>|提出MIRROR方法，通过模态对齐和保留实现病理多模态表征学习，提升癌症分型和生存分析性能。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dynamic Scene 3D Reconstruction of an Uncooperative Resident Space Object|动态场景下非合作居民空间目标的3D重建|Bala Prenith Reddy Gopu, Timothy Jacob Huber, George M. Nehma, Patrick Quinn, Madhur Tiwari, Matt Ueckermann, David Hinckley, Christopher McKenna|<http://arxiv.org/pdf/2509.07932v1>|提出了一种模拟环境评估3D重建算法，实现了对翻滚卫星的高精度几何建模。|
|🆕 发布|Accelerating Local AI on Consumer GPUs: A Hardware-Aware Dynamic Strategy for YOLOv10s|加速消费级GPU上的本地AI：面向YOLOv10s的硬件感知动态策略|Mahmudul Islam Masum, Miad Islam, Arif I. Sarwat|<http://arxiv.org/pdf/2509.07928v1>|提出了一种硬件感知的动态策略，通过两阶段自适应推理显著提升了消费者级GPU上YOLOv10s的运行效...|
|📝 更新|Hybrid-Regularized Magnitude Pruning for Robust Federated Learning under Covariate Shift|混合正则化幅度剪枝以实现协变量偏移下的稳健联邦学习|Ozgu Goksu, Nicolas Pugeault|<http://arxiv.org/pdf/2412.15010v2>|提出一种结合剪枝和正则化的联邦学习框架，增强模型在数据异质性下的鲁棒性和泛化能力。|
|📝 更新|A Data-Free Analytical Quantization Scheme for Deep Learning Models|无数据分析量化方案用于深度学习模型|Ahmed Luqman, Khuzemah Qazi, Murray Patterson, Malik Jahan Khan, Imdadullah Khan|<http://arxiv.org/pdf/2412.07391v3>|提出了一种无需数据即可优化的深度学习模型量化方法，有效减少模型大小和计算需求同时保持准确度。|
|🆕 发布|EfficientNet in Digital Twin-based Cardiac Arrest Prediction and Analysis|基于数字孪生的EfficientNet在心脏骤停预测与分析中的应用|Qasim Zia, Avais Jan, Zafar Iqbal, Muhammad Mumtaz Ali, Mukarram Ali, Murray Patterson|<http://arxiv.org/pdf/2509.07388v1>|结合EfficientNet和数字孪生技术，提出了一种提高心脏骤停早期检测与分析准确性和效率的新框架...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Signal-Based Malware Classification Using 1D CNNs|基于一维卷积神经网络的信号型恶意软件分类|Jack Wilkie, Hanan Hindy, Ivan Andonovic, Christos Tachtatzis, Robert Atkinson|<http://arxiv.org/pdf/2509.06548v2>|该研究通过将恶意软件二进制文件转化为1D信号并用1D CNN进行分类，有效减少了信息损失并提升了分类...|
|📝 更新|A multi-task neural network for atypical mitosis recognition under domain shift|一种面向域偏移下非典型有丝分裂识别的多任务神经网络|Gennaro Percannella, Mattia Sarno, Francesco Tortorella, Mario Vento|<http://arxiv.org/pdf/2508.21035v3>|提出了一种多任务学习策略，通过辅助任务帮助模型在领域迁移下准确识别异常有丝分裂图像。|
|📝 更新|Comparative Analysis of Lightweight Deep Learning Models for Memory-Constrained Devices|轻量级深度学习模型在内存受限设备上的比较分析|Tasnim Shahriar|<http://arxiv.org/pdf/2505.03303v2>|评估了五种轻量级深度学习模型在内存受限设备上的表现，揭示了准确性与效率间的权衡，为边缘计算和移动平台...|
|🆕 发布|Neural Cone Radiosity for Interactive Global Illumination with Glossy Materials|神经锥形辐射度：用于具有光泽材料交互式全局照明的算法|Jierui Ren, Haojie Jin, Bo Pang, Yisong Chen, Guoping Wang, Sheng Li|<http://arxiv.org/pdf/2509.07522v1>|提出了一种基于神经辐射度框架的反射感知射线锥编码方法，有效捕捉高频率、强视向依赖的反射分布。|
|📝 更新|HodgeFormer: Transformers for Learnable Operators on Triangular Meshes through Data-Driven Hodge Matrices|HodgeFormer：通过数据驱动Hodge矩阵在三角形网格上学习算子的变换器|Akis Nousias, Stavros Nousias|<http://arxiv.org/pdf/2509.01839v3>|提出了一种基于Transformer架构的HodgeFormer方法，通过数据驱动学习离散算子，无需...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A smart fridge with AI-enabled food computing|人工智能驱动的智能冰箱食物计算系统|Khue Nong Thuc, Khoa Tran Nguyen Anh, Tai Nguyen Huy, Du Nguyen Hao Hong, Khanh Dinh Ba|<http://arxiv.org/pdf/2509.07400v1>|提出了一种集成物联网与计算机视觉的智能冰箱系统，通过实时检测和库存管理减少食物浪费并优化消费。|
|📝 更新|VMGNet: A Low Computational Complexity Robotic Grasping Network Based on VMamba with Multi-Scale Feature Fusion|VMGNet：一种基于VMamba的多尺度特征融合的低计算复杂度机器人抓取网络|Yuhao Jin, Qizhong Gao, Xiaohui Zhu, Yong Yue, Eng Gee Lim, Yuqing Chen, Prudence Wong, Yijie Chu|<http://arxiv.org/pdf/2411.12520v2>|提出VMGNet模型，通过引入视觉状态空间和轻量级多尺度特征融合，实现了低计算复杂度的机器人抓取任务...|
|📝 更新|Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution|卷积与BSConv多深度蒸馏网络用于轻量级图像超分辨率|Akram Khatami-Rizi, Ahmad Mahmoudi-Aznaveh|<http://arxiv.org/pdf/2503.14779v2>|[代码](https://github.com/akramkhatami/IBMDN.); 提出了一种轻量级图像超分辨率网络，通过Involution和BSConv多深度蒸馏块提升重建质量同时...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Evolving from Unknown to Known: Retentive Angular Representation Learning for Incremental Open Set Recognition|从未知到已知：用于增量开放集识别的保持角表示学习|Runqing Yang, Yimin Fu, Changyuan Wu, Zhunga Liu|<http://arxiv.org/pdf/2509.06570v2>|提出了一种用于增量开放集识别的保留角表示学习方法，有效解决了模型在动态场景中维持判别性边界的问题。|
|🆕 发布|Enhancing Online Learning by Integrating Biosensors and Multimodal Learning Analytics for Detecting and Predicting Student Behavior: A Review|通过整合生物传感器与多模态学习分析来增强在线学习，用于检测和预测学生行为：综述|Alvaro Becerra, Ruth Cobos, Charles Lang|<http://arxiv.org/pdf/2509.07742v1>|整合生物传感器与多模态学习分析，提升在线学习行为预测与个性化体验。|
|🆕 发布|Understanding Ice Crystal Habit Diversity with Self-Supervised Learning|理解自监督学习在冰晶习性多样性中的应用|Joseph Ko, Hariprasath Govindarajan, Fredrik Lindsten, Vanessa Przybylo, Kara Sulia, Marcus van Lier-Walqui, Kara Lamb|<http://arxiv.org/pdf/2509.07688v1>|利用自监督学习从云粒子图像中学习冰晶形态表征，有效量化冰晶多样性以约束地球气候系统中的角色。|
|🆕 发布|Can SSD-Mamba2 Unlock Reinforcement Learning for End-to-End Motion Control?|SSD-Mamba2能否解锁端到端运动控制的强化学习？|Gavin Tao, Yinuo Wang, Jinzhao Zhou|<http://arxiv.org/pdf/2509.07593v1>|提出了一种基于SSD-Mamba2的视觉驱动跨模态强化学习框架，实现了高效、长距离依赖的端到端运动控...|
|🆕 发布|XOCT: Enhancing OCT to OCTA Translation via Cross-Dimensional Supervised Multi-Scale Feature Learning|XOCT：通过跨维度监督多尺度特征学习增强OCT至OCTA的转换|Pooya Khosravi, Kun Han, Anthony T. Wu, Arghavan Rezvani, Zexin Feng, Xiaohui Xie|<http://arxiv.org/pdf/2509.07455v1>|[代码](https://github.com/uci-cbcl/XOCT.); 提出XOCT框架，融合跨维度监督与多尺度特征融合，提升OCT到OCTA图像转换的精确度和细节表现。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 目标导向视觉决策 (Goal-oriented Visual Decision Making)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Prompt the Unseen: Evaluating Visual-Language Alignment Beyond Supervision|“激发未见：在监督之外评估视觉-语言对齐”|Raehyuk Jung, Seungjun Yu, Hyunjung Shim|<http://arxiv.org/pdf/2509.00700v2>|提出了一种评估视觉语言模型投影层泛化能力的基准，揭示了其在未见视觉概念上的显著泛化性能。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visual-TableQA: Open-Domain Benchmark for Reasoning over Table Images|视觉-表格问答：面向表格图像推理的开域基准|Boammani Aser Lompo, Marc Haraoui|<http://arxiv.org/pdf/2509.07966v1>|[代码](https://github.com/AI-4-Everyone/Visual-TableQA.); 提出了Visual-TableQA，一个大规模开放域多模态数据集，通过模块化生成流程提升视觉推理能力...|
|🆕 发布|CAViAR: Critic-Augmented Video Agentic Reasoning|CAViAR：批评增强的视频智能推理|Sachit Menon, Ahmet Iscen, Arsha Nagrani, Tobias Weyand, Carl Vondrick, Cordelia Schmid|<http://arxiv.org/pdf/2509.07680v1>|提出了一种结合大语言模型和视频模块的智能体，通过引入评判机制提升复杂视频推理性能。|
|🆕 发布|Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search|"Mini-o3：扩展推理模式与交互轮次以提升视觉搜索"|Xin Lai, Junyi Li, Wei Li, Tao Liu, Tianjian Li, Hengshuang Zhao|<http://arxiv.org/pdf/2509.07969v1>|提出了一种扩展工具式交互的系统Mini-o3，实现多轮深度推理以解决视觉搜索难题。|
|📝 更新|MaRVL-QA: A Benchmark for Mathematical Reasoning over Visual Landscapes|MaRVL-QA：面向视觉景观的数学推理基准|Nilay Pande, Sahiti Yerramilli, Jayant Sravan Tamarapalli, Rynaa Grover|<http://arxiv.org/pdf/2508.17180v2>|提出了MaRVL-QA基准，用于评估大型多模态语言模型在数学和空间推理方面的能力。|
|🆕 发布|D-LEAF: Localizing and Correcting Hallucinations in Multimodal LLMs via Layer-to-head Attention Diagnostics|D-LEAF：通过层到头注意力诊断定位和纠正多模态大型语言模型中的幻觉现象|Tiancheng Yang, Lin Zhang, Jiaye Lin, Guimin Hu, Di Wang, Lijie Hu|<http://arxiv.org/pdf/2509.07864v1>|提出方法D-LEAF，通过诊断和动态调整注意力，有效减少大型多模态语言模型生成文本与视觉输入的冲突。|
|📝 更新|$π^3$: Permutation-Equivariant Visual Geometry Learning|$π^3$：置换等价视觉几何学习|Yifan Wang, Jianjun Zhou, Haoyi Zhu, Wenzheng Chang, Yang Zhou, Zizun Li, Junyi Chen, Jiangmiao Pang .etc.|<http://arxiv.org/pdf/2507.13347v2>|提出了一种无需固定参考视角的视觉几何重建神经网络，实现了更高准确性和鲁棒性。|
|📝 更新|Towards Visuospatial Cognition via Hierarchical Fusion of Visual Experts|面向视觉空间认知的视觉专家层次融合方法|Qi Feng|<http://arxiv.org/pdf/2505.12363v4>|提出ViCA2模型，通过双视觉编码器和专门数据集提升空间推理能力。|
|🆕 发布|TextlessRAG: End-to-End Visual Document RAG by Speech Without Text|无文本RAG：通过语音实现无需文本的端到端视觉文档RAG|Peijin Xie, Shun Qian, Bingquan Liu, Dexin Wang, Lin Sun, Xiangzheng Zhang|<http://arxiv.org/pdf/2509.07538v1>|[代码](https://github.com/xiepeijinhit-hue/textlessrag); 提出首个端到端无文本视觉文档问答框架TextlessRAG，直接处理语音查询和文档图像，无需ASR、...|
|🆕 发布|Fine-Tuning Vision-Language Models for Visual Navigation Assistance|为视觉导航辅助微调视觉-语言模型|Xiao Li, Bharat Gandhi, Ming Zhan, Mohit Nehra, Zhicheng Zhang, Yuchen Sun, Meijia Song, Naisheng Zhang .etc.|<http://arxiv.org/pdf/2509.07488v1>|提出一种结合视觉和语言模型的方法，通过微调BLIP-2模型并使用LoRA技术，为视障人士生成室内导航...|
|🆕 发布|In the Eye of MLLM: Benchmarking Egocentric Video Intent Understanding with Gaze-Guided Prompting|在MLLM之眼：以视线引导提示为基准的自主视角视频意图理解|Taiying Peng, Jiacheng Hua, Miao Liu, Feng Lu|<http://arxiv.org/pdf/2509.07447v1>|提出EgoGazeVQA基准，利用视线信息提升大型语言模型对第一视角视频用户意图的理解。|
|📝 更新|HueManity: Probing Fine-Grained Visual Perception in MLLMs|《HueManity：在多模态大型语言模型中探究细粒度视觉感知》|Rynaa Grover, Jayant Sravan Tamarapalli, Sahiti Yerramilli, Nilay Pande|<http://arxiv.org/pdf/2506.03194v3>|提出HueManity基准，揭示了MLLMs在细微视觉感知任务上的不足，并分析了原因。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GLEAM: Learning to Match and Explain in Cross-View Geo-Localization|GLEAM：在跨视图地理定位中学习匹配与解释|Xudong Lu, Zhi Zheng, Yi Wan, Yongxiang Yao, Annan Wang, Renrui Zhang, Panwang Xia, Qiong Wu .etc.|<http://arxiv.org/pdf/2509.07450v1>|[代码](https://github.com/Lucky-Lance/GLEAM.); 提出GLEAM模型，整合多视角图像并引入解释性推理，提升地理定位的准确性与透明度。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Missing Fine Details in Images: Last Seen in High Frequencies|图像中缺失的细微细节：在高频中最后一次出现|Tejaswini Medi, Hsien-Yi Wang, Arianna Rampini, Margret Keuper|<http://arxiv.org/pdf/2509.05441v2>|提出了一种频率感知的变分自编码器，有效恢复了图像中的高频细节，提升了生成图像的真实感。|
|🆕 发布|Data-Efficient Fine-Tuning of Vision-Language Models for Diagnosis of Alzheimer's Disease|数据高效微调视觉语言模型用于阿尔茨海默病的诊断|Fangqi Cheng, Surajit Ray, Xiaochen Yang|<http://arxiv.org/pdf/2509.07613v1>|提出了一种高效利用元数据和临床知识的三维医学影像诊断方法，显著提升阿尔茨海默症诊断准确率。|
|📝 更新|Atomizer: Generalizing to new modalities by breaking satellite images down to a set of scalars|Atomizer：通过将卫星图像分解为一组标量来实现对新模态的泛化|Hugo Riffaud de Turckheim, Sylvain Lobry, Roberto Interdonato, Diego Marcos|<http://arxiv.org/pdf/2506.13542v2>|提出了一种灵活的Atomizer架构，将遥感图像分解为包含丰富上下文信息的标量集合，实现跨模态的泛化...|
|🆕 发布|HU-based Foreground Masking for 3D Medical Masked Image Modeling|基于HU的医学三维蒙版图像建模的前景遮罩技术|Jin Lee, Vu Dang, Gwang-Hyun Yu, Anh Le, Zahid Rahman, Jin-Ho Jang, Heonzoo Lee, Kun-Yung Kim .etc.|<http://arxiv.org/pdf/2509.07534v1>|[代码](https://github.com/AISeedHub/SubFore); 提出基于HU测量的前景掩码策略，优化3D医疗图像的分割质量。|
|📝 更新|OOD-SEG: Exploiting out-of-distribution detection techniques for learning image segmentation from sparse multi-class positive-only annotations|OOD-SEG：利用分布外检测技术从稀疏多类仅正样本注释中学习图像分割|Junwen Wang, Zhonghao Wang, Oscar MacCormac, Jonathan Shapey, Tom Vercauteren|<http://arxiv.org/pdf/2411.09553v3>|提出了一种利用异常检测技术从稀疏多类正类标注学习图像分割的方法，有效解决了标注成本高和异常像素处理问...|
|🆕 发布|MedicalPatchNet: A Patch-Based Self-Explainable AI Architecture for Chest X-ray Classification|医学补丁网络：一种基于补丁的自解释人工智能架构用于胸部X射线分类|Patrick Wienholt, Christiane Kuhl, Jakob Nikolas Kather, Sven Nebelung, Daniel Truhn|<http://arxiv.org/pdf/2509.07477v1>|[代码](https://github.com/TruhnLab/MedicalPatchNet); 提出了一种自解释的MedicalPatchNet架构，通过独立分析图像块来提高胸部X光分类的透明度和...|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Self-Supervised Cross-Encoder for Neurodegenerative Disease Diagnosis|自监督交叉编码器用于神经退行性疾病诊断|Fangqi Cheng, Yingying Zhao, Xiaochen Yang|<http://arxiv.org/pdf/2509.07623v1>|提出了一种自监督交叉编码框架，通过利用MRI扫描的时间连续性进行监督，有效提升了神经退行性疾病诊断的...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GCRPNet: Graph-Enhanced Contextual and Regional Perception Network for Salient Object Detection in Optical Remote Sensing Images|GCRPNet：图增强的上下文与区域感知网络用于光学遥感图像中的显著目标检测|Mengyu Ren, Yutong Li, Hua Li, Runmin Cong, Sam Kwong|<http://arxiv.org/pdf/2508.10542v3>|提出了一种图增强的感知网络GCRPNet，有效整合全局与局部特征，提升光学遥感图像中的显著目标检测性...|
|🆕 发布|Generating Transferrable Adversarial Examples via Local Mixing and Logits Optimization for Remote Sensing Object Recognition|通过局部混合和 logits 优化生成可迁移的对抗性示例用于遥感目标识别|Chun Liu, Hailong Wang, Bingqian Zhu, Panpan Ding, Zheng Zheng, Tao Xu, Zhigang Han, Jiayao Wang|<http://arxiv.org/pdf/2509.07495v1>|提出局部混合与 logits 优化新框架，增强遥感对象识别中对抗样本的迁移性。|
|📝 更新|HieraRS: A Hierarchical Segmentation Paradigm for Remote Sensing Enabling Multi-Granularity Interpretation and Cross-Domain Transfer|层次化遥感分割范式HieraRS：实现多粒度解释与跨域迁移|Tianlong Ai, Tianzhu Liu, Haochen Jiang, Yanfeng Gu|<http://arxiv.org/pdf/2507.08741v2>|[代码](https://github.com/AI-Tianlong/HieraRS.); 提出了一种分层解释范式HieraRS，实现多粒度预测并支持跨域任务中的异构层次转移。|
|🆕 发布|DEPF: A UAV Multispectral Object Detector with Dual-Domain Enhancement and Priority-Guided Mamba Fusion|双域增强与优先级引导的Mamba融合无人机多光谱目标检测器（DEPF）|Shucong Li, Zhenyu Liu, Zijie Hong, Zhiheng Zhou, Xianghai Cao|<http://arxiv.org/pdf/2509.07327v1>|提出了一种针对无人机多光谱目标检测的方法，通过双域增强和优先级引导的融合技术，有效提升了低光照条件下...|
|📝 更新|RSCC: A Large-Scale Remote Sensing Change Caption Dataset for Disaster Events|遥感变化标注数据集：面向灾害事件的大规模遥感变化标注数据集|Zhenyuan Chen, Chenxi Wang, Ningyu Zhang, Feng Zhang|<http://arxiv.org/pdf/2509.01907v2>|[代码](https://github.com/Bili-Sakura/RSCC.); 构建了大规模遥感变化标注数据集RSCC，助力灾难监测的时序图像理解和分析。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bias-Aware Machine Unlearning: Towards Fairer Vision Models via Controllable Forgetting|偏向感知的机器遗忘：通过可控遗忘实现更公平的视觉模型|Sai Siddhartha Chary Aylapuram, Veeraraju Elluru, Shivang Agarwal|<http://arxiv.org/pdf/2509.07456v1>|提出了一种偏差感知的机器遗忘方法，通过选择性移除偏置样本或特征表示，有效减少视觉模型中的多种偏见。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Semi-SMD: Semi-Supervised Metric Depth Estimation via Surrounding Cameras for Autonomous Driving|半监督度量深度估计：通过周围相机为自动驾驶系统实现半监督学习|Yusen Xie, Zhengmin Huang, Shaojie Shen, Jun Ma|<http://arxiv.org/pdf/2503.19713v3>|[代码](https://github.com/xieyuser/Semi-SMD.); 提出了一种用于自动驾驶的 Surrounding Cameras 设备的半监督度量深度估计框架，通过...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 可解释视觉智能 (Explainable Visual Intelligence)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|One Flight Over the Gap: A Survey from Perspective to Panoramic Vision|《一瞥跨越鸿沟：从透视到全景视觉的综述》|Xin Lin, Xian Ge, Dizhe Zhang, Zhaoliang Wan, Xianshun Wang, Xiangtai Li, Wenjie Jiang, Bo Du .etc.|<http://arxiv.org/pdf/2509.04444v2>|[代码](https://insta360-research-team.github.io/Survey-of-Panorama); 系统梳理了从传统视角图像到全景图像的转换挑战及应对策略，分类全景视觉研究为四大领域。|
|📝 更新|From Images to Insights: Explainable Biodiversity Monitoring with Plain Language Habitat Explanations|从图像到洞察：基于通俗易懂生境解释的可解释生物多样性监测|Yutong Zhou, Masahiro Ryo|<http://arxiv.org/pdf/2506.10559v2>|[代码](https://github.com/Yutong-Zhou-cv/BioX.); 提出了一种将物种图像转化为可解释的栖息地偏好因果洞察的端到端框架，助力非专业人士理解生态系统和保护生...|


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Visuospatial Cognitive Assistant|视觉空间认知助手|Qi Feng|<http://arxiv.org/pdf/2505.12312v4>|提出大规模室内视频问答数据集ViCA-322K，并训练出表现卓越的ViCA-7B模型，提升视觉空间认...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RayGaussX: Accelerating Gaussian-Based Ray Marching for Real-Time and High-Quality Novel View Synthesis|《RayGaussX：加速基于高斯的光线行进算法，实现实时高质量新视角合成》|Hugo Blanc, Jean-Emmanuel Deschaud, Alexis Paljic|<http://arxiv.org/pdf/2509.07782v1>|[代码](https://raygaussx.github.io/.); RayGaussX通过引入加速策略和优化技术，大幅提升了Gaussian-based ray mar...|
|📝 更新|Hybrid Swin Attention Networks for Simultaneously Low-Dose PET and CT Denoising|混合Swin注意力网络用于同时实现低剂量PET和CT去噪|Yichao Liu, Hengzhi Xue, YueYang Teng|<http://arxiv.org/pdf/2509.06591v2>|提出了一种Hybrid Swin Attention Network，有效提升了低剂量PET和CT图...|
|📝 更新|PATS: Proficiency-Aware Temporal Sampling for Multi-View Sports Skill Assessment|PATS：面向技能熟练度感知的多视角体育技能评估时间采样方法|Edoardo Bianchi, Antonio Liotta|<http://arxiv.org/pdf/2506.04996v3>|提出了一种保持完整运动模式的自适应时间采样策略PATS，显著提升了多视角运动技能评估的准确性。|

