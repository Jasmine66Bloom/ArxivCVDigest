## [UPDATED!] **2025-09-10** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PianoVAM: A Multimodal Piano Performance Dataset|钢琴视觉动作建模：一种多模态钢琴演奏数据集|Yonghyun Kim, Junhyung Park, Joonhyung Bae, Kirak Kim, Taegyun Kwon, Alexander Lerch, Juhan Nam|<http://arxiv.org/pdf/2509.08800v1>|介绍了PianoVAM多模态钢琴表演数据集，包含视频、音频、MIDI等信息，用于提升音乐信息检索性能...|
|📝 更新|LLaDA-VLA: Vision Language Diffusion Action Models|LLaDA-VLA：视觉语言扩散动作模型|Yuqing Wen, Hebei Li, Kefan Gu, Yucheng Zhao, Tiancai Wang, Xiaoyan Sun|<http://arxiv.org/pdf/2509.06932v2>|提出首个基于扩散模型的机器人操控视觉语言动作模型LLaDA-VLA，通过特殊动作标记分类和层级动作解...|
|🆕 发布|RoentMod: A Synthetic Chest X-Ray Modification Model to Identify and Correct Image Interpretation Model Shortcuts|RoentMod：一种合成胸部X射线修改模型，用于识别和纠正图像解释模型捷径|Lauren H. Cooke, Matthias Jung, Jan M. Brendel, Nora M. Kerkovits, Borek Foldyna, Michael T. Lu, Vineet K. Raghu|<http://arxiv.org/pdf/2509.08640v1>|提出RoentMod模型，通过生成合成病变的X光图像，揭示了并纠正了深度学习模型在医学图像解释中的捷...|
|🆕 发布|Foundation Models for Autonomous Driving Perception: A Survey Through Core Capabilities|自动驾驶感知的基础模型：通过核心能力进行的综述|Rajendramayavan Sathyam, Yueqi Li|<http://arxiv.org/pdf/2509.08302v1>|概述了基础模型如何通过四大核心能力提升自动驾驶感知的泛化性、可扩展性和鲁棒性。|
|🆕 发布|An Open Benchmark Dataset for GeoAI Foundation Models for Oil Palm Mapping in Indonesia|印度尼西亚油棕种植地图绘制用GeoAI基础模型的开源基准数据集|M. Warizmi Wafiq, Peter Cutter, Ate Poortinga, Daniel Marc G. dela Torre, Karis Tenneson, Vanna Teck, Enikoe Bihari, Chanarun Saisaward .etc.|<http://arxiv.org/pdf/2509.08303v1>|构建了一个开放的地理空间数据集，助力追踪印尼油棕种植，促进可持续发展与监管。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Calibrating MLLM-as-a-judge via Multimodal Bayesian Prompt Ensembles|通过多模态贝叶斯提示集成校准MLLM作为评判标准|Eric Slyman, Mehrab Tanjim, Kushal Kafle, Stefan Lee|<http://arxiv.org/pdf/2509.08777v1>|提出了一种针对文本到图像任务的多模态贝叶斯提示集成方法，有效提升了评估模型的准确性和校准性。|
|🆕 发布|Vision-Language Semantic Aggregation Leveraging Foundation Model for Generalizable Medical Image Segmentation|利用基础模型进行视觉-语言语义聚合以实现通用医疗图像分割|Wenjun Yu, Yinchen Zhou, Jia-Xuan Jiang, Shubin Zeng, Yuee Li, Zhong Wang|<http://arxiv.org/pdf/2509.08570v1>|提出了一种语义聚合机制，通过动态特征聚类和文本引导解码器，有效提升了医学图像分割的泛化能力。|
|📝 更新|TerraMind: Large-Scale Generative Multimodality for Earth Observation|“TerraMind：地球观测的大规模生成多模态”|Johannes Jakubik, Felix Yang, Benedikt Blumenstiel, Erik Scheurer, Rocco Sedona, Stefano Maurogiovanni, Jente Bosmans, Nikolaos Dionelis .etc.|<http://arxiv.org/pdf/2504.11171v4>|TerraMind提出首个地球观测任意模态生成模型，通过双尺度融合实现零样本和少样本应用，并引入生成...|
|🆕 发布|HuMo: Human-Centric Video Generation via Collaborative Multi-Modal Conditioning|《 HuMo：通过协作多模态调节实现以人为中心的视频生成》|Liyang Chen, Tianxiang Ma, Jiawei Liu, Bingchuan Li, Zhuowei Chen, Lijie Liu, Xu He, Gen Li .etc.|<http://arxiv.org/pdf/2509.08519v1>|[代码](https://phantom-video.github.io/HuMo.); 提出了一种统一的人为中心视频生成框架，通过构建高质量数据集和分阶段训练策略，有效整合多模态信息。|
|🆕 发布|Retrieval-Augmented VLMs for Multimodal Melanoma Diagnosis|用于多模态黑色素瘤诊断的检索增强型视觉语言模型|Jihyun Moon, Charmgil Hong|<http://arxiv.org/pdf/2509.08338v1>|分类诊断恶性黑色素瘤时，提出利用检索增强的视觉语言模型融合相似病例信息，提高了准确性和纠错能力。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Rethinking Random Masking in Self-Distillation on ViT|重新思考在ViT自蒸馏中的随机遮蔽策略|Jihyeon Seong, Hyunkyung Han|<http://arxiv.org/pdf/2506.10582v3>|提出了一种不对称的随机遮蔽策略，通过保留学生网络的局部视图和教师网络的完整视图，增强了视觉Trans...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Computational Imaging for Enhanced Computer Vision|计算成像技术在增强计算机视觉中的应用|Humera Shaikh, Kaur Jashanpreet|<http://arxiv.org/pdf/2509.08712v1>|这篇论文探讨了计算成像技术如何提升计算机视觉系统在复杂环境下的性能。|
|🆕 发布|Lightweight Deep Unfolding Networks with Enhanced Robustness for Infrared Small Target Detection|轻量级深度展开网络增强鲁棒性用于红外小目标检测|Jingjing Liu, Yinchao Han, Xianchao Xiu, Jianhua Zhang, Wanquan Liu|<http://arxiv.org/pdf/2509.08205v1>|[代码](https://github.com/xianchaoxiu/L-RPCANet.); 提出了一种基于RPCA的轻量级网络，通过瓶颈结构和噪声减少模块提升红外小目标检测的效率和鲁棒性。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CrowdQuery: Density-Guided Query Module for Enhanced 2D and 3D Detection in Crowded Scenes|人群查询：用于增强拥挤场景中2D和3D检测的密度引导查询模块|Marius Dähling, Sebastian Krebs, J. Marius Zöllner|<http://arxiv.org/pdf/2509.08738v1>|[代码](https://github.com/mdaehl/CrowdQuery.); 提出了一种利用对象密度信息提升拥挤场景中2D和3D检测性能的CrowdQuery方法。|
|🆕 发布|A Structured Review of Underwater Object Detection Challenges and Solutions: From Traditional to Large Vision Language Models|水下目标检测挑战与解决方案的结构化综述：从传统方法到大型视觉语言模型|Edwine Nabahirwa, Wei Song, Minghua Zhang, Yi Fang, Zhou Ni|<http://arxiv.org/pdf/2509.08490v1>|系统分析了水下目标检测挑战，并探索大型视觉语言模型的潜力以提升检测性能。|
|📝 更新|Vision Transformer with Sparse Scan Prior|具有稀疏扫描先验的视觉变换器|Yuguang Zhang, Qihang Fan, Huaibo Huang|<http://arxiv.org/pdf/2405.13335v2>|提出稀疏扫描自注意力机制，减少视觉模型计算负担，实现高效图像处理。|
|🆕 发布|Dual-Thresholding Heatmaps to Cluster Proposals for Weakly Supervised Object Detection|双阈值热图聚类提议用于弱监督目标检测|Yuelin Guo, Haoyu He, Zhiyuan Chen, Zitong Huang, Renhao Lu, Lu Shi, Zejun Wang, Weizhe Zhang|<http://arxiv.org/pdf/2509.08289v1>|[代码](https://github.com/gyl2565309278/DTH-CP.); 提出双阈值热图聚类方法，优化弱监督目标检测的伪标签生成和模型收敛速度。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|P3-SAM: Native 3D Part Segmentation|P3-SAM：原生三维部件分割|Changfeng Ma, Yang Li, Xinhao Yan, Jiachen Xu, Yunhan Yang, Chunshi Wang, Zibo Zhao, Yanwen Guo .etc.|<http://arxiv.org/pdf/2509.06784v3>|提出了一种自动化3D物体部件分割的新模型P3-SAM，实现了对复杂物体的精确分割和强鲁棒性。|
|📝 更新|Sigma: Siamese Mamba Network for Multi-Modal Semantic Segmentation|Sigma：用于多模态语义分割的 Siamese Mamba 网络|Zifu Wan, Pingping Zhang, Yuhao Wang, Silong Yong, Simon Stepputtis, Katia Sycara, Yaqi Xie|<http://arxiv.org/pdf/2404.04256v3>|[代码](https://github.com/zifuwan/Sigma.); 提出了一种多模态语义分割网络Sigma，利用Siamese Mamba结构实现线性复杂度的全局感知，...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LYT-NET: Lightweight YUV Transformer-based Network for Low-light Image Enhancement|LYT-网络：基于轻量级YUV变换器的低光照图像增强网络|A. Brateanu, R. Balmez, A. Avram, C. Orhei, C. Ancuti|<http://arxiv.org/pdf/2401.15204v7>|[代码](https://github.com/albrateanu/LYT-Net); 提出了一种基于轻量级YUV变换器的低光照图像增强网络，通过分离处理色彩和亮度通道，实现了高效照明调整...|
|🆕 发布|Beyond Distribution Shifts: Adaptive Hyperspectral Image Classification at Test Time|超越分布偏移：测试时的自适应高光谱图像分类|Xia Yue, Anfeng Liu, Ning Chen, Chenjia Huang, Hui Liu, Zhou Huang, Leyuan Fang|<http://arxiv.org/pdf/2509.08436v1>|提出了一种统一框架HyperTTA，通过构建多退化数据集和测试时自适应策略，增强了高光谱图像分类模型...|
|📝 更新|Nearest Neighbor Projection Removal Adversarial Training|最近邻投影移除对抗训练|Himanshu Singh, A. V. Subramanyam, Shivank Rajput, Mohan Kankanhalli|<http://arxiv.org/pdf/2509.07673v2>|提出了一种通过投影消除类间依赖的对抗训练框架，有效增强了深度神经网络的鲁棒性。|
|🆕 发布|SimCroP: Radiograph Representation Learning with Similarity-driven Cross-granularity Pre-training|SimCroP：基于相似性驱动的跨粒度预训练的X射线图像表征学习|Rongsheng Wang, Fenghe Tang, Qingsong Yao, Rui Yan, Xu Zhang, Zhen Huang, Haoran Lai, Zhiyang He .etc.|<http://arxiv.org/pdf/2509.08311v1>|[代码](https://github.com/ToniChopp/SimCroP.); 提出SimCroP框架，通过相似性驱动对齐和跨粒度融合提升胸部CT影像解读能力。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RewardDance: Reward Scaling in Visual Generation|《RewardDance：视觉生成中的奖励缩放》|Jie Wu, Yu Gao, Zilyu Ye, Ming Li, Liang Li, Hanzhong Guo, Jie Liu, Zeyue Xue .etc.|<http://arxiv.org/pdf/2509.08826v1>|提出RewardDance框架，通过创新性奖励机制有效解决视觉生成中的奖励缩放和奖励劫持问题。|
|📝 更新|CamC2V: Context-aware Controllable Video Generation|《CamC2V：基于上下文的可控视频生成》|Luis Denninger, Sina Mokhtarzadeh Azar, Juergen Gall|<http://arxiv.org/pdf/2504.06022v2>|提出CamC2V模型，通过结合多图像条件和3D约束实现更连贯和上下文感知的视频生成。|
|🆕 发布|GeneVA: A Dataset of Human Annotations for Generative Text to Video Artifacts|基因视觉注释数据集：用于生成性文本到视频制品的人类注释集|Jenna Kang, Maria Silva, Patsorn Sangkloy, Kenneth Chen, Niall Williams, Qi Sun|<http://arxiv.org/pdf/2509.08818v1>|介绍了GeneVA数据集，包含丰富的人工标注，专注于文本驱动的视频生成中的时空错误。|
|📝 更新|Reangle-A-Video: 4D Video Generation as Video-to-Video Translation|《Reangle-A-Video：视频到视频转换的四维视频生成》|Hyeonho Jeong, Suhyeon Lee, Jong Chul Ye|<http://arxiv.org/pdf/2503.09151v3>|[代码](https://hyeonho99.github.io/reangle-a-video); 提出了一种将多视角视频生成任务转化为视频到视频翻译的框架，通过自监督学习和一致性指导生成同步多视角视...|
|📝 更新|GenFlow: Interactive Modular System for Image Generation|《GenFlow：交互式模块化图像生成系统》|Duc-Hung Nguyen, Huu-Phuc Huynh, Minh-Triet Tran, Trung-Nghia Le|<http://arxiv.org/pdf/2506.21369v2>|提出GenFlow框架，简化生成艺术创作流程，实现无门槛图像生成。|
|📝 更新|LED: LLM Enhanced Open-Vocabulary Object Detection without Human Curated Data Generation|LED：无需人工筛选数据生成的LLM增强开放词汇对象检测|Yang Zhou, Shiyu Zhao, Yuxiao Chen, Zhenting Wang, Can Jin, Dimitris N. Metaxas|<http://arxiv.org/pdf/2503.13794v5>|提出了一种融合大型语言模型隐藏状态的方法LED，有效提升了无需人工数据生成的开放词汇目标检测性能。|
|📝 更新|PrediTree: A Multi-Temporal Sub-meter Dataset of Multi-Spectral Imagery Aligned With Canopy Height Maps|PrediTree：一种与冠层高度图对齐的多时相亚米级多光谱影像数据集|Hiyam Debary, Mustansar Fiaz, Levente Klein|<http://arxiv.org/pdf/2509.01202v2>|介绍了PrediTree数据集，通过结合高分辨率时空影像，提升了树木高度预测模型的准确性。|
|📝 更新|Alternating Minimization Schemes for Computing Rate-Distortion-Perception Functions with $f$-Divergence Perception Constraints|交替最小化方案用于计算具有$f$-散度感知约束的率失真感知函数|Giuseppe Serra, Photios A. Stavrou, Marios Kountouris|<http://arxiv.org/pdf/2408.15015v2>|提出交替最小化方案计算率失真感知函数，并保证收敛至全局最优解。|
|🆕 发布|Physics-Guided Rectified Flow for Low-light RAW Image Enhancement|基于物理引导的修正流算法用于低光照RAW图像增强|Juntai Zeng|<http://arxiv.org/pdf/2509.08330v1>|提出了一种结合物理噪声模型的像素级校准方法，通过物理引导的 rectified flow 框架显著提...|
|📝 更新|SGDFuse: SAM-Guided Diffusion for High-Fidelity Infrared and Visible Image Fusion|SGDFuse：基于SAM引导的扩散算法实现高保真红外与可见光图像融合|Xiaoyang Zhang, jinjiang Li, Guodong Fan, Yakun Ju, Linwei Fan, Jun Liu, Alex C. Kot|<http://arxiv.org/pdf/2508.05264v3>|[代码](https://github.com/boshizhang123/SGDFuse.); 提出SGDFuse方法，利用语义引导的扩散模型实现高保真度红外与可见光图像融合。|
|🆕 发布|GTA-Crime: A Synthetic Dataset and Generation Framework for Fatal Violence Detection with Adversarial Snippet-Level Domain Adaptation|《GTA-Crime：一种用于致命暴力检测的合成数据集与对抗性片段级域自适应生成框架》|Seongho Kim, Sejong Ryu, Hyoukjun You, Je Hyeong Hong|<http://arxiv.org/pdf/2509.08232v1>|[代码](https://github.com/ta-ho/GTA-Crime.); 提出了利用《GTA5》生成的GTA-Crime数据集及对抗性片段级域自适应策略，有效提升致命暴力事件...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Quantifying Accuracy of an Event-Based Star Tracker via Earth's Rotation|通过地球自转量化基于事件的星敏感器精度|Dennis Melamed, Connor Hashemi, Scott McCloskey|<http://arxiv.org/pdf/2509.08794v1>|利用地球自转作为基准，验证了事件相机在星跟踪姿态确定中的高精度表现。|
|🆕 发布|Multi-Modal Robust Enhancement for Coastal Water Segmentation: A Systematic HSV-Guided Framework|多模态稳健增强用于海岸水分割：一种系统的HSV引导框架|Zhen Tian, Christos Anagnostopoulos, Qiyuan Wang, Zhiwei Gao|<http://arxiv.org/pdf/2509.08694v1>|[代码](https://github.com/UofgCoastline/ICASSP-2026-Robust-Unet.); 提出了一种基于HSV颜色空间监督和多模态约束的鲁棒增强框架，有效提升了海岸线水体分割的稳定性和质量。|
|🆕 发布|X-Part: high fidelity and structure coherent shape decomposition|X-Part：高保真度和结构一致性的形状分解|Xinhao Yan, Jiachen Xu, Yang Li, Changfeng Ma, Yunhan Yang, Chunshi Wang, Zibo Zhao, Zeqiang Lai .etc.|<http://arxiv.org/pdf/2509.08643v1>|提出X-Part模型，实现高保真度且结构一致的3D形状分部生成，提升控制性和语义分解质量。|
|🆕 发布|LD-ViCE: Latent Diffusion Model for Video Counterfactual Explanations|LD-ViCE：用于视频反事实解释的潜在扩散模型|Payal Varshney, Adriano Lucieri, Christoph Balada, Sheraz Ahmed, Andreas Dengel|<http://arxiv.org/pdf/2509.08422v1>|提出LD-ViCE框架，利用潜在空间扩散模型生成视频反事实解释，提升了解释的实时性和准确性。|
|🆕 发布|EVDI++: Event-based Video Deblurring and Interpolation via Self-Supervised Learning|基于自监督学习的EVDI++：事件视频去模糊与插值|Chi Zhang, Xiang Zhang, Chenxu Jiang, Gui-Song Xia, Lei Yu|<http://arxiv.org/pdf/2509.08260v1>|提出了一种基于事件相机和自监督学习的视频去模糊和插帧框架，有效解决了运动模糊和信息丢失问题。|
|🆕 发布|Generalized Zero-Shot Learning for Point Cloud Segmentation with Evidence-Based Dynamic Calibration|基于证据的动态校准的点云分割广义零样本学习|Hyeonseok Kim, Byeongkeun Kang, Yeejin Lee|<http://arxiv.org/pdf/2509.08280v1>|提出了一种3D点云分割的广义零样本学习方法，通过证据基础的不确定性估计和动态校准，减少了模型对训练过...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LADB: Latent Aligned Diffusion Bridges for Semi-Supervised Domain Translation|潜在对齐扩散桥接用于半监督领域翻译：LADB|Xuqin Wang, Tao Wu, Yanfeng Zhang, Lu Liu, Dong Wang, Mingwei Sun, Yongliang Wang, Niclas Zeller .etc.|<http://arxiv.org/pdf/2509.08628v1>|提出了一种半监督域翻译框架LADB，利用部分成对数据有效桥接域差距，平衡了图像质量与多样性。|
|🆕 发布|EfficientIML: Efficient High-Resolution Image Manipulation Localization|高效IML：高效高分辨率图像操作定位|Jinhan Li, Haoyang He, Lei Xie, Jiangning Zhang|<http://arxiv.org/pdf/2509.08583v1>|提出EfficientIML模型，通过轻量级网络有效定位高分辨率图像中的新型扩散生成篡改。|
|📝 更新|BranchGRPO: Stable and Efficient GRPO with Structured Branching in Diffusion Models|分支GRPO：在扩散模型中具有结构分支的稳定高效GRPO|Yuming Li, Yikai Wang, Yuying Zhu, Zhongyu Zhao, Ming Lu, Qi She, Shanghang Zhang|<http://arxiv.org/pdf/2509.06040v3>|BranchGRPO通过引入分支采样策略优化了GRPO的采样过程，降低计算成本并提升探索多样性。|
|🆕 发布|CLAPS: A CLIP-Unified Auto-Prompt Segmentation for Multi-Modal Retinal Imaging|CLAPS：一种基于CLIP统一的自动提示分割方法用于多模态视网膜成像|Zhihao Zhao, Yinzheng Zhao, Junjie Yang, Xiangtong Yao, Quanmin Liang, Shahrooz Faghihroohi, Kai Huang, Nassir Navab .etc.|<http://arxiv.org/pdf/2509.08618v1>|提出了一种多模态视网膜成像统一分割方法CLAPS，通过自动生成文本和空间提示，克服了现有方法面临的挑...|
|📝 更新|PromptEnhancer: A Simple Approach to Enhance Text-to-Image Models via Chain-of-Thought Prompt Rewriting|PromptEnhancer：通过链式思维提示重写提升文本到图像模型的一种简单方法|Linqing Wang, Ximing Xing, Yiji Cheng, Zhiyuan Zhao, Jiale Tao, Qixun Wang, Ruihuang Li, Comi Chen .etc.|<http://arxiv.org/pdf/2509.04545v3>|提出了一种PromptEnhancer框架，通过Chain-of-Thought重写提示，有效提升文...|
|🆕 发布|Spherical Brownian Bridge Diffusion Models for Conditional Cortical Thickness Forecasting|基于球面布朗桥扩散模型的条件性大脑皮层厚度预测|Ivan Stoyanov, Fabian Bongratz, Christian Wachinger|<http://arxiv.org/pdf/2509.08442v1>|提出球形布朗桥扩散模型，通过双向条件布朗桥扩散过程和新型去噪模型，实现了高精度皮质厚度预测。|
|📝 更新|Moment- and Power-Spectrum-Based Gaussianity Regularization for Text-to-Image Models|基于矩和功率谱的 Gaussian 性质正则化方法在文本到图像模型中的应用|Jisung Hwang, Jaihoon Kim, Minhyuk Sung|<http://arxiv.org/pdf/2509.07027v2>|提出一种基于矩和功率谱的标准化正则化方法，提升文本到图像模型在潜在空间优化的性能。|
|📝 更新|TextSSR: Diffusion-based Data Synthesis for Scene Text Recognition|文本SSR：基于扩散的数据合成用于场景文本识别|Xingsong Ye, Yongkun Du, Yunbo Tao, Zhineng Chen|<http://arxiv.org/pdf/2412.01137v2>|[代码](https://github.com/YesianRohn/TextSSR.); 提出TextSSR方法，通过精确字符控制和风格引导生成逼真、准确的场景文本合成数据，提升识别模型性能...|
|📝 更新|Bidirectional Sparse Attention for Faster Video Diffusion Training|双向稀疏注意力机制加速视频扩散训练|Chenlu Zhan, Wen Li, Chuyu Shen, Jun Zhang, Suhui Wu, Hao Zhang|<http://arxiv.org/pdf/2509.01085v2>|提出双向稀疏注意力机制，大幅提升视频生成模型训练效率。|
|📝 更新|RetinaGuard: Obfuscating Retinal Age in Fundus Images for Biometric Privacy Preserving|视网膜保护：在眼底图像中混淆视网膜年龄以保护生物识别隐私|Zhengquan Luo, Chi Liu, Dongfu Xiao, Zhen Yu, Yueye Wang, Tianqing Zhu|<http://arxiv.org/pdf/2509.06142v2>|提出了一种新的隐私增强框架RetinaGuard，通过生成对抗遮蔽机制隐藏视网膜年龄，同时保持图像质...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AdsQA: Towards Advertisement Video Understanding|广告理解向量化：迈向广告视频理解|Xinwei Long, Kai Tian, Peng Xu, Guoli Jia, Jingxuan Li, Sa Yang, Yihua Shao, Kaiyan Zhang .etc.|<http://arxiv.org/pdf/2509.08621v1>|提出 AdsQA，首个利用广告视频评估大型语言模型的基准，并引入 ReAd-R 模型取得最佳性能。|
|📝 更新|F-Bench: Rethinking Human Preference Evaluation Metrics for Benchmarking Face Generation, Customization, and Restoration|F-Bench：重新思考人脸生成、定制与修复基准测试中的人类偏好评估指标|Lu Liu, Huiyu Duan, Qiang Hu, Liu Yang, Chunlei Cai, Tianxiao Ye, Huayu Liu, Xiaoyun Zhang .etc.|<http://arxiv.org/pdf/2412.13155v2>|提出FaceQ数据库和F-Bench基准，以人类偏好为标准评估人脸生成、定制和修复质量。|
|🆕 发布|Bitrate-Controlled Diffusion for Disentangling Motion and Content in Video|视频运动与内容解耦的比特率控制扩散方法|Xiao Li, Qi Chen, Xiulian Peng, Kai Yu, Xie Chen, Yan Lu|<http://arxiv.org/pdf/2509.08376v1>|提出了一种自监督框架，通过低比特率量化分离视频中的动态运动和静态内容，用于视频分析和生成。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SAFT: Shape and Appearance of Fabrics from Template via Differentiable Physical Simulations from Monocular Video|基于模板的单目视频中的形状与外观：通过可微分物理模拟的SAFT织物|David Stotko, Reinhard Klein|<http://arxiv.org/pdf/2509.08828v1>|提出了一种结合3D几何重建和外观估计的方法，通过物理仿真和可微分渲染，仅用单目RGB视频实现高质量布...|
|📝 更新|Physics-Driven Local-Whole Elastic Deformation Modeling for Point Cloud Representation Learning|基于物理驱动的局部-整体弹性形变建模用于点云表征学习|Zhongyu Chen, Rong Zhao, Xie Han, Xindong Guo, Song Wang, Zherui Qiao|<http://arxiv.org/pdf/2505.13812v2>|引入物理驱动的弹性变形机制，提升了点云表示学习中局部与整体结构的建模精度和泛化能力。|
|🆕 发布|VRAE: Vertical Residual Autoencoder for License Plate Denoising and Deblurring|垂直残差自动编码器：用于车牌去噪和去模糊|Cuong Nguyen, Dung T. Tran, Hong Nguyen, Xuan-Vu Phan, Nam-Phong Nguyen|<http://arxiv.org/pdf/2509.08392v1>|提出了一种垂直残差自动编码器，用于车辆监控中车牌的去噪和去模糊，显著提升了识别性能。|
|📝 更新|GNF: Gaussian Neural Fields for Multidimensional Signal Representation and Reconstruction|GNF：高斯神经网络场用于多维信号表示与重建|Abdelaziz Bouzidi, Hamid Laga, Hazem Wannous, Ferdous Sohel|<http://arxiv.org/pdf/2503.06762v2>|提出 Gaussian Neural Fields 方法，使用单个高维特征空间的 Gaussian ...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TANGO: Traversability-Aware Navigation with Local Metric Control for Topological Goals|TANGO：面向拓扑目标的局部度量控制下的可通性感知导航|Stefan Podgorski, Sourav Garg, Mehdi Hosseinzadeh, Lachlan Mares, Feras Dayoub, Ian Reid|<http://arxiv.org/pdf/2509.08699v1>|[代码](https://github.com/podgorki/TANGO.); 提出了一种无需3D地图或预训练控制器的RGB视觉导航方法，实现零样本长距离导航并有效避开障碍物。|
|📝 更新|VIM-GS: Visual-Inertial Monocular Gaussian Splatting via Object-level Guidance in Large Scenes|VIM-GS：基于对象级引导的大场景视觉-惯性单目高斯散点映射|Shengkai Zhang, Yuhe Liu, Guanjun Wu, Jianhua He, Xinggang Wang, Mozi Chen, Kezhong Liu|<http://arxiv.org/pdf/2509.06685v3>|提出了一种结合视觉惯性SfM和大型基础模型的高精度深度估计方法，显著提升了大型场景中单目图像的nov...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ViewSparsifier: Killing Redundancy in Multi-View Plant Phenotyping|《ViewSparsifier：在多视角植物表型分析中消除冗余》|Robin-Nico Kampa, Fabian Deuser, Konrad Habel, Norbert Oswald|<http://arxiv.org/pdf/2509.08550v1>|提出ViewSparsifier方法，通过优化多角度拍摄数据选择，提高了植物表型特征估计的准确性。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MESH -- Understanding Videos Like Human: Measuring Hallucinations in Large Video Models|MESH -- 如同人类理解视频：测量大型视频模型中的幻觉现象|Garry Yang, Zizhe Chen, Man Hon Wong, Haoyu Lei, Yongqiang Chen, Zhenguo Li, Kaiwen Zhou, James Cheng|<http://arxiv.org/pdf/2509.08538v1>|提出MESH基准，系统评估大型视频模型中的幻觉现象，与人类视频理解过程相吻合。|
|📝 更新|UAR-NVC: A Unified AutoRegressive Framework for Memory-Efficient Neural Video Compression|统一自回归框架：用于内存高效神经视频压缩的UAR-NVC|Jia Wang, Xinfeng Zhang, Gai Zhang, Jun Zhu, Lv Tang, Li Zhang|<http://arxiv.org/pdf/2503.02733v2>|[代码](https://wj-inf.github.io/UAR-NVC-page); 提出了一种统一的自动回归框架UAR-NVC，通过分片处理和参数优化降低神经视频压缩的内存消耗。|
|🆕 发布|Sparse Transformer for Ultra-sparse Sampled Video Compressive Sensing|结果： 稀疏变换器：用于超稀疏采样视频压缩感知|Miao Cao, Siming Zheng, Lishun Wang, Ziyang Chen, David Brady, Xin Yuan|<http://arxiv.org/pdf/2509.08228v1>|提出超稀疏采样策略并设计稀疏Transformer，有效降低视频压缩感知功耗并提升恢复性能。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Chirality in Action: Time-Aware Video Representation Learning by Latent Straightening|《动作中的手性：通过潜在拉直实现时间感知的视频表征学习》|Piyush Bagad, Andrew Zisserman|<http://arxiv.org/pdf/2509.08502v1>|提出了一种自监督方法，通过感知直方图偏置增强视频时序表征，有效区分时序相反动作。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ALOcc: Adaptive Lifting-Based 3D Semantic Occupancy and Cost Volume-Based Flow Predictions|自适应提升式三维语义占据与基于代价体积的流预测|Dubing Chen, Jin Fang, Wencheng Han, Xinjing Cheng, Junbo Yin, Chenzhong Xu, Fahad Shahbaz Khan, Jianbing Shen|<http://arxiv.org/pdf/2411.07725v2>|提出了一种自适应提升机制和成本体积预测框架，实现了3D语义占位和流预测的准确性和效率提升。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hyperspectral Mamba for Hyperspectral Object Tracking|“用于高光谱目标跟踪的高光谱曼巴”|Long Gao, Yunhe Zhang, Yan Jiang, Weiying Xie, Yunsong Li|<http://arxiv.org/pdf/2509.08265v1>|[代码](https://github.com/lgao001/HyMamba.); 提出HyMamba网络，融合光谱、深度和时序信息，提升跟踪精度。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ArgoTweak: Towards Self-Updating HD Maps through Structured Priors|ArgoTweak：基于结构先验的自主更新高精度地图方法|Lena Wild, Rafael Valencia, Patric Jensfelt|<http://arxiv.org/pdf/2509.08764v1>|[代码](https://kth-rpl.github.io/ArgoTweak); ArgoTweak通过提供首个包含真实地图先验的完整数据集，实现了高清地图的自我验证和更新。|
|📝 更新|A Chinese Continuous Sign Language Dataset Based on Complex Environments|基于复杂环境的中文连续手语数据集|Qidan Zhu, Jing Li, Fei Yuan, Jiaojiao Fan, Quan Gan|<http://arxiv.org/pdf/2409.11960v2>|构建了复杂环境下的大规模中文连续手语数据集，并提出了时间频率网络模型以提升识别准确度。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FractalPINN-Flow: A Fractal-Inspired Network for Unsupervised Optical Flow Estimation with Total Variation Regularization|分形PINN-流：一种基于分形启发的无监督光流估计网络，具有总变分正则化|Sara Behnamian, Rasoul Khaksarinezhad, Andreas Langer|<http://arxiv.org/pdf/2509.08670v1>|提出了一种基于分形几何的深度学习框架FractalPINN-Flow，无需标注数据即可实现精确的光流...|
|🆕 发布|Skeleton-based sign language recognition using a dual-stream spatio-temporal dynamic graph convolutional network|基于双流时空动态图卷积网络的骨骼手势识别|Liangjin Liu, Haoyang Zheng, Pei Zhou|<http://arxiv.org/pdf/2509.08661v1>|提出了一种双流动态图卷积网络，分离建模手势形态与轨迹，提高了手语识别准确率。|
|📝 更新|MSNav: Zero-Shot Vision-and-Language Navigation with Dynamic Memory and LLM Spatial Reasoning|MSNav：基于动态记忆和LLM空间推理的无监督视觉与语言导航|Chenghao Liu, Zhimu Zhou, Jiachen Zhang, Minghao Zhang, Songfang Huang, Huiling Duan|<http://arxiv.org/pdf/2508.16654v3>|MSNav通过融合记忆、空间推理和决策模块，解决了传统视觉导航中的空间推理不足和记忆过载问题，提升了...|
|🆕 发布|Adapting Vision-Language Models for Neutrino Event Classification in High-Energy Physics|适应视觉-语言模型用于高能物理中的中微子事件分类|Dikshant Sagar, Kaiwen Yu, Alejandro Yankelevich, Jianming Bian, Pierre Baldi|<http://arxiv.org/pdf/2509.08461v1>|将视觉语言模型应用于高能物理中的中微子事件分类，提升了性能并增强了预测的可解释性。|
|🆕 发布|First-order State Space Model for Lightweight Image Super-resolution|轻量级图像超分辨率的一阶状态空间模型|Yujie Zhu, Xinyi Zhang, Yekai Lu, Guang Yang, Faming Fang, Guixu Zhang|<http://arxiv.org/pdf/2509.08458v1>|提出了一种改进的一阶状态空间模型，通过增强标记相关性提升了轻量级图像超分辨率性能。|
|📝 更新|TransitReID: Transit OD Data Collection with Occlusion-Resistant Dynamic Passenger Re-Identification|《TransitReID：具有遮挡抵抗性的动态乘客重识别的公交OD数据采集》|Kaicong Huang, Talha Azfar, Jack Reilly, Ruimin Ke|<http://arxiv.org/pdf/2504.11500v2>|提出了一种针对公交环境的个体级抗遮挡乘客重识别框架，通过动态强调可见且具有辨识性的身体区域，实现了高...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Towards properties of adversarial image perturbations|面向对抗图像扰动特性的研究|Egor Kuznetsov, Kirill Aistov, Maxim Koroteev|<http://arxiv.org/pdf/2503.14111v2>|探究了对抗性扰动对图像质量的影响，发现适度亮度变化可显著提升VMAF指标，同时保持图像主观质量不变。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|An End-to-End Deep Learning Framework for Arsenicosis Diagnosis Using Mobile-Captured Skin Images|一种基于移动捕获皮肤图像的砷中毒诊断端到端深度学习框架|Asif Newaz, Asif Ur Rahman Adib, Rajit Sahil, Mashfique Mehzad|<http://arxiv.org/pdf/2509.08780v1>|提出了一种基于深度学习的框架，利用手机拍摄皮肤图像进行砷中毒早期诊断，提高了诊断准确性和可及性。|
|🆕 发布|Improving Greenland Bed Topography Mapping with Uncertainty-Aware Graph Learning on Sparse Radar Data|利用不确定性感知图学习在稀疏雷达数据上改进格陵兰岛床地形测绘|Bayu Adhi Tama, Homayra Alam, Mostafa Cham, Omar Faruque, Jianwu Wang, Vandana Janeja|<http://arxiv.org/pdf/2509.08571v1>|提出GraphTopoNet模型，通过图学习和不确定性建模提高格林兰岛冰床地形图的精度。|
|🆕 发布|Maximally Useful and Minimally Redundant: The Key to Self Supervised Learning for Imbalanced Data|最大效用与最小冗余：不平衡数据自监督学习的关键|Yash Kumar Sharma, Vineet Nair, Wilson Naik|<http://arxiv.org/pdf/2509.08469v1>|提出多视角互信息优化策略，提升自监督学习在失衡数据集上的泛化能力。|
|📝 更新|From Channel Bias to Feature Redundancy: Uncovering the "Less is More" Principle in Few-Shot Learning|从通道偏见到特征冗余：探索少量学习中的“少即是多”原则|Ji Zhang, Xu Luo, Lianli Gao, Difan Zou, Hengtao Shen, Jingkuan Song|<http://arxiv.org/pdf/2310.03843v2>|揭示了少样本学习中的“少即是多”原则，提出AFIA方法减轻特征冗余问题。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Have Large Vision-Language Models Mastered Art History?|大型视觉-语言模型是否掌握了艺术史？|Ombretta Strafforello, Derya Soydaner, Michiel Willems, Anne-Sofie Maerten, Stefanie De Winter|<http://arxiv.org/pdf/2409.03521v2>|探究大型视觉语言模型在艺术史领域的风格、作者和年代分类能力，对比人类专家水平。|
|🆕 发布|Implicit Shape-Prior for Few-Shot Assisted 3D Segmentation|少量样本辅助三维分割的隐式形状先验|Mathilde Monvoisin, Louise Piecuch, Blanche Texier, Cédric Hémon, Anaïs Barateau, Jérémie Huet, Antoine Nordez, Anne-Sophie Boureau .etc.|<http://arxiv.org/pdf/2509.08580v1>|引入隐式形状先验，通过少量切片手动标注实现多器官3D分割自动化，减轻医疗专业人员工作负担。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Handling Multiple Hypotheses in Coarse-to-Fine Dense Image Matching|在粗到细密集图像匹配中处理多个假设|Matthieu Vilain, Rémi Giraud, Yannick Berthoumieu, Guillaume Bourmaud|<http://arxiv.org/pdf/2509.08805v1>|提出多假设传播策略，引入BEAMER架构，增强深度不连续性和强缩放下的密集图像匹配鲁棒性。|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SocialNav-SUB: Benchmarking VLMs for Scene Understanding in Social Robot Navigation|社会导航-SUB：用于社交机器人导航中场景理解的任务的视觉语言模型基准测试|Michael J. Munje, Chen Tang, Shuijing Liu, Zichao Hu, Yifeng Zhu, Jiaxun Cui, Garrett Warnell, Joydeep Biswas .etc.|<http://arxiv.org/pdf/2509.08757v1>|[代码](https://larg.github.io/socialnav-sub); 提出SocialNav-SUB基准，评估视觉语言模型在社交机器人导航场景中的场景理解能力。|
|🆕 发布|BcQLM: Efficient Vision-Language Understanding with Distilled Q-Gated Cross-Modal Fusion|BcQLM：基于精简Q门跨模态融合的高效视觉-语言理解|Sike Xiang, Shuang Chen, Amir Atapour-Abarghouei|<http://arxiv.org/pdf/2509.08715v1>|[代码](https://github.com/thico0224/BcQLM.); 提出了一种高效的轻量级视觉问答模型BcQLM，通过优化的跨模态融合显著降低计算成本，同时保持性能。|
|📝 更新|TextlessRAG: End-to-End Visual Document RAG by Speech Without Text|无文本RAG：通过语音实现无需文本的端到端视觉文档RAG|Peijin Xie, Shun Qian, Bingquan Liu, Dexin Wang, Lin Sun, Xiangzheng Zhang|<http://arxiv.org/pdf/2509.07538v2>|[代码](https://github.com/xiepeijinhit-hue/textlessrag); 提出首个端到端无文本视觉文档问答框架TextlessRAG，直接处理语音查询，无需ASR、TTS和O...|
|🆕 发布|Good Deep Features to Track: Self-Supervised Feature Extraction and Tracking in Visual Odometry|用于跟踪的良好深度特征：视觉里程计中的自监督特征提取与跟踪|Sai Puneeth Reddy Gottam, Haoming Zhang, Eivydas Keras|<http://arxiv.org/pdf/2509.08333v1>|通过自监督学习增强深度特征提取与跟踪，提升视觉定位在复杂环境中的泛化能力和可靠性。|
|📝 更新|Learning Robust Representations via Bidirectional Transition for Visual Reinforcement Learning|通过双向过渡学习视觉强化学习中的鲁棒表征|Xiaobo Hu, Youfang Lin, Yue Liu, Jinwen Wang, Shuo Wang, Hehe Fan, Kai Lv|<http://arxiv.org/pdf/2312.01915v2>|提出双向过渡模型BiT，通过预测环境的前后变化提取可靠视觉表征，提升视觉强化学习的泛化性能和样本效率...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UOPSL: Unpaired OCT Predilection Sites Learning for Fundus Image Diagnosis Augmentation|无配对OCT偏好位点学习用于眼底图像诊断增强|Zhihao Zhao, Yinzheng Zhao, Junjie Yang, Xiangtong Yao, Quanmin Liang, Daniel Zapp, Kai Huang, Nassir Navab .etc.|<http://arxiv.org/pdf/2509.08624v1>|提出了一种无配对学习框架UOPSL，利用OCT空间先验增强仅基于眼底图像的疾病识别能力。|
|📝 更新|A Survey of World Models for Autonomous Driving|自动驾驶领域世界模型研究综述|Tuo Feng, Wenguan Wang, Yi Yang|<http://arxiv.org/pdf/2501.11260v4>|系统综述了自动驾驶世界模型的发展，提出了分类框架，分析了训练方法，为提升安全性提供了技术路线图。|
|🆕 发布|Prompt-Driven Image Analysis with Multimodal Generative AI: Detection, Segmentation, Inpainting, and Interpretation|基于多模态生成人工智能的提示驱动图像分析：检测、分割、修复与解释|Kaleem Ahmad|<http://arxiv.org/pdf/2509.08489v1>|提出了一种统一的多模态生成AI驱动的图像分析流程，通过单个自然语言指令实现检测、分割、编辑和描述。|
|🆕 发布|Boosted Training of Lightweight Early Exits for Optimizing CNN Image Classification Inference|增强轻量级早期退出策略的训练以优化卷积神经网络图像分类推理|Yehudit Aperstein, Alexander Apartsin|<http://arxiv.org/pdf/2509.08318v1>|提出了一种优化CNN实时图像分类的轻量级早期退出策略训练方法，有效平衡准确性与资源消耗。|
|🆕 发布|RepViT-CXR: A Channel Replication Strategy for Vision Transformers in Chest X-ray Tuberculosis and Pneumonia Classification|RepViT-CXR：一种用于胸部X射线结核和肺炎分类的视觉变换器通道复制策略|Faisal Ahmed|<http://arxiv.org/pdf/2509.08234v1>|提出了一种通道复制策略，使Vision Transformers能高效处理灰度胸部X射线图像，提升肺...|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|InsFusion: Rethink Instance-level LiDAR-Camera Fusion for 3D Object Detection|《InsFusion：重新思考点实例级激光雷达-相机融合的三维目标检测》|Zhongyu Xia, Hansong Yang, Yongtao Wang|<http://arxiv.org/pdf/2509.08374v1>|提出InsFusion方法，通过联合提取和查询原始特征，减少3D物体检测中的误差累积，实现性能提升。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Sparse BEV Fusion with Self-View Consistency for Multi-View Detection and Tracking|稀疏鸟瞰图融合与自视角一致性用于多视角检测与跟踪|Keisuke Toida, Taigo Sakai, Naoki Kato, Kazutoyo Yokota, Takeshi Nakamura, Kazuhiro Hotta|<http://arxiv.org/pdf/2509.08421v1>|提出SCFusion框架，通过稀疏变换和密度感知加权改善多视角特征融合，提升多目标检测与跟踪准确性。|
|📝 更新|RSCC: A Large-Scale Remote Sensing Change Caption Dataset for Disaster Events|遥感变化标注数据集：面向灾害事件的大规模遥感变化标注数据集|Zhenyuan Chen, Chenxi Wang, Feng Zhang|<http://arxiv.org/pdf/2509.01907v3>|[代码](https://github.com/Bili-Sakura/RSCC.); 构建了大规模遥感变化标注数据集RSCC，增强了对灾害事件时间序列图像的理解能力。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Symmetry Interactive Transformer with CNN Framework for Diagnosis of Alzheimer's Disease Using Structural MRI|对称交互式变换器与卷积神经网络框架结合用于结构MRI的阿尔茨海默病诊断|Zheng Yang, Yanteng Zhang, Xupeng Kou, Yang Liu, Chao Ren|<http://arxiv.org/pdf/2509.08243v1>|提出了一种利用3D CNN和对称交互变换器检测脑部不对称性的方法，提高了阿尔茨海默病的诊断准确率。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Semantic Causality-Aware Vision-Based 3D Occupancy Prediction|基于语义因果意识的视觉三维占据预测|Dubing Chen, Huan Zheng, Yucheng Zhou, Xianfei Li, Wenlong Liao, Tao He, Pai Peng, Jianbing Shen|<http://arxiv.org/pdf/2509.08388v1>|提出了一种端到端的视觉预测方法，通过引入因果损失函数，实现了2D到3D的语义一致性转换。|


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Event Camera Meets Resource-Aware Mobile Computing: Abstraction, Algorithm, Acceleration, Application|事件相机遇见资源感知移动计算：抽象、算法、加速、应用|Haoyang Wang, Ruishan Guo, Pengtao Ma, Ciyu Ruan, Xinyu Luo, Wenhua Ding, Tianyang Zhong, Jingao Xu .etc.|<http://arxiv.org/pdf/2503.22943v3>|整合事件相机与移动计算资源管理，提升高动态移动设备上的视觉感知精度和效率。|
|🆕 发布|Examining Vision Language Models through Multi-dimensional Experiments with Vision and Text Features|通过多维度实验探究视觉语言模型与视觉及文本特征的交互作用|Saurav Sengupta, Nazanin Moradinasab, Jiebei Liu, Donald E. Brown|<http://arxiv.org/pdf/2509.08266v1>|构建多维度分析框架，揭示视觉语言模型如何因输入数据特征变化而影响回答准确性和性能。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CNN-ViT Hybrid for Pneumonia Detection: Theory and Empiric on Limited Data without Pretraining|pneumonia detection: CNN-ViT混合模型在无预训练有限数据集上的肺炎检测：理论及实证研究|Prashant Singh Basnet, Roshan Chitrakar|<http://arxiv.org/pdf/2509.08586v1>|提出CNN与ViT混合模型，无需预训练在有限数据集上实现高效肺炎检测。|
|📝 更新|Hybrid Swin Attention Networks for Simultaneously Low-Dose PET and CT Denoising|混合Swin注意力网络用于同时实现低剂量PET和CT去噪|Yichao Liu, Hengzhi Xue, YueYang Teng|<http://arxiv.org/pdf/2509.06591v3>|提出了一种Hybrid Swin Attention Network，有效提升了低剂量PET和CT图...|

