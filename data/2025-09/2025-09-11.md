## [UPDATED!] **2025-09-11** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Measuring Epistemic Humility in Multimodal Large Language Models|测量多模态大型语言模型中的认知谦逊|Bingkui Tong, Jiaer Xia, Sifeng Shang, Kaiyang Zhou|<http://arxiv.org/pdf/2509.09658v1>|[代码](https://github.com/maifoundations/HumbleBench.); 提出HumbleBench基准，评估大型多模态语言模型在识别错误答案时的能力，增强AI可靠性。|
|🆕 发布|PeftCD: Leveraging Vision Foundation Models with Parameter-Efficient Fine-Tuning for Remote Sensing Change Detection|PeftCD：利用参数高效微调的视觉基础模型进行遥感变化检测|Sijun Dong, Yuxuan Hu, LiBo Wang, Geng Chen, Xiaoliang Meng|<http://arxiv.org/pdf/2509.09572v1>|[代码](https://github.com/dyzy41/PeftCD.); 提出PeftCD框架，利用参数高效微调优化视觉基础模型，提升遥感变化检测准确性与效率。|
|📝 更新|Towards Scalable Training for Handwritten Mathematical Expression Recognition|面向手写数学表达式识别的可扩展训练方法研究|Haoyang Li, Jiaqing Li, Jialun Cao, Zongyuan Yang, Yongping Xiong|<http://arxiv.org/pdf/2508.09220v3>|提出了一种利用大规模数据生成引擎，结合少量手写公式和大量LaTeX渲染公式，训练出具有最佳性能的手写...|
|🆕 发布|DualTrack: Sensorless 3D Ultrasound needs Local and Global Context|双轨迹：无传感器三维超声需要局部与全局上下文|Paul F. R. Wilson, Matteo Ronchetti, Rüdiger Göbl, Viktoria Markova, Sebastian Rosenzweig, Raphael Prevost, Parvin Mousavi, Oliver Zettinig|<http://arxiv.org/pdf/2509.09530v1>|提出双编码器架构DualTrack，通过分离局部和全局特征提取，提高3D超声成像准确性和一致性。|
|📝 更新|Robix: A Unified Model for Robot Interaction, Reasoning and Planning|Robix：一种用于机器人交互、推理和规划的统一模型|Huang Fang, Mengxi Zhang, Heng Dong, Wei Li, Zixuan Wang, Qifeng Zhang, Xueyun Tian, Yucheng Hu .etc.|<http://arxiv.org/pdf/2509.01106v2>|提出了Robix模型，将机器人推理、任务规划和自然语言交互集成于单一视觉语言架构，实现复杂指令执行和...|
|🆕 发布|ALL-PET: A Low-resource and Low-shot PET Foundation Model in the Projection Domain|ALL-PET：投影域中的低资源与小样本PET基础模型|Bin Huang, Kang Chen, Bingxuan Li, Huafeng Liu, Qiegen Liu|<http://arxiv.org/pdf/2509.09130v1>|提出ALL-PET模型，通过在投影域操作和少量样本训练，有效解决PET成像数据稀缺和资源限制问题。|
|📝 更新|ForestSplats: Deformable transient field for Gaussian Splatting in the Wild|森林泼洒：在野外环境中用于高斯泼洒的可变形瞬时场|Wongi Park, Myeongseok Nam, Siwon Kim, Sangwoo Jo, Soomok Lee|<http://arxiv.org/pdf/2503.06179v3>|提出了一种利用可变形瞬态场和超像素感知掩码的高效表示方法，无需依赖预训练模型即可区分静态场景与瞬态干...|
|🆕 发布|Zero-shot Hierarchical Plant Segmentation via Foundation Segmentation Models and Text-to-image Attention|基于基础分割模型与文本到图像注意力的零样本层次化植物分割|Junhao Xing, Ryohei Miyakawa, Yang Yang, Xinpeng Liu, Risa Shinoda, Hiroaki Santo, Yosuke Toda, Fumio Okura|<http://arxiv.org/pdf/2509.09116v1>|[代码](https://github.com/JunhaoXing/ZeroPlantSeg.); 提出ZeroPlantSeg方法，通过基础分割模型和视觉语言模型实现植物个体零样本分割。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Improving Video Diffusion Transformer Training by Multi-Feature Fusion and Alignment from Self-Supervised Vision Encoders|通过多特征融合与自监督视觉编码器的对齐来改进视频扩散变换器的训练|Dohun Lee, Hyeonho Jeong, Jiwook Kim, Duygu Ceylan, Jong Chul Ye|<http://arxiv.org/pdf/2509.09547v1>|[代码](https://align4gen.github.io/align4gen); 提出多特征融合与对齐方法，提升视频生成模型特征表现力，改善视频生成质量。|
|🆕 发布|Invisible Attributes, Visible Biases: Exploring Demographic Shortcuts in MRI-based Alzheimer's Disease Classification|《隐形属性，显性偏见：探索基于MRI的阿尔茨海默病分类中的人口学捷径》|Akshit Achara, Esther Puyol Anton, Alexander Hammers, Andrew P. King|<http://arxiv.org/pdf/2509.09558v1>|[代码](https://github.com/acharaakshit/ShortMR); 揭示了深度学习在基于MRI的阿尔茨海默病诊断中存在的种族和性别偏见问题，并提出了公平性改进方案。|
|📝 更新|A Lightweight Convolution and Vision Transformer integrated model with Multi-scale Self-attention Mechanism|一种融合多尺度自注意力机制的轻量级卷积与视觉Transformer集成模型|Yi Zhang, Lingxiao Wei, Bowei Zhang, Ziwei Liu, Kai Yi, Shu Hu|<http://arxiv.org/pdf/2508.16884v2>|提出了一种融合稀疏注意力和卷积块的轻量级ViT模型，提升了计算效率并保持了高性能。|
|📝 更新|Enhancing Automatic Modulation Recognition With a Reconstruction-Driven Vision Transformer Under Limited Labels|在有限标签下利用重建驱动的视觉变换器增强自动调制识别|Hossein Ahmadi, Banafsheh Saffari, Sajjad Emdadi Mahdimahalleh, Mohammad Esmaeil Safari, Aria Ahmadi|<http://arxiv.org/pdf/2508.20193v2>|提出了一种集成监督、自监督和重建目标的统一视觉Transformer框架，实现了在有限标签下的高效调...|
|📝 更新|TESSER: Transfer-Enhancing Adversarial Attacks from Vision Transformers via Spectral and Semantic Regularization|TESSER：通过谱和语义正则化增强迁移性的视觉Transformer对抗攻击|Amira Guesmi, Bassem Ouni, Muhammad Shafique|<http://arxiv.org/pdf/2505.19613v2>|提出了一种增强对抗攻击迁移性的方法TESSER，通过特征敏感梯度缩放和频谱平滑正则化提高攻击成功率。|
|🆕 发布|CoAtNeXt:An Attention-Enhanced ConvNeXtV2-Transformer Hybrid Model for Gastric Tissue Classification|卷积增强的NeXtV2-Transformer混合模型CoAtNeXt：用于胃组织分类的注意力增强模型|Mustafa Yurdakul, Sakir Tasdemir|<http://arxiv.org/pdf/2509.09242v1>|提出CoAtNeXt模型，结合卷积和注意力机制，提升胃组织分类准确性和效率。|
|🆕 发布|Adaptive Pareto-Optimal Token Merging for Edge Transformer Models in Semantic Communication|自适应帕累托最优标记合并策略在边缘变换模型语义通信中的应用|Omar Erak, Omar Alhussein, Hatem Abou-Zeid, Mehdi Bennis|<http://arxiv.org/pdf/2509.09168v1>|提出了一种自适应的令牌合并框架，有效平衡了边缘设备中视觉Transformer模型的计算成本和通信效...|
|🆕 发布|Video Understanding by Design: How Datasets Shape Architectures and Insights|《通过设计理解视频：数据集如何塑造架构与洞察》|Lei Wang, Piotr Koniusz, Yongsheng Gao|<http://arxiv.org/pdf/2509.09151v1>|首次提出从数据集驱动的视角分析视频理解模型架构的演变，揭示了数据集特性如何引导模型设计。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Can Multimodal LLMs See Materials Clearly? A Multimodal Benchmark on Materials Characterization|多模态大型语言模型能否清晰识别材料？一种材料特性表征的多模态基准测试|Zhengzhao Lai, Youbin Zheng, Zhenyang Cai, Haonan Lyu, Jinpu Yang, Hongqing Liang, Yan Hu, Benyou Wang|<http://arxiv.org/pdf/2509.09307v1>|[代码](https://github.com/FreedomIntelligence/MatCha.); 提出MatCha基准，评估了多模态大语言模型在材料图像理解上的局限性。|
|🆕 发布|Modality-Agnostic Input Channels Enable Segmentation of Brain lesions in Multimodal MRI with Sequences Unavailable During Training|模态无关输入通道使得在训练期间不可用的多模态MRI序列能够实现脑病变分割|Anthony P. Addison, Felix Wagner, Wentian Xu, Natalie Voets, Konstantinos Kamnitsas|<http://arxiv.org/pdf/2509.09290v1>|[代码](https://github.com/Anthony-P-Addison/AGN-MOD-SEG); 提出了一种使U-net模型能够处理训练期间未见过的MRI模态的通用输入通道，通过合成人工MRI模态进...|
|📝 更新|Deep Learning-Based Rock Particulate Classification Using Attention-Enhanced ConvNeXt|基于深度学习的岩石颗粒分类方法：使用注意力增强的ConvNeXt|Anthony Amankwah, Chris Aldrich|<http://arxiv.org/pdf/2509.01704v2>|提出了一种基于ConvNeXt架构的深度学习模型，通过融合自注意力和通道注意力机制，有效提升岩石颗粒...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Scaling Artificial Intelligence for Prostate Cancer Detection on MRI towards Organized Screening and Primary Diagnosis in a Global, Multiethnic Population (Study Protocol)|面向全球多民族人群的有序筛查和初步诊断的MRI前列腺癌检测人工智能扩展（研究协议）|Anindo Saha, Joeran S. Bosma, Jasper J. Twilt, Alexander B. C. D. Ng, Aqua Asif, Kirti Magudia, Peder Larson, Qinglin Xie .etc.|<http://arxiv.org/pdf/2508.03762v2>|本研究通过大规模多国数据训练并验证了PI-CAI-2B模型，旨在提高前列腺癌在MRI上的检测准确性和...|
|📝 更新|Automatic infant 2D pose estimation from videos: comparing seven deep neural network methods|视频中的婴儿二维姿态自动估计：比较七种深度神经网络方法|Filipe Gama, Matej Misar, Lukas Navara, Sergiu T. Popescu, Matej Hoffmann|<http://arxiv.org/pdf/2406.17382v4>|比较七种深度学习网络在婴儿二维姿态估计中的应用，发现ViTPose表现最佳且AlphaPose能接近...|
|📝 更新|V-HOP: Visuo-Haptic 6D Object Pose Tracking|视觉-触觉六自由度物体位姿跟踪|Hongyu Li, Mingxi Jia, Tuluhan Akbulut, Yu Xiang, George Konidaris, Srinath Sridhar|<http://arxiv.org/pdf/2502.17434v2>|提出了一种融合视觉和触觉信息的新型物体姿态跟踪方法，实现了在真实世界环境中的高性能和鲁棒性。|
|🆕 发布|Noise-Robust Topology Estimation of 2D Image Data via Neural Networks and Persistent Homology|通过神经网络和持久同调对二维图像数据的噪声稳健拓扑估计|Dylan Peek, Matthew P. Skerritt, Stephan Chalup|<http://arxiv.org/pdf/2509.09140v1>|通过训练神经网络预测Betti数，提出了一种在噪声环境下估计二维图像数据拓扑结构的新方法，优于传统的...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unsupervised Integrated-Circuit Defect Segmentation via Image-Intrinsic Normality|基于图像内在正常性的无监督集成电路缺陷分割|Botong Zhao, Qijun Shi, Shujing Lyu, Yue Lu|<http://arxiv.org/pdf/2509.09375v1>|提出了一种无需外部标准样本的无监督集成电路缺陷分割框架，通过学习图像自身正常模式实现缺陷检测。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Image Recognition with Vision and Language Embeddings of VLMs|基于视觉与语言嵌入的VLMs图像识别|Illia Volkov, Nikita Kisel, Klara Janouskova, Jiri Matas|<http://arxiv.org/pdf/2509.09311v1>|[代码](https://github.com/gonikisgo/bmvc2025-vlm-image-recognition.); 探究了视觉语言模型在图像分类中的互补优势，并引入了一种基于类精度融合的简单方法来提升性能。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Breaking the Statistical Similarity Trap in Extreme Convection Detection|打破极端对流检测中的统计相似性陷阱|Md Tanveer Hossain Munim|<http://arxiv.org/pdf/2509.09195v1>|提出框架DART，避免统计相似性陷阱，提升极端对流检测准确性。|
|🆕 发布|Dark-ISP: Enhancing RAW Image Processing for Low-Light Object Detection|《暗光ISP：增强低光环境下RAW图像处理以提升目标检测》|Jiasheng Guo, Xin Gao, Yuxiang Yan, Guanghao Li, Jian Pu|<http://arxiv.org/pdf/2509.09183v1>|提出了一种轻量级自适应图像信号处理插件Dark-ISP，直接处理暗光环境下的Bayer RAW图像，...|
|🆕 发布|Objectness Similarity: Capturing Object-Level Fidelity in 3D Scene Evaluation|物体相似性：在三维场景评估中捕捉物体级保真度|Yuiko Uchida, Ren Togo, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama|<http://arxiv.org/pdf/2509.09143v1>|[代码](https://github.com/Objectness-Similarity/OSIM.); 提出了一种新的3D场景评估指标OSIM，通过关注对象本身，更贴近人类视觉感知。|
|🆕 发布|OCELOT 2023: Cell Detection from Cell-Tissue Interaction Challenge|OCELOT 2023：细胞-组织交互挑战中的细胞检测|JaeWoong Shin, Jeongun Ryu, Aaron Valero Puche, Jinhee Lee, Biagio Brattoli, Wonkyung Jung, Soo Ick Cho, Kyunghyun Paeng .etc.|<http://arxiv.org/pdf/2509.09153v1>|提出多尺度细胞与组织交互标注数据集，提升了细胞检测模型的性能。|
|🆕 发布|RT-DETR++ for UAV Object Detection|用于无人机目标检测的RT-DETR++|Yuan Shufang|<http://arxiv.org/pdf/2509.09157v1>|提出了一种改进的RT-DETR++模型，通过创新的通道门控注意力和CSP-PAC技术，有效提升了无人...|
|🆕 发布|FPI-Det: a face--phone Interaction Dataset for phone-use detection and understanding|FPI-Det：用于手机使用检测与理解的面对面交互数据集|Jianqin Gao, Tianqi Wang, Yu Zhang, Yishu Zhang, Chenyuan Wang, Allan Dong, Zihao Wang|<http://arxiv.org/pdf/2509.09111v1>|[代码](https://github.com/KvCgRv/FPI-Det.); 提出手机使用检测新数据集FPI-Det，同步标注人脸与手机，提升了对复杂场景下人机交互的理解。|
|🆕 发布|IRDFusion: Iterative Relation-Map Difference guided Feature Fusion for Multispectral Object Detection|《IRDFusion：基于迭代关系图差异引导的多光谱目标检测特征融合》|Jifeng Shen, Haibo Zhan, Xin Zuo, Heng Fan, Xiaohui Yuan, Jun Li, Wankou Yang|<http://arxiv.org/pdf/2509.09085v1>|[代码](https://github.com/61s61min/IRDFusion.git.); 提出了一种迭代关系图差分引导的特征融合方法，有效抑制背景干扰并增强目标特征，实现多光谱目标检测性能的...|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Can Understanding and Generation Truly Benefit Together -- or Just Coexist?|“理解和生成能否真正相互促进——还是仅仅共存？”|Zhiyuan Yan, Kaiqing Lin, Zongjian Li, Junyan Ye, Hui Han, Zhendong Wang, Hao Liu, Bin Lin .etc.|<http://arxiv.org/pdf/2509.09666v1>|提出了一种统一模态学习框架UAE，通过双向信息流提升理解和生成质量。|
|📝 更新|3D and 4D World Modeling: A Survey|三维与四维世界建模：综述|Lingdong Kong, Wesley Yang, Jianbiao Mei, Youquan Liu, Ao Liang, Dekai Zhu, Dongyue Lu, Wei Yin .etc.|<http://arxiv.org/pdf/2509.07996v2>|[代码](https://github.com/worldbench/survey); 系统梳理了3D和4D世界建模的方法与数据集，定义了清晰的概念和分类体系。|
|🆕 发布|Region-Wise Correspondence Prediction between Manga Line Art Images|漫画线稿图像的区域对应预测|Yingxuan Li, Jiafeng Mao, Qianru Qiu, Yusuke Matsui|<http://arxiv.org/pdf/2509.09501v1>|提出了一种无标注条件下预测漫画线稿区域对应关系的方法，通过Transformer框架和聚类算法实现高...|
|📝 更新|Hallo4: High-Fidelity Dynamic Portrait Animation via Direct Preference Optimization|《Hallo4: 通过直接偏好优化实现高保真动态肖像动画》|Jiahao Cui, Yan Chen, Mingwang Xu, Hanlin Shang, Yuxuan Chen, Yun Zhan, Zilong Dong, Yao Yao .etc.|<http://arxiv.org/pdf/2505.23525v3>|[代码](https://github.com/xyz123xyz456/hallo4.); 通过直接偏好优化和时空运动调制，实现了高保真度动态肖像动画的精确唇音同步和自然表情。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dexplore: Scalable Neural Control for Dexterous Manipulation from Reference-Scoped Exploration|Dexplore：基于参考范围探索的灵巧操作可扩展神经控制|Sirui Xu, Yu-Wei Chao, Liuyu Bian, Arsalan Mousavian, Yu-Xiong Wang, Liang-Yan Gui, Wei Yang|<http://arxiv.org/pdf/2509.09671v1>|提出了一种统一优化的方法Dexplore，直接从大规模运动捕获数据中学习机器人控制策略，有效利用不完...|
|🆕 发布|FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark|FLUX-Reason-6M与PRISM-Bench：百万级文本到图像推理数据集与全面基准测试|Rongyao Fang, Aldrich Yu, Chengqi Duan, Linjiang Huang, Shuai Bai, Yuxuan Cai, Kun Wang, Si Liu .etc.|<http://arxiv.org/pdf/2509.09680v1>|提出大规模推理专用图像描述数据集FLUX-Reason-6M和综合评估框架PRISM-Bench，推...|
|🆕 发布|Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis|“Kling-Avatar：为级联长时虚拟人动画合成定位多模态指令”|Yikang Ding, Jiwen Liu, Wenyuan Zhang, Zekun Wang, Wentao Hu, Liyuan Cui, Mingming Lao, Yingchao Shao .etc.|<http://arxiv.org/pdf/2509.09595v1>|提出了一种融合多模态指令理解与高清肖像生成的级联框架，实现了长时序虚拟角色动画的流畅与真实。|
|🆕 发布|InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation|《InterAct：推进大规模多功能的3D人-物交互生成》|Sirui Xu, Dongting Li, Yucheng Zhang, Xiyan Xu, Qi Long, Ziyin Wang, Yunzhi Lu, Shuchang Dong .etc.|<http://arxiv.org/pdf/2509.09555v1>|[代码](https://github.com/wzyabcas/InterAct); 提出InterAct，一种大规模3D人-物交互数据集及优化框架，提升数据质量和生成模型性能。|
|🆕 发布|OpenFake: An Open Dataset and Platform Toward Large-Scale Deepfake Detection|开放伪造数据集：面向大规模深度伪造检测的开源数据集与平台|Victor Livernoche, Akshatha Arodi, Andreea Musulan, Zachary Yang, Adam Salvail, Gaétan Marceau Caron, Jean-François Godbout, Reihaneh Rabbany|<http://arxiv.org/pdf/2509.09495v1>|构建了一个大规模、政治敏感的深度伪造检测数据集和一个众包对抗平台，以提升检测方法的适应性和鲁棒性。|
|🆕 发布|FS-Diff: Semantic guidance and clarity-aware simultaneous multimodal image fusion and super-resolution|FS-Diff：语义引导与清晰度感知的同步多模态图像融合与超分辨率|Yuchan Jie, Yushen Xu, Xiaosong Li, Fuqiang Zhou, Jianming Lv, Huafeng Li|<http://arxiv.org/pdf/2509.09427v1>|[代码](https://github.com/XylonXu01/FS-Diff.); 提出FS-Diff方法，通过语义引导和清晰度感知实现图像融合与超分辨率，显著提升多模态图像细节和语义...|
|📝 更新|Zero-shot 3D-Aware Trajectory-Guided image-to-video generation via Test-Time Training|通过测试时训练实现的零样本3D感知轨迹引导的图像到视频生成|Ruicheng Zhang, Jun Zhou, Zunnan Xu, Zihao Liu, Jiehui Huang, Mingyang Zhang, Yu Sun, Xiu Li|<http://arxiv.org/pdf/2509.06723v2>|提出了一种零样本测试时训练框架Zo3T，通过3D感知运动投影和动态适配器增强视频生成的3D真实感和运...|
|🆕 发布|Fine-Grained Customized Fashion Design with Image-into-Prompt benchmark and dataset from LMM|细粒度定制时尚设计：基于图像到提示的基准和来自LMM的数据集|Hui Li, Yi You, Qiqi Chen, Bingfeng Zhang, George Q. Huang|<http://arxiv.org/pdf/2509.09324v1>|[代码](https://github.com/detectiveli/FashionEdit.); 提出BUG工作流，结合LMM和image-into-prompt实现精细化定制服装设计，降低设计门槛...|
|📝 更新|JAX-IK: Real-Time Inverse Kinematics for Generating Multi-Constrained Movements of Virtual Human Characters|JAX-IK：用于生成虚拟人类角色多约束运动的实时逆运动学|Hendric Voss, Stefan Kopp|<http://arxiv.org/pdf/2507.00792v3>|[代码](https://github.com/hvoss-techfak/JAX-IK); 提出了一种实时逆向运动学求解器，有效生成逼真虚拟人运动，提升了处理速度和成功率。|
|📝 更新|Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vector Drawings|从矢量绘图到CAD生成的序列到序列学习：Drawing2CAD|Feiwei Qin, Shichao Lu, Junhao Hou, Changmiao Wang, Meie Fang, Ligang Liu|<http://arxiv.org/pdf/2508.18733v5>|[代码](https://github.com/lllssc/Drawing2CAD.); 将2D工程图纸自动转换为参数化CAD模型的序列到序列学习框架，实现了几何精度和设计意图的精确保持。|
|📝 更新|AdvReal: Physical Adversarial Patch Generation Framework for Security Evaluation of Object Detection Systems|AdvReal：面向目标检测系统安全评估的物理对抗性贴图生成框架|Yuanhao Huang, Yilong Ren, Jinlei Wang, Lujia Huo, Xuesong Bai, Jinchuan Zhang, Haiyan Yu|<http://arxiv.org/pdf/2505.16402v2>|[代码](https://github.com/Huangyh98/AdvReal.git.); 提出了一种生成物理世界对抗样本的统一训练框架，有效提升了对象检测系统在真实环境下的攻击成功率和稳健性...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Locality in Image Diffusion Models Emerges from Data Statistics|图像扩散模型中的局部性源于数据统计特性|Artem Lukoianov, Chenyang Yuan, Justin Solomon, Vincent Sitzmann|<http://arxiv.org/pdf/2509.09672v1>|发现深度扩散模型中的局部性源自图像数据统计特性，而非卷积神经网络诱导偏置。|
|🆕 发布|Mechanistic Learning with Guided Diffusion Models to Predict Spatio-Temporal Brain Tumor Growth|基于引导扩散模型的机制学习预测脑肿瘤时空增长|Daria Laslo, Efthymios Georgiou, Marius George Linguraru, Andreas Rauschecker, Sabine Muller, Catherine R. Jutzeler, Sarah Bruningk|<http://arxiv.org/pdf/2509.09610v1>|结合数学模型与扩散模型预测脑肿瘤时空增长，实现了解剖学上可行的未来MRI生成。|
|📝 更新|Preprocessing Algorithm Leveraging Geometric Modeling for Scale Correction in Hyperspectral Images for Improved Unmixing Performance|利用几何建模进行尺度校正的预处理算法以提高高光谱图像解混性能|Praveen Sumanasekara, Athulya Ratnayake, Buddhi Wijenayake, Keshawa Ratnayake, Roshan Godaliyadda, Parakrama Ekanayake, Vijitha Herath|<http://arxiv.org/pdf/2508.08431v2>|提出了一种预处理算法，通过几何建模校正高光谱图像中的尺度变化，显著提升了光谱解混性能。|
|🆕 发布|Graph Alignment via Dual-Pass Spectral Encoding and Latent Space Communication|通过双通道光谱编码和潜在空间通信的图对齐|Maysam Behmanesh, Erkan Turan, Maks Ovsjanikov|<http://arxiv.org/pdf/2509.09597v1>|提出了一种双通道频谱编码和几何一致性的图对齐框架，有效提升了节点区分度和跨图几何关系一致性。|
|🆕 发布|Explainable AI for Accelerated Microstructure Imaging: A SHAP-Guided Protocol on the Connectome 2.0 scanner|《加速微观结构成像的可解释人工智能：基于SHAP引导的Connectome 2.0扫描仪协议》|Quentin Uhl, Tommaso Pavan, Julianna Gerold, Kwok-Shing Chan, Yohan Jun, Shohei Fujita, Aneri Bhatt, Yixin Ma .etc.|<http://arxiv.org/pdf/2509.09513v1>|提出了一种基于可解释AI的优化成像协议，大幅缩短扫描时间同时保持模型精度。|
|🆕 发布|Improving Human Motion Plausibility with Body Momentum|利用身体动量提高人体运动可信度|Ha Linh Nguyen, Tze Ho Elden Tse, Angela Yao|<http://arxiv.org/pdf/2509.09496v1>|[代码](https://hlinhn.github.io/momentum_bmvc.); 通过使用全身线动量和角动量作为约束，将局部运动与全局移动相结合，提高了人体运动合理性。|
|🆕 发布|Generative Diffusion Contrastive Network for Multi-View Clustering|多视角聚类生成扩散对比网络|Jian Zhu, Xin Zou, Xi Wang, Ning Zhang, Bian Wu, Yao Yang, Ying Zhou, Lingfang Zeng .etc.|<http://arxiv.org/pdf/2509.09527v1>|[代码](https://github.com/HackerHyper/GDCN.); 提出了一种生成扩散对比网络，有效处理多视角聚类中的低质量数据问题，实现了深度多视角聚类任务的最先进性...|
|📝 更新|Sigma Flows for Image and Data Labeling and Learning Structured Prediction|用于图像和数据标注的Sigma流以及学习结构化预测|Jonas Cassel, Bastian Boll, Stefania Petra, Peter Albers, Christoph Schnörr|<http://arxiv.org/pdf/2408.15946v2>|引入sigma流模型，结合几何图像处理与统计学习，用于预测数据结构化标注。|
|🆕 发布|Plug-and-play Diffusion Models for Image Compressive Sensing with Data Consistency Projection|用于图像压缩感知的数据一致性投影即插即用扩散模型|Xiaodong Wang, Ping Wang, Zhangyuan Li, Xin Yuan|<http://arxiv.org/pdf/2509.09365v1>|提出了一种结合学习先验和物理模型的图像重建框架，通过改进数据一致性模块提高了单像素成像的重建质量。|
|🆕 发布|Texture-aware Intrinsic Image Decomposition with Model- and Learning-based Priors|基于模型和学习的先验知识的纹理感知本征图像分解|Xiaodong Wang, Zijun He, Xin Yuan|<http://arxiv.org/pdf/2509.09352v1>|提出了一种基于纹理感知的正则化项，有效解决了复杂场景下的图像分解问题，提高了真实世界图像的分解质量。|
|📝 更新|S$^2$-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models|S$^2$-引导：无需训练的扩散模型增强的随机自我引导方法|Chubin Chen, Jiashu Zhu, Xiaokun Feng, Nisha Huang, Meiqi Wu, Fangyuan Mao, Jiahong Wu, Xiangxiang Chu .etc.|<http://arxiv.org/pdf/2508.12880v2>|提出了一种无需训练的S^2-Guidance方法，通过构建随机子网络优化扩散模型预测，显著提升生成质...|
|🆕 发布|Virtual staining for 3D X-ray histology of bone implants|三维X射线组织学中骨植入物的虚拟染色|Sarah C. Irvine, Christian Lucas, Diana Krüger, Bianca Guedert, Julian Moosmann, Berit Zeller-Plumhoff|<http://arxiv.org/pdf/2509.09235v1>|将虚拟染色技术应用于3D X射线成像，实现无需化学染色的生物组织特征可视化。|
|📝 更新|Bidirectional Sparse Attention for Faster Video Diffusion Training|双向稀疏注意力机制加速视频扩散训练|Chenlu Zhan, Wen Li, Chuyu Shen, Jun Zhang, Suhui Wu, Hao Zhang|<http://arxiv.org/pdf/2509.01085v3>|提出双向稀疏注意力机制，大幅提升视频生成模型训练效率。|
|📝 更新|IDEATOR: Jailbreaking and Benchmarking Large Vision-Language Models Using Themselves|IDEATOR：使用自身破解和评估大型视觉-语言模型的标准基准|Ruofan Wang, Juncheng Li, Yixu Wang, Bo Wang, Xiaosen Wang, Yan Teng, Yingchun Wang, Xingjun Ma .etc.|<http://arxiv.org/pdf/2411.00827v5>|[代码](https://roywang021.github.io/VLJailbreakBench.); 提出IDEATOR方法，自动生成恶意图像-文本对以攻击大型视觉语言模型，并创建VLJailbreak...|
|📝 更新|Imagine, Verify, Execute: Memory-guided Agentic Exploration with Vision-Language Models|想象、验证、执行：基于视觉语言模型的记忆引导智能探索|Seungjae Lee, Daniel Ekpo, Haowen Liu, Furong Huang, Abhinav Shrivastava, Jia-Bin Huang|<http://arxiv.org/pdf/2505.07815v3>|提出基于视觉语言模型的IVE框架，实现机器人自主探索并提升学习效率。|
|📝 更新|Parasite: A Steganography-based Backdoor Attack Framework for Diffusion Models|寄生物：一种基于隐写术的用于扩散模型的后门攻击框架|Jiahao Chen, Yu Pan, Yi Du, Chunkai Wu, Lin Wang|<http://arxiv.org/pdf/2504.05815v3>|提出了一种利用隐写术隐藏触发器的图像到图像任务后门攻击方法，提高了攻击的隐蔽性和灵活性。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DiFlow-TTS: Discrete Flow Matching with Factorized Speech Tokens for Low-Latency Zero-Shot Text-To-Speech|DiFlow-TTS：基于分解语音标记的低延迟零样本文本到语音的离散流匹配|Ngoc-Son Nguyen, Hieu-Nghia Huynh-Nguyen, Thanh V. T. Tran, Truong-Son Hy, Van Nguyen|<http://arxiv.org/pdf/2509.09631v1>|首次提出纯离散流匹配的DiFlow-TTS模型，实现低延迟零样本文本到语音合成，有效克隆语音属性。|
|📝 更新|Combating Falsification of Speech Videos with Live Optical Signatures (Extended Version)|对抗演讲视频伪造的光学活体签名技术（扩展版）|Hadleigh Schwartz, Xiaofeng Yan, Charles J. Carver, Xia Zhou|<http://arxiv.org/pdf/2504.21846v2>|提出VeriLight系统，通过在演讲现场创建并嵌入不可见的物理签名来保护视频免受身份和面部动作的视...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VRAE: Vertical Residual Autoencoder for License Plate Denoising and Deblurring|垂直残差自动编码器：用于车牌去噪和去模糊|Cuong Nguyen, Dung T. Tran, Hong Nguyen, Xuan-Vu Phan, Nam-Phong Nguyen|<http://arxiv.org/pdf/2509.08392v2>|提出了一种垂直残差自动编码器架构，用于交通监控中车辆牌照的去噪和去模糊，有效提升了识别性能。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VFlowOpt: A Token Pruning Framework for LMMs with Visual Information Flow-Guided Optimization|VFlowOpt：一种基于视觉信息流引导优化的语言模型标记剪枝框架|Sihan Yang, Runsen Xu, Chenhang Cui, Tai Wang, Dahua Lin, Jiangmiao Pang|<http://arxiv.org/pdf/2508.05211v2>|提出了一种视觉信息流优化的剪枝框架VFlowOpt，有效减少计算成本同时保持模型性能。|
|📝 更新|LiDAR-BIND-T: Improved and Temporally Consistent Sensor Modality Translation and Fusion for Robotic Applications|激光雷达-BIND-T：改进的时序一致传感器模态转换与融合方法在机器人应用中的研究|Niels Balemans, Ali Anwar, Jan Steckel, Siegfried Mercelis|<http://arxiv.org/pdf/2509.05728v2>|引入时间一致性机制以增强多模态传感器融合，提升机器人应用的定位与建图性能。|
|🆕 发布|S-BEVLoc: BEV-based Self-supervised Framework for Large-scale LiDAR Global Localization|基于BEV的自监督大规模激光雷达全局定位框架：S-BEVLoc|Chenghao Zhang, Lun Luo, Si-Yuan Cao, Xiaokai Bai, Yuncheng Jin, Zhu Yu, Beinan Yu, Yisen Wang .etc.|<http://arxiv.org/pdf/2509.09110v1>|提出了一种基于鸟瞰图的自监督LiDAR全局定位框架，无需高精度地面真实姿态，实现了大规模定位任务的高...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SpatialVID: A Large-Scale Video Dataset with Spatial Annotations|空间VID：一个具有空间注释的大规模视频数据集|Jiahao Wang, Yufeng Yuan, Rujie Zheng, Youtian Lin, Jian Gao, Lin-Zhuo Chen, Yajie Bao, Yi Zhang .etc.|<http://arxiv.org/pdf/2509.09676v1>|提出了大规模视频数据集SpatialVID，包含丰富空间标注，助力模型泛化与性能提升。|
|🆕 发布|In-Loop Filtering Using Learned Look-Up Tables for Video Coding|基于学习查找表的循环滤波在视频编码中的应用|Zhuoyuan Li, Jiacheng Li, Yao Li, Jialin Li, Li Li, Dong Liu, Feng Wu|<http://arxiv.org/pdf/2509.09494v1>|提出使用学习型查找表替代深度神经网络进行视频编码中的滤波处理，降低了计算复杂度和存储成本。|
|📝 更新|MESH -- Understanding Videos Like Human: Measuring Hallucinations in Large Video Models|MESH -- 如同人类理解视频：测量大型视频模型中的幻觉现象|Garry Yang, Zizhe Chen, Man Hon Wong, Haoyu Lei, Yongqiang Chen, Zhenguo Li, Kaiwen Zhou, James Cheng|<http://arxiv.org/pdf/2509.08538v2>|提出MESH基准，系统评估大型视频模型中的幻觉现象，与人类视频理解过程相吻合。|
|🆕 发布|DATE: Dynamic Absolute Time Enhancement for Long Video Understanding|动态绝对时间增强用于长视频理解|Chao Yuan, Yang Yang, Yehui Yang, Zach Cheng|<http://arxiv.org/pdf/2509.09263v1>|提出方法增强大型语言模型对长视频的时序理解，通过时间戳注入和语义引导的采样策略提升性能。|
|📝 更新|Early Exit and Multi Stage Knowledge Distillation in VLMs for Video Summarization|视频摘要中虚拟语言模型中的早期退出与多阶段知识蒸馏|Anas Anwarul Haq Khan, Utkarsh Verma, Ganesh Ramakrishnan|<http://arxiv.org/pdf/2504.21831v2>|提出了一种轻量级视频摘要模型DEEVISum，通过多阶段知识蒸馏和早期退出策略，实现了性能与效率的平...|
|📝 更新|C3VDv2 -- Colonoscopy 3D video dataset with enhanced realism|C3VDv2 -- 结肠镜3D视频数据集增强现实性|Mayank V. Golhar, Lucas Sebastian Galeano Fretes, Loren Ayers, Venkata S. Akshintala, Taylor L. Bobrow, Nicholas J. Durr|<http://arxiv.org/pdf/2506.24074v2>|[代码](https://durrlab.github.io/C3VDv2); 介绍了C3VDv2数据集，增强了真实性以促进3D结肠重建算法的定量评估。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MGTraj: Multi-Granularity Goal-Guided Human Trajectory Prediction with Recursive Refinement Network|多粒度目标引导的人类轨迹预测：带有递归细化网络的MGTraj方法|Ge Sun, Jun Ma|<http://arxiv.org/pdf/2509.09200v1>|提出多粒度目标引导的人类轨迹预测模型MGTraj，通过递归细化网络实现精准预测。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Improvement of Human-Object Interaction Action Recognition Using Scene Information and Multi-Task Learning Approach|利用场景信息与多任务学习方法提升人-物交互行为识别|Hesham M. Shehata, Mohammad Abdolrahmani|<http://arxiv.org/pdf/2509.09067v1>|利用场景信息和多任务学习改进了人-物交互动作识别的准确度。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Geometric Neural Distance Fields for Learning Human Motion Priors|几何神经网络距离场用于学习人类运动先验|Zhengdi Yu, Simone Foti, Linguang Zhang, Amy Zhao, Cem Keskin, Stefanos Zafeiriou, Tolga Birdal|<http://arxiv.org/pdf/2509.09667v1>|提出了一种基于神经距离场的3D人类运动生成先验，实现了稳健、一致且物理上合理的运动恢复。|
|📝 更新|Bridging Simplicity and Sophistication using GLinear: A Novel Architecture for Enhanced Time Series Prediction|使用GLinear桥接简洁与复杂：一种用于增强时间序列预测的新型架构|Syed Tahir Hussain Rizvi, Neel Kanwal, Muddasar Naeem|<http://arxiv.org/pdf/2501.01087v4>|提出GLinear模型，通过利用周期性模式提高多变量时间序列预测的准确性，同时减少所需历史数据量。|
|🆕 发布|Resource-Efficient Glioma Segmentation on Sub-Saharan MRI|撒哈拉以南地区MRI上的资源高效胶质瘤分割|Freedmore Sidume, Oumayma Soula, Joseph Muthui Wacira, YunFei Zhu, Abbas Rabiu Muhammad, Abderrazek Zeraii, Oluwaseun Kalejaye, Hajer Ibrahim .etc.|<http://arxiv.org/pdf/2509.09469v1>|提出了一种适用于资源受限环境的轻量级3D Attention UNet框架，用于改善撒哈拉以南地区脑...|
|📝 更新|Adapting Vision-Language Models for Neutrino Event Classification in High-Energy Physics|适应视觉-语言模型用于高能物理中的中微子事件分类|Dikshant Sagar, Kaiwen Yu, Alejandro Yankelevich, Jianming Bian, Pierre Baldi|<http://arxiv.org/pdf/2509.08461v2>|将视觉语言模型应用于高能物理中的中微子事件分类，提升了性能并增强了预测的可解释性。|
|🆕 发布|A Fully Automatic Framework for Intracranial Pressure Grading: Integrating Keyframe Identification, ONSD Measurement and Clinical Data|一种全自动的颅内压分级框架：关键帧识别、视神经鞘直径测量与临床数据融合|Pengxu Wen, Tingting Yu, Ziwei Nie, Cheng Jiang, Zhenyu Yin, Mingyang He, Bo Liao, Xiaoping Yang|<http://arxiv.org/pdf/2509.09368v1>|提出了一种自动化的 intracranial pressure 评估框架，通过结合关键帧识别、ONS...|
|📝 更新|Glo-UMF: A Unified Multi-model Framework for Automated Morphometry of Glomerular Ultrastructural Characterization|全局统一多模型框架：用于肾小球超微结构自动形态测量的方法|Zhentai Zhang, Danyi Weng, Guibin Zhang, Xiang Chen, Kaixing Long, Jian Geng, Yanmeng Lu, Lei Zhang .etc.|<http://arxiv.org/pdf/2508.10351v2>|提出统一多模型框架Glo-UMF，实现自动化肾小球超结构量化，提升病理分析效率。|
|📝 更新|EgoAgent: A Joint Predictive Agent Model in Egocentric Worlds|自我代理：在主观视角世界中的一种联合预测代理模型|Lu Chen, Yizhou Wang, Shixiang Tang, Qianhong Ma, Tong He, Wanli Ouyang, Xiaowei Zhou, Hujun Bao .etc.|<http://arxiv.org/pdf/2502.05857v3>|[代码](https://github.com/zju3dv/EgoAgent.); 提出了一种统一的第一人称视角智能体模型EgoAgent，能够同时感知环境、预测未来并采取行动，通过协...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GAPrompt: Geometry-Aware Point Cloud Prompt for 3D Vision Model|几何感知点云提示：用于三维视觉模型的GAPrompt|Zixiang Ai, Zichen Liu, Yuanhang Lei, Zhenyu Cui, Xu Zou, Jiahuan Zhou|<http://arxiv.org/pdf/2505.04119v3>|[代码](https://github.com/zhoujiahuan1991/ICML2025-GAPrompt.); 提出了一种利用几何信息的点云提示方法GAPrompt，有效提升3D视觉模型的适应性和性能。|
|🆕 发布|SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models|SQAP-VLA：一种用于高性能视觉-语言-动作模型协同量化感知剪枝框架|Hengyu Fang, Yijiang Liu, Yuan Du, Li Du, Huanrui Yang|<http://arxiv.org/pdf/2509.09090v1>|提出SQAP-VLA框架，通过协同量化与剪枝首次实现高效视觉语言动作模型加速。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Decoupling Clinical and Class-Agnostic Features for Reliable Few-Shot Adaptation under Shift|解耦临床特征与类别无关特征以实现可靠的小样本适应 under Shift|Umaima Rahman, Raza Imam, Mohammad Yaqub, Dwarikanath Mahapatra|<http://arxiv.org/pdf/2509.09397v1>|[代码](https://github.com/rumaima/DRiFt.); 提出了一种分离临床相关信号与任务无关噪声的DRiFt框架，有效提升了医学视觉语言模型在分布偏移下的适...|
|📝 更新|UnsafeBench: Benchmarking Image Safety Classifiers on Real-World and AI-Generated Images|不安全基准：在现实世界和AI生成图像上对图像安全性分类器进行基准测试|Yiting Qu, Xinyue Shen, Yixin Wu, Michael Backes, Savvas Zannettou, Yang Zhang|<http://arxiv.org/pdf/2405.03486v3>|提出 UnsafeBench，一种评估图像安全分类器在现实世界和AI生成图像上效果和鲁棒性的基准框架...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Improved GUI Grounding via Iterative Narrowing|通过迭代缩窄改进的GUI定位方法|Anthony Nguyen|<http://arxiv.org/pdf/2411.13591v7>|提出了一种迭代缩小区间的视觉提示框架，有效提升了视觉语言模型在GUI定位任务中的表现。|
|📝 更新|Total Disentanglement of Font Images into Style and Character Class Features|字体图像的风格与字符类别特征完全解耦|Daichi Haraguchi, Wataru Shimoda, Kota Yamaguchi, Seiichi Uchida|<http://arxiv.org/pdf/2403.12784v2>|[代码](https://github.com/uchidalab/total_disentanglement); 实现了字体图像在风格和字符类特征上的完全解耦，提高了识别准确度并适用于多种任务。|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Semantic Concentration for Self-Supervised Dense Representations Learning|用于自监督密集表征学习的语义集中|Peisong Wen, Qianqian Xu, Siran Dai, Runmin Cong, Qingming Huang|<http://arxiv.org/pdf/2509.09429v1>|[代码](https://github.com/KID-7391/CoTAP.); 提出了一种显式语义聚集方法，通过蒸馏 patch 对应关系和对象感知滤波器，有效学习稠密表示。|
|🆕 发布|Exploring Pre-training Across Domains for Few-Shot Surgical Skill Assessment|跨领域预训练在少量样本手术技能评估中的应用研究|Dimitrios Anastasiou, Razvan Caramalau, Nazir Sirajudeen, Matthew Boal, Philip Edwards, Justin Collins, John Kelly, Ashwin Sridhar .etc.|<http://arxiv.org/pdf/2509.09327v1>|[代码](https://github.com/anastadimi/ssa-fsl.); 探究跨领域预训练对少量样本手术技能评估的影响，发现领域相关的小数据集优于大规模不匹配数据集。|
|🆕 发布|Learning Object-Centric Representations in SAR Images with Multi-Level Feature Fusion|在SAR图像中通过多级特征融合学习以对象为中心的表示|Oh-Tae Jang, Min-Gon Cho, Kyung-Tae Kim|<http://arxiv.org/pdf/2509.09298v1>|提出了一种SlotSAR框架，通过多级特征融合分离SAR图像中的目标和背景 clutter，实现更准...|
|📝 更新|Uncertainty-aware Diffusion and Reinforcement Learning for Joint Plane Localization and Anomaly Diagnosis in 3D Ultrasound|不确定性感知的扩散与强化学习在三维超声联合平面定位与异常诊断中的应用|Yuhao Huang, Yueyue Xu, Haoran Dou, Jiaxiao Deng, Xin Yang, Hongyu Zheng, Dong Ni|<http://arxiv.org/pdf/2506.23538v2>|[代码](https://github.com/yuhoo0302/CUA-US.); 提出了一种结合去噪扩散模型和强化学习的方法，用于3D超声图像中的平面定位和异常诊断。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|You Share Beliefs, I Adapt: Progressive Heterogeneous Collaborative Perception|你共享信念，我适应：渐进式异构协同感知|Hao Si, Ehsan Javanmardi, Manabu Tsukada|<http://arxiv.org/pdf/2509.09310v1>|提出了一种无需联合训练的异质协同感知框架，通过实时自适应调整，实现了高效的特征对齐。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 目标导向视觉决策 (Goal-oriented Visual Decision Making)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning|全方位评估：通过任务自适应三维定位与身体感知推理的具身多用途规划器|Yuecheng Liu, Dafeng Chi, Shiguang Wu, Zhanguang Zhang, Yuzheng Zhuang, Bowen Yang, He Zhu, Lingfeng Zhang .etc.|<http://arxiv.org/pdf/2509.09332v1>|OmniEVA通过任务自适应3D定位和机器人约束感知推理，提升了多模态智能体的空间决策和任务规划能力...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MM-Prompt: Cross-Modal Prompt Tuning for Continual Visual Question Answering|MM-Prompt：跨模态提示调优用于持续视觉问答|Xu Li, Fan Lyu|<http://arxiv.org/pdf/2505.19455v2>|提出MM-Prompt框架，通过跨模态提示查询与恢复，解决视觉问答中模态不平衡问题，提升持续学习性能...|
|🆕 发布|ObjectReact: Learning Object-Relative Control for Visual Navigation|结果：对象相对控制视觉导航学习：ObjectReact|Sourav Garg, Dustin Craggs, Vineeth Bhat, Lachlan Mares, Stefan Podgorski, Madhava Krishna, Feras Dayoub, Ian Reid|<http://arxiv.org/pdf/2509.09594v1>|提出“对象相对”控制新范式，通过学习对象级地图表示提升视觉导航的泛化能力和路径规划效率。|
|🆕 发布|Visual Grounding from Event Cameras|事件相机视觉定位|Lingdong Kong, Dongyue Lu, Ao Liang, Rong Li, Yuhao Dong, Tianshuai Hu, Lai Xing Ng, Wei Tsang Ooi .etc.|<http://arxiv.org/pdf/2509.09584v1>|首次提出Talk2Event，一个用于事件相机视觉 grounding的大规模语言驱动基准，支持动态...|
|📝 更新|Focusing by Contrastive Attention: Enhancing VLMs' Visual Reasoning|通过对比注意力聚焦：增强视觉语言模型的视觉推理能力|Yuyao Ge, Shenghua Liu, Yiwei Wang, Lingrui Mei, Baolong Bi, Xuanshan Zhou, Jiayu Yao, Jiafeng Guo .etc.|<http://arxiv.org/pdf/2509.06461v2>|提出了一种无需额外训练的对比注意力精炼方法，有效提升视觉语言模型在复杂场景下的推理性能。|
|📝 更新|Shaken, Not Stirred: A Novel Dataset for Visual Understanding of Glasses in Human-Robot Bartending Tasks|"摇晃而非搅拌：面向人机调酒任务中酒杯视觉理解的创新数据集"|Lukáš Gajdošech, Hassan Ali, Jan-Gerrit Habekost, Martin Madaras, Matthias Kerzel, Stefan Wermter|<http://arxiv.org/pdf/2503.04308v3>|提出了一个自动标注流程和GlassNICOLDataset数据集，有效提升了机器人识别酒杯的能力。|
|🆕 发布|Visual Programmability: A Guide for Code-as-Thought in Chart Understanding|视觉编程性：图表理解中代码即思维指南|Bohao Tang, Yan Ma, Fei Zhang, Jiadi Su, Ethan Chern, Zhulin Hu, Zhixin Wang, Pengfei Liu .etc.|<http://arxiv.org/pdf/2509.09286v1>|提出了一种自适应的Code-as-Thought策略，使视觉语言模型能动态选择最佳图表理解路径。|
|🆕 发布|Model-Agnostic Open-Set Air-to-Air Visual Object Detection for Reliable UAV Perception|模型无关的开集空对空视觉目标检测以实现可靠的无人机感知|Spyridon Loukovitis, Anastasios Arsenos, Vasileios Karampinis, Athanasios Voulodimos|<http://arxiv.org/pdf/2509.09297v1>|提出了一种适用于无人机空中目标检测的模型无关的开集检测框架，通过熵模型估计语义不确定性，有效处理未知...|
|🆕 发布|Dynamic Structural Recovery Parameters Enhance Prediction of Visual Outcomes After Macular Hole Surgery|动态结构恢复参数增强视网膜孔手术后视觉结果预测|Yinzheng Zhao, Zhihao Zhao, Rundong Jiang, Louisa Sackewitz, Quanmin Liang, Mathias Maier, Daniel Zapp, Peter Charbel Issa .etc.|<http://arxiv.org/pdf/2509.09227v1>|提出动态结构恢复参数，结合深度学习框架，提高术后视力恢复预测准确性。|
|🆕 发布|VQualA 2025 Challenge on Visual Quality Comparison for Large Multimodal Models: Methods and Results|“VQualA 2025 大型多模态模型视觉质量比较挑战：方法与结果”|Hanwei Zhu, Haoning Wu, Zicheng Zhang, Lingyu Zhu, Yixuan Li, Peilin Chen, Shiqi Wang, Chris Wei Zhou .etc.|<http://arxiv.org/pdf/2509.09190v1>|介绍了VQualA 2025挑战，推动了大型多模态模型在视觉质量比较方面的能力提升。|
|🆕 发布|A Knowledge Noise Mitigation Framework for Knowledge-based Visual Question Answering|基于知识的视觉问答中知识噪声缓解框架|Zhiyue Liu, Sihang Liu, Jinyuan Liu, Xinru Zhang|<http://arxiv.org/pdf/2509.09159v1>|提出了一种减轻知识噪声的视觉问答框架，通过增强知识相关性和减少冗余来提高答案准确性。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Gradient-Attention Guided Dual-Masking Synergetic Framework for Robust Text-based Person Retrieval|梯度注意力引导的双掩码协同框架用于鲁棒基于文本的人物检索|Tianlu Zheng, Yifan Zhang, Xiang An, Ziyong Feng, Kaicheng Yang, Qichuan Ding|<http://arxiv.org/pdf/2509.09118v1>|提出梯度注意力引导的双掩码协同框架，优化了基于文本的人物检索性能。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Deep Learning Framework for Early Detection of Pancreatic Cancer Using Multi-Modal Medical Imaging Analysis|深度学习框架用于基于多模态医学影像分析的胰腺癌早期检测|Dennis Slobodzian, Amir Kordijazi|<http://arxiv.org/pdf/2508.20877v2>|开发了一种深度学习框架，通过双模态影像分析实现胰腺癌早期检测，准确率超90%，优于传统方法。|
|📝 更新|Expert-Guided Explainable Few-Shot Learning for Medical Image Diagnosis|专家引导的可解释小样本学习在医学图像诊断中的应用|Ifrat Ikhtear Uddin, Longwei Wang, KC Santosh|<http://arxiv.org/pdf/2509.08007v2>|提出了一种结合放射科专家指导的区域进行训练的解释性少样本学习方法，显著提升了医学图像诊断的准确性和可...|
|📝 更新|SV-DRR: High-Fidelity Novel View X-Ray Synthesis Using Diffusion Model|SV-DRR：基于扩散模型的高保真度新颖视角X射线合成|Chun Xie, Yuichi Yoshii, Itaru Kitahara|<http://arxiv.org/pdf/2507.05148v2>|提出了一种基于扩散模型的高保真度X射线新视角合成方法，实现了从单一视角生成多角度X射线图像，提高了图...|
|📝 更新|TinyDef-DETR: A DETR-based Framework for Defect Detection in Transmission Lines from UAV Imagery|基于DETR的无人机影像输电线路缺陷检测框架：TinyDef-DETR|Jiaming Cui, Shuai Zhou, Feng Shen|<http://arxiv.org/pdf/2509.06035v2>|提出TinyDef-DETR框架，通过增强边界敏感性和多尺度注意力机制，高效准确检测输电线路缺陷。|
|🆕 发布|FlexiD-Fuse: Flexible number of inputs multi-modal medical image fusion based on diffusion model|基于扩散模型的灵活输入数量多模态医学图像融合：FlexiD-Fuse|Yushen Xu, Xiaosong Li, Yuchun Wang, Xiaoqi Cheng, Huafeng Li, Haishu Tan|<http://arxiv.org/pdf/2509.09456v1>|提出FlexiD-Fuse模型，解决多模态医疗图像融合中输入模态数量固定的问题，实现灵活处理任意数量...|
|📝 更新|ABS-Mamba: SAM2-Driven Bidirectional Spiral Mamba Network for Medical Image Translation|ABS-Mamba：基于SAM2驱动的双向螺旋Mamba网络用于医学图像转换|Feng Yuan, Yifan Gao, Wenbin Wu, Keqing Wu, Xiaotong Guo, Jie Jiang, Xin Gao|<http://arxiv.org/pdf/2505.07687v2>|[代码](https://github.com/gatina-yone/ABS-Mamba); 提出ABS-Mamba网络，融合SAM2与CNNs，通过双分辨率框架和螺旋扫描增强医学图像跨模态翻译...|
|📝 更新|Towards Reliable Medical Image Segmentation by Modeling Evidential Calibrated Uncertainty|面向可靠医学图像分割的证据校准不确定性建模|Ke Zou, Yidi Chen, Ling Huang, Xuedong Yuan, Xiaojing Shen, Meng Wang, Rick Siow Mong Goh, Yong Liu .etc.|<http://arxiv.org/pdf/2301.00349v4>|提出了一种集成不确定性估计的医学图像分割模型，提高了预测的可靠性和准确性。|
|🆕 发布|Classification of Driver Behaviour Using External Observation Techniques for Autonomous Vehicles|使用外部观测技术对自动驾驶车辆驾驶员行为进行分类|Ian Nell, Shane Gilroy|<http://arxiv.org/pdf/2509.09349v1>|提出了一种利用外部观测技术对驾驶员行为进行分类的系统，通过实时对象跟踪和车道位置监测识别不安全驾驶行...|
|🆕 发布|Unified Start, Personalized End: Progressive Pruning for Efficient 3D Medical Image Segmentation|统一起点，个性化终点：用于高效三维医学图像分割的渐进式剪枝方法|Linhao Li, Yiwen Ye, Ziyang Chen, Yong Xia|<http://arxiv.org/pdf/2509.09267v1>|提出PSP-Seg动态剪枝框架，通过逐步剪除冗余模块提升3D医疗图像分割效率与适应多样性任务的能力。|
|🆕 发布|Towards Better Dental AI: A Multimodal Benchmark and Instruction Dataset for Panoramic X-ray Analysis|面向更优口腔AI：一种用于全景X射线分析的多模态基准和指令数据集|Jing Hao, Yuxuan Fan, Yanpeng Sun, Kaixin Guo, Lizhuo Lin, Jinrong Yang, Qi Yong H. Ai, Lun M. Wong .etc.|<http://arxiv.org/pdf/2509.09254v1>|[代码](https://github.com/isbrycee/OralGPT.); 提出了首个针对全景X光片的大型多模态指令数据集和评估基准，显著提升了牙科AI模型的诊断准确性。|
|🆕 发布|Medverse: A Universal Model for Full-Resolution 3D Medical Image Segmentation, Transformation and Enhancement|Medverse：全分辨率三维医学图像分割、转换与增强的通用模型|Jiesi Hu, Jianfeng Cao, Yanwu Yang, Chenfei Ye, Yixuan Zhang, Hanyang Peng, Ting Ma|<http://arxiv.org/pdf/2509.09232v1>|[代码](https://github.com/jiesihu/Medverse.); 提出Medverse模型，通过自回归在位学习和跨注意力模块，实现了全分辨率3D医疗图像的通用分割、转...|
|🆕 发布|Bridging the Gap Between Ideal and Real-world Evaluation: Benchmarking AI-Generated Image Detection in Challenging Scenarios|在理想与现实评估之间架起桥梁：在具有挑战性的场景中对AI生成图像检测进行基准测试|Chunxiao Li, Xiaoxiao Wang, Meiling Li, Boming Miao, Peng Sun, Yunjian Zhang, Xiangyang Ji, Yao Zhu|<http://arxiv.org/pdf/2509.09172v1>|提出Real-World Robustness Dataset，全面评估AI生成图像检测模型在复杂现...|
|🆕 发布|Enhancing 3D Medical Image Understanding with Pretraining Aided by 2D Multimodal Large Language Models|使用二维多模态大型语言模型辅助预训练增强三维医学图像理解|Qiuhui Chen, Xuancheng Yao, Huping Ye, Yi Hong|<http://arxiv.org/pdf/2509.09064v1>|[代码](https://github.com/Qybc/Med3DInsight.); 提出Med3DInsight框架，融合2D语言模型与3D图像编码器，提升医学图像理解能力。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GEMINUS: Dual-aware Global and Scene-Adaptive Mixture-of-Experts for End-to-End Autonomous Driving|GEMINUS：端到端自动驾驶中的双感知全局与场景自适应专家混合模型|Chi Wan, Yixin Cui, Jiatong Du, Shuo Yang, Yulong Bai, Peng Yi, Nan Li, Yanjun Huang|<http://arxiv.org/pdf/2507.14456v4>|[代码](https://github.com/newbrains1/GEMINUS.); 提出了一种结合全局与场景自适应专家模块的自动驾驶框架，有效提升了多样场景下的适应性和鲁棒性。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Deep Learning-based Cross-modal Reconstruction of Vehicle Target from Sparse 3D SAR Image|基于深度学习的稀疏三维合成孔径雷达图像车辆目标跨模态重建|Da Li, Guoqiang Zhao, Chen Yao, Kaiqiang Zhu, Houjun Sun, Jiacheng Bao, Maokun Li|<http://arxiv.org/pdf/2406.04158v7>|提出了一种融合光学信息的跨模态学习方法，显著提升了稀疏三维合成孔径雷达图像的车辆目标重建质量。|
|🆕 发布|CWSSNet: Hyperspectral Image Classification Enhanced by Wavelet Domain Convolution|基于小波域卷积的CWSSNet：高光谱图像分类增强方法|Yulin Tong, Fengzong Zhang, Haiqin Cheng|<http://arxiv.org/pdf/2509.09163v1>|提出CWSSNet框架，融合3D光谱-空间特征与波动域卷积，提升高光谱图像分类性能。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mind Meets Space: Rethinking Agentic Spatial Intelligence from a Neuroscience-inspired Perspective|"心智遇见空间：从神经科学启发的视角重新思考能动空间智能"|Bui Duc Manh, Soumyaratna Debnath, Zetong Zhang, Shriram Damodaran, Arvind Kumar, Yueyi Zhang, Lu Mi, Erik Cambria .etc.|<http://arxiv.org/pdf/2509.09154v1>|提出了一种基于神经科学的计算框架，以增强AI在复杂环境中的空间推理能力。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Improving Alignment in LVLMs with Debiased Self-Judgment|在LVLMs中通过去偏自我判断改进对齐|Sihan Yang, Chenhang Cui, Zihao Zhao, Yiyang Zhou, Weilong Yan, Ying Wei, Huaxiu Yao|<http://arxiv.org/pdf/2508.20655v2>|提出内部生成去偏自我评判分数的方法，自主提升大型视觉语言模型中视觉与语言模态的对齐效果。|
|📝 更新|Attention-Guided Multi-scale Interaction Network for Face Super-Resolution|基于注意力引导的多尺度交互网络用于人脸超分辨率|Xujie Wan, Wenjie Li, Guangwei Gao, Huimin Lu, Jian Yang, Chia-Wen Lin|<http://arxiv.org/pdf/2409.00591v4>|提出了一种融合局部与全局特征交互的AMINet网络，有效提升面部超分辨率性能与效率。|

