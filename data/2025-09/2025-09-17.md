## [UPDATED!] **2025-09-17** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AD-DINOv3: Enhancing DINOv3 for Zero-Shot Anomaly Detection with Anomaly-Aware Calibration|AD-DINOv3：使用异常感知校准增强DINOv3进行零样本异常检测|Jingyi Yuan, Jianxiong Ye, Wenkang Chen, Chenqiang Gao|<http://arxiv.org/pdf/2509.14084v1>|提出AD-DINOv3框架，通过视觉和文本多模态对比学习及异常感知校准，提升零样本异常检测性能。|
|🆕 发布|LLM-I: LLMs are Naturally Interleaved Multimodal Creators|LLM-I：语言模型自然融合的多模态创作者|Zirun Guo, Feng Zhang, Kai Jia, Tao Jin|<http://arxiv.org/pdf/2509.13642v1>|[代码](https://github.com/ByteDance-BandAI/LLM-I.); 提出LLM-I框架，通过智能调度多种视觉工具，解决统一模型在事实性和程序精度任务上的局限，实现图像和...|
|🆕 发布|SAMIR, an efficient registration framework via robust feature learning from SAM|and efficient registration framework based on robust feature learning from SAM  SAMIR，一种基于SAM的稳健特征学习的高效配准框架|Yue He, Min Liu, Qinghao Liu, Jiazheng Wang, Yaonan Wang, Hang Zhang, Xiang Chen|<http://arxiv.org/pdf/2509.13629v1>|提出了一种利用预训练视觉模型SAM的医学图像配准框架，通过结构感知特征提取显著提升了配准精度。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SAIL-VL2 Technical Report|"SAIL-VL2技术报告"|Weijie Yin, Yongjie Ye, Fangxun Shu, Yue Liao, Zijian Kang, Hongyuan Dong, Haiyang Yu, Dingkang Yang .etc.|<http://arxiv.org/pdf/2509.14033v1>|SAIL-VL2通过大规模数据筛选、渐进式训练框架和高效模型架构，实现了多模态理解和推理的突破性性能...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Can Current AI Models Count What We Mean, Not What They See? A Benchmark and Systematic Evaluation|当前AI模型能否计算我们的意图而非仅所见？一个基准和系统性评估|Gia Khanh Nguyen, Yifeng Huang, Minh Hoai|<http://arxiv.org/pdf/2509.13939v1>|提出PairTally基准数据集，评估了AI模型在细粒度视觉计数任务中的性能不足。|
|🆕 发布|Diving into Mitigating Hallucinations from a Vision Perspective for Large Vision-Language Models|深入探索从视觉角度减轻大规模视觉语言模型中的幻觉现象|Weihang Wang, Xinhao Li, Ziyue Wang, Yan Pang, Jielei Zhang, Peiyi Li, Qiang Zhang, Longwen Gao|<http://arxiv.org/pdf/2509.13836v1>|提出细粒度基准VHBench-10并设计VisionWeaver网络，有效减少大型视觉语言模型中的幻...|
|🆕 发布|Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation|一致视图对齐提升三维医学图像分割基础模型|Puru Vaish, Felix Meister, Tobias Heimann, Christoph Brune, Jelmer M. Wolterink|<http://arxiv.org/pdf/2509.13846v1>|[代码](https://github.com/Tenbatsu24/LatentCampus.); 提出了一种视图对齐方法，通过显式诱导结构提升3D医疗图像分割基础模型的性能。|
|📝 更新|Humor in Pixels: Benchmarking Large Multimodal Models Understanding of Online Comics|像素中的幽默：评估大型多模态模型对在线漫画理解能力的基准测试|Yuriel Ryan, Rui Yang Tan, Kenny Tsu Wei Choo, Roy Ka-Wei Lee|<http://arxiv.org/pdf/2509.12248v2>|提出了PixelHumor基准数据集，评估大型多模态模型理解在线漫画中的幽默和叙事序列的能力。|
|📝 更新|DPDEdit: Detail-Preserved Diffusion Models for Multimodal Fashion Image Editing|DPDEdit：细节保留的扩散模型用于多模态时尚图像编辑|Xiaolong Wang, Zhi-Qi Cheng, Jue Wang, Xiaojiang Peng|<http://arxiv.org/pdf/2409.01086v3>|提出了一种基于扩散模型的多模态时尚图像编辑方法，通过精确定位和纹理细节保留，显著提升了图像编辑的准确...|
|📝 更新|A Culturally-diverse Multilingual Multimodal Video Benchmark & Model|多语言多模态文化多样性视频基准与模型|Bhuiyan Sanjid Shafique, Ashmal Vayani, Muhammad Maaz, Hanoona Abdul Rasheed, Dinura Dissanayake, Mohammed Irfan Kurpath, Yahya Hmaiti, Go Inoue .etc.|<http://arxiv.org/pdf/2506.07032v2>|[代码](https://mbzuai-oryx.github.io/ViMUL); 提出首个多语言多模态视频模型基准ViMUL-Bench，促进文化及语言包容性视频理解研究。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Deceptive Beauty: Evaluating the Impact of Beauty Filters on Deepfake and Morphing Attack Detection|《美丽的陷阱：评估美颜滤镜对深度伪造和变脸攻击检测的影响》|Sara Concas, Simone Maurizio La Cava, Andrea Panzino, Ester Masala, Giulia Orrù, Gian Luca Marcialis|<http://arxiv.org/pdf/2509.14120v1>|评估美颜滤镜对深度伪造和变脸攻击检测性能的影响，发现美颜滤镜显著降低检测准确度。|
|📝 更新|A Novel Compression Framework for YOLOv8: Achieving Real-Time Aerial Object Detection on Edge Devices via Structured Pruning and Channel-Wise Distillation|《一种面向YOLOv8的新型压缩框架：通过结构化剪枝和逐通道蒸馏在边缘设备上实现实时空中目标检测》|Melika Sabaghian, Mohammad Ali Keyvanrad, Seyyedeh Mahila Moghadami|<http://arxiv.org/pdf/2509.12918v2>|提出三阶段压缩框架，通过稀疏训练、结构剪枝和知识蒸馏，实现YOLOv8模型在边缘设备上的实时空中目标...|
|🆕 发布|Morphology-optimized Multi-Scale Fusion: Combining Local Artifacts and Mesoscopic Semantics for Deepfake Detection and Localization|形态优化多尺度融合：结合局部特征与 mesoscopic 语义进行深度伪造检测与定位|Chao Shuai, Gaojian Wang, Kun Pan, Tong Wu, Fanli Jin, Haohan Tan, Mengxiang Li, Zhenguang Liu .etc.|<http://arxiv.org/pdf/2509.13776v1>|提出了一种融合局部细节和全局语义的形态优化多尺度融合方法，有效提升了深伪检测与定位的准确性和鲁棒性。|
|🆕 发布|Mitigating Query Selection Bias in Referring Video Object Segmentation|减轻指引用视频对象分割中的查询选择偏差|Dingwei Zhang, Dong Zhang, Jinhui Tang|<http://arxiv.org/pdf/2509.13722v1>|提出Triple Query Former缓解查询选择偏差，通过结合视觉和语言信息动态构建查询并引入...|
|📝 更新|Skyshield: Event-Driven Submillimetre Thin Obstacle Detection for Drone Flight Safety|天盾：面向无人机飞行安全的基于事件驱动的亚毫米级薄障碍物检测|Zhengli Zhang, Xinyu Luo, Yucheng Sun, Wenhua Ding, Dongyue Huang, Xinlei Chen|<http://arxiv.org/pdf/2508.09397v2>|提出了一种基于事件驱动的框架SkyShield，有效检测无人机面临的亚毫米级细小障碍物。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Performance Optimization of YOLO-FEDER FusionNet for Robust Drone Detection in Visually Complex Environments|《在视觉复杂环境中针对无人机检测的YOLO-FEDER FusionNet性能优化》|Tamara R. Lenhard, Andreas Weinmann, Tobias Koch|<http://arxiv.org/pdf/2509.14012v1>|优化了YOLO-FEDER FusionNet，通过改进训练数据和特征融合策略，显著提升了复杂视觉环...|
|🆕 发布|Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust Spacecraft 6-DoF Pose Estimation|弥合合成与真实差距：用于稳健航天器六自由度位姿估计的监督域自适应|Inder Pal Singh, Nidhal Eddine Chenni, Abd El Rahman Shabayek, Arunkumar Rathinam, Djamila Aouada|<http://arxiv.org/pdf/2509.13792v1>|提出了一种针对 spacecraft 6-DoF 姿态估计的监督域自适应框架，有效缓解了合成数据与真...|
|🆕 发布|SWA-PF: Semantic-Weighted Adaptive Particle Filter for Memory-Efficient 4-DoF UAV Localization in GNSS-Denied Environments|SWA-PF：面向GNSS拒止环境下内存高效四自由度无人机定位的语义加权自适应粒子滤波器|Jiayu Yuan, Ming Dai, Enhui Zheng, Chao Su, Nanxing Chen, Qiming Hu, Shibo Zhu, Yibin Cao|<http://arxiv.org/pdf/2509.13795v1>|[代码](https://github.com/YuanJiayuuu/SWA-PF.); 提出了一种结合语义特征和优化粒子滤波器的定位方法，显著提升了GNSS受限环境下无人机定位的效率和精度...|
|📝 更新|Direct Video-Based Spatiotemporal Deep Learning for Cattle Lameness Detection|基于视频的直接时空深度学习在牛跛行检测中的应用|Md Fahimuzzman Sohan, Raid Alzubi, Hadeel Alzoubi, Eid Albalawi, A. H. Abdul Hafez|<http://arxiv.org/pdf/2504.16404v3>|提出了一种基于视频的直接时空深度学习方法，实现了高效准确的牛跛行自动检测。|
|📝 更新|PlaneRecTR++: Unified Query Learning for Joint 3D Planar Reconstruction and Pose Estimation|《PlaneRecTR++：联合三维平面重建与位姿估计的统一查询学习》|Jingjia Shi, Shuaifeng Zhi, Kai Xu|<http://arxiv.org/pdf/2307.13756v4>|[代码](https://github.com/SJingjia/PlaneRecTR-PP.); PlaneRecTR++首次将多视角平面重建和姿态估计的所有任务统一于一个紧凑的单阶段框架内，提升了...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic Segmentation|少量样本三维点云语义分割中的白化聚合与恢复|Jiyun Im, SuBeen Lee, Miso Lee, Jae-Pil Heo|<http://arxiv.org/pdf/2509.13907v1>|提出了一种基于白化聚合和恢复的先进原型生成方法，有效解决了少量样本三维点云语义分割中的分布差异问题。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Leveraging Perceptual Scores for Dataset Pruning in Computer Vision Tasks|利用感知分数进行计算机视觉任务中的数据集剪枝|Raghavendra Singh|<http://arxiv.org/pdf/2408.07243v2>|提出了一种基于图像熵的简单评分方法，用于优化计算机视觉任务的数据集剪枝，提高了样本选择的质量和多样性...|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision|统一思维链：跨文本与视觉的统一推理方法|Luozheng Qin, Jia Gong, Yuqing Sun, Tianjiao Li, Mengping Yang, Xiaomeng Yang, Chao Qu, Zhiyu Tan .etc.|<http://arxiv.org/pdf/2508.05606v2>|[代码](https://sais-fuxi.github.io/projects); 提出了Uni-CoT框架，通过统一模型实现视觉与文本的连贯多模态推理，有效解决视觉状态转换难题。|
|🆕 发布|Generative AI for Misalignment-Resistant Virtual Staining to Accelerate Histopathology Workflows|《用于抗偏移性虚拟染色的生成式人工智能以加速病理组织学工作流程》|Jiabo MA, Wenqiang Li, Jinbang Li, Ziyi Liu, Linshan Wu, Fengtao Zhou, Li Liang, Ronald Cheong Kin Chan .etc.|<http://arxiv.org/pdf/2509.14119v1>|提出了一种抗错位虚拟染色的生成式AI框架，有效解决了现有方法在临床应用中的对齐问题。|
|📝 更新|SCALP: Superpixels with Contour Adherence using Linear Path|SCALP: 利用线性路径实现轮廓附着的超像素|Rémi Giraud, Vinh-Thong Ta, Nicolas Papadakis|<http://arxiv.org/pdf/1903.07149v2>|提出了一种快速迭代聚类框架下的SCALP方法，通过优化像素到超像素质心的线性路径距离，实现了规则紧凑...|
|📝 更新|Identity-Preserving Text-to-Video Generation Guided by Simple yet Effective Spatial-Temporal Decoupled Representations|保持身份一致性的基于简单而有效的时空解耦表示的文本到视频生成|Yuji Wang, Moran Li, Xiaobin Hu, Ran Yi, Jiangning Zhang, Han Feng, Weijian Cao, Yabiao Wang .etc.|<http://arxiv.org/pdf/2507.04705v2>|提出了一种将空间和时间特征解耦的简单有效框架，实现了文本到视频生成中身份保持和动态一致性的优化。|
|🆕 发布|MetricNet: Recovering Metric Scale in Generative Navigation Policies|MetricNet：在生成导航策略中恢复度量尺度|Abhijeet Nayak, Débora N. P. Oliveira, Samiran Gode, Cordelia Schmid, Wolfram Burgard|<http://arxiv.org/pdf/2509.13965v1>|提出MetricNet方法，为生成导航策略预测真实世界坐标中的距离，提升导航与探索性能。|
|🆕 发布|InterKey: Cross-modal Intersection Keypoints for Global Localization on OpenStreetMap|跨模态交点关键点：基于开放街图的全球定位|Nguyen Hoang Khoi Tran, Julie Stephany Berrio, Mao Shan, Stewart Worrall|<http://arxiv.org/pdf/2509.13857v1>|提出了一种利用道路交叉口作为显著地标进行全局定位的跨模态框架InterKey，实现了高精度车辆定位。|
|🆕 发布|A Generalization of CLAP from 3D Localization to Image Processing, A Connection With RANSAC & Hough Transforms|从三维定位到图像处理的CLAP泛化，与RANSAC和霍夫变换的关联|Ruochen Hou, Gabriel I. Fernandez, Alex Xu, Dennis W. Hong|<http://arxiv.org/pdf/2509.13605v1>|将CLAP算法从2D定位扩展到3D定位和图像拼接，提供了一种新的鲁棒去噪和错误匹配抑制方法。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GenExam: A Multidisciplinary Text-to-Image Exam|《GenExam：一种多学科文本到图像考试系统》|Zhaokai Wang, Penghao Yin, Xiangyu Zhao, Changyao Tian, Yu Qiao, Wenhai Wang, Jifeng Dai, Gen Luo|<http://arxiv.org/pdf/2509.14232v1>|提出了GenExam，首个多学科文本到图像考核基准，通过考试形式评估模型的综合知识、推理和生成能力。|
|📝 更新|Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound|视频拟音：通过时间事件条件实现的两阶段视频转声音生成拟音效果|Junwon Lee, Jaekwon Im, Dabin Kim, Juhan Nam|<http://arxiv.org/pdf/2408.11915v3>|[代码](https://jnwnlee.github.io/video-foley-demo); 提出Video-Foley系统，通过使用RMS作为直观条件与语义音色提示，实现了无需标注的音视频同步...|
|🆕 发布|Wan-Animate: Unified Character Animation and Replacement with Holistic Replication|《Wan-Animate：统一的角色动画与替换及整体复制》|Gang Cheng, Xin Gao, Li Hu, Siqi Hu, Mingyang Huang, Chaonan Ji, Ju Li, Dechao Meng .etc.|<http://arxiv.org/pdf/2509.14055v1>|提出了Wan-Animate框架，实现了角色动画和替换的统一处理，通过精确复制表情和动作生成高质量角...|
|🆕 发布|Noise-Level Diffusion Guidance: Well Begun is Half Done|噪声水平扩散引导：良好的开端是成功的一半|Harvey Mannering, Zhiwu Huang, Adam Prugel-Bennett|<http://arxiv.org/pdf/2509.13936v1>|[代码](https://github.com/harveymannering/NoiseLevelGuidance.); 提出了一种无需额外训练数据或网络结构的噪声水平优化方法NLG，有效提升了扩散模型生成图像的质量和条件...|
|📝 更新|Enhancing Intent Understanding for Ambiguous prompt: A Human-Machine Co-Adaption Strategy|《增强模糊提示意图理解：一种人机协同适应策略》|Yangfan He, Jianhui Wang, Yijin Wang, Yan Zhong, Xinyuan Song, Junjiang Lin, Xinhang Yuan, Jingqun Tang .etc.|<http://arxiv.org/pdf/2501.15167v7>|提出了一种人机协同适应策略，通过优化用户提示与图片间的互信息，有效提升了模型对用户意图的理解和适应能...|
|🆕 发布|EDITS: Enhancing Dataset Distillation with Implicit Textual Semantics|EDITS：利用隐含文本语义增强数据集蒸馏|Qianxin Xia, Jiawei Du, Guoming Lu, Zhiyong Shu, Jielei Wang|<http://arxiv.org/pdf/2509.13858v1>|[代码](https://github.com/einsteinxia/EDITS.); 利用图像内隐含的文本语义信息，提出EDITS框架以增强数据集蒸馏效果。|
|📝 更新|Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis|“Kling-Avatar：为级联长时虚拟人动画合成定位多模态指令”|Yikang Ding, Jiwen Liu, Wenyuan Zhang, Zekun Wang, Wentao Hu, Liyuan Cui, Mingming Lao, Yingchao Shao .etc.|<http://arxiv.org/pdf/2509.09595v2>|提出了一种统一多模态指令理解与照片级人像生成的级联框架，实现了生动、流畅的长时视频合成。|
|🆕 发布|Rest2Visual: Predicting Visually Evoked fMRI from Resting-State Scans|《Rest2Visual：从静息态扫描预测视觉诱发的fMRI》|Chuyang Zhou, Ziao Ji, Daochang Liu, Dongang Wang, Chenyu Wang, Chang Xu|<http://arxiv.org/pdf/2509.13612v1>|提出Rest2Visual模型，通过 resting-state fMRI 和视觉刺激预测个体化视觉...|
|📝 更新|DiffGAN: A Test Generation Approach for Differential Testing of Deep Neural Networks for Image Analysis|差分生成对抗网络：一种用于图像分析深度神经网络差分测试的测试生成方法|Zohreh Aghababaeyan, Manel Abdellatif, Lionel Briand, Ramesh S|<http://arxiv.org/pdf/2410.19794v4>|提出了一种基于生成对抗网络和遗传算法的DiffGAN方法，用于生成揭示深度神经网络行为差异的测试图像...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|StyleSculptor: Zero-Shot Style-Controllable 3D Asset Generation with Texture-Geometry Dual Guidance|《StyleSculptor：基于纹理-几何双重引导的无样本风格可控三维资产生成》|Zefan Qu, Zhenwei Wang, Haoyuan Wang, Ke Xu, Gerhard Hancke, Rynson W. H. Lau|<http://arxiv.org/pdf/2509.13301v2>|提出了StyleSculptor，一种无需训练的零样本3D资产生成方法，通过纹理和几何双重引导实现风...|
|🆕 发布|Generative Image Coding with Diffusion Prior|扩散先验的生成图像编码|Jianhui Chang|<http://arxiv.org/pdf/2509.13768v1>|提出了一种利用扩散先验的生成图像编码框架，显著提升了低比特率下的视觉保真度和压缩性能。|
|🆕 发布|Iterative Prompt Refinement for Safer Text-to-Image Generation|迭代提示精炼以提高文本到图像生成的安全性|Jinwoo Jeon, JunHyeok Oh, Hayeong Lee, Byung-Jun Lee|<http://arxiv.org/pdf/2509.13760v1>|[代码](https://github.com/ku-dmlab/IPR.); 提出了一种迭代提示精炼算法，通过视觉反馈提高文本到图像生成模型的安全性，同时保持用户意图。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Synthesis and Perceptual Scaling of High Resolution Naturalistic Images Using Stable Diffusion|使用稳定扩散合成和感知缩放高分辨率自然图像|Leonardo Pettini, Carsten Bogler, Christian Doeller, John-Dylan Haynes|<http://arxiv.org/pdf/2410.13034v2>|利用稳定扩散模型生成具有渐进过渡特性的高分辨率自然图像，为视觉感知研究提供了连续性刺激集。|
|📝 更新|Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients|通过逐步干预和测量属性梯度来局部解释预测行为|Niklas Penzel, Joachim Denzler|<http://arxiv.org/pdf/2503.05424v2>|提出了一种基于图像编辑模型的局部干预解释框架，通过量化属性变化对预测的影响，提高了深度学习模型的可解...|
|🆕 发布|Towards Robust Defense against Customization via Protective Perturbation Resistant to Diffusion-based Purification|面向抵抗基于扩散纯化的保护性扰动防御定制化攻击|Wenkui Yang, Jie Cao, Junxian Duan, Ran He|<http://arxiv.org/pdf/2509.13922v1>|提出了一种名为AntiPure的保护性扰动方法，有效抵御了图像净化攻击，增强了定制化图像的安全性。|
|🆕 发布|Distractor-Aware Memory-Based Visual Object Tracking|分心物感知的基于内存的视觉目标跟踪|Jovana Videnovic, Matej Kristan, Alan Lukezic|<http://arxiv.org/pdf/2509.13864v1>|提出了一种针对视觉对象跟踪的干扰物感知内存模块，有效减少了对干扰物的跟踪漂移并增强遮挡后物体的重新检...|
|🆕 发布|BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching|BWCache：通过块状缓存加速视频扩散变换器|Hanshuai Cui, Zhiqing Tang, Zhifei Xu, Zhi Yao, Wenyi Zeng, Weijia Jia|<http://arxiv.org/pdf/2509.13789v1>|提出了一种无训练需求的Block-Wise Caching方法，通过动态缓存和重用特征，显著加速了视...|
|🆕 发布|Controllable-Continuous Color Editing in Diffusion Model via Color Mapping|通过颜色映射在扩散模型中进行可控连续的颜色编辑|Yuqi Yang, Dongliang Chang, Yuanchen Fang, Yi-Zhe SonG, Zhanyu Ma, Jun Guo|<http://arxiv.org/pdf/2509.13756v1>|引入颜色映射模块实现精确且连续的图像颜色控制，解决了传统文本驱动图像编辑中的颜色控制难题。|
|🆕 发布|Cross-modal Full-mode Fine-grained Alignment for Text-to-Image Person Retrieval|跨模态全模式细粒度对齐用于文本到图像的人物检索|Hao Yin, Xin Man, Feiyu Chen, Jie Shao, Heng Tao Shen|<http://arxiv.org/pdf/2509.13754v1>|[代码](https://github.com/yinhao1102/FMFA.); 提出了一种全模式细粒度对齐框架，通过显式和隐式关系推理改善文本到图像人物检索的匹配精度。|
|🆕 发布|StyleProtect: Safeguarding Artistic Identity in Fine-tuned Diffusion Models|风格保护：在微调扩散模型中守护艺术身份|Qiuyu Tang, Joshua Krinsky, Aparna Bharati|<http://arxiv.org/pdf/2509.13711v1>|提出StyleProtect方法，通过更新特定注意力层有效防御艺术风格模仿。|
|🆕 发布|Re-purposing SAM into Efficient Visual Projectors for MLLM-Based Referring Image Segmentation|将 SAM 重新应用于基于 MLLM 的指引用图分割中的高效视觉投影器|Xiaobo Yang, Xiaojin Gong|<http://arxiv.org/pdf/2509.13676v1>|提出了一种利用语义超像素压缩视觉令牌的方法，大幅减少了计算负担同时保持分割性能。|
|📝 更新|GWM: Towards Scalable Gaussian World Models for Robotic Manipulation|面向机器人操作的可扩展高斯世界模型：GWM|Guanxing Lu, Baoxiong Jia, Puhao Li, Yixin Chen, Ziwei Wang, Yansong Tang, Siyuan Huang|<http://arxiv.org/pdf/2508.17600v2>|提出 Gaussian World Model，通过预测未来状态提升机器人操作精度，实现超越现有技术...|
|📝 更新|Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations|通过保持预训练表征来增强视觉-语言-动作模型的一般化能力|Shresth Grover, Akshay Gopalkrishnan, Bo Ai, Henrik I. Christensen, Hao Su, Xuanlin Li|<http://arxiv.org/pdf/2509.11417v2>|提出了一种双编码器框架，有效保留预训练特征以提升机器人操作任务的泛化能力。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MCGS-SLAM: A Multi-Camera SLAM Framework Using Gaussian Splatting for High-Fidelity Mapping|多相机SLAM框架：使用高斯散点绘制实现高保真地图构建的MCGS-SLAM|Zhihao Cao, Hanyu Wu, Li Wa Tang, Zizhou Luo, Zihan Zhu, Wei Zhang, Marc Pollefeys, Martin R. Oswald|<http://arxiv.org/pdf/2509.14191v1>|提出了一种多相机SLAM框架，通过高斯散点技术实现高保真度地图构建，提升了鲁棒性和几何覆盖范围。|
|📝 更新|Well-Conditioned Polynomial Representations for Mathematical Handwriting Recognition|数学手写体识别中的良好条件多项式表示|Robert M. Corless, Deepak Singh Kalhan, Stephen M. Watt|<http://arxiv.org/pdf/2509.10815v2>|探究不同基底与多项式度数间的平衡，以实现数学手写识别的准确建模与低计算成本。|
|📝 更新|Noise2Ghost: Self-supervised deep convolutional reconstruction for ghost imaging|噪声至鬼影：基于自监督深度卷积重构的鬼影成像|Mathieu Manni, Dmitry Karpov, K. Joost Batenburg, Sharon Shwartz, Nicola Viganò|<http://arxiv.org/pdf/2504.10288v2>|提出了一种无需参考数据的自监督深度学习重构方法，显著提升了噪声环境下鬼成像的重建性能。|
|🆕 发布|EvHand-FPV: Efficient Event-Based 3D Hand Tracking from First-Person View|基于第一视角的高效事件驱动三维手部追踪：EvHand-FPV|Zhen Xu, Guorui Lu, Chang Gao, Qinyu Chen|<http://arxiv.org/pdf/2509.13883v1>|[代码](https://github.com/zen5x5/EvHand-FPV.); 提出了一种基于事件相机的轻量级3D手部追踪框架，大幅提升了追踪准确性和效率。|
|🆕 发布|LamiGauss: Pitching Radiative Gaussian for Sparse-View X-ray Laminography Reconstruction|拉米高斯：抛投辐射高斯用于稀疏视角X射线层析重建|Chu Chen, Ander Biguri, Jean-Michel Morel, Raymond H. Chan, Carola-Bibiane Schönlieb, Jizhou Li|<http://arxiv.org/pdf/2509.13863v1>|提出了一种针对稀疏视角X射线层析成像的高效重建算法LamiGauss，通过优化模型容量分配，实现了准...|
|🆕 发布|Gaussian Alignment for Relative Camera Pose Estimation via Single-View Reconstruction|通过单视图重建的相对相机姿态估计的高斯对齐方法|Yumin Li, Dylan Campbell|<http://arxiv.org/pdf/2509.13652v1>|提出了一种无需训练的GARPS框架，通过单视图重建直接对齐3D场景以实现稳健的度量相对相机位姿估计。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dense Video Understanding with Gated Residual Tokenization|带门控残差标记的密集视频理解|Haichao Zhang, Wenhao Chai, Shwai He, Ang Li, Yun Fu|<http://arxiv.org/pdf/2509.14199v1>|提出Dense Video Understanding框架及Gated Residual Token...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PROFUSEme: PROstate Cancer Biochemical Recurrence Prediction via FUSEd Multi-modal Embeddings|PROFUSEme：通过融合多模态嵌入进行前列腺癌生化复发预测|Suhang You, Carla Pitarch-Abaigar, Sanket Kachole, Sumedh Sonawane, Juhyung Ha, Anish Sudarshan Gada, David Crandall, Rakesh Shiradkar .etc.|<http://arxiv.org/pdf/2509.14051v1>|提出了一种融合临床、影像和病理数据的跨模态嵌入方法，用于预测前列腺癌生化复发，实现了更准确的早期预测...|
|🆕 发布|CETUS: Causal Event-Driven Temporal Modeling With Unified Variable-Rate Scheduling|CETUS：统一变量率调度下的因果事件驱动时间建模|Hanfang Liang, Bing Wang, Shizhen Zhang, Wen Jiang, Yizhuo Yang, Weixiang Guo, Shenghai Yuan|<http://arxiv.org/pdf/2509.13784v1>|提出了一种直接处理原始事件流的架构，有效克服了传统方法的时间窗口延迟和计算效率问题。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Video-Language Critic: Transferable Reward Functions for Language-Conditioned Robotics|视频-语言评论家：用于语言条件机器人学的迁移性奖励函数|Minttu Alakuijala, Reginald McLean, Isaac Woungang, Nariman Farsad, Samuel Kaski, Pekka Marttinen, Kai Yuan|<http://arxiv.org/pdf/2405.19988v3>|提出Video-Language Critic奖励模型，通过对比学习和时序排序，实现语言指令与机器人...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment|MOCHA：多模态物体感知跨架构对齐|Elena Camuffo, Francesco Barbato, Mete Ozay, Simone Milani, Umberto Michieli|<http://arxiv.org/pdf/2509.14001v1>|MOCHA通过对象级知识蒸馏，将大规模视觉-语言模型的多模态语义有效迁移至轻量级视觉检测器，实现性能...|
|📝 更新|Superpixel-based Color Transfer|基于超像素的颜色传递|Rémi Giraud, Vinh-Thong Ta, Nicolas Papadakis|<http://arxiv.org/pdf/1903.06010v2>|提出了一种基于超像素的快速颜色传递方法，通过近似最近邻匹配和融合框架提升了颜色匹配效果。|


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Masked Feature Modeling Enhances Adaptive Segmentation|《掩模特征建模增强自适应分割》|Wenlve Zhou, Zhiheng Zhou, Tiantao Xian, Yikui Zhai, Weibin Wu, Biyun Ma|<http://arxiv.org/pdf/2509.13801v1>|提出Masked Feature Modeling方法，通过特征遮蔽与重建提升无监督领域自适应语义分...|
|🆕 发布|VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in Real-time MRI|VocSegMRI：实时MRI中精确声 tract 分割的多模态学习|Daiqi Liu, Tomás Arias-Vergara, Johannes Enk, Fangxu Xing, Maureen Stone, Jerry L. Prince, Jana Hutter, Andreas Maier .etc.|<http://arxiv.org/pdf/2509.13767v1>|提出了一种融合视频、音频和语音学信息的多模态框架，实现了实时MRI中精确的发音器官分割。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Where Do Tokens Go? Understanding Pruning Behaviors in STEP at High Resolutions|“ tokens 去向何方？在高分辨率下理解 STEP 的剪枝行为”|Michal Szczepanski, Martyna Poreba, Karim Haroun|<http://arxiv.org/pdf/2509.14165v1>|提出STEP框架，通过动态合并和剪枝减少计算负担，实现高效高分辨率图像分割。|
|📝 更新|Structured Preference Optimization for Vision-Language Long-Horizon Task Planning|面向视觉-语言长周期任务规划的结构化偏好优化|Xiwen Liang, Min Lin, Weiqi Ruan, Rongtao Xu, Yuecheng Liu, Jiaqi Chen, Bingqian Lin, Yuzheng Zhuang .etc.|<http://arxiv.org/pdf/2502.20742v4>|提出Structured Preference Optimization方法，通过偏好评估和优化训练...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CSMoE: An Efficient Remote Sensing Foundation Model with Soft Mixture-of-Experts|CSMoE：一种具有软混合专家的高效遥感基础模型|Leonard Hackel, Tom Burgert, Begüm Demir|<http://arxiv.org/pdf/2509.14104v1>|提出了一种融合软混合专家机制的遥感基础模型，实现了计算效率的大幅提升同时保持性能。|
|📝 更新|Lightweight Gradient-Aware Upscaling of 3D Gaussian Splatting Images|轻量级梯度感知的三维高斯散点图像上采样|Simon Niedermayr, Christoph Neuhauser Rüdiger Westermann|<http://arxiv.org/pdf/2503.14171v2>|提出了一种利用高斯图像梯度进行高效轻量级图像放大的方法，大幅提升了3D高斯渲染速度并减少了重建伪影。|
|🆕 发布|SpecDiff: Accelerating Diffusion Model Inference with Self-Speculation|SpecDiff：使用自推测加速扩散模型推理|Jiayi Pan, Jiaming Xu, Yongkang Zhou, Guohao Dai|<http://arxiv.org/pdf/2509.13848v1>|提出了一种基于未来信息推测的多级特征缓存策略SpecDiff，有效提升了扩散模型推理速度且几乎不影响...|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Reconstruction and Reenactment Separated Method for Realistic Gaussian Head|高斯头像的重建与再现分离方法|Zhiling Ye, Cong Zhou, Xiubao Zhang, Haifeng Shen, Weihong Deng, Quan Lu|<http://arxiv.org/pdf/2509.05582v2>|提出了一种分离重建与再现的框架，仅用单张人像生成可控3D头像，实现了高效渲染和性能提升。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Invisible Yet Detected: PelFANet with Attention-Guided Anatomical Fusion for Pelvic Fracture Diagnosis|“隐形却可被检测：基于注意力引导的解剖融合PelFANet用于骨盆骨折诊断”|Siam Tahsin Bhuiyan, Rashedur Rahman, Sefatul Wasi, Naomi Yagi, Syoji Kobashi, Ashraful Islam, Saadia Binte Alam|<http://arxiv.org/pdf/2509.13873v1>|提出PelFANet，一种融合原始骨盆X光片与分割骨像的注意力引导网络，有效提升盆腔骨折诊断准确性。|
|📝 更新|Stereo Anything: Unifying Zero-shot Stereo Matching with Large-Scale Mixed Data|立体任意：将零样本立体匹配与大规模混合数据统一|Xianda Guo, Chenming Zhang, Youmin Zhang, Ruilin Wang, Dujun Nie, Wenzhao Zheng, Matteo Poggi, Hao Zhao .etc.|<http://arxiv.org/pdf/2411.14053v3>|[代码](https://github.com/XiandaGuo/OpenStereo.); 提出了一种混合数据训练框架，大幅提升了立体匹配模型的零样本泛化能力。|
|🆕 发布|Deep Lookup Network|深度查找网络|Yulan Guo, Longguang Wang, Wendong Mao, Xiaoyu Dong, Yingqian Wang, Li Liu, Wei An|<http://arxiv.org/pdf/2509.13662v1>|提出使用查找表替代乘法操作以降低卷积神经网络计算复杂度，实现了高效能消耗和快速推理速度。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|NDLPNet: A Location-Aware Nighttime Deraining Network and a Real-World Benchmark Dataset|NDLPNet：一种位置感知的夜间去雨网络及一个现实世界基准数据集|Huichun Liu, Xiaosong Li, Yang Liu, Xiaoqi Cheng, Haishu Tan|<http://arxiv.org/pdf/2509.13766v1>|[代码](https://github.com/Feecuin/NDLPNet.); 提出了一种针对夜间低光照条件下雨痕去除的NDLPNet网络，通过位置感知模块有效提升去雨痕效果并构建...|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FishBEV: Distortion-Resilient Bird's Eye View Segmentation with Surround-View Fisheye Cameras|FishBEV：具有畸变鲁棒性的环视鱼眼相机鸟瞰图分割|Hang Li, Dianmo Sheng, Qiankun Dong, Zichun Wang, Zhiwei Xu, Tao Li|<http://arxiv.org/pdf/2509.13681v1>|FishBEV通过专为 fisheye 相机设计的框架，有效应对几何失真和动态变化挑战，提升鸟瞰图分...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Semi-MoE: Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation|半MoE：混合专家模型遇见半监督病理图像分割|Nguyen Lan Vi Vu, Thanh-Huy Nguyen, Thien Nguyen, Daisuke Kihara, Tianyang Wang, Xingjian Li, Min Xu|<http://arxiv.org/pdf/2509.13834v1>|[代码](https://github.com/vnlvi2k3/Semi-MoE.); 提出Semi-MoE框架，通过多任务专家网络和自适应多目标损失，提升了半监督组织病理图像分割性能。|
|📝 更新|Deep Learning for Crack Detection: A Review of Learning Paradigms, Generalizability, and Datasets|深度学习在裂缝检测中的应用：学习范式、泛化能力与数据集综述|Xinan Zhang, Haolin Wang, Yung-An Hsieh, Zhongyu Yang, Anthony Yezzi, Yi-Chang Tsai|<http://arxiv.org/pdf/2508.10256v2>|[代码](https://github.com/nantonzhang/Awesome-Crack-Detection); 系统综述了深度学习在裂缝检测中的应用趋势，并引入了新的3D激光扫描数据集以促进研究。|
|📝 更新|TrajBooster: Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning|《TrajBooster：通过轨迹中心学习提升人形机器人全身操作能力》|Jiacheng Liu, Pengxiang Ding, Qihang Zhou, Yuxuan Wu, Da Huang, Zimian Peng, Wei Xiao, Weinan Zhang .etc.|<http://arxiv.org/pdf/2509.11839v2>|[代码](https://jiachengliu3.github.io/TrajBooster); 利用轮式机器人数据提升双足机器人动作性能，TrajBooster通过轨迹中心学习实现高效动作空间理解...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Cinéaste: A Fine-grained Contextual Movie Question Answering Benchmark|《电影制作师：一种细粒度上下文电影问答基准》|Nisarg A. Shah, Amir Ziai, Chaitanya Ekanadham, Vishal M. Patel|<http://arxiv.org/pdf/2509.14227v1>|提出了Cinéaste基准，用于评估长篇电影内容中的细粒度情境推理能力。|
|🆕 发布|Teacher-Guided Pseudo Supervision and Cross-Modal Alignment for Audio-Visual Video Parsing|教师引导的伪监督与跨模态对齐的音频视觉视频解析|Yaru Chen, Ruohao Guo, Liting Gao, Yang Xiang, Qingyu Luo, Zhenbo Li, Wenwu Wang|<http://arxiv.org/pdf/2509.14097v1>|提出稳定段级伪监督和类感知跨模态对齐策略，提升弱监督音视频事件解析性能至最佳。|
|🆕 发布|MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook|MARS2 2025多模态推理挑战赛：数据集、方法、结果、讨论与展望|Peng Xu, Shengwu Xiong, Jiajun Zhang, Yaxiong Chen, Bowen Zhou, Chen Change Loy, David A. Clifton, Kyoung Mu Lee .etc.|<http://arxiv.org/pdf/2509.14142v1>|介绍了MARS2 2025多模态推理挑战，发布了两个新数据集并评估了多种模型，推动多模态机器学习发展...|
|🆕 发布|VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement|基于视觉语义增强的低质量视频场景中的多目标跟踪：VSE-MOT|Jun Du, Weiwei Xing, Ming Li, Fei Richard Yu|<http://arxiv.org/pdf/2509.14060v1>|提出了一种基于视觉语义增强的多目标跟踪框架，有效提升了低质量视频场景下的跟踪性能。|
|📝 更新|UniPLV: Towards Label-Efficient Open-World 3D Scene Understanding by Regional Visual Language Supervision|面向区域视觉语言监督的少标记开放世界三维场景理解：UniPLV|Yuru Wang, Pei Liu, Songtao Wang, Zehan Zhang, Xinyan Lu, Changwei Cai, Hao Li, Fu Liu .etc.|<http://arxiv.org/pdf/2412.18131v2>|提出UniPLV框架，通过图像桥接点云与文本，实现高效的开放式3D场景理解。|
|🆕 发布|Towards Rationale-Answer Alignment of LVLMs via Self-Rationale Calibration|通过自我解释校准实现低资源视觉语言模型的理由-答案对齐|Yuanchen Wu, Ke Yan, Shouhong Ding, Ziyin Zhou, Xiaoqiang Li|<http://arxiv.org/pdf/2509.13919v1>|提出Self-Rationale Calibration框架，通过迭代校准理由与答案的对齐，提升大型...|
|📝 更新|CROP: Contextual Region-Oriented Visual Token Pruning|上下文区域导向的可视化标记剪枝方法（CROP）|Jiawei Guo, Feifei Zhai, Pu Jian, Qianrun Wei, Yu Zhou|<http://arxiv.org/pdf/2505.21233v2>|提出CROP方法，通过定位和剪枝压缩视觉标记，减少冗余信息，提升视觉问答模型的效率和性能。|
|🆕 发布|Task-Aware Image Signal Processor for Advanced Visual Perception|面向高级视觉感知的任务感知图像信号处理器|Kai Chen, Jin Xiao, Leheng Zhang, Kexuan Shi, Shuhang Gu|<http://arxiv.org/pdf/2509.13762v1>|提出了一种紧凑的任务感知图像信号处理框架，通过预测轻量级调制算子提升视觉任务性能，同时降低计算负担。|
|🆕 发布|Improving Generalized Visual Grounding with Instance-aware Joint Learning|实例感知联合学习提升泛化视觉定位效果|Ming Dai, Wenxuan Cheng, Jiang-Jiang Liu, Lingfeng Yang, Zhenhua Feng, Wankou Yang, Jingdong Wang|<http://arxiv.org/pdf/2509.13747v1>|[代码](https://github.com/Dmmm1997/InstanceVG.); 提出InstanceVG框架，首次将实例感知能力融入广义视觉定位，实现GREC与GRES任务联合训练...|
|🆕 发布|UM-Depth : Uncertainty Masked Self-Supervised Monocular Depth Estimation with Visual Odometry|UM-Depth：基于视觉里程计的不确定性掩码自监督单目深度估计|Tae-Wook Um, Ki-Hyeon Kim, Hyun-Duck Choi, Hyo-Sung Ahn|<http://arxiv.org/pdf/2509.13713v1>|UM-Depth通过结合运动感知和不确定性估计，提高了无纹理或动态区域的自监督单目深度估计准确性。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|An Exploratory Study on Abstract Images and Visual Representations Learned from Them|《对抽象图像及其学习到的视觉表征的探索性研究》|Haotian Li, Jianbo Jiao|<http://arxiv.org/pdf/2509.14149v1>|探究抽象图像对视觉表示的影响，并引入多级别抽象的图像数据集以提升模型性能。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BEVUDA++: Geometric-aware Unsupervised Domain Adaptation for Multi-View 3D Object Detection|BEVUDA++：面向多视角3D目标检测的几何感知无监督领域自适应|Rongyu Zhang, Jiaming Liu, Xiaoqi Li, Xiaowei Chi, Dan Wang, Li Du, Yuan Du, Shanghang Zhang|<http://arxiv.org/pdf/2509.14151v1>|提出了一种几何感知的教师-学生框架BEVUDA++，有效缓解了多视角3D物体检测中的域偏移问题。|
|📝 更新|A Deep Learning Pipeline for Solid Waste Detection in Remote Sensing Images|远程遥感图像中固体废物检测的深度学习处理流程|Federico Gibellini, Piero Fraternali, Giacomo Boracchi, Luca Morandini, Thomas Martinoli, Andrea Diecidue, Simona Malegori|<http://arxiv.org/pdf/2502.06607v4>|开发了一种半自动固体废物检测流程，显著提升了对非法倾倒点的识别效率和准确性。|
|🆕 发布|Data-Efficient Spectral Classification of Hyperspectral Data Using MiniROCKET and HDC-MiniROCKET|使用MiniROCKET和HDC-MiniROCKET进行高效数据光谱分类的超光谱数据|Nick Theisen, Kenny Schlegel, Dietrich Paulus, Peer Neubert|<http://arxiv.org/pdf/2509.13809v1>|提出了一种基于MiniROCKET和HDC-MiniROCKET的谱分类方法，在数据有限情况下性能优...|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MEGANet-W: A Wavelet-Driven Edge-Guided Attention Framework for Weak Boundary Polyp Detection|MEGANet-W：一种基于小波驱动的边缘引导注意力框架用于弱边界息肉检测|Zhe Yee Tan, Ashwaq Qasem|<http://arxiv.org/pdf/2507.02668v4>|提出了一种基于小波驱动的边缘引导注意力网络MEGANet-W，有效提升了弱边界息肉检测的精确度。|
|📝 更新|Data-Efficient Fine-Tuning of Vision-Language Models for Diagnosis of Alzheimer's Disease|数据高效微调视觉语言模型用于阿尔茨海默病的诊断|Fangqi Cheng, Surajit Ray, Xiaochen Yang|<http://arxiv.org/pdf/2509.07613v2>|提出了一种高效微调医疗视觉语言模型的方法，通过合成报告和预测MMSE评分，在少量数据上实现阿尔茨海默...|
|📝 更新|Improving Generalizability of Kolmogorov-Arnold Networks via Error-Correcting Output Codes|通过错误校正输出码提高Kolmogorov-Arnold网络的泛化性|Youngjoon Lee, Jinu Gong, Joonhyuk Kang|<http://arxiv.org/pdf/2505.05798v2>|集成错误纠正输出码提升Kolmogorov-Arnold网络多类图像分类的泛化能力。|
|🆕 发布|Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification|泰勒级数展开的科尔莫哥洛夫-阿尔诺德网络在医学成像分类中的应用|Kaniz Fatema, Emad A. Mohammed, Sukhjit Singh Sehra|<http://arxiv.org/pdf/2509.13687v1>|提出了一种基于样条和泰勒级数的轻量级网络，有效提升了小数据集医疗图像分类的准确性和泛化能力。|
|🆕 发布|Federated Learning for Deforestation Detection: A Distributed Approach with Satellite Imagery|联邦学习在森林砍伐检测中的应用：一种基于卫星影像的分布式方法|Yuvraj Dutta, Aaditya Sikder, Basabdatta Palit|<http://arxiv.org/pdf/2509.13631v1>|提出了一种基于联邦学习的分布式森林砍伐检测方法，保护了数据隐私和安全。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AdaThinkDrive: Adaptive Thinking via Reinforcement Learning for Autonomous Driving|自适应思考：基于强化学习的自动驾驶适应性思考驱动|Yuechen Luo, Fang Li, Shaoqing Xu, Zhiyi Lai, Lei Yang, Qimao Chen, Ziang Luo, Zixun Xie .etc.|<http://arxiv.org/pdf/2509.13769v1>|提出自适应思考机制AdaThinkDrive，通过强化学习优化自动驾驶决策效率和质量。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Visible Yet Unreadable: A Systematic Blind Spot of Vision Language Models Across Writing Systems|“可见却不可读：视觉语言模型在多种书写系统中的系统性盲点”|Jie Zhang, Ting Xu, Gelei Deng, Runyi Hu, Han Qiu, Tianwei Zhang, Qing Guo, Ivor Tsang|<http://arxiv.org/pdf/2509.06996v2>|揭示了视觉语言模型在处理书写系统中的结构局限性，提出了构建针对符号分割和组合的新架构和训练策略。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Effort-Optimized, Accuracy-Driven Labelling and Validation of Test Inputs for DL Systems: A Mixed-Integer Linear Programming Approach|深度学习系统测试输入的优化标注与验证：基于混合整数线性规划的精确驱动方法|Mohammad Hossein Amini, Mehrdad Sabetzadeh, Shiva Nejati|<http://arxiv.org/pdf/2507.04990v2>|提出OPAL方法，通过混合整数线性规划最小化标注努力，实现高精度深度学习测试数据集构建。|
|📝 更新|Robust Shape Regularity Criteria for Superpixel Evaluation|超像素评估的鲁棒形状正则性准则|Rémi Giraud, Vinh-Thong Ta, Nicolas Papadakis|<http://arxiv.org/pdf/1903.07146v2>|提出新的超像素形状规则性评估指标，涵盖凸性、平衡分布和轮廓平滑性，提高了比较超像素方法的准确性和鲁棒...|
|🆕 发布|MAP: End-to-End Autonomous Driving with Map-Assisted Planning|地图辅助规划的端到端自动驾驶：MAP|Huilin Yin, Yiming Kan, Daniel Watzenig|<http://arxiv.org/pdf/2509.13926v1>|提出了一种融合地图辅助规划的端到端自动驾驶方法，显著提升了轨迹规划和整体性能。|

