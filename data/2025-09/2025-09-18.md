## [UPDATED!] **2025-09-18** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Two Web Toolkits for Multimodal Piano Performance Dataset Acquisition and Fingering Annotation|两种用于多模态钢琴表演数据集采集和指法标注的网页工具包|Junhyung Park, Yonghyun Kim, Joonhyung Bae, Kirak Kim, Taegyun Kwon, Alexander Lerch, Juhan Nam|<http://arxiv.org/pdf/2509.15222v1>|开发了两个网络工具包，简化了钢琴演奏多模态数据集的采集和指法标注过程。|
|📝 更新|Probing the Representational Power of Sparse Autoencoders in Vision Models|探究稀疏自动编码器在视觉模型中的表征能力|Matthew Lyle Olson, Musashi Hinck, Neale Ratzlaff, Changbai Li, Phillip Howard, Vasudev Lal, Shao-Yen Tseng|<http://arxiv.org/pdf/2508.11277v2>|探究稀疏自编码器在视觉模型中的表征能力，提升了解释性、泛化能力和控制性。|
|🆕 发布|From Pixels to Urban Policy-Intelligence: Recovering Legacy Effects of Redlining with a Multimodal LLM|从像素到城市规划智能：利用多模态大型语言模型恢复红线政策的遗留影响|Anthony Howell, Nancy Wu, Sharmistha Bagchi, Yushim Kim, Chayn Sun|<http://arxiv.org/pdf/2509.15132v1>|利用多模态大语言模型从街景图像推断社区贫困和绿化情况，评估1930年代住房歧视政策遗留影响。|
|🆕 发布|Forecasting and Visualizing Air Quality from Sky Images with Vision-Language Models|从天空图像预测和可视化空气质量：基于视觉-语言模型的探索|Mohammad Saleh Vahdatpour, Maryam Eyvazi, Yanqing Zhang|<http://arxiv.org/pdf/2509.15076v1>|提出了一种利用视觉语言模型从天空图像预测空气质量并生成污染情景的可视化方法，以增强环境决策的透明度和...|
|📝 更新|PVLM: Parsing-Aware Vision Language Model with Dynamic Contrastive Learning for Zero-Shot Deepfake Attribution|PVLM：具有解析感知的视觉语言模型，通过动态对比学习实现零样本深度伪造归因|Yaning Zhang, Jiahe Zhang, Chunjie Ma, Weili Guan, Tian Gan, Zan Gao|<http://arxiv.org/pdf/2504.14129v2>|提出了一种结合面部解析和动态对比学习的零样本深伪迹追踪模型，有效应对未见高级生成器的归因挑战。|
|📝 更新|AD-DINOv3: Enhancing DINOv3 for Zero-Shot Anomaly Detection with Anomaly-Aware Calibration|AD-DINOv3：使用异常感知校准增强DINOv3进行零样本异常检测|Jingyi Yuan, Jianxiong Ye, Wenkang Chen, Chenqiang Gao|<http://arxiv.org/pdf/2509.14084v2>|[代码](https://github.com/Kaisor-Yuan/AD-DINOv3.); 提出AD-DINOv3框架，利用视觉和文本多模态对比学习进行零样本异常检测，增强了对异常区域的识别能...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Depth AnyEvent: A Cross-Modal Distillation Paradigm for Event-Based Monocular Depth Estimation|基于事件的单目深度估计的跨模态蒸馏范式：Depth AnyEvent|Luca Bartolomei, Enrico Mannocci, Fabio Tosi, Matteo Poggi, Stefano Mattoccia|<http://arxiv.org/pdf/2509.15224v1>|提出了一种跨模态蒸馏范式，利用视觉基础模型生成稠密代理标签，实现基于事件相机的单目深度估计。|
|🆕 发布|[Re] Improving Interpretation Faithfulness for Vision Transformers|提高视觉变换器的解释保真度|Izabela Kurek, Wojciech Trejter, Stipe Frkovic, Andro Erdelez|<http://arxiv.org/pdf/2509.14846v1>|验证并扩展了Diffusion Denoised Smoothing增强视觉变换器解释性稳健性的效果...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data|"ScaleCUA：跨平台数据驱动的开源计算机使用代理扩展"|Zhaoyang Liu, JingJing Xie, Zichen Ding, Zehao Li, Bowen Yang, Zhenyu Wu, Xuehui Wang, Qiushi Sun .etc.|<http://arxiv.org/pdf/2509.15221v1>|[代码](https://github.com/OpenGVLab/ScaleCUA.); 提出了ScaleCUA，通过构建跨平台的大规模数据集，显著提升了计算机使用代理的跨平台操作能力。|
|🆕 发布|Semi-Supervised 3D Medical Segmentation from 2D Natural Images Pretrained Model|二维自然图像预训练模型驱动的半监督三维医学分割|Pak-Hei Yeung, Jayroop Ramesh, Pengfei Lyu, Ana Namburete, Jagath Rajapakse|<http://arxiv.org/pdf/2509.15167v1>|[代码](https://github.com/pakheiyeung/M-N.); 提出了一种将2D自然图像预训练模型知识迁移至3D医疗图像半监督分割的方法，实现了优于现有技术的性能。|
|🆕 发布|WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance|《WorldForge：通过无需训练的引导在视频扩散模型中解锁涌现的3D/4D生成》|Chenxi Song, Yanming Yang, Tong Zhao, Ruibo Li, Chi Zhang|<http://arxiv.org/pdf/2509.15130v1>|提出了一种无需训练的WorldForge框架，通过精确轨迹注入和自适应校正，实现了视频生成中的高真实...|
|🆕 发布|Trade-offs in Cross-Domain Generalization of Foundation Model Fine-Tuned for Biometric Applications|《面向生物识别应用的基石模型微调在跨域泛化中的权衡》|Tahar Chettaoui, Naser Damer, Fadi Boutros|<http://arxiv.org/pdf/2509.14921v1>|探讨了基础模型在生物识别任务微调后跨域泛化能力的损失与平衡。|
|📝 更新|Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation|合成到真实域自适应的扩散模型风格迁移|Estelle Chigot, Dennis G. Wilson, Meriem Ghrib, Thomas Oberlin|<http://arxiv.org/pdf/2505.16360v2>|[代码](https://github.com/echigot/cactif.); 利用扩散模型进行风格迁移，有效桥接合成数据与真实数据间的领域差距，提升视觉模型性能。|
|📝 更新|Ensemble of Pathology Foundation Models for MIDOG 2025 Track 2: Atypical Mitosis Classification|病理基础模型集成用于MIDOG 2025赛道2：非典型有丝分裂分类|Mieko Ochi, Bae Yuan|<http://arxiv.org/pdf/2509.02591v3>|利用预训练的病理基础模型和先进网络结构，通过参数高效微调，实现了对异常有丝分裂的准确分类。|
|🆕 发布|FMGS-Avatar: Mesh-Guided 2D Gaussian Splatting with Foundation Model Priors for 3D Monocular Avatar Reconstruction|FMGS-虚拟化身：基于网格引导的二维高斯散点投射与基础模型先验的三维单目虚拟化身重建|Jinlong Fan, Bingyu Hu, Xingguang Li, Yuxiang Yang, Jing Zhang|<http://arxiv.org/pdf/2509.14739v1>|通过结合网格引导的二维高斯散布和基础模型先验，有效提升了单目视频下三维动画角色的重建质量和细节表现。|
|🆕 发布|Attention Lattice Adapter: Visual Explanation Generation for Visual Foundation Model|注意力格适配器：视觉基础模型的视觉解释生成|Shinnosuke Hirano, Yuiga Wada, Tsumugi Iida, Komei Sugiura|<http://arxiv.org/pdf/2509.14664v1>|提出了一种增强视觉基础模型解释性的方法，通过注意力格适配器和交替周期架构优化参数，显著提升了解释质量...|
|📝 更新|Brought a Gun to a Knife Fight: Modern VFM Baselines Outgun Specialized Detectors on In-the-Wild AI Image Detection|带到刀战中的枪：现代VFM基线在野外AI图像检测中超越专业检测器|Yue Zhou, Xinan He, Kaiqing Lin, Bing Fan, Feng Ding, Jinhua Zeng, Bin Li|<http://arxiv.org/pdf/2509.12995v2>|使用现代视觉基础模型训练的简单线性分类器，大幅超越专用检测器在真实场景下的图像检测准确性。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation|Segmentation  ？  “迷失在翻译中？面向开放词汇语义分割的无源域自适应词汇对齐”|Silvio Mazzucco, Carl Persson, Mattia Segu, Pier Luigi Dovesi, Federico Tombari, Luc Van Gool, Matteo Poggi|<http://arxiv.org/pdf/2509.15225v1>|提出VocAlign框架，通过词汇对齐策略和Top-K选择机制实现无需源域数据的开放词汇语义分割领域...|
|🆕 发布|OmniSegmentor: A Flexible Multi-Modal Learning Framework for Semantic Segmentation|全模态分割器：一种用于语义分割的灵活多模态学习框架|Bo-Wen Yin, Jiao-Long Cao, Xuying Zhang, Yuming Chen, Ming-Ming Cheng, Qibin Hou|<http://arxiv.org/pdf/2509.15096v1>|提出了一种灵活的多模态学习框架OmniSegmentor，通过大规模多模态数据预训练，实现了多模态语...|
|📝 更新|FASL-Seg: Anatomy and Tool Segmentation of Surgical Scenes|FASL-Seg：手术场景的解剖结构与工具分割|Muraam Abdel-Ghani, Mahmoud Ali, Mohamed Ali, Fatmaelzahraa Ahmed, Muhammad Arsalan, Abdulaziz Al-Ali, Shidin Balakrishnan|<http://arxiv.org/pdf/2509.06159v2>|提出Feature-Adaptive Spatial Localization模型，通过双流处理提升...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Geometric Image Synchronization with Deep Watermarking|标题翻译为：“基于深度水印的几何图像同步”|Pierre Fernandez, Tomáš Souček, Nikola Jovanović, Hady Elsahar, Sylvestre-Alvise Rebuffi, Valeriu Lacatusu, Tuan Tran, Alexandre Mourachko|<http://arxiv.org/pdf/2509.15208v1>|提出SyncSeal方法，通过深度水印增强图像几何变换同步的鲁棒性。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Synthetic-to-Real Object Detection using YOLOv11 and Domain Randomization Strategies|使用YOLOv11和领域随机化策略的合成到现实物体检测|Luisa Torquato Niño, Hamza A. A. Gardi|<http://arxiv.org/pdf/2509.15045v1>|提出了一种利用YOLOv11和领域随机化策略的训练方法，有效缩小了合成数据与真实数据间的检测差距。|
|📝 更新|Fovea Stacking: Imaging with Dynamic Localized Aberration Correction|视网膜叠加：动态局部像差校正成像|Shi Mao, Yogeshwar Nath Mishra, Wolfgang Heidrich|<http://arxiv.org/pdf/2506.00716v2>|提出Fovea Stacking技术，通过动态局部校正像差，显著提升小型相机成像质量。|
|📝 更新|MATTER: Multiscale Attention for Registration Error Regression|MATTER：多尺度注意力用于配准误差回归|Shipeng Liu, Ziliang Xiong, Khac-Hoang Ngo, Per-Erik Forssén|<http://arxiv.org/pdf/2509.12924v2>|提出回归方法用于点云配准质量量化，通过多尺度特征提取和注意力机制提升估计准确性。|
|📝 更新|Image Super-Resolution Reconstruction Network based on Enhanced Swin Transformer via Alternating Aggregation of Local-Global Features|基于增强Swin变换器和局部-全局特征交替聚合的图像超分辨率重建网络|Yuming Huang, Yingpin Chen, Changhui Wu, Binhui Song, Hui Wang|<http://arxiv.org/pdf/2401.00241v5>|[代码](https://github.com/huangyuming2021/ESTN.); 提出了一种增强型Swin Transformer网络，通过交替聚合局部和全局特征，显著提升了图像超分...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UCorr: Wire Detection and Depth Estimation for Autonomous Drones|"UCorr：无人机线缆检测与深度估计"|Benedikt Kolbeinsson, Krystian Mikolajczyk|<http://arxiv.org/pdf/2509.14989v1>|提出了一种端到端模型，通过时序相关性处理，实现了无人机线缆检测与深度估计的精确融合。|
|📝 更新|MINGLE: VLMs for Semantically Complex Region Detection in Urban Scenes|MINGLE：面向城市场景语义复杂区域检测的视觉语言模型|Liu Liu, Alexandra Kudaeva, Marco Cipriano, Fatimeh Al Ghannam, Freya Tan, Gerard de Melo, Andres Sevtsuk|<http://arxiv.org/pdf/2509.13484v2>|提出MINGLE模型，通过模块化三阶段流程检测城市场景中复杂语义关系的社交群体区域。|
|🆕 发布|RoboEye: Enhancing 2D Robotic Object Identification with Selective 3D Geometric Keypoint Matching|罗博之眼：通过选择性三维几何关键点匹配增强二维机器人目标识别|Xingwu Zhang, Guanxuan Li, Zhuocheng Zhang, Zijun Long|<http://arxiv.org/pdf/2509.14966v1>|[代码](https://github.com/longkukuhi/RoboEye.); 提出RoboEye框架，通过结合2D特征与3D几何关键点匹配，提升仓库自动化包装中对象的准确识别。|
|🆕 发布|DF-LLaVA: Unlocking MLLM's potential for Synthetic Image Detection via Prompt-Guided Knowledge Injection|DF-LLaVA：通过提示引导的知识注入解锁多模态大型语言模型在合成图像检测中的潜力|Zhuokang Shen, Kaisen Zhang, Bohan Jia, Yuan Fang, Zhou Yu, Shaohui Lin|<http://arxiv.org/pdf/2509.14957v1>|[代码](https://github.com/Eliot-Shen/DF-LLaVA.); 提出DF-LLaVA框架，通过提示引导知识注入提升多模态语言模型在合成图像检测的准确性和可解释性。|
|🆕 发布|NeRF-based Visualization of 3D Cues Supporting Data-Driven Spacecraft Pose Estimation|基于NeRF的三维线索可视化支持数据驱动的航天器姿态估计|Antoine Legrand, Renaud Detry, Christophe De Vleeschouwer|<http://arxiv.org/pdf/2509.14890v1>|提出了一种基于NeRF的3D视觉线索可视化方法，帮助理解数据驱动航天器位姿估计的决策过程。|
|🆕 发布|Fracture interactive geodesic active contours for bone segmentation|骨折交互测地线活动轮廓法用于骨骼分割|Liheng Wang, Licheng Zhang, Hailin Xu, Jingxin Zhao, Xiuyun Su, Jiantao Li, Miutian Tang, Weilu Gao .etc.|<http://arxiv.org/pdf/2509.14817v1>|提出了一种骨折交互式测地线活动轮廓算法，有效解决了骨分割中的边缘遮挡和骨折问题，提高了分割准确性。|
|📝 更新|IV-tuning: Parameter-Efficient Transfer Learning for Infrared-Visible Tasks|IV-tuning：面向红外-可见光任务的参数高效迁移学习|Yaming Zhang, Chenqiang Gao, Fangcen Liu, Junjie Guo, Lan Wang, Xinggan Peng, Deyu Meng|<http://arxiv.org/pdf/2412.16654v4>|[代码](https://github.com/Yummy198913/IV-tuning.); 提出IV-tuning方法，通过高效参数利用改进红外与可见光任务学习，减少过拟合问题。|
|📝 更新|BST: Badminton Stroke-type Transformer for Skeleton-based Action Recognition in Racket Sports|羽毛球击球类型变换器：基于骨架的 racket sports 动作识别|Jing-Yuan Chang|<http://arxiv.org/pdf/2502.21085v3>|提出了一种针对羽毛球挥拍动作识别的Badminton Stroke-type Transformer...|
|📝 更新|Direct Video-Based Spatiotemporal Deep Learning for Cattle Lameness Detection|基于视频的直接时空深度学习在牛跛行检测中的应用|Md Fahimuzzman Sohan, Raid Alzubi, Hadeel Alzoubi, Eid Albalawi, A. H. Abdul Hafez|<http://arxiv.org/pdf/2504.16404v4>|提出了一种基于视频的直接时空深度学习方法，实现了高效准确的牛跛行自动检测。|
|🆕 发布|Edge-Aware Normalized Attention for Efficient and Detail-Preserving Single Image Super-Resolution|边缘感知归一化注意力用于高效且细节保持的单幅图像超分辨率|Penghao Rao, Tieyong Zeng|<http://arxiv.org/pdf/2509.14550v1>|提出边缘感知归一化注意力机制，通过自适应调制图提升超分辨率图像的结构清晰度和感知质量。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Lightweight and Accurate Multi-View Stereo with Confidence-Aware Diffusion Model|轻量级且精确的多视角立体匹配与置信度感知扩散模型|Fangjinhua Wang, Qingshan Xu, Yew-Soon Ong, Marc Pollefeys|<http://arxiv.org/pdf/2509.15220v1>|[代码](https://github.com/cvg/diffmvs.); 提出了一种基于扩散模型的轻量级多视角立体匹配方法，通过置信度引导的采样策略提升了三维重建的效率和准确...|
|📝 更新|Diffusion-Based Action Recognition Generalizes to Untrained Domains|基于扩散的动作识别在未训练领域中具有泛化能力|Rogerio Guimaraes, Frank Xiao, Pietro Perona, Markus Marks|<http://arxiv.org/pdf/2509.08908v2>|[代码](https://github.com/frankyaoxiao/ActionDiff); 提出了一种基于扩散模型和变换器的动作识别方法，实现了跨物种、视角和环境的泛化，达到人类水平的识别能力...|
|📝 更新|DiffCut: Catalyzing Zero-Shot Semantic Segmentation with Diffusion Features and Recursive Normalized Cut|DiffCut：利用扩散特征和递归归一化切割促进零样本语义分割|Paul Couairon, Mustafa Shukor, Jean-Emmanuel Haugeard, Matthieu Cord, Nicolas Thome|<http://arxiv.org/pdf/2406.02842v3>|提出DiffCut方法，利用扩散特征和递归归一化切割算法实现无监督零样本语义分割，显著超越现有技术水...|
|🆕 发布|Transplant-Ready? Evaluating AI Lung Segmentation Models in Candidates with Severe Lung Disease|“移植准备？评估AI肺部分割模型在重症肺病患者中的应用”|Jisoo Lee, Michael R. Harowicz, Yuwen Chen, Hanxue Gu, Isaac S. Alderete, Lin Li, Maciej A. Mazurowski, Matthew G. Hartwig|<http://arxiv.org/pdf/2509.15083v1>|评估了三种深度学习肺部分割模型在严重肺病患者中的表现，发现Unet-R231模型性能最优但需针对严重...|
|📝 更新|Moment- and Power-Spectrum-Based Gaussianity Regularization for Text-to-Image Models|基于矩和功率谱的 Gaussian 性质正则化方法在文本到图像模型中的应用|Jisung Hwang, Jaihoon Kim, Minhyuk Sung|<http://arxiv.org/pdf/2509.07027v3>|提出了一种基于矩和功率谱的标准化正则化方法，提高了文本到图像模型在潜在空间中的优化性能。|
|📝 更新|Erased or Dormant? Rethinking Concept Erasure Through Reversibility|“擦除还是休眠？通过可逆性重新思考概念擦除”|Ping Liu, Chi Zhang|<http://arxiv.org/pdf/2505.16174v2>|发现现有概念擦除方法仅实现表面抑制，提出实例级评估策略证实概念可被重新激活。|
|🆕 发布|AutoEdit: Automatic Hyperparameter Tuning for Image Editing|自动编辑：图像编辑的自动超参数调整|Chau Pham, Quan Dao, Mahesh Bhosale, Yunjie Tian, Dimitris Metaxas, David Doermann|<http://arxiv.org/pdf/2509.15031v1>|自动调整图像编辑超参数的强化学习框架，大幅减少了搜索时间和计算成本。|
|🆕 发布|M4Diffuser: Multi-View Diffusion Policy with Manipulability-Aware Control for Robust Mobile Manipulation|M4Diffuser：具有操作灵活性感知控制的多元视角扩散策略，用于鲁棒移动操作|Ju Dong, Lei Zhang, Liding Zhang, Yao Ling, Yu Fu, Kaixin Bai, Zoltán-Csaba Márton, Zhenshan Bing .etc.|<http://arxiv.org/pdf/2509.14980v1>|提出了一种多视角扩散策略与新型操控性感知控制器相结合的框架，实现了在非结构化环境下的稳健移动操控。|
|📝 更新|On the Role of Individual Differences in Current Approaches to Computational Image Aesthetics|《论个体差异在当前计算图像美学方法中的作用》|Li-Wei Chen, Ombretta Strafforello, Anne-Sofie Maerten, Tinne Tuytelaars, Johan Wagemans|<http://arxiv.org/pdf/2502.20518v2>|[代码](https://github.com/lwchen6309/aesthetics_transfer_learning.); 提出了统一模型编码个体特征，为计算图像美学评估提供了理论依据，揭示了个体差异对图像审美的影响。|
|🆕 发布|Pseudo-Label Enhanced Cascaded Framework: 2nd Technical Report for LSVOS 2025 VOS Track|伪标签增强级联框架：LSVOS 2025 视频对象分割赛道第2份技术报告|An Yan, Leilei Cao, Feng Lu, Ran Hong, Youhai Jiang, Fengjie Zhu|<http://arxiv.org/pdf/2509.14901v1>|提出伪标签增强级联框架，通过多模型融合提升了长视频复杂场景的目标分割准确性和鲁棒性。|
|🆕 发布|Controllable Localized Face Anonymization Via Diffusion Inpainting|通过扩散修复实现的可控局部人脸匿名化|Ali Salar, Qing Liu, Guoying Zhao|<http://arxiv.org/pdf/2509.14866v1>|提出了一种利用潜在扩散模型进行可控局部面部匿名的方法，实现了在不影响图像可用性的同时保护个人隐私。|
|🆕 发布|Dataset Distillation for Super-Resolution without Class Labels and Pre-trained Models|无标签和预训练模型的数据集蒸馏用于超分辨率|Sunwoo Cho, Yejin Jung, Nam Ik Cho, Jae Woong Soh|<http://arxiv.org/pdf/2509.14777v1>|提出了一种无需类别标签和预训练模型的数据精炼方法，大幅减少了超分辨率训练所需数据和计算时间。|
|🆕 发布|Chain-of-Thought Re-ranking for Image Retrieval Tasks|链式思维重排用于图像检索任务|Shangrong Wu, Yanghong Zhou, Yang Chen, Feng Zhang, P. Y. Mok|<http://arxiv.org/pdf/2509.14746v1>|[代码](https://github.com/freshfish15/CoTRR); 提出了一种利用大型多模态语言模型进行图像重排的方法，显著提升了图像检索任务的准确性。|
|🆕 发布|Data Augmentation via Latent Diffusion Models for Detecting Smell-Related Objects in Historical Artworks|通过潜在扩散模型进行数据增强以检测历史艺术品中的气味相关对象|Ahmed Sheta, Mathias Zinnen, Aline Sindel, Andreas Maier, Vincent Christlein|<http://arxiv.org/pdf/2509.14755v1>|利用潜在扩散模型生成合成数据，有效缓解了历史艺术品中气味相关物体检测的标注稀疏和类别不平衡问题。|
|📝 更新|BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching|BWCache：通过块状缓存加速视频扩散变换器|Hanshuai Cui, Zhiqing Tang, Zhifei Xu, Zhi Yao, Wenyi Zeng, Weijia Jia|<http://arxiv.org/pdf/2509.13789v2>|提出了一种无需训练的Block-Wise Caching方法，通过动态缓存和重用特征，有效加速了视频...|
|🆕 发布|DiffVL: Diffusion-Based Visual Localization on 2D Maps via BEV-Conditioned GPS Denoising|基于BEV条件GPS去噪的扩散式二维地图视觉定位：DiffVL|Li Gao, Hongyang Sun, Liu Liu, Yunhao Li, Yang Cai|<http://arxiv.org/pdf/2509.14565v1>|DiffVL将视觉定位问题转化为GPS去噪任务，通过扩散模型实现亚米级精度，无需依赖高精度地图。|
|📝 更新|Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production|混合自回归-扩散模型用于实时手语生成|Maoxiao Ye, Xinfeng Ye, Mano Manoharan|<http://arxiv.org/pdf/2507.09105v3>|提出了一种结合自回归和扩散模型的实时手语生成方法，通过多尺度姿态表示和置信度感知机制提高了生成质量和...|
|🆕 发布|Adaptive and Iterative Point Cloud Denoising with Score-Based Diffusion Model|基于得分扩散模型的自适应迭代点云去噪|Zhaonan Wang, Manyi Li, ShiQing Xin, Changhe Tu|<http://arxiv.org/pdf/2509.14560v1>|提出了一种自适应迭代点云去噪方法，通过估计噪声变化并自适应调整去噪步骤，有效提升了去噪质量和细节保持...|
|📝 更新|SCORPION: Addressing Scanner-Induced Variability in Histopathology|SCORPION：解决扫描器引起的病理组织学变异性问题|Jeongun Ryu, Heon Song, Seungeun Lee, Soo Ick Cho, Jiwon Shin, Kyunghyun Paeng, Sérgio Pereira|<http://arxiv.org/pdf/2507.20907v2>|提出SCORPION数据集和SimCons框架，用于评估和提升模型在不同扫描仪间的可靠性。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Generalizable Geometric Image Caption Synthesis|通用几何图像标题生成|Yue Xin, Wenyuan Wang, Rui Pan, Ruida Wang, Howard Meng, Renjie Pi, Shizhe Diao, Tong Zhang|<http://arxiv.org/pdf/2509.15217v1>|引入强化学习与可验证奖励机制，提升多模态大语言模型解决几何问题的泛化能力。|
|🆕 发布|RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation|RynnVLA-001：利用人类示范提高机器人操控能力|Yuming Jiang, Siteng Huang, Shengke Xue, Yaxi Zhao, Jun Cen, Sicong Leng, Kehan Li, Jiayan Guo .etc.|<http://arxiv.org/pdf/2509.15212v1>|提出了一种两阶段预训练的视觉语言动作模型，通过人类演示视频提高机器人操作性能。|
|🆕 发布|AIP: Subverting Retrieval-Augmented Generation via Adversarial Instructional Prompt|AIP：通过对抗性指令提示颠覆检索增强生成|Saket S. Chaturvedi, Gaurav Bagwe, Lan Zhang, Xiaoyong Yuan|<http://arxiv.org/pdf/2509.15159v1>|提出了一种利用对抗性指令提示操纵检索增强生成模型的新攻击方法，有效揭示了系统安全漏洞。|
|🆕 发布|Understand Before You Generate: Self-Guided Training for Autoregressive Image Generation|在生成之前理解：用于自回归图像生成的自引导训练|Xiaoyu Yue, Zidong Wang, Yuqing Wang, Wenlong Zhang, Xihui Liu, Wanli Ouyang, Lei Bai, Luping Zhou|<http://arxiv.org/pdf/2509.15185v1>|提出自引导训练框架ST-AR，通过引入自监督目标增强自回归模型图像理解能力，显著提升生成质量。|
|🆕 发布|Learning Mechanistic Subtypes of Neurodegeneration with a Physics-Informed Variational Autoencoder Mixture Model|利用物理信息优化的变分自编码器混合模型学习神经退行机制的亚型|Sanduni Pinnawala, Annabelle Hartanto, Ivor J. A. Simpson, Peter A. Wijeratne|<http://arxiv.org/pdf/2509.15124v1>|提出了一种融合物理知识的新型深度学习模型，用于从神经影像数据中发现阿尔茨海默病的不同机制亚型。|
|📝 更新|End4: End-to-end Denoising Diffusion for Diffusion-Based Inpainting Detection|端到端去噪扩散用于基于扩散的图像修复检测|Fei Wang, Xuecheng Wu, Zheng Zhang, Danlei Huang, Yuheng Huang, Bo Wang|<http://arxiv.org/pdf/2509.13214v2>|提出了一种基于端到端去噪扩散的检测方法End4，通过优化特征重建和融合模块，有效识别扩散模型生成的图...|
|📝 更新|Debias your Large Multi-Modal Model at Test-Time via Non-Contrastive Visual Attribute Steering|通过非对比视觉属性引导在测试时对大型多模态模型进行去偏|Neale Ratzlaff, Matthew Lyle Olson, Musashi Hinck, Estelle Aflalo, Shao-Yen Tseng, Vasudev Lal, Phillip Howard|<http://arxiv.org/pdf/2411.12590v3>|提出了一种无需训练的框架，通过构建导向向量减少大型多模态模型在测试时对敏感属性的依赖，有效降低偏见而...|
|🆕 发布|QuizRank: Picking Images by Quizzing VLMs|QuizRank：通过问答测试选择图像的VLMs排名方法|Tenghao Ji, Eytan Adar|<http://arxiv.org/pdf/2509.15059v1>|提出了一种利用大语言模型和视觉语言模型进行图像选择的QuizRank方法，通过问答方式评估图像对文章...|
|🆕 发布|Sea-ing Through Scattered Rays: Revisiting the Image Formation Model for Realistic Underwater Image Generation|透过散射光线看海：重新审视图像形成模型以实现真实水下图像生成|Vasiliki Ismiroglou, Malte Pedersen, Stefan H. Bengtson, Andreas Aakerberg, Thomas B. Moeslund|<http://arxiv.org/pdf/2509.15011v1>|提出了一种包含前向散射项的改进合成数据生成流程，有效模拟了高浑浊水下环境中的视觉退化现象。|
|🆕 发布|SPATIALGEN: Layout-guided 3D Indoor Scene Generation|空间生成：基于布局引导的室内三维场景生成|Chuan Fang, Heng Li, Yixun Liang, Jia Zheng, Yongsen Mao, Yuan Liu, Rui Tang, Zihan Zhou .etc.|<http://arxiv.org/pdf/2509.14981v1>|提出了SpatialGen模型，利用大规模数据集生成高质量、语义一致的3D室内场景。|
|📝 更新|GCDance: Genre-Controlled 3D Full Body Dance Generation Driven By Music|音乐驱动的风格控制三维全身舞蹈生成：GCDance|Xinran Liu, Xu Dong, Diptesh Kanojia, Wenwu Wang, Zhenhua Feng|<http://arxiv.org/pdf/2502.18309v2>|提出了一种基于音乐和文本提示的扩散框架GCDance，实现了音乐驱动的多样化舞蹈生成并保持节奏同步。|
|🆕 发布|GenKOL: Modular Generative AI Framework For Scalable Virtual KOL Generation|GenKOL：模块化生成式人工智能框架，用于可扩展虚拟KOL生成|Tan-Hiep To, Duy-Khang Nguyen, Tam V. Nguyen, Minh-Triet Tran, Trung-Nghia Le|<http://arxiv.org/pdf/2509.14927v1>|提出GenKOL框架，利用生成式AI高效创建虚拟KOL图像，降低营销成本并加速工作流程。|
|📝 更新|Boost 3D Reconstruction using Diffusion-based Monocular Camera Calibration|利用基于扩散的单目相机标定提升三维重建|Junyuan Deng, Wei Yin, Xiaoyang Guo, Qian Zhang, Xiaotao Hu, Weiqiang Ren, Xiao-Xiao Long, Ping Tan|<http://arxiv.org/pdf/2411.17240v3>|提出了一种基于稳定扩散模型的新方法，通过单张图像实现相机内参估计，显著提升3D视觉任务性能。|
|📝 更新|Domain Generalization for In-Orbit 6D Pose Estimation|在轨6D位姿估计的域泛化|Antoine Legrand, Renaud Detry, Christophe De Vleeschouwer|<http://arxiv.org/pdf/2406.11743v2>|提出了一种结合多任务学习和数据增强策略的神经网络架构，有效解决了卫星在轨位姿估计中的域差距问题。|
|📝 更新|Efficient Dual-domain Image Dehazing with Haze Prior Perception|高效双域图像去雾算法：基于雾气先验感知|Lirong Zheng, Yanshan Li, Rui Yu, Kaihao Zhang|<http://arxiv.org/pdf/2507.11035v2>|[代码](https://github.com/Dilizlr/DGFDNet.); 提出了一种双域图像去雾框架DGFDNet，通过频率调制与多级特征融合，实现了高效实时的去雾效果。|
|📝 更新|A-TDOM: Active TDOM via On-the-Fly 3DGS|动态调整的主动TDOM：通过实时3DGS的主动TDOM|Yiwei Xu, Xiang Wang, Yifei Yu, Wentian Gan, Luca Morelli, Giulio Perda, Xiongwu Xiao, Zongqian Zhan .etc.|<http://arxiv.org/pdf/2509.12759v2>|提出了一种基于实时3DGS优化的A-TDOM方法，实现了近实时生成高质量的正射影像图。|
|📝 更新|A Mutual Information Perspective on Multiple Latent Variable Generative Models for Positive View Generation|多潜在变量生成模型在正视图生成中的互信息视角研究|Dario Serez, Marco Cristani, Alessio Del Bue, Vittorio Murino, Pietro Morerio|<http://arxiv.org/pdf/2501.13718v2>|[代码](https://github.com/SerezD/mi_ml_gen.); 提出了一种基于互信息量的新框架，有效量化多潜在变量生成模型中各潜在变量的贡献，并用于生成合成数据以增...|
|📝 更新|HPGN: Hybrid Priors-Guided Network for Compressed Low-Light Image Enhancement|混合先验引导网络用于压缩低光图像增强|Hantang Li, Qiang Zhu, Xiandong Meng, Lei Xiong, Shuyuan Zhu, Xiaopeng Fan|<http://arxiv.org/pdf/2504.02373v2>|提出了一种融合压缩和光照先验的混合先验引导网络，有效提升了不同压缩质量低光照图像的增强效果。|
|🆕 发布|DACoN: DINO for Anime Paint Bucket Colorization with Any Number of Reference Images|DACoN：使用任意数量参考图像的DINO动画着色桶填充色彩化方法|Kazuma Nagata, Naoshi Kaneko|<http://arxiv.org/pdf/2509.14685v1>|[代码](https://github.com/kzmngt/DACoN.); DACoN通过融合基础模型与卷积神经网络，实现了对线稿动画的灵活多参考图着色，提升了着色准确性和鲁棒...|
|🆕 发布|MultiEdit: Advancing Instruction-based Image Editing on Diverse and Challenging Tasks|多编辑：在多样化和挑战性任务上推进基于指令的图像编辑|Mingsong Li, Lin Liu, Hongjun Wang, Haoxing Chen, Xijun Gu, Shizhan Liu, Dong Gong, Junbo Zhao .etc.|<http://arxiv.org/pdf/2509.14638v1>|提出了MultiEdit数据集，通过高质量样本和双模态大语言模型，提升了指令基础图像编辑在复杂任务上...|
|📝 更新|TIDE: Achieving Balanced Subject-Driven Image Generation via Target-Instructed Diffusion Enhancement|TIDE：通过目标指导扩散增强实现平衡的主导图像生成|Jibai Lin, Bo Ma, Yating Yang, Xi Zhou, Rong Ma, Turghun Osman, Ahtamjan Ahmat, Rui Dong .etc.|<http://arxiv.org/pdf/2509.06499v2>|[代码](https://github.com/KomJay520/TIDE.); 提出了一种Target-Instructed Diffusion Enhancing框架，通过目标监...|
|📝 更新|Morph: A Motion-free Physics Optimization Framework for Human Motion Generation|“Morph：一种无运动物理优化框架用于人体运动生成”|Zhuo Li, Mingshuang Luo, Ruibing Hou, Xin Zhao, Hao Liu, Hong Chang, Zimo Liu, Chen Li|<http://arxiv.org/pdf/2411.14951v3>|提出Morph框架，通过物理优化提高人类运动生成的真实性和稳定性。|
|📝 更新|EnCoBo: Energy-Guided Concept Bottlenecks for Interpretable Generation|EnCoBo：能量引导的概念瓶颈用于可解释生成|Sangwon Kim, Kyoungoh Lee, Jeyoun Dong, Jung Hwan Ahn, Kwang-Ju Kim|<http://arxiv.org/pdf/2507.08334v2>|提出EnCoBo方法，通过约束显式概念流改善生成模型的解释性和干预能力。|
|📝 更新|Interactive Face Video Coding: A Generative Compression Framework|交互式人脸视频编码：生成式压缩框架|Bolin Chen, Zhao Wang, Binzhe Li, Shurun Wang, Shiqi Wang, Yan Ye|<http://arxiv.org/pdf/2302.09919v2>|提出交互式人脸视频编码框架，实现高保真低延迟的人脸动画渲染与交互。|
|📝 更新|VLM Agents Generate Their Own Memories: Distilling Experience into Embodied Programs of Thought|《语言模型代理生成自身记忆：将经验提炼为具身思维程序》|Gabriel Sarch, Lawrence Jang, Michael J. Tarr, William W. Cohen, Kenneth Marino, Katerina Fragkiadaki|<http://arxiv.org/pdf/2406.14596v6>|提出方法使计算机视觉模型通过自我反思和人类反馈，将低质量轨迹转化为高质量训练数据，提升决策效率。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Efficient motion-based metrics for video frame interpolation|基于运动的高效视频帧插值度量方法|Conall Daly, Darren Ramsook, Anil Kokaram|<http://arxiv.org/pdf/2508.09078v2>|提出了一种基于运动场变化的视频帧插值质量评估指标，提高了评估效率和与人类视觉感知的契合度。|
|📝 更新|OmniSync: Towards Universal Lip Synchronization via Diffusion Transformers|全方位同步：通过扩散变换器实现通用唇同步|Ziqiao Peng, Jiwen Liu, Haoxian Zhang, Xiaoqiang Liu, Songlin Tang, Pengfei Wan, Di Zhang, Hongyan Liu .etc.|<http://arxiv.org/pdf/2505.21448v2>|提出了一种无遮挡、无身份漂移的唇同步框架OmniSync，通过扩散变换模型直接编辑帧以实现自然面部动...|
|🆕 发布|Not All Degradations Are Equal: A Targeted Feature Denoising Framework for Generalizable Image Super-Resolution|《并非所有退化都相同：一种面向泛化图像超分辨率的目标特征去噪框架》|Hongjun Wang, Jiyuan Chen, Zhengwei Yin, Xuan Song, Yinqiang Zheng|<http://arxiv.org/pdf/2509.14841v1>|提出了一种针对噪声的特定特征去噪框架，有效提升图像超分辨率模型的泛化能力。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Image-Text-Image Knowledge Transfer for Lifelong Person Re-Identification with Hybrid Clothing States|图像-文本-图像知识迁移用于具有混合着装状态的终身行人重识别|Qizao Wang, Xuelin Qian, Bin Li, Yanwei Fu, Xiangyang Xue|<http://arxiv.org/pdf/2405.16600v2>|提出 lifelong person re-identification with hybrid c...|
|📝 更新|Standardizing Generative Face Video Compression using Supplemental Enhancement Information|使用补充增强信息标准化生成人脸视频压缩|Bolin Chen, Yan Ye, Jie Chen, Ru-Ling Liao, Shanzhi Yin, Shiqi Wang, Kaifa Yang, Yue Li .etc.|<http://arxiv.org/pdf/2410.15105v3>|提出了一种利用补充增强信息进行生成式人脸视频压缩的新方法，提高了视频重建质量并定义了新的标准。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GAF: Gaussian Action Field as a Dynamic World Model for Robotic Manipulation|高斯动作场：作为机器人操作动态世界模型的GAF方法|Ying Chai, Litao Deng, Ruizhi Shao, Jiajun Zhang, Liangjun Xing, Hongwen Zhang, Yebin Liu|<http://arxiv.org/pdf/2506.14135v3>|提出V-4D-A框架，通过Gaussian Action Field实现动态场景下的精准动作推理，显...|
|🆕 发布|A Real-Time Multi-Model Parametric Representation of Point Clouds|点云的实时多模型参数化表示|Yuan Gao, Wei Dong|<http://arxiv.org/pdf/2509.14773v1>|提出了一种实时多模型参数化表示方法，通过结合高适应性模型和实时方法，实现了点云的高效表面检测与拟合。|
|📝 更新|Physics-Informed Representation Alignment for Sparse Radio-Map Reconstruction|物理信息引导的表征对齐用于稀疏射电图重建|Haozhe Jia, Wenshuo Chen, Zhihui Huang, Lei Wang, Hongru Xiao, Nanqian Jia, Keming Wu, Songning Lai .etc.|<http://arxiv.org/pdf/2501.19160v3>|提出了一种物理信息驱动的映射重建框架PhyRMDM，通过双路径学习实现了物理原理与神经网络特征的对齐...|
|📝 更新|Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation|《眼球转动：通过显式三维眼球旋转实现视线重定向》|YoungChan Choi, HengFei Wang, YiHua Cheng, Boeun Kim, Hyung Jin Chang, YoungGeun Choi, Sang-Il Choi|<http://arxiv.org/pdf/2508.06136v2>|提出了一种显式3D眼球结构 gaze 重定向方法，通过精确的眼球旋转和位移生成高质量图像。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MapAnything: Mapping Urban Assets using Single Street-View Images|《MapAnything：利用单张街景图像映射城市资产》|Miriam Louise Carnot, Jonas Kunze, Erik Fastermann, Eric Peukert, André Ludwig, Bogdan Franczyk|<http://arxiv.org/pdf/2509.14839v1>|提出了一种自动映射城市资产的方法MapAnything，通过单张街景图像准确计算对象地理坐标。|
|🆕 发布|MemEvo: Memory-Evolving Incremental Multi-view Clustering|MemEvo：内存演化的增量多视角聚类|Zisen Kong, Bo Zhong, Pengyuan Li, Dongxia Chang, Yiming Wang|<http://arxiv.org/pdf/2509.14544v1>|MemEvo通过模拟人脑记忆机制，平衡了增量多视角聚类中的稳定性和适应性。|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Out-of-Sight Trajectories: Tracking, Fusion, and Prediction|《视线外轨迹：跟踪、融合与预测》|Haichao Zhang, Yi Xu, Yun Fu|<http://arxiv.org/pdf/2509.15219v1>|[代码](https://github.com/Hai-chao-Zhang/OST); 提出了一种预测不可见物体视觉轨迹的方法，通过视觉定位去噪模块提高了轨迹预测的准确性和鲁棒性。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding|释放多模态大规模语言模型在零样本时空视频定位中的潜力|Zaiquan Yang, Yuhao Liu, Gerhard Hancke, Rynson W. H. Lau|<http://arxiv.org/pdf/2509.15178v1>|[代码](https://github.com/zaiquanyang/LLaVA_Next_STVG.); 提出了一种基于多模态大语言模型的零样本时空视频定位框架，通过分解查询和增强时序一致性显著提升视频定位...|
|📝 更新|Dense Video Understanding with Gated Residual Tokenization|带门控残差标记的密集视频理解|Haichao Zhang, Wenhao Chai, Shwai He, Ang Li, Yun Fu|<http://arxiv.org/pdf/2509.14199v2>|提出Dense Video Understanding框架及Gated Residual Token...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Doppler Radiance Field-Guided Antenna Selection for Improved Generalization in Multi-Antenna Wi-Fi-based Human Activity Recognition|多天线Wi-Fi人体活动识别中基于多普勒辐射场引导的天线选择以提高泛化性能|Navid Hasanzadeh, Shahrokh Valaee|<http://arxiv.org/pdf/2509.15129v1>|提出了一种基于多天线选择的噪声抑制方法，通过DoRF拟合误差识别关键天线，显著提升Wi-Fi人体活动...|
|🆕 发布|LSTC-MDA: A Unified Framework for Long-Short Term Temporal Convolution and Mixed Data Augmentation in Skeleton-Based Action Recognition|基于骨骼动作识别的长短期时间卷积与混合数据增强统一框架：LSTC-MDA|Feng Ding, Haisheng Fu, Soroush Oraki, Jie Liang|<http://arxiv.org/pdf/2509.14619v1>|[代码](https://github.com/xiaobaoxia/LSTC-MDA.); 提出统一框架LSTC-MDA，通过长短时序卷积与混合数据增强，提升骨骼动作识别准确性和样本多样性。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Structural-Spectral Graph Convolution with Evidential Edge Learning for Hyperspectral Image Clustering|结构-谱图卷积与证据边学习用于高光谱图像聚类|Jianhan Qi, Yuheng Jia, Hui Liu, Junhui Hou|<http://arxiv.org/pdf/2506.09920v2>|[代码](https://github.com/jhqi/SSGCO-EGAEL.); 提出结构-光谱图卷积和证据引导的边学习策略，提升了超像素级高光谱图像聚类精度。|
|🆕 发布|Temporal Representation Learning of Phenotype Trajectories for pCR Prediction in Breast Cancer|乳腺癌新辅助化疗病理完全缓解预测中的表型轨迹时间表示学习|Ivana Janíčková, Yen Y. Tan, Thomas H. Helbich, Konstantin Miloserdov, Zsuzsanna Bago-Horvath, Ulrike Heber, Georg Langs|<http://arxiv.org/pdf/2509.14872v1>|提出了一种基于影像数据学习治疗早期响应动态表示的方法，用于预测乳腺癌患者新辅助化疗后的病理完全缓解情...|


### 掩码自编码 (Masked Autoencoding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Beyond Random Masking: A Dual-Stream Approach for Rotation-Invariant Point Cloud Masked Autoencoders|超越随机遮蔽：一种用于旋转不变点云遮蔽自编码器的双流方法|Xuanhua Yin, Dingxin Zhang, Yu Feng, Shunqi Mao, Jianhui Yu, Weidong Cai|<http://arxiv.org/pdf/2509.14975v1>|提出了一种结合3D空间网格和渐进式语义掩码的双流方法，有效提升了旋转不变性点云自编码器的性能。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Race Bias Free Face Aging Model for Reliable Kinship Verification|无种族偏见的可靠亲属验证人脸老化模型|Ali Nazari, Bardiya Kariminia, Mohsen Ebrahimi Moghaddam|<http://arxiv.org/pdf/2509.15177v1>|[代码](https://github.com/bardiya2254kariminia/An-Age-Transformation-whitout-racial-bias-for-Kinship-verification); 提出了一种无种族偏见的面部老化模型RA-GAN，有效提升了亲属验证的准确性和公平性。|
|🆕 发布|MedFact-R1: Towards Factual Medical Reasoning via Pseudo-Label Augmentation|MedFact-R1：通过伪标签增强实现事实性医疗推理|Gengliang Li, Rongyu Chen, Bin Li, Linlin Yang, Guodong Ding|<http://arxiv.org/pdf/2509.15154v1>|[代码](https://github.com/Garfieldgengliang/MEDFACT-R1.); 提出MedFact-R1框架，结合外部知识库和强化学习提升医疗视觉问答的事实一致性。|
|📝 更新|Mixture of Multicenter Experts in Multimodal AI for Debiased Radiotherapy Target Delineation|多模态人工智能中多中心专家混合模型用于去偏放射治疗靶区勾画|Yujin Oh, Sangjoon Park, Xiang Li, Pengfei Jin, Yi Wang, Jonathan Paly, Jason Efstathiou, Annie Chan .etc.|<http://arxiv.org/pdf/2410.00046v3>|提出了一种多中心专家混合框架，通过整合不同医疗中心的专长，有效减少医学AI模型的偏见并提高其泛化能力...|
|🆕 发布|Communication Efficient Split Learning of ViTs with Attention-based Double Compression|基于注意力机制的双重压缩的通信高效ViT分裂学习|Federico Alvetreti, Jary Pomponi, Paolo Di Lorenzo, Simone Scardapane|<http://arxiv.org/pdf/2509.15058v1>|提出了一种高效的Split Learning框架，通过双重注意力压缩策略显著降低通信成本，同时保持模...|
|🆕 发布|No Modality Left Behind: Adapting to Missing Modalities via Knowledge Distillation for Brain Tumor Segmentation|不遗漏任何模态：通过知识蒸馏适应缺失模态进行脑肿瘤分割|Shenghao Zhu, Yifei Chen, Weihong Chen, Shuo Jiang, Guanyu Zhou, Yuanhan Wang, Feiwei Qin, Changmiao Wang .etc.|<http://arxiv.org/pdf/2509.15017v1>|[代码](https://github.com/Quanato607/AdaMM.); 提出AdaMM框架，通过知识蒸馏应对脑肿瘤分割中缺失模态问题，提升准确性和鲁棒性。|
|🆕 发布|A Knowledge-driven Adaptive Collaboration of LLMs for Enhancing Medical Decision-making|知识驱动的LLM自适应协作增强医疗决策|Xiao Wu, Ting-Zhu Huang, Liang-Jian Deng, Yanyuan Qiao, Imran Razzak, Yutong Xie|<http://arxiv.org/pdf/2509.14998v1>|[代码](https://github.com/XiaoXiao-Woo/KAMAC.); 提出了一种自适应的多语言模型协作框架KAMAC，可根据临床诊断需求动态组建专家团队，显著提升医疗决策...|
|🆕 发布|Brain-HGCN: A Hyperbolic Graph Convolutional Network for Brain Functional Network Analysis|《脑-HGCN：一种用于脑功能网络分析的双曲图卷积网络》|Junhao Jia, Yunyou Liu, Cheng Yang, Yifei Sun, Feiwei Qin, Changmiao Wang, Yong Peng|<http://arxiv.org/pdf/2509.14965v1>|提出基于双曲几何的Brain-HGCN模型，有效表征脑网络层级结构，提升精神疾病分类性能。|
|🆕 发布|Template-Based Cortical Surface Reconstruction with Minimal Energy Deformation|基于模板的最小能量变形皮质表面重建|Patrick Madlindl, Fabian Bongratz, Christian Wachinger|<http://arxiv.org/pdf/2509.14827v1>|定位皮质表面重建挑战，提出MED损失函数，增强训练一致性，不牺牲准确性和拓扑正确性。|
|📝 更新|Large Multi-modal Models Can Interpret Features in Large Multi-modal Models|大型多模态模型能够解释大型多模态模型中的特征|Kaichen Zhang, Yifei Shen, Bo Li, Ziwei Liu|<http://arxiv.org/pdf/2411.14982v2>|提出框架解析大型多模态模型内部表示，通过自动解释框架揭示模型行为背后的语义特征。|
|🆕 发布|Feature-aligned Motion Transformation for Efficient Dynamic Point Cloud Compression|特征对齐的运动变换用于高效动态点云压缩|Xuan Deng, Xiandong Meng, Longguang Wang, Tiange Zhang, Xiaopeng Fan, Debin Zhao|<http://arxiv.org/pdf/2509.14591v1>|提出了一种特征对齐的运动变换框架，通过隐式建模连续时间变化，有效提升了动态点云压缩的效率和性能。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Maize Seedling Detection Dataset (MSDD): A Curated High-Resolution RGB Dataset for Seedling Maize Detection and Benchmarking with YOLOv9, YOLO11, YOLOv12 and Faster-RCNN|玉米幼苗检测数据集（MSDD）：一个针对玉米幼苗检测与基准测试的精选高分辨率RGB数据集，支持YOLOv9、YOLO11、YOLOv12和Faster-RCNN|Dewi Endah Kharismawati, Toni Kazic|<http://arxiv.org/pdf/2509.15181v1>|介绍了高分辨率RGB数据集MSDD，提升了玉米幼苗检测的准确性和效率。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RGB-Only Supervised Camera Parameter Optimization in Dynamic Scenes|动态场景中仅基于RGB的监督相机参数优化|Fang Li, Hao Zhang, Narendra Ahuja|<http://arxiv.org/pdf/2509.15123v1>|提出了一种仅使用单个RGB视频进行监督的动态场景相机参数优化方法，提高了效率和准确性。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Skeleton-based sign language recognition using a dual-stream spatio-temporal dynamic graph convolutional network|基于双流时空动态图卷积网络的骨骼手势识别|Liangjin Liu, Haoyang Zheng, Zhengzhong Zhu, Pei Zhou|<http://arxiv.org/pdf/2509.08661v2>|提出了一种双流动态图卷积网络，分离建模手势形态与轨迹，提高了手语识别准确率。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Manipulation Facing Threats: Evaluating Physical Vulnerabilities in End-to-End Vision Language Action Models|面对操纵威胁：评估端到端视觉语言动作模型中的物理脆弱性|Hao Cheng, Erjia Xiao, Yichi Wang, Chengyuan Yu, Mengshu Sun, Qiang Zhang, Yijie Guo, Kaidi Xu .etc.|<http://arxiv.org/pdf/2409.13174v3>|提出物理威胁评估流程PVEP，全面评估视觉语言动作模型在物理世界中的鲁棒性。|
|📝 更新|SWAT: Sliding Window Adversarial Training for Gradual Domain Adaptation|滑动窗口对抗训练用于渐变域自适应的SWAT方法|Zixi Wang, Xiangxu Zhao, Tonglan Xie, Mengmeng Jing, Lin Zuo|<http://arxiv.org/pdf/2501.19155v2>|提出滑动窗口对抗训练方法SWAT，通过逐步缩小中间域差异，有效缓解机器学习中的域偏移问题。|
|📝 更新|ReservoirTTA: Prolonged Test-time Adaptation for Evolving and Recurring Domains|水库TTA：针对演化和周期性领域的时间延长测试时适应|Guillaume Vray, Devavrat Tomar, Xufeng Gao, Jean-Philippe Thiran, Evan Shelhamer, Behzad Bozorgtabar|<http://arxiv.org/pdf/2505.14511v3>|[代码](https://github.com/LTS5/ReservoirTTA.); 提出了一种持续测试时适应框架ReservoirTTA，通过模型集合应对持续变化的测试域，有效克服了遗...|


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Birds look like cars: Adversarial analysis of intrinsically interpretable deep learning|鸟儿看起来像汽车：对抗性分析本质可解释的深度学习|Hubert Baniecki, Przemyslaw Biecek|<http://arxiv.org/pdf/2503.08636v2>|揭示了所谓“内在可解释”深度学习模型易受对抗攻击的风险，并提出了两种对抗性分析策略。|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|The Art of Saying "Maybe": A Conformal Lens for Uncertainty Benchmarking in VLMs|“说出‘也许’的艺术：用于大型视觉语言模型不确定性基准测试的相符性透镜”|Asif Azad, Mohammad Sadat Hossain, MD Sadik Hossain Shanto, M Saifur Rahman, Md Rizwan Parvez|<http://arxiv.org/pdf/2509.13379v2>|开展全面的不确定性评估，揭示大规模视觉语言模型在不确定性量化上的优势。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Domain Adaptation for Ulcerative Colitis Severity Estimation Using Patient-Level Diagnoses|基于患者层面诊断的溃疡性结肠炎严重程度估计的域自适应方法|Takamasa Yamaguchi, Brian Kenji Iwana, Ryoma Bise, Shota Harada, Takumi Okuo, Kiyohito Tanaka, Kaito Shiku|<http://arxiv.org/pdf/2509.14573v1>|提出了一种利用患者级别诊断结果的弱监督域自适应方法，有效克服了溃疡性结肠炎严重程度估计中的域偏移问题...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Seeing 3D Through 2D Lenses: 3D Few-Shot Class-Incremental Learning via Cross-Modal Geometric Rectification|通过2D镜头看3D：基于跨模态几何校正的3D小样本类别增量学习|Xiang Tuo, Xu Xuemiao, Liu Bangzhen, Li Jinyi, Li Yong, He Shengfeng|<http://arxiv.org/pdf/2509.14958v1>|提出了一种通过跨模态几何校正增强3D几何保真度的方法，有效解决了3D少样本增量学习中的几何对齐和纹理...|
|🆕 发布|ProtoMedX: Towards Explainable Multi-Modal Prototype Learning for Bone Health Classification|面向骨骼健康分类的可解释多模态原型学习：ProtoMedX|Alvaro Lopez Pellicer, Andre Mariucci, Plamen Angelov, Marwan Bukhari, Jemma G. Kerns|<http://arxiv.org/pdf/2509.14830v1>|提出了一种可解释的多模态原型学习模型ProtoMedX，用于骨健康分类，同时提供直观的解释，准确率优...|
|🆕 发布|One-step Multi-view Clustering With Adaptive Low-rank Anchor-graph Learning|一步多视角聚类及自适应低秩锚点图学习|Zhiyuan Xue, Ben Yang, Xuetao Zhang, Fei Wang, Zhiping Lin|<http://arxiv.org/pdf/2509.14724v1>|提出了一种自适应低秩锚图学习的一步多视角聚类方法，有效克服了信息冗余和噪声干扰，提升了聚类效果和效率...|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Do Vision-Language Models See Urban Scenes as People Do? An Urban Perception Benchmark|《视觉语言模型是否像人类一样看待城市景象？一种城市感知基准》|Rashid Mushkani|<http://arxiv.org/pdf/2509.14574v1>|提出城市感知基准，评估视觉语言模型对城市场景的理解与人类一致性。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation|力感知VLA：通过力感知混合专家模型增强VLA模型以实现接触丰富的操作|Jiawen Yu, Hairuo Liu, Qiaojun Yu, Jieji Ren, Ce Hao, Haitong Ding, Guangyu Huang, Guofan Huang .etc.|<http://arxiv.org/pdf/2505.22159v3>|提出ForceVLA框架，通过集成力感知模态提升机器人对接触密集任务的适应性和成功率。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Leveraging Geometric Visual Illusions as Perceptual Inductive Biases for Vision Models|利用几何视觉错觉作为视觉模型的感知归纳偏置|Haobo Yang, Minghao Guo, Dequan Yang, Wenyu Wang|<http://arxiv.org/pdf/2509.15156v1>|利用几何视觉错觉作为感知归纳偏置，提升了视觉模型的泛化能力和结构敏感性。|
|📝 更新|ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning|“ThinkAct：通过强化视觉潜在规划进行视觉-语言-动作推理”|Chi-Pin Huang, Yueh-Hua Wu, Min-Hung Chen, Yu-Chiang Frank Wang, Fu-En Yang|<http://arxiv.org/pdf/2507.16815v2>|提出ThinkAct框架，通过强化视觉潜在规划连接高阶推理与低阶行动，实现复杂任务中的少样本适应和长...|
|🆕 发布|EchoVLM: Dynamic Mixture-of-Experts Vision-Language Model for Universal Ultrasound Intelligence|EchoVLM：面向通用超声智能的动态混合专家视觉-语言模型|Chaoyin She, Ruifang Lu, Lida Chen, Wei Wang, Qinghua Huang|<http://arxiv.org/pdf/2509.14977v1>|[代码](https://github.com/Asunatan/EchoVLM.); 提出EchoVLM模型，针对超声医学成像优化，提升多任务处理效率和诊断准确性。|
|📝 更新|MovieCORE: COgnitive REasoning in Movies|《MovieCORE：电影中的认知推理》|Gueter Josmy Faure, Min-Hung Chen, Jia-Fong Yeh, Ying Cheng, Hung-Ting Su, Yung-Hao Tang, Shang-Hong Lai, Winston H. Hsu|<http://arxiv.org/pdf/2508.19026v3>|[代码](https://joslefaure.github.io/assets); 提出MovieCORE数据集，利用多语言模型生成深度认知问题，并通过Agentic Choice E...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PRISM: Product Retrieval In Shopping Carts using Hybrid Matching|使用混合匹配的购物车产品检索：PRISM|Arda Kabadayi, Senem Velipasalar, Jiajing Chen|<http://arxiv.org/pdf/2509.14985v1>|提出了一种结合视觉语言模型和像素级匹配的PRISM方法，有效提升了零售环境中产品检索的准确性和速度。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MARIC: Multi-Agent Reasoning for Image Classification|多智能体推理用于图像分类(MARIC)|Wonduk Seo, Minhyeong Yu, Hyunjin An, Seunghyun Lee|<http://arxiv.org/pdf/2509.14860v1>|提出了一种多代理推理框架MARIC，通过协作分析图像不同方面，实现了更鲁棒和可解释的图像分类。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Calibration-Aware Prompt Learning for Medical Vision-Language Models|《面向医学视觉语言模型的校准感知提示学习》|Abhishek Basu, Fahad Shamshad, Ashshak Sharifdeen, Karthik Nandakumar, Muhammad Haris Khan|<http://arxiv.org/pdf/2509.15226v1>|[代码](https://github.com/iabh1shekbasu/CalibPrompt.); 提出CalibPrompt框架，通过优化可学习提示进行医学视觉语言模型的置信度校准，提高预测可靠性。|
|📝 更新|T-SYNTH: A Knowledge-Based Dataset of Synthetic Breast Images|T-SYNTH：一种基于知识的合成乳腺图像数据集|Christopher Wiedeman, Anastasiia Sarmakeeva, Elena Sizikova, Daniil Filienko, Miguel Lago, Jana G. Delfino, Aldo Badano|<http://arxiv.org/pdf/2507.04038v2>|[代码](https://github.com/DIDSR/tsynth-release.); 提出生成合成乳腺图像的方法，创建了含像素级标注的T-SYNTH数据集，助力医学成像算法开发。|
|📝 更新|Dual-Mode Deep Anomaly Detection for Medical Manufacturing: Structural Similarity and Feature Distance|双模态深度异常检测在医疗制造中的应用：结构相似性与特征距离|Julio Zanon Diaz, Georgios Siogkas, Peter Corcoran|<http://arxiv.org/pdf/2509.05796v2>|提出双模态深度异常检测方法，结合结构相似性和特征距离，有效应对医疗设备制造中的视觉检测挑战。|
|🆕 发布|Radiology Report Conditional 3D CT Generation with Multi Encoder Latent diffusion Model|基于多编码器潜在扩散模型的放射学报告条件下的3D CT生成|Sina Amirrajab, Zohaib Salahuddin, Sheng Kuang, Henry C. Woodruff, Philippe Lambin|<http://arxiv.org/pdf/2509.14780v1>|提出Report2CT框架，利用完整放射学报告和多编码器条件，实现了高质量的3D CT图像生成。|
|📝 更新|MedFuncta: A Unified Framework for Learning Efficient Medical Neural Fields|MedFuncta：学习高效医学神经场的统一框架|Paul Friedrich, Florentin Bieder, Julian McGinnis, Julia Wolleb, Daniel Rueckert, Philippe C. Cattin|<http://arxiv.org/pdf/2502.14401v3>|MedFuncta通过统一编码和元学习策略，实现了大规模医疗数据集上高效神经场的训练与泛化。|
|📝 更新|Deep Learning-Driven Multimodal Detection and Movement Analysis of Objects in Culinary|深度学习驱动的烹饪场景中物体的多模态检测与运动分析|Tahoshin Alam Ishat, Mohammad Abdul Qayum|<http://arxiv.org/pdf/2509.00033v2>|集成YOLOv8、LSTM和ASR模型，实现厨房环境中对象检测与动作分析，自动生成烹饪指南。|
|🆕 发布|Enhancing Feature Fusion of U-like Networks with Dynamic Skip Connections|增强U型网络特征融合的动态跳跃连接方法|Yue Cao, Quansong He, Kaishen Wang, Jianlong Xiong, Tao He|<http://arxiv.org/pdf/2509.14610v1>|提出动态跳跃连接模块以克服传统跳跃连接的限制，实现自适应特征融合和多尺度特征整合。|
|🆕 发布|HybridMamba: A Dual-domain Mamba for 3D Medical Image Segmentation|混合Mamba：一种用于三维医学图像分割的双域Mamba方法|Weitong Wu, Zhaohu Xing, Jing Gong, Qin Peng, Lei Zhu|<http://arxiv.org/pdf/2509.14609v1>|提出HybridMamba模型，通过双域机制平衡3D医疗图像分割中的局部与全局特征，显著提升分割精度...|
|🆕 发布|DICE: Diffusion Consensus Equilibrium for Sparse-view CT Reconstruction|DICE: 用于稀疏视角CT重建的扩散共识平衡|Leon Suarez-Rodriguez, Roman Jacome, Romario Gualdron-Hurtado, Ana Mantilla-Dulcey, Henry Arguello|<http://arxiv.org/pdf/2509.14566v1>|提出DICE框架，结合扩散模型与数据一致性，有效提升稀疏视角CT图像重建质量。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VLM-E2E: Enhancing End-to-End Autonomous Driving with Multimodal Driver Attention Fusion|VLM-E2E: 增强端到端自动驾驶的多模态驾驶员注意力融合方法|Pei Liu, Haipeng Liu, Haichao Liu, Xin Liu, Jinxin Ni, Jun Ma|<http://arxiv.org/pdf/2502.18042v2>|提出VLM-E2E框架，利用视觉语言模型增强自动驾驶系统，通过融合视觉与文本信息提升驾驶环境理解。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Frame Sampling Strategies Matter: A Benchmark for small vision language models|帧采样策略至关重要：面向小规模视觉语言模型的基准测试|Marija Brkic, Anas Filali Razzouki, Yannis Tevissen, Khalil Guetari, Mounim A. El Yacoubi|<http://arxiv.org/pdf/2509.14769v1>|提出首个针对小规模视觉语言模型的视频问答基准，揭示了不同帧采样策略对模型性能的影响。|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Designing Latent Safety Filters using Pre-Trained Vision Models|使用预训练视觉模型设计潜在安全过滤器|Ihab Tabbara, Yuxuan Yang, Ahmad Hamzeh, Maxwell Astafyev, Hussein Sibai|<http://arxiv.org/pdf/2509.14758v1>|利用预训练视觉模型设计安全过滤器，提升基于视觉控制系统的安全性。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Efficient Fine-Tuning of DINOv3 Pretrained on Natural Images for Atypical Mitotic Figure Classification in MIDOG 2025|基于自然图像预训练的DINOv3的高效微调用于MIDOG 2025中的非典型有丝分裂图像分类|Guillaume Balezo, Hana Feki, Raphaël Bourgade, Lily Monnier, Alice Blondel, Albert Pla Planas, Thomas Walter|<http://arxiv.org/pdf/2508.21041v2>|利用低秩适应和少量参数微调DINOv3模型，有效识别异常有丝分裂图像，实现领域迁移和性能提升。|
|📝 更新|Robust Shape Regularity Criteria for Superpixel Evaluation|超像素评估的鲁棒形状正则性准则|Rémi Giraud, Vinh-Thong Ta, Nicolas Papadakis|<http://arxiv.org/pdf/1903.07146v3>|提出新的超像素形状规则性评价标准，涵盖凸性、平衡分布和轮廓平滑性，提高了评价的准确性和鲁棒性。|
|📝 更新|Survivability of Backdoor Attacks on Unconstrained Face Recognition Systems|《无约束人脸识别系统中后门攻击的生存性》|Quentin Le Roux, Yannick Teglia, Teddy Furon, Philippe Loubet-Moundi, Eric Bourbao|<http://arxiv.org/pdf/2507.01607v4>|分析了无约束人脸识别系统中后门攻击的生存性，并提出有效的最佳实践和对策。|
|📝 更新|A new dataset and comparison for multi-camera frame synthesis|多摄像头帧合成的新数据集与比较|Conall Daly, Anil Kokaram|<http://arxiv.org/pdf/2508.09068v2>|构建多相机数据集，首次公平比较帧插值与视图合成方法，发现实际场景中传统方法优于深度学习。|

