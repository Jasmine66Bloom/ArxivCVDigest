## [UPDATED!] **2025-09-19** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Pointing to a Llama and Call it a Camel: On the Sycophancy of Multimodal Large Language Models|指向一只羊驼并称之为骆驼：关于多模态大型语言模型的谄媚行为研究|Renjie Pi, Kehao Miao, Li Peihang, Runtao Liu, Jiahui Gao, Jipeng Zhang, Xiaofang Zhou|<http://arxiv.org/pdf/2509.16149v1>|揭示了多模态大语言模型在图像输入下的奉承行为，并提出Sycophantic Reflective T...|
|🆕 发布|See&Trek: Training-Free Spatial Prompting for Multimodal Large Language Model|“See&Trek：无需训练的多模态大型语言模型空间提示方法”|Pengteng Li, Pinhao Song, Wuyang Li, Weiyu Guo, Huizai Yao, Yijie Xu, Dugang Liu, Hui Xiong|<http://arxiv.org/pdf/2509.16087v1>|提出了一种无需训练的视觉提示框架SEE&TREK，通过增强视觉多样性和运动重建来提升大型多模态语言模...|
|📝 更新|Advances in Multimodal Adaptation and Generalization: From Traditional Approaches to Foundation Models|多模态适应与泛化进展：从传统方法到基础模型|Hao Dong, Moru Liu, Kaiyang Zhou, Eleni Chatzi, Juho Kannala, Cyrill Stachniss, Olga Fink|<http://arxiv.org/pdf/2501.18592v4>|[代码](https://github.com/donghao51/Awesome-Multimodal-Adaptation.); 系统综述了从传统方法到基础模型的多模态适应性和泛化性进展，涵盖多模态领域适应、测试时适应、领域泛化及...|
|🆕 发布|ENSAM: an efficient foundation model for interactive segmentation of 3D medical images|ENSAM：一种用于三维医学图像交互式分割的高效基础模型|Elias Stenhede, Agnar Martin Bjørnstad, Arian Ranjbar|<http://arxiv.org/pdf/2509.15874v1>|提出了一种高效的3D医疗图像分割模型ENSAM，通过轻量级结构和优化算法在有限数据与计算资源下实现高...|
|🆕 发布|TASAM: Terrain-and-Aware Segment Anything Model for Temporal-Scale Remote Sensing Segmentation|地形感知的任意分割模型TASAM：用于时间尺度遥感分割|Tianyang Wang, Xi Xiao, Gaofei Chen, Hanzhang Chi, Qi Zhang, Guo Cheng, Yingrui Ji|<http://arxiv.org/pdf/2509.15795v1>|针对遥感图像分割挑战，提出TASAM模型，融合地形和时间信息，提升精细对象分割性能。|
|📝 更新|Beyond Pixels: Enhancing LIME with Hierarchical Features and Segmentation Foundation Models|超越像素：通过层次特征和分割基础模型增强LIME解释性|Patrick Knab, Sascha Marton, Christian Bartelt|<http://arxiv.org/pdf/2403.07733v5>|提出DSEG-LIME框架，通过数据驱动分割和用户指导的层次化处理增强LIME的解释清晰度和准确性。|
|🆕 发布|SGMAGNet: A Baseline Model for 3D Cloud Phase Structure Reconstruction on a New Passive Active Satellite Benchmark|SGMAGNet：面向新型被动主动卫星基准的3D云相结构重建基线模型|Chi Yang, Fu Wang, Xiaofei Yang, Hao Huang, Weijia Cao, Xiaowen Chu|<http://arxiv.org/pdf/2509.15706v1>|提出了一种基准模型SGMAGNet，通过多模态卫星数据实现了3D云相结构的高精度重建。|
|🆕 发布|Hybrid Lie semi-group and cascade structures for the generalized Gaussian derivative model for visual receptive fields|混合李半群和级联结构在广义高斯导数模型中的视觉感受野应用|Tony Lindeberg|<http://arxiv.org/pdf/2509.15748v1>|提出了一种结合Lie半群和级联结构的方法，处理视觉感受野对几何图像变换的适应性，优化了多参数感受野家...|
|📝 更新|VLA-Mark: A cross modal watermark for large vision-language alignment model|VLA-Mark：面向大规模视觉语言对齐模型的跨模态水印|Shuliang Liu, Qi Zheng, Jesse Jiaxi Xu, Yibo Yan, Junyan Zhang, He Geng, Aiwei Liu, Peijie Jiang .etc.|<http://arxiv.org/pdf/2507.14067v2>|提出了一种保护知识产权且不影响视觉文本对齐的跨模态水印技术VLA-Mark，通过多尺度视觉文本对齐度...|
|📝 更新|ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data|"ScaleCUA：跨平台数据驱动的开源计算机使用代理扩展"|Zhaoyang Liu, Jingjing Xie, Zichen Ding, Zehao Li, Bowen Yang, Zhenyu Wu, Xuehui Wang, Qiushi Sun .etc.|<http://arxiv.org/pdf/2509.15221v2>|[代码](https://github.com/OpenGVLab/ScaleCUA.); 提出了ScaleCUA，通过构建跨平台的大规模数据集，显著提升了计算机使用代理的跨平台操作能力。|
|📝 更新|Pruning the Paradox: How CLIP's Most Informative Heads Enhance Performance While Amplifying Bias|剪枝悖论：CLIP中最具信息性的头如何提升性能的同时放大偏差|Avinash Madasu, Vasudev Lal, Phillip Howard|<http://arxiv.org/pdf/2503.11103v3>|提出 Concept Consistency Score (CCS) 评估 CLIP 模型注意力头，...|
|🆕 发布|BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent|BTL-UI：面向图形用户界面智能体的眨眼-思考-关联推理模型|Shaojie Zhang, Ruoceng Zhang, Pei Fu, Shaokang Wang, Jiahui Yang, Xin Du, Shiqi Cui, Bin Qin .etc.|<http://arxiv.org/pdf/2509.15566v1>|提出“Blink-Think-Link”框架，模仿人类认知过程，提升AI与图形界面交互的自然性和效率...|
|🆕 发布|TennisTV: Do Multimodal Large Language Models Understand Tennis Rallies?|《TennisTV：多模态大型语言模型能理解网球回合吗？》|Zhongyuan Bao, Lejun Zhang|<http://arxiv.org/pdf/2509.15602v1>|提出TennisTV，首个全面评估大型多模态语言模型在网球视频理解上的基准，揭示了模型在快速运动理解...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer|“MANZANO：一种简单且可扩展的统一多模态模型，具有混合视觉标记器”|Yanghao Li, Rui Qian, Bowen Pan, Haotian Zhang, Haoshuo Huang, Bowen Zhang, Jialing Tong, Haoxuan You .etc.|<http://arxiv.org/pdf/2509.16197v1>|提出了一种简单可扩展的统一多模态模型Manzano，通过混合视觉编码器减少了理解与生成视觉内容间的性...|
|📝 更新|Integrating Spatiotemporal Vision Transformer into Digital Twins for High-Resolution Heat Stress Forecasting in Campus Environments|将空间时间视觉变换器集成到数字孪生中，用于校园环境下高分辨率热应激预测|Wenjing Gong, Xinyue Ye, Keshu Wu, Suphanut Jamonnak, Wenyu Zhang, Yifan Yang, Xiao Huang|<http://arxiv.org/pdf/2502.09657v2>|集成时空视觉变换器模型于数字孪生框架，实现校园环境下高分辨率热应力精准预测。|
|🆕 发布|Overview of PlantCLEF 2024: multi-species plant identification in vegetation plot images|《2024年PlantCLEF概述：植被图中的多物种植物识别》|Herve Goeau, Vincent Espitalier, Pierre Bonnet, Alexis Joly|<http://arxiv.org/pdf/2509.15768v1>|提出PlantCLEF 2024挑战，利用大规模数据集和预训练模型，实现高分辨率植被图像中多物种植物...|
|📝 更新|AToken: A Unified Tokenizer for Vision|AToken：一种统一的视觉标记器|Jiasen Lu, Liangchen Song, Mingze Xu, Byeongjoo Ahn, Yanjun Wang, Chen Chen, Afshin Dehghan, Yinfei Yang|<http://arxiv.org/pdf/2509.14476v2>|首次提出统一视觉 tokenizer AToken，实现图像、视频和3D资产的高保真重建和语义理解。|
|🆕 发布|UNIV: Unified Foundation Model for Infrared and Visible Modalities|统一基础模型：用于红外与可见光模态|Fangyuan Mao, Shuo Wang, Jilin Mei, Chen Min, Shun Lu, Fuyang Liu, Yu Hu|<http://arxiv.org/pdf/2509.15642v1>|[代码](https://github.com/fangyuanmao/UNIV.); 提出了一种统一基础模型UNIV，通过模仿生物视觉机制实现红外与可见光模态的高效融合，显著提升了多模态...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BaseReward: A Strong Baseline for Multimodal Reward Model|多模态奖励模型的一种强基线：BaseReward|Yi-Fan Zhang, Haihua Yang, Huanyu Zhang, Yang Shi, Zezhou Chen, Haochen Tian, Chaoyou Fu, Haotian Wang .etc.|<http://arxiv.org/pdf/2509.16127v1>|提出了BaseReward基线模型，为构建高效多模态奖励模型提供了明确指导，并在多个基准测试中取得最...|
|🆕 发布|Language-Instructed Reasoning for Group Activity Detection via Multimodal Large Language Model|通过多模态大型语言模型的语言指导推理进行群体活动检测|Jihua Peng, Qianxiong Xu, Yichen Liu, Chenxi Liu, Cheng Long, Rui Zhao, Ziyue Li|<http://arxiv.org/pdf/2509.16054v1>|提出了一种结合语言指导推理的多模态大规模语言模型框架，有效提升了集体活动检测的准确性和解释性。|
|🆕 发布|DistillMatch: Leveraging Knowledge Distillation from Vision Foundation Model for Multimodal Image Matching|DistillMatch：利用视觉基础模型的知识蒸馏进行多模态图像匹配|Meng Yang, Fan Fan, Zizhuo Li, Songchu Deng, Yong Ma, Jiayi Ma|<http://arxiv.org/pdf/2509.16017v1>|提出DistillMatch方法，通过知识蒸馏从视觉基础模型提取特征，提升跨模态图像匹配性能。|
|🆕 发布|RangeSAM: Leveraging Visual Foundation Models for Range-View repesented LiDAR segmentation|范围SAM：利用视觉基础模型进行范围视图表示的激光雷达分割|Paul Julius Kühn, Duc Anh Nguyen, Arjan Kuijper, Holger Graf, Dieter Fellner, Saptarshi Neil Sinha|<http://arxiv.org/pdf/2509.15886v1>|本研究利用视觉基础模型提出首个适用于激光雷达点云的range-view分割框架，实现高效准确的3D感...|
|🆕 发布|Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data|通过采样合成数据在潜在空间中进行高效的长尾学习|Nakul Sharma|<http://arxiv.org/pdf/2509.15859v1>|提出了一种利用视觉基础模型生成合成数据以高效处理长尾分类问题的新框架。|
|📝 更新|The Moon's Many Faces: A Single Unified Transformer for Multimodal Lunar Reconstruction|《月亮的多样面貌：一种用于多模态月球重构的统一转换器》|Tom Sander, Moritz Tenthoff, Kay Wohlfarth, Christian Wöhler|<http://arxiv.org/pdf/2505.05644v2>|提出了一种统一变换器架构，实现了月球多模态数据间的转换，为大规模行星三维重建提供了新方法。|
|📝 更新|Img2CAD: Reverse Engineering 3D CAD Models from Images through VLM-Assisted Conditional Factorization|通过VLM辅助的条件分解从图像逆向重建3D CAD模型：Img2CAD|Yang You, Mikaela Angelina Uy, Jiaqi Han, Rahul Thomas, Haotong Zhang, Yi Du, Hansheng Chen, Francis Engelmann .etc.|<http://arxiv.org/pdf/2408.01437v2>|[代码](https://github.com/qq456cvb/Img2CAD.); 提出了一种结合视觉语言模型和条件分解的方法，实现了从图像逆向生成3D CAD模型。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Cross-Resolution SAR Target Detection Using Structural Hierarchy Adaptation and Reliable Adjacency Alignment|跨分辨率合成孔径雷达目标检测：基于结构层次适应与可靠邻接对齐方法|Jiang Qin, Bin Zou, Haolin Li, Lamei Zhang|<http://arxiv.org/pdf/2507.08290v2>|提出了一种跨分辨率SAR目标检测方法CR-Net，通过结构层次适应和可靠邻接对齐实现域自适应，提升检...|
|🆕 发布|Sparse Multiview Open-Vocabulary 3D Detection|稀疏多视角开放词汇三维检测|Olivier Moliner, Viktor Larsson, Kalle Åström|<http://arxiv.org/pdf/2509.15924v1>|提出了一种无需训练、基于二维预训练模型的稀疏多视角三维物体检测方法，在稀疏视角设置下性能优于现有技术...|
|🆕 发布|Prostate Capsule Segmentation from Micro-Ultrasound Images using Adaptive Focal Loss|前列腺囊性分割：基于自适应焦点损失函数的微超声图像处理|Kaniz Fatema, Vaibhav Thakur, Emad A. Mohammed|<http://arxiv.org/pdf/2509.15595v1>|提出自适应焦点损失函数，有效提升微超声图像前列腺囊精准分割性能。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PAN: Pillars-Attention-Based Network for 3D Object Detection|基于柱状注意力网络的3D目标检测|Ruan Bispo, Dane Mitrev, Letizia Mariotti, Clément Botty, Denver Humphrey, Anthony Scanlan, Ciarán Eising|<http://arxiv.org/pdf/2509.15935v1>|提出了一种基于雷达柱状特征和自注意力机制的3D物体检测算法，提升了准确度并减少了推理时间。|
|🆕 发布|MCOD: The First Challenging Benchmark for Multispectral Camouflaged Object Detection|多光谱伪装目标检测的首个挑战性基准：MCOD|Yang Li, Tingfa Xu, Shuyan Bai, Peifu Liu, Jianan Li|<http://arxiv.org/pdf/2509.15753v1>|[代码](https://github.com/yl2900260-bit/MCOD.); 提出了首个针对多光谱伪装目标检测的挑战性基准数据集MCOD，提升了在困难条件下的检测性能。|
|🆕 发布|Towards Size-invariant Salient Object Detection: A Generic Evaluation and Optimization Approach|面向尺寸不变性的显著目标检测：一种通用评估与优化方法|Shilong Bao, Qianqian Xu, Feiran Li, Boyu Han, Zhiyong Yang, Xiaochun Cao, Qingming Huang|<http://arxiv.org/pdf/2509.15573v1>|[代码](https://github.com/Ferry-Li/SI-SOD.); 提出了一种大小不变性评价和优化框架，有效解决了显著物体检测中大小敏感性问题。|
|🆕 发布|Enhancing Sa2VA for Referent Video Object Segmentation: 2nd Solution for 7th LSVOS RVOS Track|增强Sa2VA用于参考视频对象分割：第七届LSVOS RVOS赛道第二次解决方案|Ran Hong, Feng Lu, Leilei Cao, An Yan, Youhai Jiang, Fengjie Zhu|<http://arxiv.org/pdf/2509.15546v1>|提出了一种无需额外训练的框架，通过视频语言检查器和关键帧采样器显著提升Sa2VA在参照视频对象分割任...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DPC-QA Net: A No-Reference Dual-Stream Perceptual and Cellular Quality Assessment Network for Histopathology Images|DPC-QA Net：一种无参考双流感知与细胞质量评估网络，用于病理组织图像|Qijun Yang, Boyang Wang, Hujun Yin|<http://arxiv.org/pdf/2509.15802v1>|提出了一种双流无参考图像质量评估网络，有效识别组织病理学图像质量问题并提高细胞识别准确度。|
|📝 更新|iCBIR-Sli: Interpretable Content-Based Image Retrieval with 2D Slice Embeddings|基于二维切片嵌入的可解释内容图像检索iCBIR-Sli|Shuhei Tomoshige, Hayato Muraki, Kenichi Oishi, Hitoshi Iyatomi|<http://arxiv.org/pdf/2501.01642v2>|提出了一种基于2D切片嵌入的脑部MR图像内容检索方法，有效聚合切片信息，实现了高完整性和可解释性的检...|
|📝 更新|Classification of Tents in Street Bazaars Using CNN|使用卷积神经网络对街头市集中的帐篷进行分类|Azamat Ibragimov, Ruslan Isaev, Remudin Reshid Mekuria, Gulnaz Gimaletdinova, Dim Shaiakhmetov|<http://arxiv.org/pdf/2506.17946v2>|提出了一种基于深度学习的帐篷分类方法，通过定制CNN和EfficientNetB0模型提高了街市帐篷...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Ideal Registration? Segmentation is All You Need|理想的配准？只需分段即可|Xiang Chen, Fengting Zhang, Qinghao Liu, Min Liu, Kun Wu, Yaonan Wang, Hang Zhang|<http://arxiv.org/pdf/2509.15784v1>|提出了一种基于区域分割的适应性图像配准框架，通过利用特定区域的变形模式显著提升了配准精度。|
|🆕 发布|Uncertainty-Gated Deformable Network for Breast Tumor Segmentation in MR Images|不确定性门控可变形网络在MR图像中乳腺肿瘤分割的应用|Yue Zhang, Jiahua Dong, Chengtao Peng, Qiuli Wang, Dan Song, Guiduo Duan|<http://arxiv.org/pdf/2509.15758v1>|提出了一种结合CNN和Transformers的不确定性门控可变形网络，用于准确分割MRI图像中的乳...|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AcT2I: Evaluating and Improving Action Depiction in Text-to-Image Models|AcT2I：评估与提升文本到图像模型中的动作描述质量|Vatsal Malaviya, Agneet Chatterjee, Maitreya Patel, Yezhou Yang, Chitta Baral|<http://arxiv.org/pdf/2509.16141v1>|提出AcT2I基准，并利用知识蒸馏技术增强文本到图像模型对动作描述的准确性。|
|📝 更新|LED: LLM Enhanced Open-Vocabulary Object Detection without Human Curated Data Generation|LED：无需人工筛选数据生成的LLM增强开放词汇对象检测|Yang Zhou, Shiyu Zhao, Yuxiao Chen, Zhenting Wang, Can Jin, Dimitris N. Metaxas|<http://arxiv.org/pdf/2503.13794v6>|提出了一种利用大型语言模型提升无需人工数据生成的开放词汇目标检测性能的方法。|
|📝 更新|Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study|《视觉-语言模型在野外环境下的安全性：基于模因的基准研究》|DongGeon Lee, Joonwon Jang, Jihae Jeong, Hwanjo Yu|<http://arxiv.org/pdf/2505.15389v2>|[代码](https://github.com/oneonlee/Meme-Safety-Bench.); 提出MemeSafetyBench基准，评估视觉语言模型在处理真实网络迷因时的安全性问题。|
|📝 更新|Assessing invariance to affine transformations in image quality metrics|评估图像质量度量对仿射变换的不变性|Nuria Alabau-Bosque, Paula Daudén-Oliver, Jorge Vila-Tomás, Valero Laparra, Jesús Malo|<http://arxiv.org/pdf/2407.17927v3>|提出了一种评估图像质量度量对仿射变换不变性的新方法，揭示了现有度量与人类视觉特性的差异。|
|📝 更新|FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait|FLOAT：音频驱动的说话肖像生成运动潜在流匹配|Taekyung Ki, Dongchan Min, Gyeongsu Chae|<http://arxiv.org/pdf/2412.01064v5>|提出了一种基于流匹配生成模型的音频驱动说话肖像视频生成方法，通过正交运动潜在空间实现高效且时间一致的...|
|📝 更新|GPSToken: Gaussian Parameterized Spatially-adaptive Tokenization for Image Representation and Generation|高斯参数化空间自适应标记化（GPSToken）：用于图像表示与生成的算法|Zhengqiang Zhang, Rongyuan Wu, Lingchen Sun, Lei Zhang|<http://arxiv.org/pdf/2509.01109v2>|[代码](https://github.com/xtudbxk/GPSToken); 提出了一种基于高斯参数化的自适应图像表征方法，通过动态调整区域形状和位置，提高了图像生成和重建的性能...|
|📝 更新|OptiScene: LLM-driven Indoor Scene Layout Generation via Scaled Human-aligned Data Synthesis and Multi-Stage Preference Optimization|"OptiScene：基于大规模人类对齐数据合成与多阶段偏好优化的LLM驱动的室内场景布局生成"|Yixuan Yang, Zhen Luo, Tongsheng Ding, Junru Lu, Mingqi Gao, Jinyu Yang, Victor Sanchez, Feng Zheng|<http://arxiv.org/pdf/2506.07570v2>|提出OptiScene模型，结合大规模数据合成与多阶段优化，提升室内布局生成的一致性和质量。|
|🆕 发布|Vision-Language Models as Differentiable Semantic and Spatial Rewards for Text-to-3D Generation|将视觉-语言模型作为可微分语义和空间奖励，用于文本到3D生成|Weimin Bai, Yubo Li, Weijian Luo, Wenzheng Chen, He Sun|<http://arxiv.org/pdf/2509.15772v1>|提出VLM3D框架，利用大型视觉语言模型作为可微分语义和空间先验，提升文本到3D生成质量和几何一致性...|
|📝 更新|Sea-ing Through Scattered Rays: Revisiting the Image Formation Model for Realistic Underwater Image Generation|透过散射光线看海：重新审视图像形成模型以实现真实水下图像生成|Vasiliki Ismiroglou, Malte Pedersen, Stefan H. Bengtson, Andreas Aakerberg, Thomas B. Moeslund|<http://arxiv.org/pdf/2509.15011v2>|提出了一种包含前向散射项的改进合成数据生成流程，有效模拟了高浑浊水下环境中的视觉退化现象。|
|🆕 发布|Layout Stroke Imitation: A Layout Guided Handwriting Stroke Generation for Style Imitation with Diffusion Model|布局笔划模仿：基于布局引导的手写笔划生成用于风格模仿的扩散模型|Sidra Hanif, Longin Jan Latecki|<http://arxiv.org/pdf/2509.15678v1>|引入布局指导的扩散模型，实现了书法风格的笔画生成与间距控制。|
|🆕 发布|FingerSplat: Contactless Fingerprint 3D Reconstruction and Generation based on 3D Gaussian Splatting|基于三维高斯散点法的非接触式指纹三维重建与生成：FingerSplat|Yuwei Jia, Yutang Lu, Zhe Cui, Fei Su|<http://arxiv.org/pdf/2509.15648v1>|提出了一种基于3D高斯散点的无接触指纹三维重建与生成框架，提高了无接触指纹识别性能。|
|🆕 发布|Latent Zoning Network: A Unified Principle for Generative Modeling, Representation Learning, and Classification|潜在分区网络：生成建模、表征学习与分类的统一原理|Zinan Lin, Enshu Liu, Xuefei Ning, Junyi Zhu, Wenyu Wang, Sergey Yekhanin|<http://arxiv.org/pdf/2509.15591v1>|[代码](https://github.com/microsoft/latent-zoning-networks.); 提出统一框架Latent Zoning Network，通过共享潜空间同时优化生成模型、表征学习和分...|
|📝 更新|OSPO: Object-centric Self-improving Preference Optimization for Text-to-Image Generation|面向文本到图像生成的以对象为中心的自优化偏好优化方法（OSPO）|Yoonjin Oh, Yongjin Kim, Hyomin Kim, Donghwan Chi, Sungwoong Kim|<http://arxiv.org/pdf/2506.02015v2>|提出了一种针对对象级别的自优化偏好优化框架OSPO，有效解决了文本到图像生成中的对象细节对齐问题。|
|📝 更新|SPATIALGEN: Layout-guided 3D Indoor Scene Generation|空间生成：基于布局引导的室内三维场景生成|Chuan Fang, Heng Li, Yixun Liang, Jia Zheng, Yongsen Mao, Yuan Liu, Rui Tang, Zihan Zhou .etc.|<http://arxiv.org/pdf/2509.14981v2>|提出了SpatialGen模型，利用大规模数据集生成高质量、语义一致的3D室内场景。|
|🆕 发布|Lynx: Towards High-Fidelity Personalized Video Generation|“Lynx：迈向高保真个性化视频生成”|Shen Sang, Tiancheng Zhi, Tianpei Gu, Jing Liu, Linjie Luo|<http://arxiv.org/pdf/2509.15496v1>|Lynx通过引入两个轻量级适配器，实现了从单张图片生成高质量个性化视频，同时保持身份真实性和视觉连贯...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dynamic Classifier-Free Diffusion Guidance via Online Feedback|动态无分类器扩散引导通过在线反馈|Pinelopi Papalampidi, Olivia Wiles, Ira Ktena, Aleksandar Shtedritski, Emanuele Bugliarello, Ivana Kajic, Isabela Albuquerque, Aida Nematzadeh|<http://arxiv.org/pdf/2509.16131v1>|提出动态调整文本到图像生成过程中的指导尺度方法，通过实时反馈优化生成质量。|
|🆕 发布|SegDINO3D: 3D Instance Segmentation Empowered by Both Image-Level and Object-Level 2D Features|SegDINO3D：基于图像级和对象级二维特征的三维实例分割|Jinyuan Qu, Hongyang Li, Xingyu Chen, Shilong Liu, Yukai Shi, Tianhe Ren, Ruitao Jing, Lei Zhang|<http://arxiv.org/pdf/2509.16098v1>|SegDINO3D通过融合图像级和对象级2D特征，显著提升了3D实例分割性能。|
|🆕 发布|DiffusionNFT: Online Diffusion Reinforcement with Forward Process|扩散NFT：在线前向过程扩散强化学习|Kaiwen Zheng, Huayu Chen, Haotian Ye, Haoxiang Wang, Qinsheng Zhang, Kai Jiang, Hang Su, Stefano Ermon .etc.|<http://arxiv.org/pdf/2509.16117v1>|提出了一种优化扩散模型的新在线强化学习范式DiffusionNFT，通过正向过程直接训练，提高了效率...|
|🆕 发布|PRISM: Probabilistic and Robust Inverse Solver with Measurement-Conditioned Diffusion Prior for Blind Inverse Problems|PRISM：用于盲目逆问题的概率性和鲁棒逆求解器，带有测量条件化的扩散先验|Yuanyun Hu, Evan Bell, Guijin Wang, Yu Sun|<http://arxiv.org/pdf/2509.16106v1>|提出了一种用于解决盲目逆问题的概率性和鲁棒性逆求解器PRISM，通过结合测量条件下的扩散先验，实现了...|
|🆕 发布|Blind-Spot Guided Diffusion for Self-supervised Real-World Denoising|盲区引导扩散用于自监督现实世界降噪|Shen Cheng, Haipeng Li, Haibin Huang, Xiaohong Liu, Shuaicheng Liu|<http://arxiv.org/pdf/2509.16091v1>|[代码](https://github.com/Sumching/BSGD.); 提出了一种双分支扩散框架，结合盲点网络和传统扩散模型，实现了无需成对数据的高效真实世界图像去噪。|
|📝 更新|HistDiST: Histopathological Diffusion-based Stain Transfer|组织病理学扩散基于染料转移的直方图匹配方法：HistDiST|Erik Großkopf, Valay Bundele, Mehran Hosseinzadeh, Hendrik P. A. Lensch|<http://arxiv.org/pdf/2505.06793v2>|提出了一种基于扩散模型的高保真度H&E到IHC染色转换方法，通过双条件策略和新型评价指标显著提升了分...|
|📝 更新|TT-DF: A Large-Scale Diffusion-Based Dataset and Benchmark for Human Body Forgery Detection|TT-DF：用于人体伪造检测的大规模扩散基础数据集与基准测试|Wenkui Yang, Zhida Zhang, Xiaoqiang Zhou, Junxian Duan, Jie Cao|<http://arxiv.org/pdf/2505.08437v2>|[代码](https://github.com/HashTAG00002/TT-DF.); 提出了TT-DF大规模数据集和TOF-Net检测模型，解决了人体伪造检测缺乏数据和方法的难题。|
|📝 更新|SAR-TEXT: A Large-Scale SAR Image-Text Dataset Built with SAR-Narrator and Progressive Transfer Learning|SAR-TEXT：基于SAR-Narrator和渐进迁移学习构建的大规模合成孔径雷达图像-文本数据集|Yiguo He, Xinjun Cheng, Junjie Zhu, Chunping Qiu, Jun Wang, Xichuan Zhang, Qiangjuan Huang, Ke Yang|<http://arxiv.org/pdf/2507.18743v2>|[代码](https://github.com/YiguoHe/SAR-TEXT.); 构建了大规模高质的SAR图像-文本数据集SAR-TEXT，通过多阶段策略提升语义理解能力。|
|📝 更新|Towards Robust Defense against Customization via Protective Perturbation Resistant to Diffusion-based Purification|面向抵抗基于扩散纯化的保护性扰动防御定制化攻击|Wenkui Yang, Jie Cao, Junxian Duan, Ran He|<http://arxiv.org/pdf/2509.13922v2>|提出了一种名为AntiPure的保护性扰动方法，有效抵御了图像净化攻击，增强了定制图像的安全性。|
|📝 更新|G2D2: Gradient-Guided Discrete Diffusion for Inverse Problem Solving|梯度引导的离散扩散用于逆问题求解的G2D2方法|Naoki Murata, Chieh-Hsin Lai, Yuhta Takida, Toshimitsu Uesaka, Bac Nguyen, Stefano Ermon, Yuki Mitsufuji|<http://arxiv.org/pdf/2410.14710v2>|[代码](https://github.com/sony/g2d2.); 提出了一种利用离散扩散模型解决线性逆问题的方法，通过近似后验分布和星形噪声过程，实现了与连续扩散技术...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MCGA: Mixture of Codebooks Hyperspectral Reconstruction via Grayscale-Aware Attention|基于灰度感知注意力的码本混合高光谱重建方法MCGA|Zhanjiang Yang, Lijun Sun, Jiawei Dong, Xiaoxin An, Yang Liu, Meng Li|<http://arxiv.org/pdf/2507.09885v2>|[代码](https://github.com/Fibonaccirabbit/MCGA.); 提出了一种高效的混合码本与灰度感知注意力的框架，通过显式利用光谱先验和光度一致性，解决了从RGB图像...|
|📝 更新|Data-Efficient Learning for Generalizable Surgical Video Understanding|数据高效学习以实现普适性手术视频理解|Sahar Nasirihaghighi|<http://arxiv.org/pdf/2508.10215v2>|提出数据高效的半监督学习方法，利用少量标注数据提升手术视频分析模型的泛化性能。|
|📝 更新|Generalizable Holographic Reconstruction via Amplitude-Only Diffusion Priors|通过振幅仅扩散先验实现通用全息重建|Jeongsol Kim, Chanseok Lee, Jongin You, Jong Chul Ye, Mooseok Jang|<http://arxiv.org/pdf/2509.12728v2>|提出了一种利用仅幅度信息的扩散模型，实现了无需相位地面真相数据的复杂场重建。|
|🆕 发布|SAMPO:Scale-wise Autoregression with Motion PrOmpt for generative world models|SAMPO：基于运动提示的尺度自回归生成世界模型|Sen Wang, Jingyi Tian, Le Wang, Zhimin Liao, Jiayi Li, Huaiyi Dong, Kun Xia, Sanping Zhou .etc.|<http://arxiv.org/pdf/2509.15536v1>|提出了一种结合视觉自回归模型与因果模型的SAMPO框架，有效提升了生成模型在动态场景预测中的时序一致...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CIDER: A Causal Cure for Brand-Obsessed Text-to-Image Models|CIDER：一种针对品牌痴迷的文本到图像模型的原因性治疗方法|Fangjian Shen, Zifeng Liang, Chao Wang, Wushao Wen|<http://arxiv.org/pdf/2509.15803v1>|提出CIDER框架，通过提示优化减轻文本到图像生成中的品牌偏见，保持图像质量和美感。|
|🆕 发布|TrueMoE: Dual-Routing Mixture of Discriminative Experts for Synthetic Image Detection|"TrueMoE：具有双路由区分性专家的合成图像检测模型"|Laixin Zhang, Shuaibo Li, Wei Ma, Hongbin Zha|<http://arxiv.org/pdf/2509.15741v1>|提出了一种双路由判别专家混合框架TrueMoE，通过多个专精子空间协作识别合成图像，提高了泛化能力和...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Graph-based Point Cloud Surface Reconstruction using B-Splines|基于B样条的图论点云曲面重建|Stuti Pathak, Rhys G. Evans, Gunther Steenackers, Rudi Penne|<http://arxiv.org/pdf/2509.16050v1>|提出了一种无需点法线的字典引导图卷积网络策略，同时预测控制点的位置和数量，实现了对噪声点云数据的平滑...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DSDNet: Raw Domain Demoiréing via Dual Color-Space Synergy|DSDNet：通过双色彩空间协同的原始域去摩尔纹网络|Qirui Yang, Fangpu Zhang, Yeying Jin, Qihua Cheng, Peng-Tao Jiang, Huanjing Yue, Jingyu Yang|<http://arxiv.org/pdf/2504.15756v2>|[代码](https://xxxxxxxxdsdnet.github.io/DSDNet); 提出了一种单阶段原始域去摩尔纹框架DSDNet，通过原始图像与YCbCr图像的协同作用，有效去除摩尔...|
|🆕 发布|Shedding Light on Depth: Explainability Assessment in Monocular Depth Estimation|单目深度估计中的解释性评估：照亮深度之谜|Lorenzo Cirillo, Claudio Schiavella, Lorenzo Papa, Paolo Russo, Irene Amerini|<http://arxiv.org/pdf/2509.15980v1>|提出了一种评估单目深度估计网络解释性的方法，引入了 Attribution Fidelity 指标以...|
|🆕 发布|Diffusion-Based Cross-Modal Feature Extraction for Multi-Label Classification|基于扩散的跨模态特征提取用于多标签分类|Tian Lan, Yiming Zheng, Jianxin Yin|<http://arxiv.org/pdf/2509.15553v1>|[代码](https://github.com/lt-0123/Diff-Feat.); 提出了一种基于预训练扩散变换器的跨模态特征提取框架，实现了多标签分类任务的最佳性能。|
|🆕 发布|Beyond Words: Enhancing Desire, Emotion, and Sentiment Recognition with Non-Verbal Cues|超越语言：利用非言语线索增强欲望、情感与情绪识别|Wei Chen, Tongguan Wang, Feiyue Xue, Junkai Li, Hui Liu, Ying Sha|<http://arxiv.org/pdf/2509.15540v1>|[代码](https://github.com/especiallyW/SyDES.); 提出了一种对称双向多模态学习框架，通过图文互导增强对意图相关表征的捕捉，提升了欲望、情感和情绪识别的...|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MoAngelo: Motion-Aware Neural Surface Reconstruction for Dynamic Scenes|动态场景下的运动感知神经表面重建：MoAngelo|Mohamed Ebbed, Zorah Lähner|<http://arxiv.org/pdf/2509.15892v1>|提出了一种动态场景的高细节重建框架，通过优化变形场和模板更新，提高了动态场景的重建精度。|
|🆕 发布|Enriched Feature Representation and Motion Prediction Module for MOSEv2 Track of 7th LSVOS Challenge: 3rd Place Solution|增强特征表示与运动预测模块：第七届LSVOS挑战赛MOSEv2赛道第三名解决方案|Chang Soo Lim, Joonyoung Moon, Donghyeon Cho|<http://arxiv.org/pdf/2509.15781v1>|[代码](https://github.com/2025-LSVOS-3rd-place/MOSEv2_3rd_place.); 集成 Cutie 和 SAM2 优势，引入运动预测模块，提升视频对象分割的稳定性和准确性。|
|🆕 发布|MS-GS: Multi-Appearance Sparse-View 3D Gaussian Splatting in the Wild|MS-GS：野外多外观稀疏视图三维高斯散点绘制|Deming Li, Kaiwen Jiang, Yutao Tang, Ravi Ramamoorthi, Rama Chellappa, Cheng Peng|<http://arxiv.org/pdf/2509.15548v1>|提出MS-GS框架，利用3D Gaussian Splatting处理多外观稀疏视图场景，提高场景重...|


## 时序视觉分析 (Temporal Visual Analysis)


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Data to Diagnosis: A Large, Comprehensive Bone Marrow Dataset and AI Methods for Childhood Leukemia Prediction|从数据到诊断：一个大型全面的骨髓数据集及用于儿童白血病预测的人工智能方法|Henning Höfener, Farina Kock, Martina Pontones, Tabita Ghete, David Pfrang, Nicholas Dickel, Meik Kunz, Daniela P. Schacherer .etc.|<http://arxiv.org/pdf/2509.15895v1>|构建大型高质量公开白血病骨髓数据集，提出细胞检测与分类方法，助力儿童白血病精准诊断。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Experimenting with Affective Computing Models in Video Interviews with Spanish-speaking Older Adults|在西班牙语老年人群的视频面试中实验情感计算模型|Josep Lopez Camunas, Cristina Bustos, Yanjun Zhu, Raquel Ros, Agata Lapedriza|<http://arxiv.org/pdf/2501.16870v2>|评估了现有情感计算模型在西班牙语老年人群中的表现，并引入了针对该人群的新数据集。|
|🆕 发布|ChronoForge-RL: Chronological Forging through Reinforcement Learning for Enhanced Video Understanding|ChronoForge-RL：基于强化学习的时序伪造增强视频理解|Kehua Chen|<http://arxiv.org/pdf/2509.15800v1>|提出了一种结合Temporal Apex Distillation和KeyFrame-aware G...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UniMRSeg: Unified Modality-Relax Segmentation via Hierarchical Self-Supervised Compensation|统一模态放松分割：通过层次化自监督补偿|Xiaoqi Zhao, Youwei Pang, Chenyang Yu, Lihe Zhang, Huchuan Lu, Shijian Lu, Georges El Fakhri, Xiaofeng Liu|<http://arxiv.org/pdf/2509.16170v1>|[代码](https://github.com/Xiaoqi-Zhao-DLUT/UniMRSeg.); 提出了一种统一的模态放松分割网络UniMRSeg，通过分层自监督补偿有效应对多模态图像分割中模态不完...|
|🆕 发布|MTS-DMAE: Dual-Masked Autoencoder for Unsupervised Multivariate Time Series Representation Learning|MTS-DMAE：双掩码自编码器用于无监督多变量时间序列表征学习|Yi Xu, Yitian Zhang, Yun Fu|<http://arxiv.org/pdf/2509.16078v1>|提出了一种无需依赖标签的Dual-Masked Autoencoder方法，通过重建和估计遮蔽特征学...|
|🆕 发布|FMD-TransUNet: Abdominal Multi-Organ Segmentation Based on Frequency Domain Multi-Axis Representation Learning and Dual Attention Mechanisms|基于频域多轴表示学习与双注意力机制的腹部多器官分割方法FMD-TransUNet|Fang Lu, Jingyu Xu, Qinxiu Sun, Qiong Lou|<http://arxiv.org/pdf/2509.16044v1>|提出FMD-TransUNet框架，融合频率域特征与双注意力机制，提升腹部多器官分割精度。|
|🆕 发布|A multi-temporal multi-spectral attention-augmented deep convolution neural network with contrastive learning for crop yield prediction|一种基于多时相多光谱注意力增强的深度卷积神经网络及对比学习用于作物产量预测|Shalini Dangi, Surya Karthikeya Mullapudi, Chandravardhan Singh Raghaw, Shahid Shafi Dar, Mohammad Zia Ur Rehman, Nagendra Kumar|<http://arxiv.org/pdf/2509.15966v1>|提出了一种融合多时序多光谱数据的深度卷积神经网络，通过对比学习显著提升了作物产量预测精度。|
|🆕 发布|Self-Supervised Cross-Modal Learning for Image-to-Point Cloud Registration|用于图像到点云配准的自监督跨模态学习|Xingmei Wang, Xiaoyu Hu, Chengkai Huang, Ziyan Zeng, Guohao Nie, Quan Z. Sheng, Lina Yao|<http://arxiv.org/pdf/2509.15882v1>|提出了一种自监督跨模态学习框架CrossI2P，通过双向对齐和粗到细的注册策略，有效桥接图像与点云间...|


### 跨模态一致性学习 (Cross-modal Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PCSR: Pseudo-label Consistency-Guided Sample Refinement for Noisy Correspondence Learning|伪标签一致性引导的样本精炼方法用于噪声对应学习：PCSR|Zhuoyao Liu, Yang Liu, Wentao Feng, Shudong Huang|<http://arxiv.org/pdf/2509.15623v1>|提出了一种基于伪标签一致性指导的样本优化框架，有效提升了噪声数据下的跨模态检索性能。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CrackSCF: Lightweight Cascaded Fusion Network for Robust and Efficient Structural Crack Segmentation|裂纹SCF：轻量级级联融合网络用于鲁棒且高效的结构裂纹分割|Hui Liu, Chen Jia, Fan Shi, Xu Cheng, Mianzhao Wang, Shengyong Chen|<http://arxiv.org/pdf/2408.12815v4>|提出了一种轻量级级联融合网络CrackSCF，有效整合局部纹理与像素依赖，实现高效稳健的结构裂缝分割...|
|📝 更新|Diffusion-Based Depth Inpainting for Transparent and Reflective Objects|基于扩散的透明和反射物体深度修复|Tianyu Sun, Dingchang Hu, Yixiang Dai, Guijin Wang|<http://arxiv.org/pdf/2410.08567v3>|提出DITR框架，通过扩散基于深度修复透明和反射物体的深度信息，有效解决了传统3D成像技术难题。|
|🆕 发布|Training-Free Pyramid Token Pruning for Efficient Large Vision-Language Models via Region, Token, and Instruction-Guided Importance|无训练的金字塔标记剪枝：通过区域、标记和指令引导的重要性实现高效的大规模视觉-语言模型|Yuxuan Liang, Xu Li, Xiaolei Chen, Yi Zheng, Haotian Chen, Bin Li, Xiangyang Xue|<http://arxiv.org/pdf/2509.15704v1>|提出了一种无需训练的 Pyramid Token Pruning 策略，通过区域、令牌和指令引导的重...|
|🆕 发布|GS-Scale: Unlocking Large-Scale 3D Gaussian Splatting Training via Host Offloading|GS-Scale：通过主机卸载解锁大规模3D高斯散点绘制训练|Donghyun Lee, Dawoon Jeong, Jae W. Lee, Hongil Yoon|<http://arxiv.org/pdf/2509.15645v1>|提出GS-Scale方法，通过主机卸载技术显著降低大规模3D高斯渲染训练的GPU内存需求。|
|📝 更新|RGB-Only Supervised Camera Parameter Optimization in Dynamic Scenes|动态场景中仅基于RGB的监督相机参数优化|Fang Li, Hao Zhang, Narendra Ahuja|<http://arxiv.org/pdf/2509.15123v2>|提出了一种仅使用单个RGB视频进行监督的动态场景相机参数优化方法，提高了效率和准确性。|
|🆕 发布|From Development to Deployment of AI-assisted Telehealth and Screening for Vision- and Hearing-threatening diseases in resource-constrained settings: Field Observations, Challenges and Way Forward|从开发到部署：在资源受限环境中基于人工智能辅助的远程医疗和视力及听力威胁性疾病筛查：现场观察、挑战与前进方向|Mahesh Shakya, Bijay Adhikari, Nirsara Shrestha, Bipin Koirala, Arun Adhikari, Prasanta Poudyal, Luna Mathema, Sarbagya Buddhacharya .etc.|<http://arxiv.org/pdf/2509.15558v1>|提出迭代跨学科合作方法，实现AI辅助远程医疗和筛查在资源受限环境的规模化部署。|
|🆕 发布|GUI-ARP: Enhancing Grounding with Adaptive Region Perception for GUI Agents|GUI-ARP：面向GUI智能体的自适应区域感知增强 grounding|Xianhang Ye, Yiqing Li, Wei Dai, Miancan Liu, Ziyuan Chen, Zhangye Han, Hongbo Min, Jinkui Ren .etc.|<http://arxiv.org/pdf/2509.15532v1>|提出GUI-ARP框架，通过自适应区域感知和多阶段推理，提升高分辨率屏幕截图中的细粒度定位准确性。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CoPAD : Multi-source Trajectory Fusion and Cooperative Trajectory Prediction with Anchor-oriented Decoder in V2X Scenarios|协同预测与多源轨迹融合：基于锚点导向解码器的车联网场景下轨迹预测|Kangyu Wu, Jiaqi Qiao, Ya Zhang|<http://arxiv.org/pdf/2509.15984v1>|提出了CoPAD框架，通过多源轨迹融合和协作预测，提高了V2X场景中轨迹预测的完整性和准确性。|
|🆕 发布|A PCA Based Model for Surface Reconstruction from Incomplete Point Clouds|基于主成分分析的从不完整点云中重建表面的模型|Hao Liu|<http://arxiv.org/pdf/2509.15675v1>|提出了一种基于主成分分析的模型，从Incomplete点云数据中重建表面，有效推断缺失数据区域的表面...|
|🆕 发布|Enhancing WSI-Based Survival Analysis with Report-Auxiliary Self-Distillation|基于报告辅助的自蒸馏增强的病理切片生存分析|Zheng Wang, Hong Liu, Zheng Wang, Danyi Li, Min Cen, Baptiste Magnier, Li Liang, Liansheng Wang|<http://arxiv.org/pdf/2509.15608v1>|[代码](https://github.com/zhengwang9/Rasa.); 提出了一种利用病理报告辅助的WSI生存分析框架，有效提升了预后预测的准确性和数据利用效率。|
|📝 更新|CADSpotting: Robust Panoptic Symbol Spotting on Large-Scale CAD Drawings|CAD标注检测：在大规模CAD图纸上的鲁棒全景符号标注检测|Fuyi Yang, Jiazuo Mu, Yanshun Zhang, Mingqian Zhang, Junxiong Zhang, Yongjian Luo, Lan Xu, Jingyi Yu .etc.|<http://arxiv.org/pdf/2412.07377v4>|CADSpotting通过使用3D点云模型和滑动窗口聚合技术，有效处理大型CAD图纸中的符号识别问题...|
|🆕 发布|Backdoor Mitigation via Invertible Pruning Masks|通过可逆剪枝掩码的后门缓解方法|Kealan Dunnett, Reza Arablouei, Dimity Miller, Volkan Dedeoglu, Raja Jurdak|<http://arxiv.org/pdf/2509.15497v1>|提出了一种可逆剪枝掩码方法，有效消除后门攻击同时保持模型性能。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Deep Feedback Models|深度反馈模型|David Calhas, Arlindo L. Oliveira|<http://arxiv.org/pdf/2509.15905v1>|[代码](https://github.com/DCalhas/deep_feedback_models.); 提出动态反馈模型，通过迭代优化内部状态，增强神经网络在噪声和少量数据下的鲁棒性和泛化能力。|
|🆕 发布|Camera Splatting for Continuous View Optimization|相机散点喷射法用于连续视图优化|Gahye Lee, Hyomin Kim, Gwangjin Ju, Jooeun Son, Hyejeong Yoon, Seungyong Lee|<http://arxiv.org/pdf/2509.15677v1>|提出Camera Splatting方法，通过优化3D Gaussian模型生成高质量新视角图像，改...|
|📝 更新|USCTNet: A deep unfolding nuclear-norm optimization solver for physically consistent HSI reconstruction|USCTNet：一种用于物理一致性高光谱图像重建的深度展开核范数优化求解器|Xiaoyang Ma, Yiyang Chai, Xinran Qu, Hong Sun|<http://arxiv.org/pdf/2509.10651v2>|[代码](https://github.com/psykheXX/USCTNet-Code-Implementation.git); 提出USCTNet，通过物理约束和自适应低秩子空间优化，实现了从RGB到HSI的高精度重建。|
|📝 更新|Navigate Beyond Shortcuts: Debiased Learning through the Lens of Neural Collapse|《超越捷径：通过神经崩溃视角的偏置消除学习》|Yining Wang, Junjie Sun, Chenyue Wang, Mi Zhang, Min Yang|<http://arxiv.org/pdf/2405.05587v2>|[代码](https://github.com/RachelWolowitz/Navigate-beyond-Shortcuts); 提出了一种避免捷径学习的框架，通过基于神经崩溃结构的短路素，有效提高了模型在偏置数据集上的泛化性能。|
|📝 更新|Training A Neural Network For Partially Occluded Road Sign Identification In The Context Of Autonomous Vehicles|在自动驾驶环境下针对部分遮挡交通标志识别的神经网络训练|Gulnaz Gimaletdinova, Dim Shaiakhmetov, Madina Akpaeva, Mukhammadmuso Abduzhabbarov, Kadyrmamat Momunov|<http://arxiv.org/pdf/2503.18177v3>|提出了一种专门训练的卷积神经网络，有效识别部分遮挡的路标，提高了自动驾驶的安全性。|
|🆕 发布|MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training|MEC-量化：极低比特量化感知训练的最大熵编码|Junbiao Pang, Tianyang Cai, Baochang Zhang|<http://arxiv.org/pdf/2509.15514v1>|提出了一种基于最大熵编码的量化感知训练方法MEC-Quant，有效减少量化带来的偏差，实现了极低比特...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Recovering Parametric Scenes from Very Few Time-of-Flight Pixels|从极少数飞行时间像素中恢复参数化场景|Carter Sifferman, Yiquan Li, Yiming Li, Fangzhou Mu, Michael Gleicher, Mohit Gupta, Yin Li|<http://arxiv.org/pdf/2509.16132v1>|利用低分辨率时间-of-飞行传感器少量像素，实现了简单参数化场景的几何重建。|
|🆕 发布|AdaSports-Traj: Role- and Domain-Aware Adaptation for Multi-Agent Trajectory Modeling in Sports|《AdaSports-Traj：面向体育多智能体轨迹建模的角色感知与领域自适应》|Yi Xu, Yun Fu|<http://arxiv.org/pdf/2509.16095v1>|提出了一种针对体育多智能体轨迹预测的适应性建模框架，通过角色和领域感知调整，有效解决跨角色和领域的分...|
|🆕 发布|Towards Sharper Object Boundaries in Self-Supervised Depth Estimation|面向自监督深度估计中更清晰的对象边界|Aurélien Cecille, Stefan Duffner, Franck Davoine, Rémi Agier, Thibault Neveu|<http://arxiv.org/pdf/2509.15987v1>|通过将深度估计建模为混合分布，该方法在不依赖细粒度监督的情况下显著提高了物体边界的清晰度。|
|🆕 发布|Minimal Semantic Sufficiency Meets Unsupervised Domain Generalization|最小语义充分性遇见无监督领域泛化|Tan Pan, Kaiyu Guo, Dongli Xu, Zhaorui Tan, Chen Jiang, Deshu Chen, Xin Guo, Brian C. Lovell .etc.|<http://arxiv.org/pdf/2509.15791v1>|提出了一种无需类别或领域标签的Minimal Sufficient Semantic Represe...|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Robust Vision-Language Models via Tensor Decomposition: A Defense Against Adversarial Attacks|通过张量分解的鲁棒视觉-语言模型：对抗攻击的防御策略|Het Patel, Muzammil Allie, Qian Zhang, Jia Chen, Evangelos E. Papalexakis|<http://arxiv.org/pdf/2509.16163v1>|提出了一种基于张量分解的轻量级防御方法，有效增强了视觉语言模型对对抗性攻击的鲁棒性。|
|📝 更新|AttentionDrop: A Novel Regularization Method for Transformer Models|《AttentionDrop：一种用于Transformer模型的新型正则化方法》|Mirza Samad Ahmed Baig, Syeda Anshrah Gillani, Abdul Akbar Khan, Shahid Munir Shah, Muhammad Omer Khan|<http://arxiv.org/pdf/2504.12088v2>|提出了一种针对Transformer模型的AttentionDrop正则化方法，有效减少过拟合并提升...|


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FedHK-MVFC: Federated Heat Kernel Multi-View Clustering|联邦热核多视角聚类：FedHK-MVFC|Kristina P. Sinaga|<http://arxiv.org/pdf/2509.15844v1>|提出了一种结合量子场论与联邦医疗分析的几何感知多视角聚类框架，提高了医疗数据聚类准确性和隐私保护。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Generalized Deep Multi-view Clustering via Causal Learning with Partially Aligned Cross-view Correspondence|通过因果学习与部分对齐的跨视图对应关系实现的广义深度多视图聚类|Xihong Yang, Siwei Wang, Jiaqi Jin, Fangdi Wang, Tianrui Liu, Yueming Jin, Xinwang Liu, En Zhu .etc.|<http://arxiv.org/pdf/2509.16022v1>|提出了一种基于因果学习的广义多视角聚类方法，有效处理了部分对齐数据下的聚类问题。|
|📝 更新|cadrille: Multi-modal CAD Reconstruction with Online Reinforcement Learning|“卡德里尔：基于在线强化学习的多模态CAD重建”|Maksim Kolodiazhnyi, Denis Tarasov, Dmitrii Zhemchuzhnikov, Alexander Nikulin, Ilya Zisman, Anna Vorontsova, Anton Konushin, Vladislav Kurenkov .etc.|<http://arxiv.org/pdf/2505.22914v2>|提出了一种多模态CAD重建方法，结合监督微调与在线强化学习，实现了对点云、图像和文本的全面处理并提升...|
|🆕 发布|Boosting Active Learning with Knowledge Transfer|增强主动学习中的知识迁移|Tianyang Wang, Xi Xiao, Gaofei Chen, Xiaoying Liao, Guo Cheng, Yingrui Ji|<http://arxiv.org/pdf/2509.15805v1>|利用知识迁移增强主动学习中的不确定性估计，无需特殊训练方式，适用于多种任务。|
|🆕 发布|Simulated Cortical Magnification Supports Self-Supervised Object Learning|模拟皮质放大支持自监督物体学习|Zhengyang Yu, Arthur Aubret, Chen Yu, Jochen Triesch|<http://arxiv.org/pdf/2509.15751v1>|通过模拟人类视觉的中央及周边分辨率差异，本研究提升了自监督学习模型中物体表征的质量。|
|🆕 发布|FloorSAM: SAM-Guided Floorplan Reconstruction with Semantic-Geometric Fusion|FloorSAM：基于SAM引导的语义-几何融合平面图重建|Han Ye, Haofu Wang, Yunchi Zhang, Jiangjian Xiao, Yuqiang Jin, Jinyuan Liu, Wen-An Zhang, Uladzislau Sychou .etc.|<http://arxiv.org/pdf/2509.15750v1>|[代码](https://github.com/Silentbarber/FloorSAM.); 提出 FloorSAM 方法，融合点云密度图与 Segment Anything Model，准确重...|
|📝 更新|Domain-invariant feature learning in brain MR imaging for content-based image retrieval|脑磁共振成像中的域不变特征学习用于基于内容的图像检索|Shuya Tobari, Shuhei Tomoshige, Hayato Muraki, Kenichi Oishi, Hitoshi Iyatomi|<http://arxiv.org/pdf/2501.01326v2>|提出了一种风格编码对抗域自适应方法，有效减少脑部MR图像的域差异并保持病理特征，实现高精度内容基于图...|
|📝 更新|Revealing Human Internal Attention Patterns from Gameplay Analysis for Reinforcement Learning|从游戏分析中揭示人类内部注意力模式以增强强化学习|Henrik Krauss, Takehisa Yairi|<http://arxiv.org/pdf/2504.11118v2>|提出了一种从游戏数据中揭示人类内部注意力模式的新方法，通过强化学习技术改进了学习稳定性。|
|🆕 发布|Multimodal Learning for Fake News Detection in Short Videos Using Linguistically Verified Data and Heterogeneous Modality Fusion|使用语言验证数据与异构模态融合的短视频虚假新闻检测的多模态学习|Shanghong Li, Chiam Wen Qi Ruth, Hong Xu, Fang Liu|<http://arxiv.org/pdf/2509.15578v1>|提出异构融合网络HFN，结合视频、音频和文本数据检测短视频真实性，显著提升fake news识别准确...|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation|CLIPTTA：鲁棒对比视觉-语言测试时适应|Marc Lafon, Gustavo Adolfo Vargas Hakim, Clément Rambour, Christian Desrosier, Nicolas Thome|<http://arxiv.org/pdf/2507.14312v2>|提出了一种针对视觉语言模型的梯度测试时适应方法CLIPTTA，通过软对比损失对齐预训练目标，有效应对...|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Spatial Understanding from Videos: Structured Prompts Meet Simulation Data|从视频中的空间理解：结构化提示遇见仿真数据|Haoyu Zhang, Meng Liu, Zaijing Li, Haokun Wen, Weili Guan, Yaowei Wang, Liqiang Nie|<http://arxiv.org/pdf/2506.03642v2>|提出了一种结合结构化提示和自动化构建的3D模拟数据集的方法，增强了预训练视觉语言模型的空间推理能力。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LLMs Can Compensate for Deficiencies in Visual Representations|大型语言模型能够补偿视觉表征的不足|Sho Takishita, Jay Gala, Abdelrahman Mohamed, Kentaro Inui, Yova Kementchedjhieva|<http://arxiv.org/pdf/2506.05439v2>|发现视觉表示不足时，语言解码器能显著补偿并恢复性能，提出动态分工的视觉语言模型架构。|
|🆕 发布|Towards Robust Visual Continual Learning with Multi-Prototype Supervision|面向多原型监督的鲁棒视觉持续学习|Xiwei Liu, Yulong Li, Yichen Li, Xinlin Zhuang, Haolin Yang, Huifa Li, Imran Razzak|<http://arxiv.org/pdf/2509.16011v1>|提出多原型监督框架MuproCL，通过轻量级语言模型解决视觉持续学习中语义歧义和类内多样性问题，提升...|
|📝 更新|ViLU: Learning Vision-Language Uncertainties for Failure Prediction|ViLU：学习视觉-语言不确定性以预测失败|Marc Lafon, Yannis Karmim, Julio Silva-Rodríguez, Paul Couairon, Clément Rambour, Raphaël Fournier-Sniehotta, Ismail Ben Ayed, Jose Dolz .etc.|<http://arxiv.org/pdf/2507.07620v4>|[代码](https://github.com/ykrmm/ViLU.); 提出ViLU框架，通过结合文本和视觉信息，有效预测视觉语言模型的不确定性和错误，提升失败预测准确性。|
|🆕 发布|SCENEFORGE: Enhancing 3D-text alignment with Structured Scene Compositions|SCENEFORGE：利用结构化场景组合增强三维文本对齐|Cristian Sbrolli, Matteo Matteucci|<http://arxiv.org/pdf/2509.15693v1>|提出SceneForge框架，通过构建结构化多对象场景增强3D点云与文本的对齐，大幅提升数据复杂性和...|
|🆕 发布|ORIC: Benchmarking Object Recognition in Incongruous Context for Large Vision-Language Models|ORIC：用于大型视觉语言模型的不协调场景对象识别基准测试|Zhaoyang Li, Zhan Ling, Yuchen Zhou, Hao Su|<http://arxiv.org/pdf/2509.15695v1>|提出ORIC基准，评估大型视觉语言模型在异常语境中的物体识别能力，揭示其局限性。|
|📝 更新|GRE Suite: Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains|GRE 套件：通过微调视觉-语言模型和增强推理链进行地理定位推断|Chun Wang, Xiaoran Pan, Zihao Pan, Haofan Wang, Yiren Song|<http://arxiv.org/pdf/2505.18700v3>|[代码](https://github.com/Thorin215/GRE.); 提出GRE Suite框架，结合细粒度视觉和世界知识推理链，显著提升地理定位准确性和解释性。|
|📝 更新|MolParser: End-to-end Visual Recognition of Molecule Structures in the Wild|《MolParser：野外环境中分子结构的端到端视觉识别》|Xi Fang, Jiankun Wang, Xiaochen Cai, Shangqian Chen, Shuwen Yang, Haoyi Tao, Nan Wang, Lin Yao .etc.|<http://arxiv.org/pdf/2411.11098v4>|提出了MolParser，一种端到端的化学结构识别方法，有效解析现实文档中的化学结构，大幅提升提取精...|
|🆕 发布|EyePCR: A Comprehensive Benchmark for Fine-Grained Perception, Knowledge Comprehension and Clinical Reasoning in Ophthalmic Surgery|眼PCR：眼科手术中细粒度感知、知识理解与临床推理的全面基准|Gui Wang, Yang Wennuo, Xusen Ma, Zehao Zhong, Zhuoru Wu, Ende Wu, Rong Qu, Wooi Ping Cheah .etc.|<http://arxiv.org/pdf/2509.15596v1>|提出了EyePCR大规模基准测试，评估眼外科手术中的感知、理解和推理能力，并展示了定制模型在临床认知...|
|📝 更新|Think or Not Think: A Study of Explicit Thinking in Rule-Based Visual Reinforcement Fine-Tuning|“思考或非思考：基于规则视觉强化微调中显式思维的研究”|Ming Li, Jike Zhong, Shitian Zhao, Yuxiang Lai, Haoquan Zhang, Wang Bill Zhu, Kaipeng Zhang|<http://arxiv.org/pdf/2503.16188v5>|探究显式思维在规则基础视觉强化微调中的作用，提出无需思维的微调方法并验证其有效性。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GLip: A Global-Local Integrated Progressive Framework for Robust Visual Speech Recognition|GLip：一种全局-局部集成渐进框架，用于鲁棒视觉语音识别|Tianyue Wang, Shuang Yang, Shiguang Shan, Xilin Chen|<http://arxiv.org/pdf/2509.16031v1>|提出了一种全局-局部融合的渐进式框架GLip，有效应对视觉挑战，提升唇语识别的鲁棒性。|
|🆕 发布|Saccadic Vision for Fine-Grained Visual Classification|用于细粒度视觉分类的扫视视觉|Johann Schmidt, Sebastian Stober, Joachim Denzler, Paul Bodesheim|<http://arxiv.org/pdf/2509.15688v1>|提出模拟人类扫视的细粒度视觉分类方法，通过先提取周边特征再进行注视点编码，有效降低空间冗余并提升分类...|
|📝 更新|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward|《Perception-R1：通过视觉感知奖励提升多模态语言模型的多模态推理能力》|Tong Xiao, Xin Xu, Zhenya Huang, Hongyu Gao, Quan Liu, Qi Liu, Enhong Chen|<http://arxiv.org/pdf/2506.07218v2>|提出了一种视觉感知奖励机制 Perception-R1，有效提升了多模态大语言模型的感知和推理能力。|
|📝 更新|RePIC: Reinforced Post-Training for Personalizing Multi-Modal Language Models|RePIC: 强化后训练以个性化多模态语言模型|Yeongtak Oh, Jisoo Mok, Dohyun Chung, Juhyeon Shin, Sangha Park, Johan Barthelemy, Sungroh Yoon|<http://arxiv.org/pdf/2506.18369v2>|提出了一种基于强化学习的多模态语言模型个性化后训练框架，有效提升了模型在个性化图像描述生成上的性能。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Global Regulation and Excitation via Attention Tuning for Stereo Matching|通过注意力调节实现立体匹配的全局调节与激发|Jiahao Li, Xinhong Chen, Zhengmin Jiang, Qian Zhou, Yung-Hui Li, Jianping Wang|<http://arxiv.org/pdf/2509.15891v1>|[代码](https://github.com/JarvisLee0423/GREAT-Stereo.); 提出了一种GREAT框架，通过三种注意力模块增强立体匹配算法在复杂场景下的性能。|
|🆕 发布|RACap: Relation-Aware Prompting for Lightweight Retrieval-Augmented Image Captioning|关系感知提示用于轻量级检索增强图像字幕生成|Xiaosheng Long, Hanyu Wang, Zhentao Song, Kun Luo, Hongde Liu|<http://arxiv.org/pdf/2509.15883v1>|提出了一种关系感知的轻量级图像描述方法RACap，通过挖掘检索描述中的结构化关系语义，提升了描述的语...|
|🆕 发布|Zero-Shot Visual Grounding in 3D Gaussians via View Retrieval|通过视图检索在三维高斯分布中实现零样本视觉定位|Liwei Liao, Xufeng Li, Xiaoyun Zheng, Boning Liu, Feng Gao, Ronggang Wang|<http://arxiv.org/pdf/2509.15871v1>|[代码](https://github.com/leviome/GVR_demos.); 提出了一种零样本视觉定位框架，通过视图检索将3D视觉定位转化为2D检索任务，避免了场景特定训练和大量...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Deformable Dynamic Convolution for Accurate yet Efficient Spatio-Temporal Traffic Prediction|可变形动态卷积用于精确且高效的空间时间交通预测|Hyeonseok Jin, Geonmin Kim, Kyungbaek Kim|<http://arxiv.org/pdf/2507.11550v2>|提出了一种结合可变形和动态卷积的神经网络架构，有效捕捉交通预测中的空间不规则性和时空异质性，同时降低...|
|🆕 发布|CoReVLA: A Dual-Stage End-to-End Autonomous Driving Framework for Long-Tail Scenarios via Collect-and-Refine|长尾场景下通过收集-精炼的端到端自动驾驶框架：CoReVLA|Shiyu Fang, Yiming Cui, Haoyang Liang, Chen Lv, Peng Hang, Jian Sun|<http://arxiv.org/pdf/2509.15968v1>|[代码](https://github.com/FanGShiYuu/CoReVLA); 提出CoReVLA框架，通过数据收集和行为优化双阶段提升自动驾驶在长尾场景的性能。|
|📝 更新|Semantic Change Detection of Roads and Bridges: A Fine-grained Dataset and Multimodal Frequency-driven Detector|道路和桥梁的语义变化检测：一种细粒度数据集和多模态频率驱动检测器|Qingling Shu, Sibao Chen, Xiao Wang, Zhihui You, Wei Lu, Jin Tang, Bin Luo|<http://arxiv.org/pdf/2505.13212v3>|[代码](https://github.com/DaGuangDaGuang/RB-SCD.); 提出首个针对道路和桥梁语义变化的细粒度数据集，并设计了一种融合多模态频率特征的检测框架。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RadarGaussianDet3D: An Efficient and Effective Gaussian-based 3D Detector with 4D Automotive Radars|雷达高斯检测3D：一种基于高斯的高效且有效的三维检测器，适用于四维汽车雷达|Weiyi Xiong, Bing Zhu, Tao Huang, Zewei Zheng|<http://arxiv.org/pdf/2509.16119v1>|提出了一种基于高斯分布的3D检测方法RadarGaussianDet3D，通过优化特征提取和损失函数...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ISP-AD: A Large-Scale Real-World Dataset for Advancing Industrial Anomaly Detection with Synthetic and Real Defects|ISP-AD：一种用于推进工业异常检测的大规模现实世界数据集，包含合成和真实缺陷|Paul J. Krassnig, Dieter P. Gruber|<http://arxiv.org/pdf/2503.04997v3>|提出了ISP-AD数据集，结合合成与真实缺陷，提升工业异常检测的泛化能力。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SLaM-DiMM: Shared Latent Modeling for Diffusion Based Missing Modality Synthesis in MRI|基于共享潜在建模的扩散缺失模态合成在MRI中的应用|Bhavesh Sandbhor, Bheeshm Sharma, Balamurugan Palaniappan|<http://arxiv.org/pdf/2509.16019v1>|[代码](https://github.com/BheeshmSharma/SLaM-DiMM-MICCAI-BraTS-Challenge-2025.); 提出了一种基于扩散模型的新框架，用于从可用MRI模态生成缺失模态，确保了图像的高保真度和结构一致性。|
|📝 更新|A re-calibration method for object detection with multi-modal alignment bias in autonomous driving|一种针对自动驾驶中多模态对齐偏差的目标检测重校准方法|Zhihang Song, Dingyi Yao, Ruibo Ming, Lihui Peng, Danya Yao, Yi Zhang|<http://arxiv.org/pdf/2405.16848v3>|提出了一种重新校准模型，通过融合多模态数据应对自动驾驶中校准偏差，提高了对象检测的鲁棒性和准确性。|
|🆕 发布|The Missing Piece: A Case for Pre-Training in 3D Medical Object Detection|缺失的一环：三维医学目标检测中预训练的应用探究|Katharina Eckstein, Constantin Ulrich, Michael Baumgartner, Jessica Kächele, Dimitrios Bounias, Tassilo Wald, Ralf Floca, Klaus H. Maier-Hein|<http://arxiv.org/pdf/2509.15947v1>|[代码](https://github.com/MIC-DKFZ/nnDetection-finetuning.); 首次系统研究将预训练方法融入3D医疗对象检测，证实了预训练能显著提升检测性能。|
|🆕 发布|LC-SLab -- An Object-based Deep Learning Framework for Large-scale Land Cover Classification from Satellite Imagery and Sparse In-situ Labels|LC-SLab -- 面向卫星影像大规模土地覆盖分类的对象基础深度学习框架及稀疏现场标签|Johannes Leonhardt, Juergen Gall, Ribana Roscher|<http://arxiv.org/pdf/2509.15868v1>|提出LC-SLab框架，利用对象级分类提升稀疏标注卫星图像的大规模土地覆盖分类准确性和连贯性。|
|📝 更新|Examining Deployment and Refinement of the VIOLA-AI Intracranial Hemorrhage Model Using an Interactive NeoMedSys Platform|探究VIOLA-AI颅内出血模型在Interactive NeoMedSys平台上的部署与优化|Qinghui Liu, Jon E. Nesvold, Hanna Raaum, Elakkyen Murugesu, Martin Røvang, Bradley J Maclntosh, Atle Bjørnerud, Karoline Skogen|<http://arxiv.org/pdf/2505.09380v2>|本研究通过交互式NeoMedSys平台实现了VIOLA-AI模型的快速部署和迭代优化，显著提升了脑出...|
|🆕 发布|QWD-GAN: Quality-aware Wavelet-driven GAN for Unsupervised Medical Microscopy Images Denoising|QWD-GAN：质量感知的小波驱动生成对抗网络用于无监督医学显微图像去噪|Qijun Yang, Yating Huang, Lintao Xiang, Hujun Yin|<http://arxiv.org/pdf/2509.15814v1>|提出了一种基于小波变换和生成对抗网络的医学显微图像去噪方法，实现了细节保留和高效处理。|
|📝 更新|RegionMed-CLIP: A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding|区域感知的多模态对比学习预训练模型RegionMed-CLIP用于医学图像理解|Tianchen Fang, Guiru Liu|<http://arxiv.org/pdf/2508.05244v2>|提出了一种区域感知的多模态对比学习模型RegionMed-CLIP，有效融合局部病理性信号和全局语义...|
|🆕 发布|CBPNet: A Continual Backpropagation Prompt Network for Alleviating Plasticity Loss on Edge Devices|CBPNet：一种用于边缘设备减轻塑性损失的不断传播提示网络|Runjie Shao, Boyu Diao, Zijia An, Ruiqi Liu, Yongjun Xu|<http://arxiv.org/pdf/2509.15785v1>|CBPNet通过自适应重置未充分利用参数，有效缓解边缘设备持续学习中的塑性损失问题。|
|🆕 发布|Toward Medical Deepfake Detection: A Comprehensive Dataset and Novel Method|面向医疗深度伪造检测：一个全面的数据库与新颖方法|Shuaibo Li, Zhaohu Xing, Hongqiu Wang, Pengfei Hao, Xingyu Li, Zekai Liu, Lei Zhu|<http://arxiv.org/pdf/2509.15711v1>|提出了MedForensics大规模医疗图像数据集和DSKI检测器，有效识别AI生成的医疗图像。|
|📝 更新|Temperature-Driven Robust Disease Detection in Brain and Gastrointestinal Disorders via Context-Aware Adaptive Knowledge Distillation|基于温度驱动的脑部及胃肠道疾病稳健检测：通过上下文感知的自适应知识蒸馏|Saif Ur Rehman Khan, Muhammad Nabeel Asim, Sebastian Vollmer, Andreas Dengel|<http://arxiv.org/pdf/2505.06381v2>|提出了一种自适应温度调节的知识蒸馏框架，结合蚁群优化算法，有效提升了医学影像疾病检测的准确性和鲁棒性...|
|🆕 发布|pFedSAM: Personalized Federated Learning of Segment Anything Model for Medical Image Segmentation|个性化联邦学习分割任意模型(pFedSAM)用于医学图像分割|Tong Wang, Xingyue Zhao, Linghao Zhuang, Haoyu Zhao, Jiayi Yin, Yuyang He, Gang Yu, Bo Lin|<http://arxiv.org/pdf/2509.15638v1>|首次提出针对医学图像分割的个性化联邦学习框架，通过聚合全局参数和局部特性优化分割性能。|
|📝 更新|DAOcc: 3D Object Detection Assisted Multi-Sensor Fusion for 3D Occupancy Prediction|DAOcc：三维目标检测辅助的多传感器融合用于三维占据预测|Zhen Yang, Yanpeng Dong, Jiayu Wang, Heng Wang, Lichao Ma, Zijian Cui, Qi Liu, Haoran Pei .etc.|<http://arxiv.org/pdf/2409.19972v4>|[代码](https://github.com/AlphaPlusTT/DAOcc.); 提出了一种利用3D物体检测辅助的多传感器融合框架，实现了高效准确的3D占用预测。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FoBa: A Foreground-Background co-Guided Method and New Benchmark for Remote Sensing Semantic Change Detection|FoBa：一种前景-背景协同引导方法及遥感语义变化检测新基准|Haotian Zhang, Han Guo, Keyan Chen, Hao Chen, Zhengxia Zou, Zhenwei Shi|<http://arxiv.org/pdf/2509.15788v1>|[代码](https://github.com/zmoka-zht/FoBa.); 提出了一种前景-背景协同引导的遥感语义变化检测方法，构建了包含丰富变化类型的新数据集，提升了模型检测...|
|📝 更新|Quality-Driven Curation of Remote Sensing Vision-Language Data via Learned Scoring Models|通过学习评分模型驱动的遥感视觉-语言数据精选质量|Dilxat Muhtar, Enzhuo Zhang, Zhenshi Li, Feng Gu, Yanglangxing He, Pengfeng Xiao, Xueliang Zhang|<http://arxiv.org/pdf/2503.00743v2>|提出了一种基于大规模遥感图像文本偏好的评分模型，自动评估遥感视觉语言数据质量，提升了模型性能。|
|🆕 发布|DC-Mamba: Bi-temporal deformable alignment and scale-sparse enhancement for remote sensing change detection|DC-Mamba：双时相可变形对齐与尺度稀疏增强用于遥感变化检测|Min Sun, Fenghui Guo|<http://arxiv.org/pdf/2509.15563v1>|提出“对齐-增强”框架DC-Mamba，通过几何感知对齐和信号增强显著提升遥感变化检测准确度。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Fast OTSU Thresholding Using Bisection Method|使用二分法快速实现OTSU阈值分割|Sai Varun Kodathala|<http://arxiv.org/pdf/2509.16179v1>|利用二分法优化Otsu阈值算法，大幅降低计算复杂度，保持分割精度。|
|🆕 发布|DAFTED: Decoupled Asymmetric Fusion of Tabular and Echocardiographic Data for Cardiac Hypertension Diagnosis|解耦对称融合表格与超声心动图数据用于心脏高血压诊断的DAFTED方法|Jérémie Stym-Popper, Nathan Painchaud, Clément Rambour, Pierre-Yves Courand, Nicolas Thome, Olivier Bernard|<http://arxiv.org/pdf/2509.15990v1>|提出了一种不对称融合策略，通过分离共享信息和模态特定信息，显著提升了对心脏高血压的诊断准确率。|
|📝 更新|FOVAL: Calibration-Free and Subject-Invariant Fixation Depth Estimation Across Diverse Eye-Tracking Datasets|FOVAL：无需校准且不受被测者影响的多样化眼动数据集上的注视深度估计|Benedikt W. Hosp|<http://arxiv.org/pdf/2408.03591v2>|提出了一种无需校准的稳健方法FOVAL，通过时空序列建模和跨用户特征标准化，实现了高精度且普适的注视...|

