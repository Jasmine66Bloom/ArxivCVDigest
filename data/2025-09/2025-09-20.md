## [UPDATED!] **2025-09-20** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Pain in 3D: Generating Controllable Synthetic Faces for Automated Pain Assessment|《三维疼痛：生成可控合成面部用于自动疼痛评估》|Xin Lei Lin, Soroush Mehraban, Abhishek Moturu, Babak Taati|<http://arxiv.org/pdf/2509.16727v1>|提出3DPain数据集和ViTPain框架，为自动化疼痛评估提供可控、多样、符合临床需求的基础。|
|🆕 发布|Enhancing Scientific Visual Question Answering via Vision-Caption aware Supervised Fine-Tuning|通过视觉-字幕感知的监督微调增强科学视觉问答|Janak Kapuriya, Anwar Shaikh, Arnav Goel, Medha Hira, Apoorv Singh, Jay Saraf, Sanjana, Vaibhav Nauriyal .etc.|<http://arxiv.org/pdf/2509.16628v1>|提出VCASFT方法，通过利用图像标题和指令微调提升小规模视觉语言模型在科学视觉问答任务上的性能。|
|🆕 发布|PM25Vision: A Large-Scale Benchmark Dataset for Visual Estimation of Air Quality|PM25Vision：用于空气质量视觉估计的大规模基准数据集|Yang Han|<http://arxiv.org/pdf/2509.16519v1>|构建了首个大规模街景图像与PM2.5浓度数据集，提升空气质量视觉估算精度。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ViLReF: An Expert Knowledge Enabled Vision-Language Retinal Foundation Model|ViLReF：一种启用专家知识的视觉-语言视网膜基础模型|Shengzhu Yang, Jiawei Du, Jia Guo, Weihang Zhang, Hanruo Liu, Huiqi Li, Ningli Wang|<http://arxiv.org/pdf/2408.10894v4>|[代码](https://github.com/T6Yang/ViLReF.); 提出ViLReF模型，利用专家知识优化视觉语言预训练，动态调整样本特征空间距离，提升视网膜图像诊断模...|
|📝 更新|Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding|进化-0：具有隐式空间理解的视觉-语言-动作模型|Tao Lin, Gen Li, Yilei Zhong, Yanwen Zou, Yuxin Du, Jiting Liu, Encheng Gu, Bo Zhao|<http://arxiv.org/pdf/2507.00416v2>|引入插件式模块，将三维几何特征隐式融入视觉语言动作模型，增强对场景几何结构和物体空间关系的理解能力。|
|🆕 发布|Detection and Simulation of Urban Heat Islands Using a Fine-Tuned Geospatial Foundation Model|利用微调地理空间基础模型检测与模拟城市热岛效应|David Kreismann|<http://arxiv.org/pdf/2509.16617v1>|利用细化的地理空间基础模型预测城市热岛效应，实现了高精度地表温度预测。|
|🆕 发布|Surgical-MambaLLM: Mamba2-enhanced Multimodal Large Language Model for VQLA in Robotic Surgery|手术-MambaLLM：Mamba2增强的多模态大型语言模型，用于机器人手术中的视觉查询语言解析与理解|Pengfei Hao, Hongqiu Wang, Shuaibo Li, Zhaohu Xing, Guang Yang, Kaishun Wu, Lei Zhu|<http://arxiv.org/pdf/2509.16618v1>|提出Surgical-MambaLLM模型，结合Mamba2与大型语言模型，提升机器人手术场景下的视...|
|🆕 发布|When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs|当大型模型训练小型模型：使用小型语言模型进行高效视觉问答的无标签模型一致性对齐|Abhirama Subramanyam Penamakuri, Navlika Singh, Piyush Arora, Anand Mishra|<http://arxiv.org/pdf/2509.16633v1>|提出了一种无标签模型对齐框架，通过利用大模型知识提升小模型性能，有效缩小了视觉问答任务中的性能差距。|
|📝 更新|FC-Attack: Jailbreaking Multimodal Large Language Models via Auto-Generated Flowcharts|FC-Attack：通过自动生成的流程图破解多模态大型语言模型|Ziyi Zhang, Zhen Sun, Zongmin Zhang, Jihui Guo, Xinlei He|<http://arxiv.org/pdf/2502.21059v3>|提出了一种利用自动生成流程图的攻击方法FC-Attack，有效突破多模态大语言模型的安全限制。|
|📝 更新|Block-Fused Attention-Driven Adaptively-Pooled ResNet Model for Improved Cervical Cancer Classification|基于块融合注意力驱动的自适应池化残差网络模型用于改进宫颈癌分类|Saurabh Saini, Kapil Ahuja, Akshat S. Chauhan|<http://arxiv.org/pdf/2405.01600v3>|提出了一种融合双级别特征提取、注意力机制和自适应池化的ResNet模型，显著提升了宫颈癌分类准确率。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Multimodal and Multi-centric Head and Neck Cancer Dataset for Segmentation, Diagnosis and Outcome Prediction|多模态和多中心头颈癌数据集用于分割、诊断和预后预测|Numan Saeed, Salma Hassan, Shahad Hardan, Ahmed Aly, Darya Taratynova, Umair Nawaz, Ufaq Khan, Muhammad Ridzuan .etc.|<http://arxiv.org/pdf/2509.00367v3>|构建了一个多模态、多中心的头颈癌数据集，用于肿瘤分割、诊断和预后预测。|
|🆕 发布|Lattice Boltzmann Model for Learning Real-World Pixel Dynamicity|学习现实世界像素动态性的格子玻尔兹曼模型|Guangze Zheng, Shijie Lin, Haobo Zuo, Si Si, Ming-Shan Wang, Changhong Fu, Jia Pan|<http://arxiv.org/pdf/2509.16527v1>|提出Lattice Boltzmann Model学习像素动态性，实现高效实时视觉跟踪。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Artificial Satellite Trails Detection Using U-Net Deep Neural Network and Line Segment Detector Algorithm|使用U-Net深度神经网络和线段检测算法的人工卫星轨迹检测|Xiaohan Chen, Hongrui Gu, Cunshi Wang, Haiyang Mu, Jie Zheng, Junju Du, Jing Ren, Zhou Fan .etc.|<http://arxiv.org/pdf/2509.16771v1>|提出了一种结合U-Net神经网络和线段检测算法的卫星轨迹检测模型，有效提高了观测数据中卫星轨迹的识别...|
|📝 更新|SWA-PF: Semantic-Weighted Adaptive Particle Filter for Memory-Efficient 4-DoF UAV Localization in GNSS-Denied Environments|SWA-PF：面向GNSS拒止环境下内存高效四自由度无人机定位的语义加权自适应粒子滤波器|Jiayu Yuan, Ming Dai, Enhui Zheng, Chao Su, Nanxing Chen, Qiming Hu, Shibo Zhu, Yibin Cao|<http://arxiv.org/pdf/2509.13795v2>|[代码](https://github.com/YuanJiayuuu/SWA-PF.); 提出了一种结合语义特征和优化粒子滤波器的SWA-PF方法，实现了GNSS拒止环境下高效准确的无人机定...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|When Confidence Fails: Revisiting Pseudo-Label Selection in Semi-supervised Semantic Segmentation|当置信度失效：重新审视半监督语义分割中的伪标签选择|Pan Liu, Jinshi Liu|<http://arxiv.org/pdf/2509.16704v1>|[代码](https://github.com/PanLiuCSU/CSL.); 提出了一种新的半监督语义分割方法，通过优化伪标签选择，有效解决了网络过自信和上下文信息丢失问题。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Automatic Real-time Vehicle Classification by Image Colour Component Based Template Matching|基于图像颜色分量模板匹配的实时车辆自动分类|Ahmet Orun|<http://arxiv.org/pdf/2210.06586v3>|提出了一种基于图像颜色分量选择的高效模板匹配算法，实现了在低成本硬件上的实时车辆分类。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CommonForms: A Large, Diverse Dataset for Form Field Detection|常见表单：一个用于表单字段检测的大型多样化数据集|Joe Barrow|<http://arxiv.org/pdf/2509.16506v1>|[代码](https://github.com/jbarrow/commonforms); 介绍了CommonForms大规模多样化表单字段检测数据集，并提出了高效的FFDNet模型。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|L2M-Reg: Building-level Uncertainty-aware Registration of Outdoor LiDAR Point Clouds and Semantic 3D City Models|L2M-Reg：面向建筑级别的室外激光雷达点云与语义三维城市模型的不确定性感知配准|Ziyang Xu, Benedikt Schwab, Yihui Yang, Thomas H. Kolbe, Christoph Holst|<http://arxiv.org/pdf/2509.16832v1>|提出了一种考虑模型不确定性的平面基精细配准方法L2M-Reg，显著提升了室外激光雷达点云与语义三维城...|
|📝 更新|Survey of Video Diffusion Models: Foundations, Implementations, and Applications|视频扩散模型综述：基础、实现与应用|Yimu Wang, Xuye Liu, Wei Pang, Li Ma, Shuai Yuan, Paul Debevec, Ning Yu|<http://arxiv.org/pdf/2504.16081v2>|[代码](https://github.com/Eyeline-Research/Survey-Video-Diffusion.); 系统梳理了视频扩散模型的发展、技术基础和应用，为相关领域研究提供了全面更新的资源。|
|📝 更新|QVGen: Pushing the Limit of Quantized Video Generative Models|QVGen：推动量化视频生成模型极限|Yushi Huang, Ruihao Gong, Jing Liu, Yifu Ding, Chengtao Lv, Haotong Qin, Jun Zhang|<http://arxiv.org/pdf/2505.11497v3>|提出了一种针对极低比特量化的视频生成模型的高性能量化感知训练框架，实现了与全精度相当的质量。|
|🆕 发布|HyPlaneHead: Rethinking Tri-plane-like Representations in Full-Head Image Synthesis|《HyPlaneHead：在全身图像合成中重新思考三平面类表示》|Heyuan Li, Kenkun Liu, Lingteng Qiu, Qi Zuo, Keru Zheng, Zilong Dong, Xiaoguang Han|<http://arxiv.org/pdf/2509.16748v1>|提出了一种结合平面与球面优势的混合平面表示方法，有效解决了特征纠缠和渗透问题，实现了全头部图像合成的...|
|🆕 发布|FitPro: A Zero-Shot Framework for Interactive Text-based Pedestrian Retrieval in Open World|FitPro：面向开放世界的基于文本的交互式行人检索零样本框架|Zengli Luo, Canlong Zhang, Xiaochun Lu, Zhixin Li|<http://arxiv.org/pdf/2509.16674v1>|提出FitPro框架，通过增强语义理解和跨场景适应性，解决了开放世界交互式文本行人检索中的泛化限制和...|
|📝 更新|Optimal Transport for Rectified Flow Image Editing: Unifying Inversion-Based and Direct Methods|最优传输用于修正流图像编辑：统一基于逆变换和直接方法|Marian Lupascu, Mihai-Sorin Stupariu|<http://arxiv.org/pdf/2508.02363v2>|[代码](https://github.com/marianlupascu/OT-RF); 利用最优传输理论统一改进了矩形流编辑中的重建保真度和编辑灵活性。|
|🆕 发布|ADVEDM:Fine-grained Adversarial Attack against VLM-based Embodied Agents|ADVEDM：针对基于VLM的具身智能体的细粒度对抗攻击|Yichen Wang, Hangtao Zhang, Hewen Pan, Ziqi Zhou, Xianlong Wang, Peijin Guo, Lulu Xue, Shengshan Hu .etc.|<http://arxiv.org/pdf/2509.16645v1>|提出了一种细粒度对抗攻击框架ADVEDM，通过修改视觉语言模型对关键对象的感知，实现了对物理世界决策...|
|🆕 发布|Describe-to-Score: Text-Guided Efficient Image Complexity Assessment|描述评分：基于文本引导的高效图像复杂性评估|Shipeng Liu, Zhonglin Zhang, Dengfeng Chen, Liang Zhao|<http://arxiv.org/pdf/2509.16609v1>|[代码](https://github.com/xauat-liushipeng/D2S); 提出了一种融合视觉与文本语义特征的图像复杂性评估框架，提高了评估准确性和泛化能力。|
|📝 更新|Ensemble YOLO Framework for Multi-Domain Mitotic Figure Detection in Histopathology Images|多域融合的YOLO框架用于病理图像中的有丝分裂图像检测|Navya Sri Kelam, Akash Parekh, Saikiran Bonthu, Nitin Singhal|<http://arxiv.org/pdf/2509.02957v2>|提出了一种结合YOLOv5和YOLOv8的集成框架，有效提升了病理图像中分裂像的检测准确性和泛化能力...|
|📝 更新|DynFaceRestore: Balancing Fidelity and Quality in Diffusion-Guided Blind Face Restoration with Dynamic Blur-Level Mapping and Guidance|DynFaceRestore：在扩散引导的盲目人脸修复中平衡保真度和质量，采用动态模糊级别映射和引导|Huu-Phu Do, Yu-Wei Chen, Yi-Cheng Liao, Chi-Wei Hsiao, Han-Yang Wang, Wei-Chen Chiu, Ching-Chun Huang|<http://arxiv.org/pdf/2507.13797v2>|[代码](https://nycu-acm.github.io/DynFaceRestore); DynFaceRestore通过动态调整模糊级别和指导策略，有效平衡了盲人脸修复中的保真度和质量。|
|📝 更新|How Much Do Large Language Models Know about Human Motion? A Case Study in 3D Avatar Control|大型语言模型对人类运动了解多少？——以3D虚拟人控制为案例研究|Kunhang Li, Jason Naradowsky, Yansong Feng, Yusuke Miyao|<http://arxiv.org/pdf/2505.21531v2>|探究大型语言模型对人类运动的认知，通过3D角色控制评估其在高级行动规划和精确身体定位的能力。|
|🆕 发布|Efficient Rectified Flow for Image Fusion|高效矫正流用于图像融合|Zirui Wang, Jiayi Zhang, Tianwei Guan, Yuhan Zhou, Xingyuan Li, Minjing Dong, Jinyuan Liu|<http://arxiv.org/pdf/2509.16549v1>|[代码](https://github.com/zirui0625/RFfusion.); 提出了一种基于Rectified Flow的高效一步扩散模型RFfusion，用于图像融合，大幅提升...|
|🆕 发布|FG-Attn: Leveraging Fine-Grained Sparsity In Diffusion Transformers|FG-Attn: 利用细粒度稀疏性在扩散变换器中|Sankeerth Durvasula, Kavya Sreedhar, Zain Moustafa, Suraj Kothawade, Ashish Gondimalla, Suvinay Subramanian, Narges Shahidi, Nandita Vijaykumar|<http://arxiv.org/pdf/2509.16518v1>|提出了一种细粒度稀疏注意力机制FG-Attn，有效提升视频生成速度并减少计算量。|
|📝 更新|Side Effects of Erasing Concepts from Diffusion Models|《从扩散模型中擦除概念的副作用》|Shaswati Saha, Sourajit Saha, Manas Gaur, Tejas Gokhale|<http://arxiv.org/pdf/2508.15124v3>|揭示了概念擦除技术在扩散模型中的副作用，并提出了用于评估其鲁棒性的Side Effect Evalu...|
|🆕 发布|Thermal Imaging-based Real-time Fall Detection using Motion Flow and Attention-enhanced Convolutional Recurrent Architecture|基于热成像的运动流与注意力增强卷积循环架构的实时跌倒检测|Christopher Silver, Thangarajah Akilan|<http://arxiv.org/pdf/2509.16479v1>|提出了一种基于热成像和双向卷积长短时记忆网络的实时跌倒检测方法，实现了高准确性和隐私保护。|
|🆕 发布|OS-DiffVSR: Towards One-step Latent Diffusion Model for High-detailed Real-world Video Super-Resolution|面向一步潜在扩散模型的高细节真实世界视频超分辨率：OS-DiffVSR|Hanting Li, Huaao Tang, Jianhong Han, Tianxiong Zhou, Jiulong Cui, Haizhen Xie, Yan Chen, Jie Hu|<http://arxiv.org/pdf/2509.16507v1>|提出了一种单步扩散模型OS-DiffVSR，通过相邻帧对抗训练和多帧融合机制，实现了高质量视频超分辨...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DiffEye: Diffusion-Based Continuous Eye-Tracking Data Generation Conditioned on Natural Images|DiffEye：基于扩散的自然图像条件下连续眼动数据生成|Ozgur Kara, Harris Nisar, James M. Rehg|<http://arxiv.org/pdf/2509.16767v1>|DiffEye利用扩散模型和对应位置嵌入技术，首次实现了对自然图像连续且多样化的眼动轨迹的生成。|
|🆕 发布|MMPart: Harnessing Multi-Modal Large Language Models for Part-Aware 3D Generation|多模态大语言模型驱动下的部件感知三维生成：MMPart|Omid Bonakdar, Nasser Mozayani|<http://arxiv.org/pdf/2509.16768v1>|提出了一种基于多模态大语言模型的框架MMPart，实现了从单张图片生成具有结构信息的部分感知3D模型...|
|📝 更新|In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer|《上下文编辑：利用大规模扩散变换器中的上下文生成实现指导性图像编辑》|Zechuan Zhang, Ji Xie, Yu Lu, Zongxin Yang, Yi Yang|<http://arxiv.org/pdf/2504.20690v2>|[代码](https://river-zhang.github.io/ICEdit-gh-pages); 提出了一种高效精确的指令式图像编辑方法ICEdit，通过少量数据和参数实现优异性能。|
|🆕 发布|Animalbooth: multimodal feature enhancement for animal subject personalization|动物 Booth：动物主体个性化中的多模态特征增强|Chen Liu, Haitao Wu, Kafeng Wang, Xiaowang Zhang|<http://arxiv.org/pdf/2509.16702v1>|AnimalBooth通过增强身份保持和频率控制的特征融合，有效解决了动物个性化图像生成中的身份漂移...|
|🆕 发布|InstanceAssemble: Layout-Aware Image Generation via Instance Assembling Attention|实例组装：通过实例组装注意力实现布局感知的图像生成|Qiang Xiang, Shuang Sun, Binglei Li, Dejia Song, Huaxia Li, Nemo Chen, Xu Tang, Yao Hu .etc.|<http://arxiv.org/pdf/2509.16691v1>|提出InstanceAssemble方法，通过实例组装注意力实现布局感知的图像生成，提升复杂布局下的...|
|📝 更新|VisText-Mosquito: A Unified Multimodal Benchmark Dataset for Visual Detection, Segmentation, and Textual Reasoning on Mosquito Breeding Sites|"VisText-蚊子：一个用于蚊子孳生地点视觉检测、分割和文本推理的统一多模态基准数据集"|Md. Adnanul Islam, Md. Faiyaz Abdullah Sayeedi, Md. Asaduzzaman Shuvo, Shahanur Rahman Bappy, Md Asiful Islam, Swakkhar Shatabda|<http://arxiv.org/pdf/2506.14629v2>|[代码](https://github.com/adnanul-islam-jisun/VisText-Mosquito); 提出了VisText-Mosquito多模态数据集，融合视觉与文本数据，提升蚊虫孳生地检测与推理准确...|
|🆕 发布|Towards Anytime Retrieval: A Benchmark for Anytime Person Re-Identification|面向实时检索：实时行人重识别基准|Xulin Li, Yan Lu, Bin Liu, Jiaze Li, Qinhong Yang, Tao Gong, Qi Chu, Mang Ye .etc.|<http://arxiv.org/pdf/2509.16635v1>|提出Anytime Person Re-identification任务，构建大规模AT-USTC数...|
|🆕 发布|Follow-Your-Emoji-Faster: Towards Efficient, Fine-Controllable, and Expressive Freestyle Portrait Animation|《跟随你的表情，更快速：迈向高效、精细可控、表现力强的自由风格肖像动画》|Yue Ma, Zexuan Yan, Hongyu Liu, Hongfa Wang, Heng Pan, Yingqing He, Junkun Yuan, Ailing Zeng .etc.|<http://arxiv.org/pdf/2509.16630v1>|[代码](https://follow-your-emoji.github.io/.); 提出了一种高效、精细可控、表现力强的自由风格肖像动画框架，通过表情感知地标和渐进生成策略实现稳定的长...|
|🆕 发布|FakeChain: Exposing Shallow Cues in Multi-Step Deepfake Detection|伪造链：揭示多步骤深度伪造检测中的浅层线索|Minji Heo, Simon S. Woo|<http://arxiv.org/pdf/2509.16602v1>|[代码](https://github.com/minjihh/FakeChain); 揭示了多步骤深伪检测中现有模型对最终操作类型的高度依赖，提出大型基准数据集FakeChain以促进对...|
|🆕 发布|Captioning for Text-Video Retrieval via Dual-Group Direct Preference Optimization|通过双组直接偏好优化进行文本-视频检索的标注|Ji Soo Lee, Byungoh Ko, Jaewon Cho, Howoong Lee, Jaewoon Byun, Hyunwoo J. Kim|<http://arxiv.org/pdf/2509.16560v1>|[代码](https://github.com/mlvlab/CaReDPO.); 提出了一种优化视频检索的框架CaRe-DPO，通过直接优化检索相关性的标题生成，提高了辅助标题的区分...|
|🆕 发布|ViTCAE: ViT-based Class-conditioned Autoencoder|Autoencoder基于ViT的类条件自动编码器|Vahid Jebraeeli, Hamid Krim, Derya Cansever|<http://arxiv.org/pdf/2509.16554v1>|ViTCAE通过将Class token转化为生成关键点并引入自适应注意力机制，提升了Transfo...|
|🆕 发布|V-CECE: Visual Counterfactual Explanations via Conceptual Edits|V-CECE：通过概念编辑的视觉反事实解释|Nikolaos Spanos, Maria Lymperaiou, Giorgos Filandrianos, Konstantinos Thomas, Athanasios Voulodimos, Giorgos Stamou|<http://arxiv.org/pdf/2509.16567v1>|提出了一种无需训练的可视化反事实生成框架，通过基于理论保证的逐步编辑，生成接近人类水平的解释。|
|📝 更新|Uni3C: Unifying Precisely 3D-Enhanced Camera and Human Motion Controls for Video Generation|统一精确的三维增强相机与人体运动控制视频生成方法 Uni3C|Chenjie Cao, Jingkai Zhou, Shikai Li, Jingyun Liang, Chaohui Yu, Fan Wang, Xiangyang Xue, Yanwei Fu|<http://arxiv.org/pdf/2504.14899v2>|Uni3C统一了3D增强的相机和人体运动控制，提高了视频生成的精确度和质量。|
|🆕 发布|Octree Latent Diffusion for Semantic 3D Scene Generation and Completion|八叉树潜在扩散用于语义三维场景生成与补全|Xujia Zhang, Brendan Crowe, Christoffer Heckman|<http://arxiv.org/pdf/2509.16483v1>|提出了一种统一的3D场景生成与完善框架，通过 octree 结构和语义扩散实现跨领域的高质量场景重建...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Text-Scene: A Scene-to-Language Parsing Framework for 3D Scene Understanding|文本-场景：用于三维场景理解的场景到语言解析框架|Haoyuan Li, Rui Liu, Hehe Fan, Yi Yang|<http://arxiv.org/pdf/2509.16721v1>|提出Text-Scene框架，自动将3D场景解析为文本描述，无需人工干预，实现3D场景理解与语言的桥...|
|📝 更新|DCA: Graph-Guided Deep Embedding Clustering for Brain Atlases|DCA：基于图引导的深度嵌入聚类用于脑图谱构建|Mo Wang, Kaining Peng, Jingsheng Tang, Hongkai Wen, Quanying Liu|<http://arxiv.org/pdf/2509.01426v2>|[代码](https://github.com/ncclab-sustech/DCA); 提出了一种个性化的脑图谱生成方法DCA，通过深度聚类和图引导，提高了脑图谱的功能同质性和空间连续性。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DA-Font: Few-Shot Font Generation via Dual-Attention Hybrid Integration|DA-Font：通过双注意力混合集成实现的少样本字体生成|Weiran Chen, Guiqian Zhu, Ying Li, Yi Ji, Chunping Liu|<http://arxiv.org/pdf/2509.16632v1>|[代码](https://github.com/wrchen2001/DA-Font); DA-Font通过引入双注意力混合模块，有效解决了少量样本字体生成中的缺陷问题，提高了字符形状准确性...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SOLAR: Switchable Output Layer for Accuracy and Robustness in Once-for-All Training|"SOLAR:面向一次性训练中准确性与鲁棒性的可切换输出层"|Shaharyar Ahmed Khan Tareen, Lei Fan, Xiaojing Yuan, Qin Lin, Bin Hu|<http://arxiv.org/pdf/2509.16833v1>|提出SOLAR方法，为每个子网分配独立分类头，减少参数共享带来的干扰，提升准确性和鲁棒性。|
|📝 更新|UniSkill: Imitating Human Videos via Cross-Embodiment Skill Representations|《UniSkill：通过跨载体技能表征模仿人类视频》|Hanjung Kim, Jaehyun Kang, Hyolim Kang, Meedeum Cho, Seon Joo Kim, Youngwoon Lee|<http://arxiv.org/pdf/2505.08787v4>|[代码](https://kimhanjung.github.io/UniSkill.); 提出UniSkill框架，从大规模跨载体视频数据中学习通用技能表示，实现人类视频技能到机器人行为的有...|
|📝 更新|Wavelet-Space Representations for Neural Super-Resolution in Rendering Pipelines|基于小波空间的神经超分辨率在渲染管线中的表示|Prateek Poudel, Prashant Aryal, Kirtan Kunwar, Navin Nepal, Dinesh Baniya Kshatri|<http://arxiv.org/pdf/2508.16024v3>|利用静止小波变换在频域分解特征，提出了一种神经超分辨率方法，提高了渲染管线中的图像清晰度和质量。|
|📝 更新|Multi-viewregulated gaussian splatting for novel view synthesis|多视角调控高斯散点绘制法用于新视角合成|Xiaobiao Du, Yida Wang, Xin Yu|<http://arxiv.org/pdf/2410.02103v2>|引入多视角训练策略和细化方法，提升三维高斯分布渲染精度和新型视角合成质量。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Active View Selection for Scene-level Multi-view Crowd Counting and Localization with Limited Labels|有限标签下的场景级多视角人群计数与定位的主动视图选择|Qi Zhang, Bin Li, Antoni B. Chan, Hui Huang|<http://arxiv.org/pdf/2509.16684v1>|提出了一种考虑场景几何的主动视图选择方法，实现了在有限标注下跨场景的多视角人群计数与定位。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Revisiting Speech-Lip Alignment: A Phoneme-Aware Speech Encoder for Robust Talking Head Synthesis|重新审视语音-唇部对齐：一种基于音素的语音编码器用于稳健的说话人头合成|Yihuan Huang, Jiajun Liu, Yanzhen Ren, Wuyang Liu, Zongkun Sun|<http://arxiv.org/pdf/2504.05803v2>|提出了一种针对发音与口型对齐问题的语音编码器PASE，通过显式强化音素与口型的精确对应，显著提升了唇...|


## 时序视觉分析 (Temporal Visual Analysis)


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PROFUSEme: PROstate Cancer Biochemical Recurrence Prediction via FUSEd Multi-modal Embeddings|PROFUSEme：通过融合多模态嵌入进行前列腺癌生化复发预测|Suhang You, Carla Pitarch-Abaigar, Sanket Kachole, Sumedh Sonawane, Juhyung Ha, Anish Sudarshan Gada, David Crandall, Rakesh Shiradkar .etc.|<http://arxiv.org/pdf/2509.14051v2>|提出了一种融合临床、影像和病理数据的跨模态前列腺癌生化复发预测方法，实现了更准确的早期预测。|
|🆕 发布|ST-GS: Vision-Based 3D Semantic Occupancy Prediction with Spatial-Temporal Gaussian Splatting|基于时空高斯散点法的视觉三维语义占据预测：ST-GS|Xiaoyang Yan, Muleilan Pei, Shaojie Shen|<http://arxiv.org/pdf/2509.16552v1>|提出了一种增强空间和时间建模的ST-GS框架，通过引导式空间聚合和几何感知时间融合，提升了3D语义占...|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Segment-to-Act: Label-Noise-Robust Action-Prompted Video Segmentation Towards Embodied Intelligence|面向具身智能的标签噪声鲁棒性动作提示视频分割：从片段到动作|Wenxin Li, Kunyu Peng, Di Wen, Ruiping Liu, Mengfei Duan, Kai Luo, Kailun Yang|<http://arxiv.org/pdf/2509.16677v1>|[代码](https://github.com/mylwx/ActiSeg-NL.); 提出了首个面向动作驱动的视频对象分割的标签噪声鲁棒方法，并建立了相关噪声学习和评估的基准。|
|🆕 发布|Person Identification from Egocentric Human-Object Interactions using 3D Hand Pose|基于第一人称视角人-物交互的3D手势姿态进行个人识别|Muhammad Hamza, Danish Hamid, Muhammad Tahir Akram|<http://arxiv.org/pdf/2509.16557v1>|提出了一种利用3D手部姿态分析的无干扰用户识别框架，实现了高准确度实时认证。|
|🆕 发布|Advancing Reference-free Evaluation of Video Captions with Factual Analysis|无参考评价视频字幕的事实分析进展|Shubhashis Roy Dipta, Tz-Ying Wu, Subarna Tripathi|<http://arxiv.org/pdf/2509.16538v1>|提出了一种无需参考真实字幕的评估框架VC-Inspector，通过事实性分析准确评估视频字幕质量。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AnyAnomaly: Zero-Shot Customizable Video Anomaly Detection with LVLM|任何异常：基于LVLM的无样本自定义视频异常检测|Sunghyun Ahn, Youngwan Jo, Kijung Lee, Sein Kwon, Inpyo Hong, Sanghyun Park|<http://arxiv.org/pdf/2503.04504v3>|[代码](https://github.com/SkiddieAhn/Paper-AnyAnomaly.); 提出了一种无需重新训练即可适应不同环境的零样本视频异常检测方法AnyAnomaly。|
|📝 更新|InfiniBench: A Benchmark for Large Multi-Modal Models in Long-Form Movies and TV Shows|《InfiniBench：长篇电影和电视剧中大型多模态模型的基准测试》|Kirolos Ataallah, Eslam Abdelrahman, Mahmoud Ahmed, Chenhui Gou, Khushbu Pahwa, Jian Ding, Mohamed Elhoseiny|<http://arxiv.org/pdf/2406.19875v4>|[代码](https://vision-cair.github.io/Infinibench); 提出了InfiniBench，用于评估长视频理解能力，包含丰富视频内容和多样化技能测试。|
|📝 更新|VideoRFT: Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning|视频RFT：通过强化微调激励多模态大型语言模型中的视频推理能力|Qi Wang, Yanrui Yu, Ye Yuan, Rui Mao, Tianfei Zhou|<http://arxiv.org/pdf/2505.12434v3>|提出VIDEORFT方法，通过强化微调提升多模态语言模型对视频的推理能力。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CGTGait: Collaborative Graph and Transformer for Gait Emotion Recognition|协作图与变换器用于步态情感识别的CGTGait|Junjie Zhou, Haijun Xiong, Junhao Lu, Ziyu Lin, Bin Feng|<http://arxiv.org/pdf/2509.16623v1>|[代码](https://github.com/githubzjj1/CGTGait.); 提出了一种融合图卷积和变压器的CGTGait框架，有效提取步行情感识别的时空特征，实现最优性能并大幅...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Looking in the mirror: A faithful counterfactual explanation method for interpreting deep image classification models|“镜子中的观察：一种忠实的事实反事实解释方法，用于解读深度图像分类模型”|Townim Faisal Chowdhury, Vu Minh Hieu Phan, Kewen Liao, Nanyu Dong, Minh-Son To, Anton Hengel, Johan Verjans, Zhibin Liao|<http://arxiv.org/pdf/2509.16822v1>|提出了一种直接在分类器特征空间中生成忠实反事实解释的方法，有效揭示了特征空间和决策边界。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spectral Compressive Imaging via Chromaticity-Intensity Decomposition|通过色度-亮度分解的频谱压缩成像|Xiaodong Wang, Zijun He, Ping Wang, Lishun Wang, Yanan Hu, Xin Yuan|<http://arxiv.org/pdf/2509.16690v1>|提出了一种基于色度-亮度分解的压缩成像框架，有效解决了高光谱图像重建中的光照依赖性和细节保持问题。|
|🆕 发布|Cross-Corpus and Cross-domain Handwriting Assessment of NeuroDegenerative Diseases via Time-Series-to-Image Conversion|跨语料库和跨领域神经退行性疾病手写评估通过时间序列到图像转换|Gabrielle Chavez, Laureano Moro-Velazquez, Ankur Butala, Najim Dehak, Thomas Thebaud|<http://arxiv.org/pdf/2509.16474v1>|提出了一种结合时间序列与图像的框架，实现了神经退行性疾病的手写评估，提升了跨数据集的检测性能。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unlocking Hidden Potential in Point Cloud Networks with Attention-Guided Grouping-Feature Coordination|解锁点云网络中隐藏潜力：基于注意力引导的分组-特征协同机制|Shangzhuo Xie, Qianqian Yang|<http://arxiv.org/pdf/2509.16639v1>|提出了一种注意力引导的点云网络模块GF-Core，通过模块整合而非结构修改显著提升了点云分析性能。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Learning to Align: Addressing Character Frequency Distribution Shifts in Handwritten Text Recognition|学习对齐：解决手写文本识别中的字符频率分布偏移问题|Panagiotis Kaliosis, John Pavlopoulos|<http://arxiv.org/pdf/2506.09846v2>|[代码](https://github.com/pkaliosis/fada.); 提出了一种新损失函数，通过 Wasserstein 距离调整字符频率分布，增强手写文本识别的准确性和...|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|IPF-RDA: An Information-Preserving Framework for Robust Data Augmentation|信息保持框架：用于稳健数据增强的IPF-RDA|Suorong Yang, Hongchao Yang, Suhan Guo, Furao Shen, Jian Zhao|<http://arxiv.org/pdf/2509.16678v1>|[代码](https://github.com/Jackbrocp/IPF-RDA.); 提出了一种信息保留框架IPF-RDA，通过识别并保护关键信息，增强了数据增强的鲁棒性并提升了模型性能...|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Quantifying and Alleviating Co-Adaptation in Sparse-View 3D Gaussian Splatting|量化并减轻稀疏视图三维高斯散点绘制中的共适应现象|Kangjie Chen, Yingji Zhong, Zhihao Li, Jiaqi Lin, Youyu Chen, Minghan Qin, Haoqian Wang|<http://arxiv.org/pdf/2508.12720v3>|提出量化方法揭示3D Gaussian Splatting在稀疏视角下的自适应问题，并提出两种策略减...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CAMBench-QR : A Structure-Aware Benchmark for Post-Hoc Explanations with QR Understanding|CAMBench-QR：面向QR理解的后验解释结构感知基准测试|Ritabrata Chakraborty, Avijit Dasgupta, Sandeep Chaurasia|<http://arxiv.org/pdf/2509.16745v1>|提出了结构感知的基准CAMBench-QR，利用QR码的几何特性评估视觉解释的准确性。|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios|长尾半监督学习在开放世界场景中的参数高效微调：LoFT|Zhiyuan Huang, Jiahao Chen, Yurou Liu, Bing Su|<http://arxiv.org/pdf/2509.09926v2>|提出LoFT框架，通过参数高效微调预训练模型，有效解决长尾分布下的半监督学习问题。|
|🆕 发布|Min: Mixture of Noise for Pre-Trained Model-Based Class-Incremental Learning|最小化：基于预训练模型的类增量学习中噪声混合方法|Kai Jiang, Zhengyan Shi, Dell Zhang, Hongyuan Zhang, Xuelong Li|<http://arxiv.org/pdf/2509.16738v1>|提出利用信息理论指导学习有益噪声，通过混合噪声策略提升预训练模型在持续学习中的泛化能力。|
|📝 更新|TACO: Enhancing Multimodal In-context Learning via Task Mapping-Guided Sequence Configuration|TACO：通过任务映射引导的序列配置增强多模态情境学习|Yanshu Li, Jianjiang Yang, Tian Yun, Pinyuan Feng, Jinfa Huang, Ruixiang Tang|<http://arxiv.org/pdf/2505.17098v2>|提出了一种基于任务映射的序列配置方法TACO，有效提升了大型视觉语言模型的多模态情境学习能力。|
|🆕 发布|SlowFast-SCI: Slow-Fast Deep Unfolding Learning for Spectral Compressive Imaging|慢快-SCI：光谱压缩成像的慢快深度展开学习|Haijin Zeng, Xuan Lu, Yurong Zhang, Yongyong Chen, Jingyong Su, Jie Liu|<http://arxiv.org/pdf/2509.16509v1>|[代码](https://github.com/XuanLu11/SlowFast-SCI.); 提出双速深度展开学习框架SlowFast-SCI，实现高效自适应光谱成像重建，提升模型泛化能力和适应...|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 目标导向视觉决策 (Goal-oriented Visual Decision Making)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|IMAIA: Interactive Maps AI Assistant for Travel Planning and Geo-Spatial Intelligence|IMAIA：旅行规划与地理空间智能的交互式地图AI助手|Jieren Deng, Zhizhang Hu, Ziyan He, Aleksandar Cvetkovic, Pak Kiu Chung, Dragomir Yankov, Chiqun Zhang|<http://arxiv.org/pdf/2507.06993v2>|IMAIA通过融合自然语言与地图及地理信息，实现了直观的地图交互和场景理解，提升了地图问答和定位任务...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Both Text and Images Leaked! A Systematic Analysis of Data Contamination in Multimodal LLM|文本与图像泄露！多模态大型语言模型数据污染的系统分析|Dingjie Song, Sicheng Lai, Mingxuan Wang, Shunian Chen, Lichao Sun, Benyou Wang|<http://arxiv.org/pdf/2411.03823v3>|提出了一种分析框架MM-Detect，揭示了多模态大语言模型中数据污染问题，并量化了污染程度。|
|🆕 发布|Benchmarking and Mitigating MCQA Selection Bias of Large Vision-Language Models|大规模视觉语言模型中MCQA选择偏差的基准测试与缓解|Md. Atabuzzaman, Ali Asgarov, Chris Thomas|<http://arxiv.org/pdf/2509.16805v1>|[代码](https://github.com/Atabuzzaman/Selection-Bias-of-LVLMs); 揭示了大型视觉语言模型在多项选择题中的选择偏差问题，并提出了一种无需重训练的实时校正方法。|
|📝 更新|Evaluating Fairness in Large Vision-Language Models Across Diverse Demographic Attributes and Prompts|结果： 评估大型视觉-语言模型在不同人口统计特性和提示下的公平性|Xuyang Wu, Yuan Wang, Hsin-Tai Wu, Zhiqiang Tao, Yi Fang|<http://arxiv.org/pdf/2406.17974v3>|评估大型视觉语言模型在不同人口属性和提示下的公平性，并提出了一种多模态链式思维策略以减轻不公平性。|
|🆕 发布|Seeing Culture: A Benchmark for Visual Reasoning and Grounding|“看见文化：一个用于视觉推理和基础研究的基准”|Burak Satar, Zhixin Ma, Patrick A. Irawan, Wilfried A. Mulyawan, Jing Jiang, Ee-Peng Lim, Chong-Wah Ngo|<http://arxiv.org/pdf/2509.16517v1>|[代码](https://github.com/buraksatar/SeeingCulture); 提出 Seeing Culture Benchmark，通过两阶段视觉推理和空间定位提升跨模态文化推...|
|📝 更新|ProReason: Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom|ProReason：多模态主动推理与解耦的视野与智慧|Jingqi Zhou, Sheng Wang, Jingwei Dong, Kai Liu, Lei Li, Jiahui Gao, Jiyue Jiang, Lingpeng Kong .etc.|<http://arxiv.org/pdf/2410.14138v4>|提出ProReason框架，通过分离视觉感知和文本推理，有效提升大型视觉语言模型的视觉推理性能。|
|🆕 发布|Eye Gaze Tells You Where to Compute: Gaze-Driven Efficient VLMs|"视线告诉你计算的位置：视线驱动的效率化大型语言模型"|Qinyu Chen, Jiawen Qi|<http://arxiv.org/pdf/2509.16476v1>|提出了一种利用人类眼动信号优化计算分配的GazeVLM框架，显著提升了视觉语言模型在边缘设备上的效率...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MedGS: Gaussian Splatting for Multi-Modal 3D Medical Imaging|MedGS：多模态三维医学成像的高斯散点绘制|Kacper Marzol, Ignacy Kolton, Weronika Smolak-Dyżewska, Joanna Kaleta, Marcin Mazur, Przemysław Spurek|<http://arxiv.org/pdf/2509.16806v1>|提出了一种基于高斯散点的半监督神经隐式表面重建框架，有效应对医学成像中的噪声和帧间信息缺失问题。|
|🆕 发布|Development of a Mobile Application for at-Home Analysis of Retinal Fundus Images|移动应用程序的开发，用于家庭环境下视网膜眼底图像分析|Mattea Reid, Zuhairah Zainal, Khaing Zin Than, Danielle Chan, Jonathan Chan|<http://arxiv.org/pdf/2509.16814v1>|开发了一款移动应用，通过监测视网膜图像指标，无需专业验证即可早期发现眼部疾病。|
|🆕 发布|Towards a Transparent and Interpretable AI Model for Medical Image Classifications|迈向透明和可解释的医学图像分类人工智能模型|Binbin Wen, Yihang Wu, Tareef Daqqaq, Ahmad Chaddad|<http://arxiv.org/pdf/2509.16685v1>|探究并应用解释性人工智能方法，提升医疗影像分类决策的透明度和可解释性。|
|🆕 发布|MedCutMix: A Data-Centric Approach to Improve Radiology Vision-Language Pre-training with Disease Awareness|MedCutMix：一种以数据为中心的提高具有疾病意识的放射学视觉-语言预训练的方法|Sinuo Wang, Yutong Xie, Yuyuan Liu, Qi Wu|<http://arxiv.org/pdf/2509.16673v1>|提出MedCutMix方法，通过增强数据多样性提升医学影像与文本预训练效果。|
|🆕 发布|Are VLMs Ready for Lane Topology Awareness in Autonomous Driving?|自动驾驶中，变分语言模型是否具备了车道拓扑意识？|Xin Chen, Jia He, Maozheng Li, Dongliang Xu, Tianyu Wang, Yixiao Chen, Zhixin Lin, Yue Yao|<http://arxiv.org/pdf/2509.16654v1>|系统评估了视觉语言模型在理解道路拓扑方面的能力，并提出了基于鸟瞰图的方法来改善自动驾驶中的空间推理问...|
|🆕 发布|Fusing Spectral Correlation Density Imaging with Deep Learning for Intelligent Fault Diagnosis in Rotating Machinery|将光谱相关密度成像与深度学习融合用于旋转机械的智能故障诊断|Dilshara Herath, Chinthaka Abeyrathne, Chamindu Adithya, Chathura Seneviratne|<http://arxiv.org/pdf/2509.16580v1>|利用光谱相关密度图像与深度学习融合，实现了旋转机械故障的智能诊断。|
|🆕 发布|SQS: Enhancing Sparse Perception Models via Query-based Splatting in Autonomous Driving|SQS：通过基于查询的散点绘制增强自动驾驶中的稀疏感知模型|Haiming Zhang, Yiyao Zhu, Wending Zhou, Xu Yan, Yingjie Cai, Bingbing Liu, Shuguang Cui, Zhen Li|<http://arxiv.org/pdf/2509.16588v1>|提出SQS方法，通过查询驱动的散点绘制增强自动驾驶中的稀疏感知模型性能。|
|🆕 发布|A Novel Metric for Detecting Memorization in Generative Models for Brain MRI Synthesis|一种用于检测脑部MRI生成模型中记忆现象的新型度量方法|Antonio Scardace, Lemuel Puglisi, Francesco Guarnera, Sebastiano Battiato, Daniele Ravì|<http://arxiv.org/pdf/2509.16582v1>|[代码](https://github.com/brAIn-science/DeepSSIM.); 提出了一种名为DeepSSIM的检测生成模型记忆化现象的新方法，通过学习嵌入空间中的图像相似性，大幅...|
|📝 更新|A Unified Deep Learning Framework for Motion Correction in Medical Imaging|医学成像运动校正的统一深度学习框架|Jian Wang, Razieh Faghihpirayesh, Danny Joca, Polina Golland, Ali Gholipour|<http://arxiv.org/pdf/2409.14204v3>|[代码](https://github.com/IntelligentImaging/UNIMO); 提出统一深度学习框架UniMo，有效纠正医学成像中的多种运动，实现跨模态应用无需重新训练。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Trajectory Prediction for Autonomous Driving: Progress, Limitations, and Future Directions|自动驾驶轨迹预测：进展、局限性与未来方向|Nadya Abdel Madjid, Abdulrahman Ahmad, Murad Mebrahtu, Yousef Babaa, Abdelmoamen Nasser, Sumbal Malik, Bilal Hassan, Naoufel Werghi .etc.|<http://arxiv.org/pdf/2503.03262v3>|系统梳理了自动驾驶轨迹预测方法，并分类现有解决方案，指出了研究空白和挑战。|
|🆕 发布|ProtoVQA: An Adaptable Prototypical Framework for Explainable Fine-Grained Visual Question Answering|原型VQA：一种适用于可解释细粒度视觉问答的适应性原型框架|Xingjian Diao, Weiyi Wu, Keyi Kong, Peijun Qing, Xinwen Xu, Ming Cheng, Soroush Vosoughi, Jiang Gui|<http://arxiv.org/pdf/2509.16680v1>|提出了一种原型驱动的可解释细粒度视觉问答框架，通过学习问题感知原型并应用空间约束匹配，实现了准确回答...|
|🆕 发布|RLGF: Reinforcement Learning with Geometric Feedback for Autonomous Driving Video Generation|强化学习结合几何反馈的自动驾驶视频生成方法|Tianyi Yan, Wencheng Han, Xia Zhou, Xueyang Zhang, Kun Zhan, Cheng-zhong Xu, Jianbing Shen|<http://arxiv.org/pdf/2509.16500v1>|引入了RLGF方法，通过几何反馈的强化学习优化自动驾驶视频生成，显著减少几何误差并提升3D物体检测性...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Investigating Long-term Training for Remote Sensing Object Detection|探究远程感知目标检测的长周期训练方法|JongHyun Park, Yechan Kim, Moongu Jeon|<http://arxiv.org/pdf/2407.15143v3>|[代码](https://github.com/unique-chan/dbf.); 探究长周期训练对遥感目标检测的影响，提出动态骨架冻结方法优化特征提取。|

