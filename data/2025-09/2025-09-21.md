## [UPDATED!] **2025-09-21** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Reflecting on the State of Rehearsal-free Continual Learning with Pretrained Models|对无复习持续学习与预训练模型状态的反思|Lukas Thede, Karsten Roth, Olivier J. Hénaff, Matthias Bethge, Zeynep Akata|<http://arxiv.org/pdf/2406.09384v2>|揭示了无复习持续学习中的方法选择与性能之间的关系，并提出了简化的参数高效微调基线。|
|🆕 发布|Parameter-efficient fine-tuning (PEFT) of Vision Foundation Models for Atypical Mitotic Figure Classification|参数高效的视觉基础模型微调（PEFT）用于非典型有丝分裂图像分类|Lavish Ramchandani, Gunjan Deotale, Dev Kumar Das|<http://arxiv.org/pdf/2509.16935v1>|探究了使用大型视觉基础模型结合低秩适应进行高效参数微调，以准确分类异常有丝分裂图像。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Point-RTD: Replaced Token Denoising for Pretraining Transformer Models on Point Clouds|点云预训练Transformer模型的替换令牌去噪|Gunner Stone, Youngsook Choi, Alireza Tavakkoli, Ankita Shukla|<http://arxiv.org/pdf/2509.17207v1>|提出了一种新的预训练策略Point-RTD，通过替换和去噪点云数据，大幅提升模型性能和效率。|
|🆕 发布|SynergyNet: Fusing Generative Priors and State-Space Models for Facial Beauty Prediction|协同网：融合生成先验和状态空间模型进行面部美感预测|Djamel Eddine Boukhari|<http://arxiv.org/pdf/2509.17172v1>|提出了一种融合生成先验和状态空间模型的MD-Net架构，有效平衡了局部美学细节和全局面部和谐预测。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DeepInsert: Early Layer Bypass for Efficient and Performant Multimodal Understanding|深度插入：用于高效和表现卓越的多模态理解的前期层旁路|Moulik Choraria, Xinbo Wu, Akhil Bhimaraju, Nitesh Sekhar, Yue Wu, Xu Zhang, Prateek Singhal, Lav R. Varshney|<http://arxiv.org/pdf/2504.19327v2>|提出了一种将多模态数据直接插入到模型中间层的方法，减少了计算成本同时保持或提升性能。|
|🆕 发布|Informative Text-Image Alignment for Visual Affordance Learning with Foundation Models|基于基础模型的视觉功效学习中的信息性文本-图像对齐|Qian Zhang, Lin Zhang, Xing Fang, Mingxin Zhang, Zhiyuan Wei, Ran Song, Wei Zhang|<http://arxiv.org/pdf/2509.17074v1>|提出了一种基于信息约束的文本引导视觉 affordance 学习框架，通过特征级文本图像对齐提升识别...|
|📝 更新|Elevating Visual Perception in Multimodal LLMs with Auxiliary Embedding Distillation|提升多模态大型语言模型中的视觉感知能力：基于辅助嵌入蒸馏的方法|Jitesh Jain, Zhengyuan Yang, Humphrey Shi, Jianfeng Gao, Jianwei Yang|<http://arxiv.org/pdf/2412.09585v2>|提出了一种将视觉感知知识融入多模态语言模型的方法，有效提升了模型在视觉任务上的表现。|
|📝 更新|LEO-MINI: An Efficient Multimodal Large Language Model using Conditional Token Reduction and Mixture of Multi-Modal Experts|LEO-MINI：一种使用条件令牌减少和多种模态专家混合的高效多模态大型语言模型|Yimu Wang, Mozhgan Nasr Azadani, Sean Sedwards, Krzysztof Czarnecki|<http://arxiv.org/pdf/2504.04653v2>|提出了一种高效的多元模态大语言模型LEO-MINI，通过条件令牌减少和多模态专家混合技术提升计算效率...|
|📝 更新|Image-to-Brain Signal Generation for Visual Prosthesis with CLIP Guided Multimodal Diffusion Models|基于CLIP引导的多模态扩散模型的视觉假体用图像到脑信号生成|Ganxi Xu, Jinyi Long, Jia Zhang|<http://arxiv.org/pdf/2509.00787v3>|提出首个图像到脑信号生成框架，利用增强的跨注意力机制模型实现图像向脑电信号的转换。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Optimized Learned Image Compression for Facial Expression Recognition|优化学习的图像压缩技术在面部表情识别中的应用|Xiumei Li, Marc Windsheimer, Misha Sadeghi, Björn Eskofier, André Kaup|<http://arxiv.org/pdf/2509.17262v1>|提出端到端模型优化图像压缩，平衡压缩效率与表情识别准确度。|
|🆕 发布|DocIQ: A Benchmark Dataset and Feature Fusion Network for Document Image Quality Assessment|文档智能质量评估：一个基准数据集与特征融合网络|Zhichao Ma, Fan Huang, Lu Zhao, Fengjun Guo, Guangtao Zhai, Xiongkuo Min|<http://arxiv.org/pdf/2509.17012v1>|提出了DIQA-5000数据集和一种融合多级视觉特征的文档图像质量评估网络，提升了质量感知与计算效率...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Automated Facility Enumeration for Building Compliance Checking using Door Detection and Large Language Models|使用门检测和大语言模型进行建筑合规性检查的自动化设施枚举|Licheng Zhan, Bach Le, Naveed Akhtar, Tuan Ngo|<http://arxiv.org/pdf/2509.17283v1>|提出了一种结合门检测和大型语言模型推理的自动化设施统计方法，提高了建筑合规性检查的效率和准确性。|
|📝 更新|PoseBench3D: A Cross-Dataset Analysis Framework for 3D Human Pose Estimation via Pose Lifting Networks|姿态提升网络三维人体姿态估计的跨数据集分析框架：PoseBench3D|Saad Manzur, Bryan Vela, Brandon Vela, Aditya Agrawal, Lan-Anh Dang-Vu, David Li, Wayne Hayes|<http://arxiv.org/pdf/2505.10888v2>|[代码](https://github.com/bryanjvela/PoseBench3D); 提出了自动化评估框架PoseBench3D，用于跨数据集三维人体姿态估计的公平比较。|
|🆕 发布|A Cross-Hierarchical Multi-Feature Fusion Network Based on Multiscale Encoder-Decoder for Hyperspectral Change Detection|基于多尺度编码器-解码器的跨层次多特征融合网络用于高光谱变化检测|Mingshuai Sheng, Bhatti Uzair Aslam, Junfeng Zhang, Siling Feng, Yonis Gulzar|<http://arxiv.org/pdf/2509.16988v1>|提出了一种基于多尺度编解码器的跨层次多特征融合网络，有效提升了高光谱变化检测的准确性和效率。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SFN-YOLO: Towards Free-Range Poultry Detection via Scale-aware Fusion Networks|SFN-YOLO：基于尺度感知融合网络的自由范围家禽检测|Jie Chen, Yuhong Feng, Tao Dai, Mingzhe Liu, Hongtao Chen, Zhaoxi He, Jiancong Bai|<http://arxiv.org/pdf/2509.17086v1>|[代码](https://github.com/chenjessiee/SFN-YOLO.); 提出了一种针对自由范围家禽检测的SFN-YOLO方法，通过尺度感知融合网络有效应对多尺度目标和复杂环...|
|🆕 发布|Enhanced Detection of Tiny Objects in Aerial Images|《增强型微小目标在航空影像中的检测》|Kihyun Kim, Michalis Lazarou, Tania Stathaki|<http://arxiv.org/pdf/2509.17078v1>|[代码](https://github.com/Kihyun11/MoonNet); 提出三种策略增强YOLOv8对微小目标的检测能力，包括调整输入图像分辨率、数据增强和注意力机制。|
|🆕 发布|Rethinking Evaluation of Infrared Small Target Detection|重新思考红外小目标检测的评价方法|Youwei Pang, Xiaoqi Zhao, Lihe Zhang, Huchuan Lu, Georges El Fakhri, Xiaofeng Liu, Shijian Lu|<http://arxiv.org/pdf/2509.16888v1>|提出全面评估框架，引入混合级指标和跨数据集评估，以改进红外小目标检测模型性能和泛化能力。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DT-NeRF: A Diffusion and Transformer-Based Optimization Approach for Neural Radiance Fields in 3D Reconstruction|基于扩散和变换优化的神经辐射场三维重建方法：DT-NeRF|Bo Liu, Runlong Li, Li Zhou, Yan Zhou|<http://arxiv.org/pdf/2509.17232v1>|提出了一种结合扩散模型和Transformer的DT-NeRF方法，显著提升了三维场景重建的细节恢复...|
|📝 更新|DescriptorMedSAM: Language-Image Fusion with Multi-Aspect Text Guidance for Medical Image Segmentation|《DescriptorMedSAM：基于多方面文本引导的语言-图像融合用于医学图像分割》|Wenjie Zhang, Liming Luo, Mengnan He, Jiarui Hai, Jiancheng Ye|<http://arxiv.org/pdf/2503.13806v2>|提出了一种融合医学文本描述与图像分割的方法，实现了无需点击的精准医学图像分割。|
|📝 更新|DD-Ranking: Rethinking the Evaluation of Dataset Distillation|DD-Ranking：重新思考数据集精简的评价方法|Zekai Li, Xinhao Zhong, Samir Khaki, Zhiyuan Liang, Yuhao Zhou, Mingjia Shi, Ziqiao Wang, Xuanlei Zhao .etc.|<http://arxiv.org/pdf/2505.13300v3>|提出统一评估框架DD-Ranking，确保客观评价数据集精炼方法性能提升。|
|📝 更新|Subjective Camera 1.0: Bridging Human Cognition and Visual Reconstruction through Sequence-Aware Sketch-Guided Diffusion|主观相机1.0：通过序列感知草图引导扩散连接人类认知与视觉重建|Haoyang Chen, Dongfang Sun, Caoyuan Ma, Shiqin Wang, Kewei Zhang, Zheng Wang, Zhixiang Wang|<http://arxiv.org/pdf/2506.23711v3>|提出主观相机框架，通过文本描述和草图引导扩散模型重建现实场景，实现高质量图像与目标场景的空间和语义对...|
|🆕 发布|Learning Attribute-Aware Hash Codes for Fine-Grained Image Retrieval via Query Optimization|通过查询优化学习属性感知哈希码进行细粒度图像检索|Peng Wang, Yong Li, Lin Zhao, Xiu-Shen Wei|<http://arxiv.org/pdf/2509.17049v1>|提出了一种基于学习查询的属性感知哈希码学习方法，通过优化查询增强图像检索的准确性和鲁棒性。|
|🆕 发布|When Color-Space Decoupling Meets Diffusion for Adverse-Weather Image Restoration|Conditioned Diffusion Models for Adverse-Weather Image Restoration when Color-Space Decoupling is Applied|Wenxuan Fang, Jili Fan, Chao Wang, Xiantao Hu, Jiangwei Weng, Ying Tai, Jian Yang, Jun Li|<http://arxiv.org/pdf/2509.17024v1>|[代码](https://github.com/fiwy0527/LCDiff.); 提出LCDiff框架，通过颜色空间分解和引导扩散模型，有效恢复恶劣天气下的图像质量。|
|🆕 发布|Penalizing Boundary Activation for Object Completeness in Diffusion Models|惩罚边界激活以实现扩散模型中的对象完整性|Haoyang Xu, Tianhao Zhao, Sibei Yang, Yutian Li|<http://arxiv.org/pdf/2509.16968v1>|提出了一种无需训练的边界激活惩罚方法，有效解决了扩散模型生成物体不完整的问题。|
|📝 更新|Attentive Eraser: Unleashing Diffusion Model's Object Removal Potential via Self-Attention Redirection Guidance|注意力擦除器：通过自注意力重定向引导释放扩散模型的对象移除潜力|Wenhao Sun, Benlei Cui, Xue-Mei Dong, Jingqun Tang|<http://arxiv.org/pdf/2412.12974v8>|[代码](https://github.com/Anonym0u3/AttentiveEraser.); 提出Attentive Eraser方法，通过重定向注意力机制优化预训练扩散模型，实现稳定有效的图像...|
|📝 更新|BiPrompt-SAM: Enhancing Image Segmentation via Explicit Selection between Point and Text Prompts|BiPrompt-SAM：通过显式选择点提示和文本提示增强图像分割|Suzhe Xu, Jialin Peng, Chengyuan Zhang|<http://arxiv.org/pdf/2503.19769v3>|提出了一种双模态图像分割框架BiPrompt-SAM，通过显式选择机制有效融合点提示和文本提示的优势...|
|🆕 发布|Learning from Gene Names, Expression Values and Images: Contrastive Masked Text-Image Pretraining for Spatial Transcriptomics Representation Learning|从基因名称、表达值和图像学习：对比掩码文本-图像预训练用于空间转录组学表征学习|Jiahe Qian, Yaoyu Fang, Ziqiao Weng, Xinkun Wang, Lee A. Cooper, Bo Zhou|<http://arxiv.org/pdf/2509.16892v1>|提出了一种联合图像、基因名和表达值学习的预训练框架，实现了零样本基因表达预测。|
|🆕 发布|PhysHDR: When Lighting Meets Materials and Scene Geometry in HDR Reconstruction|PhysHDR：当光照遇到材料与场景几何在HDR重建中的交互|Hrishav Bakul Barua, Kalin Stefanov, Ganesh Krishnasamy, KokSheik Wong, Abhinav Dhall|<http://arxiv.org/pdf/2509.16869v1>|提出PhysHDR模型，通过结合光照、深度信息和材料特性，有效提升HDR图像重建质量。|
|🆕 发布|ISCS: Parameter-Guided Channel Ordering and Grouping for Learned Image Compression|参数引导的通道排序与分组学习图像压缩方法（ISCS）|Jinhao Wang, Cihan Ruan, Nam Ling, Wei Wang, Wei Jiang|<http://arxiv.org/pdf/2509.16853v1>|提出了一种通用的方法来识别和组织重要通道，通过优化通道顺序和分组，提高了图像压缩的编码和计算效率。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MirrorSAM2: Segment Mirror in Videos with Depth Perception|视频中的深度感知分段镜面：MirrorSAM2|Mingchen Xu, Yukun Lai, Ze Ji, Jing Wu|<http://arxiv.org/pdf/2509.17220v1>|首次将Segment Anything Model 2应用于视频中的镜子分割，通过深度感知优化了反射...|
|🆕 发布|Echo-Path: Pathology-Conditioned Echo Video Generation|回声路径：病理条件下的回声视频生成|Kabir Hamzah Muhammad, Marawan Elbatel, Yi Qin, Xiaomeng Li|<http://arxiv.org/pdf/2509.17190v1>|[代码](https://github.com/Marshall-mk/EchoPathv1); 提出Echo-Path框架，生成针对特定心脏病变的超声视频，助力自动化诊断模型发展。|
|🆕 发布|Guided and Unguided Conditional Diffusion Mechanisms for Structured and Semantically-Aware 3D Point Cloud Generation|引导和无引导条件扩散机制用于结构化和语义感知的3D点云生成|Gunner Stone, Sushmita Sarker, Alireza Tavakkoli|<http://arxiv.org/pdf/2509.17206v1>|提出了一种将语义条件直接嵌入生成过程的扩散框架，实现了结构化和语义感知的3D点云生成。|
|🆕 发布|Stencil: Subject-Driven Generation with Context Guidance|_STENCIL: 基于主体驱动的带有上下文引导的生成方法_|Gordon Chen, Ziqi Huang, Cheston Tan, Ziwei Liu|<http://arxiv.org/pdf/2509.17120v1>|提出Stencil框架，结合轻量级模型与大型预训练模型，实现快速生成高质量主体驱动的图像。|
|🆕 发布|AlignedGen: Aligning Style Across Generated Images|《AlignedGen：在生成图像中跨风格对齐》|Jiexuan Zhang, Yiheng Du, Qian Wang, Weiqi Li, Yu Gu, Jian Zhang|<http://arxiv.org/pdf/2509.17088v1>|提出了一种名为AlignedGen的框架，通过优化Diffusion Transformer模型中的...|
|📝 更新|Exploring the Design Space of 3D MLLMs for CT Report Generation|探索三维多模态语言模型的的设计空间以实现CT报告生成|Mohammed Baharoon, Jun Ma, Congyu Fang, Augustin Toma, Bo Wang|<http://arxiv.org/pdf/2506.21535v2>|[代码](https://github.com/bowang-lab/AMOS-MM-Solution); 系统探究3D多模态大语言模型设计，提出两种知识增强报告方法，提升CT报告生成性能。|
|📝 更新|TempFlow-GRPO: When Timing Matters for GRPO in Flow Models|时间敏感的GRPO：在流模型中时间因素对GRPO的重要性|Xiaoxuan He, Siming Fu, Yuke Zhao, Wanli Li, Jian Yang, Dacheng Yin, Fengyun Rao, Bo Zhang|<http://arxiv.org/pdf/2508.04324v2>|提出了一种针对生成模型的新型时序优化框架TempFlow-GRPO，通过精确的奖励分配和时间感知的探...|
|📝 更新|FOCUS: Unified Vision-Language Modeling for Interactive Editing Driven by Referential Segmentation|“FOCUS：基于参照分割驱动的交互式编辑统一视觉-语言建模”|Fan Yang, Yousong Zhu, Xin Li, Yufei Zhan, Hongyin Zhao, Shurong Zheng, Yaowei Wang, Ming Tang .etc.|<http://arxiv.org/pdf/2506.16806v2>|FOCUS通过整合视觉感知与生成，实现了对图像的精确编辑控制。|
|🆕 发布|VidCLearn: A Continual Learning Approach for Text-to-Video Generation|VidCLearn：一种用于文本到视频生成的持续学习方法|Luca Zanchetta, Lorenzo Papa, Luca Maiano, Irene Amerini|<http://arxiv.org/pdf/2509.16956v1>|提出了一种持续学习框架VidCLearn，通过学生-教师模型和新型损失函数，实现了高效且高质量的文本...|
|🆕 发布|Leveraging RGB Images for Pre-Training of Event-Based Hand Pose Estimation|利用RGB图像进行基于事件的手势估计预训练|Ruicong Liu, Takehiko Ohkawa, Tze Ho Elden Tse, Mingfang Zhang, Angela Yao, Yoichi Sato|<http://arxiv.org/pdf/2509.16949v1>|首次提出利用RGB图像进行事件相机手部姿态估计预训练的方法，通过分解手部运动生成更真实的事件数据。|
|🆕 发布|PRISM: Precision-Recall Informed Data-Free Knowledge Distillation via Generative Diffusion|PRISM：通过生成扩散的精度-召回指导的无数据知识蒸馏|Xuewan He, Jielei Wang, Zihan Cheng, Yuchen Su, Shiyue Huang, Guoming Lu|<http://arxiv.org/pdf/2509.16897v1>|提出了一种名为PRISM的数据免费知识蒸馏方法，通过能量引导分布对齐和多样化提示工程，有效解决了合成...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Beat on Gaze: Learning Stylized Generation of Gaze and Head Dynamics|《超越视线：学习视线与头部动态的风格化生成》|Chengwei Shi, Chong Cao, Xin Tong, Xukun Shen|<http://arxiv.org/pdf/2509.17168v1>|提出了一种音频驱动的生成同步眼神和头部运动风格的方法，解决了现有技术中眼神、头部运动和语音协调不足的...|
|🆕 发布|Towards Generalized Synapse Detection Across Invertebrate Species|面向无脊椎动物种间通用突触检测|Samia Mohinta, Daniel Franco-Barranco, Shi Yan Lee, Albert Cardona|<http://arxiv.org/pdf/2509.17041v1>|提出了一种简单高效的神经网络模型SimpSyn，用于跨物种无脊椎动物电子显微镜图像中的突触检测，实现...|
|🆕 发布|Towards Interpretable and Efficient Attention: Compressing All by Contracting a Few|面向可解释与高效注意力：通过压缩少数实现整体压缩|Qishuai Wen, Zhiyuan Huang, Chun-Guang Li|<http://arxiv.org/pdf/2509.16875v1>|提出统一优化目标解决注意力机制的效率和可解释性问题，创新性地提出 Contract-and-Broa...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VAInpaint: Zero-Shot Video-Audio inpainting framework with LLMs-driven Module|VAInpaint：基于大型语言模型驱动的零样本视频-音频修复框架|Kam Man Wu, Zeyue Tian, Liya Ji, Qifeng Chen|<http://arxiv.org/pdf/2509.17022v1>|提出VAInpaint框架，通过LLM驱动的模块实现无需训练即可进行视频和音频的无缝修复。|
|🆕 发布|VCE: Safe Autoregressive Image Generation via Visual Contrast Exploitation|VCE：通过视觉对比利用实现安全自回归图像生成|Feng Han, Chao Gong, Zhipeng Wei, Jingjing Chen, Yu-Gang Jiang|<http://arxiv.org/pdf/2509.16986v1>|[代码](https://github.com/Maplebb/VCE.); 提出Visual Contrast Exploitation框架，通过对比图像对分离不安全概念，有效...|
|📝 更新|Disentangling Content from Style to Overcome Shortcut Learning: A Hybrid Generative-Discriminative Learning Framework|解耦内容与风格以克服捷径学习：一种混合生成-判别学习框架|Siming Fu, Sijun Dong, Xiaoliang Meng|<http://arxiv.org/pdf/2509.11598v3>|提出HyGDL框架，通过显式内容风格分离解决自监督学习中的捷径学习问题，实现更稳健的特征学习。|
|🆕 发布|$\mathtt{M^3VIR}$: A Large-Scale Multi-Modality Multi-View Synthesized Benchmark Dataset for Image Restoration and Content Creation|$\mathtt{M^3VIR}$：用于图像修复与内容创作的规模化多模态多视角合成基准数据集|Yuanzhi Li, Lebin Zhou, Nam Ling, Zhenghao Chen, Wei Wang, Wei Jiang|<http://arxiv.org/pdf/2509.16873v1>|介绍了$\mathtt{M^3VIR}$，一个大规模多模态多视角合成数据集，为图像修复和内容创作提供...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Task-Oriented Communications for 3D Scene Representation: Balancing Timeliness and Fidelity|面向任务的通信用于三维场景表示：平衡实时性与保真度|Xiangmin Xu, Zhen Meng, Kan Chen, Jiaming Yang, Emma Li, Philip G. Zhao, David Flynn|<http://arxiv.org/pdf/2509.17282v1>|提出了一种结合年龄信息与语义信息的优化策略，实现了实时三维场景表示中时效性与保真度的平衡。|
|🆕 发布|High Resolution UDF Meshing via Iterative Networks|通过迭代网络实现高分辨率UDF网格化|Federico Stella, Nicolas Talabot, Hieu Le, Pascal Fua|<http://arxiv.org/pdf/2509.17212v1>|提出了一种迭代神经网络方法，通过多次传播邻居信息，显著提高了高分辨率UDF网格化精度和完整性。|
|📝 更新|VQToken: Neural Discrete Token Representation Learning for Extreme Token Reduction in Video Large Language Models|VQToken：用于视频大型语言模型中极简代币化的神经离散代币表示学习|Haichao Zhang, Yun Fu|<http://arxiv.org/pdf/2503.16980v5>|提出极端短令牌缩减任务，VQToken通过自适应向量量化显著压缩视频序列至0.07%，同时保持高准确...|
|🆕 发布|HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis|混合辐射场：用于内存高效和高品质新视角合成的技术|Zipeng Wang, Dan Xu|<http://arxiv.org/pdf/2509.17083v1>|[代码](https://wzpscott.github.io/hyrf); 提出Hybrid Radiance Fields，结合显式高斯和神经场优势，实现高效内存占用与高质量...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SPFSplatV2: Efficient Self-Supervised Pose-Free 3D Gaussian Splatting from Sparse Views|SPFSplatV2：高效的无需姿态监督的稀疏视角下的三维高斯喷绘|Ranran Huang, Krystian Mikolajczyk|<http://arxiv.org/pdf/2509.17246v1>|[代码](https://ranrhuang.github.io/spfsplatv2); 提出了一种无需姿态监督的3D高斯渲染方法，实现了高效的多视角图像重建。|
|📝 更新|Feed-Forward Bullet-Time Reconstruction of Dynamic Scenes from Monocular Videos|从单目视频中进行前馈子弹时间动态场景重建|Hanxue Liang, Jiawei Ren, Ashkan Mirzaei, Antonio Torralba, Ziwei Liu, Igor Gilitschenski, Sanja Fidler, Cengiz Oztireli .etc.|<http://arxiv.org/pdf/2412.03526v3>|提出了首个面向动态场景实时重建与视图合成的运动感知型前馈模型BTimer，实现了150ms内高质量子...|
|📝 更新|DriveSplat: Decoupled Driving Scene Reconstruction with Geometry-enhanced Partitioned Neural Gaussians|驱动场景重建的解耦：基于几何增强的分区神经高斯分布方法|Cong Wang, Xianda Guo, Wenbo Xu, Wei Tian, Ruiqi Song, Chenming Zhang, Lingxi Li, Long Chen|<http://arxiv.org/pdf/2508.15376v3>|提出了一种针对驾驶场景的高质量三维重建方法，通过动态静态解耦和几何增强的区域划分，提高了场景渲染的准...|
|🆕 发布|Efficient 3D Scene Reconstruction and Simulation from Sparse Endoscopic Views|从稀疏内窥镜视角进行高效的三维场景重建与仿真|Zhenya Yang|<http://arxiv.org/pdf/2509.17027v1>|提出了一种基于高斯散点法的框架，从稀疏内窥镜视角高效重建交互式手术场景，并通过虚拟相机正则化提升几何...|
|📝 更新|Accurate and Complete Surface Reconstruction from 3D Gaussians via Direct SDF Learning|通过直接学习SDF实现从三维高斯分布进行精确和完整的表面重建|Wenzhi Guo, Bing Wang|<http://arxiv.org/pdf/2509.07493v2>|提出了一种将符号距离场学习直接嵌入3D高斯分布框架的方法，实现了精确且完整的表面重建。|
|🆕 发布|SLAM-Former: Putting SLAM into One Transformer|SLAM-Former: 将SLAM融入单一Transformer|Yijun Yuan, Zhuoguang Chen, Kenan Li, Weibang Wang, Hang Zhao|<http://arxiv.org/pdf/2509.16909v1>|将SLAM功能集成到单个Transformer模型中，实现高效实时的地图构建与定位。|
|🆕 发布|ConfidentSplat: Confidence-Weighted Depth Fusion for Accurate 3D Gaussian Splatting SLAM|自信散点:基于置信度的深度融合用于精确三维高斯散点SLAM|Amanuel T. Dufera, Yuan-Li Cai|<http://arxiv.org/pdf/2509.16863v1>|引入了ConfidentSplat，一种通过置信度加权融合提升RGB-only 3D重建精度的SLA...|


## 时序视觉分析 (Temporal Visual Analysis)


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MoCLIP-Lite: Efficient Video Recognition by Fusing CLIP with Motion Vectors|MoCLIP-Lite：通过融合CLIP与运动向量实现的高效视频识别|Binhua Huang, Nan Wang, Arjun Parakash, Soumyabrata Dev|<http://arxiv.org/pdf/2509.17084v1>|[代码](https://github.com/microa/MoCLIP-Lite.); 提出了一种融合CLIP与运动向量的高效视频识别框架，大幅提升了准确度同时保持了极低成本。|
|📝 更新|PASS: Path-selective State Space Model for Event-based Recognition|基于路径选择的状态空间模型PASS用于事件驱动的识别|Jiazhou Zhou, Kanghao Chen, Lei Zhang, Lin Wang|<http://arxiv.org/pdf/2409.16953v2>|提出了PASS框架，通过自适应编码事件特征和状态空间模型，实现了对事件长度更广泛的建模和跨不同推理频...|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CardiacCLIP: Video-based CLIP Adaptation for LVEF Prediction in a Few-shot Manner|《CardiacCLIP：基于视频的CLIP适应方法用于少量样本下的左心室射血分数预测》|Yao Du, Jiarong Guo, Xiaomeng Li|<http://arxiv.org/pdf/2509.17065v1>|[代码](https://github.com/xmed-lab/CardiacCLIP.); 提出CardiacCLIP模型，通过视频帧聚合和多尺度特征提取，在少量样本下准确预测心脏射血分数。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|The 1st Solution for 7th LSVOS RVOS Track: SaSaSa2VA|第七届LSVOS RVOS赛道的第一种解决方案：SaSaSa2VA|Quanzhu Niu, Dengxian Gong, Shihao Chen, Tao Zhang, Yikang Zhou, Haobo Yuan, Lu Qi, Xiangtai Li .etc.|<http://arxiv.org/pdf/2509.16972v1>|[代码](https://github.com/magic-research/Sa2VA.); 提出改进的SaSaSa2VA模型，通过增强视频帧采样和选择性融合多模态信息，提升自然语言引导的视频对...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GroundFlow: A Plug-in Module for Temporal Reasoning on 3D Point Cloud Sequential Grounding|地面流：用于三维点云序列定位的时态推理插件模块|Zijun Lin, Shuting He, Cheston Tan, Bihan Wen|<http://arxiv.org/pdf/2506.21188v3>|提出GroundFlow模块，增强3D视觉 grounding模型对时序信息的理解，显著提升序列化3...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Superpixel Graph Contrastive Clustering with Semantic-Invariant Augmentations for Hyperspectral Images|超像素图对比聚类结合语义不变增强用于高光谱图像|Jianhan Qi, Yuheng Jia, Hui Liu, Junhui Hou|<http://arxiv.org/pdf/2403.01799v2>|[代码](https://github.com/jhqi/spgcc.); 提出了一种结合3D和2D卷积神经网络与对比学习的超像素图聚类方法，有效利用了高光谱图像的空间和光谱信...|
|📝 更新|Neural Antidote: Class-Wise Prompt Tuning for Purifying Backdoors in CLIP|神经解毒剂：面向类别的提示微调以净化CLIP中的后门|Jiawei Kong, Hao Fang, Sihang Guo, Chenxi Qing, Kuofeng Gao, Bin Chen, Shu-Tao Xia, Ke Xu|<http://arxiv.org/pdf/2502.19269v2>|提出了一种针对CLIP模型的类别-wise提示微调方法，有效清除后门攻击，同时保持模型准确性。|
|📝 更新|Guiding Cross-Modal Representations with MLLM Priors via Preference Alignment|通过偏好对齐引导跨模态表征的MLLM先验|Pengfei Zhao, Rongbo Luan, Wei Zhang, Peng Wu, Sifeng He|<http://arxiv.org/pdf/2506.06970v2>|提出MAPLE框架，利用大型多模态语言模型内嵌的细粒度对齐先验，有效提升跨模态检索的细粒度区分能力。|


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ME-Mamba: Multi-Expert Mamba with Efficient Knowledge Capture and Fusion for Multimodal Survival Analysis|ME-Mamba：多专家Mamba with高效知识捕获与融合的多模态生存分析|Chengsheng Zhang, Linhao Qu, Xiaoyu Liu, Zhijian Song|<http://arxiv.org/pdf/2509.16900v1>|提出了一种多模态生存分析系统ME-Mamba，通过独立处理病理和基因组数据并高效融合，提高了癌症生存...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Computational Scaffolding of Composition, Value, and Color for Disciplined Drawing|计算性构建法则：对约束性绘画中的构图、明暗和色彩的支撑|Jiaju Ma, Chau Vu, Asya Lyubavina, Catherine Liu, Jingyi Li|<http://arxiv.org/pdf/2509.17268v1>|提出ArtKrit工具，分步骤指导数字艺术家复制参考图像，提供计算引导和自动反馈以提升绘画技能。|
|📝 更新|The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning|《学得越好，剪枝越聪明：通过可微分标记剪枝实现高效的视觉-语言-动作模型》|Titong Jiang, Xuefeng Jiang, Yuan Ma, Xin Wen, Bailin Li, Kun Zhan, Peng Jia, Yahui Liu .etc.|<http://arxiv.org/pdf/2509.12594v2>|提出了一种自适应视觉令牌剪枝框架LightVLA，通过动态剪枝提高视觉语言行动模型的效率和性能。|
|🆕 发布|Geodesic Prototype Matching via Diffusion Maps for Interpretable Fine-Grained Recognition|通过扩散地图进行测地线原型匹配以实现可解释的细粒度识别|Junhao Jia, Yunyou Liu, Yifei Sun, Huangwei Chen, Feiwei Qin, Changmiao Wang, Yong Peng|<http://arxiv.org/pdf/2509.17050v1>|提出了一种基于扩散地图的测地线原型匹配方法，通过利用深度特征的内蕴几何结构，提高了细粒度识别的准确性...|
|🆕 发布|Optimal Transport for Handwritten Text Recognition in a Low-Resource Regime|在低资源环境下手写文本识别的最优传输方法|Petros Georgoulas Wraight, Giorgos Sfikas, Ioannis Kordonis, Petros Maragos, George Retsinas|<http://arxiv.org/pdf/2509.16977v1>|利用最优传输方法迭代对齐视觉特征与语义表示，有效提升低资源手写文本识别准确率。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CoBEVMoE: Heterogeneity-aware Feature Fusion with Dynamic Mixture-of-Experts for Collaborative Perception|协同感知中的异质性感知特征融合与动态混合专家模型：CoBEVMoE|Lingzhao Kong, Jiacheng Lin, Siyu Li, Kai Luo, Zhiyong Li, Kailun Yang|<http://arxiv.org/pdf/2509.17107v1>|[代码](https://github.com/godk0509/CoBEVMoE.); 提出了一种异质性感知的协同感知框架CoBEVMoE，通过动态混合专家模型在鸟瞰视角下有效融合多智能体...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|The SAGES Critical View of Safety Challenge: A Global Benchmark for AI-Assisted Surgical Quality Assessment|《SAGES关键视角安全挑战：人工智能辅助手术质量评估的全球基准》|Deepak Alapatt, Jennifer Eckhoff, Zhiliang Lyu, Yutong Ban, Jean-Paul Mazellier, Sarah Choksi, Kunyi Yang, 2024 CVS Challenge Consortium .etc.|<http://arxiv.org/pdf/2509.17100v1>|提出了SAGES Critical View of Safety Challenge，通过全球合作和...|
|📝 更新|Unified Framework for Pre-trained Neural Network Compression via Decomposition and Optimized Rank Selection|通过分解和优化秩选择实现的预训练神经网络压缩统一框架|Ali Aghababaei-Harandi, Massih-Reza Amini|<http://arxiv.org/pdf/2409.03555v2>|提出统一框架，通过分解和优化秩选择压缩预训练神经网络，自动寻找最优秩配置以保持模型性能。|
|📝 更新|QA-HFL: Quality-Aware Hierarchical Federated Learning for Resource-Constrained Mobile Devices with Heterogeneous Image Quality|质量感知的分层联邦学习：面向异质图像质量的资源受限移动设备|Sajid Hussain, Muhammad Sohail, Nauman Ali Khan|<http://arxiv.org/pdf/2506.05411v2>|提出了质量感知的分层联邦学习框架QA-HFL，有效处理异质图像质量并提升资源受限移动设备的模型准确性...|
|📝 更新|SpecVLM: Fast Speculative Decoding in Vision-Language Models|《SpecVLM：视觉语言模型中的快速投机解码》|Haiduo Huang, Fuwei Yang, Zhenhua Liu, Xuanwu Yin, Dong Li, Pengju Ren, Emad Barsoum|<http://arxiv.org/pdf/2509.11815v2>|[代码](https://github.com/haiduo/SpecVLM.); 提出SpecVLM方法，通过弹性视觉压缩和在线-logit蒸馏，加速视觉语言模型推理速度。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Pulling Back the Curtain on ReLU Networks|揭开ReLU网络的面纱|Maciej Satkiewicz|<http://arxiv.org/pdf/2507.22832v4>|揭示了ReLU网络内部表征的机制，通过软门控和梯度对齐，增强了模型的可解释性。|
|🆕 发布|Long-Tailed Out-of-Distribution Detection with Refined Separate Class Learning|长尾分布异常检测的细化分离类学习|Shuai Feng, Yuxin Ge, Yuntao Du, Mingcai Chen, Lei Feng|<http://arxiv.org/pdf/2509.17034v1>|提出 refined separate class learning 方法，通过动态调整温度参数和挖...|
|📝 更新|KNN-MMD: Cross Domain Wireless Sensing via Local Distribution Alignment|KNN-MMD: 基于局部分布对齐的跨域无线感知|Zijian Zhao, Zhijie Cai, Tingwei Chen, Xiaoyang Li, Hang Li, Qimei Chen, Guangxu Zhu|<http://arxiv.org/pdf/2412.04783v4>|[代码](https://github.com/RS2002/KNN-MMD); 提出KNN-MMD方法，通过局部分布对齐解决无线感知模型跨环境性能下降问题。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Seeing 3D Through 2D Lenses: 3D Few-Shot Class-Incremental Learning via Cross-Modal Geometric Rectification|通过2D镜头看3D：基于跨模态几何校正的3D小样本类别增量学习|Tuo Xiang, Xuemiao Xu, Bangzhen Liu, Jinyi Li, Yong Li, Shengfeng He|<http://arxiv.org/pdf/2509.14958v2>|提出了一种通过跨模态几何校正增强3D几何保真度的方法，有效解决了3D少样本增量学习中的几何对齐和纹理...|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Few-Shot Image Quality Assessment via Adaptation of Vision-Language Models|通过视觉语言模型的适应性进行少量样本图像质量评估|Xudong Li, Zihao Huang, Yan Zhang, Yunhang Shen, Ke Li, Xiawu Zheng, Liujuan Cao, Rongrong Ji|<http://arxiv.org/pdf/2409.05381v2>|提出了一种基于视觉语言模型的元学习框架，实现了在少量数据下高效进行图像质量评估。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CameraVDP: Perceptual Display Assessment with Uncertainty Estimation via Camera and Visual Difference Prediction|CameraVDP：通过相机和视觉差异预测进行感知显示评估及不确定性估计|Yancheng Cai, Robert Wanat, Rafal Mantiuk|<http://arxiv.org/pdf/2509.08947v2>|提出了一种结合相机重建和视觉差异预测的显示评估方法，提高了测量精度并考虑了人眼可见性。|
|🆕 发布|Event-Based Visual Teach-and-Repeat via Fast Fourier-Domain Cross-Correlation|基于事件的视觉教学-重复方法：通过快速傅里叶域互相关实现|Gokul B. Nair, Alejandro Fontan, Michael Milford, Tobias Fischer|<http://arxiv.org/pdf/2509.17287v1>|首次提出基于事件相机的视觉教-重复系统，通过傅里叶域相关算法实现超高速路径匹配与自主导航。|
|🆕 发布|VaseVQA: Multimodal Agent and Benchmark for Ancient Greek Pottery|《VaseVQA：古希腊陶器多模态智能体与评测基准》|Jinchao Ge, Tengfei Cheng, Biao Wu, Zeyu Zhang, Shiya Huang, Judith Bishop, Gillian Shepherd, Meng Fang .etc.|<http://arxiv.org/pdf/2509.17191v1>|[代码](https://github.com/AIGeeksGroup/VaseVQA.); 提出VaseVL系统，通过评价转化为监督，提升了对古希腊陶器的专家级理解和分类性能。|
|🆕 发布|FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions|《FlagEval 发现报告：对自动验证文本和视觉问题的大规模推理模型的初步评估》|Bowen Qin, Chen Yue, Fang Yin, Hui Wang, JG Yao, Jiakang Liu, Jing-Shu Zheng, Miguel Hu Chen .etc.|<http://arxiv.org/pdf/2509.17177v1>|[代码](https://flageval-baai.github.io/LRM-Eval); 评估大型推理模型在自动验证文本和视觉问题上的表现，并发布ROME视觉语言模型推理测试基准。|
|🆕 发布|From Easy to Hard: The MIR Benchmark for Progressive Interleaved Multi-Image Reasoning|从易到难：MIR逐步交织多图像推理基准|Hang Du, Jiayang Zhang, Guoshun Nan, Wendi Deng, Zhenyan Chen, Chenyang Zhang, Wang Xiao, Shan Huang .etc.|<http://arxiv.org/pdf/2509.17040v1>|[代码](https://github.com/Shelly-coder239/MIRBench.); 提出了MIR基准，通过“由易到难”的学习策略，显著提升了多模态大语言模型处理多图像和交错文本的能力。|
|🆕 发布|Catching the Details: Self-Distilled RoI Predictors for Fine-Grained MLLM Perception|捕捉细节：用于细粒度多模态感知的自蒸馏区域预测器|Yuheng Shi, Xiaohuan Pei, Minjing Dong, Chang Xu|<http://arxiv.org/pdf/2509.16944v1>|[代码](https://github.com/YuHengsss/SD-RPN.); 提出了一种无需标注数据的高效自蒸馏区域提议网络，通过优化注意力图显著提升了多模态大语言模型对细节的感...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Ambiguous Medical Image Segmentation Using Diffusion Schrödinger Bridge|使用扩散薛定谔桥的模糊医学图像分割|Lalith Bharadwaj Baru, Kamalaker Dadi, Tapabrata Chakraborti, Raju S. Bapi|<http://arxiv.org/pdf/2509.17187v1>|提出Schödinger Bridge框架用于处理模糊医学图像分割，通过建模图像-掩膜动态提升性能并...|
|🆕 发布|Uncertainty-Supervised Interpretable and Robust Evidential Segmentation|不确定性监督的可解释与鲁棒性证据分割|Yuzhu Li, An Sui, Fuping Wu, Xiahai Zhuang|<http://arxiv.org/pdf/2509.17098v1>|[代码](https://github.com/suiannaius/SURE.); 提出了一种自监督学习方法，通过增强不确定性估计的监督，提高了医学图像分割的准确性和鲁棒性。|
|📝 更新|An Efficient Dual-Line Decoder Network with Multi-Scale Convolutional Attention for Multi-organ Segmentation|一种用于多器官分割的高效双线解码器网络，具有多尺度卷积注意力机制|Riad Hassan, M. Rubaiyat Hossain Mondal, Sheikh Iqbal Ahamed, Fahad Mostafa, Md Mostafijur Rahman|<http://arxiv.org/pdf/2508.17007v2>|[代码](https://github.com/riadhassan/EDLDNet); 提出了一种高效的EDLDNet网络，通过双线解码器和多尺度卷积注意力优化多器官分割的准确性和效率。|
|🆕 发布|SAM-DCE: Addressing Token Uniformity and Semantic Over-Smoothing in Medical Segmentation|SAM-DCE: 针对医学分割中的标记均匀性和语义过平滑问题进行研究|Yingzhen Hu, Yiheng Zhong, Ruobing Li, Yingxue Su, Jiabao An, Feilong Tang, Jionglong Su, Imran Razzak|<http://arxiv.org/pdf/2509.16886v1>|提出SAM-DCE模型，解决医学图像分割中的均匀性问题和语义过度平滑问题，增强类间分离度和细粒度表示...|
|📝 更新|Interpretability-Aware Pruning for Efficient Medical Image Analysis|面向解释性的高效医学图像分析剪枝方法|Nikita Malik, Pratinav Seth, Neeraj Kumar Singh, Chintan Chitroda, Vinay Kumar Sankarapu|<http://arxiv.org/pdf/2507.08330v2>|提出了一种基于可解释性的剪枝框架，实现了医疗图像分析模型的压缩与性能保持。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SAEC: Scene-Aware Enhanced Edge-Cloud Collaborative Industrial Vision Inspection with Multimodal LLM|场景感知增强的边缘-云协同工业视觉检测系统：基于多模态大型语言模型|Yuhao Tian, Zheming Yang|<http://arxiv.org/pdf/2509.17136v1>|[代码](https://github.com/YuHao-Tian/SAEC.); 提出场景感知的边缘-云协同工业视觉检测框架，通过动态调整计算负载和复杂度评估，提升缺陷检测准确性和效...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GM-MoE: Low-Light Enhancement with Gated-Mechanism Mixture-of-Experts|GM-MoE：基于门控机制专家混合的低光照增强|Minwen Liao, Hao Bo Dong, Xinyi Wang, Kurban Ubul, Yihua Shao, Ziyang Yan|<http://arxiv.org/pdf/2503.07417v4>|提出GM-MoE框架，利用混合专家网络和动态门控机制提升低光照图像质量，实现广泛任务上的泛化性能。|
|🆕 发布|LLM-Assisted Semantic Guidance for Sparsely Annotated Remote Sensing Object Detection|稀疏标注遥感目标检测中的LLM辅助语义引导|Wei Liao, Chunyan Xu, Chenxu Wang, Zhen Cui|<http://arxiv.org/pdf/2509.16970v1>|利用大型语言模型进行语义引导，提出了一种针对稀疏标注遥感对象检测的伪标签分配机制，显著提升了检测性能...|
|🆕 发布|MO R-CNN: Multispectral Oriented R-CNN for Object Detection in Remote Sensing Image|多光谱导向的区域卷积神经网络（MO R-CNN）：用于遥感图像目标检测|Leiyu Wang, Biao Jin, Feng Huang, Liqiong Chen, Zhengyong Wang, Xiaohai He, Honggang Chen|<http://arxiv.org/pdf/2509.16957v1>|[代码](https://github.com/Iwill-github/MORCNN.); 提出MO R-CNN，通过异质特征提取网络和条件性多模态标签融合，提升遥感图像多光谱定向检测性能。|
|🆕 发布|Prototype-Based Pseudo-Label Denoising for Source-Free Domain Adaptation in Remote Sensing Semantic Segmentation|基于原型的伪标签去噪用于无需源域的遥感语义分割领域自适应|Bin Wang, Fei Deng, Zeyu Chen, Zhicheng Yu, Yiguang Liu|<http://arxiv.org/pdf/2509.16942v1>|提出了一种基于原型引导的伪标签去噪框架，有效缓解了遥感图像语义分割中的域偏移问题。|
|📝 更新|EarthGPT-X: A Spatial MLLM for Multi-level Multi-Source Remote Sensing Imagery Understanding with Visual Prompting|地球GPT-X：一种基于视觉提示的多级多源遥感图像理解的空间多模态语言模型|Wei Zhang, Miaoxin Cai, Yaqian Ning, Tong Zhang, Yin Zhuang, Shijian Lu, He Chen, Jun Li .etc.|<http://arxiv.org/pdf/2504.12795v2>|提出了EarthGPT-X模型，通过视觉提示统一处理多源遥感图像，实现多任务和多尺度理解。|
|📝 更新|SAM2-ELNet: Label Enhancement and Automatic Annotation for Remote Sensing Segmentation|SAM2-ELNet：遥感分割中的标签增强与自动标注|Jianhao Yang, Wenshuo Yu, Yuanchao Lv, Jiance Sun, Bokang Sun, Mingyang Liu|<http://arxiv.org/pdf/2503.12404v2>|提出了一种增强标签质量和自动标注的框架，有效提升了资源受限的遥感图像分割性能。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AgriDoctor: A Multimodal Intelligent Assistant for Agriculture|农业医生：一种多模态智能农业助手|Mingqing Zhang, Zhuoning Xu, Peijie Wang, Rongji Li, Liang Wang, Qiang Liu, Jian Xu, Xuyao Zhang .etc.|<http://arxiv.org/pdf/2509.17044v1>|提出了一种多模态智能助手AgriDoctor，用于精准农作物病害诊断和农业知识互动，大幅提升农业领域...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Dual-Modulation Framework for RGB-T Crowd Counting via Spatially Modulated Attention and Adaptive Fusion|基于空间调制注意力和自适应融合的RGB-T人群计数双向调制框架|Yuhong Feng, Hongtao Chen, Qi Zhang, Jie Chen, Zhaoxi He, Mingzhe Liu, Jianghai Liao|<http://arxiv.org/pdf/2509.17079v1>|[代码](https://github.com/Cht2924/RGBT-Crowd-Counting.); 提出了一种双调制框架，通过空间调制注意力和自适应融合，有效提升了RGB-T人群计数在复杂环境下的定位...|
|🆕 发布|A Chain-of-thought Reasoning Breast Ultrasound Dataset Covering All Histopathology Categories|一个涵盖所有组织病理学类别的链式思维推理乳腺超声数据集|Haojun Yu, Youcheng Li, Zihan Niu, Nan Zhang, Xuantong Gong, Huan Li, Zhiying Zou, Haifeng Qi .etc.|<http://arxiv.org/pdf/2509.17046v1>|构建了一个全面覆盖99种病理类型的乳腺超声图像数据集，促进链式思维推理分析以增强AI诊断准确性。|
|📝 更新|AIM 2025 challenge on Inverse Tone Mapping Report: Methods and Results|AIM 2025挑战赛：逆向色调映射研究报告——方法与结果|Chao Wang, Francesco Banterle, Bin Ren, Radu Timofte, Xin Lu, Yufeng Peng, Chengjie Ge, Zhijing Sun .etc.|<http://arxiv.org/pdf/2508.13479v2>|总结了AIM 2025挑战赛中提高HDR图像重建质量的方法，为逆色调映射研究设立了新基准。|

