## [UPDATED!] **2025-09-22** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GraDeT-HTR: A Resource-Efficient Bengali Handwritten Text Recognition System utilizing Grapheme-based Tokenizer and Decoder-only Transformer|基于字素标记器和仅解码器Transformer的轻量级孟加拉手写文本识别系统GraDeT-HTR|Md. Mahmudul Hasan, Ahmed Nesar Tahsin Choudhury, Mahmudul Hasan, Md. Mosaddek Khan|<http://arxiv.org/pdf/2509.18081v1>|提出了一种基于图符分解和Transformer架构的轻量级孟加拉手写文本识别系统，实现了高效准确识别...|
|📝 更新|Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers|“看，聚焦，行动：通过人类注视和中央凹视觉变换器实现高效稳健的机器人学习”|Ian Chuang, Jinyu Zou, Andrew Lee, Dechen Gao, Iman Soltani|<http://arxiv.org/pdf/2507.15833v2>|[代码](https://ian-chuang.github.io/gaze-av-aloha); 提出了一种模仿人类视觉的机器人学习系统，通过集成 gaze 和 foveated Vision Tr...|
|🆕 发布|Overview of PlantCLEF 2025: Multi-Species Plant Identification in Vegetation Quadrat Images|《2025年PlantCLEF概述：植被样方图像中的多物种植物识别》|Giulio Martellucci, Herve Goeau, Pierre Bonnet, Fabrice Vinatier, Alexis Joly|<http://arxiv.org/pdf/2509.17602v1>|提出了一个大规模多物种植物识别挑战，通过弱标注数据集和预训练模型加速生态学研究。|
|🆕 发布|Unified Multimodal Coherent Field: Synchronous Semantic-Spatial-Vision Fusion for Brain Tumor Segmentation|统一多模态协同学场：脑肿瘤分割的同步语义-空间-视觉融合|Mingda Zhang, Yuyang Zheng, Ruixiang Tang, Jingru Qiu, Haiyan Ding|<http://arxiv.org/pdf/2509.17520v1>|提出了一种同步融合视觉、语义和空间信息的UMCF方法，有效提升了脑肿瘤分割的准确性和稳定性。|
|📝 更新|Diversity-Guided MLP Reduction for Efficient Large Vision Transformers|多样性引导的MLP缩减以实现高效的大规模视觉变换器|Chengchao Shen, Hourun Zhu, Gongfan Fang, Jianxin Wang, Xinchao Wang|<http://arxiv.org/pdf/2506.08591v2>|[代码](https://github.com/visresearch/DGMR.); 提出了一种多样性引导的MLP缩减方法，大幅减少大型视觉Transformer参数，实现近无损性能。|
|🆕 发布|Interpreting vision transformers via residual replacement model|通过残差替换模型解释视觉变换器|Jinyeong Kim, Junhyeok Kim, Yumin Shim, Joohyeok Kim, Sunyoung Jung, Seong Jae Hwang|<http://arxiv.org/pdf/2509.17401v1>|提出残差替换模型，解释了视觉变换器如何表示和处理信息，并简化了其计算以增强可解释性。|
|🆕 发布|Pre-Trained CNN Architecture for Transformer-Based Image Caption Generation Model|基于预训练卷积神经网络架构的Transformer图像字幕生成模型|Amanuel Tafese Dufera|<http://arxiv.org/pdf/2509.17365v1>|提出了一种结合EfficientNetB0 CNN和Transformer架构的图像描述生成模型，提...|
|🆕 发布|Revisiting Vision Language Foundations for No-Reference Image Quality Assessment|重新审视视觉语言基础，用于无需参考图像质量评估|Ankit Yadav, Ta Duc Huy, Lingqiao Liu|<http://arxiv.org/pdf/2509.17374v1>|系统评估了六种预训练模型在无参考图像质量评估中的表现，发现激活函数选择对模型泛化能力至关重要，提出了...|
|📝 更新|Walk and Read Less: Improving the Efficiency of Vision-and-Language Navigation via Tuning-Free Multimodal Token Pruning|"少走少读：通过无需调优的多模态标记剪枝提高视觉-语言导航效率"|Wenda Qin, Andrea Burns, Bryan A. Plummer, Margrit Betke|<http://arxiv.org/pdf/2509.15250v2>|提出了一种导航感知的剪枝策略，通过简化输入有效提升了视觉-语言导航任务的效率。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MetaEmbed: Scaling Multimodal Retrieval at Test-Time with Flexible Late Interaction|元嵌入：在测试时通过灵活的后期交互扩展多模态检索|Zilin Xiao, Qi Ma, Mengting Gu, Chun-cheng Jason Chen, Xintao Chen, Vicente Ordonez, Vijai Mohan|<http://arxiv.org/pdf/2509.18095v1>|MetaEmbed通过灵活的测试时多向量交互，实现了大规模多模态检索的效率与性能平衡。|
|📝 更新|Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models|“眼见为实？在多模态大型语言模型中减轻OCR幻觉”|Zhentao He, Can Zhang, Ziheng Wu, Zhenghao Chen, Yufei Zhan, Yifan Li, Zhao Zhang, Xian Wang .etc.|<http://arxiv.org/pdf/2506.20168v2>|提出首个评估OCR幻觉的KIE-HVQA基准，并引入GRPO框架减少视觉不确定性导致的错误回答。|
|📝 更新|Test-Time Multimodal Backdoor Detection by Contrastive Prompting|测试时多模态后门检测的对比性提示方法|Yuwei Niu, Shuo He, Qi Wei, Zongyu Wu, Feng Liu, Lei Feng|<http://arxiv.org/pdf/2405.15269v3>|[代码](https://github.com/Purshow/BDetCLIP.); 提出了一种在推理阶段检测CLIP模型后门攻击的高效方法BDetCLIP，通过对比性提示区分正常与异常...|
|🆕 发布|MRN: Harnessing 2D Vision Foundation Models for Diagnosing Parkinson's Disease with Limited 3D MR Data|MRN：利用2D视觉基础模型在有限3D MR数据下诊断帕金森病|Ding Shaodong, Liu Ziyang, Zhou Yijun, Liu Tao|<http://arxiv.org/pdf/2509.17566v1>|利用2D视觉基础模型处理有限3D MR数据，提高了帕金森病诊断的准确性和泛化能力。|
|📝 更新|MS-YOLO: A Multi-Scale Model for Accurate and Efficient Blood Cell Detection|MS-YOLO：一种用于精确和高效血细胞检测的多尺度模型|Guohua Wu, Shengqi Chen, Pengchao Deng, Wenting Yu|<http://arxiv.org/pdf/2506.03972v2>|提出MS-YOLO模型，通过多尺度模块提升血细胞检测精度和效率。|
|📝 更新|ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding|ViSpec：利用视觉感知的投机解码加速视觉-语言模型|Jialiang Kang, Han Shu, Wenshuo Li, Yingjie Zhai, Xinghao Chen|<http://arxiv.org/pdf/2509.15235v2>|[代码](https://github.com/KangJialiang/ViSpec.); 提出ViSpec框架，通过压缩图像信息和增强文本特征，实现了首个显著的视觉语言模型推理加速。|
|📝 更新|SafeEraser: Enhancing Safety in Multimodal Large Language Models through Multimodal Machine Unlearning|SafeEraser：通过多模态机器遗忘增强多模态大型语言模型的安全性|Junkai Chen, Zhijie Deng, Kening Zheng, Yibo Yan, Shuliang Liu, PeiJun Wu, Peijie Jiang, Jia Liu .etc.|<http://arxiv.org/pdf/2502.12520v3>|提出了一种针对多模态大型语言模型的安全遗忘方法，通过Prompt Decouple Loss减少过度...|
|🆕 发布|Mano Report|手部报告|Tianyu Fu, Anyang Su, Chenxu Zhao, Hanning Wang, Minghui Wu, Zhe Yu, Fei Hu, Mingjia Shi .etc.|<http://arxiv.org/pdf/2509.17336v1>|提出了一种结合多模态基础模型和强化学习的GUI自动化方法，显著提升了交互成功率和操作准确性。|
|📝 更新|Show-o2: Improved Native Unified Multimodal Models|展示-o2：改进的原生统一多模态模型|Jinheng Xie, Zhenheng Yang, Mike Zheng Shou|<http://arxiv.org/pdf/2506.15564v3>|[代码](https://github.com/showlab/Show-o.); 提出了一种统一的多模态模型Show-o2，通过自回归建模和流匹配，有效提升了图像和视频的理解与生成能...|
|📝 更新|GarmentDiffusion: 3D Garment Sewing Pattern Generation with Multimodal Diffusion Transformers|《GarmentDiffusion：基于多模态扩散变换器的三维服装缝制图案生成》|Xinyu Li, Qi Yao, Yuanda Wang|<http://arxiv.org/pdf/2504.21476v4>|[代码](https://shenfu-research.github.io/Garment-Diffusion); 提出GarmentDiffusion模型，通过多模态输入高效生成精确的3D服装裁剪图，大幅提升生成速...|
|📝 更新|The Sound of Simulation: Learning Multimodal Sim-to-Real Robot Policies with Generative Audio|模拟之声：利用生成音频学习多模态仿真到现实机器人策略|Renhao Wang, Haoran Geng, Tingle Li, Feishi Wang, Gopala Anumanchipalli, Trevor Darrell, Boyi Li, Pieter Abbeel .etc.|<http://arxiv.org/pdf/2507.02864v2>|提出了一种融合生成模型和物理模拟器的MultiGen框架，实现了无需真实数据即可进行多模态仿真并成功...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|How Good are Foundation Models in Step-by-Step Embodied Reasoning?|基础模型在逐步具身推理中的表现如何？|Dinura Dissanayake, Ahmed Heakl, Omkar Thawakar, Noor Ahsan, Ritesh Thawkar, Ketan More, Jean Lahoud, Rao Anwer .etc.|<http://arxiv.org/pdf/2509.15293v2>|评估基础模型在复杂环境中逐步推理的能力，并提出相应基准测试和框架。|
|🆕 发布|Semantic and Visual Crop-Guided Diffusion Models for Heterogeneous Tissue Synthesis in Histopathology|异质组织合成中的语义与视觉裁剪引导扩散模型在组织病理学中的应用|Saghir Alfasly, Wataru Uegami, MD Enamul Hoq, Ghazal Alabtah, H. R. Tizhoosh|<http://arxiv.org/pdf/2509.17847v1>|提出了一种结合语义分割图和特定组织视觉块的双重条件生成模型，实现了高质量异质组织病理图像的合成。|
|📝 更新|TennisTV: Do Multimodal Large Language Models Understand Tennis Rallies?|《TennisTV：多模态大型语言模型能理解网球回合吗？》|Zhongyuan Bao, Lejun Zhang|<http://arxiv.org/pdf/2509.15602v2>|提出TennisTV基准，首次全面评估大型多模态语言模型在网球视频理解中的表现，揭示了模型在时间定位...|
|🆕 发布|Accurate and Efficient Low-Rank Model Merging in Core Space|在核心空间中准确且高效地进行低秩模型合并|Aniello Panariello, Daniel Marczak, Simone Magistri, Angelo Porrello, Bartłomiej Twardowski, Andrew D. Bagdanov, Simone Calderara, Joost van de Weijer|<http://arxiv.org/pdf/2509.17786v1>|[代码](https://github.com/apanariello4/core-space-merging.); 提出Core Space框架，高效合并低秩适应模型，保持效率同时显著提升准确性。|
|🆕 发布|DINOv3-Diffusion Policy: Self-Supervised Large Visual Model for Visuomotor Diffusion Policy Learning|DINOv3-扩散策略：用于视觉运动扩散策略学习的自监督大型视觉模型|ThankGod Egbe, Peng Wang, Zhihao Guo, Zidong Chen|<http://arxiv.org/pdf/2509.17684v1>|验证了DINOv3自监督模型在机器人操作中学习动作扩散策略的有效性，提升了任务成功率。|
|🆕 发布|Development and validation of an AI foundation model for endoscopic diagnosis of esophagogastric junction adenocarcinoma: a cohort and deep learning study|内镜诊断食管胃交界腺癌的人工智能基础模型开发与验证：队列研究及深度学习研究|Yikun Ma, Bo Li, Ying Chen, Zijie Yue, Shuchang Xu, Jingyao Li, Lei Ma, Liang Zhong .etc.|<http://arxiv.org/pdf/2509.17660v1>|本研究首次开发并验证了一种基于AI基础模型的内镜图像诊断方法，用于食管胃交界腺癌的筛查和分期诊断，显...|
|🆕 发布|Visual Instruction Pretraining for Domain-Specific Foundation Models|特定领域基础模型的视觉指令预训练|Yuxuan Li, Yicheng Zhang, Wenhao Tang, Yimian Dai, Ming-Ming Cheng, Xiang Li, Jian Yang|<http://arxiv.org/pdf/2509.17562v1>|[代码](https://github.com/zcablii/ViTP.); 提出Visual insTruction Pretraining (ViTP)方法，通过结合高阶推理...|
|📝 更新|Mitigating Hallucinations in Large Vision-Language Models via Entity-Centric Multimodal Preference Optimization|通过实体中心多模态偏好优化减轻大型视觉语言模型中的幻觉现象|Jiulong Wu, Zhengliang Shi, Shuaiqiang Wang, Jizhou Huang, Dawei Yin, Lingyong Yan, Min Cao, Min Zhang|<http://arxiv.org/pdf/2506.04039v2>|提出了一种实体中心的多模态偏好优化方法，有效减少大型视觉语言模型中的幻觉现象。|
|📝 更新|BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent|BTL-UI：面向图形用户界面智能体的眨眼-思考-关联推理模型|Shaojie Zhang, Ruoceng Zhang, Pei Fu, Shaokang Wang, Jiahui Yang, Xin Du, Shiqi Cui, Bin Qin .etc.|<http://arxiv.org/pdf/2509.15566v2>|提出“Blink-Think-Link”框架，模仿人类认知过程，提升AI与图形界面交互的自然性和效率...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-needle Localization for Pelvic Seed Implant Brachytherapy based on Tip-handle Detection and Matching|基于尖端-把手检测与匹配的盆腔种子植入近距离放射治疗多针定位方法|Zhuo Xiao, Fugen Zhou, Jingjing Wang, Chongyu He, Bo Liu, Haitao Sun, Zhe Ji, Yuliang Jiang .etc.|<http://arxiv.org/pdf/2509.17931v1>|提出了一种基于HRNet和贪婪匹配算法的多针定位方法，有效解决了盆腔种子植入术中针定位的难题。|
|🆕 发布|RCTDistill: Cross-Modal Knowledge Distillation Framework for Radar-Camera 3D Object Detection with Temporal Fusion|RCTDistill：基于雷达-相机融合的时序交叉模态知识蒸馏框架用于三维目标检测|Geonho Bang, Minjae Seong, Jisong Kim, Geunju Baek, Daye Oh, Junhyung Kim, Junho Koh, Jun Won Choi|<http://arxiv.org/pdf/2509.17712v1>|提出RCTDistill框架，通过融合雷达与相机数据并引入时间融合与知识蒸馏策略，提升3D物体检测性...|
|🆕 发布|Tailored Transformation Invariance for Industrial Anomaly Detection|为工业异常检测定制的变换不变性|Mariette Schönfeld, Wannes Meert, Hendrik Blockeel|<http://arxiv.org/pdf/2509.17670v1>|[代码](https://github.com/marietteschonfeld/LWinNN); 提出局部窗口最近邻方法LWinNN，平衡工业异常检测中的平移不变性和计算效率。|
|🆕 发布|Domain Adaptive Object Detection for Space Applications with Real-Time Constraints|面向实时约束的空间应用领域自适应目标检测|Samet Hicsonmez, Abd El Rahman Shabayek, Arunkumar Rathinam, Djamila Aouada|<http://arxiv.org/pdf/2509.17593v1>|提出了一种针对实时空间应用的域自适应目标检测方法，通过少量真实数据训练，显著提升了模型在现实世界数据...|
|🆕 发布|An Empirical Study on the Robustness of YOLO Models for Underwater Object Detection|水下目标检测中YOLO模型鲁棒性的实证研究|Edwine Nabahirwa, Wei Song, Minghua Zhang, Shufan Chen|<http://arxiv.org/pdf/2509.17561v1>|系统评估了YOLO模型在 underwater 环境下的鲁棒性，并提出改进策略以增强水下目标检测性能...|
|🆕 发布|Real-Time Fish Detection in Indonesian Marine Ecosystems Using Lightweight YOLOv10-nano Architecture|印度尼西亚海洋生态系统中基于轻量级YOLOv10-nano架构的实时鱼类检测|Jonathan Wuntu, Muhamad Dwisnanto Putro, Rendy Syahputra|<http://arxiv.org/pdf/2509.17406v1>|利用YOLOv10-nano模型实现印尼海域实时鱼类检测，提高监测效率并降低计算需求。|
|📝 更新|GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity|GLSim：通过全局-局部相似性检测轻量级视觉模型中的对象幻觉|Seongheon Park, Yixuan Li|<http://arxiv.org/pdf/2508.19972v2>|提出了一种无需训练的GLSim框架，通过结合全局和局部相似性信号，有效检测大型视觉语言模型中的对象幻...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SmaRT: Style-Modulated Robust Test-Time Adaptation for Cross-Domain Brain Tumor Segmentation in MRI|SmaRT：风格调制稳健测试时适应用于跨域MRI脑肿瘤分割|Yuanhan Wang, Yifei Chen, Shuo Jiang, Wenjing Yu, Mingxuan Liu, Beining Wu, Jinying Zong, Feiwei Qin .etc.|<http://arxiv.org/pdf/2509.17925v1>|[代码](https://github.com/baiyou1234/SmaRT.); 提出SmaRT框架，通过风格调制和稳定策略实现跨领域MRI脑肿瘤分割的准确适应。|
|🆕 发布|Enhancing Semantic Segmentation with Continual Self-Supervised Pre-training|持续自监督预训练增强语义分割|Brown Ebouky, Ajad Chhatkuli, Cristiano Malossi, Christoph Studer, Roy Assaf, Andrea Bartezzaghi|<http://arxiv.org/pdf/2509.17816v1>|提出了一种无监督且数据高效的持续自监督预训练方法GLARE，有效提升语义分割性能。|
|🆕 发布|Depth Edge Alignment Loss: DEALing with Depth in Weakly Supervised Semantic Segmentation|深度边缘对齐损失：在弱监督语义分割中处理深度信息|Patrick Schmidt, Vasileios Belagiannis, Lazaros Nalpantidis|<http://arxiv.org/pdf/2509.17702v1>|提出了一种利用深度边缘对齐损失的方法，通过图像级监督生成像素级标签，有效提升了弱监督语义分割性能。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MOSEv2: A More Challenging Dataset for Video Object Segmentation in Complex Scenes|MOSEv2：复杂场景中视频对象分割的更具挑战性的数据集|Henghui Ding, Kaining Ying, Chang Liu, Shuting He, Xudong Jiang, Yu-Gang Jiang, Philip H. S. Torr, Song Bai|<http://arxiv.org/pdf/2508.05630v2>|MOSEv2构建了一个更具挑战性的复杂场景视频对象分割数据集，揭示了现有方法在现实世界条件下的性能不...|
|🆕 发布|VideoArtGS: Building Digital Twins of Articulated Objects from Monocular Video|视频艺术GS：从单目视频中构建关节对象的数字孪生|Yu Liu, Baoxiong Jia, Ruijie Lu, Chuyue Gan, Huayu Chen, Junfeng Ni, Song-Chun Zhu, Siyuan Huang|<http://arxiv.org/pdf/2509.17647v1>|提出了一种利用单目视频重建高保真数字双生模型的新方法，通过运动先验引导和混合中心-网格分配模块显著提...|
|🆕 发布|Automated Coral Spawn Monitoring for Reef Restoration: The Coral Spawn and Larvae Imaging Camera System (CSLICS)|珊瑚繁殖自动监测系统用于珊瑚礁修复：珊瑚繁殖与幼虫成像相机系统（CSLICS）|Dorian Tsai, Christopher A. Brunner, Riki Lamont, F. Mikaela Nordborg, Andrea Severati, Java Terry, Karen Jackel, Matthew Dunbabin .etc.|<http://arxiv.org/pdf/2509.17299v1>|提出了一种自动化的珊瑚产卵监测系统CSLICS，通过低成本模块化相机和计算机视觉技术实现高效计数，节...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dual-View Alignment Learning with Hierarchical-Prompt for Class-Imbalance Multi-Label Classification|双视角对齐学习结合层级提示用于类别不平衡的多标签分类|Sheng Huang, Jiexuan Yan, Beiyan Liu, Bo Liu, Richang Hong|<http://arxiv.org/pdf/2509.17747v1>|提出了一种利用视觉语言预训练模型的多模态知识缓解多标签分类中的类不平衡问题的新方法HP-DVAL。|
|📝 更新|HyperTTA: Test-Time Adaptation for Hyperspectral Image Classification under Distribution Shifts|超谱图像分类在分布偏移下的测试时自适应方法HyperTTA|Xia Yue, Anfeng Liu, Ning Chen, Chenjia Huang, Hui Liu, Zhou Huang, Leyuan Fang|<http://arxiv.org/pdf/2509.08436v2>|提出了一种针对光谱图像分类的测试时自适应框架HyperTTA，有效应对多种现实世界退化问题。|


## 生成式视觉模型 (Generative Visual Modeling)


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Generating 360° Video is What You Need For a 3D Scene|生成360°视频是您构建三维场景所需的关键|Zhaoyang Zhang, Yannick Hold-Geoffroy, Miloš Hašan, Ziwen Chen, Fujun Luan, Julie Dorsey, Yiwei Hu|<http://arxiv.org/pdf/2504.02045v2>|提出利用360°视频生成技术创建全场景3D环境，实现真实可导航的3D场景重建。|
|📝 更新|SD-VSum: A Method and Dataset for Script-Driven Video Summarization|脚本驱动视频摘要的方法与数据集：SD-VSum|Manolis Mylonas, Evlampios Apostolidis, Vasileios Mezaris|<http://arxiv.org/pdf/2505.03319v2>|提出基于脚本驱动的视频摘要方法SD-VSum，通过视觉与文本信息融合生成满足用户需求的视频摘要。|
|📝 更新|Proxy-Embedding as an Adversarial Teacher: An Embedding-Guided Bidirectional Attack for Referring Expression Segmentation Models|代理嵌入作为对抗性教师：一种基于嵌入引导的双向攻击方法用于指代表达式分割模型|Xingbai Chen, Tingchao Fu, Renyang Liu, Wei Zhou, Chao Yi|<http://arxiv.org/pdf/2506.16157v2>|提出了一种针对指代表达式分割模型的嵌入引导双向攻击方法，有效提高了模型对抗样本的鲁棒性。|
|📝 更新|Safe-Sora: Safe Text-to-Video Generation via Graphical Watermarking|Safe-Sora：通过图形水印实现安全的文本到视频生成|Zihan Su, Xuerui Qiu, Hongbin Xu, Tangyu Jiang, Junhao Zhuang, Chun Yuan, Ming Li, Shengfeng He .etc.|<http://arxiv.org/pdf/2505.12667v2>|[代码](https://github.com/Sugewud/Safe-Sora); 提出Safe-Sora框架，在视频生成过程中嵌入图形水印，通过自适应匹配机制和3D小波变换增强架构，...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Seg4Diff: Unveiling Open-Vocabulary Segmentation in Text-to-Image Diffusion Transformers|Seg4Diff：揭示文本到图像扩散变换器中的开放词汇分割|Chaehyun Kim, Heeseong Shin, Eunbeen Hong, Heeji Yoon, Anurag Arnab, Paul Hongsuck Seo, Sunghwan Hong, Seungryong Kim|<http://arxiv.org/pdf/2509.18096v1>|提出Seg4Diff框架，揭示了扩散变换器中注意力结构对图像生成的作用，并优化了语义分割性能。|
|🆕 发布|Preconditioned Deformation Grids|预条件形变网格|Julian Kaltheuner, Alexander Oebel, Hannah Droege, Patrick Stotko, Reinhard Klein|<http://arxiv.org/pdf/2509.18097v1>|提出了一种无需显式对应关系，利用多分辨率体素网格和Sobolev预调优直接从点云序列估计连贯变形场的...|
|🆕 发布|ContextFlow: Training-Free Video Object Editing via Adaptive Context Enrichment|自适应上下文增强的无训练视频对象编辑：ContextFlow|Yiyang Chen, Xuanhua He, Xiujun Ma, Yue Ma|<http://arxiv.org/pdf/2509.17818v1>|提出ContextFlow框架，通过自适应上下文增强实现无需训练的视频对象编辑，提高了编辑精确度和时...|
|🆕 发布|From Restoration to Reconstruction: Rethinking 3D Gaussian Splatting for Underwater Scenes|从恢复到重建：重新思考水下场景的三维高斯散点绘制|Guoxi Huang, Haoran Wang, Zipeng Qi, Wenjun Lu, David Bull, Nantheera Anantrasirichai|<http://arxiv.org/pdf/2509.17789v1>|提出了一种统一框架R-Splatting，结合水下图像修复与3D高斯散点渲染，提升水下场景的渲染质量...|
|🆕 发布|Degradation-Aware All-in-One Image Restoration via Latent Prior Encoding|通过潜在先验编码实现的退化感知一体化图像复原|S M A Sharif, Abdur Rehman, Fayaz Ali Dharejo, Radu Timofte, Rizwan Ali Naqvi|<http://arxiv.org/pdf/2509.17792v1>|提出了一种无需外部提示或预设架构先验的图像复原方法，通过自动推断退化感知表征，实现了更高效的图像复原...|
|🆕 发布|Tensor-Based Self-Calibration of Cameras via the TrifocalCalib Method|基于张量的摄像机自校准方法——三焦距校准法|Gregory Schroeder, Mohamed Sabry, Cristina Olaverri-Monreal|<http://arxiv.org/pdf/2509.17620v1>|提出了一种无需场景先验知识的相机自校准方法TrifocalCalib，提高了准确性和鲁棒性。|
|📝 更新|X-GAN: A Generative AI-Powered Unsupervised Model for Main Vessel Segmentation of Glaucoma Screening|X-GAN：一种生成式AI驱动的青光眼筛查主血管分割无监督模型|Cheng Huang, Weizheng Xie, Tsengdar J. Lee, Jui-Kai Wang, Karanjit Kooner, Ning Zhang, Jia Zhang|<http://arxiv.org/pdf/2503.06743v5>|提出了一种无需标注数据的生成式AI模型X-GAN，实现了高精度视网膜主血管分割。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ComposeMe: Attribute-Specific Image Prompts for Controllable Human Image Generation|《ComposeMe：用于可控人类图像生成的属性特定图像提示》|Guocheng Gordon Qian, Daniil Ostashev, Egor Nemchinov, Avihay Assouline, Sergey Tulyakov, Kuan-Chieh Jackson Wang, Kfir Aberman|<http://arxiv.org/pdf/2509.18092v1>|[代码](https://snap-research.github.io/composeme); 提出了一种基于特定属性图像提示的方法，实现了对人类图像发色、服饰等属性的精细控制。|
|📝 更新|Contextual Gesture: Co-Speech Gesture Video Generation through Context-aware Gesture Representation|基于上下文的姿态：通过上下文感知姿态表征实现的同声姿态视频生成|Pinxin Liu, Pengfei Zhang, Hyeongwoo Kim, Pablo Garrido, Ari Shapiro, Kyle Olszewski|<http://arxiv.org/pdf/2502.07239v3>|提出了一种同步语音与手势的生成框架，通过结合时间对齐、上下文感知的表征和结构化细化，实现了更真实和同...|
|🆕 发布|I2VWM: Robust Watermarking for Image to Video Generation|I2VWM：面向图像到视频生成的鲁棒水印技术|Guanjie Wang, Zehua Ma, Han Fang, Weiming Zhang|<http://arxiv.org/pdf/2509.17773v1>|[代码](https://github.com/MrCrims/I2VWM-Robust-Watermarking-for-Image-to-Video-Generation); 提出了一种跨模态水印框架I2VWM，通过增强水印在生成视频中的时间持久性，有效解决了图像到视频生成中...|
|🆕 发布|Qwen3-Omni Technical Report|Qwen3-全向技术报告|Jin Xu, Zhifang Guo, Hangrui Hu, Yunfei Chu, Xiong Wang, Jinzheng He, Yuxuan Wang, Xian Shi .etc.|<http://arxiv.org/pdf/2509.17765v1>|Qwen3-Omni首次实现跨文本、图像、音频和视频的多模态模型，性能达到单模态水平且在音频任务上表...|
|🆕 发布|Multi-Agent Amodal Completion: Direct Synthesis with Fine-Grained Semantic Guidance|多智能体隐式补全：细粒度语义指导下的直接合成|Hongxing Fan, Lipeng Wang, Haohua Chen, Zehuan Huang, Jiangtao Wu, Lu Sheng|<http://arxiv.org/pdf/2509.17757v1>|提出多代理协同推理框架，通过精细语义指导直接合成被遮挡物体的不可见部分，实现高质量图像修复。|
|🆕 发布|Neurodynamics-Driven Coupled Neural P Systems for Multi-Focus Image Fusion|神经动力学驱动的耦合神经网络P系统用于多焦点图像融合|Bo Li, Yunkuo Lei, Tingting Bao, Yaxian Wang, Lingling Zhang, Jun Liu|<http://arxiv.org/pdf/2509.17704v1>|[代码](https://github.com/MorvanLi/ND-CNPFuse.); 提出了一种基于神经动态驱动的耦合神经网络模型，用于生成高质量的多焦点图像融合决策图。|
|📝 更新|LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation|LRQ-DiT：对数旋转后训练量化扩散变换器以实现图像和视频生成|Lianwei Yang, Haokun Lin, Tianchen Zhao, Yichen Wu, Hongyu Zhu, Ruiqi Xie, Zhenan Sun, Yu Wang .etc.|<http://arxiv.org/pdf/2508.03485v2>|提出了一种针对图像和视频生成的Log-Rotation后训练量化框架，有效解决了低比特量化导致的性能...|
|📝 更新|Photography Perspective Composition: Towards Aesthetic Perspective Recommendation|摄影视角构图：迈向审美视角推荐|Lujian Yao, Siming Zheng, Xinbin Yuan, Zhuoxuan Cai, Pu Wu, Jinwei Chen, Bo Li, Peng-Tao Jiang|<http://arxiv.org/pdf/2505.20655v2>|提出摄影视角构图方法，通过专家照片自动构建数据集并评估视角质量，提升摄影构图美感。|
|📝 更新|SCORP: Scene-Consistent Object Refinement via Proxy Generation and Tuning|SCORP：通过代理生成与调整实现场景一致的对象细化|Ziwei Chen, Ziling Liu, Zitong Huang, Mingqi Gao, Feng Zheng|<http://arxiv.org/pdf/2506.23835v2>|[代码](https://github.com/PolySummit/SCORP.); 提出了一种通过代理生成与调整实现场景一致性的三维对象细化方法，有效解决了视角缺失导致的对象重建精度问...|
|🆕 发布|Multi-scale Temporal Prediction via Incremental Generation and Multi-agent Collaboration|通过增量生成与多智能体协作的多尺度时间预测|Zhitao Zeng, Guojian Yuan, Junyuan Mao, Yuxuan Wang, Xiaoshuang Jia, Yueming Jin|<http://arxiv.org/pdf/2509.17429v1>|提出了一种多尺度时序预测方法IG-MC，通过逐步生成和多方协作，实现了对场景状态的精准预测。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation|协同STAR：基于自适应正则化的协作课程自训练，用于无需源域的视频域自适应|Amirhossein Dadashzadeh, Parsa Esmati, Majid Mirmehdi|<http://arxiv.org/pdf/2504.11669v2>|[代码](https://github.com/Plrbear/Co-Star); 提出了Co-STAR框架，通过结合课程学习和协同自训练，有效应对了无源视频域自适应中的噪声伪标签和过...|
|🆕 发布|StableGuard: Towards Unified Copyright Protection and Tamper Localization in Latent Diffusion Models|《StableGuard：面向潜在扩散模型中统一版权保护和篡改定位》|Haoxin Yang, Bangzhen Liu, Xuemiao Xu, Cheng Xu, Yuyang Yu, Zikai Huang, Yi Wang, Shengfeng He|<http://arxiv.org/pdf/2509.17993v1>|提出StableGuard框架，将版权保护和篡改定位无缝集成到生成过程，提升AI生成内容的版权保护和...|
|🆕 发布|ComposableNav: Instruction-Following Navigation in Dynamic Environments via Composable Diffusion|可组合导航：通过可组合扩散在动态环境中遵循指令的导航|Zichao Hu, Chen Tang, Michael J. Munje, Yifeng Zhu, Alex Liu, Shuijing Liu, Garrett Warnell, Peter Stone .etc.|<http://arxiv.org/pdf/2509.17941v1>|提出了一种基于分解学习与组合策略的导航方法，使机器人在动态环境中有效遵循复杂指令。|
|🆕 发布|SISMA: Semantic Face Image Synthesis with Mamba|SISMA：基于Mamba的语义人脸图像合成|Filippo Botti, Alex Ergasti, Tomaso Fontanini, Claudio Ferrari, Massimo Bertozzi, Andrea Prati|<http://arxiv.org/pdf/2509.17651v1>|提出了一种基于Mamba的轻量级架构SISMA，通过语义掩码控制形状，实现了高效生成高质量人脸图像。|
|🆕 发布|Clothing agnostic Pre-inpainting Virtual Try-ON|服装无关预修复虚拟试穿|Sehyun Kim, Hye Jun Lee, Jiwoo Lee, Taemin Lee|<http://arxiv.org/pdf/2509.17654v1>|提出CaP-VTON方法，通过多类别遮罩和稳定扩散皮肤修复，提高了全身虚拟试衣的自然度和一致性。|
|📝 更新|Single-step Diffusion for Image Compression at Ultra-Low Bitrates|单步扩散用于超低比特率下的图像压缩|Chanung Park, Joo Chan Lee, Jong Hwan Ko|<http://arxiv.org/pdf/2506.16572v2>|提出了一种单步扩散模型，实现了在极低比特率下图像压缩的高感知质量和快速解码。|
|📝 更新|DiCo: Revitalizing ConvNets for Scalable and Efficient Diffusion Modeling|DiCo: 用于可扩展和高效扩散建模的卷积神经网络复兴|Yuang Ai, Qihang Fan, Xuefeng Hu, Zhenheng Yang, Ran He, Huaibo Huang|<http://arxiv.org/pdf/2505.11196v2>|[代码](https://github.com/shallowdream204/DiCo.); 提出了一种基于卷积的扩散模型DiCo，有效提升了生成图像的性能并显著降低了计算成本。|
|🆕 发布|OmniInsert: Mask-Free Video Insertion of Any Reference via Diffusion Transformer Models|全方位插入：通过扩散变换模型实现无需遮罩的任意参考视频插入|Jinshu Chen, Xinghui Li, Xu Bai, Tianxiang Ma, Pengze Zhang, Zhuowei Chen, Gen Li, Lijie Liu .etc.|<http://arxiv.org/pdf/2509.17627v1>|提出了一种无需蒙版的视频插入方法OmniInsert，通过构建自动数据管道和优化策略解决了数据稀缺、...|
|🆕 发布|SimToken: A Simple Baseline for Referring Audio-Visual Segmentation|SimToken：一种用于引用音频视觉分割的简单基线|Dian Jin, Yanghao Zhou, Jinxing Zhou, Jiaqi Ma, Ruohao Guo, Dan Guo|<http://arxiv.org/pdf/2509.17537v1>|[代码](https://github.com/DianJin-HFUT/SimToken); 提出了一种融合多模态大语言模型与Segment Anything模型的简单框架SimToken，有效...|
|📝 更新|Alias-Free Latent Diffusion Models: Improving Fractional Shift Equivariance of Diffusion Latent Space|无混叠 latent 扩散模型：提高扩散隐空间的分数平移等价性|Yifan Zhou, Zeqi Xiao, Shuai Yang, Xingang Pan|<http://arxiv.org/pdf/2503.09419v2>|提出了一种改进的潜在扩散模型，通过增强位移等变性，显著提高了生成过程的稳定性与一致性。|
|🆕 发布|Stable Video-Driven Portraits|稳定的视频驱动肖像|Mallikarjun B. R., Fei Yin, Vikram Voleti, Nikita Drobyshev, Maksim Lapin, Aaryaman Vasishta, Varun Jampani|<http://arxiv.org/pdf/2509.17476v1>|提出了一种基于扩散模型和面部关键区域控制的肖像动画方法，实现了高质感和高一致性的视频驱动肖像生成。|
|🆕 发布|CARINOX: Inference-time Scaling with Category-Aware Reward-based Initial Noise Optimization and Exploration|CARINOX：基于类别感知的奖励优化和探索的推理时缩放|Seyed Amir Kasaei, Ali Aghayari, Arash Marioriyad, Niki Sepasian, Shayan Baghayi Nejad, MohammadAmin Fazli, Mahdieh Soleymani Baghshah, Mohammad Hossein Rohban|<http://arxiv.org/pdf/2509.17458v1>|提出了一种结合噪声优化与探索的CARINOX框架，有效提升了文本到图像的组成对齐度。|
|📝 更新|Dynamic Classifier-Free Diffusion Guidance via Online Feedback|动态无分类器扩散引导通过在线反馈|Pinelopi Papalampidi, Olivia Wiles, Ira Ktena, Aleksandar Shtedritski, Emanuele Bugliarello, Ivana Kajic, Isabela Albuquerque, Aida Nematzadeh|<http://arxiv.org/pdf/2509.16131v2>|提出动态调整文本到图像生成过程中的指导尺度方法，通过实时反馈优化生成质量。|
|🆕 发布|Diff-GNSS: Diffusion-based Pseudorange Error Estimation|基于扩散的伪距误差估计：Diff-GNSS|Jiaqi Zhu, Shouyi Lu, Ziyao Li, Guirong Zhuo, Lu Xiong|<http://arxiv.org/pdf/2509.17397v1>|提出了一种基于扩散模型的高精度伪距误差估计框架，有效解决了GNSS测量误差问题。|
|🆕 发布|Single-Image Depth from Defocus with Coded Aperture and Diffusion Posterior Sampling|单张图像基于散焦的深度估计：编码光阑与扩散后验采样|Hodaka Kawachi, Jose Reinaldo Cunha Santos A. V. Silva Neto, Yasushi Yagi, Hajime Nagahara, Tomoya Nakamura|<http://arxiv.org/pdf/2509.17427v1>|提出了一种利用学习型扩散先验替代传统手工先验的单幅图像深度重建方法，提高了重建精度和稳定性。|
|🆕 发布|UIPro: Unleashing Superior Interaction Capability For GUI Agents|UIPro：为图形用户界面智能体释放卓越的交互能力|Hongxin Li, Jingran Su, Jingfan Chen, Zheng Ju, Yuntao Chen, Qing Li, Zhaoxiang Zhang|<http://arxiv.org/pdf/2509.17328v1>|提出了UIPro，一种基于大规模多平台和多任务数据训练的通用GUI代理，实现了统一的动作空间，显著提...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction|地理稀疏体素驯服：实现几何精确表面重建|Jiahe Li, Jiawei Zhang, Youmin Zhang, Xiao Bai, Jin Zheng, Xiaohan Yu, Lin Gu|<http://arxiv.org/pdf/2509.18090v1>|[代码](https://github.com/Fictionarry/GeoSVR.); 提出GeoSVR方法，利用稀疏体素实现精确、详细且完整的表面重建。|
|🆕 发布|ProDyG: Progressive Dynamic Scene Reconstruction via Gaussian Splatting from Monocular Videos|单目视频通过高斯散点绘制进行渐进式动态场景重建：ProDyG|Shi Chen, Erik Sandström, Sandro Lombardi, Siyuan Li, Martin R. Oswald|<http://arxiv.org/pdf/2509.17864v1>|提出了一种在线动态场景重建方法，通过分离静态和动态部分，实现了全局一致性和细节丰富的三维重建。|
|🆕 发布|Neural-MMGS: Multi-modal Neural Gaussian Splats for Large-Scale Scene Reconstruction|神经多模态高斯泼洒：用于大规模场景重建的多模态神经高斯泼洒|Sitian Shen, Georgi Pramatarov, Yifu Tao, Daniele De Martini|<http://arxiv.org/pdf/2509.17762v1>|提出了一种多模态神经高斯溅射框架，将图像、LiDAR和语义信息融合于紧凑可学习的嵌入中，实现大规模场...|
|📝 更新|BaseBoostDepth: Exploiting Larger Baselines For Self-supervised Monocular Depth Estimation|基于BaseBoostDepth的自监督单目深度估计：利用更大基线提升性能|Kieran Saunders, Luis J. Manso, George Vogiatzis|<http://arxiv.org/pdf/2407.20437v2>|[代码](https://kieran514.github.io/BaseBoostDepth-Project.); 利用课程学习优化策略和增量姿态估计，BaseBoostDepth方法有效利用大基线提升单目深度估计精...|
|🆕 发布|SmokeSeer: 3D Gaussian Splatting for Smoke Removal and Scene Reconstruction|烟雾洞察者：基于三维高斯散点法的烟雾移除与场景重建|Neham Jain, Andrew Jong, Sebastian Scherer, Ioannis Gkioulekas|<http://arxiv.org/pdf/2509.17329v1>|提出了一种融合热成像与RGB图像的3D场景重建与烟雾移除方法，有效处理不同密度和动态烟雾。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MS-GS: Multi-Appearance Sparse-View 3D Gaussian Splatting in the Wild|MS-GS：野外多外观稀疏视图三维高斯散点绘制|Deming Li, Kaiwen Jiang, Yutao Tang, Ravi Ramamoorthi, Rama Chellappa, Cheng Peng|<http://arxiv.org/pdf/2509.15548v2>|提出MS-GS框架，利用3D Gaussian Splatting处理多形态稀疏视图场景，增强场景重...|
|🆕 发布|Learning Neural Antiderivatives|学习神经反导数|Fizza Rubab, Ntumba Elie Nsampi, Martin Balint, Felix Mujkanovic, Hans-Peter Seidel, Tobias Ritschel, Thomas Leimkühler|<http://arxiv.org/pdf/2509.17755v1>|提出学习连续函数的神经反导数表示方法，扩展了传统累积运算在连续神经场景中的应用。|
|🆕 发布|Emergent 3D Correspondence from Neural Shape Representation|从神经形状表示中涌现的3D对应关系|Keyu Du, Jingyu Hu, Haipeng Li, Hao Xu, Haibing Huang, Chi-Wing Fu, Shuaicheng Liu|<http://arxiv.org/pdf/2509.17431v1>|提出了一种分层神经语义表示方法，通过全局和局部特征结合，实现了准确且鲁棒的3D语义对应估计。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs|基于强化微调的有效时间采样方法TempSamp-R1：用于视频大规模语言模型|Yunheng Li, Jing Cheng, Shaoyong Jia, Hangyi Kuang, Shaohui Jiao, Qibin Hou, Ming-Ming Cheng|<http://arxiv.org/pdf/2509.18056v1>|[代码](https://github.com/HVision-NKU/TempSamp-R1); TempSamp-R1通过结合强化学习和真实标注，优化了视频时序定位任务中大规模语言模型的适应效果。|
|🆕 发布|4DGCPro: Efficient Hierarchical 4D Gaussian Compression for Progressive Volumetric Video Streaming|4DGCPro：高效分层4D高斯压缩用于渐进式体视频流传输|Zihan Zheng, Zhenlong Wu, Houqiang Zhong, Yuan Tian, Ning Cao, Lan Xu, Jiangchao Yao, Xiaoyun Zhang .etc.|<http://arxiv.org/pdf/2509.17513v1>|[代码](https://mediax-sjtu.github.io/4DGCPro); 提出了一种高效的4D高斯压缩框架，实现实时移动解码与高质量渲染的渐进式体视频流传输。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Trainee Action Recognition through Interaction Analysis in CCATT Mixed-Reality Training|通过在CCATT混合现实训练中的交互分析进行学员动作识别|Divya Mereddy, Marcos Quinones-Grueiro, Ashwin T S, Eduardo Davalos, Gautam Biswas, Kent Etherton, Tyler Davis, Katelyn Kay .etc.|<http://arxiv.org/pdf/2509.17888v1>|提出了一种结合认知任务分析和多模态学习分析的评估框架，通过追踪训练员与设备的互动来自动评估医疗团队表...|
|🆕 发布|A$^2$M$^2$-Net: Adaptively Aligned Multi-Scale Moment for Few-Shot Action Recognition|A$^2$M$^2$-Net：自适应对齐多尺度矩用于少样本动作识别|Zilin Gao, Qilong Wang, Bingbing Zhang, Qinghua Hu, Peihua Li|<http://arxiv.org/pdf/2509.17638v1>|提出了一种自适应对齐的多尺度二阶矩网络A$^2$M$^2$-Net，有效解决了视频动作识别中的时间对...|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|TextOCVP: Object-Centric Video Prediction with Language Guidance|基于语言指导的目标中心视频预测：TextOCVP|Angel Villar-Corrales, Gjergj Plepi, Sven Behnke|<http://arxiv.org/pdf/2502.11655v2>|[代码](https://play-slot.github.io/TextOCVP.); 提出TextOCVP模型，通过文本指导预测未来场景状态，提升机器人环境适应性和预测准确性。|
|🆕 发布|SAMSON: 3rd Place Solution of LSVOS 2025 VOS Challenge|SAMSON：2025年LSVOS视频分割挑战第三名解决方案|Yujie Xie, Hongyang Zhang, Zhihui Liu, Shihai Ruan|<http://arxiv.org/pdf/2509.17500v1>|提出SAMSON方法，结合先进VOS模型优势，引入长期记忆模块应对视频对象分割挑战。|
|🆕 发布|DepTR-MOT: Unveiling the Potential of Depth-Informed Trajectory Refinement for Multi-Object Tracking|深度引导轨迹细化在多目标跟踪中的潜力揭示：DepTR-MOT|Buyin Deng, Lingxin Huang, Kai Luo, Fei Teng, Kailun Yang|<http://arxiv.org/pdf/2509.17323v1>|[代码](https://github.com/warriordby/DepTR-MOT.); 提出利用深度信息优化多目标跟踪，通过软深度标签监督和深度图蒸馏增强跟踪鲁棒性。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TS-P$^2$CL: Plug-and-Play Dual Contrastive Learning for Vision-Guided Medical Time Series Classification|TS-P$^2$CL：用于视觉引导医疗时间序列分类的即插即用双重对比学习|Qi'ao Xu, Pengfei Wang, Bo Zhong, Tianwen Qian, Xiaoling Wang, Ye Wang, Hong Yu|<http://arxiv.org/pdf/2509.17802v1>|提出了一种将一维生理信号转化为二维伪图像并利用预训练视觉模型进行双对比学习的框架，有效克服了个体差异...|
|🆕 发布|MAESTRO: Task-Relevant Optimization via Adaptive Feature Enhancement and Suppression for Multi-task 3D Perception|MAESTRO：通过自适应特征增强与抑制实现多任务三维感知的任务相关优化|Changwon Kang, Jisong Kim, Hongjae Shin, Junseo Park, Jun Won Choi|<http://arxiv.org/pdf/2509.17462v1>|MAESTRO通过自适应特征增强与抑制，有效解决多任务学习中的任务冲突，提升3D感知性能。|
|📝 更新|VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in Real-time MRI|VocSegMRI：实时MRI中精确声 tract 分割的多模态学习|Daiqi Liu, Tomás Arias-Vergara, Johannes Enk, Fangxu Xing, Maureen Stone, Jerry L. Prince, Jana Hutter, Andreas Maier .etc.|<http://arxiv.org/pdf/2509.13767v2>|提出了一种融合视频、音频和语音学信息的多模态框架，实现了实时MRI中精确的发音器官分割。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Joint Optimization of Memory Frequency, Computing Frequency, Transmission Power and Task Offloading for Energy-efficient DNN Inference|针对能量效率的深度神经网络推理的内存频率、计算频率、传输功率与任务卸载联合优化|Yunchu Han, Zhaojun Nan, Sheng Zhou, Zhisheng Niu|<http://arxiv.org/pdf/2509.17970v1>|提出了一种联合优化内存频率和计算频率的方法，有效降低深度神经网络推断能耗。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SINF: Semantic Neural Network Inference with Semantic Subgraphs|语义神经网络推理中的语义子图推断|A. Q. M. Sazzad Sayyed, Francesco Restuccia|<http://arxiv.org/pdf/2310.01259v3>|提出SINF方法，通过创建语义子图减少神经网络计算负荷，实现高效推理。|
|🆕 发布|Selecting Optimal Camera Views for Gait Analysis: A Multi-Metric Assessment of 2D Projections|选择最优摄像头视角进行步态分析：基于二维投影的多指标评估|Dong Chen, Huili Peng, Yong Hu, Kenneth MC. Cheung|<http://arxiv.org/pdf/2509.17805v1>|系统评估了不同摄像头视角对2D步态分析准确性的影响，发现侧视角对矢状面运动、正前视角对躯干对称性分析...|
|🆕 发布|Incorporating the Refractory Period into Spiking Neural Networks through Spike-Triggered Threshold Dynamics|将不应期融入尖峰神经网络通过尖峰触发阈值动力学|Yang Li, Xinyi Zeng, Zhe Xue, Pinxian Zeng, Zikai Zhang, Yan Wang|<http://arxiv.org/pdf/2509.17769v1>|提出方法将不应期融入LIF神经元，增强鲁棒性和效率，实现低延迟下性能最优。|
|📝 更新|PPORLD-EDNetLDCT: A Proximal Policy Optimization-Based Reinforcement Learning Framework for Adaptive Low-Dose CT Denoising|基于近端策略优化的自适应低剂量CT去噪强化学习框架：PPORLD-EDNetLDCT|Debopom Sutradhar, Ripon Kumar Debnath, Mohaimenul Azam Khan Raiaan, Yan Zhang, Reem E. Mohamed, Sami Azam|<http://arxiv.org/pdf/2509.03185v2>|提出了一种基于强化学习的自适应低剂量CT降噪框架，有效提升了图像质量和降噪效果。|
|🆕 发布|PRNU-Bench: A Novel Benchmark and Model for PRNU-Based Camera Identification|PRNU-Bench：一种基于PRNU的相机识别新型基准和模型|Florinel Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu|<http://arxiv.org/pdf/2509.17581v1>|[代码](https://github.com/CroitoruAlin/PRNU-Bench.); 提出了一种基于PRNU估计的相机识别新基准和模型，通过混合架构显著提升了识别准确性。|
|📝 更新|DynSTG-Mamba: Dynamic Spatio-Temporal Graph Mamba with Cross-Graph Knowledge Distillation for Gait Disorders Recognition|动态时空图Mamba：基于跨图知识蒸馏的步态障碍识别|Zakariae Zrimek, Youssef Mourchid, Mohammed El Hassouni|<http://arxiv.org/pdf/2503.13156v2>|提出了一种动态时空图框架DynSTG-Mamba，通过自适应调整骨骼关节的时空连接，有效提升了步态障...|
|🆕 发布|CSDformer: A Conversion Method for Fully Spike-Driven Transformer|CSDformer：一种全尖峰驱动转换器的转换方法|Yuhao Zhang, Chengjun Zhang, Di Wu, Jie Yang, Mohamad Sawan|<http://arxiv.org/pdf/2509.17461v1>|提出CSDformer转换方法，将标准Transformer模型高效转换为低功耗的完全脉冲驱动模型，...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|3D Cell Oversegmentation Correction via Geo-Wasserstein Divergence|通过Geo-Wasserstein散度进行三维细胞过分割修正|Peter Chen, Bryan Chang, Olivia Annette Creasey, Julie Beth Sneddon, Zev Gartner, Yining Liu|<http://arxiv.org/pdf/2502.01890v3>|提出了一种几何框架和Geo-Wasserstein散度度量，有效纠正3D细胞分割中的过分割问题。|
|🆕 发布|TASO: Task-Aligned Sparse Optimization for Parameter-Efficient Model Adaptation|任务对齐的稀疏优化：用于参数高效模型适应|Daiye Miao, Yufang Liu, Jie Wang, Changzhi Sun, Yunke Zhang, Demei Yan, Shaokang Dong, Qi Zhang .etc.|<http://arxiv.org/pdf/2509.17688v1>|提出TASO方法，通过识别并消除LoRA参数冗余，提高模型适应任务的参数效率。|
|🆕 发布|FROQ: Observing Face Recognition Models for Efficient Quality Assessment|FROQ：观察人脸识别模型进行高效质量评估|Žiga Babnik, Deepak Kumar Jain, Peter Peer, Vitomir Štruc|<http://arxiv.org/pdf/2509.17689v1>|提出了一种无需训练、基于现有人脸识别模型中间表示的半监督人脸图像质量评估方法，实现了高效准确的质量评...|
|📝 更新|AD-GS: Alternating Densification for Sparse-Input 3D Gaussian Splatting|AD-GS: 稀疏输入三维高斯散点绘制交替加密方法|Gurutva Patle, Nilay Girgaonkar, Nagabhushan Somraj, Rajiv Soundararajan|<http://arxiv.org/pdf/2509.11003v2>|[代码](https://gurutvapatle.github.io/publications); 提出了一种交替密集化框架AD-GS，通过控制模型容量增长改善稀疏输入下的3D高斯渲染质量和几何一致性...|
|🆕 发布|4D-MoDe: Towards Editable and Scalable Volumetric Streaming via Motion-Decoupled 4D Gaussian Compression|4D-MoDe：通过运动解耦4D高斯压缩实现可编辑和可扩展的体素流传输|Houqiang Zhong, Zihan Zheng, Qiang Hu, Yuan Tian, Ning Cao, Lan Xu, Xiaoyun Zhang, Zhengxue Cheng .etc.|<http://arxiv.org/pdf/2509.17506v1>|提出了一种分离动态前景与静态背景的四维高斯压缩框架，实现了高质量可编辑的体视频流传输。|
|📝 更新|IPGPhormer: Interpretable Pathology Graph-Transformer for Survival Analysis|IPGPhormer：可解释的病理图-变压器模型用于生存分析|Guo Tang, Songhan Jiang, Jinpeng Lu, Linghan Cai, Yongbing Zhang|<http://arxiv.org/pdf/2508.12381v2>|提出了一种新的病理图像分析框架IPGPhormer，通过图-Transformer结构同时建模长距离...|
|📝 更新|MolX: Enhancing Large Language Models for Molecular Understanding With A Multi-Modal Extension|MolX：通过多模态扩展增强大型语言模型对分子的理解能力|Khiem Le, Zhichun Guo, Kaiwen Dong, Xiaobao Huang, Bozhao Nan, Roshni Iyer, Xiangliang Zhang, Olaf Wiest .etc.|<http://arxiv.org/pdf/2406.06777v9>|提出多模态扩展MolX，增强大型语言模型对分子的理解能力，提升化学领域任务表现。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Show and Tell: Visually Explainable Deep Neural Nets via Spatially-Aware Concept Bottleneck Models|《展示与讲述：通过空间感知概念瓶颈模型的视觉可解释深度神经网络》|Itay Benou, Tammy Riklin-Raviv|<http://arxiv.org/pdf/2502.20134v4>|提出了一种将任意视觉神经网络转化为具有空间和概念可解释性的模型的方法，通过引入无需人工标签的“空间感...|
|🆕 发布|Overview of PlantCLEF 2022: Image-based plant identification at global scale|《2022年PlantCLEF概述：基于图像的全球尺度植物识别》|Herve Goeau, Pierre Bonnet, Alexis Joly|<http://arxiv.org/pdf/2509.17632v1>|概述了PlantCLEF 2022挑战，通过大规模多图像分类推动全球植物种类的自动识别。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Automated Labeling of Intracranial Arteries with Uncertainty Quantification Using Deep Learning|使用深度学习进行颅内动脉自动标注及不确定性量化|Javier Bisbal, Patrick Winter, Sebastian Jofre, Aaron Ponce, Sameer A. Ansari, Ramez Abdalla, Michael Markl, Oliver Welin Odeback .etc.|<http://arxiv.org/pdf/2509.17726v1>|提出了一种基于深度学习的自动标记颅内动脉方法，通过不确定性量化增强了标注的可靠性和解释性。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RECON: Robust symmetry discovery via Explicit Canonical Orientation Normalization|通过显式规范方向归一化实现的鲁棒对称性发现：RECON|Alonso Urbano, David W. Romero, Max Zimmer, Sebastian Pokutta|<http://arxiv.org/pdf/2505.13289v2>|提出RECON方法，通过数据对齐的规范方向归一化，实现了实例特定对称性的无监督发现和模型不变性增强。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Overview of PlantCLEF 2023: Image-based Plant Identification at Global Scale|《2023年PlantCLEF概述：基于图像的全球尺度植物识别》|Herve Goeau, Pierre Bonnet, Alexis Joly|<http://arxiv.org/pdf/2509.17622v1>|概述了PlantCLEF 2023挑战，推动全球植物种类自动识别技术的发展。|
|🆕 发布|Explainable AI for Analyzing Person-Specific Patterns in Facial Recognition Tasks|面向面部识别任务中分析特定人物模式的可解释人工智能|Paweł Jakub Borsukiewicz, Jordan Samhi, Jacques Klein, Tegawendé F. Bissyandé|<http://arxiv.org/pdf/2509.17457v1>|提出了一种个体化解释性AI技术LEAM，揭示了面部识别模型中个体特有识别模式，为定制化隐私保护研究奠...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Intra-Cluster Mixup: An Effective Data Augmentation Technique for Complementary-Label Learning|簇内混合：一种用于互补标签学习的有效数据增强技术|Tan-Ha Mai, Hsuan-Tien Lin|<http://arxiv.org/pdf/2509.17971v1>|提出了一种针对互补标签学习的数据增强方法Intra-Cluster Mixup，有效减少了噪声并显著...|
|🆕 发布|Breaking the Discretization Barrier of Continuous Physics Simulation Learning|打破连续物理仿真学习离散化壁垒|Fan Xu, Hao Wu, Nan Wang, Lilan Peng, Kun Wang, Wei Gong, Xibin Zhao|<http://arxiv.org/pdf/2509.17955v1>|提出了一种数据驱动的方法CoPS，有效克服了物理模拟学习中的离散化限制，实现了对连续物理动态的精确建...|
|📝 更新|DISCO: Mitigating Bias in Deep Learning with Conditional Distance Correlation|DISCO：利用条件距离相关减少深度学习中的偏见|Emre Kavak, Tom Nuno Wolf, Christian Wachinger|<http://arxiv.org/pdf/2506.11653v2>|[代码](https://Source Code: https://github.com/***.); 提出了一种基于因果理论的DISCO方法，有效减少深度学习模型中的数据集偏差，提高了预测的稳健性。|
|🆕 发布|Chat-CBM: Towards Interactive Concept Bottleneck Models with Frozen Large Language Models|Chat-CBM：面向交互式概念瓶颈模型与冻结大型语言模型的结合|Hangzhou He, Lei Zhu, Kaiwen Li, Xinliang Zhang, Jiakui Hu, Ourui Fu, Zhengjian Yao, Yanye Lu|<http://arxiv.org/pdf/2509.17522v1>|提出Chat-CBM模型，利用大语言模型实现概念级交互，增强预测准确性和用户干预能力。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|COLA: Context-aware Language-driven Test-time Adaptation|COLA: 基于上下文的语言驱动测试时适应|Aiming Zhang, Tianyuan Yu, Liang Bai, Jun Tang, Yanming Guo, Yirun Ruan, Yun Zhou, Zhihe Lu|<http://arxiv.org/pdf/2509.17598v1>|[代码](https://github.com/NUDT-Bai-Group/COLA-TTA.); 提出了一种无需共享标签空间的图像适应新方法COLA，通过结合预训练的视觉语言模型和上下文感知模块，有...|
|🆕 发布|Training-Free Label Space Alignment for Universal Domain Adaptation|无监督标签空间对齐用于通用域自适应|Dujin Lee, Sojung An, Jungmyung Wi, Kuniaki Saito, Donghyun Kim|<http://arxiv.org/pdf/2509.17452v1>|提出了一种无需训练的标签空间对齐方法，通过过滤和优化标签，提高了通用域自适应的稳定性和泛化能力。|
|🆕 发布|EmbodiedSplat: Personalized Real-to-Sim-to-Real Navigation with Gaussian Splats from a Mobile Device|具身喷溅：从移动设备获取的高斯喷溅实现的个性化现实-仿真-现实导航|Gunjan Chhablani, Xiaomeng Ye, Muhammad Zubair Irshad, Zsolt Kira|<http://arxiv.org/pdf/2509.17430v1>|[代码](https://gchhablani.github.io/embodied-splat); 提出 EmbodiedSplat 方法，通过手机捕获场景并利用 3D 高斯散点技术实现高效个性化训练...|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Sight Over Site: Perception-Aware Reinforcement Learning for Efficient Robotic Inspection|《视觉优于现场：面向高效机器人检测的感知感知强化学习》|Richard Kuhlmann, Jakob Wolfram, Boyang Sun, Jiaxu Xing, Davide Scaramuzza, Marc Pollefeys, Cesar Cadena|<http://arxiv.org/pdf/2509.17877v1>|提出了一种以目标可见性为核心目标的强化学习框架，实现了更高效的机器人检测路径规划。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UniPixel: Unified Object Referring and Segmentation for Pixel-Level Visual Reasoning|统一像素级对象指引用与分割：面向像素级视觉推理|Ye Liu, Zongyang Ma, Junfu Pu, Zhongang Qi, Yang Wu, Ying Shan, Chang Wen Chen|<http://arxiv.org/pdf/2509.18094v1>|提出UniPixel模型，融合像素级感知与视觉理解能力，实现图像与语言语义的像素级对齐。|
|🆕 发布|NeuS-QA: Grounding Long-Form Video Understanding in Temporal Logic and Neuro-Symbolic Reasoning|《NeuS-QA：将长格式视频理解基于时间逻辑与神经符号推理的接地》|Sahil Shah, S P Sharan, Harsh Goel, Minkyu Choi, Mustafa Munir, Manvik Pasula, Radu Marculescu, Sandeep Chinchali|<http://arxiv.org/pdf/2509.18041v1>|提出了一种基于神经符号推理和时序逻辑的长期视频问答方法，有效处理了复杂时序推理和因果性问题。|
|🆕 发布|Visual Detector Compression via Location-Aware Discriminant Analysis|通过位置感知判别分析的视觉检测器压缩|Qizhen Lan, Jung Im Choi, Qing Tian|<http://arxiv.org/pdf/2509.17968v1>|提出了一种利用位置信息的检测相关判别式压缩方法，有效降低视觉检测模型复杂度同时保持或提升性能。|
|🆕 发布|Does Audio Matter for Modern Video-LLMs and Their Benchmarks?|音频对现代视频大型语言模型及其基准测试是否重要？|Geewook Kim, Minjoon Seo|<http://arxiv.org/pdf/2509.17901v1>|[代码](https://github.com/naver-ai/LLaVA-AV-SSM.); 探讨了音频对现代视频语言模型的重要性，并提出了结合音频压缩技术的改进模型及新基准数据集。|
|🆕 发布|Adaptive Fast-and-Slow Visual Program Reasoning for Long-Form VideoQA|自适应快慢视觉程序推理用于长视频问答|Chenglin Li, Feng Han, FengTao, Ruilin Li, Qianglong Chen, Jingqi Tong, Yin Zhang, Jiaqi Wang|<http://arxiv.org/pdf/2509.17743v1>|提出自适应快慢视觉程序推理框架FS-VisPR，有效处理长视频问答挑战，提升效率和可靠性。|
|🆕 发布|Evict3R: Training-Free Token Eviction for Memory-Bounded Streaming Visual Geometry Transformers|结果为：《Evict3R：无需训练的内存限制流式视觉几何变换器标记逐出方法》|Soroush Mahdi, Fardin Ayar, Ehsan Javanmardi, Manabu Tsukada, Mahdi Javanmardi|<http://arxiv.org/pdf/2509.17650v1>|提出了一种无需训练的视觉流传输中内存限制的令牌淘汰策略，有效降低内存使用同时保持高准确度。|
|🆕 发布|From Benchmarks to Reality: Advancing Visual Anomaly Detection by the VAND 3.0 Challenge|从基准到现实：通过VAND 3.0挑战推进视觉异常检测|Lars Heckler-Kram, Ashwin Vaidya, Jan-Hendrik Neudeck, Ulla Scheler, Dick Ameln, Samet Akcay, Paula Ramos|<http://arxiv.org/pdf/2509.17615v1>|推动了视觉异常检测领域的发展，通过VAND 3.0挑战赛促进了学术界与工业界的结合，提升了模型对现实...|
|📝 更新|Unsupervised Interpretable Basis Extraction for Concept-Based Visual Explanations|无监督可解释基提取用于基于概念的可视化解释|Alexandros Doumanoglou, Stylianos Asteriadis, Dimitrios Zarpalas|<http://arxiv.org/pdf/2303.10523v3>|提出了一种无需概念标签监督，通过优化特征空间结构提取可解释基的方法，增强了视觉解释的直观性。|
|🆕 发布|Interpreting Attention Heads for Image-to-Text Information Flow in Large Vision-Language Models|解释图像到文本信息流在大规模视觉语言模型中注意力头的含义|Jinyeong Kim, Seil Kang, Jiwoo Park, Junhyeok Kim, Seong Jae Hwang|<http://arxiv.org/pdf/2509.17588v1>|提出了一种head attribution技术，揭示了大型视觉语言模型中图像到文本信息流的规律和结构...|
|📝 更新|On the Suitability of Reinforcement Fine-Tuning to Visual Tasks|关于强化微调适用于视觉任务的适宜性研究|Xiaxu Chen, Wei Li, Chunxu Liu, Chi Xie, Xiaoyan Hu, Chengqian Ma, Feng Zhu, Rui Zhao|<http://arxiv.org/pdf/2504.05682v2>|探究了强化微调对视觉任务的适用性，发现其在多数任务中优于标准微调，并分析了其优势和局限性。|
|📝 更新|CLIP-IN: Enhancing Fine-Grained Visual Understanding in CLIP via Instruction Editing Data and Long Captions|CLIP-IN：通过指令编辑数据与长注释增强CLIP的细粒度视觉理解|Ziteng Wang, Siqi Yang, Limeng Qiao, Lin Ma|<http://arxiv.org/pdf/2508.02329v2>|CLIP-IN通过利用指令编辑数据和长描述性字幕，显著提升了视觉语言模型对细粒度视觉理解的性能。|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|WISE: Weak-Supervision-Guided Step-by-Step Explanations for Multimodal LLMs in Image Classification|WISE：弱监督引导的逐步解释方法用于图像分类中的多模态大型语言模型|Yiwen Jiang, Deval Mehta, Siyuan Yan, Yaling Shen, Zimu Wang, Zongyuan Ge|<http://arxiv.org/pdf/2509.17740v1>|提出WISE方法，通过弱监督生成解释链增强多模态大语言模型在图像分类中的细粒度理解与准确性。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Anatomical feature-prioritized loss for enhanced MR to CT translation|解剖特征优先损失函数用于增强MR到CT的转换|Arthur Longuefosse, Baudouin Denis de Senneville, Gael Dournes, Ilyes Benlala, Pascal Desbarats, Fabien Baldacci|<http://arxiv.org/pdf/2410.10328v3>|引入解剖特征优先损失函数，提升医学图像合成中局部结构细节的精确度。|
|🆕 发布|Beyond Diagnosis: Evaluating Multimodal LLMs for Pathology Localization in Chest Radiographs|超越诊断：评估多模态大型语言模型在胸片病理定位中的应用|Advait Gosai, Arun Kavishwar, Stephanie L. McNamara, Soujanya Samineni, Renato Umeton, Alexander Chowdhury, William Lotter|<http://arxiv.org/pdf/2509.18015v1>|评估了多模态大型语言模型在胸部X光片病理定位的性能，揭示了其潜力与局限性。|
|🆕 发布|DragOSM: Extract Building Roofs and Footprints from Aerial Images by Aligning Historical Labels|DragOSM：通过校准历史标签从航拍图像中提取建筑屋顶和足迹|Kai Li, Xingxing Weng, Yupeng Deng, Yu Meng, Chao Pang, Gui-Song Xia, Xiangyu Zhao|<http://arxiv.org/pdf/2509.17951v1>|[代码](https://github.com/likaiucas/DragOSM.git.); 提出了一种利用历史标注数据校正遥感图像中建筑屋顶和轮廓线对齐的新模型DragOSM。|
|📝 更新|Conformal In-Context Reverse Classification Accuracy: Efficient Estimation of Segmentation Quality with Statistical Guarantees|保形上下文反向分类准确度：带统计保证的分割质量高效估计|Matias Cosarinsky, Ramiro Billot, Lucas Mansilla, Gabriel Jimenez, Nicolas Gaggión, Guanghui Fu, Tom Tirer, Enzo Ferrante|<http://arxiv.org/pdf/2503.04522v3>|[代码](https://github.com/mcosarinsky/Conformal-In-Context-RCA.); 提出了一种无需标注数据的图像分割质量自动评估方法，通过结合上下文学习和置信区间预测，实现了高效准确的...|
|🆕 发布|Predicting Depth Maps from Single RGB Images and Addressing Missing Information in Depth Estimation|从单张RGB图像预测深度图并解决深度估计中的信息缺失问题|Mohamad Mofeed Chaar, Jamal Raiyn, Galia Weidl|<http://arxiv.org/pdf/2509.17686v1>|提出了一种算法，能从单张RGB图像生成深度图并填补深度信息缺失，有效应用于自动驾驶系统。|
|📝 更新|TinyDef-DETR: A DETR-based Framework for Defect Detection in Transmission Lines from UAV Imagery|基于DETR的无人机影像输电线路缺陷检测框架：TinyDef-DETR|Feng Shen, Jiaming Cui, Shuai Zhou, Wenqiang Li, Ruifeng Qin|<http://arxiv.org/pdf/2509.06035v4>|提出TinyDef-DETR框架，通过增强边界敏感性和多尺度注意力机制，有效检测输电线路中的微小缺陷...|
|🆕 发布|Multimodal Medical Image Classification via Synergistic Learning Pre-training|通过协同学习预训练的多模态医学图像分类|Qinghua Lin, Guang-Hai Liu, Zuoyong Li, Yang Li, Yuting Jiang, Xiang Wu|<http://arxiv.org/pdf/2509.17492v1>|[代码](https://github.com/LQH89757/MICS.); 提出了一种基于“预训练+微调”框架的多模态半监督医学图像分类方法，通过一致性、重构性和对齐性学习实现...|
|📝 更新|DCFFSNet: Deep Connectivity Feature Fusion Separation Network for Medical Image Segmentation|DCFFSNet：深度连通性特征融合分离网络用于医学图像分割|Mingda Zhang, Xun Ye, Ruixiang Tang, Haiyan Ding|<http://arxiv.org/pdf/2507.18407v2>|提出了一种特征空间解耦策略的医学图像分割网络DCFFSNet，有效平衡特征融合与分离，提升了分割精度...|
|📝 更新|A Semantic Segmentation Algorithm for Pleural Effusion Based on DBIF-AUNet|基于DBIF-AUNet的胸水语义分割算法|Ruixiang Tang, Mingda Zhang, Jianglong Qin, Yan Song, Yi Wu, Wei Wu|<http://arxiv.org/pdf/2508.06191v2>|提出DBIF-AUNet算法，通过双分支交互融合注意力和特征解耦，提高了复杂肺积液CT图像的分割准确...|
|📝 更新|Convergence analysis of equilibrium methods for inverse problems|《逆问题平衡方法收敛性分析》|Daniel Obmann, Gyeongha Hwang, Markus Haltmeier|<http://arxiv.org/pdf/2306.01421v2>|分析了非变分正则化方法的稳定性和收敛性，为深度平衡模型和即插即用方法提供了理论支持。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Detection of Misreporting Attacks on Software-Defined Immersive Environments|软件定义沉浸式环境中误报攻击的检测|Sourya Saha, Md Nurul Absur, Shima Yousefi, Saptarshi Debroy|<http://arxiv.org/pdf/2509.18040v1>|提出了一种混合机器学习框架，有效检测软件定义沉浸环境中的负载误报攻击，保障应用质量。|
|🆕 发布|Can multimodal representation learning by alignment preserve modality-specific information?|多模态对齐表示学习能否保留模态特定信息？|Romain Thoreau, Jessie Levillain, Dawa Derksen|<http://arxiv.org/pdf/2509.17943v1>|[代码](https://github.com/Romain3Ch216/alg_maclean_25.); 探讨了多模态数据融合中空间对齐策略如何保留各模态特有的任务相关信息。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Is It Certainly a Deepfake? Reliability Analysis in Detection & Generation Ecosystem|《这确实是深度伪造吗？检测与生成生态系统的可靠性分析》|Neslihan Kose, Anthony Rhodes, Umur Aybars Ciftci, Ilke Demir|<http://arxiv.org/pdf/2509.17550v1>|首次全面分析深度伪造检测器的不确定性，利用贝叶斯神经网络和蒙特卡洛dropout量化不确定性，以提升...|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vision-Based Driver Drowsiness Monitoring: Comparative Analysis of YOLOv5-v11 Models|基于视觉的驾驶员疲劳监测：YOLOv5-v11模型比较分析|Dilshara Herath, Chinthaka Abeyrathne, Prabhani Jayaweera|<http://arxiv.org/pdf/2509.17498v1>|对比分析了YOLOv5-v11模型在实时非侵入式驾驶员疲劳监测中的表现，为自动驾驶和工业安全应用提供...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ReasonPlan: Unified Scene Prediction and Decision Reasoning for Closed-loop Autonomous Driving|闭环自动驾驶中的统一场景预测与决策推理：ReasonPlan|Xueyi Liu, Zuodong Zhong, Yuxin Guo, Yun-Fu Liu, Zhiguo Su, Qichao Zhang, Junli Wang, Yinfeng Gao .etc.|<http://arxiv.org/pdf/2505.20024v2>|[代码](https://github.com/Liuxueyi/ReasonPlan.); 提出ReasonPlan框架，通过场景预测和决策推理，提升闭环自动驾驶的性能和适应性。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Automatic Intermodal Loading Unit Identification using Computer Vision: A Scoping Review|计算机视觉辅助的自动集装箱装卸单元识别：范围综述|Emre Gülsoylu, Alhassan Abdelhalim, Derya Kara Boztas, Ole Grasse, Carlos Jahn, Simone Frintrop, Janick Edinger|<http://arxiv.org/pdf/2509.17707v1>|系统综述了计算机视觉在识别集装箱等标准化装载单元中的应用进展，强调了数据集和标准化术语的重要性。|
|🆕 发布|ChartHal: A Fine-grained Framework Evaluating Hallucination of Large Vision Language Models in Chart Understanding|ChartHal：一种评估大规模视觉语言模型在图表理解中幻觉现象的细粒度框架|Xingqi Wang, Yiming Cui, Xin Yao, Shijin Wang, Guoping Hu, Xiaoyu Qin|<http://arxiv.org/pdf/2509.17481v1>|[代码](https://github.com/ymcui/ChartHal); 提出ChartHal框架，评估大规模视觉语言模型在图表理解中的虚构问题，发现现有模型存在严重虚构现象...|


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SD-VLM: Spatial Measuring and Understanding with Depth-Encoded Vision-Language Models|深度编码视觉语言模型的空间测量与理解|Pingyi Chen, Yujing Lou, Shen Cao, Jinhui Guo, Lubin Fan, Yue Wu, Lin Yang, Lizhuang Ma .etc.|<http://arxiv.org/pdf/2509.17664v1>|[代码](https://github.com/cpystan/SD-VLM.); 提出深度位置编码方法增强视觉语言模型空间感知能力，并构建大规模空间测量理解数据集。|
|🆕 发布|Vision Language Models Are Not (Yet) Spelling Correctors|视觉语言模型尚（未）能成为拼写纠正器|Junhong Liang, Bojun Zhang|<http://arxiv.org/pdf/2509.17418v1>|首次提出ReViCo基准，评估视觉语言模型在真实世界拼写纠正上的表现，并提出两种提升性能的方法。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DriveDPO: Policy Learning via Safety DPO For End-to-End Autonomous Driving|驱动DPO：通过安全DPO进行端到端自动驾驶的策略学习|Shuyao Shang, Yuntao Chen, Yuqi Wang, Yingyan Li, Zhaoxiang Zhang|<http://arxiv.org/pdf/2509.17940v1>|提出了一种通过安全直接偏好优化的策略学习框架，有效解决了自动驾驶中的安全性问题并提升了性能。|

