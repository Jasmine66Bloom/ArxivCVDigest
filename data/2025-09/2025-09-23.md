## [UPDATED!] **2025-09-23** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Lavida-O: Elastic Large Masked Diffusion Models for Unified Multimodal Understanding and Generation|拉维达-O：用于统一多模态理解和生成的弹性大遮罩扩散模型|Shufan Li, Jiuxiang Gu, Kangning Liu, Zhe Lin, Zijun Wei, Aditya Grover, Jason Kuen|<http://arxiv.org/pdf/2509.19244v2>|提出Lavida-O模型，统一实现多模态理解和生成，提升图像理解和生成质量与效率。|
|🆕 发布|Weakly Supervised Food Image Segmentation using Vision Transformers and Segment Anything Model|使用视觉变换器和Segment Anything模型的弱监督食品图像分割|Ioannis Sarafis, Alexandros Papadopoulos, Anastasios Delopoulos|<http://arxiv.org/pdf/2509.19028v1>|提出了一种利用Vision Transformers和Segment Anything Model的...|
|🆕 发布|Latent Danger Zone: Distilling Unified Attention for Cross-Architecture Black-box Attacks|潜在危险区：针对跨架构黑盒攻击的统一注意力提炼|Yang Li, Chenyu Wang, Tingrui Wang, Yongwei Wang, Haonan Li, Zhunga Liu, Quan Pan|<http://arxiv.org/pdf/2509.19044v1>|提出了一种基于联合注意力蒸馏的攻击方法JAD，有效提升了黑盒对抗攻击的跨架构迁移性和生成效率。|
|📝 更新|A Decade of Wheat Mapping for Lebanon|《黎巴嫩小麦制图十年研究》|Hasan Wehbi, Hasan Nasrallah, Mohamad Hasan Zahweh, Zeinab Takach, Veera Ganesh Yalla, Ali J. Ghandour|<http://arxiv.org/pdf/2504.11366v4>|提出了一种结合时空视觉变换器和参数高效微调的 wheat 地块映射方法，提高了边界划分精度和地块识别...|
|📝 更新|WaveFormer: A Lightweight Transformer Model for sEMG-based Gesture Recognition|《WaveFormer：一种基于表面肌电图的手势识别轻量级Transformer模型》|Yanlong Chen, Mattia Orlandi, Pierangelo Maria Rapa, Simone Benatti, Luca Benini, Yawei Li|<http://arxiv.org/pdf/2506.11168v2>|提出了一种轻量级Transformer模型WaveFormer，通过结合时域和频域特征，提高了sEM...|
|🆕 发布|LEAF-Mamba: Local Emphatic and Adaptive Fusion State Space Model for RGB-D Salient Object Detection|LEAF-Mamba：用于RGB-D显著目标检测的局部强调与自适应融合状态空间模型|Lanhu Wu, Zilin Gao, Hao Fei, Mong-Li Lee, Wynne Hsu|<http://arxiv.org/pdf/2509.18683v1>|提出LEAF-Mamba模型，通过局部强化和自适应融合策略，提升RGB-D显眼目标检测的性能与效率。|
|🆕 发布|Learning neuroimaging models from health system-scale data|electronic 从健康系统规模数据中学习神经影像模型|Yiwei Lyu, Samir Harake, Asadur Chowdury, Soumyanil Banerjee, Rachel Gologorsky, Shixuan Liu, Anna-Katharina Meissner, Akshay Rao .etc.|<http://arxiv.org/pdf/2509.18638v1>|利用大规模健康系统数据，开发出Prima，一种提升神经影像诊断准确性和效率的视觉语言模型。|
|🆕 发布|Efficient Breast and Ovarian Cancer Classification via ViT-Based Preprocessing and Transfer Learning|通过基于ViT的预处理和迁移学习的高效乳腺癌和卵巢癌分类|Richa Rawat, Faisal Ahmed|<http://arxiv.org/pdf/2509.18553v1>|提出了一种基于ViT的预处理和迁移学习方法，有效提高了乳腺癌和卵巢癌的分类准确率。|
|📝 更新|PainFormer: a Vision Foundation Model for Automatic Pain Assessment|疼痛识别基础模型：用于自动疼痛评估的视觉基础模型|Stefanos Gkikas, Raul Fernandez Rojas, Manolis Tsiknakis|<http://arxiv.org/pdf/2505.01571v5>|[代码](https://github.com/GkikasStefanos/PainFormer.); 提出 PainFormer，一种基于多任务学习的视觉基础模型，有效提取多模态数据特征以实现自动疼痛评...|
|📝 更新|Pain in 3D: Generating Controllable Synthetic Faces for Automated Pain Assessment|《三维疼痛：生成可控合成面部用于自动疼痛评估》|Xin Lei Lin, Soroush Mehraban, Abhishek Moturu, Babak Taati|<http://arxiv.org/pdf/2509.16727v2>|提出3DPain数据集和ViTPain框架，为自动化疼痛评估提供可控、多样、符合临床需求的基础。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning|柑橘V：通过统一医学图像定位推进医学基础模型以用于临床推理|Guoxin Wang, Jun Zhao, Xinyi Liu, Yanbo Liu, Xuyang Cao, Chao Li, Zhuoyun Liu, Qintian Sun .etc.|<http://arxiv.org/pdf/2509.19090v2>|提出了一种统一的多模态医疗基础模型Citrus-V，结合图像分析与文本推理，实现从视觉定位到临床推理...|
|📝 更新|Towards Visual Text Grounding of Multimodal Large Language Model|面向多模态大型语言模型的视觉文本定位研究|Ming Li, Ruiyi Zhang, Jian Chen, Chenguang Wang, Jiuxiang Gu, Yufan Zhou, Franck Dernoncourt, Wanrong Zhu .etc.|<http://arxiv.org/pdf/2504.04974v2>|提出TRIG任务及数据集，提升多模态大语言模型在文本丰富图像中的视觉文本定位能力。|
|📝 更新|Multimodal Chain of Continuous Thought for Latent-Space Reasoning in Vision-Language Models|用于视觉语言模型潜在空间推理的多模态连续思维链|Tan-Hanh Pham, Chris Ngo|<http://arxiv.org/pdf/2508.12587v2>|[代码](https://github.com/Hanhpt23/OmniMod.); 提出了一种在联合潜在空间进行推理的Multimodal Chain of Continuous Th...|
|📝 更新|Earth Observation Foundation Model PhilEO: Pretraining on the MajorTOM and FastTOM Datasets|地球观测基础模型PhilEO：在MajorTOM和FastTOM数据集上的预训练|Nikolaos Dionelis, Riccardo Musto, Jente Bosmans, Simone Sarti, Giancarlo Paoletti, Sébastien Lefèvre, Bertrand Le Saux, Nicolas Longépé|<http://arxiv.org/pdf/2506.14765v4>|提出了一种全球数据集上预训练的地球观测基础模型，通过不同架构提升了下游任务性能。|
|📝 更新|Exploring Model Kinship for Merging Large Language Models|标题翻译为：“探索模型亲缘性以融合大型语言模型”|Yedi Hu, Yunzhi Yao, Ningyu Zhang, Huajun Chen, Shumin Deng|<http://arxiv.org/pdf/2410.12613v3>|[代码](https://github.com/zjunlp/ModelKinship.); 提出模型亲缘性概念，通过迭代合并策略提升大型语言模型性能与效率。|
|📝 更新|CrossEarth: Geospatial Vision Foundation Model for Domain Generalizable Remote Sensing Semantic Segmentation|CrossEarth：面向领域泛化的遥感语义分割的地学视觉基础模型|Ziyang Gong, Zhixiang Wei, Di Wang, Xiaoxing Hu, Xianzheng Ma, Hongruixuan Chen, Yuru Jia, Yupeng Deng .etc.|<http://arxiv.org/pdf/2410.22629v3>|提出首个面向遥感领域通用分割的CrossEarth模型，通过特别设计的数据和模型级管道实现跨域泛化。|
|🆕 发布|RSVG-ZeroOV: Exploring a Training-Free Framework for Zero-Shot Open-Vocabulary Visual Grounding in Remote Sensing Images|遥感图像中零样本开放词汇视觉定位的无训练框架探索：RSVG-ZeroOV|Ke Li, Di Wang, Ting Wang, Fuyu Dong, Yiming Zhang, Luyao Zhang, Xiangyu Wang, Shaofeng Li .etc.|<http://arxiv.org/pdf/2509.18711v1>|提出了一种无需训练的框架RSVG-ZeroOV，利用预训练模型实现零样本开放词汇遥感图像视觉定位。|
|📝 更新|Athena: Enhancing Multimodal Reasoning with Data-efficient Process Reward Models|雅典娜：利用数据高效过程奖励模型增强多模态推理|Shuai Wang, Zhenhua Liu, Jiaheng Wei, Xuanwu Yin, Dong Li, Emad Barsoum|<http://arxiv.org/pdf/2506.09532v2>|提出了一种高效生成高质量过程标注数据的方法，显著提升了多模态推理问题的解决性能。|
|📝 更新|Development and validation of an AI foundation model for endoscopic diagnosis of esophagogastric junction adenocarcinoma: a cohort and deep learning study|内镜诊断食管胃交界腺癌的人工智能基础模型开发与验证：队列研究及深度学习研究|Yikun Ma, Bo Li, Ying Chen, Zijie Yue, Shuchang Xu, Jingyao Li, Lei Ma, Liang Zhong .etc.|<http://arxiv.org/pdf/2509.17660v2>|本研究首次开发并验证了一种基于基础模型的AI方法，用于内镜下食管胃交界腺癌的筛查和分期诊断，显著提升...|
|📝 更新|Visual Instruction Pretraining for Domain-Specific Foundation Models|Objectives and Methods for Visual Instruction Pretraining in Domain-Specific Foundation Models 视觉指令预训练在领域特定基础模型中的目标与方法|Yuxuan Li, Yicheng Zhang, Wenhao Tang, Yimian Dai, Ming-Ming Cheng, Xiang Li, Jian Yang|<http://arxiv.org/pdf/2509.17562v2>|[代码](https://github.com/zcablii/ViTP.); 提出Visual insTruction Pretraining (ViTP)方法，利用推理增强感知...|
|📝 更新|DOTA: Distributional Test-Time Adaptation of Vision-Language Models|DOTA：视觉语言模型分布式测试时适应|Zongbo Han, Jialong Yang, Guangyu Wang, Junfan Li, Qianli Xu, Mike Zheng Shou, Changqing Zhang|<http://arxiv.org/pdf/2409.19375v2>|提出了一种分布性测试时适应方法DOTA，通过动态估计测试数据分布来减少灾难性遗忘，提升视觉语言模型适...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Large Vision-Language Model Alignment and Misalignment: A Survey Through the Lens of Explainability|大规模视觉-语言模型对齐与错位：从可解释性视角进行综述|Dong Shu, Haiyan Zhao, Jingyu Hu, Weiru Liu, Ali Payani, Lu Cheng, Mengnan Du|<http://arxiv.org/pdf/2501.01346v3>|系统梳理了大型视觉语言模型中视觉与文本对齐和错位的现状，提出了缓解策略和研究方向。|
|🆕 发布|Vision-Free Retrieval: Rethinking Multimodal Search with Textual Scene Descriptions|无需视觉的检索：重新思考基于文本场景描述的多模态搜索|Ioanna Ntinou, Alexandros Xenos, Yassine Ouali, Adrian Bulat, Georgios Tzimiropoulos|<http://arxiv.org/pdf/2509.19203v1>|[代码](https://github.com/IoannaNti/LexiCLIP); 提出了一种无需视觉编码器的文本到文本检索方法，通过文本描述实现隐私友好且性能卓越的多模态搜索。|
|🆕 发布|RoSe: Robust Self-supervised Stereo Matching under Adverse Weather Conditions|RoSe：在恶劣天气条件下的鲁棒自监督立体匹配|Yun Wang, Junjie Hu, Junhui Hou, Chenghao Zhang, Renwei Yang, Dapeng Oliver Wu|<http://arxiv.org/pdf/2509.19165v1>|[代码](https://github.com/cocowy1/RoSe-Robust-Self-supervised-Stereo-Matching-under-Adverse-Weather-Conditions); 提出了一种在恶劣天气条件下通过引入视觉基础模型和场景对应先验的鲁棒自监督立体匹配方法，有效提升了匹配...|
|🆕 发布|Prompt-DAS: Annotation-Efficient Prompt Learning for Domain Adaptive Semantic Segmentation of Electron Microscopy Images|Prompt-DAS：面向电子显微镜图像的域自适应语义分割的高效注释提示学习|Jiabao Chen, Shan Xiong, Jialin Peng|<http://arxiv.org/pdf/2509.18973v1>|定位电子显微镜图像的域自适应分割，Prompt-DAS通过少量标注实现高效学习，灵活适应不同提示配置...|
|🆕 发布|SmartWilds: Multimodal Wildlife Monitoring Dataset|智能Wilds：多模态野生动物监测数据集|Jenna Kline, Anirudh Potlapally, Bharath Pillai, Tanishka Wani, Rugved Katole, Vedant Patil, Penelope Covey, Hari Subramoni .etc.|<http://arxiv.org/pdf/2509.18894v1>|推出SmartWilds多模态野生动物监测数据集，支持环境监测AI研究，助力物种保护与生态管理。|
|📝 更新|EventVL: Understand Event Streams via Multimodal Large Language Model|通过多模态大型语言模型理解事件流：EventVL|Pengteng Li, Yunfan Lu, Pinghao Song, Wuyang Li, Huizai Yao, Hui Xiong|<http://arxiv.org/pdf/2501.13707v2>|提出EventVL框架，首个面向事件流显式语义理解的多模态大规模语言模型，通过大规模数据集和时空表示...|
|🆕 发布|Benchmarking Vision-Language and Multimodal Large Language Models in Zero-shot and Few-shot Scenarios: A study on Christian Iconography|在零样本和少量样本场景中评估视觉-语言和多种模态大型语言模型：对基督教图标学的研究|Gianmarco Spinaci, Lukas Klic, Giovanni Colavizza|<http://arxiv.org/pdf/2509.18839v1>|评估了通用多模态大语言模型在基督教图标分类中的表现，证实其在零样本和少样本场景下的有效性。|
|📝 更新|ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding|ViSpec：利用视觉感知的投机解码加速视觉-语言模型|Jialiang Kang, Han Shu, Wenshuo Li, Yingjie Zhai, Xinghao Chen|<http://arxiv.org/pdf/2509.15235v3>|[代码](https://github.com/KangJialiang/ViSpec.); 提出ViSpec框架，通过压缩图像信息和增强文本特征，实现了首个显著的视觉语言模型推理加速。|
|📝 更新|OpenOmni: Advancing Open-Source Omnimodal Large Language Models with Progressive Multimodal Alignment and Real-Time Self-Aware Emotional Speech Synthesis|Synthesis 开源全模态大型语言模型的进步多模态对齐与实时自我感知情感语音合成：OpenOmni|Run Luo, Ting-En Lin, Haonan Zhang, Yuchuan Wu, Xiong Liu, Min Yang, Yongbin Li, Longze Chen .etc.|<http://arxiv.org/pdf/2501.04561v6>|提出了一种两阶段训练框架OpenOmni，通过逐步多模态对齐和实时情感语音合成，实现了领先的开源全模...|
|🆕 发布|The Photographer Eye: Teaching Multimodal Large Language Models to See and Critique like Photographers|摄影师之眼：教授多模态大型语言模型像摄影师一样观察和评价|Daiqing Qi, Handong Zhao, Jing Shi, Simon Jenni, Yifei Fan, Franck Dernoncourt, Scott Cohen, Sheng Li|<http://arxiv.org/pdf/2509.18582v1>|提出了一种结合专业摄影师讨论的PhotoCritique数据集和语言引导的视觉融合模型PhotoEy...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Robust Computer-Vision based Construction Site Detection for Assistive-Technology Applications|基于计算机视觉的鲁棒性建筑工地检测方法研究：辅助技术应用|Junchi Feng, Giles Hamilton-Fletcher, Nikhil Ballem, Michael Batavia, Yifei Wang, Jiuling Zhong, Maurizio Porfiri, John-Ross Rizzo|<http://arxiv.org/pdf/2503.04139v2>|开发了一种基于计算机视觉的辅助系统，实时检测建筑工地，帮助视障人士安全导航。|
|📝 更新|Unsupervised Cross-Domain 3D Human Pose Estimation via Pseudo-Label-Guided Global Transforms|无监督跨域三维人体姿态估计：通过伪标签引导的全局变换|Jingjing Liu, Zhiyong Wang, Xinyu Fan, Amirhossein Dadashzadeh, Honghai Liu, Majid Mirmehdi|<http://arxiv.org/pdf/2504.12699v2>|提出了一种通过伪标签引导的全局变换进行无监督跨域三维人体姿态估计的方法，有效解决了不同场景间的域偏移...|
|📝 更新|3D Human Pose and Shape Estimation from LiDAR Point Clouds: A Review|从激光雷达点云中估计三维人体姿态与形状：综述|Salma Galaaoui, Eduardo Valle, David Picard, Nermin Samet|<http://arxiv.org/pdf/2509.12197v2>|[代码](https://github.com/valeoai/3D-Human-Pose-Shape-Estimation-from-LiDAR); 系统综述了从野外LiDAR点云中估计三维人体姿态和形状的方法，并建立了统一评价标准与基准。|
|🆕 发布|YOLO-LAN: Precise Polyp Detection via Optimized Loss, Augmentations and Negatives|优化的损失函数、增强技术和负样本：基于YOLO的精确息肉检测方法（YOLO-LAN）|Siddharth Gupta, Jitin Singla|<http://arxiv.org/pdf/2509.19166v1>|提出YOLO-LAN算法，通过优化损失函数、数据增强和负样本处理，提高了息肉检测的精确度和临床实用性...|
|🆕 发布|Category-Level Object Shape and Pose Estimation in Less Than a Millisecond|在不到一毫秒内进行类别级别的对象形状与姿态估计|Lorenzo Shaikewitz, Tim Nguyen, Luca Carlone|<http://arxiv.org/pdf/2509.18979v1>|[代码](https://github.com/MIT-SPARK/Fast-ShapeAndPose.); 提出了一种快速求解形状与姿态估计的方法，仅用类别级先验实现高效全局优化。|
|📝 更新|Enhancing Video-Based Robot Failure Detection Using Task Knowledge|利用任务知识增强基于视频的机器人故障检测|Santosh Thoduka, Sebastian Houben, Juergen Gall, Paul G. Plöger|<http://arxiv.org/pdf/2508.18705v2>|利用机器人执行动作和任务相关物体的时空知识，提出了一种视频基础上的机器人故障检测方法，提高了故障检测...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|mRadNet: A Compact Radar Object Detector with MetaFormer|mRadNet：一种基于元前缀转换器的紧凑雷达目标检测器|Huaiyu Chen, Fahed Hassanat, Robert Laganiere, Martin Bouchard|<http://arxiv.org/pdf/2509.16223v2>|提出mRadNet，一种紧凑型雷达目标检测模型，通过MetaFormer块提升特征捕捉效率，实现参数...|
|📝 更新|3D-ADAM: A Dataset for 3D Anomaly Detection in Additive Manufacturing|三维异常检测添加剂制造数据集：3D-ADAM|Paul McHard, Florent P. Audonnet, Oliver Summerell, Sebastian Andraos, Paul Henderson, Gerardo Aragon-Camarasa|<http://arxiv.org/pdf/2507.07838v2>|介绍了首个大规模、行业相关的3D打印表面缺陷检测数据集，为提升制造过程中异常检测性能提供了坚实基础。|
|🆕 发布|KAMERA: Enhancing Aerial Surveys of Ice-associated Seals in Arctic Environments|“KAMERA：增强北极环境中与冰相关海豹的航空调查”|Adam Romlein, Benjamin X. Hou, Yuval Boss, Cynthia L. Christman, Stacie Koslovsky, Erin E. Moreland, Jason Parham, Anthony Hoogs|<http://arxiv.org/pdf/2509.19129v1>|提出KAMERA系统，通过多相机多光谱同步技术，实现实时检测北极冰区海豹，大幅减少数据处理时间。|
|📝 更新|Injecting Explainability and Lightweight Design into Weakly Supervised Video Anomaly Detection Systems|将可解释性与轻量级设计注入弱监督视频异常检测系统|Wen-Dong Jiang, Chih-Yung Chang, Hsiang-Chuan Chang, Ji-Yuan Chen, Diptendu Sinha Roy|<http://arxiv.org/pdf/2412.20201v2>|提出了一种结合知识蒸馏和跨模态对比学习的两阶段视频异常检测系统，实现了边缘设备上的高效、准确和可解释...|
|🆕 发布|HyPSAM: Hybrid Prompt-driven Segment Anything Model for RGB-Thermal Salient Object Detection|混合提示驱动的分割一切模型（HyPSAM）：用于RGB-热成像显著目标检测|Ruichao Hou, Xingyuan Li, Tongwei Ren, Dongming Zhou, Gangshan Wu, Jinde Cao|<http://arxiv.org/pdf/2509.18738v1>|[代码](https://github.com/milotic233/HyPSAM.); 提出HyPSAM模型，通过动态融合网络和优化策略，有效提升RGB-热成像显著目标检测的准确性和完整性...|
|🆕 发布|What Makes You Unique? Attribute Prompt Composition for Object Re-Identification|《是什么让你独一无二？属性提示组合用于目标重识别》|Yingquan Wang, Pingping Zhang, Chong Sun, Dong Wang, Huchuan Lu|<http://arxiv.org/pdf/2509.18715v1>|[代码](https://github.com/AWangYQ/APC.); 提出了一种利用文本语义增强区分度和泛化能力的属性提示组合框架，有效解决对象重识别中的过拟合和泛化问题...|
|📝 更新|Rethinking Evaluation of Infrared Small Target Detection|重新思考红外小目标检测的评价方法|Youwei Pang, Xiaoqi Zhao, Lihe Zhang, Huchuan Lu, Georges El Fakhri, Xiaofeng Liu, Shijian Lu|<http://arxiv.org/pdf/2509.16888v2>|提出全面评价框架，引入混合级评价指标和跨数据集评估，以改进红外小目标检测模型性能评估和泛化能力。|
|📝 更新|AHA - Predicting What Matters Next: Online Highlight Detection Without Looking Ahead|AHA - 预测接下来重要的内容：无需前瞻的在线亮点检测|Aiden Chang, Celso De Melo, Stephanie M. Lukin|<http://arxiv.org/pdf/2509.16421v2>|提出实时视频理解框架Aha，无需预览未来帧即可根据自然语言任务描述进行高效关键帧预测。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|No Labels Needed: Zero-Shot Image Classification with Collaborative Self-Learning|无需标签：基于协作自学习的零样本图像分类|Matheus Vinícius Todescato, Joel Luís Carbonera|<http://arxiv.org/pdf/2509.18938v1>|提出了一种无需标注数据的零样本图像分类框架，通过视觉模型和语言模型的协同自我学习，实现了高效分类。|
|🆕 发布|Towards Application Aligned Synthetic Surgical Image Synthesis|面向应用对齐的合成手术图像生成|Danush Kumar Venkatesh, Stefanie Speidel|<http://arxiv.org/pdf/2509.18796v1>|提出了一种针对下游任务优化的合成手术图像生成框架，有效缓解了数据稀缺问题并提升了分类与分割性能。|
|📝 更新|ZoDIAC: Zoneout Dropout Injection Attention Calculation|“ZoDIAC：区域退出丢弃注入注意力计算”|Zanyar Zohourianshahzadi, Terrance E. Boult, Jugal K. Kalita|<http://arxiv.org/pdf/2206.14263v3>|[代码](https://github.com/zanyarz/zodiac); 提出了一种改进的注意力计算机制ZoDIAC，通过精细化调整和增强注意力值，显著提升了图像描述性能。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhancing Video Object Segmentation in TrackRAD Using XMem Memory Network|利用XMem内存网络增强TrackRAD中的视频目标分割|Pengchao Deng, Shengqi Chen|<http://arxiv.org/pdf/2509.18591v1>|利用XMem记忆网络提升实时MRI引导放疗中肿瘤跟踪的精度和效率。|
|📝 更新|InstanceBEV: Unifying Instance and BEV Representation for 3D Panoptic Segmentation|实例BEV：统一实例与鸟瞰图表示进行三维全景分割|Feng Li, Zhaoyue Wang, Enyuan Zhang, Mohammad Masum Billah, Yunduan Cui, Kun Xu|<http://arxiv.org/pdf/2505.13817v2>|提出InstanceBEV方法，融合地图和物体中心方法优势，提升3D全景分割效率与准确性。|
|📝 更新|Split Matching for Inductive Zero-shot Semantic Segmentation|分裂匹配：用于归纳零样本语义分割的方法|Jialei Chen, Xu Zheng, Dongyue Li, Chong Yi, Seigo Ito, Danda Pani Paudel, Luc Van Gool, Hiroshi Murase .etc.|<http://arxiv.org/pdf/2505.05023v3>|提出Split Matching方法，通过解耦匹配策略优化零样本语义分割，提升了对未标注类别的识别准...|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Understanding-in-Generation: Reinforcing Generative Capability of Unified Model via Infusing Understanding into Generation|《生成中的理解：通过将理解融入生成来强化统一模型的生成能力》|Yuanhuiyi Lyu, Chi Kit Wong, Chenfei Liao, Lutao Jiang, Xu Zheng, Zexin Lu, Linfeng Zhang, Xuming Hu|<http://arxiv.org/pdf/2509.18639v2>|[代码](https://github.com/QC-LY/UiG); 提出Understanding-in-Generation框架，通过融合理解能力提升统一模型在图像生...|
|📝 更新|Sparse VideoGen2: Accelerate Video Generation with Sparse Attention via Semantic-Aware Permutation|稀疏VideoGen2：通过语义感知排列的稀疏注意力加速视频生成|Shuo Yang, Haocheng Xi, Yilong Zhao, Muyang Li, Jintao Zhang, Han Cai, Yujun Lin, Xiuyu Li .etc.|<http://arxiv.org/pdf/2505.18875v2>|提出SVG2框架，通过语义感知排列优化稀疏注意力机制，在视频生成中实现质量和效率的平衡提升。|
|🆕 发布|CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching|CAR-Flow：条件感知重参数化对齐源目标以实现更好的流匹配|Chen Chen, Pengsheng Guo, Liangchen Song, Jiasen Lu, Rui Qian, Xinze Wang, Tsu-Jui Fu, Wei Liu .etc.|<http://arxiv.org/pdf/2509.19300v1>|提出条件感知重参数化方法CAR-Flow，通过调整分布缩短学习路径，提升流匹配模型训练速度和效果。|
|🆕 发布|ROPA: Synthetic Robot Pose Generation for RGB-D Bimanual Data Augmentation|ROPA：用于RGB-D双臂数据增强的合成机器人姿态生成|Jason Chen, I-Chun Arthur Liu, Gaurav Sukhatme, Daniel Seita|<http://arxiv.org/pdf/2509.19454v1>|[代码](https://ropaaug.github.io/.); 提出了一种合成机器人姿态生成方法ROPA，通过 offline 仿射学习增强RGB-D双臂操作数据，...|
|🆕 发布|OverLayBench: A Benchmark for Layout-to-Image Generation with Dense Overlaps|《OverLayBench：一个用于具有密集重叠的布局到图像生成的基准测试》|Bingnan Li, Chen-Yu Wang, Haiyang Xu, Xiang Zhang, Ethan Armand, Divyansh Srivastava, Xiaojun Shan, Zeyuan Chen .etc.|<http://arxiv.org/pdf/2509.19282v1>|[代码](https://mlpc-ucsd.github.io/OverLayBench.); 提出了一种评估布局到图像生成的新指标和基准，以及一个针对复杂重叠布局的改进模型。|
|🆕 发布|Moving by Looking: Towards Vision-Driven Avatar Motion Generation|《通过视觉驱动：迈向基于视觉的虚拟化身运动生成》|Markos Diomataris, Berat Mert Albaba, Giorgio Becherini, Partha Ghosh, Omid Taheri, Michael J. Black|<http://arxiv.org/pdf/2509.19259v1>|提出利用第一视角视觉驱动的虚拟人运动生成方法，实现类似人类的感知与运动协同。|
|📝 更新|SpinMeRound: Consistent Multi-View Identity Generation Using Diffusion Models|“SpinMeRound：使用扩散模型进行一致的多视角身份生成”|Stathis Galanakis, Alexandros Lattas, Stylianos Moschoglou, Bernhard Kainz, Stefanos Zafeiriou|<http://arxiv.org/pdf/2504.10716v2>|提出了一种基于扩散模型的 SpinMeRound 方法，能够生成从新颖视角的逼真头像并保持身份特征一...|
|📝 更新|CaKE: Circuit-aware Editing Enables Generalizable Knowledge Learners|“CaKE：电路感知编辑助力通用知识学习者”|Yunzhi Yao, Jizhan Fang, Jia-Chen Gu, Ningyu Zhang, Shumin Deng, Huajun Chen, Nanyun Peng|<http://arxiv.org/pdf/2503.16356v2>|[代码](https://github.com/zjunlp/CaKE.); 提出了一种针对大型语言模型的知识编辑方法CaKE，通过优化推理电路，显著提升了多跳推理任务的准确性。|
|🆕 发布|HyKid: An Open MRI Dataset with Expert-Annotated Multi-Structure and Choroid Plexus in Pediatric Hydrocephalus|HyKid：一个包含专家标注的多结构和脉络丛的儿童脑积水开放性MRI数据集|Yunzhi Xu, Yushuang Ding, Hu Sun, Hongxi Zhang, Li Zhao|<http://arxiv.org/pdf/2509.19218v1>|提出HyKid开放数据集，包含儿童脑积水患者3D MRI和专家标注，为神经影像算法开发提供高质量基准...|
|📝 更新|Improving Image Captioning Descriptiveness by Ranking and LLM-based Fusion|通过排序和基于大型语言模型的融合提高图像描述的详尽性|Luigi Celona, Simone Bianco, Marco Donzella, Paolo Napoletano|<http://arxiv.org/pdf/2306.11593v2>|提出了一种融合多模型生成与大型语言模型优化相结合的方法，有效提升了图像描述的丰富性和准确性。|
|📝 更新|Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study|《视觉-语言模型在野外环境下的安全性：基于模因的基准研究》|DongGeon Lee, Joonwon Jang, Jihae Jeong, Hwanjo Yu|<http://arxiv.org/pdf/2505.15389v3>|[代码](https://github.com/oneonlee/Meme-Safety-Bench.); 提出MemeSafetyBench基准，评估视觉语言模型在处理真实网络迷因时的安全性问题。|
|🆕 发布|Generative data augmentation for biliary tract detection on intraoperative images|胆管术中图像检测的生成数据增强方法|Cristina Iacono, Mariarosaria Meola, Federica Conte, Laura Mecozzi, Umberto Bracale, Pietro Falco, Fanny Ficuciello|<http://arxiv.org/pdf/2509.18958v1>|利用生成对抗网络增强训练数据，提高了术中胆管定位的准确性和效率。|
|🆕 发布|Quantum Random Synthetic Skyrmion Texture Generation, a Qiskit Simulation|量子随机合成斯克瑞梅子纹理生成：Qiskit仿真|Hillol Biswas|<http://arxiv.org/pdf/2509.18947v1>|探究量子计算生成随机Skyrmion纹理，为新型量子比特研究提供新方向。|
|🆕 发布|Hyper-Bagel: A Unified Acceleration Framework for Multimodal Understanding and Generation|“Hyper-Bagel：一种用于多模态理解和生成的统一加速框架”|Yanzuo Lu, Xin Xia, Manlin Zhang, Huafeng Kuang, Jianbin Zheng, Yuxi Ren, Xuefeng Xiao|<http://arxiv.org/pdf/2509.18824v1>|提出Hyper-Bagel框架，通过分而治策略和高效算法加速多模态理解和生成任务。|
|📝 更新|REACT: Real-time Efficiency and Accuracy Compromise for Tradeoffs in Scene Graph Generation|REACT：实时效率与精度权衡在场景图生成中的折中方案|Maëlic Neau, Paulo E. Santos, Anne-Gwenn Bosser, Cédric Buche, Akihiro Sugimoto|<http://arxiv.org/pdf/2405.16116v3>|[代码](https://github.com/Maelic/SGG-Benchmark); 提出REACT架构，平衡实时性、对象检测和关系预测，实现最快推理速度和显著提升对象检测精度。|
|📝 更新|Multi-scale Temporal Prediction via Incremental Generation and Multi-agent Collaboration|通过增量生成与多智能体协作的多尺度时间预测|Zhitao Zeng, Guojian Yuan, Junyuan Mao, Yuxuan Wang, Xiaoshuang Jia, Yueming Jin|<http://arxiv.org/pdf/2509.17429v2>|提出了一种多尺度时序预测方法IG-MC，通过逐步生成和多方协作，实现了对场景状态的精准预测。|
|📝 更新|LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation|LRQ-DiT：对数旋转后训练量化扩散变换器以实现图像和视频生成|Lianwei Yang, Haokun Lin, Tianchen Zhao, Yichen Wu, Hongyu Zhu, Ruiqi Xie, Zhenan Sun, Yu Wang .etc.|<http://arxiv.org/pdf/2508.03485v3>|提出了一种针对图像和视频生成的Log-Rotation后训练量化框架，有效解决了低比特量化导致的性能...|
|🆕 发布|Training-Free Multi-Style Fusion Through Reference-Based Adaptive Modulation|基于参考的自适应调制实现的无需训练的多风格融合|Xu Liu, Yibo Lu, Xinxian Wang, Xinyu Wu|<http://arxiv.org/pdf/2509.18602v1>|提出了一种无需训练的多风格融合框架，通过自适应调节实现了多参考风格图像的平衡与可控融合。|
|🆕 发布|OraPO: Oracle-educated Reinforcement Learning for Data-efficient and Factual Radiology Report Generation|OraPO：基于Oracle指导的强化学习在高效数据生成与事实性放射学报告撰写中的应用|Zhuoxiao Chen, Hongyang Yu, Ying Xu, Yadan Luo, Long Duong, Yuan-Fang Li|<http://arxiv.org/pdf/2509.18600v1>|提出Oracle-educated OraPO方法，通过 FactScore-based 奖励机制，...|
|📝 更新|SparseDiT: Token Sparsification for Efficient Diffusion Transformer|稀疏DiT：用于高效扩散变换器的标记稀疏化|Shuning Chang, Pichao Wang, Jiasheng Tang, Fan Wang, Yi Yang|<http://arxiv.org/pdf/2412.06028v2>|提出 SparseDiT 方法，通过时空维度上的 token 稀疏化提升扩散变换器的效率并保持生成质...|
|📝 更新|In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer|《上下文编辑：利用大规模扩散变换器中的上下文生成实现指导性图像编辑》|Zechuan Zhang, Ji Xie, Yu Lu, Zongxin Yang, Yi Yang|<http://arxiv.org/pdf/2504.20690v3>|[代码](https://river-zhang.github.io/ICEdit-gh-pages); 提出了一种高效精确的指令式图像编辑方法 ICEdit，通过在大型扩散变换器中实现无需架构修改的上下文...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MOIS-SAM2: Exemplar-based Segment Anything Model 2 for multilesion interactive segmentation of neurofibromas in whole-body MRI|MOIS-SAM2：基于示例的Segment Anything模型2，用于全身MRI中神经纤维瘤的多病变交互式分割|Georgii Kolokolnikov, Marie-Lena Schmalhofer, Sophie Goetz, Lennart Well, Said Farschtschi, Victor-Felix Mautner, Inka Ristow, Rene Werner|<http://arxiv.org/pdf/2509.19277v2>|提出MOIS-SAM2模型，结合示例引导的语义传播，高效互动分割全身MRI中的神经纤维瘤。|
|🆕 发布|TIMED: Adversarial and Autoregressive Refinement of Diffusion-Based Time Series Generation|TIMED：基于扩散的时间序列生成对抗性与自回归细化|MohammadReza EskandariNasab, Shah Muhammad Hamdi, Soukaina Filali Boubrahimi|<http://arxiv.org/pdf/2509.19638v1>|提出了一种统一的时间序列生成框架TIMED，结合了去噪扩散模型和自回归依赖学习，生成更真实、连贯的序...|
|📝 更新|From Slow Bidirectional to Fast Autoregressive Video Diffusion Models|从慢速双向到快速自回归视频扩散模型|Tianwei Yin, Qiang Zhang, Richard Zhang, William T. Freeman, Fredo Durand, Eli Shechtman, Xun Huang|<http://arxiv.org/pdf/2412.07772v4>|将双向视频扩散模型改造为高效的自回归模型，通过创新的蒸馏策略实现快速高质量视频生成。|
|🆕 发布|Synthesizing Artifact Dataset for Pixel-level Detection|合成像素级检测的人工制品数据集|Dennis Menn, Feng Liang, Diana Marculescu|<http://arxiv.org/pdf/2509.19589v1>|提出了一种自动注入伪影的方法，生成无需手动标注的像素级注释数据集，有效提升了伪影检测器的性能。|
|🆕 发布|iFinder: Structured Zero-Shot Vision-Based LLM Grounding for Dash-Cam Video Reasoning|iFinder：基于结构化零样本视觉的大语言模型定位用于行车记录仪视频推理|Manyi Yao, Bingbing Zhuang, Sparsh Garg, Amit Roy-Chowdhury, Christian Shelton, Manmohan Chandraker, Abhishek Aich|<http://arxiv.org/pdf/2509.19552v1>|提出iFinder框架，通过将驾驶视频转化为可解释的数据结构，增强大型语言模型在无监督情况下的视频理...|
|🆕 发布|Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation|“Lyra：通过视频扩散模型自蒸馏实现的生成式三维场景重建”|Sherwin Bahmani, Tianchang Shen, Jiawei Ren, Jiahui Huang, Yifeng Jiang, Haithem Turki, Andrea Tagliasacchi, David B. Lindell .etc.|<http://arxiv.org/pdf/2509.19296v1>|提出了一种无需多视角训练数据，通过视频扩散模型自蒸馏生成显式3D场景的方法。|
|🆕 发布|Long Story Short: Disentangling Compositionality and Long-Caption Understanding in VLMs|《长话短说：在大型视觉语言模型中解耦组合性与长字幕理解》|Israfel Salazar, Desmond Elliott, Yova Kementchedjhieva|<http://arxiv.org/pdf/2509.19207v1>|揭示了视觉语言模型中组合性与长字幕理解之间的相互作用，提出通过训练增强两者性能的方法。|
|📝 更新|Penalizing Boundary Activation for Object Completeness in Diffusion Models|惩罚边界激活以实现扩散模型中的对象完整性|Haoyang Xu, Tianhao Zhao, Sibei Yang, Yutian Lin|<http://arxiv.org/pdf/2509.16968v2>|提出了一种无需训练的边界激活惩罚方法，有效解决了扩散模型中物体生成不完整的问题。|
|📝 更新|Individualized Mapping of Aberrant Cortical Thickness via Stochastic Cortical Self-Reconstruction|通过随机皮质自重构实现个体化异常皮质厚度的映射|Christian Wachinger, Dennis Hedderich, Melissa Thalhammer, Fabian Bongratz|<http://arxiv.org/pdf/2403.06837v2>|提出了一种深度学习驱动的个体化皮质厚度重建方法SCSR，提高了异常皮质厚度的检测精度和疾病辨识能力。|
|🆕 发布|WaveletGaussian: Wavelet-domain Diffusion for Sparse-view 3D Gaussian Object Reconstruction|《WaveletGaussian：基于小波域扩散的稀疏视角三维高斯对象重建》|Hung Nguyen, Runfa Li, An Le, Truong Nguyen|<http://arxiv.org/pdf/2509.19073v1>|提出WaveletGaussian框架，通过在波let域应用扩散模型和轻量级网络，高效实现稀疏视角下...|
|📝 更新|StableGuard: Towards Unified Copyright Protection and Tamper Localization in Latent Diffusion Models|《StableGuard：面向潜在扩散模型中统一版权保护和篡改定位》|Haoxin Yang, Bangzhen Liu, Xuemiao Xu, Cheng Xu, Yuyang Yu, Zikai Huang, Yi Wang, Shengfeng He|<http://arxiv.org/pdf/2509.17993v2>|StableGuard通过在生成过程中集成二值水印，实现了Latent Diffusion模型中的版...|
|🆕 发布|LiDAR Point Cloud Image-based Generation Using Denoising Diffusion Probabilistic Models|基于去噪扩散概率模型的LiDAR点云图像生成|Amirhesam Aghanouri, Cristina Olaverri-Monreal|<http://arxiv.org/pdf/2509.18917v1>|利用去噪扩散概率模型生成高质量合成LiDAR点云数据，增强自动驾驶环境感知性能。|
|🆕 发布|Audio-Driven Universal Gaussian Head Avatars|音频驱动的通用高斯头虚拟人像|Kartik Teotia, Helge Rhodin, Mohit Mendiratta, Hyeongwoo Kim, Marc Habermann, Christian Theobalt|<http://arxiv.org/pdf/2509.18924v1>|提出首个音频驱动的通用高清头像合成方法，通过结合语音模型和新型通用头像先验，实现精准唇同步和细微表情...|
|📝 更新|SCoT: Straight Consistent Trajectory for Pre-Trained Diffusion Model Distillations|“SCoT：用于预训练扩散模型精炼的直线一致性轨迹”|Zhangkai Wu, Xuhui Fan, Hongyu Wu, Longbing Cao|<http://arxiv.org/pdf/2502.16972v3>|提出SCoT模型，结合一致性轨迹与直线轨迹优势，实现快速高效的数据采样。|
|🆕 发布|Text Slider: Efficient and Plug-and-Play Continuous Concept Control for Image/Video Synthesis via LoRA Adapters|文本滑块：通过LoRA适配器实现图像/视频合成的有效且即插即用的连续概念控制|Pin-Yen Chiu, I-Sheng Fang, Jun-Cheng Chen|<http://arxiv.org/pdf/2509.18831v1>|Text Slider通过在预训练文本编码器中识别低秩方向，实现了高效、即插即用的连续概念控制，大幅...|
|📝 更新|PromptEnhancer: A Simple Approach to Enhance Text-to-Image Models via Chain-of-Thought Prompt Rewriting|PromptEnhancer：通过链式思维提示重写提升文本到图像模型的一种简单方法|Linqing Wang, Ximing Xing, Yiji Cheng, Zhiyuan Zhao, Donghao Li, Tiankai Hang, Jiale Tao, Qixun Wang .etc.|<http://arxiv.org/pdf/2509.04545v5>|提出了一种PromptEnhancer框架，通过Chain-of-Thought重写提示，显著提升了...|
|📝 更新|L2M-Reg: Building-level Uncertainty-aware Registration of Outdoor LiDAR Point Clouds and Semantic 3D City Models|L2M-Reg：面向建筑级别的室外激光雷达点云与语义三维城市模型的不确定性感知配准|Ziyang Xu, Benedikt Schwab, Yihui Yang, Thomas H. Kolbe, Christoph Holst|<http://arxiv.org/pdf/2509.16832v2>|提出了一种考虑模型不确定性的平面基精细配准方法L2M-Reg，显著提升了室外激光雷达点云与语义三维城...|
|📝 更新|Clothing agnostic Pre-inpainting Virtual Try-ON|服装无关预修复虚拟试穿|Sehyun Kim, Hye Jun Lee, Jiwoo Lee, Taemin Lee|<http://arxiv.org/pdf/2509.17654v2>|提出CaP-VTON方法，通过预处理改善虚拟试衣的自然度和一致性，有效解决纹理失真和底边检测问题。|
|🆕 发布|Prompt-Guided Dual Latent Steering for Inversion Problems|基于提示的双潜在引导逆向问题解决方法|Yichen Wu, Xu Liu, Chenxuan Zhao, Xinyu Wu|<http://arxiv.org/pdf/2509.18619v1>|提出了一种无需训练的Prompt-Guided Dual Latent Steering框架，通过双...|
|📝 更新|SimToken: A Simple Baseline for Referring Audio-Visual Segmentation|SimToken：一种用于引用音频视觉分割的简单基线|Dian Jin, Yanghao Zhou, Jinxing Zhou, Jiaqi Ma, Ruohao Guo, Dan Guo|<http://arxiv.org/pdf/2509.17537v2>|提出了一种融合多模态大语言模型与分割模型的方法SimToken，有效提升了基于自然语言视频对象分割的...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EgoBridge: Domain Adaptation for Generalizable Imitation from Egocentric Human Data|自我桥接：从主观人类数据中进行泛化模仿的域自适应|Ryan Punamiya, Dhruv Patel, Patcharapong Aphiwetsa, Pranav Kuppili, Lawrence Y. Zhu, Simar Kareer, Judy Hoffman, Danfei Xu|<http://arxiv.org/pdf/2509.19626v1>|提出EgoBridge框架，通过域自适应显著缩小了人机数据间的差距，提高了机器人模仿学习成功率。|
|🆕 发布|Enabling Plant Phenotyping in Weedy Environments using Multi-Modal Imagery via Synthetic and Generated Training Data|利用合成和生成训练数据通过多模态影像在杂草环境中实现植物表型分析|Earl Ranario, Ismael Mayanja, Heesup Yun, Brian N. Bailey, J. Mason Earles|<http://arxiv.org/pdf/2509.19208v1>|利用合成图像和生成训练数据，提出了一种增强热成像中作物分割性能的新框架。|
|📝 更新|Towards Interpretable and Efficient Attention: Compressing All by Contracting a Few|面向可解释与高效注意力：通过收缩少数实现全体压缩|Qishuai Wen, Zhiyuan Huang, Chun-Guang Li|<http://arxiv.org/pdf/2509.16875v2>|提出统一优化目标解决注意力机制的效率和可解释性问题，创新性地提出 Contract-and-Broa...|
|🆕 发布|FUNCanon: Learning Pose-Aware Action Primitives via Functional Object Canonicalization for Generalizable Robotic Manipulation|FUNCanon：通过功能性对象规范化的姿态感知动作原语学习，以实现通用机器人操作|Hongli Xu, Lei Zhang, Xiaoyue Hu, Boyang Zhong, Kaixin Bai, Zoltán-Csaba Márton, Zhenshan Bing, Zhaopeng Chen .etc.|<http://arxiv.org/pdf/2509.19102v1>|提出了一种将长周期操作任务分解为可重用动作块的方法，通过功能对象规范化和动作中心扩散策略，实现了机器...|
|📝 更新|DWTGS: Rethinking Frequency Regularization for Sparse-view 3D Gaussian Splatting|DWTGS：重新思考稀疏视图三维高斯散点图的频率正则化|Hung Nguyen, Runfa Li, An Le, Truong Nguyen|<http://arxiv.org/pdf/2507.15690v2>|提出了一种基于小波变换的频率正则化方法DWTGS，有效抑制了稀疏视角3D高斯散点重建中的过拟合和伪影...|
|🆕 发布|FixingGS: Enhancing 3D Gaussian Splatting via Training-Free Score Distillation|FixingGS：通过无需训练的分数蒸馏增强三维高斯散点绘制|Zhaorui Wang, Yi Gu, Deming Zhou, Renjing Xu|<http://arxiv.org/pdf/2509.18759v1>|提出了一种无需训练的FixingGS方法，通过蒸馏技术增强3D重建，有效去除模糊和伪影问题。|
|📝 更新|LD-ViCE: Latent Diffusion Model for Video Counterfactual Explanations|LD-ViCE：用于视频反事实解释的潜在扩散模型|Payal Varshney, Adriano Lucieri, Christoph Balada, Sheraz Ahmed, Andreas Dengel|<http://arxiv.org/pdf/2509.08422v2>|提出LD-ViCE框架，利用潜在空间扩散模型生成视频的反事实解释，提升了解释的实时性和准确性。|
|🆕 发布|AGSwap: Overcoming Category Boundaries in Object Fusion via Adaptive Group Swapping|AGSwap：通过自适应组交换在对象融合中克服类别边界|Zedong Zhang, Ying Tai, Jianjun Qian, Jian Yang, Jun Li|<http://arxiv.org/pdf/2509.18699v1>|提出AGSwap方法，通过自适应组交换和更新解决跨类别对象融合中的不一致和混乱问题，并引入大规模CO...|
|🆕 发布|Live-E2T: Real-time Threat Monitoring in Video via Deduplicated Event Reasoning and Chain-of-Thought|实时威胁监控：通过去重事件推理和思维链在视频中进行实时监控|Yuhan Wang, Cheng Liu, Zihan Zhao, Weichao Wu|<http://arxiv.org/pdf/2509.18571v1>|Live-E2T通过事件去重、实时更新和逻辑推理，实现了视频威胁监测的高效性和可解释性。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Generating 360° Video is What You Need For a 3D Scene|生成360°视频是您构建三维场景所需的关键|Zhaoyang Zhang, Yannick Hold-Geoffroy, Miloš Hašan, Ziwen Chen, Fujun Luan, Julie Dorsey, Yiwei Hu|<http://arxiv.org/pdf/2504.02045v3>|提出了一种利用360°视频生成完整3D场景的方法，提高了场景一致性和导航自由度。|
|📝 更新|AvatarShield: Visual Reinforcement Learning for Human-Centric Synthetic Video Detection|《AvatarShield：面向以人为中心的合成视频检测的视觉强化学习》|Zhipei Xu, Xuanyu Zhang, Qing Huang, Xing Zhou, Jian Zhang|<http://arxiv.org/pdf/2505.15173v3>|提出了一种基于视觉强化学习的AvatarShield框架，有效检测全人身体合成视频，无需密集文本监督...|
|📝 更新|Deep Spherical Superpixels|深度球面超像素|Rémi Giraud, Michaël Clément|<http://arxiv.org/pdf/2407.17354v2>|首次提出针对全景图像的深度学习超像素分割方法，通过球形CNN和可微分K-means优化球形几何分割效...|
|🆕 发布|One-shot Embroidery Customization via Contrastive LoRA Modulation|通过对比LoRA调制实现单次刺绣定制|Jun Ma, Qian He, Gaofeng He, Huang Chen, Chen Liu, Xiaogang Jin, Huamin Wang|<http://arxiv.org/pdf/2509.18948v1>|提出了一种基于对比学习的细粒度风格迁移方法，通过单张参考图像实现刺绣定制。|
|📝 更新|Dual Data Alignment Makes AI-Generated Image Detector Easier Generalizable|双数据对齐使AI生成图像检测器更易于泛化|Ruoxin Chen, Junwei Xi, Zhiyuan Yan, Ke-Yue Zhang, Shuang Wu, Jingyi Xie, Xu Chen, Lei Xu .etc.|<http://arxiv.org/pdf/2505.14359v5>|[代码](https://github.com/roy-ch/Dual-Data-Alignment.); 提出双数据对齐方法，有效减少检测器在非偏置数据集上的性能退化。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CURE: Centroid-guided Unsupervised Representation Erasure for Facial Recognition Systems|中心点引导的无监督表征擦除方法用于面部识别系统|Fnu Shivam, Nima Najafzadeh, Yenumula Reddy, Prashnna Gyawali|<http://arxiv.org/pdf/2509.19562v1>|提出CURE方法，首个无需身份标签的 facial recognition 系统无监督遗忘框架，有效...|
|📝 更新|MCPDepth: Omnidirectional Depth Estimation via Stereo Matching from Multi-Cylindrical Panoramas|MCPDepth：通过多圆柱全景图的立体匹配进行全向深度估计|Feng Qiao, Zhexiao Xiong, Xinge Zhu, Yuexin Ma, Qiumeng He, Nathan Jacobs|<http://arxiv.org/pdf/2408.01653v2>|[代码](https://github.com/Qjizhi/MCPDepth.); 提出了一种通过多圆柱全景图进行立体匹配的深度估计方法，大幅提升了全景图像深度估计的准确性。|
|🆕 发布|Seeing Through Reflections: Advancing 3D Scene Reconstruction in Mirror-Containing Environments with Gaussian Splatting|通过反射看见：利用高斯散点法在含镜环境的3D场景重建中取得进展|Zijing Guo, Yunyang Zhao, Lin Wang|<http://arxiv.org/pdf/2509.18956v1>|提出ReflectiveGS方法，利用镜子反射信息提升三维场景重建质量。|
|📝 更新|DATA: Domain-And-Time Alignment for High-Quality Feature Fusion in Collaborative Perception|数据：协同感知中高质量特征融合的域与时间对齐|Chengchang Tian, Jianwei Ma, Yan Huang, Zhanye Chen, Honghao Wei, Hui Zhang, Wei Hong|<http://arxiv.org/pdf/2507.18237v2>|[代码](https://github.com/ChengchangTian/DATA.); 提出了一种DATA网络，通过域和时间对齐提高协同感知中特征融合的质量和鲁棒性。|
|📝 更新|Hierarchical Neural Semantic Representation for 3D Semantic Correspondence|层次化神经语义表示用于三维语义对应|Keyu Du, Jingyu Hu, Haipeng Li, Hao Xu, Haibing Huang, Chi-Wing Fu, Shuaicheng Liu|<http://arxiv.org/pdf/2509.17431v2>|提出了一种分层神经语义表示方法，通过全局与多分辨率局部特征结合，实现了精确且鲁棒的3D语义对应估计。|
|🆕 发布|Zero-shot Monocular Metric Depth for Endoscopic Images|零样本单目测距深度估计用于内窥镜图像|Nicolas Toussaint, Emanuele Colleoni, Ricardo Sanchez-Matilla, Joshua Sutcliffe, Vanessa Thompson, Muhammad Asad, Imanol Luengo, Danail Stoyanov|<http://arxiv.org/pdf/2509.18642v1>|[代码](https://github.com/TouchSurgery/EndoSynth.); 提出了一种用于内窥镜图像的零样本单目测距方法，并通过合成数据集显著提升了模型准确性。|
|📝 更新|HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis|混合辐射场：用于内存高效和高品质新视角合成的技术|Zipeng Wang, Dan Xu|<http://arxiv.org/pdf/2509.17083v2>|[代码](https://wzpscott.github.io/hyrf); 提出Hybrid Radiance Fields，结合显式高斯和神经场优势，提升novel view...|
|📝 更新|Gaussian Herding across Pens: An Optimal Transport Perspective on Global Gaussian Reduction for 3DGS|跨围栏的高斯放牧：从最优传输视角看全局高斯缩减在三维形状分析中的应用|Tao Wang, Mengyu Li, Geduo Zeng, Cheng Meng, Qiong Zhang|<http://arxiv.org/pdf/2506.09534v2>|[代码](https://github.com/DrunkenPoet/GHAP); 提出全局最优传输视角压缩3D高斯分布，大幅减少内存和渲染负担同时保持渲染质量。|
|🆕 发布|Differentiable Light Transport with Gaussian Surfels via Adapted Radiosity for Efficient Relighting and Geometry Reconstruction|通过适应辐射度的高斯微表面进行可微分光传输，实现高效重照明与几何重构|Kaiwen Jiang, Jia-Mu Sun, Zilu Li, Dan Wang, Tzu-Mao Li, Ravi Ramamoorthi|<http://arxiv.org/pdf/2509.18497v1>|引入高斯微元和改进的辐射度算法，实现了高效的全球光照效果下的几何重建与重照明。|
|📝 更新|3D Gaussian Flats: Hybrid 2D/3D Photometric Scene Reconstruction|三维高斯平面：二维/三维光度场景重建|Maria Taktasheva, Lily Goli, Alessandro Fiorini, Zhen Li, Daniel Rebain, Andrea Tagliasacchi|<http://arxiv.org/pdf/2509.16423v2>|提出了一种结合2D和3D高斯模型的混合方法，有效解决了平面表面重建问题，提升了视觉质量和几何精度。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with Voxel-Aligned Prediction|体素对齐预测下的前向3D高斯散点重思考：VolSplat|Weijie Wang, Yeqing Chen, Zeyu Zhang, Hengyu Liu, Haoxiao Wang, Zhiyuan Feng, Wenkang Qin, Zheng Zhu .etc.|<http://arxiv.org/pdf/2509.19297v1>|VolSplat通过将预测从像素级转移到体素级，解决了传统3D重建方法依赖2D特征匹配的问题，提高了...|
|🆕 发布|DeblurSplat: SfM-free 3D Gaussian Splatting with Event Camera for Robust Deblurring|去模糊喷溅：无需结构从运动（SfM）的三维高斯喷溅与事件相机实现鲁棒去模糊|Pengteng Li, Yunfan Lu, Pinhao Song, Weiyu Guo, Huizai Yao, F. Richard Yu, Hui Xiong|<http://arxiv.org/pdf/2509.18898v1>|提出了一种无需结构从运动（SfM）的基于事件相机的高斯散点3D去模糊方法，通过融合事件流和图像数据，...|
|🆕 发布|Reconstruction of Optical Coherence Tomography Images from Wavelength-space Using Deep-learning|波长空间中基于深度学习的光学相干断层扫描图像重建|Maryam Viqar, Erdem Sahin, Elena Stoykova, Violeta Madjarova|<http://arxiv.org/pdf/2509.18783v1>|提出了一种基于深度学习的波长域直接重构光学相干断层扫描图像的方法，有效降低了计算复杂度并减少了 sp...|
|🆕 发布|TriFusion-AE: Language-Guided Depth and LiDAR Fusion for Robust Point Cloud Processing|TriFusion-AE：语言引导的深度与激光雷达融合以实现鲁棒点云处理|Susmit Neogi|<http://arxiv.org/pdf/2509.18743v1>|提出TriFusion-AE模型，融合文本、图像深度和LiDAR点云，增强点云处理鲁棒性。|
|🆕 发布|Event-guided 3D Gaussian Splatting for Dynamic Human and Scene Reconstruction|基于事件引导的动态人体与场景重建的3D高斯散点绘制|Xiaoting Yin, Hao Shi, Kailun Yang, Jiajun Zhai, Shangwei Guo, Lin Wang, Kaiwei Wang|<http://arxiv.org/pdf/2509.18566v1>|提出了一种利用事件相机引导的3D高斯散点法，实现了动态人体与静态场景的联合重建，有效解决了运动模糊问...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Your Turn: At Home Turning Angle Estimation for Parkinson's Disease Severity Assessment|《您的参与：家庭环境下的转向角度估计用于帕金森病严重程度评估》|Qiushuo Cheng, Catherine Morgan, Arindam Sikdar, Alessandro Masullo, Alan Whone, Majid Mirmehdi|<http://arxiv.org/pdf/2408.08182v4>|提出了一种基于深度学习的方法，通过家庭视频自动量化帕金森病患者转身角度，以评估病情严重程度。|
|🆕 发布|Towards Robust LiDAR Localization: Deep Learning-based Uncertainty Estimation|面向鲁棒激光雷达定位：基于深度学习的 uncertainty 估计|Minoo Dolatabadi, Fardin Ayar, Ehsan Javanmardi, Manabu Tsukada, Mahdi Javanmardi|<http://arxiv.org/pdf/2509.18954v1>|提出了一种基于深度学习的LiDAR定位不确定性估计方法，无需参考地图即可提高定位准确性和鲁棒性。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|COLT: Enhancing Video Large Language Models with Continual Tool Usage|COLT：通过持续工具使用增强视频大型语言模型|Yuyang Liu, Xinyuan Shi, Xiaondan Liang|<http://arxiv.org/pdf/2509.18754v2>|提出了一种持续学习工具使用的方法COLT，使视频大型语言模型能动态适应不断变化的工具数据流。|
|🆕 发布|ConViS-Bench: Estimating Video Similarity Through Semantic Concepts|ConViS-Bench：通过语义概念估计视频相似度|Benedetta Liberatori, Alessandro Conti, Lorenzo Vaquero, Yiming Wang, Elisa Ricci, Paolo Rota|<http://arxiv.org/pdf/2509.19245v1>|提出了一种基于语义概念的视频相似度估计方法ConViS，通过可解释的相似度评分支持人类式的视频比较。|
|🆕 发布|The 1st Solution for MOSEv2 Challenge 2025: Long-term and Concept-aware Video Segmentation via SeC|2025年MOSEv2挑战的第一解决方案：基于SeC的长时性和概念感知视频分割|Mingqi Gao, Jingkun Chen, Yunqi Miao, Gengshen Wu, Zhijin Qin, Jungong Han|<http://arxiv.org/pdf/2509.19183v1>|提出了一种结合长期记忆和概念感知记忆的半监督视频对象分割方法，有效应对遮挡和重现问题，并在LSVOS...|
|🆕 发布|Track-On2: Enhancing Online Point Tracking with Memory|《Track-On2：利用内存增强在线点跟踪》|Görkay Aydemir, Weidi Xie, Fatma Güney|<http://arxiv.org/pdf/2509.19115v1>|[代码](https://kuis-ai.github.io/track_on2); 提出了一种基于记忆机制的在线点追踪模型Track-On2，有效应对长期追踪中的变化和遮挡，实现实时性...|
|🆕 发布|VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction|VIR-Bench：通过旅行视频行程重建评估多模态大型语言模型的地空和时间理解能力|Hao Wang, Eiki Murata, Lingfang Zhang, Ayako Sato, So Fukuda, Ziqi Yin, Wentao Hu, Keisuke Nakao .etc.|<http://arxiv.org/pdf/2509.19002v1>|提出VIR-Bench，通过旅行视频行程重建任务评估和提升大型多模态语言模型的地理时空理解能力。|
|🆕 发布|Surgical Video Understanding with Label Interpolation|手术视频理解中的标签插值方法|Garam Kim, Tae Kyeong Jeong, Juyoun Park|<http://arxiv.org/pdf/2509.18802v1>|提出了一种结合光流和标签插值的手术视频多任务学习框架，有效平衡了时空信息并提升了理解精度。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Chirality in Action: Time-Aware Video Representation Learning by Latent Straightening|《动作中的手性：通过潜在拉直实现时间感知的视频表征学习》|Piyush Bagad, Andrew Zisserman|<http://arxiv.org/pdf/2509.08502v2>|提出了一种基于自监督学习和感知直方修正的时序敏感视频表征方法，有效区分动作时序差异。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MsFIN: Multi-scale Feature Interaction Network for Traffic Accident Anticipation|多尺度特征交互网络用于交通事故预测|Tongshuai Wu, Chao Lu, Ze Song, Yunlong Lin, Sizhe Fan, Xuemei Chen|<http://arxiv.org/pdf/2509.19227v1>|提出MsFIN网络，通过多尺度特征融合与交互建模，提前预测交通事故，优于现有单尺度方法。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CellCLIP -- Learning Perturbation Effects in Cell Painting via Text-Guided Contrastive Learning|细胞CLIP -- 通过文本引导的对比学习了解细胞绘画中的扰动效应|Mingyu Lu, Ethan Weinberger, Chanwoo Kim, Su-In Lee|<http://arxiv.org/pdf/2506.06290v3>|提出CellCLIP框架，通过跨模态对比学习将细胞图像与扰动效果关联，提升高内涵筛选数据分析性能。|
|📝 更新|PointAD+: Learning Hierarchical Representations for Zero-shot 3D Anomaly Detection|点异常检测增强：学习用于零样本三维异常检测的层次化表示|Qihang Zhou, Shibo He, Jiangtao Yan, Wenchao Meng, Jiming Chen|<http://arxiv.org/pdf/2509.03277v2>|提出了一种结合点和像素信息的三维异常检测框架，通过分层表征学习识别未见对象的三维异常。|


### 跨模态一致性学习 (Cross-modal Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Frequency-Domain Decomposition and Recomposition for Robust Audio-Visual Segmentation|频域分解与重组用于鲁棒音频视觉分割|Yunzhe Shen, Kai Peng, Leiye Liu, Wei Ji, Jingjing Li, Miao Zhang, Yongri Piao, Huchuan Lu|<http://arxiv.org/pdf/2509.18912v1>|提出了一种基于频率域分解与重组的音频视觉分割框架，有效区分音频与视觉信号特性，实现更精确的多模态分割...|


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment|MOCHA：多模态物体感知跨架构对齐|Elena Camuffo, Francesco Barbato, Mete Ozay, Simone Milani, Umberto Michieli|<http://arxiv.org/pdf/2509.14001v2>|MOCHA通过对象级知识蒸馏，将大规模视觉-语言模型的多模态语义有效迁移至轻量级视觉检测器，实现性能...|
|🆕 发布|Knowledge Transfer from Interaction Learning|从交互学习中进行的知识迁移|Yilin Gao, Kangyi Chen, Zhongxing Peng, Hengjie Lu, Shugong Xu|<http://arxiv.org/pdf/2509.18733v1>|提出了一种模拟交互过程的认知启发框架，通过捕获预训练语言模型中的动态交互模式，有效提升了视觉基础模型...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Raw-JPEG Adapter: Efficient Raw Image Compression with JPEG|原始-JPEG适配器：基于JPEG的高效原始图像压缩|Mahmoud Afifi, Ran Zhang, Michael S. Brown|<http://arxiv.org/pdf/2509.19624v1>|提出了一种将原始图像高效适配JPEG压缩的方法，实现了高保真度的图像压缩与重建。|
|🆕 发布|Anatomy of a Feeling: Narrating Embodied Emotions via Large Vision-Language Models|《情感的解剖：通过大型视觉-语言模型叙述具身情感》|Mohammad Saim, Phan Anh Duong, Cat Luong, Aniket Bhanderi, Tianyu Jiang|<http://arxiv.org/pdf/2509.19595v1>|提出框架利用大型视觉语言模型生成情感体验的具身描述，有效识别面部遮挡下的情绪。|
|🆕 发布|Adversarially-Refined VQ-GAN with Dense Motion Tokenization for Spatio-Temporal Heatmaps|对抗性优化的VQ-GAN与密集运动符号化相结合的时空热力图生成方法|Gabriel Maldonado, Narges Rashvand, Armin Danesh Pazho, Ghazal Alinezhad Noghre, Vinit Katariya, Hamed Tabkhi|<http://arxiv.org/pdf/2509.19252v1>|[代码](https://github.com/TeCSAR-UNCC/Pose-Quantization.); 引入对抗性优化的VQ-GAN框架，通过密集运动标记压缩时空热图，保留了人体运动的细微轨迹。|
|📝 更新|LookAhead Tuning: Safer Language Models via Partial Answer Previews|前瞻调谐：通过部分答案预览实现更安全的语言模型|Kangwei Liu, Mengru Wang, Yujie Luo, Yuan Lin, Mengshu Sun, Lei Liang, Zhiqiang Zhang, Jun Zhou .etc.|<http://arxiv.org/pdf/2503.19041v2>|提出了一种名为LookAhead Tuning的数据驱动方法，在微调过程中有效保持大型语言模型的安全...|
|📝 更新|MEGS$^{2}$: Memory-Efficient Gaussian Splatting via Spherical Gaussians and Unified Pruning|MEGS$^{2}$：通过球形高斯函数和统一剪枝实现的内存高效高斯散布|Jiarui Chen, Yikeng Chen, Yingshuang Zou, Ye Huang, Peng Wang, Yuan Liu, Yujing Sun, Wenping Wang|<http://arxiv.org/pdf/2509.07021v2>|MEGS$^{2}$通过使用轻量级球形高斯函数和统一剪枝策略，有效解决了3D Gaussian Sp...|
|🆕 发布|Unveiling Chain of Step Reasoning for Vision-Language Models with Fine-grained Rewards|揭示细粒度奖励下视觉语言模型步骤推理链|Honghao Chen, Xingzhou Lou, Xiaokun Feng, Kaiqi Huang, Xinlong Wang|<http://arxiv.org/pdf/2509.19003v1>|[代码](https://github.com/baaivision/CoS.); 提出细粒度奖励机制以优化视觉语言模型中的链式推理，提升推理质量和基准测试性能。|
|🆕 发布|Failure Makes the Agent Stronger: Enhancing Accuracy through Structured Reflection for Reliable Tool Interactions|“失败成就强者：通过结构化反思增强准确度以实现可靠的工具交互”|Junhao Su, Yuanliang Wan, Junwei Yang, Hengyu Shi, Tianyang Han, Junfeng Luo, Yurui Qiu|<http://arxiv.org/pdf/2509.18847v1>|提出结构化反思方法，使模型从错误中学习并优化工具交互的准确性。|
|🆕 发布|SSCM: A Spatial-Semantic Consistent Model for Multi-Contrast MRI Super-Resolution|SSCM：一种用于多对比度MRI超分辨率的空间-语义一致性模型|Xiaoman Wu, Lubin Gan, Siying Wu, Jing Zhang, Yunwei Ou, Xiaoyan Sun|<http://arxiv.org/pdf/2509.18593v1>|提出了一种空间语义一致性模型SSCM，通过动态空间扭曲模块、语义感知标记聚合块和空间频率融合块，有效...|
|🆕 发布|SEGA: A Transferable Signed Ensemble Gaussian Black-Box Attack against No-Reference Image Quality Assessment Models|SEGA：一种针对无参考图像质量评估模型的迁移性签名集成高斯黑盒攻击|Yujia Liu, Dingquan Li, Tiejun Huang|<http://arxiv.org/pdf/2509.18546v1>|提出了一种针对无参考图像质量评估模型的转移性黑盒攻击方法SEGA，有效提升了攻击的转移性。|
|🆕 发布|Dynamical Modeling of Behaviorally Relevant Spatiotemporal Patterns in Neural Imaging Data|行为相关时空模式在神经成像数据中的动态建模|Mohammad Hosseini, Maryam M. Shanechi|<http://arxiv.org/pdf/2509.18507v1>|提出SBIND框架，通过深度学习建模神经图像的时空依赖性，有效区分行为相关和不相关的神经动态。|
|🆕 发布|Codebook-Based Adaptive Feature Compression With Semantic Enhancement for Edge-Cloud Systems|基于码本的边缘云系统中自适应特征压缩与语义增强方法|Xinyu Wang, Zikun Zhou, Yingjian Li, Xin An, Hongpeng Wang|<http://arxiv.org/pdf/2509.18481v1>|提出了一种基于码本的自适应特征压缩框架，通过保留更多视觉模式，在低比特率下显著提升分析性能。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|NeuCODEX: Edge-Cloud Co-Inference with Spike-Driven Compression and Dynamic Early-Exit|《NeuCODEX：基于尖峰驱动压缩和动态提前退出的边缘-云协同推理》|Maurf Hassan, Steven Davy, Muhammad Zawish, Owais Bin Zuber, Nouman Ashraf|<http://arxiv.org/pdf/2509.19156v1>|提出了一种神经形态协同推理架构NeuCODEX，通过时空冗余优化和动态早停机制，大幅降低边缘计算能耗...|
|🆕 发布|MoiréNet: A Compact Dual-Domain Network for Image Demoiréing|莫尔网：一种紧凑的双域网络用于图像去莫尔纹|Shuwei Guo, Simin Luan, Yan Ke, Zeyd Boukhers, John See, Cong Yang|<http://arxiv.org/pdf/2509.18910v1>|提出了一种结合频率和空间域特征的紧凑型神经网络MoiréNet，有效去除摩尔纹同时保持参数效率。|
|🆕 发布|SynapFlow: A Modular Framework Towards Large-Scale Analysis of Dendritic Spines|《SynapFlow：一种面向大规模分析树突棘的模块化框架》|Pamela Osuna-Vargas, Altug Kamacioglu, Dominik F. Aschauer, Petros E. Vlachos, Sercan Alipek, Jochen Triesch, Simon Rumpel, Matthias Kaschube|<http://arxiv.org/pdf/2509.18926v1>|[代码](https://github.com/pamelaosuna/SynapFlow); 提出了一种模块化机器学习框架，自动化检测和追踪大脑中树突棘的结构动态，提高了分析效率。|
|📝 更新|Superpixel Segmentation: A Long-Lasting Ill-Posed Problem|超像素分割：一个长期存在的病态问题|Rémi Giraud, Michaël Clément|<http://arxiv.org/pdf/2411.06478v2>|揭示了超像素分割的病态问题本质，并展示了如何使用现有架构实现竞争性结果。|
|📝 更新|Fix your downsampling ASAP! Be natively more robust via Aliasing and Spectral Artifact free Pooling|立即修复您的下采样！通过消除混叠和频谱伪迹的池化实现原生更稳健性|Julia Grabinski, Steffen Jung, Janis Keuper, Margret Keuper|<http://arxiv.org/pdf/2307.09804v2>|提出了一种无混叠和频谱伪迹的图像下采样方法，增强了卷积神经网络对常见干扰和对抗攻击的鲁棒性。|
|🆕 发布|BridgeSplat: Bidirectionally Coupled CT and Non-Rigid Gaussian Splatting for Deformable Intraoperative Surgical Navigation|桥接散点：双向耦合的CT与非刚性高斯散点法在可变形术中导航中的应用|Maximilian Fehrentz, Alexander Winkler, Thomas Heiliger, Nazim Haouchine, Christian Heiliger, Nassir Navab|<http://arxiv.org/pdf/2509.18501v1>|[代码](https://maxfehrentz.github.io/ct-informed-splatting); 提出了一种将术中3D重建与术前CT数据结合的BridgeSplat方法，实现了手术导航中变形处理的精...|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|3rd Place Report of LSVOS 2025 MeViS Track: Sa2VA-i: Improving Sa2VA Results with Consistent Training and Inference|2025年LSVOS MeViS赛道第三名报告：Sa2VA-i：通过一致性训练与推理提高Sa2VA结果|Alexey Nekrasov, Ali Athar, Daan de Geus, Alexander Hermans, Bastian Leibe|<http://arxiv.org/pdf/2509.19082v1>|[代码](https://github.com/kumuji/sa2va-i); 通过一致性训练与推理改进Sa2VA模型，显著提升视频对象分割性能。|
|🆕 发布|Attack for Defense: Adversarial Agents for Point Prompt Optimization Empowering Segment Anything Model|"攻击为防御：对抗性智能体用于点提示优化，助力Segment Anything模型"|Xueyu Liu, Xiaoyi Zhang, Guangze Shi, Meilin Liu, Yexin Lai, Yongfei Wu, Mingqiang Wei|<http://arxiv.org/pdf/2509.18891v1>|提出了一种通过对抗性强化学习自动优化点提示的方法，有效提升了Segment Anything Mod...|
|📝 更新|Variational Bayes Gaussian Splatting|变分贝叶斯高斯散点模型|Toon Van de Maele, Ozan Catal, Alexander Tschantz, Christopher L. Buckley, Tim Verbelen|<http://arxiv.org/pdf/2410.03592v2>|提出 Variational Bayes Gaussian Splatting 方法，通过变分推理优...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ColorBlindnessEval: Can Vision-Language Models Pass Color Blindness Tests?|《ColorBlindnessEval：视觉语言模型能否通过色盲测试？》|Zijian Ling, Han Zhang, Yazhuo Zhou, Jiahao Cui|<http://arxiv.org/pdf/2509.19070v1>|提出ColorBlindnessEval基准，评估视觉语言模型在视觉对抗场景下的鲁棒性。|
|🆕 发布|ViG-LRGC: Vision Graph Neural Networks with Learnable Reparameterized Graph Construction|可学习重参数化图构建的视觉图神经网络：ViG-LRGC|Ismael Elsharkawi, Hossam Sharara, Ahmed Rafea|<http://arxiv.org/pdf/2509.18840v1>|提出了一种可学习参数化图构造方法LRGC，通过自适应选择节点邻域，提高了视觉图神经网络的图像表征能力...|
|📝 更新|Joint Memory Frequency and Computing Frequency Scaling for Energy-efficient DNN Inference|联合内存频率与计算频率缩放以实现节能的深度神经网络推理|Yunchu Han, Zhaojun Nan, Sheng Zhou, Zhisheng Niu|<http://arxiv.org/pdf/2509.17970v2>|提出了一种结合内存频率和计算频率调整的方法，有效降低资源受限设备上深度神经网络推理的能耗。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Token Preference Optimization with Self-Calibrated Visual-Anchored Rewards for Hallucination Mitigation|带有自校准视觉锚定奖励的标记偏好优化以减轻幻觉现象|Jihao Gu, Yingyao Wang, Meng Cao, Pi Bu, Jun Song, Yancheng He, Shilong Li, Bo Zheng|<http://arxiv.org/pdf/2412.14487v4>|提出了一种自适应的Token偏好优化模型，通过自我校准的视觉锚定奖励减少大型视觉语言模型中的幻觉现象...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Parameter-Efficient Multi-Task Learning via Progressive Task-Specific Adaptation|通过渐进式任务特定适应实现的参数高效多任务学习|Neeraj Gangwar, Anshuka Rangi, Rishabh Deshmukh, Holakou Rahmanian, Yesh Dattatreya, Nickvash Kani|<http://arxiv.org/pdf/2509.19602v1>|提出了一种渐进式任务特定适配的多任务学习方法，通过共享适配器模块减少任务冲突，实现了参数效率的提升。|
|🆕 发布|Agentic Scene Policies: Unifying Space, Semantics, and Affordances for Robot Action|场景代理策略：统一空间、语义和可供性以指导机器人行动|Sacha Morin, Kumaraditya Gupta, Mahtab Sandhu, Charlie Gauthier, Francesco Argenziano, Kirsty Ellis, Liam Paull|<http://arxiv.org/pdf/2509.19571v1>|提出了一种利用场景表示的语义、空间和功效性查询能力的Agentic Scene Policies框架...|
|🆕 发布|Graph-Radiomic Learning (GrRAiL) Descriptor to Characterize Imaging Heterogeneity in Confounding Tumor Pathologies|图放射omic学习（GrRAiL）描述符用于表征混淆性肿瘤病理学中的成像异质性|Dheerendranath Battalapalli, Apoorva Safai, Maria Jaramillo, Hyemin Um, Gustavo Adalfo Pineda Ortiz, Ulas Bagci, Manmeet Singh Ahluwalia, Marwa Ismail .etc.|<http://arxiv.org/pdf/2509.19258v1>|提出Graph-Radiomic Learning方法，通过分析图像内部异质性区分肿瘤与混淆病变。|
|🆕 发布|DevFD: Developmental Face Forgery Detection by Learning Shared and Orthogonal LoRA Subspaces|DevFD：通过学习共享与正交LoRA子空间的发展性人脸伪造检测|Tianshuo Zhang, Li Gao, Siran Peng, Xiangyu Zhu, Zhen Lei|<http://arxiv.org/pdf/2509.19230v1>|提出了一种持续学习框架DevFD，通过分离学习真实人脸和伪造人脸的子空间，有效应对不断演变的伪造技术...|
|📝 更新|Do It Yourself: Learning Semantic Correspondence from Pseudo-Labels|自行其是：从伪标签中学习语义对应关系|Olaf Dünkel, Thomas Wimmer, Christian Theobalt, Christian Rupprecht, Adam Kortylewski|<http://arxiv.org/pdf/2506.05312v3>|通过3D感知伪标签改进了语义对应估计，实现了无需特定数据集注释即可达到新的最佳性能。|
|🆕 发布|A DyL-Unet framework based on dynamic learning for Temporally Consistent Echocardiographic Segmentation|基于动态学习的DyL-Unet框架用于时间一致性的心脏超声分割|Jierui Qu, Jianchun Zhao|<http://arxiv.org/pdf/2509.19052v1>|提出DyL-UNet框架，通过动态学习和心脏相位动态注意力增强心脏超声图像的时间一致性和分割精度。|
|📝 更新|CalFuse: Feature Calibration Enhanced Parameter Fusion for Class-Continual Learning|"CalFuse：特征校准增强的参数融合用于类连续学习"|Juncen Guo, Siao Liu, Xiaoguang Zhu, Lianlong Sun, Liangyu Teng, Jingyi Wu, Di Li, Linxiao Gong .etc.|<http://arxiv.org/pdf/2503.18672v7>|提出CalFuse框架，通过动态特征校准和参数融合策略，有效平衡新知识学习与旧知识保留。|
|📝 更新|Without Paired Labeled Data: End-to-End Self-Supervised Learning for Drone-view Geo-Localization|无需成对标注数据：面向无人机视角地理定位的端到端自监督学习|Zhongwei Chen, Zhao-Xu Yang, Hai-Jun Rong, Guoqi Li|<http://arxiv.org/pdf/2502.11381v4>|[代码](https://github.com/ISChenawei/DMNIL.); 提出了一种无配对标注数据需求的端到端自监督学习框架DMNIL，有效提升了无人机地理定位的准确性和适应...|
|🆕 发布|Real-time Deer Detection and Warning in Connected Vehicles via Thermal Sensing and Deep Learning|通过热感知与深度学习实现的车联网实时鹿群检测与预警|Hemanth Puppala, Wayne Sarasua, Srinivas Biyaguda, Farhad Farzinpour, Mashrur Chowdhury|<http://arxiv.org/pdf/2509.18779v1>|提出实时热成像与深度学习结合的鹿群检测预警系统，有效降低车辆与鹿群碰撞风险。|
|📝 更新|Class-wise Balancing Data Replay for Federated Class-Incremental Learning|类平衡数据重放策略用于联邦类增量学习|Zhuang Qi, Ying-Peng Tang, Lei Meng, Han Yu, Xiaoxiao Li, Xiangxu Meng|<http://arxiv.org/pdf/2507.07712v2>|提出了一种面向联邦增量学习的类平衡数据重放方法，通过全局协调机制和自适应温度缩放，有效解决了类不平衡...|
|📝 更新|Large Language Models Implicitly Learn to See and Hear Just By Reading|大型语言模型通过阅读隐式学习看见和听见|Prateek Verma, Mert Pilanci|<http://arxiv.org/pdf/2505.17091v2>|发现大型语言模型在仅阅读文本的情况下，能自发学会理解和处理图像与音频信息。|
|🆕 发布|HadaSmileNet: Hadamard fusion of handcrafted and deep-learning features for enhancing facial emotion recognition of genuine smiles|HadaSmileNet：基于Hadamard融合的手工特征与深度学习特征增强真实微笑面部情感识别|Mohammad Junayed Hasan, Nabeel Mohammed, Shafin Rahman, Philipp Koehn|<http://arxiv.org/pdf/2509.18550v1>|提出了一种高效的融合深度学习特征与手工特征的HadaSmileNet模型，提升了真实微笑情感识别的准...|
|🆕 发布|Hyperbolic Coarse-to-Fine Few-Shot Class-Incremental Learning|双曲粗到细少样本类增量学习|Jiaxin Dai, Xiang Xiang|<http://arxiv.org/pdf/2509.18504v1>|提出在双曲空间中实现粗到细的少量样本分类学习方法，提高了分类准确性。|
|🆕 发布|Machine learning approach to single-shot multiparameter estimation for the non-linear Schrödinger equation|机器学习方法在非线性薛定谔方程单次多参数估计中的应用|Louis Rossignol, Tangui Aladjidi, Myrann Baker-Rasooli, Quentin Glorieux|<http://arxiv.org/pdf/2509.18479v1>|利用神经网络逆解非线性薛定谔方程，实现了从单次测量中准确估计多个参数。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EmbodiedSplat: Personalized Real-to-Sim-to-Real Navigation with Gaussian Splats from a Mobile Device|具身喷溅：从移动设备获取的高斯喷溅实现的个性化现实-仿真-现实导航|Gunjan Chhablani, Xiaomeng Ye, Muhammad Zubair Irshad, Zsolt Kira|<http://arxiv.org/pdf/2509.17430v2>|[代码](https://gchhablani.github.io/embodied-splat.); 提出 EmbodiedSplat 方法，通过手机捕获场景并使用 3D 高斯散点技术进行重建，有效提升...|
|🆕 发布|VLN-Zero: Rapid Exploration and Cache-Enabled Neurosymbolic Vision-Language Planning for Zero-Shot Transfer in Robot Navigation|VLN-Zero：零样本迁移中机器人导航的快速探索与缓存支持的神经符号视觉语言规划|Neel P. Bhatt, Yunhao Yang, Rohan Siva, Pranay Samineni, Daniel Milan, Zhangyang Wang, Ufuk Topcu|<http://arxiv.org/pdf/2509.18592v1>|[代码](https://vln-zero.github.io/.); VLN-Zero通过结合快速探索、符号推理和缓存执行，实现了在未知环境中高效、可扩展的机器人导航。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DexSkin: High-Coverage Conformable Robotic Skin for Learning Contact-Rich Manipulation|DexSkin：高覆盖率自适应机器人皮肤，用于学习接触丰富的操作|Suzannah Wistreich, Baiyu Shi, Stephen Tian, Samuel Clarke, Michael Nath, Chengyi Xu, Zhenan Bao, Jiajun Wu|<http://arxiv.org/pdf/2509.18830v1>|[代码](https://dex-skin.github.io/.); 提出了一种柔软、可贴身的电容式电子皮肤DexSkin，实现了高覆盖率的触觉感应，用于学习丰富的接触操...|


### 目标导向视觉决策 (Goal-oriented Visual Decision Making)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|IMAIA: Interactive Maps AI Assistant for Travel Planning and Geo-Spatial Intelligence|IMAIA：旅行规划与地理空间智能的交互式地图AI助手|Jieren Deng, Zhizhang Hu, Ziyan He, Aleksandar Cvetkovic, Pak Kiu Chung, Dragomir Yankov, Chiqun Zhang|<http://arxiv.org/pdf/2507.06993v3>|IMAIA通过结合自然语言交互与地理空间智能，提升了地图应用中的问答准确性和响应速度。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VER-Bench: Evaluating MLLMs on Reasoning with Fine-Grained Visual Evidence|VER-Bench：评估多模态大型语言模型在细粒度视觉证据推理上的表现|Chenhui Qiang, Zhaoyang Wei, Xumeng Han, Zipeng Wang, Siyao Li, Xiangyuan Lan, Jianbin Jiao, Zhenjun Han|<http://arxiv.org/pdf/2508.04852v2>|[代码](https://github.com/verbta/ACMMM-25-Materials.); 提出VER-Bench，评估多模态语言模型对细微视觉线索的识别与推理能力。|
|📝 更新|Visual Chronicles: Using Multimodal LLMs to Analyze Massive Collections of Images|视觉编年史：使用多模态大型语言模型分析海量图像集|Boyang Deng, Songyou Peng, Kyle Genova, Gordon Wetzstein, Noah Snavely, Leonidas Guibas, Thomas Funkhouser|<http://arxiv.org/pdf/2504.08727v3>|利用多模态大规模语言模型分析大规模图像数据库，发现城市随时间变化的趋势。|
|🆕 发布|Bi-VLM: Pushing Ultra-Low Precision Post-Training Quantization Boundaries in Vision-Language Models|Bi-VLM：推动视觉语言模型超低精度后训练量化边界|Xijun Wang, Junyun Huang, Rayyan Abdalla, Chengyuan Zhang, Ruiqi Xian, Dinesh Manocha|<http://arxiv.org/pdf/2509.18763v1>|提出了一种非均匀分离模型权重的Bi-VLM方法，通过智能量化显著提升了视觉语言模型的效率和性能。|
|📝 更新|Adaptive Fast-and-Slow Visual Program Reasoning for Long-Form VideoQA|自适应快慢视觉程序推理用于长视频问答|Chenglin Li, Feng Han, Feng Tao, Ruilin Li, Qianglong Chen, Jingqi Tong, Yin Zhang, Jiaqi Wang|<http://arxiv.org/pdf/2509.17743v2>|提出自适应快慢视觉程序推理框架FS-VisPR，有效处理长视频问答挑战，提升效率和可靠性。|
|📝 更新|LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA|LaV-CoT：面向现实世界多语言视觉问答的语言感知视觉CoT多方面奖励优化方法|Jing Huang, Zhiya Tan, Shutao Gong, Fanwei Zeng, Joey Tianyi Zhou, Jianshu Li|<http://arxiv.org/pdf/2509.10026v2>|[代码](https://github.com/HJNVR/LaV-CoT); 提出了一种语言感知视觉CoT框架LaV-CoT，通过多方面奖励优化，提升了多语种视觉问答的准确性和泛...|
|📝 更新|Mitigating Hallucination in Large Vision-Language Models through Aligning Attention Distribution to Information Flow|通过将注意力分布与信息流对齐来减轻大型视觉-语言模型中的幻觉现象|Jianfei Zhao, Feng Zhang, Xin Sun, Chong Feng|<http://arxiv.org/pdf/2505.14257v3>|通过优化注意力分布与信息流的匹配，有效减少大型视觉语言模型中的幻觉现象。|
|🆕 发布|GeoRemover: Removing Objects and Their Causal Visual Artifacts|地理移除器：移除对象及其因果视觉痕迹|Zixin Zhu, Haoxiang Li, Xuelu Feng, He Wu, Chunming Qiao, Junsong Yuan|<http://arxiv.org/pdf/2509.18538v1>|[代码](https://github.com/buxiangzhiren/GeoRemover.); 提出了一种基于几何感知的两阶段框架，有效移除目标物体及其因果视觉效应，实现更精准的图像编辑。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Reading Images Like Texts: Sequential Image Understanding in Vision-Language Models|像阅读文本一样阅读图像：视觉语言模型中的序列图像理解|Yueyan Li, Chenggong Zhao, Zeyuan Zang, Caixia Yuan, Xiaojie Wang|<http://arxiv.org/pdf/2509.19191v1>|提出了一种分解视觉处理机制的方法，通过将图像内容与空间感知分离，提升了视觉语言模型的效率和空间推理能...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Handling Multiple Hypotheses in Coarse-to-Fine Dense Image Matching|在粗到细密集图像匹配中处理多个假设|Matthieu Vilain, Rémi Giraud, Yannick Berthoumieu, Guillaume Bourmaud|<http://arxiv.org/pdf/2509.08805v2>|提出多假设传播策略，通过BEAMER架构增强深度不连续性和强缩放下的密集图像匹配鲁棒性。|
|🆕 发布|Pre-training CLIP against Data Poisoning with Optimal Transport-based Matching and Alignment|基于最优传输匹配与对齐的CLIP预训练对抗数据污染|Tong Zhang, Kuofeng Gao, Jiawang Bai, Leo Yu Zhang, Xin Yin, Zonghui Wang, Shouling Ji, Wenzhi Chen|<http://arxiv.org/pdf/2509.18717v1>|提出了一种基于最优传输的图像-文本匹配框架OTCCLIP，有效抵御数据投毒攻击并提升CLIP模型性能...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Investigating Traffic Accident Detection Using Multimodal Large Language Models|探究基于多模态大型语言模型的交通事故检测|Ilhan Skender, Kailin Tong, Selim Solmaz, Daniel Watzenig|<http://arxiv.org/pdf/2509.19096v2>|探究了大型多模态语言模型在无需大量标注数据的情况下，通过图像自动检测交通事故的能力。|
|📝 更新|MedEBench: Diagnosing Reliability in Text-Guided Medical Image Editing|MedEBench：诊断文本引导的医学图像编辑中的可靠性|Minghao Liu, Zhitao He, Zhiyuan Fan, Qingyun Wang, Yi R. Fung|<http://arxiv.org/pdf/2506.01921v6>|提出MedEBench，为评估文本引导的医疗图像编辑可靠性提供临床基准和诊断工具。|
|🆕 发布|Advancing Metallic Surface Defect Detection via Anomaly-Guided Pretraining on a Large Industrial Dataset|通过在大型工业数据集上的异常引导预训练推进金属表面缺陷检测|Chuni Liu, Hongjie Li, Jiaqi Du, Yangyang Hou, Qian Sun, Lei Jin, Ke Xu|<http://arxiv.org/pdf/2509.18919v1>|[代码](https://clovermini.github.io/AGSSP-Dev); 提出了一种针对金属表面缺陷检测的异常引导预训练方法，有效缩小了领域差距并提升了检测性能。|
|📝 更新|HDM: Hybrid Diffusion Model for Unified Image Anomaly Detection|混合扩散模型：用于统一图像异常检测的模型|Zekang Weng, Jinjin Shi, Jinwei Wang, Zeming Han|<http://arxiv.org/pdf/2502.19200v2>|提出了一种混合扩散模型，统一了图像异常生成与检测任务，显著提升了异常检测的准确性和效率。|
|📝 更新|SAM-DCE: Addressing Token Uniformity and Semantic Over-Smoothing in Medical Segmentation|SAM-DCE: 针对医学分割中的标记均匀性和语义过平滑问题进行研究|Yingzhen Hu, Yiheng Zhong, Ruobing Li, Yingxue Su, Jiabao An, Feilong Tang, Jionglong Su, Imran Razzak|<http://arxiv.org/pdf/2509.16886v2>|提出SAM-DCE模型，解决医学图像分割中的均匀性问题和语义过度平滑问题，增强类间分离度和细粒度表示...|
|🆕 发布|A Kernel Space-based Multidimensional Sparse Model for Dynamic PET Image Denoising|基于核空间的多维稀疏模型用于动态PET图像去噪|Kuang Xiaodong, Li Bingxuan, Li Yuan, Rao Fan, Ma Gege, Xie Qingguo, Mok Greta S P, Liu Huafeng .etc.|<http://arxiv.org/pdf/2509.18801v1>|[代码](https://github.com/Kuangxd/Neural-KMDS-Net); 提出了一种基于核空间的多维稀疏模型及神经网络，有效提升了动态PET图像的去噪性能。|
|🆕 发布|DiSSECT: Structuring Transfer-Ready Medical Image Representations through Discrete Self-Supervision|DiSSECT：通过离散自监督构建迁移就绪的医学图像表征|Azad Singh, Deepak Mishra|<http://arxiv.org/pdf/2509.18765v1>|引入DiSSECT框架，通过离散自监督学习提升医学图像表示的迁移性，减少标签依赖。|
|📝 更新|TinyDef-DETR: A DETR-based Framework for Defect Detection in Transmission Lines from UAV Imagery|基于DETR的无人机影像输电线路缺陷检测框架：TinyDef-DETR|Feng Shen, Jiaming Cui, Shuai Zhou, Wenqiang Li, Ruifeng Qin|<http://arxiv.org/pdf/2509.06035v5>|提出TinyDef-DETR框架，通过增强边界敏感性和多尺度注意力机制，有效检测输电线路中的微小缺陷...|
|🆕 发布|Lightweight Vision Transformer with Window and Spatial Attention for Food Image Classification|轻量级视觉变换器：结合窗口与空间注意力进行食品图像分类|Xinle Gao, Linghui Ye, Zhiyong Xiao|<http://arxiv.org/pdf/2509.18692v1>|提出了一种结合窗口和空间注意力机制的轻量级视觉Transformer，有效平衡了计算效率与食品图像分...|
|🆕 发布|MLF-4DRCNet: Multi-Level Fusion with 4D Radar and Camera for 3D Object Detection in Autonomous Driving|MLF-4DRCNet：基于4D雷达与相机多级融合的自动驾驶三维目标检测|Yuzhi Wu, Li Xiao, Jun Liu, Guangfeng Jiang, XiangGen Xia|<http://arxiv.org/pdf/2509.18613v1>|提出MLF-4DRCNet，通过多级融合4D雷达和相机数据，显著提升自动驾驶中3D物体检测性能。|
|📝 更新|MediSyn: A Generalist Text-Guided Latent Diffusion Model For Diverse Medical Image Synthesis|MediSyn：一种用于多样化医学图像合成的通用文本引导潜在扩散模型|Joseph Cho, Mrudang Mathur, Cyril Zakka, Dhamanpreet Kaur, Matthew Leipzig, Alex Dalal, Aravind Krishnan, Eubee Koo .etc.|<http://arxiv.org/pdf/2405.09806v5>|MediSyn通过文本引导的潜在扩散模型，实现了跨医学专业和成像模态的多样化医疗图像合成，有效解决了...|
|📝 更新|Multimodal Medical Image Classification via Synergistic Learning Pre-training|通过协同学习预训练的多模态医学图像分类|Qinghua Lin, Guang-Hai Liu, Zuoyong Li, Yang Li, Yuting Jiang, Xiang Wu|<http://arxiv.org/pdf/2509.17492v2>|[代码](https://github.com/LQH89757/MICS.); 提出了一种基于“预训练+微调”的多模态半监督医学图像分类框架，通过协同学习预训练和分布偏移方法有效融...|
|🆕 发布|MK-UNet: Multi-kernel Lightweight CNN for Medical Image Segmentation|MK-UNet：多核轻量级卷积神经网络用于医学图像分割|Md Mostafijur Rahman, Radu Marculescu|<http://arxiv.org/pdf/2509.18493v1>|[代码](https://github.com/SLDGroup/MK-UNet.); 提出MK-UNet，一种多核轻量级卷积神经网络，用于医疗图像分割，大幅提升准确度同时降低计算负担。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|The Impact of 2D Segmentation Backbones on Point Cloud Predictions Using 4D Radar|二维分割基础模型对使用四维雷达的点云预测的影响|William L. Muckelroy III, Mohammed Alsakabi, John M. Dolan, Ozan K. Tonguz|<http://arxiv.org/pdf/2509.19644v1>|探究2D分割网络对4D雷达生成点云质量的影响，发现最优模型提升性能23.7%。|
|🆕 发布|Zero-Shot Multi-Spectral Learning: Reimagining a Generalist Multimodal Gemini 2.5 Model for Remote Sensing Applications|零样本多光谱学习：重新构想一种用于遥感应用的全能型多模态双子座2.5模型|Ganesh Mallya, Yotam Gigi, Dahun Kim, Maxim Neumann, Genady Beryozkin, Tomer Shekel, Anelia Angelova|<http://arxiv.org/pdf/2509.19087v1>|提出了一种无需训练的零样本学习方法，使通用多模态模型能够直接处理多光谱数据，提升遥感应用中的分类性能...|
|🆕 发布|RS3DBench: A Comprehensive Benchmark for 3D Spatial Perception in Remote Sensing|遥感三维空间感知的全面基准测试：RS3DBench|Jiayu Wang, Ruizhi Wang, Jie Song, Haofei Zhang, Mingli Song, Zunlei Feng, Li Sun|<http://arxiv.org/pdf/2509.18897v1>|提出了RS3DBench，一个包含54,951对遥感图像与像素级对齐深度图的全面基准，推动遥感图像3...|
|📝 更新|JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust Multi-Teacher Knowledge Distillation Framework|JL1-CD：一种新的遥感变化检测基准及稳健的多教师知识蒸馏框架|Ziyuan Liu, Ruifei Zhu, Long Gao, Yuanxiu Zhou, Jingyu Ma, Yuantao Gu|<http://arxiv.org/pdf/2502.13407v4>|[代码](https://github.com/circleLZY/MTKD-CD.); 提出大规模遥感变化检测数据集JL1-CD，并创新多教师知识蒸馏框架提升模型泛化性能。|
|🆕 发布|OSDA: A Framework for Open-Set Discovery and Automatic Interpretation of Land-cover in Remote Sensing Imagery|OSDA：一种遥感影像中地表覆盖的开集发现与自动解释框架|Siyi Chen, Kai Wang, Weicong Pang, Ruiming Yang, Ziru Chen, Renjun Gao, Alexis Kai Hon Lau, Dasa Gu .etc.|<http://arxiv.org/pdf/2509.18693v1>|提出OSDA框架，实现无需标注的遥感影像开放集土地覆盖自动发现与解释。|
|🆕 发布|Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment|无需源域的遥感图像扩散引导标签增强自适应语义分割|Wenjie Liu, Hongmin Liu, Lixin Zhang, Bin Fan|<http://arxiv.org/pdf/2509.18502v1>|提出了一种基于扩散模型的高质量伪标签优化框架，有效提升无源域自适应遥感图像语义分割性能。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EMMA: End-to-End Multimodal Model for Autonomous Driving|EMMA：面向自动驾驶的端到端多模态模型|Jyh-Jing Hwang, Runsheng Xu, Hubert Lin, Wei-Chih Hung, Jingwei Ji, Kristy Choi, Di Huang, Tong He .etc.|<http://arxiv.org/pdf/2410.23262v3>|提出EMMA模型，将原始摄像头数据直接转化为驾驶相关输出，实现自主驾驶任务的一体化处理。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Leveraging Large Models to Evaluate Novel Content: A Case Study on Advertisement Creativity|利用大型模型评估新颖内容：广告创意的案例研究|Zhaoyi Joey Hou, Adriana Kovashka, Xiang Lorraine Li|<http://arxiv.org/pdf/2503.00046v2>|提出评估视觉广告创造性的新方法，通过分解为非常规性和原创性，并验证了先进视觉语言模型与人类评价的一致...|


### 可解释视觉智能 (Explainable Visual Intelligence)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|xAI-CV: An Overview of Explainable Artificial Intelligence in Computer Vision|xAI-CV：计算机视觉中可解释人工智能的概述|Nguyen Van Tu, Pham Nguyen Hai Long, Vo Hoai Viet|<http://arxiv.org/pdf/2509.18913v1>|概述了计算机视觉中可解释人工智能的四种方法，以增强模型决策的透明度和可靠性。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Human-Interpretable Uncertainty Explanations for Point Cloud Registration|点云配准中的人类可解释不确定性解释|Johannes A. Gaus, Loris Schneider, Yitian Shi, Jongseok Lee, Rania Rayyes, Rudolph Triebel|<http://arxiv.org/pdf/2509.18786v2>|提出了一种新的点云配准方法 GP-CA，量化并解释配准不确定性，有效应对传感器噪声和姿态估计误差等问...|
|🆕 发布|HUNT: High-Speed UAV Navigation and Tracking in Unstructured Environments via Instantaneous Relative Frames|HUNT：通过瞬时相对帧在非结构化环境中实现的高速无人机导航与跟踪|Alessandro Saviolo, Jeffrey Mao, Giuseppe Loianno|<http://arxiv.org/pdf/2509.19452v1>|实现了无全局定位下的高速无人机导航与目标跟踪统一框架，适应未知非结构化环境。|
|📝 更新|Evaluation Framework of Superpixel Methods with a Global Regularity Measure|超像素方法的评估框架：基于全局正则性度量|Rémi Giraud, Vinh-Thong Ta, Nicolas Papadakis|<http://arxiv.org/pdf/1903.07162v2>|提出统一的超像素方法评估框架，引入全局规则性度量，减少比较过程中的偏差。|
|🆕 发布|Overview of LifeCLEF Plant Identification task 2020|《2020年LifeCLEF植物识别任务概述》|Herve Goeau, Pierre Bonnet, Alexis Joly|<http://arxiv.org/pdf/2509.19402v1>|利用数字化植物标本，提升了数据缺乏区域植物自动识别的准确性。|
|🆕 发布|Overview of LifeCLEF Plant Identification task 2019: diving into data deficient tropical countries|《2019年LifeCLEF植物识别任务概述：深入数据匮乏的热带国家》|Herve Goeau, Pierre Bonnet, Alexis Joly|<http://arxiv.org/pdf/2509.18705v1>|概述了2019年LifeCLEF植物识别任务，针对数据缺乏的热带地区植物识别挑战，分析了参赛方法及成...|
|🆕 发布|Overview of PlantCLEF 2021: cross-domain plant identification|《2021年PlantCLEF概述：跨领域植物识别》|Herve Goeau, Pierre Bonnet, Alexis Joly|<http://arxiv.org/pdf/2509.18697v1>|利用数字化植物标本提升数据贫乏区域植物自动识别准确率。|
|📝 更新|A Chain-of-thought Reasoning Breast Ultrasound Dataset Covering All Histopathology Categories|一个涵盖所有组织病理学类别的链式思维推理乳腺超声数据集|Haojun Yu, Youcheng Li, Zihan Niu, Nan Zhang, Xuantong Gong, Huan Li, Zhiying Zou, Haifeng Qi .etc.|<http://arxiv.org/pdf/2509.17046v2>|构建了一个全面覆盖99种病理类型的乳腺超声图像数据集，促进链式思维推理分析以增强AI诊断准确性。|

