## [UPDATED!] **2025-09-24** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Video models are zero-shot learners and reasoners|视频模型是零样本学习者和推理者|Thaddäus Wiedemer, Yuxuan Li, Paul Vicol, Shixiang Shane Gu, Nick Matarese, Kevin Swersky, Been Kim, Priyank Jaini .etc.|<http://arxiv.org/pdf/2509.20328v1>|证明了视频模型具有零样本学习能力，可进行通用视觉理解，类似于大型语言模型的通用语言理解能力。|
|🆕 发布|A Versatile Foundation Model for AI-enabled Mammogram Interpretation|一种用于AI辅助乳腺X线照片解读的通用基础模型|Fuxiang Huang, Jiayi Zhu, Yunfang Yu, Yu Xie, Yuan Guo, Qingcong Kong, Mingxiang Wu, Xinrui Jiang .etc.|<http://arxiv.org/pdf/2509.20271v1>|提出了一种全面的哺乳动物影像基础模型VersaMammo，通过大规模多机构数据集和双阶段预训练策略，...|
|📝 更新|Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning|柑橘V：通过统一医学图像定位推进医学基础模型以用于临床推理|Guoxin Wang, Jun Zhao, Xinyi Liu, Yanbo Liu, Xuyang Cao, Chao Li, Zhuoyun Liu, Qintian Sun .etc.|<http://arxiv.org/pdf/2509.19090v2>|提出了一种统一的多模态医疗基础模型Citrus-V，将图像分析与文本推理结合，实现了从视觉定位到临床...|
|🆕 发布|CHURRO: Making History Readable with an Open-Weight Large Vision-Language Model for High-Accuracy, Low-Cost Historical Text Recognition|CHURRO：利用开放权重大型视觉-语言模型实现高精度、低成本历史文本识别，让历史变得可读|Sina J. Semnani, Han Zhang, Xinyan He, Merve Tekgürler, Monica S. Lam|<http://arxiv.org/pdf/2509.19768v1>|提出CHURRO模型，专用于高精度、低成本的历史文本识别，大幅超越现有技术。|
|📝 更新|EDBench: Large-Scale Electron Density Data for Molecular Modeling|EDBench：大规模电子密度数据集用于分子建模|Hongxin Xiang, Ke Li, Mingquan Liu, Zhixiang Cheng, Bin Yao, Wenjie Du, Jun Xia, Li Zeng .etc.|<http://arxiv.org/pdf/2505.09262v2>|提出了EDBench，一个大规模高质电子密度数据集，助力基于学习的电子尺度研究，降低计算成本。|
|📝 更新|VLM See, Robot Do: Human Demo Video to Robot Action Plan via Vision Language Model|通过视觉语言模型将人类演示视频转化为机器人动作计划：VLM观看，机器人执行|Beichen Wang, Juexiao Zhang, Shuwen Dong, Irving Fang, Chen Feng|<http://arxiv.org/pdf/2410.08792v2>|利用视觉语言模型解析人类示范视频，生成机器人任务规划，实现高效模仿学习。|
|🆕 发布|Rectified Decoupled Dataset Distillation: A Closer Look for Fair and Comprehensive Evaluation|修正解耦数据集蒸馏：对公平与全面评估的深入探讨|Xinhao Zhong, Shuoyang Sun, Xulin Gu, Chenyang Zhu, Bin Chen, Yaowei Wang|<http://arxiv.org/pdf/2509.19743v1>|提出了一种标准化基准和严格评估协议的Rectified Decoupled Dataset Dist...|
|📝 更新|SurgVidLM: Towards Multi-grained Surgical Video Understanding with Large Language Model|面向多粒度手术视频理解的大语言模型：SurgVidLM|Guankun Wang, Junyi Wang, Wenjin Mo, Long Bai, Kun Yuan, Ming Hu, Jinlin Wu, Junjun He .etc.|<http://arxiv.org/pdf/2506.17873v2>|提出SurgVidLM模型，通过双阶段分析和多频率融合注意机制，实现手术视频的全局与细粒度理解。|
|📝 更新|Rethinking Pulmonary Embolism Segmentation: A Study of Current Approaches and Challenges with an Open Weight Model|重新思考肺栓塞分割：当前方法与挑战研究及开放权重模型|Yixin Zhang, Ryan Chamberlain, Lawrence Ngo, Kevin Kramer, Maciej A. Mazurowski|<http://arxiv.org/pdf/2509.18308v2>|系统评估了九种分割架构在肺栓塞检测中的应用效果，发现3D U-Net结合ResNet编码器表现最优，...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Enhancing Targeted Adversarial Attacks on Large Vision-Language Models via Intermediate Projector|通过中间投影器增强对大型视觉-语言模型的有针对性的对抗攻击|Yiming Cao, Yanjie Li, Kaisheng Liang, Bin Xiao|<http://arxiv.org/pdf/2508.13739v2>|提出了一种利用中间投影器增强大型视觉语言模型针对性攻击的新框架，提高了攻击的有效性和粒度。|
|🆕 发布|Hyperspectral Adapter for Semantic Segmentation with Vision Foundation Models|用于视觉基础模型语义分割的超光谱适配器|JuanaJuana Valeria Hurtado, Rohit Mohan, Abhinav Valada|<http://arxiv.org/pdf/2509.20107v1>|提出了一种利用预训练视觉基础模型学习 hyperspectral 数据的新颖适配器，实现了领先的语义...|
|📝 更新|Lavida-O: Elastic Large Masked Diffusion Models for Unified Multimodal Understanding and Generation|拉维达-O：用于统一多模态理解和生成的弹性大遮罩扩散模型|Shufan Li, Jiuxiang Gu, Kangning Liu, Zhe Lin, Zijun Wei, Aditya Grover, Jason Kuen|<http://arxiv.org/pdf/2509.19244v2>|提出Lavida-O模型，统一实现多模态理解和生成，提升图像理解和编辑能力及生成质量。|
|🆕 发布|Enhancing Transformer-Based Vision Models: Addressing Feature Map Anomalies Through Novel Optimization Strategies|通过创新优化策略增强基于Transformer的视觉模型：解决特征图异常问题|Sumit Mamtani|<http://arxiv.org/pdf/2509.19687v1>|提出两种优化策略减轻视觉变换器模型中的噪声，提升了解释性和任务性能。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Multimodal Reference Visual Grounding|多模态参考视觉定位|Yangxiao Lu, Ruosen Li, Liqiang Jing, Jikai Wang, Xinya Du, Yunhui Guo, Nicholas Ruozzi, Yu Xiang|<http://arxiv.org/pdf/2504.02876v2>|[代码](https://irvlutd.github.io/MultiGrounding); 提出多模态参考视觉定位任务MRVG，利用参考图像和语言描述提升相似物体识别准确性。|
|🆕 发布|PS3: A Multimodal Transformer Integrating Pathology Reports with Histology Images and Biological Pathways for Cancer Survival Prediction|PS3：一种融合病理报告、组织学图像与生物通路的多模态Transformer，用于癌症生存预测|Manahil Raza, Ayesha Azam, Talha Qaiser, Nasir Rajpoot|<http://arxiv.org/pdf/2509.20022v1>|[代码](https://github.com/manahilr/PS3.); 提出了一种三模态Transformer模型PS3，通过整合病理报告、组织切片图像和生物通路信息，提高...|
|🆕 发布|When Words Can't Capture It All: Towards Video-Based User Complaint Text Generation with Multimodal Video Complaint Dataset|当文字无法捕捉一切：面向基于视频的用户投诉文本生成及多模态视频投诉数据集构建|Sarmistha Das, R E Zera Marveen Lyngkhoi, Kirtan Jain, Vinayak Goyal, Sriparna Saha, Manish Gupta|<http://arxiv.org/pdf/2509.19952v1>|[代码](https://github.com/sarmistha-D/CoD-V.); 提出视频辅助生成投诉文本新任务，创建ComVID数据集并设计情感感知生成模型。|
|📝 更新|SafeEraser: Enhancing Safety in Multimodal Large Language Models through Multimodal Machine Unlearning|SafeEraser：通过多模态机器遗忘增强多模态大型语言模型的安全性|Junkai Chen, Zhijie Deng, Kening Zheng, Yibo Yan, Shuliang Liu, PeiJun Wu, Peijie Jiang, Jia Liu .etc.|<http://arxiv.org/pdf/2502.12520v4>|提出了一种针对多模态大型语言模型的安全遗忘方法，通过引入Prompt Decouple Loss减少...|
|🆕 发布|ThinkFake: Reasoning in Multimodal Large Language Models for AI-Generated Image Detection|“ThinkFake：多模态大型语言模型中的推理用于AI生成图像检测”|Tai-Ming Huang, Wei-Tung Lin, Kai-Lung Hua, Wen-Huang Cheng, Junichi Yamagishi, Jun-Cheng Chen|<http://arxiv.org/pdf/2509.19841v1>|提出了一种基于推理和强化学习的AI生成图像检测框架，实现了更强的泛化能力和可解释性。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Comprehensive Evaluation of YOLO-based Deer Detection Performance on Edge Devices|基于YOLO的边缘设备上鹿检测性能的全面评估|Bishal Adhikari, Jiajia Li, Eric S. Michel, Jacob Dykes, Te-Ming Paul Tseng, Mary Love Tagert, Dong Chen|<http://arxiv.org/pdf/2509.20318v1>|[代码](https://github.com/WinnerBishal/track-the-deer.); 评估了YOLO系列模型在边缘设备上的鹿检测性能，并提供了专门的数据集。|
|🆕 发布|SDE-DET: A Precision Network for Shatian Pomelo Detection in Complex Orchard Environments|SDE-DET：复杂果园环境中沙田柚检测的精确网络|Yihao Hu, Pan Wang, Xiaodong Bai, Shijie Cai, Hang Wang, Huazhong Liu, Aiping Yang, Xiangxiang Li .etc.|<http://arxiv.org/pdf/2509.19990v1>|提出了SDE-DET模型，通过高效多尺度注意力和可变形注意力机制，有效检测复杂果园环境中的沙田柚。|
|🆕 发布|AJAHR: Amputated Joint Aware 3D Human Mesh Recovery|AJAHR：截肢关节感知的3D人体网格恢复|Hyunjin Cho, Giyun Choi, Jongwon Choi|<http://arxiv.org/pdf/2509.19939v1>|提出AJAHR模型，通过自适应姿态估计和专有数据集，优化了截肢者3D人体网格重建效果。|
|📝 更新|AutoOEP -- A Multi-modal Framework for Online Exam Proctoring|自动在线监考多模态框架——AutoOEP|Aryan Kashyap Naveen, Bhuvanesh Singla, Raajan Wankhade, Shreesha M, Ramu S, Ram Mohana Reddy Guddeti|<http://arxiv.org/pdf/2509.10887v2>|[代码](https://github.com/05kashyap/AutoOEP.); 提出了一种多模态在线监考框架AutoOEP，利用计算机视觉和机器学习技术自动化检测作弊行为，显著减少...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PolypSeg-GradCAM: Towards Explainable Computer-Aided Gastrointestinal Disease Detection Using U-Net Based Segmentation and Grad-CAM Visualization on the Kvasir Dataset|《PolypSeg-GradCAM：基于U-Net分割和Grad-CAM可视化的Kvasir数据集胃肠道疾病检测的可解释计算机辅助方法》|Akwasi Asare, Ulas Bagci|<http://arxiv.org/pdf/2509.18159v2>|提出了一种结合U-Net和Grad-CAM的可解释深度学习框架，实现了高准确度的胃肠道息肉分割并增强...|
|📝 更新|LiDAR MOT-DETR: A LiDAR-based Two-Stage Transformer for 3D Multiple Object Tracking|激光雷达MOT-DETR：一种基于激光雷达的两阶段Transformer用于三维多目标跟踪|Martha Teiko Teye, Ori Maoz, Matthias Rottmann|<http://arxiv.org/pdf/2505.12753v3>|提出了一种基于LiDAR数据的两阶段Transformer模型，通过优化检测和跟踪，显著提升了3D多...|
|🆕 发布|Table Detection with Active Learning|主动学习中的表格检测|Somraj Gautam, Nachiketa Purohit, Gaurav Harit|<http://arxiv.org/pdf/2509.20003v1>|利用主动学习策略选取代表性样本，有效减少标注工作量同时保持模型性能。|
|🆕 发布|Adaptive Guidance Semantically Enhanced via Multimodal LLM for Edge-Cloud Object Detection|通过多模态大规模语言模型增强的边缘-云目标检测自适应引导|Yunqing Hu, Zheming Yang, Chang Zhao, Wen Ji|<http://arxiv.org/pdf/2509.19875v1>|提出了一种结合多模态大语言模型的边缘-云协同对象检测方法，通过自适应语义增强显著提升了复杂场景下的检...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Interpreting ResNet-based CLIP via Neuron-Attention Decomposition|通过神经元注意力分解解释基于ResNet的CLIP|Edmund Bu, Yossi Gandelsman|<http://arxiv.org/pdf/2509.19943v1>|提出了一种分解CLIP-ResNet神经元贡献的新技术，通过分析神经元与注意力头的关系，实现了无训练...|
|📝 更新|Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation|“迷失在翻译中？面向开放词汇语义分割的无源域自适应词汇对齐”|Silvio Mazzucco, Carl Persson, Mattia Segu, Pier Luigi Dovesi, Federico Tombari, Luc Van Gool, Matteo Poggi|<http://arxiv.org/pdf/2509.15225v2>|提出VocAlign框架，通过词汇对齐策略和Top-K选择机制，实现了无需源域数据的开放词汇语义分割...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Infrared Image Super-Resolution: Systematic Review, and Future Trends|红外图像超分辨率：系统性综述及未来趋势|Yongsong Huang, Tomo Miyazaki, Xiaofeng Liu, Shinichiro Omachi|<http://arxiv.org/pdf/2212.12322v5>|[代码](https://github.com/yongsongH/Infrared_Image_SR_Survey.); 系统综述了红外图像超分辨率技术，并探讨了未来发展趋势。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EditVerse: Unifying Image and Video Editing and Generation with In-Context Learning|编辑宇宙：通过上下文学习统一图像与视频编辑及生成|Xuan Ju, Tianyu Wang, Yuqian Zhou, He Zhang, Qing Liu, Nanxuan Zhao, Zhifei Zhang, Yijun Li .etc.|<http://arxiv.org/pdf/2509.20360v1>|EditVerse统一了图像与视频的生成与编辑，通过自注意力机制实现跨模态学习，解决了视频编辑数据不...|
|🆕 发布|VisualMimic: Visual Humanoid Loco-Manipulation via Motion Tracking and Generation|视觉模仿：通过运动追踪与生成实现的视觉仿人机器人定位-操作|Shaofeng Yin, Yanjie Ze, Hong-Xing Yu, C. Karen Liu, Jiajun Wu|<http://arxiv.org/pdf/2509.20322v1>|引入VisualMimic框架，通过视觉跟踪与生成实现人形机器人零样本迁移，完成多样化动作任务。|
|📝 更新|LEDiT: Your Length-Extrapolatable Diffusion Transformer without Positional Encoding|LEDiT：无需位置编码的长度外推扩散变换器|Shen Zhang, Siyuan Liang, Yaning Tan, Zhaowei Chen, Linze Li, Ge Wu, Yuhao Chen, Shuheng Li .etc.|<http://arxiv.org/pdf/2503.04344v3>|[代码](https://shenzhang2145.github.io/ledit); LEDiT通过采用无需位置编码的因果注意力机制，实现了图像分辨率的无缝扩展，显著提升了高分辨率图像生...|
|🆕 发布|PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video Generation|PhysCtrl：可控且符合物理规律的生成式物理视频生成|Chen Wang, Chuhao Chen, Yiming Huang, Zhiyang Dou, Yuan Liu, Jiatao Gu, Lingjie Liu|<http://arxiv.org/pdf/2509.20358v1>|[代码](https://cwchenwang.github.io/physctrl); 提出了PhysCtrl框架，通过结合物理参数和力控制，实现了具有物理可信度的可控视频生成。|
|🆕 发布|FAST: Foreground-aware Diffusion with Accelerated Sampling Trajectory for Segmentation-oriented Anomaly Synthesis|FAST：面向分割的目标异常合成中的前景感知扩散与加速采样轨迹|Xichen Xu, Yanshu Wang, Jinbao Wang, Xiaoning Lei, Guoyang Xie, Guannan Jiang, Zhichao Lu|<http://arxiv.org/pdf/2509.20295v1>|提出了一种前景感知的扩散框架FAST，通过加速采样轨迹和自适应调整噪声，高效生成面向分割的工业异常。|
|📝 更新|DreamMix: Decoupling Object Attributes for Enhanced Editability in Customized Image Inpainting|梦幻混合：解耦对象属性以增强定制图像修复的编辑性|Yicheng Yang, Pengxiang Li, Lu Zhang, Liqian Ma, Ping Hu, Siyu Du, Yunzhi Zhuge, Xu Jia .etc.|<http://arxiv.org/pdf/2411.17223v2>|DreamMix分离对象属性以增强定制图像修复的编辑性，通过独特机制实现身份保持与属性编辑的平衡。|
|🆕 发布|4D Driving Scene Generation With Stereo Forcing|立体驱动强制下的四维驾驶场景生成|Hao Lu, Zhuang Ma, Guangfeng Jiang, Wenhang Ge, Bohan Li, Yuzhan Cai, Wenzhao Zheng, Yunpeng Zhang .etc.|<http://arxiv.org/pdf/2509.20251v1>|[代码](https://jiangxb98.github.io/PhiGensis); 提出PhiGenesis框架，通过结合视频生成技术和几何一致性，实现了无需逐场景优化的动态4D驾驶场...|
|📝 更新|Long Video Understanding with Learnable Retrieval in Video-Language Models|长视频理解：基于可学习检索的视频-语言模型|Jiaqi Xu, Cuiling Lan, Wenxuan Xie, Xuejin Chen, Yan Lu|<http://arxiv.org/pdf/2312.04931v3>|提出了一种基于可学习检索的长视频理解模型，通过选择与问题最相关的视频片段，有效降低了计算成本并提高了...|
|📝 更新|HAZEMATCHING: Dehazing Light Microscopy Images with Guided Conditional Flow Matching|HAZEMATCHING：使用引导条件流匹配去雾化光学显微镜图像|Anirban Ray, Ashesh, Florian Jug|<http://arxiv.org/pdf/2506.22397v4>|提出了一种平衡清晰度和真实感的去雾方法HazeMatching，通过引导性条件流匹配改善显微镜图像质...|
|📝 更新|Understanding-in-Generation: Reinforcing Generative Capability of Unified Model via Infusing Understanding into Generation|《生成中的理解：通过将理解融入生成来强化统一模型的生成能力》|Yuanhuiyi Lyu, Chi Kit Wong, Chenfei Liao, Lutao Jiang, Xu Zheng, Zexin Lu, Linfeng Zhang, Xuming Hu|<http://arxiv.org/pdf/2509.18639v2>|[代码](https://github.com/QC-LY/UiG); 提出Understanding-in-Generation框架，通过融合理解能力提升统一模型在图像生...|
|📝 更新|OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling|全方位世界：一个用于四维世界建模的多领域和多模态数据集|Yang Zhou, Yifan Wang, Jianjun Zhou, Wenzheng Chang, Haoyu Guo, Zizun Li, Kaijing Ma, Xinyue Li .etc.|<http://arxiv.org/pdf/2509.12201v2>|提出了OmniWorld多领域、多模态数据集，为4D世界建模提供了高质量数据，提升了模型性能。|
|🆕 发布|Does the Manipulation Process Matter? RITA: Reasoning Composite Image Manipulations via Reversely-Ordered Incremental-Transition Autoregression|《操纵过程重要吗？RITA：通过反向顺序增量转换自回归进行复合图像操纵推理》|Xuekang Zhu, Ji-Zhe Zhou, Kaiwen Feng, Chenfan Qu, Yunfei Wang, Liting Zhou, Jian liu|<http://arxiv.org/pdf/2509.20006v1>|首次将图像操纵定位任务重构为条件序列预测问题，提出RITA框架逐层预测操纵区域，显式建模编辑操作间的...|
|🆕 发布|MultiSoundGen: Video-to-Audio Generation for Multi-Event Scenarios via SlowFast Contrastive Audio-Visual Pretraining and Direct Preference Optimization|多事件场景下的视频转音频生成：通过慢快对比视听预训练和直接偏好优化|Jianxuan Yang, Xiaoran Yang, Lipan Zhang, Xinyue Guo, Zhao Wang, Gongping Huang|<http://arxiv.org/pdf/2509.19999v1>|提出MultiSoundGen框架，通过慢快对比视听预训练和直接偏好优化，提升多事件场景下的视频转音...|
|🆕 发布|MeshMosaic: Scaling Artist Mesh Generation via Local-to-Global Assembly|《MeshMosaic：通过局部到全局组装扩展艺术家网格生成规模》|Rui Xu, Tianyang Xue, Qiujie Dong, Le Wan, Zhe Zhu, Peng Li, Zhiyang Dou, Cheng Lin .etc.|<http://arxiv.org/pdf/2509.19995v1>|提出MeshMosaic方法，通过局部到全局框架实现艺术家网格的高效生成，扩展至超过100K三角形，...|
|📝 更新|GaussianSeal: Rooting Adaptive Watermarks for 3D Gaussian Generation Model|高斯印章：为3D高斯生成模型植入自适应水印|Runyi Li, Xuanyu Zhang, Chuhan Tong, Zhipei Xu, Jian Zhang|<http://arxiv.org/pdf/2503.00531v2>|分类|
|🆕 发布|CamPVG: Camera-Controlled Panoramic Video Generation with Epipolar-Aware Diffusion|CamPVG：基于极线感知扩散的相机控制全景视频生成|Chenhao Ji, Chaohui Yu, Junyao Gao, Fan Wang, Cairong Zhao|<http://arxiv.org/pdf/2509.19979v1>|首次提出基于精确相机姿态的全景视频生成框架，通过球形投影和新型编码方法提高了视频质量和一致性。|
|🆕 发布|SynchroRaMa : Lip-Synchronized and Emotion-Aware Talking Face Generation via Multi-Modal Emotion Embedding|同步RaMa：通过多模态情感嵌入实现唇同步和情感感知的说话人脸生成|Phyo Thet Yee, Dimitrios Kollias, Sudeepta Mishra, Abhinav Dhall|<http://arxiv.org/pdf/2509.19965v1>|[代码](https://novicemm.github.io/synchrorama); 提出了SynchroRaMa框架，通过融合文本和音频的情感信号，生成具有更丰富、真实情感表达和唇同步...|
|🆕 发布|Talking Head Generation via AU-Guided Landmark Prediction|通过AU引导的标记预测实现说话人头生成|Shao-Yu Chang, Jingyi Xu, Hieu Le, Dimitris Samaras|<http://arxiv.org/pdf/2509.19749v1>|提出两阶段框架，通过面部动作单元精确控制表情生成，提升视频真实感和稳定性。|
|📝 更新|Ctrl-Room: Controllable Text-to-3D Room Meshes Generation with Layout Constraints|可控文本到三维房间网格生成：具有布局约束的Ctrl-Room方法|Chuan Fang, Yuan Dong, Kunming Luo, Xiaotao Hu, Rakesh Shrestha, Ping Tan|<http://arxiv.org/pdf/2310.03602v5>|提出Ctrl-Room方法，通过分离布局与外观建模，实现从文本生成高质量、可编辑的3D室内场景。|
|🆕 发布|Robust RGB-T Tracking via Learnable Visual Fourier Prompt Fine-tuning and Modality Fusion Prompt Generation|通过可学习视觉傅里叶提示微调与模态融合提示生成实现的稳健RGB-T跟踪|Hongtao Yang, Bineng Zhong, Qihua Liang, Zhiruo Zhu, Yaozong Zheng, Ning Li|<http://arxiv.org/pdf/2509.19733v1>|提出了一种融合频率域信息与模态交互的RGB-T跟踪方法，有效提升了跟踪性能。|
|🆕 发布|CAMILA: Context-Aware Masking for Image Editing with Language Alignment|《CAMILA：基于语言对齐的图像编辑上下文感知遮罩》|Hyunseung Kim, Chiho Choi, Srikanth Malla, Sai Prahladh Padmanabhan, Saurabh Bagchi, Joon Hee Choi|<http://arxiv.org/pdf/2509.19731v1>|提出了一种上下文感知的图像编辑方法CAMILA，有效处理了文本指导下的矛盾指令，提高了编辑的准确性和...|
|📝 更新|Sample what you cant compress|无法压缩的内容采样|Vighnesh Birodkar, Gabriel Barcik, James Lyon, Sergey Ioffe, David Minnen, Joshua V. Dillon|<http://arxiv.org/pdf/2409.02529v4>|提出结合自动编码与扩散模型的方法，实现高质量图像生成与压缩。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CLIP Can Understand Depth|CLIP能够理解深度信息|Sohee Kim, Jisu Kang, Dunam Kim, Seokju Lee|<http://arxiv.org/pdf/2402.03251v2>|提出了一种利用定制嵌入矩阵改进CLIP深度理解的方法，无需微调即可达到先进水平。|
|📝 更新|Latent Wavelet Diffusion For Ultra-High-Resolution Image Synthesis|潜在小波扩散用于超高分辨率图像合成|Luigi Sigillo, Shengfeng He, Danilo Comminiello|<http://arxiv.org/pdf/2506.00433v3>|提出了一种基于小波能量图的频率感知掩码策略，显著提升了超高清图像合成的细节和纹理保真度。|
|📝 更新|Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning via Image-Guided Diffusion|扩散课程：通过图像引导扩散实现的从合成到真实的生成课程学习|Yijun Liang, Shweta Bhardwaj, Tianyi Zhou|<http://arxiv.org/pdf/2410.13674v3>|提出了一种通过图像引导的扩散模型生成数据，并构建了“扩散课程”学习策略，有效提升了模型对少量或低质量...|
|🆕 发布|Unleashing the Potential of the Semantic Latent Space in Diffusion Models for Image Dehazing|释放扩散模型中语义潜在空间在图像去雾中的潜力|Zizheng Yang, Hu Yu, Bing Li, Jinghao Zhang, Jie Huang, Feng Zhao|<http://arxiv.org/pdf/2509.20091v1>|[代码](https://github.com/aaaasan111/difflid.); 利用预训练扩散模型的语义潜在空间，提出DiffLI$^2$D网络，有效避免模型重训练和迭代采样，实现...|
|📝 更新|Diffusion models for multivariate subsurface generation and efficient probabilistic inversion|用于多变量地下生成和高效概率反演的扩散模型|Roberto Miele, Niklas Linde|<http://arxiv.org/pdf/2507.15809v2>|提出基于扩散模型的多变量地下建模与高效概率反演方法，提升了统计稳健性和后验概率密度采样。|
|🆕 发布|Predictive Quality Assessment for Mobile Secure Graphics|移动安全图形的预测性质量评估|Cas Steigstra, Sergey Milyaev, Shaodi You|<http://arxiv.org/pdf/2509.20028v1>|提出预测性质量评估框架，通过轻量级模型预测图像帧对验证任务适用性，提高移动设备安全图形验证可靠性。|
|🆕 发布|SHMoAReg: Spark Deformable Image Registration via Spatial Heterogeneous Mixture of Experts and Attention Heads|SHMoAReg：基于空间异质专家混合与注意力头的Spark可变形图像配准|Yuxi Zheng, Jianhui Feng, Tianran Li, Marius Staring, Yuchuan Qiao|<http://arxiv.org/pdf/2509.20073v1>|提出了一种基于混合专家和注意力头的图像配准方法，通过专化特征提取和异向变形预测，显著提升了配准精度。|
|🆕 发布|GS-RoadPatching: Inpainting Gaussians via 3D Searching and Placing for Driving Scenes|GS-RoadPatching：通过三维搜索与放置进行驾驶场景高斯图像修复|Guo Chen, Jiarun Liu, Sicong Du, Chenming Wu, Deqi Li, Shi-Sheng Huang, Guofeng Zhang, Sheng Yang|<http://arxiv.org/pdf/2509.19937v1>|[代码](https://shanzhaguoo.github.io/GS-RoadPatching); 提出了一种基于3D Gaussian Splatting的直接替换式修补方法，有效处理驾驶场景中的图...|
|🆕 发布|Aerial-Ground Image Feature Matching via 3D Gaussian Splatting-based Intermediate View Rendering|基于三维高斯散点绘制中间视图渲染的天地图像特征匹配|Jiangxue Yu, Hui Wang, San Jiang, Xing Zhang, Dejin Zhang, Qingquan Li|<http://arxiv.org/pdf/2509.19898v1>|提出了一种通过3D高斯散点渲染中间视图以缓解视角变化引起的透视畸变，实现可靠空地图像特征匹配的方法。|
|📝 更新|Efficient Rectified Flow for Image Fusion|高效修正流图像融合方法|Zirui Wang, Jiayi Zhang, Tianwei Guan, Yuhan Zhou, Xingyuan Li, Minjing Dong, Jinyuan Liu|<http://arxiv.org/pdf/2509.16549v2>|[代码](https://github.com/zirui0625/RFfusion.); 提出了一种基于Rectified Flow的高效一步扩散模型RFfusion，用于图像融合，大幅提升...|
|📝 更新|MOIS-SAM2: Exemplar-based Segment Anything Model 2 for multilesion interactive segmentation of neurofibromas in whole-body MRI|MOIS-SAM2：基于示例的Segment Anything模型2，用于全身MRI中神经纤维瘤的多病变交互式分割|Georgii Kolokolnikov, Marie-Lena Schmalhofer, Sophie Goetz, Lennart Well, Said Farschtschi, Victor-Felix Mautner, Inka Ristow, Rene Werner|<http://arxiv.org/pdf/2509.19277v2>|提出了一种针对全身MRI中神经纤维瘤的高效、可扩展交互式分割模型，通过示例引导的语义传播提高了分割精...|
|📝 更新|Cross-Domain Underwater Image Enhancement Guided by No-Reference Image Quality Assessment: A Transfer Learning Approach|跨域水下图像增强：基于无需参考图像质量评估的迁移学习方法|Zhi Zhang, Minfu Li, Lu Li, Daoyi Chen|<http://arxiv.org/pdf/2503.17937v2>|提出了一种基于迁移学习的跨域水下图像增强方法，利用无参考图像质量评估引导，有效解决了域差异和数据稀缺...|
|🆕 发布|EfficienT-HDR: An Efficient Transformer-Based Framework via Multi-Exposure Fusion for HDR Reconstruction|高效HDR：一种通过多曝光融合实现HDR重建的高效Transformer框架|Yu-Shen Huang, Tzu-Han Chen, Cheng-Yen Hsiao, Shaou-Gang Miaou|<http://arxiv.org/pdf/2509.19779v1>|提出了一种基于轻量级Transformer架构的高动态范围成像方法，有效降低了计算成本并减少了鬼影现...|
|🆕 发布|From Prompt to Progression: Taming Video Diffusion Models for Seamless Attribute Transition|从提示到进展：驯服视频扩散模型以实现无缝属性转换|Ling Lo, Kelvin C. K. Chan, Wen-Huang Cheng, Ming-Hsuan Yang|<http://arxiv.org/pdf/2509.19690v1>|[代码](https://github.com/lynn-ling-lo/Prompt2Progression.); 提出了一种引导视频扩散模型实现平滑属性过渡的方法，通过逐帧调整保持了运动动态。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|KSDiff: Keyframe-Augmented Speech-Aware Dual-Path Diffusion for Facial Animation|关键帧增强的语音感知双路径扩散算法用于面部动画|Tianle Lyu, Junchuan Zhao, Ye Wang|<http://arxiv.org/pdf/2509.20128v1>|提出了一种结合语音解耦与关键帧识别的扩散模型，显著提升了面部动画的同步精度和自然度。|
|🆕 发布|Generative Adversarial Networks Applied for Privacy Preservation in Biometric-Based Authentication and Identification|基于生物特征认证与识别中隐私保护的生成对抗网络应用|Lubos Mjachky, Ivan Homoliak|<http://arxiv.org/pdf/2509.20024v1>|提出利用生成对抗网络将人脸图像转换至视觉私密域，以保护生物识别认证系统中的用户隐私。|
|🆕 发布|Generalized Shortest Path-based Superpixels for 3D Spherical Image Segmentation|基于广义最短路径的超级像素用于三维球面图像分割|Rémi Giraud, Rodrigo Borba Pinheiro, Yannick Berthoumieu|<http://arxiv.org/pdf/2509.19895v1>|提出了一种针对360度球形图像的SphSPS方法，通过考虑图像的几何特性来提高分割准确性和形状规则性...|
|🆕 发布|CapStARE: Capsule-based Spatiotemporal Architecture for Robust and Efficient Gaze Estimation|CapStARE：基于胶囊网络的时空架构用于稳健和高效的视线估计|Miren Samaniego, Igor Rodriguez, Elena Lazkano|<http://arxiv.org/pdf/2509.19936v1>|[代码](https://github.com/toukapy/capsStare); 提出了一种基于胶囊网络的时空架构CapStARE，实现了高效准确的眼动估计，适用于实时交互系统。|
|📝 更新|Lagrangian Motion Fields for Long-term Motion Generation|拉格朗日运动场用于长期运动生成|Yifei Yang, Zikai Huang, Chenshu Xu, Shengfeng He|<http://arxiv.org/pdf/2409.01522v2>|[代码](https://plyfager.github.io/LaMoG.); 提出Lagrangian Motion Fields方法，通过粒子模拟实现高效长时运动生成，提升生成...|
|🆕 发布|StrCGAN: A Generative Framework for Stellar Image Restoration|恒星图像复原的生成式框架：StrCGAN|Shantanusinh Parmar|<http://arxiv.org/pdf/2509.19805v1>|引入StrCGAN模型，通过3D卷积和光谱融合增强低分辨率天文图像，保持星体形态与物理一致性。|
|📝 更新|ChartQA-X: Generating Explanations for Visual Chart Reasoning|图表问答-X：为视觉图表推理生成解释|Shamanthak Hegde, Pooyan Fazli, Hasti Seifi|<http://arxiv.org/pdf/2504.13275v3>|提出了一种生成详细解释的ChartQA-X模型，显著提升了图表问题回答的准确性和解释质量。|
|📝 更新|Redemption Score: A Multi-Modal Evaluation Framework for Image Captioning via Distributional, Perceptual, and Linguistic Signal Triangulation|救赎分数：通过分布性、感知性和语言信号三角测量的图像字幕多模态评估框架|Ashim Dahal, Ankit Ghimire, Saydul Akbar Murad, Nick Rahimi|<http://arxiv.org/pdf/2505.16180v2>|提出了一种多模态评估框架Redemption Score，通过分布、感知和语言信号三角测量，全面评估...|
|📝 更新|X-Part: high fidelity and structure coherent shape decomposition|X-Part：高保真度和结构一致性的形状分解|Xinhao Yan, Jiachen Xu, Yang Li, Changfeng Ma, Yunhan Yang, Chunshi Wang, Zibo Zhao, Zeqiang Lai .etc.|<http://arxiv.org/pdf/2509.08643v2>|提出了一种可控生成模型X-Part，实现了高保真度且结构一致的3D形状分解。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VSF: Simple, Efficient, and Effective Negative Guidance in Few-Step Image Generation Models By Value Sign Flip|VSF：基于值符号翻转的简单、高效、有效的少步图像生成模型负向引导|Wenqi Guo, Shan Du|<http://arxiv.org/pdf/2508.10931v4>|[代码](https://github.com/weathon/VSF); 引入了Value Sign Flip (VSF)方法，通过动态翻转负提示的注意力值，有效提升少量步骤...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On|高效的无编码器姿态调节与虚拟试穿中的姿态控制|Qi Li, Shuwen Qiu, Julien Han, Xingzi Xu, Mehmet Saygin Seyfioglu, Kee Kiat Koo, Karim Bouyarmane|<http://arxiv.org/pdf/2509.20343v1>|提出了一种无需额外参数的编码器自由姿态调节方法，有效提升了虚拟试衣的准确性和灵活性。|
|🆕 发布|VIMD: Monocular Visual-Inertial Motion and Depth Estimation|单目视觉-惯性运动与深度估计：VIMD方法|Saimouli Katragadda, Guoquan Huang|<http://arxiv.org/pdf/2509.19713v1>|提出了一种利用多视角信息迭代优化像素尺度估计的视觉-惯性运动与深度估计框架，实现了高精度和鲁棒性。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Queryable 3D Scene Representation: A Multi-Modal Framework for Semantic Reasoning and Robotic Task Planning|可查询的3D场景表示：用于语义推理和机器人任务规划的多模态框架|Xun Li, Rodrigo Santa Cruz, Mingze Xi, Hu Zhang, Madhawa Perera, Ziwei Wang, Ahalya Ravendran, Brandon J. Matthews .etc.|<http://arxiv.org/pdf/2509.20077v1>|分类|
|🆕 发布|PolGS: Polarimetric Gaussian Splatting for Fast Reflective Surface Reconstruction|极化高斯散点法：用于快速反射表面重建|Yufei Han, Bowen Tie, Heng Guo, Youwei Lyu, Si Li, Boxin Shi, Yunpeng Jia, Zhanyu Ma|<http://arxiv.org/pdf/2509.19726v1>|提出了一种结合偏振约束的快速反射表面重建方法PolGS，有效提升了复杂反射率表面的重建质量。|
|📝 更新|Online Language Splatting|在线语言喷溅|Saimouli Katragadda, Cho-Ying Wu, Yuliang Guo, Xinyu Huang, Guoquan Huang, Liu Ren|<http://arxiv.org/pdf/2503.09447v2>|提出在线语言映射方法，实现实时三维场景与自然语言的无缝融合，大幅提升效率和适应能力。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Positional Prompt Tuning for Efficient 3D Representation Learning|位置提示调优用于高效的三维表示学习|Shaochen Zhang, Zekun Qi, Runpei Dong, Xiuxiu Bai, Xing Wei|<http://arxiv.org/pdf/2408.11567v2>|[代码](https://github.com/zsc000722/PPT.); 提出了一种高效的3D表示学习微调方法PPT，通过位置编码和参数高效微调，实现了点云分析的优异性能。|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Ensuring Reliable Participation in Subjective Video Quality Tests Across Platforms|确保跨平台主观视频质量测试的可靠参与|Babak Naderi, Ross Cutler|<http://arxiv.org/pdf/2509.20001v1>|提出方法检测远程桌面作弊行为，提升主观视频质量评估的可靠性。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|COLT: Enhancing Video Large Language Models with Continual Tool Usage|COLT：通过持续工具使用增强视频大型语言模型|Yuyang Liu, Xinyuan Shi, Xiaondan Liang|<http://arxiv.org/pdf/2509.18754v2>|提出了一种持续学习工具使用的方法COLT，使视频大型语言模型能动态适应不断变化的工具数据流。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Efficient Cell Painting Image Representation Learning via Cross-Well Aligned Masked Siamese Network|通过跨孔对齐遮蔽的相似性网络进行高效的细胞绘画图像表征学习|Pin-Jui Huang, Yu-Hsuan Liao, SooHeon Kim, NoSeong Park, JongBae Park, DongMyung Shin|<http://arxiv.org/pdf/2509.19896v1>|提出了一种高效细胞图像表征学习框架CWA-MSN，通过跨孔对齐增强语义一致性，实现数据与参数效率的提...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Deciphering Functions of Neurons in Vision-Language Models|解读视觉语言模型中神经元的功能|Jiaqi Xu, Cuiling Lan, Yan Lu|<http://arxiv.org/pdf/2502.18485v4>|揭示了视觉语言模型中不同类型神经元的功能，并构建了一个自动化解释神经元工作的框架。|
|🆕 发布|Predictive Coding-based Deep Neural Network Fine-tuning for Computationally Efficient Domain Adaptation|基于预测编码的深度神经网络微调方法用于计算高效的域自适应|Matteo Cardoni, Sam Leroux|<http://arxiv.org/pdf/2509.20269v1>|提出了一种结合反向传播和预测编码的混合训练方法，实现了计算高效的在设备域自适应。|
|📝 更新|EndoBench: A Comprehensive Evaluation of Multi-Modal Large Language Models for Endoscopy Analysis|内镜分析中多模态大型语言模型的全面评估：EndoBench|Shengyuan Liu, Boyun Zheng, Wenting Chen, Zhihao Peng, Zhenfei Yin, Jing Shao, Jiancong Hu, Yixuan Yuan|<http://arxiv.org/pdf/2505.23601v2>|提出EndoBench基准，全面评估多模态大型语言模型在胃镜分析中的多维度能力。|
|📝 更新|Robust superpixels using color and contour features along linear path|利用颜色和轮廓特征沿线性路径的鲁棒超像素|Rémi Giraud, Vinh-Thong Ta, Nicolas Papadakis|<http://arxiv.org/pdf/1903.07193v2>|提出了一种结合颜色和边缘特征的线性路径超像素分解方法，提高了分割准确性和鲁棒性。|
|🆕 发布|Anatomically Constrained Transformers for Cardiac Amyloidosis Classification|用于心脏淀粉样变性分类的解剖约束变换器|Alexander Thorley, Agis Chartsias, Jordan Strom, Roberto Lang, Jeremy Slivnick, Jamie O'Driscoll, Rajan Sharma, Dipak Kotecha .etc.|<http://arxiv.org/pdf/2509.19691v1>|提出了一种将Transformer模型约束在心肌区域的方法，提高了心脏淀粉样变性分类的准确性。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Design Insights and Comparative Evaluation of a Hardware-Based Cooperative Perception Architecture for Lane Change Prediction|设计洞察与基于硬件的协同感知架构在车道变换预测中的比较评估|Mohamed Manzour, Catherine M. Elias, Omar M. Shehata, Rubén Izquierdo, Miguel Ángel Sotelo|<http://arxiv.org/pdf/2509.20218v1>|探索实际硬件部署中的合作车道变换预测，揭示了实施和测试中的挑战与洞见。|
|📝 更新|PerceptronCARE: A Deep Learning-Based Intelligent Teleophthalmology Application for Diabetic Retinopathy Diagnosis|感知机CARE：一种基于深度学习的智能远程眼科诊断应用——糖尿病视网膜病变诊断|Akwasi Asare, Isaac Baffour Senkyire, Emmanuel Freeman, Mary Sagoe, Simon Hilary Ayinedenaba Aluze-Ele, Kelvin Kwao|<http://arxiv.org/pdf/2509.18160v2>|提出了一种基于深度学习的远程眼科诊断应用PerceptronCARE，实现糖尿病视网膜病变自动检测，...|
|📝 更新|An Optimized PatchMatch for Multi-scale and Multi-feature Label Fusion|多尺度多特征标签融合的优化PatchMatch算法|Rémi Giraud, Vinh-Thong Ta, Nicolas Papadakis, José V. Manjón, D. Louis Collins, Pierrick Coupé, Alzheimer's Disease Neuroimaging Initiative|<http://arxiv.org/pdf/1903.07165v2>|提出了一种优化的PatchMatch方法，实现了多尺度多特征标签融合，显著提升了MRI图像分割准确性...|
|📝 更新|LEMUR Neural Network Dataset: Towards Seamless AutoML|LEMUR神经网络数据集：迈向无缝自动机器学习|Arash Torabi Goodarzi, Roman Kochnev, Waleed Khalid, Hojjat Torabi Goudarzi, Furui Qin, Tolgay Atinc Uzun, Yashkumar Sanjaybhai Dhameliya, Yash Kanubhai Kathiriya .etc.|<http://arxiv.org/pdf/2504.10552v4>|[代码](https://github.com/ABrain-One/nn-dataset); 介绍了LEMUR开源数据集，统一存储神经网络模型，加速自动化机器学习研究。|
|📝 更新|Revisiting Residual Connections: Orthogonal Updates for Stable and Efficient Deep Networks|重新审视残差连接：正交更新以实现稳定和高效深度网络|Giyeong Oh, Woohyun Cho, Siyeol Kim, Suhwan Choi, Younjae Yu|<http://arxiv.org/pdf/2505.11881v2>|提出正交残差更新方法，增强深度网络学习新特征的能力，提升泛化准确性和训练稳定性。|
|📝 更新|Robust Training of Neural Networks at Arbitrary Precision and Sparsity|神经网络的任意精度与稀疏性稳健训练|Chengxi Ye, Grace Chu, Yanfeng Liu, Yichi Zhang, Lukasz Lew, Li Zhang, Mark Sandler, Andrew Howard|<http://arxiv.org/pdf/2409.09245v2>|提出了一种去噪去量化变换方法，使神经网络在任意精度和稀疏度下稳定训练，实现了全二值和稀疏网络的训练。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Smaller is Better: Enhancing Transparency in Vehicle AI Systems via Pruning|更小即是更好：通过剪枝增强车辆AI系统的透明度|Sanish Suwal, Shaurya Garg, Dipkamal Bhusal, Michael Clifford, Nidhi Rastogi|<http://arxiv.org/pdf/2509.20148v1>|通过模型剪枝提升车辆AI系统的解释性和决策可靠性。|
|🆕 发布|EchoBench: Benchmarking Sycophancy in Medical Large Vision-Language Models|回声基准：评估医学大规模视觉-语言模型中的谄媚行为|Botai Yuan, Yutian Zhou, Yingjie Wang, Fushuo Huo, Yongcheng Jing, Li Shen, Ying Wei, Zhiqi Shen .etc.|<http://arxiv.org/pdf/2509.20146v1>|提出EchoBench基准，系统评估医疗大视觉语言模型对错误信息的盲目跟随倾向，指导构建更可靠模型。|
|📝 更新|Intervening in Black Box: Concept Bottleneck Model for Enhancing Human Neural Network Mutual Understanding|干预黑箱：概念瓶颈模型以提高人类神经网络相互理解|Nuoye Xiong, Anqi Dong, Ning Wang, Cong Hua, Guangming Zhu, Lin Mei, Peiyi Shen, Liang Zhang|<http://arxiv.org/pdf/2506.22803v3>|[代码](https://github.com/XiGuaBo/CBM-HNMU.); 提出了一种增强人类与神经网络相互理解的模型CBM-HNMU，通过自动识别和优化概念，提高了模型的解释...|
|📝 更新|Replay-Free Continual Low-Rank Adaptation with Dynamic Memory|无需重放的连续低秩适应与动态内存管理|Huancheng Chen, Jingtao Li, Weiming Zhuang, Chen Chen, Lingjuan Lyu|<http://arxiv.org/pdf/2411.00623v3>|提出了一种结合动态记忆机制的Dual LoRA方法，有效解决了持续学习中的灾难性遗忘问题，提升了模型...|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Logics-Parsing Technical Report|逻辑解析技术报告|Xiangyang Chen, Shuzhao Li, Xiuwen Zhu, Yongfan Chen, Fan Yang, Cheng Fang, Lin Qu, Xiaoxiao Xu .etc.|<http://arxiv.org/pdf/2509.19760v1>|[代码](https://github.com/alibaba/Logics-Parsing); 提出Logics-Parsing模型，结合强化学习优化文档布局分析和阅读顺序推断，实现复杂文档解析的...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PU-Gaussian: Point Cloud Upsampling using 3D Gaussian Representation|PU-高斯：基于三维高斯表示的点云上采样|Mahmoud Khater, Mona Strauss, Philipp von Olshausen, Alexander Reiterer|<http://arxiv.org/pdf/2509.20207v1>|[代码](https://github.com/mvg-inatech/PU-Gaussian.git.); 提出了一种基于各向异性3D高斯分布的点云上采样方法，有效提升了点云的密度和几何结构保真度。|
|📝 更新|Incentivizing Reasoning for Advanced Instruction-Following of Large Language Models|激励推理以提高大型语言模型的高级指令遵循能力|Yulei Qin, Gang Li, Zongyi Li, Zihan Xu, Yuchen Shi, Zhekai Lin, Xiao Cui, Ke Li .etc.|<http://arxiv.org/pdf/2506.01413v7>|[代码](https://github.com/yuleiqin/RAIF.); 提出了一种激励推理的方法RAIF，通过强化学习提升大型语言模型处理复杂指令的能力。|
|📝 更新|Minimal Semantic Sufficiency Meets Unsupervised Domain Generalization|最小语义充分性遇见无监督领域泛化|Tan Pan, Kaiyu Guo, Dongli Xu, Zhaorui Tan, Chen Jiang, Deshu Chen, Xin Guo, Brian C. Lovell .etc.|<http://arxiv.org/pdf/2509.15791v2>|提出了一种无需类别或领域标签的语义充分且最小的无监督领域泛化方法，实现了领域泛化的新突破。|
|🆕 发布|ExpFace: Exponential Angular Margin Loss for Deep Face Recognition|ExpFace：指数角边界损失用于深度人脸识别|Jinhui Zheng, Xueyuan Gong|<http://arxiv.org/pdf/2509.19753v1>|[代码](https://github.com/dfr-code/ExpFace.); 提出了一种新的损失函数ExpFace，通过在中心区域加大惩罚、在边缘区域减小惩罚，有效抑制噪声样本并...|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Human-Interpretable Uncertainty Explanations for Point Cloud Registration|点云配准中的人类可解释不确定性解释|Johannes A. Gaus, Loris Schneider, Yitian Shi, Jongseok Lee, Rania Rayyes, Rudolph Triebel|<http://arxiv.org/pdf/2509.18786v2>|提出了一种新的点云配准方法 GP-CA，量化并解释配准不确定性，有效应对传感器噪声和姿态估计误差。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Adversarial Robustness of Discriminative Self-Supervised Learning in Vision|《视觉中判别性自监督学习的对抗鲁棒性》|Ömer Veysel Çağatan, Ömer Faruk Tal, M. Emre Gürsoy|<http://arxiv.org/pdf/2503.06361v2>|评估并揭示了自监督学习模型在对抗攻击下的鲁棒性优势及其在不同任务和条件下的变化。|
|🆕 发布|FreezeVLA: Action-Freezing Attacks against Vision-Language-Action Models|“FreezeVLA：针对视觉-语言-动作模型的动作冻结攻击”|Xin Wang, Jie Li, Zejia Weng, Yixu Wang, Yifeng Gao, Tianyu Pang, Chao Du, Yan Teng .etc.|<http://arxiv.org/pdf/2509.19870v1>|提出了一种攻击框架FreezeVLA，使视觉语言动作模型在遭遇特定图像时“冻结”，忽略后续指令。|


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Improving Generalizability and Undetectability for Targeted Adversarial Attacks on Multimodal Pre-trained Models|提高针对多模态预训练模型的目标对抗攻击的泛化性和不可检测性|Zhifang Zhang, Jiahan Zhang, Shengjie Zhou, Qi Wei, Shuo He, Feng Liu, Lei Feng|<http://arxiv.org/pdf/2509.19994v1>|提出了一种Proxy Targeted Attack方法，增强了针对多模态预训练模型的目标攻击在泛化...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PerFace: Metric Learning in Perceptual Facial Similarity for Enhanced Face Anonymization|《PerFace：基于感知面部相似度的度量学习以增强面部匿名化》|Haruka Kumagai, Leslie Wöhler, Satoshi Ikehata, Kiyoharu Aizawa|<http://arxiv.org/pdf/2509.20281v1>|提出了基于人类感知的面对面部相似度度量表，通过度量和学习预测相似度，提升了面部匿名化技术的自然度和匿...|
|🆕 发布|U-Mamba2-SSL for Semi-Supervised Tooth and Pulp Segmentation in CBCT|U-Mamba2-SSL用于CBCT半监督牙齿和牙髓分割|Zhi Qin Tan, Xiatian Zhu, Owen Addison, Yunpeng Li|<http://arxiv.org/pdf/2509.20154v1>|[代码](https://github.com/zhiqin1998/UMamba2.); 提出了一种半监督学习框架U-Mamba2-SSL，利用未标记数据实现CBCT中牙齿和牙髓的精确分割。|
|🆕 发布|C$^2$MIL: Synchronizing Semantic and Topological Causalities in Multiple Instance Learning for Robust and Interpretable Survival Analysis|C$^2$MIL：在多实例学习中同步语义和拓扑因果关系以实现鲁棒和可解释的生存分析|Min Cen, Zhenfeng Zhuang, Yuzhe Zhang, Min Zeng, Baptiste Magnier, Lequan Yu, Hong Zhang, Liansheng Wang|<http://arxiv.org/pdf/2509.20152v1>|[代码](https://github.com/mimic0127/C2MIL.); 提出了一种双因果图的多实例学习方法C$^2$MIL，有效平衡了生存分析中的语义和拓扑因果性，增强了模...|
|📝 更新|To Trust Or Not To Trust Your Vision-Language Model's Prediction|“信任或质疑您的视觉-语言模型的预测”|Hao Dong, Moru Liu, Jian Liang, Eleni Chatzi, Olga Fink|<http://arxiv.org/pdf/2505.23745v2>|[代码](https://github.com/EPFL-IMOS/TrustVLM.); 提出 TrustVLM 框架，通过评估视觉语言模型预测的可信度，有效提高了错误分类检测性能。|
|📝 更新|SMLNet: A SPD Manifold Learning Network for Infrared and Visible Image Fusion|SMLNet：一种用于红外与可见光图像融合的SPD流形学习网络|Huan Kang, Hui Li, Tianyang Xu, Xiao-Jun Wu, Rui Wang, Chunyang Cheng, Josef Kittler|<http://arxiv.org/pdf/2411.10679v3>|提出了一种基于对称正定矩阵流形的图像融合网络，通过利用图像内在统计相关性，提升了多模态图像融合性能。|
|📝 更新|A Quad-Step Approach to Uncertainty-Aware Deep Learning for Skin Cancer Classification|四步法实现皮肤癌分类中不确定性的深度学习感知|Hamzeh Asgharnezhad, Pegah Tabarisaadi, Abbas Khosravi, Roohallah Alizadehsani, U. Rajendra Acharya|<http://arxiv.org/pdf/2506.10302v2>|提出了一种四步法，结合特征提取和不确定性量化，提升了皮肤癌分类的准确性和可靠性。|
|📝 更新|Mixture of Noise for Pre-Trained Model-Based Class-Incremental Learning|基于预训练模型的噪声混合类增量学习|Kai Jiang, Zhengyan Shi, Dell Zhang, Hongyuan Zhang, Xuelong Li|<http://arxiv.org/pdf/2509.16738v3>|[代码](https://github.com/ASCIIJK/MiN-NeurIPS2025.); 提出利用信息理论指导学习有益噪声，通过混合噪声策略提升预训练模型在持续学习中的泛化能力。|
|🆕 发布|Adaptive Model Ensemble for Continual Learning|自适应模型集成在持续学习中的应用|Yuchuan Mao, Zhi Gao, Xiaomeng Fan, Yuwei Wu, Yunde Jia, Chenchen Jing|<http://arxiv.org/pdf/2509.19819v1>|提出自适应模型融合方法，通过元学习生成混合系数解决连续学习中的知识冲突问题。|
|📝 更新|Probabilistic Online Event Downsampling|概率在线事件降采样|Andreu Girbau-Xalabarder, Jun Nagata, Shinichi Sumiyoshi, Ricard Marsal, Shin'ichi Satoh|<http://arxiv.org/pdf/2506.02547v2>|提出了一种自适应概率框架POLED，通过在线估计事件重要性，实现了高效的事件降采样，保持了性能同时减...|
|🆕 发布|Learning to Stop: Reinforcement Learning for Efficient Patient-Level Echocardiographic Classification|学习停止：用于高效患者级别超声心动图分类的强化学习|Woo-Jin Cho Kim, Jorge Oliveira, Arian Beqiri, Alex Thorley, Jordan Strom, Jamie O'Driscoll, Rajan Sharma, Jeremy Slivnick .etc.|<http://arxiv.org/pdf/2509.19694v1>|利用强化学习选择最佳视频子集进行心脏疾病分类，提高准确性的同时降低计算成本。|
|🆕 发布|MoTiC: Momentum Tightness and Contrast for Few-Shot Class-Incremental Learning|MoTiC: 动量紧致性与对比性用于少量样本的新类增量学习|Zeyu He, Shuai Huang, Yuwu Lu, Ming Zhao|<http://arxiv.org/pdf/2509.19664v1>|提出了一种结合动量自监督和大规模对比学习的框架，有效减少了少量样本学习中的估计偏差，提升了持续学习性...|
|🆕 发布|C${}^2$Prompt: Class-aware Client Knowledge Interaction for Federated Continual Learning|类感知客户端知识交互的联邦持续学习C${}^2$Prompt|Kunlun Xu, Yibo Feng, Jiangmeng Li, Yongsheng Qi, Jiahuan Zhou|<http://arxiv.org/pdf/2509.19674v1>|[代码](https://github.com/zhoujiahuan1991/NeurIPS2025-C2Prompt); 提出了一种增强联邦持续学习中类间知识一致性的C${}^2$Prompt方法，有效缓解了时间和空间遗忘...|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SoFar: Language-Grounded Orientation Bridges Spatial Reasoning and Object Manipulation|《SoFar：基于语言的定向桥梁连接空间推理与物体操作》|Zekun Qi, Wenyao Zhang, Yufei Ding, Runpei Dong, Xinqiang Yu, Jingwen Li, Lingyun Xu, Baoyu Li .etc.|<http://arxiv.org/pdf/2502.13143v2>|提出语义方向概念，通过自然语言描述物体方向，实现6自由度空间推理和机器人操作。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GraphEQA: Using 3D Semantic Scene Graphs for Real-time Embodied Question Answering|图解问答：使用三维语义场景图进行实时具身问答|Saumya Saxena, Blake Buchanan, Chris Paxton, Peiqi Liu, Bingqing Chen, Narunas Vaskevicius, Luigi Palmieri, Jonathan Francis .etc.|<http://arxiv.org/pdf/2412.14480v2>|提出GraphEQA方法，利用实时3D语义场景图和图像多模态记忆，提升机器人实时情境问答的成功率和效...|
|🆕 发布|PersONAL: Towards a Comprehensive Benchmark for Personalized Embodied Agents|《PersONAL：面向个性化具身智能体的全面基准》|Filippo Ziliotto, Jelin Raphael Akkara, Alessandro Daniele, Lamberto Ballan, Luciano Serafini, Tommaso Campari|<http://arxiv.org/pdf/2509.19843v1>|提出了PersONAL基准，用于评估Embodied AI在理解个人偏好和行为方面的能力，以适应真实...|


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SEM: Enhancing Spatial Understanding for Robust Robot Manipulation|SEM：增强空间理解以实现鲁棒的机器人操作|Xuewu Lin, Tianwei Lin, Lichao Huang, Hongyu Xie, Yiwei Jin, Keyu Li, Zhizhong Su|<http://arxiv.org/pdf/2505.16196v3>|提出SEM模型，通过增强空间理解能力，显著提升机器人操作的稳健性和泛化能力。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|To Fold or Not to Fold: Graph Regularized Tensor Train for Visual Data Completion|“折叠还是不折叠：图正则化张量训练用于视觉数据补全”|Le Xu, Lei Cheng, Ngai Wong, Yik-Chung Wu|<http://arxiv.org/pdf/2306.11123v2>|提出不折叠数据张量并采用图正则化保持视觉数据局部信息，通过分解问题和稀疏概率模型优化计算复杂度。|
|🆕 发布|A Simple Data Augmentation Strategy for Text-in-Image Scientific VQA|图像中文本问答的科学简单数据增强策略|Belal Shoer, Yova Kementchedjhieva|<http://arxiv.org/pdf/2509.20119v1>|提出了一种合成“图像中文字”格式数据集的方法，有效提升了多语言视觉问答模型的性能和跨语言迁移性。|
|📝 更新|FastTracker: Real-Time and Accurate Visual Tracking|快速跟踪器：实时与精确的视觉跟踪|Hamidreza Hashempoor, Yu Dong Hwang|<http://arxiv.org/pdf/2508.14370v4>|[代码](https://github.com/Hamidreza-Hashempoor/FastTracker); 提出了一种通用多目标跟踪框架，通过考虑遮挡和道路结构，实现了车辆等不同对象在复杂场景中的实时准确跟踪...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HiPerformer: A High-Performance Global-Local Segmentation Model with Modular Hierarchical Fusion Strategy|"HiPerformer：一种具有模块化层次融合策略的高性能全局-局部分割模型"|Dayu Tan, Zhenpeng Xu, Yansen Su, Xin Peng, Chunhou Zheng, Weimin Zhong|<http://arxiv.org/pdf/2509.20280v1>|[代码](https://github.com/xzphappy/HiPerformer.); 提出了一种模块化层级融合策略的全球-局部医学图像分割模型，有效整合局部细节和全局上下文信息，提高了分...|
|🆕 发布|A co-evolving agentic AI system for medical imaging analysis|一种用于医学成像分析的合作进化智能代理系统|Songhao Li, Jonathan Xu, Tiancheng Bao, Yuxuan Liu, Yuchen Liu, Yihang Liu, Lilin Wang, Wenhui Lei .etc.|<http://arxiv.org/pdf/2509.20279v1>|提出TissueLab系统，通过互动专家反馈和持续学习，提升医学影像分析的准确性和效率。|
|📝 更新|Imaging Biomarkers for Neurodegenerative Diseases from Detailed Segmentation of Medial Temporal Lobe Subregions on in vivo Brain MRI Using Upsampling Strategy Guided by High-resolution ex vivo MRI|在活体脑磁共振成像中利用高分辨率离体MRI指导的升采样策略对内侧颞叶亚区域进行详细分割的神经退行性疾病影像生物标志物|Yue Li, Pulkit Khandelwal, Long Xie, Laura E. M. Wisse, Amanda E. Denning, Christopher A. Brown, Emily McGrew, Sydney A. Lim .etc.|<http://arxiv.org/pdf/2504.18442v2>|提出了一种多模态MTL亚区分割算法，通过将T1w和T2w MRI数据提升至近等体素空间，提高了神经退...|
|🆕 发布|ImageNet-trained CNNs are not biased towards texture: Revisiting feature reliance through controlled suppression|《ImageNet训练的卷积神经网络对纹理并无偏见：通过控制抑制重新审视特征依赖》|Tom Burgert, Oliver Stoll, Paolo Rota, Begüm Demir|<http://arxiv.org/pdf/2509.20234v1>|[代码](https://github.com/tomburgert/feature-reliance.); 挑战了CNN对纹理的内在偏见观点，提出无领域特定框架量化特征依赖，发现CNN主要依赖形状特征。|
|🆕 发布|An Anisotropic Cross-View Texture Transfer with Multi-Reference Non-Local Attention for CT Slice Interpolation|各向异性跨视图纹理传递与多参考非局部注意力机制的CT切片插值|Kwang-Hyun Uhm, Hyunjun Cho, Sung-Hoo Hong, Seung-Won Jung|<http://arxiv.org/pdf/2509.20242v1>|[代码](https://github.com/khuhm/ACVTT.); 提出了一种利用3D CT体积各向异性特点的跨视图纹理传递方法，通过多参考非局部注意力模块显著提升CT...|
|📝 更新|SpaRC: Sparse Radar-Camera Fusion for 3D Object Detection|稀疏雷达-相机融合的3D目标检测方法SpaRC|Philipp Wolters, Johannes Gilg, Torben Teepe, Fabian Herzog, Felix Fent, Gerhard Rigoll|<http://arxiv.org/pdf/2411.19860v2>|[代码](https://github.com/phi-wol/sparc.); 提出SpaRC方法，通过融合雷达和相机点特征，提高了3D物体检测的准确性和效率。|
|🆕 发布|Anomaly Detection by Clustering DINO Embeddings using a Dirichlet Process Mixture|使用狄利克雷过程混合模型对DINO嵌入进行聚类进行异常检测|Nico Schulthess, Ender Konukoglu|<http://arxiv.org/pdf/2509.19997v1>|[代码](https://github.com/NicoSchulthess/anomalydino-dpmm.); 利用Dirichlet过程混合模型对DINOv2嵌入进行聚类，实现高效医疗影像异常检测。|
|📝 更新|Investigating Traffic Accident Detection Using Multimodal Large Language Models|探究基于多模态大型语言模型的交通事故检测|Ilhan Skender, Kailin Tong, Selim Solmaz, Daniel Watzenig|<http://arxiv.org/pdf/2509.19096v2>|探究了大型多模态语言模型在无需大量标注数据的情况下，通过基础设施摄像头图像进行交通事故检测与描述的能...|
|🆕 发布|BiTAA: A Bi-Task Adversarial Attack for Object Detection and Depth Estimation via 3D Gaussian Splatting|BiTAA：一种基于三维高斯散点投射的对象检测与深度估计双向任务对抗攻击方法|Yixun Zhang, Feng Zhou, Jianqin Yin|<http://arxiv.org/pdf/2509.19793v1>|提出了一种双向任务对抗攻击方法BiTAA，通过3D高斯散点技术同时影响目标检测和单目深度估计。|
|🆕 发布|Sex-based Bias Inherent in the Dice Similarity Coefficient: A Model Independent Analysis for Multiple Anatomical Structures|基于Dice相似性系数的性别偏见：针对多种解剖结构的模型独立分析|Hartmut Häntze, Myrthe Buser, Alessa Hering, Lisa C. Adams, Keno K. Bressem|<http://arxiv.org/pdf/2509.19778v1>|揭示了Dice相似性系数中的性别偏见，指出其对小器官结构的评价不公，影响医学图像分析的准确性和公平性...|
|🆕 发布|nnFilterMatch: A Unified Semi-Supervised Learning Framework with Uncertainty-Aware Pseudo-Label Filtering for Efficient Medical Segmentation|nnFilterMatch：一种统一的不确定性感知伪标签过滤半监督学习框架，用于高效的医学分割|Yi Yang|<http://arxiv.org/pdf/2509.19746v1>|[代码](https://github.com/Ordi117/nnFilterMatch.git.); 提出了一种自适应半监督学习框架nnFilterMatch，通过伪标签过滤和不确定性感知，有效降低医疗...|
|📝 更新|NERO: Explainable Out-of-Distribution Detection with Neuron-level Relevance|NERO：基于神经元级别相关性的可解释性异常分布检测|Anju Chhetri, Jari Korhonen, Prashnna Gyawali, Binod Bhattarai|<http://arxiv.org/pdf/2506.15404v2>|提出了一种基于神经元级别相关性的新型OOD检测方法NERO，提高了医学成像中异常样本的识别准确性。|
|🆕 发布|Frequency-domain Multi-modal Fusion for Language-guided Medical Image Segmentation|频域多模态融合指导下的语言引导医学图像分割|Bo Yu, Jianhua Yang, Zetao Du, Yan Huang, Chenglong Li, Liang Wang|<http://arxiv.org/pdf/2509.19719v1>|提出了一种频率域多模态交互模型，通过语言指导有效融合视觉特征，显著提升了医学影像分割的准确性。|
|🆕 发布|Towards Robust In-Context Learning for Medical Image Segmentation via Data Synthesis|面向医学图像分割的稳健式上下文学习：通过数据合成实现|Jiesi Hu, Yanwu Yang, Zhiyu Ye, Chenfei Ye, Hanyang Peng, Jianfeng Cao, Ting Ma|<http://arxiv.org/pdf/2509.19711v1>|[代码](https://github.com/jiesihu/Neuroverse3D.); 提出SynthICL框架，通过域随机化合成多样化且适合医学数据的数据集，有效缓解了医学图像分割中的数...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Universal Camouflage Attack on Vision-Language Models for Autonomous Driving|自动驾驶视觉语言模型上的通用迷彩攻击|Dehong Kong, Sifan Yu, Siyuan Liang, Jiawei Liang, Jianhou Gan, Aishan Liu, Wenqi Ren|<http://arxiv.org/pdf/2509.20196v1>|提出了一种通用的伪装攻击框架，通过特征空间操作生成具有强泛化能力的伪装纹理，有效对抗自动驾驶视觉语言...|
|🆕 发布|OmniScene: Attention-Augmented Multimodal 4D Scene Understanding for Autonomous Driving|全方位场景：面向自动驾驶的注意力增强多模态4D场景理解|Pei Liu, Hongliang Lu, Haichao Liu, Haipeng Liu, Xin Liu, Ruoyu Yao, Shengbo Eben Li, Jun Ma|<http://arxiv.org/pdf/2509.19973v1>|提出了OmniScene框架，通过融合多模态感知和注意力机制，实现了类人4D场景理解，显著提升了自动...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CLOSP: A Unified Semantic Space for SAR, MSI, and Text in Remote Sensing|CLOSP：一种合成孔径雷达、多光谱影像与文本在遥感中的统一语义空间|Daniele Rege Cambrin, Lorenzo Vaiani, Giuseppe Gallipoli, Luca Cagliero, Paolo Garza|<http://arxiv.org/pdf/2507.10403v2>|提出了一种统一语义空间框架CLOSP，利用文本信息桥接光学和SAR图像，显著提升了遥感图像检索性能。|
|🆕 发布|Deep Learning for Clouds and Cloud Shadow Segmentation in Methane Satellite and Airborne Imaging Spectroscopy|深度学习在甲烷卫星和机载成像光谱学中用于云和云影分割|Manuel Perez-Carrasco, Maya Nasr, Sebastien Roche, Chris Chan Miller, Zhan Zhang, Core Francisco Park, Eleanor Walker, Cecilia Garraffo .etc.|<http://arxiv.org/pdf/2509.19665v1>|利用深度学习模型UNet和SCAN显著提升了甲烷遥感影像中云和云影的检测精度与细节捕捉。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RG-Attn: Radian Glue Attention for Multi-modality Multi-agent Cooperative Perception|径向粘合注意力：用于多模态多智能体协同感知的算法|Lantao Li, Kang Yang, Wenqi Zhang, Xiaoxue Wang, Chen Sun|<http://arxiv.org/pdf/2501.16803v3>|[代码](https://github.com/LantaoLi/RG-Attn); 提出了一种跨模态融合模块RG-Attn，通过坐标对齐和统一采样策略，提升了多模态多智能体协同感知的准...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Optical Ocean Recipes: Creating Realistic Datasets to Facilitate Underwater Vision Research|光学海洋配方：创建逼真数据集以促进水下视觉研究|Patricia Schöntag, David Nakath, Judith Fischer, Rüdiger Röttgers, Kevin Köser|<http://arxiv.org/pdf/2509.20171v1>|提出了Optical Ocean Recipes框架，通过在控制条件下创建真实数据集，解决了水下视觉...|


### 可解释视觉智能 (Explainable Visual Intelligence)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Challenges and Trends in Egocentric Vision: A Survey|《自我中心视觉的挑战与趋势：综述》|Xiang Li, Heqian Qiu, Lanxiao Wang, Hanwen Zhang, Chenghao Qi, Linfeng Han, Huiyu Xiong, Hongliang Li|<http://arxiv.org/pdf/2503.15275v4>|系统分析了第一视角视觉理解的研究进展，归类了四大任务领域，并展望了未来发展趋势。|


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OmniSpatial: Towards Comprehensive Spatial Reasoning Benchmark for Vision Language Models|全方位：面向视觉语言模型全面空间推理基准|Mengdi Jia, Zekun Qi, Shaochen Zhang, Wenyao Zhang, Xinqiang Yu, Jiawei He, He Wang, Li Yi|<http://arxiv.org/pdf/2506.03135v2>|提出了OmniSpatial，一个全面的视觉语言模型空间推理基准，涵盖多种空间推理类型，并探索了两种...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bias in the Picture: Benchmarking VLMs with Social-Cue News Images and LLM-as-Judge Assessment|图像中的偏见：使用社会线索新闻图像和大型语言模型作为评判的视觉语言模型基准测试|Aravind Narayanan, Vahid Reza Khazaie, Shaina Raza|<http://arxiv.org/pdf/2509.19659v1>|揭示了大型视觉语言模型在处理新闻图片时可能产生的偏见，并提出了一个包含多样图片和评估方法的公平性评估...|

