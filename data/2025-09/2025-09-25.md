## [UPDATED!] **2025-09-25** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Sentinel-3 foundation model for ocean colour|哨兵-3基础模型在海洋颜色研究中的应用|Geoffrey Dawson, Remy Vandaele, Andrew Taylor, David Moffat, Helen Tamura-Wicks, Sarah Jackson, Rosie Lickorish, Paolo Fraccaro .etc.|<http://arxiv.org/pdf/2509.21273v1>|提出了一种基于大规模未标注数据预训练的Sentinel-3基础模型，有效利用少量高质量标注数据提升海...|
|📝 更新|Retina Vision Transformer (RetinaViT): Introducing Scaled Patches into Vision Transformers|视网膜视觉变换器（RetinaViT）：在视觉变换器中引入缩放斑块|Yuyang Shu, Michael E. Bain|<http://arxiv.org/pdf/2403.13677v2>|提出Retina Vision Transformer模型，模仿人眼视觉处理顺序，先关注低频结构特征...|
|🆕 发布|Vision Transformers: the threat of realistic adversarial patches|《视觉变换器：现实对抗补丁的威胁》|Kasper Cools, Clara Maathuis, Alexander M. van Oers, Claudia S. Hübner, Nikos Deligiannis, Marijke Vandewal, Geert De Cubber|<http://arxiv.org/pdf/2509.21084v1>|揭示了Vision Transformers对现实对抗性补丁的脆弱性，并验证了从CNN转移至ViT的...|
|📝 更新|Hyperspectral Adapter for Semantic Segmentation with Vision Foundation Models|用于视觉基础模型语义分割的超光谱适配器|Juana Valeria Hurtado, Rohit Mohan, Abhinav Valada|<http://arxiv.org/pdf/2509.20107v2>|提出了一种利用预训练视觉基础模型的 hyperspectral 适配器，通过结合光谱转换器和空间先验...|
|🆕 发布|SiNGER: A Clearer Voice Distills Vision Transformers Further|SiNGER：更清晰的语音提炼使视觉变换器更进一步|Geunhyeok Yu, Sunjae Jeong, Yoonyoung Choi, Jaeseung Kim, Hyoseok Hwang|<http://arxiv.org/pdf/2509.20986v1>|提出SiNGER框架，通过抑制高范数伪影同时保留有效信息，提升视觉变换器模型的性能和可解释性。|
|🆕 发布|Unlocking Noise-Resistant Vision: Key Architectural Secrets for Robust Models|解锁抗噪视觉：稳健模型的关键架构秘密|Bum Jun Kim, Makoto Kawano, Yusuke Iwasawa, Yutaka Matsuo|<http://arxiv.org/pdf/2509.20939v1>|揭示了提高计算机视觉模型对高斯噪声鲁棒性的关键架构设计，提出了实用的设计规则。|
|🆕 发布|TasselNetV4: A vision foundation model for cross-scene, cross-scale, and cross-species plant counting|《TasselNetV4：一种适用于跨场景、跨尺度、跨物种植物计数的视觉基础模型》|Xiaonan Hu, Xuebing Li, Jinyu Xu, Abdulkadir Duran Adan, Letian Zhou, Xuhui Zhu, Yanan Li, Wei Guo .etc.|<http://arxiv.org/pdf/2509.20857v1>|提出了一种通用植物计数模型TasselNetV4，实现了跨场景、跨尺度和跨物种的计数能力。|
|🆕 发布|FHRFormer: A Self-supervised Transformer Approach for Fetal Heart Rate Inpainting and Forecasting|FHRFormer：一种用于胎儿心率修复与预测的自监督Transformer方法|Kjersti Engan, Neel Kanwal, Anita Yeconia, Ladislaus Blacy, Yuda Munyaw, Estomih Mduma, Hege Ersdal|<http://arxiv.org/pdf/2509.20852v1>|提出了一种基于自监督Transformer的 fetal heart rate信号重建方法，有效处理...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and Open Resources|MMR1：利用方差感知采样与开放资源增强多模态推理|Sicong Leng, Jing Wang, Jiaxi Li, Hao Zhang, Zhiqiang Hu, Boqiang Zhang, Yuming Jiang, Hang Zhang .etc.|<http://arxiv.org/pdf/2509.21268v1>|[代码](https://github.com/LengSicong/MMR1.); 提出了一种奖励方差感知的数据采样策略，并开放了大量高质量多模态推理数据，有效提升了多模态推理模型的稳...|
|🆕 发布|Decipher-MR: A Vision-Language Foundation Model for 3D MRI Representations|解码-MR：一种用于三维MRI表征的视觉-语言基础模型|Zhijian Yang, Noel DSouza, Istvan Megyeri, Xiaojian Xu, Amin Honarmandi Shandiz, Farzin Haddadpour, Krisztian Koos, Laszlo Rusko .etc.|<http://arxiv.org/pdf/2509.21249v1>|提出了一种大规模3D MRI视觉语言基础模型Decipher-MR，通过自监督学习和报告引导的文本监...|
|🆕 发布|VideoChat-R1.5: Visual Test-Time Scaling to Reinforce Multimodal Reasoning by Iterative Perception|视频聊天-R1.5：通过迭代感知强化多模态推理的可视化测试时缩放|Ziang Yan, Xinhao Li, Yinan He, Zhengrong Yue, Xiangyu Zeng, Yali Wang, Yu Qiao, Limin Wang .etc.|<http://arxiv.org/pdf/2509.21100v1>|引入视觉测试时间缩放技术，通过迭代感知增强多模态大语言模型的推理能力。|
|📝 更新|Vim-F: Visual State Space Model Benefiting from Learning in the Frequency Domain|频率域学习赋能的视觉状态空间模型Vim-F|Juntao Zhang, Shaogeng Liu, Jun Zhou, Kun Bian, You Zhou, Jianning Liu, Pei Zhang, Bingyan Liu|<http://arxiv.org/pdf/2405.18679v3>|[代码](https://github.com/yws-wxs/Vim-F.); 提出Vim-F模型，通过结合频率域信息，增强视觉状态空间模型处理图像的全局感知能力。|
|🆕 发布|Decoding the Surgical Scene: A Scoping Review of Scene Graphs in Surgery|解读手术场景：手术中场景图的范畴综述|Angelo Henriques, Korab Hoxha, Daniel Zapp, Peter C. Issa, Nassir Navab, M. Ali Nasseri|<http://arxiv.org/pdf/2509.20941v1>|系统梳理了手术场景图中场景图的应用与发展，揭示了数据和方法论上的关键差距。|
|📝 更新|HermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and Generation|赫尔墨斯流：无缝填补多模态理解和生成之间的差距|Ling Yang, Xinchen Zhang, Ye Tian, Chenming Shang, Minghao Xu, Wentao Zhang, Bin Cui|<http://arxiv.org/pdf/2502.12148v2>|[代码](https://github.com/Gen-Verse/HermesFlow); 提出HermesFlow框架，有效缩小了多模态大语言模型理解和生成能力之间的差距。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dense Semantic Matching with VGGT Prior|稠密语义匹配结合VGGT先验|Songlin Yang, Tianyi Wei, Yushi Lan, Zeqi Xiao, Anyi Rao, Xingang Pan|<http://arxiv.org/pdf/2509.21263v1>|提出了一种利用VGGT先验的密集语义匹配方法，有效解决了几何歧义和邻域规则问题，提高了匹配准确性和泛...|
|📝 更新|Technical report on label-informed logit redistribution for better domain generalization in low-shot classification with foundation models|低样本分类中基于基础模型的标签指导对数重新分配以实现更好的域泛化技术报告|Behraj Khan, Tahir Syed|<http://arxiv.org/pdf/2501.17595v3>|提出一种置信度校准方法，通过引入置信度不匹配惩罚，有效改善低样本分类中的域泛化性能。|
|📝 更新|Parameter-Efficient Adaptation of Geospatial Foundation Models through Embedding Deflection|通过嵌入偏移实现的地理空间基础模型参数高效适应|Romain Thoreau, Valerio Marsocci, Dawa Derksen|<http://arxiv.org/pdf/2503.09493v2>|提出了一种参数高效的地理空间基础模型适应策略DEFLECT，使用极少量额外参数显著提升多光谱卫星图像...|
|🆕 发布|ArchGPT: Understanding the World's Architectures with Large Multimodal Models|《ArchGPT：利用大型多模态模型理解世界建筑》|Yuze Wang, Luo Yang, Junyi Wang, Yue Qi|<http://arxiv.org/pdf/2509.20858v1>|提出了一种大规模多模态模型ArchGPT，通过高效数据构建流程解决建筑领域视觉问答问题。|
|🆕 发布|CaTS-Bench: Can Language Models Describe Numeric Time Series?|CaTS-Bench：语言模型能否描述数值时间序列？|Luca Zhou, Pratham Yashwante, Marshall Fisher, Alessio Sampieri, Zihao Zhou, Fabio Galasso, Rose Yu|<http://arxiv.org/pdf/2509.20823v1>|提出了CaTS-Bench，首个大规模真实世界时序数据描述基准，结合元数据和图像，增强时序描述准确性...|
|📝 更新|MonSter++: Unified Stereo Matching, Multi-view Stereo, and Real-time Stereo with Monodepth Priors|MonSter++：统一立体匹配、多视角立体匹配与基于Monodepth先验的实时立体匹配|Junda Cheng, Wenjing Liao, Zhipeng Cai, Longliang Liu, Gangwei Xu, Xianqi Wang, Yuzhou Wang, Zikang Yuan .etc.|<http://arxiv.org/pdf/2501.08643v2>|MonSter++整合单目深度先验，实现了多视角深度估计的统一框架，显著提升了准确性和实时性能。|
|📝 更新|MMaDA: Multimodal Large Diffusion Language Models|多模态大规模扩散语言模型（MMaDA）|Ling Yang, Ye Tian, Bowen Li, Xinchen Zhang, Ke Shen, Yunhai Tong, Mengdi Wang|<http://arxiv.org/pdf/2505.15809v2>|[代码](https://github.com/Gen-Verse/MMaDA); 提出MMaDA模型，通过统一架构和跨模态策略提升文本推理、多模态理解和图像生成性能。|
|📝 更新|DermINO: Hybrid Pretraining for a Versatile Dermatology Foundation Model|皮肤疾病智能识别基础模型：混合预训练实现多用途性|Jingkai Xu, De Cheng, Xiangqian Zhao, Jungang Yang, Zilong Wang, Xinyang Jiang, Xufang Luo, Lili Chen .etc.|<http://arxiv.org/pdf/2508.12190v2>|提出 DermNIO 模型，通过混合预训练框架提升皮肤病诊断模型的泛化能力，显著优于现有技术。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SOOD++: Leveraging Unlabeled Data to Boost Oriented Object Detection|SOOD++：利用未标记数据提升定向目标检测|Dingkang Liang, Wei Hua, Chunsheng Shi, Zhikang Zou, Xiaoqing Ye, Xiang Bai|<http://arxiv.org/pdf/2407.01016v2>|[代码](https://dk-liang.github.io/SOODv2); 提出了一种半监督方法SOOD++，利用未标注数据提升定向对象检测性能，尤其适用于航空影像中的小尺度、...|
|📝 更新|Lightweight Modular Parameter-Efficient Tuning for Open-Vocabulary Object Detection|轻量级模块化参数高效调整用于开放词汇对象检测|Bilal Faye, Hanane Azzag, Mustapha Lebbah|<http://arxiv.org/pdf/2408.10787v4>|提出了一种轻量级模块化参数高效调整框架UniProj-Det，仅需训练约2-5%的参数即可实现开放词...|
|🆕 发布|Real-Time Object Detection Meets DINOv3|实时目标检测遇见DINOv3|Shihua Huang, Yongjie Hou, Longfei Liu, Xuanlong Yu, Xi Shen|<http://arxiv.org/pdf/2509.20787v1>|整合DINOv3特征与DEIM框架，推出多尺度适配的DEIMv2，实现性能与效率的显著提升。|
|📝 更新|Efficiently Disentangling CLIP for Multi-Object Perception|高效解耦CLIP以实现多目标感知|Samyak Rawlekar, Yujun Cai, Yiwei Wang, Ming-Hsuan Yang, Narendra Ahuja|<http://arxiv.org/pdf/2502.02977v4>|提出DCLIP框架，通过调节特征相似度，有效提升视觉语言模型在多物体场景的识别能力。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|P3-SAM: Native 3D Part Segmentation|P3-SAM：原生三维部件分割|Changfeng Ma, Yang Li, Xinhao Yan, Jiachen Xu, Yunhan Yang, Chunshi Wang, Zibo Zhao, Yanwen Guo .etc.|<http://arxiv.org/pdf/2509.06784v4>|[代码](https://murcherful.github.io/P3-SAM); 提出了一种自动化3D物体部件分割模型P$^3$-SAM，实现了对复杂物体的精确分割并达到最佳性能。|
|🆕 发布|OmniPlantSeg: Species Agnostic 3D Point Cloud Organ Segmentation for High-Resolution Plant Phenotyping Across Modalities|全植物分割：跨模态高分辨率植物表型分析中种间通用的三维点云器官分割方法|Andreas Gilson, Lukas Meyer, Oliver Scholz, Ute Schmid|<http://arxiv.org/pdf/2509.21038v1>|提出了KDSS算法，实现了无需降采样即可对全分辨率植物点云进行物种无关的器官分割。|
|📝 更新|Interpreting ResNet-based CLIP via Neuron-Attention Decomposition|通过神经元注意力分解解释基于ResNet的CLIP|Edmund Bu, Yossi Gandelsman|<http://arxiv.org/pdf/2509.19943v2>|提出了一种分解CLIP-ResNet神经元贡献的新技术，通过分析神经元与注意力头的关系，实现了无需训...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SwinMamba: A hybrid local-global mamba framework for enhancing semantic segmentation of remotely sensed images|SwinMamba：一种用于增强遥感图像语义分割的混合局部-全局Mamba框架|Qinfeng Zhu, Han Li, Liang He, Lei Fan|<http://arxiv.org/pdf/2509.20918v1>|提出SwinMamba框架，结合局部和全局特征扫描，提升遥感图像语义分割精度。|
|🆕 发布|Concepts in Motion: Temporal Bottlenecks for Interpretable Video Classification|动态概念：用于可解释视频分类的时间瓶颈|Patrick Knab, Sascha Marton, Philipp J. Schubert, Drago Guggiana, Christian Bartelt|<http://arxiv.org/pdf/2509.20899v1>|[代码](https://github.com/patrick-knab/MoTIF.); 提出了一种视频分类框架MoTIF，通过引入时间瓶颈处理视频时序依赖，增强了解释性和性能。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Finding 3D Positions of Distant Objects from Noisy Camera Movement and Semantic Segmentation Sequences|从噪声相机运动和语义分割序列中寻找远处物体的三维位置|Julius Pesonen, Arno Solin, Eija Honkavaara|<http://arxiv.org/pdf/2509.20906v1>|提出了一种利用粒子滤波器从相机运动和语义分割序列定位远距离物体的新方法，适用于计算资源受限的监控任务...|
|🆕 发布|FSMODNet: A Closer Look at Few-Shot Detection in Multispectral Data|FSMODNet：深入探讨多光谱数据中的少样本检测|Manuel Nkegoum, Minh-Tan Pham, Élisa Fromont, Bruno Avignon, Sébastien Lefèvre|<http://arxiv.org/pdf/2509.20905v1>|提出FSMODNet框架，通过跨模态特征融合提升少量标注数据下的多光谱目标检测性能。|
|🆕 发布|Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer|超越精度：具有可学习正则化器的小量化模型蒸馏|Abdur Rehman, S M A Sharif, Md Abdur Rahaman, Mohamed Jismy Aashik Rasool, Seongwan Kim, Jaeho Lee|<http://arxiv.org/pdf/2509.20854v1>|提出了一种自适应平衡任务特定和蒸馏损失的GoR方法，有效提升了低比特量化模型的性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|NewtonGen: Physics-Consistent and Controllable Text-to-Video Generation via Neural Newtonian Dynamics|牛顿生成：通过神经牛顿动力学实现物理一致且可控的文本到视频生成|Yu Yuan, Xijun Wang, Tharindu Wickremasinghe, Zeeshan Nadir, Bole Ma, Stanley H. Chan|<http://arxiv.org/pdf/2509.21309v1>|提出了一种融合数据驱动和可学习物理原理的NewtonGen框架，通过神经网络模拟牛顿动力学实现物理一...|
|🆕 发布|SD3.5-Flash: Distribution-Guided Distillation of Generative Flows|SD3.5-Flash：分布引导的生成流蒸馏方法|Hmrishav Bandyopadhyay, Rahim Entezari, Jim Scott, Reshinth Adithyan, Yi-Zhe Song, Varun Jampani|<http://arxiv.org/pdf/2509.21318v1>|提出了一种高效的少步蒸馏框架SD3.5-Flash，通过分布匹配优化和梯度噪声减少，实现了在普通消费...|
|📝 更新|3D-MoRe: Unified Modal-Contextual Reasoning for Embodied Question Answering|3D-MoRe：统一模态-上下文推理用于具身问答|Rongtao Xu, Han Gao, Mingming Yu, Dong An, Shunpeng Chen, Changwei Wang, Li Guo, Xiaodan Liang .etc.|<http://arxiv.org/pdf/2507.12026v2>|提出3D-MoRe框架，利用基础模型生成大规模3D语言数据集，提升室内场景问答和描述性能。|
|🆕 发布|Evaluating the Evaluators: Metrics for Compositional Text-to-Image Generation|评估评估者：组合文本到图像生成的评价指标|Seyed Amir Kasaei, Ali Aghayari, Arash Marioriyad, Niki Sepasian, MohammadAmin Fazli, Mahdieh Soleymani Baghshah, Mohammad Hossein Rohban|<http://arxiv.org/pdf/2509.21227v1>|分析了多种文本到图像生成评价指标与人类判断的匹配度，发现无单一指标在所有任务中表现一致。|
|🆕 发布|Hunyuan3D-Omni: A Unified Framework for Controllable Generation of 3D Assets|Hunyuan3D-Omni：用于可控生成三维资源的统一框架|Team Hunyuan3D, :, Bowen Zhang, Chunchao Guo, Haolin Liu, Hongyu Yan, Huiwen Shi, Jingwei Huang .etc.|<http://arxiv.org/pdf/2509.21245v1>|提出了Hunyuan3D-Omni框架，实现了对3D资产生成更精细、跨模态的控制。|
|📝 更新|NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining|无需人工干预：自主高质量图像编辑三元组挖掘|Maksim Kuprashevich, Grigorii Alekseenko, Irina Tolstykh, Georgii Fedorov, Bulat Suleimanov, Vladimir Dokholyan, Aleksandr Gordeev|<http://arxiv.org/pdf/2507.14119v2>|自动化挖掘高保真图像编辑数据集，无需人工标注，大幅提升生成模型训练效率和质量。|
|🆕 发布|The Unwinnable Arms Race of AI Image Detection|人工智能图像检测的无胜算军备竞赛|Till Aczel, Lorenzo Vettor, Andreas Plesner, Roger Wattenhofer|<http://arxiv.org/pdf/2509.21135v1>|探究数据维度与复杂度对AI图像检测的影响，发现中等复杂度数据最有利于检测合成图像。|
|📝 更新|REArtGS: Reconstructing and Generating Articulated Objects via 3D Gaussian Splatting with Geometric and Motion Constraints|通过几何与运动约束的三维高斯散点法重建与生成关节对象：REArtGS|Di Wu, Liu Liu, Zhou Linli, Anran Huang, Liangtu Song, Qiaojun Yu, Qi Wu, Cewu Lu|<http://arxiv.org/pdf/2503.06677v4>|引入几何和运动约束的3D高斯散射框架，实现了关节对象的逼真表面重建和动态生成。|
|🆕 发布|MotionFlow:Learning Implicit Motion Flow for Complex Camera Trajectory Control in Video Generation|《MotionFlow：学习隐式运动流以实现复杂相机轨迹控制下的视频生成》|Guojun Lei, Chi Wang, Yikai Wang, Hong Li, Ying Song, Weiwei Xu|<http://arxiv.org/pdf/2509.21119v1>|整合相机与物体运动生成稳定视频，通过学习像素级运动流实现复杂相机轨迹控制。|
|🆕 发布|CHARM: Control-point-based 3D Anime Hairstyle Auto-Regressive Modeling|基于控制点的3D动漫发型自动回归建模：CHARM|Yuze He, Yanning Zhou, Wang Zhao, Jingwen Ye, Yushi Bai, Kaiwen Xiao, Yong-Jin Liu, Zhongqian Sun .etc.|<http://arxiv.org/pdf/2509.21114v1>|[代码](https://hyzcluster.github.io/charm); 提出了一种基于控制点的参数化表示和生成框架，实现了高效准确的动漫发型建模与生成。|
|🆕 发布|UniTransfer: Video Concept Transfer via Progressive Spatial and Timestep Decomposition|"UniTransfer：通过逐步空间和时间分解实现视频概念迁移"|Guojun Lei, Rong Zhang, Chi Wang, Tianhang Liu, Hong Li, Zhiyuan Ma, Weiwei Xu|<http://arxiv.org/pdf/2509.21086v1>|[代码](https://yu-shaonian.github.io/UniTransfer-Web); 提出UniTransfer框架，通过逐步空间和时间分解实现精确可控的视频概念转移。|
|🆕 发布|KeyWorld: Key Frame Reasoning Enables Effective and Efficient World Models|关键帧推理助力构建有效且高效的世界模型：KeyWorld|Sibo Li, Qianyue Hao, Yu Shang, Yong Li|<http://arxiv.org/pdf/2509.21027v1>|提出KeyWorld框架，通过聚焦关键帧推理和轻量级插值，提升机器人世界模型的效率和物理真实性。|
|📝 更新|Neurodynamics-Driven Coupled Neural P Systems for Multi-Focus Image Fusion|神经动力学驱动的耦合神经网络P系统用于多焦点图像融合|Bo Li, Yunkuo Lei, Tingting Bao, Yaxian Wang, Lingling Zhang, Jun Liu|<http://arxiv.org/pdf/2509.17704v2>|[代码](https://github.com/MorvanLi/ND-CNPFuse.); 提出了一种基于神经动态驱动的耦合神经网络模型，用于生成高质量的多焦点图像融合决策图。|
|🆕 发布|SimDiff: Simulator-constrained Diffusion Model for Physically Plausible Motion Generation|SimDiff：基于模拟器约束的扩散模型用于生成物理上可信的运动|Akihisa Watanabe, Jiawei Ren, Li Siyao, Yichen Peng, Erwin Wu, Edgar Simo-Serra|<http://arxiv.org/pdf/2509.20927v1>|提出SimDiff模型，通过直接整合环境参数到去噪过程，高效生成符合物理规律的人类运动。|
|🆕 发布|FerretNet: Efficient Synthetic Image Detection via Local Pixel Dependencies|FerretNet：通过局部像素依赖进行高效合成图像检测|Shuqiao Liang, Jian Liu, Renzhang Chen, Quanlong Guan|<http://arxiv.org/pdf/2509.20890v1>|提出 FerretNet，利用局部像素依赖性检测合成图像，实现高效准确识别。|
|📝 更新|HazeFlow: Revisit Haze Physical Model as ODE and Non-Homogeneous Haze Generation for Real-World Dehazing|《HazeFlow：将雾霾物理模型重新定义为常微分方程及非均匀雾霾生成用于实际世界去雾》|Junseong Shin, Seungwoo Chung, Yunjeong Yang, Tae Hyun Kim|<http://arxiv.org/pdf/2509.18190v2>|提出了一种基于微分方程的HazeFlow框架和新的非均匀 haze生成方法，有效提升了真实世界去雾性...|
|📝 更新|Understanding-in-Generation: Reinforcing Generative Capability of Unified Model via Infusing Understanding into Generation|《生成中的理解：通过将理解融入生成来强化统一模型的生成能力》|Yuanhuiyi Lyu, Chi Kit Wong, Chenfei Liao, Lutao Jiang, Xu Zheng, Zexin Lu, Linfeng Zhang, Xuming Hu|<http://arxiv.org/pdf/2509.18639v3>|[代码](https://github.com/QC-LY/UiG); 提出Understanding-in-Generation框架，通过融合理解能力提升统一模型在图像生...|
|🆕 发布|ARMesh: Autoregressive Mesh Generation via Next-Level-of-Detail Prediction|ARMesh：通过下一级细节预测的自回归网格生成|Jiabao Lei, Kewei Shi, Zhihao Liang, Kui Jia|<http://arxiv.org/pdf/2509.20824v1>|提出了一种渐进式细节预测的自动回归网格生成方法，有效捕捉几何结构并支持网格优化。|
|🆕 发布|Extrapolating Phase-Field Simulations in Space and Time with Purely Convolutional Architectures|用纯卷积架构在空间和时间上外推相场模拟|Christophe Bonneville, Nathan Bieberdorf, Pieterjan Robbe, Mark Asta, Habib N. Najm, Laurent Capolungo, Cosmin Safta|<http://arxiv.org/pdf/2509.20770v1>|提出了一种基于卷积神经网络的替代模型，大幅加速了液态金属腐蚀过程的模拟速度。|
|📝 更新|Conditional Video Generation for High-Efficiency Video Compression|条件视频生成用于高效视频压缩|Fangqiu Yi, Jingyu Xu, Jiawei Shao, Chi Zhang, Xuelong Li|<http://arxiv.org/pdf/2507.15269v4>|提出了一种基于条件扩散模型的视频压缩框架，通过多粒度条件化和模态训练优化了感知质量下的视频重建。|
|🆕 发布|Provenance Analysis of Archaeological Artifacts via Multimodal RAG Systems|通过多模态关系图系统对考古文物的来源分析|Tuo Zhang, Yuechun Sun, Ruiliang Liu|<http://arxiv.org/pdf/2509.20769v1>|提出了一种结合多模态检索和大型视觉语言模型的系统，用于考古文物的来源分析，有效支持专家推理并减轻其认...|
|🆕 发布|CusEnhancer: A Zero-Shot Scene and Controllability Enhancement Method for Photo Customization via ResInversion|“CusEnhancer：一种通过ResInversion实现零样本场景与可控性增强的图片定制方法”|Maoye Ren, Praneetha Vaddamanu, Jianjin Xu, Fernando De la Torre Frade|<http://arxiv.org/pdf/2509.20775v1>|提出了一种零样本增强框架CustomEnhancer，通过融合预训练模型和新型ResInversio...|
|📝 更新|Training-Free Layout-to-Image Generation with Marginal Attention Constraints|无需训练的布局到图像生成：基于边际注意力约束|Huancheng Chen, Jingtao Li, Weiming Zhuang, Haris Vikalo, Lingjuan Lyu|<http://arxiv.org/pdf/2411.10495v2>|提出了一种无需训练的布局到图像生成方法MAC，通过边界注意力约束优化特征，实现了更精确的图像布局控制...|
|🆕 发布|Neptune-X: Active X-to-Maritime Generation for Universal Maritime Object Detection|海王星X：主动X到航海生成法用于通用航海目标检测|Yu Guo, Shengfeng He, Yuxu Lu, Haonan An, Yihang Tao, Huilin Zhu, Jingxian Liu, Yuguang Fang|<http://arxiv.org/pdf/2509.20745v1>|[代码](https://github.com/gy65896/Neptune-X.); 提出Neptune-X框架，通过合成数据和任务感知样本选择提升海上目标检测效果。|
|📝 更新|EC-Diffuser: Multi-Object Manipulation via Entity-Centric Behavior Generation|EC-Diffuser：基于实体中心行为生成的多目标操作|Carl Qi, Dan Haramati, Tal Daniel, Aviv Tamar, Amy Zhang|<http://arxiv.org/pdf/2412.18907v3>|提出了一种基于对象中心表示和实体中心Transformer的模仿学习策略，实现了多对象操作任务的零样...|
|🆕 发布|SeamCrafte: Enhancing Mesh Seam Generation for Artist UV Unwrapping via Reinforcement Learning|SeamCrafte：通过强化学习增强艺术家UV展开的网格接缝生成|Duoteng Xu, Yuguang Chen, Jing Li, Xinhai Liu, Xueqi Ma, Zhuo Chen, Dongyu Zhang, Chunchao Guo|<http://arxiv.org/pdf/2509.20725v1>|SeamCrafter通过强化学习优化网格缝合线生成，显著降低UV扭曲和碎片化，提升艺术家贴图效率。|
|🆕 发布|ArtUV: Artist-style UV Unwrapping|艺术家风格UV展开：ArtUV|Yuguang Chen, Xinhai Liu, Yang Li, Victor Cheung, Zhuo Chen, Dongyu Zhang, Chunchao Guo|<http://arxiv.org/pdf/2509.20710v1>|提出了一种自动化的UV展开方法ArtUV，生成符合艺术家风格的UV图，提高了编辑效率和语义一致性。|
|🆕 发布|Joint Flow Trajectory Optimization For Feasible Robot Motion Generation from Video Demonstrations|联合流轨迹优化：从视频演示生成可行机器人运动|Xiaoxiang Dong, Matthew Johnson-Roberson, Weiming Zhi|<http://arxiv.org/pdf/2509.20703v1>|提出了一种优化机器人运动生成的框架，通过视频演示学习生成可行的抓取姿态和物体轨迹。|
|🆕 发布|Efficient Construction of Implicit Surface Models From a Single Image for Motion Generation|从单张图像高效构建隐式表面模型用于运动生成|Wei-Teng Chu, Tianyi Zhang, Matthew Johnson-Roberson, Weiming Zhi|<http://arxiv.org/pdf/2509.20681v1>|提出了一种快速从单张图像构建高保真隐式表面模型的方法，大幅提升了重建速度和准确性。|
|📝 更新|Does the Manipulation Process Matter? RITA: Reasoning Composite Image Manipulations via Reversely-Ordered Incremental-Transition Autoregression|《操纵过程重要吗？RITA：通过反向顺序增量转换自回归进行复合图像操纵推理》|Xuekang Zhu, Ji-Zhe Zhou, Kaiwen Feng, Chenfan Qu, Yunfei Wang, Liting Zhou, Jian Liu|<http://arxiv.org/pdf/2509.20006v2>|首次将图像操纵定位任务重构为条件序列预测任务，提出RITA框架逐层预测操纵区域，显式建模编辑操作间的...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Does FLUX Already Know How to Perform Physically Plausible Image Composition?|FLUX是否已经知道如何执行物理上可信的图像合成？|Shilin Lu, Zhuming Lian, Zihan Zhou, Shaocong Zhang, Chen Zhao, Adams Wai-Kin Kong|<http://arxiv.org/pdf/2509.21278v1>|提出SHINE框架，通过利用预训练模型实现无需训练的高质量图像合成，解决了复杂光照和分辨率下的图像合...|
|📝 更新|IDEATOR: Jailbreaking and Benchmarking Large Vision-Language Models Using Themselves|IDEATOR：使用自身破解和评估大型视觉-语言模型的标准基准|Ruofan Wang, Juncheng Li, Yixu Wang, Bo Wang, Xiaosen Wang, Yan Teng, Yingchun Wang, Xingjun Ma .etc.|<http://arxiv.org/pdf/2411.00827v6>|[代码](https://roywang021.github.io/VLJailbreakBench.); 提出IDEATOR方法，利用大型视觉语言模型自身生成恶意图像-文本对进行安全测试，创建了首个多模态安...|
|📝 更新|GVDepth: Zero-Shot Monocular Depth Estimation for Ground Vehicles based on Probabilistic Cue Fusion|GVDepth：基于概率线索融合的地面车辆零样本单目深度估计|Karlo Koledić, Luka Petrović, Ivan Marković, Ivan Petrović|<http://arxiv.org/pdf/2412.06080v2>|[代码](https://unizgfer-lamor.github.io/gvdepth); 提出了一种适用于自动驾驶的零样本单目深度估计方法，通过概率性融合不同线索，实现了跨数据集和相机设置的...|
|🆕 发布|SlideMamba: Entropy-Based Adaptive Fusion of GNN and Mamba for Enhanced Representation Learning in Digital Pathology|SlideMamba：基于熵的图神经网络与Mamba自适应融合增强数字病理学表征学习|Shakib Khan, Fariba Dambandkhameneh, Nazim Shaikh, Yao Nie, Raghavan Venugopal, Xiao Li|<http://arxiv.org/pdf/2509.21239v1>|提出了一种结合图神经网络与Mamba架构的深度学习框架SlideMamba，通过熵基自适应融合策略优...|
|📝 更新|D2-Mamba: Dual-Scale Fusion and Dual-Path Scanning with SSMs for Shadow Removal|D2-Mamba：双尺度融合与双路径扫描结合SSM进行阴影去除|Linhao Li, Boya Jin, Zizhe Li, Lanqing Guo, Hao Cheng, Bo Li, Yongfeng Dong|<http://arxiv.org/pdf/2508.12750v3>|提出了一种双尺度融合和双路径扫描的Mamba网络，有效整合非阴影区域信息以改善阴影移除效果。|
|🆕 发布|Learning Conformal Explainers for Image Classifiers|为图像分类器学习共形解释器|Amr Alkhatib, Stephanie Lowry|<http://arxiv.org/pdf/2509.21209v1>|提出了一种基于符合预测的控制解释保真度的方法，有效提升了图像分类解释的准确性和效率。|
|🆕 发布|A Unified Framework for Diffusion Model Unlearning with f-Divergence|基于f-散度的扩散模型遗忘统一框架|Nicola Novello, Federico Fontana, Luigi Cinque, Deniz Gunduz, Andrea M. Tonello|<http://arxiv.org/pdf/2509.21167v1>|提出统一框架使用f-散度改进扩散模型遗忘效果，平衡遗忘强度与概念保留。|
|📝 更新|Diff-Reg v2: Diffusion-Based Matching Matrix Estimation for Image Matching and 3D Registration|扩散调节v2：基于扩散的匹配矩阵估计用于图像匹配与三维配准|Qianliang Wu, Haobo Jiang, Yaqing Ding, Lei Luo, Jun Li, Jin Xie, Xiaojun Wu, Jian Yang|<http://arxiv.org/pdf/2503.04127v3>|提出了一种基于扩散模型在矩阵空间的匹配矩阵估计方法，有效解决了图像和点云匹配中的尺度不一致、对称性和...|
|🆕 发布|A Single Neuron Works: Precise Concept Erasure in Text-to-Image Diffusion Models|单一神经元有效：文本到图像扩散模型中的精确概念擦除|Qinqin He, Jiaqi Weng, Jialing Tao, Hui Xue|<http://arxiv.org/pdf/2509.21008v1>|提出了一种基于单个神经元的概念擦除方法，精确移除有害内容同时保持图像质量。|
|📝 更新|CNS-Bench: Benchmarking Image Classifier Robustness Under Continuous Nuisance Shifts|CNS-Bench：在连续干扰变换下图像分类器鲁棒性的基准测试|Olaf Dünkel, Artur Jesslen, Jiahao Xie, Christian Theobalt, Christian Rupprecht, Adam Kortylewski|<http://arxiv.org/pdf/2507.17651v2>|[代码](https://genintel.github.io/CNS.); 提出了CNS-Bench，一种用于评估图像分类器在连续现实干扰下的OOD鲁棒性的新基准。|
|🆕 发布|SCRA-VQA: Summarized Caption-Rerank for Augmented Large Language Models in Visual Question Answering|SCRA-VQA：基于摘要字幕重排的增强大规模语言模型在视觉问答中的应用|Yan Zhang, Jiaqing Lin, Miao Zhang, Kui Xiao, Xiaoju Hou, Yue Zhao, Zhifei Li|<http://arxiv.org/pdf/2509.20871v1>|[代码](https://github.com/HubuKG/SCRA-VQA.); 提出SCRA-VQA方法，通过总结和重排图像字幕增强大语言模型在视觉问答中的推理能力。|
|📝 更新|Instance-aware Image Colorization with Controllable Textual Descriptions and Segmentation Masks|基于可控文本描述和分割掩膜的实例感知图像着色|Yanru An, Ling Gui, Chunlei Cai, Tianxiao Ye, JIangchao Yao, Guangtao Zhai, Qiang Hu, Xiaoyun Zhang|<http://arxiv.org/pdf/2505.08705v2>|提出了一种基于扩散模型的实例级图像着色方法，通过像素级掩码注意力和文本引导，有效解决了颜色溢出和绑定...|
|📝 更新|Odo: Depth-Guided Diffusion for Identity-Preserving Body Reshaping|Odo：基于深度引导的扩散算法实现身份保持的身体重塑|Siddharth Khandelwal, Sridhar Kamath, Arjun Jain|<http://arxiv.org/pdf/2508.13065v3>|提出首个大规模人体形状编辑数据集，并创新使用深度引导扩散方法实现真实自然的人体重塑。|
|📝 更新|LazyDrag: Enabling Stable Drag-Based Editing on Multi-Modal Diffusion Transformers via Explicit Correspondence|“LazyDrag：通过显式对应关系在多模态扩散变换器上实现稳定的拖动式编辑”|Zixin Yin, Xili Dai, Duomin Wang, Xianfang Zeng, Lionel M. Ni, Gang Yu, Heung-Yeung Shum|<http://arxiv.org/pdf/2509.12203v2>|LazyDrag通过引入显式对应图消除了拖拽编辑中的隐式点匹配依赖，实现了稳定且高效的图像编辑。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hallucination as an Upper Bound: A New Perspective on Text-to-Image Evaluation|“将想象作为上限：文本到图像评估的新视角”|Seyed Amir Kasaei, Mohammad Hossein Rohban|<http://arxiv.org/pdf/2509.21257v1>|定义文本到图像生成模型中的“幻觉”现象，提出分类体系以评估模型偏差，为更全面的评估提供上限标准。|
|📝 更新|Autoregressive Image Generation with Randomized Parallel Decoding|带有随机并行解码的自回归图像生成|Haopeng Li, Jinyue Yang, Guoqi Li, Huan Wang|<http://arxiv.org/pdf/2503.10568v2>|提出了一种随机并行解码的视觉自回归模型，解决了传统顺序生成方法的效率问题，并实现了零样本泛化。|
|🆕 发布|Unlocking Financial Insights: An advanced Multimodal Summarization with Multimodal Output Framework for Financial Advisory Videos|解锁金融洞察：一种面向金融咨询视频的高级多模态摘要与多模态输出框架|Sarmistha Das, R E Zera Marveen Lyngkhoi, Sriparna Saha, Alka Maurya|<http://arxiv.org/pdf/2509.20961v1>|[代码](https://github.com/sarmistha-D/FASTER); 提出FASTER框架，通过多模态特征提取和优化总结，提高金融咨询视频内容的可访问性和实用性。|
|🆕 发布|Integrating Object Interaction Self-Attention and GAN-Based Debiasing for Visual Question Answering|融合对象交互自注意力与基于生成对抗网络的去偏方法用于视觉问答|Zhifei Li, Feng Qiu, Yiran Wang, Yujing Xia, Kui Xiao, Miao Zhang, Yan Zhang|<http://arxiv.org/pdf/2509.20884v1>|[代码](https://github.com/HubuKG/IOG-VQA.); 集成对象交互自注意力与生成对抗网络去偏策略，提升视觉问答模型对复杂场景的理解与泛化能力。|
|📝 更新|Semantic-Aware Reconstruction Error for Detecting AI-Generated Images|面向语义的重建误差用于检测AI生成的图像|Ju Yeon Kang, Jaehong Park, Semin Kim, Ji Won Yoon, Nam Soo Kim|<http://arxiv.org/pdf/2508.09487v2>|提出了一种基于语义重建误差的AI生成图像检测方法，有效应对不同生成模型的泛化问题。|
|🆕 发布|Federated Domain Generalization with Domain-specific Soft Prompts Generation|联邦域泛化与域特定软提示生成|Jianhan Wu, Xiaoyang Qu, Zhangcheng Huang, Jianzong Wang|<http://arxiv.org/pdf/2509.20807v1>|提出了一种生成特定领域软提示的方法，有效解决了联邦学习中的领域泛化问题，实现了领先性能。|
|🆕 发布|FreeInsert: Personalized Object Insertion with Geometric and Style Control|自由插入：具有几何与风格控制的个性化对象插入|Yuhong Zhang, Han Wang, Yiwen Wang, Rong Xie, Li Song|<http://arxiv.org/pdf/2509.20756v1>|提出FreeInsert框架，通过3D几何信息实现个性化物体插入，确保几何控制和风格一致性。|
|📝 更新|Generating 360° Video is What You Need For a 3D Scene|生成360°视频是您构建三维场景所需的关键|Zhaoyang Zhang, Yannick Hold-Geoffroy, Miloš Hašan, Ziwen Chen, Fujun Luan, Julie Dorsey, Yiwei Hu|<http://arxiv.org/pdf/2504.02045v4>|提出利用360°视频生成技术创建全场景3D环境，实现真实可导航的3D场景重建。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MOSS-ChatV: Reinforcement Learning with Process Reasoning Reward for Video Temporal Reasoning|MOSS-ChatV：基于过程推理奖励的强化学习在视频时间推理中的应用|Sicheng Tao, Jungang Li, Yibo Yan, Junyan Zhang, Yubo Gao, Hanqian Li, ShuHang Xun, Yuxuan Fan .etc.|<http://arxiv.org/pdf/2509.21113v1>|提出了一种基于动态时间扭曲的强化学习框架，通过过程奖励提升了视频时序推理的一致性和稳定性。|
|🆕 发布|Cross-Modal Instructions for Robot Motion Generation|跨模态指令驱动的机器人运动生成|William Barron, Xiaoxiang Dong, Matthew Johnson-Roberson, Weiming Zhi|<http://arxiv.org/pdf/2509.21107v1>|提出利用跨模态指令替代物理示教，通过集成文本和视觉信息训练机器人生成运动轨迹的新方法。|
|📝 更新|Why Settle for One? Text-to-ImageSet Generation and Evaluation|为何止步于一个？文本到图像集生成与评估|Chengyou Jia, Xin Shen, Zhuohang Dang, Zhuohang Dang, Changliang Xia, Weijia Wu, Xinyu Zhang, Hangwei Qian .etc.|<http://arxiv.org/pdf/2506.23275v2>|[代码](https://chengyou-jia.github.io/T2IS-Home.); 超出了单张图像生成范围，提出了一种生成满足多样化一致性需求的图像集合的方法AutoT2IS。|
|📝 更新|StrCGAN: A Generative Framework for Stellar Image Restoration|恒星图像复原的生成式框架：StrCGAN|Shantanusinh Parmar|<http://arxiv.org/pdf/2509.19805v2>|引入StrCGAN，通过3D卷积、多光谱融合和天文规则化模块，实现了高保真恒星图像的重建。|
|📝 更新|Learning Flow-Guided Registration for RGB-Event Semantic Segmentation|学习基于流引导的配准方法用于RGB-事件语义分割|Zhen Yao, Xiaowen Ying, Zhiyu Zhu, Mooi Choo Chuah|<http://arxiv.org/pdf/2505.01548v2>|[代码](https://github.com/zyaocoder/BRENet.); 提出将RGB-Event感知从融合问题转变为配准问题，并引入BRENet框架和MET表示，有效解决模...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CryoSplat: Gaussian Splatting for Cryo-EM Homogeneous Reconstruction|“CryoSplat：用于冷冻电镜同质重构的高斯散点技术”|Suyi Chen, Haibin Ling|<http://arxiv.org/pdf/2508.04929v3>|提出了一种结合高斯散点投射与冷冻电镜成像物理的方法，实现了从原始冷冻电镜粒子图像直接稳定高效地重建分...|
|📝 更新|Online Language Splatting|在线语言喷溅|Saimouli Katragadda, Cho-Ying Wu, Yuliang Guo, Xinyu Huang, Guoquan Huang, Liu Ren|<http://arxiv.org/pdf/2503.09447v3>|提出在线语言映射方法，实现实时三维场景与自然语言的无缝融合，大幅提升效率和适应能力。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Sparse Representations Improve Adversarial Robustness of Neural Network Classifiers|稀疏表示提高了神经网络分类器的对抗稳健性|Killian Steunou, Sigurd Saue, Théo Druilhe|<http://arxiv.org/pdf/2509.21130v1>|[代码](https://github.com/killian31/SPCARobustness.); 通过稀疏表示增强神经网络的对抗稳健性，有效抵御白盒和黑盒攻击。|
|🆕 发布|EnGraf-Net: Multiple Granularity Branch Network with Fine-Coarse Graft Grained for Classification Task|EnGraf-Net：具有精细-粗糙嫁接粒度的多粒度分支网络用于分类任务|Riccardo La Grassa, Ignazio Gallo, Nicola Landro|<http://arxiv.org/pdf/2509.21061v1>|提出了一种融合层级语义关联的EnGraf-Net模型，有效提升了细粒度图像分类性能，无需依赖裁剪技术...|
|🆕 发布|Human Semantic Representations of Social Interactions from Moving Shapes|《从动态形状中提取的人类社交互动的语义表征》|Yiling Yun, Hongjing Lu|<http://arxiv.org/pdf/2509.20673v1>|探究人类如何通过动态形状理解社交互动，发现语义模型补充视觉特征解释人类判断。|
|📝 更新|Implicit Neural Representations of Intramyocardial Motion and Strain|《心肌运动与应变的隐式神经表征》|Andrew Bell, Yan Kit Choi, Steffen E Petersen, Andrew King, Muhummad Sohaib Nazir, Alistair A Young|<http://arxiv.org/pdf/2509.09004v4>|[代码](https://github.com/andrewjackbell/Displacement-INR); 利用隐式神经表示预测左心室位移，实现心肌运动与应变的高精度快速量化。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Radar-Guided Polynomial Fitting for Metric Depth Estimation|雷达引导的多项式拟合用于度量深度估计|Patrick Rim, Hyoungseob Park, Vadim Ezhov, Jeffrey Moon, Alex Wong|<http://arxiv.org/pdf/2503.17182v2>|提出了一种利用雷达数据引导的多项式拟合方法，有效将单目深度估计模型的预测转化为精确的度量深度图。|
|🆕 发布|SLAM-Free Visual Navigation with Hierarchical Vision-Language Perception and Coarse-to-Fine Semantic Topological Planning|无SLAM视觉导航：基于层次化视觉-语言感知与粗到细语义拓扑规划|Guoyang Zhao, Yudong Li, Weiqing Qi, Kai Zhang, Bonan Liu, Kai Chen, Haoang Li, Jun Ma|<http://arxiv.org/pdf/2509.20739v1>|提出了一种无需SLAM的视觉导航框架，通过层级视觉-语言感知和粗到细语义拓扑规划，实现了更准确的语义...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VC-Agent: An Interactive Agent for Customized Video Dataset Collection|VC-Agent：一种用于定制化视频数据集收集的交互式代理|Yidan Zhang, Mutian Xu, Yiming Hao, Kun Zhou, Jiahao Chang, Xiaoqiang Liu, Pengfei Wan, Hongbo Fu .etc.|<http://arxiv.org/pdf/2509.21291v1>|[代码](https://allenyidan.github.io/vcagent_page); 提出VC-Agent，首个能理解用户需求并高效收集定制化视频数据的交互式代理。|
|🆕 发布|MedVSR: Medical Video Super-Resolution with Cross State-Space Propagation|MedVSR：基于跨状态空间传播的医疗视频超分辨率|Xinyu Liu, Guolei Sun, Cheng Wang, Yixuan Yuan, Ender Konukoglu|<http://arxiv.org/pdf/2509.21265v1>|[代码](https://github.com/CUHK-AIM-Group/MedVSR.); MedVSR通过跨状态空间传播和内部状态空间重建，有效提升了医学视频超分辨率的质量和效率。|
|📝 更新|TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs|基于强化微调的有效时间采样方法TempSamp-R1：用于视频大规模语言模型|Yunheng Li, Jing Cheng, Shaoyong Jia, Hangyi Kuang, Shaohui Jiao, Qibin Hou, Ming-Ming Cheng|<http://arxiv.org/pdf/2509.18056v2>|[代码](https://github.com/HVision-NKU/TempSamp-R1); TempSamp-R1通过结合强化学习和真实标注，优化了视频时序定位任务中大规模语言模型的适应效果。|
|🆕 发布|Poisoning Prompt-Guided Sampling in Video Large Language Models|视频大型语言模型中针对提示引导采样的中毒攻击|Yuxin Cao, Wei Song, Jingling Xue, Jin Song Dong|<http://arxiv.org/pdf/2509.20851v1>|首次提出针对视频大规模语言模型的prompt引导采样机制的攻击方法，实现了高成功率的数据污染。|
|📝 更新|VideoPASTA: 7K Preference Pairs That Matter for Video-LLM Alignment|视频PASTA：7000个关键偏好对实现视频-大型语言模型对齐的重要性|Yogesh Kulkarni, Pooyan Fazli|<http://arxiv.org/pdf/2504.14096v3>|通过精心设计的对抗示例进行偏好优化，VideoPASTA有效提升了视频语言模型对时空关系的理解能力。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MoCLIP-Lite: Efficient Video Recognition by Fusing CLIP with Motion Vectors|MoCLIP-Lite：通过融合CLIP与运动向量实现的高效视频识别|Binhua Huang, Ni Wang, Arjun Pakrashi, Soumyabrata Dev|<http://arxiv.org/pdf/2509.17084v2>|[代码](https://github.com/microa/MoCLIP-Lite.); 提出了一种融合CLIP与运动向量的高效视频识别框架，大幅提升了准确度同时保持了极低成本。|
|🆕 发布|Every Subtlety Counts: Fine-grained Person Independence Micro-Action Recognition via Distributionally Robust Optimization|《每一细微之处皆重要：通过分布鲁棒优化实现的细粒度人体独立微动作识别》|Feng-Qi Cui, Jinyang Huang, Anyang Tong, Ziyu Jia, Jie Zhang, Zhi Liu, Dan Guo, Jianwei Lu .etc.|<http://arxiv.org/pdf/2509.21261v1>|提出了一种基于分布鲁棒优化的细粒度人物独立微动作识别框架，有效解决了个体差异导致的泛化问题。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Autoregressive End-to-End Planning with Time-Invariant Spatial Alignment and Multi-Objective Policy Refinement|自回归端到端规划结合时间不变空间对齐与多目标策略优化|Jianbo Zhao, Taiyu Ban, Xiangjie Li, Xingtai Gui, Hangning Zhou, Lei Liu, Hongwei Zhao, Bin Li|<http://arxiv.org/pdf/2509.20938v1>|[代码](https://tisa-dpo-e2e.github.io/.); 提出一种自动驾驶端到端规划方法，通过时间不变空间对齐和多重目标策略优化，解决了自回归模型中的时空错位...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Frequency-Compensated Network for Daily Arctic Sea Ice Concentration Prediction|频率补偿网络在每日北极海冰浓度预测中的应用|Jialiang Zhang, Feng Gao, Yanhai Gan, Junyu Dong, Qian Du|<http://arxiv.org/pdf/2504.16745v2>|[代码](https://github.com/oucailab/FCNet); 提出了一种频率补偿网络，通过融合频率域特征和卷积特征，提高了北极海冰浓度预测的精度和细节表现。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Sigma: Semantically Informative Pre-training for Skeleton-based Sign Language Understanding|Sigma：基于骨架的手语理解语义信息预训练|Muxin Pu, Mei Kuan Lim, Chun Yong Chong, Chen Change Loy|<http://arxiv.org/pdf/2509.21223v1>|提出Sigma框架，通过融合视觉与文本模态，实现高效的语义信息预训练，提升手势语言理解性能。|
|📝 更新|CLIPin: A Non-contrastive Plug-in to CLIP for Multimodal Semantic Alignment|CLIPin：一种用于多模态语义对齐的无对比性插件式CLIP方法|Shengzhu Yang, Jiawei Du, Shuai Lu, Weihang Zhang, Ningli Wang, Huiqi Li|<http://arxiv.org/pdf/2508.06434v2>|[代码](https://github.com/T6Yang/CLIPin.); 提出CLIPin，一种非对比学习插件，增强CLIP模型的多模态语义对齐能力，提升监督质量和对齐鲁棒性...|
|📝 更新|On the Perception Bottleneck of VLMs for Chart Understanding|关于图表理解中大型视觉语言模型的感知瓶颈|Junteng Liu, Weihao Zeng, Xiwen Zhang, Yijun Wang, Zifei Shan, Junxian He|<http://arxiv.org/pdf/2503.18435v2>|[代码](https://github.com/hkust-nlp/Vision4Chart.); 揭示了现有大型视觉语言模型在图表理解中的感知瓶颈，并提出了对比学习框架下的视觉编码器增强方法。|


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Cross-Cancer Knowledge Transfer in WSI-based Prognosis Prediction|跨癌症类型知识迁移在基于全切片扫描的预后预测中的应用|Pei Liu, Luping Ji, Jiaxiang Gou, Xiangxiang Zeng|<http://arxiv.org/pdf/2508.13482v2>|[代码](https://github.com/liupei101/CROPKT.); 提出了一种跨癌症预后知识迁移方法CROPKT，利用已有癌症数据提升WSI预后预测性能。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning to Look: Cognitive Attention Alignment with Vision-Language Models|学习观察：基于视觉-语言模型的认知注意力对齐|Ryan L. Yang, Dipkamal Bhusal, Nidhi Rastogi|<http://arxiv.org/pdf/2509.21247v1>|利用自然语言提示自动生成语义注意力图，引导CNN做出更可靠、符合人类直觉的决策。|
|📝 更新|Failure Makes the Agent Stronger: Enhancing Accuracy through Structured Reflection for Reliable Tool Interactions|“失败成就强者：通过结构化反思增强准确度以实现可靠的工具交互”|Junhao Su, Yuanliang Wan, Junwei Yang, Hengyu Shi, Tianyang Han, Junfeng Luo, Yurui Qiu|<http://arxiv.org/pdf/2509.18847v2>|提出结构化反思方法，使模型从错误中学习并优化工具交互的可靠性。|
|🆕 发布|Human-like Navigation in a World Built for Humans|面向人类世界的类人导航|Bhargav Chandaka, Gloria X. Wang, Haozhe Chen, Henry Che, Albert J. Zhai, Shenlong Wang|<http://arxiv.org/pdf/2509.21189v1>|提出了一种集成人类导航行为的ReasonNav系统，通过视觉语言模型实现高效的大环境导航。|
|🆕 发布|Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy|“精度降低能否提高可靠性？对量化对CLIP准确性之外影响的全局评估”|Aymen Bouguerra, Daniel Montoya, Alexandra Gomez-Villa, Fabio Arnez, Chokri Mraidha|<http://arxiv.org/pdf/2509.21173v1>|系统评估量化对CLIP模型性能的影响，发现量化可提升某些可靠性指标，挑战效率与性能的传统权衡观念。|
|🆕 发布|Mammo-CLIP Dissect: A Framework for Analysing Mammography Concepts in Vision-Language Models|《Mammo-CLIP剖析：一种用于分析视觉-语言模型中乳腺X线摄影概念框架》|Suaiba Amina Salahuddin, Teresa Dorszewski, Marit Almenning Martiniussen, Tone Hovda, Antonio Portaluri, Solveig Thrun, Michael Kampffmeyer, Elisabeth Wetzer .etc.|<http://arxiv.org/pdf/2509.21102v1>|[代码](https://github.com/Suaiba/Mammo-CLIP-Dissect.); 提出了一种基于文本概念的哺乳射线图像分析框架，揭示了深度学习模型如何学习并捕获临床相关的哺乳射线特征...|
|📝 更新|AdaSVD: Adaptive Singular Value Decomposition for Large Language Models|自适应奇异值分解（AdaSVD）：面向大型语言模型的自适应奇异值分解方法|Zhiteng Li, Mingyuan Xia, Jingyuan Zhang, Zheng Hui, Haotong Qin, Linghe Kong, Yulun Zhang, Xiaokang Yang|<http://arxiv.org/pdf/2502.01403v4>|[代码](https://github.com/ZHITENGLI/AdaSVD.); 提出自适应奇异值分解方法AdaSVD，通过补偿截断误差和分层压缩比调整，有效压缩大型语言模型内存需求...|
|📝 更新|Buffer-free Class-Incremental Learning with Out-of-Distribution Detection|无缓冲区类别增量学习与分布外检测|Srishti Gupta, Daniele Angioni, Maura Pintor, Ambra Demontis, Lea Schönherr, Battista Biggio, Fabio Roli|<http://arxiv.org/pdf/2505.23412v2>|提出了一种无需内存缓冲的类增量学习方法，通过后处理OOD检测实现隐私保护且性能优越。|
|🆕 发布|SD-RetinaNet: Topologically Constrained Semi-Supervised Retinal Lesion and Layer Segmentation in OCT|SD-RetinaNet：拓扑约束的半监督视网膜病变和层分割算法在OCT中的应用|Botond Fazekas, Guilherme Aresta, Philipp Seeböck, Julia Mai, Ursula Schmidt-Erfurth, Hrvoje Bogunović|<http://arxiv.org/pdf/2509.20864v1>|提出了一种新的半监督模型，通过引入生物标志物拓扑引擎实现病变和层级的解剖正确分割，提升了OCT图像中...|
|🆕 发布|DAC-LoRA: Dynamic Adversarial Curriculum for Efficient and Robust Few-Shot Adaptation|DAC-LoRA：动态对抗性课程学习以实现高效且稳健的小样本适应|Ved Umrajkar|<http://arxiv.org/pdf/2509.20792v1>|提出了一种动态对抗性课程框架DAC-LoRA，通过集成对抗训练提升少量样本适应的效率和鲁棒性。|
|🆕 发布|CompressAI-Vision: Open-source software to evaluate compression methods for computer vision tasks|计算机视觉任务压缩方法评估的开源软件CompressAI-Vision|Hyomin Choi, Heeji Han, Chris Rosewarne, Fabien Racapé|<http://arxiv.org/pdf/2509.20777v1>|[代码](https://github.com/InterDigitalInc/CompressAI-Vision.); CompressAI-Vision提供了一个开源平台，用于评估针对计算机视觉任务优化的压缩方法，提高...|
|🆕 发布|AI-Enabled Crater-Based Navigation for Lunar Mapping|基于人工智能的月球地形测绘中火山坑导航方法|Sofia McLeod, Chee-Kheng Chng, Matthew Rodda, Tat-Jun Chin|<http://arxiv.org/pdf/2509.20748v1>|提出首个适用于长期月球测绘的STELLA系统，实现高精度姿态估计，适应多变的照明和视角条件。|
|📝 更新|Least Volume Analysis|最小体积分析|Qiuyi Chen, Cashen Diniz, Mark Fuge|<http://arxiv.org/pdf/2404.17773v2>|引入了最小体积（Least Volume）正则化方法，有效减少自动编码器所需的潜在维度，无需数据集内...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Differential-Integral Neural Operator for Long-Term Turbulence Forecasting|差分-积分神经网络算子用于长期湍流预测|Hao Wu, Yuan Gao, Fan Xu, Fan Zhang, Qingsong Wen, Kun Wang, Xiaomeng Huang, Xian Wu|<http://arxiv.org/pdf/2509.21196v1>|提出了一种差分-积分神经网络算子，有效解决了长期湍流预测中的误差累积和物理保真度问题。|
|🆕 发布|Marching Neurons: Accurate Surface Extraction for Neural Implicit Shapes|行进神经元：用于神经隐形状的精确表面提取|Christian Stippel, Felix Mujkanovic, Thomas Leimkühler, Pedro Hermosilla|<http://arxiv.org/pdf/2509.21007v1>|提出了一种新的神经隐函数表面提取方法，通过深度优先遍历实现高精度几何信息捕捉，无需空间离散化。|
|🆕 发布|Fast-SEnSeI: Lightweight Sensor-Independent Cloud Masking for On-board Multispectral Sensors|快速独立传感器增强指数（Fast-SEnSeI）：面向机载多光谱传感器的轻量级传感器独立云遮盖检测|Jan Kněžík, Jonáš Herec, Rado Pitoňák|<http://arxiv.org/pdf/2509.20991v1>|定位并解决了多光谱传感器云分割问题，提出Fast-SEnSeI轻量级模块，实现传感器独立、高效在轨处...|
|🆕 发布|The Unanticipated Asymmetry Between Perceptual Optimization and Assessment|《知觉优化与评估之间未曾预料的不对称性》|Jiabei Zhang, Qi Wang, Siyu Wu, Du Chen, Tianhe Wu|<http://arxiv.org/pdf/2509.20878v1>|揭示了感知优化与评估之间的不对称性，发现优化中有效的指标在评估中不一定有效。|
|🆕 发布|RAM-NAS: Resource-aware Multiobjective Neural Architecture Search Method for Robot Vision Tasks|RAM-NAS：面向机器人视觉任务的资源感知多目标神经网络架构搜索方法|Shouren Mao, Minghao Qin, Wei Dong, Huajian Liu, Yongzhuo Gao|<http://arxiv.org/pdf/2509.20688v1>|提出RAM-NAS方法，针对机器人视觉任务，实现资源感知的多目标神经架构搜索，优化模型准确性与硬件延...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Predictive Coding-based Deep Neural Network Fine-tuning for Computationally Efficient Domain Adaptation|基于预测编码的深度神经网络微调方法用于计算高效的域自适应|Matteo Cardoni, Sam Leroux|<http://arxiv.org/pdf/2509.20269v2>|提出了一种结合反向传播和预测编码的混合训练方法，实现了计算高效的在设备域自适应。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Background Prompt for Few-Shot Out-of-Distribution Detection|用于少量样本分布外检测的背景提示|Songyue Cai, Zongqian Wu, Yujie Mo, Liang Peng, Ping Hu, Xiaoshuang Shi, Xiaofeng Zhu|<http://arxiv.org/pdf/2509.21055v1>|[代码](https://github.com/YuzunoKawori/Mambo.); 提出背景提示方法增强少样本异常检测，通过学习背景提示和自适应选取背景块提高鲁棒性。|
|📝 更新|Long-Tailed Out-of-Distribution Detection with Refined Separate Class Learning|长尾分布异常检测的细化分离类学习|Shuai Feng, Yuxin Ge, Yuntao Du, Mingcai Chen, Chongjun Wang, Lei Feng|<http://arxiv.org/pdf/2509.17034v2>|提出 refined separate class learning 方法，通过动态调整温度参数和挖...|
|🆕 发布|Enhancing Cross-View Geo-Localization Generalization via Global-Local Consistency and Geometric Equivariance|通过全局-局部一致性和几何等价性增强跨视角地理定位泛化能力|Xiaowei Wang, Di Wang, Ke Li, Yifeng Wang, Chengjian Wang, Libin Sun, Zhihong Wu, Yiming Zhang .etc.|<http://arxiv.org/pdf/2509.20684v1>|提出了一种增强跨域泛化能力的CVGL框架，通过全局-局部一致性和几何等变性提取稳定特征。|
|🆕 发布|Bispectral OT: Dataset Comparison using Symmetry-Aware Optimal Transport|双谱最优传输：基于对称性感知的最优传输数据集比较|Annabel Ma, Kaiying Hou, David Alvarez-Melis, Melanie Weber|<http://arxiv.org/pdf/2509.20678v1>|引入了双谱最优传输方法，通过利用对称性保持数据结构，提高了数据对比的准确性。|
|📝 更新|Asynchronous Perception Machine For Efficient Test-Time-Training|异步感知机：用于高效测试时间训练|Rajat Modi, Yogesh Singh Rawat|<http://arxiv.org/pdf/2410.20535v4>|[代码](https://rajatmodi62.github.io/apm_project_page); 提出异步感知机(APM)架构，实现高效测试时训练，无需预训练即可识别分布外图像。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FERD: Fairness-Enhanced Data-Free Robustness Distillation|FERD：公平性增强的无数据稳健性蒸馏|Zhengxiao Li, Liming Lu, Xu Zheng, Siyuan Liang, Zhenghan Chen, Yongbin Zhou, Shuchao Pang|<http://arxiv.org/pdf/2509.20793v1>|提出了一种公平性增强的无数据稳健性蒸馏框架，通过调整对抗样本的比例和分布，提高了模型的稳健性和公平性...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Multimodal Deep Learning for Phyllodes Tumor Classification from Ultrasound and Clinical Data|多模态深度学习在超声和临床数据驱动的叶状肿瘤分类中的应用|Farhan Fuad Abir, Abigail Elliott Daly, Kyle Anderman, Tolga Ozmen, Laura J. Brattain|<http://arxiv.org/pdf/2509.00213v2>|提出了一种融合超声图像和临床数据的多模态深度学习框架，提高了乳腺肿瘤的诊断准确性。|
|🆕 发布|An Adaptor for Triggering Semi-Supervised Learning to Out-of-Box Serve Deep Image Clustering|用于触发半监督学习以即插即用服务深度图像聚类的适配器|Yue Duan, Lei Qi, Yinghuan Shi, Yang Gao|<http://arxiv.org/pdf/2509.20976v1>|提出了一种无需预训练的适配器ASD，通过半监督学习直接启动深度图像聚类，实现了与监督方法接近的准确率...|
|🆕 发布|Revisiting Data Challenges of Computational Pathology: A Pack-based Multiple Instance Learning Framework|重新审视计算病理学中的数据挑战：基于包的多实例学习框架|Wenhao Tang, Heng Fang, Ge Wu, Xiang Li, Ming-Ming Cheng|<http://arxiv.org/pdf/2509.20923v1>|[代码](https://github.com/FangHeng/PackMIL); 提出了一种基于打包的多实例学习方法，有效处理计算病理学中数据异质性和冗余问题，提升准确度并减少训练时...|
|🆕 发布|Plant identification based on noisy web data: the amazing performance of deep learning (LifeCLEF 2017)|基于噪声网络数据的植物识别：深度学习的惊人表现（LifeCLEF 2017）|Herve Goeau, Pierre Bonnet, Alexis Joly|<http://arxiv.org/pdf/2509.20856v1>|展示了深度学习在处理大规模网络噪声数据集上的卓越性能，实现了高精度植物识别。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|WAVECLIP: Wavelet Tokenization for Adaptive-Resolution CLIP|WAVECLIP：自适应分辨率CLIP的小波标记化|Moshe Kimhi, Erez Koifman, Ehud Rivlin, Eli Schwartz, Chaim Baskin|<http://arxiv.org/pdf/2509.21153v1>|提出了一种基于小波分解的自适应分辨率CLIP模型，通过多级分解实现计算效率与准确度的平衡。|
|📝 更新|Benchmarking for Practice: Few-Shot Time-Series Crop-Type Classification on the EuroCropsML Dataset|实践中评估：基于EuroCropsML数据集的少样本时间序列作物类型分类基准测试|Joana Reuss, Jan Macdonald, Simon Becker, Ekaterina Gikalo, Konrad Schultka, Lorenz Richter, Marco Körner|<http://arxiv.org/pdf/2504.11022v2>|建立了首个全面基准，评估了少量样本下作物类型分类的监督学习和半监督学习方法在现实世界条件下的表现。|
|🆕 发布|Beyond the Individual: Introducing Group Intention Forecasting with SHOT Dataset|超越个体：引入基于SHOT数据集的群体意图预测|Ruixu Zhang, Yuran Wang, Xinyi Hu, Chaoyu Mai, Wenxuan Liu, Danni Xu, Xian Zhong, Zheng Wang|<http://arxiv.org/pdf/2509.20715v1>|[代码](https://xinyi-hu.github.io/SHOT_DATASET.); 提出集体意图预测任务及相应数据集，通过个体行为分析预测集体目标的出现。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Quantized Visual Geometry Grounded Transformer|量化视觉几何定位转换器|Weilun Feng, Haotong Qin, Mingqiang Wu, Chuanguang Yang, Yuqi Li, Xiangqi Li, Zhulin An, Libo Huang .etc.|<http://arxiv.org/pdf/2509.21302v1>|[代码](https://github.com/wlfeng0509/QuantVGGT.); 提出首个针对大规模视觉几何模型的量化框架QuantVGGT，通过双平滑细粒度量化和噪声过滤多样采样，...|
|📝 更新|MMSI-Bench: A Benchmark for Multi-Image Spatial Intelligence|多图像空间智能评估基准：MMSI-Bench|Sihan Yang, Runsen Xu, Yiman Xie, Sizhe Yang, Mo Li, Jingli Lin, Chenming Zhu, Xiaochen Chen .etc.|<http://arxiv.org/pdf/2505.23764v2>|提出了MMSI-Bench，一个针对多图像空间智能的VQA基准，评估了多种模型在多图像空间推理上的性...|
|🆕 发布|Instruction-tuned Self-Questioning Framework for Multimodal Reasoning|指令微调的自问框架用于多模态推理|You-Won Jang, Yu-Jung Heo, Jaeseok Kim, Minsu Lee, Du-Seong Chang, Byoung-Tak Zhang|<http://arxiv.org/pdf/2509.21251v1>|提出了一种结合自问自答框架的多模态推理方法，通过生成图像感知的子问题和子答案，提高了多步骤推理的准确...|
|📝 更新|MME-VideoOCR: Evaluating OCR-Based Capabilities of Multimodal LLMs in Video Scenarios|MME-VideoOCR：在视频场景中评估基于OCR的多模态大型语言模型的识别能力|Yang Shi, Huanqian Wang, Wulin Xie, Huanyao Zhang, Lijie Zhao, Yi-Fan Zhang, Xinfeng Li, Chaoyou Fu .etc.|<http://arxiv.org/pdf/2505.21333v2>|提出MME-VideoOCR基准，评估多模态大语言模型在视频场景中的OCR能力，揭示其在视频理解方面...|
|🆕 发布|TABLET: A Large-Scale Dataset for Robust Visual Table Understanding|TABLET：用于稳健视觉表格理解的规模化数据集|Iñigo Alonso, Imanol Miranda, Eneko Agirre, Mirella Lapata|<http://arxiv.org/pdf/2509.21205v1>|提出大规模视觉表格理解数据集TABLET，增强模型处理真实世界表格的鲁棒性。|
|📝 更新|Automated Visual Attention Detection using Mobile Eye Tracking in Behavioral Classroom Studies|基于移动眼动追踪的行为课堂研究中自动化视觉注意力检测|Efe Bozkir, Christian Kosel, Tina Seidel, Enkelejda Kasneci|<http://arxiv.org/pdf/2505.07552v2>|提出了一种自动化处理流程，利用面部识别技术减少眼动追踪中的人工标注需求，有效识别教师关注的学生。|
|🆕 发布|MASt3R-Fusion: Integrating Feed-Forward Visual Model with IMU, GNSS for High-Functionality SLAM|MASt3R-Fusion：将前馈视觉模型与IMU、GNSS集成用于高功能性的SLAM|Yuxuan Zhou, Xingxing Li, Shengyu Li, Zhuohao Yan, Chunxi Xia, Shaoquan Feng|<http://arxiv.org/pdf/2509.20757v1>|[代码](https://github.com/GREAT-WHU/MASt3R-Fusion); 整合视觉模型与IMU、GNSS数据，MASt3R-Fusion提升了SLAM在低纹理环境下的准确性和...|
|📝 更新|Multimodal Iterative RAG for Knowledge-Intensive Visual Question Answering|多模态迭代图推理用于知识密集型视觉问答|Changin Choi, Wonseok Lee, Jungmin Ko, Wonjong Rhee|<http://arxiv.org/pdf/2509.00798v3>|提出了一种迭代的多模态知识增强框架MI-RAG，通过推理指导的多次查询和知识合成，显著提升知识密集型...|
|📝 更新|FastTracker: Real-Time and Accurate Visual Tracking|Visual Tracking 的中文翻译是“视觉跟踪”。因此，  FastTracker: Real-Time and Accurate Visual Tracking 的中文翻译是：   快速跟踪器：实时且精确的视觉跟踪|Hamidreza Hashempoor, Yu Dong Hwang|<http://arxiv.org/pdf/2508.14370v5>|[代码](https://github.com/Hamidreza-Hashempoor/FastTracker); 提出了一种通用的多目标跟踪框架，通过考虑遮挡和道路结构，实现了车辆等不同对象在复杂场景中的实时准确跟...|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Beyond Quantity: Distribution-Aware Labeling for Visual Grounding|超越数量：面向分布感知的视觉定位标注方法|Yichi Zhang, Gongwei Chen, Jun Zhu, Jia Wan, Liqiang Nie|<http://arxiv.org/pdf/2505.24372v2>|提出了一种分布感知的标注框架DAL，通过优化样本质量和覆盖范围，显著提升了视觉定位的性能和泛化能力。|
|🆕 发布|Visual Authority and the Rhetoric of Health Misinformation: A Multimodal Analysis of Social Media Videos|视觉权威与健康错误信息的修辞：社交媒体视频的多模态分析|Mohammad Reza Zarei, Barbara Stead-Coyle, Michael Christensen, Sarah Everts, Majid Komeili|<http://arxiv.org/pdf/2509.20724v1>|分析了社交媒体健康信息视频中的权威信号和叙事技巧，揭示了误导性内容如何构建可信度。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LLaVA-RadZ: Can Multimodal Large Language Models Effectively Tackle Zero-shot Radiology Recognition?|LLaVA-RadZ：多模态大型语言模型能有效应对零样本放射学识别吗？|Bangyan Li, Wenxuan Huang, Zhenkun Gao, Yeqiang Wang, Yunhang Shen, Jingzhong Lin, Ling You, Yuxiang Shen .etc.|<http://arxiv.org/pdf/2503.07487v2>|提出LLaVA-RadZ框架，通过特征对齐和领域知识锚定，提升多模态大语言模型在零样本医学疾病识别的...|
|📝 更新|GeMix: Conditional GAN-Based Mixup for Improved Medical Image Augmentation|《GeMix：基于条件生成对抗网络的混合增强方法用于改进医学图像增强》|Hugo Carlesso, Maria Eliza Patulea, Moncef Garouani, Radu Tudor Ionescu, Josiane Mothe|<http://arxiv.org/pdf/2507.15577v2>|[代码](https://github.com/hugocarlesso/GeMix); 提出了一种基于条件生成对抗网络的图像增强方法GeMix，通过学习得到的标签感知插值，提高了医学图像分...|
|📝 更新|ProstaTD: Bridging Surgical Triplet from Classification to Fully Supervised Detection|ProstaTD：从分类到完全监督检测的手术三元组桥接|Yiliang Chen, Zhixi Li, Cheng Xu, Alex Qinyang Liu, Ruize Cui, Xuemiao Xu, Jeremy Yuen-Chun Teoh, Shengfeng He .etc.|<http://arxiv.org/pdf/2506.01130v2>|提出了ProstaTD数据集，通过精确的时空边界标注，将手术三元组检测从分类推进到全监督检测。|
|🆕 发布|Stratify or Die: Rethinking Data Splits in Image Segmentation|分层或死亡：重新思考图像分割中的数据划分|Naga Venkata Sai Jitin Jami, Thomas Altstidl, Jonas Mueller, Jindong Li, Dario Zanca, Bjoern Eskofier, Heike Leutheuser|<http://arxiv.org/pdf/2509.21056v1>|提出迭代像素分层和新型遗传算法，优化图像分割数据集划分，提高模型泛化能力。|
|📝 更新|CONSIGN: Conformal Segmentation Informed by Spatial Groupings via Decomposition|基于分解的空间分组引导的共形分割：CONSIGN|Bruno Viti, Elias Karabelas, Martin Holler|<http://arxiv.org/pdf/2505.14113v2>|提出了一种结合空间相关性的图像分割不确定性量化方法，通过分解提高预测的准确性和可靠性。|
|📝 更新|SuperPatchMatch: an Algorithm for Robust Correspondences using Superpixel Patches|超像素块匹配算法：一种用于鲁棒对应关系的方法|Rémi Giraud, Vinh-Thong Ta, Aurélie Bugeau, Pierrick Coupé, Nicolas Papadakis|<http://arxiv.org/pdf/1903.07169v2>|提出SuperPatch结构并扩展PatchMatch算法，实现了高效准确的图像分割与标注。|
|🆕 发布|A Real-Time On-Device Defect Detection Framework for Laser Power-Meter Sensors via Unsupervised Learning|基于无监督学习的激光功率计传感器实时在设备上缺陷检测框架|Dongqi Zheng, Wenjin Fu, Guangzong Chen|<http://arxiv.org/pdf/2509.20946v1>|提出了一种无监督学习框架，通过仅使用正常传感器图像训练，实现激光功率计传感器涂层的缺陷检测与分类。|
|🆕 发布|Nuclear Diffusion Models for Low-Rank Background Suppression in Videos|用于视频中低秩背景抑制的核扩散模型|Tristan S. W. Stevens, Oisín Nolan, Jean-Luc Robert, Ruud J. G. van Sloun|<http://arxiv.org/pdf/2509.20886v1>|提出了一种结合低秩时序建模与扩散后验采样的方法，有效提升了视频去噪和清晰度。|
|🆕 发布|Revolutionizing Precise Low Back Pain Diagnosis via Contrastive Learning|通过对比学习革新精确下腰痛诊断|Thanh Binh Le, Hoang Nhat Khang Vo, Tan-Ha Mai, Trong Nhan Phan|<http://arxiv.org/pdf/2509.20813v1>|提出了一种名为LumbarCLIP的多模态框架，通过对比学习将腰椎MRI扫描与放射学描述对齐，实现了...|
|🆕 发布|Dual-supervised Asymmetric Co-training for Semi-supervised Medical Domain Generalization|双监督非对称协同训练用于半监督医疗领域泛化|Jincai Song, Haipeng Chen, Jun Qin, Na Zhao|<http://arxiv.org/pdf/2509.20785v1>|提出了一种针对跨域半监督领域泛化的双监督不对称协同训练框架，有效应对标注数据不足和领域偏移问题。|
|🆕 发布|Recov-Vision: Linking Street View Imagery and Vision-Language Models for Post-Disaster Recovery|灾后恢复的Recov-Vision：将街景图像与视觉-语言模型相结合|Yiming Xiao, Archit Gupta, Miguel Esparza, Yu-Hsuan Ho, Antonia Sebastian, Hannah Weas, Rose Houck, Ali Mostafavi|<http://arxiv.org/pdf/2509.20628v1>|提出FacadeTrack框架，结合街景视频与语言指导，提高灾后建筑评估的准确性和可解释性。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OmniScene: Attention-Augmented Multimodal 4D Scene Understanding for Autonomous Driving|全方位场景：面向自动驾驶的注意力增强多模态4D场景理解|Pei Liu, Hongliang Lu, Haichao Liu, Haipeng Liu, Xin Liu, Ruoyu Yao, Shengbo Eben Li, Jun Ma|<http://arxiv.org/pdf/2509.19973v2>|提出了一种模仿人类视觉的OmniScene框架，通过融合多模态信息实现了全面的4D场景理解，提升了自...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RIS-LAD: A Benchmark and Model for Referring Low-Altitude Drone Image Segmentation|RIS-LAD：面向低空无人机图像分割的基准与模型|Kai Ye, YingShi Luan, Zhudi Chen, Guangyue Meng, Pingyang Dai, Liujuan Cao|<http://arxiv.org/pdf/2507.20920v2>|[代码](https://github.com/AHideoKuzeA/RIS-LAD); 提出了首个针对低空无人机场景的细粒度图像分割基准RIS-LAD，并设计了一种适应复杂场景的语义感知网...|
|🆕 发布|DENet: Dual-Path Edge Network with Global-Local Attention for Infrared Small Target Detection|DENet：基于全局-局部注意力机制的双路径边缘网络用于红外小目标检测|Jiayi Zuo, Songwei Pei, Qian Li|<http://arxiv.org/pdf/2509.20701v1>|提出了一种双路径边缘网络，通过全局-局部注意力机制分离边缘增强和语义建模，有效提升了红外小目标检测的...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Seeing Through Words, Speaking Through Pixels: Deep Representational Alignment Between Vision and Language Models|“透过文字看世界，通过像素说话：视觉与语言模型之间的深度表征对齐”|Zoe Wanying He, Sean Trott, Meenakshi Khosla|<http://arxiv.org/pdf/2509.20751v1>|探究视觉与语言模型间的深层表征对齐，发现共享语义编码与人类判断一致。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Equi-RO: A 4D mmWave Radar Odometry via Equivariant Networks|等变RO：基于等变网络的四维毫米波雷达里程计|Zeyu Han, Shuocheng Yang, Minghan Zhu, Fang Zhang, Shaobing Xu, Maani Ghaffari, Jianqiang Wang|<http://arxiv.org/pdf/2509.20674v1>|提出了一种基于等变网络框架的4D毫米波雷达测距方法，实现了全天候下的高精度定位。|
|📝 更新|HUNT: High-Speed UAV Navigation and Tracking in Unstructured Environments via Instantaneous Relative Frames|HUNT：通过瞬时相对帧在非结构化环境中实现的高速无人机导航与跟踪|Alessandro Saviolo, Jeffrey Mao, Giuseppe Loianno|<http://arxiv.org/pdf/2509.19452v2>|提出了一种统一相对定位框架HUNT，实现了无全局定位下的高速无人机导航和目标跟踪。|
|🆕 发布|Plant identification in an open-world (LifeCLEF 2016)|开放世界中的植物识别（LifeCLEF 2016）|Herve Goeau, Pierre Bonnet, Alexis Joly|<http://arxiv.org/pdf/2509.20870v1>|提出开放集识别方法应对未知类别挑战，有效自动排除错误分类。|

