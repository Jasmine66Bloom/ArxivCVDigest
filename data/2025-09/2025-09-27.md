## [UPDATED!] **2025-09-27** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Evaluating point-light biological motion in multimodal large language models|评估多模态大型语言模型中的点光生物运动|Akila Kadambi, Marco Iacoboni, Lisa Aziz-Zadeh, Srini Narayanan|<http://arxiv.org/pdf/2509.23517v1>|首次提出ActPLD基准，评估大型多模态语言模型对人类动作的理解能力。|
|📝 更新|Generative Video Semantic Communication via Multimodal Semantic Fusion with Large Model|通过大型模型的多模态语义融合实现生成视频语义通信|Hang Yin, Li Qiao, Yu Ma, Shuo Sun, Kan Li, Zhen Gao, Dusit Niyato|<http://arxiv.org/pdf/2502.13838v2>|提出了一种多模态语义融合的生成视频语义通信框架，在极低带宽下实现高质量视频重建。|
|📝 更新|Reconstruct Anything Model: a lightweight foundation model for computational imaging|重建任意模型：一种用于计算成像的轻量级基础模型|Matthieu Terris, Samuel Hurault, Maxime Song, Julian Tachella|<http://arxiv.org/pdf/2503.08915v3>|[代码](https://github.com/matthieutrs/ram.); 提出了一种轻量级基础模型，无需迭代或特定训练即可解决多种成像逆问题，实现卓越性能。|
|🆕 发布|Planning with Unified Multimodal Models|与统一多模态模型进行规划|Yihao Sun, Zhilong Zhang, Yang Yu, Pierre-Luc Bacon|<http://arxiv.org/pdf/2509.23014v1>|提出Uni-Plan框架，利用统一多模态模型提升决策能力，通过自判别过滤减少预测误差。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VPNeXt -- Rethinking Dense Decoding for Plain Vision Transformer|VPNeXt -- 重新思考稠密解码在普通视觉变换器中的应用|Xikai Tang, Ye Huang, Guangqiang Yin, Lixin Duan|<http://arxiv.org/pdf/2502.16654v3>|VPNeXt通过引入Visual Context Replay和ViTUp模块，为Plain Vis...|
|🆕 发布|Patch Rebirth: Toward Fast and Transferable Model Inversion of Vision Transformers|"补丁重生：面向快速且迁移性强的视觉变换器模型反转"|Seongsoo Heo, Dong-Wan Choi|<http://arxiv.org/pdf/2509.23235v1>|提出Patch Rebirth Inversion方法，通过逐步释放关键区块，加速视觉变换器模型的逆...|
|🆕 发布|Deep Learning for Oral Health: Benchmarking ViT, DeiT, BEiT, ConvNeXt, and Swin Transformer|深度学习在口腔健康中的应用：ViT、DeiT、BEiT、ConvNeXt和Swin Transformer的比较研究|Ajo Babu George, Sadhvik Bathini, Niranjana S R|<http://arxiv.org/pdf/2509.23100v1>|系统评估了五种先进变换器架构在口腔疾病分类中的表现，发现ConvNeXt等模型在处理数据不平衡问题上...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned|训练视觉-语言处理奖励模型以实现多模态推理测试时的缩放：关键见解与经验教训|Brandon Ong, Tej Deep Pala, Vernon Toh, William Chandra Tjhi, Soujanya Poria|<http://arxiv.org/pdf/2509.23250v1>|提出了一种改进视觉语言模型推理可靠性的方法，通过多样化数据合成和感知级监督增强推理指导。|
|📝 更新|ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding|ViSpec：利用视觉感知的投机解码加速视觉-语言模型|Jialiang Kang, Han Shu, Wenshuo Li, Yingjie Zhai, Xinghao Chen|<http://arxiv.org/pdf/2509.15235v4>|[代码](https://github.com/KangJialiang/ViSpec.); 提出ViSpec框架，通过压缩图像信息和增强文本特征，实现了首个显著的视觉语言模型推理加速。|
|🆕 发布|Streamline pathology foundation model by cross-magnification distillation|通过跨倍率蒸馏精简病理学基础模型|Ziyu Su, Abdul Rehman Akbar, Usama Sajjad, Anil V. Parwani, Muhammad Khalid Khan Niazi|<http://arxiv.org/pdf/2509.23097v1>|提出了一种通过跨倍数蒸馏简化病理基础模型的方法，实现了30倍处理加速，接近大型基础模型的诊断准确性。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UniPose: Unified Cross-modality Pose Prior Propagation towards RGB-D data for Weakly Supervised 3D Human Pose Estimation|统一跨模态姿态先验传播方法面向RGB-D数据用于弱监督三维人体姿态估计|Jinghong Zheng, Changlong Jiang, Jiaqi Li, Haohong Kuang, Hang Xu, Tingbing Yan|<http://arxiv.org/pdf/2509.23376v1>|UniPose通过跨模态姿态先验传播，将2D姿态估计迁移至3D领域，无需3D标注数据，实现弱监督3D...|
|🆕 发布|C3-OWD: A Curriculum Cross-modal Contrastive Learning Framework for Open-World Detection|C3-OWD：面向开放世界检测的 curriculum 跨模态对比学习框架|Siheng Wang, Zhengdao Li, Yanshu Li, Canran Xiao, Haibo Zhan, Zhengtao Yao, Xuzhi Zhang, Jiale Kang .etc.|<http://arxiv.org/pdf/2509.23316v1>|[代码](https://github.com/justin-herry/C3-OWD.git.); 提出了一种统一增强鲁棒性和泛化能力的跨模态对比学习框架C3-OWD，通过分阶段训练和EMA机制有效解...|
|🆕 发布|Increasing the Diversity in RGB-to-Thermal Image Translation for Automotive Applications|提高车载应用中RGB到热成像转换的多样性|Kaili Wang, Leonardo Ravaglia, Roberto Longo, Lore Goetschalckx, David Van Hamme, Julie Moeyersoms, Ben Stoffelen, Tom De Schepper|<http://arxiv.org/pdf/2509.23243v1>|提出了一种多模态翻译框架及组件自适应实例归一化方法，实现了更真实和多样的RGB到热成像转换。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unsupervised Online 3D Instance Segmentation with Synthetic Sequences and Dynamic Loss|无监督在线三维实例分割：结合合成序列与动态损失函数|Yifan Zhang, Wei Zhang, Chuangxin He, Zhonghua Miao, Junhui Hou|<http://arxiv.org/pdf/2509.23194v1>|[代码](https://github.com/Eaphan/SFT3D.); 提出了一种利用合成序列和动态损失函数的无监督在线3D实例分割方法，增强训练多样性并提高时间关联性。|
|📝 更新|CoT-RVS: Zero-Shot Chain-of-Thought Reasoning Segmentation for Videos|CoT-RVS：面向视频的零样本链式思维推理分割|Shiu-hong Kao, Yu-Wing Tai, Chi-Keung Tang|<http://arxiv.org/pdf/2505.18561v3>|提出CoT-RVS框架，利用零样本Chain-of-Thought能力处理复杂视频分割任务，无需训练...|
|📝 更新|Advancing Marine Research: UWSAM Framework and UIIS10K Dataset for Precise Underwater Instance Segmentation|推进海洋研究：UWSAM框架与UIIS10K数据集用于精确水下实例分割|Hua Li, Shijie Lian, Zhiyuan Li, Runmin Cong, Chongyi Li, Laurence T. Yang, Weidong Zhang, Sam Kwong|<http://arxiv.org/pdf/2505.15581v4>|[代码](https://github.com/LiamLian0727/UIIS10K.); 提出UIIS10K数据集和UWSAM模型，通过知识蒸馏和自动提示生成，提升水下目标实例分割性能。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FMC-DETR: Frequency-Decoupled Multi-Domain Coordination for Aerial-View Object Detection|频率解耦的多域协同用于空视图目标检测：FMC-DETR|Ben Liang, Yuan Liu, Bingwen Qiu, Yihong Wang, Xiubao Sui, Qian Chen|<http://arxiv.org/pdf/2509.23056v1>|[代码](https://github.com/bloomingvision/FMC-DETR.); 提出了一种基于频率解耦的多域协同框架FMC-DETR，有效提升了高分辨率航拍图像中微小目标的检测性能...|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RestoRect: Degraded Image Restoration via Latent Rectified Flow & Feature Distillation|RestoRect：通过潜在修正流与特征蒸馏进行退化图像恢复|Shourya Verma, Mengbo Wang, Nadia Atallah Lanman, Ananth Grama|<http://arxiv.org/pdf/2509.23480v1>|提出RestoRect方法，通过生成式特征蒸馏和物理基分解，平衡图像恢复的质量与速度。|
|🆕 发布|Generative Modeling of Shape-Dependent Self-Contact Human Poses|形状依赖的自接触人体姿态生成建模|Takehiko Ohkawa, Jihyun Lee, Shunsuke Saito, Jason Saragih, Fabian Prado, Yichen Xu, Shoou-I Yu, Ryosuke Furuta .etc.|<http://arxiv.org/pdf/2509.23393v1>|引入首个精确身体形状注册的广泛自接触姿态数据集，并提出基于身体形状参数的条件生成模型以改进单视角姿态...|
|🆕 发布|GRAPE: Let GPRO Supervise Query Rewriting by Ranking for Retrieval|葡萄：利用GPRO通过排序对检索中的查询重写进行监督|Zhaohua Zhang, Jianhuan Zhuo, Muxi Chen, Chenchen Zhao, Wenyu Jiang, Tianwen Jiang, Mingyang Chen, Yu Tang .etc.|<http://arxiv.org/pdf/2509.23370v1>|[代码](https://github.com/Chinese0123456/GRAPE.git); 提出GRAPE方法，利用排名信号优化大型语言模型进行查询重写，有效提升多语言、长文本和跨模态检索性能...|
|🆕 发布|DiffTex: Differentiable Texturing for Architectural Proxy Models|DiffTex: 建筑代理模型的可微分纹理映射|Weidan Xiong, Yongli Wu, Bochuan Zeng, Jianwei Guo, Dani Lischinski, Daniel Cohen-Or, Hui Huang|<http://arxiv.org/pdf/2509.23336v1>|提出了一种自动生成建筑代理模型纹理映射的方法，通过不同iable渲染优化，实现了纹理的高保真度和结构...|
|🆕 发布|Targeted perturbations reveal brain-like local coding axes in robustified, but not standard, ANN-based brain models|目标扰动揭示了在强化而非标准的人工神经网络基础上脑模型中的类脑局部编码轴|Nikolas McNeal, N. Apurva Ratan Murty|<http://arxiv.org/pdf/2509.23333v1>|使用对抗扰动揭示了稳健化ANN脑模型中类似人脑的局部编码轴，而标准模型中未发现。|
|📝 更新|QVGen: Pushing the Limit of Quantized Video Generative Models|QVGen：推动量化视频生成模型极限|Yushi Huang, Ruihao Gong, Jing Liu, Yifu Ding, Chengtao Lv, Haotong Qin, Jun Zhang|<http://arxiv.org/pdf/2505.11497v4>|提出QVGen框架，通过量化感知训练和辅助模块，实现了在极低比特量化下视频生成模型的高性能和推理效率...|
|📝 更新|MagicTryOn: Harnessing Diffusion Transformer for Garment-Preserving Video Virtual Try-on|《MagicTryOn：利用扩散变换器实现服装保留的视频虚拟试穿》|Guangyuan Li, Siming Zheng, Hao Zhang, Jinwei Chen, Junsheng Luan, Binkai Ou, Lei Zhao, Bo Li .etc.|<http://arxiv.org/pdf/2505.21325v3>|提出了一种基于扩散变换器的MagicTryOn框架，通过细化服装细节和增强时空一致性，显著提升了视频...|
|📝 更新|Graph Alignment via Dual-Pass Spectral Encoding and Latent Space Communication|通过双通道光谱编码和潜在空间通信的图对齐|Maysam Behmanesh, Erkan Turan, Maks Ovsjanikov|<http://arxiv.org/pdf/2509.09597v2>|提出了一种双通道频谱编码和几何一致性的图对齐框架，有效提升了节点区分度和跨图几何关系一致性。|
|🆕 发布|CoPatch: Zero-Shot Referring Image Segmentation by Leveraging Untapped Spatial Knowledge in CLIP|"CoPatch：通过利用CLIP中未开发的空间知识实现零样本指引用图分割"|Na Min An, Inha Kang, Minhyun Lee, Hyunjung Shim|<http://arxiv.org/pdf/2509.23098v1>|提出CoPatch框架，通过挖掘CLIP模型中的空间知识，实现了零样本指引用图分割的显著性能提升。|
|🆕 发布|Follow-Your-Preference: Towards Preference-Aligned Image Inpainting|遵循你的偏好：迈向偏好对齐的图像修复|Yutao Shen, Junkun Yuan, Toru Aonishi, Hideki Nakayama, Yue Ma|<http://arxiv.org/pdf/2509.23082v1>|[代码](https://github.com/shenytzzz/Follow-Your-Preference.); 探究偏好对齐的图像修复，通过优化偏好训练显著提升模型性能。|
|📝 更新|Vid2World: Crafting Video Diffusion Models to Interactive World Models|Vid2World：构建视频扩散模型以打造交互式世界模型|Siqiao Huang, Jialong Wu, Qixing Zhou, Shangchen Miao, Mingsheng Long|<http://arxiv.org/pdf/2505.14357v2>|将预训练的视频扩散模型转化为高质互动世界模型，提升复杂环境下的决策效率。|
|🆕 发布|Copyright Infringement Detection in Text-to-Image Diffusion Models via Differential Privacy|通过差分隐私在文本到图像扩散模型中检测版权侵犯|Xiafeng Man, Zhipeng Wei, Jingjing Chen|<http://arxiv.org/pdf/2509.23022v1>|提出基于差分隐私的检测框架D-Plus-Minus，有效识别文本到图像生成模型中的版权侵犯内容。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|No Concept Left Behind: Test-Time Optimization for Compositional Text-to-Image Generation|“不让任何概念落后：组合文本到图像生成的测试时优化”|Mohammad Hossein Sameti, Amir M. Mansourian, Arash Marioriyad, Soheil Fadaee Oshyani, Mohammad Hossein Rohban, Mahdieh Soleymani Baghshah|<http://arxiv.org/pdf/2509.23457v1>|[代码](https://github.com/AmirMansurian/NoConceptLeftBehind); 提出了一种细粒度的测试时优化框架，通过分解语义概念并迭代优化提示，提高了文本到图像生成的完整性。|
|📝 更新|ODE-GS: Latent ODEs for Dynamic Scene Extrapolation with 3D Gaussian Splatting|ODE-GS：基于三维高斯散点的动态场景外推隐式常微分方程模型|Daniel Wang, Patrick Rim, Tian Tian, Alex Wong, Ganesh Sundaramoorthi|<http://arxiv.org/pdf/2506.05480v2>|将3D场景动态预测与连续时间模型结合，ODE-GS通过神经网络实现了未来场景的精准 extrapol...|
|🆕 发布|FoR-SALE: Frame of Reference-guided Spatial Adjustment in LLM-based Diffusion Editing|基于参考坐标系引导的空间调整在LLM驱动的扩散编辑中的应用|Tanawan Premsri, Parisa Kordjamshidi|<http://arxiv.org/pdf/2509.23452v1>|提出FoR-SALE方法，通过帧参考调整，提升文本到图像生成中空间描述的准确性。|
|📝 更新|CGI: Identifying Conditional Generative Models with Example Images|CGI：通过示例图像识别条件生成模型|Zhi Zhou, Hao-Zhe Tan, Peng-Xiao Song, Lan-Zhe Guo|<http://arxiv.org/pdf/2501.13991v3>|提出了一种基于示例图像的生成模型识别方法，有效帮助用户快速找到最合适的模型。|
|🆕 发布|Dynamic-TreeRPO: Breaking the Independent Trajectory Bottleneck with Structured Sampling|动态树状RPO：通过结构化采样打破独立轨迹瓶颈|Xiaolong Fu, Lichen Ma, Zipeng Guo, Gaojing Zhou, Chongxiao Wang, ShiPing Dong, Shizhe Zhou, Shizhe Zhou .etc.|<http://arxiv.org/pdf/2509.23352v1>|提出了一种树结构动态采样方法Dynamic-TreeRPO，通过共享路径和动态调整探索策略，有效提升...|
|🆕 发布|Seeing the Unseen in Low-light Spike Streams|在低光照尖峰流中看到不可见之处|Liwen Hu, Yang Li, Mianzhi Liu, Yijia Guo, Shenghao Xie, Ziluo Ding, Tiejun Huang, Lei Ma|<http://arxiv.org/pdf/2509.23304v1>|提出了一种基于扩散模型的 spike camera 低光照场景重建方法，有效利用生成先验补充纹理信息...|
|🆕 发布|SynDoc: A Hybrid Discriminative-Generative Framework for Enhancing Synthetic Domain-Adaptive Document Key Information Extraction|SynDoc：一种用于增强合成域自适应文档关键信息提取的混合判别-生成框架|Yihao Ding, Soyeon Caren Han, Yanbei Jiang, Yan Li, Zechuan Li, Yifan Peng|<http://arxiv.org/pdf/2509.23273v1>|提出SynDoc框架，融合判别与生成模型，提升合成文档关键信息提取的准确性和效率。|
|📝 更新|ReDDiT: Rehashing Noise for Discrete Visual Generation|《ReDDiT：重新哈希噪声以实现离散视觉生成》|Tianren Ma, Xiaosong Zhang, Boyu Yang, Junlan Feng, Qixiang Ye|<http://arxiv.org/pdf/2505.19656v3>|提出了一种重新哈希噪声的方法ReDDiT，通过扩展吸收状态增强了离散扩散模型的表达能力，显著提升了生...|
|🆕 发布|OracleGS: Grounding Generative Priors for Sparse-View Gaussian Splatting|OracleGS：为稀疏视图高斯散布定位生成先验|Atakan Topaloglu, Kunyi Li, Michael Niemeyer, Nassir Navab, A. Murat Tekalp, Federico Tombari|<http://arxiv.org/pdf/2509.23258v1>|提出OracleGS框架，融合生成模型的完整性与回归模型的准确性，通过3D感知验证优化稀疏视图重建。|
|📝 更新|UniUGG: Unified 3D Understanding and Generation via Geometric-Semantic Encoding|统一三维理解与生成：通过几何-语义编码实现|Yueming Xu, Jiahui Zhang, Ze Huang, Yurui Chen, Yanpeng Zhou, Zhenyu Chen, Yu-Jie Yuan, Pengxiang Xia .etc.|<http://arxiv.org/pdf/2508.11952v2>|首次提出统一框架UniUGG，结合几何与语义编码，实现3D理解与生成。|
|📝 更新|Mod-Adapter: Tuning-Free and Versatile Multi-concept Personalization via Modulation Adapter|调制适配器：无需调优的通用多概念个性化方法|Weizhi Zhong, Huan Yang, Zheng Liu, Huiguo He, Zijian He, Xuesong Niu, Di Zhang, Guanbin Li|<http://arxiv.org/pdf/2505.18612v3>|提出了一种无需测试时微调的多概念个性化方法Mod-Adapter，有效定制对象和抽象概念。|
|📝 更新|OmniGen2: Exploration to Advanced Multimodal Generation|OmniGen2：探索先进的多模态生成|Chenyuan Wu, Pengfei Zheng, Ruiran Yan, Shitao Xiao, Xin Luo, Yueze Wang, Wanli Li, Xiyan Jiang .etc.|<http://arxiv.org/pdf/2506.18871v3>|[代码](https://github.com/VectorSpaceLab/OmniGen2); OmniGen2实现了统一的多模态生成任务处理，通过独立的解码路径和参数，提升了生成质量和效率。|
|📝 更新|In-2-4D: Inbetweening from Two Single-View Images to 4D Generation|从两个单视角图像到4D生成的中间帧生成方法：In-2-4D|Sauradip Nag, Daniel Cohen-Or, Hao Zhang, Ali Mahdavi-Amiri|<http://arxiv.org/pdf/2504.08366v3>|提出了一种4D生成方法In-2-4D，通过两张单视角图片生成物体运动过程，实现精确运动控制并生成平滑...|
|🆕 发布|Earth-Agent: Unlocking the Full Landscape of Earth Observation with Agents|地球代理：利用代理解锁地球观测的全景图|Peilin Feng, Zhutao Lv, Junyan Ye, Xiaolei Wang, Xinjie Huo, Jinhua Yu, Wanghan Xu, Wenlong Zhang .etc.|<http://arxiv.org/pdf/2509.23141v1>|引入Earth-Agent框架，融合RGB与光谱数据，实现跨模态、多步骤、定量时空推理，推动地球观测...|
|🆕 发布|Stochastic Interpolants via Conditional Dependent Coupling|通过条件依赖耦合的随机插值|Chenrui Ma, Xi Xiao, Tianyang Wang, Xiao Wang, Yanning Shen|<http://arxiv.org/pdf/2509.23122v1>|提出了一种多阶段生成框架，通过条件依赖耦合策略实现高保真度和效率的图像生成。|
|📝 更新|From Specificity to Generality: Revisiting Generalizable Artifacts in Detecting Face Deepfakes|从特殊性到普遍性：重新审视检测人脸深度伪造中的通用伪影|Long Ma, Zhiyuan Yan, Jin Xu, Yize Chen, Qinglang Guo, Zhen Bi, Yong Liao, Hui Lin|<http://arxiv.org/pdf/2504.04827v2>|提出了一种通用的人脸伪造检测框架，通过识别两种普遍伪造痕迹显著提高了检测效果。|
|🆕 发布|Activation Matching for Explanation Generation|激活匹配用于解释生成|Pirzada Suhail, Aditya Anand, Amit Sethi|<http://arxiv.org/pdf/2509.23051v1>|提出了一种基于激活匹配的生成简洁、忠实解释的方法，用于解释预训练分类器在图像上的决策过程。|
|🆕 发布|Geometry-Aware Losses for Structure-Preserving Text-to-Sign Language Generation|保持结构一致性的几何感知损失函数在文本到手语生成中的应用|Zetian Wu, Tianshuo Zhou, Stefan Lee, Liang Huang|<http://arxiv.org/pdf/2509.23011v1>|引入几何约束以生成符合人体解剖结构和运动模式的文本到手语视频转换方法，显著提升了动作的自然度和准确性...|
|🆕 发布|ARSS: Taming Decoder-only Autoregressive Visual Generation for View Synthesis From Single View|ARSS：驯服仅解码器自回归视觉生成以实现单视角视图合成|Wenbin Teng, Gonglin Chen, Haiwei Chen, Yajie Zhao|<http://arxiv.org/pdf/2509.23008v1>|提出了一种基于自回归模型的ARSS框架，通过预定义相机轨迹从单视图生成高质量的新视角图像。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Action2Dialogue: Generating Character-Centric Narratives from Scene-Level Prompts|《Action2Dialogue：从场景级提示生成以角色为中心的叙事》|Taewon Kang, Ming C. Lin|<http://arxiv.org/pdf/2505.16819v3>|提出了一种将动作提示转化为具有情感和角色一致性的视觉和听觉叙事对话的模块化流程。|
|📝 更新|Text2Story: Advancing Video Storytelling with Text Guidance|《文本引导下的视频故事讲述进展：Text2Story》|Taewon Kang, Divya Kothandaraman, Ming C. Lin|<http://arxiv.org/pdf/2503.06310v3>|提出了一种基于文本指导的动态混合策略，实现了长视频序列的连贯故事讲述。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance|《WorldForge：通过无需训练的引导在视频扩散模型中解锁涌现的3D/4D生成》|Chenxi Song, Yanming Yang, Tong Zhao, Ruibo Li, Chi Zhang|<http://arxiv.org/pdf/2509.15130v2>|WorldForge通过无需训练的引导策略，实现了对视频扩散模型中运动轨迹的精细控制和高品质内容生成...|
|🆕 发布|Seeing Through the Blur: Unlocking Defocus Maps for Deepfake Detection|透过模糊：解锁深度伪造检测中的散焦图|Minsun Jeon, Simon S. Woo|<http://arxiv.org/pdf/2509.23289v1>|[代码](https://github.com/irissun9602/Defocus-Deepfake-Detection); 提出了一种利用图像中的散焦模糊作为深度伪造检测的物理可解释性特征，有效区分真实与合成视觉内容。|
|🆕 发布|Vid-Freeze: Protecting Images from Malicious Image-to-Video Generation via Temporal Freezing|Vid-Freeze：通过时间冻结保护图像免受恶意图像到视频生成的攻击|Rohit Chowdhury, Aniruddha Bala, Rohan Jaiswal, Siddharth Roheda|<http://arxiv.org/pdf/2509.23279v1>|提出Vid-Freeze方法，通过对抗性扰动破坏图像到视频生成模型中的运动合成，有效阻止恶意内容创建...|
|📝 更新|Training-Free Diffusion Framework for Stylized Image Generation with Identity Preservation|无需训练的保持身份的图像风格化生成扩散框架|Mohammad Ali Rezaei, Helia Hajikazem, Saeed Khanehgir, Mahdi Javanmardi|<http://arxiv.org/pdf/2506.06802v2>|提出了一种无需训练的扩散框架，通过“马赛克恢复内容图像”技术和内容一致性损失，实现了在风格化图像生成...|
|🆕 发布|Sparse2Dense: A Keypoint-driven Generative Framework for Human Video Compression and Vertex Prediction|稀疏转稠密：一种基于关键点驱动的人体视频压缩与顶点预测生成框架|Bolin Chen, Ru-Ling Liao, Yan Ye, Jie Chen, Shanzhi Yin, Xinrui Ju, Shiqi Wang, Yibo Fan|<http://arxiv.org/pdf/2509.23169v1>|提出Sparse2Dense框架，通过稀疏3D关键点实现低比特率视频压缩和精确顶点预测。|
|📝 更新|HiMat: DiT-based Ultra-High Resolution SVBRDF Generation|HiMat：基于DiT的超高分辨率SVBRDF生成|Zixiong Wang, Jian Yang, Yiwei Hu, Milos Hasan, Beibei Wang|<http://arxiv.org/pdf/2508.07011v3>|HiMat通过在压缩空间中生成并采用轻量级模块实现4K SVBRDF的高效、一致和多样化生成。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Orientation-anchored Hyper-Gaussian for 4D Reconstruction from Casual Videos|基于方向锚定的超高斯分布模型用于从日常视频中实现四维重建|Junyi Wu, Jiachen Tao, Haoxuan Wang, Gaowen Liu, Ramana Rao Kompella, Yan Yan|<http://arxiv.org/pdf/2509.23492v1>|提出了一种基于场景方向的高维表示方法OriGS，实现了从日常视频中进行高质量4D重建。|
|📝 更新|Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey|《前馈三维重建与视图合成进展综述》|Jiahui Zhang, Yuelei Li, Anpei Chen, Muyu Xu, Kunhao Liu, Jianyuan Wang, Xiao-Xiao Long, Hanxue Liang .etc.|<http://arxiv.org/pdf/2507.14501v3>|综述了基于深度学习的快速3D重建与视图合成技术，推动了计算机视觉领域的发展。|
|🆕 发布|FM-SIREN & FM-FINER: Nyquist-Informed Frequency Multiplier for Implicit Neural Representation with Periodic Activation|FM-SIREN与FM-FINER：基于奈奎斯特定理的频率倍增器，用于具有周期性激活的隐式神经表示|Mohammed Alsakabi, Wael Mobeirek, John M. Dolan, Ozan K. Tonguz|<http://arxiv.org/pdf/2509.23438v1>|通过为每个神经元分配特定频率乘数，FM-SIREN和FM-FINER减少了特征冗余，提升了隐式神经表...|
|🆕 发布|Perceptual Influence: Improving the Perceptual Loss Design for Low-Dose CT Enhancement|感知影响：改进低剂量CT增强的感知损失设计|Gabriel A. Viana, Luis F. Alves Pereira, Tsang Ing Ren, George D. C. Cavalcanti, Jan Sijbers|<http://arxiv.org/pdf/2509.23025v1>|[代码](https://github.com/vngabriel/perceptual-influence.); 提出感知影响力指标，系统优化感知损失设计，显著提升低剂量CT图像质量和细节保留。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|3DPCNet: Pose Canonicalization for Robust Viewpoint-Invariant 3D Kinematic Analysis from Monocular RGB cameras|单目RGB相机下基于姿态规范化的鲁棒视点不变三维运动分析：3DPCNet|Tharindu Ekanayake, Constantino Álvarez Casado, Miguel Bordallo López|<http://arxiv.org/pdf/2509.23455v1>|提出了一种3DPCNet方法，通过将3D姿态转换到统一标准坐标系，实现了视点不变的三维运动分析。|
|📝 更新|Light of Normals: Unified Feature Representation for Universal Photometric Stereo|“法线之光：用于通用光度立体成像的统一特征表示”|Hong Li, Houyuan Chen, Chongjie Ye, Zhaoxi Chen, Bohan Li, Shaocong Xu, Xianda Guo, Xuhui Liu .etc.|<http://arxiv.org/pdf/2506.18882v3>|提出了一种统一特征表示方法LINO UniPS，通过光注册令牌和交错注意力块分离光照与法线信息，并利...|
|🆕 发布|GeLoc3r: Enhancing Relative Camera Pose Regression with Geometric Consistency Regularization|几何一致性正则化增强相对相机位姿回归：GeLoc3r|Jingxing Li, Yongjae Lee, Deliang Fan|<http://arxiv.org/pdf/2509.23038v1>|GeLoc3r通过训练时引入几何一致性正则化，提升了相对相机位姿估计的回归精度，同时保持了快速推理速...|


## 时序视觉分析 (Temporal Visual Analysis)


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Imaging-Based Mortality Prediction in Patients with Systemic Sclerosis|基于成像的系统性硬化病患者死亡率预测|Alec K. Peltekian, Karolina Senkow, Gorkem Durak, Kevin M. Grudzinski, Bradford C. Bemiss, Jane E. Dematte, Carrie Richardson, Nikolay S. Markov .etc.|<http://arxiv.org/pdf/2509.23530v1>|利用放射组学和深度学习，本研究提出了一种预测系统性硬化病肺部并发症相关死亡的大规模胸部CT分析框架。|
|🆕 发布|Leave No Observation Behind: Real-time Correction for VLA Action Chunks|《不遗漏任何观测：VLA动作片段的实时校正》|Kohei Sendai, Maxime Alvarez, Tatsuya Matsushima, Yutaka Matsuo, Yusuke Iwasawa|<http://arxiv.org/pdf/2509.23224v1>|提出异步动作块修正方法A2C2，提高VLA模型在实时控制中的响应性和鲁棒性。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SPIKE-RL: Video-LLMs meet Bayesian Surprise|SPIKE-RL: 视频大模型遇见贝叶斯惊奇|Sahithya Ravi, Aditya Chinchure, Raymond T. Ng, Leonid Sigal, Vered Shwartz|<http://arxiv.org/pdf/2509.23433v1>|提出SPIKE-RL框架，通过量化视频中的惊喜时刻并优化模型信念，提高视频理解性能。|
|📝 更新|Do We Need Large VLMs for Spotting Soccer Actions?|我们是否需要大型语言模型来检测足球动作？|Ritabrata Chakraborty, Rajatsubhra Chakraborty, Avijit Dasgupta, Sandeep Chaurasia|<http://arxiv.org/pdf/2506.17144v2>|利用大型语言模型处理专家解说文本，实现高效准确的足球动作识别。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LiDAR-based Human Activity Recognition through Laplacian Spectral Analysis|基于拉普拉斯谱分析的LiDAR人体活动识别|Sasan Sharifipour, Constantino Álvarez Casado, Le Nguyen, Tharindu Ekanayake, Manuel Lage Cañellas, Nhi Nguyen, Miguel Bordallo López|<http://arxiv.org/pdf/2509.23255v1>|提出了一种基于LiDAR点云和图谱分析的 HAR 方法，实现了高效准确的人体活动识别。|
|🆕 发布|MMeViT: Multi-Modal ensemble ViT for Post-Stroke Rehabilitation Action Recognition|多模态集成Vision Transformer用于脑卒中后康复动作识别|Ye-eun Kim, Suhyeon Lim, Andrew J. Choi|<http://arxiv.org/pdf/2509.23044v1>|[代码](https://github.com/ye-Kim/MMeViT.); 提出了一种多模态深度学习模型，用于识别中风患者日常生活中的动作，提高远程康复监测系统的准确性。|
|🆕 发布|Disentangling Static and Dynamic Information for Reducing Static Bias in Action Recognition|解耦动作识别中的静态和动态信息以减少静态偏差|Masato Kobayashi, Ning Ding, Toru Tamaki|<http://arxiv.org/pdf/2509.23009v1>|提出了一种分离动态和静态信息的方法，有效减少动作识别中的静态偏差。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TRAX: TRacking Axles for Accurate Axle Count Estimation|TRAX：精确轴数估计的轴跟踪方法|Avinash Rai, Sandeep Jana, Vishal Vijay|<http://arxiv.org/pdf/2509.23171v1>|提出了一种端到端的视频处理方法TRAX，通过跟踪轮胎和车轴特征显著提高了复杂交通场景下车轴计数准确性...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 跨模态一致性学习 (Cross-modal Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Graph Your Own Prompt|绘制你自己的提示语|Xi Ding, Lei Wang, Piotr Koniusz, Yongsheng Gao|<http://arxiv.org/pdf/2509.23373v1>|[代码](https://github.com/Darcyddx/graph-prompt); 引入图一致性正则化方法，通过模型自身输出优化特征表示，增强语义结构和泛化能力。|


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CCD: Mitigating Hallucinations in Radiology MLLMs via Clinical Contrastive Decoding|CCD：通过临床对比解码减轻放射学大型语言模型中的幻觉现象|Xi Zhang, Zaiqiao Meng, Jake Lever, Edmond S. L. Ho|<http://arxiv.org/pdf/2509.23379v1>|提出了一种无训练、无检索的推理框架CCD，通过整合专业模型信号减少医学语言模型中的幻觉现象，显著提升...|
|📝 更新|Boosting Open Set Recognition Performance through Modulated Representation Learning|通过调制表征学习提升开放集识别性能|Amit Kumar Kundu, Vaishnavi S Patil, Joseph Jaja|<http://arxiv.org/pdf/2505.18137v2>|通过温度调节机制优化表示学习，提升开放集识别性能并无需额外计算开销。|
|🆕 发布|UniPrototype: Humn-Robot Skill Learning with Uniform Prototypes|统一原型：基于统一原型的机器人技能学习与人交互|Xiao Hu, Qi Yin, Yangming Shi, Yang Ye|<http://arxiv.org/pdf/2509.23021v1>|提出UniPrototype框架，通过共享运动原语实现从人类到机器人技能的有效迁移，提升学习效率和任...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhancing Polyp Segmentation via Encoder Attention and Dynamic Kernel Update|通过编码器注意力和动态核更新增强息肉分割|Fatemeh Salahi Chashmi, Roya Sotoudeh|<http://arxiv.org/pdf/2509.23502v1>|提出了一种结合动态核机制和全局编码器注意力的框架，有效提升了息肉分割的准确性和效率。|
|🆕 发布|Robust Multi-Modal Face Anti-Spoofing with Domain Adaptation: Tackling Missing Modalities, Noisy Pseudo-Labels, and Model Degradation|基于域自适应的鲁棒多模态人脸防伪：应对缺失模态、噪声伪标签和模型退化问题|Ming-Tsung Hsu, Fang-Yu Hsu, Yi-Ting Lin, Kai-Heng Chien, Jun-Ren Chen, Cheng-Hsiang Su, Yi-Chen Ou, Chiou-Ting Hsu .etc.|<http://arxiv.org/pdf/2509.23475v1>|提出了一种多模态人脸防伪框架MFAS-DANet，有效应对了模态缺失、伪标签噪声和模型退化问题。|
|🆕 发布|CasPoinTr: Point Cloud Completion with Cascaded Networks and Knowledge Distillation|级联网络与知识蒸馏的点云补全：CasPoinTr|Yifan Yang, Yuxiang Yan, Boda Liu, Jian Pu|<http://arxiv.org/pdf/2509.23375v1>|CasPoinTr通过级联网络和知识蒸馏，有效提升从稀疏点云重建完整形状的能力。|
|📝 更新|ModelNet40-E: An Uncertainty-Aware Benchmark for Point Cloud Classification|点云分类的不确定性感知基准ModelNet40-E|Pedro Alonso, Tianrui Li, Chongshou Li|<http://arxiv.org/pdf/2508.01269v2>|提出了ModelNet40-E基准，通过提供噪声污染的点云和不确定性标注，评估点云分类模型的鲁棒性和...|
|🆕 发布|Self-Consistency as a Free Lunch: Reducing Hallucinations in Vision-Language Models via Self-Reflection|作为免费午餐的自一致性：通过自我反思减少视觉语言模型中的幻觉现象|Mingfei Han, Haihong Hao, Jinxing Zhou, Zhihui Li, Yuhui Zheng, Xueqing Deng, Linjie Yang, Xiaojun Chang|<http://arxiv.org/pdf/2509.23236v1>|利用模型自我一致性，无需人工标注或外部监督，有效减少视觉语言模型中的虚构细节问题。|
|🆕 发布|Benchmarking DINOv3 for Multi-Task Stroke Analysis on Non-Contrast CT|用于非对比CT的多任务笔画分析DINOv3基准测试|Donghao Zhang, Yimin Chen, Kauê TN Duarte, Taha Aslan, Mohamed AlShamrani, Brij Karmur, Yan Wan, Shengcai Chen .etc.|<http://arxiv.org/pdf/2509.23132v1>|[代码](https://github.com/Zzz0251/DINOv3-stroke.); 利用DINOv3自监督视觉变换模型，提升了非对比CT图像的卒中分析性能。|
|🆕 发布|Desensitizing for Improving Corruption Robustness in Point Cloud Classification through Adversarial Training|通过对抗训练提高点云分类的抗干扰稳健性的脱敏方法|Zhiqiang Tian, Weigang Li, Chunhua Deng, Junwei Hu, Yongqiang Wang, Wenping Liu|<http://arxiv.org/pdf/2509.23010v1>|[代码](https://github.com/JerkyT/DesenAT); 提出了一种通过对抗训练和自蒸馏框架降低点云特征敏感度的方法，有效提高了模型对点云腐蚀的鲁棒性。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|fVDB: A Deep-Learning Framework for Sparse, Large-Scale, and High-Performance Spatial Intelligence|fVDB：面向稀疏、大规模、高性能空间智能的深度学习框架|Francis Williams, Jiahui Huang, Jonathan Swartz, Gergely Klár, Vijay Thakkar, Matthew Cong, Xuanchi Ren, Ruilong Li .etc.|<http://arxiv.org/pdf/2407.01781v2>|fVDB是一个优化的深度学习框架，用于处理大规模3D数据，提供丰富的操作集并提升性能和内存效率。|
|🆕 发布|Spatial-Spectral Binarized Neural Network for Panchromatic and Multi-spectral Images Fusion|全色与多光谱图像融合的空间-光谱二值化神经网络|Yizhen Jiang, Mengting Ma, Anqi Zhu, Xiaowen Ma, Jiaxin Li, Wei Zhang|<http://arxiv.org/pdf/2509.23321v1>|提出了一种用于全色与多光谱图像融合的高效二值神经网络结构，有效解决了计算复杂度高和光谱失真问题。|
|🆕 发布|UltraUNet: Real-Time Ultrasound Tongue Segmentation for Diverse Linguistic and Imaging Conditions|超实时超声舌部分割网络UltraUNet：适用于多种语言和成像条件的实时超声舌部分割|Alisher Myrgyyassov, Zhen Song, Yu Sun, Bruce Xiao Wang, Min Ney Wong, Yongping Zheng|<http://arxiv.org/pdf/2509.23225v1>|提出了一种优化的轻量级网络UltraUNet，实现了超声图像中舌头轮廓的实时准确分割。|
|📝 更新|MoQE: Improve Quantization Model performance via Mixture of Quantization Experts|MoQE：通过混合量化专家提升量化模型性能|Jinhao Zhang, Yunquan Zhang, Boyang Zhang, Zeyu Liu, Daning Cheng|<http://arxiv.org/pdf/2508.09204v2>|提出了一种基于混合专家架构的量化推理框架 MoQE，通过动态选择最合适的量化模型，有效缓解了量化带来...|
|🆕 发布|Sensor-Adaptive Flood Mapping with Pre-trained Multi-Modal Transformers across SAR and Multispectral Modalities|跨合成孔径雷达与多光谱模态的预训练多模态变换器实现的传感器自适应洪水制图|Tomohiro Tanaka, Narumasa Tsutsumida|<http://arxiv.org/pdf/2509.23035v1>|提出了一种轻量级多模态预训练变换器，实现了灵活应对不同传感器数据的洪水快速映射。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Temporal Generalization: A Reality Check|时间泛化：现实检验|Divyam Madaan, Sumit Chopra, Kyunghyun Cho|<http://arxiv.org/pdf/2509.23487v1>|探讨了模型仅依赖过去数据实现时间泛化的条件，发现现有方法均不优于使用最新参数的基线。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Robust Fine-Tuning from Non-Robust Pretrained Models: Mitigating Suboptimal Transfer With Adversarial Scheduling|从非鲁棒预训练模型中进行鲁棒微调：利用对抗性调度减轻次优迁移|Jonas Ngnawé, Maxime Heuillet, Sabyasachi Sahoo, Yann Pequignot, Ola Ahmad, Audrey Durand, Frédéric Precioso, Christian Gagné|<http://arxiv.org/pdf/2509.23325v1>|提出了一种对抗性调度策略 epsilon-scheduling，有效缓解了非鲁棒预训练模型在微调过程...|
|🆕 发布|Real-World Transferable Adversarial Attack on Face-Recognition Systems|面向现实世界的面部识别系统迁移性对抗攻击|Andrey Kaznacheev, Matvey Mikhalchuk, Andrey Kuznetsov, Aleksandr Petiushko, Anton Razzhigaev|<http://arxiv.org/pdf/2509.23198v1>|提出了一种生成通用、物理可转移的对抗性贴片方法，有效攻击黑盒人脸识别系统。|
|🆕 发布|Confidence-Calibrating Regularization for Robust Brain MRI Segmentation Under Domain Shift|置信度校准正则化以实现域偏移下稳健的脑部MRI分割|Behraj Khan, Tahir Qasim Syed|<http://arxiv.org/pdf/2509.23176v1>|提出CalSAM方法，通过减少领域迁移敏感性和惩罚过度自信错误，提升了脑部MRI分割准确性和不确定性...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DDP: Dual-Decoupled Prompting for Multi-Label Class-Incremental Learning|DDP：多标签类增量学习中的双解耦提示|Kaile Du, Zihan Ye, Junzhou Xie, Fan Lyu, Yixi Shen, Yuyang Li, Miaoxuan Zhu, Fuyuan Hu .etc.|<http://arxiv.org/pdf/2509.23335v1>|提出了一种针对多标签类增量学习的DDP方法，有效解决了语义混淆和标记误差问题，实现了无重放策略下的性...|
|🆕 发布|LRPO: Enhancing Blind Face Restoration through Online Reinforcement Learning|LRPO：通过在线强化学习增强盲人脸修复|Bin Wu, Yahui Liu, Chi Zhang, Yao Zhao, Wei Wang|<http://arxiv.org/pdf/2509.23339v1>|首次应用在线强化学习于盲人脸修复任务，通过优化的策略网络显著提升了恢复图像的质量和细节忠实度。|
|📝 更新|SemaMIL: Semantic-Aware Multiple Instance Learning with Retrieval-Guided State Space Modeling for Whole Slide Images|SemaMIL：面向全切片图像的检索引导状态空间建模的语义感知多实例学习|Lubin Gan, Xiaoman Wu, Jing Zhang, Zhifeng Wang, Linhao Qu, Siying Wu, Xiaoyan Sun|<http://arxiv.org/pdf/2509.00442v2>|提出SemaMIL方法，通过语义重排和检索引导的状态空间建模，提升全切片图像分类准确性同时降低计算复...|
|🆕 发布|Learning Regional Monsoon Patterns with a Multimodal Attention U-Net|学习多模态注意力U-Net的区域季风模式|Swaib Ilias Mazumder, Manish Kumar, Aparajita Khan|<http://arxiv.org/pdf/2509.23267v1>|提出了一种多模态深度学习框架，通过卫星和地球观测数据，实现了高分辨率印度季风降雨预测。|
|📝 更新|Beyond Synthetic Replays: Turning Diffusion Features into Few-Shot Class-Incremental Learning Knowledge|超越合成重放：将扩散特征转化为少量样本类增量学习知识|Junsu Kim, Yunhoe Ku, Dongyoon Han, Seungryul Baek|<http://arxiv.org/pdf/2503.23402v2>|提出了一种利用稳定扩散模型多尺度特征进行少量样本增量学习的框架，实现了优于现有方法的性能和效率。|
|📝 更新|DeepFRC: An End-to-End Deep Learning Model for Functional Registration and Classification|深度FRC：一种用于功能配准与分类的端到端深度学习模型|Siyuan Jiang, Yihan Hu, Wenjie Li, Pengcheng Zeng|<http://arxiv.org/pdf/2501.18116v3>|[代码](https://github.com/Drivergo-93589/DeepFRC.); 提出了一种端到端的深度学习模型DeepFRC，实现了功能数据的同步对齐和分类，提升了准确性和鲁棒性。|
|🆕 发布|WeatherCycle: Unpaired Multi-Weather Restoration via Color Space Decoupled Cycle Learning|《WeatherCycle：通过颜色空间解耦循环学习实现无配对多天气恢复》|Wenxuan Fang, Jiangwei Weng, Jianjun Qian, Jian Yang, Jun Li|<http://arxiv.org/pdf/2509.23150v1>|WeatherCycle通过解耦色彩空间实现无监督多天气条件下的图像复原，提出了一种新的双向退化-内...|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TATTOO: Training-free AesTheTic-aware Outfit recOmmendation|无训练的审美感知着装推荐系统TATTOO|Yuntian Wu, Xiaonan Hu, Ziqi Zhou, Hao Lu|<http://arxiv.org/pdf/2509.23242v1>|提出了一种无需训练的时尚搭配推荐方法TATTOO，利用大型语言模型和美学向量实现更佳推荐效果。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-modal Data Spectrum: Multi-modal Datasets are Multi-dimensional|多模态数据谱：多模态数据集是多维度的|Divyam Madaan, Varshan Muhunthan, Kyunghyun Cho, Sumit Chopra|<http://arxiv.org/pdf/2509.23499v1>|揭示了多模态学习中的依赖关系，并提出量化多模态数据集的方法，优化了多模态基准设计。|
|🆕 发布|Seeing Symbols, Missing Cultures: Probing Vision-Language Models' Reasoning on Fire Imagery and Cultural Meaning|“观察符号，忽视文化：探究视觉语言模型在火焰图像和文化意义推理上的表现”|Haorui Yu, Qiufeng Yi, Yijia Chu, Yang Zhao|<http://arxiv.org/pdf/2509.23311v1>|揭示了视觉语言模型在文化理解上的缺陷，并提出了一个诊断框架来评估其处理文化意象的能力。|
|🆕 发布|Decoupling Reasoning and Perception: An LLM-LMM Framework for Faithful Visual Reasoning|解耦推理与感知：一种用于忠实视觉推理的LLM-LMM框架|Hongrui Jia, Chaoya Jiang, Shikun Zhang, Wei Ye|<http://arxiv.org/pdf/2509.23322v1>|提出了一种将推理与感知解耦的框架，通过大型语言模型指挥大型多模态模型提取视觉信息，有效提升了视觉推理...|
|📝 更新|Vision-EKIPL: External Knowledge-Infused Policy Learning for Visual Reasoning|视觉-EKIPL：外部知识注入的策略学习用于视觉推理|Chaoyang Wang, Zeyu Zhang, Meng Meng, Xu Zhou, Haiyun Jiang|<http://arxiv.org/pdf/2506.06856v2>|引入外部辅助模型生成的高质量动作以优化策略学习，显著提升视觉推理性能并加速训练效率。|
|📝 更新|ProxyThinker: Test-Time Guidance through Small Visual Reasoners|代理思考者：通过小视觉推理器的测试时引导|Zilin Xiao, Jaywon Koo, Siru Ouyang, Jefferson Hernandez, Yu Meng, Vicente Ordonez|<http://arxiv.org/pdf/2505.24872v2>|[代码](https://github.com/MrZilinXiao/ProxyThinker.); ProxyThinker通过无需训练的方式，使大型模型继承小型视觉推理器的推理能力，提升复杂视觉任务...|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Better Safe Than Sorry? Overreaction Problem of Vision Language Models in Visual Emergency Recognition|“宁可信其有？视觉语言模型在视觉紧急识别中的过度反应问题”|Dasol Choi, Seunghyun Lee, Youngsook Song|<http://arxiv.org/pdf/2505.15367v3>|揭示了视觉语言模型在紧急情况识别中的“过度反应”问题，并提出了诊断基准VERI来评估模型可靠性。|
|🆕 发布|AttAnchor: Guiding Cross-Modal Token Alignment in VLMs with Attention Anchors|AttAnchor：使用注意力锚点引导大型视觉语言模型中的跨模态标记对齐|Junyang Zhang, Tianyi Zhu, Thierry Tambe|<http://arxiv.org/pdf/2509.23109v1>|提出了一种参数免费的注意力锚点框架，通过增强跨模态相似性分组，有效提升了视觉语言模型的准确性和减少了...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|S$^3$F-Net: A Multi-Modal Approach to Medical Image Classification via Spatial-Spectral Summarizer Fusion Network|S$^3$F-Net：通过空间-光谱总结器融合网络实现医学图像分类的多模态方法|Md. Saiful Bari Siddiqui, Mohammed Imamul Hassan Bhuiyan|<http://arxiv.org/pdf/2509.23442v1>|提出了一种融合空间和频域特征的多模态医疗图像分类网络，提高了分类准确性和泛化能力。|
|🆕 发布|FracDetNet: Advanced Fracture Detection via Dual-Focus Attention and Multi-scale Calibration in Medical X-ray Imaging|FracDetNet：通过双焦点注意力和多尺度校准在医学X射线成像中进行高级骨折检测|Yuyang Sun, Cuiming Zou|<http://arxiv.org/pdf/2509.23416v1>|提出FracDetNet框架，通过双焦点注意力和多尺度校准显著提升医学X光影像中骨折检测的准确性和效...|
|🆕 发布|Enhanced Fracture Diagnosis Based on Critical Regional and Scale Aware in YOLO|基于关键区域和尺度感知的YOLO骨折诊断增强方法|Yuyang Sun, Junchuan Yu, Cuiming Zou|<http://arxiv.org/pdf/2509.23408v1>|提出了一种改进的YOLO模型Fracture-YOLO，通过关键区域选择和尺度感知机制提升骨折检测的...|
|🆕 发布|DentVLM: A Multimodal Vision-Language Model for Comprehensive Dental Diagnosis and Enhanced Clinical Practice|牙科VLM：一种用于全面牙科诊断和提升临床实践的 多模态视觉-语言模型|Zijie Meng, Jin Hao, Xiwei Dai, Yang Feng, Jiaxiang Liu, Bin Feng, Huikai Wu, Xiaotang Gai .etc.|<http://arxiv.org/pdf/2509.23344v1>|提出DentVLM模型，通过多模态视觉语言技术提升口腔疾病诊断准确性和临床工作效率。|
|🆕 发布|Test-time Uncertainty Estimation for Medical Image Registration via Transformation Equivariance|通过变换等方差性对医学图像配准进行测试时不确定性估计|Lin Tian, Xiaoling Hu, Juan Eugenio Iglesias|<http://arxiv.org/pdf/2509.23355v1>|提出了一种兼容任意预训练网络的测试时不确定性估计框架，通过分析图像变换下的预测方差，提高了医学图像配...|
|📝 更新|Efficient Self-Supervised Adaptation for Medical Image Analysis|高效的自监督适应方法用于医学图像分析|Moein Sorkhei, Emir Konuk, Jingyu Guo, Chanjuan Meng, Christos Matsoukas, Kevin Smith|<http://arxiv.org/pdf/2503.18873v3>|提出了一种高效的自我监督适应框架 ESSA，通过参数高效微调技术降低计算成本并提升医疗图像分析性能。|
|📝 更新|Can General-Purpose Omnimodels Compete with Specialists? A Case Study in Medical Image Segmentation|“通用全模型能与专家模型竞争吗？以医学图像分割为例的研究”|Yizhe Zhang, Qiang Chen, Tao Zhou|<http://arxiv.org/pdf/2509.00866v2>|探究通用模型与专业模型在医疗图像分割中的性能差异，发现通用模型在处理难题上具有优势。|
|📝 更新|Applications of Small Language Models in Medical Imaging Classification with a Focus on Prompt Strategies|小语言模型在医学成像分类中的应用：重点关注提示策略|Yiting Wang, Ziwei Wang, Jiachen Zhong, Di Zhu, Weiyi Li|<http://arxiv.org/pdf/2508.13378v2>|探究小语言模型在医学影像分类中的应用，通过精心设计的提示策略提升模型准确性。|
|📝 更新|ProstaTD: Bridging Surgical Triplet from Classification to Fully Supervised Detection|ProstaTD：从分类到完全监督检测的手术三元组桥接|Yiliang Chen, Zhixi Li, Cheng Xu, Alex Qinyang Liu, Ruize Cui, Xuemiao Xu, Jeremy Yuen-Chun Teoh, Shengfeng He .etc.|<http://arxiv.org/pdf/2506.01130v3>|提出了ProstaTD数据集，通过精确的时空边界标注，将手术三元组检测从分类推进到全监督检测。|
|🆕 发布|Mask What Matters: Controllable Text-Guided Masking for Self-Supervised Medical Image Analysis|《遮蔽关键信息：可控文本引导遮蔽用于自监督医学图像分析》|Ruilang Wang, Shuotong Xu, Bowen Liu, Runlin Huang, Donglong Chen, Weifeng Su|<http://arxiv.org/pdf/2509.23054v1>|提出了一种文本引导的可控遮罩框架，通过强调诊断相关区域，提高了无监督医学图像分析的准确性和泛化能力。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|WorldSplat: Gaussian-Centric Feed-Forward 4D Scene Generation for Autonomous Driving|世界散点：高斯中心化的前馈4D场景生成方法用于自动驾驶|Ziyue Zhu, Zhanqian Wu, Zhenxin Zhu, Lijun Zhou, Haiyang Sun, Bing Wan, Kun Ma, Guang Chen .etc.|<http://arxiv.org/pdf/2509.23402v1>|提出了一种4D场景生成框架WorldSplat，通过结合4D高斯模型和视频扩散模型，实现了高质量的多...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HSACNet: Hierarchical Scale-Aware Consistency Regularized Semi-Supervised Change Detection|HSACNet：分层尺度感知一致性正则化半监督变化检测|Qi'ao Xu, Pengfei Wang, Yanjun Li, Tianwen Qian, Xiaoling Wang|<http://arxiv.org/pdf/2504.13428v2>|提出HSACNet，通过层级多尺度特征提取和一致性正则化，提升半监督变化检测在复杂场景下的性能。|
|🆕 发布|Balanced Diffusion-Guided Fusion for Multimodal Remote Sensing Classification|平衡扩散引导的多模态遥感分类融合|Hao Liu, Yongjie Zheng, Yuhan Kang, Mingyang Zhang, Maoguo Gong, Lorenzo Bruzzone|<http://arxiv.org/pdf/2509.23310v1>|[代码](https://github.com/HaoLiu-XDU/BDGF.); 提出了一种平衡扩散引导融合框架，通过自适应模态掩码和互学习策略优化多模态遥感数据分类性能。|
|🆕 发布|Towards Comprehensive Interactive Change Understanding in Remote Sensing: A Large-scale Dataset and Dual-granularity Enhanced VLM|面向遥感全面交互式变化理解：大规模数据集与双粒度增强的变分语言模型|Junxiao Xue, Quan Deng, Xuecheng Wu, Kelu Yao, Xinyi Yin, Fei Yu, Wei Zhou, Yanfei Zhong .etc.|<http://arxiv.org/pdf/2509.23105v1>|构建了大规模多任务交互式遥感变化理解数据集，并设计了双粒度增强的视觉语言模型。|
|📝 更新|Spiking Meets Attention: Efficient Remote Sensing Image Super-Resolution with Attention Spiking Neural Networks|“脉冲遇见注意力：基于注意力脉冲神经网络的高效遥感图像超分辨率”|Yi Xiao, Qiangqiang Yuan, Kui Jiang, Wenke Huang, Qiang Zhang, Tingting Zheng, Chia-Wen Lin, Liangpei Zhang|<http://arxiv.org/pdf/2503.04223v2>|提出了一种基于脉冲神经网络的图像超分辨率方法，通过注意力脉冲块优化特征表示，实现了高效率的遥感图像重...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Power Battery Detection|动力电池检测|Xiaoqi Zhao, Peiqian Cao, Chenyang Yu, Zonglei Feng, Lihe Zhang, Hanqi Liu, Jiaming Zuo, Youwei Pang .etc.|<http://arxiv.org/pdf/2508.07797v2>|[代码](https://github.com/Xiaoqi-Zhao-DLUT/X-ray-PBD); 提出首个大规模电池检测基准PBD5K和模型MDCNeXt，用于高效检测电池电极板端点。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Vision Language Models are Biased|计算机视觉语言模型存在偏见|An Vo, Khai-Nguyen Nguyen, Mohammad Reza Taesiri, Vy Tuong Dang, Anh Totti Nguyen, Daeyoung Kim|<http://arxiv.org/pdf/2505.23941v2>|揭示了视觉语言模型在计数和识别任务中的偏见问题，并提出了一个自动化的测试框架。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HTMA-Net: Towards Multiplication-Avoiding Neural Networks via Hadamard Transform and In-Memory Computing|HTMA-Net：基于哈达玛变换与内存内计算的无乘法神经网络|Emadeldeen Hamdan, Ahmet Enis Cetin|<http://arxiv.org/pdf/2509.23103v1>|HTMA-Net通过结合哈达玛变换与乘法避免的内存计算，有效降低神经网络乘法运算成本并保持准确度。|
|📝 更新|Universal Gröbner Bases of (Universal) Multiview Ideals|“多视图理想的（通用）Gröbner基的通用性”|Timothy Duff, Jack Kendrick, Rekha R. Thomas|<http://arxiv.org/pdf/2509.12376v3>|证明了特定多项式集合构成多视角理想的通用Gröbner基，实现了对称性和归纳法的无限家族应用。|

