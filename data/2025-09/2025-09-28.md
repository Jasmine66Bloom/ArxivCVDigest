## [UPDATED!] **2025-09-28** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Clebsch-Gordan Transformer: Fast and Global Equivariant Attention|克莱布斯-戈尔丹变换器：快速全局等变注意力机制|Owen Lewis Howell, Linfeng Zhao, Xupeng Zhu, Yaoyao Qian, Haojie Huang, Lingfeng Sun, Wil Thomason, Robert Platt .etc.|<http://arxiv.org/pdf/2509.24093v1>|提出Clebsch-Gordan Transformer，通过 Clebsch-Gordon 卷积实...|
|🆕 发布|EWC-Guided Diffusion Replay for Exemplar-Free Continual Learning in Medical Imaging|基于EWC引导的扩散重放用于医学影像中的无样例连续学习|Anoushka Harit, William Prew, Zhongtian Sun, Florian Markowetz|<http://arxiv.org/pdf/2509.23906v1>|提出了一种无需存储患者样本的医学影像连续学习框架，结合条件扩散重放和弹性权重巩固减少遗忘，实现高效隐...|
|🆕 发布|FairViT-GAN: A Hybrid Vision Transformer with Adversarial Debiasing for Fair and Explainable Facial Beauty Prediction|FairViT-GAN：一种具有对抗性去偏的混合视觉变换器，用于公平且可解释的面部美丽预测|Djamel Eddine Boukhari|<http://arxiv.org/pdf/2509.23859v1>|提出FairViT-GAN模型，结合CNN与Vision Transformer优势，并通过对抗性去...|
|🆕 发布|Assessing Visual Privacy Risks in Multimodal AI: A Novel Taxonomy-Grounded Evaluation of Vision-Language Models|评估多模态人工智能中的视觉隐私风险：一种基于新型分类法的视觉-语言模型评价方法|Efthymios Tsaprazlis, Tiantian Feng, Anil Ramakrishna, Rahul Gupta, Shrikanth Narayanan|<http://arxiv.org/pdf/2509.23827v1>|提出视觉隐私分类法，评估了视觉语言模型对隐私理解的局限性，指出了构建隐私感知AI的迫切需求。|
|🆕 发布|PVTAdpNet: Polyp Segmentation using Pyramid vision transformer with a novel Adapter block|息肉分割：使用金字塔视觉变换器和一种新颖的适配器模块的PVTAdpNet方法|Arshia Yousefi Nezhad, Helia Aghaei, Hedieh Sajedi|<http://arxiv.org/pdf/2509.23751v1>|[代码](https://github.com/ayousefinejad/PVTAdpNet.git); 提出PVTAdpNet模型，结合金字塔视觉变换器和适配器模块，实现实时准确的息肉分割。|
|🆕 发布|QuantSparse: Comprehensively Compressing Video Diffusion Transformer with Model Quantization and Attention Sparsification|《QuantSparse：通过模型量化和注意力稀疏化全面压缩视频扩散变换器》|Weilun Feng, Chuanguang Yang, Haotong Qin, Mingqiang Wu, Yuqi Li, Xiangqi Li, Zhulin An, Libo Huang .etc.|<http://arxiv.org/pdf/2509.23681v1>|[代码](https://github.com/wlfeng0509/QuantSparse.); 提出QuantSparse框架，结合模型量化和注意力稀疏化，显著提升视频生成模型的压缩效率和性能。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SCRAMBLe : Enhancing Multimodal LLM Compositionality with Synthetic Preference Data|SCRAMBLe：利用合成偏好数据增强多模态大型语言模型的组合性|Samarth Mishra, Kate Saenko, Venkatesh Saligrama|<http://arxiv.org/pdf/2504.04740v2>|[代码](https://github.com/samarth4149/SCRAMBLe.); 提出了一种自动化生成合成偏好数据的方法SCRAMBLe，有效提升了大型多模态语言模型的组合推理能力。|
|🆕 发布|Revisit the Imbalance Optimization in Multi-task Learning: An Experimental Analysis|重新审视多任务学习中的不平衡优化：一项实验分析|Yihang Guo, Tianyuan Yu, Liang Bai, Yanming Guo, Yirun Ruan, William Li, Weishi Zheng|<http://arxiv.org/pdf/2509.23915v1>|揭示了多任务学习中的优化不平衡问题，并提出按梯度范数缩放损失的策略以稳定性能。|
|🆕 发布|SAR-KnowLIP: Towards Multimodal Foundation Models for Remote Sensing|面向遥感的多模态基础模型：SAR-KnowLIP|Yi Yang, Xiaokun Zhang, Qingchen Fang, Ziqi Ye, Rui Li, Li Liu, Haipeng Wang|<http://arxiv.org/pdf/2509.23927v1>|提出首个面向合成孔径雷达影像的多模态基础模型SAR-KnowLIP，通过大规模数据集和自优化机制提升...|
|🆕 发布|Preserving Cross-Modal Stability for Visual Unlearning in Multimodal Scenarios|保持跨模态稳定性以实现多模态场景下的视觉遗忘|Jinghan Xu Yuyang Zhang Qixuan Cai Jiancheng Chen Keqiu Li|<http://arxiv.org/pdf/2509.23895v1>|提出了一种跨模态对比遗忘框架，有效解决了视觉遗忘中的隐私泄露问题并保持了模型性能。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Accurate and Efficient Low-Rank Model Merging in Core Space|在核心空间中准确且高效地进行低秩模型合并|Aniello Panariello, Daniel Marczak, Simone Magistri, Angelo Porrello, Bartłomiej Twardowski, Andrew D. Bagdanov, Simone Calderara, Joost van de Weijer|<http://arxiv.org/pdf/2509.17786v2>|[代码](https://github.com/apanariello4/core-space-merging.); 提出Core Space框架，高效合并低秩适应模型，保持效率同时显著提升准确性。|
|🆕 发布|Advancing Multi-agent Traffic Simulation via R1-Style Reinforcement Fine-Tuning|通过R1风格强化微调提升多智能体交通模拟|Muleilan Pei, Shaoshuai Shi, Shaojie Shen|<http://arxiv.org/pdf/2509.23993v1>|提出SMART-R1方法，通过R1-style强化微调改善多智能体交通模拟与人类驾驶行为的一致性，实...|
|🆕 发布|Reinforcement Learning with Inverse Rewards for World Model Post-training|带有逆奖励的强化学习在世界模型后训练中|Yang Ye, Tianyu He, Shuo Yang, Jiang Bian|<http://arxiv.org/pdf/2509.23958v1>|提出了一种利用逆奖励的强化学习方法，有效提升了视频世界模型对指定动作的跟随能力。|
|🆕 发布|HunyuanImage 3.0 Technical Report|《HunyuanImage 3.0 技术报告》|Siyu Cao, Hangting Chen, Peng Chen, Yiji Cheng, Yutao Cui, Xinchi Deng, Ying Dong, Kipper Gong .etc.|<http://arxiv.org/pdf/2509.23951v1>|[代码](https://github.com/Tencent-Hunyuan/HunyuanImage-3.0); HunyuanImage 3.0融合多模态理解和生成，打造了开源界最大最强图像生成模型。|
|🆕 发布|PCRI: Measuring Context Robustness in Multimodal Models for Enterprise Applications|PCRI：测量企业应用中多模态模型上下文稳健性|Hitesh Laxmichand Patel, Amit Agarwal, Srikant Panda, Hansa Meghwani, Karan Dua, Paul Li, Tao Sheng, Sujith Ravi .etc.|<http://arxiv.org/pdf/2509.23879v1>|提出PCRI指标，首次系统评估多模态大语言模型对视觉背景变化的鲁棒性。|
|📝 更新|Seedream 4.0: Toward Next-generation Multimodal Image Generation|“Seedream 4.0：迈向下一代多模态图像生成”|Team Seedream, :, Yunpeng Chen, Yu Gao, Lixue Gong, Meng Guo, Qiushan Guo, Zhiyao Guo .etc.|<http://arxiv.org/pdf/2509.20427v2>|提出了Seedream 4.0，一种高效的多模态图像生成系统，统一了文本到图像合成、图像编辑和多重图...|
|🆕 发布|LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training|LLaVA-OneVision-1.5：全面开放框架，实现多模态训练的民主化|Xiang An, Yin Xie, Kaicheng Yang, Wenkang Zhang, Xiuwei Zhao, Zheng Cheng, Yirui Wang, Songcen Xu .etc.|<http://arxiv.org/pdf/2509.23661v1>|LLaVA-OneVision-1.5提供了一种高效、开源的框架，以低成本实现顶尖的多模态模型训练性...|
|📝 更新|Any-to-Bokeh: Arbitrary-Subject Video Refocusing with Video Diffusion Model|任意主体视频重聚焦：基于视频扩散模型的任意主体视频散焦效果生成|Yang Yang, Siming Zheng, Qirui Yang, Jinwei Chen, Boxi Wu, Xiaofei He, Deng Cai, Bo Li .etc.|<http://arxiv.org/pdf/2505.21593v2>|首次提出基于扩散模型的一步视频重聚焦框架，实现了时序连贯且可控的景深效果。|
|🆕 发布|Efficient Domain-Adaptive Multi-Task Dense Prediction with Vision Foundation Models|基于视觉基础模型的高效域自适应多任务密集预测|Beomseok Kang, Niluthpol Chowdhury Mithun, Mikhail Sizintsev, Han-Pang Chiu, Supun Samarasekera|<http://arxiv.org/pdf/2509.23626v1>|提出了一种利用视觉基础模型进行高效的多任务域自适应方法，实现了最佳性能与模型压缩。|
|🆕 发布|RIV: Recursive Introspection Mask Diffusion Vision Language Model|递归内省掩码扩散视觉语言模型（RIV）|YuQian Li, Limeng Qiao, Lin Ma|<http://arxiv.org/pdf/2509.23625v1>|引入自我修正机制，通过内省训练和递归推理，提升了多模态理解任务的准确性和鲁棒性。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SVAC: Scaling Is All You Need For Referring Video Object Segmentation|SVAC：尺度变换是你进行视频目标分割所需的一切|Li Zhang, Haoxiang Gao, Zhihao Zhang, Luoxiao Huang, Tao Zhang|<http://arxiv.org/pdf/2509.24109v1>|[代码](https://github.com/lizhang1998/SVAC.); 提出SVAC模型，通过扩大输入帧和分割标记规模增强视频-语言交互，并引入ASTC和CSA策略提升处理...|
|📝 更新|Temporal Grounding as a Learning Signal for Referring Video Object Segmentation|时间定位作为视频目标分割中的学习信号|Seunghun Lee, Jiwan Seo, Jeonghoon Kim, Sungho Moon, Siwon Kim, Haeun Yun, Hyogyeong Jeon, Wonhyeok Choi .etc.|<http://arxiv.org/pdf/2508.11955v2>|提出基于时间定位的监督信号，通过新型学习框架提升视频对象分割的准确性和跟踪效果。|
|🆕 发布|Learning Adaptive Pseudo-Label Selection for Semi-Supervised 3D Object Detection|学习自适应伪标签选择用于半监督三维目标检测|Taehun Kong, Tae-Kyun Kim|<http://arxiv.org/pdf/2509.23880v1>|提出自适应伪标签选择机制，通过融合分数和上下文信息，提升半监督三维物体检测的准确性和鲁棒性。|
|🆕 发布|2nd Place Report of MOSEv2 Challenge 2025: Concept Guided Video Object Segmentation via SeC|2025年MOSEv2挑战赛二等奖报告：基于SeC的概念引导视频对象分割|Zhixiong Zhang, Shuangrui Ding, Xiaoyi Dong, Yuhang Zang, Yuhang Cao, Jiaqi Wang|<http://arxiv.org/pdf/2509.23838v1>|利用大型视觉语言模型实现概念引导的视频目标分割，增强了对抗视觉变化的鲁棒性。|
|📝 更新|Find your Needle: Small Object Image Retrieval via Multi-Object Attention Optimization|《找到你的针：通过多目标注意力优化的小目标图像检索》|Michael Green, Matan Levy, Issar Tzachor, Dvir Samuel, Nir Darshan, Rami Ben-Ari|<http://arxiv.org/pdf/2503.07038v2>|[代码](https://pihash2k.github.io/findyourneedle.github.io); 提出了一种多对象注意力优化框架，有效提升了小目标图像检索的准确性和效率。|
|📝 更新|InfoDet: A Dataset for Infographic Element Detection|信息图元素检测数据集 InfoDet|Jiangning Zhu, Yuxing Zhou, Zheng Wang, Juntao Yao, Yima Gu, Yuhui Yuan, Shixia Liu|<http://arxiv.org/pdf/2505.17473v4>|提出InfoDet数据集，增强视觉语言模型对图表元素的理解和检测能力。|
|🆕 发布|Confidence Aware SSD Ensemble with Weighted Boxes Fusion for Weapon Detection|武器检测中的置信度感知SSD集成与加权框融合|Atharva Jadhav, Arush Karekar, Manas Divekar, Shachi Natu|<http://arxiv.org/pdf/2509.23697v1>|提出了一种基于多模型融合的武器检测方法，通过加权框融合技术显著提升了检测准确率。|
|📝 更新|Synthetic-to-Real Camouflaged Object Detection|合成到现实场景中的迷彩目标检测|Zhihao Luo, Luojun Lin, Zheng Lin|<http://arxiv.org/pdf/2507.18911v3>|[代码](https://github.com/Muscape/S2R-COD.); 提出了一种基于学生-教师模型的CSRDA框架，通过伪标签和一致性正则化将分类信息从标注的合成数据域传...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bridging the Task Gap: Multi-Task Adversarial Transferability in CLIP and Its Derivatives|弥合任务差距：CLIP及其衍生品中的多任务对抗迁移性|Kuanrong Liu, Siyuan Liang, Cheng Qian, Ming Zhang, Xiaochun Cao|<http://arxiv.org/pdf/2509.23917v1>|分析了CLIP模型在不同任务间的对抗性转移性，提出MT-AdvCLIP框架增强攻击效果。|
|🆕 发布|Sim-DETR: Unlock DETR for Temporal Sentence Grounding|Sim-DETR：解锁DETR进行时序句子定位|Jiajin Tang, Zhengxuan Wei, Yuchen Zhu, Cheng Shi, Guanbin Li, Liang Lin, Sibei Yang|<http://arxiv.org/pdf/2509.23867v1>|提出Sim-DETR方法，通过优化查询约束和上下文对齐，提升DETR在视频文本匹配任务中的性能。|
|📝 更新|Measurement of Medial Elbow Joint Space using Landmark Detection|使用地标检测测量肘关节内侧间隙|Shizuka Akahori, Shotaro Teruya, Pragyan Shrestha, Yuichi Yoshii, Ryuhei Michinobu, Satoshi Iizuka, Itaru Kitahara|<http://arxiv.org/pdf/2412.13010v3>|[代码](https://github.com/Akahori000/Ultrasound-Medial-Elbow-Dataset); 提出了一种新的超声内侧肘部数据集和形状子空间 refine 方法，用于精确测量肘关节间隙以诊断 UC...|
|🆕 发布|Color-Pair Guided Robust Zero-Shot 6D Pose Estimation and Tracking of Cluttered Objects on Edge Devices|颜色对引导的边缘设备上杂乱物体鲁棒零样本6D姿态估计与跟踪|Xingjian Yang, Ashis G. Banerjee|<http://arxiv.org/pdf/2509.23647v1>|提出了一种在边缘设备上执行的统一框架，通过颜色对特征实现鲁棒的零样本6D姿态估计和跟踪。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EfficientMIL: Efficient Linear-Complexity MIL Method for WSI Classification|高效MIL：面向WSI分类的高效线性复杂度MIL方法|Chengying She, Ben Wang, Xinran Zhang, Dongjie Fan, Jialu Zhang, Chengwei Chen, Lizhuang Liu|<http://arxiv.org/pdf/2509.23640v1>|提出EfficientMIL方法，通过自适应选取patches，降低MIL计算复杂度，提升WSI分类...|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GANji: A Framework for Introductory AI Image Generation|“GANji：一个入门级人工智能图像生成框架”|Chandon Hamel, Mike Busch|<http://arxiv.org/pdf/2509.24128v1>|介绍了GANji框架，通过比较VAE、GAN和DDPM模型，揭示了模型架构、计算成本和视觉质量之间的...|
|🆕 发布|SLA: Beyond Sparsity in Diffusion Transformers via Fine-Tunable Sparse-Linear Attention|稀疏线性注意力：通过可微调的稀疏线性注意力超越扩散变换器中的稀疏性|Jintao Zhang, Haoxu Wang, Kai Jiang, Shuo Yang, Kaiwen Zheng, Haocheng Xi, Ziteng Wang, Hongzhou Zhu .etc.|<http://arxiv.org/pdf/2509.24006v1>|提出SLA方法，通过区分关键、边缘和可忽略的注意力权重，大幅加速了扩散模型的计算效率。|
|🆕 发布|Generalized Category Discovery in Hyperspectral Images via Prototype Subspace Modeling|通过原型子空间建模实现高光谱图像中的泛化类别发现|Xianlu Li, Nicolas Nadisic, Shaoguang Huang, Aleksandra Pizurica|<http://arxiv.org/pdf/2509.24017v1>|提出首个针对高光谱图像的广义类别发现框架，通过原型子空间建模提高类别表达性和区分度。|
|🆕 发布|Towards Redundancy Reduction in Diffusion Models for Efficient Video Super-Resolution|面向高效视频超分辨率扩散模型中的冗余降低|Jinpei Guo, Yifei Ji, Zheng Chen, Yufei Wang, Sizhuo Ma, Yong Guo, Yulun Zhang, Jian Wang|<http://arxiv.org/pdf/2509.23980v1>|[代码](https://github.com/jp-guo/OASIS); 提出了一种针对视频超分辨率任务的专用一步扩散模型OASIS，通过注意力分配减少冗余，提升性能和效率。|
|🆕 发布|VFSI: Validity First Spatial Intelligence for Constraint-Guided Traffic Diffusion|首先有效性空间智能VFSI：约束引导的交通扩散|Kargi Chauhan, Leilani H. Gilpin|<http://arxiv.org/pdf/2509.23971v1>|提出Validity-First Spatial Intelligence方法，通过能量引导确保交通...|
|🆕 发布|Tunable-Generalization Diffusion Powered by Self-Supervised Contextual Sub-Data for Low-Dose CT Reconstruction|基于自监督上下文子数据驱动的可调节泛化扩散用于低剂量CT重建|Guoquan Wei, Zekun Zhou, Liu Shi, Wenzhe Shan, Qiegen Liu|<http://arxiv.org/pdf/2509.23885v1>|提出了一种基于自监督上下文子数据的可调节泛化扩散方法，有效提升了低剂量CT重建的性能和泛化能力。|
|📝 更新|A Survey on Self-supervised Contrastive Learning for Multimodal Text-Image Analysis|《多模态文本-图像分析中自监督对比学习的综述》|Asifullah Khan, Laiba Asmatullah, Anza Malik, Shahzaib Khan, Hamna Asif|<http://arxiv.org/pdf/2503.11101v4>|系统梳理了自监督对比学习在文本-图像分析中的应用，推动了无标注数据下的图像理解与文本分析。|
|📝 更新|Physics-Guided Null-Space Diffusion with Sparse Masking for Corrective Sparse-View CT Reconstruction|基于物理引导的稀疏掩码空域扩散校正稀疏视角CT重建|Zekun Zhou, Yanru Gong, Liu Shi, Qiegen Liu|<http://arxiv.org/pdf/2509.05992v2>|提出了一种基于稀疏条件概率和时变权重调整的扩散模型，有效提升了稀疏视角CT图像重建的质量。|
|🆕 发布|ReLumix: Extending Image Relighting to Video via Video Diffusion Models|ReLumix：通过视频扩散模型将图像重光照扩展到视频|Lezhong Wang, Shutong Jin, Ruiqi Cui, Anders Bjorholm Dahl, Jeppe Revall Frisvad, Siavash Bigdeli|<http://arxiv.org/pdf/2509.23769v1>|提出了一种视频重光照新框架ReLumix，通过分离重光照算法与时间合成，实现了任意图像重光照技术无缝...|
|📝 更新|Half-order Fine-Tuning for Diffusion Model: A Recursive Likelihood Ratio Optimizer|半阶微调用于扩散模型：递归似然比优化器|Tao Ren, Zishi Zhang, Jingyang Jiang, Zehao Li, Shentao Qin, Yi Zheng, Guanghao Li, Qianyou Sun .etc.|<http://arxiv.org/pdf/2502.00639v3>|提出了一种针对扩散模型的高效半阶微调方法，通过递归似然比优化器解决了低样本效率和梯度估计偏差问题。|
|📝 更新|High-Precision Dichotomous Image Segmentation via Depth Integrity-Prior and Fine-Grained Patch Strategy|通过深度完整性先验和细粒度补丁策略实现的高精度二值图像分割|Xianjie Liu, Keren Fu, Qijun Zhao|<http://arxiv.org/pdf/2503.06100v4>|提出深度完整性先验和细粒度补丁策略，实现高效精确的二值图像分割。|
|🆕 发布|Diff-3DCap: Shape Captioning with Diffusion Models|扩散模型驱动的形状描述生成：Diff-3DCap|Zhenyu Shu, Jiawei Wen, Shiyang Li, Shiqing Xin, Ligang Liu|<http://arxiv.org/pdf/2509.23718v1>|提出Diff-3DCap，用连续扩散模型和投影视图表示3D形状，无需额外分类器实现高效形状描述。|
|🆕 发布|CrimEdit: Controllable Editing for Counterfactual Object Removal, Insertion, and Movement|CrimEdit：用于反事实对象移除、插入和移动的可控编辑|Boseong Jeon, Junghyuk Lee, Jimin Park, Kwanyoung Kim, Jingi Jung, Sangwon Lee, Hyunbo Shim|<http://arxiv.org/pdf/2509.23708v1>|提出了一种统一的模型CrimEdit，通过联合训练和无需额外步骤实现了对象的移除、插入和移动，同时控...|
|🆕 发布|DiffPCN: Latent Diffusion Model Based on Multi-view Depth Images for Point Cloud Completion|多视角深度图像驱动的潜在扩散模型DiffPCN用于点云补全|Zijun Li, Hongyu Yan, Shijie Li, Kunming Luo, Li Lu, Xulei Yang, Weisi Lin|<http://arxiv.org/pdf/2509.23723v1>|提出了一种基于潜在扩散模型的多视角深度图像粗到细框架DiffPCN，实现了高质量点云的生成与完善。|
|🆕 发布|LightFair: Towards an Efficient Alternative for Fair T2I Diffusion via Debiasing Pre-trained Text Encoders|《LightFair：通过去偏预训练文本编码器实现公平的T2I扩散的高效替代方案》|Boyu Han, Qianqian Xu, Shilong Bao, Zhiyong Yang, Kangli Zi, Qingming Huang|<http://arxiv.org/pdf/2509.23639v1>|[代码](https://github.com/boyuh/LightFair.); 提出了一种轻量级方法LightFair，通过优化文本编码器减少偏见，提高文本到图像生成模型的公平性和...|
|📝 更新|Revisiting Visual Understanding in Multimodal Reasoning through a Lens of Image Perturbation|通过图像扰动视角重新审视多模态推理中的视觉理解|Yuting Li, Lai Wei, Kaipeng Zheng, Jingyuan Huang, Guilin Li, Bo Wang, Linghe Kong, Lichao Sun .etc.|<http://arxiv.org/pdf/2506.09736v2>|[代码](https://github.com/YutingLi0606/Vision-Matters.); 提出视觉扰动框架增强多模态推理的感知鲁棒性，无需算法修改或额外训练数据。|
|📝 更新|From Drawings to Decisions: A Hybrid Vision-Language Framework for Parsing 2D Engineering Drawings into Structured Manufacturing Knowledge|从图纸到决策：一种将二维工程图纸解析为结构化制造知识的混合视觉-语言框架|Muhammad Tayyab Khan, Lequn Chen, Zane Yong, Jun Ming Tan, Wenhe Feng, Seung Ki Moon|<http://arxiv.org/pdf/2506.17374v2>|提出了一种结合旋转感知检测与视觉语言解析的框架，高效从2D工程图纸提取结构化制造知识。|
|🆕 发布|VividFace: High-Quality and Efficient One-Step Diffusion For Video Face Enhancement|《VividFace：高质量且高效的一步扩散视频面部增强方法》|Shulian Zhang, Yong Guo, Long Peng, Ziyang Wang, Ye Chen, Wenbo Li, Xiao Zhang, Yulun Zhang .etc.|<http://arxiv.org/pdf/2509.23584v1>|提出了一种高效的一步扩散框架VividFace，通过单步映射提升视频人脸质量，同时保持时序一致性。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unified Multi-Modal Interactive & Reactive 3D Motion Generation via Rectified Flow|通过修正流实现统一的多模态交互式与反应式三维运动生成|Prerit Gupta, Shourya Verma, Ananth Grama, Aniket Bera|<http://arxiv.org/pdf/2509.24099v1>|提出了一种统一的多模态交互式与反应式三维运动生成框架，通过修正流提高了运动合成的真实感和效率。|
|🆕 发布|Autoregressive Video Generation beyond Next Frames Prediction|超出下一帧预测的自回归视频生成|Sucheng Ren, Chen Chen, Zhenbang Wang, Liangchen Song, Xiangxin Zhu, Alan Yuille, Yinfei Yang, Jiasen Lu|<http://arxiv.org/pdf/2509.24081v1>|提出了一种视频生成框架VideoAR，通过使用时空立方体作为预测单元，突破了传统帧级预测限制，提升了...|
|📝 更新|BrainPath: Generating Subject-Specific Brain Aging Trajectories|《BrainPath：生成个体特定的大脑衰老轨迹》|Yifan Li, Javad Sohankar, Ji Luo, Jing Li, Yi Su|<http://arxiv.org/pdf/2508.16667v2>|提出BrainPath模型，通过3D生成框架预测个体大脑老化轨迹，实现精准大脑老化建模。|
|🆕 发布|SIE3D: Single-image Expressive 3D Avatar generation via Semantic Embedding and Perceptual Expression Loss|单张图像表情三维虚拟形象生成：通过语义嵌入与感知表情损失方法|Zhiqi Huang, Dulongkai Cui, Jinglu Hu|<http://arxiv.org/pdf/2509.24004v1>|[代码](https://blazingcrystal1747.github.io/SIE3D); 提出SIE3D框架，通过融合图像特征与文本语义生成具有精确表情控制的3D头像。|
|📝 更新|Interaction Field Matching: Overcoming Limitations of Electrostatic Models|交互场匹配：克服静电模型局限性|Stepan I. Manukhov, Alexander Kolesov, Vladimir V. Palyulin, Alexander Korotin|<http://arxiv.org/pdf/2506.02950v2>|提出Interaction Field Matching方法，扩展了电场匹配模型，解决了复杂电场建模...|
|📝 更新|3D-LATTE: Latent Space 3D Editing from Textual Instructions|3D-LATTE：基于文本指令的潜在空间三维编辑|Maria Parelli, Michael Oechsle, Michael Niemeyer, Federico Tombari, Andreas Geiger|<http://arxiv.org/pdf/2509.00269v2>|提出了一种无需训练的3D模型编辑方法，通过文本指令在潜在空间中直接操纵3D几何结构，实现了高质量、精...|
|🆕 发布|ColLab: A Collaborative Spatial Progressive Data Engine for Referring Expression Comprehension and Generation|“ColLab：一种用于指代表达式理解和生成的协作空间渐进数据引擎”|Shilan Zhang, Jirui Huang, Ruilin Yao, Cong Wang, Yaxiong Chen, Peng Xu, Shengwu Xiong|<http://arxiv.org/pdf/2509.23955v1>|提出ColLab，一种无需人工监督的自动化数据生成引擎，通过多模态模型交互和空间增强技术提升指代表达...|
|🆕 发布|MoReact: Generating Reactive Motion from Textual Descriptions|文本驱动的动态反应生成：从文本描述中生成反应性运动|Xiyan Xu, Sirui Xu, Yu-Xiong Wang, Liang-Yan Gui|<http://arxiv.org/pdf/2509.23911v1>|[代码](https://xiyan-xu.github.io/MoReactWebPage.); 提出了一种基于文本描述生成反应性动作的方法，通过分离全局轨迹和局部动作生成，提高了交互的适应性和真实...|
|🆕 发布|EditScore: Unlocking Online RL for Image Editing via High-Fidelity Reward Modeling|编辑评分：通过高保真度奖励建模解锁在线强化学习在图像编辑中的应用|Xin Luo, Jiahao Wang, Chenyuan Wu, Shitao Xiao, Xiyan Jiang, Defu Lian, Jiajun Zhang, Dong Liu .etc.|<http://arxiv.org/pdf/2509.23909v1>|提出EditScore，一种高保真度奖励模型，有效解锁在线强化学习在图像编辑中的应用。|
|🆕 发布|Not All Tokens are Guided Equal: Improving Guidance in Visual Autoregressive Models|“并非所有标记都受到同等指导：提高视觉自回归模型中的指导效果”|Ky Dan Nguyen, Hoang Lam Tran, Anh-Dung Dinh, Daochang Liu, Weidong Cai, Xiuying Wang, Chang Xu|<http://arxiv.org/pdf/2509.23876v1>|提出信息地指导机制IGG，通过注意力将指导信号锚定在关键语义区域，提升了视觉自回归模型的生成质量。|
|📝 更新|Semantic Discrepancy-aware Detector for Image Forgery Identification|图像伪造识别中的语义差异感知检测器|Ziye Wang, Minghang Yu, Chunyan Xu, Zhen Cui|<http://arxiv.org/pdf/2508.12341v3>|[代码](https://github.com/wzy1111111/SSD.); 提出了一种语义差异感知检测器，通过重建学习对齐伪造和语义概念空间，有效提升图像伪造检测性能。|
|🆕 发布|Towards Fine-Grained Text-to-3D Quality Assessment: A Benchmark and A Two-Stage Rank-Learning Metric|面向细粒度文本到3D质量评估：一个基准和一种两阶段排名学习度量方法|Bingyang Cui, Yujie Zhang, Qi Yang, Zhu Li, Yiling Xu|<http://arxiv.org/pdf/2509.23841v1>|[代码](https://cbysjtu.github.io/Rank2Score); 提出全新T23D-CompBench基准和Rank2Score评估指标，有效提升了文本到3D模型质量...|
|📝 更新|PERSE: Personalized 3D Generative Avatars from A Single Portrait|个性化单张肖像生成的三维生成式虚拟化身：PERSE|Hyunsoo Cha, Inhee Lee, Hanbyul Joo|<http://arxiv.org/pdf/2412.21206v2>|提出了一种从单张肖像创建个性化3D生成式头像的方法，实现了连续且独立的面部属性编辑。|
|🆕 发布|Controllable Generation of Large-Scale 3D Urban Layouts with Semantic and Structural Guidance|具有语义和结构指导的大规模三维城市布局的可控生成|Mengyuan Niu, Xinxin Zhuo, Ruizhe Wang, Yuyue Huang, Junyan Yang, Qiao Wang|<http://arxiv.org/pdf/2509.23804v1>|提出了一种结合几何与语义属性的3D城市布局生成框架，实现了可控的大规模城市模型生成。|
|🆕 发布|GenView++: Unifying Adaptive View Generation and Quality-Driven Supervision for Contrastive Representation Learning|GenView++：统一自适应视角生成与质量驱动监督以用于对比表征学习|Xiaojie Li, Bei Wang, Jianlong Wu, Yue Yu, Liqiang Nie, Min Zhang|<http://arxiv.org/pdf/2509.23770v1>|[代码](https://github.com/xiaojieli0903/GenViewPlusPlus.); GenView++通过自适应视图生成和多维度质量驱动的对比学习，提升了对比表示学习的多样性和有效性。|
|🆕 发布|UniAlignment: Semantic Alignment for Unified Image Generation, Understanding, Manipulation and Perception|统一对齐：用于统一图像生成、理解、操作和感知的语义对齐|Xinyang Song, Libin Wang, Weining Wang, Shaozhen Liu, Dandan Zheng, Jingdong Chen, Qi Li, Zhenan Sun|<http://arxiv.org/pdf/2509.23760v1>|提出UniAlignment框架，通过双流扩散训练策略提升多模态任务中的语义一致性和指令跟随鲁棒性。|
|📝 更新|Continuous Speculative Decoding for Autoregressive Image Generation|连续投机解码用于自回归图像生成|Zili Wang, Robert Zhang, Kun Ding, Qi Yang, Fei Li, Shiming Xiang|<http://arxiv.org/pdf/2411.11925v2>|[代码](https://github.com/MarkXCloud/CSpD); 提出连续预测解码方法，加速了连续视觉自回归模型的图像生成速度，同时保持了生成质量。|
|🆕 发布|HieraTok: Multi-Scale Visual Tokenizer Improves Image Reconstruction and Generation|层次化标记：多尺度视觉标记器提高图像重建与生成质量|Cong Chen, Ziyuan Huang, Cheng Zou, Muzhi Zhu, Kaixiang Ji, Jiajia Liu, Jingdong Chen, Hao Chen .etc.|<http://arxiv.org/pdf/2509.23736v1>|提出多尺度视觉标记器HieraTok，通过多尺度采样和尺度因果注意力机制，提升了图像重建和生成的性能...|
|📝 更新|Durian: Dual Reference Image-Guided Portrait Animation with Attribute Transfer|榴莲：基于双重参考图像引导的属性迁移肖像动画|Hyunsoo Cha, Byungjun Kim, Hanbyul Joo|<http://arxiv.org/pdf/2509.04434v2>|提出Durian方法，通过自重构训练实现无需配对数据的跨身份属性转移，实现肖像动画生成。|
|🆕 发布|M3DLayout: A Multi-Source Dataset of 3D Indoor Layouts and Structured Descriptions for 3D Generation|M3DLayout：一种用于三维生成的三维室内布局和多源结构化描述数据集|Yiheng Zhang, Zhuojiang Cai, Mingdao Wang, Meitong Guo, Tianxiao Li, Li Lin, Yuwang Wang|<http://arxiv.org/pdf/2509.23728v1>|提出了M3DLayout，一个大规模多源室内布局数据集，通过整合真实扫描、专业CAD设计和程序生成场...|
|🆕 发布|StrucADT: Generating Structure-controlled 3D Point Clouds with Adjacency Diffusion Transformer|结构控制的点云生成：基于邻接扩散变换器的3D点云生成|Zhenyu Shu, Jiajun Shen, Zhongui Chen, Xiaoguang Han, Shiqing Xin|<http://arxiv.org/pdf/2509.23709v1>|首次提出通过形状结构控制3D点云生成，实现用户指定形状结构的高质量点云生成。|
|🆕 发布|HIVTP: A Training-Free Method to Improve VLMs Efficiency via Hierarchical Visual Token Pruning Using Middle-Layer-Based Importance Score|HIVTP：一种基于中层重要性评分的层次视觉标记剪枝来提高大型视觉语言模型效率的无训练方法|Jingqi Xu, Jingxi Lu, Chenghao Li, Sreetama Sarkar, Peter A. Beerel|<http://arxiv.org/pdf/2509.23663v1>|提出了一种无需训练的视觉标记剪枝方法HIVTP，通过中层注意力图评估重要性，有效提升了视觉语言模型的...|
|🆕 发布|Sparse-Up: Learnable Sparse Upsampling for 3D Generation with High-Fidelity Textures|稀疏上采样：用于生成高保真纹理的三维模型的可学习稀疏上采样|Lu Xiao, Jiale Zhang, Yang Liu, Taicheng Huang, Xin Tian|<http://arxiv.org/pdf/2509.23646v1>|提出Sparse-Up方法，通过稀疏体素和表面定位有效保持3D生成物的高频纹理细节。|
|📝 更新|Score Replacement with Bounded Deviation for Rare Prompt Generation|分数替换带限界偏差的稀有提示生成|Bo-Kai Ruan, Zi-Xiang Ni, Bo-Lun Huang, Teng-Fang Hsiao, Hong-Han Shuai|<http://arxiv.org/pdf/2505.20808v3>|提出了一种自适应的分数替换策略，有效解决了生成模型处理罕见概念时的性能问题。|
|🆕 发布|MotionVerse: A Unified Multimodal Framework for Motion Comprehension, Generation and Editing|《MotionVerse：一种统一的多模态框架，用于运动理解、生成与编辑》|Ruibing Hou, Mingshuang Luo, Hongyu Pan, Hong Chang, Shiguang Shan|<http://arxiv.org/pdf/2509.23635v1>|提出了一种统一的多模态框架MotionVerse，利用大型语言模型理解和生成人体运动，通过独特的编码...|
|📝 更新|Disentangling Regional Primitives for Image Generation|解耦区域基元以生成图像|Zhengting Chen, Lei Cheng, Lianghui Ding, Liang Lin, Quanshi Zhang|<http://arxiv.org/pdf/2410.04421v3>|提出了一种分解图像生成中基础特征组件的方法，通过叠加这些组件生成完整图像。|
|🆕 发布|DiffInk: Glyph- and Style-Aware Latent Diffusion Transformer for Text to Online Handwriting Generation|DiffInk：字形和风格感知的潜在扩散变换器用于文本到在线手写生成|Wei Pan, Huiguo He, Hiuyi Cheng, Yilin Shi, Lianwen Jin|<http://arxiv.org/pdf/2509.23624v1>|DiffInk通过首个全行手写生成框架，实现了字符内容与书写风格的分离，提升了生成效率和准确性。|
|🆕 发布|ZeroScene: A Zero-Shot Framework for 3D Scene Generation from a Single Image and Controllable Texture Editing|零样本场景：从单张图像生成三维场景的零样本框架及可控纹理编辑|Xiang Tang, Ruotong Li, Xiaopeng Fan|<http://arxiv.org/pdf/2509.23607v1>|提出ZeroScene框架，通过零样本学习实现单张图像到三维场景重建及可控纹理编辑。|
|🆕 发布|InteractMove: Text-Controlled Human-Object Interaction Generation in 3D Scenes with Movable Objects|《InteractMove：在具有可移动对象的3D场景中基于文本控制的行人-对象交互生成》|Xinhao Cai, Minghang Zheng, Xin Jin, Yang Liu|<http://arxiv.org/pdf/2509.23612v1>|提出了一种文本控制的3D场景中可移动物体的人机交互生成方法，解决了现有数据集不足和模型挑战。|
|🆕 发布|RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization|RobuQ：通过稳健激活量化将DiTs推进至W1.58A2|Kaicheng Yang, Xun Zhang, Haotong Qin, Yucheng Lin, Kaisen Yang, Xianglong Yan, Yulun Zhang|<http://arxiv.org/pdf/2509.23582v1>|[代码](https://github.com/racoonykc/RobuQ); 提出RobuQ框架，通过稳健激活量化实现DiTs在极低比特设置下的高性能图像生成。|
|🆕 发布|Towards Interpretable Visual Decoding with Attention to Brain Representations|面向脑表征注意的可解释视觉解码方法|Pinyuan Feng, Hossein Adeli, Wenxuan Guo, Fan Cheng, Ethan Hwang, Nikolaus Kriegeskorte|<http://arxiv.org/pdf/2509.23566v1>|提出 NeuroAdapter，直接利用大脑表征指导生成模型，提高了视觉解码的透明度和质量。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Token Painter: Training-Free Text-Guided Image Inpainting via Mask Autoregressive Models|"Token Painter：通过掩码自回归模型实现无需训练的文本引导图像修复"|Longtao Jiang, Mingfei Han, Lei Chen, Yongqiang Yu, Feng Zhao, Xiaojun Chang, Zhihui Li|<http://arxiv.org/pdf/2509.23919v1>|提出了一种无需训练的基于掩码自回归模型的文本引导图像修复方法，通过信息融合和注意力增强实现了与文本提...|
|🆕 发布|Uni4D-LLM: A Unified SpatioTemporal-Aware VLM for 4D Understanding and Generation|统一四维理解与生成用时空感知的视觉语言模型：Uni4D-LLM|Hanyu Zhou, Gim Hee Lee|<http://arxiv.org/pdf/2509.23828v1>|提出了首个统一的空间时间感知视觉语言模型Uni4D-LLM，实现了4D场景理解和生成的集成。|
|🆕 发布|From Unstable to Playable: Stabilizing Angry Birds Levels via Object Segmentation|从不稳定到可玩：通过物体分割稳定愤怒的小鸟游戏关卡|Mahdi Farrokhimaleki, Parsa Rahmati, Richard Zhao|<http://arxiv.org/pdf/2509.23787v1>|提出了一种基于图像分割和视觉分析的修复方法，显著提升了自动生成的游戏关卡稳定性和可玩性。|
|📝 更新|VFRTok: Variable Frame Rates Video Tokenizer with Duration-Proportional Information Assumption|VFRTok：基于时长比例信息假设的可变帧率视频编码器|Tianxiong Zhong, Xingye Tian, Boyuan Jiang, Xuebo Wang, Xin Tao, Pengfei Wan, Zhiwei Zhang|<http://arxiv.org/pdf/2505.12053v2>|[代码](https://github.com/KwaiVGI/VFRTok.); 提出了一种基于Transformer的变帧率视频编码器VFRTok，通过时间长度比例假设优化信息容量...|
|📝 更新|Leveraging BEV Paradigm for Ground-to-Aerial Image Synthesis|利用鸟瞰图范式进行地面到空中图像合成|Junyan Ye, Jun He, Weijia Li, Zhutao Lv, Yi Lin, Jinhua Yu, Haote Yang, Conghui He|<http://arxiv.org/pdf/2408.01812v5>|[代码](https://opendatalab.github.io/skydiffusion); 提出SkyDiffusion方法，利用BEV范式和扩散模型实现从地面视角到鸟瞰视角的图像合成。|
|📝 更新|OViP: Online Vision-Language Preference Learning for VLM Hallucination|在线视觉-语言偏好学习以减少VLM幻觉|Shujun Liu, Siyuan Wang, Zejun Li, Jianxiang Wang, Cheng Zeng, Zhongyu Wei|<http://arxiv.org/pdf/2505.15963v2>|[代码](https://github.com/lsjlsj35/Online-Vision-Language-Preference-Learning-for-VLM-Hallucination.); 提出在线视觉语言偏好学习方法，通过动态构建对比训练数据减少大型视觉语言模型幻觉现象，提高训练效率。|
|📝 更新|SimpleGVR: A Simple Baseline for Latent-Cascaded Video Super-Resolution|简单GVR：用于潜在级联视频超分辨率的简单基线|Liangbin Xie, Yu Li, Shian Du, Menghan Xia, Xintao Wang, Fanghua Yu, Ziyan Chen, Pengfei Wan .etc.|<http://arxiv.org/pdf/2506.19838v3>|提出了一种高效的级联视频超分辨率框架，通过优化训练和推理过程显著提升分辨率输出质量。|
|🆕 发布|Griffin: Generative Reference and Layout Guided Image Composition|“Griffin：生成性参考与布局引导的图像合成”|Aryan Mikaeili, Amirhossein Alimohammadi, Negar Hassanpour, Ali Mahdavi-Amiri, Andrea Tagliasacchi|<http://arxiv.org/pdf/2509.23643v1>|提出了一种基于图像参考和布局引导的图像生成方法，实现了对图像内容和布局的精细控制。|
|🆕 发布|From Fields to Splats: A Cross-Domain Survey of Real-Time Neural Scene Representations|从场到斑：实时神经场景表示的跨领域综述|Javed Ahmad, Penggang Gao, Donatien Delehelle, Mennuti Canio, Nikhil Deshpande, Jesús Ortiz, Darwin G. Caldwell, Yonas Teodros Tefera|<http://arxiv.org/pdf/2509.23555v1>|系统比较了3D Gaussian Splatting与NeRF，揭示了其在实时渲染和场景理解中的效率...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Representation Entanglement for Generation: Training Diffusion Transformers Is Much Easier Than You Think|表示纠缠用于生成：训练扩散变换器比您想象的要容易得多|Ge Wu, Shen Zhang, Ruijing Shi, Shanghua Gao, Zhenyuan Chen, Lei Wang, Zhaowei Chen, Hongcheng Gao .etc.|<http://arxiv.org/pdf/2507.01467v2>|[代码](https://github.com/Martinser/REG.); 提出了一种名为 Representation Entanglement for Generation...|
|🆕 发布|Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution|纹理向量量化与重建感知预测的生成超分辨率|Qifan Li, Jiale Zou, Jinhua Zhang, Wei Long, Xinyu Zhou, Shuhang Gu|<http://arxiv.org/pdf/2509.23774v1>|提出了一种针对纹理的向量量化与重建感知预测策略，有效降低量化误差并提升超分辨率图像质量。|
|📝 更新|Vidar: Embodied Video Diffusion Model for Generalist Manipulation|Vidar：一种用于通用操作的具身视频扩散模型|Yao Feng, Hengkai Tan, Xinyi Mao, Chendong Xiang, Guodong Liu, Shuhe Huang, Hang Su, Jun Zhu|<http://arxiv.org/pdf/2507.12898v3>|提出了一种基于视频先验的低样本适应范式 Vidar，通过少量人类演示实现机器人操作的泛化与适应。|
|🆕 发布|VMDiff: Visual Mixing Diffusion for Limitless Cross-Object Synthesis|VMDiff：视觉混合扩散用于无限跨对象合成|Zeren Xiong, Yue Yu, Zedong Zhang, Shuo Chen, Jian Yang, Jun Li|<http://arxiv.org/pdf/2509.23605v1>|提出了一种融合扩散框架VMDiff，有效整合两幅图像生成单一连贯对象，解决了视觉合成中的共存生成和语...|
|🆕 发布|VAMamba: An Efficient Visual Adaptive Mamba for Image Restoration|VAMamba：一种高效视觉自适应蟒蛇算法用于图像复原|Han Hu, Zhuoran Zheng, Liang Li, Chen Lyu|<http://arxiv.org/pdf/2509.23601v1>|[代码](https://github.com/WaterHQH/VAMamba.); VAMamba通过自适应视觉路径和缓存增强特征学习，优化图像修复质量和效率。|
|📝 更新|AGSwap: Overcoming Category Boundaries in Object Fusion via Adaptive Group Swapping|AGSwap：通过自适应组交换在对象融合中克服类别边界|Zedong Zhang, Ying Tai, Jianjun Qian, Jian Yang, Jun Li|<http://arxiv.org/pdf/2509.18699v2>|提出AGSwap方法，通过自适应组交换和更新机制实现跨类别对象融合，解决了现有方法在视觉一致性和融合...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RPG360: Robust 360 Depth Estimation with Perspective Foundation Models and Graph Optimization|RPG360：基于透视基础模型和图优化的鲁棒360度深度估计|Dongki Jung, Jaehoon Choi, Yonghan Lee, Dinesh Manocha|<http://arxiv.org/pdf/2509.23991v1>|提出了一种无需训练的鲁棒360度单目深度估计方法，利用透视基础模型和图优化技术实现深度估计一致性。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|IM360: Large-scale Indoor Mapping with 360 Cameras|IM360：使用360度相机进行大规模室内地图绘制|Dongki Jung, Jaehoon Choi, Yonghan Lee, Dinesh Manocha|<http://arxiv.org/pdf/2502.12545v3>|提出IM360方法，利用全景相机宽视角和球形模型，显著提升室内大规模场景的三维映射效果。|
|🆕 发布|GRS-SLAM3R: Real-Time Dense SLAM with Gated Recurrent State|GRS-SLAM3R：基于门控循环状态的实时稠密SLAM|Guole Shen, Tianchen Deng, Yanbo Wang, Yongtao Chen, Yilin Shen, Jiuming Liu, Jingchuan Wang|<http://arxiv.org/pdf/2509.23737v1>|引入了GRS-SLAM3R框架，通过全局坐标下的连续3D信息聚合，实现了实时稠密SLAM的高精度场景...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CrashSplat: 2D to 3D Vehicle Damage Segmentation in Gaussian Splatting|“CrashSplat：高斯散点映射中的二维到三维车辆损伤分割”|Dragoş-Andrei Chileban, Andrei-Ştefan Bulzan, Cosmin Cernǎzanu-Glǎvan|<http://arxiv.org/pdf/2509.23947v1>|[代码](https://github.com/DragosChileban/CrashSplat.); 提出了一种将2D图像提升至3D的车辆损伤自动检测方法，通过单视图3D高斯散点技术实现精确损伤分割。|
|🆕 发布|FastViDAR: Real-Time Omnidirectional Depth Estimation via Alternative Hierarchical Attention|快速ViDAR：通过交替层次注意力实现实时全方位深度估计|Hangtian Zhao, Xiang Chen, Yizhe Li, Qianhao Wang, Haibo Lu, Fei Gao|<http://arxiv.org/pdf/2509.23733v1>|[代码](https://3f7dfc.github.io/FastVidar); 提出FastViDAR框架，通过交替层次注意力机制和等距圆柱投影融合，实现实时全方位深度估计。|
|📝 更新|Hierarchical MLANet: Multi-level Attention for 3D Face Reconstruction From Single Images|分层MLANet：从单张图像重建三维人脸的多级注意力机制|Danling Cao|<http://arxiv.org/pdf/2509.10024v3>|提出了一种多级注意力网络，实现了从单张自然环境中的人脸图像重建详细的3D人脸模型。|
|🆕 发布|DFG-PCN: Point Cloud Completion with Degree-Flexible Point Graph|DFG-PCN：具有度数可变点图的点云补全|Zhenyu Shu, Jian Yao, Shiqing Xin|<http://arxiv.org/pdf/2509.23703v1>|提出了一种自适应的点云补全框架DFG-PCN，通过智能分配节点度数和融合局部与全局特征，有效提高了复...|
|🆕 发布|OVSeg3R: Learn Open-vocabulary Instance Segmentation from 2D via 3D Reconstruction|OVSeg3R：通过三维重建从二维学习开放词汇实例分割|Hongyang Li, Jinyuan Qu, Lei Zhang|<http://arxiv.org/pdf/2509.23541v1>|提出OVSeg3R方法，通过3D重建将2D感知模型扩展到开放词汇3D实例分割，提升了尾类性能并缩小了...|


## 时序视觉分析 (Temporal Visual Analysis)


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hazy Pedestrian Trajectory Prediction via Physical Priors and Graph-Mamba|通过物理先验和图-Mamba的雾天行人轨迹预测|Jian Chen, Zhuoran Zheng, Han Hu, Guijuan Zhang, Dianjie Lu, Liang Li, Chen Lyu|<http://arxiv.org/pdf/2509.24020v1>|提出了一种结合物理先验和图模型的方法，有效预测雾霾环境下行人轨迹。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FrameMind: Frame-Interleaved Chain-of-Thought for Video Reasoning via Reinforcement Learning|帧思维：通过强化学习进行视频推理的帧交织思维链|Haonan Ge, Yiwei Wang, Kai-Wei Chang, Hang Wu, Yujun Cai|<http://arxiv.org/pdf/2509.24008v1>|FrameMind通过强化学习实现动态视觉信息请求，显著提升视频理解任务的适应性表现。|
|🆕 发布|Video Panels for Long Video Understanding|视频面板：用于长视频理解的方法|Lars Doorenbos, Federico Spurio, Juergen Gall|<http://arxiv.org/pdf/2509.23724v1>|提出了一种将多帧组合为视觉面板的策略，无需训练和调整参数，显著提升了长视频理解性能。|
|🆕 发布|Token Merging via Spatiotemporal Information Mining for Surgical Video Understanding|通过时空信息挖掘进行标记合并以实现手术视频理解|Xixi Jiang, Chen Yang, Dong Zhang, Pingcheng Dong, Xin Yang, Kwang-Ting Cheng|<http://arxiv.org/pdf/2509.23672v1>|提出了一种针对手术视频理解的时空信息挖掘的标记合并方法，有效降低了计算成本同时保持准确性。|
|🆕 发布|ReWatch-R1: Boosting Complex Video Reasoning in Large Vision-Language Models through Agentic Data Synthesis|重看-R1：通过代理数据合成提升大型视觉-语言模型中的复杂视频推理能力|Congzhi Zhang, Zhibin Wang, Yinchao Ma, Jiawei Peng, Yihan Wang, Qiang Zhou, Jun Song, Bo Zheng|<http://arxiv.org/pdf/2509.23652v1>|通过模拟人类“重看”过程的Multi-Agent ReAct框架，ReWatch-R1解决了视频推理...|
|📝 更新|Audio-centric Video Understanding Benchmark without Text Shortcut|以音频为中心的无文本捷径视频理解基准|Yudong Yang, Jimin Zhuang, Guangzhi Sun, Changli Tang, Yixuan Li, Peihan Li, Yifan Jiang, Wei Li .etc.|<http://arxiv.org/pdf/2503.19951v3>|[代码](https://github.com/lark-png/AVUT.); 提出音频中心的视频理解基准，解决文本捷径问题，全面评估多模态语言模型的音频理解能力。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AssemblyHands-X: Modeling 3D Hand-Body Coordination for Understanding Bimanual Human Activities|装配手X：建模三维手-身体协调以理解双臂人类活动|Tatsuro Banno, Takehiko Ohkawa, Ruicong Liu, Ryosuke Furuta, Yoichi Sato|<http://arxiv.org/pdf/2509.23888v1>|提出AssemblyHands-X，首个用于研究双臂活动手身协调的3D无标记基准，提升了动作识别准确...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Second-Order Perspective on Pruning at Initialization and Knowledge Transfer|初始化剪枝与知识迁移的二阶视角研究|Leonardo Iurada, Beatrice Occhiena, Tatiana Tommasi|<http://arxiv.org/pdf/2509.24066v1>|探究初始化剪枝对预训练模型的影响，发现无需特定任务数据即可保持零样本性能。|
|🆕 发布|MSD-KMamba: Bidirectional Spatial-Aware Multi-Modal 3D Brain Segmentation via Multi-scale Self-Distilled Fusion Strategy|MSD-KMamba：基于多尺度自蒸馏融合策略的双向空间感知多模态三维脑分割|Dayu Tan, Ziwei Zhang, Yansan Su, Xin Peng, Yike Dai, Chunhou Zheng, Weimin Zhong|<http://arxiv.org/pdf/2509.23677v1>|[代码](https://github.com/daimao-zhang/MSD-KMamba.); MSD-KMamba通过融合双向空间感知与多尺度自蒸馏策略，实现了高效准确的3D脑部图像分割。|
|🆕 发布|Multi-Level Heterogeneous Knowledge Transfer Network on Forward Scattering Center Model for Limited Samples SAR ATR|基于前向散射中心模型的有限样本合成孔径雷达自动目标识别的多级异质知识迁移网络|Chenxi Zhao, Daochang Wang, Siqian Zhang, Gangyao Kuang|<http://arxiv.org/pdf/2509.23596v1>|提出了一种多级异质知识迁移网络，通过迁移纯净的关键目标知识，有效解决了样本数量有限下的合成孔径雷达目...|


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Modality-Tailored Graph Modeling Framework for Urban Region Representation via Contrastive Learning|一种面向城市区域表示的对比学习定制的模态特异图建模框架|Yaya Zhao, Kaiqi Zhao, Zixuan Tang, Zhiyuan Liu, Xiaoling Lu, Yalei Du|<http://arxiv.org/pdf/2509.23772v1>|提出了一种针对不同模态特性的定制图模型框架MTGRR，通过动态融合策略优化城市区域表征。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Neural-Augmented Kelvinlet for Real-Time Soft Tissue Deformation Modeling|神经增强的凯尔文莱特模型用于实时软组织形变建模|Ashkan Shahbazi, Kyvia Pereira, Jon S. Heiselman, Elaheh Akbari, Annie C. Benson, Sepehr Seifi, Xinyuan Liu, Garrison L. Johnston .etc.|<http://arxiv.org/pdf/2506.08043v2>|提出了一种结合物理信息的神经网络框架，实现了实时软组织变形的高精度模拟。|
|📝 更新|Attentive Dilated Convolution for Automatic Sleep Staging using Force-directed Layout|基于注意力扩张卷积的自动睡眠分期方法，使用力导向布局|Md Jobayer, Md Mehedi Hasan Shawon, Tasfin Mahmud, Md. Borhan Uddin Antor, Arshad M. Chowdhury|<http://arxiv.org/pdf/2409.01962v2>|提出了一种基于深度学习的自动睡眠分期方法，通过注意力扩张卷积网络和力导向布局，实现了高准确度与低计算...|
|🆕 发布|AQUAIR: A High-Resolution Indoor Environmental Quality Dataset for Smart Aquaculture Monitoring|AQUAIR：用于智能水产养殖监测的高分辨率室内环境质量数据集|Youssef Sabiri, Walid Houmaidi, Ouail El Maadi, Yousra Chtouki|<http://arxiv.org/pdf/2509.24069v1>|介绍了AQUAIR，一个高分辨率室内环境质量数据集，为智能水产养殖监测提供关键数据支持。|
|🆕 发布|Taught Well Learned Ill: Towards Distillation-conditional Backdoor Attack|教会良学好，学坏易成灾：面向蒸馏条件下的后门攻击|Yukun Chen, Boheng Li, Yu Yuan, Leyi Qi, Yiming Li, Tianwei Zhang, Zhan Qin, Kui Ren|<http://arxiv.org/pdf/2509.23871v1>|[代码](https://github.com/WhitolfChen/SCAR.); 提出了一种针对知识蒸馏过程的条件性后门攻击方法SCAR，实现了在教师模型中植入隐蔽后门并在学生模型中...|
|📝 更新|Improving Black-Box Generative Attacks via Generator Semantic Consistency|通过增强生成器语义一致性来改进黑盒生成攻击|Jongoh Jeong, Hunmin Yang, Jaeseok Jeong, Kuk-Jin Yoon|<http://arxiv.org/pdf/2506.18248v5>|提出了一种通过增强生成器内部语义一致性来提升黑盒生成攻击的转移性和效率的方法。|
|🆕 发布|INSTINCT: Instance-Level Interaction Architecture for Query-Based Collaborative Perception|INSTINCT：基于查询的协同感知的实例级交互架构|Yunjiang Xu, Lingzhi Li, Jin Wang, Yupeng Ouyang, Benyuan Yang|<http://arxiv.org/pdf/2509.23700v1>|[代码](https://github.com/CrazyShout/INSTINCT.); INSTINCT通过质量感知筛选、双分支检测路由和跨代理本地实例融合，提升了协同感知准确度并大幅降低...|
|🆕 发布|Automated design of compound lenses with discrete-continuous optimization|离散-连续优化自动设计复合透镜|Arjun Teh, Delio Vicini, Bernd Bickel, Ioannis Gkioulekas, Matthew O'Toole|<http://arxiv.org/pdf/2509.23572v1>|自动优化复合镜头的连续和离散参数，实现更优的清晰度和速度性能。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|$\mathbf{R}^3$: Reconstruction, Raw, and Rain: Deraining Directly in the Bayer Domain|$\mathbf{R}^3$：重建、原始与降雨：直接在拜耳域进行去雨处理|Nate Rothschild, Moshe Kimhi, Avi Mendelson, Chaim Baskin|<http://arxiv.org/pdf/2509.24022v1>|直接在原始Bayer域进行去雨处理，提出信息保持分数评估指标，实现了更优的图像重建效果。|
|🆕 发布|TREAT-Net: Tabular-Referenced Echocardiography Analysis for Acute Coronary Syndrome Treatment Prediction|TREAT-Net：表格参考超声心动图分析用于急性冠脉综合征治疗预测|Diane Kim, Minh Nguyen Nhat To, Sherif Abdalla, Teresa S. M. Tsang, Purang Abolmaesumi, and Christina Luong|<http://arxiv.org/pdf/2509.23999v1>|提出TREAT-Net模型，通过结合心脏超声视频和临床记录，预测急性冠脉综合征治疗方案，提高诊断效率...|
|🆕 发布|Gaze Estimation for Human-Robot Interaction: Analysis Using the NICO Platform|人机交互中的视线估计：基于NICO平台的分析|Matej Palider, Omar Eldardeer, Viktor Kocur|<http://arxiv.org/pdf/2509.24001v1>|评估了现有凝视估计方法在人类-机器人交互共享工作空间中的表现，并引入了新的标注数据集。|
|🆕 发布|Efficient Multi-turn RL for GUI Agents via Decoupled Training and Adaptive Data Curation|通过解耦训练和自适应数据策展的高效多轮强化学习用于GUI智能体|Pengxiang Li, Zechen Hu, Zirui Shang, Jingrong Wu, Yang Liu, Hui Liu, Zhi Gao, Chenrui Shi .etc.|<http://arxiv.org/pdf/2509.23866v1>|提出了一种高效的GUI智能体多轮交互训练框架DART，通过解耦训练和自适应数据筛选显著提升训练效率和...|
|📝 更新|XTransfer: Modality-Agnostic Few-Shot Model Transfer for Human Sensing at the Edge|边缘计算中面向人体感知的无模态迁移少量样本学习模型：XTransfer|Yu Zhang, Xi Zhang, Hualin zhou, Xinyuan Chen, Shang Gao, Hong Jia, Jianfei Yang, Yuankai Qi .etc.|<http://arxiv.org/pdf/2506.22726v2>|提出XTransfer方法，实现跨模态少量样本的模型迁移，降低边缘系统的人体感知应用成本。|
|🆕 发布|ResAD++: Towards Class Agnostic Anomaly Detection via Residual Feature Learning|残差特征学习驱动的面向类别无关异常检测的ResAD++|Xincheng Yao, Chao Shi, Muming Zhao, Guangtao Zhai, Chongyang Zhang|<http://arxiv.org/pdf/2509.23741v1>|[代码](https://github.com/xcyao00/ResAD.); 提出了一种无类别依赖的异常检测框架ResAD++，通过学习残差特征分布而非原始特征分布，有效实现特征...|
|🆕 发布|RAVEN: Resilient Aerial Navigation via Open-Set Semantic Memory and Behavior Adaptation|RAVEN：通过开集语义记忆与行为适应实现鲁棒空中导航|Seungchan Kim, Omar Alama, Dmytro Kurdydyk, John Keller, Nikhil Keetha, Wenshan Wang, Yonatan Bisk, Sebastian Scherer|<http://arxiv.org/pdf/2509.23563v1>|RAVEN通过结合3D语义记忆和行为树框架，实现了无人机在复杂室外环境中的长距离语义导航。|
|🆕 发布|Calibrated and Resource-Aware Super-Resolution for Reliable Driver Behavior Analysis|校准与资源感知的超分辨率技术用于可靠的驾驶员行为分析|Ibne Farabi Shihab, Weiheng Chai, Jiyang Wang, Sanjeda Akter, Senem Velipasalar Gursoy, Anuj Sharma|<http://arxiv.org/pdf/2509.23535v1>|提出了一种资源感知的适应性超分辨率框架，优化了模型校准和关键事件的高精确度-召回率，显著提升了驾驶行...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|End-to-end Topographic Auditory Models Replicate Signatures of Human Auditory Cortex|端到端拓扑听觉模型复制人类听觉皮层特征签名|Haider Al-Tahan, Mayukh Deb, Jenelle Feather, N. Apurva Ratan Murty|<http://arxiv.org/pdf/2509.24039v1>|引入 wiring-length 约束，提出 TopoAudio 模型，实现了听觉处理中的生物拓扑结...|
|🆕 发布|AutoPrune: Each Complexity Deserves a Pruning Policy|自动剪枝：每种复杂度都值得一种剪枝策略|Hanshi Wang, Yuhao Xu, Zekun Xu, Jin Gao, Yufan Liu, Weiming Hu, Ke Wang, Zhipeng Zhang|<http://arxiv.org/pdf/2509.23931v1>|[代码](https://github.com/AutoLab-SAI-SJTU/AutoPrune.); 提出了一种自适应复杂度的剪枝策略AutoPrune，根据输入样本和任务的不同复杂度动态调整剪枝策略，...|
|🆕 发布|AISHELL6-whisper: A Chinese Mandarin Audio-visual Whisper Speech Dataset with Speech Recognition Baselines|AISHELL6-whisper：一个中文普通话音频-视觉低语语音数据集及语音识别基线|Cancan Li, Fei Su, Juan Liu, Hui Bu, Yulong Wan, Hongbin Suo, Ming Li|<http://arxiv.org/pdf/2509.23833v1>|[代码](https://zutm.github.io/AISHELL6-Whisper.); 构建了首个大规模中文音频-视觉低语语音识别数据集，并提出了基于Whisper-Flamingo框架的...|
|📝 更新|Face-voice Association in Multilingual Environments (FAME) 2026 Challenge Evaluation Plan|多语种环境中人脸-语音关联（FAME）2026挑战评估计划|Marta Moscati, Ahmed Abdullah, Muhammad Saad Saeed, Shah Nawaz, Rohan Kumar Das, Muhammad Zaigham Zaheer, Junaid Mir, Muhammad Haroon Yousaf .etc.|<http://arxiv.org/pdf/2508.04592v2>|提出了一种针对多语言环境的 face-voice 关联挑战，使用专门构建的 MAV-Celeb 数据...|
|📝 更新|Joint Memory Frequency and Computing Frequency Scaling for Energy-efficient DNN Inference|联合内存频率与计算频率缩放以实现节能的深度神经网络推理|Yunchu Han, Zhaojun Nan, Sheng Zhou, Zhisheng Niu|<http://arxiv.org/pdf/2509.17970v3>|提出了一种结合内存频率和计算频率调整的方法，有效降低资源受限设备上的神经网络推理能耗。|
|📝 更新|TRIPS: Efficient Vision-and-Language Pre-training with Text-Relevant Image Patch Selection|TRIPS：基于文本相关图像块选择的高效视觉与语言预训练|Chaoya Jiang, Haiyang Xu, Chenliang Li, Miang Yan, Wei Ye, Shikun Zhang, Bin Bi, Songfang Huang|<http://arxiv.org/pdf/2305.04474v4>|提出TRIPS模型，通过文本引导的图像块选择减少计算负担，实现高效视觉与语言预训练。|
|🆕 发布|HomeSafeBench: A Benchmark for Embodied Vision-Language Models in Free-Exploration Home Safety Inspection|《HomeSafeBench：自由探索家庭安全检查中基于具身视觉语言模型的基准测试》|Siyuan Gao, Jiashu Yao, Haoyu Wen, Yuhang Guo, Zeming Liu, Heyan Huang|<http://arxiv.org/pdf/2509.23690v1>|提出HomeSafeBench基准，通过动态第一人称视角图像评估视觉语言模型在家庭安全检查中的能力。|
|🆕 发布|Efficient Audio-Visual Speech Separation with Discrete Lip Semantics and Multi-Scale Global-Local Attention|基于离散唇部语义和多层次全局-局部注意力的高效音频-视觉语音分离|Kai Li, Kejun Gao, Xiaolin Hu|<http://arxiv.org/pdf/2509.23610v1>|提出了一种高效的音频视觉语音分离方法Dolphin，通过轻量级视频编码和全局-局部注意力机制，实现了...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Controllable Adversarial Makeup for Privacy via Text-Guided Diffusion|通过文本引导扩散实现隐私保护的可控对抗性化妆|Youngjin Kwon, Xiao Zhang|<http://arxiv.org/pdf/2503.10549v3>|提出了一种文本引导的扩散框架MASQUE，通过生成局部对抗性妆容有效对抗人脸识别，提高了隐私保护的成...|
|🆕 发布|GroupCoOp: Group-robust Fine-tuning via Group Prompt Learning|群组协作：通过群组提示学习实现的群组稳健微调|Nayeong Kim, Seong Joon Oh, Suha Kwak|<http://arxiv.org/pdf/2509.23781v1>|提出GroupCoOp算法，通过使用特定群体文本提示增强模型对不平衡数据集的群体鲁棒性。|
|🆕 发布|Accuracy-Robustness Trade Off via Spiking Neural Network Gradient Sparsity Trail|通过尖峰神经网络梯度稀疏性轨迹实现准确性与鲁棒性的权衡|Nhan T. Luu|<http://arxiv.org/pdf/2509.23762v1>|发现脉冲神经网络在特定架构下自然具有梯度稀疏性，实现了无需额外正则化的先进对抗防御性能。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GBSK: Skeleton Clustering via Granular-ball Computing and Multi-Sampling for Large-Scale Data|GBSK：基于颗粒球计算与多采样的大规模数据骨架聚类|Yewang Chen, Junfeng Li, Shuyin Xia, Qinghong Lai, Xinbo Gao, Guoyin Wang, Dongdong Cheng, Yi Liu .etc.|<http://arxiv.org/pdf/2509.23742v1>|[代码](https://github.com/XFastDataLab/GBSK); 提出了一种基于颗粒球技术和多采样的可扩展骨架聚类算法GBSK，有效处理大规模数据集的聚类任务并保持高...|
|📝 更新|FA: Forced Prompt Learning of Vision-Language Models for Out-of-Distribution Detection|FA：视觉语言模型在分布外检测中的强制提示学习|Xinhua Lu, Runhe Lai, Yanqi Wu, Kanghao Chen, Wei-Shi Zheng, Ruixuan Wang|<http://arxiv.org/pdf/2507.04511v3>|[代码](https://github.com/0xFAFA/FA.); 提出了一种基于强制提示学习的新框架，利用现有数据提升视觉模型对异常分布样本的检测能力。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GPS-MTM: Capturing Pattern of Normalcy in GPS-Trajectories with self-supervised learning|GPS-MTM：利用自监督学习捕捉GPS轨迹中的正常模式|Umang Garg, Bowen Zhang, Anantanjit Subrahmanya, Chandrakanth Gudavalli, BS Manjunath|<http://arxiv.org/pdf/2509.24031v1>|提出了一种自监督学习的GPSMasked Trajectory Transformer模型，捕捉人类...|
|🆕 发布|Joint Superpixel and Self-Representation Learning for Scalable Hyperspectral Image Clustering|联合超像素与自表示学习用于可扩展的高光谱图像聚类|Xianlu Li, Nicolas Nadisic, Shaoguang Huang, Aleksandra Pizurica|<http://arxiv.org/pdf/2509.24027v1>|提出了一种将超像素分割与子空间聚类联合优化的框架，提高了高光谱图像聚类效率并保持了光谱与空间结构。|
|🆕 发布|A Novel Hybrid Deep Learning and Chaotic Dynamics Approach for Thyroid Cancer Classification|一种新颖的混合深度学习与混沌动力学方法在甲状腺癌分类中的应用|Nada Bouchekout, Abdelkrim Boukabou, Morad Grimes, Yassine Habchi, Yassine Himeur, Hamzah Ali Alkhazaleh, Shadi Atalla, Wathiq Mansoor|<http://arxiv.org/pdf/2509.23968v1>|结合自适应卷积神经网络与混沌动力学的波let方法，实现了甲状腺癌超声图像的高准确率分类。|
|🆕 发布|Learning Encoding-Decoding Direction Pairs to Unveil Concepts of Influence in Deep Vision Networks|学习编码-解码方向对以揭示深度视觉网络中的影响概念|Alexandros Doumanoglou, Kurt Driessens, Dimitrios Zarpalas|<http://arxiv.org/pdf/2509.23926v1>|提出了一种通过学习编码-解码方向对揭示深度视觉网络概念影响的方法，增强了对深度网络的理解和调试能力。|
|🆕 发布|CE-FAM: Concept-Based Explanation via Fusion of Activation Maps|基于概念的解释：通过激活图融合的CE-FAM方法|Michihiro Kuroki, Toshihiko Yamasaki|<http://arxiv.org/pdf/2509.23849v1>|提出了一种基于概念的图像分类解释方法CE-FAM，通过融合激活图揭示了概念及其对预测的贡献。|
|📝 更新|Meta Pruning via Graph Metanetworks : A Universal Meta Learning Framework for Network Pruning|通过图元网络进行元剪枝：一种用于网络剪枝的通用元学习框架|Yewei Liu, Xiyuan Wang, Muhan Zhang|<http://arxiv.org/pdf/2506.12041v2>|[代码](https://github.com/Yewei-Liu/MetaPruning.); 提出了一种通用元学习框架，通过图元网络自动学习网络剪枝策略，实现了广泛的网络类型和剪枝方法的优化。|
|🆕 发布|BioVessel-Net and RetinaMix: Unsupervised Retinal Vessel Segmentation from OCTA Images|生物血管网-网络与视网膜混合：基于OCTA图像的无监督视网膜血管分割|Cheng Huang, Weizheng Xie, Fan Gao, Yutong Liu, Ruoling Wu, Zeyu Han, Jingxi Qiu, Xiangxiang Wang .etc.|<http://arxiv.org/pdf/2509.23617v1>|[代码](https://github.com/VikiXie/SatMar8.); 提出无监督的BioVessel-Net框架，利用生物统计特性进行血管分割，无需标注数据，准确度高且计...|
|🆕 发布|StolenLoRA: Exploring LoRA Extraction Attacks via Synthetic Data|《StolenLoRA：通过合成数据探索LoRA提取攻击》|Yixu Wang, Yan Teng, Yingchun Wang, Xingjun Ma|<http://arxiv.org/pdf/2509.23594v1>|提出了一种名为StolenLoRA的攻击方法，利用合成数据和大型语言模型提取LoRA适配模型功能，成...|
|📝 更新|BlockFUL: Enabling Unlearning in Blockchained Federated Learning|区块链联邦学习中实现遗忘功能的BlockFUL方法|Xiao Liu, Mingyuan Li, Xu Wang, Guangsheng Yu, Wei Ni, Lixiang Li, Haipeng Peng, Renping Liu|<http://arxiv.org/pdf/2402.16294v3>|提出BlockFUL框架，通过双链结构实现联邦学习中的高效遗忘操作，降低数据依赖和计算成本。|
|🆕 发布|Pancreas Part Segmentation under Federated Learning Paradigm|胰腺部位分割的联邦学习框架下的研究|Ziliang Hong, Halil Ertugrul Aktas, Andrea Mia Bejar, Katherine Wu, Hongyi Pan, Gorkem Durak, Zheyuan Zhang, Sait Kayali .etc.|<http://arxiv.org/pdf/2509.23562v1>|首次提出基于联邦学习的胰腺分区MRI分割方法，解决了数据稀缺和隐私保护问题。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Focusing on What Matters: Object-Agent-centric Tokenization for Vision Language Action models|关注重点：面向视觉语言动作模型的物体-智能体中心化标记化方法|Rokas Bendikas, Daniel Dijkman, Markus Peschl, Sanjay Haresh, Pietro Mazzaglia|<http://arxiv.org/pdf/2509.23655v1>|提出对象-代理中心化的视觉输入标记方法，减少计算成本同时保持性能。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mash, Spread, Slice! Learning to Manipulate Object States via Visual Spatial Progress|“混合、展开、切片！通过视觉空间进程学习操纵物体状态”|Priyanka Mandikal, Jiaheng Hu, Shivin Dass, Sagnik Majumder, Roberto Martín-Martín, Kristen Grauman|<http://arxiv.org/pdf/2509.24129v1>|提出了一种统一框架SPARTA，通过视觉感知实现物体状态变化的精细操控，无需演示或模拟。|
|🆕 发布|Uncovering Grounding IDs: How External Cues Shape Multi-Modal Binding|揭示基础ID：外部线索如何塑造多模态绑定|Hosein Hasani, Amirmohammad Izadi, Fatemeh Askari, Mobin Bagherian, Sadegh Mohammadian, Mohammad Izadi, Mahdieh Soleymani Baghshah|<http://arxiv.org/pdf/2509.24072v1>|揭示了外部线索如何通过 Grounding IDs 加强多模态绑定，提升视觉语言模型的精确度。|
|📝 更新|Self-Supervised Geometry-Guided Initialization for Robust Monocular Visual Odometry|自监督几何引导初始化以提高单目视觉里程计的鲁棒性|Takayuki Kanai, Igor Vasiljevic, Vitor Guizilini, Kazuhiro Shintani|<http://arxiv.org/pdf/2406.00929v2>|提出利用自监督几何引导初始化，提升单目视觉里程计在动态大运动场景下的鲁棒性。|
|📝 更新|VisionReasoner: Unified Reasoning-Integrated Visual Perception via Reinforcement Learning|《VisionReasoner：通过强化学习实现的统一推理集成的视觉感知》|Yuqi Liu, Tianyuan Qu, Zhisheng Zhong, Bohao Peng, Shu Liu, Bei Yu, Jiaya Jia|<http://arxiv.org/pdf/2505.12081v4>|提出VisionReasoner框架，通过统一奖励机制和认知学习策略，实现了在单个模型中处理多种视觉...|
|🆕 发布|Transparent Visual Reasoning via Object-Centric Agent Collaboration|通过以对象为中心的智能体协作实现透明的视觉推理|Benjamin Teoh, Ben Glocker, Francesca Toni, Avinash Kori|<http://arxiv.org/pdf/2509.23757v1>|提出了一种基于对象中心的解释性AI框架OCEAN，通过多智能体协商实现透明推理和直观可信的解释。|
|🆕 发布|Poivre: Self-Refining Visual Pointing with Reinforcement Learning|"Poivre：基于强化学习的自优化视觉指点"|Wenjie Yang, Zengfeng Huang|<http://arxiv.org/pdf/2509.23746v1>|提出了一种自我修正的视觉定位方法Poivre，通过迭代精炼坐标，结合强化学习提升视觉语言模型性能。|
|📝 更新|Hanfu-Bench: A Multimodal Benchmark on Cross-Temporal Cultural Understanding and Transcreation|汉服-基准：一个关于跨时文化理解与创生的多模态评估基准|Li Zhou, Lutong Yu, Dongchu Xie, Shaohuan Cheng, Wenyan Li, Haizhou Li|<http://arxiv.org/pdf/2506.01565v3>|提出Hanfu-Bench多模态数据集，解决跨时间文化理解和创新设计问题。|
|🆕 发布|RCI: A Score for Evaluating Global and Local Reasoning in Multimodal Benchmarks|RCI：一种用于评估多模态基准中的全局和局部推理的得分|Amit Agarwal, Hitesh Laxmichand Patel, Srikant Panda, Hansa Meghwani, Jyotika Singh, Karan Dua, Paul Li, Tao Sheng .etc.|<http://arxiv.org/pdf/2509.23673v1>|提出RCI评分，首次量化多模态数据集对全局与局部视觉信息的依赖，揭示真实应用中的潜在风险。|
|📝 更新|Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory|“观察、聆听、记忆与推理：具有长期记忆的多模态智能体”|Lin Long, Yichen He, Wentao Ye, Yiyuan Pan, Yuan Lin, Hang Li, Junbo Zhao, Wei Li|<http://arxiv.org/pdf/2508.09736v3>|[代码](https://github.com/bytedance-seed/m3-agent.); 提出M3-Agent框架，融合视觉与听觉输入，实现类似人类的长期记忆与多轮推理能力。|
|📝 更新|VisioMath: Benchmarking Figure-based Mathematical Reasoning in LMMs|VisioMath：在语言模型中基于图形的数学推理基准测试|Can Li, Ying Liu, Ting Zhang, Mei Wang, Hua Huang|<http://arxiv.org/pdf/2506.06727v2>|提出VisioMath基准，针对大模型在细微视觉差异推理上的不足，通过精准图像-文本对齐提升数学问题...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Reversed in Time: A Novel Temporal-Emphasized Benchmark for Cross-Modal Video-Text Retrieval|时间逆转：一种新颖的时序强化基准测试用于跨模态视频-文本检索|Yang Du, Yuqi Liu, Qin Jin|<http://arxiv.org/pdf/2412.19178v2>|[代码](https://github.com/qyr0403/Reversed-in-Time); 提出了RTime数据集，通过视频反转和人工标注增强时序理解挑战，提升跨模态视频文本检索性能评估。|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EarthMind: Leveraging Cross-Sensor Data for Advanced Earth Observation Interpretation with a Unified Multimodal LLM|地球智脑：利用跨传感器数据通过统一多模态大语言模型进行高级地球观测解读|Yan Shu, Bin Ren, Zhitong Xiong, Danda Pani Paudel, Luc Van Gool, Begüm Demir, Nicu Sebe, Paolo Rota|<http://arxiv.org/pdf/2506.01667v2>|EarthMind通过创新层级跨模态注意力设计，融合不同传感器数据，提升地球观测数据的解读能力。|
|🆕 发布|LUQ: Layerwise Ultra-Low Bit Quantization for Multimodal Large Language Models|逐层超低比特量化（LUQ）用于多模态大型语言模型|Shubhang Bhatnagar, Andy Xu, Kar-Han Tan, Narendra Ahuja|<http://arxiv.org/pdf/2509.23729v1>|首次研究了针对多模态大语言模型的低于4比特量化方法，提出层状超低比特量化策略，有效降低内存使用并保持...|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FlowLUT: Efficient Image Enhancement via Differentiable LUTs and Iterative Flow Matching|流查找表（FlowLUT）：通过可微分查找表和迭代流匹配实现高效图像增强|Liubing Hu, Chen Wu, Anrui Wang, Dianjie Lu, Guijuan Zhang, Zhuoran Zheng|<http://arxiv.org/pdf/2509.23608v1>|FlowLUT通过结合可微分查找表和迭代流匹配，实现了高效的图像增强，同时保持计算效率。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|3D Foundation Model for Generalizable Disease Detection in Head Computed Tomography|用于头部分计算断层扫描中疾病检测泛化的3D基础模型|Weicheng Zhu, Haoxu Huang, Huanze Tang, Rushabh Musthyala, Boyang Yu, Long Chen, Emilio Vega, Thomas O'Donnell .etc.|<http://arxiv.org/pdf/2502.02779v2>|提出了一种基于自监督学习的3D基础模型，用于无需标注数据的头部CT扫描疾病检测，显著提升诊断性能。|
|📝 更新|Chronic Obstructive Pulmonary Disease Prediction Using Deep Convolutional Network|慢性阻塞性肺疾病预测：基于深度卷积网络的实现|Shahran Rahman Alve, Muhammad Zawad Mahmud, Samiha Islam, Mohammad Monirujjaman Khan|<http://arxiv.org/pdf/2411.02449v3>|提出了一种基于深度卷积神经网络的COPD检测方法，准确度高，有助于临床诊断。|
|🆕 发布|A University of Texas Medical Branch Case Study on Aortic Calcification Detection|德克萨斯大学医学分支关于主动脉钙化检测的案例研究|Eric Walser, Peter McCaffrey, Kal Clark, Nicholas Czarnek|<http://arxiv.org/pdf/2509.23930v1>|利用先进AI工具提高主动脉钙化检测准确性和编码完整性，改善患者护理和财务状况。|
|🆕 发布|Adversarial Versus Federated: An Adversarial Learning based Multi-Modality Cross-Domain Federated Medical Segmentation|对抗与联邦：基于对抗学习的多模态跨域联邦医疗分割|You Zhou, Lijiang Chen, Shuchang Lyu, Guangxia Cui, Wenpei Bai, Zheng Zhou, Meng Li, Guangliang Cheng .etc.|<http://arxiv.org/pdf/2509.23907v1>|[代码](https://github.com/GGbond-study/FedDA.); 提出了一种基于对抗性学习的联邦域自适应框架，有效解决了医疗图像跨域分割问题。|
|🆕 发布|Interpreting deep learning-based stellar mass estimation via causal analysis and mutual information decomposition|通过因果分析及互信息分解解释基于深度学习的恒星质量估计|Wei Zhang, Qiufan Lin, Yuan-Sen Ting, Shupei Chen, Hengxin Ruan, Song Li, Yifan Wang|<http://arxiv.org/pdf/2509.23901v1>|通过因果分析和互信息分解技术，揭示了深度学习估计恒星质量中不同输入数据的贡献和作用路径。|
|🆕 发布|FedAgentBench: Towards Automating Real-world Federated Medical Image Analysis with Server-Client LLM Agents|FedAgentBench：面向自动化真实世界联邦医疗图像分析的服务器-客户端大型语言模型智能体|Pramit Saha, Joshua Strong, Divyanshu Mishra, Cheng Ouyang, J. Alison Noble|<http://arxiv.org/pdf/2509.23803v1>|提出了一个基于智能代理的联邦学习框架FedAgentBench，自动化协调医疗图像分析的复杂操作挑战...|
|🆕 发布|PD-Diag-Net: Clinical-Priors guided Network on Brain MRI for Auxiliary Diagnosis of Parkinson's Disease|PD-Diag-Net：基于临床先验的脑部MRI辅助诊断帕金森病网络|Shuai Shao, Shu Jiang, Shiyuan Zhao, Di Yang, Yan Wang, Yutong Bai, Jianguo Zhang, Jiangtao Wang|<http://arxiv.org/pdf/2509.23719v1>|提出了一种利用临床先验知识的PD-Diag-Net，通过自动分析MRI扫描进行帕金森病辅助诊断，提高...|
|📝 更新|Med-PU: Point Cloud Upsampling for High-Fidelity 3D Medical Shape Reconstruction|Med-PU：用于高保真三维医学形状重建的点云上采样|Tongxu Zhang, Bei Wang|<http://arxiv.org/pdf/2501.16716v4>|提出Med-PU方法，通过结合医学图像分割与点云上采样，实现了精确的盆腔形状重建。|
|📝 更新|Human-like Content Analysis for Generative AI with Language-Grounded Sparse Encoders|基于语言定位稀疏编码器的人性化内容分析生成式人工智能|Yiming Tang, Arash Lagzian, Srinivas Anumasa, Qiran Zou, Yingtao Zhu, Ye Zhang, Trang Nguyen, Yih-Chung Tham .etc.|<http://arxiv.org/pdf/2508.18236v2>|提出了一种语言驱动的图像分解方法LanSE，通过识别具体视觉模式提升生成AI内容分析的准确性和可解释...|
|📝 更新|RAM-W1K: A Multi-Task Wrist Dataset and Benchmark for Rheumatoid Arthritis|RAM-W1K：一种多任务手腕数据集和类风湿性关节炎基准|Songxiao Yang, Haolin Wang, Yao Fu, Ye Tian, Tamotsu Kamishima, Masayuki Ikebe, Yafei Ou, Masatoshi Okutomi|<http://arxiv.org/pdf/2507.05193v2>|创建了首个公开的腕部骨骼实例分割和多任务数据集，助力类风湿关节炎的计算机辅助诊断研究。|
|📝 更新|Are VLMs Ready for Lane Topology Awareness in Autonomous Driving?|自动驾驶中，变分语言模型是否具备了车道拓扑意识？|Xin Chen, Jia He, Maozheng Li, Dongliang Xu, Tianyu Wang, Yixiao Chen, Zhixin Lin, Yue Yao|<http://arxiv.org/pdf/2509.16654v2>|系统评估了视觉语言模型在理解道路拓扑方面的能力，并提出了基于鸟瞰图的道路拓扑推理任务。|
|🆕 发布|MAN: Latent Diffusion Enhanced Multistage Anti-Noise Network for Efficient and High-Quality Low-Dose CT Image Denoising|MAN：潜在扩散增强的多阶段抗噪声网络，用于高效和高品质的低剂量CT图像去噪|Tangtangfang Fang, Jingxi Hu, Xiangjian He, Jiaqi Yang|<http://arxiv.org/pdf/2509.23603v1>|提出了一种高效的低剂量CT图像去噪方法MAN，通过压缩潜在空间和优化网络结构，实现了高质图像重建与快...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DriveE2E: Closed-Loop Benchmark for End-to-End Autonomous Driving through Real-to-Simulation|"DriveE2E：端到端自动驾驶闭环基准测试——从现实到仿真"|Haibao Yu, Wenxian Yang, Ruiyang Hao, Chuanye Wang, Jiaru Zhong, Ping Luo, Zaiqing Nie|<http://arxiv.org/pdf/2509.23922v1>|[代码](https://github.com/AIR-THU/DriveE2E); 提出了将真实世界驾驶场景与CARLA模拟器紧密集成的闭环评估框架，提升了自动驾驶模型评估的逼真度和准...|
|🆕 发布|Q-FSRU: Quantum-Augmented Frequency-Spectral For Medical Visual Question Answering|Q-FSRU：量子增强频率谱医疗视觉问答模型|Rakesh Thakur, Yusra Tariq, Rakesh Chandra Joshi|<http://arxiv.org/pdf/2509.23899v1>|提出Q-FSRU模型，融合频域特征与量子检索技术，提升医疗视觉问答性能与解释性。|
|🆕 发布|A Multi-Camera Vision-Based Approach for Fine-Grained Assembly Quality Control|一种基于多摄像头视觉的细粒度装配质量控制方法|Ali Nazeri, Shashank Mishra, Achim Wagner, Martin Ruskowski, Didier Stricker, Jason Rambach|<http://arxiv.org/pdf/2509.23815v1>|提出了一种多摄像头视觉系统，通过多角度成像和图像融合技术，提高了小部件装配质量检测的准确性和可靠性。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving|“AgentThink：一种用于自动驾驶中工具增强的链式思维推理的视觉语言模型统一框架”|Kangan Qian, Sicong Jiang, Yang Zhong, Ziang Luo, Zilin Huang, Tianze Zhu, Kun Jiang, Mengmeng Yang .etc.|<http://arxiv.org/pdf/2505.15298v4>|[代码](https://github.com/curryqka/AgentThink.); 引入AgentThink框架，融合链式思维推理与动态工具调用，显著提升自动驾驶任务中的推理质量和准确...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Controllable Reference Guided Diffusion with Local Global Fusion for Real World Remote Sensing Image Super Resolution|可控参考引导扩散结合局部全局融合用于现实世界遥感图像超分辨率|Ce Wang, Wanjie Sun|<http://arxiv.org/pdf/2506.23801v2>|提出了一种控制参考引导的扩散模型CRefDiff，通过局部全局信息融合解决遥感图像超分辨率中的欠生成...|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Static to Dynamic: a Survey of Topology-Aware Perception in Autonomous Driving|从静态到动态：自动驾驶中拓扑感知的综述|Yixiao Chen, Ruining Yang, Xin Chen, Jia He, Dongliang Xu, Yue Yao|<http://arxiv.org/pdf/2509.23641v1>|综述了自动驾驶中拓扑感知的四个研究方向，推动从静态地图到动态感知的范式转变。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Deep Taxonomic Networks for Unsupervised Hierarchical Prototype Discovery|深度分类网络用于无监督层次原型发现|Zekun Wang, Ethan Haarer, Zhiyi Dai, Tianyi Zhu, Christopher J. MacLellan|<http://arxiv.org/pdf/2509.23602v1>|提出了一种深度分类网络，通过优化大规模潜在分类层次结构，实现了无监督的层次原型发现。|
|📝 更新|HUNT: High-Speed UAV Navigation and Tracking in Unstructured Environments via Instantaneous Relative Frames|HUNT：通过瞬时相对帧在非结构化环境中实现的高速无人机导航与跟踪|Alessandro Saviolo, Jeffrey Mao, Giuseppe Loianno|<http://arxiv.org/pdf/2509.19452v3>|实现了无人机在无结构环境下的高速导航与目标跟踪一体化，通过即时观测数据进行实时反应，无需全局定位。|
|🆕 发布|LifeCLEF Plant Identification Task 2014|2014年LifeCLEF植物识别任务|Herve Goeau, Alexis Joly, Pierre Bonnet, Souheil Selmi, Jean-Francois Molino, Daniel Barthelemy, Nozha Boujemaa|<http://arxiv.org/pdf/2509.23900v1>|构建了针对真实世界应用的植物识别数据集，并通过公民科学项目评估了多种识别方法。|
|🆕 发布|LifeCLEF Plant Identification Task 2015|2015年LifeCLEF植物识别任务|Herve Goeau, Pierre Bonnet, Alexis Joly|<http://arxiv.org/pdf/2509.23891v1>|介绍了大规模植物识别挑战，利用众包平台构建的超过10万张图片数据集评估识别方法。|
|🆕 发布|BridgeDrive: Diffusion Bridge Policy for Closed-Loop Trajectory Planning in Autonomous Driving|桥驾：自动驾驶闭环轨迹规划中的扩散桥策略|Shu Liu, Wenlin Chen, Weihao Li, Zheng Wang, Lijin Yang, Jianing Huang, Yipin Zhang, Zhongzhan Huang .etc.|<http://arxiv.org/pdf/2509.23589v1>|提出BridgeDrive方法，利用锚点引导的扩散桥策略实现精确的闭环轨迹规划，提升自动驾驶在复杂交...|

