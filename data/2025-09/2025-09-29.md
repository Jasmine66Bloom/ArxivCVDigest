## [UPDATED!] **2025-09-29** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Scalable Distributed Framework for Multimodal GigaVoxel Image Registration|一种可扩展的分布式框架用于多模态吉咖体素图像配准|Rohit Jena, Vedant Zope, Pratik Chaudhari, James C. Gee|<http://arxiv.org/pdf/2509.25044v1>|提出FFDP框架，优化非GEMM瓶颈并实现卷积感知张量分片，大幅提升大规模图像配准的速度和效率。|
|📝 更新|CHROMA: Consistent Harmonization of Multi-View Appearance via Bilateral Grid Prediction|CHROMA：通过双边网格预测实现多视角外观的一致性调和|Jisu Shin, Richard Shaw, Seunghyun Shin, Zhensong Zhang, Hae-Gon Jeon, Eduardo Perez-Pellitero|<http://arxiv.org/pdf/2507.15748v2>|提出了一种预测自适应双边网格的方法，有效解决了多视角图像的光度不一致问题，提高了三维重建质量。|
|🆕 发布|DAM: Dual Active Learning with Multimodal Foundation Model for Source-Free Domain Adaptation|DAM：基于多模态基础模型的无需源域的双主动学习|Xi Chen, Hongxun Yao, Zhaopan Xu, Kui Jiang|<http://arxiv.org/pdf/2509.24896v1>|提出DAM框架，融合视觉与语言模型和稀疏人工标注，提升无源域自适应性能。|
|🆕 发布|Toward a Vision-Language Foundation Model for Medical Data: Multimodal Dataset and Benchmarks for Vietnamese PET/CT Report Generation|面向医疗数据的视觉-语言基础模型：越南PET/CT报告生成的多模态数据集与基准|Huu Tien Nguyen, Dac Thai Nguyen, The Minh Duc Nguyen, Trung Thanh Nguyen, Thao Nguyen Truong, Huy Hieu Pham, Johan Barthelemy, Minh Quan Tran .etc.|<http://arxiv.org/pdf/2509.24739v1>|构建越南语医学影像数据集，提升低资源语言医疗视觉语言模型性能。|
|🆕 发布|FreeRet: MLLMs as Training-Free Retrievers|FreeRet：基于预训练语言模型的免训练检索器|Yuhan Zhu, Xiangyu Zeng, Chenting Wang, Xinhao Li, Yicheng Xu, Ziang Yan, Yi Wang, Limin Wang|<http://arxiv.org/pdf/2509.24621v1>|提出了一种无需额外训练即可将多模态大语言模型转化为高效检索器的FreeRet框架。|
|📝 更新|Struct2D: A Perception-Guided Framework for Spatial Reasoning in Large Multimodal Models|结构2D：一种在大型多模态模型中进行空间推理的感知引导框架|Fangrui Zhu, Hanhui Wang, Yiming Xie, Jing Gu, Tianye Ding, Jianwei Yang, Huaizu Jiang|<http://arxiv.org/pdf/2506.04220v2>|提出了一种结合鸟瞰图像与对象标记的感知引导框架Struct2D，实现了大型多模态模型在无显式3D输入...|
|🆕 发布|Vid-LLM: A Compact Video-based 3D Multimodal LLM with Reconstruction-Reasoning Synergy|Vid-LLM：一种具有重建-推理协同的紧凑型基于视频的3D多模态大语言模型|Haijier Chen, Bo Xu, Shoujian Zhang, Haoze Liu, Jiaxuan Lin, Jingrong Wang|<http://arxiv.org/pdf/2509.24385v1>|提出了一种基于视频的紧凑型3D多模态大语言模型Vid-LLM，无需外部3D数据即可处理视频输入，实现...|
|📝 更新|PartSAM: A Scalable Promptable Part Segmentation Model Trained on Native 3D Data|"PartSAM：一种基于原生三维数据训练的可扩展提示性部件分割模型"|Zhe Zhu, Le Wan, Rui Xu, Yiheng Zhang, Honghua Chen, Zhiyang Dou, Cheng Lin, Yuan Liu .etc.|<http://arxiv.org/pdf/2509.21965v2>|首次提出原生训练于大规模3D数据的promptable部分分割模型PartSAM，实现精准分割与自动...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing|MinerU2.5：一种用于高效高分辨率文档解析的解耦视觉-语言模型|Junbo Niu, Zheng Liu, Zhuangcheng Gu, Bin Wang, Linke Ouyang, Zhiyuan Zhao, Tao Chu, Tianyao He .etc.|<http://arxiv.org/pdf/2509.22186v2>|提出了一种高效的文档解析模型MinerU2.5，通过解耦全局布局分析和局部内容识别，实现了高分辨率文...|
|📝 更新|MIRAGE: Multimodal foundation model and benchmark for comprehensive retinal OCT image analysis|MIRAGE：多模态基础模型与全面视网膜OCT图像分析基准|José Morano, Botond Fazekas, Emese Sükei, Ronald Fecso, Taha Emre, Markus Gumpinger, Georg Faustmann, Marzieh Oghbaie .etc.|<http://arxiv.org/pdf/2506.08900v3>|[代码](https://github.com/j-morano/MIRAGE.); 提出了一种多模态基础模型MIRAGE，用于全面分析视网膜OCT图像，并建立了新的评估基准。|
|🆕 发布|Collaborating Vision, Depth, and Thermal Signals for Multi-Modal Tracking: Dataset and Algorithm|多模态跟踪中视觉、深度与热成像信号的协同：数据集与算法|Xue-Feng Zhu, Tianyang Xu, Yifan Pan, Jinjie Gu, Xi Li, Jiwen Lu, Xiao-Jun Wu, Josef Kittler|<http://arxiv.org/pdf/2509.24741v1>|整合RGB、深度和热红外三模态信息，提出RDTTrack算法，显著提升复杂场景下的跟踪准确性和鲁棒性...|
|📝 更新|MindVL: Towards Efficient and Effective Training of Multimodal Large Language Models on Ascend NPUs|MindVL：面向在Ascend NPUs上高效有效训练多模态大型语言模型|Feilong Chen, Yijiang Liu, Yi Huang, Hao Wang, Miren Tian, Ya-Qi Yu, Minghui Liao, Jihao Wu|<http://arxiv.org/pdf/2509.11662v2>|提出MindVL，一种在Ascend NPUs上高效训练的多模态大语言模型，大幅提升数据利用效率。|
|🆕 发布|DINOReg: Strong Point Cloud Registration with Vision Foundation Model|DINOReg：基于视觉基础模型的强大点云配准|Congjia Chen, Yufu Qu|<http://arxiv.org/pdf/2509.24370v1>|[代码](https://github.com/ccjccjccj/DINOReg.); 提出了一种结合视觉和几何信息的点云配准方法DINOReg，大幅提升了配准准确性和召回率。|
|🆕 发布|Towards Foundation Models for Cryo-ET Subtomogram Analysis|面向冷冻电子断层成像子断层图像分析的基础模型研究|Runmin Jiang, Wanyue Feng, Yuntian Yang, Shriya Pingulkar, Hong Wang, Xi Xiao, Xiaoyu Cao, Genpei Zhang .etc.|<http://arxiv.org/pdf/2509.24311v1>|首次提出针对冷冻电子断层成像子断层图的基石模型，通过大规模合成数据生成、自适应相位标记增强视觉变换器...|
|🆕 发布|EVLF-FM: Explainable Vision Language Foundation Model for Medicine|EVLF-FM：医学可解释视觉语言基础模型|Yang Bai, Haoran Cheng, Yang Zhou, Jun Zhou, Arun Thirunavukarasu, Yuhe Ke, Jie Yao, Kanae Fukutsu .etc.|<http://arxiv.org/pdf/2509.24231v1>|提出了一种统一的多模态医学诊断模型EVLF-FM，实现了高准确性与细粒度解释性相结合。|
|🆕 发布|An Efficient 3D Latent Diffusion Model for T1-contrast Enhanced MRI Generation|一种高效的三维潜在扩散模型用于T1对比增强MRI生成|Zach Eidex, Mojtaba Safari, Jie Ding, Richard Qiu, Justin Roper, David Yu, Hui-Kuo Shu, Zhen Tian .etc.|<http://arxiv.org/pdf/2509.24194v1>|提出了一种高效的3D潜在扩散模型，快速生成高质量的T1对比增强MRI图像，无需使用对比剂。|
|🆕 发布|BALR-SAM: Boundary-Aware Low-Rank Adaptation of SAM for Resource-Efficient Medical Image Segmentation|边界感知的低秩自适应SAM用于资源高效的医学图像分割|Zelin Liu, Sicheng Dong, Bocheng Li, Yixuan Yang, Jiacheng Ruan, Chenxu Zhou, Suncheng Xiang|<http://arxiv.org/pdf/2509.24204v1>|提出了一种边界感知的低秩适应框架BALR-SAM，通过优化特征表示和注意力机制，有效提升医疗图像分割...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LVT: Large-Scale Scene Reconstruction via Local View Transformers|LVT：通过局部视图转换器进行大规模场景重建|Tooba Imtiaz, Lucy Chai, Kathryn Heal, Xuan Luo, Jungyeon Park, Jennifer Dy, John Flynn|<http://arxiv.org/pdf/2509.25001v1>|[代码](https://toobaimt.github.io/lvt); 提出了一种局部视角转换器（LVT），通过仅处理每个视角附近的局部信息，实现了大规模场景的高效重建。|
|🆕 发布|Vision At Night: Exploring Biologically Inspired Preprocessing For Improved Robustness Via Color And Contrast Transformations|夜间视觉：通过颜色与对比度转换探索生物启发预处理以提高鲁棒性|Lorena Stracke, Lia Nimmermann, Shashank Agnihotri, Margret Keuper, Volker Blanz|<http://arxiv.org/pdf/2509.24863v1>|提出了一种生物启发预处理方法，通过增强对比度和色彩对立性，提高了夜间及恶劣条件下的语义分割鲁棒性。|
|🆕 发布|Vision Function Layer in Multimodal LLMs|多模态大型语言模型中的视觉功能层|Cheng Shi, Yizhou Yu, Sibei Yang|<http://arxiv.org/pdf/2509.24791v1>|揭示了多模态大语言模型中视觉功能解码分布在不同解码层，提出Visual Token Swapping...|
|📝 更新|DART: Differentiable Dynamic Adaptive Region Tokenizer for Vision Foundation Models|DART：用于视觉基础模型的微分动态自适应区域标记器|Shicheng Yin, Kaixuan Yin, Yang Liu, Weixing Chen, Liang Lin|<http://arxiv.org/pdf/2506.10390v3>|[代码](https://github.com/HCPLab-SYSU/DART.); 引入了DART，一种智能分配计算资源的动态自适应区域 tokenizer，有效解决了传统视觉模型性能...|
|🆕 发布|Uni-X: Mitigating Modality Conflict with a Two-End-Separated Architecture for Unified Multimodal Models|统一多模态模型中缓解模态冲突的双端分离架构：Uni-X|Jitai Hao, Hao Liu, Xinyan Xiao, Qiang Huang, Jun Yu|<http://arxiv.org/pdf/2509.24365v1>|[代码](https://github.com/CURRENTF/Uni-X); 提出两端分离的Uni-X架构，有效解决统一多模态模型训练中的模态冲突问题。|
|📝 更新|Scaling Diffusion Transformers Efficiently via $μ$P|通过$μ$P高效扩展扩散变压器|Chenyu Zheng, Xinyu Zhang, Rongzhen Wang, Wei Huang, Zhi Tian, Weilin Huang, Jun Zhu, Chongxuan Li|<http://arxiv.org/pdf/2505.15270v2>|本研究将Maximal Update Parametrization ($\mu$P)方法扩展至扩散...|
|📝 更新|Feature Space Analysis by Guided Diffusion Model|特征空间分析通过引导扩散模型|Kimiaki Shirahama, Miki Yanobu, Kaduki Yamashita, Miho Ohsaki|<http://arxiv.org/pdf/2509.07936v2>|提出了一种引导扩散模型解码器，能生成与用户指定特征高度匹配的图像，揭示了深度神经网络特征空间的内在属...|
|📝 更新|SiNGER: A Clearer Voice Distills Vision Transformers Further|SiNGER：更清晰的语音提炼使视觉变换器更进一步|Geunhyeok Yu, Sunjae Jeong, Yoonyoung Choi, Jaeseung Kim, Hyoseok Hwang|<http://arxiv.org/pdf/2509.20986v2>|提出SiNGER方法，通过抑制高范数伪影同时保留有效信息，提升视觉Transformer模型的性能。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CLASP: Adaptive Spectral Clustering for Unsupervised Per-Image Segmentation|CLASP：自适应光谱聚类用于无监督单张图像分割|Max Curie, Paulo da Costa|<http://arxiv.org/pdf/2509.25016v1>|提出了一种无需标注数据的自适应光谱聚类图像分割框架，实现了高效的零训练图像分割。|
|📝 更新|WMKA-Net: A Weighted Multi-Kernel Attention Network for Retinal Vessel Segmentation|WMKA-Net：一种用于视网膜血管分割的加权多核注意力网络|Xinran Xu, Yuliang Ma, Sifu Cai, Ming Meng, Qiang Lv, Ruoyan Shi|<http://arxiv.org/pdf/2504.14888v4>|提出了一种双阶段网络WMKA-Net，通过多尺度特征融合和血管导向注意力机制，有效提升了视网膜血管分...|
|🆕 发布|Evaluation of Polarimetric Fusion for Semantic Segmentation in Aquatic Environments|极化融合在 aquatic 环境语义分割中的评估|Luis F. W. Batista, Tom Bourbon, Cedric Pradalier|<http://arxiv.org/pdf/2509.24731v1>|评估了偏振成像融合在抑制水面反光以提高水生环境中漂浮物语义分割准确性的效果。|
|📝 更新|Lost in Translation? Vocabulary Alignment for Source-Free Adaptation in Open-Vocabulary Semantic Segmentation|“迷失在翻译中？面向无源适应的开放词汇语义分割中的词汇对齐”|Silvio Mazzucco, Carl Persson, Mattia Segu, Pier Luigi Dovesi, Federico Tombari, Luc Van Gool, Matteo Poggi|<http://arxiv.org/pdf/2509.15225v3>|提出VocAlign框架，通过词汇对齐策略和Top-K选择机制实现无需源域数据的开放词汇语义分割自适...|
|🆕 发布|Biomechanical-phase based Temporal Segmentation in Sports Videos: a Demonstration on Javelin-Throw|基于生物力学相的体育视频时间分割：标枪投掷演示|Bikash Kumar Badatya, Vipul Baghel, Jyotirmoy Amin, Ravi Hegde|<http://arxiv.org/pdf/2509.24606v1>|提出了一种基于结构最优传输的框架，自动识别运动阶段转换，无需手动标注，显著提升运动分析准确性和效率。|
|🆕 发布|Robust Multimodal Semantic Segmentation with Balanced Modality Contributions|具有平衡模态贡献的鲁棒多模态语义分割|Jiaqi Tan, Xu Zheng, Fangyu Li, Yang Liu|<http://arxiv.org/pdf/2509.24505v1>|提出EQUISeg框架，通过平衡模态贡献解决多模态语义分割中的模态不平衡问题，增强模型鲁棒性。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Accurate Cobb Angle Estimation via SVD-Based Curve Detection and Vertebral Wedging Quantification|通过基于奇异值分解的曲线检测和椎体楔形量化进行精确的科布角估计|Chang Shi, Nan Meng, Yipeng Zhuang, Moxin Zhao, Jason Pui Yin Cheung, Hua Huang, Xiuyuan Chen, Cong Nie .etc.|<http://arxiv.org/pdf/2509.24898v1>|提出了一种深度学习框架，通过SVD分析预测脊椎形态，准确估算Cobb角并量化脊椎楔形变，提高青少年脊...|
|🆕 发布|Traumatic Brain Injury Segmentation using an Ensemble of Encoder-decoder Models|使用编码器-解码器模型集成的创伤性脑损伤分割|Ghanshyam Dhamat, Vaanathi Sundaresan|<http://arxiv.org/pdf/2509.24684v1>|提出了一种基于nnUNet框架的集成编码器-解码器模型，实现了对创伤性脑损伤的高精度自动分割。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Classifier-Centric Adaptive Framework for Open-Vocabulary Camouflaged Object Segmentation|面向开放词汇伪装目标分割的分类器中心自适应框架|Hanyu Zhang, Yiming Zhou, Jinxia Zhang|<http://arxiv.org/pdf/2509.24681v1>|提出了一种以分类器为中心的适应性框架，通过增强分类性能显著提高了伪装物体分割的准确性。|
|📝 更新|Interpretable 3D Neural Object Volumes for Robust Conceptual Reasoning|用于鲁棒概念推理的可解释3D神经对象体积|Nhi Pham, Artur Jesslen, Bernt Schiele, Adam Kortylewski, Jonas Fischer|<http://arxiv.org/pdf/2503.13429v2>|[代码](https://github.com/phamleyennhi/CAVE.); 提出CAVE方法，结合3D对象表示和概念解释，增强图像分类的鲁棒性和可解释性。|
|🆕 发布|Combining Discrepancy-Confusion Uncertainty and Calibration Diversity for Active Fine-Grained Image Classification|结合差异-混淆不确定性和校准多样性进行主动细粒度图像分类|Yinghao Jin, Xi Yang|<http://arxiv.org/pdf/2509.24181v1>|提出了一种结合差异混淆不确定性和校准多样性的主动细粒度图像分类方法，有效区分细粒度图像特征并评估样本...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Comprehensive Benchmarking of YOLOv11 Architectures for Scalable and Granular Peripheral Blood Cell Detection|《面向可扩展和细粒度周边血细胞检测的YOLOv11架构全面基准测试》|Mohamad Abou Ali, Mariam Abdulfattah, Baraah Al Hussein, Fadi Dornaika, Ali Cherry, Mohamad Hajj-Hassan, Lara Hamawy|<http://arxiv.org/pdf/2509.24595v1>|[代码](https://github.com/Mohamad-AbouAli/OI-PBC-Dataset); 系统评估了YOLOv11架构在血细胞检测中的应用，发现Medium模型在准确性和效率间取得最佳平衡。|
|📝 更新|DEPFusion: Dual-Domain Enhancement and Priority-Guided Mamba Fusion for UAV Multispectral Object Detection|"DEPFusion：双域增强与优先级引导的Mamba融合算法用于无人机多光谱目标检测"|Shucong Li, Zhenyu Liu, Zijie Hong, Zhiheng Zhou, Xianghai Cao|<http://arxiv.org/pdf/2509.07327v2>|提出了一种针对无人机多光谱目标检测的框架DEPFusion，通过双域增强和优先级引导融合技术，有效提...|
|🆕 发布|Talk in Pieces, See in Whole: Disentangling and Hierarchical Aggregating Representations for Language-based Object Detection|“分而论之，整体观之：基于语言的目标检测中的表示解耦与层次聚合”|Sojung An, Kwanyong Park, Yong Jae Lee, Donghyun Kim|<http://arxiv.org/pdf/2509.24192v1>|提出了一种分步骤解析和层级聚合语言描述的方法，显著提升了基于语言的目标检测性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LayerD: Decomposing Raster Graphic Designs into Layers|分层D：将光栅图形设计分解为图层|Tomoyuki Suzuki, Kang-Jun Liu, Naoto Inoue, Kota Yamaguchi|<http://arxiv.org/pdf/2509.25134v1>|提出LayerD方法，将栅格图像分解为可重新编辑的图层，实现高质量分解并优于现有基准。|
|🆕 发布|MGM-Omni: Scaling Omni LLMs to Personalized Long-Horizon Speech|MGM-Omni: 将全向语言模型扩展至个性化长时距语音|Chengyao Wang, Zhisheng Zhong, Bohao Peng, Senqiao Yang, Yuqi Liu, Haokun Gui, Bin Xia, Jingyao Li .etc.|<http://arxiv.org/pdf/2509.25131v1>|提出了MGM-Omni模型，实现了全模态理解和个性化长时语音生成的统一框架，提高了数据效率和语音生成...|
|🆕 发布|Score Distillation of Flow Matching Models|分数蒸馏的流匹配模型|Mingyuan Zhou, Yi Gu, Huangjie Zheng, Liangchen Song, Guande He, Yizhe Zhang, Wenze Hu, Yinfei Yang|<http://arxiv.org/pdf/2509.25127v1>|将分数蒸馏方法成功应用于流匹配模型，实现了快速文本到图像的生成。|
|🆕 发布|STAGE: Stable and Generalizable GRPO for Autoregressive Image Generation|STAGE：用于自回归图像生成的稳定和泛化GRPO|Xiaoxiao Ma, Haibo Qiu, Guohui Zhang, Zhixiong Zeng, Siqi Yang, Lin Ma, Feng Zhao|<http://arxiv.org/pdf/2509.25027v1>|提出STAGE框架，通过优势/KL重权和熵奖励解决GRPO在自回归图像生成中的稳定性问题，提升图像质...|
|🆕 发布|CharGen: Fast and Fluent Portrait Modification|CharGen：快速流畅的肖像修改|Jan-Niklas Dihlmann, Arnela Killguss, Hendrik P. A. Lensch|<http://arxiv.org/pdf/2509.25058v1>|CharGen通过结合属性特定的概念滑块和加速采样技术，实现了快速且精确的角色图像编辑。|
|🆕 发布|BRIDGE - Building Reinforcement-Learning Depth-to-Image Data Generation Engine for Monocular Depth Estimation|BRIDGE - 构建用于单目深度估计的强化学习深度到图像数据生成引擎|Dingning Liu, Haoyu Guo, Jingyi Zhou, Tong He|<http://arxiv.org/pdf/2509.25077v1>|[代码](https://dingning-liu.github.io/bridge.github.io); 提出了一种基于强化学习的深度图到图像生成引擎，大幅提升了单目深度估计的准确性和泛化能力。|
|🆕 发布|PanoWorld-X: Generating Explorable Panoramic Worlds via Sphere-Aware Video Diffusion|PanoWorld-X：通过球面感知视频扩散生成可探索的全景世界|Yuyang Yin, HaoXiang Guo, Fangfu Liu, Mengyu Wang, Hanwen Liang, Eric Li, Yikai Wang, Xiaojie Jin .etc.|<http://arxiv.org/pdf/2509.24997v1>|提出PanoWorld-X框架，通过球形感知扩散变换器实现高保真、可控的360度全景视频生成。|
|🆕 发布|Wan-Alpha: High-Quality Text-to-Video Generation with Alpha Channel|万-Alpha：具有Alpha通道的高质量文本到视频生成|Haotian Dong, Wenjing Wang, Chen Li, Di Lin|<http://arxiv.org/pdf/2509.24979v1>|[代码](https://donghaotian123.github.io/Wan-Alpha); 提出Wan-Alpha框架，通过联合学习RGB和alpha通道，生成高质量透明视频。|
|🆕 发布|Scalable GANs with Transformers|具有可扩展性的基于变换器的生成对抗网络|Sangeek Hyun, MinKyu Lee, Jae-Pil Heo|<http://arxiv.org/pdf/2509.24935v1>|提出利用变分自编码器潜空间训练和纯变换器结构，实现GAN的可扩展性和优化稳定性。|
|🆕 发布|OpenGPT-4o-Image: A Comprehensive Dataset for Advanced Image Generation and Editing|《OpenGPT-4o-Image：一种用于高级图像生成与编辑的全面数据集》|Zhihong Chen, Xuehai Bai, Yang Shi, Chaoyou Fu, Huanyu Zhang, Haotian Wang, Xiaoyan Sun, Zhang Zhang .etc.|<http://arxiv.org/pdf/2509.24900v1>|构建了OpenGPT-4o-Image数据集，通过系统化任务分类和自动数据生成，提升图像生成与编辑性...|
|🆕 发布|VAGUEGAN: Stealthy Poisoning and Backdoor Attacks on Image Generative Pipelines|VAGUEGAN：图像生成管道的隐秘投毒与后门攻击|Mostafa Mohaimen Akand Faisal, Rabeya Amin Jhuma|<http://arxiv.org/pdf/2509.24891v1>|提出了一种隐秘的生成模型攻击方法VagueGAN，通过微小扰动实现输出图像的精确控制。|
|📝 更新|Warm Starts Accelerate Conditional Diffusion|"温启动加速条件扩散"|Jonas Scholz, Richard E. Turner|<http://arxiv.org/pdf/2507.09212v2>|提出了一种预热扩散方法，通过提供更优的起始点显著加快了条件生成模型的采样速度。|
|🆕 发布|Causal-Adapter: Taming Text-to-Image Diffusion for Faithful Counterfactual Generation|因果适配器：驯服文本到图像扩散以实现忠实反事实生成|Lei Tong, Zhihua Liu, Chaochao Lu, Dino Oglic, Tom Diethe, Philip Teare, Sotirios A. Tsaftaris, Chen Jin|<http://arxiv.org/pdf/2509.24798v1>|提出Causal-Adapter框架，通过结构因果模型和属性正则化策略实现精准的图像属性干预与修改。|
|🆕 发布|VSSFlow: Unifying Video-conditioned Sound and Speech Generation via Joint Learning|VSSFlow：通过联合学习统一视频条件声音与语音生成|Xin Cheng, Yuyue Wang, Xihua Wang, Yihan Wu, Kaisi Guan, Yijing Chen, Peng Zhang, Xiaojiang Liu .etc.|<http://arxiv.org/pdf/2509.24773v1>|提出了VSSFlow，一种统一视频条件声音和语音生成的框架，通过端到端联合学习显著提升生成效果。|
|🆕 发布|SANA-Video: Efficient Video Generation with Block Linear Diffusion Transformer|SANA-Video：基于块线性扩散变换的高效视频生成|Junsong Chen, Yuyang Zhao, Jincheng Yu, Ruihang Chu, Junyu Chen, Shuai Yang, Xianbang Wang, Yicheng Pan .etc.|<http://arxiv.org/pdf/2509.24695v1>|提出SANA-Video模型，通过线性注意力和常量内存KV缓存实现高效、高质量的长视频生成。|
|🆕 发布|IWR-Bench: Can LVLMs reconstruct interactive webpage from a user interaction video?|IWR-Bench：LVLMs能否从用户交互视频中重建交互式网页？|Yang Chen, Minghao Liu, Yufan Shen, Yunwen Li, Tianyuan Huang, Xinyu Fang, Tianyu Zheng, Wenxuan Huang .etc.|<http://arxiv.org/pdf/2509.24709v1>|[代码](https://github.com/L-O-I/IWR-Bench.); 提出了IWR-Bench，用于评估大型视觉语言模型从视频中重建交互式网页的能力，揭示了当前模型在处理...|
|🆕 发布|CEDex: Cross-Embodiment Dexterous Grasp Generation at Scale from Human-like Contact Representations|CEDex：从类人接触表示大规模生成跨载体灵巧抓取|Zhiyuan Wu, Rolandos Alexandros Potamias, Xuyang Zhang, Zhongqun Zhang, Jiankang Deng, Shan Luo|<http://arxiv.org/pdf/2509.24661v1>|提出CEDex方法，通过结合人类抓握动力学与机器人动力学，大规模生成适用于不同形态机器人手的灵巧抓握...|
|🆕 发布|Learning Object-Centric Representations Based on Slots in Real World Scenarios|基于现实世界场景中槽位学习的对象中心表示学习|Adil Kaan Akan|<http://arxiv.org/pdf/2509.24652v1>|引入了基于槽的轻量级条件框架，实现对象级编辑与全局场景一致性的平衡。|
|📝 更新|GCDance: Genre-Controlled Music-Driven 3D Full Body Dance Generation|《GCDance：风格控制的基于音乐驱动的三维全身舞蹈生成》|Xinran Liu, Xu Dong, Shenbin Qian, Diptesh Kanojia, Wenwu Wang, Zhenhua Feng|<http://arxiv.org/pdf/2502.18309v3>|提出了一种基于扩散框架的音乐驱动3D全身舞蹈生成方法，通过文本控制实现风格精确的舞蹈生成。|
|🆕 发布|SCOPE: Semantic Conditioning for Sim2Real Category-Level Object Pose Estimation in Robotics|SCOPE：面向机器人领域的语义条件约束下从仿真到现实类别级对象姿态估计|Peter Hönig, Stefan Thalhammer, Jean-Baptiste Weibel, Matthias Hirschmanner, Markus Vincze|<http://arxiv.org/pdf/2509.24572v1>|[代码](https://github.com/hoenigpeter/scope.); 提出SCOPE模型，通过结合连续语义先验和噪声模型，有效缩小了仿真到现实环境中的物体姿态估计差距。|
|📝 更新|ControlHair: Physically-based Video Diffusion for Controllable Dynamic Hair Rendering|控制毛发：基于物理的视频扩散算法实现可控动态毛发渲染|Weikai Lin, Haoxiang Li, Yuhao Zhu|<http://arxiv.org/pdf/2509.21541v2>|提出了一种融合物理模拟与条件视频扩散的ControlHair框架，实现了可控动态毛发渲染。|
|🆕 发布|NeMo: Needle in a Montage for Video-Language Understanding|《NeMo：视频语言理解中的蒙太奇里的针》|Zi-Yuan Hu, Shuo Liang, Duo Zheng, Yanyang Li, Yeyao Tao, Shijia Huang, Wei Feng, Jia Qin .etc.|<http://arxiv.org/pdf/2509.24563v1>|[代码](https://lavi-lab.github.io/NeMoBench.); 提出NeMo任务和NeMoBench基准，评估视频语言模型在复杂时序推理和长上下文理解的能力。|
|🆕 发布|Instruction Guided Multi Object Image Editing with Quantity and Layout Consistency|指令引导的多目标图像编辑：数量与布局一致性保持|Jiaqi Tan, Fangyu Li, Yang Liu|<http://arxiv.org/pdf/2509.24514v1>|提出QL-Adapter框架，通过增强布局理解和指令跟随，实现多对象图像编辑的数量与布局一致性。|
|📝 更新|Towards Generalizable AI-Generated Image Detection via Image-Adaptive Prompt Learning|面向通用的人工智能生成图像检测：基于图像自适应提示学习|Yiheng Li, Zichang Tan, Zhen Lei, Xu Zhou, Yang Yang|<http://arxiv.org/pdf/2508.01603v2>|[代码](https://github.com/liyih/IAPL.); 提出了一种动态调整输入提示的图像生成检测方法，增强了模型对未见生成器的泛化能力。|
|🆕 发布|LaMoGen: Laban Movement-Guided Diffusion for Text-to-Motion Generation|拉班动作引导扩散：从文本到动作生成的模型|Heechang Kim, Gwanghyun Kim, Se Young Chun|<http://arxiv.org/pdf/2509.24469v1>|将Laban运动分析融入文本引导的运动生成模型，实现了无额外数据的高质量、多样化运动控制。|
|🆕 发布|UI2V-Bench: An Understanding-based Image-to-video Generation Benchmark|UI2V-Bench：一个基于理解的图像到视频生成基准|Ailing Zhang, Lina Lei, Dehong Kong, Zhixin Wang, Jiaqi Xu, Fenglong Song, Chun-Le Guo, Chang Liu .etc.|<http://arxiv.org/pdf/2509.24427v1>|提出了UI2V-Bench，一个专注于评估图像到视频生成模型在语义理解和推理能力的新基准。|
|🆕 发布|UI-UG: A Unified MLLM for UI Understanding and Generation|UI-UG：一种用于界面理解与生成的统一多模态语言模型|Hao Yang, Weijie Qiu, Ru Zhang, Zhou Fang, Ruichao Mao, Xiaoyu Lin, Maji Huang, Zhaosong Huang .etc.|<http://arxiv.org/pdf/2509.24361v1>|提出UI-UG模型，融合UI理解和生成能力，通过定制化策略提升准确性和生成质量。|
|🆕 发布|Hyperspherical Latents Improve Continuous-Token Autoregressive Generation|超球面潜在变量提升连续标记自回归生成|Guolin Ke, Hui Xue|<http://arxiv.org/pdf/2509.24335v1>|提出SphereAR模型，通过将变量约束在固定半径的超球面上，解决了自回归生成模型中的方差崩溃问题，...|
|📝 更新|CryoCCD: Conditional Cycle-consistent Diffusion with Biophysical Modeling for Cryo-EM Synthesis|冷冻CCD：基于生物物理建模的冷冻电子显微镜合成条件循环一致性扩散|Runmin Jiang, Genpei Zhang, Yuntian Yang, Siqi Wu, Minhao Wu, Wanyue Feng, Yizhou Zhao, Xi Xiao .etc.|<http://arxiv.org/pdf/2505.23444v3>|CryoCCD结合生物物理模型与条件循环一致性扩散模型，为缺乏高质量标注数据的冷冻电镜技术生成逼真合...|
|🆕 发布|SVGThinker: Instruction-Aligned and Reasoning-Driven Text-to-SVG Generation|SVGThinker：指令对齐与推理驱动的文本到SVG生成|Hanqi Chen, Zhongyin Zhao, Ye Chen, Zhujin Liang, Bingbing Ni|<http://arxiv.org/pdf/2509.24299v1>|SVGThinker通过结合指令对齐和推理驱动，有效解决了文本到SVG生成中的泛化能力和指令遵循问题...|
|📝 更新|GenMix: Effective Data Augmentation with Generative Diffusion Model Image Editing|生成混合：基于生成扩散模型图像编辑的有效数据增强|Khawar Islam, Muhammad Zaigham Zaheer, Arif Mahmood, Karthik Nandakumar, Naveed Akhtar|<http://arxiv.org/pdf/2412.02366v4>|提出了一种基于生成扩散模型的通用数据增强方法GenMix，有效提升了跨域图像分类的性能和鲁棒性。|
|🆕 发布|Robust Partial 3D Point Cloud Registration via Confidence Estimation under Global Context|通过全局上下文下的置信度估计实现鲁棒的局部三维点云配准|Yongqiang Wang, Weigang Li, Wenping Liu, Zhe Xu, Zhiqiang Tian|<http://arxiv.org/pdf/2509.24275v1>|提出了一种全局上下文下的置信度估计框架，实现了鲁棒的局部3D点云配准。|
|🆕 发布|Latent Visual Reasoning|潜在视觉推理|Bangzheng Li, Ximeng Sun, Jiang Liu, Ze Wang, Jialian Wu, Xiaodong Yu, Hao Chen, Emad Barsoum .etc.|<http://arxiv.org/pdf/2509.24251v1>|提出 Latent Visual Reasoning 方法，直接在视觉嵌入空间进行自回归推理，显著提...|
|🆕 发布|FreeAction: Training-Free Techniques for Enhanced Fidelity of Trajectory-to-Video Generation|无需训练的增强轨迹到视频生成的保真度技术：FreeAction|Seungwook Kim, Seunghyeon Lee, Minsu Cho|<http://arxiv.org/pdf/2509.24241v1>|提出两种无需训练的增强机器人轨迹视频生成真实感的方法，通过动态调整引导强度和噪声分布提升动作连贯性和...|
|📝 更新|Rare-to-Frequent: Unlocking Compositional Generation Power of Diffusion Models on Rare Concepts with LLM Guidance|罕见到常见：在大型语言模型指导下解锁扩散模型在罕见概念上的组合生成能力|Dongmin Park, Sebin Kim, Taehong Moon, Minkyu Kim, Kangwook Lee, Jaewoong Cho|<http://arxiv.org/pdf/2410.22376v4>|[代码](https://github.com/krafton-ai/Rare-to-Frequent.); 提出了一种利用大型语言模型指导的扩散模型方法，有效提升了生成罕见概念组合的能力。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unsupervised Representation Learning for 3D Mesh Parameterization with Semantic and Visibility Objectives|无监督三维网格参数化表示学习：结合语义和可见性目标|AmirHossein Zamani, Bruno Roy, Arianna Rampini|<http://arxiv.org/pdf/2509.25094v1>|[代码](https://github.com/AHHHZ975/Semantic-Visibility-UV-Param.); 提出了一种无监督的差异化框架，通过结合语义和可见性目标自动优化3D网格参数化过程。|
|🆕 发布|UniLat3D: Geometry-Appearance Unified Latents for Single-Stage 3D Generation|统一形状-外观潜在变量：单阶段三维生成|Guanjun Wu, Jiemin Fang, Chen Yang, Sikuang Li, Taoran Yi, Jia Lu, Zanwei Zhou, Jiazhong Cen .etc.|<http://arxiv.org/pdf/2509.25079v1>|提出了UniLat3D框架，通过统一编码几何与外观信息，实现了单阶段高效生成高质量3D资产。|
|📝 更新|BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation|BLADE：块稀疏注意力与步长蒸馏相遇，实现高效视频生成|Youping Gu, Xiaolong Li, Yuhao Hu, Minqi Chen, Bohan Zhuang|<http://arxiv.org/pdf/2508.10774v2>|提出了一种高效视频生成框架BLADE，通过自适应块稀疏注意力和轨迹分布匹配的步进蒸馏，大幅提升了生成...|
|🆕 发布|StreamForest: Efficient Online Video Understanding with Persistent Event Memory|流森林：具有持久事件记忆的高效在线视频理解|Xiangyu Zeng, Kefan Qiu, Qingyu Zhang, Xinhao Li, Jing Wang, Jiaxin Li, Ziang Yan, Kun Tian .etc.|<http://arxiv.org/pdf/2509.24871v1>|提出StreamForest架构，通过持久事件记忆森林和细粒度时空窗口提升流视频理解的实时性和准确性...|
|🆕 发布|Enhancing Physical Plausibility in Video Generation by Reasoning the Implausibility|通过推理不合理性增强视频生成中的物理可信度|Yutong Hao, Chen Chen, Ajmal Saeed Mian, Chang Xu, Daochang Liu|<http://arxiv.org/pdf/2509.24702v1>|提出了一种无需额外训练的推理框架，通过显式识别并避免不合理动作，显著提高了视频生成的物理可信度。|
|🆕 发布|TokenSwap: Backdoor Attack on the Compositional Understanding of Large Vision-Language Models|《TokenSwap：针对大型视觉语言模型组合理解的后门攻击》|Zhifang Zhang, Qiqi Tao, Jiaqi Lv, Na Zhao, Lei Feng, Joey Tianyi Zhou|<http://arxiv.org/pdf/2509.24566v1>|提出了一种隐蔽的TokenSwap攻击方法，通过破坏大型视觉语言模型的对象关系理解来实施后门攻击。|
|📝 更新|Bridging Semantic Logic Gaps: A Cognition Inspired Multimodal Boundary Preserving Network for Image Manipulation Localization|桥接语义逻辑间隙：一种受认知启发保持多模态边界的图像操作定位网络|Songlin Li, Zhiqing Guo, Yuanman Li, Zeyu Li, Yunfeng Diao, Gaobo Yang, Liejun Wang|<http://arxiv.org/pdf/2508.07216v2>|[代码](https://github.com/vpsg-research/CMB-Net.); 提出了一种认知启发式多模态边界保持网络，通过结合大语言模型和图像特征补偿语义逻辑关系缺失，提升了图像...|
|📝 更新|DiffusionGuard: A Robust Defense Against Malicious Diffusion-based Image Editing|扩散守护者：一种针对恶意扩散基于图像编辑的鲁棒防御方法|June Suk Choi, Kyungmin Lee, Jongheon Jeong, Saining Xie, Jinwoo Shin, Kimin Lee|<http://arxiv.org/pdf/2410.05694v2>|[代码](https://github.com/choi403/DiffusionGuard.); 提出DiffusionGuard方法，有效防御扩散模型恶意图像编辑，增强对抗噪声效率和鲁棒性。|
|🆕 发布|Semantic Editing with Coupled Stochastic Differential Equations|耦合随机微分方程的语义编辑|Jianxin Zhang, Clayton Scott|<http://arxiv.org/pdf/2509.24223v1>|利用耦合随机微分方程引导生成模型采样，实现了图像编辑的高保真度和细节一致性。|
|📝 更新|NarrLV: Towards a Comprehensive Narrative-Centric Evaluation for Long Video Generation|NarrLV：面向长视频生成的全面叙事中心评估方法|X. Feng, H. Yu, M. Wu, S. Hu, J. Chen, C. Zhu, J. Wu, X. Chu .etc.|<http://arxiv.org/pdf/2507.11245v4>|提出NarrLV基准，首次全面评估长视频生成模型在叙事表达方面的能力。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning|视频聊天R1：通过强化微调增强时空感知|Xinhao Li, Ziang Yan, Desen Meng, Lu Dong, Xiangyu Zeng, Yinan He, Yali Wang, Yu Qiao .etc.|<http://arxiv.org/pdf/2504.06958v4>|通过强化微调，本文提升了视频多模态大语言模型的时空感知能力，实现了任务特定性能的显著提升。|
|🆕 发布|Score-based Membership Inference on Diffusion Models|基于分数的扩散模型成员推断|Mingxing Rao, Bowen Qu, Daniel Moyer|<http://arxiv.org/pdf/2509.25003v1>|提出了一种单次查询的SimA攻击方法，有效防御扩散模型中的成员推断攻击，并揭示了潜在扩散模型相对更不...|
|🆕 发布|SDPose: Exploiting Diffusion Priors for Out-of-Domain and Robust Pose Estimation|SDPose：利用扩散先验进行域外和鲁棒姿态估计|Shuang Liang, Jing He, Chuanmeizhi Wang, Lejun Liao, Guo Zhang, Yingcong Chen, Yuan Yuan|<http://arxiv.org/pdf/2509.24980v1>|提出SDPose框架，利用预训练的扩散模型进行人体姿态估计，实现跨域泛化并设立新标准。|
|🆕 发布|On-the-Fly Data Augmentation for Brain Tumor Segmentation|《脑肿瘤分割中的实时数据增强》|Ishika Jain, Siri Willems, Steven Latre, Tom De Schepper|<http://arxiv.org/pdf/2509.24973v1>|提出实时数据增强策略，使用预训练生成对抗网络动态插入合成肿瘤，提升脑肿瘤分割模型的泛化能力。|
|📝 更新|Origins of Creativity in Attention-Based Diffusion Models|基于注意力机制的扩散模型中创造力的起源|Emma Finn, T. Anderson Keller, Manos Theodosis, Demba E. Ba|<http://arxiv.org/pdf/2506.17324v2>|探究了注意力机制在扩散模型中如何促进全局图像一致性的生成，扩展了传统扩散模型理论。|
|🆕 发布|Attention Surgery: An Efficient Recipe to Linearize Your Video Diffusion Transformer|注意力手术：一种高效方法将您的视频扩散变压器线性化|Mohsen Ghafoorian, Denis Korzhenkov, Amirhossein Habibian|<http://arxiv.org/pdf/2509.24899v1>|提出了一种无需从头训练的“注意力手术”方法，有效将视频扩散模型中的注意力线性化，降低计算成本同时保持...|
|🆕 发布|DRCP: Diffusion on Reinforced Cooperative Perception for Perceiving Beyond Limits|DRCP：基于强化协作感知的扩散以突破感知极限|Lantao Li, Kang Yang, Rui Song, Chen Sun|<http://arxiv.org/pdf/2509.24903v1>|提出DRCP框架，通过跨模态合作感知和轻量级扩散 refine，增强自动驾驶车辆在复杂环境下的感知能...|
|🆕 发布|ThermalGen: Style-Disentangled Flow-Based Generative Models for RGB-to-Thermal Image Translation|热成像生成器：基于风格解耦的流式生成模型用于RGB到热成像的图像转换|Jiuhong Xiao, Roshan Nayak, Ning Zhang, Daniel Tortei, Giuseppe Loianno|<http://arxiv.org/pdf/2509.24878v1>|[代码](http://xjh19971.github.io/ThermalGen); 提出了一种自适应流生成模型ThermalGen，实现了从RGB到热成像的翻译，有效解决了数据稀缺问题...|
|📝 更新|Decoupled Classifier-Free Guidance for Counterfactual Diffusion Models|解耦的无分类器引导策略用于反事实扩散模型|Tian Xia, Fabio De Sousa Ribeiro, Rajat R Rasal, Avinash Kori, Raghav Mehta, Ben Glocker|<http://arxiv.org/pdf/2506.14399v3>|提出了一种新的指导策略DCFG，通过属性拆分实现更精细的生成控制，解决了传统CFG在反事实生成中的全...|
|📝 更新|UML-CoT: Structured Reasoning and Planning with Unified Modeling Language for Robotic Room Cleaning|统一建模语言辅助的机器人房间清洁：结构化推理与规划|Hongyu Chen, Guangrun Wang|<http://arxiv.org/pdf/2509.22628v2>|提出UML-CoT框架，利用统一建模语言增强机器人清扫任务的推理和规划能力。|
|📝 更新|Exploring Reprensentation Invariance in Finetuning|探究微调中的表征不变性|Wenqiang Zu, Shenghao Xie, Hao Chen, Zhiqiang Chen, Liwen Hu, Yuanhao Xi, Yiming Liang, Junliang Ye .etc.|<http://arxiv.org/pdf/2503.07399v2>|提出方法RIFT，通过保持预训练和微调模型表征相似性，有效适应跨域任务且不牺牲泛化能力。|
|📝 更新|BranchGRPO: Stable and Efficient GRPO with Structured Branching in Diffusion Models|分支GRPO：在扩散模型中具有结构分支的稳定高效GRPO|Yuming Li, Yikai Wang, Yuying Zhu, Zhongyu Zhao, Ming Lu, Qi She, Shanghang Zhang|<http://arxiv.org/pdf/2509.06040v5>|[代码](https://fredreic1849.github.io/BranchGRPO-Webpage); 提出了一种结构化分支扩散模型BranchGRPO，通过分支树优化降低了计算成本并提高了生成效率。|
|🆕 发布|ExGS: Extreme 3D Gaussian Compression with Diffusion Priors|极值三维高斯压缩与扩散先验方法（ExGS）|Jiaqi Chen, Xinhao Ji, Yuanyuan Gao, Hao Li, Yuning Gong, Yifei Liu, Dan Xu, Zhihang Zhong .etc.|<http://arxiv.org/pdf/2509.24758v1>|[代码](https://github.com/chenttt2001/ExGS); 提出了一种高效3D高斯压缩框架ExGS，通过结合扩散先验和优化剪枝，实现了超压缩比下的高质量图像恢复...|
|🆕 发布|RIFLE: Removal of Image Flicker-Banding via Latent Diffusion Enhancement|RIFLE：通过潜在扩散增强去除图像闪烁-色带|Zhu, Libo, Zhou, Zihan, Liu, Xiaoyang, Zhang, Weihang .etc.|<http://arxiv.org/pdf/2509.24644v1>|提出了一种基于扩散框架的图像闪烁带消除方法RIFLE，有效提升了图像质量和细节保留。|
|📝 更新|Diffusion models for multivariate subsurface generation and efficient probabilistic inversion|用于多变量地下生成和高效概率反演的扩散模型|Roberto Miele, Niklas Linde|<http://arxiv.org/pdf/2507.15809v3>|提出改进的扩散模型用于多变量地下建模和高效概率反演，提升了统计稳健性和后验概率密度采样。|
|🆕 发布|SAIP: A Plug-and-Play Scale-adaptive Module in Diffusion-based Inverse Problems|SAIP：一种即插即用的基于扩散逆问题中的尺度自适应模块|Lingyu Wang, Xiangming Meng|<http://arxiv.org/pdf/2509.24580v1>|提出了一种自适应调整尺度平衡的SAIP模块，有效提升了扩散模型在图像重建任务中的性能和泛化能力。|
|📝 更新|LoRACLR: Contrastive Adaptation for Customization of Diffusion Models|LoRACLR：用于定制扩散模型的对比适应方法|Enis Simsar, Thomas Hofmann, Federico Tombari, Pinar Yanardag|<http://arxiv.org/pdf/2412.09622v2>|LoRACLR通过对比目标实现多概念融合，提升了个性化图像生成的质量和效率。|
|🆕 发布|Diffusion Bridge or Flow Matching? A Unifying Framework and Comparative Analysis|扩散桥还是流匹配？一个统一框架和比较分析|Kaizhen Zhu, Mokai Pan, Zhechuan Yu, Jingya Wang, Jingyi Yu, Ye Shi|<http://arxiv.org/pdf/2509.24531v1>|提出统一框架比较Diffusion Bridge与Flow Matching，理论分析与实验验证揭示...|
|🆕 发布|CMT: Mid-Training for Efficient Learning of Consistency, Mean Flow, and Flow Map Models|CMT：一致性、均值流及流图模型的高效学习中期训练方法|Zheyuan Hu, Chieh-Hsin Lai, Yuki Mitsufuji, Stefano Ermon|<http://arxiv.org/pdf/2509.24526v1>|提出了一种中间训练方法CMT，通过稳定初始化提高流图模型训练效率，实现了更快的收敛和更优的性能。|
|📝 更新|DiTraj: training-free trajectory control for video diffusion transformer|DiTraj：无需训练的轨迹控制视频扩散变换器|Cheng Lei, Jiayu Zhang, Yue Ma, Xinyu Wang, Long Chen, Liang Tang, Yiqiang Yan, Fei Su .etc.|<http://arxiv.org/pdf/2509.21839v2>|提出了一种无需训练的DiTraj框架，通过前景-背景分离指导和空间-时间解耦位置编码，实现了文本到视...|
|🆕 发布|CLQ: Cross-Layer Guided Orthogonal-based Quantization for Diffusion Transformers|CLQ：基于跨层引导的正交量化方法用于扩散变换器|Kai Liu, Shaoqiu Zhang, Linghe Kong, Yulun Zhang|<http://arxiv.org/pdf/2509.24416v1>|[代码](https://github.com/Kai-Liu001/CLQ); 提出CLQ方法，通过跨层指导和正交量化技术，有效压缩扩散变换器模型，实现显著的内存节省和速度提升。|
|🆕 发布|RapidMV: Leveraging Spatio-Angular Representations for Efficient and Consistent Text-to-Multi-View Synthesis|快速多视图合成：利用空间-角度表示实现高效一致性的文本到多视图转换|Seungwook Kim, Yichun Shi, Kejie Li, Minsu Cho, Peng Wang|<http://arxiv.org/pdf/2509.24410v1>|提出了一种高效的文本到多视角图像生成模型RapidMV，通过独特的空间-角度潜在空间编码，实现了快速...|
|🆕 发布|REALIGN: Regularized Procedure Alignment with Matching Video Embeddings via Partial Gromov-Wasserstein Optimal Transport|“REALIGN：通过部分Gromov-Wasserstein最优传输匹配视频嵌入的正规化过程对齐”|Soumyadeep Chandra, Kaushik Roy|<http://arxiv.org/pdf/2509.24382v1>|提出了一种基于部分Gromov-Wasserstein最优传输的自监督框架REALIGN，有效处理教...|
|🆕 发布|NeRV-Diffusion: Diffuse Implicit Neural Representations for Video Synthesis|NeRV-Diffusion：用于视频合成的扩散隐式神经表示|Yixuan Ren, Hanyu Wang, Hao Chen, Bo He, Abhinav Shrivastava|<http://arxiv.org/pdf/2509.24353v1>|提出了一种基于隐式神经表示和扩散模型的高效视频合成方法，实现了高质量的视频生成和流畅的帧间插值。|
|📝 更新|DreamO: A Unified Framework for Image Customization|梦享O：图像定制统一框架|Chong Mou, Yanze Wu, Wenxu Wu, Zinan Guo, Pengze Zhang, Yufeng Cheng, Yiming Luo, Fei Ding .etc.|<http://arxiv.org/pdf/2504.16915v4>|DreamO统一框架通过扩散变换器处理多条件输入，实现高效灵活的图像定制化。|
|📝 更新|FlashEdit: Decoupling Speed, Structure, and Semantics for Precise Image Editing|《FlashEdit：解耦速度、结构与语义以实现精确图像编辑》|Junyi Wu, Zhiteng Li, Haotong Qin, Xiaohong Liu, Linghe Kong, Yulun Zhang, Xiaokang Yang|<http://arxiv.org/pdf/2509.22244v2>|[代码](https://github.com/JunyiWuCode/FlashEdit.); FlashEdit通过创新的编辑流程和注意力机制，实现了快速且高质量的图像编辑，大幅提升了效率。|
|🆕 发布|ASIA: Adaptive 3D Segmentation using Few Image Annotations|自适应少图像标注的三维分割方法（ASIA）|Sai Raj Kishore Perla, Aditya Vora, Sauradip Nag, Ali Mahdavi-Amiri, Hao Zhang|<http://arxiv.org/pdf/2509.24288v1>|提出了一种自适应3D分割框架，通过少量图像注释实现精确的3D物体分割。|
|📝 更新|Rethinking Human-Object Interaction Evaluation for both Vision-Language Models and HOI-Specific Methods|重新思考面向视觉语言模型和特定于人对象交互的方法的评价|Qinqian Lei, Bo Wang, Robby T. Tan|<http://arxiv.org/pdf/2508.18753v2>|提出新基准数据集，将人-物交互检测作为多选任务，使大型视觉语言模型超越传统专门方法。|
|📝 更新|Bidirectional Likelihood Estimation with Multi-Modal Large Language Models for Text-Video Retrieval|基于多模态大型语言模型的文本-视频检索双向似然估计|Dohwan Ko, Ji Soo Lee, Minhyuk Choi, Zihang Meng, Hyunwoo J. Kim|<http://arxiv.org/pdf/2507.23284v3>|[代码](https://github.com/mlvlab/BLiM.); 提出双向概率估计框架BLiM和候选先验归一化CPN，有效缓解文本视频检索中的候选先验偏差，提升查询-...|
|📝 更新|T2VUnlearning: A Concept Erasing Method for Text-to-Video Diffusion Models|文本到视频扩散模型的概念擦除方法：T2VUnlearning|Xiaoyu Ye, Songjie Cheng, Yongtao Wang, Yajiao Xiong, Yishen Li|<http://arxiv.org/pdf/2505.17550v3>|[代码](https://github.com/VDIGPKU/T2VUnlearning.git); 提出了一种基于“遗忘学习”的文本到视频模型概念擦除方法，有效消除特定概念的同时保持模型生成其他概念的...|
|🆕 发布|Non-Invasive Detection of PROState Cancer with Novel Time-Dependent Diffusion MRI and AI-Enhanced Quantitative Radiological Interpretation: PROS-TD-AI|非侵入性前列腺癌检测：基于新型时间依赖性扩散磁共振成像与人工智能增强定量放射学解读的PROS-TD-AI方法|Baltasar Ramos, Cristian Garrido, Paulette Narv'aez, Santiago Gelerstein Claro, Haotian Li, Rafael Salvador, Constanza V'asquez-Venegas, Iv'an Gallegos .etc.|<http://arxiv.org/pdf/2509.24227v1>|提出了一种结合时间依赖性扩散MRI与AI的定量放射学解读方法，以提高前列腺癌诊断的准确性和减少误诊。|
|🆕 发布|UniVid: The Open-Source Unified Video Model|"UniVid：开源统一视频模型"|Jiabin Luo, Junhui Lin, Zeyu Zhang, Biao Wu, Meng Fang, Ling Chen, Hao Tang|<http://arxiv.org/pdf/2509.24200v1>|提出UniVid模型，通过轻量级适配器结合MLLM与扩散解码器，优化视频理解和生成性能。|
|🆕 发布|Simulating Post-Neoadjuvant Chemotherapy Breast Cancer MRI via Diffusion Model with Prompt Tuning|通过带有提示调优的扩散模型模拟新辅助化疗后乳腺癌MRI图像|Jonghun Kim, Hyunjin Park|<http://arxiv.org/pdf/2509.24185v1>|利用扩散模型和提示调优生成预测化疗后乳腺癌MRI图像，提高了图像质量和反映肿瘤变化的准确性。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Segmentor-Guided Counterfactual Fine-Tuning for Image Synthesis|“基于分割引导的反事实微调的图像合成方法”|Tian Xia, Matthew Sinclair, Andreas Schuh, Fabio De Sousa Ribeiro, Raghav Mehta, Rajat Rasal, Esther Puyol-Antón, Samuel Gerber .etc.|<http://arxiv.org/pdf/2509.24913v1>|[代码](https://github.com/biomedia-mira/seg-cft.); 提出了一种Segmentor-Guided Counterfactual Fine-Tuning方法...|
|🆕 发布|Of-SemWat: High-payload text embedding for semantic watermarking of AI-generated images with arbitrary size|《Of-SemWat：面向任意尺寸AI生成图像的高负载文本嵌入语义水印技术》|Benedetta Tondi, Andrea Costanzo, Mauro Barni|<http://arxiv.org/pdf/2509.24823v1>|提出了一种高负载文本嵌入的水印技术，将图像的语义描述嵌入图像中，增强了水印的鲁棒性和隐蔽性。|
|📝 更新|ReactDance: Hierarchical Representation for High-Fidelity and Coherent Long-Form Reactive Dance Generation|ReactDance：用于高保真和连贯长格式反应舞蹈生成的分层表示|Jingzhong Lin, Xinru Li, Yuanyuan Qi, Bohao Zhang, Wenxiang Liu, Kecheng Tang, Wenxuan Huang, Xiangfeng Xu .etc.|<http://arxiv.org/pdf/2505.05589v2>|ReactDance通过分层表示和高效采样策略，解决了高保真度和长时序连贯性的反应舞蹈生成问题。|
|🆕 发布|NeoWorld: Neural Simulation of Explorable Virtual Worlds via Progressive 3D Unfolding|NeoWorld：通过渐进式3D展开的探索性虚拟世界神经模拟|Yanpeng Zhao, Shanyan Guan, Yunbo Wang, Yanhao Ge, Wei Li, Xiaokang Yang|<http://arxiv.org/pdf/2509.24441v1>|提出了一种基于深度学习的框架NeoWorld，通过单张输入图像生成可交互的3D虚拟世界，实现了高效且...|
|📝 更新|Deepfake Detection that Generalizes Across Benchmarks|跨基准测试的深度伪造检测泛化方法|Andrii Yermakov, Jan Cech, Jiri Matas, Mario Fritz|<http://arxiv.org/pdf/2508.06248v2>|提出了一种高效的深度伪造检测方法，通过微调预训练视觉编码器的少量参数实现跨数据集的泛化性能。|
|📝 更新|InterKey: Cross-modal Intersection Keypoints for Global Localization on OpenStreetMap|跨模态交点关键点：基于开放街图的全球定位|Nguyen Hoang Khoi Tran, Julie Stephany Berrio, Mao Shan, Stewart Worrall|<http://arxiv.org/pdf/2509.13857v2>|提出了一种利用道路交叉口作为显著地标进行全局定位的跨模态框架InterKey，实现了高精度车辆定位。|
|📝 更新|Sharpness-Aware Minimization with Z-Score Gradient Filtering|锐度感知最小化与Z分数梯度滤波|Vincent-Daniel Yun|<http://arxiv.org/pdf/2505.02369v5>|[代码](https://github.com/YUNBLAK/Sharpness-Aware-Minimization-with-Z-Score-Gradient-Filtering); 提出Z-Score梯度滤波的优化策略，通过筛选高置信度梯度，提升深度学习模型泛化能力。|
|🆕 发布|Generalist Scanner Meets Specialist Locator: A Synergistic Coarse-to-Fine Framework for Robust GUI Grounding|泛用型扫描器遇见专用定位器：一种用于鲁棒GUI定位的协同粗到细框架|Zhecheng Li, Guoxian Song, Yiwei Wang, Zhen Xiong, Junsong Yuan, Yujun Cai|<http://arxiv.org/pdf/2509.24133v1>|提出了一种 coarse-to-fine 框架 GMS，结合通用视觉语言模型和特定任务模型，显著提升...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Triangle Splatting+: Differentiable Rendering with Opaque Triangles|三角喷射+：具有不透明三角形的可微分渲染|Jan Held, Renaud Vandeghen, Sanghyun Son, Daniel Rebain, Matheus Gadelha, Yi Zhou, Ming C. Lin, Marc Van Droogenbroeck .etc.|<http://arxiv.org/pdf/2509.25122v1>|[代码](https://trianglesplatting2.github.io/trianglesplatting2); 提出Triangle Splatting+方法，直接优化三角形以实现高效的3D场景重建和实时渲染。|
|🆕 发布|Fast Feature Field ($\text{F}^3$): A Predictive Representation of Events|快速特征场($\text{F}^3$)：事件预测性表征|Richeek Das, Kostas Daniilidis, Pratik Chaudhari|<http://arxiv.org/pdf/2509.25146v1>|提出了一种高效的事件数据表示方法Fast Feature Field，通过预测未来事件实现场景结构和...|
|🆕 发布|Fast Real-Time Pipeline for Robust Arm Gesture Recognition|快速实时管道用于鲁棒手臂手势识别|Milán Zsolt Bagladi, László Gulyás, Gergő Szalay|<http://arxiv.org/pdf/2509.25042v1>|提出了一种基于人体关键点估计和循环神经网络的实时手臂手势识别方法，有效应对不同视角变化。|
|🆕 发布|GEM: 3D Gaussian Splatting for Efficient and Accurate Cryo-EM Reconstruction|GEM: 用于高效和精确冷冻电镜重建的三维高斯散点绘制|Huaizhi Qu, Xiao Wang, Gengwei Zhang, Jie Peng, Tianlong Chen|<http://arxiv.org/pdf/2509.25075v1>|[代码](https://github.com/UNITES-Lab/GEM.); 提出GEM框架，使用3D高斯散点技术实现高效的冷冻电镜三维重建，提升分辨率同时降低计算和存储成本。|
|🆕 发布|Light-SQ: Structure-aware Shape Abstraction with Superquadrics for Generated Meshes|光-SQ：用于生成网格的结构感知超二次曲面形状抽象|Yuhan Wang, Weikai Chen, Zeyu Hu, Runze Zhang, Yingda Yin, Ruoyu Wu, Keyang Luo, Shengju Qian .etc.|<http://arxiv.org/pdf/2509.24986v1>|提出了一种基于超二次曲面的结构感知形状抽象方法，有效提升了3D资产生成的效率和编辑性。|
|📝 更新|PoI: A Filter to Extract Pixel of Interest from Novel View Synthesis for Scene Coordinate Regression|PoI：一种从新视角合成中提取兴趣像素以进行场景坐标回归的过滤器|Feifei Li, Qi Song, Chi Zhang, Hui Shuai, Rui Huang|<http://arxiv.org/pdf/2502.04843v4>|提出了一种双标准筛选机制，有效识别并剔除渲染图像中的次优像素，提升了场景坐标回归的准确性。|
|📝 更新|Category Discovery: An Open-World Perspective|《类别发现：开放世界视角》|Zhenqi He, Yuanpei Liu, Kai Han|<http://arxiv.org/pdf/2509.22542v2>|[代码](https://github.com/Visual-AI/Category-Discovery.); 系统综述了类别发现领域的文献，提出了分类任务的新框架和关键洞察，指导未来研究方向。|
|📝 更新|Differentiable Light Transport with Gaussian Surfels via Adapted Radiosity for Efficient Relighting and Geometry Reconstruction|通过适应辐射度的高斯微表面进行可微分光传输以实现高效重照明和几何重构|Kaiwen Jiang, Jia-Mu Sun, Zilu Li, Dan Wang, Tzu-Mao Li, Ravi Ramamoorthi|<http://arxiv.org/pdf/2509.18497v2>|引入高斯微元和改进的辐射度算法，实现了高效的全球光照效果下的几何重建和重照明。|
|📝 更新|RED: Robust Event-Guided Motion Deblurring with Modality-Specific Disentangled Representation|RED：基于模态特定解耦表示的鲁棒事件引导运动去模糊|Yihong Leng, Siming Zheng, Jinwei Chen, Bo Li, Jiaojiao Li, Peng-Tao Jiang|<http://arxiv.org/pdf/2509.05554v2>|提出了一种鲁棒的事件引导去模糊网络，通过特定模态的解耦表示显著提升了去模糊的准确性和鲁棒性。|
|📝 更新|VQToken: Neural Discrete Token Representation Learning for Extreme Token Reduction in Video Large Language Models|VQToken：用于视频大型语言模型中极简代币化的神经离散代币表示学习|Haichao Zhang, Yun Fu|<http://arxiv.org/pdf/2503.16980v6>|提出极端短令牌缩减任务，VQToken框架通过自适应向量量化显著压缩视频序列至原长的0.07%，同时...|
|🆕 发布|Neural Visibility of Point Sets|点集的神经可见性|Jun-Hao Wang, Yi-Yang Tian, Baoquan Chen, Peng-Shuai Wang|<http://arxiv.org/pdf/2509.24150v1>|[代码](https://github.com/octree-nn/neural-visibility.); 提出了一种基于3D U-Net和MLP的神经网络方法，用于高效准确判断点云中点的可见性。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DWGS: Enhancing Sparse-View Gaussian Splatting with Hybrid-Loss Depth Estimation and Bidirectional Warping|DWGS：结合混合损失深度估计与双向扭曲增强稀疏视图高斯散点法|Yu Ma, Guoliang Wei, Yue Cheng|<http://arxiv.org/pdf/2509.24893v1>|提出DWGS框架，通过混合损失深度估计和双向映射增强稀疏视图合成，实现实时高质量三维重建。|
|🆕 发布|UP2You: Fast Reconstruction of Yourself from Unconstrained Photo Collections|《UP2You：从无约束照片集合中快速重建自我》|Zeyu Cai, Ziyang Li, Xiaoben Li, Boqian Li, Zeyu Wang, Zhenyu Zhang, Yuliang Xiu|<http://arxiv.org/pdf/2509.24817v1>|[代码](https://zcai0612.github.io/UP2You); UP2You通过高效转换无约束输入为整洁的多视角图像，实现了快速重建高质量3D着装肖像。|
|📝 更新|Model-based Metric 3D Shape and Motion Reconstruction of Wild Bottlenose Dolphins in Drone-Shot Videos|基于模型的度量三维形态与运动重建：无人机视频中的野生宽吻海豚|Daniele Baieri, Riccardo Cicciarella, Michael Krützen, Emanuele Rodolà, Silvia Zuffi|<http://arxiv.org/pdf/2504.15782v2>|提出了一种基于模型的3D形状和运动重建方法，用于从单目视频估算野生海豚的体型，克服了水下观测的挑战。|
|📝 更新|G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration|引导的三维重建：融合相机与深度先验信息的G-CUT3R方法|Ramil Khafizov, Artem Komarichev, Ruslan Rakhimov, Peter Wonka, Evgeny Burnaev|<http://arxiv.org/pdf/2508.11379v2>|引入G-CUT3R方法，通过融合深度和相机先验信息，显著提升了3D场景重建性能。|
|🆕 发布|OMeGa: Joint Optimization of Explicit Meshes and Gaussian Splats for Robust Scene-Level Surface Reconstruction|OMeGa：显式网格和高斯散斑的联合优化以实现鲁棒的场景级表面重建|Yuhang Cao, Haojun Yan, Danya Yao|<http://arxiv.org/pdf/2509.24308v1>|OMeGa通过联合优化显式三角网格和高斯散点，有效解决了室内无纹理区域重建不准确的问题，实现了更精确...|
|🆕 发布|ReCon-GS: Continuum-Preserved Guassian Streaming for Fast and Compact Reconstruction of Dynamic Scenes|ReCon-GS：连续性保持的高斯流重建方法，用于动态场景的快速紧凑重建|Jiaye Fu, Qiankun Gao, Chengxiang Wen, Yanmin Wu, Siwei Ma, Jiaqi Zhang, Jian Zhang|<http://arxiv.org/pdf/2509.24325v1>|提出了一种存储感知的动态场景重建框架ReCon-GS，通过自适应的多级高斯流实现快速且紧凑的动态场景...|
|🆕 发布|PROFusion: Robust and Accurate Dense Reconstruction via Camera Pose Regression and Optimization|PROFusion：通过相机姿态回归与优化实现鲁棒且精确的稠密重建|Siyan Dong, Zijun Wang, Lulu Cai, Yi Ma, Yanchao Yang|<http://arxiv.org/pdf/2509.24236v1>|[代码](https://github.com/siyandong/PROFusion.); 通过结合基于学习的初始化和基于优化的精炼，实现了在相机运动不稳定时的实时稠密场景重建。|
|🆕 发布|Forge4D: Feed-Forward 4D Human Reconstruction and Interpolation from Uncalibrated Sparse-view Videos|Forge4D：从非校准稀疏视角视频中进行前馈4D人体重建与插值|Yingdong Hu, Yisheng He, Jinnan Chen, Weihao Yuan, Kejie Qiu, Zehong Lin, Siyu Zhu, Zilong Dong .etc.|<http://arxiv.org/pdf/2509.24209v1>|[代码](https://zhenliuzju.github.io/huyingdong); Forge4D通过流式3D高斯重建和密集运动预测，实现了从非校准稀疏视角视频快速重建动态三维人体模型...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Loc$^2$: Interpretable Cross-View Localization via Depth-Lifted Local Feature Matching|深度提升局部特征匹配的跨视角可解释定位方法Loc$^2$|Zimin Xia, Chenghao Xu, Alexandre Alahi|<http://arxiv.org/pdf/2509.09792v2>|提出了一种通过弱监督学习地面与空中图像特征对应关系的高精度、可解释的细粒度跨视角定位方法。|
|📝 更新|Open-Vocabulary Online Semantic Mapping for SLAM|开放词汇在线语义映射用于SLAM|Tomas Berriel Martins, Martin R. Oswald, Javier Civera|<http://arxiv.org/pdf/2411.15043v3>|提出了一种低计算和内存开销的在线3D语义映射方法OVO，通过神经网络合并CLIP描述符实现高效映射与...|
|🆕 发布|Mask Clustering-based Annotation Engine for Large-Scale Submeter Land Cover Mapping|基于掩膜聚类的面向大规模亚米级土地覆盖制图的标注引擎|Hao Chen, Fang Xu, Tamer Saleh, Weifeng Hao, Gui-Song Xia|<http://arxiv.org/pdf/2509.24374v1>|[代码](https://github.com/chenhaocs/MCAE); 提出了一种基于掩膜聚类的标注引擎，大幅提升大规模亚米级土地覆盖制图的标注效率和数据质量。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Perceive, Reflect and Understand Long Video: Progressive Multi-Granular Clue Exploration with Interactive Agents|感知、反思与理解长视频：基于交互式代理的渐进多粒度线索探索|Jiahua Li, Kun Wei, Zhe Xu, Zibo Su, Xu Yang, Cheng Deng|<http://arxiv.org/pdf/2509.24943v1>|提出CogniGPT框架，通过多粒度感知与验证增强的交互循环，高效可靠地理解长视频中的关键信息。|
|📝 更新|METok: Multi-Stage Event-based Token Compression for Efficient Long Video Understanding|METok：多阶段事件基 tokens 压缩以提高长视频理解效率|Mengyue Wang, Shuo Chen, Kristian Kersting, Volker Tresp, Yunpu Ma|<http://arxiv.org/pdf/2506.02850v2>|提出了一种无需训练的多阶段事件驱动的视觉数据压缩框架METok，有效降低长视频处理计算需求同时保持准...|
|🆕 发布|LOVE-R1: Advancing Long Video Understanding with an Adaptive Zoom-in Mechanism via Multi-Step Reasoning|LOVE-R1：通过多步骤推理实现自适应缩放机制以推进长视频理解|Shenghao Fu, Qize Yang, Yuan-Ming Li, Xihan Wei, Xiaohua Xie, Wei-Shi Zheng|<http://arxiv.org/pdf/2509.24786v1>|提出了一种自适应缩放机制，通过多步骤推理优化长视频理解，实现了时空信息的最优平衡。|
|🆕 发布|FrameThinker: Learning to Think with Long Videos via Multi-Turn Frame Spotlighting|《FrameThinker：通过多轮帧聚焦学习长时间视频思考》|Zefeng He, Xiaoye Qu, Yafu Li, Siyuan Huang, Daizong Liu, Yu Cheng|<http://arxiv.org/pdf/2509.24304v1>|提出FrameThinker，通过多轮帧突出显示，使大型视觉语言模型更高效处理长视频推理任务。|
|🆕 发布|Scalable Audio-Visual Masked Autoencoders for Efficient Affective Video Facial Analysis|可扩展的音频视觉掩码自动编码器用于高效情感视频面部分析|Xuecheng Wu, Junxiao Xue, Xinyi Yin, Yunyun Shi, Liangyu Fu, Danlei Huang, Yifan Wang, Jia Zhang .etc.|<http://arxiv.org/pdf/2509.24214v1>|提出了一种音频视觉联合预训练模型AVF-MAE++，通过双模态掩码和迭代学习策略，有效提升了情感视频...|
|📝 更新|Plug-and-Play 1.x-Bit KV Cache Quantization for Video Large Language Models|"视频大型语言模型的即插即用1.x位键值缓存量化"|Keda Tao, Haoxuan You, Yang Sui, Can Qin, Huan Wang|<http://arxiv.org/pdf/2503.16257v2>|提出 VidKV 方法，通过混合精度量化有效压缩视频大规模语言模型的 KV 缓存至 1.5 位和 1...|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Towards agile multi-robot systems in the real world: Fast onboard tracking of active blinking markers for relative localization|面向现实世界的敏捷多机器人系统：快速在板上追踪活动性闪烁标记物以实现相对定位|Tim Felix Lakemann, Daniel Bonilla Licea, Viktor Walter, Tomáš Báča, Martin Saska|<http://arxiv.org/pdf/2502.01172v2>|引入了主动闪烁标记跟踪技术，提高了多机器人系统中飞行器在现实世界应用的定位准确性和通信可靠性。|
|🆕 发布|Beyond Isolated Facts: Synthesizing Narrative and Grounded Supervision for VideoQA|超越孤立事实：结合叙事和具体监督进行视频问答|Jianxin Liang, Tan Yue, Yuxuan Wang, Yueqian Wang, Zhihan Yin, Huishuai Zhang, Dongyan Zhao|<http://arxiv.org/pdf/2509.24445v1>|提出合成叙事和具体视觉证据的监督信号，显著提升了视频问答模型的准确性和泛化能力。|
|🆕 发布|Rethinking JEPA: Compute-Efficient Video SSL with Frozen Teachers|重新思考JEPA：计算高效的视频自监督学习与冻结教师模型|Xianhang Li, Chen Huang, Chun-Liang Li, Eran Malach, Josh Susskind, Vimal Thilak, Etai Littwin|<http://arxiv.org/pdf/2509.24317v1>|提出了一种冻结教师网络的视频自监督学习方法SALT，提高了训练效率和模型泛化能力。|
|🆕 发布|Asymmetric VAE for One-Step Video Super-Resolution Acceleration|不对称变分自编码器用于一步视频超分辨率加速|Jianze Li, Yong Guo, Yulun Zhang, Xiaokang Yang|<http://arxiv.org/pdf/2509.24142v1>|[代码](https://github.com/JianzeLi-114/FastVSR.); 提出FastVSR方法，通过高压缩VAE和优化训练策略，大幅提升视频超分辨率效率。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DPFlow: Adaptive Optical Flow Estimation with a Dual-Pyramid Framework|DPFlow：基于双金字塔框架的自适应光流估计|Henrique Morimitsu, Xiaobin Zhu, Roberto M. Cesar Jr., Xiangyang Ji, Xu-Cheng Yin|<http://arxiv.org/pdf/2503.14880v2>|提出DPFlow，一种适应8K分辨率的光流估计架构，并引入新基准Kubric-NK评估高分辨率性能。|
|📝 更新|Every Subtlety Counts: Fine-grained Person Independence Micro-Action Recognition via Distributionally Robust Optimization|《每一细微之处皆重要：通过分布鲁棒优化实现的细粒度人体独立微动作识别》|Feng-Qi Cui, Jinyang Huang, Anyang Tong, Ziyu Jia, Jie Zhang, Zhi Liu, Dan Guo, Jianwei Lu .etc.|<http://arxiv.org/pdf/2509.21261v2>|提出了一种基于分布鲁棒优化的细粒度人物独立微动作识别框架，有效解决了个体差异导致的泛化问题。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Event-based Facial Keypoint Alignment via Cross-Modal Fusion Attention and Self-Supervised Multi-Event Representation Learning|基于跨模态融合注意力和自监督多事件表征学习的动态人脸关键点对齐|Donghwa Kang, Junho Kim, Dongwoo Kang|<http://arxiv.org/pdf/2509.24968v1>|提出了一种结合跨模态融合注意力和自监督多事件表征学习的方法，有效提升了基于事件相机的面部关键点对齐性...|
|🆕 发布|SkyLink: Unifying Street-Satellite Geo-Localization via UAV-Mediated 3D Scene Alignment|“天链：通过无人机中介的三维场景对齐实现街道-卫星地理定位统一”|Hongyang Zhang, Yinhao Liu, Zhenyu Kuang|<http://arxiv.org/pdf/2509.24783v1>|[代码](https://github.com/HRT00/CVGL-3D.); 提出了一种通过无人机辅助的三维场景对齐方法，有效解决了不同视角下地理定位的语义退化问题。|
|📝 更新|Similarity-Dissimilarity Loss for Multi-label Supervised Contrastive Learning|多标签监督对比学习的相似性-差异性损失函数|Guangming Huang, Yunfei Long, Cunjin Luo|<http://arxiv.org/pdf/2410.13439v5>|提出相似性-差异性损失函数，优化多标签监督对比学习，提升样本识别和表征空间构建效果。|
|📝 更新|Differential Encoding for Improved Representation Learning over Graphs|图上的微分编码以提升表征学习|Haimin Zhang, Jiahao Xia, Min Xu|<http://arxiv.org/pdf/2407.02758v2>|提出了一种差分编码方法，通过结合节点自身和邻居信息，有效解决了图表示学习中信息丢失问题。|


### 跨模态一致性学习 (Cross-modal Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Rethinking Unsupervised Cross-modal Flow Estimation: Learning from Decoupled Optimization and Consistency Constraint|重新思考无监督跨模态流估计：从解耦优化和一致性约束中学习|Runmin Zhang, Jialiang Wang, Si-Yuan Cao, Zhu Yu, Junchen Yu, Guangyi Zhang, Hui-Liang Shen|<http://arxiv.org/pdf/2509.24423v1>|提出了一种解耦优化和跨模态一致性约束的框架，有效解决了模态差异和几何对齐问题，实现了无监督跨模态流估...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|The Geometry of Cortical Computation: Manifold Disentanglement and Predictive Dynamics in VCNet|皮质计算的几何学：VCNet中的流形解耦与预测动力学|Brennen A. Hill, Zhang Xinyu, Timothy Putra Prasetio|<http://arxiv.org/pdf/2508.02995v2>|提出VCNet网络，借鉴灵长类视觉系统结构，通过几何框架学习低维结构化神经流形，提升视觉模型的效率和...|
|🆕 发布|Training-Free Token Pruning via Zeroth-Order Gradient Estimation in Vision-Language Models|基于零阶梯度估计的视觉语言模型无训练剪枝令牌方法|Youngeun Kim, Youjia Zhang, Huiling Liu, Aecheon Jung, Sunwoo Lee, Sungeun Hong|<http://arxiv.org/pdf/2509.24837v1>|提出了一种无需训练的视觉语言模型token剪枝方法，通过零阶梯度估计提高模型效率并保持准确率。|
|📝 更新|ARGS: Advanced Regularization on Aligning Gaussians over the Surface|ARGS：表面高斯对齐的高级正则化|Jeong Uk Lee, Sung Hee Choi|<http://arxiv.org/pdf/2508.21344v2>|引入两种正则化策略，改善3D高斯分布形状和表面一致性，提升3D网格和视觉效果质量。|
|📝 更新|Pyramid Token Pruning for High-Resolution Large Vision-Language Models via Region, Token, and Instruction-Guided Importance|通过区域、标记和指令引导的重要性进行高分辨率大规模视觉-语言模型的金字塔标记剪枝|Yuxuan Liang, Xu Li, Xiaolei Chen, Yi Zheng, Haotian Chen, Bin Li, Xiangyang Xue|<http://arxiv.org/pdf/2509.15704v2>|提出了一种无需训练的层级视觉token剪枝策略，有效降低大型视觉语言模型在高分辨率图像处理中的计算负...|
|🆕 发布|Proxy-GS: Efficient 3D Gaussian Splatting via Proxy Mesh|代理高斯散布：通过代理网格实现高效的三维高斯散布|Yuanyuan Gao, Yuning Gong, Yifei Liu, Li Jingfeng, Zhihang Zhong, Dingwen Zhang, Yanci Zhang, Dan Xu .etc.|<http://arxiv.org/pdf/2509.24421v1>|Proxy-GS引入代理网格以实现高效的遮挡感知3D高斯渲染，大幅提升渲染速度和质量。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Social 3D Scene Graphs: Modeling Human Actions and Relations for Interactive Service Robots|社交三维场景图：为交互服务机器人建模人类行为与关系|Ermanno Bartoli, Dennis Rotondi, Buwei He, Patric Jensfelt, Kai O. Arras, Iolanda Leite|<http://arxiv.org/pdf/2509.24966v1>|提出社会三维场景图，捕捉人与环境互动，增强机器人社交智能与场景理解能力。|
|📝 更新|Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy|“精度降低能否提高可靠性？对量化对CLIP准确性之外影响 systematic 评估”|Aymen Bouguerra, Daniel Montoya, Alexandra Gomez-Villa, Fabio Arnez, Chokri Mraidha|<http://arxiv.org/pdf/2509.21173v2>|系统评估量化对CLIP模型性能的影响，发现量化可提升某些可靠性指标，挑战效率与性能的传统权衡观念。|
|📝 更新|AdaRank: Adaptive Rank Pruning for Enhanced Model Merging|自适应排名剪枝以增强模型融合的AdaRank|Chanhyuk Lee, Jiho Choi, Chanryeol Lee, Donggyun Kim, Seunghoon Hong|<http://arxiv.org/pdf/2503.22178v2>|提出自适应秩剪枝方法AdaRank，通过动态修剪降低任务间干扰，提升模型合并性能。|
|📝 更新|Do Sparse Subnetworks Exhibit Cognitively Aligned Attention? Effects of Pruning on Saliency Map Fidelity, Sparsity, and Concept Coherence|稀疏子网络表现出与认知对齐的注意力吗？剪枝对显著性图保真度、稀疏性和概念一致性的影响|Sanish Suwal, Dipkamal Bhusal, Michael Clifford, Nidhi Rastogi|<http://arxiv.org/pdf/2509.21387v2>|探究了网络剪枝对模型解释性的影响，发现适度剪枝可提升注意力图的准确性和概念一致性。|
|🆕 发布|PHASE-Net: Physics-Grounded Harmonic Attention System for Efficient Remote Photoplethysmography Measurement|PHASE-Net：基于物理的谐波注意力系统用于高效远程光电容积描记术测量|Bo Zhao, Dan Guo, Junzhe Cao, Yong Xu, Tao Tan, Yue Sun, Bochao Zou, Jie Zhang .etc.|<http://arxiv.org/pdf/2509.24850v1>|提出了一种基于物理原理的远程光电容积描记测量方法，通过设计轻量级网络结构显著提升了运动和光照变化下的...|
|🆕 发布|A TRIANGLE Enables Multimodal Alignment Beyond Cosine Similarity|"三角形模型实现超越余弦相似度的多模态对齐"|Giordano Cicchetti, Eleonora Grassucci, Danilo Comminiello|<http://arxiv.org/pdf/2509.24734v1>|提出了一种三角形面积相似度方法TRIANGLE，有效提升了多模态学习的对齐效果并显著增强模型性能。|
|🆕 发布|BFSM: 3D Bidirectional Face-Skull Morphable Model|双向面部-头骨三维形变模型（BFSM）|Zidu Wang, Meng Xu, Miao Xu, Hengyuan Ma, Jiankuo Zhao, Xutao Li, Xiangyu Zhu, Zhen Lei|<http://arxiv.org/pdf/2509.24577v1>|[代码](https://github.com/wang-zidu/BFSM); 构建双向面部-头骨形态模型，解决数据稀缺和重建精度问题，实现精准医疗应用。|
|🆕 发布|Real-Aware Residual Model Merging for Deepfake Detection|深度伪造检测中的实时感知残差模型融合|Jinhee Park, Guisik Kim, Choongsang Cho, Junseok Kwon|<http://arxiv.org/pdf/2509.24367v1>|提出了一种无需重训练的Real-aware Residual Model Merging框架，有效应...|
|📝 更新|Re-Densification Meets Cross-Scale Propagation: Real-Time Neural Compression of LiDAR Point Clouds|激光雷达点云的实时神经压缩：重密集化与跨尺度传播相结合|Pengpeng Yu, Haoran Li, Runqing Jiang, Jing Wang, Liang Lin, Yulan Guo|<http://arxiv.org/pdf/2508.20466v3>|[代码](https://github.com/pengpeng-yu/FastPCC.); 提出了一种结合几何重密化和跨尺度特征传播的LiDAR点云实时压缩方法，实现了高效压缩比和实时性能。|
|🆕 发布|TP-MVCC: Tri-plane Multi-view Fusion Model for Silkie Chicken Counting|三平面多视角融合模型TP-MVCC用于丝毛鸡计数|Sirui Chen, Yuhong Feng, Yifeng Wang, Jianghai Liao, Qi Zhang|<http://arxiv.org/pdf/2509.24329v1>|提出了一种三平面多视角融合模型TP-MVCC，通过几何投影和三平面融合准确计算密集场景中的动物数量。|
|📝 更新|CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting|CompMarkGS：用于压缩3D高斯散点投射的鲁棒水印技术|Sumin In, Youngdong Jang, Utae Jeong, MinHyuk Jang, Hyeongcheol Park, Eunbyung Park, Sangpil Kim|<http://arxiv.org/pdf/2503.12836v6>|提出了一种压缩鲁棒的3D Gaussian Splatting水印方法，通过锚点特性和量化噪声注入保...|
|🆕 发布|S$^2$NN: Sub-bit Spiking Neural Networks|S$^2$NN: 子比特脉冲神经网络|Wenjie Wei, Malu Zhang, Jieyuan Zhang, Ammar Belatreche, Shuai Wang, Yimeng Shan, Hanwen Liu, Honglin Cao .etc.|<http://arxiv.org/pdf/2509.24266v1>|提出亚比特脉冲神经网络，通过优化权重表示和特征提取，提升了资源受限环境下的性能和效率。|
|🆕 发布|When MLLMs Meet Compression Distortion: A Coding Paradigm Tailored to MLLMs|当大规模语言模型遭遇压缩失真：一种针对大规模语言模型的编码范式|Jinming Liu, Zhaoyang Jia, Jiahao Li, Bin Li, Xin Jin, Wenjun Zeng, Yan Lu|<http://arxiv.org/pdf/2509.24258v1>|提出了一种针对多模态大语言模型的图像编解码方法，通过保护多级特征实现了35.99%的比特率节省。|
|🆕 发布|Accelerating Cerebral Diagnostics with BrainFusion: A Comprehensive MRI Tumor Framework|利用BrainFusion加速脑部诊断：一种全面的MRI肿瘤分析框架|Walid Houmaidi, Youssef Sabiri, Salmane El Mansour Billah, Amine Abouaomar|<http://arxiv.org/pdf/2509.24149v1>|提出 BrainFusion 框架，融合深度学习模型提升脑肿瘤 MRI 影像的准确分类与定位。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ELPG-DTFS: Prior-Guided Adaptive Time-Frequency Graph Neural Network for EEG Depression Diagnosis|ELPG-DTFS：基于先验引导的自适应时频图神经网络用于脑电图抑郁症诊断|Jingru Qiu, Jiale Liang, Xuanhan Fan, Mingda Zhang, Zhenli He|<http://arxiv.org/pdf/2509.24860v1>|提出了一种基于图神经网络的EEG抑郁诊断方法，通过自适应时间频率分析和先验知识融合，提高了诊断准确性...|
|🆕 发布|VNODE: A Piecewise Continuous Volterra Neural Network|VNODE：分段连续Volterra神经网络|Siddharth Roheda, Aniruddha Bala, Rohit Chowdhury, Rohan Jaiswal|<http://arxiv.org/pdf/2509.24659v1>|提出VNODE模型，融合Volterra滤波与连续时间微分方程，实现高效图像分类。|
|📝 更新|RainPro-8: An Efficient Deep Learning Model to Estimate Rainfall Probabilities Over 8 Hours|结果：《RainPro-8：一种高效深度学习模型，用于估计8小时内的降雨概率》|Rafael Pablos Sarabia, Joachim Nyborg, Morten Birk, Jeppe Liborius Sjørup, Anders Lillevang Vesterholt, Ira Assent|<http://arxiv.org/pdf/2505.10271v2>|提出了一种集成多源数据的深度学习模型RainPro-8，实现了8小时内高分辨率降雨概率预测的准确性及...|
|📝 更新|Implicit-ARAP: Efficient Handle-Guided Neural Field Deformation via Local Patch Meshing|隐式ARAP：通过局部补丁网格化的高效把手引导神经场形变|Daniele Baieri, Filippo Maggioli, Emanuele Rodolà, Simone Melzi, Zorah Lähner|<http://arxiv.org/pdf/2405.12895v3>|提出了一种利用局部网格片处理实现神经场变形的新方法，提高了变形质量和计算效率。|
|🆕 发布|Foggy Crowd Counting: Combining Physical Priors and KAN-Graph|雾天人群计数：结合物理先验和KAN-图|Yuhao Wang, Zhuoran Zheng, Han Hu, Dianjie Lu, Guijuan Zhang, Chen Lyu|<http://arxiv.org/pdf/2509.24545v1>|定位雾天人群计数难题，提出结合物理先验和KAN-图的方法，有效提升计数准确度。|
|📝 更新|Invisible Yet Detected: PelFANet with Attention-Guided Anatomical Fusion for Pelvic Fracture Diagnosis|“隐形却可被检测：基于注意力引导的解剖融合PelFANet用于骨盆骨折诊断”|Siam Tahsin Bhuiyan, Rashedur Rahman, Sefatul Wasi, Naomi Yagi, Syoji Kobashi, Ashraful Islam, Saadia Binte Alam|<http://arxiv.org/pdf/2509.13873v2>|提出PelFANet，一种融合原始骨盆X光片与分割骨像的双流注意力网络，有效提升细微骨折诊断准确性。|
|🆕 发布|Performance-Efficiency Trade-off for Fashion Image Retrieval|时尚图像检索的性能效率权衡|Julio Hurtado, Haoran Ni, Duygu Sap, Connor Mattinson, Martin Lotz|<http://arxiv.org/pdf/2509.24477v1>|提出选择性表示框架，缩小数据库规模90%而不牺牲检索准确性，优化二手服装图像检索效率。|
|🆕 发布|A Data-Centric Perspective on the Influence of Image Data Quality in Machine Learning Models|《从数据中心视角探讨图像数据质量对机器学习模型影响》|Pei-Han Chen, Szu-Chi Chung|<http://arxiv.org/pdf/2509.24420v1>|探讨了图像数据质量对机器学习模型性能的影响，并提出了一套评估和提升数据质量的流程。|
|🆕 发布|Hybrid Layer-Wise ANN-SNN With Surrogate Spike Encoding-Decoding Structure|混合逐层神经网络-脉冲神经网络与替代脉冲编码-解码结构|Nhan T. Luu, Duong T. Luu, Pham Ngoc Nam, Truong Cong Thang|<http://arxiv.org/pdf/2509.24411v1>|提出了一种结合层状ANN与SNN的混合框架，通过替代梯度实现端到端训练，提升了效率和准确性。|
|📝 更新|MINGLE: Mixture of Null-Space Gated Low-Rank Experts for Test-Time Continual Model Merging|MINGLE：测试时持续模型合并的零空间门控低秩专家混合方法|Zihuan Qiu, Yi Xu, Chiyuan He, Fanman Meng, Linfeng Xu, Qingbo Wu, Hongliang Li|<http://arxiv.org/pdf/2505.11883v2>|[代码](https://github.com/zihuanqiu/MINGLE); 提出MINGLE框架，通过测试时模型合并和低秩专家动态适应，有效解决持续学习中的遗忘和分布偏移问题。|
|🆕 发布|LatXGen: Towards Radiation-Free and Accurate Quantitative Analysis of Sagittal Spinal Alignment Via Cross-Modal Radiographic View Synthesis|LatXGen：通过跨模态放射视图合成实现无辐射且精确的矢状脊柱对齐定量分析|Moxin Zhao, Nan Meng, Jason Pui Yin Cheung, Chris Yuk Kwan Tang, Chenxi Yu, Wenting Zhong, Pengyu Lu, Chang Shi .etc.|<http://arxiv.org/pdf/2509.24165v1>|提出了一种生成框架LatXGen，通过从后部RGBD图像合成真实 lateral spinal ra...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MANI-Pure: Magnitude-Adaptive Noise Injection for Adversarial Purification|《MANI-Pure：基于幅度自适应噪声注入的对抗性净化方法》|Xiaoyi Huang, Junwei Wu, Kejia Zhang, Carl Yang, Zhiming Luo|<http://arxiv.org/pdf/2509.25082v1>|提出了一种自适应幅度的噪声注入方法MANI-Pure，有效抑制高频区的对抗性扰动，保护语义结构，提升...|
|🆕 发布|DRIFT: Divergent Response in Filtered Transformations for Robust Adversarial Defense|DRIFT：基于滤波变换的分歧响应用于稳健的对抗性防御|Amira Guesmi, Muhammad Shafique|<http://arxiv.org/pdf/2509.24359v1>|提出DRIFT方法，通过破坏梯度一致性增强对抗性防御能力，显著提升模型鲁棒性。|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Uncertainty-Aware Deep Learning for Wildfire Danger Forecasting|不确定性感知的深度学习在森林火灾危险预测中的应用|Spyros Kondylatos, Gustau Camps-Valls, Ioannis Papoutsis|<http://arxiv.org/pdf/2509.25017v1>|提出不确定性感知深度学习框架，有效提升短期 wildfire 预测准确性和可靠性。|
|📝 更新|Dynamic Uncertainty Learning with Noisy Correspondence for Text-Based Person Search|基于噪声对应关系的动态不确定性学习在文本人物搜索中的应用|Zequn Xie, Haoming Ji, Chengxuan Li, Lingwei Meng|<http://arxiv.org/pdf/2505.06566v2>|提出动态不确定性学习框架DURA，有效应对文本图像匹配中的噪声问题，提升检索可靠性。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Learning Smooth State-Dependent Traversability from Dense Point Clouds|从稠密点云中学习平滑的状态依赖性可通行性|Zihao Dong, Alan Papalia, Leonard Jung, Alenna Spiro, Philip R. Osteen, Christa S. Robison, Michael Everett|<http://arxiv.org/pdf/2506.04362v2>|[代码](https://github.com/neu-autonomy/SPARTA.); 提出了一种从点云估计角度相关通行性的方法，通过平滑分析函数预测任意角度的风险分布，提高了越野自主性的...|


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Improving Generalizability and Undetectability for Targeted Adversarial Attacks on Multimodal Pre-trained Models|提高针对多模态预训练模型的目标对抗攻击的泛化性和不可检测性|Zhifang Zhang, Jiahan Zhang, Shengjie Zhou, Qi Wei, Shuo He, Feng Liu, Lei Feng|<http://arxiv.org/pdf/2509.19994v2>|提出了一种Proxy Targeted Attack方法，增强了针对多模态预训练模型的目标攻击在泛化...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VT-FSL: Bridging Vision and Text with LLMs for Few-Shot Learning|VT-FSL：使用大规模语言模型连接视觉与文本以进行少样本学习|Wenhao Li, Qiangchang Wang, Xianjing Meng, Zhibin Wu, Yilong Yin|<http://arxiv.org/pdf/2509.25033v1>|[代码](https://github.com/peacelwh/VT-FSL.); 提出VT-FSL框架，利用大型语言模型和视觉数据生成精确描述，实现少样本学习的跨模态融合。|
|📝 更新|NoiseSDF2NoiseSDF: Learning Clean Neural Fields from Noisy Supervision|从噪声监督中学习干净神经场的NoiseSDF2NoiseSDF:|Tengkai Wang, Weihao Li, Ruikai Cui, Shi Qiu, Nick Barnes|<http://arxiv.org/pdf/2507.13595v2>|提出了一种从噪声点云中直接学习干净神经SDF的方法，显著提高了表面重建质量。|
|🆕 发布|Learning Goal-Oriented Language-Guided Navigation with Self-Improving Demonstrations at Scale|学习面向目标的语言引导导航：基于大规模自我改进演示的算法|Songze Li, Zun Wang, Gengze Zhou, Jialu Li, Xiangyu Zeng, Limin Wang, Yu Qiao, Qi Wu .etc.|<http://arxiv.org/pdf/2509.24910v1>|提出了一种自提升演示的导航学习方法，通过迭代改进探索策略，显著提升了面向目标的语言引导导航性能。|
|🆕 发布|Vehicle Classification under Extreme Imbalance: A Comparative Study of Ensemble Learning and CNNs|车辆分类在极端不平衡下的研究：集成学习与卷积神经网络比较分析|Abu Hanif Muhammad Syarubany|<http://arxiv.org/pdf/2509.24880v1>|研究了在极端不平衡数据下车辆分类问题，对比了集成学习和卷积神经网络，发现深度模型具有优势。|
|🆕 发布|Discovering "Words" in Music: Unsupervised Learning of Compositional Sparse Code for Symbolic Music|在音乐中发现“单词”：符号音乐的作曲稀疏码的无监督学习|Tianle Wang, Sirui Zhang, Xinyi Tong, Peiyang Yu, Jishang Chen, Liangke Zhao, Xinpu Gao, Yves Zhu .etc.|<http://arxiv.org/pdf/2509.24603v1>|提出了一种无监督学习算法，从乐谱数据中发现音乐的基本构建模块，助力音乐分析和生成。|
|🆕 发布|A Novel Preprocessing Unit for Effective Deep Learning based Classification and Grading of Diabetic Retinopathy|一种用于深度学习基础上有效分类和分级糖尿病视网膜病变的新型预处理单元|Pranoti Nage, Sanjay Shitole|<http://arxiv.org/pdf/2509.24497v1>|提出了一种改进的预处理单元，通过自适应变量距离滤波器增强图像对比度，提高了糖尿病视网膜病变检测和分级...|
|📝 更新|GLEAM: Learning Generalizable Exploration Policy for Active Mapping in Complex 3D Indoor Scenes|GLEAM：学习复杂三维室内场景主动映射的通用探索策略|Xiao Chen, Tai Wang, Quanyi Li, Tao Huang, Jiangmiao Pang, Tianfan Xue|<http://arxiv.org/pdf/2505.20294v2>|提出GLEAM方法，通过语义表示、长期导航目标和随机策略提升移动机器人在复杂三维室内场景的通用主动建...|
|📝 更新|Frequency-Aware Ensemble Learning for BraTS 2025 Pediatric Brain Tumor Segmentation|频率感知集成学习用于 BraTS 2025 儿童脑肿瘤分割|Yuxiao Yi, Qingyao Zhuang, Zhi-Qin John Xu|<http://arxiv.org/pdf/2509.19353v2>|提出了一种集成学习方法，通过调整初始化规模、迁移学习和频率域分解，有效提升了儿童脑肿瘤分割的准确性。|
|🆕 发布|Analysis of Bias in Deep Learning Facial Beauty Regressors|深度学习面部美丑回归器中的偏见分析|Chandon Hamel, Mike Busch|<http://arxiv.org/pdf/2509.24138v1>|揭示了深度学习面部美丑评估系统中的种族偏见，并提出了平衡美学技术的潜在途径。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CORE-3D: Context-aware Open-vocabulary Retrieval by Embeddings in 3D|CORE-3D：基于三维嵌入的上下文感知开放式词汇检索|Mohamad Amin Mirzaei, Pantea Amoie, Ali Ekhterachian, Matin Mirzababaei|<http://arxiv.org/pdf/2509.24528v1>|提出了一种结合语义分割和上下文感知编码的策略，有效提升了三维场景理解和物体检索的准确性。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Euclid's Gift: Enhancing Spatial Perception and Reasoning in Vision-Language Models via Geometric Surrogate Tasks|欧几里得的礼物：通过几何替代任务增强视觉语言模型的空间感知与推理能力|Shijie Lian, Changti Wu, Laurence Tianruo Yang, Hang Yuan, Bin Yu, Lei Zhang, Kai Chen|<http://arxiv.org/pdf/2509.24473v1>|[代码](https://zgca-ai4edu.github.io/Euclids_Gift.); 通过几何问题解决作为辅助任务，提升了视觉语言模型的空间感知和推理能力。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AIRoA MoMa Dataset: A Large-Scale Hierarchical Dataset for Mobile Manipulation|AIRoA MoMa 数据集：面向移动操作的大规模层次化数据集|Ryosuke Takanami, Petr Khrapchenkov, Shu Morikuni, Jumpei Arima, Yuta Takaba, Shunsuke Maeda, Takuya Okubo, Genki Sano .etc.|<http://arxiv.org/pdf/2509.25032v1>|介绍了AIRoA MoMa数据集，为移动操作提供大规模多模态数据，包含丰富接触和长期任务，支持分层学...|
|📝 更新|FindingDory: A Benchmark to Evaluate Memory in Embodied Agents|《FindingDory：一个用于评估具身智能体记忆的基准测试》|Karmesh Yadav, Yusuf Ali, Gunshi Gupta, Yarin Gal, Zsolt Kira|<http://arxiv.org/pdf/2506.15635v2>|提出了FindingDory基准，用于评估机器人在长期任务中的记忆能力，并提供了与先进视觉语言模型结...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vision-and-Language Navigation with Analogical Textual Descriptions in LLMs|基于大型语言模型中的类比文本描述的视觉与语言导航|Yue Zhang, Tianyi Ma, Zun Wang, Yanyuan Qiao, Parisa Kordjamshidi|<http://arxiv.org/pdf/2509.25139v1>|通过引入多视角文本描述促进类比推理，提升了视觉语言导航代理的场景理解和空间推理能力。|
|📝 更新|HERO: Rethinking Visual Token Early Dropping in High-Resolution Large Vision-Language Models|HERO：重新思考高分辨率大型视觉语言模型中视觉标记的早期丢弃问题|Xu Li, Yuxuan Liang, Xiaolei Chen, Yi Zheng, Haotian Chen, Bin Li, Xiangyang Xue|<http://arxiv.org/pdf/2509.13067v2>|提出了一种视觉token早期丢弃框架HERO，通过自适应内容分配预算和功能感知选择，优化了高分辨率视...|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Pixels Versus Priors: Controlling Knowledge Priors in Vision-Language Models through Visual Counterfacts|像素与先验：通过视觉反事实控制视觉-语言模型中的知识先验|Michal Golovanevsky, William Rudman, Michael Lepori, Amir Bar, Ritambhara Singh, Carsten Eickhoff|<http://arxiv.org/pdf/2505.17127v2>|探究并控制视觉语言模型依赖先验知识还是视觉信息，提出Pixels Versus Priors干预机制...|
|📝 更新|Multimodal Iterative RAG for Knowledge-Intensive Visual Question Answering|多模态迭代图推理用于知识密集型视觉问答|Changin Choi, Wonseok Lee, Jungmin Ko, Wonjong Rhee|<http://arxiv.org/pdf/2509.00798v4>|提出了一种迭代的多模态检索增强框架MI-RAG，通过推理指导的多次查询和知识合成，有效提升知识密集型...|
|🆕 发布|VTPerception-R1: Enhancing Multimodal Reasoning via Explicit Visual and Textual Perceptual Grounding|VTPerception-R1：通过显式的视觉和文本感知接地增强多模态推理|Yizhuo Ding, Mingkang Chen, Zhibang Feng, Tong Xiao, Wanying Qu, Wenqi Shao, Yanwei Fu|<http://arxiv.org/pdf/2509.24776v1>|[代码](https://github.com/yizhuoDi/VTPerceprion-R1.); 提出了一种统一的两阶段框架VTPerception-R1，通过显式视觉和文本感知增强多模态推理的准确...|
|🆕 发布|Can you SPLICE it together? A Human Curated Benchmark for Probing Visual Reasoning in VLMs|“你能将它拼接起来吗？一个用于探测视觉语言模型视觉推理能力的人类精选基准”|Mohamad Ballout, Okajevo Wilfred, Seyedalireza Yaghoubi, Nohayr Muhammad Abdelmoneim, Julius Mayer, Elia Bruni|<http://arxiv.org/pdf/2509.24640v1>|提出SPLICE基准，评估视觉语言模型在多维度事件推理上的能力，揭示模型在视觉推理上的不足。|
|📝 更新|Causality-guided Prompt Learning for Vision-language Models via Visual Granulation|通过视觉粒度化的因果引导提示学习用于视觉-语言模型的策略|Mengyu Gao, Qiulei Dong|<http://arxiv.org/pdf/2509.03803v2>|提出了一种基于因果推理的视觉粒度引导的提示学习方法，有效提升了细粒度数据集上的识别性能。|
|🆕 发布|Mitigating Visual Hallucinations via Semantic Curriculum Preference Optimization in MLLMs|通过语义课程偏好优化在多模态大型语言模型中减轻视觉幻觉|Yuanshuai Li, Yuping Yan, Junfeng Tang, Yunxuan Li, Zeqi Zheng, Yaochu Jin|<http://arxiv.org/pdf/2509.24491v1>|提出了一种针对多模态大语言模型的语义课程偏好优化框架，有效减少视觉幻觉现象。|
|📝 更新|Visual Planning: Let's Think Only with Images|视觉规划：仅用图像思考|Yi Xu, Chengzu Li, Han Zhou, Xingchen Wan, Caiqi Zhang, Anna Korhonen, Ivan Vulić|<http://arxiv.org/pdf/2505.11409v2>|提出视觉规划新范式，通过纯图像推理提升空间任务规划效果。|
|🆕 发布|Dynamic Orchestration of Multi-Agent System for Real-World Multi-Image Agricultural VQA|动态编排多智能体系统以实现现实世界多图像农业视觉问答|Yan Ke, Xin Yu, Heming Du, Scott Chapman, Helen Huang|<http://arxiv.org/pdf/2509.24350v1>|提出多代理系统框架应对多图像农业视觉问答挑战，实现上下文丰富和答案迭代优化。|
|🆕 发布|TraitSpaces: Towards Interpretable Visual Creativity for Human-AI Co-Creation|《特质空间：迈向可解释的视觉创造力以促进人机协同创作》|Prerna Luthra|<http://arxiv.org/pdf/2509.24326v1>|提出了一种基于心理理论和艺术家见解的视觉创造力建模框架，支持可解释的视觉创作与人工智能协同。|
|📝 更新|MASt3R-Fusion: Integrating Feed-Forward Visual Model with IMU, GNSS for High-Functionality SLAM|MASt3R-Fusion：将前馈视觉模型与IMU、GNSS集成用于高功能性的SLAM|Yuxuan Zhou, Xingxing Li, Shengyu Li, Zhuohao Yan, Chunxi Xia, Shaoquan Feng|<http://arxiv.org/pdf/2509.20757v2>|[代码](https://github.com/GREAT-WHU/MASt3R-Fusion); 整合视觉模型与IMU、GNSS数据，MASt3R-Fusion提升了SLAM在低纹理环境下的准确性和...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TemMed-Bench: Evaluating Temporal Medical Image Reasoning in Vision-Language Models|TemMed-Bench：评估视觉语言模型中的时间医学图像推理|Junyi Zhang, Jia-Chen Gu, Wenbo Hu, Yu Zhou, Robinson Piramuthu, Nanyun Peng|<http://arxiv.org/pdf/2509.25143v1>|提出TemMed-Bench基准，评估视觉语言模型在分析患者随时间变化的医疗图像方面的推理能力，并发...|
|🆕 发布|Evaluating Temperature Scaling Calibration Effectiveness for CNNs under Varying Noise Levels in Brain Tumour Detection|评估温度缩放校准在脑肿瘤检测中不同噪声水平下卷积神经网络的有效性|Ankur Chanda, Kushan Choudhury, Shubhrodeep Roy, Shubhajit Biswas, Somenath Kuiry|<http://arxiv.org/pdf/2509.24951v1>|评估了温度缩放对CNN在脑肿瘤检测中置信度估计的校准效果，证实其在不同噪声条件下能提高决策可靠性。|
|🆕 发布|MMRQA: Signal-Enhanced Multimodal Large Language Models for MRI Quality Assessment|MMRQA：信号增强的多模态大型语言模型用于MRI质量评估|Fankai Jia, Daisong Gan, Zhe Zhang, Zhaochi Wen, Chenchen Dan, Dong Liang, Haifeng Wang|<http://arxiv.org/pdf/2509.24888v1>|整合多模态大语言模型与信号处理，MMRQA框架提升MRI质量评估的准确性与可解释性。|
|🆕 发布|TACO-Net: Topological Signatures Triumph in 3D Object Classification|TACO-Net：拓扑签名在三维物体分类中的胜利|Anirban Ghosh, Ayan Dutta|<http://arxiv.org/pdf/2509.24802v1>|提出了一种结合拓扑数据分析和图像滤波技术的3D物体分类方法，实现了高准确率和强鲁棒性。|
|🆕 发布|Generalist Multi-Class Anomaly Detection via Distillation to Two Heterogeneous Student Networks|通过向两个异质学生网络进行蒸馏实现的通用多类异常检测|Hangil Park, Yongmin Seo, Tae-Kyun Kim|<http://arxiv.org/pdf/2509.24448v1>|提出了一种基于知识蒸馏的双模型集成方法，实现了多领域异常检测的通用性和高性能。|
|📝 更新|Bidirectional Uncertainty-Aware Region Learning for Semi-Supervised Medical Image Segmentation|双向不确定性感知区域学习用于半监督医学图像分割|Shiwei Zhou, Xin Liu, Haifeng Zhao, Bin Luo, Dengdi Sun|<http://arxiv.org/pdf/2502.07457v2>|提出双向不确定性感知区域学习策略，有效利用标注数据精确监督并稳定未标注数据训练，显著提升半监督医疗图...|
|🆕 发布|PCICF: A Pedestrian Crossing Identification and Classification Framework|行人横穿识别与分类框架：PCICF|Junyi Gu, Beatriz Cabrero-Daniel, Ali Nouri, Lydia Armini, Christian Berger|<http://arxiv.org/pdf/2509.24386v1>|[代码](https://github.com/Claud1234/PCICF); 提出PCICF框架，通过构建多行人场景数据集和空间填充曲线技术，有效识别和分类复杂行人横穿情况。|
|🆕 发布|An Enhanced Pyramid Feature Network Based on Long-Range Dependencies for Multi-Organ Medical Image Segmentation|基于长距离依赖性的增强金字塔特征网络用于多器官医学图像分割|Dayu Tan, Cheng Kong, Yansen Su, Hai Chen, Dongliang Yang, Junfeng Xia, Chunhou Zheng|<http://arxiv.org/pdf/2509.24358v1>|提出了一种高效捕获长距离依赖和局部细节的LamFormer网络，实现了多器官医学图像精细分割的性能提...|
|🆕 发布|Skeleton-based Robust Registration Framework for Corrupted 3D Point Clouds|基于骨架的鲁棒注册框架用于修复三维点云|Yongqiang Wang, Weigang Li, Wenping Liu, Zhiqiang Tian, Jinling Li|<http://arxiv.org/pdf/2509.24273v1>|提出了一种基于骨架的鲁棒注册框架，有效应对了3D点云中的噪声和几何变形问题，提高了注册准确性和鲁棒性...|
|🆕 发布|Cycle Diffusion Model for Counterfactual Image Generation|循环扩散模型用于反事实图像生成|Fangrui Huang, Alan Wang, Binxu Li, Bailey Trang, Ridvan Yesiloglu, Tianyu Hua, Wei Peng, Ehsan Adeli|<http://arxiv.org/pdf/2509.24267v1>|提出了一种循环训练框架的Cycle Diffusion Model，通过增强条件一致性和图像真实性，...|
|📝 更新|MIAFEx: An Attention-based Feature Extraction Method for Medical Image Classification|MIAFEx：一种基于注意力的医学图像分类特征提取方法|Oscar Ramos-Soto, Jorge Ramos-Frutos, Ezequiel Perez-Zarate, Diego Oliva, Sandra E. Balderas-Mata|<http://arxiv.org/pdf/2501.08562v2>|[代码](https://github.com/Oscar-RamosS/Medical-Image-Attention-based-Feature-Extractor-MIAFEx); 提出了一种基于注意力机制的医疗图像特征提取方法MIAFEx，有效提高了小样本情况下的分类准确性和鲁棒...|
|🆕 发布|High-Order Progressive Trajectory Matching for Medical Image Dataset Distillation|高阶渐进轨迹匹配用于医学图像数据集蒸馏|Le Dong, Jinghao Bian, Jingyang Hou, Jingliang Hu, Yilei Shi, Weisheng Dong, Xiao Xiang Zhu, Lichao Mou|<http://arxiv.org/pdf/2509.24177v1>|[代码](https://github.com/Bian-jh/HoP-TM.); 提出高阶渐进轨迹匹配方法，优化医学图像数据集蒸馏，提升隐私保护下的模型准确度。|
|🆕 发布|Tumor Synthesis conditioned on Radiomics|基于放射组学的肿瘤合成|Jonghun Kim, Inye Na, Eun Sook Ko, Hyunjin Park|<http://arxiv.org/pdf/2509.24182v1>|提出了一种利用放射omics特征生成肿瘤图像的方法，解决了医学图像分析中隐私问题和数据不足的挑战。|
|🆕 发布|EYE-DEX: Eye Disease Detection and EXplanation System|眼疾检测与解释系统（EYE-DEX）|Youssef Sabiri, Walid Houmaidi, Amine Abouaomar|<http://arxiv.org/pdf/2509.24136v1>|提出EYE-DEX系统，利用深度学习自动诊断视网膜疾病并提升解释性。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GeoVLM-R1: Reinforcement Fine-Tuning for Improved Remote Sensing Reasoning|GeoVLM-R1：强化微调以提高遥感推理能力|Mustansar Fiaz, Hiyam Debary, Paolo Fraccaro, Danda Paudel, Luc Van Gool, Fahad Khan, Salman Khan|<http://arxiv.org/pdf/2509.25026v1>|[代码](https://mustansarfiaz.github.io/GeoVLM-R1); 提出了一种结合任务感知奖励的强化学习微调框架，有效提升了遥感图像的任务推理能力。|
|🆕 发布|Environment-Aware Satellite Image Generation with Diffusion Models|基于扩散模型的面向环境的卫星图像生成|Nikos Kostagiolas, Pantelis Georgiades, Yannis Panagakis, Mihalis A. Nicolaou|<http://arxiv.org/pdf/2509.24875v1>|提出了一种环境感知的扩散模型，通过结合文本、元数据和视觉信号生成高质量卫星图像，提升了生成准确性和鲁...|
|📝 更新|S2S-Net: Addressing the Domain Gap of Heterogeneous Sensor Systems in LiDAR-Based Collective Perception|S2S-Net：解决基于激光雷达的集体感知中异构传感器系统的域差距问题|Sven Teufel, Jörg Gamerdinger, Oliver Bringmann|<http://arxiv.org/pdf/2504.17399v2>|首次解决异构传感器系统在集体感知中的域差距问题，提出S2S-Net方法显著提升性能。|
|🆕 发布|From Satellite to Street: A Hybrid Framework Integrating Stable Diffusion and PanoGAN for Consistent Cross-View Synthesis|从卫星到街道：一种融合稳定扩散与全景生成对抗网络的一致性跨视角合成混合框架|Khawlah Bajbaa, Abbas Anwar, Muhammad Saqib, Hafeez Anwar, Nabin Sharma, Muhammad Usman|<http://arxiv.org/pdf/2509.24369v1>|提出了一种融合稳定扩散模型和条件生成对抗网络的框架，实现了从卫星图像到街道视图的准确转换。|
|📝 更新|OSDA: A Framework for Open-Set Discovery and Automatic Interpretation of Land-cover in Remote Sensing Imagery|OSDA：一种遥感影像中地表覆盖的开集发现与自动解释框架|Siyi Chen, Kai Wang, Weicong Pang, Ruiming Yang, Ziru Chen, Renjun Gao, Alexis Kai Hon Lau, Dasa Gu .etc.|<http://arxiv.org/pdf/2509.18693v2>|提出OSDA框架，实现无需标注的开集土地覆盖自动发现与解释，提升遥感图像解析能力。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|3DGAA: Realistic and Robust 3D Gaussian-based Adversarial Attack for Autonomous Driving|三维高斯基础上的真实与鲁棒对抗攻击方法研究：面向自动驾驶|Yixun Zhang, Lizhi Wang, Junjun Zhao, Wending Zhao, Feng Zhou, Yonghao Dang, Jianqin Yin|<http://arxiv.org/pdf/2507.09993v3>|提出3DGAA方法，通过优化几何和外观属性生成逼真的三维对抗物体，显著提升自动驾驶系统中的攻击效果和...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Wavelet-Assisted Mamba for Satellite-Derived Sea Surface Temperature Super-Resolution|结果： 基于小波辅助的Mamba算法实现卫星衍生海表温度超分辨率重建|Wankun Chen, Feng Gao, Yanhai Gan, Jingchao Cao, Junyu Dong, Qian Du|<http://arxiv.org/pdf/2509.24334v1>|[代码](https://github.com/oucailab/WMSR.); 提出了一种基于波浪辅助的Mamba框架，有效提升了卫星衍生海表温度数据的超分辨率性能。|
|🆕 发布|Similarity-Aware Selective State-Space Modeling for Semantic Correspondence|具有相似性感知的选择性状态空间建模用于语义对应关系|Seungwook Kim, Minsu Cho|<http://arxiv.org/pdf/2509.24318v1>|提出了一种高效的语义对应方法MambaMatcher，通过选择性状态空间模型有效建模高维相关性，实现...|

