## [UPDATED!] **2025-09-30** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Stitch: Training-Free Position Control in Multimodal Diffusion Transformers|“Stitch：无需训练的多模态扩散变换器中的位置控制”|Jessica Bader, Mateusz Pach, Maria A. Bravo, Serge Belongie, Zeynep Akata|<http://arxiv.org/pdf/2509.26644v1>|[代码](https://github.com/ExplainableML/Stitch.); 提出了一种无需训练的Stitch方法，通过自动生成的边界框将外部位置控制融入多模态扩散变换器，显著提...|
|🆕 发布|GastroViT: A Vision Transformer Based Ensemble Learning Approach for Gastrointestinal Disease Classification with Grad CAM & SHAP Visualization|胃肠ViT：一种基于视觉变换器的胃肠疾病分类集成学习方法，结合Grad CAM与SHAP可视化|Sumaiya Tabassum, Md. Faysal Ahamed, Hafsa Binte Kibria, Md. Nahiduzzaman, Julfikar Haider, Muhammad E. H. Chowdhury, Mohammad Tariqul Islam|<http://arxiv.org/pdf/2509.26502v1>|提出了一种基于预训练视觉变换器的集成学习方法，用于准确分类胃肠道疾病，并通过解释性AI技术增强模型可...|
|📝 更新|Octic Vision Transformers: Quicker ViTs Through Equivariance|八次视变换器：通过等方差性实现更快的视觉变换器|David Nordström, Johan Edstedt, Fredrik Kahl, Georg Bökman|<http://arxiv.org/pdf/2505.15441v4>|引入了基于八重对称性的Octic Vision Transformers，实现了计算效率的大幅提升。|
|🆕 发布|AttriGen: Automated Multi-Attribute Annotation for Blood Cell Datasets|AttriGen：血液细胞数据集的自动化多属性标注|Walid Houmaidi, Youssef Sabiri, Fatima Zahra Iguenfer, Amine Abouaomar|<http://arxiv.org/pdf/2509.26185v1>|提出AttriGen框架，自动为血细胞数据集进行细致的多属性标注，提高分类准确性和效率。|
|📝 更新|Object Detection with Multimodal Large Vision-Language Models: An In-depth Review|多模态大规模视觉-语言模型的目标检测：深度综述|Ranjan Sapkota, Manoj Karkee|<http://arxiv.org/pdf/2508.19294v2>|系统综述了多模态大规模视觉语言模型在物体检测中的创新应用，提升了适应性和上下文理解能力。|
|🆕 发布|NePTune: A Neuro-Pythonic Framework for Tunable Compositional Reasoning on Vision-Language|海王星：一种用于可调整组合推理的神经-Pythonic框架（面向视觉-语言领域）|Danial Kamali, Parisa Kordjamshidi|<http://arxiv.org/pdf/2509.25757v1>|NePTune通过结合基础视觉模型的感知能力和符号推理的组成表达，实现了对视觉语言模型在组合推理上的...|
|📝 更新|QuantSparse: Comprehensively Compressing Video Diffusion Transformer with Model Quantization and Attention Sparsification|《QuantSparse：通过模型量化和注意力稀疏化全面压缩视频扩散变换器》|Weilun Feng, Chuanguang Yang, Haotong Qin, Mingqiang Wu, Yuqi Li, Xiangqi Li, Zhulin An, Libo Huang .etc.|<http://arxiv.org/pdf/2509.23681v2>|[代码](https://github.com/wlfeng0509/QuantSparse.); 提出QuantSparse框架，结合模型量化和注意力稀疏化，显著提升视频生成模型的压缩效率和性能。|
|🆕 发布|AIMCoT: Active Information-driven Multimodal Chain-of-Thought for Vision-Language Reasoning|AIMCoT：主动信息驱动的多模态思维链用于视觉语言推理|Xiping Li, Jianghong Ma|<http://arxiv.org/pdf/2509.25699v1>|提出AIMCoT框架，通过主动信息驱动和动态调整，提升视觉语言推理的准确性和效率。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Seeing Through Deception: Uncovering Misleading Creator Intent in Multimodal News with Vision-Language Models|《透过欺骗之眼：利用视觉-语言模型揭示多模态新闻中误导性创作者意图》|Jiaying Wu, Fanxiao Li, Zihang Fu, Min-Yen Kan, Bryan Hooi|<http://arxiv.org/pdf/2505.15489v3>|提出DeceptionDecoded数据集，用于检测新闻创作者的误导性意图，揭示了现有视觉语言模型的...|
|📝 更新|Developing Generalist Foundation Models from a Multimodal Dataset for 3D Computed Tomography|从多模态数据集开发用于三维计算机断层扫描的全能基础模型|Ibrahim Ethem Hamamci, Sezgin Er, Chenyu Wang, Furkan Almas, Ayse Gulnihan Simsek, Sevval Nil Esirgun, Irem Dogan, Omer Faruk Durugol .etc.|<http://arxiv.org/pdf/2403.17834v4>|构建了大规模3D医疗图像与文本报告数据集CT-RATE，并提出了CT-CLIP和CT-CHAT模型，...|
|🆕 发布|EditReward: A Human-Aligned Reward Model for Instruction-Guided Image Editing|《EditReward：一种面向指令引导图像编辑的对齐人类奖励模型》|Keming Wu, Sicong Jiang, Max Ku, Ping Nie, Minghao Liu, Wenhu Chen|<http://arxiv.org/pdf/2509.26346v1>|提出了EditReward，一种与人类偏好高度一致的评价模型，用于指导图像编辑任务并提升训练数据质量...|
|📝 更新|RobustMerge: Parameter-Efficient Model Merging for MLLMs with Direction Robustness|鲁棒合并：面向多语言大型语言模型的参数高效模型合并方法及其方向鲁棒性|Fanhu Zeng, Haiyang Guo, Fei Zhu, Li Shen, Hao Tang|<http://arxiv.org/pdf/2502.17159v2>|[代码](https://github.com/AuroraZengfh/RobustMerge.); 提出了一种参数高效的模型融合方法RobustMerge，通过保持方向稳健性，有效解决了多任务学习中的...|
|🆕 发布|IMG: Calibrating Diffusion Models via Implicit Multimodal Guidance|隐式多模态引导校准扩散模型|Jiayi Guo, Chuanhao Yan, Xingqian Xu, Yulin Wang, Kai Wang, Gao Huang, Humphrey Shi|<http://arxiv.org/pdf/2509.26231v1>|[代码](https://github.com/SHI-Labs/IMG-Multimodal-Diffusion-Alignment.); 提出了一种无需额外数据或编辑操作的多模态对齐框架 Implicit Multimodal Guida...|
|🆕 发布|Human-MME: A Holistic Evaluation Benchmark for Human-Centric Multimodal Large Language Models|以人为中心的跨模态大型语言模型的全局评估基准：Human-MME|Yuansen Liu, Haiming Tang, Jinlong Peng, Jiangning Zhang, Xiaozhong Ji, Qingdong He, Donghao Luo, Zhenye Gan .etc.|<http://arxiv.org/pdf/2509.26165v1>|[代码](https://github.com/Yuan-Hou/Human-MME.); 提出Human-MME基准，全面评估多模态大语言模型在以人为中心的场景理解能力。|
|🆕 发布|EchoGen: Generating Visual Echoes in Any Scene via Feed-Forward Subject-Driven Auto-Regressive Model|回声生成：通过前馈主体驱动自回归模型在任意场景中生成视觉回声|Ruixiao Dong, Zhendong Wang, Keli Liu, Li Li, Ying Chen, Kai Li, Daowen Li, Houqiang Li|<http://arxiv.org/pdf/2509.26127v1>|EchoGen通过双路径注入策略，将视觉自回归模型与主体驱动生成相结合，实现了高效高质的视觉回声生成...|
|📝 更新|Fork-Merge Decoding: Enhancing Multimodal Understanding in Audio-Visual Large Language Models|叉合并解码：提升音频-视觉大型语言模型的多模态理解能力|Chaeyoung Jung, Youngjoon Jang, Jongmin Choi, Joon Son Chung|<http://arxiv.org/pdf/2505.20873v2>|提出了一种无需额外训练的Fork-Merge Decoding策略，有效平衡了音频视觉大型语言模型中...|
|🆕 发布|EasyOcc: 3D Pseudo-Label Supervision for Fully Self-Supervised Semantic Occupancy Prediction Models|EasyOcc：用于全自监督语义占有率预测模型的三维伪标签监督|Seamie Hayes, Ganesh Sistu, Ciarán Eising|<http://arxiv.org/pdf/2509.26087v1>|提出了一种利用3D伪标签和时序信息的自监督学习方法，显著提升了语义占用预测模型的性能。|
|📝 更新|LargeAD: Large-Scale Cross-Sensor Data Pretraining for Autonomous Driving|大规模跨传感器数据预训练用于自动驾驶的LargeAD|Lingdong Kong, Xiang Xu, Youquan Liu, Jun Cen, Runnan Chen, Wenwei Zhang, Liang Pan, Kai Chen .etc.|<http://arxiv.org/pdf/2501.04005v2>|定位并提出了一种大规模跨传感器数据预训练框架LargeAD，通过融合2D图像和3D点云提升自动驾驶场...|
|🆕 发布|GeoLink: Empowering Remote Sensing Foundation Model with OpenStreetMap Data|GeoLink：利用OpenStreetMap数据增强遥感基础模型|Lubian Bai, Xiuyuan Zhang, Siqi Zhang, Zepeng Zhang, Haoyu Wang, Wei Qin, Shihong Du|<http://arxiv.org/pdf/2509.26016v1>|[代码](https://github.com/bailubin/GeoLink_NeurIPS2025); 集成地面地理空间数据与遥感基础模型，GeoLink框架利用OpenStreetMap数据提升模型性能...|
|📝 更新|Using Knowledge Graphs to harvest datasets for efficient CLIP model training|利用知识图谱收集数据集以高效训练CLIP模型|Simon Ging, Sebastian Walter, Jelena Bratulić, Johannes Dienert, Hannah Bast, Thomas Brox|<http://arxiv.org/pdf/2505.02746v3>|利用知识图谱增强的智能搜索策略，用更少的数据高效训练出高质量的CLIP模型。|
|🆕 发布|LLaVAShield: Safeguarding Multimodal Multi-Turn Dialogues in Vision-Language Models|《LLaVAShield：在视觉语言模型中保护多模态多轮对话的安全》|Guolei Huang, Qingzhi Peng, Gan Xu, Yuxuan Lu, Yongjun Shen|<http://arxiv.org/pdf/2509.25896v1>|提出首个针对多模态多轮对话安全的定义和评估框架，并开发出LLaVAShield模型有效提升内容审核性...|
|📝 更新|BoundMatch: Boundary detection applied to semi-supervised segmentation|边界匹配：将边界检测应用于半监督分割|Haruya Ishikawa, Yoshimitsu Aoki|<http://arxiv.org/pdf/2503.23519v4>|提出了一种多任务半监督分割框架BoundMatch，通过显式建模语义边界，提高了半监督语义分割的性能...|
|📝 更新|FoundBioNet: A Foundation-Based Model for IDH Genotyping of Glioma from Multi-Parametric MRI|基于基础模型的FoundBioNet：用于多参数MRI下胶质瘤IDH基因分型的模型|Somayeh Farahani, Marjaneh Hejazi, Antonio Di Ieva, Sidong Liu|<http://arxiv.org/pdf/2508.06756v2>|提出了一种基于预训练模型的FoundBioNet，通过多尺度特征提取和跨模态信号分析，提高了非侵入性...|
|🆕 发布|Dolphin v1.0 Technical Report|海豚v1.0技术报告|Taohan Weng, Chi zhang, Chaoran Yan, Siya Liu, Xiaoyang Liu, Yalun Wu, Boyang Wang, Boyan Wang .etc.|<http://arxiv.org/pdf/2509.25748v1>|首次提出大规模多模态超声基础模型，统一多种临床任务，并通过三阶段训练提升诊断准确性和解释性。|
|📝 更新|MMPB: It's Time for Multi-Modal Personalization|多模态个性化：现在是时候了|Jaeik Kim, Woojin Kim, Woohyeon Park, Jaeyoung Do|<http://arxiv.org/pdf/2509.22820v2>|提出首个全面基准MMPB，评估视觉语言模型个性化性能，揭示现有模型在个性化适应方面的不足。|
|🆕 发布|dVLA: Diffusion Vision-Language-Action Model with Multimodal Chain-of-Thought|扩散视觉-语言-动作模型：具有多模态思维链的dVLA|Junjie Wen, Minjie Zhu, Jiaming Liu, Zhiyuan Liu, Yicun Yang, Linfeng Zhang, Shanghang Zhang, Yichen Zhu .etc.|<http://arxiv.org/pdf/2509.25681v1>|提出了一种基于扩散模型的dVLA，将视觉感知、语言推理和机器人控制统一于单一系统，提升了跨模态推理能...|
|📝 更新|MindVL: Towards Efficient and Effective Training of Multimodal Large Language Models on Ascend NPUs|MindVL：面向在Ascend NPUs上高效有效训练多模态大型语言模型|Feilong Chen, Yijiang Liu, Yi Huang, Hao Wang, Miren Tian, Ya-Qi Yu, Minghui Liao, Jihao Wu|<http://arxiv.org/pdf/2509.11662v3>|提出MindVL，一种在Ascend NPUs上高效训练的数据高效型多模态大语言模型。|
|📝 更新|Revisiting semi-supervised learning in the era of foundation models|重新审视基础模型时代下的半监督学习|Ping Zhang, Zheda Mai, Quang-Huy Nguyen, Wei-Lun Chao|<http://arxiv.org/pdf/2503.09707v3>|提出新基准数据集并发现参数高效微调可媲美半监督学习，通过模型集成提升伪标签质量。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CHROMA: Consistent Harmonization of Multi-View Appearance via Bilateral Grid Prediction|CHROMA：通过双边网格预测实现多视角外观的一致性调和|Jisu Shin, Richard Shaw, Seunghyun Shin, Zhensong Zhang, Hae-Gon Jeon, Eduardo Perez-Pellitero|<http://arxiv.org/pdf/2507.15748v3>|提出了一种预测自适应双边网格的方法，有效解决了多视角图像的光度不一致问题，提高了三维重建质量。|
|📝 更新|LFTR: Learning-Free Token Reduction for Multimodal Large Language Models|无学习式标记缩减：用于多模态大型语言模型的LFTR方法|Zihui Zhao, Yingxin Li, Yang Li|<http://arxiv.org/pdf/2501.17391v3>|提出了一种无需学习的视觉token减少方法LFTR，有效降低计算负担同时保持多模态大语言模型的推理性...|
|🆕 发布|DeepSketcher: Internalizing Visual Manipulation for Multimodal Reasoning|深度草图绘制者：内化视觉操作以进行多模态推理|Chi Zhang, Haibo Qiu, Qiming Zhang, Zhixiong Zeng, Lin Ma, Jing Zhang|<http://arxiv.org/pdf/2509.25866v1>|提出了一种图像-文本交织的推理方法，通过内部视觉操作实现更灵活的多模态推理。|
|📝 更新|PolSAM: Polarimetric Scattering Mechanism Informed Segment Anything Model|极化散射机制指导的任意目标分割模型（PolSAM）|Yuqing Wang, Zhongling Huang, Shuxin Yang, Hao Tang, Xiaolan Qiu, Junwei Han, Dingwen Zhang|<http://arxiv.org/pdf/2412.12737v2>|[代码](https://github.com/XAI4SAR/PolSAM.); 提出了一种融合极化散射机制的Segment Anything Model，通过引入微波视觉数据表示和...|
|🆕 发布|Adapting SAM with Dynamic Similarity Graphs for Few-Shot Parameter-Efficient Small Dense Object Detection: A Case Study of Chickpea Pods in Field Conditions|针对少样本参数高效小密集目标检测的动态相似性图自适应SAM：田间条件下鹰嘴豆荚检测案例研究|Xintong Jiang, Yixue Liu, Mohamed Debbagh, Yu Tian, Valerio Hoyos-Villegas, Viacheslav Adamchuk, Shangpeng Sun|<http://arxiv.org/pdf/2509.25805v1>|引入动态相似性图模块以适应少量样本下的小密集物体检测，大幅提升农业环境下的分割性能。|
|🆕 发布|EchoingECG: An Electrocardiogram Cross-Modal Model for Echocardiogram Tasks|EchoingECG：一种用于超声心动图任务的心电图跨模态模型|Yuan Gao, Sangwook Kim, Chris McIntosh|<http://arxiv.org/pdf/2509.25791v1>|[代码](https://github.com/mcintoshML/EchoingECG.); 提出了一种利用心电图和超声心动图联合训练的模型EchoingECG，提高了基于心电图预测心脏功能的能...|
|📝 更新|v1: Learning to Point Visual Tokens for Multimodal Grounded Reasoning|学习指点多模态基础推理中的视觉标记|Jiwan Chung, Junhyeok Kim, Siyeol Kim, Jaeyoung Lee, Min Soo Kim, Youngjae Yu|<http://arxiv.org/pdf/2505.18842v2>|[代码](https://github.com/jun297/v1.); 提出了一种通过点选复制策略实现动态视觉参考的方法，有效提升了多模态推理的准确性。|
|🆕 发布|Generalized Contrastive Learning for Universal Multimodal Retrieval|通用对比学习用于全模态检索|Jungsoo Lee, Janghoon Cho, Hyojin Park, Munawar Hayat, Kyuwoong Hwang, Fatih Porikli, Sungha Choi|<http://arxiv.org/pdf/2509.25638v1>|提出了一种通用对比学习策略GCL，通过在现有数据上学习统一表示空间，提升了多模态检索性能。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hy-Facial: Hybrid Feature Extraction by Dimensionality Reduction Methods for Enhanced Facial Expression Classification|“Hy-Facial：基于降维方法的混合特征提取以增强面部表情分类”|Xinjin Li, Yu Ma, Kaisen Ye, Jinghan Cao, Minghao Zhou, Yeyang Zhou|<http://arxiv.org/pdf/2509.26614v1>|集成深度学习和传统图像处理技术，Hy-Facial通过维度降低提升了面部表情识别准确度至83.3%。|
|🆕 发布|Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework|基于深度分割框架的钙钛矿太阳能电池材料自动化和可扩展扫描电子显微镜图像分析|Jian Guo Pan, Lin Wang, Xia Cai|<http://arxiv.org/pdf/2509.26548v1>|[代码](https://github.com/wlyyj/PerovSegNet); 提出了一种基于深度学习的SEM图像自动分析框架，实现了高效精确的太阳能电池材料微结构识别与量化。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Autoproof: Automated Segmentation Proofreading for Connectomics|自动校对连接组学的自动化分割校验|Gary B Huang, William M Katz, Stuart Berg, Louis Scheffer|<http://arxiv.org/pdf/2509.26585v1>|提出自动化分割校对方法Autoproof，利用机器学习减少80%人工校对成本并提高连接组完成率。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Point2RBox-v3: Self-Bootstrapping from Point Annotations via Integrated Pseudo-Label Refinement and Utilization|点到RBox-v3：通过集成伪标签精炼与利用实现从点标注的自举强化|Teng Zhang, Ziqian Fan, Mingxin Liu, Xin Zhang, Xudong Lu, Wentong Li, Yue Zhou, Yi Yu .etc.|<http://arxiv.org/pdf/2509.26281v1>|Point2RBox-v3通过动态伪标签和优化的损失函数，解决了点标注方法中伪标签质量和利用效率低下...|
|🆕 发布|TSalV360: A Method and Dataset for Text-driven Saliency Detection in 360-Degrees Videos|TSalV360：一种基于文本驱动的360度视频中显著性检测的方法与数据集|Ioannis Kontostathis, Evlampios Apostolidis, Vasileios Mezaris|<http://arxiv.org/pdf/2509.26208v1>|提出TSalV360方法，通过结合文本描述和视觉数据，实现360度视频中基于文本的显著物体检测。|
|📝 更新|OmniCount: Multi-label Object Counting with Semantic-Geometric Priors|全息计数：基于语义-几何先验的多标签目标计数|Anindya Mondal, Sauradip Nag, Xiatian Zhu, Anjan Dutta|<http://arxiv.org/pdf/2403.05435v9>|[代码](https://mondalanindya.github.io/OmniCount.); 提出了OmniCount方法，利用预训练模型的语义和几何先验，实现了无需额外训练即可同时计数多个对象...|
|📝 更新|Adaptive Modality Balanced Online Knowledge Distillation for Brain-Eye-Computer based Dim Object Detection|自适应模态平衡在线知识蒸馏在脑-眼-计算机基于的微光物体检测中的应用|Zixing Li, Chao Yan, Zhen Lan, Xiaojia Xiang, Han Zhou, Jun Lai, Dengqing Tang|<http://arxiv.org/pdf/2407.01894v3>|提出了一种自适应模态平衡在线知识蒸馏方法，有效融合脑电波与图像数据，提升了微光目标检测的准确性和鲁棒...|
|🆕 发布|Learning Egocentric In-Hand Object Segmentation through Weak Supervision from Human Narrations|通过人类叙述的弱监督学习自我中心手持物体分割|Nicola Messina, Rosario Leonardi, Luca Ciampi, Fabio Carrara, Giovanni Maria Farinella, Fabrizio Falchi, Antonino Furnari|<http://arxiv.org/pdf/2509.26004v1>|利用人类叙述的弱监督学习实现自我中心视角下的手持物体分割，无需依赖昂贵的手动标注数据集。|
|🆕 发布|Anchor-free Cross-view Object Geo-localization with Gaussian Position Encoding and Cross-view Association|基于高斯位置编码和跨视角关联的无锚点跨视角目标地理定位|Xingtao Ling, Chenlin Fu, Yingying Zhu|<http://arxiv.org/pdf/2509.25623v1>|提出了一种无锚点跨视角物体地理定位方法，通过高斯位置编码和跨视角关联模块，实现了更精确和高效的物体定...|
|📝 更新|Rethinking Weak-to-Strong Augmentation in Source-Free Domain Adaptive Object Detection|重新思考无源域自适应目标检测中的弱增强到强增强策略|Song Tang, Jiuzheng Yang, Mao Ye, Boyu Wang, Yan Gan, Xiatian Zhu|<http://arxiv.org/pdf/2410.05557v2>|提出补偿策略WSC，利用弱增强图像辅助强增强图像，减少类别相关语义丢失，提升无源域自适应目标检测性能...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Multi-View Projection for Unsupervised Domain Adaptation in 3D Semantic Segmentation|多视角投影用于三维语义分割的无监督领域自适应|Andrew Caunes, Thierry Chateau, Vincent Fremont|<http://arxiv.org/pdf/2505.15545v2>|提出了多视角投影框架，通过无监督域适应实现了3D语义分割的跨数据集性能提升。|
|🆕 发布|A Multi-purpose Tracking Framework for Salmon Welfare Monitoring in Challenging Environments|面向挑战环境下鲑鱼福利监测的多功能跟踪框架|Espen Uri Høgstedt, Christian Schellewald, Annette Stahl, Rudolf Mester|<http://arxiv.org/pdf/2509.25969v1>|[代码](https://github.com/espenbh/BoostCompTrack.); 提出了一种多用途跟踪框架，通过身体部位信息解决水下鲑鱼场景的跟踪挑战，实现自动化鲑鱼福利监测。|
|🆕 发布|UniMMAD: Unified Multi-Modal and Multi-Class Anomaly Detection via MoE-Driven Feature Decompression|统一的多模态和多类别异常检测：通过MoE驱动的特征解压缩|Yuan Zhao, Youwei Pang, Lihe Zhang, Hanqi Liu, Jiaming Zuo, Huchuan Lu, Xiaoqi Zhao|<http://arxiv.org/pdf/2509.25934v1>|[代码](https://github.com/yuanzhao-CVLAB/UniMMAD.); 提出了一种统一的多元模态和多元类异常检测框架UniMMAD，通过混合专家驱动的特征解压缩机制实现自适...|
|📝 更新|YOLO26: Key Architectural Enhancements and Performance Benchmarking for Real-Time Object Detection|《YOLO26：实时目标检测的关键架构增强与性能基准测试》|Ranjan Sapkota, Rahul Harsha Cheppally, Ajay Sharda, Manoj Karkee|<http://arxiv.org/pdf/2509.25164v2>|YOLO26通过架构创新和优化算法提升实时物体检测效率，适用于边缘设备且支持多任务处理。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TTT3R: 3D Reconstruction as Test-Time Training|TTT3R：测试时训练的三维重建|Xingyu Chen, Yue Chen, Yuliang Xiu, Andreas Geiger, Anpei Chen|<http://arxiv.org/pdf/2509.26645v1>|[代码](https://rover-xingyu.github.io/TTT3R); 提出了一种测试时训练方法TTT3R，通过在线学习显著提升3D重建模型在长度泛化上的性能。|
|🆕 发布|DiffCamera: Arbitrary Refocusing on Images|DiffCamera：图像上的任意重新聚焦|Yiyang Wang, Xi Chen, Xiaogang Xu, Yu Liu, Hengshuang Zhao|<http://arxiv.org/pdf/2509.26599v1>|提出DiffCamera模型，实现图像任意焦点调整，通过模拟数据和独特训练约束优化了深度场效果处理。|
|📝 更新|CE-SDWV: Effective and Efficient Concept Erasure for Text-to-Image Diffusion Models via a Semantic-Driven Word Vocabulary|CE-SDWV：基于语义驱动的词汇表的文本到图像扩散模型的有效高效概念擦除|Jiahang Tu, Qian Feng, Jiahua Dong, Hanbin Zhao, Chao Zhang, Nicu Sebe, Hui Qian|<http://arxiv.org/pdf/2501.15562v2>|[代码](https://github.com/TtuHamg/CE-SDWV.); 提出了一种高效的概念擦除框架CE-SDWV，通过调整文本条件 tokens 实现对文本到图像模型中特...|
|🆕 发布|Contrastive Diffusion Guidance for Spatial Inverse Problems|对比扩散引导在空间逆问题中的应用|Sattwik Basu, Chaitanya Amballa, Zhongweiyang Xu, Jorge Vančo Sampedro, Srihari Nelakuditi, Romit Roy Choudhury|<http://arxiv.org/pdf/2509.26489v1>|提出了一种在嵌入空间中使用对比损失训练的模型，有效解决了从运动轨迹重建空间布局的逆问题。|
|🆕 发布|Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models|通过残差截断和零抑制对扩散模型进行训练后量化|Donghoon Kim, Dongyoung Lee, Ik Joon Chang, Sung-Ho Bae|<http://arxiv.org/pdf/2509.26436v1>|提出了一种针对扩散模型的4位量化方法QuaRTZ，通过残差截断和零抑制保留纹理细节，提高了量化效率和...|
|🆕 发布|Image-Difficulty-Aware Evaluation of Super-Resolution Models|图像难度感知的超分辨率模型评估|Atakan Topaloglu, Ahmet Bilican, Cansu Korkmaz, A. Murat Tekalp|<http://arxiv.org/pdf/2509.26398v1>|提出基于图像难度评估的超分辨率模型方法，通过难度指数区分模型在不同图像上的表现差异。|
|📝 更新|Simple yet Effective Semi-supervised Knowledge Distillation from Vision-Language Models via Dual-Head Optimization|通过双头优化的视觉语言模型实现的简单而有效的半监督知识蒸馏|Seongjae Kang, Dong Bok Lee, Hyungjoon Jang, Sung Ju Hwang|<http://arxiv.org/pdf/2505.07675v2>|[代码](https://github.com/erjui/DHO.); 提出双头优化方法，利用视觉语言模型进行半监督知识蒸馏，提升学生模型特征学习效果并实现最佳性能。|
|🆕 发布|FLOWER: A Flow-Matching Solver for Inverse Problems|FLOWER：用于逆问题的流匹配求解器|Mehrsa Pourya, Bassam El Rawas, Michael Unser|<http://arxiv.org/pdf/2509.26287v1>|提出FLOWER算法，利用预训练流模型迭代求解反问题，实现最优重建质量。|
|📝 更新|Binary Diffusion Probabilistic Model|二值扩散概率模型|Vitaliy Kinakh, Slava Voloshynovskiy|<http://arxiv.org/pdf/2501.13915v2>|提出Binary Diffusion Probabilistic Model，专为二值数据设计，通过...|
|📝 更新|Decoupled Classifier-Free Guidance for Counterfactual Diffusion Models|解耦的无分类器引导策略用于反事实扩散模型|Tian Xia, Fabio De Sousa Ribeiro, Rajat R Rasal, Avinash Kori, Raghav Mehta, Ben Glocker|<http://arxiv.org/pdf/2506.14399v4>|提出了一种新的指导策略DCFG，通过属性拆分实现更精细的生成控制，解决了传统CFG在反事实生成中的全...|
|🆕 发布|Towards Continual Expansion of Data Coverage: Automatic Text-guided Edge-case Synthesis|面向数据覆盖范围的持续扩展：自动文本引导的边缘情况综合|Kyeongryeol Go|<http://arxiv.org/pdf/2509.26158v1>|[代码](https://github.com/gokyeongryeol/ATES.); 提出了一种自动文本引导的边缘案例合成方法，有效缓解了数据集偏差，增强了模型的鲁棒性。|
|📝 更新|Rethinking Diffusion Model in High Dimension|重新思考高维空间中的扩散模型|Zhenxin Zheng, Zhenjie Zheng|<http://arxiv.org/pdf/2503.08643v3>|指出扩散模型在处理高维数据时未能有效学习统计量，提出了一种无需统计概念的统一推断框架。|
|📝 更新|RIFLE: Removal of Image Flicker-Banding via Latent Diffusion Enhancement|RIFLE：通过潜在扩散增强去除图像闪烁-色带|Libo Zhu, Zihan Zhou, Xiaoyang Liu, Weihang Zhang, Keyu Shi, Yifan Fu, Yulun Zhang|<http://arxiv.org/pdf/2509.24644v2>|提出了一种基于扩散框架的图像闪烁带消除方法RIFLE，有效提升了图像的可读性和质量。|
|📝 更新|DiffTex: Differentiable Texturing for Architectural Proxy Models|DiffTex: 建筑代理模型的可微分纹理映射|Weidan Xiong, Yongli Wu, Bochuan Zeng, Jianwei Guo, Dani Lischinski, Daniel Cohen-Or, Hui Huang|<http://arxiv.org/pdf/2509.23336v2>|提出了一种自动生成建筑代理模型纹理映射的方法，通过不同iable渲染优化，实现了纹理的 photom...|
|🆕 发布|New Fourth-Order Grayscale Indicator-Based Telegraph Diffusion Model for Image Despeckling|基于新型四阶灰度指标的电报扩散模型用于图像去噪|Rajendra K. Ray, Manish Kumar|<http://arxiv.org/pdf/2509.26010v1>|提出四阶非线性PDE模型，融合扩散和波动特性，有效去除噪声并保持细节纹理。|
|📝 更新|UniVid: The Open-Source Unified Video Model|"UniVid：开源统一视频模型"|Jiabin Luo, Junhui Lin, Zeyu Zhang, Biao Wu, Meng Fang, Ling Chen, Hao Tang|<http://arxiv.org/pdf/2509.24200v2>|[代码](https://github.com/AIGeeksGroup/UniVid.); 提出UniVid模型，通过轻量级适配器结合多模态语言模型和扩散解码器，实现视频理解和生成的一体化。|
|🆕 发布|AgenticIQA: An Agentic Framework for Adaptive and Interpretable Image Quality Assessment|自适应可解释图像质量评估的智能体框架：AgenticIQA|Hanwei Zhu, Yu Tian, Keyan Ding, Baoliang Chen, Bolin Chen, Shiqi Wang, Weisi Lin|<http://arxiv.org/pdf/2509.26006v1>|提出了一种自适应且可解释的图像质量评估框架AgenticIQA，通过整合视觉语言模型和传统IQA工具...|
|🆕 发布|VRWKV-Editor: Reducing quadratic complexity in transformer-based video editing|VRWKV-编辑器：降低基于变换器的视频编辑中的二次复杂度|Abdelilah Aitrouga, Youssef Hmamouche, Amal El Fallah Seghrouchni|<http://arxiv.org/pdf/2509.25998v1>|提出VRWKV-Editor模型，通过线性时空聚合模块降低视频编辑的计算复杂度，实现更快的编辑速度和...|
|📝 更新|Modeling Saliency Dataset Bias|建模显著性数据集偏差|Matthias Kümmerer, Harneet Singh Khanuja, Matthias Bethge|<http://arxiv.org/pdf/2505.10169v2>|提出了一种针对数据集偏差的轻量级模型，通过少量参数适应新数据集，显著缩小了迁移性差距。|
|🆕 发布|CO3: Contrasting Concepts Compose Better|对比概念组合更佳：CO3方法|Debottam Dutta, Jianchong Chen, Rajalaxmi Rajagopalan, Yu-Lin Wei, Romit Roy Choudhury|<http://arxiv.org/pdf/2509.25940v1>|提出了一种引导策略CO3，通过避免单一概念过强调，改善多概念文本到图像生成模型的准确性和平衡性。|
|🆕 发布|VELA: An LLM-Hybrid-as-a-Judge Approach for Evaluating Long Image Captions|VELA：一种基于大语言模型混合评判的方法来评估长图像标题|Kazuki Matsuda, Yuiga Wada, Shinnosuke Hirano, Seitaro Otsuki, Komei Sugiura|<http://arxiv.org/pdf/2509.25818v1>|提出VELA自动评估指标，针对长图像描述进行优化，并在专门设计的LongCap-Arena基准上实现...|
|🆕 发布|Self-Evolving Vision-Language Models for Image Quality Assessment via Voting and Ranking|通过投票和排序实现图像质量评估的自进化视觉-语言模型|Wen Wen, Tianwu Zhi, Kanglong Fan, Yang Li, Xinge Peng, Yabin Zhang, Yiting Liao, Junlin Li .etc.|<http://arxiv.org/pdf/2509.25787v1>|提出了一种无需标注数据的自进化视觉语言模型EvoQuality，通过投票和排序机制显著提升图像质量评...|
|🆕 发布|Free Lunch Alignment of Text-to-Image Diffusion Models without Preference Image Pairs|无偏好图像对的文本到图像扩散模型免费午餐对齐|Jia Jun Cheng Xian, Muchen Li, Haotian Yang, Xin Tao, Pengfei Wan, Leonid Sigal, Renjie Liao|<http://arxiv.org/pdf/2509.25771v1>|[代码](https://github.com/DSL-Lab/T2I-Free-Lunch-Alignment.); 提出无需成对图像偏好数据的文本偏好优化框架，有效提升文本到图像模型的准确对齐。|
|📝 更新|Spatial Reasoning with Vision-Language Models in Ego-Centric Multi-View Scenes|基于视觉-语言模型的自我中心多视角场景空间推理|Mohsen Gholami, Ahmad Rezaei, Zhou Weimin, Sitong Mao, Shunbo Zhou, Yong Zhang, Mohammad Akbari|<http://arxiv.org/pdf/2509.06266v2>|提出了Ego3D-Bench基准和Ego3D-VLM框架，提升了视觉语言模型在第一视角多视图场景中的...|
|🆕 发布|LieHMR: Autoregressive Human Mesh Recovery with $SO(3)$ Diffusion|LieHMR：基于自回归的人类网格恢复与$SO(3)$扩散|Donghwan Kim, Tae-Kyun Kim|<http://arxiv.org/pdf/2509.25739v1>|提出了一种基于$SO(3)$扩散模型和变换器的概率性人体网格恢复方法，有效处理了从单张RGB图像恢复...|
|🆕 发布|LaTo: Landmark-tokenized Diffusion Transformer for Fine-grained Human Face Editing|LaTo: 用于细粒度人脸编辑的地标化标记扩散变换器|Zhenghao Zhang, Ziying Zhang, Junchao Liao, Xiangyu Meng, Qiang Hu, Siyu Zhu, Xiaoyun Zhang, Long Qin .etc.|<http://arxiv.org/pdf/2509.25731v1>|提出了一种基于地标量化的扩散变换器，实现了细粒度、保真的人脸编辑。|
|📝 更新|FlashEdit: Decoupling Speed, Structure, and Semantics for Precise Image Editing|《FlashEdit：解耦速度、结构与语义以实现精确图像编辑》|Junyi Wu, Zhiteng Li, Haotong Qin, Xiaohong Liu, Linghe Kong, Yulun Zhang, Xiaokang Yang|<http://arxiv.org/pdf/2509.22244v3>|[代码](https://github.com/JunyiWuCode/FlashEdit.); FlashEdit通过创新的编辑流程和注意力机制，实现了高保真实时图像编辑，大幅提升了效率。|
|🆕 发布|How Diffusion Models Memorize|扩散模型如何记忆|Juyeop Kim, Songkuk Kim, Jong-Seok Lee|<http://arxiv.org/pdf/2509.25705v1>|揭示了扩散模型如何通过早期去噪过程中的过度估计训练样本而记忆数据，提出了减少记忆现象的新见解。|
|🆕 发布|OmniDFA: A Unified Framework for Open Set Synthesis Image Detection and Few-Shot Attribution|全方位特征融合框架：开集合成图像检测与少量样本归因|Shiyu Wu, Shuyan Li, Jing Li, Jing Liu, Yequan Wang|<http://arxiv.org/pdf/2509.25682v1>|提出了一种统一框架OmniDFA，实现开放集合成图像检测与少量样本生成源识别。|
|🆕 发布|Using Images from a Video Game to Improve the Detection of Truck Axles|使用视频游戏中的图像来提高卡车车轴检测的准确性|Leandro Arab Marcomini, Andre Luiz Cunha|<http://arxiv.org/pdf/2509.25644v1>|利用视频游戏生成的图像训练卷积神经网络，有效提升卡车车轴检测性能。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Query-Kontext: An Unified Multimodal Model for Image Generation and Editing|查询-上下文：一种用于图像生成与编辑的统一多模态模型|Yuxin Song, Wenkai Dong, Shizun Wang, Qi Zhang, Song Xue, Tao Yuan, Hu Yang, Haocheng Feng .etc.|<http://arxiv.org/pdf/2509.26641v1>|提出了Query-Kontext方法，通过分离视觉语言模型和扩散模型，优化了图像生成和编辑中的多模态...|
|🆕 发布|Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training|在学习看见之前看见：揭秘来自语言预训练的LLM视觉先验|Junlin Han, Shengbang Tong, David Fan, Yufan Ren, Koustuv Sinha, Philip Torr, Filippos Kokkinos|<http://arxiv.org/pdf/2509.26625v1>|揭示了大型语言模型在仅训练文本的情况下自发形成的视觉先验，并提出了培养这些视觉先验的数据驱动方法。|
|🆕 发布|Video Object Segmentation-Aware Audio Generation|视频对象分割感知的音频生成|Ilpo Viertola, Vladimir Iashin, Esa Rahtu|<http://arxiv.org/pdf/2509.26604v1>|提出视频对象分割感知的音频生成任务，通过视觉分割掩码实现可控的高保真音效合成。|
|🆕 发布|Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation|稳定的电影计量学：专业视频生成的结构化分类与评估|Agneet Chatterjee, Rahim Entezari, Maksym Zhuravinskyi, Maksim Lapin, Reshinth Adithyan, Amit Raj, Chitta Baral, Yezhou Yang .etc.|<http://arxiv.org/pdf/2509.26555v1>|提出专业视频生成评价框架Stable Cinemetrics，通过细粒度控制节点和自动化评估流程提升...|
|📝 更新|VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use|VerlTool：面向全面工具使用的代理强化学习|Dongfu Jiang, Yi Lu, Zhuofeng Li, Zhiheng Lyu, Ping Nie, Haozhe Wang, Alex Su, Hui Chen .etc.|<http://arxiv.org/pdf/2509.01055v2>|[代码](https://github.com/TIGER-AI-Lab/verl-tool.); VerlTool提出了一种统一模块化的框架，解决了多轮工具交互中的效率问题，并实现了与现有系统的性能...|
|📝 更新|ODE-GS: Latent ODEs for Dynamic Scene Extrapolation with 3D Gaussian Splatting|ODE-GS：基于三维高斯散点的动态场景外推隐式常微分方程模型|Daniel Wang, Patrick Rim, Tian Tian, Dong Lao, Alex Wong, Ganesh Sundaramoorthi|<http://arxiv.org/pdf/2506.05480v3>|将3D场景动态预测与连续时间模型结合，ODE-GS通过神经网络实现了对未来场景的精准 extrapo...|
|📝 更新|Photography Perspective Composition: Towards Aesthetic Perspective Recommendation|摄影视角构图：迈向审美视角推荐|Lujian Yao, Siming Zheng, Xinbin Yuan, Zhuoxuan Cai, Pu Wu, Jinwei Chen, Bo Li, Peng-Tao Jiang|<http://arxiv.org/pdf/2505.20655v3>|提出摄影视角构图方法，通过专家照片自动构建数据集和评估模型，指导用户提升摄影构图美感。|
|🆕 发布|MotionRAG: Motion Retrieval-Augmented Image-to-Video Generation|运动检索增强的图像到视频生成方法：MotionRAG|Chenhui Zhu, Yilu Wu, Shuai Wang, Gangshan Wu, Limin Wang|<http://arxiv.org/pdf/2509.26391v1>|提出了一种基于检索增强的框架MotionRAG，通过借鉴相关视频的运动先验，显著提升了图像到视频生成...|
|📝 更新|EditScore: Unlocking Online RL for Image Editing via High-Fidelity Reward Modeling|编辑评分：通过高保真度奖励建模解锁在线强化学习在图像编辑中的应用|Xin Luo, Jiahao Wang, Chenyuan Wu, Shitao Xiao, Xiyan Jiang, Defu Lian, Jiajun Zhang, Dong Liu .etc.|<http://arxiv.org/pdf/2509.23909v2>|提出EditScore，一种高保真度奖励模型，有效解锁在线强化学习在图像编辑中的应用。|
|🆕 发布|Go with Your Gut: Scaling Confidence for Autoregressive Image Generation|《跟随直觉：扩展自回归图像生成中的置信度》|Harold Haodong Chen, Xianfeng Wu, Wen-Jie Shu, Rongjin Guo, Disen Lan, Harry Yang, Ying-Cong Chen|<http://arxiv.org/pdf/2509.26376v1>|首次为基于下一个标记预测的自动回归图像生成设计测试时缩放框架，通过熵信号和双层级策略提升生成质量和效...|
|📝 更新|BRIDGE -- Building Reinforcement-Learning Depth-to-Image Data Generation Engine for Monocular Depth Estimation|BRIDGE -- 用于单目深度估计的构建强化学习深度到图像数据生成引擎|Dingning Liu, Haoyu Guo, Jingyi Zhou, Tong He|<http://arxiv.org/pdf/2509.25077v2>|[代码](https://dingning-liu.github.io/bridge.github.io); 提出了一种基于强化学习的深度图到图像生成引擎，大幅提升了单目深度估计的准确性和泛化能力。|
|📝 更新|CODA: Repurposing Continuous VAEs for Discrete Tokenization|CODA：重用连续变分自编码器进行离散标记化|Zeyu Liu, Zanlin Ni, Yeguo Hua, Xin Deng, Xiao Ma, Cheng Zhong, Gao Huang|<http://arxiv.org/pdf/2503.17760v2>|将连续VAEs转化为离散 tokenizer，实现稳定高效训练并保持高视觉保真度。|
|🆕 发布|ProfVLM: A Lightweight Video-Language Model for Multi-View Proficiency Estimation|ProfVLM：一种用于多视角熟练度估计的轻量级视频-语言模型|Edoardo Bianchi, Jacopo Staiano, Antonio Liotta|<http://arxiv.org/pdf/2509.26278v1>|提出了一种轻量级视频语言模型ProfVLM，通过多视角视频生成专家反馈，提高了技能评估的准确性和解释...|
|📝 更新|Scaling RL to Long Videos|将强化学习扩展到长视频处理|Yukang Chen, Wei Huang, Baifeng Shi, Qinghao Hu, Hanrong Ye, Ligeng Zhu, Zhijian Liu, Pavlo Molchanov .etc.|<http://arxiv.org/pdf/2507.07966v4>|提出了一种全栈框架，利用强化学习将视觉语言模型扩展到长视频推理，通过大规模数据集、两阶段训练流程和高...|
|🆕 发布|3DiFACE: Synthesizing and Editing Holistic 3D Facial Animation|“3DiFACE：合成与编辑整体三维面部动画”|Balamurugan Thambiraja, Malte Prinzler, Sadegh Aliakbarian, Darren Cosker, Justus Thies|<http://arxiv.org/pdf/2509.26233v1>|[代码](https://balamuruganthambiraja.github.io/3DiFACE); 3DiFACE通过创新的扩散模型实现了基于语音的多样化3D面部动画生成与精确编辑。|
|🆕 发布|EVODiff: Entropy-aware Variance Optimized Diffusion Inference|EVODiff：基于熵感知的方差优化扩散推理|Shigui Li, Wei Chen, Delu Zeng|<http://arxiv.org/pdf/2509.26096v1>|[代码](https://github.com/ShiguiLi/EVODiff.); 提出熵感知方差优化方法EVODiff，通过优化扩散模型推断过程中的条件熵，显著减少重建误差并提升生成...|
|🆕 发布|Text-to-Scene with Large Reasoning Models|文本到场景的大推理模型生成|Frédéric Berdoz, Luca A. Lanzendörfer, Nick Tuninga, Roger Wattenhofer|<http://arxiv.org/pdf/2509.26091v1>|提出Reason-3D模型，利用大型推理模型提升文本驱动的3D场景生成在复杂几何和对象布局上的准确性...|
|🆕 发布|GaussEdit: Adaptive 3D Scene Editing with Text and Image Prompts|高斯编辑：基于文本与图像提示的适应性三维场景编辑|Zhenyu Shu, Junlong Yu, Kai Chao, Shiqing Xin, Ligang Liu|<http://arxiv.org/pdf/2509.26055v1>|提出GaussEdit框架，通过文本和图像提示实现自适应3D场景编辑，提升编辑准确性、视觉保真度和处...|
|🆕 发布|DGM4+: Dataset Extension for Global Scene Inconsistency|全局场景不一致性的数据集扩展DGM4+|Gagandeep Singh, Samudi Amarsinghe, Priyanka Singh, Xue Li|<http://arxiv.org/pdf/2509.26047v1>|[代码](https://github.com/Gaganx0/DGM4plus); 扩展DGM4数据集，引入全局不一致性样本，增强多模态媒体操纵检测能力。|
|🆕 发布|PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution|"PatchVSR：通过分块视频超分辨率突破视频扩散分辨率限制"|Shian Du, Menghan Xia, Chang Liu, Xintao Wang, Jing Wang, Pengfei Wan, Di Zhang, Xiangyang Ji|<http://arxiv.org/pdf/2509.26025v1>|提出PatchVSR方法，通过视频扩散先验和双流适配器实现高分辨率视频修复，提升细节生成质量和效率。|
|🆕 发布|Self-Supervised Anatomical Consistency Learning for Vision-Grounded Medical Report Generation|自监督解剖一致性学习用于视觉定位的医疗报告生成|Longzhen Yang, Zhangkai Ni, Ying Wen, Yihang Liu, Lianghua He, Heng Tao Shen|<http://arxiv.org/pdf/2509.25963v1>|提出了一种无需标注的自主学习框架SS-ACL，通过文字提示实现医学图像报告与解剖结构的对齐，提高了报...|
|📝 更新|Negative-Guided Subject Fidelity Optimization for Zero-Shot Subject-Driven Generation|负向引导的主体保真度优化用于零样本主体驱动生成|Chaehun Shin, Jooyoung Choi, Johan Barthelemy, Jungbeom Lee, Sungroh Yoon|<http://arxiv.org/pdf/2506.03621v2>|提出了一种增强零样本主题驱动的生成模型的方法，通过引入负样本和比较学习，显著提高了主题细节的准确性。|
|📝 更新|UI-UG: A Unified MLLM for UI Understanding and Generation|UI-UG：一种用于界面理解与生成的统一多模态语言模型|Hao Yang, Weijie Qiu, Ru Zhang, Zhou Fang, Ruichao Mao, Xiaoyu Lin, Maji Huang, Zhaosong Huang .etc.|<http://arxiv.org/pdf/2509.24361v2>|[代码](https://github.com/neovateai/UI-UG); 提出了UI-UG模型，统一了用户界面理解和生成任务，提升了准确性和生成质量。|
|📝 更新|MoWM: Mixture-of-World-Models for Embodied Planning via Latent-to-Pixel Feature Modulation|MoWM：基于潜在至像素特征调节的具身规划混合世界模型|Yu Shang, Yangcheng Yu, Xin Zhang, Xin Jin, Haisheng Su, Wei Wu, Yong Li|<http://arxiv.org/pdf/2509.21797v2>|[代码](https://github.com/tsinghua-fib-lab/MoWM.); 提出混合世界模型框架MoWM，融合显式与隐式表征，提升机器人视觉指令执行精度与泛化能力。|
|🆕 发布|LiDAR Point Cloud Colourisation Using Multi-Camera Fusion and Low-Light Image Enhancement|使用多摄像头融合与低光图像增强的LiDAR点云着色|Pasindu Ranasinghe, Dibyayan Patra, Bikram Banerjee, Simit Raval|<http://arxiv.org/pdf/2509.25859v1>|提出了一种融合多摄像头数据与低光增强技术的LiDAR点云着色方法，实现了低光环境下的高质量三维场景重...|
|🆕 发布|Training-Free Reward-Guided Image Editing via Trajectory Optimal Control|无训练的基于轨迹最优控制的奖励引导图像编辑|Jinho Chang, Jaemin Kim, Jong Chul Ye|<http://arxiv.org/pdf/2509.25845v1>|提出了一种无需训练的基于轨迹最优控制的奖励引导图像编辑方法，实现了在保持源图像语义的同时最大化目标奖...|
|🆕 发布|Vector sketch animation generation with differentialable motion trajectories|向量草图动画生成与可微分运动轨迹|Xinding Zhu, Xinye Yang, Shuyang Zheng, Zhexin Zhang, Fei Gao, Jing Huang, Jiazhou Chen|<http://arxiv.org/pdf/2509.25857v1>|提出了一种生成矢量草图动画的方法，通过引入可微分的运动轨迹表示，提高了视频的语义一致性和时间连贯性。|
|📝 更新|KDC-Diff: A Latent-Aware Diffusion Model with Knowledge Retention for Memory-Efficient Image Generation|知识保留的潜在感知扩散模型KDC-Diff：用于内存高效图像生成|Md. Naimur Asif Borno, Md Sakib Hossain Shovon, Asmaa Soliman Al-Moisheer, Mohammad Ali Moni|<http://arxiv.org/pdf/2505.06995v2>|提出了KDC-Diff，一种降低计算负担同时保持高性能的生成框架，通过知识蒸馏和持续学习优化图像生成...|
|📝 更新|Wan-Alpha: High-Quality Text-to-Video Generation with Alpha Channel|万-Alpha：具有Alpha通道的高质量文本到视频生成|Haotian Dong, Wenjing Wang, Chen Li, Di Lin|<http://arxiv.org/pdf/2509.24979v2>|[代码](https://donghaotian123.github.io/Wan-Alpha); 提出了一种生成高质量透明视频的新框架，通过联合学习RGB和alpha通道显著提升了视觉效果和透明度渲...|
|📝 更新|VSSFlow: Unifying Video-conditioned Sound and Speech Generation via Joint Learning|VSSFlow：通过联合学习统一视频条件声音与语音生成|Xin Cheng, Yuyue Wang, Xihua Wang, Yihan Wu, Kaisi Guan, Yijing Chen, Peng Zhang, Xiaojiang Liu .etc.|<http://arxiv.org/pdf/2509.24773v2>|提出了VSSFlow，一种统一视频条件声音和语音生成的框架，通过端到端联合学习显著提升生成效果。|
|🆕 发布|Personalized Scientific Figure Caption Generation: An Empirical Study on Author-Specific Writing Style Transfer|个性化科学图表标题生成：针对作者特定写作风格的实证研究|Jaeyoung Kim, Jongho Lee, Hongjun Choi, Sion Jang|<http://arxiv.org/pdf/2509.25817v1>|探究作者个性化科学图表标题生成，通过丰富个人资料提升多模态大语言模型个性化性能。|
|📝 更新|CADmium: Fine-Tuning Code Language Models for Text-Driven Sequential CAD Design|CADmium：为文本驱动的顺序CAD设计微调代码语言模型|Prashant Govindarajan, Davide Baldelli, Jay Pathak, Quentin Fournier, Sarath Chandar|<http://arxiv.org/pdf/2507.09792v2>|利用大型语言模型进行微调，实现了从自然语言描述到CAD设计的自动化转换。|
|🆕 发布|PCPO: Proportionate Credit Policy Optimization for Aligning Image Generation Models|PCPO：按比例信用策略优化以对齐图像生成模型|Jeongjae Lee, Jong Chul Ye|<http://arxiv.org/pdf/2509.25774v1>|提出了一种稳定化图像生成模型训练的方法PCPO，通过优化反馈机制显著提升了训练速度和图像质量。|
|📝 更新|Taming Diffusion Transformer for Efficient Mobile Video Generation in Seconds|驯服扩散变换器以实现高效的移动端视频生成，仅需数秒|Yushu Wu, Yanyu Li, Anil Kag, Ivan Skorokhodov, Willi Menapace, Ke Ma, Arpit Sahni, Ju Hu .etc.|<http://arxiv.org/pdf/2507.13343v2>|优化了Diffusion Transformers，实现了在移动设备上快速生成高质量视频。|
|🆕 发布|Reweighted Flow Matching via Unbalanced OT for Label-free Long-tailed Generation|通过不平衡最优传输实现无标签长尾生成的重新加权流匹配|Hyunsoo Song, Minjung Gim, Jaewoong Choi|<http://arxiv.org/pdf/2509.25713v1>|提出了一种无标签长尾分布生成模型UOT-RFM，通过不平衡最优传输和逆重加权策略减轻多数偏差，提升尾...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|BoxDreamer: Dreaming Box Corners for Generalizable Object Pose Estimation|BoxDreamer：为通用物体姿态估计梦想盒子角点|Yuanhong Yu, Xingyi He, Chen Zhao, Junhao Yu, Jiaqi Yang, Ruizhen Hu, Yujun Shen, Xing Zhu .etc.|<http://arxiv.org/pdf/2504.07955v2>|提出了一种基于物体边界框角点的通用物体姿态估计方法，有效应对遮挡和稀疏视角挑战，提升实际应用性能。|
|🆕 发布|PANDA: Towards Generalist Video Anomaly Detection via Agentic AI Engineer|PANDA：通过代理型AI工程师实现通用视频异常检测|Zhiwei Yang, Chen Gao, Mike Zheng Shou|<http://arxiv.org/pdf/2509.26386v1>|[代码](https://github.com/showlab/PANDA.); 提出PANDA，一种无需训练数据或人工干预即可自动处理任意场景和异常类型的通用视频异常检测方法。|
|🆕 发布|An Experimental Study on Generating Plausible Textual Explanations for Video Summarization|视频摘要生成可信文本解释的实验研究|Thomas Eleftheriadis, Evlampios Apostolidis, Vasileios Mezaris|<http://arxiv.org/pdf/2509.26225v1>|提出了一种结合大型多模态模型和提示生成视频摘要的自然语言描述方法，以评估解释的合理性。|
|🆕 发布|SETR: A Two-Stage Semantic-Enhanced Framework for Zero-Shot Composed Image Retrieval|SETR：一种两阶段语义增强框架用于零样本组合图像检索|Yuqi Xiao, Yingying Zhu|<http://arxiv.org/pdf/2509.26012v1>|提出两阶段语义增强框架SETR，有效过滤背景干扰并精确匹配细粒度语义关系，提升零样本组合图像检索性能...|
|📝 更新|Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution|纹理向量量化与重建感知预测的生成超分辨率|Qifan Li, Jiale Zou, Jinhua Zhang, Wei Long, Xingyu Zhou, Shuhang Gu|<http://arxiv.org/pdf/2509.23774v2>|提出了一种针对纹理的向量量化与重建感知预测策略，有效降低量化误差并提升超分辨率图像质量。|
|🆕 发布|Dragging with Geometry: From Pixels to Geometry-Guided Image Editing|“拖拽中的几何：从像素到几何引导的图像编辑”|Xinyu Pu, Hongsong Wang, Jie Gui, Pan Zhou|<http://arxiv.org/pdf/2509.25740v1>|[代码](https://github.com/xinyu-pu/GeoDrag); 引入几何引导的拖拽编辑方法GeoDrag，提升图像编辑的精确度和结构一致性。|
|📝 更新|Unified Cross-Modal Image Synthesis with Hierarchical Mixture of Product-of-Experts|统一跨模态图像合成与层次化乘积专家混合模型|Reuben Dorent, Nazim Haouchine, Alexandra Golby, Sarah Frisken, Tina Kapur, William Wells|<http://arxiv.org/pdf/2410.19378v2>|提出了一种多模态层次化变分自编码器MMHVAE，实现了跨模态图像合成的精确重建。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SQUARE: Semantic Query-Augmented Fusion and Efficient Batch Reranking for Training-free Zero-Shot Composed Image Retrieval|方形：语义查询增强融合与高效批量重排，用于无需训练的零样本组合图像检索|Ren-Di Wu, Yu-Yen Lin, Huei-Fang Yang|<http://arxiv.org/pdf/2509.26330v1>|提出了一种无需训练的零样本组合图像检索框架，通过多模态大语言模型增强语义理解和重排效果。|
|📝 更新|Taming the Tri-Space Tension: ARC-Guided Hallucination Modeling and Control for Text-to-Image Generation|驯服三空间张力：基于ARC引导的文本到图像生成的幻觉建模与控制|Jianjiang Yang, Ziyan Huang, Yanshu li, Da Peng, Huaiyuan Yao|<http://arxiv.org/pdf/2507.04946v3>|提出了一种认知启发的生成控制框架，通过动态调整三轴空间张力，有效减少文本到图像生成中的“幻觉”现象。|
|🆕 发布|Editable Noise Map Inversion: Encoding Target-image into Noise For High-Fidelity Image Manipulation|可编辑噪声图逆向：将目标图像编码入噪声以实现高保真图像操作|Mingyu Kang, Yong Suk Choi|<http://arxiv.org/pdf/2509.25776v1>|提出Editable Noise Map Inversion方法，通过优化噪声图实现高保真图像编辑与...|
|📝 更新|Griffin: Generative Reference and Layout Guided Image Composition|“Griffin：生成性参考与布局引导的图像合成”|Aryan Mikaeili, Amirhossein Alimohammadi, Negar Hassanpour, Ali Mahdavi-Amiri, Andrea Tagliasacchi|<http://arxiv.org/pdf/2509.23643v2>|提出了一种基于图像参考和布局引导的图像生成方法，实现了对图像内容和布局的精细控制。|
|🆕 发布|ART-VITON: Measurement-Guided Latent Diffusion for Artifact-Free Virtual Try-On|ART-VITON：测量引导的潜在扩散技术实现无瑕疵虚拟试穿|Junseo Park, Hyeryung Jang|<http://arxiv.org/pdf/2509.25749v1>|提出测量引导的扩散框架ART-VITON，有效消除虚拟试穿中的边界伪影并提高视觉保真度和稳健性。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HART: Human Aligned Reconstruction Transformer|人机对齐重建变换器：HART|Xiyi Chen, Shaofei Wang, Marko Mihajlovic, Taewon Kang, Sergey Prokudin, Ming Lin|<http://arxiv.org/pdf/2509.26621v1>|提出了HART框架，通过预测3D点图和身体对应关系，实现了在少量视角下精确重建人体和衣物。|
|🆕 发布|DEPTHOR++: Robust Depth Enhancement from a Real-World Lightweight dToF and RGB Guidance|深度增强++：从现实世界的轻量级dToF和RGB引导中实现鲁棒深度增强|Jijun Xiang, Longliang Liu, Xuan Zhu, Xianqi Wang, Min Lin, Xin Yang|<http://arxiv.org/pdf/2509.26498v1>|提出了一种针对实际场景中轻量级dToF传感器噪声的深度增强框架DEPTHOR++，通过模拟数据训练、...|
|🆕 发布|IPDRecon: Image-Plane Geometric Decoding for View-Invariant Indoor Scene Reconstruction|IPDRecon：图像平面几何解码用于视图不变室内场景重建|Mingyang Li, Yimeng Fan, Changsong Liu, Tianyu Zhou, Xin Wang, Yanyan Liu, Wei Zhang|<http://arxiv.org/pdf/2509.25744v1>|IPDRecon通过图像平面解码框架减少对多视角几何依赖，提升室内场景重建的稳定性和质量。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Benchmarking Egocentric Visual-Inertial SLAM at City Scale|城市规模下自我中心视觉-惯性SLAM的基准测试|Anusha Krishnan, Shaohui Liu, Paul-Edouard Sarlin, Oscar Gentilhomme, David Caruso, Maurizio Monge, Richard Newcombe, Jakob Engel .etc.|<http://arxiv.org/pdf/2509.26639v1>|提出城市规模下针对第一视角视觉-惯性SLAM的新数据集和评估标准，揭示了现有方法的不足并指导了改进方...|
|📝 更新|LiDAR-BIND-T: Improved and Temporally Consistent Sensor Modality Translation and Fusion for Robotic Applications|激光雷达-BIND-T：改进的时序一致传感器模态转换与融合方法在机器人应用中的研究|Niels Balemans, Ali Anwar, Jan Steckel, Siegfried Mercelis|<http://arxiv.org/pdf/2509.05728v3>|引入时间一致性机制以改进多模态传感器融合，提升机器人应用的定位与建图性能。|
|📝 更新|OrthoLoC: UAV 6-DoF Localization and Calibration Using Orthographic Geodata|正交定位法：利用正交地理数据实现无人机六自由度定位与校准|Oussema Dhaouadi, Riccardo Marin, Johannes Meier, Jacques Kaiser, Daniel Cremers|<http://arxiv.org/pdf/2509.18350v2>|[代码](https://deepscenario.github.io/OrthoLoC.); 提出OrthoLoC方法，利用正射地理数据实现无人机高精度定位与校准。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FM-SIREN & FM-FINER: Nyquist-Informed Frequency Multiplier for Implicit Neural Representation with Periodic Activation|FM-SIREN与FM-FINER：基于奈奎斯特定理的频率倍增器，用于具有周期性激活的隐式神经表示|Mohammed Alsakabi, Wael Mobeirek, John M. Dolan, Ozan K. Tonguz|<http://arxiv.org/pdf/2509.23438v2>|通过为每个神经元分配特定频率乘数，FM-SIREN和FM-FINER减少了特征冗余，提升了隐式神经表...|
|🆕 发布|Attention over Scene Graphs: Indoor Scene Representations Toward CSAI Classification|注意力机制在场景图上的应用：面向CSAI分类的室内场景表示|Artur Barros, Carlos Caetano, João Macedo, Jefersson A. dos Santos, Sandra Avila|<http://arxiv.org/pdf/2509.26457v1>|[代码](https://github.com/tutuzeraa/ASGRA.); 提出了一种基于场景图的注意力模型，用于室内场景分类，提高了敏感内容分析的准确性和隐私保护。|
|📝 更新|RealLiFe: Real-Time Light Field Reconstruction via Hierarchical Sparse Gradient Descent|实时光场重建：通过分层稀疏梯度下降方法|Yijie Deng, Lei Han, Tianpeng Lin, Lin Li, Jinzhi Zhang, Lu Fang|<http://arxiv.org/pdf/2307.03017v4>|提出实时生成高质量光场的优化方法，通过分层稀疏梯度下降实现100倍速度提升。|
|🆕 发布|PFDepth: Heterogeneous Pinhole-Fisheye Joint Depth Estimation via Distortion-aware Gaussian-Splatted Volumetric Fusion|PFDepth：基于畸变感知高斯散斑体积融合的异质针孔-鱼眼联合深度估计|Zhiwei Zhang, Ruikai Xu, Weijian Zhang, Zhizhong Zhang, Xin Tan, Jingyu Gong, Yuan Xie, Lizhuang Ma|<http://arxiv.org/pdf/2509.26008v1>|提出首个异构针孔-鱼眼联合深度估计框架，通过3D体积融合显著提升多视角深度估计性能。|
|📝 更新|J-NeuS: Joint field optimization for Neural Surface reconstruction in urban scenes with limited image overlap|J-NeuS: 城市场景中图像重合度有限时用于神经曲面重建的联合场优化|Fusang Wang, Hala Djeghim, Nathan Piasco, Moussab Bennehar, Luis Roldão, Yizhe WU, Fabien Moutarde, Désiré Sidibé .etc.|<http://arxiv.org/pdf/2501.03932v2>|提出了一种针对城市场景中图像重叠有限情况下的神经表面重建方法J-NeuS，通过联合优化和不确定性估计...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TimeScope: Towards Task-Oriented Temporal Grounding In Long Videos|时间视野：面向任务的长视频时序定位|Xiangrui Liu, Minghao Qin, Yan Shu, Zhengyang Liang, Yang Tian, Chen Jason Zhang, Bo Zhao, Zheng Liu|<http://arxiv.org/pdf/2509.26360v1>|提出任务导向的时间定位方法TimeScope，通过逐步推理在长视频中有效定位关键时间区间。|
|📝 更新|HumanVideo-MME: Benchmarking MLLMs for Human-Centric Video Understanding|《HumanVideo-MME：以人为中心的视频理解中多模态大型语言模型的基准测试》|Yuxuan Cai, Jiangning Zhang, Zhenye Gan, Qingdong He, Xiaobin Hu, Junwei Zhu, Yabiao Wang, Chengjie Wang .etc.|<http://arxiv.org/pdf/2507.04909v2>|提出了一种全面评估多模态大语言模型在以人为中心的视频理解能力的新型基准测试，涵盖了多样化任务和数据类...|
|📝 更新|FameMind: Frame-Interleaved Video Reasoning via Reinforcement Learning|fameMind:基于强化学习的帧交织视频推理|Haonan Ge, Yiwei Wang, Kai-Wei Chang, Hang Wu, Yujun Cai|<http://arxiv.org/pdf/2509.24008v2>|提出了FrameMind框架，通过强化学习实现动态视觉信息采样，显著提升视频理解性能。|
|🆕 发布|FinCap: Topic-Aligned Captions for Short-Form Financial YouTube Videos|“FinCap：针对短视频金融类YouTube视频的主题对齐字幕”|Siddhant Sukhani, Yash Bhardwaj, Riya Bhadani, Veer Kejriwal, Michael Galarnyk, Sudheer Chava|<http://arxiv.org/pdf/2509.25745v1>|评估多模态大语言模型在金融短视频中的主题对齐字幕生成，发现视频模态对捕捉情感和视觉线索至关重要。|
|📝 更新|FrameThinker: Learning to Think with Long Videos via Multi-Turn Frame Spotlighting|《FrameThinker：通过多轮帧聚焦学习长时间视频的思考》|Zefeng He, Xiaoye Qu, Yafu Li, Siyuan Huang, Daizong Liu, Yu Cheng|<http://arxiv.org/pdf/2509.24304v2>|提出FrameThinker框架，通过多轮帧突出显示，大幅提升长视频理解效率和准确性。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Continuous Space-Time Video Super-Resolution with 3D Fourier Fields|连续时空视频超分辨率重建方法：基于三维傅里叶场|Alexander Becker, Julius Erbach, Dominik Narnhofer, Konrad Schindler|<http://arxiv.org/pdf/2509.26325v1>|提出了一种连续时空视频超分辨率方法，通过3D傅里叶场编码视频，实现了更高质量的时空细节重建。|
|🆕 发布|Seeing Space and Motion: Enhancing Latent Actions with Spatial and Dynamic Awareness for VLA|《观察空间与运动：利用空间与动态感知增强潜在动作的视觉语言动作识别》|Zhejia Cai, Yandan Yang, Xinyuan Chang, Shiyi Liang, Ronghan Chen, Feng Xiong, Mu Xu, Ruqi Huang|<http://arxiv.org/pdf/2509.26251v1>|提出Farsighted-LAM框架，通过空间感知和动态建模增强视觉语言行动系统的稳定性和泛化能力。|
|🆕 发布|Annotation-Efficient Active Test-Time Adaptation with Conformal Prediction|高效注释的测试时自适应符合预测|Tingyu Shi, Fan Lyu, Shaoliang Peng|<http://arxiv.org/pdf/2509.25692v1>|[代码](https://github.com/tingyushi/CPATTA.); 提出了一种高效的主动测试时适应方法CPATTA，通过引入原则性不确定性度量，提高了模型在领域迁移下的...|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|The 1st Solution for MOSEv1 Challenge on LSVOS 2025: CGFSeg|2025年LSVOS视频语义分割挑战赛MOSEv1任务的第一个解决方案：CGFSeg|Tingmin Li, Yixuan Li, Yang Yang|<http://arxiv.org/pdf/2509.25738v1>|提出了一种改进的置信度引导融合分割方法CGFSeg，有效应对复杂场景下的视频对象分割挑战。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AVCD: Mitigating Hallucinations in Audio-Visual Large Language Models through Contrastive Decoding|AVCD：通过对比解码减轻音频-视觉大型语言模型中的幻觉现象|Chaeyoung Jung, Youngjoon Jang, Joon Son Chung|<http://arxiv.org/pdf/2505.20862v2>|[代码](https://github.com/kaistmm/AVCD.); 提出了一种针对音频-视觉大型语言模型的对比解码框架，有效抑制了模态诱导的虚构成分。|
|📝 更新|PathoHR: Hierarchical Reasoning for Vision-Language Models in Pathology|病理HR：病理学中视觉-语言模型分层推理|Yating Huang, Ziyan Huang, Lintao Xiang, Qijun Yang, Hujun Yin|<http://arxiv.org/pdf/2509.06105v2>|提出PathoHR-Bench基准和特定训练方案，提升视觉语言模型在病理领域的层级语义理解和组合推理...|
|📝 更新|LayerLock: Non-collapsing Representation Learning with Progressive Freezing|层锁定：具有渐进式冻结的非崩溃表示学习|Goker Erdogan, Nikhil Parthasarathy, Catalin Ionescu, Drew A. Hudson, Alexander Lerchner, Andrew Zisserman, Mehdi S. M. Sajjadi, Joao Carreira|<http://arxiv.org/pdf/2509.10156v3>|提出LayerLock方法，通过逐步冻结层加快自监督视觉表示学习，避免表示崩溃。|
|🆕 发布|LTA-L2S: Lexical Tone-Aware Lip-to-Speech Synthesis for Mandarin with Cross-Lingual Transfer Learning|《基于跨语言迁移学习的汉语声调感知唇语到语音合成方法：LTA-L2S》|Kang Yang, Yifan Liang, Fangkun Liu, Zhenping Xie, Chengshi Zheng|<http://arxiv.org/pdf/2509.25670v1>|提出了一种结合跨语言迁移学习和音调建模的唇语到语音合成方法，显著提升了普通话语音的清晰度和音调准确性...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Revealing the Power of Post-Training for Small Language Models via Knowledge Distillation|通过知识蒸馏揭示后训练在小语言模型中的力量|Miao Rang, Zhenni Bi, Hang Zhou, Hanting Chen, An Xiao, Tianyu Guo, Kai Han, Xinghao Chen .etc.|<http://arxiv.org/pdf/2509.26497v1>|提出了一种高效的模型后训练流程，显著提升了小规模语言模型在边缘设备上的性能和泛化能力。|
|🆕 发布|PRISM: Progressive Rain removal with Integrated State-space Modeling|PRISM：基于集成状态空间模型的渐进式雨滴去除方法|Pengze Xue, Shanwen Wang, Fei Zhou, Yan Cui, Xin Sun|<http://arxiv.org/pdf/2509.26413v1>|提出了一种分阶段图像去雨技术PRISM，通过多尺度特征聚合和频率融合显著提升了去雨效果和图像质量。|
|🆕 发布|Beyond Pixels: Efficient Dataset Distillation via Sparse Gaussian Representation|超越像素：通过稀疏高斯表示实现数据集的高效蒸馏|Chenyang Jiang, Zhengcen Li, Hang Zhao, Qiben Shan, Shaocong Wu, Jingyong Su|<http://arxiv.org/pdf/2509.26219v1>|[代码](https://github.com/j-cyoung/GSDatasetDistillation.); 提出了一种基于稀疏高斯表示的数据集压缩方法GSDD，提高了数据集多样性并降低了存储和计算负担。|
|🆕 发布|EntroPE: Entropy-Guided Dynamic Patch Encoder for Time Series Forecasting|熵引导的动态补丁编码器EntroPE用于时间序列预测|Sachith Abeywickrama, Emadeldeen Eldele, Min Wu, Xiaoli Li, Chau Yuen|<http://arxiv.org/pdf/2509.26157v1>|[代码](https://github.com/Sachithx/EntroPE.); 提出熵引导动态补丁编码方法EntroPE，通过自适应确定补丁边界，有效保留时间序列的时序结构并提升预...|
|🆕 发布|SGS: Segmentation-Guided Scoring for Global Scene Inconsistencies|SGS：基于分割引导的全球场景不一致性评分方法|Gagandeep Singh, Samudi Amarsinghe, Urawee Thani, Ki Fung Wong, Priyanka Singh, Xue Li|<http://arxiv.org/pdf/2509.26039v1>|[代码](https://github.com/Gaganx0/HAMMER-sgs); 提出了一种基于分割的区域感知评分方法，增强了检测全局场景不一致性的能力。|
|📝 更新|Image-Conditioned 3D Gaussian Splat Quantization|图像条件下的三维高斯散点量化|Xinshuang Liu, Runfa Blark Li, Keito Suzuki, Truong Nguyen|<http://arxiv.org/pdf/2508.15372v2>|提出了一种高效的3D场景压缩方法，通过共享编码本和图像条件解码，大幅提升压缩效率并适应场景变化。|
|📝 更新|StPR: Spatiotemporal Preservation and Routing for Exemplar-Free Video Class-Incremental Learning|StPR: 用于无示例视频类别增量学习的时空保持与路由|Huaijie Wang, De Cheng, Guozhang Li, Zhipeng Xu, Lingfeng He, Jie Li, Nannan Wang, Xinbo Gao|<http://arxiv.org/pdf/2505.13997v2>|提出了一种无示例视频类增量学习框架StPR，通过分离并保持时空信息，有效解决灾难性遗忘问题并捕捉帧内...|
|📝 更新|SSTP: Efficient Sample Selection for Trajectory Prediction|轨迹预测的高效样本选择方法：SSTP|Ruining Yang, Yi Xu, Yun Fu, Lili Su|<http://arxiv.org/pdf/2409.17385v3>|提出SSTP框架，通过构建密度平衡的紧凑数据集，提高轨迹预测模型在复杂交通场景的性能并减少训练时间。|
|📝 更新|PHASE-Net: Physics-Grounded Harmonic Attention System for Efficient Remote Photoplethysmography Measurement|PHASE-Net：基于物理的谐波注意力系统用于高效远程光电容积描记术测量|Bo Zhao, Dan Guo, Junzhe Cao, Yong Xu, Tao Tan, Yue Sun, Bochao Zou, Jie Zhang .etc.|<http://arxiv.org/pdf/2509.24850v2>|提出了一种基于物理原理的远程光电容积描记测量方法，通过设计轻量级网络显著提升了运动和光照变化下的测量...|
|📝 更新|Raw-JPEG Adapter: Efficient Raw Image Compression with JPEG|原始-JPEG适配器：基于JPEG的高效原始图像压缩|Mahmoud Afifi, Ran Zhang, Michael S. Brown|<http://arxiv.org/pdf/2509.19624v2>|提出了一种将原始图像适配JPEG压缩的方法，实现了高保真度和高效压缩的平衡。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CBAM Integrated Attention Driven Model For Betel Leaf Diseases Classification With Explainable AI|「CBAM集成注意力驱动模型用于槟榔叶病害分类及可解释人工智能」|Sumaiya Tabassum, Md. Faysal Ahamed|<http://arxiv.org/pdf/2509.26484v1>|提出了一种基于CBAM的轻量级CNN模型，有效识别槟榔叶病害并提升分类性能。|
|📝 更新|From Ideal to Real: Unified and Data-Efficient Dense Prediction for Real-World Scenarios|结果：从理想到现实：面向实际场景的统一且数据高效稠密预测|Changliang Xia, Chengyou Jia, Zhuohang Dang, Minnan Luo, Zhihui Li, Xiaojun Chang|<http://arxiv.org/pdf/2506.20279v2>|提出DenseDiT方法，利用生成模型视觉先验进行统一且高效的实际场景密集预测。|
|🆕 发布|More Thought, Less Accuracy? On the Dual Nature of Reasoning in Vision-Language Models|“更多思考，更少准确性？论视觉语言模型推理的双重性质”|Xinyu Tian, Shu Zou, Zhaoyuan Yang, Mengqi He, Fabian Waschkowski, Lukas Wesemann, Peter Tu, Jing Zhang|<http://arxiv.org/pdf/2509.25848v1>|[代码](https://xytian1008.github.io/VAPO); 揭示了视觉语言模型推理过程中的双重性，并提出了VAPO方法，有效增强模型对视觉信息的依赖。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Spatial-Spectral Binarized Neural Network for Panchromatic and Multi-spectral Images Fusion|全色与多光谱图像融合的空间-光谱二值化神经网络|Yizhen Jiang, Mengting Ma, Anqi Zhu, Xiaowen Ma, Jiaxin Li, Wei Zhang|<http://arxiv.org/pdf/2509.23321v2>|提出了一种用于全色与多光谱图像融合的高效二值神经网络结构，有效解决了计算复杂度高和光谱失真问题。|
|🆕 发布|Cat: Post-training quantization error reduction via cluster-based affine transformation|猫：基于聚类仿射变换的模型训练后量化误差降低|Ali Zoljodi, Radu Timofte, Masoud Daneshtalab|<http://arxiv.org/pdf/2509.26277v1>|提出了一种基于聚类仿射变换的误差减少框架，显著提升了低比特量化后训练的神经网络准确性。|
|📝 更新|U-Mamba2: Scaling State Space Models for Dental Anatomy Segmentation in CBCT|U-Mamba2：在CBCT中扩展状态空间模型以进行牙科解剖结构分割|Zhi Qin Tan, Xiatian Zhu, Owen Addison, Yunpeng Li|<http://arxiv.org/pdf/2509.12069v2>|[代码](https://github.com/zhiqin1998/UMamba2.); 提出U-Mamba2网络，融合状态空间模型与U-Net架构，提升CBCT牙科解剖结构分割的效率和准确...|
|📝 更新|Dynamic Novel View Synthesis in High Dynamic Range|高动态范围下的动态新视角合成|Kaixuan Zhang, Zhipeng Xiong, Minxian Li, Mingwu Ren, Jiankang Deng, Xiatian Zhu|<http://arxiv.org/pdf/2509.21853v2>|提出了一种处理动态高动态范围场景的新型方法HDR-4DGS，通过动态调整色调映射实现时空一致性的高动...|
|🆕 发布|Multi-modal Liver Segmentation and Fibrosis Staging Using Real-world MRI Images|多模态肝脏分割及纤维化分期方法研究：基于真实世界MRI图像|Yang Zhou, Kunhao Yuan, Ye Wei, Jishizhan Chen|<http://arxiv.org/pdf/2509.26061v1>|[代码](https://github.com/YangForever/care2025_liver_biodreamer.); 开发了一种自动化流程，通过多模态MRI数据实现精确的肝脏分割和纤维化分期，无需侵入性诊断。|
|🆕 发布|CoLLM-NAS: Collaborative Large Language Models for Efficient Knowledge-Guided Neural Architecture Search|协同大型语言模型用于高效知识引导的神经网络架构搜索|Zhe Li, Zhiwei Lin, Yongtao Wang|<http://arxiv.org/pdf/2509.26037v1>|提出协作大型语言模型指导的神经架构搜索方法，实现了高效的知识引导搜索并达到新的性能最优结果。|
|🆕 发布|From MNIST to ImageNet: Understanding the Scalability Boundaries of Differentiable Logic Gate Networks|从MNIST到ImageNet：理解可微分逻辑门网络的扩展边界|Sven Brändle, Till Aczel, Andreas Plesner, Roger Wattenhofer|<http://arxiv.org/pdf/2509.25933v1>|探究不同规模数据集下不同iable逻辑门网络的性能，提出适用于大规模分类的温度调整和输出策略。|
|📝 更新|Teaching Metric Distance to Discrete Autoregressive Language Models|教会离散自回归语言模型度量距离|Jiwan Chung, Saejin Kim, Yongrae Jo, Jaewoo Park, Dongjun Min, Youngjae Yu|<http://arxiv.org/pdf/2503.02379v3>|引入DIST2Loss框架，通过利用预定义的距离关系训练离散自回归模型，提升多模态应用性能。|
|🆕 发布|Importance Sampling for Multi-Negative Multimodal Direct Preference Optimization|多负样本多模态直接偏好优化中的重要性采样|Xintong Li, Chuhan Wang, Junda Wu, Rohan Surana, Tong Yu, Julian McAuley, Jingbo Shang|<http://arxiv.org/pdf/2509.25717v1>|提出多负样本选择框架MISP-DPO，通过引入Plackett-Luce模型和重要性采样优化多模态偏...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Incentivizing Reasoning for Advanced Instruction-Following of Large Language Models|激励推理以提高大型语言模型的高级指令遵循能力|Yulei Qin, Gang Li, Zongyi Li, Zihan Xu, Yuchen Shi, Zhekai Lin, Xiao Cui, Ke Li .etc.|<http://arxiv.org/pdf/2506.01413v8>|[代码](https://github.com/yuleiqin/RAIF.); 提出了一种基于强化学习和可验证奖励信号的RAIF方法，有效提升大语言模型处理复杂指令的能力。|
|🆕 发布|Ordinal Label-Distribution Learning with Constrained Asymmetric Priors for Imbalanced Retinal Grading|基于约束的不对称先验的有序标签分布学习在视网膜分级不平衡中的应用|Nagur Shareef Shaik, Teja Krishna Cherukuri, Adnan Masood, Ehsan Adeli, Dong Hye Ye|<http://arxiv.org/pdf/2509.26146v1>|提出了一种针对糖尿病视网膜病变分级问题的 CAP-WAE 框架，通过非对称先验和方向感知损失优化，提...|
|🆕 发布|Scaling Up Temporal Domain Generalization via Temporal Experts Averaging|通过时间专家平均法提升时间域泛化能力的扩展研究|Aoming Liu, Kevin Miller, Venkatesh Saligrama, Kate Saenko, Boqing Gong, Ser-Nam Lim, Bryan A. Plummer|<http://arxiv.org/pdf/2509.26045v1>|提出了一种创新的Temporal Experts Averaging框架，通过模型权重平均化实现全面...|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Keep It Real: Challenges in Attacking Compression-Based Adversarial Purification|保持真实：攻击基于压缩的对抗性净化中的挑战|Samuel Räber, Till Aczel, Andreas Plesner, Roger Wattenhofer|<http://arxiv.org/pdf/2508.05489v2>|发现高真实感的图像压缩模型能显著提高对抗攻击的难度，为防御对抗样本提供了新思路。|
|🆕 发布|The Impact of Scaling Training Data on Adversarial Robustness|训练数据缩放对对抗性鲁棒性的影响|Marco Zimmerli, Andreas Plesner, Till Aczel, Roger Wattenhofer|<http://arxiv.org/pdf/2509.25927v1>|探讨了训练数据规模和质量对模型对抗性鲁棒性的影响，发现数据质量与模型架构比规模本身更关键。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning Generalizable Shape Completion with SIM(3) Equivariance|学习具有SIM(3)等变性的通用形状补全|Yuqing Wang, Zhaiyu Chen, Xiao Xiang Zhu|<http://arxiv.org/pdf/2509.26631v1>|提出了一种SIM(3)等变性的3D形状补全网络，实现了对姿态和尺度不敏感的鲁棒性形状推断。|
|📝 更新|Unlocking Transfer Learning for Open-World Few-Shot Recognition|解锁开放世界少样本识别的迁移学习机制|Byeonggeun Kim, Juntae Lee, Kyuhong Shim, Simyung Chang|<http://arxiv.org/pdf/2411.09986v3>|提出两阶段方法解决开放世界少样本识别问题，结合开放集感知元学习和无开放集转移学习，实现最佳性能。|
|📝 更新|A Survey on SAR ship classification using Deep Learning|深度学习在合成孔径雷达船舶分类中的研究综述|Ch Muhammad Awais, Marco Reggiannini, Davide Moroni, Emanuele Salerno|<http://arxiv.org/pdf/2503.11906v2>|系统梳理了深度学习在合成孔径雷达船舶分类中的应用，提出了提升模型性能的多策略框架。|
|🆕 发布|Zero-Shot Decentralized Federated Learning|零样本去中心化联邦学习|Alessio Masano, Matteo Pennisi, Federica Proietto Salanitri, Concetto Spampinato, Giovanni Bellitto|<http://arxiv.org/pdf/2509.26462v1>|提出了一种去中心化的零样本联邦学习方法ZeroDFL，实现了无需中心服务器的分布式客户端间的零样本适...|
|📝 更新|Multi-temporal crack segmentation in concrete structures using deep learning approaches|基于深度学习的混凝土结构多时相裂缝分割|Said Harb, Pedro Achanccaray, Mehdi Maboudi, Markus Gerke|<http://arxiv.org/pdf/2411.04620v2>|利用多时序数据训练的深度学习模型显著提升了混凝土结构裂缝的分割质量。|
|🆕 发布|ExoPredicator: Learning Abstract Models of Dynamic Worlds for Robot Planning|外预测器：学习动态世界的抽象模型以辅助机器人规划|Yichao Liang, Dat Nguyen, Cambridge Yang, Tianyang Li, Joshua B. Tenenbaum, Carl Edward Rasmussen, Adrian Weller, Zenna Tavares .etc.|<http://arxiv.org/pdf/2509.26255v1>|提出了一种抽象世界模型框架，通过学习符号状态表示和内外部因果过程，实现了机器人长期规划的性能提升。|
|📝 更新|U-Mamba2-SSL for Semi-Supervised Tooth and Pulp Segmentation in CBCT|U-Mamba2-SSL 用于 CBCT 图像中牙齿和牙髓的半监督分割|Zhi Qin Tan, Xiatian Zhu, Owen Addison, Yunpeng Li|<http://arxiv.org/pdf/2509.20154v2>|[代码](https://github.com/zhiqin1998/UMamba2.); 提出了一种半监督学习框架U-Mamba2-SSL，利用未标记数据实现牙齿和牙髓在CBCT图像中的精确...|
|🆕 发布|Optimizing Indoor Environmental Quality in Smart Buildings Using Deep Learning|使用深度学习优化智能建筑室内环境质量|Youssef Sabiri, Walid Houmaidi, Aaya Bougrine, Salmane El Mansour Billah|<http://arxiv.org/pdf/2509.26187v1>|提出深度学习方法优化室内环境质量，实现节能与舒适度的平衡。|
|🆕 发布|Geometric Learning of Canonical Parameterizations of $2D$-curves|《二维曲线规范参数化的几何学习》|Ioana Ciuclea, Giorgio Longari, Alice Barbara Tumpach|<http://arxiv.org/pdf/2509.26070v1>|[代码](https://github.com/GiLonga/Geometric-Learning); 提出了一种利用主纤维束截面概念消除对称性影响的方法，优化了对象间的相似度测量并提高了分类性能。|
|🆕 发布|Predicting Penalty Kick Direction Using Multi-Modal Deep Learning with Pose-Guided Attention|使用姿态引导注意力的多模态深度学习预测点球方向|Pasindu Ranasinghe, Pamudu Ranasinghe|<http://arxiv.org/pdf/2509.26088v1>|提出了一种多模态深度学习框架，通过姿态引导的注意力机制预测点球方向，提高了预测准确性和实时性。|
|📝 更新|Learning an Ensemble Token from Task-driven Priors in Facial Analysis|从任务驱动先验中学习集合标记进行面部分析|Sunyong Seo, Semin Kim, Jongha Lee|<http://arxiv.org/pdf/2507.01290v2>|提出了一种利用任务驱动先验学习集合令牌的方法，有效提升了面部分析任务的泛化能力和特征表示。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DA$^2$: Depth Anything in Any Direction|深度任意方向检测：DA$^2$|Haodong Li, Wangguangdong Zheng, Jing He, Yuhao Liu, Xin Lin, Xin Yang, Ying-Cong Chen, Chunchao Guo|<http://arxiv.org/pdf/2509.26618v1>|[代码](https://depth-any-in-any-dir.github.io/.); 提出DA$^2$方法，实现全景图像深度估计的零样本泛化与高效处理。|
|🆕 发布|Stylos: Multi-View 3D Stylization with Single-Forward Gaussian Splatting|“Stylos：基于单向前向高斯散点喷射的多视角3D风格化”|Hanzhou Liu, Jia Huang, Mi Lu, Srikanth Saripalli, Peng Jiang|<http://arxiv.org/pdf/2509.26455v1>|提出了一种无需优化或预设姿势的3D风格迁移框架，通过全局风格-内容耦合实现多视角一致性风格化。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Beyond the Individual: Introducing Group Intention Forecasting with SHOT Dataset|超越个体：引入基于SHOT数据集的群体意图预测|Ruixu Zhang, Yuran Wang, Xinyi Hu, Chaoyu Mai, Wenxuan Liu, Danni Xu, Xian Zhong, Zheng Wang|<http://arxiv.org/pdf/2509.20715v2>|[代码](https://xinyi-hu.github.io/SHOT_DATASET.); 提出集体意图预测任务及SHOT数据集，通过个体行为和互动分析预测集体目标的出现。|
|🆕 发布|SeMoBridge: Semantic Modality Bridge for Efficient Few-Shot Adaptation of CLIP|《SeMoBridge：用于CLIP高效少样本适应的语义模态桥》|Christoph Timmermann, Hyunse Lee, Woojin Lee|<http://arxiv.org/pdf/2509.26036v1>|[代码](https://github.com/christti98/semobridge); SeMoBridge通过构建语义模态桥，有效解决了CLIP在少量样本学习中的模态不匹配问题。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 目标导向视觉决策 (Goal-oriented Visual Decision Making)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OceanGym: A Benchmark Environment for Underwater Embodied Agents|海洋健身房：水下具身智能体基准环境|Yida Xue, Mingjun Mao, Xiangyuan Ru, Yuqi Zhu, Baochang Ren, Shuofei Qiao, Mengru Wang, Shumin Deng .etc.|<http://arxiv.org/pdf/2509.26536v1>|[代码](https://github.com/OceanGPT/OceanGym.); 提出了OceanGym，首个针对水下机器人的综合基准环境，推动AI在极端条件下的发展。|


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SDA-PLANNER: State-Dependency Aware Adaptive Planner for Embodied Task Planning|SDA-PLANNER：具有状态依赖意识的适应性规划器，用于具身任务规划|Zichao Shen, Chen Gao, Jiaqi Yuan, Tianchen Zhu, Xingcheng Fu, Qingyun Sun|<http://arxiv.org/pdf/2509.26375v1>|提出SDA-PLANNER，通过自适应规划和错误处理机制提升机器人任务规划的灵活性和鲁棒性。|


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PinPoint3D: Fine-Grained 3D Part Segmentation from a Few Clicks|PinPoint3D：基于少量点击的细粒度三维部件分割|Bojun Zhang, Hangjian Ye, Hao Zheng, Jianzheng Huang, Zhengyu Lin, Zhenhong Guo, Feng Zheng|<http://arxiv.org/pdf/2509.25970v1>|PinPoint3D通过少量用户点击实现精细的3D部件分割，大幅提升交互式分割精度和效率。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Clarification as Supervision: Reinforcement Learning for Vision-Language Interfaces|澄清作为监督：视觉语言接口的强化学习|John Gkountouras, Ivan Titov|<http://arxiv.org/pdf/2509.26594v1>|提出了一种自适应澄清强化学习（AC-RL）方法，通过交互式训练提升视觉模型提供推理所需关键信息的能力...|
|🆕 发布|Ferret-UI Lite: Lessons from Building Small On-Device GUI Agents|Ferret-UI Lite：构建小型设备端GUI代理的经验教训|Zhen Yang, Zi-Yi Dou, Di Feng, Forrest Huang, Anh Nguyen, Keen You, Omar Attia, Yuhao Yang .etc.|<http://arxiv.org/pdf/2509.26539v1>|提出了一种轻量级GUI代理 Ferret-UI Lite，通过优化模型大小和增强推理能力，实现了跨平...|
|🆕 发布|Interpret, prune and distill Donut : towards lightweight VLMs for VQA on document|解读、剪枝与提炼Donut：面向文档VQA的轻量级视觉语言模型|Adnan Ben Mansour, Ayoub Karine, David Naccache|<http://arxiv.org/pdf/2509.26235v1>|提出了一种基于解释性剪枝和知识蒸馏的轻量级视觉语言模型，有效降低文档VQA的推理时间和内存占用。|
|📝 更新|ReLoop: "Seeing Twice and Thinking Backwards" via Closed-loop Training to Mitigate Hallucinations in Multimodal understanding|ReLoop: 通过闭环训练缓解多模态理解中的幻觉现象 —— “看两次，逆向思考”|Jianjiang Yang, Yanshu li, Ziyan Huang|<http://arxiv.org/pdf/2507.04943v2>|提出ReLoop框架，通过闭环训练减少多模态大语言模型中的虚构现象，增强输出可靠性。|
|🆕 发布|Towards Reliable and Holistic Visual In-Context Learning Prompt Selection|面向可靠与全面的视觉情境学习提示选择|Wenxiao Wu, Jing-Hao Xue, Chengming Xu, Chen Liu, Xinwei Sun, Changxin Gao, Nong Sang, Yanwei Fu|<http://arxiv.org/pdf/2509.25989v1>|提出了一种改进的视觉在位学习示例选择方法RH-Partial2Global，通过提高可靠性和全面性，...|
|📝 更新|UFO: A Unified Approach to Fine-grained Visual Perception via Open-ended Language Interface|UFO：通过开放式语言接口实现细粒度视觉感知的统一方法|Hao Tang, Chenwei Xie, Haiyang Wang, Xiaoyi Bao, Tingyu Weng, Pandeng Li, Yun Zheng, Liwei Wang|<http://arxiv.org/pdf/2503.01342v3>|[代码](https://github.com/nnnth/UFO.); 提出了UFO框架，通过开放式的语言接口统一了细粒度视觉感知任务，简化了架构设计与训练策略，实现了与特...|
|🆕 发布|A Multimodal LLM Approach for Visual Question Answering on Multiparametric 3D Brain MRI|多模态大规模语言模型方法在多参数3D脑磁共振成像上的视觉问答应用|Arvind Murari Vepa, Yannan Yu, Jingru Gan, Anthony Cuturrufo, Weikai Li, Wei Wang, Fabien Scalzo, Yizhou Sun|<http://arxiv.org/pdf/2509.25889v1>|提出了一种多模态大语言模型mpLLM，有效融合3D脑部MRI多参数模态，显著提升医疗视觉问答性能。|
|📝 更新|Causality-guided Prompt Learning for Vision-language Models via Visual Granulation|通过视觉粒度化的因果引导提示学习用于视觉-语言模型的策略|Mengyu Gao, Qiulei Dong|<http://arxiv.org/pdf/2509.03803v3>|提出了一种基于因果推理的视觉粒度引导的prompt学习方法，有效提升了细粒度数据集的识别性能。|
|📝 更新|iVISPAR -- An Interactive Visual-Spatial Reasoning Benchmark for VLMs|iVISPAR -- 面向语言模型的可交互视觉空间推理基准|Julius Mayer, Mohamad Ballout, Serwan Jassim, Farbod Nosrat Nezami, Elia Bruni|<http://arxiv.org/pdf/2502.03214v2>|提出iVISPAR基准，评估视觉语言模型在空间推理和视觉对齐方面的能力，揭示其与人类认知的差距。|
|🆕 发布|PatchEAD: Unifying Industrial Visual Prompting Frameworks for Patch-Exclusive Anomaly Detection|PatchEAD：统一工业视觉提示框架以实现斑块专属异常检测|Po-Han Huang, Jeng-Lin Li, Po-Hsuan Huang, Ming-Ching Chang, Wei-Chao Chen|<http://arxiv.org/pdf/2509.25856v1>|提出了PatchEAD框架，统一了视觉提示技术，实现了无需训练的异常检测，兼容多种基础模型。|
|🆕 发布|Logo-VGR: Visual Grounded Reasoning for Open-world Logo Recognition|Logo-VGR：面向开放世界的标志识别视觉定位推理|Zichen Liang, Jingjing Fei, Jie Wang, Zheming Yang, Changqing Li, Pei Wu, Minghui Qiu, Fei Yang .etc.|<http://arxiv.org/pdf/2509.25811v1>|提出了一种针对开放世界商标识别的视觉推理方法Logo-VGR，通过少量品牌监督实现大规模品牌识别的泛...|
|🆕 发布|Point-It-Out: Benchmarking Embodied Reasoning for Vision Language Models in Multi-Stage Visual Grounding|《Point-It-Out：在多阶段视觉定位中评估视觉语言模型的具身推理基准》|Haotian Xue, Yunhao Ge, Yu Zeng, Zhaoshuo Li, Ming-Yu Liu, Yongxin Chen, Jiaojiao Fan|<http://arxiv.org/pdf/2509.25794v1>|提出了Point-It-Out基准，通过精确视觉定位全面评估视觉语言模型的具身推理能力。|
|📝 更新|CoFFT: Chain of Foresight-Focus Thought for Visual Language Models|“CoFFT：视觉语言模型的前瞻-聚焦思维链”|Xinyu Zhang, Yuxuan Dong, Lingling Zhang, Chengyou Jia, Zhuohang Dang, Basura Fernando, Jun Liu, Mike Zheng Shou|<http://arxiv.org/pdf/2509.22010v2>|提出了一种模拟人类视觉认知的Chain of Foresight-Focus Thought方法，有...|
|📝 更新|Quantized Visual Geometry Grounded Transformer|量化视觉几何定位转换器|Weilun Feng, Haotong Qin, Mingqiang Wu, Chuanguang Yang, Yuqi Li, Xiangqi Li, Zhulin An, Libo Huang .etc.|<http://arxiv.org/pdf/2509.21302v2>|[代码](https://github.com/wlfeng0509/QuantVGGT.); 提出首个针对大规模视觉几何模型的量化框架QuantVGGT，通过双平滑细粒度量化和噪声过滤多样采样，...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MR$^2$-Bench: Going Beyond Matching to Reasoning in Multimodal Retrieval|MR$^2$- Bench：超越匹配，迈向多模态检索中的推理|Junjie Zhou, Ze Liu, Lei Xiong, Jin-Ge Yao, Yueze Wang, Shitao Xiao, Fenfen Lin, Miguel Hu Chen .etc.|<http://arxiv.org/pdf/2509.26378v1>|[代码](https://github.com/VectorSpaceLab/MR2-Bench.); 提出了MR$^2$-Bench，一个针对多模态检索的推理密集型基准，超越了浅层匹配以评估模型的逻辑、...|
|🆕 发布|VLM-FO1: Bridging the Gap Between High-Level Reasoning and Fine-Grained Perception in VLMs|VLM-FO1：在高级推理与细粒度感知之间搭建桥梁的视觉语言模型|Peng Liu, Haozhan Shen, Chunxin Fang, Zhicheng Sun, Jiajia Liao, Tiancheng Zhao|<http://arxiv.org/pdf/2509.25916v1>|提出了VLM-FO1框架，通过将对象感知转化为特征检索任务，有效桥接了视觉语言模型在高层次推理与细粒...|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PRPO: Paragraph-level Policy Optimization for Vision-Language Deepfake Detection|段落级策略优化用于视觉-语言深度伪造检测|Tuan Nguyen, Naseem Khan, Khang Tran, NhatHai Phan, Issa Khalil|<http://arxiv.org/pdf/2509.26272v1>|提出了一种强化学习算法PRPO，通过将大型语言模型的推理与图像内容在段落级别对齐，显著提升了深伪检测...|
|🆕 发布|MAPLE: Multi-scale Attribute-enhanced Prompt Learning for Few-shot Whole Slide Image Classification|MAPLE：多尺度属性增强提示学习用于少量样本全切片图像分类|Junjie Zhou, Wei Shao, Yagao Yue, Wei Mu, Peng Wan, Qi Zhu, Daoqiang Zhang|<http://arxiv.org/pdf/2509.25863v1>|提出了一种多尺度属性增强的提示学习方法，用于少量样本的全切片图像分类，有效捕捉了组织实体的亚型特异性...|
|📝 更新|ViewSpatial-Bench: Evaluating Multi-perspective Spatial Localization in Vision-Language Models|《ViewSpatial-Bench：评估视觉语言模型中的多视角空间定位》|Dingming Li, Hongxing Li, Zixuan Wang, Yuchen Yan, Hang Zhang, Siqi Chen, Guiyang Hou, Shengpei Jiang .etc.|<http://arxiv.org/pdf/2505.21500v2>|提出ViewSpatial-Bench基准，针对多视角空间定位识别，提升视觉语言模型的空间理解能力。|
|🆕 发布|V-HUB: A Visual-Centric Humor Understanding Benchmark for Video LLMs|V-HUB：面向视频大型语言模型的视觉中心幽默理解基准|Zhengpeng Shi, Hengli Li, Yanpeng Zhao, Jianqun Zhou, Yuxuan Wang, Qinrong Cui, Wei Bi, Songchun Zhu .etc.|<http://arxiv.org/pdf/2509.25773v1>|提出了v-HUB，一个专注于视觉的幽默理解视频基准，揭示了多模态大语言模型在仅视觉理解幽默方面的挑战...|
|🆕 发布|SAGE: Spatial-visual Adaptive Graph Exploration for Visual Place Recognition|SAGE：用于视觉位置识别的空间视觉自适应图探索|Shunpeng Chen, Changwei Wang, Rongtao Xu, Xingtian Pei, Yukun Song, Jinzhou Lin, Wenhao Xu, Jingyi Zhang .etc.|<http://arxiv.org/pdf/2509.25723v1>|[代码](https://github.com/chenshunpeng/SAGE.); 提出了一种自适应图探索方法SAGE，通过融合空间上下文和视觉相似性，显著提升了视觉位置识别的鲁棒性。|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SoMi-ToM: Evaluating Multi-Perspective Theory of Mind in Embodied Social Interactions|《SoMi-ToM：在具身社交互动中评估多视角心智理论》|Xianzhe Fan, Xuhui Zhou, Chuanyang Jin, Kolby Nottingham, Hao Zhu, Maarten Sap|<http://arxiv.org/pdf/2506.23046v2>|提出SoMi-ToM基准，通过多模态交互数据评估模型在复杂社会互动中的多视角心智理论能力。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-View Camera System for Variant-Aware Autonomous Vehicle Inspection and Defect Detection|多视角相机系统用于变体感知的自动驾驶车辆检测与缺陷识别|Yash Kulkarni, Raman Jha, Renu Kachhoria|<http://arxiv.org/pdf/2509.26454v1>|提出了一种多视角车辆自动检测系统，实现了实时变体识别和缺陷检测，大幅提升检测准确率和效率。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MIAFEx: An Attention-based Feature Extraction Method for Medical Image Classification|MIAFEx：一种基于注意力的医学图像分类特征提取方法|Oscar Ramos-Soto, Jorge Ramos-Frutos, Ezequiel Perez-Zarate, Diego Oliva, Sandra E. Balderas-Mata|<http://arxiv.org/pdf/2501.08562v3>|[代码](https://github.com/Oscar-RamosS/Medical-Image-Attention-based-Feature-Extractor-MIAFEx); 提出了一种基于注意力机制的医学图像特征提取方法MIAFEx，有效提高了小样本情况下的分类准确性和鲁棒...|
|🆕 发布|Beyond Overall Accuracy: Pose- and Occlusion-driven Fairness Analysis in Pedestrian Detection for Autonomous Driving|超越总体精度：自动驾驶行人检测中的姿态和遮挡驱动的公平性分析|Mohammad Khoshkdahan, Arman Akbari, Arash Akbari, Xuan Zhang|<http://arxiv.org/pdf/2509.26166v1>|首次全面评估行人姿态和遮挡对自动驾驶中行人检测公平性的影响。|
|🆕 发布|Causally Guided Gaussian Perturbations for Out-Of-Distribution Generalization in Medical Imaging|因果引导的高斯扰动用于医学成像的分布外泛化|Haoran Pei, Yuguang Yang, Kexin Liu, Baochang Zhang|<http://arxiv.org/pdf/2509.26027v1>|提出了一种通过在医学图像中注入空间变化的噪声并使用软因果掩码引导的方法，有效增强了模型在分布外情况下...|
|📝 更新|M$^{2}$SNet: Multi-scale in Multi-scale Subtraction Network for Medical Image Segmentation|M$^{2}$SNet：多尺度减法网络中的多尺度医疗图像分割|Xiaoqi Zhao, Hongpeng Jia, Youwei Pang, Long Lv, Feng Tian, Lihe Zhang, Weibing Sun, Huchuan Lu|<http://arxiv.org/pdf/2303.10894v2>|[代码](https://github.com/Xiaoqi-Zhao-DLUT/MSNet.); 提出了一种多尺度差异信息融合的网络结构M$^{2}$SNet，通过减法操作和自监督机制优化医疗图像分...|
|📝 更新|Adjustable Spatio-Spectral Hyperspectral Image Compression Network|可调节时空超光谱图像压缩网络|Martin Hermann Paul Fuchs, Behnood Rasti, Begüm Demir|<http://arxiv.org/pdf/2507.23447v2>|提出了一种可调节的基于学习的 Hyperspectral 图像压缩网络，有效平衡了光谱与空间压缩，提...|
|📝 更新|TinyDef-DETR: A DETR-based Framework for Defect Detection in Transmission Lines from UAV Imagery|基于DETR的无人机影像输电线路缺陷检测框架：TinyDef-DETR|Feng Shen, Jiaming Cui, Wenqiang Li, Shuai Zhou|<http://arxiv.org/pdf/2509.06035v6>|提出TinyDef-DETR框架，通过增强边界表示和细节保持，有效检测输电线路中的微小缺陷。|
|🆕 发布|ProbMed: A Probabilistic Framework for Medical Multimodal Binding|ProbMed：医学多模态绑定概率框架|Yuan Gao, Sangwook Kim, Jianzhong You, Chris McIntosh|<http://arxiv.org/pdf/2509.25711v1>|提出了一种概率框架ProbMED，通过概率对比学习改善多模态医疗数据的整合与绑定效果。|
|📝 更新|U-MAN: U-Net with Multi-scale Adaptive KAN Network for Medical Image Segmentation|U-MAN：基于多尺度自适应KAN网络的U-Net用于医学图像分割|Bohan Huang, Qianyun Bao, Haoyuan Ma|<http://arxiv.org/pdf/2509.22444v2>|提出U-MAN网络，通过多尺度特征提取和注意力引导融合，提升医学图像分割的精细度和准确性。|
|🆕 发布|YOLO-Based Defect Detection for Metal Sheets|基于YOLO的金属板材缺陷检测|Po-Heng Chou, Chun-Chi Wang, Wei-Lung Mao|<http://arxiv.org/pdf/2509.25659v1>|提出了一种基于YOLOv9和ConSinGAN的金属板材缺陷自动检测方法，提高了检测准确性和效率。|
|📝 更新|tCURLoRA: Tensor CUR Decomposition Based Low-Rank Parameter Adaptation and Its Application in Medical Image Segmentation|基于张量CUR分解的低秩参数自适应及其在医学图像分割中的应用|Guanghua He, Wangang Cheng, Hancan Zhu, Xiaohao Cai, Gaohang Yu|<http://arxiv.org/pdf/2501.02227v3>|提出了一种基于张量CUR分解的参数高效微调方法，有效降低计算和存储负担，提升医学图像分割性能。|
|📝 更新|LoRA-PT: Low-Rank Adapting UNETR for Hippocampus Segmentation Using Principal Tensor Singular Values and Vectors|LoRA-PT: 使用主张量奇异值和向量进行海马体分割的低秩适应UNETR方法|Guanghua He, Wangang Cheng, Hancan Zhu, Gaohang Yu|<http://arxiv.org/pdf/2407.11292v3>|[代码](https://github.com/WangangCheng/LoRA-PT); 提出了一种高效的参数微调方法LoRA-PT，通过低秩分解预训练模型，实现了精确的海马体分割并减少了参...|
|🆕 发布|LMOD+: A Comprehensive Multimodal Dataset and Benchmark for Developing and Evaluating Multimodal Large Language Models in Ophthalmology|LMOD+：眼科多模态大型语言模型开发与评估的全面多模态数据集和基准|Zhenyue Qin, Yang Liu, Yu Yin, Jinyu Ding, Haoran Zhang, Anran Li, Dylan Campbell, Xuansheng Wu .etc.|<http://arxiv.org/pdf/2509.25620v1>|提出了LMOD+多模态眼科学数据集，扩展并评估了大型多模态语言模型在眼科诊断中的应用。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Neighbor-aware informal settlement mapping with graph convolutional networks|基于图卷积网络的邻域感知非正式定居点制图|Thomas Hallopeau, Joris Guérin, Laurent Demagistri, Christovam Barcellos, Nadine Dessay|<http://arxiv.org/pdf/2509.26171v1>|提出图结构框架，利用图卷积网络整合地理上下文，有效提升非正式定居点映射准确性。|
|📝 更新|On the Effectiveness of Methods and Metrics for Explainable AI in Remote Sensing Image Scene Classification|关于遥感图像场景分类中可解释人工智能方法与评价指标有效性的研究|Jonas Klotz, Tom Burgert, Begüm Demir|<http://arxiv.org/pdf/2507.05916v2>|分析了遥感图像分类中解释性AI方法和评估指标的有效性，提出了选择方法和参数的指导原则。|
|📝 更新|Towards autonomous photogrammetric forest inventory using a lightweight under-canopy robotic drone|面向自主摄影测量森林清查的轻量级林下机器人无人机|Väinö Karjalainen, Niko Koivumäki, Teemu Hakala, Jesse Muhojoki, Eric Hyyppä, Anand George, Juha Suomalainen, Eija Honkavaara|<http://arxiv.org/pdf/2501.12073v3>|开发了一款轻量级林下无人机，实现了自主飞行和精确的树木参数估计。|
|🆕 发布|Overview of GeoLifeCLEF 2023: Species Composition Prediction with High Spatial Resolution at Continental Scale Using Remote Sensing|《GeoLifeCLEF 2023概述：利用高空间分辨率遥感技术在大陆尺度上进行物种组成预测》|Christophe Botella, Benjamin Deneu, Diego Marcos, Maximilien Servajean, Theo Larcher, Cesar Leblanc, Joaquim Estopinan, Pierre Bonnet .etc.|<http://arxiv.org/pdf/2509.25816v1>|概述GeoLifeCLEF 2023挑战，通过融合遥感数据与深度学习预测物种组成，解决了多标签分类问...|
|🆕 发布|DescribeEarth: Describe Anything for Remote Sensing Images|《DescribeEarth：面向遥感图像的任意内容描述》|Kaiyu Li, Zixuan Jiang, Xiangyong Cao, Jiayu Wang, Yuchen Xiao, Deyu Meng, Zhi Wang|<http://arxiv.org/pdf/2509.25654v1>|[代码](https://github.com/earth-insights/DescribeEarth.); 提出Geo-DLC任务，构建DE-Dataset，并设计DescribeEarth模型，提升遥感图像...|
|📝 更新|Investigating Long-term Training for Remote Sensing Object Detection|探究远程遥感目标检测的长周期训练方法|JongHyun Park, Yechan Kim, Moongu Jeon|<http://arxiv.org/pdf/2407.15143v4>|[代码](https://github.com/unique-chan/dbf.); 探究长周期训练对遥感目标检测的影响，提出动态骨干冻结方法优化特征提取，提升学习精度并降低计算成本。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|How Do Large Vision-Language Models See Text in Image? Unveiling the Distinctive Role of OCR Heads|“大型视觉-语言模型如何识别图像中的文本？揭示OCR头部独特作用”|Ingeol Baek, Hwan Chang, Sunghyun Ryu, Hwanhee Lee|<http://arxiv.org/pdf/2505.15865v2>|定位并解析图像中的文本信息，揭示了大型视觉语言模型中OCR头的独特作用与特性。|
|🆕 发布|MuSLR: Multimodal Symbolic Logical Reasoning|多模态符号逻辑推理：MuSLR|Jundong Xu, Hao Fei, Yuhui Zhang, Liangming Pan, Qijun Huang, Qian Liu, Preslav Nakov, Min-Yen Kan .etc.|<http://arxiv.org/pdf/2509.25851v1>|[代码](https://llm-symbol.github.io/MuSLR.); 提出MuSLR基准测试，揭示了现有视觉语言模型在符号逻辑推理上的不足，并提出了LogiCAM框架显著...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Deep Taxonomic Networks for Unsupervised Hierarchical Prototype Discovery|深度分类网络用于无监督层次原型发现|Zekun Wang, Ethan Haarer, Tianyi Zhu, Zhiyi Dai, Christopher J. MacLellan|<http://arxiv.org/pdf/2509.23602v2>|提出了一种深度分类网络，通过优化大规模潜在分类层次结构，实现了无监督的层次原型发现。|
|🆕 发布|Generalized Fine-Grained Category Discovery with Multi-Granularity Conceptual Experts|多粒度概念专家驱动的广义细粒度类别发现|Haiyang Zheng, Nan Pu, Wenjing Li, Nicu Sebe, Zhun Zhong|<http://arxiv.org/pdf/2509.26227v1>|[代码](https://github.com/HaiyangZheng/MGCE.); 提出了一种自适应挖掘视觉概念并融合多粒度知识的方法MGCE，有效解决了开放世界问题中细粒度类别发现的...|
|📝 更新|SPARE: Symmetrized Point-to-Plane Distance for Robust Non-Rigid 3D Registration|SPARE：对称点对平面距离用于鲁棒的非刚性三维配准|Yuxin Yao, Bailin Deng, Junhui Hou, Juyong Zhang|<http://arxiv.org/pdf/2405.20188v3>|[代码](https://github.com/yaoyx689/spare.); 提出了一种对称点面距离方法，用于提高非刚性三维配准的准确性和效率。|
|📝 更新|ResGS: Residual Densification of 3D Gaussian for Efficient Detail Recovery|残差密集化三维高斯分布以实现高效细节恢复：ResGS|Yanzhe Lyu, Kai Cheng, Xin Kang, Xuejin Chen|<http://arxiv.org/pdf/2412.07494v3>|提出残差分割方法增强3D高斯散点细节恢复，实现高效完整的几何重建。|
|🆕 发布|PUREVQ-GAN: Defending Data Poisoning Attacks through Vector-Quantized Bottlenecks|PUREVQ-GAN：通过向量量化瓶颈防御数据投毒攻击|Alexander Branch, Omead Pooladzandi, Radin Khosraviani, Sunay Gajanan Bhat, Jeffrey Jiang, Gregory Pottie|<http://arxiv.org/pdf/2509.25792v1>|PureVQ-GAN通过向量量化瓶颈防御数据投毒攻击，同时保持图像语义内容，大幅提升防御效果并加快处...|

