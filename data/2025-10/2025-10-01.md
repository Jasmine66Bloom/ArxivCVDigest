## [UPDATED!] **2025-10-01** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy|HAMLET：将您的视觉-语言-动作模型转换为历史感知策略|Myungkyu Koo, Daewon Choi, Taeyoung Kim, Kyungmin Lee, Changyeon Kim, Younggyo Seo, Jinwoo Shin|<http://arxiv.org/pdf/2510.00695v2>|提出了一种历史感知框架HAMLET，通过整合历史上下文信息，显著提升了机器人操作任务中的动作预测性能...|
|🆕 发布|From Videos to Indexed Knowledge Graphs -- Framework to Marry Methods for Multimodal Content Analysis and Understanding|从视频到索引知识图谱——融合多模态内容分析与理解方法的框架|Basem Rizk, Joel Walsh, Mark Core, Benjamin Nye|<http://arxiv.org/pdf/2510.01513v1>|提出了一种多模态内容分析框架，将预训练模型融合，将视频转化为可查询的帧级知识图谱，支持持续学习。|
|📝 更新|Explaining multimodal LLMs via intra-modal token interactions|通过模内标记交互解释多模态大型语言模型|Jiawei Liang, Ruoyu Chen, Xianghao Jiao, Siyuan Liang, Shiming Liu, Qunli Zhang, Zheng Hu, Xiaochun Cao|<http://arxiv.org/pdf/2509.22415v2>|提出了一种通过增强模内交互来提升多模态大语言模型解释性的方法，通过多尺度解释聚合和激活排名相关性，实...|
|📝 更新|CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification|认知对齐的视觉-语言-动作模型：通过指令驱动的路由选择与稀疏化|Wei Li, Renshan Zhang, Rui Shao, Jie He, Liqiang Nie|<http://arxiv.org/pdf/2508.21046v2>|[代码](https://github.com/JiuTian-VL/CogVLA.); 提出CogVLA框架，通过指令驱动的路由和稀疏化提升视觉语言动作模型的效率和性能。|
|📝 更新|Balancing Multimodal Training Through Game-Theoretic Regularization|通过博弈论正则化平衡多模态训练|Konstantinos Kontras, Thomas Strypsteen, Christos Chatzichristos, Paul Pu Liang, Matthew Blaschko, Maarten De Vos|<http://arxiv.org/pdf/2411.07335v3>|[代码](https://github.com/kkontras/MCR.); 提出了一种基于博弈理论的正则化方法，平衡多模态训练中的模态竞争，提升多模态学习性能。|
|📝 更新|Streamline pathology foundation model by cross-magnification distillation|通过跨倍率蒸馏精简病理学基础模型|Ziyu Su, Abdul Rehman Akbar, Usama Sajjad, Anil V. Parwani, Muhammad Khalid Khan Niazi|<http://arxiv.org/pdf/2509.23097v2>|提出了一种通过跨倍数蒸馏简化病理基础模型的方法，实现了30倍处理加速，同时保持诊断准确性。|
|📝 更新|Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned|训练视觉-语言处理奖励模型以实现多模态推理测试时的缩放：关键见解与经验教训|Brandon Ong, Tej Deep Pala, Vernon Toh, William Chandra Tjhi, Soujanya Poria|<http://arxiv.org/pdf/2509.23250v2>|提出了一种改进视觉语言模型推理可靠性的方法，通过多样化数据合成和感知级监督增强推理准确性。|
|📝 更新|SafeEraser: Enhancing Safety in Multimodal Large Language Models through Multimodal Machine Unlearning|SafeEraser：通过多模态机器遗忘增强多模态大型语言模型的安全性|Junkai Chen, Zhijie Deng, Kening Zheng, Yibo Yan, Shuliang Liu, PeiJun Wu, Peijie Jiang, Jia Liu .etc.|<http://arxiv.org/pdf/2502.12520v5>|提出SafeEraser方法，通过Prompt Decouple Loss减少多模态大语言模型中的过...|
|🆕 发布|Graph Integrated Multimodal Concept Bottleneck Model|图融合多模态概念瓶颈模型|Jiakai Lin, Jinchang Zhang, Guoyu Lu|<http://arxiv.org/pdf/2510.00701v1>|提出了一种融合图变换和混合专家模块的多模态概念瓶颈模型，有效建模概念间结构关系并提升推理适应性。|
|📝 更新|Mitigating Multimodal Hallucinations via Gradient-based Self-Reflection|通过基于梯度的自省减轻多模态幻觉|Shan Wang, Maying Shen, Nadine Chang, Chuong Nguyen, Hongdong Li, Jose M. Alvarez|<http://arxiv.org/pdf/2509.03113v2>|提出了一种无辅助模型、无需微调的梯度影响感知解码方法，有效减少多模态大语言模型输出中的虚构现象，增强...|
|📝 更新|v1: Learning to Point Visual Tokens for Multimodal Grounded Reasoning|学习指点多模态基础推理中的视觉标记|Jiwan Chung, Junhyeok Kim, Siyeol Kim, Jaeyoung Lee, Min Soo Kim, Youngjae Yu|<http://arxiv.org/pdf/2505.18842v3>|[代码](https://github.com/jun297/v1.); 提出了一种“点-复制”策略，使模型在多模态推理过程中能够持续关注图像关键区域，有效提升视觉证据的利用...|
|🆕 发布|VIRTUE: Visual-Interactive Text-Image Universal Embedder|视觉交互文本图像通用嵌入器：VIRTUE|Wei-Yao Wang, Kazuya Tateishi, Qiyu Wu, Shusuke Takahashi, Yuki Mitsufuji|<http://arxiv.org/pdf/2510.00523v1>|提出VIRTUE模型，结合视觉交互能力以精确处理用户指定图像区域，提升多模态表示学习模型的性能。|
|📝 更新|MMGeoLM: Hard Negative Contrastive Learning for Fine-Grained Geometric Understanding in Large Multimodal Models|MMGeoLM：大型多模态模型中细粒度几何理解的硬负对比学习|Kai Sun, Yushi Bai, Zhen Yang, Jiajie Zhang, Ji Qi, Lei Hou, Juanzi Li|<http://arxiv.org/pdf/2505.20152v3>|[代码](https://github.com/THU-KEG/MMGeoLM.); 提出了一种结合生成式硬负样本和规则修改的对比学习框架，显著提升了大型多模态模型在几何理解方面的细粒度...|
|📝 更新|MLLM-CL: Continual Learning for Multimodal Large Language Models|MLLM-CL: 多模态大型语言模型的持续学习|Hongbo Zhao, Fei Zhu, Haiyang Guo, Meng Wang, Rundong Wang, Gaofeng Meng, Zhaoxiang Zhang|<http://arxiv.org/pdf/2506.05453v2>|[代码](https://github.com/bjzhb666/MLLM-CL.); 提出MLLM-CL基准和参数隔离方法，实现多模态大语言模型在持续学习中的高效知识整合与遗忘最小化。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Data Selection for Fine-tuning Vision Language Models via Cross Modal Alignment Trajectories|通过跨模态对齐轨迹进行微调视觉语言模型的数据选择|Nilay Naharas, Dang Nguyen, Nesihan Bulut, Mohammadhossein Bateni, Vahab Mirrokni, Baharan Mirzasoleiman|<http://arxiv.org/pdf/2510.01454v1>|[代码](https://bigml-cs-ucla.github.io/XMAS-project-page); 提出首个针对大型视觉语言模型的数据选择方法，通过注意力矩阵轨迹聚类减少训练数据冗余，提升训练效率。|
|📝 更新|LLaVAShield: Safeguarding Multimodal Multi-Turn Dialogues in Vision-Language Models|《LLaVAShield：在视觉语言模型中保护多模态多轮对话的安全》|Guolei Huang, Qinzhi Peng, Gan Xu, Yuxuan Lu, Yongjun Shen|<http://arxiv.org/pdf/2509.25896v2>|提出首个针对多模态多轮对话安全的定义及数据集，并开发出LLaVAShield模型进行有效检测与评估。|
|🆕 发布|VENTURA: Adapting Image Diffusion Models for Unified Task Conditioned Navigation|VENTURA：适应图像扩散模型以实现统一任务条件导航|Arthur Zhang, Xiangyun Meng, Luca Calliari, Dong-Ki Kim, Shayegan Omidshafiei, Joydeep Biswas, Ali Agha, Amirreza Shaban|<http://arxiv.org/pdf/2510.01388v1>|VENTURA通过微调互联网预训练的图像扩散模型生成视觉路径，实现了自然语言指导下的机器人多样化导航...|
|📝 更新|Semantic and Visual Crop-Guided Diffusion Models for Heterogeneous Tissue Synthesis in Histopathology|异质组织合成中的语义与视觉裁剪引导扩散模型在组织病理学中的应用|Saghir Alfasly, Wataru Uegami, MD Enamul Hoq, Ghazal Alabtah, H. R. Tizhoosh|<http://arxiv.org/pdf/2509.17847v2>|提出了一种结合语义分割图和视觉裁剪的双条件扩散模型，实现了高质量异质组织病理学图像的生成。|
|📝 更新|LEGATO: Large-scale End-to-end Generalizable Approach to Typeset OMR|“LEGATO：大规模端到端通用排版光学音乐识别方法”|Guang Yang, Victoria Ebert, Nazif Tamer, Brian Siyuan Zheng, Luiza Pozzobon, Noah A. Smith|<http://arxiv.org/pdf/2506.19065v2>|提出了一种端到端的大规模预训练光学音乐识别模型Legato，能够将乐谱图像转换为机器可读的ABC符号...|
|🆕 发布|SPUS: A Lightweight and Parameter-Efficient Foundation Model for PDEs|SPUS：一种轻量级且参数高效的PDEs基础模型|Abu Bucker Siddik, Diane Oyen, Alexander Most, Michal Kucer, Ayan Biswas|<http://arxiv.org/pdf/2510.01370v1>|提出了一种基于轻量级残差U-Net架构的SPUS模型，高效解决多种PDE问题，实现参数效率最大化。|
|📝 更新|A Framework for Double-Blind Federated Adaptation of Foundation Models|《双向盲联邦适配基础模型框架》|Nurbek Tastan, Karthik Nandakumar|<http://arxiv.org/pdf/2502.01289v2>|提出了一种保护隐私的联邦基础模型适应框架，通过加密技术实现数据所有者和模型提供者间的协作适应。|
|🆕 发布|Can World Models Benefit VLMs for World Dynamics?|世界模型能否为视觉语言模型理解世界动态带来益处？|Kevin Zhang, Kuangzhi Ge, Xiaowei Chi, Renrui Zhang, Shaojun Shi, Zhen Dong, Sirui Han, Shanghang Zhang|<http://arxiv.org/pdf/2510.00855v1>|探究将生成世界模型融入视觉语言模型，显著提升空间推理和多帧理解能力。|
|🆕 发布|Assessing Foundation Models for Mold Colony Detection with Limited Training Data|评估有限训练数据下基础模型在霉菌菌落检测中的应用|Henrik Pichler, Janis Keuper, Matthew Copping|<http://arxiv.org/pdf/2510.00561v1>|展示了数据高效的基础模型仅需少量数据即可达到传统模型性能，加速微生物自动化系统的开发。|
|🆕 发布|CardioBench: Do Echocardiography Foundation Models Generalize Beyond the Lab?|心电基准：超声心动图基础模型在实验室之外是否具有泛化能力？|Darya Taratynova, Ahmed Aly, Numan Saeed, Mohammad Yaqub|<http://arxiv.org/pdf/2510.00520v1>|提出了CardioBench基准，统一评估超声心动图基础模型在多种任务上的泛化能力。|
|📝 更新|GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents|GUI-R1：一种面向GUI智能体的通用R1风格视觉-语言动作模型|Run Luo, Lu Wang, Wanwei He, Longze Chen, Jiaming Li, Xiaobo Xia|<http://arxiv.org/pdf/2504.10458v4>|提出了一种基于强化学习的GUI操作模型GUI-R1，通过统一动作空间规则建模，大幅减少训练数据需求并...|
|🆕 发布|Plug-and-Play Prompt Refinement via Latent Feedback for Diffusion Model Alignment|通过潜在反馈进行即插即用提示精炼以实现扩散模型对齐|Suhyeon Lee, Jong Chul Ye|<http://arxiv.org/pdf/2510.00430v1>|提出PromptLoop框架，通过强化学习迭代更新提示，增强扩散模型适应性和鲁棒性。|
|📝 更新|Dolphin v1.0 Technical Report|海豚v1.0技术报告|Taohan Weng, Chi zhang, Chaoran Yan, Siya Liu, Xiaoyang Liu, Yalun Wu, Boyang Wang, Boyan Wang .etc.|<http://arxiv.org/pdf/2509.25748v2>|首次提出大规模多模态超声基础模型，统一多种临床任务，并通过三阶段训练提升诊断准确性和解释性。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Grounded GUI Understanding for Vision-Based Spatial Intelligent Agent: Exemplified by Extended Reality Apps|基于视觉的空间智能体地面GUI理解：以扩展现实应用为例|Shuqing Li, Binchang Li, Yepang Liu, Cuiyun Gao, Jianping Zhang, Shing-Chi Cheung, Michael R. Lyu|<http://arxiv.org/pdf/2409.10811v4>|提出首个面向虚拟现实应用的零样本、上下文敏感的可交互GUI元素检测框架，通过模仿人类行为理解场景语义...|
|🆕 发布|Solar PV Installation Potential Assessment on Building Facades Based on Vision and Language Foundation Models|基于视觉与语言基础模型的建筑立面太阳能光伏安装潜力评估|Ruyu Liu, Dongxu Zhuang, Jianhua Zhang, Arega Getaneh Abate, Per Sieverts Nielsen, Ben Wang, Xiufeng Liu|<http://arxiv.org/pdf/2510.00797v1>|[代码](https://github.com/CodeAXu/Solar-PV-Installation); 提出了一种自动化的建筑立面光伏潜力评估框架，通过计算机视觉和语言模型技术优化光伏布局并提高评估效率。|
|🆕 发布|DEAP DIVE: Dataset Investigation with Vision transformers for EEG evaluation|深度探索：利用视觉变换器对脑电图数据进行调查评估|Annemarie Hoffsommer, Helen Schneider, Svetlana Pavlitska, J. Marius Zöllner|<http://arxiv.org/pdf/2510.00725v1>|利用仅12个EEG通道的波形图，通过训练视觉变换器模型，实现了高准确度的情绪预测。|
|🆕 发布|Multi-Objective Task-Aware Predictor for Image-Text Alignment|多目标任务感知预测器用于图像-文本对齐|Eunki Kim, Na Min An, James Thorne, Hyunjung Shim|<http://arxiv.org/pdf/2510.00766v1>|提出了一种多目标任务感知预测器MULTI-TAP，有效提升了图像文本对齐度评价的全面性及效率。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GeoSURGE: Geo-localization using Semantic Fusion with Hierarchy of Geographic Embeddings|地理定位：利用地理嵌入层次进行语义融合的方法|Angel Daruna, Nicholas Meegan, Han-Pang Chiu, Supun Samarasekera, Rakesh Kumar|<http://arxiv.org/pdf/2510.01448v1>|提出了一种分层地理嵌入的语义融合方法，显著提升了视觉地理定位的准确性。|
|📝 更新|PAN: Pillars-Attention-Based Network for 3D Object Detection|基于柱状注意力网络的3D目标检测|Ruan Bispo, Dane Mitrev, Letizia Mariotti, Clément Botty, Denver Humphrey, Anthony Scanlan, Ciarán Eising|<http://arxiv.org/pdf/2509.15935v2>|提出了一种基于雷达柱状特征和自注意力机制的3D物体检测算法，实现了实时准确检测并提升了处理速度。|
|🆕 发布|Robust Context-Aware Object Recognition|稳健的上下文感知目标识别|Klara Janouskova, Cristian Gavrus, Jiri Matas|<http://arxiv.org/pdf/2510.00618v1>|提出RCOR方法，通过联合定位与识别实现无需牺牲上下文信息的稳健目标识别。|
|📝 更新|Are All Marine Species Created Equal? Performance Disparities in Underwater Object Detection|所有海洋物种生来平等吗？水下目标检测中的性能差异|Melanie Wille, Tobias Fischer, Scarlett Raine|<http://arxiv.org/pdf/2508.18729v2>|探究了水下物体检测中性能差异的原因，并提出优化策略以改善表现不佳的海洋物种检测。|
|📝 更新|ATAS: Any-to-Any Self-Distillation for Enhanced Open-Vocabulary Dense Prediction|ATAS：任意到任意自蒸馏以提高开放词汇密集预测性能|Juan Yeo, Soonwoo Cha, Jiwoo Song, Hyunbin Jin, Taesup Kim|<http://arxiv.org/pdf/2506.08678v2>|提出ATAS方法，通过内部自蒸馏同时增强语义一致性和细粒度对齐，提升开放词汇密集预测任务性能。|
|📝 更新|DPDETR: Decoupled Position Detection Transformer for Infrared-Visible Object Detection|DPDETR：解耦位置检测Transformer用于红外-可见光目标检测|Junjie Guo, Chenqiang Gao, Fangcen Liu, Deyu Meng|<http://arxiv.org/pdf/2408.06123v2>|[代码](https://github.com/gjj45/DPDETR); 提出DPDETR方法，通过解耦位置检测和跨模态特征融合，有效解决红外-可见光对象检测中的模态不对齐问...|
|🆕 发布|VLOD-TTA: Test-Time Adaptation of Vision-Language Object Detectors|视觉语言对象检测器的测试时适应：VLOD-TTA|Atif Belal, Heitor R. Medeiros, Marco Pedersoli, Eric Granger|<http://arxiv.org/pdf/2510.00458v1>|[代码](https://github.com/imatif17/VLOD-TTA); 提出了一种测试时适应框架VLOD-TTA，通过利用密集提案重叠和图像条件提示得分，有效提升了视觉语言...|
|📝 更新|Source-Free Domain Adaptive Object Detection with Semantics Compensation|无源域自适应目标检测及语义补偿|Song Tang, Jiuzheng Yang, Mao Ye, Boyu Wang, Yan Gan, Xiatian Zhu|<http://arxiv.org/pdf/2410.05557v3>|提出了一种补偿策略WSCo，通过弱增强图像辅助强增强图像，有效缓解了数据增强导致的类别相关语义丢失问...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Semi-Supervised Unconstrained Head Pose Estimation in the Wild|野外半监督无约束头部姿态估计|Huayi Zhou, Fei Jiang, Jin Yuan, Yong Rui, Hongtao Lu, Kui Jia|<http://arxiv.org/pdf/2404.02544v4>|[代码](https://github.com/hnuzhy/SemiUHPE.); 提出了一种半监督的无约束自然场景人头姿态估计方法，通过动态熵过滤和头向增强技术，有效利用未标记图像提...|
|🆕 发布|LAKAN: Landmark-assisted Adaptive Kolmogorov-Arnold Network for Face Forgery Detection|地标辅助自适应科尔莫哥洛夫-阿尔诺德网络用于人脸伪造检测|Jiayao Jiang, Siran Peng, Bin Liu, Qi Chu, Nenghai Yu|<http://arxiv.org/pdf/2510.00634v1>|提出了一种结合面部标记引导的Kolmogorov-Arnold网络，有效提升了人脸伪造检测的准确度。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Uncertainty-Aware Concept Bottleneck Models with Enhanced Interpretability|不确定性感知的概念瓶颈模型与增强的可解释性|Haifei Zhang, Patrick Barry, Eduardo Brandao|<http://arxiv.org/pdf/2510.00773v1>|提出了一种不确定性感知的可解释分类器，通过学习类级概念原型，同时增强了概念瓶颈模型的解释性和鲁棒性。|
|🆕 发布|ProtoMask: Segmentation-Guided Prototype Learning|原型遮罩：基于分割的指导原型学习|Steffen Meinert, Philipp Schlinge, Nils Strodthoff, Martin Atzmueller|<http://arxiv.org/pdf/2510.00683v1>|[代码](https://github.com/uos-sis/quanproto); 提出了一种利用图像分割指导原型学习的方法ProtoMask，增强了原型解释性的准确性和可靠性。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SoftCFG: Uncertainty-guided Stable Guidance for Visual Autoregressive Model|软配置图：不确定性引导的视觉自回归模型稳定引导方法|Dongli Xu, Aleksei Tiulpin, Matthew B. Blaschko|<http://arxiv.org/pdf/2510.00996v2>|SoftCFG通过引入不确定性指导机制，解决了视觉自回归模型中的引导衰减和过引导问题，提高了图像生成...|
|🆕 发布|Purrception: Variational Flow Matching for Vector-Quantized Image Generation|“猫觉”：变分流匹配用于矢量量化图像生成|Răzvan-Andrei Matişan, Vincent Tao Hu, Grigory Bartosh, Björn Ommer, Cees G. M. Snoek, Max Welling, Jan-Willem van de Meent, Mohammad Mahdi Derakhshani .etc.|<http://arxiv.org/pdf/2510.01478v1>|提出Purrception方法，结合连续和离散生成图像的优势，提升训练效率和生成质量。|
|🆕 发布|DisCo: Reinforcement with Diversity Constraints for Multi-Human Generation|多样性约束的强化学习用于多人物生成：DisCo|Shubhankar Borse, Farzad Farhadzadeh, Munawar Hayat, Fatih Porikli|<http://arxiv.org/pdf/2510.01399v1>|引入DisCo框架，通过强化学习直接优化多人生成中的身份多样性，解决了生成模型中的身份危机问题。|
|📝 更新|Diffusion Adversarial Post-Training for One-Step Video Generation|扩散对抗后训练用于一步视频生成|Shanchuan Lin, Xin Xia, Yuxi Ren, Ceyuan Yang, Xuefeng Xiao, Lu Jiang|<http://arxiv.org/pdf/2501.08316v3>|提出了一种基于扩散模型和对抗性后训练的方法，实现了快速高质量的一步视频生成。|
|📝 更新|Autoregressive Adversarial Post-Training for Real-Time Interactive Video Generation|自回归对抗性后训练用于实时交互式视频生成|Shanchuan Lin, Ceyuan Yang, Hao He, Jianwen Jiang, Yuxi Ren, Xin Xia, Yang Zhao, Xuefeng Xiao .etc.|<http://arxiv.org/pdf/2506.09350v2>|提出了一种高效的实时交互式视频生成方法，通过自回归对抗性后训练将预训练模型转化为高效率的视频生成器。|
|📝 更新|CAMILA: Context-Aware Masking for Image Editing with Language Alignment|CAMILA：基于语言对齐的图像编辑上下文感知遮罩|Hyunseung Kim, Chiho Choi, Srikanth Malla, Sai Prahladh Padmanabhan, Saurabh Bagchi, Joon Hee Choi|<http://arxiv.org/pdf/2509.19731v2>|提出了一种上下文感知的图像编辑方法CAMILA，有效处理了文本指导下的矛盾指令，提高了编辑的准确性和...|
|🆕 发布|IMAGEdit: Let Any Subject Transform|IMAGEdit：让任何主题进行转换|Fei Shen, Weihao Xu, Rui Yan, Dong Zhang, Xiangbo Shu, Jinhui Tang|<http://arxiv.org/pdf/2510.01186v1>|[代码](https://github.com/XWH-A/IMAGEdit.); 提出IMAGEdit框架，无需训练即可编辑任意数量视频中的特定主体，同时保持非目标区域不变。|
|📝 更新|SUPER-Net: Trustworthy Image Segmentation via Uncertainty Propagation in Encoder-Decoder Networks|SUPER-Net：通过编码器-解码器网络中的不确定性传播实现可靠图像分割|Giuseppina Carannante, Nidhal C. Bouaynaya, Dimah Dera, Hassan M. Fathallah-Shaykh, Ghulam Rasool|<http://arxiv.org/pdf/2111.05978v4>|提出了一种通过不确定性传播增强可靠性的图像分割框架SUPER-Net，有效提高了模型在噪声和对抗性条...|
|🆕 发布|EvoWorld: Evolving Panoramic World Generation with Explicit 3D Memory|《EvoWorld：具有显式3D内存的全景世界生成进化》|Jiahao Wang, Luoxin Ye, TaiMing Lu, Junfei Xiao, Jiahan Zhang, Yuxiang Guo, Xijun Liu, Rama Chellappa .etc.|<http://arxiv.org/pdf/2510.01183v1>|提出EvoWorld模型，结合全景视频生成与动态3D记忆，实现空间一致的长距离探索。|
|🆕 发布|Image Generation Based on Image Style Extraction|基于图像风格提取的图像生成|Shuochen Chang|<http://arxiv.org/pdf/2510.01347v1>|提出三阶段训练风格提取法，通过单张风格参考图像生成精细控制的风格化图像。|
|🆕 发布|EditTrack: Detecting and Attributing AI-assisted Image Editing|编辑追踪：检测与归因人工智能辅助图像编辑|Zhengyuan Jiang, Yuyang Zhang, Moyang Guo, Neil Zhenqiang Gong|<http://arxiv.org/pdf/2510.01173v1>|提出EditTrack框架，首次解决特定原图与AI编辑图像的检测与归因问题。|
|📝 更新|SpargeAttention: Accurate and Training-free Sparse Attention Accelerating Any Model Inference|SpargeAttention：准确且无需训练的稀疏注意力加速任意模型推理|Jintao Zhang, Chendong Xiang, Haofeng Huang, Jia Wei, Haocheng Xi, Jun Zhu, Jianfei Chen|<http://arxiv.org/pdf/2502.18137v7>|[代码](https://github.com/thu-ml/SpargeAttn.); 提出了一种通用且无需训练的稀疏注意力加速方法，有效提升多种模型推理速度而不牺牲性能。|
|🆕 发布|KeySG: Hierarchical Keyframe-Based 3D Scene Graphs|关键帧层级3D场景图：基于层次结构的关键帧 KeySG|Abdelrhman Werby, Dennis Rotondi, Fabio Scaparro, Kai O. Arras|<http://arxiv.org/pdf/2510.01049v1>|提出KeySG框架，通过关键帧和多模态信息优化3D场景图构建，提升语义丰富性和处理效率。|
|📝 更新|SageAttention2: Efficient Attention with Thorough Outlier Smoothing and Per-thread INT4 Quantization|SageAttention2：具有彻底异常值平滑和线程级INT4量化的高效注意力机制|Jintao Zhang, Haofeng Huang, Pengle Zhang, Jia Wei, Jun Zhu, Jianfei Chen|<http://arxiv.org/pdf/2411.10958v7>|[代码](https://github.com/thu-ml/SageAttention.); 提出了一种高效注意力机制SageAttention2，通过INT4量化和异常值平滑技术提升计算效率并...|
|📝 更新|Easier Painting Than Thinking: Can Text-to-Image Models Set the Stage, but Not Direct the Play?|“绘画易过思考：文本到图像模型能搭建舞台，却不能指导剧本吗？”|Ouxiang Li, Yuan Wang, Xinting Hu, Huijuan Huang, Rui Chen, Jiarong Ou, Xin Tao, Pengfei Wan .etc.|<http://arxiv.org/pdf/2509.03516v2>|提出了一种全面的复杂基准T2I-CoReBench，评估文本到图像模型在构建和推理两方面的能力。|
|🆕 发布|ImageDoctor: Diagnosing Text-to-Image Generation via Grounded Image Reasoning|图像医生：通过基于图像推理对文本到图像生成的诊断|Yuxiang Guo, Jiang Liu, Ze Wang, Hao Chen, Ximeng Sun, Yang Zhao, Jialian Wu, Xiaodong Yu .etc.|<http://arxiv.org/pdf/2510.01010v1>|定位并评估文本到图像生成质量的多维度框架，通过像素级热图指示缺陷，提升生成图像偏好一致性。|
|🆕 发布|JEPA-T: Joint-Embedding Predictive Architecture with Text Fusion for Image Generation|联合嵌入预测架构结合文本融合用于图像生成：JEPA-T|Siheng Wan, Zhengtao Yao, Zhengdao Li, Junhao Dong, Yanshu Li, Yikai Li, Linshan Li, Haoyan Xu .etc.|<http://arxiv.org/pdf/2510.00974v1>|[代码](https://github.com/justin-herry/JEPA-T.git); 提出了一种统一的多模态框架JEPA-T，通过联合嵌入预测Transformer有效融合文本和视觉元素...|
|📝 更新|PortraitTalk: Towards Customizable One-Shot Audio-to-Talking Face Generation|《PortraitTalk：迈向可定制的单次音频到说话面部生成》|Fatemeh Nazarieh, Zhenhua Feng, Diptesh Kanojia, Muhammad Awais, Josef Kittler|<http://arxiv.org/pdf/2412.07754v2>|提出了一种创新的音频驱动的个性化说话人脸生成框架，通过身份和动画网络以及文本提示，实现了高质量和定制...|
|🆕 发布|From Seeing to Predicting: A Vision-Language Framework for Trajectory Forecasting and Controlled Video Generation|从观察至预测：一种用于轨迹预测与控制视频生成的视觉-语言框架|Fan Yang, Zhiyang Chen, Yousong Zhu, Xin Li, Jinqiao Wang|<http://arxiv.org/pdf/2510.00806v1>|提出TrajVLM-Gen框架，通过预测物理一致的运动轨迹指导视频生成，提升了视频生成模型的物理真实...|
|📝 更新|Toward a Robust R2D2 Paradigm for Radio-interferometric Imaging: Revisiting Deep Neural Network Training and Architecture|面向射电干涉成像的鲁棒R2D2范式：重新审视深度神经网络训练与架构|Amir Aghabiglou, Chung San Chu, Chao Tang, Arwa Dabbech, Yves Wiaux|<http://arxiv.org/pdf/2503.02554v2>|通过改进训练方法和网络架构，增强了R2D2模型在射电干涉成像中的泛化能力、数据保真度和不确定性估计。|
|📝 更新|ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation|简洁提示：通过生成过程中的连续简洁提示提升高效推理|Siao Tang, Xinyin Ma, Gongfan Fang, Xinchao Wang|<http://arxiv.org/pdf/2506.18810v3>|提出ConciseHint框架，通过生成过程中注入提示，有效提升大型推理模型简洁性和效率。|
|📝 更新|Dressing the Imagination: A Dataset for AI-Powered Translation of Text into Fashion Outfits and A Novel KAN Adapter for Enhanced Feature Adaptation|《装扮想象：一种将文本翻译为时尚装扮的AI驱动数据集及一种增强特征适应性的新型KAN适配器》|Gayatri Deshmukh, Somsubhra De, Chirag Sehgal, Jishu Sen Gupta, Sparsh Mittal|<http://arxiv.org/pdf/2411.13901v3>|提出FLORA数据集，增强AI对时尚描述的理解，并引入NeRA架构提升特征适应能力。|
|📝 更新|Rectified Diffusion Guidance for Conditional Generation|条件生成中的校正扩散引导|Mengfei Xia, Nan Xue, Yujun Shen, Ran Yi, Tieliang Gong, Yong-Jin Liu|<http://arxiv.org/pdf/2410.18737v2>|[代码](https://github.com/thuxmf/recfg); 提出了一种改进的条件生成方法ReCFG，通过优化指导系数，确保了与扩散理论的严格一致性并提供了闭式解...|
|🆕 发布|UCD: Unconditional Discriminator Promotes Nash Equilibrium in GANs|无条件判别器促进生成对抗网络中的纳什均衡|Mengfei Xia, Nan Xue, Jiapeng Zhu, Yujun Shen|<http://arxiv.org/pdf/2510.00624v1>|提出无条件判别器UCD，促进GAN训练达到纳什均衡，提升生成图像质量与效率。|
|🆕 发布|Virtual Fashion Photo-Shoots: Building a Large-Scale Garment-Lookbook Dataset|虚拟时尚摄影：构建大规模服装样册数据集|Yannick Hauri, Luca A. Lanzendörfer, Till Aczel|<http://arxiv.org/pdf/2510.00633v1>|构建首个大规模服装样册对数据集，推动从电商向富有创意的时尚影像生成转变。|
|🆕 发布|Hybrid Training for Vision-Language-Action Models|《视觉-语言-动作模型的混合训练》|Pietro Mazzaglia, Cansu Sancaktar, Markus Peschl, Daniel Dijkman|<http://arxiv.org/pdf/2510.00600v1>|提出Hybrid Training框架，使视觉语言动作模型在训练时学习思维链，而在推理时可选地跳过思...|
|📝 更新|DACoN: DINO for Anime Paint Bucket Colorization with Any Number of Reference Images|DACoN：使用任意数量参考图像的DINO动画着色桶填充色彩化方法|Kazuma Nagata, Naoshi Kaneko|<http://arxiv.org/pdf/2509.14685v2>|[代码](https://github.com/kzmngt/DACoN.); DACoN通过融合基础模型与卷积神经网络，实现了对线稿动画的灵活多参考图着色，提升了着色准确性和鲁棒...|
|🆕 发布|Arbitrary Generative Video Interpolation|任意生成视频插值|Guozhen Zhang, Haiguang Wang, Chunyu Wang, Yuan Zhou, Qinglin Lu, Limin Wang|<http://arxiv.org/pdf/2510.00578v1>|[代码](https://mcg-nju.github.io/ArbInterp-Web); 提出ArbInterp框架，实现任意时间戳和长度的视频帧插值，提高了视频生成应用的灵活性和连贯性。|
|📝 更新|Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal LLMs|通过多模态大型语言模型学习人类感知的AI生成视频伪造性|Xingyu Fu, Siyi Liu, Yinuo Xu, Pan Lu, Guangqiuse Hu, Tianbo Yang, Taran Anantasagar, Christopher Shen .etc.|<http://arxiv.org/pdf/2509.22646v2>|提出了一种标注人类感知的伪造痕迹的基准，训练语言模型以识别和解释AI生成视频中的深伪痕迹。|
|📝 更新|Dynamic-TreeRPO: Breaking the Independent Trajectory Bottleneck with Structured Sampling|动态树状RPO：通过结构化采样打破独立轨迹瓶颈|Xiaolong Fu, Lichen Ma, Zipeng Guo, Gaojing Zhou, Chongxiao Wang, ShiPing Dong, Shizhe Zhou, Shizhe Zhou .etc.|<http://arxiv.org/pdf/2509.23352v2>|提出了一种树结构动态采样方法Dynamic-TreeRPO，通过共享路径和动态调整探索策略，有效提升...|
|📝 更新|SpikeGen: Decoupled "Rods and Cones" Visual Representation Processing with Latent Generative Framework|"SpikeGen：使用潜在生成框架解耦的“视杆细胞和视锥细胞”视觉表示处理"|Gaole Dai, Menghang Dong, Rongyu Zhang, Ruichuan An, Shanghang Zhang, Tiejun Huang|<http://arxiv.org/pdf/2505.18049v2>|提出SpikeGen方法，通过分离处理视觉信息中的动态和色彩要素，增强生成模型对多模态视觉数据的处理...|
|🆕 发布|BindWeave: Subject-Consistent Video Generation via Cross-Modal Integration|BindWeave：通过跨模态融合实现主题一致的视频生成|Zhaoyang Li, Dongjun Qian, Kai Su, Qishuai Diao, Xiangyang Xia, Chang Liu, Wenfei Yang, Tianzhu Zhang .etc.|<http://arxiv.org/pdf/2510.00438v1>|提出BindWeave框架，通过跨模态集成实现主体一致的高保真视频生成。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Normal-Abnormal Guided Generalist Anomaly Detection|正常-异常引导的全能异常检测|Yuexin Wang, Xiaolei Wang, Yizheng Gong, Jimin Xiao|<http://arxiv.org/pdf/2510.00495v2>|[代码](https://github.com/JasonKyng/NAGL.); 提出利用正常和异常样本共同指导的通用异常检测方法，提升了跨域异常检测的准确性和效率。|
|🆕 发布|On the Role of Domain Experts in Creating Effective Tutoring Systems|关于领域专家在创建有效辅导系统中的作用|Sarath Sreedharan, Kelsey Sikes, Nathaniel Blanchard, Lisa Mason, Nikhil Krishnaswamy, Jill Zarestky|<http://arxiv.org/pdf/2510.01432v1>|强调领域专家知识在构建高效辅导系统中的作用，通过解释性AI和专家指定课程提升学习体验和系统效率。|
|🆕 发布|Code2Video: A Code-centric Paradigm for Educational Video Generation|代码到视频：一种以代码为中心的教育视频生成范式|Yanzhe Chen, Kevin Qinghong Lin, Mike Zheng Shou|<http://arxiv.org/pdf/2510.01174v1>|[代码](https://github.com/showlab/Code2Video.); 提出了一种基于Python代码的教育视频生成框架Code2Video，通过逻辑命令控制视频内容，提高...|
|📝 更新|Alternating Training-based Label Smoothing Enhances Prompt Generalization|基于交替训练的标签平滑增强提示泛化性|Yang Chen, Yanbin Wei, Ke Jin, Yi Kong, James Kwok, Yu Zhang|<http://arxiv.org/pdf/2508.17846v2>|提出交替训练标签平滑方法ATLaS，结合类和实例关系软标签，增强提示调谐泛化能力。|
|🆕 发布|TextCAM: Explaining Class Activation Map with Text|文本CAM：用文本解释类激活图|Qiming Zhao, Xingjian Li, Xiaoyu Cao, Xiaolong Wu, Min Xu|<http://arxiv.org/pdf/2510.01004v1>|提出TextCAM方法，结合视觉定位与自然语言描述，增强深度视觉模型的可解释性。|
|🆕 发布|A Scene is Worth a Thousand Features: Feed-Forward Camera Localization from a Collection of Image Features|一个场景胜过千个特征：从图像特征集合中实现的馈送前向相机定位|Axel Barroso-Laguna, Tommaso Cavallari, Victor Adrian Prisacariu, Eric Brachmann|<http://arxiv.org/pdf/2510.00978v1>|提出了一种快速定位相机姿态的方法FastForward，通过单次前向传播直接预测图像与场景的对应关系...|
|🆕 发布|InfVSR: Breaking Length Limits of Generic Video Super-Resolution|《InfVSR：突破通用视频超分辨率的长度的限制》|Ziqing Zhang, Kai Liu, Zheng Chen, Xi Li, Yucong Chen, Bingnan Duan, Linghe Kong, Yulun Zhang|<http://arxiv.org/pdf/2510.00948v1>|[代码](https://github.com/Kai-Liu001/InfVSR.); 提出了一种基于自回归一步扩散范式的InfVSR方法，有效解决了长视频序列超分辨率处理的效率与质量难题...|
|🆕 发布|What You See is What You Ask: Evaluating Audio Descriptions|你所见的即你所问：评估音频描述|Divy Kala, Eshika Khandelwal, Makarand Tapaswi|<http://arxiv.org/pdf/2510.00808v1>|提出ADQA基准，通过长视频片段评估自动音频描述对视障用户故事理解和视觉欣赏的帮助。|
|📝 更新|HR-INR: Continuous Space-Time Video Super-Resolution via Event Camera|HR-INR：基于事件相机的时间连续视频超分辨率|Yunfan Lu, Yusheng Wang, Zipeng Wang, Pengteng Li, Bin Yang, Hui Xiong|<http://arxiv.org/pdf/2405.13389v2>|[代码](https://github.com/yunfanLu/HR-INR); 提出了一种基于事件相机和隐式神经表示的连续时空视频超分辨率框架，有效捕捉快速复杂运动和长期依赖。|
|🆕 发布|Affordance-Guided Diffusion Prior for 3D Hand Reconstruction|“基于可达性引导的扩散先验用于三维手部重建”|Naru Suzuki, Takehiko Ohkawa, Tatsuro Banno, Jihyun Lee, Ryosuke Furuta, Yoichi Sato|<http://arxiv.org/pdf/2510.00506v1>|提出了一种基于文本描述的 affordance 意识扩散模型，有效改善了遮挡严重的手部姿态重建准确性...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|WALT: Web Agents that Learn Tools|网络智能体：学习工具的Web代理|Viraj Prabhu, Yutong Dai, Matthew Fernandez, Jing Gu, Krithika Ramakrishnan, Yanqi Luo, Silvio Savarese, Caiming Xiong .etc.|<http://arxiv.org/pdf/2510.01524v1>|提出了一种利用网站内置功能工具的浏览器自动化框架，提高了自动化任务的鲁棒性和效率。|
|📝 更新|IC-Custom: Diverse Image Customization via In-Context Learning|IC-Custom：通过上下文学习实现的多样化图像定制|Yaowei Li, Xiaoyu Li, Zhaoyang Zhang, Yuxuan Bian, Gan Liu, Xinyuan Li, Jiale Xu, Wenbo Hu .etc.|<http://arxiv.org/pdf/2507.01926v3>|[代码](https://liyaowei-stu.github.io/project); 提出统一框架IC-Custom，通过在位学习整合位置感知与位置无关图像定制，大幅提升定制多样性和效果...|
|🆕 发布|MorphGen: Controllable and Morphologically Plausible Generative Cell-Imaging|形态生成器：可控且形态上合理的生成性细胞成像|Berker Demirel, Marco Fumero, Theofanis Karaletsos, Francesco Locatello|<http://arxiv.org/pdf/2510.01298v1>|[代码](https://github.com/czi-ai/MorphGen.); MorphGen通过结合扩散模型与生物基础模型，实现了多细胞类型和干预下的可控生成，并保留了详细的细...|
|🆕 发布|Erased, But Not Forgotten: Erased Rectified Flow Transformers Still Remain Unsafe Under Concept Attack|被擦除，但未被遗忘：擦除修正流变换器在概念攻击下仍然不安全|Nanxiang Jiang, Zhaoxin Fan, Enhan Kang, Daiheng Gao, Yun Zhou, Yanxia Chang, Zheng Zhu, Yeying Jin .etc.|<http://arxiv.org/pdf/2510.00635v1>|提出了一种针对最新一代图像生成模型的概念攻击方法，有效评估了概念擦除策略的鲁棒性。|
|📝 更新|DreamCS: Geometry-Aware Text-to-3D Generation with Unpaired 3D Reward Supervision|DreamCS：具有无配对3D奖励监督的几何感知文本到3D生成|Xiandong Zou, Ruihao Xia, Hongsong Wang, Pan Zhou|<http://arxiv.org/pdf/2506.09814v2>|DreamCS通过直接在无配对3D数据上训练奖励模型，有效学习人类几何偏好，生成符合人类喜好的3D资...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AortaDiff: A Unified Multitask Diffusion Framework For Contrast-Free AAA Imaging|主动脉差异：一种用于无对比剂腹主动脉瘤成像的统一多任务扩散框架|Yuxuan Ou, Ning Bi, Jiazhen Pan, Jiancheng Yang, Boliang Yu, Usama Zidan, Regent Lee, Vicente Grau|<http://arxiv.org/pdf/2510.01498v1>|[代码](https://github.com/yuxuanou623/AortaDiff.git.); 提出了一种统一的多任务扩散框架，同时生成合成图像并分割主动脉腔和血栓，提高了成像质量和临床测量准确性...|
|🆕 发布|LVTINO: LAtent Video consisTency INverse sOlver for High Definition Video Restoration|LVTINO：用于高清视频修复的潜在视频一致性逆求解器|Alessio Spagnoletti, Andrés Almansa, Marcelo Pereyra|<http://arxiv.org/pdf/2510.01339v1>|提出了一种基于视频一致性模型的零样本高清视频修复方法LVTINO，实现了帧间一致性和高质量视频重建。|
|🆕 发布|Audio Driven Real-Time Facial Animation for Social Telepresence|音频驱动的实时面部动画实现社会远程临场感|Jiye Lee, Chenghui Li, Linh Tran, Shih-En Wei, Jason Saragih, Alexander Richard, Hanbyul Joo, Shaojie Bai|<http://arxiv.org/pdf/2510.01176v1>|实现了基于音频驱动的实时3D面部动画，通过创新架构大幅降低延迟并提升动画精度。|
|📝 更新|BlobCtrl: Taming Controllable Blob for Element-level Image Editing|BlobCtrl：驯服可控Blob以实现元素级图像编辑|Yaowei Li, Lingen Li, Zhaoyang Zhang, Xiaoyu Li, Guangzhi Wang, Hongxiang Li, Xiaodong Cun, Ying Shan .etc.|<http://arxiv.org/pdf/2503.13434v2>|[代码](https://liyaowei-stu.github.io/project); 提出BlobCtrl框架，通过概率Blob表示实现元素级图像编辑，分离布局与外观，提升编辑灵活性和精...|
|🆕 发布|Authentic Discrete Diffusion Model|真实离散扩散模型|Xiao Li, Jiaqi Zhang, Shuxiang Zhang, Tianshui Chen, Liang Lin, Guangrun Wang|<http://arxiv.org/pdf/2510.01047v1>|提出Authentic Discrete Diffusion框架，通过在one-hot空间直接保持核...|
|🆕 发布|Secure and reversible face anonymization with diffusion models|扩散模型的安全可逆人脸匿名化|Pol Labarbarie, Vincent Itier, William Puech|<http://arxiv.org/pdf/2510.01031v1>|提出了一种基于扩散模型的高质量、可逆匿名化方法，通过结合密钥机制保护隐私且不影响身份验证。|
|📝 更新|Image-Difficulty-Aware Evaluation of Super-Resolution Models|图像难度感知的超分辨率模型评估|Atakan Topaloglu, Ahmet Bilican, Cansu Korkmaz, A. Murat Tekalp|<http://arxiv.org/pdf/2509.26398v2>|提出基于图像难度评估的超分辨率模型方法，通过两个难度指标区分模型在不同难度图像上的表现。|
|📝 更新|PSScreen: Partially Supervised Multiple Retinal Disease Screening|PSScreen：部分监督的多视网膜疾病筛查|Boyi Zheng, Qing Liu|<http://arxiv.org/pdf/2508.10549v3>|[代码](https://github.com/boyiZheng99/PSScreen.); 提出PSScreen模型，通过半监督学习与特征蒸馏解决多视网膜疾病筛查中的标注不足和数据域差异问题。|
|🆕 发布|NSARM: Next-Scale Autoregressive Modeling for Robust Real-World Image Super-Resolution|NSARM：下一代自回归建模用于稳健的现实世界图像超分辨率|Xiangtao Kong, Rongyuan Wu, Shuaizheng Liu, Lingchen Sun, Lei Zhang|<http://arxiv.org/pdf/2510.00820v1>|[代码](https://github.com/Xiangtaokong/NSARM); 提出了一种基于 next-scale 预测的图像超分辨率框架 NSARM，通过两阶段训练提高了生成质...|
|🆕 发布|PhraseStereo: The First Open-Vocabulary Stereo Image Segmentation Dataset|短语立体：首个开放词汇立体图像分割数据集|Thomas Campagnolo, Ezio Malis, Philippe Martinet, Gaetan Bahl|<http://arxiv.org/pdf/2510.00818v1>|提出了PhraseStereo，首个将自然语言短语与立体图像配对的语义分割数据集，为融合语言与三维感...|
|🆕 发布|MetaLogic: Robustness Evaluation of Text-to-Image Models via Logically Equivalent Prompts|《MetaLogic：通过逻辑等价提示评估文本到图像模型的鲁棒性》|Yifan Shen, Yangyang Shu, Hye-young Paik, Yulei Sui|<http://arxiv.org/pdf/2510.00796v1>|提出了一种无地面真实检测文本到图像模型语义一致性的新框架MetaLogic，有效识别逻辑理解稳健性问...|
|📝 更新|Easi3R: Estimating Disentangled Motion from DUSt3R Without Training|Easi3R：无需训练从DUSt3R估计解耦运动|Xingyu Chen, Yue Chen, Yuliang Xiu, Andreas Geiger, Anpei Chen|<http://arxiv.org/pdf/2503.24391v3>|提出了一种无需训练的4D重建方法Easi3R，通过注意力机制自适应实现动态场景重建。|
|🆕 发布|A Geometric Unification of Generative AI with Manifold-Probabilistic Projection Models|生成式人工智能与流形-概率投影模型的几何统一|Leah Bar, Liron Mor Yosef, Shai Zucker, Neta Shoham, Inbar Seroussi, Nir Sochen|<http://arxiv.org/pdf/2510.00666v1>|提出了一种将几何与概率方法统一的图像生成框架，通过新型Manifold-Probabilistic ...|
|🆕 发布|Adaptive Event Stream Slicing for Open-Vocabulary Event-Based Object Detection via Vision-Language Knowledge Distillation|自适应事件流切片：通过视觉语言知识蒸馏实现开放词汇事件驱动目标检测|Jinchang Zhang, Zijun Li, Jiakai Lin, Guoyu Lu|<http://arxiv.org/pdf/2510.00681v1>|提出了一种结合视觉语言模型和自适应事件流切片的框架，实现了基于事件相机数据的开放词汇对象检测。|
|🆕 发布|Align Your Tangent: Training Better Consistency Models via Manifold-Aligned Tangents|“对齐您的切线：通过流形对齐切线训练更优一致性模型”|Beomsu Kim, Byunghee Cha, Jong Chul Ye|<http://arxiv.org/pdf/2510.00658v1>|[代码](https://github.com/1202kbs/AYT); 提出了一种新的损失函数，通过引导一致性模型沿数据流形训练，大幅加速训练速度并提升样本质量。|
|📝 更新|Towards More Accurate Diffusion Model Acceleration with A Timestep Tuner|面向更精确的扩散模型加速：使用时间步调谐器|Mengfei Xia, Yujun Shen, Changsong Lei, Yu Zhou, Ran Yi, Deli Zhao, Wenping Wang, Yong-Jin Liu|<http://arxiv.org/pdf/2310.09469v2>|[代码](https://github.com/THU-LYJ-Lab/time-tuner); 提出了一种时间步调整方法，通过优化积分方向显著提升了扩散模型加速的准确性和效率。|
|📝 更新|SMaRt: Improving GANs with Score Matching Regularity|SMaRt：利用得分匹配正则性改进生成对抗网络|Mengfei Xia, Yujun Shen, Ceyuan Yang, Ran Yi, Wenping Wang, Yong-Jin Liu|<http://arxiv.org/pdf/2311.18208v3>|[代码](https://github.com/thuxmf/SMaRt); 提出利用得分匹配正则性改进生成对抗网络，有效推动生成数据点靠近真实数据流形。|
|🆕 发布|Color Models in Image Processing: A Review and Experimental Comparison|《图像处理中的颜色模型：综述与实验比较》|Muragul Muratbekova, Nuray Toganas, Ayan Igali, Maksat Shagyrov, Elnara Kadyrgali, Adilet Yerkin, Pakizar Shamoi|<http://arxiv.org/pdf/2510.00584v1>|系统评估了多种颜色模型，发现HS*模型最符合人类感知。|
|📝 更新|iFinder: Structured Zero-Shot Vision-Based LLM Grounding for Dash-Cam Video Reasoning|iFinder：基于结构化零样本视觉的大语言模型定位用于行车记录仪视频推理|Manyi Yao, Bingbing Zhuang, Sparsh Garg, Amit Roy-Chowdhury, Christian Shelton, Manmohan Chandraker, Abhishek Aich|<http://arxiv.org/pdf/2509.19552v2>|提出iFinder框架，通过将驾驶视频转化为可解释的数据结构，增强大型语言模型在无监督条件下的视频理...|
|🆕 发布|Cascaded Diffusion Framework for Probabilistic Coarse-to-Fine Hand Pose Estimation|级联扩散框架用于概率粗到细手部姿态估计|Taeyun Woo, Jinah Park, Tae-Kyun Kim|<http://arxiv.org/pdf/2510.00527v1>|提出级联扩散框架，融合概率建模与细化，准确估计三维手部姿态并建模姿态不确定性。|
|📝 更新|H3AE: High Compression, High Speed, and High Quality AutoEncoder for Video Diffusion Models|H3AE：面向视频扩散模型的高压缩、高速、高质量自动编码器|Yushu Wu, Yanyu Li, Ivan Skorokhodov, Anil Kag, Willi Menapace, Sharath Girish, Aliaksandr Siarohin, Yanzhi Wang .etc.|<http://arxiv.org/pdf/2504.10567v2>|提出了一种高效、高压缩比的自动编码器，实现了视频实时解码和高质量重建。|
|📝 更新|AgenticIQA: An Agentic Framework for Adaptive and Interpretable Image Quality Assessment|自适应可解释图像质量评估的智能体框架：AgenticIQA|Hanwei Zhu, Yu Tian, Keyan Ding, Baoliang Chen, Bolin Chen, Shiqi Wang, Weisi Lin|<http://arxiv.org/pdf/2509.26006v2>|提出了一种自适应且可解释的图像质量评估框架AgenticIQA，通过整合视觉语言模型和传统IQA工具...|
|📝 更新|STORK: Faster Diffusion And Flow Matching Sampling By Resolving Both Stiffness And Structure-Dependence|STORK：通过解决刚度和结构依赖性实现更快的扩散与流匹配采样|Zheng Tan, Weizhen Wang, Andrea L. Bertozzi, Ernest K. Ryu|<http://arxiv.org/pdf/2505.24210v2>|[代码](https://github.com/ZT220501/STORK.); 提出STORK方法，同时解决扩散模型和流匹配模型采样中的刚度问题与结构依赖性，提高图像和视频生成效率...|
|📝 更新|DC-Gen: Post-Training Diffusion Acceleration with Deeply Compressed Latent Space|DC-Gen：基于深度压缩潜在空间的训练后扩散加速|Wenkun He, Yuchao Gu, Junyu Chen, Dongyun Zou, Yujun Lin, Zhekai Zhang, Haocheng Xi, Muyang Li .etc.|<http://arxiv.org/pdf/2509.25180v2>|[代码](https://github.com/dc-ai-projects/DC-Gen.); 提出了一种压缩潜在空间的加速框架DC-Gen，通过后训练提高文本到图像生成模型的效率。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Ultra-Efficient Decoding for End-to-End Neural Compression and Reconstruction|端到端神经压缩与重建的超高效解码|Ethan G. Rogers, Cheng Wang|<http://arxiv.org/pdf/2510.01407v1>|提出了一种基于低秩表示的解码框架，有效降低了神经压缩解码阶段的计算负担，同时保持图像输出高保真度。|
|📝 更新|SEE: See Everything Every Time -- Adaptive Brightness Adjustment for Broad Light Range Images via Events|SEE：每次查看所有内容 -- 通过事件实现宽亮度范围图像的自适应亮度调整|Yunfan Lu, Xiaogang Xu, Hao Lu, Yanlin Qian, Pengteng Li, Huizai Yao, Bin Yang, Junyi Li .etc.|<http://arxiv.org/pdf/2502.21120v2>|[代码](https://github.com/yunfanLu/SEE.); 提出了一种利用事件相机数据自适应调整图像亮度的方法，有效应对不同光照条件下的图像增强问题。|
|🆕 发布|Multi-level Dynamic Style Transfer for NeRFs|多级动态风格迁移用于神经辐射场(NeRFs)|Zesheng Li, Shuaibo Li, Wei Ma, Jianwei Guo, Hongbin Zha|<http://arxiv.org/pdf/2510.00592v1>|提出了一种多级动态风格迁移方法MDS-NeRF，通过重新设计NeRF管道和引入动态风格注入模块，实现...|
|🆕 发布|Relative-Absolute Fusion: Rethinking Feature Extraction in Image-Based Iterative Method Selection for Solving Sparse Linear Systems|相对-绝对融合：重新思考基于图像的迭代方法选择中特征提取用于求解稀疏线性系统|Kaiqi Zhang, Mingguan Yang, Dali Chang, Chun Chen, Yuxiang Zhang, Kexun He, Jing Zhao|<http://arxiv.org/pdf/2510.00500v1>|[代码](https://github.com/zkqq/BMCMat.); 提出RAF方法，融合相对特征与绝对数值特征，提升图像选代法解决稀疏线性系统的准确性和效率。|
|📝 更新|Editing Physiological Signals in Videos Using Latent Representations|使用潜在表征编辑视频中生理信号|Tianwen Zhou, Akshay Paruchuri, Josef Spjut, Kaan Akşit|<http://arxiv.org/pdf/2509.25348v2>|提出了一种编辑视频中生理信号的方法，通过学习框架在保持视觉质量的同时实现心率调控。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Oh-A-DINO: Understanding and Enhancing Attribute-Level Information in Self-Supervised Object-Centric Representations|《Oh-A-DINO：理解和增强自监督以对象为中心表征中的属性级信息》|Stefan Sylvius Wagner, Stefan Harmeling|<http://arxiv.org/pdf/2503.09867v3>|提出了一种辅助潜空间学习策略，增强了自监督模型对物体非几何属性的理解和检索能力。|
|🆕 发布|Instant4D: 4D Gaussian Splatting in Minutes|即时4D：分钟级的4D高斯散点绘制|Zhanpeng Luo, Haoxi Ran, Li Lu|<http://arxiv.org/pdf/2510.01119v1>|[代码](https://instant4d.github.io/.); 提出了一种高效的4D表示方法，实现了无需校准相机或深度传感器的快速单目视频重建。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PAL-Net: A Point-Wise CNN with Patch-Attention for 3D Facial Landmark Localization|PAL-Net：一种用于三维面部标志定位的点-wise卷积神经网络与补丁注意力机制|Ali Shadman Yazdi, Annalisa Cappella, Benedetta Baldini, Riccardo Solazzo, Gianluca Tartaglia, Chiarella Sforza, Giuseppe Baselli|<http://arxiv.org/pdf/2510.00910v1>|[代码](https://github.com/Ali5hadman/PAL-Net-A-Point-Wise-CNN-with-Patch-Attention); 提出了一种基于 patch-attention 的点-wise CNN（PAL-Net），实现了高效...|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Aligning Video Models with Human Social Judgments via Behavior-Guided Fine-Tuning|通过行为引导的微调使视频模型与人类社会判断保持一致|Kathy Garcia, Leyla Isik|<http://arxiv.org/pdf/2510.01502v1>|通过行为引导的微调，使视频模型与人类社交判断一致，提升了社交属性的理解。|
|📝 更新|Learning Frequency and Memory-Aware Prompts for Multi-Modal Object Tracking|学习频率与记忆感知提示在多模态目标跟踪中的应用|Boyue Xu, Ruichao Hou, Tongwei Ren, Dongming zhou, Gangshan Wu, Jinde Cao|<http://arxiv.org/pdf/2506.23972v2>|[代码](https://github.com/xuboyue1999/mmtrack.git.); 提出了一种双适配器框架，通过频率引导和多层记忆增强多模态目标跟踪的准确性和鲁棒性。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|StreamAgent: Towards Anticipatory Agents for Streaming Video Understanding|面向流视频理解的预测性智能体：StreamAgent|Haolin Yang, Feilong Tang, Linxiao Zhao, Xiang An, Ming Hu, Huifa Li, Xinlin Zhuang, Boqian Wang .etc.|<http://arxiv.org/pdf/2508.01875v2>|提出了一种面向实时视频理解的预测性智能体StreamAgent，通过预测关键事件的时间和空间信息，提...|
|🆕 发布|EvoStruggle: A Dataset Capturing the Evolution of Struggle across Activities and Skill Levels|《EvoStruggle：一个捕捉活动过程中挣扎演化的数据集及其技能水平》|Shijia Feng, Michael Wray, Walterio Mayol-Cuevas|<http://arxiv.org/pdf/2510.01362v1>|[代码](https://github.com/FELIXFENG2019/EvoStruggle.); 提出了首个捕捉技能学习过程中挣扎演化的视频数据集，助力模型准确识别学习者的挣扎时段。|
|🆕 发布|An Efficient Quality Metric for Video Frame Interpolation Based on Motion-Field Divergence|基于运动场分歧的视频帧插值高效质量度量方法|Conall Daly, Darren Ramsook, Anil Kokaram|<http://arxiv.org/pdf/2510.01361v1>|[代码](https://github.com/conalld/psnr-div.); 提出了一种基于运动场分歧加权的PSNR改进质量评估指标，提高了视频帧插值质量评估的效率和准确性。|
|📝 更新|ReWatch-R1: Boosting Complex Video Reasoning in Large Vision-Language Models through Agentic Data Synthesis|通过代理数据合成提升大型视觉-语言模型中的复杂视频推理能力：ReWatch-R1|Congzhi Zhang, Zhibin Wang, Yinchao Ma, Jiawei Peng, Yihan Wang, Qiang Zhou, Jun Song, Bo Zheng|<http://arxiv.org/pdf/2509.23652v2>|通过模拟人类“重看”过程的Multi-Agent ReAct框架，构建大规模ReWatch数据集并训...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Multi-modal Spatio-Temporal Transformer for High-resolution Land Subsidence Prediction|多模态时空变换器用于高分辨率土地沉降预测|Wendong Yao, Binhua Huang, Soumyabrata Dev|<http://arxiv.org/pdf/2509.25393v2>|提出了一种多模态时空变换器框架，融合动态位移数据和静态物理先验，大幅提高了高分辨率土地沉降预测的准确...|
|🆕 发布|EgoTraj-Bench: Towards Robust Trajectory Prediction Under Ego-view Noisy Observations|自我轨迹预测基准：面向自我视角噪声观测下的鲁棒轨迹预测|Jiayi Liu, Jiaming Zhou, Ke Ye, Kun-Yu Lin, Allan Wang, Junwei Liang|<http://arxiv.org/pdf/2510.00405v1>|提出了首个针对第一视角噪声观测的轨迹预测基准EgoTraj-Bench，并设计了BiFlow模型以增...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Out-of-Distribution Detection with Relative Angles|《基于相对角度的分布外检测》|Berker Demirel, Marco Fumero, Francesco Locatello|<http://arxiv.org/pdf/2410.04525v2>|[代码](https://github.com/berkerdemirel/ORA-OOD-Detection-with-Relative-Angles.); 提出了一种基于相对角度的异常检测方法，通过分析特征向量与决策边界之间的角度，有效区分正常与异常数据。|
|🆕 发布|Rehearsal-free and Task-free Online Continual Learning With Contrastive Prompt|无复习和无任务在线连续学习：基于对比提示的方法|Aopeng Wang, Ke Deng, Yongli Ren, Jun Luo|<http://arxiv.org/pdf/2510.00467v1>|提出了一种无复习和任务依赖的在线持续学习方法，通过对比提示有效解决了灾难性遗忘问题。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Grasp Pre-shape Selection by Synthetic Training: Eye-in-hand Shared Control on the Hannes Prosthesis|合成训练下的抓握预形状选择：Hannes假肢的眼在手共享控制|Federico Vasile, Elisa Maiettini, Giulia Pasquale, Astrid Florio, Nicolò Boccardo, Lorenzo Natale|<http://arxiv.org/pdf/2203.09812v3>|提出了一种基于合成训练的视觉系统，用于预测假肢手的预抓取形状，有效减轻用户认知负担并提高抓取性能。|
|📝 更新|Continuous Wrist Control on the Hannes Prosthesis: a Vision-based Shared Autonomy Framework|汉尼斯假肢上的连续手腕控制：一种基于视觉的共享自主性框架|Federico Vasile, Elisa Maiettini, Giulia Pasquale, Nicolò Boccardo, Lorenzo Natale|<http://arxiv.org/pdf/2502.17265v2>|[代码](https://hsp-iit.github.io/hannes-wrist-control.); 提出了一种基于视觉共享自主框架的连续手腕控制方法，实现了假肢手腕的自然运动和精准抓握。|
|🆕 发布|AI-CNet3D: An Anatomically-Informed Cross-Attention Network with Multi-Task Consistency Fine-tuning for 3D Glaucoma Classification|AI-CNet3D：一种基于解剖信息的三维青光眼分类跨注意力网络与多任务一致性微调|Roshan Kenia, Anfei Li, Rishabh Srivastava, Kaveri A. Thakoor|<http://arxiv.org/pdf/2510.00882v1>|提出了一种结合3D卷积神经网络和交叉注意力机制的AI-CNet3D模型，用于提高青光眼分类的准确性和...|
|🆕 发布|Disentangling Foreground and Background for vision-Language Navigation via Online Augmentation|通过在线增强实现视觉语言导航中的前景与背景解耦|Yunbo Xu, Xuesong Zhang, Jia Li, Zhenzhen Hu, Richang Hong|<http://arxiv.org/pdf/2510.00604v1>|提出在线增强策略COFA，通过分离前景与背景特征，提升视觉导航在复杂环境下的泛化能力。|
|📝 更新|Proxy-GS: Efficient 3D Gaussian Splatting via Proxy Mesh|代理高斯散布：通过代理网格实现高效的三维高斯散布|Yuanyuan Gao, Yuning Gong, Yifei Liu, Li Jingfeng, Zhihang Zhong, Dingwen Zhang, Yanci Zhang, Dan Xu .etc.|<http://arxiv.org/pdf/2509.24421v2>|Proxy-GS通过引入代理网格实现高效率的3D高斯散布渲染，显著提升了遮挡场景下的渲染速度和质量。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Looking Alike From Far to Near: Enhancing Cross-Resolution Re-Identification via Feature Vector Panning|从远到近外观相似：通过特征向量平移增强跨分辨率重识别|Zanwu Liu, Chao Yuan, Bo Li, Xiaowei Zhang, Guanglin Niu|<http://arxiv.org/pdf/2510.00936v1>|提出了一种基于特征向量平移的轻量级跨分辨率行人重识别框架，有效解决了不同分辨率图像匹配难题。|
|🆕 发布|Gather-Scatter Mamba: Accelerating Propagation with Efficient State Space Model|“ Gather-Scatter Mamba：使用高效状态空间模型加速传播”|Hyun-kyu Ko, Youbin Kim, Jihyeon Park, Dongheok Park, Gyeongjin Kang, Wonjun Cho, Hyung Yi, Eunbyung Park|<http://arxiv.org/pdf/2510.00862v1>|[代码](https://github.com/Ko-Lani/GSMamba.); 提出了一种结合空间注意力与选择性状态空间模型的视频超分辨率方法，有效提升了长序列处理的效率和准确性。|
|🆕 发布|Efficient Multi-modal Large Language Models via Progressive Consistency Distillation|通过渐进一致性蒸馏的高效多模态大型语言模型|Zichen Wen, Shaobo Wang, Yufa Zhou, Junyuan Zhang, Qintong Zhang, Yifeng Gao, Zhaorun Chen, Bin Wang .etc.|<http://arxiv.org/pdf/2510.00515v1>|提出了一种渐进式一致性蒸馏框架EPIC，通过分解视觉token压缩带来的特征空间扰动，有效提升了多模...|
|🆕 发布|A Fast and Precise Method for Searching Rectangular Tumor Regions in Brain MR Images|脑磁共振图像中搜索矩形肿瘤区域的一种快速精确方法|Hidenori Takeshima, Shuki Maruyama|<http://arxiv.org/pdf/2510.00505v1>|提出了一种快速精确的搜索脑部MR图像矩形肿瘤区域的方法，大幅缩短了处理时间并优化了区域质量。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Scheduling Weight Transitions for Quantization-Aware Training|结果： 为量化感知训练调度权重转换|Junghyup Lee, Jeimin Jeon, Dohyung Kim, Bumsub Ham|<http://arxiv.org/pdf/2404.19248v4>|提出了一种新的量化感知训练参数更新策略，通过控制量化权重过渡率来优化训练效果。|
|🆕 发布|FIN: Fast Inference Network for Map Segmentation|快速推理网络：用于地图分割的FIN|Ruan Bispo, Tim Brophy, Reenu Mohandas, Anthony Scanlan, Ciarán Eising|<http://arxiv.org/pdf/2510.00651v1>|提出了高效实时地图分割架构，结合相机和雷达数据，在保持高准确度的同时大幅提升推理速度。|
|📝 更新|Combating Noisy Labels via Dynamic Connection Masking|通过动态连接掩码对抗噪声标签|Xinlei Zhang, Fan Liu, Chuanyi Zhang, Fan Cheng, Yuhui Zheng|<http://arxiv.org/pdf/2508.09697v2>|提出动态连接掩码机制，增强模型对噪声标签的鲁棒性，优于现有方法。|
|🆕 发布|On-the-Fly Data Augmentation via Gradient-Guided and Sample-Aware Influence Estimation|通过梯度引导和样本感知影响估计的实时数据增强|Suorong Yang, Jie Zong, Lihang Wang, Ziheng Qin, Hai Gan, Pengfei Zhou, Kai Wang, Yang You .etc.|<http://arxiv.org/pdf/2510.00434v1>|提出了一种根据样本影响动态调整数据增强强度的方法，有效提升了模型泛化能力和训练效果。|
|🆕 发布|A Deep Learning Pipeline for Epilepsy Genomic Analysis Using GPT-2 XL and NVIDIA H100|使用 GPT-2 XL 和 NVIDIA H100 的癫痫基因组分析深度学习流程|Muhammad Omer Latif, Hayat Ullah, Muhammad Ali Shafique, Zhihua Dong|<http://arxiv.org/pdf/2510.00392v1>|利用GPT-2 XL和NVIDIA H100 GPU加速，提出了一种高效分析癫痫基因表达的新方法。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Sparkle: Mastering Basic Spatial Capabilities in Vision Language Models Elicits Generalization to Spatial Reasoning|“Sparkle：在视觉语言模型中掌握基本空间能力可引发空间推理的泛化”|Yihong Tang, Ao Qu, Zhaokai Wang, Dingyi Zhuang, Zhaofeng Wu, Wei Ma, Shenhao Wang, Yunhan Zheng .etc.|<http://arxiv.org/pdf/2410.16162v4>|[代码](https://github.com/YihongT/Sparkle.); 通过训练基本空间能力提升视觉语言模型的空间推理能力，Sparkle框架有效促进了复杂空间任务的性能提...|
|📝 更新|Meta-Transfer Derm-Diagnosis: Exploring Few-Shot Learning and Transfer Learning for Skin Disease Classification in Long-Tail Distribution|元迁移皮肤诊断：探索少量样本学习和迁移学习在长尾分布皮肤疾病分类中的应用|Zeynep Özdemir, Hacer Yalim Keles, Ömer Özgür Tanrıöver|<http://arxiv.org/pdf/2404.16814v2>|提出三种学习策略以应对少量标记数据和长尾分布的皮肤疾病分类问题，实现最佳性能。|
|🆕 发布|Activation-Deactivation: A General Framework for Robust Post-hoc Explainable AI|激活-失活：一种用于鲁棒的后验可解释人工智能的通用框架|Akchunya Chanchal, David A. Kelly, Hana Chockler|<http://arxiv.org/pdf/2510.01038v1>|提出了一种无需额外训练的Activation-Deactivation框架，通过内部模型调整实现了更...|
|🆕 发布|ReSWD: ReSTIR'd, not shaken. Combining Reservoir Sampling and Sliced Wasserstein Distance for Variance Reduction|重采样Sliced Wasserstein距离以减少方差：ReSTIR改进版，未被动摇|Mark Boss, Andreas Engelhardt, Simon Donné, Varun Jampani|<http://arxiv.org/pdf/2510.01061v1>|提出ReSWD方法，结合水库抽样和切片Wasserstein距离，有效降低方差并保持无偏估计，提升视...|
|🆕 发布|Diagnosing Shortcut-Induced Rigidity in Continual Learning: The Einstellung Rigidity Index (ERI)|诊断连续学习中捷径引起的刚性：定势刚性指数（ERI）|Kai Gu, Weishi Shi|<http://arxiv.org/pdf/2510.00475v1>|提出Einstellung Rigidity Index (ERI)诊断工具，揭示了持续学习中的捷径...|
|🆕 发布|VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators|VLA-RFT：基于验证奖励的视觉-语言-动作强化微调在世界模拟器中|Hengtao Li, Pengxiang Ding, Runze Suo, Yihao Wang, Zirui Ge, Dongyuan Zang, Kexian Yu, Mingyang Sun .etc.|<http://arxiv.org/pdf/2510.00406v1>|[代码](https://vla-rft.github.io/.); 提出了VLA-RFT框架，通过使用数据驱动的世界模型作为可控仿真器，有效降低样本需求并增强VLA模型...|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Adversarial Training under Hyperspectral Images|面向高光谱图像的对抗训练方法研究|Weihua Zhang, Chengze Jiang, Jie Gui, Lu Dong|<http://arxiv.org/pdf/2510.01014v1>|提出针对 hyperspectral 图像的 AT-RA 训练方法，增强对抗性攻击下的模型鲁棒性并保...|
|🆕 发布|ZQBA: Zero Query Black-box Adversarial Attack|零查询黑盒对抗攻击方法ZQBA|Joana C. Costa, Tiago Roxo, Hugo Proença, Pedro R. M. Inácio|<http://arxiv.org/pdf/2510.00769v1>|[代码](https://github.com/Joana-Cabral/ZQBA.); 提出了一种无需查询的零查询黑盒攻击方法，通过利用深度神经网络的表征来生成对抗样本，有效提高了攻击效率...|
|📝 更新|Robustness and sex differences in skin cancer detection: logistic regression vs CNNs|皮肤癌检测中的鲁棒性与性别差异：逻辑回归与卷积神经网络对比|Nikolette Pedersen, Regitze Sydendal, Andreas Wulff, Ralf Raumanns, Eike Petersen, Veronika Cheplygina|<http://arxiv.org/pdf/2504.11415v2>|探究性别差异对皮肤癌检测模型影响，发现CNN对男性患者准确度更高。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Equivariant Splitting: Self-supervised learning from incomplete data|等变分割：从不完整数据中进行自监督学习|Victor Sechaud, Jérémy Scanvic, Quentin Barthélemy, Patrice Abry, Julián Tachella|<http://arxiv.org/pdf/2510.00929v2>|提出了一种针对不完全数据的新型自监督学习方法，通过结合等变性和自监督分割损失，实现了与监督学习相当的...|
|📝 更新|Hierarchical place recognition with omnidirectional images and curriculum learning-based loss functions|基于全方位图像与基于课程学习损失函数的层次化场景识别|Marcos Alfaro, Juan José Cabrera, María Flores, Óscar Reinoso, Luis Payá|<http://arxiv.org/pdf/2404.14117v3>|[代码](https://github.com/MarcosAlfaro/TripletNetworksIndoorLocalization.git.); 提出了一种结合全景图像和基于课程学习的三元损失函数的视觉定位方法，提高了移动机器人导航的准确性和鲁棒...|
|📝 更新|AS400-DET: Detection using Deep Learning Model for IBM i (AS/400)|AS400-DET：基于深度学习模型的IBM i（AS/400）检测|Thanh Tran, Son T. Luu, Quan Bui, Shoshin Nomura|<http://arxiv.org/pdf/2506.13032v2>|提出了一种用于IBM i系统自动GUI组件检测的深度学习方法，并构建了首个相关的人类注释数据集。|
|🆕 发布|Feature Identification for Hierarchical Contrastive Learning|层次对比学习的特征识别|Julius Ott, Nastassia Vysotskaya, Huawei Sun, Lorenzo Servadei, Robert Wille|<http://arxiv.org/pdf/2510.00837v1>|提出两种新型层级对比学习方法，通过显式建模类间关系和解决类别不平衡问题，实现跨层级细粒度聚类，达到C...|
|🆕 发布|Deep learning motion correction of quantitative stress perfusion cardiovascular magnetic resonance|深度学习驱动的定量应力灌注心血管磁共振运动校正|Noortje I. P. Schueler, Nathan C. K. Wong, Richard J. Crawley, Josien P. W. Pluim, Amedeo Chiribiri, Cian M. Scannell|<http://arxiv.org/pdf/2510.00723v1>|提出了一种基于深度学习的快速、稳健的心肌灌注磁共振成像运动校正方法，提高了成像准确性和处理效率。|
|🆕 发布|Batch-CAM: Introduction to better reasoning in convolutional deep learning models|批处理-CAM：卷积深度学习模型中更好的推理方法介绍|Giacomo Ignesti, Davide Moroni, Massimo Martinelli|<http://arxiv.org/pdf/2510.00664v1>|引入Batch-CAM方法，结合Grad-CAM与原型重构损失，提升深度学习模型准确性与解释性。|
|🆕 发布|Weakly Supervised Cloud Detection Combining Spectral Features and Multi-Scale Deep Network|弱监督云检测：结合光谱特征与多尺度深度网络|Shaocong Zhu, Zhiwei Li, Xinghua Li, Huanfeng Shen|<http://arxiv.org/pdf/2510.00654v1>|提出了一种结合光谱特征与多尺度深度网络的弱监督云检测方法，显著提升了云检测精度。|
|🆕 发布|Unsupervised Unfolded rPCA (U2-rPCA): Deep Interpretable Clutter Filtering for Ultrasound Microvascular Imaging|无监督展开的rPCA（U2-rPCA）：用于超声微血管成像的深度可解释杂波过滤|Huaying Li, Liansheng Wang, Yinran Chen|<http://arxiv.org/pdf/2510.00660v1>|提出了一种无监督的U2-rPCA方法，通过数学可解释的算法展开和增强稀疏信号捕捉，有效提高了超声微血...|
|📝 更新|Divergence-Based Similarity Function for Multi-View Contrastive Learning|基于散度的多视角对比学习相似性函数|Jae Hyoung Jeon, Cheolsu Lim, Myungjoo Kang|<http://arxiv.org/pdf/2507.06560v2>|提出了一种基于分布差异的相似度函数，有效建模多视角间的联合结构并提升对比学习性能。|
|🆕 发布|Adaptive Shared Experts with LoRA-Based Mixture of Experts for Multi-Task Learning|自适应共享专家与基于LoRA的混合专家模型用于多任务学习|Minghao Yang, Ren Togo, Guang Li, Takahiro Ogawa, Miki Haseyama|<http://arxiv.org/pdf/2510.00570v1>|提出了一种自适应共享专家与LoRA混合专家模型，优化了多任务学习中的知识共享和专家专长。|
|📝 更新|ExoPredicator: Learning Abstract Models of Dynamic Worlds for Robot Planning|外预测器：学习动态世界的抽象模型以辅助机器人规划|Yichao Liang, Dat Nguyen, Cambridge Yang, Tianyang Li, Joshua B. Tenenbaum, Carl Edward Rasmussen, Adrian Weller, Zenna Tavares .etc.|<http://arxiv.org/pdf/2509.26255v2>|提出了一种抽象世界模型框架，通过学习符号状态表示和因果过程，实现了机器人长距离规划的快速泛化。|
|🆕 发布|PAL-UI: Planning with Active Look-back for Vision-Based GUI Agents|PAL-UI：基于视觉的GUI智能体主动回溯规划方法|Zikang Liu, Junyi Li, Wayne Xin Zhao, Dawei Gao, Yaliang Li, Ji-rong Wen|<http://arxiv.org/pdf/2510.00413v1>|提出了一种自适应回顾历史观测的GUI智能体框架，有效提升了长周期任务的处理能力。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Beyond the Individual: Introducing Group Intention Forecasting with SHOT Dataset|超越个体：引入基于SHOT数据集的群体意图预测|Ruixu Zhang, Yuran Wang, Xinyi Hu, Chaoyu Mai, Wenxuan Liu, Danni Xu, Xian Zhong, Zheng Wang|<http://arxiv.org/pdf/2509.20715v3>|[代码](https://xinyi-hu.github.io/SHOT_DATASET.); 提出集体意图预测任务及相应数据集，通过个体行为分析预测集体目标的出现。|
|📝 更新|SeMoBridge: Semantic Modality Bridge for Efficient Few-Shot Adaptation of CLIP|《SeMoBridge：用于CLIP高效少样本适应的语义模态桥》|Christoph Timmermann, Hyunse Lee, Woojin Lee|<http://arxiv.org/pdf/2509.26036v2>|[代码](https://github.com/christti98/semobridge.); SeMoBridge通过构建语义模态桥直接解决CLIP在少量样本分类中的模态内失准问题，有效提升其性...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Visual Self-Refinement for Autoregressive Models|自回归模型的可视化自我精炼|Jiamian Wang, Ziqi Zhou, Chaithanya Kumar Mummadi, Sohail Dianat, Majid Rabbani, Raghuveer Rao, Chen Qiu, Zhiqiang Tao|<http://arxiv.org/pdf/2510.00993v1>|提出了一种视觉自精炼模块，有效提升了自回归模型在视觉序列生成中的空间对应建模能力。|
|🆕 发布|POVQA: Preference-Optimized Video Question Answering with Rationales for Data Efficiency|偏好优化的视频问答及数据效率的理性解释：POVQA|Ashim Dahal, Ankit Ghimire, Saydul Akbar Murad, Nick Rahimi|<http://arxiv.org/pdf/2510.01009v1>|提出了一种数据高效的视频问答方法POVQA，通过将视频压缩为单帧图像并使用轻量级监督，显著提升了性能...|
|📝 更新|VisualOverload: Probing Visual Understanding of VLMs in Really Dense Scenes|《视觉超载：在极高密度场景中探测大型视觉语言模型的视觉理解能力》|Paul Gavrikov, Wei Lin, M. Jehanzeb Mirza, Soumya Jahagirdar, Muhammad Huzaifa, Sivan Doveh, Serena Yeung-Levy, James Glass .etc.|<http://arxiv.org/pdf/2509.25339v2>|[代码](http://paulgavrikov.github.io/visualoverload); 提出了VisualOverload基准，揭示了现有视觉模型在处理复杂密集场景中的视觉理解缺陷。|
|🆕 发布|Training-free Uncertainty Guidance for Complex Visual Tasks with MLLMs|无需训练的不确定性引导策略：利用大规模语言模型处理复杂视觉任务|Sanghwan Kim, Rui Xiao, Stephan Alaniz, Yongqin Xian, Zeynep Akata|<http://arxiv.org/pdf/2510.00705v1>|提出了一种无需训练的框架，利用多模态大语言模型内禀不确定性作为指导信号，提升复杂视觉任务的性能。|
|📝 更新|CoFFT: Chain of Foresight-Focus Thought for Visual Language Models|“CoFFT：视觉语言模型的前瞻-聚焦思维链”|Xinyu Zhang, Yuxuan Dong, Lingling Zhang, Chengyou Jia, Zhuohang Dang, Basura Fernando, Jun Liu, Mike Zheng Shou|<http://arxiv.org/pdf/2509.22010v3>|提出了一种模拟人类视觉认知的Chain of Foresight-Focus Thought方法，有...|
|🆕 发布|LVLMs as inspectors: an agentic framework for category-level structural defect annotation|LVLMs作为检查员：用于类别级结构缺陷标注的代理框架|Sheng Jiang, Yuanmin Ning, Bingxi Huang, Peiyin Chen, Zhaohui Chen|<http://arxiv.org/pdf/2510.00603v1>|提出了一种自动缺陷标注框架ADPT，利用大型视觉语言模型和迭代自问机制，无需人工监督即可生成高质量的...|
|📝 更新|A Multimodal LLM Approach for Visual Question Answering on Multiparametric 3D Brain MRI|一种多模态大规模语言模型方法用于多参数3D脑磁共振成像的视觉问答|Arvind Murari Vepa, Yannan Yu, Jingru Gan, Anthony Cuturrufo, Weikai Li, Wei Wang, Fabien Scalzo, Yizhou Sun|<http://arxiv.org/pdf/2509.25889v2>|提出了一种针对多参数3D脑部MRI的视觉问答新方法，实现了跨模态信息融合并显著提升了性能。|
|🆕 发布|MathSticks: A Benchmark for Visual Symbolic Compositional Reasoning with Matchstick Puzzles|火柴棍数学：基于火柴棍拼图视觉符号组合推理的基准测试|Yuheng Ji, Huajie Tan, Cheng Chi, Yijie Xu, Yuting Zhao, Enshen Zhou, Huaihai Lyu, Pengwei Wang .etc.|<http://arxiv.org/pdf/2510.00483v1>|[代码](https://github.com/Yuheng2000/MathSticks.); 提出MathSticks基准，测试视觉符号组合推理能力，涵盖视觉与符号操作，揭示模型局限性。|
|📝 更新|Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents|“分解与构建：基于技能的视觉与语言导航代理的混合”|Tianyi Ma, Yue Zhang, Zehao Wang, Parisa Kordjamshidi|<http://arxiv.org/pdf/2508.07642v2>|提出SkillNav框架，通过模块化解耦的技能推理提升视觉语言导航在复杂环境下的泛化能力。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PRPO: Paragraph-level Policy Optimization for Vision-Language Deepfake Detection|段落级策略优化用于视觉-语言深度伪造检测|Tuan Nguyen, Naseem Khan, Khang Tran, NhatHai Phan, Issa Khalil|<http://arxiv.org/pdf/2509.26272v2>|提出了一种强化学习算法PRPO，通过将大型语言模型的推理与图像内容在段落级别对齐，显著提升了深伪检测...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-Domain Brain Vessel Segmentation Through Feature Disentanglement|多域脑血管分割通过特征解耦|Francesco Galati, Daniele Falcetta, Rosa Cortese, Ferran Prados, Ninon Burgos, Maria A. Zuluaga|<http://arxiv.org/pdf/2510.00665v2>|[代码](https://github.com/i-vesseg/MultiVesSeg.); 提出了一种通过特征解耦实现多领域脑血管分割的方法，有效适应不同数据集和成像模式。|
|🆕 发布|Does Bigger Mean Better? Comparitive Analysis of CNNs and Biomedical Vision Language Modles in Medical Diagnosis|更大的网络意味着更好的性能吗？CNN与生物医学视觉语言模型在医学诊断中的比较分析|Ran Tong, Jiaqi Liu, Su Liu, Jiexi Xu, Lanruo Wang, Tong Wang|<http://arxiv.org/pdf/2510.00411v2>|通过决策阈值校准，论文证明了零样本医疗视觉语言模型BiomedCLIP在肺炎和肺结核检测上可媲美或超...|
|📝 更新|Development of a Mobile Application for at-Home Analysis of Retinal Fundus Images|移动应用程序的开发，用于家庭环境下视网膜眼底图像分析|Mattea Reid, Zuhairah Zainal, Khaing Zin Than, Danielle Chan, Jonathan Chan|<http://arxiv.org/pdf/2509.16814v2>|开发了一款移动应用，通过监测视网膜图像指标，为年龄相关眼病提供早期预警。|
|🆕 发布|Intuitions of Machine Learning Researchers about Transfer Learning for Medical Image Classification|机器学习研究者在医学图像分类迁移学习方面的直觉|Yucheng Lu, Hubert Dariusz Zając, Veronika Cheplygina, Amelia Jiménez-Sánchez|<http://arxiv.org/pdf/2510.00902v1>|探究了医学图像分类中迁移学习数据集选择的直觉性因素，提出了更系统选择方法的实践见解。|
|🆕 发布|Defect Segmentation in OCT scans of ceramic parts for non-destructive inspection using deep learning|陶瓷部件OCT扫描中的缺陷分割：用于无损检测的深度学习方法|Andrés Laveda-Martínez, Natalia P. García-de-la-Puente, Fernando García-Torres, Niels Møller Israelsen, Ole Bang, Dominik Brouczek, Niels Benson, Adrián Colomer .etc.|<http://arxiv.org/pdf/2510.00745v1>|提出了一种基于U-Net架构的深度学习系统，用于自动检测陶瓷部件OCT扫描中的缺陷，实现高效可靠的非...|
|🆕 发布|From 2D to 3D, Deep Learning-based Shape Reconstruction in Magnetic Resonance Imaging: A Review|从二维到三维：基于深度学习的磁共振成像形状重建综述|Emma McMillian, Abhirup Banerjee, Alfonso Bueno-Orovio|<http://arxiv.org/pdf/2510.01296v1>|系统综述了基于深度学习的2D MRI到3D形状重建技术，推动医学成像诊断与治疗发展。|
|📝 更新|Electromagnetic Inverse Scattering from a Single Transmitter|单一发射源电磁逆散射|Yizhe Cheng, Chunxun Tian, Haoru Wang, Wentao Zhu, Xiaoxuan Ma, Yizhou Wang|<http://arxiv.org/pdf/2506.21349v4>|提出了一种数据驱动的电磁逆散射框架，能在只有一个发射器的情况下准确预测散射体的相对介电常数。|
|🆕 发布|Beyond one-hot encoding? Journey into compact encoding for large multi-class segmentation|超越独热编码？深入探索大型多类分割的紧凑编码之旅|Aaron Kujawa, Thomas Booth, Tom Vercauteren|<http://arxiv.org/pdf/2510.00667v1>|提出了一种针对多类医学图像分割的紧凑编码方法，以降低计算和内存需求。|
|🆕 发布|U-DFA: A Unified DINOv2-Unet with Dual Fusion Attention for Multi-Dataset Medical Segmentation|U-DFA：一种面向多数据集医学分割的统一DINOv2-Unet双融合注意力模型|Zulkaif Sajjad, Furqan Shaukat, Junaid Mir|<http://arxiv.org/pdf/2510.00585v1>|提出了一种融合局部与全局特征的U-DFA框架，有效提升多数据集医学图像分割性能。|
|🆕 发布|Domain-Specialized Interactive Segmentation Framework for Meningioma Radiotherapy Planning|meningioma 的翻译为“脑膜瘤”，radiotherapy 的翻译为“放射治疗”。以下是翻译结果：  用于脑膜瘤放射治疗规划的领域专业化交互式分割框架|Junhyeok Lee, Han Jang, Kyu Sung Choi|<http://arxiv.org/pdf/2510.00416v1>|[代码](https://github.com/snuh-rad-aicon/Interactive-MEN-RT); 开发了专用于脑膜瘤放疗规划的交互式分割工具，提高了临床分割精度和效率。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Strategic Fusion of Vision Language Models: Shapley-Credited Context-Aware Dawid-Skene for Multi-Label Tasks in Autonomous Driving|视觉语言模型的战略融合：基于Shapley值的上下文感知Dawid-Skene算法在自动驾驶多标签任务中的应用|Yuxiang Feng, Keyang Zhang, Hassane Ouchouid, Ashwil Kaniamparambil, Ioannis Souflas, Panagiotis Angeloudis|<http://arxiv.org/pdf/2510.01126v1>|提出了一种基于博弈论的视觉语言模型融合方法，有效提升了自动驾驶多标签任务准确性和鲁棒性。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RS-OOD: A Vision-Language Augmented Framework for Out-of-Distribution Detection in Remote Sensing|遥感中的异常分布检测：一种视觉-语言增强框架RS-OOD|Chenhao Wang, Yingrui Ji, Yu Meng, Yunjian Zhang, Yao Zhu|<http://arxiv.org/pdf/2509.02273v2>|提出RS-OOD框架，利用视觉语言模型实现遥感图像的稳健少量样本异常检测。|
|🆕 发布|Forestpest-YOLO: A High-Performance Detection Framework for Small Forestry Pests|《Forestpest-YOLO：一种用于小型林业害虫的高性能检测框架》|Aoduo Li, Peikai Lin, Jiancheng Li, Zhen Zhang, Shiting Wu, Zexiao Liang, Zhifa Jiang|<http://arxiv.org/pdf/2510.00547v1>|优化YOLOv8架构，引入创新模块，显著提升复杂森林环境中微小害虫检测性能。|
|🆕 发布|Discrete Wavelet Transform as a Facilitator for Expressive Latent Space Representation in Variational Autoencoders in Satellite Imagery|离散小波变换在变分自编码器中促进卫星图像表现性潜在空间表示的应用|Arpan Mahara, Md Rezaul Karim Khan, Naphtali Rishe, Wenjia Wang, Seyed Masoud Sadjadi|<http://arxiv.org/pdf/2510.00376v1>|引入离散小波变换增强变分自编码器的潜在空间表示，提高了卫星图像的表征能力。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GoalFlow: Goal-Driven Flow Matching for Multimodal Trajectories Generation in End-to-End Autonomous Driving|目标流：面向端到端自动驾驶的多模态轨迹生成中的目标驱动流匹配|Zebin Xing, Xingyu Zhang, Yang Hu, Bo Jiang, Tong He, Qian Zhang, Xiaoxiao Long, Wei Yin|<http://arxiv.org/pdf/2503.05689v6>|[代码](https://github.com/YvanYin/GoalFlow.); 提出GoalFlow方法，通过引入目标点约束生成高质量的多模态轨迹，解决了自动驾驶中轨迹选择复杂性和...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DepthLM: Metric Depth From Vision Language Models|深度学习模型度量化深度：从视觉语言模型中学习|Zhipeng Cai, Ching-Feng Yeh, Hu Xu, Zhuang Liu, Gregory Meyer, Xinjie Lei, Changsheng Zhao, Shang-Wen Li .etc.|<http://arxiv.org/pdf/2509.25413v2>|提出了一种基于视觉提示和条件增强的文本交互方法DepthLM，使视觉语言模型在无需改变架构或损失函数...|


### 可解释视觉智能 (Explainable Visual Intelligence)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Achieving More Human Brain-Like Vision via Human EEG Representational Alignment|通过人类脑电图表征对齐实现更接近人脑的视觉|Zitong Lu, Yile Wang, Julie D. Golomb|<http://arxiv.org/pdf/2401.17231v3>|通过非侵入式EEG实现人脑视觉表征对齐，提出ReAlnet模型，使计算机视觉更接近人脑处理方式。|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Beyond Semantics: Rediscovering Spatial Awareness in Vision-Language Models|超越语义：在视觉-语言模型中重新发现空间意识|Jianing Qi, Jiawei Liu, Hao Tang, Zhigang Zhu|<http://arxiv.org/pdf/2503.17349v2>|揭示了视觉语言模型中空间信息处理的不足，并提出了三种解释性工具来改善模型的空间推理能力。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Extreme Blind Image Restoration via Prompt-Conditioned Information Bottleneck|通过提示条件的信息瓶颈进行极端盲图像恢复|Hongeun Kim, Bryan Sangwoo Kim, Jong Chul Ye|<http://arxiv.org/pdf/2510.00728v1>|提出了一种基于信息瓶颈理论的框架，通过分步映射和预训练模型实现了极端退化图像的高质量恢复。|
|🆕 发布|OTTER: Open-Tagging via Text-Image Representation for Multi-modal Understanding|OTTER：基于文本-图像表示的开标签标注方法用于多模态理解|Jieer Ouyang, Xiaoneng Xiang, Zheng Wang, Yangkai Ding|<http://arxiv.org/pdf/2510.00652v1>|提出OTTER框架，融合预定义标签集的稳定性和用户驱动的开放标签适应性，提升多模态理解性能。|
|🆕 发布|Measuring and Controlling the Spectral Bias for Self-Supervised Image Denoising|测量与控制自监督图像去噪中的光谱偏差|Wang Zhang, Huaqiu Li, Xiaowan Hu, Tao Jiang, Zikang Chen, Haoqian Wang|<http://arxiv.org/pdf/2510.00454v1>|提出方法SCNet优化自监督图像去噪，通过频域分离和低秩重构保留高频细节。|

