## [UPDATED!] **2025-10-02** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Inferring Dynamic Physical Properties from Video Foundation Models|从视频基础模型推断动态物理属性|Guanqi Zhan, Xianzheng Ma, Weidi Xie, Andrew Zisserman|<http://arxiv.org/pdf/2510.02311v1>|提出新数据集和三种视频推断方法，用于预测动态物理属性，实现视频基础模型性能接近理想效果。|
|🆕 发布|FRIEREN: Federated Learning with Vision-Language Regularization for Segmentation|联邦学习与视觉语言正则化相结合的分割方法：FRIEREN|Ding-Ruei Shen|<http://arxiv.org/pdf/2510.02114v1>|提出了一种结合视觉与语言模态的联邦学习方法FRIEREN，有效解决无标签客户端数据导致的领域偏移问题...|
|🆕 发布|FideDiff: Efficient Diffusion Model for High-Fidelity Image Motion Deblurring|FideDiff：高保真图像运动去模糊的高效扩散模型|Xiaoyang Liu, Zhengyan Zhou, Zihang Xu, Jiezhang Cao, Zheng Chen, Yulun Zhang|<http://arxiv.org/pdf/2510.01641v1>|[代码](https://github.com/xyLiu339/FideDiff.); 提出了FideDiff模型，通过扩散过程和一致性训练实现高效的高保真图像去模糊。|
|🆕 发布|ImageNet-Think-250K: A Large-Scale Synthetic Dataset for Multimodal Reasoning for Vision Language Models|《ImageNet-Think-250K：一种用于视觉语言模型多模态推理的大规模合成数据集》|Krishna Teja Chitty-Venkata, Murali Emani|<http://arxiv.org/pdf/2510.01582v1>|构建了一个大规模合成数据集ImageNet-Think-250K，用于训练和评估具有显式推理能力的视...|
|🆕 发布|Guiding Multimodal Large Language Models with Blind and Low Vision People Visual Questions for Proactive Visual Interpretations|引导多模态大型语言模型通过盲人和低视力人群的视觉问题进行主动视觉解释|Ricardo Gonzalez Penuela, Felipe Arias-Russi, Victor Capriles|<http://arxiv.org/pdf/2510.01576v1>|[代码](https://github.com/rgonzalezp/guiding-multimodal-large-language-models-with-blind-and-low-vision-people-visual-questions); 利用历史盲人和低视力用户问题指导大型多模态语言模型，生成更符合用户需求的视觉描述。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|TrimTokenator: Towards Adaptive Visual Token Pruning for Large Multimodal Models|《TrimTokenator：面向大型多模态模型的自适应视觉标记剪枝方法》|Hao Zhang, Mengsi Lyu, Chenrui He, Yulong Ao, Yonghua Lin|<http://arxiv.org/pdf/2509.00320v2>|提出了一种针对视觉token的适应性剪枝策略，有效降低大型多模态模型推理成本同时保持性能。|
|🆕 发布|Model Merging to Maintain Language-Only Performance in Developmentally Plausible Multimodal Models|模型融合以在发展可解释的多模态模型中保持仅语言性能|Ece Takmaz, Lisa Bylinina, Jakub Dotlacil|<http://arxiv.org/pdf/2510.01845v1>|通过模型合并策略，在保持多模态性能的同时，提升了低资源设置下语言模型的单一语言任务表现。|
|📝 更新|HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy|HAMLET：将您的视觉-语言-动作模型转换为历史感知策略|Myungkyu Koo, Daewon Choi, Taeyoung Kim, Kyungmin Lee, Changyeon Kim, Younggyo Seo, Jinwoo Shin|<http://arxiv.org/pdf/2510.00695v2>|提出了一种历史感知框架HAMLET，通过整合历史上下文信息，显著提升了机器人操作任务的成功率。|
|🆕 发布|Beyond Simple Fusion: Adaptive Gated Fusion for Robust Multimodal Sentiment Analysis|超越简单融合：自适应门控融合用于稳健的多模态情感分析|Han Wu, Yanming Sun, Yunhe Yang, Derek F. Wong|<http://arxiv.org/pdf/2510.01677v1>|提出了一种自适应门控融合网络，通过调整特征权重有效应对多模态情感分析中的噪声和模态差异问题。|
|🆕 发布|Growing Visual Generative Capacity for Pre-Trained MLLMs|为预训练的多模态语言模型培养视觉生成能力|Hanyu Wang, Jiaming Han, Ziyan Yang, Qi Zhao, Shanchuan Lin, Xiangyu Yue, Abhinav Shrivastava, Zhenheng Yang .etc.|<http://arxiv.org/pdf/2510.01546v1>|提出Bridge模型，通过混合转换器架构增强预训练视觉模型的生成能力，实现统一框架下的图像理解和生成...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Audio-Enhanced Vision-Language Modeling with Latent Space Broadening for High Quality Data Expansion|音频增强的视觉语言建模：利用潜在空间扩展实现高质量数据扩张|Yu Sun, Yin Li, Ruixiao Sun, Chunhui Liu, Fangming Zhou, Ze Jin, Linjie Wang, Xiang Shen .etc.|<http://arxiv.org/pdf/2503.17551v2>|提出kNN-based Latent Space Broadening和Vision-Languag...|
|🆕 发布|Consistent Assistant Domains Transformer for Source-free Domain Adaptation|一致辅助域变换器：无需源域的域自适应|Renrong Shao, Wei Zhang, Kangyang Luo, Qin Li, and Jun Wang|<http://arxiv.org/pdf/2510.01559v1>|[代码](https://github.com/RoryShao/CADTrans.git.); 提出了一种构建一致性辅助域的变换器方法，有效解决了无源域数据条件下的域自适应问题。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|microCLIP: Unsupervised CLIP Adaptation via Coarse-Fine Token Fusion for Fine-Grained Image Classification|微CLIP：通过粗细粒度标记融合进行无监督CLIP适应以实现细粒度图像分类|Sathira Silva, Eman Ali, Chetan Arora, Muhammad Haris Khan|<http://arxiv.org/pdf/2510.02270v1>|[代码](https://github.com/sathiiii/microCLIP.); 提出了一种自训练框架microCLIP，通过精细线索优化CLIP模型，提升细粒度图像分类性能。|
|📝 更新|UltraUPConvNet: A UPerNet- and ConvNeXt-Based Multi-Task Network for Ultrasound Tissue Segmentation and Disease Prediction|超UPConvNet：一种基于UPerNet和ConvNeXt的多任务网络，用于超声组织分割和疾病预测|Zhi Chen, Le Zhang|<http://arxiv.org/pdf/2509.11108v2>|[代码](https://github.com/yyxl123/UltraUPConvNet); 提出了一种高效的多任务网络UltraUPConvNet，实现超声图像分类和分割的同时降低计算负担。|
|🆕 发布|ClustViT: Clustering-based Token Merging for Semantic Segmentation|基于聚类的标记合并用于语义分割的ClustViT|Fabio Montello, Ronja Güldenring, Lazaros Nalpantidis|<http://arxiv.org/pdf/2510.01948v1>|提出ClustViT方法，通过可训练的聚类模块合并相似图像块，提高视觉Transformer在语义分...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GeoPurify: A Data-Efficient Geometric Distillation Framework for Open-Vocabulary 3D Segmentation|GeoPurify：面向开放词汇三维分割的数据高效几何蒸馏框架|Weijia Dou, Xu Zhang, Yi Bin, Jian Liu, Bo Peng, Guoqing Wang, Yang Yang, Heng Tao Shen|<http://arxiv.org/pdf/2510.02186v1>|[代码](https://github.com/tj12323/GeoPurify); 提出GeoPurify框架，利用几何先验和少量数据高效实现2D视觉语言模型到3D语义分割的转换。|
|🆕 发布|A Multicentric Dataset for Training and Benchmarking Breast Cancer Segmentation in H&E Slides|《用于训练和评估H&E切片中乳腺癌分割的多中心数据集》|Carlijn Lems, Leslie Tessier, John-Melle Bokhorst, Mart van Rijthoven, Witali Aswolinskiy, Matteo Pozzi, Natalie Klubickova, Suzanne Dintzis .etc.|<http://arxiv.org/pdf/2510.02037v1>|介绍了BEETLE多中心乳腺癌H&E切片分割数据集，增强了模型泛化能力和生物标志物验证的稳健性。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Automated Model Evaluation for Object Detection via Prediction Consistency and Reliability|通过预测一致性和可靠性进行目标检测的自动化模型评估|Seungju Yoo, Hyuk Kwon, Joong-Won Hwang, Kibok Lee|<http://arxiv.org/pdf/2508.12082v2>|[代码](https://github.com/YonseiML/autoeval-det.); 提出了一种自动评估对象检测模型性能的方法，通过测量预测框的一致性和可靠性来无需标注数据评估模型表现。|
|🆕 发布|An Efficient Deep Template Matching and In-Plane Pose Estimation Method via Template-Aware Dynamic Convolution|一种基于模板感知动态卷积的高效深度模板匹配与平面内位姿估计方法|Ke Jia, Ji Zhou, Hanxin Li, Zhigan Zhou, Haojie Chu, Xiaojie Li|<http://arxiv.org/pdf/2510.01678v1>|[代码](https://github.com/ZhouJ6610/PoseMatch-TDCM.); 提出了一种高效的深度模板匹配与平面位姿估计方法，通过模板感知动态卷积模块提升复杂背景下的定位和几何回...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GaussianMorphing: Mesh-Guided 3D Gaussians for Semantic-Aware Object Morphing|高斯变形：网格引导的3D高斯函数用于语义感知的对象变形|Mengtian Li, Yunshu Bai, Yimin Chu, Yijun Shen, Zhongmei Li, Weifeng Ge, Zhifeng Xie, Chaofeng Chen|<http://arxiv.org/pdf/2510.02034v1>|[代码](https://baiyunshu.github.io/GAUSSIANMORPHING.github.io); 提出了一种基于三维高斯分布和网格引导的形态变换方法，实现了无需标注数据的语义感知三维形状与纹理变换。|
|🆕 发布|kabr-tools: Automated Framework for Multi-Species Behavioral Monitoring|KABR工具：多物种行为监测自动化框架|Jenna Kline, Maksim Kholiavchenko, Samuel Stevens, Nina van Tiel, Alison Zhong, Namrata Banerji, Alec Sheets, Sowbaranika Balasubramaniam .etc.|<http://arxiv.org/pdf/2510.02030v1>|提出了一种开源自动化框架kabr-tools，利用无人机视频和机器学习技术实现多物种行为监测，提高了...|
|📝 更新|Temporal Overlapping Prediction: A Self-supervised Pre-training Method for LiDAR Moving Object Segmentation|时间重叠预测：一种用于激光雷达运动目标分割的自监督预训练方法|Ziliang Miao, Runjian Chen, Yixi Cai, Buwei He, Wenquan Zhao, Wenqi Shao, Bo Zhang, Fu Zhang|<http://arxiv.org/pdf/2503.07167v2>|提出了一种自监督预训练方法Temporal Overlapping Prediction，通过利用L...|
|📝 更新|PlaceIt3D: Language-Guided Object Placement in Real 3D Scenes|《PlaceIt3D：基于语言引导的实时三维场景中的物体放置》|Ahmed Abdelreheem, Filippo Aleotti, Jamie Watson, Zawar Qureshi, Abdelrahman Eldesokey, Peter Wonka, Gabriel Brostow, Sara Vicente .etc.|<http://arxiv.org/pdf/2505.05288v2>|提出语言引导的3D场景物体放置任务，并创建基准与数据集，实现首个有效基线方法。|
|📝 更新|Towards Methane Detection Onboard Satellites|面向卫星甲烷检测的研究|Maggie Chen, Hala Lambdouar, Luca Marini, Laura Martínez-Ferrer, Chris Bridges, Giacomo Acciarini|<http://arxiv.org/pdf/2509.00626v2>|[代码](https://github.com/spaceml-org/plume-hunter.); 提出了一种利用未校正卫星数据实现甲烷快速检测的机器学习方法，性能媲美传统校正方法。|
|📝 更新|Using KL-Divergence to Focus Frequency Information in Low-Light Image Enhancement|使用KL散度聚焦低光图像增强中的频率信息|Yan Xingyang, Huang Xiaohong, Zhang Zhao, You Tian, Xu Ziheng|<http://arxiv.org/pdf/2509.13083v2>|[代码](https://github.com/YanXY000/LLFDisc); 提出了一种基于KL散度的频率信息拟合方法，通过U型网络结构优化低光图像增强，实现了更好的结构保真度和...|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models|平衡匹配：隐式能量基模型的生成建模|Runqian Wang, Yilun Du|<http://arxiv.org/pdf/2510.02300v1>|引入了平衡匹配（EqM）生成模型框架，通过学习隐性能量景观的平衡梯度，优化了采样过程并提升了生成性能...|
|🆕 发布|NoiseShift: Resolution-Aware Noise Recalibration for Better Low-Resolution Image Generation|噪声转换：分辨率感知噪声重新校准以改善低分辨率图像生成|Ruozhen He, Moayed Haji-Ali, Ziyan Yang, Vicente Ordonez|<http://arxiv.org/pdf/2510.02307v1>|提出了一种无需训练的NoiseShift方法，通过调整去噪器的噪声水平以适应不同分辨率，显著提升了低...|
|🆕 发布|MultiModal Action Conditioned Video Generation|多模态动作条件视频生成|Yichen Li, Antonio Torralba|<http://arxiv.org/pdf/2510.02287v1>|引入多模态精细动作感知，提升了视频生成模型的实时精细控制能力。|
|🆕 发布|Learning to Generate Object Interactions with Physics-Guided Video Diffusion|学习生成基于物理引导的视频扩散中的对象交互|David Romero, Ariana Bermudez, Hao Li, Fabio Pizzati, Ivan Laptev|<http://arxiv.org/pdf/2510.02284v1>|提出了一种物理引导的视频生成方法KineMask，实现了更真实的物体交互和控制。|
|🆕 发布|Self-Forcing++: Towards Minute-Scale High-Quality Video Generation|自强化++：迈向分钟级高质量视频生成|Justin Cui, Jie Wu, Ming Li, Tao Yang, Xiaojie Li, Rui Wang, Andrew Bai, Yuanhao Ban .etc.|<http://arxiv.org/pdf/2510.02283v1>|提出了一种无需长视频教师指导或重训练的简化方法，通过自生成视频片段指导学生模型，实现了长达4分15秒...|
|🆕 发布|Paving the Way Towards Kinematic Assessment Using Monocular Video: A Preclinical Benchmark of State-of-the-Art Deep-Learning-Based 3D Human Pose Estimators Against Inertial Sensors in Daily Living Activities|面向运动学评估的单目视频研究之路：一种评估日常活动中最先进深度学习三维人体姿态估计器与惯性传感器性能的前临床基准|Mario Medrano-Paredes, Carmen Fernández-González, Francisco-Javier Díaz-Pernas, Hichem Saoudi, Javier González-Alonso, Mario Martínez-Zarzuela|<http://arxiv.org/pdf/2510.02264v1>|定位了单目视频在运动评估中的应用潜力，对比了深度学习模型与惯性传感器性能。|
|🆕 发布|DragFlow: Unleashing DiT Priors with Region Based Supervision for Drag Editing|DragFlow：利用基于区域的监督释放DiT先验进行拖动编辑|Zihan Zhou, Shilin Lu, Shuli Leng, Shaocong Zhang, Zhuming Lian, Xinlei Yu, Adams Wai-Kin Kong|<http://arxiv.org/pdf/2510.02253v1>|提出DragFlow框架，利用DiT的强大先验进行基于区域的拖动编辑，显著提升了图像编辑质量。|
|📝 更新|VITA: Vision-to-Action Flow Matching Policy|VITA：视觉到动作流匹配策略|Dechen Gao, Boqi Zhao, Andrew Lee, Ian Chuang, Hanchu Zhou, Hang Wang, Zhe Zhao, Junshan Zhang .etc.|<http://arxiv.org/pdf/2507.13231v2>|[代码](https://ucd-dare.github.io/VITA); 提出了一种无需噪声和条件机制的直接映射视觉表示到潜在动作的VITA框架，实现了更快的推理速度和优于现...|
|📝 更新|GenExam: A Multidisciplinary Text-to-Image Exam|《GenExam：一种多学科文本到图像考试系统》|Zhaokai Wang, Penghao Yin, Xiangyu Zhao, Changyao Tian, Yu Qiao, Wenhai Wang, Jifeng Dai, Gen Luo|<http://arxiv.org/pdf/2509.14232v2>|[代码](https://github.com/OpenGVLab/GenExam.); 提出GenExam基准，通过考试形式评估模型在理解和生成图像方面的综合能力。|
|📝 更新|Enhancing Corpus Callosum Segmentation in Fetal MRI via Pathology-Informed Domain Randomization|通过病理学指导的域随机化增强胎儿MRI中胼胝体分割|Marina Grifell i Plana, Vladyslav Zalevskyi, Léa Schmidt, Yvan Gomez, Thomas Sanchez, Vincent Dunet, Mériam Koob, Vanessa Siffredi .etc.|<http://arxiv.org/pdf/2508.20475v2>|提出了一种病理知识指导的合成数据生成策略，有效解决了胎儿脑部罕见疾病的数据稀缺问题，显著提升了分割准...|
|📝 更新|Causal-Adapter: Taming Text-to-Image Diffusion for Faithful Counterfactual Generation|因果适配器：驯服文本到图像扩散以实现忠实反事实生成|Lei Tong, Zhihua Liu, Chaochao Lu, Dino Oglic, Tom Diethe, Philip Teare, Sotirios A. Tsaftaris, Chen Jin|<http://arxiv.org/pdf/2509.24798v2>|提出Causal-Adapter框架，通过结构因果模型和属性正则化策略，实现了忠实且保留核心身份的图...|
|🆕 发布|Generating Findings for Jaw Cysts in Dental Panoramic Radiographs Using GPT-4o: Building a Two-Stage Self-Correction Loop with Structured Output (SLSO) Framework|使用GPT-4o生成牙全景X射线上颌囊肿检测结果：构建基于结构化输出（SLSO）框架的两阶段自校正循环|Nanaka Hosokawa, Ryo Takahashi, Tomoya Kitano, Yukihiro Iida, Chisako Muramatsu, Tatsuro Hayashi, Yuta Seino, Xiangrong Zhou .etc.|<http://arxiv.org/pdf/2510.02001v1>|利用GPT-4o多模态能力构建两阶段自校正循环框架，提升牙颌囊肿检测准确性。|
|📝 更新|How far can we go with ImageNet for Text-to-Image generation?|我们使用ImageNet进行文本到图像生成能走多远？|L. Degeorge, A. Ghosh, N. Dufour, D. Picard, V. Kalogeiton|<http://arxiv.org/pdf/2502.21318v3>|通过增强ImageNet数据集并使用精心设计的文本和图像增强，实现了与大规模网络抓取数据集训练的模型...|
|🆕 发布|ZK-WAGON: Imperceptible Watermark for Image Generation Models using ZK-SNARKs|ZK-WAGON：使用ZK-SNARKs对图像生成模型的无感知水印|Aadarsh Anantha Ramakrishnan, Shubham Agarwal, Selvanayagam S, Kunwar Singh|<http://arxiv.org/pdf/2510.01967v1>|提出了一种利用ZK-SNARKs为图像生成模型嵌入不可见水印的方法，确保了图像来源的可验证性而不暴露...|
|📝 更新|DreamOmni: Unified Image Generation and Editing|梦之全息：统一图像生成与编辑|Bin Xia, Yuechen Zhang, Jingyao Li, Chengyao Wang, Yitong Wang, Xinglong Wu, Bei Yu, Jiaya Jia|<http://arxiv.org/pdf/2412.17098v2>|DreamOmni统一了图像生成与编辑，通过合成数据管道提升编辑性能和质量。|
|📝 更新|SoftCFG: Uncertainty-guided Stable Guidance for Visual Autoregressive Model|软配置图：不确定性引导的视觉自回归模型稳定引导方法|Dongli Xu, Aleksei Tiulpin, Matthew B. Blaschko|<http://arxiv.org/pdf/2510.00996v2>|SoftCFG通过引入不确定性指导，解决了视觉自回归模型中的引导衰减和过引导问题，提高了图像生成质量...|
|🆕 发布|Pack and Force Your Memory: Long-form and Consistent Video Generation|“打包并强化你的记忆：长格式和一致性视频生成”|Xiaofei Wu, Guozhen Zhang, Zhiyong Xu, Yuan Zhou, Qinglin Lu, Xuming He|<http://arxiv.org/pdf/2510.01784v1>|提出MemoryPack和Direct Forcing方法，提高长视频生成的时序一致性和可靠性。|
|🆕 发布|Towards Photonic Band Diagram Generation with Transformer-Latent Diffusion Models|面向光子带图生成的Transformer-潜在扩散模型|Valentin Delchevalerie, Nicolas Roy, Arnaud Bougaham, Alexandre Mayer, Benoît Frénay, Michaël Lobet|<http://arxiv.org/pdf/2510.01749v1>|提出了一种基于Transformer和扩散模型的方法，用于高效生成任意三维结构的光子带图。|
|📝 更新|AniMaker: Multi-Agent Animated Storytelling with MCTS-Driven Clip Generation|《AniMaker：基于蒙特卡洛树搜索驱动的片段生成实现多智能体动画故事讲述》|Haoyuan Shi, Yunxin Li, Xinyu Chen, Longyue Wang, Baotian Hu, Min Zhang|<http://arxiv.org/pdf/2506.10540v2>|提出了一种多智能体协同的动画制作框架AniMaker，通过MCTS-Gen和AniEval技术实现了...|
|🆕 发布|VLA-R1: Enhancing Reasoning in Vision-Language-Action Models|VLA-R1：提升视觉-语言-动作模型中的推理能力|Angen Ye, Zeyu Zhang, Boyuan Wang, Xiaofeng Wang, Dapeng Zhang, Zheng Zhu|<http://arxiv.org/pdf/2510.01623v1>|[代码](https://github.com/GigaAI-research/VLA-R1.); 提出了一种增强推理能力的Vision-Language-Action模型VLA-R1，通过结合可验证...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Continual Personalization for Diffusion Models|持续个性化扩散模型|Yu-Chien Liao, Jr-Jen Chen, Chi-Pin Huang, Ci-Siang Lin, Meng-Lin Wu, Yu-Chiang Frank Wang|<http://arxiv.org/pdf/2510.02296v1>|提出了一种概念神经元选择策略，实现了扩散模型的持续个性化，有效解决了灾难性遗忘问题并保持了零样本生成...|
|🆕 发布|Optimal Control Meets Flow Matching: A Principled Route to Multi-Subject Fidelity|最优控制遇见流匹配：一种原则性的多主体保真度路径|Eric Tillmann Bill, Enis Simsar, Thomas Hofmann|<http://arxiv.org/pdf/2510.02315v1>|提出了一种基于最优控制和流匹配的理论框架，有效解决了多主体描述中的属性泄露和身份纠缠问题。|
|🆕 发布|Test-Time Anchoring for Discrete Diffusion Posterior Sampling|测试时锚定用于离散扩散后验采样|Litu Rout, Andreas Lugmayr, Yasamin Jafarian, Srivatsan Varadharajan, Constantine Caramanis, Sanjay Shakkottai, Ira Kemelmacher-Shlizerman|<http://arxiv.org/pdf/2510.02291v1>|提出了一种基于量化期望和锚定重采样的后验采样方法，有效克服了离散扩散模型后验采样中的挑战，实现了无需...|
|🆕 发布|TempoControl: Temporal Attention Guidance for Text-to-Video Models|时间控制：文本到视频模型中的时间注意力引导|Shira Schiber, Ofir Lindenbaum, Idan Schwartz|<http://arxiv.org/pdf/2510.02226v1>|超文本摘要一句话总结：TempoControl通过优化注意力机制，实现了对文本到视频生成中视觉元素时...|
|🆕 发布|Measurement-Guided Consistency Model Sampling for Inverse Problems|测量引导的一致性模型采样方法在逆问题中的应用|Amirreza Tanevardi, Pooria Abbas Rad Moghadam, Sajjad Amini|<http://arxiv.org/pdf/2510.02208v1>|本文提出了一种针对逆问题重建的测量引导一致性模型采样方法，通过测量一致性机制提高了生成效率和图像质量...|
|📝 更新|One-Step Residual Shifting Diffusion for Image Super-Resolution via Distillation|一步残差移位扩散通过蒸馏实现图像超分辨率|Daniil Selikhanovych, David Li, Aleksei Leonov, Nikita Gushchin, Sergei Kushneriuk, Alexander Filippov, Evgeny Burnaev, Iaroslav Koshelev .etc.|<http://arxiv.org/pdf/2503.13358v3>|提出了一种基于蒸馏的单步残差位移扩散方法，有效提升了超分辨率图像质量且降低了计算成本。|
|📝 更新|DiCache: Let Diffusion Model Determine Its Own Cache|DiCache：让扩散模型自行确定其缓存|Jiazi Bu, Pengyang Ling, Yujie Zhou, Yibin Wang, Yuhang Zang, Dahua Lin, Jiaqi Wang|<http://arxiv.org/pdf/2508.17356v2>|提出自适应缓存策略DiCache，通过实时监测调整缓存时机与方式，提升扩散模型运行效率与视觉质量。|
|🆕 发布|Mapping Historic Urban Footprints in France: Balancing Quality, Scalability and AI Techniques|法国历史城市足迹映射：平衡质量、可扩展性与人工智能技术|Walid Rabehi, Marion Le Texier, Rémi Lemoy|<http://arxiv.org/pdf/2510.02097v1>|利用双通道U-Net处理历史地图，创建首个法国全国范围的城市足迹数据集。|
|🆕 发布|Zero-shot Human Pose Estimation using Diffusion-based Inverse solvers|基于扩散逆向求解器的零样本人体姿态估计|Sahil Bhandary Karnoor, Romit Roy Choudhury|<http://arxiv.org/pdf/2510.02043v1>|提出了一种基于扩散模型逆解的零样本人体姿态估计方法，实现了不同用户间的通用性。|
|🆕 发布|LiLa-Net: Lightweight Latent LiDAR Autoencoder for 3D Point Cloud Reconstruction|LiLa-Net：轻量级潜在激光雷达自动编码器用于三维点云重建|Mario Resino, Borja Pérez, Jaime Godoy, Abdulla Al-Kaff, Fernando García|<http://arxiv.org/pdf/2510.02028v1>|提出了一种轻量级3D点云重建方法LiLa-Net，通过优化编码器结构和简化跳连，实现了高效的特征提取...|
|🆕 发布|$\text{G}^2$RPO: Granular GRPO for Precise Reward in Flow Models|$\text{G}^2$RPO：用于流模型精确奖励的细粒度GRPO|Yujie Zhou, Pengyang Ling, Jiazi Bu, Yibin Wang, Yuhang Zang, Jiaqi Wang, Li Niu, Guangtao Zhai|<http://arxiv.org/pdf/2510.01982v1>|提出了一种精确奖励评估的$\text{G}^2$RPO框架，通过细分探索和聚合多尺度优势，提高了流模...|
|📝 更新|Feature Representation Transferring to Lightweight Models via Perception Coherence|通过感知一致性将特征表示转移到轻量级模型中|Hai-Vy Nguyen, Fabrice Gamboa, Sixin Zhang, Reda Chhaibi, Serge Gratton, Thierry Giaccone|<http://arxiv.org/pdf/2505.06595v2>|提出了一种通过感知一致性将特征表示从大型教师模型转移到轻量级学生模型的方法。|
|📝 更新|There and Back Again: On the relation between Noise and Image Inversions in Diffusion Models|《往返之旅：论噪声与扩散模型中图像逆操作的关系》|Łukasz Staniszewski, Łukasz Kuciński, Kamil Deja|<http://arxiv.org/pdf/2410.23530v4>|[代码](https://github.com/luk-st/taba.); 揭示了扩散模型中噪声与图像逆向转换的关系，并提出改进方法以增强编辑和插值质量。|
|📝 更新|VRWKV-Editor: Reducing quadratic complexity in transformer-based video editing|VRWKV-编辑器：降低基于变压器的视频编辑中的二次复杂度|Abdelilah Aitrouga, Youssef Hmamouche, Amal El Fallah Seghrouchni|<http://arxiv.org/pdf/2509.25998v2>|提出VRWKV-Editor模型，通过线性时空聚合模块降低视频编辑的计算复杂度，实现更快的处理速度和...|
|🆕 发布|Flow-Matching Guided Deep Unfolding for Hyperspectral Image Reconstruction|基于流匹配引导的深度展开用于高光谱图像重建|Yi Ai, Yuanhao Cai, Yulun Zhang, Xiaokang Yang|<http://arxiv.org/pdf/2510.01912v1>|[代码](https://github.com/YiAi03/FMU.); 首次将流匹配与深度展开框架结合，用于高光谱图像重建，提高了重构质量。|
|📝 更新|Concept Unlearning by Modeling Key Steps of Diffusion Process|通过建模扩散过程的关键步骤实现概念遗忘|Chaoshuo Zhang, Chenhao Lin, Zhengyu Zhao, Le Yang, Qian Wang, Chao Shen|<http://arxiv.org/pdf/2507.06526v3>|提出Key Step Concept Unlearning方法，通过选择性优化关键步骤，有效提高概念...|
|📝 更新|SCoT: Unifying Consistency Models and Rectified Flows via Straight-Consistent Trajectories|统一一致性模型和修正流通过直连一致性轨迹的SCoT方法|Zhangkai Wu, Xuhui Fan, Hongyu Wu, Longbing Cao|<http://arxiv.org/pdf/2502.16972v4>|提出SCoT模型，结合一致性模型和矫正流方法，实现快速且准确的数据采样。|
|🆕 发布|Leveraging Prior Knowledge of Diffusion Model for Person Search|利用扩散模型先验知识进行行人搜索|Giyeol Kim, Sooyoung Yang, Jihyong Oh, Myungjoo Kang, Chanho Eom|<http://arxiv.org/pdf/2510.01841v1>|利用预训练扩散模型消除任务间优化冲突，提出DiffPS框架提升人物搜索性能。|
|📝 更新|DiffCut: Catalyzing Zero-Shot Semantic Segmentation with Diffusion Features and Recursive Normalized Cut|DiffCut：利用扩散特征和递归归一化切割促进零样本语义分割|Paul Couairon, Mustafa Shukor, Jean-Emmanuel Haugeard, Matthieu Cord, Nicolas Thome|<http://arxiv.org/pdf/2406.02842v4>|提出DiffCut方法，利用扩散特征和递归归一化切割算法实现无监督零样本语义分割，显著超越现有技术水...|
|📝 更新|RIFLE: Removal of Image Flicker-Banding via Latent Diffusion Enhancement|RIFLE：通过潜在扩散增强去除图像闪烁-色带|Libo Zhu, Zihan Zhou, Xiaoyang Liu, Weihang Zhang, Keyu Shi, Yifan Fu, Yulun Zhang|<http://arxiv.org/pdf/2509.24644v3>|提出了一种基于扩散框架的图像频闪带消除方法RIFLE，有效去除屏幕图像中的频闪带问题。|
|🆕 发布|UniVerse: Unleashing the Scene Prior of Video Diffusion Models for Robust Radiance Field Reconstruction|《UniVerse：释放视频扩散模型场景先验以实现稳健的辐射场重建》|Jin Cao, Hongrui Wu, Ziyong Feng, Hujun Bao, Xiaowei Zhou, Sida Peng|<http://arxiv.org/pdf/2510.01669v1>|[代码](https://jin-cao-tma.github.io/UniVerse.github.io); 提出了一种基于视频扩散模型的统一框架UniVerse，将不一致的多视角图像分解为视频，再恢复为一致图...|
|📝 更新|Diffusion Model as a Noise-Aware Latent Reward Model for Step-Level Preference Optimization|扩散模型作为噪声感知的潜在奖励模型用于步级偏好优化|Tao Zhang, Cheng Da, Kun Ding, Huan Yang, Kun Jin, Yan Li, Tingting Gao, Di Zhang .etc.|<http://arxiv.org/pdf/2502.01051v5>|[代码](https://github.com/Kwai-Kolors/LPO.); 提出利用预训练的扩散模型直接在噪声潜伏空间进行偏好优化，大幅提升效率与偏好匹配度。|
|🆕 发布|NPN: Non-Linear Projections of the Null-Space for Imaging Inverse Problems|NPN：用于成像逆问题的零空间非线性投影|Roman Jacome, Romario Gualdrón-Hurtado, Leon Suarez, Henry Arguello|<http://arxiv.org/pdf/2510.01608v1>|提出了一种基于神经网络的新型正则化方法NPN，通过在感知矩阵的零空间中寻找低维投影来改善成像逆问题的...|
|📝 更新|How Can Time Series Analysis Benefit From Multiple Modalities? A Survey and Outlook|时间序列分析如何从多模态中受益？综述与展望|Haoxin Liu, Harshavardhan Kamarthi, Zhiyuan Zhao, Shangqing Xu, Shiyu Wang, Qingsong Wen, Tom Hartvigsen, Fei Wang .etc.|<http://arxiv.org/pdf/2503.11835v4>|系统综述了多模态如何增强时间序列分析，包括模型复用、多模态扩展和跨模态交互。|
|🆕 发布|Towards Better Optimization For Listwise Preference in Diffusion Models|面向在扩散模型中列表偏好优化的改进|Jiamu Bai, Xin Yu, Meilong Xu, Weitao Lu, Xin Pan, Kiwan Maeng, Daniel Kifer, Jian Wang .etc.|<http://arxiv.org/pdf/2510.01540v1>|提出了一种优化扩散模型列表偏好排序的新框架Diffusion-LPO，提升了图像生成和编辑任务中的视...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|The Unreasonable Effectiveness of Scaling Agents for Computer Use|《计算机使用中缩放代理的异常有效性》|Gonzalo Gonzalez-Pumariega, Vincent Tu, Chih-Lun Lee, Jiachen Yang, Ang Li, Xin Eric Wang|<http://arxiv.org/pdf/2510.02250v1>|提出 Behavior Best-of-N 方法，通过多轨迹生成和选择，显著提升计算机使用代理的稳健...|
|📝 更新|Segmentor-Guided Counterfactual Fine-Tuning for Locally Coherent and Targeted Image Synthesis|“基于分割引导的反事实微调方法，用于局部一致性和目标导向的图像合成”|Tian Xia, Matthew Sinclair, Andreas Schuh, Fabio De Sousa Ribeiro, Raghav Mehta, Rajat Rasal, Esther Puyol-Antón, Samuel Gerber .etc.|<http://arxiv.org/pdf/2509.24913v2>|[代码](https://github.com/biomedia-mira/seg-cft.); 提出了一种Segmentor-Guided Counterfactual Fine-Tuning方法...|
|🆕 发布|DisCo-Layout: Disentangling and Coordinating Semantic and Physical Refinement in a Multi-Agent Framework for 3D Indoor Layout Synthesis|解耦与协同语义与物理细化：面向三维室内布局合成的多智能体框架|Jialin Gao, Donghao Zhou, Mingjian Liang, Lihao Liu, Chi-Wing Fu, Xiaowei Hu, Pheng-Ann Heng|<http://arxiv.org/pdf/2510.02178v1>|提出DisCo-Layout框架，通过分离和协调物理与语义细化，生成真实且通用的3D室内布局。|
|🆕 发布|Unlocking Vision-Language Models for Video Anomaly Detection via Fine-Grained Prompting|通过细粒度提示解锁视觉-语言模型以进行视频异常检测|Shu Zou, Xinyu Tian, Lukas Wesemann, Fabian Waschkowski, Zhaoyuan Yang, Jing Zhang|<http://arxiv.org/pdf/2510.02155v1>|提出细粒度提示框架 ASK-Hint，通过动作知识引导，提升视频异常检测准确性和解释性。|
|📝 更新|Momentum-SAM: Sharpness Aware Minimization without Computational Overhead|动量-SAM：无需计算开销的锐度感知最小化|Marlon Becker, Frederick Altrock, Benjamin Risse|<http://arxiv.org/pdf/2401.12033v3>|[代码](https://github.com/MarlonBecker/MSAM.); 提出Momentum-SAM优化算法，通过利用动量向量减少计算负担同时保持SAM的低尖锐度优势。|
|📝 更新|Normal-Abnormal Guided Generalist Anomaly Detection|正常-异常引导的全能异常检测|Yuexin Wang, Xiaolei Wang, Yizheng Gong, Jimin Xiao|<http://arxiv.org/pdf/2510.00495v2>|[代码](https://github.com/JasonKyng/NAGL.); 提出利用正常和异常样本共同指导的通用异常检测方法，通过残差挖掘和特征学习显著提升跨域异常检测准确性。|
|🆕 发布|FreeViS: Training-free Video Stylization with Inconsistent References|无需训练的视频风格化：带有不一致参考的FreeViS方法|Jiacong Xu, Yiqun Mei, Ke Zhang, Vishal M. Patel|<http://arxiv.org/pdf/2510.01686v1>|[代码](https://xujiacong.github.io/FreeViS); 提出了一种无需训练的视频风格化框架FreeViS，通过整合多个风格化参考，实现了丰富的风格细节和强烈...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Uncovering Semantic Selectivity of Latent Groups in Higher Visual Cortex with Mutual Information-Guided Diffusion|利用互信息引导扩散揭示高视觉皮层中潜在群体的语义选择性|Yule Wang, Joseph Yu, Chengrui Li, Weihan Li, Anqi Wu|<http://arxiv.org/pdf/2510.02182v1>|提出MIG-Vis方法，利用扩散模型揭示高视觉皮层中神经潜伏子空间的视觉语义特征组织结构。|
|📝 更新|VideoGen-of-Thought: Step-by-step generating multi-shot video with minimal manual intervention|《VideoGen-of-Thought：最小人工干预下逐步生成多镜头视频》|Mingzhe Zheng, Yongqi Xu, Haojian Huang, Xuran Ma, Yexin Liu, Wenjie Shu, Yatian Pang, Feilong Tang .etc.|<http://arxiv.org/pdf/2412.02259v3>|VideoGen-of-Thought通过动态故事线建模和身份感知跨镜头传播，实现了从单句描述自动生...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|StealthAttack: Robust 3D Gaussian Splatting Poisoning via Density-Guided Illusions|隐攻击：基于密度引导错觉的鲁棒三维高斯散点污染|Bo-Hsu Ke, You-Zhe Xie, Yu-Lun Liu, Wei-Chen Chiu|<http://arxiv.org/pdf/2510.02314v1>|[代码](https://hentci.github.io/stealthattack); 提出了一种针对3D场景表示方法的密度引导式攻击策略，通过在低密度区域注入噪声点增强攻击效果。|
|📝 更新|NeRAF: 3D Scene Infused Neural Radiance and Acoustic Fields|神经辐射与声场融合的三维场景NeRAF|Amandine Brunetto, Sascha Hornauer, Fabien Moutarde|<http://arxiv.org/pdf/2405.18213v4>|NeRAF通过结合视觉与声学信息，实现了高质量音频与视觉场景的同步生成。|
|📝 更新|GEM: 3D Gaussian Splatting for Efficient and Accurate Cryo-EM Reconstruction|GEM: 用于高效和精确冷冻电镜重建的三维高斯散点绘制方法|Huaizhi Qu, Xiao Wang, Gengwei Zhang, Jie Peng, Tianlong Chen|<http://arxiv.org/pdf/2509.25075v2>|[代码](https://github.com/UNITES-Lab/GEM.); 提出GEM框架，通过3D高斯散点技术实现高效的冷冻电镜三维重构，提升分辨率同时降低计算和存储成本。|
|📝 更新|Fusing Foveal Fixations Using Linear Retinal Transformations and Bayesian Experimental Design|利用线性视网膜变换和贝叶斯实验设计融合中央凹注视点|Christopher K. I. Williams|<http://arxiv.org/pdf/2505.01249v2>|提出了一种线性视网膜变换和贝叶斯实验设计融合人眼注视的方法，有效整合场景多注视点信息。|
|📝 更新|LiDAR-HMR: 3D Human Mesh Recovery from LiDAR|从LiDAR数据中恢复三维人体网格的LiDAR-HMR方法|Bohao Fan, Wenzhao Zheng, Jianjiang Feng, Jie Zhou|<http://arxiv.org/pdf/2311.11971v2>|[代码](https://github.com/soullessrobot/LiDAR-HMR); 首次提出从稀疏LiDAR点云中恢复3D人体网格的方法，通过级联图变换器优化重建效果。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Interior Object Geometry via Fitted Frames|通过拟合框架获取室内物体几何结构|Stephen M. Pizer, Zhiyuan Liu, Junjie Zhao, Nicholas Tapp-Hughes, James Damon, Miaomiao Zhang, JS Marron, Mohsen Taheri .etc.|<http://arxiv.org/pdf/2407.14357v3>|提出了一种基于拟合框架的内部对象几何建模方法，实现了对象间强局部对应，显著提升了分类性能。|
|🆕 发布|LOBE-GS: Load-Balanced and Efficient 3D Gaussian Splatting for Large-Scale Scene Reconstruction|LOBE-GS：负载均衡与高效三维高斯散点绘制用于大规模场景重建|Sheng-Hsiang Hung, Ting-Yu Yen, Wei-Fang Sun, Simon See, Shih-Hsuan Hung, Hung-Kuo Chu|<http://arxiv.org/pdf/2510.01767v1>|提出了一种负载均衡的高效3D高斯散布框架，大幅缩短预处理时间并提升大规模场景重建效率。|
|🆕 发布|Joint Deblurring and 3D Reconstruction for Macrophotography|联合去模糊与三维重建在微距摄影中的应用|Yifan Zhao, Liangchen Li, Yuqi Zhou, Kai Wang, Yan Liang, Juyong Zhang|<http://arxiv.org/pdf/2510.01640v1>|提出了一种联合去模糊与三维重建的方法，有效解决了宏观摄影中的模糊问题并实现了高质量的三维模型恢复。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|NeoARCADE: Robust Calibration for Distance Estimation to Support Assistive Drones for the Visually Impaired|NeoARCADE：面向视障人士辅助无人机的距离估计稳健标定方法|Suman Raj, Bhavani A Madhabhavi, Madhav Kumar, Prabhav Gupta, Yogesh Simmhan|<http://arxiv.org/pdf/2504.01988v2>|提出了一种用于辅助视障人士导航的无人机距离估计的稳健校准方法，实现了高精度距离预测。|
|🆕 发布|Patch-as-Decodable-Token: Towards Unified Multi-Modal Vision Tasks in MLLMs|"Patch-as-Decodable-Token：面向多模态视觉任务的大规模语言模型统一框架"|Yongyi Su, Haojie Zhang, Shijie Li, Nanqing Liu, Jingyi Liao, Junyi Pan, Yuan Liu, Xiaofen Xing .etc.|<http://arxiv.org/pdf/2510.01954v1>|[代码](https://github.com/Gorilla-Lab-SCUT/PaDT.); 提出Patch-as-Decodable Token方法，使大型多模态语言模型能直接生成文本和视觉输...|
|🆕 发布|Non-Rigid Structure-from-Motion via Differential Geometry with Recoverable Conformal Scale|通过微分几何与可恢复共形尺度进行非刚性结构从运动恢复|Yongbo Chen, Yanhao Zhang, Shaifali Parashar, Liang Zhao, Shoudong Huang|<http://arxiv.org/pdf/2510.01665v1>|提出了一种新的非刚性结构从运动恢复方法，通过优化图像扭曲准确计算局部符合尺度，提高了重建精度和鲁棒性...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VideoNSA: Native Sparse Attention Scales Video Understanding|视频NSA：原生稀疏注意力尺度提升视频理解|Enxin Song, Wenhao Chai, Shusheng Yang, Ethan Armand, Xiaojun Shan, Haiyang Xu, Jianwen Xie, Zhuowen Tu|<http://arxiv.org/pdf/2510.02295v1>|通过引入原生稀疏注意力机制，VideoNSA提升了视频理解的性能并优化了长时序连贯性。|
|🆕 发布|VidGuard-R1: AI-Generated Video Detection and Explanation via Reasoning MLLMs and RL|VidGuard-R1：通过推理大规模语言模型和强化学习生成视频检测与解释|Kyoungjun Park, Yifan Yang, Juheon Yi, Shicheng Zheng, Yifei Shen, Dongqi Han, Caihua Shan, Muhammad Muaz .etc.|<http://arxiv.org/pdf/2510.02282v1>|VidGuard-R1通过优化多模态大语言模型，实现了对AI生成视频的高效检测和可解释性判断。|
|🆕 发布|From Frames to Clips: Efficient Key Clip Selection for Long-Form Video Understanding|从帧到剪辑：长视频理解中的高效关键剪辑选择|Guangyu Sun, Archit Singhal, Burak Uzkent, Mubarak Shah, Chen Chen, Garin Kessler|<http://arxiv.org/pdf/2510.02262v1>|提出了一种基于关键视频片段选择的方法，有效提升了长视频理解的时序连贯性和性能。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Clink! Chop! Thud! -- Learning Object Sounds from Real-World Interactions|“咔哒！咔嚓！砰！——从现实世界交互中学习物体声音”|Mengyu Yang, Yiming Chen, Haozheng Pei, Siddhant Agarwal, Arun Balajee Vasudevan, James Hays|<http://arxiv.org/pdf/2510.02313v1>|提出了一种多模态对象感知框架，通过分析日常互动视频中的声音与物体关系，实现了对声音与物体直接关联的检...|
|🆕 发布|When Tracking Fails: Analyzing Failure Modes of SAM2 for Point-Based Tracking in Surgical Videos|当跟踪失败时：分析SAM2在手术视频点跟踪中的失败模式|Woowon Jang, Jiwon Im, Juseung Choi, Niki Rashidian, Wesley De Neve, Utku Ozbulak|<http://arxiv.org/pdf/2510.02100v1>|分析了点追踪在手术视频中的失败模式，并提出了改进追踪点选择与放置的建议。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MMDEW: Multipurpose Multiclass Density Estimation in the Wild|多用途多类密度估计野外方法：MMDEW|Villanelle O'Reilly, Jonathan Cox, Georgios Leontidis, Marc Hanheide, Petra Bosilj, James Brown|<http://arxiv.org/pdf/2510.02213v1>|提出了一种多类密度估计框架，通过双金字塔视觉变换器和多尺度解码方法，显著提升了密集场景中的目标计数准...|
|🆕 发布|PyramidStyler: Transformer-Based Neural Style Transfer with Pyramidal Positional Encoding and Reinforcement Learning|金字塔风格化：基于变换器和金字塔位置编码的神经风格迁移与强化学习|Raahul Krishna Durairaju, K. Saruladha|<http://arxiv.org/pdf/2510.01715v1>|提出PyramidStyler，通过金字塔位置编码和强化学习优化神经风格迁移，实现高效高质艺术图像合...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|What Makes a Good Dataset for Knowledge Distillation?|什么构成了知识蒸馏的良好数据集？|Logan Frank, Jim Davis|<http://arxiv.org/pdf/2411.12817v2>|[代码](https://github.com/osu-cvl/good-kd-dataset.); 探究并提出了评估适用于知识蒸馏的优秀数据集的标准。|
|🆕 发布|Pure-Pass: Fine-Grained, Adaptive Masking for Dynamic Token-Mixing Routing in Lightweight Image Super-Resolution|"纯传递：轻量级图像超分辨率中动态令牌混合路由的细粒度自适应掩码"|Junyu Wu, Jie Tang, Jie Liu, Gangshan Wu|<http://arxiv.org/pdf/2510.01997v1>|提出Pure-Pass方法，通过像素级精细掩码提高图像超分辨率性能，减少计算负担。|
|🆕 发布|4DGS-Craft: Consistent and Interactive 4D Gaussian Splatting Editing|4DGS-Craft：一致性与交互式4D高斯散点编辑|Lei Liu, Can Wang, Zhenghao Chen, Dong Xu|<http://arxiv.org/pdf/2510.01991v1>|提出4DGS-Craft框架，通过4D感知模型和多视图一致性优化，实现了4D场景编辑的一致性和交互性...|
|📝 更新|A Survey on Dynamic Neural Networks: from Computer Vision to Multi-modal Sensor Fusion|动态神经网络综述：从计算机视觉到多模态传感器融合|Fabio Montello, Ronja Güldenring, Simone Scardapane, Lazaros Nalpantidis|<http://arxiv.org/pdf/2501.07451v2>|[代码](https://github.com/DTU-PAS/awesome-dynn-for-cv); 概述了动态神经网络在计算机视觉和传感器融合中的应用，提出了一种基于输入复杂性的计算自适应方法。|
|🆕 发布|Discrete Facial Encoding: : A Framework for Data-driven Facial Display Discovery|离散面部编码：数据驱动面部显示发现的框架|Minh Tran, Maksim Siniukov, Zhangyu Jin, Mohammad Soleymani|<http://arxiv.org/pdf/2510.01662v1>|提出了一种无监督的数据驱动方法Discrete Facial Encoding，通过学习3D面部网格...|
|🆕 发布|Automated Genomic Interpretation via Concept Bottleneck Models for Medical Robotics|通过概念瓶颈模型实现医疗机器人自动化基因组解读|Zijun Li, Jinchang Zhang, Ming Zhang, Guoyu Lu|<http://arxiv.org/pdf/2510.01618v1>|提出了一种结合概念瓶颈模型的自动化基因组解读模块，实现了高准确度的分类和可解释的决策支持，优化了医疗...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Cross-Breed Pig Identification Using Auricular Vein Pattern Recognition: A Machine Learning Approach for Small-Scale Farming Applications|利用耳静脉模式识别的跨品种猪只识别：面向小规模农场应用的机器学习方法|Emmanuel Nsengiyumvaa, Leonard Niyitegekaa, Eric Umuhoza|<http://arxiv.org/pdf/2510.02197v1>|提出了一种利用猪耳静脉模式进行非侵入式生物识别的方法，提高了小规模农场动物识别的准确性和成本效益。|
|📝 更新|More Thought, Less Accuracy? On the Dual Nature of Reasoning in Vision-Language Models|“更多思考，更少准确性？论视觉语言模型推理的双重性质”|Xinyu Tian, Shu Zou, Zhaoyuan Yang, Mengqi He, Fabian Waschkowski, Lukas Wesemann, Peter Tu, Jing Zhang|<http://arxiv.org/pdf/2509.25848v2>|[代码](https://xytian1008.github.io/VAPO); 揭示了视觉语言模型推理过程中的双重性，并提出了视觉锚定策略优化方法，有效平衡推理与感知。|
|🆕 发布|Holistic Order Prediction in Natural Scenes|自然场景中的整体顺序预测|Pierre Musacchio, Hyunmin Lee, Jaesik Park|<http://arxiv.org/pdf/2510.01704v1>|[代码](https://github.com/SNU-VGILab/InstaOrder.); 提出InstaFormer网络，通过单次前向传播直接预测自然场景中所有实例的完整遮挡和深度顺序。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Subspace Node Pruning|子空间节点剪枝|Joshua Offergeld, Marcel van Gerven, Nasir Ahmad|<http://arxiv.org/pdf/2405.17506v3>|提出了一种通过正交子空间投影和节点剪枝优化神经网络推理效率的方法，实现了性能保持下的计算成本显著降低...|
|📝 更新|An Improved Pure Fully Connected Neural Network for Rice Grain Classification|一种改进的纯全连接神经网络用于稻谷分类|Wanke Xia, Bo Lv, Xunwen Xiang, Ruoxin Peng, Haoqi Chu, Xinlei Zhu, Zhiyu Yang, Lili Yang|<http://arxiv.org/pdf/2503.03111v3>|提出两阶段训练和图像位置校正方法，显著提升纯全连接神经网络对相似稻谷的分类准确率。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Post-hoc Probabilistic Vision-Language Models|后验概率视觉-语言模型|Anton Baumann, Rui Li, Marcus Klasson, Santeri Mentu, Shyamgopal Karthik, Zeynep Akata, Arno Solin, Martin Trapp|<http://arxiv.org/pdf/2412.06014v4>|提出后处理方法为视觉语言模型引入不确定性估计，无需额外训练，提升预测准确性和主动学习效率。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Accelerating Targeted Hard-Label Adversarial Attacks in Low-Query Black-Box Settings|在低查询黑盒设置中加速目标硬标签对抗性攻击|Arjhun Swaminathan, Mete Akgün|<http://arxiv.org/pdf/2505.16313v2>|提出了一种利用目标图像边缘信息的攻击方法TEA，在低查询量的黑盒设置中显著提高了针对性攻击的效率。|
|🆕 发布|LadderMoE: Ladder-Side Mixture of Experts Adapters for Bronze Inscription Recognition|《LadderMoE：面向青铜器铭文识别的梯形侧边混合专家适配器》|Rixin Zhou, Peiqiang Qiu, Qian Zhang, Chuntao Li, Xi Yang|<http://arxiv.org/pdf/2510.01651v1>|提出了一种针对青铜铭文识别的LadderMoE方法，通过动态专家专长和强鲁棒性，有效应对视觉退化和类...|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Uncovering Overconfident Failures in CXR Models via Augmentation-Sensitivity Risk Scoring|通过增强敏感性风险评估揭示CXR模型中的过度自信失败|Han-Jay Shu, Wei-Ning Chiu, Shun-Ting Chang, Meng-Ping Huang, Takeshi Tohyama, Ahram Han, Po-Chih Kuo|<http://arxiv.org/pdf/2510.01683v1>|提出了一种基于图像增广的评估框架，有效识别出医学影像模型中的潜在错误案例，提高医疗AI的公平性和安全...|
|🆕 发布|Robust Classification of Oral Cancer with Limited Training Data|有限训练数据下的口腔癌鲁棒分类|Akshay Bhagwan Sonawane, Lena D. Swamikannan, Lakshman Tamil|<http://arxiv.org/pdf/2510.01547v1>|提出了一种结合卷积神经网络与贝叶斯深度学习的方法，在数据有限的情况下提高了口腔癌分类的可靠性和泛化能...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|The Reasoning Boundary Paradox: How Reinforcement Learning Constrains Language Models|《推理边界悖论：强化学习如何约束语言模型》|Phuc Minh Nguyen, Chinh D. La, Duy M. H. Nguyen, Nitesh V. Chawla, Binh T. Nguyen, Khoa D. Doan|<http://arxiv.org/pdf/2510.02230v1>|[代码](https://github.com/mail-research/SELF-llm-interference.); 揭示了强化学习在提升语言模型推理能力中的边界限制问题，并提出了一种聚焦低概率问题的数据筛选算法以改善...|
|📝 更新|Learning to Weight Parameters for Training Data Attribution|学习为训练数据归因加权参数|Shuangqi Li, Hieu Le, Jingyi Xu, Mathieu Salzmann|<http://arxiv.org/pdf/2506.05647v2>|提出了一种学习参数重要性权重的方法，无需标注数据即可准确识别影响模型输出的关键训练样本。|
|📝 更新|Multiple Queries with Multiple Keys: A Precise Prompt Matching Paradigm for Prompt-based Continual Learning|多查询与多键：基于提示的持续学习中的精确提示匹配范式|Dunwei Tu, Huiyu Yi, Yuchi Wang, Baile Xu, Jian Zhao, Furao Shen|<http://arxiv.org/pdf/2501.12635v3>|[代码](https://github.com/DunweiTu/MQMK.); 提出MQMK精确提示匹配范式，通过多查询和多键策略提升持续学习中的提示选择准确度。|
|📝 更新|Equivariant Splitting: Self-supervised learning from incomplete data|等变分割：从不完整数据中进行自监督学习|Victor Sechaud, Jérémy Scanvic, Quentin Barthélemy, Patrice Abry, Julián Tachella|<http://arxiv.org/pdf/2510.00929v2>|提出了一种新的自监督学习方法，通过结合等变性和自监督分割损失，实现了在不完整数据下的高质量重建。|
|📝 更新|LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios|长尾半监督学习在开放世界场景中的参数高效微调：LoFT|Zhiyuan Huang, Jiahao Chen, Yurou Liu, Bing Su|<http://arxiv.org/pdf/2509.09926v3>|提出LoFT框架，通过参数高效微调预训练模型，有效解决长尾分布下的半监督学习问题。|
|📝 更新|Patch-Level Kernel Alignment for Dense Self-Supervised Learning|patch-Level 核对齐用于密集自监督学习|Juan Yeo, Ijun Jang, Taesup Kim|<http://arxiv.org/pdf/2509.05606v2>|提出了一种非参数的Patch-level Kernel Alignment方法，通过轻量级后训练显著...|
|📝 更新|What are You Looking at? Modality Contribution in Multimodal Medical Deep Learning|你在看什么？多模态医学深度学习中的模态贡献|Christian Gapp, Elias Tappeiner, Martin Welk, Karl Fritscher, Elke Ruth Gizewski, Rainer Schubert|<http://arxiv.org/pdf/2503.01904v2>|[代码](https://github.com/ChristianGappGit/MC_MMD.); 提出了一种评估多模态医学深度学习模型中各模态贡献的方法，增强了模型可解释性和数据集平衡性。|
|🆕 发布|MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust Physics-Based Dynamics|MPMAvatar：学习具有精确且鲁棒物理基础动力学的三维高斯虚拟形象|Changmin Lee, Jihyun Lee, Tae-Kyun Kim|<http://arxiv.org/pdf/2510.01619v1>|[代码](https://KAISTChangmin.github.io/MPMAvatar); 提出MPMAvatar框架，通过物理模拟和3D Gaussian Splatting实现高保真3D人...|
|🆕 发布|MATCH: Multi-faceted Adaptive Topo-Consistency for Semi-Supervised Histopathology Segmentation|MATCH：多方面自适应拓扑一致性用于半监督组织病理学分割|Meilong Xu, Xiaoling Hu, Shahira Abousamra, Chen Li, Chao Chen|<http://arxiv.org/pdf/2510.01532v1>|[代码](https://github.com/Melon-Xu/MATCH); 提出了一种多方面自适应拓扑一致性策略，通过匹配预测中的拓扑特征，提高了半监督组织病理图像分割的准确性...|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Euclid's Gift: Enhancing Spatial Perception and Reasoning in Vision-Language Models via Geometric Surrogate Tasks|欧几里得的礼物：通过几何替代任务增强视觉语言模型的空间感知与推理能力|Shijie Lian, Changti Wu, Laurence Tianruo Yang, Hang Yuan, Bin Yu, Lei Zhang, Kai Chen|<http://arxiv.org/pdf/2509.24473v2>|[代码](https://zgca-ai4edu.github.io/Euclids_Gift.); 提出使用几何问题解决作为代理任务，通过Euclid30K数据集和GRPO优化，提升了视觉语言模型的空...|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Do You Know Where Your Camera Is? View-Invariant Policy Learning with Camera Conditioning|你知道你的摄像头在哪里吗？基于摄像头条件的视角不变策略学习|Tianchong Jiang, Jingtian Ji, Xiangshan Tan, Jiading Fang, Anand Bhattad, Vitor Guizilini, Matthew R. Walter|<http://arxiv.org/pdf/2510.02268v1>|[代码](https://ripl.github.io/know_your_camera); 通过将相机外参与策略学习相结合，实现了视角不变性的模仿学习，增强了机器人控制策略在不同视角下的泛化能...|
|🆕 发布|ActiveUMI: Robotic Manipulation with Active Perception from Robot-Free Human Demonstrations|主动UMI：从无需机器人参与的示范中获取主动感知的机器人操作|Qiyuan Zeng, Chengmeng Li, Jude St. John, Zhongyi Zhou, Junjie Wen, Guorui Feng, Yichen Zhu, Yi Xu|<http://arxiv.org/pdf/2510.01607v1>|提出ActiveUMI框架，通过虚拟现实远程操作和传感器化控制器，将人类演示转化为机器人复杂双臂操作...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|NeuroSwift: A Lightweight Cross-Subject Framework for fMRI Visual Reconstruction of Complex Scenes|神经 Swift：一种轻量级跨受试者功能性磁共振成像复杂场景视觉重建框架|Shiyi Zhang, Dong Liang, Yihang Zhou|<http://arxiv.org/pdf/2510.02266v1>|提出了一种跨受试者fMRI视觉重建轻量级框架NeuroSwift，通过结合低级特征和语义适配器，实现...|
|🆕 发布|RewardMap: Tackling Sparse Rewards in Fine-grained Visual Reasoning via Multi-Stage Reinforcement Learning|奖励图：通过多阶段强化学习解决细粒度视觉推理中的稀疏奖励问题|Sicheng Feng, Kaiwen Tuo, Song Wang, Lingdong Kong, Jianke Zhu, Huan Wang|<http://arxiv.org/pdf/2510.02240v1>|提出多阶段强化学习框架RewardMap，通过困难感知奖励设计和分阶段训练策略，有效解决细粒度视觉推...|
|📝 更新|EyePCR: A Comprehensive Benchmark for Fine-Grained Perception, Knowledge Comprehension and Clinical Reasoning in Ophthalmic Surgery|眼科手术中细粒度感知、知识理解与临床推理的全面基准：EyePCR|Gui Wang, Yang Wennuo, Xusen Ma, Zehao Zhong, Zhuoru Wu, Ende Wu, Rong Qu, Wooi Ping Cheah .etc.|<http://arxiv.org/pdf/2509.15596v2>|提出了EyePCR大规模基准，通过丰富的注释提升多模态大语言模型在眼科手术认知任务中的表现。|
|🆕 发布|Foundation Visual Encoders Are Secretly Few-Shot Anomaly Detectors|基础视觉编码器实际上是少量样本异常检测器|Guangyao Zhai, Yue Zhou, Xinyan Deng, Lars Heckler, Nassir Navab, Benjamin Busam|<http://arxiv.org/pdf/2510.01934v1>|发现了预训练视觉编码器在异常检测中的潜力，提出了一种使用少量样本进行多类异常检测的有效方法。|
|🆕 发布|VaPR -- Vision-language Preference alignment for Reasoning|视觉-语言偏好对齐推理方法（VaPR）|Rohan Wadhawan, Fabrice Y Harel-Canada, Zi-Yi Dou, Suhaila Shakiah, Robinson Piramuthu, Nanyun Peng|<http://arxiv.org/pdf/2510.01700v1>|提出了一种针对人类偏好噪声的硬负样本生成框架，通过LLM引导的响应编辑，显著提升了大型视觉语言模型在...|
|📝 更新|Efficient Whole Slide Pathology VQA via Token Compression|通过标记压缩实现高效的全幻灯片病理学视觉问答|Weimin Lyu, Qingqiao Hu, Kehan Qi, Zhan Shi, Wentao Huang, Saumya Gupta, Chao Chen|<http://arxiv.org/pdf/2507.14497v2>|提出了一种基于压缩 tokens 的病理全切片图像 VQA 方法，有效降低了计算资源消耗并提高了问答...|
|🆕 发布|Look Less, Reason More: Rollout-Guided Adaptive Pixel-Space Reasoning|“少看多思考：基于滚动指导的自适应像素空间推理”|Xuchen Li, Xuzhao Li, Jiahui Gao, Renjie Pi, Shiyu Hu, Wentao Zhang|<http://arxiv.org/pdf/2510.01681v1>|提出自适应像素推理框架，通过动态确定必要操作，提升视觉语言模型处理细粒度视觉元素的能力，同时减少不必...|
|🆕 发布|VirDA: Reusing Backbone for Unsupervised Domain Adaptation with Visual Reprogramming|VirDA：利用视觉重编程重用主干网络进行无监督领域自适应|Duy Nguyen, Dat Nguyen|<http://arxiv.org/pdf/2510.01660v1>|VirDA通过添加视觉重编程层而非微调整个主干网络，有效重用预训练参数进行无监督领域适应。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SpurBreast: A Curated Dataset for Investigating Spurious Correlations in Real-world Breast MRI Classification|《SpurBreast：一个用于研究现实世界乳腺MRI分类中伪相关性的专门数据集》|Jong Bum Won, Wesley De Neve, Joris Vankerschaver, Utku Ozbulak|<http://arxiv.org/pdf/2510.02109v1>|[代码](https://github.com/utkuozbulak/spurbreast.); 介绍了SpurBreast数据集，用于研究现实世界医学影像分类中的误导性关联对模型性能的影响。|
|🆕 发布|VGDM: Vision-Guided Diffusion Model for Brain Tumor Detection and Segmentation|VGDM：视觉引导的扩散模型用于脑肿瘤检测与分割|Arman Behnam|<http://arxiv.org/pdf/2510.02086v1>|提出VGDM框架，融合视觉Transformer与扩散模型，提升脑肿瘤检测与分割的准确性和边界精度。|
|🆕 发布|GFSR-Net: Guided Focus via Segment-Wise Relevance Network for Interpretable Deep Learning in Medical Imaging|GFSR-Net：通过分段相关性网络引导焦点以实现医学影像中深度学习的可解释性|Jhonatan Contreras, Thomas Bocklitz|<http://arxiv.org/pdf/2510.01919v1>|提出GFSR-Net方法，通过少量人类标注指导模型关注图像的关键区域，增强医疗影像分析的可靠性与可解...|
|🆕 发布|Automated Defect Detection for Mass-Produced Electronic Components Based on YOLO Object Detection Models|基于YOLO目标检测模型的批量生产电子元件自动缺陷检测|Wei-Lung Mao, Chun-Chi Wang, Po-Heng Chou, Yen-Ting Liu|<http://arxiv.org/pdf/2510.01914v1>|提出了一种基于YOLOv7和ConSinGAN的自动化电子元件缺陷检测系统，提高了检测准确性和效率。|
|📝 更新|Multi-Domain Brain Vessel Segmentation Through Feature Disentanglement|多域脑血管分割通过特征解耦|Francesco Galati, Daniele Falcetta, Rosa Cortese, Ferran Prados, Ninon Burgos, Maria A. Zuluaga|<http://arxiv.org/pdf/2510.00665v2>|[代码](https://github.com/i-vesseg/MultiVesSeg.); 提出了一种通过特征解耦实现多领域脑血管分割的方法，有效适应不同数据集和成像模式。|
|🆕 发布|MedQ-Bench: Evaluating and Exploring Medical Image Quality Assessment Abilities in MLLMs|MedQ- Bench：评估和探索大型机器学习模型在医学图像质量评估方面的能力|Jiyao Liu, Jinjie Wei, Wanying Qu, Chenglong Ma, Junzhi Ning, Yunheng Li, Ying Chen, Xinzhe Luo .etc.|<http://arxiv.org/pdf/2510.01691v1>|提出MedQ-Bench，通过语言模型评估医学图像质量，模拟人类评估的感知与推理过程。|
|🆕 发布|Median2Median: Zero-shot Suppression of Structured Noise in Images|中值到中值：零样本抑制图像中的结构噪声|Jianxu Wang, Ge Wang|<http://arxiv.org/pdf/2510.01666v1>|提出了Median2Median框架，通过自适应排除结构噪声实现了零样本图像去噪。|
|📝 更新|Does Bigger Mean Better? Comparitive Analysis of CNNs and Biomedical Vision Language Modles in Medical Diagnosis|更大的网络意味着更好的性能吗？CNN与生物医学视觉语言模型在医学诊断中的比较分析|Ran Tong, Jiaqi Liu, Su Liu, Jiexi Xu, Lanruo Wang, Tong Wang|<http://arxiv.org/pdf/2510.00411v2>|通过决策阈值校准，论文证明了零样本医疗视觉语言模型BiomedCLIP在医学影像诊断中的性能可媲美或...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Landcover classification and change detection using remote sensing and machine learning: a case study of Western Fiji|利用遥感与机器学习进行土地覆盖分类与变化检测：西斐济的案例研究|Yadvendra Gurjar, Ruoni Wan, Ehsan Farahbakhsh, Rohitash Chandra|<http://arxiv.org/pdf/2509.13388v2>|利用机器学习和遥感技术监测斐济Nadi地区2013至2024年土地利用变化。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Poutine: Vision-Language-Trajectory Pre-Training and Reinforcement Learning Post-Training Enable Robust End-to-End Autonomous Driving|“Poutine：视觉-语言-轨迹预训练与强化学习后训练助力稳健的端到端自动驾驶”|Luke Rowe, Rodrigue de Schaetzen, Roger Girgis, Christopher Pal, Liam Paull|<http://arxiv.org/pdf/2506.11234v3>|利用大型语言模型的通用知识和推理能力，Poutine方法通过简单的视觉-语言-轨迹预训练和强化学习微...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Behavioral Performance to Internal Competence: Interpreting Vision-Language Models with VLM-Lens|从行为表现到内部能力：使用VLM-Lens解释视觉-语言模型|Hala Sheta, Eric Huang, Shuyu Wu, Ilia Alenabi, Jiajun Hong, Ryker Lin, Ruoxi Ning, Daniel Wei .etc.|<http://arxiv.org/pdf/2510.02292v1>|介绍了VLM-Lens工具包，实现了对视觉语言模型中间输出的统一提取和便捷分析。|
|📝 更新|L4P: Towards Unified Low-Level 4D Vision Perception|面向统一低层次四维视觉感知的L4P方法|Abhishek Badki, Hang Su, Bowen Wen, Orazio Gallo|<http://arxiv.org/pdf/2502.13078v3>|提出统一架构L4P，通过预训练视频编码器高效解决多种低级4D视觉任务。|
|🆕 发布|Unsupervised Dynamic Feature Selection for Robust Latent Spaces in Vision Tasks|无监督动态特征选择以增强视觉任务中的稳健潜在空间|Bruno Corcuera, Carlos Eiras-Franco, Brais Cancela|<http://arxiv.org/pdf/2510.01758v1>|提出了一种无监督动态特征选择方法，有效提升了视觉任务中潜在空间的鲁棒性。|


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Robust Prompt Tuning for Vision-Language Models with Mild Semantic Noise|具有轻微语义噪声的视觉语言模型的鲁棒提示微调|Yansheng Gao, Yufei Zheng, Shengsheng Wang|<http://arxiv.org/pdf/2508.04677v3>|提出了一种引入弱语义噪声的稳健提示调优框架ANPrompt，有效提升了视觉语言模型的鲁棒性和泛化能力...|


### 可解释视觉智能 (Explainable Visual Intelligence)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TriAlignXA: An Explainable Trilemma Alignment Framework for Trustworthy Agri-product Grading|TriAlignXA：一种用于可靠农产品分级的三难问题对齐解释框架|Jianfei Xie, Ziyang Li|<http://arxiv.org/pdf/2510.01990v1>|提出TriAlignXA框架，通过多目标优化平衡农产品分级中的生物特性、时效性和经济性，增强在线交易...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spec-Gloss Surfels and Normal-Diffuse Priors for Relightable Glossy Objects|“用于可重光照光滑物体的Spec-Gloss表面元素和Normal-Diffuse先验”|Georgios Kouros, Minye Wu, Tinne Tuytelaars|<http://arxiv.org/pdf/2510.02069v1>|提出了一种结合微表面BRDF与延迟着色的二维高斯绘制框架，实现了高质量的光泽物体重建和真实光照效果。|
|🆕 发布|ROI-GS: Interest-based Local Quality 3D Gaussian Splatting|ROI-GS：基于兴趣点的局部质量三维高斯散点绘制|Quoc-Anh Bui, Gilles Rougeron, Géraldine Morin, Simone Gasparini|<http://arxiv.org/pdf/2510.01978v1>|提出ROI-GS方法，通过关注对象指导的资源分配，提升感兴趣区域的3D场景重建细节并减小模型大小。|
|📝 更新|RGS-DR: Deferred Reflections and Residual Shading in 2D Gaussian Splatting|RGS-DR：二维高斯散点绘制中的延迟反射与残差着色|Georgios Kouros, Minye Wu, Tinne Tuytelaars|<http://arxiv.org/pdf/2504.18468v4>|通过延迟着色和残差处理改进二维高斯散点渲染，提升了对镜面反射的细节捕捉和材质编辑能力。|
|📝 更新|GARLIC: GAussian Representation LearnIng for spaCe partitioning|大蒜：高斯表示学习用于空间划分|Panagiotis Rigas, Panagiotis Drivas, Charalambos Tzamos, Ioannis Chamodrakas, George Ioannakis, Leonidas J. Guibas, Ioannis Z. Emiris|<http://arxiv.org/pdf/2505.24608v2>|提出了一种基于局部几何和密度自适应的高维空间划分方法，有效优化了近似最近邻搜索的性能。|
|📝 更新|LRFusionPR: A Polar BEV-Based LiDAR-Radar Fusion Network for Place Recognition|极坐标BEV基础上的LiDAR-Radar融合网络LRFusionPR用于地点识别|Zhangshuo Qi, Luqi Cheng, Zijie Zhou, Guangming Xiong|<http://arxiv.org/pdf/2504.19186v3>|[代码](https://github.com/QiZS-BIT/LRFusionPR.); 提出了一种基于极坐标鸟瞰图的激光雷达与雷达融合网络，提升了定位准确性和恶劣天气下的鲁棒性。|
|🆕 发布|Calibrating the Full Predictive Class Distribution of 3D Object Detectors for Autonomous Driving|为自动驾驶校准三维物体检测器的完整预测类分布|Cornelius Schröder, Marius-Raphael Schlüter, Markus Lienkamp|<http://arxiv.org/pdf/2510.01829v1>|提出方法校准3D物体检测器的全预测置信度分布，提升自动驾驶系统对象检测的精确性和不确定性估计。|

