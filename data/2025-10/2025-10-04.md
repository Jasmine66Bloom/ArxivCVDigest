## [UPDATED!] **2025-10-04** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OpenCUA: Open Foundations for Computer-Use Agents|开放CUA：计算机使用代理的开放基础|Xinyuan Wang, Bowen Wang, Dunjie Lu, Junlin Yang, Tianbao Xie, Junli Wang, Jiaqi Deng, Xiaole Guo .etc.|<http://arxiv.org/pdf/2508.09123v3>|提出OpenCUA框架，开源支持计算机使用代理的数据和模型，实现CUA任务自动化并达到新性能标准。|
|📝 更新|RGB-to-Polarization Estimation: A New Task and Benchmark Study|RGB到偏振估计：一项新任务与基准研究|Beibei Lin, Zifeng Yuan, Tingting Chen|<http://arxiv.org/pdf/2505.13050v2>|提出RGB-to-Polarization图像估计任务，通过深度学习模型从RGB图像推断极化信息，建...|
|📝 更新|Resolving Task Objective Conflicts in Unified Model via Task-Aware Mixture-of-Experts|通过任务感知的混合专家模型解决统一模型中的任务目标冲突|Jiaxing Zhang, Hao Tang|<http://arxiv.org/pdf/2506.03591v2>|提出了一种任务感知的混合专家框架，有效解决了统一模型中任务目标冲突，实现了多模态任务的最佳性能。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Cross-View Open-Vocabulary Object Detection in Aerial Imagery|跨视角开放词汇目标检测在航空影像中|Jyoti Kini, Rohit Gupta, Mubarak Shah|<http://arxiv.org/pdf/2510.03858v1>|提出了一种跨视图开放词汇对象检测框架，通过结构化域对齐，实现了从地面视图到航拍图像的零样本检测性能提...|
|🆕 发布|The Overlooked Value of Test-time Reference Sets in Visual Place Recognition|《测试时参考集在视觉位置识别中被忽视的价值》|Mubariz Zaffar, Liangliang Nan, Sebastian Scherer, Julian F. P. Kooij|<http://arxiv.org/pdf/2510.03751v1>|定位视觉地点识别难题，提出测试时参考集微调方法，提升现有技术水平。|
|🆕 发布|Bridging the Gap Between Multimodal Foundation Models and World Models|弥合多模态基础模型与世界模型之间的差距|Xuehai He|<http://arxiv.org/pdf/2510.03727v1>|提出新框架增强多模态基础模型的推理和生成能力，实现深度关系理解和细粒度控制生成。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|InfMasking: Unleashing Synergistic Information by Contrastive Multimodal Interactions|信息遮蔽：通过对比性多模态交互释放协同信息|Liangjian Wen, Qun Dai, Jianzhuang Liu, Jiangtao Zheng, Yong Dai, Dongkai Wang, Zhao Kang, Jun Wang .etc.|<http://arxiv.org/pdf/2509.25270v2>|[代码](https://github.com/brightest66/InfMasking.); 提出了一种无限遮蔽策略InfMasking，通过对比学习增强多模态间的协同信息，实现了多模态表征学习...|
|🆕 发布|Model-Guided Microstimulation Steers Primate Visual Behavior|模型引导的微刺激控制灵长类动物视觉行为|Johannes Mehrer, Ben Lonnqvist, Anna Mitola, Abdulkadir Gokce, Paolo Papale, Martin Schrimpf|<http://arxiv.org/pdf/2510.03684v1>|提出模型引导微刺激方法，实现高级视觉皮层精准刺激，显著改变灵长类视觉选择行为。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Comparative Benchmark of Real-time Detectors for Blueberry Detection towards Precision Orchard Management|《面向精准果园管理的高效蓝莓检测实时检测器比较基准》|Xinyang Mu, Yuzhen Lu, Boyang Deng|<http://arxiv.org/pdf/2509.20580v2>|比较了多种实时对象检测器在蓝莓检测中的应用，并提出了一个包含大量标注实例的新数据集。|
|📝 更新|Enhancing Transformers Through Conditioned Embedded Tokens|通过条件嵌入令牌增强Transformer模型|Hemanth Saratchandran, Simon Lucey|<http://arxiv.org/pdf/2505.12789v2>|提出改善Transformer注意力机制的方法，通过条件嵌入令牌增强训练稳定性与效率。|
|🆕 发布|SAMSOD: Rethinking SAM Optimization for RGB-T Salient Object Detection|SAMSOD：重新思考RGB-T显著目标检测中的SAM优化|Zhengyi Liu, Xinrui Wang, Xianyong Fang, Zhengzheng Tu, Linbo Wang|<http://arxiv.org/pdf/2510.03689v1>|提出SAMSOD模型，通过增强非主导模态学习和减少冲突梯度影响，提升RGB-T显眼目标检测性能。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Exploring Instruction Data Quality for Explainable Image Quality Assessment|探究指令数据质量对可解释图像质量评估的影响|Yunhao Li, Sijing Wu, Huiyu Duan, Yucheng Zhu, Qi Jia, Guangtao Zhai|<http://arxiv.org/pdf/2510.03880v1>|挑战规模法则，提出基于聚类的数据选择方法IQA-Select，以少量高质量数据提升图像质量评估性能。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Joint Neural SDF Reconstruction and Semantic Segmentation for CAD Models|联合神经符号距离函数重建与CAD模型语义分割|Shen Fan, Przemyslaw Musialski|<http://arxiv.org/pdf/2510.03837v1>|提出了一种简单高效的方法，通过结合神经SDF重建网络和部分分割头，实现了无需固定分类体系的CAD模型...|
|📝 更新|TSLA: A Task-Specific Learning Adaptation for Semantic Segmentation on Autonomous Vehicles Platform|特定任务学习适应：面向自动驾驶平台语义分割的TSLA方法|Jun Liu, Zhenglun Kong, Pu Zhao, Weihao Zeng, Hao Tang, Xuan Shen, Changdi Yang, Wenbin Zhang .etc.|<http://arxiv.org/pdf/2508.12279v2>|提出了一种针对自动驾驶硬件计算限制的动态适应语义分割网络，通过调整模型组件实现资源优化和性能提升。|
|🆕 发布|Artery-Vein Segmentation from Fundus Images using Deep Learning|基于深度学习的眼底图像动脉-静脉分割|Sharan SK, Subin Sahayam, Umarani Jayaraman, Lakshmi Priya A|<http://arxiv.org/pdf/2510.03717v1>|提出基于注意力机制的Attention-WNet模型，实现了对视网膜图像中动脉和静脉的高效精准分割。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EfficientMIL: Efficient Linear-Complexity MIL Method for WSI Classification|高效MIL：面向WSI分类的高效线性复杂度MIL方法|Chengying She, Chengwei Chen, Dongjie Fan, Lizhuang Liu, Chengwei Shao, Yun Bian, Ben Wang, Xinran Zhang|<http://arxiv.org/pdf/2509.23640v2>|提出EfficientMIL方法，通过自适应选取patches，降低MIL计算复杂度，提升WSI分类...|
|📝 更新|Foveated Retinotopy Improves Classification and Localization in CNNs|焦点视网膜拓扑结构提高了卷积神经网络中的分类和定位性能|Jean-Nicolas Jérémie, Emmanuel Daucé, Laurent U Perrinet|<http://arxiv.org/pdf/2402.15480v4>|引入仿生视网膜结构提升卷积神经网络在图像分类中的鲁棒性和定位能力。|
|📝 更新|QGFace: Quality-Guided Joint Training For Mixed-Quality Face Recognition|QGFace：质量引导的混合质量人脸识别联合训练|Youzhe Song, Feng Wang|<http://arxiv.org/pdf/2312.17494v2>|提出了一种质量引导的联合训练方法，有效提升了混合质量人脸图像的识别性能。|
|🆕 发布|Exploring the Hierarchical Reasoning Model for Small Natural-Image Classification Without Augmentation|探索无增强条件下小自然图像分类的层次推理模型|Alexander V. Mantzaris|<http://arxiv.org/pdf/2510.03598v1>|探索层次推理模型作为无数据增强的小自然图像分类器，发现其性能不如简单卷积架构。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Controllable Video Generation with Provable Disentanglement|可控视频生成与可证明解耦|Yifan Shen, Peiyuan Zhu, Zijian Li, Shaoan Xie, Namrata Deka, Zongfang Liu, Zeyu Tang, Guangyi Chen .etc.|<http://arxiv.org/pdf/2502.02690v3>|提出了一种视频生成方法CoVoGAN，通过解耦视频概念实现高效独立控制，显著提升了视频生成质量和可控...|
|🆕 发布|Generating Human Motion Videos using a Cascaded Text-to-Video Framework|使用级联文本到视频框架生成人体运动视频|Hyelin Nam, Hyojun Go, Byeongjun Park, Byung-Hoon Kim, Hyungjin Chung|<http://arxiv.org/pdf/2510.03909v1>|提出了一种级联文本到视频框架，有效结合文本到动作模型和条件视频扩散模型，实现了通用人类运动视频的生成...|
|🆕 发布|PoseGaze-AHP: A Knowledge-Based 3D Dataset for AI-Driven Ocular and Postural Diagnosis|姿态视线-AHP：一种基于知识的用于人工智能驱动的眼部和姿态诊断的三维数据集|Saja Al-Dabet, Sherzod Turaev, Nazar Zaki, Arif O. Khan, Luai Eldweik|<http://arxiv.org/pdf/2510.03873v1>|提出了 PoseGaze-AHP，一个同步捕获头部姿势和眼球运动信息的3D数据集，以支持基于AI的异...|
|🆕 发布|Mirage: Unveiling Hidden Artifacts in Synthetic Images with Large Vision-Language Models|幻影：利用大型视觉-语言模型揭示合成图像中的隐藏痕迹|Pranav Sharma, Shivank Garg, Durga Toshniwal|<http://arxiv.org/pdf/2510.03840v1>|提出Mirage数据集，展示大型视觉语言模型在检测带有可见瑕疵的合成图像上的优势。|
|🆕 发布|Diverse Text-to-Image Generation via Contrastive Noise Optimization|通过对比噪声优化实现多样化的文本到图像生成|Byungjun Kim, Soobin Um, Jong Chul Ye|<http://arxiv.org/pdf/2510.03813v1>|提出了一种对比噪声优化方法，有效解决了文本到图像生成中的多样性问题。|
|🆕 发布|Contrastive-SDE: Guiding Stochastic Differential Equations with Contrastive Learning for Unpaired Image-to-Image Translation|对比度SDE：使用对比学习引导随机微分方程进行无配对图像到图像转换|Venkata Narendra Kotyada, Revanth Eranki, Nagesh Bhattu Sristy|<http://arxiv.org/pdf/2510.03821v1>|提出了一种结合对比学习与随机微分方程的模型，有效提升了无配对图像转换的性能与效率。|
|📝 更新|OracleGS: Grounding Generative Priors for Sparse-View Gaussian Splatting|OracleGS：为稀疏视图高斯散布定位生成先验|Atakan Topaloglu, Kunyi Li, Michael Niemeyer, Nassir Navab, A. Murat Tekalp, Federico Tombari|<http://arxiv.org/pdf/2509.23258v2>|提出OracleGS框架，融合生成模型的完整性与回归模型的准确性，通过3D感知验证优化稀疏视图重建。|
|🆕 发布|UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG|统一文档中心多模态关系图基准：UNIDOC-BENCH|Xiangyu Peng, Cab Qin, Zeyuan Chen, Ran Xu, Caiming Xiong, Chien-Sheng Wu|<http://arxiv.org/pdf/2510.03663v1>|提出了UniDoc-Bench，首个面向文档中心多模态检索增强生成的大规模现实基准，证明了融合文本与...|
|📝 更新|ReMoMask: Retrieval-Augmented Masked Motion Generation|《ReMoMask：检索增强的遮罩运动生成》|Zhengdao Li, Siheng Wang, Zeyu Zhang, Hao Tang|<http://arxiv.org/pdf/2508.02605v2>|[代码](https://github.com/AIGeeksGroup/ReMoMask.); ReMoMask通过结合双向动量模型、语义时空注意力和无分类器引导，解决了文本到动作生成中的多样性限...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bridge Thinking and Acting: Unleashing Physical Potential of VLM with Generalizable Action Expert|“桥接思考与行动：释放大型视觉语言模型物理潜能的通用动作专家”|Mingyu Liu, Zheng Huang, Xiaoyi Lin, Muzhi Zhu, Canyu Zhao, Zongze Du, Yating Wang, Haoyi Zhu .etc.|<http://arxiv.org/pdf/2510.03896v1>|首次提出结合通用动作专家的框架，通过稀疏3D轨迹连接视觉语言模型的高层规划和低层物理动作。|
|🆕 发布|Towards Robust and Generalizable Continuous Space-Time Video Super-Resolution with Events|面向鲁棒性与泛化性的连续时空视频超分辨率处理方法研究|Shuoyan Wei, Feng Li, Shengeng Tang, Runmin Cong, Yao Zhao, Meng Wang, Huihui Bai|<http://arxiv.org/pdf/2510.03833v1>|[代码](https://github.com/W-Shuoyan/EvEnhancerPlus.); 提出EvEnhancer方法，利用事件流的高时间分辨率和动态范围特性，实现鲁棒且通用的连续时空视频超...|
|🆕 发布|Mapping Rio de Janeiro's favelas: general-purpose vs. satellite-specific neural networks|《映射里约热内卢的贫民窟：通用神经网络与卫星特定神经网络的比较》|Thomas Hallopeau, Joris Guérin, Laurent Demagistri, Youssef Fouzai, Renata Gracie, Vanderlei Pascoal De Matos, Helen Gurgel, Nadine Dessay|<http://arxiv.org/pdf/2510.03725v1>|比较通用预训练网络与卫星图像专训网络在检测里约热内卢贫民窟的性能差异。|
|📝 更新|MetaSpatial: Reinforcing 3D Spatial Reasoning in VLMs for the Metaverse|《MetaSpatial：在虚拟宇宙中增强大型视觉语言模型的三维空间推理能力》|Zhenyu Pan, Han Liu|<http://arxiv.org/pdf/2503.18470v2>|[代码](https://github.com/PzySeere/MetaSpatial.); MetaSpatial通过强化学习框架增强视觉语言模型的3D空间推理能力，实现无需预设优化即可生成逼...|
|📝 更新|FreeInsert: Disentangled Text-Guided Object Insertion in 3D Gaussian Scene without Spatial Priors|自由插入：在无需空间先验的3D高斯场景中实现解耦的文本引导对象插入|Chenxi Li, Weijie Wang, Qiang Li, Bruno Lepri, Nicu Sebe, Weizhi Nie|<http://arxiv.org/pdf/2505.01322v3>|提出FreeInsert框架，通过解耦对象生成与空间放置，实现无需空间先验的3D场景文本驱动对象插入...|
|📝 更新|Constructing a 3D Scene from a Single Image|从单张图像构建三维场景|Kaizhi Zheng, Ruijian Zha, Zishuo Xu, Jing Gu, Jie Yang, Xin Eric Wang|<http://arxiv.org/pdf/2505.15765v2>|提出了一种无需训练的SceneFuse-3D框架，从单张俯视图生成高质量、结构连贯的3D场景。|
|🆕 发布|Unsupervised Transformer Pre-Training for Images: Self-Distillation, Mean Teachers, and Random Crops|无监督的图像Transformer预训练：自蒸馏、均值教师和随机裁剪|Mattia Scardecchia|<http://arxiv.org/pdf/2510.03606v1>|提出了一种无监督的图像特征学习框架，通过多裁剪增强和自蒸馏均值教师方法，实现了视觉特征的精细捕获和性...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization|面向超越记忆的视觉-语言-动作模型的鲁棒性与公平性评估：LIBERO-PRO|Xueyang Zhou, Yangming Xu, Guiyao Tie, Yongchao Chen, Guowen Zhang, Duanfeng Chu, Pan Zhou, Lichao Sun|<http://arxiv.org/pdf/2510.03827v1>|[代码](https://github.com/Zxy-MLlab/LIBERO-PRO.); 提出LIBERO-PRO基准，通过多维度扰动评估VLA模型，揭示现有模型对记忆的过度依赖。|
|🆕 发布|CoPA: Hierarchical Concept Prompting and Aggregating Network for Explainable Diagnosis|CoPA：分层概念提示与聚合网络用于可解释诊断|Yiheng Dong, Yi Lin, Xin Yang|<http://arxiv.org/pdf/2510.03767v1>|[代码](https://github.com/yihengd/CoPA.); 提出CoPA框架，通过分层概念提示和聚合提升诊断模型的透明度和准确性。|
|📝 更新|RoboSwap: A GAN-driven Video Diffusion Framework For Unsupervised Robot Arm Swapping|RoboSwap：一种基于生成对抗网络的半监督机器人臂替换视频扩散框架|Yang Bai, Liudi Yang, George Eskandar, Fengyi Shen, Dong Chen, Mohammad Altillawi, Ziyuan Liu, Gitta Kutyniok|<http://arxiv.org/pdf/2506.08632v2>|提出了RoboSwap框架，通过GAN和扩散模型实现无监督机器人臂互换，提升跨平台学习数据的多样性和...|
|📝 更新|Jasmine: Harnessing Diffusion Prior for Self-supervised Depth Estimation|Jasmine：利用扩散先验进行自监督深度估计|Jiyuan Wang, Chunyu Lin, Cheng Guan, Lang Nie, Jing He, Haodong Li, Kang Liao, Yao Zhao|<http://arxiv.org/pdf/2503.15905v2>|提出Jasmine框架，利用稳定扩散模型视觉先验进行无监督深度估计，提升预测清晰度和泛化能力。|
|📝 更新|RESCUE: Crowd Evacuation Simulation via Controlling SDM-United Characters|RESCUE：通过控制SDM-联合角色进行人群疏散模拟|Xiaolin Liu, Tianyi Zhou, Hongbo Kang, Jian Ma, Ziwen Wang, Jing Huang, Wenguo Weng, Yu-Kun Lai .etc.|<http://arxiv.org/pdf/2507.20117v2>|提出了一种集成社会力模型和个性化步态控制的实时三维人群疏散模拟框架，提升了模拟的真实性和动态轨迹规划...|
|📝 更新|SAR-TEXT: A Large-Scale SAR Image-Text Dataset Built with SAR-Narrator and A Progressive Learning Strategy for Downstream Tasks|SAR-TEXT：基于SAR-Narrator构建的大规模合成孔径雷达图像-文本数据集及其下游任务的渐进学习策略|Yiguo He, Xinjun Cheng, Junjie Zhu, Chunping Qiu, Jun Wang, Xichuan Zhang, Qiangjuan Huang, Ke Yang|<http://arxiv.org/pdf/2507.18743v3>|[代码](https://github.com/YiguoHe/SAR-TEXT.); 构建了大规模高质SAR图像-文本数据集SAR-TEXT，并设计了多阶段生成框架提升语义理解。|
|🆕 发布|Diffusion-Classifier Synergy: Reward-Aligned Learning via Mutual Boosting Loop for FSCIL|扩散分类器协同：通过互促循环实现面向FSCIL的奖励对齐学习|Ruitao Wu, Yifan Zhao, Guangyao Chen, Jia Li|<http://arxiv.org/pdf/2510.03608v1>|提出Diffusion-Classifier Synergy框架，通过奖励对齐学习策略实现少样本增量...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Erased, But Not Forgotten: Erased Rectified Flow Transformers Still Remain Unsafe Under Concept Attack|被擦除，但未被遗忘：擦除修正流变换器在概念攻击下仍然不安全|Nanxiang Jiang, Zhaoxin Fan, Enhan Kang, Daiheng Gao, Yun Zhou, Yanxia Chang, Zheng Zhu, Yeying Jin .etc.|<http://arxiv.org/pdf/2510.00635v2>|提出了一种针对最新一代图像生成模型的攻击策略，有效评估了概念擦除方法在应对概念攻击时的不足。|
|🆕 发布|Person-Centric Annotations of LAION-400M: Auditing Bias and Its Transfer to Models|以人为中心的LAION-400M注释：审查偏见及其向模型的迁移|Leander Girrbach, Stephan Alaniz, Genevieve Smith, Trevor Darrell, Zeynep Akata|<http://arxiv.org/pdf/2510.03721v1>|创建了针对LAION-400M的人为中心的标注，揭示了数据集组成与模型偏见之间的联系。|
|📝 更新|Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control|“遵循你的形状：通过轨迹引导的区域控制实现形状感知图像编辑”|Zeqian Long, Mingzhe Zheng, Kunyu Feng, Xinhua Zhang, Hongyu Liu, Harry Yang, Linfeng Zhang, Qifeng Chen .etc.|<http://arxiv.org/pdf/2508.08134v3>|提出了一种无需训练和遮罩的图像编辑框架，通过轨迹引导精确控制对象形状变换，同时保护非目标内容。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Super-resolution image projection over an extended depth of field using a diffractive decoder|采用衍射解码器在扩展景深范围内实现超分辨率图像投影|Hanlong Chen, Cagatay Isil, Tianyi Gan, Mona Jarrahi, Aydogan Ozcan|<http://arxiv.org/pdf/2510.03938v1>|提出了一种结合卷积神经网络和衍射解码器的混合图像投影系统，实现了扩展景深下的高分辨率图像重建。|
|🆕 发布|Skin Lesion Classification Based on ResNet-50 Enhanced With Adaptive Spatial Feature Fusion|基于增强自适应空间特征融合的ResNet-50皮肤病变分类|Runhao Liu, Ziming Chen, Peng Zhang|<http://arxiv.org/pdf/2510.03876v1>|提出了一种增强的ResNet-50模型，通过自适应空间特征融合提升皮肤病变分类性能。|
|📝 更新|Deep Spectral Epipolar Representations for Dense Light Field Reconstruction|深度光谱极线表示用于密集光场重建|Noor Islam S. Mohammad|<http://arxiv.org/pdf/2508.08900v2>|提出了一种Deep Spectral Epipolar Representation框架，通过结合频...|
|📝 更新|Circle-RoPE: Cone-like Decoupled Rotary Positional Embedding for Large Vision-Language Models|圆-RoPE：圆锥形解耦旋转位置编码用于大型视觉-语言模型|Chengcheng Wang, Jianyuan Guo, Hongguang Li, Yuchuan Tian, Ying Nie, Chang Xu, Kai Han|<http://arxiv.org/pdf/2505.16416v2>|[代码](https://github.com/lose4578/CircleRoPE.); 提出Circle-RoPE方法，通过环形编码消除视觉语言模型中的跨模态位置偏差。|
|📝 更新|FreqPolicy: Frequency Autoregressive Visuomotor Policy with Continuous Tokens|频率自回归视觉运动策略与连续符号|Yiming Zhong, Yumeng Liu, Chuyang Xiao, Zemin Yang, Youzhuo Wang, Yufei Zhu, Ye Shi, Yujing Sun .etc.|<http://arxiv.org/pdf/2506.01583v2>|[代码](https://github.com/4DVLab/Freqpolicy); 提出了一种基于频率域和连续潜变量的 visuomotor 策略学习方法，提高了机器人操作的准确性和效...|
|📝 更新|PanDORA: Casual HDR Radiance Acquisition for Indoor Scenes|潘多拉：室内场景的 casual HDR 辐射获取|Mohammad Reza Karimi Dastjerdi, Dominique Tanguay-Gaudreau, Frédéric Fortier-Chouinard, Yannick Hold-Geoffroy, Claude Demers, Nima Kalantari, Jean-François Lalonde|<http://arxiv.org/pdf/2407.06150v2>|PanDORA通过双摄像头系统及两阶段NeRF算法，实现了室内场景高质量HDR捕获，解决了传统方法动...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Light of Normals: Unified Feature Representation for Universal Photometric Stereo|“法线之光：用于通用光度立体成像的统一特征表示”|Hong Li, Houyuan Chen, Chongjie Ye, Zhaoxi Chen, Bohan Li, Shaocong Xu, Xianda Guo, Xuhui Liu .etc.|<http://arxiv.org/pdf/2506.18882v4>|提出了一种统一特征表示方法LINO UniPS，通过光注册令牌和交错注意力块分离光照与法线信息，同时...|
|📝 更新|Motion Blender Gaussian Splatting for Dynamic Scene Reconstruction|动态场景重建中的运动混合高斯散点绘制|Xinyu Zhang, Haonan Chang, Yuhan Liu, Abdeslam Boularias|<http://arxiv.org/pdf/2503.09040v4>|[代码](http://mlzxy.github.io/motion-blender-gs.); 提出Motion Blender Gaussian Splatting方法，使用显式运动图表示和可学...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Harnessing Synthetic Preference Data for Enhancing Temporal Understanding of Video-LLMs|利用合成偏好数据增强视频语言模型的时间理解能力|Sameep Vani, Shreyas Jena, Maitreya Patel, Chitta Baral, Somak Aditya, Yezhou Yang|<http://arxiv.org/pdf/2510.03955v1>|[代码](https://github.com/sameepv21/timewarp.); 提出TimeWarp方法，通过合成数据集增强视频大语言模型对时间细节的理解能力。|
|🆕 发布|Sliding Window Attention for Learned Video Compression|滑动窗口注意力机制在视频压缩学习中的应用|Alexander Kopte, André Kaup|<http://arxiv.org/pdf/2510.03926v1>|引入3D滑动窗口注意力机制，提升视频压缩性能并降低解码器复杂度。|
|📝 更新|VSRM: A Robust Mamba-Based Framework for Video Super-Resolution|视频超分辨率稳健的Mamba基础框架：VSRM|Dinh Phu Tran, Dao Duy Hung, Daeyoung Kim|<http://arxiv.org/pdf/2506.22762v3>|提出VSRM框架，利用Mamba提取长距离时空特征，实现视频超分辨率的高效处理。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Talking Tennis: Language Feedback from 3D Biomechanical Action Recognition|《对话网球：来自三维生物力学动作识别的语言反馈》|Arushi Dashore, Aryan Anumala, Emily Hui, Olivia Yang|<http://arxiv.org/pdf/2510.03921v1>|提出了一种结合生物力学特征与深度学习技术的框架，为网球运动员提供准确且实用的语言反馈。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DHQA-4D: Perceptual Quality Assessment of Dynamic 4D Digital Human|动态4D数字人的感知质量评估：DHQA-4D|Yunhao Li, Sijing Wu, Yucheng Zhu, Huiyu Duan, Zicheng Zhang, Guangtao Zhai|<http://arxiv.org/pdf/2510.03874v1>|提出动态4D数字人质量评估数据集DHQA-4D和评估模型DynaMesh-Rater，有效预测4D人...|
|🆕 发布|NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation|《NoTVLA：密集动作轨迹的压缩用于通用机器人操作》|Zheng Huang, Mingyu Liu, Xiaoyi Lin, Muzhi Zhu, Canyu Zhao, Zongze Du, Xiaoman Li, Yiduo Jia .etc.|<http://arxiv.org/pdf/2510.03895v1>|提出NoTVLA框架，通过聚焦稀疏轨迹避免密集轨迹微调导致的灾难性遗忘，提升机器人操作性能和泛化能力...|
|🆕 发布|SDAKD: Student Discriminator Assisted Knowledge Distillation for Super-Resolution Generative Adversarial Networks|学生判别器辅助的知识蒸馏用于超分辨率生成对抗网络|Nikolaos Kaparinos, Vasileios Mezaris|<http://arxiv.org/pdf/2510.03870v1>|提出了一种学生判别器辅助的知识蒸馏方法SDAKD，有效解决了GAN压缩中的容量不匹配问题，提升了超分...|
|🆕 发布|Optimized Minimal 4D Gaussian Splatting|优化最小四维高斯散点绘制|Minseo Lee, Byeonghyeon Lee, Lucas Yunkyu Lee, Eunsoo Lee, Sangmin Kim, Seunghyeon Song, Joo Chan Lee, Jong Hwan Ko .etc.|<http://arxiv.org/pdf/2510.03857v1>|[代码](https://minshirley.github.io/OMG4); 提出OMG4方法，通过优化高斯分布的采样、剪枝和合并，大幅减少动态场景表示的存储需求同时保持视觉质量...|
|🆕 发布|Efficiency vs. Efficacy: Assessing the Compression Ratio-Dice Score Relationship through a Simple Benchmarking Framework for Cerebrovascular 3D Segmentation|效率与效力：通过简单基准测试框架评估脑血管3D分割中的压缩比-_dice得分关系|Shimaa Elbana, Ahmad Kamal, Shahd Ahmed Ali, Ahmad Al-Kabbany|<http://arxiv.org/pdf/2510.03769v1>|探究ZFP压缩技术在保持性能的同时，显著提高医疗3D图像数据压缩比。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization|自适应采样-重用-混合分解梯度以加速锐度感知最小化|Jiaxin Deng, Junbiao Pang|<http://arxiv.org/pdf/2510.03763v1>|[代码](https://github.com/ajiaaa/ARSAM.); 提出ARSAM方法，通过自适应采样和重用分解梯度，加速Sharpness-Aware Minimiz...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LoRA Patching: Exposing the Fragility of Proactive Defenses against Deepfakes|《LoRA补丁：揭示主动防御对抗深度伪造的脆弱性》|Zuomin Qu, Yimao Guo, Qianyue Hu, Wei Lu|<http://arxiv.org/pdf/2510.03747v1>|[代码](https://github.com/ZOMIN28/LoRA-Patching.); 揭示了预防性对抗防御的脆弱性，并提出LoRA patching方法绕过先进防御机制。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Physics-Based Motion Imitation with Adversarial Differential Discriminators|基于物理的运动模仿与对抗性微分判别器|Ziyu Zhang, Sergey Bashkirov, Dun Yang, Yi Shi, Michael Taylor, Xue Bin Peng|<http://arxiv.org/pdf/2505.04961v2>|[代码](https://add-moo.github.io/.); 提出了一种无需手动设计奖励函数的对抗性多目标优化技术，实现了高保真度的运动跟踪。|
|📝 更新|Segmenting Bi-Atrial Structures Using ResNext Based Framework|基于ResNext框架的双心房结构分割|Malitha Gunawardhana, Mark L Trew, Gregory B Sands, Jichao Zhao|<http://arxiv.org/pdf/2503.02892v3>|提出了一种基于ResNeXt的深度学习框架，实现了心房结构的自动化精确分割，提高了心律失常治疗的准确...|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation|时间序列无源域自适应中的时间源恢复|Yucheng Wang, Peiliang Gong, Min Wu, Felix Ott, Xiaoli Li, Lihua Xie, Zhenghua Chen|<http://arxiv.org/pdf/2409.19635v2>|提出Temporal Source Recovery框架，通过恢复时间序列数据中的源时序依赖性，实现...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AI-Assisted Pleural Effusion Volume Estimation from Contrast-Enhanced CT Images|基于人工智能的增强CT图像中胸腔积液体积估算|Sanhita Basu, Tomas Fröding, Ali Teymur Kahraman, Dimitris Toumpanakis, Tobias Sjöblom|<http://arxiv.org/pdf/2510.03856v1>|提出TTAS半监督深度学习框架，提高了胸腔积液体积的CT图像分割精度。|
|📝 更新|PAL-UI: Planning with Active Look-back for Vision-Based GUI Agents|PAL-UI：基于视觉的GUI智能体主动回溯规划方法|Zikang Liu, Junyi Li, Wayne Xin Zhao, Dawei Gao, Yaliang Li, Ji-rong Wen|<http://arxiv.org/pdf/2510.00413v2>|提出了一种自适应回顾历史观测的GUI代理规划框架，有效提升了长周期任务的处理能力。|
|📝 更新|Capsule Network Projectors are Equivariant and Invariant Learners|胶囊网络投影器是等变性和不变性学习者|Miles Everett, Aiden Durrant, Mingjun Zhong, Georgios Leontidis|<http://arxiv.org/pdf/2405.14386v4>|[代码](https://github.com/AberdeenML/CapsIE.); 提出了一种基于胶囊网络的自我监督学习架构，实现了等变性和不变性，提升了等效变任务的表现和效率。|
|🆕 发布|Road Damage and Manhole Detection using Deep Learning for Smart Cities: A Polygonal Annotation Approach|基于深度学习的智慧城市道路损伤和井盖检测：一种多边形标注方法|Rasel Hossen, Diptajoy Mistry, Mushiur Rahman, Waki As Sami Atikur Rahman Hridoy, Sajib Saha, Muhammad Ibrahim|<http://arxiv.org/pdf/2510.03797v1>|利用YOLOv9算法和精确的边形标注，实现了智能城市中道路损坏和井盖的自动检测。|
|🆕 发布|EmbodiSwap for Zero-Shot Robot Imitation Learning|EmbodiSwap 用于零样本机器人模仿学习|Eadom Dessalene, Pavan Mantripragada, Michael Maynord, Yiannis Aloimonos|<http://arxiv.org/pdf/2510.03706v1>|提出 EmbodiSwap 方法，通过合成机器人覆盖视频实现零样本机器人模仿学习，显著提升模仿成功率...|
|🆕 发布|FrameOracle: Learning What to See and How Much to See in Videos|帧Oracle：学习在视频中看什么和看多少|Chaoyu Li, Tianzhi Li, Fei Tao, Zhenyu Zhao, Ziqian Wu, Maozheng Zhao, Juntong Song, Cheng Niu .etc.|<http://arxiv.org/pdf/2510.03584v1>|提出了FrameOracle，一种预测关键帧数量与选择的模块，有效提升了视频理解的效率和准确性。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language Models|《不浪费任何标记：在生物医学视觉-语言模型中利用长上下文》|Min Woo Sun, Alejandro Lozano, Javier Gamazo Tejero, Vishwesh Nath, Xiao Xiao Sun, James Burgess, Yuhui Zhang, Kun Yuan .etc.|<http://arxiv.org/pdf/2510.03978v1>|提出长文本编码策略提升生物医学视觉语言模型性能，减少 token 浪费并提高检索与分类效果。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OpenFLAME: Federated Visual Positioning System to Enable Large-Scale Augmented Reality Applications|开放火焰：联邦视觉定位系统，以支持大规模增强现实应用|Sagar Bharadwaj, Harrison Williams, Luke Wang, Michael Liang, Tao Jin, Srinivasan Seshan, Anthony Rowe|<http://arxiv.org/pdf/2510.03915v1>|提出了一种分布式视觉定位系统OpenFLAME，解决隐私和覆盖问题，实现室内外大规模增强现实应用。|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Neurosymbolic Agent System for Compositional Visual Reasoning|用于组合视觉推理的神经符号智能体系统|Yichang Xu, Gaowen Liu, Ramana Rao Kompella, Sihao Hu, Fatih Ilhan, Selim Furkan Tekin, Zachary Yahn, Ling Liu|<http://arxiv.org/pdf/2506.07778v3>|提出了一种神经符号方法VLAgent，通过两阶段推理系统和语法修正，有效提升了组合视觉推理能力。|
|🆕 发布|Zero-Shot Fine-Grained Image Classification Using Large Vision-Language Models|使用大型视觉-语言模型进行零样本细粒度图像分类|Md. Atabuzzaman, Andrew Zhang, Chris Thomas|<http://arxiv.org/pdf/2510.03903v1>|[代码](https://github.com/Atabuzzaman/Fine-grained-classification); 提出将零样本细粒度图像分类转化为视觉问答框架，利用大型视觉语言模型的综合理解能力，并通过新颖的注意力...|
|🆕 发布|UGround: Towards Unified Visual Grounding with Unrolled Transformers|统一视觉定位：基于展开变换器的探索|Rui Qian, Xin Yin, Chuanhang Deng, Zhiyuan Peng, Jian Xiong, Wei Zhai, Dejing Dou|<http://arxiv.org/pdf/2510.03853v1>|[代码](https://github.com/rui-qian/UGround); UGround通过动态选择未展开变换器的中间层，并采用随机跳接和掩码提示策略，解决了传统视觉定位中固...|
|🆕 发布|A Hybrid Co-Finetuning Approach for Visual Bug Detection in Video Games|视频游戏中视觉缺陷检测的混合协同微调方法|Faliu Yi, Sherif Abdelfattah, Wei Huang, Adrian Brown|<http://arxiv.org/pdf/2510.03591v1>|提出了一种混合协同微调方法，利用少量标注数据和大量未标注数据，有效提升游戏视觉缺陷检测的准确性和适应...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|AutoDrive-QA: A Multiple-Choice Benchmark for Vision-Language Evaluation in Urban Autonomous Driving|自动驾驶问答：面向城市自动驾驶的视觉语言评估多选基准|Boshra Khalili, Andrew W. Smyth|<http://arxiv.org/pdf/2503.15778v2>|提出了一种将开放性问题转化为结构化多项选择题的评估框架，为城市自动驾驶的视觉语言模型提供了标准化和可...|
|🆕 发布|Referring Expression Comprehension for Small Objects|小目标指代表达式理解|Kanoko Goto, Takumi Hirose, Mahiro Ukai, Shuhei Kurita, Nakamasa Inoue|<http://arxiv.org/pdf/2510.03701v1>|针对小目标物体的指代表达式理解挑战，提出了一种高效的数据集和渐进式迭代缩放适配器方法。|
|🆕 发布|A Novel Cloud-Based Diffusion-Guided Hybrid Model for High-Accuracy Accident Detection in Intelligent Transportation Systems|一种基于云的扩散引导混合模型用于智能交通系统中的高精度事故检测|Siva Sai, Saksham Gupta, Vinay Chamola, Rajkumar Buyya|<http://arxiv.org/pdf/2510.03675v1>|提出了一种基于云的扩散引导混合模型，通过整合分类与扩散技术，显著提升了智能交通系统中的事故检测准确性...|
|🆕 发布|MonitorVLM:A Vision Language Framework for Safety Violation Detection in Mining Operations|监控VLM：一种用于采矿作业安全违规检测的视觉语言框架|Jiang Wu, Sichao Wu, Yinsong Ma, Guangyuan Yu, Haoyuan Xu, Lifang Zheng, Jingliang Duan|<http://arxiv.org/pdf/2510.03666v1>|提出了一种视觉-语言框架MonitorVLM，用于从监控视频流中直接检测矿业作业中的安全违规行为，提...|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Filters to VLMs: Benchmarking Defogging Methods through Object Detection and Segmentation Performance|从滤波器到视觉语言模型：通过目标检测和分割性能评估去雾方法|Ardalan Aryashad, Parsa Razmara, Amin Mahjoub, Seyedarmin Azizi, Mahdi Salmani, Arad Firouzkouhi|<http://arxiv.org/pdf/2510.03906v1>|通过综合评估去雾方法对物体检测和分割性能的影响，论文建立了一个透明的、面向任务的基准，揭示了预处理在...|
|🆕 发布|Multi-Modal Oral Cancer Detection Using Weighted Ensemble Convolutional Neural Networks|多模态口腔癌检测利用加权集成卷积神经网络|Ajo Babu George, Sreehari J R Ajo Babu George, Sreehari J R Ajo Babu George, Sreehari J R|<http://arxiv.org/pdf/2510.03878v1>|提出了一种融合临床、放射和病理图像的多模态深度学习框架，提高了口腔鳞状细胞癌的早期诊断准确性。|
|🆕 发布|Exploring the Challenge and Value of Deep Learning in Automated Skin Disease Diagnosis|探索深度学习在自动化皮肤病诊断中的挑战与价值|Runhao Liu, Ziming Chen, Peng Zhang|<http://arxiv.org/pdf/2510.03869v1>|探讨深度学习在自动化皮肤病诊断中的挑战与价值，提出数据增强、混合模型等创新方法提升诊断准确性。|
|📝 更新|MedEBench: Diagnosing Reliability in Text-Guided Medical Image Editing|MedEBench：诊断文本引导的医学图像编辑中的可靠性|Minghao Liu, Zhitao He, Zhiyuan Fan, Qingyun Wang, Yi R. Fung|<http://arxiv.org/pdf/2506.01921v7>|提出MedEBench，为评估文本引导的医疗图像编辑可靠性提供临床基准和诊断工具。|
|🆕 发布|MambaCAFU: Hybrid Multi-Scale and Multi-Attention Model with Mamba-Based Fusion for Medical Image Segmentation|MambaCAFU：基于Mamba融合的混合多尺度与多注意力模型用于医学图像分割|T-Mai Bui, Fares Bougourzi, Fadi Dornaika, Vinh Truong Hoang|<http://arxiv.org/pdf/2510.03786v1>|提出了一种融合CNN、Transformers和Mamba注意力机制的混合模型，提升了医疗图像分割的...|
|📝 更新|Mask What Matters: Controllable Text-Guided Masking for Self-Supervised Medical Image Analysis|《遮蔽关键信息：可控文本引导遮蔽用于自监督医学图像分析》|Ruilang Wang, Shuotong Xu, Bowen Liu, Runlin Huang, Donglong Chen, Weifeng Su|<http://arxiv.org/pdf/2509.23054v2>|提出了一种文本引导的可控遮蔽框架，通过强调诊断相关区域，提升了医学图像分析的自监督学习性能。|
|📝 更新|Automated Defect Detection for Mass-Produced Electronic Components Based on YOLO Object Detection Models|基于YOLO目标检测模型的批量生产电子元件自动缺陷检测|Wei-Lung Mao, Chun-Chi Wang, Po-Heng Chou, Yen-Ting Liu|<http://arxiv.org/pdf/2510.01914v2>|提出了一种基于YOLOv7和ConSinGAN的自动化电子元件缺陷检测系统，提高了检测准确性和效率。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Use of Quadcopter Wakes to Supplement Strawberry Pollination|利用四旋翼无人机尾流辅助草莓授粉|Sadie Cutler, Ben DeFay, Scott McArt, Kirstin Petersen|<http://arxiv.org/pdf/2510.03974v1>|探究了使用无人机辅助风媒授粉的新方法，以补充草莓作物的自然授粉不足。|

