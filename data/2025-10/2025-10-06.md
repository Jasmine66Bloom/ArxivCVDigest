## [UPDATED!] **2025-10-06** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Graph-Based Framework for Interpretable Whole Slide Image Analysis|基于图的解释性全切片图像分析框架|Alexander Weers, Alexander H. Berger, Laurin Lux, Peter Schüffler, Daniel Rueckert, Johannes C. Paetzold|<http://arxiv.org/pdf/2503.11846v2>|[代码](https://github.com/HistoGraph31/pix2pathology.); 提出了一种基于图的生物信息分析方法，将全切片图像转化为可解释的图表示，实现了高效且可解释的病理诊断。|
|📝 更新|Leveraging Foundation Models for Multimodal Graph-Based Action Recognition|利用基础模型进行多模态图论动作识别|Fatemeh Ziaeetabar, Florentin Wörgötter|<http://arxiv.org/pdf/2505.15192v2>|提出了一种融合视觉语言基础模型的动态图框架，用于细粒度双手动操作识别，实现了性能的提升。|
|🆕 发布|Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models|视频LMM后训练：深入探索大型多模态模型在视频推理中的应用|Yunlong Tang, Jing Bi, Pinxin Liu, Zhenyu Pan, Zhangyun Tan, Qianxiang Shen, Jiani Liu, Hang Hua .etc.|<http://arxiv.org/pdf/2510.05034v1>|[代码](https://github.com/yunlong10/Awesome-Video-LMM-Post-Training); 系统梳理了视频理解中大型多模态模型的后训练方法，提升了模型推理能力和效率。|
|🆕 发布|Visual Representations inside the Language Model|语言模型内部的视觉表示|Benlin Liu, Amita Kamath, Madeleine Grunde-McLaughlin, Winson Han, Ranjay Krishna|<http://arxiv.org/pdf/2510.04819v1>|揭示了多模态语言模型处理视觉信息的方式，提出通过控制视觉信息流提升模型感知能力的新方向。|
|📝 更新|Law of Vision Representation in MLLMs|《多模态大型语言模型中视觉表征的规律》|Shijia Yang, Bohan Zhai, Quanzeng You, Jianbo Yuan, Hongxia Yang, Chenfeng Xu|<http://arxiv.org/pdf/2408.16357v3>|揭示了多模态大语言模型中视觉表示的组合与模型性能之间的强相关性，并提出了一种降低计算成本的方法。|
|📝 更新|Towards Cross-modal Backward-compatible Representation Learning for Vision-Language Models|面向视觉语言模型的跨模态向后兼容表征学习|Young Kyun Jang, Ser-nam Lim|<http://arxiv.org/pdf/2405.14715v3>|提出了一种跨模态向后兼容的训练方法，通过映射模块实现新旧视觉语言模型兼容，减少数据重计算需求。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Safe-LLaVA: A Privacy-Preserving Vision-Language Dataset and Benchmark for Biometric Safety|《Safe-LLaVA：一个保护隐私的视觉-语言数据集和生物识别安全基准》|Younggun Kim, Sirnam Swetha, Fazil Kagdi, Mubarak Shah|<http://arxiv.org/pdf/2509.00192v2>|提出PRISM基准和Safe-LLaVA数据集，用于评估和减少多模态大语言模型中的生物特征泄露问题。|
|🆕 发布|Federated Learning for Surgical Vision in Appendicitis Classification: Results of the FedSurg EndoVis 2024 Challenge|联邦学习在阑尾炎分类的手术视觉中的应用：FedSurg EndoVis 2024挑战赛结果|Max Kirchner, Hanna Hoffmann, Alexander C. Jenke, Oliver L. Saldanha, Kevin Pfeiffer, Weam Kanjo, Julia Alekseenko, Claas de Boer .etc.|<http://arxiv.org/pdf/2510.04772v1>|该研究通过FedSurg挑战，确立了首个用于评估联邦学习在手术视频分类中的效果基准，并揭示了模型架构...|
|🆕 发布|A Comparative Study of Vision Transformers and CNNs for Few-Shot Rigid Transformation and Fundamental Matrix Estimation|《少量样本刚体变换与基础矩阵估计中视觉变换器与卷积神经网络对比研究》|Alon Kaya, Igal Bilik, Inna Stainvas|<http://arxiv.org/pdf/2510.04794v1>|比较了Vision Transformers和CNNs在少量样本下的几何估计任务表现，揭示了ViTs...|
|🆕 发布|Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction|渐进高斯变换器：具有各向异性感知采样的开放词汇占有率预测|Chi Yan, Dan Xu|<http://arxiv.org/pdf/2510.04759v1>|[代码](https://yanchi-3dv.github.io/PG-Occ); 提出渐进高斯变换框架PG-Occ，通过逐步细化3D表示和各向异性采样策略，实现了开放词汇的3D占位预...|
|📝 更新|LIAM: Multimodal Transformer for Language Instructions, Images, Actions and Semantic Maps|LIAM：用于语言指令、图像、动作和语义地图的多模态Transformer|Yihao Wang, Raphael Memmesheimer, Sven Behnke|<http://arxiv.org/pdf/2503.12230v2>|提出了一种多模态Transformer模型LIAM，通过语言、图像、动作和地图输入预测动作转录，有效...|
|📝 更新|Depth-Sequence Transformer (DST) for Segment-Specific ICA Calcification Mapping on Non-Contrast CT|用于非对比CT的段特异性ICA钙化映射的深度序列转换器（DST）|Xiangjian Hou, Ebru Yaman Akcicek, Xin Wang, Kazem Hashemizadeh, Scott Mcnally, Chun Yuan, Xiaodong Ma|<http://arxiv.org/pdf/2507.08214v3>|提出了一种深度序列变换器（DST），通过处理CT切片序列实现了高精度动脉钙化定位，为局部病变分析提供...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|What Lurks Within? Concept Auditing for Shared Diffusion Models at Scale|《共享扩散模型大规模概念审计：探寻其中隐藏的内容》|Xiaoyong Yuan, Xiaolong Ma, Linke Guo, Lan Zhang|<http://arxiv.org/pdf/2504.14815v2>|提出 Prompt-Agnostic Image-Free Auditing 方法，实现扩散模型部署...|
|📝 更新|Autonomous Imagination: Closed-Loop Decomposition of Visual-to-Textual Conversion in Visual Reasoning for Multimodal Large Language Models|自主想象：视觉推理中视觉到文本转换的闭环分解在多模态大型语言模型中的应用|Jingming Liu, Yumeng Li, Boyuan Xiao, Yichang Jian, Ziang Qin, Tianjia Shao, Yao-Xiang Ding, Kun Zhou|<http://arxiv.org/pdf/2411.18142v4>|[代码](https://future-item.github.io/autoimagine-site); 提出自主想象方法，通过迭代修改视觉输入，使多模态大语言模型能解决原本超出其感知能力的视觉任务。|
|📝 更新|Bias in Gender Bias Benchmarks: How Spurious Features Distort Evaluation|性别偏见基准中的偏见：如何伪特征扭曲评估|Yusuke Hirota, Ryo Hachiuma, Boyi Li, Ximing Lu, Michael Ross Boone, Boris Ivanovic, Yejin Choi, Marco Pavone .etc.|<http://arxiv.org/pdf/2509.07596v2>|揭示了现有性别偏见评估基准中非性别特征对评估结果的扭曲，建议通过特征敏感性测量来增强评估可靠性。|
|🆕 发布|EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents|教育个体：虚拟学生代理主观能力边界的基准测试|Buyuan Zhu, Shiyu Hu, Yiping Ma, Yuanming Zhang, Kang Hao Cheong|<http://arxiv.org/pdf/2510.04648v1>|提出首个关注学生主观能力的教育场景基准，通过分阶段任务评估模型表现，显著提升虚拟学生代理的教育互动质...|
|🆕 发布|Your Vision-Language Model Can't Even Count to 20: Exposing the Failures of VLMs in Compositional Counting|你的视觉语言模型甚至无法数到20：揭示视觉语言模型在组合计数中的失败|Xuyang Guo, Zekai Huang, Zhenmei Shi, Zhao Song, Jiahao Zhang|<http://arxiv.org/pdf/2510.04401v1>|揭示了视觉语言模型在组合计数任务中的缺陷，并提出了专门的基准测试方法来评估其计数能力。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Fine-Tuned CNN-Based Approach for Multi-Class Mango Leaf Disease Detection|基于精细调优卷积神经网络的芒果叶片多类别病害检测方法|Jalal Ahmmed, Faruk Ahmed, Rashedul Hasan Shohan, Md. Mahabub Rana, Mahdi Hasan|<http://arxiv.org/pdf/2510.05326v1>|提出了一种基于预训练卷积神经网络和迁移学习的芒果叶病害多类别检测方法，实现了99.33%的高准确率。|
|📝 更新|ViP$^2$-CLIP: Visual-Perception Prompting with Unified Alignment for Zero-Shot Anomaly Detection|ViP$^2$-CLIP：统一对齐的视觉感知提示用于零样本异常检测|Ziteng Yang, Jingzehua Xu, Yanshu Li, Zepeng Li, Yeqiang Wang, Xinghui Li|<http://arxiv.org/pdf/2505.17692v3>|提出ViP$^2$-CLIP，通过融合视觉上下文自适应生成细粒度文本提示，实现无需目标域训练样本的异...|
|🆕 发布|CLEAR-IR: Clarity-Enhanced Active Reconstruction of Infrared Imagery|结果为：CLEAR-IR：红外图像清晰度增强的主动重建|Nathan Shankar, Pawel Ladosz, Hujun Yin|<http://arxiv.org/pdf/2510.04883v1>|提出了一种基于U-Net架构的清晰度增强红外图像重建方法，有效提升了机器人感知在暗环境中的性能。|
|🆕 发布|ExposureEngine: Oriented Logo Detection and Sponsor Visibility Analytics in Sports Broadcasts|曝光引擎：定向标识检测与体育直播赞助商可见性分析|Mehdi Houshmand Sarkhoosh, Frøy Øye, Henrik Nestor Sørlie, Nam Hoang Vu, Dag Johansen, Cise Midoglu, Tomas Kupka, Pål Halvorsen|<http://arxiv.org/pdf/2510.04739v1>|提出了一种面向体育直播中赞助商可见性分析的旋转感知型标志检测系统ExposureEngine，通过预...|
|📝 更新|Leveraging Confident Image Regions for Source-Free Domain-Adaptive Object Detection|利用可靠图像区域进行无需源域的域自适应目标检测|Mohamed Lamine Mekhalfi, Davide Boscaini, Fabio Poiesi|<http://arxiv.org/pdf/2501.10081v2>|提出了一种无需源数据的数据增强方法，通过裁剪并增强目标图像中检测器置信度高的区域，实现了源无关的域自...|
|🆕 发布|SPEGNet: Synergistic Perception-Guided Network for Camouflaged Object Detection|SPEGNet：协同感知引导网络用于迷彩目标检测|Baber Jan, Saeed Anwar, Aiman H. El-Maleh, Abdul Jabbar Siddiqui, Abdul Bais|<http://arxiv.org/pdf/2510.04472v1>|[代码](https://github.com/Baber-Jan/SPEGNet); 提出了一种统一的网络架构SPEGNet，通过多尺度特征融合和边界直接生成，有效平衡了边界精度和区域一...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|No-reference Quality Assessment of Contrast-distorted Images using Contrast-enhanced Pseudo Reference|基于对比度增强伪参考的无参考图像质量评估|Mohammad-Ali Mahmoudpour, Saeed Mahmoudpour|<http://arxiv.org/pdf/2510.05053v1>|提出无参考图像质量评估方法，通过生成伪参考图像将问题转化为有参考评估，有效处理对比度失真图像质量评估...|
|📝 更新|Graph Algorithm Unrolling with Douglas-Rachford Iterations for Image Interpolation with Guaranteed Initialization|图像插值中具有初始化保证的图算法展开与Douglas-Rachford迭代|Xue Zhang, Bingshuo Hu, Gene Cheung|<http://arxiv.org/pdf/2509.11926v2>|提出了一种基于图算法展开和Douglas-Rachford迭代的图像插值方法，初始化保证性能并减少参...|
|📝 更新|MambaMoE: Mixture-of-Spectral-Spatial-Experts State Space Model for Hyperspectral Image Classification|“MambaMoE：用于高光谱图像分类的谱-空专家混合状态空间模型”|Yichu Xu, Di Wang, Hongzan Jiao, Lefei Zhang, Liangpei Zhang|<http://arxiv.org/pdf/2504.20509v2>|[代码](https://github.com/YichuXu/MambaMoE.); 提出了一种针对高光谱图像分类的混合频谱-空间专家模型，通过自适应特征建模和不确定性指导的修正学习，实...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SegMASt3R: Geometry Grounded Segment Matching|基于几何定位的片段匹配算法：SegMASt3R|Rohit Jayanti, Swayam Agrawal, Vansh Garg, Siddharth Tourani, Muhammad Haris Khan, Sourav Garg, Madhava Krishna|<http://arxiv.org/pdf/2510.05051v1>|利用3D基础模型的空间理解能力，提出了一种处理极端视角变化的图像区域匹配方法，实现了30%的性能提升...|
|🆕 发布|Anomaly-Aware YOLO: A Frugal yet Robust Approach to Infrared Small Target Detection|异常感知的YOLO：一种节俭而健壮的红外小目标检测方法|Alina Ciocarlan, Sylvie Le Hégarat-Mascle, Sidonie Lefebvre|<http://arxiv.org/pdf/2510.04741v1>|提出Anomaly-Aware YOLO方法，通过集成异常检测控制红外小目标检测中的误报率，增强鲁棒...|
|📝 更新|Novel Object 6D Pose Estimation with a Single Reference View|单视角参考下的新颖物体6D位姿估计|Jian Liu, Wei Sun, Kai Zeng, Jin Zheng, Hui Yang, Hossein Rahmani, Ajmal Mian, Lin Wang|<http://arxiv.org/pdf/2503.05578v3>|[代码](https://github.com/CNJianLiu/SinRef-6D.); 提出了一种基于单参考视角的6D姿态估计方法，通过迭代点对齐和状态空间模型，有效处理大姿态差异和空间信...|
|🆕 发布|SFANet: Spatial-Frequency Attention Network for Deepfake Detection|SFANet：用于深度伪造检测的空间-频率注意力网络|Vrushank Ahire, Aniruddh Muley, Shivam Zample, Siddharth Verma, Pranav Menon, Surbhi Madan, Abhinav Dhall|<http://arxiv.org/pdf/2510.04630v1>|提出了一种结合变换器和纹理方法的新型混合框架，有效提高了深伪检测的准确性和鲁棒性。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EMedNeXt: An Enhanced Brain Tumor Segmentation Framework for Sub-Saharan Africa using MedNeXt V2 with Deep Supervision|EMedNeXt：一种面向撒哈拉以南非洲的增强脑肿瘤分割框架，采用带有深度监督的MedNeXt V2|Ahmed Jaheen, Abdelrahman Elsayed, Damir Kim, Daniil Tikhonov, Matheus Scatolin, Mohor Banerjee, Qiankun Ji, Mostafa Salem .etc.|<http://arxiv.org/pdf/2507.23256v2>|针对撒哈拉以南非洲资源匮乏问题，提出EMedNeXt框架，通过优化网络结构和模型融合提升脑肿瘤分割精...|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Personalizing Retrieval using Joint Embeddings or "the Return of Fluffy"|个性化检索使用联合嵌入或“Fluffy的回归”|Bruno Korbar, Andrew Zisserman|<http://arxiv.org/pdf/2510.05411v1>|提出了一种映射网络pi-map，将图像实例嵌入转换为文本token，结合自然语言描述提升个性化图像检...|
|📝 更新|Anchors Aweigh! Sail for Optimal Unified Multi-Modal Representations|"锚定启航！驶向最优统一多模态表征"|Minoh Jeong, Zae Myung Kim, Min Namgung, Dongyeop Kang, Yao-Yi Chiang, Alfred Hero|<http://arxiv.org/pdf/2410.02086v3>|提出自适应锚定方法CentroBind，克服固定锚定模态依赖，提升多模态学习效率和性能。|
|🆕 发布|VChain: Chain-of-Visual-Thought for Reasoning in Video Generation|视频生成中的链式视觉思维：VChain|Ziqi Huang, Ning Yu, Gordon Chen, Haonan Qiu, Paul Debevec, Ziwei Liu|<http://arxiv.org/pdf/2510.05094v1>|引入了VChain框架，将多模态模型的视觉推理信号融入视频生成，提升了生成的视频质量。|
|🆕 发布|Character Mixing for Video Generation|视频生成中的字符混合技术|Tingting Liao, Chongjian Ge, Guangyi Liu, Hao Li, Yi Zhou|<http://arxiv.org/pdf/2510.05093v1>|[代码](https://tingtingliao.github.io/mimix); 引入了跨角色嵌入和增强技术，实现了不同风格角色间的自然互动和风格保真。|
|🆕 发布|StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation|StaMo：从紧凑状态表示中无监督学习泛化的机器人运动|Mingyu Liu, Jiuhe Shu, Hui Chen, Zeju Li, Canyu Zhao, Jiange Yang, Shenyuan Gao, Hao Chen .etc.|<http://arxiv.org/pdf/2510.05057v1>|提出了一种无监督学习框架 StaMo，通过紧凑状态表示学习通用机器人运动，提升模型性能和动作解码能力...|
|🆕 发布|Bridging Text and Video Generation: A Survey|文本与视频生成的桥梁：综述|Nilay Kumar, Priyansh Bhandari, G. Maragatham|<http://arxiv.org/pdf/2510.04999v1>|系统梳理了文本到视频生成模型的发展，提出了克服质量、连贯性和控制挑战的新架构方向。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LightCache: Memory-Efficient, Training-Free Acceleration for Video Generation|《LightCache：一种内存高效、无需训练的视频生成加速方法》|Yang Xiao, Gen Li, Kaiyuan Deng, Yushu Wu, Zheng Zhan, Yanzhi Wang, Xiaolong Ma, Bo Hui|<http://arxiv.org/pdf/2510.05367v1>|[代码](https://github.com/NKUShaw/LightCache); 提出异步缓存交换、特征分块和切片解码策略，减少视频生成过程中的内存消耗，提高推理速度。|
|🆕 发布|Pulp Motion: Framing-aware multimodal camera and human motion generation|《脉冲运动：具有帧感知的多模态相机与人体运动生成》|Robin Courant, Xi Wang, David Loiseaux, Marc Christie, Vicky Kalogeiton|<http://arxiv.org/pdf/2510.05097v1>|首次提出文本驱动的联合生成框架，实现画面内人物动作与摄像机轨迹的一致性生成。|
|📝 更新|LaB-RAG: Label Boosted Retrieval Augmented Generation for Radiology Report Generation|LaB-RAG：标签增强的检索增强生成模型用于放射科报告生成|Steven Song, Anirudh Subramanyam, Irene Madejski, Robert L. Grossman|<http://arxiv.org/pdf/2411.16523v2>|提出了一种小模型方法LaB-RAG，利用图像标签增强生成放射学报告，无需专门训练模型即可取得优异性表...|
|🆕 发布|Paper2Video: Automatic Video Generation from Scientific Papers|论文到视频：从科学论文自动生成视频|Zeyu Zhu, Kevin Qinghong Lin, Mike Zheng Shou|<http://arxiv.org/pdf/2510.05096v1>|[代码](https://github.com/showlab/Paper2Video.); 提出了一种自动从学术论文生成视频的方法，通过多代理框架有效整合内容和形式，提高了学术视频的制作效率和...|
|📝 更新|The Telephone Game: Evaluating Semantic Drift in Unified Models|《电话游戏：评估统一模型中的语义漂移》|Sabbir Mollah, Rohit Gupta, Sirnam Swetha, Qingyang Liu, Ahnaf Munir, Mubarak Shah|<http://arxiv.org/pdf/2509.04438v2>|[代码](https://github.com/mollahsabbir/Semantic-Drift-in-Unified-Models); 引入了语义漂移协议（SDP），通过循环评估统一模型在图像和文本间的语义一致性。|
|🆕 发布|Factuality Matters: When Image Generation and Editing Meet Structured Visuals|事实性至关重要：当图像生成与编辑遇到结构化视觉元素|Le Zhuo, Songhao Han, Yuandong Pu, Boxiang Qiu, Sayak Paul, Yue Liao, Yihao Liu, Jie Shao .etc.|<http://arxiv.org/pdf/2510.05091v1>|首次系统探究了结构化视觉生成与编辑难题，提出统一模型和评估基准，显著提升事实准确性。|
|🆕 发布|On Structured State-Space Duality|《论结构状态空间的对偶性》|Jerry Yao-Chieh Hu, Xiwen Zhang, Weimin Wu, Han Liu|<http://arxiv.org/pdf/2510.04944v1>|揭示了结构化状态空间模型与掩码注意力机制之间的对偶性，拓宽了高效序列模型的设计空间。|
|🆕 发布|Bidirectional Mammogram View Translation with Column-Aware and Implicit 3D Conditional Diffusion|双向乳腺X线照片视图转换：列感知与隐式三维条件扩散|Xin Li, Kaixiang Yang, Qiang Li, Zhiwei Wang|<http://arxiv.org/pdf/2510.04947v1>|提出了一种基于条件扩散模型的乳腺X光照片视图转换框架，通过列感知机制和隐式3D结构重建，有效解决了视...|
|🆕 发布|SSDD: Single-Step Diffusion Decoder for Efficient Image Tokenization|单步扩散解码器：用于高效图像标记化的方法|Théophane Vallaeys, Jakob Verbeek, Matthieu Cord|<http://arxiv.org/pdf/2510.04961v1>|提出了一种高效的图像标记化方法SSDD，通过单步解码和无需对抗训练，实现了优于传统KL-VAE的重建...|
|🆕 发布|Flow Matching for Conditional MRI-CT and CBCT-CT Image Synthesis|基于流匹配的条件性MRI-CT和CBCT-CT图像合成|Arnela Hadzic, Simon Johannes Joham, Martin Urschler|<http://arxiv.org/pdf/2510.04823v1>|采用3D Flow Matching框架，实现了从MRI或CBCT到CT的高质量图像合成，提高了放疗...|
|📝 更新|Generating Findings for Jaw Cysts in Dental Panoramic Radiographs Using GPT-4o: Building a Two-Stage Self-Correction Loop with Structured Output (SLSO) Framework|使用 GPT-4o 生成牙科全景 X 光片下颌囊肿检测结果：构建基于结构化输出（SLSO）框架的两阶段自校正循环|Nanaka Hosokawa, Ryo Takahashi, Tomoya Kitano, Yukihiro Iida, Chisako Muramatsu, Tatsuro Hayashi, Yuta Seino, Xiangrong Zhou .etc.|<http://arxiv.org/pdf/2510.02001v2>|利用GPT-4o多模态能力构建两阶段自校正循环框架，提升牙颌囊肿检测准确性。|
|📝 更新|A Survey of Defenses Against AI-Generated Visual Media: Detection,Disruption, and Authentication|《针对AI生成视觉媒体的防御方法综述：检测、干扰与认证》|Jingyi Deng, Chenhao Lin, Zhengyu Zhao, Shuai Liu, Zhe Peng, Qian Wang, Chao Shen|<http://arxiv.org/pdf/2407.10575v3>|系统综述了对抗AI生成视觉媒体的检测、干扰和认证方法，提出了统一的防御框架和未来研究方向。|
|🆕 发布|Watch and Learn: Learning to Use Computers from Online Videos|观察与学习：从在线视频中学习使用计算机|Chan Hee Song, Yiwen Song, Palash Goyal, Yu Su, Oriana Riva, Hamid Palangi, Tomas Pfister|<http://arxiv.org/pdf/2510.04673v1>|提出了一种利用网络视频生成大规模高质量UI轨迹的框架，有效提升了计算机使用代理的学习效率和泛化能力。|
|📝 更新|SEE-DPO: Self Entropy Enhanced Direct Preference Optimization|SEE-DPO：自熵增强的直接偏好优化|Shivanshu Shekhar, Shreyas Singh, Tong Zhang|<http://arxiv.org/pdf/2411.04712v2>|引入自我熵正则化机制以稳定扩散模型训练，提升图像生成质量和多样性。|
|🆕 发布|Label-Efficient Cross-Modality Generalization for Liver Segmentation in Multi-Phase MRI|跨模态少量标记肝脏分割在多相位MRI中的泛化|Quang-Khai Bui-Tran, Minh-Toan Dinh, Thanh-Huy Nguyen, Ba-Thinh Lam, Mai-Anh Vu, Ulas Bagci|<http://arxiv.org/pdf/2510.04705v1>|提出了一种高效的少标记跨模态肝脏分割方法，通过模型微调与协同训练，实现了多相位多厂商MRI数据的准确...|
|🆕 发布|ID-Consistent, Precise Expression Generation with Blendshape-Guided Diffusion|具有ID一致性、精确表情生成的Blendshape引导扩散方法|Foivos Paraperas Papantoniou, Stefanos Zafeiriou|<http://arxiv.org/pdf/2510.04706v1>|[代码](https://github.com/foivospar/Arc2Face.); 提出了一种基于扩散框架的生成模型，通过表情交叉注意力模块和Blendshape参数，实现了身份一致且...|
|📝 更新|SIA: Enhancing Safety via Intent Awareness for Vision-Language Models|意图感知增强视觉语言模型的安全性：SIA方法|Youngjin Na, Sangheon Jeong, Youngwan Lee, Jian Lee, Dawoon Jeong, Youngman Kim|<http://arxiv.org/pdf/2507.16856v2>|提出SIA框架，通过识别潜在有害意图，无需大量重训练即可提高视觉语言模型的安全性。|
|🆕 发布|Social Agent: Mastering Dyadic Nonverbal Behavior Generation via Conversational LLM Agents|社交智能体：通过对话大型语言模型智能体掌握二元非言语行为生成|Zeyi Zhang, Yanju Zhou, Heyuan Yao, Tenglong Ao, Xiaohang Zhan, Libin Liu|<http://arxiv.org/pdf/2510.04637v1>|提出Social Agent框架，通过大型语言模型和自动回归扩散模型生成逼真的对话中协调的非言语行为...|
|📝 更新|What Drives Compositional Generalization in Visual Generative Models?|视觉生成模型中驱动组合泛化的因素是什么？|Karim Farid, Rajat Sahay, Yumna Ali Alnaggar, Simon Schrodi, Volker Fischer, Cordelia Schmid, Thomas Brox|<http://arxiv.org/pdf/2510.03075v2>|探究视觉生成模型组合泛化驱动因素，提出通过调整训练目标和条件信息改善性能。|
|🆕 发布|SONA: Learning Conditional, Unconditional, and Mismatching-Aware Discriminator|SONA：学习条件型、无条件型和失配感知型判别器|Yuhta Takida, Satoshi Hayakawa, Takashi Shibuya, Masaaki Imaizumi, Naoki Murata, Bac Nguyen, Toshimitsu Uesaka, Chieh-Hsin Lai .etc.|<http://arxiv.org/pdf/2510.04576v1>|提出了一种三功能集成判别器SONA，有效平衡了生成模型中真实性和条件对齐的挑战。|
|🆕 发布|Real-time Prediction of Urban Sound Propagation with Conditioned Normalizing Flows|基于条件归一化流的实时城市声音传播预测|Achim Eckerle, Martin Spitznagel, Janis Keuper|<http://arxiv.org/pdf/2510.04510v1>|提出了一种基于条件归一化流的实时城市噪声预测方法，大幅提高了速度和准确性。|
|🆕 发布|Asynchronous Denoising Diffusion Models for Aligning Text-to-Image Generation|异步去噪扩散模型用于对齐文本到图像生成|Zijing Hu, Yunze Tong, Fengda Zhang, Junkun Yuan, Jun Xiao, Kun Kuang|<http://arxiv.org/pdf/2510.04504v1>|[代码](https://github.com/hu-zijing/AsynDM.); 提出异步去噪扩散模型，通过分配不同时间步长给不同像素，有效提升文本到图像的对齐质量。|
|📝 更新|STIV: Scalable Text and Image Conditioned Video Generation|STIV：可扩展的文本和图像条件视频生成|Zongyu Lin, Wei Liu, Chen Chen, Jiasen Lu, Wenze Hu, Tsu-Jui Fu, Jesse Allardice, Zhengfeng Lai .etc.|<http://arxiv.org/pdf/2412.07730v2>|提出了一种简单可扩展的文本和图像条件视频生成框架STIV，实现了文本到视频和图像文本到视频的生成，并...|
|🆕 发布|TBStar-Edit: From Image Editing Pattern Shifting to Consistency Enhancement|TBStar-Edit：从图像编辑模式转换到一致性增强|Hao Fang, Zechao Zhan, Weixin Feng, Ziwei Huang, XuBin Li, Tiezheng Ge|<http://arxiv.org/pdf/2510.04483v1>|提出了针对电商领域的TBStar-Edit图像编辑模型，通过数据工程和模型设计实现了精确编辑和一致性...|
|🆕 发布|REAR: Rethinking Visual Autoregressive Models via Generator-Tokenizer Consistency Regularization|REAR：通过生成器-标记器一致性正则化重新思考视觉自回归模型|Qiyuan He, Yicong Li, Haotian Ye, Jinghao Wang, Xinyao Liao, Pheng-Ann Heng, Stefano Ermon, James Zou .etc.|<http://arxiv.org/pdf/2510.04450v1>|提出了一种生成器-标记器一致性正则化策略，有效提升了视觉自回归模型的性能。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mitigating Diffusion Model Hallucinations with Dynamic Guidance|动态引导减轻扩散模型幻觉|Kostas Triaridis, Alexandros Graikos, Aggelina Chatziagapi, Grigorios G. Chrysos, Dimitris Samaras|<http://arxiv.org/pdf/2510.05356v1>|提出动态引导方法，有效减少生成过程中的虚假图像问题，保持语义多样性。|
|🆕 发布|SAEdit: Token-level control for continuous image editing via Sparse AutoEncoder|SAEdit：通过稀疏自动编码器实现连续图像编辑的标记级控制|Ronen Kamenetsky, Sara Dorfman, Daniel Garibi, Roni Paiss, Or Patashnik, Daniel Cohen-Or|<http://arxiv.org/pdf/2510.05081v1>|通过 Sparse AutoEncoder 实现对文本嵌入的细粒度操作，实现了图像编辑的解耦和连续控...|
|📝 更新|QDFlow: A Python package for physics simulations of quantum dot devices|量子点器件物理模拟的Python软件包QDFlow|Donovan L. Buterakos, Sandesh S. Kalantre, Joshua Ziegler, Jacob M Taylor, Justyna P. Zwolak|<http://arxiv.org/pdf/2509.13298v2>|QDFlow提供了一个开源物理模拟器，生成带有真实标签的量子点设备模拟数据，助力机器学习发展和量子设...|
|📝 更新|Fast constrained sampling in pre-trained diffusion models|快速约束采样在预训练扩散模型中的应用|Alexandros Graikos, Nebojsa Jojic, Dimitris Samaras|<http://arxiv.org/pdf/2410.18804v3>|[代码](https://github.com/cvlab-stonybrook/fast-constrained-sampling.); 提出了一种快速高效的算法，利用牛顿优化近似在预训练扩散模型中实现任意约束下的图像生成。|
|🆕 发布|ReactDiff: Fundamental Multiple Appropriate Facial Reaction Diffusion Model|反应差分：基础多适宜面部反应扩散模型|Luo Cheng, Song Siyang, Yan Siyuan, Yu Zhen, Ge Zongyuan|<http://arxiv.org/pdf/2510.04712v1>|提出ReactDiff模型，通过模拟人类面部行为生成逼真且多样的对话反应。|
|📝 更新|Copyright Infringement Detection in Text-to-Image Diffusion Models via Differential Privacy|通过差分隐私在文本到图像扩散模型中检测版权侵犯|Xiafeng Man, Zhipeng Wei, Jingjing Chen|<http://arxiv.org/pdf/2509.23022v2>|提出基于差分隐私的检测框架D-Plus-Minus，有效识别文本到图像生成模型中的版权侵犯内容。|
|🆕 发布|ConceptSplit: Decoupled Multi-Concept Personalization of Diffusion Models via Token-wise Adaptation and Attention Disentanglement|概念拆分：通过标记适配与注意力解耦实现扩散模型的多概念解耦个性化|Habin Lim, Yeongseob Won, Juwon Seo, Gyeong-Moon Park|<http://arxiv.org/pdf/2510.04668v1>|[代码](https://github.com/KU-VGI/ConceptSplit); 提出了一种名为ConceptSplit的框架，通过Token-wise Value Adaptati...|
|📝 更新|CoralSCOP-LAT: Labeling and Analyzing Tool for Coral Reef Images with Dense Mask|珊瑚SCOP-LAT：用于密集遮罩珊瑚礁图像的标注与分析工具|Yuk-Kwan Wong, Ziqiang Zheng, Mingzhe Zhang, David Suggett, Sai-Kit Yeung|<http://arxiv.org/pdf/2410.20436v2>|[代码](https://github.com/ykwongaq/CoralSCOP-LAT.); 提出CoralSCOP-LAT工具，自动分割和分析珊瑚图像，大幅提升标注效率和精度。|
|🆕 发布|Pathology-CoT: Learning Visual Chain-of-Thought Agent from Expert Whole Slide Image Diagnosis Behavior|病理学-CoT：从专家全切片图像诊断行为中学习视觉思维链代理|Sheng Wang, Ruiming Wu, Charles Herndon, Yihang Liu, Shunsuke Koga, Jeanne Shen, Zhi Huang|<http://arxiv.org/pdf/2510.04587v1>|提出AI Session Recorder记录专家诊断行为，构建Pathologist-o3模型实现...|
|🆕 发布|C3Editor: Achieving Controllable Consistency in 2D Model for 3D Editing|C3Editor：在3D编辑中实现2D模型的可控一致性|Zeng Tao, Zheng Ding, Zeyuan Chen, Xiang Zhang, Leizhi Li, Zhuowen Tu|<http://arxiv.org/pdf/2510.04539v1>|提出了C3Editor框架，通过建立视图一致的2D编辑模型，实现了更一致和可控的2D和3D编辑效果。|
|📝 更新|Do We Need All the Synthetic Data? Targeted Synthetic Image Augmentation via Diffusion Models|我们需要所有的合成数据吗？通过扩散模型进行针对性合成图像增强|Dang Nguyen, Jiping Li, Jinghao Zheng, Baharan Mirzasoleiman|<http://arxiv.org/pdf/2505.21574v2>|提出针对训练早期未学习数据的合成图像增强策略，以少量高质量图像提升模型泛化能力。|
|🆕 发布|TAG:Tangential Amplifying Guidance for Hallucination-Resistant Diffusion Sampling|切向放大引导：用于抗幻觉扩散采样的方法|Hyunmin Cho, Donghoon Ahn, Susung Hong, Jee Eun Kim, Seungryong Kim, Kyong Hwan Jin|<http://arxiv.org/pdf/2510.04533v1>|提出了一种高效的图像生成引导方法TAG，通过直接操作轨迹信号来减少扩散模型中的幻觉现象，提高样本质量...|
|📝 更新|Divergence Minimization Preference Optimization for Diffusion Model Alignment|扩散模型对齐的分歧最小化偏好优化|Binxu Li, Minkai Xu, Jiaqi Han, Meihua Dang, Stefano Ermon|<http://arxiv.org/pdf/2507.07510v2>|提出基于反向KL散度最小化的DMPO方法，有效优化扩散模型与人类偏好对齐。|
|📝 更新|FEB-Cache: Frequency-Guided Exposure Bias Reduction for Enhancing Diffusion Transformer Caching|频率引导曝光偏差减少以增强扩散变换器缓存的FEB-Cache方法|Zhen Zou, Feng Zhao|<http://arxiv.org/pdf/2503.07120v3>|[代码](https://github.com/aSleepyTree/EB-Cache.); 提出频率引导的FEB-Cache策略，优化了DiT模型缓存机制，减少曝光偏差，提升生成质量与效率。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|UniUIR: Considering Underwater Image Restoration as An All-in-One Learner|统一水下图像复原：将水下图像复原视为一体化学习器|Xu Zhang, Huan Zhang, Guoli Wang, Qian Zhang, Lefei Zhang, Bo Du|<http://arxiv.org/pdf/2501.12981v2>|提出了一种全面的水下图像复原方法UniUIR，通过混合专家模块和深度信息处理复杂退化问题。|
|🆕 发布|3Dify: a Framework for Procedural 3D-CG Generation Assisted by LLMs Using MCP and RAG|“3Dify：一种基于大规模语言模型辅助的MCP和RAG流程化3D计算机生成框架”|Shun-ichiro Hayashi, Daichi Mukunoki, Tetsuya Hoshino, Satoshi Ohshima, Takahiro Katagiri|<http://arxiv.org/pdf/2510.04536v1>|提出3Dify框架，利用大型语言模型通过自然语言指令生成3D计算机图形内容。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Human + AI for Accelerating Ad Localization Evaluation|结果：人类 + 人工智能加速广告定位评估|Harshit Rajgarhia, Shivali Dalmia, Mengyang Zhao, Mukherji Abhishek, Kiran Ganesh|<http://arxiv.org/pdf/2509.12543v3>|提出结合自动化与人工监督的框架，优化广告本地化评估流程，实现视觉一致性和风格完整性。|
|🆕 发布|BenthiCat: An opti-acoustic dataset for advancing benthic classification and habitat mapping|ベント希猫：一种用于推进海底分类和栖息地制图的光声数据集|Hayat Rajani, Valerio Franchi, Borja Martinez-Clavel Valles, Raimon Ramos, Rafael Garcia, Nuno Gracias|<http://arxiv.org/pdf/2510.04876v1>|介绍了首个大规模多模态海洋底质分类数据集，推动自主水下底质分类与多传感器融合研究。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Survey on 3D Gaussian Splatting|三维高斯散点绘制综述|Guikun Chen, Wenguan Wang|<http://arxiv.org/pdf/2401.03890v8>|系统综述了3D Gaussian Splatting技术，实现实时渲染与高编辑性，推动3D场景重建与...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AvatarVTON: 4D Virtual Try-On for Animatable Avatars|AvatarVTON：可动画化虚拟形象的4D虚拟试穿|Zicheng Jiang, Jixin Gao, Shengfeng He, Xinzhe Li, Yulong Zheng, Zhaotong Yang, Junyu Dong, Yong Du|<http://arxiv.org/pdf/2510.04822v1>|提出AvatarVTON框架，实现单视角下的4D虚拟试衣，支持自由姿态控制和多样服装选择。|
|📝 更新|Explaining Human Preferences via Metrics for Structured 3D Reconstruction|通过度量结构化三维重建来解释人类偏好|Jack Langerman, Denys Rozumnyi, Yuzhong Huang, Dmytro Mishkin|<http://arxiv.org/pdf/2503.08208v2>|[代码](https://github.com/s23dr/wireframe-metrics-iccv2025); 提出了一套评估结构化3D重建的自动化指标，并通过专家偏好分析提出了一种学习型指标。|
|🆕 发布|Benchmark on Monocular Metric Depth Estimation in Wildlife Setting|单目测距深度估计在野生动物环境中的基准测试|Niccolò Niccoli, Lorenzo Seidenari, Ilaria Greco, Francesco Rovero|<http://arxiv.org/pdf/2510.04723v1>|建立了首个针对野生动物环境下单目测距的基准，评估了四种先进方法并指导了深度估计在保护监测中的应用。|
|📝 更新|TimeFormer: Capturing Temporal Relationships of Deformable 3D Gaussians for Robust Reconstruction|时间形变者：捕捉可变形三维高斯分布的时序关系以实现鲁棒重建|DaDong Jiang, Zhihui Ke, Xiaobo Zhou, Zhi Hou, Xianghui Yang, Wenbo Hu, Tie Qiu, Chunchao Guo|<http://arxiv.org/pdf/2411.11941v2>|[代码](https://patrickddj.github.io/TimeFormer); 提出TimeFormer模块，通过学习动态场景中3D高斯ians的时序关系，增强复杂动态场景的重建效...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VidGuard-R1: AI-Generated Video Detection and Explanation via Reasoning MLLMs and RL|VidGuard-R1：基于推理大规模语言模型和强化学习的AI生成视频检测与解释|Kyoungjun Park, Yifan Yang, Juheon Yi, Shicheng Zheng, Yifei Shen, Dongqi Han, Caihua Shan, Muhammad Muaz .etc.|<http://arxiv.org/pdf/2510.02282v2>|VidGuard-R1通过优化多模态大语言模型，实现了对AI生成视频的高效检测与可解释性判断。|
|🆕 发布|A.I.R.: Enabling Adaptive, Iterative, and Reasoning-based Frame Selection For Video Question Answering|"A.I.R.: 为视频问答实现自适应、迭代和基于推理的帧选择"|Yuanhao Zou, Shengji Jin, Andong Deng, Youpeng Zhao, Jun Wang, Chen Chen|<http://arxiv.org/pdf/2510.04428v1>|提出了一种自适应、迭代和基于推理的帧选择方法A.I.R.，有效平衡了视频问答中计算效率与准确性的矛盾...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Latent Uncertainty Representations for Video-based Driver Action and Intention Recognition|视频驱动的驾驶员行为与意图识别的潜在不确定性表征|Koen Vellenga, H. Joe Steinhauer, Jonas Andersson, Anders Sjögren|<http://arxiv.org/pdf/2510.05006v1>|提出了一种通过增加变换层来估计不确定性的方法，提高了视频驱动的驾驶员行为和意图识别的效率和准确性。|
|🆕 发布|Read the Room: Inferring Social Context Through Dyadic Interaction Recognition in Cyber-physical-social Infrastructure Systems|“读懂房间：通过赛博-物理-社会基础设施系统中的成对交互识别推断社交情境”|Cheyu Lin, John Martins, Katherine A. Flanigan, Ph. D|<http://arxiv.org/pdf/2510.04854v1>|提出了一种利用深度传感器和骨骼运动分析来识别两人互动的方法，以促进理解和测量社会行为。|
|🆕 发布|From Actions to Kinesics: Extracting Human Psychological States through Bodily Movements|从行为到肢体语言：通过身体运动提取人类心理状态|Cheyu Lin, Katherine A. Flanigan|<http://arxiv.org/pdf/2510.04844v1>|提出了一种从3D人体动作数据推断心理状态的框架，通过结合深度学习技术保护隐私并提高模型泛化能力。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SkinMap: Weighted Full-Body Skin Segmentation for Robust Remote Photoplethysmography|《SkinMap：用于鲁棒远程光电容积描记法的加权全身皮肤分割》|Zahra Maleki, Amirhossein Akbari, Amirhossein Binesh, Babak Khalaj|<http://arxiv.org/pdf/2510.05296v1>|提出了一种加权全身皮肤分割技术，增强了远程光电容积描记术的信号质量并提高了对不同肤色和动态条件下的心...|
|🆕 发布|Exploring the Efficacy of Modified Transfer Learning in Identifying Parkinson's Disease Through Drawn Image Patterns|探究改进迁移学习在通过绘制图像模式识别帕金森病中的有效性|Nabil Daiyan, Md Rakibul Haque|<http://arxiv.org/pdf/2510.05015v1>|提出了一种基于机器学习和图像识别的帕金森病早期诊断方法，通过手绘螺旋和波浪图像实现高准确率检测。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MoME: Estimating Psychological Traits from Gait with Multi-Stage Mixture of Movement Experts|多阶段动作专家混合模型（MoME）：基于步态估计心理特征|Andy Cǎtrunǎ, Adrian Cosma, Emilian Rǎdoi|<http://arxiv.org/pdf/2510.04654v2>|提出了一种多阶段运动专家混合架构，通过步态预测心理特征，实现了优于现有方法的性能。|
|🆕 发布|DeepAf: One-Shot Spatiospectral Auto-Focus Model for Digital Pathology|深度自动对焦：数字病理学中的单次空间光谱自动对焦模型|Yousef Yeganeh, Maximilian Frantzen, Michael Lee, Kun-Hsing Yu, Nassir Navab, Azade Farshad|<http://arxiv.org/pdf/2510.05315v1>|提出了一种单次拍摄的自动对焦模型DeepAf，通过结合空间和光谱特征，大幅减少了对焦时间并提高了对焦...|
|🆕 发布|Beyond Monolithic Rewards: A Hybrid and Multi-Aspect Reward Optimization for MLLM Alignment|超越单一奖励：面向多模态语言模型对齐的混合多方面奖励优化|Radha Gulhane, Sathish Reddy Indurthi|<http://arxiv.org/pdf/2510.05283v1>|提出了一种融合模型和规则基础的混合奖励框架，通过多方面奖励优化，显著提升了多模态大语言模型与人类偏好...|
|📝 更新|RowDetr: End-to-End Crop Row Detection Using Polynomials|《RowDetr：使用多项式实现端到端的作物行列检测》|Rahul Harsha Cheppally, Ajay Sharda|<http://arxiv.org/pdf/2412.10525v3>|提出RowDetr，一种基于多项式参数化的端到端作物行列检测方法，提高了检测精度并实现了实时性能。|
|🆕 发布|ERDE: Entropy-Regularized Distillation for Early-exit|ERDE：基于熵正则化的早期退出蒸馏方法|Martial Guidez, Stefan Duffner, Yannick Alpou, Oscar Röth, Christophe Garcia|<http://arxiv.org/pdf/2510.04856v1>|提出熵正则化知识蒸馏方法，优化早退出模型的训练，平衡准确性与效率。|
|🆕 发布|Beyond Random: Automatic Inner-loop Optimization in Dataset Distillation|超越随机：数据集精炼中的自动内循环优化|Muquan Li, Hang Gou, Dongyang Zhang, Shuang Liang, Xiurui Xie, Deqiang Ouyang, Ke Qin|<http://arxiv.org/pdf/2510.04838v1>|提出自适应截断策略AT-BPTT优化数据集精简，提升模型性能并减少计算成本。|
|🆕 发布|Beyond Appearance: Transformer-based Person Identification from Conversational Dynamics|超越外观：基于Transformer的对话动态中的人体识别|Masoumeh Chapariniya, Teodora Vukovic, Sarah Ebling, Volker Dellwo|<http://arxiv.org/pdf/2510.04753v1>|提出了一种基于Transformer架构的两人对话中身份识别方法，通过空间配置和多层次时间动态建模实...|
|📝 更新|Neural Brain: A Neuroscience-inspired Framework for Embodied Agents|神经脑：一种受神经科学启发的具身智能体框架|Jian Liu, Xiongtao Shi, Thai Duy Nguyen, Haitian Zhang, Tianxiang Zhang, Wei Sun, Yanjie Li, Athanasios V. Vasilakos .etc.|<http://arxiv.org/pdf/2505.07634v3>|提出了一种生物启发架构，为具身智能体打造了集成多模态感知、认知行动功能和神经形态优化的大脑框架，以实...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RegMix: Adversarial Mutual and Generalization Regularization for Enhancing DNN Robustness|RegMix：对抗性互信息和泛化正则化增强深度神经网络鲁棒性|Zhenyu Liu, Varun Ojha|<http://arxiv.org/pdf/2510.05317v1>|提出两种新正则化策略，通过优化对抗训练中的损失函数，有效增强深度神经网络对抗性鲁棒性。|
|📝 更新|RealKIE: Five Novel Datasets for Enterprise Key Information Extraction|《RealKIE：面向企业关键信息提取的五个新颖数据集》|Benjamin Townsend, Madison May, Katherine Mackowiak, Christopher Wells|<http://arxiv.org/pdf/2403.20101v2>|[代码](https://indicodatasolutions.github.io/RealKIE); 提出五个面向企业应用的挑战性数据集RealKIE，助力关键信息提取技术发展。|
|📝 更新|Attention, Please! Revisiting Attentive Probing Through the Lens of Efficiency|请注意！从效率角度重新审视注意力探测|Bill Psomas, Dionysis Christopoulos, Eirini Baltzi, Ioannis Kakogeorgiou, Tilemachos Aravanis, Nikos Komodakis, Konstantinos Karantzalos, Yannis Avrithis .etc.|<http://arxiv.org/pdf/2506.10178v2>|[代码](https://github.com/billpsomas/efficient-probing.); 提出了一种高效的注意力探测方法EP，减少了参数数量并提升了模型性能。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Detailed Aerial Mapping of Photovoltaic Power Plants Through Semantically Significant Keypoints|通过语义显著关键点进行光伏电站的详细航空测绘|Viktor Kozák, Jan Chudoba, Libor Přeučil|<http://arxiv.org/pdf/2510.04840v1>|提出了一种基于视觉关键点的自动化光伏电站详细映射方法，无需第三方数据即可实现精确建模。|
|🆕 发布|Did you just see that? Arbitrary view synthesis for egocentric replay of operating room workflows from ambient sensors|“您刚刚看到那了吗？利用环境传感器实现第一视角手术室工作流程回放中的任意视角合成”|Han Zhang, Lalithkumar Seenivasan, Jose L. Porras, Roger D. Soberanis-Mukul, Hao Ding, Hongchao Shu, Benjamin D. Killeen, Ankita Ghosh .etc.|<http://arxiv.org/pdf/2510.04802v1>|提出EgoSurg框架，通过固定摄像头视频重建任意手术室人员的动态主观视角，增强手术流程的可视化与分...|
|📝 更新|Poisson multi-Bernoulli mixture filter for trajectory measurements|泊松多伯努利混合滤波器在轨迹测量中的应用|Marco Fontana, Ángel F. García-Fernández, Simon Maskell|<http://arxiv.org/pdf/2504.08421v2>|提出了一种基于Poisson multi-Bernoulli混合模型的滤波器，用于处理基于轨迹测量的...|
|📝 更新|WetCat: Enabling Automated Skill Assessment in Wet-Lab Cataract Surgery Videos|《湿猫：实现湿实验室白内障手术视频中的自动化技能评估》|Negin Ghamsarian, Raphael Sznitman, Klaus Schoeffmann, Jens Kowal|<http://arxiv.org/pdf/2506.08896v4>|提出首个针对湿实验室白内障手术视频的自动化技能评估数据集，提高了手术训练效率与客观性。|
|🆕 发布|Post-training quantization of vision encoders needs prefixing registers|训练后视觉编码器的量化需要前缀寄存器|Seunghyeon Kim, Jinho Kim, Taesun Yeom, Wonpyo Park, Kyuyeun Kim, Jaeho Lee|<http://arxiv.org/pdf/2510.04547v1>|提出RegCache算法，通过引入无意义的prefix tokens减少视觉编码器中的异常值，实现高...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Accuracy-Robustness Trade Off via Spiking Neural Network Gradient Sparsity Trail|通过尖峰神经网络梯度稀疏性轨迹实现准确性与鲁棒性的权衡|Nhan T. Luu|<http://arxiv.org/pdf/2509.23762v2>|发现脉冲神经网络在特定架构下自然具有稀疏梯度，实现了无需额外正则化的先进对抗防御性能。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OpenFake: An Open Dataset and Platform Toward Real-World Deepfake Detection|开放伪造数据集：面向现实世界深度伪造检测的开源数据集与平台|Victor Livernoche, Akshatha Arodi, Andreea Musulan, Zachary Yang, Adam Salvail, Gaétan Marceau Caron, Jean-François Godbout, Reihaneh Rabbany|<http://arxiv.org/pdf/2509.09495v2>|提出开放数据集OpenFake，助力提升现代高仿真深伪检测性能，并通过众包平台持续更新。|
|📝 更新|Conformal Prediction for Long-Tailed Classification|长尾分类的保角预测|Tiffany Ding, Jean-Baptiste Fermanian, Joseph Salmon|<http://arxiv.org/pdf/2507.06867v2>|提出了一种针对长尾分布分类问题的方法，平衡了预测集的大小和类条件覆盖率。|
|🆕 发布|Hands-Free Heritage: Automated 3D Scanning for Cultural Heritage Digitization|"无需手动干预的遗产数字化：文化遗产自动三维扫描"|Javed Ahmad, Federico Dassiè, Selene Frascella, Gabriele Marchello, Ferdinando Cannella, Arianna Traviglia|<http://arxiv.org/pdf/2510.04781v1>|实现了无需手动干预的自动化双机器人3D扫描系统，大幅提升文化遗产数字化精度和效率。|
|🆕 发布|Beyond the Seen: Bounded Distribution Estimation for Open-Vocabulary Learning|《超越所见：面向开放词汇学习的有界分布估计》|Xiaomeng Fan, Yuchuan Mao, Zhi Gao, Yuwei Wu, Jin Chen, Yunde Jia|<http://arxiv.org/pdf/2510.04770v1>|提出了一种生成未见类别数据的方法来估计开放环境下的数据分布，有效控制了估计误差。|
|🆕 发布|Partial Information Decomposition via Normalizing Flows in Latent Gaussian Distributions|通过在潜在高斯分布中应用归一化流进行部分信息分解|Wenyuan Zhao, Adithya Balachandran, Chao Tian, Paul Pu Liang|<http://arxiv.org/pdf/2510.04417v1>|提出了一种基于正则化流的梯度算法，有效解决了连续高维模态信息的部分信息分解问题。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Deep Learning Approaches with Explainable AI for Differentiating Alzheimer Disease and Mild Cognitive Impairment|深度学习方法结合可解释人工智能区分阿尔茨海默病与轻度认知障碍|Fahad Mostafa, Kannon Hossain, Hafiz Khan|<http://arxiv.org/pdf/2510.00048v2>|提出了一种结合深度学习和解释性AI的框架，准确区分阿尔茨海默病与轻度认知障碍，实现了99.21%的分...|
|🆕 发布|Attention-Enhanced Prototypical Learning for Few-Shot Infrastructure Defect Segmentation|基于注意力增强的原型学习用于少量样本基础设施缺陷分割|Christina Thrainer, Md Meftahul Ferdaus, Mahdi Abdelguerfi, Christian Guetl, Steven Sloan, Kendall N. Niles, Ken Pathak|<http://arxiv.org/pdf/2510.05266v1>|提出了一种基于原型学习和注意力机制的框架，有效提升了少量样本下基础设施缺陷分割的性能。|
|🆕 发布|Unsupervised Active Learning via Natural Feature Progressive Framework|无监督主动学习通过自然特征渐进框架|Yuxi Liu, Catherine Lalman, Yimin Yang|<http://arxiv.org/pdf/2510.04939v1>|提出了一种自然特征渐进框架的半监督学习方法，通过有效量化样本对模型性能的贡献，大幅超越现有无监督主动...|
|📝 更新|A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation|两位专家的故事：无需源域数据的无监督域自适应合作学习|Jiaping Yu, Muli Yang, Jiapeng Ji, Jiexi Yan, Cheng Deng|<http://arxiv.org/pdf/2509.22229v2>|提出了一种无源域自适应方法EXCL，通过双专家框架和优化管道挖掘目标数据潜在结构，实现无需源数据即可...|
|🆕 发布|In-Field Mapping of Grape Yield and Quality with Illumination-Invariant Deep Learning|《利用光照不变深度学习进行田间葡萄产量与品质映射》|Ciem Cornelissen, Sander De Coninck, Axel Willekens, Sam Leroux, Pieter Simoens|<http://arxiv.org/pdf/2510.04864v1>|提出了一种物联网驱动的机器人系统，通过光照不变性深度学习实现葡萄产量和质量的高分辨率实时映射。|
|📝 更新|TACO: Enhancing Multimodal In-context Learning via Task Mapping-Guided Sequence Configuration|TACO：通过任务映射引导的序列配置增强多模态情境学习|Yanshu Li, Jianjiang Yang, Tian Yun, Pinyuan Feng, Jinfa Huang, Ruixiang Tang|<http://arxiv.org/pdf/2505.17098v3>|提出TACO模型，通过任务感知注意力动态优化多模态序列，提升大型视觉语言模型在复杂任务中的表现。|
|🆕 发布|Object-Centric Representation Learning for Enhanced 3D Scene Graph Prediction|面向对象的表示学习用于增强三维场景图预测|KunHo Heo, GiHyun Kim, SuYeon Kim, MyeongAh Cho|<http://arxiv.org/pdf/2510.04714v1>|[代码](https://github.com/VisualScienceLab-KHU/OCRL-3DSSG-Codes.); 提出了一种针对物体特征的高区分度编码器，通过对比预训练策略提升3D场景图预测准确性。|
|🆕 发布|Conditional Representation Learning for Customized Tasks|条件表示学习用于定制化任务|Honglin Liu, Chao Sun, Peng Hu, Yunfan Li, Xi Peng|<http://arxiv.org/pdf/2510.04564v1>|[代码](https://github.com/XLearning-SCU/2025-NeurIPS-CRL.); 提出了一种条件表示学习方法，通过生成描述性文本构建特定任务的特征空间，有效提升定制化任务的性能。|
|📝 更新|Fast-RF-Shimming: Accelerate RF Shimming in 7T MRI using Deep Learning|快速射频匀场：使用深度学习加速7T MRI中的射频匀场过程|Zhengyi Lu, Hao Liang, Ming Lu, Xiao Wang, Xinqiang Yan, Yuankai Huo|<http://arxiv.org/pdf/2501.12157v2>|提出Fast-RF-Shimming方法，利用深度学习大幅加快7T MRI射频匀场速度，提升图像质量...|
|🆕 发布|CodeFormer++: Blind Face Restoration Using Deformable Registration and Deep Metric Learning|代码前者++：使用可变形注册和深度度量学习进行盲目人脸修复|Venkata Bharath Reddy Reddem, Akshay P Sarashetti, Ranjith Merugu, Amit Satish Unde|<http://arxiv.org/pdf/2510.04410v1>|CodeFormer++通过可变形注册和深度度量学习，实现了高质量且身份一致的脸部修复。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|One Patch to Caption Them All: A Unified Zero-Shot Captioning Framework|一贴以概括全局：统一零样本图像字幕生成框架|Lorenzo Bianchi, Giacomo Pacini, Fabio Carrara, Nicola Messina, Giuseppe Amato, Fabrizio Falchi|<http://arxiv.org/pdf/2510.02898v2>|提出了一种基于图像局部区域的零样本图像描述框架，通过聚合不同图像块实现灵活的区域描述。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Optimal Transport for Brain-Image Alignment: Unveiling Redundancy and Synergy in Neural Information Processing|最优传输在脑图像对齐中的应用：揭示神经信息处理中的冗余与协同作用|Yang Xiao, Wang Lu, Jie Ji, Ruimeng Ye, Gen Li, Xiaolong Ma, Bo Hui|<http://arxiv.org/pdf/2503.10663v2>|[代码](https://github.com/NKUShaw/OT-Alignment4brain-to-image.); 利用最优传输理论提升脑信号与图像的匹配精度，揭示了脑信息处理的冗余与协同效应。|
|🆕 发布|ActiveMark: on watermarking of visual foundation models via massive activations|ActiveMark：通过大量激活对视觉基础模型进行水印标记|Anna Chistyakova, Mikhail Pautov|<http://arxiv.org/pdf/2510.04966v1>|提出了一种在视觉基础模型中嵌入数字水印的方法，有效实现了模型所有权的验证。|
|📝 更新|MMLongBench: Benchmarking Long-Context Vision-Language Models Effectively and Thoroughly|MMLongBench：有效且全面地评估长上下文视觉-语言模型的基准测试|Zhaowei Wang, Wenhao Yu, Xiyu Ren, Jipeng Zhang, Yu Zhao, Rohit Saxena, Liang Cheng, Ginny Wong .etc.|<http://arxiv.org/pdf/2505.10610v3>|提出了MMLongBench基准，全面评估长上下文视觉语言模型的性能。|
|📝 更新|PRO-VPT: Distribution-Adaptive Visual Prompt Tuning via Prompt Relocation|PRO-VPT：通过提示重新定位的分布自适应视觉提示微调|Chikai Shang, Mengke Li, Yiqun Zhang, Zhen Chen, Jinlin Wu, Fangqing Gu, Yang Lu, Yiu-ming Cheung|<http://arxiv.org/pdf/2503.06901v2>|[代码](https://github.com/ckshang/PRO-VPT.); 提出了一种自适应调整视觉提示分布的方法PRO-VPT，通过迭代优化提示位置，显著提升了预训练模型在下...|
|🆕 发布|ChartAgent: A Multimodal Agent for Visually Grounded Reasoning in Complex Chart Question Answering|ChartAgent：一种用于复杂数据图表问题回答的可视化基础推理多模态智能体|Rachneet Kaur, Nishan Srishankar, Zhen Zeng, Sumitra Ganesh, Manuela Veloso|<http://arxiv.org/pdf/2510.04514v1>|ChartAgent通过直接在图表空间域进行视觉推理，有效解决了复杂图表问题回答中的视觉理解挑战。|
|🆕 发布|VaseVQA-3D: Benchmarking 3D VLMs on Ancient Greek Pottery|《VaseVQA-3D：在古希腊陶器上对三维视觉语言模型的基准测试》|Nonghai Zhang, Zeyu Zhang, Jiazi Wang, Yang Zhao, Hao Tang|<http://arxiv.org/pdf/2510.04479v1>|提出了VaseVQA-3D数据集和VaseVLM模型，提升了古希腊陶器3D模型的分析能力。|
|📝 更新|SIRI-Bench: Challenging VLMs' Spatial Intelligence through Complex Reasoning Tasks|SIRI-Bench：通过复杂推理任务挑战视觉语言模型的空间智能|Zijian Song, Xiaoxin Lin, Qiuming Huang, Guangrun Wang, Liang Lin|<http://arxiv.org/pdf/2506.14512v2>|提出SIRI-Bench基准，通过复杂空间推理任务评估和提升视觉语言模型的空间智能。|
|📝 更新|VirDA: Reusing Backbone for Unsupervised Domain Adaptation with Visual Reprogramming|VirDA：利用视觉重编程重用主干网络进行无监督领域自适应|Duy Nguyen, Dat Nguyen|<http://arxiv.org/pdf/2510.01660v3>|提出了一种利用视觉重编程层进行无监督域自适应的方法，避免了对已有骨干网络的参数调整，实现了参数的高效...|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|See the past: Time-Reversed Scene Reconstruction from Thermal Traces Using Visual Language Models|看到过去：使用视觉语言模型从热迹中逆向重构场景时间序列|Kebin Contreras, Luis Toscano-Palomino, Mauro Dalla Mura, Jorge Bacca|<http://arxiv.org/pdf/2510.05408v1>|提出了一种结合视觉语言模型和约束扩散过程的逆向时间重构框架，从热成像中恢复数秒前的场景状态。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Tables Guide Vision: Learning to See the Heart through Tabular Data|表格引导视觉：通过表格数据学习观察核心|Marta Hasny, Maxime Di Folco, Keno Bressem, Julia Schnabel|<http://arxiv.org/pdf/2503.14998v2>|提出了一种利用表格数据指导的对比学习框架，通过临床相关属性提高心血管疾病图像的语义表示学习效果。|
|🆕 发布|Neuroplastic Modular Framework: Cross-Domain Image Classification of Garbage and Industrial Surfaces|神经可塑性模块化框架：垃圾与工业表面跨域图像分类|Debojyoti Ghosh, Soumya K Ghosh, Adrijit Goswami|<http://arxiv.org/pdf/2510.05071v1>|提出了一种自适应的神经塑性模块分类器，通过动态扩展学习模块提升动态环境下图像分类的准确性和适应性。|
|📝 更新|RAM-W600: A Multi-Task Wrist Dataset and Benchmark for Rheumatoid Arthritis|RAM-W600：一种多任务手腕数据集和类风湿性关节炎基准|Songxiao Yang, Haolin Wang, Yao Fu, Ye Tian, Tamotsu Kamishima, Masayuki Ikebe, Yafei Ou, Masatoshi Okutomi|<http://arxiv.org/pdf/2507.05193v3>|提出首个公开的腕部骨骼实例分割数据集，助力类风湿关节炎的计算机辅助诊断研究。|
|🆕 发布|REN: Anatomically-Informed Mixture-of-Experts for Interstitial Lung Disease Diagnosis|REN：基于解剖信息的多专家混合模型用于间质性肺病诊断|Alec K. Peltekian, Halil Ertugrul Aktas, Gorkem Durak, Kevin Grudzinski, Bradford C. Bemiss, Carrie Richardson, Jane E. Dematte, G. R. Scott Budinger .etc.|<http://arxiv.org/pdf/2510.04923v1>|提出了一种针对医学图像分类的解剖信息指导的混合专家网络，通过专门化子网络精确建模区域特异性病理变化，...|
|🆕 发布|Comparative Analysis of YOLOv5, Faster R-CNN, SSD, and RetinaNet for Motorbike Detection in Kigali Autonomous Driving Context|《在基加利自动驾驶环境中对YOLOv5、Faster R-CNN、SSD和RetinaNet摩托车检测的比较分析》|Ngeyen Yinkfu, Sunday Nwovu, Jonathan Kayizzi, Angelique Uwamahoro|<http://arxiv.org/pdf/2510.04912v1>|比较了四种目标检测模型在卢旺达基加利摩托车检测中的应用效果，推荐了适合资源受限环境的简化架构。|
|🆕 发布|μDeepIQA: deep learning-based fast and robust image quality assessment with local predictions for optical microscopy|μDeepIQA：基于深度学习的快速稳健光学显微镜图像质量评估方法，采用局部预测|Elena Corbetta, Thomas Bocklitz|<http://arxiv.org/pdf/2510.04859v1>|提出了一种基于深度学习的快速稳健图像质量评估方法，适用于光学显微镜图像，实现局部质量预测并提供稳定性...|
|📝 更新|Medical Image Classification with KAN-Integrated Transformers and Dilated Neighborhood Attention|带有KAN集成的变换器和扩张邻域注意力的医学图像分类|Omid Nejati Manzari, Hojat Asgariandehkordi, Taha Koleilat, Yiming Xiao, Hassan Rivaz|<http://arxiv.org/pdf/2502.13693v3>|提出MedViTV2架构，融合KAN层和 Dilated Neighborhood Attentio...|
|📝 更新|CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification|CBVLM：无需训练的可解释概念基大型视觉语言模型用于医学图像分类|Cristiano Patrício, Isabel Rio-Torto, Jaime S. Cardoso, Luís F. Teixeira, João C. Neves|<http://arxiv.org/pdf/2501.12266v3>|[代码](https://cristianopatricio.github.io/CBVLM); 提出CBVLM方法，利用大型视觉语言模型实现少量标注数据的医学图像分类并保持可解释性。|
|📝 更新|Filling of incomplete sinograms from sparse PET detector configurations using a residual U-Net|使用残差U-Net从稀疏PET探测器配置填充不完整正弦图|Klara Leffler, Luigi Tommaso Luppino, Samuel Kuttner, Karin Söderkvist, Jan Axelsson|<http://arxiv.org/pdf/2506.19600v2>|提出了一种深度学习网络，通过恢复缺失的sinogram数据，有效补偿稀疏PET探测器配置导致的图像质...|
|🆕 发布|Do Superpixel Segmentation Methods Influence Deforestation Image Classification?|超像素分割方法是否影响森林砍伐图像分类？|Hugo Resende, Fabio A. Faria, Eduardo B. Neto, Isabela Borlido, Victor Sundermann, Silvio Jamil F. Guimarães, Álvaro L. Fazenda|<http://arxiv.org/pdf/2510.04645v1>|探究不同超像素分割方法对森林砍伐检测模型性能的影响，发现结合多种分类器可提升准确度。|
|🆕 发布|Fast Witness Persistence for MRI Volumes via Hybrid Landmarking|通过混合标记实现MRI体积快速见证持久性|Jorge Leonardo Ruiz Williams|<http://arxiv.org/pdf/2510.04553v1>|[代码](https://github.com/jorgeLRW/whale.); 提出了一种结合密度感知地标选择和GPU加速的持久同伦方法，有效优化了全脑MRI体积数据的拓扑特征保持...|
|🆕 发布|MedCLM: Learning to Localize and Reason via a CoT-Curriculum in Medical Vision-Language Models|MedCLM：通过CoT课程在医学视觉语言模型中学习定位和推理|Soo Yong Kim, Suin Cho, Vincent-Daniel Yun, Gyeongyeon Hwang|<http://arxiv.org/pdf/2510.04477v1>|提出MedCLM模型，通过CoT-Curriculum策略将医学图像检测数据转化为VQA数据，实现医...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Semantics-Aware Hierarchical Self-Supervised Approach to Classification of Remote Sensing Images|一种面向语义感知的层次化自监督方法在遥感图像分类中的应用|Giulio Weikmann, Gianmarco Perantoni, Lorenzo Bruzzone|<http://arxiv.org/pdf/2510.04916v1>|提出了一种语义感知的分层自监督方法，通过整合特定层级的分类头和可训练的层级矩阵，有效提升了遥感图像分...|
|🆕 发布|A Spatial-Spectral-Frequency Interactive Network for Multimodal Remote Sensing Classification|一种用于多模态遥感分类的空间-光谱-频率交互网络|Hao Liu, Yunhao Gao, Wei Li, Mingyang Zhang, Maoguo Gong, Lorenzo Bruzzone|<http://arxiv.org/pdf/2510.04628v1>|[代码](https://github.com/HaoLiu-XDU/SSFin.); 提出了一种融合空间、光谱和频率域的交互网络，有效提取异质多模态遥感图像的结构和细节特征。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Praxis-VLM: Vision-Grounded Decision Making via Text-Driven Reinforcement Learning|基于文本驱动的强化学习的视觉定位决策模型Praxis-VLM|Zhe Hu, Jing Li, Zhongzhu Pu, Hou Pong Chan, Yu Yin|<http://arxiv.org/pdf/2503.16965v3>|提出了一种基于文本驱动的强化学习，使视觉语言模型在决策制定中具备强大推理能力的方法。|

