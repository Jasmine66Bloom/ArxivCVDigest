## [UPDATED!] **2025-10-07** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EgoNight: Towards Egocentric Vision Understanding at Night with a Challenging Benchmark|《EgoNight：面向夜间自我视觉理解的研究及具有挑战性的基准测试》|Deheng Zhang, Yuqian Fu, Runyi Yang, Yang Miao, Tianwen Qian, Xu Zheng, Guolei Sun, Ajad Chhatkuli .etc.|<http://arxiv.org/pdf/2510.06218v1>|提出EgoNight，首个针对夜间第一视角视觉理解的全面基准，通过日夜对齐视频提升夜间标注质量和模型...|
|📝 更新|OneCAT: Decoder-Only Auto-Regressive Model for Unified Understanding and Generation|统一理解与生成用的解码器仅自动回归模型：OneCAT|Han Li, Xinyu Peng, Yaoming Wang, Zelin Peng, Xin Chen, Rongxiang Weng, Jingang Wang, Xunliang Cai .etc.|<http://arxiv.org/pdf/2509.03498v3>|提出OneCAT模型，通过纯解码器架构统一了多模态理解、生成和编辑，提升了效率和性能。|
|🆕 发布|There is More to Attention: Statistical Filtering Enhances Explanations in Vision Transformers|“注意力之外：统计滤波增强视觉变换器中的解释性”|Meghna P Ayyar, Jenny Benois-Pineau, Akka Zemmari|<http://arxiv.org/pdf/2510.06070v1>|结合统计滤波技术，改进了Vision Transformers的注意力解释，生成更清晰、准确的解释图...|
|🆕 发布|Leveraging Vision Transformers for Enhanced Classification of Emotions using ECG Signals|利用视觉变换器增强基于ECG信号的情感分类|Pubudu L. Indrasiri, Bipasha Kashyap, Pubudu N. Pathirana|<http://arxiv.org/pdf/2510.05826v1>|利用改进的视觉变换器模型，通过心电图信号图像处理，提升了情绪识别的准确性和性能。|
|🆕 发布|When and How to Cut Classical Concerts? A Multimodal Automated Video Editing Approach|何时以及如何剪辑古典音乐会？一种多模态自动化视频编辑方法|Daniel Gonzálbez-Biosca, Josep Cabacas-Maso, Carles Ventura, Ismael Benito-Altamirano|<http://arxiv.org/pdf/2510.05661v1>|提出了一种多模态自动视频编辑方法，通过分析音频和图像特征优化古典音乐会视频剪辑时机与方式。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Discrete Diffusion Models with MLLMs for Unified Medical Multimodal Generation|统一医学多模态生成的具有MLLMs的离散扩散模型|Jiawei Mao, Yuhan Wang, Lifeng Chen, Can Zhao, Yucheng Tang, Dong Yang, Liangqiong Qu, Daguang Xu .etc.|<http://arxiv.org/pdf/2510.06131v1>|提出MeDiM模型，通过共享概率空间统一医学多模态数据生成，提升跨模态生成质量和报告准确性。|
|🆕 发布|Multimodal Feature Prototype Learning for Interpretable and Discriminative Cancer Survival Prediction|多模态特征原型学习用于可解释且具有辨别力的癌症生存预测|Shuo Jiang, Zhuwen Chen, Liaoman Xu, Yanming Zhu, Changmiao Wang, Jiong Zhang, Feiwei Qin, Yifei Chen .etc.|<http://arxiv.org/pdf/2510.06113v1>|[代码](https://github.com/JSLiam94/FeatProto.); 提出了一种多模态特征原型学习方法FeatProto，通过融合全局与局部特征及基因数据，提高了癌症生存...|
|📝 更新|v1: Learning to Point Visual Tokens for Multimodal Grounded Reasoning|学习指点多模态基础推理中的视觉标记|Jiwan Chung, Junhyeok Kim, Siyeol Kim, Jaeyoung Lee, Min Soo Kim, Youngjae Yu|<http://arxiv.org/pdf/2505.18842v4>|[代码](https://github.com/jun297/v1.); 提出了一种“点-复制”策略，使模型在多模态推理过程中能够持续关注图像关键区域，显著提升了推理性能。|
|🆕 发布|BioAutoML-NAS: An End-to-End AutoML Framework for Multimodal Insect Classification via Neural Architecture Search on Large-Scale Biodiversity Data|生物自动机器学习-神经架构搜索：一种基于大规模生物多样性数据的多模态昆虫分类端到端自动机器学习框架|Arefin Ittesafun Abian, Debopom Sutradhar, Md Rafi Ur Rashid, Reem E. Mohamed, Md Rafiqul Islam, Asif Karim, Kheng Cher Yeo, Sami Azam|<http://arxiv.org/pdf/2510.05888v1>|提出了一种利用多模态数据和神经架构搜索的自动化昆虫分类框架，有效提升了分类准确性和效率。|
|📝 更新|When Semantics Mislead Vision: Mitigating Large Multimodal Models Hallucinations in Scene Text Spotting and Understanding|当语义误导视觉：减轻大规模多模态模型在场景文本检测与理解中的幻觉现象|Yan Shu, Hangui Lin, Yexin Liu, Yan Zhang, Gangyan Zeng, Yan Li, Yu Zhou, Ser-Nam Lim .etc.|<http://arxiv.org/pdf/2506.05551v2>|提出无训练的框架减轻大规模多模态模型在视觉模糊或非语义场景文本中的错误识别问题。|
|🆕 发布|Towards Robust and Realible Multimodal Fake News Detection with Incomplete Modality|面向鲁棒与可靠的多模态虚假新闻检测：处理不完整模态问题|Hengyang Zhou, Yiwei Wei, Jian Yang, Zhenyu Zhang|<http://arxiv.org/pdf/2510.05839v1>|[代码](https://github.com/zhyhome/MMLNet.); 提出了一种针对信息缺失情况下的多模态假新闻检测方法MMLNet，通过多专家协作推理和自适应学习显著提...|
|🆕 发布|FoleyGRAM: Video-to-Audio Generation with GRAM-Aligned Multimodal Encoders|FoleyGRAM：基于GRAM对齐的多模态编码器的视频到音频生成|Riccardo Fosco Gramaccioni, Christian Marinoni, Eleonora Grassucci, Giordano Cicchetti, Aurelio Uncini, Danilo Comminiello|<http://arxiv.org/pdf/2510.05829v1>|提出了一种利用GRAM对齐多模态编码器的视频转音频生成方法，实现了音频与视频内容在语义上的精确对应。|
|🆕 发布|Context Matters: Learning Global Semantics for Visual Reasoning and Comprehension|上下文至关重要：学习全局语义以进行视觉推理和理解|Jike Zhong, Yuxiang Lai, Xiaofeng Yang, Konstantinos Psounis|<http://arxiv.org/pdf/2510.05674v1>|提出对象级表征学习法，增强视觉模型语义理解和推理能力。|
|🆕 发布|SD-MVSum: Script-Driven Multimodal Video Summarization Method and Datasets|脚本驱动的多模态视频摘要方法与数据集|Manolis Mylonas, Charalampia Zerva, Evlampios Apostolidis, Vasileios Mezaris|<http://arxiv.org/pdf/2510.05652v1>|[代码](https://github.com/IDT-ITI/SD-MVSum.); 提出了一种结合用户脚本和视频内容的加权跨模态注意力机制，用于提高视频摘要的相关性。|
|🆕 发布|InstaGeo: Compute-Efficient Geospatial Machine Learning from Data to Deployment|“InstaGeo：从数据到部署的高效计算地理空间机器学习”|Ibrahim Salihu Yusuf, Iffanice Houndayi, Rym Oualha, Mohamed Aziz Cherif, Kobby Panford-Quainoo, Arnu Pretorius|<http://arxiv.org/pdf/2510.05617v1>|[代码](https://github.com/instadeepai/InstaGeo-E2E-Geospatial-ML.git); 提出InstaGeo框架，自动化处理地理数据并压缩模型，实现快速部署和低能耗地球观测。|
|🆕 发布|HOI-R1: Exploring the Potential of Multimodal Large Language Models for Human-Object Interaction Detection|人对象交互检测中探索多模态大型语言模型的潜力：HOI-R1|Junwen Chen, Peilin Xiong, Keiji Yanai|<http://arxiv.org/pdf/2510.05609v1>|[代码](https://github.com/cjw2021/HOI-R1.); 首次探索了大型多模态语言模型在人类-物体交互检测任务中的潜力，通过纯文本推理显著提升准确率。|
|📝 更新|Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned|训练视觉-语言处理奖励模型以实现多模态推理测试时的缩放：关键见解与经验教训|Brandon Ong, Tej Deep Pala, Vernon Toh, William Chandra Tjhi, Soujanya Poria|<http://arxiv.org/pdf/2509.23250v3>|提出了一种改进视觉语言模型推理可靠性的方法，通过多样化数据合成和测试时扩展策略，有效提升多模态推理性...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Detection and Measurement of Hailstones with Multimodal Large Language Models|利用多模态大型语言模型进行冰雹检测与测量|Moritz Alker, David C. Schedl, Andreas Stöckl|<http://arxiv.org/pdf/2510.06008v1>|利用预训练的多模态大语言模型从社交媒体图像中检测和测量冰雹直径，提高了灾害评估的速度和细节。|
|🆕 发布|StereoSync: Spatially-Aware Stereo Audio Generation from Video|《StereoSync：从视频生成空间感知立体声》|Christian Marinoni, Riccardo Fosco Gramaccioni, Kazuki Shimada, Takashi Shibuya, Yuki Mitsufuji, Danilo Comminiello|<http://arxiv.org/pdf/2510.05828v1>|提出了一种空间感知立体声生成模型 StereoSync，通过结合深度图和边界框实现视频同步音频的空间...|
|🆕 发布|ALISE: Annotation-Free LiDAR Instance Segmentation for Autonomous Driving|无需标注的激光雷达实例分割方法ALISE：面向自动驾驶|Yongxuan Lyu, Guangfeng Jiang, Hongsi Liu, Jun Liu|<http://arxiv.org/pdf/2510.05752v1>|提出无标注激光雷达点云实例分割方法ALISE，通过视觉基础模型和时空投票模块实现高性能无监督学习。|
|🆕 发布|NEO: No-Optimization Test-Time Adaptation through Latent Re-Centering|NEO: 通过潜在重中心化实现的无需优化的测试时适应|Alexander Murphy, Michal Danilowski, Soumyajit Chatterjee, Abhirup Ghosh|<http://arxiv.org/pdf/2510.05635v1>|提出了一种无需优化的测试时适应方法NEO，通过在潜在空间重新中心化目标数据嵌入，有效提高了模型在分布...|
|📝 更新|Can Video Large Multimodal Models Think Like Doubters-or Double-Down: A Study on Defeasible Video Entailment|视频大型多模态模型能否像怀疑者一样思考或加倍下注：对可辩驳视频蕴含的研究|Yue Zhang, Jilei Sun, Yunhui Guo, Vibhav Gogate|<http://arxiv.org/pdf/2506.22385v2>|提出Defeasible Video Entailment任务，通过Chain of Counter...|
|📝 更新|SpaCE-10: A Comprehensive Benchmark for Multimodal Large Language Models in Compositional Spatial Intelligence|空间智能组合性多模态大型语言模型的全面基准：SpaCE-10|Ziyang Gong, Wenhao Li, Oliver Ma, Songyuan Li, Zhaokai Wang, Songyuan Li, Jiayi Ji, Xue Yang .etc.|<http://arxiv.org/pdf/2506.07966v4>|提出了SpaCE-10基准，全面评估多模态大语言模型在组合空间智能上的表现。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dropping the D: RGB-D SLAM Without the Depth Sensor|放弃D：无需深度传感器的RGB-D SLAM|Mert Kiray, Alican Karaomer, Benjamin Busam|<http://arxiv.org/pdf/2510.06216v1>|提出了一种不依赖深度传感器的实时单目SLAM系统，通过预训练视觉模型实现RGB-D级精度。|
|🆕 发布|Overlap-aware segmentation for topological reconstruction of obscured objects|遮挡物体的拓扑重建中的重叠感知分割|J. Schueler, H. M. Araújo, S. N. Balashov, J. E. Borg, C. Brew, F. M. Brunbauer, C. Cazzaniga, A. Cottle .etc.|<http://arxiv.org/pdf/2510.06194v1>|提出加权损失函数的分割回归框架OASIS，优先处理重叠区域，改善遮挡物体的拓扑重建效果。|
|📝 更新|AuxDet: Auxiliary Metadata Matters for Omni-Domain Infrared Small Target Detection|AuxDet：辅助元数据对全领域红外小目标检测至关重要|Yangting Shi, Yinfei Zhu, Renjie He, Le Hui, Meng Cai, Ming-Ming Cheng, Yimian Dai|<http://arxiv.org/pdf/2505.15184v2>|[代码](https://github.com/GrokCV/AuxDet.); 提出利用辅助元数据优化红外小目标检测，提高了跨场景适应性和准确性。|
|📝 更新|Background Semantics Matter: Cross-Task Feature Exchange Network for Clustered Infrared Small Target Detection|背景语义重要：面向聚类红外小目标检测的跨任务特征交换网络|Mengxuan Xiao, Yinfei Zhu, Yiming Zhu, Boyang Li, Feifei Zhang, Huan Wang, Meng Cai, Yimian Dai|<http://arxiv.org/pdf/2407.20078v3>|[代码](https://github.com/GrokCV/BAFE-Net.); 提出了一种多任务网络BAFE-Net，通过任务间特征交换增强红外小目标检测准确性。|
|🆕 发布|DeLTa: Demonstration and Language-Guided Novel Transparent Object Manipulation|DeLTa: 示范与语言引导的新型透明物体操作|Taeyeop Lee, Gyuree Kang, Bowen Wen, Youngho Kim, Seunghyeok Back, In So Kweon, David Hyunchul Shim, Kuk-Jin Yoon|<http://arxiv.org/pdf/2510.05662v1>|提出了一种结合深度估计、6D位姿估计和视觉语言规划的框架，实现了根据自然任务指导的透明物体精确长时操...|
|📝 更新|SBP-YOLO:A Lightweight Real-Time Model for Detecting Speed Bumps and Potholes toward Intelligent Vehicle Suspension Systems|SBP-YOLO：面向智能车辆悬挂系统的轻量级实时减速带和坑洼检测模型|Chuanqi Liang, Jie Fu, Miao Yu, Lei Luo|<http://arxiv.org/pdf/2508.01339v4>|提出了一种针对嵌入式系统的高效道路异常检测框架SBP-YOLO，通过优化网络结构和训练策略，实现了快...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Smartphone-based iris recognition through high-quality visible-spectrum iris image capture.V2|基于智能手机的高质量可见光波段虹膜图像捕获的虹膜识别技术。V2|Naveenkumar G Venkataswamy, Yu Liu, Soumyabrata Dey, Stephanie Schuckers, Masudul H Imtiaz|<http://arxiv.org/pdf/2510.06170v1>|提出了一种基于智能手机的可见光谱虹膜识别方法，通过标准化图像采集和轻量级模型实现了高准确度识别。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Incremental Object Detection with Prompt-based Methods|基于提示方法的增量目标检测|Matthias Neuwirth-Trapp, Maarten Bieshaar, Danda Pani Paudel, Luc Van Gool|<http://arxiv.org/pdf/2508.14599v2>|将提示方法应用于增量目标检测，并通过结合数据重放实现了最佳效果。|
|🆕 发布|Mysteries of the Deep: Role of Intermediate Representations in Out of Distribution Detection|《深海的奥秘：中间表示在分布外检测中的作用》|I. M. De la Jara, C. Rodriguez-Opazo, D. Teney, D. Ranasinghe, E. Abbasnejad|<http://arxiv.org/pdf/2510.05782v1>|揭示了预训练模型中间层可编码丰富信号以提升分布外检测准确性，并提出了自动识别最有信息层的方法。|
|📝 更新|The Mirage of Performance Gains: Why Contrastive Decoding Fails to Mitigate Object Hallucinations in MLLMs?|《性能提升的幻象：为什么对比解码无法减轻大型语言模型中对象幻觉的问题？》|Hao Yin, Guangzong Si, Zilei Wang|<http://arxiv.org/pdf/2504.10020v3>|指出对比解码策略未能有效减少大型多模态语言模型中的物体幻觉问题，揭示了其性能提升的假象。|


## 生成式视觉模型 (Generative Visual Modeling)


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Fine-grained Defocus Blur Control for Generative Image Models|生成图像模型的细粒度散焦模糊控制|Ayush Shrivastava, Connelly Barnes, Xuaner Zhang, Lingzhi Zhang, Andrew Owens, Sohrab Amirghodsi, Eli Shechtman|<http://arxiv.org/pdf/2510.06215v1>|引入了一种利用相机元数据生成可控散焦效果的文本到图像扩散框架。|
|🆕 发布|When Thinking Drifts: Evidential Grounding for Robust Video Reasoning|当思维漂移时：用于鲁棒视频推理的证据定位|Mi Luo, Zihui Xue, Alex Dimakis, Kristen Grauman|<http://arxiv.org/pdf/2510.06077v1>|提出视觉证据奖励框架，有效抑制视频推理中的思维漂移，增强模型对视觉证据的依赖。|
|📝 更新|Inference-Time Text-to-Video Alignment with Diffusion Latent Beam Search|推理时文本到视频对齐的扩散潜在光束搜索方法|Yuta Oshima, Masahiro Suzuki, Yutaka Matsuo, Hiroki Furuta|<http://arxiv.org/pdf/2501.19252v3>|提出了一种优化视频生成质量的实时文本到视频对齐方法，通过奖励校准和扩散潜在光束搜索提高了视频的自然度...|
|📝 更新|Bridging Semantic Logic Gaps: A Cognition Inspired Multimodal Boundary Preserving Network for Image Manipulation Localization|桥接语义逻辑间隙：一种受认知启发保持多模态边界的图像操作定位网络|Songlin Li, Zhiqing Guo, Yuanman Li, Zeyu Li, Yunfeng Diao, Gaobo Yang, Liejun Wang|<http://arxiv.org/pdf/2508.07216v3>|[代码](https://github.com/vpsg-research/CMB-Net.); 提出了一种认知启发式多模态边界保持网络，通过结合大语言模型和图像特征补偿语义逻辑关系缺失，提升了图像...|
|🆕 发布|Redefining Generalization in Visual Domains: A Two-Axis Framework for Fake Image Detection with FusionDetect|在视觉领域中重新定义泛化：一种用于伪造图像检测的融合检测双轴框架|Amirtaha Amanzadi, Zahra Dehghanian, Hamid Beigy, Hamid R. Rabiee|<http://arxiv.org/pdf/2510.05740v1>|[代码](http://github.com/amir-aman/FusionDetect); 提出全新基准OmniGen和融合模型FusionDetect，有效提升合成图像检测的跨生成器和跨视觉...|
|📝 更新|HiMat: DiT-based Ultra-High Resolution SVBRDF Generation|HiMat：基于DiT的超高分辨率SVBRDF生成|Zixiong Wang, Jian Yang, Yiwei Hu, Milos Hasan, Beibei Wang|<http://arxiv.org/pdf/2508.07011v4>|HiMat通过在压缩空间中生成并利用轻量级模块保持一致性，实现了高效的4K SVBRDF生成。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ShapeGen4D: Towards High Quality 4D Shape Generation from Videos|《ShapeGen4D：面向高质量四维形状生成的视频处理方法》|Jiraphon Yenphraphai, Ashkan Mirzaei, Jianqi Chen, Jiaxu Zou, Sergey Tulyakov, Raymond A. Yeh, Peter Wonka, Chaoyang Wang|<http://arxiv.org/pdf/2510.06208v1>|提出了一个原生视频到4D形状生成的框架，通过时序注意力和时间感知的点采样，实现了高质量的非刚性运动和...|
|🆕 发布|Drive&Gen: Co-Evaluating End-to-End Driving and Video Generation Models|驱动与生成：端到端驾驶与视频生成模型协同评估|Jiahao Wang, Zhenpei Yang, Yijing Bai, Yingwei Li, Yuliang Zou, Bo Sun, Abhijit Kundu, Jose Lezama .etc.|<http://arxiv.org/pdf/2510.06209v1>|提出 Drive&Gen 方法，结合驾驶模型与生成模型，评估生成视频真实性并提升自动驾驶模型泛化能力...|
|📝 更新|Sparse VideoGen2: Accelerate Video Generation with Sparse Attention via Semantic-Aware Permutation|稀疏VideoGen2：通过语义感知排列的稀疏注意力加速视频生成|Shuo Yang, Haocheng Xi, Yilong Zhao, Muyang Li, Jintao Zhang, Han Cai, Yujun Lin, Xiuyu Li .etc.|<http://arxiv.org/pdf/2505.18875v3>|[代码](https://github.com/svg-project/Sparse-VideoGen); 提出SVG2框架，通过语义感知排列优化稀疏注意力机制，在视频生成中实现质量和效率的平衡。|
|🆕 发布|Controllable Audio-Visual Viewpoint Generation from 360° Spatial Information|从360°空间信息生成可控的音频-视觉视角|Christian Marinoni, Riccardo Fosco Gramaccioni, Eleonora Grassucci, Danilo Comminiello|<http://arxiv.org/pdf/2510.06060v1>|首次提出一种可控音视频生成框架，利用360度空间信息生成具有细粒度视角控制的沉浸式内容。|
|🆕 发布|Diffusion-Based Image Editing for Breaking Robust Watermarks|基于扩散的图像编辑方法用于破解鲁棒水印|Yunyi Ni, Finn Carter, Ze Niu, Emily Davis, Bo Zhang|<http://arxiv.org/pdf/2510.05978v1>|提出了一种基于扩散模型的方法，有效破解了传统鲁棒图像水印技术。|
|🆕 发布|$\bf{D^3}$QE: Learning Discrete Distribution Discrepancy-aware Quantization Error for Autoregressive-Generated Image Detection|学习离散分布差异感知量化误差以用于自回归生成图像检测的$\bf{D^3}$QE方法|Yanran Zhang, Bingyao Yu, Yu Zheng, Wenzhao Zheng, Yueqi Duan, Lei Chen, Jie Zhou, Jiwen Lu|<http://arxiv.org/pdf/2510.05891v1>|[代码](https://github.com/Zhangyr2022/D3QE); 提出D$^3$QE方法，通过分析生成图像的量化误差和分布差异，有效检测视觉自回归模型生成的图像。|
|📝 更新|Towards Unified Image Deblurring using a Mixture-of-Experts Decoder|面向统一图像去模糊的混合专家解码器方法|Daniel Feijoo, Paula Garrido-Mellado, Jaesung Rim, Alvaro Garcia, Marcos V. Conde|<http://arxiv.org/pdf/2508.06228v2>|[代码](https://github.com/cidautai/DeMoE.); 提出了一种混合专家解码器，实现了对多种模糊类型图像的统一去模糊处理，提高了去模糊的通用性和效率。|
|🆕 发布|AgeBooth: Controllable Facial Aging and Rejuvenation via Diffusion Models|AgeBooth：通过扩散模型实现可控的面部老龄化和年轻化|Shihao Zhu, Bohan Cao, Ziheng Ouyang, Zhen Li, Peng-Tao Jiang, Qibin Hou|<http://arxiv.org/pdf/2510.05715v1>|提出了一种创新的年龄特定微调方法AgeBooth，通过无需年龄变化数据集即可有效控制面部图像的年龄变...|
|📝 更新|PartSDF: Part-Based Implicit Neural Representation for Composite 3D Shape Parametrization and Optimization|基于部分的隐式神经表示法用于组合三维形状参数化与优化：PartSDF|Nicolas Talabot, Olivier Clerc, Arda Cinar Demirtas, Hieu Le, Doruk Oner, Pascal Fua|<http://arxiv.org/pdf/2502.12985v2>|[代码](https://github.com/cvlab-epfl/PartSDF.); 提出PartSDF方法，通过独立可控的部件显式建模复合形状，提高了3D形状表示的准确性和适用性。|
|📝 更新|Keep It on a Leash: Controllable Pseudo-label Generation Towards Realistic Long-Tailed Semi-Supervised Learning|“约束在缰绳上：面向真实长尾半监督学习的可控伪标签生成”|Yaxin Hou, Bo Han, Yuheng Jia, Hui Liu, Junhui Hou|<http://arxiv.org/pdf/2510.03993v2>|[代码](https://github.com/yaxinhou/CPG.); 提出了一种可控伪标签生成框架，通过动态筛选可靠伪标签，使长尾分布的半监督学习不受未标注数据分布影响。|
|📝 更新|VisRet: Visualization Improves Knowledge-Intensive Text-to-Image Retrieval|视觉检索：可视化提升知识密集型文本到图像检索|Di Wu, Yixin Wan, Kai-Wei Chang|<http://arxiv.org/pdf/2505.20291v2>|提出Visualize-then-Retrieve方法，通过图像生成和图像检索改善文本到图像检索中视...|
|🆕 发布|Beyond Spectral Peaks: Interpreting the Cues Behind Synthetic Image Detection|超越光谱峰值：解读合成图像检测背后的线索|Sara Mandelli, Diego Vila-Portela, David Vázquez-Padín, Paolo Bestagini, Fernando Pérez-González|<http://arxiv.org/pdf/2510.05633v1>|挑战了合成图像检测中频率域特征的传统认知，提出了一种可解释的基于频率峰值的线性检测器。|
|📝 更新|Step-by-Step Video-to-Audio Synthesis via Negative Audio Guidance|通过负音频引导的逐步视频到音频合成|Akio Hayakawa, Masato Ishii, Takashi Shibuya, Yuki Mitsufuji|<http://arxiv.org/pdf/2506.20995v3>|提出了一种逐步视频转音频合成方法，通过负向音频引导增强生成控制性和音频真实性。|
|🆕 发布|Efficient Conditional Generation on Scale-based Visual Autoregressive Models|基于尺度条件的视觉自回归模型的高效生成|Jiaqi Liu, Tao Huang, Chang Xu|<http://arxiv.org/pdf/2510.05610v1>|提出Efficient Control Model（ECM），通过轻量级控制模块和早期采样策略，提高...|
|🆕 发布|PointNSP: Autoregressive 3D Point Cloud Generation with Next-Scale Level-of-Detail Prediction|点邻域预测：基于自回归的3D点云生成与下一尺度细节预测|Ziqiao Meng, Qichao Wang, Zhiyang Dou, Zixing Song, Zhipeng Zhou, Irwin King, Peilin Zhao|<http://arxiv.org/pdf/2510.05613v1>|PointNSP通过 coarse-to-fine 框架和 next-scale 预测，提升了 au...|
|🆕 发布|Improving Chain-of-Thought Efficiency for Autoregressive Image Generation|提高自回归图像生成中思维链路的效率|Zeqi Gu, Markos Georgopoulos, Xiaoliang Dai, Marjan Ghazvininejad, Chu Wang, Felix Juefei-Xu, Kunpeng Li, Yujun Shi .etc.|<http://arxiv.org/pdf/2510.05593v1>|提出ShortCoTI优化框架，减少图像生成中链式思维冗余，提升效率同时保持图像质量。|
|📝 更新|High-pass filtered fidelity-imposed network edit (HP-FINE) for robust quantitative susceptibility mapping from high-pass filtered phase|高通滤波保真度约束网络编辑（HP-FINE）用于从高通滤波相位实现稳健的定量磁化率映射|Jinwei Zhang, Alexey Dimov, Chao Li, Hang Zhang, Thanh D. Nguyen, Pascal Spincemaille, Yi Wang|<http://arxiv.org/pdf/2305.03844v2>|提出HP-FINE网络微调方法，通过低频保留正则化增强定量磁化率映射的预测准确性。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Noise2Score3D: Tweedie's Approach for Unsupervised Point Cloud Denoising|噪声至评分三维：Tweedie方法用于无监督点云去噪|Xiangbin Wei, Yuanfeng Wang, Ao XU, Lingyu Zhu, Dongyong Sun, Keren Li, Yang Li, Qi Qin|<http://arxiv.org/pdf/2503.09283v3>|提出了一种无需干净数据训练的Noise2Score3D框架，利用Tweedie公式单步去噪点云，提升...|
|🆕 发布|Deforming Videos to Masks: Flow Matching for Referring Video Segmentation|将视频变形为掩模：用于参考视频分割的流匹配|Zanyi Wang, Dengyang Jiang, Liuzhuozheng Li, Sizhe Dang, Chengzu Li, Harry Yang, Guang Dai, Mengmeng Wang .etc.|<http://arxiv.org/pdf/2510.06139v1>|提出了一种基于语言引导的连续流形变形方法，实现了视频对象分割任务的新突破。|
|🆕 发布|VideoMiner: Iteratively Grounding Key Frames of Hour-Long Videos via Tree-based Group Relative Policy Optimization|VideoMiner：通过基于树的群体相对策略优化迭代定位长达一小时的视频关键帧|Xinye Cao, Hongcan Guo, Jiawen Qian, Guoshun Nan, Chao Wang, Yuqi Pan, Tianhao Hou, Xiaojuan Wang .etc.|<http://arxiv.org/pdf/2510.06040v1>|[代码](https://github.com/caoxinye/VideoMiner.); 提出VideoMiner模型，通过迭代分割、标注和聚类长视频，并结合强化学习优化关键帧定位，有效减轻...|
|📝 更新|MoSA: Motion-Coherent Human Video Generation via Structure-Appearance Decoupling|MoSA：通过结构与外观解耦实现运动一致性的视频生成|Haoyu Wang, Hao Tang, Donglin Di, Zhilu Zhang, Wangmeng Zuo, Feng Gao, Siwei Ma, Shiliang Zhang|<http://arxiv.org/pdf/2508.17404v2>|提出MoSA方法，通过分离结构和外观生成，实现了复杂人体运动的高质量视频合成。|
|🆕 发布|Continual Learning for Image Captioning through Improved Image-Text Alignment|通过改进的图像-文本对齐进行图像字幕的持续学习|Bertram Taetz, Gal Bordelius|<http://arxiv.org/pdf/2510.06009v1>|提出了一种多损失框架，通过提示式持续学习和对比对齐，有效解决了图像字幕生成中的灾难性遗忘和语义对齐问...|
|🆕 发布|Deformable Image Registration for Self-supervised Cardiac Phase Detection in Multi-View Multi-Disease Cardiac Magnetic Resonance Images|多视角多疾病心脏磁共振图像中基于自监督心脏相位检测的变形图像配准|Sven Koehler, Sarah Kaye Mueller, Jonathan Kiekenap, Gerald Greil, Tarique Hussain, Samir Sarikouch, Florian André, Norbert Frey .etc.|<http://arxiv.org/pdf/2510.05819v1>|[代码](https://github.com/Cardio-AI/cmr-multi-view-phase-detection.git); 提出了一种自监督深度学习方法，通过变形图像配准显著提高了心脏磁共振图像关键帧检测的准确性。|
|🆕 发布|Neighborhood-Adaptive Generalized Linear Graph Embedding with Latent Pattern Mining|邻域自适应广义线性图嵌入与潜在模式挖掘|S. Peng, L. Hu, W. Zhang, B. Jie, Y. Luo|<http://arxiv.org/pdf/2510.05719v1>|提出了一种自适应邻域的图嵌入方法NGLGE，通过潜在模式挖掘有效揭示数据内在相关性。|
|📝 更新|Imagining the Unseen: Generative Location Modeling for Object Placement|想象不可见：用于物体放置的生成位置建模|Jooyeol Yun, Davide Abati, Mohamed Omran, Jaegul Choo, Amirhossein Habibian, Auke Wiggers|<http://arxiv.org/pdf/2410.13564v2>|提出了一种生成位置模型，通过预测物体可能的放置位置，解决了场景中物体位置建模的挑战。|
|🆕 发布|HoloScene: Simulation-Ready Interactive 3D Worlds from a Single Video|《全息场景：从单个视频中构建的仿真就绪交互式3D世界》|Hongchi Xia, Chih-Hao Lin, Hao-Yu Hsu, Quentin Leboutet, Katelyn Gao, Michael Paulitsch, Benjamin Ummenhofer, Shenlong Wang|<http://arxiv.org/pdf/2510.05560v1>|[代码](https://xiahongchi.github.io/HoloScene.); 提出了一种交互式3D重建框架HoloScene，实现了精确几何、物理稳定性和真实渲染的数字孪生。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bimanual 3D Hand Motion and Articulation Forecasting in Everyday Images|日常图像中的双手动3D手势运动与关节预测|Aditya Prakash, David Forsyth, Saurabh Gupta|<http://arxiv.org/pdf/2510.06145v1>|提出了一种预测日常环境中双手三维运动和关节角度的方法，通过二维关键点序列生成三维运动，实现了14%的...|
|🆕 发布|Emergent AI Surveillance: Overlearned Person Re-Identification and Its Mitigation in Law Enforcement Context|新兴人工智能监控：执法背景下过学习的人脸重识别及其缓解措施|An Thi Nguyen, Radina Stoykova, Eric Arazo|<http://arxiv.org/pdf/2510.06026v1>|揭示了通用搜索模型在无人类数据训练下意外识别个体的能力，并评估了两种降低识别准确性的技术手段。|
|📝 更新|Uni-Instruct: One-step Diffusion Model through Unified Diffusion Divergence Instruction|统一指令一步扩散模型：通过统一扩散发散指令|Yifei Wang, Weimin Bai, Colin Zhang, Debing Zhang, Weijian Luo, He Sun|<http://arxiv.org/pdf/2505.20755v3>|统一了超过10种一步扩散蒸馏方法，提出扩散扩展理论，实现了最优的一步扩散模型训练效果。|
|📝 更新|AutoEdit: Automatic Hyperparameter Tuning for Image Editing|自动编辑：图像编辑的自动超参数调优|Chau Pham, Quan Dao, Mahesh Bhosale, Yunjie Tian, Dimitris Metaxas, David Doermann|<http://arxiv.org/pdf/2509.15031v2>|[代码](https://github.com/chaupham1709/AutoEdit.git.); 自动调整图像编辑超参数的强化学习框架，大幅减少搜索时间和计算成本。|
|🆕 发布|Diffusion Models for Low-Light Image Enhancement: A Multi-Perspective Taxonomy and Performance Analysis|低光照图像增强的扩散模型：多视角分类法与性能分析|Eashan Adhikarla, Yixin Liu, Brian D. Davison|<http://arxiv.org/pdf/2510.05976v1>|系统分析了扩散模型在低光图像增强中的应用，提出了包含六类方法的全面分类体系。|
|📝 更新|A weakly-supervised deep learning model for fast localisation and delineation of the skeleton, internal organs, and spinal canal on Whole-Body Diffusion-Weighted MRI (WB-DWI)|一种用于在全身弥散加权磁共振成像（WB-DWI）上快速定位和勾勒骨骼、内部器官及脊髓管的弱监督深度学习模型|A. Candito, A. Dragan, R. Holbrey, A. Ribeiro, R. Donners, C. Messiou, N. Tunariu, D. -M. Koh .etc.|<http://arxiv.org/pdf/2503.20722v2>|提出了一种基于弱监督学习的快速定位和描绘全身弥散加权核磁共振成像中骨骼、内部器官和脊髓管道的方法。|
|📝 更新|Robust Concept Erasure in Diffusion Models: A Theoretical Perspective on Security and Robustness|扩散模型中的鲁棒概念擦除：关于安全性与鲁棒性的理论视角|Zixuan Fu, Yan Ren, Finn Carter, Chenyue Wen, Le Ku, Daheng Yu, Emily Davis, Bo Zhang|<http://arxiv.org/pdf/2509.12024v2>|提出了一种名为SCORE的框架，通过最小化概念与生成图像间的互信息，实现了在扩散模型中鲁棒地移除敏感...|
|📝 更新|Evaluation of Deformable Image Registration under Alignment-Regularity Trade-of|《评估在对齐-正则性权衡下的可变形图像配准》|Vasiliki Sideri-Lampretsa, Daniel Rueckert, Huaqi Qiu|<http://arxiv.org/pdf/2503.07185v3>|提出了一种连续捕捉对齐与规则性权衡的评估方案，通过ARC曲线全面评价变形图像配准方法。|
|🆕 发布|Data Factory with Minimal Human Effort Using VLMs|使用最小人工努力的虚拟数据工厂|Jiaojiao Ye, Jiaxing Zhong, Qian Xie, Yuzhou Zhou, Niki Trigoni, Andrew Markham|<http://arxiv.org/pdf/2510.05722v1>|利用预训练的ControlNet和Vision-Language Models，提出了一种无需手动标...|
|🆕 发布|Teleportraits: Training-Free People Insertion into Any Scene|《远程肖像：无需训练将人物插入任意场景》|Jialu Gao, K J Joseph, Fernando De La Torre|<http://arxiv.org/pdf/2510.05660v1>|提出了一种无需训练的统一流程，利用预训练的文本到图像扩散模型实现人物无缝插入任意场景。|
|📝 更新|Think Before You Diffuse: Infusing Physical Rules into Video Diffusion|"三思而后行：将物理规则融入视频扩散"|Ke Zhang, Cihan Xiao, Jiacong Xu, Yiqun Mei, Vishal M. Patel|<http://arxiv.org/pdf/2505.21653v3>|[代码](https://bwgzk-keke.github.io/DiffPhy); 提出DiffPhy框架，结合大型语言模型和视频扩散模型，实现物理规则正确的视频生成。|
|🆕 发布|CalibCLIP: Contextual Calibration of Dominant Semantics for Text-Driven Image Retrieval|"CalibCLIP：文本驱动图像检索中的主导语义上下文校准"|Bin Kang, Bin Chen, Junjie Wang, Yulin Li, Junzhi Zhao, Zhuotao Tian|<http://arxiv.org/pdf/2510.05586v1>|[代码](https://github.com/kangbin98/CalibCLIP); 提出了一种无训练的CalibCLIP方法，通过调整文本和视觉空间中的关键信息，有效解决了视觉语言模型...|
|📝 更新|ExGS: Extreme 3D Gaussian Compression with Diffusion Priors|极值三维高斯压缩与扩散先验方法（ExGS）|Jiaqi Chen, Xinhao Ji, Yuanyuan Gao, Hao Li, Yuning Gong, Yifei Liu, Dan Xu, Zhihang Zhong .etc.|<http://arxiv.org/pdf/2509.24758v4>|[代码](https://github.com/chenttt2001/ExGS); 提出了一种高效3D高斯场景压缩方法ExGS，通过结合优化剪枝与扩散先验，实现了超压缩比下的高质量图像...|
|📝 更新|Ouroboros: Single-step Diffusion Models for Cycle-consistent Forward and Inverse Rendering|《乌洛波洛斯：用于循环一致的正向和逆向渲染的单步扩散模型》|Shanlin Sun, Yifan Wang, Hanwen Zhang, Yifeng Xiong, Qin Ren, Ruogu Fang, Xiaohui Xie, Chenyu You|<http://arxiv.org/pdf/2508.14461v2>|提出了一种双向互强化的单步扩散模型框架Ouroboros，实现了快速且一致的图像渲染和分解。|
|🆕 发布|Teamwork: Collaborative Diffusion with Low-rank Coordination and Adaptation|团队合作：基于低秩协调与适应的协同扩散|Sam Sartor, Pieter Peers|<http://arxiv.org/pdf/2510.05532v1>|提出了一种灵活高效的统一解决方案Teamwork，通过协调和适应多个扩散模型实例实现通道扩展和任务适...|
|📝 更新|Self-Evolving Vision-Language Models for Image Quality Assessment via Voting and Ranking|通过投票和排序进行图像质量评估的自进化视觉-语言模型|Wen Wen, Tianwu Zhi, Kanglong Fan, Yang Li, Xinge Peng, Yabin Zhang, Yiting Liao, Junlin Li .etc.|<http://arxiv.org/pdf/2509.25787v3>|提出了一种无需标注数据的自进化视觉语言模型，通过投票和排序显著提升图像质量评估性能。|
|🆕 发布|Be Tangential to Manifold: Discovering Riemannian Metric for Diffusion Models|保持流形切向：为扩散模型发现黎曼度量|Shinnosuke Saito, Takashi Matsubara|<http://arxiv.org/pdf/2510.05509v1>|提出了一种新的黎曼度量方法，使扩散模型在噪声空间中的路径更贴近数据流形，生成更自然的图像插值效果。|
|📝 更新|DiffCom: Decoupled Sparse Priors Guided Diffusion Compression for Point Clouds|解耦稀疏先验引导的点云扩散压缩方法DiffCom|Xiaoge Zhang, Zijie Wu, Mehwish Nasim, Mingtao Feng, Saeed Anwar, Ajmal Mian|<http://arxiv.org/pdf/2411.13860v3>|提出了一种基于稀疏先验引导的扩散压缩框架DiffCom，有效降低点云潜在表示冗余，实现高质量重建。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Human3R: Everyone Everywhere All at Once|《Human3R: 无处不在的每个人，时刻在一起》|Yue Chen, Xingyu Chen, Yuxuan Xue, Anpei Chen, Yuliang Xiu, Gerard Pons-Moll|<http://arxiv.org/pdf/2510.06219v1>|[代码](https://fanegg.github.io/Human3R); 提出了一种统一的实时4D人体与场景重建框架，实现了单次处理多人、场景和相机轨迹的精确重建。|
|🆕 发布|Human Action Recognition from Point Clouds over Time|基于时间点云的人体动作识别|James Dickens|<http://arxiv.org/pdf/2510.05506v1>|提出了一种结合点云技术和稀疏卷积网络的人类动作识别方法，提升了识别准确度。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Compact Multi-level-prior Tensor Representation for Hyperspectral Image Super-resolution|紧凑的多级先验张量表示用于高光谱图像超分辨率|Yinjian Wang, Wei Li, Yuanyuan Gui, Gemine Vivone|<http://arxiv.org/pdf/2510.06098v1>|[代码](https://code implementation will be available from https://github.com/WongYinJ.); 提出了一种紧凑的多级先验张量表示方法，有效融合高光谱图像的多维低秩性和多级空间先验，实现了高光谱图像...|
|🆕 发布|GLVD: Guided Learned Vertex Descent|引导学习顶点下降法：GLVD|Pol Caselles Rico, Francesc Moreno Noguer|<http://arxiv.org/pdf/2510.06046v1>|提出了一种结合全局结构引导和逐顶点优化的3D人脸重建方法GLVD，提升了重建质量并减少了计算时间。|
|📝 更新|Low-Rank Tensor Recovery via Variational Schatten-p Quasi-Norm and Jacobian Regularization|通过变分Schatten-p准范数和雅可比正则化的低秩张量恢复|Zhengyun Cheng, Ruizhe Zhang, Guanwen Zhang, Yi Xu, Xiangyang Ji, Wei Zhou|<http://arxiv.org/pdf/2506.22134v2>|[代码](https://github.com/CZY-Code/CP-Pruner.); 提出了一种基于神经网络和变分Schatten-p准范数的低秩张量恢复方法，实现了更稀疏的CP分解并提...|
|📝 更新|Sparse Representations Improve Adversarial Robustness of Neural Network Classifiers|稀疏表示提高了神经网络分类器的对抗稳健性|Killian Steunou, Théo Druilhe, Sigurd Saue|<http://arxiv.org/pdf/2509.21130v2>|[代码](https://github.com/killian31/SPCARobustness.); 通过稀疏表示增强神经网络分类器对抗攻击的鲁棒性。|
|📝 更新|LV-MAE: Learning Long Video Representations through Masked-Embedding Autoencoders|LV-MAE：通过遮蔽-嵌入自动编码器学习长视频表征|Ilan Naiman, Emanuel Ben-Baruch, Oron Anschel, Alon Shoshan, Igor Kviatkovsky, Manoj Aggarwal, Gerard Medioni|<http://arxiv.org/pdf/2504.03501v2>|[代码](https://github.com/amazon-science/lv-mae.); 提出了一种用于学习长视频表示的自监督框架LV-MAE，通过分离短长期依赖关系，有效处理长视频并实现最...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HBSplat: Robust Sparse-View Gaussian Reconstruction with Hybrid-Loss Guided Depth and Bidirectional Warping|HBSplat：基于混合损失引导深度与双向扭曲的稳健稀疏视图高斯重建|Yu Ma, Guoliang Wei, Yue Cheng|<http://arxiv.org/pdf/2509.24893v2>|[代码](https://github.com/eternalland/HBSplat.); 提出HBSplat框架，通过混合损失深度估计、双向图像映射和遮挡感知重建，实现了稀疏视角下的高保真三...|
|🆕 发布|A Hierarchical Geometry-guided Transformer for Histological Subtyping of Primary Liver Cancer|一种分层几何引导的Transformer用于原发性肝癌的组织学亚型分类|Anwen Lu, Mingxin Liu, Yiping Jiao, Hongyi Gong, Geyang Xu, Jun Chen, Jun Xu|<http://arxiv.org/pdf/2510.05657v1>|提出了一种层级几何引导的Transformer模型ARGUS，通过捕捉肝脏肿瘤微环境中宏观、中观、微...|
|📝 更新|SAMCIRT: A Simultaneous Reconstruction and Affine Motion Compensation Technique for Four Dimensional Computed Tomography (4DCT)|SAMCIRT：一种用于四维计算机断层扫描（4DCT）的同时重建与仿射运动补偿技术|Anh-Tuan Nguyen, Jens Renders, Khoi-Nguyen Nguyen, Tat-Dat To, Domenico Iuso, Yves Maris|<http://arxiv.org/pdf/2402.04480v2>|提出了一种同时进行图像重建和仿射运动估计的迭代方法，提高了4DCT的计算效率和重建精度。|


## 时序视觉分析 (Temporal Visual Analysis)


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Trajectory Prediction Meets Large Language Models: A Survey|轨迹预测遇见大型语言模型：综述|Yi Xu, Ruining Yang, Yitian Zhang, Jianglin Lu, Mingyuan Zhang, Yizhou Wang, Lili Su, Yun Fu|<http://arxiv.org/pdf/2506.03408v2>|整合大型语言模型提升自动系统轨迹预测的语义理解和推理能力。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Enhancing Fitness Movement Recognition with Attention Mechanism and Pre-Trained Feature Extractors|使用注意力机制和预训练特征提取器增强健身动作识别|Shanjid Hasan Nishat, Srabonti Deb, Mohiuddin Ahmed|<http://arxiv.org/pdf/2509.02511v2>|提出了一种结合预训练2D CNN和LSTM的轻量级框架，通过注意力机制提升健身动作识别准确性和实时性...|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Flow4Agent: Long-form Video Understanding via Motion Prior from Optical Flow|《Flow4Agent：通过光流运动先验实现长视频理解的算法》|Ruyang Liu, Shangkun Sun, Haoran Tang, Ge Li, Wei Gao|<http://arxiv.org/pdf/2510.05836v1>|Flow4Agent通过引入光流运动先验，优化了长视频理解和表示，有效减轻了冗余信息的影响。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Universal Neural Architecture Space: Covering ConvNets, Transformers and Everything in Between|通用神经网络结构空间：涵盖卷积神经网络、变换器网络及其中间所有结构|Ondřej Týbl, Lukáš Neumann|<http://arxiv.org/pdf/2510.06035v1>|提出通用神经架构空间UniNAS，统一了卷积网络、变换器和混合架构的搜索，发现超越现有水平的架构。|
|📝 更新|Teaching Metric Distance to Discrete Autoregressive Language Models|教会离散自回归语言模型度量距离|Jiwan Chung, Saejin Kim, Yongrae Jo, Jaewoo Park, Dongjun Min, Youngjae Yu|<http://arxiv.org/pdf/2503.02379v4>|引入DIST2Loss框架，通过利用预定义的距离关系训练语言模型，增强多模态应用性能。|
|🆕 发布|OneVision: An End-to-End Generative Framework for Multi-view E-commerce Vision Search|"OneVision：一种用于多视角电商视觉搜索的端到端生成框架"|Zexin Zheng, Huangyu Dai, Lingtao Mao, Xinyu Sun, Zihan Liang, Ben Chen, Yuqing Ding, Chenyi Lei .etc.|<http://arxiv.org/pdf/2510.05759v1>|提出端到端生成框架OneVision，通过视觉对齐残差量化编码和多阶段语义对齐，优化电商视觉搜索的用...|
|📝 更新|Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation|基于聚类仿射变换的猫：训练后量化误差降低方法|Ali Zoljodi, Radu Timofte, Masoud Daneshtalab|<http://arxiv.org/pdf/2509.26277v2>|提出了一种基于聚类仿射变换的误差减少框架，有效提升了低比特量化后训练的神经网络准确性。|
|📝 更新|Deep Reinforcement Learning for Urban Air Quality Management: Multi-Objective Optimization of Pollution Mitigation Booth Placement in Metropolitan Environments|深度强化学习在都市空气质量管理中的应用：大城市环境中污染缓解亭位置的多目标优化|Kirtan Rajesh, Suvidha Rupesh Kumar|<http://arxiv.org/pdf/2505.00668v2>|提出了一种深度强化学习框架，优化空气净化装置布局以改善德里空气质量。|
|📝 更新|MoME: Estimating Psychological Traits from Gait with Multi-Stage Mixture of Movement Experts|多阶段动作专家混合模型（MoME）：基于步态估计心理特征|Andy Cǎtrunǎ, Adrian Cosma, Emilian Rǎdoi|<http://arxiv.org/pdf/2510.04654v2>|提出了一种分阶段处理步行周期的MoME架构，通过多任务学习从步态中预测心理特征，实现了优于现有方法的...|
|🆕 发布|EduVerse: A User-Defined Multi-Agent Simulation Space for Education Scenario|教育场景中用户定义的多智能体仿真空间：EduVerse|Yiping Ma, Shiyu Hu, Buyuan Zhu, Yipei Wang, Yaxuan Kang, Shiqing Liu, Kang Hao Cheong|<http://arxiv.org/pdf/2510.05650v1>|提出了EduVerse，一个支持自定义环境和代理的模拟空间，以重现真实课堂的复杂性和长期发展。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A discussion about violin reduction: geometric analysis of contour lines and channel of minima|关于小提琴简化的讨论：轮廓线的几何分析及最小值通道研究|Philémon Beghin, Anne-Emmanuelle Ceulemans, François Glineur|<http://arxiv.org/pdf/2404.01995v2>|提出了一种针对提琴几何形态的分析方法，通过优化参考平面和计算轮廓线与最小通道，提高了提琴形态分析的准...|
|📝 更新|Adapting Large Language Models to Mitigate Skin Tone Biases in Clinical Dermatology Tasks: A Mixed-Methods Study|适应大型语言模型以减轻临床皮肤病学任务中的肤色偏见：一项混合方法研究|Kiran Nijjer, Ryan Bui, Derek Jiu, Adnan Ahmed, Peter Wang, Kevin Zhu, Lilly Zhu|<http://arxiv.org/pdf/2510.00055v2>|提出方法减轻计算机视觉模型在深色皮肤上的诊断偏见，提高了皮肤疾病分类的公平性和准确性。|
|📝 更新|Robust Neural Rendering in the Wild with Asymmetric Dual 3D Gaussian Splatting|野外环境下基于非对称双三次高斯散点的鲁棒神经渲染|Chengqi Li, Zhihao Shi, Yangdi Lu, Wenbo He, Xiangyu Xu|<http://arxiv.org/pdf/2506.03538v2>|[代码](https://steveli88.github.io/AsymGS.); 提出了一种不对称双3D高斯渲染框架，通过一致性约束和互补掩码策略，有效抑制视觉伪影并提高三维重建质量...|
|🆕 发布|ArchitectHead: Continuous Level of Detail Control for 3D Gaussian Head Avatars|架构头：三维高斯人头模型的连续细节级别控制|Peizhi Yan, Rabab Ward, Qiang Tang, Shan Du|<http://arxiv.org/pdf/2510.05488v1>|提出了一种支持连续细节级别控制的3D高斯人头模型架构，通过动态调整特征图采样实现渲染效率与质量的平衡...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Rasterized Steered Mixture of Experts for Efficient 2D Image Regression|栅格化引导的专家混合模型用于高效的二维图像回归|Yi-Hsin Li, Thomas Sikora, Sebastian Knorr, Mårten Sjöström|<http://arxiv.org/pdf/2510.05814v1>|提出了一种基于光栅化的优化策略，结合了高效的光栅化高斯核渲染和边缘感知的导向混合专家模型，实现了二维...|
|📝 更新|Submillimeter-Accurate 3D Lumbar Spine Reconstruction from Biplanar X-Ray Images: Incorporating a Multi-Task Network and Landmark-Weighted Loss|亚毫米级精度的双平面X射线图像三维腰椎重建：融合多任务网络和地标加权损失函数|Wanxin Yu, Zhemin Zhu, Cong Wang, Yihang Bao, Chunjie Xia, Rongshan Cheng, Yan Yu, Tsung-Yuan Tsai|<http://arxiv.org/pdf/2503.14573v3>|提出了一种多任务网络和地标加权损失的高精度3D腰椎重建方法，实现了亚毫米级精度和20秒内完成重建。|
|🆕 发布|Ocular-Induced Abnormal Head Posture: Diagnosis and Missing Data Imputation|眼动引起的异常头姿：诊断与缺失数据插补|Saja Al-Dabet, Sherzod Turaev, Nazar Zaki, Arif O. Khan, Luai Eldweik|<http://arxiv.org/pdf/2510.05649v1>|提出了一种深度学习框架，用于自动诊断眼部异常引起的头姿异常并填补缺失数据，提高了诊断准确性和数据完整...|
|📝 更新|ECORE: Energy-Conscious Optimized Routing for Deep Learning Models at the Edge|边缘计算中考虑能耗的深度学习模型优化路由算法（ECORE）|Daghash K. Alqahtani, Maria A. Rodriguez, Muhammad Aamir Cheema, Hamid Rezatofighi, Adel N. Toosi|<http://arxiv.org/pdf/2507.06011v3>|提出ECORE框架，通过动态路由策略优化边缘计算中的能耗和对象检测精度。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Gaussian Embeddings: How JEPAs Secretly Learn Your Data Density|高斯嵌入：JEPAs如何秘密学习您的数据密度|Randall Balestriero, Nicolas Ballas, Mike Rabbat, Yann LeCun|<http://arxiv.org/pdf/2510.05949v1>|揭示了JEPAs通过抗塌陷项隐式学习数据密度，提出JEPA-SCORE方法有效估计样本概率。|
|🆕 发布|A Warm-basis Method for Bridging Learning and Iteration: a Case Study in Fluorescence Molecular Tomography|基于预热方法连接学习与迭代：荧光分子层析成像案例研究|Ruchi Guo, Jiahua Jiang, Bangti Jin, Wuwei Ren, Jianru Zhang|<http://arxiv.org/pdf/2510.05926v1>|提出了一种结合学习与迭代的新型方法WB-IPM，有效提升了荧光分子断层成像的深度重建精度。|
|🆕 发布|D2E: Scaling Vision-Action Pretraining on Desktop Data for Transfer to Embodied AI|D2E：在桌面数据上扩展视觉-动作预训练以迁移至具身人工智能|Suwhan Choi, Jaeyoon Jung, Haebin Seong, Minchan Kim, Minyeong Kim, Yongjun Cho, Yoonshik Kim, Yubeen Park .etc.|<http://arxiv.org/pdf/2510.05684v1>|[代码](https://worv-ai.github.io/d2e); 提出D2E框架，利用桌面环境数据进行预训练，实现机器人零样本泛化并提高物理操作和导航成功率。|
|🆕 发布|Combined Hyperbolic and Euclidean Soft Triple Loss Beyond the Single Space Deep Metric Learning|超双曲与欧几里得软三元损失相结合的单空间外深度度量学习|Shozo Saeki, Minoru Kawahara, Hirohisa Aman|<http://arxiv.org/pdf/2510.05643v1>|提出了一种结合双曲和欧几里得空间的CHEST损失函数，提升了深度度量学习的准确性和稳定性。|
|📝 更新|Integrating Feature Selection and Machine Learning for Nitrogen Assessment in Grapevine Leaves using In-Field Hyperspectral Imaging|利用现场高光谱成像技术集成特征选择与机器学习对葡萄叶氮含量进行评估|Atif Bilal Asad, Achyut Paudel, Safal Kshetri, Chenchen Kang, Salik Ram Khanal, Nataliya Shcherbatyuk, Pierre Davadant, R. Paul Schreiner .etc.|<http://arxiv.org/pdf/2507.17869v2>|利用现场高光谱成像结合特征选择和机器学习技术，有效预测葡萄叶氮含量。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 目标导向视觉决策 (Goal-oriented Visual Decision Making)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Midway Network: Learning Representations for Recognition and Motion from Latent Dynamics|中途网络：从潜在动态中学习识别和运动表征|Christopher Hoang, Mengye Ren|<http://arxiv.org/pdf/2510.05558v1>|首次提出Midway Network，通过自然视频学习同时实现物体识别和运动理解的高效视觉表示。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Video-in-the-Loop: Span-Grounded Long Video QA with Interleaved Reasoning|视频循环：带交错推理的跨 grounded 长视频问答|Chendong Wang, Donglin Bai, Yifan Yang, Xiao Jin, Anlan Zhang, Rui Wang, Shiqi Jiang, Yuqing Yang .etc.|<http://arxiv.org/pdf/2510.04022v2>|提出Video-in-the-Loop框架，通过分阶段处理实现长视频问答的高效定位与回答。|
|📝 更新|VisioMath: Benchmarking Figure-based Mathematical Reasoning in LMMs|VisioMath：在语言模型中基于图形的数学推理基准测试|Can Li, Ying Liu, Ting Zhang, Mei Wang, Hua Huang|<http://arxiv.org/pdf/2506.06727v3>|提出VisioMath基准，评估大型多模态模型在处理具有细微视觉差异的数学问题上的推理能力，并探索了...|
|📝 更新|GeoRemover: Removing Objects and Their Causal Visual Artifacts|地理移除器：移除对象及其因果视觉痕迹|Zixin Zhu, Haoxiang Li, Xuelu Feng, He Wu, Chunming Qiao, Junsong Yuan|<http://arxiv.org/pdf/2509.18538v2>|[代码](https://github.com/buxiangzhiren/GeoRemover.); 提出了一种基于几何感知的两阶段框架，有效移除目标物体及其因果视觉效应，实现更精准的图像编辑。|
|🆕 发布|Seeing the Big Picture: Evaluating Multimodal LLMs' Ability to Interpret and Grade Handwritten Student Work|《洞察全局：评估多模态大型语言模型解读和评定手写学生作业的能力》|Owen Henkel, Bill Roberts, Doug Jaffe, Laurence Holt|<http://arxiv.org/pdf/2510.05538v1>|探究了大型多模态语言模型在评估手写学生作业中的表现，发现模型在处理客观题时接近人类准确度，但在主观题...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Electromagnetic Inverse Scattering from a Single Transmitter|单一发射源电磁逆散射|Yizhe Cheng, Chunxun Tian, Haoru Wang, Wentao Zhu, Xiaoxuan Ma, Yizhou Wang|<http://arxiv.org/pdf/2506.21349v5>|提出了一种数据驱动的电磁逆散射框架，能在只有一个发射器的情况下准确预测散射体的相对介电常数。|
|🆕 发布|Towards Data-Efficient Medical Imaging: A Generative and Semi-Supervised Framework|面向数据高效的医学成像：一个生成与半监督框架|Mosong Ma, Tania Stathaki, Michalis Lazarou|<http://arxiv.org/pdf/2510.06123v1>|提出了一种结合生成模型和半监督学习的SSGNet框架，有效缓解了医疗影像中标注数据稀缺的问题，提升了...|
|🆕 发布|A public cardiac CT dataset featuring the left atrial appendage|公开的心脏CT数据集，特征为左心耳|Bjoern Hansen, Jonas Pedersen, Klaus F. Kofoed, Oscar Camara, Rasmus R. Paulsen, Kristine Soerensen|<http://arxiv.org/pdf/2510.06090v1>|创建了首个开源、高分辨率的心脏CT图像数据集，助力左心耳等结构的高精度分割研究。|
|📝 更新|Unified Cross-Modal Medical Image Synthesis with Hierarchical Mixture of Product-of-Experts|统一跨模态医学图像生成：基于层次化乘积专家混合模型|Reuben Dorent, Nazim Haouchine, Alexandra Golby, Sarah Frisken, Tina Kapur, William Wells|<http://arxiv.org/pdf/2410.19378v3>|提出了一种多模态医学图像合成方法MMHVAE，通过深度学习有效融合不同模态图像信息，生成缺失的高分辨...|
|📝 更新|A Comprehensive Survey of Mamba Architectures for Medical Image Analysis: Classification, Segmentation, Restoration and Beyond|《医学图像分析中Mamba架构的全面调研：分类、分割、恢复及拓展》|Shubhi Bansal, Sreeharish A, Madhava Prasath J, Manikandan S, Sreekanth Madisetty, Mohammad Zia Ur Rehman, Chandravardhan Singh Raghaw, Gaurav Duggal .etc.|<http://arxiv.org/pdf/2410.02362v2>|概述了Mamba架构在医疗影像分析中的应用，解决了传统方法计算复杂度高和长距离依赖处理难题。|
|📝 更新|ImageNet-trained CNNs are not biased towards texture: Revisiting feature reliance through controlled suppression|《ImageNet训练的卷积神经网络对纹理并无偏见：通过控制抑制重新审视特征依赖》|Tom Burgert, Oliver Stoll, Paolo Rota, Begüm Demir|<http://arxiv.org/pdf/2509.20234v2>|[代码](https://github.com/tomburgert/feature-reliance.); 挑战了CNN对纹理的内在偏向假设，提出了一种量化特征依赖的通用框架，发现CNN主要依赖形状特征。|
|🆕 发布|Shaken or Stirred? An Analysis of MetaFormer's Token Mixing for Medical Imaging|“摇晃还是搅拌？对MetaFormer在医学成像中标记混合的分析”|Ron Keuth, Paul Kaftan, Mattias P. Heinrich|<http://arxiv.org/pdf/2510.05971v1>|系统分析了不同类型的token混.mixer在医学成像任务中的表现，为医学图像处理提供了有效的架构选...|
|🆕 发布|Efficient Universal Models for Medical Image Segmentation via Weakly Supervised In-Context Learning|通过弱监督上下文学习实现医学图像分割的高效通用模型|Jiesi Hu, Yanwu Yang, Zhiyu Ye, Jinyan Zhou, Jianfeng Cao, Hanyang Peng, Ting Ma|<http://arxiv.org/pdf/2510.05899v1>|[代码](https://github.com/jiesihu/Weak-ICL.); 提出弱监督在位学习（WS-ICL）方法，减少医疗图像分割标注工作量，实现高效通用模型训练。|
|🆕 发布|acia-workflows: Automated Single-cell Imaging Analysis for Scalable and Deep Learning-based Live-cell Imaging Analysis Workflows|acia工作流：基于可扩展性和深度学习的自动化单细胞成像分析活细胞成像分析工作流|Johannes Seiffarth, Keitaro Kasahara, Michelle Bund, Benita Lückel, Richard D. Paul, Mathias Pesch, Lennart Witting, Michael Bott .etc.|<http://arxiv.org/pdf/2510.05886v1>|[代码](https://github.com/JuBiotech/acia-workflows.); 提出了一种集成深度学习工具的自动化单细胞成像分析平台，实现了高通量活细胞成像数据的可扩展和用户友好分...|
|🆕 发布|The Safety Challenge of World Models for Embodied AI Agents: A Review|《具身人工智能代理的全球模型安全性挑战：综述》|Lorenzo Baraldi, Zifan Zeng, Chongzhe Zhang, Aradhana Nayak, Hongbo Zhu, Feng Liu, Qunli Zhang, Peng Wang .etc.|<http://arxiv.org/pdf/2510.05865v1>|综述了World Models在自动驾驶和机器人领域的安全性挑战，并通过实证分析揭示了常见故障及其影...|
|📝 更新|RICO: Two Realistic Benchmarks and an In-Depth Analysis for Incremental Learning in Object Detection|RICO：面向目标检测增量学习的两个真实基准与深入分析|Matthias Neuwirth-Trapp, Maarten Bieshaar, Danda Pani Paudel, Luc Van Gool|<http://arxiv.org/pdf/2508.13878v2>|提出两个现实增量目标检测基准，揭示了现有增量学习方法在适应性和保留旧知识方面的不足。|
|🆕 发布|Development and Validation of a Low-Cost Imaging System for Seedling Germination Kinetics through Time-Cumulative Analysis|低成本成像系统在种子发芽动力学时间累积分析中的开发与验证|M. Torrente, A. Follador, A. Calcante, P. Casati, R. Oberti|<http://arxiv.org/pdf/2510.05668v1>|开发了一种低成本成像系统，通过时间累积分析准确监测种子发芽动态和早期生长。|
|🆕 发布|TFM Dataset: A Novel Multi-task Dataset and Integrated Pipeline for Automated Tear Film Break-Up Segmentation|TFM数据集：一种新颖的多任务数据集和自动泪膜破裂分割集成管道|Guangrong Wan, Jun liu, Tang tang, Lianghao Shi, Wenjun Luo, TingTing Xu|<http://arxiv.org/pdf/2510.05615v1>|[代码](https://github.com/glory-wan/TF-Net); 提出了TFM数据集和TF-Net模型，实现了泪膜破裂自动分割，提高了干眼症诊断效率。|
|🆕 发布|nnSAM2: nnUNet-Enhanced One-Prompt SAM2 for Few-shot Multi-Modality Segmentation and Composition Analysis of Lumbar Paraspinal Muscles|nnSAM2：nnUNet增强的单提示SAM2用于少量样本多模态分割和腰椎旁肌群的组成分析|Zhongyi Zhang, Julie A. Hides, Enrico De Martino, Abdul Joseph Fofanah, Gervase Tuxworth|<http://arxiv.org/pdf/2510.05555v1>|提出了一种高效少量样本学习方法nnsam2，实现了腰椎旁肌肉多模态图像的精确分割。|
|📝 更新|MediSyn: A Generalist Text-Guided Latent Diffusion Model For Diverse Medical Image Synthesis|MediSyn：一种用于多样化医学图像合成的通用文本引导潜在扩散模型|Joseph Cho, Mrudang Mathur, Cyril Zakka, Dhamanpreet Kaur, Matthew Leipzig, Alex Dalal, Aravind Krishnan, Eubee Koo .etc.|<http://arxiv.org/pdf/2405.09806v6>|MediSyn通过文本引导的潜在扩散模型，实现了跨医学专业和成像模态的多样化医疗图像合成，有效解决了...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Kaputt: A Large-Scale Dataset for Visual Defect Detection|《Kaputt：一个用于视觉缺陷检测的大规模数据集》|Sebastian Höfer, Dorian Henning, Artemij Amiranashvili, Douglas Morrison, Mariliza Tzes, Ingmar Posner, Marc Matvienko, Alessandro Rennola .etc.|<http://arxiv.org/pdf/2510.05903v1>|介绍了大规模缺陷检测数据集Kaputt，解决了零售物流中物体姿态和外观多样性带来的挑战。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Novel Technique for Robust Training of Deep Networks With Multisource Weak Labeled Remote Sensing Data|一种基于多源弱标记遥感数据稳健训练深度网络的新型技术|Gianmarco Perantoni, Lorenzo Bruzzone|<http://arxiv.org/pdf/2510.05760v1>|提出了一种利用多重弱标注数据源及其误差统计进行深度网络训练的新策略，增强了模型的鲁棒性和泛化能力。|
|📝 更新|Self-Supervised Representation Learning with Joint Embedding Predictive Architecture for Automotive LiDAR Object Detection|面向汽车激光雷达目标检测的联合嵌入预测架构的自监督表征学习|Haoran Zhu, Zhenyuan Dong, Kristi Topollai, Beiyao Sha, Anna Choromanska|<http://arxiv.org/pdf/2501.04969v2>|提出了一种用于汽车激光雷达物体检测的联合嵌入预测架构的自监督表征学习方法，实现了更高效的训练和更好的...|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Robust Object Detection for Autonomous Driving via Curriculum-Guided Group Relative Policy Optimization|通过课程引导的组相对策略优化实现的自动驾驶鲁棒目标检测|Xu Jia|<http://arxiv.org/pdf/2509.22688v2>|提出了一种结合课程指导的数据调度和难度感知过滤的强化学习框架，显著提升了自动驾驶中的目标检测准确性和...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Medical Vision Language Models as Policies for Robotic Surgery|医疗视觉语言模型作为机器人手术的策略|Akshay Muppidi, Martin Radfar|<http://arxiv.org/pdf/2510.06064v1>|集成医学领域特定视觉语言模型MedFlamingo与PPO，提升机器人腹腔镜手术任务表现与收敛速度。|
|🆕 发布|Reasoning under Vision: Understanding Visual-Spatial Cognition in Vision-Language Models for CAPTCHA|视觉下的推理：理解视觉-空间认知在验证码视觉语言模型中的应用|Python Song, Luke Tenyi Chang, Yun-Yun Tsai, Penghui Li, Junfeng Yang|<http://arxiv.org/pdf/2510.06067v1>|提出了一种逐步推理框架，大幅提升了视觉语言模型解决验证码的准确率至83.9%。|


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Neural Activity to Computation: Biological Reservoirs for Pattern Recognition in Digit Classification|从神经活动到计算：数字分类模式识别中的生物共振器|Ludovico Iannello, Luca Ciampi, Fabrizio Tonelli, Gabriele Lagani, Lucio Maria Calcagnile, Federico Cremisi, Angelo Di Garbo, Giuseppe Amato|<http://arxiv.org/pdf/2510.05637v1>|将活体神经元网络作为计算基底，实现了生物启发式的模式识别与数字分类。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Improving Clinical Dataset Condensation with Mode Connectivity-based Trajectory Surrogates|基于模态连通性的轨迹替代物改进临床数据集浓缩|Pafue Christy Nganjimi, Andrew Soltan, Danielle Belgrave, Lei Clifton, David A. Clifton, Anshul Thakur|<http://arxiv.org/pdf/2510.05805v1>|提出使用二次贝塞尔曲线替代全随机梯度下降轨迹，稳定训练并提升临床数据集凝结效果。|
|🆕 发布|A Dynamic Mode Decomposition Approach to Morphological Component Analysis|动态模式分解在形态学成分分析中的应用|Owen T. Huber, Raghu G. Raj, Tianyu Chen, Zacharie I. Idriss|<http://arxiv.org/pdf/2510.05977v1>|提出了一种基于动态模式分解的形态学成分分析方法，自适应学习视频表示以分离结构不同的形态。|
|📝 更新|RimSet: Quantitatively Identifying and Characterizing Chronic Active Multiple Sclerosis Lesion on Quantitative Susceptibility Maps|“RimSet：在定量磁化率图上定量识别和表征慢性活动性多发性硬化症病变”|Jinwei Zhang, Thanh D. Nguyen, Renjiu Hu, Susan A. Gauthier, Yi Wang, Hang Zhang|<http://arxiv.org/pdf/2312.16835v2>|提出RimSet方法，通过定量分析定量磁化率图上的Rim+病变，提高了多发性硬化症病变检测的准确性。|

