## [UPDATED!] **2025-10-08** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LLMVA-GEBC: Large Language Model with Video Adapter for Generic Event Boundary Captioning|用于通用事件边界标注的大语言模型与视频适配器（LLMVA-GEBC）|Yolo Yunlong Tang, Jinrui Zhang, Xiangchen Wang, Teng Wang, Feng Zheng|<http://arxiv.org/pdf/2306.10354v2>|[代码](https://github.com/zjr2000/LLMVA-GEBC); 提出了一种结合大型语言模型和视频适配器的方法，实现了对视频事件边界的精准描述。|
|🆕 发布|Evaluating Fundus-Specific Foundation Models for Diabetic Macular Edema Detection|评估用于糖尿病性黄斑水肿检测的眼底专用基础模型|Franco Javier Arellano, José Ignacio Orlando|<http://arxiv.org/pdf/2510.07277v1>|系统评估了基础模型在糖尿病黄斑水肿检测中的表现，发现轻量级卷积神经网络仍为有效基准。|
|🆕 发布|TalkCuts: A Large-Scale Dataset for Multi-Shot Human Speech Video Generation|《TalkCuts：用于多镜头人类语音视频生成的大规模数据集》|Jiaben Chen, Zixin Wang, Ailing Zeng, Yang Fu, Xueyang Yu, Siyuan Cen, Julian Tanke, Yihang Chen .etc.|<http://arxiv.org/pdf/2510.07249v1>|提出大规模TalkCuts数据集，用于多镜头人类言语视频生成，增强视频连贯性和视觉吸引力。|
|🆕 发布|MV-Performer: Taming Video Diffusion Model for Faithful and Synchronized Multi-view Performer Synthesis|MV-Performer：驯化视频扩散模型以实现真实且同步的多视角表演者合成|Yihao Zhi, Chenghong Li, Hongjie Liao, Xihe Yang, Zhengwentai Sun, Jiahao Chang, Xiaodong Cun, Wensen Feng .etc.|<http://arxiv.org/pdf/2510.07190v1>|提出MV-Performer框架，通过多视角同步生成360度人体动作视频，解决了单视角视频生成中的视...|
|🆕 发布|Revisiting Mixout: An Overlooked Path to Robust Finetuning|重新审视Mixout：一种被忽视的稳健微调路径|Masih Aminbeidokhti, Heitor Rapela Medeiros, Eric Granger, Marco Pedersoli|<http://arxiv.org/pdf/2510.06982v1>|提出GMixout方法，通过适应性权重共享增强微调模型的鲁棒性，无需额外推理成本。|
|🆕 发布|VA-Adapter: Adapting Ultrasound Foundation Model to Echocardiography Probe Guidance|VA-Adapter：将超声基础模型适配至心脏超声探头引导|Teng Wang, Haojun Jiang, Yuxuan Wang, Zhenguo Sun, Shiji Song, Gao Huang|<http://arxiv.org/pdf/2510.06809v1>|提出VA-Adapter方法，通过参数高效的适配器使基础模型适应探头指导任务，提升心脏超声图像质量。|
|🆕 发布|GPT-5 Model Corrected GPT-4V's Chart Reading Errors, Not Prompting|GPT-5模型纠正了GPT-4V的图表读取错误，无需提示|Kaichun Yang, Jian Chen|<http://arxiv.org/pdf/2510.06782v1>|GPT-5显著提升了图表阅读任务的准确度，优于仅靠提示的GPT-4V模型。|
|🆕 发布|UniFField: A Generalizable Unified Neural Feature Field for Visual, Semantic, and Spatial Uncertainties in Any Scene|统一场：一种适用于任意场景中视觉、语义和空间不确定性的通用统一神经特征场|Christian Maurer, Snehal Jauhri, Sophie Lueth, Georgia Chalvatzaki|<http://arxiv.org/pdf/2510.06754v1>|提出了一种统一的神经特征场UniFField，结合视觉、语义和几何特征，并预测各类不确定性，实现机器...|
|🆕 发布|DeRainMamba: A Frequency-Aware State Space Model with Detail Enhancement for Image Deraining|《DeRainMamba:一种具有频率感知能力的状态空间模型及细节增强的图像去雨技术》|Zhiliang Zhu, Tao Zeng, Tao Yang, Guoliang Luo, Jiyong Zeng|<http://arxiv.org/pdf/2510.06746v1>|提出DeRainMamba模型，结合频率域处理与细节增强，有效提升图像去雨效果并保持细节。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Pixel-Perfect Depth with Semantics-Prompted Diffusion Transformers|像素级完美深度：语义驱动的扩散变换器|Gangwei Xu, Haotong Lin, Hongcheng Luo, Xianqi Wang, Jingfeng Yao, Lianghui Zhu, Yuechuan Pu, Cheng Chi .etc.|<http://arxiv.org/pdf/2510.07316v1>|提出了Pixel-Perfect Depth模型，通过在像素空间直接进行扩散生成避免了VAE引入的飞...|
|📝 更新|Uncertainty-Aware Remaining Lifespan Prediction from Images|基于不确定性的图像剩余寿命预测|Tristan Kenneweg, Philip Kenneweg, Barbara Hammer|<http://arxiv.org/pdf/2506.13430v3>|提出了一种基于预训练视觉变换器模型预测剩余寿命并量化不确定性的方法，实现了最先进的预测精度。|
|📝 更新|Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction|渐进高斯变换器：具有各向异性感知采样的开放词汇占有率预测|Chi Yan, Dan Xu|<http://arxiv.org/pdf/2510.04759v2>|[代码](https://yanchi-3dv.github.io/PG-Occ); 提出渐进高斯变换框架，通过逐步细化3D场景表示和各向异性采样策略，实现了开放词汇的3D占位预测。|
|📝 更新|Platonic Transformers: A Solid Choice For Equivariance|柏拉图式变换器：保持等方差性的坚实选择|Mohammad Mohaiminul Islam, Rishabh Anand, David R. Wessels, Friso de Kruiff, Thijs P. Kuipers, Rex Ying, Clara I. Sánchez, Sharvaree Vadgama .etc.|<http://arxiv.org/pdf/2510.03511v2>|引入Platonic Transformer，通过固有的几何对称性，实现了与传统Transforme...|
|🆕 发布|Cluster Paths: Navigating Interpretability in Neural Networks|聚类路径：在神经网络中导航可解释性|Nicholas M. Kroeger, Vincent Bindschaedler|<http://arxiv.org/pdf/2510.06541v1>|提出了一种名为“cluster paths”的神经网络解释方法，通过聚类激活层并评估路径指标，有效揭...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models|视频LMM后训练：深入探索大型多模态模型在视频推理中的应用|Yolo Yunlong Tang, Jing Bi, Pinxin Liu, Zhenyu Pan, Zhangyun Tan, Qianxiang Shen, Jiani Liu, Hang Hua .etc.|<http://arxiv.org/pdf/2510.05034v2>|[代码](https://github.com/yunlong10/Awesome-Video-LMM-Post-Training); 系统梳理了视频理解中大型多模态模型的后训练方法，提升了模型在时空推理和跨模态整合方面的能力。|
|🆕 发布|SaFeR-VLM: Toward Safety-aware Fine-grained Reasoning in Multimodal Models|面向安全的细粒度推理在多模态模型中的研究：SaFeR-VLM|Huahui Yi, Kun Wang, Qiankun Li, Miao Yu, Liang Lin, Gongli Xi, Hao Wu, Xuming Hu .etc.|<http://arxiv.org/pdf/2510.06871v1>|[代码](https://github.com/HarveyYi/SaFeR-VLM.); 提出了一种将安全性嵌入到多模态推理过程中的强化学习框架，有效提升了模型在对抗和危险情境下的稳健性和安...|
|📝 更新|The Percept-V Challenge: Can Multimodal LLMs Crack Simple Perception Problems?|《感知V挑战：多模态大型语言模型能否破解简单感知问题？》|Samrajnee Ghosh, Naman Agarwal, Hemanshu Garg, Chinmay Mittal, Mausam, Parag Singla|<http://arxiv.org/pdf/2508.21143v2>|提出Percept-V挑战，发现现有大型多模态语言模型在基本视觉感知任务上的表现弱于人类。|
|🆕 发布|Self-supervised Physics-guided Model with Implicit Representation Regularization for Fast MRI Reconstruction|自监督物理引导模型结合隐式表示正则化用于快速磁共振成像重建|Jingran Xu, Yuanyuan Liu, Yanjie Zhu|<http://arxiv.org/pdf/2510.06611v1>|提出了一种无需外部训练数据的自监督MRI重建框架，通过结合物理引导的迭代架构和隐式神经表示正则化，实...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DADO: A Depth-Attention framework for Object Discovery|DADO：面向目标发现的深度注意力框架|Federico Gonzalez, Estefania Talavera, Petia Radeva|<http://arxiv.org/pdf/2510.07089v1>|提出了一种结合注意力和深度模型的DADO框架，自适应优化对象发现准确性和鲁棒性。|
|🆕 发布|Learning Global Representation from Queries for Vectorized HD Map Construction|从查询中学习全局表示以构建向量化高精度地图|Shoumeng Qiu, Xinrun Li, Yang Long, Xiangyang Xue, Varun Ojha, Jian Pu|<http://arxiv.org/pdf/2510.06969v1>|提出了一种学习全局表示的MapGR架构，通过全局视角优化查询，显著提升高精度地图构建性能。|
|🆕 发布|Lattice-allocated Real-time Line Segment Feature Detection and Tracking Using Only an Event-based Camera|基于事件相机的时间 lattice 分配实时线段特征检测与跟踪|Mikihiro Ikura, Arren Glover, Masayoshi Mizuno, Chiara Bartolozzi|<http://arxiv.org/pdf/2510.06829v1>|实现了仅使用事件相机的高分辨率实时线段检测与跟踪，提升了准确性和效率。|
|📝 更新|Point2RBox-v3: Self-Bootstrapping from Point Annotations via Integrated Pseudo-Label Refinement and Utilization|点到RBox-v3：通过集成伪标签精炼与利用实现从点注释的自举强化|Teng Zhang, Ziqian Fan, Mingxin Liu, Xin Zhang, Xudong Lu, Wentong Li, Yue Zhou, Yi Yu .etc.|<http://arxiv.org/pdf/2509.26281v2>|Point2RBox-v3通过动态伪标签和优化的损失函数，提升了面向弱监督学习的点标注对象检测性能。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HARP-NeXt: High-Speed and Accurate Range-Point Fusion Network for 3D LiDAR Semantic Segmentation|HARP-NeXt：用于三维激光雷达语义分割的高速精确范围-点融合网络|Samir Abou Haidar, Alexandre Chariot, Mehdi Darouich, Cyril Joly, Jean-Emmanuel Deschaud|<http://arxiv.org/pdf/2510.06876v1>|[代码](https://github.com/SamirAbouHaidar/HARP-NeXt); 提出了HARP-NeXt网络，通过高效预处理和多尺度融合显著提升了LiDAR语义分割的速度与准确性。|
|🆕 发布|Semantic Segmentation Algorithm Based on Light Field and LiDAR Fusion|基于光场与激光雷达融合的语义分割算法|Jie Luo, Yuxuan Jiang, Xin Jin, Mingyu Liu, Yihui Fan|<http://arxiv.org/pdf/2510.06687v1>|提出首个融合光场和LiDAR数据的语义分割网络，有效应对遮挡问题并提升分割准确性。|
|🆕 发布|Through the Perspective of LiDAR: A Feature-Enriched and Uncertainty-Aware Annotation Pipeline for Terrestrial Point Cloud Segmentation|通过激光雷达视角：一种面向地面点云分割的特征增强与不确定性感知标注流程|Fei Zhang, Rob Chancia, Josie Clapp, Amirhossein Hassanzadeh, Dimah Dera, Richard MacKenzie, Jan van Aardt|<http://arxiv.org/pdf/2510.06582v1>|[代码](https://fz-rit.github.io/through-the-lidars-eye); 提出了一种半自动化、不确定性感知的标注流程，通过特征增强和集成学习减少激光扫描点云标注工作量，同时保...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unsupervised Backdoor Detection and Mitigation for Spiking Neural Networks|无监督的后门检测与缓解方法研究：针对尖峰神经网络|Jiachen Li, Bang Wu, Xiaoyu Xia, Xiaoning Liu, Xun Yi, Xiuzhen Zhang|<http://arxiv.org/pdf/2510.06629v1>|提出无监督检测框架TMPBD和抑制机制NDSBM，有效防御脉冲神经网络中的后门攻击。|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation|《WristWorld：通过4D世界模型生成手腕视角以实现机器人操控》|Zezhong Qian, Xiaowei Chi, Yuming Li, Shizun Wang, Zhiyuan Qin, Xiaozhu Ju, Sirui Han, Shanghang Zhang|<http://arxiv.org/pdf/2510.07313v1>|提出WristWorld模型，通过4D世界模型从标准视角生成手腕视角视频，提升机器人操作性能。|
|📝 更新|RespoDiff: Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation|责任与忠实文本到图像生成的双模块瓶颈转换：RespoDiff|Silpa Vadakkeeveetil Sreelatha, Sauradip Nag, Muhammad Awais, Serge Belongie, Anjan Dutta|<http://arxiv.org/pdf/2509.15257v2>|提出RespoDiff框架，通过双模块瓶颈变换实现负责任且语义一致的文字到图像生成，同时优化公平性、...|
|🆕 发布|Online Generic Event Boundary Detection|在线通用事件边界检测|Hyungrok Jung, Daneul Kim, Seunggyun Lim, Jeany Son, Jonghyun Choi|<http://arxiv.org/pdf/2510.06855v1>|提出实时视频事件边界检测框架Estimator，模仿人类处理信息方式，提升了对动态事件变化的敏感度。|
|📝 更新|DWTGS: Rethinking Frequency Regularization for Sparse-view 3D Gaussian Splatting|DWTGS：重新思考稀疏视图三维高斯散点图的频率正则化|Hung Nguyen, Runfa Li, An Le, Truong Nguyen|<http://arxiv.org/pdf/2507.15690v3>|提出了一种基于小波变换的频率正则化方法DWTGS，有效抑制了稀疏视角3D高斯散点重建中的过拟合和高频...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MATRIX: Mask Track Alignment for Interaction-aware Video Generation|矩阵：面向交互感知视频生成的掩码轨迹对齐|Siyoon Jin, Seongchan Kim, Dahyun Chung, Jaeho Lee, Hyunwook Choi, Jisu Nam, Jiyoung Kim, Seungryong Kim|<http://arxiv.org/pdf/2510.07310v1>|提出了一种增强视频生成中多实例和主体-对象交互建模的MATRIX方法，通过特定层与多实例掩码轨迹对齐...|
|🆕 发布|Temporal Prompting Matters: Rethinking Referring Video Object Segmentation|时间提示至关重要：重新思考视频目标分割的参照方法|Ci-Siang Lin, Min-Hung Chen, I-Jieh Liu, Chien-Yi Wang, Sifei Liu, Yu-Chiang Frank Wang|<http://arxiv.org/pdf/2510.07319v1>|提出了一种基于现有基础分割模型的Temporal Prompt Generation and Sel...|
|🆕 发布|SpecGuard: Spectral Projection-based Advanced Invisible Watermarking|光谱投影-based高级隐形水印技术：SpecGuard|Inzamamul Alam, Md Tanvir Islam, Khan Muhammad, Simon S. Woo|<http://arxiv.org/pdf/2510.07302v1>|[代码](https://github.com/inzamamulDU/SpecGuard_ICCV_2025); 提出SpecGuard方法，通过频域转换增强水印的隐蔽性和鲁棒性，有效抵抗多种图像变换攻击。|
|🆕 发布|GenPilot: A Multi-Agent System for Test-Time Prompt Optimization in Image Generation|《GenPilot：一种用于图像生成测试时提示优化的多智能体系统》|Wen Ye, Zhaocheng Liu, Yuwei Gui, Tingyu Yuan, Yunyue Su, Bowen Fang, Chaoyang Zhao, Qiang Liu .etc.|<http://arxiv.org/pdf/2510.07217v1>|[代码](https://github.com/27yw/GenPilot.); 提出了一种模型无关的测试时提示优化策略GenPilot，通过多代理系统提升文本到图像生成的准确性和一...|
|📝 更新|Generative AI for Cel-Animation: A Survey|《细胞动画生成式人工智能综述》|Yolo Yunlong Tang, Junjia Guo, Pinxin Liu, Zhiyuan Wang, Hang Hua, Jia-Xing Zhong, Yunzhong Xiao, Chao Huang .etc.|<http://arxiv.org/pdf/2501.06250v4>|[代码](https://github.com/yunlong10/Awesome-AI4Animation); 概述了生成式人工智能如何自动化传统动画制作流程，降低技术门槛，提升创作效率。|
|📝 更新|Color Bind: Exploring Color Perception in Text-to-Image Models|《色彩束缚：在文本到图像模型中探索颜色感知》|Shay Shomer Chai, Wenxuan Peng, Bharath Hariharan, Hadar Averbuch-Elor|<http://arxiv.org/pdf/2508.19791v2>|提出了一种专用的图像编辑技术，有效解决了多颜色对象提示下的语义对齐问题。|
|🆕 发布|Sharpness-Aware Data Generation for Zero-shot Quantization|锐度感知的数据生成用于零样本量化|Dung Hoang-Anh, Cuong Pham Trung Le, Jianfei Cai, Thanh-Toan Do|<http://arxiv.org/pdf/2510.07018v1>|引入了一种考虑量化模型锐度的新颖数据生成方法，以增强零样本量化模型的泛化能力。|
|🆕 发布|Addressing the ID-Matching Challenge in Long Video Captioning|应对长视频字幕中的身份匹配挑战|Zhantao Yang, Huangji Wang, Ruili Feng, Han Zhang, Yuting Hu, Shangwen Zhu, Junyan Li, Yu Liu .etc.|<http://arxiv.org/pdf/2510.06973v1>|提出了一种新方法RICE，通过增强图像信息使用和个体描述信息量，显著提升了长视频字幕中的身份匹配精度...|
|🆕 发布|IAR2: Improving Autoregressive Visual Generation with Semantic-Detail Associated Token Prediction|IAR2：通过语义细节关联标记预测改进自回归视觉生成|Ran Yi, Teng Hu, Zihan Su, Lizhuang Ma|<http://arxiv.org/pdf/2510.06928v1>|提出了一种分层语义-细节合成的自回归图像生成框架IAR2，通过解耦的代码本和改进的预测方案显著提升了...|
|🆕 发布|OBJVanish: Physically Realizable Text-to-3D Adv. Generation of LiDAR-Invisible Objects|OBJVanish：物理可实现的文本到3D先进生成激光雷达不可见物体|Bing Li, Wuqi Wang, Yanan Zhang, Jingzheng Li, Haigen Min, Wei Feng, Xingyu Zhao, Jie Zhang .etc.|<http://arxiv.org/pdf/2510.06952v1>|提出了一种生成LiDAR无法检测到的3D物体的新方法，通过文本到3D的逆向优化，实现了物理环境中有效...|
|📝 更新|Polyp-Gen: Realistic and Diverse Polyp Image Generation for Endoscopic Dataset Expansion|《Polyp-Gen：用于内窥镜数据集扩展的逼真且多样化的息肉图像生成》|Shengyuan Liu, Zhen Chen, Qiushi Yang, Weihao Yu, Di Dong, Jiancong Hu, Yixuan Yuan|<http://arxiv.org/pdf/2501.16679v3>|[代码](https://github.com/CUHK-AIM-Group/Polyp-Gen.); 提出了一种自动化的扩散模型Polyp-Gen，用于生成真实且多样的肠镜图像，以增强自动化诊断系统的性...|
|📝 更新|Generative Pre-trained Autoregressive Diffusion Transformer|生成预训练自回归扩散变换器|Yuan Zhang, Jiacheng Jiang, Guoqing Ma, Zhiying Lu, Haoyang Huang, Jianlong Yuan, Nan Duan, Daxin Jiang|<http://arxiv.org/pdf/2505.07344v5>|提出了一种融合扩散和自回归模型的长视频生成方法，提高了生成质量和动态建模能力。|
|📝 更新|Robot Learning from Any Images|从任意图像中学习的机器人|Siheng Zhao, Jiageng Mao, Wei Chow, Zeyu Shangguan, Tianheng Shi, Rong Xue, Yuxi Zheng, Yijia Weng .etc.|<http://arxiv.org/pdf/2509.22970v2>|[代码](https://sihengz02.github.io/RoLA); 提出RoLA框架，将任意现实图像转化为互动式物理机器人环境，无需额外硬件或数字资源。|
|🆕 发布|DreamOmni2: Multimodal Instruction-based Editing and Generation|梦幻全息2：多模态指令驱动编辑与生成|Bin Xia, Bohao Peng, Yuechen Zhang, Junjia Huang, Jiyang Liu, Jingyao Li, Haoru Tan, Sitong Wu .etc.|<http://arxiv.org/pdf/2510.06679v1>|DreamOmni2通过结合文本和图像指令，扩展了编辑和生成任务的范围，解决了传统方法在细节捕捉和抽...|
|🆕 发布|Heptapod: Language Modeling on Visual Signals|七足兽：视觉信号上的语言建模|Yongxin Zhu, Jiawei Chen, Yuanzhe Chen, Zhuo Chen, Dongya Jia, Jian Cong, Xiaobin Zhuang, Yuping Wang .etc.|<http://arxiv.org/pdf/2510.06673v1>|引入Heptapod模型，通过预测图像二维分布，统一了自回归框架的顺序建模与自监督学习的图像语义捕捉...|
|🆕 发布|Ming-UniVision: Joint Image Understanding and Generation with a Unified Continuous Tokenizer|明统一视觉：使用统一连续标记器的图像理解与生成联合框架|Ziyuan Huang, DanDan Zheng, Cheng Zou, Rui Liu, Xiaolong Wang, Kaixiang Ji, Weilong Chai, Jianxin Sun .etc.|<http://arxiv.org/pdf/2510.06590v1>|引入连续视觉编码器MingTok，统一了图像理解和生成任务，实现了跨领域的最佳性能。|
|🆕 发布|VUGEN: Visual Understanding priors for GENeration|VUGEN：用于生成的视觉理解先验|Xiangyi Chen, Théophane Vallaeys, Maha Elbayad, John Nguyen, Jakob Verbeek|<http://arxiv.org/pdf/2510.06529v1>|提出VUGEN框架，利用预训练视觉理解先验实现高效高质量图像生成。|
|📝 更新|Keep It on a Leash: Controllable Pseudo-label Generation Towards Realistic Long-Tailed Semi-Supervised Learning|“约束在缰绳上：面向真实长尾半监督学习的可控伪标签生成”|Yaxin Hou, Bo Han, Yuheng Jia, Hui Liu, Junhui Hou|<http://arxiv.org/pdf/2510.03993v3>|[代码](https://github.com/yaxinhou/CPG.); 提出了一种可控伪标签生成框架，通过动态筛选可靠伪标签，使长尾分布的半监督学习不受未标注数据分布影响，...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|V2Xum-LLM: Cross-Modal Video Summarization with Temporal Prompt Instruction Tuning|V2Xum-LLM：基于时间提示指令微调的跨模态视频摘要|Hang Hua, Yolo Yunlong Tang, Chenliang Xu, Jiebo Luo|<http://arxiv.org/pdf/2404.12353v3>|提出首个统一不同视频摘要任务的V2Xum-LLM框架，通过时间提示和任务指令实现可控视频摘要。|
|📝 更新|CaRDiff: Video Salient Object Ranking Chain of Thought Reasoning for Saliency Prediction with Diffusion|CaRDiff：基于扩散的显著物体预测的视频显著对象排名链式思维推理|Yolo Yunlong Tang, Gen Zhan, Li Yang, Yiting Liao, Chenliang Xu|<http://arxiv.org/pdf/2408.12009v2>|提出了一种融合多模态大语言模型和推理过程的CaRDiff框架，有效提升了视频显著物体预测的准确性。|
|🆕 发布|Generating Surface for Text-to-3D using 2D Gaussian Splatting|使用二维高斯散点绘制生成文本到三维的表面|Huanning Dong, Fan Li, Ping Kuang, Jianwen Min|<http://arxiv.org/pdf/2510.06967v1>|提出了一种利用条件文本生成模型和二维高斯散点绘制技术生成3D对象表面的新方法，实现了多样化且高保真的...|
|🆕 发布|StyleKeeper: Prevent Content Leakage using Negative Visual Query Guidance|风格守护者：使用负视觉查询引导防止内容泄露|Jaeseok Jeong, Junho Kim, Gayoung Lee, Yunjey Choi, Youngjung Uh|<http://arxiv.org/pdf/2510.06827v1>|[代码](https://github.com/naver-ai/StyleKeeper); StyleKeeper通过引入负视觉查询引导方法，有效防止了文本到图像生成中的内容泄露问题。|
|📝 更新|SafeGuider: Robust and Practical Content Safety Control for Text-to-Image Models|《SafeGuider：针对文本到图像模型的健壮且实用的内容安全控制》|Peigui Qi, Kunsheng Tang, Wenbo Zhou, Weiming Zhang, Nenghai Yu, Tianwei Zhang, Qing Guo, Jie Zhang|<http://arxiv.org/pdf/2510.05173v2>|提出SafeGuider框架，通过两步骤策略有效提升文本到图像模型的安全性，同时保持生成图像质量。|
|📝 更新|MM-PoisonRAG: Disrupting Multimodal RAG with Local and Global Poisoning Attacks|MM-PoisonRAG：利用局部和全局中毒攻击破坏多模态RAG|Hyeonjeong Ha, Qiusi Zhan, Jeonghwan Kim, Dimitrios Bralios, Saikrishna Sanniboina, Nanyun Peng, Kai-Wei Chang, Daniel Kang .etc.|<http://arxiv.org/pdf/2502.17832v3>|提出MM-PoisonRAG框架，通过局部和全局攻击策略首次系统设计多模态RAG的知识毒化攻击方法。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EigenScore: OOD Detection using Covariance in Diffusion Models|《EigenScore：利用扩散模型中的协方差进行异常检测》|Shirin Shoushtari, Yi Wang, Xiao Shi, M. Salman Asif, Ulugbek S. Kamilov|<http://arxiv.org/pdf/2510.07206v1>|提出EigenScore方法，利用扩散模型的后验协方差特征进行异常检测，实现领先性能。|
|🆕 发布|TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking|《TrackVLA++：在VLA模型中释放推理和记忆能力以实现具身视觉跟踪》|Jiahang Liu, Yunpeng Qi, Jiazhao Zhang, Minghan Li, Shaoan Wang, Kui Wu, Hanjing Ye, Hong Zhang .etc.|<http://arxiv.org/pdf/2510.07134v1>|TrackVLA++引入空间推理和目标记忆模块，显著提升复杂场景中视觉追踪的鲁棒性和准确性。|
|🆕 发布|No MoCap Needed: Post-Training Motion Diffusion Models with Reinforcement Learning using Only Textual Prompts|无需动作捕捉：仅使用文本提示的强化学习后训练运动扩散模型|Girolamo Macaluso, Lorenzo Mandelli, Mirko Bicchierai, Stefano Berretti, Andrew D. Bagdanov|<http://arxiv.org/pdf/2510.06988v1>|提出了一种基于文本提示的强化学习后训练框架，无需额外动作捕捉数据即可适应未见过的动作或风格。|
|📝 更新|Unlocking Dataset Distillation with Diffusion Models|解锁数据集蒸馏：使用扩散模型|Brian B. Moser, Federico Raue, Sebastian Palacio, Stanislav Frolov, Andreas Dengel|<http://arxiv.org/pdf/2403.03881v4>|[代码](https://github.com/Brian-Moser/prune_and_distill.); 提出了一种利用扩散模型进行数据集精简的方法LD3M，通过端到端学习显著提升了下游任务准确率。|
|🆕 发布|Extreme Amodal Face Detection|极值非模态人脸检测|Changlin Song, Yunzhong Hou, Michael Randall Barnes, Rahul Shome, Dylan Campbell|<http://arxiv.org/pdf/2510.06791v1>|提出了一种基于图像上下文线索的单幅图像极端非模态人脸检测方法，无需采样即可高效预测出帧区域。|
|📝 更新|Taming Diffusion Models for Image Restoration: A Review|驯服扩散模型进行图像恢复：综述|Ziwei Luo, Fredrik K. Gustafsson, Zheng Zhao, Jens Sjölund, Thomas B. Schön|<http://arxiv.org/pdf/2409.10353v3>|概述了扩散模型在图像恢复任务中的应用，分析了其挑战与局限，并指出了未来研究方向。|
|🆕 发布|OBS-Diff: Accurate Pruning For Diffusion Models in One-Shot|OBS-Diff：单次学习中用于扩散模型的精确剪枝|Junhan Zhu, Hesong Wang, Mingluo Su, Zefang Wang, Huan Wang|<http://arxiv.org/pdf/2510.06751v1>|提出OBS-Diff框架，实现无需训练的大规模文本到图像扩散模型的一键精确剪枝。|
|🆕 发布|Control-Augmented Autoregressive Diffusion for Data Assimilation|控制增强自回归扩散用于数据同化|Prakhar Srivastava, Farrin Marouf Sofian, Francesco Immorlano, Kushagra Pandey, Stephan Mandt|<http://arxiv.org/pdf/2510.06637v1>|引入轻量级控制器网络以增强自回归扩散模型，实现高效数据同化，提升预测稳定性和准确性。|
|📝 更新|HoPE: Hybrid of Position Embedding for Long Context Vision-Language Models|《HoPE：长上下文视觉语言模型中的位置嵌入混合方法》|Haoran Li, Yingjie Qin, Baoyuan Ou, Lai Xu, Ruiwen Xu|<http://arxiv.org/pdf/2505.20444v2>|[代码](https://github.com/hrlics/HoPE.); 提出了一种混合位置编码策略HoPE，有效提升长上下文场景下视觉语言模型的性能。|
|🆕 发布|HSNet: Heterogeneous Subgraph Network for Single Image Super-resolution|HSNet：异质子图网络用于单幅图像超分辨率|Qiongyang Hu, Wenyang Liu, Wenbin Zou, Yuejiao Su, Lap-Pui Chau, Yi Wang|<http://arxiv.org/pdf/2510.06564v1>|提出HSNet，通过分解全局图为子图并聚合特征，实现了图像超分辨率的高效计算与质量提升。|
|📝 更新|Rethinking Inter-LoRA Orthogonality in Adapter Merging: Insights from Orthogonal Monte Carlo Dropout|重新思考适配器合并中Inter-LoRA正交性：来自正交蒙特卡洛丢弃的洞见|Andi Zhang, Xuan Ding, Haofan Wang, Steven McDonagh, Samuel Kaski|<http://arxiv.org/pdf/2510.03262v2>|提出Orthogonal Monte Carlo Dropout方法，确保合并LoRA模块时输出正交...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|BIM-Constrained Optimization for Accurate Localization and Deviation Correction in Construction Monitoring|建筑监测中基于BIM的精确定位与偏差校正优化方法|Asier Bikandi-Noya, Muhammad Shaheer, Hriday Bavle, Jayan Jevanesan, Holger Voos, Jose Luis Sanchez-Lopez|<http://arxiv.org/pdf/2504.17693v2>|提出了一种结合建筑信息模型（BIM）的漂移校正方法，有效减少建筑监测中的定位误差和偏差。|
|📝 更新|Human Action Recognition from Point Clouds over Time|基于时间点云的人体动作识别|James Dickens|<http://arxiv.org/pdf/2510.05506v2>|提出了一种结合点云技术和稀疏卷积网络的人体动作识别方法，提升了识别准确度。|
|📝 更新|VGGT-X: When VGGT Meets Dense Novel View Synthesis|VGGT-X：当VGGT遇见密集新视角合成|Yang Liu, Chuanchen Luo, Zimo Tang, Junran Peng, Zhaoxiang Zhang|<http://arxiv.org/pdf/2509.25191v2>|[代码](https://dekuliutesla.github.io/vggt-x.github.io); 提出VGGT-X方法，解决3D基础模型在密集新视图合成中的内存负担和输出质量问题，实现无需COLMA...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HBSplat: Robust Sparse-View Gaussian Reconstruction with Hybrid-Loss Guided Depth and Bidirectional Warping|HBSplat：基于混合损失引导深度与双向扭曲的稳健稀疏视图高斯重建|Yu Ma, Guoliang Wei, Haihong Xiao, Yue Cheng|<http://arxiv.org/pdf/2509.24893v3>|[代码](https://github.com/eternalland/HBSplat.); 提出HBSplat框架，通过混合损失深度估计、双向图像映射和遮挡感知重建，实现了稀疏视角下的高质量三...|
|🆕 发布|MoRe: Monocular Geometry Refinement via Graph Optimization for Cross-View Consistency|单目几何细化：通过图优化实现跨视角一致性|Dongki Jung, Jaehoon Choi, Yonghan Lee, Sungmin Eum, Heesung Kwon, Dinesh Manocha|<http://arxiv.org/pdf/2510.07119v1>|提出了一种无需训练的单目几何细化方法，通过图优化增强跨视角一致性和尺度对齐。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Empowering LLMs with Pseudo-Untrimmed Videos for Audio-Visual Temporal Understanding|赋予大型语言模型以伪未剪辑视频进行音频-视觉时序理解的能力|Yolo Yunlong Tang, Daiki Shimada, Jing Bi, Mingqian Feng, Hang Hua, Chenliang Xu|<http://arxiv.org/pdf/2403.16276v3>|提出PU-VALOR数据集，通过伪未剪辑视频增强大型语言模型对音视频事件的时间理解能力。|
|📝 更新|VidComposition: Can MLLMs Analyze Compositions in Compiled Videos?|VidComposition：大型语言模型能否分析汇编视频中的构成？|Yolo Yunlong Tang, Junjia Guo, Hang Hua, Susan Liang, Mingqian Feng, Xinyang Li, Rui Mao, Chao Huang .etc.|<http://arxiv.org/pdf/2411.10979v4>|[代码](https://yunlong10.github.io/VidComposition); 提出VidComposition基准，评估大型多模态语言模型对视频构成的理解能力，揭示性能差距。|
|📝 更新|Video Understanding with Large Language Models: A Survey|视频理解与大型语言模型：综述|Yolo Yunlong Tang, Jing Bi, Siting Xu, Luchuan Song, Susan Liang, Teng Wang, Daoan Zhang, Jie An .etc.|<http://arxiv.org/pdf/2312.17432v7>|[代码](https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding.); 概述了大型语言模型在视频理解中的应用进展，分类了不同方法并探讨了未来研究方向。|
|📝 更新|Multi-modal Segment Assemblage Network for Ad Video Editing with Importance-Coherence Reward|多模态片段组装网络：用于广告视频编辑的重要性-一致性奖励方法|Yolo Yunlong Tang, Siting Xu, Teng Wang, Qin Lin, Qinglin Lu, Feng Zheng|<http://arxiv.org/pdf/2209.12164v2>|[代码](https://github.com/yunlong10/Ads-1k); 提出了一种端到端的视频编辑网络M-SAN，通过多模态表征和重要性-连贯性奖励机制，有效提升了广告视频...|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Fully Spiking Neural Networks for Unified Frame-Event Object Tracking|统一帧-事件目标跟踪的全 spikes 神经网络|Jingjun Yang, Liangwei Fan, Jinpu Zhang, Xiangkai Lian, Hui Shen, Dewen Hu|<http://arxiv.org/pdf/2505.20834v2>|提出了一种融合图像和事件流的完全脉冲神经网络跟踪框架，实现了高效的对象跟踪与能耗平衡。|
|🆕 发布|MSITrack: A Challenging Benchmark for Multispectral Single Object Tracking|MSITrack：多光谱单目标跟踪的挑战性基准|Tao Feng, Tingfa Xu, Haolin Qin, Tianhao Li, Shuaihao Han, Xuyang Zou, Zhan Lv, Jianan Li|<http://arxiv.org/pdf/2510.06619v1>|[代码](https://github.com/Fengtao191/MSITrack.); 提出了MSITrack，一个最具挑战性的多光谱单目标跟踪数据集，显著提升了跟踪性能。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Resolution scaling governs DINOv3 transfer performance in chest radiograph classification|分辨率缩放决定DINOv3在胸片分类中的迁移性能|Soroosh Tayebi Arasteh, Mina Shaigan, Christiane Kuhl, Jakob Nikolas Kather, Sven Nebelung, Daniel Truhn|<http://arxiv.org/pdf/2510.07191v1>|提高胸部X射线分类性能，发现输入分辨率512x512像素对DINOv3模型效果最佳。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Lossy Neural Compression for Geospatial Analytics: A Review|地理空间分析中的有损神经压缩：综述|Carlos Gomes, Isabelle Wittmann, Damien Robert, Johannes Jakubik, Tim Reichelt, Michele Martone, Stefano Maurogiovanni, Rikard Vinge .etc.|<http://arxiv.org/pdf/2503.01505v2>|概述了神经网络压缩在地球观测和地球系统模型数据中的应用，强调了其在处理大规模地理空间数据中的潜力。|
|🆕 发布|Bayesian Modelling of Multi-Year Crop Type Classification Using Deep Neural Networks and Hidden Markov Models|利用深度神经网络和隐马尔可夫模型进行多年作物类型分类的贝叶斯建模|Gianmarco Perantoni, Giulio Weikmann, Lorenzo Bruzzone|<http://arxiv.org/pdf/2510.07008v1>|结合深度学习和贝叶斯模型，提出了一种利用隐藏马尔可夫模型和变压器编码器进行多年作物类型分类的方法，有...|
|📝 更新|Gaze Estimation for Human-Robot Interaction: Analysis Using the NICO Platform|人机交互中的视线估计：基于NICO平台的分析|Matej Palider, Omar Eldardeer, Viktor Kocur|<http://arxiv.org/pdf/2509.24001v2>|评估了现有视线估计方法在共享工作空间的人机交互场景中的表现，并引入了一个新的标注数据集。|
|🆕 发布|FEAorta: A Fully Automated Framework for Finite Element Analysis of the Aorta From 3D CT Images|FEAorta：基于三维CT图像的主动脉有限元分析全自动框架|Jiasong Chen, Linchen Qian, Ruonan Gong, Christina Sun, Tongran Qin, Thuy Pham, Caitlin Martin, Mohammad Zafar .etc.|<http://arxiv.org/pdf/2510.06621v1>|提出了一种自动生成患者特异性的主动脉有限元网格的深度学习方法，大幅降低了3D重建的工作量和计算时间。|
|🆕 发布|SDQM: Synthetic Data Quality Metric for Object Detection Dataset Evaluation|合成数据质量度量指标（SDQM）：用于目标检测数据集评估|Ayush Zenith, Arnold Zumbrun, Neel Raut, Jing Lin|<http://arxiv.org/pdf/2510.06596v1>|[代码](https://github.com/ayushzenith/SDQM); 提出SDQM评估指标，有效衡量合成数据集质量，提高对象检测任务性能。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Is My Data in Your AI? Membership Inference Test (MINT) applied to Face Biometrics|我的数据在您的AI中吗？成员推断测试（MINT）应用于人脸生物特征识别|Daniel DeAlcala, Aythami Morales, Julian Fierrez, Gonzalo Mancera, Ruben Tolosana, Javier Ortega-Garcia|<http://arxiv.org/pdf/2402.09225v4>|提出了一种Membership Inference Test (MINT)方法，能检测特定数据是否被...|
|🆕 发布|Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications|面向机器人学的视觉-语言-动作模型：面向实际应用的综述|Kento Kawaharazuka, Jihoon Oh, Jun Yamada, Ingmar Posner, Yuke Zhu|<http://arxiv.org/pdf/2510.07077v1>|系统综述了Vision-Language-Action模型，推动机器人灵活应对多样化任务与真实环境。|
|📝 更新|OneVision: An End-to-End Generative Framework for Multi-view E-commerce Vision Search|"OneVision：一种用于多视角电商视觉搜索的端到端生成框架"|Zexin Zheng, Huangyu Dai, Lingtao Mao, Xinyu Sun, Zihan Liang, Ben Chen, Yuqing Ding, Chenyi Lei .etc.|<http://arxiv.org/pdf/2510.05759v2>|提出端到端生成框架OneVision，通过视觉对齐残差量化和多阶段语义对齐，优化电商视觉搜索的用户体...|
|📝 更新|Adaptive Rank, Reduced Forgetting: Knowledge Retention in Continual Learning Vision-Language Models with Dynamic Rank-Selective LoRA|自适应排名，减少遗忘：动态排名选择LoRA的持续学习视觉-语言模型中的知识保持|Haodong Lu, Chongyang Zhao, Jason Xue, Lina Yao, Kristen Moore, Dong Gong|<http://arxiv.org/pdf/2412.01004v6>|[代码](https://github.com/jeff024/codyra.); 提出了一种自适应调整秩的LoRA方法，实现了视觉语言模型在持续学习中的知识保持与遗忘平衡。|
|🆕 发布|SCas4D: Structural Cascaded Optimization for Boosting Persistent 4D Novel View Synthesis|SCas4D：结构级联优化以提升持久性四维新视角合成|Jipeng Lyu, Jiahua Dong, Yu-Xiong Wang|<http://arxiv.org/pdf/2510.06694v1>|提出了一种结构级联优化的方法SCas4D，通过利用现实世界变形的层次结构，大幅提升动态场景建模效率。|
|📝 更新|Decomposed Global Optimization for Robust Point Matching with Low-Dimensional Branching|分解全局优化方法用于具有低维分支的鲁棒点匹配|Wei Lian, Zhesen Cui, Fei Ma, Hang Pan, Wangmeng Zuo, Jianmei Zhang|<http://arxiv.org/pdf/2405.08589v2>|提出全局优化方法，将Robust Point Matching问题转化为低维凸二次规划，增强了对非刚...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PolyPose: Deformable 2D/3D Registration via Polyrigid Transformations|PolyPose：基于多项刚体变换的变形二维/三维配准|Vivek Gopalakrishnan, Neel Dey, Polina Golland|<http://arxiv.org/pdf/2505.19256v4>|提出了一种基于多刚体变换的2D/3D配准方法PolyPose，实现了仅用两张X射线图像就能准确对齐患...|
|🆕 发布|Introspection in Learned Semantic Scene Graph Localisation|内省式学习在语义场景图定位中的应用|Manshika Charvi Bissessur, Efimia Panagiotaki, Daniele De Martini|<http://arxiv.org/pdf/2510.07053v1>|探究语义如何影响定位性能和鲁棒性，验证了集成梯度和注意力权重在解释模型行为上的可靠性。|
|🆕 发布|Capture and Interact: Rapid 3D Object Acquisition and Rendering with Gaussian Splatting in Unity|"捕捉与交互：在Unity中利用高斯散点法进行快速三维物体获取与渲染"|Islomjon Shukhratov, Sergey Gorinsky|<http://arxiv.org/pdf/2510.06802v1>|利用3D高斯散点技术实现移动设备快速扫描和实时渲染三维物体。|
|🆕 发布|Efficient Discriminative Joint Encoders for Large Scale Vision-Language Reranking|大规模视觉语言重排的高效判别性联合编码器|Mitchell Keren Taraday, Shahaf Wagner, Chaim Baskin|<http://arxiv.org/pdf/2510.06820v1>|提出了一种高效的视觉-语言联合编码器EDJE，通过预计算和压缩视觉特征，大幅降低存储和计算需求，实现...|
|📝 更新|A Deep Learning System for Rapid and Accurate Warning of Acute Aortic Syndrome on Non-contrast CT in China|中国地区基于非增强CT的急性主动脉综合征快速准确预警的深度学习系统|Yujian Hu, Yilang Xiang, Yan-Jie Zhou, Yangyan He, Dehai Lang, Shifeng Yang, Xiaolong Du, Chunlan Den .etc.|<http://arxiv.org/pdf/2406.15222v5>|提出了一种基于深度学习的预警系统iAorta，利用非对比CT快速准确识别急性主动脉综合征。|
|📝 更新|Robust Neural Rendering in the Wild with Asymmetric Dual 3D Gaussian Splatting|野外环境下基于非对称双三次高斯散点的鲁棒神经渲染|Chengqi Li, Zhihao Shi, Yangdi Lu, Wenbo He, Xiangyu Xu|<http://arxiv.org/pdf/2506.03538v3>|[代码](https://steveli88.github.io/AsymGS.); 提出了一种不对称双3D高斯散点渲染框架，有效处理野外观测中的光照不均和干扰问题，提高了三维重建的稳定...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 视觉安全与隐私 (Visual Security & Privacy)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Sustainable Self-evolution Adversarial Training|可持续自演化对抗训练|Wenxuan Wang, Chenglei Wang, Huihui Qi, Menghao Ye, Xuelin Qian, Peng Wang, Yanning Zhang|<http://arxiv.org/pdf/2412.02270v2>|[代码](https://github.com/aup520/SSEAT); 提出了一种可持续自我演化的对抗训练框架，有效应对动态变化的攻击方法，增强模型长期应用的防御性能。|
|📝 更新|DiffMI: Breaking Face Recognition Privacy via Diffusion-Driven Training-Free Model Inversion|差分隐私破坏：通过扩散驱动训练无关模型反转人脸识别隐私|Hanrui Wang, Shuo Wang, Chun-Shien Lu, Isao Echizen|<http://arxiv.org/pdf/2504.18015v3>|[代码](https://github.com/azrealwang/DiffMI.); 提出了一种无训练需求的扩散驱动模型反转攻击方法DiffMI，有效突破面部识别隐私保护。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Maximising the Utility of Validation Sets for Imbalanced Noisy-label Meta-learning|最大化不平衡噪声标签元学习验证集的效用|Dung Anh Hoang, Cuong Nguyen, Belagiannis Vasileios, Thanh-Toan Do, Gustavo Carneiro|<http://arxiv.org/pdf/2208.08132v4>|提出新标准以优化验证集构建，提出INOLML算法自动提升其效用，实现不平衡噪声标签学习的性能提升。|
|🆕 发布|High-Rate Mixout: Revisiting Mixout for Robust Domain Generalization|高比率Mixout：重新审视Mixout以实现稳健的域泛化|Masih Aminbeidokhti, Heitor Rapela Medeiros, Eric Granger, Marco Pedersoli|<http://arxiv.org/pdf/2510.06955v1>|提出高率Mixout方法，通过概率性权重交换提升域泛化能力，减少训练成本。|
|📝 更新|Domain Generalization by Rejecting Extreme Augmentations|通过拒绝极端增强实现域泛化|Masih Aminbeidokhti, Fidel A. Guerrero Peña, Heitor Rapela Medeiros, Thomas Dubail, Eric Granger, Marco Pedersoli|<http://arxiv.org/pdf/2310.06670v2>|[代码](https://github.com/Masseeh/DCAug); 提出了一种针对域泛化的数据增强策略，通过拒绝极端增强来提高模型在未知域的准确度。|
|🆕 发布|Continual Action Quality Assessment via Adaptive Manifold-Aligned Graph Regularization|通过自适应流形对齐图正则化实现的连续动作质量评估|Kanglei Zhou, Qingyi Pan, Xingxing Zhang, Hubert P. H. Shum, Frederick W. B. Li, Xiaohui Liang, Liyuan Wang|<http://arxiv.org/pdf/2510.06842v1>|[代码](https://github.com/ZhouKanglei/MAGRPP.); 提出了一种针对动态质量分布的连续动作质量评估方法，通过自适应流形对齐图正则化有效缓解灾难性遗忘。|
|🆕 发布|Transforming Noise Distributions with Histogram Matching: Towards a Single Denoiser for All|利用直方图匹配转换噪声分布：迈向通用降噪器|Sheng Fu, Junchao Zhang, Kailun Yang|<http://arxiv.org/pdf/2510.06757v1>|提出了一种通过直方图匹配转换噪声分布的方法，使单一去噪器能有效应对多种未知噪声类型。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Guardians of Image Quality: Benchmarking Defenses Against Adversarial Attacks on Image Quality Metrics|图像质量的守护者：对抗图像质量度量指标对抗攻击的防御基准测试|Alexander Gushchin, Khaled Abud, Georgii Bychkov, Ekaterina Shumitskaya, Anna Chistyakova, Sergey Lavrushkin, Bader Rasheed, Kirill Malyshev .etc.|<http://arxiv.org/pdf/2408.01541v2>|系统评估了25种防御策略对抗图像质量评估指标中的对抗攻击，旨在提升评估指标的稳健性。|
|📝 更新|GreedyPixel: Fine-Grained Black-Box Adversarial Attack Via Greedy Algorithm|贪心像素：通过贪心算法实现的细粒度黑盒对抗攻击|Hanrui Wang, Ching-Chun Chang, Chun-Shien Lu, Christopher Leckie, Isao Echizen|<http://arxiv.org/pdf/2501.14230v2>|[代码](https://github.com/azrealwang/greedypixel.); GreedyPixel通过结合代理模型和贪心算法，实现了高效的细粒度黑盒攻击，提高了攻击成功率并保持...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality|知行强化学习：探索基于知识的真实性强化学习|Baochang Ren, Shuofei Qiao, Da Zheng, Huajun Chen, Ningyu Zhang|<http://arxiv.org/pdf/2506.19807v3>|[代码](https://github.com/zjunlp/KnowRL.); 提出KnowRL方法，通过引入事实性奖励，减少大型语言模型在推理过程中的虚构现象。|
|🆕 发布|Validation of Various Normalization Methods for Brain Tumor Segmentation: Can Federated Learning Overcome This Heterogeneity?|《验证不同归一化方法在脑肿瘤分割中的有效性：联邦学习能否克服这种异质性？》|Jan Fiszer, Dominika Ciupek, Maciej Malawski|<http://arxiv.org/pdf/2510.07126v1>|[代码](https://github.com/SanoScience/fl-varying-normalization.); 探究了不同MRI强度归一化方法对脑肿瘤分割模型的影响，并证实联邦学习能有效应对数据异质性。|
|📝 更新|MetaSlot: Break Through the Fixed Number of Slots in Object-Centric Learning|元槽位：在以对象为中心的学习中突破固定槽位数限制|Hongjia Liu, Rongzhen Zhao, Haohan Chen, Joni Pajarinen|<http://arxiv.org/pdf/2505.20772v2>|MetaSlot突破传统对象中心学习方法固定槽数量限制，通过自适应调整实现更优的对象表示和性能提升。|
|🆕 发布|Bionetta: Efficient Client-Side Zero-Knowledge Machine Learning Proving|"BioNetta：高效客户端零知识机器学习证明"|Dmytro Zakharov, Oleksandr Kurbatov, Artem Sdobnov, Lev Soukhanov, Yevhenii Sekhin, Vitalii Volovyk, Mykhailo Velykodnyi, Mark Cherepovskyi .etc.|<http://arxiv.org/pdf/2510.06784v1>|Bionetta通过优化零知识证明，实现了在移动设备上快速证明定制神经网络，适用于EVM智能合约。|
|📝 更新|IRNet: Iterative Refinement Network for Noisy Partial Label Learning|噪声部分标签学习的迭代细化网络（IRNet）|Zheng Lian, Mingyu Xu, Lan Chen, Licai Sun, Bin Liu, Lei Feng, Jianhua Tao|<http://arxiv.org/pdf/2211.04774v6>|[代码](https://github.com/zeroQiaoba/IRNet.); 提出迭代精炼网络 IRNet 处理带噪声的部分标注学习问题，通过样本净化和标签校正提升性能。|
|🆕 发布|A deep multiple instance learning approach based on coarse labels for high-resolution land-cover mapping|基于粗标签的深度多实例学习方法用于高分辨率土地覆盖制图|Gianmarco Perantoni, Lorenzo Bruzzone|<http://arxiv.org/pdf/2510.06769v1>|提出了一种基于弱标签的高分辨率土地覆盖分类方法，通过深度多实例学习有效结合高低分辨率数据。|
|📝 更新|GPS-MTM: Capturing Pattern of Normalcy in GPS-Trajectories with self-supervised learning|GPS-MTM：利用自监督学习捕捉GPS轨迹中的正常模式|Umang Garg, Bowen Zhang, Anantajit Subrahmanya, Chandrakanth Gudavalli, BS Manjunath|<http://arxiv.org/pdf/2509.24031v2>|提出GPS-MTM模型，通过自监督学习捕捉人类移动的正常模式，提升轨迹预测和分析性能。|
|📝 更新|VT-FSL: Bridging Vision and Text with LLMs for Few-Shot Learning|VT-FSL：使用大规模语言模型连接视觉与文本以进行少样本学习|Wenhao Li, Qiangchang Wang, Xianjing Meng, Zhibin Wu, Yilong Yin|<http://arxiv.org/pdf/2509.25033v2>|[代码](https://github.com/peacelwh/VT-FSL.); 提出了一种融合大型语言模型和视觉信息的VT-FSL框架，通过迭代提示和几何对齐，有效提升少量样本学习...|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhancing Concept Localization in CLIP-based Concept Bottleneck Models|增强基于CLIP的概念瓶颈模型中的概念定位能力|Rémi Kazmierczak, Steve Azzolin, Eloïse Berthier, Goran Frehse, Gianni Franchi|<http://arxiv.org/pdf/2510.07115v1>|提出CHILI方法，抑制CLIP模型在概念定位中的幻觉现象，增强解释性。|
|🆕 发布|A Bridge from Audio to Video: Phoneme-Viseme Alignment Allows Every Face to Speak Multiple Languages|从音频到视频的桥梁：音素-视觉对齐使得任何一张脸都能说出多种语言|Zibo Su, Kun Wei, Jiahua Li, Xu Yang, Cheng Deng|<http://arxiv.org/pdf/2510.06612v1>|提出了一种跨语言语音驱动的面部合成框架，通过音素-口型对应改善多语言面部动画的逼真度和泛化能力。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|The False Promise of Zero-Shot Super-Resolution in Machine-Learned Operators|机器学习操作符中零样本超分辨率虚假承诺|Mansi Sakarvadia, Kareem Hegazy, Amin Totounferoush, Kyle Chard, Yaoqing Yang, Ian Foster, Michael W. Mahoney|<http://arxiv.org/pdf/2510.06646v1>|指出机器学习算子在零样本超分辨率上的局限性，并提出了一个有效的多分辨率训练协议。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MMPerspective: Do MLLMs Understand Perspective? A Comprehensive Benchmark for Perspective Perception, Reasoning, and Robustness|MMPerspective：多模态语言模型是否理解视角？一种全面的视角感知、推理和鲁棒性基准|Yolo Yunlong Tang, Pinxin Liu, Mingqian Feng, Zhangyun Tan, Rui Mao, Chao Huang, Jing Bi, Yunzhong Xiao .etc.|<http://arxiv.org/pdf/2505.20426v2>|[代码](https://yunlong10.github.io/MMPerspective); 提出MMPerspective基准，首次系统评估大型多模态语言模型对透视理解的能力。|
|🆕 发布|TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics|TIGeR：面向机器人视觉语言模型的工具集成几何推理|Yi Han, Cheng Chi, Enshen Zhou, Shanyu Rong, Jingkun An, Pengwei Wang, Zhongyuan Wang, Lu Sheng .etc.|<http://arxiv.org/pdf/2510.07181v1>|提出了一种利用外部工具进行几何计算的新框架，使视觉语言模型在机器人操作中实现厘米级精度。|
|📝 更新|AerialVG: A Challenging Benchmark for Aerial Visual Grounding by Exploring Positional Relations|《AerialVG：通过探索位置关系构建的航空视觉定位基准测试》|Junli Liu, Qizhi Chen, Zhigang Wang, Yiwen Tang, Yiting Zhang, Chi Yan, Dong Wang, Xuelong Li .etc.|<http://arxiv.org/pdf/2504.07836v4>|提出了针对航空视觉定位的新任务和模型，强调位置关系处理，提高了空间推理能力。|
|🆕 发布|Are We Using the Right Benchmark: An Evaluation Framework for Visual Token Compression Methods|我们是否使用了正确的基准：视觉标记压缩方法评估框架|Chenfei Liao, Wensong Wang, Zichen Wen, Xu Zheng, Yiyu Wang, Haocong He, Yuanhuiyi Lyu, Lutao Jiang .etc.|<http://arxiv.org/pdf/2510.07143v1>|[代码](https://github.com/Chenfei-Liao/VTC-Bench.); 提出新的视觉token压缩评估框架VTC-Bench，解决现有基准任务不匹配问题，提高评估准确性。|
|🆕 发布|TTRV: Test-Time Reinforcement Learning for Vision Language Models|测试时强化学习用于视觉语言模型：TTRV|Akshit Singh, Shyam Marjit, Wei Lin, Paul Gavrikov, Serena Yeung-Levy, Hilde Kuehne, Rogerio Feris, Sivan Doveh .etc.|<http://arxiv.org/pdf/2510.06783v1>|提出了一种无需标注数据，通过测试时强化学习即时适应模型的方法，显著提升了视觉语言理解性能。|
|🆕 发布|StaR-KVQA: Structured Reasoning Traces for Implicit-Knowledge Visual Question Answering|StaR-KVQA：用于隐知识视觉问答的结构化推理轨迹|Zhihao Wen, Wenkang Wei, Yuan Fang, Xingtong Yu, Hui Zhang, Weicheng Zhu, Xin Zhang|<http://arxiv.org/pdf/2510.06638v1>|StaR-KVQA通过监督结构化推理轨迹，提升了视觉问答的准确性和可解释性。|
|📝 更新|Video-in-the-Loop: Span-Grounded Long Video QA with Interleaved Reasoning|视频循环：带交错推理的跨 grounded 长视频问答|Chendong Wang, Donglin Bai, Yifan Yang, Xiao Jin, Anlan Zhang, Rui Wang, Shiqi Jiang, Yuqing Yang .etc.|<http://arxiv.org/pdf/2510.04022v3>|提出Video-in-the-Loop框架，通过分阶段处理实现长视频问答的高效性和准确性。|
|📝 更新|LoDisc: Learning Global-Local Discriminative Features for Self-Supervised Fine-Grained Visual Recognition|《LoDisc：用于自监督细粒度视觉识别的全局-局部判别性特征学习》|Jialu Shi, Zhiqiang Wei, Jie Nie, Lei Huang|<http://arxiv.org/pdf/2403.04066v2>|引入局部区分任务，提升自监督学习在细粒度视觉识别中的表现。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SubGrapher: Visual Fingerprinting of Chemical Structures|子图分析器：化学结构的视觉指纹识别|Lucas Morin, Gerhard Ingmar Meijer, Valéry Weber, Luc Van Gool, Peter W. J. Staar|<http://arxiv.org/pdf/2504.19695v2>|提出SubGrapher方法，通过直接提取化学结构图像的分子指纹，提高了化学结构检索的准确性和鲁棒性...|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RePIC: Reinforced Post-Training for Personalizing Multi-Modal Language Models|RePIC: 强化后训练以个性化多模态语言模型|Yeongtak Oh, Dohyun Chung, Juhyeon Shin, Sangha Park, Johan Barthelemy, Jisoo Mok, Sungroh Yoon|<http://arxiv.org/pdf/2506.18369v3>|[代码](https://github.com/oyt9306/RePIC); 提出了一种基于强化学习的多模态语言模型个性化后训练方法，有效提升了模型在个性化图像描述方面的表现。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Graph Conditioned Diffusion for Controllable Histopathology Image Generation|图条件扩散用于可控病理图像生成|Sarah Cechnicka, Matthew Baugh, Weitong Zhang, Mischa Dombrowski, Zhe Li, Johannes C. Paetzold, Candice Roufosse, Bernhard Kainz|<http://arxiv.org/pdf/2510.07129v1>|提出图条件扩散方法，通过对象级图表示实现医学图像的精细控制生成。|
|📝 更新|Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine|面向生物医学的具有像素级洞察的多模态大型语言模型|Xiaoshuang Huang, Lingdong Shen, Jia Liu, Fangxin Shang, Hongxiang Li, Haifeng Huang, Yehui Yang|<http://arxiv.org/pdf/2412.09278v3>|[代码](https://github.com/ShawnHuang497/MedPLIB.); 提出MedPLIB模型，实现生物医学领域的像素级理解，提升多模态大语言模型的多任务处理能力。|
|🆕 发布|U-Bench: A Comprehensive Understanding of U-Net through 100-Variant Benchmarking|U-Bench：通过100种变体基准测试对U-Net的全面理解|Fenghe Tang, Chengqi Dong, Wenxin Ma, Zikang Xu, Heqin Zhu, Zihang Jiang, Rongsheng Wang, Yuhao Wang .etc.|<http://arxiv.org/pdf/2510.07041v1>|[代码](https://github.com/FengheTan9/U-Bench.); 提出了U-Bench，首个大规模、统计严谨的U-Net变体性能评估框架，全面评价了100种变体的性能...|
|🆕 发布|Label-frugal satellite image change detection with generative virtual exemplar learning|带有生成虚拟样本学习的标签节约型卫星图像变化检测|Hichem Sahbi|<http://arxiv.org/pdf/2510.06926v1>|提出了一种基于主动学习的卫星图像变化检测算法，通过生成虚拟样本减少标注需求，提高了学习效率。|
|📝 更新|Unified Unsupervised Anomaly Detection via Matching Cost Filtering|通过匹配成本过滤的统一无监督异常检测|Zhe Zhang, Mingxiu Cai, Gaochang Wu, Jing Zhang, Lingqiao Liu, Dacheng Tao, Tianyou Chai, Xiatian Zhu|<http://arxiv.org/pdf/2510.03363v2>|[代码](https://github.com/ZHE-SAPI/CostFilter-AD.); 提出了一种统一的无监督异常检测框架，通过匹配成本过滤有效降低噪声，提升了对各类模态数据中细微异常的检...|
|🆕 发布|Lung Infection Severity Prediction Using Transformers with Conditional TransMix Augmentation and Cross-Attention|使用带有条件TransMix增强和交叉注意力的变换器进行肺部感染严重程度预测|Bouthaina Slika, Fadi Dornaika, Fares Bougourzi, Karim Hammoudi|<http://arxiv.org/pdf/2510.06887v1>|[代码](https://github.com/bouthainas/QCross-Att-PVT.); 提出了一种基于Transformer的肺感染严重程度预测方法，通过交叉注意力和条件数据增强显著提升了...|
|📝 更新|Train-Free Segmentation in MRI with Cubical Persistent Homology|MRI中的无训练分割与立方持久同调|Anton François, Raphaël Tinarrage|<http://arxiv.org/pdf/2401.01160v2>|提出了一种基于拓扑数据分析的MRI扫描无训练分割框架，无需大量标注数据即可实现精确分割。|
|📝 更新|Intelligent Healthcare Imaging Platform: A VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation|智能医疗影像平台：基于大型语言模型的自动化医疗影像分析及临床报告生成框架|Samer Al-Hamadani|<http://arxiv.org/pdf/2509.13590v2>|提出了一种基于视觉语言模型的医疗影像分析框架，实现了自动化肿瘤检测和临床报告生成。|
|📝 更新|acia-workflows: Automated Single-cell Imaging Analysis for Scalable and Deep Learning-based Live-cell Imaging Analysis Workflows|acia工作流：基于可扩展性和深度学习的自动化单细胞成像分析活细胞成像分析工作流|Johannes Seiffarth, Keitaro Kasahara, Michelle Bund, Benita Lückel, Richard D. Paul, Matthias Pesch, Lennart Witting, Michael Bott .etc.|<http://arxiv.org/pdf/2510.05886v2>|[代码](https://github.com/JuBiotech/acia-workflows.); 提出了一种集成深度学习工具的自动化单细胞成像分析平台，简化了活细胞成像数据分析流程。|
|📝 更新|Efficient Universal Models for Medical Image Segmentation via Weakly Supervised In-Context Learning|通过弱监督上下文学习实现医学图像分割的高效通用模型|Jiesi Hu, Yanwu Yang, Zhiyu Ye, Jinyan Zhou, Jianfeng Cao, Hanyang Peng, Ting Ma|<http://arxiv.org/pdf/2510.05899v2>|[代码](https://github.com/jiesihu/Weak-ICL.); 提出弱监督在位学习（WS-ICL）方法，减少医疗图像分割标注工作量，实现高效通用模型训练。|
|📝 更新|TFM Dataset: A Novel Multi-task Dataset and Integrated Pipeline for Automated Tear Film Break-Up Segmentation|TFM数据集：一种新颖的多任务数据集和自动泪膜破裂分割集成管道|Guangrong Wan, Jun liu, Qiyang Zhou, Tang tang, Lianghao Shi, Wenjun Luo, TingTing Xu|<http://arxiv.org/pdf/2510.05615v2>|[代码](https://github.com/glory-wan/TF-Net); 提出了TFM数据集和TF-Net模型，实现了泪膜破裂自动分割，提高了干眼症诊断的准确性和效率。|
|🆕 发布|Adaptive Stain Normalization for Cross-Domain Medical Histology|跨域医学组织学自适应染料归一化|Tianyue Xu, Yanlin Wu, Abhai K. Tripathi, Matthew M. Ippolito, Benjamin D. Haeffele|<http://arxiv.org/pdf/2510.06592v1>|[代码](https://github.com/xutianyue/BeerLaNet.); 提出了一种基于物理原理的可训练颜色归一化模型，有效解决了不同条件下医学组织图像的颜色不一致问题。|
|🆕 发布|AIM 2025 Challenge on Real-World RAW Image Denoising|AIM 2025挑战：面向现实世界的RAW图像去噪|Feiran Li, Jiacheng Li, Marcos V. Conde, Beril Besbinar, Vlad Hosu, Daisuke Iso, Radu Timofte|<http://arxiv.org/pdf/2510.06601v1>|提出了AIM 2025挑战，通过合成数据推动低光RAW图像去噪技术的发展。|
|🆕 发布|Improving Artifact Robustness for CT Deep Learning Models Without Labeled Artifact Images via Domain Adaptation|通过域自适应提高CT深度学习模型对伪影的鲁棒性，无需标记的伪影图像|Justin Cheung, Samuel Savine, Calvin Nguyen, Lin Lu, Alhassan S. Yasin|<http://arxiv.org/pdf/2510.06584v1>|提出了一种无需标注新伪影图像的域自适应方法，有效提高了CT图像分类模型对新型伪影的鲁棒性。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Few-Shot Adaptation Benchmark for Remote Sensing Vision-Language Models|遥感视觉语言模型的少量样本适应基准|Karim El Khoury, Maxime Zanella, Christophe De Vleeschouwer, Benoit Macq|<http://arxiv.org/pdf/2510.07135v1>|[代码](https://github.com/elkhouryk/fewshot_RSVLMs); 提出了首个用于评估遥感视觉语言模型在少量样本条件下的适应性的结构化基准。|
|🆕 发布|Explaining raw data complexity to improve satellite onboard processing|将原始数据复杂性解释以提高卫星在轨处理能力|Adrien Dorise, Marjorie Bellizzi, Adrien Girard, Benjamin Francesconi, Stéphane May|<http://arxiv.org/pdf/2510.06858v1>|探究了利用原始卫星数据训练深度学习模型，提出改进轮廓识别方法以增强在轨AI性能。|
|🆕 发布|Evaluating LLMs for Historical Document OCR: A Methodological Framework for Digital Humanities|评估大型语言模型在历史文档OCR中的应用：数字人文研究的方法论框架|Maria Levchenko|<http://arxiv.org/pdf/2510.06743v1>|提出了一套针对历史文档OCR的评估框架，引入新指标以减少大语言模型的历史偏差和错误。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models|Roboflow100-VL：面向视觉语言模型的多领域目标检测基准|Peter Robicheaux, Matvei Popov, Anish Madan, Isaac Robinson, Joseph Nelson, Deva Ramanan, Neehar Peri|<http://arxiv.org/pdf/2505.20612v3>|[代码](https://github.com/roboflow/rf100-vl); 提出了Roboflow100-VL多模态对象检测数据集，通过少量视觉示例和丰富文本描述，提升视觉语言...|
|🆕 发布|Automated Neural Architecture Design for Industrial Defect Detection|工业缺陷检测的自动化神经网络架构设计|Yuxi Liu, Yunfeng Ma, Yi Tang, Min Liu, Shuai Jiang, Yaonan Wang|<http://arxiv.org/pdf/2510.06669v1>|[代码](https://github.com/Yuxi104/AutoNAD.); 提出自动神经架构设计框架AutoNAD，有效解决工业表面缺陷检测的挑战，提升检测准确性和效率。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Quantum-enhanced Computer Vision: Going Beyond Classical Algorithms|量子增强计算机视觉：超越经典算法|Natacha Kuete Meli, Shuteng Wang, Marcel Seelbach Benkner, Michele Sasdelli, Tat-Jun Chin, Tolga Birdal, Michael Moeller, Vladislav Golyanik|<http://arxiv.org/pdf/2510.07317v1>|概述了量子增强计算机视觉领域，提出量子计算在视觉信号处理中的优势及新算法开发需求。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RGS-DR: Deferred Reflections and Residual Shading in 2D Gaussian Splatting|RGS-DR：二维高斯散点绘制中的延迟反射与残差着色|Georgios Kouros, Minye Wu, Tinne Tuytelaars|<http://arxiv.org/pdf/2504.18468v5>|通过延迟着色和残差处理改进二维高斯散点渲染中的镜面反射，提高了渲染质量和材料编辑性。|
|🆕 发布|Concept Retrieval -- What and How?|概念检索——检索什么与如何检索？|Ori nizan, Oren Shrout, Ayellet Tal|<http://arxiv.org/pdf/2510.07058v1>|提出了一种基于图像概念检索的新方法，通过建模邻居关系发现并识别图像间的核心概念。|
|🆕 发布|Angular Constraint Embedding via SpherePair Loss for Constrained Clustering|通过球对损失实现角度约束嵌入的约束聚类|Shaojie Zhang, Ke Chen|<http://arxiv.org/pdf/2510.06907v1>|[代码](https://github.com/spherepaircc/SpherePairCC); 提出了一种SpherePair损失函数，通过在角空间进行约束聚类，有效分离了表示学习与聚类过程，提高...|
|🆕 发布|StruSR: Structure-Aware Symbolic Regression with Physics-Informed Taylor Guidance|结构感知的符号回归：基于物理信息泰勒引导|Yunpeng Gong, Sihan Lan, Can Yang, Kunpeng Xu, Min Jiang|<http://arxiv.org/pdf/2510.06635v1>|提出结构感知的符号回归框架StruSR，利用物理信息神经网络从时间序列中提取物理先验，加速并提高符号...|

