## [UPDATED!] **2025-10-09** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MATRIX: Multimodal Agent Tuning for Robust Tool-Use Reasoning|MATRIX：多模态智能体调优以实现鲁棒的工具使用推理|Tajamul Ashraf, Umair Nawaz, Abdelrahman M. Shaker, Rao Anwer, Philip Torr, Fahad Shahbaz Khan, Salman Khan|<http://arxiv.org/pdf/2510.08567v1>|[代码](https://github.com/mbzuai-oryx/MATRIX.); 提出了一种自动合成多模态轨迹的视觉中心代理调优框架，通过模仿学习和偏好对学习，提高了工具使用推理的鲁...|
|🆕 发布|How to Teach Large Multimodal Models New Skills|如何教授大型多模态模型新技能|Zhen Zhu, Yiming Gong, Yao Xiao, Yaoyao Liu, Derek Hoiem|<http://arxiv.org/pdf/2510.08564v1>|[代码](https://github.com/jessemelpolio/LMM_CL); 提出方法有效教会大型多模态模型新技能，同时减少对原有能力的负面影响。|
|📝 更新|Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models|视频LMM后训练：深入探索大型多模态模型在视频推理中的应用|Yolo Yunlong Tang, Jing Bi, Pinxin Liu, Zhenyu Pan, Zhangyun Tan, Qianxiang Shen, Jiani Liu, Hang Hua .etc.|<http://arxiv.org/pdf/2510.05034v3>|[代码](https://github.com/yunlong10/Awesome-Video-LMM-Post-Training); 系统梳理了视频理解中大型多模态模型的后训练方法，提升了模型在时空推理和跨模态证据整合方面的能力。|
|🆕 发布|ARTDECO: Towards Efficient and High-Fidelity On-the-Fly 3D Reconstruction with Structured Scene Representation|ARTDECO：面向高效和高保真实时三维重建的结构化场景表示方法|Guanghao Li, Kerui Ren, Linning Xu, Zhewen Zheng, Changjian Jiang, Xin Gao, Bo Dai, Jian Pu .etc.|<http://arxiv.org/pdf/2510.08551v1>|[代码](https://city-super.github.io/artdeco); 提出了一种结合了前馈模型效率和SLAM可靠性的ARTDECO框架，实现了高效且高保真的实时3D重建。|
|🆕 发布|MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization|MM-HELIX：利用整体平台与自适应混合策略优化提升多模态长链反射性推理|Xiangyu Zhao, Junming Lin, Tianhao Liang, Yifan Zhou, Wenhao Chai, Yuzhe Gu, Weiyun Wang, Kai Chen .etc.|<http://arxiv.org/pdf/2510.08540v1>|提出了一种自适应混合策略优化方法，显著提升了多模态大语言模型在长链反思性推理任务上的性能。|
|📝 更新|Zebra-CoT: A Dataset for Interleaved Vision Language Reasoning|斑马-联合推理数据集：用于交错视觉语言推理的数据集|Ang Li, Charles Wang, Deqing Fu, Kaiyu Yue, Zikui Cai, Wang Bill Zhu, Ollie Liu, Peng Guo .etc.|<http://arxiv.org/pdf/2507.16746v2>|提出Zebra-CoT数据集，增强多模态模型视觉推理能力，显著提升模型准确性和表现。|
|🆕 发布|Better Together: Leveraging Unpaired Multimodal Data for Stronger Unimodal Models|《携手共进：利用未配对的多模态数据增强单模态模型》|Sharut Gupta, Shobhita Sundaram, Chenyu Wang, Stefanie Jegelka, Phillip Isola|<http://arxiv.org/pdf/2510.08492v1>|提出了一种无需配对的多模态学习框架UML，通过跨模态数据共享参数增强单模态表征学习。|
|🆕 发布|A Multimodal Depth-Aware Method For Embodied Reference Understanding|一种多模态深度感知方法用于具身参照理解|Fevziye Irem Eyiokur, Dogucan Yaman, Hazım Kemal Ekenel, Alexander Waibel|<http://arxiv.org/pdf/2510.08278v1>|提出了一种深度感知的多模态方法，有效提升了基于语言和手势的视觉场景目标识别准确性。|
|📝 更新|SaFeR-VLM: Toward Safety-aware Fine-grained Reasoning in Multimodal Models|面向安全的细粒度推理在多模态模型中的研究：SaFeR-VLM|Huahui Yi, Kun Wang, Qiankun Li, Miao Yu, Liang Lin, Gongli Xi, Hao Wu, Xuming Hu .etc.|<http://arxiv.org/pdf/2510.06871v2>|[代码](https://github.com/HarveyYi/SaFeR-VLM.); 提出了一种将安全性嵌入到多模态推理过程中的强化学习框架，有效提升了模型在对抗和危险情境下的稳健性和安...|
|📝 更新|MotionSight: Boosting Fine-Grained Motion Understanding in Multimodal LLMs|《MotionSight：在多模态大型语言模型中提升细粒度运动理解》|Yipeng Du, Tiehan Fan, Kepan Nan, Rui Xie, Penghao Zhou, Xiang Li, Jian Yang, Zhenheng Yang .etc.|<http://arxiv.org/pdf/2506.01674v2>|提出了一种零样本方法MotionSight，通过引入视觉提示显著提升多模态大语言模型对视频细微运动的...|
|📝 更新|BRIGHT: A globally distributed multimodal building damage assessment dataset with very-high-resolution for all-weather disaster response|"BRIGHT：一种用于全天候灾害响应的全景分布多模态建筑损毁评估数据集，具备非常高分辨率"|Hongruixuan Chen, Jian Song, Olivier Dietrich, Clifford Broni-Bediako, Weihao Xuan, Junjue Wang, Xinlei Shao, Yimin Wei .etc.|<http://arxiv.org/pdf/2501.06019v4>|[代码](https://github.com/ChenHongruixuan/BRIGHT.); 介绍了首个全球分布的多模态建筑损毁评估数据集BRIGHT，支持全天候灾害响应的AI模型训练。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|NaViL: Rethinking Scaling Properties of Native Multimodal Large Language Models under Data Constraints|NaViL：在数据约束下重新思考原生多模态大型语言模型的缩放特性|Changyao Tian, Hao Li, Gen Luo, Xizhou Zhu, Weijie Su, Hanming Deng, Jinguo Zhu, Jie Shao .etc.|<http://arxiv.org/pdf/2510.08565v1>|探索了原生多模态大语言模型在数据约束下的训练策略，提出了平衡性能与成本的NaViL模型。|
|🆕 发布|SliceFine: The Universal Winning-Slice Hypothesis for Pretrained Networks|切片精修：预训练网络通用胜切片假设|Md Kowsher, Ali O. Polat, Ehsan Mohammady Ardehaly, Mehrdad Salehi, Zia Ghiasi, Prasanth Murali, Chen Chen|<http://arxiv.org/pdf/2510.08513v1>|提出了一种基于“胜出切片”理论的参数高效微调方法SliceFine，有效提升了预训练模型在下游任务中...|
|🆕 发布|X2Video: Adapting Diffusion Models for Multimodal Controllable Neural Video Rendering|X2Video：适应扩散模型用于多模态可控神经视频渲染|Zhitong Huang, Mohan Zhang, Renhan Wang, Rui Tang, Hao Zhu, Jing Liao|<http://arxiv.org/pdf/2510.08530v1>|[代码](https://luckyhzt.github.io/x2video); 提出X2Video模型，通过内在通道和参考图像、文本提示实现视频渲染的精确控制与高保真度。|
|🆕 发布|Unlocking 3D Affordance Segmentation with 2D Semantic Knowledge|解锁三维可达性分割：利用二维语义知识|Yu Huang, Zelin Peng, Changsong Wen, Xiaokang Yang, Wei Shen|<http://arxiv.org/pdf/2510.08316v1>|将二维视觉基础模型的语义知识转移到三维领域，提出了一种新的三维功能分割框架。|
|📝 更新|VisionTS++: Cross-Modal Time Series Foundation Model with Continual Pre-trained Vision Backbones|《VisionTS++：具有持续预训练视觉骨干的跨模态时间序列基础模型》|Lefei Shen, Mouxiang Chen, Xu Liu, Han Fu, Xiaoxue Ren, Jianling Sun, Zhuo Li, Chenghao Liu|<http://arxiv.org/pdf/2508.04379v2>|[代码](https://github.com/HALF111/VisionTSpp.); 提出VisionTS++模型，通过持续预训练视觉模型处理时间序列数据，有效桥接模态差异并提升预测性能...|
|📝 更新|LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training|LLaVA-OneVision-1.5：全面开放框架，实现多模态训练普及化|Xiang An, Yin Xie, Kaicheng Yang, Wenkang Zhang, Xiuwei Zhao, Zheng Cheng, Yirui Wang, Songcen Xu .etc.|<http://arxiv.org/pdf/2509.23661v2>|提出了LLaVA-OneVision-1.5框架，以低成本实现领先的多模态模型训练与性能。|
|📝 更新|DvD: Unleashing a Generative Paradigm for Document Dewarping via Coordinates-based Diffusion Model|DvD：通过基于坐标的扩散模型释放文档去扭曲的生成范式|Weiguang Zhang, Huangcheng Lu, Maizhen Ning, Xiaowei Huang, Wei Wang, Kaizhu Huang, Qiufeng Wang|<http://arxiv.org/pdf/2505.21975v2>|[代码](https://github.com/hanquansanren/DvD.); 提出了一种基于坐标级扩散模型的文档去扭曲方法，有效保持了文档结构的同时实现高效率矫正。|
|📝 更新|Scalable Cosmic AI Inference using Cloud Serverless Computing|使用云无服务器计算的可扩展宇宙人工智能推理|Mills Staylor, Amirreza Dolatpour Fathkouhi, Md Khairul Islam, Kaleigh O'Hara, Ryan Ghiles Goudjil, Geoffrey Fox, Judy Fox|<http://arxiv.org/pdf/2501.06249v3>|[代码](https://github.com/UVA-MLSys/AI-for-Astronomy.); 提出了一种基于云函数的宇宙AI推理框架，实现了高效、可扩展的天文图像处理，大幅降低了成本和时间。|
|🆕 发布|PIT-QMM: A Large Multimodal Model For No-Reference Point Cloud Quality Assessment|PIT-QMM：一种用于无参考点云质量评估的大型多模态模型|Shashank Gupta, Gregoire Phillips, Alan C. Bovik|<http://arxiv.org/pdf/2510.07636v1>|[代码](https://github.com/shngt/pit-qmm.); 提出了一种多模态模型PIT-QMM，通过融合文本、图像和点云数据，实现了无需参考的点云质量评估。|
|🆕 发布|Test-Time Matching: Unlocking Compositional Reasoning in Multimodal Models|测试时匹配：解锁多模态模型中的组合推理|Yinglun Zhu, Jiancheng Zhang, Fuzhi Tang|<http://arxiv.org/pdf/2510.07632v1>|提出了一种测试时匹配算法，显著提升了多模态模型在组合推理任务上的性能。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|To Sink or Not to Sink: Visual Information Pathways in Large Vision-Language Models|“沉与否：大型视觉语言模型中的视觉信息路径”|Jiayun Luo, Wan-Cyuan Fan, Lyuyang Wang, Xiangteng He, Tanzila Rahman, Purang Abolmaesumi, Leonid Sigal|<http://arxiv.org/pdf/2510.08510v1>|发现了ViT中的高语义视觉注意力 sink，提出方法提升LVLM视觉推理能力。|
|📝 更新|PainFormer: a Vision Foundation Model for Automatic Pain Assessment|疼痛识别基础模型：用于自动疼痛评估的视觉基础模型|Stefanos Gkikas, Raul Fernandez Rojas, Manolis Tsiknakis|<http://arxiv.org/pdf/2505.01571v6>|[代码](https://github.com/GkikasStefanos/PainFormer.); 提出 PainFormer，一种基于多任务学习的视觉基础模型，有效提取多模态数据特征以实现自动疼痛评...|
|📝 更新|TransMamba: Fast Universal Architecture Adaption from Transformers to Mamba|“TransMamba：从Transformer到Mamba的快速通用架构适配”|Xiuwei Chen, Wentao Hu, Xiao Dong, Sihao Lin, Zisheng Chen, Meng Cao, Yina Zhuang, Jianhua Han .etc.|<http://arxiv.org/pdf/2502.15130v2>|提出了一种跨架构知识迁移方法TransMamba，利用Transformer预训练模型加速Mamba...|
|🆕 发布|Automatic Text Box Placement for Supporting Typographic Design|自动文本框放置以支持排版设计|Jun Muraoka, Daichi Haraguchi, Naoto Inoue, Wataru Shimoda, Kota Yamaguchi, Seiichi Uchida|<http://arxiv.org/pdf/2510.07665v1>|研究了自动化文本框布局方法，发现特定任务架构优于传统模型，尤其在高视觉信息场景下。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Rethinking Decoders for Transformer-based Semantic Segmentation: A Compression Perspective|Comprehensive Survey on Deep Learning for Image Classification: From Traditional Methods to Next-Generation Architectures  重新思考基于变换器的语义分割解码器：压缩视角|Qishuai Wen, Chun-Guang Li|<http://arxiv.org/pdf/2411.03033v4>|从压缩视角重新设计Transformer解码器，提出了一种新的图像分割方法DEPICT，实现了更好的...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SPICE: Simple and Practical Image Clarification and Enhancement|SPICE：简单实用的图像清晰化和增强|Alexander Belyaev, Pierre-Alain Fayolle, Michael Cohen|<http://arxiv.org/pdf/2510.08358v1>|提出了一种简单高效的方法，有效增强并清晰化低光和雾霾等恶劣条件下的图像。|
|📝 更新|Maintaining Performance with Less Data|用更少的数据保持性能|Dominic Sanderson, Tatiana Kalgonova|<http://arxiv.org/pdf/2208.02007v2>|提出动态减少输入数据的新方法，减少神经网络训练成本同时保持准确率。|
|🆕 发布|The impact of abstract and object tags on image privacy classification|《抽象标签与物体标签对图像隐私分类的影响》|Darya Baranouskaya, Andrea Cavallaro|<http://arxiv.org/pdf/2510.07976v1>|探究了抽象标签和对象标签在图像隐私分类中的作用，发现抽象标签在标签数量有限时更有效。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LTCA: Long-range Temporal Context Attention for Referring Video Object Segmentation|LTCA：用于视频目标分割的长时序上下文注意力机制|Cilin Yan, Jingyun Wang, Guoliang Kang|<http://arxiv.org/pdf/2510.08305v1>|提出了一种长程时间上下文注意力机制，有效平衡了局部与全局信息，提升了视频对象分割的准确性。|
|📝 更新|Ultra-Efficient On-Device Object Detection on AI-Integrated Smart Glasses with TinyissimoYOLO|《在集成AI的智能眼镜上实现超高效设备端物体检测：基于TinyissimoYOLO》|Julian Moosmann, Pietro Bonazzi, Yawei Li, Sizhen Bian, Philipp Mayer, Luca Benini, Michele Magno|<http://arxiv.org/pdf/2311.01057v3>|[代码](https://github.com/ETH-PBL/TinyissimoYOLO); 提出了一种面向智能眼镜的超高效实时物体检测方案，通过定制处理器和轻量级网络实现了低功耗与高性能的平衡...|
|📝 更新|Towards Methane Detection Onboard Satellites|面向卫星甲烷检测的研究|Maggie Chen, Hala Lambdouar, Luca Marini, Laura Martínez-Ferrer, Chris Bridges, Giacomo Acciarini|<http://arxiv.org/pdf/2509.00626v3>|[代码](https://github.com/spaceml-org/plume-hunter.); 提出了一种利用机器学习直接处理未经几何校正的卫星数据的方法，实现了与常规预处理方法相当的性能。|
|🆕 发布|A Large-scale Dataset for Robust Complex Anime Scene Text Detection|大规模数据集用于稳健的复杂动漫场景文本检测|Ziyi Dong, Yurui Zhang, Changmao Li, Naomi Rue Golding, Qing Long|<http://arxiv.org/pdf/2510.07951v1>|提出了AnimeText大规模数据集，针对动漫场景中的文本检测问题，提升了模型在复杂场景下的检测性能...|
|📝 更新|ManipGPT: Is Affordance Segmentation by Large Vision Models Enough for Articulated Object Manipulation?|ManipGPT：大型视觉模型进行功效分割是否足以实现关节对象的操作？|Taewhan Kim, Hojin Bae, Zeming Li, Xiaoqi Li, Iaroslav Ponomarenko, Ruihai Wu, Hao Dong|<http://arxiv.org/pdf/2412.10050v3>|利用大型预训练视觉模型预测最优交互区域，显著提升关节对象操作的适应性和效率。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GraphEnet: Event-driven Human Pose Estimation with a Graph Neural Network|图神经网络驱动的实时人体姿态估计：GraphEnet|Gaurvi Goyal, Pham Cong Thuong, Arren Glover, Masayoshi Mizuno, Chiara Bartolozzi|<http://arxiv.org/pdf/2510.07990v1>|[代码](https://github.com/event-driven-robotics/GraphEnet-NeVi-ICCV2025.); 首次应用图神经网络于事件相机数据，实现高频单人物2D姿态估计。|
|🆕 发布|Hybrid CNN-BYOL Approach for Fault Detection in Induction Motors Using Thermal Images|基于混合卷积神经网络与BYOL方法的感应电机热图像故障检测方法|Tangin Amir Smrity, MD Zahin Muntaqim Hasan Muhammad Kafi, Abu Saleh Musa Miah, Najmul Hassan, Yuichi Okuyama, Nobuyoshi Asai, Taro Suzuki, Jungpil Shin|<http://arxiv.org/pdf/2510.07692v1>|提出了一种结合CNN和BYOL的混合方法，用于通过热图像检测电机故障，实现了高准确率和快速推断。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|NovaFlow: Zero-Shot Manipulation via Actionable Flow from Generated Videos|诺瓦流：通过生成视频中的可操作流实现零样本操作|Hongyu Li, Lingfeng Sun, Yafei Hu, Duy Ta, Jennifer Barry, George Konidaris, Jiahui Fu|<http://arxiv.org/pdf/2510.08568v1>|提出NovaFlow框架，通过生成视频和3D对象流实现无需示范的零样本机器人操作任务。|
|📝 更新|IMAGHarmony: Controllable Image Editing with Consistent Object Quantity and Layout|《IMAGHarmony：具有一致物体数量和布局的可控图像编辑》|Fei Shen, Yutong Gao, Jian Yu, Xiaoyu Du, Jinhui Tang|<http://arxiv.org/pdf/2506.01949v2>|[代码](https://github.com/muzishen/IMAGHarmony.); 提出了一种图像编辑框架IMAGHarmony，通过控制对象数量和布局实现多对象场景的一致性编辑。|
|🆕 发布|R2RGEN: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation|R2RGEN：用于空间泛化操作的真实到真实三维数据生成|Xiuwei Xu, Angyuan Ma, Hankun Li, Bingyao Yu, Zheng Zhu, Jie Zhou, Jiwen Lu|<http://arxiv.org/pdf/2510.08547v1>|提出了一种无需模拟器和渲染的真实到真实三维数据生成框架R2RGen，有效弥补了数据不足并提高了机器人...|
|🆕 发布|VideoCanvas: Unified Video Completion from Arbitrary Spatiotemporal Patches via In-Context Conditioning|视频画布：通过上下文条件从任意时空补丁进行统一视频补全|Minghong Cai, Qiulin Wang, Zongli Ye, Wenze Liu, Quande Liu, Weicai Ye, Xintao Wang, Pengfei Wan .etc.|<http://arxiv.org/pdf/2510.08555v1>|提出了VideoCanvas框架，通过零参数的In-Context Conditioning和Tem...|
|🆕 发布|Kontinuous Kontext: Continuous Strength Control for Instruction-based Image Editing|“连续上下文：基于指令的图像编辑的连续强度控制”|Rishubh Parihar, Or Patashnik, Daniil Ostashev, R. Venkatesh Babu, Daniel Cohen-Or, Kuan-Chieh Wang|<http://arxiv.org/pdf/2510.08532v1>|引入了Kontinuous Kontext模型，通过连续调整编辑强度实现基于指令的图像编辑的精细控制...|
|🆕 发布|FlexTraj: Image-to-Video Generation with Flexible Point Trajectory Control|FlexTraj：具有灵活点轨迹控制的图像到视频生成|Zhiyuan Zhang, Can Wang, Dongdong Chen, Jing Liao|<http://arxiv.org/pdf/2510.08527v1>|FlexTraj通过统一的点轨迹控制，实现了灵活的图像到视频生成，提高了控制效率和生成质量。|
|📝 更新|Paper2Video: Automatic Video Generation from Scientific Papers|论文到视频：从科学论文自动生成视频|Zeyu Zhu, Kevin Qinghong Lin, Mike Zheng Shou|<http://arxiv.org/pdf/2510.05096v2>|[代码](https://github.com/showlab/Paper2Video.); 提出了 Paper2Video，一种自动从学术论文生成视频的多代理框架，提高了学术视频制作的效率和准...|
|🆕 发布|VideoVerse: How Far is Your T2V Generator from a World Model?|《VideoVerse：您的T2V生成器距离世界模型还有多远？》|Zeqing Wang, Xinyu Wei, Bairui Li, Zhen Guo, Jinrui Zhang, Hongyang Wei, Keze Wang, Lei Zhang|<http://arxiv.org/pdf/2510.08398v1>|提出了VideoVerse基准，全面评估T2V模型对复杂时间因果性和世界知识的理解能力。|
|🆕 发布|Biology-driven assessment of deep learning super-resolution imaging of the porosity network in dentin|基于生物学的深度学习超分辨率成像在牙本质孔隙网络评估中的应用|Lauren Anderson, Lucas Chatelain, Nicolas Tremblay, Kathryn Grandfield, David Rousseau, Aurélien Gourrier|<http://arxiv.org/pdf/2510.08407v1>|利用深度学习超分辨率技术提高牙本质孔隙网络成像分辨率，通过生物学驱动的评估方法揭示了模型性能差异。|
|🆕 发布|UniVideo: Unified Understanding, Generation, and Editing for Videos|统一视频理解、生成与编辑方法：UniVideo|Cong Wei, Quande Liu, Zixuan Ye, Qiulin Wang, Xintao Wang, Pengfei Wan, Kun Gai, Wenhu Chen|<http://arxiv.org/pdf/2510.08377v1>|UniVideo通过融合多模态语言模型和生成模型，实现了视频理解、生成和编辑的统一框架，提升了任务灵...|
|🆕 发布|LinVideo: A Post-Training Framework towards O(n) Attention in Efficient Video Generation|LinVideo：面向高效视频生成的O(n)注意力后训练框架|Yushi Huang, Xingtong Ge, Ruihao Gong, Chengtao Lv, Jun Zhang|<http://arxiv.org/pdf/2510.08318v1>|提出了一种高效的后训练框架LinVideo，通过选择性转换注意力机制，实现了视频生成中计算成本的显著...|
|📝 更新|Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models|平衡匹配：隐式能量基模型的生成建模|Runqian Wang, Yilun Du|<http://arxiv.org/pdf/2510.02300v2>|引入平衡匹配（EqM）生成模型框架，通过学习隐性能量景观的平衡梯度，优化了采样过程并提升了生成性能。|
|🆕 发布|Fine-grained text-driven dual-human motion generation via dynamic hierarchical interaction|通过动态层次交互的精细粒度文本驱动双人类运动生成|Mu Li, Yin Wang, Zhiying Leng, Jiapeng Liu, Frederick W. B. Li, Xiaohui Liang|<http://arxiv.org/pdf/2510.08260v1>|提出了一种细粒度文本驱动的双人物动态生成方法FineDual，通过分阶段建模个体到整体间的动态层次交...|
|🆕 发布|SViM3D: Stable Video Material Diffusion for Single Image 3D Generation|SViM3D：单张图像三维生成中的稳定视频材质扩散|Andreas Engelhardt, Mark Boss, Vikram Voletti, Chun-Han Yao, Hendrik P. A. Lensch, Varun Jampani|<http://arxiv.org/pdf/2510.08271v1>|提出SViM3D框架，通过单张图像生成具有物理渲染效果的3D模型，实现高质量的多视角一致性和可控重照...|
|📝 更新|DiffEye: Diffusion-Based Continuous Eye-Tracking Data Generation Conditioned on Natural Images|DiffEye：基于扩散的自然图像条件下连续眼动数据生成|Ozgur Kara, Harris Nisar, James M. Rehg|<http://arxiv.org/pdf/2509.16767v2>|提出DiffEye模型，利用扩散模型捕捉并生成自然图像观看中的连续多样化眼动轨迹。|
|🆕 发布|Beyond Textual CoT: Interleaved Text-Image Chains with Deep Confidence Reasoning for Image Editing|超越文本性协同推理：深度置信推理的交错文本-图像链用于图像编辑|Zhentao Zou, Zhengrong Yue, Kunpeng Du, Binlei Bao, Hanting Li, Haizhen Xie, Guozheng Xu, Yue Zhou .etc.|<http://arxiv.org/pdf/2510.08157v1>|提出了一种结合文本和视觉线索的多模态编辑框架，有效处理复杂图像编辑任务并提高编辑精度。|
|🆕 发布|UniMMVSR: A Unified Multi-Modal Framework for Cascaded Video Super-Resolution|统一多模态框架用于级联视频超分辨率|Shian Du, Menghan Xia, Chang Liu, Quande Liu, Xintao Wang, Pengfei Wan, Xiangyang Ji|<http://arxiv.org/pdf/2510.08143v1>|提出了UniMMVSR框架，首次结合文本、图像和视频多种模态条件，实现了高效的视频超分辨率生成。|
|📝 更新|RAGDiffusion: Faithful Cloth Generation via External Knowledge Assimilation|RAGDiffusion：通过外部知识同化实现真实布料生成的算法|Yuhan Li, Xianfeng Tan, Wenxiang Shang, Yubo Wu, Jian Wang, Xuanhong Chen, Yi Zhang, Ran Lin .etc.|<http://arxiv.org/pdf/2411.19528v2>|提出 Retrieval-Augmented Generation 框架 RAGDiffusion，...|
|📝 更新|Coefficients-Preserving Sampling for Reinforcement Learning with Flow Matching|保持系数的流匹配强化学习采样方法|Feng Wang, Zihao Yu|<http://arxiv.org/pdf/2509.05952v3>|[代码](https://github.com/IamCreateAI/FlowCPS); 提出了一种消除噪声 artifact 的 Coefficients-Preserving Sampl...|
|📝 更新|Condition Weaving Meets Expert Modulation: Towards Universal and Controllable Image Generation|条件编织遇见专家调制：迈向通用与可控的图像生成|Guoqing Zhang, Xingtong Ge, Lu Shi, Xin Zhang, Muqing Xue, Wanru Xu, Yigang Cen, Jian Zhang|<http://arxiv.org/pdf/2508.17364v2>|[代码](https://github.com/gavin-gqzhang/UniGen.); 提出统一图像生成框架UniGen及CoMoE模块，有效整合条件输入，提升生成效率和表现力。|
|🆕 发布|TTOM: Test-Time Optimization and Memorization for Compositional Video Generation|TTOM：测试时优化与记忆增强的组合视频生成方法|Leigang Qu, Ziyang Wang, Na Zheng, Wenjie Wang, Liqiang Nie, Tat-Seng Chua|<http://arxiv.org/pdf/2510.07940v1>|提出TTOM框架，通过测试时优化和记忆机制提升视频生成中元素布局的准确性。|
|🆕 发布|SatFusion: A Unified Framework for Enhancing Satellite IoT Images via Multi-Temporal and Multi-Source Data Fusion|SatFusion：一种通过多时相和多源数据融合提升卫星物联网图像的统一框架|Yufei Tong, Guanjie Cheng, Peihan Wu, Yicheng Zhu, Kexu Lu, Feiyi Chen, Meng Xi, Junqin Huang .etc.|<http://arxiv.org/pdf/2510.07905v1>|[代码](https://github.com/dllgyufei/SatFusion.git.); 提出了一种统一框架SatFusion，通过多时序和多源数据融合显著提升卫星物联网图像质量和鲁棒性。|
|📝 更新|MAGREF: Masked Guidance for Any-Reference Video Generation with Subject Disentanglement|"MAGREF：基于遮蔽引导的任意参考视频生成与主体解耦"|Yufan Deng, Yuanyang Yin, Xun Guo, Yizhi Wang, Jacob Zhiyuan Fang, Shenghai Yuan, Yiding Yang, Angtian Wang .etc.|<http://arxiv.org/pdf/2505.23742v2>|[代码](https://github.com/MAGREF-Video/MAGREF); 提出MAGREF框架，通过掩码引导和主体解耦机制，实现任意参考视频生成，解决了身份不一致、主体混淆和...|
|📝 更新|MAMBO: High-Resolution Generative Approach for Mammography Images|MAMBO：用于乳腺X线照片图像的高分辨率生成方法|Milica Škipina, Nikola Jovišić, Nicola Dall'Asen, Vanja Švenda, Anil Osman Tur, Slobodan Ilić, Elisa Ricci, Dubravko Ćulibrk|<http://arxiv.org/pdf/2506.08677v3>|[代码](https://github.com/iai-rs/mambo.); 提出了一种生成高清哺乳图像的MAMBO模型，通过组合局部和全局信息，解决了隐私限制下的数据不足问题。|
|🆕 发布|IsoSignVid2Aud: Sign Language Video to Audio Conversion without Text Intermediaries|《IsoSignVid2Aud：不通过文本中介的直接手语视频转音频》|Harsh Kavediya, Vighnesh Nayak, Bheeshm Sharma, Balamurugan Palaniappan|<http://arxiv.org/pdf/2510.07837v1>|[代码](https://github.com/BheeshmSharma/IsoSignVid2Aud_AIMLsystems-2025.); 提出了一种端到端框架，直接将孤立手势视频转化为语音，无需文本中介，提高了交流效率和语音质量。|
|📝 更新|GL-PGENet: A Parameterized Generation Framework for Robust Document Image Enhancement|GL-PGENet：一种用于鲁棒文档图像增强的参数化生成框架|Zhihong Tang|<http://arxiv.org/pdf/2505.22021v2>|提出了一种针对多退化彩色文档图像的增强框架，通过全局与局部参数化生成机制实现高效稳健的图像质量提升。|
|📝 更新|UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG|统一文档中心多模态关系图基准：UNIDOC-BENCH|Xiangyu Peng, Can Qin, Zeyuan Chen, Ran Xu, Caiming Xiong, Chien-Sheng Wu|<http://arxiv.org/pdf/2510.03663v2>|提出了UniDoc-Bench，首个面向文档中心多模态检索增强生成的大规模现实基准，证明了融合文本和...|
|📝 更新|MAViS: A Multi-Agent Framework for Long-Sequence Video Storytelling|多智能体框架：用于长序列视频故事讲述的MAViS|Qian Wang, Ziqi Huang, Ruoxi Jia, Paul Debevec, Ning Yu|<http://arxiv.org/pdf/2508.08487v4>|提出MAViS多代理协作框架，提升长序列视频故事讲述的辅助能力、视觉质量和表现力。|
|🆕 发布|SyncHuman: Synchronizing 2D and 3D Generative Models for Single-view Human Reconstruction|SyncHuman：同步2D和3D生成模型以实现单视角人体重建|Wenyue Chen, Peng Li, Wangguandong Zheng, Chengfeng Zhao, Mengfei Li, Yaolong Zhu, Zhiyang Dou, Ronggang Wang .etc.|<http://arxiv.org/pdf/2510.07723v1>|提出了一种结合2D多视角生成模型和3D原生生成模型的SyncHuman框架，实现了单视角下高质量着装...|
|📝 更新|HIVTP: A Training-Free Method to Improve VLMs Efficiency via Hierarchical Visual Token Pruning Using Middle-Layer-Based Importance Score|HIVTP：一种基于中层重要性评分的层次视觉标记剪枝来提高大型视觉语言模型效率的无训练方法|Jingqi Xu, Jingxi Lu, Chenghao Li, Sreetama Sarkar, Peter A. Beerel|<http://arxiv.org/pdf/2509.23663v2>|提出了一种无需训练的视觉标记剪枝方法HIVTP，通过中层注意力图评估重要性，有效提升了视觉语言模型的...|
|📝 更新|Product of Experts for Visual Generation|专家乘积模型在视觉生成中的应用|Yunzhi Zhang, Carson Murtuza-Lanier, Zizhang Li, Yilun Du, Jiajun Wu|<http://arxiv.org/pdf/2506.08894v2>|提出了一种无需训练的异质模型知识融合框架Product of Experts，通过样本合成提升了图像...|
|🆕 发布|Controllable Video Synthesis via Variational Inference|通过变分推理实现可控视频合成|Haoyi Duan, Yunzhi Zhang, Yilun Du, Jiajun Wu|<http://arxiv.org/pdf/2510.07670v1>|提出了一种可控视频合成方法，通过变分推理实现元素指定控制与多样性的平衡。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MultiCOIN: Multi-Modal COntrollable Video INbetweening|多模态可控视频插值：MultiCOIN|Maham Tanveer, Yang Zhou, Simon Niklaus, Ali Mahdavi Amiri, Hao Zhang, Krishna Kumar Singh, Nanxuan Zhao|<http://arxiv.org/pdf/2510.08561v1>|提出了一种多模态可控视频插值框架，通过深度转换、分层、运动轨迹和文本提示实现了精细的视频帧生成控制。|
|🆕 发布|InstructUDrag: Joint Text Instructions and Object Dragging for Interactive Image Editing|指令拖拽：结合文本指令与对象拖拽的交互式图像编辑方法|Haoran Yu, Yi Shi|<http://arxiv.org/pdf/2510.08181v1>|InstructUDrag结合文本指令与对象拖拽，实现了高保真且精确的图像编辑。|
|📝 更新|EFSA: Episodic Few-Shot Adaptation for Text-to-Image Retrieval|EFSA：用于文本到图像检索的偶发少量样本适应|Muhammad Huzaifa, Yova Kementchedjhieva|<http://arxiv.org/pdf/2412.00139v3>|提出EFSA方法，通过动态适应查询领域，提升开放域文本到图像检索的鲁棒性。|
|🆕 发布|Towards Real-World Deepfake Detection: A Diverse In-the-wild Dataset of Forgery Faces|面向现实世界的深度伪造检测：一个多样化的野外伪造人脸数据集|Junyu Shi, Minghui Li, Junguo Zuo, Zhifei Yu, Yipeng Lin, Shengshan Hu, Ziqi Zhou, Yechao Zhang .etc.|<http://arxiv.org/pdf/2510.08067v1>|[代码](https://github.com/kikyou-220/RedFace.); 构建了一个包含60,000伪造图像和1,000视频的RedFace数据集，利用9个商业平台技术模拟真...|
|📝 更新|Safe-Control: A Safety Patch for Mitigating Unsafe Content in Text-to-Image Generation Models|《Safe-Control：一种用于减轻文本到图像生成模型中不安全内容的安全补丁》|Xiangtao Meng, Yingkai Dong, Ning Yu, Li Wang, Zheng Li, Shanqing Guo|<http://arxiv.org/pdf/2508.21099v2>|提出了一种创新的Safe-Control安全补丁，有效减少文本到图像生成模型中的不安全内容生成。|
|🆕 发布|Once Is Enough: Lightweight DiT-Based Video Virtual Try-On via One-Time Garment Appearance Injection|单次就足够：基于轻量级DiT的一次性服装外观注入视频虚拟试穿|Yanjie Pan, Qingdong He, Lidong Wang, Bo Peng, Mingmin Chi|<http://arxiv.org/pdf/2510.07654v1>|提出了一种基于单帧服装替换的轻量级视频虚拟试穿方法，实现了参数和计算效率的显著提升。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SpatialLadder: Progressive Training for Spatial Reasoning in Vision-Language Models|空间梯级：视觉语言模型中空间推理的渐进训练|Hongxing Li, Dingming Li, Zixuan Wang, Yuchen Yan, Hang Wu, Wenqi Zhang, Yongliang Shen, Weiming Lu .etc.|<http://arxiv.org/pdf/2510.08531v1>|提出分阶段训练方法SpatialLadder，通过感知到推理的逐步提升，显著增强视觉语言模型的空间推...|
|🆕 发布|InstructX: Towards Unified Visual Editing with MLLM Guidance|指令X：面向MLLM指导下的统一视觉编辑|Chong Mou, Qichao Sun, Yanze Wu, Pengze Zhang, Xinghui Li, Fulong Ye, Songtao Zhao, Qian He|<http://arxiv.org/pdf/2510.08485v1>|提出InstructX框架，利用多模态大语言模型指导扩散模型进行图像和视频编辑，实现无需显式视频数据...|
|📝 更新|Deblurring in the Wild: A Real-World Image Deblurring Dataset from Smartphone High-Speed Videos|《野外去模糊：来自智能手机高速视频的实际图像去模糊数据集》|Syed Mumtahin Mahmud, Mahdi Mohd Hossain Noki, Prothito Shovon Majumder, Abdul Mohaimen Al Radi, Sudipto Das Sukanto, Afia Lubaina, Md. Mosaddek Khan|<http://arxiv.org/pdf/2506.19445v4>|构建了首个大规模真实世界图像去模糊数据集，显著提升了去模糊模型的性能和泛化能力。|
|🆕 发布|Large Scale Diffusion Distillation via Score-Regularized Continuous-Time Consistency|通过得分正则化的连续时间一致性进行大规模扩散蒸馏|Kaiwen Zheng, Yuji Wang, Qianli Ma, Huayu Chen, Jintao Zhang, Yogesh Balaji, Jianfei Chen, Ming-Yu Liu .etc.|<http://arxiv.org/pdf/2510.08431v1>|首次将连续时间一致性蒸馏扩展到大规模图像和视频扩散模型，提出了一种改进的得分正则化连续时间一致性模型...|
|🆕 发布|Reinforcing Diffusion Models by Direct Group Preference Optimization|通过直接群体偏好优化强化扩散模型|Yihong Luo, Tianyang Hu, Jing Tang|<http://arxiv.org/pdf/2510.08425v1>|[代码](https://github.com/Luo-Yihong/DGPO.); 提出DGPO算法，直接优化样本组偏好，摒弃了传统策略梯度框架，实现高效训练并提升性能。|
|🆕 发布|Hyperspectral data augmentation with transformer-based diffusion models|基于变压器的扩散模型对高光谱数据进行增强|Mattia Ferrari, Lorenzo Bruzzone|<http://arxiv.org/pdf/2510.08363v1>|提出了一种基于变换器网络的扩散模型数据增强技术，有效缓解了小样本数据集训练中的过拟合问题。|
|🆕 发布|One Stone with Two Birds: A Null-Text-Null Frequency-Aware Diffusion Models for Text-Guided Image Inpainting|一石二鸟：面向文本引导图像修复的零文本零频率感知扩散模型|Haipeng Liu, Yang Wang, Meng Wang|<http://arxiv.org/pdf/2510.08273v1>|[代码](https://github.com/htyjers/NTN-Diff.); 提出了一种频率感知的扩散模型NTN-Diff，通过分频段处理实现文本引导的图像修复，同时保持未遮挡区...|
|📝 更新|Feedback Guidance of Diffusion Models|扩散模型的反馈引导|Felix Koulischer, Florian Handke, Johannes Deleu, Thomas Demeester, Luca Ambrogioni|<http://arxiv.org/pdf/2506.06085v2>|提出反馈引导方法，动态调整扩散模型中的指导力度，提升样本多样性和减少记忆效应。|
|🆕 发布|Real-Time Motion-Controllable Autoregressive Video Diffusion|实时运动控制自回归视频扩散|Kesen Zhao, Jiaxin Shi, Beier Zhu, Junbao Zhou, Xiaolong Shen, Yuan Zhou, Qianru Sun, Hanwang Zhang|<http://arxiv.org/pdf/2510.08131v1>|[代码](https://kesenzhao.github.io/AR-Drag.github.io); 提出了一种实时可控运动的视频生成方法 AR-Drag，通过强化学习优化，大幅降低了生成延迟并提高了视...|
|📝 更新|DICEPTION: A Generalist Diffusion Model for Visual Perceptual Tasks|DICEPTION：一种用于视觉感知任务的通用扩散模型|Canyu Zhao, Yanlong Sun, Mingyu Liu, Huanyi Zheng, Muzhi Zhu, Zhiyue Zhao, Hao Chen, Tong He .etc.|<http://arxiv.org/pdf/2502.17157v3>|[代码](https://github.com/aim-uofa/Diception); 提出了一种高效的视觉通用模型DICEPTION，利用预训练的扩散模型处理多种视觉任务，仅需少量数据和...|
|🆕 发布|CIR-CoT: Towards Interpretable Composed Image Retrieval via End-to-End Chain-of-Thought Reasoning|CIR-CoT: 面向端到端链式思维推理的可解释组合图像检索|Weihuang Lin, Yiwei Ma, Jiayi Ji, Xiaoshuai Sun, Rongrong Ji|<http://arxiv.org/pdf/2510.08003v1>|提出首个集成显式链式推理的端到端多模态模型，提升图像检索准确性和解释性。|
|🆕 发布|Latent Harmony: Synergistic Unified UHD Image Restoration via Latent Space Regularization and Controllable Refinement|潜在和谐：通过潜在空间正则化和可控细化实现超高清图像恢复的协同统一|Yidi Liu, Xueyang Fu, Jie Huang, Jie Xiao, Dong Li, Wenlong Zhang, Lei Bai, Zheng-Jun Zha|<http://arxiv.org/pdf/2510.07961v1>|提出了一种两阶段框架Latent Harmony，通过潜空间正则化和可控细化，有效平衡了超高清图像恢...|
|🆕 发布|XYZCylinder: Feedforward Reconstruction for Driving Scenes Based on A Unified Cylinder Lifting Method|XYZ圆柱体：基于统一圆柱体提升方法的驾驶场景前馈重建|Haochen Yu, Qiankun Liu, Hongyuan Liu, Jianfei Jiang, Juntao Lyu, Jiansheng Chen, Huimin Ma|<http://arxiv.org/pdf/2510.07856v1>|[代码](https://yuyuyu223.github.io/XYZCYlinder-projectpage); 提出了一种统一圆柱提升方法的XYZCylinder模型，通过调整参数统一不同相机配置并提高驾驶场景重...|
|📝 更新|Self-Training with Dynamic Weighting for Robust Gradual Domain Adaptation|自训练与动态权重分配用于稳健的渐变域自适应|Zixi Wang, Yushe Cao, Yubo Huang, Jinzhu Wei, Jingzehua Xu, Shuai Zhang, Xin Lai|<http://arxiv.org/pdf/2501.19159v2>|[代码](https://github.com/Dramwig/STDW.); 提出了一种自适应动态权重策略，通过平衡源域和目标域的损失贡献，增强了渐变域自适应的鲁棒性。|
|🆕 发布|Curriculum Learning with Synthetic Data for Enhanced Pulmonary Nodule Detection in Chest Radiographs|基于合成数据的课程学习以增强胸部X射线中肺结节检测|Pranav Sambhu, Om Guin, Madhav Sambhu, Jinho Cha|<http://arxiv.org/pdf/2510.07681v1>|利用合成数据和课程学习提高了胸部X光片中困难肺结节检测的准确性和鲁棒性。|
|🆕 发布|MONKEY: Masking ON KEY-Value Activation Adapter for Personalization|MONKEY：基于键值激活适配器的个性化掩码方法|James Baker|<http://arxiv.org/pdf/2510.07656v1>|提出了一种利用自动生成遮罩增强个性化图像生成的方法，有效结合主体与文本提示，提高图像与提示的匹配度。|
|🆕 发布|Rectified-CFG++ for Flow Based Models|基于流模型的Rectified-CFG++|Shreshth Saini, Shashank Gupta, Alan C. Bovik|<http://arxiv.org/pdf/2510.07631v1>|提出Rectified-CFG++方法，通过自适应预测-校正引导，有效解决传统CFG在流模型中的偏移...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AI-Driven Radiology Report Generation for Traumatic Brain Injuries|基于人工智能的创伤性脑损伤放射学报告生成|Riadh Bouslimi, Houda Trabelsi, Wahiba Ben Abdssalem Karaa, Hana Hedhli|<http://arxiv.org/pdf/2510.08498v1>|提出了一种结合特征提取与文本生成的AI方法，用于自动生成颅脑创伤的放射学报告，提高了诊断准确性和报告...|
|🆕 发布|DexMan: Learning Bimanual Dexterous Manipulation from Human and Generated Videos|DexMan：从人类和生成视频中学习双臂灵巧操作|Jhen Hsieh, Kuan-Hsun Tu, Kuo-Han Hung, Tsung-Wei Ke|<http://arxiv.org/pdf/2510.08475v1>|提出DexMan框架，将人类视觉示范转化为机器人双臂灵巧操作技能，无需复杂设备或标注，实现高效学习。|
|🆕 发布|Physics-Driven Spatiotemporal Modeling for AI-Generated Video Detection|基于物理驱动的时空建模用于AI生成视频检测|Shuhai Zhang, ZiHao Lian, Jiahao Yang, Daiyuan Li, Guoxuan Pang, Feng Liu, Bo Han, Shutao Li .etc.|<http://arxiv.org/pdf/2510.08073v1>|[代码](https://github.com/ZSHsh98/NSG-VD.); 提出了一种基于物理定律的概率流守恒原理的AI生成视频检测方法，通过量化时空梯度与密度变化比率来识别异...|
|🆕 发布|RetouchLLM: Training-free White-box Image Retouching|无需训练的白盒图像修饰：RetouchLLM|Moon Ye-Bin, Roy Miles, Tae-Hyun Oh, Ismail Elezi, Jiankang Deng|<http://arxiv.org/pdf/2510.08054v1>|提出了一种无需训练数据的白盒图像修图系统RetouchLLM，实现了可解释的代码化修图过程，适用于多...|
|🆕 发布|PrismGS: Physically-Grounded Anti-Aliasing for High-Fidelity Large-Scale 3D Gaussian Splatting|PrismGS：基于物理的抗锯齿算法用于高保真大规模三维高斯散点绘制|Houqiang Zhong, Zhenglong Wu, Sihua Fu, Zihan Zheng, Xin Jin, Xiaoyun Zhang, Li Song, Qiang Hu|<http://arxiv.org/pdf/2510.07830v1>|提出了PrismGS方法，通过物理基础的规则化框架减少了大规模3D场景渲染中的走样现象。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|D$^2$GS: Depth-and-Density Guided Gaussian Splatting for Stable and Accurate Sparse-View Reconstruction|深度与密度引导的高斯散点投射算法用于稳定且精确的稀疏视角重建|Meixi Song, Xin Lin, Dizhe Zhang, Haodong Li, Xiangtai Li, Bo Du, Lu Qi|<http://arxiv.org/pdf/2510.08566v1>|[代码](https://insta360-research-team.github.io/DDGS-website); 提出了一种深度和密度引导的高斯散射框架，有效解决了稀疏视角下的过拟合和欠拟合问题，显著提升了重建质量...|
|🆕 发布|Splat the Net: Radiance Fields with Splattable Neural Primitives|将网络散布开：具有可散布神经原语的辐射场|Xilong Zhou, Bao-Huy Nguyen, Loïc Magne, Vladislav Golyanik, Thomas Leimkühler, Christian Theobalt|<http://arxiv.org/pdf/2510.08491v1>|提出了一种结合神经模型表达性和基于原语体素化效率的新体积表示方法，实现了无需昂贵光线追踪的高效三维场...|
|🆕 发布|Learning Neural Exposure Fields for View Synthesis|学习神经曝光场以实现视图合成|Michael Niemeyer, Fabian Manhardt, Marie-Julie Rakotosaona, Michael Oechsle, Christina Tsalicoglou, Keisuke Tateno, Jonathan T. Barron, Federico Tombari|<http://arxiv.org/pdf/2510.08279v1>|提出了一种学习三维场景曝光场的神经场技术，实现了高动态范围场景的高质量三维重建和视图合成。|
|📝 更新|CurvNet: Latent Contour Representation and Iterative Data Engine for Curvature Angle Estimation|CurvNet：潜在轮廓表示与曲率角度估计的迭代数据引擎|Zhiwen Shao, Yichen Yuan, Lizhuang Ma, Xiaojia Zhu|<http://arxiv.org/pdf/2411.12604v2>|[代码](https://github.com/Ernestchenchen/CurvNet); 提出CurvNet框架，通过潜空间轮廓表示和数据引擎迭代生成，实现精确的脊柱曲率角测量。|
|📝 更新|Attention based End to end network for Offline Writer Identification on Word level data|基于注意力机制的开卷端到端网络在单词级别离线书写者识别上的应用|Vineet Kumar, Suresh Sundaram|<http://arxiv.org/pdf/2404.07602v2>|提出了一种基于注意力的卷积神经网络，通过金字塔策略处理单词图像片段，提升少量样本下的书写者识别准确度...|
|📝 更新|Targetless LiDAR-Camera Calibration with Neural Gaussian Splatting|无需目标的LiDAR-相机标定方法：基于神经高斯散点投射|Haebeom Jung, Namtae Kim, Jungwoo Kim, Jaesik Park|<http://arxiv.org/pdf/2504.04597v2>|提出了一种无需物理标定的LiDAR-Camera联合校准方法，通过神经高斯散点技术实现稳定准确的传感...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MonoGSDF: Exploring Monocular Geometric Cues for Gaussian Splatting-Guided Implicit Surface Reconstruction|单目几何线索探索：基于高斯散点绘制引导的隐式表面重建|Kunyi Li, Michael Niemeyer, Zeyu Chen, Nassir Navab, Federico Tombari|<http://arxiv.org/pdf/2411.16898v3>|MonoGSDF通过结合高斯基元和神经符号距离场，实现了从单目图像到高质量三维表面重建的突破。|
|🆕 发布|AlignGS: Aligning Geometry and Semantics for Robust Indoor Reconstruction from Sparse Views|《AlignGS：对齐几何与语义以实现稀疏视角下鲁棒的室内重建》|Yijie Gao, Houqiang Zhong, Tianchi Zhu, Zhengxue Cheng, Qiang Hu, Li Song|<http://arxiv.org/pdf/2510.07839v1>|[代码](https://github.com/MediaX-SJTU/AlignGS); 引入AlignGS框架，通过语义指导几何优化，从稀疏视角重建室内场景，实现几何精度和视觉效果的双重提...|
|🆕 发布|An End-to-End Room Geometry Constrained Depth Estimation Framework for Indoor Panorama Images|室内全景图像的端到端房间几何约束深度估计框架|Kanglin Ning, Ruzhao Chen, Penghong Wang, Xingtao Wang, Ruiqin Xiong, Xiaopeng Fan|<http://arxiv.org/pdf/2510.07817v1>|[代码](https://github.com/emiyaning/RGCNet.); 提出了一种基于房间几何约束的深度估计框架，通过布局预测和背景分割机制提高了室内全景图像的深度估计准确...|
|📝 更新|Surfel-based Gaussian Inverse Rendering for Fast and Relightable Dynamic Human Reconstruction from Monocular Video|基于Surfel的高斯逆渲染：从单目视频中实现快速且可重光照的动态人体重建|Yiqun Zhao, Chenming Wu, Binbin Huang, Yihao Zhi, Chen Zhao, Jingdong Wang, Shenghua Gao|<http://arxiv.org/pdf/2407.15212v3>|提出SGIA方法，通过高效训练和渲染实现单目视频中的动态着装人类角色的快速重建和重光照。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Language learning shapes visual category-selectivity in deep neural networks|深度神经网络中语言学习塑造视觉分类选择性|Zitong Lu, Yuxin Wang|<http://arxiv.org/pdf/2502.16456v2>|发现语言经验能系统性重塑深度神经网络中的视觉类别表示，导致更分布式、语义对齐的编码。|
|📝 更新|Human Action Recognition from Point Clouds over Time|基于时间点云的人体动作识别|James Dickens|<http://arxiv.org/pdf/2510.05506v3>|提出了一种结合点云技术和稀疏卷积网络的人类动作识别方法，提升了识别准确度。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VideoNorms: Benchmarking Cultural Awareness of Video Language Models|视频规范：评估视频语言模型的文化意识基准|Nikhil Reddy Varimalla, Yunfei Xu, Arkadiy Saakyan, Meng Fan Wang, Smaranda Muresan|<http://arxiv.org/pdf/2510.08543v1>|提出了VideoNorms基准，通过人机协作标注文化规范，揭示了视频语言模型在文化理解上的不足。|
|🆕 发布|Improving Temporal Understanding Logic Consistency in Video-Language Models via Attention Enhancement|通过增强注意力机制提升视频-语言模型中的时间理解逻辑一致性|Chengzhi Li, Heyan Huang, Ping Jian, Zhen Yang, Yaning Tian|<http://arxiv.org/pdf/2510.08138v1>|提出了一种增强型注意力方法TCAS，有效提升了视频语言模型在时间逻辑一致性方面的表现。|
|📝 更新|Think With Videos For Agentic Long-Video Understanding|为代理型长视频理解思考的视频处理方法|Huaying Yuan, Zheng Liu, Junjie Zhou, Hongjin Qian, Yan Shu, Nicu Sebe, Ji-Rong Wen, Zhicheng Dou|<http://arxiv.org/pdf/2506.10821v4>|[代码](https://github.com/yhy-2000/VideoDeepResearch); 提出了一种视频探索框架VideoExplorer，通过迭代提问和定位相关时刻，实现了高效、可解释的长...|
|🆕 发布|MARC: Memory-Augmented RL Token Compression for Efficient Video Understanding|记忆增强的RL标记压缩用于高效视频理解|Peiran Wu, Zhuorui Yu, Yunze Liu, Chi-Hao Wu, Enmin Zhou, Junxiao Shen|<http://arxiv.org/pdf/2510.07915v1>|提出了一种基于记忆增强的强化学习视频理解token压缩方法，大幅减少了计算资源需求同时保持近基线准确...|
|📝 更新|PRVR: Partially Relevant Video Retrieval|部分相关视频检索|Xianke Chen, Daizong Liu, Xun Yang, Xirong Li, Jianfeng Dong, Meng Wang, Xun Wang|<http://arxiv.org/pdf/2208.12510v2>|提出了一种针对部分相关视频检索问题的新型学习方法，通过多尺度相似性学习网络有效识别视频中的相关片段。|
|📝 更新|Controllable Hybrid Captioner for Improved Long-form Video Understanding|可控混合字幕生成器：用于提升长格式视频理解的算法研究|Kuleen Sasse, Efsun Sarioglu Kayi, Arun Reddy|<http://arxiv.org/pdf/2507.17047v3>|提出了一种可控混合字幕生成方法，通过结合视频动作和场景描述，提高了长视频内容理解和问题回答能力。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MoA-VR: A Mixture-of-Agents System Towards All-in-One Video Restoration|MoA-VR：面向一站式视频修复的混合智能体系统|Lu Liu, Chunlei Cai, Shaocheng Shen, Jianfeng Liang, Weimin Ouyang, Tianxiao Ye, Jian Mao, Huiyu Duan .etc.|<http://arxiv.org/pdf/2510.08508v1>|提出了一种混合代理系统MoA-VR，通过模拟人类专家的推理和处理流程，有效应对视频的多种复杂退化问题...|
|📝 更新|BEVTrack: A Simple and Strong Baseline for 3D Single Object Tracking in Bird's-Eye View|BEVTrack：面向鸟瞰图三维单目标跟踪的简洁而强大的基线方法|Yuxiang Yang, Yingqi Deng, Mian Pan, Zheng-Jun Zha, Jing Zhang|<http://arxiv.org/pdf/2309.02185v8>|[代码](https://github.com/xmm-prio/BEVTrack.); 提出了BEVTrack，一种简单有效的基于单回归损失的直接估计物体在鸟瞰视图中的运动的方法，提升了3...|
|🆕 发布|Dual-Stream Alignment for Action Segmentation|动作分割的双流对齐方法|Harshala Gammulle, Clinton Fookes, Sridha Sridharan, Simon Denman|<http://arxiv.org/pdf/2510.07652v1>|提出双流对齐网络DSA Net，融合动作和动作转换线索，实现动作分割性能提升。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Prompt-guided Representation Disentanglement for Action Recognition|动作识别中的提示引导表示解耦|Tianci Wu, Guangming Zhu, Jiang Lu, Siyuan Wang, Ning Wang, Nuoye Xiong, Zhang Liang|<http://arxiv.org/pdf/2509.21783v2>|[代码](https://github.com/iamsnaping/ProDA.git); 提出ProDA框架，通过动态提示模块和图解析神经网络分离多动作场景中的特定动作。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GazeProphet: Software-Only Gaze Prediction for VR Foveated Rendering|《GazeProphet：仅软件实现的虚拟现实注视点预测技术用于注视点渲染》|Farhaan Ebadulla, Chiraag Mudlapur, Gaurav BV|<http://arxiv.org/pdf/2508.13546v2>|提出了一种无需专用硬件的眼动预测方法，通过软件实现降低VR渲染计算需求。|
|🆕 发布|MMHOI: Modeling Complex 3D Multi-Human Multi-Object Interactions|多人体多物体交互建模：复杂三维场景下的MMHOI|Kaen Kogashi, Anoop Cherian, Meng-Yu Jennifer Kuo|<http://arxiv.org/pdf/2510.07828v1>|提出了MMHOI数据集和MMHOI-Net模型，实现了对复杂三维多人多物交互的高效建模与预测。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 掩码自编码 (Masked Autoencoding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data|MAESTRO：用于多模态、多时相和多光谱地球观测数据的掩码自编码器|Antoine Labatie, Michael Vaccaro, Nina Lardiere, Anatol Garioud, Nicolas Gonthier|<http://arxiv.org/pdf/2508.10894v2>|[代码](https://github.com/ignf/maestro.); 提出了一种针对多模态、多时态、多光谱地球观测数据的Masked AutoEncoder改进方法，实现...|


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PointAD+: Learning Hierarchical Representations for Zero-shot 3D Anomaly Detection|点异常检测增强：学习用于零样本三维异常检测的层次化表示|Qihang Zhou, Shibo He, Jiangtao Yan, Wenchao Meng, Jiming Chen|<http://arxiv.org/pdf/2509.03277v4>|提出了一种结合点和像素级信息的三维异常检测框架，通过显式和隐式表示学习识别未见物体的三维异常。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DexNDM: Closing the Reality Gap for Dexterous In-Hand Rotation via Joint-Wise Neural Dynamics Model|DexNDM：通过关节-wise神经动态模型缩小灵巧手内旋转的现实差距|Xueyi Liu, He Wang, Li Yi|<http://arxiv.org/pdf/2510.08556v1>|[代码](https://meowuu7.github.io/DexNDM); 提出了一种学习关节动态的模型，有效缩小了仿真与实际操作间的差距，实现了对多种复杂物体的灵活操控。|
|🆕 发布|Dream to Recall: Imagination-Guided Experience Retrieval for Memory-Persistent Vision-and-Language Navigation|梦境回忆：想象引导的经验检索用于记忆持久性的视觉与语言导航|Yunzhe Xu, Yiyuan Pan, Zhe Liu|<http://arxiv.org/pdf/2510.08553v1>|[代码](https://github.com/xyz9911/Memoir.); 提出了一种基于想象力的记忆检索机制，有效提升了视觉与语言导航中的记忆持久性表现。|
|🆕 发布|Have We Scene It All? Scene Graph-Aware Deep Point Cloud Compression|“我们是否已经见过一切？场景图感知的深度点云压缩”|Nikolaos Stathoulopoulos, Christoforos Kanellakis, George Nikolakopoulos|<http://arxiv.org/pdf/2510.08512v1>|提出了一种基于场景图的深度点云压缩框架，通过语义分解和紧凑编码实现高达98%的数据压缩，同时保持结构...|
|🆕 发布|Efficient Label Refinement for Face Parsing Under Extreme Poses Using 3D Gaussian Splatting|高效的三维高斯散点法对面部解析极端姿态下的标签细化|Ankit Gahlawat, Anirban Mukherjee, Dinesh Babu Jayagopi|<http://arxiv.org/pdf/2510.08096v1>|利用3D高斯散点技术，本文提出了一种有效的标签优化流程，显著提升了极端姿态下的面部解析精度。|
|🆕 发布|FlowLensing: Simulating Gravitational Lensing with Flow Matching|流量透镜：使用流量匹配模拟引力透镜效应|Hamees Sayed, Pranath Reddy, Michael W. Toomey, Sergei Gleyzer|<http://arxiv.org/pdf/2510.07878v1>|FlowLensing通过高效的流匹配模型加速了强引力透镜效应的仿真，大幅提高了大规模模拟的速度和保...|
|🆕 发布|IntentionVLA: Generalizable and Efficient Embodied Intention Reasoning for Human-Robot Interaction|意图VLA：用于人机交互的通用高效具身意图推理|Yandu Chen, Kefan Gu, Yuqing Wen, Yucheng Zhao, Tiancai Wang, Liqiang Nie|<http://arxiv.org/pdf/2510.07778v1>|提出IntentionVLA框架，通过推理数据和紧凑推理输出提升机器人对人类隐含意图的理解和响应能力...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Hierarchical Spatial Algorithms for High-Resolution Image Quantization and Feature Extraction|高分辨率图像量化与特征提取的层次化空间算法|Noor Islam S. Mohammad|<http://arxiv.org/pdf/2510.08449v1>|提出了一种模块化图像处理框架，通过量化、增强和特征提取提高了图像处理效率和准确性。|
|🆕 发布|Demystifying Deep Learning-based Brain Tumor Segmentation with 3D UNets and Explainable AI (XAI): A Comparative Analysis|揭开基于深度学习的脑肿瘤分割之谜：采用3D UNets和可解释人工智能（XAI）的比较分析|Ming Jie Ong, Sze Yinn Ung, Sim Kuan Goh, Jimmy Y. Zhong|<http://arxiv.org/pdf/2510.07785v1>|[代码](https://github.com/ethanong98/MultiModel-XAI-Brats2020); 本研究通过应用3D UNet模型和解释性AI技术，提升了脑肿瘤在MRI图像中的分割精度，增强了医生对...|
|🆕 发布|DEGS: Deformable Event-based 3D Gaussian Splatting from RGB and Event Stream|可变形事件驱动的基于RGB和事件流的3D高斯散点绘制方法（DEGS）|Junhao He, Jiaxu Wang, Jia Li, Mingyuan Sun, Qiang Zhang, Jiahang Cao, Ziyi Zhang, Yi Gu .etc.|<http://arxiv.org/pdf/2510.07752v1>|提出了一种结合RGB视频和事件流优化动态3D高斯散布的新框架，有效解决了大范围帧间运动带来的重建不确...|
|🆕 发布|ComGS: Efficient 3D Object-Scene Composition via Surface Octahedral Probes|ComGS：通过表面八叉探针实现高效的3D物体-场景组合|Jian Gao, Mengqi Yuan, Yifei Zeng, Chang Zeng, Zhihao Li, Zhenyu Chen, Weichao Qiu, Xiao-Xiao Long .etc.|<http://arxiv.org/pdf/2510.07729v1>|[代码](https://nju-3dv.github.io/projects); 提出了一种高效的3D对象场景组合方法ComGS，通过表面八叉探测避免了昂贵的光线追踪，实现了实时高质...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Spectral Prefiltering of Neural Fields|神经场的频谱预滤波|Mustafa B. Yaldiz, Ishit Mehta, Nithin Raghavan, Andreas Meuleman, Tzu-Mao Li, Ravi Ramamoorthi|<http://arxiv.org/pdf/2510.08394v1>|提出了一种优化神经场表示连续视觉信号的方法，通过单次前向传播实现频谱预滤波，提高了滤波效率和效果。|
|🆕 发布|Is Architectural Complexity Always the Answer? A Case Study on SwinIR vs. an Efficient CNN|“建筑复杂性是否总是答案？关于SwinIR与高效卷积神经网络的一个案例研究”|Chandresh Sutariya, Nitin Singh|<http://arxiv.org/pdf/2510.07984v1>|证明了在低光图像处理中，标准轻量级CNN在性能上可接近复杂的Transformer模型，且计算成本显...|
|📝 更新|How We Won BraTS-SSA 2025: Brain Tumor Segmentation in the Sub-Saharan African Population Using Segmentation-Aware Data Augmentation and Model Ensembling|我们如何赢得BraTS-SSA 2025：利用分割感知数据增强和模型融合对撒哈拉以南非洲人口进行脑肿瘤分割|Claudia Takyi Ankomah, Livingstone Eli Ayivor, Ireneaus Nyame, Leslie Wambo, Patrick Yeboah Bonsu, Aondona Moses Iorumbur, Raymond Confidence, Toufiq Musah|<http://arxiv.org/pdf/2510.03568v2>|[代码](https://github.com/SPARK-Academy-2025/SPARK-2025); 提出针对欠发达地区脑肿瘤分割的模型，通过数据增强和模型融合提升了准确性和泛化能力。|
|🆕 发布|FMANet: A Novel Dual-Phase Optical Flow Approach with Fusion Motion Attention Network for Robust Micro-expression Recognition|FMANet：一种具有融合运动注意力网络的新型双相光流方法，用于鲁棒的微表情识别|Luu Tu Nguyen, Vu Tram Anh Khuong, Thi Bich Phuong Man, Thi Duyen Ngo, Thanh Ha Le|<http://arxiv.org/pdf/2510.07810v1>|提出了一种融合双阶段光流信息的微表情识别网络，有效提升了微表情的捕捉与识别准确性。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SimCast: Enhancing Precipitation Nowcasting with Short-to-Long Term Knowledge Distillation|SimCast：利用短期至长期知识蒸馏增强降水预报|Yifang Yin, Shengkai Chen, Yiyao Li, Lu Wang, Ruibing Jin, Wei Cui, Shili Xiang|<http://arxiv.org/pdf/2510.07953v1>|提出SimCast训练流程，通过短期到长期知识蒸馏和加权MSE损失优化降水预测，显著提升预测准确性。|
|📝 更新|I&S-ViT: An Inclusive & Stable Method for Pushing the Limit of Post-Training ViTs Quantization|I&S-ViT：一种包容且稳定的方法，推动训练后ViT量化的极限|Yunshan Zhong, Jiawei Hu, Mingbao lin, Mengzhao Chen, Rongrong Ji|<http://arxiv.org/pdf/2311.10126v3>|提出I&S-ViT方法，通过改进量化器和优化策略，有效提升低比特位ViT模型的性能和稳定性。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Revisiting Reweighted Risk for Calibration: AURC, Focal, and Inverse Focal Loss|重新审视校准的重新加权风险：AURC、焦点损失和逆焦点损失|Han Zhou, Sebastian G. Gruber, Teodora Popordanoska, Matthew B. Blaschko|<http://arxiv.org/pdf/2505.23463v4>|建立了加权风险函数与校准误差的原理性联系，提出了一种优化选择性风险以提高模型校准性能的方法。|
|📝 更新|Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations|野外环境下的域泛化：解耦分类与域感知表征|Ha Min Son, Zhe Zhao, Shahbaz Rezaei, Xin Liu|<http://arxiv.org/pdf/2508.21769v2>|提出了一种增强领域意识并实现领域不变分类的新方法CLIP-DCA，有效提升了模型在未见过数据集上的泛...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ReSplat: Learning Recurrent Gaussian Splats|“ReSplat：学习循环高斯散点”|Haofei Xu, Daniel Barath, Andreas Geiger, Marc Pollefeys|<http://arxiv.org/pdf/2510.08575v1>|[代码](https://haofeixu.github.io/resplat); 提出迭代精炼3D高斯分布的ReSplat模型，通过反馈信号学习有效更新，减少高斯数量并提升渲染速度。|
|📝 更新|Play to Generalize: Learning to Reason Through Game Play|《玩以泛化：通过游戏玩耍学习推理》|Yunfei Xie, Yinsong Ma, Shiyi Lan, Alan Yuille, Junfei Xiao, Chen Wei|<http://arxiv.org/pdf/2506.08011v4>|提出了一种通过玩电子游戏来提升大型多模态语言模型推理能力的方法，实现了在多种任务上的性能提升。|
|🆕 发布|Detecting Legend Items on Historical Maps Using GPT-4o with In-Context Learning|使用带有上下文学习功能的GPT-4o检测历史地图上的图例项|Sofia Kirsanova, Yao-Yi Chiang, Weiwei Duan|<http://arxiv.org/pdf/2510.08385v1>|利用GPT-4o与in-context学习结合布局检测，实现了历史地图图例项目的自动识别与关联。|
|📝 更新|ProtoMedX: Towards Explainable Multi-Modal Prototype Learning for Bone Health Classification|面向骨骼健康分类的可解释多模态原型学习：ProtoMedX|Alvaro Lopez Pellicer, Andre Mariucci, Plamen Angelov, Marwan Bukhari, Jemma G. Kerns|<http://arxiv.org/pdf/2509.14830v2>|提出了一种可解释的多模态原型学习模型ProtoMedX，用于骨健康分类，同时实现了优于现有方法的准确...|
|🆕 发布|Dual-granularity Sinkhorn Distillation for Enhanced Learning from Long-tailed Noisy Data|双粒度辛钦蒸馏法用于增强长尾噪声数据的学习|Feng Hong, Yu Huang, Zihua Zhao, Zhihan Zhou, Jiangchao Yao, Dongsheng Li, Ya Zhang, Yanfeng Wang|<http://arxiv.org/pdf/2510.08179v1>|提出双粒度 Sinkhorn 蒸馏框架，通过结合专用于解决类别不平衡和标签噪声的辅助模型，增强学习长...|
|🆕 发布|MMM: Quantum-Chemical Molecular Representation Learning for Combinatorial Drug Recommendation|MMM: 用于组合药物推荐的量子化学分子表示学习|Chongmyung Kwon, Yujin Kim, Seoeun Park, Yunji Lee, Charmgil Hong|<http://arxiv.org/pdf/2510.07910v1>|提出了一种融合三维量子化学信息的药物表示学习方法，提高了药物相互作用预测的准确性。|
|🆕 发布|Self-Supervised Learning Strategies for a Platform to Test the Toxicity of New Chemicals and Materials|用于测试新化学品和材料毒性的自监督学习策略平台|Thomas Lautenschlager, Nils Friederich, Angelo Jovin Yamachui Sitcheu, Katja Nau, Gaëlle Hayot, Thomas Dickmeis, Ralf Mikut|<http://arxiv.org/pdf/2510.07853v1>|利用自监督学习识别有毒化合物引起的胚胎变化，提高毒性测试自动化评估效果。|
|🆕 发布|Team Xiaomi EV-AD VLA: Learning to Navigate Socially Through Proactive Risk Perception - Technical Report for IROS 2025 RoboSense Challenge Social Navigation Track|小米EV-AD VLA团队：通过主动风险感知学习社交导航 - 2025年IROS RoboSense挑战社交导航赛道技术报告|Erjia Xiao, Lingfeng Zhang, Yingbo Tang, Hao Cheng, Renjing Xu, Wenbo Ding, Lei Zhou, Long Chen .etc.|<http://arxiv.org/pdf/2510.07871v1>|提出了一种增强社会导航性能的风险感知模块，通过预测碰撞风险，提高了自主代理在动态人群环境中的避障能力...|
|📝 更新|Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning|学习绳索技巧，然后信任胜利：基于渐进探索的代理强化学习中的自我模仿|Yulei Qin, Xiaoyu Tan, Zhengbao He, Gang Li, Haojia Lin, Zongyi Li, Zihan Xu, Yuchen Shi .etc.|<http://arxiv.org/pdf/2509.22601v2>|提出了一种基于自我模仿和渐进探索的强化学习方法，平衡了探索与利用，提高了长时 horizon 任务的...|
|🆕 发布|Mutual Learning for Hashing: Unlocking Strong Hash Functions from Weak Supervision|相互学习用于哈希：从弱监督中解锁强大的哈希函数|Xiaoxu Ma, Runhao Li, Zhenyu Weng|<http://arxiv.org/pdf/2510.07703v1>|提出了一种弱监督学习的Mutual Learning for Hashing框架，通过结合中心化和成...|
|🆕 发布|RePainter: Empowering E-commerce Object Removal via Spatial-matting Reinforcement Learning|“RePainter：通过空间遮罩强化学习赋能电子商务对象移除”|Zipeng Guo, Lichen Ma, Xiaolong Fu, Gaojing Zhou, Lan Yang, Yuchen Zhou, Linkai Liu, Yu He .etc.|<http://arxiv.org/pdf/2510.07721v1>|提出了一种结合空间遮罩强化学习的Repainter框架，用于电商图像中去除干扰元素，显著提升了视觉效...|
|🆕 发布|UltraLED: Learning to See Everything in Ultra-High Dynamic Range Scenes|超亮显：在超高动态范围场景中学习看见一切|Yuang Meng, Xin Jin, Lina Lei, Chun-Le Guo, Chongyi Li|<http://arxiv.org/pdf/2510.07741v1>|[代码](https://srameo.github.io/projects); 提出了一种两阶段框架UltraLED，仅使用单张短曝光RAW图像实现UHDR场景的细节恢复和动态范围...|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RASALoRE: Region Aware Spatial Attention with Location-based Random Embeddings for Weakly Supervised Anomaly Detection in Brain MRI Scans|区域感知空间注意力与基于位置随机嵌入的弱监督脑部MRI扫描异常检测方法|Bheeshm Sharma, Karthikeyan Jaganathan, Balamurugan Palaniappan|<http://arxiv.org/pdf/2510.08052v1>|[代码](https://github.com/BheeshmSharma/RASALoRE-BMVC-2025); 提出了一种两阶段弱监督异常检测框架RASALoRE，通过区域感知注意力和位置随机嵌入显著提升脑部MR...|
|📝 更新|CORE-3D: Context-aware Open-vocabulary Retrieval by Embeddings in 3D|CORE-3D：基于三维嵌入的上下文感知开放式词汇检索|Mohamad Amin Mirzaei, Pantea Amoie, Ali Ekhterachian, Matin Mirzababaei, Babak Khalaj|<http://arxiv.org/pdf/2509.24528v2>|提出了一种结合语义分割和上下文感知编码的策略，有效提升了三维场景理解和物体检索的准确性。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|NavSpace: How Navigation Agents Follow Spatial Intelligence Instructions|导航空间：导航智能体如何遵循空间智能指令|Haolin Yang, Yuxing Long, Zhuoyuan Yu, Zihan Yang, Minghan Wang, Jiapeng Xu, Yihan Wang, Ziyan Yu .etc.|<http://arxiv.org/pdf/2510.08173v1>|提出NavSpace基准，评估导航代理的空间智能，并提出了表现卓越的SNav模型。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SciVideoBench: Benchmarking Scientific Video Reasoning in Large Multimodal Models|SciVideoBench：大规模多模态模型中科学视频推理的基准测试|Andong Deng, Taojiannan Yang, Shoubin Yu, Lincoln Spencer, Mohit Bansal, Chen Chen, Serena Yeung-Levy, Xiaohan Wang|<http://arxiv.org/pdf/2510.08559v1>|提出了SciVideoBench，专为评估大型多模态模型在科学视频推理中的高级认知能力设计。|
|🆕 发布|The Visual Iconicity Challenge: Evaluating Vision-Language Models on Sign Language Form-Meaning Mapping|视觉图标性挑战：评估视觉-语言模型在手语形式-意义映射上的表现|Onur Keleş, Aslı Özyürek, Gerardo Ortega, Kadir Gökgö, Esam Ghaleb|<http://arxiv.org/pdf/2510.08482v1>|提出了“视觉象征性挑战”基准，评估视觉语言模型在动态手势语言中的形式与意义映射能力。|
|🆕 发布|Video-STAR: Reinforcing Open-Vocabulary Action Recognition with Tools|视频-STAR：利用工具强化开放词汇动作识别|Zhenlong Yuan, Xiangyan Qu, Chengxuan Qian, Rui Chen, Jing Tang, Lei Sun, Xiangxiang Chu, Dapeng Zhang .etc.|<http://arxiv.org/pdf/2510.08480v1>|提出Video-STAR框架，通过分解动作并利用工具增强学习，实现了细粒度开放词汇动作识别。|
|🆕 发布|Gaze on the Prize: Shaping Visual Attention with Return-Guided Contrastive Learning|《聚焦于目标：利用返回引导的对比学习塑造视觉注意力》|Andrew Lee, Ian Chuang, Dechen Gao, Kai Fukazawa, Iman Soltani|<http://arxiv.org/pdf/2510.08442v1>|引入基于回报差异的自监督视觉注意力机制，提升视觉强化学习样本效率和稳定性。|
|🆕 发布|Evaluating Small Vision-Language Models on Distance-Dependent Traffic Perception|评估小规模视觉-语言模型在距离依赖性交通感知任务上的表现|Nikos Theodoridis, Tim Brophy, Reenu Mohandas, Ganesh Sistu, Fiachra Collins, Anthony Scanlan, Ciaran Eising|<http://arxiv.org/pdf/2510.08352v1>|提出首个针对交通场景距离感知的视觉问答基准，评估小型视觉语言模型在远近距离的感知能力。|
|📝 更新|TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics|TIGeR：面向机器人视觉语言模型的工具集成几何推理|Yi Han, Cheng Chi, Enshen Zhou, Shanyu Rong, Jingkun An, Pengwei Wang, Zhongyuan Wang, Lu Sheng .etc.|<http://arxiv.org/pdf/2510.07181v2>|提出了一种使视觉语言模型具备精确几何计算能力的新框架，通过调用外部工具实现厘米级精度的机器人操控。|
|🆕 发布|RayFusion: Ray Fusion Enhanced Collaborative Visual Perception|射线融合增强协同视觉感知|Shaohong Wang, Bin Lu, Xinyu Xiao, Hanzhi Zhong, Bowen Pang, Tong Wang, Zhiyu Xiang, Hangguan Shan .etc.|<http://arxiv.org/pdf/2510.08017v1>|[代码](https://github.com/wangsh0111/RayFusion.); 提出了一种基于射线融合的协同视觉感知方法RayFusion，通过利用射线占用信息减少冗余和误报，显著...|
|📝 更新|OASIS: Online Sample Selection for Continual Visual Instruction Tuning|OASIS：在线样本选择用于持续视觉指令微调|Minjae Lee, Minhyuk Seo, Tingyu Qu, Tinne Tuytelaars, Jonghyun Choi|<http://arxiv.org/pdf/2506.02011v2>|提出了一种自适应在线样本选择方法OASIS，通过估计样本相对所有历史数据的 informativen...|
|🆕 发布|Enhancing Visual Prompting through Expanded Transformation Space and Overfitting Mitigation|通过扩展变换空间和过拟合缓解增强视觉提示效果|Shohei Enomoto|<http://arxiv.org/pdf/2510.07823v1>|提出了一种增强视觉提示方法，通过引入仿射和颜色变换以及防止过拟合，提高了视觉模型的适应性精度。|
|📝 更新|AlignCAT: Visual-Linguistic Alignment of Category and Attribute for Weakly Supervised Visual Grounding|《AlignCAT：类别与属性弱监督视觉定位的视觉-语言对齐》|Yidan Wang, Chenyi Zhuang, Wutao Liu, Pan Gao, Nicu Sebe|<http://arxiv.org/pdf/2508.03201v2>|[代码](https://github.com/I2-Multimedia-Lab/AlignCAT.); 提出 AlignCAT 方法，通过细粒度语义匹配解决弱监督视觉定位中描述文本的模糊性问题。|
|📝 更新|Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory|“观察、聆听、记忆与推理：具有长期记忆的多模态智能体”|Lin Long, Yichen He, Wentao Ye, Yiyuan Pan, Yuan Lin, Hang Li, Junbo Zhao, Wei Li|<http://arxiv.org/pdf/2508.09736v4>|[代码](https://github.com/bytedance-seed/m3-agent.); 提出了M3-Agent，一种具备长期记忆能力的多模态智能体框架，通过自主推理和记忆检索完成复杂任务。|
|📝 更新|Efficient Multi Subject Visual Reconstruction from fMRI Using Aligned Representations|基于对齐表示的fMRI多主体视觉重建效率化方法|Christos Zangos, Danish Ebadulla, Thomas Christopher Sprague, Ambuj Singh|<http://arxiv.org/pdf/2505.01670v2>|利用通用表示空间对fMRI数据进行对齐，提出了一种高效的多主体视觉重建方法。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Q-CLIP: Unleashing the Power of Vision-Language Models for Video Quality Assessment through Unified Cross-Modal Adaptation|Q-CLIP：通过统一跨模态适配释放视觉-语言模型在视频质量评估中的力量|Yachun Mi, Yu Li, Yanting Li, Chen Hui, Tong Zhang, Zhixuan Li, Chenyue Song, Wei Yang Bryan Lim .etc.|<http://arxiv.org/pdf/2508.06092v2>|提出首个基于视觉语言模型的视频质量评估框架，通过跨模态适配器降低计算成本并增强质量感知能力。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Scalable Offline Metrics for Autonomous Driving|自动驾驶的可扩展离线评价指标|Animikh Aich, Adwait Kulkarni, Eshed Ohn-Bar|<http://arxiv.org/pdf/2510.08571v1>|提出了一种基于不确定性的新离线评价指标，提高了预测在线性能与离线评估之间的相关性。|
|🆕 发布|Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning|基于课程学习的无需源域的医学图像分割鲁棒迁移适应|Ziqi Zhang, Yuexiang Li, Yawen Huang, Nanjun He, Tao Xu, Liwei Lin, Yefeng Zheng, Shaoxin Li .etc.|<http://arxiv.org/pdf/2510.08393v1>|提出了一种基于课程学习的无源域自适应框架，有效解决了医学图像分割中的数据隐私和安全问题。|
|📝 更新|H3DE-Net: Efficient and Accurate 3D Landmark Detection in Medical Imaging|H3DE-Net：医学影像中高效准确的三维地标检测网络|Zhen Huang, Tao Tang, Ronghao Xu, Yangbo Wei, Wenkai Yang, Suhua Wang, Xiaoxin Sun, Han Li .etc.|<http://arxiv.org/pdf/2502.14221v2>|提出了一种结合CNN和轻量级注意力机制的H3DE-Net，实现了高效准确的3D医学图像标志点检测。|
|🆕 发布|Random Window Augmentations for Deep Learning Robustness in CT and Liver Tumor Segmentation|深度学习中针对CT图像和肝脏肿瘤分割的随机窗口增强方法|Eirik A. Østmo, Kristoffer K. Wickstrøm, Keyur Radiya, Michael C. Kampffmeyer, Karl Øyvind Mikalsen, Robert Jenssen|<http://arxiv.org/pdf/2510.08116v1>|提出了一种针对CT图像的随机窗口增强技术，提高了肝脏肿瘤分割模型的鲁棒性和性能。|
|📝 更新|FireGNN: Neuro-Symbolic Graph Neural Networks with Trainable Fuzzy Rules for Interpretable Medical Image Classification|FireGNN：具有可训练模糊规则的神经符号图神经网络，用于可解释的医疗图像分类|Prajit Sengupta, Islem Rekik|<http://arxiv.org/pdf/2509.10510v2>|[代码](https://github.com/basiralab/FireGNN); 引入可训练的模糊规则到图神经网络中，FireGNN实现了高预测性能和可解释性，适用于医疗图像分类。|
|🆕 发布|ASBench: Image Anomalies Synthesis Benchmark for Anomaly Detection|ASBench：用于异常检测的图像异常合成基准|Qunyi Zhang, Songan Zhang, Jinbao Wang, Xiaoning Lei, Guoyang Xie, Guannan Jiang, Zhichao Lu|<http://arxiv.org/pdf/2510.07927v1>|提出ASBench，首个全面评估异常合成方法的框架，提升异常检测在制造质量控制的适用性。|
|📝 更新|MInDI-3D: Iterative Deep Learning in 3D for Sparse-view Cone Beam Computed Tomography|MInDI-3D：用于稀疏视角锥形束计算机断层扫描的三维迭代深度学习|Daniel Barco, Marc Stadelmann, Martin Oswald, Ivo Herzig, Lukas Lichtensteiger, Pascal Paysan, Igor Peterlik, Michal Walczak .etc.|<http://arxiv.org/pdf/2508.09616v2>|首次将3D条件扩散模型应用于稀疏视角锥形束CT，实现辐射暴露降低8倍同时保持图像质量。|
|🆕 发布|GTR-Bench: Evaluating Geo-Temporal Reasoning in Vision-Language Models|GTR-Bench：评估视觉语言模型中的地理时间推理|Qinghongbing Xie, Zhaoyuan Xia, Feng Zhu, Lijun Gong, Ziyue Li, Rui Zhao, Long Zeng|<http://arxiv.org/pdf/2510.07791v1>|[代码](https://github.com/X-Luffy/GTR-Bench.); 提出Geo-Temporal Reasoning基准，评估视觉语言模型在处理地理时空推理任务中的性能...|
|🆕 发布|TCIP: Threshold-Controlled Iterative Pyramid Network for Deformable Medical Image Registration|TCIP：阈值控制迭代金字塔网络用于可变形医学图像配准|Heming Wu, Di Wang, Tai Ma, Peng Zhao, Yubin Xiao, Zhongke Wu, Xing-Ce Wang, Chuang Li .etc.|<http://arxiv.org/pdf/2510.07666v1>|提出了一种自适应迭代金字塔网络TCIP，通过增强特征模块和阈值控制策略，有效减少了医学图像配准中的结...|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ResAD: Normalized Residual Trajectory Modeling for End-to-End Autonomous Driving|残差归一化轨迹建模方法ResAD：用于端到端自动驾驶|Zhiyu Zheng, Shaoyu Chen, Haoran Yin, Xinbang Zhang, Jialv Zou, Xinggang Wang, Qian Zhang, Lefei Zhang|<http://arxiv.org/pdf/2510.08562v1>|提出了一种预测轨迹残差的规范化方法ResAD，通过学习轨迹偏差改善自动驾驶系统的即时安全性和长期预测...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ThinkGeo: Evaluating Tool-Augmented Agents for Remote Sensing Tasks|“ThinkGeo：评估工具增强型代理在遥感任务中的表现”|Akashah Shabbir, Muhammad Akhtar Munir, Akshay Dudhane, Muhammad Umer Sheikh, Muhammad Haris Khan, Paolo Fraccaro, Juan Bernabe Moreno, Fahad Shahbaz Khan .etc.|<http://arxiv.org/pdf/2505.23752v2>|提出首个针对遥感任务的工具增强智能体评估基准，通过多步骤规划和工具使用提升模型在遥感应用中的推理能力...|
|🆕 发布|Adaptive Gradient Calibration for Single-Positive Multi-Label Learning in Remote Sensing Image Scene Classification|Scene分类中的遥感图像单正多标签学习自适应梯度校准|Chenying Liu, Gianmarco Perantoni, Lorenzo Bruzzone, Xiao Xiang Zhu|<http://arxiv.org/pdf/2510.08269v1>|提出了一种自适应梯度校准框架AdaGC，有效解决了遥感图像多标签学习中标签不完整的问题。|
|📝 更新|Explaining raw data complexity to improve satellite onboard processing|将原始数据复杂性解释以提高卫星在轨处理能力|Adrien Dorise, Marjorie Bellizzi, Adrien Girard, Benjamin Francesconi, Stéphane May|<http://arxiv.org/pdf/2510.06858v2>|探究了在卫星上直接使用原始数据训练深度学习模型的效果，提出改进AI架构以增强对象检测能力。|
|🆕 发布|A class-driven hierarchical ResNet for classification of multispectral remote sensing images|基于类驱动的层次化ResNet用于多光谱遥感图像分类|Giulio Weikmann, Gianmarco Perantoni, Lorenzo Bruzzone|<http://arxiv.org/pdf/2510.08060v1>|提出了一种分层ResNet架构，通过引入额外分支和层级惩罚，有效提升了多光谱遥感图像分类的精确度。|
|📝 更新|Spiking Meets Attention: Efficient Remote Sensing Image Super-Resolution with Attention Spiking Neural Networks|“脉冲遇见注意力：基于注意力脉冲神经网络的高效遥感图像超分辨率”|Yi Xiao, Qiangqiang Yuan, Kui Jiang, Wenke Huang, Qiang Zhang, Tingting Zheng, Chia-Wen Lin, Liangpei Zhang|<http://arxiv.org/pdf/2503.04223v3>|[代码](https://github.com/XY-boy/SpikeSR.); 提出了一种基于脉冲神经网络的图像超分辨率方法，通过注意力脉冲块优化特征表示，实现了高效的遥感图像重建...|
|🆕 发布|CVD-STORM: Cross-View Video Diffusion with Spatial-Temporal Reconstruction Model for Autonomous Driving|交叉视图视频扩散与时空重建模型CVD-STORM：面向自动驾驶的应用|Tianrui Zhang, Yichen Liu, Zilin Guo, Yuxin Guo, Jingcheng Ni, Chenjing Ding, Dan Xu, Lewei Lu .etc.|<http://arxiv.org/pdf/2510.07944v1>|提出了一种生成模型CVD-STORM，通过时空重建VAE实现多视角、长期视频的4D重建，提升自动驾驶...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Motion Capture from Inertial and Vision Sensors|从惯性测量单元和视觉传感器进行运动捕捉|Xiaodong Chen, Wu Liu, Qian Bao, Xinchen Liu, Quanwei Yang, Ruoli Dai, Tao Mei|<http://arxiv.org/pdf/2407.16341v2>|提出MINIONS数据集和SparseNet框架，利用单目摄像头和少量IMU实现低成本多模态人体运动...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Robust Canonicalization through Bootstrapped Data Re-Alignment|通过引导数据重新对齐实现的鲁棒规范化|Johann Schmidt, Sebastian Stober|<http://arxiv.org/pdf/2510.08178v1>|提出了一种迭代重对齐训练样本的引导算法，有效克服了细粒度视觉分类任务中的几何偏置和噪声问题。|
|🆕 发布|DarkHash: A Data-Free Backdoor Attack Against Deep Hashing|《DarkHash：一种无需数据的对抗深度哈希的后门攻击》|Ziqi Zhou, Menghao Deng, Yufei Song, Hangtao Zhang, Wei Wan, Shengshan Hu, Minghui Li, Leo Yu Zhang .etc.|<http://arxiv.org/pdf/2510.08094v1>|提出了一种无需原始训练数据的DarkHash方法，实现了对深度哈希模型的数据无关后门攻击。|
|📝 更新|Empowering Lightweight MLLMs with Reasoning via Long CoT SFT|通过长CoT SFT赋予轻量级多模态LLM推理能力|Linyu Ou, YuYang Yin|<http://arxiv.org/pdf/2509.03321v2>|探究长Chain-of-Thought数据对轻量级多模态语言模型推理能力的提升，发现先监督微调再强化...|

