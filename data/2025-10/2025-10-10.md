## [UPDATED!] **2025-10-10** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation|VITA-VLA：通过动作专家蒸馏高效地教导视觉语言模型执行动作|Shaoqi Dong, Chaoyou Fu, Haihan Gao, Yi-Fan Zhang, Chi Yan, Chu Wu, Xiaoyu Liu, Yunhang Shen .etc.|<http://arxiv.org/pdf/2510.09607v1>|提出了一种基于知识蒸馏的框架，通过小规模动作模型的知识迁移，有效提升视觉语言模型在机器人操作中的效率...|
|📝 更新|RobustMerge: Parameter-Efficient Model Merging for MLLMs with Direction Robustness|鲁棒合并：面向多语言大型语言模型的参数高效模型合并方法及方向鲁棒性|Fanhu Zeng, Haiyang Guo, Fei Zhu, Li Shen, Hao Tang|<http://arxiv.org/pdf/2502.17159v3>|[代码](https://github.com/AuroraZengfh/RobustMerge.); 提出了一种参数高效的模型融合方法RobustMerge，通过保持方向稳健性，有效解决了多任务学习模型...|
|🆕 发布|Utilizing dynamic sparsity on pretrained DETR|利用动态稀疏性优化预训练目标检测模型DETR|Reza Sedghi, Anand Subramoney, David Kappel|<http://arxiv.org/pdf/2510.09380v1>|提出两种方法利用DETR模型中的固有稀疏性，无需重新训练即可提高推理效率。|
|🆕 发布|BLINK-Twice: You see, but do you observe? A Reasoning Benchmark on Visual Perception|“BLINK-两次：你看到了，但你是否观察了？一种基于视觉感知的推理基准测试”|Junyan Ye, Dongzhi Jiang, Jun He, Baichuan Zhou, Zilong Huang, Zhiyuan Yan, Hongsheng Li, Conghui He .etc.|<http://arxiv.org/pdf/2510.09361v1>|[代码](https://github.com/PicoTrex/BLINK-Twice); 提出了BLINK-Twice视觉推理基准，挑战现有模型在深度视觉理解上的能力，强调从图像内容中进行精...|
|🆕 发布|Rewiring Development in Brain Segmentation: Leveraging Adult Brain Priors for Enhancing Infant MRI Segmentation|重新连接大脑分割的发展：利用成人脑先验知识增强婴儿MRI分割|Alemu Sisay Nigru, Michele Svanera, Austin Dibble, Connor Dalby, Mattia Savardi, Sergio Benini|<http://arxiv.org/pdf/2510.09306v1>|利用成人脑部MRI分割模型的知识，提出了一种增强婴儿MRI分割性能的新框架。|
|📝 更新|PanoLAM: Large Avatar Model for Gaussian Full-Head Synthesis from One-shot Unposed Image|全景LAM：从单张非摆姿势图像实现高斯全头合成的超大头像模型|Peng Li, Yisheng He, Yingdong Hu, Yuan Dong, Weihao Yuan, Yuan Liu, Siyu Zhu, Gang Cheng .etc.|<http://arxiv.org/pdf/2509.07552v2>|[代码](https://panolam.github.io/.); 提出了单张非摆姿势图像快速生成高保真全身模型的框架，通过 coarse-to-fine 管道和双分支...|
|📝 更新|RadVLM: A Multitask Conversational Vision-Language Model for Radiology|《RadVLM：一种用于放射学的多任务对话视觉-语言模型》|Nicolas Deperrois, Hidetoshi Matsuo, Samuel Ruipérez-Campillo, Moritz Vandenhirtz, Sonia Laguna, Alain Ryser, Koji Fujimoto, Mizuho Nishio .etc.|<http://arxiv.org/pdf/2502.03333v2>|提出RadVLM模型，通过大规模数据训练实现 chest X-ray 的多任务交互式诊断与报告生成。|
|🆕 发布|MSDM: Generating Task-Specific Pathology Images with a Multimodal Conditioned Diffusion Model for Cell and Nuclei Segmentation|MSDM：基于多模态条件扩散模型为细胞和核分割生成特定任务病理图像|Dominik Winter, Mai Bui, Monica Azqueta Gavaldon, Nicolas Triltsch, Marco Rosati, Nicolas Brieu|<http://arxiv.org/pdf/2510.09121v1>|提出了一种多模态条件扩散模型MSDM，通过生成定制化图像数据，有效提升了细胞和核分割模型的准确性和泛...|
|📝 更新|Any-to-Bokeh: Arbitrary-Subject Video Refocusing with Video Diffusion Model|任意主体视频重聚焦：基于视频扩散模型的任意主体视频散焦效果生成|Yang Yang, Siming Zheng, Qirui Yang, Jinwei Chen, Boxi Wu, Xiaofei He, Deng Cai, Bo Li .etc.|<http://arxiv.org/pdf/2505.21593v3>|首次提出基于扩散模型的一步视频重聚焦框架，实现了时序连贯且可控的景深效果。|
|📝 更新|ALISE: Annotation-Free LiDAR Instance Segmentation for Autonomous Driving|无需标注的激光雷达实例分割方法ALISE：面向自动驾驶|Yongxuan Lyu, Guangfeng Jiang, Hongsi Liu, Jun Liu|<http://arxiv.org/pdf/2510.05752v2>|定位：无标注激光雷达点云实例分割，方法：使用视觉基础模型生成伪标签，并通过时空投票模块优化，实现无需...|
|📝 更新|VisionTS++: Cross-Modal Time Series Foundation Model with Continual Pre-trained Vision Backbones|《VisionTS++：具有持续预训练视觉骨干的跨模态时间序列基础模型》|Lefei Shen, Mouxiang Chen, Xu Liu, Han Fu, Xiaoxue Ren, Jianling Sun, Zhuo Li, Chenghao Liu|<http://arxiv.org/pdf/2508.04379v3>|[代码](https://github.com/HALF111/VisionTSpp.); 提出VisonTS++模型，通过持续预训练视觉模型处理时间序列，有效桥接模态差异并提升预测性能。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Multimodal Depth-Aware Method For Embodied Reference Understanding|一种多模态深度感知方法用于具身参照理解|Fevziye Irem Eyiokur, Dogucan Yaman, Hazım Kemal Ekenel, Alexander Waibel|<http://arxiv.org/pdf/2510.08278v2>|提出了一种深度感知的多模态方法，有效提升了基于语言和手势的视觉场景目标识别准确性。|
|📝 更新|Multimodal Language Models See Better When They Look Shallower|多模态语言模型在浅层观察时看得更清楚|Haoran Chen, Junyan Lin, Xinghao Chen, Yue Fan, Jianfeng Dong, Xin Jin, Hui Su, Jinlan Fu .etc.|<http://arxiv.org/pdf/2504.21447v2>|发现视觉任务中，使用预训练ViT的浅层特征能提升多模态语言模型性能，提出了一种融合浅层特征的方法。|
|🆕 发布|Spotlight on Token Perception for Multimodal Reinforcement Learning|多模态强化学习中标记感知的聚焦研究|Siyuan Huang, Xiaoye Qu, Yafu Li, Yun Luo, Zefeng He, Daizong Liu, Yu Cheng|<http://arxiv.org/pdf/2510.09285v1>|提出了一种基于视觉依赖度的优化策略，显著增强了大型视觉语言模型的多模态推理能力。|
|📝 更新|ACD-CLIP: Decoupling Representation and Dynamic Fusion for Zero-Shot Anomaly Detection|ACD-CLIP：解耦表示与动态融合用于零样本异常检测|Ke Ma, Jun Long, Hongxiao Fei, Liujie Hua, Zhen Dai, Yueyi Luo|<http://arxiv.org/pdf/2508.07819v5>|[代码](https://github.com/cockmake/ACD-CLIP.); 提出了一种结合局部归纳偏置和动态模态融合的架构共设计方法，有效提升了零样本异常检测的准确性和鲁棒性。|
|📝 更新|Unified Multimodal Model as Auto-Encoder|统一多模态模型作为自动编码器|Zhiyuan Yan, Kaiqing Lin, Zongjian Li, Junyan Ye, Hui Han, Zhendong Wang, Hao Liu, Bin Lin .etc.|<http://arxiv.org/pdf/2509.09666v3>|提出了一种将理解与生成统一为自动编码器框架的模型，通过相互增强实现了更深入的多模态智能。|
|🆕 发布|Cattle-CLIP: A Multimodal Framework for Cattle Behaviour Recognition|牛只CLIP：一种用于牛只行为识别的多模态框架|Huimin Liu, Jing Gao, Daria Baran, AxelX Montout, Neill W Campbell, Andrew W Dowsey|<http://arxiv.org/pdf/2510.09203v1>|提出了一种多模态深度学习框架Cattle-CLIP，利用语义线索提升牛行为识别准确率并有效应对数据稀...|
|📝 更新|RangeSAM: Leveraging Visual Foundation Models for Range-View repesented LiDAR segmentation|范围SAM：利用视觉基础模型进行范围视图表示的激光雷达分割|Paul Julius Kühn, Duc Anh Nguyen, Arjan Kuijper, Holger Graf, Dieter Fellner, Saptarshi Neil Sinha|<http://arxiv.org/pdf/2509.15886v2>|将视觉基础模型应用于LiDAR点云的range-view分割，实现高效准确预测。|
|📝 更新|From Captions to Keyframes: KeyScore for Multimodal Frame Scoring and Video-Language Understanding|从字幕到关键帧：KeyScore 用于多模态帧评分与视频-语言理解|Shih-Yao Lin, Sibendu Paul, Caren Chen|<http://arxiv.org/pdf/2510.06509v2>|提出KeyScore方法，通过结合语义相似度、时间代表性和上下文影响，有效筛选关键帧以提升视频理解效...|
|📝 更新|Visual Representation Alignment for Multimodal Large Language Models|多模态大型语言模型的视觉表示对齐|Heeji Yoon, Jaewoo Jung, Junwan Kim, Hyungyu Choi, Heeseong Shin, Sangbeom Lim, Honggyu An, Chaehyun Kim .etc.|<http://arxiv.org/pdf/2509.07979v2>|提出VIRAL方法，通过视觉表示对齐提升多模态大语言模型在视觉任务上的性能。|
|📝 更新|UniLiP: Adapting CLIP for Unified Multimodal Understanding, Generation and Editing|统一多模态理解、生成与编辑的CLIP适配：UniLiP|Hao Tang, Chenwei Xie, Xiaoyi Bao, Tingyu Weng, Pandeng Li, Yun Zheng, Liwei Wang|<http://arxiv.org/pdf/2507.23278v2>|[代码](https://github.com/nnnth/UniLIP.); 提出了UniLIP框架，通过两阶段训练和自蒸馏策略，使CLIP具备高保真重建能力，实现统一的多模态理...|
|🆕 发布|Unleashing Perception-Time Scaling to Multimodal Reasoning Models|释放感知时间缩放到多模态推理模型中|Yifan Li, Zhenghao Chen, Ziheng Wu, Kun Zhou, Ruipu Luo, Can Zhang, Zhentao He, Yufei Zhan .etc.|<http://arxiv.org/pdf/2510.08964v1>|提出 Perception-Time Scaling 方法，通过分解视觉感知任务提高大型视觉语言模型...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Modeling Time-Lapse Trajectories to Characterize Cranberry Growth|建模时间序列轨迹以表征蔓越莓生长|Ronan John, Anis Chihoub, Ryan Meegan, Gina Sidelli, Jeffery Neyhart, Peter Oudemans, Kristin Dana|<http://arxiv.org/pdf/2510.08901v1>|提出了一种自监督学习方法，通过视觉变压器模型精细调整来监测作物生长，无需手动图像标注。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FSP-DETR: Few-Shot Prototypical Parasitic Ova Detection|FSP-DETR: 基于少量样本原型的寄生卵检测|Shubham Trehan, Udhav Ramachandran, Akash Rao, Ruth Scimeca, Sathyanarayanan N. Aakur|<http://arxiv.org/pdf/2510.09583v1>|提出了一种统一框架FSP-DETR，实现少量样本下的稳健目标检测和开放集识别，有效应对生物医学领域数...|
|🆕 发布|SOS: Synthetic Object Segments Improve Detection, Segmentation, and Grounding|"SOS:合成对象片段提高检测、分割与定位性能"|Weikai Huang, Jieyu Zhang, Taoyang Jia, Chenhao Zheng, Ziqi Gao, Jae Sung Park, Ranjay Krishna|<http://arxiv.org/pdf/2510.09110v1>|提出SOS数据合成管道，通过对象中心组合策略生成高质量合成图像，提升检测和定位性能。|
|📝 更新|CQ-DINO: Mitigating Gradient Dilution via Category Queries for Vast Vocabulary Object Detection|CQ-DINO：通过类别查询减轻梯度稀释以实现大规模词汇表目标检测|Zhichao Sun, Huazhang Hu, Yidong Ma, Gang Liu, Yibo Chen, Xu Tang, Yao Hu, Yongchao Xu|<http://arxiv.org/pdf/2503.18430v4>|[代码](https://github.com/FireRedTeam/CQ-DINO.); 提出了一种基于类别查询的物体检测框架CQ-DINO，通过对比学习平衡梯度分布，有效应对大规模类别检测...|
|🆕 发布|GL-DT: Multi-UAV Detection and Tracking with Global-Local Integration|全局-局部集成多无人机检测与跟踪：GL-DT|Juanqin Liu, Leonardo Plotegher, Eloy Roura, Shaoming He|<http://arxiv.org/pdf/2510.09092v1>|提出GL-DT框架，通过全局-局部协同检测和时空特征融合，有效提升多无人机检测与跟踪的准确性和连续性...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PRNet: Original Information Is All You Have|PRNet：原始信息就是您的全部|PeiHuang Zheng, Yunlong Zhao, Zheng Cui, Yang Li|<http://arxiv.org/pdf/2510.09531v1>|提出PRNet检测框架，通过优化浅层特征利用，显著提升空中小目标检测准确性和效率。|
|📝 更新|Differentially Private 2D Human Pose Estimation|差分隐私二维人体姿态估计|Kaushik Bhargav Sivangi, Paul Henderson, Fani Deligianni|<http://arxiv.org/pdf/2504.10190v3>|提出了一种结合特征选择和梯度投影的差分隐私框架，实现了2D人体姿态估计中的隐私保护与性能平衡。|
|📝 更新|Efficient and Accurate Pneumonia Detection Using a Novel Multi-Scale Transformer Approach|使用新颖多尺度变换器方法的高效准确肺炎检测|Alireza Saber, Amirreza Fateh, Pouria Parhami, Alimohammad Siahkarzadeh, Mansoor Fateh, Saideh Ferdowsi|<http://arxiv.org/pdf/2408.04290v6>|[代码](https://github.com/amirrezafateh/Multi-Scale-Transformer-Pneumonia); 提出了一种结合多尺度特征提取和轻量级变换器的 pneumonia 检测方法，提高了诊断准确性且计算效...|
|📝 更新|Event-RGB Fusion for Spacecraft Pose Estimation Under Harsh Lighting|恶劣光照条件下的事件-RGB融合航天器姿态估计|Mohsi Jawaid, Marcus Märtens, Tat-Jun Chin|<http://arxiv.org/pdf/2507.05698v2>|提出了一种融合RGB与事件传感器的空间craft姿态估计方法，有效应对极端光照条件。|
|🆕 发布|mmJoints: Expanding Joint Representations Beyond (x,y,z) in mmWave-Based 3D Pose Estimation|毫米波三维姿态估计中扩展关节表示：超越（x,y,z）的mmJoints|Zhenyu Wang, Mahathir Monjur, Shahriar Nirjon|<http://arxiv.org/pdf/2510.08970v1>|引入mmJoints框架，通过增加关节描述符提高3D姿态估计的准确性和活动识别性能。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SilvaScenes: Tree Segmentation and Species Classification from Under-Canopy Images in Natural Forests|《SilvaScenes：自然森林下冠层图像中的树木分割与物种分类》|David-Alexandre Duclos, William Guimont-Martin, Gabriel Jeanson, Arthur Larochelle-Tremblay, Théo Defosse, Frédéric Moore, Philippe Nolet, François Pomerleau .etc.|<http://arxiv.org/pdf/2510.09458v1>|[代码](https://github.com/norlab-ulaval/SilvaScenes.); 提出SilvaScenes数据集，助力森林环境下树木实例分割与物种分类。|
|📝 更新|FFT-based Selection and Optimization of Statistics for Robust Recognition of Severely Corrupted Images|基于傅里叶变换的统计量选择与优化以实现严重受损图像的鲁棒识别|Elena Camuffo, Umberto Michieli, Jijoong Moon, Daehyun Kim, Mete Ozay|<http://arxiv.org/pdf/2403.14335v2>|提出了一种名为FROST的方法，通过使用高频特征检测和层特征规范化统计选择，显著提升了严重退化图像的...|
|🆕 发布|Zero-shot image privacy classification with Vision-Language Models|零样本图像隐私分类与视觉-语言模型|Alina Elena Baia, Alessio Xompero, Andrea Cavallaro|<http://arxiv.org/pdf/2510.09253v1>|提出零样本图像隐私分类基准，对比显示大型视觉语言模型在准确度上不如专用小模型，但在图像扰动下更稳健。|
|🆕 发布|Instance-Level Generation for Representation Learning|实例级生成用于表征学习|Yankun Wu, Zakaria Laskar, Giorgos Kordopatis-Zilos, Noa Garcia, Giorgos Tolias|<http://arxiv.org/pdf/2510.09171v1>|提出了一种无需真实图像的合成方法，生成多样化对象实例以提升细粒度图像识别的性能。|
|🆕 发布|Exploring Single Domain Generalization of LiDAR-based Semantic Segmentation under Imperfect Labels|探索在不完美标签下基于激光雷达的语义分割的单域泛化性|Weitong Kong, Zichao Zeng, Di Wen, Jiale Wei, Kunyu Peng, June Moh Goo, Jan Boehm, Rainer Stiefelhagen|<http://arxiv.org/pdf/2510.09035v1>|提出了一种针对LiDAR数据在噪声标签下的域泛化方法DuNe，提升了3D语义分割的鲁棒性。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Instance-Aware Robust Consistency Regularization for Semi-Supervised Nuclei Instance Segmentation|实例感知的稳健一致性正则化用于半监督核质实例分割|Zenan Lin, Wei Li, Jintao Chen, Zihao Wu, Wenxiong Kang, Changxin Gao, Liansheng Wang, Jin-Gang Yu|<http://arxiv.org/pdf/2510.09329v1>|提出了一种针对半监督核实例分割的Instance-Aware Robust Consistency ...|
|📝 更新|EMedNeXt: An Enhanced Brain Tumor Segmentation Framework for Sub-Saharan Africa using MedNeXt V2 with Deep Supervision|EMedNeXt：一种面向撒哈拉以南非洲的增强脑肿瘤分割框架，采用带有深度监督的MedNeXt V2|Ahmed Jaheen, Abdelrahman Elsayed, Damir Kim, Daniil Tikhonov, Matheus Scatolin, Mohor Banerjee, Qiankun Ji, Mostafa Salem .etc.|<http://arxiv.org/pdf/2507.23256v3>|针对撒哈拉以南非洲资源限制和图像质量退化问题，提出EMedNeXt框架，通过优化网络结构和模型融合显...|
|📝 更新|SkipClick: Combining Quick Responses and Low-Level Features for Interactive Segmentation in Winter Sports Contexts|“SkipClick：结合快速响应和低级特征在冬季运动场景中的交互式分割”|Robin Schön, Julian Lorenz, Daniel Kienzle, Rainer Lienhart|<http://arxiv.org/pdf/2501.07960v2>|提出了一种快速响应与低级特征结合的交互式分割架构，在冬季运动场景中实现了优于现有方法的分割性能。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vision Language Models: A Survey of 26K Papers|计算机视觉语言模型：26K篇论文的综述|Fengming Lin|<http://arxiv.org/pdf/2510.09586v1>|揭示了计算机视觉与语言模型融合的趋势，并分析了研究方法的演变。|
|📝 更新|Gaussian Scenes: Pose-Free Sparse-View Scene Reconstruction using Depth-Enhanced Diffusion Priors|高斯场景：基于深度增强扩散先验的无姿态稀疏视图场景重建|Soumava Paul, Prakhar Kaushik, Alan Yuille|<http://arxiv.org/pdf/2411.15966v3>|提出了一种无需相机参数的360度场景稀疏视图重建方法，通过深度增强扩散先验实现细节完整的3D场景重建...|
|📝 更新|Towards Sequence Modeling Alignment between Tokenizer and Autoregressive Model|面向序列建模的标记器与自回归模型对齐研究|Pingyu Wu, Kai Zhu, Yu Liu, Longxiang Tang, Jian Yang, Yansong Peng, Wei Zhai, Yang Cao .etc.|<http://arxiv.org/pdf/2506.05289v2>|[代码](https://github.com/ali-vilab/alitok.); 提出了一种新型对齐式分词器AliTok，通过改变依赖结构，提高了自回归模型在图像生成中的性能和速度。|
|🆕 发布|D-TPT: Dimensional Entropy Maximization for Calibrating Test-Time Prompt Tuning in Vision-Language Models|D-TPT: 视觉语言模型中测试时提示调校的维度熵最大化校准|Jisu Han, Wonjun Hwang|<http://arxiv.org/pdf/2510.09473v1>|提出了一种维数熵最大化方法，通过平衡文本特征分布，提高了视觉语言模型在测试时微调的校准性能。|
|📝 更新|What's Inside Your Diffusion Model? A Score-Based Riemannian Metric to Explore the Data Manifold|你的扩散模型里有什么？一种基于分数的黎曼度量来探索数据流形|Simone Azeglio, Arianna Di Bernardo|<http://arxiv.org/pdf/2505.11128v3>|提出了一种基于扩散模型得分函数的黎曼度量方法，揭示了数据流形的内在几何结构并优化了图像插值与外推效果...|
|📝 更新|Diffusion-based RGB-D Semantic Segmentation with Deformable Attention Transformer|基于扩散的RGB-D语义分割与可变形注意力变换器|Minh Bui, Kostas Alexis|<http://arxiv.org/pdf/2409.15117v3>|提出了一种基于扩散框架和可变形注意力变换器的RGB-D语义分割方法，实现了在挑战性场景下的稳健性能和...|
|🆕 发布|Foraging with the Eyes: Dynamics in Human Visual Gaze and Deep Predictive Modeling|《以眼觅食：人类视觉注视动态与深度预测建模》|Tejaswi V. Panchagnula|<http://arxiv.org/pdf/2510.09299v1>|揭示了人类视觉搜索遵循类似动物觅食的统计规律，并利用深度学习模型预测视觉关注区域。|
|📝 更新|SpatialSplat: Efficient Semantic 3D from Sparse Unposed Images|空间喷溅：从稀疏无定位图像中高效提取语义三维信息|Yu Sheng, Jiajun Deng, Xinran Zhang, Yu Zhang, Bei Hua, Yanyong Zhang, Jianmin Ji|<http://arxiv.org/pdf/2505.23044v2>|[代码](https://github.com/shengyuuu/SpatialSplat.git); 提出了一种高效的3D重建框架SpatialSplat，通过双场语义表示和选择性高斯机制减少冗余，提升...|
|📝 更新|G$^2$RPO: Granular GRPO for Precise Reward in Flow Models|G$^2$RPO：用于流模型精确奖励的细粒度GRPO|Yujie Zhou, Pengyang Ling, Jiazi Bu, Yibin Wang, Yuhang Zang, Jiaqi Wang, Li Niu, Guangtao Zhai|<http://arxiv.org/pdf/2510.01982v2>|提出了一种精确全面的奖励评估框架G$^2$RPO，通过细分探索步骤和聚合多尺度优势，提高了流模型中强...|
|📝 更新|RetouchLLM: Training-free Code-based Image Retouching with Vision Language Models|无需训练的基于视觉语言模型的代码式图像修饰：RetouchLLM|Moon Ye-Bin, Roy Miles, Tae-Hyun Oh, Ismail Elezi, Jiankang Deng|<http://arxiv.org/pdf/2510.08054v2>|提出了一种无需训练数据的图像修图方法RetouchLLM，通过可解释的代码直接对高分辨率图像进行多样...|
|📝 更新|One Stone with Two Birds: A Null-Text-Null Frequency-Aware Diffusion Models for Text-Guided Image Inpainting|一石二鸟：面向文本引导图像修复的零文本零频率感知扩散模型|Haipeng Liu, Yang Wang, Meng Wang|<http://arxiv.org/pdf/2510.08273v2>|[代码](https://github.com/htyjers/NTN-Diff.); 提出了一种频率感知的扩散模型NTN-Diff，通过分离不同频率带的语义一致性，同时保持未遮蔽区域，解...|
|📝 更新|DenseDPO: Fine-Grained Temporal Preference Optimization for Video Diffusion Models|密集DPO：针对视频扩散模型的细粒度时间偏好优化|Ziyi Wu, Anil Kag, Ivan Skorokhodov, Willi Menapace, Ashkan Mirzaei, Igor Gilitschenski, Sergey Tulyakov, Aliaksandr Siarohin|<http://arxiv.org/pdf/2506.03517v2>|提出DenseDPO方法，通过优化视频扩散模型中的时间偏好，减少运动偏差并提升生成质量。|
|🆕 发布|SAM2-3dMed: Empowering SAM2 for 3D Medical Image Segmentation|SAM2-3dMed：为SAM2赋予三维医学图像分割能力|Yeqing Yang, Le Xu, Lixia Tian|<http://arxiv.org/pdf/2510.08967v1>|提出SAM2-3dMed，通过引入切片相对位置预测和边界检测模块，有效提升3D医疗图像分割精度。|
|🆕 发布|Denoised Diffusion for Object-Focused Image Augmentation|去噪扩散用于对象聚焦的图像增强|Nisha Pillai, Aditi Virupakshaiah, Harrison W. Smith, Amanda J. Ashworth, Prasanna Gowda, Phillip R. Owens, Adam R. Rivers, Bindu Nanduri .etc.|<http://arxiv.org/pdf/2510.08955v1>|提出针对动物健康监测的数据增强框架，通过分割和扩散合成技术，有效提升数据稀缺场景下的动物检测性能。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Editable Noise Map Inversion: Encoding Target-image into Noise For High-Fidelity Image Manipulation|可编辑噪声图逆向：将目标图像编码入噪声以实现高保真图像操作|Mingyu Kang, Yong Suk Choi|<http://arxiv.org/pdf/2509.25776v2>|提出了一种可编辑噪声图反转方法，实现了高保真图像编辑与文本提示的精准匹配。|
|📝 更新|MorphGen: Controllable and Morphologically Plausible Generative Cell-Imaging|形态生成器：可控且形态上合理的生成性细胞成像|Berker Demirel, Marco Fumero, Theofanis Karaletsos, Francesco Locatello|<http://arxiv.org/pdf/2510.01298v2>|[代码](https://github.com/czi-ai/MorphGen.); 提出MorphGen模型，通过生成荧光显微镜图像实现细胞形态的可控模拟，提高药物发现和基因编辑的效率...|
|📝 更新|Brain2Text Decoding Model Reveals the Neural Mechanisms of Visual Semantic Processing|脑到文本解码模型揭示了视觉语义处理的神经机制|Feihan Feng, Jingxin Nie|<http://arxiv.org/pdf/2503.22697v2>|提出了一种无需视觉信息训练的深度学习模型，实现了fMRI信号到图像文本描述的直接解码，揭示了视觉语义...|
|📝 更新|DeHate: A Stable Diffusion-based Multimodal Approach to Mitigate Hate Speech in Images|《DeHate：一种基于稳定扩散的多模态方法减轻图像中的仇恨言论》|Dwip Dalal, Gautam Vashishtha, Anku Rani, Aishwarya Reganti, Parth Patwa, Mohd Sarique, Chandan Gupta, Keshav Nath .etc.|<http://arxiv.org/pdf/2509.21787v2>|提出了一种结合稳定扩散技术和数字注意力分析模块的多模态方法，用于检测并消除图像中的仇恨内容。|
|🆕 发布|Towards Better & Faster Autoregressive Image Generation: From the Perspective of Entropy|面向更优更快自回归图像生成：从熵的角度出发|Xiaoxiao Ma, Feng Zhao, Pengyang Ling, Haibo Qiu, Zhixiang Wei, Hu Yu, Jie Huang, Zhixiong Zeng .etc.|<http://arxiv.org/pdf/2510.09012v1>|提出熵指导的解码策略，提升自回归图像生成质量并加快合成速度。|
|📝 更新|TTS-VAR: A Test-Time Scaling Framework for Visual Auto-Regressive Generation|测试时缩放框架：用于视觉自回归生成的TTS-VAR|Zhekai Chen, Ruihang Chu, Yukang Chen, Shiwei Zhang, Yujie Wei, Yingya Zhang, Xihui Liu|<http://arxiv.org/pdf/2507.18537v2>|[代码](https://github.com/ali-vilab/TTS-VAR.); 提出了一种测试时扩展框架TTS-VAR，通过自适应批处理和多样性搜索优化视觉自动回归模型的生成质量。|
|🆕 发布|Speculative Jacobi-Denoising Decoding for Accelerating Autoregressive Text-to-image Generation|speculative 可译为“猜测性的”或“推测性的”，但在计算机视觉领域，此类术语通常保持原样以保持专业性。Jacobi-Denoising Decoding 可译为“雅可比去噪解码”，Autoregressive Text-to-image Generation 可译为“自回归文本到图像生成”。因此，整个标题可翻译为：  “加速自回归文本到图像生成的猜测性雅可比去噪解码”|Yao Teng, Fuyun Wang, Xian Liu, Zhekai Chen, Han Shi, Yu Wang, Zhenguo Li, Weiyang Liu .etc.|<http://arxiv.org/pdf/2510.08994v1>|提出了一种并行生成策略，通过将去噪过程融入迭代解码，大幅提升了文本到图像生成模型的推理效率。|
|📝 更新|The Role of Video Generation in Enhancing Data-Limited Action Understanding|视频生成在提升数据受限动作理解中的作用|Wei Li, Dezhao Luo, Dongbao Yang, Zhenhang Li, Weiping Wang, Yu Zhou|<http://arxiv.org/pdf/2505.19495v2>|利用文本到视频的扩散变换器生成标注数据，解决了数据受限的动作理解问题，实现了零样本动作识别的领先性能...|
|📝 更新|Deep Learning for Sports Video Event Detection: Tasks, Datasets, Methods, and Challenges|深度学习在体育视频事件检测中的应用：任务、数据集、方法与挑战|Hao Xu, Arbind Agrahari Baniya, Sam Well, Mohamed Reda Bouadjenek, Richard Dazeley, Sunil Aryal|<http://arxiv.org/pdf/2505.03991v3>|系统梳理了体育视频事件检测任务，提出了针对性的方法分类和评估标准，助力精确事件定位研究。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TC-LoRA: Temporally Modulated Conditional LoRA for Adaptive Diffusion Control|TC-LoRA：时间调制条件LoRA用于自适应扩散控制|Minkyoung Cho, Ruben Ohana, Christian Jacobsen, Adityan Jothi, Min-Hung Chen, Z. Morley Mao, Ethem Can|<http://arxiv.org/pdf/2510.09561v1>|提出了一种动态调整模型权重的TC-LoRA方法，实现了更精准的生成控制和提高了生成质量。|
|📝 更新|Solving Inverse Problems with FLAIR|用FLAIR解决反问题|Julius Erbach, Dominik Narnhofer, Andreas Dombos, Bernt Schiele, Jan Eric Lenssen, Konrad Schindler|<http://arxiv.org/pdf/2506.02680v2>|[代码](https://inverseflair.github.io/.); 提出了一种无训练的变分框架FLAIR，利用基于流的生成模型作为先验解决逆成像问题，提高了重建质量和样...|
|🆕 发布|Few-shot multi-token DreamBooth with LoRa for style-consistent character generation|少量样本多标记DreamBooth结合LoRa实现风格一致的字符生成|Ruben Pascual, Mikel Sesma-Sara, Aranzazu Jurio, Daniel Paternain, Mikel Galar|<http://arxiv.org/pdf/2510.09475v1>|提出了一种多标记DreamBooth与LoRa结合的方法，实现了少量样本下风格一致的字符生成。|
|📝 更新|The 1st Solution for CARE Liver Task Challenge 2025: Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation|2025年CARE肝脏任务挑战第一名解决方案：具有域泛化与测试时适应性的对比感知半监督分割|Jincan Lou, Jingkun Chen, Haoquan Li, Hang Li, Wenjian Huang, Weihua Chen, Fan Wang, Jianguo Zhang|<http://arxiv.org/pdf/2510.04243v2>|提出了一种结合半监督学习和域自适应的肝脏分割框架，有效应对数据不足和域偏移挑战。|
|🆕 发布|Identifying & Interactively Refining Ambiguous User Goals for Data Visualization Code Generation|识别与交互式细化数据可视化代码生成的模糊用户目标|Mert İnan, Anthony Sicilia, Alex Xie, Saujas Vaduguru, Daniel Fried, Malihe Alikhani|<http://arxiv.org/pdf/2510.09390v1>|提出了一种用于数据可视化代码生成的多轮对话策略，有效减少歧义并提高代码准确性。|
|🆕 发布|RadioFlow: Efficient Radio Map Construction Framework with Flow Matching|RadioFlow：基于流匹配的无线电地图高效构建框架|Haozhe Jia, Wenshuo Chen, Xiucheng Wang, Nan Cheng, Hongbo Zhang, Kuimou Yu, Songning Lai, Nanjian Jia .etc.|<http://arxiv.org/pdf/2510.09314v1>|[代码](https://github.com/Hxxxz0/RadioFlow); 提出RadioFlow框架，通过流匹配实现高效的单步采样，生成高质量无线电地图，减少参数量并加快推理...|
|📝 更新|Robustness in Both Domains: CLIP Needs a Robust Text Encoder|两个域中的鲁棒性：CLIP需要一个鲁棒的文本编码器|Elias Abad Rocamora, Christian Schlarmann, Naman Deep Singh, Yongtao Wu, Matthias Hein, Volkan Cevher|<http://arxiv.org/pdf/2506.03355v2>|[代码](https://github.com/LIONS-EPFL/LEAF); 提出了一种针对CLIP文本编码器的有效对抗性微调方法，显著提升了零样本对抗性准确度并保持视觉性能。|
|📝 更新|SQ-GAN: Semantic Image Communications Using Masked Vector Quantization|SQ-GAN:基于掩码向量量化的语义图像通信|Francesco Pezone, Sergio Barbarossa, Giuseppe Caire|<http://arxiv.org/pdf/2502.09520v2>|提出SQ-GAN方法，通过语义驱动的图像编码和向量量化优化图像压缩，提升任务导向通信的性能。|
|📝 更新|DiffMark: Diffusion-based Robust Watermark Against Deepfakes|_diffusion-based鲁棒水印技术对抗深度伪造的DiffMark_|Chen Sun, Haiyang Sun, Zhiqing Guo, Yunfeng Diao, Liejun Wang, Dan Ma, Gaobo Yang, Keqin Li|<http://arxiv.org/pdf/2507.01428v2>|[代码](https://github.com/vpsg-research/DiffMark.); 提出基于扩散模型的DiffMark水印框架，有效抵抗Deepfake攻击，增强图像真实性验证。|
|🆕 发布|Stable Video Infinity: Infinite-Length Video Generation with Error Recycling|稳定视频无限：带误差回收的无限长度视频生成|Wuyang Li, Wentao Pan, Po-Chien Luan, Yang Gao, Alexandre Alahi|<http://arxiv.org/pdf/2510.09212v1>|提出了一种无限时长视频生成方法SVI，通过错误循环训练有效解决视频生成中的误差累积问题，实现高一致性...|
|🆕 发布|Dense2MoE: Restructuring Diffusion Transformer to MoE for Efficient Text-to-Image Generation|密集2模块：将扩散变换器重构为模块化结构以实现高效文本到图像生成|Youwei Zheng, Yuxi Ren, Xin Xia, Xuefeng Xiao, Xiaohua Xie|<http://arxiv.org/pdf/2510.09094v1>|将密集型Diffusion Transformer转化为Mixture of Experts结构，实...|
|🆕 发布|MMAudioSep: Taming Video-to-Audio Generative Model Towards Video/Text-Queried Sound Separation|MMAudioSep：面向视频/文本查询声音分离的视频至音频生成模型的驯化|Akira Takahashi, Shusuke Takahashi, Yuki Mitsufuji|<http://arxiv.org/pdf/2510.09065v1>|[代码](https://github.com/sony/mmaudiosep.); 提出MMAudioSep模型，利用预训练视频到音频生成模型和音频生成模型知识，实现视频/文本查询声音...|
|🆕 发布|OSCAR: Orthogonal Stochastic Control for Alignment-Respecting Diversity in Flow Matching|OSCAR：正交随机控制以保持流匹配中对齐尊重的多样性|Jingxuan Wu, Zhenglin Wan, Xingrui Yu, Yuzhe Yang, Bo An, Ivor Tsang|<http://arxiv.org/pdf/2510.09060v1>|引入正交随机控制机制以增强文本到图像生成的多样性，同时保持图像质量不变。|
|📝 更新|Improving Image Captioning Descriptiveness by Ranking and LLM-based Fusion|通过排序和基于大型语言模型的融合提高图像描述的详尽性|Luigi Celona, Simone Bianco, Marco Donzella, Paolo Napoletano|<http://arxiv.org/pdf/2306.11593v3>|提出了一种融合多模型生成和大型语言模型优化技术的图像描述方法，有效提升了图像描述的丰富性和准确性。|
|📝 更新|TBStar-Edit: From Image Editing Pattern Shifting to Consistency Enhancement|TBStar-Edit：从图像编辑模式转换到一致性增强|Hao Fang, Zechao Zhan, Weixin Feng, Ziwei Huang, Xubin Li, Tiezheng Ge|<http://arxiv.org/pdf/2510.04483v2>|提出了针对电商领域的TBStar-Edit图像编辑模型，通过数据工程和模型设计实现了精确编辑和一致性...|
|🆕 发布|Hierarchical Scheduling for Multi-Vector Image Retrieval|多矢量图像检索的层次调度策略|Maoliang Li, Ke Li, Yaoyang Liu, Jiayu Chen, Zihao Zheng, Yinjun Wu, Xiang Chen|<http://arxiv.org/pdf/2510.08976v1>|提出了一种分层调度框架HiMIR，通过多级粒度对齐和减少冗余匹配，显著提升了图像检索的准确性和效率。|
|🆕 发布|HandEval: Taking the First Step Towards Hand Quality Evaluation in Generated Images|《HandEval：迈向生成图像中手部质量评估的第一步》|Zichuan Wang, Bo Peng, Songlin Yang, Zhenchen Tang, Jing Dong|<http://arxiv.org/pdf/2510.08978v1>|提出首个针对生成图像中手部质量评估的任务和模型HandEval，提高了手部图像质量评估的准确性并优化...|
|📝 更新|RAGDiffusion: Faithful Cloth Generation via External Knowledge Assimilation|RAGDiffusion：通过外部知识同化实现逼真布料生成的算法|Xianfeng Tan, Yuhan Li, Wenxiang Shang, Yubo Wu, Jian Wang, Xuanhong Chen, Yi Zhang, Ran Lin .etc.|<http://arxiv.org/pdf/2411.19528v3>|提出 Retrieval-Augmented Generation 框架 RAGDiffusion，...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Biophysically-Conditioned Generative Framework for 3D Brain Tumor MRI Synthesis|生物物理约束下的三维脑肿瘤MRI生成模型框架|Valentin Biller, Lucas Zimmer, Can Erdur, Sandeep Nagar, Daniel Rückert, Niklas Bubeck, Jonas Weidner|<http://arxiv.org/pdf/2510.09365v1>|[代码](https://github.com/valentin-biller/ldm.git); 首次提出基于连续肿瘤浓度的生成模型，实现了高质量的3D脑肿瘤MRI合成与修复。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CAPE: A CLIP-Aware Pointing Ensemble of Complementary Heatmap Cues for Embodied Reference Understanding|CAPE：一种面向具身参考理解的CLIP感知互补热图线索指针集成方法|Fevziye Irem Eyiokur, Dogucan Yaman, Hazım Kemal Ekenel, Alexander Waibel|<http://arxiv.org/pdf/2507.21888v2>|提出了一种结合头部和手腕指向线索的模型框架，通过CLIP-Aware Pointing Ensemb...|
|🆕 发布|Mono4DEditor: Text-Driven 4D Scene Editing from Monocular Video via Point-Level Localization of Language-Embedded Gaussians|单目视频中的文本驱动四维场景编辑：通过嵌入语言的高斯分布点级定位|Jin-Chuan Shi, Chengye Su, Jiajun Wang, Ariel Shamir, Miao Wang|<http://arxiv.org/pdf/2510.09438v1>|提出了一种基于文本提示的4D场景编辑框架，通过点级定位实现精确语义编辑，同时保持场景完整性。|
|🆕 发布|Hybrid-grained Feature Aggregation with Coarse-to-fine Language Guidance for Self-supervised Monocular Depth Estimation|混合粒度特征聚合与粗到细语言引导的自监督单目深度估计|Wenyao Zhang, Hongsi Liu, Bohan Li, Jiawei He, Zekun Qi, Yunnan Wang, Shengyang Zhao, Xinqiang Yu .etc.|<http://arxiv.org/pdf/2510.09320v1>|[代码](https://github.com/Zhangwenyao1/Hybrid-depth.); 提出了一种融合粗到细语言指导的视觉先验提取框架，显著提升了自监督单目深度估计性能。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SMF: Template-free and Rig-free Animation Transfer using Kinetic Codes|SMF：无需模板和无约束的动作用动能编码进行转移|Sanjeev Muralikrishnan, Niladri Shekhar Dutt, Niloy J. Mitra|<http://arxiv.org/pdf/2504.04831v2>|提出无需模板或骨架的自监督运动场方法，通过动能码实现高效运动转移和形状适应。|
|📝 更新|Learning Neural Exposure Fields for View Synthesis|学习神经曝光场以实现视图合成|Michael Niemeyer, Fabian Manhardt, Marie-Julie Rakotosaona, Michael Oechsle, Christina Tsalicoglou, Keisuke Tateno, Jonathan T. Barron, Federico Tombari|<http://arxiv.org/pdf/2510.08279v2>|提出了一种学习三维场景曝光场的神经场方法，实现了高动态范围场景的高质量三维重建和视图合成。|
|📝 更新|TARO: Timestep-Adaptive Representation Alignment with Onset-Aware Conditioning for Synchronized Video-to-Audio Synthesis|TARO：基于时间步长自适应表示对齐与起始感知条件同步的视频到音频合成|Tri Ton, Ji Woo Hong, Chang D. Yoo|<http://arxiv.org/pdf/2504.05684v3>|提出了一种视频音频同步合成的新框架TARO，通过动态调整表示对齐和整合视觉事件起止线索，实现了高保真...|
|🆕 发布|3D Reconstruction from Transient Measurements with Time-Resolved Transformer|从瞬态测量中结合时间解析变换器进行三维重建|Yue Li, Shida Sun, Yu Hong, Feihu Xu, Zhiwei Xiong|<http://arxiv.org/pdf/2510.09205v1>|[代码](https://github.com/Depth2World/TRT.); 提出了一种Time-Resolved Transformer架构，通过优化注意力机制显著提升了低光效...|


### 单视图三维推理 (Single-view 3D Inference)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Online Video Depth Anything: Temporally-Consistent Depth Prediction with Low Memory Consumption|在线视频深度任意：具有低内存消耗的时间一致性深度预测|Johann-Friedrich Feiden, Tim Küchler, Denis Zavadski, Bogdan Savchynskyy, Carsten Rother|<http://arxiv.org/pdf/2510.09182v1>|提出在线视频深度估计方法oVDA，通过缓存特征和遮蔽技术降低内存消耗，实现高效深度预测。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dynamic Weight-based Temporal Aggregation for Low-light Video Enhancement|基于动态权重的低光照视频增强时域聚合方法|Ruirui Lin, Guoxi Huang, Nantheera Anantrasirichai|<http://arxiv.org/pdf/2510.09450v1>|提出了一种两阶段框架DWTA-Net，通过动态权重聚合时间信息有效提升低光照视频质量。|
|📝 更新|HoliTom: Holistic Token Merging for Fast Video Large Language Models|《HoliTom：整体标记融合以加速视频大型语言模型》|Kele Shao, Keda Tao, Can Qin, Haoxuan You, Yang Sui, Huan Wang|<http://arxiv.org/pdf/2505.21334v3>|提出了一种全局时序分割与空间时序融合的 holistic token merging 方法，大幅降低...|
|📝 更新|TimeScope: Towards Task-Oriented Temporal Grounding In Long Videos|时间视野：面向任务的长时间视频中的时间定位|Xiangrui Liu, Minghao Qin, Yan Shu, Zhengyang Liang, Yang Tian, Chen Jason Zhang, Bo Zhao, Zheng Liu|<http://arxiv.org/pdf/2509.26360v2>|提出任务导向的时间定位方法TimeScope，有效识别长视频中的关键时间区间。|
|🆕 发布|MomentSeg: Moment-Centric Sampling for Enhanced Video Pixel Understanding|基于矩中心的采样增强视频像素理解的MomentSeg|Ming Dai, Sen Yang, Boqiang Duan, Wankou Yang, Jingdong Wang|<http://arxiv.org/pdf/2510.09274v1>|[代码](https://github.com/Dmmm1997/MomentSeg); 提出了一种基于关键时刻采样的视频像素理解框架，通过结合时间句子定位和视频对象分割，提高了视觉理解的准...|
|🆕 发布|Towards Safer and Understandable Driver Intention Prediction|面向更安全且可理解的驾驶员意图预测|Mukilan Karuppasamy, Shankar Gangisetty, Shyam Nandan Rai, Carlo Masone, C V Jawahar|<http://arxiv.org/pdf/2510.09200v1>|[代码](https://mukil07.github.io/VCBM.github.io); 提出 interpretable DIP 任务，并引入 DAAD-X 数据集和 Video Conc...|
|🆕 发布|RO-Bench: Large-scale robustness evaluation of MLLMs with text-driven counterfactual videos|RO-Bench：大规模评估文本驱动反事实视频下多模态大型语言模型的鲁棒性|Zixi Yang, Jiapeng Li, Muxi Diao, Yinuo Jing, Kongming Liang|<http://arxiv.org/pdf/2510.08936v1>|提出了Ro-Bench，首个用于评估多模态大语言模型在动态非分布外视频内容上的鲁棒性的基准，并通过对...|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Contour Errors: An Ego-Centric Metric for Reliable 3D Multi-Object Tracking|轮廓误差：一种用于可靠三维多目标跟踪的自我中心度量方法|Sharang Kaul, Mario Berk, Thiemo Gerbich, Abhinav Valada|<http://arxiv.org/pdf/2506.04122v2>|提出Contour Errors ego-centric度量，提高3D多目标跟踪在复杂场景中的匹配可...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Diagnosing Shoulder Disorders Using Multimodal Large Language Models and Consumer-Grade Cameras|使用多模态大型语言模型和消费级相机诊断肩部疾病|Jindong Hong, Wencheng Zhang, Shiqin Qiao, Jianhai Chen, Jianing Qiu, Chuanyang Zheng, Qian Xu, Yun Ji .etc.|<http://arxiv.org/pdf/2510.09230v1>|提出了一种利用消费级相机和多功能大型语言模型进行肩部疾病初步诊断的低成本框架，显著提升了诊断准确性。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment|MOCHA：多模态物体感知跨架构对齐|Elena Camuffo, Francesco Barbato, Mete Ozay, Simone Milani, Umberto Michieli|<http://arxiv.org/pdf/2509.14001v3>|MOCHA通过对象级知识蒸馏，将大型视觉-语言模型的多模态语义有效转移到轻量级视觉检测器，实现性能提...|


### 掩码自编码 (Masked Autoencoding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MultiMAE for Brain MRIs: Robustness to Missing Inputs Using Multi-Modal Masked Autoencoder|多模态遮蔽自动编码器用于脑部磁共振成像：对缺失输入的鲁棒性|Ayhan Can Erdur, Christian Beischl, Daniel Scholz, Jiazhen Pan, Benedikt Wiestler, Daniel Rueckert, Jan C Peeken|<http://arxiv.org/pdf/2509.11442v2>|提出了一种多模态掩码自编码器，通过跨序列推理有效处理脑部MRI图像中缺失的输入序列。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|STaTS: Structure-Aware Temporal Sequence Summarization via Statistical Window Merging|STaTS：基于统计窗口合并的结构感知时间序列摘要|Disharee Bhowmick, Ranjith Ramanathan, Sathyanarayanan N. Aakur|<http://arxiv.org/pdf/2510.09593v1>|提出了一种自适应压缩时间序列数据的方法STaTS，通过统计窗口合并有效保留核心时序动态，提升模型效率...|
|📝 更新|ProbRes: Probabilistic Jump Diffusion for Open-World Egocentric Activity Recognition|《ProbRes：面向开放世界自我中心活动识别的概率跳跃扩散》|Sanjoy Kundu, Shanmukha Vellamcheti, Sathyanarayanan N. Aakur|<http://arxiv.org/pdf/2504.03948v2>|提出ProbRes框架，通过概率性残差搜索高效识别开放世界中的第一视角活动。|
|🆕 发布|Diagonal Artifacts in Samsung Images: PRNU Challenges and Solutions|三星图像中的对角线伪影：PRNU挑战与解决方案|David Vázquez-Padín, Fernando Pérez-González, Alejandro Martín-Del-Río|<http://arxiv.org/pdf/2510.09509v1>|揭示了三星手机图像中的对角线伪影问题，并提出利用原始图像进行相机源验证的解决方案。|
|🆕 发布|Minkowski-MambaNet: A Point Cloud Framework with Selective State Space Models for Forest Biomass Quantification|闵可夫斯基-曼巴网：一种基于选择性状态空间模型的点云框架，用于森林生物量量化|Jinxiang Tu, Dayong Ren, Fei Shi, Zhenhong Jia, Yahong Ren, Jiwei Qin, Fang He|<http://arxiv.org/pdf/2510.09367v1>|提出了一种结合选择性状态空间模型的点云框架，有效提升了森林生物量测量的准确性和鲁棒性。|
|🆕 发布|Boosting Multi-modal Keyphrase Prediction with Dynamic Chain-of-Thought in Vision-Language Models|提升视觉语言模型中多模态关键词预测的动态思维链方法|Qihang Ma, Shengyu Li, Jie Tang, Dingkang Yang, Shaodong Chen, Yingyi Zhang, Chao Feng, Jiao Ran|<http://arxiv.org/pdf/2510.09358v1>|[代码](https://github.com/bytedance/DynamicCoT.); 提出利用视觉语言模型提升多模态关键词预测，引入动态思维链策略增强推理能力。|
|📝 更新|Mem4Nav: Boosting Vision-and-Language Navigation in Urban Environments with a Hierarchical Spatial-Cognition Long-Short Memory System|Mem4Nav：利用分层空间认知长短时记忆系统提升城市环境下的视觉-语言导航性能|Lixuan He, Haoyu Dong, Zhenxing Chen, Yangcheng Yu, Jie Feng, Yong Li|<http://arxiv.org/pdf/2506.19433v2>|[代码](https://github.com/tsinghua-fib-lab/Mem4Nav.); Mem4Nav通过引入层级空间认知长短期记忆系统，有效融合视觉与语言导航，增强大型城市环境中的实时避...|
|🆕 发布|Visibility-Aware Densification for 3D Gaussian Splatting in Dynamic Urban Scenes|动态城市场景中考虑可见性的三维高斯散点加密|Yikang Zhang, Rui Fan|<http://arxiv.org/pdf/2510.09364v1>|提出VAD-GS框架，通过可见性分析和多视角重建改善动态城市场景中的3D重建质量。|
|🆕 发布|Goal-oriented Backdoor Attack against Vision-Language-Action Models via Physical Objects|面向视觉-语言-动作模型的通过物理对象的目标导向后门攻击|Zirun Zhou, Zhengyang Xiao, Haochuan Xu, Jing Sun, Di Wang, Jingfeng Zhang|<http://arxiv.org/pdf/2510.09269v1>|[代码](https://goba-attack.github.io/.); 提出针对视觉语言动作模型的新型物理对象触发后门攻击方法，实现特定目标导向行为而不影响正常性能。|
|🆕 发布|Online Topological Localization for Navigation Assistance in Bronchoscopy|支气管镜导航辅助的在线拓扑定位|Clara Tomasini, Luis Riazuelo, Ana C. Murillo|<http://arxiv.org/pdf/2510.09144v1>|提出了一种无需患者CT扫描的图像基于支气管镜拓扑定位方法，有效辅助手术导航。|
|🆕 发布|MambaH-Fit: Rethinking Hyper-surface Fitting-based Point Cloud Normal Estimation via State Space Modelling|MambaH-Fit：通过状态空间建模重新思考基于超表面拟合的点云法线估计|Weijia Wang, Yuanzhi Su, Pei-Gen Ye, Yuan-Gen Wang, Xuequan Lu|<http://arxiv.org/pdf/2510.09088v1>|提出了一种基于状态空间模型和注意力驱动的点云法线估计方法，有效捕捉了局部几何细节，提升了预测准确性。|
|🆕 发布|Uncolorable Examples: Preventing Unauthorized AI Colorization via Perception-Aware Chroma-Restrictive Perturbation|不可着色示例：通过感知感知色度限制扰动防止未经授权的AI着色|Yuki Nii, Futa Waseda, Ching-Chun Chang, Isao Echizen|<http://arxiv.org/pdf/2510.08979v1>|提出防御范式“Uncolorable Examples”，通过在灰度图像中嵌入不可见扰动防止非法AI...|
|📝 更新|UltraSeP: Sequence-aware Pre-training for Echocardiography Probe Movement Guidance|《UltraSeP：面向超声心动图探头运动引导的序列感知预训练》|Haojun Jiang, Teng Wang, Zhenguo Sun, Yulin Wang, Yang Yue, Yu Sun, Ning Jia, Meng Li .etc.|<http://arxiv.org/pdf/2408.15026v3>|提出了序列感知的自监督预训练方法，用于个性化心脏结构学习，有效减少超声探头引导误差。|
|🆕 发布|Defense against Unauthorized Distillation in Image Restoration via Feature Space Perturbation|通过特征空间扰动防御图像恢复中的未授权蒸馏攻击|Han Hu, Zhuoran Zheng, Chen Lyu|<http://arxiv.org/pdf/2510.08925v1>|提出了一种针对图像恢复模型的防御方法，通过特征空间扰动有效阻止了非法知识蒸馏。|
|📝 更新|Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants|基于逐层冻结的站点级微调：面向在极早早产儿第一天胸部X射线中稳健预测支气管肺发育不良|Sybelle Goedicke-Fritz, Michelle Bous, Annika Engel, Matthias Flotho, Pascal Hirsch, Hannah Wittig, Dino Milanovic, Dominik Mohr .etc.|<http://arxiv.org/pdf/2507.12269v3>|提出了一种针对极低出生体重婴儿的BPD预测方法，通过特定领域预训练和渐进式层冻结提升准确性和可行性。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FLOWING: Implicit Neural Flows for Structure-Preserving Morphing|流动：用于结构保持形变的隐式神经流方法|Arthur Bizzi, Matias Grynberg, Vitor Matias, Daniel Perazzo, João Paulo Lima, Luiz Velho, Nuno Gonçalves, João Pereira .etc.|<http://arxiv.org/pdf/2510.09537v1>|[代码](http://schardong.github.io/flowing.); 提出了一种基于微分向量流的FLOWING框架，实现了稳定且结构保真的图像与形状变形。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Flattery in Motion: Benchmarking and Analyzing Sycophancy in Video-LLMs|动态奉承：在视频大型语言模型中评估和分析谄媚行为|Wenrui Zhou, Mohamed Hendy, Shu Yang, Qingsong Yang, Zikun Guo, Yuyu Luo, Lijie Hu, Di Wang|<http://arxiv.org/pdf/2506.07180v2>|[代码](https://github.com/William030422/Video-Sycophancy.); 提出首个视频大语言模型奉承行为评估基准，并探索了两种无需训练的缓解策略。|
|🆕 发布|Enhancing Infrared Vision: Progressive Prompt Fusion Network and Benchmark|增强红外视觉：渐进式提示融合网络与基准测试|Jinyuan Liu, Zihang Chen, Zhu Liu, Zhiying Jiang, Long Ma, Xin Fan, Risheng Liu|<http://arxiv.org/pdf/2510.09343v1>|[代码](https://github.com/Zihang-Chen/HM-TIR.); 提出了一种针对热红外图像增强的渐进提示融合网络，有效处理多种图像退化问题并显著提升图像质量。|
|🆕 发布|Tag-Enriched Multi-Attention with Large Language Models for Cross-Domain Sequential Recommendation|跨域序列推荐中结合大型语言模型的标签增强多注意力机制|Wangyu Wu, Xuhang Chen, Zhenhong Chen, Jing-En Jiang, Kim-Fung Tsang, Xiaowei Huang, Fei Ma, Jimin Xiao|<http://arxiv.org/pdf/2510.09224v1>|提出了一种融合大型语言模型和标签增强多注意力机制的跨域序列推荐框架，有效提升了个性化推荐系统的准确性...|
|🆕 发布|Polar Separable Transform for Efficient Orthogonal Rotation-Invariant Image Representation|极坐标可分离变换用于高效正交旋转不变图像表示|Satya P. Singh, Rashmi Chaudhry, Anand Srivastava, Jagath C. Rajapakse|<http://arxiv.org/pdf/2510.09125v1>|提出了一种极坐标分离正交变换方法，大幅降低了图像处理中的计算复杂度和提高了数值稳定性。|
|📝 更新|Post-training quantization of vision encoders needs prefixing registers|训练后视觉编码器的量化需要前缀寄存器|Seunghyeon Kim, Jinho Kim, Taesun Yeom, Wonpyo Park, Kyuyeun Kim, Jaeho Lee|<http://arxiv.org/pdf/2510.04547v2>|提出了一种无训练算法RegCache，通过引入前缀标记减少视觉编码器中的异常值，实现量化后的模型精度...|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Efficient Bayesian Inference from Noisy Pairwise Comparisons|从带噪声的双样本比较中进行高效贝叶斯推断|Till Aczel, Lucas Theis, Wattenhofer Roger|<http://arxiv.org/pdf/2510.09333v1>|提出了一种考虑评价者质量的贝叶斯Bradley-Terry模型，有效提升了从带噪声的成对比较中进行鲁...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Covariances for Free: Exploiting Mean Distributions for Training-free Federated Learning|"免费协方差：利用均值分布进行无需训练的联邦学习"|Dipam Goswami, Simone Magistri, Kai Wang, Bartłomiej Twardowski, Andrew D. Bagdanov, Joost van de Weijer|<http://arxiv.org/pdf/2412.14326v3>|[代码](https://github.com/dipamgoswami/FedCOF.); 提出了一种无需训练的联邦学习方法，通过仅使用类别均值估计类协方差矩阵，有效提高了初始化性能并降低了通...|
|📝 更新|AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance|AMFT：通过元学习优化模仿-探索平衡来对齐大型语言模型推理器|Lixuan He, Jie Feng, Yong Li|<http://arxiv.org/pdf/2508.06944v3>|[代码](https://github.com/hlxtsyj/AMFT.); 提出了一种自适应元微调算法，动态平衡语言模型训练中的模仿与探索，实现了推理任务的新突破。|
|🆕 发布|Auto-scaling Continuous Memory for GUI Agent|自动调整连续内存以适应GUI智能体|Wenyi Wu, Kun Zhou, Ruoxin Yuan, Vivian Yu, Stephen Wang, Zhiting Hu, Biwei Huang|<http://arxiv.org/pdf/2510.09038v1>|提出连续记忆机制，通过固定长度连续嵌入编码GUI轨迹，提升界面操作代理在长时任务和陌生界面上的泛化能...|


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bi-level Meta-Policy Control for Dynamic Uncertainty Calibration in Evidential Deep Learning|双层次元策略控制用于证据深度学习中的动态不确定性校准|Zhen Yang, Yansong Ma, Lei Chen|<http://arxiv.org/pdf/2510.08938v1>|提出了一种动态元学习框架Meta-Policy Controller，通过调整KL散度系数和Diri...|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SegTrans: Transferable Adversarial Examples for Segmentation Models|SegTrans: 用于分割模型的可迁移对抗性示例|Yufei Song, Ziqi Zhou, Qi Lu, Hangtao Zhang, Yifan Hu, Lulu Xue, Shengshan Hu, Minghui Li .etc.|<http://arxiv.org/pdf/2510.08922v1>|提出SegTrans框架，通过局部语义信息优化扰动，提高对抗样本在不同分割模型间的迁移性。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Understanding Ice Crystal Habit Diversity with Self-Supervised Learning|理解自监督学习在冰晶习性多样性中的应用|Joseph Ko, Hariprasath Govindarajan, Fredrik Lindsten, Vanessa Przybylo, Kara Sulia, Marcus van Lier-Walqui, Kara Lamb|<http://arxiv.org/pdf/2509.07688v2>|利用自监督学习学习冰晶形态的潜在表征，有效量化冰晶多样性并改善气候系统建模。|
|🆕 发布|Dyna-Mind: Learning to Simulate from Experience for Better AI Agents|动态思维：从经验中学习模拟以打造更优秀的AI代理|Xiao Yu, Baolin Peng, Michel Galley, Hao Cheng, Qianhui Wu, Janardhan Kulkarni, Suman Nath, Zhou Yu .etc.|<http://arxiv.org/pdf/2510.09577v1>|提出Dyna-Mind框架，通过模拟未来情景提升AI在复杂交互环境中的理解和决策能力。|
|📝 更新|Continual Adapter Tuning with Semantic Shift Compensation for Class-Incremental Learning|持续适配器调整与语义偏移补偿的类增量学习|Qinhao Zhou, Yuwen Tan, Boqing Gong, Xiang Xiang|<http://arxiv.org/pdf/2403.19979v2>|提出了一种无需参数扩展且避免样本保留的持续学习策略，通过自适应器和原型更新实现类增量学习中的语义漂移...|
|🆕 发布|Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study|现代深度学习技术在板球击球分类中的应用：一项全面的基线研究|Sungwoo Kang|<http://arxiv.org/pdf/2510.09187v1>|对比七种深度学习模型在板球击球分类中的应用，发现现代架构和优化显著提升性能。|
|📝 更新|Frequency-Aware Ensemble Learning for BraTS 2025 Pediatric Brain Tumor Segmentation|频率感知集成学习用于 BraTS 2025 儿童脑肿瘤分割|Yuxiao Yi, Qingyao Zhuang, Zhi-Qin John Xu, Xiaowen Wang, Yan Ren, Tianming Qiu|<http://arxiv.org/pdf/2509.19353v3>|提出了一种集成学习方法，通过调整初始化规模、迁移学习和频率域分解，有效提升了儿童脑肿瘤分割的准确性。|
|🆕 发布|PHyCLIP: $\ell_1$-Product of Hyperbolic Factors Unifies Hierarchy and Compositionality in Vision-Language Representation Learning|PHyCLIP：双曲因子$\ell_1$-乘积在视觉语言表征学习中统一层次性与组合性|Daiki Yoshikawa, Takashi Matsubara|<http://arxiv.org/pdf/2510.08919v1>|提出了一种结合双曲空间与特定度量方法的新模型，有效平衡视觉语言模型中的层次性与组合性。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|StreamingVLM: Real-Time Understanding for Infinite Video Streams|流式VLM：无限视频流实时理解|Ruyi Xu, Guangxuan Xiao, Yukang Chen, Liuning He, Kelly Peng, Yao Lu, Song Han|<http://arxiv.org/pdf/2510.09608v1>|[代码](https://github.com/mit-han-lab/streaming-vlm.); 提出了StreamingVLM模型，通过统一训练与流式推理，实现了对无限视频流的实时稳定理解。|
|🆕 发布|SpaceVista: All-Scale Visual Spatial Reasoning from mm to km|SpaceVista：从毫米到千米的全尺度视觉空间推理|Peiwen Sun, Shiqiang Lang, Dongming Wu, Yi Ding, Kaituo Feng, Huadai Liu, Zhen Ye, Rui Liu .etc.|<http://arxiv.org/pdf/2510.09606v1>|[代码](https://peiwensun2000.github.io/mm2km); 提出了SpaceVista框架，通过结构化知识系统、尺度感知建模和渐进训练策略，解决了全尺度视觉空间...|
|🆕 发布|PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs|物理工具理解基准测试：面向多模态大型语言模型的评估|Zixin Zhang, Kanghao Chen, Xingwang Lin, Lutao Jiang, Xu Zheng, Yuanhuiyi Lyu, Litao Guo, Yinchuan Li .etc.|<http://arxiv.org/pdf/2510.09507v1>|提出PhysToolBench，首个评估大型多模态语言模型对物理工具理解能力的视觉问答数据集。|
|📝 更新|Benchmarking and Mitigate Sycophancy in Medical Vision-Language Models|医疗视觉语言模型中的基准测试与谄媚缓解|Zikun Guo, Xinyue Xu, Pei Xiang, Shu Yang, Xin Han, Di Wang, Lijie Hu|<http://arxiv.org/pdf/2509.21979v2>|提出了一种针对医疗视觉问答模型中的奉承行为的新基准和轻量级缓解策略，提高了基于证据的响应准确性。|
|🆕 发布|Hallucination Filtering in Radiology Vision-Language Models Using Discrete Semantic Entropy|使用离散语义熵对放射学视觉-语言模型中的幻觉过滤|Patrick Wienholt, Sophie Caselitz, Robert Siepmann, Philipp Bruners, Keno Bressem, Christiane Kuhl, Jakob Nikolas Kather, Sven Nebelung .etc.|<http://arxiv.org/pdf/2510.09256v1>|提出使用离散语义熵过滤生成幻觉的问题，显著提升了医学图像视觉问答模型的准确度。|
|📝 更新|LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA|LaV-CoT：面向现实世界多语言视觉问答的语言感知视觉CoT多方面奖励优化方法|Jing Huang, Zhiya Tan, Shutao Gong, Fanwei Zeng, Joey Tianyi Zhou, Changtao Miao, Huazhe Tan, Weibin Yao .etc.|<http://arxiv.org/pdf/2509.10026v3>|[代码](https://github.com/HJNVR/LaV-CoT); 提出了一种语言感知视觉CoT框架LaV-CoT，通过多方面奖励优化，提升了多语种视觉问答的准确性和泛...|
|📝 更新|Don't Just Chase "Highlighted Tokens" in MLLMs: Revisiting Visual Holistic Context Retention|不要只追求大型语言模型中的“高亮标记”：重新审视视觉整体上下文保持|Xin Zou, Di Lu, Yizhou Wang, Yibo Yan, Yuanhuiyi Lyu, Xu Zheng, Linfeng Zhang, Xuming Hu|<http://arxiv.org/pdf/2510.02912v2>|提出了一种全局视觉上下文保留的视觉token剪枝框架HoloV，有效提升了多模态大语言模型的效率与准...|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RePIC: Reinforced Post-Training for Personalizing Multi-Modal Language Models|RePIC: 强化后训练以个性化多模态语言模型|Yeongtak Oh, Dohyun Chung, Juhyeon Shin, Sangha Park, Johan Barthelemy, Jisoo Mok, Sungroh Yoon|<http://arxiv.org/pdf/2506.18369v4>|[代码](https://github.com/oyt9306/RePIC); 提出了一种基于强化学习的多模态语言模型个性化后训练方法，有效提升了模型在个性化图像描述方面的表现。|
|🆕 发布|Visual Anomaly Detection for Reliable Robotic Implantation of Flexible Microelectrode Array|计算机视觉异常检测用于柔性微电极阵列的可靠机器人植入|Yitong Chen, Xinyao Xu, Ping Zhu, Xinyong Han, Fangbo Qin, Shan Yu|<http://arxiv.org/pdf/2510.09071v1>|开发了一种基于图像的异常检测框架，通过显微镜摄像头监测柔性微电极植入过程，提高植入可靠性和安全性。|
|🆕 发布|On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models|关于大型视觉语言模型中视觉标记的认知不确定性对物体幻觉的影响|Hoigi Seo, Dong Un Kang, Hyunjin Cho, Joohoon Lee, Se Young Chun|<http://arxiv.org/pdf/2510.09008v1>|揭示了视觉编码中的不确定性是大型视觉语言模型产生对象虚构的关键因素，并提出了一种有效抑制虚构的方法。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|The Impact of 2D Segmentation Backbones on Point Cloud Predictions Using 4D Radar|二维分割基础模型对使用四维雷达的点云预测的影响|William Muckelroy III, Mohammed Alsakabi, John Dolan, Ozan Tonguz|<http://arxiv.org/pdf/2509.19644v2>|探究2D分割网络对4D雷达生成点云质量的影响，发现最优模型提升性能23.7%。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A methodology for clinically driven interactive segmentation evaluation|一种基于临床驱动的交互式分割评估方法|Parhom Esmaeili, Virginia Fernandez, Pedro Borges, Eli Gibson, Sebastien Ourselin, M. Jorge Cardoso|<http://arxiv.org/pdf/2510.09499v1>|提出了一种针对临床需求的互动分割评估方法，构建了标准化评估流程框架，揭示了模型稳健性和性能的关键因素...|
|📝 更新|A Comprehensive Survey of Mamba Architectures for Medical Image Analysis: Classification, Segmentation, Restoration and Beyond|《医学图像分析中Mamba架构的全面调研：分类、分割、恢复及拓展》|Shubhi Bansal, Sreeharish A, Madhava Prasath J, Manikandan S, Sreekanth Madisetty, Mohammad Zia Ur Rehman, Chandravardhan Singh Raghaw, Gaurav Duggal .etc.|<http://arxiv.org/pdf/2410.02362v3>|概述了Mamba架构在医疗影像分析中的应用，解决了传统方法计算复杂度高和长距离依赖处理难题。|
|📝 更新|MedCAL-Bench: A Comprehensive Benchmark on Cold-Start Active Learning with Foundation Models for Medical Image Analysis|MedCAL-Bench：基于基础模型的医学图像分析冷启动主动学习全面基准测试|Ning Zhu, Xiaochuan Ma, Shaoting Zhang, Guotai Wang|<http://arxiv.org/pdf/2508.03441v2>|[代码](https://github.com/HiLab-git/MedCAL-Bench.); 提出MedCAL-Bench，首个针对医疗图像分析的基于预训练模型的全流程冷启动主动学习基准测试。|
|📝 更新|GTR-Bench: Evaluating Geo-Temporal Reasoning in Vision-Language Models|GTR-Bench：评估视觉语言模型中的地理时间推理|Qinghongbing Xie, Zhaoyuan Xia, Feng Zhu, Lijun Gong, Ziyue Li, Rui Zhao, Long Zeng|<http://arxiv.org/pdf/2510.07791v2>|[代码](https://github.com/X-Luffy/GTR-Bench.); 提出GTR-Bench，评估视觉语言模型在地图与视频结合的地理时空推理能力。|
|🆕 发布|A Novel Multi-branch ConvNeXt Architecture for Identifying Subtle Pathological Features in CT Scans|一种新颖的多分支ConvNeXt架构用于识别CT扫描中的细微病理特征|Irash Perera, Uthayasanker Thayasivam|<http://arxiv.org/pdf/2510.09107v1>|提出了一种多分支ConvNeXt架构，通过精细数据处理和双阶段训练，有效识别CT扫描中的细微病理特征...|
|🆕 发布|Lesion-Aware Post-Training of Latent Diffusion Models for Synthesizing Diffusion MRI from CT Perfusion|病变感知的潜在扩散模型后训练用于从CT灌注合成扩散MRI|Junhyeok Lee, Hyunwoong Kim, Hyungjin Chung, Heeseong Eom, Joon Jang, Chul-Ho Sohn, Kyu Sung Choi|<http://arxiv.org/pdf/2510.09056v1>|提出了一种针对医学图像转换的病变感知后训练框架，显著提升了图像质量和病变轮廓的精确度。|
|🆕 发布|Progressive Uncertainty-Guided Evidential U-KAN for Trustworthy Medical Image Segmentation|逐步不确定性引导的证据U-KAN用于可靠医学图像分割|Zhen Yang, Yansong Ma, Lei Chen|<http://arxiv.org/pdf/2510.08949v1>|提出了一种结合不确定性图和证据学习的医疗图像分割方法，提高了模糊边界的分割准确性和可靠性。|
|🆕 发布|FS-RWKV: Leveraging Frequency Spatial-Aware RWKV for 3T-to-7T MRI Translation|FS-RWKV：利用频率空间感知RWKV实现3T至7T MRI转换|Yingtie Lei, Zimeng Li, Chi-Man Pun, Yupeng Liu, Xuhang Chen|<http://arxiv.org/pdf/2510.08951v1>|提出FS-RWKV框架，通过频率-空间处理提升3T MRI到7T MRI图像转换的质量和效率。|
|📝 更新|Enhancing Feature Fusion of U-like Networks with Dynamic Skip Connections|《增强U型网络特征融合的动态跳跃连接》|Yue Cao, Quansong He, Kaishen Wang, Jianlong Xiong, Tao He|<http://arxiv.org/pdf/2509.14610v2>|提出动态跳跃连接块以增强U型网络特征融合，通过自适应机制提升多尺度特征交互和内容感知特性。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Clear Roads, Clear Vision: Advancements in Multi-Weather Restoration for Smart Transportation|清晰道路，清晰视野：智能交通多天气复原技术的进展|Vijay M. Galshetwar, Praful Hambarde, Prashant W. Patil, Akshay Dudhane, Sachin Chaudhary, Santosh Kumar Vipparathi, Subrahmanyam Murala|<http://arxiv.org/pdf/2510.09228v1>|[代码](https://github.com/ChaudharyUPES/A-comprehensive-review-on-Multi-weather-restoration); 系统综述了多种天气条件下的图像和视频恢复技术，旨在提升智能交通系统在恶劣天气下的视觉性能。|
|📝 更新|AD-EE: Early Exiting for Fast and Reliable Vision-Language Models in Autonomous Driving|自动驾驶中的AD-EE：用于快速可靠视觉-语言模型的早期退出机制|Lianming Huang, Haibo Hu, Yufei Cui, Jiacheng Zuo, Shangyu Wu, Nan Guan, Chun Jason Xue|<http://arxiv.org/pdf/2506.05404v2>|提出了一种针对自动驾驶的AD-EE早期退出框架，通过利用因果推断优化退出层，大幅降低延迟并提升对象检...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Training Feature Attribution for Vision Models|为视觉模型训练特征归因|Aziz Bacha, Thomas George|<http://arxiv.org/pdf/2510.09135v1>|提出了一种训练特征归因方法，将测试预测与特定训练图像的具体区域关联，揭示了深度模型的内部工作机制。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CapGeo: A Caption-Assisted Approach to Geometric Reasoning|CapGeo：一种基于标题辅助的几何推理方法|Yuying Li, Siyi Qian, Hao Liang, Leqi Zheng, Ruichuan An, Yongzhen Guo, Wentao Zhang|<http://arxiv.org/pdf/2510.09302v1>|提出了一种将视觉内容转化为文本描述的CapGeo框架，大幅提升多模态大语言模型解决几何问题的能力。|
|🆕 发布|TARO: Toward Semantically Rich Open-World Object Detection|面向语义丰富的开放世界目标检测：TARO|Yuchen Zhang, Yao Lu, Johannes Betz|<http://arxiv.org/pdf/2510.09173v1>|提出了一种开放世界对象检测框架TARO，通过将未知对象分类到粗略的语义类别中，提高了安全关键决策的准...|

