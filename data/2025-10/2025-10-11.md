## [UPDATED!] **2025-10-11** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vision4PPG: Emergent PPG Analysis Capability of Vision Foundation Models for Vital Signs like Blood Pressure|《Vision4PPG：视觉基础模型新兴的心率变异性分析能力，用于血压等生命体征的监测》|Saurabh Kataria, Ayca Ermis, Lovely Yeswanth Panchumarthi, Minxiao Wang, Xiao Hu|<http://arxiv.org/pdf/2510.10366v1>|提出了一种将一维PPG信号转化为二维图像表示的方法，利用视觉基础模型实现生理参数估计，达到领先性能。|
|📝 更新|MGPATH: Vision-Language Model with Multi-Granular Prompt Learning for Few-Shot WSI Classification|MGPATH：基于多粒度提示学习的视觉-语言模型用于少量样本全切片分类|Anh-Tien Nguyen, Duy Minh Ho Nguyen, Nghiem Tuong Diep, Trung Quoc Nguyen, Nhat Ho, Jacqueline Michelle Metsch, Miriam Cindy Maurer, Daniel Sonntag .etc.|<http://arxiv.org/pdf/2502.07409v4>|提出了一种多粒度提示学习法，通过对比图像片段与文本，提升了少量样本下的病理图像分类性能。|
|🆕 发布|SAM2LoRA: Composite Loss-Guided, Parameter-Efficient Finetuning of SAM2 for Retinal Fundus Segmentation|SAM2LoRA：基于组合损失引导的SAM2参数高效微调用于视网膜眼底分割|Sayan Mandal, Divyadarshini Karthikeyan, Manas Paldhe|<http://arxiv.org/pdf/2510.10288v1>|提出SAM2LoRA方法，通过低秩适配器高效微调SAM2模型，实现视网膜图像精准分割。|
|🆕 发布|X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model|X-VLA：软提示变压器作为可扩展的跨实体视觉-语言-动作模型|Jinliang Zheng, Jianxiong Li, Zhihao Wang, Dongxiu Liu, Xirui Kang, Yuchun Feng, Yinan Zheng, Jiayin Zou .etc.|<http://arxiv.org/pdf/2510.10274v1>|[代码](https://thu-air-dream.github.io/X-VLA); 提出Soft Prompt方法，通过少量参数提升异构机器人数据源的 Vision-Language-...|
|📝 更新|{S\textsuperscript{2}M\textsuperscript{2}}: Scalable Stereo Matching Model for Reliable Depth Estimation|{S\textsuperscript{2}M\textsuperscript{2}}：可扩展立体匹配模型用于可靠深度估计|Junhong Min, Youngpil Jeon, Jimin Kim, Minyong Choi|<http://arxiv.org/pdf/2507.13229v4>|提出了一种高效的全球匹配架构，实现了无数据集特定微调下的准确深度估计。|
|📝 更新|A Comprehensive Survey on Knowledge Distillation|《知识蒸馏的全面综述》|Amir M. Mansourian, Rozhan Ahmadi, Masoud Ghafouri, Amir Mohammad Babaei, Elaheh Badali Golezani, Zeynab Yasamani Ghamchi, Vida Ramezanian, Alireza Taherian .etc.|<http://arxiv.org/pdf/2503.12067v2>|[代码](https://github.com/IPL-Sharif/KD_Survey); 系统梳理了知识蒸馏方法，为轻量级模型训练提供了新视角和结构化分类。|
|🆕 发布|Tracking the Spatiotemporal Evolution of Landslide Scars Using a Vision Foundation Model: A Novel and Universal Framework|利用视觉基础模型追踪滑坡痕迹时空演化：一种新颖且通用的框架|Meijun Zhou, Gang Mei, Zhengjing Ma, Nengxiong Xu, Jianbing Peng|<http://arxiv.org/pdf/2510.10084v1>|提出了一种基于视觉基础模型的框架，实现了大规模滑坡疤痕的连续时空演化追踪。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bridging Perspectives: Foundation Model Guided BEV Maps for 3D Object Detection and Tracking|《融合视角：基于基础模型引导的鸟瞰图地图用于三维目标检测与跟踪》|Markus Käppeler, Özgün Çiçek, Daniele Cattaneo, Claudius Gläser, Yakov Miron, Abhinav Valada|<http://arxiv.org/pdf/2510.10287v1>|提出了一种融合视角特征与基础模型指导的鸟瞰图方法，提升了自动驾驶中的三维物体检测与跟踪性能。|
|🆕 发布|From Generic to Specialized: A Subspecialty Diagnostic System Powered by Self-Supervised Learning for Cervical Histopathology|从通用到专业：基于自监督学习驱动的宫颈组织病理学亚专科诊断系统|Yizhi Wang, Li Chen, Qiang Huang, Tian Guan, Xi Deng, Zhiyuan Shen, Jiawen Li, Xinrui Chen .etc.|<http://arxiv.org/pdf/2510.10196v1>|开发了一种针对宫颈病理诊断的专用系统CerS-Path，通过自监督学习显著提升了诊断准确性和泛化能力...|
|🆕 发布|INR-Bench: A Unified Benchmark for Implicit Neural Representations in Multi-Domain Regression and Reconstruction|INR-Bench：多域回归与重建中隐式神经表示的统一基准|Linfei Li, Fengyi Zhang, Zhong Wang, Lin Zhang, Ying Shen|<http://arxiv.org/pdf/2510.10188v1>|[代码](https://github.com/lif314/INR-Bench.); 提出INR-Bench，首个针对多模态隐式神经表征任务的综合基准，分析模型架构对信号处理的影响。|
|🆕 发布|Gesplat: Robust Pose-Free 3D Reconstruction via Geometry-Guided Gaussian Splatting|“Gesplat：基于几何引导的高斯散点法的鲁棒无姿态三维重建”|Jiahui Lu, Haihong Xiao, Xueyan Zhao, Wenxiong Kang|<http://arxiv.org/pdf/2510.10097v1>|提出了一种基于几何引导的高斯散点框架，实现了无需准确相机姿态的稳健三维重建。|
|📝 更新|Benchmarking and Bridging Emotion Conflicts for Multimodal Emotion Reasoning|多模态情感推理中的基准测试与情感冲突桥接|Zhiyuan Han, Beier Zhu, Yanlong Xu, Peipei Song, Xun Yang|<http://arxiv.org/pdf/2508.01181v2>|提出CA-MER基准测试和MoSEAR框架，缓解多模态情感推理中的情绪冲突问题，实现模态间平衡。|
|📝 更新|MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization|MM-HELIX：利用整体平台与自适应混合策略优化提升多模态长链反射性推理|Xiangyu Zhao, Junming Lin, Tianhao Liang, Yifan Zhou, Wenhao Chai, Yuzhe Gu, Weiyun Wang, Kai Chen .etc.|<http://arxiv.org/pdf/2510.08540v2>|提出了一种自适应混合策略优化方法，有效提升了多模态大语言模型在长链反思性推理任务上的性能。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SecureWebArena: A Holistic Security Evaluation Benchmark for LVLM-based Web Agents|“SecureWebArena：基于LVLM的网页代理全方位安全评估基准”|Zonghao Ying, Yangguang Shao, Jianle Gan, Gan Xu, Junjie Shen, Wenxin Zhang, Quanchen Zou, Junzheng Shi .etc.|<http://arxiv.org/pdf/2510.10073v1>|提出了首个全面的评估框架SecureWebArena，用于评估大型视觉语言模型驱动的网络代理的安全性...|
|🆕 发布|DREAM: A Benchmark Study for Deepfake REalism AssessMent|DREAM：深度伪造真实感评估基准研究|Bo Peng, Zichuan Wang, Sheng Yu, Xiaochuan Jin, Wei Wang, Jing Dong|<http://arxiv.org/pdf/2510.10053v1>|提出DREAM基准，评估深伪视频视觉真实感，助力深伪检测与生成研究。|
|📝 更新|SenseShift6D: Multimodal RGB-D Benchmarking for Robust 6D Pose Estimation across Environment and Sensor Variations|SenseShift6D：跨环境和传感器变化的稳健6D姿态估计多模态RGB-D基准测试|Yegyu Han, Taegyoon Yoon, Dayeon Woo, Sojeong Kim, Hyung-Sin Kim|<http://arxiv.org/pdf/2507.05751v2>|引入SenseShift6D数据集，通过测试时传感器控制提升6D姿态估计在多变环境下的鲁棒性。|
|📝 更新|OmniSAM: Omnidirectional Segment Anything Model for UDA in Panoramic Semantic Segmentation|全方位分割一切模型OmniSAM：用于全景语义分割的无监督域自适应|Ding Zhong, Xu Zheng, Chenfei Liao, Yuanhuiyi Lyu, Jialei Chen, Shengyang Wu, Linfeng Zhang, Xuming Hu|<http://arxiv.org/pdf/2503.07098v3>|提出了OmniSAM框架，通过分块处理和特征连续性改进，解决了全景图像语义分割中的视场差距和语义理解...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Synthetic Dataset for Manometry Recognition in Robotic Applications|机器人应用中的压力计识别合成数据集|Pedro Antonio Rabelo Saraiva, Enzo Ferreira de Souza, Joao Manoel Herrera Pinheiro, Thiago H. Segreto, Ricardo V. Godoy, Marcelo Becker|<http://arxiv.org/pdf/2508.17468v2>|提出了一种结合 procedural rendering 和 AI 视频生成的数据合成方法，有效解决...|
|🆕 发布|HccePose(BF): Predicting Front \& Back Surfaces to Construct Ultra-Dense 2D-3D Correspondences for Pose Estimation|HccePose(BF)：预测前后表面以构建超密集二维-三维对应关系用于姿态估计|Yulin Wang, Mengting Hu, Hongli Li, Chen Luo|<http://arxiv.org/pdf/2510.10177v1>|[代码](https://github.com/WangYuLin-SEU/HCCEPose.); 提出预测物体前后表面3D坐标的方法，通过超密集2D-3D对应提升姿态估计精度。|
|🆕 发布|Multi Class Parkinsons Disease Detection Based on Finger Tapping Using Attention-Enhanced CNN BiLSTM|基于手指敲击的注意力增强CNN BiLSTM多类帕金森病检测|Abu Saleh Musa Miah, Najmul Hassan, Md Maruf Al Hossain, Yuichi Okuyama, Jungpil Shin|<http://arxiv.org/pdf/2510.10121v1>|提出了一种基于手指敲击动作和深度学习模型的帕金森病多级别严重程度检测方法，提高了疾病严重程度的自动识...|
|🆕 发布|YOLOv11-Litchi: Efficient Litchi Fruit Detection based on UAV-Captured Agricultural Imagery in Complex Orchard Environments|基于无人机捕获的复杂果园环境中高效荔枝检测的YOLOv11-Litchi方法|Hongxing Peng, Haopei Xie, Weijia Lia, Huanai Liuc, Ximing Li|<http://arxiv.org/pdf/2510.10141v1>|提出了一种针对复杂果园环境下无人机荔枝检测的轻量级高效模型YOLOv11-Litchi，提升了检测准...|
|🆕 发布|A Multi-Strategy Framework for Enhancing Shatian Pomelo Detection in Real-World Orchards|一种多策略框架用于提高现实果园中沙田柚检测的准确性|Pan Wang, Yihao Hu, Xiaodong Bai, Aiping Yang, Xiangxiang Li, Meiping Ding, Jianguo Yao|<http://arxiv.org/pdf/2510.09948v1>|提出多策略框架应对实际果园中沙田柚检测的挑战，通过多场景数据集和改进网络结构提升检测精度。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SparseUWSeg: Active Sparse Point-Label Augmentation for Underwater Semantic Segmentation|稀疏UWSeg：水下语义分割的主动稀疏点标签增强方法|César Borja, Carlos Plou, Rubén Martinez-Cantín, Ana C. Murillo|<http://arxiv.org/pdf/2510.10163v1>|提出SparseUWSeg框架，通过主动采样和混合传播策略，有效提升水下图像语义分割精度。|
|🆕 发布|SaFiRe: Saccade-Fixation Reiteration with Mamba for Referring Image Segmentation|SaFiRe: 利用Mamba进行注视-扫视重迭的图像分割方法|Zhenjie Mao, Yuhuan Yang, Chaofan Ma, Dongsheng Jiang, Jiangchao Yao, Ya Zhang, Yanfeng Wang|<http://arxiv.org/pdf/2510.10160v1>|提出了一种模拟人类认知过程的SaFiRe框架，有效处理含糊的图像参照表达，提升图像分割准确性。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Training-Free In-Context Forensic Chain for Image Manipulation Detection and Localization|无需训练的图像操纵检测与定位中的在位法医链|Rui Chen, Bin Liu, Changtao Miao, Xinghao Wang, Yi Li, Tao Gong, Qi Chu, Nenghai Yu|<http://arxiv.org/pdf/2510.10111v1>|提出了一种无需训练的In-Context Forensic Chain框架，利用大型多模态语言模型进...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Collaborative Learning of Semantic-Aware Feature Learning and Label Recovery for Multi-Label Image Recognition with Incomplete Labels|协同学习语义感知特征学习与标签恢复的多标签图像识别方法研究（针对不完整标签）|Zhi-Fen He, Ren-Dong Xie, Bo Li, Bin Liu, Jin-Yan Hu|<http://arxiv.org/pdf/2510.10055v1>|提出了一种统一学习框架CLSL，通过协同学习语义感知特征学习和标签恢复，有效提升了不完全标签多标签图...|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Ortho-Fuse: Orthomosaic Generation for Sparse High-Resolution Crop Health Maps Through Intermediate Optical Flow Estimation|Ortho-Fuse：通过中间光流估计生成稀疏高分辨率作物健康正射影像图|Rugved Katole, Christopher Stewart|<http://arxiv.org/pdf/2510.10360v1>|提出Ortho-Fuse方法，通过光学流估计生成可靠的正射镶嵌图，降低了对高分辨率稀疏航空影像数据集...|
|📝 更新|Baking Gaussian Splatting into Diffusion Denoiser for Fast and Scalable Single-stage Image-to-3D Generation and Reconstruction|将高斯散点绘制技术融入扩散去噪器以实现快速且可扩展的单阶段图像到3D生成与重建|Yuanhao Cai, He Zhang, Kai Zhang, Yixun Liang, Mengwei Ren, Fujun Luan, Qing Liu, Soo Ye Kim .etc.|<http://arxiv.org/pdf/2411.14384v5>|[代码](https://github.com/caiyuanhao1998/Open-DiffusionGS); 提出了一种单阶段3D扩散模型DiffusionGS，通过直接输出3D高斯点云实现快速且可扩展的单视图...|
|📝 更新|OmniVCus: Feedforward Subject-driven Video Customization with Multimodal Control Conditions|全方位个性化视频定制：基于前馈主体驱动及多模态控制条件|Yuanhao Cai, He Zhang, Xi Chen, Jinbo Xing, Yiwei Hu, Yuqian Zhou, Kai Zhang, Zhifei Zhang .etc.|<http://arxiv.org/pdf/2506.23361v2>|[代码](https://github.com/caiyuanhao1998/Open-OmniVCus); 提出了一种多模态控制的视频定制方法OmniVCus，通过创新的数据构建和扩散Transformer框...|
|🆕 发布|From Programs to Poses: Factored Real-World Scene Generation via Learned Program Libraries|从程序到姿态：通过学习程序库实现分解现实世界场景生成|Joy Hsu, Emily Jin, Jiajun Wu, Niloy J. Mitra|<http://arxiv.org/pdf/2510.10292v1>|提出FactoredScenes框架，通过学习房间结构和物体姿态生成逼真的三维场景。|
|📝 更新|Imbalance-Robust and Sampling-Efficient Continuous Conditional GANs via Adaptive Vicinity and Auxiliary Regularization|通过自适应邻域和辅助正则化实现的平衡鲁棒且采样高效的条件生成对抗网络|Xin Ding, Yun Chen, Yongwei Wang, Kao Zhang, Sen Zhang, Peibei Cao, Xiangxue Wang|<http://arxiv.org/pdf/2508.01725v3>|提出自适应邻域和辅助正则化的CcGAN-AVAR，解决数据不平衡和采样效率问题，实现更快推理速度和卓...|
|🆕 发布|VividAnimator: An End-to-End Audio and Pose-driven Half-Body Human Animation Framework|生动动画师：一种端到端的音频和姿态驱动的半身人体动画框架|Donglin Huang, Yongyuan Li, Tianhang Liu, Junming Huang, Xiaoda Yang, Chi Wang, Weiwei Xu|<http://arxiv.org/pdf/2510.10269v1>|VividAnimator通过预训练手部纹理码本、双流音频感知模块和姿态校准技巧，解决了音频与头部运...|
|📝 更新|Seg2Any: Open-set Segmentation-Mask-to-Image Generation with Precise Shape and Semantic Control|Seg2Any：开集分割掩码到图像生成，具有精确形状和语义控制|Danfeng li, Hui Zhang, Sheng Wang, Jiacheng Li, Zuxuan Wu|<http://arxiv.org/pdf/2506.00596v2>|Seg2Any通过分离语义和形状信息，并引入隔离注意力机制，实现了精确的图像生成控制。|
|🆕 发布|ReMix: Towards a Unified View of Consistent Character Generation and Editing|《ReMix：迈向一致性格生成与编辑的统一视角》|Benjia Zhou, Bin Fu, Pei Cheng, Yanru Wang, Jiayuan Fan, Tao Chen|<http://arxiv.org/pdf/2510.10156v1>|提出统一框架ReMix，结合生成与编辑优势，实现角色一致性图像生成与编辑。|
|📝 更新|DetailMaster: Can Your Text-to-Image Model Handle Long Prompts?|《DetailMaster：您的文本到图像模型能处理长提示吗？》|Qirui Jiao, Daoyuan Chen, Yilun Huang, Xika Lin, Ying Shen, Yaliang Li|<http://arxiv.org/pdf/2505.16915v2>|提出首个全面评估文本到图像模型处理长详细提示能力的DetailMaster基准，揭示了现有模型在复杂...|
|📝 更新|NEP: Autoregressive Image Editing via Next Editing Token Prediction|下一代编辑标记：通过下一编辑标记预测的自回归图像编辑|Huimin Wu, Xiaojian Ma, Haozhe Zhao, Yanpeng Zhao, Qing Li|<http://arxiv.org/pdf/2508.06044v2>|提出了一种基于自回归图像生成的Next Editing-token Prediction方法，仅编辑...|
|📝 更新|Diverse Text-to-Image Generation via Contrastive Noise Optimization|通过对比噪声优化实现多样化的文本到图像生成|Byungjun Kim, Soobin Um, Jong Chul Ye|<http://arxiv.org/pdf/2510.03813v2>|提出了一种对比噪声优化方法，有效解决了文本到图像生成中的多样性问题。|
|🆕 发布|FlareX: A Physics-Informed Dataset for Lens Flare Removal via 2D Synthesis and 3D Rendering|FlareX：一种基于物理信息的透镜眩光去除数据集，通过2D合成与3D渲染|Lishen Qu, Zhihao Liu, Jinshan Pan, Shihao Zhou, Jinglei Shi, Duosheng Chen, Jufeng Yang|<http://arxiv.org/pdf/2510.09995v1>|提出了物理信息指导的FlareX数据集，通过结合2D合成与3D渲染，增强了镜头炫光去除模型的泛化能力...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CURE: Concept Unlearning via Orthogonal Representation Editing in Diffusion Models|CURE：通过正交表示编辑在扩散模型中进行概念遗忘|Shristi Das Biswas, Arani Roy, Kaushik Roy|<http://arxiv.org/pdf/2505.12677v2>|提出了一种无需重新训练的CURE框架，通过在预训练模型权重空间中操作，快速有效地移除不期望的概念。|
|📝 更新|OSCAR: One-Step Diffusion Codec Across Multiple Bit-rates|OSCAR：一步扩散编解码器跨多比特率|Jinpei Guo, Yifei Ji, Zheng Chen, Kai Liu, Min Liu, Wang Rao, Wenbo Li, Yong Guo .etc.|<http://arxiv.org/pdf/2505.16091v5>|[代码](https://github.com/jp-guo/OSCAR.); OSCAR提出了一种多码率下的一步扩散编解码方法，通过映射压缩码率到伪扩散时间步，实现了高效的单步去...|
|📝 更新|Large-Area Fabrication-Aware Computational Diffractive Optics|大面积制造感知计算衍射光学|Kaixuan Wei, Hector A. Jimenez-Romero, Hadi Amata, Jipeng Sun, Qiang Fu, Felix Heide, Wolfgang Heidrich|<http://arxiv.org/pdf/2505.22313v2>|提出了一种面向制造的超分辨率神经光刻模型，实现了大区域计算衍射光学系统的端到端优化。|
|🆕 发布|DeepFusionNet: Autoencoder-Based Low-Light Image Enhancement and Super-Resolution|深度融合网：基于自动编码器的低光照图像增强与超分辨率|Halil Hüseyin Çalışkan, Talha Koruk|<http://arxiv.org/pdf/2510.10122v1>|DeepFusionNet通过结合自编码器结构，有效提升了低光照图像增强和超分辨率处理的性能与效率。|
|🆕 发布|Answer-Consistent Chain-of-thought Reinforcement Learning For Multi-modal Large Langauge Models|答案一致性的链式思维强化学习用于多模态大型语言模型|Minbin Huang, Runhui Huang, Chuanyang Zheng, Jingyao Li, Guoxuan Chen, Han Shi, Hong Cheng|<http://arxiv.org/pdf/2510.10104v1>|提出了一种增强多模态大语言模型推理一致性的方法，通过引入答案一致性验证奖励，有效提高了视觉推理任务中...|
|📝 更新|Blind Video Super-Resolution based on Implicit Kernels|基于隐式核的盲视频超分辨率|Qiang Zhu, Yuxuan Jiang, Shuyuan Zhu, Fan Zhang, David Bull, Bing Zeng|<http://arxiv.org/pdf/2503.07856v2>|[代码](https://github.com/QZ1-boy/BVSR-IK.); 提出了一种基于隐式核的多尺度字典构建方法，通过预测系数权重实现视频超分辨率，提升了性能。|
|🆕 发布|Denoising Diffusion as a New Framework for Underwater Images|水下图像去噪扩散：一种新的框架|Nilesh Jain, Elie Alhajjar|<http://arxiv.org/pdf/2510.09934v1>|提出利用扩散去噪模型和控制网增强技术，提升水下图像质量和数据集多样性，以改善海洋生态系统研究。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Semantic Visual Anomaly Detection and Reasoning in AI-Generated Images|人工智能生成图像中的语义视觉异常检测与推理|Chuangchuang Tan, Xiang Ming, Jinglu Wang, Renshuai Tao, Bin Li, Yunchao Wei, Yao Zhao, Yan Lu|<http://arxiv.org/pdf/2510.10231v1>|提出语义异常检测与推理方法，构建大规模数据集AnomReason，提升AI生成图像的语义可信度。|
|📝 更新|MarkPlugger: Generalizable Watermark Framework for Latent Diffusion Models without Retraining|MarkPlugger：无需重新训练的潜在扩散模型通用水印框架|Guokai Zhang, Lanjun Wang, Yuting Su, An-An Liu|<http://arxiv.org/pdf/2404.05607v2>|提出了一种无需重新训练的通用水印框架MarkPlugger，有效嵌入水印于扩散模型生成的图像中，保持...|
|📝 更新|MultiCOIN: Multi-Modal COntrollable Video INbetweening|多模态可控视频插值：MultiCOIN|Maham Tanveer, Yang Zhou, Simon Niklaus, Ali Mahdavi Amiri, Hao Zhang, Krishna Kumar Singh, Nanxuan Zhao|<http://arxiv.org/pdf/2510.08561v2>|引入了MultiCOIN框架，通过多模态控制实现精细的视频插帧，提高了视频编辑的灵活性和精确度。|
|📝 更新|RATLIP: Generative Adversarial CLIP Text-to-Image Synthesis Based on Recurrent Affine Transformations|基于循环仿射变换的生成对抗CLIP文本到图像合成：RATLIP|Chengde Lin, Xijun Lu, Guangxi Chen|<http://arxiv.org/pdf/2405.08114v2>|[代码](https://github.com/OxygenLu/RATLIP.); 提出了一种结合循环神经网络和条件仿射变换的生成对抗网络模型，通过shuffle注意力机制和CLIP模...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Generative Latent Video Compression|生成潜在视频压缩|Zongyu Guo, Zhaoyang Jia, Jiahao Li, Xiaoyi Zhang, Bin Li, Yan Lu|<http://arxiv.org/pdf/2510.09987v1>|提出了一种基于生成潜在空间的视频压缩框架GLVC，有效平衡了视频压缩中的率失真感知权衡，减少了闪烁伪...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Opacity-Gradient Driven Density Control for Compact and Efficient Few-Shot 3D Gaussian Splatting|基于不透明度梯度驱动的密度控制以实现紧凑高效的小样本3D高斯散点绘制|Abdelrhman Elrawy, Emad A. Mohammed|<http://arxiv.org/pdf/2510.10257v1>|提出了一种基于透明度梯度的密度控制方法，显著提升了少量样本下的三维高斯散点渲染效率。|
|🆕 发布|Color3D: Controllable and Consistent 3D Colorization with Personalized Colorizer|《Color3D：具有可控性和一致性的人物定制色彩化的三维着色方法》|Yecong Wan, Mingwen Shao, Renlong Wu, Wangmeng Zuo|<http://arxiv.org/pdf/2510.10152v1>|[代码](https://yecongwan.github.io/Color3D); 提出了一种个性化的3D场景着色框架，通过单视角训练实现多视角和时间上的一致性与可控性。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Improving Hierarchical Representations of Vectorized HD Maps with Perspective Clues|利用透视线索改进矢量高清地图的层次表示|Chi Zhang, Qi Song, Feifei Li, Jie Li, Rui Huang|<http://arxiv.org/pdf/2404.11155v2>|提出方法PerCMap利用视角特征改善高精度地图向量表示，有效恢复地图实例属性和点坐标准确性。|
|🆕 发布|Translution: Unifying Self-attention and Convolution for Adaptive and Relative Modeling|“Translution：统一自注意力与卷积以实现自适应与相对建模”|Hehe Fan, Yi Yang, Mohan Kankanhalli, Fei Wu|<http://arxiv.org/pdf/2510.10060v1>|[代码](https://github.com/hehefan/Translution.); 统一了自注意力与卷积的优势，提出Translution模型，实现了自适应且相对位置编码的数据建模。|
|📝 更新|ViFusionTST: Deep Fusion of Time-Series Image Representations from Load Signals for Early Bed-Exit Prediction|基于负载信号的时间序列图像表示深度融合的ViFusionTST：用于早期离床预测|Hao Liu, Yu Hu, Rakiba Rayhana, Ling Bai, Zheng Liu|<http://arxiv.org/pdf/2506.22498v3>|提出了一种利用图像转换和双流Swin Transformer融合负载信号的方法，实现了早期离床意图的...|
|📝 更新|Attention based End to end network for Offline Writer Identification on Word level data|基于注意力机制的开卷端到端网络在单词级别离线书写者识别上的应用|Vineet Kumar, Suresh Sundaram|<http://arxiv.org/pdf/2404.07602v3>|提出了一种基于注意力的卷积神经网络，通过金字塔策略处理单词图像片段，提升少量样本下的书写者识别准确度...|
|🆕 发布|CLoD-GS: Continuous Level-of-Detail via 3D Gaussian Splatting|通过三维高斯散点绘制实现的连续细节级别：CLoD-GS|Zhigang Cheng, Mingchao Sun, Yu Liu, Zengye Ge, Luyang Tang, Mu Xu, Yangyan Li, Peng Pan|<http://arxiv.org/pdf/2510.09997v1>|提出了一种连续细节级别框架CLoD-GS，通过3D高斯散点技术实现平滑渲染和存储优化。|
|🆕 发布|Semi-disentangled spatiotemporal implicit neural representations of longitudinal neuroimaging data for trajectory classification|纵向神经影像数据的半解耦时空隐神经表示用于轨迹分类|Agampreet Aulakh, Nils D. Forkert, Matthias Wilms|<http://arxiv.org/pdf/2510.09936v1>|提出了一种半解耦的时空隐式神经表征方法，用于连续建模和分析脑老化轨迹，实现了更准确的分类效果。|


## 时序视觉分析 (Temporal Visual Analysis)


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Hyper-STTN: Hypergraph Augmented Spatial-Temporal Transformer Network for Trajectory Prediction|超图增强的空间-时间变换网络Hyper-STTN：用于轨迹预测|Weizheng Wang, Baijian Yang, Sungeun Hong, Wenhai Sun, Byung-Cheol Min|<http://arxiv.org/pdf/2401.06344v3>|提出了一种基于超图的时空变换网络Hyper-STTN，有效预测群体轨迹并建模个体间复杂交互。|
|📝 更新|CrunchLLM: Multitask LLMs for Structured Business Reasoning and Outcome Prediction|CrunchLLM：面向结构化商业推理和结果预测的多任务大型语言模型|Rabeya Tus Sadia, Qiang Cheng|<http://arxiv.org/pdf/2509.10698v2>|提出CrunchLLM框架，融合结构化数据与文本信息，提升初创公司成功预测准确率至80%以上。|
|📝 更新|IONext: Unlocking the Next Era of Inertial Odometry|IONext：解锁惯性里程计的新时代|Shanshan Zhang, Qi Zhang, Siyue Wang, Tianshui Wen, Liqin Wu, Ziheng Zhou, Xuemin Hong, Ao Peng .etc.|<http://arxiv.org/pdf/2507.17089v2>|提出了一种CNN-based模块，有效结合全局运动模式和局部细节，显著提升了惯性导航的定位精度和泛化...|
|📝 更新|MMHOI: Modeling Complex 3D Multi-Human Multi-Object Interactions|多人体多物体交互复杂建模：MMHOI|Kaen Kogashi, Anoop Cherian, Meng-Yu Jennifer Kuo|<http://arxiv.org/pdf/2510.07828v2>|提出了MMHOI数据集和MMHOI-Net模型，实现了对复杂三维多人多物交互的高效建模与预测。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Audio Does Matter: Importance-Aware Multi-Granularity Fusion for Video Moment Retrieval|音频确实重要：基于重要性感知的多粒度融合视频瞬间检索|Junan Lin, Daizong Liu, Xianke Chen, Xiaoye Qu, Xun Yang, Jixiang Zhu, Sanyuan Zhang, Jianfeng Dong|<http://arxiv.org/pdf/2508.04273v2>|[代码](https://github.com/HuiGuanLab/IMG.); 提出了一种重要性感知的多粒度融合模型，有效利用音频信息提升视频瞬间检索性能。|
|📝 更新|FCVSR: A Frequency-aware Method for Compressed Video Super-Resolution|频率感知压缩视频超分辨率方法：FCVSR|Qiang Zhu, Fan Zhang, Feiyu Chen, Shuyuan Zhu, David Bull, Bing Zeng|<http://arxiv.org/pdf/2502.06431v2>|提出了一种频率感知的压缩视频超分辨率方法，通过频率域的时空信息处理，显著提升了超分辨率性能和细节重建...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ImmerIris: A Large-Scale Dataset and Benchmark for Immersive Iris Recognition in Open Scenes|沉浸式虹膜识别大规模数据集与开放场景基准测试：ImmerIris|Yuxi Mi, Qiuyang Yuan, Zhizhou Zhong, Xuan Zhao, Jiaogen Zhou, Fubao Zhu, Jihong Guan, Shuigeng Zhou|<http://arxiv.org/pdf/2510.10113v1>|提出大规模ImmerIris数据集，针对沉浸式虹膜识别挑战，提出无需规范化的学习范式。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Probabilistic Hyper-Graphs using Multiple Randomly Masked Autoencoders for Semi-supervised Multi-modal Multi-task Learning|基于多随机遮蔽自编码器的概率超图用于半监督多模态多任务学习|Pîrvu Mihai-Cristian, Leordeanu Marius|<http://arxiv.org/pdf/2510.10068v1>|提出了一种融合概率超图和随机遮蔽自编码器的半监督多模态多任务学习模型，提升了预测性能和一致性。|
|🆕 发布|Complementary and Contrastive Learning for Audio-Visual Segmentation|音频视觉分割中的互补性与对比性学习|Sitong Gong, Yunzhi Zhuge, Lu Zhang, Pingping Zhang, Huchuan Lu|<http://arxiv.org/pdf/2510.10051v1>|[代码](https://github.com/SitongGong/CCFormer); 提出CCFormer框架，融合多模态特征与时空上下文，提升音频视觉分割准确性和鲁棒性。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FMANet: A Novel Dual-Phase Optical Flow Approach with Fusion Motion Attention Network for Robust Micro-expression Recognition|FMANet：一种具有融合运动注意力网络的新型双相光流方法，用于鲁棒的微表情识别|Luu Tu Nguyen, Vu Tram Anh Khuong, Thi Bich Phuong Man, Thi Duyen Ngo, Thanh Ha Le|<http://arxiv.org/pdf/2510.07810v2>|提出了一种融合双阶段运动信息的微表情识别网络，提高了微表情的捕捉准确性。|
|📝 更新|GI-NAS: Boosting Gradient Inversion Attacks Through Adaptive Neural Architecture Search|GI-NAS：通过自适应神经架构搜索提升梯度反转攻击|Wenbo Yu, Hao Fang, Bin Chen, Xiaohang Sui, Chuan Chen, Hao Wu, Shu-Tao Xia, Ke Xu|<http://arxiv.org/pdf/2405.20725v4>|提出了一种自适应神经架构搜索方法GI-NAS，有效提升梯度反转攻击性能，无需领域特定先验知识。|
|🆕 发布|Enabling High-Quality In-the-Wild Imaging from Severely Aberrated Metalens Bursts|实现从严重畸变金属透镜爆发中获取高质量野外成像的技术|Debabrata Mandal, Zhihan Peng, Yujie Wang, Praneeth Chakravarthula|<http://arxiv.org/pdf/2510.10083v1>|提出了一种集成超薄金属透镜与定制多图像复原框架的方法，有效解决了野外成像中的严重像差问题。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Pure-Pass: Fine-Grained, Adaptive Masking for Dynamic Token-Mixing Routing in Lightweight Image Super-Resolution|"纯传递：轻量级图像超分辨率中动态令牌混合路由的细粒度自适应掩码"|Junyu Wu, Jie Liu, Jie Tang, Gangshan Wu|<http://arxiv.org/pdf/2510.01997v2>|提出Pure-Pass方法，通过像素级精细掩码提高图像超分辨率性能，减少计算负担。|
|🆕 发布|P-4DGS: Predictive 4D Gaussian Splatting with 90$\times$ Compression|P-4DGS：预测性四维高斯散点绘制，压缩比为90×|Henan Wang, Hanxin Zhu, Xinliang Gong, Tianyu He, Xin Li, Zhibo Chen|<http://arxiv.org/pdf/2510.10030v1>|提出P-4DGS方法，利用时空预测和自适应量化压缩动态3D场景，实现高达90倍的数据压缩。|
|🆕 发布|BurstDeflicker: A Benchmark Dataset for Flicker Removal in Dynamic Scenes|动态场景去闪烁基准数据集：BurstDeflicker|Lishen Qu, Zhihao Liu, Shihao Zhou, Yaqi Luo, Jie Liang, Hui Zeng, Lei Zhang, Jufeng Yang|<http://arxiv.org/pdf/2510.09996v1>|提出了BurstDeflicker数据集，通过多种策略生成和收集图像，助力解决了动态场景中图像频闪去...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Explainable Human-in-the-Loop Segmentation via Critic Feedback Signals|通过评判反馈信号实现可解释的人机协作分割|Pouya Shaeri, Ryan T. Woo, Yasaman Mohammadpour, Ariane Middel|<http://arxiv.org/pdf/2510.09945v1>|提出了一种结合人类反馈的交互式分割框架，通过针对性纠正提高模型准确性和鲁棒性。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PointMAC: Meta-Learned Adaptation for Robust Test-Time Point Cloud Completion|点云元学习自适应：用于鲁棒测试时点云补全的方法|Linlian Jiang, Rui Ma, Li Gu, Ziqiang Wang, Xinxin Zuo, Yang Wang|<http://arxiv.org/pdf/2510.10365v1>|提出了PointMAC，一种通过元学习实现测试时点云完成的自适应框架，有效应对新结构模式和传感器失真...|
|📝 更新|Optimizing Grasping in Legged Robots: A Deep Learning Approach to Loco-Manipulation|优化四足机器人的抓取：一种基于深度学习的位姿操作方法|Dilermando Almeida, Guilherme Lazzarini, Juliano Negri, Thiago H. Segreto, Ricardo V. Godoy, Marcelo Becker|<http://arxiv.org/pdf/2508.17466v2>|提出了一种基于深度学习的四足机器人抓取优化框架，通过模拟训练显著提升了抓取精度和适应性。|
|📝 更新|Cryo-RL: automating prostate cancer cryoablation planning with reinforcement learning|冷冻消融自动化规划：利用强化学习进行前列腺癌冷冻消融治疗|Trixia Simangan, Ahmed Nadeem Abbasi, Yipeng Hu, Shaheer U. Saeed|<http://arxiv.org/pdf/2509.04886v2>|提出了一种基于强化学习的自动化前列腺癌冷冻消融规划方法，提高了肿瘤覆盖率和规划效率。|
|🆕 发布|Fairness Without Labels: Pseudo-Balancing for Bias Mitigation in Face Gender Classification|无标签公平性：伪平衡法用于人脸性别分类中的偏见缓解|Haohua Dong, Ana Manzano Rodríguez, Camille Guinaudeau, Shin'ichi Satoh|<http://arxiv.org/pdf/2510.10191v1>|提出 pseudo-balancing 方法，通过在无标签数据上强制人口平衡，有效减少人脸性别分类中...|
|🆕 发布|B2N3D: Progressive Learning from Binary to N-ary Relationships for 3D Object Grounding|从二进制到N元关系的三维物体定位渐进学习：B2N3D|Feng Xiao, Hongbin Xu, Hai Ci, Wenxiong Kang|<http://arxiv.org/pdf/2510.10194v1>|提出了一种从二进制到多元关系的渐进式学习方法，用于三维物体定位，有效提升了多模态关系理解能力。|
|🆕 发布|Dejavu: Post-Deployment Learning for Embodied Agents via Experience Feedback|“dejavu：通过经验反馈实现具身智能体部署后学习”|Shaokai Wu, Yanbiao Ji, Qiuchang Li, Zhiyi Zhang, Qichen He, Wenyuan Xie, Guodong Zhang, Bayram Bayramli .etc.|<http://arxiv.org/pdf/2510.10181v1>|提出了一种名为Dejavu的框架，通过经验反馈网络使部署后的实体智能体能够学习并优化行为表现。|
|🆕 发布|Uncertainty-Aware Post-Detection Framework for Enhanced Fire and Smoke Detection in Compact Deep Learning Models|具有不确定性感知的后检测框架以提高紧凑深度学习模型中火焰和烟雾检测的性能|Aniruddha Srinivas Joshi, Godwyn James William, Shreyas Srinivas Joshi|<http://arxiv.org/pdf/2510.10108v1>|提出了一种考虑不确定性的后检测框架，通过结合统计不确定性和视觉线索调整置信度，提高了紧凑型深度学习模...|
|🆕 发布|Cooperative Pseudo Labeling for Unsupervised Federated Classification|合作伪标签法用于无监督联邦分类|Kuangpu Guo, Lijun Sheng, Yongcan Yu, Jian Liang, Zilei Wang, Ran He|<http://arxiv.org/pdf/2510.10100v1>|[代码](https://github.com/krumpguo/FedCoPL); 首次将CLIP模型应用于联邦学习中的无监督分类问题，提出FedCoPL方法，通过伪标签合作改善性能。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ArtPerception: ASCII Art-based Jailbreak on LLMs with Recognition Pre-test|艺术感知：基于ASCII艺术的LLM越狱与识别预测试|Guan-Yan Yang, Tzu-Yu Cheng, Ya-Wen Teng, Farn Wanga, Kuo-Hui Yeh|<http://arxiv.org/pdf/2510.10281v1>|提出了一种利用ASCII艺术绕过大型语言模型安全措施的系统性攻击框架，通过预测试优化攻击策略。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Vision-Based Shared-Control Teleoperation Scheme for Controlling the Robotic Arm of a Four-Legged Robot|基于视觉的共享控制远程操作方案：用于控制四足机器人的机械臂|Murilo Vinicius da Silva, Matheus Hipolito Carvalho, Juliano Negri, Thiago Segreto, Gustavo J. G. Lahr, Ricardo V. Godoy, Marcelo Becker|<http://arxiv.org/pdf/2508.14994v2>|提出了一种基于视觉的共享控制远程操作方案，将人类手臂动作映射至四足机器人机械臂，实现直观且安全的实时...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|The Visual Iconicity Challenge: Evaluating Vision-Language Models on Sign Language Form-Meaning Mapping|视觉图标性挑战：评估视觉-语言模型在手语形式-意义映射上的表现|Onur Keleş, Aslı Özyürek, Gerardo Ortega, Kadir Gökgöz, Esam Ghaleb|<http://arxiv.org/pdf/2510.08482v2>|提出视觉图标性挑战，评估视觉语言模型在动态手势语言中的形式与意义映射能力。|
|📝 更新|CoRGI: Verified Chain-of-Thought Reasoning with Post-hoc Visual Grounding|CoRGI：带有后处理视觉定位的验证链式思维推理|Shixin Yi, Lin Shang|<http://arxiv.org/pdf/2508.00378v2>|提出了一种后验视觉验证框架CoRGI，有效减少视觉语言模型推理中的虚构现象，提高答案准确性和解释忠实...|
|📝 更新|Learning to Instruct for Visual Instruction Tuning|学习指导视觉指令微调|Zhihan Zhou, Feng Hong, Jiaan Luo, Jiangchao Yao, Dongsheng Li, Bo Han, Ya Zhang, Yanfeng Wang|<http://arxiv.org/pdf/2503.22215v2>|[代码](https://github.com/Feng-Hong/L2T.); 提出L2T方法，通过融合指令与响应序列的损失函数，有效避免视觉指令调优中的过拟合和捷径学习，显著提升...|
|📝 更新|CLIP-IN: Enhancing Fine-Grained Visual Understanding in CLIP via Instruction Editing Data and Long Captions|CLIP-IN：通过指令编辑数据与长注释增强CLIP的细粒度视觉理解|Ziteng Wang, Siqi Yang, Limeng Qiao, Lin Ma|<http://arxiv.org/pdf/2508.02329v3>|CLIP-IN通过利用指令编辑数据和长描述性字幕，显著提升了视觉语言模型对细粒度视觉理解的性能。|
|🆕 发布|Q-Adapter: Visual Query Adapter for Extracting Textually-related Features in Video Captioning|Q-Adapter：视频字幕中提取文本相关特征的视觉查询适配器|Junan Chen, Trung Thanh Nguyen, Takahiro Komamizu, Ichiro Ide|<http://arxiv.org/pdf/2510.10022v1>|提出了一种轻量级视觉适配器Q-Adapter，通过有效提取视频中的相关视觉特征，实现了参数高效的视频...|
|📝 更新|Jigsaw-R1: A Study of Rule-based Visual Reinforcement Learning with Jigsaw Puzzles|拼图R1：基于规则的视觉强化学习研究与应用拼图游戏|Zifu Wang, Junyi Zhu, Bo Tang, Zhiyu Li, Feiyu Xiong, Jiaqian Yu, Matthew B. Blaschko|<http://arxiv.org/pdf/2505.23590v3>|[代码](https://github.com/zifuwanggg/Jigsaw-R1); 研究了基于规则的视觉强化学习在拼图任务上的表现，揭示了模型在泛化和推理过程中的特性。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TCMA: Text-Conditioned Multi-granularity Alignment for Drone Cross-Modal Text-Video Retrieval|TCMA：基于文本条件的多粒度对齐用于无人机跨模态文本-视频检索|Zixu Zhao, Yang Zhan|<http://arxiv.org/pdf/2510.10180v1>|提出无人机跨模态文本-视频检索的新框架TCMA，通过多粒度对齐提升检索性能。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Ordinal Scale Traffic Congestion Classification with Multi-Modal Vision-Language and Motion Analysis|基于多模态视觉-语言与运动分析的序数尺度交通拥堵分类|Yu-Hsuan Lin|<http://arxiv.org/pdf/2510.10342v1>|提出了一种融合视觉语言推理、物体检测和运动分析的多模态框架，实现了对交通拥堵水平的有效分类。|
|🆕 发布|MRI Brain Tumor Detection with Computer Vision|计算机视觉辅助的MRI脑肿瘤检测|Jack Krolik, Jake Lynn, John Henry Rudden, Dmytro Vremenko|<http://arxiv.org/pdf/2510.10250v1>|利用深度学习技术提升MRI脑肿瘤检测的准确性和效率。|
|🆕 发布|Scaling Traffic Insights with AI and Language Model-Powered Camera Systems for Data-Driven Transportation Decision Making|利用人工智能和语言模型驱动的摄像系统扩展交通洞察，以支持基于数据驱动的交通决策|Fan Zuo, Donglin Zhou, Jingqin Gao, Kaan Ozbay|<http://arxiv.org/pdf/2510.09981v1>|提出了一种利用现有交通摄像头和大规模语言模型进行实时交通监测与分析的端到端AI框架，有效降低人力成本...|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Lightweight Joint Optimization of General-Purpose Vision-Language Models and Retrievers for RAG-Based Medical Diagnosis|轻量级通用视觉语言模型与检索器联合优化，用于基于RAG的医疗诊断|Nir Mazor, Tom Hope|<http://arxiv.org/pdf/2508.17394v3>|[代码](https://github.com/Nirmaz/JOMED.); 提出了一种联合优化通用视觉语言模型和检索器的轻量级方法，用于提高医疗诊断的准确性。|
|🆕 发布|Are Video Models Emerging as Zero-Shot Learners and Reasoners in Medical Imaging?|视频模型是否正在成为医学成像中的零样本学习者和推理者？|Yuxiang Lai, Jike Zhong, Ming Li, Yuheng Li, Xiaofeng Yang|<http://arxiv.org/pdf/2510.10254v1>|探究了大型视觉模型在未训练医疗数据上的零样本学习与推理能力，实现医疗影像任务上的出色表现。|
|🆕 发布|A Style-Based Metric for Quantifying the Synthetic-to-Real Gap in Autonomous Driving Image Datasets|一种基于风格的度量方法，用于量化自动驾驶图像数据集中的合成到现实差距|Dingyi Yao, Xinyao Han, Ruibo Ming, Zhihang Song, Lihui Peng, Jianming Hu, Danya Yao, Yi Zhang|<http://arxiv.org/pdf/2510.10203v1>|提出了一种量化自动驾驶图像数据集中合成与真实差距的系统框架和评价指标SEDD。|
|📝 更新|Multimodal Alignment and Fusion: A Survey|多模态对齐与融合：综述|Songtao Li, Hao Tang|<http://arxiv.org/pdf/2411.17040v2>|系统梳理了多模态对齐与融合技术，提出结构化和方法驱动的框架，提升多模态学习系统的通用性和效率。|
|🆕 发布|ViConEx-Med: Visual Concept Explainability via Multi-Concept Token Transformer for Medical Image Analysis|ViConEx-Med：通过多概念标记转换器实现医学图像分析的可视化概念解释性|Cristiano Patrício, Luís F. Teixeira, João C. Neves|<http://arxiv.org/pdf/2510.10174v1>|[代码](https://github.com/CristianoPatricio/viconex-med.); 提出了一种基于多概念学习令牌的视觉概念解释性框架ViConEx-Med，实现了高精度预测与概念定位。|
|🆕 发布|Stroke Locus Net: Occluded Vessel Localization from MRI Modalities|《笔画轨迹网：从MRI模态中定位遮挡血管》|Mohamed Hamad, Muhammad Khan, Tamer Khattab, Mohamed Mabrok|<http://arxiv.org/pdf/2510.10155v1>|提出了一种端到端深度学习系统Stroke Locus Net，通过MRI扫描实现阻塞血管的精准定位，...|
|🆕 发布|Think Twice to See More: Iterative Visual Reasoning in Medical VLMs|“三思而后见：医学视觉语言模型中的迭代视觉推理”|Kaitao Chen, Shaohao Rui, Yankai Jiang, Jiamin Wu, Qihao Zheng, Chunfeng Song, Xiaosong Wang, Mu Zhou .etc.|<http://arxiv.org/pdf/2510.10052v1>|提出迭代视觉推理框架ViTAR，模仿人类专家诊断过程中的多步骤思考，提升医学视觉语言模型的诊断性能和...|
|📝 更新|Automated detection of underdiagnosed medical conditions via opportunistic imaging|通过机会性成像自动检测未被充分诊断的医学状况|Asad Aali, Andrew Johnston, Louis Blankemeier, Dave Van Veen, Laura T Derry, David Svec, Jason Hom, Robert D. Boutin .etc.|<http://arxiv.org/pdf/2409.11686v5>|利用深度学习分析常规CT图像，提高未充分诊断疾病的检测准确性和临床记录完整性。|
|📝 更新|A Lightweight and Robust Framework for Real-Time Colorectal Polyp Detection Using LOF-Based Preprocessing and YOLO-v11n|一种基于LOF预处理和YOLO-v11n的实时结直肠癌变息肉检测轻量级鲁棒框架|Saadat Behzadi, Danial Sharifrazi, Bita Mesbahzadeh, Javad Hassannataj Joloudari, Roohallah Alizadehsani|<http://arxiv.org/pdf/2507.10864v3>|提出了一种结合LOF算法和YOLO-v11n模型的实时结直肠息肉检测框架，提升了检测准确性和效率。|
|📝 更新|SatDreamer360: Multiview-Consistent Generation of Ground-Level Scenes from Satellite Imagery|“SatDreamer360：从卫星图像生成地面场景的多视角一致性生成”|Xianghui Ze, Beiyi Zhu, Zhenbo Song, Jianfeng Lu, Yujiao Shi|<http://arxiv.org/pdf/2506.00600v2>|提出SatDreamer360框架，从单张卫星图像生成几何一致的多视角地面全景图。|
|🆕 发布|J-RAS: Enhancing Medical Image Segmentation via Retrieval-Augmented Joint Training|J-RAS: 通过检索增强的联合训练提升医学图像分割|Salma J. Ahmed, Emad A. Mohammed, Azam Asilian Bidgoli|<http://arxiv.org/pdf/2510.09953v1>|提出了一种结合检索增强的医学图像分割方法J-RAS，通过联合训练提升模型对复杂病例的泛化能力。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output|MIMO：一种具有视觉参照多模态输入与像素定位多模态输出的医学视觉语言模型|Yanyuan Chen, Dexuan Xu, Yu Huang, Songkun Zhan, Hanpin Wang, Dongxue Chen, Xueping Wang, Meikang Qiu .etc.|<http://arxiv.org/pdf/2510.10011v1>|提出MIMO模型，通过结合视觉线索和文本指令理解医学图像，并在输出中实现文本与图像关键区域的对应。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Investigating VLM Hallucination from a Cognitive Psychology Perspective: A First Step Toward Interpretation with Intriguing Observations|从认知心理学视角探究VLM幻觉：迈向解释性研究的初步探索及有趣观察|Xiangrui Liu, Man Luo, Agneet Chatterjee, Hua Wei, Chitta Baral, Yezhou Yang|<http://arxiv.org/pdf/2507.03123v2>|提出心理分类法分析视觉语言模型中的认知偏见，并设计AIpsych基准揭示模型行为倾向。|


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Revisit What You See: Disclose Language Prior in Vision Tokens for LVLM Decoding|重新审视你所见：在视觉标记中揭示语言先验以用于LVLM解码|Beomsik Cho, Jaehyung Kim|<http://arxiv.org/pdf/2506.09522v2>|提出了一种无需训练的解码方法ReVisiT，通过参考视觉信息提升大型视觉语言模型的文本生成准确性。|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Motion Capture from Inertial and Vision Sensors|从惯性测量单元和视觉传感器进行运动捕捉|Xiaodong Chen, Wu Liu, Qian Bao, Xinchen Liu, Ruoli Dai, Yongdong Zhang, Tao Mei|<http://arxiv.org/pdf/2407.16341v3>|提出MINIONS多模态运动捕捉数据集，并利用 SparseNet 框架实现低成本运动捕捉。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|TC-GS: A Faster Gaussian Splatting Module Utilizing Tensor Cores|TC-GS:一种利用张量核心的快速高斯散点模块|Zimu Liao, Jifeng Ding, Siwei Cui, Ruixuan Gong, Boni Hu, Yi Wang, Hengjie Li, XIngcheng Zhang .etc.|<http://arxiv.org/pdf/2505.24796v2>|提出TC-GS模块，利用Tensor Core优化3D Gaussian Splatting计算，实...|

