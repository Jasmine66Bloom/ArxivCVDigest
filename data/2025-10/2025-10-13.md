## [UPDATED!] **2025-10-13** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Scaling Language-Centric Omnimodal Representation Learning|扩展以语言为中心的全模态表征学习|Chenghao Xiao, Hou Pong Chan, Hao Zhang, Weiwen Xu, Mahani Aljunied, Yu Rong|<http://arxiv.org/pdf/2510.11693v1>|[代码](https://github.com/LCO-Embedding/LCO-Embedding.); 提出了一种语言中心的多模态嵌入框架LCO-Emb，通过增强生成能力显著提升表示质量。|
|📝 更新|Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models|视频LMM后训练：深入探索大型多模态模型在视频推理中的应用|Yolo Yunlong Tang, Jing Bi, Pinxin Liu, Zhenyu Pan, Zhangyun Tan, Qianxiang Shen, Jiani Liu, Hang Hua .etc.|<http://arxiv.org/pdf/2510.05034v4>|[代码](https://github.com/yunlong10/Awesome-Video-LMM-Post-Training); 系统梳理了视频理解中大型多模态模型的后训练方法，提升了模型推理能力和效率。|
|📝 更新|Holistic Evaluation of Multimodal LLMs on Spatial Intelligence|多模态大型语言模型在空间智能上的全面评估|Zhongang Cai, Yubo Wang, Qingping Sun, Ruisi Wang, Chenyang Gu, Wanqi Yin, Zhiqian Lin, Zhitao Yang .etc.|<http://arxiv.org/pdf/2508.13142v2>|提出全面的空间智能任务分类法，标准化评估领先多模态模型，揭示GPT-5在空间智能上的不足。|
|📝 更新|Towards Robust and Realible Multimodal Fake News Detection with Incomplete Modality|面向鲁棒与可靠的多模态虚假新闻检测：处理不完整模态问题|Hengyang Zhou, Yiwei Wei, Jian Yang, Zhenyu Zhang|<http://arxiv.org/pdf/2510.05839v2>|[代码](https://github.com/zhyhome/MMLNet.); 提出了一种针对信息缺失情况下的多模态虚假新闻检测方法MMLNet，通过多专家协作推理和自适应学习显著...|
|🆕 发布|FlexAC: Towards Flexible Control of Associative Reasoning in Multimodal Large Language Models|FlexAC：面向多模态大型语言模型中关联推理的灵活控制|Shengming Yuan, Xinyu Lyu, Shuailong Wang, Beitao Chen, Jingkuan Song, Lianli Gao|<http://arxiv.org/pdf/2510.11190v1>|[代码](https://github.com/ylhz/FlexAC.); 提出FlexAC框架，实现了对多模态大语言模型中联想推理灵活控制，提升了创造性和准确性。|
|🆕 发布|Connecting Giants: Synergistic Knowledge Transfer of Large Multimodal Models for Few-Shot Learning|连接巨擘：大型多模态模型在少样本学习中的协同知识迁移|Hao Tang, Shengfeng He, Jing Qin|<http://arxiv.org/pdf/2510.11115v1>|提出了一种协同知识迁移框架SynTrans，利用大型多模态模型的知识提升少量样本学习性能。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CodePlot-CoT: Mathematical Visual Reasoning by Thinking with Code-Driven Images|代码图-思维链：基于代码驱动图像的数学视觉推理|Chengqi Duan, Kaiyue Sun, Rongyao Fang, Manyuan Zhang, Yan Feng, Ying Luo, Yufang Liu, Ke Wang .etc.|<http://arxiv.org/pdf/2510.11718v1>|[代码](https://github.com/HKU-MMLab/Math-VR-CodePlot-CoT.); 提出了一种代码驱动的数学视觉推理方法CodePlot-CoT，通过生成图像辅助解决数学问题。|
|📝 更新|Q-Router: Agentic Video Quality Assessment with Expert Model Routing and Artifact Localization|Q-Router：基于专家模型路由和瑕疵定位的代理视频质量评估|Shuo Xing, Soumik Dey, Mingyang Wu, Ashirbad Mishra, Naveen Ravipati, Binbin Li, Hansi Wu, Zhengzhong Tu|<http://arxiv.org/pdf/2510.08789v2>|提出Q-Router框架，通过多模型动态组合提升视频质量评估的泛化能力与解释性。|
|📝 更新|ViDRiP-LLaVA: A Dataset and Benchmark for Diagnostic Reasoning from Pathology Videos|ViDRiP-LLaVA：用于病理视频诊断推理的数据库与基准测试|Trinh T. L. Vuong, Jin Tae Kwak|<http://arxiv.org/pdf/2505.04192v2>|[代码](https://github.com/QuIIL/ViDRiP-LLaVA.); 提出了ViDRiP-LLaVA，首个融合三种图像场景的大型多模态模型，为病理视频诊断推理提供新基准。|
|🆕 发布|How many samples to label for an application given a foundation model? Chest X-ray classification study|给定基础模型的应用需要标注多少样本？胸部X射线分类研究|Nikolay Nechaev, Evgenia Przhezdzetskaya, Viktor Gombolevskiy, Dmitry Umerenkov, Dmitry Dylov|<http://arxiv.org/pdf/2510.11553v1>|通过使用少量标注样本的幂律拟合预测，实现了降低胸部X光分类标注数据需求的方法。|
|🆕 发布|AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model|《AndesVL技术报告：一种高效移动端多模态大型语言模型》|Zhiwei Jin, Xiaohui Song, Nan Wang, Yafei Liu, Chao Li, Xin Li, Ruichen Wang, Zhihao Li .etc.|<http://arxiv.org/pdf/2510.11496v1>|介绍了AndesVL，一种参数规模在0.6B至4B的移动端多模态大语言模型，实现了与现有大型模型相当...|
|🆕 发布|Situat3DChange: Situated 3D Change Understanding Dataset for Multimodal Large Language Model|《Situat3DChange：面向多模态大型语言模型的情境化三维变化理解数据集》|Ruiping Liu, Junwei Zheng, Yufan Chen, Zirui Wang, Kunyu Peng, Kailun Yang, Jiaming Zhang, Marc Pollefeys .etc.|<http://arxiv.org/pdf/2510.11509v1>|提出了Situat3DChange数据集，通过融合多模态信息，提升了大型语言模型对动态环境变化的感知...|
|📝 更新|Surface-Aware Distilled 3D Semantic Features|表面感知的三维语义特征蒸馏|Lukas Uzolas, Elmar Eisemann, Petr Kellnhofer|<http://arxiv.org/pdf/2503.18254v2>|提出了一种自监督学习表面感知的3D语义特征嵌入方法，有效区分相同语义类别的实例并提高3D形状匹配准确...|
|🆕 发布|InternSVG: Towards Unified SVG Tasks with Multimodal Large Language Models|面向统一SVG任务的多模态大型语言模型：InternSVG|Haomin Wang, Jinhui Yin, Qi Wei, Wenguang Zeng, Lixin Gu, Shenglong Ye, Zhangwei Gao, Yaohui Wang .etc.|<http://arxiv.org/pdf/2510.11341v1>|利用多模态大型语言模型的强大迁移性，实现了SVG任务统一建模和理解。|
|🆕 发布|BLEnD-Vis: Benchmarking Multimodal Cultural Understanding in Vision Language Models|BLEnD-Vis：视觉语言模型中多模态文化理解基准测试|Bryan Chen Zhengyu Tan, Zheng Weihua, Zhengyuan Liu, Nancy F. Chen, Hwaran Lee, Kenny Tsu Wei Choo, Roy Ka-Wei Lee|<http://arxiv.org/pdf/2510.11178v1>|提出了一种评估视觉语言模型跨文化理解能力的多模态基准，揭示了模型在文化知识和跨模态整合方面的脆弱性。|
|📝 更新|Muddit: Liberating Generation Beyond Text-to-Image with a Unified Discrete Diffusion Model|Muddit：用统一离散扩散模型超越文本到图像生成的解放|Qingyu Shi, Jinbin Bai, Zhuoran Zhao, Wenhao Chai, Kaidong Yu, Jianzong Wu, Shuangyong Song, Yunhai Tong .etc.|<http://arxiv.org/pdf/2505.23606v2>|提出了一种融合预训练视觉先验的统一离散扩散模型Muddit，实现了快速高效的多模态生成。|
|🆕 发布|Multimodal Disease Progression Modeling via Spatiotemporal Disentanglement and Multiscale Alignment|通过时空解耦与多尺度对齐的多模态疾病进展建模|Chen Liu, Wenfang Yao, Kejing Yin, William K. Cheung, Jing Qin|<http://arxiv.org/pdf/2510.11112v1>|提出了一种框架DiPro，通过区域感知解耦和多尺度对齐，有效处理疾病进展的长期多模态数据。|
|📝 更新|BabyVLM: Data-Efficient Pretraining of VLMs Inspired by Infant Learning|婴儿视觉语言模型：受婴儿学习启发的数据高效预训练方法|Shengao Wang, Arjun Chandra, Aoming Liu, Venkatesh Saligrama, Boqing Gong|<http://arxiv.org/pdf/2504.09426v2>|提出了一种模拟婴儿学习方式的 BabyVLM 框架，通过合成数据集实现了高效预训练视觉语言模型。|
|🆕 发布|Benchmarking Deep Learning Models for Laryngeal Cancer Staging Using the LaryngealCT Dataset|使用LaryngealCT数据集对深度学习模型在喉癌分期中的性能评估|Nivea Roy, Son Tran, Atul Sajjanhar, K. Devaraja, Prakashini Koteshwara, Yong Xiang, Divya Rao|<http://arxiv.org/pdf/2510.11047v1>|该研究构建了LaryngealCT标准化数据集，并对比了多种3D深度学习模型在喉癌分期中的应用效果。|
|🆕 发布|Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning|“Vlaser：具有协同具身推理的视觉-语言-动作模型”|Ganlin Yang, Tianyi Zhang, Haoran Hao, Weiyun Wang, Yibin Liu, Dehui Wang, Guanzhou Chen, Zijian Cai .etc.|<http://arxiv.org/pdf/2510.11027v1>|提出了Vlaser模型，通过融合高级推理与低级控制，有效桥接了视觉语言模型与机器人控制之间的差距。|
|🆕 发布|A Survey on Agentic Multimodal Large Language Models|《关于代理型多模态大型语言模型的综述》|Huanjin Yao, Ruifei Zhang, Jiaxing Huang, Jingyi Zhang, Yibo Wang, Bo Fang, Ruolin Zhu, Yongcheng Jing .etc.|<http://arxiv.org/pdf/2510.10991v1>|[代码](https://github.com/HJYao00/Awesome-Agentic-MLLMs.); 系统性地调研了具有自主性和多模态功能的大型语言模型，构建了评估和发展的框架。|
|🆕 发布|FG-CLIP 2: A Bilingual Fine-grained Vision-Language Alignment Model|FG-CLIP 2：一种双语的细粒度视觉-语言对齐模型|Chunyu Xie, Bin Wang, Fanjing Kong, Jincheng Li, Dawei Liang, Ji Ao, Dawei Leng, Yuhui Yin|<http://arxiv.org/pdf/2510.10921v1>|FG-CLIP 2通过融合丰富细粒度监督和对比损失，实现了中英双语细粒度视觉语言对齐的性能提升。|
|📝 更新|TalkCuts: A Large-Scale Dataset for Multi-Shot Human Speech Video Generation|《TalkCuts：用于多镜头人类语音视频生成的大规模数据集》|Jiaben Chen, Zixin Wang, Ailing Zeng, Yang Fu, Xueyang Yu, Siyuan Cen, Julian Tanke, Yihang Chen .etc.|<http://arxiv.org/pdf/2510.07249v2>|提出了TalkCuts大规模数据集，用于生成多镜头人类言语视频，提升了视频的连贯性和视觉吸引力。|
|🆕 发布|Where on Earth? A Vision-Language Benchmark for Probing Model Geolocation Skills Across Scales|《地球上的何处？一个用于探测模型在不同尺度上地理定位技能的视觉-语言基准》|Zhaofang Qian, Hardy Chen, Zeyu Wang, Li Zhang, Zijun Wang, Xiaoke Huang, Hui Liu, Xianfeng Tang .etc.|<http://arxiv.org/pdf/2510.10880v1>|[代码](https://github.com/UCSC-VLAA/EarthWhere.); 提出EarthWhere基准，评估视觉模型在开放世界中进行图像定位的能力，并揭示了模型在推理和搜索中...|
|📝 更新|Precise Mobile Manipulation of Small Everyday Objects|小型日常物体的精确移动操作|Arjun Gupta, Rishik Sathua, Saurabh Gupta|<http://arxiv.org/pdf/2502.13964v2>|提出Servoing with Vision Models (SVM)框架，利用视觉模型实现移动机械...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Beyond 'Templates': Category-Agnostic Object Pose, Size, and Shape Estimation from a Single View|超越“模板”：从单视角进行类别无关的对象姿态、尺寸和形状估计|Jinyu Zhang, Haitao Lin, Jiashu Hou, Xiangyang Xue, Yanwei Fu|<http://arxiv.org/pdf/2510.11687v1>|提出了一种无需模板或CAD模型的通用框架，实现了从单张RGB-D图像同时预测物体的6D姿态、尺寸和形...|
|🆕 发布|Benchmarking foundation models for hyperspectral image classification: Application to cereal crop type mapping|高光谱图像分类基准模型评估：应用于谷物作物类型映射|Walid Elbarz, Mohamed Bourriz, Hicham Hajji, Hamd Ait Abdelali, François Bourzeix|<http://arxiv.org/pdf/2510.11576v1>|评估了三种基础模型在小麦作物分类中的应用，发现SpectralEarth模型在超光谱图像分类上效果最...|
|📝 更新|Isolated Channel Vision Transformers: From Single-Channel Pretraining to Multi-Channel Finetuning|孤立通道视觉变换器：从单通道预训练到多通道微调|Wenyi Lian, Patrick Micke, Joakim Lindblad, Nataša Sladoje|<http://arxiv.org/pdf/2503.09826v2>|[代码](https://github.com/shermanlian/IC-ViT.); 提出了一种针对多通道成像数据的有效预训练框架，通过单独处理图像通道提高多模态任务性能。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|NV3D: Leveraging Spatial Shape Through Normal Vector-based 3D Object Detection|基于法向量三维物体检测的NV3D：利用空间形状信息|Krittin Chaowakarn, Paramin Sangwongngam, Nang Htet Htet Aung, Chalie Charoenlarpnopparut|<http://arxiv.org/pdf/2510.11632v1>|NV3D通过利用基于体素邻居的法向量特征，提高了自动驾驶中3D物体检测的准确性和效率。|
|🆕 发布|Enhancing Maritime Domain Awareness on Inland Waterways: A YOLO-Based Fusion of Satellite and AIS for Vessel Characterization|增强内河领域意识：基于YOLO的卫星与AIS数据融合船舶特征提取|Geoffery Agorku, Sarah Hernandez, Hayley Hames, Cade Wagner|<http://arxiv.org/pdf/2510.11449v1>|融合卫星图像与AIS数据，提升内河船舶监测能力，实现实时船队清单与异常检测。|
|🆕 发布|When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models|监督训练何时值得？视觉语言模型时代目标检测背后的隐藏经济学|Samer Al-Hamadani|<http://arxiv.org/pdf/2510.11302v1>|分析了监督学习和零样本学习在目标检测中的成本效益，提供了决策框架以优化架构选择。|
|🆕 发布|A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images|扫描电子显微镜图像的大语言模型辅助自动化比例尺检测与提取框架|Yuxuan Chen, Ruotong Yang, Zhengyang Zhang, Mehreen Ahmed, Yanming Wang|<http://arxiv.org/pdf/2510.11260v1>|提出了一种大语言模型辅助的自动化尺度条检测与提取框架，提高了扫描电子显微镜图像分析的效率和准确性。|
|📝 更新|RoHOI: Robustness Benchmark for Human-Object Interaction Detection|RoHOI：用于人类-物体交互检测的鲁棒性基准|Di Wen, Kunyu Peng, Kailun Yang, Yufan Chen, Ruiping Liu, Junwei Zheng, Alina Roitberg, Danda Pani Paudel .etc.|<http://arxiv.org/pdf/2507.09111v3>|[代码](https://github.com/KratosWen/RoHOI.); 提出了RoHOI基准，评估并提升了人类-物体交互检测模型在复杂环境下的鲁棒性。|
|🆕 发布|LSVOS 2025 Challenge Report: Recent Advances in Complex Video Object Segmentation|《LSVOS 2025挑战报告：复杂视频目标分割的最新进展》|Chang Liu, Henghui Ding, Kaining Ying, Lingyi Hong, Ning Xu, Linjie Yang, Yuchen Fan, Mingqi Gao .etc.|<http://arxiv.org/pdf/2510.11063v1>|介绍了2025年LSVOS挑战赛的进展，引入更复杂的视频场景以提升长期一致性和泛化能力。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SWIFT: Semantic Watermarking for Image Forgery Thwarting|SWIFT：用于图像伪造防范的语义水印技术|Gautier Evennou, Vivien Chappelier, Ewa Kijak, Teddy Furon|<http://arxiv.org/pdf/2407.18995v2>|提出了一种利用水印技术嵌入语义信息进行图像认证和篡改检测的新方法，大幅提升了鲁棒性并增强了实际应用性...|
|🆕 发布|Validation of an Artificial Intelligence Tool for the Detection of Sperm DNA Fragmentation Using the TUNEL In Situ Hybridization Assay|"使用TUNEL原位杂交技术检测精子DNA片段的人工智能工具验证"|Byron Alexander Jacobs, Aqeel Morris, Ifthakaar Shaik, Frando Lin|<http://arxiv.org/pdf/2510.11142v1>|验证了一种结合图像处理和机器学习模型的人工智能工具，用于通过相衬显微镜图像检测精子DNA碎片化。|
|🆕 发布|Lightweight Facial Landmark Detection in Thermal Images via Multi-Level Cross-Modal Knowledge Transfer|通过多级跨模态知识迁移实现热图像中的轻量级面部特征点检测|Qiyi Tong, Olivia Nocentini, Marta Lagomarsino, Kuanqi Cai, Marta Lorenzini, Arash Ajoudani|<http://arxiv.org/pdf/2510.11128v1>|提出了一种多级跨模态知识蒸馏框架，有效提升了热成像面部特征点检测的准确性和效率。|
|🆕 发布|High-Resolution Spatiotemporal Modeling with Global-Local State Space Models for Video-Based Human Pose Estimation|基于全局-局部状态空间模型的高分辨率时空建模用于视频人体姿态估计|Runyang Feng, Hyung Jin Chang, Tze Ho Elden Tse, Boeun Kim, Yi Chang, Yixing Gao|<http://arxiv.org/pdf/2510.11017v1>|提出了一种全局-局部状态空间模型，有效平衡视频人体姿态估计中的全局动态和局部细节处理。|
|📝 更新|LSP-ST: Ladder Shape-Biased Side-Tuning for Robust Infrared Small Target Detection|LSP-ST：基于梯形偏置的侧向调谐算法用于稳健的红外小目标检测|Guoyi Zhang, Siyang Chen, Guangsheng Xu, Han Wang, Donghe Wang, Xiaohu Zhang|<http://arxiv.org/pdf/2504.14481v2>|提出了一种全局形状感知的侧调方法LSP-ST，有效应对红外小目标检测中的领域差异问题，实现最优性能。|
|🆕 发布|DKPMV: Dense Keypoints Fusion from Multi-View RGB Frames for 6D Pose Estimation of Textureless Objects|DKPMV：基于多视角RGB帧的密集关键点融合用于无纹理物体的6D位姿估计|Jiahong Chen, Jinghao Wang, Zi Wang, Ziwen Wang, Banglei Guan, Qifeng Yu|<http://arxiv.org/pdf/2510.10933v1>|提出了一种仅使用多视角RGB图像进行稠密关键点融合的6D位姿估计方法，通过三阶段优化策略和对称性训练...|
|🆕 发布|rareboost3d: a synthetic lidar dataset with enhanced rare classes|“RareBoost3D：一种增强稀有类别的合成激光雷达数据集”|Shutong Lin, Zhengkang Xiang, Jianzhong Qi, Kourosh Khoshelham|<http://arxiv.org/pdf/2510.10876v1>|提出合成点云数据集RareBoost3D解决长尾问题，并引入CSC损失实现跨域特征对齐提升LiDAR...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multiview Manifold Evidential Fusion for PolSAR Image Classification|多视角流形证据融合用于极化合成孔径雷达图像分类|Junfei Shi, Haojia Zhang, Haiyan Jin, Junhuai Li, Xiaogang Song, Yuanfan Guo, Haonan Su, Weisi Lin|<http://arxiv.org/pdf/2510.11171v1>|提出了一种多视角证据融合方法，有效融合PolSAR图像的协方差矩阵和多种特征，提高了分类准确性和鲁棒...|
|📝 更新|Open Vocabulary Multi-Label Video Classification|开放词汇多标签视频分类|Rohit Gupta, Mamshad Nayeem Rizve, Jayakrishnan Unnikrishnan, Ashish Tawari, Son Tran, Mubarak Shah, Benjamin Yao, Trishul Chilimbi|<http://arxiv.org/pdf/2407.09073v2>|提出了一种结合大型语言模型指导的预训练视觉语言模型，实现了视频中的多标签开放词汇分类。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Point Prompting: Counterfactual Tracking with Video Diffusion Models|点提示：基于视频扩散模型的反事实跟踪|Ayush Shrivastava, Sanyam Mehta, Daniel Geng, Andrew Owens|<http://arxiv.org/pdf/2510.11715v1>|提出利用预训练视频扩散模型通过视觉标记点实现零样本点追踪，性能优于先前零样本方法。|
|🆕 发布|DiT360: High-Fidelity Panoramic Image Generation via Hybrid Training|DiT360：通过混合训练实现高保真全景图像生成|Haoran Feng, Dizhe Zhang, Xiangtai Li, Bo Du, Lu Qi|<http://arxiv.org/pdf/2510.11712v1>|[代码](https://github.com/Insta360-Research-Team/DiT360.); 提出DiT360框架，通过融合透视和全景数据进行训练，显著提升了全景图像的几何保真度和真实感。|
|🆕 发布|InfiniHuman: Infinite 3D Human Creation with Precise Control|无限人类：具有精确控制的无限三维人类创建|Yuxuan Xue, Xianghui Xie, Margaret Kostyrko, Gerard Pons-Moll|<http://arxiv.org/pdf/2510.11650v1>|分类|
|🆕 发布|EvoCAD: Evolutionary CAD Code Generation with Vision Language Models|EvoCAD：基于视觉语言模型的进化式CAD代码生成|Tobias Preintner, Weixuan Yuan, Adrian König, Thomas Bäck, Elena Raponi, Niki van Stein|<http://arxiv.org/pdf/2510.11631v1>|提出EvoCAD方法，结合视觉语言模型与进化算法生成CAD对象，提升拓扑正确性。|
|📝 更新|SyncHuman: Synchronizing 2D and 3D Generative Models for Single-view Human Reconstruction|SyncHuman：同步2D和3D生成模型以实现单视角人体重建|Wenyue Chen, Peng Li, Wangguandong Zheng, Chengfeng Zhao, Mengfei Li, Yaolong Zhu, Zhiyang Dou, Ronggang Wang .etc.|<http://arxiv.org/pdf/2510.07723v2>|提出了一种结合2D多视角生成模型和3D原生生成模型的SyncHuman框架，实现了单视角下高质量着装...|
|🆕 发布|ACE-G: Improving Generalization of Scene Coordinate Regression Through Query Pre-Training|ACE-G：通过查询预训练提高场景坐标回归泛化性|Leonard Bruns, Axel Barroso-Laguna, Tommaso Cavallari, Áron Monszpart, Sowmya Munukutla, Victor Adrian Prisacariu, Eric Brachmann|<http://arxiv.org/pdf/2510.11605v1>|提出了一种将坐标回归器与场景特定地图编码分离的方法，通过预训练提高场景坐标回归模型的泛化能力。|
|🆕 发布|A Framework for Low-Effort Training Data Generation for Urban Semantic Segmentation|城市语义分割的低成本训练数据生成框架|Denis Zavadski, Damjan Kalšan, Tim Küchler, Haebom Lee, Stefan Roth, Carsten Rother|<http://arxiv.org/pdf/2510.11567v1>|提出了一种利用扩散模型生成高保真度目标域对齐图像的框架，有效提升了城市场景语义分割的训练数据质量。|
|📝 更新|Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models|平衡匹配：隐式能量基模型的生成建模|Runqian Wang, Yilun Du|<http://arxiv.org/pdf/2510.02300v3>|引入了平衡匹配（EqM）生成模型框架，通过学习隐性能量景观的平衡梯度，优化了生成性能并扩展了应用范围...|
|📝 更新|Automatic Synthesis of High-Quality Triplet Data for Composed Image Retrieval|自动合成高质量三元组数据以用于组合图像检索|Haiwen Li, Delong Liu, Zhaohui Hou, Zhicheng Zhao, Fei Su|<http://arxiv.org/pdf/2507.05970v3>|提出自动生成高质量三元组数据的方法，用于提升组合图像检索的扩展性和零样本能力。|
|📝 更新|NeMo: Needle in a Montage for Video-Language Understanding|《NeMo：视频语言理解中的蒙太奇里的针》|Zi-Yuan Hu, Shuo Liang, Duo Zheng, Yanyang Li, Yeyao Tao, Shijia Huang, Wei Feng, Jia Qin .etc.|<http://arxiv.org/pdf/2509.24563v2>|[代码](https://lavi-lab.github.io/NeMoBench.); 提出NeMo任务和NeMoBench基准，评估视频语言模型的长时记忆和时序定位能力。|
|📝 更新|ID-Booth: Identity-consistent Face Generation with Diffusion Models|ID-Booth：基于扩散模型的身份一致性人脸生成|Darian Tomašević, Fadi Boutros, Chenhao Lin, Naser Damer, Vitomir Štruc, Peter Peer|<http://arxiv.org/pdf/2504.07392v6>|[代码](https://github.com/dariant/ID-Booth.); 提出了一种新的生成扩散框架ID-Booth，通过三元组身份训练目标实现了一致的身份图像生成并保持预训...|
|🆕 发布|Uncertainty-Aware ControlNet: Bridging Domain Gaps with Synthetic Image Generation|不确定性感知的ControlNet：通过合成图像生成桥接领域差距|Joshua Niemeijer, Jan Ehrhardt, Heinz Handels, Hristina Uzunova|<http://arxiv.org/pdf/2510.11346v1>|引入不确定性控制机制，利用无标签数据训练ControlNet，生成适应不同域的合成标注图像。|
|🆕 发布|sketch2symm: Symmetry-aware sketch-to-shape generation via semantic bridging|“sketch2symm：通过语义桥接实现对称感知的草图到形状生成”|Yan Zhou, Mingji Li, Xiantao Zeng, Jie Lin, Yuexia Zhou|<http://arxiv.org/pdf/2510.11303v1>|提出了一种两阶段对称感知的草图到形状生成方法，通过语义桥接增强稀疏草图表示，有效提升了3D形状重建的...|
|📝 更新|SANA-Video: Efficient Video Generation with Block Linear Diffusion Transformer|SANA-Video：基于块线性扩散变换的高效视频生成|Junsong Chen, Yuyang Zhao, Jincheng Yu, Ruihang Chu, Junyu Chen, Shuai Yang, Xianbang Wang, Yicheng Pan .etc.|<http://arxiv.org/pdf/2509.24695v2>|提出SANA-Video模型，通过线性注意力和常量内存缓存实现高效、高质量的长视频生成。|
|🆕 发布|MoMaps: Semantics-Aware Scene Motion Generation with Motion Maps|"MoMaps：具有运动地图的语义感知场景运动生成"|Jiahui Lei, Kyle Genova, George Kopanas, Noah Snavely, Leonidas Guibas|<http://arxiv.org/pdf/2510.11107v1>|提出了一种基于MoMap的3D场景运动预测方法，通过学习真实视频中的运动先验，实现了从单张图片预测未...|
|🆕 发布|Zero-shot Face Editing via ID-Attribute Decoupled Inversion|零样本人脸编辑：通过身份-属性解耦逆变换|Yang Hou, Minggu Wang, Jianjun Zhao|<http://arxiv.org/pdf/2510.11050v1>|提出了一种基于ID-属性解耦的零样本人脸编辑方法，实现了独立控制身份和属性，确保了编辑的一致性和精确...|
|📝 更新|STAR: A Benchmark for Astronomical Star Fields Super-Resolution|STAR：天文星场超分辨率基准|Kuo-Cheng Wu, Guohang Zhuang, Jinyang Huang, Xiang Zhang, Wanli Ouyang, Yan Lu|<http://arxiv.org/pdf/2507.16385v2>|[代码](https://github.com/GuoCheng12/STAR.); 提出STAR数据集，解决了天文超分辨率成像中的关键问题，并提出了准确预测高分辨率图像的FISR模型。|
|📝 更新|LaMoGen: Laban Movement-Guided Diffusion for Text-to-Motion Generation|拉班动作引导扩散：从文本到动作生成的模型|Heechang Kim, Gwanghyun Kim, Se Young Chun|<http://arxiv.org/pdf/2509.24469v2>|将Laban运动分析融入文本引导的运动生成模型，实现了无额外数据的高质量、多样化运动控制。|
|🆕 发布|ContextGen: Contextual Layout Anchoring for Identity-Consistent Multi-Instance Generation|上下文生成：基于上下文布局锚定的身份一致多实例生成|Ruihang Xu, Dewei Zhou, Fan Ma, Yi Yang|<http://arxiv.org/pdf/2510.11000v1>|提出ContextGen框架，通过布局引导和参考图像确保多实例生成中的位置精确和身份一致性。|
|🆕 发布|IUT-Plug: A Plug-in tool for Interleaved Image-Text Generation|"IUT-Plug: A Plug-in tool for Interleaved Image-Text Generation" 翻译成中文为：“IUT-插件：一种用于交织图像-文本生成的插件工具”|Zeteng Lin, Xingxing Li, Wen You, Xiaoyang Li, Zehan Lu, Yujun Cai, Jing Tang|<http://arxiv.org/pdf/2510.10969v1>|提出了一种基于图像理解树的IUT-Plug模块，通过显式结构化推理减少逻辑、实体身份和风格漂移，提升...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Diffusion Transformers with Representation Autoencoders|扩散变换器与表示自动编码器|Boyang Zheng, Nanye Ma, Shengbang Tong, Saining Xie|<http://arxiv.org/pdf/2510.11690v1>|提出使用预训练表示编码器替代传统VAE，提升扩散变换器的生成质量和效率。|
|🆕 发布|ODI-Bench: Can MLLMs Understand Immersive Omnidirectional Environments?|ODI-Bench：多模态大型语言模型能否理解沉浸式全方位环境？|Liu Yang, Huiyu Duan, Ran Tao, Juntao Cheng, Sijing Wu, Yunhao Li, Jing Liu, Xiongkuo Min .etc.|<http://arxiv.org/pdf/2510.11549v1>|提出了ODI-Bench基准，揭示了现有多模态大语言模型在理解全方位图像环境中的不足，并引入了Omn...|
|🆕 发布|LikePhys: Evaluating Intuitive Physics Understanding in Video Diffusion Models via Likelihood Preference|“通过似然偏好评估视频扩散模型中的直观物理理解：LikePhys”|Jianhao Yuan, Fabio Pizzati, Francesco Pinto, Lars Kunze, Ivan Laptev, Paul Newman, Philip Torr, Daniele De Martini|<http://arxiv.org/pdf/2510.11512v1>|提出了一种无训练需求的评价方法LikePhys，通过区分物理有效与不可能视频，准确评估视频扩散模型中...|
|📝 更新|Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion|量化扩散中的误差传播机制与补偿策略|Songwei Liu, Chao Zeng, Chenqian Yan, Xurui Peng, Xing Wang, Fangmin Chen, Xing Mei|<http://arxiv.org/pdf/2508.12094v2>|提出了一种针对量化误差传播的理论框架和补偿策略，有效提高了扩散模型图像合成的输出质量。|
|🆕 发布|Reasoning as Representation: Rethinking Visual Reinforcement Learning in Image Quality Assessment|推理即表征：重新思考图像质量评估中的视觉强化学习|Shijie Zhao, Xuanyu Zhang, Weiqi Li, Junlin Li, Li Zhang, Tianfan Xue, Jian Zhang|<http://arxiv.org/pdf/2510.11369v1>|提出RALI算法，通过对比学习直接将图像与强化学习得到的通用文本表示对齐，实现高效图像质量评估。|
|📝 更新|MRFD: Multi-Region Fusion Decoding with Self-Consistency for Mitigating Hallucinations in LVLMs|MRFD：基于自一致性多区域融合解码减轻LVLMs中的幻觉现象|Haonan Ge, Yiwei Wang, Ming-Hsuan Yang, Yujun Cai|<http://arxiv.org/pdf/2508.10264v2>|提出了一种无训练解码方法MRFD，通过建模区域间一致性显著减少视觉语言模型中的幻觉现象。|
|📝 更新|One Stone with Two Birds: A Null-Text-Null Frequency-Aware Diffusion Models for Text-Guided Image Inpainting|一石二鸟：面向文本引导图像修复的零文本零频率感知扩散模型|Haipeng Liu, Yang Wang, Meng Wang|<http://arxiv.org/pdf/2510.08273v3>|[代码](https://github.com/htyjers/NTN-Diff.); 提出了一种分解频率带的扩散模型NTN-Diff，通过分别处理不同频率实现文本引导的图像修复，同时保护...|
|📝 更新|VLMGuard-R1: Proactive Safety Alignment for VLMs via Reasoning-Driven Prompt Optimization|VLMGuard-R1：通过推理驱动的提示优化对大型视觉语言模型进行主动安全对齐|Menglan Chen, Xianghe Pang, Jingjing Dong, WenHao Wang, Yaxin Du, Siheng Chen|<http://arxiv.org/pdf/2504.12661v2>|提出了一种通过多模态推理引导的提示优化框架VLMGuard-R1，有效提升了视觉语言模型的安全性。|
|🆕 发布|Demystifying Numerosity in Diffusion Models -- Limitations and Remedies|《揭秘扩散模型中的数量效应 -- 局限性与解决策略》|Yaqi Zhao, Xiaochen Wang, Li Dong, Wentao Zhang, Yuhui Yuan|<http://arxiv.org/pdf/2510.11117v1>|发现扩散模型在计数任务上的局限性，并提出注入计数感知布局信息的方法来提高准确性。|
|🆕 发布|Source-Free Object Detection with Detection Transformer|无源目标检测与检测变换器|Huizai Yao, Sicheng Zhao, Shuo Lu, Hui Chen, Yangyang Li, Guoping Liu, Tengfei Xing, Chenggang Yan .etc.|<http://arxiv.org/pdf/2510.11090v1>|提出了一种针对 Detection Transformer 的无源域对象检测框架，通过特征重权和对比...|
|🆕 发布|CoDefend: Cross-Modal Collaborative Defense via Diffusion Purification and Prompt Optimization|CoDefend：通过扩散净化和提示优化实现的跨模态协同防御|Fengling Zhu, Boshi Liu, Jingyu Hua, Sheng Zhong|<http://arxiv.org/pdf/2510.11096v1>|提出了一种结合监督扩散去噪和提示优化的跨模态协同防御策略，有效增强了多模态大语言模型对视觉模态的攻击...|
|📝 更新|Context Guided Transformer Entropy Modeling for Video Compression|视频压缩中基于上下文的变换器熵模型指导|Junlong Tong, Wei Zhang, Yaohui Jin, Xiaoyu Shen|<http://arxiv.org/pdf/2508.01852v2>|提出了一种结合时空上下文的Context Guided Transformer熵模型，有效降低视频冗...|
|📝 更新|GDO:Gradual Domain Osmosis|渐变域渗透：GDO算法|Zixi Wang, Yubo Huang|<http://arxiv.org/pdf/2501.19159v3>|提出了一种渐进式领域渗透方法Gradual Domain Osmosis，通过动态调整损失权重实现更...|
|🆕 发布|GeoVLMath: Enhancing Geometry Reasoning in Vision-Language Models via Cross-Modal Reward for Auxiliary Line Creation|GeoVLMath：通过跨模态奖励辅助线创建增强视觉语言模型中的几何推理|Shasha Guo, Liang Pang, Xi Wang, Yanling Wang, Huawei Shen, Jing Zhang|<http://arxiv.org/pdf/2510.11020v1>|提出了一种通过跨模态奖励增强文本描述与图像对齐的强化学习框架，有效提升大型视觉语言模型解决几何问题的...|
|📝 更新|Learning Diffusion Models with Flexible Representation Guidance|学习具有灵活表征引导的扩散模型|Chenyu Wang, Cai Zhou, Sharut Gupta, Zongyu Lin, Stefanie Jegelka, Stephen Bates, Tommi Jaakkola|<http://arxiv.org/pdf/2507.08980v2>|[代码](https://github.com/ChenyuWang-Monica/REED.); 引入了灵活的表示引导策略，提升了扩散模型性能并加速了训练过程。|
|🆕 发布|Into the Unknown: Towards using Generative Models for Sampling Priors of Environment Uncertainty for Planning in Configuration Spaces|《走向未知：利用生成模型对环境不确定性进行规划的前采样先验配置空间》|Subhransu S. Bhattacharjee, Hao Lu, Dylan Campbell, Rahul Shome|<http://arxiv.org/pdf/2510.11014v1>|利用预训练生成模型，创新采样环境不确定性概率先验，助力机器人规划。|
|📝 更新|DeRIS: Decoupling Perception and Cognition for Enhanced Referring Image Segmentation through Loopback Synergy|解耦感知与认知以提高参照图像分割性能的DeRIS：通过回环协同作用实现|Ming Dai, Wenxuan Cheng, Jiang-jiang Liu, Sen Yang, Wenxiao Cai, Yanpeng Sun, Wankou Yang|<http://arxiv.org/pdf/2507.01738v2>|[代码](https://github.com/Dmmm1997/DeRIS.); 提出了一种解耦感知与认知的DeRIS框架，通过Loopback Synergy机制提升图像分割精度和...|
|📝 更新|Latent Harmony: Synergistic Unified UHD Image Restoration via Latent Space Regularization and Controllable Refinement|潜在和谐：通过潜在空间正则化和可控细化实现超高清图像恢复的协同统一|Yidi Liu, Xueyang Fu, Jie Huang, Jie Xiao, Dong Li, Wenlong Zhang, Lei Bai, Zheng-Jun Zha|<http://arxiv.org/pdf/2510.07961v2>|提出了一种两阶段框架Latent Harmony，通过潜空间正则化和高频感知重建，有效平衡了超高清图...|
|🆕 发布|DreamMakeup: Face Makeup Customization using Latent Diffusion Models|梦幻美妆：基于潜在扩散模型的面部妆容定制|Geon Yeong Park, Inhwa Han, Serin Yang, Yeobin Hong, Seongmin Jeong, Heechan Jeon, Myeongjin Goh, Sung Won Yi .etc.|<http://arxiv.org/pdf/2510.10918v1>|DreamMakeup通过采用无需训练的扩散模型，实现了高可控性和精确的实时图像编辑，解决了传统GA...|
|🆕 发布|SceneTextStylizer: A Training-Free Scene Text Style Transfer Framework with Diffusion Model|《SceneTextStylizer：一种基于扩散模型的无训练场景文本风格迁移框架》|Honghui Yuan, Keiji Yanai|<http://arxiv.org/pdf/2510.10910v1>|提出了SceneTextStylizer，一种无需训练的基于扩散模型的高保真场景文本风格转换框架。|
|📝 更新|Prompt4Trust: A Reinforcement Learning Prompt Augmentation Framework for Clinically-Aligned Confidence Calibration in Multimodal Large Language Models|Prompt4Trust：面向临床对齐置信度校准的多模态大规模语言模型强化学习提示增强框架|Anita Kriz, Elizabeth Laura Janes, Xing Shen, Tal Arbel|<http://arxiv.org/pdf/2507.09279v4>|[代码](https://github.com/xingbpshen/prompt4trust.); Prompt4Trust通过强化学习优化提示设计，提升多模态大语言模型在医疗应用中的准确性与可信度。|
|🆕 发布|FastHMR: Accelerating Human Mesh Recovery via Token and Layer Merging with Diffusion Decoding|快速HMR：通过Token和层合并以及扩散解码加速人体网格恢复|Soroush Mehraban, Andrea Iaboni, Babak Taati|<http://arxiv.org/pdf/2510.10868v1>|提出两种高效的人类网格恢复合并策略，结合扩散解码，实现速度提升同时保持性能。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|IVEBench: Modern Benchmark Suite for Instruction-Guided Video Editing Assessment|IVEBench：面向指导性视频编辑评估的现代基准测试套件|Yinan Chen, Jiangning Zhang, Teng Hu, Yuxiang Zeng, Zhucun Xue, Qingdong He, Chengjie Wang, Yong Liu .etc.|<http://arxiv.org/pdf/2510.11647v1>|IVEBench解决了现有视频编辑评估不足的问题，提出了一套全面评估指令引导视频编辑的新基准测试集。|
|🆕 发布|Massive Activations are the Key to Local Detail Synthesis in Diffusion Transformers|大规模激活是扩散变换器中局部细节合成的关键|Chaofan Gan, Zicheng Zhao, Yuanpeng Tu, Xi Chen, Ziran Qin, Tieyuan Chen, Mehrtash Harandi, Weiyao Lin|<http://arxiv.org/pdf/2510.11538v1>|揭示了大规模激活在视觉生成中关键作用，并提出了一种增强局部细节的新策略。|
|🆕 发布|DocReward: A Document Reward Model for Structuring and Stylizing|文档奖励模型：用于文档结构化和风格化的奖励模型|Junpeng Liu, Yuzhong Zhao, Bowen Cao, Jiayu Ding, Yilin Jia, Tengchao Lv, Yupan Huang, Shaohan Huang .etc.|<http://arxiv.org/pdf/2510.11391v1>|提出DocReward模型，通过评估文档的结构和风格，提高了自动化生成专业文档的质量。|
|🆕 发布|GIR-Bench: Versatile Benchmark for Generating Images with Reasoning|GIR-Bench：用于生成具有推理功能的图像的多功能基准测试|Hongxiang Li, Yaowei Li, Bin Lin, Yuwei Niu, Yuhang Yang, Xiaoshuang Huang, Jiayin Cai, Xiaolong Jiang .etc.|<http://arxiv.org/pdf/2510.11026v1>|[代码](https://hkust-longgroup.github.io/GIR-Bench); 提出了GIR-Bench，一个全面的基准测试，用于评估统一模型在理解与生成一致性、文本到图像推理生成...|
|🆕 发布|Perspective-aware 3D Gaussian Inpainting with Multi-view Consistency|具有多视角一致性的透视感知三维高斯图像修复|Yuxin Cheng, Binxiao Huang, Taiqiang Wu, Wenyong Zhou, Chenchen Ding, Zhengwu Liu, Graziano Chesi, Ngai Wong|<http://arxiv.org/pdf/2510.10993v1>|提出了一种视角感知的3D高斯修复方法，通过多视角一致性验证显著提升了纹理质量和全局一致性。|
|📝 更新|TAG-WM: Tamper-Aware Generative Image Watermarking via Diffusion Inversion Sensitivity|TAG-WM：基于扩散逆敏感性的人工图像水印技术及其篡改感知能力|Yuzhuo Chen, Zehua Ma, Han Fang, Weiming Zhang, Nenghai Yu|<http://arxiv.org/pdf/2506.23484v3>|[代码](https://github.com/Suchenl/TAG-WM.); 提出了一种抗篡改生成图像水印方法TAG-WM，通过在潜在空间嵌入水印并利用扩散逆敏感性检测篡改，实现...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|$Δ\mathrm{Energy}$: Optimizing Energy Change During Vision-Language Alignment Improves both OOD Detection and OOD Generalization|$Δ\mathrm{能量}$：在视觉-语言对齐过程中优化能量变化可同时提高OOD检测和OOD泛化能力|Lin Zhu, Yifeng Yang, Xinbing Wang, Qinying Gu, Nanyang Ye|<http://arxiv.org/pdf/2510.11296v1>|提出ΔEnergy方法，通过优化视觉语言对齐过程中的能量变化，有效提升异常检测和泛化能力。|
|🆕 发布|Generalisation of automatic tumour segmentation in histopathological whole-slide images across multiple cancer types|跨多种癌症类型的全切片病理图像自动肿瘤分割泛化|Ole-Johan Skrede, Manohar Pradhan, Maria Xepapadakis Isaksen, Tarjei Sveinsgjerd Hveem, Ljiljana Vlatkovic, Arild Nesbakken, Kristina Lindemann, Gunnar B Kristensen .etc.|<http://arxiv.org/pdf/2510.11182v1>|开发了一种通用肿瘤分割模型，跨多种癌症类型保持了高准确率。|
|🆕 发布|Comparative Evaluation of Neural Network Architectures for Generalizable Human Spatial Preference Prediction in Unseen Built Environments|神经网络架构在未见建筑环境中通用人类空间偏好预测的比较评估|Maral Doctorarastoo, Katherine A. Flanigan, Mario Bergés, Christopher McComb|<http://arxiv.org/pdf/2510.10954v1>|比较了图神经网络、卷积神经网络和标准前馈神经网络在预测未见建筑环境中人类空间偏好的泛化能力。|
|📝 更新|Generating Multi-Image Synthetic Data for Text-to-Image Customization|为文本到图像定制生成多图像合成数据集|Nupur Kumari, Xi Yin, Jun-Yan Zhu, Ishan Misra, Samaneh Azadi|<http://arxiv.org/pdf/2502.01720v2>|提出了一种利用多图像合成数据训练的编码器模型，通过共享注意力机制和归一化推理技术，有效提升了文本到图...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Ev4DGS: Novel-view Rendering of Non-Rigid Objects from Monocular Event Streams|Ev4DGS：从单目事件流中非刚性物体的新视角渲染|Takuya Nakabayashi, Navami Kairanda, Hideo Saito, Vladislav Golyanik|<http://arxiv.org/pdf/2510.11717v1>|首次提出仅利用单目事件流对非刚性变形物体进行显式空间新视角渲染的方法Ev4DGS。|
|📝 更新|Beyond [cls]: Exploring the true potential of Masked Image Modeling representations|超越[cls]：探索遮蔽图像建模表征的真正潜力|Marcin Przewięźlikowski, Randall Balestriero, Wojciech Jasiński, Marek Śmieja, Bartosz Zieliński|<http://arxiv.org/pdf/2412.03215v3>|提出选择性聚合方法改善Masked Image Modeling的初始性能，有效利用保留在图像块中的...|
|📝 更新|Learned Display Radiance Fields with Lensless Cameras|基于无透镜相机的学习显示辐射场|Ziyang Chen, Yuta Itoh, Kaan Akşit|<http://arxiv.org/pdf/2510.03356v2>|提出了一种无需专业设备的显示校准方法，通过结合无透镜相机和隐式神经表示算法捕捉显示特性。|
|📝 更新|LiDAR-GS:Real-time LiDAR Re-Simulation using Gaussian Splatting|LiDAR-GS：基于高斯散点法的实时LiDAR重仿真|Qifeng Chen, Sheng Yang, Sicong Du, Tao Tang, Rengan Xie, Peng Chen, Yuchi Huo|<http://arxiv.org/pdf/2410.05111v3>|[代码](https://github.com/cqf7419/LiDAR-GS.); 提出LiDAR-GS方法，通过高斯散点技术实时重现LiDAR扫描，提升了渲染帧率和质量。|
|📝 更新|LH2Face: Loss function for Hard High-quality Face|LH2Face：面向困难高质量人脸的损失函数|Fan Xie, Yang Wang, Yikang Jiao, Zhenyu Yuan, Congxi Chen, Chuanxin Zhao|<http://arxiv.org/pdf/2506.23555v3>|提出了一种针对硬样本和高质量人脸的适应性边缘损失函数LH2Face，有效提升了人脸识别准确率。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PhySIC: Physically Plausible 3D Human-Scene Interaction and Contact from a Single Image|物理可信的单张图像中的三维人体-场景交互与接触|Pradyumna Yalandur Muralidhar, Yuxuan Xue, Xianghui Xie, Margaret Kostyrko, Gerard Pons-Moll|<http://arxiv.org/pdf/2510.11649v1>|提出了PhySIC框架，通过单张图像实现物理可信的三维人体与场景交互和接触重建。|
|🆕 发布|VA-GS: Enhancing the Geometric Representation of Gaussian Splatting via View Alignment|VA-GS：通过视图对齐增强高斯散点法的几何表示|Qing Li, Huifang Feng, Xun Gong, Yu-Shen Liu|<http://arxiv.org/pdf/2510.11473v1>|[代码](https://github.com/LeoQLi/VA-GS.); 提出了一种通过视图对齐增强3D高斯分布几何表示的方法，提高了表面重建和视图合成的准确性。|
|📝 更新|Real-Time Position-Aware View Synthesis from Single-View Input|从单视角输入实现实时位置感知视图合成|Manu Gond, Emin Zerman, Sebastian Knorr, Mårten Sjöström|<http://arxiv.org/pdf/2412.14005v2>|提出了一种轻量级、实时性强的位置感知网络，实现了从单视角输入合成新视角图像，提升了效率和视觉效果。|
|🆕 发布|Text-Enhanced Panoptic Symbol Spotting in CAD Drawings|图纸中的文本增强全景符号检测|Xianlin Liu, Yan Gong, Bohao Li, Jiajing Huang, Bowen Du, Junchen Ye, Liyan Xu|<http://arxiv.org/pdf/2510.11091v1>|提出了一种融合文本注释的泛视图符号检测框架，有效提升了CAD图纸中符号检测的准确性和鲁棒性。|
|🆕 发布|On the Optimal Representation Efficiency of Barlow Twins: An Information-Geometric Interpretation|《Barlow双胞胎的最优表示效率：信息几何学解释》|Di Zhang|<http://arxiv.org/pdf/2510.10980v1>|提出信息几何框架量化自监督学习效率，证明Barlow Twins达到最优效率。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Evaluating the effects of preprocessing, method selection, and hyperparameter tuning on SAR-based flood mapping and water depth estimation|评估预处理、方法选择和超参数调整对合成孔径雷达(SAR)洪水制图和水深估计的影响|Jean-Paul Travert, Cédric Goeury, Sébastien Boyaval, Vito Bacchi, Fabrice Zaoui|<http://arxiv.org/pdf/2510.11305v1>|评估了预处理、方法选择和超参数调整对合成孔径雷达洪水制图和水深估计的影响，强调了整个处理流程的重要性...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|StreamAgent: Towards Anticipatory Agents for Streaming Video Understanding|面向流视频理解的预测性智能体：StreamAgent|Haolin Yang, Feilong Tang, Lingxiao Zhao, Xiang An, Ming Hu, Huifa Li, Xinlin Zhuang, Yifan Lu .etc.|<http://arxiv.org/pdf/2508.01875v3>|提出了一种面向实时视频理解的预测性智能体StreamAgent，通过预测关键事件的时间和空间信息，实...|
|🆕 发布|ExpVid: A Benchmark for Experiment Video Understanding & Reasoning|ExpVid：实验视频理解与推理基准|Yicheng Xu, Yue Wu, Jiashuo Yu, Ziang Yan, Tianxiang Jiang, Yinan He, Qingsong Zhao, Kai Chen .etc.|<http://arxiv.org/pdf/2510.11606v1>|提出ExpVid基准，评估多模态大语言模型在理解科学实验视频中的细粒度感知、过程理解和科学推理能力。|
|🆕 发布|video-SALMONN S: Streaming Audio-Visual LLMs Beyond Length Limits via Memory|视频-SALMONN S：通过内存扩展超越长度限制的流式音频-视觉大型语言模型|Guangzhi Sun, Yixuan Li, Xiaodong Wu, Yudong Yang, Wei Li, Zejun Ma, Chao Zhang|<http://arxiv.org/pdf/2510.11129v1>|提出了一种新型流式音频视觉语言模型video-SALMONN S，通过测试时训练模块和选择性内存读取...|
|📝 更新|VideoAds for Fast-Paced Video Understanding|视频广告：用于快速视频理解的算法研究|Zheyuan Zhang, Monica Dou, Linkai Peng, Hongyi Pan, Ulas Bagci, Boqing Gong|<http://arxiv.org/pdf/2504.09282v2>|提出了VideoAds数据集，专为评估多模态大型语言模型在广告视频理解上的性能。|
|🆕 发布|Mixup Helps Understanding Multimodal Video Better|混合策略有助于更好地理解多模态视频|Xiaoyu Ma, Ding Ding, Hao Chen|<http://arxiv.org/pdf/2510.10986v1>|提出Multimodal Mixup和Balanced Multimodal Mixup方法，缓解多...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Future-Aware End-to-End Driving: Bidirectional Modeling of Trajectory Planning and Scene Evolution|面向未来的端到端驾驶：轨迹规划和场景演化的双向建模|Bozhou Zhang, Nan Song, Jingyu Li, Xiatian Zhu, Jiankang Deng, Li Zhang|<http://arxiv.org/pdf/2510.11092v1>|提出了一种端到端驾驶框架SeerDrive，通过预测未来场景动态和规划轨迹的相互作用，显著提升了自动...|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SAVeD: Learning to Denoise Low-SNR Video for Improved Downstream Performance|SAVeD：学习在低信噪比视频去噪以提高下游性能|Suzanne Stathatos, Michael Hobley, Pietro Perona, Markus Marks|<http://arxiv.org/pdf/2504.00161v2>|[代码](https://github.com/suzanne-stathatos/SAVeD); 提出了一种自监督视频去噪方法SAVeD，仅使用原始噪声数据提升低信噪比视频质量，无需清洁视频即可实现...|
|📝 更新|SMC++: Masked Learning of Unsupervised Video Semantic Compression|SMC++：无监督视频语义压缩的遮蔽学习|Yuan Tian, Xiaoyue Ling, Cong Geng, Qiang Hu, Guo Lu, Guangtao Zhai|<http://arxiv.org/pdf/2406.04765v2>|[代码](https://github.com/tianyuan168326/VideoSemanticCompression-Pytorch.); 提出了一种基于自监督学习的视频压缩框架，有效保留了视频语义信息，提升了视频分析任务的性能。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Contrastive Representation Distillation via Multi-Scale Feature Decoupling|通过多尺度特征解耦的对比表示蒸馏|Cuipeng Wang, Haipeng Wang|<http://arxiv.org/pdf/2502.05835v3>|提出了一种多尺度特征解耦的对比表示蒸馏框架，有效提升了小模型性能并减少了对外部存储的依赖。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|QeRL: Beyond Efficiency -- Quantization-enhanced Reinforcement Learning for LLMs|QeRL：超越效率 -- 面向大规模语言模型的量化增强强化学习|Wei Huang, Yi Ge, Shuai Yang, Yicheng Xiao, Huizi Mao, Yujun Lin, Hanrong Ye, Sifei Liu .etc.|<http://arxiv.org/pdf/2510.11696v1>|提出QeRL框架，通过量化增强强化学习，有效提升大规模语言模型训练速度和探索效果。|
|📝 更新|Breaking the Compression Ceiling: Data-Free Pipeline for Ultra-Efficient Delta Compression|突破压缩上限：无需数据的高效差值压缩管道|Xiaohui Wang, Peng Ye, Chenyu Huang, Shenghe Zheng, Bo Zhang, Lei Bai, Wanli Ouyang, Tao Chen|<http://arxiv.org/pdf/2505.13563v3>|[代码](https://github.com/xiaohuiwang000/UltraDelta.); 提出了一种无数据驱动的UltraDelta压缩方法，实现了高压缩率和强性能的平衡。|
|🆕 发布|Robust Ego-Exo Correspondence with Long-Term Memory|具有长期记忆的鲁棒自我-外部对应关系|Yijun Hu, Bing Fan, Xin Gu, Haiqing Ren, Dongfang Liu, Heng Fan, Libo Zhang|<http://arxiv.org/pdf/2510.11417v1>|[代码](https://github.com/juneyeeHu/LM-EEC.); 提出了一种结合长时记忆的ego-exo对应框架，通过自适应特征路由和双记忆体结构显著提升了视频对象对...|
|📝 更新|The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models|《进步的幻象？对视觉语言模型测试时适应性的批判性审视》|Lijun Sheng, Jian Liang, Ran He, Zilei Wang, Tieniu Tan|<http://arxiv.org/pdf/2506.24000v2>|提出统一框架TTA-VLM，全面评估视觉语言模型测试时适应方法，发现现有方法效果有限且影响模型可信度...|
|🆕 发布|Investigating Identity Signals in Conversational Facial Dynamics via Disentangled Expression Features|通过解耦表情特征探究对话面部动态中的身份信号|Masoumeh Chapariniya, Pierre Vuillecard, Jean-Marc Odobez, Volker Dellwo, Teodora Vukovic|<http://arxiv.org/pdf/2510.11223v1>|探究面部表情动态中的身份特征，通过分离形状和表情系数识别个体身份。|
|🆕 发布|Saudi Sign Language Translation Using T5|使用T5进行沙特手语翻译|Ali Alhejab, Tomas Zelezny, Lamya Alkanhal, Ivan Gruber, Yazeed Alharbi, Jakub Straka, Vaclav Javorek, Marek Hruz .etc.|<http://arxiv.org/pdf/2510.11183v1>|利用T5模型和跨语言预训练技术，有效提升了沙特手语翻译性能。|
|🆕 发布|G2L:From Giga-Scale to Cancer-Specific Large-Scale Pathology Foundation Models via Knowledge Distillation|G2L：通过知识蒸馏从大规模到癌症特异性的大尺度病理基础模型|Yesung Cho, Sungmin Lee, Geongyu Lee, Minkyung Lee, Jongbae Park, Dongmyung Shin|<http://arxiv.org/pdf/2510.11176v1>|提出G2L框架，通过知识蒸馏将大型模型性能提升至接近巨型模型水平，大幅降低计算负担。|
|📝 更新|FormCoach: Lift Smarter, Not Harder|FormCoach：更智能地举重，而非更努力地举重|Xiaoye Zuo, Nikos Athanasiou, Ginger Delmas, Yiming Huang, Xingyu Fu, Lingjie Liu|<http://arxiv.org/pdf/2508.07501v3>|FormCoach利用视觉语言模型将普通摄像头转变为实时交互式训练伙伴，纠正健身动作中的细微错误。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bayesian Topological Convolutional Neural Nets|贝叶斯拓扑卷积神经网络|Sarah Harkins Dayton, Hayden Everett, Ioannis Schizas, David L. Boothe Jr., Vasileios Maroulas|<http://arxiv.org/pdf/2510.11704v1>|提出了一种结合拓扑学习和贝叶斯抽样的卷积神经网络，有效提升了小数据集训练的性能和不确定性量化。|
|🆕 发布|MS-Mix: Unveiling the Power of Mixup for Multimodal Sentiment Analysis|MS-Mix：揭示Mixup在多模态情感分析中的力量|Hongyu Zhu, Lin Chen, Mounim A. El-Yacoubi, Mingsheng Shang|<http://arxiv.org/pdf/2510.11579v1>|[代码](https://github.com/HongyuZhu-s/MS-Mix.); 提出MS-Mix框架，通过情感敏感的样本混合增强多模态情感分析模型的泛化能力。|
|🆕 发布|MMAP: A Multi-Magnification and Prototype-Aware Architecture for Predicting Spatial Gene Expression|多尺度与原型感知架构用于预测空间基因表达：MMAP|Hai Dang Nguyen, Nguyen Dang Huy Pham, The Minh Duc Nguyen, Dac Thai Nguyen, Hang Thi Nguyen, Duong M. Nguyen|<http://arxiv.org/pdf/2510.11344v1>|提出了一种多倍放大和原型感知的架构MMAP，通过结合细粒度局部特征和全局空间上下文，有效预测空间基因...|
|🆕 发布|LightPneumoNet: Lightweight Pneumonia Classifier|轻量级肺炎分类器：LightPneumoNet|Neilansh Chauhan, Piyush Kumar Gupta, Faraz Doja|<http://arxiv.org/pdf/2510.11232v1>|提出了一种轻量级肺炎检测网络LightPneumoNet，实现了高准确性和低资源消耗，适用于资源有限...|
|📝 更新|Goal-Based Vision-Language Driving|基于目标的视觉-语言驾驶|Santosh Patapati, Trisanth Srinivasan|<http://arxiv.org/pdf/2507.23042v2>|提出了一种融合视觉与语言的单分支架构NovaDrive，通过精细的注意力机制和创新的平滑度损失，显著...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|High-resolution Photo Enhancement in Real-time: A Laplacian Pyramid Network|实时高分辨率照片增强：拉普拉斯金字塔网络|Feng Zhang, Haoyou Deng, Zhiqiang Li, Lida Li, Bin Xu, Qingbo Lu, Zisheng Cao, Minchen Wei .etc.|<http://arxiv.org/pdf/2510.11613v1>|[代码](https://github.com/fengzhang427/LLF-LUT.); 提出了一种LLF-LUT++网络，通过结合全局和局部操作实现了高分辨率图像的实时增强。|
|📝 更新|TTF-VLA: Temporal Token Fusion via Pixel-Attention Integration for Vision-Language-Action Models|TTF-VLA: 通过像素注意力集成的时序标记融合用于视觉-语言-动作模型|Chenghao Liu, Jiachen Zhang, Chengxuan Li, Zhimu Zhou, Shixin Wu, Songfang Huang, Huiling Duan|<http://arxiv.org/pdf/2508.19257v2>|提出了无需训练的时空信息融合方法TTF，有效整合历史和当前视觉表示，提升视觉语言动作模型的推理质量。|
|📝 更新|When Language Model Guides Vision: Grounding DINO for Cattle Muzzle Detection|当语言模型引导视觉：基于DINO的牛鼻部检测定位|Rabin Dulal, Lihong Zheng, Muhammad Ashad Kabir|<http://arxiv.org/pdf/2509.06427v2>|提出了一种无需标注数据的零样本牛鼻部检测框架，通过自然语言提示实现灵活的检测。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MaterialRefGS: Reflective Gaussian Splatting with Multi-view Consistent Material Inference|材料反射场：具有多视角一致性材料推理的反射高斯散点喷射|Wenyuan Zhang, Jimin Tang, Weiqi Zhang, Yi Fang, Yu-Shen Liu, Zhizhong Han|<http://arxiv.org/pdf/2510.11387v1>|通过多视角一致性材料推理和环境建模策略，提高了高斯散点渲染的反射效果和真实感。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Adversarial Attacks Leverage Interference Between Features in Superposition|对抗攻击利用叠加特征之间的干扰|Edward Stevinson, Lucas Prieto, Melih Barsbey, Tolga Birdal|<http://arxiv.org/pdf/2510.11709v1>|揭示了神经网络中对抗性漏洞的根源在于信息编码效率，提出利用特征叠加干扰的机制解释攻击模式。|
|🆕 发布|The Easy Path to Robustness: Coreset Selection using Sample Hardness|易走的稳健之路：基于样本难度进行核心集选择|Pranav Ramesh, Arjun Roy, Deepak Ravikumar, Kaushik Roy, Gopalakrishnan Srinivasan|<http://arxiv.org/pdf/2510.11018v1>|提出基于样本硬度选择训练数据的方法EasyCore，有效提升模型对抗性稳健性。|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FACE: Faithful Automatic Concept Extraction|面部：忠实自动概念提取|Dipkamal Bhusal, Michael Clifford, Sara Rampazzi, Nidhi Rastogi|<http://arxiv.org/pdf/2510.11675v1>|提出FACE框架，通过结合NMF与KL散度正则化，确保概念提取与模型决策一致性，提升解释忠实度。|
|📝 更新|Editable-DeepSC: Reliable Cross-Modal Semantic Communications for Facial Editing|可编辑深度SC：面向面部编辑的可靠跨模态语义通信|Bin Chen, Wenbo Yu, Qinshan Zhang, Tianqu Zhuang, Yong Jiang, Shu-Tao Xia|<http://arxiv.org/pdf/2411.15702v3>|提出Editable-DeepSC方法，通过整合编辑与通信，有效提升面部编辑的语义通信效率并节省带宽...|
|🆕 发布|Towards Distribution-Shift Uncertainty Estimation for Inverse Problems with Generative Priors|面向分布偏移不确定性估计的具有生成先验的逆问题研究|Namhoon Kim, Sara Fridovich-Keil|<http://arxiv.org/pdf/2510.10947v1>|提出了一种无需校准的分布偏移敏感的不确定性指标，用于检测图像重建中的数据分布变化。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SCOOP'D: Learning Mixed-Liquid-Solid Scooping via Sim2Real Generative Policy|SCOOP'D：通过Sim2Real生成策略学习混合液体-固体挖取|Kuanning Wang, Yongchong Gu, Yuqian Fu, Zeyu Shangguan, Sicheng He, Xiangyang Xue, Yanwei Fu, Daniel Seita|<http://arxiv.org/pdf/2510.11566v1>|[代码](https://scoopdiff.github.io/.); 提出了一种利用模拟训练和生成策略学习机器人 scoop 技能的方法，实现了在多种现实场景下的零样本部...|
|📝 更新|Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?|强化学习真的能激励大型语言模型超越基础模型的推理能力吗？|Yang Yue, Zhiqi Chen, Rui Lu, Andrew Zhao, Zhaokai Wang, Yang Yue, Shiji Song, Gao Huang|<http://arxiv.org/pdf/2504.13837v3>|发现当前强化学习未能显著提升LLM推理能力，提出需改进学习范式以激发新推理模式。|
|📝 更新|OVS Meets Continual Learning: Towards Sustainable Open-Vocabulary Segmentation|面向可持续性的开放词汇分割：OVS与持续学习的结合|Dongjun Hwang, Yejin Kim, Minyoung Lee, Seong Joon Oh, Junsuk Choe|<http://arxiv.org/pdf/2410.11536v2>|提出ConOVS方法，通过动态结合专家解码器，有效提升开放词汇分割模型在连续数据收集场景下的性能。|
|🆕 发布|Nepali Sign Language Characters Recognition: Dataset Development and Deep Learning Approaches|尼泊尔手语字符识别：数据集开发与深度学习方法|Birat Poudel, Satyam Ghimire, Sijan Bhattarai, Saurav Bhandari, Suramya Sharma Dahal|<http://arxiv.org/pdf/2510.11243v1>|开发了首个尼泊尔手语字符识别数据集，并使用深度学习模型实现了高准确率识别。|
|🆕 发布|Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos|基于类原型的对比学习用于多标签和细粒度教育视频分类|Rohit Gupta, Anirban Roy, Claire Christensen, Sujeong Kim, Sarah Gerard, Madeline Cincebeaux, Ajay Divakaran, Todd Grindal .etc.|<http://arxiv.org/pdf/2510.11204v1>|[代码](https://github.com/rohit-gupta/MMContrast); 提出了一种基于类原型监督对比学习的细粒度多标签视频分类方法，有效识别包含教育内容的在线视频。|
|📝 更新|Learning Shared Representations from Unpaired Data|从无配对数据中学习共享表示|Amitai Yacobi, Nir Ben-Ari, Ronen Talmon, Uri Shaham|<http://arxiv.org/pdf/2505.21524v2>|[代码](https://shaham-lab.github.io/SUE_page.); 首次实现仅从无配对数据中学习共享表征，有效捕捉跨模态关系。|
|🆕 发布|CoPRS: Learning Positional Prior from Chain-of-Thought for Reasoning Segmentation|链式思维先验学习用于推理分割的CoPRS|Zhenyu Lu, Liupeng Li, Jinpeng Wang, Yan Feng, Bin Chen, Ke Chen, Yaowei Wang|<http://arxiv.org/pdf/2510.11173v1>|[代码](https://github.com/ZhenyuLU-Heliodore/CoPRS.git.); 提出CoPRS模型，通过多模态链式思维将语言推理与图像分割结合，增强了解释性和分割精度。|
|🆕 发布|Compositional Zero-Shot Learning: A Survey|组合零样本学习：综述|Ans Munir, Faisal Z. Qureshi, Mohsen Ali, Muhammad Haris Khan|<http://arxiv.org/pdf/2510.11106v1>|[代码](https://github.com/ans92/Compositional-Zero-Shot-Learning); 系统综述了组合零样本学习的方法，分类为四种，并分析了优缺点及未来研究方向。|
|🆕 发布|ROFI: A Deep Learning-Based Ophthalmic Sign-Preserving and Reversible Patient Face Anonymizer|ROFI：一种基于深度学习的眼科体征保留与可逆患者面部匿名化方法|Yuan Tian, Min Zhou, Yitong Chen, Fang Li, Lingzi Qi, Shuo Wang, Xieyang Xu, Yu Yu .etc.|<http://arxiv.org/pdf/2510.11073v1>|提出ROFI框架，通过深度学习实现眼科患者面部隐私保护，同时保留疾病特征。|
|🆕 发布|Topological Alignment of Shared Vision-Language Embedding Space|共享视觉-语言嵌入空间的拓扑对齐|Junwon You, Dasol Kang, Jae-Hun Jung|<http://arxiv.org/pdf/2510.10889v1>|引入ToMCLIP框架，通过拓扑保持约束实现多语言嵌入空间的精准对齐，提升跨模态表示的结构一致性和零...|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SNAP: Towards Segmenting Anything in Any Point Cloud|SNAP: 面向任意点云中任意目标的分割|Aniket Gupta, Hanhui Wang, Charles Saunders, Aruni RoyChowdhury, Hanumant Singh, Huaizu Jiang|<http://arxiv.org/pdf/2510.11565v1>|[代码](https://neu-vi.github.io/SNAP); 提出了一种统一的3D点云分割模型SNAP，支持多种交互方式，实现了跨领域泛化，提升了分割质量。|
|🆕 发布|REACT3D: Recovering Articulations for Interactive Physical 3D Scenes|REACT3D：为交互式物理三维场景恢复关节|Zhao Huang, Boyang Sun, Alexandros Delitzas, Jiaqi Chen, Marc Pollefeys|<http://arxiv.org/pdf/2510.11340v1>|提出了一种零样本框架REACT3D，将静态3D场景转化为可交互的仿真副本，实现高效场景理解与模拟。|
|🆕 发布|Enhancing Zero-Shot Anomaly Detection: CLIP-SAM Collaboration with Cascaded Prompts|增强零样本异常检测：CLIP-SAM协作与级联提示|Yanning Hou, Ke Xu, Junfa Li, Yanran Ruan, Jianfeng Qiu|<http://arxiv.org/pdf/2510.11028v1>|分类|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|mmWalk: Towards Multi-modal Multi-view Walking Assistance|面向多模态多视角步行辅助的mmWalk方法|Kedi Ying, Ruiping Liu, Chongyan Chen, Mingzhe Tao, Hao Shi, Kailun Yang, Jiaming Zhang, Rainer Stiefelhagen|<http://arxiv.org/pdf/2510.11520v1>|构建了mmWalk多模态多视角数据集，助力视障人士在复杂环境中安全导航。|
|🆕 发布|Human Uncertainty-Aware Data Selection and Automatic Labeling in Visual Question Answering|人类不确定性感知的数据选择与视觉问答中的自动标注|Jian Lan, Zhicheng Liu, Udo Schlegel, Raoyuan Zhao, Yihong Liu, Hinrich Schütze, Michael A. Hedderich, Thomas Seidl|<http://arxiv.org/pdf/2510.11295v1>|提出了一种针对视觉问答的高效数据选择与自动标注框架，减少对人工标注的依赖，提高模型准确性和校准性。|
|📝 更新|Go Beyond Earth: Understanding Human Actions and Scenes in Microgravity Environments|《超越地球：在微重力环境中理解人类行为与场景》|Di Wen, Lei Qi, Kunyu Peng, Kailun Yang, Fei Teng, Ao Luo, Jia Fu, Yufan Chen .etc.|<http://arxiv.org/pdf/2506.02845v3>|[代码](https://github.com/LEI-QI-233/HAR-in-Space.); 首次提出针对微重力环境下人类活动和场景理解的基准数据集MicroG-4M，为空间应用中的视觉系统提供...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Coupled Degradation Modeling and Fusion: A VLM-Guided Degradation-Coupled Network for Degradation-Aware Infrared and Visible Image Fusion|耦合退化建模与融合：一种基于VLM引导的退化耦合网络用于退化感知的红外与可见光图像融合|Tianpei Zhang, Jufeng Zhao, Yiming Zhu, Guangmang Cui|<http://arxiv.org/pdf/2510.11456v1>|[代码](https://github.com/Lmmh058/VGDCFusion.); 提出了一种将退化建模与融合过程紧密结合的VLM-Guided网络，有效提升了退化图像的融合质量。|
|📝 更新|Learning Visual Hierarchies in Hyperbolic Space for Image Retrieval|在双曲空间中学习视觉层次结构以进行图像检索|Ziwei Wang, Sameera Ramasinghe, Chenchen Xu, Julien Monteil, Loris Bazzani, Thalaiyasingam Ajanthan|<http://arxiv.org/pdf/2411.17490v3>|首次提出在双曲空间中学习用户定义的多级复杂视觉层次，无需显式层次标签，提升图像检索的层次性。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|One More Glance with Sharp Eyes: Rethinking Lightweight Captioning as a Practical Visual Specialist|《再以敏锐之眼一瞥：重新思考轻量级字幕生成作为实用视觉专家》|Junha Song, Yongsik Jo, So Yeon Min, Quanting Xie, Taehwan Kim, Yonatan Bisk, Jaegul Choo|<http://arxiv.org/pdf/2508.21451v2>|提出轻量级图像描述模型并创新Sharp-Eyed Refinement框架，实现高效准确视觉描述。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|InstructSAM: A Training-Free Framework for Instruction-Oriented Remote Sensing Object Recognition|面向指令的遥感目标识别无需训练框架：InstructSAM|Yijie Zheng, Weijie Wu, Qingyun Li, Xuehui Wang, Xu Zhou, Aiai Ren, Jun Shen, Long Zhao .etc.|<http://arxiv.org/pdf/2505.15818v2>|提出了一种无需训练的InstructSAM框架，通过大模型理解指令实现遥感图像对象识别，提升了处理复...|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DTEA: Dynamic Topology Weaving and Instability-Driven Entropic Attenuation for Medical Image Segmentation|动态拓扑编织与不稳定性驱动的熵衰减用于医学图像分割|Weixuan Li, Quanjun Li, Guang Yu, Song Yang, Zimeng Li, Chi-Man Pun, Yupeng Liu, Xuhang Chen|<http://arxiv.org/pdf/2510.11259v1>|[代码](https://github.com/LWX-Research/DTEA); 提出DTEA模型，通过动态超图和熵扰动门控改进跳跃连接，提升医疗图像分割准确性和泛化能力。|
|🆕 发布|Exploring and Leveraging Class Vectors for Classifier Editing|探索和利用类向量进行分类器编辑|Jaeik Kim, Jaeyoung Do|<http://arxiv.org/pdf/2510.11268v1>|提出Class Vectors实现高效灵活的图像分类器编辑，无需大规模重训练。|
|🆕 发布|EEMS: Edge-Prompt Enhanced Medical Image Segmentation Based on Learnable Gating Mechanism|边缘提示增强的可学习门控机制基于医学图像分割EEMS|Han Xia, Quanjun Li, Qian Li, Zimeng Li, Hongbin Ye, Yupeng Liu, Haolun Li, Xuhang Chen|<http://arxiv.org/pdf/2510.11287v1>|提出EEMS模型，通过边缘感知增强和多尺度提示生成，提高了医学图像分割的准确性和鲁棒性。|
|🆕 发布|Evaluating Reasoning Faithfulness in Medical Vision-Language Models using Multimodal Perturbations|使用多模态扰动评估医学视觉语言模型中的推理忠实性|Johannes Moll, Markus Graf, Tristan Lemke, Nicolas Lenhart, Daniel Truhn, Jean-Benoit Delbrouck, Jiazhen Pan, Daniel Rueckert .etc.|<http://arxiv.org/pdf/2510.11196v1>|提出了一种评估医学视觉语言模型推理忠实性的框架，通过多模态扰动揭示了答案准确性与解释质量之间的不一致...|
|📝 更新|PD-Diag-Net: Clinical-Priors guided Network on Brain MRI for Auxiliary Diagnosis of Parkinson's Disease|PD-Diag-Net：基于临床先验的脑部MRI辅助诊断帕金森病网络|Shuai Shao, Shu Jiang, Shiyuan Zhao, Di Yang, Yan Wang, Yutong Bai, Jianguo Zhang, Jiangtao Wang|<http://arxiv.org/pdf/2509.23719v2>|提出了一种利用临床先验知识的脑部MRI自动化诊断方法PD-Diag-Net，提高了帕金森病早期诊断的...|
|🆕 发布|Frequency Domain Unlocks New Perspectives for Abdominal Medical Image Segmentation|频域分析为腹部医学图像分割带来新视角|Kai Han, Siqi Ma, Chengxuan Qian, Jun Chen, Chongwen Lyu, Yuqing Song, Zhe Liu|<http://arxiv.org/pdf/2510.11005v1>|提出 foreground-aware 频域分割框架，增强低对比度医学图像的分割准确性和细节识别。|
|📝 更新|Vision-Language Cross-Attention for Real-Time Autonomous Driving|用于实时自动驾驶的视觉-语言交叉注意力机制|Santosh Patapati, Trisanth Srinivasan, Murari Ambati|<http://arxiv.org/pdf/2507.23064v3>|提出了一种融合视觉、地图和导航目标的实时自动驾驶模型，通过交叉注意力机制提升驾驶准确性和效率。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|COCO-Tree: Compositional Hierarchical Concept Trees for Enhanced Reasoning in Vision Language Models|COCO-树：用于视觉语言模型增强推理的组合层次概念树|Sanchit Sinha, Guangzhi Xiong, Aidong Zhang|<http://arxiv.org/pdf/2510.11012v1>|提出COCO-Tree方法，通过结合大型语言模型生成的概念树增强视觉语言模型的组合推理能力。|


### 可解释视觉智能 (Explainable Visual Intelligence)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Chart-RVR: Reinforcement Learning with Verifiable Rewards for Explainable Chart Reasoning|图表推理的可验证奖励强化学习：用于解释性图表推理的Chart-RVR|Sanchit Sinha, Oana Frunza, Kashif Rasul, Yuriy Nevmyvaka, Aidong Zhang|<http://arxiv.org/pdf/2510.10973v1>|提出Chart-RVR框架，通过强化学习与可验证奖励提升图表推理模型的鲁棒性和可解释性。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Fast and Scalable Normal Integration using Continuous Components|面向快速和可扩展的法线积分的连续组件使用方法|Francesco Milano, Jen Jen Chung, Lionel Ott, Roland Siegwart|<http://arxiv.org/pdf/2510.11508v1>|将表面法线积分问题转化为连续组件相对尺度估计，大幅减少优化变量，实现快速高效表面重建。|
|📝 更新|DDFusion:Degradation-Decoupled Fusion Framework for Robust Infrared and Visible Images Fusion|DDFusion：去退化耦合融合框架用于稳健的红外与可见光图像融合|Tianpei Zhang, Jufeng Zhao, Yiming Zhu, Guangmang Cui, Yuxin Jing|<http://arxiv.org/pdf/2504.10871v2>|[代码](https://github.com/Lmmh058/DDFusion.); 提出了一种针对红外与可见光图像融合的DDFusion框架，有效解决了实际场景中的退化问题，实现了更优...|
|🆕 发布|Reliable Cross-modal Alignment via Prototype Iterative Construction|通过原型迭代构建实现可靠的跨模态对齐|Xiang Ma, Litian Xu, Lexin Fang, Caiming Zhang, Lizhen Cui|<http://arxiv.org/pdf/2510.11175v1>|提出了一种迭代构建原型的方法来抑制风格干扰，实现了更可靠的跨模态对齐。|

