## [UPDATED!] **2025-10-14** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UniFusion: Vision-Language Model as Unified Encoder in Image Generation|统一融合：将视觉-语言模型作为图像生成中的统一编码器|Kevin Li, Manuel Brack, Sudeep Katakol, Hareesh Ravi, Ajinkya Kale|<http://arxiv.org/pdf/2510.12789v1>|提出UniFusion模型，利用大型视觉语言模型作为统一编码器，通过层注意力池化提升图像生成和编辑能...|
|🆕 发布|Beyond Seeing: Evaluating Multimodal LLMs on Tool-Enabled Image Perception, Transformation, and Reasoning|超越视觉：评估工具增强型图像感知、转换与推理的多模态大型语言模型|Xingang Guo, Utkarsh Tyagi, Advait Gosai, Paula Vergara, Ernesto Gabriel Hernández Montoya, Chen Bo Calvin Zhang, Bin Hu, Yunzhong He .etc.|<http://arxiv.org/pdf/2510.12712v1>|提出了IRIS基准，评估大型多模态语言模型在动态图像处理和复杂视觉-文本任务中的能力。|
|🆕 发布|On the Use of Hierarchical Vision Foundation Models for Low-Cost Human Mesh Recovery and Pose Estimation|基于层次化视觉基础模型的低成本人体网格恢复与姿态估计|Shuhei Tarashima, Yushan Wang, Norio Tagawa|<http://arxiv.org/pdf/2510.12660v1>|提出了一种基于层次化视觉基础模型的低成本人体网格恢复与姿态估计方法，实现了性能与计算效率的优化平衡。|
|🆕 发布|A Review of Longitudinal Radiology Report Generation: Dataset Composition, Methods, and Performance Evaluation|《纵向放射学报告生成的回顾：数据集构成、方法及性能评估》|Shaoyang Zhou, Yingshu Li, Yunyi Liu, Lingqiao Liu, Lei Wang, Luping Zhou|<http://arxiv.org/pdf/2510.12444v1>|系统综述了利用纵向数据生成胸部X光放射报告的方法，提升了报告的临床准确性和效率。|
|📝 更新|Benchmarking foundation models for hyperspectral image classification: Application to cereal crop type mapping|高光谱图像分类基准模型评估：应用于谷物作物类型映射|Walid Elbarz, Mohamed Bourriz, Hicham Hajji, Hamd Ait Abdelali, François Bourzeix|<http://arxiv.org/pdf/2510.11576v2>|评估了三种基础模型在小麦作物分类中的应用，发现SpectralEarth模型性能最优，强调了模型架构...|
|🆕 发布|Playmate2: Training-Free Multi-Character Audio-Driven Animation via Diffusion Transformer with Reward Feedback|Playmate2：基于扩散变换器和奖励反馈的无训练多角色音频驱动动画|Xingpei Ma, Shenneng Huang, Jiaran Cai, Yuansheng Guan, Shen Zheng, Hanfeng Zhao, Qiang Zhang, Shunsi Zhang|<http://arxiv.org/pdf/2510.12089v1>|提出了一种无需训练的基于扩散变换器的多角色音频驱动动画生成方法，提高了唇同步准确性和视频时序连贯性。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SRUM: Fine-Grained Self-Rewarding for Unified Multimodal Models|SRUM：统一多模态模型中的细粒度自奖励|Weiyang Jin, Yuwei Niu, Jiaqi Liao, Chengqi Duan, Aoxue Li, Shenghua Gao, Xihui Liu|<http://arxiv.org/pdf/2510.12784v1>|提出SRUM框架，通过模型自身理解模块为生成模块提供反馈，提升图像生成质量。|
|🆕 发布|Personalized Federated Fine-Tuning of Vision Foundation Models for Healthcare|面向医疗健康的视觉基础模型个性化联邦微调|Adam Tupper, Christian Gagné|<http://arxiv.org/pdf/2510.12741v1>|提出了一种个性化的联邦微调方法，通过学习正交LoRA适配器分离通用和特定客户知识，有效利用各客户端数...|
|📝 更新|Human-MME: A Holistic Evaluation Benchmark for Human-Centric Multimodal Large Language Models|以人为中心的跨模态大型语言模型的全局评估基准：Human-MME|Yuansen Liu, Haiming Tang, Jinlong Peng, Jiangning Zhang, Xiaozhong Ji, Qingdong He, Wenbin Wu, Donghao Luo .etc.|<http://arxiv.org/pdf/2509.26165v2>|[代码](https://github.com/Yuan-Hou/Human-MME.); 提出Human-MME基准，全面评估多模态大语言模型在以人为中心的场景理解能力。|
|📝 更新|Contrast Sensitivity in Multimodal Large Language Models: A Psychophysics-Inspired Evaluation|多模态大型语言模型中的对比度敏感性：一种受心理物理学启发的评估方法|Pablo Hernández-Cámara, Alexandra Gomez-Villa, Jose Manuel Jaén-Lorites, Jorge Vila-Tomás, Valero Laparra, Jesus Malo|<http://arxiv.org/pdf/2508.10367v2>|引入了一种基于人类心理物理学的方法，评估了多模态大型语言模型对视觉特征的感知能力。|
|📝 更新|CryoFastAR: Fast Cryo-EM Ab Initio Reconstruction Made Easy|“CryoFastAR：快速冷冻电镜从头重构轻松实现”|Jiakai Zhang, Shouchen Zhou, Haizhao Dai, Xinhang Liu, Peihao Wang, Zhiwen Fan, Yuan Pei, Jingyi Yu|<http://arxiv.org/pdf/2506.05864v2>|提出CryoFastAR模型，通过直接预测姿态实现快速冷冻电镜三维重构，大幅提升效率和准确性。|
|📝 更新|AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model|《AndesVL技术报告：一种高效移动端多模态大型语言模型》|Zhiwei Jin, Xiaohui Song, Nan Wang, Yafei Liu, Chao Li, Xin Li, Ruichen Wang, Zhihao Li .etc.|<http://arxiv.org/pdf/2510.11496v2>|提出了一种适用于移动端的轻量级多模态大语言模型AndesVL，通过1+N LoRA架构和QALFT框...|
|🆕 发布|MAPS: Masked Attribution-based Probing of Strategies- A computational framework to align human and model explanations|掩码归因探策略（MAPS）：一种使人类解释与模型解释对齐的计算框架|Sabine Muzellec, Yousif Kashef Alghetaa, Simon Kornblith, Kohitij Kar|<http://arxiv.org/pdf/2510.12141v1>|提出了一种名为MAPS的计算框架，通过比较人类和模型在解释视觉信息时的策略，有效评估和选择神经网络解...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SAIL-Embedding Technical Report: Omni-modal Embedding Foundation Model|《SAIL-Embedding技术报告：全模态嵌入基础模型》|Lin Lin, Jiefeng Long, Zhihe Wan, Yuchi Wang, Dingkang Yang, Shuang Yang, Yueyang Yao, Xu Chen .etc.|<http://arxiv.org/pdf/2510.12709v1>|提出了SAIL-Embedding模型，通过多阶段训练策略和架构设计，解决了多模态嵌入模型在真实应用...|
|🆕 发布|Unlocking Zero-Shot Plant Segmentation with Pl@ntNet Intelligence|解锁基于Pl@ntNet智能的零样本植物分割方法|Simon Ravé, Jean-Christophe Lombardo, Pejman Rasti, Alexis Joly, David Rousseau|<http://arxiv.org/pdf/2510.12579v1>|利用Plantnet智能，提出零样本植物分割方法，通过细化粗略分割掩码，有效解决农业图像分割问题。|
|📝 更新|FlexAC: Towards Flexible Control of Associative Reasoning in Multimodal Large Language Models|FlexAC：面向多模态大型语言模型中关联推理的灵活控制|Shengming Yuan, Xinyu Lyu, Shuailong Wang, Beitao Chen, Jingkuan Song, Lianli Gao|<http://arxiv.org/pdf/2510.11190v2>|[代码](https://github.com/ylhz/FlexAC.); 提出FlexAC框架，实现了对多模态大语言模型中联想推理灵活控制，显著提升创意性和减少幻觉。|
|🆕 发布|UniGS: Unified Geometry-Aware Gaussian Splatting for Multimodal Rendering|统一几何感知高斯散点绘制方法用于多模态渲染|Yusen Xie, Zhenmin Huang, Jianhao Jiao, Dimitrios Kanoulas, Jun Ma|<http://arxiv.org/pdf/2510.12174v1>|提出了一种统一的高保真多模态三维重建框架，通过几何感知的高斯散点渲染优化了旋转和缩放属性。|
|📝 更新|Towards Robust and Realible Multimodal Misinformation Recognition with Incomplete Modality|面向鲁棒与可靠的多模态虚假信息识别：处理不完整模态问题|Hengyang Zhou, Yiwei Wei, Jian Yang, Zhenyu Zhang|<http://arxiv.org/pdf/2510.05839v3>|[代码](https://github.com/zhyhome/MMLNet.); 提出了一种应对多媒体信息缺失问题的稳健多模态融合策略，有效提升了虚假信息识别的准确性和鲁棒性。|
|📝 更新|GarmageNet: A Multimodal Generative Framework for Sewing Pattern Design and Generic Garment Modeling|GarmageNet：一种用于缝纫图案设计和通用服装建模的多模态生成框架|Siran Li, Ruiyang Liu, Chen Liu, Zhendong Wang, Gaofeng He, Yong-Lu Li, Xiaogang Jin, Huamin Wang|<http://arxiv.org/pdf/2504.01483v4>|[代码](https://style3d.github.io/garmagenet); 提出了GarmageNet框架，自动化地将2D裁片图案转化为逼真的3D服装模型，简化了数字服装制作流...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Detect Anything via Next Point Prediction|通过下一个点预测检测任意目标|Qing Jiang, Junan Huo, Xingyu Chen, Yuda Xiong, Zhaoyang Zeng, Yihao Chen, Tianhe Ren, Junzhi Yu .etc.|<http://arxiv.org/pdf/2510.12798v1>|提出Rex-Omni模型，通过特殊token和强化学习优化坐标预测，实现零样本检测性能超越传统回归模...|
|📝 更新|Constructing a Real-World Benchmark for Early Wildfire Detection with the New PYRONEAR-2025 Dataset|构建面向早期森林火灾检测的实际世界基准：基于新的PYRONEAR-2025数据集|Mateo Lostanlen, Nicolas Isla, Jose Guillen, Renzo Zanca, Felix Veith, Cristian Buc, Valentin Barriere|<http://arxiv.org/pdf/2402.05349v3>|[代码](https://github.com/joseg20/wildfires2025); 构建了大规模多样化的PYRONEAR-2025数据集，提升早期野火烟雾检测模型的训练与评估效果。|
|📝 更新|Enhancing Representations through Heterogeneous Self-Supervised Learning|通过异构自监督学习增强表示|Zhong-Yu Li, Bo-Wen Yin, Yongxiang Liu, Li Liu, Ming-Ming Cheng|<http://arxiv.org/pdf/2310.05108v4>|[代码](https://github.com/NK-JittorCV/Self-Supervised); 提出异构自监督学习方法，通过辅助异构头提升基础模型的表征质量，实现多种视觉任务性能提升。|
|📝 更新|HccePose(BF): Predicting Front & Back Surfaces to Construct Ultra-Dense 2D-3D Correspondences for Pose Estimation|HccePose(BF)：预测前后表面以构建超密集二维-三维对应关系用于姿态估计|Yulin Wang, Mengting Hu, Hongli Li, Chen Luo|<http://arxiv.org/pdf/2510.10177v2>|[代码](https://github.com/WangYuLin-SEU/HCCEPose.); 提出预测物体前后表面3D坐标的方法，通过超密集2D-3D对应提升姿态估计精度。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OpenLex3D: A Tiered Evaluation Benchmark for Open-Vocabulary 3D Scene Representations|开放词汇三维场景表示的分层评估基准：OpenLex3D|Christina Kassab, Sacha Morin, Martin Büchner, Matías Mattamala, Kumaraditya Gupta, Abhinav Valada, Liam Paull, Maurice Fallon|<http://arxiv.org/pdf/2503.19764v2>|[代码](https://openlex3d.github.io/.); 提出了OpenLex3D，一个用于评估开放词汇3D场景表示的分层评价基准，引入了丰富的语言标注以捕捉...|
|🆕 发布|APGNet: Adaptive Prior-Guided for Underwater Camouflaged Object Detection|APGNet：自适应先验引导的水下伪装目标检测|Xinxin Huang, Han Sun, Junmin Cai, Ningzhong Liu, Huiyu Zhou|<http://arxiv.org/pdf/2510.12056v1>|提出APGNet网络，通过结合先验引导机制和图像增强技术，有效提升了水下伪装目标检测的准确性和鲁棒性...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Function Centric Perspective On Flat and Sharp Minima|《关于平坦和尖锐极小值的函数中心视角》|Israel Mason-Williams, Gabryel Mason-Williams, Helen Yannakoudakis|<http://arxiv.org/pdf/2510.12451v1>|重新审视尖锐度在模型性能中的作用，提出其是函数依赖属性，并通过实证研究显示尖锐极小值可带来更好的泛化...|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MVP4D: Multi-View Portrait Video Diffusion for Animatable 4D Avatars|多视角肖像视频扩散以实现可动画化的四维虚拟化身|Felix Taubner, Ruihang Zhang, Mathieu Tuli, Sherwin Bahmani, David B. Lindell|<http://arxiv.org/pdf/2510.12785v1>|提出了一种基于单张参考图像生成高质量多视角动态数字人类的方法，大幅提升了真实感和三维一致性。|
|🆕 发布|FlashVSR: Towards Real-Time Diffusion-Based Streaming Video Super-Resolution|FlashVSR：面向实时扩散基于流的视频超分辨率|Junhao Zhuang, Shi Guo, Xin Cai, Xiaohui Li, Yihao Liu, Chun Yuan, Tianfan Xue|<http://arxiv.org/pdf/2510.12747v1>|提出FlashVSR，首个实现实时视频超分辨率的一步扩散模型，通过三阶段训练和稀疏注意力显著提升效率...|
|📝 更新|TTT3R: 3D Reconstruction as Test-Time Training|TTT3R：测试时训练的三维重建|Xingyu Chen, Yue Chen, Yuliang Xiu, Andreas Geiger, Anpei Chen|<http://arxiv.org/pdf/2509.26645v2>|[代码](https://rover-xingyu.github.io/TTT3R); 提出了一种测试时训练方法TTT3R，通过在线学习显著提升3D重建模型在长度泛化上的性能。|
|🆕 发布|DiffEM: Learning from Corrupted Data with Diffusion Models via Expectation Maximization|差分期望最大化：通过扩散模型从损坏数据中学习|Danial Hosseintabar, Fan Chen, Giannis Daras, Antonio Torralba, Constantinos Daskalakis|<http://arxiv.org/pdf/2510.12691v1>|提出了一种利用期望最大化从损坏数据中训练扩散模型的新方法DiffEM，有效解决了仅能获取损坏或噪声数...|
|📝 更新|Denoised Diffusion for Object-Focused Image Augmentation|去噪扩散用于对象聚焦的图像增强|Nisha Pillai, Aditi Virupakshaiah, Harrison W. Smith, Amanda J. Ashworth, Prasanna Gowda, Phillip R. Owens, Adam R. Rivers, Bindu Nanduri .etc.|<http://arxiv.org/pdf/2510.08955v2>|提出针对动物健康监测的数据增强框架，通过分割和扩散合成技术，有效提升数据稀缺场景下的动物检测性能。|
|📝 更新|Image Quality Assessment for Embodied AI|具身人工智能的图像质量评估|Chunyi Li, Jiaohao Xiao, Jianbo Zhang, Farong Wen, Zicheng Zhang, Yuan Tian, Xiangyang Zhu, Xiaohong Liu .etc.|<http://arxiv.org/pdf/2505.16815v2>|[代码](https://github.com/lcysyzxdxc/EmbodiedIQA); 提出 Embodied-IQA 方法，为Embodied AI场景下的图像质量评估提供了首个数据库和...|
|📝 更新|OmniLens: Towards Universal Lens Aberration Correction via LensLib-to-Specific Domain Adaptation|全焦透镜：通过LensLib至特定领域适配实现通用镜头像差校正|Qi Jiang, Yao Gao, Shaohua Gao, Zhonghua Yi, Xiaolong Qian, Hao Shi, Kailun Yang, Lei Sun .etc.|<http://arxiv.org/pdf/2409.05809v2>|[代码](https://github.com/zju-jiangqi/OmniLens.); 提出了OmniLens，通过构建全面覆盖的镜头库和快速领域自适应，实现了通用镜头像差校正的强泛化能力...|
|🆕 发布|Voronoi-Assisted Diffusion for Computing Unsigned Distance Fields from Unoriented Points|Voronoi图辅助扩散算法计算无符号距离场|Jiayi Kong, Chen Zong, Junkai Deng, Xuhui Chen, Fei Hou, Shiqing Xin, Junhui Hou, Chen Qian .etc.|<http://arxiv.org/pdf/2510.12524v1>|提出了一种无需神经网络的Voronoi-Assisted Diffusion方法，直接从无向点云计算...|
|🆕 发布|Scene Coordinate Reconstruction Priors|场景坐标重建先验|Wenjing Bian, Axel Barroso-Laguna, Tommaso Cavallari, Victor Adrian Prisacariu, Eric Brachmann|<http://arxiv.org/pdf/2510.12387v1>|引入重建先验，提升3D场景表示学习效果，增强场景点云连贯性和相机定位准确性。|
|📝 更新|NinA: Normalizing Flows in Action. Training VLA Models with Normalizing Flows|NinA：动作中的归一化流。使用归一化流训练VLA模型|Denis Tarasov, Alexander Nikulin, Ilya Zisman, Albina Klepach, Nikita Lyubaykin, Andrei Polubarov, Alexander Derevyagin, Vladislav Kurenkov|<http://arxiv.org/pdf/2508.16845v2>|提出了一种基于归一化流的快速高效动作解码器，大幅减少了推理时间而不牺牲性能。|
|📝 更新|SPEED: Scalable, Precise, and Efficient Concept Erasure for Diffusion Models|SPEED：可扩展、精确、高效的概念擦除方法用于扩散模型|Ouxiang Li, Yuan Wang, Xinting Hu, Houcheng Jiang, Tao Liang, Yanbin Hao, Guojun Ma, Fuli Feng|<http://arxiv.org/pdf/2503.07392v3>|[代码](https://github.com/Ouxiang-Li/SPEED.); 提出了一种高效的概念擦除方法SPEED，通过直接编辑模型参数精确擦除目标概念，同时保留非目标概念的生...|
|📝 更新|AsynFusion: Towards Asynchronous Latent Consistency Models for Decoupled Whole-Body Audio-Driven Avatars|异步融合：面向解耦全身音频驱动角色的异步潜在一致性模型|Tianbao Zhang, Jian Zhao, Yuer Li, Zheng Zhu, Ping Hu, Zhaoxin Fan, Wenjun Wu, Xuelong Li|<http://arxiv.org/pdf/2505.15058v2>|提出异步融合框架AsynFusion，通过双向特征交互和异步采样策略，实现更自然的全身音频驱动动画。|
|📝 更新|Finding Dori: Memorization in Text-to-Image Diffusion Models Is Not Local|《寻找多莉：文本到图像扩散模型中的记忆并非局部化》|Antoni Kowalczuk, Dominik Hintersdorf, Lukas Struppek, Kristian Kersting, Adam Dziedzic, Franziska Boenisch|<http://arxiv.org/pdf/2507.16880v2>|挑战了文本到图像扩散模型中记忆局部化的假设，提出通过对抗性微调实现更稳健的防御。|
|📝 更新|Highlighting What Matters: Promptable Embeddings for Attribute-Focused Image Retrieval|凸显关键所在：用于属性聚焦图像检索的可提示嵌入向量|Siting Li, Xiang Gao, Simon Shaolei Du|<http://arxiv.org/pdf/2505.15877v2>|提出了一种通过可提示图像嵌入来增强属性关注图像检索性能的方法，有效解决了现有模型在处理特定属性查询时...|
|🆕 发布|Self-Supervised Selective-Guided Diffusion Model for Old-Photo Face Restoration|自监督选择性引导扩散模型在老照片面部修复中的应用|Wenjie Li, Xiangyi Wang, Heng Guo, Guangwei Gao, Zhanyu Ma|<http://arxiv.org/pdf/2510.12114v1>|[代码](https://github.com/PRIS-CV/SSDiff.); 提出了一种自监督选择性引导扩散模型，有效恢复了老照片中的人脸细节和自然色彩。|
|📝 更新|VR-Thinker: Boosting Video Reward Models through Thinking-with-Image Reasoning|VR-Thinker：通过图像推理思考提升视频奖励模型|Qunzhong Wang, Jie Liu, Jiajun Liang, Yilei Jiang, Yuanxing Zhang, Jinyuan Chen, Yaozhi Zheng, Xintao Wang .etc.|<http://arxiv.org/pdf/2510.10518v2>|提出VR-Thinker框架，通过视觉推理操作和可配置视觉内存窗口提升视频奖励模型准确性和可靠性。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AnyUp: Universal Feature Upsampling|AnyUp：通用特征上采样|Thomas Wimmer, Prune Truong, Marie-Julie Rakotosaona, Michael Oechsle, Federico Tombari, Bernt Schiele, Jan Eric Lenssen|<http://arxiv.org/pdf/2510.12764v1>|提出了一种通用的特征上采样方法AnyUp，无需针对特定特征进行训练，提升了上采样质量和效率。|
|🆕 发布|VISaGE: Understanding Visual Generics and Exceptions|“VISaGE：理解视觉泛型与异常”|Stella Frank, Emily Allaway|<http://arxiv.org/pdf/2510.12548v1>|提出VISaGE数据集，揭示了视觉语言模型在处理典型与异常图像时的概念理解差异。|
|🆕 发布|Tensor Completion via Monotone Inclusion: Generalized Low-Rank Priors Meet Deep Denoisers|通过单调包含的张量完成：广义低秩先验与深度去噪器的结合|Peng Chen, Deliang Wei, Jiale Yao, Fang Li|<http://arxiv.org/pdf/2510.12425v1>|提出了一种基于单调包含原理的 tensor 完成框架，整合广义低秩先验与深度去噪器，实现了全局收敛和...|
|📝 更新|UVE: Are MLLMs Unified Evaluators for AI-Generated Videos?|UVE：大规模语言模型是否为AI生成视频的统一评估者？|Yuanxin Liu, Rui Zhu, Shuhuai Ren, Jiacong Wang, Haoyuan Guo, Xu Sun, Lu Jiang|<http://arxiv.org/pdf/2503.09949v3>|探究了使用多模态大语言模型作为AI生成视频的统一评估器的可行性，并提出UVE-Bench基准进行验证...|
|📝 更新|STRIDE-QA: Visual Question Answering Dataset for Spatiotemporal Reasoning in Urban Driving Scenes|STRIDE-QA：面向城市驾驶场景中的时空推理视觉问答数据集|Keishi Ishihara, Kento Sasaki, Tsubasa Takahashi, Daiki Shiono, Yu Yamaguchi|<http://arxiv.org/pdf/2508.10427v2>|提出了STRIDE-QA数据集，通过大规模视觉问答任务促进自动驾驶系统对动态交通场景的精确时空推理。|
|🆕 发布|FedHUG: Federated Heterogeneous Unsupervised Generalization for Remote Physiological Measurements|联邦异构无监督泛化用于远程生理测量|Xiao Yang, Jiyao Wang|<http://arxiv.org/pdf/2510.12132v1>|提出FedHUG框架，通过无监督学习实现跨域生理参数估计，解决隐私敏感数据缺乏标签的问题。|
|🆕 发布|MetaCaptioner: Towards Generalist Visual Captioning with Open-source Suites|元标注器：面向通用视觉标注的开源工具套件|Zhenxin Lei, Zhangwei Gao, Changyao Tian, Erfei Cui, Guanzhou Chen, Danni Yang, Yuchen Duan, Zhaokai Wang .etc.|<http://arxiv.org/pdf/2510.12126v1>|提出CapFlow多代理协作流程，实现开源模型生成与GPT-4.1质量相当的视觉字幕，降低成本89....|
|🆕 发布|G4Splat: Geometry-Guided Gaussian Splatting with Generative Prior|几何引导的高斯散点绘制与生成先验方法：G4Splat|Junfeng Ni, Yixin Chen, Zhifei Yang, Yu Liu, Ruijie Lu, Song-Chun Zhu, Siyuan Huang|<http://arxiv.org/pdf/2510.12099v1>|[代码](https://dali-jack.github.io/g4splat-web); 利用平面结构推导精确深度图，通过几何指导提升三维场景重建质量和一致性。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DarkIR: Robust Low-Light Image Restoration|《DarkIR：稳健的低光照图像恢复》|Daniel Feijoo, Juan C. Benito, Alvaro Garcia, Marcos V. Conde|<http://arxiv.org/pdf/2412.13443v3>|[代码](https://github.com/cidautai/DarkIR); 提出了一种多任务低光图像复原的神经网络，通过新注意力机制增强CNN感受野，实现了计算成本降低和性能提...|
|🆕 发布|SPORTS: Simultaneous Panoptic Odometry, Rendering, Tracking and Segmentation for Urban Scenes Understanding|SPORTS：面向城市场景理解的同步全景里程、渲染、跟踪与分割|Zhiliu Yang, Jinyu Dai, Jianyuan Zhang, Zhu Yang|<http://arxiv.org/pdf/2510.12749v1>|整合全景分割、视觉测距与场景渲染，SPORTS框架全面提升城市场景理解的准确性与真实性。|
|📝 更新|Joint Embedding vs Reconstruction: Provable Benefits of Latent Space Prediction for Self Supervised Learning|联合嵌入与重建：自监督学习中潜在空间预测的可证明优势|Hugues Van Assel, Mark Ibrahim, Tommaso Biancalani, Aviv Regev, Randall Balestriero|<http://arxiv.org/pdf/2505.12477v2>|揭示了自监督学习中联合嵌入与重建两种范式的核心机制，证明了在无关特征显著时联合嵌入方法更具优势。|
|🆕 发布|Omni-Captioner: Data Pipeline, Models, and Benchmark for Omni Detailed Perception|全方位标注器：全方位细节感知的数据管道、模型与基准|Ziyang Ma, Ruiyang Xu, Zhenghao Xing, Yunfei Chu, Yuxuan Wang, Jinzheng He, Jin Xu, Pheng-Ann Heng .etc.|<http://arxiv.org/pdf/2510.12720v1>|提出Omni-Detective数据生成管道和Omni-Captioner模型，实现了对多模态细节的...|
|🆕 发布|EReLiFM: Evidential Reliability-Aware Residual Flow Meta-Learning for Open-Set Domain Generalization under Noisy Labels|证据可靠性感知的残差流元学习用于带噪声标签的开集领域泛化|Kunyu Peng, Di Wen, Kailun Yang, Jia Fu, Yufan Chen, Ruiping Liu, Jiamin Wu, Junwei Zheng .etc.|<http://arxiv.org/pdf/2510.12687v1>|[代码](https://github.com/KPeng9510/ERELIFM.); 提出了一种用于开放式域泛化的元学习方法，通过残差流和证据可靠性提升在噪声标签下的性能。|
|🆕 发布|Advancing End-to-End Pixel Space Generative Modeling via Self-supervised Pre-training|通过自监督预训练推进端到端像素空间生成建模|Jiachen Lei, Keli Liu, Julius Berner, Haiming Yu, Hongkai Zheng, Jiahong Wu, Xiangxiang Chu|<http://arxiv.org/pdf/2510.12586v1>|提出了一种两阶段预训练框架，显著提升了像素空间生成模型的性能和效率。|
|📝 更新|TreeDiffusion: Hierarchical Generative Clustering for Conditional Diffusion|树扩散：条件扩散的层次生成聚类|Jorge da Silva Gonçalves, Laura Manduchi, Moritz Vandenhirtz, Julia E. Vogt|<http://arxiv.org/pdf/2410.16910v2>|通过将扩散模型与VAE学习的层级聚类表示相结合，TreeDiffusion实现了高质量、针对性强的生...|
|🆕 发布|WaterFlow: Explicit Physics-Prior Rectified Flow for Underwater Saliency Mask Generation|水流：显式物理先验修正流用于水下显著性掩码生成|Runting Li, Shijie Lian, Hua Li, Yutong Li, Wenhui Wu, Sam Kwong|<http://arxiv.org/pdf/2510.12605v1>|提出WaterFlow框架，将水下成像物理信息作为先验直接融入网络训练，增强水下显著目标检测能力。|
|🆕 发布|LayerSync: Self-aligning Intermediate Layers|层同步：自对齐中间层|Yasaman Haghighi, Bastien van Delft, Mariam Hassan, Alexandre Alahi|<http://arxiv.org/pdf/2510.12581v1>|[代码](https://github.com/vita-epfl/LayerSync.); 提出LayerSync方法，通过内部层间指导提升扩散模型生成质量和训练效率。|
|🆕 发布|Unconditional Human Motion and Shape Generation via Balanced Score-Based Diffusion|无条件人体运动与形状生成：基于平衡评分的扩散方法|David Björkstrand, Tiesheng Wang, Lars Bretzner, Josephine Sullivan|<http://arxiv.org/pdf/2510.12537v1>|通过特征空间归一化和分析得出的权重优化，实现了无需额外辅助损失的高效无条件人体运动与形状生成。|
|🆕 发布|Learning Human Motion with Temporally Conditional Mamba|学习基于时间条件的Mamba人体运动|Quang Nguyen, Tri Le, Baoru Huang, Minh Nhat Vu, Ngan Le, Thieu Vo, Anh Nguyen|<http://arxiv.org/pdf/2510.12573v1>|[代码](https://zquang2202.github.io/TCM.); 引入了Temporally Conditional Mamba模型，通过整合条件信息到Mamba块的...|
|🆕 发布|MS-GAGA: Metric-Selective Guided Adversarial Generation Attack|MS-GAGA：度量子选导向导对抗生成攻击|Dion J. X. Ho, Gabriel Lee Jun Rong, Niharika Shrivastava, Harshavardhan Abichandani, Pai Chet Ng, Xiaoxiao Miao|<http://arxiv.org/pdf/2510.12468v1>|提出MS-GAGA方法，通过双阶段框架生成难以察觉且跨模型有效的对抗样本，显著提高了对深度伪造检测器...|
|🆕 发布|BSGS: Bi-stage 3D Gaussian Splatting for Camera Motion Deblurring|BSGS：双阶段三维高斯散点法用于相机运动去模糊|An Zhao, Piaopiao Yu, Zhe Zhu, Mingqiang Wei|<http://arxiv.org/pdf/2510.12493v1>|提出双阶段3D高斯散点法，优化相机姿态和纠正运动模糊，显著提升运动模糊图像的3D场景重建质量。|
|🆕 发布|Low-Field Magnetic Resonance Image Quality Enhancement using a Conditional Flow Matching Model|低场磁共振图像质量增强：基于条件流匹配模型的方法|Huu Tien Nguyen, Ahmed Karam Eldaly|<http://arxiv.org/pdf/2510.12408v1>|提出了一种基于条件流匹配的图像质量增强框架，有效提升了低场磁共振成像的信号质量和诊断效果。|
|🆕 发布|Towards General Urban Monitoring with Vision-Language Models: A Review, Evaluation, and a Research Agenda|面向通用城市监控的视觉-语言模型：综述、评估与研究议程|André Torneiro, Diogo Monteiro, Paulo Novais, Pedro Rangel Henriques, Nuno F. Rodrigues|<http://arxiv.org/pdf/2510.12400v1>|探讨了视觉语言模型在通用城市监测中的应用，强调了其在零样本任务中的潜力。|
|🆕 发布|Hybrid Gaussian Splatting for Novel Urban View Synthesis|混合高斯散点法用于新城市视图合成|Mohamed Omran, Farhad Zanjani, Davide Abati, Jens Petersen, Amirhossein Habibian|<http://arxiv.org/pdf/2510.12308v1>|提出了一种结合高斯散点和扩散模型的两阶段方法，用于生成高质量的新视角城市街景渲染。|
|📝 更新|Extremely low-bitrate Image Compression Semantically Disentangled by LMMs from a Human Perception Perspective|由人类感知视角通过LMMs实现语义解耦的极低比特率图像压缩|Juan Song, Lijie Yang, Mingtao Feng|<http://arxiv.org/pdf/2503.00399v4>|提出了一种基于人类感知机制的图像压缩框架SEDIC，在极低比特率下实现了语义一致性和高感知质量。|
|🆕 发布|BIGFix: Bidirectional Image Generation with Token Fixing|双向图像生成与标记固定方法：BIGFix|Victor Besnier, David Hurych, Andrei Bursuc, Eduardo Valle|<http://arxiv.org/pdf/2510.12231v1>|提出了一种自我修正的图像生成方法，通过迭代优化采样到的令牌，同时保持并行预测的高效性。|
|📝 更新|Reframing Image Difference Captioning with BLIP2IDC and Synthetic Augmentation|用BLIP2IDC和合成增强方法重构图像差异标注|Gautier Evennou, Antoine Chaffin, Vivien Chappelier, Ewa Kijak|<http://arxiv.org/pdf/2412.15939v2>|提出了一种适应图像差异描述任务的框架BLIP2IDC，并通过合成数据增强显著提升了模型性能。|
|🆕 发布|BEEP3D: Box-Supervised End-to-End Pseudo-Mask Generation for 3D Instance Segmentation|BEEP3D：基于框监督的端到端伪掩码生成用于三维实例分割|Youngju Yoo, Seho Kim, Changick Kim|<http://arxiv.org/pdf/2510.12182v1>|提出了BEEP3D方法，通过端到端训练生成伪掩码，有效解决了3D实例分割中的标注成本和定位模糊问题。|
|🆕 发布|ImageSentinel: Protecting Visual Datasets from Unauthorized Retrieval-Augmented Image Generation|图像哨兵：保护视觉数据集免受未经授权的检索增强图像生成的影响|Ziyuan Luo, Yangyi Zhao, Ka Chun Cheung, Simon See, Renjie Wan|<http://arxiv.org/pdf/2510.12119v1>|[代码](https://github.com/luo-ziyuan/ImageSentinel.); 提出ImageSentinel框架，通过合成 sentinel 图像保护视觉数据集免受 RAIG 系...|
|📝 更新|IWR-Bench: Can LVLMs reconstruct interactive webpage from a user interaction video?|IWR-Bench：LVLMs能否从用户交互视频中重建交互式网页？|Yang Chen, Minghao Liu, Yufan Shen, Yunwen Li, Tianyuan Huang, Xinyu Fang, Tianyu Zheng, Wenxuan Huang .etc.|<http://arxiv.org/pdf/2509.24709v2>|[代码](https://github.com/L-O-I/IWR-Bench.); 提出了IWR-Bench，用于评估大型视觉语言模型从视频中重建交互式网页的能力，揭示了当前模型在处理...|
|🆕 发布|IL3D: A Large-Scale Indoor Layout Dataset for LLM-Driven 3D Scene Generation|IL3D：用于LLM驱动的3D场景生成的大规模室内布局数据集|Wenxu Zhou, Kaixuan Nie, Hang Du, Dong Yin, Wei Huang, Siqiang Guo, Xiaobo Zhang, Pengbo Hu|<http://arxiv.org/pdf/2510.12095v1>|提出了IL3D大规模室内布局数据集，助力大型语言模型驱动的3D场景生成，提升室内设计训练数据多样性和...|
|🆕 发布|VIDMP3: Video Editing by Representing Motion with Pose and Position Priors|VIDMP3：通过姿态和位置先验表示运动进行视频编辑|Sandeep Mishra, Oindrila Saha, Alan C. Bovik|<http://arxiv.org/pdf/2510.12069v1>|[代码](https://github.com/sandeep-sm/VidMP3.); 提出了一种利用姿态和位置先验学习运动表示的视频编辑方法，实现了结构及语义的灵活性同时保持原始运动。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Zero-Shot CFC: Fast Real-World Image Denoising based on Cross-Frequency Consistency|基于跨频率一致性的快速现实世界图像去噪：零样本CFC|Yanlin Jiang, Yuchen Liu, Mingren Liu|<http://arxiv.org/pdf/2510.12646v1>|提出了一种基于单张噪声图像的零样本去噪方法ZSCFC，有效克服了噪声分布假设的限制并提升了计算效率与...|
|📝 更新|Learning Adaptive and Temporally Causal Video Tokenization in a 1D Latent Space|在1D潜在空间中学习自适应和时序因果的视频标记化|Yan Li, Changyao Tian, Renqiu Xia, Ning Liao, Weiwei Guo, Junchi Yan, Hongsheng Li, Jifeng Dai .etc.|<http://arxiv.org/pdf/2505.17011v2>|提出了一种自适应时序因果视频标记化方法，根据视频内容灵活分配帧标记，实现了更高效的视频重建和生成。|
|📝 更新|Macro-from-Micro Planning for High-Quality and Parallelized Autoregressive Long Video Generation|从微观到宏观规划实现高质量并行化自回归长视频生成|Xunzhi Xiang, Yabo Chen, Guiyu Zhang, Zhongyu Wang, Zhe Gao, Quanming Xiang, Gonghu Shang, Junqi Liu .etc.|<http://arxiv.org/pdf/2508.03334v3>|提出了一种长视频生成框架MMPL，通过分阶段规划关键帧实现高质量且可并行生成的长视频。|
|📝 更新|Massive Activations are the Key to Local Detail Synthesis in Diffusion Transformers|大规模激活是扩散变换器中局部细节合成的关键|Chaofan Gan, Zicheng Zhao, Yuanpeng Tu, Xi Chen, Ziran Qin, Tieyuan Chen, Mehrtash Harandi, Weiyao Lin|<http://arxiv.org/pdf/2510.11538v2>|揭示了大规模激活在视觉生成中关键作用，并提出了一种增强局部细节的新策略。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|E-MoFlow: Learning Egomotion and Optical Flow from Event Data via Implicit Regularization|E-MoFlow：通过隐式正则化从事件数据中学习自我运动和光流|Wenpu Li, Bangyan Liao, Yi Zhou, Qi Xu, Pian Wan, Peidong Liu|<http://arxiv.org/pdf/2510.12753v1>|E-MoFlow通过隐式正则化统一了无监督范式下的自运动和光流估计，实现了优于现有方法的性能。|
|🆕 发布|Vectorized Video Representation with Easy Editing via Hierarchical Spatio-Temporally Consistent Proxy Embedding|通过分层时空一致代理嵌入实现的易于编辑的矢量化视频表示|Ye Chen, Liming Tan, Yupeng Zhu, Yuanbin Wang, Bingbing Ni|<http://arxiv.org/pdf/2510.12256v1>|提出了一种稳定的视频表示方法，通过层次化时空一致代理节点，有效应对视频中的运动和遮挡问题，并支持精细...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Uncertainty Matters in Dynamic Gaussian Splatting for Monocular 4D Reconstruction|单目4D重建中动态高斯散点法的误差不确定性至关重要|Fengzhi Guo, Chih-Chuan Hsu, Sihao Ding, Cheng Zhang|<http://arxiv.org/pdf/2510.12768v1>|引入了不确定性感知的动态高斯散点框架USplat4D，通过优化不确定性提高单目4D重建的稳定性和质量...|
|🆕 发布|CurriFlow: Curriculum-Guided Depth Fusion with Optical Flow-Based Temporal Alignment for 3D Semantic Scene Completion|CurriFlow：基于光流时间对齐的 curriculum 指导深度融合用于三维语义场景补全|Jinzhou Lin, Jie Zhou, Wenhao Xu, Rongtao Xu, Changwei Wang, Shunpeng Chen, Kexue Fu, Yihua Shao .etc.|<http://arxiv.org/pdf/2510.12362v1>|CurriFlow通过结合光流时空对齐和分阶段深度融合策略，有效提升了自动驾驶中三维场景语义完成的准...|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MCOP: Multi-UAV Collaborative Occupancy Prediction|多无人机协同占用预测：MCOP|Zefu Lin, Wenbo Chen, Xiaojuan Jin, Yuran Yang, Lue Fan, Yixin Zhang, Yufeng Zhang, Zhaoxiang Zhang|<http://arxiv.org/pdf/2510.12679v1>|提出了一种多无人机协同占用预测框架，通过空间感知特征编码和跨无人机特征整合，有效保留了场景的3D结构...|
|🆕 发布|MMOT: The First Challenging Benchmark for Drone-based Multispectral Multi-Object Tracking|多光谱多目标跟踪的首个挑战性基准：基于无人机的MMOT|Tianhao Li, Tingfa Xu, Ying Wang, Haolin Qin, Xu Lin, Jianan Li|<http://arxiv.org/pdf/2510.12565v1>|[代码](https://github.com/Annzstbl/MMOT.); 提出首个无人机多光谱多目标跟踪基准MMOT，通过融合多光谱图像和方向感知技术，显著提升小目标和密集场...|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|VideoRFT: Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning|视频RFT：通过强化微调激励多模态大型语言模型中的视频推理能力|Qi Wang, Yanrui Yu, Ye Yuan, Rui Mao, Tianfei Zhou|<http://arxiv.org/pdf/2505.12434v4>|提出VideoRFT方法，通过强化微调培养多模态语言模型的人类级视频推理能力。|
|🆕 发布|VideoLucy: Deep Memory Backtracking for Long Video Understanding|VideoLucy：深度记忆回溯用于长视频理解|Jialong Zuo, Yongtai Deng, Lingdong Kong, Jingkang Yang, Rui Jin, Yiwei Zhang, Nong Sang, Liang Pan .etc.|<http://arxiv.org/pdf/2510.12422v1>|提出VideoLucy框架，通过深度记忆回溯解决长视频理解和细节保留难题，显著提升性能。|
|🆕 发布|Dual Learning with Dynamic Knowledge Distillation and Soft Alignment for Partially Relevant Video Retrieval|双学习策略结合动态知识蒸馏与软对齐用于部分相关视频检索|Jianfeng Dong, Lei Huang, Daizong Liu, Xianke Chen, Xun Yang, Changting Lin, Xun Wang, Meng Wang|<http://arxiv.org/pdf/2510.12283v1>|[代码](https://github.com/HuiGuanLab/DL-DKD.); 提出了一种针对部分相关视频检索的框架，通过动态知识蒸馏和软对齐学习，有效处理长视频中的复杂背景内容。|
|🆕 发布|State Space Prompting via Gathering and Spreading Spatio-Temporal Information for Video Understanding|通过聚集与扩散时空信息进行状态空间提示以实现视频理解|Jiahuan Zhou, Kai Zhu, Zhenyu Cui, Zichen Liu, Xu Zou, Gang Hua|<http://arxiv.org/pdf/2510.12160v1>|提出了一种结合帧内和帧间提示的 State Space Prompting 方法，有效聚合和传播视频...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Probabilistic Temporal Masked Attention for Cross-view Online Action Detection|概率时间遮蔽注意力机制在多视角在线动作检测中的应用|Liping Xie, Yang Tan, Shicheng Jing, Huimin Lu, Kanjian Zhang|<http://arxiv.org/pdf/2508.17025v2>|提出了一种概率时间遮蔽注意力模型，通过跨视角视频帧的潜在压缩表示，有效提高了在线动作检测在不同视角下...|
|🆕 发布|Learning to Recognize Correctly Completed Procedure Steps in Egocentric Assembly Videos through Spatio-Temporal Modeling|通过空间时间建模学习识别第一视角装配视频中的正确完成步骤|Tim J. Schoonbeek, Shao-Hsuan Hung, Dan Lehman, Hans Onvlee, Jacek Kustra, Peter H. N. de With, Fons van der Sommen|<http://arxiv.org/pdf/2510.12385v1>|[代码](https://timschoonbeek.github.io/stormpsr); 提出了一种结合空间与时间特征的模型STORM-PSR，有效识别遮挡下的组装步骤完成情况。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|EgoBrain: Synergizing Minds and Eyes For Human Action Understanding|自我大脑：融合思维与视觉以理解人类行为|Nie Lin, Yansen Wang, Dongqi Han, Weibang Jiang, Jingyuan Li, Ryosuke Furuta, Yoichi Sato, Dongsheng Li|<http://arxiv.org/pdf/2506.01353v2>|首次创建了大规模同步的视觉与脑电波数据集，并开发了一种融合这两种模态的多模态学习框架，提高了人类行为...|
|📝 更新|Prompt-guided Representation Disentanglement for Action Recognition|动作识别中的提示引导表示解耦|Tianci Wu, Guangming Zhu, Jiang Lu, Siyuan Wang, Ning Wang, Nuoye Xiong, Zhang Liang|<http://arxiv.org/pdf/2509.21783v3>|[代码](https://github.com/iamsnaping/ProDA.git); 提出ProDA框架，通过动态提示模块和图解析神经网络分离多动作场景中的特定动作。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GTPBD: A Fine-Grained Global Terraced Parcel and Boundary Dataset|GTPBD：一种细粒度全局梯田地块与边界数据集|Zhiwei Zhang, Zi Ye, Yibin Wen, Shuai Yuan, Haohuan Fu, Jianxi Huang, Juepeng Zheng|<http://arxiv.org/pdf/2507.14697v2>|提出了全球首个细粒度梯田地块和边界数据集GTPBD，为复杂梯田地形的高精度农业分析提供了基础数据支持...|


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DRL: Discriminative Representation Learning with Parallel Adapters for Class Incremental Learning|深度强化学习：带有并行适配器的判别性表征学习用于类别增量学习|Jiawei Zhan, Jun Liu, Jinlong Peng, Xiaochen Chen, Bin-Bin Gao, Yong Liu, Chengjie Wang|<http://arxiv.org/pdf/2510.12107v1>|提出DRL框架，通过增量学习中的轻量级适配器和解耦监督策略，有效解决类增量学习中的模型复杂度、表示偏...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ViCO: A Training Strategy towards Semantic Aware Dynamic High-Resolution|ViCO：面向语义感知动态高分辨率训练策略|Long Cui, Weiyun Wang, Jie Shao, Zichen Wen, Gen Luo, Linfeng Zhang, Yanting Zhang, Yu Qiao .etc.|<http://arxiv.org/pdf/2510.12793v1>|提出ViCO训练策略，通过视觉一致性学习减少视觉token数量，根据图像语义复杂度动态调整，提升多模...|
|🆕 发布|Efficient Real-World Deblurring using Single Images: AIM 2025 Challenge Report|使用单张图像的高效真实世界去模糊：AIM 2025 挑战报告|Daniel Feijoo, Paula Garrido-Mellado, Marcos V. Conde, Jaesung Rim, Alvaro Garcia, Sunghyun Cho, Radu Timofte|<http://arxiv.org/pdf/2510.12788v1>|提出了高效的单张图像去模糊方法，在严格参数和计算预算下实现31.1298 dB的PSNR。|
|📝 更新|How to Train Your Metamorphic Deep Neural Network|如何训练你的变形深度神经网络|Thomas Sommariva, Simone Calderara, Angelo Porrello|<http://arxiv.org/pdf/2505.05510v2>|[代码](https://github.com/TSommariva/HTTY_NeuMeta.); 提出了一种改进的Neural Metamorphosis训练算法，实现了全网络的可变宽度和深度，同时...|
|🆕 发布|TerraCodec: Compressing Earth Observations|TerraCodec：压缩地球观测数据|Julen Costa-Watanabe, Isabelle Wittmann, Benedikt Blumenstiel, Konrad Schindler|<http://arxiv.org/pdf/2510.12670v1>|提出TerraCodec，一种针对地球观测数据设计的压缩算法，通过利用时间依赖性实现高效压缩和云修复...|
|📝 更新|Logarithmic Mathematical Morphology: theory and applications|对数数学形态学：理论与应用|Guillaume Noyel|<http://arxiv.org/pdf/2309.02007v2>|提出对数数学形态学框架，解决光照变化问题，增强图像分析稳健性。|
|📝 更新|Online Topological Localization for Navigation Assistance in Bronchoscopy|支气管镜导航辅助的在线拓扑定位|Clara Tomasini, Luis Riazuelo, Ana C. Murillo|<http://arxiv.org/pdf/2510.09144v2>|提出了一种无需患者CT扫描的图像基于支气管镜拓扑定位方法，有效辅助手术导航。|
|🆕 发布|PAGS: Priority-Adaptive Gaussian Splatting for Dynamic Driving Scenes|PAGS：动态驾驶场景的优先级自适应高斯散点喷射|Ying A, Wenzhang Sun, Chang Zeng, Chunfeng Wang, Hao Li, Jianxun Cui|<http://arxiv.org/pdf/2510.12282v1>|引入了优先级自适应高斯散点法（PAGS），通过任务感知的语义优先级优化三维城市场景重建与渲染效率。|
|🆕 发布|DIANet: A Phase-Aware Dual-Stream Network for Micro-Expression Recognition via Dynamic Images|DIANet：一种基于动态图像的相位感知双流网络用于微表情识别|Vu Tram Anh Khuong, Luu Tu Nguyen, Thi Bich Phuong Man, Thanh Ha Le, Thi Duyen Ngo|<http://arxiv.org/pdf/2510.12219v1>|提出了一种双流网络DIANet，通过区分微表情的不同阶段来提高微表情识别的准确性。|
|🆕 发布|Hardware-aware Coding Function Design for Compressive Single-Photon 3D Cameras|面向硬件的压缩单光子三维相机编码函数设计|David Parra, Felipe Gutierrez-Barragan, Trevor Seets, Andreas Velten|<http://arxiv.org/pdf/2510.12123v1>|提出了一种优化编码函数的方法，提升压缩单光子3D相机在硬件限制下的性能。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Fast Visuomotor Policy for Robotic Manipulation|机器人操作快速视觉运动策略|Jingkai Jia, Tong Yang, Xueyao Chen, Chenhuan Liu, Wenqiang Zhang|<http://arxiv.org/pdf/2510.12483v1>|提出了一种高效的机器人操作策略框架Energy Policy，通过单次前向传播预测多模态动作，实现高...|
|🆕 发布|Deep Attention-guided Adaptive Subsampling|深度注意力引导的自适应子采样|Sharath M Shankaranarayana, Soumava Kumar Roy, Prasad Sudhakar, Chandan Aladahalli|<http://arxiv.org/pdf/2510.12376v1>|提出了一种动态的注意力引导自适应子采样框架，有效降低计算复杂度并提升神经网络性能。|
|📝 更新|Optimally Deep Networks -- Adapting Model Depth to Datasets for Superior Efficiency|最优深度网络——根据数据集调整模型深度以实现卓越效率|Shaharyar Ahmed Khan Tareen, Filza Khan Tareen|<http://arxiv.org/pdf/2510.10764v2>|提出了一种自适应模型深度的优化网络训练策略，有效平衡模型复杂度与任务需求，减少资源消耗。|
|🆕 发布|An Adaptive Edge-Guided Dual-Network Framework for Fast QR Code Motion Deblurring|一种自适应边缘引导的双网络框架用于快速QR码运动去模糊|Jianping Li, Dongyang Guo, Wenjie Li, Wei Zhao|<http://arxiv.org/pdf/2510.12098v1>|[代码](https://github.com/leejianping/ADNet); 提出了一种自适应双边网络框架，通过边缘引导的注意力模块显著提升二维码去模糊效果和速度。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Robust Real-Time Endoscopic Stereo Matching under Fuzzy Tissue Boundaries|实时鲁棒性内镜立体匹配算法研究：模糊组织边界下的匹配|Yang Ding, Can Han, Sijia Du, Yaqi Wang, Dahong Qian|<http://arxiv.org/pdf/2503.00731v2>|[代码](https://github.com/Sonne-Ding/RRESM.); 提出了一种针对内窥镜图像的实时立体匹配方法，通过增强位置敏感注意力和高频细节优化，实现了高准确度和实...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Your VAR Model is Secretly an Efficient and Explainable Generative Classifier|您的向量自回归模型实际上是一个高效且可解释的生成分类器|Yi-Chung Chen, David I. Inouye, Jing Gao|<http://arxiv.org/pdf/2510.12060v1>|提出了一种基于视觉自回归模型的生成分类器，提高了分类效率和可解释性。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|What If : Understanding Motion Through Sparse Interactions|如果怎样：通过稀疏交互理解运动|Stefan Andreas Baumann, Nick Stracke, Timy Phan, Björn Ommer|<http://arxiv.org/pdf/2510.12777v1>|[代码](https://compvis.github.io/flow-poke-transformer.); 提出了一种预测物理场景局部运动分布的新框架，通过稀疏交互实现多模态场景运动理解和不确定性表达。|
|📝 更新|Hands-Free Heritage: Automated 3D Scanning for Cultural Heritage Digitization|"无需手动干预的遗产数字化：文化遗产自动三维扫描"|Javed Ahmad, Federico Dassiè, Selene Frascella, Gabriele Marchello, Ferdinando Cannella, Arianna Traviglia|<http://arxiv.org/pdf/2510.04781v2>|实现了无需手动干预的自动化双机器人3D扫描系统，大幅提升了文化遗产数字化精度和效率。|
|📝 更新|Funny-Valen-Tine: Planning Solution Distribution Enhances Machine Abstract Reasoning Ability|《Funny-Valen-Tine：规划解决方案分布增强机器抽象推理能力》|Ruizhuo Song, Beiming Yuan|<http://arxiv.org/pdf/2407.02688v3>|[代码](https://github.com/Yuanbeiming/Funny-Valen-Tine-Planning-Solution-Distribution-Enhances-Machine-Abstract-Reasoning-Ability); 提出了一种概率突出基线Valen和分布规划方法Funny，显著增强了机器的抽象推理能力。|
|🆕 发布|Local Background Features Matter in Out-of-Distribution Detection|局部背景特征在分布外检测中至关重要|Jinlun Ye, Zhuohao Sun, Yiqiao Qiu, Qiu Li, Zhijun Tan, Ruixuan Wang|<http://arxiv.org/pdf/2510.12259v1>|利用本地背景特征作为伪OOD特征进行训练，有效减轻了神经网络在OOD数据上的过度自信问题。|
|🆕 发布|Ivan-ISTD: Rethinking Cross-domain Heteroscedastic Noise Perturbations in Infrared Small Target Detection|伊凡-ISTD：重新思考红外小目标检测中的跨域异方差噪声扰动|Yuehui Li, Yahao Lu, Haoyuan Wu, Sen Zhang, Liang Lin, Yukai Shi|<http://arxiv.org/pdf/2510.12241v1>|[代码](https://github.com/nanjin1/Ivan-ISTD.); 提出了一种双重波导不变性学习框架Ivan-ISTD，有效应对红外小目标检测中的跨域偏移和异方差噪声扰...|
|🆕 发布|Class-aware Domain Knowledge Fusion and Fission for Continual Test-Time Adaptation|面向类别的域知识融合与裂变用于持续测试时适应|Jiahuan Zhou, Chao Zhu, Zhenyu Cui, Zichen Liu, Xu Zou, Gang Hua|<http://arxiv.org/pdf/2510.12150v1>|提出了一种类感知的域知识融合与裂变方法，有效解决连续测试时适应中的知识遗忘和新知识学习不足问题。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|StegOT: Trade-offs in Steganography via Optimal Transport|通过最优传输在隐写术中的权衡：StegOT|Chengde Lin, Xuezhu Gong, Shuxue Ding, Mingzhe Yang, Xijun Lu, Chengjun Mo|<http://arxiv.org/pdf/2509.11178v2>|[代码](https://github.com/Rss1124/StegOT.); 提出了一种基于最优传输理论的自动编码器模型StegOT，有效解决了图像隐写中的信息不平衡问题。|
|🆕 发布|A Review on Domain Adaption and Generative Adversarial Networks(GANs)|关于域自适应与生成对抗网络（GANs）的综述|Aashish Dhawan, Divyanshu Mudgal|<http://arxiv.org/pdf/2510.12075v1>|综述了领域自适应方法，以利用已有模型预测不同领域数据，解决标注数据稀缺问题。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PET Head Motion Estimation Using Supervised Deep Learning with Attention|使用监督深度学习与注意力机制的PET头部运动估计|Zhuotong Cai, Tianyi Zeng, Jiazhen Zhang, Eléonore V. Lieffrig, Kathryn Fontaine, Chenyu You, Enette Mae Revilla, James S. Duncan .etc.|<http://arxiv.org/pdf/2510.12758v1>|[代码](https://github.com/maxxxxxxcai/DL-HMC-TMI.); 提出了一种基于深度学习的PET头部运动估计方法，有效克服了硬件运动跟踪的限制，实现了高精度的运动校正...|
|📝 更新|Modular Embedding Recomposition for Incremental Learning|模块化嵌入重组成增量学习|Aniello Panariello, Emanuele Frascaroli, Pietro Buzzega, Lorenzo Bonicelli, Angelo Porrello, Simone Calderara|<http://arxiv.org/pdf/2508.16463v2>|[代码](https://github.com/aimagelab/mammoth.); 提出了一种增强预训练视觉语言模型零样本分类能力的方法，通过模块化嵌入重组提升增量学习性能。|
|📝 更新|Mind the (Data) Gap: Evaluating Vision Systems in Small Data Applications|关注数据差距：在小数据应用中评估视觉系统|Samuel Stevens, S M Rayeed, Jenna Kline|<http://arxiv.org/pdf/2504.06486v2>|对比了多模态大语言模型与仅视觉方法在小数据场景下的表现，强调了在AI研究中对小数据集评估的重要性。|
|📝 更新|Capturing More: Learning Multi-Domain Representations for Robust Online Handwriting Verification|捕捉更多：学习多域表示以实现鲁棒的在线手写验证|Peirong Zhang, Kai Ding, Lianwen Jin|<http://arxiv.org/pdf/2508.01427v2>|[代码](https://github.com/NiceRingNode/SPECTRUM.); 提出SPECTRUM模型，融合时间-频率多域表征，显著提升在线手写验证的准确性。|
|📝 更新|Tracing Back the Malicious Clients in Poisoning Attacks to Federated Learning|追溯联邦学习中中毒攻击的恶意客户端|Yuqi Jia, Minghong Fang, Hongbin Liu, Jinghuai Zhang, Neil Zhenqiang Gong|<http://arxiv.org/pdf/2407.07221v2>|提出FLForensics方法，针对联邦学习中数据投毒攻击后追溯恶意客户端。|
|📝 更新|Levarging Learning Bias for Noisy Anomaly Detection|利用学习偏差进行噪声异常检测|Yuxin Zhang, Yunkang Cao, Yuqi Cheng, Yihan Sun, Weiming Shen|<http://arxiv.org/pdf/2508.07441v2>|[代码](https://github.com/hustzhangyuxin/LLBNAD.); 利用模型学习偏差，提出两阶段框架，有效应对含噪声训练数据的图像异常检测挑战。|
|📝 更新|FOCUS on Contamination: A Geospatial Deep Learning Framework with a Noise-Aware Loss for Surface Water PFAS Prediction|关注污染：一种带有噪声感知损失的地学空间深度学习框架用于地表水PFAS预测|Jowaria Khan, Alexa Friedman, Sydney Evans, Rachel Klein, Runzi Wang, Katherine E. Manz, Kaley Beins, David Q. Andrews .etc.|<http://arxiv.org/pdf/2502.14894v3>|提出了一种地理空间深度学习框架，通过噪声感知损失函数预测PFAS水污染，提高了预测准确性。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|REACT3D: Recovering Articulations for Interactive Physical 3D Scenes|REACT3D：为交互式物理三维场景恢复关节|Zhao Huang, Boyang Sun, Alexandros Delitzas, Jiaqi Chen, Marc Pollefeys|<http://arxiv.org/pdf/2510.11340v2>|提出了一种零样本框架REACT3D，将静态3D场景转化为可交互的仿真副本，实现高效互动物理场景构建。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Gaussian Semantic Field for One-shot LiDAR Global Localization|高斯语义场用于单次激光雷达全局定位|Pengyu Yin, Shenghai Yuan, Haozhi Cao, Xingyu Ji, Ruofei Bai, Siyu Chen, Lihua Xie|<http://arxiv.org/pdf/2510.12101v1>|提出了一种基于连续函数的LiDAR全局定位算法，通过语义分布建模改善了一帧定位的准确性。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|InternScenes: A Large-scale Simulatable Indoor Scene Dataset with Realistic Layouts|《InternScenes：一个具有真实布局的大型可模拟室内场景数据集》|Weipeng Zhong, Peizhou Cao, Yichen Jin, Li Luo, Wenzhe Cai, Jingli Lin, Hanqing Wang, Zhaoyang Lyu .etc.|<http://arxiv.org/pdf/2509.10813v2>|提出了InternScenes，一个包含40,000个多样化场景的大型室内场景数据集，通过整合真实世...|
|📝 更新|EvolveNav: Empowering LLM-Based Vision-Language Navigation via Self-Improving Embodied Reasoning|EvolveNav：通过自我提升的具身推理赋能基于LLM的视觉语言导航|Bingqian Lin, Yunshuang Nie, Khun Loun Zai, Ziming Wei, Mingfei Han, Rongtao Xu, Minzhe Niu, Jianhua Han .etc.|<http://arxiv.org/pdf/2506.01551v3>|[代码](https://github.com/expectorlin/EvolveNav.); 提出EvolveNav方法，通过自我优化的具身推理提升大语言模型在视觉语言导航任务中的表现和泛化能力...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DeepMMSearch-R1: Empowering Multimodal LLMs in Multimodal Web Search|深度多模态搜索-R1：提升多模态大型语言模型在多模态网络搜索中的能力|Kartik Narayan, Yang Xu, Tian Cao, Kavya Nerella, Vishal M. Patel, Navid Shiee, Peter Grasch, Chao Jia .etc.|<http://arxiv.org/pdf/2510.12801v1>|提出了一种多模态大型语言模型DeepMMSearch-R1，通过动态构建查询和迭代优化，有效提升多模...|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VQArt-Bench: A semantically rich VQA Benchmark for Art and Cultural Heritage|VQArt-Bench：艺术与文化遗产行业语义丰富的视觉问答基准|A. Alfarano, L. Venturoli, D. Negueruela del Castillo|<http://arxiv.org/pdf/2510.12750v1>|提出了VQArt-Bench，一个针对文化遗产领域的大型VQA基准，通过多代理管道生成多样化问题，揭...|
|📝 更新|FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions|《FlagEval 发现报告：对自动验证文本和视觉问题的大规模推理模型的初步评估》|Bowen Qin, Chen Yue, Fang Yin, Hui Wang, JG Yao, Jiakang Liu, Jing-Shu Zheng, Miguel Hu Chen .etc.|<http://arxiv.org/pdf/2509.17177v2>|[代码](https://flageval-baai.github.io/LRM-Eval); 评估大型推理模型在自动验证文本和视觉问题上的表现，并发布ROME视觉语言模型推理测试基准。|
|📝 更新|Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions|探索视觉语言模型的边界：当前方法综述与未来方向|Akash Ghosh, Arkadeep Acharya, Sriparna Saha, Vinija Jain, Aman Chadha|<http://arxiv.org/pdf/2404.07214v4>|系统梳理了视觉语言模型的发展，分类并分析了各类模型的优势与局限，展望了未来研究方向。|
|📝 更新|CoRGI: Verified Chain-of-Thought Reasoning with Post-hoc Visual Grounding|CoRGI：带有后验视觉定位的验证链式思维推理|Shixin Yi, Lin Shang|<http://arxiv.org/pdf/2508.00378v3>|提出了一种后验视觉验证框架CoRGI，有效减少视觉语言模型推理中的虚构现象，提高答案准确性和解释真实...|
|📝 更新|In the Eye of MLLM: Benchmarking Egocentric Video Intent Understanding with Gaze-Guided Prompting|在MLLM之眼：以视线引导提示为基准的自主视角视频意图理解|Taiying Peng, Jiacheng Hua, Miao Liu, Feng Lu|<http://arxiv.org/pdf/2509.07447v2>|[代码](https://taiyi98.github.io/projects); 提出EgoGazeVQA基准，利用视线信息提升大型多模态语言模型对第一视角视频用户意图的理解。|
|📝 更新|OST-Bench: Evaluating the Capabilities of MLLMs in Online Spatio-temporal Scene Understanding|OST-Bench：评估大规模语言模型在在线时空场景理解中的能力|Jingli Lin, Chenming Zhu, Runsen Xu, Xiaohan Mao, Xihui Liu, Tai Wang, Jiangmiao Pang|<http://arxiv.org/pdf/2507.07984v2>|[代码](https://rbler1234.github.io/OSTBench.github.io); 提出了OST-Bench，一种评估大型多模态语言模型在线时空场景理解能力的全新基准，揭示了现有模型在...|
|🆕 发布|HoneyBee: Data Recipes for Vision-Language Reasoners|《蜜蜂蜜：面向视觉语言推理者的数据配方》|Hritik Bansal, Devandra Singh Sachan, Kai-Wei Chang, Aditya Grover, Gargi Ghosh, Wen-tau Yih, Ramakanth Pasunuru|<http://arxiv.org/pdf/2510.12225v1>|提出数据筛选策略并构建大规模高质量推理数据集HoneyBee，提升视觉语言模型推理能力。|
|🆕 发布|CompoDistill: Attention Distillation for Compositional Reasoning in Multimodal LLMs|《CompoDistill：多模态大规模语言模型中的组合推理注意力蒸馏》|Jiwan Kim, Kibum Kim, Sangwoo Seo, Chanyoung Park|<http://arxiv.org/pdf/2510.12184v1>|提出CompoDistill方法，通过视觉注意力对齐提升小型多模态模型在视觉感知任务上的表现。|
|📝 更新|DSM: Constructing a Diverse Semantic Map for 3D Visual Grounding|DSM：构建用于三维视觉定位的多样化语义地图|Qinghongbing Xie, Zijian Liang, Fuhao Li, Long Zeng|<http://arxiv.org/pdf/2504.08307v2>|提出Diverse Semantic Map框架，融合多维度语义信息，显著提升3D视觉定位准确性和解...|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vision Language Models Map Logos to Text via Semantic Entanglement in the Visual Projector|视觉语言模型通过视觉投影器的语义纠缠将标志映射到文本|Sifan Li, Hongkai Chen, Yujun Cai, Qingwen Ye, Liyang Chen, Junsong Yuan, Yiwei Wang|<http://arxiv.org/pdf/2510.12287v1>|揭示了视觉语言模型在识别无文字标志时的错误机制，并提出了减少错误的方法。|
|📝 更新|GeoRanker: Distance-Aware Ranking for Worldwide Image Geolocalization|GeoRanker：面向全球图像地理定位的距离感知排序|Pengyue Jia, Seongheon Park, Song Gao, Xiangyu Zhao, Sharon Li|<http://arxiv.org/pdf/2505.13731v3>|提出了一种距离感知的图像地理定位排名框架GeoRanker，通过编码查询-候选交互和预测地理接近度，...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CuMPerLay: Learning Cubical Multiparameter Persistence Vectorizations|CuMPerLay：学习立方体多参数持久向量化解|Caner Korkmaz, Brighton Nuwagira, Barış Coşkunuzer, Tolga Birdal|<http://arxiv.org/pdf/2510.12795v1>|提出CuMPerLay算法，将立方多参数持久性融入深度学习，提升图像分类和分割性能。|
|📝 更新|KonfAI: A Modular and Fully Configurable Framework for Deep Learning in Medical Imaging|KonfAI：用于医学成像中深度学习的模块化和完全可配置框架|Valentin Boussot, Jean-Louis Dillenseger|<http://arxiv.org/pdf/2508.09823v2>|[代码](https://github.com/vboussot/KonfAI.); KonfAI是一个模块化、可扩展且完全可配置的深度学习框架，通过YAML配置文件简化医疗影像任务的工...|
|🆕 发布|Hybrid Explanation-Guided Learning for Transformer-Based Chest X-Ray Diagnosis|混合解释引导学习：基于Transformer的胸部X射线诊断|Shelley Zixin Shu, Haozhe Luo, Alexander Poellinger, Mauricio Reyes|<http://arxiv.org/pdf/2510.12704v1>|提出了一种结合自监督和人工指导的Hybrid Explanation-Guided Learning...|
|📝 更新|J-RAS: Enhancing Medical Image Segmentation via Retrieval-Augmented Joint Training|J-RAS: 通过检索增强的联合训练提升医学图像分割|Salma J. Ahmed, Emad A. Mohammed, Azam Asilian Bidgoli|<http://arxiv.org/pdf/2510.09953v2>|提出了一种结合检索和分割的医学图像分割方法J-RAS，通过联合训练提升模型对复杂病例的泛化能力。|
|🆕 发布|A Text-Image Fusion Method with Data Augmentation Capabilities for Referring Medical Image Segmentation|文本-图像融合方法结合数据增强能力用于指示性医学图像分割|Shurong Chai, Rahul Kumar JAIN, Rui Xu, Shaocong Mo, Ruibo Hou, Shiyu Teng, Jiaqing Liu, Lanfen Lin .etc.|<http://arxiv.org/pdf/2510.12482v1>|[代码](https://github.com/11yxk/MedSeg_EarlyFusion.); 提出了一种融合文本与图像特征并具备数据增强能力的早期融合框架，实现了医学图像分割的性能提升。|
|📝 更新|BAAF: A benchmark attention adaptive framework for medical ultrasound image segmentation tasks|BAAF：用于医学超声图像分割任务的基准注意力自适应框架|Gongping Chen, Lei Zhao, Xiaotao Yin, Liang Cui, Jianxun Zhang, Yu Dai, Ningning Liu|<http://arxiv.org/pdf/2310.00919v3>|提出了一种 Benchmark Attention Adaptive Framework (BAAF...|
|📝 更新|Calibration and Uncertainty for multiRater Volume Assessment in multiorgan Segmentation (CURVAS) challenge results|多器官分割中多评估者体积评估的标定与不确定性（CURVAS）挑战结果|Meritxell Riera-Marin, Sikha O K, Julia Rodriguez-Comas, Matthias Stefan May, Zhaohong Pan, Xiang Zhou, Xiaokun Liang, Franciskus Xaverius Erick .etc.|<http://arxiv.org/pdf/2505.08685v2>|提出多标注者校准与不确定性评估框架，提升医学图像分割模型的可靠性和临床适用性。|
|🆕 发布|SpineBench: Benchmarking Multimodal LLMs for Spinal Pathology Analysis|脊柱病理分析多模态大型语言模型基准测试：SpineBench|Chenghanyu Zhang, Zekun Li, Peipei Li, Xing Cui, Shuhan Xia, Weixiang Yan, Yiqiao Zhang, Qianyu Zhuang|<http://arxiv.org/pdf/2510.12267v1>|[代码](https://zhangchenghanyu.github.io/SpineBench.github.io); 提出了SpineBench，一个针对脊柱疾病分析的视觉问答基准，评估多模态大语言模型在脊柱领域的性能...|
|🆕 发布|AngularFuse: A Closer Look at Angle-based Perception for Spatial-Sensitive Multi-Modality Image Fusion|角融合：对基于角度的空间敏感多模态图像融合的深入探讨|Xiaopeng Liu, Yupei Lin, Sen Zhang, Xiao Wang, Yukai Shi, Liang Lin|<http://arxiv.org/pdf/2510.12260v1>|提出角度感知框架AngularFuse，通过细粒度参考图像合成和角度感知损失，实现了多模态图像融合的...|
|🆕 发布|Multiplicative Loss for Enhancing Semantic Segmentation in Medical and Cellular Images|乘性损失以增强医学和细胞图像的语义分割|Yuto Yokoi, Kazuhiro Hotta|<http://arxiv.org/pdf/2510.12258v1>|提出两种新损失函数，通过乘法方式结合Cross Entropy和Dice Loss，有效提升医学和细...|
|🆕 发布|The Impact of Synthetic Data on Object Detection Model Performance: A Comparative Analysis with Real-World Data|合成数据对目标检测模型性能的影响：与真实世界数据的比较分析|Muammer Bay, Timo von Marcard, Dren Fazlija|<http://arxiv.org/pdf/2510.12208v1>|分析了合成数据对物体检测模型性能的影响，发现结合合成与真实数据可提升模型鲁棒性和效率。|
|📝 更新|Boosting Generic Semi-Supervised Medical Image Segmentation via Diverse Teaching and Label Propagation|通过多样化教学和标签传播提升通用半监督医学图像分割性能|Wei Li, Pengcheng Zhou, Linye Ma, Wenyi Zhao, Huihua Yang|<http://arxiv.org/pdf/2508.08549v2>|提出了一种通用半监督医学图像分割框架，通过多样化教学和标签传播有效应对标注限制和领域偏移问题。|
|🆕 发布|DPL: Spatial-Conditioned Diffusion Prototype Enhancement for One-Shot Medical Segmentation|DPL：空间条件扩散原型增强用于单次医学分割|Ziyuan Gao, Philippe Morel|<http://arxiv.org/pdf/2510.12159v1>|提出了一种基于扩散概率分布的医学图像分割原型增强方法，有效应对少量标注数据和患者间解剖变异性挑战。|
|📝 更新|Uncertainty-Supervised Interpretable and Robust Evidential Segmentation|不确定性监督的可解释与稳健证据分割|Yuzhu Li, An Sui, Fuping Wu, Xiahai Zhuang|<http://arxiv.org/pdf/2509.17098v2>|[代码](https://github.com/suiannaius/SURE.); 提出了一种自监督的不确定性估计方法，通过引导学习不确定性，增强了医学图像分割的准确性和鲁棒性。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving|"DriveVLA-W0：世界模型增强自动驾驶中的数据缩放法则"|Yingyan Li, Shuyao Shang, Weisong Liu, Bing Zhan, Haochen Wang, Yuqi Wang, Yuntao Chen, Xiaoman Wang .etc.|<http://arxiv.org/pdf/2510.12796v1>|提出DriveVLA-W0训练范式，通过世界模型预测未来图像，增强自动驾驶模型泛化能力并提升大数据训...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SAIP-Net: Enhancing Remote Sensing Image Segmentation via Spectral Adaptive Information Propagation|SAIP-Net：通过光谱自适应信息传播增强遥感图像分割|Zhongtao Wang, Xizhe Cao, Yisong Chen, Guoping Wang|<http://arxiv.org/pdf/2504.16564v2>|提出SAIP-Net，通过频谱自适应信息传播和多层次感受野增强，提高了遥感图像分割的精度和边界清晰度...|
|📝 更新|GeoVLM-R1: Reinforcement Fine-Tuning for Improved Remote Sensing Reasoning|GeoVLM-R1：强化微调以提高遥感推理能力|Mustansar Fiaz, Hiyam Debary, Paolo Fraccaro, Danda Paudel, Luc Van Gool, Fahad Khan, Salman Khan|<http://arxiv.org/pdf/2509.25026v3>|[代码](https://mustansarfiaz.github.io/GeoVLM-R1); 提出了一种结合任务感知奖励的强化学习微调框架，有效提升了遥感图像的任务推理能力。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|UrbanTwin: Building High-Fidelity Digital Twins for Sim2Real LiDAR Perception and Evaluation|《UrbanTwin：构建高保真数字孪生体以实现Sim2Real激光雷达感知与评估》|Muhammad Shahbaz, Shaurya Agarwal|<http://arxiv.org/pdf/2509.02903v2>|提出了一种构建高保真数字孪生方法，生成逼真合成数据集，有效提升LiDAR感知系统的Sim2Real学...|
|📝 更新|CoVLA: Comprehensive Vision-Language-Action Dataset for Autonomous Driving|自动驾驶的综合视觉-语言-动作数据集：CoVLA|Hidehisa Arai, Keita Miwa, Kento Sasaki, Yu Yamaguchi, Kohei Watanabe, Shunsuke Aoki, Issei Yamamoto|<http://arxiv.org/pdf/2408.10845v3>|提出了CoVLA数据集，融合视觉、语言和动作，为自动驾驶训练和评估提供全面平台。|
|🆕 发布|Hierarchical Reasoning with Vision-Language Models for Incident Reports from Dashcam Videos|基于视觉-语言模型的分层推理在行车记录仪视频事件报告中的应用|Shingo Yokoi, Kento Sasaki, Yu Yamaguchi|<http://arxiv.org/pdf/2510.12190v1>|[代码](https://github.com/riron1206/kaggle-2COOOL-2nd-Place-Solution.); 提出了一种结合视觉语言模型的多层次推理框架，用于从行车记录仪视频中生成准确的事故报告。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving|协同竞争模仿-强化学习在潜在世界模型中的自动驾驶|Xiaoji Zheng, Ziyuan Yang, Yanhao Chen, Yuhang Peng, Yuanrong Tang, Gengyuan Liu, Bokui Chen, Jiangtao Gong|<http://arxiv.org/pdf/2510.12560v1>|[代码](https://github.com/SEU-zxj/CoIRL-AD.); 提出CoIRL-AD框架，结合模仿学习和强化学习，有效提升自动驾驶模型的泛化能力和性能。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Reasoning in the Dark: Interleaved Vision-Text Reasoning in Latent Space|《在黑暗中进行推理：潜在空间中的视觉-文本交错推理》|Chao Chen, Zhixin Ma, Yongqi Li, Yupeng Hu, Yinwei Wei, Wenjie Li, Liqiang Nie|<http://arxiv.org/pdf/2510.12603v1>|[代码](https://github.com/FYYDCC/IVT-LR.); 提出了一种在潜在空间中融合视觉和文本信息的推理方法IVT-LR，减少了标注需求并提升了推理效率。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|mmWave Radar-Based Non-Line-of-Sight Pedestrian Localization at T-Junctions Utilizing Road Layout Extraction via Camera|利用相机提取道路布局的毫米波雷达基于非视距路口行人定位|Byeonggyu Park, Hee-Yeun Kim, Byonghyok Choi, Hansang Cho, Byungkwan Kim, Soomok Lee, Mingu Jeon, Seong-Woo Kim|<http://arxiv.org/pdf/2508.02348v2>|利用摄像头提取的道路布局辅助毫米波雷达点云数据，实现了对城市环境中非视线区域行人的准确定位。|
|🆕 发布|Efficient Perceptual Image Super Resolution: AIM 2025 Study and Benchmark|高效感知图像超分辨率：AIM 2025研究及基准|Bruno Longarela, Marcos V. Conde, Alvaro Garcia, Radu Timofte|<http://arxiv.org/pdf/2510.12765v1>|提出了一种高效的感知图像超分辨率方法，在严格参数和计算限制下优于现有技术。|
|📝 更新|Efficient Fine-Tuning of DINOv3 Pretrained on Natural Images for Atypical Mitotic Figure Classification (MIDOG 2025 Task 2 Winner)|基于自然图像预训练的DINOv3的高效微调用于非典型有丝分裂图像分类（MIDOG 2025任务2冠军）|Guillaume Balezo, Hana Feki, Raphaël Bourgade, Lily Monnier, Matthieu Blons, Alice Blondel, Etienne Decencière, Albert Pla Planas .etc.|<http://arxiv.org/pdf/2508.21041v3>|通过低秩适应和少量参数训练，有效将DINOv3模型应用于异常有丝分裂图像分类，取得领先性能。|

