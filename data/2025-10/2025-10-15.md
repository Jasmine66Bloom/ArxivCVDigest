## [UPDATED!] **2025-10-15** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Generative Universal Verifier as Multimodal Meta-Reasoner|生成性通用验证器作为多模态元推理器|Xinchen Zhang, Xiaoying Zhang, Youbin Wu, Yanbin Cao, Renrui Zhang, Ruihang Chu, Ling Yang, Yujiu Yang|<http://arxiv.org/pdf/2510.13804v1>|定位并提升了视觉语言模型中的多模态推理能力，通过创新的生成性通用验证器实现可靠反射与优化。|
|🆕 发布|Uni-MMMU: A Massive Multi-discipline Multimodal Unified Benchmark|统一多学科多模态统一基准：Uni-MMMU|Kai Zou, Ziqi Huang, Yuhao Dong, Shulin Tian, Dian Zheng, Hongbo Liu, Jingwen He, Bin Liu .etc.|<http://arxiv.org/pdf/2510.13759v1>|提出了Uni-MMMU基准，全面评估了统一多模态模型在理解和生成任务中的双向协同作用。|
|🆕 发布|UrbanFusion: Stochastic Multimodal Fusion for Contrastive Learning of Robust Spatial Representations|城市融合：用于对比学习鲁棒空间表示的随机多模态融合|Dominik J. Mühlematter, Lin Che, Ye Hong, Martin Raubal, Nina Wiedemann|<http://arxiv.org/pdf/2510.13774v1>|[代码](https://github.com/DominikM198/UrbanFusion.); UrbanFusion通过随机多模态融合技术，为城市现象预测提供了强大的多模态数据处理能力，实现了广...|
|🆕 发布|NExT-OMNI: Towards Any-to-Any Omnimodal Foundation Models with Discrete Flow Matching|NExT-OMNI：面向任意到任意全模态基础模型的离散流匹配方法|Run Luo, Xiaobo Xia, Lu Wang, Longze Chen, Renke Shan, Jing Luo, Min Yang, Tat-Seng Chua|<http://arxiv.org/pdf/2510.13721v1>|提出了NExT-OMNI模型，通过离散流范式实现任意模态间的统一理解和生成，提升了多模态交互和检索性...|
|📝 更新|Multimodal Fusion and Vision-Language Models: A Survey for Robot Vision|多模态融合与视觉-语言模型：机器人视觉的综述|Xiaofeng Han, Shunpeng Chen, Zenghuang Fu, Zhe Feng, Lue Fan, Dong An, Changwei Wang, Li Guo .etc.|<http://arxiv.org/pdf/2504.02477v3>|[代码](https://github.com/Xiaofeng-Han-Res/MF-RV.); 系统综述了多模态融合技术和视觉语言模型在机器人视觉中的应用与发展，提出了未来研究方向。|
|🆕 发布|UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning|UniME-V2：将多模态嵌入学习中的大规模语言模型作为评判标准|Tiancheng Gu, Kaicheng Yang, Kaichen Zhang, Xiang An, Ziyong Feng, Yueyi Zhang, Weidong Cai, Jiankang Deng .etc.|<http://arxiv.org/pdf/2510.13515v1>|提出了一种利用大型语言模型评估语义匹配的UniME-V2模型，有效提升了多模态嵌入学习的区分度。|
|🆕 发布|Generalizing WiFi Gesture Recognition via Large-Model-Aware Semantic Distillation and Alignment|通过大型模型感知的语义蒸馏与对齐推广WiFi手势识别|Feng-Qi Cui, Yu-Tong Guo, Tianyue Zheng, Jinyang Huang|<http://arxiv.org/pdf/2510.13390v1>|提出GLSDA框架，利用大型预训练模型语义先验增强WiFi手势识别的泛化能力和语义表现。|
|🆕 发布|FlyAwareV2: A Multimodal Cross-Domain UAV Dataset for Urban Scene Understanding|《FlyAwareV2：一种用于城市场景理解的多模态跨域无人机数据集》|Francesco Barbato, Matteo Caligiuri, Pietro Zanuttigh|<http://arxiv.org/pdf/2510.13243v1>|提出了FlyAwareV2，一个包含真实与合成影像的多模态无人机数据集，助力城市场景理解并提升模型泛...|
|📝 更新|MATRIX: Multimodal Agent Tuning for Robust Tool-Use Reasoning|MATRIX：多模态智能体调优以实现鲁棒的工具使用推理|Tajamul Ashraf, Umair Nawaz, Abdelrahman M. Shaker, Rao Anwer, Philip Torr, Fahad Shahbaz Khan, Salman Khan|<http://arxiv.org/pdf/2510.08567v2>|[代码](https://github.com/mbzuai-oryx/MATRIX.); 提出了一种自动合成多模态轨迹的视觉中心化代理调优框架，通过逐步偏好学习训练VLM控制器，实现了鲁棒的...|
|📝 更新|MIRROR: Multimodal Cognitive Reframing Therapy for Rolling with Resistance|“MIRROR：具有抗性的滚动中的多模态认知重塑疗法”|Subin Kim, Hoonrae Kim, Jihyun Lee, Yejin Jeon, Gary Geunbae Lee|<http://arxiv.org/pdf/2504.13211v3>|提出多模态认知重塑疗法，通过分析非言语线索增强AI心理咨询师应对客户抵触的能力。|
|📝 更新|SAIL-Embedding Technical Report: Omni-modal Embedding Foundation Model|《SAIL-Embedding技术报告：全模态嵌入基础模型》|Lin Lin, Jiefeng Long, Zhihe Wan, Yuchi Wang, Dingkang Yang, Shuang Yang, Yueyang Yao, Xu Chen .etc.|<http://arxiv.org/pdf/2510.12709v2>|提出了SAIL-Embedding模型，通过多阶段训练策略和架构设计，解决了多模态嵌入模型在真实应用...|
|📝 更新|FLEX: A Largescale Multimodal, Multiview Dataset for Learning Structured Representations for Fitness Action Quality Assessment|FLEX：用于学习健身动作质量评估的结构化表示的大规模多模态、多视角数据集|Hao Yin, Lijun Gu, Paritosh Parmar, Lin Xu, Tianxiao Guo, Weiwei Fu, Yang Zhang, Tianyou Zheng|<http://arxiv.org/pdf/2506.03198v2>|[代码](https://haoyin116.github.io/FLEX_Dataset.); 提出了FLEX多模态、多视角大规模数据集，融合表面肌电图信号，提升健身动作质量评估性能。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|InteractiveOmni: A Unified Omni-modal Model for Audio-Visual Multi-turn Dialogue|互动全模态模型InteractiveOmni：一种用于音频-视觉多轮对话的全模态统一模型|Wenwen Tong, Hewei Guo, Dongchuan Ran, Jiangnan Chen, Jiefan Lu, Kaibin Wang, Keqiang Li, Xiaoxu Zhu .etc.|<http://arxiv.org/pdf/2510.13747v1>|InteractiveOmni统一了视觉、音频编码器与语言模型，实现了高效的多模态多轮对话处理。|
|📝 更新|Human-MME: A Holistic Evaluation Benchmark for Human-Centric Multimodal Large Language Models|以人为中心的跨模态大型语言模型的全局评估基准：Human-MME|Yuansen Liu, Haiming Tang, Jinlong Peng, Jiangning Zhang, Xiaozhong Ji, Qingdong He, Wenbin Wu, Donghao Luo .etc.|<http://arxiv.org/pdf/2509.26165v3>|[代码](https://github.com/Yuan-Hou/Human-MME.); 提出Human-MME基准，全面评估多模态大语言模型在以人为中心的场景理解能力。|
|🆕 发布|Risk-adaptive Activation Steering for Safe Multimodal Large Language Models|风险自适应激活引导确保多模态大型语言模型的安全性|Jonghyun Park, Minhyuk Seo, Jonghyun Choi|<http://arxiv.org/pdf/2510.13698v1>|提出风险自适应激活引导方法，有效提升大型多模态语言模型对恶意图像查询的防御能力并加快响应速度。|
|📝 更新|MedDINOv3: How to adapt vision foundation models for medical image segmentation?|MedDINOv3：如何将视觉基础模型适配于医学图像分割？|Yuheng Li, Yizhou Wu, Yuxiang Lai, Mingzhe Hu, Xiaofeng Yang|<http://arxiv.org/pdf/2509.02379v3>|[代码](https://github.com/ricklisz/MedDINOv3.); MedDINOv3通过改进ViT架构和域自适应预训练，提升了医学图像分割的泛化性能。|
|🆕 发布|Prompt-based Adaptation in Large-scale Vision Models: A Survey|基于提示的大规模视觉模型自适应：综述|Xi Xiao, Yunbei Zhang, Lin Zhao, Yiyang Liu, Xiaoying Liao, Zheda Mai, Xingjian Li, Xiao Wang .etc.|<http://arxiv.org/pdf/2510.13219v1>|系统梳理了视觉提示适配技术，明确了不同方法的分类和在各领域的应用。|
|📝 更新|Brought a Gun to a Knife Fight: Modern VFM Baselines Outgun Specialized Detectors on In-the-Wild AI Image Detection|“带枪参加刀战：现代VFM基线在野外AI图像检测中超越专业检测器”|Yue Zhou, Xinan He, Kaiqing Lin, Bing Fan, Feng Ding, Jinhua Zeng, Bin Li|<http://arxiv.org/pdf/2509.12995v3>|使用现代视觉基础模型训练的简单线性分类器，大幅超越专用检测器在真实场景下的图像检测准确性。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Scaling Vision Transformers for Functional MRI with Flat Maps|将视觉变换器扩展用于功能性磁共振成像的平面图|Connor Lane, Daniel Z. Kaplan, Tanishq Mathew Abraham, Paul S. Scotti|<http://arxiv.org/pdf/2510.13768v1>|[代码](https://github.com/MedARC-AI/fmri-fm.); 将4D fMRI数据转换为2D flat map视频，用Vision Transformers学习丰...|
|📝 更新|ChA-MAEViT: Unifying Channel-Aware Masked Autoencoders and Multi-Channel Vision Transformers for Improved Cross-Channel Learning|通道感知遮蔽自编码器与多通道视觉变换器的统一：用于改进跨通道学习的ChA-MAEViT|Chau Pham, Juan C. Caicedo, Bryan A. Plummer|<http://arxiv.org/pdf/2503.19331v2>|[代码](https://github.com/chaudatascience/cha_mae_vit.); 提出了一种增强多通道图像特征学习的方法ChA-MAEViT，通过动态通道-补丁掩码和记忆标记等策略，...|
|🆕 发布|DepthVLA: Enhancing Vision-Language-Action Models with Depth-Aware Spatial Reasoning|深度感知空间推理增强的视觉-语言-动作模型：DepthVLA|Tianyuan Yuan, Yicheng Liu, Chenhao Lu, Zhuoguang Chen, Tao Jiang, Hang Zhao|<http://arxiv.org/pdf/2510.13375v1>|提出DepthVLA模型，通过集成深度预测模块增强视觉语言动作模型的精确空间推理能力。|
|📝 更新|Cross-modal Associations in Vision and Language Models: Revisiting the Bouba-Kiki Effect|视觉与语言模型中的跨模态关联：重新审视Bouba-Kiki效应|Tom Kouwenhoven, Kiana Shahrasbi, Tessa Verhoef|<http://arxiv.org/pdf/2507.10013v2>|通过对比CLIP模型在形状-词汇匹配任务中的表现与人类行为，揭示了视觉语言模型在跨模态信息整合上的局...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition|《Ultralytics YOLO进化：计算机视觉与模式识别中YOLO26、YOLO11、YOLOv8和YOLOv5目标检测器概述》|Ranjan Sapkota, Manoj Karkee|<http://arxiv.org/pdf/2510.09653v2>|概述了Ultralytics YOLO系列检测器的发展，提升了准确性与效率，并探讨了未来挑战。|
|📝 更新|Towards Methane Detection Onboard Satellites|面向卫星甲烷检测的研究|Maggie Chen, Hala Lambdouar, Luca Marini, Laura Martínez-Ferrer, Chris Bridges, Giacomo Acciarini|<http://arxiv.org/pdf/2509.00626v4>|[代码](https://github.com/spaceml-org/plume-hunter.); 提出了一种利用机器学习直接处理未经几何校正的卫星数据的方法，实现了与常规预处理方法相当的性能。|
|🆕 发布|Fusion Meets Diverse Conditions: A High-diversity Benchmark and Baseline for UAV-based Multimodal Object Detection with Condition Cues|融合遇见多样化条件：面向无人机多模态目标检测的条件线索高多样性基准与基线|Chen Chen, Kangcheng Bin, Ting Hu, Jiahao Qi, Xingyue Liu, Tianpeng Liu, Zhen Liu, Yongxiang Liu .etc.|<http://arxiv.org/pdf/2510.13620v1>|提出了一个高多样性数据集和条件感知动态融合方法，有效应对无人机多模态目标检测中的复杂环境条件。|
|🆕 发布|DEF-YOLO: Leveraging YOLO for Concealed Weapon Detection in Thermal Imagin|DEF-YOLO：利用YOLO进行热成像中隐藏武器检测|Divya Bhardwaj, Arnav Ramamoorthy, Poonam Goyal|<http://arxiv.org/pdf/2510.13326v1>|提出DEF-YOLO方法，利用YOLOv8针对热成像特点优化，解决了隐蔽武器检测问题，并创建了首个大...|
|📝 更新|GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity|GLSim：通过全局-局部相似性检测轻量级视觉模型中的对象幻觉|Seongheon Park, Sharon Li|<http://arxiv.org/pdf/2508.19972v3>|提出了一种无需训练的GLSim框架，通过结合全局和局部相似性信号，有效检测大型视觉语言模型中的对象幻...|
|📝 更新|DIP-R1: Deep Inspection and Perception with RL Looking Through and Understanding Complex Scenes|深度检查与感知：通过强化学习洞察和理解复杂场景（DIP-R1）|Sungjune Park, Hyunjun Kim, Junho Kim, Seongho Kim, Yong Man Ro|<http://arxiv.org/pdf/2505.23179v2>|提出了一种基于强化学习的视觉感知框架DIP-R1，显著提升了大规模语言模型在复杂场景中的视觉理解能力...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-Scale High-Resolution Logarithmic Grapher Module for Efficient Vision GNNs|多尺度高分辨率对数图模块用于高效视觉图神经网络|Mustafa Munir, Alex Zhang, Radu Marculescu|<http://arxiv.org/pdf/2510.13740v1>|[代码](https://github.com/mmunir127/LogViG-Official.); 提出了一种新的图构建方法LSGC和混合模型LogViG，通过限制长距离链接数量提升视觉图神经网络性能...|
|📝 更新|A Simple Framework for Open-Vocabulary Zero-Shot Segmentation|用于开放词汇零样本分割的简单框架|Thomas Stegmüller, Tim Lebailly, Nikola Dukic, Behzad Bozorgtabar, Tinne Tuytelaars, Jean-Philippe Thiran|<http://arxiv.org/pdf/2406.16085v3>|提出SimZSS框架，通过利用视觉模型的定位能力和文本的离散性，实现了无需额外标注的开词汇零样本分割...|
|📝 更新|End-to-End Semantic Preservation in Text-Aware Image Compression Systems|端到端语义保持在文本感知图像压缩系统中的研究|Stefano Della Fiore, Alessandro Gnutti, Marco Dalai, Pierangelo Migliorati, Riccardo Leonardi|<http://arxiv.org/pdf/2503.19495v2>|提出了一种端到端图像压缩框架，优化了文本特征保留，显著提升低比特率下的文本提取准确度。|
|🆕 发布|Universal Image Restoration Pre-training via Masked Degradation Classification|通过遮蔽退化分类的通用图像恢复预训练|JiaKui Hu, Zhengjian Yao, Lujia Jin, Yinghao Chen, Yanye Lu|<http://arxiv.org/pdf/2510.13282v1>|[代码](https://github.com/MILab-PKU/MaskDCPT.); 提出了一种通过遮罩退化分类预训练的通用图像复原方法，有效提升了模型性能和泛化能力。|
|📝 更新|ESG-Net: Event-Aware Semantic Guided Network for Dense Audio-Visual Event Localization|ESG-Net：面向事件的语义引导网络用于密集音频视觉事件定位|Huilai Li, Yonghao Dang, Ying Xing, Yiming Wang, Jianqin Yin|<http://arxiv.org/pdf/2507.09945v2>|[代码](https://github.com/uchiha99999/ESG-Net.); 提出了一种事件感知的语义引导网络ESG-Net，通过多阶段语义引导和事件关系建模，有效提升了音视频事...|
|🆕 发布|Direction-aware multi-scale gradient loss for infrared and visible image fusion|面向红外与可见光图像融合的方向感知多尺度梯度损失|Kaixuan Yang, Wei Xiang, Zhenshuai Chen, Tong Jin, Yunpeng Liu|<http://arxiv.org/pdf/2510.13067v1>|提出了一种方向感知的多尺度梯度损失函数，有效提升了红外与可见光图像融合的边缘清晰度和纹理保留效果。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results|and Results  2025年NTIRE低光照图像增强挑战：方法与结果|Xiaoning Liu, Zongwei Wu, Florin-Alexandru Vasluianu, Hailong Yan, Bin Ren, Yulun Zhang, Shuhang Gu, Le Zhang .etc.|<http://arxiv.org/pdf/2510.13670v1>|总结了NTIRE 2025低光照图像增强挑战中的先进方法，推动了图像清晰度与亮度的显著提升。|
|🆕 发布|Towards Adversarial Robustness and Uncertainty Quantification in DINOv2-based Few-Shot Anomaly Detection|面向基于DINOv2的少样本异常检测中的对抗鲁棒性与不确定性量化|Akib Mohammed Khan, Bartosz Krawczyk|<http://arxiv.org/pdf/2510.13643v1>|研究了DINOv2在少样本异常检测中的对抗攻击脆弱性和不确定性估计问题，提出了一种校准后异常评分的方...|
|🆕 发布|Automated document processing system for government agencies using DBNET++ and BART models|政府机构使用的基于DBNET++和BART模型的自动化文档处理系统|Aya Kaysan Bahjat|<http://arxiv.org/pdf/2510.13303v1>|提出了一种结合DBNET++文本检测和BART文本分类的自动化文档处理系统，有效应对多种成像挑战。|
|📝 更新|Axis-level Symmetry Detection with Group-Equivariant Representation|轴级别对称性检测与群等变表示|Wongyun Yu, Ahyun Seo, Minsu Cho|<http://arxiv.org/pdf/2508.10740v2>|提出了一种对偶分支架构，利用群等变特征精确检测反射和旋转对称轴，实现了计算机视觉中对称性检测的精度提...|
|📝 更新|TMT: Cross-domain Semantic Segmentation with Region-adaptive Transferability Estimation|TMT: 基于区域自适应迁移性估计的跨域语义分割|Enming Zhang, Zhengyu Li, Yanru Wu, Jingge Wang, Yang Tan, Guan Wang, Yang Li, Xiaoping Zhang|<http://arxiv.org/pdf/2504.05774v3>|提出了一种区域自适应的Transferable Mask Transformer（TMT）框架，通过...|
|📝 更新|IterMask3D: Unsupervised Anomaly Detection and Segmentation with Test-Time Iterative Mask Refinement in 3D Brain MR|IterMask3D：三维脑部磁共振成像中测试时迭代掩码精炼的无监督异常检测与分割|Ziyun Liang, Xiaoqing Guo, Wentian Xu, Yasin Ibrahim, Natalie Voets, Pieter M Pretorius, J. Alison Noble, Konstantinos Kamnitsas|<http://arxiv.org/pdf/2504.04911v2>|[代码](https://github.com/ZiyunLiang/IterMask3D.); 提出了一种迭代空间掩码优化策略IterMask3D，通过逐步揭示正常区域减少误报，提高了3D脑部MR...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Software System for Low-Cost, GUI-Based Microscopy Segmentation: Algorithmic Implementation|低成本、基于图形用户界面的显微镜分割软件系统：算法实现|Surajit Das, Pavel Zun|<http://arxiv.org/pdf/2509.11354v3>|开发了一种低成本、用户友好的显微镜图像分析系统，无需标注数据即可实现活细胞的高精度分割。|
|🆕 发布|Novel Class Discovery for Point Cloud Segmentation via Joint Learning of Causal Representation and Reasoning|通过联合学习因果表示和推理的点云分割新类发现|Yang Li, Aming Wu, Zihao Zhang, Yahong Han|<http://arxiv.org/pdf/2510.13307v1>|提出了一种通过联合学习因果表示和推理实现点云分割中新颖类发现的方法，有效区分了基础类和未标记的新类。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|NoisePrints: Distortion-Free Watermarks for Authorship in Private Diffusion Models|《NoisePrints：用于私人扩散模型版权声明的无失真水印》|Nir Goren, Oren Katzir, Abhinav Nakarmi, Eyal Ronen, Mahmood Sharif, Or Patashnik|<http://arxiv.org/pdf/2510.13793v1>|提出了一种利用扩散过程初始化随机种子作为版权证明的轻量级水印方案，无需修改生成过程且难以移除。|
|🆕 发布|Cyclic Self-Supervised Diffusion for Ultra Low-field to High-field MRI Synthesis|循环自监督扩散用于超低场到高场MRI合成|Zhenxuan Zhang, Peiyuan Jing, Zi Wang, Ula Briski, Coraline Beitone, Yue Yang, Yinzhe Wu, Fanwen Wang .etc.|<http://arxiv.org/pdf/2510.13735v1>|提出了一种循环自监督扩散框架，通过保持解剖结构一致性，实现了从低场MRI到高场MRI的高质量图像合成...|
|🆕 发布|MVCustom: Multi-View Customized Diffusion via Geometric Latent Rendering and Completion|多视角定制扩散：通过几何潜在渲染与补全|Minjung Shin, Hyunin Cho, Sooyeon Go, Jin-Hwa Kim, Youngjung Uh|<http://arxiv.org/pdf/2510.13702v1>|提出了一种多视角生成与定制统一框架MVCustom，通过深度感知特征渲染和一致性感知潜在补全实现几何...|
|📝 更新|MULTI: Multimodal Understanding Leaderboard with Text and Images|多模态理解排行榜：文本与图像的多模态理解|Zichen Zhu, Yang Xu, Lu Chen, Jingkai Yang, Yichuan Ma, Yiming Sun, Hailin Wen, Jiaqi Liu .etc.|<http://arxiv.org/pdf/2402.03173v4>|提出MULTI多模态数据集，以真实考试题目评估模型性能，揭示大型语言模型在复杂任务上的提升空间。|
|🆕 发布|An efficient approach with theoretical guarantees to simultaneously reconstruct activity and attenuation sinogram for TOF-PET|一种具有理论保证的效率方法，用于同时重建 TOF-PET 的活动度和衰减正弦图|Liyang Hu, Chong Chen|<http://arxiv.org/pdf/2510.13562v1>|提出了一种无需额外扫描即可同时重建活动性和衰减正弦图的新模型，提高了PET成像的准确性和效率。|
|🆕 发布|Steerable Conditional Diffusion for Domain Adaptation in PET Image Reconstruction|可调节条件扩散在PET图像重建中的域自适应应用|George Webber, Alexander Hammers, Andrew P. King, Andrew J. Reader|<http://arxiv.org/pdf/2510.13441v1>|提出了一种自适应调整扩散模型的方法，有效减少了PET图像重建中的领域偏移问题。|
|📝 更新|VRS-UIE: Value-Driven Reordering Scanning for Underwater Image Enhancement|VRS-UIE：基于价值驱动的水下图像增强重排序扫描|Kui Jiang, Yan Luo, Junjun Jiang, Ke Gu, Nan Ma, Xianming Liu|<http://arxiv.org/pdf/2505.01224v2>|提出了一种价值驱动的重排序扫描框架VRS-UIE，通过优先处理关键区域显著提升了水下图像增强效果。|
|🆕 发布|End-to-End Multi-Modal Diffusion Mamba|端到端多模态扩散Mamba|Chunhao Lu, Qiang Lu, Meichen Dong, Jake Luo|<http://arxiv.org/pdf/2510.13253v1>|提出统一编码解码架构MDM，通过多模态扩散模型提升高维数据处理性能。|
|📝 更新|Diffusion-Classifier Synergy: Reward-Aligned Learning via Mutual Boosting Loop for FSCIL|扩散分类器协同：通过互促循环实现面向FSCIL的奖励对齐学习|Ruitao Wu, Yifan Zhao, Guangyao Chen, Jia Li|<http://arxiv.org/pdf/2510.03608v2>|提出Diffusion-Classifier Synergy框架，通过奖励对齐学习策略实现少量样本增...|
|📝 更新|VR-Thinker: Boosting Video Reward Models through Thinking-with-Image Reasoning|VR-Thinker：通过图像推理思考提升视频奖励模型|Qunzhong Wang, Jie Liu, Jiajun Liang, Yilei Jiang, Yuanxing Zhang, Jinyuan Chen, Yaozhi Zheng, Xintao Wang .etc.|<http://arxiv.org/pdf/2510.10518v3>|VR-Thinker通过引入视觉推理操作和可配置视觉记忆窗口，提升了视频奖励模型在长视频中的推理准确...|
|🆕 发布|Counting Hallucinations in Diffusion Models|扩散模型中的计数幻觉|Shuai Fu, Jian Zhou, Qi Chen, Huang Jing, Huy Anh Nguyen, Xiaohan Liu, Zhixiong Zeng, Lin Ma .etc.|<http://arxiv.org/pdf/2510.13080v1>|提出了一套量化扩散模型中计数错误的方法，并揭示了与现有评价指标的关联性。|
|🆕 发布|Edit-Your-Interest: Efficient Video Editing via Feature Most-Similar Propagation|“编辑你的兴趣：通过特征最相似传播实现高效视频编辑”|Yi Zuo, Zitao Wang, Lingling Li, Xu Liu, Fang Liu, Licheng Jiao|<http://arxiv.org/pdf/2510.13084v1>|提出了一种高效的文本驱动的视频编辑方法，通过特征最相似传播和时空特征记忆缓存，实现了低计算开销和视觉...|
|📝 更新|Jigsaw++: Imagining Complete Shape Priors for Object Reassembly|拼图++：想象完整的形状先验以实现物体重组|Jiaxin Lu, Gang Hua, Qixing Huang|<http://arxiv.org/pdf/2410.11816v2>|引入Jigsaw++，一种生成完整形状先验的新方法，通过“重定向”策略提升对象重组精度。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PhysMaster: Mastering Physical Representation for Video Generation via Reinforcement Learning|物理表征掌握：通过强化学习实现视频生成的物理表征掌握|Sihui Ji, Xi Chen, Xin Tao, Pengfei Wan, Hengshuang Zhao|<http://arxiv.org/pdf/2510.13809v1>|提出PhysMaster模型，通过强化学习中的表示学习提升视频生成模型对物理规律的理解和遵循。|
|🆕 发布|RECODE: Reasoning Through Code Generation for Visual Question Answering|通过代码生成进行推理的视觉问答：RECODE|Junhong Shen, Mu Cai, Bo Hu, Ameet Talwalkar, David A Ross, Cordelia Schmid, Alireza Fathi|<http://arxiv.org/pdf/2510.13756v1>|提出利用代码生成进行视觉推理的新框架RECODE，通过将图像转化为可执行代码，实现了更准确的视觉推理...|
|🆕 发布|UniCalli: A Unified Diffusion Framework for Column-Level Generation and Recognition of Chinese Calligraphy|统一扩散框架：面向汉字书法列级生成与识别的UniCalli|Tianshuo Xu, Kai Wang, Zhifei Chen, Leyi Wu, Tianshui Wen, Fei Chao, Ying-Cong Chen|<http://arxiv.org/pdf/2510.13745v1>|[代码](https://github.com/EnVision-Research/UniCalli); 提出了UniCalli框架，通过联合训练识别与生成任务，实现了高质量的中国书法列级生成与识别。|
|📝 更新|QuaDreamer: Controllable Panoramic Video Generation for Quadruped Robots|四足机器人可控全景视频生成：QuaDreamer|Sheng Wu, Fei Teng, Hao Shi, Qi Jiang, Kai Luo, Kaiwei Wang, Kailun Yang|<http://arxiv.org/pdf/2508.02512v3>|[代码](https://github.com/losehu/QuaDreamer.); 提出QuaDreamer，一种模拟四足机器人运动生成高质量全景视频的数据生成引擎，通过垂直抖动编码和...|
|🆕 发布|CanvasMAR: Improving Masked Autoregressive Video Generation With Canvas|CanvasMAR：通过画布增强改进遮蔽自回归视频生成|Zian Li, Muhan Zhang|<http://arxiv.org/pdf/2510.13669v1>|CanvasMAR通过引入全局预测的canvas机制，有效解决了视频生成中的慢启动和误差累积问题。|
|🆕 发布|FlashWorld: High-quality 3D Scene Generation within Seconds|《FlashWorld：数秒内生成高质量三维场景》|Xinyang Li, Tengfei Wang, Zixiao Gu, Shengchuan Zhang, Chunchao Guo, Liujuan Cao|<http://arxiv.org/pdf/2510.13678v1>|FlashWorld通过3D导向生成模型，实现了秒级高质量3D场景生成，融合了多视角和3D生成优势。|
|📝 更新|DIO: Refining Mutual Information and Causal Chain to Enhance Machine Abstract Reasoning Ability|DIO：优化互信息和因果链以提高机器抽象推理能力|Ruizhuo Song, Beiming Yuan|<http://arxiv.org/pdf/2508.15387v5>|提出DIO模型，通过优化互信息和因果链，增强机器的抽象推理能力。|
|🆕 发布|OmniGaze: Reward-inspired Generalizable Gaze Estimation In The Wild|全方位注视：基于奖励启发的野外泛化注视估计|Hongyu Qu, Jianan Wei, Xiangbo Shu, Yazhou Yao, Wenguan Wang, Jinhui Tang|<http://arxiv.org/pdf/2510.13660v1>|提出了一种半监督3D gaze估计框架OmniGaze，利用大规模未标注数据减少领域偏差，实现野外场...|
|📝 更新|MotionAgent: Fine-grained Controllable Video Generation via Motion Field Agent|《MotionAgent：通过运动场代理实现细粒度可控视频生成》|Xinyao Liao, Xianfang Zeng, Liao Wang, Gang Yu, Guosheng Lin, Chi Zhang|<http://arxiv.org/pdf/2502.03207v2>|提出MotionAgent方法，通过文本引导实现图像到视频的细粒度运动控制。|
|📝 更新|TBStar-Edit: From Image Editing Pattern Shifting to Consistency Enhancement|TBStar-Edit：从图像编辑模式转换到一致性增强|Hao Fang, Zechao Zhan, Weixin Feng, Ziwei Huang, Xubin Li, Tiezheng Ge|<http://arxiv.org/pdf/2510.04483v3>|提出了针对电商领域的TBStar-Edit图像编辑模型，通过数据工程和模型设计实现了精确编辑与一致性...|
|📝 更新|MERIT: Multilingual Semantic Retrieval with Interleaved Multi-Condition Query|多语言语义检索与交错多条件查询的MERIT方法|Wei Chow, Yuan Gao, Linfeng Li, Xian Wang, Qi Xu, Hang Song, Lingdong Kong, Ran Zhou .etc.|<http://arxiv.org/pdf/2506.03144v2>|提出首个多语言多条件语义检索数据集MERIT，并开发出Coral框架，有效提升检索性能。|
|🆕 发布|Reinforcement Learning Meets Masked Generative Models: Mask-GRPO for Text-to-Image Generation|强化学习遇见遮蔽生成模型：用于文本到图像生成的Mask-GRPO方法|Yifu Luo, Xinhao Hu, Keyu Fan, Haoyuan Sun, Zeyu Chen, Bo Xia, Tiantian Zhang, Yongzhe Chang .etc.|<http://arxiv.org/pdf/2510.13418v1>|[代码](https://github.com/xingzhejun/Mask-GRPO); 首次将基于Group Relative Policy Optimization的强化学习应用于mas...|
|🆕 发布|No-Reference Rendered Video Quality Assessment: Dataset and Metrics|无参考渲染视频质量评估：数据集与指标|Sipeng Yang, Jiayu Ji, Qingchuan Zhu, Zhiyao Yang, Xiaogang Jin|<http://arxiv.org/pdf/2510.13349v1>|提出首个面向渲染视频的无参考质量评估数据集和指标，有效适应3D场景和渲染设置。|
|🆕 发布|CymbaDiff: Structured Spatial Diffusion for Sketch-based 3D Semantic Urban Scene Generation|《CymbaDiff：基于草图的三维语义城市场景生成的结构化空间扩散》|Li Liang, Bo Miao, Xinyu Wang, Naveed Akhtar, Jordan Vice, Ajmal Mian|<http://arxiv.org/pdf/2510.13245v1>|[代码](https://github.com/Lillian-research-hub/CymbaDiff); 提出SketchSem3D数据集并引入CymbaDiff方法，提升3D户外场景生成的空间一致性和真实...|
|🆕 发布|MimicParts: Part-aware Style Injection for Speech-Driven 3D Motion Generation|模仿部件：部分感知的风格注入用于语音驱动的3D运动生成|Lianlian Liu, YongKang He, Zhaojie Chu, Xiaofen Xing, Xiangmin Xu|<http://arxiv.org/pdf/2510.13208v1>|提出MimicParts框架，通过区域感知风格注入和去噪网络，实现与语音节奏和情感同步的精细3D人体...|
|📝 更新|TempFlow-GRPO: When Timing Matters for GRPO in Flow Models|时间敏感的GRPO：在流模型中时间因素对GRPO的重要性|Xiaoxuan He, Siming Fu, Yuke Zhao, Wanli Li, Jian Yang, Dacheng Yin, Fengyun Rao, Bo Zhang|<http://arxiv.org/pdf/2508.04324v4>|提出了一种针对生成模型的新型时序优化框架TempFlow-GRPO，通过利用生成过程中的时间结构，显...|
|🆕 发布|VPREG: An Optimal Control Formulation for Diffeomorphic Image Registration Based on the Variational Principle Grid Generation Method|VPREG：基于变分原理网格生成方法的保形图像配准最优控制公式|Zicong Zhou, Baihan Zhao, Andreas Mang, Guojun Liao|<http://arxiv.org/pdf/2510.13109v1>|提出了一种基于变分原理的图像配准方法VPREG，实现了高精度配准并保证了变换的质量和逆变换的准确性。|
|📝 更新|EReLiFM: Evidential Reliability-Aware Residual Flow Meta-Learning for Open-Set Domain Generalization under Noisy Labels|证据可靠性感知的残差流元学习用于带噪声标签的开集领域泛化|Kunyu Peng, Di Wen, Kailun Yang, Jia Fu, Yufan Chen, Ruiping Liu, Jiamin Wu, Junwei Zheng .etc.|<http://arxiv.org/pdf/2510.12687v2>|[代码](https://github.com/KPeng9510/ERELIFM.); 提出了一种用于开放集域泛化的元学习方法EReLiFM，通过残差流匹配和证据可靠性感知，有效应对噪声标...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Adaptive Visual Conditioning for Semantic Consistency in Diffusion-Based Story Continuation|自适应视觉调节以保持基于扩散的故事延续中的语义一致性|Seyed Mohammad Mousavi, Morteza Analoui|<http://arxiv.org/pdf/2510.13787v1>|引入了自适应视觉调节框架，通过在故事续集中智能调整历史图像影响，实现文本与图像的语义一致性。|
|🆕 发布|InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy|《InternVLA-M1：一种用于通用机器人策略的空间引导视觉-语言-动作框架》|Xinyi Chen, Yilun Chen, Yanwei Fu, Ning Gao, Jiaya Jia, Weiyang Jin, Hao Li, Yao Mu .etc.|<http://arxiv.org/pdf/2510.13778v1>|[代码](https://github.com/InternRobotics/InternVLA-M1.); 提出了一种空间引导的视觉-语言-动作框架，通过空间定位提升机器人指令执行的一致性和准确性。|
|📝 更新|MetaCaptioner: Towards Generalist Visual Captioning with Open-source Suites|元标注器：面向通用视觉标注的开源工具套件|Zhenxin Lei, Zhangwei Gao, Changyao Tian, Erfei Cui, Guanzhou Chen, Danni Yang, Yuchen Duan, Zhaokai Wang .etc.|<http://arxiv.org/pdf/2510.12126v2>|提出CapFlow多代理协作流程，实现开源模型生成与GPT-4.1质量相当的视觉字幕，降低成本89....|
|🆕 发布|Map the Flow: Revealing Hidden Pathways of Information in VideoLLMs|映射流动：揭示视频LLMs中信息的隐藏路径|Minji Kim, Taekyung Kim, Bohyung Han|<http://arxiv.org/pdf/2510.13251v1>|揭示了VideoLLMs在视频问答任务中如何通过特定信息流进行时序推理和视频-文本整合。|
|📝 更新|$Δ\mathrm{Energy}$: Optimizing Energy Change During Vision-Language Alignment Improves both OOD Detection and OOD Generalization|$Δ\mathrm{能量}$：在视觉-语言对齐过程中优化能量变化可同时提高OOD检测和OOD泛化能力|Lin Zhu, Yifeng Yang, Xinbing Wang, Qinying Gu, Nanyang Ye|<http://arxiv.org/pdf/2510.11296v2>|提出ΔEnergy方法，通过优化视觉语言对齐过程中的能量变化，有效提升异常检测和泛化能力。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VIST3A: Text-to-3D by Stitching a Multi-view Reconstruction Network to a Video Generator|VIST3A：通过将多视角重建网络与视频生成器缝合实现从文本到3D的转换|Hyojun Go, Dominik Narnhofer, Goutam Bhat, Prune Truong, Federico Tombari, Konrad Schindler|<http://arxiv.org/pdf/2510.13454v1>|提出VIST3A框架，融合文本到视频生成器和三维重建解码器，实现高质量文本驱动的三维场景生成。|
|🆕 发布|Ultra High-Resolution Image Inpainting with Patch-Based Content Consistency Adapter|超高分辨率图像修复的基于斑块的内容一致性适配器方法|Jianhui Zhang, Sheng Cheng, Qirui Sun, Jia Liu, Wang Luyang, Chaoyu Feng, Chen Fang, Lei Lei .etc.|<http://arxiv.org/pdf/2510.13419v1>|提出Patch-Adapter框架，实现4K+高分辨率图像修复，同时保持内容一致性和精确对齐。|
|📝 更新|SafeGuider: Robust and Practical Content Safety Control for Text-to-Image Models|SafeGuider：用于文本到图像模型的健壮且实用的内容安全控制|Peigui Qi, Kunsheng Tang, Wenbo Zhou, Weiming Zhang, Nenghai Yu, Tianwei Zhang, Qing Guo, Jie Zhang|<http://arxiv.org/pdf/2510.05173v3>|提出SafeGuider框架，通过两步骤策略增强文本到图像模型的安全性，同时保持生成图像质量。|
|📝 更新|Towards Generalized Video Quality Assessment: A Weak-to-Strong Learning Paradigm|面向通用视频质量评估：从弱监督到强监督学习范式|Linhan Cao, Wei Sun, Xiangyang Zhu, Kaiwei Zhang, Jun Jia, Yicong Peng, Dandan Zhu, Guangtao Zhai .etc.|<http://arxiv.org/pdf/2505.03631v3>|提出弱转强学习范式，通过无需大规模人工标注数据的方法，实现了视频质量评估的泛化性能提升。|
|🆕 发布|OS-HGAdapter: Open Semantic Hypergraph Adapter for Large Language Models Assisted Entropy-Enhanced Image-Text Alignment|OS-HGAdapter：面向大规模语言模型辅助的熵增强图像-文本对齐的开源语义超图适配器|Rongjun Chen, Chengsi Yao, Jinchang Ren, Xianxian Zeng, Peixian Wang, Jun Yuan, Jiawen Li, Huimin Zhao .etc.|<http://arxiv.org/pdf/2510.13131v1>|提出利用大型语言模型弥补文本与图像信息熵差异，通过熵增强的图像-文本对齐实现更精准的跨模态检索。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Reasoning in Space via Grounding in the World|通过在世界中定位来实现空间推理|Yiming Chen, Zekun Qi, Wenyao Zhang, Xin Jin, Li Zhang, Peidong Liu|<http://arxiv.org/pdf/2510.13800v1>|提出了一种统一的三维空间推理框架GS-Reasoner，通过双路径池化机制整合语义与几何信息，实现了...|
|🆕 发布|Circle of Willis Centerline Graphs: A Dataset and Baseline Algorithm|威尔逊环中心线图：一个数据集与基线算法|Fabio Musio, Norman Juchler, Kaiyuan Yang, Suprosanna Shit, Chinmay Prabhakar, Bjoern Menze, Sven Hirsch|<http://arxiv.org/pdf/2510.13720v1>|提出了一种基于学习型细化算法的脑部血管中心线提取方法，实现了高精度拓扑重建和特征提取。|
|🆕 发布|Leveraging 2D Priors and SDF Guidance for Dynamic Urban Scene Rendering|利用二维先验和SDF引导进行动态城市场景渲染|Siddharth Tourani, Jayaram Reddy, Akash Kumbar, Satyajit Tourani, Nishant Goyal, Madhava Krishna, N. Dinesh Reddy, Muhammad Haris Khan|<http://arxiv.org/pdf/2510.13381v1>|整合二维无目标先验和符号距离函数，提升动态城市场景渲染的准确性和适应性。|
|🆕 发布|InstantSfM: Fully Sparse and Parallel Structure-from-Motion|即时SfM：完全稀疏和并行的运动恢复结构|Jiankun Zhong, Zitong Zhan, Quankai Gao, Ziyu Chen, Haozhe Lou, Jiageng Mao, Ulrich Neumann, Yue Wang|<http://arxiv.org/pdf/2510.13310v1>|[代码](https://cre185.github.io/InstantSfM); 提出了一种全稀疏并行结构从运动恢复方法，大幅提升了大规模场景下的重建速度和精度。|
|🆕 发布|UniVector: Unified Vector Extraction via Instance-Geometry Interaction|统一向量提取：通过实例-几何交互实现|Yinglong Yan, Jun Yue, Shaobo Xia, Hanmeng Sun, Tianxu Ying, Chengcheng Wu, Sifan Lan, Min He .etc.|<http://arxiv.org/pdf/2510.13234v1>|[代码](https://github.com/yyyyll0ss/UniVector.); 提出了一种统一向量提取框架UniVector，通过实例与几何交互提取多种结构向量，实现了更高效的图像...|
|🆕 发布|True Self-Supervised Novel View Synthesis is Transferable|真正的自监督新视角合成具有迁移性|Thomas W. Mitchel, Hyunwoo Ryu, Vincent Sitzmann|<http://arxiv.org/pdf/2510.13063v1>|提出了一种无需几何先验的几何无关自监督模型XFactor，实现了真正的视图合成转移性。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LiFMCR: Dataset and Benchmark for Light Field Multi-Camera Registration|LiFMCR：光场多相机配准数据集与基准测试|Aymeric Fleith, Julian Zirbel, Daniel Cremers, Niclas Zeller|<http://arxiv.org/pdf/2510.13729v1>|提出LiFMCR数据集，为多相机光场配准提供高精度基准和两种配准方法。|
|🆕 发布|Learning Neural Parametric 3D Breast Shape Models for Metrical Surface Reconstruction From Monocular RGB Videos|学习用于从单目RGB视频进行度量表面重建的神经参数化三维乳腺形状模型|Maximilian Weiherer, Antonia von Riedheim, Vanessa Brébant, Bernhard Egger, Christoph Palm|<http://arxiv.org/pdf/2510.13540v1>|提出了一种基于局部神经表示的3D乳腺形状模型，实现了低成本、高精度的单目视频乳腺表面重建。|
|📝 更新|PASE: Phoneme-Aware Speech Encoder to Improve Lip Sync Accuracy for Talking Head Synthesis|PASE：音素感知语音编码器，以提高说话人头合成中的唇同步精度|Yihuan Huang, Jiajun Liu, Yanzhen Ren, Jun Xue, Wuyang Liu, Zongkun Sun|<http://arxiv.org/pdf/2504.05803v3>|提出PASE模型，通过引入音素嵌入和对比对齐模块，显著提升唇同步精度。|
|📝 更新|Endoscopic Depth Estimation Based on Deep Learning: A Survey|基于深度学习的内窥镜深度估计：综述|Ke Niu, Zeyun Liu, Xue Feng, Heng Li, Qika Lin, Kaize Shi|<http://arxiv.org/pdf/2507.20881v2>|系统综述了基于深度学习的内窥镜深度估计技术，为临床应用提供了全面的数据、方法和挑战分析。|
|🆕 发布|Foveation Improves Payload Capacity in Steganography|视网膜注视增强隐写术中的载荷容量|Lifeng Qiu Lin, Henry Kam, Qi Sun, Kaan Akşit|<http://arxiv.org/pdf/2510.13151v1>|利用人眼视觉特性，提出新型隐写术模型，大幅提升信息隐藏容量并保持高视觉质量。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|AVAR-Net: A Lightweight Audio-Visual Anomaly Recognition Framework with a Benchmark Dataset|AVAR-Net：一种轻量级音频-视觉异常识别框架及其基准数据集|Amjid Ali, Zulfiqar Ahmad Khan, Altaf Hussain, Muhammad Munsif, Adnan Hussain, Sung Wook Baik|<http://arxiv.org/pdf/2510.13630v1>|提出了一种融合音频与视频的轻量级异常识别框架AVAR-Net，提高了多模态异常识别的准确性和鲁棒性。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Trace Anything: Representing Any Video in 4D via Trajectory Fields|"追踪一切：通过轨迹场在四维空间中表示任意视频"|Xinhang Liu, Yuxi Xiao, Donny Y. Chen, Jiashi Feng, Yu-Wing Tai, Chi-Keung Tang, Bingyi Kang|<http://arxiv.org/pdf/2510.13802v1>|[代码](https://trace-anything.github.io/.); 提出了一种通过轨迹场表示视频的4D模型，实现了高效的单次前向传播轨迹预测。|
|📝 更新|Fact-R1: Towards Explainable Video Misinformation Detection with Deep Reasoning|面向深度推理的可解释视频虚假信息检测方法Fact-R1|Fanrui Zhang, Dian Li, Qiang Zhang, Jun Chen, Gang Liu, Junxiong Lin, Jiahong Yan, Jiawei Liu .etc.|<http://arxiv.org/pdf/2505.16836v3>|提出大规模视频文本数据集FakeVV和 Fact-R1框架，结合深度推理与强化学习检测视频 misi...|
|📝 更新|Spatio-Temporal LLM: Reasoning about Environments and Actions|空间时间语言模型：对环境和动作的推理|Haozhen Zheng, Beitong Tian, Mingyuan Wu, Zhenggang Tang, Klara Nahrstedt, Alex Schwing|<http://arxiv.org/pdf/2507.05258v2>|[代码](https://zoezheng126.github.io/STLLM-website); 提出新框架和模型STLLM，解决多模态大语言模型处理空间时间提示的挑战，提升了对环境和动作的整体理解...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Modeling Cultural Bias in Facial Expression Recognition with Adaptive Agents|自适应代理在面部表情识别中建模文化偏见|David Freire-Obregón, José Salas-Cáceres, Javier Lorenzo-Navarro, Oliverio J. Santana, Daniel Hernández-Sosa, Modesto Castrillón-Santana|<http://arxiv.org/pdf/2510.13557v1>|提出了一种基于自适应代理的模型，揭示了文化构成和视觉质量对表情识别稳健性的影响。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EPIPTrack: Rethinking Prompt Modeling with Explicit and Implicit Prompts for Multi-Object Tracking|《EPIPTrack：用显式和隐式提示重新思考多目标跟踪中的提示建模》|Yukuan Zhang, Jiarui Zhao, Shangqing Nie, Jin Kuang, Shengsheng Wang|<http://arxiv.org/pdf/2510.13235v1>|提出了一种结合显式和隐式提示的多模态视觉语言跟踪框架，有效应对目标状态变化和虚构问题，提升多目标跟踪...|
|🆕 发布|Paper Copilot: Tracking the Evolution of Peer Review in AI Conferences|论文协作者：追踪人工智能会议同行评审的演变|Jing Yang, Qiyao Wei, Jiaxin Pei|<http://arxiv.org/pdf/2510.13201v1>|构建了 Paper Copilot 系统，通过数字档案和开放数据集分析 AI 会议论文评审的演变，促...|
|📝 更新|HUMOTO: A 4D Dataset of Mocap Human Object Interactions|"HUMOTO：动态捕捉人对象交互的4D数据集"|Jiaxin Lu, Chun-Hao Paul Huang, Uttaran Bhattacharya, Qixing Huang, Yi Zhou|<http://arxiv.org/pdf/2504.10414v2>|[代码](https://jiaxin-lu.github.io/humoto); 提出了高保真度的HUMOTO数据集，通过精确建模和场景驱动脚本，实现了真实人类与物体的互动捕捉。|
|📝 更新|MCOP: Multi-UAV Collaborative Occupancy Prediction|多无人机协同占用预测：MCOP|Zefu Lin, Wenbo Chen, Xiaojuan Jin, Yuran Yang, Lue Fan, Yixin Zhang, Yufeng Zhang, Zhaoxiang Zhang|<http://arxiv.org/pdf/2510.12679v2>|提出了一种多无人机协同占用预测框架，通过集成空间感知特征编码和跨无人机特征整合，有效保留了场景的3D...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RelTopo: Multi-Level Relational Modeling for Driving Scene Topology Reasoning|《RelTopo：多层次关系建模用于驾驶场景拓扑推理》|Yueru Luo, Changqing Zhou, Yiming Yang, Erlong Li, Chao Zheng, Shuqi Mei, Shuguang Cui, Zhen Li|<http://arxiv.org/pdf/2506.13553v2>|引入关系建模以联合增强自动驾驶中的车道感知和拓扑推理，实现感知与推理的双重提升。|


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Semantically Guided Action Anticipation|语义引导的动作预测|Anxhelo Diko, Antonino Furnari, Luigi Cinque, Giovanni Maria Farinella|<http://arxiv.org/pdf/2411.15557v4>|通过语义引导调整潜在空间中概念的相对位置，实现了域自适应任务中的准确性和域特性保持。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs|蜜蜂：一种高质量语料库与全栈解决方案，用以解锁先进的完全开放多模态大型语言模型|Yi Zhang, Bolin Ni, Xin-Sheng Chen, Heng-Rui Zhang, Yongming Rao, Houwen Peng, Qinglin Lu, Han Hu .etc.|<http://arxiv.org/pdf/2510.13795v1>|构建高质量数据集 Honey-Data-15M 和数据管道 HoneyPipe，提升全开放多模态大语...|
|📝 更新|SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology|SSL4Eco：用于生态学地理空间基础模型的全球季节性数据集|Elena Plekhanova, Damien Robert, Johannes Dollinger, Emilia Arens, Philipp Brun, Jan Dirk Wegner, Niklaus Zimmermann|<http://arxiv.org/pdf/2504.18256v2>|[代码](https://github.com/PlekhanovaElena/ssl4eco.); 提出了基于季节性采样策略的SSL4Eco数据集，通过训练提升了遥感模型在生态任务中的表现。|
|🆕 发布|Group-Wise Optimization for Self-Extensible Codebooks in Vector Quantized Models|组内优化用于向量量化模型中自扩展码本的构建|Hong-Kai Zheng, Piji Li|<http://arxiv.org/pdf/2510.13331v1>|提出Group-VQ方法，通过分组优化解决VQ-VAEs中代码本坍塌问题，提升图像重建质量。|
|📝 更新|Uncolorable Examples: Preventing Unauthorized AI Colorization via Perception-Aware Chroma-Restrictive Perturbation|不可着色示例：通过感知感知的色度限制扰动防止未经授权的AI着色|Yuki Nii, Futa Waseda, Ching-Chun Chang, Isao Echizen|<http://arxiv.org/pdf/2510.08979v2>|提出防御范式“Uncolorable Examples”，通过在灰度图像中嵌入不可见扰动，有效阻止未...|
|🆕 发布|STT-GS: Sample-Then-Transmit Edge Gaussian Splatting with Joint Client Selection and Power Control|STT-GS: 基于样本传输的边缘高斯散点绘制，结合客户端选择与功率控制|Zhen Li, Xibin Jin, Guoliang Li, Shuai Wang, Miaowen Wen, Huseyin Arslan, Derrick Wing Kwan Ng, Chengzhong Xu|<http://arxiv.org/pdf/2510.13186v1>|提出STT-GS策略，通过样本选择和功率控制优化边缘高斯散点渲染质量与通信效率。|
|🆕 发布|DP-TTA: Test-time Adaptation for Transient Electromagnetic Signal Denoising via Dictionary-driven Prior Regularization|DP-TTA：基于字典驱动先验正则化的瞬态电磁信号去噪测试时自适应方法|Meng Yang, Kecheng Chen, Wei Luo, Xianjie Chen, Yong Jia, Mingyue Wang, Fanqiang Lin|<http://arxiv.org/pdf/2510.13160v1>|提出了一种基于字典驱动的先验正则化测试时自适应方法，有效提升了不同环境下电磁信号的去噪性能。|
|📝 更新|GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT|《GranQ：通过向量化预缩放实现零样本量化训练的通道高效量化》|Inpyo Hong, Youngwan Jo, Hyojeong Lee, Sunghyun Ahn, Kijung Lee, Sanghyun Park|<http://arxiv.org/pdf/2503.18339v6>|提出了一种高效的预缩放策略GranQ，通过向量化的预缩放步骤减少计算负担，实现了低比特量化下的精细量...|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dedelayed: Deleting remote inference delay via on-device correction|通过设备端修正消除远程推理延迟的Dedelayed方法|Dan Jacobellis, Mateen Ulhaq, Fabien Racapé, Hyomin Choi, Neeraja J. Yadwadkar|<http://arxiv.org/pdf/2510.13714v1>|提出了一种减少远程推理延迟的方法Dedelayed，通过本地轻量级模型结合远程模型特征，实现实时低延...|
|📝 更新|Robust Real-Time Endoscopic Stereo Matching under Fuzzy Tissue Boundaries|实时鲁棒性内镜立体匹配算法研究：模糊组织边界下的匹配|Yang Ding, Can Han, Sijia Du, Yaqi Wang, Dahong Qian|<http://arxiv.org/pdf/2503.00731v3>|[代码](https://github.com/Sonne-Ding/RRESM.); 提出了一种针对内窥镜图像的实时立体匹配方法，通过增强位置敏感注意力和高频细节优化，实现了高准确度和实...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models|LIBERO-Plus：视觉-语言-动作模型的深入鲁棒性分析|Senyu Fei, Siyin Wang, Junhao Shi, Zihao Dai, Jikun Cai, Pengfang Qian, Li Ji, Xinzhe He .etc.|<http://arxiv.org/pdf/2510.13626v1>|揭示了视觉语言行动模型在真实环境下的脆弱性，提出了全面的分析方法来评估其鲁棒性。|
|📝 更新|PRISM: Self-Pruning Intrinsic Selection Method for Training-Free Multimodal Data Selection|PRISM：无训练多模态数据选择的自我剪枝内在选择方法|Jinhe Bi, Yifan Wang, Danqi Yan, Aniri, Wenke Huang, Zengjie Jin, Xiaowen Ma, Artur Hecker .etc.|<http://arxiv.org/pdf/2502.12119v2>|[代码](https://github.com/bibisbar/PRISM); 提出了一种无需训练的PRISM框架，通过消除全局背景特征影响，高效选择视觉指令数据并提升模型性能。|
|🆕 发布|Beyond Pixels: A Differentiable Pipeline for Probing Neuronal Selectivity in 3D|超越像素：一种用于探测三维神经元选择性的可微分处理流程|Pavithra Elumalai, Mohammad Bashiri, Goirik Chakrabarty, Suhas Shrinivasan, Fabian H. Sinz|<http://arxiv.org/pdf/2510.13433v1>|引入了可微分渲染流程，通过优化3D可变形网格直接获取神经元对物理场景特性的选择性。|
|📝 更新|On Robustness of Vision-Language-Action Model against Multi-Modal Perturbations|《面向多模态扰动下视觉-语言-动作模型的鲁棒性研究》|Jianing Guo, Zhenhong Wu, Chang Tu, Yiyao Ma, Xiangqi Kong, Zhiqian Liu, Jiaming Ji, Shuning Zhang .etc.|<http://arxiv.org/pdf/2510.00037v2>|提出RobustVLA模型，增强视觉语言动作模型对多模态干扰的鲁棒性，显著提升在各种扰动下的性能。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FMANet: A Novel Dual-Phase Optical Flow Approach with Fusion Motion Attention Network for Robust Micro-expression Recognition|FMANet：一种具有融合运动注意力网络的新型双相光流方法，用于稳健的微表情识别|Luu Tu Nguyen, Vu Tram Anh Khuong, Thi Bich Phuong Man, Thi Duyen Ngo, Thanh Ha Le|<http://arxiv.org/pdf/2510.07810v3>|提出了一种融合双阶段光流信息的神经网络架构，有效提升了微表情识别的准确性。|
|📝 更新|Perspective-Aware Teaching: Adapting Knowledge for Heterogeneous Distillation|具有透视感知的教学：为异构蒸馏适配知识|Jhe-Hao Lin, Yi Yao, Chan-Feng Hsu, Hongxia Xie, Hong-Han Shuai, Wen-Huang Cheng|<http://arxiv.org/pdf/2501.08885v2>|[代码](https://github.com/jimmylin0979/PAT.git.); 提出了一种视角感知的教学框架，实现了不同架构间的特征蒸馏，有效提升了知识迁移效率。|
|🆕 发布|ExpressNet-MoE: A Hybrid Deep Neural Network for Emotion Recognition|ExpressNet-MoE：一种用于情感识别的混合深度神经网络|Deeptimaan Banerjee, Prateek Gothwal, Ashis Kumer Biswas|<http://arxiv.org/pdf/2510.13493v1>|[代码](https://github.com/DeeptimaanB/ExpressNet-MoE.); 提出了一种融合卷积神经网络和混合专家框架的ExpressNet-MoE模型，有效提升了情感识别的准确...|
|🆕 发布|CoDS: Enhancing Collaborative Perception in Heterogeneous Scenarios via Domain Separation|异构场景下通过域分离增强协同感知的CoDS方法|Yushan Han, Hui Zhang, Honglei Zhang, Chuntao Ding, Yuanzhouhan Cao, Yidong Li|<http://arxiv.org/pdf/2510.13432v1>|提出CoDS方法，通过域分离解决异质场景下协同感知中的特征差异问题，提升检测准确性与效率。|
|🆕 发布|Real-Time Crowd Counting for Embedded Systems with Lightweight Architecture|嵌入式系统轻量级架构的实时人群计数|Zhiyuan Zhao, Yubin Wen, Siyu Yang, Lichen Ning, Yuandong Liu, Junyu Gao|<http://arxiv.org/pdf/2510.13250v1>|设计了一种适用于嵌入式系统的超实时轻量级人群计数模型，实现了比现有方法更快的推理速度和较高准确性。|
|🆕 发布|Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models|模型无关的视觉-语言-动作模型对抗攻击与防御|Haochuan Xu, Yun Sing Koh, Shuhuai Huang, Zirun Zhou, Di Wang, Jun Sakuma, Jingfeng Zhang|<http://arxiv.org/pdf/2510.13237v1>|[代码](https://edpa-attack.github.io/.); 提出了一种模型无关的对抗攻击和防御策略，用于提高视觉语言动作模型的鲁棒性。|
|🆕 发布|Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN|使用深度学习的实时手语到文本翻译：LSTM与3D CNN的比较研究|Madhumati Pol, Anvay Anturkar, Anushka Khot, Ayush Andure, Aniruddha Ghosh, Anvit Magadum, Anvay Bahadur|<http://arxiv.org/pdf/2510.13137v1>|比较了3D CNN和LSTM在实时手语识别中的表现，发现3D CNN准确度高但计算量大，LSTM则相...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|XD-RCDepth: Lightweight Radar-Camera Depth Estimation with Explainability-Aligned and Distribution-Aware Distillation|XD-RCDepth：具有解释性对齐和分布感知的轻量级雷达-相机深度估计|Huawei Sun, Zixu Wang, Xiangyuan Peng, Julius Ott, Georg Stettinger, Lorenzo Servadei, Robert Wille|<http://arxiv.org/pdf/2510.13565v1>|提出了一种轻量级雷达-相机融合深度估计方法，通过知识蒸馏保持了准确度并增强了可解释性。|
|📝 更新|Identifying Hard Noise in Long-Tailed Sample Distribution|识别长尾样本分布中的硬噪声|Xuanyu Yi, Kaihua Tang, Xian-Sheng Hua, Joo-Hwee Lim, Hanwang Zhang|<http://arxiv.org/pdf/2207.13378v3>|[代码](https://github.com/yxymessi/H2E-Framework); 提出应对长尾分布中难识别噪声的新挑战，设计迭代学习框架Hard-to-Easy提升分类稳定性。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Improving Transferability of Adversarial Examples via Bayesian Attacks|通过贝叶斯攻击提高对抗样本的迁移性|Qizhang Li, Yiwen Guo, Xiaochen Yang, Wangmeng Zuo, Hao Chen|<http://arxiv.org/pdf/2307.11334v2>|[代码](https://github.com/qizhangli/MoreBayesian-jrnl.); 通过将贝叶斯方法应用于模型参数和输入，本研究显著提升了对抗样本的迁移性。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Health Care Waste Classification Using Deep Learning Aligned with Nepal's Bin Color Guidelines|基于深度学习的医疗废物分类方法，符合尼泊尔垃圾桶颜色指南|Suman Kunwar, Prabesh Rai|<http://arxiv.org/pdf/2508.07450v2>|提出了一种基于深度学习的医疗废物分类方法，符合尼泊尔垃圾桶颜色规范，实现了95.06%的最高准确率。|
|🆕 发布|High Semantic Features for the Continual Learning of Complex Emotions: a Lightweight Solution|用于复杂情绪持续学习的高语义特征：一种轻量级解决方案|Thibault Geoffroy, gauthier Gerspacher, Lionel Prevost|<http://arxiv.org/pdf/2510.13534v1>|提出了一种利用高语义特征的动作单元进行复杂情绪识别的增量学习方法，实现了高效学习且模型轻量。|
|📝 更新|Position: The Artificial Intelligence and Machine Learning Community Should Adopt a More Transparent and Regulated Peer Review Process|《立场：人工智能与机器学习社区应采用更加透明和规范的同行评审流程》|Jing Yang|<http://arxiv.org/pdf/2502.00874v3>|倡导采用更透明、规范的同行评审流程，以增强社区参与并推动领域进步。|
|📝 更新|AquaCluster: Using Satellite Images And Self-supervised Machine Learning Networks To Detect Water Hidden Under Vegetation|"AquaCluster：利用卫星图像和自监督机器学习网络检测植被下隐藏的水体"|Ioannis Iakovidis, Zahra Kalantari, Amir Hossein Payberah, Fernando Jaramillo, Francisco Pena Escobar|<http://arxiv.org/pdf/2506.08214v3>|提出AquaCluster模型，利用自监督学习从雷达卫星图像中无需标注即可检测隐藏在植被下的水体。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Language as a Label: Zero-Shot Multimodal Classification of Everyday Postures under Data Scarcity|“语言作为标签：在数据稀缺条件下对日常姿态进行零样本多模态分类”|MingZe Tang, Jubal Chandy Jacob|<http://arxiv.org/pdf/2510.13364v1>|探究了提示词设计对零样本分类的影响，发现简单提示词在最佳模型中效果更佳。|
|📝 更新|Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignment|通过概率高斯对齐的无反向传播测试时适应|Youjia Zhang, Youngeun Kim, Young-Geun Choi, Hongyeob Kim, Huiling Liu, Sungeun Hong|<http://arxiv.org/pdf/2508.15568v3>|提出了一种无需反向传播的测试时自适应方法，通过高斯概率推理显著提升了模型在分布偏移下的鲁棒性和可扩展...|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 交互式感知 (Interactive Perception)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EgoSocial: Benchmarking Proactive Intervention Ability of Omnimodal LLMs via Egocentric Social Interaction Perception|自我社交：通过第一视角社交互动感知评估全模态大型语言模型的前瞻干预能力基准|Xijun Wang, Tanay Sharma, Achin Kulshrestha, Abhimitra Meka, Aveek Purohit, Dinesh Manocha|<http://arxiv.org/pdf/2510.13105v1>|提出EgoSocial数据集和EgoSoD方法，提升AI在社交互动中的干预时机识别能力。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VisCoP: Visual Probing for Video Domain Adaptation of Vision Language Models|VisCoP：视觉探测用于视觉语言模型在视频领域的自适应|Dominick Reilly, Manish Kumar Govind, Le Xue, Srijan Das|<http://arxiv.org/pdf/2510.13808v1>|提出了一种视觉探针增强方法VisCoP，有效解决视觉语言模型在新型领域性能退化问题，同时保持原有能力...|
|📝 更新|MEGC2025: Micro-Expression Grand Challenge on Spot Then Recognize and Visual Question Answering|MEGC2025：微表情大挑战——定位后识别与视觉问答|Xinqi Fan, Jingting Li, John See, Moi Hoon Yap, Wen-Huang Cheng, Xiaobai Li, Xiaopeng Hong, Su-Jing Wang .etc.|<http://arxiv.org/pdf/2506.15298v2>|整合微表情检测与识别流程，并利用大型多模态模型提升微表情理解能力。|
|🆕 发布|Accelerated Feature Detectors for Visual SLAM: A Comparative Study of FPGA vs GPU|视觉SLAM中的加速特征检测器：FPGA与GPU的比较研究|Ruiqi Ye, Mikel Luján|<http://arxiv.org/pdf/2510.13546v1>|比较了GPU和FPGA在视觉SLAM中特征检测的性能，发现FPGA对学习型检测器有优势。|
|📝 更新|ProReason: Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom|ProReason：多模态主动推理与解耦的视野与智慧|Jingqi Zhou, Sheng Wang, Jingwei Dong, Kai Liu, Lei Li, Jiahui Gao, Jiyue Jiang, Lingpeng Kong .etc.|<http://arxiv.org/pdf/2410.14138v5>|提出了一种分解视觉推理过程的新型框架ProReason，通过分离视觉感知和文本推理能力，有效提升了多...|
|🆕 发布|Through the Lens of Doubt: Robust and Efficient Uncertainty Estimation for Visual Place Recognition|《透过怀疑之镜：视觉位置识别的稳健与高效不确定性估计》|Emily Miller, Michael Milford, Muhammad Burhan Hafez, SD Ramchurn, Shoaib Ehsan|<http://arxiv.org/pdf/2510.13464v1>|提出三种无需训练的视觉定位不确定性估计方法，有效区分正确与错误匹配，提升机器人应用的精度和鲁棒性。|
|🆕 发布|Spatial-DISE: A Unified Benchmark for Evaluating Spatial Reasoning in Vision-Language Models|空间DISE：一种用于评估视觉语言模型空间推理的统一基准|Xinmiao Huang, Qisong He, Zhenglin Huang, Boxuan Wang, Zhuoyun Li, Guangliang Cheng, Yi Dong, Xiaowei Huang|<http://arxiv.org/pdf/2510.13394v1>|提出统一基准 Spatial-DISE 评估视觉语言模型空间推理能力，并创建自动化数据生成流程。|
|🆕 发布|Self-Augmented Visual Contrastive Decoding|自增强视觉对比解码|Eun Woo Im, Muhammad Kashif Ali, Vivek Gupta|<http://arxiv.org/pdf/2510.13315v1>|提出了一种结合查询依赖的自增强视觉对比解码策略，有效提升了大型视觉语言模型的事实一致性。|
|🆕 发布|Visual Interestingness Decoded: How GPT-4o Mirrors Human Interests|《视觉趣味性解码：GPT-4o如何映射人类兴趣》|Fitim Abdullahu, Helmut Grabner|<http://arxiv.org/pdf/2510.13316v1>|探究GPT-4o对视觉吸引力的理解与人类评估的匹配度，为深入理解人类兴趣奠定基础。|
|🆕 发布|What "Not" to Detect: Negation-Aware VLMs via Structured Reasoning and Token Merging|《什么“不”要检测：通过结构化推理和标记合并实现的否定感知视觉语言模型》|Inha Kang, Youngsun Lim, Seonho Lee, Jiho Choi, Junsuk Choe, Hyunjung Shim|<http://arxiv.org/pdf/2510.13232v1>|提出了一种结合结构化推理和令牌合并的否定感知视觉语言模型，有效解决了现有模型在否定理解上的缺陷。|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|The Mechanistic Emergence of Symbol Grounding in Language Models|语言模型中符号接地机制的出现过程|Shuyu Wu, Ziqiao Ma, Xiaoxi Luo, Yidong Huang, Josue Torres-Fonseca, Freda Shi, Joyce Chai|<http://arxiv.org/pdf/2510.13796v1>|提出了一种新的评估框架，揭示了语言模型内部计算中符号接地现象的机制和位置。|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Seeing and Knowing in the Wild: Open-domain Visual Entity Recognition with Large-scale Knowledge Graphs via Contrastive Learning|在野外看与知：通过对比学习利用大规模知识图谱进行开放域视觉实体识别|Hongkuan Zhou, Lavdim Halilaj, Sebastian Monka, Stefan Schmid, Yuqicheng Zhu, Jingcheng Wu, Nadeem Nazer, Steffen Staab|<http://arxiv.org/pdf/2510.13675v1>|提出知识引导对比学习框架，结合图像和文本描述，实现开放域视觉实体识别的零样本学习。|
|📝 更新|SemVink: Advancing VLMs' Semantic Understanding of Optical Illusions via Visual Global Thinking|SemVink：通过视觉全局思维提升视觉语言模型对光学错觉的语义理解能力|Sifan Li, Yujun Cai, Yiwei Wang|<http://arxiv.org/pdf/2506.02803v3>|提出HC-Bench基准测试，发现VLMs对视觉错觉识别不足，并提出SemVink方法通过降低图像分...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Improving Visual Recommendation on E-commerce Platforms Using Vision-Language Models|使用视觉-语言模型提升电子商务平台上的视觉推荐效果|Yuki Yada, Sho Akiyama, Ryo Watanabe, Yuta Ueno, Yusuke Shido, Andre Rusli|<http://arxiv.org/pdf/2510.13359v1>|利用视觉语言模型提升电商平台的视觉推荐效果，实现了点击率和转化率的显著提升。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Generating healthy counterfactuals with denoising diffusion bridge models|生成具有降噪扩散桥模型的健康反事实|Ana Lawry Aguila, Peirong Liu, Marina Crespo Aguirre, Juan Eugenio Iglesias|<http://arxiv.org/pdf/2510.13684v1>|提出了一种利用去噪扩散桥模型生成健康对比图像的方法，有效平衡了病变移除与个体特征保留。|
|🆕 发布|Challenges, Advances, and Evaluation Metrics in Medical Image Enhancement: A Systematic Literature Review|医学图像增强的挑战、进展与评估指标：系统性文献综述|Chun Wai Chin, Haniza Yazid, Hoi Leong Lee|<http://arxiv.org/pdf/2510.13638v1>|系统综述了医学图像增强的关键挑战、最新进展及评估指标，突出了深度学习技术的重要性。|
|📝 更新|SynDiff-AD: Improving Semantic Segmentation and End-to-End Autonomous Driving with Synthetic Data from Latent Diffusion Models|SynDiff-AD：利用潜在扩散模型生成的合成数据提升语义分割和端到端自动驾驶性能|Harsh Goel, Sai Shankar Narasimhan, Oguzhan Akcin, Sandeep Chinchali|<http://arxiv.org/pdf/2411.16776v2>|[代码](https://github.com/UTAustin-SwarmLab/SynDiff-AD.); 提出SynDiff-AD方法，利用扩散模型生成特殊环境下的合成数据，提升语义分割和自动驾驶性能。|
|🆕 发布|Near-Infrared Hyperspectral Imaging Applications in Food Analysis -- Improving Algorithms and Methodologies|近红外高光谱成像在食品分析中的应用——改进算法与方法论|Ole-Christian Galbo Engstrøm|<http://arxiv.org/pdf/2510.13452v1>|探究近红外高光谱成像在食品分析中的应用，提出结合空间与光谱信息的CNN模型，提高了化学参数预测性能。|
|📝 更新|Data-Efficient Fine-Tuning of Vision-Language Models for Diagnosis of Alzheimer's Disease|数据高效微调视觉语言模型用于阿尔茨海默病的诊断|Fangqi Cheng, Surajit Ray, Xiaochen Yang|<http://arxiv.org/pdf/2509.07613v3>|[代码](https://github.com/CFQ666312/DEFT-VLM-AD.); 提出了一种高效微调3D医疗视觉语言模型的方法，通过合成报告和预测MMSE分数，实现了阿尔茨海默病诊断...|
|🆕 发布|Unsupervised Domain Adaptation via Content Alignment for Hippocampus Segmentation|无监督领域自适应通过内容对齐进行海马体分割|Hoda Kalabizadeh, Ludovica Griffanti, Pak-Hei Yeung, Ana I. L. Namburete, Nicola K. Dinsdale, Konstantinos Kamnitsas|<http://arxiv.org/pdf/2510.13075v1>|提出了一种针对跨数据集医疗图像分割域偏移问题的无监督内容对齐方法，有效提升了 hippocampus...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Geo-R1: Improving Few-Shot Geospatial Referring Expression Understanding with Reinforcement Fine-Tuning|Geo-R1：利用强化微调提升少量样本地理空间指代表达式理解|Zilun Zhang, Zian Guan, Tiancheng Zhao, Haozhan Shen, Tianyu Li, Yuxiang Cai, Zhonggen Su, Zhaojun Liu .etc.|<http://arxiv.org/pdf/2509.21976v2>|[代码](https://github.com/Geo-R1/geo-r1.); 提出Geo-R1方法，通过强化学习微调提升少量样本地理参照表达理解能力，增强泛化性和可解释性。|
|🆕 发布|Complementary Information Guided Occupancy Prediction via Multi-Level Representation Fusion|通过多层次表征融合的互补信息引导占有率预测|Rongtao Xu, Jinzhou Lin, Jialei Zhou, Jiahua Dong, Changwei Wang, Ruisheng Wang, Li Guo, Shibiao Xu .etc.|<http://arxiv.org/pdf/2510.13198v1>|[代码](https://github.com/VitaLemonTea1/CIGOcc); 提出了一种基于多级特征融合的两阶段占用预测框架，有效利用图像特征多样性，实现自动驾驶中3D场景感知的...|
|📝 更新|RealEngine: Simulating Autonomous Driving in Realistic Context|《RealEngine：在真实场景中模拟自动驾驶》|Junzhe Jiang, Nan Song, Jingyu Li, Xiatian Zhu, Li Zhang|<http://arxiv.org/pdf/2505.16902v2>|提出了一种全面的驾驶仿真框架RealEngine，通过3D场景重建和视图合成技术实现逼真的闭环仿真，...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Hints of Prompt: Enhancing Visual Representation for Multimodal LLMs in Autonomous Driving|自动驾驶中多模态大语言模型视觉表征增强的提示线索|Hao Zhou, Zhanning Gao, Zhili Chen, Maosheng Ye, Qifeng Chen, Tongyi Cao, Honggang Qi|<http://arxiv.org/pdf/2411.13076v2>|提出Hints of Prompt框架，通过引入亲和性、语义和问题提示增强视觉表征，提升自动驾驶场景...|
|🆕 发布|Sample-Centric Multi-Task Learning for Detection and Segmentation of Industrial Surface Defects|基于样本中心的工业表面缺陷检测与分割的多任务学习|Hang-Cheng Dong, Yibo Jiao, Fupeng Wei, Guodong Liu, Dong Ye, Bingguo Liu|<http://arxiv.org/pdf/2510.13226v1>|提出了一种样本中心的的多任务学习框架，通过样本级监督增强对小缺陷的检测能力并提高样本级决策的稳定性。|
|🆕 发布|DriveCritic: Towards Context-Aware, Human-Aligned Evaluation for Autonomous Driving with Vision-Language Models|驱动评价家：面向情境感知、与人类一致性的自动驾驶视觉语言模型评估方法|Jingyu Song, Zhenxin Li, Shiyi Lan, Xinglong Sun, Nadine Chang, Maying Shen, Joshua Chen, Katherine A. Skinner .etc.|<http://arxiv.org/pdf/2510.13108v1>|提出DriveCritic框架，通过结合视觉与语言模型评估自动驾驶系统，更贴近人类判断标准。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 可解释视觉智能 (Explainable Visual Intelligence)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Systematic Literature Review on Vehicular Collaborative Perception - A Computer Vision Perspective|车辆协同感知系统性文献综述——计算机视觉视角|Lei Wan, Jianxin Zhao, Andreas Wiedholz, Manuel Bied, Mateus Martinez de Lucena, Abhishek Dinkar Jagtap, Andreas Festag, Antônio Augusto Fröhlich .etc.|<http://arxiv.org/pdf/2504.04631v2>|系统综述了车辆协同感知领域的计算机视觉研究，揭示了提升自动驾驶可靠性的新方法和挑战。|


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Visible Yet Unreadable: A Systematic Blind Spot of Vision Language Models Across Writing Systems|《可见却不可读：视觉语言模型在多种书写系统中的系统性盲点》|Jie Zhang, Ting Xu, Gelei Deng, Runyi Hu, Han Qiu, Tianwei Zhang, Qing Guo, Ivor Tsang|<http://arxiv.org/pdf/2509.06996v3>|揭示了视觉语言模型在处理书写系统中的结构局限性，提出了构建针对符号分割和组合的新架构和训练策略。|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MMLongCite: A Benchmark for Evaluating Fidelity of Long-Context Vision-Language Models|MMLongCite：用于评估长上下文视觉-语言模型保真度的基准|Keyan Zhou, Zecheng Tang, Lingfeng Ming, Guanghao Zhou, Qiguang Chen, Dan Qiao, Zheming Yang, Libo Qin .etc.|<http://arxiv.org/pdf/2510.13276v1>|提出了MMLongCite基准，用于评估大型视觉语言模型在长上下文场景中的准确性。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Removing Cost Volumes from Optical Flow Estimators|从光流估计器中移除代价体素|Simon Kiefhaber, Stefan Roth, Simone Schaub-Meyer|<http://arxiv.org/pdf/2510.13317v1>|提出了一种无需成本体积的光流估计训练策略，大幅提升了速度并降低了内存需求。|
|📝 更新|FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games|《FlashAdventure：一个用于GUI智能体在多样化冒险游戏中解决完整故事弧的基准》|Jaewoo Ahn, Junseo Kim, Heeseung Yun, Jaehyeon Son, Dongmin Park, Jaewoong Cho, Gunhee Kim|<http://arxiv.org/pdf/2509.01052v2>|提出了FlashAdventure基准，包含34款Flash冒险游戏，用于评估GUI智能体完成完整故...|

