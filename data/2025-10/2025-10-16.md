## [UPDATED!] **2025-10-16** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning an Image Editing Model without Image Editing Pairs|无监督学习图像编辑模型：无需图像编辑对|Nupur Kumari, Sheng-Yu Wang, Nanxuan Zhao, Yotam Nitzan, Yuheng Li, Krishna Kumar Singh, Richard Zhang, Eli Shechtman .etc.|<http://arxiv.org/pdf/2510.14978v1>|提出了一种无需图像编辑对的新训练范式，通过视觉语言模型反馈和分布匹配损失优化扩散模型，实现无需配对数...|
|📝 更新|GRAB: A Challenging GRaph Analysis Benchmark for Large Multimodal Models|GRAB：面向大型多模态模型的大规模图分析挑战基准|Jonathan Roberts, Kai Han, Samuel Albanie|<http://arxiv.org/pdf/2408.11817v3>|提出了GRAB基准，为大型多模态模型在图形分析任务上提供了高难度的挑战和评估标准。|
|🆕 发布|Benchmarking Multimodal Large Language Models for Face Recognition|多模态大型语言模型在人脸识别中的基准测试|Hatef Otroshi Shahreza, Sébastien Marcel|<http://arxiv.org/pdf/2510.14866v1>|系统评估了多模态大型语言模型在人脸识别上的表现，为提升模型准确性和泛化能力提供了基准和洞见。|
|📝 更新|Gradient-Sign Masking for Task Vector Transport Across Pre-Trained Models|梯度符号遮蔽：跨预训练模型的任务向量传输|Filippo Rinaldi, Aniello Panariello, Giacomo Salici, Fengyuan Liu, Marco Ciccone, Angelo Porrello, Simone Calderara|<http://arxiv.org/pdf/2510.09658v2>|提出GradFix方法，通过梯度符号结构实现跨预训练模型的任务向量迁移，仅需少量样本即可有效适应新模...|
|📝 更新|Subspace-Boosted Model Merging|子空间增强的模型融合|Ronald Skorobogat, Karsten Roth, Mariana-Iuliana Georgescu|<http://arxiv.org/pdf/2506.16506v2>|提出方法解决模型融合中任务空间秩塌陷问题，通过子空间提升显著提高多专家模型融合效果。|
|🆕 发布|In-Context Learning with Unpaired Clips for Instruction-based Video Editing|基于指令的视频编辑的无配对片段上下文学习|Xinyao Liao, Xianfang Zeng, Ziye Song, Zhoujie Fu, Gang Yu, Guosheng Lin|<http://arxiv.org/pdf/2510.14648v1>|提出了一种低成本预训练策略，通过未配对视频片段的上下文学习实现指令驱动的视频编辑，显著提升了编辑质量...|
|📝 更新|UniEgoMotion: A Unified Model for Egocentric Motion Reconstruction, Forecasting, and Generation|《UniEgoMotion：一种用于自我中心运动重建、预测和生成的统一模型》|Chaitanya Patel, Hiroki Nakamura, Yuta Kyuragi, Kazuki Kozuka, Juan Carlos Niebles, Ehsan Adeli|<http://arxiv.org/pdf/2508.01126v2>|提出UniEgoMotion模型，通过提取第一视角图像中的场景信息，实现了 egocentric 运...|
|📝 更新|Emergent Visual Grounding in Large Multimodal Models Without Grounding Supervision|无监督大型多模态模型中的涌现视觉定位|Shengcao Cao, Liang-Yan Gui, Yu-Xiong Wang|<http://arxiv.org/pdf/2410.08209v2>|发现无需显式接地监督的大规模多模态模型中可自发产生接地能力，提出了一种增强接地能力的DIFFLMM模...|
|📝 更新|WoW: Towards a World omniscient World model Through Embodied Interaction|《WoW：通过具身交互构建全知世界模型》|Xiaowei Chi, Peidong Jia, Chun-Kai Fan, Xiaozhu Ju, Weishi Mi, Kevin Zhang, Zhiyuan Qin, Wanxin Tian .etc.|<http://arxiv.org/pdf/2509.22642v2>|提出了一种通过机器人互动学习物理直觉的14亿参数生成世界模型，实现了视频中的物理一致性和因果推理的最...|
|📝 更新|Falcon: A Remote Sensing Vision-Language Foundation Model (Technical Report)|“Falcon：一种遥感视觉-语言基础模型（技术报告）”|Kelu Yao, Nuo Xu, Rong Yang, Yingying Xu, Zhuoyan Gao, Titinunt Kitrungrotsakul, Yi Ren, Pu Zhang .etc.|<http://arxiv.org/pdf/2503.11070v2>|[代码](https://github.com/TianHuiLab/Falcon); 提出了Falcon模型，一种针对遥感领域的统一视觉语言基础模型，实现了14项复杂遥感任务的高效执行。|
|📝 更新|Spot the Fake: Large Multimodal Model-Based Synthetic Image Detection with Artifact Explanation|“识破假象：基于大型多模态模型的合成图像检测及瑕疵解释”|Siwei Wen, Junyan Ye, Peilin Feng, Hengrui Kang, Zichen Wen, Yize Chen, Jiang Wu, Wenjun Wu .etc.|<http://arxiv.org/pdf/2503.14905v2>|[代码](https://github.com/opendatalab/FakeVLM.); 提出 FakeVLM 模型，用于有效检测合成图像并提供清晰的图像伪造痕迹解释。|
|🆕 发布|GauSSmart: Enhanced 3D Reconstruction through 2D Foundation Models and Geometric Filtering|高斯智能：通过二维基础模型与几何滤波增强的三维重建|Alexander Valverde, Brian Xu, Yuyin Zhou, Meng Xu, Hongyun Wang|<http://arxiv.org/pdf/2510.14270v1>|提出了一种融合2D基础模型与3D高斯散点重建的GauSSmart方法，有效提升了场景重建的细节表现和...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation|方言生成：多模态生成中的方言鲁棒性基准测试与改进|Yu Zhou, Sohyun An, Haikang Deng, Da Yin, Clark Peng, Cho-Jui Hsieh, Kai-Wei Chang, Nanyun Peng|<http://arxiv.org/pdf/2510.14949v1>|定位方言鲁棒性缺陷并提出一种通用编码器策略，使多模态生成模型在方言和标准英语上表现相当。|
|🆕 发布|Leveraging Multimodal LLM Descriptions of Activity for Explainable Semi-Supervised Video Anomaly Detection|利用多模态大型语言模型对活动描述进行可解释的半监督视频异常检测|Furkan Mumcu, Michael J. Jones, Anoop Cherian, Yasin Yilmaz|<http://arxiv.org/pdf/2510.14896v1>|提出了一种利用多模态大型语言模型描述物体活动与交互的半监督视频异常检测框架，有效识别复杂交互异常并增...|
|🆕 发布|Backdoor Unlearning by Linear Task Decomposition|通过线性任务分解的后门遗忘|Amel Abdelraheem, Alessandro Favero, Gerome Bovet, Pascal Frossard|<http://arxiv.org/pdf/2510.14845v1>|提出了一种线性任务分解方法，实现了在不损害模型原有性能的前提下有效移除后门攻击。|
|🆕 发布|Supervised Fine-Tuning or Contrastive Learning? Towards Better Multimodal LLM Reranking|监督微调还是对比学习？迈向更优的多模态大型语言模型重排|Ziqi Dai, Xin Zhang, Mingxin Li, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, Wenjie Li .etc.|<http://arxiv.org/pdf/2510.14824v1>|比较了对比学习与监督微调在大型语言模型reranking中的效果，发现监督微调更具优势。|
|🆕 发布|Morphology-Aware Prognostic model for Five-Year Survival Prediction in Colorectal Cancer from H&E Whole Slide Images|基于形态学感知的预后模型：从H&E全切片图像预测结直肠癌五年生存率|Usama Sajjad, Abdul Rehman Akbar, Ziyu Su, Deborah Knight, Wendy L. Frankel, Metin N. Gurcan, Wei Chen, Muhammad Khalid Khan Niazi|<http://arxiv.org/pdf/2510.14800v1>|提出了一种新的 interpretable AI 模型 PRISM，通过整合形态学特征预测结直肠癌患...|
|🆕 发布|DCMIL: A Progressive Representation Learning Model of Whole Slide Images for Cancer Prognosis Analysis|全切片图像的渐进式表征学习模型DCMIL：用于癌症预后分析|Chao Tu, Kun Huang, Jie Zhang, Qianjin Feng, Yu Zhang, Zhenyuan Ning|<http://arxiv.org/pdf/2510.14403v1>|[代码](https://github.com/tuuuc/DCMIL.); 提出了一种无需密集标注的渐进式表示学习模型DCMIL，有效处理全切片图像以预测癌症预后。|
|🆕 发布|Vision-Centric Activation and Coordination for Multimodal Large Language Models|视觉中心激活与多模态大型语言模型的协同|Yunnan Wang, Fan Lu, Kecheng Zheng, Ziyuan Huang, Ziqiang Li, Wenjun Zeng, Xin Jin|<http://arxiv.org/pdf/2510.14349v1>|引入VaCo方法，通过视觉激活与协调，提升多模态大语言模型对视觉信息的理解和处理能力。|
|📝 更新|NExT-OMNI: Towards Any-to-Any Omnimodal Foundation Models with Discrete Flow Matching|NExT-OMNI：面向任意到任意全模态基础模型的离散流匹配方法|Run Luo, Xiaobo Xia, Lu Wang, Longze Chen, Renke Shan, Jing Luo, Min Yang, Tat-Seng Chua|<http://arxiv.org/pdf/2510.13721v2>|提出了NExT-OMNI模型，通过离散流范式实现任意模态间的统一理解和生成，提升了多模态交互和检索性...|
|🆕 发布|Joint Modeling of Big Five and HEXACO for Multimodal Apparent Personality-trait Recognition|《多模态表型人格特质识别中的五大人格与HEXACO联合建模》|Ryo Masumura, Shota Orihashi, Mana Ihori, Tomohiro Tanaka, Naoki Makishima, Taiga Yamane, Naotaka Kawata, Satoshi Suzuki .etc.|<http://arxiv.org/pdf/2510.14203v1>|提出了一种联合建模方法，结合Big Five和HEXACO模型，有效提升多模态人格特质识别准确性。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Decorrelation Speeds Up Vision Transformers|decorrelation speeds up vision transformers    decorrelation加速了视觉变换器|Kieran Carrigg, Rob van Gastel, Melda Yeghaian, Sander Dalm, Faysal Boughorbel, Marcel van Gerven|<http://arxiv.org/pdf/2510.14657v1>|引入Decorrelated Backpropagation优化Masked Autoencoder...|
|📝 更新|EDIT: Enhancing Vision Transformers by Mitigating Attention Sink through an Encoder-Decoder Architecture|通过编码器-解码器架构减轻注意力汇聚以增强视觉变换器：EDIT|Wenfeng Feng, Hongxiang Wang, Jianlong Wang, Xin Zhang, Jingjing Zhao, Yueyue Liang, Xiang Chen, Duokui Han|<http://arxiv.org/pdf/2504.06738v2>|提出EDIT架构，通过编码器-解码器设计缓解Vision Transformer中的注意力汇聚问题，...|
|🆕 发布|Zero-Shot Wildlife Sorting Using Vision Transformers: Evaluating Clustering and Continuous Similarity Ordering|使用视觉变换器进行零样本野生动物分类：评估聚类与连续相似度排序|Hugo Markoff, Jevgenijs Galaktionovs|<http://arxiv.org/pdf/2510.14596v1>|提出零样本野生动物图像分类方法，使用自监督视觉变换器进行无标签图像组织，实现高准确度排序。|
|🆕 发布|Hierarchical Re-Classification: Combining Animal Classification Models with Vision Transformers|分层重分类：结合动物分类模型与视觉变换器|Hugo Markoff, Jevgenijs Galaktionovs|<http://arxiv.org/pdf/2510.14594v1>|提出了一种结合SpeciesNet和CLIP嵌入的动物分类系统，实现了高精度物种级别识别。|
|🆕 发布|Towards Generalist Intelligence in Dentistry: Vision Foundation Models for Oral and Maxillofacial Radiology|迈向牙科通用智能：口腔及颌面放射学视觉基础模型|Xinrui Huang, Fan Xiao, Dongming He, Anqi Gao, Dandan Li, Xiaofan Zhang, Shaoting Zhang, Xudong Wang|<http://arxiv.org/pdf/2510.14532v1>|提出首个面向牙科的全模态视觉基础模型DentVFM，通过自监督学习提升多任务泛化能力，解决牙科影像诊...|
|📝 更新|Beyond Seeing: Evaluating Multimodal LLMs on Tool-Enabled Image Perception, Transformation, and Reasoning|超越视觉：评估工具增强型图像感知、转换与推理的多模态大型语言模型|Xingang Guo, Utkarsh Tyagi, Advait Gosai, Paula Vergara, Ernesto Gabriel Hernández Montoya, Chen Bo Calvin Zhang, Bin Hu, Yunzhong He .etc.|<http://arxiv.org/pdf/2510.12712v2>|提出了VisualToolBench，首个针对多模态大语言模型在动态图像处理与工具整合能力上进行评估...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Scaling Artificial Intelligence for Multi-Tumor Early Detection with More Reports, Fewer Masks|利用更多报告、更少掩模扩展人工智能进行多肿瘤早期检测|Pedro R. A. S. Bassi, Xinze Zhou, Wenxuan Li, Szymon Płotka, Jieneng Chen, Qi Chen, Zheren Zhu, Jakub Prządo .etc.|<http://arxiv.org/pdf/2510.14803v1>|[代码](https://github.com/MrGiovanni/R-Super); 利用医疗报告训练AI模型进行肿瘤分割，减少对人工绘制肿瘤掩膜的需求。|
|🆕 发布|Cross-Layer Feature Self-Attention Module for Multi-Scale Object Detection|跨层特征自注意力模块用于多尺度目标检测|Dingzhou Xie, Rushi Lan, Cheng Pang, Enhao Ning, Jiahao Zeng, Wei Zheng|<http://arxiv.org/pdf/2510.14726v1>|提出了一种跨层特征自注意力模块，有效提升了多尺度目标检测的性能和训练收敛速度。|
|📝 更新|HyCoVAD: A Hybrid SSL-LLM Model for Complex Video Anomaly Detection|《HyCoVAD：一种用于复杂视频异常检测的混合自监督学习-语言模型》|Mohammad Mahdi Hemmatyar, Mahdi Jafari, Mohammad Amin Yousefi, Mohammad Reza Nemati, Mobin Azadani, Hamid Reza Rastad, Amirmohammad Akbari|<http://arxiv.org/pdf/2509.22544v2>|提出HyCoVAD模型，融合自监督学习和大型语言模型，有效识别复杂视频异常。|
|📝 更新|InfoDet: A Dataset for Infographic Element Detection|信息图元素检测数据集 InfoDet|Jiangning Zhu, Yuxing Zhou, Zheng Wang, Juntao Yao, Yima Gu, Yuhui Yuan, Shixia Liu|<http://arxiv.org/pdf/2505.17473v5>|提出InfoDet数据集，增强视觉语言模型对图表元素的理解和检测能力。|
|🆕 发布|Structured Universal Adversarial Attacks on Object Detection for Video Sequences|视频序列目标检测中的结构化通用对抗攻击|Sven Jacob, Weijia Shao, Gjergji Kasneci|<http://arxiv.org/pdf/2510.14460v1>|[代码](https://github.com/jsve96/AO-Exp-Attack.); 提出了一种针对视频对象检测的微调结构化通用对抗攻击方法，通过核范数正则化提高攻击效果并保持隐蔽性。|
|📝 更新|UrbanTwin: Synthetic LiDAR Datasets (LUMPI, V2X-Real-IC, and TUMTraf-I)|《UrbanTwin：合成激光雷达数据集（LUMPI、V2X-Real-IC和TUMTraf-I）》|Muhammad Shahbaz, Shaurya Agarwal|<http://arxiv.org/pdf/2509.06781v2>|创建了UrbanTwin合成LiDAR数据集，通过数字孪生技术增强训练样本和场景多样性，提升3D感知...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Free-Grained Hierarchical Recognition|细粒度层次化识别|Seulki Park, Zilin Wang, Stella X. Yu|<http://arxiv.org/pdf/2510.14737v1>|提出free-grain学习框架，通过异质监督和视觉语言模型，提升了混合标注下的层次分类性能。|
|📝 更新|Analysis of Hyperparameter Optimization Effects on Lightweight Deep Models for Real-Time Image Classification|《实时图像分类轻量级深度模型中超参数优化效果分析》|Vineet Kumar Rakesh, Soumya Mazumdar, Tapas Samanta, Hemendra Kumar Pandey, Amitabha Das|<http://arxiv.org/pdf/2507.23315v2>|[代码](https://vineetkumarrakesh.github.io/lcnn-opt); 评估了超参数优化对轻量级网络实时图像分类性能的影响，实现了准确度提升和边缘设备部署优化。|
|🆕 发布|Leveraging Learned Image Prior for 3D Gaussian Compression|利用学习到的图像先验进行三维高斯压缩|Seungjoo Shin, Jaesik Park, Sunghyun Cho|<http://arxiv.org/pdf/2510.14705v1>|提出了一种利用学习到的图像先验的3D高斯压缩框架，有效提升了压缩率和渲染质量。|
|📝 更新|On Large Multimodal Models as Open-World Image Classifiers|《大型多模态模型作为开放世界图像分类器》|Alessandro Conti, Massimiliano Mancini, Enrico Fini, Yiming Wang, Paolo Rota, Elisa Ricci|<http://arxiv.org/pdf/2503.21851v2>|提出开放世界图像分类新方法，通过全面评估大型多模态模型，揭示了其在细粒度分类中的挑战及优化途径。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FASTopoWM: Fast-Slow Lane Segment Topology Reasoning with Latent World Models|FASTopoWM：基于潜在世界模型的速度-慢速车道线拓扑推理|Yiming Yang, Hongbin Lin, Yueru Luo, Suzhong Fu, Chao Zheng, Xinrui Yan, Shuqi Mei, Kun Tang .etc.|<http://arxiv.org/pdf/2507.23325v2>|提出了一种结合快慢拓扑推理和潜在世界模型的框架，有效利用时间信息提升自动驾驶系统中的道路场景理解性能...|
|🆕 发布|A Density-Informed Multimodal Artificial Intelligence Framework for Improving Breast Cancer Detection Across All Breast Densities|一种基于密度信息的多元人工智能框架，用于提高各种乳腺密度下的乳腺癌检测准确性|Siva Teja Kakileti, Bharath Govindaraju, Sudhakar Sampangi, Geetha Manjunath|<http://arxiv.org/pdf/2510.14340v1>|提出了一种基于乳腺密度动态选择成像模态的多模态AI框架，提高了乳腺癌检测的准确性和覆盖不同乳腺密度的...|
|📝 更新|ELASTIC: Efficient Once For All Iterative Search for Object Detection on Microcontrollers|弹性：面向微控制器的对象检测高效一次性迭代搜索|Tony Tran, Qin Lin, Bin Hu|<http://arxiv.org/pdf/2503.21999v2>|提出了一种针对微控制器的统一硬件感知NAS框架，通过循环优化各模块，实现了更快的收敛速度和更高的检测...|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SOHES: Self-supervised Open-world Hierarchical Entity Segmentation|自监督开放世界层次实体分割方法（SOHES）|Shengcao Cao, Jiuxiang Gu, Jason Kuen, Hao Tan, Ruiyi Zhang, Handong Zhao, Ani Nenkova, Liang-Yan Gui .etc.|<http://arxiv.org/pdf/2404.12386v2>|提出了一种无需人工标注的开放世界实体分割方法SOHES，通过自监督学习实现高质量分割效果。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|WithAnyone: Towards Controllable and ID Consistent Image Generation|与任何人：迈向可控且身份一致性的图像生成|Hengyuan Xu, Wei Cheng, Peng Xing, Yixiao Fang, Shuhan Wu, Rui Wang, Xianfang Zeng, Daxin Jiang .etc.|<http://arxiv.org/pdf/2510.14975v1>|提出了一种对抗复制粘贴现象的图像生成模型WithAnyone，通过大规模数据集和对比损失函数实现了身...|
|🆕 发布|pi-Flow: Policy-Based Few-Step Generation via Imitation Distillation|π-流：基于策略的少步生成通过模仿蒸馏|Hansheng Chen, Kai Zhang, Hao Tan, Leonidas Guibas, Gordon Wetzstein, Sai Bi|<http://arxiv.org/pdf/2510.14974v1>|提出了一种基于策略的生成模型pi-Flow，通过模仿蒸馏避免质量-多样性权衡，实现快速准确的数据去噪...|
|🆕 发布|Terra: Explorable Native 3D World Model with Point Latents|“Terra：具有点潜在特性的可探索原生3D世界模型”|Yuanhui Huang, Weiliang Chen, Wenzhao Zheng, Xin Tao, Pengfei Wan, Jie Zhou, Jiwen Lu|<http://arxiv.org/pdf/2510.14977v1>|提出原生3D世界模型Terra，使用点隐空间编码和解码，实现高效且一致的三维场景重建与探索。|
|🆕 发布|MathCanvas: Intrinsic Visual Chain-of-Thought for Multimodal Mathematical Reasoning|数学画布：用于多模态数学推理的内在视觉思维链|Weikang Shi, Aldrich Yu, Rongyao Fang, Houxing Ren, Ke Wang, Aojun Zhou, Changyao Tian, Xinyu Fu .etc.|<http://arxiv.org/pdf/2510.14958v1>|提出MathCanvas框架，使大型多模态模型具备内在的视觉推理能力，显著提升数学问题解决性能。|
|🆕 发布|OmniMotion: Multimodal Motion Generation with Continuous Masked Autoregression|全方位运动生成：基于连续遮蔽自回归的多模态运动生成|Zhe Li, Weihao Yuan, Weichao Shen, Siyu Zhu, Zilong Dong, Chang Xu|<http://arxiv.org/pdf/2510.14954v1>|提出了一种连续掩码自回归的全身多模态运动生成机制，有效融合文本、语音和音乐等多种模态信息。|
|🆕 发布|3D Scene Prompting for Scene-Consistent Camera-Controllable Video Generation|用于场景一致性的相机可控视频生成的三维场景提示|JoungBin Lee, Jaewoo Jung, Jisang Han, Takuya Narihira, Kazumi Fukuda, Junyoung Seo, Sunghwan Hong, Yuki Mitsufuji .etc.|<http://arxiv.org/pdf/2510.14945v1>|[代码](https://cvlab-kaist.github.io/3DScenePrompt); 提出3DScenePrompt框架，通过双时空条件实现精确相机控制和场景一致性，生成高质量视频片段。|
|🆕 发布|From Language to Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance|从语言到移动：通过运动潜在引导的无重定向 humanoid 控制|Zhe Li, Cheng Chi, Yangyang Wei, Boan Zhu, Yibo Peng, Tao Huang, Pengwei Wang, Zhongyuan Wang .etc.|<http://arxiv.org/pdf/2510.14952v1>|分类|
|🆕 发布|ScaleWeaver: Weaving Efficient Controllable T2I Generation with Multi-Scale Reference Attention|《ScaleWeaver：利用多尺度参考注意力编织高效可控的文本到图像生成》|Keli Liu, Zhendong Wang, Wengang Zhou, Shaodong Xu, Ruixiao Dong, Houqiang Li|<http://arxiv.org/pdf/2510.14882v1>|提出ScaleWeaver框架，通过参数高效微调实现视觉自回归模型的高保真、可控文本到图像生成。|
|📝 更新|Ctrl-VI: Controllable Video Synthesis via Variational Inference|Ctrl-VI：通过变分推理实现可控视频合成|Haoyi Duan, Yunzhi Zhang, Yilun Du, Jiajun Wu|<http://arxiv.org/pdf/2510.07670v2>|提出了一种可控视频合成方法Ctrl-VI，通过变分推理实现高元素控制性和多样性的平衡。|
|🆕 发布|TOUCH: Text-guided Controllable Generation of Free-Form Hand-Object Interactions|《TOUCH：基于文本引导的自由形式手-物交互可控生成》|Guangyi Han, Wei Zhai, Yuhang Yang, Yang Cao, Zheng-Jun Zha|<http://arxiv.org/pdf/2510.14874v1>|[代码](https://guangyid.github.io/hoi123touch); 提出了一种多级扩散模型TOUCH，实现了基于细粒度意图的多样化、可控且物理可信的手-物交互生成。|
|📝 更新|AvatarSync: Rethinking Talking-Head Animation through Phoneme-Guided Autoregressive Perspective|《AvatarSync：通过音素引导的自回归视角重新思考说话人头动画》|Yuchen Deng, Xiuyang Wu, Hai-Tao Zheng, Suiyang Zhang, Yi He, Yuxing Han|<http://arxiv.org/pdf/2509.12052v2>|提出AvatarSync方法，通过音素引导自回归框架，解决了说话人头动画中的帧间闪烁和推理速度慢的问...|
|🆕 发布|FraQAT: Quantization Aware Training with Fractional bits|FraQAT: 基于分数位的量化感知训练|Luca Morreale, Alberto Gil C. P. Ramos, Malcolm Chadwick, Mehid Noroozi, Ruchika Chavhan, Abhinav Mehrotra, Sourav Bhattacharya|<http://arxiv.org/pdf/2510.14823v1>|提出了一种基于分数位量化的训练方法，通过逐步降低模型精度并利用分数位优化，有效保持了生成图像的质量。|
|🆕 发布|Adapting Self-Supervised Representations as a Latent Space for Efficient Generation|将自监督表征适配为高效生成的潜在空间|Ming Gui, Johannes Schusterbauer, Timy Phan, Felix Krause, Josh Susskind, Miguel Angel Bautista, Björn Ommer|<http://arxiv.org/pdf/2510.14630v1>|提出了一种利用自监督学习表征作为潜在空间的生成模型，有效降低训练成本并实现竞争性生成效果。|
|📝 更新|3DOT: Texture Transfer for 3DGS Objects from a Single Reference Image|3DOT：从单张参考图像进行三维游戏角色对象的纹理迁移|Xiao Cao, Beibei Lin, Bo Wang, Zhiyong Huang, Robby T. Tan|<http://arxiv.org/pdf/2503.18853v2>|提出了一种3D纹理转换方法，通过渐进生成和一致性引导，实现了高效且视角一致的3D对象纹理定制。|
|🆕 发布|Consistent text-to-image generation via scene de-contextualization|通过场景去上下文化的文本到图像一致性生成|Song Tang, Peihao Gong, Kunyu Li, Kai Guo, Boyu Wang, Mao Ye, Jianwei Zhang, Xiatian Zhu|<http://arxiv.org/pdf/2510.14553v1>|提出了一种无需训练的Scene De-Contextualization方法，有效解决了文本到图像生...|
|📝 更新|ChartGalaxy: A Dataset for Infographic Chart Understanding and Generation|图表星系：一个用于信息图表理解和生成的数据集|Zhen Li, Duan Li, Yukai Guo, Xinyuan Guo, Bowen Li, Lanxi Xiao, Shenyu Qiao, Jiashu Chen .etc.|<http://arxiv.org/pdf/2505.18668v5>|提出了ChartGalaxy数据集，通过合成 infographic 图表，提升了大型视觉语言模型对...|
|🆕 发布|Deep Compositional Phase Diffusion for Long Motion Sequence Generation|深度组合相位扩散用于长运动序列生成|Ho Yin Au, Jie Chen, Junkun Jiang, Jingyu Xiang|<http://arxiv.org/pdf/2510.14427v1>|[代码](https://github.com/asdryau/TransPhase.); 提出了一种生成连续性更好的复合运动序列的方法，通过逐步融合语义指导和相位细节，解决了运动剪辑间过渡不...|
|🆕 发布|DOS: Directional Object Separation in Text Embeddings for Multi-Object Image Generation|用于多对象图像生成的文本嵌入中的方向性对象分离DOS|Dongnam Byun, Jungwon Park, Jumgmin Ko, Changin Choi, Wonjong Rhee|<http://arxiv.org/pdf/2510.14376v1>|提出DOS方法，通过修改CLIP文本嵌入提升多物体图像生成质量，减少物体混合。|
|📝 更新|Flows and Diffusions on the Neural Manifold|神经网络流形上的流与扩散|Daniel Saragih, Deyu Cao, Tejas Balaji|<http://arxiv.org/pdf/2507.10623v2>|将梯度下降轨迹视为轨迹推理问题，统一多种推理技术以匹配梯度流，提升生成模型在权重空间学习的效果。|
|📝 更新|Earth-Agent: Unlocking the Full Landscape of Earth Observation with Agents|地球代理：利用代理解锁地球观测的全景图|Peilin Feng, Zhutao Lv, Junyan Ye, Xiaolei Wang, Xinjie Huo, Jinhua Yu, Wanghan Xu, Wenlong Zhang .etc.|<http://arxiv.org/pdf/2509.23141v2>|提出了一种集成RGB与光谱数据的Earth-Agent框架，实现了跨模态、多步骤的地球观测推理分析。|
|📝 更新|A Clinically-Grounded Two-Stage Framework for Renal CT Report Generation|基于临床的肾CT报告生成的两阶段框架|Renjie Liang, Zhengkang Fan, Jinqian Pan, Chenkun Sun, Bruce Daniel Steinberg, Russell Terry, Jie Xu|<http://arxiv.org/pdf/2506.23584v2>|提出了一种两阶段临床导向框架，通过结合结构化特征检测和条件性报告生成，提高了肾CT报告的准确性和临床...|
|📝 更新|ComposeMe: Attribute-Specific Image Prompts for Controllable Human Image Generation|《ComposeMe：用于可控人类图像生成的属性特定图像提示》|Guocheng Gordon Qian, Daniil Ostashev, Egor Nemchinov, Avihay Assouline, Sergey Tulyakov, Kuan-Chieh Jackson Wang, Kfir Aberman|<http://arxiv.org/pdf/2509.18092v2>|[代码](https://snap-research.github.io/composeme); 提出了一种基于特定属性图像提示的方法，实现了对人类图像生成中发型和服饰等属性的细粒度控制。|
|📝 更新|SphereDrag: Spherical Geometry-Aware Panoramic Image Editing|球面拖拽：基于球面几何的全景图像编辑|Zhiao Feng, Xuewei Li, Junjie Yang, Jingchao Li, Yuxin Peng, Xi Li|<http://arxiv.org/pdf/2506.11863v2>|提出SphereDrag框架，利用球面几何知识解决全景图像编辑中的边界不连续、轨迹变形和像素密度不均...|
|🆕 发布|Identity-GRPO: Optimizing Multi-Human Identity-preserving Video Generation via Reinforcement Learning|身份-GRPO：通过强化学习优化多人身份保持视频生成|Xiangyu Meng, Zixian Zhang, Zhenghao Zhang, Junchao Liao, Long Qin, Weizhi Wang|<http://arxiv.org/pdf/2510.14256v1>|提出了一种基于人类反馈的优化管道Identity-GRPO，用于提升多人物视频生成中身份一致性的保持...|
|📝 更新|CymbaDiff: Structured Spatial Diffusion for Sketch-based 3D Semantic Urban Scene Generation|《CymbaDiff：基于草图的三维语义城市场景生成的结构化空间扩散》|Li Liang, Bo Miao, Xinyu Wang, Naveed Akhtar, Jordan Vice, Ajmal Mian|<http://arxiv.org/pdf/2510.13245v2>|[代码](https://github.com/Lillian-research-hub/CymbaDiff); 提出SketchSem3D数据集并引入CymbaDiff方法，提高了3D户外场景生成的空间一致性和真...|
|📝 更新|OmniGaze: Reward-inspired Generalizable Gaze Estimation In The Wild|全方位注视：基于奖励启发的野外泛化注视估计|Hongyu Qu, Jianan Wei, Xiangbo Shu, Yazhou Yao, Wenguan Wang, Jinhui Tang|<http://arxiv.org/pdf/2510.13660v2>|OmniGaze通过半监督框架和奖励模型，利用大规模未标注数据集，有效提升了3D gaze esti...|
|📝 更新|CAP: Evaluation of Persuasive and Creative Image Generation|CAP: 图像生成中的说服力与创造力评估|Aysan Aghazadeh, Adriana Kovashka|<http://arxiv.org/pdf/2412.10426v2>|提出三个评价指标评估广告图像的创造力、提示对齐性和说服力，并引入一种增强文本到图像模型生成效果的方法...|
|📝 更新|HuGDiffusion: Generalizable Single-Image Human Rendering via 3D Gaussian Diffusion|HuGDiffusion：通过三维高斯扩散实现的通用单张图像人物渲染|Yingzhi Tang, Qijian Zhang, Junhui Hou|<http://arxiv.org/pdf/2501.15008v2>|提出了一种基于单张图片的通用人体渲染方法，通过3D高斯扩散实现新颖视角合成。|
|🆕 发布|LOTA: Bit-Planes Guided AI-Generated Image Detection|LOTA：比特平面引导的AI生成图像检测|Hongsong Wang, Renxi Cheng, Yang Zhang, Chaolei Han, Jie Gui|<http://arxiv.org/pdf/2510.14230v1>|[代码](https://github.com/hongsong-wang/LOTA.); 提出了一种基于比特平面处理的AI生成图像检测方法，大幅提升了检测速度和准确性。|
|📝 更新|EdiVal-Agent: An Object-Centric Framework for Automated, Fine-Grained Evaluation of Multi-Turn Editing|EdiVal-Agent：一种面向对象的自动化、细粒度多轮编辑评估框架|Tianyu Chen, Yasi Zhang, Zhi Zhang, Peiyu Yu, Shu Wang, Zhendong Wang, Kevin Lin, Xiaofei Wang .etc.|<http://arxiv.org/pdf/2509.13399v2>|提出了一种基于对象中心的EdiVal-Agent框架，精确评估多轮指令驱动的图像编辑性能。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Ponimator: Unfolding Interactive Pose for Versatile Human-human Interaction Animation|Ponimator：展开交互式姿态以实现多样化的人与人交互动画|Shaowei Liu, Chuan Guo, Bing Zhou, Jian Wang|<http://arxiv.org/pdf/2510.14976v1>|提出Ponimator框架，利用互动姿态先验生成多样化交互动画，实现从单个体姿态到动态互动的转换。|
|🆕 发布|Coupled Diffusion Sampling for Training-Free Multi-View Image Editing|耦合扩散采样用于无需训练的多视角图像编辑|Hadi Alzayer, Yunzhi Zhang, Chen Geng, Jia-Bin Huang, Jiajun Wu|<http://arxiv.org/pdf/2510.14981v1>|分类|
|🆕 发布|RainDiff: End-to-end Precipitation Nowcasting Via Token-wise Attention Diffusion|雨滴差分：通过逐标记注意力扩散实现端到端降水预测|Thao Nguyen, Jiaqi Ma, Fahad Shahbaz Khan, Souhaib Ben Taieb, Salman Khan|<http://arxiv.org/pdf/2510.14962v1>|提出了一种结合注意力机制的U-Net扩散模型，有效捕捉多尺度时空交互，提升降水预测的准确性。|
|🆕 发布|RealDPO: Real or Not Real, that is the Preference|《RealDPO：是真是假，这就是偏好》|Guo Cheng, Danni Yang, Ziqi Huang, Jianlou Si, Chenyang Si, Ziwei Liu|<http://arxiv.org/pdf/2510.14955v1>|提出RealDPO方法，利用现实世界数据优化偏好学习，显著提升视频生成模型中复杂运动的自然度和连贯性...|
|📝 更新|Deep Few-view High-resolution Photon-counting CT at Halved Dose for Extremity Imaging|深度学习驱动的低剂量高清光子计数CT在肢体成像中的应用|Mengzhou Li, Chuang Niu, Ge Wang, Maya R Amma, Krishna M Chapagain, Stefan Gabrielson, Andrew Li, Kevin Jonker .etc.|<http://arxiv.org/pdf/2403.12331v2>|提出了一种深度学习方法，实现了在减半辐射剂量的同时加倍速度进行高分辨率X射线光子计数CT成像。|
|🆕 发布|Inpainting the Red Planet: Diffusion Models for the Reconstruction of Martian Environments in Virtual Reality|《修复红色星球：用于虚拟现实中火星环境重建的扩散模型》|Giuseppe Lorenzo Catalano, Agata Marta Soccini|<http://arxiv.org/pdf/2510.14765v1>|提出了一种基于无条件扩散模型的方法，用于精确重构火星表面，显著优于传统插值技术。|
|🆕 发布|DEXTER: Diffusion-Guided EXplanations with TExtual Reasoning for Vision Models|DEXTER：基于文本推理的扩散引导视觉模型解释方法|Simone Carnemolla, Matteo Pennisi, Sarinda Samarasinghe, Giovanni Bellitto, Simone Palazzo, Daniela Giordano, Mubarak Shah, Concetto Spampinato|<http://arxiv.org/pdf/2510.14741v1>|[代码](https://github.com/perceivelab/dexter.); DEXTER通过结合扩散模型和大型语言模型，无需训练数据即可为视觉分类器生成全局性文本解释。|
|📝 更新|Synthetic History: Evaluating Visual Representations of the Past in Diffusion Models|合成历史：评估扩散模型中过去视觉表征的有效性|Maria-Teresa De Rosa Palmini, Eva Cetinic|<http://arxiv.org/pdf/2505.17064v2>|提出历史场景描绘评估基准，揭示了文本到图像模型在历史准确性方面的不足。|
|📝 更新|Attention Surgery: An Efficient Recipe to Linearize Your Video Diffusion Transformer|注意力手术：一种高效方法将您的视频扩散变压器线性化|Mohsen Ghafoorian, Denis Korzhenkov, Amirhossein Habibian|<http://arxiv.org/pdf/2509.24899v2>|[代码](https://qualcomm-ai-research.github.io/attention-surgery.); 提出了一种无需从头训练的“注意力手术”方法，有效将视频扩散模型中的注意力线性化，降低计算成本同时保持...|
|📝 更新|Does FLUX Already Know How to Perform Physically Plausible Image Composition?|FLUX是否已经知道如何执行物理上可信的图像合成？|Shilin Lu, Zhuming Lian, Zihan Zhou, Shaocong Zhang, Chen Zhao, Adams Wai-Kin Kong|<http://arxiv.org/pdf/2509.21278v2>|提出SHINE框架，通过利用预训练模型实现无需训练的高质量图像合成，解决了复杂光照和多样输入下的合成...|
|📝 更新|A Denoising Framework for Real-World Ultra-Low Dose Lung CT Images Based on an Image Purification Strategy|基于图像净化策略的实际超低剂量肺部CT图像去噪框架|Guoliang Gong, Man Yu|<http://arxiv.org/pdf/2510.07492v2>|[代码](https://github.com/MonkeyDadLufy/flow-matching.); 提出了一种基于图像净化策略的降噪框架，有效解决了低剂量CT图像的噪声和错位问题，实现了最佳的解剖结构...|
|📝 更新|TTT3R: 3D Reconstruction as Test-Time Training|TTT3R：测试时训练的三维重建|Xingyu Chen, Yue Chen, Yuliang Xiu, Andreas Geiger, Anpei Chen|<http://arxiv.org/pdf/2509.26645v3>|[代码](https://rover-xingyu.github.io/TTT3R); 提出了一种测试时训练方法TTT3R，通过在线学习显著提升3D重建模型在长度泛化上的性能。|
|🆕 发布|Noise Projection: Closing the Prompt-Agnostic Gap Behind Text-to-Image Misalignment in Diffusion Models|噪声投影：弥合文本到图像失配背后的扩散模型中提示无关性差距|Yunze Tong, Didi Zhu, Zijing Hu, Jinluan Yang, Ziyu Zhao|<http://arxiv.org/pdf/2510.14526v1>|提出噪声投影方法，通过文本条件优化初始噪声，有效提升文本到图像的对齐度。|
|📝 更新|OmnimatteZero: Fast Training-free Omnimatte with Pre-trained Video Diffusion Models|全向材质零：基于预训练视频扩散模型的快速无训练全向材质|Dvir Samuel, Matan Levy, Nir Darshan, Gal Chechik, Rami Ben-Ari|<http://arxiv.org/pdf/2503.18033v3>|提出了一种无需训练的OmnimatteZero方法，利用预训练视频扩散模型实现视频中的对象移除和效果...|
|🆕 发布|Unsupervised Deep Generative Models for Anomaly Detection in Neuroimaging: A Systematic Scoping Review|无监督深度生成模型在神经影像异常检测中的应用：系统性范围综述|Youwan Mahé, Elise Bannier, Stéphanie Leplaideur, Elisa Fromont, Francesca Galassi|<http://arxiv.org/pdf/2510.14462v1>|提出无监督深度生成模型用于神经影像异常检测，无需标注数据即可识别病变。|
|🆕 发布|Spatial Preference Rewarding for MLLMs Spatial Understanding|用于提升多模态语言模型空间理解的空间偏好奖励方法|Han Qiu, Peng Gao, Lewei Lu, Xiaoqin Zhang, Ling Shao, Shijian Lu|<http://arxiv.org/pdf/2510.14374v1>|[代码](https://github.com/hanqiu-hq/SPR); 提出了一种奖励机制SPR，通过精确对象定位增强大型多模态语言模型的细粒度空间感知能力。|
|📝 更新|One Stone with Two Birds: A Null-Text-Null Frequency-Aware Diffusion Models for Text-Guided Image Inpainting|一石二鸟：面向文本引导图像修复的零文本零频率感知扩散模型|Haipeng Liu, Yang Wang, Meng Wang|<http://arxiv.org/pdf/2510.08273v4>|[代码](https://github.com/htyjers/NTN-Diff.); 提出了一种分解频率带的扩散模型NTN-Diff，通过分阶段处理实现文本引导的图像修复，同时保持未遮蔽...|
|📝 更新|AttenCraft: Attention-guided Disentanglement of Multiple Concepts for Text-to-Image Customization|AttenCraft：基于注意力引导的多概念解耦用于文本到图像定制化|Junjie Shentu, Matthew Watson, Noura Al Moubayed|<http://arxiv.org/pdf/2405.17965v2>|提出了一种基于注意力的多概念解耦方法AttenCraft，有效解决了特征融合和异步学习问题，提升了图...|
|📝 更新|On Equivariance and Fast Sampling in Video Diffusion Models Trained with Warped Noise|在视频扩散模型中关于等方差性和快速采样训练的研究：基于扭曲噪声的模型训练|Chao Liu, Arash Vahdat|<http://arxiv.org/pdf/2504.09789v2>|提出了一种视频生成模型训练方法，通过引入扭曲噪声实现空间变换等变性和高效采样，显著提升了视频时序一致...|
|🆕 发布|A Multi-domain Image Translative Diffusion StyleGAN for Iris Presentation Attack Detection|多域图像迁移扩散风格 StyleGAN 用于虹膜呈现攻击检测|Shivangi Yadav, Arun Ross|<http://arxiv.org/pdf/2510.14314v1>|提出了一种生成合成眼部图像的MID-StyleGAN框架，有效解决了iris PAD数据稀缺问题并提...|
|📝 更新|ForensicHub: A Unified Benchmark & Codebase for All-Domain Fake Image Detection and Localization|法医中心：一种用于全领域伪造图像检测与定位的统一基准与代码库|Bo Du, Xuekang Zhu, Xiaochen Ma, Chenfan Qu, Kaiwen Feng, Zhe Yang, Chi-Man Pun, Jian Liu .etc.|<http://arxiv.org/pdf/2505.11003v2>|ForensicHub统一了fake图像检测与定位的四个领域，通过模块化架构和基准，促进了跨域比较和...|
|📝 更新|TRACE: Your Diffusion Model is Secretly an Instance Edge Detector|TRACE：你的扩散模型实际上是一个实例边缘检测器|Sanghyun Jo, Ziseok Lee, Wooyeol Lee, Jonghyun Choi, Jaesik Park, Kyungsu Kim|<http://arxiv.org/pdf/2503.07982v2>|[代码](https://github.com/shjo-april/DiffEGG.); 提出TRACE方法，利用扩散模型自动检测实例边缘，无需密集标注即可提升分割质量。|
|🆕 发布|Virtually Being: Customizing Camera-Controllable Video Diffusion Models with Multi-View Performance Captures|虚拟存在：利用多视角表演捕捉定制摄像头可控视频扩散模型|Yuancheng Xu, Wenqi Xian, Li Ma, Julien Philip, Ahmet Levent Taşel, Yiwei Zhao, Ryan Burgert, Mingming He .etc.|<http://arxiv.org/pdf/2510.14179v1>|[代码](https://eyeline-labs.github.io/Virtually-Being.); 提出了一种定制化多视角视频扩散模型的新框架，实现了精确的相机控制和多视角一致性。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints|影像搜索：超越语义依赖约束的适应性测试时视频生成搜索|Meiqi Wu, Jiashu Zhu, Xiaokun Feng, Chubin Chen, Chen Zhu, Bingze Song, Fangyuan Mao, Jiahong Wu .etc.|<http://arxiv.org/pdf/2510.14847v1>|提出了一种自适应测试时搜索策略ImagerySearch，通过动态调整搜索空间和奖励函数，有效提升了...|
|📝 更新|MetaCaptioner: Towards Generalist Visual Captioning with Open-source Suites|元标注器：面向通用视觉标注的开源工具套件|Zhenxin Lei, Zhangwei Gao, Changyao Tian, Erfei Cui, Guanzhou Chen, Danni Yang, Yuchen Duan, Zhaokai Wang .etc.|<http://arxiv.org/pdf/2510.12126v3>|提出CapFlow多代理协作流程，实现开源模型生成与GPT-4.1质量相当的视觉字幕，降低成本89....|
|🆕 发布|GOPLA: Generalizable Object Placement Learning via Synthetic Augmentation of Human Arrangement|GOPLA：通过合成增强人类排列的泛化对象放置学习|Yao Zhong, Hanzhi Chen, Simon Schaefer, Anran Zhang, Stefan Leutenegger|<http://arxiv.org/pdf/2510.14627v1>|提出了一种学习通用物体放置的分层框架，通过合成数据增强人类演示，显著提升了机器人日常物品摆放的成功率...|
|🆕 发布|Shot2Tactic-Caption: Multi-Scale Captioning of Badminton Videos for Tactical Understanding|《羽毛球视频战术理解的多尺度字幕标注：Shot2Tactic-Caption》|Ning Ding, Keisuke Fujii, Toru Tamaki|<http://arxiv.org/pdf/2510.14617v1>|提出了一种多尺度视频字幕框架，用于解析羽毛球比赛中的动作和战术执行过程。|
|🆕 发布|STANCE: Motion Coherent Video Generation Via Sparse-to-Dense Anchored Encoding|STANCE：通过稀疏到密集锚定编码实现运动连贯的视频生成|Zhifei Chen, Tianshuo Xu, Leyi Wu, Luozhou Wang, Dongyu Yan, Zihan You, Wenting Luo, Guo Zhang .etc.|<http://arxiv.org/pdf/2510.14588v1>|通过引入实例提示和密集旋转位置编码，STANCE框架有效提升了视频生成中的运动一致性和时序连贯性。|
|📝 更新|HANS-Net: Hyperbolic Convolution and Adaptive Temporal Attention for Accurate and Generalizable Liver and Tumor Segmentation in CT Imaging|HANS-Net：双曲卷积与自适应时间注意力机制用于精确且泛化的肝脏和肿瘤分割在CT成像中|Arefin Ittesafun Abian, Ripon Kumar Debnath, Md. Abdur Rahman, Mohaimenul Azam Khan Raiaan, Md Rafiqul Islam, Asif Karim, Reem E. Mohamed, Sami Azam|<http://arxiv.org/pdf/2507.11325v2>|提出HANS-Net，结合超双曲卷积与自适应时序注意力，实现了腹部CT图像中肝脏和肿瘤的高准确度与泛...|
|🆕 发布|AI for Service: Proactive Assistance with AI Glasses|服务用AI：通过AI眼镜的主动辅助|Zichen Wen, Yiyu Wang, Chenfei Liao, Boxue Yang, Junxian Li, Weifeng Liu, Haocong He, Bolong Feng .etc.|<http://arxiv.org/pdf/2510.14359v1>|提出AI4Service新范式，通过Alpha-Service框架实现智能眼镜的主动实时辅助。|
|🆕 发布|Identity-Preserving Image-to-Video Generation via Reward-Guided Optimization|通过奖励引导优化实现的保真图像到视频生成|Liao Shen, Wentao Jiang, Yiran Zhu, Tiezheng Ge, Zhiguo Cao, Bo Zheng|<http://arxiv.org/pdf/2510.14255v1>|提出了一种基于强化学习的视频生成框架，通过优化扩散模型有效保持了人物身份一致性。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Moto: Latent Motion Token as the Bridging Language for Learning Robot Manipulation from Videos|“Moto：潜在运动标记作为从视频学习机器人操作的中介语言”|Yi Chen, Yuying Ge, Weiliang Tang, Yizhuo Li, Yixiao Ge, Mingyu Ding, Ying Shan, Xihui Liu|<http://arxiv.org/pdf/2412.04445v4>|提出将视频转化为运动潜码序列，通过自回归预训练提升机器人操作学习效率。|
|📝 更新|ART-VITON: Measurement-Guided Latent Diffusion for Artifact-Free Virtual Try-On|ART-VITON：测量引导的潜在扩散技术实现无瑕疵虚拟试穿|Junseo Park, Hyeryung Jang|<http://arxiv.org/pdf/2509.25749v2>|提出测量引导的扩散框架ART-VITON，有效消除虚拟试衣中的边界伪影并提高视觉保真度和稳健性。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LinPrim: Linear Primitives for Differentiable Volumetric Rendering|线性基元：用于可微体积渲染的线性原语|Nicolas von Lützow, Matthias Nießner|<http://arxiv.org/pdf/2501.16312v4>|引入线性原语（八面体和四面体）作为体积渲染的新型场景表示，实现高效实时渲染与优化。|
|📝 更新|Impact of Regularization on Calibration and Robustness: from the Representation Space Perspective|正则化对校准与鲁棒性的影响：从表征空间视角分析|Jonghyun Park, Juyeop Kim, Jong-Seok Lee|<http://arxiv.org/pdf/2410.03999v2>|从特征空间角度揭示了正则化如何通过调整特征分布改善模型的校准性和鲁棒性。|
|📝 更新|SimULi: Real-Time LiDAR and Camera Simulation with Unscented Transforms|“SimULi：基于无迹变换的实时激光雷达与摄像头仿真”|Haithem Turki, Qi Wu, Xin Kang, Janick Martinez Esturo, Shengyu Huang, Ruilong Li, Zan Gojcic, Riccardo de Lutio|<http://arxiv.org/pdf/2510.12901v2>|SimULi通过实时渲染任意相机模型和LiDAR数据，解决了现有方法速度慢和传感器不一致问题。|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|C4D: 4D Made from 3D through Dual Correspondences|从三维到四维的转换：通过双重对应关系实现|Shizun Wang, Zhenxiang Jiang, Xingyi Yang, Xinchao Wang|<http://arxiv.org/pdf/2510.14960v1>|[代码](https://littlepure2333.github.io/C4D); 提出了一种利用双对应关系从3D重建扩展到4D动态场景的框架，有效解决了动态几何和相机姿态估计问题。|
|📝 更新|Shape of Motion: 4D Reconstruction from a Single Video|运动的形状：从单个视频中进行四维重建|Qianqian Wang, Vickie Ye, Hang Gao, Weijia Zeng, Jake Austin, Zhengqi Li, Angjoo Kanazawa|<http://arxiv.org/pdf/2407.13764v2>|提出了一种利用紧凑运动基和先验数据驱动方法，从单视频重建动态三维场景的新技术。|
|📝 更新|Reasoning in Space via Grounding in the World|通过在世界中定位来实现空间推理|Yiming Chen, Zekun Qi, Wenyao Zhang, Xin Jin, Li Zhang, Peidong Liu|<http://arxiv.org/pdf/2510.13800v2>|提出了一种统一的三维空间推理框架GS-Reasoner，通过双路径池化机制整合语义与几何信息，实现了...|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MaskCaptioner : Learning to Jointly Segment and Caption Object Trajectories in Videos|视频中的对象轨迹联合分割与标注学习：MaskCaptioner|Gabriel Fiastre, Antoine Yang, Cordelia Schmid|<http://arxiv.org/pdf/2510.14904v1>|提出了一种端到端模型MaskCaptioner，实现了视频中的对象轨迹检测、分割、跟踪和字幕生成的一...|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BADAS: Context Aware Collision Prediction Using Real-World Dashcam Data|BADAS：利用现实世界行车记录仪数据实现上下文感知的碰撞预测|Roni Goldshmidt, Hamish Scott, Lorenzo Niccolini, Shizhan Zhu, Daniel Moura, Orly Zvitia|<http://arxiv.org/pdf/2510.14876v1>|提出了一种基于现实世界行车记录仪数据的碰撞预测模型BADAS，有效区分了驾驶员车辆相关威胁与其他随机...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SVAG-Bench: A Large-Scale Benchmark for Multi-Instance Spatio-temporal Video Action Grounding|SVAG-Bench：多实例时空视频动作定位的大规模基准数据集|Tanveer Hannan, Shuaicong Wu, Mark Weber, Suprosanna Shit, Jindong Gu, Rajat Koner, Aljoša Ošep, Laura Leal-Taixé .etc.|<http://arxiv.org/pdf/2510.13016v2>|提出SVAG-Bench大规模基准，用于多实例时空视频动作定位，并设计相应模型和评估工具。|
|📝 更新|MSF-Mamba: Motion-aware State Fusion Mamba for Efficient Micro-Gesture Recognition|MSF-Mamba：面向高效微手势识别的运动感知状态融合Mamba|Deng Li, Jun Shao, Bohao Xing, Rong Gao, Bihan Wen, Heikki Kälviäinen, Xin Liu|<http://arxiv.org/pdf/2510.10478v2>|提出MSF-Mamba模型，通过融合局部时空状态和引入运动感知模块，高效识别微动作。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Camera Movement Classification in Historical Footage: A Comparative Study of Deep Video Models|历史影像中的摄像机运动分类：深度视频模型的比较研究|Tingyu Lin, Armin Dadras, Florian Kleber, Robert Sablatnig|<http://arxiv.org/pdf/2510.14713v1>|首次系统评估了深度视频模型在历史影像中的表现，发现Video Swin Transformer模型在...|
|🆕 发布|Eyes Wide Open: Ego Proactive Video-LLM for Streaming Video|“睁大眼睛：面向流视频的自适应 ego 视频大模型”|Yulin Zhang, Cheng Shi, Yang Wang, Sibei Yang|<http://arxiv.org/pdf/2510.14560v1>|[代码](https://zhangyl4.github.io/publications); 提出了一种面向第一视角视频的主动式理解和响应模型，通过同步感知与推理，提升了视频流中实时问题解答的效...|
|🆕 发布|Real-Time Neural Video Compression with Unified Intra and Inter Coding|统一 intra 和 inter 编码的实时神经视频压缩|Hui Xiang, Yifan Bian, Li Li, Jingran Wu, Xianguo Zhang, Dong Liu|<http://arxiv.org/pdf/2510.14431v1>|提出统一 intra 和 inter 编码的实时神经视频压缩框架，有效处理视频遮挡和新内容，减少错误...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multi-modal video data-pipelines for machine learning with minimal human supervision|多模态视频数据处理管道：在最小人工监督下进行机器学习|Mihai-Cristian Pîrvu, Marius Leordeanu|<http://arxiv.org/pdf/2510.14862v1>|整合多模态视觉数据，实现无需或少量人工监督的自主学习，提出高效低参数模型。|
|🆕 发布|Watermarking for Factuality: Guiding Vision-Language Models Toward Truth via Tri-layer Contrastive Decoding|水印真实性：通过三层对比解码引导视觉-语言模型趋向真实|Kyungryul Back, Seongbeom Park, Milim Kim, Mincheol Kwon, SangHyeok Lee, Hyunyoung Lee, Junhee Cho, Seunghyun Park .etc.|<http://arxiv.org/pdf/2510.14304v1>|提出了一种无训练需求的三角层对比解码水印方法，有效减少大型视觉语言模型中的虚构现象，提高输出真实性。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Agentic Design of Compositional Machines|《组合机器的代理性设计》|Wenqian Zhang, Weiyang Liu, Zhen Liu|<http://arxiv.org/pdf/2510.14980v1>|探究大语言模型在组合机器设计中的创造力，引入BesiegeField测试床并使用强化学习提升模型性能...|
|🆕 发布|QDepth-VLA: Quantized Depth Prediction as Auxiliary Supervision for Vision-Language-Action Models|QDepth-VLA：量化深度预测作为视觉-语言-动作模型的辅助监督|Yixuan Li, Yuhui Chen, Mingcai Zhou, Haoran Li|<http://arxiv.org/pdf/2510.14836v1>|提出了一种通过辅助深度预测任务增强视觉语言动作模型空间感知能力的方法，有效提升了模型的精细操作性能。|
|🆕 发布|LightQANet: Quantized and Adaptive Feature Learning for Low-Light Image Enhancement|《LightQANet：低光照图像增强的量化与自适应特征学习》|Xu Wu, Zhihui Lai, Xianxu Hou, Jie Zhou, Ya-nan Zhang, Linlin Shen|<http://arxiv.org/pdf/2510.14753v1>|提出了一种结合量化与自适应特征学习的低光照图像增强框架，有效提升了图像质量和光照适应性。|
|🆕 发布|EuroMineNet: A Multitemporal Sentinel-2 Benchmark for Spatiotemporal Mining Footprint Analysis in the European Union (2015-2024)|欧洲矿网：一个用于欧盟地区2015-2024年时空开采足迹分析的多时相哨兵-2基准数据集|Weikang Yu, Vincent Nwazelibe, Xianping Ma, Xiaokang Zhang, Richard Gloaguen, Xiao Xiang Zhu, Pedram Ghamisi|<http://arxiv.org/pdf/2510.14661v1>|[代码](https://github.com/EricYu97/EuroMineNet.); 提出了EuroMineNet，一个基于Sentinel-2影像的全面多时相基准，用于监测和分析欧洲联...|
|🆕 发布|Efficient Video Sampling: Pruning Temporally Redundant Tokens for Faster VLM Inference|高效视频采样：剪枝时间冗余标记以加快视觉语言模型推理速度|Natan Bagrov, Eugene Khvedchenia, Borys Tymchenko, Shay Aharon, Lior Kadoch, Tomer Keren, Ofri Masad, Yonatan Geifman .etc.|<http://arxiv.org/pdf/2510.14624v1>|提出了一种简单易用的视频采样方法EVS，通过剪除非静态图像区域，有效减少语言模型处理负担，实现快速视...|
|🆕 发布|DRBD-Mamba for Robust and Efficient Brain Tumor Segmentation with Analytical Insights|DRBD-Mamba：用于稳健且高效的大脑肿瘤分割及其分析洞察|Danish Ali, Ajmal Mian, Naveed Akhtar, Ghulam Mubashar Hassan|<http://arxiv.org/pdf/2510.14383v1>|提出了一种高效的3D脑肿瘤分割模型DRBD-Mamba，通过双分辨率和双向特征融合显著提升了准确性和...|
|📝 更新|Group-Wise Optimization for Self-Extensible Codebooks in Vector Quantized Models|分组优化用于向量量化模型中自扩展码本的构建|Hong-Kai Zheng, Piji Li|<http://arxiv.org/pdf/2510.13331v2>|提出Group-VQ方法，通过分组优化解决VQ-VAEs中代码本坍塌问题，提升图像重建质量。|
|🆕 发布|MatchAttention: Matching the Relative Positions for High-Resolution Cross-View Matching|匹配注意力：匹配相对位置以实现高分辨率跨视角匹配|Tingman Yan, Tao Liu, Xilian Yang, Qunfei Zhao, Zeyang Xia|<http://arxiv.org/pdf/2510.14260v1>|[代码](https://github.com/TingmanYan/MatchAttention.); 提出MatchAttention机制，通过动态匹配相对位置实现高分辨率跨视图匹配，有效处理遮挡并提升...|
|🆕 发布|MACE: Mixture-of-Experts Accelerated Coordinate Encoding for Large-Scale Scene Localization and Rendering|MACE：大规模场景定位与渲染的混合专家加速坐标编码|Mingkai Liu, Dikai Fan, Haohua Que, Haojia Gao, Xiao Liu, Shuxue Peng, Meixia Lin, Shengyu Gu .etc.|<http://arxiv.org/pdf/2510.14251v1>|提出MACE方法，通过混合专家网络和无需辅助损失的负载均衡策略，高效实现大规模场景的定位和渲染。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|From Pixels to Words -- Towards Native Vision-Language Primitives at Scale|从像素到文字——迈向大规模原生视觉语言基本单元|Haiwen Diao, Mingxuan Li, Silei Wu, Linjun Dai, Xiaohua Wang, Hanming Deng, Lewei Lu, Dahua Lin .etc.|<http://arxiv.org/pdf/2510.14979v1>|[代码](https://github.com/EvolvingLMMs-Lab/NEO.); 提出构建原则并实现NEO模型，使原生视觉语言模型在性能上比肩顶级模块化模型。|
|📝 更新|TABSurfer: a Hybrid Deep Learning Architecture for Subcortical Segmentation|TABSurfer：一种用于皮层下结构分割的混合深度学习架构|Aaron Cao, Vishwanatha M. Rao, Kejia Liu, Xinrui Liu, Andrew F. Laine, Jia Guo|<http://arxiv.org/pdf/2312.08267v2>|提出了一种3D patch-based CNN-Transformer混合模型TABSurfer，实...|
|📝 更新|Pruning Sparse Tensor Neural Networks Enables Deep Learning for 3D Ultrasound Localization Microscopy|剪枝稀疏张量神经网络使得三维超声定位显微术的深度学习成为可能|Brice Rauby, Paul Xing, Jonathan Porée, Maxime Gasse, Jean Provost|<http://arxiv.org/pdf/2402.09359v2>|提出稀疏张量神经网络，降低3D超声定位显微镜数据处理内存需求，提升高浓度下性能。|
|📝 更新|Online Continual Learning via Spiking Neural Networks with Sleep Enhanced Latent Replay|在线连续学习：通过睡眠增强潜在重放的尖峰神经网络|Erliang Lin, Wenbin Luo, Wei Jia, Yu Chen, Shaofu Yang|<http://arxiv.org/pdf/2507.02901v3>|提出SESZR方法，通过脉冲神经网络和睡眠增强的潜在重放策略，有效降低在线连续学习中的内存消耗并减少...|
|📝 更新|Perspective-Aware Teaching: Adapting Knowledge for Heterogeneous Distillation|具有透视感知的教学：为异构蒸馏适配知识|Jhe-Hao Lin, Yi Yao, Chan-Feng Hsu, Hongxia Xie, Hong-Han Shuai, Wen-Huang Cheng|<http://arxiv.org/pdf/2501.08885v3>|[代码](https://github.com/jimmylin0979/PAT.git.); 提出了一种视角感知的教学框架，实现了不同架构间的特征蒸馏，有效提升了知识迁移的效率和准确性。|
|🆕 发布|CALM-Net: Curvature-Aware LiDAR Point Cloud-based Multi-Branch Neural Network for Vehicle Re-Identification|CALM-Net：基于曲率感知的LiDAR点云多分支神经网络车辆重识别|Dongwook Lee, Sol Han, Jinwhan Kim|<http://arxiv.org/pdf/2510.14576v1>|提出了一种基于激光雷达点云的多分支神经网络，通过融合边缘卷积、点注意力和曲率嵌入，有效提升了车辆重识...|
|📝 更新|Towards Inclusive Communication: A Unified Framework for Generating Spoken Language from Sign, Lip, and Audio|迈向包容性通信：一种从手语、唇语和音频生成口语的统一框架|Jeong Hun Yeo, Hyeongseop Rha, Sungjune Park, Junil Won, Yong Man Ro|<http://arxiv.org/pdf/2508.20476v2>|提出首个统一框架，融合手语、唇读和音频，生成口语文本，提升了对聋哑人士的包容性通信。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BalanceGS: Algorithm-System Co-design for Efficient 3D Gaussian Splatting Training on GPU|"BalanceGS：GPU上高效三维高斯散点绘制训练的算法-系统协同设计"|Junyi Wu, Jiaming Xu, Jinhao Li, Yongkang Zhou, Jiayi Pan, Xingyang Li, Guohao Dai|<http://arxiv.org/pdf/2510.14564v1>|BalanceGS通过算法-系统协同设计优化3D Gaussian Splatting训练，平衡计算...|
|🆕 发布|PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model|PaddleOCR-VL：通过0.9B超紧凑视觉语言模型提升多语言文档解析性能|Cheng Cui, Ting Sun, Suyin Liang, Tingquan Gao, Zelun Zhang, Jiaxuan Liu, Xueqing Wang, Changda Zhou .etc.|<http://arxiv.org/pdf/2510.14528v1>|提出PaddleOCR-VL，一种高效的文档解析模型，通过结合视觉编码器和语言模型，实现多语言复杂元...|
|🆕 发布|Pruning Overparameterized Multi-Task Networks for Degraded Web Image Restoration|剪枝过参数化多任务网络以实现退化网络图像恢复|Thomas Katraouras, Dimitrios Rafailidis|<http://arxiv.org/pdf/2510.14463v1>|[代码](https://github.com/Thomkat/MIR-L.); 提出了一种压缩多任务图像修复模型的方法，通过迭代剪枝和权重重置，实现了参数减少90%而性能不减。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Scaling Tumor Segmentation: Best Lessons from Real and Synthetic Data|肿瘤分割的扩展：来自真实与合成数据的最佳经验教训|Qi Chen, Xinze Zhou, Chen Liu, Hao Chen, Wenxuan Li, Zekun Jiang, Ziyan Huang, Yuxuan Zhao .etc.|<http://arxiv.org/pdf/2510.14831v1>|利用合成数据加速肿瘤分割模型训练，创建了大规模多器官肿瘤标注数据集AbdomenAtlas 2.0。|
|📝 更新|The Principle of Uncertain Maximum Entropy|不确定最大熵原理|Kenneth Bogert, Matthew Kothe|<http://arxiv.org/pdf/2305.09868v5>|提出了一种放松最大熵原理要求的新方法，通过引入通信通道框架，提高了未知分布熵的上界估计和通信信息损失...|
|🆕 发布|CLEAR: Causal Learning Framework For Robust Histopathology Tumor Detection Under Out-Of-Distribution Shifts|CLEAR: 面对分布偏移的稳健病理组织学肿瘤检测的因果学习框架|Kieu-Anh Truong Thi, Huy-Hieu Pham, Duc-Trong Le|<http://arxiv.org/pdf/2510.14273v1>|提出了一种基于因果推断的框架，通过利用语义特征减轻混杂因素影响，有效应对病理图像领域迁移问题。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SteeringTTA: Guiding Diffusion Trajectories for Robust Test-Time-Adaptation|引导扩散轨迹以实现稳健的测试时适应：SteeringTTA|Jihyun Yu, Yoojin Oh, Wonho Bae, Mingyu Kim, Junhyug Noh|<http://arxiv.org/pdf/2510.14634v1>|提出了一种无模型更新需求的 SteeringTTA 方法，通过引导扩散轨迹平衡探索与置信度，有效提升...|
|📝 更新|The Fluorescent Veil: A Stealthy and Effective Physical Adversarial Patch Against Traffic Sign Recognition|《荧光面纱：一种隐秘且有效的物理对抗贴片，对抗交通标志识别》|Shuai Yuan, Xingshuo Han, Hongwei Li, Guowen Xu, Wenbo Jiang, Tao Ni, Qingchuan Zhao, Yuguang Fang|<http://arxiv.org/pdf/2409.12394v2>|提出了一种使用荧光墨水设计的隐秘且有效的物理对抗性贴片，在低光条件下使交通标志识别系统误识别率达到9...|
|📝 更新|RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety Evaluation via Role-Specialized Collaboration|雷达：一种基于角色专业化协作的面向大型语言模型安全性评估的风险感知动态多智能体框架|Xiuyuan Chen, Jian Zhao, Yuchen Yuan, Tianle Zhang, Huilin Zhou, Zheng Zhu, Ping Hu, Linghe Kong .etc.|<http://arxiv.org/pdf/2509.25271v2>|提出了一种风险感知的多智能体协作框架RADAR，通过角色专业化合作和动态更新机制，有效提升了大型语言...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|You May Speak Freely: Improving the Fine-Grained Visual Recognition Capabilities of Multimodal Large Language Models with Answer Extraction|您可能自由发言：通过答案提取改进多模态大型语言模型的细粒度视觉识别能力|Logan Lawrence, Oindrila Saha, Megan Wei, Chen Sun, Subhransu Maji, Grant Van Horn|<http://arxiv.org/pdf/2510.14885v1>|提出了一种两阶段方法nlg2choice，通过开放性问题询问和多选答案预测，提升了多模态大语言模型在...|
|📝 更新|Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignment|通过概率高斯对齐的无反向传播测试时适应|Youjia Zhang, Youngeun Kim, Young-Geun Choi, Hongyeob Kim, Huiling Liu, Sungeun Hong|<http://arxiv.org/pdf/2508.15568v4>|提出了一种无需反向传播的测试时自适应方法，通过高斯概率推理显著提升了模型在分布偏移下的鲁棒性和可扩展...|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Multi-Task Deep Learning Framework for Skin Lesion Classification, ABCDE Feature Quantification, and Evolution Simulation|多任务深度学习框架：用于皮肤病变分类、ABCDE特征量化及演化模拟|Harsha Kotla, Arun Kumar Rajasekaran, Hannah Rana|<http://arxiv.org/pdf/2510.14855v1>|提出了一种多任务深度学习框架，实现对皮肤病变的分类和ABCDE特征的量化，助力医生将机器学习诊断与临...|
|🆕 发布|Unifying Environment Perception and Route Choice Modeling for Trajectory Representation Learning|统一环境感知与路径选择建模的轨迹表示学习|Ji Cao, Yu Wang, Tongya Zheng, Zujie Ren, Canghong Jin, Gang Chen, Mingli Song|<http://arxiv.org/pdf/2510.14819v1>|整合环境感知与路径选择建模，提出PRTraj框架，有效提升轨迹表示学习性能。|
|📝 更新|High Semantic Features for the Continual Learning of Complex Emotions: a Lightweight Solution|用于复杂情绪持续学习的高语义特征：一种轻量级解决方案|Thibault Geoffroy, Gauthier Gerspacher, Lionel Prevost|<http://arxiv.org/pdf/2510.13534v2>|提出了一种基于面部肌肉运动的高语义特征学习方法，有效解决了复杂情绪识别中的连续学习问题。|
|📝 更新|DevFD: Developmental Face Forgery Detection by Learning Shared and Orthogonal LoRA Subspaces|DevFD：通过学习共享与正交LoRA子空间的发展性人脸伪造检测|Tianshuo Zhang, Li Gao, Siran Peng, Xiangyu Zhu, Zhen Lei|<http://arxiv.org/pdf/2509.19230v2>|提出了一种持续学习框架DevFD，通过分离学习真实人脸和伪造人脸的子空间，有效应对不断演变的伪造技术...|
|🆕 发布|Learning Human-Humanoid Coordination for Collaborative Object Carrying|学习人-人形机器人协同搬运的协调策略|Yushi Du, Yixuan Li, Baoxiong Jia, Yutang Lin, Pei Zhou, Wei Liang, Yanchao Yang, Siyuan Huang|<http://arxiv.org/pdf/2510.14293v1>|提出了一种仅依赖本体感知的强化学习方法，实现人与机器人协作搬运的平衡与高效。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks|RDD：基于检索的演示分解器，用于长周期任务中的规划器对齐|Mingxuan Yan, Yuping Wang, Zechun Liu, Jiachen Li|<http://arxiv.org/pdf/2510.14968v1>|提出了一种自动将长周期任务分解为子任务的RDD方法，通过视觉特征对齐提升任务性能。|


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SGAligner++: Cross-Modal Language-Aided 3D Scene Graph Alignment|SGAligner++：跨模态语言辅助三维场景图对齐|Binod Singh, Sayan Deb Sarkar, Iro Armeni|<http://arxiv.org/pdf/2509.20401v2>|提出了一种跨模态、语言辅助的3D场景图对齐框架，有效处理部分重叠和噪声环境下的场景对齐问题。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ChangingGrounding: 3D Visual Grounding in Changing Scenes|变化的视觉定位：动态场景中的三维视觉定位|Miao Hu, Zhiwei Huang, Tai Wang, Jiangmiao Pang, Dahua Lin, Nanning Zheng, Runsen Xu|<http://arxiv.org/pdf/2510.14965v1>|[代码](https://hm123450.github.io/CGB); 提出了一种记忆驱动的3D视觉定位方法，有效应对动态场景中的物体定位挑战。|
|🆕 发布|Exploring Cross-Modal Flows for Few-Shot Learning|探索跨模态流以实现少样本学习|Ziqi Jiang, Yanghao Wang, Long Chen|<http://arxiv.org/pdf/2510.14543v1>|提出了一种多步骤调整的跨模态学习策略，有效解决了复杂数据集中模态特征纠缠问题。|
|📝 更新|Training-Free Personalization via Retrieval and Reasoning on Fingerprints|通过指纹检索和推理的无训练个性化|Deepayan Das, Davide Talon, Yiming Wang, Massimiliano Mancini, Elisa Ricci|<http://arxiv.org/pdf/2503.18623v2>|首次提出无需训练的个人化方法R2P，通过检索和推理指纹特征实现视觉语言模型的个性化理解。|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|The Mechanistic Emergence of Symbol Grounding in Language Models|语言模型中符号接地机制的出现过程|Shuyu Wu, Ziqiao Ma, Xiaoxi Luo, Yidong Huang, Josue Torres-Fonseca, Freda Shi, Joyce Chai|<http://arxiv.org/pdf/2510.13796v2>|提出了一种评价框架，揭示了语言模型内部如何通过注意力机制实现符号的机制性接地。|


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CoT-PL: Visual Chain-of-Thought Reasoning Meets Pseudo-Labeling for Open-Vocabulary Object Detection|CoT-PL：视觉链式思维推理与伪标签标注相遇的开词汇对象检测|Hojun Choi, Youngsun Lim, Jaeyo Shin, Hyunjung Shim|<http://arxiv.org/pdf/2510.14792v1>|引入视觉链式思维推理与伪标签结合框架，提升开放词汇目标检测在复杂场景下的鲁棒性。|
|🆕 发布|MoCom: Motion-based Inter-MAV Visual Communication Using Event Vision and Spiking Neural Networks|基于事件视觉和尖峰神经网络的多微型飞行器间运动驱动的视觉通信方法（MoCom）|Zhang Nengbo, Hann Woei Ho, Ye Zhou|<http://arxiv.org/pdf/2510.14770v1>|提出了一种基于视觉运动信号和脉冲神经网络的新型 MAV 群体通信方法，以解决无线电通信的局限性。|
|🆕 发布|VTimeCoT: Thinking by Drawing for Video Temporal Grounding and Reasoning|VTimeCoT：绘制思考法实现视频时间定位与推理|Jinglei Zhang, Yuanfan Guo, Rolandos Alexandros Potamias, Jiankang Deng, Hang Xu, Chao Ma|<http://arxiv.org/pdf/2510.14672v1>|提出VTimeCoT框架，通过模拟人类使用进度条理解视频，提升视频时序定位与推理性能。|
|📝 更新|SCENEFORGE: Enhancing 3D-text alignment with Structured Scene Compositions|SCENEFORGE：利用结构化场景组合增强三维文本对齐|Cristian Sbrolli, Matteo Matteucci|<http://arxiv.org/pdf/2509.15693v2>|通过构建具有明确空间关系的多对象场景，SceneForge增强了3D点云与文本的对齐，有效解决了大规...|
|🆕 发布|Knowledge-based Visual Question Answer with Multimodal Processing, Retrieval and Filtering|基于知识的视觉问答：多模态处理、检索与过滤|Yuyang Hong, Jiaqi Gu, Qi Yang, Lubin Fan, Yue Wu, Ying Wang, Kun Ding, Shiming Xiang .etc.|<http://arxiv.org/pdf/2510.14605v1>|[代码](https://github.com/cqu-student/Wiki-PRF); 提出三阶段Wiki-PRF方法，结合视觉工具提取信息和强化学习优化知识检索，显著提升KB-VQA任务...|
|📝 更新|Catching the Details: Self-Distilled RoI Predictors for Fine-Grained MLLM Perception|捕捉细节：用于细粒度多模态感知的自蒸馏区域预测器|Yuheng Shi, Xiaohuan Pei, Minjing Dong, Chang Xu|<http://arxiv.org/pdf/2509.16944v2>|[代码](https://github.com/YuHengsss/SD-RPN.); 提出了一种无需标注数据的高效自蒸馏区域提议网络，通过优化注意力图显著提升了多模态大语言模型对细节的感...|
|🆕 发布|Exploring Image Representation with Decoupled Classical Visual Descriptors|探索解耦经典视觉描述符的图像表示|Chenyuan Qu, Hao Chen, Jianbo Jiao|<http://arxiv.org/pdf/2510.14536v1>|提出了一种将图像分解为独立经典视觉描述符的VisualSplit框架，增强了视觉任务的解释性和属性控...|
|📝 更新|From Easy to Hard: The MIR Benchmark for Progressive Interleaved Multi-Image Reasoning|从易到难：MIR逐步交织多图像推理基准|Hang Du, Jiayang Zhang, Guoshun Nan, Wendi Deng, Zhenyan Chen, Chenyang Zhang, Wang Xiao, Shan Huang .etc.|<http://arxiv.org/pdf/2509.17040v2>|提出了MIR基准，通过“由易到难”的学习策略，显著提升了多模态大语言模型处理多图像交错文本推理任务的...|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Talking Points: Describing and Localizing Pixels|谈话要点：描述和定位像素|Matan Rusanovsky, Shimon Malnick, Shai Avidan|<http://arxiv.org/pdf/2510.14583v1>|[代码](https://github.com/matanr/Talking_Points.); 提出了一种像素级关键点描述与定位框架，通过自然语言实现精确的关键点理解与定位。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Where are the Whales: A Human-in-the-loop Detection Method for Identifying Whales in High-resolution Satellite Imagery|《在哪里：一种结合人工参与的检测方法用于高分辨率卫星图像中识别鲸鱼》|Caleb Robinson, Kimberly T. Goetz, Christin B. Khan, Meredith Sackett, Kathleen Leonard, Rahul Dodhia, Juan M. Lavista Ferres|<http://arxiv.org/pdf/2510.14709v1>|[代码](https://github.com/microsoft/whales.); 提出了一种半自动化鲸鱼检测方法，通过统计异常检测减少专家工作量，实现高效卫星图像监测。|
|🆕 发布|WeCKD: Weakly-supervised Chained Distillation Network for Efficient Multimodal Medical Imaging|弱监督链式蒸馏网络WeCKD：用于高效多模态医学成像|Md. Abdur Rahman, Mohaimenul Azam Khan Raiaan, Sami Azam, Asif Karim, Jemima Beissbarth, Amanda Leach|<http://arxiv.org/pdf/2510.14668v1>|提出了一种弱监督链式知识蒸馏网络WeCKD，通过连续模型链优化知识传递，有效提升少量数据下的医学影像...|
|🆕 发布|Acquisition of interpretable domain information during brain MR image harmonization for content-based image retrieval|在脑部磁共振图像 harmonization 过程中获取可解释的域信息以支持基于内容的图像检索|Keima Abe, Hayato Muraki, Shuhei Tomoshige, Kenichi Oishi, Hitoshi Iyatomi|<http://arxiv.org/pdf/2510.14535v1>|提出PL-SE-ADA框架，实现脑部MR图像域 harmonization及疾病相关信息保持的可解释...|
|🆕 发布|Grazing Detection using Deep Learning and Sentinel-2 Time Series Data|使用深度学习和Sentinel-2时间序列数据进行的放牧检测|Aleksis Pirinen, Delia Fano Yela, Smita Chakraborty, Erik Källman|<http://arxiv.org/pdf/2510.14493v1>|利用深度学习和Sentinel-2时序数据实现季节性放牧监测，提高土地用途合规检查效率。|
|📝 更新|TinyDef-DETR: A Transformer-Based Framework for Defect Detection in Transmission Lines from UAV Imagery|基于Transformer的无人机影像输电线路缺陷检测框架：TinyDef-DETR|Feng Shen, Jiaming Cui, Wenqiang Li, Shuai Zhou|<http://arxiv.org/pdf/2509.06035v7>|提出TinyDef-DETR框架，通过增强边界敏感性和多尺度注意力机制，有效检测输电线路中的微小缺陷...|
|🆕 发布|Reinforcement Learning for Unsupervised Domain Adaptation in Spatio-Temporal Echocardiography Segmentation|强化学习在时空超声心动图分割的无监督领域自适应中的应用|Arnaud Judge, Nicolas Duchateau, Thierry Judge, Roman A. Sandler, Joseph Z. Sokol, Christian Desrosiers, Olivier Bernard, Pierre-Marc Jodoin|<http://arxiv.org/pdf/2510.14244v1>|[代码](https://github.com/arnaudjudge/RL4Seg3D.); 提出了一种基于强化学习的无监督域自适应框架，用于提高心脏超声图像分割的准确性、解剖有效性和时间一致性...|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|WorldSplat: Gaussian-Centric Feed-Forward 4D Scene Generation for Autonomous Driving|世界散点：高斯中心化的前馈4D场景生成方法用于自动驾驶|Ziyue Zhu, Zhanqian Wu, Zhenxin Zhu, Lijun Zhou, Haiyang Sun, Bing Wan, Kun Ma, Guang Chen .etc.|<http://arxiv.org/pdf/2509.23402v2>|[代码](https://wm-research.github.io/worldsplat); 提出了一种4D场景生成框架WorldSplat，通过结合4D感知模型和视频扩散模型，实现了高质量的多...|
|🆕 发布|PIA: Deepfake Detection Using Phoneme-Temporal and Identity-Dynamic Analysis|PIA：基于音素时序和身份动态分析的深度伪造检测|Soumyya Kanti Datta, Tanvi Ranga, Chengzhe Sun, Siwei Lyu|<http://arxiv.org/pdf/2510.14241v1>|[代码](https://github.com/skrantidatta/PIA); 提出了一种多模态音频-视觉框架PIA，通过融合语言、动态面部运动和面部识别线索，有效检测现代深度伪造...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Real-Time Surgical Instrument Defect Detection via Non-Destructive Testing|通过无损检测实现实时手术器械缺陷检测|Qurrat Ul Ain, Atif Aftab Ahmed Jilani, Zunaira Shafqat, Nigar Azhar Butt|<http://arxiv.org/pdf/2510.14525v1>|提出SurgScan，一种基于YOLOv8的实时手术器械缺陷检测框架，提高质量控制准确性和效率。|
|📝 更新|Incomplete Multimodal Industrial Anomaly Detection via Cross-Modal Distillation|通过跨模态蒸馏的不完整多模态工业异常检测|Wenbo Sui, Daniel Lichau, Josselin Lefèvre, Harold Phelippeau|<http://arxiv.org/pdf/2405.13571v4>|提出了一种多模态工业异常检测的跨模态蒸馏框架，实现了在训练时利用多模态数据、在推理时处理不完整模态信...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Mapping Farmed Landscapes from Remote Sensing|从遥感数据映射农田景观|Michelangelo Conserva, Alex Wilson, Charlotte Stanton, Vishal Batchu, Varun Gulshan|<http://arxiv.org/pdf/2506.13993v2>|首次创建覆盖英格兰大部分地区的高分辨率农村景观特征图，使用深度学习模型精确识别关键生态元素。|
|📝 更新|TopoStreamer: Temporal Lane Segment Topology Reasoning in Autonomous Driving|"TopoStreamer：自动驾驶中的车道段落拓扑推理时序分析"|Yiming Yang, Yueru Luo, Bingkun He, Hongbin Lin, Suzhong Fu, Chao Zheng, Zhipeng Cao, Erlong Li .etc.|<http://arxiv.org/pdf/2507.00709v3>|提出TopoStreamer模型，通过动态位置编码和属性约束改进自动驾驶中的车道拓扑推理，提升感知准...|
|📝 更新|TinyRS-R1: Compact Multimodal Language Model for Remote Sensing|TinyRS-R1：用于遥感的小型多模态语言模型|Aybora Koksal, A. Aydin Alatan|<http://arxiv.org/pdf/2505.12099v2>|首次提出针对遥感优化的2B参数小型多模态语言模型TinyRS及其推理增强版本TinyRS-R1，实现...|
|📝 更新|CVD-STORM: Cross-View Video Diffusion with Spatial-Temporal Reconstruction Model for Autonomous Driving|交叉视图视频扩散与时空重建模型CVD-STORM：面向自动驾驶的应用|Tianrui Zhang, Yichen Liu, Zilin Guo, Yuxin Guo, Jingcheng Ni, Chenjing Ding, Dan Xu, Lewei Lu .etc.|<http://arxiv.org/pdf/2510.07944v2>|[代码](https://sensetime-fvg.github.io/CVD-STORM.); 提出了一种生成多视角、长期视频的4D重建方法CVD-STORM，通过时空重建VAE显著提升了视频生成...|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|BoardVision: Deployment-ready and Robust Motherboard Defect Detection with YOLO+Faster-RCNN Ensemble|板视觉：部署就绪且稳健的主板缺陷检测，采用YOLO与Faster-RCNN集成方法|Brandon Hill, Kma Solaiman|<http://arxiv.org/pdf/2510.14389v1>|提出BoardVision框架，通过YOLO和Faster-RCNN集成及轻量级投票机制，提升主板装...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vision Mamba for Permeability Prediction of Porous Media|孔隙介质渗透率预测的Vision Mamba方法|Ali Kashefi, Tapan Mukerji|<http://arxiv.org/pdf/2510.14516v1>|首次将Vision Mamba应用于预测三维多孔介质的渗透性，提升了计算和内存效率。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Multi-level Reliable Guidance for Unpaired Multi-view Clustering|多级别可靠引导的无配对多视角聚类|Like Xin, Wanqi Yang, Lei Wang, Ming Yang|<http://arxiv.org/pdf/2407.01247v3>|提出了一种多级可靠引导方法MRG-UMC，通过跨视图一致性学习，有效提升了无配对多视角聚类的一致性和...|
|🆕 发布|Experimental Demonstration of Event-based Optical Camera Communication in Long-Range Outdoor Environment|基于事件的室外长距离光相机通信实验演示|Miu Sumino, Mayu Ishii, Shun Kaizu, Daisuke Hisano, Yu Nakayama|<http://arxiv.org/pdf/2510.14266v1>|首次实现了在户外环境中，基于事件视觉传感器的光相机通信系统，通过结合OOK和toggle解调以及数字...|
|🆕 发布|Event Interval Modulation: A Novel Scheme for Event-based Optical Camera Communication|事件间隔调制：一种基于事件的 optical 相机通信新方案|Miu Sumino, Mayu Ishii, Shun Kaizu, Daisuke Hisano, Yu Nakayama|<http://arxiv.org/pdf/2510.14245v1>|提出事件间隔调制方案，提升基于事件的光学相机通信传输速度和距离。|
|🆕 发布|Leveraging Cycle-Consistent Anchor Points for Self-Supervised RGB-D Registration|利用循环一致性锚点进行自监督RGB-D配准|Siddharth Tourani, Jayaram Reddy, Sarvesh Thakur, K Madhava Krishna, Muhammad Haris Khan, N Dinesh Reddy|<http://arxiv.org/pdf/2510.14354v1>|利用循环一致性关键点增强匹配精度，提出结合GRU和变换同步的姿姿块，提升自监督RGB-D配准性能。|

