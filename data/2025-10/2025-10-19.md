## [UPDATED!] **2025-10-19** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|How Universal Are SAM2 Features?|SAM2特征通用性如何？|Masoud Khairi Atani, Alon Harell, Hyomin Choi, Runyu Yang, Fabien Racape, Ivan V. Bajic|<http://arxiv.org/pdf/2510.17051v1>|比较通用视觉模型与专用模型特征通用性，发现专用模型在相关任务上表现优异但牺牲了语义信息广泛性。|
|🆕 发布|Enrich and Detect: Video Temporal Grounding with Multimodal LLMs|丰富与检测：基于多模态大型语言模型的视频时间定位|Shraman Pramanick, Effrosyni Mavroudi, Yale Song, Rama Chellappa, Lorenzo Torresani, Triantafyllos Afouras|<http://arxiv.org/pdf/2510.17023v1>|提出了一种两阶段视频时间定位方法，利用多模态大语言模型增强查询，实现精准的时序定位。|
|🆕 发布|Segmentation as A Plug-and-Play Capability for Frozen Multimodal LLMs|"将分割作为冻结多模态大型语言模型的即插即用功能"|Jiazhen Liu, Long Chen|<http://arxiv.org/pdf/2510.16785v1>|提出LENS方法，通过在不冻结的多模态大语言模型上附加轻量级头部，实现高效图像分割同时保持模型泛化能...|
|📝 更新|FetalCLIP: A Visual-Language Foundation Model for Fetal Ultrasound Image Analysis|胎儿CLIP：用于胎儿超声图像分析的可视化-语言基础模型|Fadillah Maani, Numan Saeed, Tausifa Saleem, Zaid Farooq, Hussain Alasmawi, Werner Diehl, Ameera Mohammad, Gareth Waring .etc.|<http://arxiv.org/pdf/2502.14807v3>|提出了FetalCLIP模型，通过大规模图像和文本数据预训练，有效提升胎儿超声图像分析性能。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DINO-CVA: A Multimodal Goal-Conditioned Vision-to-Action Model for Autonomous Catheter Navigation|DINO-CVA：一种用于自主导管导航的多模态目标条件视觉至动作模型|Pedram Fekri, Majid Roshanfar, Samuel Barbeau, Seyedfarzad Famouri, Thomas Looi, Dale Podolsky, Mehrdad Zadeh, Javad Dargahi|<http://arxiv.org/pdf/2510.17038v1>|提出了一种多模态目标条件视觉至动作模型DINO-CVA，实现自主导管导航，减少人工操作依赖。|
|📝 更新|Efficient Long-duration Talking Video Synthesis with Linear Diffusion Transformer under Multimodal Guidance|基于多模态引导的线性扩散变换器实现的长时间对话视频高效合成|Haojie Zhang, Zhihao Liang, Ruibo Fu, Bingyan Liu, Zhengqi Wen, Xuefei Liu, Jianhua Tao, Yaling Liang|<http://arxiv.org/pdf/2411.16748v4>|提出了一种结合多模态指导和记忆机制的扩散变换框架，实现了高效、高质量的长时对话视频生成。|
|🆕 发布|Beyond RGB: Leveraging Vision Transformers for Thermal Weapon Segmentation|超越RGB：利用视觉变换器进行热成像武器分割|Akhila Kambhatla, Ahmed R Khaled|<http://arxiv.org/pdf/2510.16913v1>|利用Vision Transformers进行热成像武器分割，显著提升低光和视线受阻环境下的检测性能...|
|🆕 发布|ArmFormer: Lightweight Transformer Architecture for Real-Time Multi-Class Weapon Segmentation and Classification|ArmFormer：面向实时多类武器分割与分类的轻量级Transformer架构|Akhila Kambhatla, Taminul Islam, Khaled R Ahmed|<http://arxiv.org/pdf/2510.16854v1>|提出ArmFormer，一种轻量级Transformer架构，实现实时多类武器精细分割与分类。|
|📝 更新|AutoLungDx: A Hybrid Deep Learning Approach for Early Lung Cancer Diagnosis Using 3D Res-U-Net, YOLOv5, and Vision Transformers|自动肺诊断系统：基于3D Res-U-Net、YOLOv5和视觉变换器的混合深度学习方法用于早期肺癌诊断|Samiul Based Shuvo, Tasnia Binte Mamun|<http://arxiv.org/pdf/2305.00046v4>|提出了一种适用于资源匮乏环境的自动化深度学习框架，通过3D Res-U-Net、YOLOv5和Vis...|
|🆕 发布|EMRRG: Efficient Fine-Tuning Pre-trained X-ray Mamba Networks for Radiology Report Generation|EMRRG：高效微调预训练X射线蟒蛇网络以生成放射学报告|Mingzheng Zhang, Jinfeng Gao, Dan Xu, Jiangrui Yu, Yuhan Qiao, Lan Chen, Jin Tang, Xiao Wang|<http://arxiv.org/pdf/2510.16776v1>|[代码](https://github.com/Event-AHU/Medical_Image_Analysis.); 提出了一种高效微调预训练X射线Mamba网络的医学报告生成框架，通过参数高效方法显著提升X射线图像的...|
|📝 更新|Multimodal Fusion at Three Tiers: Physics-Driven Data Generation and Vision-Language Guidance for Brain Tumor Segmentation|三级多模态融合：基于物理的数据生成与视觉-语言引导的脑肿瘤分割|Mingda Zhang|<http://arxiv.org/pdf/2507.09966v3>|提出三层次多模态融合框架，通过物理建模、跨模态特征融合和语义引导，实现了精确的脑肿瘤分割。|
|🆕 发布|UKANFormer: Noise-Robust Semantic Segmentation for Coral Reef Mapping via a Kolmogorov-Arnold Network-Transformer Hybrid|UKANFormer：基于科尔莫哥洛夫-阿尔诺德网络-变压器混合模型的噪声稳健型珊瑚礁映射语义分割|Tianyang Dou, Ming Li, Jiangying Qin, Xuan Liao, Jiageng Zhong, Armin Gruen, Mengyi Deng|<http://arxiv.org/pdf/2510.16730v1>|提出UKANFormer模型，通过全局-局部Transformer结构提升噪声环境下珊瑚礁精细映射的...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GeoReasoner: Geo-localization with Reasoning in Street Views using a Large Vision-Language Model|地理推理器：利用大规模视觉语言模型在街景中进行地理定位与推理|Ling Li, Yu Ye, Yao Zhou, Wei Zeng|<http://arxiv.org/pdf/2406.18572v3>|[代码](https://github.com/lingli1996/GeoReasoner.); 利用大型视觉语言模型和人类推理知识，GeoReasoner在街景图像地理定位任务上实现了显著性能提升...|
|🆕 发布|Res-Bench: Benchmarking the Robustness of Multimodal Large Language Models to Dynamic Resolution Input|动态分辨率输入下多模态大型语言模型鲁棒性的基准测试：Res-Bench|Chenxu Li, Zhicai Wang, Yuan Sheng, Xingyu Zhu, Yanbin Hao, Xiang Wang|<http://arxiv.org/pdf/2510.16926v1>|提出Res-Bench基准，评估多模态大语言模型在不同分辨率输入下的稳定性，引入新的鲁棒性度量指标。|
|📝 更新|Dolphin v1.0 Technical Report|海豚v1.0技术报告|Taohan Weng, Kaibing Hu, Henan Liu, Siya Liu, Xiaoyang Liu, Zhenyu Liu, Jiren Ren, Boyan Wang .etc.|<http://arxiv.org/pdf/2509.25748v3>|首次提出大规模多模态超声基础模型，统一多种临床任务，并通过三阶段训练提升诊断准确性。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Robust Pan-Cancer Mitotic Figure Detection with YOLOv12|基于YOLOv12的泛癌有丝分裂图像稳健检测|Raphaël Bourgade, Guillaume Balezo, Hana Feki, Lily Monier, Matthieu Blons, Alice Blondel, Delphine Loussouarn, Anne Vincent-Salomon .etc.|<http://arxiv.org/pdf/2509.02593v4>|提出了一种基于YOLOv12架构的稳健性癌细胞分裂图像检测方法，提升了检测准确度并减少了观察者间的差...|
|📝 更新|Mysteries of the Deep: Role of Intermediate Representations in Out of Distribution Detection|《深不可测：中间表示在分布外检测中的作用》|I. M. De la Jara, C. Rodriguez-Opazo, D. Teney, D. Ranasinghe, E. Abbasnejad|<http://arxiv.org/pdf/2510.05782v2>|发现了预训练模型中间层在分布外检测中的价值，提出了一种自动识别最有信息量层的方法。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CARE: Contrastive Alignment for ADL Recognition from Event-Triggered Sensor Streams|CARE: 事件触发传感器流的自适应对比对齐用于日常活动识别|Junhao Zhao, Zishuai Liu, Ruili Fang, Jin Lu, Linghan Zhang, Fei Dou|<http://arxiv.org/pdf/2510.16988v1>|提出了一种结合序列与图像表征的ADL识别框架，通过对比对齐学习提升了智能家居日常活动识别的准确性和鲁...|
|🆕 发布|An RGB-D Image Dataset for Lychee Detection and Maturity Classification for Robotic Harvesting|荔枝检测与成熟度分类的RGB-D图像数据集用于机器人采摘|Zhenpeng Zhang, Yi Wang, Shanglei Chai, Yingying Liu, Zekai Xie, Wenhao Huang, Pengyu Li, Zipei Luo .etc.|<http://arxiv.org/pdf/2510.16800v1>|构建了一个包含11,414张图像的RGB-D数据集，用于荔枝检测与成熟度分类，助力视觉采摘机器人研发...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GS2POSE: Marry Gaussian Splatting to 6D Object Pose Estimation|GS2POSE：将高斯散布与六自由度物体姿态估计相结合|Junbo Li, Weimin Yuan, Yinuo Wang, Yue Zeng, Shihao Shu, Cai Meng, Xiangzhi Bai|<http://arxiv.org/pdf/2510.16777v1>|提出了一种基于高斯散布和迭代优化的6D物体姿态估计方法，提高了对无纹理物体和变化光照条件的适应性。|
|📝 更新|GMatch: A Lightweight, Geometry-Constrained Keypoint Matcher for Zero-Shot 6DoF Pose Estimation in Robotic Grasp Tasks|GMatch：一种用于机器人抓取任务中零样本六自由度位姿估计的轻量级、几何约束关键点匹配器|Ming Yang, Haoran Li|<http://arxiv.org/pdf/2505.16144v2>|提出了一种轻量级、基于几何约束的关键点匹配方法GMatch，适用于资源受限的机器人系统进行高效的六自...|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Person Re-Identification via Generalized Class Prototypes|通过广义类原型进行行人重识别|Md Ahmed Al Muzaddid, William J. Beksi|<http://arxiv.org/pdf/2510.17043v1>|提出了一种选择更优类别代表的方法，通过平衡准确性和平均精度，显著提升了行人重识别性能。|
|📝 更新|Consistent Story Generation: Unlocking the Potential of Zigzag Sampling|一致故事生成：解锁之字形采样的潜力|Mingxiao Li, Mang Ning, Marie-Francine Moens|<http://arxiv.org/pdf/2506.09612v4>|[代码](https://github.com/Mingxiao-Li/Asymmetry-Zigzag-StoryDiffusion.); 提出了一种无训练的Zigzag采样策略，通过交替使用非对称提示和视觉共享机制，显著提升了视觉故事生成...|
|🆕 发布|Xiaoice: Training-Free Video Understanding via Self-Supervised Spatio-Temporal Clustering of Semantic Features|小冰：通过自监督时空聚类语义特征的无训练视频理解|Shihao Ji, Zihui Song|<http://arxiv.org/pdf/2510.16781v1>|提出了一种无需训练的零样本视频理解框架，通过自监督时空聚类预训练视觉语言模型的语义特征实现视频内容自...|
|📝 更新|STANCE: Motion Coherent Video Generation Via Sparse-to-Dense Anchored Encoding|STANCE：通过稀疏到密集锚定编码实现运动连贯的视频生成|Zhifei Chen, Tianshuo Xu, Leyi Wu, Luozhou Wang, Dongyu Yan, Zihan You, Wenting Luo, Guo Zhang .etc.|<http://arxiv.org/pdf/2510.14588v2>|提出STANCE框架，通过实例提示和密集旋转位置编码增强视频生成中的运动连贯性。|
|🆕 发布|HumanCM: One Step Human Motion Prediction|人类CM：一步预测人体运动|Liu Haojie, Gao Suixiang|<http://arxiv.org/pdf/2510.16709v1>|提出了一种基于一致性模型的一步人类运动预测框架，大幅减少了推理步骤同时保持或超越现有模型的准确性。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Generate, but Verify: Reducing Hallucination in Vision-Language Models with Retrospective Resampling|“生成，但要验证：通过回顾性重采样减少视觉语言模型中的幻觉现象”|Tsung-Han Wu, Heekyung Lee, Jiaxin Ge, Joseph E. Gonzalez, Trevor Darrell, David M. Chan|<http://arxiv.org/pdf/2504.13169v3>|提出REVERSE框架，结合视觉语言模型中的幻觉检测与动态修正，有效减少视觉幻觉问题。|
|🆕 发布|Conditional Synthetic Live and Spoof Fingerprint Generation|条件合成实时与仿造指纹生成|Syed Konain Abbas, Sandip Purnapatra, M. G. Sarwar Murshed, Conor Miller-Lynch, Lambert Igene, Soumyabrata Dey, Stephanie Schuckers, Faraz Hussain|<http://arxiv.org/pdf/2510.17035v1>|提出了一种生成高分辨率合成指纹的方法，利用生成模型解决隐私、成本和生物识别数据获取难题。|
|📝 更新|Is Artificial Intelligence Generated Image Detection a Solved Problem?|人工智能生成图像检测问题是否已解决？|Ziqiang Li, Jiazhen Yan, Ziwen He, Kai Zeng, Weiwei Jiang, Lizhi Xiong, Zhangjie Fu|<http://arxiv.org/pdf/2505.12335v2>|[代码](https://github.com/HorizonTEL/AIGIBench.); 提出AIGIBench基准，揭示了现有AI生成图像检测器在真实世界数据上的性能不足。|
|🆕 发布|From Mannequin to Human: A Pose-Aware and Identity-Preserving Video Generation Framework for Lifelike Clothing Display|从模特到真人：一种用于逼真服装展示的姿态感知与身份保持视频生成框架|Xiangyu Mu, Dongliang Zhou, Jie Hou, Haijun Zhang, Weili Guan|<http://arxiv.org/pdf/2510.16833v1>|提出了一种生成逼真人类视频的框架，通过融合身体姿态和面部语义解决模特展示的非真实感和身份漂移问题。|
|📝 更新|Text-controlled Motion Mamba: Text-Instructed Temporal Grounding of Human Motion|文本控制的运动眼镜蛇：基于文本指令的人类运动时间定位|Xinghan Wang, Zixi Kang, Yadong Mu|<http://arxiv.org/pdf/2404.11375v2>|提出文本控制的人体运动定位任务，并设计了一种高效模型以精确定位文本描述对应的运动时间片段。|
|📝 更新|GeoCAD: Local Geometry-Controllable CAD Generation with Large Language Models|地理CAD：基于大型语言模型的局部几何可控计算机辅助设计生成|Zhanwei Zhang, Kaiyuan Liu, Junjie Liu, Wenxiao Wang, Binbin Lin, Liang Xie, Chen Shen, Deng Cai|<http://arxiv.org/pdf/2506.10337v2>|[代码](https://github.com/Zhanwei-Z/GeoCAD.); 提出GeoCAD方法，通过大语言模型实现局部几何可控的CAD生成，遵循用户指定的几何指令。|
|📝 更新|Exploring the Limits of Vision-Language-Action Manipulations in Cross-task Generalization|探索跨任务泛化中视觉-语言-动作操作的限制|Jiaming Zhou, Ke Ye, Jiayi Liu, Teli Ma, Zifan Wang, Ronghe Qiu, Kun-Yu Lin, Zhilin Zhao .etc.|<http://arxiv.org/pdf/2505.15660v3>|提出AGNOSTOS基准和X-ICM方法，提升视觉语言行动模型在跨任务零样本泛化中的表现。|
|🆕 发布|Region in Context: Text-condition Image editing with Human-like semantic reasoning|《区域上下文：基于类人语义推理的文本条件图像编辑》|Thuy Phuong Vu, Dinh-Cuong Hoang, Minhhuy Le, Phan Xuan Tan|<http://arxiv.org/pdf/2510.16772v1>|[代码](https://github.com/thuyvuphuong/Region-in-Context.git); 提出了一种结合全局视觉与文本理解的图像编辑框架，实现了更和谐且符合指令的局部编辑效果。|
|🆕 发布|Filtering of Small Components for Isosurface Generation|小部件过滤用于等值面生成|Devin Zhao, Rephael Wenger|<http://arxiv.org/pdf/2510.16684v1>|提出了一种简单预滤波方法，有效移除扫描数据中不影响主体可视化的微小组件。|
|📝 更新|Free$^2$Guide: Training-Free Text-to-Video Alignment using Image LVLM|无需训练的文本到视频对齐：使用图像大型语言模型的方法|Jaemin Kim, Bryan Sangwoo Kim, Jong Chul Ye|<http://arxiv.org/pdf/2411.17041v2>|[代码](https://kjm981995.github.io/free2guide); 提出了一种无需训练的Free$^2$Guide框架，利用大型视觉语言模型提升文本与视频的准确对齐。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|An empirical study of the effect of video encoders on Temporal Video Grounding|视频编码器对时间视频定位影响的实证研究|Ignacio M. De la Jara, Cristian Rodriguez-Opazo, Edison Marrese-Taylor, Felipe Bravo-Marquez|<http://arxiv.org/pdf/2510.17007v1>|研究了不同视频编码器对时间视频定位任务的影响，揭示了特征互补性对模型性能的关键作用。|
|🆕 发布|Do Satellite Tasks Need Special Pretraining?|卫星任务需要特殊的预训练吗？|Ani Vanyan, Alvard Barseghyan, Hakob Tamazyan, Tigran Galstyan, Vahan Huroyan, Naira Hovakimyan, Hrant Khachatrian|<http://arxiv.org/pdf/2510.17014v1>|挑战了特定卫星图像基础模型优于通用视觉基础模型的观念，提出iBOT模型在小型规模上表现不优于通用模型...|
|🆕 发布|One-step Diffusion Models with Bregman Density Ratio Matching|一步扩散模型与Bregman密度比匹配|Yuanzhi Zhu, Eleftherios Tsonis, Lucas Degeorge, Vicky Kalogeiton|<http://arxiv.org/pdf/2510.16983v1>|提出了一种基于Bregman散度的密度比匹配框架Di-Bregman，实现了高效的一步扩散模型训练。|
|🆕 发布|Contrail-to-Flight Attribution Using Ground Visible Cameras and Flight Surveillance Data|利用地面可见相机和飞行监控数据进行航线到飞行归因|Ramon Dalmau, Gabriel Jarry, Philippe Very|<http://arxiv.org/pdf/2510.16891v1>|提出了一种基于地面可见相机和飞行监控数据，将观测到的凝结尾迹与其生成航班关联的模块化框架。|
|🆕 发布|Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback|Uniworld-V2：使用扩散负向感知微调与MLLM隐式反馈强化图像编辑|Zongjian Li, Zheyuan Liu, Qihui Zhang, Bin Lin, Shenghai Yuan, Zhiyuan Yan, Yang Ye, Wangbo Yu .etc.|<http://arxiv.org/pdf/2510.16888v1>|[代码](https://github.com/PKU-YuanGroup/UniWorld-V2.); 提出了Edit-R1框架，通过扩散负样本感知微调和大型语言模型隐式反馈，提升了图像编辑的泛化能力和性...|
|🆕 发布|Visual Autoregressive Models Beat Diffusion Models on Inference Time Scaling|视觉自回归模型在推理时间缩放上超越扩散模型|Erik Riise, Mehmet Onurcan Kaya, Dim P. Papadopoulos|<http://arxiv.org/pdf/2510.16751v1>|证明了视觉自回归模型通过搜索策略在推理时间扩展上优于扩散模型。|
|📝 更新|Eye-for-an-eye: Appearance Transfer with Semantic Correspondence in Diffusion Models|《以眼还眼：在扩散模型中基于语义对应的外观转换》|Sooyeon Go, Kyungmook Choi, Minjung Shin, Youngjung Uh|<http://arxiv.org/pdf/2406.07008v2>|提出了一种基于密集语义对应关系的无训练外观转换方法，有效保持了目标图像结构并准确反映参考图像颜色。|
|🆕 发布|Prominence-Aware Artifact Detection and Dataset for Image Super-Resolution|显眼性感知的图像超分辨率重建中的伪影检测与数据集|Ivan Molodetskikh, Kirill Malyshev, Mark Mirgaleev, Nikita Zagainov, Evgeney Bogatyrev, Dmitriy Vatolin|<http://arxiv.org/pdf/2510.16752v1>|提出了一种基于人类视觉感知的显著度评分的图像超分辨率瑕疵检测方法，有效区分并识别出影响视觉质量的显著...|
|🆕 发布|A Comprehensive Survey on World Models for Embodied AI|《关于Embodied AI的World Models的全面综述》|Xinqing Li, Xin He, Le Zhang, Yun Liu|<http://arxiv.org/pdf/2510.16732v1>|[代码](https://github.com/Li-Zn-H/AwesomeWorldModels.); 系统化梳理了Embodied AI中的世界模型，提出了功能、时间建模和空间表示的分类框架。|
|🆕 发布|WaMaIR: Image Restoration via Multiscale Wavelet Convolutions and Mamba-based Channel Modeling with Texture Enhancement|瓦玛尔：通过多尺度小波卷积和基于曼巴的通道建模进行图像复原及纹理增强|Shengyu Zhu, Fan, Fuxuan Zhang|<http://arxiv.org/pdf/2510.16765v1>|提出WaMaIR框架，通过多尺度小波卷积和基于Mamba的通道建模增强图像纹理细节的恢复效果。|
|📝 更新|Jasmine: Harnessing Diffusion Prior for Self-supervised Depth Estimation|Jasmine：利用扩散先验进行自监督深度估计|Jiyuan Wang, Chunyu Lin, Cheng Guan, Lang Nie, Jing He, Haodong Li, Kang Liao, Yao Zhao|<http://arxiv.org/pdf/2503.15905v3>|提出了一种基于稳定扩散模型的自监督深度估计框架，通过混合图像重建任务和尺度位移门控单元，提升了预测的...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Towards Better & Faster Autoregressive Image Generation: From the Perspective of Entropy|面向更优更快自回归图像生成：从熵的角度出发|Xiaoxiao Ma, Feng Zhao, Pengyang Ling, Haibo Qiu, Zhixiang Wei, Hu Yu, Jie Huang, Zhixiong Zeng .etc.|<http://arxiv.org/pdf/2510.09012v2>|提出熵指导的解码策略，提升自回归图像生成质量并加快合成速度。|
|🆕 发布|Personalized Image Filter: Mastering Your Photographic Style|个性化图像滤镜：掌握你的摄影风格|Chengxuan Zhu, Shuchen Weng, Jiacong Fang, Peixuan Zhang, Si Li, Chao Xu, Boxin Shi|<http://arxiv.org/pdf/2510.16791v1>|提出个性化图像滤镜方法，通过文本提示学习并转移摄影风格，有效保留原图内容。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|2DGS-R: Revisiting the Normal Consistency Regularization in 2D Gaussian Splatting|二维高斯散点法中的法向一致性正则化再探讨|Haofan Ren, Qingsong Yan, Ming Lu, Rongfeng Lu, Zunjie Zhu|<http://arxiv.org/pdf/2510.16837v1>|提出了一种分层次训练的2DGS-R方法，通过新型克隆操作显著提升渲染质量同时保持几何精度。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ActAlign: Zero-Shot Fine-Grained Video Classification via Language-Guided Sequence Alignment|ActAlign：通过语言引导序列对齐实现的零样本细粒度视频分类|Amir Aghdam, Vincent Tao Hu, Björn Ommer|<http://arxiv.org/pdf/2506.22967v3>|提出了一种无需训练、零样本的ActAlign方法，通过语言引导的序列对齐实现极细粒度动作视频分类。|
|🆕 发布|Training-free Online Video Step Grounding|无训练在线视频步骤定位|Luca Zanella, Massimiliano Mancini, Yiming Wang, Alessio Tonioni, Elisa Ricci|<http://arxiv.org/pdf/2510.16989v1>|提出了一种无需训练的在线视频步骤定位方法，利用大型多模态模型实现了优于传统方法的性能。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Video Reasoning without Training|无训练的视频推理|Deepak Sridhar, Kartikeya Bhardwaj, Jeya Pradha Jeyaraj, Nuno Vasconcelos, Ankita Nayak, Harris Teague|<http://arxiv.org/pdf/2510.17045v1>|通过熵信号优化模型行为，提出V-Reason方法，无需训练即可显著提升视频推理性能并降低计算开销。|
|🆕 发布|Where, Not What: Compelling Video LLMs to Learn Geometric Causality for 3D-Grounding|“何地，而非何物：促使视频大型语言模型学习三维定位中的几何因果关系”|Yutong Zhong|<http://arxiv.org/pdf/2510.17034v1>|提出方法W2R2解决2D语义偏置问题，通过区分2D语义特征和3D空间特征提升3D定位准确性。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Seeing in the Dark: A Teacher-Student Framework for Dark Video Action Recognition via Knowledge Distillation and Contrastive Learning|《在黑暗中看见：通过知识蒸馏和对比学习实现暗视频行为识别的教师-学生框架》|Sharana Dharshikgan Suresh Dass, Hrishav Bakul Barua, Ganesh Krishnasamy, Raveendran Paramesran, Raphael C. -W. Phan|<http://arxiv.org/pdf/2502.03724v2>|[代码](https://github.com/HrishavBakulBarua/ActLumos); 提出了一种基于教师-学生框架的低光照视频动作识别方法，通过知识蒸馏和对比学习实现了单流推理的高精度。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Fly-CL: A Fly-Inspired Framework for Enhancing Efficient Decorrelation and Reduced Training Time in Pre-trained Model-based Continual Representation Learning|飞-CL：一种受苍蝇启发增强预训练模型基础上的连续表征学习中高效去相关性和减少训练时间的框架|Heming Zou, Yunliang Zang, Wutong Xu, Xiangyang Ji|<http://arxiv.org/pdf/2510.16877v1>|[代码](https://github.com/gfyddha/Fly-CL.); 提出了一种受蝇嗅觉电路启发的Fly-CL框架，有效减少预训练模型持续学习中的训练时间和解决特征多重共...|


### 表征知识迁移 (Representation Knowledge Transfer)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Robust Cross-Domain Adaptation in Texture Features Transferring for Wood Chip Moisture Content Prediction|木材 chips 水分含量预测中的纹理特征跨域自适应稳健迁移|Abdur Rahman, Mohammad Marufuzzaman, Jason Street, Haifeng Wang, Veera G. Gude, Randy Buchanan|<http://arxiv.org/pdf/2510.16832v1>|提出了一种域自适应方法AdaptMoist，利用纹理特征在不同木材数据源间转移知识，提高了木材湿度预...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FireANTs: Adaptive Riemannian Optimization for Multi-Scale Diffeomorphic Matching|FireANTs：自适应黎曼优化用于多尺度微分同构匹配|Rohit Jena, Pratik Chaudhari, James C. Gee|<http://arxiv.org/pdf/2404.01249v4>|提出了一种无需训练、GPU加速的多尺度自适应黎曼优化算法，实现了快速准确的密集微分同构图像匹配。|
|📝 更新|MaterialRefGS: Reflective Gaussian Splatting with Multi-view Consistent Material Inference|材料反射场：具有多视角一致性材料推理的反射高斯散点喷射|Wenyuan Zhang, Jimin Tang, Weiqi Zhang, Yi Fang, Yu-Shen Liu, Zhizhong Han|<http://arxiv.org/pdf/2510.11387v2>|提出了一种多视角一致性材料推理方法，通过改进环境建模和反射处理，实现了高质量的图像渲染效果。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Uncovering Brain-Like Hierarchical Patterns in Vision-Language Models through fMRI-Based Neural Encoding|通过基于fMRI的神经编码揭示视觉语言模型中的类脑层次模式|Yudan Ren, Xinlong Wang, Kexin Wang, Tian Xia, Zihan Ma, Zhaowei Li, Xiangrong Bi, Xiao Li .etc.|<http://arxiv.org/pdf/2510.16870v1>|提出了一种神经元级分析框架，揭示了视觉语言模型中类似人脑的多模态信息处理机制。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Limitations of Data-Driven Spectral Reconstruction -- An Optics-Aware Analysis|数据驱动光谱重建的局限性——一种光学感知分析|Qiang Fu, Matheus Souza, Eunsue Choi, Suhyun Shin, Seung-Hwan Baek, Wolfgang Heidrich|<http://arxiv.org/pdf/2401.03835v4>|[代码](https://github.com/vccimaging/OpticsAwareHSI-Analysis.); 揭示了数据驱动光谱重建方法的局限性，并探讨了利用光学编码改善性能的潜力。|
|📝 更新|Agentic Design of Compositional Machines|《组合机器的代理性设计》|Wenqian Zhang, Weiyang Liu, Zhen Liu|<http://arxiv.org/pdf/2510.14980v2>|探究大语言模型在机器设计中的应用，引入BesiegeField测试床，并通过强化学习提升模型性能。|
|🆕 发布|Pursuing Minimal Sufficiency in Spatial Reasoning|在空间推理中追求最小充分性|Yejie Guo, Yunzhong Hou, Wufei Ma, Meng Tang, Ming-Hsuan Yang|<http://arxiv.org/pdf/2510.16688v1>|[代码](https://github.com/gyj155/mssr.); 提出双代理框架MSSR，通过精选必要3D信息提升视觉语言模型的推理性能。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vision-Centric 4D Occupancy Forecasting and Planning via Implicit Residual World Models|基于视觉的4D占用预测与规划：隐式残差世界模型方法|Jianbiao Mei, Yu Yang, Xuemeng Yang, Licheng Wen, Jiajun Lv, Botian Shi, Yong Liu|<http://arxiv.org/pdf/2510.16729v1>|提出了一种隐式残差世界模型，专注于预测动态变化而非完整重构未来场景，显著提升了自动驾驶系统中的占位预...|
|📝 更新|Cutting-edge 3D reconstruction solutions for underwater coral reef images: A review and comparison|水下珊瑚礁图像的尖端三维重建解决方案：综述与比较|Jiageng Zhong, Ming Li, Armin Gruen, Konrad Schindler, Xuan Liao, Qinghua Guo|<http://arxiv.org/pdf/2502.20154v2>|系统评估了先进3D重建技术在珊瑚礁图像中的应用，为科学家提供了技术指导和实践建议。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 不确定性量化 (Uncertainty Quantification)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Beyond Uncertainty Quantification: Learning Uncertainty for Trust-Informed Neural Network Decisions - A Case Study in COVID-19 Classification|超越不确定性量化：学习不确定性以增强神经网络决策的可信度 —— 以COVID-19分类为例|Hassan Gharoun, Mohammad Sadegh Khorshidi, Fang Chen, Amir H. Gandomi|<http://arxiv.org/pdf/2410.02805v2>|提出了一种不确定性感知的神经网络框架，通过学习判断预测的可信度，减少了高置信度错误预测，提高了决策支...|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Domain Generalizable Continual Learning|领域泛化的持续学习|Hongwei Yan, Guanglong Sun, Zhiqi Kang, Yi Zhong, Liyuan Wang|<http://arxiv.org/pdf/2510.16914v1>|提出了一种适应性的域转换方法DoT，以实现跨域持续学习中的泛化性能提升。|
|🆕 发布|Connecting Domains and Contrasting Samples: A Ladder for Domain Generalization|连接域与对比样本：用于域泛化的梯子方法|Tianxin Wei, Yifan Chen, Xinrui He, Wenxuan Bao, Jingrui He|<http://arxiv.org/pdf/2510.16704v1>|[代码](https://github.com/weitianxin/DCCL); 提出了一种域连接对比学习框架，通过增强跨域连通性，有效提升了域泛化性能。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Click, Predict, Trust: Clinician-in-the-Loop AI Segmentation for Lung Cancer CT-Based Prognosis within the Knowledge-to-Action Framework|“点击、预测、信任：基于知识转化为行动框架的肺癌CT影像预后中融入临床医生的人工智能分割方法”|Mohammad R. Salmanpour, Sonya Falahati, Amir Hossein Pouria, Amin Mousavi, Somayeh Sadat Mehrnia, Morteza Alizadeh, Arman Gorji, Zeinab Farsangi .etc.|<http://arxiv.org/pdf/2510.17039v1>|本研究开发了一种结合医生参与的深度学习流程，提高了肺癌CT影像分割的准确性和临床信任度。|
|📝 更新|Hierarchical Material Recognition from Local Appearance|从局部外观进行层次化材料识别|Matthew Beveridge, Shree K. Nayar|<http://arxiv.org/pdf/2505.22911v3>|提出了一种基于图注意力网络的层次化材料识别方法，利用材料物理特性构建的taxonomy和野外数据集，...|
|📝 更新|Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering|增强骨质疏松检测：一个具有特征融合与变量聚类的可解释多模态学习框架|Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Farshid Rostami Pouria, Behzad Moshiri, Md. Jalil Piran, Oliver Faust|<http://arxiv.org/pdf/2411.00916v3>|提出了一种融合临床和影像数据的可解释多模态学习框架，提高了骨质疏松症诊断的准确性和模型可解释性。|
|🆕 发布|Needles in the Landscape: Semi-Supervised Pseudolabeling for Archaeological Site Discovery under Label Scarcity|《景观中的针：在标签稀缺条件下用于考古遗址发现的半监督伪标签法》|Simon Jaxy, Anton Theys, Patrick Willett, W. Chris Carleton, Ralf Vandam, Pieter Libin|<http://arxiv.org/pdf/2510.16814v1>|提出半监督学习策略，通过动态伪标签和条件随机场提升考古遗址发现准确率。|


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Enhancing Test Time Adaptation with Few-shot Guidance|增强测试时间适应性的少量样本引导|Siqi Luo, Yi Xin, Yuntao Du, Zhongwei Wan, Tao Tan, Guangtao Zhai, Xiaohong Liu|<http://arxiv.org/pdf/2409.01341v3>|提出了一种利用少量样本指导的测试时适应方法，有效应对了训练与测试数据分布差异导致的性能下降问题。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ReefNet: A Large scale, Taxonomically Enriched Dataset and Benchmark for Hard Coral Classification|《ReefNet：一个大规模、分类学丰富的数据集和硬珊瑚分类基准》|Yahia Battach, Abdulwahab Felemban, Faizan Farooq Khan, Yousef A. Radwan, Xiang Li, Fabio Marchese, Sara Beery, Burton H. Jones .etc.|<http://arxiv.org/pdf/2510.16822v1>|介绍了ReefNet，一个大规模、分类详细的珊瑚礁图像数据集，为精细分类和领域泛化提供了挑战性基准。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|End-to-end Listen, Look, Speak and Act|端到端听、看、说与行动|Siyin Wang, Wenyi Yu, Xianzhao Chen, Xiaohai Tian, Jun Zhang, Lu Lu, Chao Zhang|<http://arxiv.org/pdf/2510.16756v1>|首次实现全双工、端到端的跨模态感知与生成模型，通过专门化专家和统一注意力机制提升自然交互能力。|
|🆕 发布|Eliciting Grounded Chain-of-Thought Reasoning in 3D Scenes|在3D场景中激发基于实体的链式思维推理|Xiongkun Linghu, Jiangyong Huang, Ziyu Zhu, Baoxiong Jia, Siyuan Huang|<http://arxiv.org/pdf/2510.16714v1>|提出了一种3D场景中基于地面链式思维推理的新框架，实现了类似人类的逐步推理。|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ASCD: Attention-Steerable Contrastive Decoding for Reducing Hallucination in MLLM|注意驱动的对比解码以减少大规模语言模型中的虚构现象|Yujun Wang, Aniri, Jinhe Bi, Soeren Pirk, Yunpu Ma|<http://arxiv.org/pdf/2506.14766v2>|提出了一种注意力引导的对比解码方法，有效减少多模态大语言模型在解码时的虚构现象。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Foundation Models in Medical Image Analysis: A Systematic Review and Meta-Analysis|医学影像分析中的基础模型：系统评价与荟萃分析|Praveenbalaji Rajendran, Mojtaba Safari, Wenfeng He, Mingzhe Hu, Shansong Wang, Jun Zhou, Xiaofeng Yang|<http://arxiv.org/pdf/2510.16973v1>|系统综述并量化分析了基础模型在医学影像分析中的应用，推动其在临床实践中的转化。|
|🆕 发布|Class-N-Diff: Classification-Induced Diffusion Model Can Make Fair Skin Cancer Diagnosis|类-差分：分类引导扩散模型可促进公平的皮肤癌诊断|Nusrat Munia, Abdullah Imran|<http://arxiv.org/pdf/2510.16887v1>|[代码](https://github.com/Munia03/Class-N-Diff.); 提出了一种集成分类器的Class-N-Diff模型，通过指导图像生成改善皮肤癌诊断图像的准确性和多样...|
|🆕 发布|BARL: Bilateral Alignment in Representation and Label Spaces for Semi-Supervised Volumetric Medical Image Segmentation|Segmentation：分割   BARL：用于半监督体素医学图像分割的表现和标签空间双边对齐|Shujian Gao, Yuan Wang, Zekuan Yu|<http://arxiv.org/pdf/2510.16863v1>|提出了一种双向对齐框架BARL，通过在表示空间和标签空间同时进行对齐，有效提升了半监督医学图像分割的...|
|🆕 发布|SDPA++: A General Framework for Self-Supervised Denoising with Patch Aggregation|SDPA++：一种基于斑块聚合的自监督去噪通用框架|Huy Minh Nhat Nguyen, Triet Hoang Minh Dao, Chau Vinh Hoang Truong, Cuong Tuan Nguyen|<http://arxiv.org/pdf/2510.16702v1>|提出了一种无需清洁图像参考的自我监督去噪框架SDPA++，通过伪地面真实图像和修补聚合策略提升OCT...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Registration is a Powerful Rotation-Invariance Learner for 3D Anomaly Detection|“注册是一种用于三维异常检测的强大旋转不变性学习器”|Yuyang Yu, Zhengwei Chen, Xuemiao Xu, Lei Zhang, Haoxin Yang, Yongwei Nie, Shengfeng He|<http://arxiv.org/pdf/2510.16865v1>|提出了一种结合点云配准与特征提取的方法，有效提升了三维异常检测的旋转不变性和局部特征识别能力。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unsupervised Monocular Road Segmentation for Autonomous Driving via Scene Geometry|通过场景几何实现的无监督单目道路分割用于自动驾驶|Sara Hatami Rostami, Behrooz Nasihatkon|<http://arxiv.org/pdf/2510.16790v1>|提出了一种无监督的单目道路分割方法，利用场景几何和时序线索实现道路与非道路区域的区分。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Parameter-Efficient Fine-Tuning for Pre-Trained Vision Models: A Survey and Benchmark|参数高效的微调方法用于预训练视觉模型：综述与基准测试|Yi Xin, Jianjiang Yang, Siqi Luo, Yuntao Du, Qi Qin, Kangrui Cen, Yangfan He, Zhiwei Zhang .etc.|<http://arxiv.org/pdf/2402.02242v6>|[代码](https://github.com/synbol/Awesome-Parameter-Efficient-Transfer-Learning.); 该论文综述了参数高效微调方法，旨在降低预训练视觉模型在微调阶段的计算和存储需求。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unlocking Off-the-Grid Sparse Recovery with Unlimited Sensing: Simultaneous Super-Resolution in Time and Amplitude|解锁无限感知下的非网格稀疏恢复：时间和幅度同时超分辨率|Ruiming Guo, Ayush Bhandari|<http://arxiv.org/pdf/2510.16948v1>|提出了一种无限感知框架下的超分辨率方法，实现了在固定比特预算下的时间和幅度同时超分辨率恢复。|

