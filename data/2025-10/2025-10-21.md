## [UPDATED!] **2025-10-21** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unifying and Enhancing Graph Transformers via a Hierarchical Mask Framework|通过分层掩码框架统一和增强图变换器|Yujie Xing, Xiao Wang, Bin Wu, Hai Huang, Chuan Shi|<http://arxiv.org/pdf/2510.18825v1>|提出统一层次掩码框架以增强图变换器灵活性，实现多级交互信息融合，提升图表示学习性能。|
|🆕 发布|Exploring a Unified Vision-Centric Contrastive Alternatives on Multi-Modal Web Documents|探索面向多模态网络文档的统一视觉中心对比替代方法|Yiqi Lin, Alex Jinpeng Wang, Linjie Li, Zhengyuan Yang, Mike Zheng Shou|<http://arxiv.org/pdf/2510.18703v1>|[代码](https://github.com/showlab/VC2L.); 提出了一种统一的视觉中心对比学习框架VC2L，直接在像素空间处理文本和图像，有效提升了复杂网页文档的...|
|📝 更新|Polyline Path Masked Attention for Vision Transformer|折线路径掩码注意力机制在视觉变换器中的应用|Zhongchen Zhao, Chaodong Xiao, Hui Lin, Qi Xie, Lei Zhang, Deyu Meng|<http://arxiv.org/pdf/2506.15940v2>|[代码](https://github.com/zhongchenzhao/PPMA.); 提出了一种结合 Vision Transformer 和 Mamba2 优势的 Polyline P...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Detection and Simulation of Urban Heat Islands Using a Fine-Tuned Geospatial Foundation Model for Microclimate Impact Prediction|使用微调地理空间基础模型进行城市热岛检测与模拟以预测微气候影响|Jannis Fleckenstein, David Kreismann, Tamara Rosemary Govindasamy, Thomas Brunschwiler, Etienne Vos, Mattia Rigotti|<http://arxiv.org/pdf/2510.18773v1>|利用地理基础模型微调预测城市热岛效应，助力气候适应型城市建设。|
|📝 更新|CaMiT: A Time-Aware Car Model Dataset for Classification and Generation|时间感知的车辆模型数据集：用于分类和生成|Frédéric LIN, Biruk Abere Ambaw, Adrian Popescu, Hejer Ammar, Romaric Audigier, Hervé Le Borgne|<http://arxiv.org/pdf/2510.17626v2>|提出了CaMiT数据集，通过时间感知的预训练和分类策略，增强了模型对汽车模型时变特征的识别和生成能力...|
|📝 更新|Adapting Medical Vision Foundation Models for Volumetric Medical Image Segmentation via Active Learning and Selective Semi-supervised Fine-tuning|通过主动学习和选择性半监督微调适应医学视觉基础模型进行体积医学图像分割|Jin Yang, Daniel S. Marcus, Aristeidis Sotiras|<http://arxiv.org/pdf/2509.10784v2>|提出了一种高效适应目标域的医学视觉基础模型微调方法，通过主动学习和选择性半监督微调选择最有信息量的样...|
|🆕 发布|Zero-Shot Vehicle Model Recognition via Text-Based Retrieval-Augmented Generation|基于文本检索增强生成的零样本车辆模型识别|Wei-Chia Chang, Yan-Ann Chen|<http://arxiv.org/pdf/2510.18502v1>|提出了一种结合视觉语言模型和检索增强生成的方法，实现了无需大规模重训练的零样本车辆型号识别。|
|🆕 发布|ScaleNet: Scaling up Pretrained Neural Networks with Incremental Parameters|ScaleNet：通过增量参数扩展预训练神经网络规模|Zhiwei Hao, Jianyuan Guo, Li Shen, Kai Han, Yehui Tang, Han Hu, Yunhe Wang|<http://arxiv.org/pdf/2510.18431v1>|提出了一种高效扩展预训练视觉变换器模型的方法ScaleNet，通过引入少量调整参数实现性能提升。|
|🆕 发布|Beyond Single Models: Mitigating Multimodal Hallucinations via Adaptive Token Ensemble Decoding|超越单一模型：通过自适应标记集合解码减轻多模态幻觉|Jinlin Li, Yuran Wang, Yifei Yuan, Xiao Zhou, Yingying Zhang, Xixian Yong, Yefeng Zheng, Xian Wu|<http://arxiv.org/pdf/2510.18321v1>|[代码](https://github.com/jinlin2021/ATED.); 提出了一种无训练的适应性令牌集成解码框架，有效减少大型视觉语言模型在多模态任务中的对象虚造问题。|
|📝 更新|Foundation Cures Personalization: Improving Personalized Models' Prompt Consistency via Hidden Foundation Knowledge|基于基础知识的个性化修正：通过隐藏基础知识提高个性化模型提示一致性|Yiyang Cai, Zhengkai Jiang, Yulong Liu, Chunyang Jiang, Wei Xue, Yike Guo, Wenhan Luo|<http://arxiv.org/pdf/2411.15277v3>|提出FreeCure框架，利用基础模型知识提升个性化模型提示一致性，增强面部属性控制。|
|📝 更新|Distilling LLM Prior to Flow Model for Generalizable Agent's Imagination in Object Goal Navigation|将大型语言模型先验知识蒸馏到流模型中以实现物体目标导航中代理的泛化想象力|Badi Li, Ren-jie Lu, Yu Zhou, Jingke Meng, Wei-shi Zheng|<http://arxiv.org/pdf/2508.09423v2>|[代码](https://github.com/Badi-Li/GOAL.); 提出了一种融合大型语言模型先验知识的生成流框架，有效提升了物体导航任务在不熟悉环境中的泛化能力。|
|📝 更新|MSR-Align: Policy-Grounded Multimodal Alignment for Safety-Aware Reasoning in Vision-Language Models|MSR-Align：基于策略的多模态对齐方法，用于视觉语言模型中的安全感知推理|Yinan Xia, Yilei Jiang, Yingshui Tan, Xiaoyong Zhu, Xiangyu Yue, Bo Zheng|<http://arxiv.org/pdf/2506.19257v2>|提出MSR-Align数据集，增强视觉语言模型在多模态输入下的安全推理能力。|
|📝 更新|VisuRiddles: Fine-grained Perception is a Primary Bottleneck for Multimodal Large Language Models in Abstract Visual Reasoning|“VisuRiddles：在抽象视觉推理中，细粒度感知是多模态大型语言模型的主要瓶颈”|Hao Yan, Xingchen Liu, Hao Wang, Zhenbiao Cao, Handong Zheng, Liang Yin, Xinxing Su, Zihao Chen .etc.|<http://arxiv.org/pdf/2506.02537v3>|[代码](https://github.com/yh-hust/VisuRiddles); 提出VisuRiddles基准和Perceptual Riddle Synthesizer框架，提升...|
|🆕 发布|BlendCLIP: Bridging Synthetic and Real Domains for Zero-Shot 3D Object Classification with Multimodal Pretraining|BlendCLIP：融合合成与真实域进行零样本三维物体分类的多模态预训练|Ajinkya Khoche, Gergő László Nagy, Maciej Wozniak, Thomas Gustafsson, Patric Jensfelt|<http://arxiv.org/pdf/2510.18244v1>|[代码](https://github.com/kesu1/BlendCLIP.); BlendCLIP通过结合合成与真实数据域的优势，提出了一种渐进式数据混合策略，有效提升了零样本3D...|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CovMatch: Cross-Covariance Guided Multimodal Dataset Distillation with Trainable Text Encoder|协方差匹配：基于跨协方差引导的可训练文本编码器多模态数据集蒸馏|Yongmin Lee, Hye Won Chung|<http://arxiv.org/pdf/2510.18583v1>|提出CovMatch框架，通过联合优化图像和文本编码器，实现了更强大的跨模态对齐和性能提升。|
|🆕 发布|Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views|"以三维思考：基于有限视角的几何想象扎根空间推理"|Zhangquan Chen, Manyuan Zhang, Xinlei Yu, Xufang Luo, Mingze Sun, Zihao Pan, Yan Feng, Peng Pei .etc.|<http://arxiv.org/pdf/2510.18632v1>|[代码](https://github.com/zhangquanchen/3DThinker.); 提出3DThinker框架，通过二维图像实现三维空间推理，无需三维先验输入或标注数据。|
|📝 更新|A Multimodal Deep Learning Approach for White Matter Shape Prediction in Diffusion MRI Tractography|用于扩散MRI追踪术中白质形状预测的多模态深度学习方法|Yui Lo, Yuqian Chen, Dongnan Liu, Leo Zekelman, Jarrett Rushmore, Yogesh Rathi, Nikos Makris, Alexandra J. Golby .etc.|<http://arxiv.org/pdf/2504.18400v4>|提出了一种多模态深度学习方法Tract2Shape，快速准确预测白质轨迹形状，提高了大规模数据集处理...|
|📝 更新|MATRIX: Multimodal Agent Tuning for Robust Tool-Use Reasoning|MATRIX：多模态智能体调优以实现鲁棒的工具使用推理|Tajamul Ashraf, Umair Nawaz, Abdelrahman M. Shaker, Rao Anwer, Philip Torr, Fahad Shahbaz Khan, Salman Khan|<http://arxiv.org/pdf/2510.08567v3>|[代码](https://github.com/mbzuai-oryx/MATRIX.); 提出了一种自动合成多模态轨迹的视觉中心化代理调优框架，有效提升了工具使用推理的鲁棒性。|
|🆕 发布|Vision Foundation Models Can Be Good Tokenizers for Latent Diffusion Models|视觉基础模型可以作为潜在扩散模型的有效标记器|Tianci Bi, Xiaoyi Zhang, Yan Lu, Nanning Zheng|<http://arxiv.org/pdf/2510.18457v1>|提出直接整合视觉基础模型作为潜在扩散模型的优质编码器，大幅提升训练速度和性能。|
|🆕 发布|Proactive Reasoning-with-Retrieval Framework for Medical Multimodal Large Language Models|主动推理与检索框架用于医疗多模态大型语言模型|Lehan Wang, Yi Qin, Honglong Yang, Xiaomeng Li|<http://arxiv.org/pdf/2510.18303v1>|[代码](https://github.com/xmed-lab/Med-RwR.); 提出首个多模态医疗推理与检索框架Med-RwR，通过主动检索外部知识增强模型推理能力。|
|📝 更新|Latent Diffusion Model without Variational Autoencoder|不使用变分自编码器的潜在扩散模型|Minglei Shi, Haolin Wang, Wenzhao Zheng, Ziyang Yuan, Xiaoshi Wu, Xintao Wang, Pengfei Wan, Jie Zhou .etc.|<http://arxiv.org/pdf/2510.15301v3>|[代码](https://howlin-wang.github.io/svg); 提出无VAE的SVG模型，利用自监督表征提升扩散模型训练效率和生成质量。|
|📝 更新|Learning Collaborative Knowledge with Multimodal Representation for Polyp Re-Identification|学习用于息肉重识别的多模态表征协作知识|Suncheng Xiang, Jiale Guan, Shilun Cai, Jiacheng Ruan, Dahong Qian|<http://arxiv.org/pdf/2408.05914v3>|[代码](https://github.com/JeremyXSC/DMCL.); 提出了一种多模态协同学习框架DMCL，有效融合视觉和文本信息，提升结直肠镜下息肉重识别性能。|
|🆕 发布|VLSU: Mapping the Limits of Joint Multimodal Understanding for AI Safety|VLSU：映射人工智能安全性的联合多模态理解极限|Shruti Palaskar, Leon Gatys, Mona Abdelrahman, Mar Jacobo, Larry Lindsey, Rutika Moharir, Gunnar Lund, Yang Xu .etc.|<http://arxiv.org/pdf/2510.18214v1>|提出了一种全面评估多模态模型安全性的框架，揭示了图像和文本联合理解中的缺陷。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Fourier Transform Multiple Instance Learning for Whole Slide Image Classification|傅里叶变换多实例学习在整张玻片图像分类中的应用|Anthony Bilic, Guangyu Sun, Ming Li, Md Sanzid Bin Hossain, Yu Tian, Wei Zhang, Laura Brattain, Dexter Hadley .etc.|<http://arxiv.org/pdf/2510.15138v2>|提出了一种结合频率域学习的FFT-MIL方法，通过增强全局依赖性，提高了全切片图像分类的准确性和效率...|
|🆕 发布|FedDEAP: Adaptive Dual-Prompt Tuning for Multi-Domain Federated Learning|FedDEAP：面向多域联邦学习的自适应双提示调谐方法|Yubin Zheng, Pak-Hei Yeung, Jing Xia, Tianjie Ju, Peng Tang, Weidong Qiu, Jagath C. Rajapakse|<http://arxiv.org/pdf/2510.18837v1>|提出自适应联邦提示调优框架FedDEAP，通过分离图像的语义和领域特征，增强CLIP在多领域联邦学习...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|An Explainable Hybrid AI Framework for Enhanced Tuberculosis and Symptom Detection|一个用于增强肺结核和症状检测的可解释混合人工智能框架|Neel Patel, Alexander Wong, Ashkan Ebadi|<http://arxiv.org/pdf/2510.18819v1>|提出了一种结合监督学习和自监督学习的混合AI框架，提高了肺结核和症状检测的准确性和可解释性。|
|📝 更新|scSplit: Bringing Severity Cognizance to Image Decomposition in Fluorescence Microscopy|scSplit：将严重性认知引入荧光显微镜下的图像分解|Ashesh Ashesh, Florian Jug|<http://arxiv.org/pdf/2503.22983v3>|[代码](https://github.com/juglab/scSplit); 提出scSplit方法，通过预测和适应不同混合比例，优化荧光显微镜图像分解和去干扰。|
|🆕 发布|Bayesian Fully-Connected Tensor Network for Hyperspectral-Multispectral Image Fusion|贝叶斯全连接张量网络用于高光谱-多光谱图像融合|Linsong Shan, Zecan Yang, Laurence T. Yang, Changlong Li, Honglu Zhao, Xin Nie|<http://arxiv.org/pdf/2510.18400v1>|提出了一种贝叶斯全连接张量网络方法，有效解决了高光谱-多光谱图像融合中的结构保持和参数调整问题。|
|🆕 发布|Cross-Modal Scene Semantic Alignment for Image Complexity Assessment|跨模态场景语义对齐用于图像复杂性评估|Yuqing Luo, Yixiao Li, Jiang Liu, Jun Fu, Hadi Amirpour, Guanghui Yue, Baoquan Zhao, Padraig Corcoran .etc.|<http://arxiv.org/pdf/2510.18377v1>|[代码](https://github.com/XQ2K/First-Cross-Model-ICA.); 提出了一种利用跨模态场景语义信息的方法，提高了图像复杂性评估的准确性和一致性。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ε-Seg: Sparsely Supervised Semantic Segmentation of Microscopy Data|ε-Seg：稀疏监督下的显微数据语义分割|Sheida Rahnamai Kordasiabi, Damian Dalle Nogare, Florian Jug|<http://arxiv.org/pdf/2510.18637v1>|提出了一种基于变分自编码器的稀疏监督语义分割方法ε-Seg，有效处理了复杂生物图像数据的分割问题。|
|🆕 发布|OpenInsGaussian: Open-vocabulary Instance Gaussian Segmentation with Context-aware Cross-view Fusion|开放词汇实例高斯分割：基于上下文感知的跨视角融合|Tianyu Huang, Runnan Chen, Dongting Hu, Fengming Huang, Mingming Gong, Tongliang Liu|<http://arxiv.org/pdf/2510.18253v1>|提出OpenInsGaussian框架，通过上下文感知特征提取和注意力驱动的多视角融合，提升三维场景...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DWaste: Greener AI for Waste Sorting using Mobile and Edge Devices|DWaste：利用移动和边缘设备进行垃圾分类的绿色AI|Suman Kunwar|<http://arxiv.org/pdf/2510.18513v1>|开发DWaste平台，利用轻量级计算机视觉模型实现移动和边缘设备上的实时废物分类，提升效率与可持续性...|
|📝 更新|Mask Image Watermarking|遮罩图像水印技术|Runyi Hu, Jie Zhang, Shiqian Zhao, Nils Lukas, Jiwei Li, Qing Guo, Han Qiu, Tianwei Zhang|<http://arxiv.org/pdf/2504.12739v3>|提出了一种高效灵活的图像水印框架MaskWM，实现了全局和局部水印的嵌入与提取，提升了鲁棒性并保持了...|
|🆕 发布|Automated Wicket-Taking Delivery Segmentation and Weakness Detection in Cricket Videos Using OCR-Guided YOLOv8 and Trajectory Modeling|板球视频中的自动取球投球分段与弱点检测：基于OCR引导的YOLOv8和轨迹建模|Mst Jannatun Ferdous, Masum Billah, Joy Karmoker, Mohd Ruhul Ameen, Akif Islam, Md. Omar Faruqe|<http://arxiv.org/pdf/2510.18405v1>|提出了一种基于OCR和YOLOv8的自动板球视频分析系统，用于提取得分时刻和球轨迹建模，助力教练策略...|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|See the Text: From Tokenization to Visual Reading|看到文本：从分词到视觉阅读|Ling Xing, Alex Jinpeng Wang, Rui Yan, Hongyu Qu, Zechao Li, Jinhui Tang|<http://arxiv.org/pdf/2510.18840v1>|挑战传统分词方法，提出视觉阅读的SeeTok模型，提升低资源语言处理效率。|
|🆕 发布|DP$^2$O-SR: Direct Perceptual Preference Optimization for Real-World Image Super-Resolution|DP$^2$O-超分辨率：面向真实世界图像的超分辨率直接感知偏好优化|Rongyuan Wu, Lingchen Sun, Zhengqiang Zhang, Shihao Wang, Tianhe Wu, Qiaosi Yi, Shuai Li, Lei Zhang|<http://arxiv.org/pdf/2510.18851v1>|提出了一种无需人工标注的感知偏好优化的图像超分辨率框架，有效提升了真实世界图像的感知质量和泛化能力。|
|📝 更新|RODS: Robust Optimization Inspired Diffusion Sampling for Detecting and Reducing Hallucination in Generative Models|RODS：基于鲁棒优化启发的扩散采样方法用于检测和减少生成模型中的幻觉现象|Yiqi Tian, Pengfei Jin, Mingze Yuan, Na Li, Bo Zeng, Quanzheng Li|<http://arxiv.org/pdf/2507.12201v2>|[代码](https://github.com/Yiqi-Verna-Tian/RODS.); 提出RODS方法，通过优化视角检测并减少生成模型中的幻觉现象，提高采样保真度和鲁棒性。|
|📝 更新|Improving Diffusion-based Inverse Algorithms under Few-Step Constraint via Learnable Linear Extrapolation|通过可学习线性外推法在少步约束下改进基于扩散的反向算法|Jiawei Zhang, Ziyuan Liu, Leon Yan, Gen Li, Yuantao Gu|<http://arxiv.org/pdf/2503.10103v3>|[代码](https://github.com/weigerzan/LLE_inverse_problem.); 提出了一种轻量级方法Learnable Linear Extrapolation，有效提升少步扩散逆...|
|📝 更新|ITVTON: Virtual Try-On Diffusion Transformer Based on Integrated Image and Text|集成图像与文本的虚拟试穿扩散变换器：ITVTON|Haifeng Ni, Ming Xu|<http://arxiv.org/pdf/2501.16757v3>|提出ITVTON框架，通过集成图像和文本信息，简化了虚拟试穿模型的复杂性并提升了效果。|
|📝 更新|REPA-E: Unlocking VAE for End-to-End Tuning with Latent Diffusion Transformers|REPA-E：使用潜在扩散变换器解锁vae的端到端微调|Xingjian Leng, Jaskirat Singh, Yunzhong Hou, Zhenchang Xing, Saining Xie, Liang Zheng|<http://arxiv.org/pdf/2504.10483v2>|提出方法REPA-E，实现VAE与扩散模型端到端训练，显著提升性能并创ImageNet新纪录。|
|🆕 发布|RayPose: Ray Bundling Diffusion for Template Views in Unseen 6D Object Pose Estimation|《RayPose：在不可见6D物体位姿估计中基于光线捆绑扩散的模板视图方法》|Junwen Huang, Shishir Reddy Vutukur, Peter KT Yu, Nassir Navab, Slobodan Ilic, Benjamin Busam|<http://arxiv.org/pdf/2510.18521v1>|将基于模板的物体位姿估计转化为射线对齐问题，提出了一种基于扩散变换器的框架，有效提升了未见物体位姿估...|
|📝 更新|Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback|Uniworld-V2：使用扩散负向感知微调与MLLM隐式反馈强化图像编辑|Zongjian Li, Zheyuan Liu, Qihui Zhang, Bin Lin, Feize Wu, Shenghai Yuan, Zhiyuan Yan, Yang Ye .etc.|<http://arxiv.org/pdf/2510.16888v2>|[代码](https://github.com/PKU-YuanGroup/UniWorld-V2.); 提出了一种基于策略优化的图像编辑后训练框架Edit-R1，利用扩散负样本感知微调和多模态大语言模型隐...|
|🆕 发布|Beyond Single Images: Retrieval Self-Augmented Unsupervised Camouflaged Object Detection|超越单张图像：检索自增强的无监督迷彩目标检测|Ji Du, Xin Wang, Fangwei Hao, Mingyang Yu, Chunyuan Chen, Jiesheng Wu, Bin Wang, Jing Xu .etc.|<http://arxiv.org/pdf/2510.18437v1>|[代码](https://github.com/xiaohainku/RISE.); 提出RISE方法，利用整个训练数据集生成伪标签以训练伪装目标检测模型，无需标注即可提升检测性能。|
|🆕 发布|ImageGem: In-the-wild Generative Image Interaction Dataset for Generative Model Personalization|《ImageGem：面向生成模型个性化的野外生成图像交互数据集》|Yuanhe Guo, Linxi Xie, Zhuoran Chen, Kangrui Yu, Ryan Po, Guandao Yang, Gordon Wetztein, Hongyi Wen|<http://arxiv.org/pdf/2510.18433v1>|提出了ImageGem数据集，通过用户偏好注释训练出更精准的生成模型，实现了生成模型个性化。|
|🆕 发布|Ranking-based Preference Optimization for Diffusion Models from Implicit User Feedback|基于排名的偏好优化：从隐式用户反馈中优化扩散模型|Yi-Lun Wu, Bo-Kai Ruan, Chiang Tseng, Hong-Han Shuai|<http://arxiv.org/pdf/2510.18353v1>|[代码](https://github.com/basiclab/DiffusionDRO.); 提出Diffusion-DRO框架，通过将偏好学习转化为排名问题，优化了扩散模型对人类偏好的适应，提...|
|🆕 发布|GeoDiff: Geometry-Guided Diffusion for Metric Depth Estimation|GeoDiff：基于几何引导的扩散用于度量深度估计|Tuan Pham, Thanh-Tung Le, Xiaohui Xie, Stephan Mandt|<http://arxiv.org/pdf/2510.18291v1>|提出了一种利用立体视觉引导的几何约束增强方法，解决了单目图像绝对深度估计的尺度模糊问题。|
|📝 更新|View Transformation Robustness for Multi-View 3D Object Reconstruction with Reconstruction Error-Guided View Selection|多视角三维物体重建中基于重建误差引导的视图选择对视图变换的鲁棒性|Qi Zhang, Zhouhang Luo, Tao Yu, Hui Huang|<http://arxiv.org/pdf/2412.11428v2>|[代码](https://github.com/zqyq/VTR.); 提出了一种基于重建误差指导的视图选择方法，增强了多视角3D重建模型对视图变换的鲁棒性。|
|📝 更新|NEBULA: Do We Evaluate Vision-Language-Action Agents Correctly?|“NEBULA：我们是否正确评估了视觉-语言-动作智能体？”|Jierui Peng, Yanyan Zhang, Yicheng Duan, Tuo Liang, Vipin Chaudhary, Yu Yin|<http://arxiv.org/pdf/2510.16263v2>|提出了一种双轴评价协议的统一生态系统NEBULA，用于精确诊断和评估视觉语言行动代理的技能和鲁棒性。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|UniVideo: Unified Understanding, Generation, and Editing for Videos|统一视频理解、生成与编辑方法：UniVideo|Cong Wei, Quande Liu, Zixuan Ye, Qiulin Wang, Xintao Wang, Pengfei Wan, Kun Gai, Wenhu Chen|<http://arxiv.org/pdf/2510.08377v2>|UniVideo统一了视频理解和生成编辑，通过双流设计实现多模态指令解析和视觉一致性，提升了视频生成...|
|📝 更新|Janus-Pro-R1: Advancing Collaborative Visual Comprehension and Generation via Reinforcement Learning|Janus-Pro-R1：通过强化学习推进协同视觉理解与生成|Kaihang Pan, Yang Wu, Wendong Bu, Kai Shen, Juncheng Li, Yingting Wang, Yunfei Li, Siliang Tang .etc.|<http://arxiv.org/pdf/2506.01480v2>|通过强化学习促进视觉理解和生成协同进化，实现了更高效的图像生成和评估。|
|📝 更新|VideoVerse: How Far is Your T2V Generator from a World Model?|《VideoVerse：您的T2V生成器离世界模型还有多远？》|Zeqing Wang, Xinyu Wei, Bairui Li, Zhen Guo, Jinrui Zhang, Hongyang Wei, Keze Wang, Lei Zhang|<http://arxiv.org/pdf/2510.08398v2>|提出了VideoVerse基准，全面评估T2V模型对复杂时间因果性和世界知识的理解能力。|
|🆕 发布|SSD: Spatial-Semantic Head Decoupling for Efficient Autoregressive Image Generation|SSD：空间语义头部解耦用于高效自回归图像生成|Siyong Jian, Huan Wang|<http://arxiv.org/pdf/2510.18716v1>|提出了一种视觉令牌注意力头解耦的KV缓存压缩框架，实现了高效的自回归图像生成，大幅降低内存使用和计算...|
|📝 更新|Increasing the Utility of Synthetic Images through Chamfer Guidance|通过Chamfer引导提高合成图像的实用性|Nicola Dall'Asen, Xiaofeng Zhang, Reyhane Askari Hemmat, Melissa Hall, Jakob Verbeek, Adriana Romero-Soriano, Michal Drozdzal|<http://arxiv.org/pdf/2508.10631v2>|提出了一种名为Chamfer Guidance的无训练引导方法，通过少量真实图像样本提高合成图像的多...|
|📝 更新|Every Camera Effect, Every Time, All at Once: 4D Gaussian Ray Tracing for Physics-based Camera Effect Data Generation|每一次每一种相机效果，一次性全部呈现：基于物理的相机效果数据生成的四维高斯光线追踪|Yi-Ruei Liu, You-Zhe Xie, Yu-Hsiang Hsu, I-Sheng Fang, Yu-Lun Liu, Jun-Cheng Chen|<http://arxiv.org/pdf/2509.10759v2>|提出4D Gaussian Ray Tracing方法，通过物理基础的射线追踪生成具有可控、精确相机...|
|🆕 发布|UniGenBench++: A Unified Semantic Evaluation Benchmark for Text-to-Image Generation|统一语义评估基准：用于文本到图像生成的UniGenBench++|Yibin Wang, Zhimin Li, Yuhang Zang, Jiazi Bu, Yujie Zhou, Yi Xin, Junjun He, Chunyu Wang .etc.|<http://arxiv.org/pdf/2510.18701v1>|提出了UniGenBench++，一个统一语义评估基准，涵盖多场景和语言，全面评估文本到图像生成模型...|
|🆕 发布|MoGA: Mixture-of-Groups Attention for End-to-End Long Video Generation|MoGA：面向端到端长视频生成的混合组注意力机制|Weinan Jia, Yuning Lu, Mengqi Huang, Hualiang Wang, Binyuan Huang, Nan Chen, Mu Liu, Jidong Jiang .etc.|<http://arxiv.org/pdf/2510.18692v1>|提出了一种高效稀疏注意力机制MoGA，通过精确匹配 tokens 优化长视频生成效率。|
|🆕 发布|Kaleido: Open-Sourced Multi-Subject Reference Video Generation Model|《Kaleido：开源多主体参考视频生成模型》|Zhenxing Zhang, Jiayan Teng, Zhuoyi Yang, Tiankun Cao, Cheng Wang, Xiaotao Gu, Jie Tang, Dan Guo .etc.|<http://arxiv.org/pdf/2510.18573v1>|提出Kaleido模型，通过专门的数据构建流程和参考图像处理技术，解决了多主体视频生成中的连贯性和背...|
|🆕 发布|Descriptor: Occluded nuScenes: A Multi-Sensor Dataset for Evaluating Perception Robustness in Automated Driving|遮挡的nuScenes：一个用于评估自动驾驶感知鲁棒性的多传感器数据集|Sanjay Kumar, Tim Brophy, Reenu Mohandas, Eoin Martino Grua, Ganesh Sistu, Valentina Donzella, Ciaran Eising|<http://arxiv.org/pdf/2510.18552v1>|提出了Occluded nuScenes多传感器数据集，为评估自动驾驶感知系统在恶劣条件下的鲁棒性提...|
|📝 更新|PICABench: How Far Are We from Physically Realistic Image Editing?|PICABench：我们距离物理逼真的图像编辑还有多远？|Yuandong Pu, Le Zhuo, Songhao Han, Jinbo Xing, Kaiwen Zhu, Shuo Cao, Bin Fu, Si Liu .etc.|<http://arxiv.org/pdf/2510.17681v2>|提出PICABench基准和PICAEval评估协议，系统评估图像编辑的物理真实性并探索有效解决方案...|
|📝 更新|VisualQuality-R1: Reasoning-Induced Image Quality Assessment via Reinforcement Learning to Rank|视觉质量R1：通过强化学习排序的推理诱导图像质量评估|Tianhe Wu, Jian Zou, Jie Liang, Lei Zhang, Kede Ma|<http://arxiv.org/pdf/2505.14460v2>|提出了一种基于强化学习排名的视觉推理诱导无参考图像质量评估模型，实现了优于传统方法的性能。|
|🆕 发布|LAND: Lung and Nodule Diffusion for 3D Chest CT Synthesis with Anatomical Guidance|LAND：基于解剖引导的3D胸部CT合成中肺部与结节扩散|Anna Oliveras, Roger Marí, Rafael Redondo, Oriol Guardià, Ana Tost, Bhalaji Nagarajan, Carolina Migliorelli, Vicent Ribas .etc.|<http://arxiv.org/pdf/2510.18446v1>|引入了一种新的潜在扩散模型，通过解剖学掩码指导生成高质量的3D胸部CT扫描。|
|🆕 发布|Efficient Few-shot Identity Preserving Attribute Editing for 3D-aware Deep Generative Models|高效少样本身份保持属性编辑方法用于3D感知深度生成模型|Vishal Vinod|<http://arxiv.org/pdf/2510.18287v1>|[代码](https://vishal-vinod.github.io/gmpi-edit); 提出了一种基于3D深度生成模型的高效少量样本身份保持属性编辑方法，实现了3D面部属性的精准修改。|
|🆕 发布|From Competition to Synergy: Unlocking Reinforcement Learning for Subject-Driven Image Generation|从竞争到协同：解锁强化学习在主体驱动图像生成中的应用|Ziwei Huang, Ying Shu, Hao Fang, Quanyu Long, Wenya Wang, Qiushi Guo, Tiezheng Ge, Leilei Gan|<http://arxiv.org/pdf/2510.18263v1>|提出了一种协同优化的强化学习方法Customized-GRPO，有效平衡了图像生成中的身份保持和提示...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LightMem: Lightweight and Efficient Memory-Augmented Generation|《LightMem：轻量级高效内存增强生成》|Jizhan Fang, Xinle Deng, Haoming Xu, Ziyan Jiang, Yuqi Tang, Ziwen Xu, Shumin Deng, Yunzhi Yao .etc.|<http://arxiv.org/pdf/2510.18866v1>|[代码](https://github.com/zjunlp/LightMem.); 提出了一种高效的轻量级记忆增强系统LightMem，通过模仿人类记忆模型，大幅提升大型语言模型处理历...|
|🆕 发布|UltraGen: High-Resolution Video Generation with Hierarchical Attention|"UltraGen：具有分层注意力的高分辨率视频生成"|Teng Hu, Jiangning Zhang, Zihan Su, Ran Yi|<http://arxiv.org/pdf/2510.18775v1>|提出了一种分层注意力架构，UltraGen实现了高效的高分辨率视频生成，解决了现有模型分辨率限制问题...|
|🆕 发布|IF-VidCap: Can Video Caption Models Follow Instructions?|IF-VidCap：视频字幕模型能遵循指令吗？|Shihao Li, Yuanxing Zhang, Jiangtao Wu, Zhide Lei, Yiwen He, Runzhe Wen, Chenxi Liao, Chengkang Jiang .etc.|<http://arxiv.org/pdf/2510.18726v1>|提出IF-VidCap基准，评估视频字幕模型遵循用户指令的能力，揭示现有模型在复杂指令下的性能差异。|
|📝 更新|Dual Data Alignment Makes AI-Generated Image Detector Easier Generalizable|双数据对齐使AI生成图像检测器更易于泛化|Ruoxin Chen, Junwei Xi, Zhiyuan Yan, Ke-Yue Zhang, Shuang Wu, Jingyi Xie, Xu Chen, Lei Xu .etc.|<http://arxiv.org/pdf/2505.14359v6>|[代码](https://github.com/roy-ch/Dual-Data-Alignment.); 提出双数据对齐方法，有效解决检测器在非偏置数据集上的性能退化问题，显著提升泛化能力。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Context-Aware Pseudo-Label Scoring for Zero-Shot Video Summarization|零样本视频摘要中的上下文感知伪标签评分|Yuanli Wu, Long Zhang, Yue Du, Bin Li|<http://arxiv.org/pdf/2510.17501v2>|提出了一种基于伪标签评分的零样本视频摘要方法，通过上下文感知和评分量表指导，提高了LLM的稳定性和通...|
|📝 更新|gen2seg: Generative Models Enable Generalizable Instance Segmentation|生成模型助力通用实例分割：gen2seg|Om Khangaonkar, Hamed Pirsiavash|<http://arxiv.org/pdf/2505.15263v2>|利用生成模型预训练理解物体边界，实现无需大规模预训练即可进行通用实例分割。|
|📝 更新|SAMPO:Scale-wise Autoregression with Motion PrOmpt for generative world models|SAMPO：基于运动提示的尺度自回归生成世界模型|Sen Wang, Jingyi Tian, Le Wang, Zhimin Liao, Jiayi Li, Huaiyi Dong, Kun Xia, Sanping Zhou .etc.|<http://arxiv.org/pdf/2509.15536v2>|提出了一种结合视觉自回归模型与因果模型的SAMPO框架，通过保持空间局部性和并行解码，显著提升了视频...|
|🆕 发布|EMA-SAM: Exponential Moving-average for SAM-based PTMC Segmentation|EMA-SAM：基于SAM的PTMC分割的指数移动平均法|Maryam Dialameh, Hossein Rajabzadeh, Jung Suk Sim, Hyock Ju Kwon|<http://arxiv.org/pdf/2510.18213v1>|[代码](https://github.com/mdialameh/EMA-SAM); 提出了一种改进的Segment Anything Model，通过引入指数移动平均指针增强了对干预超...|
|📝 更新|A Unified Solution to Video Fusion: From Multi-Frame Learning to Benchmarking|视频融合的统一解决方案：从多帧学习到基准测试|Zixiang Zhao, Haowen Bai, Bingxin Ke, Yukun Cui, Lilun Deng, Yulun Zhang, Kai Zhang, Konrad Schindler|<http://arxiv.org/pdf/2505.19858v2>|提出了一种统一视频融合框架，利用多帧学习和光流特征校正，实现了信息丰富且时间连贯的视频融合效果，并建...|
|🆕 发布|DualHash: A Stochastic Primal-Dual Algorithm with Theoretical Guarantee for Deep Hashing|双哈希：一种具有理论保证的深度哈希随机原-对偶算法|Luxuan Li, Xiao Wang, Chunfeng Cui|<http://arxiv.org/pdf/2510.18218v1>|提出了一种具有理论保证的随机 primal-dual 算法 DualHash，有效解决了深度哈希中的...|
|🆕 发布|A Generalizable Light Transport 3D Embedding for Global Illumination|一种泛化的光传输三维嵌入方法用于全局光照|Bing Xu, Mukund Varma T, Cheng Wang, Tzumao Li, Lifan Wu, Bartlomiej Wronski, Ravi Ramamoorthi, Marco Salvi|<http://arxiv.org/pdf/2510.18189v1>|提出了一种通用的3D光照传输嵌入方法，直接从三维场景配置近似全局光照，无需依赖光线追踪。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|SimCortex: Collision-free Simultaneous Cortical Surfaces Reconstruction|"SimCortex：无碰撞的同时皮质表面重建"|Kaveh Moradkhani, R Jarrett Rushmore, Sylvain Bouix|<http://arxiv.org/pdf/2507.06955v2>|SimCortex通过深度学习框架同时重建大脑表面，避免了碰撞和拓扑缺陷，提高了几何精度。|
|🆕 发布|Moving Light Adaptive Colonoscopy Reconstruction via Illumination-Attenuation-Aware 3D Gaussian Splatting|通过光照衰减感知的3D高斯散点绘制实现的移动光源自适应结肠镜重建|Hao Wang, Ying Zhou, Haoyu Zhao, Rui Wang, Qiang Hu, Xing Zhang, Qiang Li, Zhiwei Wang|<http://arxiv.org/pdf/2510.18739v1>|提出了一种针对结肠镜检查的改进3D高斯散点框架，通过考虑光照衰减因素，实现了高质量的实时三维重建。|
|🆕 发布|PLANA3R: Zero-shot Metric Planar 3D Reconstruction via Feed-Forward Planar Splatting|PLANA3R：通过前向平面喷洒实现的零样本度量平面三维重建|Changkun Liu, Bin Tan, Zeran Ke, Shangzhan Zhang, Jiachen Liu, Ming Qian, Nan Xue, Yujun Shen .etc.|<http://arxiv.org/pdf/2510.18714v1>|[代码](https://lck666666.github.io/plana3r); 提出了一种无需3D平面标注的零样本度量平面3D重建方法，通过平面泼洒和视觉变压器实现高效室内场景重建...|
|📝 更新|Pose-free 3D Gaussian splatting via shape-ray estimation|基于形状射线估计的无姿态三维高斯散点绘制|Youngju Na, Taeyeon Kim, Jumin Lee, Kyu Beom Han, Woo Jae Kim, Sung-eui Yoon|<http://arxiv.org/pdf/2505.22978v3>|[代码](https://github.com/youngju-na/SHARE); 提出了一种无需精确相机位姿的3D高斯渲染框架，通过联合估计形状和光线来减少几何对齐误差。|
|🆕 发布|Entropy-Enhanced Conformal Features from Ricci Flow for Robust Alzheimer's Disease Classification|基于里奇流熵增强的共形特征用于稳健的阿尔茨海默病分类|F. Ahmadi, B. Bidabad, H. Nasiri|<http://arxiv.org/pdf/2510.18396v1>|提出了一种基于熵增强的黎曼流几何特征方法，有效提高了阿尔茨海默病自动诊断的准确性和稳健性。|
|📝 更新|DeepDetect: Learning All-in-One Dense Keypoints|深度检测：学习一体化密集关键点|Shaharyar Ahmed Khan Tareen, Filza Khan Tareen|<http://arxiv.org/pdf/2510.17422v2>|提出了一种深度学习密集关键点检测方法DeepDetect，通过融合多种视觉线索，实现了高密度、高重复...|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Neural 3D Object Reconstruction with Small-Scale Unmanned Aerial Vehicles|小型无人机神经三维物体重建|Àlmos Veres-Vitàlyos, Genis Castillo Gomez-Raya, Filip Lemic, Daniel Johannes Bugelnig, Bernhard Rinner, Sergi Abadal, Xavier Costa-Pérez|<http://arxiv.org/pdf/2509.12458v2>|提出了一种利用小型无人机进行高质量3D重建的自主系统，通过实时反馈调整飞行轨迹以优化数据采集。|
|📝 更新|PRISMM-Bench: A Benchmark of Peer-Review Grounded Multimodal Inconsistencies|PRISMM-Bench：基于同行评审的模态不一致性基准测试|Lukas Selch, Yufang Hou, M. Jehanzeb Mirza, Sivan Doveh, James Glass, Rogerio Feris, Wei Lin|<http://arxiv.org/pdf/2510.16505v2>|提出了首个基于真实审稿人标记的不一致性的多模态模型评估基准，揭示了现有模型在多模态科学推理中的低性能...|
|🆕 发布|Mono4DGS-HDR: High Dynamic Range 4D Gaussian Splatting from Alternating-exposure Monocular Videos|Mono4DGS-HDR：从交替曝光的单目视频中生成高动态范围四维高斯散点图|Jinfeng Liu, Lingtong Kong, Mi Zhou, Jinwen Chen, Dan Xu|<http://arxiv.org/pdf/2510.18489v1>|Mono4DGS-HDR通过两阶段优化方法，首次实现了从交替曝光的单目低动态范围视频重建高质量的四维...|
|📝 更新|H3D-DGS: Exploring Heterogeneous 3D Motion Representation for Deformable 3D Gaussian Splatting|异构3D运动表示探索：用于可变形3D高斯散点的H3D-DGS|Bing He, Yunuo Chen, Guo Lu, Qi Wang, Qunshan Gu, Rong Xie, Li Song, Wenjun Zhang|<http://arxiv.org/pdf/2408.13036v3>|提出异质3D控制点方法，结合光流和梯度优化，提高动态场景重建的收敛性和效率。|
|📝 更新|When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models|当大型语言模型步入三维世界：通过多模态大型语言模型进行三维任务的研究综述与荟萃分析|Xianzheng Ma, Brandon Smart, Yash Bhalgat, Shuai Chen, Xinghui Li, Jian Ding, Jindong Gu, Dave Zhenyu Chen .etc.|<http://arxiv.org/pdf/2405.10255v2>|[代码](https://github.com/ActiveVisionLab/Awesome-LLM-3D.); 概述了多模态大型语言模型处理三维数据的方法，强调了其在空间理解和交互中的潜力。|
|🆕 发布|Hyperbolic Space Learning Method Leveraging Temporal Motion Priors for Human Mesh Recovery|利用时间运动先验的人体网格恢复的双曲空间学习方法|Xiang Zhang, Suping Wu, Weibin Qiu, Zhaocheng Jin, Sheng Yang|<http://arxiv.org/pdf/2510.18256v1>|提出了一种利用时序运动先验在双曲空间中学习的方法，有效恢复了视频中3D人体网格结构。|
|📝 更新|ViFusionTST: Deep Fusion of Time-Series Image Representations from Load Signals for Early Bed-Exit Prediction|基于负载信号的时间序列图像表示深度融合的ViFusionTST：用于早期离床预测|Hao Liu, Yu Hu, Rakiba Rayhana, Ling Bai, Zheng Liu|<http://arxiv.org/pdf/2506.22498v4>|提出了一种基于图像的负载信号融合方法ViFusionTST，用于实时预测患者床下活动，提高了早期离床...|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SAM 2++: Tracking Anything at Any Granularity|SAM 2++：任意粒度下跟踪任意目标|Jiaming Zhang, Cheng Liang, Yichun Yang, Chenkai Zeng, Yutao Cui, Xinwen Zhang, Xin Zhou, Kai Ma .etc.|<http://arxiv.org/pdf/2510.18822v1>|提出了SAM 2++，一种统一处理不同粒度视频追踪任务的新型模型，提升了追踪准确性和泛化能力。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Renaissance of Explicit Motion Information Mining from Transformers for Action Recognition|显式运动信息挖掘在动作识别中从变换器的复兴|Peiqin Zhuang, Lei Bai, Yichao Wu, Ding Liang, Luping Zhou, Yali Wang, Wanli Ouyang|<http://arxiv.org/pdf/2510.18705v1>|提出了一种显式运动信息挖掘模块，有效融合了运动建模特性，提升了动作识别在运动敏感数据集上的性能。|
|🆕 发布|FST.ai 2.0: An Explainable AI Ecosystem for Fair, Fast, and Inclusive Decision-Making in Olympic and Paralympic Taekwondo|FST.ai 2.0：面向奥运会和残奥会跆拳道公平、快速、包容性决策的可解释人工智能生态系统|Keivan Shariatmadar, Ahmad Osman, Ramin Ray, Usman Dildar, Kisam Kim|<http://arxiv.org/pdf/2510.18193v1>|提出FST.ai 2.0系统，通过实时动作识别和不确定性建模辅助裁判决策，实现快速、公平、透明的体育...|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LongInsightBench: A Comprehensive Benchmark for Evaluating Omni-Modal Models on Human-Centric Long-Video Understanding|《LongInsightBench：一个用于评估以人为中心的长时间视频理解的全模态模型综合基准》|ZhaoYang Han, Qihan Lin, Hao Liang, Bowen Chen, Zhou Liu, Wentao Zhang|<http://arxiv.org/pdf/2510.17305v2>|提出了LongInsightBench，首个全面评估全模态模型在长视频理解能力的基准，涵盖视觉、音频...|
|📝 更新|Think With Videos For Agentic Long-Video Understanding|为代理型长视频理解思考的视频处理方法|Huaying Yuan, Zheng Liu, Junjie Zhou, Hongjin Qian, Yan Shu, Nicu Sebe, Ji-Rong Wen, Zhicheng Dou|<http://arxiv.org/pdf/2506.10821v5>|[代码](https://github.com/yhy-2000/VideoDeepResearch); 提出了一种视频探索框架VideoExplorer，通过迭代提问和定位相关时刻，实现了高效、可解释的长...|
|🆕 发布|FeatureFool: Zero-Query Fooling of Video Models via Feature Map|特征愚弄：通过特征图实现对视频模型的零查询欺骗|Duoxun Tang, Xi Xiao, Guangwu Hu, Kangkang Sun, Xiao Yang, Dongyang Chen, Qing Li, Yongjie Yin .etc.|<http://arxiv.org/pdf/2510.18362v1>|提出了一种无需查询的零查询攻击方法FeatureFool，通过直接利用神经网络提取的信息改变视频特征...|
|🆕 发布|StreamingTOM: Streaming Token Compression for Efficient Video Understanding|流式TOM：流式令牌压缩以提高视频理解效率|Xueyi Chen, Keda Tao, Kele Shao, Huan Wang|<http://arxiv.org/pdf/2510.18269v1>|StreamingTOM通过两阶段框架有效解决了流视频处理中的因果性和累积性问题，实现了kv-cac...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ProCLIP: Progressive Vision-Language Alignment via LLM-based Embedder|Contrastive Language-Image Pre-training  《ProCLIP：通过基于大规模语言模型嵌入器的渐进式视觉-语言对齐》|Xiaoxing Hu, Kaicheng Yang, Ziyong Feng, Qi Ming, Zonghao Guo, Xiang An, Ziyong Feng, Junchi Yan .etc.|<http://arxiv.org/pdf/2510.18795v1>|[代码](https://github.com/VisionXLab/ProCLIP); 提出ProCLIP框架，通过逐步对齐图像编码器和基于LLM的文本编码器，提升长文本处理和细粒度语义理...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs|蜜蜂：一种高质量语料库与全栈解决方案，用以解锁先进的完全开放多模态大型语言模型|Yi Zhang, Bolin Ni, Xin-Sheng Chen, Heng-Rui Zhang, Yongming Rao, Houwen Peng, Qinglin Lu, Han Hu .etc.|<http://arxiv.org/pdf/2510.13795v2>|构建高质量数据集 Honey-Data-15M 和数据管道 HoneyPipe，提升全开放多模态大语...|
|📝 更新|Glyph: Scaling Context Windows via Visual-Text Compression|Glyph：通过视觉-文本压缩缩放上下文窗口|Jiale Cheng, Yusen Liu, Xinyu Zhang, Yulin Fei, Wenyi Hong, Ruiliang Lyu, Weihan Wang, Zhe Su .etc.|<http://arxiv.org/pdf/2510.17800v2>|[代码](https://github.com/thu-coai/Glyph.); 提出将文本渲染为图像并用视觉语言模型处理，实现长文本的高效压缩与准确理解。|
|🆕 发布|Binary Quadratic Quantization: Beyond First-Order Quantization for Real-Valued Matrix Compression|二进制二次量化：超越一阶量化实现实值矩阵压缩|Kyo Kuroki, Yasuyuki Okoshi, Thiem Van Chu, Kazushi Kawamura, Masato Motomura|<http://arxiv.org/pdf/2510.18650v1>|提出了一种新型矩阵量化方法BQQ，通过利用二进制二次表达式的表现力，实现了高效矩阵压缩和神经网络量化...|
|🆕 发布|C-SWAP: Explainability-Aware Structured Pruning for Efficient Neural Networks Compression|C-SWAP：面向解释性的结构化剪枝用于高效神经网络压缩|Baptiste Bauvin, Loïc Baret, Ola Ahmad|<http://arxiv.org/pdf/2510.18636v1>|提出了一种基于可解释深度学习的一步式剪枝框架，实现了模型尺寸大幅缩减且性能损失微小。|
|📝 更新|ReID5o: Achieving Omni Multi-modal Person Re-identification in a Single Model|ReID5o：在单一模型中实现全模态行人重识别|Jialong Zuo, Yongtai Deng, Mengdan Tan, Rui Jin, Dongyue Wu, Nong Sang, Liang Pan, Changxin Gao|<http://arxiv.org/pdf/2506.09385v2>|[代码](https://github.com/Zplusdragon/ReID5o_ORBench.); 提出Omni Multi-modal Person Re-identification问题并构建首个...|
|🆕 发布|S2AP: Score-space Sharpness Minimization for Adversarial Pruning|S2AP：分数空间锐度最小化用于对抗性剪枝|Giorgio Piras, Qi Zhao, Fabio Brau, Maura Pintor, Christian Wressnegger, Battista Biggio|<http://arxiv.org/pdf/2510.18381v1>|提出一种S2AP方法，通过最小化评分空间尖锐度来稳定权重剪枝，增强对抗性攻击下的模型鲁棒性。|
|📝 更新|GeoArena: An Open Platform for Benchmarking Large Vision-language Models on WorldWide Image Geolocalization|GeoArena：一个用于对全球图像地理定位的大型视觉-语言模型进行基准测试的开放平台|Pengyue Jia, Yingyi Zhang, Xiangyu Zhao, Sharon Li|<http://arxiv.org/pdf/2509.04334v3>|提出GeoArena平台，解决图像地理定位评估中的数据泄露和隐私问题，通过人类判断优化模型评估。|
|🆕 发布|DeepSeek-OCR: Contexts Optical Compression|深度搜索-OCR：上下文光学压缩|Haoran Wei, Yaofeng Sun, Yukun Li|<http://arxiv.org/pdf/2510.18234v1>|[代码](http://github.com/deepseek-ai/DeepSeek-OCR.); 提出DeepSeek-OCR，通过光学2D映射压缩长文本上下文，实现高压缩比下的OCR精度。|
|📝 更新|Implicit Neural Compression of Point Clouds|点云的隐式神经压缩|Hongning Ruan, Yulin Shao, Qianqian Yang, Liang Zhao, Zhaoyang Zhang, Dusit Niyato|<http://arxiv.org/pdf/2412.10433v2>|提出了一种利用隐式神经表示的点云压缩框架，有效编码几何和属性信息，提升静态和动态点云压缩性能。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DSI-Bench: A Benchmark for Dynamic Spatial Intelligence|动态空间智能基准测试：DSI-Bench|Ziang Zhang, Zehan Wang, Guanghao Zhang, Weilong Dai, Yan Xia, Ziang Yan, Minjie Hong, Zhou Zhao|<http://arxiv.org/pdf/2510.18873v1>|提出DSI-Bench基准，评估模型对动态三维场景中空间关系的理解能力。|
|🆕 发布|Prototyping an End-to-End Multi-Modal Tiny-CNN for Cardiovascular Sensor Patches|心血管传感器贴片端到端多模态微小卷积神经网络的原型设计|Mustafa Fuad Rifet Ibrahim, Tunc Alkanat, Maurice Meijer, Felix Manthey, Alexander Schlaefer, Peer Stelldinger|<http://arxiv.org/pdf/2510.18668v1>|提出了一种高效的卷积神经网络，通过早期融合心电和心音数据，在资源受限设备上实现心血管疾病早期迹象的准...|
|📝 更新|VLA-Cache: Efficient Vision-Language-Action Manipulation via Adaptive Token Caching|VLA-Cache：通过自适应标记缓存实现高效的视觉-语言-动作操作|Siyu Xu, Yunke Wang, Chenghao Xia, Dihao Zhu, Tao Huang, Chang Xu|<http://arxiv.org/pdf/2502.02175v2>|提出了一种自适应视觉令牌缓存方法VLA-Cache，通过缓存和重用静态视觉令牌，有效降低视觉语言行动...|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Ensembling Pruned Attention Heads For Uncertainty-Aware Efficient Transformers|集成剪枝注意力头以实现不确定性感知的高效变换器|Firas Gabetni, Giuseppe Curci, Andrea Pilzer, Subhankar Roy, Elisa Ricci, Gianni Franchi|<http://arxiv.org/pdf/2510.18358v1>|提出了一种高效的不确定性感知Transformer集成方法，通过剪枝注意力头创建多样性成员，实现了接...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GBlobs: Local LiDAR Geometry for Improved Sensor Placement Generalization|GBlobs：用于改进传感器布局泛化的局部LiDAR几何学|Dušan Malić, Christian Fruhwirth-Reisinger, Alexander Prutsch, Wei Lin, Samuel Schulter, Horst Possegger|<http://arxiv.org/pdf/2510.18539v1>|提出GBlobs局部点云特征描述符，有效提升模型在不同LiDAR配置下的泛化能力。|
|📝 更新|WMamba: Wavelet-based Mamba for Face Forgery Detection|WMamba：基于小波变换的Mamba人脸伪造检测方法|Siran Peng, Tianshuo Zhang, Li Gao, Xiangyu Zhu, Haoyuan Zhang, Kai Pang, Zhen Lei|<http://arxiv.org/pdf/2501.09617v2>|提出了一种基于小波变换和动态轮廓卷积的WMamba算法，有效提升了人脸伪造检测的性能。|
|📝 更新|CrossRay3D: Geometry and Distribution Guidance for Efficient Multimodal 3D Detection|CrossRay3D：基于几何与分布引导的高效多模态三维检测|Huiming Yang|<http://arxiv.org/pdf/2510.15991v2>|提出 Sparse Selector 方法提升稀疏检测器性能，实现多模态3D检测效率与准确性的平衡。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GreenHyperSpectra: A multi-source hyperspectral dataset for global vegetation trait prediction|绿色超光谱：一种用于全球植被特性预测的多源超光谱数据集|Eya Cherif, Arthur Ouaknine, Luke A. Brown, Phuong D. Dao, Kyle R. Kovach, Bing Lu, Daniel Mederer, Hannes Feilhauer .etc.|<http://arxiv.org/pdf/2507.06806v2>|[代码](https://github.com/echerif18/HyspectraSSL.); 构建了跨传感器、跨生态系统的GreenHyperSpectra数据集，通过半监督学习显著提升了植被特...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Rebellious Student: A Complementary Learning Framework for Background Feature Enhancement in Hyperspectral Anomaly Detection|《叛逆学生：一种用于高光谱异常检测中背景特征增强的补充学习框架》|Wenping Jin, Yuyang Tang, Li Zhu, Fei Guo|<http://arxiv.org/pdf/2510.18781v1>|[代码](https://github.com/xjpp2016/FERS.); 提出“反叛学生”框架，通过空间特征与光谱特征互补学习，提升高光谱异常检测性能。|
|📝 更新|Learning to See and Act: Task-Aware View Planning for Robotic Manipulation|学会观察与行动：面向机器人操作的任务感知视角规划|Yongjie Bai, Zhouxia Wang, Yang Liu, Weixing Chen, Ziliang Chen, Mingtong Dai, Yongsen Zheng, Lingbo Liu .etc.|<http://arxiv.org/pdf/2508.05186v2>|[代码](https://hcplab-sysu.github.io/TAVP.); 提出了一种任务感知视角规划框架TAVP，通过主动获取信息视角和任务特定特征解耦，提升了机器人操作的鲁...|
|🆕 发布|SEAL: Semantic-Aware Hierarchical Learning for Generalized Category Discovery|SEAL：面向泛化类别发现的语义感知层次学习|Zhenqi He, Yuanpei Liu, Kai Han|<http://arxiv.org/pdf/2510.18740v1>|[代码](https://visual-ai.github.io/seal); 提出SEAL框架，通过层级语义指导的对比学习，实现了对广义类别发现的准确性和扩展性提升。|
|🆕 发布|Beyond the Pipeline: Analyzing Key Factors in End-to-End Deep Learning for Historical Writer Identification|超越管道：分析端到端深度学习在历史作家识别中的关键因素|Hanif Rasyidi, Moshiur Farazi|<http://arxiv.org/pdf/2510.18671v1>|分析了影响历史文档作者识别性能的关键因素，并提出了有效的端到端深度学习架构。|
|📝 更新|Deep Learning in Palmprint Recognition-A Comprehensive Survey|《掌纹识别中的深度学习——全面综述》|Chengrui Gao, Ziyuan Yang, Wei Jia, Lu Leng, Bob Zhang, Andrew Beng Jin Teoh|<http://arxiv.org/pdf/2501.01166v2>|系统综述了深度学习在掌纹识别中的应用进展，填补了传统方法在表示能力上的不足。|
|📝 更新|Cryo-RL: automating prostate cancer cryoablation planning with reinforcement learning|冷冻消融规划自动化：利用强化学习进行前列腺癌冷冻消融治疗|Trixia Simangan, Ahmed Nadeem Abbasi, Yipeng Hu, Shaheer U. Saeed|<http://arxiv.org/pdf/2509.04886v3>|提出了一种基于强化学习的自动化前列腺癌冷冻消融计划方法，提高了肿瘤覆盖率和计划效率。|
|🆕 发布|Learning Human-Object Interaction as Groups|将人类-物体交互学习视为群体行为|Jiajun Hong, Jianan Wei, Wenguan Wang|<http://arxiv.org/pdf/2510.18357v1>|提出了一种基于群体行为理解的交互检测框架GroupHOI，通过空间和语义相似性聚合上下文信息，提升了...|
|📝 更新|Global Prompt Refinement with Non-Interfering Attention Masking for One-Shot Federated Learning|全局提示精炼与非干扰注意力掩码的单次联邦学习|Zhuang Qi, Pan Yu, Lei Meng, Sijin Zhou, Han Yu, Xiaoxiao Li, Xiangxu Meng|<http://arxiv.org/pdf/2509.22700v2>|提出了一种抑制原始文本与可学习提示过度交互的GPR-NIAM方法，实现了一轮通信下的联邦学习任务泛化...|
|📝 更新|Class-wise Balancing Data Replay for Federated Class-Incremental Learning|类平衡数据重放策略用于联邦类增量学习|Zhuang Qi, Ying-Peng Tang, Lei Meng, Han Yu, Xiaoxiao Li, Xiangxu Meng|<http://arxiv.org/pdf/2507.07712v3>|提出了一种面向联邦增量学习的类平衡数据重放策略，通过全局协调机制和自适应温度缩放，有效解决了类不平衡...|
|🆕 发布|Latent-Info and Low-Dimensional Learning for Human Mesh Recovery and Parallel Optimization|人体网格恢复的潜在信息与低维学习及并行优化|Xiang Zhang, Suping Wu, Sheng Yang|<http://arxiv.org/pdf/2510.18267v1>|提出了一种基于潜在信息和低维学习的两阶段网络，有效利用图像特征的全局与局部信息，降低计算成本同时提高...|
|📝 更新|RAD: Training an End-to-End Driving Policy via Large-Scale 3DGS-based Reinforcement Learning|RAD：通过基于大规模3DGS的强化学习训练端到端驾驶策略|Hao Gao, Shaoyu Chen, Bo Jiang, Bencheng Liao, Yiang Shi, Xiaoyang Guo, Yuechuan Pu, Haoran Yin .etc.|<http://arxiv.org/pdf/2502.13144v2>|[代码](https://github.com/hustvl/RAD); 提出了一种基于大规模3DGS的强化学习框架，有效解决了自动驾驶中的因果混淆和开环差距问题。|
|📝 更新|Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing|无限解析器：面向版面感知的扫描文档解析强化学习|Baode Wang, Biao Wu, Weizhen Li, Meng Fang, Zuming Huang, Jun Huang, Haozhe Wang, Yanjie Liang .etc.|<http://arxiv.org/pdf/2506.03197v3>|提出了一种布局感知的强化学习框架layoutRL，通过Infinity-Parser实现了文档解析的...|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DA$^2$: Depth Anything in Any Direction|深度任意方向检测：DA$^2$|Haodong Li, Wangguangdong Zheng, Jing He, Yuhao Liu, Xin Lin, Xin Yang, Ying-Cong Chen, Chunchao Guo|<http://arxiv.org/pdf/2509.26618v3>|[代码](https://depth-any-in-any-dir.github.io/.); 提出了一种全景图像深度估计方法DA$^2$，通过数据增强和球形坐标处理，实现了高效的零样本泛化性能。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Grasp Any Region: Towards Precise, Contextual Pixel Understanding for Multimodal LLMs|抓取任意区域：面向多模态大型语言模型的精确、上下文像素理解|Haochen Wang, Yuhao Wang, Tao Zhang, Yikang Zhou, Yanwei Li, Jiacong Wang, Ye Tian, Jiahao Meng .etc.|<http://arxiv.org/pdf/2510.18876v1>|提出Grasp Any Region模型，通过全局上下文和跨提示互动提升多模态大语言模型对复杂场景的...|
|📝 更新|UniPixel: Unified Object Referring and Segmentation for Pixel-Level Visual Reasoning|统一像素级对象指引用与分割：面向像素级视觉推理|Ye Liu, Zongyang Ma, Junfu Pu, Zhongang Qi, Yang Wu, Ying Shan, Chang Wen Chen|<http://arxiv.org/pdf/2509.18094v2>|提出UniPixel模型，融合像素级感知与视觉理解能力，实现图像与语言语义的像素级对齐。|
|📝 更新|VIKI-R: Coordinating Embodied Multi-Agent Cooperation via Reinforcement Learning|VIKI-R：通过强化学习协调具身多智能体合作|Li Kang, Xiufeng Song, Heng Zhou, Yiran Qin, Jie Yang, Xiaohong Liu, Philip Torr, Lei Bai .etc.|<http://arxiv.org/pdf/2506.09049v2>|提出VIKI-Bench和VIKI-R，通过视觉输入和强化学习提升多机器人协同合作效率。|
|🆕 发布|CUARewardBench: A Benchmark for Evaluating Reward Models on Computer-using Agent|CUARewardBench：面向计算机使用代理的奖励模型评估基准|Haojia Lin, Xiaoyu Tan, Yulei Qin, Zihan Xu, Yuchen Shi, Zongyi Li, Gang Li, Shaofei Cai .etc.|<http://arxiv.org/pdf/2510.18596v1>|提出了CUARewardBench基准，评估计算机使用代理的奖励模型，通过综合分析和创新的无缝pro...|
|📝 更新|From Objects to Anywhere: A Holistic Benchmark for Multi-level Visual Grounding in 3D Scenes|从物体到任意位置：三维场景中多层次视觉定位的全面基准|Tianxu Wang, Zhuofan Zhang, Ziyu Zhu, Yue Fan, Jing Xiong, Pengxiang Li, Xiaojian Ma, Qing Li|<http://arxiv.org/pdf/2506.04897v2>|提出 holistic 3D visual grounding 基准，涵盖不同层次空间与物体定位挑战...|
|📝 更新|SceneCOT: Eliciting Grounded Chain-of-Thought Reasoning in 3D Scenes|场景COT：在三维场景中激发基于实体的链式思维推理|Xiongkun Linghu, Jiangyong Huang, Ziyu Zhu, Baoxiong Jia, Siyuan Huang|<http://arxiv.org/pdf/2510.16714v2>|提出了一种3D场景中基于地面链式思维推理的新框架，实现了类似人类的逐步推理。|
|🆕 发布|AV-Master: Dual-Path Comprehensive Perception Makes Better Audio-Visual Question Answering|AV-Master：双路径综合感知使音频-视觉问答更加出色|Jiayu Zhang, Qilang Ye, Shuo Ye, Xun Lin, Zihan Song, Zitong Yu|<http://arxiv.org/pdf/2510.18346v1>|提出双路径综合感知框架AV-Master，动态优化时序采样和模态偏好，显著提升音频视觉问答在复杂场景...|
|📝 更新|Visionary-R1: Mitigating Shortcuts in Visual Reasoning with Reinforcement Learning|Visionary-R1：利用强化学习减轻视觉推理中的捷径问题|Jiaer Xia, Yuhang Zang, Peng Gao, Yixuan Li, Kaiyang Zhou|<http://arxiv.org/pdf/2505.14677v2>|通过强化学习训练视觉语言模型进行图像推理，并采用“描述-推理-回答”格式有效减少捷径学习，提升模型泛...|
|🆕 发布|UWBench: A Comprehensive Vision-Language Benchmark for Underwater Understanding|水下理解综合视觉-语言基准：UWBench|Da Zhang, Chenggang Rong, Bingyu Li, Feiyu Wang, Zhiyuan Zhao, Junyu Gao, Xuelong Li|<http://arxiv.org/pdf/2510.18262v1>|提出了UWBench，一个针对水下视觉语言理解的全面基准，包含大量水下图像和详细注释，以促进水下环境...|
|📝 更新|LLM-RG: Referential Grounding in Outdoor Scenarios using Large Language Models|LLM-RG：利用大型语言模型在户外场景中进行参照物定位|Pranav Saxena, Avigyan Bhattacharya, Ji Zhang, Wenshan Wang|<http://arxiv.org/pdf/2509.25528v2>|提出LLM-RG方法，结合大型语言模型和视觉语言模型，有效解决户外场景中自然语言参照物定位的挑战。|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Leveraging AV1 motion vectors for Fast and Dense Feature Matching|利用AV1运动向量实现快速和密集的特征匹配|Julien Zouein, Hossein Javidnia, François Pitié, Anil Kokaram|<http://arxiv.org/pdf/2510.17434v2>|利用AV1运动向量实现快速密集特征匹配，提高匹配密度并降低CPU使用。|
|🆕 发布|GPTFace: Generative Pre-training of Facial-Linguistic Transformer by Span Masking and Weakly Correlated Text-image Data|GPTFace：通过跨度遮蔽和弱相关文本-图像数据进行面部-语言转换器的生成预训练|Yudong Li, Hao Li, Xianxu Hou, Linlin Shen|<http://arxiv.org/pdf/2510.18345v1>|提出了一种利用大规模网络构建数据自监督预训练的GPTFace模型，有效提升面部知识学习效率和面部任务...|
|📝 更新|Exploring Cross-Modal Flows for Few-Shot Learning|探索跨模态流以实现少样本学习|Ziqi Jiang, Yanghao Wang, Long Chen|<http://arxiv.org/pdf/2510.14543v2>|提出了一种多步骤调整的跨模态学习策略，有效解决了复杂数据集中模态特征纠缠问题。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|H3DE-Net: Efficient and Accurate 3D Landmark Detection in Medical Imaging|H3DE-Net：医学影像中高效准确的三维地标检测网络|Zhen Huang, Tao Tang, Ronghao Xu, Yangbo Wei, Wenkai Yang, Suhua Wang, Xiaoxin Sun, Han Li .etc.|<http://arxiv.org/pdf/2502.14221v3>|提出了一种结合CNN和轻量级注意力机制的H3DE-Net，实现了高效准确的3D医学图像标志点检测。|
|📝 更新|Interpretable Decision-Making for End-to-End Autonomous Driving|端到端自动驾驶的可解释决策制定|Mona Mirzaie, Bodo Rosenhahn|<http://arxiv.org/pdf/2508.18898v3>|提出了一种增强自动驾驶控制命令可解释性的方法，通过生成稀疏局部特征图减少违规，提高驾驶安全性。|
|🆕 发布|Image augmentation with invertible networks in interactive satellite image change detection|交互式卫星图像变化检测中的可逆网络图像增强|Hichem Sahbi|<http://arxiv.org/pdf/2510.18660v1>|提出了一种基于可逆网络的图像增强方法，有效提升了交互式卫星图像变化检测的准确性。|
|📝 更新|Regression is all you need for medical image translation|您需要的中文翻译为：“回归是医学图像转换的全部所需”|Sebastian Rassmann, David Kügler, Christian Ewert, Martin Reuter|<http://arxiv.org/pdf/2505.02048v3>|提出YODA方法，通过回归采样实现高效、高质量的医学图像转换，优于传统GANs和DMs。|
|📝 更新|Med-2E3: A 2D-Enhanced 3D Medical Multimodal Large Language Model|Med-2E3:一种二维增强的三维医疗多模态大型语言模型|Yiming Shi, Xun Zhu, Kaiwen Wang, Ying Hu, Chenyi Guo, Miao Li, Ji Wu|<http://arxiv.org/pdf/2411.12783v2>|[代码](https://github.com/MSIIP/Med-2E3); Med-2E3通过融合3D与2D图像特征，提升了医疗图像分析的泛化能力和任务表现。|
|🆕 发布|ViSE: A Systematic Approach to Vision-Only Street-View Extrapolation|ViSE：一种面向仅视觉街景外推的系统性方法|Kaiyuan Tan, Yingying Shen, Haiyang Sun, Bing Wang, Guang Chen, Hangjun Ye|<http://arxiv.org/pdf/2510.18341v1>|提出了一种四阶段管道的街景外推方法，通过生成伪LiDAR点云和利用生成先验，实现了更真实的街景扩展。|
|🆕 发布|Enhancing Few-Shot Classification of Benchmark and Disaster Imagery with ATTBHFA-Net|利用ATTBHFA-Net增强基准图像与灾害图像的少样本分类性能|Gao Yu Lee, Tanmoy Dam, Md Meftahul Ferdaus, Daniel Puiu Poenar, Vu Duong|<http://arxiv.org/pdf/2510.18326v1>|提出了一种针对灾害图像分类的 ATTBHFA-Net 方法，通过结合 Bhattacharyya 系...|
|🆕 发布|OmniNWM: Omniscient Driving Navigation World Models|全知驾驶导航世界模型：OmniNWM|Bohan Li, Zhuang Ma, Dalong Du, Baorui Peng, Zhujin Liang, Zhenqiang Liu, Chao Ma, Yueming Jin .etc.|<http://arxiv.org/pdf/2510.18313v1>|[代码](https://github.com/Arlo0o/OmniNWM.); OmniNWM通过全景视频生成与精确控制，统一框架内提升自动驾驶状态感知、行为决策和奖励学习。|
|🆕 发布|The Impact of Image Resolution on Biomedical Multimodal Large Language Models|图像分辨率对生物医学多模态大型语言模型的影响|Liangyu Chen, James Burgess, Jeffrey J Nirschl, Orr Zohar, Serena Yeung-Levy|<http://arxiv.org/pdf/2510.18304v1>|探究图像分辨率对生物医学多模态大语言模型性能的影响，提出原分辨率训练和混合分辨率训练以优化模型表现。|
|🆕 发布|TreeFedDG: Alleviating Global Drift in Federated Domain Generalization for Medical Image Segmentation|树结构联邦域泛化中的全局漂移缓解：面向医学图像分割的TreeFedDG方法|Yucheng Song, Chenxi Li, Haokang Ding, Zhining Liao, Zhifang Liao|<http://arxiv.org/pdf/2510.18268v1>|提出TreeFedDG框架，通过树状拓扑结构和参数差异风格混合方法减轻联邦学习中的全局漂移问题，提升...|
|🆕 发布|Beyond Frequency: Scoring-Driven Debiasing for Object Detection via Blueprint-Prompted Image Synthesis|超越频率：基于评分驱动的目标检测去偏置方法：通过蓝图提示的图像合成|Xinhao Cai, Liulei Li, Gensheng Pei, Tao Chen, Jinshan Pan, Yazhou Yao, Wenguan Wang|<http://arxiv.org/pdf/2510.18229v1>|提出了一种基于生成和评分驱动的去偏框架，通过精确视觉蓝图和生成对齐策略，有效提升了对象检测中代表性不...|
|🆕 发布|VelocityNet: Real-Time Crowd Anomaly Detection via Person-Specific Velocity Analysis|人群异常检测的实时实现：基于个体速度分析的VelocityNet|Fatima AlGhamdi, Omar Alharbi, Abdullah Aldwyish, Raied Aljadaany, Muhammad Kamran J Khan, Huda Alamri|<http://arxiv.org/pdf/2510.18187v1>|提出了一种结合头部检测和密集光流的双管道框架，通过个体速度分析实现了高密度人群场景中的实时异常检测。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Seg the HAB: Language-Guided Geospatial Algae Bloom Reasoning and Segmentation|《基于语言指导的地理空间藻华推理与分割》|Patterson Hsieh, Jerry Yeh, Mao-Chi He, Wen-Han Hsieh, Elvis Hsieh|<http://arxiv.org/pdf/2510.18751v1>|提出ALGOS系统，结合遥感图像理解和严重性评估，有效监测有害藻华。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|RadDiagSeg-M: A Vision Language Model for Joint Diagnosis and Multi-Target Segmentation in Radiology|放射诊断分割模型M（RadDiagSeg-M）：一种用于放射学联合诊断和多目标分割的视觉语言模型|Chengrun Li, Corentin Royer, Haozhe Luo, Bastian Wittmann, Xia Li, Ibrahim Hamamci, Sezgin Er, Anjany Sekuboyina .etc.|<http://arxiv.org/pdf/2510.18188v1>|提出了一种统一的医学视觉语言模型RadDiagSeg-M，能同时进行诊断文本生成和像素级多目标分割，...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Visible Yet Unreadable: A Systematic Blind Spot of Vision Language Models Across Writing Systems|《可见却不可读：视觉语言模型在书写系统中的系统性盲点》|Jie Zhang, Ting Xu, Gelei Deng, Runyi Hu, Han Qiu, Tianwei Zhang, Qing Guo, Ivor Tsang|<http://arxiv.org/pdf/2509.06996v4>|揭示了视觉语言模型在处理书写系统中的结构局限性，提出了构建针对符号分割和组合的新架构和训练策略。|


### 视觉认知计算 (Visual Cognitive Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DiffVLA++: Bridging Cognitive Reasoning and End-to-End Driving through Metric-Guided Alignment|DiffVLA++：通过度量引导对齐连接认知推理与端到端驾驶|Yu Gao, Anqing Jiang, Yiru Wang, Heng Yuwen, Wang Shuo, Sun Hao, Wang Jijun|<http://arxiv.org/pdf/2510.17148v2>|DiffVLA++整合认知推理与端到端驾驶，通过度量引导对齐提升自动驾驶在复杂场景的泛化能力。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Geometric Approach to Steerable Convolutions|几何方法在可 steer 性卷积中的应用|Soumyabrata Kundu, Risi Kondor|<http://arxiv.org/pdf/2510.18813v1>|提出了一种基于几何原理的直观推导方法，用于构建更稳健的 steerable 卷积神经网络。|
|📝 更新|Facial Expression-based Parkinson's Disease Severity Diagnosis via Feature Fusion and Adaptive Class Balancing|基于面部表情的帕金森病严重程度诊断：特征融合与自适应类别平衡|Yintao Zhou, Wei Huang, Zhengyu Li, Jing Huang, Meng Pang|<http://arxiv.org/pdf/2510.17373v2>|提出了一种融合多种面部表情特征的方法，通过自适应类别平衡策略，有效诊断帕金森病严重程度。|

