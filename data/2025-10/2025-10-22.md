## [UPDATED!] **2025-10-22** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing|Pico-Banana-400K：用于文本引导图像编辑的大规模数据集|Yusu Qian, Eli Bocek-Rivele, Liangchen Song, Jialing Tong, Yinfei Yang, Jiasen Lu, Wenze Hu, Zhe Gan|<http://arxiv.org/pdf/2510.19808v1>|构建了Pico-Banana-400K大规模数据集，通过精细编辑分类和质量控制，推动文本引导图像编辑...|
|🆕 发布|Detecting Latin in Historical Books with Large Language Models: A Multimodal Benchmark|利用大型语言模型检测历史书籍中的拉丁文：一种多模态基准|Yu Wu, Ke Shu, Jonas Fischer, Lidia Pivovarova, David Rosson, Eetu Mäkelä, Mikko Tolonen|<http://arxiv.org/pdf/2510.19585v1>|提出了一种利用大型语言模型从混合语言历史文档中提取拉丁文片段的新方法，并验证了其有效性。|
|📝 更新|Uni-MuMER: Unified Multi-Task Fine-Tuning of Vision-Language Model for Handwritten Mathematical Expression Recognition|统一多任务微调视觉语言模型用于手写数学表达式识别|Yu Li, Jin Jiang, Jianhua Zhu, Shuai Peng, Baole Wei, Yuxuan Zhou, Liangcai Gao|<http://arxiv.org/pdf/2505.23566v3>|[代码](https://github.com/BFlameSwift/Uni-MuMER); Uni-MuMER通过全面微调预训练的视觉语言模型，整合了三种数据驱动任务，实现了手写数学表达式识别...|
|📝 更新|How many samples to label for an application given a foundation model? Chest X-ray classification study|给定基础模型的应用需要标注多少样本？胸部X射线分类研究|Nikolay Nechaev, Evgeniia Przhezdzetskaia, Viktor Gombolevskiy, Dmitry Umerenkov, Dmitry Dylov|<http://arxiv.org/pdf/2510.11553v2>|通过使用少量标注样本和幂律预测，实现了高效 chest X-ray 分类性能。|
|🆕 发布|GigaBrain-0: A World Model-Powered Vision-Language-Action Model|《GigaBrain-0：一种基于世界模型的视觉-语言-动作模型》|GigaBrain Team, Angen Ye, Boyuan Wang, Chaojun Ni, Guan Huang, Guosheng Zhao, Haoyun Li, Jie Li .etc.|<http://arxiv.org/pdf/2510.19430v1>|提出了GigaBrain-0模型，通过使用世界模型生成数据减少对真实机器人数据的依赖，提升机器人任务...|
|📝 更新|Towards Enhanced Image Generation Via Multi-modal Chain of Thought in Unified Generative Models|通过统一生成模型中的多模态思维链增强图像生成方法|Yi Wang, Mushui Liu, Wanggui He, Hanyang Yuan, Longxiang Zhang, Ziwei Huang, Guanghao Zhang, Wenkai Fang .etc.|<http://arxiv.org/pdf/2503.01298v2>|引入多模态链式思维策略，提升统一生成模型处理复杂图像生成任务的能力。|
|📝 更新|Probing Perceptual Constancy in Large Vision-Language Models|在大型视觉-语言模型中探测感知恒常性|Haoran Sun, Bingyang Wang, Suyang Yu, Yijiang Li, Qingying Gao, Haiyun Lyu, Hokin Deng, Dezhi Luo|<http://arxiv.org/pdf/2502.10273v2>|探究了大型视觉语言模型在颜色、大小和形状恒常性方面的表现，发现模型在不同领域存在显著性能差异。|
|📝 更新|ScaleNet: Scaling up Pretrained Neural Networks with Incremental Parameters|ScaleNet：通过增量参数扩展预训练神经网络规模|Zhiwei Hao, Jianyuan Guo, Li Shen, Kai Han, Yehui Tang, Han Hu, Yunhe Wang|<http://arxiv.org/pdf/2510.18431v2>|提出了一种高效扩展预训练视觉变换器模型的方法ScaleNet，通过引入少量调整参数实现性能提升。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|QoQ-Med: Building Multimodal Clinical Foundation Models with Domain-Aware GRPO Training|QoQ-Med:基于领域感知GRPO训练构建多模态临床基础模型|Wei Dai, Peilin Chen, Chanakya Ekbote, Paul Pu Liang|<http://arxiv.org/pdf/2506.00711v2>|[代码](https://github.com/DDVD233/QoQ_Med.); 提出首个跨医疗领域多模态基础模型QoQ-Med，通过域感知强化学习优化平衡性能，提升诊断准确率。|
|🆕 发布|A Matter of Time: Revealing the Structure of Time in Vision-Language Models|时间之维：揭示视觉-语言模型中的时间结构|Nidham Tekaya, Manuela Waldner, Matthias Zeppelzauer|<http://arxiv.org/pdf/2510.19559v1>|[代码](https://tekayanidham.github.io/timeline-page); 探究视觉语言模型的时间感知能力，提出从模型嵌入空间提取时间线表示的方法。|
|🆕 发布|Reasoning Like Experts: Leveraging Multimodal Large Language Models for Drawing-based Psychoanalysis|像专家一样推理：利用多模态大型语言模型进行基于绘画的心理分析|Xueqi Ma, Yanbei Jiang, Sarah Erfani, James Bailey, Weifeng Liu, Krista A. Ehinger, Jey Han Lau|<http://arxiv.org/pdf/2510.19451v1>|提出了一种结合多模态大语言模型的框架，通过分层次分析和知识注入，实现了对视觉艺术作品的心理分析。|
|📝 更新|With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You|在多模态对齐数据有限的情况下，让结构引导你|Fabian Gröger, Shuo Wen, Huyen Le, Maria Brbić|<http://arxiv.org/pdf/2506.16895v2>|提出了一种少量样本下的多模态模型构建方法STRUCTURE，实现了高质量的多模态对齐。|
|📝 更新|The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers|摄影师之眼：教授多模态大型语言模型像摄影师一样理解图像美学|Daiqing Qi, Handong Zhao, Jing Shi, Simon Jenni, Yifei Fan, Franck Dernoncourt, Scott Cohen, Sheng Li|<http://arxiv.org/pdf/2509.18582v2>|提出了一种语言引导的多视角视觉融合模型PhotoEye，通过专业摄影师讨论构建的PhotoCriti...|
|📝 更新|Chiron-o1: Igniting Multimodal Large Language Models towards Generalizable Medical Reasoning via Mentor-Intern Collaborative Search|Chiron-o1：通过导师-实习生协作搜索点燃多模态大型语言模型，实现通用医疗推理|Haoran Sun, Yankai Jiang, Wenjie Lou, Yujie Zhang, Wenjie Li, Lilong Wang, Mianxin Liu, Lei Liu .etc.|<http://arxiv.org/pdf/2506.16962v2>|[代码](https://github.com/manglu097/Chiron-o1); 提出Mentor-Intern Collaborative Search方法，通过协作搜索生成高质量...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Weakly Supervised Food Image Segmentation using Vision Transformers and Segment Anything Model|使用视觉变换器和Segment Anything模型的弱监督食品图像分割|Ioannis Sarafis, Alexandros Papadopoulos, Anastasios Delopoulos|<http://arxiv.org/pdf/2509.19028v2>|提出了一种利用Vision Transformers和Segment Anything Model的...|
|📝 更新|VLsI: Verbalized Layers-to-Interactions from Large to Small Vision Language Models|从大到小视觉语言模型中的语言化层到交互转换研究|Byung-Kwan Lee, Ryo Hachiuma, Yu-Chiang Frank Wang, Yong Man Ro, Yueh-Hua Wu|<http://arxiv.org/pdf/2412.01822v2>|提出VLsI方法，通过层间蒸馏和自然语言映射提升小规模视觉语言模型性能，无需模型扩容。|
|📝 更新|Towards Depth Foundation Model: Recent Trends in Vision-Based Depth Estimation|面向深度基础模型：基于视觉的深度估计近期趋势|Zhen Xu, Hongyu Zhou, Sida Peng, Haotong Lin, Haoyu Guo, Jiahao Shao, Peishan Yang, Qinglin Yang .etc.|<http://arxiv.org/pdf/2507.11540v2>|提出深度基础模型，通过大规模数据训练实现深度估计的零样本泛化能力。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Explainable Face Presentation Attack Detection via Ensemble-CAM|通过集成-CAM实现的可解释人脸呈现攻击检测|Rashik Shadman, M G Sarwar Murshed, Faraz Hussain|<http://arxiv.org/pdf/2510.19695v1>|提出了一种名为Ensemble-CAM的新技术，为深度学习人脸攻击检测系统提供可视化解释，增强其透明...|
|🆕 发布|Decomposed Attention Fusion in MLLMs for Training-Free Video Reasoning Segmentation|基于分解注意力融合的多模态大型语言模型中无需训练的视频推理分割|Su Ho Han, Jeongseok Hyun, Pilhyeon Lee, Minho Shim, Dongyoon Wee, Seon Joo Kim|<http://arxiv.org/pdf/2510.19592v1>|[代码](https://github.com/HYUNJS/DecAF.); 提出Decomposed Attention Fusion方法，通过对比和互补融合机制优化视觉注意力...|
|🆕 发布|PRGCN: A Graph Memory Network for Cross-Sequence Pattern Reuse in 3D Human Pose Estimation|PRGCN：用于三维人体姿态估计中跨序列模式重用的图记忆网络|Zhuoyang Xie, Yibo Zhao, Hui Huang, Riwei Wang, Zan Gao|<http://arxiv.org/pdf/2510.19475v1>|提出了一种图记忆网络PRGCN，通过跨序列模式重用显著提升了3D人体姿态估计的准确性。|
|🆕 发布|Mitigating representation bias caused by missing pixels in methane plume detection|减轻由于甲烷羽流检测中缺失像素引起的表示偏差|Julia Wąsala, Joannes D. Maasakkers, Ilse Aben, Rochelle Schneider, Holger Hoos, Mitra Baratchi|<http://arxiv.org/pdf/2510.19478v1>|提出了一种加权重采样和多重插补方法，有效减轻卫星图像中缺失像素导致的表示偏差，提高了甲烷羽流检测的准...|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Can You Trust What You See? Alpha Channel No-Box Attacks on Video Object Detection|您能相信您所看到的吗？Alpha通道无框攻击对视频目标检测的影响|Ariana Yi, Ce Zhou, Liyang Xiao, Qiben Yan|<http://arxiv.org/pdf/2510.19574v1>|提出了一种利用视频Alpha通道的无框攻击方法，成功欺骗对象检测器而不被人类视觉察觉。|
|📝 更新|ASAP: Advancing Semantic Alignment Promotes Multi-Modal Manipulation Detecting and Grounding|ASAP：推进语义对齐促进多模态操作检测与定位|Zhenxing Zhang, Yaxiong Wang, Lechao Cheng, Zhun Zhong, Dan Guo, Meng Wang|<http://arxiv.org/pdf/2412.12718v2>|提出了一种通过增强跨模态语义对齐来提升多模态操纵检测与定位准确性的新框架ASAP。|
|📝 更新|DitHub: A Modular Framework for Incremental Open-Vocabulary Object Detection|DitHub：用于增量式开放词汇目标检测的模块化框架|Chiara Cappellino, Gianluca Mancusi, Matteo Mosconi, Angelo Porrello, Simone Calderara, Rita Cucchiara|<http://arxiv.org/pdf/2503.09271v4>|[代码](https://aimagelab.github.io/DitHub); 提出模块化框架DitHub，通过分支管理实现开放词汇对象检测的增量适应，达到最佳性能。|
|📝 更新|kabr-tools: Automated Framework for Multi-Species Behavioral Monitoring|KABR工具：多物种行为监测自动化框架|Jenna Kline, Maksim Kholiavchenko, Samuel Stevens, Nina van Tiel, Alison Zhong, Namrata Banerji, Alec Sheets, Sowbaranika Balasubramaniam .etc.|<http://arxiv.org/pdf/2510.02030v2>|提出了一种开源自动化框架kabr-tools，利用无人机视频和机器学习技术实现多物种行为监测，提高了...|
|🆕 发布|Space Object Detection using Multi-frame Temporal Trajectory Completion Method|基于多帧时间轨迹补全方法的太空目标检测|Xiaoqing Lan, Biqiao Xin, Bingshu Wang, Han Zhang, Laixian Zhang|<http://arxiv.org/pdf/2510.19220v1>|提出了一种多帧时空轨迹补全方法，有效提高了地球静止轨道空间目标检测的准确性和鲁棒性。|
|🆕 发布|Malaria Detection from Blood Cell Images Using XceptionNet|基于XceptionNet的血液细胞图像疟疾检测|Warisa Nusrat, Mostafijur Rahman, Ayatullah Faruk Mollah|<http://arxiv.org/pdf/2510.19182v1>|利用XceptionNet深度网络从血细胞图像中提取特征，实现了高准确率的疟疾自动检测。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Training-Free Framework for Open-Vocabulary Image Segmentation and Recognition with EfficientNet and CLIP|无训练框架的开词汇图像分割与识别：结合EfficientNet与CLIP方法|Ying Dai, Wei Yu Chen|<http://arxiv.org/pdf/2510.19333v1>|提出了一种无需训练的框架，结合EfficientNet和CLIP实现开放词汇图像分割与识别，达到领先...|
|📝 更新|Where are we with calibration under dataset shift in image classification?|在图像分类中，数据集偏移下的标定技术现状如何？|Mélanie Roschewitz, Raghav Mehta, Fabio de Sousa Ribeiro, Ben Glocker|<http://arxiv.org/pdf/2507.07780v2>|研究了图像分类中数据集偏移下的校准问题，提出了有效的后处理和训练中校准策略。|


## 生成式视觉模型 (Generative Visual Modeling)


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Context-Aware Pseudo-Label Scoring for Zero-Shot Video Summarization|零样本视频摘要中的上下文感知伪标签评分|Yuanli Wu, Long Zhang, Yue Du, Bin Li|<http://arxiv.org/pdf/2510.17501v3>|提出了一种基于评分的零样本视频摘要框架，通过伪标签和上下文提示稳定了大型语言模型的性能。|
|📝 更新|ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints|影像搜索：超越语义依赖约束的适应性测试时视频生成搜索|Meiqi Wu, Jiashu Zhu, Xiaokun Feng, Chubin Chen, Chen Zhu, Bingze Song, Fangyuan Mao, Jiahong Wu .etc.|<http://arxiv.org/pdf/2510.14847v2>|提出了一种自适应测试时搜索策略ImagerySearch，通过动态调整搜索空间和奖励函数，有效提升了...|
|🆕 发布|Addressing the Depth-of-Field Constraint: A New Paradigm for High Resolution Multi-Focus Image Fusion|解决景深约束：高分辨率多焦点图像融合的新范式|Luca Piano, Peng Huanwen, Radu Ciprian Bilcu|<http://arxiv.org/pdf/2510.19581v1>|提出VAEEDOF方法，通过高效图像重建解决多焦点图像融合的深度场限制问题，实现无缝融合效果。|
|🆕 发布|Exploring Scale Shift in Crowd Localization under the Context of Domain Generalization|探索域泛化背景下人群定位中的尺度转换|Juncheng Wang, Lei Shang, Ziqi Liu, Wang Lu, Xixu Hu, Zhe Hu, Jindong Wang, Shujun Wang|<http://arxiv.org/pdf/2510.19330v1>|探究并缓解了群定位中的尺度偏移问题，提出了有效的Causal Feature Decompositi...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OmniMotion-X: Versatile Multimodal Whole-Body Motion Generation|全方位运动X：多模态全身运动生成通用方法|Guowei Xu, Yuxuan Bian, Ailing Zeng, Mingyi Shi, Shaoli Huang, Wen Li, Lixin Duan, Qiang Xu|<http://arxiv.org/pdf/2510.19789v1>|提出了OmniMotion-X框架，通过统一序列到序列的方式，实现了多样化模态的人体全身运动生成。|
|🆕 发布|A Survey on Cache Methods in Diffusion Models: Toward Efficient Multi-Modal Generation|《扩散模型中缓存方法的综述：迈向高效的多模态生成》|Jiacheng Liu, Xinyu Wang, Yuqi Lin, Zhikai Wang, Peiru Wang, Peiliang Cai, Qinming Zhou, Zhengan Yan .etc.|<http://arxiv.org/pdf/2510.19755v1>|提出了一种无需训练、适用于多种架构的扩散缓存方法，通过识别和重用扩散过程中的计算冗余，有效降低生成模...|
|🆕 发布|From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction|从预测到规划：协同状态-动作预测的策略世界模型|Zhida Zhao, Talas Fu, Yifan Wang, Lijun Wang, Huchuan Lu|<http://arxiv.org/pdf/2510.19654v1>|[代码](https://github.com/6550Zhao/Policy-World-Model.); 提出了一种集世界模型与轨迹规划于一体的Policy World Model，通过未来状态预测提升了规...|
|🆕 发布|Pragmatic Heterogeneous Collaborative Perception via Generative Communication Mechanism|通过生成性通信机制的语用异质协同感知|Junfei Zhou, Penglin Dai, Quanmin Wei, Bingyi Liu, Xiao Wu, Jianping Wang|<http://arxiv.org/pdf/2510.19618v1>|[代码](https://github.com/jeffreychou777/GenComm.); 提出了一种生成通信机制，通过特征生成和轻量级空间信息对齐，实现了异构多智能体系统间的无缝感知合作。|
|🆕 发布|The Intricate Dance of Prompt Complexity, Quality, Diversity, and Consistency in T2I Models|《在T2I模型中提示复杂性、质量、多样性和一致性的复杂舞动》|Xiaofeng Zhang, Aaron Courville, Michal Drozdzal, Adriana Romero-Soriano|<http://arxiv.org/pdf/2510.19557v1>|探究了提示复杂性对合成数据质量、多样性和一致性的影响，并提出了新的评估框架。|
|🆕 发布|PoseCrafter: Extreme Pose Estimation with Hybrid Video Synthesis|姿态创造者：基于混合视频合成的极限姿态估计|Qing Mao, Tianxin Huang, Yu Zhu, Jinqiu Sun, Yanning Zhang, Gim Hee Lee|<http://arxiv.org/pdf/2510.19527v1>|提出了Hybrid Video Generation和Feature Matching Select...|
|🆕 发布|Predicting before Reconstruction: A generative prior framework for MRI acceleration|预测先于重建：一种用于MRI加速的生成先验框架|Juhyung Park, Rokgi Hong, Roh-Eul Yoo, Jaehyeon Koo, Se Young Chun, Seung Hong Choi, Jongho Lee|<http://arxiv.org/pdf/2510.19472v1>|提出了一种预测性成像框架，通过生成模型预测目标图像作为先验，加速MRI重建过程。|
|🆕 发布|PCP-GAN: Property-Constrained Pore-scale image reconstruction via conditional Generative Adversarial Networks|PCP-GAN：基于条件生成对抗网络的属性约束孔隙尺度图像重建|Ali Sadeghkhani, Brandon Bennett, Masoud Babaei, Arash Rabbani|<http://arxiv.org/pdf/2510.19465v1>|提出了一种多条件生成对抗网络框架，精确控制孔隙图像属性，解决了地下表征的代表性和数据稀缺问题。|
|📝 更新|Brain3D: Generating 3D Objects from fMRI|脑3D：从fMRI生成三维物体|Yuankun Yang, Li Zhang, Ziyang Xie, Zhiyuan Yuan, Jianfeng Feng, Xiatian Zhu, Yu-Gang Jiang|<http://arxiv.org/pdf/2405.15239v5>|[代码](https://brain-3d.github.io/.); 提出了一种将fMRI信号转化为3D物体的方法Brain3D，实现了对脑信号的高级语义解析和功能建模。|
|🆕 发布|D2D: Detector-to-Differentiable Critic for Improved Numeracy in Text-to-Image Generation|D2D: 用于提升文本到图像生成数值准确性的检测器到可微分评判器方法|Nobline Yoo, Olga Russakovsky, Ye Zhu|<http://arxiv.org/pdf/2510.19278v1>|提出了一种将非微分检测模型转化为微分评判器的D2D框架，有效提升了文本到图像生成中物体数量的准确性。|
|🆕 发布|Advances in 4D Representation: Geometry, Motion, and Interaction|四维表示的进展：几何、运动与交互|Mingrui Zhao, Sauradip Nag, Kai Wang, Aditya Vora, Guangda Ji, Peter Chun, Ali Mahdavi-Amiri, Hao Zhang|<http://arxiv.org/pdf/2510.19255v1>|[代码](https://mingrui-zhao.github.io/4DRep-GMI); 综述了4D表示方法，强调如何根据任务需求选择和定制几何、运动和交互的4D模型。|
|📝 更新|Chimera: Compositional Image Generation using Part-based Concepting|“奇美拉：基于部分概念组合的图像生成方法”|Shivam Singh, Yiming Chen, Agneet Chatterjee, Amit Raj, James Hays, Yezhou Yang, Chitta Baral|<http://arxiv.org/pdf/2510.18083v2>|提出了一种基于文本指导的图像生成模型Chimera，通过组合不同源图像的特定部分来生成新颖对象。|
|🆕 发布|Video Consistency Distance: Enhancing Temporal Consistency for Image-to-Video Generation via Reward-Based Fine-Tuning|视频一致性距离：通过基于奖励的微调增强图像到视频生成的时序一致性|Takehiro Aoshima, Yusuke Shinohara, Park Byeongseon|<http://arxiv.org/pdf/2510.19193v1>|提出Video Consistency Distance（VCD）增强图像转视频时的时间一致性，通过...|
|📝 更新|FairGen: Controlling Sensitive Attributes for Fair Generations in Diffusion Models via Adaptive Latent Guidance|FairGen：通过自适应潜在引导控制敏感属性以实现扩散模型中的公平生成|Mintong Kang, Vinayshekhar Bannihatti Kumar, Shamik Roy, Abhishek Kumar, Sopan Khosla, Balakrishnan Murali Narayanaswamy, Rashmi Gangadharaiah|<http://arxiv.org/pdf/2503.01872v2>|提出FairGen方法，通过自适应隐空间引导降低扩散模型生成偏见，同时保持生成质量。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|olmOCR 2: Unit Test Rewards for Document OCR|olmOCR 2：文档OCR的单位测试奖励|Jake Poznanski, Luca Soldaini, Kyle Lo|<http://arxiv.org/pdf/2510.19817v1>|提出了一种基于强化学习和可验证奖励的OCR系统，大幅提升了数学公式、表格和多栏文本的识别准确性。|
|📝 更新|Variable Rate Image Compression via N-Gram Context based Swin-transformer|基于N-Gram上下文的Swin变换器实现的可变率图像压缩|Priyanka Mudgal|<http://arxiv.org/pdf/2510.00058v2>|引入N-gram上下文的Swin Transformer实现可变率图像压缩，扩展了考虑区域，提升了高...|
|📝 更新|Uni-Instruct: One-step Diffusion Model through Unified Diffusion Divergence Instruction|统一指令一步扩散模型：通过统一扩散发散指令|Yifei Wang, Weimin Bai, Colin Zhang, Debing Zhang, Weijian Luo, He Sun|<http://arxiv.org/pdf/2505.20755v4>|统一了超过10种一步扩散蒸馏方法，提出扩散扩展理论，实现了最优的一步扩散模型训练效果。|
|🆕 发布|CBDiff:Conditional Bernoulli Diffusion Models for Image Forgery Localization|CBDiff：条件伯努利扩散模型用于图像伪造定位|Zhou Lei, Pan Gang, Wang Jiahao, Sun Di|<http://arxiv.org/pdf/2510.19597v1>|提出了一种生成多张定位图的Conditional Bernoulli Diffusion Model...|
|📝 更新|One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution|一步扩散实现细节丰富且时间一致的视频超分辨率|Yujing Sun, Lingchen Sun, Shuaizheng Liu, Rongyuan Wu, Zhengqiang Zhang, Lei Zhang|<http://arxiv.org/pdf/2506.15591v3>|[代码](https://github.com/yjsunnn/DLoRAL.); 提出了一种双LoRA学习框架，通过迭代优化实现视频超分辨率中的细节丰富和时序一致性。|
|📝 更新|REPA-E: Unlocking VAE for End-to-End Tuning with Latent Diffusion Transformers|REPA-E：使用潜在扩散变换器解锁vae的端到端微调|Xingjian Leng, Jaskirat Singh, Yunzhong Hou, Zhenchang Xing, Saining Xie, Liang Zheng|<http://arxiv.org/pdf/2504.10483v3>|定位了vae与扩散模型端到端训练的关键问题，提出REPA-E方法，大幅提升训练效率和生成质量。|
|📝 更新|MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset|多环境、多物种、低空无人机数据集（MMLA）|Jenna Kline, Samuel Stevens, Guy Maalouf, Camille Rondeau Saint-Jean, Dat Nguyen Ngoc, Majid Mirmehdi, David Guerin, Tilo Burghardt .etc.|<http://arxiv.org/pdf/2504.07744v3>|提出多环境、多物种低空无人机数据集MMLA，通过在多样化环境中收集数据，有效提升了动物检测模型的准确...|
|🆕 发布|SCEESR: Semantic-Control Edge Enhancement for Diffusion-Based Super-Resolution|语义控制边缘增强用于扩散型超分辨率重建|Yun Kai Zhuang|<http://arxiv.org/pdf/2510.19272v1>|[代码](https://github.com/ARBEZ-ZEBRA/SCEESR.); 提出了一种结合语义边缘引导的扩散模型增强框架，有效平衡了超分辨率图像的质量和生成速度。|
|📝 更新|Latent Diffusion Models with Masked AutoEncoders|带有遮蔽自编码器的潜在扩散模型|Junho Lee, Jeongwoo Shin, Hyungwook Choi, Joonseok Lee|<http://arxiv.org/pdf/2507.09984v3>|[代码](https://github.com/isno0907/ldmae.); 提出新型Variational Masked AutoEncoders，优化了Latent Diff...|
|📝 更新|Flexible-length Text Infilling for Discrete Diffusion Models|《面向离散扩散模型的灵活长度文本填充》|Andrew Zhang, Anushka Sivakumar, Chiawei Tang, Chris Thomas|<http://arxiv.org/pdf/2506.13579v2>|提出DDOT模型，通过结合最优传输耦合，实现了离散扩散模型中灵活长度和位置的文本填充。|
|📝 更新|VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation|VO-DP：面向视觉独驱机器人操作的任务语义-几何自适应扩散策略|Zehao Ni, Yonghao He, Lingfeng Qian, Jilei Mao, Fa Fu, Wei Sui, Hu Su, Junran Peng .etc.|<http://arxiv.org/pdf/2510.15530v2>|提出了一种视觉基础模型驱动的机器人操作方法，实现了语义与几何特征的深度融合，显著提升了真实与模拟环境...|
|📝 更新|Learning What Matters: Steering Diffusion via Spectrally Anisotropic Forward Noise|学习关键所在：通过频谱各向异性前向噪声引导扩散|Luca Scimeca, Thomas Jiralerspong, Berton Earnshaw, Jason Hartford, Yoshua Bengio|<http://arxiv.org/pdf/2510.09660v3>|引入各向异性噪声操作以优化扩散模型训练，提升数据分布适应性并实现选择性忽略特定频段。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|WikiVideo: Article Generation from Multiple Videos|《WikiVideo：从多个视频生成文章》|Alexander Martin, Reno Kriz, William Gantt Walden, Kate Sanders, Hannah Recknor, Eugene Yang, Francis Ferraro, Benjamin Van Durme|<http://arxiv.org/pdf/2504.00939v2>|提出了一种结合视频和文本的协同创作方法，用于生成深入且证据充分的文章。|
|📝 更新|MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models|MUG-V 10B：大型视频生成模型的高效训练管道|Yongshun Zhang, Zhongyi Fan, Yonghang Zhang, Zhangzikang Li, Weifeng Chen, Zhongwei Feng, Chaoyue Wang, Peng Hou .etc.|<http://arxiv.org/pdf/2510.17519v2>|[代码](https://github.com/Shopee-MUG/MUG-V.); 提出高效训练框架MUG-V 10B，优化数据处理、模型架构、训练策略和基础设施，实现大规模视频生成模...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|How to Evaluate Monocular Depth Estimation?|如何评估单目深度估计？|Siyang Wu, Jack Nugent, Willow Yang, Jia Deng|<http://arxiv.org/pdf/2510.19814v1>|[代码](https://github.com/princeton-vl/evalmde.); 提出了一种新的评估单目深度估计的方法，通过分析现有指标并引入基于相对表面法线的指标，以更接近人类判断...|
|🆕 发布|[De&#124;Re]constructing VLMs' Reasoning in Counting|[解构&#124;重构]视觉语言模型的计数推理|Simone Alghisi, Gabriel Roccabruna, Massimo Rizzoli, Seyed Mahed Mousavi, Giuseppe Riccardi|<http://arxiv.org/pdf/2510.19555v1>|揭示了视觉语言模型在计数任务中的局限，并提出了针对性的训练方法来提升其推理能力。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Discretized Gaussian Representation for Tomographic Reconstruction|离散高斯表示法在断层成像重建中的应用|Shaokai Wu, Yuxiang Lu, Yapan Guo, Wei Ji, Suizhi Huang, Fengyu Yang, Shalayiding Sirejiding, Qichen He .etc.|<http://arxiv.org/pdf/2411.04844v4>|[代码](https://github.com/wskingdom/DGR.); 提出离散高斯表示法（DGR）直接用高斯函数重建三维体积，大幅提升CT重建质量和效率。|
|🆕 发布|Spatio-temporal Sign Language Representation and Translation|空间时间手语表示与翻译|Yasser Hamidullah, Josef van Genabith, Cristina España-Bonet|<http://arxiv.org/pdf/2510.19413v1>|提出了一种端到端的时空特征学习与翻译模型，提高了手语翻译的泛化能力。|
|🆕 发布|AegisRF: Adversarial Perturbations Guided with Sensitivity for Protecting Intellectual Property of Neural Radiance Fields|"AegisRF：基于敏感性的对抗扰动引导保护神经辐射场知识产权"|Woo Jae Kim, Kyu Beom Han, Yoonki Cho, Youngju Na, Junsik Jung, Sooel Son, Sung-eui Yoon|<http://arxiv.org/pdf/2510.19371v1>|[代码](https://github.com/wkim97/AegisRF.); 提出了一种通过注入对抗性扰动并自适应约束几何扰动来保护神经辐射场知识产权的方法，实现了渲染质量与版权...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Beyond sparse denoising in frames: minimax estimation with a scattering transform|帧内稀疏去噪之外：基于散射变换的最小最大估计|Nathanaël Cuvelle--Magar, Stéphane Mallat|<http://arxiv.org/pdf/2510.19612v1>|提出了一种基于散射变换的图像去噪方法，通过最小化和最大化散射系数的$\ell^1$范数，实现了对卡通...|
|🆕 发布|Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes|跨视角观察：在机器人场景中评估视觉语言模型的空间推理基准|Zhiyuan Feng, Zhaolu Kang, Qijie Wang, Zhiying Du, Jiongrui Yan, Shubin Shi, Chengbo Yuan, Huizhi Liang .etc.|<http://arxiv.org/pdf/2510.19400v1>|提出MV-RoboBench基准，评估视觉语言模型在机器人场景中的多视角空间推理能力。|
|📝 更新|FLARE: Feed-forward Geometry, Appearance and Camera Estimation from Uncalibrated Sparse Views|FLARE：从未校准稀疏视角中前馈几何、外观和相机估计|Shangzan Zhang, Jianyuan Wang, Yinghao Xu, Nan Xue, Christian Rupprecht, Xiaowei Zhou, Yujun Shen, Gordon Wetzstein|<http://arxiv.org/pdf/2502.12138v5>|[代码](https://zhanghe3z.github.io/FLARE); FLARE通过级联学习范式，从少量未校准图像中高效估计相机姿态和3D结构，实现领先性能。|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Is This Tracker On? A Benchmark Protocol for Dynamic Tracking|这是追踪器开启了吗？动态追踪基准协议|Ilona Demler, Saumya Chauhan, Georgia Gkioxari|<http://arxiv.org/pdf/2510.19819v1>|提出ITTO基准，针对现实场景中点追踪的挑战进行评估和诊断，揭示了现有追踪方法的不足。|
|🆕 发布|HAD: Hierarchical Asymmetric Distillation to Bridge Spatio-Temporal Gaps in Event-Based Object Tracking|基于层次不对称蒸馏以桥接事件驱动目标跟踪中的时空差距：HAD方法|Yao Deng, Xian Zhong, Wenxuan Liu, Zhaofei Yu, Jingling Yuan, Tiejun Huang|<http://arxiv.org/pdf/2510.19560v1>|提出了一种多模态知识蒸馏框架 Hierarchical Asymmetric Distillatio...|
|🆕 发布|Multi-Camera Worker Tracking in Logistics Warehouse Considering Wide-Angle Distortion|物流仓库中考虑广角畸变的多人摄像头工人追踪|Yuki Mori, Kazuma Kano, Yusuke Asai, Shin Katayama, Kenta Urano, Takuro Yonezawa, Nobuo Kawaguchi|<http://arxiv.org/pdf/2510.19432v1>|提出了一种利用19个广角摄像头进行仓库工人追踪的方法，通过校正图像畸变提高了追踪准确度超过20%。|
|📝 更新|SAM 2++: Tracking Anything at Any Granularity|SAM 2++：任意粒度下跟踪任意目标|Jiaming Zhang, Cheng Liang, Yichun Yang, Chenkai Zeng, Yutao Cui, Xinwen Zhang, Xin Zhou, Kai Ma .etc.|<http://arxiv.org/pdf/2510.18822v2>|提出了SAM 2++模型，实现了视频跟踪任务在不同粒度下的统一处理，提升了跟踪准确性和泛化能力。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Video-R1: Reinforcing Video Reasoning in MLLMs|视频R1：在多模态大型语言模型中强化视频推理|Kaituo Feng, Kaixiong Gong, Bohao Li, Zonghao Guo, Yibing Wang, Tianshuo Peng, Junfei Wu, Xiaoying Zhang .etc.|<http://arxiv.org/pdf/2503.21776v4>|[代码](https://github.com/tulerfeng/Video-R1.); 首次提出T-GRPO算法，结合图像数据，增强大型多模态语言模型视频推理能力。|
|📝 更新|FeatureFool: Zero-Query Fooling of Video Models via Feature Map|特征愚弄：通过特征图实现对视频模型的零查询欺骗|Duoxun Tang, Xi Xiao, Guangwu Hu, Kangkang Sun, Xiao Yang, Dongyang Chen, Qing Li, Yongjie Yin .etc.|<http://arxiv.org/pdf/2510.18362v2>|提出了一种无需查询的零查询攻击方法FeatureFool，通过直接利用神经网络提取的信息改变视频特征...|
|🆕 发布|X-Ego: Acquiring Team-Level Tactical Situational Awareness via Cross-Egocentric Contrastive Video Representation Learning|Learning 《X-Ego：通过跨自我中心对比视频表征学习获取团队级战术态势感知》|Yunzhe Wang, Soham Hans, Volkan Ustun|<http://arxiv.org/pdf/2510.19150v1>|[代码](https://github.com/HATS-ICT/x-ego.); 提出了一种同步跨第一人称视角的对比学习策略，增强了团队战术情境感知能力。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LyTimeT: Towards Robust and Interpretable State-Variable Discovery|面向鲁棒性和可解释性的状态变量发现：LyTimeT|Kuai Yu, Crystal Su, Xiang Liu, Judah Goldfeder, Mingyuan Shao, Hod Lipson|<http://arxiv.org/pdf/2510.19716v1>|提出了一种两阶段框架LyTimeT，通过时空注意力和稳定性约束从高维视频提取解释性状态变量，实现了准...|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vision-Based Mistake Analysis in Procedural Activities: A Review of Advances and Challenges|基于视觉的程序活动错误分析：进展与挑战综述|Konstantinos Bacharidis, Antonis A. Argyros|<http://arxiv.org/pdf/2510.19292v1>|综述了基于视觉的流程活动错误检测方法，提出了应对挑战的统一视角。|
|🆕 发布|MobiAct: Efficient MAV Action Recognition Using MobileNetV4 with Contrastive Learning and Knowledge Distillation|"基于MobileNetV4、对比学习与知识蒸馏的微型空中机器人动作识别方法MobiAct：高效实现"|Zhang Nengbo, Ho Hann Woei|<http://arxiv.org/pdf/2510.19273v1>|提出了一种高效的微型无人机动作识别框架MobiAct，通过MobileNetV4网络和知识蒸馏技术实...|
|📝 更新|FST.ai 2.0: An Explainable AI Ecosystem for Fair, Fast, and Inclusive Decision-Making in Olympic and Paralympic Taekwondo|FST.ai 2.0：面向奥运会和残奥会跆拳道公平、快速、包容性决策的可解释人工智能生态系统|Keivan Shariatmadar, Ahmad Osman, Ramin Ray, Kisam Kim|<http://arxiv.org/pdf/2510.18193v2>|提出FST.ai 2.0系统，通过实时动作识别和决策支持减少评审时间并提升信任度。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Learning Differential Pyramid Representation for Tone Mapping|学习差分金字塔表示法进行色调映射|Qirui Yang, Yinbo Li, Yihao Liu, Peng-Tao Jiang, Fangpu Zhang, Qihua Cheng, Huanjing Yue, Jingyu Yang|<http://arxiv.org/pdf/2412.01463v2>|[代码](https://xxxxxxdprnet.github.io/DPRNet); 提出了一种自适应差分金字塔网络，有效平衡全局色调一致性和局部对比度增强，实现了高保真度色调映射。|
|📝 更新|ProCLIP: Progressive Vision-Language Alignment via LLM-based Embedder|ProCLIP: 通过基于大规模语言模型嵌入器的渐进式视觉-语言对齐|Xiaoxing Hu, Kaicheng Yang, Ziyang Gong, Qi Ming, Zonghao Guo, Xiang An, Ziyong Feng, Junchi Yan .etc.|<http://arxiv.org/pdf/2510.18795v2>|[代码](https://github.com/VisionXLab/ProCLIP.); 提出ProCLIP框架，通过逐步对齐图像编码器和基于LLM的文本编码器，提升处理长文本和多语言能力。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Optimized 3D Gaussian Splatting using Coarse-to-Fine Image Frequency Modulation|使用粗到细图像频率调制优化的三维高斯散点绘制|Umar Farooq, Jean-Yves Guillemaut, Adrian Hilton, Marco Volino|<http://arxiv.org/pdf/2503.14475v2>|提出了一种优化3D高斯散点框架，通过频率调制减少了内存需求并保持了视觉效果。|
|📝 更新|SparseWorld: A Flexible, Adaptive, and Efficient 4D Occupancy World Model Powered by Sparse and Dynamic Queries|稀疏世界：一种由稀疏动态查询驱动的灵活、自适应且高效的四维占据世界模型|Chenxu Dang, Haiyan Liu, Guangjun Bao, Pei An, Xinyue Tang, An Pan, Jie Ma, Bingchuan Sun .etc.|<http://arxiv.org/pdf/2510.17482v2>|[代码](https://github.com/MSunDYY/SparseWorld.); 提出SparseWorld模型，通过稀疏动态查询实现灵活、自适应且高效的4D占用世界表示。|
|🆕 发布|CARES: Context-Aware Resolution Selector for VLMs|具有上下文感知分辨率的VLM选择器：CARES|Moshe Kimhi, Nimrod Shabtay, Raja Giryes, Chaim Baskin, Eli Schwartz|<http://arxiv.org/pdf/2510.19496v1>|提出了一种智能分辨率选择器CARES，通过预测最小必要输入分辨率，大幅降低大型视觉语言模型的计算负担...|
|🆕 发布|PruneHal: Reducing Hallucinations in Multi-modal Large Language Models through Adaptive KV Cache Pruning|《PruneHal：通过自适应键值缓存剪枝减少多模态大型语言模型中的幻觉现象》|Fengyuan Sun, Hui Chen, Xinhao Xu, Dandan Zheng, Jingdong Chen, Jun Zhou, Jungong Han, Guiguang Ding|<http://arxiv.org/pdf/2510.19183v1>|提出了一种无需额外训练、通过自适应键值缓存剪枝减少多模态大语言模型幻觉现象的有效方法。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks|自适应分布感知量化方法用于混合精度神经网络|Shaohang Jia, Zhiyong Huang, Zhi Yu, Mingyang Hou, Shuai Miao, Han Yang|<http://arxiv.org/pdf/2510.19760v1>|提出了一种自适应分布感知量化方法，有效解决了神经网络权重量化和激活量化中的分布不均和静态码本问题。|
|📝 更新|Spiking Neural Networks Need High Frequency Information|尖峰神经网络需要高频信息|Yuetong Fang, Deming Zhou, Ziqing Wang, Hongwei Ren, ZeCui Zeng, Lusong Li, Shibo Zhou, Renjing Xu|<http://arxiv.org/pdf/2505.18608v3>|[代码](https://github.com/bic-L/MaxFormer.); 揭示了Spiking Neural Networks中的频率偏差问题，并通过Max-Former网络...|
|📝 更新|MINGLE: Mixture of Null-Space Gated Low-Rank Experts for Test-Time Continual Model Merging|MINGLE：测试时持续模型合并的零空间门控低秩专家混合方法|Zihuan Qiu, Yi Xu, Chiyuan He, Fanman Meng, Linfeng Xu, Qingbo Wu, Hongliang Li|<http://arxiv.org/pdf/2505.11883v3>|[代码](https://github.com/zihuanqiu/MINGLE); 提出MINGLE框架，通过测试时模型合并和低秩专家动态适应，有效解决持续学习中的遗忘和分布偏移问题。|
|🆕 发布|DaMo: Data Mixing Optimizer in Fine-tuning Multimodal LLMs for Mobile Phone Agents|DaMo：面向手机代理的细粒度多模态大型语言模型微调中的数据混合优化器|Kai Shi, Jun Yang, Ni Yang, Binqiang Pan, Qingsong Xie, Chao Zhang, Zhenyu Yang, Tianhuang Su .etc.|<http://arxiv.org/pdf/2510.19336v1>|[代码](https://github.com/OPPO-Mente-Lab/DaMo.git); 提出DaMo优化器，通过预测任务表现自动调整多模态数据混合，提升移动端多任务性能。|
|🆕 发布|MoE-GS: Mixture of Experts for Dynamic Gaussian Splatting|MoE-GS: 用于动态高斯散点的专家混合模型|In-Hwan Jin, Hyeongju Mun, Joonsoo Kim, Kugjin Yun, Kyeongbo Kong|<http://arxiv.org/pdf/2510.19210v1>|提出了一种融合多个专家的动态高斯散点框架，通过体积感知像素路由器提升动态场景重建的一致性和效率。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning|《备忘：使用强化学习训练内存高效的具身智能体》|Gunshi Gupta, Karmesh Yadav, Zsolt Kira, Yarin Gal, Rahaf Aljundi|<http://arxiv.org/pdf/2510.19732v1>|提出了一种基于变压器的记忆增强强化学习架构Memo，有效处理长时序任务中的记忆问题，提高了计算和存储...|
|🆕 发布|Augmenting Moment Retrieval: Zero-Dependency Two-Stage Learning|增强矩检索：零依赖两阶段学习|Zhengxuan Wei, Jiajin Tang, Sibei Yang|<http://arxiv.org/pdf/2510.19622v1>|提出了一种零依赖性的增强瞬间检索框架AMR，通过两阶段学习有效解决了数据稀缺、边界模糊和细粒度语义区...|
|🆕 发布|Digitizing Paper ECGs at Scale: An Open-Source Algorithm for Clinical Research|大规模数字化纸质心电图：面向临床研究的开源算法|Elias Stenhede, Agnar Martin Bjørnstad, Arian Ranjbar|<http://arxiv.org/pdf/2510.19590v1>|提出了一种自动化的开源算法，将纸质心电图转换为数字信号，提升了临床研究的可用性和AI诊断的普及。|
|🆕 发布|Multi-modal Co-learning for Earth Observation: Enhancing single-modality models via modality collaboration|多模态协同学习用于地球观测：通过模态协作增强单模态模型|Francisco Mena, Dino Ienco, Cassio F. Dantas, Roberto Interdonato, Andreas Dengel|<http://arxiv.org/pdf/2510.19579v1>|提出了一种多模态协同学习框架，通过不同模态间的信息共享，有效提升了单模态模型在地球观测数据上的预测性...|
|🆕 发布|Exploring "Many in Few" and "Few in Many" Properties in Long-Tailed, Highly-Imbalanced IC Defect Classification|探索长尾、高度不平衡的集成电路缺陷分类中的“多中见少”与“少中见多”特性|Hao-Chiang Shao, Chun-Hao Chang, Yu-Hsien Lin, Chia-Wen Lin, Shao-Yun Fang, Yan-Hsiu Liu|<http://arxiv.org/pdf/2510.19463v1>|提出ReCAME-Net模型，针对IC缺陷分类中的高度不平衡数据，通过多专家框架和区域注意力机制提升...|
|🆕 发布|Automated Morphological Analysis of Neurons in Fluorescence Microscopy Using YOLOv8|基于YOLOv8的荧光显微镜下神经元自动形态学分析|Banan Alnemri, Arwa Basbrain|<http://arxiv.org/pdf/2510.19455v1>|利用YOLOv8实现神经元自动形态分析，大幅提升荧光显微镜图像处理效率和精确度。|
|🆕 发布|Online Handwritten Signature Verification Based on Temporal-Spatial Graph Attention Transformer|基于时空图注意力变换器的在线手写签名验证|Hai-jie Yuan, Heng Zhang, Fei Yin|<http://arxiv.org/pdf/2510.19321v1>|提出了一种基于图注意力变换器的动态手写签名验证方法，有效提升了认证准确性和抗伪造能力。|
|🆕 发布|Unified Reinforcement and Imitation Learning for Vision-Language Models|统一强化学习与模仿学习在视觉语言模型中的应用|Byung-Kwan Lee, Ryo Hachiuma, Yong Man Ro, Yu-Chiang Frank Wang, Yueh-Hua Wu|<http://arxiv.org/pdf/2510.19307v1>|提出Unified Reinforcement and Imitation Learning算法，通...|
|🆕 发布|Background Fades, Foreground Leads: Curriculum-Guided Background Pruning for Efficient Foreground-Centric Collaborative Perception|背景消退，前景引领：以课程为指导的背景剪枝策略实现高效的前景中心协同感知|Yuheng Wu, Xiangbo Gao, Quang Tau, Zhengzhong Tu, Dongman Lee|<http://arxiv.org/pdf/2510.19250v1>|提出了一种前景中心化的感知框架FadeLead，通过逐步剪除背景信息，将背景上下文融入紧凑的前景特征...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Class-Aware Prototype Learning with Negative Contrast for Test-Time Adaptation of Vision-Language Models|具有负对比的类感知原型学习以实现视觉语言模型测试时的适应|Xiaozhen Qiao, Jingkai Zhao, Yuqiu Jiang, Xianda Guo, Zhe Sun, Hongyuan Zhang, Xuelong Li|<http://arxiv.org/pdf/2510.19802v1>|提出了一种针对视觉语言模型的测试时适应方法CPL-NC，通过动态调整类原型和负对比学习增强模型在分布...|
|🆕 发布|FrogDeepSDM: Improving Frog Counting and Occurrence Prediction Using Multimodal Data and Pseudo-Absence Imputation|青蛙深度空间分布模型：利用多模态数据与伪缺失值填充提高青蛙计数与出现预测|Chirag Padubidri, Pranesh Velmurugan, Andreas Lanitis, Andreas Kamilaris|<http://arxiv.org/pdf/2510.19305v1>|通过融合多模态数据和伪缺失值填充，本研究提升了青蛙计数和分布预测的准确性。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety Evaluation via Role-Specialized Collaboration|雷达：一种基于角色专业化协作的面向大型语言模型安全性评估的风险感知动态多智能体框架|Xiuyuan Chen, Jian Zhao, Yuchen Yuan, Tianle Zhang, Huilin Zhou, Zheng Zhu, Ping Hu, Linghe Kong .etc.|<http://arxiv.org/pdf/2509.25271v3>|提出了一种风险感知的多智能体协作框架RADAR，通过角色专业化合作和动态更新机制，有效提升了大型语言...|
|📝 更新|Adversarial Attacks on LiDAR-Based Tracking Across Road Users: Robustness Evaluation and Target-Aware Black-Box Method|激光雷达基于的跨道路用户跟踪对抗攻击：鲁棒性评估与目标感知黑盒方法|Shengjing Tian, Xiantong Zhao, Yuhao Bian, Yinan Han, Bin Liu|<http://arxiv.org/pdf/2410.20893v3>|评估了基于LiDAR的点云追踪模型对抗攻击的鲁棒性，并提出了有效的黑盒攻击方法TAPG。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 小样本学习 (Few-shot Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignment|通过概率高斯对齐的无反向传播测试时适应|Youjia Zhang, Youngeun Kim, Young-Geun Choi, Hongyeob Kim, Huiling Liu, Sungeun Hong|<http://arxiv.org/pdf/2508.15568v5>|提出了一种无需反向传播的测试时自适应方法，通过高斯概率推理显著提升了模型在分布偏移下的鲁棒性和可扩展...|


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Deep Linear Probe Generators for Weight Space Learning|深度线性探测生成器用于权重空间学习|Jonathan Kahana, Eliahu Horwitz, Imri Shuval, Yedid Hoshen|<http://arxiv.org/pdf/2410.10811v2>|提出了一种深度线性探针生成器，有效改进了权重空间学习中的探针学习策略，大幅减少了计算量。|
|📝 更新|Learning Spatially Adaptive $\ell_1$-Norms Weights for Convolutional Synthesis Regularization|学习空间自适应 $\ell_1$-范数权重以进行卷积合成正则化|Andreas Kofler, Luca Calatroni, Christoph Kolbitsch, Kostas Papafitsoros|<http://arxiv.org/pdf/2503.09483v4>|提出了一种学习空间自适应参数图的方法，通过卷积合成和稀疏正则化，有效提升了图像重建质量并增强了算法可...|
|📝 更新|See through the Dark: Learning Illumination-affined Representations for Nighttime Occupancy Prediction|《透过黑暗：学习夜间占用预测的光照关联表征》|Yuan Wu, Zhiqiang Yan, Yigong Zhang, Xiang Li, Jian Yang|<http://arxiv.org/pdf/2505.20641v3>|[代码](https://github.com/yanzq95/LIAR); 提出了一种学习光照关联表征的框架LIAR，通过自适应图像增强和光照感知采样，显著提升了夜间场景的占有...|
|📝 更新|Rethinking Multimodal Learning from the Perspective of Mitigating Classification Ability Disproportion|从减轻分类能力失衡角度重新思考多模态学习|QingYuan Jiang, Longfei Huang, Yang Yang|<http://arxiv.org/pdf/2502.20120v3>|[代码](https://github.com/njustkmg/NeurIPS25-AUG.); 提出了一种基于增强原理的多模态学习方法，动态平衡强弱模态的分类能力，有效缓解了模态不平衡问题。|
|🆕 发布|Learning To Defer To A Population With Limited Demonstrations|学习在有限示范下向群体延迟决策|Nilesh Ramgolam, Gustavo Carneiro, Hsiang-Ting, Chen|<http://arxiv.org/pdf/2510.19351v1>|[代码](https://github.com/nil123532/learning-to-defer-to-a-population-with-limited-demonstrations.); 提出了一种半监督元学习方法，通过少量示范生成专家特定嵌入，有效解决了学习延迟系统在数据稀缺问题上的应...|
|📝 更新|Breaking the Discretization Barrier of Continuous Physics Simulation Learning|打破连续物理仿真学习离散化壁垒|Fan Xu, Hao Wu, Nan Wang, Lilan Peng, Kun Wang, Wei Gong, Xibin Zhao|<http://arxiv.org/pdf/2509.17955v2>|提出了一种数据驱动方法CoPS，有效克服了物理模拟学习中的离散化限制，实现了对连续物理动态的精确建模...|
|📝 更新|Semi-off-Policy Reinforcement Learning for Vision-Language Slow-Thinking Reasoning|半策略强化学习在视觉语言慢思考推理中的应用|Junhao Shen, Haiteng Zhao, Yuzhe Gu, Songyang Gao, Kuikun Liu, Haian Huang, Jianfei Gao, Dahua Lin .etc.|<http://arxiv.org/pdf/2507.16814v2>|提出SOPHIA方法，结合视觉模型与语言模型，通过半离策略强化学习提升大型视觉语言模型的慢思考推理能...|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Training-Free Label Space Alignment for Universal Domain Adaptation|无监督标签空间对齐用于通用域自适应|Dujin Lee, Sojung An, Jungmyung Wi, Kuniaki Saito, Donghyun Kim|<http://arxiv.org/pdf/2509.17452v2>|提出了一种无需训练的标签空间对齐方法，通过过滤和优化标签，提高了通用领域自适应的稳定性和泛化能力。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|3D Visual Illusion Depth Estimation|三维视觉错觉深度估计|Chengtang Yao, Zhidan Liu, Jiaxi Zeng, Lidong Yu, Yuwei Wu, Yunde Jia|<http://arxiv.org/pdf/2505.13061v4>|提出了一种融合视觉语言模型常见知识的3D视觉错觉深度估计框架，提升了深度估计准确性。|
|📝 更新|CNeuroMod-THINGS, a densely-sampled fMRI dataset for visual neuroscience|CNeuroMod-THINGS，一个用于视觉神经科学的高度密集采样fMRI数据集|Marie St-Laurent, Basile Pinsard, Oliver Contier, Elizabeth DuPre, Katja Seeliger, Valentina Borghesani, Julie A. Boyle, Lune Bellec .etc.|<http://arxiv.org/pdf/2507.09024v4>|构建大规模 densely-sampled fMRI 数据集 CNeuroMod-THINGS，融合...|
|🆕 发布|I Spy With My Model's Eye: Visual Search as a Behavioural Test for MLLMs|我以我的模型之眼侦探：视觉搜索作为大型语言模型的行为测试|John Burden, Jonathan Prunty, Ben Slater, Matthieu Tehenan, Greg Davis, Lucy Cheke|<http://arxiv.org/pdf/2510.19678v1>|利用视觉搜索测试，揭示了大型多模态语言模型在视觉处理上具有类似人类的感知能力。|
|🆕 发布|VGD: Visual Geometry Gaussian Splatting for Feed-Forward Surround-view Driving Reconstruction|VGD：视觉几何高斯散点法用于前向环绕视图驾驶重建|Junhong Lin, Kangli Wang, Shunzhou Wang, Songlin Fan, Ge Li, Wei Gao|<http://arxiv.org/pdf/2510.19578v1>|提出了一种名为VGD的端到端学习框架，通过显式学习几何信息并优化特征一致性，实现了高质量环绕视图的重...|
|📝 更新|EgoBlind: Towards Egocentric Visual Assistance for the Blind|面向盲人的自我中心视觉辅助系统EgoBlind|Junbin Xiao, Nanxin Huang, Hao Qiu, Zhulin Tao, Xun Yang, Richang Hong, Meng Wang, Angela Yao|<http://arxiv.org/pdf/2503.08221v3>|[代码](https://github.com/doc-doc/EgoBlind.); 提出了EgoBlind，首个由盲人收集的 egocentric VideoQA 数据集，用于评估大型...|
|🆕 发布|Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts|面向单源域泛化目标检测的因果视觉提示方法|Chen Li, Huiying Xu, Changxin Gao, Zeyu Wang, Yun Liu, Xinzhong Zhu|<http://arxiv.org/pdf/2510.19487v1>|提出了一种通过因果视觉提示减少领域偏见的单源域泛化目标检测方法，实现了领域通用性的显著提升。|
|🆕 发布|From See to Shield: ML-Assisted Fine-Grained Access Control for Visual Data|从看到保护：基于机器学习的视觉数据细粒度访问控制|Mete Harun Akcay, Buse Gul Atli, Siddharth Prakash Rao, Alexandros Bakas|<http://arxiv.org/pdf/2510.19418v1>|提出了一种基于机器学习的细粒度访问控制系统，有效保护视觉数据中的敏感区域并提高数据共享的安全性。|
|📝 更新|Visual Multi-Agent System: Mitigating Hallucination Snowballing via Visual Flow|视觉多智能体系统：通过视觉流减轻幻觉雪崩效应|Xinlei Yu, Chengming Xu, Guibin Zhang, Yongbo He, Zhangquan Chen, Zhucun Xue, Jiangning Zhang, Yue Liao .etc.|<http://arxiv.org/pdf/2509.21789v2>|[代码](https://github.com/YU-deep/ViF.git.); 提出方法ViF缓解多智能体系统中视觉假象累积问题，通过视觉流传递信息并优化注意力分配。|
|📝 更新|Grasp Any Region: Towards Precise, Contextual Pixel Understanding for Multimodal LLMs|抓取任意区域：面向多模态大型语言模型的精确、上下文像素理解|Haochen Wang, Yuhao Wang, Tao Zhang, Yikang Zhou, Yanwei Li, Jiacong Wang, Jiani Zheng, Ye Tian .etc.|<http://arxiv.org/pdf/2510.18876v2>|提出Grasp Any Region模型，通过全局上下文和跨提示交互提升多模态大语言模型对复杂场景的...|
|🆕 发布|FootFormer: Estimating Stability from Visual Input|足部形态估计：从视觉输入估计稳定性|Keaton Kraiger, Jingjing Li, Skanda Bharadwaj, Jesse Scott, Robert T. Collins, Yanxi Liu|<http://arxiv.org/pdf/2510.19170v1>|[代码](https://github.com/keatonkraiger/Vision-to-Stability.git.); 提出了一种跨模态方法 FootFormer，直接从视觉输入预测人体运动动力学，实现了估计脚部压力分布...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Curvilinear Structure-preserving Unpaired Cross-domain Medical Image Translation|保持曲线结构不变的未配对跨域医学图像翻译|Zihao Chen, Yi Zhou, Xudong Jiang, Li Chen, Leopold Schmetterer, Bingyao Tan, Jun Cheng|<http://arxiv.org/pdf/2510.19679v1>|提出了一种保持曲线结构完整性的无配对跨域医学图像翻译方法，有效提高了图像转换的保真度和临床诊断可靠性...|
|🆕 发布|MedReason-R1: Learning to Reason for CT Diagnosis with Reinforcement Learning and Local Zoom|MedReason-R1：基于强化学习和局部缩放的CT诊断推理学习|Yifan Li, Fenghe Tang, Yingtai Li, Shaohua Kevin Zhou|<http://arxiv.org/pdf/2510.19626v1>|[代码](https://github.com/Leevan001/MedReason-R1); 提出MedReason-R1模型，结合强化学习和局部放大策略，提升CT影像诊断准确性和效率。|
|📝 更新|OmniNWM: Omniscient Driving Navigation World Models|全知驾驶导航世界模型：OmniNWM|Bohan Li, Zhuang Ma, Dalong Du, Baorui Peng, Zhujin Liang, Zhenqiang Liu, Chao Ma, Yueming Jin .etc.|<http://arxiv.org/pdf/2510.18313v2>|[代码](https://github.com/Arlo0o/OmniNWM.); OmniNWM通过全景视频生成、精确控制和高密度奖励定义，统一提升了自动驾驶世界模型的性能。|
|🆕 发布|Uncertainty evaluation of segmentation models for Earth observation|地球观测分割模型不确定性评估|Melanie Rey, Andriy Mnih, Maxim Neumann, Matt Overlan, Drew Purves|<http://arxiv.org/pdf/2510.19586v1>|评估卫星图像分割模型的不确定性，提升预测错误和噪声区域的识别能力。|
|🆕 发布|DARE: A Deformable Adaptive Regularization Estimator for Learning-Based Medical Image Registration|DARE：用于基于学习医学图像配准的变形自适应正则化估计器|Ahsan Raza Siyal, Markus Haltmeier, Ruth Steiger, Malik Galijasevic, Elke Ruth Gizewski, Astrid Ellen Grams|<http://arxiv.org/pdf/2510.19353v1>|提出DARE框架，通过自适应调整弹性正则化，提高了医学图像配准的准确性和解剖合理性。|
|🆕 发布|Enhancing Early Alzheimer Disease Detection through Big Data and Ensemble Few-Shot Learning|通过大数据与集成少量样本学习增强早期阿尔茨海默病检测|Safa Ben Atitallah, Maha Driss, Wadii Boulila, Anis Koubaa|<http://arxiv.org/pdf/2510.19282v1>|利用大数据和集成少量样本学习提升早期阿尔茨海默病检测准确率。|
|🆕 发布|SFGFusion: Surface Fitting Guided 3D Object Detection with 4D Radar and Camera Fusion|基于表面拟合引导的4D雷达与相机融合的三维物体检测方法：SFGFusion|Xiaozhi Li, Huijun Di, Jian Li, Feng Liu, Wei Liang|<http://arxiv.org/pdf/2510.19215v1>|提出了一种基于曲面拟合的4D雷达与相机融合的3D物体检测方法，有效提升了空间表示和跨模态交互。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|On the Effectiveness of Methods and Metrics for Explainable AI in Remote Sensing Image Scene Classification|关于遥感图像场景分类中可解释人工智能方法与评价指标有效性的研究|Jonas Klotz, Tom Burgert, Begüm Demir|<http://arxiv.org/pdf/2507.05916v3>|分析了遥感图像分类中解释性AI方法和评估指标的有效性，提出了选择方法和参数的指导原则。|
|🆕 发布|Seabed-Net: A multi-task network for joint bathymetry estimation and seabed classification from remote sensing imagery in shallow waters|海底网：一种用于浅水区遥感影像联合测深和海底分类的多任务网络|Panagiotis Agrafiotis, Begüm Demir|<http://arxiv.org/pdf/2510.19329v1>|[代码](https://github.com/pagraf/Seabed-Net.); 提出了一种多任务网络Seabed-Net，联合估计浅水区域的海底地形和分类，实现了更高的精度和一致性...|
|📝 更新|MsEdF: A Multi-stream Encoder-decoder Framework for Remote Sensing Image Captioning|多流编码器-解码器框架MsEdF：用于遥感图像标注|Swadhin Das, Raksha Sharma|<http://arxiv.org/pdf/2502.09282v3>|提出了一种多流编码器-解码器框架，通过融合多尺度特征和优化语义建模，提高了遥感图像描述的准确性和多样...|
|📝 更新|Advancing Image Super-resolution Techniques in Remote Sensing: A Comprehensive Survey|《推进遥感图像超分辨率技术：全面综述》|Yunliang Qi, Meng Lou, Yimin Liu, Lu Li, Zhen Yang, Wen Nie|<http://arxiv.org/pdf/2505.23248v3>|系统综述了遥感图像超分辨率算法，分析了现有方法的局限，并提出了未来研究方向。|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|XBench: A Comprehensive Benchmark for Visual-Language Explanations in Chest Radiography|XBench：胸部X射线影像视觉-语言解释的全面基准测试|Haozhe Luo, Shelley Zixin Shu, Ziyu Zhou, Sebastian Otalora, Mauricio Reyes|<http://arxiv.org/pdf/2510.19599v1>|[代码](https://github.com/Roypic/Benchmarkingattention); 提出XBench基准，评估视觉语言模型在胸片解释中的跨模态可解释性，揭示模型在细小病变定位上的不足。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ComDrive: Comfort-Oriented End-to-End Autonomous Driving|《ComDrive：面向舒适的端到端自动驾驶》|Junming Wang, Xingyu Zhang, Zebin Xing, Songen Gu, Xiaoyang Guo, Yang Hu, Ziying Song, Qian Zhang .etc.|<http://arxiv.org/pdf/2410.05051v2>|[代码](https://jmwang0117.github.io/ComDrive); 提出ComDrive系统，通过稀疏感知和条件去噪扩散模型生成舒适且一致的自动驾驶轨迹。|
|🆕 发布|Rethinking Driving World Model as Synthetic Data Generator for Perception Tasks|重新思考驾驶世界模型作为感知任务合成数据生成器|Kai Zeng, Zhanqian Wu, Kaixin Xiong, Xiaobao Wei, Xiangyu Guo, Zhenxin Zhu, Kalok Ho, Lijun Zhou .etc.|<http://arxiv.org/pdf/2510.19195v1>|[代码](https://wm-research.github.io/Dream4Drive); 提出Dream4Drive框架，通过3D指导图和资产渲染提升自动驾驶感知任务性能。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision Geometry Priors|从视频中学习三维世界：利用三维视觉几何先验增强多模态语言模型|Duo Zheng, Shijia Huang, Yanyang Li, Liwei Wang|<http://arxiv.org/pdf/2505.24625v3>|提出了一种无需额外3D输入的Video-3D Geometry LLM，通过视频直接增强MLLM对3...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LBL: Logarithmic Barrier Loss Function for One-class Classification|对数障碍损失函数用于单类分类：LBL|Xiaofeng Guo, Ziyang Jiang, Tianlei Wang, Shichen Zhang, Dinghan Hu, Jiuwen Cao|<http://arxiv.org/pdf/2307.10753v2>|[代码](https://github.com/ML-HDU/LBL_LBLSig.); 提出了一种新的对数障碍损失函数LBL，通过为大边界样本分配较大梯度，有效优化了一类分类问题中的超球体...|
|🆕 发布|BrainMCLIP: Brain Image Decoding with Multi-Layer feature Fusion of CLIP|《BrainMCLIP：基于CLIP多层特征融合的脑图像解码》|Tian Xia, Zihan Ma, Xinlong Wang, Qing Liu, Xiaowei He, Tianming Liu, Yudan Ren|<http://arxiv.org/pdf/2510.19332v1>|BrainMCLIP通过多层级特征融合，无需VAE管道，有效解码脑图像并保持细节与语义平衡。|
|📝 更新|Investigating the Relationship between the Weighted Figure of Merit and Rosin's Measure|探究加权性能指标与Rosin测度之间的关系|Bimal Kumar Ray|<http://arxiv.org/pdf/2506.05749v3>|探讨了加权性能指标与Rosin度量之间的关系，证明了两者理论上的独立性。|
|📝 更新|Vectorization of Persistence Diagrams for Topological Data Analysis in R and Python Using TDAvec Package|《使用TDAvec包在R和Python中对持久性图进行向量化处理以进行拓扑数据分析》|Aleksei Luchinsky, Umar Islambekov|<http://arxiv.org/pdf/2411.17340v3>|提出了一种新的软件包，将拓扑持久性图向量化，使其适用于机器学习应用。|
|📝 更新|LookUp3D: Data-Driven 3D Scanning|《LookUp3D：数据驱动的三维扫描》|Giancarlo Pereira, Yidan Gao, Yurii Piadyk, David Fouhey, Claudio T Silva, Daniele Panozzo|<http://arxiv.org/pdf/2405.14882v2>|首次实现450帧/秒的1兆像素或1,450帧/秒的0.4兆像素高速高分辨率3D扫描，通过像素级查找表...|
|🆕 发布|GRASPLAT: Enabling dexterous grasping through novel view synthesis|GRASPLAT：通过新颖视图合成实现灵巧抓取|Matteo Bortolon, Nuno Ferreira Duarte, Plinio Moreno, Fabio Poiesi, José Santos-Victor, Alessio Del Bue|<http://arxiv.org/pdf/2510.19200v1>|[代码](https://mbortolon97.github.io/grasplat); 提出了一种基于RGB图像的抓握预测框架GRASPLAT，通过合成手部抓握图像来提高机器人灵巧抓握的成...|
|📝 更新|Rethinking Backbone Design for Lightweight 3D Object Detection in LiDAR|重新思考轻量级激光雷达三维物体检测中的主干网络设计|Adwait Chandorkar, Hasan Tercan, Tobias Meisen|<http://arxiv.org/pdf/2508.00744v2>|提出轻量级Dense Backbone架构，用于3D物体检测，减少计算复杂度同时保持高准确率。|

