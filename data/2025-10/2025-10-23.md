## [UPDATED!] **2025-10-23** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ARGenSeg: Image Segmentation with Autoregressive Image Generation Model|自回归生成模型驱动的图像分割：ARGenSeg|Xiaolong Wang, Lixiang Ru, Ziyuan Huang, Kaixiang Ji, Dandan Zheng, Jingdong Chen, Jun Zhou|<http://arxiv.org/pdf/2510.20803v1>|提出了一种基于图像生成模型的图像分割新框架，通过像素级理解实现了多模态感知和高效分割。|
|📝 更新|Structured Spectral Graph Representation Learning for Multi-label Abnormality Analysis from 3D CT Scans|用于三维CT扫描多标签异常性分析的结构化光谱图表示学习|Theo Di Piazza, Carole Lazarus, Olivier Nempont, Loic Boussel|<http://arxiv.org/pdf/2510.10779v2>|提出了一种基于图结构的2.5D方法，通过谱图卷积处理CT切片，有效捕捉长距离依赖性，提升多标签异常分...|
|📝 更新|X-Reflect: Cross-Reflection Prompting for Multimodal Recommendation|X-Reflect: 跨反射提示用于多模态推荐|Hanjia Lyu, Ryan Rossi, Xiang Chen, Md Mehrab Tanjim, Stefano Petrangeli, Somdeb Sarkhel, Jiebo Luo|<http://arxiv.org/pdf/2408.15172v2>|引入了Cross-Reflection Prompting框架，通过融合文本和图像信息提升推荐系统准...|
|📝 更新|BioCLIP 2: Emergent Properties from Scaling Hierarchical Contrastive Learning|BioCLIP 2：从扩展层次对比学习中涌现的性质|Jianyang Gu, Samuel Stevens, Elizabeth G Campolongo, Matthew J Thompson, Net Zhang, Jiaman Wu, Andrei Kopanev, Zheda Mai .etc.|<http://arxiv.org/pdf/2505.23883v2>|通过大规模对比视觉语言训练，BioCLIP 2在生物视觉任务中展现出超越初始目标的显著性能。|
|📝 更新|MCIF: Multimodal Crosslingual Instruction-Following Benchmark from Scientific Talks|MCIF：从科学讲座中提取的多模态跨语言指令遵循基准|Sara Papi, Maike Züfle, Marco Gaido, Beatrice Savoldi, Danni Liu, Ioannis Douros, Luisa Bentivogli, Jan Niehues|<http://arxiv.org/pdf/2507.19634v2>|提出了MCIF基准，首个多语言、多模态、基于科学演讲的人类注释指令跟随评估框架。|
|📝 更新|ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding|ViSpec：利用视觉感知的投机解码加速视觉-语言模型|Jialiang Kang, Han Shu, Wenshuo Li, Yingjie Zhai, Xinghao Chen|<http://arxiv.org/pdf/2509.15235v5>|[代码](https://github.com/KangJialiang/ViSpec.); 提出ViSpec框架，通过压缩图像信息和增强文本特征，实现了首个显著的视觉语言模型推理加速。|
|📝 更新|Toward a Vision-Language Foundation Model for Medical Data: Multimodal Dataset and Benchmarks for Vietnamese PET/CT Report Generation|面向医疗数据的视觉-语言基础模型：越南PET/CT报告生成的多模态数据集与基准|Huu Tien Nguyen, Dac Thai Nguyen, The Minh Duc Nguyen, Trung Thanh Nguyen, Thao Nguyen Truong, Huy Hieu Pham, Johan Barthelemy, Minh Quan Tran .etc.|<http://arxiv.org/pdf/2509.24739v2>|[代码](https://github.com/AIoT-Lab-BKAI/ViPET-ReportGen.); 构建越南语医学影像与报告的多模态数据集，提升低资源语言医疗视觉语言模型性能。|
|📝 更新|Vision-Centric Activation and Coordination for Multimodal Large Language Models|视觉中心激活与多模态大型语言模型的协同|Yunnan Wang, Fan Lu, Kecheng Zheng, Ziyuan Huang, Ziqiang Li, Wenjun Zeng, Xin Jin|<http://arxiv.org/pdf/2510.14349v3>|引入VaCo方法，通过视觉激活与协调，增强多模态大语言模型对视觉信息的理解和处理能力。|
|🆕 发布|Calibrating Multimodal Consensus for Emotion Recognition|《校准多模态共识以进行情感识别》|Guowei Zhong, Junjie Li, Huaiyu Zhu, Ruohong Huan, Yun Pan|<http://arxiv.org/pdf/2510.20256v1>|[代码](https://github.com/gw-zhong/CMC.); 提出了一种缓解文本主导和语义不一致问题的多模态情感识别方法，通过伪标签生成和参数无关融合实现可靠共识...|
|🆕 发布|A Structured Review and Quantitative Profiling of Public Brain MRI Datasets for Foundation Model Development|针对基础模型开发公共大脑MRI数据集的结构化回顾与定量分析|Minh Sao Khue Luu, Margaret V. Benedichuk, Ekaterina I. Roppert, Roman M. Kenzhin, Bair N. Tuchinov|<http://arxiv.org/pdf/2510.20196v1>|系统评估了公共脑部MRI数据集的规模、多样性和一致性，为开发通用脑部MRI基础模型提供了多级别概览和...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GenLit: Reformulating Single-Image Relighting as Video Generation|《GenLit：将单张图像重光照重定义为视频生成》|Shrisha Bharadwaj, Haiwen Feng, Giorgio Becherini, Victoria Fernandez Abrevaya, Michael J. Black|<http://arxiv.org/pdf/2412.11224v4>|将单张图像的重光照问题转化为视频生成任务，利用视频扩散模型实现无需3D重建或光线追踪的直接光照调整。|
|📝 更新|Fast-Slow Thinking GRPO for Large Vision-Language Model Reasoning|用于大规模视觉语言模型推理的快慢思维GRPO方法|Wenyi Xiao, Leilei Gan|<http://arxiv.org/pdf/2504.18458v2>|提出了一种自适应推理深度的FAST-GRPO方法，有效平衡了大型视觉语言模型推理的长度和准确性。|
|📝 更新|REOBench: Benchmarking Robustness of Earth Observation Foundation Models|REOBench：地球观测基础模型鲁棒性基准测试|Xiang Li, Yong Tao, Siyuan Zhang, Siwei Liu, Zhitong Xiong, Chunbo Luo, Lu Liu, Mykola Pechenizkiy .etc.|<http://arxiv.org/pdf/2505.16793v2>|[代码](https://github.com/lx709/REOBench.); 介绍了REOBench，首个评估地球观测基础模型在多种现实世界扰动下的鲁棒性的全面基准。|
|🆕 发布|EmbodiedBrain: Expanding Performance Boundaries of Task Planning for Embodied Intelligence|具身大脑：扩展具身智能任务规划的性能边界|Ding Zou, Feifan Wang, Mengyu Ge, Siyuan Fan, Zongbing Zhang, Wei Chen, Lingfeng Wang, Zhongyou Hu .etc.|<http://arxiv.org/pdf/2510.20578v1>|[代码](https://zterobot.github.io/EmbodiedBrain.github.io.); 提出EmbodiedBrain模型，通过结合大规模监督微调和增强策略优化，提升Embodied AI...|
|📝 更新|EasyOcc: 3D Pseudo-Label Supervision for Fully Self-Supervised Semantic Occupancy Prediction Models|EasyOcc：用于全自监督语义占有率预测模型的三维伪标签监督|Seamie Hayes, Ganesh Sistu, Ciarán Eising|<http://arxiv.org/pdf/2509.26087v2>|提出了一种利用3D伪标签和时序信息的自监督学习方法，显著提升了语义占用预测模型的性能。|
|🆕 发布|Breakdance Video classification in the age of Generative AI|生成式人工智能时代的Breaking舞视频分类|Sauptik Dhar, Naveen Ramakrishnan, Michelle Munson|<http://arxiv.org/pdf/2510.20287v1>|探究了现代视频基础模型在_breakdance_视频分类中的应用，发现视频编码器模型优于现有视频语言...|
|📝 更新|Epistemic-aware Vision-Language Foundation Model for Fetal Ultrasound Interpretation|胎儿超声解读中的认知感知视觉-语言基础模型|Xiao He, Huangxuan Zhao, Guojia Wan, Wei Zhou, Yanxing Liu, Juhua Liu, Yongchao Xu, Yong Luo .etc.|<http://arxiv.org/pdf/2510.12953v2>|[代码](https://hexiao0275.github.io/FetalMind.); 提出FetalMind系统，通过Salient Epistemic Disentanglement和...|
|🆕 发布|BIOCAP: Exploiting Synthetic Captions Beyond Labels in Biological Foundation Models|生物基础模型中利用合成字幕超越标签的BIOCAP方法|Ziheng Zhang, Xinyue Ma, Arpita Chowdhury, Elizabeth G. Campolongo, Matthew J. Thompson, Net Zhang, Samuel Stevens, Hilmar Lapp .etc.|<http://arxiv.org/pdf/2510.20095v1>|利用合成描述性字幕增强生物多模态基础模型的训练，提升物种分类和图文检索性能。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for Tissue Segmentation in Histopathology|ACS-SegNet：一种基于注意力的CNN-SegFormer组织分割网络，用于组织病理学中的组织分割|Nima Torbati, Anastasia Meshcheryakova, Ramona Woitek, Diana Mechtcheriakova, Amirreza Mahbod|<http://arxiv.org/pdf/2510.20754v1>|[代码](https://github.com/NimaTorbati/ACS-SegNet); 提出了一种结合卷积神经网络和视觉变换器的双编码器模型，通过注意力驱动的特征融合显著提升了组织分割性能...|
|📝 更新|MARIS: Marine Open-Vocabulary Instance Segmentation with Geometric Enhancement and Semantic Alignment|海洋开放词汇实例分割的几何增强与语义对齐：MARIS|Bingyu Li, Feiyu Wang, Da Zhang, Zhiyuan Zhao, Junyu Gao, Xuelong Li|<http://arxiv.org/pdf/2510.15398v2>|提出首个针对水下场景的开词汇实例分割框架，通过几何先验增强和语义对齐提升识别未见类别的能力。|
|🆕 发布|COS3D: Collaborative Open-Vocabulary 3D Segmentation|协同开放词汇三维分割：COS3D|Runsong Zhu, Ka-Hei Hui, Zhengzhe Liu, Qianyi Wu, Weiliang Tang, Shi Qiu, Pheng-Ann Heng, Chi-Wing Fu|<http://arxiv.org/pdf/2510.20238v1>|[代码](https://github.com/Runsong123/COS3D); 提出了一种协作式开放词汇3D分割框架COS3D，通过结合实例和语言场有效整合语言和分割线索。|
|📝 更新|Novel Class Discovery for Point Cloud Segmentation via Joint Learning of Causal Representation and Reasoning|通过联合学习因果表示和推理的点云分割新类发现|Yang Li, Aming Wu, Zihao Zhang, Yahong Han|<http://arxiv.org/pdf/2510.13307v2>|提出了一种通过联合学习因果表示和推理实现点云分割中新颖类发现的模型，有效区分了基础类和未标记的新类。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Frequency-Dynamic Attention Modulation for Dense Prediction|频率动态注意力调制用于密集预测|Linwei Chen, Lin Gu, Ying Fu|<http://arxiv.org/pdf/2507.12006v4>|[代码](https://github.com/Linwei-Chen/FDAM.); 提出Frequency-Dynamic Attention Modulation方法，解决Trans...|
|📝 更新|MODEM: A Morton-Order Degradation Estimation Mechanism for Adverse Weather Image Recovery|MODEM：一种基于莫顿顺序退化估计机制的恶劣天气图像恢复方法|Hainuo Wang, Qiming Hu, Xiaojie Guo|<http://arxiv.org/pdf/2505.17581v2>|[代码](https://github.com/hainuo-wang/MODEM.git.); 提出了一种用于恶劣天气图像恢复的降解估计机制MODEM，通过长距离依赖和局部结构一致性实现自适应图像...|
|📝 更新|SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation|稀疏感知轻量级三维手势姿态估计（SPLite Hand）|Yeh Keng Hao, Hsu Tzu Wei, Sun Min|<http://arxiv.org/pdf/2510.16396v2>|提出了一种稀疏性感知的轻量级3D手部姿态估计框架，大幅提升了边缘设备上的运行效率并保持了高准确性。|
|🆕 发布|Synthetic Data for Robust Runway Detection|合成数据用于稳健的跑道检测|Estelle Chigot, Dennis G. Wilson, Meriem Ghrib, Fabrice Jimenez, Thomas Oberlin|<http://arxiv.org/pdf/2510.20349v1>|利用商业飞行模拟器生成合成图像，有效补充少量真实标注数据，提升跑道检测模型的准确性和鲁棒性。|
|🆕 发布|Real-Time Currency Detection and Voice Feedback for Visually Impaired Individuals|结果：实时货币检测与语音反馈辅助视障人士|Saraf Anzum Shreya, MD. Abu Ismail Siddique, Sharaf Tasnim|<http://arxiv.org/pdf/2510.20267v1>|实现实时货币检测并为视障人士提供语音反馈，提高他们独立处理货币的能力。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Knowledge-Informed Neural Network for Complex-Valued SAR Image Recognition|知识引导的复值合成孔径雷达图像识别神经网络|Haodong Yang, Zhongling Huang, Shaojie Guo, Zhe Zhang, Gong Cheng, Junwei Han|<http://arxiv.org/pdf/2510.20284v1>|提出知识引导的神经网络KINN，通过物理先验和轻量架构解决SAR图像识别中的泛化、解释性和效率难题。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Towards Objective Obstetric Ultrasound Assessment: Contrastive Representation Learning for Fetal Movement Detection|面向客观产前超声评估：用于胎儿运动检测的对比表示学习|Talha Ilyas, Duong Nhu, Allison Thomas, Arie Levin, Lim Wei Yap, Shu Gong, David Vera Anaya, Yiwen Jiang .etc.|<http://arxiv.org/pdf/2510.20214v1>|提出了一种自监督学习框架CURL，通过对比学习提高胎动检测的准确性和客观性。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas|《LayerComposer：通过空间感知分层画布实现的交互式个性化文本到图像》|Guocheng Gordon Qian, Ruihang Zhang, Tsai-Shien Chen, Yusuf Dalva, Anujraaj Argo Goyal, Willi Menapace, Ivan Skorokhodov, Meng Dong .etc.|<http://arxiv.org/pdf/2510.20820v1>|LayerComposer通过分层画布和锁定机制，实现了多主体个性化图像生成的交互式控制。|
|🆕 发布|Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge|面向通用模态转换的对偶对比与预测潜在扩散桥|Nimrod Berman, Omkar Joglekar, Eitan Kosman, Dotan Di Castro, Omri Azencot|<http://arxiv.org/pdf/2510.20819v1>|提出了一种通用模态转换框架LDDBM，通过对比和对预测损失学习跨模态信息转换，实现了无需对齐维度的多...|
|📝 更新|DragFlow: Unleashing DiT Priors with Region Based Supervision for Drag Editing|DragFlow：利用基于区域的监督释放DiT先验进行拖动编辑|Zihan Zhou, Shilin Lu, Shuli Leng, Shaocong Zhang, Zhuming Lian, Xinlei Yu, Adams Wai-Kin Kong|<http://arxiv.org/pdf/2510.02253v2>|提出DragFlow框架，利用DiT的强大先验进行基于区域的拖拽编辑，显著提升了图像编辑质量。|
|📝 更新|Watermarking Autoregressive Image Generation|"水印嵌入自回归图像生成"|Nikola Jovanović, Ismail Labiad, Tomáš Souček, Martin Vechev, Pierre Fernandez|<http://arxiv.org/pdf/2506.16349v2>|[代码](https://github.com/facebookresearch/wmar.); 首次提出在自回归图像生成模型中通过水印技术追踪图像来源，增强了水印的鲁棒性。|
|🆕 发布|CUPID: Pose-Grounded Generative 3D Reconstruction from a Single Image|CUPID：基于姿态定位的单张图像生成式三维重建|Binbin Huang, Haobin Duan, Yiqun Zhao, Zibo Zhao, Yi Ma, Shenghua Gao|<http://arxiv.org/pdf/2510.20776v1>|提出了一种基于生成模型的单张图像3D重建方法，通过联合生成体素和像素-体素对应，实现了准确的相机姿态...|
|🆕 发布|AutoScape: Geometry-Consistent Long-Horizon Scene Generation|自动景观：几何一致性的长时景深生成|Jiacheng Chen, Ziyu Jiang, Mingfu Liang, Bingbing Zhuang, Jong-Chyi Su, Sparsh Garg, Ying Wu, Manmohan Chandraker|<http://arxiv.org/pdf/2510.20726v1>|提出AutoScape框架，通过RGB-D扩散模型生成几何一致的长距离驾驶场景视频，显著提升现实性和...|
|📝 更新|FreeGraftor: Training-Free Cross-Image Feature Grafting for Subject-Driven Text-to-Image Generation|无需训练的跨图像特征嫁接方法：面向主题驱动的文本到图像生成|Zebin Yao, Lei Ren, Huixing Jiang, Chen Wei, Xiaojie Wang, Ruifan Li, Fangxiang Feng|<http://arxiv.org/pdf/2504.15958v3>|[代码](https://github.com/Nihukat/FreeGraftor.); 提出了一种无需训练的跨图像特征嫁接方法FreeGraftor，实现了高效且精确的主体身份转移和文本对...|
|🆕 发布|GenColorBench: A Color Evaluation Benchmark for Text-to-Image Generation Models|《GenColorBench：用于文本到图像生成模型的颜色评估基准》|Muhammad Atif Butt, Alexandra Gomez-Villa, Tao Wu, Javier Vazquez-Corral, Joost Van De Weijer, Kai Wang|<http://arxiv.org/pdf/2510.20586v1>|提出首个全面评估文本到图像生成模型颜色精确度的GenColorBench基准，系统检测颜色匹配准确性...|
|📝 更新|A novel attention mechanism for noise-adaptive and robust segmentation of microtubules in microscopy images|一种新颖的噪声自适应且稳健的微管分割注意力机制在显微图像中的应用|Achraf Ait Laydi, Louis Cueff, Mewen Crespo, Yousef El Mourabit, Hélène Bouvrais|<http://arxiv.org/pdf/2507.07800v2>|提出了一种自适应噪声调整的注意力机制，通过集成到U-Net架构中，实现了对显微图像中微管的高效分割。|
|🆕 发布|From Cheap to Pro: A Learning-based Adaptive Camera Parameter Network for Professional-Style Imaging|从低成本到专业：一种基于学习的自适应相机参数网络，用于专业风格成像|Fuchen Li, Yansong Du, Wenbo Cheng, Xiaoxia Zhou, Sen Yin|<http://arxiv.org/pdf/2510.20550v1>|提出了一种自适应相机参数网络ACamera-Net，通过直接预测最佳曝光和白平衡，显著提升了复杂光照...|
|📝 更新|Grounding Language with Vision: A Conditional Mutual Information Calibrated Decoding Strategy for Reducing Hallucinations in LVLMs|将语言与视觉结合：一种条件互信息校准解码策略，用于减少LVLMs中的虚构现象|Hao Fang, Changle Zhou, Jiawei Kong, Kuofeng Gao, Bin Chen, Shu-Tao Xia|<http://arxiv.org/pdf/2505.19678v3>|提出了一种基于条件互信息校准的解码策略，有效减少大型视觉语言模型中的幻觉现象。|
|📝 更新|Mesh-RFT: Enhancing Mesh Generation via Fine-grained Reinforcement Fine-Tuning|网格细化强化微调：通过细粒度强化微调增强网格生成|Jian Liu, Jing Xu, Song Guo, Jing Li, Jingfeng Guo, Jiaao Yu, Haohan Weng, Biwen Lei .etc.|<http://arxiv.org/pdf/2505.16761v2>|[代码](https://hitcslj.github.io/mesh-rft); 提出了一种细粒度强化微调框架Mesh-RFT，通过局部优化显著提升了3D网格生成质量与拓扑规则性。|
|📝 更新|Occluded nuScenes: A Multi-Sensor Dataset for Evaluating Perception Robustness in Automated Driving|遮挡的nuScenes：一个用于评估自动驾驶感知鲁棒性的多传感器数据集|Sanjay Kumar, Tim Brophy, Reenu Mohandas, Eoin Martino Grua, Ganesh Sistu, Valentina Donzella, Ciaran Eising|<http://arxiv.org/pdf/2510.18552v2>|介绍了首个具有可控、可重复退化特性的多传感器遮挡数据集，以评估自动驾驶感知模型在恶劣条件下的鲁棒性。|
|📝 更新|SnapMoGen: Human Motion Generation from Expressive Texts|SnapMoGen：从表现性文本生成人体运动|Chuan Guo, Inwoo Hwang, Jian Wang, Bing Zhou|<http://arxiv.org/pdf/2507.09122v2>|[代码](https://snap-research.github.io/SnapMoGen); 提出了SnapMoGen，一种结合详细文本注释的高质量动作捕捉数据集，并通过改进的生成模型实现了对细...|
|📝 更新|A Survey on Cache Methods in Diffusion Models: Toward Efficient Multi-Modal Generation|《扩散模型中缓存方法的综述：迈向高效的多模态生成》|Jiacheng Liu, Xinyu Wang, Yuqi Lin, Zhikai Wang, Peiru Wang, Peiliang Cai, Qinming Zhou, Zhengan Yan .etc.|<http://arxiv.org/pdf/2510.19755v2>|提出了一种无需训练、适用于多种架构的扩散缓存方法，通过识别和重用扩散过程中的计算冗余，有效降低生成模...|
|📝 更新|Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering|基于文本条件的状态空间模型用于域泛化的变化检测视觉问答|Elman Ghazaei, Erchan Aptoula|<http://arxiv.org/pdf/2508.08974v2>|[代码](https://github.com/Elman295/TCSSM.); 提出了一种结合文本信息的统一状态空间模型，有效解决了视觉问答中的领域迁移问题。|
|📝 更新|Video Consistency Distance: Enhancing Temporal Consistency for Image-to-Video Generation via Reward-Based Fine-Tuning|视频一致性距离：通过基于奖励的微调增强图像到视频生成的时序一致性|Takehiro Aoshima, Yusuke Shinohara, Byeongseon Park|<http://arxiv.org/pdf/2510.19193v2>|提出Video Consistency Distance (VCD)增强图像转视频时的时间一致性，通...|
|🆕 发布|EditInfinity: Image Editing with Binary-Quantized Generative Models|EditInfinity：基于二值量化生成模型的图像编辑|Jiahuan Wang, Yuxin Chen, Jun Yu, Guangming Lu, Wenjie Pei|<http://arxiv.org/pdf/2510.20217v1>|[代码](https://github.com/yx-chen-ust/EditInfinity.); 提出EditInfinity方法，利用二值量化生成模型进行精确图像编辑，有效克服了传统扩散模型在图像...|
|📝 更新|FerretNet: Efficient Synthetic Image Detection via Local Pixel Dependencies|FerretNet：通过局部像素依赖进行高效合成图像检测|Shuqiao Liang, Jian Liu, Renzhang Chen, Quanlong Guan|<http://arxiv.org/pdf/2509.20890v2>|[代码](https://github.com/xigua7105/FerretNet.); 提出 FerretNet，利用局部像素依赖性检测合成图像，实现高效准确识别。|
|🆕 发布|RAPO++: Cross-Stage Prompt Optimization for Text-to-Video Generation via Data Alignment and Test-Time Scaling|RAPO++：通过数据对齐和测试时缩放实现文本到视频生成的跨阶段提示优化|Bingjie Gao, Qianli Ma, Xiaoxue Wu, Shuai Yang, Guanzhou Lan, Haonan Zhao, Jiaxuan Chen, Qingyang Liu .etc.|<http://arxiv.org/pdf/2510.20206v1>|[代码](https://github.com/Vchitect/RAPO.); RAPO++通过跨阶段提示优化，结合数据对齐和测试时缩放，大幅提升了文本到视频生成的质量。|
|🆕 发布|Evaluating Video Models as Simulators of Multi-Person Pedestrian Trajectories|评估视频模型作为多行人轨迹模拟器的有效性|Aaron Appelle, Jerome P. Lynch|<http://arxiv.org/pdf/2510.20182v1>|提出了一种评价协议，用于衡量视频模型模拟多人行人轨迹的准确性，揭示了模型在多行人动态模拟方面的有效性...|
|🆕 发布|PartNeXt: A Next-Generation Dataset for Fine-Grained and Hierarchical 3D Part Understanding|PartNeXt：用于细粒度和层次化3D部件理解的下一代数据集|Penghao Wang, Yiyang He, Xin Lv, Yukai Zhou, Lan Xu, Jingyi Yu, Jiayuan Gu|<http://arxiv.org/pdf/2510.20155v1>|提出了PartNeXt数据集，通过高质量、纹理丰富的3D模型和细粒度层次标注，提升了3D部件理解的可...|
|📝 更新|Towards Physical Understanding in Video Generation: A 3D Point Regularization Approach|面向视频生成的物理理解：一种三维点正则化方法|Yunuo Chen, Junli Cao, Vidit Goel, Sergei Korolev, Chenfanfu Jiang, Jian Ren, Sergey Tulyakov, Anil Kag|<http://arxiv.org/pdf/2502.03639v2>|引入3D点轨迹增强视频生成模型，通过正则化形状与运动，显著提升了视频质量和物理真实性。|
|🆕 发布|StableSketcher: Enhancing Diffusion Model for Pixel-based Sketch Generation via Visual Question Answering Feedback|《StableSketcher：通过视觉问答反馈增强扩散模型以实现基于像素的草图生成》|Jiho Park, Sieun Choi, Jaeyoon Seo, Jihie Kim|<http://arxiv.org/pdf/2510.20093v1>|提出StableSketcher框架，通过VAE优化和视觉问答反馈增强扩散模型，实现高保真像素级手绘...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video Narratives|《全息电影：电影多镜头长视频叙事的整体生成》|Yihao Meng, Hao Ouyang, Yue Yu, Qiuyu Wang, Wen Wang, Ka Leong Cheng, Hanlin Wang, Yixuan Li .etc.|<http://arxiv.org/pdf/2510.20822v1>|[代码](https://holo-cine.github.io/.); 提出HoloCine模型，通过全局一致性和导演级控制生成连贯的多镜头叙事视频。|
|🆕 发布|Video Prediction of Dynamic Physical Simulations With Pixel-Space Spatiotemporal Transformers|动态物理模拟的像素空间时空变换视频预测|Dean L Slack, G Thomas Hudson, Thomas Winterbottom, Noura Al Moubayed|<http://arxiv.org/pdf/2510.20807v1>|提出了一种基于纯变换器的视频预测方法，通过连续像素空间表示，显著延长了物理准确预测的时间范围。|
|📝 更新|HumanCM: One Step Human Motion Prediction|人类CM：一步预测人体运动|Liu Haojie, Gao Suixiang|<http://arxiv.org/pdf/2510.16709v2>|提出了一种基于一致性模型的单步人体运动预测框架，大幅减少了推理步骤同时保持了预测精度。|
|📝 更新|Identity-Preserving Image-to-Video Generation via Reward-Guided Optimization|通过奖励引导优化实现的保持身份图像到视频生成|Liao Shen, Wentao Jiang, Yiran Zhu, Jiahe Li, Tiezheng Ge, Zhiguo Cao, Bo Zheng|<http://arxiv.org/pdf/2510.14255v3>|[代码](https://ipro-alimama.github.io/.); 提出了一种基于强化学习的视频生成框架，通过优化扩散模型有效保持了人物身份一致性。|
|🆕 发布|Positional Encoding Field|位置编码场|Yunpeng Bai, Haoxiang Li, Qixing Huang|<http://arxiv.org/pdf/2510.20385v1>|提出了一种结构化的3D位置编码场，使DiT模型能直接在3D空间建模几何，实现图像合成的最佳性能。|
|🆕 发布|A Parameter-Efficient Mixture-of-Experts Framework for Cross-Modal Geo-Localization|一种参数高效的跨模态地理定位混合专家框架|LinFeng Li, Jian Zhao, Zepeng Yang, Yuhang Song, Bojun Lin, Tianle Zhang, Yuchen Yuan, Chi Zhang .etc.|<http://arxiv.org/pdf/2510.20291v1>|提出了一种针对跨模态地理定位的混合专家框架，有效解决了不同平台异质性和领域差距问题。|
|🆕 发布|IB-GAN: Disentangled Representation Learning with Information Bottleneck Generative Adversarial Networks|基于信息瓶颈的生成对抗网络：解耦表示学习|Insu Jeon, Wonkwang Lee, Myeongjang Pyeon, Gunhee Kim|<http://arxiv.org/pdf/2510.20165v1>|提出了一种基于GAN的解耦表示学习方法IB-GAN，通过约束生成器中间层的互信息，实现了优于现有方法...|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Real Deep Research for AI, Robotics and Beyond|《面向人工智能、机器人技术及其他领域的深度研究》|Xueyan Zou, Jianglong Ye, Hao Zhang, Xiaoyu Xiang, Mingyu Ding, Zhaojing Yang, Yong Jae Lee, Zhuowen Tu .etc.|<http://arxiv.org/pdf/2510.20809v1>|提出了一种通用研究分析框架Real Deep Research，助力AI与机器人领域研究者把握趋势与...|
|🆕 发布|DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion|动态位置外推用于超高分扩散模型|Noam Issachar, Guy Yariv, Sagie Benaim, Yossi Adi, Dani Lischinski, Raanan Fattal|<http://arxiv.org/pdf/2510.20766v1>|[代码](https://noamissachar.github.io/DyPE); 提出了一种无需额外训练的动态位置外推方法DyPE，使预训练的扩散变换器能生成远超训练分辨率的高清图像...|
|🆕 发布|Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal Evidence|《Open-o3视频：基于显式时空证据的地面视频推理》|Jiahao Meng, Xiangtai Li, Haochen Wang, Yue Tan, Tao Zhang, Lingdong Kong, Yunhai Tong, Anran Wang .etc.|<http://arxiv.org/pdf/2510.20579v1>|Open-o3 Video引入显式时空证据进行视频推理，通过专门设计的奖励机制提升准确性和定位精度。|
|🆕 发布|Blur2seq: Blind Deblurring and Camera Trajectory Estimation from a Single Camera Motion-blurred Image|从单张运动模糊图像中进行盲去模糊和相机轨迹估计的Blur2seq方法|Guillermo Carbajal, Andrés Almansa, Pablo Musé|<http://arxiv.org/pdf/2510.20539v1>|[代码](https://github.com/GuillermoCarbajal/Blur2Seq); 提出了一种深度学习方法，能从单张运动模糊图像中同时估计出清晰图像和相机运动轨迹，实现了运动模糊的盲去...|
|🆕 发布|EchoDistill: Bidirectional Concept Distillation for One-Step Diffusion Personalization|回声蒸馏：一步扩散个性化中的双向概念蒸馏|Yixiong Yang, Tao Wu, Senmao Li, Shiqi Yang, Yaxing Wang, Joost van de Weijer, Kai Wang|<http://arxiv.org/pdf/2510.20512v1>|提出了一种双向概念蒸馏框架EchoDistill，通过教师与学生模型协同训练，实现了快速有效的文本到...|
|📝 更新|FairGen: Enhancing Fairness in Text-to-Image Diffusion Models via Self-Discovering Latent Directions|FairGen：通过自我发现的潜在方向增强文本到图像扩散模型中的公平性|Yilei Jiang, Weihong Li, Yiyuan Zhang, Minghong Cai, Xiangyu Yue|<http://arxiv.org/pdf/2412.18810v3>|FairGen通过自我发现潜在方向，无需参考数据集，有效消除扩散模型中的偏见。|
|📝 更新|VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation|VO-DP：面向视觉独驱机器人操作的任务语义-几何自适应扩散策略|Zehao Ni, Yonghao He, Lingfeng Qian, Jilei Mao, Fa Fu, Wei Sui, Hu Su, Junran Peng .etc.|<http://arxiv.org/pdf/2510.15530v3>|提出了一种视觉基础模型驱动的语义几何融合策略，实现了视觉仅凭方案在机器人操作中的性能提升。|
|🆕 发布|AccuQuant: Simulating Multiple Denoising Steps for Quantizing Diffusion Models|AccuQuant：为量化扩散模型模拟多步去噪过程|Seunghoon Lee, Jeongwoo Choi, Byunggwan Son, Jaehyeon Moon, Jeimin Jeon, Bumsub Ham|<http://arxiv.org/pdf/2510.20348v1>|提出AccuQuant方法，通过模拟多步去噪过程减少量化误差积累，显著提升扩散模型量化后的性能。|
|🆕 发布|AnyPcc: Compressing Any Point Cloud with a Single Universal Model|AnyPcc: 使用单一通用模型压缩任意点云|Kangli Wang, Qianxi Yi, Yuqi Ye, Shihao Li, Wei Gao|<http://arxiv.org/pdf/2510.20331v1>|提出了一种通用的点云压缩框架 AnyPcc，通过结合全局上下文模型和实例自适应微调策略，有效解决了点...|
|📝 更新|Comprehensive Evaluation and Analysis for NSFW Concept Erasure in Text-to-Image Diffusion Models|计算机视觉中文论文标题翻译：  文本到图像扩散模型中不良内容概念擦除的全面评估与分析|Die Chen, Zhiwen Li, Cen Chen, Yuexiang Xie, Xiaodan Li, Jinyan Ye, Yingda Chen, Yaliang Li|<http://arxiv.org/pdf/2505.15450v2>|系统评估了文本到图像扩散模型中不安全内容的概念擦除方法，提供了实际应用指导。|
|📝 更新|LucidFlux: Caption-Free Universal Image Restoration via a Large-Scale Diffusion Transformer|LucidFlux：无需字幕的通用图像恢复——通过大规模扩散变换器|Song Fei, Tian Ye, Lujia Wang, Lei Zhu|<http://arxiv.org/pdf/2509.22414v2>|LucidFlux通过无需文本描述的大规模扩散变换器，实现了在未知混合退化条件下的图像恢复，同时保持...|
|📝 更新|PlantSegNeRF: A few-shot, cross-species method for plant 3D instance point cloud reconstruction via joint-channel NeRF with multi-view image instance matching|植物SegNeRF：一种基于联合通道NeRF与多视角图像实例匹配的少样本、跨物种植物三维实例点云重建方法|Xin Yang, Ruiming Du, Hanyang Huang, Jiayang Xie, Pengyao Xie, Leisen Fang, Ziyue Guo, Nanjun Jiang .etc.|<http://arxiv.org/pdf/2507.00371v2>|提出了一种PlantSegNeRF方法，通过多视角图像匹配和神经辐射场，实现了跨物种植物器官的高精度...|
|📝 更新|CBDiff:Conditional Bernoulli Diffusion Models for Image Forgery Localization|CBDiff：条件伯努利扩散模型用于图像伪造定位|Zhou Lei, Pan Gang, Wang Jiahao, Sun Di|<http://arxiv.org/pdf/2510.19597v2>|提出了一种生成多张定位图的Conditional Bernoulli Diffusion Model...|
|📝 更新|OpenWorldSAM: Extending SAM2 for Universal Image Segmentation with Language Prompts|开放世界SAM：使用语言提示扩展SAM2进行通用图像分割|Shiting Xiao, Rishabh Kabra, Yuhang Li, Donghyun Lee, Joao Carreira, Priyadarshini Panda|<http://arxiv.org/pdf/2507.05427v2>|[代码](https://github.com/GinnyXiao/OpenWorldSAM.); OpenWorldSAM通过集成轻量级视觉语言模型，实现了基于开放语言提示的通用图像分割，提升了对未...|
|📝 更新|Generative diffusion model surrogates for mechanistic agent-based biological models|生成扩散模型代理在机理性基于代理的生物模型中的应用|Tien Comlekoglu, J. Quetzalcoatl Toledo-Marín, Douglas W. DeSimone, Shayn M. Peirce, Geoffrey Fox, James A. Glazier|<http://arxiv.org/pdf/2505.09630v3>|利用生成扩散模型训练代理模型，大幅减少复杂生物系统计算时间。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UltraHR-100K: Enhancing UHR Image Synthesis with A Large-Scale High-Quality Dataset|超分辨率图像合成增强：基于大规模高质量数据集的UltraHR-100K|Chen Zhao, En Ci, Yunzhe Xu, Tiehan Fan, Shanyan Guan, Yanhao Ge, Jian Yang, Ying Tai|<http://arxiv.org/pdf/2510.20661v1>|[代码](https://github.com/NJU-PCALab/UltraHR-100k); 提出了大规模高质量超高清图像数据集UltraHR-100K和频率感知后训练方法，显著提升了超高清文本...|
|🆕 发布|Transferable Black-Box One-Shot Forging of Watermarks via Image Preference Models|通过图像偏好模型实现的迁移性黑盒单次水印伪造|Tomáš Souček, Sylvestre-Alvise Rebuffi, Pierre Fernandez, Nikola Jovanović, Hady Elsahar, Valeriu Lacatusu, Tuan Tran, Alexandre Mourachko|<http://arxiv.org/pdf/2510.20468v1>|提出了一种利用图像偏好模型进行一键式水印盗用和伪造的新方法，简化了攻击过程并质疑了现有水印技术的安全...|
|📝 更新|PreFM: Online Audio-Visual Event Parsing via Predictive Future Modeling|预未来建模的在线音频视觉事件解析：PreFM|Xiao Yu, Yan Fang, Xiaojie Jin, Yao Zhao, Yunchao Wei|<http://arxiv.org/pdf/2505.23155v2>|[代码](https://github.com/XiaoYu-1123/PreFM.); 提出在线音频视觉事件解析方法PreFM，通过预测未来多模态信息增强实时视频理解能力。|
|📝 更新|Direct Numerical Layout Generation for 3D Indoor Scene Synthesis via Spatial Reasoning|通过空间推理的3D室内场景合成直接数值布局生成|Xingjian Ran, Yixuan Li, Linning Xu, Mulin Yu, Bo Dai|<http://arxiv.org/pdf/2506.05341v2>|提出了一种基于大型语言模型空间推理的3D室内场景布局生成方法，实现了灵活且符合用户指令的高质量场景生...|
|🆕 发布|FlowCycle: Pursuing Cycle-Consistent Flows for Text-based Editing|《FlowCycle：追求基于文本编辑的循环一致性流》|Yanghao Wang, Zhen Wang, Long Chen|<http://arxiv.org/pdf/2510.20212v1>|提出了一种目标感知的图像编辑框架FlowCycle，通过循环一致性优化，实现了高保真度和源一致性编辑...|
|🆕 发布|Multimedia-Aware Question Answering: A Review of Retrieval and Cross-Modal Reasoning Architectures|多媒体感知问答：检索与跨模态推理架构综述|Rahul Raja, Arpita Vats|<http://arxiv.org/pdf/2510.20193v1>|综述了融合多媒体信息检索与用户查询的问答系统架构，探讨了跨模态对齐等挑战及未来研究方向。|
|🆕 发布|Inverse Image-Based Rendering for Light Field Generation from Single Images|基于逆向图像渲染的单张图像光场生成|Hyunjun Jung, Hae-Gon Jeon|<http://arxiv.org/pdf/2510.20132v1>|提出了一种从单张图像生成光场的逆图像渲染方法，通过存储和计算光流关系，实现了无需额外设备和训练的高效...|
|🆕 发布|Attentive Convolution: Unifying the Expressivity of Self-Attention with Convolutional Efficiency|注意力卷积：统一自注意力表达性与卷积效率|Hao Yu, Haoyu Chen, Yan Jiang, Wei Peng, Zhaodong Sun, Samuel Kaski, Guoying Zhao|<http://arxiv.org/pdf/2510.20092v1>|[代码](https://github.com/price112/Attentive-Convolution.); 提出了一种融合自注意力表达性和卷积效率的Attentive Convolution，实现了高性能与低...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OnlineSplatter: Pose-Free Online 3D Reconstruction for Free-Moving Objects|在线散点：面向自由移动物体的无姿态在线三维重建|Mark He Huang, Lin Geng Foo, Christian Theobalt, Ying Sun, De Wen Soh|<http://arxiv.org/pdf/2510.20605v1>|提出OnlineSplatter方法，无需相机位姿或深度信息，实现自由移动物体的在线高质量3D重建。|
|🆕 发布|From Far and Near: Perceptual Evaluation of Crowd Representations Across Levels of Detail|从远及近：跨细节层次的人群表征的感知评估|Xiaohan Sun, Carol O'Sullivan|<http://arxiv.org/pdf/2510.20558v1>|探究了不同细节级别和视距下人群角色表示的视觉质量，为设计感知优化的细节层次策略提供了指导。|
|📝 更新|A primal-dual algorithm for image reconstruction with input-convex neural network regularizers|基于输入凸神经网络正则化的图像重建原始-对偶算法|Matthias J. Ehrhardt, Subhadip Mukherjee, Hok Shing Wong|<http://arxiv.org/pdf/2410.12441v2>|提出了一种基于输入凸神经网络的原始对偶算法，有效解决了数据驱动变分重建框架中的优化问题。|


## 时序视觉分析 (Temporal Visual Analysis)


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Radar-Camera Fused Multi-Object Tracking: Online Calibration and Common Feature|雷达-相机融合的多目标跟踪：在线校准与通用特征|Lei Cheng, Siyang Cao|<http://arxiv.org/pdf/2510.20794v1>|[代码](https://github.com/radar-lab/Radar_Camera_MOT); 融合雷达与摄像头数据，实现在线校准的多目标跟踪框架，提升跟踪效率与精度。|
|🆕 发布|Physics-Guided Fusion for Robust 3D Tracking of Fast Moving Small Objects|物理引导融合以实现快速移动小目标的鲁棒三维跟踪|Prithvi Raj Singh, Raju Gottumukkala, Anthony S. Maida, Alan B. Barhorst, Vijaya Gopu|<http://arxiv.org/pdf/2510.20126v1>|提出了一种结合深度学习和物理模型的3D追踪系统，有效应对快速移动小物体的追踪难题。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Face-Human-Bench: A Comprehensive Benchmark of Face and Human Understanding for Multi-modal Assistants|人脸-人体-基准：面向多模态助手的全面人脸与人体理解评估集|Lixiong Qin, Shilong Ou, Miaoxuan Zhang, Jiangning Wei, Yuhang Zhang, Xiaoshuai Song, Yuchen Liu, Mei Wang .etc.|<http://arxiv.org/pdf/2501.01243v3>|提出了Face-Human-Bench，一个全面评估多模态助手对 faces 和 humans 理解...|
|🆕 发布|GMFVAD: Using Grained Multi-modal Feature to Improve Video Anomaly Detection|基于粒度多模态特征的异常视频检测改进方法GMFVAD|Guangyu Dai, Dong Chen, Siliang Tang, Yueting Zhuang|<http://arxiv.org/pdf/2510.20268v1>|提出细粒度多模态特征融合方法GMFVAD，减少视觉特征冗余，提升视频异常检测性能。|


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SPAN: Continuous Modeling of Suspicion Progression for Temporal Intention Localization|SPAN：连续建模怀疑进展以实现时间意图定位|Xinyi Hu, Yuran Wang, Yue Li, Wenxuan Liu, Zheng Wang|<http://arxiv.org/pdf/2510.20189v1>|提出连续建模方法SPAN，通过回归分析捕捉可疑意图的波动和演变，提升视频监控的早期干预和解释性。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Renaissance of Explicit Motion Information Mining from Transformers for Action Recognition|显式运动信息挖掘在动作识别中从变换器的复兴|Peiqin Zhuang, Lei Bai, Yichao Wu, Ding Liang, Luping Zhou, Yali Wang, Wanli Ouyang|<http://arxiv.org/pdf/2510.18705v2>|[代码](https://github.com/PeiqinZhuang/EMIM); 提出了一种显式运动信息挖掘模块，有效融合了运动建模特性，提升了动作识别在运动敏感数据集上的性能。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation|基于相似性的原型无监督领域自适应用于跨模态分割|Ziyu Ye, Chen Ju, Chaofan Ma, Xiaoyun Zhang|<http://arxiv.org/pdf/2510.20596v1>|提出了一种基于相似性原型的无监督域自适应方法，有效提升了跨模态分割性能。|
|📝 更新|Rebalancing Contrastive Alignment with Bottlenecked Semantic Increments in Text-Video Retrieval|在文本-视频检索中用瓶颈语义增量重平衡对比对齐|Jian Xiao, Zijie Song, Jialong Hu, Hao Cheng, Jia Li, Zhenzhen Hu, Richang Hong|<http://arxiv.org/pdf/2505.12499v5>|[代码](https://github.com/musicman217/GARE-text-video-retrieval.); 提出GARE框架缓解模态差距带来的优化张力，通过特定增量增强文本-视频检索的准确性和鲁棒性。|
|📝 更新|Learning Contrastive Feature Representations for Facial Action Unit Detection|学习用于面部动作单元检测的对偶特征表示|Zi-Qiao Shang, Bin Liu, Feng-Mao Lv, Fei Teng, Tian-Rui Li, Lan-Zhe Guo|<http://arxiv.org/pdf/2402.06165v7>|[代码](https://github.com/Ziqiao-Shang/AUNCE.); 提出了一种结合自监督和监督信号的对比学习框架，通过调整参数更新步长和采样技术，有效提升了面部动作单元...|
|🆕 发布|TOMCAT: Test-time Comprehensive Knowledge Accumulation for Compositional Zero-Shot Learning|TOMCAT: 测试时综合知识积累用于组合零样本学习|Xudong Yan, Songhe Feng|<http://arxiv.org/pdf/2510.20162v1>|[代码](https://github.com/xud-yan/TOMCAT); 提出了一种在测试时通过无监督数据累积文本和视觉模态的全面知识，动态调整原型以适应分布偏移的零样本学习...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples|压缩以震撼：使用单个梯度步骤在100个样本上高效适应大型语言模型|Shiva Sreeram, Alaa Maalouf, Pratyusha Sharma, Daniela Rus|<http://arxiv.org/pdf/2510.20800v1>|提出了一种高效的大模型适应新任务方法，仅需在100个样本上单步梯度更新，无需完整数据集微调。|
|🆕 发布|AlphaFlow: Understanding and Improving MeanFlow Models|AlphaFlow：理解与改进均值流模型|Huijie Zhang, Aliaksandr Siarohin, Willi Menapace, Michael Vasilkovsky, Sergey Tulyakov, Qing Qu, Ivan Skorokhodov|<http://arxiv.org/pdf/2510.20771v1>|揭示了MeanFlow模型优化冲突问题，提出α-Flow方法，有效改善收敛速度并实现最优性能。|
|🆕 发布|Mixing Importance with Diversity: Joint Optimization for KV Cache Compression in Large Vision-Language Models|融合重要性与多样性：大型视觉语言模型中KV缓存压缩的联合优化|Xuyang Liu, Xiyan Gui, Yuchao Zhang, Linfeng Zhang|<http://arxiv.org/pdf/2510.20707v1>|[代码](https://github.com/xuyang-liu16/MixKV); 提出了一种结合重要性和多样性的KV缓存压缩方法MixKV，有效解决了大型视觉语言模型内存瓶颈问题。|
|📝 更新|Balanced Token Pruning: Accelerating Vision Language Models Beyond Local Optimization|平衡标记剪枝：超越局部优化的视觉语言模型加速方法|Kaiyuan Li, Xiaoyue Chen, Chen Gao, Yong Li, Xinlei Chen|<http://arxiv.org/pdf/2505.22038v2>|[代码](https://github.com/EmbodiedCity/NeurIPS2025-Balanced-Token-Pruning.); 提出了一种平衡剪枝策略，有效减少视觉语言模型计算负担同时保持性能。|
|📝 更新|The Faiss library|Faiss库|Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy, Pierre-Emmanuel Mazaré, Maria Lomeli, Lucas Hosseini .etc.|<http://arxiv.org/pdf/2401.08281v4>|提出Faiss库，优化向量相似性搜索，提升向量数据库管理效率。|
|🆕 发布|Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role of Context|为何LVLMs在更长回应中更易产生幻觉：上下文的作用|Ge Zheng, Jiaye Qian, Jiajin Tang, Sibei Yang|<http://arxiv.org/pdf/2510.20229v1>|揭示了长回答中LVLMs易产生幻觉的深层原因是依赖上下文，并提出了“诱导-检测-抑制”框架来减少幻觉...|
|📝 更新|REOrdering Patches Improves Vision Models|“重排图像块可提升视觉模型性能”|Declan Kutscher, David M. Chan, Yutong Bai, Trevor Darrell, Ritwik Gupta|<http://arxiv.org/pdf/2505.23751v3>|提出了一种优化图像块顺序的框架REOrder，通过学习任务最优的顺序显著提升模型准确性。|
|🆕 发布|PPMStereo: Pick-and-Play Memory Construction for Consistent Dynamic Stereo Matching|PPMStereo：用于一致性动态立体匹配的即点即玩内存构建|Yun Wang, Junjie Hu, Qiaole Dong, Yongjian Zhang, Yanwei Fu, Tin Lun Lam, Dapeng Wu|<http://arxiv.org/pdf/2510.20178v1>|[代码](https://github.com/cocowy1/PPMStereo); 提出了一种高效的动态立体匹配方法PPMStereo，通过构建记忆缓冲区实现长距离时空一致性建模。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Efficient Multi-bit Quantization Network Training via Weight Bias Correction and Bit-wise Coreset Sampling|通过权重偏置校正和位宽核心集采样的高效多比特量化网络训练|Jinhee Kim, Jae Jun An, Kang Eun Jeon, Jong Hwan Ko|<http://arxiv.org/pdf/2510.20673v1>|[代码](https://github.com/a2jinhee/EMQNet_jk.); 提出方法减少多比特量化网络训练负担，通过权重偏置校正和位向核心集采样提高效率。|
|📝 更新|CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs|连续自适应卷积：用于时间依赖偏微分方程潜在空间建模的CALM-PDE|Jan Hagnberger, Daniel Musekamp, Mathias Niepert|<http://arxiv.org/pdf/2505.12944v2>|提出了一种连续自适应卷积神经网络模型CALM-PDE，高效解决任意离散化PDEs，提升内存和推理效率...|
|🆕 发布|HybridSOMSpikeNet: A Deep Model with Differentiable Soft Self-Organizing Maps and Spiking Dynamics for Waste Classification|混合SOM尖峰网：一种具有可微分软自组织映射与尖峰动态的深度模型，用于废物分类|Debojyoti Ghosh, Adrijit Goswami|<http://arxiv.org/pdf/2510.20669v1>|提出了一种结合深度学习与脉冲神经网络的HybridSOMSpikeNet模型，实现了高效准确的废物分...|
|🆕 发布|Deep Learning in Dental Image Analysis: A Systematic Review of Datasets, Methodologies, and Emerging Challenges|深度学习在牙科图像分析中的应用：数据集、方法及新兴挑战的系统综述|Zhenhuan Zhou, Jingbo Zhu, Yuchen Zhang, Xiaohang Guan, Peng Wang, Tao Li|<http://arxiv.org/pdf/2510.20634v1>|系统综述了深度学习在牙科图像分析中的应用，涵盖数据集、模型及其挑战，助力提升诊断效率和精确性。|
|🆕 发布|Fake-in-Facext: Towards Fine-Grained Explainable DeepFake Analysis|面向细粒度可解释深度伪造分析的方法研究：Fake-in-Facext|Lixiong Qin, Yang Zhang, Mei Wang, Jiani Hu, Weihong Deng, Weiran Xu|<http://arxiv.org/pdf/2510.20531v1>|[代码](https://github.com/lxq1000/Fake-in-Facext.); 提出细粒度数据标注和模型架构，实现深度伪造的可解释分析，提升了对视觉伪造证据的理解。|
|📝 更新|Sign-In to the Lottery: Reparameterizing Sparse Training From Scratch|“签到抽奖：从头开始重参数化稀疏训练”|Advait Gadhikar, Tom Jacobs, Chao Zhou, Rebekka Burkholz|<http://arxiv.org/pdf/2504.12801v2>|提出Sign-In方法，通过动态重参数化诱导符号翻转，缩小从头开始训练稀疏神经网络与密集转稀疏训练的...|
|📝 更新|Quantization-Aware Neuromorphic Architecture for Efficient Skin Disease Classification on Resource-Constrained Devices|量化感知类神经形态架构用于资源受限设备上的高效皮肤病分类|Haitian Wang, Xinyu Wang, Yiren Wang, Zichen Geng, Xian Zhang, Yu Zhang, Bo Miao|<http://arxiv.org/pdf/2507.15958v2>|提出了一种量化的类神经形态架构QANA，实现了在资源受限设备上高效准确的皮肤疾病分类。|
|🆕 发布|GUSL-Dehaze: A Green U-Shaped Learning Approach to Image Dehazing|绿色U型学习法在图像去雾中的应用：GUSL-Dehaze|Mahtab Movaheddrad, Laurence Palmer, C. -C. Jay Kuo|<http://arxiv.org/pdf/2510.20266v1>|提出了一种结合物理模型与绿色学习框架的轻量级图像去雾方法，实现了参数减少与性能提升。|
|🆕 发布|Empower Words: DualGround for Structured Phrase and Sentence-Level Temporal Grounding|赋予词语力量：DualGround 用于结构化短语和句子级别的时序定位|Minseok Kang, Minhyeok Lee, Minjung Kim, Donghyeong Kim, Sangyoun Lee|<http://arxiv.org/pdf/2510.20244v1>|提出了一种双分支结构的DualGround方法，通过分离全局和局部语义，提高了视频时间定位的精细度和...|
|📝 更新|Spiking Neural Networks Need High Frequency Information|尖峰神经网络需要高频信息|Yuetong Fang, Deming Zhou, Ziqing Wang, Hongwei Ren, ZeCui Zeng, Lusong Li, Shibo Zhou, Renjing Xu|<http://arxiv.org/pdf/2505.18608v4>|[代码](https://github.com/bic-L/MaxFormer.); 揭示了Spiking Neural Networks中的频率偏差问题，并通过Max-Former网络...|
|🆕 发布|Endoshare: A Source Available Solution to De-Identify and Manage Surgical Videos|内窥共享：一种开源解决方案用于去识别和管理手术视频|Lorenzo Arboit, Dennis N. Schneider, Britty Baby, Vinkle Srivastav, Pietro Mascagni, Nicolas Padoy|<http://arxiv.org/pdf/2510.20087v1>|[代码](https://camma-public.github.io/Endoshare); 提出Endoshare系统，解决手术视频格式不统一和隐私问题，实现标准化和去识别处理。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|PolyPose: Deformable 2D/3D Registration via Polyrigid Transformations|PolyPose：基于多项刚体变换的变形二维/三维配准|Vivek Gopalakrishnan, Neel Dey, Polina Golland|<http://arxiv.org/pdf/2505.19256v5>|提出了一种基于多刚体变换的2D/3D配准方法PolyPose，能够在仅两张X射线图像的情况下实现精确...|
|🆕 发布|HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models|HyperET：用于多模态大型语言模型的双曲空间高效训练|Zelin Peng, Zhengqin Xu, Qingyang Liu, Xiaokang Yang, Wei Shen|<http://arxiv.org/pdf/2510.20322v1>|提出了一种在双曲空间中训练多模态大型语言模型的高效方法，通过动态调整双曲半径实现视觉与文本在多粒度级...|
|🆕 发布|Kinaema: a recurrent sequence model for memory and pose in motion|动态记忆与姿态的循环序列模型：Kinaema|Mert Bulent Sariyildiz, Philippe Weinzaepfel, Guillaume Bono, Gianluca Monaci, Christian Wolf|<http://arxiv.org/pdf/2510.20261v1>|提出了一种能够高效处理视觉信息并预测空间位置关系的循环序列模型Kinaema，优化了机器人定位效率。|
|📝 更新|Sherlock: Self-Correcting Reasoning in Vision-Language Models|Sherlock: 视觉语言模型中的自纠正推理|Yi Ding, Ruqi Zhang|<http://arxiv.org/pdf/2505.22651v2>|提出Sherlock框架，通过自我修正提升视觉语言模型的推理能力，减少对大量标注数据的依赖。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Reliable and Reproducible Demographic Inference for Fairness in Face Analysis|可靠且可复制的面部分析公平性人口统计推断|Alexandre Fournier-Montgieux, Hervé Le Borgne, Adrian Popescu, Bertrand Luvison|<http://arxiv.org/pdf/2510.20482v1>|提出了一种模块化迁移学习的人脸属性推断方法，提高了公平性审计的可靠性和可重复性。|
|🆕 发布|UI-Ins: Enhancing GUI Grounding with Multi-Perspective Instruction-as-Reasoning|UI-Ins：利用多视角指令推理增强图形界面定位|Liangyu Chen, Hanzhang Zhou, Chenglin Cai, Jianan Zhang, Panrong Tong, Quyu Kong, Xu Zhang, Chen Liu .etc.|<http://arxiv.org/pdf/2510.20286v1>|[代码](https://github.com/alibaba/UI-Ins.); 提出多视角指令推理框架UI-Ins，通过多样化指令训练和强化学习提升GUI定位性能。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Tex-ViT: A Generalizable, Robust, Texture-based dual-branch cross-attention deepfake detector|《Tex-ViT：一种通用型、鲁棒性、基于纹理的双分支交叉注意力深度伪造检测器》|Deepak Dagar, Dinesh Kumar Vishwakarma|<http://arxiv.org/pdf/2408.16892v2>|提出了一种结合ResNet和视觉变换器的Tex-ViT模型，有效提高了跨域场景下深度伪造检测的准确性...|
|🆕 发布|Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking|恐龙扩散模块化设计缩小了自主泊车中的跨域差距|Zixuan Wu, Hengyuan Zhang, Ting-Hsuan Chen, Yuliang Guo, David Paz, Xinyu Huang, Liu Ren|<http://arxiv.org/pdf/2510.20335v1>|提出了一种跨域通用的自主停车方法Dino-Diffusion，通过结合视觉基础模型和扩散规划，实现了...|
|📝 更新|RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety Evaluation via Role-Specialized Collaboration|雷达：一种基于角色专业化协作的面向大型语言模型安全性评估的风险感知动态多智能体框架|Xiuyuan Chen, Jian Zhao, Yuchen Yuan, Tianle Zhang, Huilin Zhou, Zheng Zhu, Ping Hu, Linghe Kong .etc.|<http://arxiv.org/pdf/2509.25271v4>|提出了一种风险感知的多智能体协作框架RADAR，通过角色专业化合作和动态更新机制，有效提高了大型语言...|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Learning Dense Hand Contact Estimation from Imbalanced Data|从非平衡数据中学习密集手部接触估计|Daniel Sungho Jung, Kyoung Mu Lee|<http://arxiv.org/pdf/2505.11152v2>|[代码](https://github.com/dqj5182/HACO_RELEASE.); 提出了一种处理不平衡数据的手部接触密集估计框架，通过平衡采样和顶点级损失重加权解决了类别和空间不平衡...|
|🆕 发布|Revisiting Logit Distributions for Reliable Out-of-Distribution Detection|重新审视逻辑分布以提高异常检测的可靠性|Jiachen Liang, Ruibing Hou, Minyang Hu, Hong Chang, Shiguang Shan, Xilin Chen|<http://arxiv.org/pdf/2510.20134v1>|[代码](https://github.com/GIT-LJc/LogitGap.); 提出LogitGap方法，利用模型logits空间信息增强分布内外样本分离度，实现可靠的开集异常检测...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SpectraMorph: Structured Latent Learning for Self-Supervised Hyperspectral Super-Resolution|《SpectraMorph：用于自监督高光谱超分辨率的结构化潜在学习》|Ritik Shah, Marco F Duarte|<http://arxiv.org/pdf/2510.20814v1>|提出了一种基于物理引导的自监督融合框架SpectraMorph，通过结构化潜在空间提升超光谱图像超分...|
|🆕 发布|GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation|GSWorld：机器人操作闭环真实感照片模拟套件|Guangqi Jiang, Haoran Chang, Ri-Zhao Qiu, Yutong Liang, Mazeyu Ji, Jiyue Zhu, Zhao Dong, Xueyan Zou .etc.|<http://arxiv.org/pdf/2510.20813v1>|[代码](https://3dgsworld.github.io/.); 提出GSWorld，一种结合3D Gaussian Splatting与物理引擎的逼真机器人操作模拟...|
|📝 更新|Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?|强化学习真的能激励大型语言模型超越基础模型的推理能力吗？|Yang Yue, Zhiqi Chen, Rui Lu, Andrew Zhao, Zhaokai Wang, Yang Yue, Shiji Song, Gao Huang|<http://arxiv.org/pdf/2504.13837v4>|发现当前强化学习未能充分激发大语言模型的新推理能力，需改进学习范式。|
|📝 更新|Residual Kolmogorov-Arnold Network for Enhanced Deep Learning|残差科尔莫哥洛夫-阿尔诺德网络用于增强深度学习|Ray Congrui Yu, Sherry Wu, Jiang Gui|<http://arxiv.org/pdf/2410.05500v3>|提出了一种高度紧凑的Residual Kolmogorov-Arnold网络模块，有效优化深度学习网...|
|📝 更新|BevSplat: Resolving Height Ambiguity via Feature-Based Gaussian Primitives for Weakly-Supervised Cross-View Localization|通过基于特征的高斯基元解决高度模糊性：用于弱监督跨视角定位的BevSplat方法|Qiwei Wang, Shaoxun Wu, Yujiao Shi|<http://arxiv.org/pdf/2502.09080v3>|提出了一种基于特征高斯原语的BevSplat方法，解决了弱监督跨视角定位中的高度模糊问题，显著提升了...|
|📝 更新|Rebellious Student: A Complementary Learning Framework for Background Feature Enhancement in Hyperspectral Anomaly Detection|《叛逆学生：一种用于高光谱异常检测中背景特征增强的补充学习框架》|Wenping Jin, Yuyang Tang, Li Zhu, Fei Guo|<http://arxiv.org/pdf/2510.18781v2>|[代码](https://github.com/xjpp2016/FERS.); 提出了一种“反叛学生”框架，通过互补学习增强高光谱异常检测中的背景特征，无需场景特定训练即可提升检测...|
|📝 更新|Revisiting End-to-End Learning with Slide-level Supervision in Computational Pathology|重新审视计算病理学中基于切片级监督的端到端学习|Wenhao Tang, Rong Qin, Heng Fang, Fengtao Zhou, Hao Chen, Xiang Li, Ming-Ming Cheng|<http://arxiv.org/pdf/2506.02408v2>|[代码](https://github.com/DearCaat/E2E-WSI-ABMILX.); 提出了一种针对计算病理学的端到端学习方法，通过优化多实例学习机制，实现了高效准确的病理图像分析。|
|📝 更新|VT-FSL: Bridging Vision and Text with LLMs for Few-Shot Learning|VT-FSL：使用大规模语言模型连接视觉与文本以进行少样本学习|Wenhao Li, Qiangchang Wang, Xianjing Meng, Zhibin Wu, Yilong Yin|<http://arxiv.org/pdf/2509.25033v3>|[代码](https://github.com/peacelwh/VT-FSL.); 提出VT-FSL框架，利用大型语言模型和视觉数据生成精确描述，实现高效的少量样本学习。|
|📝 更新|Learning To Defer To A Population With Limited Demonstrations|学习在有限示范下向群体延迟决策|Nilesh Ramgolam, Gustavo Carneiro, Hsiang-Ting Chen|<http://arxiv.org/pdf/2510.19351v2>|[代码](https://github.com/nil123532/learning-to-defer-to-a-population-with-limited-demonstrations.); 提出了一种半监督元学习方法，通过少量示范生成专家特定嵌入，有效解决了学习延迟系统中的数据稀缺问题。|
|🆕 发布|Why Prototypes Collapse: Diagnosing and Preventing Partial Collapse in Prototypical Self-Supervised Learning|为何原型会崩溃：诊断和预防原型自监督学习中的部分崩溃|Gabriel Y. Arteaga, Marius Aasan, Rwiddhi Chakraborty, Martine Hjelkrem-Tan, Thalles Silva, Michael Kampffmeyer, Adín Ramírez Rivera|<http://arxiv.org/pdf/2510.20108v1>|提出了一种解耦训练策略，有效解决了自监督学习中原型坍塌问题，提升了表示多样性和下游性能。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation|小草图，大判断：通过推测进行信息密集型视觉推理|Yuhan Liu, Lianhui Qin, Shengjie Wang|<http://arxiv.org/pdf/2510.20812v1>|[代码](https://github.com/Tinaliu0123/speculative-verdict); 提出了一种无需训练的Speculative Verdict框架，通过多个轻量级模型生成候选推理路径并...|
|🆕 发布|MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging Most Exciting Inputs|MEIcoder：通过利用最激动人心的输入从神经活动中解码视觉刺激|Jan Sobotka, Luca Baroni, Ján Antolík|<http://arxiv.org/pdf/2510.20762v1>|提出了一种利用特定神经元最兴奋输入的生物启发解码方法MEIcoder，在小数据集上实现了视觉刺激的高...|
|📝 更新|mmWalk: Towards Multi-modal Multi-view Walking Assistance|面向多模态多视角步行辅助的mmWalk方法|Kedi Ying, Ruiping Liu, Chongyan Chen, Mingzhe Tao, Hao Shi, Kailun Yang, Jiaming Zhang, Rainer Stiefelhagen|<http://arxiv.org/pdf/2510.11520v2>|构建了mmWalk多模态多视角数据集，助力视障人士在复杂环境中安全导航。|
|📝 更新|Spatial-DISE: A Unified Benchmark for Evaluating Spatial Reasoning in Vision-Language Models|空间DISE：一种用于评估视觉语言模型空间推理的统一基准|Xinmiao Huang, Qisong He, Zhenglin Huang, Boxuan Wang, Zhuoyun Li, Guangliang Cheng, Yi Dong, Xiaowei Huang|<http://arxiv.org/pdf/2510.13394v2>|提出了统一的空间推理评估基准 Spatial-DISE，解决了现有评估不足的问题，并创建了多样化的数...|
|🆕 发布|Deep Learning-Powered Visual SLAM Aimed at Assisting Visually Impaired Navigation|面向辅助视障导航的深度学习驱动的视觉SLAM|Marziyeh Bamdad, Hans-Peter Hutter, Alireza Darvishy|<http://arxiv.org/pdf/2510.20549v1>|提出了一种深度学习增强的视觉SLAM框架SELM-SLAM3，显著提升了在低纹理和动态场景下的导航可...|
|🆕 发布|Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence|Conan：在多尺度视觉证据上像侦探一样逐步推理学习|Kun Ouyang, Yuanxin Liu, Linli Yao, Yishuo Cai, Hao Zhou, Jie Zhou, Fandong Meng, Xu Sun|<http://arxiv.org/pdf/2510.20470v1>|提出了一种基于多尺度视觉证据的证据引导的多步视频推理框架Conan，有效提升了多模态大语言模型的推理...|
|🆕 发布|Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning|“Metis-HOME：多模态推理的混合优化专家模型”|Xiaohan Lan, Fanfan Liu, Haibo Qiu, Siqi Yang, Delian Ruan, Peng Shi, Lin Ma|<http://arxiv.org/pdf/2510.20519v1>|提出了一种混合优化专家模型Metis-HOME，通过区分思维和非思维分支，平衡了多模态推理的复杂任务...|
|📝 更新|VITRIX-CLIPIN: Enhancing Fine-Grained Visual Understanding in CLIP via Instruction Editing Data and Long Captions|VITRIX-CLIPIN：通过指令编辑数据与长标题增强CLIP的细粒度视觉理解|Ziteng Wang, Siqi Yang, Limeng Qiao, Lin Ma|<http://arxiv.org/pdf/2508.02329v4>|通过引入指令编辑数据和长描述性字幕，CLIP-IN增强了视觉语言模型对细粒度视觉理解的性能。|
|🆕 发布|DMC$^3$: Dual-Modal Counterfactual Contrastive Construction for Egocentric Video Question Answering|DMC$^3$: 双模态反事实对比构建用于自我中心视频问答|Jiayi Zou, Chaofan Chen, Bing-Kun Bao, Changsheng Xu|<http://arxiv.org/pdf/2510.20285v1>|提出了一种针对第一人称视频理解的DMC$^3$框架，通过构建对比样本优化模型，有效提升了问题回答的准...|
|🆕 发布|Causal Debiasing for Visual Commonsense Reasoning|视觉常识推理的因果去偏方法|Jiayi Zou, Gengyun Jia, Bing-Kun Bao|<http://arxiv.org/pdf/2510.20281v1>|提出了一种针对视觉常识推理的因果去偏方法，通过消除数据集偏差显著提升了模型泛化能力。|
|🆕 发布|Monocular Visual 8D Pose Estimation for Articulated Bicycles and Cyclists|单目视觉下的自行车及骑行者关节8D位姿估计|Eduardo R. Corral-Soto, Yang Liu, Yuan Ren, Bai Dongfeng, Liu Bingbing|<http://arxiv.org/pdf/2510.20158v1>|提出了一种从单张RGB图像估计自行车和骑行者8D姿态的方法，提高了对自行车动态姿态和行驶方向的预测准...|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Diagnosing Visual Reasoning: Challenges, Insights, and a Path Forward|视觉推理诊断：挑战、洞见与前进之路|Jing Bi, Guangyu Sun, Ali Vosoughi, Chen Chen, Chenliang Xu|<http://arxiv.org/pdf/2510.20696v1>|提出三阶段评估框架诊断视觉推理问题，提出结合大语言模型与轻量级视觉模块的架构，实现性能显著提升。|
|📝 更新|Uncovering Anomalous Events for Marine Environmental Monitoring via Visual Anomaly Detection|通过视觉异常检测揭示海洋环境监测中的异常事件|Laura Weihl, Stefan H. Bengtson, Nejc Novak, Malte Pedersen|<http://arxiv.org/pdf/2510.10750v2>|提出使用深度学习进行水下异常事件检测，创建了首个多标注者基准数据集AURA，并证明了其在海洋生物多样...|
|🆕 发布|SeViCES: Unifying Semantic-Visual Evidence Consensus for Long Video Understanding|《SeViCES：统一语义-视觉证据共识以实现长视频理解》|Yuan Sheng, Yanbin Hao, Chenxu Li, Shuo Wang, Xiangnan He|<http://arxiv.org/pdf/2510.20622v1>|提出了一种无训练需求的SeViCES框架，通过融合语义和视觉证据选择关键帧，提高了长视频理解的准确性...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Mitigating Cross-modal Representation Bias for Multicultural Image-to-Recipe Retrieval|减轻跨模态表征偏见以促进多元文化图像到食谱检索|Qing Wang, Chong-Wah Ngo, Yu Cao, Ee-Peng Lim|<http://arxiv.org/pdf/2510.20393v1>|提出了一种预测并融入被图像忽视的烹饪元素的新方法，有效减轻了多模态表示中的文化偏见。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|ALICE-LRI: A General Method for Lossless Range Image Generation for Spinning LiDAR Sensors without Calibration Metadata|ALICE-LRI：一种无需校准元数据的旋转激光雷达传感器无损范围图像生成的通用方法|Samuel Soutullo, Miguel Yermo, David L. Vilariño, Óscar G. Lorenzo, José C. Cabaleiro, Francisco F. Rivera|<http://arxiv.org/pdf/2510.20708v1>|提出了一种无需校准数据的旋转LiDAR传感器无损范围图像生成方法，实现了点云的完美保存和几何精度。|
|📝 更新|SeG-SR: Integrating Semantic Knowledge into Remote Sensing Image Super-Resolution via Vision-Language Model|基于视觉语言模型的遥感图像超分辨率中融入语义知识的SeG-SR方法|Bowen Chen, Keyan Chen, Mohan Yang, Zhengxia Zou, Zhenwei Shi|<http://arxiv.org/pdf/2505.23010v2>|提出了一种融合语义知识的遥感图像超分辨率框架SeG-SR，通过视觉语言模型提升重建质量与一致性。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging|更好的标记实现更佳的三维效果：推进三维医学成像中的视觉-语言建模|Ibrahim Ethem Hamamci, Sezgin Er, Suprosanna Shit, Hadrien Reynaud, Dong Yang, Pengfei Guo, Marc Edgar, Daguang Xu .etc.|<http://arxiv.org/pdf/2510.20639v1>|[代码](https://github.com/ibrahimethemhamamci/BTB3D); 提出了一种新的3D医疗影像编码器，通过精确的体素级tokenization显著提升了报告生成和图像合...|
|📝 更新|OpenMIBOOD: Open Medical Imaging Benchmarks for Out-Of-Distribution Detection|开放医学成像基准测试集OpenMIBOOD：用于分布外检测的开放医学成像基准|Max Gutbrod, David Rauber, Danilo Weber Nunes, Christoph Palm|<http://arxiv.org/pdf/2503.16247v2>|[代码](https://github.com/remic-othr/OpenMIBOOD.); 提出OpenMIBOOD框架，为医学影像领域提供全面的异常输入检测基准，促进可靠AI系统发展。|
|🆕 发布|Dynamic Weight Adjustment for Knowledge Distillation: Leveraging Vision Transformer for High-Accuracy Lung Cancer Detection and Real-Time Deployment|动态权重调整用于知识蒸馏：利用视觉变换器实现高精度肺癌检测与实时部署|Saif Ur Rehman Khan, Muhammad Nabeel Asim, Sebastian Vollmer, Andreas Dengel|<http://arxiv.org/pdf/2510.20438v1>|提出动态模糊逻辑知识蒸馏方法，通过调整权重优化肺癌检测模型，提升准确性和实时部署能力。|
|📝 更新|ControlFusion: A Controllable Image Fusion Framework with Language-Vision Degradation Prompts|控制融合：一种具有语言-视觉退化提示的可控图像融合框架|Linfeng Tang, Yeda Wang, Zhanchuan Cai, Junjun Jiang, Jiayi Ma|<http://arxiv.org/pdf/2503.23356v2>|[代码](https://github.com/Linfeng-Tang/ControlFusion.); 提出了一种可控图像融合框架ControlFusion，通过语言-视觉提示适应性地中和复合退化，满足用...|
|📝 更新|A Style-Based Profiling Framework for Quantifying the Synthetic-to-Real Gap in Autonomous Driving Datasets|一种基于风格的量化自动驾驶数据集中合成与真实差距的剖析框架|Dingyi Yao, Xinyao Han, Ruibo Ming, Zhihang Song, Lihui Peng, Jianming Hu, Danya Yao, Yi Zhang|<http://arxiv.org/pdf/2510.10203v2>|提出了一种基于风格嵌入的评估框架，量化自动驾驶数据集中的合成与真实差距，促进数据质量控制和模型泛化。|
|🆕 发布|Seeing the Unseen: Mask-Driven Positional Encoding and Strip-Convolution Context Modeling for Cross-View Object Geo-Localization|看到未见之处：基于掩膜的位编码与条带卷积上下文建模的跨视角物体地理定位|Shuhan Hu, Yiru Li, Yuanyuan Li, Yingying Zhu|<http://arxiv.org/pdf/2510.20247v1>|提出了一种基于掩膜的定位编码和条带卷积的上下文建模方法，提高了跨视图目标地理定位的准确性和鲁棒性。|
|📝 更新|FuseUNet: A Multi-Scale Feature Fusion Method for U-like Networks|FuseUNet：用于U型网络的多尺度特征融合方法|Quansong He, Xiangde Min, Kaishen Wang, Tao He|<http://arxiv.org/pdf/2506.05821v3>|[代码](https://github.com/nayutayuki/FuseUNet.); 提出了一种基于微分方程的多尺度特征融合方法，有效提升了U-Net网络的特征利用效率和性能。|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Panoptic-CUDAL: Rural Australia Point Cloud Dataset in Rainy Conditions|全景-CUDAL：澳大利亚乡村雨季点云数据集|Tzu-Yun Tseng, Alexey Nekrasov, Malcolm Burdorf, Bastian Leibe, Julie Stephany Berrio, Mao Shan, Zhenxing Ming, Stewart Worrall|<http://arxiv.org/pdf/2503.16378v2>|介绍了专为雨中乡村环境设计的Panoptic-CUDAL数据集，为自动驾驶系统提供了恶劣天气下的训练...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Frequency Cam: Imaging Periodic Signals in Real-Time|频率摄像头：实时成像周期性信号|Bernd Pfrommer|<http://arxiv.org/pdf/2211.00198v2>|[代码](https://github.com/ros-event-camera/frequency_cam); 提出了一种基于事件相机的高效异步算法，能够实时检测图像像素的闪烁频率。|

