## [UPDATED!] **2025-10-25** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Benchmarking Egocentric Multimodal Goal Inference for Assistive Wearable Agents|基准测试面向辅助可穿戴代理的自传式多模态目标推理|Vijay Veerabadran, Fanyi Xiao, Nitin Kamra, Pedro Matias, Joy Chen, Caley Drooff, Brett D Roads, Riley Williams .etc.|<http://arxiv.org/pdf/2510.22443v1>|构建了WAGIBench基准，用于评估视觉语言模型在推断用户目标方面的性能，并展示了大型模型的优势。|
|🆕 发布|BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles|BLIP-FusePPO：一种面向自动驾驶车辆车道保持的视觉-语言深度强化学习框架|Seyed Ahmad Hosseini Miangoleh, Amin Jalal Aghdasian, Farzaneh Abdollahi|<http://arxiv.org/pdf/2510.22370v1>|提出了一种融合视觉语言模型与低级控制信号的多模态强化学习框架，有效提升了自动驾驶车辆在复杂环境下的车...|
|📝 更新|Open-Set 3D Semantic Instance Maps for Vision Language Navigation -- O3D-SIM|用于视觉语言导航的开集三维语义实例地图 -- O3D-SIM|Laksh Nanwani, Kumaraditya Gupta, Aditya Mathur, Swayam Agrawal, A. H. Abdul Hafez, K. Madhava Krishna|<http://arxiv.org/pdf/2404.17922v2>|[代码](https://smart-wheelchair-rrc.github.io/o3d-sim-webpage); 提出3D点云地图与实例级嵌入，增强语言导航任务的成功率和对象识别能力。|
|📝 更新|DEEMO: De-identity Multimodal Emotion Recognition and Reasoning|DEEMO：去身份化多模态情感识别与推理|Deng Li, Bohao Xing, Xin Liu, Baiqiang Xia, Bihan Wen, Heikki Kälviäinen|<http://arxiv.org/pdf/2504.19549v2>|提出了一种去身份化多模态情感识别与推理方法，保护隐私的同时实现情感理解。|
|🆕 发布|HARMONY: Hidden Activation Representations and Model Output-Aware Uncertainty Estimation for Vision-Language Models|《HARMONY：面向视觉语言模型的隐藏激活表示和模型输出感知的不确定性估计》|Erum Mushtaq, Zalan Fabian, Yavuz Faruk Bakman, Anil Ramakrishna, Mahdi Soltanolkotabi, Salman Avestimehr|<http://arxiv.org/pdf/2510.22171v1>|提出了一种融合模型内部视觉理解和输出概率分布的不确定性估计框架HARMONY，有效提升了视觉语言模型...|
|📝 更新|Vision Foundation Models as Effective Visual Tokenizers for Autoregressive Image Generation|视觉基础模型作为自回归图像生成的有效视觉标记器|Anlin Zheng, Xin Wen, Xuanyang Zhang, Chuofan Ma, Tiancai Wang, Gang Yu, Xiangyu Zhang, Xiaojuan Qi|<http://arxiv.org/pdf/2507.08441v2>|[代码](https://github.com/CVMI-Lab/VFMTok.); 提出利用冻结视觉基础模型构建图像标记器，通过区域自适应量化框架和语义重建目标提升图像生成质量与效率。|
|📝 更新|SafeEraser: Enhancing Safety in Multimodal Large Language Models through Multimodal Machine Unlearning|SafeEraser：通过多模态机器遗忘增强多模态大型语言模型的安全性|Junkai Chen, Zhijie Deng, Kening Zheng, Yibo Yan, Shuliang Liu, PeiJun Wu, Peijie Jiang, Jia Liu .etc.|<http://arxiv.org/pdf/2502.12520v6>|提出了一种针对多模态大型语言模型的安全遗忘方法，通过Prompt Decouple Loss减少过度...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EndoSfM3D: Learning to 3D Reconstruct Any Endoscopic Surgery Scene using Self-supervised Foundation Model|内镜SfM3D：使用自监督基础模型学习对任何内镜手术场景进行三维重建|Changhao Zhang, Matthew J. Clarkson, Mobarak I. Hoque|<http://arxiv.org/pdf/2510.22359v1>|[代码](https://github.com/MOYF-beta/EndoSfM3D.); 提出了一种自监督框架，通过估计内参实现了内窥镜手术场景的精确三维重建。|
|🆕 发布|Expert Validation of Synthetic Cervical Spine Radiographs Generated with a Denoising Diffusion Probabilistic Model|专家验证使用去噪扩散概率模型生成的合成颈椎X射线照片|Austin A. Barr, Brij S. Karmur, Anthony J. Winder, Eddie Guo, John T. Lysack, James N. Scott, William F. Morrish, Muneer Eesa .etc.|<http://arxiv.org/pdf/2510.22166v1>|利用去噪扩散概率模型生成逼真的颈椎X光图像，为大规模神经影像数据集创建提供新方法。|
|📝 更新|Uni-MuMER: Unified Multi-Task Fine-Tuning of Vision-Language Model for Handwritten Mathematical Expression Recognition|统一多任务微调视觉语言模型用于手写数学表达式识别|Yu Li, Jin Jiang, Jianhua Zhu, Shuai Peng, Baole Wei, Yuxuan Zhou, Liangcai Gao|<http://arxiv.org/pdf/2505.23566v4>|[代码](https://github.com/BFlameSwift/Uni-MuMER); Uni-MuMER通过全面微调预训练的视觉语言模型，整合了三种数据驱动任务，实现了手写数学表达式识别...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Vision Transformers Don't Need Trained Registers|视觉变换器无需训练寄存器|Nick Jiang, Amil Dravid, Alexei Efros, Yossi Gandelsman|<http://arxiv.org/pdf/2506.08010v5>|提出了一种无需重新训练的解决视觉变换器噪声问题的方法，通过转移高范数激活至未训练的额外令牌，改善模型...|
|📝 更新|ChA-MAEViT: Unifying Channel-Aware Masked Autoencoders and Multi-Channel Vision Transformers for Improved Cross-Channel Learning|通道感知遮蔽自编码器与多通道视觉变换器的统一：用于改进跨通道学习的ChA-MAEViT|Chau Pham, Juan C. Caicedo, Bryan A. Plummer|<http://arxiv.org/pdf/2503.19331v3>|[代码](https://github.com/chaudatascience/cha_mae_vit.); 提出了一种增强多通道图像特征学习的方法ChA-MAEViT，通过动态通道掩码和记忆 tokens 提...|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Deep Learning-Based CCTV System for Automatic Smoking Detection in Fire Exit Zones|基于深度学习的消防通道自动吸烟检测闭路电视系统|Sami Sadat, Mohammad Irtiza Hossain, Junaid Ahmed Sifat, Suhail Haque Rafi, Md. Waseq Alauddin Alvi, Md. Khalilur Rhaman|<http://arxiv.org/pdf/2508.11696v2>|提出了一种基于YOLOv8的定制深度学习模型，实现了火警出口区域实时吸烟检测，提升了对象检测性能。|
|📝 更新|A Poisson-Guided Decomposition Network for Extreme Low-Light Image Enhancement|泊松引导分解网络用于极低光照图像增强|Isha Rao, Ratul Chakraborty, Sanjay Ghosh|<http://arxiv.org/pdf/2506.04470v2>|提出了一种结合Retinex分解和Poisson去噪的深度学习方法，有效提升了极低光照条件下图像的亮...|
|🆕 发布|TrajGATFormer: A Graph-Based Transformer Approach for Worker and Obstacle Trajectory Prediction in Off-site Construction Environments|轨迹图注意力转换器：一种基于图的转换器方法用于离岸建筑环境中工人与障碍物轨迹预测|Mohammed Alduais, Xinming Li, Qipei Mei|<http://arxiv.org/pdf/2510.22205v1>|提出了一种基于图注意力网络的Transformer框架，用于预测建筑环境中工人和障碍物的轨迹，提高了...|
|📝 更新|Learning Knowledge-based Prompts for Robust 3D Mask Presentation Attack Detection|学习基于知识的提示以实现鲁棒的3D面具攻击检测|Fangling Jiang, Qi Li, Bing Liu, Weining Wang, Caifeng Shan, Zhenan Sun, Ming-Hsuan Yang|<http://arxiv.org/pdf/2505.03610v2>|提出了一种结合知识图谱的视觉-语言模型提示学习框架，有效提升3D面具攻击检测的泛化能力。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework|基于CGRA4ML框架的FPGA实时语义分割在自动驾驶车辆中应用LMIINet网络|Amir Mohammad Khadem Hosseini, Sattar Mirzakuchaki|<http://arxiv.org/pdf/2510.22243v1>|实现了一种基于FPGA的实时语义分割方法，通过LMIINet架构和CGRA4ML框架提升效率与准确性...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Simplifying Knowledge Transfer in Pretrained Models|简化预训练模型中的知识迁移|Siddharth Jain, Shyamgopal Karthik, Vineet Gandhi|<http://arxiv.org/pdf/2510.22208v1>|提出了一种自主选择教师与学生角色的预训练模型知识迁移策略，有效提升了多种任务性能。|
|🆕 发布|Frequency-Spatial Interaction Driven Network for Low-Light Image Enhancement|频率-空间交互驱动的低光照图像增强网络|Yunhong Tao, Wenbing Tao, Xiang Xiang|<http://arxiv.org/pdf/2510.22154v1>|提出了一种两阶段频率-空间交互驱动的网络，有效提升了低光照图像增强的性能和效率。|
|📝 更新|TransFace++: Rethinking the Face Recognition Paradigm with a Focus on Accuracy, Efficiency, and Security|《TransFace++：以准确性、效率和安全性为核心的重塑人脸识别范式》|Jun Dan, Yang Liu, Baigui Sun, Jiankang Deng, Shan Luo|<http://arxiv.org/pdf/2308.10133v2>|[代码](https://github.com/DanJun6737/TransFace_pp.); 提出双框架TransFace和TransFace++，利用ViTs和图像字节提升人脸识别的准确度、效...|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RestoreVAR: Visual Autoregressive Generation for All-in-One Image Restoration|RestoreVAR：全面图像复原的视觉自回归生成方法|Sudarshan Rajagopalan, Kartik Narayan, Vishal M. Patel|<http://arxiv.org/pdf/2505.18047v2>|RestoreVAR通过结合视觉自回归模型，实现了比传统扩散模型更快且性能更优的全能图像复原。|
|🆕 发布|Top-Down Semantic Refinement for Image Captioning|自顶向下语义细化用于图像标注|Jusheng Zhang, Kaitong Cai, Jing Yang, Jian Wang, Chengpei Tang, Keze Wang|<http://arxiv.org/pdf/2510.22391v1>|提出了一种Top-Down Semantic Refinement框架，通过高效的蒙特卡洛树搜索算法...|
|🆕 发布|Hollywood Town: Long-Video Generation via Cross-Modal Multi-Agent Orchestration|好莱坞小镇：通过跨模态多智能体协同实现长视频生成|Zheng Wei, Mingchen Li, Zeqian Zhang, Ruibin Yuan, Pan Hui, Huamin Qu, James Evans, Maneesh Agrawala .etc.|<http://arxiv.org/pdf/2510.22431v1>|提出了一种分层图基多智能体框架OmniAgent，通过模块化专业化和可扩展协作，实现了长视频生成中的...|
|🆕 发布|GeoDiffusion: A Training-Free Framework for Accurate 3D Geometric Conditioning in Image Generation|GeoDiffusion：一种无需训练的精确3D几何条件在图像生成中的框架|Phillip Mueller, Talip Uenlue, Sebastian Schmidt, Marcel Kollovieh, Jiajie Fan, Stephan Guennemann, Lars Mikelsons|<http://arxiv.org/pdf/2510.22337v1>|提出GeoDiffusion框架，无需训练即可高效准确地在图像生成中对3D几何特征进行条件化处理。|
|🆕 发布|GRPO-Guard: Mitigating Implicit Over-Optimization in Flow Matching via Regulated Clipping|GRPO-Guard: 通过调节裁剪缓解流匹配中的隐式过度优化|Jing Wang, Jiajun Liang, Jie Liu, Henglin Liu, Gongye Liu, Jun Zheng, Wanyuan Pang, Ao Ma .etc.|<http://arxiv.org/pdf/2510.22319v1>|提出GRPO-Guard方法，通过比例规范和梯度重加权抑制了流匹配中的隐式过优化问题，稳定了优化过程...|
|📝 更新|DIO: Refining Mutual Information and Causal Chain to Enhance Machine Abstract Reasoning Ability|DIO：优化互信息和因果链以提高机器抽象推理能力|Ruizhuo Song, Beiming Yuan|<http://arxiv.org/pdf/2508.15387v6>|提出DIO模型，通过优化互信息和因果链，增强机器的抽象推理能力。|
|🆕 发布|Enpowering Your Pansharpening Models with Generalizability: Unified Distribution is All You Need|赋予您的全色锐化模型泛化能力：统一分布，这就是您所需要的全部|Yongchuan Cui, Peng Liu, Hui Zhang|<http://arxiv.org/pdf/2510.22217v1>|[代码](https://github.com/yc-cui/UniPAN.); 提出了一种统一分布策略UniPAN，通过分布转换函数提升遥感图像 pansharpening 模型的...|
|📝 更新|VEGGIE: Instructional Editing and Reasoning Video Concepts with Grounded Generation|VEGGIE：基于实例生成和推理的视频概念指导编辑|Shoubin Yu, Difan Liu, Ziqiao Ma, Yicong Hong, Yang Zhou, Hao Tan, Joyce Chai, Mohit Bansal|<http://arxiv.org/pdf/2503.14350v3>|VEGGIE通过统一框架实现视频编辑与理解，基于指令生成编辑视频，提升多任务处理能力。|
|📝 更新|Net2Net: When Un-trained Meets Pre-trained Networks for Robust Real-World Denoising|Net2Net：当未训练网络遇见预训练网络以实现稳健的现实世界降噪|Weimin Yuan, Cai Meng|<http://arxiv.org/pdf/2510.02733v2>|Net2Net结合未训练和预训练网络，有效提升真实世界图像去噪的泛化能力和性能。|
|🆕 发布|MOGRAS: Human Motion with Grasping in 3D Scenes|MOGRAS：三维场景中抓取动作的人类运动|Kunal Bhosikar, Siddharth Katageri, Vivek Madhavaram, Kai Han, Charu Sharma|<http://arxiv.org/pdf/2510.22199v1>|提出MOGRAS数据集，解决了3D场景中生成真实全身抓握动作的挑战，并通过新方法提升了场景感知能力。|
|🆕 发布|LongCat-Video Technical Report|《LongCat-Video技术报告》|Meituan LongCat Team, Xunliang Cai, Qilong Huang, Zhuoliang Kang, Hongyu Li, Shijun Liang, Liya Ma, Siyu Ren .etc.|<http://arxiv.org/pdf/2510.22200v1>|提出了一种大型视频生成模型LongCat-Video，实现了高效且高质量的长视频生成。|
|🆕 发布|SentiMaithili: A Benchmark Dataset for Sentiment and Reason Generation for the Low-Resource Maithili Language|“SentiMaithili：一种面向低资源迈蒂利语的情感和原因生成基准数据集”|Rahul Ranjan, Mahendra Kumar Gurve, Anuj, Nitin, Yamuna Prasad|<http://arxiv.org/pdf/2510.22160v1>|创建了首个针对低资源语言Maithili的带有情感极性和解释的标注数据集，促进了多语言自然语言处理和...|
|📝 更新|SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus|脊柱基准：基于SpineMed-450k语料库的具有临床显著性、层次感知的评测标准|Ming Zhao, Wenhui Dong, Yang Zhang, Xiang Zheng, Zhonghao Zhang, Zian Zhou, Yunzhi Guan, Liukun Xu .etc.|<http://arxiv.org/pdf/2510.03160v2>|提出首个针对脊椎级别推理的大规模多模态数据集SpineMed-450k，并创建SpineBench评...|
|📝 更新|EEdit: Rethinking the Spatial and Temporal Redundancy for Efficient Image Editing|EEdit：重新思考空间和时间冗余以提高图像编辑效率|Zexuan Yan, Yue Ma, Chang Zou, Wenteng Chen, Qifeng Chen, Linfeng Zhang|<http://arxiv.org/pdf/2503.10270v3>|[代码](https://github.com/yuriYanZeXuan/EEdit); 提出EEdit框架，通过减少空间和时间冗余，有效提升图像编辑效率。|
|🆕 发布|GRAID: Enhancing Spatial Reasoning of VLMs Through High-Fidelity Data Generation|GRAID：通过高保真数据生成增强视觉语言模型的空间推理能力|Karim Elmaaroufi, Liheng Lai, Justin Svegliato, Yutong Bai, Sanjit A. Seshia, Matei Zaharia|<http://arxiv.org/pdf/2510.22118v1>|[代码](https://ke7.github.io/graid); 提出GRAID方法，通过2D几何元素提高视觉语言模型空间推理能力，生成高质量数据集。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|T2SMark: Balancing Robustness and Diversity in Noise-as-Watermark for Diffusion Models|T2SMark：在噪声作为水印的扩散模型中平衡鲁棒性与多样性|Jindong Yang, Han Fang, Weiming Zhang, Nenghai Yu, Kejiang Chen|<http://arxiv.org/pdf/2510.22366v1>|[代码](https://github.com/0xD009/T2SMark); 提出了一种两阶段水印方案T2SMark，通过尾截断采样增强鲁棒性并保持生成多样性。|
|📝 更新|Kernel Density Steering: Inference-Time Scaling via Mode Seeking for Image Restoration|核密度引导：通过模式搜索实现图像复原中的推理时间缩放|Yuyang Hu, Kangfu Mei, Mojtaba Sahraee-Ardakan, Ulugbek S. Kamilov, Peyman Milanfar, Mauricio Delbracio|<http://arxiv.org/pdf/2507.05604v2>|提出Kernel Density Steering方法，通过集体模式搜索提升图像修复质量，减少伪影。|
|🆕 发布|Moving Beyond Diffusion: Hierarchy-to-Hierarchy Autoregression for fMRI-to-Image Reconstruction|超越扩散：从层次到层次的自动回归用于fMRI到图像的重构|Xu Zhang, Ruijie Quan, Wenguan Wang, Yi Yang|<http://arxiv.org/pdf/2510.22335v1>|提出了一种基于层次自回归的fMRI到图像重建框架，通过多级神经编码和层间对应，实现了更高效的图像重构...|
|🆕 发布|T2I-RiskyPrompt: A Benchmark for Safety Evaluation, Attack, and Defense on Text-to-Image Model|文本到图像模型安全性评估、攻击与防御基准：T2I-RiskyPrompt|Chenyu Zhang, Tairen Zhang, Lanjun Wang, Ruidong Chen, Wenhui Li, Anan Liu|<http://arxiv.org/pdf/2510.22300v1>|[代码](https://github.com/datar001/T2I-RiskyPrompt.); 提出了T2I-RiskyPrompt，一个全面的基准，通过构建细致的风险分类体系，提升了文本到图像模...|
|📝 更新|Continuous and complete liver vessel segmentation with graph-attention guided diffusion|图注意力引导扩散的连续与完整肝脏血管分割|Xiaotong Zhang, Alexander Broersen, Gonnie CM van Erp, Silvia L. Pintea, Jouke Dijkstra|<http://arxiv.org/pdf/2411.00617v3>|[代码](https://github.com/ZhangXiaotong015/GATSegDiff.); 提出了一种基于图注意力引导的扩散模型，有效提升了肝脏血管分割的连续性和完整性。|
|🆕 发布|DiffusionLane: Diffusion Model for Lane Detection|扩散车道线：用于车道检测的扩散模型|Kunyang Zhou, Yeqin Shao|<http://arxiv.org/pdf/2510.22236v1>|[代码](https://github.com/zkyntu/UnLanedet.); 提出了一种基于扩散模型的道路检测方法DiffusionLane，通过逐步去噪提高检测准确性和泛化能力...|
|🆕 发布|Diffusion-Driven Two-Stage Active Learning for Low-Budget Semantic Segmentation|基于扩散驱动的两阶段主动学习用于低成本语义分割|Jeongin Kim, Wonho Bae, YouLee Han, Giyeong Oh, Youngjae Yu, Danica J. Sutherland, Junhyug Noh|<http://arxiv.org/pdf/2510.22229v1>|[代码](https://github.com/jn-kim/two-stage-edald.); 提出了一种两阶段主动学习方法，通过预训练的扩散模型和熵增强的不确定性评分，在极低标注预算下实现高效语...|
|📝 更新|PlantSegNeRF: A few-shot, cross-species method for plant 3D instance point cloud reconstruction via joint-channel NeRF with multi-view image instance matching|植物SegNeRF：一种基于联合通道NeRF与多视角图像实例匹配的少样本、跨物种植物三维实例点云重建方法|Xin Yang, Ruiming Du, Hanyang Huang, Jiayang Xie, Pengyao Xie, Leisen Fang, Ziyue Guo, Nanjun Jiang .etc.|<http://arxiv.org/pdf/2507.00371v3>|提出了一种PlantSegNeRF方法，通过多视角图像匹配和神经辐射场，实现了植物器官的高精度3D点...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GOPLA: Generalizable Object Placement Learning via Synthetic Augmentation of Human Arrangement|GOPLA：通过合成增强人类排列的泛化对象放置学习|Yao Zhong, Hanzhi Chen, Simon Schaefer, Anran Zhang, Stefan Leutenegger|<http://arxiv.org/pdf/2510.14627v2>|提出了一种通过合成增强人类演示学习通用物体放置的方法，大幅提高了机器人放置成功率。|
|📝 更新|MEXA: Towards General Multimodal Reasoning with Dynamic Multi-Expert Aggregation|MEXA：迈向动态多专家聚合的通用多模态推理|Shoubin Yu, Yue Zhang, Ziyang Wang, Jaehong Yoon, Mohit Bansal|<http://arxiv.org/pdf/2506.17113v2>|提出了一种无需训练的MEXA框架，通过动态多专家聚合实现跨领域的有效多模态推理。|
|📝 更新|Macro2Micro: A Rapid and Precise Cross-modal Magnetic Resonance Imaging Synthesis using Multi-scale Structural Brain Similarity|宏观至微观：利用多尺度脑结构相似性实现快速精确的跨模态磁共振成像合成|Sooyoung Kim, Joonwoo Kwon, Junbeom Kwon, Jungyoun Janice Min, Sangyoon Bae, Yuewei Lin, Shinjae Yoo, Jiook Cha|<http://arxiv.org/pdf/2412.11277v2>|提出了一种基于生成对抗网络的跨模态MRI合成方法，实现了从宏观脑结构到微观结构的快速精准预测。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Dynamic-Aware Spatio-temporal Representation Learning for Dynamic MRI Reconstruction|动态感知的时空表征学习用于动态MRI重建|Dayoung Baik, Jaejun Yoo|<http://arxiv.org/pdf/2501.09049v2>|提出了一种动态感知的隐式神经表示模型，有效提升了动态MRI重建质量并减少了优化时间与参数调整需求。|
|🆕 发布|I2-NeRF: Learning Neural Radiance Fields Under Physically-Grounded Media Interactions|I2-NeRF：在物理基础介质交互下学习神经辐射场|Shuhong Liu, Lin Gu, Ziteng Cui, Xuangeng Chu, Tatsuya Harada|<http://arxiv.org/pdf/2510.22161v1>|提出I2-NeRF框架，通过逆向分层上采样和统一辐射公式，在复杂介质中实现均匀的三维空间感知和物理一...|


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GSAlign: Geometric and Semantic Alignment Network for Aerial-Ground Person Re-Identification|GSAlign：面向天地人重识别的几何与语义对齐网络|Qiao Li, Jie Li, Yukang Zhang, Lei Tan, Jing Chen, Jiayi Ji|<http://arxiv.org/pdf/2510.22268v1>|[代码](https://github.com/stone96123/GSAlign); 提出GSAlign网络，通过几何和语义对齐解决空地行人重识别中的视角差异和遮挡问题。|
|🆕 发布|STG-Avatar: Animatable Human Avatars via Spacetime Gaussian|时空高斯方法实现的可动画化人类虚拟形象：STG-Avatar|Guangan Jiang, Tianzi Zhang, Dong Li, Zhenjun Zhao, Haoang Li, Mingrui Li, Hongyu Wang|<http://arxiv.org/pdf/2510.22140v1>|[代码](https://github.com/jiangguangan/STG-Avatar); STG-Avatar通过结合线性混合蒙皮与时空高斯优化，实现了高质量动态人类角色的实时重建。|


## 时序视觉分析 (Temporal Visual Analysis)


### 时序建模与预测 (Temporal Modeling & Prediction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Accident Anticipation via Temporal Occurrence Prediction|通过时间发生预测的事故预判|Tianhao Zhao, Yiyang Zou, Zihao Mao, Peilun Xiao, Yulin Huang, Hongda Yang, Yuxuan Li, Qun Li .etc.|<http://arxiv.org/pdf/2510.22260v1>|提出了一种通过预测未来时间点的事故分数来预判交通事故的新方法，提高了预警准确性和实时性。|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Audio Does Matter: Importance-Aware Multi-Granularity Fusion for Video Moment Retrieval|音频确实重要：基于重要性感知的多粒度融合视频瞬间检索|Junan Lin, Daizong Liu, Xianke Chen, Xiaoye Qu, Xun Yang, Jixiang Zhu, Sanyuan Zhang, Jianfeng Dong|<http://arxiv.org/pdf/2508.04273v3>|[代码](https://github.com/HuiGuanLab/IMG.); 提出了一种重要性感知的多粒度融合模型，有效利用音频信息提升视频瞬间检索性能。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|egoEMOTION: Egocentric Vision and Physiological Signals for Emotion and Personality Recognition in Real-World Tasks|自我情感识别：基于第一视角视觉与生理信号在现实世界任务中的情感与人格识别|Matthias Jammot, Bjöern Braun, Paul Streli, Rafael Wampfler, Christian Holz|<http://arxiv.org/pdf/2510.22129v1>|首次结合 egocentric 视觉与生理信号，为情感与个性识别创建新数据集并定义基准任务。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Robust Multimodal Learning via Cross-Modal Proxy Tokens|通过跨模态代理标记实现的鲁棒多模态学习|Md Kaykobad Reza, Ameya Patil, Mashhour Solh, M. Salman Asif|<http://arxiv.org/pdf/2501.17823v4>|[代码](https://github.com/CSIPlab/Cross-Modal-Proxy-Tokens.); 提出了一种增强多模态学习鲁棒性的方法，通过引入跨模态代理标记来应对缺失模态的挑战。|
|🆕 发布|LOC: A General Language-Guided Framework for Open-Set 3D Occupancy Prediction|LOC：一种用于开放集三维占据预测的通用语言引导框架|Yuhang Gao, Xiang Xiang, Sheng Zhong, Guoyou Wang|<http://arxiv.org/pdf/2510.22141v1>|提出了一种语言引导的框架LOC，通过融合多帧LiDAR点和对比学习，实现了无需额外训练数据的开放集三...|
|🆕 发布|Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation|基于对比度的无源域自适应注意力残差融合网络|Renrong Shao, Wei Zhang, Jun Wang|<http://arxiv.org/pdf/2510.22142v1>|提出了一种基于对比学习的注意力残差融合网络，有效缓解了无源域适应中的负迁移和域偏移问题。|


### 跨模态一致性学习 (Cross-modal Consistency Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VisJudge-Bench: Aesthetics and Quality Assessment of Visualizations|VisJudge-Bench：可视化美学与质量评估基准|Yupeng Xie, Zhiyang Zhang, Yifan Wu, Sirong Lu, Jiayi Zhang, Zhaoyang Yu, Jinlin Wang, Sirui Hong .etc.|<http://arxiv.org/pdf/2510.22373v1>|[代码](https://github.com/HKUSTDial/VisJudgeBench.); 提出VisJudge-Bench基准和VisJudge模型，用于评估大型语言模型对可视化美学和质量评...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Privacy-Aware Federated nnU-Net for ECG Page Digitization|隐私感知的联邦nnU-Net用于ECG页面数字化|Nader Nemati|<http://arxiv.org/pdf/2510.22387v1>|提出了一种隐私保护的联邦学习框架，实现了ECG图像的端到端数字化而不共享原始图像，保障了跨机构隐私。|
|📝 更新|ZigzagPointMamba: Spatial-Semantic Mamba for Point Cloud Understanding|“之字形点魔霸：用于点云理解的空间语义魔霸”|Linshuang Diao, Sensen Song, Yurong Qian, Dayong Ren|<http://arxiv.org/pdf/2505.21381v6>|提出ZigzagPointMamba方法，通过优化点云序列和引入语义相似掩码，增强点云理解和下游任务...|
|📝 更新|REP: Resource-Efficient Prompting for Rehearsal-Free Continual Learning|REP：无需复习的持续学习中的资源高效提示|Sungho Jeon, Xinyue Ma, Kwang In Kim, Myeongjae Jeon|<http://arxiv.org/pdf/2406.04772v4>|提出资源高效提示方法，优化无复习连续学习资源消耗，同时保持准确率。|
|🆕 发布|Audio Frequency-Time Dual Domain Evaluation on Depression Diagnosis|抑郁症诊断中的音频频率-时间双域评估|Yu Luo, Nan Huang, Sophie Yu, Hendry Xu, Jerry Wang, Colin Wang, Zhichao Liu, Chen Zeng|<http://arxiv.org/pdf/2510.22225v1>|利用声音频率-时间双域特征及深度学习模型，开发出高效抑郁症诊断算法。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Dynamic Dropout: Leveraging Conway's Game of Life for Neural Networks Regularization|动态丢弃：利用康威生命游戏进行神经网络正则化|David Freire-Obregón, José Salas-Cáceres, Modesto Castrillón-Santana|<http://arxiv.org/pdf/2510.22383v1>|将神经网络中的传统dropout替换为基于Conway's Game of Life的动态单元失活策...|
|🆕 发布|Scaling Non-Parametric Sampling with Representation|《扩展表示下的非参数采样缩放》|Vincent Lu, Aaron Truong, Zeyu Yun, Yubei Chen|<http://arxiv.org/pdf/2510.22196v1>|提出了一种简化的非参数生成模型，利用图像的局部上下文生成高质量样本，揭示了自然图像结构的基本理论。|
|📝 更新|Dual-Flow: Transferable Multi-Target, Instance-Agnostic Attacks via In-the-wild Cascading Flow Optimization|双流：通过野外级联流优化实现的迁移性多目标、实例无关攻击|Yixiao Chen, Shikun Sun, Jianshu Li, Ruoyu Li, Zhe Li, Junliang Xing|<http://arxiv.org/pdf/2502.02096v3>|[代码](https://github.com/Chyxx/Dual-Flow); 提出了一种Dual-Flow框架，通过级联分布偏移训练提高多目标攻击的迁移性和成功率。|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DynaSolidGeo: A Dynamic Benchmark for Genuine Spatial Mathematical Reasoning of VLMs in Solid Geometry|动态实体几何：面向实体几何中大型视觉语言模型真实空间数学推理的动态基准|Changti Wu, Shijie Lian, Zihao Liu, Lei Zhang, Laurence Tianruo Yang, Kai Chen|<http://arxiv.org/pdf/2510.22340v1>|[代码](https://zgca-ai4edu.github.io/DynaSolidGeo); 提出了DynaSolidGeo，首个动态基准用于评估视觉语言模型在立体几何中的真实空间推理能力。|
|🆕 发布|DynamicTree: Interactive Real Tree Animation via Sparse Voxel Spectrum|动态树：通过稀疏体素频谱实现的交互式真实树木动画|Yaokun Li, Lihe Ding, Xiao Chen, Guang Tan, Tianfan Xue|<http://arxiv.org/pdf/2510.22213v1>|提出了一种基于稀疏体素谱的交互式三维树木动画生成框架，实现了高质量且实时的树木动态效果。|
|📝 更新|Holistic Order Prediction in Natural Scenes|自然场景中的整体顺序预测|Pierre Musacchio, Hyunmin Lee, Jaesik Park|<http://arxiv.org/pdf/2510.01704v2>|[代码](https://github.com/SNU-VGILab/InstaOrder.); 提出InstaFormer网络，通过单次前向传播直接预测自然场景中所有实例的完整遮挡和深度顺序。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|TraceTrans: Translation and Spatial Tracing for Surgical Prediction|《TraceTrans：手术预测的翻译与空间追踪》|Xiyu Luo, Haodong LI, Xinxing Cheng, He Zhao, Yang Hu, Xuan Song, Tianyang Zhang|<http://arxiv.org/pdf/2510.22379v1>|提出了一种用于术后预测的图像翻译模型TraceTrans，通过保持源图像与翻译图像间的空间对应关系，...|
|🆕 发布|Mint: A Simple Test-Time Adaptation of Vision-Language Models against Common Corruptions|“Mint：一种针对常见噪声的简单测试时视觉语言模型适应方法”|Wenxuan Bao, Ruxi Deng, Jingrui He|<http://arxiv.org/pdf/2510.22127v1>|[代码](https://github.com/baowenxuan/Mint); 提出了一种测试时适应方法Mint，通过最大化伪标签间的方差来增强视觉语言模型对常见图像扰动的鲁棒性。|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1|一种令人沮丧的简单却高度有效的攻击基线：针对 GPT-4.5/4o/o1 强黑盒模型超过 90% 的成功率|Zhaoyi Li, Xiaohan Zhao, Dong-Dong Wu, Jiacheng Cui, Zhiqiang Shen|<http://arxiv.org/pdf/2503.10635v2>|提出了一种针对商业闭源视觉语言模型的攻击方法，通过在关键区域聚集语义细节，实现了超过90%的攻击成功...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SemiETPicker: Fast and Label-Efficient Particle Picking for CryoET Tomography Using Semi-Supervised Learning|半监督学习的快速且标注高效的冷冻电子断层扫描粒子挑选方法：SemiETPicker|Linhan Wang, Jianwen Dou, Wang Li, Shengkun Wang, Zhiwu Xie, Chang-Tien Lu, Yinlin Chen|<http://arxiv.org/pdf/2510.22454v1>|提出了一种高效的半监督学习框架，通过利用未标记数据，快速准确地进行冷冻电子断层扫描中的粒子挑选任务。|
|🆕 发布|Beyond Augmentation: Leveraging Inter-Instance Relation in Self-Supervised Representation Learning|超越数据增强：在自监督表征学习中利用实例间关系|Ali Javidani, Babak Nadjar Araabi, Mohammad Amin Sadeghi|<http://arxiv.org/pdf/2510.22322v1>|[代码](https://github.com/alijavidani/SSL-GraphNNCLR.); 引入图论到自监督学习，通过构建KNN图捕捉样本间关系，提升表示学习准确性。|
|🆕 发布|CityRiSE: Reasoning Urban Socio-Economic Status in Vision-Language Models via Reinforcement Learning|城市崛起：通过强化学习在视觉-语言模型中推理城市社会经济状况|Tianhui Liu, Hetian Pang, Xin Zhang, Jie Feng, Yong Li, Pan Hui|<http://arxiv.org/pdf/2510.22282v1>|提出了CityRiSE框架，通过强化学习提升大型视觉语言模型对城市社会经济状态的预测准确性和泛化能力...|
|🆕 发布|Power to the Clients: Federated Learning in a Dictatorship Setting|客户端的力量：独裁制度下的联邦学习|Mohammadsajad Alipour, Mohammad Mohammadi Amiri|<http://arxiv.org/pdf/2510.22149v1>|提出恶意客户端模型，分析了其在联邦学习中对全局模型收敛性的影响，并给出具体攻击策略。|


### 零/少样本泛化 (Zero/Few-shot Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|CogStereo: Neural Stereo Matching with Implicit Spatial Cognition Embedding|《CogStereo：具有隐式空间认知嵌入的神经立体匹配》|Lihuang Fang, Xiao Hu, Yuchen Zou, Hong Zhang|<http://arxiv.org/pdf/2510.22119v1>|提出CogStereo框架，通过融入隐式空间认知嵌入，实现立体匹配在复杂区域和跨领域泛化上的突破。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LT-Exosense: A Vision-centric Multi-session Mapping System for Lifelong Safe Navigation of Exoskeletons|LT-Exosense：一种以视觉为中心的多会话映射系统，用于外骨骼终身安全导航|Jianeng Wang, Matias Mattamala, Christina Kassab, Nived Chebrolu, Guillaume Burger, Fabio Elnecave, Marine Petriaux, Maurice Fallon|<http://arxiv.org/pdf/2510.22164v1>|提出了一种视觉中心的长期多会话映射系统，支持智能路径规划以适应动态环境，实现精准导航。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Think or Not Think: A Study of Explicit Thinking in Rule-Based Visual Reinforcement Fine-Tuning|“思考或非思考：基于规则视觉强化微调中显式思维的研究”|Ming Li, Jike Zhong, Shitian Zhao, Yuxiang Lai, Haoquan Zhang, Wang Bill Zhu, Kaipeng Zhang|<http://arxiv.org/pdf/2503.16188v6>|探究显式思维在规则基础强化微调中的作用，提出无需思维的强化学习策略，提升模型性能。|
|🆕 发布|Mitigating Coordinate Prediction Bias from Positional Encoding Failures|减轻位置编码失败导致的坐标预测偏差|Xingjian Tao, Yiwei Wang, Yujun Cai, Yihong Luo, Jing Tang|<http://arxiv.org/pdf/2510.22102v1>|提出了一种纠正多模态大语言模型坐标预测偏差的方法，通过测试时 Vision-PE Shuffle G...|


### 跨模态检索与匹配 (Cross-modal Retrieval & Matching)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Retrv-R1: A Reasoning-Driven MLLM Framework for Universal and Efficient Multimodal Retrieval|Retrv-R1：一种面向通用高效多模态检索的推理驱动的多模态语言模型框架|Lanyun Zhu, Deyi Ji, Tianrun Chen, Haiyang Wu, Shiqi Wang|<http://arxiv.org/pdf/2510.02745v2>|提出Retrv-R1框架，通过推理增强的多模态检索，提升了性能和效率。|
|🆕 发布|Hybrid-Vector Retrieval for Visually Rich Documents: Combining Single-Vector Efficiency and Multi-Vector Accuracy|《视觉丰富文档的混合向量检索：结合单向量效率与多向量准确性》|Juyeon Kim, Geon Lee, Dongwon Choi, Taeuk Kim, Kijung Shin|<http://arxiv.org/pdf/2510.22215v1>|[代码](https://github.com/juyeonnn/HEAVEN); 提出了一种结合单向量效率和多向量准确性的两阶段混合向量检索框架HEAVEN，大幅提升视觉丰富文档检索...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Efficient Large-Deformation Medical Image Registration via Recurrent Dynamic Correlation|通过循环动态相关性实现高效大变形医学图像配准|Tianran Li, Marius Staring, Yuchuan Qiao|<http://arxiv.org/pdf/2510.22380v1>|提出了一种动态相关性的循环框架，通过逐步调整匹配区域实现高效的大形变医学图像配准。|
|📝 更新|Zero-Shot Multi-modal Large Language Model v.s. Supervised Deep Learning: A Comparative Study on CT-Based Intracranial Hemorrhage Subtyping|零样本多模态大型语言模型与监督深度学习对比研究：基于CT的颅内出血亚型分类|Yinuo Wang, Yue Zeng, Kai Chen, Cai Meng, Chao Pan, Zhouping Tang|<http://arxiv.org/pdf/2505.09252v2>|比较零样本多模态大语言模型与传统深度学习在脑出血亚型分类中的表现，发现后者准确性更高。|
|🆕 发布|Discovering Latent Graphs with GFlowNets for Diverse Conditional Image Generation|使用GFlowNets发现潜在图以实现多样化的条件图像生成|Bailey Trang, Parham Saremi, Alan Q. Wang, Fangrui Huang, Zahra TehraniNasab, Amar Kumar, Tal Arbel, Li Fei-Fei .etc.|<http://arxiv.org/pdf/2510.22107v1>|提出Rainbow框架，通过分解条件输入为多样潜在表示，利用GFlowNets生成多样条件图像。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|3D Roadway Scene Object Detection with LIDARs in Snowfall Conditions|雪天条件下基于LIDAR的3D道路场景目标检测|Ghazal Farhani, Taufiq Rahman, Syed Mostaquim Ali, Andrew Liu, Mohamed Zaki, Dominique Charlebois, Benoit Anctil|<http://arxiv.org/pdf/2510.22436v1>|提出了一种物理模型，通过模拟不同雪fall率的LiDAR信号衰减，提高了自动驾驶系统在雪天条件下的物...|
|📝 更新|Raw2Drive: Reinforcement Learning with Aligned World Models for End-to-End Autonomous Driving (in CARLA v2)|《Raw2Drive：面向端到端自动驾驶的强化学习与对齐世界模型》（在CARLA v2中）|Zhenjie Yang, Xiaosong Jia, Qifeng Li, Xue Yang, Maoqing Yao, Junchi Yan|<http://arxiv.org/pdf/2505.16394v2>|提出双流模型Raw2Drive，通过强化学习与对齐的世界模型，直接处理原始传感器数据，实现端到端自动...|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|CapRecover: A Cross-Modality Feature Inversion Attack Framework on Vision Language Models|CapRecover：一种面向视觉语言模型的跨模态特征逆向攻击框架|Kedong Xiu, Sai Qian Zhang|<http://arxiv.org/pdf/2507.22828v3>|[代码](https://jus1mple.github.io/Image2CaptionAttack.); 提出CapRecover框架，直接从视觉模型中间特征恢复高级语义内容，无需图像重建。|


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RoboRefer: Towards Spatial Referring with Reasoning in Vision-Language Models for Robotics|“RoboRefer：面向机器人视觉语言模型中的推理式空间指引用法”|Enshen Zhou, Jingkun An, Cheng Chi, Yi Han, Shanyu Rong, Chi Zhang, Pengwei Wang, Zhongyuan Wang .etc.|<http://arxiv.org/pdf/2506.04308v3>|[代码](https://zhoues.github.io/RoboRefer.); 提出RoboRefer模型，通过深度编码器和强化学习实现机器人对复杂三维场景的精确空间理解和多步骤推...|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Fully Interpretable Statistical Approach for Roadside LiDAR Background Subtraction|一种完全可解释的统计方法用于路边激光雷达背景减除|Aitor Iglesias, Nerea Aranjuelo, Patricia Javierre, Ainhoa Menendez, Ignacio Arganda-Carreras, Marcos Nieto|<http://arxiv.org/pdf/2510.22390v1>|提出了一种可解释性强、适应广泛的统计方法，通过高斯分布网格模型和滤波算法，有效区分路边LiDAR数据...|
|🆕 发布|GALA: A GlobAl-LocAl Approach for Multi-Source Active Domain Adaptation|“GALA：一种面向多源主动域自适应的全局-局部方法”|Juepeng Zheng, Peifeng Zhang, Yibin Wen, Qingmei Li, Yang Zhang, Haohuan Fu|<http://arxiv.org/pdf/2510.22214v1>|提出了一种全局-局部选择策略GALA，通过主动获取目标域标注，有效提升了多源域自适应的性能。|
|🆕 发布|WAON: Large-Scale and High-Quality Japanese Image-Text Pair Dataset for Vision-Language Models|WAON：用于视觉语言模型的大规模高质量日文图像-文本对数据集|Issa Sugiura, Shuhei Kurita, Yusuke Oda, Daisuke Kawahara, Yasuo Okabe, Naoaki Okazaki|<http://arxiv.org/pdf/2510.22276v1>|[代码](https://speed1313.github.io/WAON.); 构建了大规模高质量的日文图像文本对数据集WAON，提升了视觉语言模型的性能。|

