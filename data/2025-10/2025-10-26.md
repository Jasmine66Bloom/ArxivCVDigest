## [UPDATED!] **2025-10-26** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FastJAM: a Fast Joint Alignment Model for Images|快速联合对齐模型FastJAM：面向图像的|Omri Hirsch, Ron Shapira Weber, Shira Ifergane, Oren Freifeld|<http://arxiv.org/pdf/2510.22842v1>|[代码](https://bgu-cs-vil.github.io/FastJAM); 提出了FastJAM方法，通过图神经网络高效预测图像对齐参数，大幅缩短了图像联合对齐的计算时间。|
|📝 更新|PARTONOMY: Large Multimodal Models with Part-Level Visual Understanding|部分本体论：具有部分级别视觉理解的大型多模态模型|Ansel Blume, Jeonghwan Kim, Hyeonjeong Ha, Elen Chatikyan, Xiaomeng Jin, Khanh Duy Nguyen, Nanyun Peng, Kai-Wei Chang .etc.|<http://arxiv.org/pdf/2505.20759v3>|提出PARTONOMY基准，挑战大型多模态模型对物体部件的识别，并引入PLUM模型以提升视觉理解能力...|
|📝 更新|Navigating the Accuracy-Size Trade-Off with Flexible Model Merging|在准确性与模型大小权衡中实现灵活模型合并导航|Akash Dhasade, Divyansh Jhunjhunwala, Milos Vujasinovic, Gauri Joshi, Anne-Marie Kermarrec|<http://arxiv.org/pdf/2505.23209v2>|提出FlexMerge框架，灵活生成不同大小的合并模型，优化了模型准确性与存储成本之间的权衡。|
|🆕 发布|SARCLIP: A Vision Language Foundation Model for Semantic Understanding and Target Recognition in SAR Imagery|SARCLIP：一种用于合成孔径雷达图像中的语义理解和目标识别的视觉语言基础模型|Qiwei Ma, Zhiyu Wang, Wang Liu, Xukun Lu, Bin Deng, Puhong Duan, Xudong Kang, Shutao Li|<http://arxiv.org/pdf/2510.22665v1>|提出首个面向合成孔径雷达领域的视觉语言基础模型SARCLIP，通过大规模数据集和对比学习提升SAR影...|
|📝 更新|DynamicVL: Benchmarking Multimodal Large Language Models for Dynamic City Understanding|动态VL：针对动态城市理解的跨模态大型语言模型基准测试|Weihao Xuan, Junjue Wang, Heli Qi, Zihang Chen, Zhuo Zheng, Yanfei Zhong, Junshi Xia, Naoto Yokoya|<http://arxiv.org/pdf/2505.21076v2>|提出DVL-Suite框架，通过多模态大语言模型分析长期城市动态，提升模型在多时相遥感图像理解上的能...|
|📝 更新|ChemVLM: Exploring the Power of Multimodal Large Language Models in Chemistry Area|ChemVLM：探索多模态大型语言模型在化学领域的力量|Junxian Li, Di Zhang, Xunzhi Wang, Zeying Hao, Jingdi Lei, Qian Tan, Cai Zhou, Wei Liu .etc.|<http://arxiv.org/pdf/2408.07246v6>|提出ChemVLM模型，融合文本与视觉信息处理化学任务，提升多模态理解能力。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Unsupervised Document and Template Clustering using Multimodal Embeddings|无监督文档与模板聚类：基于多模态嵌入的方法|Phillipe R. Sampaio, Helene Maxcici|<http://arxiv.org/pdf/2506.12116v3>|提出了一种无监督文档和模板聚类方法，通过多模态嵌入和经典聚类算法实现文档分类。|
|📝 更新|Principled Multimodal Representation Learning|原则性多模态表征学习|Xiaohao Liu, Xiaobo Xia, See-Kiong Ng, Tat-Seng Chua|<http://arxiv.org/pdf/2507.17343v2>|提出了一种无需依赖锚点的稳定多模态表征学习框架，通过优化主导奇异值实现各模态间的统一对齐。|
|🆕 发布|Look and Tell: A Dataset for Multimodal Grounding Across Egocentric and Exocentric Views|“查看并讲述：一个用于自我中心与外部中心视角多模态定位的数据集”|Anna Deichler, Jonas Beskow|<http://arxiv.org/pdf/2510.22672v1>|介绍了Look and Tell多模态数据集，用于研究第一人称和第三人称视角下的参照性沟通。|
|🆕 发布|DeepfakeBench-MM: A Comprehensive Benchmark for Multimodal Deepfake Detection|深度伪造检测多模态全面基准：DeepfakeBench-MM|Kangran Zhao, Yupeng Chen, Xiaoyu Zhang, Yize Chen, Weinan Guan, Baicheng Chen, Chengzhe Sun, Soumyya Kanti Datta .etc.|<http://arxiv.org/pdf/2510.22622v1>|构建大规模多模态伪造数据集Mega-MMDF，并创建首个统一的多模态伪造检测基准DeepfakeBe...|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Alias-Free ViT: Fractional Shift Invariance via Linear Attention|无混叠 ViT：通过线性注意力实现的分数平移不变性|Hagay Michaeli, Daniel Soudry|<http://arxiv.org/pdf/2510.22673v1>|提出了一种Alias-Free ViT模型，通过使用无混叠采样和线性注意力机制，增强了视觉变换器对图...|
|🆕 发布|PSScreen V2: Partially Supervised Multiple Retinal Disease Screening|PSScreen V2：部分监督多视网膜疾病筛查|Boyi Zheng, Yalin Zheng, Hrvoje Bogunović, Qing Liu|<http://arxiv.org/pdf/2510.22589v1>|[代码](https://github.com/boyiZheng99/PSScreen_V2.); 提出了PSScreen V2框架，通过部分监督学习和跨域特征增强，有效解决了视网膜疾病筛查中的标签缺...|
|📝 更新|Visual Thoughts: A Unified Perspective of Understanding Multimodal Chain-of-Thought|《视觉思维：理解多模态思维链的统一视角》|Zihui Cheng, Qiguang Chen, Xiao Xu, Jiaqi Wang, Weiyun Wang, Hao Fei, Yidong Wang, Alex Jinpeng Wang .etc.|<http://arxiv.org/pdf/2505.15510v2>|揭示了视觉思维在提升大型视觉语言模型多模态任务性能和解释性的作用，并定义了四种视觉思维表达形式。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Critical Study on Tea Leaf Disease Detection using Deep Learning Techniques|深度学习技术在茶叶病害检测中的关键研究|Nabajyoti Borah, Raju Moni Borah, Bandan Boruah, Purnendu Bikash Acharjee, Sajal Saha, Ripjyoti Hazarika|<http://arxiv.org/pdf/2510.22647v1>|提出了一种基于深度学习的茶叶病害检测方法，有效识别三种病害并计算受损面积。|
|🆕 发布|Cross-Species Transfer Learning in Agricultural AI: Evaluating ZebraPose Adaptation for Dairy Cattle Pose Estimation|农业人工智能中的跨物种迁移学习：评估ZebraPose适应于奶牛姿态估计的效果|Mackenzie Tapp, Sibi Chakravarthy Parivendan, Kashfia Sailunaz, Suresh Neethirajan|<http://arxiv.org/pdf/2510.22618v1>|评估了将针对斑马训练的ZebraPose模型应用于奶牛姿态估计的跨物种迁移学习效果与局限性。|


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|STATUS Bench: A Rigorous Benchmark for Evaluating Object State Understanding in Vision-Language Models|状态评估基准：一种用于评估视觉语言模型中对象状态理解的严格基准|Mahiro Ukai, Shuhei Kurita, Nakamasa Inoue|<http://arxiv.org/pdf/2510.22571v1>|提出STATUS Bench，首个严格评估视觉语言模型理解物体状态细微变化的基准，并引入大规模训练数...|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LLM-based Fusion of Multi-modal Features for Commercial Memorability Prediction|基于大型语言模型的 多模态特征融合用于商业记忆性预测|Aleksandar Pramov|<http://arxiv.org/pdf/2510.22829v1>|[代码](https://github.com/dsgt-arc/mediaeval-2025-memorability); 提出了一种基于大型语言模型的多模态特征融合方法，有效预测商业广告的记忆度并提升模型泛化能力。|
|📝 更新|Diffusion Beats Autoregressive in Data-Constrained Settings|在数据约束设置中，扩散模型优于自回归模型|Mihir Prabhudesai, Mengning Wu, Amir Zadeh, Katerina Fragkiadaki, Deepak Pathak|<http://arxiv.org/pdf/2507.15857v7>|在数据有限的情况下，扩散模型比自回归模型表现更佳，有效利用重复数据降低验证损失。|
|🆕 发布|Semantic Surgery: Zero-Shot Concept Erasure in Diffusion Models|语义手术：扩散模型中的零样本概念擦除|Lexiang Xiong, Chengyu Liu, Jingwen Ye, Yan Liu, Yuecong Xu|<http://arxiv.org/pdf/2510.22851v1>|提出了一种无需训练的零样本概念擦除框架，通过在文本嵌入前操作，有效提高了图像生成质量和擦除效果。|
|📝 更新|Efficient Semi-Supervised Adversarial Training via Latent Clustering-Based Data Reduction|通过基于潜在聚类数据减少的高效半监督对抗训练|Somrita Ghosh, Yuelin Xu, Xiao Zhang|<http://arxiv.org/pdf/2501.10466v2>|提出了一种基于潜在聚类的高效半监督对抗训练数据缩减策略，大幅降低了训练数据需求和计算成本。|
|📝 更新|Are Pixel-Wise Metrics Reliable for Sparse-View Computed Tomography Reconstruction?|像素级指标对于稀疏视角计算机断层扫描重建是否可靠？|Tianyu Lin, Xinran Li, Chuntung Zhuang, Qi Chen, Yuanhao Cai, Kai Ding, Alan L. Yuille, Zongwei Zhou|<http://arxiv.org/pdf/2506.02093v2>|提出新指标评估稀疏视角CT重建，引入CARE框架增强关键结构完整性。|
|🆕 发布|Cross-view Localization and Synthesis - Datasets, Challenges and Opportunities|跨视图定位与合成 - 数据集、挑战与机遇|Ningli Xu, Rongjun Qin|<http://arxiv.org/pdf/2510.22736v1>|[代码](https://github.com/GDAOSU/Awesome-Cross-View-Methods.); 系统梳理了跨视角定位与合成技术的发展，分析了挑战与机遇，展望了未来研究方向。|
|🆕 发布|VADTree: Explainable Training-Free Video Anomaly Detection via Hierarchical Granularity-Aware Tree|VADTree：通过分层粒度感知树实现的无需训练的可解释视频异常检测|Wenlong Li, Yifei Xu, Yuan Rao, Zhenhua Wang, Shuiguang Deng|<http://arxiv.org/pdf/2510.22693v1>|[代码](https://github.com/wenlongli10/VADTree.); 提出了一种无需训练的层级粒度感知树结构VADTree，通过灵活采样有效捕捉视频异常，实现了训练-fr...|
|🆕 发布|Self-Attention Decomposition For Training Free Diffusion Editing|自注意力分解用于训练自由扩散编辑|Tharun Anand, Mohammad Hassan Vali, Arno Solin|<http://arxiv.org/pdf/2510.22650v1>|提出了一种无需额外数据或训练的解析方法，通过自注意力矩阵直接获取扩散模型中的语义编辑方向，大幅提升编...|
|🆕 发布|Projection Embedded Diffusion Bridge for CT Reconstruction from Incomplete Data|从Incomplete Data到CT重建的投影内嵌扩散桥|Yuang Wang, Pengfei Jin, Siyeop Yoon, Matthew Tivnan, Shaoyang Zhang, Li Zhang, Quanzheng Li, Zhiqiang Chen .etc.|<http://arxiv.org/pdf/2510.22605v1>|提出了一种将投影数据嵌入到扩散桥模型中的方法，有效提高了从Incomplete Data重建CT图像...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MagicMotion: Controllable Video Generation with Dense-to-Sparse Trajectory Guidance|《MagicMotion：基于稠密到稀疏轨迹引导的可控视频生成》|Quanhao Li, Zhen Xing, Rui Wang, Hui Zhang, Qi Dai, Zuxuan Wu|<http://arxiv.org/pdf/2503.16421v3>|[代码](https://quanhaol.github.io/magicmotion-site.); MagicMotion通过三级条件引导实现了轨迹可控的视频生成，同时保持物体一致性和视觉质量，解决了...|
|🆕 发布|MAGIC-Talk: Motion-aware Audio-Driven Talking Face Generation with Customizable Identity Control|《MAGIC-Talk：具有身份自定义控制功能的运动感知音频驱动说话人脸生成》|Fatemeh Nazarieh, Zhenhua Feng, Diptesh Kanojia, Muhammad Awais, Josef Kittler|<http://arxiv.org/pdf/2510.22810v1>|MAGIC-Talk通过单张图片实现个性化且稳定的说话面部生成，解决了身份保持和视频连贯性问题。|
|🆕 发布|Windsock is Dancing: Adaptive Multimodal Retrieval-Augmented Generation|"风袋在起舞：自适应多模态检索增强生成"|Shu Zhao, Tianyi Shen, Nilesh Ahuja, Omesh Tickoo, Vijaykrishnan Narayanan|<http://arxiv.org/pdf/2510.22694v1>|提出了一种自适应的多模态检索增强生成方法Windsock，有效解决了检索时机、模态选择和信息利用问题...|
|🆕 发布|RoboSVG: A Unified Framework for Interactive SVG Generation with Multi-modal Guidance|RoboSVG：一种用于交互式SVG生成的多模态引导统一框架|Jiuniu Wang, Gongjie Zhang, Quanhao Qian, Junlong Gao, Deli Zhao, Ran Xu|<http://arxiv.org/pdf/2510.22684v1>|提出RoboSVG框架，通过多模态指导生成高质量的交互式SVG图像，实现SVG生成任务的新突破。|
|📝 更新|EVODiff: Entropy-aware Variance Optimized Diffusion Inference|EVODiff：基于熵感知的方差优化扩散推理|Shigui Li, Wei Chen, Delu Zeng|<http://arxiv.org/pdf/2509.26096v2>|[代码](https://github.com/ShiguiLi/EVODiff.); 提出熵感知方差优化方法EVODiff，通过优化扩散模型推断过程中的条件熵，显著减少重建误差并提升生成...|
|📝 更新|Unbiased Scene Graph Generation from Biased Training|从有偏训练数据中生成无偏场景图|Kaihua Tang, Yulei Niu, Jianqiang Huang, Jiaxin Shi, Hanwang Zhang|<http://arxiv.org/pdf/2002.11949v4>|提出了一种基于因果推断的场景图生成框架，有效消除了训练数据中的不良偏差。|
|📝 更新|Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge|面向通用模态转换的对偶对比与预测潜在扩散桥|Nimrod Berman, Omkar Joglekar, Eitan Kosman, Dotan Di Castro, Omri Azencot|<http://arxiv.org/pdf/2510.20819v2>|提出了一种通用模态转换框架LDDBM，通过对比和对预测损失学习跨模态信息转换，实现了无需对齐维度的多...|
|📝 更新|RealCustom++: Representing Images as Real Textual Word for Real-Time Customization|实时定制化表示图像为真实文本单词的RealCustom++方法|Zhendong Mao, Mengqi Huang, Fei Ding, Mingcong Liu, Qian He, Yongdong Zhang|<http://arxiv.org/pdf/2408.09744v3>|[代码](https://github.com/bytedance/RealCustom.); 提出了一种使用真实单词表示主体的新范式，通过解耦训练和推理过程，实现了文本到图像定制中相似度和控制性...|
|📝 更新|CannyEdit: Selective Canny Control and Dual-Prompt Guidance for Training-Free Image Editing|CannyEdit：选择性Canny控制和双提示引导的无训练图像编辑|Weiyan Xie, Han Gao, Didan Deng, Kaican Li, April Hua Liu, Yongxiang Huang, Nevin L. Zhang|<http://arxiv.org/pdf/2508.06937v2>|CannyEdit通过选择性Canny控制和双提示引导，实现了无需训练的图像编辑，平衡了编辑区域的文...|
|🆕 发布|SRSR: Enhancing Semantic Accuracy in Real-World Image Super-Resolution with Spatially Re-Focused Text-Conditioning|空间重聚焦文本条件下的真实世界图像超分辨率增强：提高语义准确性(SRSR)|Chen Chen, Majid Abdolshah, Violetta Shevchenko, Hongdong Li, Chang Xu, Pulak Purkait|<http://arxiv.org/pdf/2510.22534v1>|提出了一种新的图像超分辨率框架SRSR，通过精确的文本条件和视觉引导的注意力机制，有效提升了真实世界...|
|🆕 发布|AesCrop: Aesthetic-driven Cropping Guided by Composition|《AesCrop：基于构图的审美驱动裁剪引导》|Yen-Hong Wong, Lai-Kuan Wong|<http://arxiv.org/pdf/2510.22528v1>|提出了一种融合摄影构图指导的图像裁剪模型AesCrop，有效平衡了裁剪的多样性和全局性。|
|🆕 发布|Open Multimodal Retrieval-Augmented Factual Image Generation|开放多模态检索增强的事实图像生成|Yang Tian, Fan Liu, Jingyuan Zhang, Wei Bi, Yupeng Hu, Liqiang Nie|<http://arxiv.org/pdf/2510.22521v1>|提出了一种开放式多模态检索增强框架ORIG，通过迭代检索和整合网络多模态证据，有效提升图像生成的事实...|
|📝 更新|SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent|“SceneWeaver：具有可扩展性和自省能力的全功能三维场景合成代理”|Yandan Yang, Baoxiong Jia, Shujie Zhang, Siyuan Huang|<http://arxiv.org/pdf/2509.20414v2>|[代码](https://scene-weaver.github.io/.); SceneWeaver通过工具式迭代优化，整合多种室内场景生成方法，实现物理可信、视觉逼真且语义一致...|
|🆕 发布|LAMP: Data-Efficient Linear Affine Weight-Space Models for Parameter-Controlled 3D Shape Generation and Extrapolation|LAMP：用于参数控制三维形状生成与外推的数据高效线性仿射权重空间模型|Ghadi Nehme, Yanxia Zhang, Dule Shu, Matt Klenk, Faez Ahmed|<http://arxiv.org/pdf/2510.22491v1>|提出LAMP方法，通过参数化形状的线性仿射混合实现高效、可控且安全的3D形状生成与外推。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FairJudge: MLLM Judging for Social Attributes and Prompt Image Alignment|公平评判者：多模态大型语言模型对社会属性的评价与提示图像对齐|Zahraa Al Sahili, Maryam Fetanat, Maimuna Nowaz, Ioannis Patras, Matthew Purver|<http://arxiv.org/pdf/2510.22827v1>|提出FairJudge协议，通过多模态LLM评估图像与提示的匹配度及模型处理社会属性公平性。|
|🆕 发布|DynaPose4D: High-Quality 4D Dynamic Content Generation via Pose Alignment Loss|动态姿态4D：通过姿态对齐损失实现高质量4D动态内容生成|Jing Yang, Yufeng Yang|<http://arxiv.org/pdf/2510.22473v1>|提出DynaPose4D，通过结合4D Gaussian Splatting与Category-Ag...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|IGGT: Instance-Grounded Geometry Transformer for Semantic 3D Reconstruction|实例定位几何变换器用于语义三维重建：IGGT|Hao Li, Zhengyu Zou, Fangfu Liu, Xuanyang Zhang, Fangzhou Hong, Yukang Cao, Yushi Lan, Manyuan Zhang .etc.|<http://arxiv.org/pdf/2510.22706v1>|提出Instance-Grounded Geometry Transformer，统一空间重建和实例...|
|🆕 发布|MELDAE: A Framework for Micro-Expression Spotting, Detection, and Automatic Evaluation in In-the-Wild Conversational Scenes|MELDAE：野外对话场景中微表情定位、检测与自动评估框架|Yigui Feng, Qinglin Wang, Yang Liu, Ke Liu, Haotian Mo, Enhao Huang, Gencheng Liu, Mingzhe Liu .etc.|<http://arxiv.org/pdf/2510.22575v1>|提出针对自然对话场景的微表情检测框架MELDAE，包含首个野外对话场景微表情数据集和边界感知损失函数...|
|📝 更新|A Cycle Ride to HDR: Semantics Aware Self-Supervised Framework for Unpaired LDR-to-HDR Image Reconstruction|《骑行至HDR：面向无配对低动态范围到高动态范围图像重建的语义感知自监督框架》|Hrishav Bakul Barua, Kalin Stefanov, Lemuel Lai En Che, Abhinav Dhall, KokSheik Wong, Ganesh Krishnasamy|<http://arxiv.org/pdf/2410.15068v4>|[代码](https://github.com/HrishavBakulBarua/Cycle-HDR); 提出了一种无需成对数据，利用自监督和语义一致性改进的HDR图像重建方法CycleHDR，实现了高质量...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Segment then Splat: Unified 3D Open-Vocabulary Segmentation via Gaussian Splatting|“分段后散布：通过高斯散布实现的统一三维开放词汇分割”|Yiren Lu, Yunlai Zhou, Yiran Qiao, Chaoda Song, Tuo Liang, Jing Ma, Huan Wang, Yu Yin|<http://arxiv.org/pdf/2503.22204v2>|提出了一种基于高斯散点的三维开放词汇分割方法，有效解决了动态场景下的对象分割问题。|
|📝 更新|Object-X: Learning to Reconstruct Multi-Modal 3D Object Representations|对象X：学习重建多模态三维物体表征|Gaia Di Lorenzo, Federico Tombari, Marc Pollefeys, Daniel Barath|<http://arxiv.org/pdf/2506.04789v2>|提出了一种多模态3D对象表示框架Object-X，实现了高保真几何重建并支持多种下游任务。|
|📝 更新|Beyond sparse denoising in frames: minimax estimation with a scattering transform|帧内稀疏去噪之外：基于散射变换的最小最大估计|Nathanaël Cuvelle--Magar, Stéphane Mallat|<http://arxiv.org/pdf/2510.19612v2>|提出了一种基于散射变换的图像去噪方法，通过联合优化散射系数的$\ell^1$范数，实现了对卡通图像的...|
|📝 更新|GS-ProCams: Gaussian Splatting-based Projector-Camera Systems|基于高斯散布的投影仪-摄像机系统：GS-ProCams|Qingyue Deng, Jijiang Li, Haibin Ling, Bingyao Huang|<http://arxiv.org/pdf/2412.11762v2>|[代码](https://realqingyue.github.io/GS-ProCams); 提出GS-ProCams框架，使用高斯散点提升投影映射效率，无需额外设备，实现高质量且高效的视点无关...|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Estimation of Fireproof Structure Class and Construction Year for Disaster Risk Assessment|火灾防护结构类别与建设年份估计：用于灾害风险评估|Hibiki Ayabe, Kazushi Okamoto, Koki Karube, Atsushi Shibata, Kei Harada|<http://arxiv.org/pdf/2510.22683v1>|提出了一种基于图像的多任务学习模型，用于预测建筑物的建造年份和结构类型，进而评估防火等级。|
|🆕 发布|Cross-View UAV Geo-Localization with Precision-Focused Efficient Design: A Hierarchical Distillation Approach with Multi-view Refinement|跨视角无人机精确地理定位的高效设计：基于多视角优化的层次蒸馏方法|Jian Sun, Kangdao Liu, Chi Zhang, Chuangquan Chen, Junge Shen, Chi-Man Vong|<http://arxiv.org/pdf/2510.22582v1>|[代码](https://github.com/SkyEyeLoc/PFED); 提出了一种高效的跨视角无人机地理定位框架，通过分层知识转移和多视角数据优化，实现了精度与效率的显著提...|
|🆕 发布|Bag-of-Word-Groups (BoWG): A Robust and Efficient Loop Closure Detection Method Under Perceptual Aliasing|词袋组（BoWG）：一种在感知别名下稳健且高效的闭环检测方法|Xiang Fei, Tina Tian, Howie Choset, Lu Li|<http://arxiv.org/pdf/2510.22529v1>|提出BoWG方法，通过构建视觉词组在线词典和引入时间一致性，提升闭环检测的准确性和效率。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LVD-GS: Gaussian Splatting SLAM for Dynamic Scenes via Hierarchical Explicit-Implicit Representation Collaboration Rendering|LVD-GS：通过分层显式-隐式表示协作渲染实现动态场景的高斯散布SLAM|Wenkai Zhu, Xu Li, Qimin Xu, Benwu Wang, Kun Wei, Yiming Peng, Zihang Wang|<http://arxiv.org/pdf/2510.22669v1>|提出了一种融合激光雷达和视觉数据的层次化协同表示SLAM系统，有效解决了动态场景中的尺度漂移和重建鲁...|
|📝 更新|Optimize the Unseen - Fast NeRF Cleanup with Free Space Prior|优化未见场景 - 基于自由空间先验的快速NeRF清理|Leo Segre, Shai Avidan|<http://arxiv.org/pdf/2412.12772v3>|提出了一种快速的后处理方法，通过自由空间先验消除NeRF中的“浮点”伪影，提升了novel view...|
|📝 更新|NVS-SQA: Exploring Self-Supervised Quality Representation Learning for Neurally Synthesized Scenes without References|NVS-SQA：无参考神经合成场景中的自监督质量表征学习探索|Qiang Qu, Yiran Shen, Xiaoming Chen, Yuk Ying Chung, Weidong Cai, Tongliang Liu|<http://arxiv.org/pdf/2501.06488v3>|提出了一种无参考神经合成场景质量评估方法NVS-SQA，通过自监督学习无需依赖人工标签，大幅超越了现...|
|🆕 发布|From Pixels to Views: Learning Angular-Aware and Physics-Consistent Representations for Light Field Microscopy|从像素到视角：学习适用于光场显微术的角感知与物理一致性表征|Feng He, Guodong Tan, Qiankun Li, Jun Yu, Quan Wen|<http://arxiv.org/pdf/2510.22577v1>|提出了大规模数据集和两种新方法，提升光场显微镜三维重建效果。|


## 时序视觉分析 (Temporal Visual Analysis)


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Neural-HAR: A Dimension-Gated CNN Accelerator for Real-Time Radar Human Activity Recognition|神经-HAR：一种用于实时雷达人体活动识别的维度门控卷积神经网络加速器|Yizhuo Wu, Francesco Fioranelli, Chang Gao|<http://arxiv.org/pdf/2510.22772v1>|[代码](https://github.com/lab-emi/AIRHAR.); 提出了一种针对资源受限平台实时雷达人体活动识别的参数高效维度门控卷积网络加速器。|
|🆕 发布|Mitigating Attention Sinks and Massive Activations in Audio-Visual Speech Recognition with LLMS|利用长语言模型减轻音频视觉语音识别中的注意力泄漏和大规模激活|Anand, Umberto Cappellazzo, Stavros Petridis, Maja Pantic|<http://arxiv.org/pdf/2510.22603v1>|本研究首次在多模态语音识别中识别并缓解了注意力 sink 和大规模激活现象，通过引入去相关损失有效降...|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Learning Event-guided Exposure-agnostic Video Frame Interpolation via Adaptive Feature Blending|通过自适应特征融合学习事件引导的曝光无关视频帧插值|Junsik Jung, Yoonki Cho, Woo Jae Kim, Lin Wang, Sune-eui Yoon|<http://arxiv.org/pdf/2510.22565v1>|提出了一种基于事件相机和自适应特征融合的曝光无关视频插帧方法，有效解决了低帧率模糊视频的清晰度问题。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Edge Collaborative Gaussian Splatting with Integrated Rendering and Communication|边缘协同高斯散点渲染与通信集成|Yujie Wan, Chenxuan Liu, Shuai Wang, Tong Zhang, James Jianqiao Yu, Kejiang Ye, Dusit Niyato, Chengzhong Xu|<http://arxiv.org/pdf/2510.22718v1>|提出边缘协作高斯散布策略，通过集成渲染与通信优化，提升低成本设备上的渲染质量与效率。|
|📝 更新|SA-UNetv2: Rethinking Spatial Attention U-Net for Retinal Vessel Segmentation|SA-UNetv2：重新思考用于视网膜血管分割的空间注意力U-Net|Changlu Guo, Anders Nymark Christensen, Anders Bjorholm Dahl, Yugen Yi, Morten Rieger Hannemose|<http://arxiv.org/pdf/2509.11774v2>|SA-UNetv2通过在所有跳跃连接中引入跨尺度空间注意力，并采用加权损失函数，有效提升了视网膜血管...|
|🆕 发布|Atlas Urban Index: A VLM-Based Approach for Spatially and Temporally Calibrated Urban Development Monitoring|城市地图指数：一种基于视觉语言模型的空间和时间校准的城市发展监测方法|Mithul Chander, Sai Pragnya Ranga, Prathamesh Mayekar|<http://arxiv.org/pdf/2510.22702v1>|提出了一种基于视觉语言模型的新指标，有效克服了传统城市指数在监测城市发展中的局限性。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LRW-Persian: Lip-reading in the Wild Dataset for Persian Language|LRW-波斯语：波斯语野外唇语识别数据集|Zahra Taghizadeh, Mohammad Shahverdikondori, Arian Noori, Alireza Dadgarnia|<http://arxiv.org/pdf/2510.22716v1>|介绍了首个大规模波斯语唇读数据集LRW-Persian，为低资源语言的多模态语音研究提供了基准资源。|
|🆕 发布|SWAN: Self-supervised Wavelet Neural Network for Hyperspectral Image Unmixing|SWAN：用于高光谱图像解混的自监督小波神经网络|Yassh Ramchandani, Vijayashekhar S S, Jignesh S. Bhatt|<http://arxiv.org/pdf/2510.22607v1>|提出了一种三阶段自监督小波神经网络，实现了无需地面真实值即可对高光谱图像进行端元和丰度联合估计。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Self-Calibrated Consistency can Fight Back for Adversarial Robustness in Vision-Language Models|自校准一致性能够为视觉-语言模型对抗稳健性反击|Jiaxiang Liu, Jiawei Du, Xiao Liu, Prayag Tiwari, Mingkun Xu|<http://arxiv.org/pdf/2510.22785v1>|提出了一种自校准一致性方法，有效增强了视觉语言模型在零样本设置下的对抗稳健性。|
|📝 更新|Progressive Multi-Source Domain Adaptation for Personalized Facial Expression Recognition|逐步多源域自适应用于个性化面部表情识别|Muhammad Osama Zeeshan, Marco Pedersoli, Alessandro Lameiras Koerich, Eric Granger|<http://arxiv.org/pdf/2504.04252v2>|提出渐进式多源域自适应方法，针对个性化面部表情识别，逐步引入与目标相似度高的源域信息，减少负迁移和计...|
|📝 更新|Measuring the (Un)Faithfulness of Concept-Based Explanations|测量基于概念的解释的（不）忠实度|Shubham Kumar, Narendra Ahuja|<http://arxiv.org/pdf/2504.10833v2>|提出统一框架评估概念解释忠实度，引入SURF度量法，发现现有方法不足。|
|🆕 发布|Robust Atypical Mitosis Classification with DenseNet121: Stain-Aware Augmentation and Hybrid Loss for Domain Generalization|具有DenseNet121的稳健非典型有丝分裂分类：着色感知增强与混合损失函数用于域泛化|Adinath Dukre, Ankan Deria, Yutong Xie, Imran Razzak|<http://arxiv.org/pdf/2510.22630v1>|提出了一种针对异常有丝分裂分类的DenseNet-121框架，通过染色感知增强和混合损失函数实现域泛...|
|📝 更新|Pulling Back the Curtain: Unsupervised Adversarial Detection via Contrastive Auxiliary Networks|拉开序幕：通过对比辅助网络进行无监督对抗性检测|Eylon Mizrahi, Raz Lapid, Moshe Sipper|<http://arxiv.org/pdf/2502.09110v3>|提出了一种无监督的对抗性检测方法U-CAN，通过对比辅助网络增强特征表示，有效区分良性输入与对抗性输...|


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Spurious-Aware Prototype Refinement for Reliable Out-of-Distribution Detection|伪迹感知的原型精炼：用于可靠分布外检测|Reihaneh Zohrabi, Hosein Hasani, Mahdieh Soleymani Baghshah, Anna Rohrbach, Marcus Rohrbach, Mohammad Hossein Rohban|<http://arxiv.org/pdf/2506.23881v2>|提出了一种针对未知伪相关性的原型细化方法SPROD，有效提升了OOD检测的可靠性和准确性。|
|🆕 发布|Single-Teacher View Augmentation: Boosting Knowledge Distillation via Angular Diversity|单教师视角增强：通过角多样性提升知识蒸馏效果|Seonghoon Yu, Dongjun Nam, Dina Katabi, Jeany Son|<http://arxiv.org/pdf/2510.22480v1>|提出了一种高效的知识增强方法，通过单一教师网络生成多视角，提升知识蒸馏性能。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Structure-preserving contrastive learning for spatial time series|保持结构对比的学习用于空间时间序列|Yiru Jiao, Sander van Cranenburgh, Simeon Calvert, Hans van Lint|<http://arxiv.org/pdf/2502.06380v5>|[代码](https://github.com/yiru-jiao/spclt); 提出结构保持对比学习方法，有效编码空间时间序列的细粒度时空相似性，提升模型性能。|
|📝 更新|Structural-Spectral Graph Convolution with Evidential Edge Learning for Hyperspectral Image Clustering|结构-谱图卷积与证据边学习用于高光谱图像聚类|Jianhan Qi, Yuheng Jia, Hui Liu, Junhui Hou|<http://arxiv.org/pdf/2506.09920v3>|[代码](https://github.com/jhqi/SSGCO-EGAEL.); 提出结构-光谱图卷积和证据引导的边学习策略，提升超像素级光谱图像聚类精度。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Fine-Grained Preference Optimization Improves Spatial Reasoning in VLMs|细粒度偏好优化提高了视觉语言模型中的空间推理能力|Yifan Shen, Yuanzhe Liu, Jingyuan Zhu, Xu Cao, Xiaofeng Zhang, Yixiao He, Wenming Ye, James Matthew Rehg .etc.|<http://arxiv.org/pdf/2506.21656v2>|引入细粒度偏好优化方法，提升了视觉语言模型在精细空间推理任务中的性能。|
|🆕 发布|Semantic-Preserving Cross-Style Visual Reasoning for Robust Multi-Modal Understanding in Large Vision-Language Models|用于大型视觉语言模型中稳健多模态理解的语义保持跨风格视觉推理|Aya Nakayama, Brian Wong, Yuji Nishimura, Kaito Tanaka|<http://arxiv.org/pdf/2510.22838v1>|提出了一种新颖的框架SP-CSVR，通过风格-内容解耦和自适应跨风格视觉推理，增强了大型视觉语言模型...|
|📝 更新|MECD+: Unlocking Event-Level Causal Graph Discovery for Video Reasoning|MECD+：解锁视频推理的事件级因果图发现|Tieyuan Chen, Huabin Liu, Yi Wang, Yihang Chen, Tianyao He, Chaofan Gan, Huanyu He, Weiyao Lin|<http://arxiv.org/pdf/2501.07227v4>|提出多事件因果发现任务，通过事件遮蔽和因果推理技术，实现了视频事件间复杂因果关系的识别与推理。|
|📝 更新|VideoHallu: Evaluating and Mitigating Multi-modal Hallucinations on Synthetic Video Understanding|视频幻觉评估与缓解：在合成视频理解中的多模态幻觉处理|Zongxia Li, Xiyang Wu, Guangyao Shi, Yubin Qin, Hongyang Du, Fuxiao Liu, Tianyi Zhou, Dinesh Manocha .etc.|<http://arxiv.org/pdf/2505.01481v4>|[代码](https://github.com/zli12321/VideoHallu.git.); 提出用合成不可能事件视频测试视觉语言模型的真实理解能力，并通过强化学习提升其视觉推理。|
|📝 更新|Visionary-R1: Mitigating Shortcuts in Visual Reasoning with Reinforcement Learning|Visionary-R1：利用强化学习减轻视觉推理中的捷径问题|Jiaer Xia, Yuhang Zang, Peng Gao, Sharon Li, Kaiyang Zhou|<http://arxiv.org/pdf/2505.14677v3>|通过强化学习训练视觉语言模型进行图像推理，并采用“描述-推理-回答”格式减少捷径学习，Visiona...|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LUQ: Layerwise Ultra-Low Bit Quantization for Multimodal Large Language Models|逐层超低比特量化（LUQ）用于多模态大型语言模型|Shubhang Bhatnagar, Andy Xu, Kar-Han Tan, Narendra Ahuja|<http://arxiv.org/pdf/2509.23729v2>|首次研究了针对多模态大语言模型的低于4位的超低位量化方法，提出层状超低位量化策略，有效减少内存使用并...|


### 视觉内容描述 (Visual Content Description)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Pindrop it! Audio and Visual Deepfake Countermeasures for Robust Detection and Fine Grained-Localization|“滴答声定位！音频与视觉深度伪造对策用于鲁棒检测与细微粒度定位”|Nicholas Klein, Hemlata Tak, James Fullwood, Krishna Regmi, Leonidas Spinoulas, Ganesh Sivaraman, Tianxiang Chen, Elie Khoury|<http://arxiv.org/pdf/2508.08141v2>|提出音频与视觉深度伪造检测与定位方法，在分类与时间定位任务中均取得优异表现。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Seeing the Unseen: Towards Zero-Shot Inspection for Wind Turbine Blades using Knowledge-Augmented Vision Language Models|《看见未见：基于知识增强视觉语言模型的零样本风电机叶片检测研究》|Yang Zhang, Qianyu Zhou, Farhad Imani, Jiong Tang|<http://arxiv.org/pdf/2510.22868v1>|提出了一种结合知识增强的视觉语言模型和检索增强生成框架，实现了无需大量标注数据即可检测风力涡轮叶片损...|
|🆕 发布|S-Chain: Structured Visual Chain-of-Thought For Medicine|S-Chain：医学领域的结构化视觉思维链|Khai Le-Duc, Duy M. H. Nguyen, Phuong T. H. Trinh, Tien-Phat Nguyen, Nghiem T. Diep, An Ngo, Tung Vu, Trinh Vuong .etc.|<http://arxiv.org/pdf/2510.22728v1>|提出了S-Chain，首个大规模专家标注的医学图像数据集，通过结构化视觉链式推理显著提升了解释性和准...|
|📝 更新|AutoVLA: A Vision-Language-Action Model for End-to-End Autonomous Driving with Adaptive Reasoning and Reinforcement Fine-Tuning|端到端自动驾驶的视觉-语言-动作模型：自适应推理与强化微调|Zewei Zhou, Tianhui Cai, Seth Z. Zhao, Yun Zhang, Zhiyu Huang, Bolei Zhou, Jiaqi Ma|<http://arxiv.org/pdf/2506.13757v2>|提出了AutoVLA模型，通过整合推理和动作生成，提升自动驾驶的规划和执行效率。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MedXplain-VQA: Multi-Component Explainable Medical Visual Question Answering|MedXplain-VQA：多组件可解释医疗视觉问答|Hai-Dang Nguyen, Minh-Anh Dang, Minh-Tan Le, Minh-Tuan Le|<http://arxiv.org/pdf/2510.22803v1>|提出MedXplain-VQA框架，融合五种解释性AI技术，为医学视觉问答提供透明推理和高质量诊断解...|
|🆕 发布|ConMatFormer: A Multi-attention and Transformer Integrated ConvNext based Deep Learning Model for Enhanced Diabetic Foot Ulcer Classification|《ConMatFormer：一种融合多注意力机制和Transformer的ConvNext基深度学习模型，用于增强糖尿病足溃疡分类》|Raihan Ahamed Rifat, Fuyad Hasan Bhoyan, Md Humaion Kabir Mehedi, Md Kaviul Hossain, Md. Jakir Hossen, M. F. Mridha|<http://arxiv.org/pdf/2510.22743v1>|提出ConMatFormer模型，融合卷积与Transformer优势，有效提升糖尿病足溃疡分类准确...|
|🆕 发布|GateFuseNet: An Adaptive 3D Multimodal Neuroimaging Fusion Network for Parkinson's Disease Diagnosis|GateFuseNet：一种自适应三维多模态神经影像融合网络用于帕金森病诊断|Rui Jin, Chen Chen, Yin Liu, Hongfu Sun, Min Zeng, Min Li, Yang Gao|<http://arxiv.org/pdf/2510.22507v1>|[代码](https://github.com/YangGaoUQ/GateFuseNet); 提出了一种自适应3D多模态神经影像融合网络GateFuseNet，通过整合QSM和T1w图像提高了帕...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Understanding What Is Not Said:Referring Remote Sensing Image Segmentation with Scarce Expressions|理解未言之物：在稀疏表达下进行遥感图像分割的指引用法|Kai Ye, Bowen Liu, Jianghang Lin, Jiayi Ji, Pingyang Dai, Liujuan Cao|<http://arxiv.org/pdf/2510.22760v1>|提出弱表达学习框架，通过少量精确参照和大量类别名实现遥感图像精细分割。|
|🆕 发布|WaveMAE: Wavelet decomposition Masked Auto-Encoder for Remote Sensing|波动掩码自编码器：基于小波分解的遥感图像处理方法|Vittorio Bernuzzi, Leonardo Rossi, Tomaso Fontanini, Massimo Bertozzi, Andrea Prati|<http://arxiv.org/pdf/2510.22697v1>|提出WaveMAE方法，通过小波变换和地理信息融合，提升遥感图像自监督学习性能。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DAMap: Distance-aware MapNet for High Quality HD Map Construction|距离感知的地图网络：用于高质量高清地图构建的DAMap|Jinpeng Dong, Chen Li, Yutong Lin, Jingwen Fu, Sanping Zhou, Nanning Zheng|<http://arxiv.org/pdf/2510.22675v1>|[代码](https://github.com/jpdong-xjtu/DAMap.); 提出了一种针对高质量高精度地图构建的DAMap方法，通过优化标签分配和特征提取显著提升了自动驾驶地图...|

