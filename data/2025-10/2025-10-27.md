## [UPDATED!] **2025-10-27** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|UrbanVLA: A Vision-Language-Action Model for Urban Micromobility|《UrbanVLA：一种面向城市微出行的视觉-语言-动作模型》|Anqi Li, Zhiyong Wang, Jiazhao Zhang, Minghan Li, Yunpeng Qi, Zhibo Chen, Zhizheng Zhang, He Wang|<http://arxiv.org/pdf/2510.23576v1>|提出了UrbanVLA模型，通过结合视觉、语言和动作处理，实现了大规模城市环境下的可靠导航。|
|🆕 发布|Towards Generalisable Foundation Models for 3D Brain MRI|面向通用基础模型的3D脑部MRI研究|Moona Mazher, Geoff J. M. Parker, Daniel C. Alexander|<http://arxiv.org/pdf/2510.23415v1>|提出了BrainFound模型，通过扩展2D视觉变换器至3D脑部MRI，实现了高效的多模态脑部影像分...|
|📝 更新|BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent|BTL-UI：面向图形用户界面智能体的眨眼-思考-关联推理模型|Shaojie Zhang, Ruoceng Zhang, Pei Fu, Shaokang Wang, Jiahui Yang, Xin Du, Shiqi Cui, Bin Qin .etc.|<http://arxiv.org/pdf/2509.15566v4>|提出“Blink-Think-Link”框架，模仿人类认知过程，提升AI与图形界面自然交互的性能。|
|🆕 发布|USF-MAE: Ultrasound Self-Supervised Foundation Model with Masked Autoencoding|USF-MAE：基于遮蔽自编码的超声自监督基础模型|Youssef Megahed, Robin Ducharme, Mark Walker, Steven Hawken, Adrian D. C. Chan|<http://arxiv.org/pdf/2510.22990v1>|提出USF-MAE模型，通过自监督学习在超声图像上实现高效特征提取，提升分类性能。|
|🆕 发布|Positional Preservation Embedding for Multimodal Large Language Models|多模态大型语言模型的位置保持嵌入|Mouxiao Huang, Borui Jiang, Dehua Zheng, Hailin Hu, Kai Han, Xinghao Chen|<http://arxiv.org/pdf/2510.22936v1>|提出了一种名为PPE的编码操作符，通过保持视觉token的空间时间结构，提高了多模态大语言模型的效率...|
|📝 更新|Refusal as Silence: Gendered Disparities in Vision-Language Model Responses|“拒绝即沉默：视觉语言模型响应中的性别差异”|Sha Luo, Sang Jung Kim, Zening Duan, Kaiping Chen|<http://arxiv.org/pdf/2406.08222v3>|揭示了大型语言模型在处理不同性别身份用户请求时的拒绝行为差异，强调了算法公平性的重要性。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|A Fine-Grained Attention and Geometric Correspondence Model for Musculoskeletal Risk Classification in Athletes Using Multimodal Visual and Skeletal Features|用于运动员肌肉骨骼风险分类的多模态视觉与骨骼特征精细化注意力与几何对应模型|Md. Abdur Rahman, Mohaimenul Azam Khan Raiaan, Tamanna Shermin, Md Rafiqul Islam, Mukhtar Hussain, Sami Azam|<http://arxiv.org/pdf/2509.05913v2>|提出了一种融合视觉与骨骼特征的多模态深度学习模型ViSK-GAT，有效提升运动员肌肉骨骼风险早期评估...|
|🆕 发布|MMSD3.0: A Multi-Image Benchmark for Real-World Multimodal Sarcasm Detection|多模态讽刺检测的面向现实世界的多图像基准MMSD3.0|Haochen Zhao, Yuyao Kong, Yongxiu Xu, Gaopeng Gou, Hongbo Xu, Yubin Wang, Haoliang Zhang|<http://arxiv.org/pdf/2510.23299v1>|提出了MMSD3.0多图像基准和Cross-Image Reasoning Model模型，有效提升...|
|🆕 发布|Accurate and Scalable Multimodal Pathology Retrieval via Attentive Vision-Language Alignment|通过注意力视觉-语言对齐实现精确且可扩展的多模态病理检索|Hongyi Wang, Zhengjie Zhu, Jiabo Ma, Fang Wang, Yue Shi, Bo Luo, Jili Wang, Qiuyu Cai .etc.|<http://arxiv.org/pdf/2510.23224v1>|提出PathSearch框架，通过图像与文本的对比学习实现精确高效的病理切片多模态检索。|
|🆕 发布|Finding 3D Scene Analogies with Multimodal Foundation Models|使用多模态基础模型寻找三维场景类比|Junho Kim, Young Min Kim|<http://arxiv.org/pdf/2510.23184v1>|提出使用多模态基础模型在零样本、开放词汇设置中寻找3D场景类比，通过结合视觉语言模型特征和3D形状基...|
|🆕 发布|Revisiting Multimodal Positional Encoding in Vision-Language Models|重新审视视觉语言模型中的多模态位置编码|Jie Huang, Xuejing Liu, Sibo Song, Ruibing Hou, Hong Chang, Junyang Lin, Shuai Bai|<http://arxiv.org/pdf/2510.23095v1>|[代码](https://github.com/JJJYmmm/Multimodal-RoPEs.); 提出多模态位置编码新方法，提升视觉语言模型理解能力。|
|🆕 发布|Survey of Multimodal Geospatial Foundation Models: Techniques, Applications, and Challenges|多模态地理空间基础模型综述：技术、应用与挑战|Liling Yang, Ning Chen, Jun Yue, Yidan Liu, Jiayi Ma, Pedram Ghamisi, Antonio Plaza, Leyuan Fang|<http://arxiv.org/pdf/2510.22964v1>|系统综述了多模态地理空间基础模型的技术、应用与挑战，为遥感图像分析提供了新的研究前沿。|
|🆕 发布|LightBagel: A Light-weighted, Double Fusion Framework for Unified Multimodal Understanding and Generation|轻量级双融合框架：用于统一多模态理解和生成的LightBagel|Zeyu Wang, Zilong Chen, Chenhui Gou, Feng Li, Chaorui Deng, Deyao Zhu, Kunchang Li, Weihao Yu .etc.|<http://arxiv.org/pdf/2510.22946v1>|提出了一种高效的轻量级多模态融合框架，通过结合专业模型实现高性能的多模态理解和生成。|
|📝 更新|Gesplat: Robust Pose-Free 3D Reconstruction via Geometry-Guided Gaussian Splatting|“Gesplat：基于几何引导的高斯散点法的鲁棒无姿态三维重建”|Jiahui Lu, Haihong Xiao, Xueyan Zhao, Wenxiong Kang|<http://arxiv.org/pdf/2510.10097v2>|提出了一种基于几何引导的高斯散点框架，实现了无需准确相机姿态的稳健三维重建。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Attention! Your Vision Language Model Could Be Maliciously Manipulated|《注意！您的视觉语言模型可能被恶意操纵》|Xiaosen Wang, Shaokang Wang, Zhijin Ge, Yuyang Luo, Shudong Zhang|<http://arxiv.org/pdf/2505.19911v2>|[代码](https://github.com/Trustworthy-AI-Group/VMA.); 揭示了大型视觉语言模型对图像对抗样本的脆弱性，并提出了VMA攻击方法来精确操纵模型输出。|
|🆕 发布|Implicit Modeling for Transferability Estimation of Vision Foundation Models|视觉基础模型迁移性估计的隐式建模|Yaoyan Zheng, Huiqun Wang, Nan Zhou, Di Huang|<http://arxiv.org/pdf/2510.23145v1>|提出 Implicit Transferability Modeling 框架，有效估算新兴预训练模...|
|📝 更新|HoliSafe: Holistic Safety Benchmarking and Modeling for Vision-Language Model|《HoliSafe：视觉语言模型的全局安全性基准测试与建模》|Youngwan Lee, Kangsan Kim, Kwanyong Park, Ilcahe Jung, Soojin Jang, Seanie Lee, Yong-Ju Lee, Sung Ju Hwang|<http://arxiv.org/pdf/2506.04704v3>|提出全面安全数据集HoliSafe及模块化框架VGM，增强视觉语言模型的安全性和可解释性。|
|📝 更新|UKANFormer: Noise-Robust Semantic Segmentation for Coral Reef Mapping via a Kolmogorov-Arnold Network-Transformer Hybrid|UKANFormer：基于科尔莫哥洛夫-阿尔诺德网络-变压器混合模型的噪声稳健型珊瑚礁映射语义分割|Tianyang Dou, Ming Li, Jiangying Qin, Xuan Liao, Jiageng Zhong, Armin Gruen, Mengyi Deng|<http://arxiv.org/pdf/2510.16730v2>|提出UKANFormer模型，通过全局-局部Transformer结构提升在噪声监督下的珊瑚礁精细映...|
|🆕 发布|Bi-Encoder Contrastive Learning for Fingerprint and Iris Biometrics|双编码器对比学习在指纹和虹膜生物特征识别中的应用|Matthew So, Judah Goldfeder, Mark Lis, Hod Lipson|<http://arxiv.org/pdf/2510.22937v1>|[代码](https://github.com/MatthewSo/bio_fingerprints_iris.); 提出双编码器对比学习框架，挑战传统生物特征独立假设，实现指纹和虹膜匹配的高效验证。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A U-Net and Transformer Pipeline for Multilingual Image Translation|用于多语言图像翻译的U-Net与Transformer级联流程|Siddharth Sahay, Radhika Agarwal|<http://arxiv.org/pdf/2510.23554v1>|提出了一种集成U-Net和Transformer的端到端多语言图像翻译系统，实现了从图像到文本的准确...|
|📝 更新|Training-Free In-Context Forensic Chain for Image Manipulation Detection and Localization|无需训练的图像操纵检测与定位中的在位法医链|Rui Chen, Bin Liu, Changtao Miao, Xinghao Wang, Yi Li, Tao Gong, Qi Chu, Nenghai Yu|<http://arxiv.org/pdf/2510.10111v2>|提出了一种无需训练的In-Context Forensic Chain框架，利用大型多模态语言模型进...|
|🆕 发布|AG-Fusion: adaptive gated multimodal fusion for 3d object detection in complex scenes|AG-Fusion：自适应门控多模态融合用于复杂场景中的三维目标检测|Sixian Liu, Chen Xu, Qiang Wang, Donghai Shi, Yiwen Li|<http://arxiv.org/pdf/2510.23151v1>|提出了一种自适应门控多模态融合方法AG-Fusion，有效提升了复杂场景下三维物体检测的鲁棒性。|
|🆕 发布|DQ3D: Depth-guided Query for Transformer-Based 3D Object Detection in Traffic Scenarios|基于变换器的交通场景三维目标检测中的深度引导查询方法DQ3D|Ziyu Wang, Wenhao Li, Ji Wu|<http://arxiv.org/pdf/2510.23144v1>|提出深度引导的查询生成方法DQ3D，结合深度信息和2D检测结果优化3D物体检测，提高准确率。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DPGLA: Bridging the Gap between Synthetic and Real Data for Unsupervised Domain Adaptation in 3D LiDAR Semantic Segmentation|DPGLA：用于三维激光雷达语义分割的无监督域自适应中，合成数据与真实数据之间的桥梁|Wanmeng Li, Simone Mosco, Daniel Fusaro, Alberto Pretto|<http://arxiv.org/pdf/2510.23525v1>|提出动态伪标签过滤和先验引导数据增强方法，有效提升3D激光雷达点云无监督域自适应语义分割性能。|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Smartphone-based iris recognition through high-quality visible-spectrum iris image capture.V2|基于智能手机的高质量可见光波段虹膜图像捕获的虹膜识别技术。V2|Naveenkumar G Venkataswamy, Yu Liu, Soumyabrata Dey, Stephanie Schuckers, Masudul H Imtiaz|<http://arxiv.org/pdf/2510.06170v2>|提出了一种基于智能手机的可见光谱虹膜识别方法，通过标准化图像采集和轻量级模型实现了高准确度识别。|
|🆕 发布|Color and Frequency Correction for Image Colorization|图像色彩化中的颜色与频率校正|Yun Kai Zhuang|<http://arxiv.org/pdf/2510.23399v1>|提出两种优化方案改善DDColor模型在特定频率带和色彩偏差问题，提升了图像质量指标。|
|🆕 发布|hYOLO Model: Enhancing Object Classification with Hierarchical Context in YOLOv8|hYOLO模型：利用层次化上下文增强YOLOv8中的目标分类|Veska Tsenkova, Peter Stanchev, Daniel Petrov, Deyan Lazarov|<http://arxiv.org/pdf/2510.23278v1>|提出了一种基于YOLO的层级模型，通过引入层级架构和定制损失函数，提升了图像检测和分类的上下文理解能...|
|🆕 发布|DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification|DecoDINO：基于语义分类的三维人体-场景接触预测|Lukas Bierling, Davide Pasero, Fleur Dolmans, Helia Ghasemi, Angelo Broere|<http://arxiv.org/pdf/2510.23203v1>|[代码](https://github.com/DavidePasero/deco); 提出DecoDINO模型，通过双编码器和改进的注意力机制，提高了3D人体与场景接触预测的准确性和语义...|
|📝 更新|A Training-Free Framework for Open-Vocabulary Image Segmentation and Recognition with EfficientNet and CLIP|无训练框架的开词汇图像分割与识别：结合EfficientNet与CLIP方法|Ying Dai, Wei Yu Chen|<http://arxiv.org/pdf/2510.19333v2>|提出了一种无需训练的框架，结合EfficientNetB0进行无监督图像分割和CLIP进行开放词汇对...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|THUNDER: Tile-level Histopathology image UNDERstanding benchmark|“THUNDER：瓦片级别病理图像理解基准”|Pierre Marza, Leo Fillioux, Sofiène Boutaj, Kunal Mahatha, Christian Desrosiers, Pablo Piantanida, Jose Dolz, Stergios Christodoulidis .etc.|<http://arxiv.org/pdf/2507.07860v2>|[代码](https://github.com/MICS-Lab/thunder.); 提出了THUNDER基准，为数字病理学领域提供了一种快速、易用的方法来比较多种基础模型在多个数据集和...|
|📝 更新|Robust Modality-incomplete Anomaly Detection: A Modality-instructive Framework with Benchmark|稳健的模态不完整异常检测：一种模态指导框架及基准|Bingchen Miao, Wenqiao Zhang, Juncheng Li, Wangyu Wu, Siliang Tang, Zhaocheng Li, Haochen Shi, Jun Xiao .etc.|<http://arxiv.org/pdf/2410.01737v2>|提出了一种针对模态不完整数据的鲁棒多模态异常检测框架RADAR，有效应对工业质量检测中的数据缺失问题...|
|📝 更新|CMIE: Combining MLLM Insights with External Evidence for Explainable Out-of-Context Misinformation Detection|CMIE：结合多模态语言模型洞见与外部证据进行可解释的上下文外错误信息检测|Fanxiao Li, Jiaying Wu, Canyuan He, Wei Zhou|<http://arxiv.org/pdf/2505.23449v3>|提出CMIE框架，通过挖掘图像与文本的潜在关联关系和选择性地利用证据，有效提升误信息检测准确性。|
|🆕 发布|Estimating Pasture Biomass from Top-View Images: A Dataset for Precision Agriculture|从俯视图图像估算牧场生物量：一个用于精准农业的数据集|Qiyu Liao, Dadong Wang, Rebecca Haling, Jiajun Liu, Xun Li, Martyna Plomecka, Andrew Robson, Matthew Pringle .etc.|<http://arxiv.org/pdf/2510.22916v1>|构建了一个包含1162张标注的牧场俯视图像数据集，助力精准农业中的牧场生物质估算。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PixelRefer: A Unified Framework for Spatio-Temporal Object Referring with Arbitrary Granularity|像素指代：一种用于任意粒度时空目标指代的统一框架|Yuqian Yuan, Wenqiao Zhang, Xin Li, Shihao Wang, Kehan Li, Wentong Li, Jun Xiao, Lei Zhang .etc.|<http://arxiv.org/pdf/2510.23603v1>|PixelRefer提出了一种统一的多模态语言模型框架，通过细粒度对象理解实现了对任意区域的高效描述...|
|📝 更新|Noise Diffusion for Enhancing Semantic Faithfulness in Text-to-Image Synthesis|噪声扩散用于提升文本到图像合成中的语义保真度|Boming Miao, Chunxiao Li, Xiaoxiao Wang, Andi Zhang, Rui Sun, Zizhe Wang, Yao Zhu|<http://arxiv.org/pdf/2411.16503v2>|[代码](https://github.com/Bomingmiao/NoiseDiffusion.); 利用大型视觉语言模型优化噪声潜伏，提出噪声扩散过程以增强文本到图像合成的语义保真度。|
|🆕 发布|Yesnt: Are Diffusion Relighting Models Ready for Capture Stage Compositing? A Hybrid Alternative to Bridge the Gap|“叶森特：扩散重光照模型是否已准备好用于捕获阶段合成？一种混合替代方案以填补鸿沟”|Elisabeth Jüttner, Leona Krath, Stefan Korfhage, Hannah Dröge, Matthias B. Hullin, Markus Plack|<http://arxiv.org/pdf/2510.23494v1>|提出了一种结合扩散先验和物理渲染的混合框架，实现了更稳定的视频逐帧重光照效果。|
|🆕 发布|Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with Free-Form Preferences|全奖励：面向具有自由形式偏好的通用全模态奖励建模|Zhuoran Jin, Hongbang Yuan, Kejian Zhu, Jiachun Li, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao|<http://arxiv.org/pdf/2510.23451v1>|提出Omni-Reward，一种支持多模态和个性化偏好的通用奖励模型，解决模态不平衡和偏好固定性问题...|
|🆕 发布|Adaptive Stochastic Coefficients for Accelerating Diffusion Sampling|自适应随机系数以加速扩散采样|Ruoyu Wang, Beier Zhu, Junzhi Li, Liangyu Yuan, Chi Zhang|<http://arxiv.org/pdf/2510.23285v1>|[代码](https://github.com/WLU-wry02/AdaSDE.); 提出AdaSDE方法，通过动态调节误差校正强度，平衡了计算速度和样本质量，实现扩散采样的加速。|
|📝 更新|T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting|T2ICount：增强零样本计数中的跨模态理解|Yifei Qian, Zhongliang Guo, Bowen Deng, Chun Tong Lei, Shuai Zhao, Chun Pong Lau, Xiaopeng Hong, Michael P. Pound|<http://arxiv.org/pdf/2502.20625v3>|[代码](https://github.com/cha15yq/T2ICount.); 提出了一种基于扩散模型和层次语义校正的零样本计数框架，有效提升了文本引导的计数准确性。|
|🆕 发布|Residual Diffusion Bridge Model for Image Restoration|残差扩散桥模型用于图像恢复|Hebaixu Wang, Jing Zhang, Haoyang Chen, Haonan Guo, Di Wang, Jiayi Ma, Bo Du|<http://arxiv.org/pdf/2510.23116v1>|[代码](https://github.com/MiliLab/RDBM.); 提出Residual Diffusion Bridge Model，通过残差调制优化图像复原，同时保...|
|📝 更新|Neural Stereo Video Compression with Hybrid Disparity Compensation|神经立体视频压缩与混合视差补偿|Shiyin Jiang, Zhenghao Chen, Minghao Han, Shuhang Gu|<http://arxiv.org/pdf/2504.20383v2>|提出了一种混合视差补偿策略，结合显式像素位移和隐式注意力机制，显著提升了立体视频压缩性能。|
|📝 更新|S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation|首先，我会将标题中的专业术语翻译为对应的中文，然后再组合成完整的中文标题。  - S$^2$Q-VDiT：保持原样，作为模型名称。 - Accurate：精确的 - Quantized：量化的 - Video Diffusion Transformer：视频扩散变压器（这里“变压器”指的是一种深度学习模型结构，即Transformer） - Salient Data：显著数据 - Sparse Token Distillation：稀疏令牌蒸馏  结合以上翻译，完整的中文标题为：  S$^2$Q-VDiT：基于显著数据与稀疏令牌蒸馏的精确量化视频扩散变压器|Weilun Feng, Haotong Qin, Chuanguang Yang, Xiangqi Li, Han Yang, Yuqi Li, Zhulin An, Libo Huang .etc.|<http://arxiv.org/pdf/2508.04016v3>|[代码](https://github.com/wlfeng0509/s2q-vdit.); 提出S$^2$Q-VDiT框架，通过关键数据选择和稀疏注意力蒸馏，实现视频生成模型的压缩和加速。|
|📝 更新|Kuramoto Orientation Diffusion Models|Kuramoto取向扩散模型|Yue Song, T. Anderson Keller, Sevan Brodjian, Takeru Miyato, Yisong Yue, Pietro Perona, Max Welling|<http://arxiv.org/pdf/2509.15328v2>|提出了一种基于Kuramoto动态的生成模型，利用同步现象优化了方向密集图像的生成质量。|
|📝 更新|One Stone with Two Birds: A Null-Text-Null Frequency-Aware Diffusion Models for Text-Guided Image Inpainting|一石二鸟：面向文本引导图像修复的零文本零频率感知扩散模型|Haipeng Liu, Yang Wang, Meng Wang|<http://arxiv.org/pdf/2510.08273v5>|[代码](https://github.com/htyjers/NTN-Diff.); 提出了一种分解频率带的扩散模型NTN-Diff，通过分别处理不同频率以达到文本引导的图像修复中的一致...|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas|《LayerComposer：通过空间感知分层画布实现的交互式个性化文本到图像》|Guocheng Gordon Qian, Ruihang Zhang, Tsai-Shien Chen, Yusuf Dalva, Anujraaj Argo Goyal, Willi Menapace, Ivan Skorokhodov, Meng Dong .etc.|<http://arxiv.org/pdf/2510.20820v2>|LayerComposer通过分层画布与锁定机制，实现了多主体个性化图像生成的交互式控制与高质量保留...|
|🆕 发布|Lookahead Anchoring: Preserving Character Identity in Audio-Driven Human Animation|前瞻锚定：在音频驱动的人体动画中保持角色身份一致性|Junyoung Seo, Rodrigo Mira, Alexandros Haliassos, Stella Bounareli, Honglie Chen, Linh Tran, Seungryong Kim, Zoe Landgraf .etc.|<http://arxiv.org/pdf/2510.23581v1>|提出 Lookahead Anchoring 方法，通过引用未来关键帧保持角色身份一致性，解决了音频...|
|📝 更新|ESCA: Contextualizing Embodied Agents via Scene-Graph Generation|ESCA：通过场景图生成对具身智能体进行情境化|Jiani Huang, Amish Sethi, Matthew Kuo, Mayank Keoliya, Neelay Velingker, JungHo Jung, Ser-Nam Lim, Ziyang Li .etc.|<http://arxiv.org/pdf/2510.15963v2>|[代码](https://github.com/video-fm/LASER); 提出ESCA框架，通过生成时空场景图增强Embodied Agents的感知准确性。|
|📝 更新|ReXGroundingCT: A 3D Chest CT Dataset for Segmentation of Findings from Free-Text Reports|“ReXGroundingCT：一种用于从自由文本报告中分割发现的3D胸部CT数据集”|Mohammed Baharoon, Luyang Luo, Michael Moritz, Abhinav Kumar, Sung Eun Kim, Xiaoman Zhang, Miao Zhu, Mahmoud Hussain Alabbad .etc.|<http://arxiv.org/pdf/2507.22030v2>|首次创建了一个将自由文本报告中的发现与3D胸部CT扫描像素级分割关联的公开数据集。|
|🆕 发布|More Than Generation: Unifying Generation and Depth Estimation via Text-to-Image Diffusion Models|“不止于生成：通过文本到图像扩散模型统一生成与深度估计”|Hongkai Lin, Dingkang Liang, Mingyang Du, Xin Zhou, Xiang Bai|<http://arxiv.org/pdf/2510.23574v1>|[代码](https://github.com/H-EmbodVis/MERGE); 提出MERGE模型，通过插件式转换器在图像生成与深度估计间无缝切换，实现两者能力共存且性能领先。|
|📝 更新|Synthesize Privacy-Preserving High-Resolution Images via Private Textual Intermediaries|通过私人文本中介合成保护隐私的高分辨率图像|Haoxiang Wang, Zinan Lin, Da Yu, Huishuai Zhang|<http://arxiv.org/pdf/2506.07555v3>|提出了一种利用隐私文本中介生成高分辨率差分隐私图像的新方法，大幅提升了图像质量和隐私保护水平。|
|🆕 发布|FreeFuse: Multi-Subject LoRA Fusion via Auto Masking at Test Time|结果：FreeFuse：测试时通过自动掩模实现多主体LoRA融合|Yaoli Liu, Yao-Xiang Ding, Kun Zhou|<http://arxiv.org/pdf/2510.23515v1>|[代码](https://future-item.github.io/FreeFuse); 提出了一种无需训练、自动融合多主体LoRA的图像生成方法，提升了生成质量和实用性。|
|📝 更新|Topology Sculptor, Shape Refiner: Discrete Diffusion Model for High-Fidelity 3D Meshes Generation|拓扑雕刻家，形状细化器：用于高保真三维网格生成的离散扩散模型|Kaiyu Song, Hanjiang Lai, Yaqing Zhang, Chuangjian Cai, Yan Pan Kun Yue, Jian Yin|<http://arxiv.org/pdf/2510.21264v2>|[代码](https://github.com/psky1111/Tencent-TSSR.); 提出了一种基于离散扩散模型的高效3D网格生成方法，通过拓扑雕塑和形状细化两阶段实现高质量艺术家风格网...|
|📝 更新|Self-supervised Representation Learning with Local Aggregation for Image-based Profiling|基于局部聚合的自监督表征学习在图像分析中的应用|Siran Dai, Qianqian Xu, Peisong Wen, Yang Liu, Qingming Huang|<http://arxiv.org/pdf/2506.14265v2>|提出了一种针对细胞图像的自监督学习框架，通过局部聚合和定制化数据增强，提高了特征提取器的跨站点一致性...|
|📝 更新|Psi-Sampler: Initial Particle Sampling for SMC-Based Inference-Time Reward Alignment in Score Models|Ψ采样器：基于SMC的推理时得分模型奖励对齐的初始粒子采样|Taehoon Yoon, Yunhong Min, Kyeongmin Yeo, Minhyuk Sung|<http://arxiv.org/pdf/2506.01320v3>|引入了$\Psi$-Sampler，一种结合pCNL算法的高效后验采样方法，用于基于SMC的推理时奖...|
|📝 更新|TEn-CATG:Text-Enriched Audio-Visual Video Parsing with Multi-Scale Category-Aware Temporal Graph|文本增强的多尺度类别感知时序图音频视觉视频解析方法TEn-CATG|Yaru Chen, Faegheh Sardari, Peiliang Zhang, Ruohao Guo, Yang Xiang, Zhenbo Li, Wenwu Wang|<http://arxiv.org/pdf/2509.04086v2>|提出了一种融合文本信息的音频视觉视频解析框架TEn-CATG，通过双向文本融合和类别感知时序图模型，...|
|🆕 发布|ReconViaGen: Towards Accurate Multi-view 3D Object Reconstruction via Generation|通过生成方法实现精确的多视角三维物体重建：ReconViaGen|Jiahao Chang, Chongjie Ye, Yushuang Wu, Yuantao Chen, Yidan Zhang, Zhongjin Luo, Chenghong Li, Yihao Zhi .etc.|<http://arxiv.org/pdf/2510.23306v1>|[代码](https://jiahao620.github.io/reconviagen.); 提出了一种创新的3D重建方法ReconViaGen，通过整合生成框架和重建先验，有效解决了多视角重建...|
|🆕 发布|Through the Lens: Benchmarking Deepfake Detectors Against Moiré-Induced Distortions|通过镜头：对深度伪造检测器在莫尔纹理诱导失真下的基准测试|Razaib Tariq, Minji Heo, Simon S. Woo, Shahroz Tariq|<http://arxiv.org/pdf/2510.23225v1>|评估了现有深度伪造检测器在摩尔纹干扰下的性能，并构建了专用数据集以促进鲁棒检测模型的研究。|
|🆕 发布|Autoregressive Styled Text Image Generation, but Make it Reliable|自回归风格化文本图像生成，但要确保可靠性|Carmine Zaccagnino, Fabio Quattrini, Vittorio Pippi, Silvia Cascianelli, Alessio Tonioni, Rita Cucchiara|<http://arxiv.org/pdf/2510.23240v1>|提出了一种改进的自动回归生成模型Eruku，通过多模态提示和无需额外输入的策略，提高了生成手写文本图...|
|📝 更新|C-DiffDet+: Fusing Global Scene Context with Generative Denoising for High-Fidelity Car Damage Detection|C-DiffDet+：融合全局场景上下文与生成去噪以提高车辆损伤检测的高保真度|Abdellah Zakaria Sellam, Ilyes Benaissa, Salah Eddine Bekhouche, Abdenour Hadid, Vito Renó, Cosimo Distante|<http://arxiv.org/pdf/2509.00578v4>|引入上下文感知融合技术，结合全局场景上下文与生成去噪，提升车辆损伤检测的准确性和真实性。|
|📝 更新|Flow-GRPO: Training Flow Matching Models via Online RL|流-GRPO：通过在线强化学习训练流匹配模型|Jie Liu, Gongye Liu, Jiajun Liang, Yangguang Li, Jiaheng Liu, Xintao Wang, Pengfei Wan, Di Zhang .etc.|<http://arxiv.org/pdf/2505.05470v5>|Flow-GRPO首次将在线强化学习融入流匹配模型，通过随机微分方程转换和去噪简化策略，大幅提升生成...|
|🆕 发布|Task-Agnostic Fusion of Time Series and Imagery for Earth Observation|任务无关的时间序列与图像融合用于地球观测|Gianfranco Basile, Johannes Jakubik, Benedikt Blumenstiel, Thomas Brunschwiler, Juan Bernabe Moreno|<http://arxiv.org/pdf/2510.23118v1>|提出了一种跨模态融合时间序列和图像的通用框架，实现了地球观测数据的生成和性能提升。|
|📝 更新|Reconstruction Alignment Improves Unified Multimodal Models|统一多模态模型的重构对齐改进|Ji Xie, Trevor Darrell, Luke Zettlemoyer, XuDong Wang|<http://arxiv.org/pdf/2509.07295v3>|提出了一种名为Reconstruction Alignment的简单高效方法，通过利用视觉理解编码器...|
|📝 更新|Improving Video Generation with Human Feedback|利用人类反馈提高视频生成质量|Jie Liu, Gongye Liu, Jiajun Liang, Ziyang Yuan, Xiaokun Liu, Mingwu Zheng, Xiele Wu, Qiulin Wang .etc.|<http://arxiv.org/pdf/2501.13918v2>|利用人类反馈优化视频生成模型，显著提升运动流畅性和视频与提示对齐度。|
|📝 更新|ORIGEN: Zero-Shot 3D Orientation Grounding in Text-to-Image Generation|ORIGEN：文本到图像生成中的零样本3D方向定位|Yunhong Min, Daehyeon Choi, Kyeongmin Yeo, Jihyun Lee, Minhyuk Sung|<http://arxiv.org/pdf/2503.22194v3>|首次提出零样本3D方向定位方法，通过奖励引导采样和 Langevin 动力学优化图像生成。|
|📝 更新|DOS: Directional Object Separation in Text Embeddings for Multi-Object Image Generation|用于多对象图像生成的文本嵌入中的方向性对象分离DOS|Dongnam Byun, Jungwon Park, Jumgmin Ko, Changin Choi, Wonjong Rhee|<http://arxiv.org/pdf/2510.14376v2>|提出DOS方法，通过修改CLIP文本嵌入提升多物体图像生成质量，减少物体混合。|
|🆕 发布|Nested AutoRegressive Models|嵌套自回归模型|Hongyu Wu, Xuhui Fan, Zhangkai Wu, Longbing Cao|<http://arxiv.org/pdf/2510.23028v1>|提出了Nested AutoRegressive模型，通过嵌套结构降低计算复杂度并提升图像生成多样性...|
|🆕 发布|CoMo: Compositional Motion Customization for Text-to-Video Generation|"CoMo：用于文本到视频生成的组合运动定制"|Youcan Xu, Zhen Wang, Jiaxin Shi, Kexin Li, Feifei Shao, Jun Xiao, Yi Yang, Jun Yu .etc.|<http://arxiv.org/pdf/2510.23007v1>|[代码](https://como6.github.io/.); 提出了一种用于文本到视频生成的组合运动定制框架，有效解决了多运动合成中的运动外观耦合和运动混合问题。|
|🆕 发布|M$^{3}$T2IBench: A Large-Scale Multi-Category, Multi-Instance, Multi-Relation Text-to-Image Benchmark|M$^{3}$T2IBench：大规模多类别、多实例、多关系文本到图像基准数据集|Huixuan Zhang, Xiaojun Wan|<http://arxiv.org/pdf/2510.23020v1>|提出了M$^3$T2IBench基准和Revise-Then-Enforce方法，显著提升了文本到图...|
|🆕 发布|SceneDecorator: Towards Scene-Oriented Story Generation with Scene Planning and Scene Consistency|场景装饰器：面向场景的故事生成方法，结合场景规划与场景一致性|Quanjian Song, Donghao Zhou, Jingyu Lin, Fei Shen, Jiaze Wang, Xiaowei Hu, Cunjian Chen, Pheng-Ann Heng|<http://arxiv.org/pdf/2510.22994v1>|提出了一种面向场景的故事生成框架SceneDecorator，通过全局到局部场景规划和长期场景共享注...|
|🆕 发布|Exploring Semantic-constrained Adversarial Example with Instruction Uncertainty Reduction|探索语义约束的对抗样本生成方法及指令不确定性降低|Jin Hu, Jiakai Wang, Linna Jing, Haolin Li, Haodong Liu, Haotong Qin, Aishan Liu, Ke Xu .etc.|<http://arxiv.org/pdf/2510.22981v1>|提出了一种多维指令不确定性降低框架，有效提升了语义约束对抗样本的生成质量和攻击能力。|
|🆕 发布|Scaling Up Occupancy-centric Driving Scene Generation: Dataset and Method|扩大基于占用中心的驾驶场景生成：数据集与方法|Bohan Li, Xin Jin, Hu Zhu, Hongsi Liu, Ruikai Li, Jiazhe Guo, Kaiwen Cai, Chao Ma .etc.|<http://arxiv.org/pdf/2510.22973v1>|[代码](https://github.com/Arlo0o/UniScene-Unified-Occupancy-centric-Driving-Scene-Generation); 提出了大规模语义占据数据集Nuplan-Occ和统一框架，实现了高质量驾驶场景的生成与模拟。|
|📝 更新|GOOD: Training-Free Guided Diffusion Sampling for Out-of-Distribution Detection|无监督引导扩散采样用于分布外检测的免训练方法|Xin Gao, Jiyao Liu, Guanghao Li, Yueming Lyu, Jianxiong Gao, Weichen Yu, Ningsheng Xu, Liang Wang .etc.|<http://arxiv.org/pdf/2510.17131v2>|提出GOOD框架，通过无需训练的引导扩散采样生成多样化离群样本，提升真实场景下的异常检测性能。|
|📝 更新|ControlText: Unlocking Controllable Fonts in Multilingual Text Rendering without Font Annotations|控制文本：在无需字体注释的多语言文本渲染中解锁可控字体|Bowen Jiang, Yuan Yuan, Xinyi Bai, Zhuoqun Hao, Alyson Yin, Yaojie Hu, Wenyu Liao, Lyle Ungar .etc.|<http://arxiv.org/pdf/2502.10999v2>|[代码](https://github.com/bowen-upenn/ControlText.); 提出了一种无需字体标注，利用扩散模型和文本分割技术实现多语言字体可控渲染的方法。|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Track, Inpaint, Resplat: Subject-driven 3D and 4D Generation with Progressive Texture Infilling|“追踪，修复，重绘：基于主题驱动的渐进纹理填充的3D和4D生成”|Shuhong Zheng, Ashkan Mirzaei, Igor Gilitschenski|<http://arxiv.org/pdf/2510.23605v1>|[代码](https://zsh2000.github.io/track-inpaint-resplat.github.io); 提出了一种基于视频跟踪和逐步纹理填充的个性化3D/4D生成方法，有效保持了主体身份一致性。|
|🆕 发布|JanusCoder: Towards a Foundational Visual-Programmatic Interface for Code Intelligence|JanusCoder：迈向代码智能的基础视觉-编程界面|Qiushi Sun, Jingyang Gong, Yang Liu, Qiaosheng Chen, Lei Li, Kai Chen, Qipeng Guo, Ben Kao .etc.|<http://arxiv.org/pdf/2510.23538v1>|[代码](https://github.com/InternLM/JanusCoder.); JanusCoder通过构建大规模多模态代码语料库和统一模型，实现了从文本和视觉输入生成代码的突破性...|
|📝 更新|Integrating Reinforcement Learning with Visual Generative Models: Foundations and Advances|将强化学习与视觉生成模型相结合：基础与进展|Yuanzhi Liang, Yijie Fang, Rui Li, Ziqi Ni, Ruijie Su, Chi Zhang|<http://arxiv.org/pdf/2508.10316v2>|整合强化学习与视觉生成模型，提升生成内容的感知质量与高级目标一致性。|
|📝 更新|Editable Noise Map Inversion: Encoding Target-image into Noise For High-Fidelity Image Manipulation|可编辑噪声图逆向：将目标图像编码入噪声以实现高保真图像操作|Mingyu Kang, Yong Suk Choi|<http://arxiv.org/pdf/2509.25776v3>|提出Editable Noise Map Inversion方法，通过优化噪声图实现图像编辑的高保真...|
|🆕 发布|UniAIDet: A Unified and Universal Benchmark for AI-Generated Image Content Detection and Localization|"UniAIDet：一种统一且通用的AI生成图像内容检测与定位基准"|Huixuan Zhang, Xiaojun Wan|<http://arxiv.org/pdf/2510.23023v1>|提出了UniAIDet，一个全面的图像真伪检测基准，覆盖多种生成模型和图像类型，提升检测方法的泛化能...|
|🆕 发布|VALA: Learning Latent Anchors for Training-Free and Temporally Consistent|VALA：学习潜在锚点以实现无训练和时序一致性|Zhangkai Wu, Xuhui Fan, Zhongyuan Xie, Kaize Shi, Longbing Cao|<http://arxiv.org/pdf/2510.22970v1>|提出VALA方法，通过自适应选择关键帧并压缩其特征，实现了无需训练且时间一致的视频编辑。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Identity-Preserving Text-to-Video Generation Guided by Simple yet Effective Spatial-Temporal Decoupled Representations|保持身份一致性的基于简单而有效的时空解耦表示的文本到视频生成|Yuji Wang, Moran Li, Xiaobin Hu, Ran Yi, Jiangning Zhang, Han Feng, Weijian Cao, Yabiao Wang .etc.|<http://arxiv.org/pdf/2507.04705v3>|[代码](https://github.com/rain152/IPVG.); 提出了一种将空间和时间特征分离的框架，有效解决了文本到视频生成中身份保持与动态实现的矛盾。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MiCADangelo: Fine-Grained Reconstruction of Constrained CAD Models from 3D Scans|米开朗基罗：从三维扫描中重建受约束的精细CAD模型的细节|Ahmet Serdar Karadeniz, Dimitrios Mallis, Danila Rukhovich, Kseniya Cherenkova, Anis Kacem, Djamila Aouada|<http://arxiv.org/pdf/2510.23429v1>|提出了一种结合多平面截面和草图约束的逆向CAD建模方法，实现了精细且可编辑的CAD模型重建。|
|📝 更新|Capture, Canonicalize, Splat: Zero-Shot 3D Gaussian Avatars from Unstructured Phone Images|捕捉、规范、散布：从非结构化手机图像中零样本生成三维高斯头像|Emanuel Garbin, Guy Adam, Oded Krams, Zohar Barzelay, Eran Guendelman, Michael Schwarz, Matteo Presutto, Moran Vatelmacher .etc.|<http://arxiv.org/pdf/2510.14081v3>|提出了一种“捕获、标准化、渲染”新方法，从非结构化手机照片创建超逼真且身份保持的三维头像。|
|🆕 发布|EndoWave: Rational-Wavelet 4D Gaussian Splatting for Endoscopic Reconstruction|内镜重建中的理性小波四维高斯散点绘制：EndoWave|Taoyu Wu, Yiyi Miao, Jiaxin Guo, Ziyan Chen, Sihang Zhao, Zhuoxiao Li, Zhe Tang, Baoru Huang .etc.|<http://arxiv.org/pdf/2510.23087v1>|提出了一种结合光流几何约束和多层理性小波监督的内窥镜视频4D高斯重建框架，显著提升了手术场景的重建质...|
|📝 更新|Image-Plane Geometric Decoding for View-Invariant Indoor Scene Reconstruction|图像平面几何解码用于视点不变室内场景重建|Mingyang Li, Yimeng Fan, Changsong Liu, Lixue Xu, Xin Wang, Yanyan Liu, Wei Zhang|<http://arxiv.org/pdf/2509.25744v2>|提出了一种基于单视图空间信息的解码框架，有效提升了室内场景重建的稳定性和质量。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Representational Difference Explanations|表示差异解释|Neehar Kondapaneni, Oisin Mac Aodha, Pietro Perona|<http://arxiv.org/pdf/2505.23917v2>|提出了一种名为RDX的方法，有效发现并可视化两个学习表征的差异，解决了现有XAI技术在模型比较中的不...|
|🆕 发布|VoMP: Predicting Volumetric Mechanical Property Fields|体机械属性场预测：VoMP|Rishit Dagli, Donglai Xiang, Vismay Modi, Charles Loop, Clement Fuji Tsang, Anka He Chen, Anita Hu, Gavriel State .etc.|<http://arxiv.org/pdf/2510.22975v1>|VoMP通过训练预测3D对象体积的机械属性，实现了快速准确的物理模拟。|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|InFlux: A Benchmark for Self-Calibration of Dynamic Intrinsics of Video Cameras|InFlux：用于视频相机动态内参自校准的基准测试|Erich Liang, Roma Bhattacharjee, Sreemanti Dey, Rafael Moschopoulos, Caitlin Wang, Michel Liao, Grace Tan, Andrew Wang .etc.|<http://arxiv.org/pdf/2510.23589v1>|提出了InFlux基准，为动态相机内参的自校准提供了首个大规模真实世界视频数据集。|
|🆕 发布|Revising Second Order Terms in Deep Animation Video Coding|深度动画视频编码中二阶项的修订|Konstantin Schmidt, Thomas Richter|<http://arxiv.org/pdf/2510.23561v1>|优化了深度动画视频编码中的二阶项，通过全局旋转和稳定训练显著提升了旋转头部视频的编码效率和视觉质量。|
|🆕 发布|VideoTG-R1: Boosting Video Temporal Grounding via Curriculum Reinforcement Learning on Reflected Boundary Annotations|视频TG-R1：通过在反射边界注释上进行课程强化学习提升视频时间定位|Lu Dong, Haiyu Zhang, Han Lin, Ziang Yan, Xiangyu Zeng, Hongjie Zhang, Yifei Huang, Yi Wang .etc.|<http://arxiv.org/pdf/2510.23397v1>|[代码](https://github.com/ldong1111/VideoTG-R1.); 提出了一种基于 curriculum 强化学习和边界反射注释的视频时间定位方法，有效解决了样本质量和...|
|🆕 发布|Evaluation of Vision-LLMs in Surveillance Video|《监控视频中视觉语言模型的评估》|Pascal Benschop, Cristian Meo, Justin Dauwels, Jelte P. Mense|<http://arxiv.org/pdf/2510.23190v1>|[代码](https://github.com/pascalbenschopTU/VLLM_AnomalyRecognition); 探究了视觉语言模型在监控视频中的空间推理能力，通过文本描述和文本蕴含进行零样本异常检测。|
|🆕 发布|FAME: Fairness-aware Attention-modulated Video Editing|FAME：公平感知的注意力调制视频编辑|Zhangkai Wu, Xuhui Fan, Zhongyuan Xie, Kaize Shi, Zhidong Li, Longbing Cao|<http://arxiv.org/pdf/2510.22960v1>|提出FAME方法，通过公平性嵌入和注意力调制减少视频编辑中的职业性别偏见，保持视觉连贯性。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PlanarTrack: A high-quality and challenging benchmark for large-scale planar object tracking|平面追踪：大规模平面对象跟踪的高质量与挑战性基准|Yifan Jiao, Xinran Liu, Xiaoqiong Liu, Xiaohui Yuan, Heng Fan, Libo Zhang|<http://arxiv.org/pdf/2510.23368v1>|[代码](https://github.com/HengLan/PlanarTrack); 提出了PlanarTrack，一个大规模、高质量、具有挑战性的平面目标跟踪基准，以促进平面跟踪领域的...|
|📝 更新|Bootstrapping Referring Multi-Object Tracking|"引导式参照多目标跟踪"|Yani Zhang, Dongming Wu, Wencheng Han, Xingping Dong|<http://arxiv.org/pdf/2406.05039v2>|[代码](https://github.com/zyn213/TempRMOT.); 提出了一种基于语言表达指导的多目标跟踪方法，有效处理了动态对象数量和时序语义的多样性。|
|🆕 发布|HieraMamba: Video Temporal Grounding via Hierarchical Anchor-Mamba Pooling|层次锚点-曼巴池化：通过层次化锚点-曼巴池化实现视频时间定位|Joungbin An, Kristen Grauman|<http://arxiv.org/pdf/2510.23043v1>|提出了一种分层架构HieraMamba，通过多尺度锚点池化实现长视频中的精确时间定位。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FARMER: Flow AutoRegressive Transformer over Pixels|农夫：基于像素的流自动回归变换器|Guangting Zheng, Qinyu Zhao, Tao Yang, Fei Xiao, Zhijie Lin, Jie Wu, Jiajun Deng, Yanyong Zhang .etc.|<http://arxiv.org/pdf/2510.23588v1>|提出了FARMER框架，融合了归一化流和自回归模型，有效解决了视觉像素数据的高维建模问题，实现了高质...|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|EgoThinker: Unveiling Egocentric Reasoning with Spatio-Temporal CoT|自我思考者：揭示以空间时间协同推理为中心的自我中心认知|Baoqi Pei, Yifei Huang, Jilan Xu, Yuping He, Guo Chen, Fei Wu, Yu Qiao, Jiangmiao Pang|<http://arxiv.org/pdf/2510.23569v1>|[代码](https://github.com/InternRobotics/EgoThinker.); 引入EgoThinker框架，通过时空链式思维监督和双阶段学习策略，增强大型语言模型对第一人称视角视...|
|🆕 发布|RobotArena $\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation|机器人竞技场 $\infty$：通过现实到仿真转换的可扩展机器人基准测试|Yash Jangir, Yidi Zhang, Kashu Yamazaki, Chenyu Zhang, Kuan-Hsun Tu, Tsung-Wei Ke, Lei Ke, Yonatan Bisk .etc.|<http://arxiv.org/pdf/2510.23571v1>|提出了一种将真实世界机器人操作视频转化为模拟环境的方法，实现了大规模、可复现的机器人性能评估。|
|🆕 发布|VOLD: Reasoning Transfer from LLMs to Vision-Language Models via On-Policy Distillation|VOLD：通过策略蒸馏从大型语言模型到视觉语言模型的推理迁移|Walid Bousselham, Hilde Kuehne, Cordelia Schmid|<http://arxiv.org/pdf/2510.23497v1>|提出了一种利用大型语言模型推理能力迁移至视觉语言模型的框架VOLD，有效解决了视觉语言模型训练数据稀...|
|🆕 发布|UrbanIng-V2X: A Large-Scale Multi-Vehicle, Multi-Infrastructure Dataset Across Multiple Intersections for Cooperative Perception|"UrbanIng-V2X：一种跨多个交叉口的协同感知大规模多车辆、多基础设施数据集"|Karthikeyan Chandra Sekaran, Markus Geisler, Dominik Rößle, Adithya Mohan, Daniel Cremers, Wolfgang Utschick, Michael Botsch, Werner Huber .etc.|<http://arxiv.org/pdf/2510.23478v1>|UrbanIng-V2X解决了现有数据集单一场景限制问题，创建了跨多个交叉口的车辆与基础设施协同感知...|
|📝 更新|Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy|“精度降低能否提高可靠性？对量化对CLIP准确性之外影响的系统性评估”|Aymen Bouguerra, Daniel Montoya, Alexandra Gomez-Villa, Fabio Arnez, Chokri Mraidha|<http://arxiv.org/pdf/2509.21173v3>|系统评估量化对CLIP模型性能的影响，发现量化可提升某些可靠性指标，挑战效率与性能的传统权衡观念。|
|🆕 发布|DeepSalt: Bridging Laboratory and Satellite Spectra through Domain Adaptation and Knowledge Distillation for Large-Scale Soil Salinity Estimation|深度盐分：通过域适应与知识蒸馏连接实验室与卫星光谱进行大规模土壤盐分估算|Rupasree Dey, Abdul Matin, Everett Lewark, Tanjim Bin Faruk, Andrei Bachinin, Sam Leuthold, M. Francesca Cotrufo, Shrideep Pallickara .etc.|<http://arxiv.org/pdf/2510.23124v1>|提出DeepSalt框架，通过域适应和知识蒸馏将实验室光谱数据转化为卫星光谱，实现大范围土壤盐碱度精...|
|🆕 发布|Fast Voxel-Wise Kinetic Modeling in Dynamic PET using a Physics-Informed CycleGAN|使用物理信息循环生成对抗网络的动态PET中快速体素级动力学建模|Christian Salomonsen, Samuel Kuttner, Michael Kampffmeyer, Robert Jenssen, Kristoffer Wickstrøm, Jong Chul Ye, Elisabeth Wetzer|<http://arxiv.org/pdf/2510.23140v1>|利用物理信息指导的CycleGAN，实现了动态PET中快速准确的动脉输入函数预测。|
|🆕 发布|UGAE: Unified Geometry and Attribute Enhancement for G-PCC Compressed Point Clouds|统一几何与属性增强方法用于G-PCC压缩点云|Pan Zhao, Hui Yuan, Chongzhen Tian, Tian Guo, Raouf Hamzaoui, Zhigeng Pan|<http://arxiv.org/pdf/2510.23009v1>|提出了一种统一几何与属性增强框架UGAE，有效改善了点云压缩中的几何结构和属性信息损失问题。|
|🆕 发布|Switchable Token-Specific Codebook Quantization For Face Image Compression|可切换的标记特定码本量化用于人脸图像压缩|Yongbo Wang, Haonan Wang, Guodong Mu, Ruixin Zhang, Jiaqi Chen, Jingyun Zhang, Jun Wang, Yuan Xie .etc.|<http://arxiv.org/pdf/2510.22943v1>|提出了一种针对面部图像的切换式独立码本量化方法，通过为不同图像类别学习独立码本，提高了低比特率下的重...|
|🆕 发布|Gen-LangSplat: Generalized Language Gaussian Splatting with Pre-Trained Feature Compression|《Gen-LangSplat: 预训练特征压缩的广义语言高斯散点绘制》|Pranav Saxena|<http://arxiv.org/pdf/2510.22930v1>|提出了一种通用预训练的自动编码器替代特定场景训练，提升了3D场景语言字段建模的效率和性能。|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Video-Thinker: Sparking "Thinking with Videos" via Reinforcement Learning|视频思考者：通过强化学习激发“以视频思考”|Shijian Wang, Jiarui Jin, Xingjian Wang, Linxin Song, Runhao Fu, Hecheng Wang, Zongyuan Ge, Yuan Lu .etc.|<http://arxiv.org/pdf/2510.23473v1>|提出Video-Thinker，通过强化学习使多模态大语言模型能自主处理视频推理任务，实现性能显著提...|
|🆕 发布|VR-Drive: Viewpoint-Robust End-to-End Driving with Feed-Forward 3D Gaussian Splatting|VR-Drive：基于前向3D高斯散点投射的视点鲁棒端到端驾驶|Hoonhee Cho, Jae-Young Kang, Giwon Lee, Hyemin Yang, Heejun Park, Seokwoo Jung, Kuk-Jin Yoon|<http://arxiv.org/pdf/2510.23205v1>|提出VR-Drive框架，通过3D场景重建和视图合成增强视角泛化，提升端到端自动驾驶系统的鲁棒性。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Seeing Structural Failure Before it Happens: An Image-Based Physics-Informed Neural Network (PINN) for Spaghetti Bridge Load Prediction|在事故发生之前预见结构失效：一种基于图像的物理信息神经网络（PINN）用于意大利面桥负载预测|Omer Jauhar Khan, Sudais Khan, Hafeez Anwar|<http://arxiv.org/pdf/2510.23117v1>|[代码](https://github.com/OmerJauhar/PINNS-For-Spaghetti-Bridges.); 提出物理约束的神经网络模型PIKAN，用于预测小型意大利面桥的承重，实现高准确度预测。|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Now you see me! Attribution Distributions Reveal What is Truly Important for a Prediction|“现在你看到了！归因分布揭示了预测中真正重要的因素”|Nils Philipp Walter, Jilles Vreeken, Jonas Fischer|<http://arxiv.org/pdf/2503.07346v2>|[代码](https://github.com/nilspwalter/var.); 提出了一种新的归因方法，通过计算多类别的归因分布，提高了神经网络的决策透明度和特异性。|
|🆕 发布|Localising under the drape: proprioception in the era of distributed surgical robotic system|在帷幕下定位：分布式手术机器人系统时代的本体感知|Martin Huber, Nicola A. Cavalcanti, Ayoob Davoodi, Ruixuan Li, Christopher E. Mower, Fabio Carrillo, Christoph J. Laux, Francois Teyssere .etc.|<http://arxiv.org/pdf/2510.23512v1>|提出了一种无标记的机器人定位方法，通过轻量级相机和深度学习模型，实现了手术机器人在遮挡环境下的精准定...|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Generalization Bounds for Robust Contrastive Learning: From Theory to Practice|《稳健对比学习的泛化界限：从理论到实践》|Ngoc N. Tran, Lam Tran, Hoang Phan, Anh Bui, Tung Pham, Toan Tran, Dinh Phung, Trung Le|<http://arxiv.org/pdf/2311.09671v2>|提出理论框架分析对抗性对比学习的稳健性，揭示无监督训练中提升稳健性的关键因素。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial Representations|协奏曲：二维-三维自监督学习涌现空间表征|Yujia Zhang, Xiaoyang Wu, Yixing Lao, Chengyao Wang, Zhuotao Tian, Naiyan Wang, Hengshuang Zhao|<http://arxiv.org/pdf/2510.23607v1>|Concerto通过结合2D-3D跨模态联合嵌入和3D intra-modal自蒸馏，学习到更一致且...|
|🆕 发布|T-REGS: Minimum Spanning Tree Regularization for Self-Supervised Learning|T-REGS：最小生成树正则化用于自监督学习|Julie Mordacq, David Loiseaux, Vicky Kalogeiton, Steve Oudot|<http://arxiv.org/pdf/2510.23484v1>|引入了基于最小生成树长度的T-REGS正则化框架，有效避免特征维度崩溃并提升分布均匀性，增强无监督学...|
|🆕 发布|Symmetria: A Synthetic Dataset for Learning in Point Clouds|对称性：一个用于点云学习的合成数据集|Ivan Sipiran, Gustavo Santelices, Lucas Oyarzún, Andrea Ranieri, Chiara Romanengo, Silvia Biasotti, Bianca Falcidieno|<http://arxiv.org/pdf/2510.23414v1>|提出了Symmetria合成数据集，通过利用对称性原理，有效解决了点云学习领域数据不足的问题。|
|📝 更新|RotaTouille: Rotation Equivariant Deep Learning for Contours|《RotaTouille：用于轮廓的旋转等变深度学习》|Odin Hoff Gardaa, Nello Blaser|<http://arxiv.org/pdf/2508.16359v2>|提出了一种使深度学习模型对旋转和平移具有不变性的方法，通过复数圆卷积处理轮廓数据。|
|🆕 发布|MDReID: Modality-Decoupled Learning for Any-to-Any Multi-Modal Object Re-Identification|MDReID：模态解耦学习用于任意到任意多模态目标重识别|Yingying Feng, Jie Li, Jie Hu, Yukang Zhang, Lei Tan, Jiayi Ji|<http://arxiv.org/pdf/2510.23301v1>|[代码](https://github.com/stone96123/MDReID); 提出MDReID框架，通过解耦模态特征实现任意模态间物体重识别，提升跨模态检索性能。|
|📝 更新|First SFT, Second RL, Third UPT: Continual Improving Multi-Modal LLM Reasoning via Unsupervised Post-Training|首步SFT，次步RL，三步UPT：通过无监督后训练持续提升多模态LLM推理能力|Lai Wei, Yuting Li, Chen Wang, Yue Wang, Linghe Kong, Weiran Huang, Lichao Sun|<http://arxiv.org/pdf/2505.22453v2>|[代码](https://github.com/waltonfuture/MM-UPT.); 提出无监督后训练框架MM-UPT，实现多模态大语言模型的持续自我提升，无需外部监督数据。|
|📝 更新|KAN or MLP? Point Cloud Shows the Way Forward|“KAN还是MLP？点云指明前进之路”|Yan Shi, Qingdong He, Yijun Liu, Xiaoyu Liu, Jingyong Su|<http://arxiv.org/pdf/2504.13593v4>|提出PointKAN模型，利用Kolmogorov-Arnold Networks提升点云特征表示，...|
|🆕 发布|Strategies for Robust Deep Learning Based Deformable Registration|《基于深度学习的鲁棒性形变配准策略》|Joel Honkamaa, Pekka Marttinen|<http://arxiv.org/pdf/2510.23079v1>|提出了一种将图像转换至MIND特征空间并采用特殊集成策略的深度学习变形配准方法，显著增强了模型在训练...|
|📝 更新|TokenCLIP: Token-wise Prompt Learning for Zero-shot Anomaly Detection|《TokenCLIP：基于Token的提示学习用于零样本异常检测》|Qihang Zhou, Binbin Gao, Guansong Pang, Xin Wang, Jiming Chen, Shibo He|<http://arxiv.org/pdf/2510.21171v2>|TokenCLIP通过为每个视觉标记定制文本子空间，实现了细粒度异常检测的动态对齐和优化。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Seq-DeepIPC: Sequential Sensing for End-to-End Control in Legged Robot Navigation|序列深度IPC：用于四足机器人导航端到端控制的顺序感知|Oskar Natan, Jun Miura|<http://arxiv.org/pdf/2510.23057v1>|[代码](https://github.com/oskarnatan/Seq-DeepIPC.); Seq-DeepIPC通过融合多模态感知与控制，提升了四足机器人实时导航的感知与决策能力。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|PRISM-Bench: A Benchmark of Puzzle-Based Visual Tasks with CoT Error Detection|基于谜题的视觉任务基准测试与协同推理错误检测的PRISM-Bench|Yusu Qian, Cheng Wan, Chao Jia, Yinfei Yang, Qingyu Zhao, Zhe Gan|<http://arxiv.org/pdf/2510.23594v1>|提出PRISM-Bench，一种评估视觉推理和错误检测能力的拼图基准，挑战模型逻辑一致性。|
|🆕 发布|MergeMix: A Unified Augmentation Paradigm for Visual and Multi-Modal Understanding|MergeMix：用于视觉与多模态理解的统一增强范式|Xin Jin, Siyuan Li, Siyong Jian, Kai Yu, Huan Wang|<http://arxiv.org/pdf/2510.23479v1>|提出了一种融合视觉与多模态理解的统一增强方法MergeMix，有效平衡了大规模模型训练中的可扩展性、...|
|🆕 发布|On the Faithfulness of Visual Thinking: Measurement and Enhancement|关于视觉思维忠实度的测量与增强|Zujing Liu, Junwen Pan, Qi She, Yuan Gao, Guisong Xia|<http://arxiv.org/pdf/2510.23482v1>|[代码](https://github.com/EugeneLiu01/Faithful_Thinking_with_Image.); 提出方法增强视觉推理准确性，通过自动评估和优化视觉信息可靠性及充分性。|
|📝 更新|AlignCAT: Visual-Linguistic Alignment of Category and Attribute for Weakly Supervised Visual Grounding|《AlignCAT：类别与属性弱监督视觉定位的视觉-语言对齐》|Yidan Wang, Chenyi Zhuang, Wutao Liu, Pan Gao, Nicu Sebe|<http://arxiv.org/pdf/2508.03201v3>|[代码](https://github.com/I2-Multimedia-Lab/AlignCAT.); 提出AlignCAT框架，通过 coarse-grained 和 fine-grained 对齐模块...|
|📝 更新|GRE Suite: Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains|GRE 套件：通过微调视觉-语言模型和增强推理链进行地理定位推断|Chun Wang, Xiaojun Ye, Xiaoran Pan, Zihao Pan, Haofan Wang, Yiren Song|<http://arxiv.org/pdf/2505.18700v4>|[代码](https://github.com/Thorin215/GRE.); 提出GRE Suite框架，结合细粒度视觉和世界知识推理链，显著提升地理定位准确性和解释性。|
|🆕 发布|A Video Is Not Worth a Thousand Words|一段视频的价值不及一千个字|Sam Pollard, Michael Wray|<http://arxiv.org/pdf/2510.23253v1>|[代码](https://github.com/sjpollard/a-video-is-not-worth-a-thousand-words.); 提出了一种基于Shapley值的特征归因和模态评分方法，揭示了视频问答模型对文本的过度依赖。|
|📝 更新|UniPixel: Unified Object Referring and Segmentation for Pixel-Level Visual Reasoning|统一像素级对象指引用与分割：面向像素级视觉推理|Ye Liu, Zongyang Ma, Junfu Pu, Zhongang Qi, Yang Wu, Ying Shan, Chang Wen Chen|<http://arxiv.org/pdf/2509.18094v3>|提出UniPixel模型，实现了像素级视觉理解与语言语义的统一处理，提升了细粒度视觉推理能力。|
|📝 更新|CXReasonBench: A Benchmark for Evaluating Structured Diagnostic Reasoning in Chest X-rays|CXReasonBench：一个用于评估胸部X射线结构化诊断推理的基准|Hyungyung Lee, Geon Choi, Jung-Oh Lee, Hangyul Yoon, Hyuk Gi Hong, Edward Choi|<http://arxiv.org/pdf/2505.18087v2>|[代码](https://github.com/ttumyche/CXReasonBench); 提出CheXStruct和CXReasonBench，用于评估模型在胸片诊断中的结构化推理能力。|
|📝 更新|Task-Oriented Feature Compression for Multimodal Understanding via Device-Edge Co-Inference|面向任务的特性压缩以实现多模态理解通过设备边缘协同推断|Cheng Yuan, Zhening Liu, Jiashu Lv, Jiawei Shao, Yufei Jiang, Jun Zhang, Xuelong Li|<http://arxiv.org/pdf/2503.12926v3>|提出了一种针对边缘设备计算限制的任务导向特征压缩方法，有效降低了数据传输和计算延迟。|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|An Intelligent Water-Saving Irrigation System Based on Multi-Sensor Fusion and Visual Servoing Control|基于多传感器融合与视觉伺服控制的智能节水灌溉系统|ZhengKai Huang, YiKun Wang, ChenYu Hui, XiaoCheng|<http://arxiv.org/pdf/2510.23003v1>|该研究开发了一种融合多传感器和视觉伺服的智能节水灌溉系统，有效应对精准农业中的水资源浪费和地形适应性...|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|iPac: Incorporating Intra-image Patch Context into Graph Neural Networks for Medical Image Classification|iPac: 将图像内补丁上下文融入图神经网络进行医学图像分类|Usama Zidan, Mohamed Gaber, Mohammed M. Abdelsamea|<http://arxiv.org/pdf/2510.23504v1>|提出方法iPac，通过构建图像内部结构关系的图表示，提升了医疗图像分类的准确度。|
|📝 更新|RWKV-UNet: Improving UNet with Long-Range Cooperation for Effective Medical Image Segmentation|RWKV-UNet：通过长距离协作改进UNet以实现高效的医学图像分割|Juntao Jiang, Jiangning Zhang, Weixuan Liu, Muxuan Gao, Xiaobin Hu, Zhucun Xue, Yong Liu, Shuicheng Yan|<http://arxiv.org/pdf/2501.08458v3>|提出RWKV-UNet模型，结合CNN与RWKV结构，有效提升医学图像分割的长距离依赖捕捉能力。|
|🆕 发布|CURVETE: Curriculum Learning and Progressive Self-supervised Training for Medical Image Classification|CURVETE：基于课程学习和渐进式自监督训练的医疗图像分类|Asmaa Abbas, Mohamed Gaber, Mohammed M. Abdelsamea|<http://arxiv.org/pdf/2510.23442v1>|提出CURVETE模型，通过逐步自监督训练和课程学习策略，有效应对医学图像分类中的样本不足和类别分布...|
|📝 更新|Med-R1: Reinforcement Learning for Generalizable Medical Reasoning in Vision-Language Models|Med-R1：用于视觉语言模型中泛化医疗推理的强化学习|Yuxiang Lai, Jike Zhong, Ming Li, Shitian Zhao, Yuheng Li, Konstantinos Psounis, Xiaofeng Yang|<http://arxiv.org/pdf/2503.13939v5>|提出Med-R1模型，利用强化学习提升医学视觉问答的泛化能力和可靠性。|
|🆕 发布|Multitask Multimodal Self-Supervised Learning for Medical Images|多任务多模态自监督医学图像学习|Cristian Simionescu|<http://arxiv.org/pdf/2510.23325v1>|提出了一种多任务多模态自监督学习方法，通过Medformer网络减少对大量标注数据的依赖，提高医疗图...|
|🆕 发布|Interpretable Tile-Based Classification of Paclitaxel Exposure|基于瓦片的可解释性紫杉醇暴露分类|Sean Fletcher, Gabby Scott, Douglas Currie, Xin Zhang, Yuqi Song, Bruce MacLeod|<http://arxiv.org/pdf/2510.23363v1>|提出了一种基于图像分块和聚合的药物暴露分类方法，提高了准确度并增强了模型可解释性。|
|🆕 发布|Progressive Growing of Patch Size: Curriculum Learning for Accelerated and Improved Medical Image Segmentation|逐步增长补丁大小：用于加速和改善医学图像分割的教程学习法|Stefan M. Fischer, Johannes Kiechle, Laura Daza, Lina Felsner, Richard Osuala, Daniel M. Lang, Karim Lekadir, Jan C. Peeken .etc.|<http://arxiv.org/pdf/2510.23241v1>|提出了一种逐步增加图像块大小的教学方法，有效提升了医学图像分割的性能并缩短了训练时间。|
|📝 更新|3D-RAD: A Comprehensive 3D Radiology Med-VQA Dataset with Multi-Temporal Analysis and Diverse Diagnostic Tasks|三维RAD：一个具有多时间分析及多样化诊断任务的综合三维放射学医疗视觉问答数据集|Xiaotang Gai, Jiaxiang Liu, Yichen Li, Zijie Meng, Jian Wu, Zuozhu Liu|<http://arxiv.org/pdf/2506.11147v2>|[代码](https://github.com/Tang-xiaoxiao/3D-RAD.); 提出了3D-RAD数据集，扩展了3D医疗视觉问答研究，包含多种诊断任务，提升模型在复杂医疗推理中的性...|
|📝 更新|A Novel Multi-branch ConvNeXt Architecture for Identifying Subtle Pathological Features in CT Scans|一种新颖的多分支ConvNeXt架构用于识别CT扫描中的细微病理特征|Irash Perera, Uthayasanker Thayasivam|<http://arxiv.org/pdf/2510.09107v2>|提出了一种多分支ConvNeXt架构，通过精细数据预处理和独特的三并行特征提取，显著提升了CT扫描中...|
|🆕 发布|LoMix: Learnable Weighted Multi-Scale Logits Mixing for Medical Image Segmentation|LoMix: 医学图像分割的可学习加权多尺度逻辑混合|Md Mostafijur Rahman, Radu Marculescu|<http://arxiv.org/pdf/2510.22995v1>|[代码](https://github.com/SLDGroup/LoMix.); 提出了一种可学习权重多尺度融合策略LoMix，有效提升了医学图像分割的准确性和数据效率。|
|📝 更新|Enhancing Feature Fusion of U-like Networks with Dynamic Skip Connections|增强U型网络的特征融合：动态跳跃连接优化|Yue Cao, Quansong He, Kaishen Wang, Jianlong Xiong, Zhang Yi, Tao He|<http://arxiv.org/pdf/2509.14610v4>|提出动态跳跃连接方法，通过自适应机制增强特征融合，提升医学图像分割效果。|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Quality-controlled registration of urban MLS point clouds reducing drift effects by adaptive fragmentation|城市MLS点云的质量控制注册：通过自适应分割减少漂移效应|Marco Antonio Ortiz Rincon, Yihui Yang, Christoph Holst|<http://arxiv.org/pdf/2510.23416v1>|提出了一种针对城市环境的MLS点云高效精准配准方法，通过自适应分片和改进的迭代最近点算法显著减少漂移...|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|An Efficient Remote Sensing Super Resolution Method Exploring Diffusion Priors and Multi-Modal Constraints for Crop Type Mapping|一种探索扩散先验与多模态约束的高效遥感超分辨率方法用于作物类型制图|Songxi Yang, Tang Sui, Qunying Huang|<http://arxiv.org/pdf/2510.23382v1>|提出了一种高效的远程遥感超分辨率方法，利用扩散先验和多模态约束提升作物类型映射精度。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FRBNet: Revisiting Low-Light Vision through Frequency-Domain Radial Basis Network|FRBNet：通过频域径向基网络重新审视低光照视觉|Fangtong Sun, Congyu Li, Ke Yang, Yuchen Pan, Hanwen Yu, Xichuan Zhang, Yiying Li|<http://arxiv.org/pdf/2510.23444v1>|[代码](https://github.com/Sing-Forevet/FRBNet.); 提出了一种频率域径向基网络FRBNet，通过提取光照不变特征显著提升了低光照条件下的图像处理性能。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Note on the Construction of Structure Tensor|关于结构张量构造的注记|Josef Bigun, Fernado Alonso-Fernandez|<http://arxiv.org/pdf/2510.23137v1>|将两种结构张量构建方法统一于总最小二乘法框架下，简化了张量解释并扩展了适用滤波器类型。|
|📝 更新|FaceTracer: Unveiling Source Identities from Swapped Face Images and Videos for Fraud Prevention|《FaceTracer：从交换人脸图像和视频中揭示源身份以预防欺诈》|Zhongyi Zhang, Jie Zhang, Wenbo Zhou, Xinghui Zhou, Qing Guo, Weiming Zhang, Tianwei Zhang, Nenghai Yu|<http://arxiv.org/pdf/2412.08082v2>|[代码](https://github.com/zzy224/FaceTracer.); 提出FaceTracer框架，通过分离源身份特征追踪换脸图像背后的原始个体，有效预防欺诈行为。|
|📝 更新|BCR-Net: Boundary-Category Refinement Network for Weakly Semi-Supervised X-Ray Prohibited Item Detection with Points|BCR-Net：基于边界-类别细化网络的弱半监督X射线禁运物品检测点方法|Sanjoeng Wong|<http://arxiv.org/pdf/2412.18918v2>|提出BCR-Net网络，通过少量框标注和大量点标注实现精确的X射线违禁品检测。|
|📝 更新|Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular Videos|从散焦和运动模糊的单目视频中动态高斯散点渲染|Xuankai Zhang, Junjin Xiao, Qing Zhang|<http://arxiv.org/pdf/2510.10691v2>|[代码](https://github.com/hhhddddddd/dydeblur); 提出了一种统一框架，通过利用场景和相机信息估计可靠模糊核，实现了从模糊和运动模糊的单目视频生成高质量...|

