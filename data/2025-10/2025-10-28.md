## [UPDATED!] **2025-10-28** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Does Object Binding Naturally Emerge in Large Pretrained Vision Transformers?|物体绑定是否会在大型预训练视觉变换器中自然涌现？|Yihao Li, Saeed Salehi, Lyle Ungar, Konrad P. Kording|<http://arxiv.org/pdf/2510.24709v1>|发现Vision Transformers通过特定预训练目标自然习得对象绑定能力，提升模型性能。|
|📝 更新|Frequency-Aware Vision Transformers for High-Fidelity Super-Resolution of Earth System Models|频率感知视觉变换器用于地球系统模型的高保真超分辨率重建|Ehsan Zeraatkar, Salah A Faroughi, Jelena Tešić|<http://arxiv.org/pdf/2502.12427v4>|提出频率感知的视觉变换器框架，有效提升地球系统模型输出的超分辨率重建质量。|


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs|潜在画板：通过绘制视觉思维来激发多模态推理在大规模语言模型中的应用|Huanyu Zhang, Wenshan Wu, Chengzu Li, Ning Shang, Yan Xia, Yangyu Huang, Yifan Zhang, Li Dong .etc.|<http://arxiv.org/pdf/2510.24514v1>|[代码](https://latent-sketchpad.github.io/.); 提出了一种名为Latent Sketchpad的框架，使多模态大语言模型具备生成视觉思维的能力，从而...|
|📝 更新|Mano Technical Report|《手部技术报告》|Tianyu Fu, Anyang Su, Chenxu Zhao, Hanning Wang, Minghui Wu, Zhe Yu, Fei Hu, Mingjia Shi .etc.|<http://arxiv.org/pdf/2509.17336v2>|提出了一种结合多模态基础模型和强化学习的GUI自动化方法，显著提升了交互成功率和操作准确性。|
|📝 更新|Look and Tell: A Dataset for Multimodal Grounding Across Egocentric and Exocentric Views|“查看并讲述：一个用于自我中心与外部中心视角多模态定位的数据集”|Anna Deichler, Jonas Beskow|<http://arxiv.org/pdf/2510.22672v2>|构建了一个多模态数据集，研究第一人称和第三人称视角下参考沟通的差异，推动Embodied AI发展。|
|📝 更新|LiDAR Remote Sensing Meets Weak Supervision: Concepts, Methods, and Perspectives|激光雷达遥感遇见弱监督：概念、方法与展望|Yuan Gao, Shaobo Xia, Pu Wang, Xiaohuan Xi, Sheng Nie, Cheng Wang|<http://arxiv.org/pdf/2503.18384v2>|将弱监督学习应用于LiDAR遥感，降低标注成本并提升时空适应性。|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|OmniResponse: Online Multimodal Conversational Response Generation in Dyadic Interactions|全方位响应：二人互动中的在线多模态对话回应生成|Cheng Luo, Jianghui Wang, Bing Li, Siyang Song, Bernard Ghanem|<http://arxiv.org/pdf/2505.21724v2>|提出在线多模态对话响应生成任务，通过OmniResponse模型同步生成语音和非语言反馈，提升多模态...|
|🆕 发布|Rethinking Visual Intelligence: Insights from Video Pretraining|重新思考视觉智能：视频预训练的洞见|Pablo Acuaviva, Aram Davtyan, Mariam Hassan, Sebastian Stapf, Ahmad Rahimi, Alexandre Alahi, Paolo Favaro|<http://arxiv.org/pdf/2510.24448v1>|探究视频预训练模型以提升视觉任务适应性和数据效率。|
|📝 更新|Detecting Latin in Historical Books with Large Language Models: A Multimodal Benchmark|利用大型语言模型检测历史书籍中的拉丁文：一种多模态基准|Yu Wu, Ke Shu, Jonas Fischer, Lidia Pivovarova, David Rosson, Eetu Mäkelä, Mikko Tolonen|<http://arxiv.org/pdf/2510.19585v2>|提出了一种利用大型语言模型从混合语言历史文档中提取拉丁文片段的新方法，并验证了其有效性。|
|🆕 发布|SCOPE: Saliency-Coverage Oriented Token Pruning for Efficient Multimodel LLMs|SCOPE：面向显著性和覆盖率的标记剪枝以提高多模态大型语言模型的效率|Jinhong Deng, Wen Li, Joey Tianyi Zhou, Yang He|<http://arxiv.org/pdf/2510.24214v1>|[代码](https://github.com/kinredon/SCOPE); 提出了一种视觉token剪枝策略SCOPE，通过结合显著性和覆盖度，有效保留了多模态大语言模型中的语...|
|📝 更新|CPathAgent: An Agent-based Foundation Model for Interpretable High-Resolution Pathology Image Analysis Mimicking Pathologists' Diagnostic Logic|CPathAgent：一种模仿病理医生诊断逻辑的可解释高分辨率病理图像分析基于代理的基石模型|Yuxuan Sun, Yixuan Si, Chenglu Zhu, Kai Zhang, Zhongyi Shui, Bowen Ding, Tao Lin, Lin Yang|<http://arxiv.org/pdf/2505.20510v2>|提出了一种模仿病理医生诊断逻辑的CPathAgent模型，通过自主导航全切片图像生成透明且可解释的诊...|
|🆕 发布|DogMo: A Large-Scale Multi-View RGB-D Dataset for 4D Canine Motion Recovery|犬类运动恢复的大规模多视角RGB-D数据集：DogMo|Zan Wang, Siyu Chen, Luya Mo, Xinfeng Gao, Yuxin Shen, Lebin Ding, Wei Liang|<http://arxiv.org/pdf/2510.24117v1>|提出大规模多视角RGB-D犬类运动数据集DogMo，并建立三阶段优化流程以实现精确运动恢复。|
|🆕 发布|Mars-Bench: A Benchmark for Evaluating Foundation Models for Mars Science Tasks|火星基准：用于评估面向火星科学任务的基石模型的基准测试|Mirali Purohit, Bimal Gajera, Vatsal Malaviya, Irish Mehta, Kunal Kasodekar, Jacob Adler, Steven Lu, Umaa Rebbapragada .etc.|<http://arxiv.org/pdf/2510.24010v1>|[代码](https://mars-bench.github.io/.); 提出了Mars-Bench，首个用于系统评估火星科学任务基础模型的标准化基准，涵盖多种火星地质特征任...|
|📝 更新|Boosting Omnidirectional Stereo Matching with a Pre-trained Depth Foundation Model|使用预训练深度基础模型提升全向立体匹配性能|Jannik Endres, Oliver Hahn, Charles Corbière, Simone Schaub-Meyer, Stefan Roth, Alexandre Alahi|<http://arxiv.org/pdf/2503.23502v3>|提出了一种利用预训练深度基础模型的全方位立体匹配方法，显著提升了不同环境下深度估计的准确性。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|GroundLoc: Efficient Large-Scale Outdoor LiDAR-Only Localization|地面定位：高效的大规模室外仅LiDAR定位|Nicolai Steinke, Daniel Goehring|<http://arxiv.org/pdf/2510.24623v1>|[代码](https://github.com/dcmlr/groundloc.); 提出GroundLoc方法，利用激光雷达和鸟瞰图投影实现高效的大规模室外机器人定位。|
|📝 更新|Superpowering Open-Vocabulary Object Detectors for X-ray Vision|赋予开放式词汇对象检测器X射线视觉的超级能力|Pablo Garcia-Fernandez, Lorenzo Vaquero, Mingxuan Liu, Feng Xue, Daniel Cores, Nicu Sebe, Manuel Mucientes, Elisa Ricci|<http://arxiv.org/pdf/2503.17071v2>|[代码](https://github.com/PAGF188/RAXO.); 提出RAXO框架，通过无需训练的方式将RGB对象检测器应用于X射线成像，显著提升开放词汇对象检测性能...|
|📝 更新|Multispectral State-Space Feature Fusion: Bridging Shared and Cross-Parametric Interactions for Object Detection|多光谱状态空间特征融合：桥接共享与交叉参数交互以实现目标检测|Jifeng Shen, Haibo Zhan, Shaohua Dong, Xin Zuo, Wankou Yang, Haibin Ling|<http://arxiv.org/pdf/2507.14643v2>|[代码](https://github.com/61s61min/MS2Fusion.git.); 提出MS2Fusion框架，通过双路径参数交互机制有效融合多光谱特征，提升物体检测性能。|
|🆕 发布|Delving into Cascaded Instability: A Lipschitz Continuity View on Image Restoration and Object Detection Synergy|深入探究级联不稳定性：从Lipschitz连续性视角看图像恢复与目标检测协同|Qing Zhao, Weijian Deng, Pengxu Wei, ZiYi Dong, Hannan Lu, Xiangyang Ji, Liang Lin|<http://arxiv.org/pdf/2510.24232v1>|提出了一种结合Lipschitz正则化的对象检测框架，有效解决了图像复原与检测间的功能不匹配问题，提...|
|📝 更新|Long-RVOS: A Comprehensive Benchmark for Long-term Referring Video Object Segmentation|长期视频目标分割的全面基准：Long-RVOS|Tianming Liang, Haichao Jiang, Yuting Yang, Chaolei Tan, Shuai Li, Wei-Shi Zheng, Jian-Fang Hu|<http://arxiv.org/pdf/2505.12702v2>|提出了Long-RVOS长视频对象分割基准，并引入了ReferMo方法，提升长视频场景下的分割性能。|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DWaste: Greener AI for Waste Sorting using Mobile and Edge Devices|DWaste：利用移动和边缘设备进行垃圾分类的绿色AI|Suman Kunwar|<http://arxiv.org/pdf/2510.18513v2>|开发DWaste平台，利用轻量级计算机视觉模型实现移动和边缘设备上的实时废物分类，提升效率并降低能耗...|
|🆕 发布|A Critical Study towards the Detection of Parkinsons Disease using ML Technologies|面向帕金森病检测的机器学习技术应用关键研究|Vivek Chetia, Abdul Taher Khan, Rahish Gogoi, David Kapsian Khual, Purnendu Bikash, Sajal Saha|<http://arxiv.org/pdf/2510.24456v1>|提出了一种基于深度学习的茶叶病害检测方法，通过SSD MobileNet V2和Faster R-C...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|XAI Evaluation Framework for Semantic Segmentation|用于语义分割的可解释性评估框架|Reem Hammoud, Abdul karim Gizzini, Ali J. Ghandour|<http://arxiv.org/pdf/2510.24414v1>|提出了一种针对语义分割的XAI评估框架，实现了对解释性人工智能方法的细致评价与优化。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Stroke Lesion Segmentation in Clinical Workflows: A Modular, Lightweight, and Deployment-Ready Tool|临床工作流程中的中风病变分割：一种模块化、轻量化和部署就绪的工具|Yann Kerverdo, Florent Leray, Youwan Mahé, Stéphanie Leplaideur, Francesca Galassi|<http://arxiv.org/pdf/2510.24378v1>|提出了一种模块化、轻量化的脑卒中病变分割工具StrokeSeg，实现了研究级模型到临床应用的转换。|


## 生成式视觉模型 (Generative Visual Modeling)


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Uniform Discrete Diffusion with Metric Path for Video Generation|统一度量路径的均匀离散扩散视频生成方法|Haoge Deng, Ting Pan, Fan Zhang, Yang Liu, Zhuoyan Luo, Yufeng Cui, Wenxuan Wang, Chunhua Shen .etc.|<http://arxiv.org/pdf/2510.24717v1>|[代码](https://github.com/baaivision/URSA); 提出了一种名为URSA的离散生成模型，通过迭代全局优化离散时空标记，有效弥补了与连续方法在视频生成方...|
|🆕 发布|Generative View Stitching|生成视图拼接|Chonghyuk Song, Michal Stary, Boyuan Chen, George Kopanas, Vincent Sitzmann|<http://arxiv.org/pdf/2510.24718v1>|[代码](https://andrewsonga.github.io/gvs.); 提出Generative View Stitching算法，通过并行采样实现稳定、无碰撞、帧间一致的...|
|🆕 发布|A Dual-Branch CNN for Robust Detection of AI-Generated Facial Forgeries|一种双分支卷积神经网络用于稳健检测人工智能生成的面部伪造品|Xin Zhang, Yuqi Song, Fei Zuo|<http://arxiv.org/pdf/2510.24640v1>|提出了一种双分支卷积神经网络，通过融合空间域和频率域信息，有效检测AI生成的面部伪造图像。|
|🆕 发布|OSWorld-MCP: Benchmarking MCP Tool Invocation In Computer-Use Agents|OSWorld-MCP：计算机使用代理中MCP工具调用的基准测试|Hongrui Jia, Jitong Liao, Xi Zhang, Haiyang Xu, Tianbao Xie, Chaoya Jiang, Ming Yan, Si Liu .etc.|<http://arxiv.org/pdf/2510.24563v1>|提出首个公平全面的OSWorld-MCP基准，评估计算机使用代理的工具调用和决策能力。|
|🆕 发布|Decoupled MeanFlow: Turning Flow Models into Flow Maps for Accelerated Sampling|解耦均值流：将流模型转化为流图以加速采样|Kyungmin Lee, Sihyun Yu, Jinwoo Shin|<http://arxiv.org/pdf/2510.24474v1>|提出了一种无需修改架构的Decoupled MeanFlow方法，将流模型转化为流图模型，大幅加速了...|
|🆕 发布|Local Performance vs. Out-of-Distribution Generalization: An Empirical Analysis of Personalized Federated Learning in Heterogeneous Data Environments|局部性能与分布外泛化：异质数据环境下个性化联邦学习的实证分析|Mortesa Hussaini, Jan Theiß, Anthony Stein|<http://arxiv.org/pdf/2510.24503v1>|分析了个性化联邦学习在异质数据环境下的本地性能与泛化能力，并提出了一种改进的联邦平均算法以增强模型泛...|
|📝 更新|LongCat-Video Technical Report|《LongCat-Video技术报告》|Meituan LongCat Team, Xunliang Cai, Qilong Huang, Zhuoliang Kang, Hongyu Li, Shijun Liang, Liya Ma, Siyu Ren .etc.|<http://arxiv.org/pdf/2510.22200v2>|提出了一种大型视频生成模型LongCat-Video，实现了高效且高质量的长视频生成。|
|🆕 发布|Deeply-Conditioned Image Compression via Self-Generated Priors|通过自生成先验进行深度条件图像压缩|Zhineng Zhao, Zhihai He, Zikun Zhou, Siwei Ma, Yaowei Wang|<http://arxiv.org/pdf/2510.24437v1>|提出了一种基于功能分解的图像压缩框架，通过自生成先验有效减轻低比特率下的几何变形问题。|
|🆕 发布|GenTrack: A New Generation of Multi-Object Tracking|《GenTrack：新一代多目标跟踪》|Toan Van Nguyen, Rasmus G. K. Christiansen, Dirk Kraft, Leon Bodenhagen|<http://arxiv.org/pdf/2510.24399v1>|[代码](https://github.com/SDU-VelKoTek/GenTrack); GenTrack通过结合随机与确定性策略，有效处理动态目标数量和社交交互，提升了多目标跟踪的准确性和...|
|🆕 发布|Training-free Source Attribution of AI-generated Images via Resynthesis|无训练的AI生成图像来源归因通过重合成|Pietro Bongini, Valentina Molinari, Andrea Costanzo, Benedetta Tondi, Mauro Barni|<http://arxiv.org/pdf/2510.24278v1>|提出了一种无需训练的基于图像重合成的单次源归属方法，有效应对少量样本训练挑战。|
|🆕 发布|ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model|ViPER：赋予视觉语言模型视觉感知能力自我进化的能力|Juntian Zhang, Song Jin, Chuanqi Cheng, Yuhan Liu, Yankai Lin, Xun Zhang, Yufei Zhang, Fei Jiang .etc.|<http://arxiv.org/pdf/2510.24285v1>|提出ViPER框架，通过自我评价与预测迭代提升视觉感知能力，有效解决了视觉语言模型在细粒度视觉感知上...|
|📝 更新|Through the Lens: Benchmarking Deepfake Detectors Against Moiré-Induced Distortions|通过镜头：对深度伪造检测器在莫尔纹理诱导失真下的基准测试|Razaib Tariq, Minji Heo, Simon S. Woo, Shahroz Tariq|<http://arxiv.org/pdf/2510.23225v2>|评估了现有深度伪造检测器在摩尔纹干扰下的性能，并构建了专门数据集以促进鲁棒检测模型的研究。|
|🆕 发布|UtilGen: Utility-Centric Generative Data Augmentation with Dual-Level Task Adaptation|"UtilGen：以实用性为中心的生成数据增强方法及双层任务适配"|Jiyu Guo, Shuo Yang, Yiming Huang, Yancheng Long, Xiaobo Xia, Xiu Su, Bo Zhao, Zeke Xie .etc.|<http://arxiv.org/pdf/2510.24262v1>|提出了一种以任务效用为中心的数据增强框架UtilGen，通过任务反馈自适应优化数据生成过程，显著提升...|
|🆕 发布|MC-SJD : Maximal Coupling Speculative Jacobi Decoding for Autoregressive Visual Generation Acceleration|MC-SJD : 用于自回归视觉生成加速的最大耦合投机雅可比解码|Junhyuk So, Hyunho Kook, Chaeyeon Jang, Eunhyeok Park|<http://arxiv.org/pdf/2510.24211v1>|提出MC-SJD方法，通过信息耦合加速自回归视觉生成，实现图像和视频生成速度大幅提升。|
|📝 更新|A Generalized Label Shift Perspective for Cross-Domain Gaze Estimation|《跨域 gaze 估计的广义标签偏移视角》|Hao-Ran Yang, Xiaohui Chen, Chuan-Xian Ren|<http://arxiv.org/pdf/2505.13043v2>|引入广义标签偏移视角解决跨域 gaze 估计问题，提出基于截断高斯分布的重加权策略和概率感知估计方法...|
|📝 更新|CustomVideo: Customizing Text-to-Video Generation with Multiple Subjects|《CustomVideo：多主体定制化文本到视频生成》|Zhao Wang, Aoxue Li, Lingting Zhu, Yong Guo, Qi Dou, Zhenguo Li|<http://arxiv.org/pdf/2401.09962v3>|提出了一种多主体引导的个性化文本到视频生成框架CustomVideo，有效解决了多主体场景下的视频生...|
|📝 更新|UMCFuse: A Unified Multiple Complex Scenes Infrared and Visible Image Fusion Framework|UMCFuse：一种统一的多复杂场景红外与可见光图像融合框架|Xilai Li, Xiaosong Li, Tianshu Tan, Huafeng Li, Tao Ye|<http://arxiv.org/pdf/2402.02096v2>|[代码](https://github.com/ixilai/UMCFuse.); 提出了一种统一框架UMCFuse，针对复杂场景下红外与可见光图像融合问题，通过自适应去噪策略和能量特...|
|🆕 发布|Compositional Image Synthesis with Inference-Time Scaling|合成图像生成与推理时缩放|Minsuk Ji, Sanghyeok Lee, Namhyuk Ahn|<http://arxiv.org/pdf/2510.24133v1>|[代码](https://github.com/gcl-inha/ReFocus.); 提出了一种结合对象中心方法和自我优化的训练无关框架，通过利用大型语言模型生成布局并迭代选择最符合提示...|
|📝 更新|Task-Agnostic Fusion of Time Series and Imagery for Earth Observation|任务无关的时间序列与图像融合用于地球观测|Gianfranco Basile, Johannes Jakubik, Benedikt Blumenstiel, Thomas Brunschwiler, Juan Bernabe Moreno|<http://arxiv.org/pdf/2510.23118v2>|提出了一种任务无关的多模态融合框架，将时间序列和图像数据统一表示，显著提升了地球观测领域的下游任务性...|
|🆕 发布|Beyond Objects: Contextual Synthetic Data Generation for Fine-Grained Classification|超越物体：细粒度分类的上下文合成数据生成|William Yang, Xindi Wu, Zhiwei Deng, Esin Tureci, Olga Russakovsky|<http://arxiv.org/pdf/2510.24078v1>|提出了一种名为BOB的细粒度分类合成数据生成策略，通过利用类无关属性减少过拟合并提高生成样本多样性。|
|📝 更新|Bridging the gap to real-world language-grounded visual concept learning|弥合现实世界语言基础视觉概念学习的差距|Whie Jung, Semin Kim, Junee Kim, Seunghoon Hong|<http://arxiv.org/pdf/2510.21412v2>|[代码](https://github.com/whieya/Language-grounded-VCL.); 提出了一种自适应识别图像相关概念轴并实现视觉概念学习的框架，有效提升了真实世界场景下的视觉概念理解和...|
|📝 更新|InstanceAssemble: Layout-Aware Image Generation via Instance Assembling Attention|实例组装：通过实例组装注意力实现布局感知的图像生成|Qiang Xiang, Shuang Sun, Binglei Li, Dejia Song, Huaxia Li, Nemo Chen, Xu Tang, Yao Hu .etc.|<http://arxiv.org/pdf/2509.16691v2>|[代码](https://github.com/FireRedTeam/InstanceAssemble.); 定位并控制布局生成图像，InstanceAssemble通过实例组装注意力实现精确的图像合成。|
|🆕 发布|AutoPrompt: Automated Red-Teaming of Text-to-Image Models via LLM-Driven Adversarial Prompts|自动提示：通过大型语言模型驱动的对抗性提示对文本到图像模型进行自动化红队测试|Yufan Liu, Wanqian Zhang, Huashan Chen, Lin Wang, Xiaojun Jia, Zheng Lin, Weiping Wang|<http://arxiv.org/pdf/2510.24034v1>|提出了一种自动生成对抗性提示的框架，利用大型语言模型增强文本到图像模型的安全性。|
|🆕 发布|Neural USD: An object-centric framework for iterative editing and control|神经USD：一种面向对象的迭代编辑与控制框架|Alejandro Escontrela, Shrinu Kushagra, Sjoerd van Steenkiste, Yulia Rubanova, Aleksander Holynski, Kelsey Allen, Kevin Murphy, Thomas Kipf|<http://arxiv.org/pdf/2510.23956v1>|提出了Neural USD框架，实现了对场景中对象的精确迭代编辑与控制。|
|📝 更新|GRAID: Enhancing Spatial Reasoning of VLMs Through High-Fidelity Data Generation|GRAID：通过高保真数据生成增强视觉语言模型的空间推理能力|Karim Elmaaroufi, Liheng Lai, Justin Svegliato, Yutong Bai, Sanjit A. Seshia, Matei Zaharia|<http://arxiv.org/pdf/2510.22118v2>|提出GRAID方法，通过2D几何元素生成高质量数据集，增强视觉语言模型的空间推理能力。|


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Routing Matters in MoE: Scaling Diffusion Transformers with Explicit Routing Guidance|"路由在MoE中至关重要：通过显式路由指导扩展扩散变压器"|Yujie Wei, Shiwei Zhang, Hangjie Yuan, Yujin Han, Zhekai Chen, Jiayu Wang, Difan Zou, Xihui Liu .etc.|<http://arxiv.org/pdf/2510.24711v1>|提出ProMoE框架，通过显式路由指导优化视觉MoE模型专家专精，提升图像处理性能。|
|📝 更新|Long-VITA: Scaling Large Multi-modal Models to 1 Million Tokens with Leading Short-Context Accuracy|长VITA：扩展大型多模态模型至100万个标记，实现领先短语境准确性|Yunhang Shen, Chaoyou Fu, Shaoqi Dong, Xiong Wang, Yi-Fan Zhang, Peixian Chen, Mengdan Zhang, Haoyu Cao .etc.|<http://arxiv.org/pdf/2502.05177v3>|提出Long-VITA模型，有效处理长文本和图像，实现领先短文本多模态任务性能。|
|📝 更新|VADTree: Explainable Training-Free Video Anomaly Detection via Hierarchical Granularity-Aware Tree|VADTree：通过分层粒度感知树实现的无需训练的可解释视频异常检测|Wenlong Li, Yifei Xu, Yuan Rao, Zhenhua Wang, Shuiguang Deng|<http://arxiv.org/pdf/2510.22693v2>|[代码](https://github.com/wenlongli10/VADTree.); 提出了一种无需训练的层级粒度感知树结构VADTree，通过灵活采样有效捕捉视频异常，实现了训练自由设...|
|🆕 发布|SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box Adversarial Paraphrasing in Text Autoencoder Latent Space|SPARTA：通过在文本自动编码器潜在空间的黑盒对抗性改写评估推理分割鲁棒性|Viktoriia Zinkovich, Anton Antonov, Andrei Spiridonov, Denis Shepelev, Andrey Moskalenko, Daria Pugacheva, Elena Tutubalina, Andrey Kuznetsov .etc.|<http://arxiv.org/pdf/2510.24446v1>|提出了一种在文本自动编码器潜在空间中操作的黑盒对抗性改写方法SPARTA，用于评估推理分割的鲁棒性。|
|📝 更新|Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies|离散扩散VLA：将离散扩散应用于视觉-语言-动作策略中的动作解码|Zhixuan Liang, Yizhuo Li, Tianshuo Yang, Chengyue Wu, Sitong Mao, Tian Nian, Liuao Pei, Shunbo Zhou .etc.|<http://arxiv.org/pdf/2508.20072v2>|[代码](https://github.com/Liang-ZX/DiscreteDiffusionVLA); 提出了一种统一Transformer架构的Discrete Diffusion VLA，通过离散扩散...|
|🆕 发布|Unsupervised Detection of Post-Stroke Brain Abnormalities|无监督检测脑卒中后异常|Youwan Mahé, Elise Bannier, Stéphanie Leplaideur, Elisa Fromont, Francesca Galassi|<http://arxiv.org/pdf/2510.24398v1>|提出了一种基于生成模型的脑卒中后异常无监督检测方法，提高了对非病变区域异常的识别准确性。|
|📝 更新|Video-SafetyBench: A Benchmark for Safety Evaluation of Video LVLMs|视频安全基准：用于视频大型视觉语言模型安全性评估的基准|Xuannan Liu, Zekun Li, Zheqi He, Peipei Li, Shuhan Xia, Xing Cui, Huaibo Huang, Xi Yang .etc.|<http://arxiv.org/pdf/2505.11842v3>|提出了Video-SafetyBench，首个针对视频输入下大型视觉语言模型安全性评估的全面基准。|
|🆕 发布|Beyond Inference Intervention: Identity-Decoupled Diffusion for Face Anonymization|超越推理干预：身份解耦扩散用于面部匿名化|Haoxin Yang, Yihong Lin, Jingdan Kang, Xuemiao Xu, Yue Li, Cheng Xu, Shengfeng He|<http://arxiv.org/pdf/2510.24213v1>|提出了一种训练阶段的去识别框架ID²Face，通过显式解耦身份和非身份信息，实现了无需推理阶段优化的...|
|🆕 发布|ETC: training-free diffusion models acceleration with Error-aware Trend Consistency|ETC：无需训练的扩散模型加速，基于误差感知趋势一致性|Jiajian Xie, Hubery Yin, Chen Li, Zhou Zhao, Shengyu Zhang|<http://arxiv.org/pdf/2510.24129v1>|提出了一种无需训练的扩散模型加速框架ETC，通过误差感知趋势一致性提高了生成质量和效率。|
|📝 更新|VSA: Faster Video Diffusion with Trainable Sparse Attention|VSA：可训练稀疏注意力加速视频扩散|Peiyuan Zhang, Yongqi Chen, Haofeng Huang, Will Lin, Zhengzhong Liu, Ion Stoica, Eric Xing, Hao Zhang|<http://arxiv.org/pdf/2505.13389v5>|[代码](https://github.com/hao-ai-lab/FastVideo.); 提出了一种高效的稀疏注意力机制VSA，通过池化关键区域减少计算量，实现了视频生成模型的加速训练与推理...|
|📝 更新|Unveiling Concept Attribution in Diffusion Models|揭示扩散模型中的概念归属|Quang H. Nguyen, Hoang Phan, Khoa D. Doan|<http://arxiv.org/pdf/2412.02542v3>|[代码](https://github.com/mail-research/CAD-attribution4diffusion); 提出了一种组件归因框架，揭示了扩散模型中各组件在生成概念时的作用，并引入了两种模型编辑算法以增强或削...|
|📝 更新|Unsupervised Monocular Depth Estimation Based on Hierarchical Feature-Guided Diffusion|基于层次特征引导扩散的无监督单目深度估计|Runze Liu, Dongchen Zhu, Guanghui Zhang, Yue Xu, Wenjun Shi, Xiaolin Zhang, Lei Wang, Jiamao Li|<http://arxiv.org/pdf/2406.09782v3>|提出了一种基于生成网络扩散模型和层级特征引导去噪模块的无监督单目深度估计方法，增强了模型的鲁棒性和深...|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SAGE: Structure-Aware Generative Video Transitions between Diverse Clips|SAGE：结构感知的多样化视频片段生成过渡|Mia Kan, Yilin Liu, Niloy Mitra|<http://arxiv.org/pdf/2510.24667v1>|提出结构感知生成视频转换方法SAGE，通过结合结构引导和生成合成，实现了无微调情况下多样化视频片段间...|
|📝 更新|Polygonal network disorder and the turning distance|多边形网络紊乱与转向距离|Alex Dolce, Ryan Lavelle, Bernard Scott, Ashlyn Urbanski, Joseph Klobusicky|<http://arxiv.org/pdf/2503.06415v2>|提出了一种衡量多边形网络无序度的方法，通过计算与规则形状的转向距离，提高了计算效率。|
|📝 更新|PANDA: Towards Generalist Video Anomaly Detection via Agentic AI Engineer|PANDA：通过代理型AI工程师实现通用视频异常检测|Zhiwei Yang, Chen Gao, Mike Zheng Shou|<http://arxiv.org/pdf/2509.26386v2>|[代码](https://github.com/showlab/PANDA.); 提出PANDA，一种无需训练数据或人工干预即可自动处理任意场景和异常类型的通用视频异常检测方法。|
|🆕 发布|VC4VG: Optimizing Video Captions for Text-to-Video Generation|视频字幕优化以促进文本到视频生成：VC4VG|Yang Du, Zhuoran Lin, Kaiqiang Song, Biao Wang, Zhicheng Zheng, Tiezheng Ge, Bo Zheng, Qin Jin|<http://arxiv.org/pdf/2510.24134v1>|[代码](https://github.com/qyr0403/VC4VG); 提出视频字幕优化框架VC4VG，提升文本到视频生成模型的性能。|
|📝 更新|GS4: Generalizable Sparse Splatting Semantic SLAM|GS4：通用稀疏散点绘制语义SLAM|Mingqi Jiang, Chanho Kim, Chen Ziwen, Li Fuxin|<http://arxiv.org/pdf/2506.06517v2>|提出GS4，首个通用化基于高斯散布的语义SLAM系统，实现快速、高效的三维映射与语义整合。|
|📝 更新|IGGT: Instance-Grounded Geometry Transformer for Semantic 3D Reconstruction|实例定位几何变换器用于语义三维重建：IGGT|Hao Li, Zhengyu Zou, Fangfu Liu, Xuanyang Zhang, Fangzhou Hong, Yukang Cao, Yushi Lan, Manyuan Zhang .etc.|<http://arxiv.org/pdf/2510.22706v2>|提出了一种统一的空间重建与实例级理解的大型端到端Transformer模型，通过2D视觉输入实现3D...|


### 三维内容生成 (3D Content Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Group Relative Attention Guidance for Image Editing|图像编辑中的组相对注意力引导|Xuanpu Zhang, Xuesong Niu, Ruidong Chen, Dan Song, Jianhao Zeng, Penghui Du, Haoxiang Cao, Kai Wu .etc.|<http://arxiv.org/pdf/2510.24657v1>|[代码](https://github.com/little-misfit/GRAG-Image-Editing.); 提出了一种新的图像编辑方法Group Relative Attention Guidance，通过调...|
|📝 更新|RETTA: Retrieval-Enhanced Test-Time Adaptation for Zero-Shot Video Captioning|RETTA：检索增强的测试时适应方法用于零样本视频标注|Yunchuan Ma, Laiyun Qing, Guorong Li, Yuankai Qi, Amin Beheshti, Quan Z. Sheng, Qingming Huang|<http://arxiv.org/pdf/2405.07046v3>|提出了一种零样本视频字幕生成框架RETTA，通过测试时适应和预训练模型间的可学习令牌交流，显著提升了...|
|📝 更新|Does CLIP perceive art the same way we do?|《CLIP 是否像我们一样感知艺术？》|Andrea Asperti, Leonardo Dessì, Maria Chiara Tonetti, Nico Wu|<http://arxiv.org/pdf/2505.05229v2>|探究CLIP模型对艺术作品的理解与人类感知的契合度，揭示了其在审美和创作意图上的优势和局限。|
|📝 更新|AnyCap Project: A Unified Framework, Dataset, and Benchmark for Controllable Omni-modal Captioning|AnyCap项目：可控全模态字幕生成的统一框架、数据集与基准|Yiming Ren, Zhiqiang Lin, Yu Li, Gao Meng, Weiyun Wang, Junjie Wang, Zicheng Lin, Jifeng Dai .etc.|<http://arxiv.org/pdf/2507.12841v2>|提出AnyCap Project，通过轻量级框架增强多模态字幕生成控制性，构建专用数据集和评估指标，...|
|🆕 发布|OmniText: A Training-Free Generalist for Controllable Text-Image Manipulation|全文本：一种无需训练的可控文本图像操作通用模型|Agus Gunawan, Samuel Teodoro, Yun Chen, Soo Ye Kim, Jihyong Oh, Munchurl Kim|<http://arxiv.org/pdf/2510.24093v1>|提出OmniText，一种无需训练的通用模型，能执行多种文本图像操作任务，实现文本去除和风格控制。|
|📝 更新|Riemannian-Geometric Fingerprints of Generative Models|生成模型的双曲几何指纹|Hae Jin Song, Laurent Itti|<http://arxiv.org/pdf/2506.22802v2>|提出了一种基于黎曼几何的生成模型指纹识别方法，有效区分不同生成模型并提高模型归属性能。|
|🆕 发布|SafeVision: Efficient Image Guardrail with Robust Policy Adherence and Explainability|安全视觉：具有鲁棒策略遵守和可解释性的高效图像防护栏|Peiyang Xu, Minzhou Pan, Zhaorun Chen, Shuang Yang, Chaowei Xiao, Bo Li|<http://arxiv.org/pdf/2510.23960v1>|SafeVision通过集成类人推理提升了图像安全防护的适应性和透明度，无需重新训练即可动态适应新威...|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Kineo: Calibration-Free Metric Motion Capture From Sparse RGB Cameras|“Kineo：无需校准的稀疏RGB相机度量运动捕捉”|Charles Javerliat, Pierre Raimbaud, Guillaume Lavoué|<http://arxiv.org/pdf/2510.24464v1>|[代码](https://liris-xr.github.io/kineo); 提出了一种无需精确相机校准的自动运动捕捉方法Kineo，大幅提高了重建精度和效率。|
|🆕 发布|DynaRend: Learning 3D Dynamics via Masked Future Rendering for Robotic Manipulation|动态渲染：通过遮罩未来渲染学习机器人操作的三维动力学|Jingyi Tian, Le Wang, Sanping Zhou, Sen Wang, Jiayi Li, Gang Hua|<http://arxiv.org/pdf/2510.24261v1>|提出了一种3D动态感知的表示学习框架DynaRend，通过预训练提升机器人操作任务的泛化能力和成功率...|
|📝 更新|Geo-Sign: Hyperbolic Contrastive Regularisation for Geometrically Aware Sign Language Translation|地理签名：基于双曲对比正则化的几何感知手语翻译|Edward Fish, Richard Bowden|<http://arxiv.org/pdf/2506.00129v2>|[代码](https://github.com/ed-fish/geo-sign.); 提出Geo-Sign方法，利用双曲几何增强签语动作的骨骼表示，提升翻译准确性和计算效率。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Sound Source Localization for Spatial Mapping of Surgical Actions in Dynamic Scenes|动态场景中手术动作的空间映射声音源定位|Jonas Hein, Lazaros Vlachopoulos, Maurits Geert Laurent Olthof, Bastian Sigrist, Philipp Fürnstahl, Matthias Seibold|<http://arxiv.org/pdf/2510.24332v1>|提出首个动态手术场景中的空间声音定位方法，融合声视觉数据提升手术活动理解。|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Acoustic Neural 3D Reconstruction Under Pose Drift|声学神经三维重建中的位姿漂移问题研究|Tianxiang Lin, Mohamad Qadri, Kevin Zhang, Adithya Pediredla, Christopher A. Metzler, Michael Kaess|<http://arxiv.org/pdf/2503.08930v2>|提出了一种优化神经隐式表面和声纳姿态的算法，实现了姿态漂移下的高保真3D重建。|
|🆕 发布|Enhancing Pre-trained Representation Classifiability can Boost its Interpretability|提升预训练表征的可分类性可以增强其可解释性|Shufan Shen, Zhaobo Qi, Junshu Sun, Qingming Huang, Qi Tian, Shuhui Wang|<http://arxiv.org/pdf/2510.24105v1>|[代码](https://github.com/ssfgunner/IIS.); 提出Inherent Interpretability Score评估方法，发现预训练模型的可解释性...|


## 时序视觉分析 (Temporal Visual Analysis)


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Benchmarking Microsaccade Recognition with Event Cameras: A Novel Dataset and Evaluation|微眼跳识别的事件相机基准测试：一种新颖的数据集与评估方法|Waseem Shariff, Timothy Hanley, Maciej Stec, Hossein Javidnia, Peter Corcoran|<http://arxiv.org/pdf/2510.24231v1>|[代码](https://waseemshariff126.github.io/microsaccades); 该研究创建了一个基于事件相机的微眼动识别数据集，并通过尖峰神经网络实现了高精度分类。|
|📝 更新|MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition|运动原语变换器：用于可穿戴传感器活动识别的运动原语变换器|Hao Zhang, Zhan Zhuang, Xuehao Wang, Xiaodong Yang, Yu Zhang|<http://arxiv.org/pdf/2505.20744v2>|提出了一种将可解释的运动原语与Transformer结合的框架，有效提升了可穿戴传感器活动识别的跨数...|


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Real-Time Neural Video Compression with Unified Intra and Inter Coding|统一 intra 和 inter 编码的实时神经视频压缩|Hui Xiang, Yifan Bian, Li Li, Jingran Wu, Xianguo Zhang, Dong Liu|<http://arxiv.org/pdf/2510.14431v2>|提出统一 intra 和 inter 编码的实时神经视频压缩框架，有效处理视频遮挡和新内容，减少错误...|
|📝 更新|MDP3: A Training-free Approach for List-wise Frame Selection in Video-LLMs|MDP3：一种无需训练的视频-LLMs中列表式帧选择方法|Hui Sun, Shiyin Lu, Huanyu Wang, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang, Ming Li|<http://arxiv.org/pdf/2501.02885v2>|提出了一种无需训练的MDP3方法，通过动态规划选择视频帧，有效提升Video-LLMs处理视频的效率...|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|DeshadowMamba: Deshadowing as 1D Sequential Similarity|《DeshadowMamba：将去阴影处理视为一维序列相似性》|Zhaotong Yang, Yi Chen, Yanying Li, Shengfeng He, Yangyang Xu, Junyu Dong, Jian Yang, Yong Du|<http://arxiv.org/pdf/2510.24260v1>|提出了一种基于序列建模的阴影去除方法，通过方向性状态转换和阴影感知机制，实现了结构完整性和颜色一致性...|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|ADMN: A Layer-Wise Adaptive Multimodal Network for Dynamic Input Noise and Compute Resources|ADMN：一种针对动态输入噪声和计算资源的逐层自适应多模态网络|Jason Wu, Yuyang Yuan, Kang Yang, Lance Kaplan, Mani Srivastava|<http://arxiv.org/pdf/2502.07862v2>|提出了一种自适应多模态网络，能在计算资源波动和输入质量变化时动态调整网络结构，提高效率并保持准确率。|
|🆕 发布|Eye-Tracking, Mouse Tracking, Stimulus Tracking,and Decision-Making Datasets in Digital Pathology|数字病理学中的眼动追踪、鼠标追踪、刺激追踪与决策制定数据集|Veronica Thai, Rui Li, Meng Ling, Shuning Jiang, Jeremy Wolfe, Raghu Machiraju, Yan Hu, Zaibo Li .etc.|<http://arxiv.org/pdf/2510.24653v1>|构建了首个全面记录病理诊断过程中视觉搜索和决策行为的综合数据集，助力提升病理诊断准确性和AI系统训练...|
|🆕 发布|Fast and accurate neural reflectance transformation imaging through knowledge distillation|通过知识蒸馏实现的快速准确神经反射率变换成像|Tinsae G. Dulecha, Leonardo Righetto, Ruggero Pintus, Enrico Gobbetti, Andrea Giachetti|<http://arxiv.org/pdf/2510.24486v1>|通过知识蒸馏技术，有效降低了神经反射变换成像的计算成本，同时保持了高质量的视觉效果。|
|🆕 发布|Decoupling What to Count and Where to See for Referring Expression Counting|“解耦计数对象与定位视觉参照表达计数”|Yuda Zou, Zijian Zhang, Yongchao Xu|<http://arxiv.org/pdf/2510.24374v1>|提出W2-Net框架，通过分离“计数对象”和“视觉定位”任务，有效提升细粒度类别计数精度。|
|🆕 发布|NVSim: Novel View Synthesis Simulator for Large Scale Indoor Navigation|NVSim：大规模室内导航的新型视图合成模拟器|Mingyu Jeong, Eunsung Kim, Sehun Park, Andrew Jaeyong Choi|<http://arxiv.org/pdf/2510.24335v1>|NVSim通过自动构建大型室内导航模拟器，解决了传统3D扫描成本高和扩展性差的问题。|
|📝 更新|On Robustness of Vision-Language-Action Model against Multi-Modal Perturbations|《面向多模态扰动下视觉-语言-动作模型的鲁棒性研究》|Jianing Guo, Zhenhong Wu, Chang Tu, Yiyao Ma, Xiangqi Kong, Zhiqian Liu, Jiaming Ji, Shuning Zhang .etc.|<http://arxiv.org/pdf/2510.00037v3>|提出RobustVLA模型，增强视觉语言动作模型对多模态干扰的鲁棒性，显著提升在各种扰动下的性能。|


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DRBD-Mamba for Robust and Efficient Brain Tumor Segmentation with Analytical Insights|DRBD-Mamba：用于稳健且高效的大脑肿瘤分割及其分析洞察|Danish Ali, Ajmal Mian, Naveed Akhtar, Ghulam Mubashar Hassan|<http://arxiv.org/pdf/2510.14383v2>|提出了一种双分辨率双向Mamba模型，通过捕获多尺度长距离依赖性，实现了高效稳健的脑肿瘤分割。|
|📝 更新|DArFace: Deformation Aware Robustness for Low Quality Face Recognition|《DArFace：面向低质量人脸识别的形变感知鲁棒性》|Sadaf Gulshad, Abdullah Aldahlawi|<http://arxiv.org/pdf/2505.08423v4>|提出了一种考虑局部非刚性变形的DArFace框架，有效提升了低质量人脸识别的鲁棒性。|
|🆕 发布|MSRANetV2: An Explainable Deep Learning Architecture for Multi-class Classification of Colorectal Histopathological Images|MSRANetV2：一种用于结直肠癌组织病理学图像多类分类的可解释深度学习架构|Ovi Sarkar, Md Shafiuzzaman, Md. Faysal Ahamed, Golam Mahmud, Muhammad E. H. Chowdhury|<http://arxiv.org/pdf/2510.24136v1>|提出MSRANetV2模型，通过融合多尺度特征和注意力机制，有效提升结直肠癌组织图像分类的准确性和解...|
|🆕 发布|ResNet: Enabling Deep Convolutional Neural Networks through Residual Learning|残差学习启用的深度卷积神经网络：ResNet|Xingyu Liu, Kun Ming Goh|<http://arxiv.org/pdf/2510.24036v1>|通过引入跳跃连接解决梯度消失问题，ResNet实现了数百层网络的训练并提升准确率。|
|🆕 发布|Towards the Automatic Segmentation, Modeling and Meshing of the Aortic Vessel Tree from Multicenter Acquisitions: An Overview of the SEG.A. 2023 Segmentation of the Aorta Challenge|面向多中心采集数据中主动脉血管树的自动分割、建模和网格化：SEG.A. 2023 主动脉分割挑战概述|Yuan Jin, Antonio Pepe, Gian Marco Melito, Yuxuan Chen, Yunsu Byeon, Hyeseong Kim, Kyungwon Kim, Doohyun Park .etc.|<http://arxiv.org/pdf/2510.24009v1>|推动了主动脉血管树自动分割技术发展，通过大规模多中心数据集和深度学习模型融合提升性能。|
|🆕 发布|Synergistic Neural Forecasting of Air Pollution with Stochastic Sampling|协同神经网络预测空气污染及其随机采样|Yohan Abeysinghe, Muhammad Akhtar Munir, Sanoojan Baliah, Ron Sarafian, Fahad Shahbaz Khan, Yinon Rudich, Salman Khan|<http://arxiv.org/pdf/2510.23977v1>|提出SynCast模型，融合气象与空气成分数据，提高极端空气污染事件预测准确性。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows|OS-Sentinel：通过现实工作流中的混合验证实现安全性增强的移动GUI智能体|Qiushi Sun, Mukai Li, Zhoumianze Liu, Zhihui Xie, Fangzhi Xu, Zhangyue Yin, Kanzhi Cheng, Zehao Li .etc.|<http://arxiv.org/pdf/2510.24411v1>|提出OS-Sentinel框架，结合形式验证器和视觉语言模型，有效提升移动GUI代理的安全性检测。|
|📝 更新|VOLD: Reasoning Transfer from LLMs to Vision-Language Models via On-Policy Distillation|VOLD：通过策略蒸馏从大型语言模型到视觉语言模型的推理迁移|Walid Bousselham, Hilde Kuehne, Cordelia Schmid|<http://arxiv.org/pdf/2510.23497v2>|提出了一种利用大型语言模型推理能力迁移至视觉语言模型的框架VOLD，有效解决了视觉语言模型训练数据稀...|
|📝 更新|Normal and Abnormal Pathology Knowledge-Augmented Vision-Language Model for Anomaly Detection in Pathology Images|病理学知识与视觉语言模型增强的正常与异常病理图像异常检测|Jinsol Song, Jiamu Wang, Anh Tien Nguyen, Keunho Byeon, Sangjeong Ahn, Sung Hak Lee, Jin Tae Kwak|<http://arxiv.org/pdf/2508.15256v2>|提出Ano-NAViLa模型，融合病理知识增强的视觉语言技术，提升病理图像异常检测准确性和解释性。|
|🆕 发布|UHKD: A Unified Framework for Heterogeneous Knowledge Distillation via Frequency-Domain Representations|异质知识蒸馏的统一框架：基于频域表示的UHKD|Fengming Yu, Haiwei Pan, Kejia Zhang, Jian Guan, Haiying Jiang|<http://arxiv.org/pdf/2510.24116v1>|提出了一种利用频域表示的统一框架UHKD，有效解决了异构模型间的知识蒸馏问题，提升了视觉知识利用效率...|
|📝 更新|Switchable Token-Specific Codebook Quantization For Face Image Compression|可切换的标记特定码本量化用于人脸图像压缩|Yongbo Wang, Haonan Wang, Guodong Mu, Ruixin Zhang, Jiaqi Chen, Jingyun Zhang, Jun Wang, Yuan Xie .etc.|<http://arxiv.org/pdf/2510.22943v2>|提出了一种针对面部图像的切换式独立码本量化方法，通过为不同图像类别学习独立码本，提高了低比特率下的重...|
|📝 更新|Radar and Event Camera Fusion for Agile Robot Ego-Motion Estimation|雷达与事件相机融合的敏捷机器人自我运动估计|Yang Lyu, Zhenghao Zou, Yanfeng Li, Xiaohu Guo, Chunhui Zhao, Quan Pan|<http://arxiv.org/pdf/2506.18443v2>|[代码](https://github.com/ZzhYgwh/TwistEstimator.); 提出了一种无需IMU和特征关联的框架，融合事件相机和毫米波雷达，实现动态场景下机器人平台的精确速度估...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Physics-Inspired Gaussian Kolmogorov-Arnold Networks for X-ray Scatter Correction in Cone-Beam CT|基于物理启发的高斯科尔莫哥洛夫-阿尔诺德网络用于锥形束CT的X射线散射校正|Xu Jiang, Huiying Pan, Ligen Shi, Jianing Sun, Wenfeng Xu, Xing Zhao|<http://arxiv.org/pdf/2510.24579v1>|提出了一种基于物理启发深度学习的X射线散射线校正方法，有效提升了CBCT图像质量。|
|📝 更新|TraceTrans: Translation and Spatial Tracing for Surgical Prediction|《TraceTrans：手术预测的翻译与空间追踪》|Xiyu Luo, Haodong Li, Xinxing Cheng, He Zhao, Yang Hu, Xuan Song, Tianyang Zhang|<http://arxiv.org/pdf/2510.22379v2>|提出了一种用于术后预测的图像翻译模型TraceTrans，通过保持源图像与翻译图像间的空间对应关系，...|


### 对抗鲁棒性 (Adversarial Robustness)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Vanish into Thin Air: Cross-prompt Universal Adversarial Attacks for SAM2|"化为乌有：针对SAM2的跨提示通用对抗攻击"|Ziqi Zhou, Yifan Hu, Yufei Song, Zijing Li, Shengshan Hu, Leo Yu Zhang, Dezhong Yao, Long Zheng .etc.|<http://arxiv.org/pdf/2510.24195v1>|提出首个针对SAM2的跨提示通用对抗攻击方法UAP-SAM2，通过双重语义偏差优化，有效攻击视频分割...|
|🆕 发布|Enhancing CLIP Robustness via Cross-Modality Alignment|通过跨模态对齐增强CLIP鲁棒性|Xingyu Zhu, Beier Zhu, Shuo Wang, Kesen Zhao, Hanwang Zhang|<http://arxiv.org/pdf/2510.24038v1>|提出了一种基于最优传输理论的跨模态对齐框架COLA，有效增强了CLIP模型在对抗攻击下的鲁棒性。|
|🆕 发布|AdvBlur: Adversarial Blur for Robust Diabetic Retinopathy Classification and Cross-Domain Generalization|《AdvBlur：用于稳健糖尿病视网膜病变分类和跨域泛化的对抗性模糊》|Heethanjan Kanagalingam, Thenukan Pathmanathan, Mokeeshan Vathanakumar, Tharmakulasingam Mukunthan|<http://arxiv.org/pdf/2510.24000v1>|提出AdvBlur方法，通过整合对抗性模糊图像和双损失函数框架，增强糖尿病视网膜病变分类的鲁棒性和跨...|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Towards Real Unsupervised Anomaly Detection Via Confident Meta-Learning|面向真实无监督异常检测的置信元学习方法|Muhammad Aqeel, Shakiba Sharifi, Marco Cristani, Francesco Setti|<http://arxiv.org/pdf/2508.02293v2>|[代码](https://github.com/aqeeelmirza/CoMet); 提出了一种无需手动筛选异常样本的自信元学习方法，有效提升无监督异常检测的准确性和鲁棒性。|
|📝 更新|MTFL: Multi-Timescale Feature Learning for Weakly-Supervised Anomaly Detection in Surveillance Videos|多时间尺度特征学习：用于监控视频中的弱监督异常检测|Yiling Zhang, Erkut Akdag, Egor Bondarev, Peter H. N. De With|<http://arxiv.org/pdf/2410.05900v2>|提出了一种多时间尺度特征学习方法MTFL，通过融合不同时间尺度的视频特征，有效提升了监控视频异常事件...|
|📝 更新|Advancing Compositional Awareness in CLIP with Efficient Fine-Tuning|在CLIP中通过高效微调提升组合意识|Amit Peleg, Naman Deep Singh, Matthias Hein|<http://arxiv.org/pdf/2505.24424v2>|分类和检索中，CLIP模型在组合推理上存在难题，本文提出CLIC方法，通过多图像与标题结合训练，提升...|
|📝 更新|CalFuse: Multi-Modal Continual Learning via Feature Calibration and Parameter Fusion|"CalFuse：通过特征校准和参数融合实现的多模态持续学习"|Juncen Guo, Siao Liu, Xiaoguang Zhu, Lianlong Sun, Liangyu Teng, Jingyi Wu, Di Li, Linxiao Gong .etc.|<http://arxiv.org/pdf/2503.18672v8>|提出了一种融合特征校准与参数融合的多模态持续学习方法，有效平衡了新知识学习与旧知识保留。|
|📝 更新|Learning to See and Act: Task-Aware View Planning for Robotic Manipulation|学会观察与行动：面向机器人操作的任务感知视角规划|Yongjie Bai, Zhouxia Wang, Yang Liu, Weixing Chen, Ziliang Chen, Mingtong Dai, Yongsen Zheng, Lingbo Liu .etc.|<http://arxiv.org/pdf/2508.05186v3>|[代码](https://hcplab-sysu.github.io/TAVP.); 提出了一种任务感知视角规划框架TAVP，通过主动获取信息视角和任务特定特征分离，提升了机器人操作的鲁...|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉导航与路径规划 (Visual Navigation & Path Planning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Navigation with VLM framework: Towards Going to Any Language|基于VLM框架的导航：迈向任意语言的转向|Zecheng Yin, Chonghao Cheng, and Yao Guo, Zhen Li|<http://arxiv.org/pdf/2410.02787v2>|提出NavVLM框架，利用无需训练的视觉语言模型实现智能导航，有效处理开放场景中的抽象语言目标。|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MMPerspective: Do MLLMs Understand Perspective? A Comprehensive Benchmark for Perspective Perception, Reasoning, and Robustness|MMPerspective：多模态语言模型是否理解视角？一种全面的视角感知、推理和鲁棒性基准|Yolo Yunlong Tang, Pinxin Liu, Zhangyun Tan, Mingqian Feng, Rui Mao, Chao Huang, Jing Bi, Yunzhong Xiao .etc.|<http://arxiv.org/pdf/2505.20426v3>|[代码](https://yunlong10.github.io/MMPerspective); 提出MMPerspective基准，首次系统评估大型多模态语言模型对透视理解的能力。|
|🆕 发布|A Hybrid Approach for Visual Multi-Object Tracking|一种视觉多目标跟踪的混合方法|Toan Van Nguyen, Rasmus G. K. Christiansen, Dirk Kraft, Leon Bodenhagen|<http://arxiv.org/pdf/2510.24410v1>|[代码](https://github.com/SDU-VelKoTek/GenTrack2); 提出了一种结合随机和确定性机制的视觉多目标跟踪方法，有效处理了非线性动态和未知数量的目标跟踪问题。|
|📝 更新|GEMeX-RMCoT: An Enhanced Med-VQA Dataset for Region-Aware Multimodal Chain-of-Thought Reasoning|GEMeX-RMCoT：一种用于区域感知多模态链式思维推理的增强型Med-VQA数据集|Bo Liu, Xiangyu Zhao, Along He, Yidi Chen, Huazhu Fu, Xiao-Ming Wu|<http://arxiv.org/pdf/2506.17939v2>|提出了一种增强的医学术图像问答数据集和可验证的奖励机制，通过区域感知多模态链式思维推理提高了模型的解...|
|📝 更新|Global urban visual perception varies across demographics and personalities|全球城市视觉感知在不同人口统计学特征与个性之间存在差异|Matias Quintana, Youlong Gu, Xiucheng Liang, Yujun Hou, Koichi Ito, Yihan Zhu, Mahmoud Abdelrahman, Filip Biljecki|<http://arxiv.org/pdf/2505.12758v4>|揭示了不同人口统计特征和性格特质对城市视觉感知的影响，提出了考虑社会经济的街景评价新方法。|
|🆕 发布|Listening without Looking: Modality Bias in Audio-Visual Captioning|不听而观：视听字幕中的模态偏见|Yuchi Ishikawa, Toranosuke Manabe, Tatsuya Komatsu, Yoshimitsu Aoki|<http://arxiv.org/pdf/2510.24024v1>|揭示了现有音频视觉字幕模型中的模态偏差，并通过增强数据集减少了这种偏差。|
|📝 更新|From Objects to Anywhere: A Holistic Benchmark for Multi-level Visual Grounding in 3D Scenes|从物体到任意位置：三维场景中多层次视觉定位的全面基准|Tianxu Wang, Zhuofan Zhang, Ziyu Zhu, Yue Fan, Jing Xiong, Pengxiang Li, Xiaojian Ma, Qing Li|<http://arxiv.org/pdf/2506.04897v3>|提出 holistic 3D visual grounding 基准，涵盖不同层次空间与物体定位挑战...|
|📝 更新|PRISM-Bench: A Benchmark of Puzzle-Based Visual Tasks with CoT Error Detection|基于谜题的视觉任务基准测试与协同推理错误检测的PRISM-Bench|Yusu Qian, Cheng Wan, Chao Jia, Yinfei Yang, Qingyu Zhao, Zhe Gan|<http://arxiv.org/pdf/2510.23594v2>|提出了PRISM-Bench，一种评估视觉推理和错误检测能力的拼图基准，揭示了现有模型在逻辑推理上的...|
|📝 更新|CAUSAL3D: A Comprehensive Benchmark for Causal Learning from Visual Data|因果三维：一个用于从视觉数据中学习因果关系的全面基准|Disheng Liu, Yiran Qiao, Wuche Liu, Yiren Lu, Yunlai Zhou, Tuo Liang, Yu Yin, Jing Ma|<http://arxiv.org/pdf/2503.04852v2>|提出了Causal3D基准，结合视觉数据与结构化数据评估模型因果推理能力。|
|🆕 发布|TeleEgo: Benchmarking Egocentric AI Assistants in the Wild|《TeleEgo：在现实世界中评估第一视角AI助手的基准测试》|Jiaqi Yan, Ruilong Ren, Jingren Liu, Shuning Xu, Ling Wang, Yiheng Wang, Yun Wang, Long Zhang .etc.|<http://arxiv.org/pdf/2510.23981v1>|提出了TeleEgo，一个全面的基准测试，用于在真实日常环境中评估具有长期记忆和实时处理能力的 eg...|


### 多模态对话系统 (Multimodal Dialogue Systems)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|What do vision-language models see in the context? Investigating multimodal in-context learning|视觉语言模型在上下文中看到了什么？探讨多模态上下文学习|Gabriel O. dos Santos, Esther Colombini, Sandra Avila|<http://arxiv.org/pdf/2510.24331v1>|系统研究了视觉语言模型中的上下文学习，揭示了其多模态信息整合的局限性。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MIC-BEV: Multi-Infrastructure Camera Bird's-Eye-View Transformer with Relation-Aware Fusion for 3D Object Detection|MIC-BEV：基于多基础设施相机鸟瞰图变换器的关系感知融合三维目标检测|Yun Zhang, Zhaoliang Zheng, Johnson Liu, Zhiyu Huang, Zewei Zhou, Zonglin Meng, Tianhui Cai, Jiaqi Ma|<http://arxiv.org/pdf/2510.24688v1>|[代码](https://github.com/HandsomeYun/MIC-BEV.); 提出了一种基于Transformer的鸟瞰图感知框架MIC-BEV，通过关系感知融合实现了多相机3D...|
|📝 更新|Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond|《Sora是否为世界模拟器？关于通用世界模型及其超越的全面综述》|Zheng Zhu, Xiaofeng Wang, Wangbo Zhao, Chen Min, Bohan Li, Nianchen Deng, Min Dou, Yuqi Wang .etc.|<http://arxiv.org/pdf/2405.03520v2>|[代码](https://github.com/GigaAI-research/General-World-Models-Survey.); 系统梳理了通用世界模型的发展，特别关注Sora模型的仿真能力及其在自动驾驶和智能交互中的应用。|


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|50 Years of Water Body Monitoring: The Case of Qaraaoun Reservoir, Lebanon|《水体监测五十年：黎巴嫩卡拉翁水库的案例研究》|Ali Ahmad Faour, Nabil Amacha, Ali J. Ghandour|<http://arxiv.org/pdf/2510.24413v1>|提出了一种无传感器的水库容量监测方法，利用卫星图像和机器学习技术实时估算水库表面积和体积。|
|🆕 发布|When are radiology reports useful for training medical image classifiers?|放射学报告在训练医学图像分类器时何时有用？|Herman Bergström, Zhongqi Yue, Fredrik D. Johansson|<http://arxiv.org/pdf/2510.24385v1>|探究了放射学报告在训练医学图像分类器中的有效利用时机及方法，发现预训练和微调阶段结合报告可提升性能。|
|🆕 发布|A Luminance-Aware Multi-Scale Network for Polarization Image Fusion with a Multi-Scene Dataset|一种基于亮度感知的多尺度网络用于多场景数据集下的偏振图像融合|Zhuangfan Huang, Xiaosong Li, Gao Wang, Tao Ye, Haishu Tan, Huafeng Li|<http://arxiv.org/pdf/2510.24379v1>|[代码](https://github.com/1hzf/MLS-UNet.); 提出了一种亮度感知的多尺度网络，有效融合复杂光照下的偏振图像，显著提升了融合质量。|
|🆕 发布|Adaptive Knowledge Transferring with Switching Dual-Student Framework for Semi-Supervised Medical Image Segmentation|自适应知识迁移：基于切换双学生框架的半监督医学图像分割|Thanh-Huy Nguyen, Hoang-Thien Nguyen, Ba-Thinh Lam, Vi Vu, Bach X. Nguyen, Jianhua Xing, Tianyang Wang, Xingjian Li .etc.|<http://arxiv.org/pdf/2510.24366v1>|提出了一种切换双学生架构，通过选择最可靠的学生网络迭代增强协作，有效提升了半监督医学图像分割的准确性...|
|📝 更新|ImageNet-trained CNNs are not biased towards texture: Revisiting feature reliance through controlled suppression|《ImageNet训练的卷积神经网络对纹理并无偏见：通过控制抑制重新审视特征依赖》|Tom Burgert, Oliver Stoll, Paolo Rota, Begüm Demir|<http://arxiv.org/pdf/2509.20234v3>|[代码](https://github.com/tomburgert/feature-reliance.); 挑战了CNN对纹理的内在偏见观点，提出了一种量化特征依赖的通用框架，发现CNN主要依赖形状特征。|
|📝 更新|Federated Learning with Partially Labeled Data: A Conditional Distillation Approach|联邦学习中的部分标记数据：条件蒸馏方法|Pochuan Wang, Chen Shen, Masahiro Oda, Chiou-Shann Fuh, Kensaku Mori, Weichung Wang, Holger R. Roth|<http://arxiv.org/pdf/2412.18833v2>|提出了一种结合条件蒸馏的联邦学习方法ConDistFL，有效利用部分标注数据提升医学图像分割精度并保...|
|🆕 发布|CLFSeg: A Fuzzy-Logic based Solution for Boundary Clarity and Uncertainty Reduction in Medical Image Segmentation|CLFSeg：基于模糊逻辑的医学图像分割边界清晰度提升和不确定性降低解决方案|Anshul Kaushal, Kunal Jangid, Vinod K. Kurmi|<http://arxiv.org/pdf/2510.24202v1>|[代码](https://visdomlab.github.io/CLFSeg); 提出CLFSeg模型，融合模糊逻辑和卷积网络，提升医疗图像分割准确性和边界处理能力。|
|🆕 发布|Reasoning Visual Language Model for Chest X-Ray Analysis|用于胸部X射线分析的推理视觉语言模型|Andriy Myronenko, Dong Yang, Baris Turkbey, Mariam Aboian, Sena Azamat, Esra Akcicek, Hongxu Yin, Pavlo Molchanov .etc.|<http://arxiv.org/pdf/2510.23968v1>|引入链式思维推理，提升胸部X光分析的可解释性和临床审计性。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Few-Shot Remote Sensing Image Scene Classification with CLIP and Prompt Learning|少量样本遥感图像场景分类中的CLIP与提示学习应用|Ivica Dimitrovski, Vlatko Spasev, Ivan Kitanovski|<http://arxiv.org/pdf/2510.24321v1>|提出了一种基于prompt学习的远程感知图像场景分类方法，有效解决了少量样本场景下的域差距问题。|
|🆕 发布|ZTRS: Zero-Imitation End-to-end Autonomous Driving with Trajectory Scoring|零模仿端到端自动驾驶轨迹评分方法：ZTRS|Zhenxin Li, Wenhao Yao, Zi Wang, Xinglong Sun, Jingde Chen, Nadine Chang, Maying Shen, Jingyu Song .etc.|<http://arxiv.org/pdf/2510.24108v1>|[代码](https://github.com/woxihuanjiangguo/ZTRS.); 提出了一种无需模仿学习的端到端自动驾驶框架，通过强化学习直接处理原始传感器数据，实现了更稳健的规划性...|
|📝 更新|GRASP: Geospatial pixel Reasoning viA Structured Policy learning|GRASP：通过结构化策略学习进行地理空间像素推理|Chengjie Jiang, Yunqi Zhou, Jiafeng Yan, Jing Li, Jiayang Li, Yue Zhou, Hongjie He, Jonathan Li|<http://arxiv.org/pdf/2508.17102v2>|提出了一种结合强化学习和结构化策略学习的框架，有效解决了地理像素推理中的标注成本和泛化能力问题。|
|📝 更新|MsEdF: A Multi-stream Encoder-decoder Framework for Remote Sensing Image Captioning|多流编码器-解码器框架MsEdF：用于遥感图像标注|Swadhin Das, Raksha Sharma|<http://arxiv.org/pdf/2502.09282v4>|提出了一种多流编码器-解码器框架，通过融合多尺度特征和优化语义建模，提高了遥感图像描述的准确性和多样...|
|📝 更新|GaussianFusion: Gaussian-Based Multi-Sensor Fusion for End-to-End Autonomous Driving|高斯融合：基于高斯的多传感器融合用于端到端自动驾驶|Shuai Liu, Quanmin Liang, Zefeng Li, Boyang Li, Kai Huang|<http://arxiv.org/pdf/2506.00034v2>|[代码](https://github.com/Say2L/GaussianFusion.); 提出 GaussianFusion，一种基于高斯分布的多传感器融合框架，通过直观的高斯表示聚合信息，...|


### 创意媒体生成 (Creative Media Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Is It Certainly a Deepfake? Reliability Analysis in Detection & Generation Ecosystem|《这确实是深度伪造吗？检测与生成生态系统的可靠性分析》|Neslihan Kose, Anthony Rhodes, Umur Aybars Ciftci, Ilke Demir|<http://arxiv.org/pdf/2509.17550v3>|首次全面分析深度伪造检测器的不确定性，利用贝叶斯神经网络和蒙特卡洛dropout量化不确定性，以提升...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning|通过任务特定提示和空间推理增强自动驾驶中的视觉-语言模型|Aodi Wu, Xubo Luo|<http://arxiv.org/pdf/2510.24152v1>|[代码](https://github.com/wuaodi/UCAS-CSU-phase2.); 通过任务特定提示和空间推理增强视觉语言模型，显著提升自动驾驶场景理解性能。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 神经-符号视觉 (Neuro-symbolic Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FRBNet: Revisiting Low-Light Vision through Frequency-Domain Radial Basis Network|FRBNet：通过频域径向基网络重新审视低光照视觉|Fangtong Sun, Congyu Li, Ke Yang, Yuchen Pan, Hanwen Yu, Xichuan Zhang, Yiying Li|<http://arxiv.org/pdf/2510.23444v2>|[代码](https://github.com/Sing-Forevet/FRBNet.); 提出了一种频率域径向基网络FRBNet，通过提取光照不变特征显著提升了低光照条件下的图像处理性能。|
|🆕 发布|Kernelized Sparse Fine-Tuning with Bi-level Parameter Competition for Vision Models|基于核方法的稀疏微调与双层次参数竞争的视觉模型训练|Shufan Shen, Junshu Sun, Shuhui Wang, Qingming Huang|<http://arxiv.org/pdf/2510.24037v1>|[代码](https://github.com/ssfgunner/SNELL.); 提出了一种高效的参数调整方法SNELLA，通过引入双级参数竞争机制和核函数扩展低秩分解，实现了低内存...|


### 可解释视觉智能 (Explainable Visual Intelligence)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Caption-Driven Explainability: Probing CNNs for Bias via CLIP|基于标题的计算机视觉论文标题翻译如下：  “标题驱动的解释性：通过CLIP探测卷积神经网络中的偏见”|Patrick Koller, Amil V. Dravid, Guido M. Schuster, Aggelos K. Katsaggelos|<http://arxiv.org/pdf/2510.22035v2>|[代码](https://github.com/patch0816/caption-driven-xai); 提出了一种基于图像描述的XAI方法，通过整合CLIP模型揭示模型核心概念，增强模型鲁棒性。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Stealthy Patch-Wise Backdoor Attack in 3D Point Cloud via Curvature Awareness|曲率感知的3D点云中隐秘的块级后门攻击|Yu Feng, Dingxin Zhang, Runkai Zhao, Yong Xia, Heng Huang, Weidong Cai|<http://arxiv.org/pdf/2503.09336v3>|[代码](https://github.com/HazardFY/SPBA.); 提出了一种针对3D点云的局部区域隐秘后门攻击方法，通过曲率感知选择视觉不敏感区域注入触发器，提高了攻...|
|🆕 发布|Efficient Cost-and-Quality Controllable Arbitrary-scale Super-resolution with Fourier Constraints|具有傅里叶约束的效率、成本和质量可控的任意尺度超分辨率|Kazutoshi Akita, Norimichi Ukita|<http://arxiv.org/pdf/2510.23978v1>|提出了一种联合预测傅里叶分量方法，提高了任意尺度超分辨率图像的质量和效率。|

