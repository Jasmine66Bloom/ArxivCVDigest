## [UPDATED!] **2025-10-29** (Update Time)


## 视觉表征与基础模型 (Visual Representation & Foundation Models)


### 多模态表征学习 (Multimodal Representation Learning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks|多模态空间推理在大模型时代：综述与基准测试|Xu Zheng, Zihao Dongfang, Lutao Jiang, Boyuan Zheng, Yulong Guo, Zhenquan Zhang, Giuliano Albanese, Runyi Yang .etc.|<http://arxiv.org/pdf/2510.25760v1>|[代码](https://github.com/zhengxuJosh/Awesome-Spatial-Reasoning.); 系统综述了大型多模态模型在空间推理任务上的进展，并推出了公开评估基准。|
|🆕 发布|StreamingCoT: A Dataset for Temporal Dynamics and Multimodal Chain-of-Thought Reasoning in Streaming VideoQA|流式CoT：用于流式视频问答中的时序动态与多模态链式思维推理的数据集|Yuhang Hu, Zhenyu Yang, Shihan Wang, Shengsheng Qian, Bin Wen, Fan Yang, Tingting Gao, Changsheng Xu|<http://arxiv.org/pdf/2510.25332v1>|[代码](https://github.com/Fleeting-hyh/StreamingCoT.); 提出了StreamingCoT数据集，通过动态注释和显式推理链，增强视频理解与复杂推理能力。|
|📝 更新|DGTRSD & DGTRS-CLIP: A Dual-Granularity Remote Sensing Image-Text Dataset and Vision Language Foundation Model for Alignment|DGTRSD & DGTRS-CLIP：一种双粒度遥感图像-文本数据集与视觉语言基础模型对齐方法|Weizhi Chen, Yupeng Deng, Jin Wei, Jingbo Chen, Jiansheng Chen, Yuman Feng, Zhihao Xi, Diyou Liu .etc.|<http://arxiv.org/pdf/2503.19311v2>|[代码](https://github.com/MitsuiChen14/DGTRS.); 提出了DGTRSD数据集和DGTRS-CLIP模型，通过结合长短文本提升遥感图像语义对齐效果。|
|🆕 发布|RT-DETRv4: Painlessly Furthering Real-Time Object Detection with Vision Foundation Models|RT-DETRv4：轻松推动实时目标检测与视觉基础模型的发展|Zijun Liao, Yian Zhao, Xin Shan, Yu Yan, Chang Liu, Lei Lu, Xiangyang Ji, Jie Chen|<http://arxiv.org/pdf/2510.25257v1>|提出了一种高效且适应性强的知识蒸馏框架，利用视觉基础模型提升轻量级实时物体检测性能。|
|🆕 发布|Test-Time Adaptive Object Detection with Foundation Model|测试时基于基础模型的自适应目标检测|Yingjie Gao, Yanan Zhang, Zhi Cai, Di Huang|<http://arxiv.org/pdf/2510.25175v1>|[代码](https://github.com/gaoyingjay/ttaod_foundation.); 提出了一种无需源数据、基于基础模型的测试时自适应目标检测方法，有效克服了传统闭集限制并提升了跨域适应...|
|📝 更新|LightBagel: A Light-weighted, Double Fusion Framework for Unified Multimodal Understanding and Generation|轻量级双重融合框架：用于统一多模态理解和生成的LightBagel|Zeyu Wang, Zilong Chen, Chenhui Gou, Feng Li, Chaorui Deng, Deyao Zhu, Kunchang Li, Weihao Yu .etc.|<http://arxiv.org/pdf/2510.22946v2>|提出了一种高效的轻量级多模态融合框架，通过结合专业模型实现统一理解和生成，大幅提升性能同时降低资源需...|
|📝 更新|Unified Multimodal Chain-of-Thought Reward Model through Reinforcement Fine-Tuning|通过强化微调统一的跨模态思维链奖励模型|Yibin Wang, Zhimin Li, Yuhang Zang, Chunyu Wang, Qinglin Lu, Cheng Jin, Jiaqi Wang|<http://arxiv.org/pdf/2505.03318v3>|提出了一种统一的多模态长链推理奖励模型，通过强化微调激发模型复杂推理能力，提升奖励信号的准确性和鲁棒...|


### 大规模预训练模型 (Large-scale Pretrained Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FaCT: Faithful Concept Traces for Explaining Neural Network Decisions|FaCT：用于解释神经网络决策的忠实概念轨迹|Amin Parchami-Araghi, Sukrut Rao, Jonas Fischer, Bernt Schiele|<http://arxiv.org/pdf/2510.25512v1>|提出了一种忠实于模型内在机制的概念解释方法FaCT，通过共享概念和新的评价标准C$^2$-Score...|
|📝 更新|FastJAM: a Fast Joint Alignment Model for Images|快速联合对齐模型FastJAM：面向图像的|Omri Hirsch, Ron Shapira Weber, Shira Ifergane, Oren Freifeld|<http://arxiv.org/pdf/2510.22842v2>|[代码](https://bgu-cs-vil.github.io/FastJAM); 提出了FastJAM方法，通过图神经网络和快速非参数聚类大幅降低图像联合对齐的计算复杂度。|
|📝 更新|Multimodal Recurrent Ensembles for Predicting Brain Responses to Naturalistic Movies (Algonauts 2025)|多模态循环集成模型用于预测大脑对自然场景电影反应的研究（Algonauts 2025）|Semih Eren, Deniz Kucukahmetler, Nico Scherf|<http://arxiv.org/pdf/2507.17897v4>|提出了一种融合视觉、听觉和语义信息的多模态循环集成模型，有效预测大脑对自然场景的反应。|
|📝 更新|Open3D-VQA: A Benchmark for Comprehensive Spatial Reasoning with Multimodal Large Language Model in Open Space|开放3D-VQA：在开放空间中利用多模态大型语言模型进行综合空间推理的基准测试|Weichen Zhang, Zile Zhou, Xin Zeng, Xuchen Liu, Jianjie Fang, Chen Gao, Yong Li, Jinqiang Cui .etc.|<http://arxiv.org/pdf/2503.11094v3>|[代码](https://github.com/EmbodiedCity/Open3D-VQA.code.); 提出Open3D-VQA基准，评估大型多模态语言模型在开放空间中的综合空间推理能力。|
|🆕 发布|$D^2GS$: Dense Depth Regularization for LiDAR-free Urban Scene Reconstruction|$D^2GS$：无激光雷达的城市场景重建的密集深度正则化|Kejing Xia, Jidong Jia, Ke Jin, Yucai Bai, Li Sun, Dacheng Tao, Youjian Zhang|<http://arxiv.org/pdf/2510.25173v1>|提出无LiDAR城市场景重建框架，通过深度增强和几何优化实现高精度三维重建。|
|📝 更新|Why Foundation Models in Pathology Are Failing|病理学基础模型为何失败|Hamid R. Tizhoosh|<http://arxiv.org/pdf/2510.23807v2>|指出病理基础模型因与组织形态本质不匹配而存在缺陷，呼吁重新思考模型构建范式。|
|📝 更新|AI in Lung Health: Benchmarking Detection and Diagnostic Models Across Multiple CT Scan Datasets|人工智能在肺部健康中的应用：跨多个CT扫描数据集对检测与诊断模型进行基准测试|Fakrul Islam Tushar, Avivah Wang, Lavsen Dahal, Ehsan Samei, Michael R. Harowicz, Jayashree Kalpathy-Cramer, Kyle J. Lafata, Tina D. Tailor .etc.|<http://arxiv.org/pdf/2405.04605v4>|建立了标准化肺癌AI研究基准资源，提升了结节检测与分类模型的开发与验证效率。|
|🆕 发布|DRIP: Dynamic patch Reduction via Interpretable Pooling|DRIP: 通过可解释池化的动态补丁减少|Yusen Peng, Sachin Kumar|<http://arxiv.org/pdf/2510.25067v1>|提出DRIP方法，通过可解释池化动态合并视觉编码器深层 tokens，减少计算量同时保持性能。|


### 视觉Transformer架构 (Vision Transformer Architectures)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|A Study on Inference Latency for Vision Transformers on Mobile Devices|移动设备上视觉变换器推理延迟的研究|Zhuojin Li, Marco Paolieri, Leana Golubchik|<http://arxiv.org/pdf/2510.25166v1>|研究了移动设备上视觉变换器的性能，提出了一种准确预测新ViT延迟的方法。|
|🆕 发布|Towards Real-Time Inference of Thin Liquid Film Thickness Profiles from Interference Patterns Using Vision Transformers|面向实时推断薄液膜厚度剖面：利用视觉变换器从干涉图案中解析|Gautam A. Viruthagiri, Arnuv Tandon, Gerald G. Fuller, Vinny Chandran Suja|<http://arxiv.org/pdf/2510.25157v1>|提出了一种基于视觉变换器的实时液膜厚度推断方法，解决了传统重建方法速度慢、易受噪声影响的问题。|
|📝 更新|Pixel-Perfect Depth with Semantics-Prompted Diffusion Transformers|像素级完美深度：语义驱动的扩散变换器|Gangwei Xu, Haotong Lin, Hongcheng Luo, Xianqi Wang, Jingfeng Yao, Lianghui Zhu, Yuechuan Pu, Cheng Chi .etc.|<http://arxiv.org/pdf/2510.07316v2>|提出了一种避免飞点瑕疵的像素级深度估计模型，通过语义引导的扩散变换器实现高质量点云生成。|
|🆕 发布|Breast Cancer VLMs: Clinically Practical Vision-Language Train-Inference Models|乳腺癌VLMs：临床实用的视觉-语言训练-推理模型|Shunjie-Fabian Zheng, Hyeonjun Lee, Thijs Kooi, Ali Diba|<http://arxiv.org/pdf/2510.25051v1>|提出了一种结合视觉特征与文本描述的乳腺癌诊断模型，提升了癌症检测和钙化识别的准确性。|


## 视觉识别与理解 (Visual Recognition & Understanding)


### 目标检测与定位 (Object Detection & Localization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|U-DECN: End-to-End Underwater Object Detection ConvNet with Improved DeNoising Training|U-DECN：端到端水下目标检测卷积网络，具有改进的去噪训练|Zhuoyan Liu, Bo Wang, Bing Wang, Ye Li|<http://arxiv.org/pdf/2408.05780v2>|[代码](https://github.com/LEFTeyex/U-DECN.); 提出U-DECN模型，通过改进去噪训练有效应对水下环境挑战，实现快速准确的水下目标检测。|
|🆕 发布|Prototype-Driven Adaptation for Few-Shot Object Detection|原型驱动的少量样本目标检测适应方法|Yushen Huang, Zhiming Wang|<http://arxiv.org/pdf/2510.25318v1>|提出了一种轻量级原型驱动适配方法，有效缓解了少量样本下的检测偏差和校准不稳定问题。|
|🆕 发布|GaTector+: A Unified Head-free Framework for Gaze Object and Gaze Following Prediction|《GaTector+：一种统一的无头部框架，用于注视目标与注视跟随预测》|Yang Jin, Guangyu Guo, Binglu Wang|<http://arxiv.org/pdf/2510.25301v1>|提出了一种无需头部先验知识的统一框架 GaTector+，用于同时预测注视对象和注视跟踪任务。|
|🆕 发布|DINO-YOLO: Self-Supervised Pre-training for Data-Efficient Object Detection in Civil Engineering Applications|DINO-YOLO：面向土木工程应用的数据高效目标检测的自监督预训练|Malaisree P, Youwai S, Kitkobsin T, Janrungautai S, Amorndechaphon D, Rojanavasu P|<http://arxiv.org/pdf/2510.25140v1>|提出DINO-YOLO，结合YOLOv12与自监督DINOv3，实现数据高效的目标检测，提升土木工程...|
|🆕 发布|Region-CAM: Towards Accurate Object Regions in Class Activation Maps for Weakly Supervised Learning Tasks|面向弱监督学习任务中精确对象区域的目标：Region-CAM在类激活图中的应用|Qingdong Cai, Charith Abhayaratne|<http://arxiv.org/pdf/2510.25134v1>|提出Region-CAM方法，通过提取语义信息图并进行信息传播，更全面准确地标注对象区域，提升弱监督...|


### 图像分类与识别 (Image Classification & Recognition)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Single Image Estimation of Cell Migration Direction by Deep Circular Regression|深度循环回归的单幅图像细胞迁移方向估计|Lennart Bruns, Lucas Lamparter, Milos Galic, Xiaoyi Jiang|<http://arxiv.org/pdf/2406.19162v2>|提出了一种基于深度圆回归的细胞迁移方向估计方法，将平均误差降至约17度，显著优于之前的30度和34度...|
|🆕 发布|Mapping and Classification of Trees Outside Forests using Deep Learning|利用深度学习进行林外树木的映射与分类|Moritz Lucas, Hamid Ebrahimy, Viacheslav Barkov, Ralf Pecenka, Kai-Uwe Kühnberger, Björn Waske|<http://arxiv.org/pdf/2510.25239v1>|[代码](https://github.com/Moerizzy/TOFMapper); 利用深度学习对林外树木进行精细分类，提高了生态研究的准确性和适应性。|
|🆕 发布|Classifier Enhancement Using Extended Context and Domain Experts for Semantic Segmentation|使用扩展上下文和领域专家增强分类器进行语义分割|Huadong Tang, Youpeng Zhao, Min Xu, Jun Wang, Qiang Wu|<http://arxiv.org/pdf/2510.25174v1>|提出了一种动态调整分类器的Extended Context-Aware Classifier方法，利...|


### 关键点定位与姿态估计 (Keypoint Detection & Pose Estimation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|LangHOPS: Language Grounded Hierarchical Open-Vocabulary Part Segmentation|《LangHOPS：基于语言定位的分层开放词汇部件分割》|Yang Miao, Jan-Nico Zaech, Xi Wang, Fabien Despinoy, Danda Pani Paudel, Luc Van Gool|<http://arxiv.org/pdf/2510.25263v1>|提出LangHOPS框架，利用大型多模态语言模型实现开放词汇的对象-部分实例分割，达到领先性能。|


### 语义/实例分割 (Semantic/Instance Segmentation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Auto3DSeg for Brain Tumor Segmentation from 3D MRI in BraTS 2023 Challenge|自动3D脑肿瘤分割方法在BraTS 2023挑战中的磁共振成像应用|Andriy Myronenko, Dong Yang, Yufan He, Daguang Xu|<http://arxiv.org/pdf/2510.25058v1>|提出Auto3DSeg方法，在BraTS 2023挑战中实现脑肿瘤精准分割，多个任务取得领先成绩。|


## 生成式视觉模型 (Generative Visual Modeling)


### 扩散概率模型 (Diffusion Probabilistic Models)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RL-I2IT: Image-to-Image Translation with Deep Reinforcement Learning|深度强化学习驱动的图像到图像翻译：RL-I2IT|Jing Hu, Chengming Feng, Shu Hu, Ming-Ching Chang, Xin Li, Xi Wu, Xin Wang|<http://arxiv.org/pdf/2309.13672v8>|[代码](https://github.com/Algolzw/SPAC-Deformable-Registration.); 将图像翻译问题转化为逐步决策过程，提出基于深度强化学习的轻量级模型，有效处理高维连续动作空间挑战。|
|🆕 发布|Instance-Level Composed Image Retrieval|实例级组合图像检索|Bill Psomas, George Retsinas, Nikos Efthymiadis, Panagiotis Filntisis, Yannis Avrithis, Petros Maragos, Ondrej Chum, Giorgos Tolias|<http://arxiv.org/pdf/2510.25387v1>|提出了一种新的图像检索数据集i-CIR和无需训练的BASIC方法，提升了特定对象检索的准确性和效率。|
|🆕 发布|Seeing Clearly and Deeply: An RGBD Imaging Approach with a Bio-inspired Monocentric Design|《清晰而深入地观察：一种基于生物启发单中心设计的RGBD成像方法》|Zongxi Yu, Xiaolong Qian, Shaohua Gao, Qi Jiang, Yao Gao, Kailun Yang, Kaiwei Wang|<http://arxiv.org/pdf/2510.25314v1>|[代码](https://github.com/ZongxiYu-ZJU/BMI.); 提出了一种生物启发全球形光学设计，通过自然编码深度信息，实现了高保真度紧凑型RGBD成像。|
|🆕 发布|Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation|基于扩散驱动的渐进目标操纵的无源域自适应|Yuyang Huang, Yabo Chen, Junyu Zhou, Wenrui Dai, Xiaopeng Zhang, Junni Zou, Hongkai Xiong, Qi Tian|<http://arxiv.org/pdf/2510.25279v1>|提出了一种基于扩散驱动的渐进目标操纵框架，通过可靠生成和逐步优化伪目标域，有效解决了无源域自适应中的...|
|📝 更新|WaMaIR: Image Restoration via Multiscale Wavelet Convolutions and Mamba-based Channel Modeling with Texture Enhancement|瓦玛尔：通过多尺度小波卷积和基于曼巴的通道建模进行图像复原及纹理增强|Shengyu Zhu, Congyi Fan, Fuxuan Zhang|<http://arxiv.org/pdf/2510.16765v2>|提出WaMaIR框架，通过多尺度小波卷积和基于Mamba的通道建模增强图像纹理细节的恢复。|


### 条件式生成与编辑 (Conditional Generation & Editing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|FreeArt3D: Training-Free Articulated Object Generation using 3D Diffusion|无需训练的关节对象生成：基于三维扩散的FreeArt3D|Chuhao Chen, Isabella Liu, Xinyue Wei, Hao Su, Minghua Liu|<http://arxiv.org/pdf/2510.25765v1>|提出了无需训练的FreeArt3D框架，利用预训练的3D模型生成高质量的可活动三维物体。|
|🆕 发布|Hawk: Leveraging Spatial Context for Faster Autoregressive Text-to-Image Generation|鹰眼：利用空间上下文加速自回归文本到图像生成|Zhi-Kai Chen, Jun-Peng Jiang, Han-Jia Ye, De-Chuan Zhan|<http://arxiv.org/pdf/2510.25739v1>|利用图像的空间结构，Hawk方法加速了文本到图像的生成速度，同时保持了图像质量和多样性。|
|🆕 发布|VFXMaster: Unlocking Dynamic Visual Effect Generation via In-Context Learning|VFXMaster：通过上下文学习解锁动态视觉特效生成|Baolu Li, Yiming Zhang, Qinghe Wang, Liqian Ma, Xiaoyu Shi, Xintao Wang, Pengfei Wan, Zhenfei Yin .etc.|<http://arxiv.org/pdf/2510.25772v1>|VFXMaster通过将特效生成视为在上下文中的学习任务，实现了从参考视频到目标内容的多样化动态效果...|
|📝 更新|Quantizing Space and Time: Fusing Time Series and Images for Earth Observation|空间与时间的量化：融合时间序列与图像进行地球观测|Gianfranco Basile, Johannes Jakubik, Benedikt Blumenstiel, Thomas Brunschwiler, Juan Bernabe Moreno|<http://arxiv.org/pdf/2510.23118v3>|提出了一种跨模态融合时间序列和图像的通用框架，实现了从卫星图像生成全球温度分布的高效预测。|
|🆕 发布|RegionE: Adaptive Region-Aware Generation for Efficient Image Editing|区域E：自适应区域感知生成以提高图像编辑效率|Pengtao Chen, Xianfang Zeng, Maosen Zhao, Mingzhu Shen, Peng Ye, Bangyin Xiang, Zhibo Wang, Wei Cheng .etc.|<http://arxiv.org/pdf/2510.25590v1>|提出了一种自适应区域感知生成框架RegionE，通过区分编辑与未编辑区域优化图像编辑效率。|
|📝 更新|Activation Matching for Explanation Generation|激活匹配用于解释生成|Pirzada Suhail, Aditya Anand, Amit Sethi|<http://arxiv.org/pdf/2509.23051v2>|提出了一种基于激活匹配的生成最小化、忠实解释的方法，用于解释预训练分类器在图像上的决策过程。|
|📝 更新|MagicPortrait: Temporally Consistent Face Reenactment with 3D Geometric Guidance|《MagicPortrait：基于三维几何引导的时序一致面部再现》|Mengting Wei, Yante Li, Tuomas Varanka, Yan Jiang, Guoying Zhao|<http://arxiv.org/pdf/2504.21497v3>|[代码](https://github.com/weimengting/MagicPortrait.); 集成3D人脸参数模型于扩散框架，提升视频人脸重现的形状一致性和运动控制。|
|📝 更新|XY-Cut++: Advanced Layout Ordering via Hierarchical Mask Mechanism on a Novel Benchmark|XY-Cut++：基于新型基准的层次化掩码机制的高级布局排序|Shuai Liu, Youmeng Li, Jizeng Wei|<http://arxiv.org/pdf/2504.10258v2>|提出了一种集成预掩处理、多粒度分割和跨模态匹配的XY-Cut++方法，显著提升了复杂布局文档的阅读顺...|
|🆕 发布|Balanced conic rectified flow|平衡的圆锥正规流|Kim Shin Seong, Mingi Kwon, Jaeseok Jeong, Youngjung Uh|<http://arxiv.org/pdf/2510.25229v1>|提出了一种结合真实图像训练的改进型rectified flow方法，有效降低了对大量生成数据的依赖并...|
|🆕 发布|Target-Guided Bayesian Flow Networks for Quantitatively Constrained CAD Generation|目标引导的贝叶斯流网络用于定量约束的计算机辅助设计生成|Wenhao Zheng, Chenwei Sun, Wenbo Zhang, Jiancheng Lv, Xianggen Liu|<http://arxiv.org/pdf/2510.25163v1>|[代码](https://github.com/scu-zwh/TGBFN.); 提出了一种统一处理CAD序列多模态性的Target-Guided Bayesian Flow Net...|
|🆕 发布|Revisiting Reconstruction-based AI-generated Image Detection: A Geometric Perspective|重新审视基于重建的AI生成图像检测：几何视角分析|Wan Jiang, Jing Yan, Ruixuan Zhang, Xiaojing Chen, Changtao Miao, Zhe Li, Chenhao Lin, Yunfeng Diao .etc.|<http://arxiv.org/pdf/2510.25141v1>|提出了一种基于几何视角的动态重建误差检测方法ReGap，有效区分真实与生成图像，提高了AI生成图像的...|
|📝 更新|Depth-Aware Super-Resolution via Distance-Adaptive Variational Formulation|基于距离自适应变分公式的深度感知超分辨率|Tianhao Guo, Bingjie Lu, Feng Wang, Zhengyang Lu|<http://arxiv.org/pdf/2509.05746v2>|提出了一种深度感知的超分辨率方法，通过距离自适应的变分框架显著提升了复杂场景的重建性能。|
|🆕 发布|PSTF-AttControl: Per-Subject-Tuning-Free Personalized Image Generation with Controllable Face Attributes|《PSTF-AttControl：无需个体微调的具有可控面部属性的个人化图像生成方法》|Xiang liu, Zhaoxiang Liu, Huan Hu, Zipeng Wang, Ping Chen, Zezhou Chen, Kai Wang, Shiguo Lian|<http://arxiv.org/pdf/2510.25084v1>|[代码](https://github.com/UnicomAI/PSTF-AttControl.); 提出了一种无需个体微调的高保真个性化图像生成方法，实现了对脸部属性的精细控制。|


### 时空一致性生成 (Spatiotemporal Coherent Generation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|More than a Moment: Towards Coherent Sequences of Audio Descriptions|超越瞬间：迈向连贯的音频描述序列|Eshika Khandelwal, Junyu Xie, Tengda Han, Max Bain, Arsha Nagrani, Andrew Zisserman, Gül Varol, Makarand Tapaswi|<http://arxiv.org/pdf/2510.25440v1>|提出了一种无需训练的方法CoherentAD，通过自动选择生成连贯且信息丰富的音频描述序列，解决了传...|
|🆕 发布|U-CAN: Unsupervised Point Cloud Denoising with Consistency-Aware Noise2Noise Matching|U-CAN：基于一致性感知的噪声对噪声匹配的无监督点云去噪|Junsheng Zhou, Xingyu Shi, Haichuan Song, Yi Fang, Yu-Shen Liu, Zhizhong Han|<http://arxiv.org/pdf/2510.25210v1>|提出了一种无需标注数据的点云去噪方法U-CAN，通过噪声匹配和一致性约束实现高效去噪。|


## 三维视觉与几何推理 (3D Vision & Geometric Reasoning)


### 多视图几何重建 (Multi-view Geometric Reconstruction)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|MILo: Mesh-In-the-Loop Gaussian Splatting for Detailed and Efficient Surface Reconstruction|MILo：基于网格循环的高斯散点投射法用于详细且高效表面重建|Antoine Guédon, Diego Gomez, Nissim Maruani, Bingchen Gong, George Drettakis, Maks Ovsjanikov|<http://arxiv.org/pdf/2506.24096v2>|MILo通过将高斯分布直接转换为表面网格，实现了高效且细节丰富的三维场景重建。|
|📝 更新|HF-VTON: High-Fidelity Virtual Try-On via Consistent Geometric and Semantic Alignment|HF-VTON：通过一致几何与语义对齐的高保真虚拟试穿|Ming Meng, Qi Dong, Jiajie Li, Zhe Zhu, Xingyu Wang, Zhaoxin Fan, Wei Zhao, Wenjun Wu|<http://arxiv.org/pdf/2505.19638v3>|提出了一种高保真虚拟试穿框架HF-VTON，通过几何与语义一致性对齐，解决了多姿态下的视觉一致性问题...|
|🆕 发布|EA3D: Online Open-World 3D Object Extraction from Streaming Videos|EA3D：在线开放世界三维物体提取自流视频|Xiaoyu Zhou, Jingqi Wang, Yuang Jia, Yongtao Wang, Deqing Sun, Ming-Hsuan Yang|<http://arxiv.org/pdf/2510.25146v1>|提出了一种在线开放世界三维物体提取框架，实现了几何重建和场景理解的统一处理。|
|🆕 发布|AtlasGS: Atlanta-world Guided Surface Reconstruction with Implicit Structured Gaussians|《AtlasGS：亚特兰大世界引导的隐式结构高斯表面重建》|Xiyu Zhang, Chong Bao, Yipeng Chen, Hongjia Zhai, Yitong Dong, Hujun Bao, Zhaopeng Cui, Guofeng Zhang|<http://arxiv.org/pdf/2510.25129v1>|提出了一种结合Atlanta-world模型和隐式结构高斯散布的方法，实现了室内外场景的高效平滑重建...|


### 神经辐射场表示 (Neural Radiance Field Representation)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HAIF-GS: Hierarchical and Induced Flow-Guided Gaussian Splatting for Dynamic Scene|HAIF-GS：分层与诱导流引导的高斯散点绘制方法用于动态场景|Jianing Chen, Zehao Li, Yujun Cai, Hao Jiang, Chengxuan Qian, Juyuan Kang, Shuqin Gao, Honglong Zhao .etc.|<http://arxiv.org/pdf/2506.09518v2>|提出HAIF-GS框架，通过稀疏锚点驱动建模，有效提升了动态场景的实时三维重建质量与效率。|


### 视觉定位与映射 (Visual Localization & Mapping)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|SPADE: Sparsity Adaptive Depth Estimator for Zero-Shot, Real-Time, Monocular Depth Estimation in Underwater Environments|SPADEF：适用于零样本、实时、单目水下环境深度估计的稀疏性自适应深度估计器|Hongjie Zhang, Gideon Billings, Stefan B. Williams|<http://arxiv.org/pdf/2510.25463v1>|提出了一种结合预训练相对深度估计器和稀疏深度先验的单目深度估计方法，实现了水下环境中高效准确的深度映...|


## 时序视觉分析 (Temporal Visual Analysis)


### 长时序视频理解 (Long-term Video Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO|深度视频R1：基于难度感知回归GRPO的视频强化微调|Jinyoung Park, Jeehye Na, Jinyoung Kim, Hyunwoo J. Kim|<http://arxiv.org/pdf/2506.07464v3>|提出DeepVideo-R1模型，通过回归GRPO和难度感知数据增强，改善视频大语言模型的推理能力。|


### 动作识别与理解 (Action Recognition & Understanding)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Informative Sample Selection Model for Skeleton-based Action Recognition with Limited Training Samples|基于有限训练样本的骨架动作识别中的信息样本选择模型|Zhigang Tu, Zhengbo Zhang, Jia Gong, Junsong Yuan, Bo Du|<http://arxiv.org/pdf/2510.25345v1>|提出了一种基于马尔可夫决策过程的样本选择模型，通过智能选取标注样本，提高了3D动作识别的准确率。|


### 视频目标跟踪 (Video Object Tracking)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|VADB: A Large-Scale Video Aesthetic Database with Professional and Multi-Dimensional Annotations|视频美学数据库VADB：具有专业性和多维度标注的大规模视频库|Qianqian Qiao, DanDan Zheng, Yihang Bo, Bao Peng, Heng Huang, Longteng Jiang, Huaye Wang, Jingdong Chen .etc.|<http://arxiv.org/pdf/2510.25238v1>|[代码](https://github.com/BestiVictory/VADB.); 构建大规模视频审美数据库VADB，并设计双模态预训练框架VADB-Net，提升视频审美评估性能。|


## 自监督与表征学习 (Self-supervised & Representation Learning)


### 对比学习方法 (Contrastive Learning Methods)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|InstDrive: Instance-Aware 3D Gaussian Splatting for Driving Scenes|实例驱动：面向驾驶场景的实例感知三维高斯散点绘制|Hongyuan Liu, Haochen Yu, Bochao Zou, Jianfei Jiang, Qiankun Liu, Jiansheng Chen, Huimin Ma|<http://arxiv.org/pdf/2508.12015v2>|提出了一种针对动态驾驶场景的实例感知3D高斯散点框架，实现了开放世界驾驶场景的3D实例分割。|


## 计算效率与模型优化 (Computational Efficiency & Model Optimization)


### 神经架构优化 (Neural Architecture Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|GENRE-CMR: Generalizable Deep Learning for Diverse Multi-Domain Cardiac MRI Reconstruction|GENRE-CMR：多样化多域心脏磁共振成像重建的泛化深度学习|Kian Anvari Hamedani, Narges Razizadeh, Shahabedin Nabavi, Mohsen Ebrahimi Moghaddam|<http://arxiv.org/pdf/2508.20600v2>|提出了一种基于生成对抗网络的CMR图像重建框架，通过残差连接和定制损失函数提升了重建质量和泛化能力。|


### 模型压缩与加速 (Model Compression & Acceleration)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Feedback Alignment Meets Low-Rank Manifolds: A Structured Recipe for Local Learning|反馈对齐遇见低秩流形：一种用于局部学习的结构化配方|Arani Roy, Marco P. Apolinario, Shristi Das Biswas, Kaushik Roy|<http://arxiv.org/pdf/2510.25594v1>|提出了一种在低秩流形上进行的结构化局部学习框架，以减少参数数量并实现与全梯度训练相当的准确度。|
|📝 更新|DPMambaIR: All-in-One Image Restoration via Degradation-Aware Prompt State Space Model|DPMambaIR：通过退化感知提示状态空间模型实现一站式图像复原|Zhanwen Liu, Sai Zhou, Yuchao Dai, Yang Wang, Yisheng An, Xiangmo Zhao|<http://arxiv.org/pdf/2504.17732v2>|提出了DPMambaIR框架，通过细粒度退化提取器和退化感知提示状态空间模型，实现了单一模型对多种图...|


### 推理优化 (Inference Optimization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding|MMEdge：通过管道化感知与编码加速设备端多模态推理|Runxi Huang, Mingxuan Yu, Mingyu Tsoi, Xiaomin Ouyang|<http://arxiv.org/pdf/2510.25327v1>|提出了一种基于流水线感知和编码的边缘设备多模态推理框架，通过分解推理过程和动态优化配置，显著降低了延...|


### 资源受限视觉计算 (Resource-constrained Visual Computing)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models|HyperET：用于多模态大型语言模型的双曲空间高效训练|Zelin Peng, Zhengqin Xu, Qingyang Liu, Xiaokang Yang, Wei Shen|<http://arxiv.org/pdf/2510.20322v2>|提出了一种在双曲空间中训练多模态大语言模型的HyperET方法，通过动态调整双曲半径实现视觉与文本在...|
|📝 更新|Vision-Centric 4D Occupancy Forecasting and Planning via Implicit Residual World Models|基于视觉的4D占用预测与规划：隐式残差世界模型方法|Jianbiao Mei, Yu Yang, Xuemeng Yang, Licheng Wen, Jiajun Lv, Botian Shi, Yong Liu|<http://arxiv.org/pdf/2510.16729v2>|提出了一种隐式残差世界模型，专注于预测动态变化而非完整重构未来场景，显著提升了自动驾驶系统中的占位预...|


## 鲁棒性与可靠性 (Robustness & Reliability)


### 分布外泛化 (Out-of-distribution Generalization)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Simulating Automotive Radar with Lidar and Camera Inputs|利用激光雷达和摄像头输入模拟汽车雷达|Peili Song, Dezhen Song, Yifan Yang, Enfan Lan, Jingtai Liu|<http://arxiv.org/pdf/2503.08068v2>|提出了一种利用相机图像和激光雷达数据模拟毫米波雷达信号的新方法，有效解决了雷达数据不足问题。|
|📝 更新|Probabilistic Kernel Function for Fast Angle Testing|概率核函数在快速角度测试中的应用|Kejing Lu, Chuan Xiao, Yoshiharu Ishikawa|<http://arxiv.org/pdf/2505.20274v2>|提出基于参考角度的概率核函数，提高高维空间相似性搜索效率，实现查询速度大幅提升。|
|📝 更新|NoisyGRPO: Incentivizing Multimodal CoT Reasoning via Noise Injection and Bayesian Estimation|噪声注入与贝叶斯估计激励的多模态协同推理|Longtian Qiu, Shan Ning, Jiaxuan Sun, Xuming He|<http://arxiv.org/pdf/2510.21122v2>|[代码](https://artanic30.github.io/project_pages); 引入可控噪声和贝叶斯估计以增强多模态大语言模型的泛化能力和鲁棒性。|


## 低资源与高效学习 (Low-resource & Efficient Learning)


### 主动学习策略 (Active Learning Strategies)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|3D CT-Based Coronary Calcium Assessment: A Feature-Driven Machine Learning Framework|基于三维CT的冠状动脉钙化评估：一种特征驱动的机器学习框架|Ayman Abaid, Gianpiero Guidone, Sara Alsubai, Foziyah Alquahtani, Talha Iqbal, Ruth Sharif, Hesham Elzomor, Emiliano Bianchini .etc.|<http://arxiv.org/pdf/2510.25347v1>|提出了一种基于伪标签和预训练模型的冠脉钙化评分方法，无需专家标注即可高效预测冠脉疾病风险。|
|🆕 发布|Learning Disentangled Speech- and Expression-Driven Blendshapes for 3D Talking Face Animation|学习解耦的语音和表情驱动的混合形状用于三维说话面部动画|Yuxiang Mao, Zhijie Zhang, Zhiheng Zhang, Jiawei Liu, Chen Zeng, Shihong Xia|<http://arxiv.org/pdf/2510.25234v1>|提出了一种将语音和情感分离建模的方法，实现了具有指定表情的自然3D说话面部动画。|
|🆕 发布|Mask-Robust Face Verification for Online Learning via YOLOv5 and Residual Networks|通过YOLOv5和残差网络实现在线学习中的口罩鲁棒人脸验证|Zhifeng Wang, Minghui Wang, Chunyan Zeng, Jialong Yao, Yang Yang, Hongmin Xu|<http://arxiv.org/pdf/2510.25184v1>|提出了一种结合YOLOv5和残差网络的在线学习身份验证方法，增强了在线教育的安全性和稳定性。|
|📝 更新|Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models|“思考或不然？基于强化学习的视觉语言模型选择性推理”|Jiaqi Wang, Kevin Qinghong Lin, James Cheng, Mike Zheng Shou|<http://arxiv.org/pdf/2505.16854v3>|[代码](https://github.com/kokolerk/TON.); 提出选择性推理策略TON，通过先判断再推理，显著减少计算量而不牺牲性能。|


## 具身智能与交互视觉 (Embodied Intelligence & Interactive Vision)


### 视觉操作与控制 (Visual Manipulation & Control)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|RoboOmni: Proactive Robot Manipulation in Omni-modal Context|罗博全模：全模态环境下的主动机器人操控|Siyin Wang, Jinlan Fu, Feihong Liu, Xinzhe He, Huangxuan Wu, Junhao Shi, Kexin Huang, Zhaoye Fei .etc.|<http://arxiv.org/pdf/2510.23763v2>|提出了一种融合听觉和视觉信号的机器人主动意图识别与执行框架，有效提升了机器人对用户隐含意图的理解和响...|
|🆕 发布|SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation|《SynHLMA：利用离散人机交互表示合成关节对象的手语操作》|Wang zhi, Yuyan Liu, Liu Liu, Li Zhang, Ruixuan Lu, Dan Guo|<http://arxiv.org/pdf/2510.25268v1>|提出SynHLMA框架，通过离散人对象交互表示生成符合语言描述的手部操作序列，实现关节对象的长效互动...|
|📝 更新|RoboCerebra: A Large-scale Benchmark for Long-horizon Robotic Manipulation Evaluation|"RoboCerebra：长时机器人操作评估的大规模基准"|Songhao Han, Boxiang Qiu, Yue Liao, Siyuan Huang, Chen Gao, Shuicheng Yan, Si Liu|<http://arxiv.org/pdf/2506.06677v2>|提出了RoboCerebra，一个用于评估长时机器人操作中高级推理的大规模基准，结合了高级行为规划与...|


## 视觉-语言协同理解 (Vision-Language Joint Understanding)


### 视觉问答与推理 (Visual Question Answering & Reasoning)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FOCUS: Internal MLLM Representations for Efficient Fine-Grained Visual Question Answering|FOCUS：用于高效细粒度视觉问答的内部多模态语言模型表示|Liangyu Zhong, Fabio Rosenthal, Joachim Sicking, Fabian Hüger, Thorsten Bagdonat, Hanno Gottschalk, Leo Schwinn|<http://arxiv.org/pdf/2506.21710v2>|提出了一种无需训练的视觉裁剪方法FOCUS，利用大型多模态语言模型内部表示来高效定位图像细节，提升细...|
|📝 更新|InfoChartQA: A Benchmark for Multimodal Question Answering on Infographic Charts|信息图表问答：面向信息图表的多模态问答基准|Tianchi Xie, Minzhi Lin, Mengchen Liu, Yilin Ye, Changjian Chen, Shixia Liu|<http://arxiv.org/pdf/2505.19028v4>|[代码](https://github.com/CoolDawnAnt/InfoChartQA.); 提出了InfoChartQA基准，用于评估大型语言模型在理解信息图表方面的能力，并揭示了模型在处理视...|
|🆕 发布|Visual Diversity and Region-aware Prompt Learning for Zero-shot HOI Detection|零样本人体动作检测中的视觉多样性与区域感知提示学习|Chanhyeong Yang, Taehoon Song, Jihwan Park, Hyunwoo J. Kim|<http://arxiv.org/pdf/2510.25094v1>|[代码](https://github.com/mlvlab/VDRP.); 提出VDRP框架，通过视觉多样性和区域感知提示学习，有效处理零样本人类-物体交互检测中的视觉复杂性问...|
|🆕 发布|Vision-Language Integration for Zero-Shot Scene Understanding in Real-World Environments|面向现实世界环境的零样本场景理解中的视觉-语言一体化|Manjunath Prasad Holenarasipura Rajiv, B. M. Vidyavathi|<http://arxiv.org/pdf/2510.25070v1>|提出了一种融合视觉编码器和语言模型的框架，实现了无需标注样本即可理解现实世界场景的零样本学习能力。|


## 领域特定视觉应用 (Domain-specific Visual Applications)


### 医学影像分析 (Medical Image Analysis)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Comparative Study of UNet-based Architectures for Liver Tumor Segmentation in Multi-Phase Contrast-Enhanced Computed Tomography|基于UNet架构在多相位增强计算机断层扫描中肝脏肿瘤分割的比较研究|Doan-Van-Anh Ly, Thi-Thu-Hien Pham, Thanh-Hai Le|<http://arxiv.org/pdf/2510.25522v1>|探究了UNet架构在肝肿瘤分割中的应用，发现结合ResNet和CBAM注意力的模型性能最优。|
|📝 更新|ScribbleVS: Scribble-Supervised Medical Image Segmentation via Dynamic Competitive Pseudo Label Selection|“ScribbleVS：通过动态竞争伪标签选择实现的scribble监督医学图像分割”|Tao Wang, Xinlin Zhang, Zhenxuan Zhang, Yuanbo Zhou, Yuanbin Chen, Longxuan Zhao, Chaohui Xu, Shun Chen .etc.|<http://arxiv.org/pdf/2411.10237v2>|[代码](https://github.com/ortonwang/ScribbleVS.); 提出 ScribbleVS 框架，通过动态竞争伪标签选择，利用 Scribble 注解高效训练医学图...|
|📝 更新|Classification of Driver Behaviour Using External Observation Techniques for Autonomous Vehicles|使用外部观测技术对自动驾驶车辆驾驶员行为进行分类|Ian Nell, Shane Gilroy|<http://arxiv.org/pdf/2509.09349v2>|提出了一种利用外部观测技术对驾驶员行为进行分类的系统，通过实时对象跟踪和车道位置监测识别不安全驾驶行...|
|📝 更新|When are radiology reports useful for training medical image classifiers?|放射学报告在训练医学图像分类器时何时有用？|Herman Bergström, Zhongqi Yue, Fredrik D. Johansson|<http://arxiv.org/pdf/2510.24385v2>|探究了何时及如何利用放射学报告辅助训练医学图像分类器，发现预训练与微调结合报告数据可提升性能。|
|🆕 发布|DeepShield: Fortifying Deepfake Video Detection with Local and Global Forgery Analysis|深度护盾：通过局部与全局伪造分析强化深度伪造视频检测|Yinqi Cai, Jichang Li, Zhaolun Li, Weikai Chen, Rushi Lan, Xi Xie, Xiaonan Luo, Guanbin Li|<http://arxiv.org/pdf/2510.25237v1>|提出DeepShield框架，结合局部敏感性和全局泛化能力，增强对抗未见深伪攻击的鲁棒性。|
|🆕 发布|Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation|将分离的内容对齐：用于无源域自适应医学图像分割的去噪补丁混合方法|Quang-Khai Bui-Tran, Thanh-Huy Nguyen, Hoang-Thien Nguyen, Ba-Thinh Lam, Nguyen Lan Vi Vu, Phat K. Huynh, Ulas Bagci, Min Xu|<http://arxiv.org/pdf/2510.25227v1>|提出了一种结合难样本选择和去噪块混合的源自由域自适应框架，有效应对隐私限制下的医学图像分割问题。|
|📝 更新|Diverse Teaching and Label Propagation for Generic Semi-Supervised Medical Image Segmentation|多样化教学与标签传播在通用半监督医学图像分割中的应用|Wei Li, Pengcheng Zhou, Linye Ma, Wenyi Zhao, Huihua Yang, Yuchen Guo|<http://arxiv.org/pdf/2508.08549v3>|提出了一种通用框架DTLP-Net，通过多样教学和标签传播提高半监督医疗图像分割的鲁棒性和准确性。|
|🆕 发布|AI-Powered Early Detection of Critical Diseases using Image Processing and Audio Analysis|基于图像处理和音频分析的AI辅助重大疾病早期检测|Manisha More, Kavya Bhand, Kaustubh Mukdam, Kavya Sharma, Manas Kawtikwar, Hridayansh Kaware, Prajwal Kavhar|<http://arxiv.org/pdf/2510.25199v1>|提出了一种集成图像、热成像和音频分析的轻量级AI框架，实现低成本、非侵入性重大疾病早期诊断。|
|🆕 发布|Transformers in Medicine: Improving Vision-Language Alignment for Medical Image Captioning|医学中的变换器：提高医学图像字幕生成中的视觉-语言对齐|Yogesh Thakku Suresh, Vishwajeet Shivaji Hogale, Luca-Alexandru Zamfira, Anandavardhana Hegde|<http://arxiv.org/pdf/2510.25164v1>|提出了一种基于Transformer的医学图像描述生成框架，通过特定领域数据训练显著提升了描述准确性...|


### 工业视觉检测 (Industrial Visual Inspection)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|FutureSightDrive: Thinking Visually with Spatio-Temporal CoT for Autonomous Driving|未来视驾：利用空间时间协同思维视觉进行自动驾驶|Shuang Zeng, Xinyuan Chang, Mengwei Xie, Xinran Liu, Yifan Bai, Zheng Pan, Mu Xu, Xing Wei|<http://arxiv.org/pdf/2505.17685v2>|[代码](https://github.com/MIV-XJTU/FSDrive.); 提出视觉空间时间链式思维框架FSDrive，通过生成统一未来帧，缩小感知与规划间的跨模态差距，提升自...|


### 智能交通视觉 (Intelligent Transportation Vision)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Evaluation of Safety Cognition Capability in Vision-Language Models for Autonomous Driving|自动驾驶视觉语言模型安全性认知能力的评估|Enming Zhang, Peizhe Gong, Xingyuan Dai, Min Huang, Yisheng Lv, Qinghai Miao|<http://arxiv.org/pdf/2503.06497v3>|提出SCD-Bench评估框架和ADA半自动化标注系统，提升自动驾驶视觉语言模型的安全性认知能力。|


### 遥感与地理信息 (Remote Sensing & Geospatial Information)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|L2RSI: Cross-view LiDAR-based Place Recognition for Large-scale Urban Scenes via Remote Sensing Imagery|基于遥感影像的大规模城市场景跨视角激光雷达位置识别：L2RSI|Ziwei Shi, Xiaoran Zhang, Wenjing Xu, Yan Xia, Yu Zang, Siqi Shen, Cheng Wang|<http://arxiv.org/pdf/2503.11245v4>|[代码](https://shizw695.github.io/L2RSI); 提出了一种利用高分辨率遥感影像进行跨视角激光雷达定位的方法，实现了低成本的大规模场景定位。|
|🆕 发布|Neighborhood Feature Pooling for Remote Sensing Image Classification|遥感图像分类中的邻域特征池化方法|Fahimeh Orvati Nia, Amirmohammad Mohammadi, Salim Al Kharsa, Pragati Naikare, Zigfried Hampel-Arias, Joshua Peeples|<http://arxiv.org/pdf/2510.25077v1>|提出邻域特征池化方法，提升遥感图像分类性能且参数负担小。|


## 新兴理论与跨学科方向 (Emerging Theory & Interdisciplinary Directions)


### 量子视觉算法 (Quantum Visual Algorithms)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|Prompt Estimation from Prototypes for Federated Prompt Tuning of Vision Transformers|从原型进行提示估计以实现视觉变换器的联邦提示微调|M Yashwanth, Sharannya Ghosh, Aditay Tripathi, Anirban Chakraborty|<http://arxiv.org/pdf/2510.25372v1>|提出PEP-FedPT框架，通过类特定提示和全局提示结合，实现联邦学习下的视觉Transformer...|


### 可解释视觉智能 (Explainable Visual Intelligence)

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|📝 更新|Caption-Driven Explainability: Probing CNNs for Bias via CLIP|基于标题的计算机视觉论文标题翻译如下：  “标题驱动的解释性：通过CLIP探测卷积神经网络中的偏见”|Patrick Koller, Amil V. Dravid, Guido M. Schuster, Aggelos K. Katsaggelos|<http://arxiv.org/pdf/2510.22035v3>|[代码](https://github.com/patch0816/caption-driven-xai); 提出了一种基于图像描述的XAI方法，通过整合CLIP模型揭示模型预测的主导概念，增强模型鲁棒性。|


## 其他 (Others)


### 未分类

|状态|英文标题|中文标题|作者|PDF链接|代码/贡献|
|---|---|---|---|---|---|
|🆕 发布|MSF-Net: Multi-Stage Feature Extraction and Fusion for Robust Photometric Stereo|MSF-Net：多阶段特征提取与融合的稳健光度立体算法|Shiyu Qin, Zhihao Cai, Kaixuan Wang, Lin Qi, Junyu Dong|<http://arxiv.org/pdf/2510.25221v1>|提出多阶段特征提取与融合的MSF-Net，有效提升表面法线估计的准确性。|
|📝 更新|Graph-Theoretic Consistency for Robust and Topology-Aware Semi-Supervised Histopathology Segmentation|图论一致性用于鲁棒且拓扑感知的半监督组织病理学分割|Ha-Hieu Pham, Minh Le, Han Huynh, Nguyen Quoc Khanh Le, Huy-Hieu Pham|<http://arxiv.org/pdf/2509.22689v2>|提出了一种基于图论约束的半监督分割框架，有效提高了病理图像分割的准确性和拓扑一致性。|

