## [UPDATED!] **2025-11-25** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|RubricRL: Simple Generalizable Rewards for Text-to-Image Generation|RubricRLï¼šç”¨äºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„ç®€å•é€šç”¨å¥–åŠ±å‡½æ•°|Xuelu Feng, Yunsheng Li, Ziyu Wan, Zixuan Gao, Junsong Yuan, Dongdong Chen, Chunming Qiao|<https://arxiv.org/pdf/2511.20651v1>|æå‡ºäº†ä¸€ç§åŸºäºç»†ç²’åº¦è¯„åˆ†æ ‡å‡†çš„RubricRLæ–¹æ³•ï¼Œæé«˜äº†æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œçµæ´»æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|New York Smells: A Large Multimodal Dataset for Olfaction|ã€Šçº½çº¦çš„æ°”æ¯ï¼šä¸€ä¸ªç”¨äºå—…è§‰ç ”ç©¶çš„å¤§å‹å¤šæ¨¡æ€æ•°æ®é›†ã€‹|Ege Ozguroglu, Junbang Liang, Ruoshi Liu, Mia Chiquier, Michael DeTienne, Wesley Wei Qian, Alexandra Horowitz, Andrew Owens .etc.|<https://arxiv.org/pdf/2511.20544v1>|æ„å»ºäº†é¦–ä¸ªå¤§è§„æ¨¡è‡ªç„¶åœºæ™¯ä¸‹çš„æ°”å‘³-å›¾åƒé…å¯¹æ•°æ®é›†ï¼Œå®ç°äº†è·¨æ¨¡æ€å—…è§‰è¡¨å¾å­¦ä¹ ã€‚|
|ğŸ“ æ›´æ–°|ConceptGuard: Proactive Safety in Text-and-Image-to-Video Generation through Multimodal Risk Detection|ConceptGuardï¼šé€šè¿‡å¤šæ¨¡æ€é£é™©æ£€æµ‹å®ç°æ–‡æœ¬-å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆçš„ä¸»åŠ¨å®‰å…¨é˜²æŠ¤|Ruize Ma, Minghong Cai, Yilei Jiang, Jiaming Han, Yi Feng, Yingshui Tan, Xiaoyong Zhu, Bo Zhang .etc.|<https://arxiv.org/pdf/2511.18780v2>|[ä»£ç ](https://github.com/Ruize-Ma/ConceptGuard.); æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„å®‰å…¨é˜²æŠ¤æ¡†æ¶ConceptGuardï¼Œé€šè¿‡å¯¹æ¯”æ£€æµ‹å’Œè¯­ä¹‰æŠ‘åˆ¶ä¸»åŠ¨è¯†åˆ«å’Œå‡è½»å¤šæ¨¡æ€è§†é¢‘...|
|ğŸ†• å‘å¸ƒ|HBridge: H-Shape Bridging of Heterogeneous Experts for Unified Multimodal Understanding and Generation|HBridgeï¼šå¼‚è´¨ä¸“å®¶çš„Hå½¢æ¡¥æ¥ç”¨äºç»Ÿä¸€çš„å¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆ|Xiang Wang, Zhifei Zhang, He Zhang, Zhe Lin, Yuqian Zhou, Qing Liu, Shiwei Zhang, Yijun Li .etc.|<https://arxiv.org/pdf/2511.20520v1>|æå‡ºHBridgeæ¶æ„ï¼Œé€šè¿‡ä¸å¯¹ç§°Hå‹ç»“æ„ä¼˜åŒ–å¼‚è´¨ä¸“å®¶é—´çš„æ¨¡æ€èåˆï¼Œæå‡å¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆæ•ˆç‡ã€‚|
|ğŸ†• å‘å¸ƒ|VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning|VibraVerseï¼šä¸€ç§ç”¨äºç‰©ç†ä¸€è‡´å¤šæ¨¡æ€å­¦ä¹ çš„å¤§è§„æ¨¡å‡ ä½•å£°å­¦å¯¹é½æ•°æ®é›†|Bo Pang, Chenxi Xu, Jierui Ren, Guoping Wang, Sheng Li|<https://arxiv.org/pdf/2511.20422v1>|æå‡ºäº†VibraVerseæ•°æ®é›†ï¼Œé€šè¿‡æ˜¾å¼è¿æ¥3Då‡ ä½•ä¸å£°å­¦ä¿¡å·ï¼Œå®ç°äº†ç‰©ç†ä¸€è‡´çš„å¤šæ¨¡æ€å­¦ä¹ ã€‚|
|ğŸ†• å‘å¸ƒ|Image-Free Timestep Distillation via Continuous-Time Consistency with Trajectory-Sampled Pairs|åŸºäºè¿ç»­æ—¶é—´ä¸€è‡´æ€§åŠè½¨è¿¹é‡‡æ ·å¯¹çš„æ— éœ€å›¾åƒçš„æ—¶é—´æ­¥é•¿è’¸é¦|Bao Tang, Shuai Zhang, Yueting Zhu, Jijun Xiang, Xin Yang, Li Yu, Wenyu Liu, Xinggang Wang|<https://arxiv.org/pdf/2511.20410v1>|[ä»£ç ](https://github.com/hustvl/TBCM.); æå‡ºäº†ä¸€ç§æ— éœ€å¤–éƒ¨è®­ç»ƒæ•°æ®çš„è‡ªåŒ…å«æ—¶åºè’¸é¦æ–¹æ³•ï¼Œå¤§å¹…æå‡äº†æ•ˆç‡å¹¶ç®€åŒ–äº†æµç¨‹ã€‚|
|ğŸ†• å‘å¸ƒ|The Image as Its Own Reward: Reinforcement Learning with Adversarial Reward for Image Generation|å›¾åƒä½œä¸ºè‡ªèº«çš„å¥–åŠ±ï¼šåŸºäºå¯¹æŠ—æ€§å¥–åŠ±çš„å›¾åƒç”Ÿæˆå¼ºåŒ–å­¦ä¹ |Weijia Mao, Hao Chen, Zhenheng Yang, Mike Zheng Shou|<https://arxiv.org/pdf/2511.20256v1>|æå‡ºäº†ä¸€ç§ä½¿ç”¨å¯¹æŠ—æ€§å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶Adv-GRPOï¼Œé€šè¿‡è§†è§‰è¾“å‡ºç›´æ¥æŒ‡å¯¼ç”Ÿæˆå™¨ï¼Œæœ‰æ•ˆé¿å…äº†å¥–åŠ±åŠ«...|
|ğŸ†• å‘å¸ƒ|Exo2EgoSyn: Unlocking Foundation Video Generation Models for Exocentric-to-Egocentric Video Synthesis|ã€ŠExo2EgoSynï¼šè§£é”åŸºç¡€è§†é¢‘ç”Ÿæˆæ¨¡å‹ä»¥å®ç°å¤–è§†è§’åˆ°ç¬¬ä¸€è§†è§’è§†é¢‘åˆæˆã€‹|Mohammad Mahdi, Yuqian Fu, Nedko Savov, Jiancheng Pan, Danda Pani Paudel, Luc Van Gool|<https://arxiv.org/pdf/2511.20186v1>|æå‡ºExo2EgoSynæ–¹æ³•ï¼Œé€šè¿‡è°ƒæ•´ç”Ÿæˆæ¨¡å‹å®ç°ä»ç¬¬ä¸‰äººç§°è§†è§’åˆ°ç¬¬ä¸€äººç§°è§†è§’çš„è§†é¢‘è½¬æ¢ã€‚|
|ğŸ“ æ›´æ–°|OmniLens++: Blind Lens Aberration Correction via Large LensLib Pre-Training and Latent PSF Representation|å…¨è§†é•œ++ï¼šé€šè¿‡å¤§é•œå¤´åº“é¢„è®­ç»ƒå’Œæ½œåœ¨ç‚¹æ‰©æ•£å‡½æ•°è¡¨ç¤ºå®ç°ç›²ç›®é•œå¤´åƒå·®æ ¡æ­£|Qi Jiang, Xiaolong Qian, Yao Gao, Lei Sun, Kailun Yang, Zhonghua Yi, Wenyong Li, Ming-Hsuan Yang .etc.|<https://arxiv.org/pdf/2511.17126v3>|[ä»£ç ](https://github.com/zju-jiangqi/OmniLens2.); OmniLens++é€šè¿‡å¤§è§„æ¨¡é¢„è®­ç»ƒå’Œéšæ€§PSFè¡¨å¾ï¼Œæœ‰æ•ˆè§£å†³äº†é•œå¤´ç•¸å˜æ ¡æ­£çš„æ•°æ®æ‰©å±•å’Œå…ˆéªŒæŒ‡å¯¼é—®é¢˜...|
|ğŸ“ æ›´æ–°|PaSE: Prototype-aligned Calibration and Shapley-based Equilibrium for Multimodal Sentiment Analysis|PaSEï¼šåŸå‹å¯¹é½æ ¡å‡†ä¸åŸºäºShapleyçš„å¹³è¡¡æ–¹æ³•ç”¨äºå¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æ|Kang He, Boyu Chen, Yuzhe Ding, Fei Li, Chong Teng, Donghong Ji|<https://arxiv.org/pdf/2511.17585v2>|æå‡ºäº†ä¸€ç§ç¼“è§£æ¨¡æ€ç«äº‰çš„PaSEæ¡†æ¶ï¼Œé€šè¿‡åŸå‹å¯¹é½æ ¡å‡†å’ŒShapleyä¼˜åŒ–å¹³è¡¡æå‡å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†ææ€§èƒ½...|
|ğŸ†• å‘å¸ƒ|Boosting Reasoning in Large Multimodal Models via Activation Replay|é€šè¿‡æ¿€æ´»é‡æ”¾æå‡å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ä¸­çš„æ¨ç†èƒ½åŠ›|Yun Xing, Xiaobin Hu, Qingdong He, Jiangning Zhang, Shuicheng Yan, Shijian Lu, Yu-Gang Jiang|<https://arxiv.org/pdf/2511.19972v1>|æå‡ºäº†ä¸€ç§åä¸º Activation Replay çš„æ— è®­ç»ƒæ–¹æ³•ï¼Œé€šè¿‡é‡æ”¾ä½ç†µæ¿€æ´»æå‡å¤§å‹å¤šæ¨¡æ€æ¨¡å‹...|
|ğŸ“ æ›´æ–°|Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models|è§†é¢‘LMMåè®­ç»ƒï¼šæ·±å…¥æ¢ç´¢å¤§å‹å¤šæ¨¡æ€æ¨¡å‹åœ¨è§†é¢‘æ¨ç†ä¸­çš„åº”ç”¨|Yolo Y. Tang, Jing Bi, Pinxin Liu, Zhenyu Pan, Zhangyun Tan, Qianxiang Shen, Jiani Liu, Hang Hua .etc.|<https://arxiv.org/pdf/2510.05034v6>|[ä»£ç ](https://github.com/yunlong10/Awesome-Video-LMM-Post-Training); ç³»ç»Ÿæ¢³ç†äº†è§†é¢‘ç†è§£ä¸­å¤§å‹å¤šæ¨¡æ€æ¨¡å‹çš„åè®­ç»ƒæ–¹æ³•ï¼Œæå‡äº†æ¨¡å‹åœ¨æ—¶ç©ºæ¨ç†å’Œè·¨æ¨¡æ€è¯æ®æ•´åˆæ–¹é¢çš„èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|Temporal-Visual Semantic Alignment: A Unified Architecture for Transferring Spatial Priors from Vision Models to Zero-Shot Temporal Tasks|æ—¶é—´-è§†è§‰è¯­ä¹‰å¯¹é½ï¼šä¸€ç§å°†è§†è§‰æ¨¡å‹çš„ç©ºé—´å…ˆéªŒè½¬ç§»è‡³é›¶æ ·æœ¬æ—¶é—´ä»»åŠ¡çš„ç»Ÿä¸€æ¶æ„|Xiangkai Ma, Han Zhang, Wenzhong Li, Sanglu Lu|<https://arxiv.org/pdf/2511.19856v1>|æå‡ºTimeArtistæ¡†æ¶ï¼Œå®ç°æ—¶é—´åºåˆ—ä¸è§†è§‰æ¦‚å¿µåœ¨è¯­ä¹‰å±‚é¢çš„ç²¾å‡†å¯¹é½ï¼Œæå‡è·¨æ¨¡æ€ç”Ÿæˆè´¨é‡ä¸æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|Face, Whole-Person, and Object Classification in a Unified Space Via The Interleaved Multi-Domain Identity Curriculum|é€šè¿‡äº¤ç»‡çš„å¤šåŸŸèº«ä»½è¯¾ç¨‹åœ¨ç»Ÿä¸€ç©ºé—´ä¸­è¿›è¡Œé¢éƒ¨ã€å…¨èº«å’Œç‰©ä½“åˆ†ç±»|Thomas M Metz, Matthew Q Hill, Alice J O'Toole|<https://arxiv.org/pdf/2511.19846v1>|é€šè¿‡Interleaved Multi-Domain Identity Curriculumæ–¹æ³•ï¼Œå®...|
|ğŸ“ æ›´æ–°|RadAgents: Multimodal Agentic Reasoning for Chest X-ray Interpretation with Radiologist-like Workflows|RadAgentsï¼šå…·æœ‰æ”¾å°„ç§‘æŠ€å¸ˆé£æ ¼å·¥ä½œæµç¨‹çš„èƒ¸éƒ¨Xå°„çº¿è§£é‡Šå¤šæ¨¡æ€ä»£ç†æ¨ç†|Kai Zhang, Corey D Barrett, Jangwon Kim, Lichao Sun, Tara Taghavi, Krishnaram Kenthapadi|<https://arxiv.org/pdf/2509.20490v2>|æå‡ºRadAgentså¤šä»£ç†æ¡†æ¶ï¼Œèåˆä¸´åºŠå…ˆéªŒå’Œä»»åŠ¡æ„ŸçŸ¥å¤šæ¨¡æ€æ¨ç†ï¼Œæ¨¡æ‹Ÿæ”¾å°„ç§‘åŒ»ç”Ÿå·¥ä½œæµç¨‹ï¼Œæå‡èƒ¸éƒ¨...|
|ğŸ†• å‘å¸ƒ|Large Language Model Aided Birt-Hogg-Dube Syndrome Diagnosis with Multimodal Retrieval-Augmented Generation|åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹è¾…åŠ©çš„Birch-Hogg-Dubeç»¼åˆå¾å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆè¯Šæ–­æ–¹æ³•|Haoqing Li, Jun Shi, Xianmeng Chen, Qiwei Jia, Rui Wang, Wei Wei, Hong An, Xiaowen Hu|<https://arxiv.org/pdf/2511.19834v1>|æå‡ºäº†ä¸€ç§èåˆä¸“ä¸šçŸ¥è¯†ä¸å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„BHD-RAGæ¡†æ¶ï¼Œæœ‰æ•ˆæå‡äº†Birt-Hogg-Dube...|


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|LocateAnything3D: Vision-Language 3D Detection with Chain-of-Sight|â€œLocateAnything3Dï¼šåŸºäºè§†è§‰-è¯­è¨€çš„ä¸‰ç»´æ£€æµ‹ä¸è§†çº¿é“¾â€|Yunze Man, Shihao Wang, Guowen Zhang, Johan Bjorck, Zhiqi Li, Liang-Yan Gui, Jim Fan, Jan Kautz .etc.|<https://arxiv.org/pdf/2511.20648v1>|æå‡ºäº†ä¸€ç§å°†3Dæ£€æµ‹è½¬åŒ–ä¸ºé€ä¸ªé¢„æµ‹é—®é¢˜çš„æ–¹æ³•ï¼Œé€šè¿‡Chain-of-Sightåºåˆ—å®ç°è§†è§‰æ¨ç†ï¼Œæ˜¾è‘—...|
|ğŸ“ æ›´æ–°|HoliSafe: Holistic Safety Benchmarking and Modeling for Vision-Language Model|ã€ŠHoliSafeï¼šè§†è§‰è¯­è¨€æ¨¡å‹çš„å…¨å±€å®‰å…¨æ€§åŸºå‡†æµ‹è¯•ä¸å»ºæ¨¡ã€‹|Youngwan Lee, Kangsan Kim, Kwanyong Park, Ilcahe Jung, Soojin Jang, Seanie Lee, Yong-Ju Lee, Sung Ju Hwang|<https://arxiv.org/pdf/2506.04704v5>|æå‡ºäº†å…¨é¢çš„è®¡ç®—æœºè§†è§‰æ¨¡å‹å®‰å…¨è¯„ä¼°æ–¹æ³•HoliSafeï¼Œå¹¶å¼•å…¥äº†è§†è§‰å®ˆå«æ¨¡å—ä»¥å¢å¼ºæ¨¡å‹å®‰å…¨æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Patch-Level Glioblastoma Subregion Classification with a Contrastive Learning-Based Encoder|åŸºäºå¯¹æ¯”å­¦ä¹ ç¼–ç å™¨çš„æ–‘å—çº§åˆ«èƒ¶è´¨oblastomaå­åŒºåŸŸåˆ†ç±»|Juexin Zhang, Qifeng Zhong, Ying Weng, Ke Chen|<https://arxiv.org/pdf/2511.20221v1>|åˆ©ç”¨å¯¹æ¯”å­¦ä¹ ä¼˜åŒ–çš„Vision Transformerç¼–ç å™¨ï¼Œå®ç°äº†èƒ¶è´¨oblastomaäºšåŒºåˆ†ç±»çš„...|
|ğŸ†• å‘å¸ƒ|Hybrid Convolution and Frequency State Space Network for Image Compression|æ··åˆå·ç§¯ä¸é¢‘ç‡çŠ¶æ€ç©ºé—´ç½‘ç»œç”¨äºå›¾åƒå‹ç¼©|Haodong Pan, Hao Wei, Yusong Wang, Nanning Zheng, Caigui Jiang|<https://arxiv.org/pdf/2511.20151v1>|æå‡ºäº†ä¸€ç§ç»“åˆå·ç§¯ç¥ç»ç½‘ç»œå’ŒçŠ¶æ€ç©ºé—´æ¨¡å‹çš„æ··åˆæ¶æ„ï¼Œæœ‰æ•ˆå¹³è¡¡å›¾åƒå‹ç¼©ä¸­çš„å±€éƒ¨ç»†èŠ‚å’Œé•¿è·ç¦»ä¿¡æ¯å»ºæ¨¡ã€‚|
|ğŸ†• å‘å¸ƒ|LungEvaty: A Scalable, Open-Source Transformer-based Deep Learning Model for Lung Cancer Risk Prediction in LDCT Screening|LungEvatyï¼šä¸€ç§ç”¨äºä½å‰‚é‡è®¡ç®—æœºæ–­å±‚æ‰«æç­›æŸ¥ä¸­è‚ºç™Œé£é™©é¢„æµ‹çš„å¯æ‰©å±•ã€å¼€æºçš„åŸºäºå˜æ¢å™¨çš„æ·±åº¦å­¦ä¹ æ¨¡å‹|Johannes Brandt, Maulik Chevli, Rickmer Braren, Georgios Kaissis, Philip MÃ¼ller, Daniel Rueckert|<https://arxiv.org/pdf/2511.20116v1>|æå‡ºäº†ä¸€ç§åŸºäºTransformerçš„æ·±åº¦å­¦ä¹ æ¨¡å‹LungEvatyï¼Œç”¨äºé«˜æ•ˆé¢„æµ‹è‚ºç™Œé£é™©ï¼Œæ— éœ€åƒç´ ...|
|ğŸ“ æ›´æ–°|Ming-Flash-Omni: A Sparse, Unified Architecture for Multimodal Perception and Generation|æ˜é—ªå…¨æ¨¡ï¼šä¸€ç§ç”¨äºå¤šæ¨¡æ€æ„ŸçŸ¥ä¸ç”Ÿæˆçš„ç¨€ç–ç»Ÿä¸€æ¶æ„|Inclusion AI, :, Bowen Ma, Cheng Zou, Canxiang Yan, Chunxiang Jin, Chunjie Shen, Chenyu Lian .etc.|<https://arxiv.org/pdf/2510.24821v2>|æå‡ºäº†ä¸€ç§ç¨€ç–ç»Ÿä¸€æ¶æ„Ming-Flash-Omniï¼Œå¤§å¹…æå‡å¤šæ¨¡æ€æ„ŸçŸ¥ä¸ç”Ÿæˆèƒ½åŠ›ï¼Œå®ç°è§†è§‰ã€è¯­éŸ³ã€...|
|ğŸ†• å‘å¸ƒ|Multi-Context Fusion Transformer for Pedestrian Crossing Intention Prediction in Urban Environments|åŸå¸‚ç¯å¢ƒä¸­è¡Œäººæ¨ªç©¿æ„å›¾é¢„æµ‹çš„å¤šä¸Šä¸‹æ–‡èåˆå˜æ¢å™¨|Yuanzhe Li, Hang Zhong, Steffen MÃ¼ller|<https://arxiv.org/pdf/2511.20011v1>|[ä»£ç ](https://github.com/ZhongHang0307/Multi-Context-Fusion-Transformer.); æå‡ºäº†ä¸€ç§å¤šä¸Šä¸‹æ–‡èåˆTransformerï¼Œé€šè¿‡æ•´åˆè¡Œäººè¡Œä¸ºã€ç¯å¢ƒã€å®šä½å’Œè½¦è¾†è¿åŠ¨å››ä¸ªç»´åº¦çš„ä¿¡æ¯ï¼Œ...|
|ğŸ†• å‘å¸ƒ|Pedestrian Crossing Intention Prediction Using Multimodal Fusion Network|åŸºäºå¤šæ¨¡æ€èåˆç½‘ç»œçš„è¡Œäººè¿‡è¡—æ„å›¾é¢„æµ‹|Yuanzhe Li, Steffen MÃ¼ller|<https://arxiv.org/pdf/2511.20008v1>|æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€èåˆç½‘ç»œï¼Œé€šè¿‡ç»“åˆè§†è§‰å’Œè¿åŠ¨ä¿¡æ¯ï¼Œæœ‰æ•ˆé¢„æµ‹è¡Œäººçš„æ¨ªç©¿æ„å›¾ï¼Œæå‡è‡ªåŠ¨é©¾é©¶è½¦è¾†çš„å®‰å…¨æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Supervise Less, See More: Training-free Nuclear Instance Segmentation with Prototype-Guided Prompting|"ç›‘ç£æ›´å°‘ï¼Œçœ‹è§æ›´å¤šï¼šåŸºäºåŸå‹å¼•å¯¼æç¤ºçš„æ— è®­ç»ƒæ ¸å®ä¾‹åˆ†å‰²"|Wen Zhang, Qin Ren, Wenjing Liu, Haibin Ling, Chenyu You|<https://arxiv.org/pdf/2511.19953v1>|æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒå’Œæ ‡æ³¨çš„æ ¸å®ä¾‹åˆ†å‰²æ¡†æ¶SPROUTï¼Œé€šè¿‡åŸå‹å¼•å¯¼æç¤ºå®ç°ç²¾ç¡®çš„æ ¸åˆ†å‰²ã€‚|
|ğŸ“ æ›´æ–°|Shape-Adapting Gated Experts: Dynamic Expert Routing for Colonoscopic Lesion Segmentation|å½¢çŠ¶è‡ªé€‚åº”é—¨æ§ä¸“å®¶ï¼šç»“ç›´è‚ é•œä¸‹ç—…å˜åˆ†å‰²çš„åŠ¨æ€ä¸“å®¶è·¯ç”±|Gia Huy Thai, Hoang-Nguyen Vu, Anh-Minh Phan, Quang-Thinh Ly, Tram Dinh, Thi-Ngoc-Truc Nguyen, Nhat Ho|<https://arxiv.org/pdf/2511.18493v2>|æå‡ºåŠ¨æ€ä¸“å®¶è·¯ç”±æ¡†æ¶SAGEï¼Œé€šè¿‡é€‚åº”è¾“å…¥å˜åŒ–çš„æ¶æ„ä¼˜åŒ–äº†ç»“è‚ é•œç—…å˜åˆ†å‰²çš„æ€§èƒ½ã€‚|


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|RobustMerge: Parameter-Efficient Model Merging for MLLMs with Direction Robustness|é²æ£’åˆå¹¶ï¼šé¢å‘å¤šè¯­è¨€å¤§å‹è¯­è¨€æ¨¡å‹çš„å‚æ•°é«˜æ•ˆæ¨¡å‹åˆå¹¶æ–¹æ³•åŠæ–¹å‘é²æ£’æ€§|Fanhu Zeng, Haiyang Guo, Fei Zhu, Li Shen, Hao Tang|<https://arxiv.org/pdf/2502.17159v4>|[ä»£ç ](https://github.com/AuroraZengfh/RobustMerge.); æå‡ºäº†ä¸€ç§å‚æ•°é«˜æ•ˆçš„æ¨¡å‹èåˆæ–¹æ³•RobustMergeï¼Œé€šè¿‡ä¿æŒæ–¹å‘ç¨³å¥æ€§è§£å†³äº†å¤šä»»åŠ¡å­¦ä¹ ä¸­çš„æ¨¡å‹è...|
|ğŸ“ æ›´æ–°|Alternating Perception-Reasoning for Hallucination-Resistant Video Understanding|ç”¨äºæŠµæŠ—å¹»è§‰çš„è§†é¢‘ç†è§£çš„äº¤æ›¿æ„ŸçŸ¥-æ¨ç†æ–¹æ³•|Bowei Pu, Chuanbin Liu, Yifan Ge, Peicheng Zhou, Yiwei Sun, Zhiying Lu, Jiankang Wang, Hongtao Xie|<https://arxiv.org/pdf/2511.18463v2>|[ä»£ç ](https://github.com/BoweiPu/VideoPLR.); æå‡ºå¾ªç¯æ„ŸçŸ¥æ¨ç†æ¡†æ¶PLRåŠåè™šæ„è¯„ä¼°å™¨FAEï¼Œæå‡è§†é¢‘ç†è§£å‡†ç¡®æ€§å’Œæ•°æ®æ•ˆç‡è‡³æœ€ä½³æ°´å¹³ã€‚|
|ğŸ†• å‘å¸ƒ|ADNet: A Large-Scale and Extensible Multi-Domain Benchmark for Anomaly Detection Across 380 Real-World Categories|ADNetï¼šé¢å‘380ä¸ªç°å®ä¸–ç•Œç±»åˆ«çš„å¼‚å¸¸æ£€æµ‹çš„å¤§è§„æ¨¡å¯æ‰©å±•å¤šé¢†åŸŸåŸºå‡†|Hai Ling, Jia Guo, Zhulin Tao, Yunkang Cao, Donglin Di, Hongyan Xu, Xiu Su, Yang Song .etc.|<https://arxiv.org/pdf/2511.20169v1>|[ä»£ç ](https://grainnet.github.io/ADNet); æå‡ºäº†ADNetï¼Œä¸€ä¸ªåŒ…å«380ä¸ªç±»åˆ«çš„å¤šé¢†åŸŸå¼‚å¸¸æ£€æµ‹å¤§è§„æ¨¡åŸºå‡†ï¼Œå¹¶å¼•å…¥äº†Dinomaly-mæ¨¡å‹ä»¥...|
|ğŸ†• å‘å¸ƒ|Zero-Shot Transfer Capabilities of the Sundial Foundation Model for Leaf Area Index Forecasting|ã€ŠSundialåŸºç¡€æ¨¡å‹åœ¨å¶é¢ç§¯æŒ‡æ•°é¢„æµ‹ä¸­çš„é›¶æ ·æœ¬è¿ç§»èƒ½åŠ›ã€‹|Peining Zhang, Hongchen Qin, Haochen Zhang, Ziqi Guo, Guiling Wang, Jinbo Bi|<https://arxiv.org/pdf/2511.20004v1>|é¦–æ¬¡è¯æ˜é€šç”¨é¢„è®­ç»ƒæ¨¡å‹åœ¨æ— éœ€ç‰¹å®šä»»åŠ¡è°ƒä¼˜çš„æƒ…å†µä¸‹ï¼Œèƒ½è¶…è¶Šä¸“ä¸šç›‘ç£æ¨¡å‹è¿›è¡Œé¥æ„Ÿæ—¶é—´åºåˆ—é¢„æµ‹ã€‚|
|ğŸ“ æ›´æ–°|GigaBrain-0: A World Model-Powered Vision-Language-Action Model|ã€ŠGigaBrain-0ï¼šä¸€ç§åŸºäºä¸–ç•Œæ¨¡å‹çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ã€‹|GigaBrain Team, Angen Ye, Boyuan Wang, Chaojun Ni, Guan Huang, Guosheng Zhao, Haoyun Li, Jie Li .etc.|<https://arxiv.org/pdf/2510.19430v2>|æå‡ºäº†GigaBrain-0æ¨¡å‹ï¼Œé€šè¿‡ä½¿ç”¨ä¸–ç•Œæ¨¡å‹ç”Ÿæˆæ•°æ®å‡å°‘å¯¹çœŸå®æœºå™¨äººæ•°æ®çš„ä¾èµ–ï¼Œæå‡æœºå™¨äººä»»åŠ¡...|
|ğŸ†• å‘å¸ƒ|MHB: Multimodal Handshape-aware Boundary Detection for Continuous Sign Language Recognition|å¤šæ¨¡æ€æ‰‹å½¢æ„ŸçŸ¥è¾¹ç•Œæ£€æµ‹ç”¨äºè¿ç»­æ‰‹è¯­è¯†åˆ«ï¼šMHBæ–¹æ³•|Mingyu Zhao, Zhanfu Yang, Yang Zhou, Zhaoyang Xia, Can Jin, Xiaoxiao He, Carol Neidle, Dimitris N. Metaxas|<https://arxiv.org/pdf/2511.19907v1>|æå‡ºäº†ä¸€ç§èåˆ3Dæ‰‹åŠ¿å’Œéª¨éª¼ç‰¹å¾çš„å¤šæ¨¡æ€æ–¹æ³•ï¼Œç”¨äºè¿ç»­æ‰‹è¯­è¯†åˆ«ä¸­çš„æ‰‹åŠ¿è¾¹ç•Œæ£€æµ‹ï¼Œæ˜¾è‘—æå‡äº†è¯†åˆ«å‡†ç¡®åº¦...|
|ğŸ“ æ›´æ–°|The Early Bird Identifies the Worm: You Can't Beat a Head Start in Long-Term Body Re-ID (ECHO-BID)|â€œå…ˆå‘åˆ¶äººï¼šåœ¨é•¿æœŸäººä½“é‡è¯†åˆ«ä¸­å…ˆè¡Œä¸€æ­¥çš„ä¼˜åŠ¿ï¼ˆECHO-BIDï¼‰â€|Thomas M. Metz, Matthew Q. Hill, Alice J. O'Toole|<https://arxiv.org/pdf/2507.17640v2>|é€šè¿‡é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹å¹¶åº”ç”¨åŸŸè½¬ç§»å­¦ä¹ ï¼ŒECHO-BIDæ–¹æ³•åœ¨é•¿æœŸäººä½“é‡è¯†åˆ«ä¸Šå–å¾—äº†æ˜¾è‘—æ€§èƒ½æå‡ã€‚|


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### ç›®æ ‡æ£€æµ‹ä¸å®šä½ (Object Detection & Localization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Automated Monitoring of Cultural Heritage Artifacts Using Semantic Segmentation|ä½¿ç”¨è¯­ä¹‰åˆ†å‰²è‡ªåŠ¨ç›‘æµ‹æ–‡åŒ–é—äº§è‰ºæœ¯å“|Andrea Ranieri, Giorgio Palmieri, Silvia Biasotti|<https://arxiv.org/pdf/2511.20541v1>|æå‡ºäº†ä¸€ç§åŸºäºU-Netæ¶æ„çš„è‡ªåŠ¨åŒ–æ–‡åŒ–é—äº§è£‚çº¹æ£€æµ‹æ–¹æ³•ï¼Œå®ç°äº†å¯¹é›•åƒå’Œçºªå¿µç¢‘çš„åƒç´ çº§è£‚çº¹è¯†åˆ«ã€‚|
|ğŸ†• å‘å¸ƒ|SelfMOTR: Revisiting MOTR with Self-Generating Detection Priors|è‡ªç”Ÿæˆæ£€æµ‹å…ˆéªŒçš„MOTRé‡æ¢ï¼šSelfMOTR|Fabian GÃ¼lhan, Emil Mededovic, Yuli Wu, Johannes Stegmaier|<https://arxiv.org/pdf/2511.20279v1>|æå‡ºSelfMOTRæ¨¡å‹ï¼Œé€šè¿‡è‡ªæˆ‘ç”Ÿæˆçš„æ£€æµ‹å…ˆéªŒæ”¹å–„è·Ÿè¸ªæ€§èƒ½ï¼Œå®ç°ä¸ç°æœ‰é¡¶çº§è·Ÿè¸ªæ–¹æ³•ç«äº‰çš„æ•ˆæœã€‚|
|ğŸ“ æ›´æ–°|Panoramic Distortion-Aware Tokenization for Person Detection and Localization in Overhead Fisheye Images|å…¨æ™¯å¤±çœŸæ„ŸçŸ¥çš„æ ‡è®°åŒ–æ–¹æ³•ç”¨äºä¿¯è§†é±¼çœ¼å›¾åƒä¸­çš„äººç‰©æ£€æµ‹ä¸å®šä½|Nobuhiko Wakai, Satoshi Sato, Yasunori Ishii, Takayoshi Yamashita|<https://arxiv.org/pdf/2503.14228v3>|æå‡ºäº†ä¸€ç§å…¨æ™¯ç•¸å˜æ„ŸçŸ¥çš„æ ‡è®°åŒ–æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº† overhead é±¼çœ¼å›¾åƒä¸­è¾ƒå°äººç‰©çš„æ£€æµ‹å’Œå®šä½å‡†ç¡®...|
|ğŸ“ æ›´æ–°|Beyond Fully Supervised Pixel Annotations: Scribble-Driven Weakly-Supervised Framework for Image Manipulation Localization|è¶…è¶Šå®Œå…¨ç›‘ç£åƒç´ æ ‡æ³¨ï¼šåŸºäºæ¶‚æŠ¹é©±åŠ¨çš„å¼±ç›‘ç£å›¾åƒæ“ä½œå®šä½æ¡†æ¶|Songlin Li, Guofeng Yu, Zhiqing Guo, Yunfeng Diao, Dan Ma, Gaobo Yang|<https://arxiv.org/pdf/2507.13018v2>|æå‡ºäº†ä¸€ç§åŸºäºæ¶‚é¸¦æ ‡æ³¨çš„å¼±ç›‘ç£å›¾åƒæ“ä½œå®šä½æ¡†æ¶ï¼Œé€šè¿‡è‡ªç›‘ç£è®­ç»ƒå’Œå…ˆéªŒä¿¡æ¯è°ƒåˆ¶ï¼Œæå‡äº†æ£€æµ‹æ€§èƒ½å’Œæ ‡æ³¨æ•ˆ...|


### å›¾åƒåˆ†ç±»ä¸è¯†åˆ« (Image Classification & Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Dance Style Classification using Laban-Inspired and Frequency-Domain Motion Features|ä½¿ç”¨æ‹‰ç­å¯å‘å¼å’Œé¢‘åŸŸè¿åŠ¨ç‰¹å¾çš„èˆè¹ˆé£æ ¼åˆ†ç±»|Ben Hamscher, Arnold Brosch, Nicolas Binninger, Maksymilian Jan Dejna, Kira Maag|<https://arxiv.org/pdf/2511.20469v1>|æå‡ºäº†ä¸€ç§åŸºäºLabanè¿åŠ¨åˆ†æå’Œé¢‘ç‡åŸŸç‰¹å¾çš„ä½è®¡ç®—é‡èˆè¹ˆé£æ ¼åˆ†ç±»æ¡†æ¶ï¼Œæœ‰æ•ˆåŒºåˆ†äº†ä¸åŒèˆè¹ˆé£æ ¼ã€‚|
|ğŸ†• å‘å¸ƒ|Advancing Image Classification with Discrete Diffusion Classification Modeling|ç”¨ç¦»æ•£æ‰©æ•£åˆ†ç±»å»ºæ¨¡æ¨è¿›å›¾åƒåˆ†ç±»|Omer Belhasin, Shelly Golan, Ran El-Yaniv, Michael Elad|<https://arxiv.org/pdf/2511.20263v1>|[ä»£ç ](https://github.com/omerb01/didicm); æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£è¿‡ç¨‹çš„å›¾åƒåˆ†ç±»æ–°æ¡†æ¶DiDiCMï¼Œæœ‰æ•ˆåº”å¯¹é«˜ä¸ç¡®å®šæ¡ä»¶ä¸‹çš„åˆ†ç±»æŒ‘æˆ˜ã€‚|


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Harnessing Vision-Language Models for Time Series Anomaly Detection|åˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡Œæ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹|Zelin He, Sarah Alnegheimish, Matthew Reimherr|<https://arxiv.org/pdf/2506.06836v2>|æå‡ºäº†ä¸€ç§ç»“åˆè§†è§‰è¯­è¨€æ¨¡å‹çš„ä¸¤é˜¶æ®µæ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚|
|ğŸ†• å‘å¸ƒ|XiCAD: Camera Activation Detection in the Da Vinci Xi User Interface|"XiCADï¼šè¾¾èŠ¬å¥‡Xiç”¨æˆ·ç•Œé¢ä¸­çš„ç›¸æœºæ¿€æ´»æ£€æµ‹"|Alexander C. Jenke, Gregor Just, Claas de Boer, Martin Wagner, Sebastian Bodenstedt, Stefanie Speidel|<https://arxiv.org/pdf/2511.20254v1>|æå‡ºäº†ä¸€ç§åŸºäºResNet18çš„è½»é‡çº§æ¨¡å‹ï¼Œå®ç°äº†å®æ—¶æ£€æµ‹è¾¾èŠ¬å¥‡Xiç³»ç»Ÿä¸­å†…çª¥é•œæ‘„åƒå¤´çš„æ¿€æ´»çŠ¶æ€ã€‚|
|ğŸ†• å‘å¸ƒ|Zoo3D: Zero-Shot 3D Object Detection at Scene Level|Zoo3Dï¼šé›¶æ ·æœ¬ä¸‰ç»´ç‰©ä½“åœºæ™¯çº§æ£€æµ‹|Andrey Lemeshko, Bulat Gabdullin, Nikita Drozdov, Anton Konushin, Danila Rukhovich, Maksim Kolodiazhnyi|<https://arxiv.org/pdf/2511.20253v1>|[ä»£ç ](https://github.com/col14m/zoo3d); æå‡ºé¦–ä¸ªæ— éœ€è®­ç»ƒçš„3Dç‰©ä½“æ£€æµ‹æ¡†æ¶Zoo3Dï¼Œé€šè¿‡2Då®ä¾‹æ©è†œå›¾èšç±»å’Œå¼€æ”¾è¯æ±‡æ¨¡å—å®ç°é›¶æ ·æœ¬æ£€æµ‹ã€‚|
|ğŸ“ æ›´æ–°|Unleashing the Power of Chain-of-Prediction for Monocular 3D Object Detection|é‡Šæ”¾é“¾å¼é¢„æµ‹çš„åŠ›é‡ä»¥å®ç°å•ç›®3Dç›®æ ‡æ£€æµ‹|Zhihao Zhang, Abhinav Kumar, Girish Chandar Ganesan, Xiaoming Liu|<https://arxiv.org/pdf/2505.04594v6>|æå‡ºäº†ä¸€ç§è‡ªé€‚åº”æ¡†æ¶MonoCoPï¼Œé€šè¿‡é“¾å¼é¢„æµ‹å’Œä¸ç¡®å®šæ€§å¼•å¯¼é€‰æ‹©ï¼Œæœ‰æ•ˆåˆ©ç”¨å±æ€§é—´å…³è”æ€§ï¼Œæ˜¾è‘—æå‡å•...|
|ğŸ†• å‘å¸ƒ|Multi Head Attention Enhanced Inception v3 for Cardiomegaly Detection|å¤šå¤´éƒ¨æ³¨æ„åŠ›å¢å¼ºçš„Inception v3ç”¨äºå¿ƒè„å¢å¤§æ£€æµ‹|Abishek Karthik, Pandiyaraju V|<https://arxiv.org/pdf/2511.20101v1>|æå‡ºäº†ä¸€ç§ç»“åˆInception V3å’Œå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶çš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œç”¨äºå‡†ç¡®æ£€æµ‹å¿ƒå½±å¢å¤§ã€‚|
|ğŸ†• å‘å¸ƒ|Exploring State-of-the-art models for Early Detection of Forest Fires|æ¢ç´¢æœ€å…ˆè¿›çš„æ¨¡å‹ç”¨äºæ£®æ—ç«ç¾çš„æ—©æœŸæ£€æµ‹|Sharjeel Ahmed, Daim Armaghan, Fatima Naweed, Umair Yousaf, Ahmad Zubair, Murtaza Taj|<https://arxiv.org/pdf/2511.20096v1>|æå‡ºç”¨äºæ—©æœŸæ£®æ—ç«ç¾æ£€æµ‹çš„ä¸“é—¨æ•°æ®é›†ï¼Œå¹¶å¯¹æ¯”äº†YOLOv7å’Œæ£€æµ‹å˜å‹å™¨æ¨¡å‹çš„æ•ˆæœã€‚|
|ğŸ†• å‘å¸ƒ|Redefining Radar Segmentation: Simultaneous Static-Moving Segmentation and Ego-Motion Estimation using Radar Point Clouds|é‡æ–°å®šä¹‰é›·è¾¾åˆ†å‰²ï¼šåˆ©ç”¨é›·è¾¾ç‚¹äº‘å®ç°é™æ€-è¿åŠ¨åˆ†å‰²ä¸è‡ªèº«è¿åŠ¨ä¼°è®¡çš„åŒæ­¥è¿›è¡Œ|Simin Zhu, Satish Ravindran, Alexander Yarovoy, Francesco Fioranelli|<https://arxiv.org/pdf/2511.20003v1>|æå‡ºäº†ä¸€ç§åŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•ï¼Œèƒ½åŒæ—¶ä»é›·è¾¾ç‚¹äº‘ä¸­åŒºåˆ†é™æ€å’ŒåŠ¨æ€ç‰©ä½“å¹¶ä¼°è®¡è‡ªèº«è¿åŠ¨é€Ÿåº¦ã€‚|


### è¯­ä¹‰/å®ä¾‹åˆ†å‰² (Semantic/Instance Segmentation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|CrossEarth-Gate: Fisher-Guided Adaptive Tuning Engine for Efficient Adaptation of Cross-Domain Remote Sensing Semantic Segmentation|CrossEarth-Gateï¼šåŸºäºFisherå¼•å¯¼çš„è‡ªé€‚åº”è°ƒèŠ‚å¼•æ“ï¼Œç”¨äºè·¨åŸŸé¥æ„Ÿè¯­ä¹‰åˆ†å‰²çš„é«˜æ•ˆé€‚åº”|Shilei Cao, Ziyang Gong, Hehai Lin, Yang Liu, Jiashun Cheng, Xiaoxing Hu, Haoyuan Liang, Guowen Li .etc.|<https://arxiv.org/pdf/2511.20302v1>|CrossEarth-Gateé€šè¿‡å¼•å…¥ç»¼åˆé¥æ„Ÿæ¨¡å—å·¥å…·ç®±å’ŒåŸºäºè´¹èˆå°”ä¿¡æ¯çš„è‡ªé€‚åº”é€‰æ‹©æœºåˆ¶ï¼Œæœ‰æ•ˆåº”å¯¹è·¨...|
|ğŸ†• å‘å¸ƒ|SAM-MI: A Mask-Injected Framework for Enhancing Open-Vocabulary Semantic Segmentation with SAM|SAM-MIï¼šä¸€ç§ç”¨äºå¢å¼ºå¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²çš„æ©ç æ³¨å…¥æ¡†æ¶ï¼Œç»“åˆSAM|Lin Chen, Yingjian Zhu, Qi Yang, Xin Niu, Kun Ding, Shiming Xiang|<https://arxiv.org/pdf/2511.20027v1>|æå‡ºäº†ä¸€ç§mask-injectedæ¡†æ¶SAM-MIï¼Œé€šè¿‡ä¼˜åŒ–é‡‡æ ·å’Œèšåˆç­–ç•¥ï¼Œæœ‰æ•ˆè§£å†³SAMåœ¨å¼€æ”¾è¯...|
|ğŸ“ æ›´æ–°|MSP-MVS: Multi-Granularity Segmentation Prior Guided Multi-View Stereo|å¤šç²’åº¦åˆ†å‰²å…ˆéªŒå¼•å¯¼çš„å¤šè§†è§’ç«‹ä½“åŒ¹é…æ–¹æ³•ï¼ˆMSP-MVSï¼‰|Zhenlong Yuan, Cong Liu, Fei Shen, Zhaoxin Li, Jinguo Luo, Tianlu Mao, Zhaoqi Wang|<https://arxiv.org/pdf/2407.19323v6>|å¼•å…¥å¤šç²’åº¦åˆ†å‰²å…ˆéªŒä»¥ç¨³å®šè¾¹ç¼˜é™åˆ¶çš„è¡¥ä¸å˜å½¢ï¼Œæå‡å¤šè§†è§’ç«‹ä½“åŒ¹é…æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|DBGroup: Dual-Branch Point Grouping for Weakly Supervised 3D Semantic Instance Segmentation|åŒåˆ†æ”¯ç‚¹ç»„ç­–ç•¥ï¼šç”¨äºå¼±ç›‘ç£ä¸‰ç»´è¯­ä¹‰å®ä¾‹åˆ†å‰²|Xuexun Liu, Xiaoxu Xu, Qiudan Zhang, Lin Ma, Xu Wang|<https://arxiv.org/pdf/2511.10003v2>|[ä»£ç ](https://github.com/liuxuexun/DBGroup.); æå‡ºäº†ä¸€ç§åˆ©ç”¨åœºæ™¯çº§æ³¨é‡Šçš„å¼±ç›‘ç£3Då®ä¾‹åˆ†å‰²æ¡†æ¶DBGroupï¼Œé€šè¿‡åŒåˆ†æ”¯ç‚¹åˆ†ç»„å’Œè‡ªè®­ç»ƒæ˜¾è‘—æå‡æ ‡æ³¨...|


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Infinity-RoPE: Action-Controllable Infinite Video Generation Emerges From Autoregressive Self-Rollout|æ— é™æ»šåŠ¨ç”Ÿæˆï¼šè‡ªå›å½’è‡ªå±•å¼€äº§ç”Ÿçš„åŠ¨ä½œå¯æ§æ— é™è§†é¢‘ç”Ÿæˆ|Hidir Yesiltepe, Tuna Han Salih Meral, Adil Kaan Akan, Kaan Oktay, Pinar Yanardag|<https://arxiv.org/pdf/2511.20649v1>|æå‡ºäº†ä¸€ç§æ— é™è§†é¢‘ç”Ÿæˆæ¡†æ¶ Infinity-RoPEï¼Œå…‹æœäº†ç°æœ‰æ¨¡å‹åœ¨æ—¶åºé™åˆ¶ã€åŠ¨ä½œæ§åˆ¶å“åº”é€Ÿåº¦å’Œ...|
|ğŸ†• å‘å¸ƒ|PixelDiT: Pixel Diffusion Transformers for Image Generation|åƒç´ æ‰©æ•£å˜æ¢å™¨ç”¨äºå›¾åƒç”Ÿæˆï¼šPixelDiT|Yongsheng Yu, Wei Xiong, Weili Nie, Yichen Sheng, Shiqiu Liu, Jiebo Luo|<https://arxiv.org/pdf/2511.20645v1>|PixelDiTé€šè¿‡ç›´æ¥åœ¨åƒç´ ç©ºé—´å­¦ä¹ æ‰©æ•£è¿‡ç¨‹ï¼Œé‡‡ç”¨åŒçº§åˆ«Transformeræ¶æ„ï¼Œæœ‰æ•ˆæå‡äº†å›¾åƒ...|
|ğŸ†• å‘å¸ƒ|Diverse Video Generation with Determinantal Point Process-Guided Policy Optimization|ç”¨è¡Œåˆ—å¼ç‚¹è¿‡ç¨‹å¼•å¯¼çš„ç­–ç•¥ä¼˜åŒ–å®ç°å¤šæ ·åŒ–è§†é¢‘ç”Ÿæˆ|Tahira Kazimi, Connor Dunlop, Pinar Yanardag|<https://arxiv.org/pdf/2511.20647v1>|æå‡ºäº†ä¸€ç§ç»“åˆDeterminantal Point Processeså’ŒGroup Relativ...|
|ğŸ†• å‘å¸ƒ|iMontage: Unified, Versatile, Highly Dynamic Many-to-many Image Generation|iMontageï¼šç»Ÿä¸€ã€å¤šåŠŸèƒ½çš„è¶…é«˜åŠ¨æ€å¤šå¯¹å¤šå›¾åƒç”Ÿæˆ|Zhoujie Fu, Xianfang Zeng, Jinghong Lan, Xinyao Liao, Cheng Chen, Junyi Chen, Jiacheng Wei, Wei Cheng .etc.|<https://arxiv.org/pdf/2511.20635v1>|[ä»£ç ](https://kr1sjfu.github.io/iMontage-web); iMontageé€šè¿‡æ•´åˆè§†é¢‘æ¨¡å‹ä¸å›¾åƒæ•°æ®ï¼Œå®ç°äº†åŠ¨æ€èŒƒå›´æ›´å¹¿ä¸”è¿‡æ¸¡è‡ªç„¶çš„å›¾åƒç”Ÿæˆã€‚|
|ğŸ†• å‘å¸ƒ|MapReduce LoRA: Advancing the Pareto Front in Multi-Preference Optimization for Generative Models|MapReduce LoRAï¼šåœ¨ç”Ÿæˆæ¨¡å‹çš„å¤šåå¥½ä¼˜åŒ–ä¸­æ¨è¿›å¸•ç´¯æ‰˜å‰æ²¿|Chieh-Yun Chen, Zhonghao Wang, Qi Chen, Zhifan Ye, Min Shi, Yue Zhao, Yinan Zhao, Hui Qu .etc.|<https://arxiv.org/pdf/2511.20629v1>|æå‡ºåŒé‡ä¼˜åŒ–ç­–ç•¥MapReduce LoRAå’ŒRaTEï¼Œæœ‰æ•ˆå¹³è¡¡å¤šåå¥½ç”Ÿæˆæ¨¡å‹è®­ç»ƒä¸­çš„æ€§èƒ½æŸå¤±ã€‚|
|ğŸ†• å‘å¸ƒ|MotionV2V: Editing Motion in a Video|è§†é¢‘è¿åŠ¨ç¼–è¾‘ï¼šåŸºäºè§†é¢‘çš„è¿åŠ¨è½¬æ¢|Ryan Burgert, Charles Herrmann, Forrester Cole, Michael S Ryoo, Neal Wadhwa, Andrey Voynov, Nataniel Ruiz|<https://arxiv.org/pdf/2511.20640v1>|[ä»£ç ](https://ryanndagreat.github.io/MotionV2V); æå‡ºäº†ä¸€ç§é€šè¿‡ç¼–è¾‘è¾“å…¥è§†é¢‘ä¸­ç¨€ç–è½¨è¿¹çš„æ–¹æ³•æ¥ç²¾ç¡®æ§åˆ¶è§†é¢‘è¿åŠ¨ï¼Œå®ç°äº†å¼ºå¤§çš„è§†é¢‘ç¼–è¾‘èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|ShapeGen: Towards High-Quality 3D Shape Synthesis|å½¢çŠ¶ç”Ÿæˆï¼šè¿ˆå‘é«˜è´¨é‡ä¸‰ç»´å½¢çŠ¶åˆæˆ|Yangguang Li, Xianglong He, Zi-Xin Zou, Zexiang Liu, Wanli Ouyang, Ding Liang, Yan-Pei Cao|<https://arxiv.org/pdf/2511.20624v1>|ShapeGené€šè¿‡æ”¹è¿›3Dè¡¨ç¤ºå’Œç›‘ç£ç­–ç•¥ã€æå‡åˆ†è¾¨ç‡å¹¶åˆ©ç”¨çº¿æ€§å˜å‹å™¨ä¼˜åŠ¿ï¼Œå®ç°äº†é«˜è´¨é‡çš„å›¾åƒåˆ°3D...|
|ğŸ†• å‘å¸ƒ|The Consistency Critic: Correcting Inconsistencies in Generated Images via Reference-Guided Attentive Alignment|ã€Šä¸€è‡´æ€§è¯„åˆ¤è€…ï¼šé€šè¿‡å‚è€ƒå¼•å¯¼çš„æ³¨æ„åŠ›å¯¹é½æ¥çº æ­£ç”Ÿæˆå›¾åƒä¸­çš„ä¸ä¸€è‡´æ€§ã€‹|Ziheng Ouyang, Yiren Song, Yaoli Liu, Shihao Zhu, Qibin Hou, Ming-Ming Cheng, Mike Zheng Shou|<https://arxiv.org/pdf/2511.20614v1>|æå‡ºäº†ä¸€ç§å‚è€ƒå¼•å¯¼çš„å›¾åƒåç¼–è¾‘æ–¹æ³•ImageCriticï¼Œæœ‰æ•ˆè§£å†³äº†ç”Ÿæˆå›¾åƒä¸­çš„ç»†èŠ‚ä¸ä¸€è‡´é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|Does Understanding Inform Generation in Unified Multimodal Models? From Analysis to Path Forward|â€œç†è§£æ˜¯å¦æŒ‡å¯¼ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹ä¸­çš„ç”Ÿæˆï¼Ÿä»åˆ†æåˆ°å‰è¿›è·¯å¾„â€|Yuwei Niu, Weiyang Jin, Jiaqi Liao, Chaoran Feng, Peng Jin, Bin Lin, Zongjian Li, Bin Zhu .etc.|<https://arxiv.org/pdf/2511.20561v1>|[ä»£ç ](https://github.com/PKU-YuanGroup/UniSandBox); å®šä½å¹¶ç¼©å°äº†ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹ä¸­ç†è§£ä¸ç”Ÿæˆä¹‹é—´çš„å·®è·ï¼Œæå‡ºUniSandboxæ¡†æ¶å’Œæ˜¾å¼æ€ç»´é“¾ç­–ç•¥ã€‚|
|ğŸ†• å‘å¸ƒ|PhysChoreo: Physics-Controllable Video Generation with Part-Aware Semantic Grounding|ç‰©ç†å¯æ§çš„è§†é¢‘ç”Ÿæˆï¼šåŸºäºéƒ¨ä»¶æ„ŸçŸ¥çš„è¯­ä¹‰æ¥åœ°|Haoze Zhang, Tianyu Huang, Zichen Wan, Xiaowei Jin, Hongzhi Zhang, Hui Li, Wangmeng Zuo|<https://arxiv.org/pdf/2511.20562v1>|æå‡ºäº†PhysChoreoæ¡†æ¶ï¼Œé€šè¿‡ç‰©ç†å±æ€§é‡å»ºå’Œç¼–è¾‘æ€§ä»¿çœŸï¼Œå®ç°äº†ä»å•å¼ å›¾ç‰‡ç”Ÿæˆå…·æœ‰å¤šæ ·æ§åˆ¶æ€§å’Œç‰©...|
|ğŸ†• å‘å¸ƒ|A Reason-then-Describe Instruction Interpreter for Controllable Video Generation|ç”¨äºå¯æ§è§†é¢‘ç”Ÿæˆçš„å…ˆè§£é‡ŠåŸå› åæè¿°çš„æŒ‡ä»¤è§£é‡Šå™¨|Shengqiong Wu, Weicai Ye, Yuanxing Zhang, Jiahao Wang, Quande Liu, Xintao Wang, Pengfei Wan, Kun Gai .etc.|<https://arxiv.org/pdf/2511.20563v1>|æå‡ºReaDeæ¨¡å‹ï¼Œé€šè¿‡åˆ†æç”¨æˆ·æŒ‡ä»¤å¹¶ç”Ÿæˆè¯¦ç»†æŒ‡å¯¼ï¼Œæé«˜äº†è§†é¢‘ç”Ÿæˆçš„å¯æ§æ€§å’Œè´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|Flash-DMD: Towards High-Fidelity Few-Step Image Generation with Efficient Distillation and Joint Reinforcement Learning|å¿«é€ŸåŠ¨æ€æ¨¡å¼åˆ†è§£ï¼šé¢å‘é«˜æ•ˆè’¸é¦ä¸è”åˆå¼ºåŒ–å­¦ä¹ çš„é«˜ä¿çœŸå°‘æ­¥å›¾åƒç”Ÿæˆ|Guanjie Chen, Shirui Huang, Kai Liu, Jianchen Zhu, Xiaoye Qu, Peng Chen, Yu Cheng, Yifu Sun|<https://arxiv.org/pdf/2511.20549v1>|æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„å›¾åƒç”Ÿæˆæ¡†æ¶Flash-DMDï¼Œé€šè¿‡ç»“åˆæ—¶é—´æ­¥è’¸é¦å’Œå¼ºåŒ–å­¦ä¹ ï¼Œå®ç°äº†å¿«é€Ÿä¸”é«˜è´¨é‡çš„å›¾...|
|ğŸ†• å‘å¸ƒ|DesignPref: Capturing Personal Preferences in Visual Design Generation|è®¾è®¡åå¥½ï¼šåœ¨è§†è§‰è®¾è®¡ç”Ÿæˆä¸­æ•æ‰ä¸ªäººåå¥½|Yi-Hao Peng, Jeffrey P. Bigham, Jason Wu|<https://arxiv.org/pdf/2511.20513v1>|å¼•å…¥DesignPrefæ•°æ®é›†ï¼Œé€šè¿‡ä¸ªæ€§åŒ–ç­–ç•¥æå‡è§†è§‰è®¾è®¡ç”Ÿæˆæ¨¡å‹å¯¹ä¸ªäººåå¥½çš„é¢„æµ‹å‡†ç¡®æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|STARFlow-V: End-to-End Video Generative Modeling with Normalizing Flow|STARFlow-Vï¼šåŸºäºå½’ä¸€åŒ–æµçš„ç«¯åˆ°ç«¯è§†é¢‘ç”Ÿæˆå»ºæ¨¡|Jiatao Gu, Ying Shen, Tianrong Chen, Laurent Dinh, Yuyang Wang, Miguel Angel Bautista, David Berthelot, Josh Susskind .etc.|<https://arxiv.org/pdf/2511.20462v1>|[ä»£ç ](https://github.com/apple/ml-starflow.); æå‡ºäº†ä¸€ç§åŸºäºå½’ä¸€åŒ–æµçš„ç«¯åˆ°ç«¯è§†é¢‘ç”Ÿæˆæ¨¡å‹STARFlow-Vï¼Œå®ç°äº†é«˜è´¨é‡ä¸”å…·æœ‰æ—¶é—´ä¸€è‡´æ€§çš„è§†é¢‘ç”Ÿ...|
|ğŸ†• å‘å¸ƒ|Learning to Generate Human-Human-Object Interactions from Textual Descriptions|ä»æ–‡æœ¬æè¿°ä¸­å­¦ä¹ ç”Ÿæˆäººä¸äººç‰©ä½“äº¤äº’|Jeonghyeon Na, Sangwon Baik, Inhee Lee, Junyoung Lee, Hanbyul Joo|<https://arxiv.org/pdf/2511.20446v1>|æå‡ºäº†ä¸€ç§ç”Ÿæˆæ¶‰åŠå¤šäººåœ¨å¯¹è±¡äº¤äº’ä¸­çš„æ–°æ¨¡å‹ï¼Œé€šè¿‡æ–‡æœ¬æè¿°ç”Ÿæˆé€¼çœŸçš„äººç±»-äººç±»-å¯¹è±¡äº¤äº’åœºæ™¯ã€‚|
|ğŸ“ æ›´æ–°|Segmentation-Aware Generative Reinforcement Network (GRN) for Tissue Layer Segmentation in 3-D Ultrasound Images for Chronic Low-back Pain (cLBP) Assessment|åŸºäºåˆ†å‰²æ„ŸçŸ¥çš„ç”Ÿæˆå¼ºåŒ–ç½‘ç»œï¼ˆGRNï¼‰ç”¨äºä¸‰ç»´è¶…å£°å›¾åƒä¸­ç»„ç»‡å±‚åˆ†å‰²ä»¥è¯„ä¼°æ…¢æ€§ä¸‹è…°ç—›ï¼ˆcLBPï¼‰|Zixue Zeng, Xiaoyan Zhao, Matthew Cartier, Tong Yu, Jing Wang, Xin Meng, Zhiyu Sheng, Maryam Satarpour .etc.|<https://arxiv.org/pdf/2501.17690v4>|æå‡ºäº†ä¸€ç§é›†æˆåˆ†å‰²æŸå¤±åé¦ˆçš„ç”Ÿæˆå¼ºåŒ–ç½‘ç»œï¼ˆGRNï¼‰ï¼Œåœ¨å‡å°‘æ ‡æ³¨æ•°æ®çš„åŒæ—¶ä¼˜åŒ–äº†å›¾åƒç”Ÿæˆå’Œåˆ†å‰²æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|Block Cascading: Training Free Acceleration of Block-Causal Video Models|å—çº§çº§è”ï¼šè®­ç»ƒå…è´¹åŠ é€Ÿçš„å—å› æœè§†é¢‘æ¨¡å‹|Hmrishav Bandyopadhyay, Nikhil Pinnaparaju, Rahim Entezari, Jim Scott, Yi-Zhe Song, Varun Jampani|<https://arxiv.org/pdf/2511.20426v1>|[ä»£ç ](https://hmrishavbandy.github.io/block_cascading_page); æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„å¹¶è¡ŒåŒ–æ–¹æ³•Block Cascadingï¼Œæœ‰æ•ˆè§£å†³äº†è§†é¢‘ç”Ÿæˆä¸­é€Ÿåº¦ä¸è´¨é‡çš„æƒè¡¡é—®...|
|ğŸ†• å‘å¸ƒ|BRIC: Bridging Kinematic Plans and Physical Control at Test Time|BRICï¼šåœ¨æµ‹è¯•æ—¶æ¡¥æ¥è¿åŠ¨è§„åˆ’ä¸ç‰©ç†æ§åˆ¶|Dohun Lim, Minji Kim, Jaewoon Lim, Sungchan Kim|<https://arxiv.org/pdf/2511.20431v1>|BRICé€šè¿‡æµ‹è¯•æ—¶é€‚åº”æ¡†æ¶ï¼Œæœ‰æ•ˆæ¡¥æ¥äº†è¿åŠ¨è§„åˆ’ä¸ç‰©ç†æ§åˆ¶é—´çš„å·®å¼‚ï¼Œå®ç°äº†è¿è´¯ä¸”ç‰©ç†å¯è¡Œçš„é•¿æœŸäººç±»è¿åŠ¨...|
|ğŸ†• å‘å¸ƒ|MajutsuCity: Language-driven Aesthetic-adaptive City Generation with Controllable 3D Assets and Layouts|é­”æ³•éƒ½å¸‚ï¼šåŸºäºè¯­è¨€çš„å®¡ç¾è‡ªé€‚åº”åŸå¸‚ç”Ÿæˆï¼Œå…·æœ‰å¯æ§çš„3Dèµ„äº§ä¸å¸ƒå±€|Zilong Huang, Jun He, Xiaobin Huang, Ziyi Xiong, Yang Luo, Junyan Ye, Weijia Li, Yiping Chen .etc.|<https://arxiv.org/pdf/2511.20415v1>|[ä»£ç ](https://github.com/LongHZ140516/MajutsuCity.); æå‡ºäº†MajutsuCityï¼Œä¸€ç§åŸºäºè‡ªç„¶è¯­è¨€å’Œå®¡ç¾è‡ªé€‚åº”çš„3DåŸå¸‚ç”Ÿæˆæ¡†æ¶ï¼Œå®ç°äº†ç»“æ„ä¸€è‡´æ€§ã€é£æ ¼...|
|ğŸ†• å‘å¸ƒ|A Training-Free Approach for Multi-ID Customization via Attention Adjustment and Spatial Control|ä¸€ç§æ— éœ€è®­ç»ƒçš„å¤šèº«ä»½å®šåˆ¶æ–¹æ³•ï¼šé€šè¿‡æ³¨æ„åŠ›è°ƒæ•´ä¸ç©ºé—´æ§åˆ¶|Jiawei Lin, Guanlong Jiao, Jianjin Xu|<https://arxiv.org/pdf/2511.20401v1>|æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„å¤šèº«ä»½å®šåˆ¶æ–¹æ³•ï¼Œé€šè¿‡æ³¨æ„åŠ›è°ƒæ•´å’Œç©ºé—´æ§åˆ¶è§£å†³å›¾åƒè´¨é‡å’Œæ–‡æœ¬ä¸€è‡´æ€§é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|Bootstrapping Physics-Grounded Video Generation through VLM-Guided Iterative Self-Refinement|é€šè¿‡åŸºäºè¯­è¨€æ¨¡å‹çš„è¿­ä»£è‡ªæˆ‘ç²¾ç‚¼å¼•å¯¼ç”Ÿæˆç‰©ç†å›ºåŒ–çš„è§†é¢‘|Yang Liu, Xilin Zhao, Peisong Wen, Siran Dai, Qingming Huang|<https://arxiv.org/pdf/2511.20280v1>|å¼•å…¥äº†ä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å’Œè§†è§‰è¯­è¨€æ¨¡å‹è¿›è¡Œç‰©ç†æ„ŸçŸ¥æŒ‡å¯¼çš„è¿­ä»£è‡ªä¼˜åŒ–æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†è§†é¢‘ç”Ÿæˆçš„ç‰©ç†ä¸€è‡´...|
|ğŸ“ æ›´æ–°|AlignCVC: Aligning Cross-View Consistency for Single-Image-to-3D Generation|AlignCVCï¼šå¯¹å•å¼ å›¾åƒåˆ°3Dç”Ÿæˆçš„è·¨è§†è§’ä¸€è‡´æ€§è¿›è¡Œå¯¹é½|Xinyue Liang, Zhiyuan Ma, Lingchen Sun, Yanjun Guo, Lei Zhang|<https://arxiv.org/pdf/2506.23150v2>|æå‡ºäº†ä¸€ç§é€šè¿‡åˆ†å¸ƒå¯¹é½æ”¹è¿›å¤šè§†è§’ä¸€è‡´æ€§çš„å•å¼ å›¾åƒåˆ°3Dç”Ÿæˆæ¡†æ¶ï¼Œå¤§å¹…æå‡äº†ç”Ÿæˆè´¨é‡å’Œæ•ˆç‡ã€‚|
|ğŸ†• å‘å¸ƒ|Text-guided Controllable Diffusion for Realistic Camouflage Images Generation|åŸºäºæ–‡æœ¬å¼•å¯¼çš„å¯æ§æ‰©æ•£ç”Ÿæˆé€¼çœŸè¿·å½©å›¾åƒçš„æ–¹æ³•|Yuhang Qian, Haiyan Chen, Wentong Li, Ningzhong Liu, Jie Qin|<https://arxiv.org/pdf/2511.20218v1>|æå‡ºäº†ä¸€ç§æ–‡æœ¬å¼•å¯¼çš„å¯æ§æ‰©æ•£æ–¹æ³•ï¼Œç”Ÿæˆä¸èƒŒæ™¯é€»è¾‘å…³ç³»è‡ªç„¶çš„é€¼çœŸä¼ªè£…å›¾åƒã€‚|
|ğŸ†• å‘å¸ƒ|OmniAlpha: A Sequence-to-Sequence Framework for Unified Multi-Task RGBA Generation|OmniAlphaï¼šç»Ÿä¸€å¤šä»»åŠ¡RGBAç”Ÿæˆçš„åºåˆ—åˆ°åºåˆ—æ¡†æ¶|Hao Yu, Jiabo Zhan, Zile Wang, Jinglin Wang, Huaisong Zhang, Hongyu Li, Xinrui Chen, Yongxian Wei .etc.|<https://arxiv.org/pdf/2511.20211v1>|æå‡ºäº†OmniAlphaæ¡†æ¶ï¼Œé¦–ä¸ªç»Ÿä¸€çš„å¤šä»»åŠ¡ç”Ÿæˆæ¨¡å‹ï¼Œå®ç°äº†RGBAå›¾åƒçš„ç”Ÿæˆä¸ç¼–è¾‘ï¼Œæ˜¾è‘—ä¼˜äºå•ä¸€...|
|ğŸ“ æ›´æ–°|M2SVid: End-to-End Inpainting and Refinement for Monocular-to-Stereo Video Conversion|M2SVidï¼šå•ç›®åˆ°ç«‹ä½“è§†é¢‘è½¬æ¢çš„ç«¯åˆ°ç«¯ä¿®å¤ä¸ä¼˜åŒ–|Nina Shvetsova, Goutam Bhat, Prune Truong, Hilde Kuehne, Federico Tombari|<https://arxiv.org/pdf/2505.16565v2>|æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯è§†é¢‘è½¬æ¢æ–¹æ³•ï¼Œé€šè¿‡æ·±åº¦é‡æŠ•å½±å’Œæ”¹è¿›çš„ç¨³å®šè§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œé«˜æ•ˆç”Ÿæˆé«˜è´¨é‡ç«‹ä½“è§†é¢‘å³è§†å›¾ã€‚|
|ğŸ†• å‘å¸ƒ|Restora-Flow: Mask-Guided Image Restoration with Flow Matching|"Restora-Flowï¼šåŸºäºæ©è†œå¼•å¯¼çš„æµåŒ¹é…å›¾åƒå¤åŸ"|Arnela Hadzic, Franz Thaler, Lea Bogensperger, Simon Johannes Joham, Martin Urschler|<https://arxiv.org/pdf/2511.20152v1>|æå‡ºRestora-Flowæ–¹æ³•ï¼Œé€šè¿‡é™è§£æ©ç æŒ‡å¯¼æµåŒ¹é…é‡‡æ ·å¹¶å¢å¼ºè½¨è¿¹ä¸€è‡´æ€§ï¼Œæœ‰æ•ˆæå‡å›¾åƒæ¢å¤è´¨é‡å’Œ...|
|ğŸ†• å‘å¸ƒ|Vision-Language Models for Automated 3D PET/CT Report Generation|ç”¨äºè‡ªåŠ¨åŒ–ä¸‰ç»´PET/CTæŠ¥å‘Šç”Ÿæˆçš„è§†è§‰-è¯­è¨€æ¨¡å‹|Wenpei Jiao, Kun Shang, Hui Li, Ke Yan, Jiajin Zhang, Guangjie Yang, Lijuan Guo, Yan Wan .etc.|<https://arxiv.org/pdf/2511.20145v1>|æå‡ºäº†ä¸€ç§3DåŒåˆ†æ”¯æ¡†æ¶PETRG-3Dï¼Œç”¨äºè‡ªåŠ¨ç”ŸæˆPET/CTæŠ¥å‘Šï¼Œæœ‰æ•ˆæå‡äº†ä¸´åºŠæŠ¥å‘Šè´¨é‡å’Œæ•ˆç‡...|
|ğŸ“ æ›´æ–°|Orientation Matters: Making 3D Generative Models Orientation-Aligned|ã€Šæ–¹å‘è‡³å…³é‡è¦ï¼šä½¿ä¸‰ç»´ç”Ÿæˆæ¨¡å‹æ–¹å‘å¯¹é½ã€‹|Yichong Lu, Yuzhuo Tian, Zijin Jiang, Yikun Zhao, Yuanbo Yang, Hao Ouyang, Haoji Hu, Huimin Yu .etc.|<https://arxiv.org/pdf/2506.08640v2>|æå‡ºäº†ä¸€ç§ä½¿3Dç”Ÿæˆæ¨¡å‹è¾“å‡ºæ–¹å‘ä¸€è‡´çš„æ–°æ–¹æ³•ï¼Œé€šè¿‡æ„å»ºç‰¹å®šæ•°æ®é›†ä¼˜åŒ–æ¨¡å‹ï¼Œæé«˜äº†å¯¹è±¡ç”Ÿæˆçš„å‡†ç¡®æ€§ã€‚|
|ğŸ“ æ›´æ–°|Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation|â€œStand-Inï¼šä¸€ç§è½»é‡çº§ä¸”å³æ’å³ç”¨çš„è§†é¢‘ç”Ÿæˆèº«ä»½æ§åˆ¶æ–¹æ³•â€|Bowen Xue, Zheng-Peng Duan, Qixin Yan, Wenjing Wang, Hao Liu, Chun-Le Guo, Chongyi Li, Chen Li .etc.|<https://arxiv.org/pdf/2508.07901v3>|æå‡ºäº†ä¸€ç§è½»é‡çº§è§†é¢‘ç”Ÿæˆæ¡†æ¶Stand-Inï¼Œé€šè¿‡æ¡ä»¶å›¾åƒåˆ†æ”¯å’Œé™åˆ¶æ€§è‡ªæ³¨æ„åŠ›å®ç°é«˜æ•ˆçš„èº«ä»½æ§åˆ¶ã€‚|
|ğŸ“ æ›´æ–°|Leveraging Unlabeled Data from Unknown Sources via Dual-Path Guidance for Deepfake Face Detection|é€šè¿‡åŒè·¯å¾„å¼•å¯¼åˆ©ç”¨æœªçŸ¥æ¥æºçš„æ— æ ‡ç­¾æ•°æ®ä»¥æé«˜æ·±åº¦ä¼ªé€ äººè„¸æ£€æµ‹æ€§èƒ½|Zhiqiang Yang, Renshuai Tao, Chunjie Zhang, guodong yang, Xiaolong Zheng, Yao Zhao|<https://arxiv.org/pdf/2508.09022v3>|æå‡ºäº†ä¸€ç§åŒè·¯å¾„å¼•å¯¼ç½‘ç»œDPGNetï¼Œåˆ©ç”¨æ— æ ‡ç­¾æ•°æ®è§£å†³æ·±åº¦ä¼ªé€ è„¸æ£€æµ‹ä¸­çš„æ³›åŒ–å¤±è´¥é—®é¢˜ã€‚|
|ğŸ“ æ›´æ–°|PrismAudio: Decomposed Chain-of-Thoughts and Multi-dimensional Rewards for Video-to-Audio Generation|PrismAudioï¼šåˆ†è§£æ€ç»´é“¾ä¸å¤šç»´å¥–åŠ±ç”¨äºè§†é¢‘åˆ°éŸ³é¢‘ç”Ÿæˆ|Huadai Liu, Kaicheng Luo, Wen Wang, Qian Chen, Peiwen Sun, Rongjie Huang, Xiangang Li, Jieping Ye .etc.|<https://arxiv.org/pdf/2511.18833v2>|PrismAudioé€šè¿‡åˆ†è§£æ€ç»´é“¾å’Œå¤šç»´å¥–åŠ±æœºåˆ¶ï¼Œè§£å†³äº†è§†é¢‘è½¬éŸ³é¢‘ç”Ÿæˆä¸­çš„ç›®æ ‡çº ç¼ é—®é¢˜ï¼Œå®ç°äº†è·¨æ„ŸçŸ¥...|
|ğŸ†• å‘å¸ƒ|PRADA: Probability-Ratio-Based Attribution and Detection of Autoregressive-Generated Images|PRADAï¼šåŸºäºæ¦‚ç‡æ¯”å½’å› ä¸è‡ªå›å½’ç”Ÿæˆå›¾åƒçš„æ£€æµ‹|Simon Damm, Jonas Ricker, Henning Petzka, Asja Fischer|<https://arxiv.org/pdf/2511.20068v1>|æå‡ºäº†ä¸€ç§åŸºäºæ¦‚ç‡æ¯”çš„æ–¹æ³•PRADAï¼Œå¯é æ£€æµ‹å¹¶å½’å› è‡ªå›å½’ç”Ÿæˆçš„å›¾åƒã€‚|
|ğŸ“ æ›´æ–°|Unified Text-Image-to-Video Generation: A Training-Free Approach to Flexible Visual Conditioning|ç»Ÿä¸€æ–‡æœ¬-å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆï¼šä¸€ç§æ— éœ€è®­ç»ƒçš„çµæ´»è§†è§‰æ¡ä»¶åŒ–æ–¹æ³•|Bolin Lai, Sangmin Lee, Xu Cao, Xiang Li, James M. Rehg|<https://arxiv.org/pdf/2505.20629v2>|æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„ç»Ÿä¸€æ–‡æœ¬-å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆæ–¹æ³•ï¼Œå®ç°äº†çµæ´»çš„è§†è§‰æ¡ä»¶æ§åˆ¶ã€‚|
|ğŸ†• å‘å¸ƒ|MFM-point: Multi-scale Flow Matching for Point Cloud Generation|å¤šå°ºåº¦æµåŒ¹é…ç”¨äºç‚¹äº‘ç”Ÿæˆçš„MFM-pointæ–¹æ³•|Petr Molodyk, Jaemoo Choi, David W. Romero, Ming-Yu Liu, Yongxin Chen|<https://arxiv.org/pdf/2511.20041v1>|æå‡ºäº†ä¸€ç§å¤šå°ºåº¦æµåŒ¹é…æ¡†æ¶MFM-Pointï¼Œæ˜¾è‘—æå‡äº†ç‚¹äº‘ç”Ÿæˆæ–¹æ³•çš„æ€§èƒ½å’Œå¯æ‰©å±•æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Clair Obscur: an Illumination-Aware Method for Real-World Image Vectorization|ã€Šclair obscurï¼šä¸€ç§é¢å‘çœŸå®ä¸–ç•Œå›¾åƒå‘é‡åŒ–çš„å…‰ç…§æ„ŸçŸ¥æ–¹æ³•ã€‹|Xingyue Lin, Shuai Peng, Xiangyu Xie, Jianhua Zhu, Yuxuan Zhou, Liangcai Gao|<https://arxiv.org/pdf/2511.20034v1>|æå‡ºäº†ä¸€ç§å…‰ç…§æ„ŸçŸ¥çš„å›¾åƒçŸ¢é‡åŒ–æ–¹æ³•COVecï¼Œé€šè¿‡åˆ†è§£å›¾åƒä¸ºåå…‰ç‡ã€é˜´å½±å’Œé«˜å…‰å±‚ï¼Œæé«˜äº†è§†è§‰ä¿çœŸåº¦å’Œ...|
|ğŸ“ æ›´æ–°|LayerComposer: Multi-Human Personalized Generation via Layered Canvas|å±‚ç»„åˆå™¨ï¼šé€šè¿‡åˆ†å±‚ç”»å¸ƒå®ç°å¤šäººç‰©ä¸ªæ€§åŒ–ç”Ÿæˆ|Guocheng Gordon Qian, Ruihang Zhang, Tsai-Shien Chen, Yusuf Dalva, Anujraaj Argo Goyal, Willi Menapace, Ivan Skorokhodov, Meng Dong .etc.|<https://arxiv.org/pdf/2510.20820v3>|LayerComposeré€šè¿‡åˆ†å±‚ç”»å¸ƒå®ç°å¤šäººç‰©ä¸ªæ€§åŒ–ç”Ÿæˆï¼Œæä¾›ç›´è§‚çš„ç©ºé—´æ§åˆ¶å’Œæ‰©å±•æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|CREward: A Type-Specific Creativity Reward Model|ç»“æœï¼šCREwardï¼šä¸€ç§ç‰¹å®šç±»å‹çš„åˆ›é€ åŠ›å¥–åŠ±æ¨¡å‹|Jiyeon Han, Ali Mahdavi-Amiri, Hao Zhang, Haedong Jeong|<https://arxiv.org/pdf/2511.19995v1>|é¦–æ¬¡æå‡ºäº†ä¸€ç§åˆ†ç±»å‹çš„åˆ›é€ åŠ›å¥–åŠ±æ¨¡å‹CREwardï¼Œé€šè¿‡å›¾åƒå½¢æˆæµç¨‹çš„ä¸‰ä¸ªç»´åº¦æ¥è¯„ä¼°å’Œç”Ÿæˆåˆ›æ„å›¾åƒã€‚|
|ğŸ“ æ›´æ–°|KEPT: Knowledge-Enhanced Prediction of Trajectories from Consecutive Driving Frames with Vision-Language Models|KEPTï¼šåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„çŸ¥è¯†å¢å¼ºè¿ç»­é©¾é©¶å¸§è½¨è¿¹é¢„æµ‹|Yujin Wang, Tianyi Wang, Quanfeng Liu, Wenxian Fan, Junfeng Jiao, Christian Claudel, Yunbing Yan, Bingzhao Gao .etc.|<https://arxiv.org/pdf/2509.02966v2>|æå‡ºäº†ä¸€ç§èåˆè§†è§‰è¯­è¨€æ¨¡å‹ä¸çŸ¥è¯†å¢å¼ºçš„è½¨è¿¹é¢„æµ‹æ¡†æ¶KEPTï¼Œæœ‰æ•ˆæå‡äº†è‡ªåŠ¨é©¾é©¶ä¸­çš„çŸ­æœŸè½¨è¿¹é¢„æµ‹å‡†ç¡®æ€§...|
|ğŸ“ æ›´æ–°|How Animals Dance (When You're Not Looking)|ã€Šå½“æ‚¨ä¸åœ¨åœºæ—¶ï¼ŒåŠ¨ç‰©å¦‚ä½•è·³èˆã€‹|Xiaojuan Wang, Aleksander Holynski, Brian Curless, Ira Kemelmacher, Steve Seitz|<https://arxiv.org/pdf/2505.23738v2>|æå‡ºäº†ä¸€ç§ç”Ÿæˆä¸éŸ³ä¹åŒæ­¥çš„åŠ¨ç‰©èˆè¹ˆè§†é¢‘æ¡†æ¶ï¼Œé€šè¿‡ä¼˜åŒ–å…³é”®å¸§ç»“æ„å’Œå¼•å…¥èˆè¹ˆç¼–æ’æ¨¡å¼å®ç°ã€‚|
|ğŸ†• å‘å¸ƒ|HiCoGen: Hierarchical Compositional Text-to-Image Generation in Diffusion Models via Reinforcement Learning|HiCoGenï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ åœ¨æ‰©æ•£æ¨¡å‹ä¸­è¿›è¡Œå±‚æ¬¡åŒ–ç»„åˆæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ|Hongji Yang, Yucheng Zhou, Wencheng Han, Runzhou Tao, Zhongying Qiu, Jianfei Yang, Jianbing Shen|<https://arxiv.org/pdf/2511.19965v1>|æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹å’Œå¼ºåŒ–å­¦ä¹ çš„å±‚æ¬¡åŒ–æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¡†æ¶ï¼Œæœ‰æ•ˆè§£å†³äº†å¤æ‚æç¤ºä¸‹çš„æ¦‚å¿µé—æ¼å’Œç»„åˆæ€§é—®...|
|ğŸ†• å‘å¸ƒ|Low-Resolution Editing is All You Need for High-Resolution Editing|ä½åˆ†è¾¨ç‡ç¼–è¾‘è¶³ä»¥å®ç°é«˜åˆ†è¾¨ç‡ç¼–è¾‘|Junsung Lee, Hyunsoo Lee, Yong Jae Lee, Bohyung Han|<https://arxiv.org/pdf/2511.19945v1>|æå‡ºäº†ä¸€ç§é«˜åˆ†è¾¨ç‡å›¾åƒç¼–è¾‘çš„æµ‹è¯•æ—¶ä¼˜åŒ–æ¡†æ¶ï¼Œé€šè¿‡åˆ†å—ä¼˜åŒ–å’Œç»†èŠ‚è¿ç§»å®ç°é«˜è´¨é‡ç¼–è¾‘ã€‚|
|ğŸ†• å‘å¸ƒ|HybriDLA: Hybrid Generation for Document Layout Analysis|æ··åˆç”Ÿæˆç”¨äºæ–‡æ¡£å¸ƒå±€åˆ†æçš„HybriDLA|Yufan Chen, Omar Moured, Ruiping Liu, Junwei Zheng, Kunyu Peng, Jiaming Zhang, Rainer Stiefelhagen|<https://arxiv.org/pdf/2511.19919v1>|[ä»£ç ](https://yufanchen96.github.io/projects); æå‡ºHybriDLAæ¡†æ¶ï¼Œèåˆæ‰©æ•£ä¸è‡ªå›å½’è§£ç ï¼Œæå‡å¤æ‚æ–‡æ¡£å¸ƒå±€åˆ†æçš„å‡†ç¡®æ€§å’Œé€‚åº”æ€§ã€‚|
|ğŸ“ æ›´æ–°|SatSAM2: Motion-Constrained Video Object Tracking in Satellite Imagery using Promptable SAM2 and Kalman Priors|SatSAM2ï¼šåŸºäºå¯æç¤ºSAM2å’Œå¡å°”æ›¼å…ˆéªŒçš„å«æ˜Ÿå½±åƒè¿åŠ¨çº¦æŸè§†é¢‘ç›®æ ‡è·Ÿè¸ª|Ruijie Fan, Junyan Ye, Huan Chen, Zilong Huang, Xiaolei Wang, Weijia Li|<https://arxiv.org/pdf/2511.18264v2>|æå‡ºäº†ä¸€ç§é›¶æ ·æœ¬å«æ˜Ÿè§†é¢‘è·Ÿè¸ªæ–¹æ³•SatSAM2ï¼Œé€šè¿‡å¼•å…¥è¿åŠ¨çº¦æŸæ¨¡å—å’ŒçŠ¶æ€æœºï¼Œæœ‰æ•ˆåº”å¯¹äº†å«æ˜Ÿå½±åƒè·Ÿè¸ª...|
|ğŸ†• å‘å¸ƒ|Reasoning-VLA: A Fast and General Vision-Language-Action Reasoning Model for Autonomous Driving|è‡ªåŠ¨é©¾é©¶ç”¨å¿«é€Ÿé€šç”¨è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨ç†æ¨¡å‹ï¼šReasoning-VLA|Dapeng Zhang, Zhenlong Yuan, Zhangquan Chen, Chih-Ting Liao, Yinda Chen, Fei Shen, Qingguo Zhou, Tat-Seng Chua|<https://arxiv.org/pdf/2511.19912v1>|æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„è§†è§‰-è¯­è¨€-è¡ŒåŠ¨æ¨ç†æ¨¡å‹Reasoning-VLAï¼Œé€šè¿‡å­¦ä¹ è¡ŒåŠ¨æŸ¥è¯¢å’Œå¢å¼ºçš„æ¨ç†èƒ½åŠ›...|
|ğŸ†• å‘å¸ƒ|Motion Marionette: Rethinking Rigid Motion Transfer via Prior Guidance|è¿åŠ¨æœ¨å¶ï¼šé€šè¿‡å…ˆéªŒå¼•å¯¼é‡æ–°æ€è€ƒåˆšä½“è¿åŠ¨è¿ç§»|Haoxuan Wang, Jiachen Tao, Junyi Wu, Gaowen Liu, Ramana Rao Kompella, Yan Yan|<https://arxiv.org/pdf/2511.19909v1>|æå‡ºäº†ä¸€ç§å†…éƒ¨å…ˆéªŒæŒ‡å¯¼çš„åˆšä½“è¿åŠ¨è¿ç§»æ¡†æ¶ï¼Œå®ç°äº†ä»å•ç›®è§†é¢‘åˆ°å•è§†å›¾å›¾åƒçš„æ— ç›‘ç£è¿åŠ¨è½¬ç§»ã€‚|
|ğŸ“ æ›´æ–°|Generative AI for Cel-Animation: A Survey|ã€Šç»†èƒåŠ¨ç”»ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ç»¼è¿°ã€‹|Yolo Y. Tang, Junjia Guo, Pinxin Liu, Zhiyuan Wang, Hang Hua, Jia-Xing Zhong, Yunzhong Xiao, Chao Huang .etc.|<https://arxiv.org/pdf/2501.06250v5>|[ä»£ç ](https://github.com/yunlong10/Awesome-AI4Animation); æ¢è®¨ç”Ÿæˆå¼AIå¦‚ä½•é©æ–°ä¼ ç»ŸåŠ¨ç”»æµç¨‹ï¼Œé™ä½æŠ€æœ¯é—¨æ§›ï¼Œæå‡åˆ›ä½œæ•ˆç‡ã€‚|
|ğŸ“ æ›´æ–°|From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction|ä»é¢„æµ‹åˆ°è§„åˆ’ï¼šååŒçŠ¶æ€-åŠ¨ä½œé¢„æµ‹çš„ç­–ç•¥ä¸–ç•Œæ¨¡å‹|Zhida Zhao, Talas Fu, Yifan Wang, Lijun Wang, Huchuan Lu|<https://arxiv.org/pdf/2510.19654v2>|[ä»£ç ](https://github.com/6550Zhao/Policy-World-Model.); æå‡ºäº†ä¸€ç§é›†æˆäº†ä¸–ç•Œæ¨¡å‹ä¸è½¨è¿¹è§„åˆ’çš„æ”¿ç­–ä¸–ç•Œæ¨¡å‹ï¼Œé€šè¿‡é¢„æµ‹æœªæ¥çŠ¶æ€æå‡è§„åˆ’å¯é æ€§ã€‚|
|ğŸ“ æ›´æ–°|VisionReward: Fine-Grained Multi-Dimensional Human Preference Learning for Image and Video Generation|ã€ŠVisionRewardï¼šç”¨äºå›¾åƒå’Œè§†é¢‘ç”Ÿæˆçš„ç»†ç²’åº¦å¤šç»´äººç±»åå¥½å­¦ä¹ ã€‹|Jiazheng Xu, Yu Huang, Jiale Cheng, Yuanming Yang, Jiajun Xu, Yuan Wang, Wenbo Duan, Shen Yang .etc.|<https://arxiv.org/pdf/2412.21059v3>|[ä»£ç ](https://github.com/THUDM/VisionReward.); å¼•å…¥VisionRewardæ¡†æ¶ï¼Œé€šè¿‡ç»†ç²’åº¦å¤šç»´äººç±»åå¥½å­¦ä¹ æ˜¾è‘—æå‡å›¾åƒå’Œè§†é¢‘ç”Ÿæˆä¸äººç±»åå¥½çš„ä¸€è‡´æ€§...|
|ğŸ“ æ›´æ–°|HunyuanVideo 1.5 Technical Report|ã€ŠHunyuanVideo 1.5 æŠ€æœ¯æŠ¥å‘Šã€‹|Bing Wu, Chang Zou, Changlin Li, Duojun Huang, Fang Yang, Hao Tan, Jack Peng, Jianbing Wu .etc.|<https://arxiv.org/pdf/2511.18870v2>|[ä»£ç ](https://github.com/Tencent-Hunyuan/HunyuanVideo-1.5.); ä»‹ç»äº†HunyuanVideo 1.5ï¼Œä¸€ç§å‚æ•°ä»…ä¸º83äº¿çš„é«˜æ•ˆå¼€æºè§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œå®ç°å“è¶Šè§†è§‰è´¨é‡å’Œ...|
|ğŸ†• å‘å¸ƒ|Rectified SpaAttn: Revisiting Attention Sparsity for Efficient Video Generation|ä¿®æ­£ç©ºé—´æ³¨æ„åŠ›ï¼šé‡æ–°å®¡è§†æ³¨æ„åŠ›ç¨€ç–æ€§ä»¥æé«˜è§†é¢‘ç”Ÿæˆæ•ˆç‡|Xuewen Liu, Zhikai Li, Jing Zhang, Mengjuan Chen, Qingyi Gu|<https://arxiv.org/pdf/2511.19835v1>|[ä»£ç ](https://github.com/BienLuky/Rectified-SpaAttn); æå‡ºRectified SpaAttnæ–¹æ³•ï¼Œä¼˜åŒ–æ³¨æ„åŠ›åˆ†é…ï¼Œæå‡è§†é¢‘ç”Ÿæˆæ•ˆç‡å¹¶ä¿æŒé«˜è´¨é‡ã€‚|
|ğŸ“ æ›´æ–°|E$^{3}$NeRF: Efficient Event-Enhanced Neural Radiance Fields from Blurry Images|E$^{3}$NeRFï¼šä»æ¨¡ç³Šå›¾åƒä¸­æ¢å¤é«˜æ•ˆçš„äº‹ä»¶å¢å¼ºç¥ç»è¾å°„åœº|Yunshan Qi, Jia Li, Yifan Zhao, Yu Zhang, Lin Zhu|<https://arxiv.org/pdf/2408.01840v2>|æå‡ºäº†ä¸€ç§åˆ©ç”¨æ¨¡ç³Šå›¾åƒå’Œäº‹ä»¶æµé‡å»ºæ¸…æ™°ç¥ç»è¾å°„åœºçš„æ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†é«˜é€Ÿè¿åŠ¨å’Œä½å…‰ç¯å¢ƒä¸‹æ¨¡ç³Šå›¾åƒçš„3D...|
|ğŸ†• å‘å¸ƒ|4DWorldBench: A Comprehensive Evaluation Framework for 3D/4D World Generation Models|4DWorldBenchï¼šä¸‰ç»´/å››ç»´ä¸–ç•Œç”Ÿæˆæ¨¡å‹ç»¼åˆè¯„ä¼°æ¡†æ¶|Yiting Lu, Wei Luo, Peiyan Tu, Haoran Li, Hanxin Zhu, Zihao Yu, Xingrui Wang, Xinyi Chen .etc.|<https://arxiv.org/pdf/2511.19836v1>|[ä»£ç ](https://yeppp27.github.io/4DWorldBench.github.io); æå‡ºäº†4DWorldBenchè¯„ä¼°æ¡†æ¶ï¼Œå…¨é¢è¯„ä»·3D/4Dä¸–ç•Œç”Ÿæˆæ¨¡å‹åœ¨æ„ŸçŸ¥è´¨é‡ã€æ—¶ç©ºä¸€è‡´æ€§ã€ç‰©ç†çœŸ...|
|ğŸ†• å‘å¸ƒ|ReDirector: Creating Any-Length Video Retakes with Rotary Camera Encoding|â€œReDirectorï¼šä½¿ç”¨æ—‹è½¬ç›¸æœºç¼–ç åˆ›å»ºä»»æ„é•¿åº¦è§†é¢‘é‡æ‹â€|Byeongjun Park, Byung-Hoon Kim, Hyungjin Chung, Jong Chul Ye|<https://arxiv.org/pdf/2511.19827v1>|æå‡ºReDirectoræ–¹æ³•ï¼Œé€šè¿‡ç›¸æœºæ§åˆ¶çš„è§†é¢‘é‡æ‹ç”Ÿæˆï¼Œå®ç°åŠ¨æ€è§†é¢‘ä»»æ„é•¿åº¦å¤„ç†ä¸å¤šè§†è§’å…³ç³»æ•´åˆã€‚|
|ğŸ†• å‘å¸ƒ|Training-Free Generation of Diverse and High-Fidelity Images via Prompt Semantic Space Optimization|é€šè¿‡æç¤ºè¯­ä¹‰ç©ºé—´ä¼˜åŒ–å®ç°æ— éœ€è®­ç»ƒçš„å¤šæ ·åŒ–å’Œé«˜ä¿çœŸå›¾åƒç”Ÿæˆ|Debin Meng, Chen Jin, Zheng Gao, Yanran Li, Ioannis Patras, Georgios Tzimiropoulos|<https://arxiv.org/pdf/2511.19811v1>|æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„TPSOæ–¹æ³•ï¼Œé€šè¿‡ä¼˜åŒ–æç¤ºè¯­ä¹‰ç©ºé—´ï¼Œæœ‰æ•ˆæå‡äº†æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„å¤šæ ·æ€§å’Œå›¾åƒè´¨...|


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Multi-modal Generative AI: Multi-modal LLMs, Diffusions, and the Unification|å¤šæ¨¡æ€ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼šå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ã€æ‰©æ•£æ¨¡å‹åŠå…¶ç»Ÿä¸€|Xin Wang, Yuwei Zhou, Bin Huang, Hong Chen, Wenwu Zhu|<https://arxiv.org/pdf/2409.14993v3>|ç³»ç»Ÿç»¼è¿°äº†å¤šæ¨¡æ€ç”ŸæˆAIæŠ€æœ¯ï¼ŒåŒ…æ‹¬å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å’Œæ‰©æ•£æ¨¡å‹ï¼Œå¹¶æ¢è®¨äº†ç»Ÿä¸€ç†è§£ä¸ç”Ÿæˆæ¨¡å‹çš„ç­–ç•¥ã€‚|
|ğŸ†• å‘å¸ƒ|Latent Diffusion Inversion Requires Understanding the Latent Space|æ½œåœ¨æ‰©æ•£é€†è¿‡ç¨‹éœ€è¦ç†è§£æ½œåœ¨ç©ºé—´|Mingxing Rao, Bowen Qu, Daniel Moyer|<https://arxiv.org/pdf/2511.20592v1>|æ­ç¤ºäº†æ½œåœ¨æ‰©æ•£æ¨¡å‹åœ¨æ½œåœ¨ç©ºé—´ä¸­çš„è®°å¿†ç‰¹æ€§ï¼Œå¹¶æå‡ºäº†è¯„ä¼°å’Œé™ä½éšç§é£é™©çš„ç»´åº¦æ’åºæ–¹æ³•ã€‚|
|ğŸ†• å‘å¸ƒ|AlignBench: Benchmarking Fine-Grained Image-Text Alignment with Synthetic Image-Caption Pairs|ã€ŠAlignBenchï¼šåˆ©ç”¨åˆæˆå›¾åƒ-æ ‡é¢˜å¯¹è¿›è¡Œç»†ç²’åº¦å›¾åƒ-æ–‡æœ¬å¯¹é½çš„åŸºå‡†æµ‹è¯•ã€‹|Kuniaki Saito, Risa Shinoda, Shohei Tanaka, Tosho Hirasawa, Fumio Okura, Yoshitaka Ushiku|<https://arxiv.org/pdf/2511.20515v1>|[ä»£ç ](https://dahlian00.github.io/AlignBench); æå‡ºAlignBenchï¼Œé€šè¿‡åˆæˆå›¾åƒ-æ–‡æœ¬å¯¹ç²¾ç¡®è¯„ä¼°å›¾åƒæ–‡æœ¬å¯¹é½æ€§èƒ½ï¼Œæ­ç¤ºäº†ç°æœ‰æ¨¡å‹åœ¨ç»†ç²’åº¦å¯¹é½ä¸Š...|
|ğŸ“ æ›´æ–°|CardioComposer: Leveraging Differentiable Geometry for Compositional Control of Anatomical Diffusion Models|â€œCardioComposerï¼šåˆ©ç”¨å¯å¾®åˆ†å‡ ä½•è¿›è¡Œè§£å‰–æ‰©æ•£æ¨¡å‹ç»„åˆæ§åˆ¶â€|Karim Kadry, Shoaib Goraya, Ajay Manicka, Abdalla Abdelwahed, Naravich Chutisilp, Farhad Nezami, Elazer Edelman|<https://arxiv.org/pdf/2509.08015v2>|CardioComposeré€šè¿‡å¯è§£é‡Šæ¤­çƒåŸºå…ƒå’Œå¾®åˆ†å‡ ä½•æµ‹é‡ï¼Œå®ç°äº†å¯¹3Då¿ƒè¡€ç®¡è§£å‰–ç»“æ„ç”Ÿæˆæ¨¡å‹çš„é«˜...|
|ğŸ†• å‘å¸ƒ|FREE: Uncertainty-Aware Autoregression for Parallel Diffusion Transformers|å…è´¹ï¼šä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„è‡ªå›å½’æ–¹æ³•ç”¨äºå¹¶è¡Œæ‰©æ•£å˜æ¢å™¨|Xinwan Wen, Bowen Li, Jiajun Luo, Ye Li, Zhi Wang|<https://arxiv.org/pdf/2511.20390v1>|æå‡ºFREEæ¡†æ¶ï¼Œé€šè¿‡ç‰¹å¾çº§è‡ªå›å½’å’Œä¸ç¡®å®šæ€§å¼•å¯¼çš„æ”¾æ¾ç­–ç•¥ï¼ŒåŠ é€Ÿäº†DiTsçš„å¹¶è¡Œæ‰©æ•£å˜æ¢è¿‡ç¨‹ã€‚|
|ğŸ“ æ›´æ–°|LikePhys: Evaluating Intuitive Physics Understanding in Video Diffusion Models via Likelihood Preference|â€œé€šè¿‡ä¼¼ç„¶åå¥½è¯„ä¼°è§†é¢‘æ‰©æ•£æ¨¡å‹ä¸­çš„ç›´è§‚ç‰©ç†ç†è§£ï¼šLikePhysâ€|Jianhao Yuan, Fabio Pizzati, Francesco Pinto, Lars Kunze, Ivan Laptev, Paul Newman, Philip Torr, Daniele De Martini|<https://arxiv.org/pdf/2510.11512v2>|æå‡ºäº†ä¸€ç§æ— è®­ç»ƒéœ€æ±‚çš„LikePhysæ–¹æ³•ï¼Œé€šè¿‡åŒºåˆ†ç‰©ç†æœ‰æ•ˆä¸ä¸å¯èƒ½è§†é¢‘ï¼Œå‡†ç¡®è¯„ä¼°è§†é¢‘æ‰©æ•£æ¨¡å‹ä¸­çš„ç›´...|
|ğŸ†• å‘å¸ƒ|From Passive Perception to Active Memory: A Weakly Supervised Image Manipulation Localization Framework Driven by Coarse-Grained Annotations|ä»è¢«åŠ¨æ„ŸçŸ¥åˆ°ä¸»åŠ¨è®°å¿†ï¼šç”±ç²—ç²’åº¦æ ‡æ³¨é©±åŠ¨çš„å¼±ç›‘ç£å›¾åƒæ“ä½œå®šä½æ¡†æ¶|Zhiqing Guo, Dongdong Xi, Songlin Li, Gaobo Yang|<https://arxiv.org/pdf/2511.20359v1>|æå‡ºäº†ä¸€ç§åŸºäºç²—ç•¥åŒºåŸŸæ ‡æ³¨çš„å¼±ç›‘ç£å›¾åƒæ“ä½œå®šä½æ¡†æ¶ï¼Œé€šè¿‡åŒå¼•å¯¼ç­–ç•¥å’ŒçŸ¥è¯†è’¸é¦ï¼Œå®ç°äº†ä½æˆæœ¬æ ‡æ³¨ä¸é«˜ç²¾...|
|ğŸ†• å‘å¸ƒ|TReFT: Taming Rectified Flow Models For One-Step Image Translation|TReFTï¼šé©¯åŒ–ä¿®æ­£æµæ¨¡å‹ä»¥å®ç°ä¸€æ­¥å›¾åƒç¿»è¯‘|Shengqian Li, Ming Gao, Yi Liu, Zuzeng Lin, Feng Wang, Feng Dai|<https://arxiv.org/pdf/2511.20307v1>|æå‡ºäº†ä¸€ç§ç›´æ¥åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹é¢„æµ‹é€Ÿåº¦çš„æ–¹æ³•TReFTï¼Œå®ç°äº†ä¸€æ­¥å›¾åƒç¿»è¯‘çš„é«˜æ•ˆå®æ—¶å¤„ç†ã€‚|
|ğŸ†• å‘å¸ƒ|ShelfRectNet: Single View Shelf Image Rectification with Homography Estimation|å•è§†å›¾è´§æ¶å›¾åƒæ ¡æ­£ä¸å•åº”æ€§ä¼°è®¡çš„ShelfRectNet|Onur Berk Tore, Ibrahim Samil Yalciner, Server Calap|<https://arxiv.org/pdf/2511.20335v1>|æå‡ºäº†ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„å•è§†è§’è´§æ¶å›¾åƒçŸ«æ­£æ–¹æ³•ï¼Œé€šè¿‡é¢„æµ‹å››ç‚¹å‚æ•°åŒ–çš„å•åº”æ€§çŸ©é˜µï¼Œæœ‰æ•ˆè§£å†³äº†å•è§†è§’å›¾åƒ...|
|ğŸ†• å‘å¸ƒ|IrisNet: Infrared Image Status Awareness Meta Decoder for Infrared Small Targets Detection|è™¹è†œç½‘ï¼šç”¨äºçº¢å¤–å°ç›®æ ‡æ£€æµ‹çš„çº¢å¤–å›¾åƒçŠ¶æ€æ„ŸçŸ¥å…ƒè§£ç å™¨|Xuelin Qian, Jiaming Lu, Zixuan Wang, Wenxuan Wang, Zhongling Huang, Dingwen Zhang, Junwei Han|<https://arxiv.org/pdf/2511.20319v1>|æå‡ºIrisNetï¼Œä¸€ç§è‡ªé€‚åº”çº¢å¤–å›¾åƒçŠ¶æ€çš„å…ƒå­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡åŠ¨æ€è°ƒæ•´è§£ç ç­–ç•¥æå‡çº¢å¤–å°ç›®æ ‡æ£€æµ‹æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|Are Image-to-Video Models Good Zero-Shot Image Editors?|å›¾åƒåˆ°è§†é¢‘æ¨¡å‹æ˜¯ä¼˜ç§€çš„é›¶æ ·æœ¬å›¾åƒç¼–è¾‘å™¨å—ï¼Ÿ|Zechuan Zhang, Zhenyuan Chen, Zongxin Yang, Yi Yang|<https://arxiv.org/pdf/2511.19435v2>|æå‡ºIF-Editæ¡†æ¶ï¼Œåˆ©ç”¨é¢„è®­ç»ƒå›¾åƒåˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹å®ç°æ— éœ€è°ƒä¼˜çš„æŒ‡ä»¤é©±åŠ¨å›¾åƒç¼–è¾‘ã€‚|
|ğŸ“ æ›´æ–°|Panoptic Captioning: An Equivalence Bridge for Image and Text|å…¨æ™¯æ ‡æ³¨ï¼šå›¾åƒä¸æ–‡æœ¬çš„ç­‰ä»·æ¡¥æ¢|Kun-Yu Lin, Hongjun Wang, Weining Ren, Kai Han|<https://arxiv.org/pdf/2505.16334v3>|[ä»£ç ](https://visual-ai.github.io/pancap); æå‡ºå…¨æ™¯æ ‡æ³¨ä»»åŠ¡ï¼Œé€šè¿‡åˆ†é˜¶æ®µç”Ÿæˆæè¿°å›¾åƒä¸­æ‰€æœ‰å®ä½“åŠå…¶å…³ç³»çš„æ–‡æœ¬ï¼Œè¶…è¶Šäº†ç°æœ‰å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|Robust 3D Brain MRI Inpainting with Random Masking Augmentation|éšæœºé®ç½©å¢å¼ºçš„ç¨³å¥ä¸‰ç»´è„‘éƒ¨MRIä¿®å¤|Juexin Zhang, Ying Weng, Ke Chen|<https://arxiv.org/pdf/2511.20202v1>|æå‡ºäº†ä¸€ç§åŸºäºU-Netæ¶æ„çš„3Dè„‘éƒ¨MRIä¿®å¤æ–¹æ³•ï¼Œç»“åˆéšæœºé®ç½©å¢å¼ºï¼Œæœ‰æ•ˆæé«˜äº†å›¾åƒä¿®å¤è´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|SFA: Scan, Focus, and Amplify toward Guidance-aware Answering for Video TextVQA|æ‰«æã€èšç„¦ä¸å¢å¼ºï¼šé¢å‘å¼•å¯¼æ„ŸçŸ¥çš„è§†é¢‘æ–‡æœ¬è§†è§‰é—®ç­”|Haibin He, Qihuang Zhong, Juhua Liu, Bo Du, Peng Wang, Jing Zhang|<https://arxiv.org/pdf/2511.20190v1>|æå‡ºSFAæ¡†æ¶ï¼Œé€šè¿‡è‡ªé€‚åº”æ‰«æã€é€‰æ‹©æ€§èšç„¦å’Œç›´æ¥æ”¾å¤§è§†é¢‘å¸§ä¸­çš„å…³é”®åŒºåŸŸï¼Œæœ‰æ•ˆæŒ‡å¯¼Video-LLMå…³...|
|ğŸ†• å‘å¸ƒ|Alzheimers Disease Progression Prediction Based on Manifold Mapping of Irregularly Sampled Longitudinal Data|åŸºäºä¸è§„åˆ™é‡‡æ ·çºµå‘æ•°æ®æµå½¢æ˜ å°„çš„é˜¿å°”èŒ¨æµ·é»˜ç—…è¿›å±•é¢„æµ‹|Xin Hong, Ying Shi, Yinhao Li, Yen-Wei Chen|<https://arxiv.org/pdf/2511.20154v1>|æå‡ºäº†ä¸€ç§åŸºäºæµå½¢æ˜ å°„çš„æ¡†æ¶ï¼Œæœ‰æ•ˆé¢„æµ‹é˜¿å°”èŒ¨æµ·é»˜ç—…è¿›å±•ï¼Œé€‚åº”ä¸è§„å¾‹é‡‡æ ·æ•°æ®ã€‚|
|ğŸ“ æ›´æ–°|Comparison of Generative Learning Methods for Turbulence Surrogates|ã€Šæ¹æµæ›¿ä»£æ¨¡å‹çš„ç”Ÿæˆå­¦ä¹ æ–¹æ³•æ¯”è¾ƒã€‹|Claudia Drygala, Edmund Ross, Francesca di Mare, Hanno Gottschalk|<https://arxiv.org/pdf/2411.16417v2>|æ¯”è¾ƒä¸‰ç§ç”Ÿæˆå­¦ä¹ æ¨¡å‹åœ¨æ¨¡æ‹Ÿæ¹æµä¸­çš„åº”ç”¨ï¼Œå‘ç°DDPMå’ŒDCGANèƒ½æœ‰æ•ˆå¤åˆ¶æµåœºç‰¹æ€§ï¼Œæä¾›é«˜æ•ˆçš„æ¹æµæ›¿...|
|ğŸ“ æ›´æ–°|From Spots to Pixels: Dense Spatial Gene Expression Prediction from Histology Images|ä»æ–‘ç‚¹åˆ°åƒç´ ï¼šä»ç»„ç»‡å­¦å›¾åƒé¢„æµ‹å¯†é›†ç©ºé—´åŸºå› è¡¨è¾¾|Ruikun Zhang, Yan Yang, Liyuan Pan|<https://arxiv.org/pdf/2503.01347v4>|æå‡º PixNetï¼Œé€šè¿‡ç›´æ¥åˆ†æå®Œæ•´ç»„ç»‡åˆ‡ç‰‡å›¾åƒï¼Œå®ç°äº†é«˜åˆ†è¾¨ç‡ä¸”å°ºåº¦çµæ´»çš„åŸºå› è¡¨è¾¾é¢„æµ‹ã€‚|
|ğŸ“ æ›´æ–°|FAPE-IR: Frequency-Aware Planning and Execution Framework for All-in-One Image Restoration|FAPE-IRï¼šé¢å‘ä¸€ç«™å¼å›¾åƒå¤åŸçš„é¢‘ç‡æ„ŸçŸ¥è§„åˆ’ä¸æ‰§è¡Œæ¡†æ¶|Jingren Liu, Shuning Xu, Qirui Yang, Yun Wang, Xiangyu Chen, Zhong Ji|<https://arxiv.org/pdf/2511.14099v2>|æå‡ºäº†ä¸€ç§é¢‘ç‡æ„ŸçŸ¥çš„å›¾åƒæ¢å¤æ¡†æ¶FAPE-IRï¼Œé€šè¿‡è¯­ä¹‰è§„åˆ’å’Œé¢‘ç‡æ¢å¤ç›¸ç»“åˆï¼Œå®ç°äº†ç»Ÿä¸€ä¸”å¯è§£é‡Šçš„å¤š...|
|ğŸ†• å‘å¸ƒ|SONIC: Spectral Optimization of Noise for Inpainting with Consistency|SONICï¼šåŸºäºå…‰è°±ä¼˜åŒ–çš„å™ªå£°å¤„ç†ä¸€è‡´æ€§ä¿®å¤ç®—æ³•|Seungyeon Baek, Erqun Dong, Shadan Namazifard, Mark J. Matthews, Kwang Moo Yi|<https://arxiv.org/pdf/2511.19985v1>|[ä»£ç ](https://ubc-vision.github.io/sonic); æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„å›¾åƒä¿®å¤æ–¹æ³•ï¼Œé€šè¿‡ä¼˜åŒ–åˆå§‹å™ªå£°åŒ¹é…å›¾åƒå†…å®¹ï¼Œå®ç°äº†ä¼˜äºç°æœ‰æŠ€æœ¯çš„ä¿®å¤æ•ˆæœã€‚|
|ğŸ†• å‘å¸ƒ|Image Diffusion Models Exhibit Emergent Temporal Propagation in Videos|å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨è§†é¢‘ä¸­å±•ç°å‡ºæ–°å…´çš„æ—¶é—´ä¼ æ’­ç‰¹æ€§|Youngseo Kim, Dohyun Kim, Geohee Han, Paul Hongsuck Seo|<https://arxiv.org/pdf/2511.19936v1>|æå‡ºåˆ©ç”¨å›¾åƒæ‰©æ•£æ¨¡å‹å®ç°è§†é¢‘ä¸­çš„é›¶æ ·æœ¬å¯¹è±¡è·Ÿè¸ªï¼Œé€šè¿‡è‡ªæ³¨æ„åŠ›å›¾å®ç°åƒç´ çº§å¯¹åº”å’Œæ—¶åºä¼ æ’­ã€‚|
|ğŸ†• å‘å¸ƒ|Scale Where It Matters: Training-Free Localized Scaling for Diffusion Models|ã€Šåœ¨å…³é”®ä½ç½®è¿›è¡Œç¼©æ”¾ï¼šæ— éœ€è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å±€éƒ¨ç¼©æ”¾æ–¹æ³•ã€‹|Qin Ren, Yufei Wang, Lanqing Guo, Wen Zhang, Zhiwen Fan, Chenyu You|<https://arxiv.org/pdf/2511.19917v1>|æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„å±€éƒ¨è‡ªé€‚åº”ç¼©æ”¾æ–¹æ³•LoTTSï¼Œé€šè¿‡ç²¾ç¡®å®šä½å¹¶ä¼˜åŒ–å›¾åƒç¼ºé™·åŒºåŸŸï¼Œæé«˜äº†å›¾åƒè´¨é‡å’Œæ•ˆ...|
|ğŸ†• å‘å¸ƒ|DLADiff: A Dual-Layer Defense Framework against Fine-Tuning and Zero-Shot Customization of Diffusion Models|DLADiffï¼šä¸€ç§é’ˆå¯¹æ‰©æ•£æ¨¡å‹å¾®è°ƒä¸é›¶æ ·æœ¬å®šåˆ¶åŒ–çš„åŒå±‚é˜²å¾¡æ¡†æ¶|Jun Jia, Hongyi Miao, Yingjie Zhou, Linhan Cao, Yanwei Jiang, Wangqiu Zhou, Dandan Zhu, Hua Yang .etc.|<https://arxiv.org/pdf/2511.19910v1>|æå‡ºåŒå±‚æ¬¡é˜²å¾¡æ¡†æ¶DLADiffï¼Œæœ‰æ•ˆæŠµå¾¡æ‰©æ•£æ¨¡å‹å¾®è°ƒå’Œé›¶æ ·æœ¬å®šåˆ¶æ”»å‡»ã€‚|
|ğŸ“ æ›´æ–°|Video-R4: Reinforcing Text-Rich Video Reasoning with Visual Rumination|è§†é¢‘R4ï¼šé€šè¿‡è§†è§‰æ²‰æ€å¼ºåŒ–å¯Œå«æ–‡æœ¬çš„è§†é¢‘æ¨ç†|Yolo Y. Tang, Daiki Shimada, Hang Hua, Chao Huang, Jing Bi, Rogerio Feris, Chenliang Xu|<https://arxiv.org/pdf/2511.17490v2>|[ä»£ç ](https://yunlong10.github.io/Video-R4); æå‡ºäº†ä¸€ç§è¿­ä»£è§†è§‰é‡å®¡çš„æ¨¡å‹Video-R4ï¼Œé€šè¿‡åå¤æ£€æŸ¥è§†é¢‘ä¸­çš„å…³é”®å¸§å’ŒåŒºåŸŸï¼Œæ˜¾è‘—æå‡äº†æ–‡æœ¬ä¸°å¯Œè§†...|
|ğŸ“ æ›´æ–°|InstaDA: Augmenting Instance Segmentation Data with Dual-Agent System|InstaDAï¼šåˆ©ç”¨åŒä»£ç†ç³»ç»Ÿå¢å¼ºå®ä¾‹åˆ†å‰²æ•°æ®é›†|Xianbao Hou, Yonghao He, Zeyd Boukhers, John See, Hu Su, Wei Sui, Cong Yang|<https://arxiv.org/pdf/2509.02973v2>|æå‡ºInstaDAï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„åŒä»£ç†ç³»ç»Ÿï¼Œé€šè¿‡LLMå’Œæ‰©æ•£æ¨¡å‹åä½œå¢å¼ºå®ä¾‹åˆ†å‰²æ•°æ®é›†å¤šæ ·æ€§ï¼Œæ˜¾è‘—...|


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Localizing Knowledge in Diffusion Transformers|æ‰©æ•£å˜æ¢å™¨ä¸­å®šä½çŸ¥è¯†|Arman Zarei, Samyadeep Basu, Keivan Rezaei, Zihao Lin, Sayan Nag, Soheil Feizi|<https://arxiv.org/pdf/2505.18832v2>|æå‡ºäº†ä¸€ç§çŸ¥è¯†å®šä½æ–¹æ³•ï¼Œç”¨äºè¯†åˆ«å’Œä¼˜åŒ–Diffusion Transformeræ¨¡å‹ä¸­çš„çŸ¥è¯†åˆ†å¸ƒï¼Œæ...|
|ğŸ“ æ›´æ–°|Personalized Generative Low-light Image Denoising and Enhancement|ä¸ªæ€§åŒ–ç”Ÿæˆä½å…‰ç…§å›¾åƒå»å™ªä¸å¢å¼º|Xijun Wang, Prateek Chennuri, Dilshan Godaliyadda, Yu Yuan, Bole Ma, Xingguang Zhang, Hamid R. Sheikh, Stanley Chan|<https://arxiv.org/pdf/2412.14327v3>|[ä»£ç ](https://genai-restore.github.io/DiffPGD); æå‡ºäº†ä¸€ç§ä¸ªæ€§åŒ–çš„åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒå»å™ªå’Œå¢å¼ºæ–¹æ³•ï¼Œåˆ©ç”¨ç”¨æˆ·ä¸ªäººç›¸å†Œæ„å»ºèº«ä»½ä¸€è‡´æ€§çš„ç‰©ç†ç¼“å†²åŒºï¼Œæœ‰æ•ˆ...|
|ğŸ“ æ›´æ–°|CGCE: Classifier-Guided Concept Erasure in Generative Models|CGCEï¼šåˆ†ç±»å™¨å¼•å¯¼çš„æ¦‚å¿µæ“¦é™¤åœ¨ç”Ÿæˆæ¨¡å‹ä¸­çš„åº”ç”¨|Viet Nguyen, Vishal M. Patel|<https://arxiv.org/pdf/2511.05865v2>|æå‡ºäº†ä¸€ç§é«˜æ•ˆæ¡†æ¶CGCEï¼Œé€šè¿‡è½»é‡çº§åˆ†ç±»å™¨å®ç°ç”Ÿæˆæ¨¡å‹ä¸­çš„ç¨³å¥æ¦‚å¿µæ“¦é™¤ï¼Œå¹³è¡¡äº†å®‰å…¨æ€§å’Œç”Ÿæˆè´¨é‡ã€‚|
|ğŸ“ æ›´æ–°|IVY-FAKE: A Unified Explainable Framework and Benchmark for Image and Video AIGC Detection|IVY-FAKEï¼šä¸€ç§ç»Ÿä¸€çš„å¯è§£é‡Šæ¡†æ¶ä¸å›¾åƒåŠè§†é¢‘AIGCæ£€æµ‹åŸºå‡†|Changjiang Jiang, Wenhui Dong, Zhonghao Zhang, Chenyang Si, Fengchang Yu, Wei Peng, Xinbin Yuan, Yifei Bi .etc.|<https://arxiv.org/pdf/2506.00979v2>|æå‡ºäº†IVY-FAKEæ¡†æ¶å’ŒåŸºå‡†ï¼Œé€šè¿‡ä¸°å¯Œæ³¨é‡Šçš„å¤šæ¨¡æ€æ•°æ®é›†å’Œå¼ºåŒ–å­¦ä¹ æ¨¡å‹ï¼Œæé«˜äº†åˆæˆå†…å®¹æ£€æµ‹çš„æ€§èƒ½...|
|ğŸ“ æ›´æ–°|Target-aware Image Editing via Cycle-consistent Constraints|é€šè¿‡å¾ªç¯ä¸€è‡´æ€§çº¦æŸå®ç°ç›®æ ‡æ„ŸçŸ¥å›¾åƒç¼–è¾‘|Yanghao Wang, Zhen Wang, Long Chen|<https://arxiv.org/pdf/2510.20212v2>|æå‡ºäº†FlowCycleï¼Œä¸€ç§ç›®æ ‡æ„ŸçŸ¥çš„å›¾åƒç¼–è¾‘æ¡†æ¶ï¼Œé€šè¿‡å¾ªç¯ä¸€è‡´æ€§ä¼˜åŒ–ï¼Œå®ç°äº†æ›´é«˜è´¨é‡çš„ç¼–è¾‘æ•ˆæœå’Œ...|
|ğŸ“ æ›´æ–°|LightMem: Lightweight and Efficient Memory-Augmented Generation|ã€ŠLightMemï¼šè½»é‡çº§é«˜æ•ˆå†…å­˜å¢å¼ºç”Ÿæˆã€‹|Jizhan Fang, Xinle Deng, Haoming Xu, Ziyan Jiang, Yuqi Tang, Ziwen Xu, Shumin Deng, Yunzhi Yao .etc.|<https://arxiv.org/pdf/2510.18866v2>|[ä»£ç ](https://github.com/zjunlp/LightMem.); æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„LightMemè®°å¿†ç³»ç»Ÿï¼Œé€šè¿‡ä¸‰é˜¶æ®µç»„ç»‡è®°å¿†ï¼Œæ˜¾è‘—æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŠ¨æ€å¤æ‚ç¯å¢ƒä¸­çš„...|
|ğŸ†• å‘å¸ƒ|PromptMoG: Enhancing Diversity in Long-Prompt Image Generation via Prompt Embedding Mixture-of-Gaussian Sampling|PromptMoGï¼šé€šè¿‡PromptåµŒå…¥é«˜æ–¯æ··åˆé‡‡æ ·å¢å¼ºé•¿æç¤ºå›¾åƒç”Ÿæˆçš„å¤šæ ·æ€§|Bo-Kai Ruan, Teng-Fang Hsiao, Ling Lo, Yi-Lun Wu, Hong-Han Shuai|<https://arxiv.org/pdf/2511.20251v1>|æå‡ºäº†ä¸€ç§é€šè¿‡é«˜æ–¯æ··åˆæ¨¡å‹é‡‡æ ·æç¤ºåµŒå…¥çš„æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†é•¿æç¤ºç”Ÿæˆå›¾åƒçš„å¤šæ ·æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|UltraViCo: Breaking Extrapolation Limits in Video Diffusion Transformers|"UltraViCoï¼šçªç ´è§†é¢‘æ‰©æ•£å˜å‹å™¨çš„å¤–æ¨æé™"|Min Zhao, Hongzhou Zhu, Yingze Wang, Bokai Yan, Jintao Zhang, Guande He, Ling Yang, Chongxuan Li .etc.|<https://arxiv.org/pdf/2511.20123v1>|æå‡ºUltraViCoæ–¹æ³•ï¼Œè§£å†³è§†é¢‘æ‰©æ•£å˜æ¢å™¨åœ¨è®­ç»ƒé•¿åº¦å¤–æ³›åŒ–é—®é¢˜ï¼Œå°† extrapolation ...|
|ğŸ†• å‘å¸ƒ|Tell Model Where to Look: Mitigating Hallucinations in MLLMs by Vision-Guided Attention|å‘Šè¯‰æ¨¡å‹çœ‹å‘å“ªé‡Œï¼šé€šè¿‡è§†è§‰å¼•å¯¼æ³¨æ„åŠ›å‡è½»å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰ç°è±¡|Jianfei Zhao, Feng Zhang, Xin Sun, Chong Feng, Zhixing Tan|<https://arxiv.org/pdf/2511.20032v1>|æå‡ºäº†ä¸€ç§è§†è§‰å¼•å¯¼æ³¨æ„åŠ›æ–¹æ³•VGAï¼Œæœ‰æ•ˆå‡å°‘äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å›¾åƒç†è§£ä¸­çš„å¹»è§‰ç°è±¡ã€‚|
|ğŸ†• å‘å¸ƒ|EmoFeedback2: Reinforcement of Continuous Emotional Image Generation via LVLM-based Reward and Textual Feedback|ã€ŠEmoFeedback2ï¼šåŸºäºLVLMå¥–åŠ±ä¸æ–‡æœ¬åé¦ˆçš„è¿ç»­æƒ…æ„Ÿå›¾åƒç”Ÿæˆçš„å¼ºåŒ–ã€‹|Jingyang Jia, Kai Shu, Gang Yang, Long Xing, Xun Chen, Aiping Liu|<https://arxiv.org/pdf/2511.19982v1>|æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹è¿›è¡Œå¥–åŠ±å’Œæ–‡æœ¬åé¦ˆçš„è¿ç»­æƒ…æ„Ÿå›¾åƒç”Ÿæˆå¼ºåŒ–èŒƒå¼ï¼Œæœ‰æ•ˆæå‡äº†å›¾åƒçš„æƒ…æ„Ÿè¿ç»­...|
|ğŸ“ æ›´æ–°|ManipShield: A Unified Framework for Image Manipulation Detection, Localization and Explanation|ManipShieldï¼šç”¨äºå›¾åƒæ“çºµæ£€æµ‹ã€å®šä½ä¸è§£é‡Šçš„ç»Ÿä¸€æ¡†æ¶|Zitong Xu, Huiyu Duan, Xiaoyu Wang, Zhaolin Cai, Kaiwei Zhang, Qiang Hu, Jing Liu, Xiongkuo Min .etc.|<https://arxiv.org/pdf/2511.14259v2>|æå‡ºå¤§è§„æ¨¡ ManipBench æ•°æ®é›†å’Œ ManipShield æ¨¡å‹ï¼Œå®ç°å›¾åƒæ“çºµçš„æ£€æµ‹ã€å®šä½ä¸...|


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Scalable FPGA Framework for Real-Time Denoising in High-Throughput Imaging: A DRAM-Optimized Pipeline using High-Level Synthesis|å¯æ‰©å±•çš„FPGAæ¡†æ¶ç”¨äºé«˜ååé‡æˆåƒä¸­çš„å®æ—¶å»å™ªï¼šä¸€ç§åŸºäºé«˜é˜¶ç»¼åˆçš„DRAMä¼˜åŒ–ç®¡é“|Weichien Liao|<https://arxiv.org/pdf/2508.14917v2>|æå‡ºäº†ä¸€ç§åŸºäºFPGAçš„é«˜é€šé‡æˆåƒå®æ—¶å»å™ªæ¡†æ¶ï¼Œé€šè¿‡é«˜çº§è¡Œä¸ºåˆæˆå’ŒDRAMä¼˜åŒ–ï¼Œå®ç°äº†ä½å»¶è¿Ÿçš„å›¾åƒé¢„...|
|ğŸ“ æ›´æ–°|StrCGAN: A Generative Framework for Stellar Image Restoration|æ’æ˜Ÿå›¾åƒå¤åŸçš„ç”Ÿæˆæ¡†æ¶ï¼šStrCGAN|Shantanusinh Parmar, Silas Janke|<https://arxiv.org/pdf/2509.19805v3>|æå‡ºStrCGANæ¨¡å‹ï¼Œé€šè¿‡å¤šå…‰è°±èåˆå’Œå¤©ä½“ç‰©ç†æ­£åˆ™åŒ–æ¨¡å—ï¼Œæœ‰æ•ˆæå‡äº†ä½åˆ†è¾¨ç‡å¤©ä½“å›¾åƒçš„æ¸…æ™°åº¦å’Œå½¢æ€...|
|ğŸ†• å‘å¸ƒ|ArtiBench and ArtiBrain: Benchmarking Generalizable Vision-Language Articulated Object Manipulation|â€œArtiBenchä¸ArtiBrainï¼šé€šç”¨è§†è§‰è¯­è¨€åè°ƒç‰©ä½“æ“ä½œåŸºå‡†æµ‹è¯•â€|Yuhan Wu, Tiantian Wei, Shuo Wang, ZhiChao Wang, Yanyong Zhang, Daniel Cremers, Yan Xia|<https://arxiv.org/pdf/2511.20330v1>|æå‡ºäº†ArtiBenchåŸºå‡†å’ŒArtiBrainæ¡†æ¶ï¼Œç”¨äºæå‡è§†è§‰è¯­è¨€åœ¨å…³èŠ‚å¯¹è±¡æ“ä½œä¸­çš„æ³›åŒ–èƒ½åŠ›å’Œé²...|
|ğŸ“ æ›´æ–°|ContextFlow: Training-Free Video Object Editing via Adaptive Context Enrichment|è‡ªé€‚åº”ä¸Šä¸‹æ–‡å¢å¼ºçš„æ— è®­ç»ƒè§†é¢‘å¯¹è±¡ç¼–è¾‘ï¼šContextFlow|Yiyang Chen, Xuanhua He, Xiujun Ma, Yue Ma|<https://arxiv.org/pdf/2509.17818v2>|æå‡ºContextFlowæ¡†æ¶ï¼Œé€šè¿‡è‡ªé€‚åº”ä¸Šä¸‹æ–‡å¢å¼ºå®ç°æ— éœ€è®­ç»ƒçš„è§†é¢‘å¯¹è±¡ç¼–è¾‘ï¼Œæœ‰æ•ˆè§£å†³å‡†ç¡®æ€§å’Œä¸€è‡´...|
|ğŸ“ æ›´æ–°|Dream-IF: Dynamic Relative EnhAnceMent for Image Fusion|åŠ¨æ€ç›¸å¯¹å¢å¼ºèåˆæ–¹æ³•ï¼šDream-IF|Xingxin Xu, Bing Cao, Dongdong Li, Qinghua Hu, Pengfei Zhu|<https://arxiv.org/pdf/2503.10109v2>|[ä»£ç ](https://github.com/jehovahxu/Dream-IF); æå‡ºäº†ä¸€ç§åŠ¨æ€ç›¸å¯¹å¢å¼ºæ¡†æ¶ï¼Œé€šè¿‡èåˆå›¾åƒçš„ä¼˜åŠ¿åŒºåŸŸå®ç°å›¾åƒå¢å¼ºä¸èåˆçš„ç»Ÿä¸€å¤„ç†ï¼Œæ˜¾è‘—æå‡äº†èåˆè´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|OmniRefiner: Reinforcement-Guided Local Diffusion Refinement|å…¨æ–¹ä½ç»†åŒ–å™¨ï¼šå¼ºåŒ–å¼•å¯¼å±€éƒ¨æ‰©æ•£ç»†åŒ–|Yaoli Liu, Ziheng Ouyang, Shengtao Lou, Yiren Song|<https://arxiv.org/pdf/2511.19990v1>|OmniRefineré€šè¿‡ç»“åˆå‚è€ƒå›¾åƒçš„ç²¾ç»†è°ƒæ•´å’Œå¼ºåŒ–å­¦ä¹ ä¼˜åŒ–çš„å±€éƒ¨ç¼–è¾‘ï¼Œæœ‰æ•ˆè§£å†³äº†ä¼ ç»Ÿæ‰©æ•£æ¨¡å‹åœ¨ç»†...|
|ğŸ“ æ›´æ–°|Natural Image Stitching Using Depth Maps|è‡ªç„¶å›¾åƒæ‹¼æ¥ä½¿ç”¨æ·±åº¦å›¾|Tianli Liao, Nan Li|<https://arxiv.org/pdf/2202.06276v3>|[ä»£ç ](https://github.com/tlliao/NIS_depths.); æå‡ºäº†ä¸€ç§åˆ©ç”¨æ·±åº¦å›¾è¿›è¡Œè‡ªç„¶å›¾åƒæ‹¼æ¥çš„æ–°æ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†éå¹³é¢åœºæ™¯å’Œæ‰‹æŒç›¸æœºæ‹æ‘„å¸¦æ¥çš„è§†å·®é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|Frequency Bias Matters: Diving into Robust and Generalized Deep Image Forgery Detection|é¢‘ç‡åå·®å¾ˆé‡è¦ï¼šæ·±å…¥æ¢ç©¶é²æ£’æ€§ä¸æ³›åŒ–çš„æ·±åº¦å›¾åƒä¼ªé€ æ£€æµ‹|Chi Liu, Tianqing Zhu, Wanlei Zhou, Wei Zhao|<https://arxiv.org/pdf/2511.19886v1>|æ­ç¤ºäº†é¢‘ç‡åå·®æ˜¯å½±å“å›¾åƒä¼ªé€ æ£€æµ‹æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§çš„æ ¹æœ¬åŸå› ï¼Œå¹¶æå‡ºäº†ä¸€ç§é¢‘ç‡å¯¹é½æ–¹æ³•æ¥æå‡æ£€æµ‹å™¨æ€§èƒ½...|
|ğŸ“ æ›´æ–°|Zero-Shot Video Translation via Token Warping|é›¶æ ·æœ¬è§†é¢‘è½¬æ¢é€šè¿‡æ ‡è®°æ‰­æ›²|Haiming Zhu, Yangyang Xu, Jun Yu, Shengfeng He|<https://arxiv.org/pdf/2402.12099v4>|[ä»£ç ](https://github.com/Alex-Zhu1/TokenWarping.); æå‡ºäº†ä¸€ç§TokenWarpingæ¡†æ¶ï¼Œé€šè¿‡ç›´æ¥å¯¹è§†é¢‘å¸§ä¸­çš„æŸ¥è¯¢ã€é”®å’Œå€¼è¿›è¡Œæ—¶ç©ºå˜æ¢ï¼Œå®ç°äº†é«˜è´¨é‡çš„...|
|ğŸ†• å‘å¸ƒ|GigaWorld-0: World Models as Data Engine to Empower Embodied AI|ã€ŠGigaWorld-0ï¼šå°†ä¸–ç•Œæ¨¡å‹ä½œä¸ºæ•°æ®å¼•æ“ä»¥èµ‹èƒ½å…·èº«äººå·¥æ™ºèƒ½ã€‹|GigaWorld Team, Angen Ye, Boyuan Wang, Chaojun Ni, Guan Huang, Guosheng Zhao, Haoyun Li, Jiagang Zhu .etc.|<https://arxiv.org/pdf/2511.19861v1>|æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„ä¸–ç•Œæ¨¡å‹æ¡†æ¶GigaWorld-0ï¼Œä½œä¸ºæ•°æ®å¼•æ“åŠ©åŠ›è§†è§‰è¯­è¨€è¡ŒåŠ¨å­¦ä¹ ï¼Œç”Ÿæˆé«˜è´¨é‡ã€å¤š...|
|ğŸ“ æ›´æ–°|MovieDreamer: Hierarchical Generation for Coherent Long Visual Sequence|ã€ŠMovieDreamerï¼šç”¨äºç”Ÿæˆè¿è´¯é•¿è§†è§‰åºåˆ—çš„å±‚æ¬¡åŒ–æ–¹æ³•ã€‹|Canyu Zhao, Mingyu Liu, Wen Wang, Weihua Chen, Fan Wang, Hao Chen, Bo Zhang, Chunhua Shen|<https://arxiv.org/pdf/2407.16655v3>|[ä»£ç ](https://aim-uofa.github.io/MovieDreamer); æå‡ºMovieDreamerï¼Œä¸€ç§ç»“åˆè‡ªå›å½’æ¨¡å‹ä¸æ‰©æ•£æ¸²æŸ“çš„æ¡†æ¶ï¼Œå®ç°é•¿è§†é¢‘ç”Ÿæˆå¹¶ä¿æŒæ•…äº‹è¿è´¯ä¸è§†è§‰...|
|ğŸ†• å‘å¸ƒ|Reading Between the Lines: Abstaining from VLM-Generated OCR Errors via Latent Representation Probes|ã€Šè¡Œé—´é˜…è¯»ï¼šé€šè¿‡æ½œåœ¨è¡¨å¾æ¢é’ˆé¿å…VLMç”ŸæˆOCRé”™è¯¯ã€‹|Jihan Yao, Achin Kulshrestha, Nathalie Rauschmayr, Reed Roberts, Banghua Zhu, Yulia Tsvetkov, Federico Tombari|<https://arxiv.org/pdf/2511.19806v1>|æå‡ºäº†ä¸€ç§åŸºäºå†…éƒ¨è¡¨å¾çš„æ¢æµ‹æ–¹æ³•ï¼Œæ˜¾è‘—æå‡è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ä¸ç¡®å®šæƒ…å†µä¸‹çš„æ‹’ç»å›ç­”å‡†ç¡®æ€§ã€‚|


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|3D-Aware Multi-Task Learning with Cross-View Correlations for Dense Scene Understanding|ä¸‰ç»´æ„ŸçŸ¥çš„å¤šä»»åŠ¡å­¦ä¹ ï¼šåˆ©ç”¨è·¨è§†å›¾ç›¸å…³æ€§è¿›è¡Œå¯†é›†åœºæ™¯ç†è§£|Xiaoye Wang, Chen Tang, Xiangyu Yue, Wei-Hong Li|<https://arxiv.org/pdf/2511.20646v1>|å¼•å…¥è·¨è§†å›¾ç›¸å…³æ€§æ¨¡å—ï¼Œæå‡å¤šä»»åŠ¡å­¦ä¹ ç½‘ç»œå¯¹ä¸‰ç»´åœºæ™¯ç†è§£çš„å‡ ä½•ä¸€è‡´æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Material-informed Gaussian Splatting for 3D World Reconstruction in a Digital Twin|åŸºäºææ–™ä¿¡æ¯çš„é«˜æ–¯æ•£ç‚¹ç»˜åˆ¶ç”¨äºæ•°å­—å­ªç”Ÿä¸­çš„ä¸‰ç»´ä¸–ç•Œé‡å»º|JoÃ£o Malheiro Silva, Andy Huynh, Tong Duy Son, Holger Caesar|<https://arxiv.org/pdf/2511.20348v1>|æå‡ºäº†ä¸€ç§æ— éœ€å¤æ‚æ ¡å‡†çš„ç›¸æœºä»…é‡å»ºæ–¹æ³•ï¼Œç»“åˆ3Dé«˜æ–¯æ•£ç‚¹ä¸æè´¨ä¿¡æ¯ï¼Œå®ç°ä¸LiDARèåˆç›¸å½“çš„æ•ˆæœã€‚|
|ğŸ†• å‘å¸ƒ|VGGTFace: Topologically Consistent Facial Geometry Reconstruction in the Wild|VGGTFaceï¼šåœ¨é‡å¤–ç¯å¢ƒä¸­ä¿æŒæ‹“æ‰‘ä¸€è‡´æ€§çš„é¢éƒ¨å‡ ä½•é‡å»º|Xin Ming, Yuxuan Han, Tianyu Huang, Feng Xu|<https://arxiv.org/pdf/2511.20366v1>|[ä»£ç ](https://github.com/grignarder/vggtface.); æå‡ºVGGTFaceæ–¹æ³•ï¼Œåˆ©ç”¨3DåŸºç¡€æ¨¡å‹è‡ªåŠ¨ä»å¤šè§†è§’å›¾åƒé‡å»ºé¢éƒ¨å‡ ä½•ç»“æ„ï¼Œå®ç°æ‹“æ‰‘ä¸€è‡´æ€§å¹¶æå‡æ³›åŒ–...|
|ğŸ†• å‘å¸ƒ|AMB3R: Accurate Feed-forward Metric-scale 3D Reconstruction with Backend|AMB3Rï¼šå…·æœ‰åç«¯æ”¯æŒçš„é«˜ç²¾åº¦å‰é¦ˆåº¦é‡çº§ä¸‰ç»´é‡å»º|Hengyi Wang, Lourdes Agapito|<https://arxiv.org/pdf/2511.20343v1>|æå‡ºAMB3Ræ¨¡å‹ï¼Œé€šè¿‡ç´§å‡‘çš„ä¸‰ç»´ä½“ç§¯è¡¨ç¤ºå®ç°ç²¾ç¡®çš„åº¦é‡çº§ä¸‰ç»´é‡å»ºï¼Œæ‰©å±•é€‚ç”¨äºå¤šç§è§†è§‰ä»»åŠ¡ã€‚|
|ğŸ†• å‘å¸ƒ|Prompting Lipschitz-constrained network for multiple-in-one sparse-view CT reconstruction|ç”¨äºå¤šåˆä¸€ç¨€ç–è§†è§’CTé‡å»ºçš„Lipschitzçº¦æŸç½‘ç»œæç¤ºæ–¹æ³•|Baoshun Shi, Ke Jiang, Qiusheng Lian, Xinran Yu, Huazhu Fu|<https://arxiv.org/pdf/2511.20296v1>|[ä»£ç ](https://github.com/shibaoshun/PromptCT.); æå‡ºäº†ä¸€ç§é›†æˆæ˜¾å¼Lipschitzçº¦æŸå’Œæç¤ºæ¨¡å—çš„å•ä¸€æ¨¡å‹ï¼Œå®ç°äº†å¤šé…ç½®ç¨€ç–è§†å›¾CTé‡å»ºçš„é«˜è´¨é‡è¾“...|
|ğŸ“ æ›´æ–°|Multi-view Surface Reconstruction Using Normal and Reflectance Cues|å¤šè§†è§’è¡¨é¢é‡å»ºåˆ©ç”¨æ³•å‘é‡å’Œåå°„ç‡çº¿ç´¢|Robin Bruneau, Baptiste Brument, Yvain QuÃ©au, Jean MÃ©lou, FranÃ§ois Bernard Lauze, Jean-Denis Durou, Lilian Calvet|<https://arxiv.org/pdf/2506.04115v2>|[ä»£ç ](https://github.com/RobinBruneau/RNb-NeuS2.); å¼•å…¥å¤šè§†è§’æ³•çº¿å’Œåå°„å›¾ï¼Œæå‡å¤æ‚æè´¨è¡¨é¢ç»†èŠ‚çš„3Dé‡å»ºç²¾åº¦ã€‚|
|ğŸ“ æ›´æ–°|MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian Splatting|"MeshSplatï¼šé€šè¿‡é«˜æ–¯æ•£ç‚¹æŠ•å°„å®ç°é€šç”¨æ€§ç¨€ç–è§†å›¾è¡¨é¢é‡å»º"|Hanzhi Chang, Ruijie Zhu, Wenjie Chang, Mulin Yu, Yanzhe Liang, Jiahao Lu, Zhuoyuan Li, Tianzhu Zhang|<https://arxiv.org/pdf/2508.17811v2>|[ä»£ç ](https://hanzhichang.github.io/meshsplat_web); æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯æ•£ç‚¹çš„é€šç”¨ç¨€ç–è§†è§’è¡¨é¢é‡å»ºæ¡†æ¶ï¼Œé€šè¿‡è¿æ¥æ–°è§†è§’åˆæˆä¸å­¦ä¹ åˆ°çš„å‡ ä½•å…ˆéªŒï¼Œå®ç°äº†æ— éœ€3...|
|ğŸ“ æ›´æ–°|SplatCo: Structure-View Collaborative Gaussian Splatting for Detail-Preserving Rendering of Large-Scale Unbounded Scenes|â€œSplatCoï¼šåŸºäºç»“æ„è§†è§’ååŒçš„é«˜æ–¯æ•£ç‚¹æ¸²æŸ“æ–¹æ³•ï¼Œç”¨äºä¿ç•™å¤§è§„æ¨¡æ— ç•Œåœºæ™¯ç»†èŠ‚çš„æ¸²æŸ“â€|Haihong Xiao, Jianan Zou, Yuxin Zhou, Ying He, Wenxiong Kang|<https://arxiv.org/pdf/2505.17951v3>|[ä»£ç ](https://github.com/SCUT-BIP-Lab/SplatCo.); æå‡ºäº†ä¸€ç§ç»“æ„è§†å›¾åä½œçš„é«˜ä¿çœŸæ¸²æŸ“æ¡†æ¶ï¼Œé€šè¿‡å…¨å±€ä¸å±€éƒ¨ç‰¹å¾èåˆåŠå¤šè§†è§’è®­ç»ƒç­–ç•¥ï¼Œæ˜¾è‘—æå‡äº†å¤§è§„æ¨¡æ— ç•Œ...|
|ğŸ“ æ›´æ–°|DVP-MVS: Synergize Depth-Edge and Visibility Prior for Multi-View Stereo|DVP-MVSï¼šèåˆæ·±åº¦è¾¹ç¼˜å’Œå¯è§æ€§å…ˆéªŒçš„å¤šè§†è§’ç«‹ä½“åŒ¹é…|Zhenlong Yuan, Jinguo Luo, Fei Shen, Zhaoxin Li, Cong Liu, Tianlu Mao, Zhaoqi Wang|<https://arxiv.org/pdf/2412.11578v3>|æå‡ºäº†ä¸€ç§ç»“åˆæ·±åº¦è¾¹ç¼˜å¯¹é½å’Œè·¨è§†è§’å…ˆéªŒçš„ç¨³å¥ä¸”å…·æœ‰å¯è§†æ€§æ„ŸçŸ¥çš„ä¿®è¡¥å˜å½¢æ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†å¤šè§†è§’ç«‹ä½“é‡å»º...|
|ğŸ†• å‘å¸ƒ|STAvatar: Soft Binding and Temporal Density Control for Monocular 3D Head Avatars Reconstruction|STAvatarï¼šå•ç›®3Däººå¤´è™šæ‹Ÿé‡å»ºä¸­çš„è½¯ç»‘å®šä¸æ—¶é—´å¯†åº¦æ§åˆ¶|Jiankuo Zhao, Xiangyu Zhu, Zidu Wang, Zhen Lei|<https://arxiv.org/pdf/2511.19854v1>|STAvataré€šè¿‡è½¯ç»‘å®šå’Œæ—¶åºå¯†åº¦æ§åˆ¶æŠ€æœ¯ï¼Œå®ç°äº†ä»å•ç›®è§†é¢‘é‡å»ºé«˜è´¨é‡ã€å¯åŠ¨ç”»åŒ–çš„3Då¤´åƒã€‚|


### è§†è§‰å®šä½ä¸æ˜ å°„ (Visual Localization & Mapping)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|FastGS: Training 3D Gaussian Splatting in 100 Seconds|å¿«é€Ÿé«˜æ–¯æ•£ç‚¹è®­ç»ƒï¼š100ç§’å†…å®Œæˆä¸‰ç»´é«˜æ–¯æ•£ç‚¹ç»˜åˆ¶|Shiwei Ren, Tianci Wen, Yongchun Fang, Biao Lu|<https://arxiv.org/pdf/2511.04283v2>|æå‡ºFastGSæ–¹æ³•ï¼Œé€šè¿‡å¤šè§†è§’ä¸€è‡´æ€§ä¼˜åŒ–é«˜æ–¯åˆ†å¸ƒè®­ç»ƒï¼Œå¤§å¹…æå‡è®­ç»ƒé€Ÿåº¦åŒæ—¶ä¿æŒæ¸²æŸ“è´¨é‡ã€‚|


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|SuperQuadricOcc: Multi-Layer Gaussian Approximation of Superquadrics for Real-Time Self-Supervised Occupancy Estimation|è¶…äºŒæ¬¡ä½“å ç”¨ï¼šå¤šå±‚é«˜æ–¯è¿‘ä¼¼è¶…äºŒæ¬¡ä½“ç”¨äºå®æ—¶è‡ªç›‘ç£å ç”¨ä¼°è®¡|Seamie Hayes, Reenu Mohandas, Tim Brophy, Alexandre Boulch, Ganesh Sistu, Ciaran Eising|<https://arxiv.org/pdf/2511.17361v2>|[ä»£ç ](https://github.com/seamie6/SuperQuadricOcc.); æå‡ºäº†ä¸€ç§åŸºäºè¶…äºŒæ¬¡ä½“çš„å®æ—¶è‡ªç›‘ç£å ç”¨ä¼°è®¡æ–¹æ³•ï¼Œå¤§å¹…é™ä½äº†å†…å­˜éœ€æ±‚å’Œæé«˜äº†æ¨ç†é€Ÿåº¦ã€‚|
|ğŸ“ æ›´æ–°|Prompt Guiding Multi-Scale Adaptive Sparse Representation-driven Network for Low-Dose CT MAR|åŸºäºæç¤ºå¼•å¯¼çš„å¤šå°ºåº¦è‡ªé€‚åº”ç¨€ç–è¡¨ç¤ºé©±åŠ¨çš„ç½‘ç»œç”¨äºä½å‰‚é‡CTå»å™ª|Baoshun Shi, Bing Chen, Shaolei Zhang, Huazhu Fu, Zhanli Hu|<https://arxiv.org/pdf/2504.19687v3>|æå‡ºäº†ä¸€ç§å¤šå°ºåº¦è‡ªé€‚åº”ç¨€ç–è¡¨ç¤ºé©±åŠ¨çš„ç½‘ç»œï¼Œé€šè¿‡æç¤ºå¼•å¯¼ç­–ç•¥å®ç°äº†ä½å‰‚é‡CTé‡å»ºå’Œé‡‘å±ä¼ªå½±å‡å°‘çš„ç»Ÿä¸€æ¨¡...|
|ğŸ†• å‘å¸ƒ|DeLightMono: Enhancing Self-Supervised Monocular Depth Estimation in Endoscopy by Decoupling Uneven Illumination|ã€ŠDeLightMonoï¼šé€šè¿‡è§£è€¦ä¸å‡åŒ€ç…§æ˜å¢å¼ºå†…çª¥é•œä¸­è‡ªç›‘ç£å•ç›®æ·±åº¦ä¼°è®¡ã€‹|Mingyang Ou, Haojin Li, Yifeng Zhang, Ke Niu, Zhongxi Qiu, Heng Li, Jiang Liu|<https://arxiv.org/pdf/2511.20058v1>|æå‡ºäº†ä¸€ç§é’ˆå¯¹å†…çª¥é•œå›¾åƒä¸å‡åŒ€ç…§æ˜çš„è‡ªç›‘ç£å•ç›®æ·±åº¦ä¼°è®¡æ¡†æ¶ï¼Œé€šè¿‡è§£è€¦ç…§æ˜å’Œåå°„ä¿¡æ¯æ¥æå‡æ·±åº¦ä¼°è®¡å‡†ç¡®...|
|ğŸ“ æ›´æ–°|LiHi-GS: LiDAR-Supervised Gaussian Splatting for Highway Driving Scene Reconstruction|LiHi-GSï¼šæ¿€å…‰é›·è¾¾ç›‘ç£é«˜æ–¯æ•£ç‚¹ç»˜åˆ¶æ³•ç”¨äºé«˜é€Ÿå…¬è·¯é©¾é©¶åœºæ™¯é‡å»º|Pou-Chun Kung, Xianling Zhang, Katherine A. Skinner, Nikita Jaipuria|<https://arxiv.org/pdf/2412.15447v3>|[ä»£ç ](https://umautobots.github.io/lihi_gs); æå‡ºäº†ä¸€ç§é’ˆå¯¹é«˜é€Ÿå…¬è·¯åœºæ™¯çš„LiDARç›‘ç£é«˜æ–¯æ•£ç‚¹æ³•ï¼Œé€šè¿‡åˆ©ç”¨LiDARæ·±åº¦ä¿¡æ¯æå‡åœºæ™¯é‡å»ºè´¨é‡ã€‚|
|ğŸ“ æ›´æ–°|High Resolution UDF Meshing via Iterative Networks|é€šè¿‡è¿­ä»£ç½‘ç»œå®ç°é«˜åˆ†è¾¨ç‡UDFç½‘æ ¼åŒ–|Federico Stella, Nicolas Talabot, Hieu Le, Pascal Fua|<https://arxiv.org/pdf/2509.17212v2>|æå‡ºäº†ä¸€ç§è¿­ä»£ç¥ç»ç½‘ç»œæ–¹æ³•ï¼Œé€šè¿‡ç©ºé—´ä¼ æ’­é‚»åŸŸä¿¡æ¯ï¼Œæ˜¾è‘—æé«˜äº†é«˜åˆ†è¾¨ç‡UDFç½‘æ ¼åŒ–ç²¾åº¦å’Œå®Œæ•´æ€§ã€‚|


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Mistake Attribution: Fine-Grained Mistake Understanding in Egocentric Videos|é”™è¯¯å½’å› ï¼šç¬¬ä¸€è§†è§’è§†é¢‘ä¸­çš„ç»†ç²’åº¦é”™è¯¯ç†è§£|Yayuan Li, Aadit Jain, Filippos Bellos, Jason J. Corso|<https://arxiv.org/pdf/2511.20525v1>|æå‡ºMistake Attributionä»»åŠ¡ï¼Œé€šè¿‡MisFormeræ¨¡å‹ç²¾ç¡®å½’å›  egocentr...|
|ğŸ“ æ›´æ–°|ExDDV: A New Dataset for Explainable Deepfake Detection in Video|å¯è§£é‡Šæ·±åº¦ä¼ªé€ æ£€æµ‹è§†é¢‘æ–°æ•°æ®é›†ï¼šExDDV|Vlad Hondru, Eduard Hogea, Darian Onchis, Radu Tudor Ionescu|<https://arxiv.org/pdf/2503.14421v2>|[ä»£ç ](https://github.com/vladhondru25/ExDDV.); æå‡ºé¦–ä¸ªç”¨äºå¯è§£é‡Šè§†é¢‘ deepfake æ£€æµ‹çš„ ExDDV æ•°æ®é›†ï¼Œç»“åˆæ–‡æœ¬å’Œç‚¹å‡»æ³¨é‡Šæå‡æ¨¡å‹é²æ£’...|
|ğŸ“ æ›´æ–°|Detecting Cultural Differences in News Video Thumbnails via Computational Aesthetics|é€šè¿‡è®¡ç®—ç¾å­¦æ£€æµ‹æ–°é—»è§†é¢‘ç¼©ç•¥å›¾ä¸­çš„æ–‡åŒ–å·®å¼‚|Marvin Limpijankit, John Kender|<https://arxiv.org/pdf/2505.21912v2>|æå‡ºä¸¤é˜¶æ®µè®¡ç®—ç¾å­¦æ–¹æ³•ï¼ŒåŒºåˆ†ä¸åŒæ–‡åŒ–æ¥æºå›¾åƒé£æ ¼å·®å¼‚ï¼Œå‘ç°ä¸­ç¾YouTubeè§†é¢‘ç¼©ç•¥å›¾é£æ ¼å·®å¼‚åæ˜ æ–‡...|
|ğŸ†• å‘å¸ƒ|Back to the Feature: Explaining Video Classifiers with Video Counterfactual Explanations|å›å½’ç‰¹å¾ï¼šä½¿ç”¨è§†é¢‘åäº‹å®è§£é‡Šå¯¹è§†é¢‘åˆ†ç±»å™¨è¿›è¡Œè§£é‡Š|Chao Wang, Chengan Che, Xinyue Chen, Sophia Tsoka, Luis C. Garcia-Peraza-Herrera|<https://arxiv.org/pdf/2511.20295v1>|æå‡ºäº†ä¸€ç§ä¼˜åŒ–æ¡†æ¶Back To The Featureï¼Œç”Ÿæˆç¬¦åˆç‰©ç†è§„å¾‹ä¸”æ—¶é—´è¿è´¯çš„è§†é¢‘åäº‹å®è§£é‡Š...|
|ğŸ“ æ›´æ–°|X-ReID: Multi-granularity Information Interaction for Video-Based Visible-Infrared Person Re-Identification|åŸºäºè§†é¢‘çš„å¯è§å…‰-çº¢å¤–å¤šç²’åº¦ä¿¡æ¯äº¤äº’çš„äººé‡è¯†åˆ«ï¼šX-ReID|Chenyang Yu, Xuehu Liu, Pingping Zhang, Huchuan Lu|<https://arxiv.org/pdf/2511.17964v2>|[ä»£ç ](https://github.com/AsuradaYuci/X-ReID.); æå‡ºäº†ä¸€ç§è·¨æ¨¡æ€ç‰¹å¾å­¦ä¹ æ¡†æ¶X-ReIDï¼Œé€šè¿‡å¤šç²’åº¦ä¿¡æ¯äº¤äº’æœ‰æ•ˆç¼©å°æ¨¡æ€å·®å¼‚å¹¶å¢å¼ºè§†é¢‘æ—¶åºå»ºæ¨¡ã€‚|
|ğŸ“ æ›´æ–°|VidComposition: Can MLLMs Analyze Compositions in Compiled Videos?|VidCompositionï¼šå¤§å‹è¯­è¨€æ¨¡å‹èƒ½å¦åˆ†ææ±‡ç¼–è§†é¢‘ä¸­çš„æ„æˆï¼Ÿ|Yolo Y. Tang, Junjia Guo, Hang Hua, Susan Liang, Mingqian Feng, Xinyang Li, Rui Mao, Chao Huang .etc.|<https://arxiv.org/pdf/2411.10979v5>|[ä»£ç ](https://yunlong10.github.io/VidComposition); æå‡ºVidCompositionåŸºå‡†ï¼Œè¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å¯¹è§†é¢‘æ„æˆçš„ç†è§£èƒ½åŠ›ï¼Œæ­ç¤ºæ¨¡å‹ä¸äººç±»åœ¨å¤æ‚...|
|ğŸ“ æ›´æ–°|Video Understanding with Large Language Models: A Survey|è§†é¢‘ç†è§£ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼šç»¼è¿°|Yolo Y. Tang, Jing Bi, Siting Xu, Luchuan Song, Susan Liang, Teng Wang, Daoan Zhang, Jie An .etc.|<https://arxiv.org/pdf/2312.17432v8>|[ä»£ç ](https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding.); å®šä½å¹¶ç»¼è¿°äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è§†é¢‘ç†è§£ä¸­çš„åº”ç”¨ï¼Œåˆ†ç±»äº†ä¸åŒæ–¹æ³•å¹¶æ¢è®¨äº†æœªæ¥ç ”ç©¶æ–¹å‘ã€‚|


### è§†é¢‘ç›®æ ‡è·Ÿè¸ª (Video Object Tracking)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|StableTrack: Stabilizing Multi-Object Tracking on Low-Frequency Detections|ã€ŠStableTrackï¼šåœ¨ä½é¢‘æ£€æµ‹ä¸‹ç¨³å®šçš„å¤šç›®æ ‡è·Ÿè¸ªã€‹|Matvei Shelukhan, Timur Mamedov, Karina Kvanchiani|<https://arxiv.org/pdf/2511.20418v1>|StableTracké€šè¿‡åˆ›æ–°çš„ä¸¤é˜¶æ®µåŒ¹é…ç­–ç•¥å’ŒåŸºäºè¾¹æ¡†çš„è·ç¦»åº¦é‡ï¼Œæœ‰æ•ˆæå‡äº†ä½é¢‘ç‡æ£€æµ‹ä¸‹çš„å¤šç›®æ ‡è·Ÿ...|
|ğŸ†• å‘å¸ƒ|Realizing Fully-Integrated, Low-Power, Event-Based Pupil Tracking with Neuromorphic Hardware|å®ç°åŸºäºç±»ç¥ç»å½¢æ€ç¡¬ä»¶çš„å…¨é›†æˆã€ä½åŠŸè€—äº‹ä»¶é©±åŠ¨ç³å­”è¿½è¸ª|Federico Paredes-Valles, Yoshitaka Miyatani, Kirk Y. W. Scheper|<https://arxiv.org/pdf/2511.20175v1>|å®ç°äº†ä¸€ç§é›†æˆåœ¨ç”µæ± ä¾›ç”µå¯ç©¿æˆ´è®¾å¤‡ä¸Šçš„ä½åŠŸè€—åŸºäºäº‹ä»¶çš„ç³å­”è¿½è¸ªç³»ç»Ÿï¼Œç»“åˆäº†äº‹ä»¶æ„ŸçŸ¥å’Œç±»ç¥ç»å½¢æ€å¤„ç†ã€‚|
|ğŸ†• å‘å¸ƒ|While recognizing actions, LMMs struggle to detect core interaction events|åœ¨è¯†åˆ«åŠ¨ä½œæ—¶ï¼ŒLMMséš¾ä»¥æ£€æµ‹æ ¸å¿ƒäº¤äº’äº‹ä»¶|Daniel Harari, Michael Sidorov, Liel David, Chen Shterental, Abrham Kahsay Gebreselasie, Muhammad Haris Khan|<https://arxiv.org/pdf/2511.20162v1>|å‘ç°å¤§å‹å¤šæ¨¡æ€æ¨¡å‹åœ¨è¯†åˆ«åŠ¨æ€äº¤äº’äº‹ä»¶æ—¶åˆ»å’Œä½ç½®ä¸Šå­˜åœ¨å›°éš¾ï¼Œå¼•å…¥äº†é¦–ä¸ªå¤§è§„æ¨¡äº¤äº’äº‹ä»¶æ ‡æ³¨æ•°æ®é›†ã€‚|
|ğŸ†• å‘å¸ƒ|Learning Procedural-aware Video Representations through State-Grounded Hierarchy Unfolding|é€šè¿‡çŠ¶æ€åŸºç¡€å±‚æ¬¡å±•å¼€å­¦ä¹ è¿‡ç¨‹æ„ŸçŸ¥è§†é¢‘è¡¨ç¤º|Jinghan Zhao, Yifei Huang, Feng Lu|<https://arxiv.org/pdf/2511.20073v1>|æå‡ºåŸºäºçŠ¶æ€çš„è§†è§‰è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡åˆ†å±‚æ¬¡é¢„è®­ç»ƒæå‡æ¨¡å‹å¯¹å¤æ‚ä»»åŠ¡çš„ç†è§£å’Œæ‰§è¡Œèƒ½åŠ›ã€‚|
|ğŸ“ æ›´æ–°|Click2Graph: Interactive Panoptic Video Scene Graphs from a Single Click|ç‚¹å‡»æˆå›¾ï¼šä»å•æ¬¡ç‚¹å‡»ç”Ÿæˆäº¤äº’å¼å…¨åœºæ™¯è§†é¢‘åœºæ™¯å›¾|Raphael Ruschel, Hardikkumar Prajapati, Awsafur Rahman, B. S. Manjunath|<https://arxiv.org/pdf/2511.15948v2>|é¦–æ¬¡æå‡ºäº¤äº’å¼å…¨æ™¯è§†é¢‘åœºæ™¯å›¾ç”Ÿæˆæ¡†æ¶ï¼Œç»“åˆç”¨æˆ·æç¤ºä¸è§†è§‰ç†è§£ï¼Œå®ç°å¯æ§ä¸”å¯è§£é‡Šçš„è§†é¢‘åœºæ™¯ç†è§£ã€‚|
|ğŸ“ æ›´æ–°|Rethinking Two-Stage Referring-by-Tracking in Referring Multi-Object Tracking: Make it Strong Again|é‡æ–°æ€è€ƒåœ¨æŒ‡å¼•ç”¨å¤šç›®æ ‡è·Ÿè¸ªä¸­çš„ä¸¤é˜¶æ®µè·Ÿè¸ªæ–¹æ³•ï¼šè®©å…¶å†æ¬¡å¼ºå¤§èµ·æ¥|Weize Li, Yunhao Du, Qixiang Yin, Zhicheng Zhao, Fei Su|<https://arxiv.org/pdf/2503.07516v4>|æå‡ºFlexHookæ¡†æ¶ï¼Œé€šè¿‡é‡‡æ ·ç­–ç•¥å’Œè¯­è¨€æ¡ä»¶åŒ–æ”¹è¿›ä¸¤é˜¶æ®µè·Ÿè¸ªæ–¹æ³•ï¼Œå®ç°æ€§èƒ½è¶…è¶Šç°æœ‰æŠ€æœ¯ã€‚|


### æ—¶åºå»ºæ¨¡ä¸é¢„æµ‹ (Temporal Modeling & Prediction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ACIT: Attention-Guided Cross-Modal Interaction Transformer for Pedestrian Crossing Intention Prediction|è¡Œäººæ¨ªç©¿æ„å›¾é¢„æµ‹çš„æ³¨æ„åŠ›å¼•å¯¼è·¨æ¨¡æ€äº¤äº’å˜æ¢å™¨ï¼ˆACITï¼‰|Yuanzhe Li, Steffen MÃ¼ller|<https://arxiv.org/pdf/2511.20020v1>|æå‡ºäº†ä¸€ç§åŸºäºTransformerçš„æ³¨æ„åŠ›å¼•å¯¼è·¨æ¨¡æ€äº¤äº’æ–¹æ³•ï¼Œæœ‰æ•ˆé¢„æµ‹è¡Œäººæ¨ªç©¿æ„å›¾å¹¶æå‡å‡†ç¡®ç‡ã€‚|
|ğŸ†• å‘å¸ƒ|GazeProphetV2: Head-Movement-Based Gaze Prediction Enabling Efficient Foveated Rendering on Mobile VR|ã€ŠGazeProphetV2ï¼šåŸºäºå¤´éƒ¨è¿åŠ¨çš„æ³¨è§†é¢„æµ‹ï¼Œå®ç°ç§»åŠ¨è™šæ‹Ÿç°å®ä¸­çš„é«˜æ•ˆç„¦ç‚¹æ¸²æŸ“ã€‹|Farhaan Ebadulla, Chiraag Mudlpaur, Shreya Chaurasia, Gaurav BV|<https://arxiv.org/pdf/2511.19988v1>|é¢„æµ‹è™šæ‹Ÿç°å®ç¯å¢ƒä¸‹ç”¨æˆ·è§†çº¿è¡Œä¸ºï¼Œé€šè¿‡èåˆè§†çº¿å†å²ã€å¤´éƒ¨è¿åŠ¨å’Œåœºæ™¯ä¿¡æ¯ï¼Œæé«˜äº†è§†çº¿é¢„æµ‹å‡†ç¡®æ€§ã€‚|


### åŠ¨ä½œè¯†åˆ«ä¸ç†è§£ (Action Recognition & Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|GFT-GCN: Privacy-Preserving 3D Face Mesh Recognition with Spectral Diffusion|è°±æ‰©æ•£ä¿æŠ¤çš„éšç§ä¿æŒä¸‰ç»´äººè„¸ç½‘æ ¼è¯†åˆ«GFT-GCN|Hichem Felouat, Hanrui Wang, Isao Echizen|<https://arxiv.org/pdf/2511.19958v1>|æå‡ºäº†ä¸€ç§ç»“åˆå›¾é¢‘è°±å­¦ä¹ å’Œæ‰©æ•£ä¿æŠ¤çš„éšç§ä¿æŠ¤3Däººè„¸è¯†åˆ«æ¡†æ¶ï¼Œå®ç°äº†é«˜å‡†ç¡®åº¦è¯†åˆ«ä¸æ•°æ®å®‰å…¨ã€‚|


## è‡ªç›‘ç£ä¸è¡¨å¾å­¦ä¹  (Self-supervised & Representation Learning)


### è¡¨å¾çŸ¥è¯†è¿ç§» (Representation Knowledge Transfer)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Distilling Cross-Modal Knowledge via Feature Disentanglement|é€šè¿‡ç‰¹å¾è§£è€¦è’¸é¦è·¨æ¨¡æ€çŸ¥è¯†|Junhong Liu, Yuan Zhang, Tao Huang, Wenchao Xu, Renyu Yang|<https://arxiv.org/pdf/2511.19887v1>|[ä»£ç ](https://github.com/Johumliu/FD-CMKD.); æå‡ºäº†ä¸€ç§é€šè¿‡é¢‘ç‡è§£è€¦å®ç°çš„è·¨æ¨¡æ€çŸ¥è¯†è’¸é¦æ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†ä¸åŒæ¨¡æ€é—´çŸ¥è¯†ä¼ é€’å›°éš¾çš„é—®é¢˜ã€‚|


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Evaluating the Performance of Deep Learning Models in Whole-body Dynamic 3D Posture Prediction During Load-reaching Activities|è¯„ä¼°æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨è´Ÿè½½ä¼¸å±•æ´»åŠ¨ä¸­å…¨èº«åŠ¨æ€3Då§¿æ€é¢„æµ‹çš„æ€§èƒ½|Seyede Niloofar Hosseini, Ali Mojibi, Mahdi Mohseni, Navid Arjmand, Alireza Taheri|<https://arxiv.org/pdf/2511.20615v1>|æå‡ºäº†ä¸€ç§ä¼˜åŒ–ä»£ä»·å‡½æ•°çš„æ–¹æ³•ï¼Œé€šè¿‡ä¿æŒèº«ä½“æ®µé•¿åº¦æ’å®šï¼Œæ˜¾è‘—æå‡äº†æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å…¨èº«åŠ¨æ€3Då§¿æ€é¢„æµ‹ä¸­...|
|ğŸ†• å‘å¸ƒ|Optimization of Sums of Bivariate Functions: An Introduction to Relaxation-Based Methods for the Case of Finite Domains|åŒå˜é‡å‡½æ•°å’Œçš„ä¼˜åŒ–ï¼šæœ‰é™åŸŸæƒ…å†µä¸‹åŸºäºæ¾å¼›æ–¹æ³•å¯¼è®º|Nils MÃ¼ller|<https://arxiv.org/pdf/2511.20607v1>|æå‡ºäº†ä¸€ç§åŸºäºæ¾å¼›æ–¹æ³•ä¼˜åŒ–äºŒå…ƒå’Œå‡½æ•°çš„ç­–ç•¥ï¼Œæœ‰æ•ˆè§£å†³äº†NPéš¾åº¦é—®é¢˜å¹¶é€‚ç”¨äºå¤šç§å‡½æ•°ç±»ã€‚|
|ğŸ†• å‘å¸ƒ|Modular Deep Learning Framework for Assistive Perception: Gaze, Affect, and Speaker Identification|è¾…åŠ©æ„ŸçŸ¥çš„æ¨¡å—åŒ–æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼šè§†çº¿ã€æƒ…æ„Ÿä¸æ¼”è®²è€…è¯†åˆ«|Akshit Pramod Anchan, Jewelith Thomas, Sritama Roy|<https://arxiv.org/pdf/2511.20474v1>|æå‡ºäº†ä¸€ç§æ¨¡å—åŒ–æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡ç‹¬ç«‹è§†è§‰å’Œå¬è§‰æ„ŸçŸ¥æ¨¡å—ï¼Œå®ç°äº†è¾…åŠ©æŠ€æœ¯çš„é«˜ç²¾åº¦è¯†åˆ«ä¸é›†æˆã€‚|
|ğŸ†• å‘å¸ƒ|A Physics-Informed Loss Function for Boundary-Consistent and Robust Artery Segmentation in DSA Sequences|ç‰©ç†ä¿¡æ¯å¼•å¯¼çš„æŸå¤±å‡½æ•°ç”¨äºDSAåºåˆ—ä¸­è¾¹ç•Œä¸€è‡´ä¸”ç¨³å¥çš„åŠ¨è„‰åˆ†å‰²|Muhammad Irfan, Nasir Rahim, Khalid Mahmood Malik|<https://arxiv.org/pdf/2511.20501v1>|[ä»£ç ](https://github.com/irfantahir301/Physicsis_loss.); æå‡ºäº†ä¸€ç§ç‰©ç†ä¿¡æ¯æŸå¤±å‡½æ•°ï¼Œé€šè¿‡æ¨¡æ‹Ÿè¡€ç®¡è¾¹ç•Œçš„å¼¹æ€§äº’åŠ¨ï¼Œæé«˜äº†DSAåºåˆ—ä¸­åŠ¨è„‰åˆ†å‰²çš„å‡†ç¡®æ€§å’Œç¨³å®šæ€§ã€‚|
|ğŸ“ æ›´æ–°|Exploring Convolutional Neural Networks for Rice Grain Classification: An Explainable AI Approach|æ¢ç´¢å·ç§¯ç¥ç»ç½‘ç»œåœ¨æ°´ç¨»è°·ç‰©åˆ†ç±»ä¸­çš„åº”ç”¨ï¼šä¸€ç§å¯è§£é‡Šçš„äººå·¥æ™ºèƒ½æ–¹æ³•|Muhammad Junaid Asif, Hamza Khan, Rabia Tehseen, Rana Fayyaz Ahmad, Mujtaba Asad, Syed Tahir Hussain Rizvi, Shazia Saqib|<https://arxiv.org/pdf/2505.05513v4>|æå‡ºäº†ä¸€ç§åŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„è‡ªåŠ¨æ¡†æ¶ï¼Œé«˜æ•ˆåˆ†ç±»ä¸åŒå“ç§çš„å¤§ç±³ grainsï¼Œå¹¶é€šè¿‡è§£é‡Šæ€§æŠ€æœ¯æ­ç¤ºäº†å†³...|
|ğŸ†• å‘å¸ƒ|SKEL-CF: Coarse-to-Fine Biomechanical Skeleton and Surface Mesh Recovery|SKEL-CFï¼šä»ç²—åˆ°ç»†çš„ç”Ÿç‰©åŠ›å­¦éª¨æ¶ä¸è¡¨é¢ç½‘æ ¼æ¢å¤|Da Li, Ji-Ping Jin, Xuanlong Yu, Wei Liu, Xiaodong Cun, Kai Chen, Rui Fan, Jiangang Kong .etc.|<https://arxiv.org/pdf/2511.20157v1>|[ä»£ç ](https://pokerman8.github.io/SKEL-CF); æå‡ºäº†SKEL-CFæ¡†æ¶ï¼Œé€šè¿‡ç²—åˆ°ç»†çš„æ–¹æ³•æœ‰æ•ˆä¼°è®¡ç”Ÿç‰©åŠ›å­¦éª¨éª¼å’Œè¡¨é¢ç½‘æ ¼å‚æ•°ï¼Œæå‡äº†äººä½“è¿åŠ¨åˆ†æçš„ç²¾...|
|ğŸ†• å‘å¸ƒ|WPT: World-to-Policy Transfer via Online World Model Distillation|WPTï¼šé€šè¿‡åœ¨çº¿ä¸–ç•Œæ¨¡å‹è’¸é¦å®ç°ä»ä¸–ç•Œåˆ°ç­–ç•¥çš„è¿ç§»|Guangfeng Jiang, Yueru Luo, Jun Liu, Yi Huang, Yiyao Zhu, Zhan Qu, Dave Zhenyu Chen, Bingbing Liu .etc.|<https://arxiv.org/pdf/2511.20095v1>|æå‡ºWPTè®­ç»ƒèŒƒå¼ï¼Œé€šè¿‡åœ¨çº¿ä¸–ç•Œæ¨¡å‹è’¸é¦æå‡ç­–ç•¥æ€§èƒ½ï¼Œå®ç°å®æ—¶éƒ¨ç½²ä¸å“è¶Šè¡¨ç°ã€‚|
|ğŸ“ æ›´æ–°|Optimally Deep Networks - Adapting Model Depth to Datasets for Superior Efficiency|æœ€ä¼˜æ·±åº¦ç½‘ç»œ - æ ¹æ®æ•°æ®é›†è°ƒæ•´æ¨¡å‹æ·±åº¦ä»¥å®ç°å“è¶Šæ•ˆç‡|Shaharyar Ahmed Khan Tareen, Filza Khan Tareen|<https://arxiv.org/pdf/2510.10764v4>|æå‡ºä¼˜åŒ–æ·±åº¦ç½‘ç»œæ–¹æ³•ï¼Œæ ¹æ®ä»»åŠ¡éœ€æ±‚åŠ¨æ€è°ƒæ•´æ¨¡å‹æ·±åº¦ï¼Œå®ç°é«˜æ•ˆè®¡ç®—ä¸èµ„æºèŠ‚çº¦ã€‚|
|ğŸ“ æ›´æ–°|SD-MVS: Segmentation-Driven Deformation Multi-View Stereo with Spherical Refinement and EM optimization|åŸºäºåˆ†å‰²é©±åŠ¨çš„å½¢å˜å¤šè§†è§’ç«‹ä½“åŒ¹é…ä¸çƒå½¢ç»†åŒ–åŠEMä¼˜åŒ–çš„SD-MVSæ–¹æ³•|Zhenlong Yuan, Jiakai Cao, Zhaoxin Li, Hao Jiang, Zhaoqi Wang|<https://arxiv.org/pdf/2401.06385v2>|æå‡ºäº†ä¸€ç§åŸºäºè¯­ä¹‰åˆ†å‰²å’Œä¼˜åŒ–çš„å¤šè§†è§’ç«‹ä½“é‡å»ºæ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†æ— çº¹ç†åŒºåŸŸçš„3Dé‡å»ºé—®é¢˜ã€‚|
|ğŸ“ æ›´æ–°|Optimizing DINOv2 with Registers for Face Anti-Spoofing|ä½¿ç”¨å¯„å­˜å™¨ä¼˜åŒ–DINOv2è¿›è¡Œäººè„¸åæ¬ºéª—|Mika Feng, Pierre Gallin-Martel, Koichi Ito, Takafumi Aoki|<https://arxiv.org/pdf/2510.17201v2>|[ä»£ç ](https://gsisaoki.github.io/FAS-DINOv2-ICCVW); æå‡ºäº†ä¸€ç§åŸºäºDINOv2ä¸å¯„å­˜å™¨çš„æ–¹æ³•ï¼Œæœ‰æ•ˆåŒºåˆ†æ´»ä½“ä¸ä¼ªé€ äººè„¸å›¾åƒï¼Œå¢å¼ºé˜²ä¼ªèƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|DOGE: Differentiable Bezier Graph Optimization for Road Network Extraction|å¯å¾®è´å¡å°”å›¾ä¼˜åŒ–ç”¨äºé“è·¯ç½‘ç»œæå–|Jiahui Sun, Junran Lu, Jinhui Yin, Yishuo Xu, Yuanqi Li, Yanwen Guo|<https://arxiv.org/pdf/2511.19850v1>|æå‡ºäº†åŸºäºå‚æ•°åŒ–è´å¡å°”å›¾çš„å…¨çƒä¼˜åŒ–æ¡†æ¶DOGEï¼Œæ— éœ€çŸ¢é‡åœ°é¢çœŸå®æ•°æ®å³å¯ä»èˆªæ‹å½±åƒè‡ªåŠ¨æå–é“è·¯ç½‘ç»œã€‚|


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Object-Centric Vision Token Pruning for Vision Language Models|é¢å‘å¯¹è±¡çš„è§†è§‰æ ‡è®°å‰ªæä»¥ä¼˜åŒ–è§†è§‰è¯­è¨€æ¨¡å‹|Guangyuan Li, Rongzhen Zhao, Jinhong Deng, Yanbo Wang, Joni Pajarinen|<https://arxiv.org/pdf/2511.20439v1>|[ä»£ç ](https://github.com/GarryLarry010131/OC-VTP.); æå‡ºäº†ä¸€ç§ç›´æ¥ä¸”ä¿è¯æ€§çš„è§†è§‰æ ‡è®°å‰ªææ–¹æ³•OC-VTPï¼Œæœ‰æ•ˆæå‡è§†è§‰è¯­è¨€æ¨¡å‹æ¨ç†æ•ˆç‡åŒæ—¶ä¿æŒå‡†ç¡®åº¦ã€‚|
|ğŸ†• å‘å¸ƒ|GS-Checker: Tampering Localization for 3D Gaussian Splatting|GS-æ£€æµ‹å™¨ï¼šä¸‰ç»´é«˜æ–¯æ•£ç‚¹ç»˜åˆ¶ç¯¡æ”¹å®šä½|Haoliang Han, Ziyuan Luo, Jun Qi, Anderson Rocha, Renjie Wan|<https://arxiv.org/pdf/2511.20354v1>|æå‡ºGS-Checkeræ–¹æ³•ï¼Œé€šè¿‡3Då¯¹æ¯”æœºåˆ¶å’Œå¾ªç¯ä¼˜åŒ–ç­–ç•¥ï¼Œæœ‰æ•ˆå®šä½3D Gaussian Spl...|
|ğŸ†• å‘å¸ƒ|DAPointMamba: Domain Adaptive Point Mamba for Point Cloud Completion|DAPointMambaï¼šç”¨äºç‚¹äº‘è¡¥å…¨çš„åŸŸè‡ªé€‚åº”ç‚¹é­”éœ¸|Yinghui Li, Qianyu Zhou, Di Shao, Hao Yang, Ye Zhu, Richard Dazeley, Xuequan Lu|<https://arxiv.org/pdf/2511.20278v1>|æå‡ºäº†ä¸€ç§åŸºäºçŠ¶æ€ç©ºé—´æ¨¡å‹çš„ç‚¹äº‘è¡¥å…¨æ¡†æ¶DAPointMambaï¼Œæœ‰æ•ˆè§£å†³è·¨åŸŸå‡ ä½•ä¸è¯­ä¹‰å·®å¼‚é—®é¢˜ï¼Œå®...|
|ğŸ†• å‘å¸ƒ|Modality-Balanced Collaborative Distillation for Multi-Modal Domain Generalization|å¤šæ¨¡æ€åŸŸæ³›åŒ–ä¸­çš„æ¨¡æ€å¹³è¡¡ååŒè’¸é¦|Xiaohan Wang, Zhangtao Cheng, Ting Zhong, Leiting Chen, Fan Zhou|<https://arxiv.org/pdf/2511.20258v1>|æå‡ºäº†ä¸€ç§å¹³è¡¡æ¨¡æ€åä½œè’¸é¦æ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†å¤šæ¨¡æ€é¢†åŸŸæ³›åŒ–ä¸­çš„æ¨¡æ€ä¸å¹³è¡¡é—®é¢˜ï¼Œæå‡äº†æ³›åŒ–æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|FLaTEC: Frequency-Disentangled Latent Triplanes for Efficient Compression of LiDAR Point Clouds|é¢‘ç‡è§£è€¦æ½œåœ¨ä¸‰å¹³é¢ï¼šç”¨äºæ¿€å…‰é›·è¾¾ç‚¹äº‘é«˜æ•ˆå‹ç¼©çš„æ–¹æ³•|Xiaoge Zhang, Zijie Wu, Mingtao Feng, Zichen Geng, Mehwish Nasim, Saeed Anwar, Ajmal Mian|<https://arxiv.org/pdf/2511.20065v1>|æå‡ºäº†ä¸€ç§é¢‘ç‡è§£è€¦çš„å‹ç¼©æ¨¡å‹FLaTECï¼Œé€šè¿‡åˆ†ç¦»ä½é¢‘å’Œé«˜é¢‘æˆåˆ†ï¼Œå®ç°äº†LiDARç‚¹äº‘çš„é«˜æ•ˆå‹ç¼©ã€‚|
|ğŸ“ æ›´æ–°|Temporally Compressed 3D Gaussian Splatting for Dynamic Scenes|åŠ¨æ€åœºæ™¯çš„æ—¶é—´å‹ç¼©ä¸‰ç»´é«˜æ–¯æ•£ç‚¹ç»˜åˆ¶|Saqib Javed, Ahmad Jarrar Khan, Corentin Dumery, Chen Zhao, Mathieu Salzmann|<https://arxiv.org/pdf/2412.05700v2>|[ä»£ç ](https://ahmad-jarrar.github.io/tc-3dgs); æå‡ºäº†ä¸€ç§é’ˆå¯¹åŠ¨æ€åœºæ™¯çš„é«˜æ•ˆ3Dé«˜æ–¯è¡¨ç¤ºå‹ç¼©æŠ€æœ¯ï¼Œé€šè¿‡é€‰æ‹©æ€§ä¿®å‰ªå’Œæ—¶é—´æ’å€¼å®ç°67å€å‹ç¼©ï¼ŒåŒæ—¶ä¿æŒè§†...|
|ğŸ†• å‘å¸ƒ|On-Demand Multi-Task Sparsity for Efficient Large-Model Deployment on Edge Devices|æŒ‰éœ€å¤šä»»åŠ¡ç¨€ç–æ€§ï¼šè¾¹ç¼˜è®¾å¤‡ä¸Šé«˜æ•ˆå¤§å‹æ¨¡å‹éƒ¨ç½²|Lianming Huang, Haibo Hu, Qiao Li, Nan Guan, Chun Jason Xue|<https://arxiv.org/pdf/2511.19986v1>|æå‡ºäº†ä¸€ç§æŒ‰éœ€å¤šä»»åŠ¡ç¨€ç–æ€§æ¡†æ¶ï¼Œé€šè¿‡æœ€å¤§åŒ–å‚æ•°é‡ç”¨ä»¥å‡å°‘ä»»åŠ¡åˆ‡æ¢å¼€é”€ï¼Œæ˜¾è‘—æå‡äº†è¾¹ç¼˜è®¾å¤‡ä¸Šå¤§å‹æ¨¡å‹çš„...|
|ğŸ“ æ›´æ–°|Deep Hybrid Model for Region of Interest Detection in Omnidirectional Videos|æ·±åº¦æ··åˆæ¨¡å‹åœ¨å…¨æ–¹ä½è§†é¢‘ä¸­å…´è¶£åŒºåŸŸæ£€æµ‹çš„åº”ç”¨|Sana Alamgeer, Mylene Farias, Marcelo Carvalho|<https://arxiv.org/pdf/2511.18856v2>|æå‡ºäº†ä¸€ç§é¢„æµ‹360åº¦è§†é¢‘ä¸­å…´è¶£åŒºåŸŸçš„æ··åˆæ˜¾è‘—æ€§æ¨¡å‹ï¼Œä¼˜åŒ–äº†è§†é¢‘æµä¼ è¾“çš„å¸¦å®½ä½¿ç”¨å’Œè§‚çœ‹ä½“éªŒã€‚|
|ğŸ“ æ›´æ–°|STT-GS: Sample-Then-Transmit Edge Gaussian Splatting with Joint Client Selection and Power Control|STT-GS: åŸºäºæ ·æœ¬ä¼ è¾“çš„è¾¹ç¼˜é«˜æ–¯æ•£ç‚¹ç»˜åˆ¶ï¼Œç»“åˆå®¢æˆ·ç«¯é€‰æ‹©ä¸åŠŸç‡æ§åˆ¶|Zhen Li, Xibin Jin, Guoliang Li, Shuai Wang, Miaowen Wen, Huseyin Arslan, Derrick Wing Kwan Ng, Chengzhong Xu|<https://arxiv.org/pdf/2510.13186v3>|æå‡ºSTT-GSç­–ç•¥ï¼Œé€šè¿‡é‡‡æ ·åä¼ è¾“å’Œè”åˆå®¢æˆ·ç«¯é€‰æ‹©ä¸åŠŸç‡æ§åˆ¶ä¼˜åŒ–è¾¹ç¼˜é«˜æ–¯æ•£ç‚¹æ¸²æŸ“è´¨é‡ã€‚|
|ğŸ“ æ›´æ–°|Human-Centric Open-Future Task Discovery: Formulation, Benchmark, and Scalable Tree-Based Search|ä»¥äººä¸ºæœ¬çš„å¼€æ”¾æœªæ¥ä»»åŠ¡å‘ç°ï¼šå…¬å¼åŒ–ã€åŸºå‡†æµ‹è¯•ä¸å¯æ‰©å±•çš„æ ‘çŠ¶æœç´¢|Zijian Song, Xiaoxin Lin, Tao Pu, Zhenlong Yuan, Guangrun Wang, Liang Lin|<https://arxiv.org/pdf/2511.18929v2>|æå‡ºHuman-centric Open-future Task Discoveryé—®é¢˜ï¼Œå¹¶å¼•å…¥CM...|
|ğŸ“ æ›´æ–°|Learning Hierarchical Sparse Transform Coding of 3DGS|å­¦ä¹ ä¸‰ç»´å‡ ä½•å½¢çŠ¶çš„å±‚æ¬¡ç¨€ç–å˜æ¢ç¼–ç |Hao Xu, Xiaolin Wu, Xi Zhang|<https://arxiv.org/pdf/2505.22908v2>|[ä»£ç ](https://github.com/hxu160/SHTC_for_3DGS_compression.); æå‡ºäº†ä¸€ç§ç¨€ç–å¼•å¯¼çš„å±‚çº§å˜æ¢ç¼–ç æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†3DGSæ¨¡å‹çš„å‹ç¼©æ•ˆç‡å’Œè§£ç é€Ÿåº¦ã€‚|


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Time-step Mixup for Efficient Spiking Knowledge Transfer from Appearance to Event Domain|æ—¶é—´æ­¥æ··åˆï¼šä»å¤–è§‚åŸŸåˆ°äº‹ä»¶åŸŸçš„é«˜æ•ˆå°–å³°çŸ¥è¯†è¿ç§»|Yuqi Xie, Shuhan Ye, Yi Yu, Chong Wang, Qixin Zhang, Jiazhen Xu, Le Shen, Yuanbin Qian .etc.|<https://arxiv.org/pdf/2509.12959v2>|æå‡ºäº†ä¸€ç§æ—¶é—´æ­¥æ··åˆç­–ç•¥ï¼Œé€šè¿‡åœ¨ä¸åŒæ—¶é—´æ­¥æ··åˆRGBå’ŒDVSè¾“å…¥ï¼Œæœ‰æ•ˆç¼“è§£äº†æ¨¡æ€å·®å¼‚ï¼Œæå‡äº†äº‹ä»¶åŸŸå›¾...|
|ğŸ“ æ›´æ–°|MAPo : Motion-Aware Partitioning of Deformable 3D Gaussian Splatting for High-Fidelity Dynamic Scene Reconstruction|MAPoï¼šåŸºäºè¿åŠ¨æ„ŸçŸ¥çš„å˜å½¢ä¸‰ç»´é«˜æ–¯ç‚¹ç»˜åˆ¶çš„é«˜ä¿çœŸåŠ¨æ€åœºæ™¯é‡å»ºä¸­çš„åˆ†åŒºç­–ç•¥|Han Jiao, Jiakai Sun, Yexing Xu, Lei Zhao, Wei Xing, Huaizhong Lin|<https://arxiv.org/pdf/2508.19786v2>|æå‡ºåŠ¨æ€åœºæ™¯é‡å»ºä¸­çš„ä¸€ç§æ–°æ–¹æ³•MAPoï¼Œé€šè¿‡åŒºåˆ†åŠ¨æ€ç¨‹åº¦å¯¹3Dé«˜æ–¯åˆ†å¸ƒè¿›è¡Œåˆ†åŒºå¤„ç†ï¼Œæ˜¾è‘—æå‡äº†è¿åŠ¨ç»†...|
|ğŸ†• å‘å¸ƒ|Context-Aware Token Pruning and Discriminative Selective Attention for Transformer Tracking|ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ ‡è®°å‰ªæä¸åˆ¤åˆ«æ€§é€‰æ‹©æ³¨æ„åŠ›çš„Transformerè·Ÿè¸ªæ–¹æ³•|Janani Kugarajeevan, Thanikasalam Kokul, Amirthalingam Ramanan, Subha Fernando|<https://arxiv.org/pdf/2511.19928v1>|æå‡ºCPDATrackæ¡†æ¶ï¼Œé€šè¿‡æ™ºèƒ½å‰ªæå’Œé€‰æ‹©æ€§æ³¨æ„åŠ›æœºåˆ¶æŠ‘åˆ¶èƒŒæ™¯å¹²æ‰°ï¼Œæå‡ç›®æ ‡è·Ÿè¸ªå‡†ç¡®æ€§ã€‚|
|ğŸ“ æ›´æ–°|PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model|PaddleOCR-VLï¼šé€šè¿‡0.9Bè¶…ç´§å‡‘è§†è§‰è¯­è¨€æ¨¡å‹æå‡å¤šè¯­è¨€æ–‡æ¡£è§£ææ€§èƒ½|Cheng Cui, Ting Sun, Suyin Liang, Tingquan Gao, Zelun Zhang, Jiaxuan Liu, Xueqing Wang, Changda Zhou .etc.|<https://arxiv.org/pdf/2510.14528v4>|[ä»£ç ](https://github.com/PaddlePaddle/PaddleOCR); æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„æ–‡æ¡£è§£ææ¨¡å‹PaddleOCR-VLï¼Œé€šè¿‡ç»“åˆè§†è§‰ç¼–ç å™¨å’Œè¯­è¨€æ¨¡å‹ï¼Œå®ç°äº†å¤šè¯­è¨€æ–‡æ¡£...|
|ğŸ“ æ›´æ–°|NeuroGaze-Distill: Brain-informed Distillation and Depression-Inspired Geometric Priors for Robust Facial Emotion Recognition|ç¥ç»æ³¨è§†-è’¸é¦ï¼šåŸºäºå¤§è„‘ä¿¡æ¯çš„è’¸é¦ä¸æŠ‘éƒå¯å‘çš„å‡ ä½•å…ˆéªŒçŸ¥è¯†ç”¨äºç¨³å¥çš„é¢éƒ¨æƒ…æ„Ÿè¯†åˆ«|Zilin Li, Weiwei Xu, Xuanqi Zhao, Yiran Zhu|<https://arxiv.org/pdf/2509.11916v2>|å¼•å…¥è„‘ä¿¡æ¯æŒ‡å¯¼çš„è¿ç§»å­¦ä¹ å’Œæƒ…æ„Ÿå‡ ä½•å…ˆéªŒï¼Œæå‡é¢éƒ¨è¡¨æƒ…è¯†åˆ«çš„è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ã€‚|


### æ¨ç†ä¼˜åŒ– (Inference Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Hestia: Voxel-Face-Aware Hierarchical Next-Best-View Acquisition for Efficient 3D Reconstruction|èµ«æ–¯æäºšï¼šé¢å‘ä½“ç´ äººè„¸æ„ŸçŸ¥çš„åˆ†å±‚æœ€ä¼˜è§†è§’è·å–ä»¥æé«˜ä¸‰ç»´é‡å»ºæ•ˆç‡|Cheng-You Lu, Zhuoli Zhuang, Nguyen Thanh Trung Le, Da Xiao, Yu-Cheng Chang, Thomas Do, Srinath Sridhar, Chin-teng Lin|<https://arxiv.org/pdf/2508.01014v3>|[ä»£ç ](https://johnnylu305.github.io/hestia); æå‡ºäº†ä¸€ç§é¢å‘ä½“ç´ é¢çš„å±‚æ¬¡åŒ–ä¸‹ä¸€æœ€ä½³è§†è§’è·å–æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†3Dé‡å»ºçš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚|


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### åˆ†å¸ƒå¤–æ³›åŒ– (Out-of-distribution Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Cloud4D: Estimating Cloud Properties at a High Spatial and Temporal Resolution|ã€ŠCloud4Dï¼šåœ¨é«˜ç©ºé—´å’Œæ—¶é—´åˆ†è¾¨ç‡ä¸‹ä¼°ç®—äº‘å±æ€§ã€‹|Jacob Lin, Edward Gryspeerdt, Ronald Clark|<https://arxiv.org/pdf/2511.19431v2>|Cloud4Dé€šè¿‡ä½¿ç”¨åœ°é¢ç›¸æœºï¼Œé¦–æ¬¡å®ç°äº†é«˜æ—¶ç©ºåˆ†è¾¨ç‡çš„äº‘çŠ¶æ€é‡å»ºï¼Œæ˜¾è‘—æå‡äº†å¤©æ°”é¢„æµ‹æ¨¡å‹çš„ç²¾åº¦ã€‚|
|ğŸ†• å‘å¸ƒ|Concept-Aware Batch Sampling Improves Language-Image Pretraining|æ¦‚å¿µæ„ŸçŸ¥æ‰¹é‡é‡‡æ ·æå‡è¯­è¨€-å›¾åƒé¢„è®­ç»ƒæ•ˆæœ|Adhiraj Ghosh, Vishaal Udandarao, Thao Nguyen, Matteo Farina, Mehdi Cherti, Jenia Jitsev, Sewoong Oh, Elisa Ricci .etc.|<https://arxiv.org/pdf/2511.20643v1>|æå‡ºåœ¨çº¿æ¦‚å¿µé©±åŠ¨çš„æ•°æ®é‡‡æ ·æ–¹æ³•CABSï¼Œä¼˜åŒ–è¯­è¨€å›¾åƒé¢„è®­ç»ƒæ¨¡å‹æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|A2Seek: Towards Reasoning-Centric Benchmark for Aerial Anomaly Understanding|é¢å‘æ¨ç†ä¸­å¿ƒçš„èˆªç©ºå¼‚å¸¸ç†è§£åŸºå‡†ï¼šA2Seek|Mengjingcheng Mo, Xinyang Tong, Mingpi Tan, Jiaxu Leng, Jiankang Zheng, Yiran Liu, Haosheng Chen, Ji Gan .etc.|<https://arxiv.org/pdf/2505.21962v2>|[ä»£ç ](https://2-mo.github.io/A2Seek); æå‡ºäº†A2Seekæ•°æ®é›†å’ŒA2Seek-R1æ¨ç†æ¡†æ¶ï¼Œæå‡äº†æ— äººæœºè§†è§’å¼‚å¸¸æ£€æµ‹çš„å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|MAPS: Preserving Vision-Language Representations via Module-Wise Proximity Scheduling for Better Vision-Language-Action Generalization|é€šè¿‡æ¨¡å—åŒ–é‚»è¿‘è°ƒåº¦ä¿æŒè§†è§‰-è¯­è¨€è¡¨ç¤ºä»¥å®ç°æ›´å¥½çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ³›åŒ–ï¼šMAPSæ–¹æ³•|Chengyue Huang, Mellon M. Zhang, Robert Azarcon, Glen Chou, Zsolt Kira|<https://arxiv.org/pdf/2511.19878v1>|æå‡ºäº†ä¸€ç§æ¨¡å—åŒ– proximity è°ƒåº¦æ–¹æ³• MAPSï¼Œæœ‰æ•ˆå¹³è¡¡è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡å‹çš„ç¨³å®šæ€§å’Œçµæ´»æ€§ï¼Œ...|


### å¯¹æŠ—é²æ£’æ€§ (Adversarial Robustness)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Adversarial Robustness for Unified Multi-Modal Encoders via Efficient Calibration|é€šè¿‡é«˜æ•ˆæ ¡å‡†å®ç°ç»Ÿä¸€å¤šæ¨¡æ€ç¼–ç å™¨çš„å¯¹æŠ—é²æ£’æ€§|Chih-Ting Liao, Zhangquan Chen, Chunlei Meng, Tzu-Yu Huang, Xin Cao, Xu Zheng|<https://arxiv.org/pdf/2505.11895v2>|æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„å¯¹æŠ—æ€§æ ¡å‡†æ¡†æ¶ï¼Œå¢å¼ºäº†ç»Ÿä¸€å¤šæ¨¡æ€ç¼–ç å™¨åœ¨å¯¹æŠ—æ€§æ‰°åŠ¨ä¸‹çš„é²æ£’æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|V-Attack: Targeting Disentangled Value Features for Controllable Adversarial Attacks on LVLMs|V-æ”»å‡»ï¼šé’ˆå¯¹è§£è€¦ä»·å€¼ç‰¹å¾çš„å¯æ§å¯¹æŠ—æ”»å‡»åœ¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ä¸Šçš„åº”ç”¨|Sen Nie, Jie Zhang, Jianxin Yan, Shiguang Shan, Xilin Chen|<https://arxiv.org/pdf/2511.20223v1>|[ä»£ç ](https://github.com/Summu77/V-Attack.); æå‡ºV-Attackæ–¹æ³•ï¼Œé€šè¿‡ç²¾ç¡®æ“æ§ä»·å€¼ç‰¹å¾å®ç°å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹çš„å¯æ§å¯¹æŠ—æ”»å‡»ã€‚|
|ğŸ†• å‘å¸ƒ|On the Feasibility of Hijacking MLLMs' Decision Chain via One Perturbation|å…³äºé€šè¿‡å•ä¸€æ‰°åŠ¨åŠ«æŒå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹å†³ç­–é“¾çš„å¯è¡Œæ€§ç ”ç©¶|Changyue Li, Jiaying Li, Youliang Yuan, Jiaming He, Zhicong Huang, Pinjia He|<https://arxiv.org/pdf/2511.20002v1>|æå‡ºäº†ä¸€ç§èƒ½é€šè¿‡å•ä¸€æ‰°åŠ¨åŠ«æŒæ¨¡å‹å†³ç­–é“¾çš„æ–¹æ³•ï¼Œé€šè¿‡è¯­ä¹‰æ„ŸçŸ¥é€šç”¨æ‰°åŠ¨å®ç°äº†å¯¹å¤šç›®æ ‡è¾“å‡ºçš„æ§åˆ¶ã€‚|


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Rethinking the Learning Paradigm for Facial Expression Recognition|é‡æ–°æ€è€ƒé¢éƒ¨è¡¨æƒ…è¯†åˆ«çš„å­¦ä¹ èŒƒå¼|Weijie Wang, Nicu Sebe, Bruno Lepri|<https://arxiv.org/pdf/2209.15402v3>|æå‡ºå¼±ç›‘ç£å­¦ä¹ ç­–ç•¥ä»¥å¤„ç†FERæ•°æ®é›†çš„æ¨¡ç³Šæ ‡æ³¨é—®é¢˜ï¼Œä¼˜åŒ–é¢éƒ¨è¡¨æƒ…è¯†åˆ«æ¨¡å‹è®­ç»ƒã€‚|
|ğŸ“ æ›´æ–°|Probabilistic Hyper-Graphs using Multiple Randomly Masked Autoencoders for Semi-supervised Multi-modal Multi-task Learning|åŸºäºå¤šéšæœºé®è”½è‡ªç¼–ç å™¨çš„æ¦‚ç‡è¶…å›¾ç”¨äºåŠç›‘ç£å¤šæ¨¡æ€å¤šä»»åŠ¡å­¦ä¹ |PÃ®rvu Mihai-Cristian, Marius Leordeanu|<https://arxiv.org/pdf/2510.10068v2>|æå‡ºäº†ä¸€ç§èåˆç¥ç»å›¾ç†è®ºä¸æ©ç è‡ªç¼–ç å™¨çš„åŠç›‘ç£å¤šæ¨¡æ€å¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡éšæœºæ©ç æ•´ä¸ªæ¨¡æ€æé«˜äº†é¢„æµ‹æ€§...|
|ğŸ“ æ›´æ–°|Zero-Shot Anomaly Detection with Dual-Branch Prompt Selection|åŒåˆ†æ”¯æç¤ºé€‰æ‹©çš„æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹|Zihan Wang, Samira Ebrahimi Kahou, Narges Armanfard|<https://arxiv.org/pdf/2508.00777v3>|æå‡ºäº†ä¸€ç§è‡ªé€‚åº”åŒåˆ†æ”¯æç¤ºé€‰æ‹©æ¡†æ¶ï¼Œæœ‰æ•ˆåº”å¯¹é¢†åŸŸåç§»ï¼Œå®ç°é›¶æ ·æœ¬å¼‚å¸¸æ£€æµ‹ä¸å®šä½ã€‚|
|ğŸ“ æ›´æ–°|Spatial-SSRL: Enhancing Spatial Understanding via Self-Supervised Reinforcement Learning|ç©ºé—´-è‡ªç›‘ç£å¼ºåŒ–å­¦ä¹ å¢å¼ºç©ºé—´ç†è§£èƒ½åŠ›|Yuhong Liu, Beichen Zhang, Yuhang Zang, Yuhang Cao, Long Xing, Xiaoyi Dong, Haodong Duan, Dahua Lin .etc.|<https://arxiv.org/pdf/2510.27606v2>|æå‡ºäº†ä¸€ç§è‡ªç›‘ç£å¼ºåŒ–å­¦ä¹ æ–¹æ³•Spatial-SSRLï¼Œé€šè¿‡æ™®é€šå›¾åƒç›´æ¥æå‡å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹çš„ç©ºé—´ç†è§£...|
|ğŸ†• å‘å¸ƒ|CropVLM: Learning to Zoom for Fine-Grained Vision-Language Perception|ã€ŠCropVLMï¼šå­¦ä¹ ç¼©æ”¾ä»¥å®ç°ç»†ç²’åº¦è§†è§‰è¯­è¨€æ„ŸçŸ¥ã€‹|Miguel Carvalho, Helder Dias, Bruno Martins|<https://arxiv.org/pdf/2511.19820v1>|æå‡ºäº†ä¸€ç§ä½æˆæœ¬å¤–éƒ¨æ–¹æ³•CropVLMï¼Œé€šè¿‡åŠ¨æ€èšç„¦å›¾åƒå…³é”®åŒºåŸŸï¼Œå¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹å¯¹ç»†èŠ‚çš„æ•æ‰èƒ½åŠ›ã€‚|
|ğŸ“ æ›´æ–°|Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning|å­¦ä¹ ç»³ç´¢æŠ€å·§ï¼Œç„¶åä¿¡ä»»èƒœåˆ©ï¼šåŸºäºæ¸è¿›æ¢ç´¢çš„ä»£ç†å¼ºåŒ–å­¦ä¹ ä¸­çš„è‡ªæˆ‘æ¨¡ä»¿|Yulei Qin, Xiaoyu Tan, Zhengbao He, Gang Li, Haojia Lin, Zongyi Li, Zihan Xu, Yuchen Shi .etc.|<https://arxiv.org/pdf/2509.22601v3>|æå‡ºäº†ä¸€ç§è‡ªæˆ‘æ¨¡ä»¿å­¦ä¹ ç­–ç•¥SPEARï¼Œé€šè¿‡åˆ†é˜¶æ®µè°ƒæ•´ç­–ç•¥ç†µå¹³è¡¡å¼ºåŒ–å­¦ä¹ ä¸­çš„æ¢ç´¢ä¸åˆ©ç”¨ï¼Œæ˜¾è‘—æå‡äº†é•¿å‘¨...|


### é›¶/å°‘æ ·æœ¬æ³›åŒ– (Zero/Few-shot Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Embodied Crowd Counting|â€œå…·èº«äººç¾¤è®¡æ•°â€|Runling Long, Yunlong Wang, Jia Wan, Xiang Deng, Xinting Zhu, Weili Guan, Antoni B. Chan, Liqiang Nie|<https://arxiv.org/pdf/2503.08367v2>|æå‡ºEmbodied Crowd Countingä»»åŠ¡ï¼Œé€šè¿‡æ„å»ºäº¤äº’å¼ä»¿çœŸå™¨å’Œé›¶æ ·æœ¬å¯¼èˆªæ–¹æ³•ï¼Œæœ‰æ•ˆè§£...|


## å…·èº«æ™ºèƒ½ä¸äº¤äº’è§†è§‰ (Embodied Intelligence & Interactive Vision)


### è§†è§‰å¯¼èˆªä¸è·¯å¾„è§„åˆ’ (Visual Navigation & Path Planning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Wanderland: Geometrically Grounded Simulation for Open-World Embodied AI|ã€Šå¥‡å¹»æ¼«æ¸¸ï¼šé¢å‘å¼€æ”¾ä¸–ç•Œå…·èº«AIçš„å‡ ä½•åŸºç¡€æ¨¡æ‹Ÿã€‹|Xinhao Liu, Jiaqi Li, Youming Deng, Ruxin Chen, Yingjia Zhang, Yifei Ma, Li Guo, Yiming Li .etc.|<https://arxiv.org/pdf/2511.20620v1>|[ä»£ç ](https://ai4ce.github.io/wanderland); æå‡ºäº†Wanderlandæ¡†æ¶ï¼Œé€šè¿‡ç»“åˆå¤šä¼ æ„Ÿå™¨æ•è·å’Œå‡ ä½•ç²¾ç¡®é‡å»ºï¼Œè§£å†³äº†Embodied AIåœ¨å¼€...|
|ğŸ†• å‘å¸ƒ|CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents|CostNavï¼šä¸€ç§ç”¨äºæˆæœ¬æ„ŸçŸ¥çš„å…·èº«æ™ºèƒ½ä½“è¯„ä¼°çš„å¯¼èˆªåŸºå‡†|Haebin Seong, Sungmin Kim, Minchan Kim, Yongjun Cho, Myunchul Joe, Suhwan Choi, Jaeyoon Jung, Jiyong Youn .etc.|<https://arxiv.org/pdf/2511.20216v1>|æå‡ºäº†CostNavï¼Œé¦–ä¸ªå°†å¯¼èˆªç ”ç©¶çš„ä»»åŠ¡æˆåŠŸæŒ‡æ ‡ä¸å•†ä¸šå¯è¡Œæ€§ç»“åˆè¿›è¡Œæˆæœ¬æ”¶ç›Šåˆ†æçš„æµ‹è¯•åºŠã€‚|


### ç›®æ ‡å¯¼å‘è§†è§‰å†³ç­– (Goal-oriented Visual Decision Making)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|OceanGym: A Benchmark Environment for Underwater Embodied Agents|æµ·æ´‹å¥èº«æˆ¿ï¼šæ°´ä¸‹å…·èº«æ™ºèƒ½ä½“åŸºå‡†ç¯å¢ƒ|Yida Xue, Mingjun Mao, Xiangyuan Ru, Yuqi Zhu, Baochang Ren, Shuofei Qiao, Mengru Wang, Shumin Deng .etc.|<https://arxiv.org/pdf/2509.26536v2>|[ä»£ç ](https://github.com/OceanGPT/OceanGym.); æå‡ºäº†OceanGymï¼Œé¦–ä¸ªé’ˆå¯¹æ°´ä¸‹æœºå™¨äººçš„ç»¼åˆåŸºå‡†ç¯å¢ƒï¼Œé€šè¿‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æå‡AIåœ¨æç«¯æ°´ä¸‹æ¡ä»¶...|
|ğŸ†• å‘å¸ƒ|Coupled Physics-Gated Adaptation: Spatially Decoding Volumetric Photochemical Conversion in Complex 3D-Printed Objects|è€¦åˆç‰©ç†é—¨æ§è‡ªé€‚åº”ï¼šåœ¨å¤æ‚3Dæ‰“å°å¯¹è±¡ä¸­ç©ºé—´è§£ç ä½“ç§¯å…‰åŒ–å­¦è½¬æ¢|Maryam Eftekharifar, Churun Zhang, Jialiang Wei, Xudong Cao, Hossein Heidari|<https://arxiv.org/pdf/2511.19913v1>|æå‡ºäº†ä¸€ç§é¢„æµ‹å¤æ‚3Dæ‰“å°ç‰©ä½“å†…éƒ¨ç‰©ç†æ€§è´¨çš„æ–°æ¡†æ¶ï¼Œé€šè¿‡è€¦åˆç‰©ç†å¼•å¯¼çš„ç‰¹å¾è°ƒåˆ¶å®ç°ç²¾ç¡®åŒ–å­¦çŠ¶æ€æ§åˆ¶ã€‚|


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Vision-Language Memory for Spatial Reasoning|è§†è§‰-è¯­è¨€è®°å¿†ç”¨äºç©ºé—´æ¨ç†|Zuntao Liu, Yi Du, Taimeng Fu, Shaoshu Su, Cherie Ho, Chen Wang|<https://arxiv.org/pdf/2511.20644v1>|æå‡ºäº†ä¸€ç§å…·å¤‡æŒä¹…è®°å¿†çš„è§†è§‰è¯­è¨€æ¨¡å‹VLM$^2$ï¼Œé€šè¿‡åŒè®°å¿†æ¨¡å—æ˜¾è‘—æå‡äº†è§†é¢‘ä¸­çš„ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|Unleashing the Power of Vision-Language Models for Long-Tailed Multi-Label Visual Recognition|é‡Šæ”¾è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨é•¿å°¾å¤šæ ‡ç­¾è§†è§‰è¯†åˆ«ä¸­çš„åŠ›é‡|Wei Tang, Zuo-Zheng Wang, Kun Zhang, Tong Wei, Min-Ling Zhang|<https://arxiv.org/pdf/2511.20641v1>|æå‡ºäº†ä¸€ç§æ–°å‹æ¡†æ¶CAPNETï¼Œé€šè¿‡å»ºæ¨¡æ ‡ç­¾ç›¸å…³æ€§å¹¶å¹³è¡¡æ•°æ®åˆ†å¸ƒï¼Œæœ‰æ•ˆæå‡äº†é•¿å°¾å¤šæ ‡ç­¾è§†è§‰è¯†åˆ«çš„æ€§èƒ½...|
|ğŸ†• å‘å¸ƒ|VQ-VA World: Towards High-Quality Visual Question-Visual Answering|VQ-VAä¸–ç•Œï¼šè¿ˆå‘é«˜è´¨é‡è§†è§‰é—®é¢˜-è§†è§‰å›ç­”|Chenhui Gou, Zilong Chen, Zeyu Wang, Feng Li, Deyao Zhu, Zicheng Duan, Kunchang Li, Chaorui Deng .etc.|<https://arxiv.org/pdf/2511.20573v1>|æå‡ºVQ-VA Worldæ¡†æ¶ï¼Œé€šè¿‡å¤§è§„æ¨¡æ•°æ®æ„å»ºæå‡è§†è§‰é—®ç­”ç”Ÿæˆå›¾åƒè´¨é‡ï¼Œæ˜¾è‘—è¶…è¶Šç°æœ‰å¼€æºåŸºå‡†ã€‚|
|ğŸ†• å‘å¸ƒ|DINO-Tok: Adapting DINO for Visual Tokenizers|"DINO-Tokï¼šå°†DINOé€‚é…ä¸ºè§†è§‰æ ‡è®°å™¨"|Mingkai Jia, Mingxiao Li, Liaoyuan Fan, Tianxing Shi, Jiaxin Guo, Zeming Li, Xiaoyang Guo, Xiao-Xiao Long .etc.|<https://arxiv.org/pdf/2511.20565v1>|[ä»£ç ](https://github.com/MKJia/DINO-Tok.); å¼•å…¥DINO-Tokï¼Œé€šè¿‡èåˆé¢„è®­ç»ƒè§†è§‰æ¨¡å‹çš„é«˜å±‚è¯­ä¹‰ä¸æµ…å±‚ç»†èŠ‚ï¼Œå®ç°äº†é«˜ä¿çœŸåº¦è§†è§‰ç¼–ç ã€‚|
|ğŸ“ æ›´æ–°|FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions|ã€ŠFlagEval å‘ç°æŠ¥å‘Šï¼šå¯¹è‡ªåŠ¨éªŒè¯æ–‡æœ¬å’Œè§†è§‰é—®é¢˜çš„å¤§è§„æ¨¡æ¨ç†æ¨¡å‹çš„åˆæ­¥è¯„ä¼°ã€‹|Bowen Qin, Chen Yue, Fang Yin, Hui Wang, JG Yao, Jiakang Liu, Jing-Shu Zheng, Miguel Hu Chen .etc.|<https://arxiv.org/pdf/2509.17177v3>|[ä»£ç ](https://flageval-baai.github.io/LRM-Eval); è¯„ä¼°å¤§å‹æ¨ç†æ¨¡å‹åœ¨è‡ªåŠ¨éªŒè¯æ–‡æœ¬å’Œè§†è§‰é—®é¢˜ä¸Šçš„è¡¨ç°ï¼Œå¹¶å‘å¸ƒROMEè§†è§‰è¯­è¨€æ¨¡å‹æ¨ç†æµ‹è¯•åŸºå‡†ã€‚|
|ğŸ†• å‘å¸ƒ|Beyond Generation: Multi-Hop Reasoning for Factual Accuracy in Vision-Language Models|è¶…è¶Šç”Ÿæˆï¼šå¤šè·³æ¨ç†åœ¨è§†è§‰è¯­è¨€æ¨¡å‹ä¸­ç¡®ä¿äº‹å®å‡†ç¡®æ€§|Shamima Hossain|<https://arxiv.org/pdf/2511.20531v1>|æå‡ºçŸ¥è¯†å¼•å¯¼çš„å¤šè·³æ¨ç†æ¡†æ¶ï¼Œæ˜¾è‘—æå‡è§†è§‰è¯­è¨€æ¨¡å‹çš„äº‹å®å‡†ç¡®æ€§ã€‚|
|ğŸ“ æ›´æ–°|AutoFocus-IL: VLM-based Saliency Maps for Data-Efficient Visual Imitation Learning without Extra Human Annotations|è‡ªåŠ¨å¯¹ç„¦-ILï¼šåŸºäºVLMçš„æ˜¾è‘—æ€§å›¾å®ç°æ— éœ€é¢å¤–äººå·¥æ ‡æ³¨çš„æ•°æ®é«˜æ•ˆè§†è§‰æ¨¡ä»¿å­¦ä¹ |Litian Gong, Fatemeh Bahrani, Yutai Zhou, Amin Banayeeanzade, Jiachen Li, Erdem BÄ±yÄ±k|<https://arxiv.org/pdf/2511.18617v2>|[ä»£ç ](https://AutoFocus-IL.github.io/.); AutoFocus-ILé€šè¿‡ä½¿ç”¨è§†è§‰è¯­è¨€æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆ saliency mapsï¼Œæœ‰æ•ˆæå‡äº†è§†è§‰æ¨¡ä»¿...|
|ğŸ“ æ›´æ–°|When to Think and When to Look: Uncertainty-Guided Lookback|â€œä½•æ—¶æ€è€ƒä¸ä½•æ—¶è§‚å¯Ÿï¼šä¸ç¡®å®šæ€§æŒ‡å¯¼çš„å›æº¯æœºåˆ¶â€|Jing Bi, Filippos Bellos, Junjia Guo, Yayuan Li, Chao Huang, Yolo Y. Tang, Luchuan Song, Susan Liang .etc.|<https://arxiv.org/pdf/2511.15613v2>|æå‡ºäº†ä¸€ç§åŸºäºä¸ç¡®å®šæ€§çš„è‡ªé€‚åº”å›é¡¾ç­–ç•¥ï¼Œæœ‰æ•ˆæå‡äº†å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹çš„è§†è§‰æ¨ç†æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|Look Where It Matters: Training-Free Ultra-HR Remote Sensing VQA via Adaptive Zoom Search|â€œå…³æ³¨é‡ç‚¹ï¼šæ— éœ€è®­ç»ƒçš„è¶…é«˜åˆ†è¾¨ç‡é¥æ„Ÿè§†è§‰é—®ç­”é€šè¿‡è‡ªé€‚åº”ç¼©æ”¾æœç´¢â€|Yunqi Zhou, Chengjie Jiang, Chun Yuan, Jing Li|<https://arxiv.org/pdf/2511.20460v1>|æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„è¿œç¨‹ä¼ æ„Ÿè¶…é«˜æ¸…è§†è§‰é—®ç­”æ–¹æ³•ï¼Œé€šè¿‡è‡ªé€‚åº”ç¼©æ”¾æœç´¢ç²¾ç¡®å®šä½å…³é”®åŒºåŸŸï¼Œå¤§å¹…æå‡å‡†ç¡®æ€§å’Œ...|
|ğŸ†• å‘å¸ƒ|Thinking in 360Â°: Humanoid Visual Search in the Wild|ã€Š360Â°æ€è€ƒï¼šé‡å¤–äººå½¢è§†è§‰æœç´¢ã€‹|Heyang Yu, Yinan Han, Xiangyu Zhang, Baiqiao Yin, Bowen Chang, Xiangyu Han, Xinhao Liu, Jing Zhang .etc.|<https://arxiv.org/pdf/2511.20351v1>|æå‡º humanoid è§†è§‰æœç´¢æ–¹æ³•ï¼Œé€šè¿‡äººå¤´æ—‹è½¬åœ¨å…¨æ™¯å›¾åƒä¸­æœç´¢ç›®æ ‡ï¼Œæ˜¾è‘—æå‡äº†æœç´¢æˆåŠŸç‡ã€‚|
|ğŸ†• å‘å¸ƒ|VKnowU: Evaluating Visual Knowledge Understanding in Multimodal LLMs|â€œVKnowUï¼šè¯„ä¼°å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§†è§‰çŸ¥è¯†ç†è§£â€|Tianxiang Jiang, Sheng Xia, Yicheng Xu, Linquan Wu, Xiangyu Zeng, Limin Wang, Yu Qiao, Yi Wang|<https://arxiv.org/pdf/2511.20272v1>|æå‡ºVKnowUåŸºå‡†å’ŒVideoKnow+æ¨¡å‹ï¼Œè¯„ä¼°å¹¶å¢å¼ºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å¯¹è§†è§‰çŸ¥è¯†çš„ç†è§£ã€‚|
|ğŸ†• å‘å¸ƒ|GHR-VQA: Graph-guided Hierarchical Relational Reasoning for Video Question Answering|å›¾å¼•å¯¼çš„å±‚æ¬¡å…³ç³»æ¨ç†ç”¨äºè§†é¢‘é—®ç­”çš„GHR-VQA|Dionysia Danai Brilli, Dimitrios Mallis, Vassilis Pitsikalis, Petros Maragos|<https://arxiv.org/pdf/2511.20201v1>|æå‡ºäº†ä¸€ç§åŸºäºåœºæ™¯å›¾å’Œå›¾ç¥ç»ç½‘ç»œçš„äººç±»ä¸­å¿ƒè§†é¢‘é—®ç­”æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†å¯¹è±¡å…³ç³»æ¨ç†æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|Harmonious Parameter Adaptation in Continual Visual Instruction Tuning for Safety-Aligned MLLMs|æŒç»­è§†è§‰æŒ‡ä»¤å¾®è°ƒä¸­å®‰å…¨æ€§å¯¹é½çš„å’Œè°å‚æ•°é€‚é…|Ziqi Wang, Chang Che, Qi Wang, Hui Ma, Zenglin Shi, Cees G. M. Snoek, Meng Wang|<https://arxiv.org/pdf/2511.20158v1>|æå‡ºäº†ä¸€ç§å¹³è¡¡å®‰å…¨æ€§å’Œä»»åŠ¡æ€§èƒ½çš„å‚æ•°é€‚åº”æ¡†æ¶ï¼Œæœ‰æ•ˆç¼“è§£äº†æŒç»­è§†è§‰æŒ‡ä»¤å¾®è°ƒä¸­çš„ä»»åŠ¡é—å¿˜å’Œå®‰å…¨é€€åŒ–é—®é¢˜ã€‚|
|ğŸ“ æ›´æ–°|Cross-Layer Vision Smoothing: Enhancing Visual Understanding via Sustained Focus on Key Objects in Large Vision-Language Models|è·¨å±‚è§†è§‰å¹³æ»‘ï¼šé€šè¿‡åœ¨å¤§è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­å¯¹å…³é”®å¯¹è±¡æŒç»­å…³æ³¨å¢å¼ºè§†è§‰ç†è§£|Jianfei Zhao, Feng Zhang, Xin Sun, Chong Feng, Zhixing Tan|<https://arxiv.org/pdf/2509.12897v2>|æå‡ºCross-Layer Vision Smoothingæ–¹æ³•ï¼Œé€šè¿‡æŒç»­å…³æ³¨å…³é”®å¯¹è±¡æå‡å¤§å‹è§†è§‰è¯­...|
|ğŸ“ æ›´æ–°|Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning|â€œMetis-HOMEï¼šå¤šæ¨¡æ€æ¨ç†çš„æ··åˆä¼˜åŒ–ä¸“å®¶æ¨¡å‹â€|Xiaohan Lan, Fanfan Liu, Haibo Qiu, Siqi Yang, Delian Ruan, Peng Shi, Lin Ma|<https://arxiv.org/pdf/2510.20519v2>|[ä»£ç ](https://github.com/MM-Thinking/Metis-HOME.); æå‡ºäº†ä¸€ç§æ··åˆä¼˜åŒ–ä¸“å®¶æ¨¡å‹Metis-HOMEï¼Œé€šè¿‡åŒºåˆ†æ€ç»´å’Œéæ€ç»´åˆ†æ”¯ï¼Œæœ‰æ•ˆå¹³è¡¡äº†å¤šæ¨¡æ€æ¨ç†çš„å¤æ‚...|
|ğŸ†• å‘å¸ƒ|VGGT4D: Mining Motion Cues in Visual Geometry Transformers for 4D Scene Reconstruction|VGGT4Dï¼šåœ¨è§†è§‰å‡ ä½•å˜æ¢å™¨ä¸­æŒ–æ˜è¿åŠ¨çº¿ç´¢ç”¨äºå››ç»´åœºæ™¯é‡å»º|Yu Hu, Chong Cheng, Sicheng Yu, Xiaoyang Guo, Hao Wang|<https://arxiv.org/pdf/2511.19971v1>|æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„VGGT4Dæ¡†æ¶ï¼Œé€šè¿‡æŒ–æ˜å’Œæ”¾å¤§åŠ¨æ€çº¿ç´¢å®ç°4Dåœºæ™¯é‡å»ºï¼Œæœ‰æ•ˆåŒºåˆ†åŠ¨æ€ç‰©ä½“ä¸é™æ€...|
|ğŸ†• å‘å¸ƒ|MambaEye: A Size-Agnostic Visual Encoder with Causal Sequential Processing|MambaEyeï¼šä¸€ç§å¤§å°æ— å…³çš„è§†è§‰ç¼–ç å™¨ï¼Œå…·æœ‰å› æœé¡ºåºå¤„ç†èƒ½åŠ›|Changho Choi, Minho Kim, Jinkyu Kim|<https://arxiv.org/pdf/2511.19963v1>|æå‡ºäº†ä¸€ç§å¤§å°æ— å…³çš„è§†è§‰ç¼–ç å™¨MambaEyeï¼Œé€šè¿‡å•å‘å› æœå¤„ç†å’Œç›¸å¯¹ç§»åŠ¨åµŒå…¥å®ç°translati...|
|ğŸ†• å‘å¸ƒ|CounterVQA: Evaluating and Improving Counterfactual Reasoning in Vision-Language Models for Video Understanding|ã€ŠCounterVQAï¼šè¯„ä¼°ä¸æå‡è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨è§†é¢‘ç†è§£ä¸­çš„åäº‹å®æ¨ç†èƒ½åŠ›ã€‹|Yuefei Chen, Jiang Liu, Xiaodong Lin, Ruixiang Tang|<https://arxiv.org/pdf/2511.19923v1>|æå‡ºCounterVQAåŸºå‡†è¯„ä¼°è§†è§‰è¯­è¨€æ¨¡å‹åœ¨åäº‹å®æ¨ç†ä¸Šçš„èƒ½åŠ›ï¼Œå¹¶å¼€å‘CFGPTæ–¹æ³•æå‡å…¶æ¨ç†æ€§èƒ½...|
|ğŸ†• å‘å¸ƒ|Agent0-VL: Exploring Self-Evolving Agent for Tool-Integrated Vision-Language Reasoning|Agent0-VLï¼šæ¢ç´¢ç”¨äºå·¥å…·é›†æˆè§†è§‰è¯­è¨€æ¨ç†çš„è‡ªæ¼”åŒ–ä»£ç†|Jiaqi Liu, Kaiwen Xiong, Peng Xia, Yiyang Zhou, Haonian Ji, Lu Feng, Siwei Han, Mingyu Ding .etc.|<https://arxiv.org/pdf/2511.19900v1>|[ä»£ç ](https://github.com/aiming-lab/Agent0); æå‡ºäº†ä¸€ç§è‡ªè¿›åŒ–è§†è§‰è¯­è¨€ä»£ç†Agent0-VLï¼Œé€šè¿‡å·¥å…·é›†æˆæ¨ç†å’Œè‡ªæˆ‘è¯„ä¼°å®ç°æ— éœ€å¤–éƒ¨å¥–åŠ±çš„è‡ªæˆ‘ä¼˜åŒ–...|
|ğŸ†• å‘å¸ƒ|VeriSciQA: An Auto-Verified Dataset for Scientific Visual Question Answering|â€œVeriSciQAï¼šä¸€ä¸ªç”¨äºç§‘å­¦è§†è§‰é—®ç­”çš„è‡ªåŠ¨éªŒè¯æ•°æ®é›†â€|Yuyi Li, Daoyuan Chen, Zhen Wang, Yutong Lu, Yaliang Li|<https://arxiv.org/pdf/2511.19899v1>|æå‡ºäº†ä¸€ä¸ªç”ŸæˆåéªŒè¯æ¡†æ¶ï¼Œåˆ›å»ºäº†VeriSciQAæ•°æ®é›†ï¼Œæé«˜äº†ç§‘å­¦è§†è§‰é—®ç­”çš„å‡†ç¡®æ€§å’Œæ¨¡å‹æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|MMPerspective: Do MLLMs Understand Perspective? A Comprehensive Benchmark for Perspective Perception, Reasoning, and Robustness|MMPerspectiveï¼šå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹æ˜¯å¦ç†è§£è§†è§’ï¼Ÿä¸€ç§å…¨é¢çš„è§†è§’æ„ŸçŸ¥ã€æ¨ç†å’Œé²æ£’æ€§åŸºå‡†|Yolo Y. Tang, Pinxin Liu, Zhangyun Tan, Mingqian Feng, Rui Mao, Chao Huang, Jing Bi, Yunzhong Xiao .etc.|<https://arxiv.org/pdf/2505.20426v5>|[ä»£ç ](https://yunlong10.github.io/MMPerspective); æå‡ºMMPerspectiveåŸºå‡†ï¼Œç³»ç»Ÿè¯„ä¼°å¤§å‹å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹å¯¹é€è§†ç†è§£çš„èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|It Hears, It Sees too: Multi-Modal LLM for Depression Detection By Integrating Visual Understanding into Audio Language Models|å®ƒå¬å¾—åˆ°ï¼Œå®ƒä¹Ÿçœ‹å¾—è§ï¼šé€šè¿‡å°†è§†è§‰ç†è§£èå…¥éŸ³é¢‘è¯­è¨€æ¨¡å‹çš„å¤šæ¨¡æ€å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ç”¨äºæŠ‘éƒæ£€æµ‹|Xiangyu Zhao, Yaling Shen, Yiwen Jiang, Zimu Wang, Jiahe Liu, Maxmartwell H Cheng, Guilherme C Oliveira, Robert Desimone .etc.|<https://arxiv.org/pdf/2511.19877v1>|æå‡ºäº†ä¸€ç§èåˆè§†è§‰ç†è§£ä¸éŸ³é¢‘è¯­è¨€æ¨¡å‹çš„å¤šæ¨¡æ€LLMæ¡†æ¶ï¼Œæœ‰æ•ˆæå‡äº†æŠ‘éƒæ£€æµ‹çš„å‡†ç¡®æ€§ã€‚|


### è·¨æ¨¡æ€æ£€ç´¢ä¸åŒ¹é… (Cross-modal Retrieval & Matching)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ScenarioCLIP: Pretrained Transferable Visual Language Models and Action-Genome Dataset for Natural Scene Analysis|åœºæ™¯CLIPï¼šé¢„è®­ç»ƒè¿ç§»æ€§è§†è§‰è¯­è¨€æ¨¡å‹ä¸åŠ¨ä½œåŸºå› ç»„æ•°æ®é›†ç”¨äºè‡ªç„¶åœºæ™¯åˆ†æ|Advik Sinha, Saurabh Atreya, Aashutosh A, Sk Aziz Ali, Abhijit Das|<https://arxiv.org/pdf/2511.20274v1>|[ä»£ç ](https://github.com/scenario-clip/ScenarioCLIP); ScenarioCLIPé€šè¿‡ç»“åˆå…³ç³»å’Œåœºæ™¯æ•°æ®ï¼Œæå‡äº†è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤æ‚åœºæ™¯åˆ†æä¸­çš„è¡¨ç°ã€‚|
|ğŸ“ æ›´æ–°|Can Modern Vision Models Understand the Difference Between an Object and a Look-alike?|ç°ä»£è§†è§‰æ¨¡å‹èƒ½å¤Ÿç†è§£ç‰©ä½“ä¸å…¶ç›¸ä¼¼ç‰©ä¹‹é—´çš„å·®å¼‚å—ï¼Ÿ|Itay Cohen, Ethan Fetaya, Amir Rosenfeld|<https://arxiv.org/pdf/2511.19200v2>|æ¢ç©¶äº†ç°ä»£è§†è§‰æ¨¡å‹åŒºåˆ†ç‰©ä½“ä¸å…¶ç›¸ä¼¼ç‰©èƒ½åŠ›ï¼Œå¹¶æå‡ºäº†RoLAæ•°æ®é›†åŠæ”¹è¿›CLIPæ¨¡å‹çš„æ–¹æ³•ã€‚|


### è§†è§‰å†…å®¹æè¿° (Visual Content Description)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Explainable Visual Anomaly Detection via Concept Bottleneck Models|é€šè¿‡æ¦‚å¿µç“¶é¢ˆæ¨¡å‹çš„è§†è§‰å¼‚å¸¸æ£€æµ‹è§£é‡Šæ–¹æ³•|Arianna Stropeni, Valentina Zaccaria, Francesco Borsatti, Davide Dalle Pezze, Manuel Barusco, Gian Antonio Susto|<https://arxiv.org/pdf/2511.20088v1>|æå‡ºäº†ä¸€ç§ç»“åˆæ¦‚å¿µç“¶é¢ˆæ¨¡å‹çš„å¯è§£é‡Šè§†è§‰å¼‚å¸¸æ£€æµ‹æ–¹æ³•ï¼Œé€šè¿‡å­¦ä¹ æœ‰æ„ä¹‰çš„æ¦‚å¿µæä¾›æ›´ä¸°å¯Œã€åŸºäºæ¦‚å¿µçš„å¼‚å¸¸è§£...|


### å¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿ (Multimodal Dialogue Systems)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|ABM-LoRA: Activation Boundary Matching for Fast Convergence in Low-Rank Adaptation|ABM-LoRAï¼šåŸºäºæ¿€æ´»è¾¹ç•ŒåŒ¹é…çš„ä½ç§©é€‚åº”å¿«é€Ÿæ”¶æ•›æ–¹æ³•|Dongha Lee, Jinhee Park, Minjun Kim, Junseok Kwon|<https://arxiv.org/pdf/2511.19145v2>|æå‡ºäº†ä¸€ç§åˆå§‹åŒ–ç­–ç•¥ABM-LoRAï¼Œé€šè¿‡åŒ¹é…æ¿€æ´»è¾¹ç•ŒåŠ å¿«ä½ç§©é€‚é…å™¨çš„æ”¶æ•›é€Ÿåº¦ã€‚|
|ğŸ“ æ›´æ–°|Disc3D: Automatic Curation of High-Quality 3D Dialog Data via Discriminative Object Referring|Disc3Dï¼šé€šè¿‡åˆ¤åˆ«æ€§ç‰©ä½“æŒ‡å¼•ç”¨è‡ªåŠ¨ç­›é€‰é«˜è´¨é‡ä¸‰ç»´å¯¹è¯æ•°æ®é›†|Siyuan Wei, Chunjie Wang, Xiao Liu, Xiaosheng Yan, Zhishan Zhou, Rui Huang|<https://arxiv.org/pdf/2511.18817v2>|æå‡ºäº†ä¸€ç§è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡3Dåœºæ™¯å¯¹è¯æ•°æ®çš„å…¨è‡ªåŠ¨åŒ–æµç¨‹ï¼Œè§£å†³äº†è§†è§’å’Œå¯¹è±¡æŒ‡ä»£æ¨¡ç³Šé—®é¢˜ã€‚|


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MedROV: Towards Real-Time Open-Vocabulary Detection Across Diverse Medical Imaging Modalities|MedROVï¼šé¢å‘å¤šæ¨¡æ€åŒ»å­¦æˆåƒçš„å®æ—¶å¼€æ”¾è¯æ±‡æ£€æµ‹|Tooba Tehreem Sheikh, Jean Lahoud, Rao Muhammad Anwer, Fahad Shahbaz Khan, Salman Khan, Hisham Cholakkal|<https://arxiv.org/pdf/2511.20650v1>|[ä»£ç ](https://github.com/toobatehreem/MedROV.); MedROVå®ç°äº†åŒ»ç–—å½±åƒå®æ—¶å¼€æ”¾è¯æ±‡æ£€æµ‹ï¼Œé€šè¿‡å¤§è§„æ¨¡æ•°æ®é›†å’Œå¯¹æ¯”å­¦ä¹ æå‡æ³›åŒ–èƒ½åŠ›ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ¨¡å‹...|
|ğŸ“ æ›´æ–°|LoRA-based methods on Unet for transfer learning in Subarachnoid Hematoma Segmentation|åŸºäºLoRAçš„Unetè¿ç§»å­¦ä¹ æ–¹æ³•åœ¨è››ç½‘è†œä¸‹è…”å‡ºè¡€åˆ†å‰²ä¸­çš„åº”ç”¨|Cristian Minoccheri, Matthew Hodgman, Haoyuan Ma, Rameez Merchant, Emily Wittrup, Craig Williamson, Kayvan Najarian|<https://arxiv.org/pdf/2508.01772v3>|æå‡ºåŸºäºLoRAçš„Unetè¿ç§»å­¦ä¹ æ–¹æ³•ï¼Œæ˜¾è‘—æå‡è„‘å‡ºè¡€äºšç§åˆ†å‰²æ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|CLIP-IT: CLIP-based Pairing for Histology Images Classification|CLIP-ITï¼šåŸºäºCLIPçš„ç—…ç†å›¾åƒåˆ†ç±»é…å¯¹æ–¹æ³•|Banafsheh Karimian, Giulia Avanzato, Soufian Belharbi, Alexis Guichemerre, Luke McCaffrey, Mohammadhadi Shateri, Eric Granger|<https://arxiv.org/pdf/2504.16181v5>|CLIP-ITé€šè¿‡åˆ©ç”¨æœªé…å¯¹çš„æ–‡æœ¬æŠ¥å‘Šå’ŒCLIPæ¨¡å‹ï¼Œå®ç°äº†æ— éœ€é…å¯¹æ•°æ®çš„å¤šæ¨¡æ€åŒ»å­¦å›¾åƒåˆ†ç±»ã€‚|
|ğŸ†• å‘å¸ƒ|HistoSpeckle-Net: Mutual Information-Guided Deep Learning for high-fidelity reconstruction of complex OrganAMNIST images via perturbed Multimode Fibers|HistoSpeckle-Netï¼šåŸºäºäº’ä¿¡æ¯çš„æ·±åº¦å­¦ä¹ ï¼Œé€šè¿‡æ‰°åŠ¨å¤šæ¨¡å…‰çº¤å®ç°å¤æ‚OrganAMNISTå›¾åƒçš„é«˜ä¿çœŸé‡å»º|Jawaria Maqbool, M. Imran Cheema|<https://arxiv.org/pdf/2511.20245v1>|æå‡ºäº†ä¸€ç§åŸºäºäº’ä¿¡æ¯æŒ‡å¯¼çš„æ·±åº¦å­¦ä¹ æ¶æ„HistoSpeckle-Netï¼Œå®ç°äº†åœ¨å°‘é‡æ•°æ®ä¸‹å¯¹å¤æ‚åŒ»å­¦...|
|ğŸ“ æ›´æ–°|WeatherDiffusion: Controllable Weather Editing in Intrinsic Space|ã€ŠWeatherDiffusionï¼šå†…åœ¨ç©ºé—´ä¸­çš„å¯æ§å¤©æ°”ç¼–è¾‘ã€‹|Yixin Zhu, Zuoliang Zhu, Jian Yang, MiloÅ¡ HaÅ¡an, Jin Xie, Beibei Wang|<https://arxiv.org/pdf/2508.06982v2>|WeatherDiffusioné€šè¿‡åœ¨å›ºæœ‰ç©ºé—´ä¸­ç¼–è¾‘å¤©æ°”ï¼Œæé«˜äº†æ§åˆ¶æ€§å’Œæ¸²æŸ“è´¨é‡ï¼Œä¼˜äºä¼ ç»Ÿåƒç´ ç©ºé—´æ–¹...|
|ğŸ“ æ›´æ–°|TK-Mamba: Marrying KAN With Mamba for Text-Driven 3D Medical Image Segmentation|TK-Mambaï¼šå°†KANä¸Mambaç»“åˆç”¨äºæ–‡æœ¬é©±åŠ¨çš„ä¸‰ç»´åŒ»å­¦å›¾åƒåˆ†å‰²|Haoyu Yang, Yutong Guan, Meixing Shi, Yuxiang Cai, Jintao Chen, Sun Bing, Wenhui Lei, Mianxin Liu .etc.|<https://arxiv.org/pdf/2505.18525v2>|[ä»£ç ](https://github.com/yhy-whu/TK-Mamba); æå‡ºäº†ä¸€ç§èåˆæ–‡æœ¬å’Œ3Då›¾åƒçš„åˆ†å‰²æ¡†æ¶TK-Mambaï¼Œæé«˜äº†åŒ»ç–—å›¾åƒåˆ†å‰²çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚|
|ğŸ†• å‘å¸ƒ|LiMT: A Multi-task Liver Image Benchmark Dataset|LiMTï¼šä¸€ä¸ªå¤šä»»åŠ¡è‚è„å›¾åƒåŸºå‡†æ•°æ®é›†|Zhe Liu, Kai Han, Siqi Ma, Yan Zhu, Jun Chen, Chongwen Lyu, Xinyi Qiu, Chengxuan Qian .etc.|<https://arxiv.org/pdf/2511.19889v1>|æ„å»ºäº†ä¸€ä¸ªå¤šä»»åŠ¡è‚è„å›¾åƒæ•°æ®é›†LiMTï¼Œæ”¯æŒè‚è„å’Œè‚¿ç˜¤åˆ†å‰²ã€å¤šæ ‡ç­¾ç—…å˜åˆ†ç±»åŠæ£€æµ‹ï¼Œä¿ƒè¿›è®¡ç®—æœºè¾…åŠ©è¯Šæ–­...|


### æ™ºèƒ½äº¤é€šè§†è§‰ (Intelligent Transportation Vision)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|AD-R1: Closed-Loop Reinforcement Learning for End-to-End Autonomous Driving with Impartial World Models|AD-R1ï¼šåŸºäºä¸åè¢’ä¸–ç•Œæ¨¡å‹çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶é—­ç¯å¼ºåŒ–å­¦ä¹ |Tianyi Yan, Tao Tang, Xingtai Gui, Yongkang Li, Jiasen Zhesng, Weiyao Huang, Lingdong Kong, Wencheng Han .etc.|<https://arxiv.org/pdf/2511.20325v1>|æå‡ºäº†ä¸€ç§åˆ©ç”¨æ— åä¸–ç•Œæ¨¡å‹å’Œå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯¹æç«¯æƒ…å†µçš„å¤„ç†èƒ½åŠ›ã€‚|


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|TaCo: Capturing Spatio-Temporal Semantic Consistency in Remote Sensing Change Detection|TaCo: åœ¨é¥æ„Ÿå˜åŒ–æ£€æµ‹ä¸­æ•æ‰æ—¶ç©ºè¯­ä¹‰ä¸€è‡´æ€§|Han Guo, Chenyang Liu, Haotian Zhang, Bowen Chen, Zhengxia Zou, Zhenwei Shi|<https://arxiv.org/pdf/2511.20306v1>|æå‡ºäº†ä¸€ç§æ—¶ç©ºè¯­ä¹‰ä¸€è‡´æ€§ç½‘ç»œTaCoï¼Œé€šè¿‡å¼•å…¥æ–‡æœ¬å¼•å¯¼çš„è½¬æ¢ç”Ÿæˆå™¨ï¼Œæœ‰æ•ˆè§£å†³äº†é¥æ„Ÿå˜åŒ–æ£€æµ‹ä¸­çš„è¯­ä¹‰ä¸...|
|ğŸ†• å‘å¸ƒ|Map-World: Masked Action planning and Path-Integral World Model for Autonomous Driving|åœ°å›¾ä¸–ç•Œï¼šé¢å‘è‡ªåŠ¨é©¾é©¶çš„é®è”½åŠ¨ä½œè§„åˆ’ä¸è·¯å¾„ç§¯åˆ†ä¸–ç•Œæ¨¡å‹|Bin Hu, Zijian Lu, Haicheng Liao, Chengran Yuan, Bin Rao, Yongkang Li, Guofa Li, Zhiyong Cui .etc.|<https://arxiv.org/pdf/2511.20156v1>|æå‡ºäº†ä¸€ç§æ— éœ€é¢„è®¾é”šç‚¹çš„å¤šæ¨¡æ€è‡ªåŠ¨é©¾é©¶è§„åˆ’æ¡†æ¶ï¼Œé€šè¿‡ç»“åˆæ©ç åŠ¨ä½œè§„åˆ’å’Œè·¯å¾„åŠ æƒçš„ä¸–ç•Œæ¨¡å‹ï¼Œå®ç°äº†é«˜æ•ˆ...|
|ğŸ†• å‘å¸ƒ|History-Augmented Contrastive Meta-Learning for Unsupervised Blind Super-Resolution of Planetary Remote Sensing Images|å†å²å¢å¼ºçš„å¯¹æ¯”å…ƒå­¦ä¹ ç”¨äºè¡Œæ˜Ÿé¥æ„Ÿå›¾åƒçš„æ— ç›‘ç£ç›²è¶…åˆ†è¾¨ç‡é‡å»º|Huijia Zhao, Jie Lu, Yunqing Jiang, Xiao-Ping Lu, Kaichang Di|<https://arxiv.org/pdf/2511.20045v1>|[ä»£ç ](https://github.com/2333repeat/HACBSR); æå‡ºäº†ä¸€ç§æ— ç›‘ç£çš„ç›²è¶…åˆ†è¾¨ç‡æ¡†æ¶ï¼Œé€šè¿‡å†å²å¢å¼ºå¯¹æ¯”å­¦ä¹ æå‡è¡Œæ˜Ÿé¥æ„Ÿå›¾åƒè´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|ChessMamba: Structure-Aware Interleaving of State Spaces for Change Detection in Remote Sensing Images|ChessMambaï¼šé¢å‘é¥æ„Ÿå›¾åƒå˜åŒ–æ£€æµ‹çš„çŠ¶æ€ç©ºé—´ç»“æ„æ„ŸçŸ¥äº¤é”™æ–¹æ³•|Lei Ding, Tong Liu, Xuanguang Liu, Xiangyun Liu, Haitao Guo, Jun Lu|<https://arxiv.org/pdf/2511.19882v1>|[ä»£ç ](https://github.com/DingLei14/ChessMamba.); æå‡ºäº†ä¸€ç§ç»“æ„æ„ŸçŸ¥çš„æ¡†æ¶ChessMambaï¼Œé€šè¿‡äº¤é”™çŠ¶æ€ç©ºé—´å»ºæ¨¡å¢å¼ºå¤šæ—¶ç›¸é¥æ„Ÿå›¾åƒå˜åŒ–æ£€æµ‹çš„å‡†ç¡®æ€§...|


### å·¥ä¸šè§†è§‰æ£€æµ‹ (Industrial Visual Inspection)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|DRL-Guided Neural Batch Sampling for Semi-Supervised Pixel-Level Anomaly Detection|æ·±åº¦å¼ºåŒ–å­¦ä¹ å¼•å¯¼çš„ç¥ç»æ‰¹é‡é‡‡æ ·ç”¨äºåŠç›‘ç£åƒç´ çº§å¼‚å¸¸æ£€æµ‹|Amirhossein Khadivi Noghredeh, Abdollah Safari, Fatemeh Ziaeetabar, Firoozeh Haghighi|<https://arxiv.org/pdf/2511.20270v1>|æå‡ºäº†ä¸€ç§åŠç›‘ç£æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡è‡ªé€‚åº”é€‰æ‹©ä¿¡æ¯ patchesï¼Œæœ‰æ•ˆå­¦ä¹ æ­£å¸¸å’Œç¼ºé™·æ¨¡å¼ï¼Œæé«˜äº†...|
|ğŸ†• å‘å¸ƒ|WaymoQA: A Multi-View Visual Question Answering Dataset for Safety-Critical Reasoning in Autonomous Driving|WaymoQAï¼šé¢å‘è‡ªåŠ¨é©¾é©¶å®‰å…¨å…³é”®æ¨ç†çš„å¤šè§†è§’è§†è§‰é—®ç­”æ•°æ®é›†|Seungjun Yu, Seonho Lee, Namho Kim, Jaeyo Shin, Junsung Park, Wonjeong Ryu, Raehyuk Jung, Hyunjung Shim|<https://arxiv.org/pdf/2511.20022v1>|æå‡ºäº†Safety-Critical Reasoningä»»åŠ¡ï¼Œå¹¶åˆ›å»ºäº†WaymoQAå¤šè§†è§’è§†è§‰é—®ç­”æ•°...|
|ğŸ†• å‘å¸ƒ|Intelligent Image Search Algorithms Fusing Visual Large Models|èåˆè§†è§‰å¤§è§„æ¨¡æ¨¡å‹çš„æ™ºèƒ½å›¾åƒæœç´¢ç®—æ³•|Kehan Wang, Tingqiong Cui, Yang Zhang, Yu Chen, Shifeng Wu, Zhenzhang Li|<https://arxiv.org/pdf/2511.19920v1>|æå‡ºäº†ä¸€ç§èåˆç‰©ä½“æ£€æµ‹ä¸è§†è§‰å¤§æ¨¡å‹çš„æ™ºèƒ½å›¾åƒæœç´¢æ¡†æ¶DetVLMï¼Œå®ç°äº†åŸºäºçŠ¶æ€å’Œé›¶æ ·æœ¬çš„å›¾åƒæ£€ç´¢ã€‚|


## æ–°å…´ç†è®ºä¸è·¨å­¦ç§‘æ–¹å‘ (Emerging Theory & Interdisciplinary Directions)


### ç¥ç»-ç¬¦å·è§†è§‰ (Neuro-symbolic Vision)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|3D Motion Perception of Binocular Vision Target with PID-CNN|åŒçœ¼è§†è§‰ç›®æ ‡çš„PID-CNNä¸‰ç»´è¿åŠ¨æ„ŸçŸ¥|Shi Jiazhao, Pan Pan, Shi Haotian|<https://arxiv.org/pdf/2511.20332v1>|æå‡ºäº†ä¸€ç§åŸºäºPIDçš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œå®ç°äº†å¯¹åŒç›®è§†è§‰ç›®æ ‡çš„ä¸‰ç»´è¿åŠ¨ä¿¡æ¯å®æ—¶æ„ŸçŸ¥ã€‚|


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Blind Adaptive Local Denoising for CEST Imaging|ç›²è‡ªé€‚åº”å±€éƒ¨é™å™ªåœ¨CESTæˆåƒä¸­çš„åº”ç”¨|Chu Chen, Aitor Artola, Yang Liu, Se Weon Park, Raymond H. Chan, Jean-Michel Morel, Kannie W. Y. Chan|<https://arxiv.org/pdf/2511.20081v1>|æå‡ºäº†ä¸€ç§è‡ªé€‚åº”å±€éƒ¨ç›²å»å™ªæ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†CESTæˆåƒä¸­çš„ç©ºé—´å˜å™ªå£°é—®é¢˜ï¼Œæé«˜äº†åˆ†å­æµ“åº¦æ˜ å°„å’Œç™Œç—‡æ£€...|
|ğŸ†• å‘å¸ƒ|Uplifting Table Tennis: A Robust, Real-World Application for 3D Trajectory and Spin Estimation|æå‡ä¹’ä¹“çƒï¼šä¸€ç§ç”¨äºä¸‰ç»´è½¨è¿¹å’Œæ—‹è½¬ä¼°è®¡çš„é²æ£’æ€§ç°å®ä¸–ç•Œåº”ç”¨|Daniel Kienzle, Katja Ludwig, Julian Lorenz, Shin'ichi Satoh, Rainer Lienhart|<https://arxiv.org/pdf/2511.20250v1>|æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µ pipelineï¼Œé€šè¿‡ç»“åˆ2Dç›‘ç£å’Œåˆæˆæ•°æ®è®­ç»ƒï¼Œå®ç°äº†å¯¹ç°å®ä¸–ç•Œä¹’ä¹“çƒ3Dè½¨è¿¹å’Œ...|

