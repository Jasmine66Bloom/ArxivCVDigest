## [UPDATED!] **2025-12-02** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|DynamicVerse: A Physically-Aware Multimodal Framework for 4D World Modeling|åŠ¨æ€è¯—ç¯‡ï¼šä¸€ç§ç‰©ç†æ„ŸçŸ¥çš„å¤šæ¨¡æ€æ¡†æ¶ç”¨äºå››ç»´ä¸–ç•Œå»ºæ¨¡|Kairun Wen, Yuzhi Huang, Runyu Chen, Hui Zheng, Yunlong Lin, Panwang Pan, Chenxin Li, Wenyan Cong .etc.|<https://arxiv.org/pdf/2512.03000v2>|æå‡ºäº†ä¸€ç§ç‰©ç†æ„ŸçŸ¥çš„å¤šæ¨¡æ€4Dä¸–ç•Œå»ºæ¨¡æ¡†æ¶DynamicVerseï¼Œæœ‰æ•ˆæå‡äº†åŠ¨æ€çœŸå®ä¸–ç•Œè§†é¢‘çš„å»ºæ¨¡...|
|ğŸ†• å‘å¸ƒ|OneThinker: All-in-one Reasoning Model for Image and Video|â€œä¸€æ€è€…ï¼šå›¾åƒä¸è§†é¢‘çš„å…¨èƒ½æ¨ç†æ¨¡å‹â€|Kaituo Feng, Manyuan Zhang, Hongyu Li, Kaixuan Fan, Shuang Chen, Yilei Jiang, Dian Zheng, Peiwen Sun .etc.|<https://arxiv.org/pdf/2512.03043v2>|OneThinkerç»Ÿä¸€äº†å›¾åƒå’Œè§†é¢‘ç†è§£ï¼Œæå‡äº†å¤šæ¨¡æ€æ¨ç†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’ŒçŸ¥è¯†å…±äº«ã€‚|
|ğŸ†• å‘å¸ƒ|Polar Perspectives: Evaluating 2-D LiDAR Projections for Robust Place Recognition with Visual Foundation Models|æè§†è§’æ¢ç´¢ï¼šåŸºäºè§†è§‰åŸºç¡€æ¨¡å‹çš„äºŒç»´æ¿€å…‰é›·è¾¾æŠ•å½±åœ¨é²æ£’ä½ç½®è¯†åˆ«ä¸­çš„è¯„ä¼°|Pierpaolo Serio, Giulio Pisaneschi, Andrea Dan Ryals, Vincenzo Infantino, Lorenzo Gentilini, Valentina Donzella, Lorenzo Pollini|<https://arxiv.org/pdf/2512.02897v1>|æ¢ç©¶ä¸åŒLiDARæŠ•å½±å¯¹è§†è§‰åŸºç¡€æ¨¡å‹çš„å½±å“ï¼Œæå‡ºæ¨¡å—åŒ–æ£€ç´¢æµç¨‹ä¼˜åŒ–äºŒç»´æŠ•å½±åœ¨ä½ç½®è¯†åˆ«ä¸­çš„åº”ç”¨ã€‚|
|ğŸ†• å‘å¸ƒ|GeoBridge: A Semantic-Anchored Multi-View Foundation Model Bridging Images and Text for Geo-Localization|GeoBridgeï¼šä¸€ç§è¯­ä¹‰é”šå®šçš„å¤šè§†è§’åŸºç¡€æ¨¡å‹ï¼Œç”¨äºå›¾åƒä¸æ–‡æœ¬ä¹‹é—´çš„åœ°ç†å®šä½æ¡¥æ¥|Zixuan Song, Jing Zhang, Di Wang, Zidie Zhou, Wenbin Liu, Haonan Guo, En Wang, Bo Du|<https://arxiv.org/pdf/2512.02697v1>|[ä»£ç ](https://github.com/MiliLab/GeoBridge.); æå‡ºGeoBridgeæ¨¡å‹ï¼Œåˆ©ç”¨è¯­ä¹‰é”šå®šæœºåˆ¶èåˆå¤šè§†è§’å›¾åƒä¸æ–‡æœ¬ä¿¡æ¯ï¼Œå¢å¼ºåœ°ç†å®šä½çš„é²æ£’æ€§å’Œçµæ´»æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Leveraging Large-Scale Pretrained Spatial-Spectral Priors for General Zero-Shot Pansharpening|åˆ©ç”¨å¤§è§„æ¨¡é¢„è®­ç»ƒçš„ç©ºé—´-å…‰è°±å…ˆéªŒè¿›è¡Œé€šç”¨é›¶æ ·æœ¬å…¨è‰²é”åŒ–|Yongchuan Cui, Peng Liu, Yi Zeng|<https://arxiv.org/pdf/2512.02643v1>|æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§è§„æ¨¡é¢„è®­ç»ƒçš„ç©ºè°±å…ˆéªŒè¿›è¡Œé€šç”¨é›¶æ ·æœ¬ pansharpening çš„æ–°ç­–ç•¥ï¼Œæœ‰æ•ˆæå‡äº†...|
|ğŸ†• å‘å¸ƒ|RULER-Bench: Probing Rule-based Reasoning Abilities of Next-level Video Generation Models for Vision Foundation Intelligence|RULER-Benchï¼šæ¢æµ‹ä¸‹ä¸€ä»£è§†é¢‘ç”Ÿæˆæ¨¡å‹åœ¨è§†è§‰åŸºç¡€æ™ºèƒ½ä¸­çš„åŸºäºè§„åˆ™æ¨ç†èƒ½åŠ›|Xuming He, Zehao Fan, Hengjia Li, Fan Zhuo, Hankun Xu, Senlin Cheng, Di Weng, Haifeng Liu .etc.|<https://arxiv.org/pdf/2512.02622v1>|æå‡ºäº†RULER-Benchï¼Œä¸€ç§è¯„ä¼°è§†é¢‘ç”Ÿæˆæ¨¡å‹åŸºäºè®¤çŸ¥è§„åˆ™æ¨ç†èƒ½åŠ›çš„æ–°åŸºå‡†ï¼Œæ­ç¤ºäº†ç°æœ‰æ¨¡å‹åœ¨æ¨ç†...|


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Two-Stage Vision Transformer for Image Restoration: Colorization Pretraining + Residual Upsampling|ä¸¤é˜¶æ®µè§†è§‰å˜æ¢å™¨ç”¨äºå›¾åƒæ¢å¤ï¼šè‰²å½©åŒ–é¢„è®­ç»ƒ + æ®‹å·®ä¸Šé‡‡æ ·|Aditya Chaudhary, Prachet Dev Singh, Ankit Jha|<https://arxiv.org/pdf/2512.02512v2>|æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µè®­ç»ƒçš„ViT-SRæ–¹æ³•ï¼Œé€šè¿‡è‰²å½©åŒ–é¢„è®­ç»ƒå’Œæ®‹å·®ä¸Šé‡‡æ ·æ˜¾è‘—æå‡å›¾åƒè¶…åˆ†è¾¨ç‡æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|Layout Anything: One Transformer for Universal Room Layout Estimation|ã€Šé€šç”¨æˆ¿é—´å¸ƒå±€ä¼°è®¡çš„ä¸€ä½“åŒ–Transformerï¼šLayout Anythingã€‹|Md Sohag Mia, Muhammad Abdullah Adnan|<https://arxiv.org/pdf/2512.02952v1>|æå‡ºäº†ä¸€ç§åŸºäºTransformerçš„é€šç”¨å®¤å†…å¸ƒå±€ä¼°è®¡æ¡†æ¶ï¼Œé€šè¿‡ä»»åŠ¡æ¡ä»¶æŸ¥è¯¢å’Œå¯¹æ¯”å­¦ä¹ ï¼Œç»“åˆå¸ƒå±€é€€åŒ–...|
|ğŸ†• å‘å¸ƒ|ALDI-ray: Adapting the ALDI Framework for Security X-ray Object Detection|ALDI-rayï¼šå°†ALDIæ¡†æ¶é€‚é…äºå®‰å…¨Xå°„çº¿ç‰©ä½“æ£€æµ‹|Omid Reza Heidari, Yang Wang, Xinxin Zuo|<https://arxiv.org/pdf/2512.02696v1>|å°†ALDI++æ¡†æ¶åº”ç”¨äºXå°„çº¿å®‰æ£€å›¾åƒé¢†åŸŸè‡ªé€‚åº”ï¼Œæå‡äº†è·¨åŸŸç‰©ä½“æ£€æµ‹çš„å‡†ç¡®æ€§å’Œç¨³å®šæ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Spatially-Grounded Document Retrieval via Patch-to-Region Relevance Propagation|åŸºäºç©ºé—´å®šä½çš„æ–‡æ¡£æ£€ç´¢ï¼šé€šè¿‡è¡¥ä¸åˆ°åŒºåŸŸçš„ç›¸å…³æ€§ä¼ æ’­|Agathoklis Georgiou|<https://arxiv.org/pdf/2512.02660v1>|æå‡ºäº†ä¸€ç§èåˆè§†è§‰è¯­è¨€æ¨¡å‹ä¸OCRçš„æ··åˆæ¶æ„ï¼Œé€šè¿‡ç©ºé—´ç›¸å…³æ€§è¿‡æ»¤æå‡æ–‡æ¡£æ£€ç´¢çš„ç²¾ç¡®åº¦ã€‚|


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Some Modalities are More Equal Than Others: Decoding and Architecting Multimodal Integration in MLLMs|â€œæŸäº›æ¨¡æ€æ¯”å…¶ä»–æ¨¡æ€æ›´å¹³ç­‰ï¼šè§£ç å’Œæ„å»ºå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹çš„æ¨¡æ€é›†æˆâ€|Tianle Chen, Chaitanya Chakka, Arjun Reddy Akula, Xavier Thomas, Deepti Ghadiyaram|<https://arxiv.org/pdf/2511.22826v2>|æ­ç¤ºäº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†çŸ›ç›¾æ¨¡æ€æ—¶çš„è„†å¼±æ€§ï¼Œå¹¶æå‡ºäº†æ¨¡æ€å¯¹é½è°ƒä¼˜ç­–ç•¥ä»¥å¢å¼ºå…¶è·¨æ¨¡æ€æ¨ç†èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|Real-Time Multimodal Data Collection Using Smartwatches and Its Visualization in Education|æ™ºèƒ½æ‰‹è¡¨å®æ—¶å¤šæ¨¡æ€æ•°æ®é‡‡é›†åŠå…¶åœ¨æ•™è‚²é¢†åŸŸçš„å¯è§†åŒ–å±•ç¤º|Alvaro Becerra, Pablo Villegas, Ruth Cobos|<https://arxiv.org/pdf/2512.02651v1>|å¼€å‘äº†æ™ºèƒ½æ‰‹è¡¨æ•°æ®é‡‡é›†ä¸å¯è§†åŒ–å·¥å…·ï¼Œæ”¯æŒæ•™è‚²ç¯å¢ƒä¸­å¤šæ¨¡æ€å­¦ä¹ åˆ†æçš„å®é™…åº”ç”¨ã€‚|
|ğŸ†• å‘å¸ƒ|WeMMU: Enhanced Bridging of Vision-Language Models and Diffusion Models via Noisy Query Tokens|WeMMUï¼šé€šè¿‡å™ªå£°æŸ¥è¯¢æ ‡è®°å¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹ä¸æ‰©æ•£æ¨¡å‹ä¹‹é—´çš„æ¡¥æ¥|Jian Yang, Dacheng Yin, Xiaoxuan He, Yong Li, Fengyun Rao, Jing Lyu, Wei Zhai, Yang Cao .etc.|<https://arxiv.org/pdf/2512.02536v1>|æå‡ºNoisy Query Tokensæ–¹æ³•ï¼Œæœ‰æ•ˆæ¡¥æ¥è§†è§‰è¯­è¨€æ¨¡å‹ä¸æ‰©æ•£æ¨¡å‹ï¼Œå¢å¼ºå¤šæ¨¡æ€ä»»åŠ¡çš„æŒç»­å­¦...|


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### ç›®æ ‡æ£€æµ‹ä¸å®šä½ (Object Detection & Localization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Culture Affordance Atlas: Reconciling Object Diversity Through Functional Mapping|æ–‡åŒ–å¯ç”¨æ€§å›¾è°±ï¼šé€šè¿‡åŠŸèƒ½æ˜ å°„è°ƒå’Œå¯¹è±¡å¤šæ ·æ€§|Joan Nwatu, Longju Bai, Oana Ignat, Rada Mihalcea|<https://arxiv.org/pdf/2512.03173v1>|æå‡ºåŠŸèƒ½å¯¼å‘æ¡†æ¶ Culture Affordance Atlasï¼Œå‡å°‘è§†è§‰è¯­è¨€æ¨¡å‹çš„æ–‡åŒ–åè§ï¼Œæå‡...|
|ğŸ†• å‘å¸ƒ|GraphFusion3D: Dynamic Graph Attention Convolution with Adaptive Cross-Modal Transformer for 3D Object Detection|å›¾èåˆ3Dï¼šåŠ¨æ€å›¾æ³¨æ„åŠ›å·ç§¯ä¸è‡ªé€‚åº”è·¨æ¨¡æ€å˜æ¢å™¨ç”¨äºä¸‰ç»´ç‰©ä½“æ£€æµ‹|Md Sohag Mia, Md Nahid Hasan, Tawhid Ahmed, Muhammad Abdullah Adnan|<https://arxiv.org/pdf/2512.02991v1>|GraphFusion3Dé€šè¿‡è‡ªé€‚åº”è·¨æ¨¡æ€è½¬æ¢å™¨å’Œå›¾æ¨ç†æ¨¡å—ï¼Œæœ‰æ•ˆèåˆå¤šæ¨¡æ€ä¿¡æ¯å¹¶æå‡3Dç‰©ä½“æ£€æµ‹æ€§...|
|ğŸ“ æ›´æ–°|AIDEN: Design and Pilot Study of an AI Assistant for the Visually Impaired|AIDENï¼šè§†éšœäººå£«AIåŠ©æ‰‹çš„è®¾è®¡ä¸åˆæ­¥ç ”ç©¶|Luis Marquez-Carpintero, Francisco Gomez-Donoso, Zuria Bauer, Bessie Dominguez-Dager, Alvaro Belmonte-Baeza, MÃ³nica Pina-Navarro, Francisco Morillas-Espejo, Felix Escalona .etc.|<https://arxiv.org/pdf/2511.06080v3>|æå‡ºAIDENç³»ç»Ÿï¼Œé€šè¿‡èåˆå®æ—¶ç‰©ä½“æ£€æµ‹å’Œè§†è§‰æè¿°æŠ€æœ¯ï¼Œä¸ºè§†éšœäººå£«æä¾›ç›´è§‚çš„è§¦è§‰å¯¼èˆªï¼Œæå‡è‡ªä¸»æ€§å’Œç”Ÿ...|
|ğŸ“ æ›´æ–°|Toward Content-based Indexing and Retrieval of Head and Neck CT with Abscess Segmentation|é¢å‘åŸºäºå†…å®¹çš„å¤´é¢ˆCTå›¾åƒç´¢å¼•ä¸æ£€ç´¢åŠè„“è‚¿åˆ†å‰²|Thao Thi Phuong Dao, Tan-Cong Nguyen, Trong-Le Do, Truong Hoang Viet, Nguyen Chi Thanh, Huynh Nguyen Thuan, Do Vo Cong Nguyen, Minh-Khoi Pham .etc.|<https://arxiv.org/pdf/2512.01589v2>|[ä»£ç ](https://github.com/drthaodao3101/AbscessHeNe.git.); æå‡ºAbscessHeNeæ•°æ®é›†ï¼ŒåŠ©åŠ›å¤´é¢ˆè„“è‚¿ç²¾å‡†åˆ†å‰²ä¸ä¸´åºŠå†³ç­–æ”¯æŒã€‚|
|ğŸ“ æ›´æ–°|Learning Egocentric In-Hand Object Segmentation through Weak Supervision from Human Narrations|é€šè¿‡äººç±»å™è¿°çš„å¼±ç›‘ç£å­¦ä¹ è‡ªæˆ‘ä¸­å¿ƒæ‰‹æŒç‰©ä½“åˆ†å‰²|Nicola Messina, Rosario Leonardi, Luca Ciampi, Fabio Carrara, Giovanni Maria Farinella, Fabrizio Falchi, Antonino Furnari|<https://arxiv.org/pdf/2509.26004v2>|[ä»£ç ](https://fpv-iplab.github.io/WISH.); æå‡ºäº†ä¸€ç§åˆ©ç”¨äººç±»å™è¿°è¿›è¡Œå¼±ç›‘ç£å­¦ä¹ çš„æ‰‹æŒç‰©ä½“åˆ†å‰²æ–¹æ³•ï¼Œæ— éœ€ç²¾ç»†åƒç´ çº§æ ‡æ³¨å³å¯å®ç°é«˜æ•ˆåˆ†å‰²ã€‚|
|ğŸ“ æ›´æ–°|Detect Anything 3D in the Wild|åœ¨é‡å¤–æ£€æµ‹ä»»ä½•ä¸‰ç»´ç‰©ä½“|Hanxue Zhang, Haoran Jiang, Qingsong Yao, Yanan Sun, Renrui Zhang, Hao Zhao, Hongyang Li, Hongzi Zhu .etc.|<https://arxiv.org/pdf/2504.07958v3>|æå‡ºDetAny3Dæ¨¡å‹ï¼Œåˆ©ç”¨é¢„è®­ç»ƒ2Dæ¨¡å‹çŸ¥è¯†ï¼Œå®ç°ä»»æ„ç›¸æœºé…ç½®ä¸‹3Dç‰©ä½“æ£€æµ‹çš„é›¶æ ·æœ¬æ³›åŒ–ã€‚|


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|BEVDilation: LiDAR-Centric Multi-Modal Fusion for 3D Object Detection|BEVDilationï¼šåŸºäºæ¿€å…‰é›·è¾¾çš„å¤šæ¨¡æ€èåˆä¸‰ç»´ç›®æ ‡æ£€æµ‹|Guowen Zhang, Chenhang He, Liyi Chen, Lei Zhang|<https://arxiv.org/pdf/2512.02972v1>|[ä»£ç ](https://github.com/gwenzhang/BEVDilation.); æå‡ºLiDAR-centricçš„BEVDilationæ¡†æ¶ï¼Œé€šè¿‡å›¾åƒå¼•å¯¼ä¼˜åŒ–ç‚¹äº‘ç¨€ç–æ€§å’Œè¯­ä¹‰é™åˆ¶ï¼Œæ...|
|ğŸ“ æ›´æ–°|SkelSplat: Robust Multi-view 3D Human Pose Estimation with Differentiable Gaussian Rendering|ã€ŠSkelSplatï¼šå…·æœ‰å¯å¾®åˆ†é«˜æ–¯æ¸²æŸ“çš„é²æ£’å¤šè§†è§’ä¸‰ç»´äººä½“å§¿æ€ä¼°è®¡ã€‹|Laura Bragagnolo, Leonardo Barcellona, Stefano Ghidoni|<https://arxiv.org/pdf/2511.08294v2>|æå‡ºSkelSplatæ¡†æ¶ï¼Œé€šè¿‡å¯å¾®åˆ†é«˜æ–¯æ¸²æŸ“å®ç°æ— éœ€3Dæ ‡æ³¨çš„å¤šè§†è§’ä¸‰ç»´äººä½“å§¿æ€ä¼°è®¡ã€‚|
|ğŸ†• å‘å¸ƒ|DF-Mamba: Deformable State Space Modeling for 3D Hand Pose Estimation in Interactions|DF-Mambaï¼šäº¤äº’ä¸­ä¸‰ç»´æ‰‹éƒ¨å§¿æ€ä¼°è®¡çš„å¯å˜å½¢çŠ¶æ€ç©ºé—´å»ºæ¨¡|Yifan Zhou, Takehiko Ohkawa, Guwenxiao Zhou, Kanoko Goto, Takumi Hirose, Yusuke Sekikawa, Nakamasa Inoue|<https://arxiv.org/pdf/2512.02727v1>|æå‡ºäº†ä¸€ç§åŸºäºçŠ¶æ€ç©ºé—´å»ºæ¨¡çš„3Dæ‰‹éƒ¨å§¿æ€ä¼°è®¡æ¡†æ¶ï¼Œé€šè¿‡é€‰æ‹©æ€§çŠ¶æ€å»ºæ¨¡å’Œå¯å˜å½¢çŠ¶æ€æ‰«æå¢å¼ºå…¨å±€ä¸Šä¸‹æ–‡æ„Ÿ...|
|ğŸ“ æ›´æ–°|End-to-End Multi-Person Pose Estimation with Pose-Aware Video Transformer|ç«¯åˆ°ç«¯å¤šäººå§¿æ€ä¼°è®¡ï¼šåŸºäºå§¿æ€æ„ŸçŸ¥çš„è§†é¢‘å˜æ¢å™¨|Yonghui Yu, Jiahang Cai, Xun Wang, Wenwu Yang|<https://arxiv.org/pdf/2511.13208v2>|[ä»£ç ](https://github.com/zgspose/PAVENet.); æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯çš„è§†é¢‘å¤šäººå§¿æ€ä¼°è®¡æ¡†æ¶PAVE-Netï¼Œé€šè¿‡å§¿æ€æ„ŸçŸ¥æ³¨æ„åŠ›æœºåˆ¶æ¶ˆé™¤äº†ä¼ ç»Ÿä¸¤é˜¶æ®µæ–¹æ³•çš„...|


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SMP: Reusable Score-Matching Motion Priors for Physics-Based Character Control|SMPï¼šç”¨äºåŸºäºç‰©ç†è§’è‰²æ§åˆ¶çš„å¯é‡ç”¨å¾—åˆ†åŒ¹é…è¿åŠ¨å…ˆéªŒ|Yuxuan Mu, Ziyu Zhang, Yi Shi, Minami Matsumoto, Kotaro Imamura, Guy Tevet, Chuan Guo, Michael Taylor .etc.|<https://arxiv.org/pdf/2512.03028v2>|æå‡ºäº†ä¸€ç§å¯é‡ç”¨çš„Score-Matchingè¿åŠ¨å…ˆéªŒæ–¹æ³•ï¼Œé€šè¿‡é¢„è®­ç»ƒæ¨¡å‹å®ç°è·¨ä»»åŠ¡çš„è‡ªç„¶è¡Œä¸ºæ§åˆ¶ã€‚|
|ğŸ“ æ›´æ–°|Flow to the Mode: Mode-Seeking Diffusion Autoencoders for State-of-the-Art Image Tokenization|æµè‡³æ¨¡å¼ï¼šç”¨äºæœ€å…ˆè¿›å›¾åƒæ ‡è®°çš„æ¨¡å¼å¯»æ‰¾æ‰©æ•£è‡ªåŠ¨ç¼–ç å™¨|Kyle Sargent, Kyle Hsu, Justin Johnson, Li Fei-Fei, Jiajun Wu|<https://arxiv.org/pdf/2503.11056v3>|[ä»£ç ](http://kylesargent.github.io/flowmo); æå‡ºFlowMoï¼Œä¸€ç§æ— éœ€å·ç§¯å’Œå¯¹æŠ—æŸå¤±çš„å˜å‹å™¨åŸºæ‰©æ•£è‡ªåŠ¨ç¼–ç å™¨ï¼Œå®ç°å›¾åƒ tokenize æ–°çªç ´...|
|ğŸ†• å‘å¸ƒ|CAMEO: Correspondence-Attention Alignment for Multi-View Diffusion Models|ã€ŠCAMEOï¼šå¤šè§†è§’æ‰©æ•£æ¨¡å‹çš„å¯¹é½æ³¨æ„å¯¹åº”å…³ç³»ã€‹|Minkyung Kwon, Jinhyeok Choi, Jiho Park, Seonghu Jeon, Jinhyuk Jang, Junyoung Seo, Minseop Kwak, Jin-Hwa Kim .etc.|<https://arxiv.org/pdf/2512.03045v1>|å¼•å…¥CAMEOè®­ç»ƒæŠ€æœ¯ï¼Œé€šè¿‡å‡ ä½•å¯¹åº”ç›´æ¥ç›‘ç£æ³¨æ„åŠ›å›¾ï¼Œæå‡å¤šè§†è§’æ‰©æ•£æ¨¡å‹è®­ç»ƒæ•ˆç‡å’Œç”Ÿæˆè´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|Instant Video Models: Universal Adapters for Stabilizing Image-Based Networks|å³æ—¶è§†é¢‘æ¨¡å‹ï¼šç”¨äºç¨³å®šåŸºäºå›¾åƒç½‘ç»œçš„é€šç”¨é€‚é…å™¨|Matthew Dutson, Nathan Labiosa, Yin Li, Mohit Gupta|<https://arxiv.org/pdf/2512.03014v1>|æå‡ºäº†ä¸€ç§ç¨³å®šæ€§å’Œé²æ£’æ€§é€‚é…å™¨ï¼Œæœ‰æ•ˆè§£å†³äº†è§†é¢‘å¸§å¤„ç†ä¸­çš„æ—¶åºä¸ä¸€è‡´é—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|Glance: Accelerating Diffusion Models with 1 Sample|ã€Šä¸€ç¥ï¼šä½¿ç”¨å•æ ·æœ¬åŠ é€Ÿæ‰©æ•£æ¨¡å‹ã€‹|Zhuobai Dong, Rui Zhao, Songjie Wu, Junchao Yi, Linjie Li, Zhengyuan Yang, Lijuan Wang, Alex Jinpeng Wang|<https://arxiv.org/pdf/2512.02899v1>|é€šè¿‡å¼•å…¥è½»é‡çº§LoRAé€‚é…å™¨ï¼Œå®ç°äº†é’ˆå¯¹ä¸åŒé˜¶æ®µæ™ºèƒ½åŠ é€Ÿçš„æ‰©æ•£æ¨¡å‹ï¼Œå¤§å¹…æå‡äº†æ¨ç†é€Ÿåº¦å¹¶ä¿æŒäº†å›¾åƒè´¨...|
|ğŸ“ æ›´æ–°|NOCTIS: Novel Object Cyclic Threshold based Instance Segmentation|NOCTISï¼šåŸºäºæ–°é¢–å¯¹è±¡å¾ªç¯é˜ˆå€¼å®ä¾‹åˆ†å‰²|Max Gandyra, Alessandro Santonicola, Michael Beetz|<https://arxiv.org/pdf/2507.01463v4>|æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„NOCTISæ¡†æ¶ï¼Œé€šè¿‡é›†æˆé¢„è®­ç»ƒæ¨¡å‹å’Œæ–°å‹å¾ªç¯é˜ˆå€¼æœºåˆ¶ï¼Œå®ç°äº†å¯¹æ–°é¢–ç‰©ä½“å®ä¾‹çš„é«˜...|
|ğŸ“ æ›´æ–°|Aligning Diffusion Models with Noise-Conditioned Perception|å°†å™ªå£°æ¡ä»¶æ„ŸçŸ¥ä¸æ‰©æ•£æ¨¡å‹å¯¹é½|Alexander Gambashidze, Anton Kulikov, Yuriy Sosnin, Ilya Makarov|<https://arxiv.org/pdf/2406.17636v2>|æå‡ºäº†ä¸€ç§åœ¨U-NetåµŒå…¥ç©ºé—´ä¸­ä¼˜åŒ–æ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ï¼Œæå‡äº†è®­ç»ƒæ•ˆç‡å’Œå›¾åƒè´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|Beyond Paired Data: Self-Supervised UAV Geo-Localization from Reference Imagery Alone|ery è¶…è¶Šæˆå¯¹æ•°æ®ï¼šä»…ä»å‚è€ƒå›¾åƒä¸­è¿›è¡Œçš„è‡ªç›‘ç£æ— äººæœºåœ°ç†å®šä½|Tristan Amadei, Enric Meinhardt-Llopis, Benedicte Bascle, Corentin Abgrall, Gabriele Facciolo|<https://arxiv.org/pdf/2512.02737v1>|æå‡ºäº†ä¸€ç§æ— éœ€æˆå¯¹æ•°æ®çš„è‡ªç›‘ç£æ— äººæœºåœ°ç†å®šä½æ–¹æ³•ï¼Œé€šè¿‡ä»…ä½¿ç”¨å«æ˜Ÿå›¾åƒè®­ç»ƒï¼Œå®ç°äº†ä¸æˆå¯¹æ•°æ®è®­ç»ƒæ–¹æ³•ç›¸...|
|ğŸ†• å‘å¸ƒ|PGP-DiffSR: Phase-Guided Progressive Pruning for Efficient Diffusion-based Image Super-Resolution|PGP-DiffSRï¼šç›¸ä½å¼•å¯¼çš„æ¸è¿›å¼å‰ªæç”¨äºé«˜æ•ˆæ‰©æ•£åŸºäºå›¾åƒè¶…åˆ†è¾¨ç‡|Zhongbao Yang, Jiangxin Dong, Yazhou Yao, Jinhui Tang, Jinshan Pan|<https://arxiv.org/pdf/2512.02681v1>|[ä»£ç ](https://github.com/yzb1997/PGP-DiffSR.); æå‡ºäº†ä¸€ç§åŸºäºç›¸ä½ä¿¡æ¯çš„è½»é‡çº§æ‰©æ•£æ¨¡å‹å‰ªææ–¹æ³•ï¼Œæœ‰æ•ˆé™ä½è®¡ç®—å’Œå†…å­˜æˆæœ¬åŒæ—¶ä¿æŒå›¾åƒè¶…åˆ†è¾¨ç‡è´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|Joint Distillation for Fast Likelihood Evaluation and Sampling in Flow-based Models|åŸºäºæµçš„æ¨¡å‹ä¸­ç”¨äºå¿«é€Ÿä¼¼ç„¶è¯„ä¼°å’Œé‡‡æ ·çš„è”åˆè’¸é¦|Xinyue Ai, Yutong He, Albert Gu, Ruslan Salakhutdinov, J Zico Kolter, Nicholas Matthew Boffi, Max Simchowitz|<https://arxiv.org/pdf/2512.02636v1>|æå‡ºäº†ä¸€ç§è”åˆè’¸é¦æ¡†æ¶F2D2ï¼Œå¤§å¹…å‡å°‘æµæ¨¡å‹é‡‡æ ·å’Œä¼¼ç„¶è¯„ä¼°æ‰€éœ€çš„å‡½æ•°è®¡ç®—æ¬¡æ•°ã€‚|


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Does Hearing Help Seeing? Investigating Audio-Video Joint Denoising for Video Generation|å¬åŠ›æœ‰åŠ©äºè§†è§‰å—ï¼Ÿæ¢ç©¶éŸ³é¢‘-è§†é¢‘è”åˆå»å™ªåœ¨è§†é¢‘ç”Ÿæˆä¸­çš„åº”ç”¨|Jianzong Wu, Hao Lian, Dachao Hao, Ye Tian, Qingyu Shi, Biaolong Chen, Hao Jiang, Yunhai Tong|<https://arxiv.org/pdf/2512.02457v2>|æ¢ç©¶éŸ³é¢‘è§†é¢‘è”åˆå»å™ªè®­ç»ƒå¦‚ä½•æå‡è§†é¢‘ç”Ÿæˆè´¨é‡ï¼Œæå‡ºAVFullDiTæ¶æ„å®ç°è·¨æ¨¡æ€ååŒã€‚|
|ğŸ†• å‘å¸ƒ|LoVoRA: Text-guided and Mask-free Video Object Removal and Addition with Learnable Object-aware Localization|ã€ŠLoVoRAï¼šåŸºäºæ–‡æœ¬å¼•å¯¼å’Œæ— é®æŒ¡çš„è§†é¢‘ç›®æ ‡ç§»é™¤ä¸æ·»åŠ æ–¹æ³•ï¼Œå…·æœ‰å¯å­¦ä¹ å¯¹è±¡æ„ŸçŸ¥å®šä½ã€‹|Zhihan Xiao, Lin Liu, Yixin Gao, Xiaopeng Zhang, Haoxuan Che, Songping Mai, Qi Tian|<https://arxiv.org/pdf/2512.02933v2>|[ä»£ç ](https://cz-5f.github.io/LoVoRA.github.io); æå‡ºäº†ä¸€ç§æ— éœ€é¢å¤–æ©è†œæˆ–å‚è€ƒå›¾åƒçš„æ–‡æœ¬å¼•å¯¼è§†é¢‘ç¼–è¾‘æ¡†æ¶ï¼Œé€šè¿‡å¯å­¦ä¹ å¯¹è±¡æ„ŸçŸ¥å®šä½æœºåˆ¶å®ç°ç‰©ä½“ç§»é™¤ä¸æ·»åŠ ...|
|ğŸ†• å‘å¸ƒ|MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding|å¤šåˆ†è¾¨ç‡æ£€ç´¢-æ£€æµ‹èåˆç”¨äºé«˜åˆ†è¾¨ç‡å›¾åƒç†è§£|Fan Yang, Kaihao Zhang|<https://arxiv.org/pdf/2512.02906v2>|æå‡ºäº†ä¸€ç§å¤šåˆ†è¾¨ç‡æ£€ç´¢-æ£€æµ‹èåˆæ¡†æ¶ï¼Œé€šè¿‡æ•´åˆä¸åŒåˆ†è¾¨ç‡ä¸‹çš„è¯­ä¹‰ä¿¡æ¯ï¼Œæœ‰æ•ˆæå‡äº†é«˜åˆ†è¾¨ç‡å›¾åƒçš„ç†è§£èƒ½...|
|ğŸ“ æ›´æ–°|Generative Action Tell-Tales: Assessing Human Motion in Synthesized Videos|ç”Ÿæˆè¡Œä¸ºè¿¹è±¡ï¼šåœ¨åˆæˆè§†é¢‘ä¸­è¯„ä¼°äººç±»è¿åŠ¨|Xavier Thomas, Youngsun Lim, Ananya Srinivasan, Audrey Zheng, Deepti Ghadiyaram|<https://arxiv.org/pdf/2512.01803v2>|æå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œé€šè¿‡å­¦ä¹ çœŸå®äººç±»åŠ¨ä½œçš„æ½œåœ¨ç©ºé—´ï¼Œæ˜¾è‘—æé«˜äº†å¯¹ç”Ÿæˆè§†é¢‘ä¸­åŠ¨ä½œè´¨é‡çš„è¯„ä¼°å‡†ç¡®æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|PixPerfect: Seamless Latent Diffusion Local Editing with Discriminative Pixel-Space Refinement|â€œPixPerfectï¼šå…·æœ‰åˆ¤åˆ«æ€§åƒç´ ç©ºé—´ä¼˜åŒ–çš„æ— ç¼æ½œåœ¨æ‰©æ•£å±€éƒ¨ç¼–è¾‘â€|Haitian Zheng, Yuan Yao, Yongsheng Yu, Yuqian Zhou, Jiebo Luo, Zhe Lin|<https://arxiv.org/pdf/2512.03247v1>|æå‡ºäº†PixPerfectæ¡†æ¶ï¼Œé€šè¿‡åƒç´ çº§ç»†åŒ–æ˜¾è‘—å‡å°‘äº†å›¾åƒç¼–è¾‘ä¸­çš„ä¸ä¸€è‡´æ€§å’Œç‘•ç–µï¼Œæå‡äº†å›¾åƒç¼–è¾‘è´¨...|
|ğŸ†• å‘å¸ƒ|MagicQuillV2: Precise and Interactive Image Editing with Layered Visual Cues|ã€ŠMagicQuillV2ï¼šå¸¦æœ‰åˆ†å±‚è§†è§‰çº¿ç´¢çš„ç²¾ç¡®äº’åŠ¨å›¾åƒç¼–è¾‘ã€‹|Zichen Liu, Yue Yu, Hao Ouyang, Qiuyu Wang, Shuailei Ma, Ka Leong Cheng, Wen Wang, Qingyan Bai .etc.|<https://arxiv.org/pdf/2512.03046v1>|å¼•å…¥åˆ†å±‚ç»„åˆèŒƒå¼ï¼Œå®ç°ç²¾ç¡®äº’åŠ¨å›¾åƒç¼–è¾‘ï¼Œå¼¥åˆç”Ÿæˆæ¨¡å‹ä¸å›¾å½¢è½¯ä»¶æ§åˆ¶ä¹‹é—´çš„å·®è·ã€‚|
|ğŸ†• å‘å¸ƒ|PPTArena: A Benchmark for Agentic PowerPoint Editing|PPTArenaï¼šä¸€ä¸ªç”¨äºä»£ç†å¼PowerPointç¼–è¾‘çš„åŸºå‡†æµ‹è¯•|Michael Ofengenden, Yunze Man, Ziqi Pang, Yu-Xiong Wang|<https://arxiv.org/pdf/2512.03042v1>|æå‡ºPPTArenaåŸºå‡†ï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€æŒ‡ä»¤å®ç°PowerPointç²¾ç¡®ç¼–è¾‘ï¼Œå¹¶æå‡ºPPTPilotç¼–...|
|ğŸ“ æ›´æ–°|UniEdit-I: Training-free Image Editing for Unified VLM via Iterative Understanding, Editing and Verifying|ç»Ÿä¸€è¯­è¨€æ¨¡å‹è¿­ä»£ç†è§£ã€ç¼–è¾‘ä¸éªŒè¯çš„æ— è®­ç»ƒå›¾åƒç¼–è¾‘ï¼šUniEdit-I|Chengyu Bai, Jintao Chen, Xiang Bai, Yilong Chen, Qi She, Ming Lu, Shanghang Zhang|<https://arxiv.org/pdf/2508.03142v2>|æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„å›¾åƒç¼–è¾‘æ¡†æ¶UniEdit-Iï¼Œé€šè¿‡ç†è§£-ç¼–è¾‘-éªŒè¯å¾ªç¯åœ¨è¯­ä¹‰æ½œåœ¨ç©ºé—´å†…å®ç°é—­ç¯...|
|ğŸ†• å‘å¸ƒ|Video4Spatial: Towards Visuospatial Intelligence with Context-Guided Video Generation|é¢å‘è§†è§‰ç©ºé—´æ™ºèƒ½ï¼šåŸºäºä¸Šä¸‹æ–‡å¼•å¯¼çš„è§†é¢‘ç”Ÿæˆæ–¹æ³•|Zeqi Xiao, Yiwei Zhao, Lingxiao Li, Yushi Lan, Yu Ning, Rahul Garg, Roshni Cooper, Mohammad H. Taghavi .etc.|<https://arxiv.org/pdf/2512.03040v1>|æå‡ºVideo4Spatialæ¡†æ¶ï¼Œä»…ç”¨è§†è§‰æ•°æ®è®­ç»ƒçš„è§†é¢‘ç”Ÿæˆæ¨¡å‹å®ç°ç©ºé—´æ™ºèƒ½ï¼Œå®Œæˆå¤æ‚ç©ºé—´ä»»åŠ¡ã€‚|
|ğŸ†• å‘å¸ƒ|ViSAudio: End-to-End Video-Driven Binaural Spatial Audio Generation|ViSAudioï¼šç«¯åˆ°ç«¯è§†é¢‘é©±åŠ¨çš„åŒè€³ç©ºé—´éŸ³é¢‘ç”Ÿæˆ|Mengchen Zhang, Qi Chen, Tong Wu, Zihan Liu, Dahua Lin|<https://arxiv.org/pdf/2512.03036v1>|[ä»£ç ](https://kszpxxzmc.github.io/ViSAudio-project.); æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯è§†é¢‘é©±åŠ¨çš„åŒè€³ç©ºé—´éŸ³é¢‘ç”Ÿæˆæ¡†æ¶ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨ç©ºé—´æ²‰æµ¸æ„Ÿå’Œä¸€è‡´æ€§ä¸Šçš„ä¸è¶³ã€‚|
|ğŸ†• å‘å¸ƒ|Unrolled Networks are Conditional Probability Flows in MRI Reconstruction|å±•å¼€ç½‘ç»œåœ¨MRIé‡å»ºä¸­æ˜¯æ¡ä»¶æ¦‚ç‡æµ|Kehan Qi, Saumya Gupta, Qingqiao Hu, Weimin Lyu, Chao Chen|<https://arxiv.org/pdf/2512.03020v1>|å°†å±•å¼€ç½‘ç»œç†è®ºåŒ–ä¸ºæ¡ä»¶æ¦‚ç‡æµODEsï¼Œæå‡ºFlow-Aligned Trainingæ–¹æ³•ï¼Œæå‡MRI...|
|ğŸ†• å‘å¸ƒ|AutoBrep: Autoregressive B-Rep Generation with Unified Topology and Geometry|è‡ªåŠ¨B-Repç”Ÿæˆï¼šç»Ÿä¸€æ‹“æ‰‘ä¸å‡ ä½•çš„è‡ªåŠ¨å›å½’B-Repç”Ÿæˆæ–¹æ³•|Xiang Xu, Pradeep Kumar Jayaraman, Joseph G. Lambourne, Yilin Liu, Durvesh Malpure, Pete Meltzer|<https://arxiv.org/pdf/2512.03018v1>|[ä»£ç ](https://github.com/AutodeskAILab/AutoBrep.); æå‡ºäº†ä¸€ç§åŸºäºTransformerçš„AutoBrepæ¨¡å‹ï¼Œé€šè¿‡ç»Ÿä¸€ç¼–ç å‡ ä½•ä¸æ‹“æ‰‘ç‰¹æ€§ï¼Œé«˜æ•ˆç”Ÿæˆç²¾ç¡®...|
|ğŸ†• å‘å¸ƒ|In-Context Sync-LoRA for Portrait Video Editing|ã€ŠåŸºäºä¸Šä¸‹æ–‡çš„åŒæ­¥LoRAäººåƒè§†é¢‘ç¼–è¾‘æ–¹æ³•ã€‹|Sagi Polaczek, Or Patashnik, Ali Mahdavi-Amiri, Daniel Cohen-Or|<https://arxiv.org/pdf/2512.03013v1>|æå‡ºäº†ä¸€ç§ç¼–è¾‘è‚–åƒè§†é¢‘çš„æ–¹æ³•ï¼Œé€šè¿‡ä¿®æ”¹é¦–å¸§å¹¶ä¿æŒå¸§åŒæ­¥ï¼Œå®ç°äº†é«˜è´¨é‡çš„è§†è§‰ä¿®æ”¹å’Œèº«ä»½ä¸€è‡´æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|U4D: Uncertainty-Aware 4D World Modeling from LiDAR Sequences|U4Dï¼šä»æ¿€å…‰é›·è¾¾åºåˆ—ä¸­è¿›è¡Œä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„4Dä¸–ç•Œå»ºæ¨¡|Xiang Xu, Ao Liang, Youquan Liu, Linfeng Li, Lingdong Kong, Ziwei Liu, Qingshan Liu|<https://arxiv.org/pdf/2512.02982v1>|æå‡ºäº†ä¸€ç§è€ƒè™‘ä¸ç¡®å®šæ€§çš„4D LiDARä¸–ç•Œå»ºæ¨¡æ¡†æ¶ï¼Œé€šè¿‡åˆ†é˜¶æ®µå¤„ç†å’Œæ—¶ç©ºèåˆæé«˜äº†å»ºæ¨¡çš„å‡ ä½•çœŸå®æ€§...|
|ğŸ“ æ›´æ–°|PrITTI: Primitive-based Generation of Controllable and Editable 3D Semantic Urban Scenes|åŸºäºåŸè¯­çš„ç”Ÿæˆå¯æ§å¯ç¼–è¾‘ä¸‰ç»´è¯­ä¹‰åŸå¸‚åœºæ™¯çš„æ–¹æ³•PrITTI|Christina Ourania Tze, Daniel Dauner, Yiyi Liao, Dzmitry Tsishkou, Andreas Geiger|<https://arxiv.org/pdf/2506.19117v2>|[ä»£ç ](https://raniatze.github.io/pritti); æå‡ºäº†ä¸€ç§åŸºäºåŸè¯­è¡¨ç¤ºçš„3DåŸå¸‚åœºæ™¯ç”Ÿæˆæ–¹æ³•ï¼Œå®ç°äº†é«˜è´¨é‡ã€æ˜“ç¼–è¾‘çš„åœºæ™¯ç”Ÿæˆã€‚|
|ğŸ†• å‘å¸ƒ|Benchmarking Scientific Understanding and Reasoning for Video Generation using VideoScience-Bench|ä½¿ç”¨VideoScience-Benchå¯¹è§†é¢‘ç”Ÿæˆä¸­çš„ç§‘å­¦ç†è§£ä¸æ¨ç†è¿›è¡ŒåŸºå‡†æµ‹è¯•|Lanxiang Hu, Abhilash Shankarampeta, Yixin Huang, Zilin Dai, Haoyang Yu, Yujie Zhao, Haoqiang Kang, Daniel Zhao .etc.|<https://arxiv.org/pdf/2512.02942v1>|[ä»£ç ](https://github.com/hao-ai-lab/VideoScience); æå‡ºäº†VideoScience-Benchï¼Œé¦–ä¸ªè¯„ä¼°è§†é¢‘æ¨¡å‹ç§‘å­¦ç†è§£å’Œæ¨ç†èƒ½åŠ›çš„åŸºå‡†ï¼Œæ¶µç›–ç‰©ç†å’ŒåŒ–å­¦...|
|ğŸ†• å‘å¸ƒ|DiverseAR: Boosting Diversity in Bitwise Autoregressive Image Generation|å¤šæ ·åŒ–ARï¼šæå‡ä½è¿ç®—è‡ªå›å½’å›¾åƒç”Ÿæˆä¸­çš„å¤šæ ·æ€§|Ying Yang, Zhengyao Lv, Tianlin Pan, Haofan Wang, Binxin Yang, Hubery Yin, Chen Li, Chenyang Si|<https://arxiv.org/pdf/2512.02931v1>|æå‡ºäº†ä¸€ç§è‡ªé€‚åº”åˆ†å¸ƒç¼©æ”¾æœºåˆ¶ï¼Œé€šè¿‡è°ƒæ•´é¢„æµ‹åˆ†å¸ƒçš„å°–é”åº¦ï¼Œæ˜¾è‘—æå‡äº†è‡ªå›å½’å›¾åƒç”Ÿæˆä¸­çš„æ ·æœ¬å¤šæ ·æ€§ã€‚|
|ğŸ†• å‘å¸ƒ|Taming Camera-Controlled Video Generation with Verifiable Geometry Reward|ç”¨å¯éªŒè¯å‡ ä½•å¥–åŠ±é©¯æœç›¸æœºæ§åˆ¶è§†é¢‘ç”Ÿæˆ|Zhaoqing Wang, Xiaobo Xia, Zhuolin Bie, Jinlin Liu, Dongdong Yu, Jia-Wang Bian, Changhu Wang|<https://arxiv.org/pdf/2512.02870v1>|æå‡ºäº†ä¸€ç§åœ¨çº¿å¼ºåŒ–å­¦ä¹ åè®­ç»ƒæ¡†æ¶ï¼Œé€šè¿‡å¯éªŒè¯çš„å‡ ä½•å¥–åŠ±ä¼˜åŒ–é¢„è®­ç»ƒè§†é¢‘ç”Ÿæˆå™¨ï¼Œå®ç°äº†ç²¾ç¡®çš„ç›¸æœºæ§åˆ¶ã€‚|
|ğŸ†• å‘å¸ƒ|Are Detectors Fair to Indian IP-AIGC? A Cross-Generator Study|å°åº¦IP-AIGCæ£€æµ‹å™¨æ˜¯å¦å…¬å¹³ï¼Ÿä¸€é¡¹è·¨ç”Ÿæˆå™¨ç ”ç©¶|Vishal Dubey, Pallavi Tyagi|<https://arxiv.org/pdf/2512.02850v1>|ç ”ç©¶äº†å°åº¦äººç¾¤åœ¨èº«ä»½ä¿ç•™ç”Ÿæˆå›¾åƒæ£€æµ‹ä¸­çš„å…¬å¹³æ€§ï¼Œå‘ç°ç°æœ‰æ£€æµ‹å™¨å­˜åœ¨è¿‡æ‹Ÿåˆé—®é¢˜ã€‚|
|ğŸ†• å‘å¸ƒ|PaCo-RL: Advancing Reinforcement Learning for Consistent Image Generation with Pairwise Reward Modeling|PaCo-RLï¼šåˆ©ç”¨æˆå¯¹å¥–åŠ±å»ºæ¨¡æ¨è¿›å¼ºåŒ–å­¦ä¹ åœ¨ä¸€è‡´å›¾åƒç”Ÿæˆä¸­çš„åº”ç”¨|Bowen Ping, Chengyou Jia, Minnan Luo, Changliang Xia, Xin Shen, Zhuohang Dang, Hangwei Qian|<https://arxiv.org/pdf/2512.04784v1>|[ä»£ç ](https://x-gengroup.github.io/HomePage_PaCo-RL); PaCo-RLé€šè¿‡ç»“åˆä¸€è‡´æ€§å¥–åŠ±æ¨¡å‹å’Œé«˜æ•ˆå¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œå®ç°äº†æ— éœ€å¤§é‡æ•°æ®å³å¯ç”Ÿæˆè§†è§‰ä¸€è‡´æ€§çš„å›¾åƒã€‚|
|ğŸ“ æ›´æ–°|3DIS: Depth-Driven Decoupled Instance Synthesis for Text-to-Image Generation|3DISï¼šåŸºäºæ·±åº¦é©±åŠ¨çš„è§£è€¦å®ä¾‹åˆæˆç”¨äºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ|Dewei Zhou, Ji Xie, Zongxin Yang, Yi Yang|<https://arxiv.org/pdf/2410.12669v2>|[ä»£ç ](https://github.com/limuloo/3DIS.); æå‡ºäº†ä¸€ç§æ·±åº¦é©±åŠ¨çš„è§£è€¦å®ä¾‹åˆæˆæ¡†æ¶3DISï¼Œé€šè¿‡åˆ†é˜¶æ®µå¤„ç†å®ç°äº†æ›´ç²¾ç¡®çš„å¸ƒå±€å’Œå±æ€§æ¸²æŸ“ã€‚|
|ğŸ†• å‘å¸ƒ|ClimaOoD: Improving Anomaly Segmentation via Physically Realistic Synthetic Data|é€šè¿‡ç‰©ç†é€¼çœŸçš„åˆæˆæ•°æ®æ”¹è¿›å¼‚å¸¸åˆ†å‰²çš„ClimaOoD|Yuxing Liu, Yong Liu|<https://arxiv.org/pdf/2512.02686v1>|æå‡ºäº†ä¸€ç§ç”Ÿæˆç‰©ç†çœŸå®åˆæˆå¼‚å¸¸æ•°æ®çš„æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†å¼‚å¸¸åˆ†å‰²æ¨¡å‹åœ¨å¼€æ”¾ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|Hear What Matters! Text-conditioned Selective Video-to-Audio Generation|å¬è§æ‰€å…³å¿ƒä¹‹äº‹ï¼åŸºäºæ–‡æœ¬æ¡ä»¶çš„è§†é¢‘åˆ°éŸ³é¢‘é€‰æ‹©æ€§ç”Ÿæˆ|Junwon Lee, Juhan Nam, Jiyoung Lee|<https://arxiv.org/pdf/2512.02650v1>|[ä»£ç ](https://jnwnlee.github.io/selva-demo); æå‡ºäº†ä¸€ç§åŸºäºæ–‡æœ¬æç¤ºçš„é€‰åŒºè§†é¢‘è½¬éŸ³é¢‘æ–¹æ³•ï¼Œæœ‰æ•ˆæå–ç›®æ ‡å£°éŸ³æºï¼Œä¼˜åŒ–äº†å¤šåª’ä½“åˆ¶ä½œä¸­çš„éŸ³é¢‘ç¼–è¾‘ä¸æ··éŸ³ã€‚|
|ğŸ“ æ›´æ–°|FairT2I: Mitigating Social Bias in Text-to-Image Generation via Large Language Model-Assisted Detection and Attribute Rebalancing|å…¬å¹³T2Iï¼šé€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹è¾…åŠ©æ£€æµ‹ä¸å±æ€§é‡å¹³è¡¡å‡è½»æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„ç¤¾ä¼šåè§|Jinya Sakurai, Yuki Koyama, Issei Sato|<https://arxiv.org/pdf/2502.03826v3>|æå‡ºFairT2Iæ¡†æ¶ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹æ£€æµ‹å¹¶å¹³è¡¡æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„ç¤¾ä¼šåè§ï¼Œæå‡ç”Ÿæˆå›¾åƒçš„å…¬å¹³æ€§å’Œ...|
|ğŸ†• å‘å¸ƒ|OmniPerson: Unified Identity-Preserving Pedestrian Generation|å…¨æ–¹ä½è¡Œäººï¼šç»Ÿä¸€èº«ä»½ä¿æŒçš„è¡Œäººç”Ÿæˆ|Changxiao Ma, Chao Yuan, Xincheng Shi, Yuzhuo Ma, Yongfei Zhang, Longkun Zhou, Yujia Zhang, Shangze Li .etc.|<https://arxiv.org/pdf/2512.02554v1>|æå‡ºOmniPersonæ¨¡å‹ï¼Œé¦–æ¬¡å®ç°ç»Ÿä¸€èº«ä»½ä¿æŒçš„è¡Œäººç”Ÿæˆï¼Œæœ‰æ•ˆè§£å†³è¡Œäººé‡è¯†åˆ«æ•°æ®ä¸è¶³é—®é¢˜ã€‚|
|ğŸ“ æ›´æ–°|Walk Before You Dance: High-fidelity and Editable Dance Synthesis via Generative Masked Motion Prior|åœ¨è·³èˆä¹‹å‰å…ˆå­¦èµ°ï¼šé€šè¿‡ç”Ÿæˆé®è”½è¿åŠ¨å…ˆéªŒå®ç°é«˜ä¿çœŸä¸”å¯ç¼–è¾‘çš„èˆè¹ˆåˆæˆ|Foram N Shah, Parshwa Shah, Muhammad Usama Saleem, Ekkasit Pinyoanuntapong, Pu Wang, Hongfei Xue, Ahmed Helmy|<https://arxiv.org/pdf/2504.04634v3>|[ä»£ç ](https://foram-s1.github.io/DanceMosaic); æå‡ºäº†ä¸€ç§ç”Ÿæˆå¼é®è”½æ–‡æœ¬åˆ°åŠ¨ä½œæ¨¡å‹ï¼Œå®ç°äº†é«˜è´¨é‡èˆè¹ˆåŠ¨ä½œçš„åŒæ­¥ç”Ÿæˆä¸ç¼–è¾‘ã€‚|


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MultiShotMaster: A Controllable Multi-Shot Video Generation Framework|å¤šé•œå¤´æŒæ§å¸ˆï¼šä¸€ä¸ªå¯æ§çš„å¤šé•œå¤´è§†é¢‘ç”Ÿæˆæ¡†æ¶|Qinghe Wang, Xiaoyu Shi, Baolu Li, Weikang Bian, Quande Liu, Huchuan Lu, Xintao Wang, Pengfei Wan .etc.|<https://arxiv.org/pdf/2512.03041v1>|æå‡ºäº†ä¸€ç§å¤šé•œå¤´è§†é¢‘ç”Ÿæˆæ¡†æ¶MultiShotMasterï¼Œé€šè¿‡åˆ›æ–°çš„RoPEå˜ä½“å’Œè‡ªåŠ¨åŒ–æ•°æ®æ ‡æ³¨æµ...|
|ğŸ†• å‘å¸ƒ|MAViD: A Multimodal Framework for Audio-Visual Dialogue Understanding and Generation|MAViDï¼šä¸€ç§ç”¨äºéŸ³é¢‘-è§†è§‰å¯¹è¯ç†è§£å’Œç”Ÿæˆçš„å¤šæ¨¡æ€æ¡†æ¶|Youxin Pang, Jiajun Liu, Lingfeng Tan, Yong Zhang, Feng Gao, Xiang Deng, Zhuoliang Kang, Xiaoming Wei .etc.|<https://arxiv.org/pdf/2512.03034v1>|æå‡ºMAViDæ¡†æ¶ï¼Œé€šè¿‡Conductor-Creatoræ¶æ„å®ç°éŸ³é¢‘è§†è§‰å¯¹è¯ç†è§£å’Œç”Ÿæˆï¼Œç”Ÿæˆè¿è´¯çš„...|
|ğŸ†• å‘å¸ƒ|LumiX: Structured and Coherent Text-to-Intrinsic Generation|ã€ŠLumiXï¼šç»“æ„åŒ–ä¸ä¸€è‡´æ€§æ–‡æœ¬åˆ°æœ¬å¾å±æ€§ç”Ÿæˆã€‹|Xu Han, Biao Zhang, Xiangjun Tang, Xianzhi Li, Peter Wonka|<https://arxiv.org/pdf/2512.02781v1>|æå‡ºäº†ä¸€ç§ç»“æ„åŒ–æ‰©æ•£æ¡†æ¶LumiXï¼Œé€šè¿‡Query-Broadcast Attentionå’ŒTens...|
|ğŸ†• å‘å¸ƒ|PPTBench: Towards Holistic Evaluation of Large Language Models for PowerPoint Layout and Design Understanding|PPTBenchï¼šé¢å‘PowerPointå¸ƒå±€ä¸è®¾è®¡ç†è§£çš„å¤§å‹è¯­è¨€æ¨¡å‹å…¨é¢è¯„ä¼°|Zheng Huang, Xukai Liu, Tianyu Hu, Kai Zhang, Ye Liu|<https://arxiv.org/pdf/2512.02624v1>|æå‡ºäº†PPTBenchï¼Œä¸€ä¸ªå…¨é¢çš„åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨PowerPointå¸ƒå±€ä¸è®¾è®¡ç†è§£...|
|ğŸ†• å‘å¸ƒ|Co-speech Gesture Video Generation via Motion-Based Graph Retrieval|åŸºäºè¿åŠ¨é©±åŠ¨çš„å›¾æ£€ç´¢çš„ååŒè¯­éŸ³æ‰‹åŠ¿è§†é¢‘ç”Ÿæˆ|Yafei Song, Peng Zhang, Bang Zhang|<https://arxiv.org/pdf/2512.02576v1>|æå‡ºäº†ä¸€ç§ç»“åˆæ‰©æ•£æ¨¡å‹å’ŒåŸºäºè¿åŠ¨å›¾çš„æ£€ç´¢ç®—æ³•ï¼Œç”ŸæˆåŒæ­¥ä¸”è‡ªç„¶çš„ä¼´éšè¨€è¯­æ‰‹åŠ¿è§†é¢‘çš„æ–°æ¡†æ¶ã€‚|


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|TEXTRIX: Latent Attribute Grid for Native Texture Generation and Beyond|TEXTRIXï¼šåŸç”Ÿçº¹ç†ç”ŸæˆåŠè¶…è¶Šçš„æ½œåœ¨å±æ€§ç½‘æ ¼|Yifei Zeng, Yajie Bao, Jiachen Qian, Shuang Wu, Youtian Lin, Hao Zhu, Buyu Li, Feihu Zhang .etc.|<https://arxiv.org/pdf/2512.02993v1>|æå‡ºäº†ä¸€ç§åŸç”Ÿä¸‰ç»´å±æ€§ç”Ÿæˆæ¡†æ¶TEXTRIXï¼Œé€šè¿‡æ„å»ºæ½œä¸‰ç»´å±æ€§ç½‘æ ¼å’Œç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°äº†é«˜ä¿çœŸçº¹...|
|ğŸ†• å‘å¸ƒ|Reasoning-Aware Multimodal Fusion for Hateful Video Detection|å…·æœ‰æ¨ç†æ„è¯†çš„å¤šå…ƒæ¨¡æ€èåˆç”¨äºä»‡æ¨è§†é¢‘æ£€æµ‹|Shuonan Yang, Tailin Chen, Jiangbei Yue, Guangliang Cheng, Jianbo Jiao, Zeyu Fu|<https://arxiv.org/pdf/2512.02743v1>|æå‡ºäº†ä¸€ç§èåˆå±€éƒ¨å’Œå…¨å±€ä¸Šä¸‹æ–‡çš„Reasoning-Aware Multimodal Fusionæ¡†...|


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Flux4D: Flow-based Unsupervised 4D Reconstruction|åŸºäºæµçš„æ— ç›‘ç£å››ç»´é‡å»ºï¼šFlux4D|Jingkang Wang, Henry Che, Yun Chen, Ze Yang, Lily Goli, Sivabalan Manivasagam, Raquel Urtasun|<https://arxiv.org/pdf/2512.03210v1>|æå‡ºäº†Flux4Dï¼Œä¸€ç§æ— éœ€æ ‡æ³¨å³å¯é«˜æ•ˆé‡å»ºå¤§è§„æ¨¡åŠ¨æ€åœºæ™¯çš„æ¡†æ¶ï¼Œå®ç°äº†å¿«é€Ÿã€å¯æ‰©å±•ä¸”æ³›åŒ–èƒ½åŠ›å¼ºçš„4...|
|ğŸ“ æ›´æ–°|DehazeGS: Seeing Through Fog with 3D Gaussian Splatting|ã€ŠDehazeGSï¼šåˆ©ç”¨ä¸‰ç»´é«˜æ–¯æ•£ç‚¹é€è¿‡é›¾æ°”è§‚å¯Ÿã€‹|Jinze Yu, Yiqun Wang, Aiheng Jiang, Zhengda Lu, Jianwei Guo, Yong Li, Hongxing Qin, Xiaopeng Zhang|<https://arxiv.org/pdf/2501.03659v6>|æå‡ºäº†ä¸€ç§åŸºäºæ˜¾å¼é«˜æ–¯è¡¨ç¤ºçš„é›¾å¤©å›¾åƒå»é›¾æ–¹æ³•DehazeGSï¼Œé€šè¿‡ç‰©ç†æ¸²æŸ“è¿‡ç¨‹æœ‰æ•ˆæ¢å¤é›¾å¤©åœºæ™¯çš„ç»†èŠ‚...|
|ğŸ†• å‘å¸ƒ|PolarGuide-GSDR: 3D Gaussian Splatting Driven by Polarization Priors and Deferred Reflection for Real-World Reflective Scenes|æåŒ–å¼•å¯¼-å…¨å±€è¡¨é¢ç»˜åˆ¶ï¼šç”±æåŒ–å…ˆéªŒé©±åŠ¨çš„ä¸‰ç»´é«˜æ–¯æ•£ç‚¹ç»˜åˆ¶ä¸å»¶è¿Ÿåå°„æŠ€æœ¯ç”¨äºçœŸå®ä¸–ç•Œåå°„æ€§åœºæ™¯|Derui Shan, Qian Qiao, Hao Lu, Tao Du, Peng Lu|<https://arxiv.org/pdf/2512.02664v1>|æå‡ºPolarGuide-GSDRæ–¹æ³•ï¼Œé€šè¿‡æåŒ–å…ˆéªŒä¸3D Gaussian Splattingè€¦åˆ...|
|ğŸ“ æ›´æ–°|PRIMU: Uncertainty Estimation for Novel Views in Gaussian Splatting from Primitive-Based Representations of Error and Coverage|PRIMUï¼šåŸºäºåŸå§‹è¯¯å·®å’Œè¦†ç›–è¡¨ç¤ºçš„é«˜æ–¯æ•£ç‚¹ä¸­æ–°è§†è§’çš„ä¸ç¡®å®šæ€§ä¼°è®¡|Thomas Gottwald, Edgar Heinert, Peter Stehr, Chamuditha Jayanga Galappaththige, Matthias Rottmann|<https://arxiv.org/pdf/2508.02443v2>|æå‡ºäº†ä¸€ç§åä¸ºPRIMUçš„æ¡†æ¶ï¼Œé€šè¿‡æ„å»ºè¯¯å·®å’Œè¦†ç›–ç‡çš„åŸºå…ƒçº§è¡¨ç¤ºï¼Œå®ç°äº†é«˜æ–¯æ•£ç‚¹ç»˜åˆ¶ä¸­çš„ä¸ç¡®å®šæ€§ä¼°è®¡...|


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|EGGS: Exchangeable 2D/3D Gaussian Splatting for Geometry-Appearance Balanced Novel View Synthesis|EGGSï¼šç”¨äºå‡ ä½•å¤–è§‚å¹³è¡¡çš„æ–°è§†è§’åˆæˆå¯äº¤æ¢2D/3Dé«˜æ–¯æ•£ç‚¹æŠ€æœ¯|Yancheng Zhang, Guangyu Sun, Chen Chen|<https://arxiv.org/pdf/2512.02932v1>|æå‡ºäº†ä¸€ç§ç»“åˆ2Då’Œ3Dé«˜æ–¯åˆ†å¸ƒçš„EGGSæ–¹æ³•ï¼Œå¹³è¡¡äº†è§†è§‰æ•ˆæœä¸å‡ ä½•ç²¾åº¦ï¼Œæå‡äº†æ–°è§†è§’åˆæˆçš„è´¨é‡ä¸æ•ˆ...|
|ğŸ†• å‘å¸ƒ|Content-Aware Texturing for Gaussian Splatting|é«˜æ–¯æ•£ç‚¹ç»˜åˆ¶ä¸­çš„å†…å®¹æ„ŸçŸ¥çº¹ç†æ˜ å°„|Panagiotis Papantonakis, Georgios Kopanas, Fredo Durand, George Drettakis|<https://arxiv.org/pdf/2512.02621v1>|æå‡ºåˆ©ç”¨çº¹ç†æ˜ å°„ä¼˜åŒ–é«˜æ–¯æ•£ç‚¹æ¸²æŸ“ï¼Œé€šè¿‡è‡ªé€‚åº”è°ƒæ•´çº¹ç†åˆ†è¾¨ç‡ï¼Œæå‡ç»†èŠ‚è¡¨ç°åŒæ—¶å‡å°‘å‚æ•°æ•°é‡ã€‚|


### è§†è§‰å®šä½ä¸æ˜ å°„ (Visual Localization & Mapping)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|From Panel to Pixel: Zoom-In Vision-Language Pretraining from Biomedical Scientific Literature|ä»é¢æ¿åˆ°åƒç´ ï¼šåŸºäºç”Ÿç‰©åŒ»å­¦ç§‘å­¦æ–‡çŒ®çš„ç»†ç²’åº¦è§†è§‰è¯­è¨€é¢„è®­ç»ƒ|Kun Yuan, Min Woo Sun, Zhen Chen, Alejandro Lozano, Xiangteng He, Shi Li, Nassir Navab, Xiaoxiao Sun .etc.|<https://arxiv.org/pdf/2512.02566v1>|æå‡ºPanel2Patchæ–¹æ³•ï¼Œé€šè¿‡æŒ–æ˜ç”Ÿç‰©åŒ»å­¦æ–‡çŒ®ä¸­çš„å±‚æ¬¡ç»“æ„ï¼Œå®ç°ç»†ç²’åº¦è§†è§‰è¯­è¨€é¢„è®­ç»ƒï¼Œæå‡æ¨¡å‹...|


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### è§†é¢‘ç›®æ ‡è·Ÿè¸ª (Video Object Tracking)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Ov3R: Open-Vocabulary Semantic 3D Reconstruction from RGB Videos|ã€ŠOv3Rï¼šä»RGBè§†é¢‘ä¸­è¿›è¡Œå¼€æ”¾è¯æ±‡è¯­ä¹‰ä¸‰ç»´é‡å»ºã€‹|Ziren Gong, Xiaohan Li, Fabio Tosi, Jiawei Han, Stefano Mattoccia, Jianfei Cai, Matteo Poggi|<https://arxiv.org/pdf/2507.22052v2>|æå‡ºOv3Ræ¡†æ¶ï¼ŒèåˆCLIPè¯­ä¹‰ä¸3Dé‡å»ºï¼Œå®ç°é«˜ç²¾åº¦è¯­ä¹‰3Dé‡æ„ã€‚|
|ğŸ†• å‘å¸ƒ|ReVSeg: Incentivizing the Reasoning Chain for Video Segmentation with Reinforcement Learning|è§†é¢‘åˆ†å‰²ä¸­æ¿€åŠ±æ¨ç†é“¾çš„ReVSegï¼šåŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•|Yifan Li, Yingda Yin, Lingting Zhu, Weikai Chen, Shengju Qian, Xin Wang, Yanwei Fu|<https://arxiv.org/pdf/2512.02835v1>|[ä»£ç ](https://clementine24.github.io/ReVSeg); æå‡ºæ˜¾å¼åˆ†è§£çš„è§†é¢‘å¯¹è±¡åˆ†å‰²æ–¹æ³•ReVSegï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å¤šæ­¥éª¤æ¨ç†é“¾ï¼Œå®ç°æ›´ç²¾å‡†å’Œå¯è§£é‡Šçš„åˆ†å‰²æ•ˆ...|
|ğŸ†• å‘å¸ƒ|TrackNetV5: Residual-Driven Spatio-Temporal Refinement and Motion Direction Decoupling for Fast Object Tracking|TrackNetV5ï¼šåŸºäºæ®‹å·®é©±åŠ¨çš„æ—¶ç©ºç»†åŒ–ä¸è¿åŠ¨æ–¹å‘è§£è€¦çš„å¿«é€Ÿç›®æ ‡è·Ÿè¸ª|Tang Haonan, Chen Yanjun, Jiang Lezhi|<https://arxiv.org/pdf/2512.02789v1>|TrackNetV5é€šè¿‡å¼•å…¥è¿åŠ¨æ–¹å‘è§£è€¦æ¨¡å—å’Œæ®‹å·®é©±åŠ¨çš„æ—¶ç©ºç»†åŒ–å¤´éƒ¨ï¼Œæœ‰æ•ˆè§£å†³äº†é®æŒ¡é—®é¢˜å¹¶æé«˜äº†è·Ÿè¸ª...|


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Action Anticipation at a Glimpse: To What Extent Can Multimodal Cues Replace Video?|ä¸€ç¥ä¸­çš„è¡Œä¸ºé¢„æµ‹ï¼šå¤šæ¨¡æ€çº¿ç´¢èƒ½åœ¨å¤šå¤§ç¨‹åº¦ä¸Šæ›¿ä»£è§†é¢‘ï¼Ÿ|Manuel Benavent-Lledo, Konstantinos Bacharidis, Victoria Manousaki, Konstantinos Papoutsakis, Antonis Argyros, Jose Garcia-Rodriguez|<https://arxiv.org/pdf/2512.02846v1>|æå‡ºäº†ä¸€ç§åŸºäºå•å¸§å›¾åƒå’Œæ·±åº¦çº¿ç´¢çš„å¤šæ¨¡æ€åŠ¨ä½œé¢„æµ‹æ–¹æ³•AAGï¼Œå®ç°äº†ä¸è§†é¢‘èšåˆæ–¹æ³•ç›¸å½“çš„æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|HUD: Hierarchical Uncertainty-Aware Disambiguation Network for Composed Video Retrieval|HUDï¼šåˆ†å±‚ä¸ç¡®å®šæ€§æ„ŸçŸ¥æ¶ˆæ­§ç½‘ç»œç”¨äºç»„åˆè§†é¢‘æ£€ç´¢|Zhiwei Chen, Yupeng Hu, Zixu Li, Zhiheng Fu, Haokun Wen, Weili Guan|<https://arxiv.org/pdf/2512.02792v1>|[ä»£ç ](https://zivchen-ty.github.io/HUD.github.io); æå‡ºäº†ä¸€ç§é’ˆå¯¹ç»„åˆè§†é¢‘æ£€ç´¢çš„HUDæ¡†æ¶ï¼Œé€šè¿‡åˆ©ç”¨è§†é¢‘å’Œæ–‡æœ¬ä¿¡æ¯å¯†åº¦çš„å·®å¼‚æ¥å¢å¼ºå¤šæ¨¡æ€æŸ¥è¯¢ç†è§£ï¼Œæœ‰æ•ˆè§£...|
|ğŸ†• å‘å¸ƒ|Rethinking Surgical Smoke: A Smoke-Type-Aware Laparoscopic Video Desmoking Method and Dataset|é‡æ–°æ€è€ƒæ‰‹æœ¯çƒŸé›¾ï¼šä¸€ç§çƒŸé›¾ç±»å‹æ„ŸçŸ¥çš„è…¹è…”é•œè§†é¢‘å»çƒŸé›¾æ–¹æ³•ä¸æ•°æ®é›†|Qifan Liang, Junlin Li, Zhen Han, Xihao Wang, Zhongyuan Wang, Bin Mei|<https://arxiv.org/pdf/2512.02780v1>|æå‡ºäº†ä¸€ç§é’ˆå¯¹ä¸åŒç±»å‹çƒŸé›¾çš„è…¹è…”é•œè§†é¢‘å»çƒŸé›¾ç½‘ç»œï¼Œé€šè¿‡è¯†åˆ«çƒŸé›¾ç±»å‹æ˜¾è‘—æå‡äº†å»çƒŸé›¾æ•ˆæœå’Œæ‰‹æœ¯ä»»åŠ¡æ³›åŒ–...|


### æ—¶åºå»ºæ¨¡ä¸é¢„æµ‹ (Temporal Modeling & Prediction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SAM2Grasp: Resolve Multi-modal Grasping via Prompt-conditioned Temporal Action Prediction|SAM2Graspï¼šé€šè¿‡æç¤ºæ¡ä»¶æ—¶é—´åŠ¨ä½œé¢„æµ‹è§£å†³å¤šæ¨¡æ€æŠ“å–é—®é¢˜|Shengkai Wu, Jinrong Yang, Wenqiu Luo, Linfeng Gao, Chaohui Shang, Meiyu Zhi, Mingshan Sun, Fangping Yang .etc.|<https://arxiv.org/pdf/2512.02609v1>|è§£å†³äº†æœºå™¨äººæŠ“å–ä¸­çš„å¤šæ¨¡æ€é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæç¤ºæ¡ä»¶çš„åŠ¨ä½œé¢„æµ‹æ¡†æ¶ SAM2Graspï¼Œå®ç°ç²¾ç¡®æŠ“...|


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### æ¨ç†ä¼˜åŒ– (Inference Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MindGPT-4ov: An Enhanced MLLM via a Multi-Stage Post-Training Paradigm|MindGPT-4ovï¼šé€šè¿‡å¤šé˜¶æ®µåè®­ç»ƒèŒƒå¼å¢å¼ºçš„æ¯«å‡æ¨¡å‹|Wei Chen, Chaoqun Du, Feng Gu, Wei He, Qizhen Li, Zide Liu, Xuhao Pan, Chang Ren .etc.|<https://arxiv.org/pdf/2512.02895v2>|MindGPT-4ové€šè¿‡å¤šé˜¶æ®µåè®­ç»ƒèŒƒå¼ï¼Œæå‡äº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|SurfFill: Completion of LiDAR Point Clouds via Gaussian Surfel Splatting|é€šè¿‡é«˜æ–¯æ›²é¢ç‰‡ç»˜åˆ¶å®ŒæˆLiDARç‚¹äº‘çš„SurfFillæ–¹æ³•|Svenja Strobel, Matthias Innmann, Bernhard Egger, Marc Stamminger, Linus Franke|<https://arxiv.org/pdf/2512.03010v1>|æå‡ºäº†ä¸€ç§ç»“åˆLiDARä¸ç›¸æœºæ•è·ä¼˜åŠ¿çš„SurfFillæ–¹æ³•ï¼Œé€šè¿‡Gaussian surfelä¼˜åŒ–...|


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Beyond Top Activations: Efficient and Reliable Crowdsourced Evaluation of Automated Interpretability|è¶…è¶Šé¡¶çº§æ¿€æ´»ï¼šé«˜æ•ˆå¯é çš„äººç¾¤æºè‡ªåŠ¨è§£é‡Šæ€§è¯„ä¼°|Tuomas Oikarinen, Ge Yan, Akshay Kulkarni, Tsui-Wei Weng|<https://arxiv.org/pdf/2506.07985v2>|æå‡ºé«˜æ•ˆå¯é çš„æ–¹æ³•ï¼Œé€šè¿‡æ¨¡å‹æŒ‡å¯¼çš„é‡è¦æ€§æŠ½æ ·å’Œè´å¶æ–¯è¯„åˆ†èšåˆï¼Œé™ä½è‡ªåŠ¨åŒ–è§£é‡Šæ€§è¯„ä¼°æˆæœ¬40å€ã€‚|
|ğŸ†• å‘å¸ƒ|Does Head Pose Correction Improve Biometric Facial Recognition?|å¤´éƒ¨å§¿æ€æ ¡æ­£æ˜¯å¦æé«˜äº†ç”Ÿç‰©è¯†åˆ«é¢éƒ¨è¯†åˆ«æ•ˆæœï¼Ÿ|Justin Norman, Hany Farid|<https://arxiv.org/pdf/2512.03199v1>|é€šè¿‡é€‰æ‹©æ€§åº”ç”¨å›¾åƒä¿®å¤æŠ€æœ¯ï¼Œæœ‰æ•ˆæå‡äº†éæ­£é¢äººè„¸è¯†åˆ«çš„å‡†ç¡®åº¦ã€‚|
|ğŸ“ æ›´æ–°|OpenLVLM-MIA: A Controlled Benchmark Revealing the Limits of Membership Inference Attacks on Large Vision-Language Models|å¼€æ”¾LVLM-MIAï¼šä¸€ä¸ªæ­ç¤ºå¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹æˆå‘˜æ¨æ–­æ”»å‡»æé™çš„å¯æ§åŸºå‡†|Ryoto Miyamoto, Xin Fan, Fuyuko Kido, Tsuneo Matsumoto, Hayato Yamana|<https://arxiv.org/pdf/2510.16295v2>|æ­ç¤ºäº†å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹æˆå‘˜æ¨æ–­æ”»å‡»çš„å±€é™æ€§ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªå¹³è¡¡æ ·æœ¬åˆ†å¸ƒçš„ controlled ben...|
|ğŸ“ æ›´æ–°|MasHeNe: A Benchmark for Head and Neck CT Mass Segmentation using Window-Enhanced Mamba with Frequency-Domain Integration|MasHeNeï¼šåŸºäºçª—å£å¢å¼ºMambaä¸é¢‘åŸŸé›†æˆçš„å¤´é¢ˆCTè´¨é‡åˆ†å‰²åŸºå‡†|Thao Thi Phuong Dao, Tan-Cong Nguyen, Nguyen Chi Thanh, Truong Hoang Viet, Trong-Le Do, Mai-Khiem Tran, Minh-Khoi Pham, Trung-Nghia Le .etc.|<https://arxiv.org/pdf/2512.01563v2>|[ä»£ç ](https://github.com/drthaodao3101/MasHeNe.git.); æå‡ºMasHeNeæ•°æ®é›†å¹¶å¼•å…¥WEMFæ¨¡å‹ï¼Œæå‡å¤´é¢ˆéƒ¨ä½ç—…å˜çš„CTå›¾åƒåˆ†å‰²æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|AVGGT: Rethinking Global Attention for Accelerating VGGT|AVGGTï¼šé‡æ–°æ€è€ƒå…¨å±€æ³¨æ„åŠ›ä»¥åŠ é€ŸVGGT|Xianbing Sun, Zhikai Zhu, Zhengyu Lou, Bo Yang, Jinyang Tang, Liqing Zhang, He Wang, Jianfu Zhang|<https://arxiv.org/pdf/2512.02541v1>|æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„ä¸¤æ­¥åŠ é€Ÿæ–¹æ¡ˆï¼Œé€šè¿‡è½¬æ¢å…¨å±€æ³¨æ„åŠ›å±‚å’Œå­é‡‡æ ·æŠ€æœ¯ï¼Œæ˜¾è‘—æå‡äº†å¤šè§†å›¾3Dæ¨¡å‹çš„æ¨ç†é€Ÿ...|


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Multi-Agent Reinforcement Learning and Real-Time Decision-Making in Robotic Soccer for Virtual Environments|å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ åœ¨è™šæ‹Ÿç¯å¢ƒä¸‹çš„æœºå™¨äººè¶³çƒå®æ—¶å†³ç­–åº”ç”¨|Aya Taourirte, Md Sohag Mia|<https://arxiv.org/pdf/2512.03166v1>|æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡åˆ†å±‚å†³ç­–å’Œå‡å€¼åœºç†è®ºæå‡äº†æœºå™¨äººè¶³çƒä¸­çš„å®æ—¶å†³ç­–å’Œå›¢é˜Ÿåä½œ...|
|ğŸ†• å‘å¸ƒ|Hierarchical Process Reward Models are Symbolic Vision Learners|åˆ†å±‚è¿‡ç¨‹å¥–åŠ±æ¨¡å‹æ˜¯ç¬¦å·è§†è§‰å­¦ä¹ è€…|Shan Zhang, Aotian Chen, Kai Zou, Jindong Gu, Yuan Xue, Anton van den Hengel|<https://arxiv.org/pdf/2512.03126v1>|æå‡ºäº†ä¸€ç§ç¬¦å·è§†è§‰å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡å±‚çº§è¿‡ç¨‹å¥–åŠ±æ¨¡å‹å®ç°å›¾è§£çš„å‡ ä½•è§£æå’Œé‡å»ºï¼Œæå‡äº†è®¡ç®—æœºè§†è§‰çš„æ¨ç†å’Œè§£...|
|ğŸ“ æ›´æ–°|APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation|APTxç¥ç»å…ƒï¼šä¸€ç§é›†æ¿€æ´»ä¸è®¡ç®—äºä¸€ä½“çš„ç»Ÿä¸€å¯è®­ç»ƒç¥ç»å…ƒæ¶æ„|Ravin Kumar|<https://arxiv.org/pdf/2507.14270v5>|[ä»£ç ](https://github.com/mr-ravin/aptx_neuron.); æå‡ºäº†ä¸€ç§ç»Ÿä¸€å¯è®­ç»ƒçš„ç¥ç»å…ƒæ¶æ„APTx Neuronï¼Œæ•´åˆäº†æ¿€æ´»å’Œè®¡ç®—åŠŸèƒ½ï¼Œæå‡äº†è¡¨è¾¾åŠ›å’Œè®­ç»ƒæ•ˆç‡...|
|ğŸ“ æ›´æ–°|VeLU: Variance-enhanced Learning Unit for Deep Neural Networks|VeLUï¼šç”¨äºæ·±åº¦ç¥ç»ç½‘ç»œçš„æ–¹å·®å¢å¼ºå­¦ä¹ å•å…ƒ|Ashkan Shakarami, Yousef Yeganeh, Azade Farshad, Lorenzo NicolÃ¨, Stefano Ghidoni, Nassir Navab|<https://arxiv.org/pdf/2504.15051v2>|æå‡ºVeLUæ¿€æ´»å‡½æ•°ï¼Œé€šè¿‡è‡ªé€‚åº”è°ƒæ•´å“åº”åŸºäºå±€éƒ¨æ¿€æ´»æ–¹å·®ï¼Œæå‡äº†è®­ç»ƒç¨³å®šæ€§å’Œæ¨¡å‹æ€§èƒ½ã€‚|
|ğŸ†• å‘å¸ƒ|Emergent Bayesian Behaviour and Optimal Cue Combination in LLMs|æ¶Œç°çš„è´å¶æ–¯è¡Œä¸ºä¸å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„æœ€ä¼˜çº¿ç´¢èåˆ|Julian Ma, Jun Wang, Zafeirios Fountas|<https://arxiv.org/pdf/2512.02719v1>|å‘ç°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æœªæ˜ç¡®è®­ç»ƒä¸‹èƒ½è¿‘ä¼¼é‡‡ç”¨è´å¶æ–¯ç­–ç•¥è¿›è¡Œå¤šæ¨¡æ€ä¿¡æ¯èåˆï¼Œæå‡ºBayesBenchåŸºå‡†è¯„...|


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Can Vision-Language Models Count? A Synthetic Benchmark and Analysis of Attention-Based Interventions|è§†è§‰è¯­è¨€æ¨¡å‹èƒ½è®¡æ•°å—ï¼Ÿä¸€ä¸ªåˆæˆåŸºå‡†åŠåŸºäºæ³¨æ„åŠ›å¹²é¢„çš„åˆ†æ|Saurav Sengupta, Nazanin Moradinasab, Jiebei Liu, Donald E. Brown|<https://arxiv.org/pdf/2511.17722v2>|æå‡ºåˆæˆæ•°æ®é›†å’Œæ³¨æ„åŠ›å¹²é¢„æ–¹æ³•ï¼Œåˆ†æè§†è§‰è¯­è¨€æ¨¡å‹è®¡æ•°æ€§èƒ½åŠå…¶ä¼˜åŒ–è·¯å¾„ã€‚|
|ğŸ†• å‘å¸ƒ|VLM-Pruner: Buffering for Spatial Sparsity in an Efficient VLM Centrifugal Token Pruning Paradigm|VLM-Prunerï¼šåœ¨é«˜æ•ˆVLMç¦»å¿ƒå¼ä»¤ç‰Œå‰ªæèŒƒå¼ä¸­çš„ç©ºé—´ç¨€ç–ç¼“å†²ç­–ç•¥|Zhenkai Wu, Xiaowen Ma, Zhenliang Ni, Dengming Zhang, Han Shu, Xin Jiang, Xinghao Chen|<https://arxiv.org/pdf/2512.02700v1>|æå‡ºVLM-Prunerç®—æ³•ï¼Œå¹³è¡¡è§†è§‰tokençš„å†—ä½™ä¸ç©ºé—´ç¨€ç–æ€§ï¼Œæå‡ç§»åŠ¨è®¾å¤‡ä¸Šçš„å›¾åƒç†è§£æ•ˆç‡ã€‚|


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### å¯¹æŠ—é²æ£’æ€§ (Adversarial Robustness)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Defense That Attacks: How Robust Models Become Better Attackers|é˜²å¾¡å³æ”»å‡»ï¼šå¦‚ä½•ä½¿é²æ£’æ¨¡å‹æˆä¸ºæ›´å¼ºçš„æ”»å‡»è€…|Mohamed Awad, Mahmoud Akrm, Walid Gomaa|<https://arxiv.org/pdf/2512.02830v2>|å‘ç°å¯¹æŠ—è®­ç»ƒæ„å¤–å¢å¼ºäº†æ”»å‡»æ ·æœ¬çš„è¿ç§»æ€§ï¼Œæå‡ºåº”å…¨é¢è¯„ä¼°æ¨¡å‹çš„é˜²å¾¡åŠ›å’Œæ”»å‡»æ ·æœ¬ç”Ÿæˆèƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|InEx: Hallucination Mitigation via Introspection and Cross-Modal Multi-Agent Collaboration|InExï¼šé€šè¿‡å†…çœå’Œè·¨æ¨¡æ€å¤šæ™ºèƒ½ä½“åä½œå‡è½»å¹»è§‰ç°è±¡|Zhongyu Yang, Yingfang Yuan, Xuanming Jiang, Baoyi An, Wei Pang|<https://arxiv.org/pdf/2512.02981v1>|æå‡ºInExæ¡†æ¶ï¼Œé€šè¿‡å†…çœæ¨ç†å’Œè·¨æ¨¡æ€å¤šæ™ºèƒ½ä½“åä½œï¼Œæœ‰æ•ˆå‡å°‘å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è™šæ„ç°è±¡ã€‚|


### ä¸ç¡®å®šæ€§é‡åŒ– (Uncertainty Quantification)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Drainage: A Unifying Framework for Addressing Class Uncertainty|æ’æ°´ï¼šä¸€ä¸ªç»Ÿä¸€æ¡†æ¶åº”å¯¹ç±»åˆ«ä¸ç¡®å®šæ€§é—®é¢˜|Yasser Taha, GrÃ©goire Montavon, Nils KÃ¶rber|<https://arxiv.org/pdf/2512.03182v1>|æå‡ºäº†ä¸€ç§â€œæ’æ°´èŠ‚ç‚¹â€æ¡†æ¶ï¼Œé€šè¿‡é‡æ–°åˆ†é…æ¦‚ç‡è´¨é‡åº”å¯¹æ ‡ç­¾å™ªå£°å’Œæ ·æœ¬ä¸ç¡®å®šæ€§ï¼Œæå‡æ¨¡å‹é²æ£’æ€§ã€‚|


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### é›¶/å°‘æ ·æœ¬æ³›åŒ– (Zero/Few-shot Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|LLM-Guided Material Inference for 3D Point Clouds|åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹å¼•å¯¼çš„ææ–™æ¨æ–­æ–¹æ³•ç”¨äºä¸‰ç»´ç‚¹äº‘|Nafiseh Izadyar, Teseo Schneider|<https://arxiv.org/pdf/2512.03237v1>|æå‡ºäº†ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ä¸¤é˜¶æ®µæ–¹æ³•ï¼Œä»3Dç‚¹äº‘ä¸­æ¨æ–­ææ–™ç»„æˆï¼Œæ— éœ€ç‰¹å®šä»»åŠ¡è®­ç»ƒã€‚|


### å°æ ·æœ¬å­¦ä¹  (Few-shot Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|2-Shots in the Dark: Low-Light Denoising with Minimal Data Acquisition|ã€Šåœ¨é»‘æš—ä¸­çš„ä¸¤æªï¼šåŸºäºæœ€å°æ•°æ®é‡‡é›†çš„ä½å…‰ç…§å»å™ªã€‹|Liying Lu, RaphaÃ«l Achddou, Sabine SÃ¼sstrunk|<https://arxiv.org/pdf/2512.03245v1>|æå‡ºäº†ä¸€ç§ä»…éœ€ä¸€å¼ å™ªç‚¹å›¾åƒå’Œä¸€å¼ æš—å¸§çš„å™ªå£°åˆæˆæ–¹æ³•ï¼Œå®ç°äº†ä½å…‰ç…§æ¡ä»¶ä¸‹å›¾åƒçš„é«˜è´¨é‡å»å™ªã€‚|
|ğŸ†• å‘å¸ƒ|Object Counting with GPT-4o and GPT-5: A Comparative Study|ä½¿ç”¨GPT-4oå’ŒGPT-5è¿›è¡Œç›®æ ‡è®¡æ•°ï¼šä¸€é¡¹æ¯”è¾ƒç ”ç©¶|Richard FÃ¼zessÃ©ry, Kaziwa Saleh, SÃ¡ndor SzÃ©nÃ¡si, ZoltÃ¡n VÃ¡mossy|<https://arxiv.org/pdf/2512.03233v1>|åˆ©ç”¨GPT-4oå’ŒGPT-5çš„å¤šæ¨¡æ€èƒ½åŠ›ï¼Œå®ç°äº†æ— éœ€ç›‘ç£çš„é›¶æ ·æœ¬ç‰©ä½“è®¡æ•°ï¼Œæ€§èƒ½åª²ç¾ç°æœ‰æœ€ä½³æ–¹æ³•ã€‚|
|ğŸ†• å‘å¸ƒ|DGGT: Feedforward 4D Reconstruction of Dynamic Driving Scenes using Unposed Images|åŠ¨æ€é©¾é©¶åœºæ™¯çš„åŸºäºæ— å®šä½å›¾åƒçš„å‰é¦ˆå››ç»´é‡å»ºï¼šDGGT|Xiaoxue Chen, Ziyi Xiong, Yuantao Chen, Gen Li, Nan Wang, Hongcheng Luo, Long Chen, Haiyang Sun .etc.|<https://arxiv.org/pdf/2512.03004v1>|æå‡ºäº†ä¸€ç§æ— éœ€ç›¸æœºæ ¡å‡†çš„åŠ¨æ€é©¾é©¶åœºæ™¯4Dé‡å»ºæ¡†æ¶ï¼Œå®ç°äº†å¿«é€Ÿã€å¯æ‰©å±•çš„é‡å»ºæ•ˆæœã€‚|


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MICCAI STSR 2025 Challenge: Semi-Supervised Teeth and Pulp Segmentation and CBCT-IOS Registration|MICCAI STSR 2025æŒ‘æˆ˜ï¼šåŠç›‘ç£ç‰™é½¿å’Œç‰™é«“åˆ†å‰²åŠCBCT-IOSé…å‡†|Yaqi Wang, Zhi Li, Chengyu Wu, Jun Liu, Yifan Zhang, Jialuo Chen, Jiaxue Ni, Qian Luo .etc.|<https://arxiv.org/pdf/2512.02867v1>|[ä»£ç ](https://github.com/ricoleehduu/STS-Challenge-2025); ç»„ç»‡STSR 2025æŒ‘æˆ˜ï¼Œåˆ©ç”¨åŠç›‘ç£å­¦ä¹ å®ç°CBCTå’ŒIOSçš„ç‰™é½¿ä¸ç‰™é«“åˆ†å‰²åŠé…å‡†ï¼Œæå‡æ ‡æ³¨æ•°æ®ç¨€...|
|ğŸ“ æ›´æ–°|Zero-shot self-supervised learning of single breath-hold magnetic resonance cholangiopancreatography (MRCP) reconstruction|é›¶æ ·æœ¬è‡ªç›‘ç£å­¦ä¹ å•æ¬¡å±æ°”ç£å…±æŒ¯èƒ†èƒ°ç®¡æˆåƒï¼ˆMRCPï¼‰é‡å»º|Jinho Kim, Marcel Dominik Nickel, Florian Knoll|<https://arxiv.org/pdf/2508.09200v2>|æå‡ºäº†ä¸€ç§é›¶æ ·æœ¬è‡ªç›‘ç£å­¦ä¹ æ¡†æ¶ï¼Œæœ‰æ•ˆç¼©çŸ­äº†ç£å…±æŒ¯èƒ†ç®¡æˆåƒçš„å±æ°”æ—¶é—´å¹¶æé«˜äº†å›¾åƒè´¨é‡ã€‚|
|ğŸ†• å‘å¸ƒ|Unsupervised Structural Scene Decomposition via Foreground-Aware Slot Attention with Pseudo-Mask Guidance|æ— ç›‘ç£ç»“æ„åœºæ™¯åˆ†è§£ï¼šé€šè¿‡å‰æ™¯æ„ŸçŸ¥çš„æ§½æ³¨æ„åŠ›ä¸ä¼ªæ©ç å¼•å¯¼|Huankun Sheng, Ming Li, Yixiang Wei, Yeying Fan, Yu-Hui Wen, Tieliang Gong, Yong-Jin Liu|<https://arxiv.org/pdf/2512.02685v1>|æå‡ºäº†ä¸€ç§å‰æ™¯æ„ŸçŸ¥çš„æ§½æ³¨æ„åŠ›æ¡†æ¶ï¼Œé€šè¿‡åˆ†ç¦»å‰æ™¯å’ŒèƒŒæ™¯æ˜¾è‘—æå‡äº†æ— ç›‘ç£åœºæ™¯åˆ†è§£çš„å‡†ç¡®æ€§ã€‚|
|ğŸ“ æ›´æ–°|MRI Super-Resolution with Deep Learning: A Comprehensive Survey|MRIè¶…åˆ†è¾¨ç‡é‡å»ºä¸­çš„æ·±åº¦å­¦ä¹ ï¼šå…¨é¢ç»¼è¿°|Mohammad Khateri, Serge Vasylechko, Morteza Ghahremani, Liam Timms, Deniz Kocanaogullari, Simon K. Warfield, Camilo Jaimes, Davood Karimi .etc.|<https://arxiv.org/pdf/2511.16854v3>|[ä»£ç ](https://github.com/mkhateri/Awesome-MRI-Super-Resolution.); ç³»ç»Ÿç»¼è¿°äº†æ·±åº¦å­¦ä¹ åœ¨MRIè¶…åˆ†è¾¨ç‡ä¸­çš„åº”ç”¨ï¼Œæå‡ºäº†åˆ†ç±»æ¡†æ¶å’Œå¼€æºèµ„æºï¼ŒåŠ©åŠ›æå‡æˆåƒè´¨é‡å’Œæ•ˆç‡ã€‚|


## å…·èº«æ™ºèƒ½ä¸äº¤äº’è§†è§‰ (Embodied Intelligence & Interactive Vision)


### è§†è§‰æ“ä½œä¸æ§åˆ¶ (Visual Manipulation & Control)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Guardian: Detecting Robotic Planning and Execution Errors with Vision-Language Models|å®ˆå«è€…ï¼šåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹æ£€æµ‹æœºå™¨äººè§„åˆ’å’Œæ‰§è¡Œé”™è¯¯|Paul Pacaud, Ricardo Garcia, Shizhe Chen, Cordelia Schmid|<https://arxiv.org/pdf/2512.01946v2>|æå‡ºè‡ªåŠ¨ç”Ÿæˆæœºå™¨äººå¤±è´¥æ•°æ®æ–¹æ³•ï¼Œè®­ç»ƒGuardianæ¨¡å‹æå‡æ•…éšœæ£€æµ‹ä¸å¤„ç†èƒ½åŠ›ã€‚|


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Diagnose, Correct, and Learn from Manipulation Failures via Visual Symbols|é€šè¿‡è§†è§‰ç¬¦å·è¯Šæ–­ã€çº æ­£å’Œå­¦ä¹ æ“ä½œå¤±è´¥|Xianchao Zeng, Xinyu Zhou, Youcheng Li, Jiayou Shi, Tianle Li, Liangming Chen, Lei Ren, Yong-Lu Li|<https://arxiv.org/pdf/2512.02787v2>|[ä»£ç ](https://x1nyuzhou.github.io/vifailback.github.io); æå‡ºViFailbackæ¡†æ¶ï¼Œé€šè¿‡è§†è§‰ç¬¦å·è¯Šæ–­å¹¶æŒ‡å¯¼ä¿®æ­£æœºå™¨äººæ“ä½œå¤±è´¥ï¼Œå®ç°çœŸå®ä¸–ç•Œåº”ç”¨æ€§èƒ½æå‡ã€‚|
|ğŸ†• å‘å¸ƒ|SpatialReasoner: Active Perception for Large-Scale 3D Scene Understanding|ç©ºé—´æ¨ç†å™¨ï¼šå¤§è§„æ¨¡ä¸‰ç»´åœºæ™¯ç†è§£ä¸­çš„ä¸»åŠ¨æ„ŸçŸ¥|Hongpei Zheng, Shijie Li, Yanran Li, Hujun Yin|<https://arxiv.org/pdf/2512.03284v1>|æå‡ºäº†SpatialReasoneræ¡†æ¶ï¼Œé€šè¿‡ä¸»åŠ¨æ¢ç´¢å’Œç©ºé—´æ¨ç†ï¼Œåœ¨å¤§å‹3Dåœºæ™¯ç†è§£ä¸­å®ç°é¢†å…ˆæ€§èƒ½ã€‚|
|ğŸ“ æ›´æ–°|AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention|AVA-VLAï¼šä½¿ç”¨ä¸»åŠ¨è§†è§‰æ³¨æ„åŠ›æ”¹è¿›è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹|Lei Xiao, Jifeng Li, Juntao Gao, Feiyang Ye, Yan Jin, Jingjing Qian, Jing Zhang, Yong Wu .etc.|<https://arxiv.org/pdf/2511.18960v2>|æå‡ºäº†ä¸€ç§åŸºäºå†å²ä¿¡å¿µçŠ¶æ€çš„Active Visual Attentionæ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†VLAæ¨¡å‹...|
|ğŸ“ æ›´æ–°|Bias Beyond Demographics: Probing Decision Boundaries in Black-Box LVLMs via Counterfactual VQA|ã€Šè¶…è¶Šäººå£ç»Ÿè®¡å­¦çš„åè§ï¼šé€šè¿‡åäº‹å®è§†è§‰é—®ç­”æ¢æµ‹é»‘ç›’å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹çš„å†³ç­–è¾¹ç•Œã€‹|Zaiying Zhao, Toshihiko Yamasaki|<https://arxiv.org/pdf/2508.03079v2>|æå‡ºäº†ä¸€ç§æ–°çš„å…¬å¹³æ€§è¯„ä¼°æ–¹æ³•ï¼Œé€šè¿‡å¯¹æ¯”éäººå£ç»Ÿè®¡å±æ€§å¯¹å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹å†³ç­–è¾¹ç•Œçš„å½±å“ï¼Œæ­ç¤ºäº†ç¯å¢ƒå’Œç¤¾...|


### å¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿ (Multimodal Dialogue Systems)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Contextual Image Attack: How Visual Context Exposes Multimodal Safety Vulnerabilities|å›¾åƒä¸Šä¸‹æ–‡æ”»å‡»ï¼šè§†è§‰ä¸Šä¸‹æ–‡å¦‚ä½•æ­ç¤ºå¤šæ¨¡æ€å®‰å…¨æ¼æ´|Yuan Xiong, Ziqi Miao, Lijun Li, Chen Qian, Jie Li, Jing Shao|<https://arxiv.org/pdf/2512.02973v1>|æå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒæ”»å‡»æ–¹æ³•ï¼Œé€šè¿‡åœ¨è§†è§‰ä¸Šä¸‹æ–‡ä¸­åµŒå…¥æœ‰å®³æŸ¥è¯¢ï¼Œæœ‰æ•ˆçªç ´äº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„å®‰å…¨é™åˆ¶ã€‚|
|ğŸ†• å‘å¸ƒ|UAUTrack: Towards Unified Multimodal Anti-UAV Visual Tracking|UAUTrackï¼šé¢å‘ç»Ÿä¸€çš„å¤šæ¨¡æ€åæ— äººæœºè§†è§‰è·Ÿè¸ª|Qionglin Ren, Dawei Zhang, Chunxu Tian, Dan Zhang|<https://arxiv.org/pdf/2512.02668v1>|æå‡ºç»Ÿä¸€çš„å¤šæ¨¡æ€åæ— äººæœºè§†è§‰è·Ÿè¸ªæ¡†æ¶UAUTrackï¼Œèåˆå¤šç§æ¨¡æ€æ•°æ®ï¼Œæå‡è·Ÿè¸ªå‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚|


### è§†è§‰å†…å®¹æè¿° (Visual Content Description)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Multimodal LLMs See Sentiment|å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹è§‚æµ‹æƒ…æ„Ÿ|Neemias B. da Silva, John Harrison, Rodrigo Minetto, Myriam R. Delgado, Bogdan T. Nassu, Thiago H. Silva|<https://arxiv.org/pdf/2508.16873v2>|æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ¡†æ¶MLLMsentï¼Œé€šè¿‡å›¾åƒç›´æ¥åˆ†ç±»ã€è‡ªåŠ¨ç”Ÿæˆæè¿°åˆ†æåŠæè¿°å¾®è°ƒä¸‰ç§æ–¹å¼...|


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Multilingual Training-Free Remote Sensing Image Captioning|å¤šè¯­è¨€è®­ç»ƒæ— å…³çš„é¥æ„Ÿå›¾åƒå­—å¹•ç”Ÿæˆ|Carlos Rebelo, Gil Rocha, JoÃ£o Daniel Silva, Bruno Martins|<https://arxiv.org/pdf/2512.00887v2>|æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„å¤šè¯­è¨€é¥æ„Ÿå›¾åƒå­—å¹•ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡æ£€ç´¢å¢å¼ºæç¤ºï¼Œå®ç°äº†è·¨è¯­è¨€çš„å¹¿æ³›åº”ç”¨ã€‚|
|ğŸ†• å‘å¸ƒ|PyroFocus: A Deep Learning Approach to Real-Time Wildfire Detection in Multispectral Remote Sensing Imagery|â€œPyroFocusï¼šä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„å¤šå…‰è°±é¥æ„Ÿå½±åƒå®æ—¶æ£®æ—ç«ç¾æ£€æµ‹æ–¹æ³•â€|Mark Moussa, Andre Williams, Seth Roffe, Douglas Morton|<https://arxiv.org/pdf/2512.03257v1>|æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µæ·±åº¦å­¦ä¹ æ¨¡å‹PyroFocusï¼Œå®ç°äº†å®æ—¶å¤šå…‰è°±é¥æ„Ÿå½±åƒä¸­çš„é‡ç«æ£€æµ‹ä¸å¼ºåº¦ä¼°è®¡ï¼Œå¹³è¡¡...|
|ğŸ“ æ›´æ–°|From Pixels to Prose: Advancing Multi-Modal Language Models for Remote Sensing|ä»åƒç´ åˆ°æ•£æ–‡ï¼šæ¨è¿›å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹åœ¨é¥æ„Ÿé¢†åŸŸçš„åº”ç”¨|Xintian Sun, Benji Peng, Charles Zhang, Fei Jin, Qian Niu, Junyu Liu, Keyu Chen, Ming Li .etc.|<https://arxiv.org/pdf/2411.05826v2>|æ¢è®¨äº†å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹åœ¨é¥æ„Ÿé¢†åŸŸçš„åº”ç”¨ï¼Œæå‡äº†å«æ˜Ÿå›¾åƒçš„è‡ªç„¶è¯­è¨€æè¿°èƒ½åŠ›ã€‚|
|ğŸ†• å‘å¸ƒ|GeoViS: Geospatially Rewarded Visual Search for Remote Sensing Visual Grounding|åœ°ç†ç©ºé—´å¥–åŠ±è§†è§‰æœç´¢ç”¨äºé¥æ„Ÿè§†è§‰å®šä½ï¼šGeoViS|Peirong Zhang, Yidan Zhang, Luxiao Xu, Jinliang Lin, Zonghao Guo, Fengxiang Wang, Xue Yang, Kaiwen Wei .etc.|<https://arxiv.org/pdf/2512.02715v1>|æå‡ºGeoViSæ¡†æ¶ï¼Œå°†é¥æ„Ÿè§†è§‰å®šä½è½¬åŒ–ä¸ºé€æ­¥æœç´¢æ¨ç†è¿‡ç¨‹ï¼Œæå‡äº†å¯¹å¾®å°ç›®æ ‡çš„æ£€æµ‹å’Œæ•´ä½“åœºæ™¯ç†è§£èƒ½åŠ›...|


### æ™ºèƒ½äº¤é€šè§†è§‰ (Intelligent Transportation Vision)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|All You Need for Object Detection: From Pixels, Points, and Prompts to Next-Gen Fusion and Multimodal LLMs/VLMs in Autonomous Vehicles|ç‰©ä½“æ£€æµ‹æ‰€éœ€çš„ä¸€åˆ‡ï¼šä»åƒç´ ã€ç‚¹åˆ°æç¤ºï¼Œå†åˆ°è‡ªåŠ¨é©¾é©¶ä¸­çš„ä¸‹ä¸€ä»£èåˆä¸å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹/è§†è§‰è¯­è¨€æ¨¡å‹|Sayed Pedram Haeri Boroujeni, Niloufar Mehrabi, Hazim Alzorgan, Mahlagha Fazeli, Abolfazl Razi|<https://arxiv.org/pdf/2510.26641v2>|æ•´åˆå¤šæ¨¡æ€æ„ŸçŸ¥ä¸å…ˆè¿›è¯­è¨€æ¨¡å‹ï¼Œä¸ºè‡ªåŠ¨é©¾é©¶è½¦è¾†ä¸­çš„ç‰©ä½“æ£€æµ‹æä¾›å…¨é¢å‰æ²¿åˆ†æã€‚|
|ğŸ“ æ›´æ–°|OpenREAD: Reinforced Open-Ended Reasoning for End-to-End Autonomous Driving with LLM-as-Critic|å¼€æ”¾å¼æ¨ç†å¢å¼ºï¼šä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºè¯„ä»·å™¨çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿ|Songyan Zhang, Wenhui Huang, Zhan Chen, Chua Jiahao Collister, Qihang Huang, Chen Lv|<https://arxiv.org/pdf/2512.01830v2>|æå‡ºOpenREADæ¡†æ¶ï¼Œé€šè¿‡å¤§è§„æ¨¡Chain-of-Thoughtæ³¨é‡Šå’Œå¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°æ¨ç†è´¨é‡ï¼Œ...|


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Learning Multimodal Embeddings for Traffic Accident Prediction and Causal Estimation|å­¦ä¹ å¤šæ¨¡æ€åµŒå…¥ç”¨äºäº¤é€šäº‹æ•…é¢„æµ‹ä¸å› æœä¼°è®¡|Ziniu Zhang, Minxuan Duan, Haris N. Koutsopoulos, Hongyang R. Zhang|<https://arxiv.org/pdf/2512.02920v1>|æ•´åˆå«æ˜Ÿå›¾åƒä¸è·¯ç½‘æ•°æ®çš„å¤šæ¨¡æ€åµŒå…¥æ–¹æ³•ï¼Œæé«˜äº†äº¤é€šäº‹æ•…é¢„æµ‹å‡†ç¡®ç‡å¹¶æ­ç¤ºäº†å…³é”®å½±å“å› ç´ ã€‚|
|ğŸ†• å‘å¸ƒ|AttMetNet: Attention-Enhanced Deep Neural Network for Methane Plume Detection in Sentinel-2 Satellite Imagery|AttMetNetï¼šåŸºäºæ³¨æ„åŠ›å¢å¼ºçš„æ·±åº¦ç¥ç»ç½‘ç»œç”¨äºSentinel-2å«æ˜Ÿå›¾åƒä¸­çš„ç”²çƒ·ç¾½æµæ£€æµ‹|Rakib Ahsan, MD Sadik Hossain Shanto, Md Sultanul Arifin, Tanzima Hashem|<https://arxiv.org/pdf/2512.02751v1>|æå‡ºäº†ä¸€ç§é’ˆå¯¹å«æ˜Ÿå›¾åƒçš„ç”²çƒ·ç¾½çŠ¶ç‰©æ£€æµ‹æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡èåˆç”²çƒ·æ•æ„ŸæŒ‡æ•°å’Œæ³¨æ„åŠ›æœºåˆ¶ï¼Œæœ‰æ•ˆé™ä½äº†è¯¯æŠ¥...|
|ğŸ†• å‘å¸ƒ|Tissue-mask supported inter-subject whole-body image registration in the UK Biobank -- A method benchmarking study|åŸºäºç»„ç»‡æ©æ¨¡çš„è·¨ä¸ªä½“å…¨èº«å›¾åƒé…å‡†åœ¨è‹±å›½ç”Ÿç‰©é“¶è¡Œä¸­çš„ç ”ç©¶ â€”â€” ä¸€ç§æ–¹æ³•åŸºå‡†æµ‹è¯•|Yasemin Utkueri, Elin LundstrÃ¶m, HÃ¥kan AhlstrÃ¶m, Johan Ã–fverstedt, Joel Kullberg|<https://arxiv.org/pdf/2512.02702v1>|æå‡ºäº†ä¸€ç§åˆ©ç”¨æ€§åˆ«åˆ†ç±»å’Œç‰¹å®šç»„ç»‡é®ç½©å¢å¼ºçš„å…¨èº«ä½“éƒ¨å›¾åƒé…å‡†æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†é…å‡†å‡†ç¡®æ€§å’ŒåŒ»å­¦æ•°æ®åˆ†æè´¨...|


## æ–°å…´ç†è®ºä¸è·¨å­¦ç§‘æ–¹å‘ (Emerging Theory & Interdisciplinary Directions)


### ç¥ç»-ç¬¦å·è§†è§‰ (Neuro-symbolic Vision)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|A Lightweight Real-Time Low-Light Enhancement Network for Embedded Automotive Vision Systems|é¢å‘åµŒå…¥å¼è½¦è½½è§†è§‰ç³»ç»Ÿçš„è½»é‡çº§å®æ—¶ä½å…‰ç…§å¢å¼ºç½‘ç»œ|Yuhan Chen, Yicui Shi, Guofa Li, Guangrui Bai, Jinyuan Shao, Xiangfei Huang, Wenbo Chu, Keqiang Li|<https://arxiv.org/pdf/2512.02965v1>|[ä»£ç ](https://github.com/YuhanChen2024/UltraFast-LiNET); æå‡ºäº†ä¸€ç§è½»é‡çº§å®æ—¶ä½å…‰ç…§å¢å¼ºç½‘ç»œï¼Œé€šè¿‡åŠ¨æ€ç§»ä½å·ç§¯å’Œå¤šå±‚æ¢¯åº¦æ„ŸçŸ¥æŸå¤±å‡½æ•°ï¼Œåœ¨æœ‰é™èµ„æºä¸‹å®ç°äº†é«˜æ€§èƒ½...|


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Kaleidoscopic Scintillation Event Imaging|ä¸‡èŠ±ç­’å¼é—ªçƒäº‹ä»¶æˆåƒ|Alex Bocchieri, John Mamish, David Appleyard, Andreas Velten|<https://arxiv.org/pdf/2512.03216v1>|[ä»£ç ](https://github.com/bocchs/kaleidoscopic_scintillator.); æå‡ºäº†ä¸€ç§ kaleidoscopic scintillator è®¾è®¡ï¼Œå¢å¼ºå•å…‰å­ç›¸æœºå¯¹ä½äº®åº¦äº‹ä»¶çš„...|
|ğŸ†• å‘å¸ƒ|RFOP: Rethinking Fusion and Orthogonal Projection for Face-Voice Association|RFOPï¼šé‡æ–°æ€è€ƒèåˆä¸æ­£äº¤æŠ•å½±åœ¨äººè„¸-å£°éŸ³å…³è”ä¸­çš„åº”ç”¨|Abdul Hannan, Furqan Malik, Hina Jabbar, Syed Suleman Sadiq, Mubashir Noman|<https://arxiv.org/pdf/2512.02860v1>|æå‡ºäº†ä¸€ç§æ”¹è¿›çš„èåˆä¸æ­£äº¤æŠ•å½±æ–¹æ³•ï¼Œæœ‰æ•ˆèšç„¦ä¸¤ç§æ¨¡æ€ç›¸å…³è¯­ä¹‰ä¿¡æ¯ï¼Œæå‡å¤šè¯­ç¯å¢ƒä¸­äººè„¸-è¯­éŸ³å…³è”ä»»åŠ¡çš„...|
|ğŸ†• å‘å¸ƒ|PoreTrack3D: A Benchmark for Dynamic 3D Gaussian Splatting in Pore-Scale Facial Trajectory Tracking|"å­”éš™è¿½è¸ª3Dï¼šåŠ¨æ€ä¸‰ç»´é«˜æ–¯æ•£ç‚¹æŠ€æœ¯åœ¨å­”éš™å°ºåº¦é¢éƒ¨è½¨è¿¹è·Ÿè¸ªä¸­çš„åŸºå‡†æµ‹è¯•"|Dong Li, Jiahao Xiong, Yingda Huang, Le Chang|<https://arxiv.org/pdf/2512.02648v1>|[ä»£ç ](https://github.com/JHXion9/PoreTrack3D); æå‡ºäº†PoreTrack3Dï¼Œé¦–ä¸ªé’ˆå¯¹å¾®ç»†é¢éƒ¨è½¨è¿¹è¿½è¸ªçš„3Dé«˜æ–¯æ•£ç‚¹åŸºå‡†ï¼Œæ¨åŠ¨äº†ç²¾ç»†é¢éƒ¨è¡¨æƒ…ç ”ç©¶ã€‚|

