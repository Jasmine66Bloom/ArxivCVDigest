## [UPDATED!] **2026-01-07** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|CRUNet-MR-Univ: A Foundation Model for Diverse Cardiac MRI Reconstruction|CRUNet-MR-Univ: ä¸€ç§ç”¨äºå¤šæ ·åŒ–å¿ƒè„ MRI é‡å»ºçš„åŸºç¡€æ¨¡å‹|Donghang Lyu, Marius Staring, Hildo Lamb, Mariya Doneva|<https://arxiv.org/pdf/2601.04428v1>|æ— |
|ğŸ†• å‘å¸ƒ|Few-Shot LoRA Adaptation of a Flow-Matching Foundation Model for Cross-Spectral Object Detection|åŸºäºFlow MatchingåŸºç¡€æ¨¡å‹çš„Few-Shot LoRAé€‚é…ç”¨äºè·¨å…‰è°±ç›®æ ‡æ£€æµ‹|Maxim Clouser, Kia Khezeli, John Kalantari|<https://arxiv.org/pdf/2601.04381v1>|æ— |
|ğŸ†• å‘å¸ƒ|Scanner-Induced Domain Shifts Undermine the Robustness of Pathology Foundation Models|Scannerå¼•èµ·çš„åŸŸåç§»å‰Šå¼±äº†Pathology Foundation Modelsçš„é²æ£’æ€§|Erik Thiringer, Fredrik K. Gustafsson, Kajsa Ledesma Eriksson, Mattias Rantalainen|<https://arxiv.org/pdf/2601.04163v1>|æ— |
|ğŸ†• å‘å¸ƒ|Thinking with Frames: Generative Video Distortion Evaluation via Frame Reward Model|Thinking with Frames: é€šè¿‡ Frame Reward Model è¿›è¡Œç”Ÿæˆå¼è§†é¢‘å¤±çœŸè¯„ä¼°|Yuan Wang, Borui Liao, Huijuan Huang, Jinda Lu, Ouxiang Li, Kuien Liu, Meng Wang, Xiang Wang|<https://arxiv.org/pdf/2601.04033v1>|æ— |
|ğŸ†• å‘å¸ƒ|HemBLIP: A Vision-Language Model for Interpretable Leukemia Cell Morphology Analysis|HemBLIP: ä¸€ç§ç”¨äºå¯è§£é‡Šç™½è¡€ç—…ç»†èƒå½¢æ€åˆ†æçš„Vision-Language Model|Julie van Logtestijn, Petru Manescu|<https://arxiv.org/pdf/2601.03915v1>|æ— |
|ğŸ“ æ›´æ–°|PM4Bench: Benchmarking Large Vision-Language Models with Parallel Multilingual Multi-Modal Multi-task Corpus|PM4Bench: ä½¿ç”¨å¹¶è¡Œå¤šè¯­è¨€å¤šæ¨¡æ€å¤šä»»åŠ¡è¯­æ–™åº“è¯„ä¼° Large Vision-Language Models|Junyuan Gao, Jiahe Song, Jiang Wu, Runchuan Zhu, Guanlin Shen, Shasha Wang, Xingjian Wei, Haote Yang .etc.|<https://arxiv.org/pdf/2503.18484v2>|[ä»£ç ](https://github.com/opendatalab/PM4Bench)|
|ğŸ†• å‘å¸ƒ|EvalBlocks: A Modular Pipeline for Rapidly Evaluating Foundation Models in Medical Imaging|EvalBlocksï¼šç”¨äºå¿«é€Ÿè¯„ä¼°åŒ»å­¦å½±åƒä¸­ Foundation Models çš„æ¨¡å—åŒ– Pipeline|Jan Tagscherer, Sarah de Boer, Lena Philipp, Fennie van der Graaf, DrÃ© Peeters, Joeran Bosma, Lars Leijten, Bogdan Obreja .etc.|<https://arxiv.org/pdf/2601.03811v1>|[ä»£ç ](https://github.com/DIAGNijmegen/eval-blocks.)|
|ğŸ†• å‘å¸ƒ|A Comparative Study of 3D Model Acquisition Methods for Synthetic Data Generation of Agricultural Products|ç”¨äºå†œäº§å“åˆæˆæ•°æ®ç”Ÿæˆçš„3Dæ¨¡å‹è·å–æ–¹æ³•å¯¹æ¯”ç ”ç©¶|Steven Moonen, Rob Salaets, Kenneth Batstone, Abdellatif Bey-Temsamani, Nick Michiels|<https://arxiv.org/pdf/2601.03784v1>|æ— |
|ğŸ“ æ›´æ–°|MoTE: Mixture of Ternary Experts for Memory-efficient Large Multimodal Models|MoTE: ç”¨äºå†…å­˜é«˜æ•ˆå¤§å‹å¤šæ¨¡æ€æ¨¡å‹çš„ä¸‰å…ƒä¸“å®¶æ··åˆ|Hongyu Wang, Jiayu Xu, Ruiping Wang, Yan Feng, Yitao Zhai, Peng Pei, Xunliang Cai, Xilin Chen|<https://arxiv.org/pdf/2506.14435v2>|æ— |
|ğŸ†• å‘å¸ƒ|HyperCOD: The First Challenging Benchmark and Baseline for Hyperspectral Camouflaged Object Detection|HyperCODï¼šé¦–ä¸ªé«˜å…‰è°±ä¼ªè£…ç›®æ ‡æ£€æµ‹çš„æŒ‘æˆ˜æ€§åŸºå‡†ä¸åŸºçº¿|Shuyan Bai, Tingfa Xu, Peifu Liu, Yuhao Qiu, Huiyan Bai, Huan Chen, Yanyan Peng, Jianan Li|<https://arxiv.org/pdf/2601.03736v1>|æ— |
|ğŸ“ æ›´æ–°|Difficulty Controlled Diffusion Model for Synthesizing Effective Training Data|[ç¿»è¯‘å¤±è´¥] Difficulty Controlled Diffusion Model for Synthesizing Effective Training Data|Zerun Wang, Jiafeng Mao, Xueting Wang, Toshihiko Yamasaki|<https://arxiv.org/pdf/2411.18109v2>|æ— |


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|UNIC: Learning Unified Multimodal Extrinsic Contact Estimation|UNIC: å­¦ä¹ ç»Ÿä¸€çš„å¤šæ¨¡æ€å¤–éƒ¨æ¥è§¦ä¼°è®¡|Zhengtong Xu, Yuki Shirai|<https://arxiv.org/pdf/2601.04356v1>|æ— |
|ğŸ†• å‘å¸ƒ|ArtCognition: A Multimodal AI Framework for Affective State Sensing from Visual and Kinematic Drawing Cues|ArtCognitionï¼šä¸€ç§åŸºäºè§†è§‰å’Œè¿åŠ¨å­¦ç»˜ç”»çº¿ç´¢çš„æƒ…æ„ŸçŠ¶æ€æ„ŸçŸ¥å¤šæ¨¡æ€AIæ¡†æ¶|Behrad Binaei-Haghighi, Nafiseh Sadat Sajadi, Mehrad Liviyan, Reyhane Akhavan Kharazi, Fatemeh Amirkhani, Behnam Bahrak|<https://arxiv.org/pdf/2601.04297v1>|æ— |
|ğŸ“ æ›´æ–°|Adapting Vision-Language Foundation Model for Next Generation Medical Ultrasound Image Analysis|[ç¿»è¯‘å¤±è´¥] Adapting Vision-Language Foundation Model for Next Generation Medical Ultrasound Image Analysis|Jingguo Qu, Xinyang Han, Jia Ai, Juan Wu, Tong Zhao, Tonghuan Xiao, Sheng Ning, Yuqi Yang .etc.|<https://arxiv.org/pdf/2506.08849v3>|[ä»£ç ](https://github.com/jinggqu/NextGen-UIA.)|
|ğŸ“ æ›´æ–°|V-Agent: An Interactive Video Search System Using Vision-Language Models|V-Agent: ä½¿ç”¨ Vision-Language Models çš„äº¤äº’å¼è§†é¢‘æœç´¢ç³»ç»Ÿ|SunYoung Park, Jong-Hyeon Lee, Youngjune Kim, Daegyu Sung, Younghyun Yu, Young-rok Cha, Jeongho Ju|<https://arxiv.org/pdf/2512.16925v2>|æ— |


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Language as Prior, Vision as Calibration: Metric Scale Recovery for Monocular Depth Estimation|Language as Prior, Vision as Calibration: Monocular Depth Estimation çš„ Metric Scale Recovery|Mingxing Zhan, Li Zhang, Beibei Wang, Yingjie Wang, Zenglin Shi|<https://arxiv.org/pdf/2601.01457v2>|æ— |
|ğŸ“ æ›´æ–°|ViMoNet: A Multimodal Vision-Language Framework for Human Behavior Understanding from Motion and Video|ViMoNet: ä¸€ä¸ªåŸºäº Motion å’Œ Video è¿›è¡Œäººç±»è¡Œä¸ºç†è§£çš„å¤šæ¨¡æ€ Vision-Language æ¡†æ¶|Rajan Das Gupta, Lei Wei, Md Yeasin Rahat, Nafiz Fahad, Abir Ahmed, Liew Tze Hui|<https://arxiv.org/pdf/2508.09818v3>|æ— |
|ğŸ†• å‘å¸ƒ|MGPC: Multimodal Network for Generalizable Point Cloud Completion With Modality Dropout and Progressive Decoding|MGPC: åŸºäºæ¨¡æ€ä¸¢å¼ƒå’Œæ¸è¿›è§£ç çš„å¯æ³›åŒ–ç‚¹äº‘è¡¥å…¨å¤šæ¨¡æ€ç½‘ç»œ|Jiangyuan Liu, Hongxuan Ma, Yuhao Zhao, Zhe Liu, Jian Wang, Wei Zou|<https://arxiv.org/pdf/2601.03660v1>|æ— |
|ğŸ“ æ›´æ–°|Sortblock: Similarity-Aware Feature Reuse for Diffusion Model|Sortblock: é¢å‘ Diffusion Model çš„ç›¸ä¼¼åº¦æ„ŸçŸ¥ç‰¹å¾å¤ç”¨|Hanqi Chen, Xu Zhang, Xiaoliu Guan, Lielin Jiang, Guanzhong Wang, Zeyu Chen, Yi Liu|<https://arxiv.org/pdf/2508.00412v2>|æ— |


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|TRec: Egocentric Action Recognition using 2D Point Tracks|TRecï¼šä½¿ç”¨2D Point Tracksè¿›è¡Œä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„åŠ¨ä½œè¯†åˆ«|Dennis Holzmann, Sven Wachsmuth|<https://arxiv.org/pdf/2601.03667v2>|æ— |
|ğŸ“ æ›´æ–°|A Novel Convolution and Attention Mechanism-based Model for 6D Object Pose Estimation|ä¸€ç§åŸºäºå·ç§¯å’Œæ³¨æ„åŠ›æœºåˆ¶çš„æ–°å‹6Dç‰©ä½“ä½å§¿ä¼°è®¡æ¨¡å‹|Alexander Du, Xiujin Liu|<https://arxiv.org/pdf/2501.01993v2>|æ— |
|ğŸ†• å‘å¸ƒ|BREATH-VL: Vision-Language-Guided 6-DoF Bronchoscopy Localization via Semantic-Geometric Fusion|BREATH-VL: åŸºäºSemantic-Geometric Fusionçš„Vision-Language-Guided 6-DoFæ”¯æ°”ç®¡é•œå®šä½|Qingyao Tian, Bingyu Yang, Huai Liao, Xinyan Huang, Junyong Li, Dong Yi, Hongbin Liu|<https://arxiv.org/pdf/2601.03713v1>|æ— |


### å›¾åƒåˆ†ç±»ä¸è¯†åˆ« (Image Classification & Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Performance Analysis of Image Classification on Bangladeshi Datasets|Bangladeshi æ•°æ®é›†ä¸Š Image Classification çš„æ€§èƒ½åˆ†æ|Mohammed Sami Khan, Fabiha Muniat, Rowzatul Zannat|<https://arxiv.org/pdf/2601.04397v1>|æ— |
|ğŸ†• å‘å¸ƒ|Unsupervised Modular Adaptive Region Growing and RegionMix Classification for Wind Turbine Segmentation|æ— ç›‘ç£æ¨¡å—åŒ–è‡ªé€‚åº”åŒºåŸŸç”Ÿé•¿ä¸ RegionMix åˆ†ç±»ç”¨äºé£åŠ›å‘ç”µæœºåˆ†å‰²|RaÃ¼l PÃ©rez-Gonzalo, Riccardo Magro, Andreas Espersen, Antonio Agudo|<https://arxiv.org/pdf/2601.04065v1>|æ— |
|ğŸ†• å‘å¸ƒ|Shape Classification using Approximately Convex Segment Features|ä½¿ç”¨è¿‘ä¼¼å‡¸æ®µç‰¹å¾çš„å½¢çŠ¶åˆ†ç±»|Bimal Kumar Ray|<https://arxiv.org/pdf/2601.03625v1>|æ— |


### ç›®æ ‡æ£€æµ‹ä¸å®šä½ (Object Detection & Localization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Improving VisNet for Object Recognition|æ”¹è¿› VisNet ç”¨äºç‰©ä½“è¯†åˆ«|Mehdi Fatan Serj, C. Alejandro Parraga, Xavier Otazu|<https://arxiv.org/pdf/2511.08897v3>|æ— |
|ğŸ“ æ›´æ–°|SortWaste: A Densely Annotated Dataset for Object Detection in Industrial Waste Sorting|SortWaste: ç”¨äºå·¥ä¸šåºŸæ–™åˆ†æ‹£ä¸­ç›®æ ‡æ£€æµ‹çš„å¯†é›†æ ‡æ³¨æ•°æ®é›†|Sara InÃ¡cio, Hugo ProenÃ§a, JoÃ£o C. Neves|<https://arxiv.org/pdf/2601.02299v2>|æ— |
|ğŸ†• å‘å¸ƒ|Systematic Evaluation of Depth Backbones and Semantic Cues for Monocular Pseudo-LiDAR 3D Detection|å•ç›® Pseudo-LiDAR 3D æ£€æµ‹ä¸­ Depth Backbones å’Œ Semantic Cues çš„ç³»ç»Ÿæ€§è¯„ä¼°|Samson Oseiwe Ajadalu|<https://arxiv.org/pdf/2601.03617v1>|æ— |


### è¯­ä¹‰/å®ä¾‹åˆ†å‰² (Semantic/Instance Segmentation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|G2P: Gaussian-to-Point Attribute Alignment for Boundary-Aware 3D Semantic Segmentation|G2P: Gaussian-to-Point å±æ€§å¯¹é½ç”¨äºè¾¹ç•Œæ„ŸçŸ¥çš„ 3D è¯­ä¹‰åˆ†å‰²|Hojun Song, Chae-yeong Song, Jeong-hun Hong, Chaewon Moon, Dong-hwi Kim, Gahyeon Kim, Soo Ye Kim, Yiyi Liao .etc.|<https://arxiv.org/pdf/2601.03510v1>|æ— |


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|InfiniteWeb: Scalable Web Environment Synthesis for GUI Agent Training|InfiniteWebï¼šç”¨äº GUI Agent è®­ç»ƒçš„å¯æ‰©å±• Web ç¯å¢ƒåˆæˆ|Ziyun Zhang, Zezhou Wang, Xiaoyi Zhang, Zongyu Guo, Jiahao Li, Bin Li, Yan Lu|<https://arxiv.org/pdf/2601.04126v2>|æ— |
|ğŸ†• å‘å¸ƒ|PackCache: A Training-Free Acceleration Method for Unified Autoregressive Video Generation via Compact KV-Cache|PackCacheï¼šä¸€ç§é€šè¿‡ç´§å‡‘ KV-Cache å®ç°ç»Ÿä¸€è‡ªå›å½’è§†é¢‘ç”Ÿæˆçš„å…è®­ç»ƒåŠ é€Ÿæ–¹æ³•|Kunyang Li, Mubarak Shah, Yuzhang Shang|<https://arxiv.org/pdf/2601.04359v1>|æ— |
|ğŸ†• å‘å¸ƒ|MFC-RFNet: A Multi-scale Guided Rectified Flow Network for Radar Sequence Prediction|MFC-RFNet: ä¸€ç§ç”¨äºé›·è¾¾åºåˆ—é¢„æµ‹çš„å¤šå°ºåº¦å¼•å¯¼æ•´æµæµç½‘ç»œ|Wenjie Luo, Chuanhu Deng, Chaorong Li, Rongyao Deng, Qiang Yang|<https://arxiv.org/pdf/2601.03633v1>|æ— |
|ğŸ†• å‘å¸ƒ|Unveiling Text in Challenging Stone Inscriptions: A Character-Context-Aware Patching Strategy for Binarization|æ­ç¤ºå…·æœ‰æŒ‘æˆ˜æ€§çš„çŸ³åˆ»æ–‡å­—ï¼šä¸€ç§ç”¨äºäºŒå€¼åŒ–çš„å­—ç¬¦ä¸Šä¸‹æ–‡æ„ŸçŸ¥åˆ†å—ç­–ç•¥|Pratyush Jena, Amal Joseph, Arnav Sharma, Ravi Kiran Sarvadevabhatla|<https://arxiv.org/pdf/2601.03609v1>|æ— |
|ğŸ†• å‘å¸ƒ|Detecting AI-Generated Images via Distributional Deviations from Real Images|é€šè¿‡æ£€æµ‹ä¸çœŸå®å›¾åƒçš„åˆ†å¸ƒåå·®æ¥è¯†åˆ« AI ç”Ÿæˆçš„å›¾åƒ|Yakun Niu, Yingjian Chen, Lei Zhang|<https://arxiv.org/pdf/2601.03586v1>|æ— |


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|CrackSegFlow: Controllable Flow Matching Synthesis for Generalizable Crack Segmentation with a 50K Image-Mask Benchmark|CrackSegFlowï¼šåŸºäºå¯æ§Flow Matchingåˆæˆçš„å¯æ³›åŒ–è£‚ç¼åˆ†å‰²åŠ50Kå›¾åƒ-æ©ç åŸºå‡†|Babak Asadi, Peiyang Wu, Mani Golparvar-Fard, Ramez Hajj|<https://arxiv.org/pdf/2601.03637v2>|æ— |
|ğŸ†• å‘å¸ƒ|Towards Real-world Lens Active Alignment with Unlabeled Data via Domain Adaptation|[ç¿»è¯‘å¤±è´¥] Towards Real-world Lens Active Alignment with Unlabeled Data via Domain Adaptation|Wenyong Li, Qi Jiang, Weijian Hu, Kailun Yang, Zhanjun Zhang, Wenjun Tian, Kaiwei Wang, Jian Bai|<https://arxiv.org/pdf/2601.03718v2>|æ— |
|ğŸ“ æ›´æ–°|StreamFlow: Theory, Algorithm, and Implementation for High-Efficiency Rectified Flow Generation|StreamFlowï¼šé«˜æ•ˆRectified Flowç”Ÿæˆçš„ç†è®ºã€ç®—æ³•ä¸å®ç°|Sen Fang, Hongbin Zhong, Yalin Feng, Yanxin Zhang, Dimitris N. Metaxas|<https://arxiv.org/pdf/2511.22009v2>|æ— |
|ğŸ†• å‘å¸ƒ|Unified Text-Image Generation with Weakness-Targeted Post-Training|åŸºäºå¼±ç‚¹å®šå‘åè®­ç»ƒçš„ç»Ÿä¸€æ–‡æœ¬-å›¾åƒç”Ÿæˆ|Jiahui Chen, Philippe Hansen-Estruch, Xiaochuang Han, Yushi Hu, Emily Dinan, Amita Kamath, Michal Drozdzal, Reyhane Askari-Hemmat .etc.|<https://arxiv.org/pdf/2601.04339v1>|æ— |
|ğŸ†• å‘å¸ƒ|Klear: Unified Multi-Task Audio-Video Joint Generation|Klear: ç»Ÿä¸€å¤šä»»åŠ¡éŸ³è§†é¢‘è”åˆç”Ÿæˆ|Jun Wang, Chunyu Qiang, Yuxin Guo, Yiran Wang, Xijuan Zeng, Chen Zhang, Pengfei Wan|<https://arxiv.org/pdf/2601.04151v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Wow, wo, val! A Comprehensive Embodied World Model Evaluation Turing Test|Wow, wo, val! ä¸€é¡¹å…¨é¢çš„å…·èº«ä¸–ç•Œæ¨¡å‹è¯„ä¼°å›¾çµæµ‹è¯•|Chun-Kai Fan, Xiaowei Chi, Xiaozhu Ju, Hao Li, Yong Bao, Yu-Kai Wang, Lizhang Chen, Zhiyuan Jiang .etc.|<https://arxiv.org/pdf/2601.04137v1>|æ— |
|ğŸ†• å‘å¸ƒ|Gen3R: 3D Scene Generation Meets Feed-Forward Reconstruction|Gen3R: 3Dåœºæ™¯ç”Ÿæˆé‡è§å‰é¦ˆé‡å»º|Jiaxin Huang, Yuanbo Yang, Bangbang Yang, Lin Ma, Yuewen Ma, Yiyi Liao|<https://arxiv.org/pdf/2601.04090v1>|æ— |
|ğŸ“ æ›´æ–°|UniVideo: Unified Understanding, Generation, and Editing for Videos|UniVideo: ç»Ÿä¸€çš„è§†é¢‘ç†è§£ã€ç”Ÿæˆä¸ç¼–è¾‘|Cong Wei, Quande Liu, Zixuan Ye, Qiulin Wang, Xintao Wang, Pengfei Wan, Kun Gai, Wenhu Chen|<https://arxiv.org/pdf/2510.08377v3>|æ— |
|ğŸ“ æ›´æ–°|FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation|FastV-RAG: åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆçš„å¿«é€Ÿç»†ç²’åº¦è§†é¢‘é—®ç­”|Gen Li, Peiyu Liu|<https://arxiv.org/pdf/2601.01513v2>|æ— |
|ğŸ“ æ›´æ–°|Boosting Resolution Generalization of Diffusion Transformers with Randomized Positional Encodings|åˆ©ç”¨éšæœºä½ç½®ç¼–ç æå‡ Diffusion Transformers çš„åˆ†è¾¨ç‡æ³›åŒ–èƒ½åŠ›|Liang Hou, Cong Liu, Mingwu Zheng, Xin Tao, Pengfei Wan, Di Zhang, Kun Gai|<https://arxiv.org/pdf/2503.18719v2>|æ— |
|ğŸ†• å‘å¸ƒ|ResTok: Learning Hierarchical Residuals in 1D Visual Tokenizers for Autoregressive Image Generation|ResTokï¼šåœ¨ç”¨äºè‡ªå›å½’å›¾åƒç”Ÿæˆçš„1D Visual Tokenizersä¸­å­¦ä¹ åˆ†å±‚æ®‹å·®|Xu Zhang, Cheng Da, Huan Yang, Kun Gai, Ming Lu, Zhan Ma|<https://arxiv.org/pdf/2601.03955v1>|[ä»£ç ](https://github.com/Kwai-Kolors/ResTok.)|
|ğŸ“ æ›´æ–°|U-REPA: Aligning Diffusion U-Nets to ViTs|U-REPA: å°† Diffusion U-Nets ä¸ ViTs å¯¹é½|Yuchuan Tian, Hanting Chen, Mengyu Zheng, Yuchen Liang, Chao Xu, Yunhe Wang|<https://arxiv.org/pdf/2503.18414v3>|[ä»£ç ](https://github.com/YuchuanTian/U-REPA)|
|ğŸ†• å‘å¸ƒ|From Brute Force to Semantic Insight: Performance-Guided Data Transformation Design with LLMs|ä»æš´åŠ›ç ´è§£åˆ°è¯­ä¹‰æ´å¯Ÿï¼šåˆ©ç”¨ LLM è¿›è¡Œæ€§èƒ½å¼•å¯¼çš„æ•°æ®å˜æ¢è®¾è®¡|Usha Shrestha, Dmitry Ignatov, Radu Timofte|<https://arxiv.org/pdf/2601.03808v1>|æ— |
|ğŸ“ æ›´æ–°|Generating Storytelling Images with Rich Chains-of-Reasoning|ç”Ÿæˆå…·æœ‰ä¸°å¯Œæ¨ç†é“¾çš„å™äº‹å›¾åƒ|Xiujie Song, Qi Jia, Shota Watanabe, Xiaoyi Pang, Ruijie Chen, Mengyue Wu, Kenny Q. Zhu|<https://arxiv.org/pdf/2512.07198v2>|æ— |
|ğŸ“ æ›´æ–°|Point Cloud Synthesis Using Inner Product Transforms|ä½¿ç”¨å†…ç§¯å˜æ¢çš„ç‚¹äº‘åˆæˆ|Ernst RÃ¶ell, Bastian Rieck|<https://arxiv.org/pdf/2410.18987v5>|æ— |
|ğŸ“ æ›´æ–°|Multivariate Diffusion Transformer with Decoupled Attention for High-Fidelity Mask-Text Collaborative Facial Generation|å…·æœ‰è§£è€¦æ³¨æ„åŠ›çš„å¤šå…ƒæ‰©æ•£Transformerç”¨äºé«˜ä¿çœŸMask-TextååŒäººè„¸ç”Ÿæˆ|Yushe Cao, Dianxi Shi, Xing Fu, Xuechao Zou, Haikuo Peng, Xueqi Li, Chun Yu, Junliang Xing|<https://arxiv.org/pdf/2511.12631v2>|æ— |
|ğŸ†• å‘å¸ƒ|I2E: From Image Pixels to Actionable Interactive Environments for Text-Guided Image Editing|I2Eï¼šä»å›¾åƒåƒç´ åˆ°ç”¨äº Text-Guided Image Editing çš„å¯æ“ä½œäº¤äº’ç¯å¢ƒ|Jinghan Yu, Junhao Xiao, Chenyu Zhu, Jiaming Li, Jia Li, HanMing Deng, Xirui Wang, Guoli Jia .etc.|<https://arxiv.org/pdf/2601.03741v1>|æ— |
|ğŸ“ æ›´æ–°|FairT2I: Mitigating Social Bias in Text-to-Image Generation via Large Language Model-Assisted Detection and Attribute Rebalancing|FairT2I: é€šè¿‡ Large Language Model è¾…åŠ©æ£€æµ‹å’Œå±æ€§é‡å¹³è¡¡ç¼“è§£ Text-to-Image ç”Ÿæˆä¸­çš„ç¤¾ä¼šåè§|Jinya Sakurai, Yuki Koyama, Issei Sato|<https://arxiv.org/pdf/2502.03826v4>|æ— |
|ğŸ†• å‘å¸ƒ|PhysVideoGenerator: Towards Physically Aware Video Generation via Latent Physics Guidance|PhysVideoGenerator: é€šè¿‡ Latent Physics Guidance å®ç°ç‰©ç†æ„ŸçŸ¥çš„è§†é¢‘ç”Ÿæˆ|Siddarth Nilol Kundur Satish, Devesh Jaiswal, Hongyu Chen, Abhishek Bakshi|<https://arxiv.org/pdf/2601.03665v1>|æ— |
|ğŸ†• å‘å¸ƒ|VideoMemory: Toward Consistent Video Generation via Memory Integration|VideoMemory: é€šè¿‡Memory Integrationå®ç°ä¸€è‡´çš„è§†é¢‘ç”Ÿæˆ|Jinsong Zhou, Yihua Du, Xinli Xu, Luozhou Wang, Zijie Zhuang, Yehang Zhang, Shuaibo Li, Xiaojun Hu .etc.|<https://arxiv.org/pdf/2601.03655v1>|æ— |
|ğŸ“ æ›´æ–°|I-Scene: 3D Instance Models are Implicit Generalizable Spatial Learners|[ç¿»è¯‘å¤±è´¥] I-Scene: 3D Instance Models are Implicit Generalizable Spatial Learners|Lu Ling, Yunhao Ge, Yichen Sheng, Aniket Bera|<https://arxiv.org/pdf/2512.13683v2>|[ä»£ç ](https://luling06.github.io/I-Scene-project)|
|ğŸ“ æ›´æ–°|Where MLLMs Attend and What They Rely On: Explaining Autoregressive Token Generation|MLLMs å…³æ³¨çš„ä½ç½®åŠå…¶ä¾èµ–çš„å†…å®¹ï¼šè§£é‡Šè‡ªå›å½’ Token ç”Ÿæˆ|Ruoyu Chen, Xiaoqing Guo, Kangwei Liu, Siyuan Liang, Shiming Liu, Qunli Zhang, Laiyuan Wang, Hua Zhang .etc.|<https://arxiv.org/pdf/2509.22496v4>|æ— |
|ğŸ“ æ›´æ–°|VisualCloze: A Universal Image Generation Framework via Visual In-Context Learning|VisualClozeï¼šé€šè¿‡Visual In-Context Learningçš„é€šç”¨å›¾åƒç”Ÿæˆæ¡†æ¶|Zhong-Yu Li, Ruoyi Du, Juncheng Yan, Le Zhuo, Qilong Wu, Zhen Li, Peng Gao, Zhanyu Ma .etc.|<https://arxiv.org/pdf/2504.07960v4>|æ— |


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Mind the Generative Details: Direct Localized Detail Preference Optimization for Video Diffusion Models|[ç¿»è¯‘å¤±è´¥] Mind the Generative Details: Direct Localized Detail Preference Optimization for Video Diffusion Models|Zitong Huang, Kaidong Zhang, Yukang Ding, Chao Gao, Rui Ding, Ying Chen, Wangmeng Zuo|<https://arxiv.org/pdf/2601.04068v2>|æ— |
|ğŸ†• å‘å¸ƒ|3D-Agent:Tri-Modal Multi-Agent Collaboration for Scalable 3D Object Annotation|3D-Agent:ç”¨äºå¯æ‰©å±•3Då¯¹è±¡æ ‡æ³¨çš„ä¸‰æ¨¡æ€å¤šæ™ºèƒ½ä½“åä½œ|Jusheng Zhang, Yijia Fan, Zimo Wen, Jian Wang, Keze Wang|<https://arxiv.org/pdf/2601.04404v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Beyond Fixed Topologies: Unregistered Training and Comprehensive Evaluation Metrics for 3D Talking Heads|è¶…è¶Šè¶…è¶Šå›ºå®šæ‹“æ‰‘ï¼š3D è¯´è¯å¤´éƒ¨çš„éé…å‡†è®­ç»ƒä¸ç»¼åˆè¯„ä¼°æŒ‡æ ‡|Federico Nocentini, Thomas Besnier, Claudio Ferrari, Sylvain Arguillere, Mohamed Daoudi, Stefano Berretti|<https://arxiv.org/pdf/2410.11041v3>|æ— |
|ğŸ†• å‘å¸ƒ|ReHyAt: Recurrent Hybrid Attention for Video Diffusion Transformers|ReHyAt: ç”¨äº Video Diffusion Transformers çš„ Recurrent Hybrid Attention|Mohsen Ghafoorian, Amirhossein Habibian|<https://arxiv.org/pdf/2601.04342v1>|[ä»£ç ](https://qualcomm-ai-research.github.io/rehyat.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Choreographing a World of Dynamic Objects|ç¼–æ’ä¸€ä¸ªå……æ»¡åŠ¨æ€å¯¹è±¡çš„ä¸–ç•Œ|Yanzhe Lyu, Chen Geng, Karthik Dharmarajan, Yunzhi Zhang, Hadi Alzayer, Shangzhe Wu, Jiajun Wu|<https://arxiv.org/pdf/2601.04194v1>|[ä»£ç ](https://yanzhelyu.github.io/chord)|
|ğŸ†• å‘å¸ƒ|Embedding Textual Information in Images Using Quinary Pixel Combinations|ä½¿ç”¨äº”è¿›åˆ¶åƒç´ ç»„åˆåœ¨å›¾åƒä¸­åµŒå…¥æ–‡æœ¬ä¿¡æ¯|A V Uday Kiran Kandala|<https://arxiv.org/pdf/2601.04302v1>|æ— |
|ğŸ†• å‘å¸ƒ|Beyond Binary Preference: Aligning Diffusion Models to Fine-grained Criteria by Decoupling Attributes|è¶…è¶ŠäºŒå…ƒåå¥½ï¼šé€šè¿‡è§£è€¦å±æ€§å°† Diffusion Models ä¸ç»†ç²’åº¦æ ‡å‡†å¯¹é½|Chenye Meng, Zejian Li, Zhongni Liu, Yize Li, Changle Xie, Kaixin Jia, Ling Yang, Huanghuang Deng .etc.|<https://arxiv.org/pdf/2601.04300v1>|æ— |
|ğŸ†• å‘å¸ƒ|Diffusion-DRF: Differentiable Reward Flow for Video Diffusion Fine-Tuning|Diffusion-DRF: ç”¨äº Video Diffusion Fine-Tuning çš„ Differentiable Reward Flow|Yifan Wang, Yanyu Li, Sergey Tulyakov, Yun Fu, Anil Kag|<https://arxiv.org/pdf/2601.04153v1>|æ— |
|ğŸ†• å‘å¸ƒ|CLAP: Contrastive Latent Action Pretraining for Learning Vision-Language-Action Models from Human Videos|CLAPï¼šç”¨äºä»äººç±»è§†é¢‘ä¸­å­¦ä¹  Vision-Language-Action Models çš„å¯¹æ¯”æ½œåœ¨åŠ¨ä½œé¢„è®­ç»ƒ|Chubin Zhang, Jianan Wang, Zifeng Gao, Yue Su, Tianru Dai, Cai Zhou, Jiwen Lu, Yansong Tang|<https://arxiv.org/pdf/2601.04061v1>|æ— |
|ğŸ“ æ›´æ–°|Controllable Generation with Text-to-Image Diffusion Models: A Survey|åŸºäºText-to-Image Diffusion Modelsçš„å¯æ§ç”Ÿæˆï¼šç»¼è¿°|Pu Cao, Feng Zhou, Qing Song, Lu Yang|<https://arxiv.org/pdf/2403.04279v2>|[ä»£ç ](https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models.)|
|ğŸ†• å‘å¸ƒ|FUSION: Full-Body Unified Motion Prior for Body and Hands via Diffusion|FUSION: é€šè¿‡ Diffusion å®ç°èº«ä½“å’Œæ‰‹éƒ¨çš„å…¨èº«ç»Ÿä¸€è¿åŠ¨å…ˆéªŒ|Enes Duran, Nikos Athanasiou, Muhammed Kocabas, Michael J. Black, Omid Taheri|<https://arxiv.org/pdf/2601.03959v1>|æ— |
|ğŸ†• å‘å¸ƒ|CSMCIR: CoT-Enhanced Symmetric Alignment with Memory Bank for Composed Image Retrieval|CSMCIR: åŸºäºMemory Bankçš„CoTå¢å¼ºå¯¹ç§°å¯¹é½ç”¨äºç»„åˆå›¾åƒæ£€ç´¢|Zhipeng Qian, Zihan Liang, Yufei Ma, Ben Chen, Huangyu Dai, Yiwei Ma, Jiayi Ji, Chenyi Lei .etc.|<https://arxiv.org/pdf/2601.03728v1>|æ— |
|ğŸ“ æ›´æ–°|Back to Basics: Let Denoising Generative Models Denoise|å›å½’åŸºç¡€ï¼šè®©å»å™ªç”Ÿæˆæ¨¡å‹å»å™ª|Tianhong Li, Kaiming He|<https://arxiv.org/pdf/2511.13720v2>|æ— |
|ğŸ“ æ›´æ–°|BiPO: Bidirectional Partial Occlusion Network for Text-to-Motion Synthesis|BiPOï¼šç”¨äºText-to-Motion Synthesisçš„åŒå‘éƒ¨åˆ†é®æŒ¡ç½‘ç»œ|Seong-Eun Hong, Soobin Lim, Juyeong Hwang, Minwook Chang, Hyeongyeop Kang|<https://arxiv.org/pdf/2412.00112v3>|æ— |
|ğŸ“ æ›´æ–°|Adaptive Anomaly Recovery for Telemanipulation: A Diffusion Model Approach to Vision-Based Tracking|é¥æ“ä½œçš„è‡ªé€‚åº”å¼‚å¸¸æ¢å¤ï¼šä¸€ç§åŸºäºè§†è§‰è·Ÿè¸ªçš„æ‰©æ•£æ¨¡å‹æ–¹æ³•|Haoyang Wang, Haoran Guo, Lingfeng Tao, Zhengxiong Li|<https://arxiv.org/pdf/2503.09632v2>|æ— |
|ğŸ†• å‘å¸ƒ|Physics-Constrained Cross-Resolution Enhancement Network for Optics-Guided Thermal UAV Image Super-Resolution|[ç¿»è¯‘å¤±è´¥] Physics-Constrained Cross-Resolution Enhancement Network for Optics-Guided Thermal UAV Image Super-Resolution|Zhicheng Zhao, Fengjiao Peng, Jinquan Yan, Wei Lu, Chenglong Li, Jin Tang|<https://arxiv.org/pdf/2601.03526v1>|æ— |
|ğŸ†• å‘å¸ƒ|Semantic Belief-State World Model for 3D Human Motion Prediction|ç”¨äº3Däººä½“è¿åŠ¨é¢„æµ‹çš„è¯­ä¹‰ä¿¡å¿µçŠ¶æ€ä¸–ç•Œæ¨¡å‹|Sarim Chaudhry|<https://arxiv.org/pdf/2601.03517v1>|æ— |


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Jailbreaking Safeguarded Text-to-Image Models via Large Language Models|é€šè¿‡ Large Language Models æ”»å‡»å—ä¿æŠ¤çš„ Text-to-Image Models|Zhengyuan Jiang, Yuepeng Hu, Yuchen Yang, Yinzhi Cao, Neil Zhenqiang Gong|<https://arxiv.org/pdf/2503.01839v2>|æ— |
|ğŸ†• å‘å¸ƒ|PosterVerse: A Full-Workflow Framework for Commercial-Grade Poster Generation with HTML-Based Scalable Typography|PosterVerse: ä¸€ä¸ªåŸºäºHTMLå¯ç¼©æ’ç‰ˆçš„å•†ä¸šçº§æµ·æŠ¥ç”Ÿæˆå…¨æµç¨‹æ¡†æ¶|Junle Liu, Peirong Zhang, Yuyi Zhang, Pengyu Yan, Hui Zhou, Xinyue Zhou, Fengjun Guo, Lianwen Jin|<https://arxiv.org/pdf/2601.03993v1>|[ä»£ç ](https://github.com/wuhaer/PosterVerse.)|
|ğŸ“ æ›´æ–°|Benchmarking Content-Based Puzzle Solvers on Corrupted Jigsaw Puzzles|åœ¨æŸåçš„æ‹¼å›¾ä¸Šå¯¹åŸºäºå†…å®¹çš„æ‹¼å›¾æ±‚è§£å™¨è¿›è¡ŒåŸºå‡†æµ‹è¯•|Richard Dirauf, Florian Wolz, Dario Zanca, BjÃ¶rn Eskofier|<https://arxiv.org/pdf/2507.07828v2>|æ— |
|ğŸ“ æ›´æ–°|Generative Refocusing: Flexible Defocus Control from a Single Image|[ç¿»è¯‘å¤±è´¥] Generative Refocusing: Flexible Defocus Control from a Single Image|Chun-Wei Tuan Mu, Jia-Bin Huang, Yu-Lun Liu|<https://arxiv.org/pdf/2512.16923v2>|æ— |


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|In-SRAM Radiant Foam Rendering on a Graph Processor|Graph Processor ä¸Šçš„ In-SRAM Radiant Foam Rendering|Zulkhuu Tuya, Ignacio Alzugaray, Nicholas Fry, Andrew J. Davison|<https://arxiv.org/pdf/2601.04382v1>|æ— |
|ğŸ†• å‘å¸ƒ|Bayesian Monocular Depth Refinement via Neural Radiance Fields|åŸºäºNeRFçš„è´å¶æ–¯å•ç›®æ·±åº¦ç»†åŒ–|Arun Muthukkumar|<https://arxiv.org/pdf/2601.03869v1>|æ— |
|ğŸ†• å‘å¸ƒ|EASLT: Emotion-Aware Sign Language Translation|[ç¿»è¯‘å¤±è´¥] EASLT: Emotion-Aware Sign Language Translation|Guobin Tu, Di Weng|<https://arxiv.org/pdf/2601.03549v1>|[ä»£ç ](https://github.com/TuGuobin/EASLT.)|


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Semantic-E2VID: a Semantic-Enriched Paradigm for Event-to-Video Reconstruction|Semantic-E2VID: ä¸€ç§ç”¨äºEvent-to-Video Reconstructionçš„è¯­ä¹‰å¢å¼ºèŒƒå¼|Jingqian Wu, Yunbo Jia, Shengpeng Xu, Edmund Y. Lam|<https://arxiv.org/pdf/2510.17347v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|IDESplat: Iterative Depth Probability Estimation for Generalizable 3D Gaussian Splatting|IDESplat: ç”¨äºå¯æ³›åŒ–3D Gaussian Splattingçš„è¿­ä»£æ·±åº¦æ¦‚ç‡ä¼°è®¡|Wei Long, Haifeng Wu, Shiyin Jiang, Jinhua Zhang, Xinchun Ji, Shuhang Gu|<https://arxiv.org/pdf/2601.03824v1>|æ— |


### è§†è§‰å®šä½ä¸æ˜ å°„ (Visual Localization & Mapping)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SpatiaLoc: Leveraging Multi-Level Spatial Enhanced Descriptors for Cross-Modal Localization|SpatiaLoc: åˆ©ç”¨å¤šçº§ç©ºé—´å¢å¼ºæè¿°ç¬¦è¿›è¡Œè·¨æ¨¡æ€å®šä½|Tianyi Shang, Pengjie Xu, Zhaojun Deng, Zhenyu Li, Zhicong Chen, Lijun Wu|<https://arxiv.org/pdf/2601.03579v1>|æ— |


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Combining facial videos and biosignals for stress estimation during driving|[ç¿»è¯‘å¤±è´¥] Combining facial videos and biosignals for stress estimation during driving|Paraskevi Valergaki, Vassilis C. Nicodemou, Iason Oikonomidis, Antonis Argyros, Anastasios Roussos|<https://arxiv.org/pdf/2601.04376v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|PrismVAU: Prompt-Refined Inference System for Multimodal Video Anomaly Understanding|PrismVAU: Prompt-Refined å¤šæ¨¡æ€è§†é¢‘å¼‚å¸¸ç†è§£æ¨ç†ç³»ç»Ÿ|IÃ±aki Erregue, Kamal Nasrollahi, Sergio Escalera|<https://arxiv.org/pdf/2601.02927v2>|æ— |
|ğŸ“ æ›´æ–°|Video LLMs for Temporal Reasoning in Long Videos|ç”¨äºé•¿è§†é¢‘æ—¶åºæ¨ç†çš„ Video LLMs|Fawad Javed Fateh, Umer Ahmed, Hamza Khan, M. Zeeshan Zia, Quoc-Huy Tran|<https://arxiv.org/pdf/2412.02930v5>|æ— |


### è§†é¢‘ç›®æ ‡è·Ÿè¸ª (Video Object Tracking)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MVP: Enhancing Video Large Language Models via Self-supervised Masked Video Prediction|MVP: é€šè¿‡è‡ªç›‘ç£æ©ç è§†é¢‘é¢„æµ‹å¢å¼ºè§†é¢‘å¤§è¯­è¨€æ¨¡å‹|Xiaokun Sun, Zezhong Wu, Zewen Ding, Linli Xu|<https://arxiv.org/pdf/2601.03781v1>|æ— |


### åŠ¨ä½œè¯†åˆ«ä¸ç†è§£ (Action Recognition & Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Real-Time In-Cabin Driver Behavior Recognition on Low-Cost Edge Hardware|ä½æˆæœ¬è¾¹ç¼˜ç¡¬ä»¶ä¸Šçš„å®æ—¶è½¦å†…é©¾é©¶å‘˜è¡Œä¸ºè¯†åˆ«|Vesal Ahsani, Babak Hossein Khalaj, Hamed Shah-Mansouri|<https://arxiv.org/pdf/2512.22298v2>|æ— |


## è‡ªç›‘ç£ä¸è¡¨å¾å­¦ä¹  (Self-supervised & Representation Learning)


### å¯¹æ¯”å­¦ä¹ æ–¹æ³• (Contrastive Learning Methods)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ToTMNet: FFT-Accelerated Toeplitz Temporal Mixing Network for Lightweight Remote Photoplethysmography|ToTMNet: FFTåŠ é€Ÿçš„Toeplitzæ—¶é—´æ··åˆç½‘ç»œï¼Œç”¨äºè½»é‡çº§è¿œç¨‹å…‰ç”µå®¹ç§¯æè®°æœ¯|Vladimir Frants, Sos Agaian, Karen Panetta|<https://arxiv.org/pdf/2601.04159v1>|æ— |
|ğŸ“ æ›´æ–°|S2Vec: Self-Supervised Geospatial Embeddings for the Built Environment|S2Vec: ç”¨äºå»ºæˆç¯å¢ƒçš„è‡ªç›‘ç£åœ°ç†ç©ºé—´åµŒå…¥|Shushman Choudhury, Elad Aharoni, Chandrakumari Suvarna, Iveel Tsogsuren, Abdul Rahman Kreidieh, Chun-Ta Lu, Neha Arora|<https://arxiv.org/pdf/2504.16942v2>|æ— |
|ğŸ“ æ›´æ–°|ProCLIP: Progressive Vision-Language Alignment via LLM-based Embedder|ProCLIP: åŸºäº LLM Embedder çš„æ¸è¿›å¼è§†è§‰-è¯­è¨€å¯¹é½|Xiaoxing Hu, Kaicheng Yang, Ziyang Gong, Qi Ming, Zonghao Guo, Yu Tian, Xiang An, Ziyong Feng .etc.|<https://arxiv.org/pdf/2510.18795v3>|[ä»£ç ](https://github.com/VisionXLab/ProCLIP.)|


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Addressing Overthinking in Large Vision-Language Models via Gated Perception-Reasoning Optimization|é€šè¿‡é—¨æ§æ„ŸçŸ¥-æ¨ç†ä¼˜åŒ–è§£å†³ Large Vision-Language Models ä¸­çš„è¿‡åº¦æ€è€ƒé—®é¢˜|Xingjian Diao, Zheyuan Liu, Chunhui Zhang, Weiyi Wu, Keyi Kong, Lin Shi, Kaize Ding, Soroush Vosoughi .etc.|<https://arxiv.org/pdf/2601.04442v1>|æ— |
|ğŸ“ æ›´æ–°|VISTA: Mitigating Semantic Inertia in Video-LLMs via Training-Free Dynamic Chain-of-Thought Routing|VISTA: é€šè¿‡å…è®­ç»ƒåŠ¨æ€æ€ç»´é“¾è·¯ç”±ç¼“è§£ Video-LLMs ä¸­çš„è¯­ä¹‰æƒ¯æ€§|Hongbo Jin, Jiayu Ding, Siyi Xie, Guibo Luo, Ge Li|<https://arxiv.org/pdf/2505.11830v3>|æ— |


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Aligned explanations in neural networks|ç¥ç»ç½‘ç»œä¸­çš„å¯¹é½è§£é‡Š|Corentin Lobet, Francesca Chiaromonte|<https://arxiv.org/pdf/2601.04378v1>|æ— |
|ğŸ†• å‘å¸ƒ|End-to-end differentiable design of geometric waveguide displays|å‡ ä½•æ³¢å¯¼æ˜¾ç¤ºå™¨çš„ç«¯åˆ°ç«¯å¯å¾®åˆ†è®¾è®¡|Xinge Yang, Zhaocheng Liu, Zhaoyu Nie, Qingyuan Fan, Zhimin Shi, Jim Bonar, Wolfgang Heidrich|<https://arxiv.org/pdf/2601.04370v1>|æ— |
|ğŸ†• å‘å¸ƒ|Comparative Analysis of Custom CNN Architectures versus Pre-trained Models and Transfer Learning: A Study on Five Bangladesh Datasets|Custom CNN æ¶æ„ä¸é¢„è®­ç»ƒæ¨¡å‹åŠè¿ç§»å­¦ä¹ çš„å¯¹æ¯”åˆ†æï¼šåŸºäºäº”ä¸ª Bangladesh æ•°æ®é›†çš„ç ”ç©¶|Ibrahim Tanvir, Alif Ruslan, Sartaj Solaiman|<https://arxiv.org/pdf/2601.04352v1>|æ— |


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SCAR-GS: Spatial Context Attention for Residuals in Progressive Gaussian Splatting|SCAR-GS: æ¸è¿›å¼ Gaussian Splatting ä¸­æ®‹å·®çš„ç©ºé—´ä¸Šä¸‹æ–‡æ³¨æ„åŠ›|Diego Revilla, Pooja Suresh, Anand Bhojan, Ooi Wei Tsang|<https://arxiv.org/pdf/2601.04348v1>|æ— |
|ğŸ†• å‘å¸ƒ|PadÃ© Neurons for Efficient Neural Models|[ç¿»è¯‘å¤±è´¥] PadÃ© Neurons for Efficient Neural Models|Onur KeleÅŸ, A. Murat Tekalp|<https://arxiv.org/pdf/2601.04005v1>|[ä»£ç ](https://github.com/onur-keles/Paon.)|
|ğŸ†• å‘å¸ƒ|A low-complexity method for efficient depth-guided image deblurring|ä¸€ç§ç”¨äºé«˜æ•ˆæ·±åº¦å¼•å¯¼å›¾åƒå»æ¨¡ç³Šçš„ä½å¤æ‚åº¦æ–¹æ³•|Ziyao Yi, Diego Valsesia, Tiziano Bianchi, Enrico Magli|<https://arxiv.org/pdf/2601.03924v1>|æ— |
|ğŸ†• å‘å¸ƒ|PointWorld: Scaling 3D World Models for In-The-Wild Robotic Manipulation|PointWorld: æ‰©å±•ç”¨äºé‡å¤–æœºå™¨äººæ“ä½œçš„3Dä¸–ç•Œæ¨¡å‹|Wenlong Huang, Yu-Wei Chao, Arsalan Mousavian, Ming-Yu Liu, Dieter Fox, Kaichun Mo, Li Fei-Fei|<https://arxiv.org/pdf/2601.03782v1>|[ä»£ç ](https://point-world.github.io/.)|
|ğŸ†• å‘å¸ƒ|Persona-aware and Explainable Bikeability Assessment: A Vision-Language Model Approach|[ç¿»è¯‘å¤±è´¥] Persona-aware and Explainable Bikeability Assessment: A Vision-Language Model Approach|Yilong Dai, Ziyi Wang, Chenguang Wang, Kexin Zhou, Yiheng Qian, Susu Xu, Xiang Yan|<https://arxiv.org/pdf/2601.03534v1>|æ— |
|ğŸ†• å‘å¸ƒ|REFA: Real-time Egocentric Facial Animations for Virtual Reality|REFAï¼šç”¨äº Virtual Reality çš„å®æ—¶ Egocentric é¢éƒ¨åŠ¨ç”»|Qiang Zhang, Tong Xiao, Haroun Habeeb, Larissa Laich, Sofien Bouaziz, Patrick Snape, Wenjing Zhang, Matthew Cioffi .etc.|<https://arxiv.org/pdf/2601.03507v1>|æ— |


### æ¨ç†ä¼˜åŒ– (Inference Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|BEDS : Bayesian Emergent Dissipative Structures : A Formal Framework for Continuous Inference Under Energy Constraints|[ç¿»è¯‘å¤±è´¥] BEDS : Bayesian Emergent Dissipative Structures : A Formal Framework for Continuous Inference Under Energy Constraints|Laurent Caraffa|<https://arxiv.org/pdf/2601.02329v2>|æ— |


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### åˆ†å¸ƒå¤–æ³›åŒ– (Out-of-distribution Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|FLNet: Flood-Induced Agriculture Damage Assessment using Super Resolution of Satellite Images|FLNet: åˆ©ç”¨å«æ˜Ÿå›¾åƒè¶…åˆ†è¾¨ç‡æŠ€æœ¯è¯„ä¼°æ´ªæ°´å¼•å‘çš„å†œä¸šæŸå¤±|Sanidhya Ghosal, Anurag Sharma, Sushil Ghildiyal, Mukesh Saini|<https://arxiv.org/pdf/2601.03884v1>|æ— |
|ğŸ“ æ›´æ–°|Mitigating Label Noise using Prompt-Based Hyperbolic Meta-Learning in Open-Set Domain Generalization|ä½¿ç”¨åŸºäº Prompt çš„åŒæ›²å…ƒå­¦ä¹ ç¼“è§£å¼€æ”¾é›†åŸŸæ³›åŒ–ä¸­çš„æ ‡ç­¾å™ªå£°|Kunyu Peng, Di Wen, M. Saquib Sarfraz, Yufan Chen, Junwei Zheng, David Schneider, Kailun Yang, Jiamin Wu .etc.|<https://arxiv.org/pdf/2412.18342v2>|[ä»£ç ](https://github.com/KPeng9510/HyProMeta.)|


### ä¸ç¡®å®šæ€§é‡åŒ– (Uncertainty Quantification)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Data relativistic uncertainty framework for low-illumination anime scenery image enhancement|ä½å…‰ç…§åŠ¨æ¼«é£æ™¯å›¾åƒå¢å¼ºçš„æ•°æ®ç›¸å¯¹è®ºä¸ç¡®å®šæ€§æ¡†æ¶|Yiquan Gao, John See|<https://arxiv.org/pdf/2512.21944v2>|æ— |


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|From Preoperative CT to Postmastoidectomy Mesh Construction:1Mastoidectomy Shape Prediction for Cochlear Implant Surgery|[ç¿»è¯‘å¤±è´¥] From Preoperative CT to Postmastoidectomy Mesh Construction:1Mastoidectomy Shape Prediction for Cochlear Implant Surgery|Yike Zhang, Eduardo Davalos, Dingjie Su, Ange Lou, Jack Noble|<https://arxiv.org/pdf/2601.04405v1>|æ— |
|ğŸ“ æ›´æ–°|FedDUAL: A Dual-Strategy with Adaptive Loss and Dynamic Aggregation for Mitigating Data Heterogeneity in Federated Learning|FedDUALï¼šä¸€ç§å…·æœ‰è‡ªé€‚åº”æŸå¤±å’ŒåŠ¨æ€èšåˆçš„åŒç­–ç•¥ï¼Œç”¨äºç¼“è§£è”é‚¦å­¦ä¹ ä¸­çš„æ•°æ®å¼‚æ„æ€§|Pranab Sahoo, Ashutosh Tripathi, Sriparna Saha, Samrat Mondal|<https://arxiv.org/pdf/2412.04416v2>|æ— |
|ğŸ“ æ›´æ–°|An Overview of Prototype Formulations for Interpretable Deep Learning|å¯è§£é‡Šæ·±åº¦å­¦ä¹ ä¸­åŸå‹å…¬å¼ç»¼è¿°|Maximilian Xiling Li, Korbinian Franz Rudolf, Paul Mattes, Nils Blank, Rudolf Lioutikov|<https://arxiv.org/pdf/2410.08925v4>|æ— |
|ğŸ†• å‘å¸ƒ|MATANet: A Multi-context Attention and Taxonomy-Aware Network for Fine-Grained Underwater Recognition of Marine Species|MATANet: ç”¨äºæµ·æ´‹ç‰©ç§ç»†ç²’åº¦æ°´ä¸‹è¯†åˆ«çš„å¤šä¸Šä¸‹æ–‡æ³¨æ„åŠ›ä¸åˆ†ç±»æ„ŸçŸ¥ç½‘ç»œ|Donghwan Lee, Byeongjin Kim, Geunhee Kim, Hyukjin Kwon, Nahyeon Maeng, Wooju Kim|<https://arxiv.org/pdf/2601.03729v1>|[ä»£ç ](https://github.com/dhlee-work/fathomnet-cvpr2025-ssl)|


### é›¶/å°‘æ ·æœ¬æ³›åŒ– (Zero/Few-shot Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Name That Part: 3D Part Segmentation and Naming|[ç¿»è¯‘å¤±è´¥] Name That Part: 3D Part Segmentation and Naming|Soumava Paul, Prakhar Kaushik, Ankit Vaidya, Anand Bhattad, Alan Yuille|<https://arxiv.org/pdf/2512.18003v2>|æ— |
|ğŸ“ æ›´æ–°|DiFlow-TTS: Compact and Low-Latency Zero-Shot Text-to-Speech with Factorized Discrete Flow Matching|DiFlow-TTSï¼šåŸºäºåˆ†è§£ç¦»æ•£æµåŒ¹é…çš„ç´§å‡‘ä½å»¶è¿Ÿ Zero-Shot Text-to-Speech|Ngoc-Son Nguyen, Thanh V. T. Tran, Hieu-Nghia Huynh-Nguyen, Truong-Son Hy, Van Nguyen|<https://arxiv.org/pdf/2509.09631v3>|æ— |
|ğŸ“ æ›´æ–°|Generalized Logit Adjustment: Calibrating Fine-tuned Models by Removing Label Bias in Foundation Models|å¹¿ä¹‰ Logit Adjustmentï¼šé€šè¿‡ç§»é™¤ Foundation Models ä¸­çš„æ ‡ç­¾åå·®æ ¡å‡† Fine-tuned Models|Beier Zhu, Kaihua Tang, Qianru Sun, Hanwang Zhang|<https://arxiv.org/pdf/2310.08106v4>|[ä»£ç ](https://github.com/BeierZhu/GLA.)|


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Visual Merit or Linguistic Crutch? A Close Look at DeepSeek-OCR|[ç¿»è¯‘å¤±è´¥] Visual Merit or Linguistic Crutch? A Close Look at DeepSeek-OCR|Yunhao Liang, Ruixuan Ying, Bo Li, Hong Li, Kai Yan, Qingwen Li, Min Yang, Okamoto Satoshi .etc.|<https://arxiv.org/pdf/2601.03714v2>|[ä»£ç ](https://github.com/dududuck00/DeepSeekOCR.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|ImLoc: Revisiting Visual Localization with Image-based Representation|ImLoc: åŸºäºå›¾åƒè¡¨ç¤ºçš„è§†è§‰å®šä½å†æ¢|Xudong Jiang, Fangjinhua Wang, Silvano Galliani, Christoph Vogel, Marc Pollefeys|<https://arxiv.org/pdf/2601.04185v1>|[ä»£ç ](https://github.com/cvg/Hierarchical-Localization.)|
|ğŸ†• å‘å¸ƒ|Analyzing Reasoning Consistency in Large Multimodal Models under Cross-Modal Conflicts|åˆ†æè·¨æ¨¡æ€å†²çªä¸‹ Large Multimodal Models çš„æ¨ç†ä¸€è‡´æ€§|Zhihao Zhu, Jiafeng Liang, Shixin Jiang, Jinlan Fu, Ming Liu, Guanglu Sun, See-Kiong Ng, Bing Qin|<https://arxiv.org/pdf/2601.04073v1>|æ— |
|ğŸ†• å‘å¸ƒ|FocusUI: Efficient UI Grounding via Position-Preserving Visual Token Selection|FocusUI: é€šè¿‡ä½ç½®ä¿æŒçš„è§†è§‰ Token é€‰æ‹©å®ç°é«˜æ•ˆçš„ UI Grounding|Mingyu Ouyang, Kevin Qinghong Lin, Mike Zheng Shou, Hwee Tou Ng|<https://arxiv.org/pdf/2601.03928v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|HOLO: Homography-Guided Pose Estimator Network for Fine-Grained Visual Localization on SD Maps|HOLOï¼šç”¨äºSDåœ°å›¾ä¸Šç»†ç²’åº¦è§†è§‰å®šä½çš„å•åº”æ€§å¼•å¯¼ä½å§¿ä¼°è®¡ç½‘ç»œ|Xuchang Zhong, Xu Cao, Jinke Feng, Hao Fang|<https://arxiv.org/pdf/2601.02730v2>|æ— |
|ğŸ“ æ›´æ–°|WebGym: Scaling Training Environments for Visual Web Agents with Realistic Tasks|WebGymï¼šåˆ©ç”¨çœŸå®ä»»åŠ¡ä¸ºè§†è§‰ Web Agent æ‰©å±•è®­ç»ƒç¯å¢ƒ|Hao Bai, Alexey Taymanov, Tong Zhang, Aviral Kumar, Spencer Whitehead|<https://arxiv.org/pdf/2601.02439v2>|æ— |
|ğŸ“ æ›´æ–°|Are Vision Language Models Cross-Cultural Theory of Mind Reasoners?|Vision Language Models æ˜¯è·¨æ–‡åŒ–å¿ƒæ™ºç†è®ºæ¨ç†è€…å—ï¼Ÿ|Zabir Al Nazi, GM Shahariar, Md. Abrar Hossain, Wei Peng|<https://arxiv.org/pdf/2512.17394v2>|æ— |
|ğŸ“ æ›´æ–°|CaTS-Bench: Can Language Models Describe Time Series?|CaTS-Bench: Language Models èƒ½å¦æè¿° Time Seriesï¼Ÿ|Luca Zhou, Pratham Yashwante, Marshall Fisher, Alessio Sampieri, Zihao Zhou, Fabio Galasso, Rose Yu|<https://arxiv.org/pdf/2509.20823v3>|æ— |
|ğŸ“ æ›´æ–°|ChartAgent: A Multimodal Agent for Visually Grounded Reasoning in Complex Chart Question Answering|ChartAgent: ç”¨äºå¤æ‚å›¾è¡¨é—®ç­”ä¸­è§†è§‰å®šä½æ¨ç†çš„å¤šæ¨¡æ€ Agent|Rachneet Kaur, Nishan Srishankar, Zhen Zeng, Sumitra Ganesh, Manuela Veloso|<https://arxiv.org/pdf/2510.04514v2>|æ— |
|ğŸ†• å‘å¸ƒ|Can LLMs See Without Pixels? Benchmarking Spatial Intelligence from Textual Descriptions|LLM èƒ½åœ¨æ²¡æœ‰åƒç´ çš„æƒ…å†µä¸‹è¿›è¡Œè§†è§‰æ„ŸçŸ¥å—ï¼ŸåŸºäºæ–‡æœ¬æè¿°çš„ç©ºé—´æ™ºèƒ½åŸºå‡†æµ‹è¯•|Zhongbin Guo, Zhen Yang, Yushan Li, Xinyue Zhang, Wenyu Gao, Jiacheng Wang, Chengzhi Li, Xiangrui Liu .etc.|<https://arxiv.org/pdf/2601.03590v1>|[ä»£ç ](https://github.com/binisalegend/SiT-Bench)|
|ğŸ“ æ›´æ–°|Deep But Reliable: Advancing Multi-turn Reasoning for Thinking with Images|Deep But Reliable: æ¨è¿› Thinking with Images çš„å¤šè½®æ¨ç†|Wenhao Yang, Yu Xia, Jinlong Huang, Shiyin Lu, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang .etc.|<https://arxiv.org/pdf/2512.17306v2>|æ— |


### è·¨æ¨¡æ€æ£€ç´¢ä¸åŒ¹é… (Cross-modal Retrieval & Matching)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|e5-omni: Explicit Cross-modal Alignment for Omni-modal Embeddings|e5-omni: ç”¨äºOmni-modal Embeddingsçš„æ˜¾å¼è·¨æ¨¡æ€å¯¹é½|Haonan Chen, Sicheng Gao, Radu Timofte, Tetsuya Sakai, Zhicheng Dou|<https://arxiv.org/pdf/2601.03666v1>|æ— |


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|GeoReason: Aligning Thinking And Answering In Remote Sensing Vision-Language Models Via Logical Consistency Reinforcement Learning|GeoReason: é€šè¿‡é€»è¾‘ä¸€è‡´æ€§å¼ºåŒ–å­¦ä¹ å¯¹é½é¥æ„Ÿè§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„æ€è€ƒä¸å›ç­”|Wenshuai Li, Xiantai Xiang, Zixiao Wen, Guangyao Zhou, Ben Niu, Feng Wang, Lijia Huang, Qiantong Wang .etc.|<https://arxiv.org/pdf/2601.04118v2>|æ— |
|ğŸ†• å‘å¸ƒ|Pixel-Wise Multimodal Contrastive Learning for Remote Sensing Images|[ç¿»è¯‘å¤±è´¥] Pixel-Wise Multimodal Contrastive Learning for Remote Sensing Images|Leandro Stival, Ricardo da Silva Torres, Helio Pedrini|<https://arxiv.org/pdf/2601.04127v1>|æ— |
|ğŸ†• å‘å¸ƒ|CloudMatch: Weak-to-Strong Consistency Learning for Semi-Supervised Cloud Detection|CloudMatchï¼šç”¨äºåŠç›‘ç£äº‘æ£€æµ‹çš„å¼±åˆ°å¼ºä¸€è‡´æ€§å­¦ä¹ |Jiayi Zhao, Changlu Chen, Jingsheng Li, Tianxiang Xue, Kun Zhan|<https://arxiv.org/pdf/2601.03528v1>|æ— |
|ğŸ†• å‘å¸ƒ|CroBIM-U: Uncertainty-Driven Referring Remote Sensing Image Segmentation|CroBIM-U: ä¸ç¡®å®šæ€§é©±åŠ¨çš„æŒ‡ä»£é¥æ„Ÿå›¾åƒåˆ†å‰²|Yuzhe Sun, Zhe Dong, Haochen Jiang, Tianzhu Liu, Yanfeng Gu|<https://arxiv.org/pdf/2601.03490v1>|æ— |


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|UniDrive-WM: Unified Understanding, Planning and Generation World Model For Autonomous Driving|UniDrive-WMï¼šç”¨äºè‡ªåŠ¨é©¾é©¶çš„ç»Ÿä¸€ç†è§£ã€è§„åˆ’å’Œç”Ÿæˆä¸–ç•Œæ¨¡å‹|Zhexiao Xiong, Xin Ye, Burhan Yaman, Sheng Cheng, Yiren Lu, Jingru Luo, Nathan Jacobs, Liu Ren|<https://arxiv.org/pdf/2601.04453v1>|[ä»£ç ](https://unidrive-wm.github.io/UniDrive-WM)|
|ğŸ“ æ›´æ–°|Comparative Analysis of Binarization Methods For Medical Image Hashing On Odir Dataset|ODIRæ•°æ®é›†ä¸ŠåŒ»å­¦å›¾åƒå“ˆå¸ŒäºŒå€¼åŒ–æ–¹æ³•çš„æ¯”è¾ƒåˆ†æ|Nedim Muzoglu|<https://arxiv.org/pdf/2601.02564v2>|æ— |
|ğŸ†• å‘å¸ƒ|MORPHFED: Federated Learning for Cross-institutional Blood Morphology Analysis|MORPHFED: ç”¨äºè·¨æœºæ„è¡€æ¶²å½¢æ€åˆ†æçš„è”é‚¦å­¦ä¹ |Gabriel Ansah, Eden Ruffell, Delmiro Fernandez-Reyes, Petru Manescu|<https://arxiv.org/pdf/2601.04121v1>|æ— |
|ğŸ“ æ›´æ–°|Plasticine: A Traceable Diffusion Model for Medical Image Translation|[ç¿»è¯‘å¤±è´¥] Plasticine: A Traceable Diffusion Model for Medical Image Translation|Tianyang Zhang, Xinxing Cheng, Jun Cheng, Shaoming Zheng, He Zhao, Huazhu Fu, Alejandro F Frangi, Jiang Liu .etc.|<https://arxiv.org/pdf/2512.18455v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Staged Voxel-Level Deep Reinforcement Learning for 3D Medical Image Segmentation with Noisy Annotations|ç”¨äºå«å™ªæ ‡æ³¨ 3D åŒ»å­¦å›¾åƒåˆ†å‰²çš„åˆ†é˜¶æ®µä½“ç´ çº§æ·±åº¦å¼ºåŒ–å­¦ä¹ |Yuyang Fu, Xiuzhen Guo, Ji Shi|<https://arxiv.org/pdf/2601.03875v1>|æ— |
|ğŸ†• å‘å¸ƒ|RadDiff: Describing Differences in Radiology Image Sets with Natural Language|RadDiff: ç”¨è‡ªç„¶è¯­è¨€æè¿°æ”¾å°„å­¦å›¾åƒé›†çš„å·®å¼‚|Xiaoxian Shen, Yuhui Zhang, Sahithi Ankireddy, Xiaohan Wang, Maya Varma, Henry Guo, Curtis Langlotz, Serena Yeung-Levy|<https://arxiv.org/pdf/2601.03733v1>|æ— |
|ğŸ“ æ›´æ–°|Efficient 3D affinely equivariant CNNs with adaptive fusion of augmented spherical Fourier-Bessel bases|å…·æœ‰å¢å¼ºçƒé¢å‚…é‡Œå¶-è´å¡å°”åŸºè‡ªé€‚åº”èåˆçš„é«˜æ•ˆ 3D ä»¿å°„ç­‰å˜ CNN|Wenzhao Zhao, Steffen Albert, Barbara D. Wichtmann, Angelika Maurer, Ulrike Attenberger, Frank G. ZÃ¶llner, JÃ¼rgen Hesser|<https://arxiv.org/pdf/2402.16825v5>|[ä»£ç ](https://github.com/ZhaoWenzhao/WMCSFB.)|
|ğŸ“ æ›´æ–°|WeatherDiffusion: Controllable Weather Editing in Intrinsic Space|WeatherDiffusion: Intrinsic Spaceä¸­çš„å¯æ§å¤©æ°”ç¼–è¾‘|Yixin Zhu, Zuoliang Zhu, Jian Yang, MiloÅ¡ HaÅ¡an, Jin Xie, Beibei Wang|<https://arxiv.org/pdf/2508.06982v5>|æ— |
|ğŸ†• å‘å¸ƒ|Adaptive Attention Distillation for Robust Few-Shot Segmentation under Environmental Perturbations|ç¯å¢ƒæ‰°åŠ¨ä¸‹é²æ£’Few-Shotåˆ†å‰²çš„è‡ªé€‚åº”æ³¨æ„åŠ›è’¸é¦|Qianyu Guo, Jingrong Wu, Jieji Ren, Weifeng Ge, Wenqiang Zhang|<https://arxiv.org/pdf/2601.03596v1>|[ä»£ç ](https://github.com/guoqianyu-alberta/Adaptive-Attention-Distillation-for-FSS.)|
|ğŸ†• å‘å¸ƒ|GeoDiff-SAR: A Geometric Prior Guided Diffusion Model for SAR Image Generation|GeoDiff-SAR: ä¸€ç§å‡ ä½•å…ˆéªŒå¼•å¯¼çš„SARå›¾åƒç”Ÿæˆæ‰©æ•£æ¨¡å‹|Fan Zhang, Xuanting Wu, Fei Ma, Qiang Yin, Yuxin Hu|<https://arxiv.org/pdf/2601.03499v1>|æ— |
|ğŸ“ æ›´æ–°|Learn2Reg 2024: New Benchmark Datasets Driving Progress on New Challenges|Learn2Reg 2024ï¼šæ¨åŠ¨æ–°æŒ‘æˆ˜è¿›å±•çš„æ–°åŸºå‡†æ•°æ®é›†|Lasse Hansen, Wiebke Heyer, Christoph GroÃŸbrÃ¶hmer, Frederic Madesta, Thilo Sentker, Wang Jiazheng, Yuxi Zhang, Hang Zhang .etc.|<https://arxiv.org/pdf/2509.01217v3>|æ— |


### æ™ºèƒ½äº¤é€šè§†è§‰ (Intelligent Transportation Vision)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|From Human Intention to Action Prediction: Intention-Driven End-to-End Autonomous Driving|ä»äººç±»æ„å›¾åˆ°åŠ¨ä½œé¢„æµ‹ï¼šæ„å›¾é©±åŠ¨çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶|Huan Zheng, Yucheng Zhou, Tianyi Yan, Jiayi Su, Hongjun Chen, Dubing Chen, Xingtai Gui, Wencheng Han .etc.|<https://arxiv.org/pdf/2512.12302v2>|æ— |


## æ–°å…´ç†è®ºä¸è·¨å­¦ç§‘æ–¹å‘ (Emerging Theory & Interdisciplinary Directions)


### é‡å­è§†è§‰ç®—æ³• (Quantum Visual Algorithms)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SDCD: Structure-Disrupted Contrastive Decoding for Mitigating Hallucinations in Large Vision-Language Models|SDCD: ç”¨äºç¼“è§£ Large Vision-Language Models å¹»è§‰çš„ç»“æ„ç ´åå¯¹æ¯”è§£ç |Yuxuan Xia, Siheng Wang, Peng Li|<https://arxiv.org/pdf/2601.03500v1>|æ— |


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|$\mathbf{S^2LM}$: Towards Semantic Steganography via Large Language Models|[ç¿»è¯‘å¤±è´¥] $\mathbf{S^2LM}$: Towards Semantic Steganography via Large Language Models|Huanqi Wu, Huangbiao Xu, Runfeng Xie, Jiaxin Cai, Kaixin Zhang, Xiao Ke|<https://arxiv.org/pdf/2511.05319v2>|æ— |
|ğŸ“ æ›´æ–°|SpatialTree: How Spatial Abilities Branch Out in MLLMs|SpatialTree: ç©ºé—´èƒ½åŠ›å¦‚ä½•åœ¨ MLLMs ä¸­å‘å±•|Yuxi Xiao, Longfei Li, Shen Yan, Xinhang Liu, Sida Peng, Yunchao Wei, Xiaowei Zhou, Bingyi Kang|<https://arxiv.org/pdf/2512.20617v2>|æ— |
|ğŸ“ æ›´æ–°|PhysDepth: Plug-and-Play Physical Refinement for Monocular Depth Estimation in Challenging Environments|PhysDepth: é¢å‘æŒ‘æˆ˜æ€§ç¯å¢ƒä¸‹å•ç›®æ·±åº¦ä¼°è®¡çš„å³æ’å³ç”¨ç‰©ç†ä¼˜åŒ–|Kebin Peng, Haotang Li, Zhenyu Qi, Huashan Chen, Zi Wang, Wei Zhang, Sen He, Huanrui Yang .etc.|<https://arxiv.org/pdf/2412.04666v3>|åˆ†æå¤±è´¥|

