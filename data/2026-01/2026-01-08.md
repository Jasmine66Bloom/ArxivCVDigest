## [UPDATED!] **2026-01-08** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Pixel-Perfect Visual Geometry Estimation|Pixel-Perfect è§†è§‰å‡ ä½•ä¼°è®¡|Gangwei Xu, Haotong Lin, Hongcheng Luo, Haiyang Sun, Bing Wang, Guang Chen, Sida Peng, Hangjun Ye .etc.|<https://arxiv.org/pdf/2601.05246v1>|æ— |
|ğŸ†• å‘å¸ƒ|A Lightweight and Explainable Vision-Language Framework for Crop Disease Visual Question Answering|ä¸€ç§è½»é‡çº§ä¸”å¯è§£é‡Šçš„è§†è§‰-è¯­è¨€æ¡†æ¶ï¼Œç”¨äºä½œç‰©ç—…å®³è§†è§‰é—®ç­”|Md. Zahid Hossain, Most. Sharmin Sultana Samu, Md. Rakibul Islam, Md. Siam Ansary|<https://arxiv.org/pdf/2601.05143v1>|æ— |
|ğŸ“ æ›´æ–°|POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering|POLYCHARTQAï¼šåˆ©ç”¨å¤šè¯­è¨€å›¾è¡¨é—®ç­”è¯„ä¼° Large Vision-Language Models|Yichen Xu, Liangyu Chen, Liang Zhang, Jianzhe Ma, Wenxuan Wang, Qin Jin|<https://arxiv.org/pdf/2507.11939v2>|æ— |
|ğŸ†• å‘å¸ƒ|Driving on Registers|åŸºäºå¯„å­˜å™¨çš„é©¾é©¶|Ellington Kirby, Alexandre Boulch, Yihong Xu, Yuan Yin, Gilles Puy, Ã‰loi Zablocki, Andrei Bursuc, Spyros Gidaris .etc.|<https://arxiv.org/pdf/2601.05083v1>|æ— |
|ğŸ†• å‘å¸ƒ|Scaling Vision Language Models for Pharmaceutical Long Form Video Reasoning on Industrial GenAI Platform|é¢å‘å·¥ä¸š GenAI å¹³å°çš„åˆ¶è¯é•¿è§†é¢‘æ¨ç†çš„ Vision Language Models æ‰©å±•|Suyash Mishra, Qiang Li, Srikanth Patil, Satyanarayan Pati, Baddu Narendra|<https://arxiv.org/pdf/2601.04891v1>|æ— |
|ğŸ“ æ›´æ–°|MoIIE: Mixture of Intra- and Inter-Modality Experts for Large Vision Language Models|MoIIE: ç”¨äº Large Vision Language Models çš„ Intra- å’Œ Inter-Modality Experts æ··åˆ|Dianyi Wang, Siyuan Wang, Zejun Li, Yikun Wang, Yitong Li, Duyu Tang, Xiaoyu Shen, Xuanjing Huang .etc.|<https://arxiv.org/pdf/2508.09779v2>|[ä»£ç ](https://github.com/AlenjandroWang/MoIIE.)|


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Cutting AI Research Costs: How Task-Aware Compression Makes Large Language Model Agents Affordable|é™ä½ AI ç ”ç©¶æˆæœ¬ï¼šTask-Aware Compression å¦‚ä½•è®© Large Language Model Agents å˜å¾—å®æƒ |Zuhair Ahmed Khan Taha, Mohammed Mudassir Uddin, Shahnawaz Alam|<https://arxiv.org/pdf/2601.05191v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Atlas 2 -- Foundation models for clinical deployment|Atlas 2 -- ç”¨äºä¸´åºŠéƒ¨ç½²çš„åŸºç¡€æ¨¡å‹|Maximilian Alber, Timo Milbich, Alexandra Carpen-Amarie, Stephan Tietz, Jonas Dippel, Lukas Muttenthaler, Beatriz Perez Cancer, Alessandro Benetti .etc.|<https://arxiv.org/pdf/2601.05148v1>|æ— |
|ğŸ†• å‘å¸ƒ|VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control|VerseCrafter: å…·æœ‰4Då‡ ä½•æ§åˆ¶çš„åŠ¨æ€é€¼çœŸè§†é¢‘ä¸–ç•Œæ¨¡å‹|Sixiao Zheng, Minghao Yin, Wenbo Hu, Xiaoyu Li, Ying Shan, Yanwei Fu|<https://arxiv.org/pdf/2601.05138v1>|æ— |
|ğŸ†• å‘å¸ƒ|UniLiPs: Unified LiDAR Pseudo-Labeling with Geometry-Grounded Dynamic Scene Decomposition|UniLiPs: åŸºäºå‡ ä½•é”šå®šçš„åŠ¨æ€åœºæ™¯åˆ†è§£çš„ç»Ÿä¸€ LiDAR ä¼ªæ ‡ç­¾ç”Ÿæˆ|Filippo Ghilotti, Samuel Brucker, Nahku Saidy, Matteo Matteucci, Mario Bijelic, Felix Heide|<https://arxiv.org/pdf/2601.05105v1>|æ— |
|ğŸ“ æ›´æ–°|UniCorn: Towards Self-Improving Unified Multimodal Models through Self-Generated Supervision|UniCorn: é€šè¿‡è‡ªç”Ÿæˆç›‘ç£è¿ˆå‘è‡ªæ”¹è¿›çš„ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹|Ruiyan Han, Zhen Fang, XinYu Sun, Yuchen Ma, Ziheng Wang, Yu Zeng, Zehui Chen, Lin Chen .etc.|<https://arxiv.org/pdf/2601.03193v2>|æ— |
|ğŸ†• å‘å¸ƒ|SOVABench: A Vehicle Surveillance Action Retrieval Benchmark for Multimodal Large Language Models|SOVABench: é¢å‘å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„è½¦è¾†ç›‘æ§åŠ¨ä½œæ£€ç´¢åŸºå‡†|Oriol Rabasseda, Zenjie Li, Kamal Nasrollahi, Sergio Escalera|<https://arxiv.org/pdf/2601.04824v1>|æ— |
|ğŸ†• å‘å¸ƒ|PyramidalWan: On Making Pretrained Video Model Pyramidal for Efficient Inference|PyramidalWan: è®ºä½¿é¢„è®­ç»ƒè§†é¢‘æ¨¡å‹é‡‘å­—å¡”åŒ–ä»¥å®ç°é«˜æ•ˆæ¨ç†|Denis Korzhenkov, Adil Karjauv, Animesh Karnewar, Mohsen Ghafoorian, Amirhossein Habibian|<https://arxiv.org/pdf/2601.04792v1>|[ä»£ç ](https://qualcomm-ai-research.github.io/PyramidalWan.)|
|ğŸ†• å‘å¸ƒ|GeM-VG: Towards Generalized Multi-image Visual Grounding with Multimodal Large Language Models|GeM-VGï¼šåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹è¿ˆå‘å¹¿ä¹‰å¤šå›¾åƒè§†è§‰å®šä½|Shurong Zheng, Yousong Zhu, Hongyin Zhao, Fan Yang, Yufei Zhan, Ming Tang, Jinqiao Wang|<https://arxiv.org/pdf/2601.04777v1>|æ— |
|ğŸ†• å‘å¸ƒ|Skeletonization-Based Adversarial Perturbations on Large Vision Language Model's Mathematical Text Recognition|åŸºäºéª¨æ¶åŒ–çš„ Large Vision Language Model æ•°å­¦æ–‡æœ¬è¯†åˆ«å¯¹æŠ—æ‰°åŠ¨|Masatomo Yoshida, Haruto Namura, Nicola Adami, Masahiro Okuda|<https://arxiv.org/pdf/2601.04752v1>|æ— |
|ğŸ“ æ›´æ–°|SynDroneVision: A Synthetic Dataset for Image-Based Drone Detection|SynDroneVision: ä¸€ä¸ªç”¨äºåŸºäºå›¾åƒçš„æ— äººæœºæ£€æµ‹çš„åˆæˆæ•°æ®é›†|Tamara R. Lenhard, Andreas Weinmann, Kai Franke, Tobias Koch|<https://arxiv.org/pdf/2411.05633v2>|æ— |


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Prototypicality Bias Reveals Blindspots in Multimodal Evaluation Metrics|Prototypicality Bias æ­ç¤ºäº†å¤šæ¨¡æ€è¯„ä¼°æŒ‡æ ‡çš„ç›²åŒº|Subhadeep Roy, Gagan Bhatia, Steffen Eger|<https://arxiv.org/pdf/2601.04946v1>|æ— |
|ğŸ†• å‘å¸ƒ|Forge-and-Quench: Enhancing Image Generation for Higher Fidelity in Unified Multimodal Models|Forge-and-Quenchï¼šå¢å¼ºç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹ä¸­çš„å›¾åƒç”Ÿæˆä»¥å®ç°æ›´é«˜ä¿çœŸåº¦|Yanbing Zeng, Jia Wang, Hanghang Ma, Junqiang Wu, Jie Zhu, Xiaoming Wei, Jie Hu|<https://arxiv.org/pdf/2601.04706v1>|[ä»£ç ](https://github.com/YanbingZeng/Forge-and-Quench.)|
|ğŸ“ æ›´æ–°|Forging Spatial Intelligence: A Roadmap of Multi-Modal Data Pre-Training for Autonomous Systems|é”»é€ ç©ºé—´æ™ºèƒ½ï¼šé¢å‘è‡ªä¸»ç³»ç»Ÿçš„å¤šæ¨¡æ€æ•°æ®é¢„è®­ç»ƒè·¯çº¿å›¾|Song Wang, Lingdong Kong, Xiaolu Liu, Hao Shi, Wentong Li, Jianke Zhu, Steven C. H. Hoi|<https://arxiv.org/pdf/2512.24385v2>|æ— |
|ğŸ“ æ›´æ–°|Simulation of prosthetic vision with PRIMA system and enhancement of face representation|åŸºäº PRIMA ç³»ç»Ÿçš„å‡ä½“è§†è§‰æ¨¡æ‹Ÿä¸äººè„¸è¡¨ç¤ºå¢å¼º|Anna Kochnev Goldstein, Jungyeon Park, Yueming Zhuo, Nathan Jensen, Daniel Palanker|<https://arxiv.org/pdf/2503.11677v3>|æ— |


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### è¯­ä¹‰/å®ä¾‹åˆ†å‰² (Semantic/Instance Segmentation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Full segmentation annotations of 3D time-lapse microscopy images of MDA231 cells|MDA231ç»†èƒ3Då»¶æ—¶æ˜¾å¾®é•œå›¾åƒçš„å®Œæ•´åˆ†å‰²æ ‡æ³¨|Aleksandra Melnikova, Petr Matula|<https://arxiv.org/pdf/2510.10797v2>|æ— |
|ğŸ†• å‘å¸ƒ|DB-MSMUNet:Dual Branch Multi-scale Mamba UNet for Pancreatic CT Scans Segmentation|DB-MSMUNet:ç”¨äºèƒ°è…ºCTæ‰«æåˆ†å‰²çš„åŒåˆ†æ”¯å¤šå°ºåº¦Mamba UNet|Qiu Guan, Zhiqiang Yang, Dezhang Ye, Yang Chen, Xinli Xu, Ying Tang|<https://arxiv.org/pdf/2601.04676v1>|æ— |


### ç›®æ ‡æ£€æµ‹ä¸å®šä½ (Object Detection & Localization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Higher-Order Adversarial Patches for Real-Time Object Detectors|é¢å‘å®æ—¶ç›®æ ‡æ£€æµ‹å™¨çš„é«˜é˜¶å¯¹æŠ—è¡¥ä¸|Jens Bayer, Stefan Becker, David MÃ¼nch, Michael Arens, JÃ¼rgen Beyerer|<https://arxiv.org/pdf/2601.04991v1>|[ä»£ç ](https://github.com/JensBayer/HigherOrder)|
|ğŸ“ æ›´æ–°|From Dataset to Real-world: General 3D Object Detection via Generalized Cross-domain Few-shot Learning|[ç¿»è¯‘å¤±è´¥] From Dataset to Real-world: General 3D Object Detection via Generalized Cross-domain Few-shot Learning|Shuangzhi Li, Junlong Shen, Lei Ma, Xingyu Li|<https://arxiv.org/pdf/2503.06282v2>|æ— |


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Character Detection using YOLO for Writer Identification in multiple Medieval books|ä½¿ç”¨YOLOè¿›è¡Œå¤šæœ¬ä¸­ä¸–çºªä¹¦ç±ä¸­ç”¨äºä½œè€…èº«ä»½è¯†åˆ«çš„å­—ç¬¦æ£€æµ‹|Alessandra Scotto di Freca, Tiziana D Alessandro, Francesco Fontanella, Filippo Sarria, Claudio De Stefano|<https://arxiv.org/pdf/2601.04834v1>|æ— |
|ğŸ“ æ›´æ–°|TRec: Egocentric Action Recognition using 2D Point Tracks|TRecï¼šä½¿ç”¨2Dç‚¹è½¨è¿¹è¿›è¡Œä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„åŠ¨ä½œè¯†åˆ«|Dennis Holzmann, Sven Wachsmuth|<https://arxiv.org/pdf/2601.03667v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Detection of Deployment Operational Deviations for Safety and Security of AI-Enabled Human-Centric Cyber Physical Systems|é¢å‘å®‰å…¨çš„äººå·¥æ™ºèƒ½èµ‹èƒ½äººæœºä¿¡æ¯ç‰©ç†ç³»ç»Ÿéƒ¨ç½²æ“ä½œåå·®æ£€æµ‹|Bernard Ngabonziza, Ayan Banerjee, Sandeep K. S. Gupta|<https://arxiv.org/pdf/2601.04605v1>|æ— |
|ğŸ“ æ›´æ–°|Probing Deep into Temporal Profile Makes the Infrared Small Target Detector Much Better|æ·±å…¥æ¢ç©¶æ—¶é—´ç‰¹å¾ä½¿çº¢å¤–å°ç›®æ ‡æ£€æµ‹å™¨æ€§èƒ½æ˜¾è‘—æå‡|Ruojing Li, Wei An, Yingqian Wang, Xinyi Ying, Yimian Dai, Longguang Wang, Miao Li, Yulan Guo .etc.|<https://arxiv.org/pdf/2506.12766v2>|[ä»£ç ](https://github.com/TinaLRJ/DeepPro.)|


### å›¾åƒåˆ†ç±»ä¸è¯†åˆ« (Image Classification & Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Integrated Framework for Selecting and Enhancing Ancient Marathi Inscription Images from Stone, Metal Plate, and Paper Documents|ç”¨äºä»çŸ³åˆ»ã€é‡‘å±æ¿å’Œçº¸è´¨æ–‡æ¡£ä¸­é€‰æ‹©å’Œå¢å¼ºå¤Marathié“­æ–‡å›¾åƒçš„é›†æˆæ¡†æ¶|Bapu D. Chendage, Rajivkumar S. Mente|<https://arxiv.org/pdf/2601.04800v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Explainable Binary Classification of Separable Shape Ensembles|å¯è§£é‡Šçš„å¯åˆ†ç¦»å½¢çŠ¶é›†åˆäºŒåˆ†ç±»|Zachary Grey, Nicholas Fisher, Andrew Glaws|<https://arxiv.org/pdf/2410.12994v2>|æ— |
|ğŸ“ æ›´æ–°|DermaCon-IN: A Multi-concept Annotated Dermatological Image Dataset of Indian Skin Disorders for Clinical AI Research|DermaCon-INï¼šä¸€ä¸ªç”¨äºä¸´åºŠAIç ”ç©¶çš„å°åº¦çš®è‚¤ç–¾ç—…å¤šæ¦‚å¿µæ ‡æ³¨çš®è‚¤ç§‘å›¾åƒæ•°æ®é›†|Shanawaj S Madarkar, Mahajabeen Madarkar, Madhumitha Venkatesh, Deepanshu Bansal, Teli Prakash, Konda Reddy Mopuri, Vinaykumar MV, KVL Sathwika .etc.|<https://arxiv.org/pdf/2506.06099v2>|æ— |


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Mesh4D: 4D Mesh Reconstruction and Tracking from Monocular Video|Mesh4Dï¼šä»å•ç›®è§†é¢‘è¿›è¡Œ4Dç½‘æ ¼é‡å»ºä¸è·Ÿè¸ª|Zeren Jiang, Chuanxia Zheng, Iro Laina, Diane Larlus, Andrea Vedaldi|<https://arxiv.org/pdf/2601.05251v1>|æ— |
|ğŸ†• å‘å¸ƒ|VideoAuto-R1: Video Auto Reasoning via Thinking Once, Answering Twice|VideoAuto-R1: é€šè¿‡æ€è€ƒä¸€æ¬¡ã€å›ç­”ä¸¤æ¬¡å®ç°è§†é¢‘è‡ªåŠ¨æ¨ç†|Shuming Liu, Mingchen Zhuge, Changsheng Zhao, Jun Chen, Lemeng Wu, Zechun Liu, Chenchen Zhu, Zhipeng Cai .etc.|<https://arxiv.org/pdf/2601.05175v1>|æ— |
|ğŸ†• å‘å¸ƒ|Patch-based Representation and Learning for Efficient Deformation Modeling|åŸºäºPatchçš„è¡¨ç¤ºä¸å­¦ä¹ ç”¨äºé«˜æ•ˆå˜å½¢å»ºæ¨¡|Ruochen Chen, Thuy Tran, Shaifali Parashar|<https://arxiv.org/pdf/2601.05035v1>|æ— |
|ğŸ†• å‘å¸ƒ|TEA: Temporal Adaptive Satellite Image Semantic Segmentation|TEAï¼šæ—¶é—´è‡ªé€‚åº”å«æ˜Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²|Juyuan Kang, Hao Zhu, Yan Zhu, Wei Zhang, Jianing Chen, Tianxiang Xiao, Yike Ma, Hao Jiang .etc.|<https://arxiv.org/pdf/2601.04956v1>|æ— |
|ğŸ“ æ›´æ–°|BlurDM: A Blur Diffusion Model for Image Deblurring|BlurDM: ç”¨äºå›¾åƒå»æ¨¡ç³Šçš„æ¨¡ç³Šæ‰©æ•£æ¨¡å‹|Jin-Ting He, Fu-Jen Tsai, Yan-Tsung Peng, Min-Hung Chen, Chia-Wen Lin, Yen-Yu Lin|<https://arxiv.org/pdf/2512.03979v3>|[ä»£ç ](https://jin-ting-he.github.io/BlurDM)|
|ğŸ“ æ›´æ–°|Novel View Synthesis using DDIM Inversion|ä½¿ç”¨ DDIM Inversion çš„æ–°è§†è§’åˆæˆ|Sehajdeep Singh, A V Subramanyam, Aditya Gupta, Sahil Gupta|<https://arxiv.org/pdf/2508.10688v2>|æ— |
|ğŸ†• å‘å¸ƒ|Measurement-Consistent Langevin Corrector: A Remedy for Latent Diffusion Inverse Solvers|Measurement-Consistent Langevin Corrector: Latent Diffusion é€†å‘æ±‚è§£å™¨çš„ä¸€ç§è¡¥æ•‘æ–¹æ³•|Lee Hyoseok, Sohwi Lim, Eunju Cha, Tae-Hyun Oh|<https://arxiv.org/pdf/2601.04791v1>|æ— |
|ğŸ†• å‘å¸ƒ|Defocus Aberration Theory Confirms Gaussian Model in Most Imaging Devices|[ç¿»è¯‘å¤±è´¥] Defocus Aberration Theory Confirms Gaussian Model in Most Imaging Devices|Akbar Saadat|<https://arxiv.org/pdf/2601.04779v1>|æ— |
|ğŸ†• å‘å¸ƒ|HATIR: Heat-Aware Diffusion for Turbulent Infrared Video Super-Resolution|HATIR: é¢å‘çƒ­æ„ŸçŸ¥çš„æ¹æµçº¢å¤–è§†é¢‘è¶…åˆ†è¾¨ç‡æ‰©æ•£|Yang Zou, Xingyue Zhu, Kaiqi Han, Jun Ma, Xingyuan Li, Zhiying Jiang, Jinyuan Liu|<https://arxiv.org/pdf/2601.04682v1>|[ä»£ç ](https://github.com/JZ0606/HATIR)|
|ğŸ“ æ›´æ–°|Mind the Generative Details: Direct Localized Detail Preference Optimization for Video Diffusion Models|[ç¿»è¯‘å¤±è´¥] Mind the Generative Details: Direct Localized Detail Preference Optimization for Video Diffusion Models|Zitong Huang, Kaidong Zhang, Yukang Ding, Chao Gao, Rui Ding, Ying Chen, Wangmeng Zuo|<https://arxiv.org/pdf/2601.04068v2>|æ— |
|ğŸ†• å‘å¸ƒ|Towards Spatio-Temporal Extrapolation of Phase-Field Simulations with Convolution-Only Neural Networks|[ç¿»è¯‘å¤±è´¥] Towards Spatio-Temporal Extrapolation of Phase-Field Simulations with Convolution-Only Neural Networks|Christophe Bonneville, Nathan Bieberdorf, Pieterjan Robbe, Mark Asta, Habib Najm, Laurent Capolungo, Cosmin Safta|<https://arxiv.org/pdf/2601.04510v1>|æ— |


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|GREx: Generalized Referring Expression Segmentation, Comprehension, and Generation|GREx: å¹¿ä¹‰æŒ‡ä»£è¡¨è¾¾åˆ†å‰²ã€ç†è§£ä¸ç”Ÿæˆ|Henghui Ding, Chang Liu, Shuting He, Xudong Jiang, Yu-Gang Jiang|<https://arxiv.org/pdf/2601.05244v1>|[ä»£ç ](https://henghuiding.github.io/GREx.)|
|ğŸ“ æ›´æ–°|Leveraging Clinical Text and Class Conditioning for 3D Prostate MRI Generation|åˆ©ç”¨ä¸´åºŠæ–‡æœ¬å’Œç±»åˆ«æ¡ä»¶è¿›è¡Œ 3D å‰åˆ—è…º MRI ç”Ÿæˆ|Emerson P. Grabke, Babak Taati, Masoom A. Haider|<https://arxiv.org/pdf/2506.10230v3>|æ— |
|ğŸ†• å‘å¸ƒ|RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation|RoboVIPï¼šåˆ©ç”¨è§†è§‰èº«ä»½æç¤ºçš„å¤šè§†è§’è§†é¢‘ç”Ÿæˆå¢å¼ºæœºå™¨äººæ“ä½œ|Boyang Wang, Haoran Zhang, Shujie Zhang, Jinkun Hao, Mingda Jia, Qi Lv, Yucheng Mao, Zhaoyang Lyu .etc.|<https://arxiv.org/pdf/2601.05241v1>|æ— |
|ğŸ†• å‘å¸ƒ|Plenoptic Video Generation|[ç¿»è¯‘å¤±è´¥] Plenoptic Video Generation|Xiao Fu, Shitao Tang, Min Shi, Xian Liu, Jinwei Gu, Ming-Yu Liu, Dahua Lin, Chen-Hsuan Lin|<https://arxiv.org/pdf/2601.05239v1>|æ— |
|ğŸ†• å‘å¸ƒ|FlowLet: Conditional 3D Brain MRI Synthesis using Wavelet Flow Matching|FlowLet: ä½¿ç”¨ Wavelet Flow Matching è¿›è¡Œæ¡ä»¶ 3D è„‘éƒ¨ MRI åˆæˆ|Danilo Danese, Angela Lombardi, Matteo Attimonelli, Giuseppe Fasano, Tommaso Di Noia|<https://arxiv.org/pdf/2601.05212v1>|æ— |
|ğŸ†• å‘å¸ƒ|GenAI-DrawIO-Creator: A Framework for Automated Diagram Generation|GenAI-DrawIO-Creatorï¼šä¸€ä¸ªè‡ªåŠ¨ç”Ÿæˆå›¾è¡¨çš„æ¡†æ¶|Jinze Yu, Dayuan Jiang|<https://arxiv.org/pdf/2601.05162v1>|æ— |
|ğŸ†• å‘å¸ƒ|Multi-Scale Local Speculative Decoding for Image Generation|ç”¨äºå›¾åƒç”Ÿæˆçš„å¤šå°ºåº¦å±€éƒ¨æ¨æµ‹è§£ç |Elia Peruzzo, Guillaume SautiÃ¨re, Amirhossein Habibian|<https://arxiv.org/pdf/2601.05149v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Re-Align: Structured Reasoning-guided Alignment for In-Context Image Generation and Editing|Re-Align: ç»“æ„åŒ–æ¨ç†å¼•å¯¼çš„ In-Context å›¾åƒç”Ÿæˆä¸ç¼–è¾‘å¯¹é½|Runze He, Yiji Cheng, Tiankai Hang, Zhimin Li, Yu Xu, Zijin Yin, Shiyi Zhang, Wenxun Dai .etc.|<https://arxiv.org/pdf/2601.05124v1>|æ— |
|ğŸ†• å‘å¸ƒ|Scalable neural pushbroom architectures for real-time denoising of hyperspectral images onboard satellites|ç”¨äºå«æ˜Ÿä¸Šé«˜å…‰è°±å›¾åƒå®æ—¶å»å™ªçš„å¯æ‰©å±•ç¥ç»æ¨æ‰«æ¶æ„|Ziyao Yi, Davide Piccinini, Diego Valsesia, Tiziano Bianchi, Enrico Magli|<https://arxiv.org/pdf/2601.05020v1>|æ— |
|ğŸ“ æ›´æ–°|Single Image Reflection Separation via Dual Prior Interaction Transformer|[ç¿»è¯‘å¤±è´¥] Single Image Reflection Separation via Dual Prior Interaction Transformer|Yue Huang, Zi'ang Li, Tianle Hu, Jie Wen, Guanbin Li, Jinglin Zhang, Guoxu Zhou, Xiaozhao Fang|<https://arxiv.org/pdf/2505.12641v2>|æ— |
|ğŸ“ æ›´æ–°|Agentic Retoucher for Text-To-Image Generation|ç”¨äº Text-To-Image ç”Ÿæˆçš„ Agentic Retoucher|Shaocheng Shen, Jianfeng Liang, Chunlei Cai, Cong Geng, Huiyu Duan, Xiaoyun Zhang, Qiang Hu, Guangtao Zhai|<https://arxiv.org/pdf/2601.02046v2>|æ— |
|ğŸ†• å‘å¸ƒ|CounterVid: Counterfactual Video Generation for Mitigating Action and Temporal Hallucinations in Video-Language Models|CounterVidï¼šç”¨äºç¼“è§£ Video-Language Models ä¸­åŠ¨ä½œå’Œæ—¶é—´å¹»è§‰çš„åäº‹å®è§†é¢‘ç”Ÿæˆ|Tobia Poppi, Burak Uzkent, Amanmeet Garg, Lucas Porto, Garin Kessler, Yezhou Yang, Marcella Cornia, Lorenzo Baraldi .etc.|<https://arxiv.org/pdf/2601.04778v1>|æ— |
|ğŸ“ æ›´æ–°|MM-Sonate: Multimodal Controllable Audio-Video Generation with Zero-Shot Voice Cloning|MM-Sonate: å…·æœ‰Zero-Shot Voice Cloningçš„å¤šæ¨¡æ€å¯æ§Audio-Video Generation|Chunyu Qiang, Jun Wang, Xiaopeng Wang, Kang Yin, Yuxin Guo|<https://arxiv.org/pdf/2601.01568v2>|æ— |
|ğŸ“ æ›´æ–°|Interleaved Latent Visual Reasoning with Selective Perceptual Modeling|å…·æœ‰é€‰æ‹©æ€§æ„ŸçŸ¥å»ºæ¨¡çš„äº¤é”™æ½œåœ¨è§†è§‰æ¨ç†|Shuai Dong, Siyuan Wang, Xingyu Liu, Chenglin Li, Haowen Hou, Zhongyu Wei|<https://arxiv.org/pdf/2512.05665v2>|æ— |
|ğŸ†• å‘å¸ƒ|HyperAlign: Hyperbolic Entailment Cones for Adaptive Text-to-Image Alignment Assessment|HyperAlignï¼šç”¨äºè‡ªé€‚åº” Text-to-Image å¯¹é½è¯„ä¼°çš„åŒæ›²è•´å«é”¥|Wenzhi Chen, Bo Hu, Leida Li, Lihuo He, Wen Lu, Xinbo Gao|<https://arxiv.org/pdf/2601.04614v1>|æ— |
|ğŸ“ æ›´æ–°|CrackSegFlow: Controllable Flow Matching Synthesis for Generalizable Crack Segmentation with a 50K Image-Mask Benchmark|CrackSegFlowï¼šç”¨äºå¯æ³›åŒ–è£‚ç¼åˆ†å‰²çš„å¯æ§æµåŒ¹é…åˆæˆåŠåŒ…å«50Kå¼ å›¾åƒ-æ©ç çš„åŸºå‡†æ•°æ®é›†|Babak Asadi, Peiyang Wu, Mani Golparvar-Fard, Ramez Hajj|<https://arxiv.org/pdf/2601.03637v2>|æ— |
|ğŸ†• å‘å¸ƒ|MiLDEdit: Reasoning-Based Multi-Layer Design Document Editing|MiLDEdit: åŸºäºæ¨ç†çš„å¤šå±‚è®¾è®¡æ–‡æ¡£ç¼–è¾‘|Zihao Lin, Wanrong Zhu, Jiuxiang Gu, Jihyung Kil, Christopher Tensmeyer, Lin Zhang, Shilong Liu, Ruiyi Zhang .etc.|<https://arxiv.org/pdf/2601.04589v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|3D Conditional Image Synthesis of Left Atrial LGE MRI from Composite Semantic Masks|åŸºäºå¤åˆè¯­ä¹‰æ©è†œçš„å·¦å¿ƒæˆ¿LGE MRIçš„3Dæ¡ä»¶å›¾åƒåˆæˆ|Yusri Al-Sanaani, Rebecca Thornhill, Sreeraman Rajan|<https://arxiv.org/pdf/2601.04588v1>|æ— |
|ğŸ“ æ›´æ–°|CADmium: Fine-Tuning Code Language Models for Text-Driven Sequential CAD Design|CADmiumï¼šç”¨äºæ–‡æœ¬é©±åŠ¨é¡ºåº CAD è®¾è®¡çš„ä»£ç è¯­è¨€æ¨¡å‹å¾®è°ƒ|Prashant Govindarajan, Davide Baldelli, Jay Pathak, Quentin Fournier, Sarath Chandar|<https://arxiv.org/pdf/2507.09792v3>|æ— |
|ğŸ“ æ›´æ–°|Towards Real-world Lens Active Alignment with Unlabeled Data via Domain Adaptation|[ç¿»è¯‘å¤±è´¥] Towards Real-world Lens Active Alignment with Unlabeled Data via Domain Adaptation|Wenyong Li, Qi Jiang, Weijian Hu, Kailun Yang, Zhanjun Zhang, Wenjun Tian, Kaiwei Wang, Jian Bai|<https://arxiv.org/pdf/2601.03718v2>|æ— |
|ğŸ“ æ›´æ–°|FluencyVE: Marrying Temporal-Aware Mamba with Bypass Attention for Video Editing|FluencyVE: ç»“åˆæ—¶åºæ„ŸçŸ¥ Mamba ä¸æ—è·¯æ³¨æ„åŠ›çš„è§†é¢‘ç¼–è¾‘|Mingshu Cai, Yixuan Li, Osamu Yoshie, Yuya Ieiri|<https://arxiv.org/pdf/2512.21015v2>|æ— |


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Generate, Transfer, Adapt: Learning Functional Dexterous Grasping from a Single Human Demonstration|Generate, Transfer, Adapt: ä»å•ä¸ªäººç±»æ¼”ç¤ºä¸­å­¦ä¹ åŠŸèƒ½æ€§çµå·§æŠ“å–|Xingyi He, Adhitya Polavaram, Yunhao Cao, Om Deshmukh, Tianrui Wang, Xiaowei Zhou, Kuan Fang|<https://arxiv.org/pdf/2601.05243v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|ObjectForesight: Predicting Future 3D Object Trajectories from Human Videos|ObjectForesight: ä»äººç±»è§†é¢‘ä¸­é¢„æµ‹æœªæ¥3D Objectè½¨è¿¹|Rustin Soraki, Homanga Bharadhwaj, Ali Farhadi, Roozbeh Mottaghi|<https://arxiv.org/pdf/2601.05237v1>|æ— |
|ğŸ“ æ›´æ–°|CHIMERA: Adaptive Cache Injection and Semantic Anchor Prompting for Zero-shot Image Morphing with Morphing-oriented Metrics|CHIMERAï¼šé¢å‘Zero-shot Image Morphingçš„è‡ªé€‚åº”ç¼“å­˜æ³¨å…¥ä¸è¯­ä¹‰é”šç‚¹æç¤ºï¼Œé‡‡ç”¨Morphing-oriented Metrics|Dahyeon Kye, Jeahun Sung, Minkyu Jeon, Jihyong Oh|<https://arxiv.org/pdf/2512.07155v4>|æ— |
|ğŸ“ æ›´æ–°|InfiniteWeb: Scalable Web Environment Synthesis for GUI Agent Training|InfiniteWeb: ç”¨äº GUI Agent è®­ç»ƒçš„å¯æ‰©å±• Web ç¯å¢ƒåˆæˆ|Ziyun Zhang, Zezhou Wang, Xiaoyi Zhang, Zongyu Guo, Jiahao Li, Bin Li, Yan Lu|<https://arxiv.org/pdf/2601.04126v2>|æ— |
|ğŸ“ æ›´æ–°|Talk2Move: Reinforcement Learning for Text-Instructed Object-Level Geometric Transformation in Scenes|Talk2Moveï¼šåœºæ™¯ä¸­æ–‡æœ¬æŒ‡å¯¼çš„ç‰©ä½“çº§å‡ ä½•å˜æ¢çš„å¼ºåŒ–å­¦ä¹ |Jing Tan, Zhaoyang Zhang, Yantao Shen, Jiarui Cai, Shuo Yang, Jiajun Wu, Wei Xia, Zhuowen Tu .etc.|<https://arxiv.org/pdf/2601.02356v2>|æ— |
|ğŸ“ æ›´æ–°|FoldNet: Learning Generalizable Closed-Loop Policy for Garment Folding via Keypoint-Driven Asset and Demonstration Synthesis|FoldNet: é€šè¿‡Keypoint-Driven Asset and Demonstration Synthesiså­¦ä¹ å¯æ³›åŒ–çš„Garment Foldingé—­ç¯ç­–ç•¥|Yuxing Chen, Bowen Xiao, He Wang|<https://arxiv.org/pdf/2505.09109v2>|æ— |


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|FALCONEye: Finding Answers and Localizing Content in ONE-hour-long videos with multi-modal LLMs|FALCONEye: åˆ©ç”¨å¤šæ¨¡æ€ LLMs åœ¨ä¸€å°æ—¶é•¿è§†é¢‘ä¸­å¯»æ‰¾ç­”æ¡ˆå¹¶å®šä½å†…å®¹|Carlos Plou, Cesar Borja, Ruben Martinez-Cantin, Ana C. Murillo|<https://arxiv.org/pdf/2503.19850v3>|æ— |
|ğŸ†• å‘å¸ƒ|From Understanding to Engagement: Personalized pharmacy Video Clips via Vision Language Models (VLMs)|ä»ç†è§£åˆ°å‚ä¸ï¼šé€šè¿‡ Vision Language Models (VLMs) å®ç°ä¸ªæ€§åŒ– pharmacy è§†é¢‘ç‰‡æ®µ|Suyash Mishra, Qiang Li, Srikanth Patil, Anubhav Girdhar|<https://arxiv.org/pdf/2601.05059v1>|æ— |
|ğŸ“ æ›´æ–°|Boosting HDR Image Reconstruction via Semantic Knowledge Transfer|é€šè¿‡è¯­ä¹‰çŸ¥è¯†æå‡HDRå›¾åƒé‡å»º|Tao Hu, Longyao Wu, Wei Dong, Peng Wu, Jinqiu Sun, Xiaogang Xu, Qingsen Yan, Yanning Zhang|<https://arxiv.org/pdf/2503.15361v2>|æ— |
|ğŸ†• å‘å¸ƒ|On the Holistic Approach for Detecting Human Image Forgery|è®ºæ£€æµ‹äººåƒä¼ªé€ çš„æ•´ä½“æ–¹æ³•|Xiao Guo, Jie Zhu, Anil Jain, Xiaoming Liu|<https://arxiv.org/pdf/2601.04715v1>|æ— |
|ğŸ†• å‘å¸ƒ|FaceRefiner: High-Fidelity Facial Texture Refinement with Differentiable Rendering-based Style Transfer|FaceRefiner: åŸºäºå¯å¾®æ¸²æŸ“é£æ ¼è¿ç§»çš„é«˜ä¿çœŸé¢éƒ¨çº¹ç†ä¼˜åŒ–|Chengyang Li, Baoping Cheng, Yao Cheng, Haocheng Zhang, Renshuai Liu, Yinglin Zheng, Jing Liao, Xuan Cheng|<https://arxiv.org/pdf/2601.04520v1>|æ— |
|ğŸ†• å‘å¸ƒ|IGenBench: Benchmarking the Reliability of Text-to-Infographic Generation|IGenBenchï¼šè¯„ä¼° Text-to-Infographic Generation çš„å¯é æ€§|Yinghao Tang, Xueding Liu, Boyuan Zhang, Tingfeng Lan, Yupeng Xie, Jiale Lao, Yiyao Wang, Haoxuan Li .etc.|<https://arxiv.org/pdf/2601.04498v1>|æ— |


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|QNeRF: Neural Radiance Fields on a Simulated Gate-Based Quantum Computer|QNeRF: åŸºäºæ¨¡æ‹Ÿé—¨é‡å­è®¡ç®—æœºçš„ Neural Radiance Fields|Daniele Lizzio Bosco, Shuteng Wang, Giuseppe Serra, Vladislav Golyanik|<https://arxiv.org/pdf/2601.05250v1>|æ— |
|ğŸ†• å‘å¸ƒ|DivAS: Interactive 3D Segmentation of NeRFs via Depth-Weighted Voxel Aggregation|DivASï¼šé€šè¿‡æ·±åº¦åŠ æƒä½“ç´ èšåˆå®ç°NeRFçš„äº¤äº’å¼3Dåˆ†å‰²|Ayush Pande|<https://arxiv.org/pdf/2601.04860v1>|åˆ†æå¤±è´¥|


### è§†è§‰å®šä½ä¸æ˜ å°„ (Visual Localization & Mapping)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MoE3D: A Mixture-of-Experts Module for 3D Reconstruction|MoE3D: ç”¨äº3D Reconstructionçš„Mixture-of-Expertsæ¨¡å—|Zichen Wang, Ang Cao, Liam J. Wang, Jeong Joon Park|<https://arxiv.org/pdf/2601.05208v1>|æ— |


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|OceanSplat: Object-aware Gaussian Splatting with Trinocular View Consistency for Underwater Scene Reconstruction|OceanSplatï¼šåŸºäºä¸‰ç›®è§†å›¾ä¸€è‡´æ€§çš„ç‰©ä½“æ„ŸçŸ¥é«˜æ–¯æ³¼æº…ç”¨äºæ°´ä¸‹åœºæ™¯é‡å»º|Minseong Kweon, Jinsun Park|<https://arxiv.org/pdf/2601.04984v1>|æ— |
|ğŸ†• å‘å¸ƒ|Segmentation-Driven Monocular Shape from Polarization based on Physical Model|åŸºäºç‰©ç†æ¨¡å‹çš„åˆ†å‰²é©±åŠ¨å•ç›®åæŒ¯å½¢çŠ¶æ¢å¤|Jinyu Zhang, Xu Ma, Weili Chen, Gonzalo R. Arce|<https://arxiv.org/pdf/2601.04776v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Robust Scene Coordinate Regression via Geometrically-Consistent Global Descriptors|åŸºäºå‡ ä½•ä¸€è‡´æ€§å…¨å±€æè¿°å­çš„é²æ£’åœºæ™¯åæ ‡å›å½’|Son Tung Nguyen, Alejandro Fontan, Michael Milford, Tobias Fischer|<https://arxiv.org/pdf/2512.17226v2>|[ä»£ç ](https://github.com/sontung/robust_scr.); åˆ†æå¤±è´¥|


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues|MT-Video-Benchï¼šä¸€ä¸ªç”¨äºè¯„ä¼°å¤šè½®å¯¹è¯ä¸­å¤šæ¨¡æ€LLMsçš„ç»¼åˆè§†é¢‘ç†è§£åŸºå‡†|Yaning Pan, Qianqian Xie, Guohui Zhang, Zekun Wang, Yongqian Wen, Yuanxing Zhang, Haoxuan Hu, Zhiyu Pan .etc.|<https://arxiv.org/pdf/2510.17722v2>|æ— |
|ğŸ“ æ›´æ–°|Minimal Clips, Maximum Salience: Long Video Summarization via Key Moment Extraction|Minimal Clips, Maximum Salience: é€šè¿‡å…³é”®æ—¶åˆ»æå–çš„é•¿è§†é¢‘æ‘˜è¦|Galann Pennec, Zhengyuan Liu, Nicholas Asher, Philippe Muller, Nancy F. Chen|<https://arxiv.org/pdf/2512.11399v2>|æ— |


### æ—¶åºå»ºæ¨¡ä¸é¢„æµ‹ (Temporal Modeling & Prediction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|CaTFormer: Causal Temporal Transformer with Dynamic Contextual Fusion for Driving Intention Prediction|CaTFormer: ç”¨äºé©¾é©¶æ„å›¾é¢„æµ‹çš„å…·æœ‰åŠ¨æ€ä¸Šä¸‹æ–‡èåˆçš„å› æœæ—¶åº Transformer|Sirui Wang, Zhou Guan, Bingxi Zhao, Tongjia Gu, Jie Liu|<https://arxiv.org/pdf/2507.13425v2>|æ— |


## è‡ªç›‘ç£ä¸è¡¨å¾å­¦ä¹  (Self-supervised & Representation Learning)


### è·¨æ¨¡æ€ä¸€è‡´æ€§å­¦ä¹  (Cross-modal Consistency Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|From Rays to Projections: Better Inputs for Feed-Forward View Synthesis|ä»å…‰çº¿åˆ°æŠ•å½±ï¼šå‰é¦ˆè§†å›¾åˆæˆçš„æ›´å¥½è¾“å…¥|Zirui Wu, Zeren Jiang, Martin R. Oswald, Jie Song|<https://arxiv.org/pdf/2601.05116v1>|æ— |


### å¯¹æ¯”å­¦ä¹ æ–¹æ³• (Contrastive Learning Methods)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Is Contrastive Distillation Enough for Learning Comprehensive 3D Representations?|å¯¹æ¯”è’¸é¦æ˜¯å¦è¶³ä»¥å­¦ä¹ å…¨é¢çš„3Dè¡¨ç¤ºï¼Ÿ|Yifan Zhang, Junhui Hou|<https://arxiv.org/pdf/2412.08973v3>|[ä»£ç ](https://github.com/Eaphan/CMCR.)|


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Learning Latent Action World Models In The Wild|[ç¿»è¯‘å¤±è´¥] Learning Latent Action World Models In The Wild|Quentin Garrido, Tushar Nagarajan, Basile Terver, Nicolas Ballas, Yann LeCun, Michael Rabbat|<https://arxiv.org/pdf/2601.05230v1>|æ— |
|ğŸ“ æ›´æ–°|NASTaR: NovaSAR Automated Ship Target Recognition Dataset|[ç¿»è¯‘å¤±è´¥] NASTaR: NovaSAR Automated Ship Target Recognition Dataset|Benyamin Hosseiny, Kamirul Kamirul, Odysseas Pappas, Alin Achim|<https://arxiv.org/pdf/2512.18503v2>|[ä»£ç ](https://github.com/benyaminhosseiny/nastar.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Decentralized Privacy-Preserving Federal Learning of Computer Vision Models on Edge Devices|è¾¹ç¼˜è®¾å¤‡ä¸Šè®¡ç®—æœºè§†è§‰æ¨¡å‹çš„å»ä¸­å¿ƒåŒ–éšç§ä¿æŠ¤è”é‚¦å­¦ä¹ |Damian HarenÄÃ¡k, LukÃ¡Å¡ GajdoÅ¡ech, Martin Madaras|<https://arxiv.org/pdf/2601.04912v1>|æ— |
|ğŸ†• å‘å¸ƒ|Rotation-Robust Regression with Convolutional Model Trees|åŸºäºå·ç§¯æ¨¡å‹æ ‘çš„æ—‹è½¬é²æ£’å›å½’|Hongyi Li, William Ward Armstrong, Jun Xu|<https://arxiv.org/pdf/2601.04899v1>|æ— |
|ğŸ“ æ›´æ–°|Crafting Adversarial Inputs for Large Vision-Language Models Using Black-Box Optimization|åˆ©ç”¨é»‘ç›’ä¼˜åŒ–ä¸ºå¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹åˆ¶ä½œå¯¹æŠ—è¾“å…¥|Jiwei Guan, Haibo Jin, Haohan Wang|<https://arxiv.org/pdf/2601.01747v2>|æ— |
|ğŸ†• å‘å¸ƒ|All Changes May Have Invariant Principles: Improving Ever-Shifting Harmful Meme Detection via Design Concept Reproduction|æ‰€æœ‰å˜åŒ–å¯èƒ½éƒ½æœ‰ä¸å˜åŸåˆ™ï¼šé€šè¿‡è®¾è®¡æ¦‚å¿µå¤ç°æ”¹è¿›ä¸æ–­å˜åŒ–çš„æœ‰å®³æ¨¡å› æ£€æµ‹|Ziyou Jiang, Mingyang Li, Junjie Wang, Yuekai Huang, Jie Huang, Zhiyuan Chang, Zhaoyang Li, Qing Wang|<https://arxiv.org/pdf/2601.04567v1>|æ— |


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Mechanisms of Prompt-Induced Hallucination in Vision-Language Models|Vision-Language Modelsä¸­Prompt-Inducedå¹»è§‰çš„æœºåˆ¶|William Rudman, Michal Golovanevsky, Dana Arad, Yonatan Belinkov, Ritambhara Singh, Carsten Eickhoff, Kyle Mahowald|<https://arxiv.org/pdf/2601.05201v1>|æ— |
|ğŸ“ æ›´æ–°|MAFNet:Multi-frequency Adaptive Fusion Network for Real-time Stereo Matching|MAFNet:ç”¨äºå®æ—¶ç«‹ä½“åŒ¹é…çš„å¤šé¢‘è‡ªé€‚åº”èåˆç½‘ç»œ|Ao Xu, Rujin Zhao, Xiong Xu, Boceng Huang, Yujia Jia, Hongfeng Long, Fuxuan Chen, Zilong Cao .etc.|<https://arxiv.org/pdf/2512.04358v2>|åˆ†æå¤±è´¥|


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Spontaneous emergence of linguistic statistical laws in images via artificial neural networks|é€šè¿‡äººå·¥ç¥ç»ç½‘ç»œåœ¨å›¾åƒä¸­è‡ªå‘æ¶Œç°è¯­è¨€ç»Ÿè®¡è§„å¾‹|Ping-Rui Tsai, Chi-hsiang Wang, Yu-Cheng Liao, Hong-Yue Huang, Tzay-Ming Hong|<https://arxiv.org/pdf/2501.18620v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Illumination Angular Spectrum Encoding for Controlling the Functionality of Diffractive Networks|ç”¨äºæ§åˆ¶ Diffractive Networks åŠŸèƒ½çš„ Illumination Angular Spectrum Encoding|Matan Kleiner, Lior Michaeli, Tomer Michaeli|<https://arxiv.org/pdf/2601.04825v1>|æ— |
|ğŸ“ æ›´æ–°|Automated Invoice Data Extraction: Using LLM and OCR|è‡ªåŠ¨åŒ–å‘ç¥¨æ•°æ®æå–ï¼šä½¿ç”¨ LLM å’Œ OCR|Khushi Khanchandani, Advait Thakur, Akshita Shetty, Chaitravi Reddy, Ritisa Behera|<https://arxiv.org/pdf/2511.05547v2>|æ— |
|ğŸ†• å‘å¸ƒ|Training a Custom CNN on Five Heterogeneous Image Datasets|åœ¨äº”ä¸ªå¼‚æ„å›¾åƒæ•°æ®é›†ä¸Šè®­ç»ƒè‡ªå®šä¹‰CNN|Anika Tabassum, Tasnuva Mahazabin Tuba, Nafisa Naznin|<https://arxiv.org/pdf/2601.04727v1>|æ— |
|ğŸ†• å‘å¸ƒ|WebCryptoAgent: Agentic Crypto Trading with Web Informatics|WebCryptoAgentï¼šåŸºäº Web Informatics çš„æ™ºèƒ½åŠ å¯†è´§å¸äº¤æ˜“|Ali Kurban, Wei Luo, Liangyu Zuo, Zeyu Zhang, Renda Han, Zhaolu Kang, Hao Tang|<https://arxiv.org/pdf/2601.04687v1>|[ä»£ç ](https://github.com/AIGeeksGroup/WebCryptoAgent.)|
|ğŸ“ æ›´æ–°|OneVision: An End-to-End Generative Framework for Multi-view E-commerce Vision Search|OneVisionï¼šä¸€ä¸ªç”¨äºå¤šè§†å›¾ç”µå•†è§†è§‰æœç´¢çš„ç«¯åˆ°ç«¯ç”Ÿæˆæ¡†æ¶|Zexin Zheng, Huangyu Dai, Lingtao Mao, Xinyu Sun, Zihan Liang, Ben Chen, Yuqing Ding, Chenyi Lei .etc.|<https://arxiv.org/pdf/2510.05759v4>|æ— |
|ğŸ“ æ›´æ–°|MobileGeo: Exploring Hierarchical Knowledge Distillation for Resource-Efficient Cross-view Drone Geo-Localization|MobileGeo: æ¢ç´¢ç”¨äºèµ„æºé«˜æ•ˆè·¨è§†è§’æ— äººæœºåœ°ç†å®šä½çš„åˆ†å±‚çŸ¥è¯†è’¸é¦|Jian Sun, Kangdao Liu, Chi Zhang, Chuangquan Chen, Junge Shen, C. L. Philip Chen, Chi-Man Vong|<https://arxiv.org/pdf/2510.22582v3>|[ä»£ç ](https://github.com/SkyEyeLoc/MobileGeo.)|
|ğŸ“ æ›´æ–°|QUIET-SR: Quantum Image Enhancement Transformer for Single Image Super-Resolution|QUIET-SR: ç”¨äºå•å›¾åƒè¶…åˆ†è¾¨ç‡çš„é‡å­å›¾åƒå¢å¼º Transformer|Siddhant Dutta, Nouhaila Innan, Khadijeh Najafi, Sadok Ben Yahia, Muhammad Shafique|<https://arxiv.org/pdf/2503.08759v2>|æ— |


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes|RL-AWB: ç”¨äºä½å…‰å¤œé—´åœºæ™¯è‡ªåŠ¨ç™½å¹³è¡¡æ ¡æ­£çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ |Yuan-Kang Lee, Kuan-Lin Chen, Chia-Che Chang, Yu-Lun Liu|<https://arxiv.org/pdf/2601.05249v1>|[ä»£ç ](https://ntuneillee.github.io/research); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Quantitative mapping from conventional MRI using self-supervised physics-guided deep learning: applications to a large-scale, clinically heterogeneous dataset|ä½¿ç”¨è‡ªç›‘ç£ç‰©ç†å¼•å¯¼æ·±åº¦å­¦ä¹ ä»å¸¸è§„MRIè¿›è¡Œå®šé‡æ˜ å°„ï¼šåœ¨å¤§è§„æ¨¡ä¸´åºŠå¼‚æ„æ•°æ®é›†ä¸Šçš„åº”ç”¨|Jelmer van Lune, Stefano Mandija, Oscar van der Heide, Matteo Maspero, Martin B. Schilder, Jan Willem Dankbaar, Cornelis A. T. van den Berg, Alessandro Sbrizzi|<https://arxiv.org/pdf/2601.05063v1>|æ— |
|ğŸ†• å‘å¸ƒ|HUR-MACL: High-Uncertainty Region-Guided Multi-Architecture Collaborative Learning for Head and Neck Multi-Organ Segmentation|HUR-MACL: é«˜ä¸ç¡®å®šæ€§åŒºåŸŸå¼•å¯¼çš„å¤šæ¶æ„ååŒå­¦ä¹ ç”¨äºå¤´é¢ˆéƒ¨å¤šå™¨å®˜åˆ†å‰²|Xiaoyu Liu, Siwen Wei, Linhao Qu, Mingyuan Pan, Chengsheng Zhang, Yonghong Shi, Zhijian Song|<https://arxiv.org/pdf/2601.04607v1>|æ— |


### å°æ ·æœ¬å­¦ä¹  (Few-shot Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Extended OpenTT Games Dataset: A table tennis dataset for fine-grained shot type and point outcome|æ‰©å±•çš„OpenTTæ¯”èµ›æ•°æ®é›†ï¼šä¸€ä¸ªç”¨äºç»†ç²’åº¦å‡»çƒç±»å‹å’Œå¾—åˆ†ç»“æœçš„ä¹’ä¹“çƒæ•°æ®é›†|Moamal Fadhil Abdul-Mahdi, Jonas Bruun Hubrechts, Thomas Martini JÃ¸rgensen, Emil Hovad|<https://arxiv.org/pdf/2512.19327v2>|æ— |
|ğŸ†• å‘å¸ƒ|Detector-Augmented SAMURAI for Long-Duration Drone Tracking|[ç¿»è¯‘å¤±è´¥] Detector-Augmented SAMURAI for Long-Duration Drone Tracking|Tamara R. Lenhard, Andreas Weinmann, Hichem Snoussi, Tobias Koch|<https://arxiv.org/pdf/2601.04798v1>|æ— |
|ğŸ†• å‘å¸ƒ|See, Explain, and Intervene: A Few-Shot Multimodal Agent Framework for Hateful Meme Moderation|See, Explain, and Interveneï¼šä¸€ç§ç”¨äº Hateful Meme Moderation çš„ Few-Shot Multimodal Agent Framework|Naquee Rizwan, Subhankar Swain, Paramananda Bhaskar, Gagan Aryan, Shehryaar Shah Khan, Animesh Mukherjee|<https://arxiv.org/pdf/2601.04692v1>|æ— |


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|CoV: Chain-of-View Prompting for Spatial Reasoning|CoVï¼šç”¨äºç©ºé—´æ¨ç†çš„Chain-of-View Prompting|Haoyu Zhao, Akide Liu, Zeyu Zhang, Weijie Wang, Feng Chen, Ruihan Zhu, Gholamreza Haffari, Bohan Zhuang|<https://arxiv.org/pdf/2601.05172v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|VERSE: Visual Embedding Reduction and Space Exploration. Clustering-Guided Insights for Training Data Enhancement in Visually-Rich Document Understanding|[ç¿»è¯‘å¤±è´¥] VERSE: Visual Embedding Reduction and Space Exploration. Clustering-Guided Insights for Training Data Enhancement in Visually-Rich Document Understanding|Ignacio de Rodrigo, Alvaro J. Lopez-Lopez, Jaime Boal|<https://arxiv.org/pdf/2601.05125v1>|æ— |
|ğŸ“ æ›´æ–°|BOP-Distrib: Revisiting 6D Pose Estimation Benchmarks for Better Evaluation under Visual Ambiguities|BOP-Distrib: é‡æ–°å®¡è§†6D Pose EstimationåŸºå‡†ä»¥åœ¨è§†è§‰æ­§ä¹‰ä¸‹å®ç°æ›´å¥½çš„è¯„ä¼°|Boris Meden, Asma Brazi, Fabrice Mayran de Chamisso, Steve Bourgeois, Vincent Lepetit|<https://arxiv.org/pdf/2408.17297v4>|æ— |
|ğŸ†• å‘å¸ƒ|V-FAT: Benchmarking Visual Fidelity Against Text-bias|V-FAT: è¯„ä¼° Visual Fidelity ä¸ Text-bias çš„ Benchmark|Ziteng Wang, Yujie He, Guanliang Li, Siqi Yang, Jiaqi Xiong, Songxiang Liu|<https://arxiv.org/pdf/2601.04897v1>|æ— |
|ğŸ†• å‘å¸ƒ|AIVD: Adaptive Edge-Cloud Collaboration for Accurate and Efficient Industrial Visual Detection|AIVDï¼šé¢å‘ç²¾å‡†é«˜æ•ˆå·¥ä¸šè§†è§‰æ£€æµ‹çš„è‡ªé€‚åº”è¾¹ç¼˜-äº‘åä½œ|Yunqing Hu, Zheming Yang, Chang Zhao, Qi Guo, Meng Gao, Pengcheng Li, Wen Ji|<https://arxiv.org/pdf/2601.04734v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Visual Merit or Linguistic Crutch? A Close Look at DeepSeek-OCR|[ç¿»è¯‘å¤±è´¥] Visual Merit or Linguistic Crutch? A Close Look at DeepSeek-OCR|Yunhao Liang, Ruixuan Ying, Bo Li, Hong Li, Kai Yan, Qingwen Li, Min Yang, Okamoto Satoshi .etc.|<https://arxiv.org/pdf/2601.03714v2>|[ä»£ç ](https://github.com/dududuck00/DeepSeekOCR.)|
|ğŸ†• å‘å¸ƒ|Agri-R1: Empowering Generalizable Agricultural Reasoning in Vision-Language Models with Reinforcement Learning|Agri-R1ï¼šåˆ©ç”¨å¼ºåŒ–å­¦ä¹ å¢å¼º Vision-Language Models ä¸­çš„å¯æ³›åŒ–å†œä¸šæ¨ç†èƒ½åŠ›|Wentao Zhang, Lifei Wang, Lina Lu, MingKun Xu, Shangyang Li, Yanchao Yang, Tao Fang|<https://arxiv.org/pdf/2601.04672v1>|æ— |


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|MVT: Mask-Grounded Vision-Language Models for Taxonomy-Aligned Land-Cover Tagging|MVT: ç”¨äºåˆ†ç±»å¯¹é½åœ°è¡¨è¦†ç›–æ ‡æ³¨çš„Mask-Grounded Vision-Language Models|Siyi Chen, Kai Wang, Weicong Pang, Ruiming Yang, Ziru Chen, Renjun Gao, Alexis Kai Hon Lau, Dasa Gu .etc.|<https://arxiv.org/pdf/2509.18693v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|SparseLaneSTP: Leveraging Spatio-Temporal Priors with Sparse Transformers for 3D Lane Detection|SparseLaneSTP: åˆ©ç”¨ç¨€ç–Transformerç»“åˆæ—¶ç©ºå…ˆéªŒè¿›è¡Œ3Dè½¦é“çº¿æ£€æµ‹|Maximilian Pittner, Joel Janai, Mario Faigle, Alexandru Paul Condurache|<https://arxiv.org/pdf/2601.04968v1>|æ— |
|ğŸ“ æ›´æ–°|GeoReason: Aligning Thinking And Answering In Remote Sensing Vision-Language Models Via Logical Consistency Reinforcement Learning|GeoReason: é€šè¿‡é€»è¾‘ä¸€è‡´æ€§å¼ºåŒ–å­¦ä¹ å¯¹é½é¥æ„Ÿè§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„æ€è€ƒä¸å›ç­”|Wenshuai Li, Xiantai Xiang, Zixiao Wen, Guangyao Zhou, Ben Niu, Feng Wang, Lijia Huang, Qiantong Wang .etc.|<https://arxiv.org/pdf/2601.04118v2>|æ— |


### åˆ›æ„åª’ä½“ç”Ÿæˆ (Creative Media Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Cognitive-Hierarchy Guided End-to-End Planning for Autonomous Driving|Cognitive-Hierarchy å¼•å¯¼çš„è‡ªåŠ¨é©¾é©¶ç«¯åˆ°ç«¯è§„åˆ’|Zhennan Wang, Jianing Teng, Canqun Xiang, Kangliang Chen, Xing Pan, Lu Deng, Weihao Gu|<https://arxiv.org/pdf/2505.21581v3>|æ— |


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Two-Stream Thermal Imaging Fusion for Enhanced Time of Birth Detection in Neonatal Care|[ç¿»è¯‘å¤±è´¥] Two-Stream Thermal Imaging Fusion for Enhanced Time of Birth Detection in Neonatal Care|Jorge GarcÃ­a-Torres, Ã˜yvind Meinich-Bache, Sara Brunner, Siren Rettedal, Vilde Kolstad, Kjersti Engan|<https://arxiv.org/pdf/2503.03244v2>|æ— |
|ğŸ†• å‘å¸ƒ|SRU-Pix2Pix: A Fusion-Driven Generator Network for Medical Image Translation with Few-Shot Learning|SRU-Pix2Pix: ä¸€ç§åŸºäºèåˆé©±åŠ¨çš„åŒ»å­¦å›¾åƒç¿»è¯‘ç”Ÿæˆç½‘ç»œï¼Œé‡‡ç”¨Few-Shot Learning|Xihe Qiu, Yang Dai, Xiaoyu Tan, Sijia Li, Fenghao Sun, Lu Gan, Liang Liu|<https://arxiv.org/pdf/2601.04785v1>|æ— |
|ğŸ“ æ›´æ–°|GCR: Geometry-Consistent Routing for Task-Agnostic Continual Anomaly Detection|GCR: ç”¨äºä»»åŠ¡æ— å…³æŒç»­å¼‚å¸¸æ£€æµ‹çš„å‡ ä½•ä¸€è‡´æ€§è·¯ç”±|Joongwon Chae, Lihui Luo, Yang Liu, Runming Wang, Dongmei Yu, Zeming Liang, Xi Yuan, Dayan Zhang .etc.|<https://arxiv.org/pdf/2601.01856v2>|[ä»£ç ](https://github.com/jw-chae/GCR)|
|ğŸ†• å‘å¸ƒ|TokenSeg: Efficient 3D Medical Image Segmentation via Hierarchical Visual Token Compression|TokenSeg: é€šè¿‡åˆ†å±‚è§†è§‰Tokenå‹ç¼©å®ç°é«˜æ•ˆ3DåŒ»å­¦å›¾åƒåˆ†å‰²|Sen Zeng, Hong Zhou, Zheng Zhu, Yang Liu|<https://arxiv.org/pdf/2601.04519v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Vision-Language Agents for Interactive Forest Change Analysis|ç”¨äºäº¤äº’å¼æ£®æ—å˜åŒ–åˆ†æçš„ Vision-Language Agents|James Brock, Ce Zhang, Nantheera Anantrasirichai|<https://arxiv.org/pdf/2601.04497v1>|[ä»£ç ](https://github.com/JamesBrockUoB/ForestChat.)|


## æ–°å…´ç†è®ºä¸è·¨å­¦ç§‘æ–¹å‘ (Emerging Theory & Interdisciplinary Directions)


### è§†è§‰è®¤çŸ¥è®¡ç®— (Visual Cognitive Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Vision-Language Introspection: Mitigating Overconfident Hallucinations in MLLMs via Interpretable Bi-Causal Steering|Vision-Language å†…çœï¼šé€šè¿‡å¯è§£é‡Šçš„åŒå› æœå¼•å¯¼ç¼“è§£ MLLMs ä¸­çš„è¿‡åº¦è‡ªä¿¡å¹»è§‰|Shuliang Liu, Songbo Yang, Dong Fang, Sihang Jia, Yuqi Tang, Lingfeng Su, Ruoshui Peng, Yibo Yan .etc.|<https://arxiv.org/pdf/2601.05159v1>|æ— |


### ç¥ç»-ç¬¦å·è§†è§‰ (Neuro-symbolic Vision)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|A Vision for Multisensory Intelligence: Sensing, Synergy, and Science|å¤šæ„Ÿå®˜æ™ºèƒ½çš„æ„¿æ™¯ï¼šæ„ŸçŸ¥ã€ååŒä¸ç§‘å­¦|Paul Pu Liang|<https://arxiv.org/pdf/2601.04563v1>|[ä»£ç ](https://mit-mi.github.io/.)|


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ProFuse: Efficient Cross-View Context Fusion for Open-Vocabulary 3D Gaussian Splatting|ProFuseï¼šé¢å‘ Open-Vocabulary 3D Gaussian Splatting çš„é«˜æ•ˆè·¨è§†å›¾ä¸Šä¸‹æ–‡èåˆ|Yen-Jen Chiou, Wei-Tse Cheng, Yuan-Fu Yang|<https://arxiv.org/pdf/2601.04754v1>|æ— |
|ğŸ“ æ›´æ–°|Clinically-Validated Innovative Mobile Application for Assessing Blinking and Eyelid Movements|ç»è¿‡ä¸´åºŠéªŒè¯çš„åˆ›æ–°ç§»åŠ¨åº”ç”¨ç¨‹åºï¼Œç”¨äºè¯„ä¼°çœ¨çœ¼å’Œçœ¼ç‘è¿åŠ¨|Gustavo Adolpho Bonesso, Carlos Marcelo GurjÃ£o de Godoy, Tammy Hentona Osaki, Midori Hentona Osaki, BÃ¡rbara Moreira Ribeiro Trindade dos Santos, Juliana Yuka Washiya, Regina CÃ©lia Coelho|<https://arxiv.org/pdf/2511.14361v2>|æ— |

