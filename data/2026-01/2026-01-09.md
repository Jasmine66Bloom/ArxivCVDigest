## [UPDATED!] **2026-01-09** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Adapting Vision Transformers to Ultra-High Resolution Semantic Segmentation with Relay Tokens|åˆ©ç”¨Relay Tokenså°†Vision Transformersé€‚åº”äºè¶…é«˜åˆ†è¾¨ç‡è¯­ä¹‰åˆ†å‰²|Yohann Perron, Vladyslav Sydorov, Christophe Pottier, Loic Landrieu|<https://arxiv.org/pdf/2601.05927v1>|æ— |
|ğŸ†• å‘å¸ƒ|Performance of a Deep Learning-Based Segmentation Model for Pancreatic Tumors on Public Endoscopic Ultrasound Datasets|åŸºäºæ·±åº¦å­¦ä¹ çš„åˆ†å‰²æ¨¡å‹åœ¨å…¬å…±å†…é•œè¶…å£°æ•°æ®é›†ä¸Šå¯¹èƒ°è…ºè‚¿ç˜¤çš„æ€§èƒ½|Pankaj Gupta, Priya Mudgil, Niharika Dutta, Kartik Bose, Nitish Kumar, Anupam Kumar, Jimil Shah, Vaneet Jearth .etc.|<https://arxiv.org/pdf/2601.05937v1>|æ— |
|ğŸ†• å‘å¸ƒ|ViTNT-FIQA: Training-Free Face Image Quality Assessment with Vision Transformers|ViTNT-FIQA: åŸºäº Vision Transformers çš„æ— è®­ç»ƒäººè„¸å›¾åƒè´¨é‡è¯„ä¼°|Guray Ozgur, Eduarda Caldeira, Tahar Chettaoui, Jan Niklas Kolf, Marco Huber, Naser Damer, Fadi Boutros|<https://arxiv.org/pdf/2601.05741v1>|æ— |
|ğŸ“ æ›´æ–°|PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language|PsOCR: é¢å‘ä½èµ„æº Pashto è¯­è¨€å…‰å­¦å­—ç¬¦è¯†åˆ«çš„å¤§è§„æ¨¡å¤šæ¨¡æ€æ¨¡å‹åŸºå‡†æµ‹è¯•|Ijazul Haq, Yingjie Zhang, Irfan Ali Khan|<https://arxiv.org/pdf/2505.10055v2>|[ä»£ç ](https://github.com/zirak-ai/PashtoOCR.)|
|ğŸ“ æ›´æ–°|Language as Prior, Vision as Calibration: Metric Scale Recovery for Monocular Depth Estimation|Language as Prior, Vision as Calibration: Monocular Depth Estimation çš„ Metric Scale Recovery|Mingxia Zhan, Li Zhang, Beibei Wang, Yingjie Wang, Zenglin Shi|<https://arxiv.org/pdf/2601.01457v3>|æ— |


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Boosting Latent Diffusion Models via Disentangled Representation Alignment|é€šè¿‡è§£è€¦è¡¨ç¤ºå¯¹é½æå‡æ½œåœ¨æ‰©æ•£æ¨¡å‹|John Page, Xuesong Niu, Kai Wu, Kun Gai|<https://arxiv.org/pdf/2601.05823v1>|æ— |
|ğŸ“ æ›´æ–°|AtomThink: Multimodal Slow Thinking with Atomic Step Reasoning|AtomThinkï¼šåŸºäºåŸå­æ­¥éª¤æ¨ç†çš„å¤šæ¨¡æ€æ…¢æ€è€ƒ|Kun Xiang, Zhili Liu, Terry Jingchen Zhang, Yinya Huang, Yunshuang Nie, Kaixin Cai, Yiyang Yin, Runhui Huang .etc.|<https://arxiv.org/pdf/2411.11930v5>|[ä»£ç ](https://github.com/Kun-Xiang/AtomThink.)|
|ğŸ†• å‘å¸ƒ|What's Left Unsaid? Detecting and Correcting Misleading Omissions in Multimodal News Previews|[ç¿»è¯‘å¤±è´¥] What's Left Unsaid? Detecting and Correcting Misleading Omissions in Multimodal News Previews|Fanxiao Li, Jiaying Wu, Tingchao Fu, Dayang Li, Herun Wan, Wei Zhou, Min-Yen Kan|<https://arxiv.org/pdf/2601.05563v1>|æ— |


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|SOVABench: A Vehicle Surveillance Action Retrieval Benchmark for Multimodal Large Language Models|SOVABench: é¢å‘å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„è½¦è¾†ç›‘æ§åŠ¨ä½œæ£€ç´¢åŸºå‡†|Oriol Rabasseda, Zenjie Li, Kamal Nasrollahi, Sergio Escalera|<https://arxiv.org/pdf/2601.04824v2>|æ— |
|ğŸ†• å‘å¸ƒ|One Language-Free Foundation Model Is Enough for Universal Vision Anomaly Detection|ä¸€ä¸ªæ— è¯­è¨€åŸºç¡€æ¨¡å‹è¶³ä»¥ç”¨äºé€šç”¨è§†è§‰å¼‚å¸¸æ£€æµ‹|Bin-Bin Gao, Chengjie Wang|<https://arxiv.org/pdf/2601.05552v1>|[ä»£ç ](https://github.com/gaobb/UniADet.)|


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Phase4DFD: Multi-Domain Phase-Aware Attention for Deepfake Detection|Phase4DFD: ç”¨äºDeepfake Detectionçš„å¤šåŸŸç›¸ä½æ„ŸçŸ¥æ³¨æ„åŠ›|Zhen-Xin Lin, Shang-Kuan Chen|<https://arxiv.org/pdf/2601.05861v1>|æ— |
|ğŸ“ æ›´æ–°|Pyramidal Adaptive Cross-Gating for Multimodal Detection|é‡‘å­—å¡”å¼è‡ªé€‚åº”äº¤å‰é—¨æ§ç”¨äºå¤šæ¨¡æ€æ£€æµ‹|Zidong Gu, Shoufu Tian|<https://arxiv.org/pdf/2512.18291v2>|æ— |
|ğŸ†• å‘å¸ƒ|FlyPose: Towards Robust Human Pose Estimation From Aerial Views|FlyPose: é¢å‘é²æ£’çš„èˆªæ‹è§†è§’äººä½“å§¿æ€ä¼°è®¡|Hassaan Farooq, Marvin Brenner, Peter St\Ã¼tz|<https://arxiv.org/pdf/2601.05747v1>|[ä»£ç ](https://github.com/farooqhassaan/FlyPose.)|
|ğŸ“ æ›´æ–°|Dense 3D Displacement Estimation for Landslide Monitoring via Fusion of TLS Point Clouds and Embedded RGB Images|ç”¨äºæ»‘å¡ç›‘æµ‹çš„TLSç‚¹äº‘ä¸åµŒå…¥å¼RGBå›¾åƒèåˆçš„å¯†é›†3Dä½ç§»ä¼°è®¡|Zhaoyi Wang, Jemil Avers Butt, Shengyu Huang, Tomislav Medic, Andreas Wieser|<https://arxiv.org/pdf/2506.16265v2>|[ä»£ç ](https://github.com/gseg-ethz/fusion4landslide.)|
|ğŸ“ æ›´æ–°|TRec: Learning Hand-Object Interactions through 2D Point Track Motion|TRec: é€šè¿‡2Dç‚¹è·Ÿè¸ªè¿åŠ¨å­¦ä¹ æ‰‹-ç‰©ä½“äº¤äº’|Dennis Holzmann, Sven Wachsmuth|<https://arxiv.org/pdf/2601.03667v3>|æ— |
|ğŸ“ æ›´æ–°|Probing Deep into Temporal Profile Makes the Infrared Small Target Detector Much Better|æ·±å…¥æ¢ç©¶æ—¶é—´ç‰¹å¾ä½¿çº¢å¤–å°ç›®æ ‡æ£€æµ‹å™¨æ€§èƒ½æ˜¾è‘—æå‡|Ruojing Li, Wei An, Yingqian Wang, Xinyi Ying, Yimian Dai, Longguang Wang, Miao Li, Yulan Guo .etc.|<https://arxiv.org/pdf/2506.12766v3>|[ä»£ç ](https://github.com/TinaLRJ/DeepPro.)|
|ğŸ†• å‘å¸ƒ|TAPM-Net: Trajectory-Aware Perturbation Modeling for Infrared Small Target Detection|TAPM-Net: ç”¨äºçº¢å¤–å°ç›®æ ‡æ£€æµ‹çš„è½¨è¿¹æ„ŸçŸ¥æ‰°åŠ¨å»ºæ¨¡|Hongyang Xie, Hongyang He, Victor Sanchez|<https://arxiv.org/pdf/2601.05446v1>|æ— |


### å›¾åƒåˆ†ç±»ä¸è¯†åˆ« (Image Classification & Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Adaptive aggregation of Monte Carlo augmented decomposed filters for efficient group-equivariant convolutional neural network|Monte Carloå¢å¼ºåˆ†è§£æ»¤æ³¢å™¨çš„è‡ªé€‚åº”èšåˆï¼Œç”¨äºé«˜æ•ˆgroup-equivariantå·ç§¯ç¥ç»ç½‘ç»œ|Wenzhao Zhao, Barbara D. Wichtmann, Steffen Albert, Angelika Maurer, Frank G. ZÃ¶llner, JÃ¼rgen Hesser|<https://arxiv.org/pdf/2305.10110v4>|[ä»£ç ](https://github.com/ZhaoWenzhao/MCG_CNN.)|
|ğŸ†• å‘å¸ƒ|Prompt-Free SAM-Based Multi-Task Framework for Breast Ultrasound Lesion Segmentation and Classification|åŸºäºSAMçš„æ— æç¤ºå¤šä»»åŠ¡æ¡†æ¶ç”¨äºä¹³è…ºè¶…å£°ç—…ç¶åˆ†å‰²ä¸åˆ†ç±»|Samuel E. Johnny, Bernes L. Atabonfack, Israel Alagbe, Assane Gueye|<https://arxiv.org/pdf/2601.05498v1>|æ— |


### è¯­ä¹‰/å®ä¾‹åˆ†å‰² (Semantic/Instance Segmentation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|AURASeg: Attention Guided Upsampling with Residual Boundary-Assistive Refinement for Drivable-Area Segmentation|AURASeg: ç”¨äºå¯è¡Œé©¶åŒºåŸŸåˆ†å‰²çš„åŸºäºæ³¨æ„åŠ›å¼•å¯¼ä¸Šé‡‡æ ·å’Œæ®‹å·®è¾¹ç•Œè¾…åŠ©ä¼˜åŒ–çš„æ–¹æ³•|Narendhiran Vijayakumar, Sridevi. M|<https://arxiv.org/pdf/2510.21536v2>|[ä»£ç ](https://github.com/Narendhiranv04/AURASeg)|


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Adaptive Conditional Contrast-Agnostic Deformable Image Registration with Uncertainty Estimation|å…·æœ‰ä¸ç¡®å®šæ€§ä¼°è®¡çš„è‡ªé€‚åº”æ¡ä»¶å¯¹æ¯”æ— å…³å¯å˜å½¢å›¾åƒé…å‡†|Yinsong Wang, Xinzhe Luo, Siyi Du, Chen Qin|<https://arxiv.org/pdf/2601.05981v1>|[ä»£ç ](https://github.com/Yinsong0510/AC-CAR.)|
|ğŸ“ æ›´æ–°|Controlled Automatic Task-Specific Synthetic Data Generation for Hallucination Detection|ç”¨äºå¹»è§‰æ£€æµ‹çš„å—æ§è‡ªåŠ¨ä»»åŠ¡ç‰¹å®šåˆæˆæ•°æ®ç”Ÿæˆ|Yong Xie, Karan Aggarwal, Aitzaz Ahmad, Stephen Lau|<https://arxiv.org/pdf/2410.12278v2>|æ— |
|ğŸ†• å‘å¸ƒ|VideoAR: Autoregressive Video Generation via Next-Frame & Scale Prediction|VideoAR: é€šè¿‡ä¸‹ä¸€å¸§ä¸å°ºåº¦é¢„æµ‹çš„è‡ªå›å½’è§†é¢‘ç”Ÿæˆ|Longbin Ji, Xiaoxiong Liu, Junyuan Shang, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang|<https://arxiv.org/pdf/2601.05966v1>|æ— |
|ğŸ†• å‘å¸ƒ|Context-Aware Decoding for Faithful Vision-Language Generation|[ç¿»è¯‘å¤±è´¥] Context-Aware Decoding for Faithful Vision-Language Generation|Mehrdad Fazli, Bowen Wei, Ziwei Zhu|<https://arxiv.org/pdf/2601.05939v1>|æ— |
|ğŸ†• å‘å¸ƒ|Goal Force: Teaching Video Models To Accomplish Physics-Conditioned Goals|Goal Force: æ•™æˆ Video Models å®ç°åŸºäº Physics-Conditioned çš„ç›®æ ‡|Nate Gillman, Yinghua Zhou, Zitian Tang, Evan Luo, Arjan Chakravarthy, Daksh Aggarwal, Michael Freeman, Charles Herrmann .etc.|<https://arxiv.org/pdf/2601.05848v1>|æ— |
|ğŸ†• å‘å¸ƒ|TAGRPO: Boosting GRPO on Image-to-Video Generation with Direct Trajectory Alignment|TAGRPO: é€šè¿‡ç›´æ¥è½¨è¿¹å¯¹é½æå‡å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆä¸­çš„ GRPO|Jin Wang, Jianxiang Lu, Guangzheng Xu, Comi Chen, Haoyu Yang, Linqing Wang, Peng Chen, Mingtao Chen .etc.|<https://arxiv.org/pdf/2601.05729v1>|æ— |
|ğŸ†• å‘å¸ƒ|Rotate Your Character: Revisiting Video Diffusion Models for High-Quality 3D Character Generation|Rotate Your Character: é‡æ–°å®¡è§†ç”¨äºé«˜è´¨é‡ 3D Character ç”Ÿæˆçš„ Video Diffusion Models|Jin Wang, Jianxiang Lu, Comi Chen, Guangzheng Xu, Haoyu Yang, Peng Chen, Na Zhang, Yifan Xu .etc.|<https://arxiv.org/pdf/2601.05722v1>|æ— |
|ğŸ“ æ›´æ–°|Neural-Driven Image Editing|Neural-Driven å›¾åƒç¼–è¾‘|Pengfei Zhou, Jie Xia, Xiaopeng Peng, Wangbo Zhao, Zilong Ye, Zekai Li, Suorong Yang, Jiadong Pan .etc.|<https://arxiv.org/pdf/2507.05397v3>|æ— |
|ğŸ“ æ›´æ–°|3D-WAG: Hierarchical Wavelet-Guided Autoregressive Generation for High-Fidelity 3D Shapes|3D-WAG: ç”¨äºé«˜ä¿çœŸ3Då½¢çŠ¶çš„åˆ†å±‚å°æ³¢å¼•å¯¼è‡ªå›å½’ç”Ÿæˆ|Tejaswini Medi, Arianna Rampini, Pradyumna Reddy, Pradeep Kumar Jayaraman, Margret Keuper|<https://arxiv.org/pdf/2411.19037v3>|æ— |
|ğŸ†• å‘å¸ƒ|SketchVL: Policy Optimization via Fine-Grained Credit Assignment for Chart Understanding and More|SketchVLï¼šé€šè¿‡ç»†ç²’åº¦ä¿¡ç”¨åˆ†é…è¿›è¡Œç­–ç•¥ä¼˜åŒ–ï¼Œç”¨äºå›¾è¡¨ç†è§£åŠæ›´å¤šä»»åŠ¡|Muye Huang, Lingling Zhang, Yifei Li, Yaqiang Wu, Jun Liu|<https://arxiv.org/pdf/2601.05688v1>|æ— |
|ğŸ†• å‘å¸ƒ|AGDC: Autoregressive Generation of Variable-Length Sequences with Joint Discrete and Continuous Spaces|AGDCï¼šè”åˆç¦»æ•£å’Œè¿ç»­ç©ºé—´çš„å˜é•¿åºåˆ—è‡ªå›å½’ç”Ÿæˆ|Yeonsang Shin, Insoo Kim, Bongkeun Kim, Keonwoo Bae, Bohyung Han|<https://arxiv.org/pdf/2601.05680v1>|æ— |
|ğŸ“ æ›´æ–°|Subject-driven Video Generation via Disentangled Identity and Motion|åŸºäºè§£è€¦èº«ä»½å’Œè¿åŠ¨çš„ä¸»ä½“é©±åŠ¨è§†é¢‘ç”Ÿæˆ|Daneul Kim, Jingxu Zhang, Wonjoon Jin, Sunghyun Cho, Qi Dai, Jaesik Park, Chong Luo|<https://arxiv.org/pdf/2504.17816v2>|æ— |
|ğŸ“ æ›´æ–°|Video Generation Models Are Good Latent Reward Models|è§†é¢‘ç”Ÿæˆæ¨¡å‹æ˜¯ä¼˜ç§€çš„æ½œåœ¨å¥–åŠ±æ¨¡å‹|Xiaoyue Mi, Wenqing Yu, Jiesong Lian, Shibo Jie, Ruizhe Zhong, Zijun Liu, Guozhen Zhang, Zixiang Zhou .etc.|<https://arxiv.org/pdf/2511.21541v3>|æ— |
|ğŸ†• å‘å¸ƒ|Towards Generalized Multi-Image Editing for Unified Multimodal Models|é¢å‘ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹çš„é€šç”¨å¤šå›¾åƒç¼–è¾‘|Pengcheng Xu, Peng Tang, Donghao Luo, Xiaobin Hu, Weichu Cui, Qingdong He, Zhennan Chen, Jiangning Zhang .etc.|<https://arxiv.org/pdf/2601.05572v1>|æ— |
|ğŸ“ æ›´æ–°|Scaling Beyond Context: A Survey of Multimodal Retrieval-Augmented Generation for Document Understanding|è¶…è¶Šä¸Šä¸‹æ–‡æ‰©å±•ï¼šé¢å‘æ–‡æ¡£ç†è§£çš„å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆç»¼è¿°|Sensen Gao, Shanshan Zhao, Xu Jiang, Lunhao Duan, Yong Xien Chng, Qing-Guo Chen, Weihua Luo, Kaifu Zhang .etc.|<https://arxiv.org/pdf/2510.15253v2>|æ— |
|ğŸ†• å‘å¸ƒ|MoGen: A Unified Collaborative Framework for Controllable Multi-Object Image Generation|MoGen: ä¸€ä¸ªç”¨äºå¯æ§å¤šå¯¹è±¡å›¾åƒç”Ÿæˆçš„ç»Ÿä¸€åä½œæ¡†æ¶|Yanfeng Li, Yue Sun, Keren Fu, Sio-Kei Im, Xiaoming Liu, Guangtao Zhai, Xiaohong Liu, Tao Tan|<https://arxiv.org/pdf/2601.05546v1>|[ä»£ç ](https://github.com/Tear-kitty/MoGen)|
|ğŸ“ æ›´æ–°|ThinkRL-Edit: Thinking in Reinforcement Learning for Reasoning-Centric Image Editing|ThinkRL-Edit: ä»¥æ¨ç†ä¸ºæ ¸å¿ƒçš„å›¾åƒç¼–è¾‘ä¸­çš„å¼ºåŒ–å­¦ä¹ æ€è€ƒ|Hengjia Li, Liming Jiang, Qing Yan, Yizhi Song, Hao Kang, Zichuan Liu, Xin Lu, Boxi Wu .etc.|<https://arxiv.org/pdf/2601.03467v2>|æ— |


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|LayerGS: Decomposition and Inpainting of Layered 3D Human Avatars via 2D Gaussian Splatting|LayerGS: åŸºäº2D Gaussian Splattingçš„åˆ†å±‚3Däººä½“åŒ–èº«åˆ†è§£ä¸ä¿®å¤|Yinghan Xu, John Dingliana|<https://arxiv.org/pdf/2601.05853v1>|[ä»£ç ](https://github.com/RockyXu66/LayerGS)|
|ğŸ†• å‘å¸ƒ|Kidney Cancer Detection Using 3D-Based Latent Diffusion Models|åŸºäº3D Latent Diffusion Modelsçš„è‚¾ç™Œæ£€æµ‹|Jen Dusseljee, Sarah de Boer, Alessa Hering|<https://arxiv.org/pdf/2601.05852v1>|æ— |
|ğŸ“ æ›´æ–°|CAST-LUT: Tokenizer-Guided HSV Look-Up Tables for Purple Flare Removal|[ç¿»è¯‘å¤±è´¥] CAST-LUT: Tokenizer-Guided HSV Look-Up Tables for Purple Flare Removal|Pu Wang, Shuning Sun, Jialang Lu, Chen Wu, Zhihua Zhang, Youshan Zhang, Chenggang Shan, Dianjie Lu .etc.|<https://arxiv.org/pdf/2511.06764v2>|æ— |
|ğŸ“ æ›´æ–°|AttriCtrl: Fine-Grained Control of Aesthetic Attribute Intensity in Diffusion Models|AttriCtrlï¼šDiffusion Models ä¸­å®¡ç¾å±æ€§å¼ºåº¦çš„ç»†ç²’åº¦æ§åˆ¶|Die Chen, Zhongjie Duan, Zhiwen Li, Cen Chen, Daoyuan Chen, Yaliang Li, Yingda Chen|<https://arxiv.org/pdf/2508.02151v2>|æ— |
|ğŸ“ æ›´æ–°|Sprint: Sparse-Dense Residual Fusion for Efficient Diffusion Transformers|Sprintï¼šç”¨äºé«˜æ•ˆ Diffusion Transformers çš„ç¨€ç–-å¯†é›†æ®‹å·®èåˆ|Dogyun Park, Moayed Haji-Ali, Yanyu Li, Willi Menapace, Sergey Tulyakov, Hyunwoo J. Kim, Aliaksandr Siarohin, Anil Kag|<https://arxiv.org/pdf/2510.21986v2>|æ— |


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SceneFoundry: Generating Interactive Infinite 3D Worlds|SceneFoundryï¼šç”Ÿæˆäº¤äº’å¼æ— é™3Dä¸–ç•Œ|ChunTeng Chen, YiChen Hsu, YiWen Liu, WeiFang Sun, TsaiChing Ni, ChunYi Lee, Min Sun, YuanFu Yang|<https://arxiv.org/pdf/2601.05810v1>|æ— |
|ğŸ†• å‘å¸ƒ|Generalizable and Adaptive Continual Learning Framework for AI-generated Image Detection|å¯æ³›åŒ–ä¸”è‡ªé€‚åº”çš„æŒç»­å­¦ä¹ æ¡†æ¶ç”¨äºAIç”Ÿæˆå›¾åƒæ£€æµ‹|Hanyi Wang, Jun Lan, Yaoyu Kang, Huijia Zhu, Weiqiang Wang, Zhuosheng Zhang, Shilin Wang|<https://arxiv.org/pdf/2601.05580v1>|æ— |
|ğŸ“ æ›´æ–°|Transferability of Adversarial Attacks in Video-based MLLMs: A Cross-modal Image-to-Video Approach|åŸºäºè§†é¢‘çš„MLLMsä¸­å¯¹æŠ—æ”»å‡»çš„å¯è¿ç§»æ€§ï¼šä¸€ç§è·¨æ¨¡æ€Image-to-Videoæ–¹æ³•|Linhao Huang, Xue Jiang, Zhiqiang Wang, Wentao Mo, Xi Xiao, Yong-Jie Yin, Bo Han, Feng Zheng|<https://arxiv.org/pdf/2501.01042v4>|æ— |


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|VIB-Probe: Detecting and Mitigating Hallucinations in Vision-Language Models via Variational Information Bottleneck|VIB-Probe: é€šè¿‡å˜åˆ†ä¿¡æ¯ç“¶é¢ˆæ£€æµ‹å’Œç¼“è§£ Vision-Language Models ä¸­çš„å¹»è§‰|Feiran Zhang, Yixin Wu, Zhenghua Wang, Xiaohua Wang, Changze Lv, Xuanjing Huang, Xiaoqing Zheng|<https://arxiv.org/pdf/2601.05547v1>|æ— |


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Reflect3r: Single-View 3D Stereo Reconstruction Aided by Mirror Reflections|Reflect3r: å€ŸåŠ©é•œé¢åå°„çš„å•è§†è§’ 3D ç«‹ä½“é‡å»º|Jing Wu, Zirui Wang, Iro Laina, Victor Adrian Prisacariu|<https://arxiv.org/pdf/2509.20607v2>|æ— |
|ğŸ“ æ›´æ–°|DYRECT Computed Tomography: DYnamic Reconstruction of Events on a Continuous Timescale|DYRECT Computed Tomographyï¼šè¿ç»­æ—¶é—´å°ºåº¦ä¸Šçš„äº‹ä»¶åŠ¨æ€é‡å»º|Wannes Goethals, Tom Bultreys, Steffen Berg, Matthieu N. Boone, Jan Aelterman|<https://arxiv.org/pdf/2412.00065v2>|æ— |
|ğŸ†• å‘å¸ƒ|GeoSurDepth: Spatial Geometry-Consistent Self-Supervised Depth Estimation for Surround-View Cameras|GeoSurDepth: é’ˆå¯¹ç¯è§†ç›¸æœºçš„ç©ºé—´å‡ ä½•ä¸€è‡´æ€§è‡ªç›‘ç£æ·±åº¦ä¼°è®¡|Weimin Liu, Wenjun Wang, Joshua H. Meng|<https://arxiv.org/pdf/2601.05839v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Adaptive Disentangled Representation Learning for Incomplete Multi-View Multi-Label Classification|é¢å‘Incomplete Multi-View Multi-Label Classificationçš„è‡ªé€‚åº”è§£è€¦è¡¨ç¤ºå­¦ä¹ |Quanjiang Li, Zhiming Liu, Tianxiang Xu, Tingjin Luo, Chenping Hou|<https://arxiv.org/pdf/2601.05785v1>|æ— |


### è§†è§‰å®šä½ä¸æ˜ å°„ (Visual Localization & Mapping)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Solving Inverse Problems in Stochastic Self-Organizing Systems through Invariant Representations|é€šè¿‡ä¸å˜è¡¨ç¤ºæ±‚è§£éšæœºè‡ªç»„ç»‡ç³»ç»Ÿä¸­çš„é€†é—®é¢˜|Elias Najarro, Nicolas Bessone, Sebastian Risi|<https://arxiv.org/pdf/2506.11796v2>|æ— |
|ğŸ†• å‘å¸ƒ|FeatureSLAM: Feature-enriched 3D gaussian splatting SLAM in real time|FeatureSLAM: å®æ—¶ç‰¹å¾å¢å¼ºçš„3D Gaussian Splatting SLAM|Christopher Thirgood, Oscar Mendez, Erin Ling, Jon Storey, Simon Hadfield|<https://arxiv.org/pdf/2601.05738v1>|æ— |


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|SLAM&Render: A Benchmark for the Intersection Between Neural Rendering, Gaussian Splatting and SLAM|SLAM&Render: ç¥ç»æ¸²æŸ“ã€Gaussian Splatting ä¸ SLAM äº¤å‰é¢†åŸŸçš„åŸºå‡†|Samuel Cerezo, Gaetano Meli, TomÃ¡s Berriel Martins, Kirill Safronov, Javier Civera|<https://arxiv.org/pdf/2504.13713v5>|æ— |
|ğŸ†• å‘å¸ƒ|SAS-VPReID: A Scale-Adaptive Framework with Shape Priors for Video-based Person Re-Identification at Extreme Far Distances|SAS-VPReID: ä¸€ç§åŸºäºå½¢çŠ¶å…ˆéªŒçš„å°ºåº¦è‡ªé€‚åº”æ¡†æ¶ï¼Œç”¨äºæè¿œè·ç¦»ä¸‹çš„åŸºäºè§†é¢‘çš„äººå‘˜é‡è¯†åˆ«|Qiwei Yang, Pingping Zhang, Yuhao Wang, Zijing Gong|<https://arxiv.org/pdf/2601.05535v1>|[ä»£ç ](https://github.com/YangQiWei3/SAS-VPReID.)|


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Causality-Aware Temporal Projection for Video Understanding in Video-LLMs|[ç¿»è¯‘å¤±è´¥] Causality-Aware Temporal Projection for Video Understanding in Video-LLMs|Zhengjian Kang, Qi Chen, Rui Liu, Kangtong Mo, Xingyu Zhang, Xiaoyu Deng, Ye Zhang|<https://arxiv.org/pdf/2601.01804v2>|æ— |
|ğŸ†• å‘å¸ƒ|GaussianSwap: Animatable Video Face Swapping with 3D Gaussian Splatting|GaussianSwap: åŸºäº 3D Gaussian Splatting çš„å¯åŠ¨ç”»è§†é¢‘äººè„¸æ›¿æ¢|Xuan Cheng, Jiahao Rao, Chengyang Li, Wenhao Wang, Weilin Chen, Lvqing Yang|<https://arxiv.org/pdf/2601.05511v1>|æ— |


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Efficient Bayesian Computation Using Plug-and-Play Priors for Poisson Inverse Problems|ä½¿ç”¨ Plug-and-Play Priors è¿›è¡Œæ³Šæ¾é€†é—®é¢˜çš„é«˜æ•ˆè´å¶æ–¯è®¡ç®—|Teresa Klatzer, Savvas Melidonis, Marcelo Pereyra, Konstantinos C. Zygalakis|<https://arxiv.org/pdf/2503.16222v2>|[ä»£ç ](https://github.com/freyyia/pnp-langevin-poisson.)|
|ğŸ†• å‘å¸ƒ|DIFF-MF: A Difference-Driven Channel-Spatial State Space Model for Multi-Modal Image Fusion|DIFF-MF: ä¸€ç§é¢å‘å¤šæ¨¡æ€å›¾åƒèåˆçš„å·®åˆ†é©±åŠ¨é€šé“-ç©ºé—´çŠ¶æ€ç©ºé—´æ¨¡å‹|Yiming Sun, Zifan Ye, Qinghua Hu, Pengfei Zhu|<https://arxiv.org/pdf/2601.05538v1>|æ— |


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Low-Latency Event-Based Velocimetry for Quadrotor Control in a Narrow Pipe|ç”¨äºç‹­çª„ç®¡é“ä¸­ Quadrotor æ§åˆ¶çš„ä½å»¶è¿Ÿ Event-Based æµ‹é€Ÿ|Leonard Bauersfeld, Davide Scaramuzza|<https://arxiv.org/pdf/2507.15444v2>|æ— |
|ğŸ†• å‘å¸ƒ|Quantifying and Inducing Shape Bias in CNNs via Max-Pool Dilation|é€šè¿‡ Max-Pool Dilation é‡åŒ–å¹¶è¯±å¯¼ CNNs ä¸­çš„ Shape Bias|Takito Sawada, Akinori Iwata, Masahiro Okuda|<https://arxiv.org/pdf/2601.05599v1>|æ— |
|ğŸ†• å‘å¸ƒ|ROAP: A Reading-Order and Attention-Prior Pipeline for Optimizing Layout Transformers in Key Information Extraction|ROAPï¼šä¸€ç§ç”¨äºä¼˜åŒ–å…³é”®ä¿¡æ¯æå–ä¸­ Layout Transformers çš„é˜…è¯»é¡ºåºå’Œæ³¨æ„åŠ›å…ˆéªŒ Pipeline|Tingwei Xie, Jinxin He, Yonghong Song|<https://arxiv.org/pdf/2601.05470v1>|[ä»£ç ](https://github.com/KevinYuLei/ROAP.)|


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Compressing image encoders via latent distillation|é€šè¿‡ latent distillation å‹ç¼© image encoders|Caroline Mazini Rodrigues, Nicolas Keriven, Thomas Maugey|<https://arxiv.org/pdf/2601.05639v1>|æ— |
|ğŸ†• å‘å¸ƒ|GS-DMSR: Dynamic Sensitive Multi-scale Manifold Enhancement for Accelerated High-Quality 3D Gaussian Splatting|GS-DMSR: ç”¨äºåŠ é€Ÿé«˜è´¨é‡3D Gaussian Splattingçš„åŠ¨æ€æ•æ„Ÿå¤šå°ºåº¦æµå½¢å¢å¼º|Nengbo Lu, Minghua Pan, Shaohua Sun, Yizhou Liang|<https://arxiv.org/pdf/2601.05584v1>|æ— |
|ğŸ“ æ›´æ–°|CombatVLA: An Efficient Vision-Language-Action Model for Combat Tasks in 3D Action Role-Playing Games|CombatVLAï¼šä¸€ç§ç”¨äº3DåŠ¨ä½œè§’è‰²æ‰®æ¼”æ¸¸æˆä¸­æˆ˜æ–—ä»»åŠ¡çš„é«˜æ•ˆVision-Language-Actionæ¨¡å‹|Peng Chen, Pi Bu, Yingyao Wang, Xinyi Wang, Ziming Wang, Jie Guo, Yingxiu Zhao, Qi Zhu .etc.|<https://arxiv.org/pdf/2503.09527v2>|[ä»£ç ](https://combatvla.github.io/.)|
|ğŸ†• å‘å¸ƒ|Enabling Stroke-Level Structural Analysis of Hieroglyphic Scripts without Language-Specific Priors|[ç¿»è¯‘å¤±è´¥] Enabling Stroke-Level Structural Analysis of Hieroglyphic Scripts without Language-Specific Priors|Fuwen Luo, Zihao Wan, Ziyue Wang, Yaluo Liu, Pau Tong Lin Xu, Xuanjia Qiao, Xiaolong Wang, Peng Li .etc.|<https://arxiv.org/pdf/2601.05508v1>|[ä»£ç ](https://github.com/THUNLP-MT/HieroSA.)|


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### å¯¹æŠ—é²æ£’æ€§ (Adversarial Robustness)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Deepfake detectors are DUMB: A benchmark to assess adversarial training robustness under transferability constraints|Deepfakeæ£€æµ‹å™¨æ˜¯DUMBï¼šä¸€ä¸ªè¯„ä¼°å¯è¿ç§»æ€§çº¦æŸä¸‹å¯¹æŠ—è®­ç»ƒé²æ£’æ€§çš„åŸºå‡†|Adrian Serrano, Erwan Umlil, Ronan Thomas|<https://arxiv.org/pdf/2601.05986v1>|æ— |


### åˆ†å¸ƒå¤–æ³›åŒ– (Out-of-distribution Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Higher-Order Domain Generalization in Magnetic Resonance-Based Assessment of Alzheimer's Disease|åŸºäºç£å…±æŒ¯çš„é˜¿å°”èŒ¨æµ·é»˜ç—…è¯„ä¼°ä¸­çš„é«˜é˜¶åŸŸæ³›åŒ–|Zobia Batool, Diala Lteif, Vijaya B. Kolachalama, Huseyin Ozkan, Erchan Aptoula|<https://arxiv.org/pdf/2601.01485v2>|[ä»£ç ](https://github.com/zobia111/Extended-Mixstyle.)|
|ğŸ†• å‘å¸ƒ|WaveRNet: Wavelet-Guided Frequency Learning for Multi-Source Domain-Generalized Retinal Vessel Segmentation|WaveRNet: ç”¨äºå¤šæºåŸŸæ³›åŒ–è§†ç½‘è†œè¡€ç®¡åˆ†å‰²çš„å°æ³¢å¼•å¯¼é¢‘ç‡å­¦ä¹ |Chanchan Wang, Yuanfang Wang, Qing Xu, Guanxin Chen|<https://arxiv.org/pdf/2601.05942v1>|[ä»£ç ](https://github.com/Chanchan-Wang/WaveRNet.)|


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Continual Learning of Achieving Forgetting-free and Positive Knowledge Transfer|å®ç°æ— é—å¿˜ä¸æ­£å‘çŸ¥è¯†è¿ç§»çš„Continual Learning|Zhi Wang, Zhongbin Wu, Yanni Li, Bing Liu, Guangxi Li, Yuping Wang|<https://arxiv.org/pdf/2601.05623v1>|æ— |
|ğŸ†• å‘å¸ƒ|Learning Geometric Invariance for Gait Recognition|Learningæ­¥è¯†åˆ«ä¸­çš„å‡ ä½•ä¸å˜æ€§å­¦ä¹ |Zengbin Wang, Junjie Li, Saihui Hou, Xu Liu, Chunshui Cao, Yongzhen Huang, Muyi Sun, Siye Wang .etc.|<https://arxiv.org/pdf/2601.05604v1>|æ— |
|ğŸ†• å‘å¸ƒ|Semi-Supervised Facial Expression Recognition based on Dynamic Threshold and Negative Learning|åŸºäºåŠ¨æ€é˜ˆå€¼å’Œè´Ÿå­¦ä¹ çš„åŠç›‘ç£é¢éƒ¨è¡¨æƒ…è¯†åˆ«|Zhongpeng Cai, Jun Yu, Wei Xu, Tianyu Liu, Jianqing Sun, Jiaen Liang|<https://arxiv.org/pdf/2601.05556v1>|æ— |
|ğŸ“ æ›´æ–°|Branch, or Layer? Zeroth-Order Optimization for Continual Learning of Vision-Language Models|[ç¿»è¯‘å¤±è´¥] Branch, or Layer? Zeroth-Order Optimization for Continual Learning of Vision-Language Models|Ziwei Liu, Borui Kang, Wei Li, Hangjie Yuan, Yanbing Yang, Wenbin Li, Yifan Zhu, Tao Feng .etc.|<https://arxiv.org/pdf/2506.12409v3>|æ— |
|ğŸ“ æ›´æ–°|From Preoperative CT to Postmastoidectomy Mesh Construction: Mastoidectomy Shape Prediction for Cochlear Implant Surgery|ä»æœ¯å‰CTåˆ°ä¹³çªåˆ‡é™¤æœ¯åMeshæ„å»ºï¼šç”¨äºäººå·¥è€³èœ—æ‰‹æœ¯çš„ä¹³çªåˆ‡é™¤å½¢çŠ¶é¢„æµ‹|Yike Zhang, Eduardo Davalos, Dingjie Su, Ange Lou, Jack Noble|<https://arxiv.org/pdf/2601.04405v2>|åˆ†æå¤±è´¥|


### é›¶/å°‘æ ·æœ¬æ³›åŒ– (Zero/Few-shot Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Orient Anything V2: Unifying Orientation and Rotation Understanding|Orient Anything V2: ç»Ÿä¸€æ–¹å‘ä¸æ—‹è½¬ç†è§£|Zehan Wang, Ziang Zhang, Jiayang Xu, Jialei Wang, Tianyu Pang, Chao Du, HengShuang Zhao, Zhou Zhao|<https://arxiv.org/pdf/2601.05573v1>|æ— |


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Router-Suggest: Dynamic Routing for Multimodal Auto-Completion in Visually-Grounded Dialogs|Router-Suggest: Visually-Grounded Dialogsä¸­å¤šæ¨¡æ€è‡ªåŠ¨è¡¥å…¨çš„åŠ¨æ€è·¯ç”±|Sandeep Mishra, Devichand Budagam, Anubhab Mandal, Bishal Santra, Pawan Goyal, Manish Gupta|<https://arxiv.org/pdf/2601.05851v1>|æ— |
|ğŸ“ æ›´æ–°|From See to Shield: ML-Assisted Fine-Grained Access Control for Visual Data|ä»çœ‹è§åˆ°é˜²æŠ¤ï¼šé¢å‘è§†è§‰æ•°æ®çš„ ML è¾…åŠ©ç»†ç²’åº¦è®¿é—®æ§åˆ¶|Mete Harun Akcay, Buse Gul Atli, Siddharth Prakash Rao, Alexandros Bakas|<https://arxiv.org/pdf/2510.19418v2>|æ— |
|ğŸ“ æ›´æ–°|PixelArena: A benchmark for Pixel-Precision Visual Intelligence|PixelArena: ä¸€ä¸ªç”¨äºPixel-Precisionè§†è§‰æ™ºèƒ½çš„åŸºå‡†|Feng Liang, Sizhe Cheng, Chenqi Yi, Yong Wang|<https://arxiv.org/pdf/2512.16303v2>|æ— |
|ğŸ“ æ›´æ–°|360DVO: Deep Visual Odometry for Monocular 360-Degree Camera|360DVO: é¢å‘å•ç›® 360 åº¦ç›¸æœºçš„æ·±åº¦è§†è§‰é‡Œç¨‹è®¡|Xiaopeng Guo, Yinzhe Xu, Huajian Huang, Sai-Kit Yeung|<https://arxiv.org/pdf/2601.02309v2>|[ä»£ç ](https://chris1004336379.github.io/360DVO-homepage)|
|ğŸ†• å‘å¸ƒ|SceneAlign: Aligning Multimodal Reasoning to Scene Graphs in Complex Visual Scenes|SceneAlign: åœ¨å¤æ‚è§†è§‰åœºæ™¯ä¸­å°†å¤šæ¨¡æ€æ¨ç†ä¸åœºæ™¯å›¾å¯¹é½|Chuhan Wang, Xintong Li, Jennifer Yuntong Zhang, Junda Wu, Chengkai Huang, Lina Yao, Julian McAuley, Jingbo Shang|<https://arxiv.org/pdf/2601.05600v1>|æ— |
|ğŸ“ æ›´æ–°|CoV: Chain-of-View Prompting for Spatial Reasoning|CoVï¼šç”¨äºç©ºé—´æ¨ç†çš„Chain-of-View Prompting|Haoyu Zhao, Akide Liu, Zeyu Zhang, Weijie Wang, Feng Chen, Ruihan Zhu, Gholamreza Haffari, Bohan Zhuang|<https://arxiv.org/pdf/2601.05172v2>|[ä»£ç ](https://github.com/ziplab/CoV)|
|ğŸ“ æ›´æ–°|RxnBench: A Multimodal Benchmark for Evaluating Large Language Models on Chemical Reaction Understanding from Scientific Literature|RxnBenchï¼šä¸€ä¸ªç”¨äºè¯„ä¼° Large Language Models ä»ç§‘å­¦æ–‡çŒ®ä¸­ç†è§£åŒ–å­¦ååº”çš„ Multimodal Benchmark|Hanzheng Li, Xi Fang, Yixuan Li, Chaozheng Huang, Junjie Wang, Xi Wang, Hongzhe Bai, Bojun Hao .etc.|<https://arxiv.org/pdf/2512.23565v3>|æ— |


### è§†è§‰å†…å®¹æè¿° (Visual Content Description)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MMViR: A Multi-Modal and Multi-Granularity Representation for Long-range Video Understanding|MMViR: ä¸€ç§ç”¨äºé•¿è§†é¢‘ç†è§£çš„å¤šæ¨¡æ€å¤šç²’åº¦è¡¨ç¤º|Zizhong Li, Haopeng Zhang, Jiawei Zhang|<https://arxiv.org/pdf/2601.05495v1>|æ— |


### è·¨æ¨¡æ€æ£€ç´¢ä¸åŒ¹é… (Cross-modal Retrieval & Matching)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|e5-omni: Explicit Cross-modal Alignment for Omni-modal Embeddings|e5-omni: ç”¨äºOmni-modal Embeddingsçš„æ˜¾å¼è·¨æ¨¡æ€å¯¹é½|Haonan Chen, Sicheng Gao, Radu Timofte, Tetsuya Sakai, Zhicheng Dou|<https://arxiv.org/pdf/2601.03666v2>|æ— |


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Co-Training Vision Language Models for Remote Sensing Multi-task Learning|[ç¿»è¯‘å¤±è´¥] Co-Training Vision Language Models for Remote Sensing Multi-task Learning|Qingyun Li, Shuran Ma, Junwei Luo, Yi Yu, Yue Zhou, Fengxiang Wang, Xudong Lu, Xiaoxing Wang .etc.|<https://arxiv.org/pdf/2511.21272v2>|æ— |
|ğŸ“ æ›´æ–°|Multimodal Interpretation of Remote Sensing Images: Dynamic Resolution Input Strategy and Multi-scale Vision-Language Alignment Mechanism|[ç¿»è¯‘å¤±è´¥] Multimodal Interpretation of Remote Sensing Images: Dynamic Resolution Input Strategy and Multi-scale Vision-Language Alignment Mechanism|Siyu Zhang, Lianlei Shan, Runhe Qiu|<https://arxiv.org/pdf/2512.23243v2>|æ— |
|ğŸ†• å‘å¸ƒ|SGDrive: Scene-to-Goal Hierarchical World Cognition for Autonomous Driving|SGDrive: ç”¨äºè‡ªåŠ¨é©¾é©¶çš„Scene-to-Goalåˆ†å±‚ä¸–ç•Œè®¤çŸ¥|Jingyu Li, Junjie Wu, Dongnan Hu, Xiangkai Huang, Bin Sun, Zhihui Hao, Xianpeng Lang, Xiatian Zhu .etc.|<https://arxiv.org/pdf/2601.05640v1>|æ— |
|ğŸ“ æ›´æ–°|LightFormer: A lightweight and efficient decoder for remote sensing image segmentation|LightFormer: ä¸€ç§ç”¨äºé¥æ„Ÿå›¾åƒåˆ†å‰²çš„è½»é‡çº§é«˜æ•ˆè§£ç å™¨|Sihang Chen, Lijun Yun, Ze Liu, JianFeng Zhu, Jie Chen, Hui Wang, Yueping Nie|<https://arxiv.org/pdf/2504.10834v3>|æ— |


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|ImageNet-trained CNNs are not biased towards texture: Revisiting feature reliance through controlled suppression|ImageNetè®­ç»ƒçš„CNNå¹¶ä¸åå‘çº¹ç†ï¼šé€šè¿‡å—æ§æŠ‘åˆ¶é‡æ–°å®¡è§†ç‰¹å¾ä¾èµ–|Tom Burgert, Oliver Stoll, Paolo Rota, BegÃ¼m Demir|<https://arxiv.org/pdf/2509.20234v5>|[ä»£ç ](https://github.com/tomburgert/feature-reliance.)|
|ğŸ“ æ›´æ–°|A Novel Patch-Based TDA Approach for Computed Tomography|ä¸€ç§åŸºäº Patch çš„ TDA æ–¹æ³•ç”¨äº Computed Tomography|Dashti A. Ali, Aras T. Asaad, Jacob J. Peoples, Mohammad Hamghalam, Alex Robins, Mane Piliposyan, Richard K. G. Do, Natalie Gangai .etc.|<https://arxiv.org/pdf/2512.12108v2>|æ— |
|ğŸ†• å‘å¸ƒ|Bidirectional Channel-selective Semantic Interaction for Semi-Supervised Medical Segmentation|åŒå‘é€šé“é€‰æ‹©æ€§è¯­ä¹‰äº¤äº’ç”¨äºåŠç›‘ç£åŒ»å­¦åˆ†å‰²|Kaiwen Huang, Yizhe Zhang, Yi Zhou, Tianyang Xu, Tao Zhou|<https://arxiv.org/pdf/2601.05855v1>|æ— |
|ğŸ†• å‘å¸ƒ|Multi-Image Super Resolution Framework for Detection and Analysis of Plant Roots|ç”¨äºæ¤ç‰©æ ¹ç³»æ£€æµ‹ä¸åˆ†æçš„å¤šå›¾åƒ Super Resolution æ¡†æ¶|Shubham Agarwal, Ofek Nourian, Michael Sidorov, Sharon Chemweno, Ofer Hadar, Naftali Lazarovitch, Jhonathan E. Ephrath|<https://arxiv.org/pdf/2601.05482v1>|æ— |


### æ™ºèƒ½äº¤é€šè§†è§‰ (Intelligent Transportation Vision)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|LatentVLA: Efficient Vision-Language Models for Autonomous Driving via Latent Action Prediction|LatentVLAï¼šé€šè¿‡Latent Action Predictionå®ç°è‡ªåŠ¨é©¾é©¶çš„é«˜æ•ˆVision-Language Models|Chengen Xie, Bin Sun, Tianyu Li, Junjie Wu, Zhihui Hao, XianPeng Lang, Hongyang Li|<https://arxiv.org/pdf/2601.05611v1>|æ— |


### åˆ›æ„åª’ä½“ç”Ÿæˆ (Creative Media Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Hippocampal Atrophy Patterns Across the Alzheimer's Disease Spectrum: A Voxel-Based Morphometry Analysis|é˜¿å°”èŒ¨æµ·é»˜ç—…è°±ç³»ä¸­çš„æµ·é©¬èç¼©æ¨¡å¼ï¼šåŸºäºä½“ç´ çš„å½¢æ€å­¦åˆ†æ|Trishna Niraula|<https://arxiv.org/pdf/2601.05494v1>|æ— |


## æ–°å…´ç†è®ºä¸è·¨å­¦ç§‘æ–¹å‘ (Emerging Theory & Interdisciplinary Directions)


### ç¥ç»-ç¬¦å·è§†è§‰ (Neuro-symbolic Vision)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|PII-VisBench: Evaluating Personally Identifiable Information Safety in Vision Language Models Along a Continuum of Visibility|PII-VisBenchï¼šè¯„ä¼° Vision Language Models åœ¨å¯è§æ€§è¿ç»­ä½“ä¸­çš„ PII å®‰å…¨æ€§|G M Shahariar, Zabir Al Nazi, Md Olid Hasan Bhuiyan, Zhouxing Shi|<https://arxiv.org/pdf/2601.05739v1>|æ— |


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|RobustFormer: Noise-Robust Pre-training for images and videos|RobustFormer: é¢å‘å›¾åƒå’Œè§†é¢‘çš„æŠ—å™ªé¢„è®­ç»ƒ|Ashish Bastola, Nishant Luitel, Hao Wang, Danda Pani Paudel, Roshani Poudel, Abolfazl Razi|<https://arxiv.org/pdf/2411.13040v2>|æ— |

