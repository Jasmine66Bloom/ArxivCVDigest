## [UPDATED!] **2026-01-10** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Consensus in the Parliament of AI: Harmonized Multi-Region CT-Radiomics and Foundation-Model Signatures for Multicentre NSCLC Risk Stratification|AIè®®ä¼šä¸­çš„å…±è¯†ï¼šç”¨äºå¤šä¸­å¿ƒNSCLCé£é™©åˆ†å±‚çš„åè°ƒå¤šåŒºåŸŸCT-Radiomicså’ŒFoundation-Modelç‰¹å¾|Shruti Atul Mali, Zohaib Salahuddin, Danial Khan, Yumeng Zhang, Henry C. Woodruff, Eduardo Ibor-Crespo, Ana Jimenez-Pastor, Luis Marti-Bonmati .etc.|<https://arxiv.org/pdf/2505.17893v2>|æ— |
|ğŸ“ æ›´æ–°|Towards Scalable Training for Handwritten Mathematical Expression Recognition|[ç¿»è¯‘å¤±è´¥] Towards Scalable Training for Handwritten Mathematical Expression Recognition|Haoyang Li, Jiaqing Li, Jialun Cao, Zongyuan Yang, Yongping Xiong|<https://arxiv.org/pdf/2508.09220v4>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|QCaption: Video Captioning and Q&A through Fusion of Large Multimodal Models|[ç¿»è¯‘å¤±è´¥] QCaption: Video Captioning and Q&A through Fusion of Large Multimodal Models|Jiale Wang, Gee Wah Ng, Lee Onn Mak, Randall Cher, Ng Ding Hei Ryan, Davis Wang|<https://arxiv.org/pdf/2601.06566v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Pengembangan Model untuk Mendeteksi Kerusakan pada Terumbu Karang dengan Klasifikasi Citra|ç”¨äºé€šè¿‡å›¾åƒåˆ†ç±»æ£€æµ‹çŠç‘šç¤æŸä¼¤çš„æ¨¡å‹å¼€å‘|Fadhil Muhammad, Alif Bintang Elfandra, Iqbal Pahlevi Amin, Alfan Farizki Wicaksono|<https://arxiv.org/pdf/2308.04337v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|SRFlow: A Dataset and Regularization Model for High-Resolution Facial Optical Flow via Splatting Rasterization|SRFlow: ä¸€ä¸ªé€šè¿‡Splatting Rasterizationå®ç°é«˜åˆ†è¾¨ç‡é¢éƒ¨å…‰æµçš„Datasetå’ŒRegularization Model|JiaLin Zhang, Dong Li|<https://arxiv.org/pdf/2601.06479v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems|ç”Ÿæˆå¼æ•°å­—å­ªç”Ÿï¼šç”¨äºå¯æ‰§è¡Œå·¥ä¸šç³»ç»Ÿçš„ Vision-Language ä»¿çœŸæ¨¡å‹|YuChe Hsu, AnJui Wang, TsaiChing Ni, YuanFu Yang|<https://arxiv.org/pdf/2512.20387v3>|[ä»£ç ](https://danielhsu2014.github.io/GDT-VLSM-project)|
|ğŸ“ æ›´æ–°|Parameter-efficient fine-tuning (PEFT) of Vision Foundation Models for Atypical Mitotic Figure Classification|Vision Foundation Models çš„å‚æ•°é«˜æ•ˆå¾®è°ƒ (PEFT) ç”¨äºéå…¸å‹æ ¸åˆ†è£‚è±¡åˆ†ç±»|Lavish Ramchandani, Gunjan Deotale, Dev Kumar Das|<https://arxiv.org/pdf/2509.16935v2>|æ— |
|ğŸ†• å‘å¸ƒ|How to Build Robust, Scalable Models for GSV-Based Indicators in Neighborhood Research|å¦‚ä½•æ„å»ºç”¨äºé‚»é‡Œç ”ç©¶ä¸­åŸºäºGSVæŒ‡æ ‡çš„é²æ£’ã€å¯æ‰©å±•æ¨¡å‹|Xiaoya Tang, Xiaohe Yue, Heran Mane, Dapeng Li, Quynh Nguyen, Tolga Tasdizen|<https://arxiv.org/pdf/2601.06443v1>|æ— |
|ğŸ†• å‘å¸ƒ|Semantic Enrichment of CAD-Based Industrial Environments via Scene Graphs for Simulation and Reasoning|åŸºäºScene Graphsçš„CADå·¥ä¸šç¯å¢ƒè¯­ä¹‰ä¸°å¯ŒåŒ–ï¼Œç”¨äºä»¿çœŸä¸æ¨ç†|Nathan Pascal Walus, Ranulfo Bezerra, Shotaro Kojima, Tsige Tadesse Alemayoh, Satoshi Tadokoro, Kazunori Ohno|<https://arxiv.org/pdf/2601.06415v1>|åˆ†æå¤±è´¥|


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Quantification and Classification of Carbon Nanotubes in Electron Micrographs using Vision Foundation Models|ç”µå­æ˜¾å¾®é•œå›¾åƒä¸­ç¢³çº³ç±³ç®¡çš„å®šé‡ä¸åˆ†ç±»ä½¿ç”¨ Vision Foundation Models|Sanjay Pradeep, Chen Wang, Matthew M. Dahm, Jeff D. Eldredge, Candace S. J. Tsai|<https://arxiv.org/pdf/2601.06673v1>|æ— |
|ğŸ“ æ›´æ–°|Practical Continual Forgetting for Pre-trained Vision Models|[ç¿»è¯‘å¤±è´¥] Practical Continual Forgetting for Pre-trained Vision Models|Hongbo Zhao, Fei Zhu, Bolin Ni, Feng Zhu, Gaofeng Meng, Zhaoxiang Zhang|<https://arxiv.org/pdf/2501.09705v2>|[ä»£ç ](https://github.com/bjzhb666/GS-LoRA.); åˆ†æå¤±è´¥|


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|OpenRT: An Open-Source Red Teaming Framework for Multimodal LLMs|OpenRTï¼šé¢å‘å¤šæ¨¡æ€LLMçš„å¼€æºçº¢é˜Ÿæµ‹è¯•æ¡†æ¶|Xin Wang, Yunhao Chen, Juncheng Li, Yixu Wang, Yang Yao, Tianle Gu, Jie Li, Yan Teng .etc.|<https://arxiv.org/pdf/2601.01592v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Towards Open-Vocabulary Industrial Defect Understanding with a Large-Scale Multimodal Dataset|è¿ˆå‘åŸºäºå¤§è§„æ¨¡å¤šæ¨¡æ€æ•°æ®é›†çš„å¼€æ”¾è¯æ±‡å·¥ä¸šç¼ºé™·ç†è§£|TsaiChing Ni, ZhenQi Chen, YuanFu Yang|<https://arxiv.org/pdf/2512.24160v2>|[ä»£ç ](https://ninaneon.github.io/projectpage); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Prototypicality Bias Reveals Blindspots in Multimodal Evaluation Metrics|Prototypicality Bias æ­ç¤ºäº†å¤šæ¨¡æ€è¯„ä¼°æŒ‡æ ‡çš„ç›²åŒº|Subhadeep Roy, Gagan Bhatia, Steffen Eger|<https://arxiv.org/pdf/2601.04946v2>|åˆ†æå¤±è´¥|


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### è¯­ä¹‰/å®ä¾‹åˆ†å‰² (Semantic/Instance Segmentation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Boosting Overlapping Organoid Instance Segmentation Using Pseudo-Label Unmixing and Synthesis-Assisted Learning|åˆ©ç”¨ä¼ªæ ‡ç­¾è§£æ··ä¸åˆæˆè¾…åŠ©å­¦ä¹ æå‡é‡å ç±»å™¨å®˜å®ä¾‹åˆ†å‰²|Gui Huang, Kangyuan Zheng, Xuan Cai, Jiaqi Wang, Jianjia Zhang, Kaida Ning, Wenbo Wei, Yujuan Zhu .etc.|<https://arxiv.org/pdf/2601.06642v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Towards Robust Pseudo-Label Learning in Semantic Segmentation: An Encoding Perspective|[ç¿»è¯‘å¤±è´¥] Towards Robust Pseudo-Label Learning in Semantic Segmentation: An Encoding Perspective|Wangkai Li, Rui Sun, Zhaoyang Li, Tianzhu Zhang|<https://arxiv.org/pdf/2512.06870v2>|[ä»£ç ](https://github.com/Woof6/ECOCSeg.); åˆ†æå¤±è´¥|


### ç›®æ ‡æ£€æµ‹ä¸å®šä½ (Object Detection & Localization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|LLMTrack: Semantic Multi-Object Tracking with Multi-modal Large Language Models|LLMTrack: åŸºäºå¤šæ¨¡æ€ Large Language Models çš„è¯­ä¹‰å¤šç›®æ ‡è·Ÿè¸ª|Pan Liao, Feng Yang, Di Wu, Jinwen Yu, Yuhua Zhu, Wenhui Zhao|<https://arxiv.org/pdf/2601.06550v1>|åˆ†æå¤±è´¥|


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Towards Egocentric 3D Hand Pose Estimation in Unseen Domains|[ç¿»è¯‘å¤±è´¥] Towards Egocentric 3D Hand Pose Estimation in Unseen Domains|Wiktor Mucha, Michael Wray, Martin Kampel|<https://arxiv.org/pdf/2601.06537v1>|åˆ†æå¤±è´¥|


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|PositionIC: Unified Position and Identity Consistency for Image Customization|PositionICï¼šç”¨äºå›¾åƒå®šåˆ¶çš„ç»Ÿä¸€ä½ç½®ä¸èº«ä»½ä¸€è‡´æ€§|Junjie Hu, Tianyang Han, Kai Ma, Jialin Gao, Song Yang, Xianhua He, Junfeng Luo, Xiaoming Wei .etc.|<https://arxiv.org/pdf/2507.13861v5>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|JoIN: Joint GANs Inversion for Intrinsic Image Decomposition|JoIN: ç”¨äºIntrinsic Image Decompositionçš„è”åˆGANs Inversion|Viraj Shah, Svetlana Lazebnik, Julien Philip|<https://arxiv.org/pdf/2305.11321v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Bridging Robustness and Efficiency: Real-Time Low-Light Enhancement via Attention U-Net GAN|[ç¿»è¯‘å¤±è´¥] Bridging Robustness and Efficiency: Real-Time Low-Light Enhancement via Attention U-Net GAN|Yash Thesia, Meera Suthar|<https://arxiv.org/pdf/2601.06518v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|SparseOccVLA: Bridging Occupancy and Vision-Language Models via Sparse Queries for Unified 4D Scene Understanding and Planning|SparseOccVLA: é€šè¿‡ç¨€ç–æŸ¥è¯¢æ¡¥æ¥Occupancyå’ŒVision-Language Modelsä»¥å®ç°ç»Ÿä¸€çš„4Dåœºæ™¯ç†è§£ä¸è§„åˆ’|Chenxu Dang, Jie Wang, Guang Li, Zhiwen Hou, Zihan You, Hangjun Ye, Jie Ma, Long Chen .etc.|<https://arxiv.org/pdf/2601.06474v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|R$^3$D: Regional-guided Residual Radar Diffusion|[ç¿»è¯‘å¤±è´¥] R$^3$D: Regional-guided Residual Radar Diffusion|Hao Li, Xinqi Liu, Yaoqing Jin|<https://arxiv.org/pdf/2601.06465v1>|æ— |
|ğŸ†• å‘å¸ƒ|Tone Matters: The Impact of Linguistic Tone on Hallucination in VLMs|Tone Matters: è¯­è¨€å­¦ Tone å¯¹ VLMs ä¸­ Hallucination çš„å½±å“|Weihao Hong, Zhiyuan Jiang, Bingyu Shen, Xinlei Guan, Yangyi Feng, Meng Xu, Boyang Li|<https://arxiv.org/pdf/2601.06460v1>|[ä»£ç ](https://github.com/bli1/tone-matters); åˆ†æå¤±è´¥|


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|VibES: Induced Vibration for Persistent Event-Based Sensing|VibES: ç”¨äºæŒç»­ Event-Based Sensing çš„è¯±å¯¼æŒ¯åŠ¨|Vincenzo Polizzi, Stephen Yang, Quentin Clark, Jonathan Kelly, Igor Gilitschenski, David B. Lindell|<https://arxiv.org/pdf/2508.19094v2>|æ— |
|ğŸ†• å‘å¸ƒ|APEX: Learning Adaptive Priorities for Multi-Objective Alignment in Vision-Language Generation|[ç¿»è¯‘å¤±è´¥] APEX: Learning Adaptive Priorities for Multi-Objective Alignment in Vision-Language Generation|Dongliang Chen, Xinlin Zhuang, Junjie Xu, Luojian Xie, Zehui Wang, Jiaxi Zhuang, Haolin Yang, Liang Dou .etc.|<https://arxiv.org/pdf/2601.06574v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|3D CoCa v2: Contrastive Learners with Test-Time Search for Generalizable Spatial Intelligence|3D CoCa v2ï¼šç”¨äºå¯æ³›åŒ–ç©ºé—´æ™ºèƒ½çš„æµ‹è¯•æ—¶æœç´¢å¯¹æ¯”å­¦ä¹ å™¨|Hao Tang, Ting Huang, Zeyu Zhang|<https://arxiv.org/pdf/2601.06496v1>|[ä»£ç ](https://github.com/AIGeeksGroup/3DCoCav2.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|From Easy to Hard++: Promoting Differentially Private Image Synthesis Through Spatial-Frequency Curriculum|From Easy to Hard++: é€šè¿‡ç©ºé—´-é¢‘ç‡è¯¾ç¨‹ä¿ƒè¿›å·®åˆ†éšç§å›¾åƒåˆæˆ|Chen Gong, Kecen Li, Zinan Lin, Tianhao Wang|<https://arxiv.org/pdf/2601.06368v1>|æ— |


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Sissi: Zero-shot Style-guided Image Synthesis via Semantic-style Integration|Sissi: é€šè¿‡è¯­ä¹‰-é£æ ¼é›†æˆå®ç°çš„Zero-shoté£æ ¼å¼•å¯¼å›¾åƒåˆæˆ|Yingying Deng, Xiangyu He, Fan Tang, Weiming Dong, Xucheng Yin|<https://arxiv.org/pdf/2601.06605v1>|æ— |
|ğŸ“ æ›´æ–°|A Survey of Multimodal Hallucination Evaluation and Detection|å¤šæ¨¡æ€å¹»è§‰è¯„ä¼°ä¸æ£€æµ‹ç»¼è¿°|Zhiyuan Chen, Yuecong Min, Jie Zhang, Bei Yan, Jiahao Wang, Xiaozhen Wang, Shiguang Shan|<https://arxiv.org/pdf/2507.19024v2>|åˆ†æå¤±è´¥|


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Toward Generalizable Deblurring: Leveraging Massive Blur Priors with Linear Attention for Real-World Scenarios|è¿ˆå‘å¯æ³›åŒ–çš„å»æ¨¡ç³Šï¼šåˆ©ç”¨çº¿æ€§æ³¨æ„åŠ›æœºåˆ¶ç»“åˆæµ·é‡æ¨¡ç³Šå…ˆéªŒåº”å¯¹çœŸå®åœºæ™¯|Yuanting Gao, Shuo Cao, Xiaohui Li, Yuandong Pu, Yihao Liu, Kai Zhang|<https://arxiv.org/pdf/2601.06525v1>|[ä»£ç ](https://vegdog007.github.io/GLOWDeblur_Website); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|GlobalPaint: Spatiotemporal Coherent Video Outpainting with Global Feature Guidance|GlobalPaint: åŸºäºGlobal Feature Guidanceçš„æ—¶ç©ºè¿è´¯è§†é¢‘Outpainting|Yueming Pan, Ruoyu Feng, Jianmin Bao, Chong Luo, Nanning Zheng|<https://arxiv.org/pdf/2601.06413v1>|[ä»£ç ](https://yuemingpan.github.io/GlobalPaint); åˆ†æå¤±è´¥|


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### è§†è§‰å®šä½ä¸æ˜ å°„ (Visual Localization & Mapping)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Mesquite MoCap: Democratizing Real-Time Motion Capture with Affordable, Bodyworn IoT Sensors and WebXR SLAM|Mesquite MoCapï¼šåˆ©ç”¨ç»æµå®æƒ çš„å¯ç©¿æˆ´ IoT ä¼ æ„Ÿå™¨å’Œ WebXR SLAM å®ç°å®æ—¶åŠ¨ä½œæ•æ‰çš„æ°‘ä¸»åŒ–|Poojan Vanani, Darsh Patel, Danyal Khorami, Siva Munaganuru, Pavan Reddy, Varun Reddy, Bhargav Raghunath, Ishrat Lallmamode .etc.|<https://arxiv.org/pdf/2512.22690v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|VPGS-SLAM: Voxel-based Progressive 3D Gaussian SLAM in Large-Scale Scenes|VPGS-SLAMï¼šå¤§è§„æ¨¡åœºæ™¯ä¸­åŸºäºä½“ç´ çš„æ¸è¿›å¼3D Gaussian SLAM|Tianchen Deng, Wenhua Wu, Junjie He, Yue Pan, Shenghai Yuan, Danwei Wang, Hesheng Wang|<https://arxiv.org/pdf/2505.18992v2>|[ä»£ç ](https://github.com/dtc111111/vpgs-slam.); åˆ†æå¤±è´¥|


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Multi-view Surface Reconstruction Using Normal and Reflectance Cues|åˆ©ç”¨æ³•å‘é‡å’Œåå°„ç‡çº¿ç´¢çš„å¤šè§†è§’è¡¨é¢é‡å»º|Robin Bruneau, Baptiste Brument, Yvain QuÃ©au, Jean MÃ©lou, FranÃ§ois Bernard Lauze, Jean-Denis Durou, Lilian Calvet|<https://arxiv.org/pdf/2506.04115v3>|[ä»£ç ](https://github.com/RobinBruneau/RNb-NeuS2.)|


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|What Is The Best 3D Scene Representation for Robotics? From Geometric to Foundation Models|ä»€ä¹ˆæ˜¯æœºå™¨äººé¢†åŸŸæœ€ä½³çš„ 3D åœºæ™¯è¡¨ç¤ºï¼Ÿä»å‡ ä½•æ¨¡å‹åˆ° Foundation Models|Tianchen Deng, Yue Pan, Shenghai Yuan, Dong Li, Chen Wang, Mingrui Li, Long Chen, Lihua Xie .etc.|<https://arxiv.org/pdf/2512.03422v2>|åˆ†æå¤±è´¥|


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Combining Facial Videos and Biosignals for Stress Estimation During Driving|ç»“åˆé¢éƒ¨è§†é¢‘å’Œç”Ÿç‰©ä¿¡å·è¿›è¡Œé©¾é©¶å‹åŠ›ä¼°è®¡|Paraskevi Valergaki, Vassilis C. Nicodemou, Iason Oikonomidis, Antonis Argyros, Anastasios Roussos|<https://arxiv.org/pdf/2601.04376v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|DeepFake Detection in Dyadic Video Calls using Point of Gaze Tracking|Dyadic Video Calls ä¸­åŸºäº Point of Gaze Tracking çš„ DeepFake Detection|Odin Kohler, Rahul Vijaykumar, Masudul H. Imtiaz|<https://arxiv.org/pdf/2509.25503v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|ArrowGEV: Grounding Events in Video via Learning the Arrow of Time|ArrowGEV: é€šè¿‡å­¦ä¹ æ—¶é—´ä¹‹ç®­åœ¨è§†é¢‘ä¸­å®šä½äº‹ä»¶|Fangxu Yu, Ziyao Lu, Liqiang Niu, Fandong Meng, Jie Zhou|<https://arxiv.org/pdf/2601.06559v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|MomentSeeker: A Task-Oriented Benchmark For Long-Video Moment Retrieval|MomentSeeker: é¢å‘é•¿è§†é¢‘æ—¶åˆ»æ£€ç´¢çš„Task-OrientedåŸºå‡†|Huaying Yuan, Jian Ni, Zheng Liu, Yueze Wang, Junjie Zhou, Zhengyang Liang, Bo Zhao, Zhao Cao .etc.|<https://arxiv.org/pdf/2502.12558v5>|[ä»£ç ](https://yhy-2000.github.io/MomentSeeker)|


### è§†é¢‘ç›®æ ‡è·Ÿè¸ª (Video Object Tracking)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|eSkiTB: A Synthetic Event-based Dataset for Tracking Skiers|eSkiTB: ä¸€ä¸ªç”¨äºè¿½è¸ªæ»‘é›ªè€…çš„åŸºäºäº‹ä»¶çš„åˆæˆæ•°æ®é›†|Krishna Vinod, Joseph Raj Vishal, Kaustav Chanda, Prithvi Jai Ramesh, Yezhou Yang, Bharatesh Chakravarthi|<https://arxiv.org/pdf/2601.06647v1>|[ä»£ç ](https://github.com/eventbasedvision/eSkiTB.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Object-WIPER : Training-Free Object and Associated Effect Removal in Videos|Object-WIPERï¼šæ— éœ€è®­ç»ƒçš„è§†é¢‘ä¸­ç‰©ä½“åŠå…¶å…³è”æ•ˆæœç§»é™¤|Saksham Singh Kushwaha, Sayan Nag, Yapeng Tian, Kuldeep Kulkarni|<https://arxiv.org/pdf/2601.06391v1>|æ— |


### åŠ¨ä½œè¯†åˆ«ä¸ç†è§£ (Action Recognition & Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Context Matters: Peer-Aware Student Behavioral Engagement Measurement via VLM Action Parsing and LLM Sequence Classification|Context Matters: é€šè¿‡ VLM åŠ¨ä½œè§£æå’Œ LLM åºåˆ—åˆ†ç±»è¿›è¡Œæ„ŸçŸ¥åŒä¼´çš„å­¦ç”Ÿè¡Œä¸ºå‚ä¸åº¦æµ‹é‡|Ahmed Abdelkawy, Ahmed Elsayed, Asem Ali, Aly Farag, Thomas Tretter, Michael McIntyre|<https://arxiv.org/pdf/2601.06394v1>|åˆ†æå¤±è´¥|


## è‡ªç›‘ç£ä¸è¡¨å¾å­¦ä¹  (Self-supervised & Representation Learning)


### å¯¹æ¯”å­¦ä¹ æ–¹æ³• (Contrastive Learning Methods)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|TRASE: Tracking-free 4D Segmentation and Editing|[ç¿»è¯‘å¤±è´¥] TRASE: Tracking-free 4D Segmentation and Editing|Yun-Jin Li, Mariia Gladkova, Yan Xia, Daniel Cremers|<https://arxiv.org/pdf/2411.19290v2>|[ä»£ç ](https://yunjinli.github.io/project-sadg); åˆ†æå¤±è´¥|


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Expert Consensus-based Video-Based Assessment Tool for Workflow Analysis in Minimally Invasive Colorectal Surgery: Development and Validation of ColoWorkflow|åŸºäºä¸“å®¶å…±è¯†çš„å¾®åˆ›ç»“ç›´è‚ æ‰‹æœ¯å·¥ä½œæµåˆ†æè§†é¢‘è¯„ä¼°å·¥å…·ï¼šColoWorkflowçš„å¼€å‘ä¸éªŒè¯|Pooja P Jain, Pietro Mascagni, Giuseppe Massimiani, Nabani Banik, Marta Goglia, Lorenzo Arboit, Britty Baby, Andrea Balla .etc.|<https://arxiv.org/pdf/2511.10766v2>|åˆ†æå¤±è´¥|


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Hard Thresholding Pursuit Algorithms for Least Absolute Deviations Problem|[ç¿»è¯‘å¤±è´¥] Hard Thresholding Pursuit Algorithms for Least Absolute Deviations Problem|Jiao Xu, Peng Li, Bing Zheng|<https://arxiv.org/pdf/2601.06558v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Revisiting Residual Connections: Orthogonal Updates for Stable and Efficient Deep Networks|é‡æ–°å®¡è§†æ®‹å·®è¿æ¥ï¼šç”¨äºç¨³å®šä¸”é«˜æ•ˆæ·±åº¦ç½‘ç»œçš„ Orthogonal Updates|Giyeong Oh, Woohyun Cho, Siyeol Kim, Suhwan Choi, Youngjae Yu|<https://arxiv.org/pdf/2505.11881v5>|æ— |
|ğŸ“ æ›´æ–°|Integrated Multivariate Segmentation Tree for Heterogeneous Credit Data Analysis in Small- and Medium-Sized Enterprises|é¢å‘ä¸­å°ä¼ä¸šå¼‚æ„ä¿¡ç”¨æ•°æ®åˆ†æçš„é›†æˆå¤šå˜é‡åˆ†å‰²æ ‘|Lu Han, Xiuying Wang|<https://arxiv.org/pdf/2509.00550v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|LOGLO-FNO: Efficient Learning of Local and Global Features in Fourier Neural Operators|LOGLO-FNO: Fourier Neural Operatorsä¸­å±€éƒ¨å’Œå…¨å±€ç‰¹å¾çš„é«˜æ•ˆå­¦ä¹ |Marimuthu Kalimuthu, David HolzmÃ¼ller, Mathias Niepert|<https://arxiv.org/pdf/2504.04260v2>|åˆ†æå¤±è´¥|


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|CulinaryCut-VLAP: A Vision-Language-Action-Physics Framework for Food Cutting via a Force-Aware Material Point Method|[ç¿»è¯‘å¤±è´¥] CulinaryCut-VLAP: A Vision-Language-Action-Physics Framework for Food Cutting via a Force-Aware Material Point Method|Hyunseo Koh, Chang-Yong Song, Youngjae Choi, Misa Viveiros, David Hyde, Heewon Kim|<https://arxiv.org/pdf/2601.06451v1>|åˆ†æå¤±è´¥|


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### å¯¹æŠ—é²æ£’æ€§ (Adversarial Robustness)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|On the Adversarial Robustness of 3D Large Vision-Language Models|å…³äº3D Large Vision-Language Modelsçš„å¯¹æŠ—é²æ£’æ€§|Chao Liu, Ngai-Man Cheung|<https://arxiv.org/pdf/2601.06464v1>|æ— |


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Beyond Perfect Scores: Proof-by-Contradiction for Trustworthy Machine Learning|è¶…è¶Šå®Œç¾åˆ†æ•°ï¼šå¯ä¿¡æœºå™¨å­¦ä¹ çš„åè¯æ³•|Dushan N. Wadduwage, Dineth Jayakody, Leonidas Zimianitis|<https://arxiv.org/pdf/2601.06704v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|MAC: A Benchmark for Multiple Attributes Compositional Zero-Shot Learning|[ç¿»è¯‘å¤±è´¥] MAC: A Benchmark for Multiple Attributes Compositional Zero-Shot Learning|Shuo Xu, Sai Wang, Xinyue Hu, Yutian Lin, Sibei Yang, Yu Wu|<https://arxiv.org/pdf/2406.12757v4>|æ— |
|ğŸ†• å‘å¸ƒ|Learning Domain Agnostic Latent Embeddings of 3D Faces for Zero-shot Animal Expression Transfer|[ç¿»è¯‘å¤±è´¥] Learning Domain Agnostic Latent Embeddings of 3D Faces for Zero-shot Animal Expression Transfer|Yue Wang, Lawrence Amadi, Xiang Gao, Yazheng Chen, Yuanpeng Liu, Ning Lu, Xianfeng Gu|<https://arxiv.org/pdf/2601.06484v1>|åˆ†æå¤±è´¥|


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|BabyVision: Visual Reasoning Beyond Language|BabyVision: è¶…è¶Šè¯­è¨€çš„è§†è§‰æ¨ç†|Liang Chen, Weichu Xie, Yiyan Liang, Hongfeng He, Hans Zhao, Zhibo Yang, Zhiqi Huang, Haoning Wu .etc.|<https://arxiv.org/pdf/2601.06521v1>|[ä»£ç ](https://github.com/UniPat-AI/BabyVision); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|VVTRec: Radio Interferometric Reconstruction through Visual and Textual Modality Enrichment|VVTRec: é€šè¿‡è§†è§‰å’Œæ–‡æœ¬æ¨¡æ€å¢å¼ºçš„å°„ç”µå¹²æ¶‰é‡å»º|Kai Cheng, Ruoqi Wang, Qiong Luo|<https://arxiv.org/pdf/2601.06475v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|VIPER Strike: Defeating Visual Reasoning CAPTCHAs via Structured Vision-Language Inference|[ç¿»è¯‘å¤±è´¥] VIPER Strike: Defeating Visual Reasoning CAPTCHAs via Structured Vision-Language Inference|Minfeng Qi, Dongyang He, Qin Wang, Lefeng Zhang|<https://arxiv.org/pdf/2601.06461v1>|åˆ†æå¤±è´¥|


### è§†è§‰å†…å®¹æè¿° (Visual Content Description)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|PixRec: Leveraging Visual Context for Next-Item Prediction in Sequential Recommendation|PixRec: åˆ©ç”¨è§†è§‰ä¸Šä¸‹æ–‡è¿›è¡Œåºåˆ—æ¨èä¸­çš„ä¸‹ä¸€é¡¹é¢„æµ‹|Sayak Chakrabarty, Souradip Pal|<https://arxiv.org/pdf/2601.06458v1>|åˆ†æå¤±è´¥|


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Encoding Structural Constraints into Segment Anything Models via Probabilistic Graphical Models|[ç¿»è¯‘å¤±è´¥] Encoding Structural Constraints into Segment Anything Models via Probabilistic Graphical Models|Yu Li, Da Chang, Xi Xiao|<https://arxiv.org/pdf/2509.21750v2>|æ— |


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Neighborhood Feature Pooling for Remote Sensing Image Classification|[ç¿»è¯‘å¤±è´¥] Neighborhood Feature Pooling for Remote Sensing Image Classification|Fahimeh Orvati Nia, Amirmohammad Mohammadi, Salim Al Kharsa, Pragati Naikare, Zigfried Hampel-Arias, Joshua Peeples|<https://arxiv.org/pdf/2510.25077v3>|åˆ†æå¤±è´¥|


### ç”Ÿç‰©ç‰¹å¾è¯†åˆ« (Biometric Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|WHU-PCPR: A cross-platform heterogeneous point cloud dataset for place recognition in complex urban scenes|WHU-PCPR: ä¸€ä¸ªç”¨äºå¤æ‚åŸå¸‚åœºæ™¯ä¸­åœ°ç‚¹è¯†åˆ«çš„è·¨å¹³å°å¼‚æ„ç‚¹äº‘æ•°æ®é›†|Xianghong Zou, Jianping Li, Yandi Yang, Weitong Wu, Yuan Wang, Qiegen Liu, Zhen Dong|<https://arxiv.org/pdf/2601.06442v1>|[ä»£ç ](https://github.com/zouxianghong/WHU-PCPR.)|


## æ–°å…´ç†è®ºä¸è·¨å­¦ç§‘æ–¹å‘ (Emerging Theory & Interdisciplinary Directions)


### é‡å­è§†è§‰ç®—æ³• (Quantum Visual Algorithms)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|HiRes-LLaVA: Restoring Fragmentation Input in High-Resolution Large Vision-Language Models|HiRes-LLaVA: åœ¨é«˜åˆ†è¾¨ç‡å¤§è§†è§‰è¯­è¨€æ¨¡å‹ä¸­æ¢å¤ç¢ç‰‡åŒ–è¾“å…¥|Runhui Huang, Xinpeng Ding, Chunwei Wang, Jianhua Han, Yulong Liu, Hengshuang Zhao, Hang Xu, Lu Hou .etc.|<https://arxiv.org/pdf/2407.08706v2>|åˆ†æå¤±è´¥|


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Precision Meets Art: Autonomous Multi-UAV System for Large Scale Mural Drawing|[ç¿»è¯‘å¤±è´¥] Precision Meets Art: Autonomous Multi-UAV System for Large Scale Mural Drawing|Andrei A. Korigodskii, Artem E. Vasiunik, Georgii A. Varin, Adilia M. Zukhurova, Matvei V. Urvantsev, Semen A. Osipenkov, Igor S. Efremov, Georgii E. Bondar|<https://arxiv.org/pdf/2601.06508v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|TLRN: Temporal Latent Residual Networks For Large Deformation Image Registration|TLRN: ç”¨äºå¤§å˜å½¢å›¾åƒé…å‡†çš„æ—¶é—´æ½œåœ¨æ®‹å·®ç½‘ç»œ|Nian Wu, Jiarui Xing, Miaomiao Zhang|<https://arxiv.org/pdf/2407.11219v3>|[ä»£ç ](https://github.com/nellie689/TLRN.); åˆ†æå¤±è´¥|

