## [UPDATED!] **2026-01-11** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Pain in 3D: Generating Controllable Synthetic Faces for Automated Pain Assessment|Pain in 3Dï¼šç”Ÿæˆç”¨äºè‡ªåŠ¨ç–¼ç—›è¯„ä¼°çš„å¯æ§åˆæˆäººè„¸|Xin Lei Lin, Soroush Mehraban, Abhishek Moturu, Babak Taati|<https://arxiv.org/pdf/2509.16727v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|CLIMP: Contrastive Language-Image Mamba Pretraining|CLIMP: å¯¹æ¯”è¯­è¨€-å›¾åƒ Mamba é¢„è®­ç»ƒ|Nimrod Shabtay, Itamar Zimerman, Eli Schwartz, Raja Giryes|<https://arxiv.org/pdf/2601.06891v1>|æ— |
|ğŸ“ æ›´æ–°|Does DINOv3 Set a New Medical Vision Standard?|DINOv3 æ˜¯å¦æ ‘ç«‹äº†æ–°çš„åŒ»å­¦è§†è§‰æ ‡å‡†ï¼Ÿ|Che Liu, Yinda Chen, Haoyuan Shi, Jinpeng Lu, Bailiang Jian, Jiazhen Pan, Linghan Cai, Jiayi Wang .etc.|<https://arxiv.org/pdf/2509.06467v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|MVGGT: Multimodal Visual Geometry Grounded Transformer for Multiview 3D Referring Expression Segmentation|MVGGT: ç”¨äºå¤šè§†å›¾ 3D æŒ‡ä»£è¡¨è¾¾åˆ†å‰²çš„å¤šæ¨¡æ€è§†è§‰å‡ ä½• Transformer|Changli Wu, Haodong Wang, Jiayi Ji, Yutian Yao, Chunsai Du, Jihua Kang, Yanwei Fu, Liujuan Cao|<https://arxiv.org/pdf/2601.06874v1>|åˆ†æå¤±è´¥|


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SketchJudge: A Diagnostic Benchmark for Grading Hand-drawn Diagrams with Multimodal Large Language Models|SketchJudgeï¼šä¸€ä¸ªåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å¯¹æ‰‹ç»˜å›¾è¡¨è¿›è¡Œè¯„åˆ†çš„è¯Šæ–­åŸºå‡†|Yuhang Su, Mei Wang, Yaoyao Zhong, Guozhang Li, Shixing Li, Yihan Feng, Hua Huang|<https://arxiv.org/pdf/2601.06944v1>|[ä»£ç ](https://github.com/yuhangsu82/SketchJudge.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Speak While Watching: Unleashing TRUE Real-Time Video Understanding Capability of Multimodal Large Language Models|è¾¹çœ‹è¾¹è¯´ï¼šé‡Šæ”¾å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„TRUEå®æ—¶è§†é¢‘ç†è§£èƒ½åŠ›|Junyan Lin, Junlong Tong, Hao Wu, Jialiang Zhang, Jinming Liu, Xin Jin, Xiaoyu Shen|<https://arxiv.org/pdf/2601.06843v1>|[ä»£ç ](https://github.com/EIT-NLP/Speak-While-Watching.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Benchmarking Egocentric Clinical Intent Understanding Capability for Medical Multimodal Large Language Models|è¯„ä¼° Medical Multimodal Large Language Models çš„ Egocentric Clinical Intent Understanding èƒ½åŠ›åŸºå‡†|Shaonan Liu, Guo Yu, Xiaoling Luo, Shiyi Zheng, Wenting Chen, Jie Liu, Linlin Shen|<https://arxiv.org/pdf/2601.06750v1>|åˆ†æå¤±è´¥|


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Billboard in Focus: Estimating Driver Gaze Duration from a Single Image|Billboard in Focus: ä»å•å¼ å›¾åƒä¼°è®¡é©¾é©¶å‘˜æ³¨è§†æ—¶é•¿|Carlos Pizarroso, Zuzana Berger HaladovÃ¡, Zuzana ÄŒernekovÃ¡, Viktor Kocur|<https://arxiv.org/pdf/2601.07073v1>|æ— |
|ğŸ“ æ›´æ–°|DATransNet: Dynamic Attention Transformer Network for Infrared Small Target Detection|DATransNet: ç”¨äºçº¢å¤–å°ç›®æ ‡æ£€æµ‹çš„åŠ¨æ€æ³¨æ„åŠ›Transformerç½‘ç»œ|Chen Hu, Yian Huang, Kexuan Li, Luping Zhang, Chang Long, Yiming Zhu, Tian Pu, Zhenming Peng|<https://arxiv.org/pdf/2409.19599v5>|[ä»£ç ](https://github.com/greekinRoma/DATransNet.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|MixRI: Mixing Features of Reference Images for Novel Object Pose Estimation|MixRI: æ··åˆå‚è€ƒå›¾åƒçš„ç‰¹å¾ç”¨äºæ–°ç‰©ä½“å§¿æ€ä¼°è®¡|Xinhang Liu, Jiawei Shi, Zheng Dang, Yuchao Dai|<https://arxiv.org/pdf/2601.06883v1>|åˆ†æå¤±è´¥|


### ç›®æ ‡æ£€æµ‹ä¸å®šä½ (Object Detection & Localization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|SeePerSea: Multi-modal Perception Dataset of In-water Objects for Autonomous Surface Vehicles|SeePerSea: ç”¨äºè‡ªä¸»æ°´é¢èˆ°è‰‡çš„æ°´ä¸‹ç‰©ä½“å¤šæ¨¡æ€æ„ŸçŸ¥æ•°æ®é›†|Mingi Jeong, Arihant Chadda, Ziang Ren, Luyang Zhao, Haowen Liu, Monika Roznere, Aiwei Zhang, Yitao Jiang .etc.|<https://arxiv.org/pdf/2404.18411v3>|[ä»£ç ](https://seepersea.github.io/.)|
|ğŸ†• å‘å¸ƒ|MedGround: Bridging the Evidence Gap in Medical Vision-Language Models with Verified Grounding Data|MedGround: åˆ©ç”¨Verified Grounding Dataå¼¥åˆMedical Vision-Language Modelsä¸­çš„è¯æ®å·®è·|Mengmeng Zhang, Xiaoping Wu, Hao Luo, Fan Wang, Yisheng Lv|<https://arxiv.org/pdf/2601.06847v1>|åˆ†æå¤±è´¥|


### è¯­ä¹‰/å®ä¾‹åˆ†å‰² (Semantic/Instance Segmentation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Unsupervised Domain Adaptation with SAM-RefiSeR for Enhanced Brain Tumor Segmentation|åŸºäºSAM-RefiSeRçš„æ— ç›‘ç£åŸŸè‡ªé€‚åº”ä»¥å¢å¼ºè„‘è‚¿ç˜¤åˆ†å‰²|Dillan Imans, Phuoc-Nguyen Bui, Duc-Tai Le, Hyunseung Choo|<https://arxiv.org/pdf/2601.06882v1>|åˆ†æå¤±è´¥|


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Flow Matching and Diffusion Models via PointNet for Generating Fluid Fields on Irregular Geometries|åŸºäº PointNet çš„ Flow Matching å’Œ Diffusion æ¨¡å‹ç”¨äºåœ¨ä¸è§„åˆ™å‡ ä½•ä¸Šç”Ÿæˆæµåœº|Ali Kashefi|<https://arxiv.org/pdf/2601.03030v2>|æ— |
|ğŸ†• å‘å¸ƒ|3D Wavelet-Based Structural Priors for Controlled Diffusion in Whole-Body Low-Dose PET Denoising|åŸºäº3Då°æ³¢çš„ç»“æ„å…ˆéªŒç”¨äºå…¨èº«ä½å‰‚é‡PETå»å™ªä¸­çš„å¯æ§æ‰©æ•£|Peiyuan Jing, Yue Tang, Chun-Wun Cheng, Zhenxuan Zhang, Liutao Yang, Thiago V. Lima, Klaus Strobel, Antoine Leimgruber .etc.|<https://arxiv.org/pdf/2601.07093v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|BLANKET: Anonymizing Faces in Infant Video Recordings|BLANKETï¼šåœ¨å©´å„¿è§†é¢‘è®°å½•ä¸­åŒ¿ååŒ–äººè„¸|Ditmar Hadera, Jan Cech, Miroslav Purkrabek, Matej Hoffmann|<https://arxiv.org/pdf/2512.15542v2>|[ä»£ç ](https://github.com/ctu-vras/blanket-infant-face-anonym.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Measuring Social Bias in Vision-Language Models with Face-Only Counterfactuals from Real Photos|ä½¿ç”¨æ¥è‡ªçœŸå®ç…§ç‰‡çš„ä»…äººè„¸åäº‹å®æµ‹é‡ Vision-Language Models ä¸­çš„ç¤¾ä¼šåè§|Haodong Chen, Qiang Huang, Jiaqi Zhao, Qiuping Jiang, Xiaojun Chang, Jun Yu|<https://arxiv.org/pdf/2601.06931v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|RenderFlow: Single-Step Neural Rendering via Flow Matching|RenderFlowï¼šé€šè¿‡ Flow Matching å®ç°å•æ­¥ç¥ç»æ¸²æŸ“|Shenghao Zhang, Runtao Liu, Christopher Schroers, Yang Zhang|<https://arxiv.org/pdf/2601.06928v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|OSCAR: Optical-aware Semantic Control for Aleatoric Refinement in Sar-to-Optical Translation|OSCAR: ç”¨äºSar-to-Opticalç¿»è¯‘ä¸­å¶ç„¶æ€§ç»†åŒ–çš„å…‰æ„ŸçŸ¥è¯­ä¹‰æ§åˆ¶|Hyunseo Lee, Sang Min Kim, Ho Kyung Shin, Taeheon Kim, Woo-Jeoung Nam|<https://arxiv.org/pdf/2601.06835v1>|åˆ†æå¤±è´¥|


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|CrackSegFlow: Controllable Flow Matching Synthesis for Generalizable Crack Segmentation with a 50K Image-Mask Benchmark|CrackSegFlow: ç”¨äºå¯æ³›åŒ–è£‚ç¼åˆ†å‰²çš„å¯æ§æµåŒ¹é…åˆæˆï¼Œé™„å¸¦ä¸€ä¸ªåŒ…å«50Kå¼ å›¾åƒ-æ©ç çš„åŸºå‡†æ•°æ®é›†|Babak Asadi, Peiyang Wu, Mani Golparvar-Fard, Ramez Hajj|<https://arxiv.org/pdf/2601.03637v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Unified Personalized Understanding, Generating and Editing|ç»Ÿä¸€çš„ä¸ªæ€§åŒ–ç†è§£ã€ç”Ÿæˆä¸ç¼–è¾‘|Yu Zhong, Tianwei Lin, Ruike Zhu, Yuqian Yuan, Haoyu Zheng, Liang Liang, Wenqiao Zhang, Feifei Shao .etc.|<https://arxiv.org/pdf/2601.06965v1>|æ— |
|ğŸ“ æ›´æ–°|Terrain Diffusion: A Diffusion-Based Successor to Perlin Noise in Infinite, Real-Time Terrain Generation|Terrain Diffusionï¼šä¸€ç§åŸºäº Diffusion çš„ Perlin Noise ç»§ä»»è€…ï¼Œç”¨äºæ— é™ã€å®æ—¶çš„ Terrain Generation|Alexander Goslin|<https://arxiv.org/pdf/2512.08309v3>|æ— |
|ğŸ“ æ›´æ–°|RealCamo: Boosting Real Camouflage Synthesis with Layout Controls and Textual-Visual Guidance|RealCamo: åˆ©ç”¨å¸ƒå±€æ§åˆ¶å’Œæ–‡æœ¬-è§†è§‰æŒ‡å¯¼æå‡çœŸå®ä¼ªè£…åˆæˆ|Chunyuan Chen, Yunuo Cai, Shujuan Li, Weiyun Liang, Bin Wang, Jing Xu|<https://arxiv.org/pdf/2512.22974v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|UDPNet: Unleashing Depth-based Priors for Robust Image Dehazing|[ç¿»è¯‘å¤±è´¥] UDPNet: Unleashing Depth-based Priors for Robust Image Dehazing|Zengyuan Zuo, Junjun Jiang, Gang Wu, Xianming Liu|<https://arxiv.org/pdf/2601.06909v1>|[ä»£ç ](https://github.com/Harbinzzy/UDPNet.)|
|ğŸ“ æ›´æ–°|Omni2Sound: Towards Unified Video-Text-to-Audio Generation|[ç¿»è¯‘å¤±è´¥] Omni2Sound: Towards Unified Video-Text-to-Audio Generation|Yusheng Dai, Zehua Chen, Yuxuan Jiang, Baolong Gao, Qiuhong Ke, Jun Zhu, Jianfei Cai|<https://arxiv.org/pdf/2601.02731v2>|[ä»£ç ](https://swapforward.github.io/Omni2Sound.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|FashionMAC: Deformation-Free Fashion Image Generation with Fine-Grained Model Appearance Customization|FashionMAC: æ— å½¢å˜çš„ç»†ç²’åº¦æ¨¡å‹å¤–è§‚å®šåˆ¶æ—¶å°šå›¾åƒç”Ÿæˆ|Rong Zhang, Jinxiao Li, Jingnan Wang, Zhiwen Zuo, Jianfeng Dong, Wei Li, Chi Wang, Weiwei Xu .etc.|<https://arxiv.org/pdf/2511.14031v2>|åˆ†æå¤±è´¥|


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|AutoTour: Automatic Photo Tour Guide with Smartphones and LLMs|AutoTourï¼šåŸºäºæ™ºèƒ½æ‰‹æœºå’ŒLLMçš„è‡ªåŠ¨ç…§ç‰‡å¯¼æ¸¸|Huatao Xu, Zihe Liu, Zilin Zeng, Baichuan Li, Mo Li|<https://arxiv.org/pdf/2601.06781v1>|æ— |


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|C3Po: Cross-View Cross-Modality Correspondence by Pointmap Prediction|C3Po: é€šè¿‡Pointmap Predictionå®ç°Cross-View Cross-Modality Correspondence|Kuan Wei Huang, Brandon Li, Bharath Hariharan, Noah Snavely|<https://arxiv.org/pdf/2511.18559v2>|æ— |
|ğŸ†• å‘å¸ƒ|ObjSplat: Geometry-Aware Gaussian Surfels for Active Object Reconstruction|ObjSplat: ç”¨äºä¸»åŠ¨ç‰©ä½“é‡å»ºçš„å‡ ä½•æ„ŸçŸ¥ Gaussian Surfels|Yuetao Li, Zhizhou Jia, Yu Zhang, Qun Hao, Shaohui Zhang|<https://arxiv.org/pdf/2601.06997v1>|[ä»£ç ](https://li-yuetao.github.io/ObjSplat-page)|
|ğŸ“ æ›´æ–°|MG-SLAM: Structure Gaussian Splatting SLAM with Manhattan World Hypothesis|MG-SLAM: åŸºäº Manhattan World å‡è®¾çš„ç»“æ„ Gaussian Splatting SLAM|Shuhong Liu, Tianchen Deng, Heng Zhou, Liuzhuozheng Li, Hongyu Wang, Danwei Wang, Mingrui Li|<https://arxiv.org/pdf/2405.20031v4>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|SARA: Scene-Aware Reconstruction Accelerator|[ç¿»è¯‘å¤±è´¥] SARA: Scene-Aware Reconstruction Accelerator|Jee Won Lee, Hansol Lim, Minhyeok Im, Dohyeon Lee, Jongseong Brad Choi|<https://arxiv.org/pdf/2601.06831v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|CliffordNet: All You Need is Geometric Algebra|[ç¿»è¯‘å¤±è´¥] CliffordNet: All You Need is Geometric Algebra|Zhongping Ji|<https://arxiv.org/pdf/2601.06793v1>|[ä»£ç ](https://github.com/ParaMind2025/CAN.)|


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Explainable Deep Radiogenomic Molecular Imaging for MGMT Methylation Prediction in Glioblastoma|[ç¿»è¯‘å¤±è´¥] Explainable Deep Radiogenomic Molecular Imaging for MGMT Methylation Prediction in Glioblastoma|Hasan M Jamil|<https://arxiv.org/pdf/2601.07035v1>|æ— |
|ğŸ†• å‘å¸ƒ|Enhancing Low-resolution Image Representation Through Normalizing Flows|é€šè¿‡ Normalizing Flows å¢å¼ºä½åˆ†è¾¨ç‡å›¾åƒè¡¨ç¤º|Chenglong Bao, Tongyao Pang, Zuowei Shen, Dihan Zheng, Yihang Zou|<https://arxiv.org/pdf/2601.06834v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|USFetal: Tools for Fetal Brain Ultrasound Compounding|USFetal: ç”¨äºèƒå„¿å¤§è„‘è¶…å£°åˆæˆçš„å·¥å…·|Mohammad Khateri, Morteza Ghahremani, Sergio Valencia, Camilo Jaimes, Alejandra Sierra, Jussi Tohka, P. Ellen Grant, Davood Karimi|<https://arxiv.org/pdf/2601.06726v1>|åˆ†æå¤±è´¥|


### è§†è§‰å®šä½ä¸æ˜ å°„ (Visual Localization & Mapping)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Radiant Foam Rendering on a Graph Processor|Graph Processor ä¸Šçš„ Radiant Foam æ¸²æŸ“|Zulkhuu Tuya, Ignacio Alzugaray, Nicholas Fry, Andrew J. Davison|<https://arxiv.org/pdf/2601.04382v2>|æ— |
|ğŸ†• å‘å¸ƒ|SpatialNav: Leveraging Spatial Scene Graphs for Zero-Shot Vision-and-Language Navigation|SpatialNav: åˆ©ç”¨ç©ºé—´åœºæ™¯å›¾è¿›è¡Œé›¶æ ·æœ¬è§†è§‰ä¸è¯­è¨€å¯¼èˆª|Jiwen Zhang, Zejun Li, Siyuan Wang, Xiangyu Shi, Zhongyu Wei, Qi Wu|<https://arxiv.org/pdf/2601.06806v1>|æ— |


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Polymorph: Energy-Efficient Multi-Label Classification for Video Streams on Embedded Devices|Polymorphï¼šåµŒå…¥å¼è®¾å¤‡ä¸Šè§†é¢‘æµçš„é«˜æ•ˆå¤šæ ‡ç­¾åˆ†ç±»|Saeid Ghafouri, Mohsen Fayyaz, Xiangchen Li, Deepu John, Bo Ji, Dimitrios Nikolopoulos, Hans Vandierendonck|<https://arxiv.org/pdf/2507.14959v3>|[ä»£ç ](https://github.com/inference-serving/polymorph)|
|ğŸ†• å‘å¸ƒ|qAttCNN - Self Attention Mechanism for Video QoE Prediction in Encrypted Traffic|qAttCNN - ç”¨äºåŠ å¯†æµé‡è§†é¢‘ QoE é¢„æµ‹çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶|Michael Sidorov, Ofer Hadar|<https://arxiv.org/pdf/2601.06862v1>|æ— |
|ğŸ“ æ›´æ–°|VC-Inspector: Advancing Reference-free Evaluation of Video Captions with Factual Analy|VC-Inspector: åˆ©ç”¨äº‹å®åˆ†ææ¨è¿›æ— å‚è€ƒè§†é¢‘å­—å¹•è¯„ä¼°|Shubhashis Roy Dipta, Tz-Ying Wu, Subarna Tripathi|<https://arxiv.org/pdf/2509.16538v2>|åˆ†æå¤±è´¥|


### è§†é¢‘ç›®æ ‡è·Ÿè¸ª (Video Object Tracking)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|FMVP: Masked Flow Matching for Adversarial Video Purification|FMVP: ç”¨äºå¯¹æŠ—æ€§è§†é¢‘å‡€åŒ–çš„æ©ç æµåŒ¹é…|Duoxun Tang, Xueyi Zhang, Chak Hin Wang, Xi Xiao, Dasen Dai, Xinhang Jiang, Wentao Shi, Rui Li .etc.|<https://arxiv.org/pdf/2601.02228v2>|åˆ†æå¤±è´¥|


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|When Humans Judge Irises: Pupil Size Normalization as an Aid and Synthetic Irises as a Challenge|å½“äººç±»è¯„åˆ¤è™¹è†œï¼šç³å­”å¤§å°å½’ä¸€åŒ–ä½œä¸ºè¾…åŠ©æ‰‹æ®µä¸åˆæˆè™¹è†œä½œä¸ºæŒ‘æˆ˜|Mahsa Mitcheff, Adam Czajka|<https://arxiv.org/pdf/2601.06725v1>|æ— |


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### åˆ†å¸ƒå¤–æ³›åŒ– (Out-of-distribution Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Out-of-Distribution Semantic Occupancy Prediction|Out-of-Distribution è¯­ä¹‰å æ®é¢„æµ‹|Yuheng Zhang, Mengfei Duan, Kunyu Peng, Yuhang Wang, Ruiping Liu, Fei Teng, Kai Luo, Zhiyong Li .etc.|<https://arxiv.org/pdf/2506.21185v2>|[ä»£ç ](https://github.com/7uHeng/OccOoD.); åˆ†æå¤±è´¥|


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Spatial Multi-Task Learning for Breast Cancer Molecular Subtype Prediction from Single-Phase DCE-MRI|ç”¨äºå•ç›¸ DCE-MRI ä¹³è…ºç™Œåˆ†å­äºšå‹é¢„æµ‹çš„ç©ºé—´å¤šä»»åŠ¡å­¦ä¹ |Sen Zeng, Hong Zhou, Zheng Zhu, Yang Liu|<https://arxiv.org/pdf/2601.07001v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|The Normalized Difference Layer: A Differentiable Spectral Index Formulation for Deep Learning|Normalized Difference Layerï¼šä¸€ç§ç”¨äº Deep Learning çš„å¯å¾®åˆ† Spectral Index å…¬å¼|Ali Lotfi, Adam Carter, Mohammad Meysami, Thuan Ha, Kwabena Nketia, Steve Shirtliffe|<https://arxiv.org/pdf/2601.06777v1>|åˆ†æå¤±è´¥|


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Can Textual Reasoning Improve the Performance of MLLMs on Fine-grained Visual Classification?|[ç¿»è¯‘å¤±è´¥] Can Textual Reasoning Improve the Performance of MLLMs on Fine-grained Visual Classification?|Jie Zhu, Yiyang Su, Xiaoming Liu|<https://arxiv.org/pdf/2601.06993v1>|[ä»£ç ](https://github.com/jiezhu23/ReFine-RFT); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Watching, Reasoning, and Searching: A Video Deep Research Benchmark on Open Web for Agentic Video Reasoning|è§‚çœ‹ã€æ¨ç†ä¸æœç´¢ï¼šé¢å‘ Agentic Video Reasoning çš„å¼€æ”¾ Web è§†é¢‘æ·±åº¦ç ”ç©¶åŸºå‡†|Chengwen Liu, Xiaomin Yu, Zhuoyue Chang, Zhe Huang, Shuo Zhang, Heng Lian, Kunyi Wang, Rui Xu .etc.|<https://arxiv.org/pdf/2601.06943v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Forest Before Trees: Latent Superposition for Efficient Visual Reasoning|[ç¿»è¯‘å¤±è´¥] Forest Before Trees: Latent Superposition for Efficient Visual Reasoning|Yubo Wang, Juntian Zhang, Yichen Wu, Yankai Lin, Nils Lukas, Yuhan Liu|<https://arxiv.org/pdf/2601.06803v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|ORB-SfMLearner: ORB-Guided Self-supervised Visual Odometry with Selective Online Adaptation|[ç¿»è¯‘å¤±è´¥] ORB-SfMLearner: ORB-Guided Self-supervised Visual Odometry with Selective Online Adaptation|Yanlin Jin, Rui-Yang Ju, Haojun Liu, Yuzhong Zhong|<https://arxiv.org/pdf/2409.11692v5>|[ä»£ç ](https://github.com/PeaceNeil/ORB-SfMLearner); åˆ†æå¤±è´¥|


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### å·¥ä¸šè§†è§‰æ£€æµ‹ (Industrial Visual Inspection)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Efficient Visual Question Answering Pipeline for Autonomous Driving via Scene Region Compression|é¢å‘è‡ªåŠ¨é©¾é©¶çš„é«˜æ•ˆè§†è§‰é—®ç­”ç®¡é“ï¼šé€šè¿‡åœºæ™¯åŒºåŸŸå‹ç¼©|Yuliang Cai, Dongqiangzi Ye, Zitian Chen, Chongruo Wu|<https://arxiv.org/pdf/2601.07092v1>|åˆ†æå¤±è´¥|


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Adversarial Attacks on Medical Hyperspectral Imaging Exploiting Spectral-Spatial Dependencies and Multiscale Features|åˆ©ç”¨å…‰è°±-ç©ºé—´ä¾èµ–å…³ç³»å’Œå¤šå°ºåº¦ç‰¹å¾çš„åŒ»å­¦é«˜å…‰è°±æˆåƒå¯¹æŠ—æ”»å‡»|Yunrui Gu, Zhenzhe Gao, Cong Kong, Zhaoxia Yin|<https://arxiv.org/pdf/2601.07056v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|REN: Anatomically-Informed Mixture-of-Experts for Interstitial Lung Disease Diagnosis|RENï¼šç”¨äºé—´è´¨æ€§è‚ºç—…è¯Šæ–­çš„è§£å‰–å­¦æ„ŸçŸ¥æ··åˆä¸“å®¶æ¨¡å‹|Alec K. Peltekian, Halil Ertugrul Aktas, Gorkem Durak, Kevin Grudzinski, Bradford C. Bemiss, Carrie Richardson, Jane E. Dematte, G. R. Scott Budinger .etc.|<https://arxiv.org/pdf/2510.04923v2>|[ä»£ç ](https://github.com/NUBagciLab/MoE-REN.)|


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|From Features to Reference Points: Lightweight and Adaptive Fusion for Cooperative Autonomous Driving|ä»ç‰¹å¾åˆ°å‚è€ƒç‚¹ï¼šç”¨äºååŒè‡ªåŠ¨é©¾é©¶çš„è½»é‡çº§è‡ªé€‚åº”èåˆ|Yongqi Zhu, Morui Zhu, Qi Chen, Deyuan Qu, Isabella Luo, Song Fu, Qing Yang|<https://arxiv.org/pdf/2511.18757v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|ATRNet-STAR: A Large Dataset and Benchmark Towards Remote Sensing Object Recognition in the Wild|ATRNet-STAR: é¢å‘é‡å¤–é¥æ„Ÿç›®æ ‡è¯†åˆ«çš„å¤§è§„æ¨¡æ•°æ®é›†ä¸åŸºå‡†|Yongxiang Liu, Weijie Li, Li Liu, Jie Zhou, Bowen Peng, Yafei Song, Xuying Xiong, Wei Yang .etc.|<https://arxiv.org/pdf/2501.13354v6>|åˆ†æå¤±è´¥|


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|PRISM: Color-Stratified Point Cloud Sampling|[ç¿»è¯‘å¤±è´¥] PRISM: Color-Stratified Point Cloud Sampling|Hansol Lim, Minhyeok Im, Jongseong Brad Choi|<https://arxiv.org/pdf/2601.06839v1>|åˆ†æå¤±è´¥|

