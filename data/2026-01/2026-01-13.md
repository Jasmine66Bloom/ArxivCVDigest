## [UPDATED!] **2026-01-13** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|MVGGT: Multimodal Visual Geometry Grounded Transformer for Multiview 3D Referring Expression Segmentation|MVGGT: ç”¨äºå¤šè§†è§’ 3D æŒ‡ä»£è¡¨è¾¾åˆ†å‰²çš„å¤šæ¨¡æ€è§†è§‰å‡ ä½• grounded Transformer|Changli Wu, Haodong Wang, Jiayi Ji, Yutian Yao, Chunsai Du, Jihua Kang, Yanwei Fu, Liujuan Cao|<https://arxiv.org/pdf/2601.06874v2>|æ— |
|ğŸ“ æ›´æ–°|Latent Reconstruction from Generated Data for Multimodal Misinformation Detection|åŸºäºç”Ÿæˆæ•°æ®çš„æ½œåœ¨é‡å»ºç”¨äºå¤šæ¨¡æ€è™šå‡ä¿¡æ¯æ£€æµ‹|Stefanos-Iordanis Papadopoulos, Christos Koutlis, Symeon Papadopoulos, Panagiotis C. Petrantonakis|<https://arxiv.org/pdf/2504.06010v3>|[ä»£ç ](https://github.com/stevejpapad/miscaptioned-image-reconstruction)|
|ğŸ†• å‘å¸ƒ|EfficientFSL: Enhancing Few-Shot Classification via Query-Only Tuning in Vision Transformers|EfficientFSL: é€šè¿‡ Vision Transformers ä¸­çš„ Query-Only Tuning å¢å¼ºå°‘æ ·æœ¬åˆ†ç±»|Wenwen Liao, Hang Ruan|<https://arxiv.org/pdf/2601.08499v1>|æ— |
|ğŸ†• å‘å¸ƒ|Closed-Loop LLM Discovery of Non-Standard Channel Priors in Vision Models|è§†è§‰æ¨¡å‹ä¸­éæ ‡å‡†é€šé“å…ˆéªŒçš„é—­ç¯ LLM å‘ç°|Tolgay Atinc Uzun, Dmitry Ignatov, Radu Timofte|<https://arxiv.org/pdf/2601.08517v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Temporal-Enhanced Interpretable Multi-Modal Prognosis and Risk Stratification Framework for Diabetic Retinopathy (TIMM-ProRS)|é¢å‘ç³–å°¿ç—…è§†ç½‘è†œç—…å˜çš„æ—¶é—´å¢å¼ºå¯è§£é‡Šå¤šæ¨¡æ€é¢„åä¸é£é™©åˆ†å±‚æ¡†æ¶ (TIMM-ProRS)|Susmita Kar, A S M Ahsanul Sarkar Akib, Abdul Hasib, Samin Yaser, Anas Bin Azim|<https://arxiv.org/pdf/2601.08240v1>|æ— |


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Simulating the Visual World with Artificial Intelligence: A Roadmap|ç”¨äººå·¥æ™ºèƒ½æ¨¡æ‹Ÿè§†è§‰ä¸–ç•Œï¼šè·¯çº¿å›¾|Jingtong Yue, Ziqi Huang, Zhaoxi Chen, Xintao Wang, Pengfei Wan, Ziwei Liu|<https://arxiv.org/pdf/2511.08585v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|VeriTaS: The First Dynamic Benchmark for Multimodal Automated Fact-Checking|VeriTaS: é¦–ä¸ªå¤šæ¨¡æ€è‡ªåŠ¨äº‹å®æ ¸æŸ¥åŠ¨æ€åŸºå‡†|Mark Rothermel, Marcus Kornmann, Marcus Rohrbach, Anna Rohrbach|<https://arxiv.org/pdf/2601.08611v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|UM-Text: A Unified Multimodal Model for Image Understanding|UM-Text: ç”¨äº Image Understanding çš„ Unified Multimodal Model|Lichen Ma, Xiaolong Fu, Gaojing Zhou, Zipeng Guo, Ting Zhu, Yichun Liu, Yu Shi, Jason Li .etc.|<https://arxiv.org/pdf/2601.08321v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|KidVis: Do Multimodal Large Language Models Possess the Visual Perceptual Capabilities of a 6-Year-Old?|KidVis: å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ˜¯å¦å…·å¤‡6å²å„¿ç«¥çš„è§†è§‰æ„ŸçŸ¥èƒ½åŠ›ï¼Ÿ|Xianfeng Wang, Kaiwei Zhang, Qi Jia, Zijian Chen, Guangtao Zhai, Xiongkuo Min|<https://arxiv.org/pdf/2601.08292v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems|ç”Ÿæˆå¼æ•°å­—å­ªç”Ÿï¼šç”¨äºå¯æ‰§è¡Œå·¥ä¸šç³»ç»Ÿçš„ Vision-Language ä»¿çœŸæ¨¡å‹|YuChe Hsu, AnJui Wang, TsaiChing Ni, YuanFu Yang|<https://arxiv.org/pdf/2512.20387v4>|[ä»£ç ](https://danielhsu2014.github.io/GDT-VLSM-project); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|GI-Bench: A Panoramic Benchmark Revealing the Knowledge-Experience Dissociation of Multimodal Large Language Models in Gastrointestinal Endoscopy Against Clinical Standards|GI-Benchï¼šä¸€ä¸ªæ­ç¤ºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨èƒƒè‚ å†…é•œä¸­ç›¸å¯¹äºä¸´åºŠæ ‡å‡†çš„çŸ¥è¯†ä¸ç»éªŒåˆ†ç¦»çš„å…¨æ™¯åŸºå‡†|Yan Zhu, Te Luo, Pei-Yao Fu, Zhen Zhang, Zi-Long Wang, Yi-Fan Qu, Zi-Han Geng, Jia-Qi Xu .etc.|<https://arxiv.org/pdf/2601.08183v1>|[ä»£ç ](https://roterdl.github.io/GIBench)|


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Franca: Nested Matryoshka Clustering for Scalable Visual Representation Learning|Franca: ç”¨äºå¯æ‰©å±•è§†è§‰è¡¨ç¤ºå­¦ä¹ çš„åµŒå¥— Matryoshka èšç±»|Shashanka Venkataramanan, Valentinos Pariza, Mohammadreza Salehi, Lukas Knobel, Spyros Gidaris, Elias Ramzi, Andrei Bursuc, Yuki M. Asano|<https://arxiv.org/pdf/2507.14137v3>|[ä»£ç ](https://github.com/valeoai/Franca.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|MoHoBench: Assessing Honesty of Multimodal Large Language Models via Unanswerable Visual Questions|MoHoBench: é€šè¿‡æ— æ³•å›ç­”çš„è§†è§‰é—®é¢˜è¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„è¯šå®æ€§|Yanxu Zhu, Shitong Duan, Xiangxu Zhang, Jitao Sang, Peng Zhang, Tun Lu, Xiao Zhou, Jing Yao .etc.|<https://arxiv.org/pdf/2507.21503v4>|[ä»£ç ](https://github.com/yanxuzhu/MoHoBench.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Edge-Optimized Multimodal Learning for UAV Video Understanding via BLIP-2|é¢å‘UAVè§†é¢‘ç†è§£çš„åŸºäºBLIP-2çš„è¾¹ç¼˜ä¼˜åŒ–å¤šæ¨¡æ€å­¦ä¹ |Yizhan Feng, Hichem Snoussi, Jing Teng, Jian Liu, Yuyang Wang, Abel Cherouat, Tian Wang|<https://arxiv.org/pdf/2601.08408v1>|æ— |
|ğŸ“ æ›´æ–°|Aligning by Misaligning: Boundary-aware Curriculum Learning for Multimodal Alignment|[ç¿»è¯‘å¤±è´¥] Aligning by Misaligning: Boundary-aware Curriculum Learning for Multimodal Alignment|Hua Ye, Hang Ding, Siyuan Chen, Yiyang Jiang, Changyuan Zhang, Xuan Zhang|<https://arxiv.org/pdf/2511.08399v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|UniF$^2$ace: A Unified Fine-grained Face Understanding and Generation Model|UniF$^2$ace: ä¸€ä¸ªç»Ÿä¸€çš„ç»†ç²’åº¦äººè„¸ç†è§£ä¸ç”Ÿæˆæ¨¡å‹|Junzhe Li, Sifan Zhou, Liya Guo, Xuerui Qiu, Linrui Xu, Delin Qu, Tingting Long, Chun Fan .etc.|<https://arxiv.org/pdf/2503.08120v5>|åˆ†æå¤±è´¥|


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|3AM: Segment Anything with Geometric Consistency in Videos|3AMï¼šåœ¨è§†é¢‘ä¸­åˆ©ç”¨å‡ ä½•ä¸€è‡´æ€§å®ç°Segment Anything|Yang-Che Sun, Cheng Sun, Chin-Yang Lin, Fu-En Yang, Min-Hung Chen, Yen-Yu Lin, Yu-Lun Liu|<https://arxiv.org/pdf/2601.08831v1>|[ä»£ç ](https://jayisaking.github.io/3AM-Page)|
|ğŸ†• å‘å¸ƒ|DentalX: Context-Aware Dental Disease Detection with Radiographs|DentalXï¼šåŸºäºRadiographsçš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç‰™ç§‘ç–¾ç—…æ£€æµ‹|Zhi Qin Tan, Xiatian Zhu, Owen Addison, Yunpeng Li|<https://arxiv.org/pdf/2601.08797v1>|[ä»£ç ](https://github.com/zhiqin1998/DentYOLOX.)|
|ğŸ†• å‘å¸ƒ|A Single-Parameter Factor-Graph Image Prior|[ç¿»è¯‘å¤±è´¥] A Single-Parameter Factor-Graph Image Prior|Tianyang Wang, Ender Konukoglu, Hans-Andrea Loeliger|<https://arxiv.org/pdf/2601.08749v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|AlÃ©m do Desempenho: Um Estudo da Confiabilidade de Detectores de Deepfakes|è¶…è¶Šæ€§èƒ½ï¼šDeepfake æ£€æµ‹å™¨çš„å¯é æ€§ç ”ç©¶|Lucas Lopes, Rayson Laroca, AndrÃ© GrÃ©gio|<https://arxiv.org/pdf/2601.08674v1>|æ— |
|ğŸ“ æ›´æ–°|PI3DETR: Parametric Instance Detection of 3D Point Cloud Edges With a Geometry-Aware 3DETR|PI3DETR: åŸºäºGeometry-Aware 3DETRçš„3Dç‚¹äº‘è¾¹ç¼˜å‚æ•°åŒ–å®ä¾‹æ£€æµ‹|Fabio F. Oberweger, Michael Schwingshackl, Vanessa Staderini|<https://arxiv.org/pdf/2509.03262v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|WaveFormer: Frequency-Time Decoupled Vision Modeling with Wave Equation|WaveFormer: åŸºäºæ³¢åŠ¨æ–¹ç¨‹çš„é¢‘ç‡-æ—¶é—´è§£è€¦è§†è§‰å»ºæ¨¡|Zishan Shu, Juntong Wu, Wei Yan, Xudong Liu, Hongyu Zhang, Chang Liu, Youdong Mao, Jie Chen|<https://arxiv.org/pdf/2601.08602v1>|[ä»£ç ](https://github.com/ZishanShu/WaveFormer.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Zero-Shot Distracted Driver Detection via Vision Language Models with Double Decoupling|Zero-Shot åˆ†å¿ƒé©¾é©¶å‘˜æ£€æµ‹ via Vision Language Models with Double Decoupling|Takamichi Miyata, Sumiko Miyata, Andrew Morris|<https://arxiv.org/pdf/2601.08467v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|YOLOBirDrone: Dataset for Bird vs Drone Detection and Classification and a YOLO based enhanced learning architecture|YOLOBirDrone: é¸Ÿç±»ä¸æ— äººæœºæ£€æµ‹åˆ†ç±»æ•°æ®é›†åŠåŸºäºYOLOçš„å¢å¼ºå­¦ä¹ æ¶æ„|Dapinder Kaur, Neeraj Battish, Arnav Bhavsar, Shashi Poddar|<https://arxiv.org/pdf/2601.08319v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Human-inspired Global-to-Parallel Multi-scale Encoding for Lightweight Vision Models|å—äººç±»å¯å‘çš„å…¨å±€åˆ°å¹¶è¡Œå¤šå°ºåº¦ç¼–ç ï¼Œç”¨äºè½»é‡çº§ Vision Models|Wei Xu|<https://arxiv.org/pdf/2601.08190v1>|æ— |


### ç›®æ ‡æ£€æµ‹ä¸å®šä½ (Object Detection & Localization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MEMEWEAVER: Inter-Meme Graph Reasoning for Sexism and Misogyny Detection|MEMEWEAVER: ç”¨äºæ€§åˆ«æ­§è§†å’ŒåŒå¥³ç—‡æ£€æµ‹çš„è¿·å› é—´å›¾æ¨ç†|Paolo Italiani, David Gimeno-Gomez, Luca Ragazzi, Gianluca Moro, Paolo Rosso|<https://arxiv.org/pdf/2601.08684v1>|æ— |
|ğŸ†• å‘å¸ƒ|TRACE: Reconstruction-Based Anomaly Detection in Ensemble and Time-Dependent Simulations|TRACE: åŸºäºé‡æ„çš„é›†æˆä¸æ—¶é—´ä¾èµ–æ¨¡æ‹Ÿä¸­çš„å¼‚å¸¸æ£€æµ‹|Hamid Gadirov, Martijn Westra, Steffen Frey|<https://arxiv.org/pdf/2601.08659v1>|æ— |
|ğŸ“ æ›´æ–°|Backdoor Attacks on Open Vocabulary Object Detectors via Multi-Modal Prompt Tuning|é€šè¿‡å¤šæ¨¡æ€æç¤ºè°ƒä¼˜å¯¹å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹å™¨çš„åé—¨æ”»å‡»|Ankita Raj, Chetan Arora|<https://arxiv.org/pdf/2511.12735v2>|[ä»£ç ](https://github.com/rajankita/TrAP)|
|ğŸ†• å‘å¸ƒ|Modality-Decoupled RGB-Thermal Object Detector via Query Fusion|åŸºäº Query Fusion çš„æ¨¡æ€è§£è€¦ RGB-Thermal ç›®æ ‡æ£€æµ‹å™¨|Chao Tian, Zikun Zhou, Chao Yang, Guoqing Zhu, Fu'an Zhong, Zhenyu He|<https://arxiv.org/pdf/2601.08458v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|From Local Windows to Adaptive Candidates via Individualized Exploratory: Rethinking Attention for Image Super-Resolution|ä»å±€éƒ¨çª—å£åˆ°è‡ªé€‚åº”å€™é€‰ï¼šé€šè¿‡ä¸ªæ€§åŒ–æ¢ç´¢é‡æ–°æ€è€ƒå›¾åƒè¶…åˆ†è¾¨ç‡ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶|Chunyu Meng, Wei Long, Shuhang Gu|<https://arxiv.org/pdf/2601.08341v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|FUME: Fused Unified Multi-Gas Emission Network for Livestock Rumen Acidosis Detection|FUMEï¼šç”¨äºå®¶ç•œç˜¤èƒƒé…¸ä¸­æ¯’æ£€æµ‹çš„èåˆç»Ÿä¸€å¤šæ°”ä½“æ’æ”¾ç½‘ç»œ|Taminul Islam, Toqi Tahamid Sarker, Mohamed Embaby, Khaled R Ahmed, Amer AbuGhazaleh|<https://arxiv.org/pdf/2601.08205v1>|[ä»£ç ](https://github.com/taminulislam/fume.)|
|ğŸ†• å‘å¸ƒ|Towards Cross-Platform Generalization: Domain Adaptive 3D Detection with Augmentation and Pseudo-Labeling|è¿ˆå‘è·¨å¹³å°æ³›åŒ–ï¼šåŸºäºå¢å¼ºå’Œä¼ªæ ‡ç­¾çš„åŸŸè‡ªé€‚åº”3Dæ£€æµ‹|Xiyan Feng, Wenbo Zhang, Lu Zhang, Yunzhi Zhuge, Huchuan Lu, You He|<https://arxiv.org/pdf/2601.08174v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Instance-Aligned Captions for Explainable Video Anomaly Detection|[ç¿»è¯‘å¤±è´¥] Instance-Aligned Captions for Explainable Video Anomaly Detection|Inpyo Song, Minjun Joo, Joonhyung Kwon, Eunji Jeon, Jangwon Lee|<https://arxiv.org/pdf/2601.08155v1>|åˆ†æå¤±è´¥|


### å›¾åƒåˆ†ç±»ä¸è¯†åˆ« (Image Classification & Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|AIMC-Spec: A Benchmark Dataset for Automatic Intrapulse Modulation Classification under Variable Noise Conditions|AIMC-Spec: Variable Noise Conditions ä¸‹è‡ªåŠ¨è„‰å†…è°ƒåˆ¶åˆ†ç±»çš„åŸºå‡†æ•°æ®é›†|Sebastian L. Cocks, Salvador Dreo, Feras Dayoub|<https://arxiv.org/pdf/2601.08265v1>|æ— |
|ğŸ†• å‘å¸ƒ|Unified Multi-Site Multi-Sequence Brain MRI Harmonization Enriched by Biomedical Semantic Style|å¤šç«™ç‚¹å¤šåºåˆ—è„‘MRIç»Ÿä¸€åè°ƒï¼Œç”±ç”Ÿç‰©åŒ»å­¦è¯­ä¹‰é£æ ¼å¢å¼º|Mengqi Wu, Yongheng Sun, Qianqian Wang, Pew-Thian Yap, Mingxia Liu|<https://arxiv.org/pdf/2601.08193v1>|åˆ†æå¤±è´¥|


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|FilmSceneDesigner: Chaining Set Design for Procedural Film Scene Generation|FilmSceneDesigner: ç”¨äºç¨‹åºåŒ–ç”µå½±åœºæ™¯ç”Ÿæˆçš„å¸ƒæ™¯è®¾è®¡é“¾å¼æ–¹æ³•|Zhifeng Xie, Keyi Zhang, Yiye Yan, Yuling Guo, Fan Yang, Jiting Zhou, Mengtian Li|<https://arxiv.org/pdf/2511.19137v2>|æ— |
|ğŸ†• å‘å¸ƒ|Motion Attribution for Video Generation|[ç¿»è¯‘å¤±è´¥] Motion Attribution for Video Generation|Xindi Wu, Despoina Paschalidou, Jun Gao, Antonio Torralba, Laura Leal-TaixÃ©, Olga Russakovsky, Sanja Fidler, Jonathan Lorraine|<https://arxiv.org/pdf/2601.08828v1>|æ— |
|ğŸ†• å‘å¸ƒ|Salience-SGG: Enhancing Unbiased Scene Graph Generation with Iterative Salience Estimation|Salience-SGG: åˆ©ç”¨è¿­ä»£æ˜¾è‘—æ€§ä¼°è®¡å¢å¼ºæ— ååœºæ™¯å›¾ç”Ÿæˆ|Runfeng Qu, Ole Hall, Pia K Bideau, Julie Ouerfelli-Ethier, Martin Rolfs, Klaus Obermayer, Olaf Hellwich|<https://arxiv.org/pdf/2601.08728v1>|æ— |
|ğŸ“ æ›´æ–°|Apollo: Unified Multi-Task Audio-Video Joint Generation|Apollo: ç»Ÿä¸€å¤šä»»åŠ¡ Audio-Video è”åˆç”Ÿæˆ|Jun Wang, Chunyu Qiang, Yuxin Guo, Yiran Wang, Xijuan Zeng, Feng Deng|<https://arxiv.org/pdf/2601.04151v2>|æ— |
|ğŸ†• å‘å¸ƒ|ViDoRe V3: A Comprehensive Evaluation of Retrieval Augmented Generation in Complex Real-World Scenarios|ViDoRe V3: å¤æ‚ç°å®åœºæ™¯ä¸­æ£€ç´¢å¢å¼ºç”Ÿæˆçš„ç»¼åˆè¯„ä¼°|AntÃ³nio Loison, Quentin MacÃ©, Antoine Edy, Victor Xing, Tom Balough, Gabriel Moreira, Bo Liu, Manuel Faysse .etc.|<https://arxiv.org/pdf/2601.08620v1>|æ— |
|ğŸ†• å‘å¸ƒ|Towards Safer Mobile Agents: Scalable Generation and Evaluation of Diverse Scenarios for VLMs|è¿ˆå‘æ›´å®‰å…¨çš„ Mobile Agentsï¼šé¢å‘ VLMs çš„å¤šæ ·åŒ–åœºæ™¯å¯æ‰©å±•ç”Ÿæˆä¸è¯„ä¼°|Takara Taniguchi, Kuniaki Saito, Atsushi Hashimoto|<https://arxiv.org/pdf/2601.08470v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|MOGO: Residual Quantized Hierarchical Causal Transformer for High-Quality and Real-Time 3D Human Motion Generation|MOOGOï¼šç”¨äºé«˜è´¨é‡å’Œå®æ—¶3Däººä½“è¿åŠ¨ç”Ÿæˆçš„æ®‹å·®é‡åŒ–åˆ†å±‚å› æœTransformer|Dongjie Fu, Tengjiao Sun, Pengcheng Fang, Xiaohao Cai, Hansung Kim|<https://arxiv.org/pdf/2506.05952v3>|æ— |
|ğŸ†• å‘å¸ƒ|CoMa: Contextual Massing Generation with Vision-Language Models|CoMa: åŸºäºVision-Language Modelsçš„ä¸Šä¸‹æ–‡ä½“é‡ç”Ÿæˆ|Evgenii Maslov, Valentin Khrulkov, Anastasia Volkova, Anton Gusarov, Andrey Kuznetsov, Ivan Oseledets|<https://arxiv.org/pdf/2601.08464v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|IGAN: A New Inception-based Model for Stable and High-Fidelity Image Synthesis Using Generative Adversarial Networks|IGAN: ä¸€ç§åŸºäºInceptionçš„ç¨³å®šé«˜ä¿çœŸå›¾åƒç”Ÿæˆå¯¹æŠ—ç½‘ç»œæ–°æ¨¡å‹|Ahmed A. Hashim, Ali Al-Shuwaili, Asraa Saeed, Ali Al-Bayaty|<https://arxiv.org/pdf/2601.08332v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Enhancing Image Quality Assessment Ability of LMMs via Retrieval-Augmented Generation|é€šè¿‡æ£€ç´¢å¢å¼ºç”Ÿæˆæå‡ LMMs çš„å›¾åƒè´¨é‡è¯„ä¼°èƒ½åŠ›|Kang Fu, Huiyu Duan, Zicheng Zhang, Yucheng Zhu, Jun Zhao, Xiongkuo Min, Jia Wang, Guangtao Zhai|<https://arxiv.org/pdf/2601.08311v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|MixGRPO: Unlocking Flow-based GRPO Efficiency with Mixed ODE-SDE|MixGRPO: åˆ©ç”¨æ··åˆ ODE-SDE è§£é”åŸºäº Flow çš„ GRPO æ•ˆç‡|Junzhe Li, Yutao Cui, Tao Huang, Yinping Ma, Chun Fan, Miles Yang, Zhao Zhong|<https://arxiv.org/pdf/2507.21802v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|SnapGen++: Unleashing Diffusion Transformers for Efficient High-Fidelity Image Generation on Edge Devices|SnapGen++ï¼šåœ¨ Edge Devices ä¸Šé‡Šæ”¾ Diffusion Transformers ä»¥å®ç°é«˜æ•ˆçš„é«˜ä¿çœŸå›¾åƒç”Ÿæˆ|Dongting Hu, Aarush Gupta, Magzhan Gabidolla, Arpit Sahni, Huseyin Coskun, Yanyu Li, Yerlan Idelbayev, Ahsan Mahmood .etc.|<https://arxiv.org/pdf/2601.08303v1>|æ— |
|ğŸ†• å‘å¸ƒ|HIPPO: Accelerating Video Large Language Models Inference via Holistic-aware Parallel Speculative Decoding|HIPPOï¼šé€šè¿‡æ•´ä½“æ„ŸçŸ¥å¹¶è¡Œæ¨æµ‹è§£ç åŠ é€Ÿè§†é¢‘å¤§è¯­è¨€æ¨¡å‹æ¨ç†|Qitan Lv, Tianyu Liu, Wen Wu, Xuenan Xu, Bowen Zhou, Feng Wu, Chao Zhang|<https://arxiv.org/pdf/2601.08273v1>|æ— |
|ğŸ†• å‘å¸ƒ|Instruction-Driven 3D Facial Expression Generation and Transition|Instruction-Driven 3D é¢éƒ¨è¡¨æƒ…ç”Ÿæˆä¸è½¬æ¢|Anh H. Vo, Tae-Seok Kim, Hulin Jin, Soo-Mi Choi, Yong-Guk Kim|<https://arxiv.org/pdf/2601.08179v1>|[ä»£ç ](https://vohoanganh.github.io/tg3dfet)|
|ğŸ†• å‘å¸ƒ|From Prompts to Deployment: Auto-Curated Domain-Specific Dataset Generation via Diffusion Models|ä» Prompts åˆ°éƒ¨ç½²ï¼šé€šè¿‡ Diffusion Models å®ç°è‡ªåŠ¨ç²¾é€‰çš„ç‰¹å®šé¢†åŸŸæ•°æ®é›†ç”Ÿæˆ|Dongsik Yoon, Jongeun Kim|<https://arxiv.org/pdf/2601.08095v1>|æ— |


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|DGAE: Diffusion-Guided Autoencoder for Efficient Latent Representation Learning|[ç¿»è¯‘å¤±è´¥] DGAE: Diffusion-Guided Autoencoder for Efficient Latent Representation Learning|Dongxu Liu, Jiahui Zhu, Yuang Peng, Haomiao Tang, Yuwei Chen, Chunrui Han, Zheng Ge, Daxin Jiang .etc.|<https://arxiv.org/pdf/2506.09644v2>|æ— |
|ğŸ†• å‘å¸ƒ|Translating Light-Sheet Microscopy Images to Virtual H&E Using CycleGAN|ä½¿ç”¨ CycleGAN å°†å…‰ç‰‡æ˜¾å¾®é•œå›¾åƒè½¬æ¢ä¸ºè™šæ‹Ÿ H&E|Yanhua Zhao|<https://arxiv.org/pdf/2601.08776v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|ISLA: A U-Net for MRI-based acute ischemic stroke lesion segmentation with deep supervision, attention, domain adaptation, and ensemble learning|ISLAï¼šä¸€ç§åŸºäºæ·±åº¦ç›‘ç£ã€æ³¨æ„åŠ›ã€åŸŸé€‚åº”å’Œé›†æˆå­¦ä¹ çš„ç”¨äºMRIæ€¥æ€§ç¼ºè¡€æ€§å’ä¸­ç—…ç¶åˆ†å‰²çš„U-Net|Vincent Roca, Martin Bretzner, Hilde Henon, Laurent Puy, GrÃ©gory Kuchcinski, Renaud Lopes|<https://arxiv.org/pdf/2601.08732v1>|æ— |
|ğŸ†• å‘å¸ƒ|Automated Lesion Segmentation of Stroke MRI Using nnU-Net: A Comprehensive External Validation Across Acute and Chronic Lesions|ä½¿ç”¨ nnU-Net çš„å’ä¸­ MRI ç—…ç¶è‡ªåŠ¨åˆ†å‰²ï¼šè·¨è¶Šæ€¥æ€§å’Œæ…¢æ€§ç—…ç¶çš„å…¨é¢å¤–éƒ¨éªŒè¯|Tammar Truzman, Matthew A. Lambon Ralph, Ajay D. Halai|<https://arxiv.org/pdf/2601.08701v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|CasTex: Cascaded Text-to-Texture Synthesis via Explicit Texture Maps and Physically-Based Shading|CasTexï¼šé€šè¿‡æ˜¾å¼çº¹ç†å›¾å’ŒåŸºäºç‰©ç†çš„ç€è‰²è¿›è¡Œçº§è”Text-to-Textureåˆæˆ|Mishan Aliev, Dmitry Baranchuk, Kirill Struminsky|<https://arxiv.org/pdf/2504.06856v2>|æ— |
|ğŸ†• å‘å¸ƒ|REVNET: Rotation-Equivariant Point Cloud Completion via Vector Neuron Anchor Transformer|REVNET: é€šè¿‡ Vector Neuron Anchor Transformer å®ç°æ—‹è½¬ç­‰å˜ç‚¹äº‘è¡¥å…¨|Zhifan Ni, Eckehard Steinbach|<https://arxiv.org/pdf/2601.08558v1>|[ä»£ç ](https://github.com/nizhf/REVNET.)|
|ğŸ†• å‘å¸ƒ|DiffMM: Efficient Method for Accurate Noisy and Sparse Trajectory Map Matching via One Step Diffusion|DiffMMï¼šé€šè¿‡ä¸€æ­¥æ‰©æ•£å®ç°ç²¾ç¡®å™ªå£°å’Œç¨€ç–è½¨è¿¹åœ°å›¾åŒ¹é…çš„é«˜æ•ˆæ–¹æ³•|Chenxu Han, Sean Bin Yang, Jilin Hu|<https://arxiv.org/pdf/2601.08482v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Deep Learning Based Facial Retargeting Using Local Patches|åŸºäº Local Patches çš„ Deep Learning é¢éƒ¨é‡å®šå‘|Yeonsoo Choi, Inyup Lee, Sihun Cha, Seonghyeon Kim, Sunjin Jung, Junyong Noh|<https://arxiv.org/pdf/2601.08429v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Training-Free Distribution Adaptation for Diffusion Models via Maximum Mean Discrepancy Guidance|é€šè¿‡Maximum Mean Discrepancy Guidanceå®ç°Diffusion Modelsçš„å…è®­ç»ƒåˆ†å¸ƒé€‚åº”|Matina Mahdizadeh Sani, Nima Jamali, Mohammad Jalali, Farzan Farnia|<https://arxiv.org/pdf/2601.08379v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Latent Geometry of Taste: Scalable Low-Rank Matrix Factorization for Recommender Systems|Latent Geometry of Tasteï¼šç”¨äºæ¨èç³»ç»Ÿçš„å¯æ‰©å±•ä½ç§©çŸ©é˜µåˆ†è§£|Joshua Salako|<https://arxiv.org/pdf/2601.03466v2>|[ä»£ç ](https://github.com/joshsalako/recommender.git); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|PathoSyn: Imaging-Pathology MRI Synthesis via Disentangled Deviation Diffusion|PathoSynï¼šåŸºäºè§£è€¦åå·®æ‰©æ•£çš„å½±åƒ-ç—…ç† MRI åˆæˆ|Jian Wang, Sixing Rong, Jiarui Xing, Yuling Xu, Weide Liu|<https://arxiv.org/pdf/2512.23130v2>|åˆ†æå¤±è´¥|


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Aggregating Diverse Cue Experts for AI-Generated Image Detection|èšåˆå¤šæ ·åŒ– Cue Experts ç”¨äº AI ç”Ÿæˆå›¾åƒæ£€æµ‹|Lei Tan, Shuwei Li, Mohan Kankanhalli, Robby T. Tan|<https://arxiv.org/pdf/2601.08790v1>|æ— |
|ğŸ†• å‘å¸ƒ|SafeRedir: Prompt Embedding Redirection for Robust Unlearning in Image Generation Models|SafeRedirï¼šç”¨äºå›¾åƒç”Ÿæˆæ¨¡å‹ä¸­é²æ£’é—å¿˜çš„ Prompt Embedding é‡å®šå‘|Renyang Liu, Kangjie Chen, Han Qiu, Jie Zhang, Kwok-Yan Lam, Tianwei Zhang, See-Kiong Ng|<https://arxiv.org/pdf/2601.08623v1>|[ä»£ç ](https://github.com/ryliu68/SafeRedir.)|


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Generative Adversarial Networks for Image Super-Resolution: A Survey|ç”¨äºå›¾åƒè¶…åˆ†è¾¨ç‡çš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼šç»¼è¿°|Ziang Wu, Xuanyu Zhang, Yinbo Yu, Qi Zhu, Jerry Chun-Wei Lin, Chunwei Tian|<https://arxiv.org/pdf/2204.13620v5>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|VideoHEDGE: Entropy-Based Hallucination Detection for Video-VLMs via Semantic Clustering and Spatiotemporal Perturbations|VideoHEDGE: åŸºäºç†µçš„Video-VLMså¹»è§‰æ£€æµ‹ï¼Œé€šè¿‡è¯­ä¹‰èšç±»å’Œæ—¶ç©ºæ‰°åŠ¨|Sushant Gautam, Cise Midoglu, Vajira Thambawita, Michael A. Riegler, PÃ¥l Halvorsen|<https://arxiv.org/pdf/2601.08557v1>|[ä»£ç ](https://github.com/Simula/HEDGE)|
|ğŸ“ æ›´æ–°|Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions|ä»ç™Œç—‡ç»„ç»‡ç—…ç†å­¦ç”Ÿæˆè·¨æ¨¡æ€åŸºå› è¡¨è¾¾å¯æ”¹å–„å¤šæ¨¡æ€ AI é¢„æµ‹|Samiran Dey, Christopher R. S. Banerji, Partha Basuchowdhuri, Sanjoy K. Saha, Deepak Parashar, Tapabrata Chakraborti|<https://arxiv.org/pdf/2502.00568v4>|[ä»£ç ](https://github.com/Samiran-Dey/PathGen.)|
|ğŸ“ æ›´æ–°|FoldNet: Learning Generalizable Closed-Loop Policy for Garment Folding via Keypoint-Driven Asset and Demonstration Synthesis|FoldNet: é€šè¿‡Keypoint-Driven Asset and Demonstration Synthesiså­¦ä¹ å¯æ³›åŒ–çš„æœè£…æŠ˜å é—­ç¯ç­–ç•¥|Yuxing Chen, Bowen Xiao, He Wang|<https://arxiv.org/pdf/2505.09109v3>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Tuning-free Visual Effect Transfer across Videos|è·¨è§†é¢‘æ— è°ƒä¼˜è§†è§‰ç‰¹æ•ˆè¿ç§»|Maxwell Jones, Rameen Abdal, Or Patashnik, Ruslan Salakhutdinov, Sergey Tulyakov, Jun-Yan Zhu, Kuan-Chieh Jackson Wang|<https://arxiv.org/pdf/2601.07833v2>|[ä»£ç ](https://tuningfreevisualeffects-maker.github.io/Tuning-free-Visual-Effect-Transfer-across-Videos-Project-Page)|


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|GSAlign: Geometric and Semantic Alignment Network for Aerial-Ground Person Re-Identification|GSAlign: ç”¨äºç©ºåœ°è¡Œäººé‡è¯†åˆ«çš„å‡ ä½•ä¸è¯­ä¹‰å¯¹é½ç½‘ç»œ|Qiao Li, Jie Li, Yukang Zhang, Lei Tan, Jing Chen, Jiayi Ji|<https://arxiv.org/pdf/2510.22268v2>|æ— |
|ğŸ“ æ›´æ–°|Unifying Appearance Codes and Bilateral Grids for Driving Scene Gaussian Splatting|ç»Ÿä¸€å¤–è§‚ç¼–ç ä¸åŒè¾¹ç½‘æ ¼ç”¨äºé©¾é©¶åœºæ™¯ Gaussian Splatting|Nan Wang, Yuantao Chen, Lixing Xiao, Weiqing Xiao, Bohan Li, Zhaoxi Chen, Chongjie Ye, Shaocong Xu .etc.|<https://arxiv.org/pdf/2506.05280v4>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|HiFi-Mamba: Dual-Stream W-Laplacian Enhanced Mamba for High-Fidelity MRI Reconstruction|HiFi-Mamba: ç”¨äºé«˜ä¿çœŸ MRI é‡å»ºçš„åŒæµ W-Laplacian å¢å¼º Mamba|Hongli Chen, Pengcheng Fang, Yuxia Chen, Yingxuan Ren, Jing Hao, Fangfang Tang, Xiaohao Cai, Shanshan Shan .etc.|<https://arxiv.org/pdf/2508.09179v2>|æ— |
|ğŸ“ æ›´æ–°|Learning-based Multi-View Stereo: A Survey|åŸºäºå­¦ä¹ çš„å¤šè§†å›¾ç«‹ä½“è§†è§‰ï¼šç»¼è¿°|Fangjinhua Wang, Qingtian Zhu, Di Chang, Quankai Gao, Junlin Han, Tong Zhang, Richard Hartley, Marc Pollefeys|<https://arxiv.org/pdf/2408.15235v3>|æ— |
|ğŸ†• å‘å¸ƒ|SPARK: Scalable Real-Time Point Cloud Aggregation with Multi-View Self-Calibration|SPARKï¼šå…·æœ‰å¤šè§†å›¾è‡ªæ ¡å‡†çš„å¯æ‰©å±•å®æ—¶ç‚¹äº‘èšåˆ|Chentian Sun|<https://arxiv.org/pdf/2601.08414v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Geo-NVS-w: Geometry-Aware Novel View Synthesis In-the-Wild with an SDF Renderer|Geo-NVS-wï¼šåŸºäºå‡ ä½•æ„ŸçŸ¥çš„é‡å¤–æ–°è§†å›¾åˆæˆï¼Œä½¿ç”¨ SDF Renderer|Anastasios Tsalakopoulos, Angelos Kanlis, Evangelos Chatzis, Antonis Karakottas, Dimitrios Zarpalas|<https://arxiv.org/pdf/2601.08371v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Reconstruct, Inpaint, Test-Time Finetune: Dynamic Novel-view Synthesis from Monocular Videos|é‡å»ºã€ä¿®å¤ã€æµ‹è¯•æ—¶å¾®è°ƒï¼šæ¥è‡ªå•ç›®è§†é¢‘çš„åŠ¨æ€æ–°è§†è§’åˆæˆ|Kaihua Chen, Tarasha Khurana, Deva Ramanan|<https://arxiv.org/pdf/2507.12646v2>|åˆ†æå¤±è´¥|


### è§†è§‰å®šä½ä¸æ˜ å°„ (Visual Localization & Mapping)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization|RGS-SLAM: å…·æœ‰å•æ¬¡å¯†é›†åˆå§‹åŒ–çš„é²æ£’ Gaussian Splatting SLAM|Wei-Tse Cheng, Yen-Jen Chiou, Yuan-Fu Yang|<https://arxiv.org/pdf/2601.00705v2>|[ä»£ç ](https://breeze1124.github.io/rgs-slam-project-page)|
|ğŸ†• å‘å¸ƒ|Second-order Gaussian directional derivative representations for image high-resolution corner detection|Second-order Gaussian æ–¹å‘å¯¼æ•°è¡¨ç¤ºç”¨äºå›¾åƒé«˜åˆ†è¾¨ç‡è§’ç‚¹æ£€æµ‹|Dongbo Xie, Junjie Qiu, Changming Sun, Weichuan Zhang|<https://arxiv.org/pdf/2601.08182v1>|æ— |
|ğŸ†• å‘å¸ƒ|CogniMap3D: Cognitive 3D Mapping and Rapid Retrieval|CogniMap3D: è®¤çŸ¥3Då»ºå›¾ä¸å¿«é€Ÿæ£€ç´¢|Feiran Wang, Junyi Wu, Dawen Cai, Yuan Hong, Yan Yan|<https://arxiv.org/pdf/2601.08175v1>|åˆ†æå¤±è´¥|


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|S3-CLIP: Video Super Resolution for Person-ReID|S3-CLIP: ç”¨äº Person-ReID çš„è§†é¢‘è¶…åˆ†è¾¨ç‡|Tamas Endrei, Gyorgy Cserey|<https://arxiv.org/pdf/2601.08807v1>|æ— |


### è§†é¢‘ç›®æ ‡è·Ÿè¸ª (Video Object Tracking)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|TrackNetV5: Residual-Driven Spatio-Temporal Refinement and Motion Direction Decoupling for Fast Object Tracking|TrackNetV5: åŸºäºæ®‹å·®é©±åŠ¨çš„æ—¶ç©ºç»†åŒ–å’Œè¿åŠ¨æ–¹å‘è§£è€¦çš„å¿«é€Ÿç›®æ ‡è·Ÿè¸ª|Haonan Tang, Yanjun Chen, Lezhi Jiang, Qianfei Li, Xinyu Guo|<https://arxiv.org/pdf/2512.02789v4>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|End-to-End Video Character Replacement without Structural Guidance|æ— ç»“æ„æŒ‡å¯¼çš„ç«¯åˆ°ç«¯è§†é¢‘è§’è‰²æ›¿æ¢|Zhengbo Xu, Jie Ma, Ziheng Wang, Zhan Peng, Jun Liang, Jing Li|<https://arxiv.org/pdf/2601.08587v1>|åˆ†æå¤±è´¥|


### åŠ¨ä½œè¯†åˆ«ä¸ç†è§£ (Action Recognition & Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MobiDiary: Autoregressive Action Captioning with Wearable Devices and Wireless Signals|MobiDiaryï¼šåŸºäºå¯ç©¿æˆ´è®¾å¤‡å’Œæ— çº¿ä¿¡å·çš„è‡ªå›å½’åŠ¨ä½œæè¿°|Fei Deng, Yinghui He, Chuntong Chu, Ge Wang, Han Ding, Jinsong Han, Fei Wang|<https://arxiv.org/pdf/2601.08204v1>|åˆ†æå¤±è´¥|


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Blind Deconvolution in Astronomy: How Does a Standalone U-Net Perform?|å¤©æ–‡å­¦ä¸­çš„ç›²å»å·ç§¯ï¼šç‹¬ç«‹çš„ U-Net è¡¨ç°å¦‚ä½•ï¼Ÿ|Jean-Eric Campagne|<https://arxiv.org/pdf/2601.08666v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|An IoT-Enabled Smart Aquarium System for Real-Time Water Quality Monitoring and Automated Feeding|ä¸€ç§æ”¯æŒIoTçš„æ™ºèƒ½æ°´æ—ç³»ç»Ÿï¼Œç”¨äºå®æ—¶æ°´è´¨ç›‘æµ‹å’Œè‡ªåŠ¨æŠ•å–‚|MD Fatin Ishraque Ayon, Sabrin Nahar, Ataur Rahman, Md. Taslim Arif, Abdul Hasib, A. S. M. Ahsanul Sarkar Akib|<https://arxiv.org/pdf/2601.08484v1>|æ— |
|ğŸ†• å‘å¸ƒ|M3SR: Multi-Scale Multi-Perceptual Mamba for Efficient Spectral Reconstruction|M3SR: ç”¨äºé«˜æ•ˆå…‰è°±é‡å»ºçš„å¤šå°ºåº¦å¤šæ„ŸçŸ¥ Mamba|Yuze Zhang, Lingjie Li, Qiuzhen Lin, Zhong Ming, Fei Yu, Victor C. M. Leung|<https://arxiv.org/pdf/2601.08293v1>|æ— |
|ğŸ“ æ›´æ–°|Semi-Tensor-Product Based Convolutional Neural Networks|åŸºäºåŠå¼ é‡ç§¯çš„å·ç§¯ç¥ç»ç½‘ç»œ|Daizhan Cheng, Xiao Zhang|<https://arxiv.org/pdf/2506.10407v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Real-Time LiDAR Point Cloud Densification for Low-Latency Spatial Data Transmission|ç”¨äºä½å»¶è¿Ÿç©ºé—´æ•°æ®ä¼ è¾“çš„å®æ—¶ LiDAR ç‚¹äº‘åŠ å¯†|Kazuhiko Murasaki, Shunsuke Konagai, Masakatsu Aoki, Taiga Yoshida, Ryuichi Tanida|<https://arxiv.org/pdf/2601.01210v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Quantization-Aware Neuromorphic Architecture for Skin Disease Classification on Resource-Constrained Devices|é¢å‘èµ„æºå—é™è®¾å¤‡çš„çš®è‚¤ç—…åˆ†ç±»é‡åŒ–æ„ŸçŸ¥ç¥ç»å½¢æ€æ¶æ„|Haitian Wang, Xinyu Wang, Yiren Wang, Bo Miao, Atif Mansoor|<https://arxiv.org/pdf/2507.15958v3>|æ— |
|ğŸ†• å‘å¸ƒ|Subspace Alignment for Vision-Language Model Test-time Adaptation|[ç¿»è¯‘å¤±è´¥] Subspace Alignment for Vision-Language Model Test-time Adaptation|Zhichen Zeng, Wenxuan Bao, Xiao Lin, Ruizhong Qiu, Tianxin Wei, Xuying Ning, Yuchen Yan, Chen Luo .etc.|<https://arxiv.org/pdf/2601.08139v1>|åˆ†æå¤±è´¥|


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Real-Time Localization Framework for Autonomous Basketball Robots|è‡ªä¸»ç¯®çƒæœºå™¨äººçš„å®æ—¶å®šä½æ¡†æ¶|Naren Medarametla, Sreejon Mondal|<https://arxiv.org/pdf/2601.08713v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|SfMamba: Efficient Source-Free Domain Adaptation via Selective Scan Modeling|SfMamba: é€šè¿‡é€‰æ‹©æ€§æ‰«æå»ºæ¨¡å®ç°é«˜æ•ˆæ— æºåŸŸé€‚åº”|Xi Chen, Hongxun Yao, Sicheng Zhao, Jiankun Zhu, Jing Jiang, Kui Jiang|<https://arxiv.org/pdf/2601.08608v1>|[ä»£ç ](https://github.com/chenxi52/SfMamba.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Robust Subpixel Localization of Diagonal Markers in Large-Scale Navigation via Multi-Layer Screening and Adaptive Matching|åŸºäºå¤šå±‚ç­›é€‰å’Œè‡ªé€‚åº”åŒ¹é…çš„å¤§è§„æ¨¡å¯¼èˆªä¸­è§’æ ‡æ ‡è®°çš„é²æ£’äºšåƒç´ å®šä½|Jing Tao, Banglei Guan, Yang Shang, Shunkun Liang, Qifeng Yu|<https://arxiv.org/pdf/2601.08161v1>|æ— |
|ğŸ“ æ›´æ–°|Perceptual Region-Driven Infrared-Visible Co-Fusion for Extreme Scene Enhancement|[ç¿»è¯‘å¤±è´¥] Perceptual Region-Driven Infrared-Visible Co-Fusion for Extreme Scene Enhancement|Jing Tao, Yonghong Zong, Banglei Guan, Pengju Sun, Taihang Lei, Yang Shanga, Qifeng Yu|<https://arxiv.org/pdf/2512.06400v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|PRISM: Self-Pruning Intrinsic Selection Method for Training-Free Multimodal Data Selection|PRISMï¼šç”¨äºå…è®­ç»ƒå¤šæ¨¡æ€æ•°æ®é€‰æ‹©çš„è‡ªå‰ªæå†…åœ¨é€‰æ‹©æ–¹æ³•|Jinhe Bi, Aniri, Yifan Wang, Danqi Yan, Wenke Huang, Zengjie Jin, Xiaowen Ma, Sikuan Yan .etc.|<https://arxiv.org/pdf/2502.12119v3>|[ä»£ç ](https://github.com/bibisbar/PRISM); åˆ†æå¤±è´¥|


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Interpretability and Individuality in Knee MRI: Patient-Specific Radiomic Fingerprint with Reconstructed Healthy Personas|Knee MRI ä¸­çš„å¯è§£é‡Šæ€§å’Œä¸ªä½“æ€§ï¼šåŸºäºé‡å»ºå¥åº·äººåƒçš„æ‚£è€…ç‰¹å¼‚æ€§ Radiomic Fingerprint|Yaxi Chen, Simin Ni, Shuai Li, Shaheer U. Saeed, Aleksandra Ivanova, Rikin Hargunani, Jie Huang, Chaozong Liu .etc.|<https://arxiv.org/pdf/2601.08604v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Developing Predictive and Robust Radiomics Models for Chemotherapy Response in High-Grade Serous Ovarian Carcinoma|å¼€å‘ç”¨äºé«˜çº§åˆ«æµ†æ¶²æ€§åµå·¢ç™ŒåŒ–ç–—ååº”çš„é¢„æµ‹æ€§å’Œé²æ£’æ€§ Radiomics æ¨¡å‹|Sepideh Hatamikia, Geevarghese George, Florian Schwarzhans, Amirreza Mahbod, Marika AV Reinius, Ali Abbasian Ardakani, Mercedes Jimenez-Linan, Satish Viswanath .etc.|<https://arxiv.org/pdf/2601.08455v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Deep Exploration of Epoch-wise Double Descent in Noisy Data: Signal Separation, Large Activation, and Benign Overfitting|Noisy Data ä¸­ Epoch-wise Double Descent çš„æ·±åº¦æ¢ç´¢ï¼šSignal Separationã€Large Activation å’Œ Benign Overfitting|Tomoki Kubo, Ryuken Uda, Yusuke Iida|<https://arxiv.org/pdf/2601.08316v1>|æ— |
|ğŸ“ æ›´æ–°|PINGS-X: Physics-Informed Normalized Gaussian Splatting with Axes Alignment for Efficient Super-Resolution of 4D Flow MRI|PINGS-X: åŸºäºè½´å¯¹é½çš„ç‰©ç†ä¿¡æ¯å½’ä¸€åŒ–é«˜æ–¯æ³¼æº…ï¼Œç”¨äº4D Flow MRIçš„é«˜æ•ˆè¶…åˆ†è¾¨ç‡|Sun Jo, Seok Young Hong, JinHyun Kim, Seungmin Kang, Ahjin Choi, Don-Gwan An, Simon Song, Je Hyeong Hong|<https://arxiv.org/pdf/2511.11048v2>|[ä»£ç ](https://github.com/SpatialAILab/PINGS-X.)|
|ğŸ†• å‘å¸ƒ|Tissue Classification and Whole-Slide Images Analysis via Modeling of the Tumor Microenvironment and Biological Pathways|é€šè¿‡è‚¿ç˜¤å¾®ç¯å¢ƒå’Œç”Ÿç‰©é€šè·¯å»ºæ¨¡è¿›è¡Œç»„ç»‡åˆ†ç±»ä¸å…¨åˆ‡ç‰‡å›¾åƒåˆ†æ|Junzhuo Liu, Xuemei Du, Daniel Reisenbuchler, Ye Chen, Markus Eckstein, Christian Matek, Friedrich Feuerhake, Dorit Merhof|<https://arxiv.org/pdf/2601.08336v1>|æ— |
|ğŸ“ æ›´æ–°|Global Compression Commander: Plug-and-Play Inference Acceleration for High-Resolution Large Vision-Language Models|Global Compression Commanderï¼šé¢å‘é«˜åˆ†è¾¨ç‡ Large Vision-Language Models çš„å³æ’å³ç”¨æ¨ç†åŠ é€Ÿ|Xuyang Liu, Ziming Wang, Junjie Chen, Yuhang Han, Yingyao Wang, Jiale Yuan, Jun Song, Siteng Huang .etc.|<https://arxiv.org/pdf/2501.05179v6>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Your Super Resolution Model is not Enough for Tackling Real-World Scenarios|ä½ çš„ Super Resolution æ¨¡å‹ä¸è¶³ä»¥åº”å¯¹ Real-World åœºæ™¯|Dongsik Yoon, Jongeun Kim|<https://arxiv.org/pdf/2509.06387v2>|æ— |


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### åˆ†å¸ƒå¤–æ³›åŒ– (Out-of-distribution Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Keyframe-based Dense Mapping with the Graph of View-Dependent Local Maps|åŸºäºå…³é”®å¸§çš„ç¨ å¯†å»ºå›¾ä¸è§†ç‚¹ä¾èµ–å±€éƒ¨åœ°å›¾å›¾|Krzysztof Zielinski, Dominik Belter|<https://arxiv.org/pdf/2601.08520v1>|åˆ†æå¤±è´¥|


### å¯¹æŠ—é²æ£’æ€§ (Adversarial Robustness)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|CausAdv: A Causal-based Framework for Detecting Adversarial Examples|CausAdvï¼šä¸€ç§åŸºäºCausalçš„Adversarial Examplesæ£€æµ‹æ¡†æ¶|Hichem Debbi|<https://arxiv.org/pdf/2411.00839v2>|åˆ†æå¤±è´¥|


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|SemiETPicker: Fast and Label-Efficient Particle Picking for CryoET Tomography Using Semi-Supervised Learning|SemiETPickerï¼šåˆ©ç”¨åŠç›‘ç£å­¦ä¹ å®ç°CryoETæ–­å±‚æ‰«æçš„å¿«é€Ÿä¸”æ ‡ç­¾é«˜æ•ˆçš„é¢—ç²’æŒ‘é€‰|Linhan Wang, Jianwen Dou, Wang Li, Shengkun Wang, Zhiwu Xie, Chang-Tien Lu, Yinlin Chen|<https://arxiv.org/pdf/2510.22454v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|MDReID: Modality-Decoupled Learning for Any-to-Any Multi-Modal Object Re-Identification|MDReID: ç”¨äºä»»æ„åˆ°ä»»æ„å¤šæ¨¡æ€ç›®æ ‡é‡è¯†åˆ«çš„æ¨¡æ€è§£è€¦å­¦ä¹ |Yingying Feng, Jie Li, Jie Hu, Yukang Zhang, Lei Tan, Jiayi Ji|<https://arxiv.org/pdf/2510.23301v2>|[ä»£ç ](https://github.com/stone96123/MDReID); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|VLingNav: Embodied Navigation with Adaptive Reasoning and Visual-Assisted Linguistic Memory|VLingNav: å…·æœ‰è‡ªé€‚åº”æ¨ç†å’Œè§†è§‰è¾…åŠ©è¯­è¨€è®°å¿†çš„å…·èº«å¯¼èˆª|Shaoan Wang, Yuanfei Luo, Xingyu Chen, Aocheng Luo, Dongyue Li, Chang Liu, Sheng Chen, Yangang Zhang .etc.|<https://arxiv.org/pdf/2601.08665v1>|æ— |
|ğŸ“ æ›´æ–°|Divergence-Based Similarity Function for Multi-View Contrastive Learning|åŸºäºæ•£åº¦çš„å¤šè§†å›¾å¯¹æ¯”å­¦ä¹ ç›¸ä¼¼åº¦å‡½æ•°|Jae Hyoung Jeon, Cheolsu Lim, Myungjoo Kang|<https://arxiv.org/pdf/2507.06560v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|CD^2: Constrained Dataset Distillation for Few-Shot Class-Incremental Learning|CD^2: ç”¨äº Few-Shot Class-Incremental Learning çš„çº¦æŸ Dataset Distillation|Kexin Bao, Daichi Zhang, Hansong Zhang, Yong Li, Yutao Yue, Shiming Ge|<https://arxiv.org/pdf/2601.08519v1>|æ— |
|ğŸ†• å‘å¸ƒ|PKI: Prior Knowledge-Infused Neural Network for Few-Shot Class-Incremental Learning|[ç¿»è¯‘å¤±è´¥] PKI: Prior Knowledge-Infused Neural Network for Few-Shot Class-Incremental Learning|Kexin Baoa, Fanzhao Lin, Zichen Wang, Yong Li, Dan Zeng, Shiming Ge|<https://arxiv.org/pdf/2601.08493v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Divide and Conquer: Static-Dynamic Collaboration for Few-Shot Class-Incremental Learning|åˆ†è€Œæ²»ä¹‹ï¼šç”¨äº Few-Shot Class-Incremental Learning çš„é™æ€-åŠ¨æ€åä½œ|Kexin Bao, Daichi Zhang, Yong Li, Dan Zeng, Shiming Ge|<https://arxiv.org/pdf/2601.08448v1>|æ— |
|ğŸ†• å‘å¸ƒ|An Explainable Two Stage Deep Learning Framework for Pericoronitis Assessment in Panoramic Radiographs Using YOLOv8 and ResNet-50|ä¸€ç§åŸºäºYOLOv8å’ŒResNet-50ç”¨äºå…¨æ™¯ç‰‡å† å‘¨ç‚è¯„ä¼°çš„å¯è§£é‡Šä¸¤é˜¶æ®µæ·±åº¦å­¦ä¹ æ¡†æ¶|Ajo Babu George, Pranav S, Kunal Agarwal|<https://arxiv.org/pdf/2601.08401v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Knowledge-based learning in Text-RAG and Image-RAG|åŸºäºå­¦ä¹ çš„ Text-RAG å’Œ Image-RAG|Alexander Shim, Khalil Saieh, Samuel Clarke|<https://arxiv.org/pdf/2601.08226v1>|åˆ†æå¤±è´¥|


### é›¶/å°‘æ ·æœ¬æ³›åŒ– (Zero/Few-shot Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|RAVEN: Erasing Invisible Watermarks via Novel View Synthesis|RAVEN: é€šè¿‡ Novel View Synthesis æ“¦é™¤ Invisible Watermarks|Fahad Shamshad, Nils Lukas, Karthik Nandakumar|<https://arxiv.org/pdf/2601.08832v1>|åˆ†æå¤±è´¥|


### å°æ ·æœ¬å­¦ä¹  (Few-shot Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Near-perfect photo-ID of the Hula painted frog with zero-shot deep local-feature matching|Hulaå½©ç»˜è›™çš„è¿‘ä¹å®Œç¾çš„ç…§ç‰‡è¯†åˆ«ï¼Œé‡‡ç”¨zero-shotæ·±åº¦å±€éƒ¨ç‰¹å¾åŒ¹é…|Maayan Yesharim, R. G. Bina Perl, Uri Roll, Sarig Gafny, Eli Geffen, Yoav Ram|<https://arxiv.org/pdf/2601.08798v1>|æ— |
|ğŸ†• å‘å¸ƒ|Cross-modal Proxy Evolving for OOD Detection with Vision-Language Models|åŸºäºVision-Language Modelsçš„OODæ£€æµ‹è·¨æ¨¡æ€ä»£ç†æ¼”åŒ–|Hao Tang, Yu Liu, Shuanglin Yan, Fei Shen, Shengfeng He, Jing Qin|<https://arxiv.org/pdf/2601.08476v1>|æ— |
|ğŸ†• å‘å¸ƒ|One-Shot Identification with Different Neural Network Approaches|[ç¿»è¯‘å¤±è´¥] One-Shot Identification with Different Neural Network Approaches|Janis Mohr, JÃ¶rg Frochte|<https://arxiv.org/pdf/2601.08278v1>|æ— |
|ğŸ†• å‘å¸ƒ|Improving Zero-shot ADL Recognition with Large Language Models through Event-based Context and Confidence|åˆ©ç”¨åŸºäºäº‹ä»¶çš„ä¸Šä¸‹æ–‡å’Œç½®ä¿¡åº¦ï¼Œé€šè¿‡ Large Language Models æ”¹è¿› Zero-shot ADL Recognition|Michele Fiori, Gabriele Civitarese, Marco Colussi, Claudio Bettini|<https://arxiv.org/pdf/2601.08241v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|A Hardware-Algorithm Co-Designed Framework for HDR Imaging and Dehazing in Extreme Rocket Launch Environments|é¢å‘æç«¯ç«ç®­å‘å°„ç¯å¢ƒçš„HDRæˆåƒä¸å»é›¾ç¡¬ä»¶-ç®—æ³•ååŒè®¾è®¡æ¡†æ¶|Jing Tao, Banglei Guan, Pengju Sun, Taihang Lei, Yang Shang, Qifeng Yu|<https://arxiv.org/pdf/2601.08162v1>|åˆ†æå¤±è´¥|


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Reasoning Matters for 3D Visual Grounding|[ç¿»è¯‘å¤±è´¥] Reasoning Matters for 3D Visual Grounding|Hsiang-Wei Huang, Kuang-Ming Chen, Wenhao Chai, Cheng-Yen Yang, Jen-Hao Cheng, Jenq-Neng Hwang|<https://arxiv.org/pdf/2601.08811v1>|æ— |
|ğŸ“ æ›´æ–°|ClimateIQA: A New Dataset and Benchmark to Advance Vision-Language Models in Meteorology Anomalies Analysis|ClimateIQA: ä¸€ä¸ªç”¨äºæ¨è¿›æ°”è±¡å¼‚å¸¸åˆ†æä¸­Vision-Language Modelsçš„æ–°æ•°æ®é›†å’ŒåŸºå‡†|Jian Chen, Peilin Zhou, Yining Hua, Dading Chong, Meng Cao, Yaowei Li, Wei Chen, Bing Zhu .etc.|<https://arxiv.org/pdf/2406.09838v4>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Visually Prompted Benchmarks Are Surprisingly Fragile|è§†è§‰æç¤ºçš„åŸºå‡†æµ‹è¯•å‡ºäººæ„æ–™åœ°è„†å¼±|Haiwen Feng, Long Lian, Lisa Dunlap, Jiahao Shu, XuDong Wang, Renhao Wang, Trevor Darrell, Alane Suhr .etc.|<https://arxiv.org/pdf/2512.17875v2>|[ä»£ç ](https://lisadunlap.github.io/vpbench)|
|ğŸ“ æ›´æ–°|Ground What You See: Hallucination-Resistant MLLMs via Caption Feedback, Diversity-Aware Sampling, and Conflict Regularization|Ground What You See: é€šè¿‡Caption Feedbackã€Diversity-Aware Samplingå’ŒConflict Regularizationå®ç°æŠ—å¹»è§‰MLLMs|Miao Pan, Wangjie Gan, Jintao Chen, Wenqi Zhang, Bing Sun, Jianwei Yin, Xuhong Zhang|<https://arxiv.org/pdf/2601.06224v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Where Does Vision Meet Language? Understanding and Refining Visual Fusion in MLLMs via Contrastive Attention|è§†è§‰ä¸è¯­è¨€åœ¨ä½•å¤„ç›¸é‡ï¼Ÿé€šè¿‡å¯¹æ¯”æ³¨æ„åŠ›ç†è§£å’Œæ”¹è¿› MLLMs ä¸­çš„è§†è§‰èåˆ|Shezheng Song, Shasha Li, Jie Yu|<https://arxiv.org/pdf/2601.08151v1>|åˆ†æå¤±è´¥|


### å¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿ (Multimodal Dialogue Systems)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Cascading multi-agent anomaly detection in surveillance systems via vision-language models and embedding-based classification|åŸºäºvision-language modelså’Œembedding-based classificationçš„ç›‘æ§ç³»ç»Ÿä¸­çº§è”å¤šagentå¼‚å¸¸æ£€æµ‹|Tayyab Rehman, Giovanni De Gasperis, Aly Shmahell|<https://arxiv.org/pdf/2601.06204v2>|åˆ†æå¤±è´¥|


### è§†è§‰å†…å®¹æè¿° (Visual Content Description)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Incentivizing Cardiologist-Like Reasoning in MLLMs for Interpretable Echocardiographic Diagnosis|æ¿€åŠ±MLLMsä¸­ç±»ä¼¼å¿ƒè„ç—…å­¦å®¶çš„æ¨ç†ä»¥å®ç°å¯è§£é‡Šçš„è¶…å£°å¿ƒåŠ¨å›¾è¯Šæ–­|Yi Qin, Lehan Wang, Chenxu Zhao, Alex P. W. Lee, Xiaomeng Li|<https://arxiv.org/pdf/2601.08440v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|How Do Optical Flow and Textual Prompts Collaborate to Assist in Audio-Visual Semantic Segmentation?|Optical Flow å’Œ Textual Prompts å¦‚ä½•ååŒè¾…åŠ© Audio-Visual Semantic Segmentationï¼Ÿ|Peng Gao, Yujian Lee, Yongqi Xu, Wentao Fan|<https://arxiv.org/pdf/2601.08133v1>|åˆ†æå¤±è´¥|


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Comparative validation of surgical phase recognition, instrument keypoint estimation, and instrument instance segmentation in endoscopy: Results of the PhaKIR 2024 challenge|å†…çª¥é•œæ‰‹æœ¯é˜¶æ®µè¯†åˆ«ã€å™¨æ¢°å…³é”®ç‚¹ä¼°è®¡å’Œå™¨æ¢°å®ä¾‹åˆ†å‰²çš„æ¯”è¾ƒéªŒè¯ï¼šPhaKIR 2024æŒ‘æˆ˜èµ›ç»“æœ|Tobias Rueckert, David Rauber, Raphaela Maerkl, Leonard Klausmann, Suemeyye R. Yildiran, Max Gutbrod, Danilo Weber Nunes, Alvaro Fernandez Moreno .etc.|<https://arxiv.org/pdf/2507.16559v2>|æ— |
|ğŸ†• å‘å¸ƒ|M3CoTBench: Benchmark Chain-of-Thought of MLLMs in Medical Image Understanding|M3CoTBench: åŒ»å­¦å›¾åƒç†è§£ä¸­MLLMsæ€ç»´é“¾çš„åŸºå‡†æµ‹è¯•|Juntao Jiang, Jiangning Zhang, Yali Bi, Jinsheng Bai, Weixuan Liu, Weiwei Jin, Zhucun Xue, Yong Liu .etc.|<https://arxiv.org/pdf/2601.08758v1>|[ä»£ç ](https://juntaojianggavin.github.io/projects)|
|ğŸ†• å‘å¸ƒ|Region of interest detection for efficient aortic segmentation|æ„Ÿå…´è¶£åŒºåŸŸæ£€æµ‹ç”¨äºé«˜æ•ˆä¸»åŠ¨è„‰åˆ†å‰²|Loris Giordano, Ine Dirks, Tom Lenaerts, Jef Vandemeulebroucke|<https://arxiv.org/pdf/2601.08683v1>|æ— |
|ğŸ“ æ›´æ–°|ViewMorpher3D: A 3D-aware Diffusion Framework for Multi-Camera Novel View Synthesis in Autonomous Driving|ViewMorpher3Dï¼šä¸€ç§ç”¨äºè‡ªåŠ¨é©¾é©¶ä¸­å¤šç›¸æœºæ–°è§†å›¾åˆæˆçš„3Dæ„ŸçŸ¥æ‰©æ•£æ¡†æ¶|Farhad G. Zanjani, Hong Cai, Amirhossein Habibian|<https://arxiv.org/pdf/2601.07540v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Two-Stream Thermal Imaging Fusion for Enhanced Time of Birth Detection in Neonatal Care|[ç¿»è¯‘å¤±è´¥] Two-Stream Thermal Imaging Fusion for Enhanced Time of Birth Detection in Neonatal Care|Jorge GarcÃ­a-Torres, Ã˜yvind Meinich-Bache, Sara Brunner, Siren Rettedal, Vilde Kolstad, Kjersti Engan|<https://arxiv.org/pdf/2503.03244v3>|æ— |
|ğŸ†• å‘å¸ƒ|ReCo-KD: Region- and Context-Aware Knowledge Distillation for Efficient 3D Medical Image Segmentation|ReCo-KD: ç”¨äºé«˜æ•ˆ 3D åŒ»å­¦å›¾åƒåˆ†å‰²çš„åŒºåŸŸå’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥çŸ¥è¯†è’¸é¦|Qizhen Lan, Yu-Chun Hsu, Nida Saddaf Khan, Xiaoqian Jiang|<https://arxiv.org/pdf/2601.08301v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|MSSF: A 4D Radar and Camera Fusion Framework With Multi-Stage Sampling for 3D Object Detection in Autonomous Driving|MSSFï¼šä¸€ç§ç”¨äºè‡ªåŠ¨é©¾é©¶3Dç›®æ ‡æ£€æµ‹çš„å¤šé˜¶æ®µé‡‡æ ·4Dé›·è¾¾ä¸ç›¸æœºèåˆæ¡†æ¶|Hongsi Liu, Jun Liu, Guangfeng Jiang, Xin Jin|<https://arxiv.org/pdf/2411.15016v2>|æ— |
|ğŸ†• å‘å¸ƒ|Route, Retrieve, Reflect, Repair: Self-Improving Agentic Framework for Visual Detection and Linguistic Reasoning in Medical Imaging|Route, Retrieve, Reflect, Repairï¼šåŒ»å­¦å½±åƒä¸­è§†è§‰æ£€æµ‹ä¸è¯­è¨€æ¨ç†çš„è‡ªæ”¹è¿›æ™ºèƒ½ä½“æ¡†æ¶|Md. Faiyaz Abdullah Sayeedi, Rashedur Rahman, Siam Tahsin Bhuiyan, Sefatul Wasi, Ashraful Islam, Saadia Binte Alam, AKM Mahbubur Rahman|<https://arxiv.org/pdf/2601.08192v1>|[ä»£ç ](https://github.com/faiyazabdullah/MultimodalMedAgent)|
|ğŸ†• å‘å¸ƒ|Representation Learning with Semantic-aware Instance and Sparse Token Alignments|å…·æœ‰è¯­ä¹‰æ„ŸçŸ¥å®ä¾‹å’Œç¨€ç–Tokenå¯¹é½çš„è¡¨ç¤ºå­¦ä¹ |Phuoc-Nguyen Bui, Toan Duc Nguyen, Junghyun Bum, Duc-Tai Le, Hyunseung Choo|<https://arxiv.org/pdf/2601.08165v1>|æ— |
|ğŸ†• å‘å¸ƒ|PathoGen: Diffusion-Based Synthesis of Realistic Lesions in Histopathology Images|PathoGenï¼šåŸºäºDiffusionçš„Histopathology Imagesä¸­Realistic Lesionsåˆæˆ|Mohamad Koohi-Moghadam, Mohammad-Ali Nikouei Mahani, Kyongtae Tyler Bae|<https://arxiv.org/pdf/2601.08127v1>|æ— |


### æ™ºèƒ½äº¤é€šè§†è§‰ (Intelligent Transportation Vision)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SoC: Semantic Orthogonal Calibration for Test-Time Prompt Tuning|SoCï¼šç”¨äºTest-Time Prompt Tuningçš„è¯­ä¹‰æ­£äº¤æ ¡å‡†|Leo Fillioux, Omprakash Chakraborty, Ismail Ben Ayed, Paul-Henry CournÃ¨de, Stergios Christodoulidis, Maria Vakalopoulou, Jose Dolz|<https://arxiv.org/pdf/2601.08617v1>|æ— |
|ğŸ“ æ›´æ–°|DriveRX: A Vision-Language Reasoning Model for Cross-Task Autonomous Driving|DriveRX: ä¸€ä¸ªç”¨äºè·¨ä»»åŠ¡è‡ªåŠ¨é©¾é©¶çš„è§†è§‰è¯­è¨€æ¨ç†æ¨¡å‹|Muxi Diao, Lele Yang, Hongbo Yin, Zhexu Wang, Yejie Wang, Daxin Tian, Kongming Liang, Zhanyu Ma|<https://arxiv.org/pdf/2505.20665v2>|åˆ†æå¤±è´¥|


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MMLGNet: Cross-Modal Alignment of Remote Sensing Data using CLIP|MMLGNet: ä½¿ç”¨CLIPè¿›è¡Œé¥æ„Ÿæ•°æ®çš„è·¨æ¨¡æ€å¯¹é½|Aditya Chaudhary, Sneha Barman, Mainak Singha, Ankit Jha, Girish Mishra, Biplab Banerjee|<https://arxiv.org/pdf/2601.08420v1>|[ä»£ç ](https://github.com/AdityaChaudhary2913/CLIP_HSI.)|
|ğŸ†• å‘å¸ƒ|Noise-Adaptive Regularization for Robust Multi-Label Remote Sensing Image Classification|[ç¿»è¯‘å¤±è´¥] Noise-Adaptive Regularization for Robust Multi-Label Remote Sensing Image Classification|Tom Burgert, Julia Henkel, BegÃ¼m Demir|<https://arxiv.org/pdf/2601.08446v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Source-Free Domain Adaptation for Geospatial Point Cloud Semantic Segmentation|[ç¿»è¯‘å¤±è´¥] Source-Free Domain Adaptation for Geospatial Point Cloud Semantic Segmentation|Yuan Gao, Di Cao, Xiaohuan Xi, Sheng Nie, Shaobo Xia, Cheng Wang|<https://arxiv.org/pdf/2601.08375v1>|æ— |
|ğŸ“ æ›´æ–°|HisTrackMap: Global Vectorized High-Definition Map Construction via History Map Tracking|HisTrackMap: é€šè¿‡å†å²åœ°å›¾è·Ÿè¸ªè¿›è¡Œå…¨å±€çŸ¢é‡åŒ–é«˜ç²¾åœ°å›¾æ„å»º|Jing Yang, Sen Yang, Xiao Tan, Hanli Wang|<https://arxiv.org/pdf/2503.07168v3>|[ä»£ç ](https://yj772881654.github.io/HisTrackMap.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|A Diff-Attention Aware State Space Fusion Model for Remote Sensing Classification|ä¸€ç§Diff-Attentionæ„ŸçŸ¥çš„çŠ¶æ€ç©ºé—´èåˆæ¨¡å‹ç”¨äºé¥æ„Ÿåˆ†ç±»|Wenping Ma, Boyou Xue, Mengru Ma, Chuang Chen, Hekai Zhang, Hao Zhu|<https://arxiv.org/pdf/2504.16665v2>|[ä»£ç ](https://github.com/AVKSKVL/DAS-F-Model); åˆ†æå¤±è´¥|


### å·¥ä¸šè§†è§‰æ£€æµ‹ (Industrial Visual Inspection)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Semantic Misalignment in Vision-Language Models under Perceptual Degradation|æ„ŸçŸ¥é€€åŒ–ä¸‹Vision-Language Modelsä¸­çš„è¯­ä¹‰é”™ä½|Guo Cheng|<https://arxiv.org/pdf/2601.08355v1>|æ— |


## æ–°å…´ç†è®ºä¸è·¨å­¦ç§‘æ–¹å‘ (Emerging Theory & Interdisciplinary Directions)


### ç¥ç»-ç¬¦å·è§†è§‰ (Neuro-symbolic Vision)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|A Vision for Multisensory Intelligence: Sensing, Science, and Synergy|å¤šæ„Ÿå®˜æ™ºèƒ½çš„æ„¿æ™¯ï¼šæ„ŸçŸ¥ã€ç§‘å­¦ä¸ååŒ|Paul Pu Liang|<https://arxiv.org/pdf/2601.04563v3>|[ä»£ç ](https://mit-mi.github.io/.)|


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Explaning with trees: interpreting CNNs using hierarchies|[ç¿»è¯‘å¤±è´¥] Explaning with trees: interpreting CNNs using hierarchies|Caroline Mazini Rodrigues, Nicolas Boutry, Laurent Najman|<https://arxiv.org/pdf/2406.13257v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Design and Development of a Low-Cost Scalable GSM-IoT Smart Pet Feeder with a Remote Mobile Application|ä½æˆæœ¬å¯æ‰©å±• GSM-IoT æ™ºèƒ½å® ç‰©å–‚é£Ÿå™¨çš„è®¾è®¡ä¸å¼€å‘ï¼Œé…å¤‡è¿œç¨‹ç§»åŠ¨åº”ç”¨ç¨‹åº|Md. Rakibul Hasan Nishat, S. M. Khalid Bin Zahid, Abdul Hasib, T. M. Mehrab Hasan, Mohammad Arman, A. S. M. Ahsanul Sarkar Akib|<https://arxiv.org/pdf/2601.08394v1>|åˆ†æå¤±è´¥|

