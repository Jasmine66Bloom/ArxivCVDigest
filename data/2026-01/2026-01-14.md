## [UPDATED!] **2026-01-14** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|STEP3-VL-10B Technical Report|STEP3-VL-10B æŠ€æœ¯æŠ¥å‘Š|Ailin Huang, Chengyuan Yao, Chunrui Han, Fanqi Wan, Hangyu Guo, Haoran Lv, Hongyu Zhou, Jia Wang .etc.|<https://arxiv.org/pdf/2601.09668v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|CogRail: Benchmarking VLMs in Cognitive Intrusion Perception for Intelligent Railway Transportation Systems|CogRail: æ™ºèƒ½é“è·¯è¿è¾“ç³»ç»Ÿä¸­è®¤çŸ¥å…¥ä¾µæ„ŸçŸ¥çš„ VLMs åŸºå‡†æµ‹è¯•|Yonglin Tian, Qiyao Zhang, Wei Xu, Yutong Wang, Yihao Wu, Xinyi Li, Xingyuan Dai, Hui Zhang .etc.|<https://arxiv.org/pdf/2601.09613v1>|[ä»£ç ](https://github.com/Hub-Tian/CogRail.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|LP-LLM: End-to-End Real-World Degraded License Plate Text Recognition via Large Multimodal Models|LPç¿»è¯‘è¿™ä¸ªè®¡ç®—æœºè§†è§‰è®ºæ–‡æ ‡é¢˜ï¼š|Haoyan Gong, Hongbin Liu|<https://arxiv.org/pdf/2601.09116v1>|åˆ†æå¤±è´¥|


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|LLMs can Compress LLMs: Adaptive Pruning by Agents|[ç¿»è¯‘å¤±è´¥] LLMs can Compress LLMs: Adaptive Pruning by Agents|Sai Varun Kodathala, Rakesh Vunnam|<https://arxiv.org/pdf/2601.09694v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Large-scale modality-invariant foundation models for brain MRI analysis: Application to lesion segmentation|ç”¨äºè„‘MRIåˆ†æçš„å¤§è§„æ¨¡æ¨¡æ€ä¸å˜åŸºç¡€æ¨¡å‹ï¼šåœ¨ç—…ç¶åˆ†å‰²ä¸­çš„åº”ç”¨|Petros Koutsouvelis, Matej Gazda, Leroy Volmer, Sina Amirrajab, Kamil Barbierik, Branislav Setlak, Jakub Gazda, Peter Drotar|<https://arxiv.org/pdf/2511.11311v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Video-MSR: Benchmarking Multi-hop Spatial Reasoning Capabilities of MLLMs|Video-MSRï¼šMLLMså¤šè·³ç©ºé—´æ¨ç†èƒ½åŠ›åŸºå‡†æµ‹è¯•|Rui Zhu, Xin Shen, Shuchen Wu, Chenxi Miao, Xin Yu, Yang Li, Weikang Li, Deguo Xia .etc.|<https://arxiv.org/pdf/2601.09430v1>|[ä»£ç ](https://github.com/ruiz-nju/Video-MSR.)|
|ğŸ“ æ›´æ–°|Frequency Is What You Need: Considering Word Frequency When Text Masking Benefits Vision-Language Model Pre-training|Frequency Is What You Need: è€ƒè™‘ Text Masking æ—¶çš„ Word Frequency æœ‰ç›Šäº Vision-Language Model Pre-training|Mingliang Liang, Martha Larson|<https://arxiv.org/pdf/2412.16148v3>|æ— |
|ğŸ†• å‘å¸ƒ|SAM-Aug: Leveraging SAM Priors for Few-Shot Parcel Segmentation in Satellite Time Series|SAM-Aug: åˆ©ç”¨ SAM å…ˆéªŒè¿›è¡Œå«æ˜Ÿæ—¶é—´åºåˆ—çš„å°æ ·æœ¬åœ°å—åˆ†å‰²|Kai Hu, Yaozu Feng, Vladimir Lysenko, Ya Guo Member, Huayi Wu|<https://arxiv.org/pdf/2601.09110v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Small but Mighty: Dynamic Wavelet Expert-Guided Fine-Tuning of Large-Scale Models for Optical Remote Sensing Object Segmentation|å°è€Œå¼ºå¤§ï¼šç”¨äºå…‰å­¦é¥æ„Ÿç›®æ ‡åˆ†å‰²çš„å¤§è§„æ¨¡æ¨¡å‹åŠ¨æ€å°æ³¢ä¸“å®¶å¼•å¯¼å¾®è°ƒ|Yanguang Sun, Chao Wang, Jian Yang, Lei Luo|<https://arxiv.org/pdf/2601.09108v1>|[ä»£ç ](https://github.com/CSYSI/WEFT.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Vision Foundation Models for Domain Generalisable Cross-View Localisation in Planetary Ground-Aerial Robotic Teams|ç”¨äºè¡Œæ˜Ÿåœ°é¢-ç©ºä¸­æœºå™¨äººå›¢é˜Ÿä¸­åŸŸæ³›åŒ–è·¨è§†å›¾å®šä½çš„Vision Foundation Models|Lachlan Holden, Feras Dayoub, Alberto Candela, David Harvey, Tat-Jun Chin|<https://arxiv.org/pdf/2601.09107v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|AviationLMM: A Large Multimodal Foundation Model for Civil Aviation|AviationLMM: ç”¨äºæ°‘èˆªçš„å¤§å‹å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹|Wenbin Li, Jingling Wu, Xiaoyong Lin. Jing Chen, Cong Chen|<https://arxiv.org/pdf/2601.09105v1>|æ— |
|ğŸ“ æ›´æ–°|GI-Bench: A Panoramic Benchmark Revealing the Knowledge-Experience Dissociation of Multimodal Large Language Models in Gastrointestinal Endoscopy Against Clinical Standards|GI-Benchï¼šä¸€ä¸ªæ­ç¤ºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨èƒƒè‚ å†…é•œä¸­ç›¸å¯¹äºä¸´åºŠæ ‡å‡†çš„çŸ¥è¯†ä¸ç»éªŒåˆ†ç¦»çš„å…¨æ™¯åŸºå‡†|Yan Zhu, Te Luo, Pei-Yao Fu, Zhen Zhang, Zi-Long Wang, Yi-Fan Qu, Zi-Han Geng, Jia-Qi Xu .etc.|<https://arxiv.org/pdf/2601.08183v2>|[ä»£ç ](https://roterdl.github.io/GIBench); åˆ†æå¤±è´¥|


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Head Pursuit: Probing Attention Specialization in Multimodal Transformers|Head Pursuitï¼šæ¢ç©¶ Multimodal Transformers ä¸­çš„ Attention Specialization|Lorenzo Basile, Valentino Maiorca, Diego Doimo, Francesco Locatello, Alberto Cazzaniga|<https://arxiv.org/pdf/2510.21518v2>|æ— |
|ğŸ†• å‘å¸ƒ|Do Transformers Understand Ancient Roman Coin Motifs Better than CNNs?|[ç¿»è¯‘å¤±è´¥] Do Transformers Understand Ancient Roman Coin Motifs Better than CNNs?|David Reid, Ognjen Arandjelovic|<https://arxiv.org/pdf/2601.09433v1>|æ— |
|ğŸ†• å‘å¸ƒ|Beyond the final layer: Attentive multilayer fusion for vision transformers|[ç¿»è¯‘å¤±è´¥] Beyond the final layer: Attentive multilayer fusion for vision transformers|Laure Ciernik, Marco Morik, Lukas Thede, Luca Eyring, Shinichi Nakajima, Zeynep Akata, Lukas Muttenthaler|<https://arxiv.org/pdf/2601.09322v1>|æ— |
|ğŸ“ æ›´æ–°|LC4-DViT: Land-cover Creation for Land-cover Classification with Deformable Vision Transformer|LC4-DViT: ç”¨äº Deformable Vision Transformer åœŸåœ°è¦†ç›–åˆ†ç±»çš„åœŸåœ°è¦†ç›–ç”Ÿæˆ|Kai Wang, Siyi Chen, Weicong Pang, Chenchen Zhang, Renjun Gao, Ziru Chen, Cheng Li, Dasa Gu .etc.|<https://arxiv.org/pdf/2511.22812v2>|æ— |
|ğŸ“ æ›´æ–°|MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head|MHLA: é€šè¿‡ Token-Level Multi-Head æ¢å¤ Linear Attention çš„è¡¨ç°åŠ›|Kewei Zhang, Ye Huang, Yufan Deng, Jincheng Yu, Junsong Chen, Huan Ling, Enze Xie, Daquan Zhou|<https://arxiv.org/pdf/2601.07832v2>|æ— |
|ğŸ†• å‘å¸ƒ|Equi-ViT: Rotational Equivariant Vision Transformer for Robust Histopathology Analysis|Equi-ViTï¼šç”¨äºé²æ£’ç»„ç»‡ç—…ç†å­¦åˆ†æçš„æ—‹è½¬ç­‰å˜ Vision Transformer|Fuyao Chen, Yuexi Du, ElÃ¨onore V. Lieffrig, Nicha C. Dvornek, John A. Onofrey|<https://arxiv.org/pdf/2601.09130v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Scaling Remote Sensing Foundation Models: Data Domain Tradeoffs at the Peta-Scale|æ‰©å±•é¥æ„ŸåŸºç¡€æ¨¡å‹ï¼šPeta-Scale æ•°æ®åŸŸçš„æƒè¡¡|Charith Wickrema, Eliza Mace, Hunter Brown, Heidys Cabrera, Nick Krall, Matthew O'Neill, Shivangi Sarkar, Lowell Weissman .etc.|<https://arxiv.org/pdf/2512.23903v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Image-to-Brain Signal Generation for Visual Prosthesis with CLIP Guided Multimodal Diffusion Models|ç”¨äºè§†è§‰å‡ä½“çš„ CLIP å¼•å¯¼å¤šæ¨¡æ€æ‰©æ•£æ¨¡å‹å›¾åƒåˆ°è„‘ä¿¡å·ç”Ÿæˆ|Ganxi Xu, Zhao-Rong Lai, Yuting Tang, Yonghao Song, Guoxu Zhou, Boyu wang, Jian Zhu, Jinyi Long|<https://arxiv.org/pdf/2509.00787v4>|æ— |
|ğŸ†• å‘å¸ƒ|Depth-Wise Representation Development Under Blockwise Self-Supervised Learning for Video Vision Transformers|åŸºäºåˆ†å—è‡ªç›‘ç£å­¦ä¹ çš„è§†é¢‘ Vision Transformer é€é€šé“è¡¨ç¤ºå‘å±•|Jonas RÃ¶mer, Timo Dickscheid|<https://arxiv.org/pdf/2601.09040v1>|åˆ†æå¤±è´¥|


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|COMPOSE: Hypergraph Cover Optimization for Multi-view 3D Human Pose Estimation|COMPOSE: ç”¨äºå¤šè§†è§’ 3D äººä½“å§¿æ€ä¼°è®¡çš„è¶…å›¾è¦†ç›–ä¼˜åŒ–|Tony Danjun Wang, Tolga Birdal, Nassir Navab, Lennart Bastian|<https://arxiv.org/pdf/2601.09698v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration|AQ-PCDSysï¼šä¸€ç§ç”¨äºè‡ªä¸»å¤ªç©ºæ¢ç´¢çš„è‡ªé€‚åº”é‡åŒ–è¡Œæ˜Ÿé™¨çŸ³å‘æ£€æµ‹ç³»ç»Ÿ|Aditri Paul, Archan Paul|<https://arxiv.org/pdf/2508.18025v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|GlovEgo-HOI: Bridging the Synthetic-to-Real Gap for Industrial Egocentric Human-Object Interaction Detection|GlovEgo-HOI: å¼¥åˆå·¥ä¸šåœºæ™¯ç¬¬ä¸€è§†è§’äººç‰©äº¤äº’æ£€æµ‹ä¸­çš„åˆæˆåˆ°çœŸå®åŸŸå·®è·|Alfio Spoto, Rosario Leonardi, Francesco Ragusa, Giovanni Maria Farinella|<https://arxiv.org/pdf/2601.09528v1>|æ— |
|ğŸ†• å‘å¸ƒ|DeTracker: Motion-decoupled Vehicle Detection and Tracking in Unstabilized Satellite Videos|DeTracker: éç¨³å®šå«æ˜Ÿè§†é¢‘ä¸­çš„è¿åŠ¨è§£è€¦è½¦è¾†æ£€æµ‹ä¸è·Ÿè¸ª|Jiajun Chen, Jing Xiao, Shaohan Cao, Yuming Zhu, Liang Liao, Jun Pan, Mi Wang|<https://arxiv.org/pdf/2601.09240v1>|åˆ†æå¤±è´¥|


### ç›®æ ‡æ£€æµ‹ä¸å®šä½ (Object Detection & Localization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|AquaFeat+: an Underwater Vision Learning-based Enhancement Method for Object Detection, Classification, and Tracking|[ç¿»è¯‘å¤±è´¥] AquaFeat+: an Underwater Vision Learning-based Enhancement Method for Object Detection, Classification, and Tracking|Emanuel da Costa Silva, Tatiana TaÃ­s Schein, JosÃ© David GarcÃ­a Ramos, Eduardo Lawson da Silva, Stephanie Loi BriÃ£o, Felipe Gomes de Oliveira, Paulo Lilles Jorge Drews-Jr|<https://arxiv.org/pdf/2601.09652v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Towards Robust Cross-Dataset Object Detection Generalization under Domain Specificity|[ç¿»è¯‘å¤±è´¥] Towards Robust Cross-Dataset Object Detection Generalization under Domain Specificity|Ritabrata Chakraborty, Hrishit Mitra, Shivakumara Palaiahnakote, Umapada Pal|<https://arxiv.org/pdf/2601.09497v1>|[ä»£ç ](https://github.com/Ritabrata04/cdod-icpr.git)|
|ğŸ†• å‘å¸ƒ|Disentangle Object and Non-object Infrared Features via Language Guidance|é€šè¿‡è¯­è¨€å¼•å¯¼è§£è€¦ç‰©ä½“ä¸éç‰©ä½“çº¢å¤–ç‰¹å¾|Fan Liu, Ting Wu, Chuanyi Zhang, Liang Yao, Xing Ma, Yuhui Zheng|<https://arxiv.org/pdf/2601.09228v1>|åˆ†æå¤±è´¥|


### å›¾åƒåˆ†ç±»ä¸è¯†åˆ« (Image Classification & Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|PrivLEX: Detecting legal concepts in images through Vision-Language Models|PrivLEX: é€šè¿‡Vision-Language Modelsæ£€æµ‹å›¾åƒä¸­çš„æ³•å¾‹æ¦‚å¿µ|Darya Baranouskaya, Andrea Cavallaro|<https://arxiv.org/pdf/2601.09449v1>|æ— |
|ğŸ“ æ›´æ–°|Analysis of Quantum Image Representations for Supervised Classification|ç›‘ç£åˆ†ç±»ä¸­é‡å­å›¾åƒè¡¨ç¤ºçš„åˆ†æ|Marco Parigi, Mehran Khosrojerdi, Filippo Caruso, Leonardo Banchi|<https://arxiv.org/pdf/2507.22039v2>|åˆ†æå¤±è´¥|


### è¯­ä¹‰/å®ä¾‹åˆ†å‰² (Semantic/Instance Segmentation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|AURASeg: Attention Guided Upsampling with Residual Boundary-Assistive Refinement for Drivable-Area Segmentation|AURASeg: åŸºäºæ®‹å·®è¾¹ç•Œè¾…åŠ©ç»†åŒ–çš„æ³¨æ„åŠ›å¼•å¯¼ä¸Šé‡‡æ ·ç”¨äºå¯è¡Œé©¶åŒºåŸŸåˆ†å‰²|Narendhiran Vijayakumar, Sridevi. M|<https://arxiv.org/pdf/2510.21536v3>|[ä»£ç ](https://github.com/Narendhiranv04/AURASeg)|


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Efficient Camera-Controlled Video Generation of Static Scenes via Sparse Diffusion and 3D Rendering|åŸºäºç¨€ç–æ‰©æ•£å’Œ3Dæ¸²æŸ“çš„é™æ€åœºæ™¯é«˜æ•ˆç›¸æœºæ§åˆ¶è§†é¢‘ç”Ÿæˆ|Jieying Chen, Jeffrey Hu, Joan Lasenby, Ayush Tewari|<https://arxiv.org/pdf/2601.09697v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Identifying Models Behind Text-to-Image Leaderboards|è¯†åˆ« Text-to-Image æ’è¡Œæ¦œèƒŒåçš„æ¨¡å‹|Ali Naseh, Yuefeng Peng, Anshuman Suri, Harsh Chaudhari, Alina Oprea, Amir Houmansadr|<https://arxiv.org/pdf/2601.09647v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Image2Garment: Simulation-ready Garment Generation from a Single Image|[ç¿»è¯‘å¤±è´¥] Image2Garment: Simulation-ready Garment Generation from a Single Image|Selim Emir Can, Jan Ackermann, Kiyohiro Nakayama, Ruofan Liu, Tong Wu, Yang Zheng, Hugo Bertiche, Menglei Chai .etc.|<https://arxiv.org/pdf/2601.09658v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Sim2real Image Translation Enables Viewpoint-Robust Policies from Fixed-Camera Datasets|Sim2realå›¾åƒç¿»è¯‘ä½¿åŸºäºå›ºå®šæ‘„åƒå¤´æ•°æ®é›†çš„è§†ç‚¹é²æ£’ç­–ç•¥æˆä¸ºå¯èƒ½|Jeremiah Coholich, Justin Wit, Robert Azarcon, Zsolt Kira|<https://arxiv.org/pdf/2601.09605v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|FigEx2: Visual-Conditioned Panel Detection and Captioning for Scientific Compound Figures|FigEx2ï¼šç§‘å­¦å¤åˆå›¾è¡¨çš„è§†è§‰æ¡ä»¶é¢æ¿æ£€æµ‹ä¸æè¿°ç”Ÿæˆ|Jifeng Song, Arun Das, Pan Wang, Hui Ji, Kun Zhao, Yufei Huang|<https://arxiv.org/pdf/2601.08026v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|VideoAR: Autoregressive Video Generation via Next-Frame & Scale Prediction|VideoAR: é€šè¿‡ä¸‹ä¸€å¸§ä¸å°ºåº¦é¢„æµ‹çš„è‡ªå›å½’è§†é¢‘ç”Ÿæˆ|Longbin Ji, Xiaoxiong Liu, Junyuan Shang, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang|<https://arxiv.org/pdf/2601.05966v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|GroupNL: Low-Resource and Robust CNN Design over Cloud and Device|GroupNLï¼šäº‘ç«¯å’Œè®¾å¤‡ä¸Šçš„ä½èµ„æºä¸é²æ£’CNNè®¾è®¡|Chuntao Ding, Jianhang Xie, Junna Zhang, Salman Raza, Shangguang Wang, Jiannong Cao|<https://arxiv.org/pdf/2506.12335v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Multi-Modal LLM based Image Captioning in ICT: Bridging the Gap Between General and Industry Domain|åŸºäº Multi-Modal LLM çš„ ICT é¢†åŸŸ Image Captioningï¼šå¼¥åˆ General Domain ä¸ Industry Domain ä¹‹é—´çš„å·®è·|Lianying Chao, Haoran Cai, Xubin Li, Kai Zhang, Sijie Wu, Rui Xu|<https://arxiv.org/pdf/2601.09298v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|JoyAvatar-Flash: Real-time and Infinite Audio-Driven Avatar Generation with Autoregressive Diffusion|JoyAvatar-Flashï¼šåŸºäºè‡ªå›å½’æ‰©æ•£çš„å®æ—¶æ— é™éŸ³é¢‘é©±åŠ¨Avatarç”Ÿæˆ|Chaochao Li, Ruikui Wang, Liangbo Zhou, Jinheng Feng, Huaishao Luo, Huan Zhang, Youzheng Wu, Xiaodong He|<https://arxiv.org/pdf/2512.11423v2>|æ— |
|ğŸ†• å‘å¸ƒ|Annealed Relaxation of Speculative Decoding for Faster Autoregressive Image Generation|Speculative Decoding çš„é€€ç«æ¾å¼›ç”¨äºæ›´å¿«çš„è‡ªå›å½’å›¾åƒç”Ÿæˆ|Xingyao Li, Fengzhuo Zhang, Cunxiao Du, Hui Ji|<https://arxiv.org/pdf/2601.09212v1>|æ— |
|ğŸ“ æ›´æ–°|Beyond the Last Frame: Process-aware Evaluation for Generative Video Reasoning|è¶…è¶Šæœ€åä¸€å¸§ï¼šç”Ÿæˆå¼è§†é¢‘æ¨ç†çš„æµç¨‹æ„ŸçŸ¥è¯„ä¼°|Yifan Li, Yukai Gu, Yingqian Min, Zikang Liu, Yifan Du, Kun Zhou, Min Yang, Wayne Xin Zhao .etc.|<https://arxiv.org/pdf/2512.24952v2>|[ä»£ç ](https://github.com/RUCAIBox/VIPER.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|GenView++: Unifying Adaptive View Generation and Quality-Driven Supervision for Contrastive Representation Learning|GenView++ï¼šç»Ÿä¸€è‡ªé€‚åº”è§†å›¾ç”Ÿæˆä¸è´¨é‡é©±åŠ¨çš„ç›‘ç£ç”¨äºå¯¹æ¯”è¡¨ç¤ºå­¦ä¹ |Xiaojie Li, Bei Wang, Jianlong Wu, Yue Yu, Liqiang Nie, Min Zhang|<https://arxiv.org/pdf/2509.23770v2>|æ— |
|ğŸ“ æ›´æ–°|DyDiT++: Diffusion Transformers with Timestep and Spatial Dynamics for Efficient Visual Generation|DyDiT++: å…·æœ‰æ—¶æ­¥å’Œç©ºé—´åŠ¨æ€çš„ Diffusion Transformers ç”¨äºé«˜æ•ˆè§†è§‰ç”Ÿæˆ|Wangbo Zhao, Yizeng Han, Jiasheng Tang, Kai Wang, Hao Luo, Yibing Song, Gao Huang, Fan Wang .etc.|<https://arxiv.org/pdf/2504.06803v4>|[ä»£ç ](https://github.com/alibaba-damo-academy/DyDiT.); åˆ†æå¤±è´¥|


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Trustworthy Longitudinal Brain MRI Completion: A Deformation-Based Approach with KAN-Enhanced Diffusion Model|å¯ä¿¡çš„çºµå‘è„‘MRIè¡¥å…¨ï¼šåŸºäºå˜å½¢çš„KANå¢å¼ºæ‰©æ•£æ¨¡å‹æ–¹æ³•|Tianli Tao, Ziyang Wang, Delong Yang, Han Zhang, Le Zhang|<https://arxiv.org/pdf/2601.09572v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|ViSTA: Visual Storytelling using Multi-modal Adapters for Text-to-Image Diffusion Models|ViSTA: ä½¿ç”¨å¤šæ¨¡æ€é€‚é…å™¨è¿›è¡Œæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„è§†è§‰å™äº‹|Sibo Dong, Ismail Shaheen, Maggie Shen, Rupayan Mallick, Sarah Adel Bargal|<https://arxiv.org/pdf/2506.12198v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Learning Whole-Body Human-Humanoid Interaction from Human-Human Demonstrations|[ç¿»è¯‘å¤±è´¥] Learning Whole-Body Human-Humanoid Interaction from Human-Human Demonstrations|Wei-Jin Huang, Yue-Yi Zhang, Yi-Lin Wei, Zhi-Wei Xia, Juantao Tan, Yuan-Ming Li, Zhilin Zhao, Wei-Shi Zheng|<https://arxiv.org/pdf/2601.09518v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Prompting4Debugging: Red-Teaming Text-to-Image Diffusion Models by Finding Problematic Prompts|Prompting4Debuggingï¼šé€šè¿‡å‘ç°æœ‰é—®é¢˜çš„Promptå¯¹Text-to-Image Diffusion Modelsè¿›è¡ŒRed-Teaming|Zhi-Yi Chin, Chieh-Ming Jiang, Ching-Chun Huang, Pin-Yu Chen, Wei-Chen Chiu|<https://arxiv.org/pdf/2309.06135v3>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Decoupling Continual Semantic Segmentation|è§£è€¦æŒç»­è¯­ä¹‰åˆ†å‰²|Yifu Guo, Yuquan Lu, Wentao Zhang, Zishan Xu, Dexia Chen, Siyu Zhang, Yizhe Zhang, Ruixuan Wang|<https://arxiv.org/pdf/2508.05065v2>|[ä»£ç ](https://github.com/euyis1019/Decoupling-Continual-Semantic-Segmentation.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Detail Loss in Super-Resolution Models Based on the Laplacian Pyramid and Repeated Upscaling and Downscaling Process|åŸºäº, the user wants me to translate a computer vision paper title into Chinese. Let me break this down carefully.|Sangjun Han, Youngmi Hur|<https://arxiv.org/pdf/2601.09410v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|FeatInv: Spatially resolved mapping from feature space to input space using conditional diffusion models|FeatInv: ä½¿ç”¨æ¡ä»¶æ‰©æ•£æ¨¡å‹ä»ç‰¹å¾ç©ºé—´åˆ°è¾“å…¥ç©ºé—´çš„ç©ºé—´åˆ†è¾¨æ˜ å°„|Nils Neukirch, Johanna Vielhaben, Nils Strodthoff|<https://arxiv.org/pdf/2505.21032v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|SpikeVAEDiff: Neural Spike-based Natural Visual Scene Reconstruction via VD-VAE and Versatile Diffusion|SpikeVAEDiff: åŸºäº Neural Spike çš„è‡ªç„¶è§†è§‰åœºæ™¯é‡å»ºï¼Œé€šè¿‡ VD-VAE å’Œ Versatile Diffusion|Jialu Li, Taiyan Zhou|<https://arxiv.org/pdf/2601.09213v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Beyond One-Size-Fits-All: A Survey of Personalized Affective Computing in Human-Agent Interaction|è¶…è¶Šä¸€åˆ€åˆ‡ï¼šäººæœºäº¤äº’ä¸­ä¸ªæ€§åŒ–æƒ…æ„Ÿè®¡ç®—ç»¼è¿°|Jialin Li, Maha Elgarf, Alia Waleed, Hanan Salam|<https://arxiv.org/pdf/2304.00377v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Universal Few-Shot Spatial Control for Diffusion Models|[ç¿»è¯‘å¤±è´¥] Universal Few-Shot Spatial Control for Diffusion Models|Kiet T. Nguyen, Chanhyuk Lee, Donggyun Kim, Dong Hoon Lee, Seunghoon Hong|<https://arxiv.org/pdf/2509.07530v2>|[ä»£ç ](https://github.com/kietngt00/UFC.); åˆ†æå¤±è´¥|


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|DEAR: Dataset for Evaluating the Aesthetics of Rendering|DEAR: ç”¨äºè¯„ä¼°æ¸²æŸ“ç¾å­¦çš„æ•°æ®é›†|Vsevolod Plohotnuk, Artyom Panshin, Nikola BaniÄ‡, Simone Bianco, Michael Freeman, Egor Ershov|<https://arxiv.org/pdf/2512.05209v4>|æ— |
|ğŸ†• å‘å¸ƒ|PhyRPR: Training-Free Physics-Constrained Video Generation|PhyRPR: æ— éœ€è®­ç»ƒçš„ç‰©ç†çº¦æŸè§†é¢‘ç”Ÿæˆ|Yibo Zhao, Hengjia Li, Xiaofei He, Boxi Wu|<https://arxiv.org/pdf/2601.09255v1>|æ— |
|ğŸ†• å‘å¸ƒ|Architecture inside the mirage: evaluating generative image models on architectural style, elements, and typologies|æµ·å¸‚èœƒæ¥¼ä¸­çš„å»ºç­‘ï¼šè¯„ä¼°ç”Ÿæˆå¼å›¾åƒæ¨¡å‹åœ¨å»ºç­‘é£æ ¼ã€å…ƒç´ å’Œç±»å‹å­¦ä¸Šçš„è¡¨ç°|Jamie Magrill, Leah Gornstein, Sandra Seekins, Barry Magrill|<https://arxiv.org/pdf/2601.09169v1>|æ— |


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MAD: Motion Appearance Decoupling for efficient Driving World Models|MADï¼šç”¨äºé«˜æ•ˆDriving World Modelsçš„Motion Appearance Decoupling|Ahmad Rahimi, Valentin Gerard, Eloi Zablocki, Matthieu Cord, Alexandre Alahi|<https://arxiv.org/pdf/2601.09452v1>|[ä»£ç ](https://vita-epfl.github.io/MAD-World-Model); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|TeleMem: Building Long-Term and Multimodal Memory for Agentic AI|TeleMemï¼šä¸º Agentic AI æ„å»ºé•¿æœŸå’Œå¤šæ¨¡æ€è®°å¿†|Chunliang Chen, Ming Guan, Xiao Lin, Jiaxu Li, Qiyi Wang, Xiangyu Chen, Jixiang Luo, Changzhi Sun .etc.|<https://arxiv.org/pdf/2601.06037v2>|æ— |
|ğŸ†• å‘å¸ƒ|A$^2$TG: Adaptive Anisotropic Textured Gaussians for Efficient 3D Scene Representation|A$^2$TG: ç”¨äºé«˜æ•ˆ3Dåœºæ™¯è¡¨ç¤ºçš„è‡ªé€‚åº”å„å‘å¼‚æ€§çº¹ç†é«˜æ–¯|Sheng-Chi Hsu, Ting-Yu Yen, Shih-Hsuan Hung, Hung-Kuo Chu|<https://arxiv.org/pdf/2601.09243v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Affostruction: 3D Affordance Grounding with Generative Reconstruction|Affostruction: åŸºäºç”Ÿæˆé‡å»ºçš„ 3D Affordance Grounding|Chunghyun Park, Seunghyeon Lee, Minsu Cho|<https://arxiv.org/pdf/2601.09211v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Tuning-free Visual Effect Transfer across Videos|[ç¿»è¯‘å¤±è´¥] Tuning-free Visual Effect Transfer across Videos|Maxwell Jones, Rameen Abdal, Or Patashnik, Ruslan Salakhutdinov, Sergey Tulyakov, Jun-Yan Zhu, Kuan-Chieh Jackson Wang|<https://arxiv.org/pdf/2601.07833v3>|[ä»£ç ](https://tuningfreevisualeffects-maker.github.io/Tuning-free-Visual-Effect-Transfer-across-Videos-Project-Page); åˆ†æå¤±è´¥|


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SCE-SLAM: Scale-Consistent Monocular SLAM via Scene Coordinate Embeddings|SCE-SLAM: é€šè¿‡åœºæ™¯åæ ‡åµŒå…¥å®ç°å°ºåº¦ä¸€è‡´çš„å•ç›®SLAM|Yuchen Wu, Jiahe Li, Xiaohan Yu, Lina Yu, Jin Zheng, Xiao Bai|<https://arxiv.org/pdf/2601.09665v1>|æ— |
|ğŸ†• å‘å¸ƒ|V-DPM: 4D Video Reconstruction with Dynamic Point Maps|V-DPM: ä½¿ç”¨åŠ¨æ€ç‚¹å›¾çš„4Dè§†é¢‘é‡å»º|Edgar Sucar, Eldar Insafutdinov, Zihang Lai, Andrea Vedaldi|<https://arxiv.org/pdf/2601.09499v1>|åˆ†æå¤±è´¥|


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Self-Supervised Animal Identification for Long Videos|é¢å‘é•¿è§†é¢‘çš„è‡ªç›‘ç£åŠ¨ç‰©è¯†åˆ«|Xuyang Fang, Sion Hannuna, Edwin Simpson, Neill Campbell|<https://arxiv.org/pdf/2601.09663v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|See More, Store Less: Memory-Efficient Resolution for Video Moment Retrieval|[ç¿»è¯‘å¤±è´¥] See More, Store Less: Memory-Efficient Resolution for Video Moment Retrieval|Mingyu Jeon, Sungjin Han, Jinkwon Hwang, Minchol Kwon, Jonghee Kim, Junyeong Kim|<https://arxiv.org/pdf/2601.09350v1>|æ— |
|ğŸ“ æ›´æ–°|SlumpGuard: An AI-Powered Real-Time System for Automated Concrete Slump Prediction via Video Analysis|SlumpGuardï¼šä¸€ç§åŸºäºè§†é¢‘åˆ†æã€åˆ©ç”¨AIé©±åŠ¨çš„å®æ—¶æ··å‡åœŸSlumpè‡ªåŠ¨é¢„æµ‹ç³»ç»Ÿ|Youngmin Kim, Giyeong Oh, Kwangsoo Youm, Youngjae Yu|<https://arxiv.org/pdf/2507.10171v4>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Point Tracking as a Temporal Cue for Robust Myocardial Segmentation in Echocardiography Videos|ç‚¹è·Ÿè¸ªä½œä¸ºè¶…å£°å¿ƒåŠ¨å›¾è§†é¢‘ä¸­é²æ£’å¿ƒè‚Œåˆ†å‰²çš„æ—¶é—´çº¿ç´¢|Bahar Khodabakhshian, Nima Hashemi, Armin Saadat, Zahra Gholami, In-Chang Hwang, Samira Sojoudi, Christina Luong, Purang Abolmaesumi .etc.|<https://arxiv.org/pdf/2601.09207v1>|[ä»£ç ](https://github.com/DeepRCL/PointSeg.)|
|ğŸ“ æ›´æ–°|Video Prediction Transformers without Recurrence or Convolution|æ— å¾ªç¯æˆ–å·ç§¯çš„è§†é¢‘é¢„æµ‹ Transformers|Yujin Tang, Lu Qi, Xiangtai Li, Chao Ma, Ming-Hsuan Yang|<https://arxiv.org/pdf/2410.04733v4>|[ä»£ç ](https://github.com/yyyujintang/PredFormer.)|


### è§†é¢‘ç›®æ ‡è·Ÿè¸ª (Video Object Tracking)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SAM3-DMS: Decoupled Memory Selection for Multi-target Video Segmentation of SAM3|SAM3-DMS: ç”¨äºSAM3å¤šç›®æ ‡è§†é¢‘åˆ†å‰²çš„è§£è€¦è®°å¿†é€‰æ‹©|Ruiqi Shen, Chang Liu, Henghui Ding|<https://arxiv.org/pdf/2601.09699v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|OpenVoxel: Training-Free Grouping and Captioning Voxels for Open-Vocabulary 3D Scene Understanding|OpenVoxelï¼šç”¨äºOpen-Vocabulary 3Dåœºæ™¯ç†è§£çš„å…è®­ç»ƒä½“ç´ åˆ†ç»„ä¸æè¿°|Sheng-Yu Huang, Jaesung Choe, Yu-Chiang Frank Wang, Cheng Sun|<https://arxiv.org/pdf/2601.09575v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|SPOT!: Map-Guided LLM Agent for Unsupervised Multi-CCTV Dynamic Object Tracking|SPOT!ï¼šé¢å‘æ— ç›‘ç£å¤šCCTVåŠ¨æ€ç›®æ ‡è·Ÿè¸ªçš„Map-Guided LLM Agent|Yujin Roh, Inho Jake Park, Chigon Hwang|<https://arxiv.org/pdf/2512.20975v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|MoCha:End-to-End Video Character Replacement without Structural Guidance|MoChaï¼šæ— éœ€ç»“æ„æŒ‡å¯¼çš„ç«¯åˆ°ç«¯è§†é¢‘è§’è‰²æ›¿æ¢|Zhengbo Xu, Jie Ma, Ziheng Wang, Zhan Peng, Jun Liang, Jing Li|<https://arxiv.org/pdf/2601.08587v2>|æ— |


### æ—¶åºå»ºæ¨¡ä¸é¢„æµ‹ (Temporal Modeling & Prediction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Toward Understanding Unlearning Difficulty: A Mechanistic Perspective and Circuit-Guided Difficulty Metric|è¿ˆå‘ç†è§£é—å¿˜éš¾åº¦ï¼šæœºåˆ¶è§†è§’ä¸ç”µè·¯å¼•å¯¼çš„éš¾åº¦åº¦é‡|Jiali Cheng, Ziheng Chen, Chirag Agarwal, Hadi Amiri|<https://arxiv.org/pdf/2601.09624v1>|ä»æœºåˆ¶è§†è§’ç ”ç©¶æœºå™¨é—å¿˜éš¾åº¦ï¼Œæå‡ºåŸºäºæ¨¡å‹ç”µè·¯çš„éš¾åº¦åº¦é‡æ–¹æ³•ã€‚|


### åŠ¨ä½œè¯†åˆ«ä¸ç†è§£ (Action Recognition & Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|egoEMOTION: Egocentric Vision and Physiological Signals for Emotion and Personality Recognition in Real-World Tasks|egoEMOTIONï¼šç”¨äºçœŸå®ä¸–ç•Œä»»åŠ¡ä¸­æƒ…ç»ªå’Œäººæ ¼è¯†åˆ«çš„è‡ªæˆ‘ä¸­å¿ƒè§†è§‰ä¸ç”Ÿç†ä¿¡å·|Matthias Jammot, BjÃ¶rn Braun, Paul Streli, Rafael Wampfler, Christian Holz|<https://arxiv.org/pdf/2510.22129v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Video Joint-Embedding Predictive Architectures for Facial Expression Recognition|ç”¨äºé¢éƒ¨è¡¨æƒ…è¯†åˆ«çš„Video Joint-Embedding Predictive Architectures|Lennart Eing, Cristina Luna-JimÃ©nez, Silvan Mertes, Elisabeth AndrÃ©|<https://arxiv.org/pdf/2601.09524v1>|[ä»£ç ](https://github.com/lennarteingunia/vjepa-for-fer.)|


## è‡ªç›‘ç£ä¸è¡¨å¾å­¦ä¹  (Self-supervised & Representation Learning)


### å¯¹æ¯”å­¦ä¹ æ–¹æ³• (Contrastive Learning Methods)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Prototypical Contrastive Learning-based CLIP Fine-tuning for Object Re-identification|åŸºäºåŸå‹å¯¹æ¯”å­¦ä¹ çš„CLIPå¾®è°ƒç”¨äºç›®æ ‡é‡è¯†åˆ«|Jiachen Li, Xiaojin Gong|<https://arxiv.org/pdf/2310.17218v3>|[ä»£ç ](https://github.com/RikoLi/PCL-CLIP.); åˆ†æå¤±è´¥|


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning|Fast-ThinkActï¼šé€šè¿‡å¯è¯­è¨€åŒ–æ½œåœ¨è§„åˆ’å®ç°é«˜æ•ˆçš„Vision-Language-Actionæ¨ç†|Chi-Pin Huang, Yunze Man, Zhiding Yu, Min-Hung Chen, Jan Kautz, Yu-Chiang Frank Wang, Fu-En Yang|<https://arxiv.org/pdf/2601.09708v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Frequency Error-Guided Under-sampling Optimization for Multi-Contrast MRI Reconstruction|[ç¿»è¯‘å¤±è´¥] Frequency Error-Guided Under-sampling Optimization for Multi-Contrast MRI Reconstruction|Xinming Fang, Chaoyan Huang, Juncheng Li, Jun Wang, Jun Shi, Guixu Zhang|<https://arxiv.org/pdf/2601.09316v1>|[ä»£ç ](https://github.com/fangxinming/JUF-MRI.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Unified Multimodal Brain Decoding via Cross-Subject Soft-ROI Fusion|é€šè¿‡è·¨å—è¯•è€… Soft-ROI èåˆå®ç°ç»Ÿä¸€çš„å¤šæ¨¡æ€è„‘è§£ç |Xuanyu Hu|<https://arxiv.org/pdf/2512.20249v2>|åˆ†æå¤±è´¥|


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Deep Hybrid Model for Region of Interest Detection in Omnidirectional Videos|ç”¨äºOmnidirectional Videosä¸­Region of Interest Detectionçš„Deep Hybrid Model|Sana Alamgeer, Mylene Farias, Marcelo Carvalho|<https://arxiv.org/pdf/2511.18856v3>|æ— |
|ğŸ“ æ›´æ–°|Uncovering Intrinsic Capabilities: A Paradigm for Data Curation in Vision-Language Models|æ­ç¤ºå†…åœ¨èƒ½åŠ›ï¼šVision-Language Modelsä¸­æ•°æ®ç­–åˆ’çš„ä¸€ç§èŒƒå¼|Junjie Li, Ziao Wang, Jianghong Ma, Xiaofeng Zhang|<https://arxiv.org/pdf/2510.00040v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|ProfVLM: A Lightweight Video-Language Model for Multi-View Proficiency Estimation|ProfVLM: ç”¨äºå¤šè§†è§’ç†Ÿç»ƒåº¦è¯„ä¼°çš„è½»é‡çº§ Video-Language Model|Edoardo Bianchi, Jacopo Staiano, Antonio Liotta|<https://arxiv.org/pdf/2509.26278v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Spectral Complex Autoencoder Pruning: A Fidelity-Guided Criterion for Extreme Structured Channel Compression|Spectral Complex Autoencoder Pruning: ä¸€ç§ç”¨äºæç«¯ç»“æ„åŒ–é€šé“å‹ç¼©çš„ä¿çœŸåº¦å¼•å¯¼å‡†åˆ™|Wei Liu, Xing Deng, Haijian Shao, Yingtao Jiang|<https://arxiv.org/pdf/2601.09352v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|GaussianFluent: Gaussian Simulation for Dynamic Scenes with Mixed Materials|GaussianFluent: æ··åˆææ–™åŠ¨æ€åœºæ™¯çš„ Gaussian Simulation|Bei Huang, Yixin Chen, Ruijie Lu, Gang Zeng, Hongbin Zha, Yuru Pei, Siyuan Huang|<https://arxiv.org/pdf/2601.09265v1>|æ— |
|ğŸ†• å‘å¸ƒ|BrainSegNet: A Novel Framework for Whole-Brain MRI Parcellation Enhanced by Large Models|BrainSegNet: ä¸€ç§ç”±å¤§æ¨¡å‹å¢å¼ºçš„å…¨è„‘MRIåˆ†å‰²æ–°æ¡†æ¶|Yucheng Li, Xiaofan Wang, Junyi Wang, Yijie Li, Xi Zhu, Mubai Du, Dian Sheng, Wei Zhang .etc.|<https://arxiv.org/pdf/2601.09263v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Pairing-free Group-level Knowledge Distillation for Robust Gastrointestinal Lesion Classification in White-Light Endoscopy|æ— é…å¯¹ç»„çº§çŸ¥è¯†è’¸é¦ç”¨äºç™½å…‰å†…é•œä¸­ç¨³å¥çš„èƒƒè‚ é“ç—…å˜åˆ†ç±»|Qiang Hu, Qimei Wang, Yingjie Guo, Qiang Li, Zhiwei Wang|<https://arxiv.org/pdf/2601.09209v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|From Snow to Rain: Evaluating Robustness, Calibration, and Complexity of Model-Based Robust Training|ä»é›ªåˆ°é›¨ï¼šè¯„ä¼°åŸºäºæ¨¡å‹çš„é²æ£’è®­ç»ƒçš„é²æ£’æ€§ã€æ ¡å‡†å’Œå¤æ‚æ€§|JosuÃ© MartÃ­nez-MartÃ­nez, Olivia Brown, Giselle Zeno, Pooya Khorrami, Rajmonda Caceres|<https://arxiv.org/pdf/2601.09153v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|GeoMotionGPT: Geometry-Aligned Motion Understanding with Large Language Models|[ç¿»è¯‘å¤±è´¥] GeoMotionGPT: Geometry-Aligned Motion Understanding with Large Language Models|Zhankai Ye, Bofan Li, Yukai Jin, Shuoqiu Li, Wei Wang, Yanfu Zhang, Shangqian Gao, Xin Liu|<https://arxiv.org/pdf/2601.07632v2>|åˆ†æå¤±è´¥|


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|GRCF: Two-Stage Groupwise Ranking and Calibration Framework for Multimodal Sentiment Analysis|GRCFï¼šç”¨äºMultimodal Sentiment Analysisçš„ä¸¤é˜¶æ®µGroupwise Rankingä¸Calibrationæ¡†æ¶|Manning Gao, Leheng Zhang, Shiqin Han, Haifeng Hu, Yuncheng Jiang, Sijie Mai|<https://arxiv.org/pdf/2601.09606v1>|æ— |
|ğŸ†• å‘å¸ƒ|Iterative Differential Entropy Minimization (IDEM) method for fine rigid pairwise 3D Point Cloud Registration: A Focus on the Metric|ç”¨äºç²¾ç»†åˆšä½“æˆå¯¹ 3D Point Cloud Registration çš„è¿­ä»£ Differential Entropy Minimization (IDEM) æ–¹æ³•ï¼šèšç„¦äº Metric|Emmanuele Barberi, Felice Sfravara, Filippo Cucinotta|<https://arxiv.org/pdf/2601.09601v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|AGE-US: automated gestational age estimation based on fetal ultrasound images|AGE-US: åŸºäºèƒå„¿è¶…å£°å›¾åƒçš„è‡ªåŠ¨èƒé¾„ä¼°è®¡|CÃ©sar DÃ­az-Parga, Marta NuÃ±ez-Garcia, Maria J. Carreira, Gabriel Bernardino, NicolÃ¡s Vila-Blanco|<https://arxiv.org/pdf/2506.16256v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Positional Embedding-Aware Activations|[ç¿»è¯‘å¤±è´¥] Positional Embedding-Aware Activations|Kathan Shah, Chawin Sitawarin|<https://arxiv.org/pdf/2306.15242v2>|æ— |
|ğŸ†• å‘å¸ƒ|Integrating Diverse Assignment Strategies into DETRs|å°†å¤šæ ·åŒ–åˆ†é…ç­–ç•¥é›†æˆåˆ°DETRsä¸­|Yiwei Zhang, Jin Gao, Hanshi Wang, Fudong Ge, Guan Luo, Weiming Hu, Zhipeng Zhang|<https://arxiv.org/pdf/2601.09247v1>|æ— |
|ğŸ†• å‘å¸ƒ|CLIDD: Cross-Layer Independent Deformable Description for Efficient and Discriminative Local Feature Representation|CLIDD: ç”¨äºé«˜æ•ˆä¸”å…·æœ‰åˆ¤åˆ«åŠ›çš„å±€éƒ¨ç‰¹å¾è¡¨ç¤ºçš„è·¨å±‚ç‹¬ç«‹å¯å˜å½¢æè¿°|Haodi Yao, Fenghua He, Ning Hao, Yao Su|<https://arxiv.org/pdf/2601.09230v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|SPOT-Face: Forensic Face Identification using Attention Guided Optimal Transport|SPOT-Face: ä½¿ç”¨æ³¨æ„åŠ›å¼•å¯¼æœ€ä¼˜ä¼ è¾“çš„å–è¯äººè„¸è¯†åˆ«|Ravi Shankar Prasad, Dinesh Singh|<https://arxiv.org/pdf/2601.09229v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|N-EIoU-YOLOv9: A Signal-Aware Bounding Box Regression Loss for Lightweight Mobile Detection of Rice Leaf Diseases|N-EIoU-YOLOv9ï¼šä¸€ç§ç”¨äºæ°´ç¨»ç—…å®³è½»é‡åŒ–ç§»åŠ¨æ£€æµ‹çš„ä¿¡å·æ„ŸçŸ¥è¾¹ç•Œæ¡†å›å½’æŸå¤±|Dung Ta Nguyen Duc, Thanh Bui Dang, Hoang Le Minh, Tung Nguyen Viet, Huong Nguyen Thanh, Dong Trinh Cong|<https://arxiv.org/pdf/2601.09170v1>|åˆ†æå¤±è´¥|


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### ä¸ç¡®å®šæ€§é‡åŒ– (Uncertainty Quantification)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Class Adaptive Conformal Training|[ç¿»è¯‘å¤±è´¥] Class Adaptive Conformal Training|Badr-Eddine Marani, Julio Silva-Rodriguez, Ismail Ben Ayed, Maria Vakalopoulou, Stergios Christodoulidis, Jose Dolz|<https://arxiv.org/pdf/2601.09522v1>|åˆ†æå¤±è´¥|


### åˆ†å¸ƒå¤–æ³›åŒ– (Out-of-distribution Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Beyond Seen Bounds: Class-Centric Polarization for Single-Domain Generalized Deep Metric Learning|è¶…è¶Šå¯è§è¾¹ç•Œï¼šé¢å‘å•åŸŸå¹¿ä¹‰æ·±åº¦åº¦é‡å­¦ä¹ çš„ä»¥ç±»ä¸ºä¸­å¿ƒæåŒ–|Xin Yuan, Meiqi Wan, Wei Liu, Xin Xu, Zheng Wang|<https://arxiv.org/pdf/2601.09121v1>|åˆ†æå¤±è´¥|


### å¯¹æŠ—é²æ£’æ€§ (Adversarial Robustness)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Boosting Adversarial Transferability with Low-Cost Optimization via Maximin Expected Flatness|é€šè¿‡æå¤§æå°æœŸæœ›å¹³å¦åº¦åˆ©ç”¨ä½æˆæœ¬ä¼˜åŒ–æå‡å¯¹æŠ—è¿ç§»æ€§|Chunlin Qiu, Ang Li, Yiheng Duan, Shenyi Zhang, Yuanjie Zhang, Lingchen Zhao, Qian Wang|<https://arxiv.org/pdf/2405.16181v3>|[ä»£ç ](https://github.com/SignedQiu/MEFAttack.)|


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### å°æ ·æœ¬å­¦ä¹  (Few-shot Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|LiteEmbed: Adapting CLIP to Rare Classes|LiteEmbedï¼šå°†CLIPé€‚åº”äºç¨€æœ‰ç±»åˆ«|Aishwarya Agarwal, Srikrishna Karanam, Vineet Gandhi|<https://arxiv.org/pdf/2601.09661v1>|æ— |


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|A Multi-Stage Deep Learning Framework with PKCP-MixUp Augmentation for Pediatric Liver Tumor Diagnosis Using Multi-Phase Contrast-Enhanced CT|ä¸€ç§ç»“åˆPKCP-MixUpæ•°æ®å¢å¼ºçš„å¤šé˜¶æ®µæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºåŸºäºå¤šæœŸå¯¹æ¯”å¢å¼ºCTçš„å„¿ç«¥è‚è‚¿ç˜¤è¯Šæ–­|Wanqi Wang, Chun Yang, Jianbo Shao, Yaokai Zhang, Xuehua Peng, Jin Sun, Chao Xiong, Long Lu .etc.|<https://arxiv.org/pdf/2511.19478v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Radiomics-Integrated Deep Learning with Hierarchical Loss for Osteosarcoma Histology Classification|èåˆRadiomicsçš„åˆ†å±‚æŸå¤±æ·±åº¦å­¦ä¹ ç”¨äºéª¨è‚‰ç˜¤ç»„ç»‡å­¦åˆ†ç±»|Yaxi Chen, Zi Ye, Shaheer U. Saeed, Oliver Yu, Simin Ni, Jie Huang, Yipeng Hu|<https://arxiv.org/pdf/2601.09416v1>|[ä»£ç ](https://github.com/YaxiiC/RadiomicsOS.git.)|
|ğŸ“ æ›´æ–°|Divergence-Based Similarity Function for Multi-View Contrastive Learning|åŸºäºæ•£åº¦çš„å¤šè§†å›¾å¯¹æ¯”å­¦ä¹ ç›¸ä¼¼åº¦å‡½æ•°|Jae Hyoung Jeon, Cheolsu Lim, Myungjoo Kang|<https://arxiv.org/pdf/2507.06560v4>|æ— |
|ğŸ“ æ›´æ–°|Self-Paced Learning for Images of Antinuclear Antibodies|æŠ—æ ¸æŠ—ä½“å›¾åƒçš„è‡ªæ­¥å­¦ä¹ |Yiyang Jiang, Guangwu Qian, Jiaxin Wu, Qi Huang, Qing Li, Yongkang Wu, Xiao-Yong Wei|<https://arxiv.org/pdf/2511.21519v2>|[ä»£ç ](https://github.com/fletcherjiang/ANA-SelfPacedLearning.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|An Attention Infused Deep Learning System with Grad-CAM Visualization for Early Screening of Glaucoma|ä¸€ç§èåˆæ³¨æ„åŠ›æœºåˆ¶å¹¶é‡‡ç”¨Grad-CAMå¯è§†åŒ–çš„æ·±åº¦å­¦ä¹ ç³»ç»Ÿï¼Œç”¨äºé’å…‰çœ¼çš„æ—©æœŸç­›æŸ¥|Ramanathan Swaminathan|<https://arxiv.org/pdf/2505.17808v2>|åˆ†æå¤±è´¥|


## å…·èº«æ™ºèƒ½ä¸äº¤äº’è§†è§‰ (Embodied Intelligence & Interactive Vision)


### è§†è§‰å¯¼èˆªä¸è·¯å¾„è§„åˆ’ (Visual Navigation & Path Planning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Towards Open Environments and Instructions: General Vision-Language Navigation via Fast-Slow Interactive Reasoning|[ç¿»è¯‘å¤±è´¥] Towards Open Environments and Instructions: General Vision-Language Navigation via Fast-Slow Interactive Reasoning|Yang Li, Aming Wu, Zihao Zhang, Yahong Han|<https://arxiv.org/pdf/2601.09111v1>|åˆ†æå¤±è´¥|


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Show, don't tell -- Providing Visual Error Feedback for Handwritten Documents|Show, don't tell â€”â€” ä¸ºæ‰‹å†™æ–‡æ¡£æä¾› Visual Error Feedback|Said Yasin, Torsten Zesch|<https://arxiv.org/pdf/2601.09586v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Hot-Start from Pixels: Low-Resolution Visual Tokens for Chinese Language Modeling|ä»åƒç´ çƒ­å¯åŠ¨ï¼šç”¨äºä¸­æ–‡è¯­è¨€å»ºæ¨¡çš„ä½åˆ†è¾¨ç‡ Visual Tokens|Shuyang Xiang, Hao Guan|<https://arxiv.org/pdf/2601.09566v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Improved Segmentation of Polyps and Visual Explainability Analysis|æ¯è‚‰åˆ†å‰²çš„æ”¹è¿›ä¸è§†è§‰å¯è§£é‡Šæ€§åˆ†æ|Akwasi Asare, Thanh-Huy Nguyen, Ulas Bagci|<https://arxiv.org/pdf/2509.18159v6>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Hybrid guided variational autoencoder for visual place recognition|æ··åˆå¼•å¯¼å˜åˆ†è‡ªç¼–ç å™¨ç”¨äºè§†è§‰ä½ç½®è¯†åˆ«|Ni Wang, Zihan You, Emre Neftci, Thorben Schoepe|<https://arxiv.org/pdf/2601.09248v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|SkinFlow: Efficient Information Transmission for Open Dermatological Diagnosis via Dynamic Visual Encoding and Staged RL|SkinFlowï¼šé€šè¿‡åŠ¨æ€è§†è§‰ç¼–ç å’Œåˆ†é˜¶æ®µRLå®ç°å¼€æ”¾çš®è‚¤è¯Šæ–­çš„é«˜æ•ˆä¿¡æ¯ä¼ è¾“|Lijun Liu, Linwei Chen, Zhishou Zhang, Meng Tian, Hengfu Cui, Ruiyang Li, Zhaocheng Liu, Qiang Ju .etc.|<https://arxiv.org/pdf/2601.09136v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Exploring Reliable Spatiotemporal Dependencies for Efficient Visual Tracking|æ¢ç´¢å¯é çš„æ—¶ç©ºä¾èµ–ä»¥å®ç°é«˜æ•ˆè§†è§‰è·Ÿè¸ª|Junze Shi, Yang Yu, Jian Shi, Haibo Luo|<https://arxiv.org/pdf/2601.09078v1>|æ— |


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|BARL: Bilateral Alignment in Representation and Label Spaces for Semi-Supervised Volumetric Medical Image Segmentation|BARL: è¡¨å¾ç©ºé—´ä¸æ ‡ç­¾ç©ºé—´çš„åŒè¾¹å¯¹é½ç”¨äºåŠç›‘ç£ä½“ç§¯åŒ»å­¦å›¾åƒåˆ†å‰²|Shujian Gao, Yuan Wang, Zekuan Yu|<https://arxiv.org/pdf/2510.16863v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Fair Foundation Models for Medical Image Analysis: Challenges and Perspectives|é¢å‘åŒ»å­¦å›¾åƒåˆ†æçš„å…¬å¹³åŸºç¡€æ¨¡å‹ï¼šæŒ‘æˆ˜ä¸å±•æœ›|Dilermando Queiroz, Anderson Carlos, AndrÃ© Anjos, Lilian Berton|<https://arxiv.org/pdf/2502.16841v2>|æ— |
|ğŸ“ æ›´æ–°|LVLM-Aware Multimodal Retrieval for RAG-Based Medical Diagnosis with General-Purpose Models|é¢å‘åŸºäºRAGçš„é€šç”¨æ¨¡å‹åŒ»ç–—è¯Šæ–­çš„LVLMæ„ŸçŸ¥å¤šæ¨¡æ€æ£€ç´¢|Nir Mazor, Tom Hope|<https://arxiv.org/pdf/2508.17394v5>|[ä»£ç ](https://github.com/Nirmaz/CLARE.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Comprehensive language-image pre-training for 3D medical image understanding|é¢å‘3DåŒ»å­¦å›¾åƒç†è§£çš„å…¨é¢è¯­è¨€-å›¾åƒé¢„è®­ç»ƒ|Tassilo Wald, Ibrahim Ethem Hamamci, Yuan Gao, Sam Bond-Taylor, Harshita Sharma, Maximilian Ilse, Cynthia Lo, Olesya Melnichenko .etc.|<https://arxiv.org/pdf/2510.15042v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Magnifying change: Rapid burn scar mapping with multi-resolution, multi-source satellite imagery|æ”¾å¤§å˜åŒ–ï¼šåˆ©ç”¨å¤šåˆ†è¾¨ç‡ã€å¤šæºå«æ˜Ÿå½±åƒè¿›è¡Œå¿«é€Ÿçƒ§ä¼¤ç–¤ç—•åˆ¶å›¾|Maria Sdraka, Dimitrios Michail, Ioannis Papoutsis|<https://arxiv.org/pdf/2601.09262v1>|[ä»£ç ](https://github.com/Orion-AI-Lab/BAM-MRCD.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|A Multi-Mode Structured Light 3D Imaging System with Multi-Source Information Fusion for Underwater Pipeline Detection|ä¸€ç§ç”¨äºæ°´ä¸‹ç®¡é“æ£€æµ‹çš„å¤šæºä¿¡æ¯èåˆå¤šæ¨¡å¼ç»“æ„å…‰3Dæˆåƒç³»ç»Ÿ|Qinghan Hu, Haijiang Zhu, Na Sun, Lei Chen, Zhengqiang Fan, Zhiqing Li|<https://arxiv.org/pdf/2512.11354v2>|æ— |
|ğŸ†• å‘å¸ƒ|Knowledge-Embedded and Hypernetwork-Guided Few-Shot Substation Meter Defect Image Generation Method|[ç¿»è¯‘å¤±è´¥] Knowledge-Embedded and Hypernetwork-Guided Few-Shot Substation Meter Defect Image Generation Method|Jackie Alex, Justin Petter|<https://arxiv.org/pdf/2601.09238v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|From Performance to Practice: Knowledge-Distilled Segmentator for On-Premises Clinical Workflows|ä»æ€§èƒ½åˆ°å®è·µï¼šç”¨äºæœ¬åœ°ä¸´åºŠå·¥ä½œæµçš„çŸ¥è¯†è’¸é¦åˆ†å‰²å™¨|Qizhen Lan, Aaron Choi, Jun Ma, Bo Wang, Zhaogming Zhao, Xiaoqian Jiang, Yu-Chun Hsu|<https://arxiv.org/pdf/2601.09191v1>|æ— |
|ğŸ“ æ›´æ–°|Weakly Supervised Concept Learning with Class-Level Priors for Interpretable Medical Diagnosis|åŸºäºç±»çº§å…ˆéªŒçš„å¯è§£é‡ŠåŒ»å­¦è¯Šæ–­å¼±ç›‘ç£æ¦‚å¿µå­¦ä¹ |Md Nahiduzzaman, Steven Korevaar, Alireza Bab-Hadiashar, Ruwan Tennakoon|<https://arxiv.org/pdf/2511.01131v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|M3CoTBench: Benchmark Chain-of-Thought of MLLMs in Medical Image Understanding|M3CoTBench: åŒ»å­¦å›¾åƒç†è§£ä¸­MLLMsæ€ç»´é“¾çš„åŸºå‡†æµ‹è¯•|Juntao Jiang, Jiangning Zhang, Yali Bi, Jinsheng Bai, Weixuan Liu, Weiwei Jin, Zhucun Xue, Yong Liu .etc.|<https://arxiv.org/pdf/2601.08758v2>|[ä»£ç ](https://juntaojianggavin.github.io/projects)|
|ğŸ“ æ›´æ–°|MedicalNarratives: Connecting Medical Vision and Language with Localized Narratives|MedicalNarratives: åˆ©ç”¨ Localized Narratives è¿æ¥ Medical Vision å’Œ Language|Wisdom O. Ikezogwo, Kevin Zhang, Mehmet Saygin Seyfioglu, Fatemeh Ghezloo, Linda Shapiro, Ranjay Krishna|<https://arxiv.org/pdf/2501.04184v3>|æ— |
|ğŸ†• å‘å¸ƒ|POWDR: Pathology-preserving Outpainting with Wavelet Diffusion for 3D MRI|POWDRï¼šåŸºäºå°æ³¢æ‰©æ•£çš„3D MRIç—…ç†ä¿æŒå¤–ç»˜|Fei Tan, Ashok Vardhan Addala, Bruno Astuto Arouche Nunes, Xucheng Zhu, Ravi Soni|<https://arxiv.org/pdf/2601.09044v1>|åˆ†æå¤±è´¥|


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Hierarchical Fusion of Local and Global Visual Features with Mixture-of-Experts for Remote Sensing Image Scene Classification|åŸºäºæ··åˆä¸“å®¶çš„å±€éƒ¨ä¸å…¨å±€è§†è§‰ç‰¹å¾åˆ†å±‚èåˆç”¨äºé¥æ„Ÿå›¾åƒåœºæ™¯åˆ†ç±»|Yuanhao Tang, Xuechao Zou, Zhengpei Hu, Junliang Xing, Chengkun Zhang, Jianqiang Huang|<https://arxiv.org/pdf/2510.27155v2>|åˆ†æå¤±è´¥|


### å·¥ä¸šè§†è§‰æ£€æµ‹ (Industrial Visual Inspection)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SSVP: Synergistic Semantic-Visual Prompting for Industrial Zero-Shot Anomaly Detection|SSVP: ç”¨äºå·¥ä¸šé›¶æ ·æœ¬å¼‚å¸¸æ£€æµ‹çš„ååŒè¯­ä¹‰-è§†è§‰ Prompting|Chenhao Fu, Han Fang, Xiuzheng Zheng, Wenbo Wei, Yonghua Li, Hao Sun, Xuelong Li|<https://arxiv.org/pdf/2601.09147v1>|æ— |
|ğŸ†• å‘å¸ƒ|LPCAN: Lightweight Pyramid Cross-Attention Network for Rail Surface Defect Detection Using RGB-D Data|LPCAN: åŸºäºRGB-Dæ•°æ®çš„è½»é‡çº§é‡‘å­—å¡”äº¤å‰æ³¨æ„åŠ›ç½‘ç»œç”¨äºé“è·¯è¡¨é¢ç¼ºé™·æ£€æµ‹|Jackie Alex, Guoqiang Huan|<https://arxiv.org/pdf/2601.09118v1>|æ— |


## æ–°å…´ç†è®ºä¸è·¨å­¦ç§‘æ–¹å‘ (Emerging Theory & Interdisciplinary Directions)


### ç¥ç»-ç¬¦å·è§†è§‰ (Neuro-symbolic Vision)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Bipartite Mode Matching for Vision Training Set Search from a Hierarchical Data Server|ç”¨äºä» Hierarchical Data Server ä¸­è¿›è¡Œ Vision Training Set Search çš„äºŒåˆ†æ¨¡å¼åŒ¹é…|Yue Yao, Ruining Yang, Tom Gedeon|<https://arxiv.org/pdf/2601.09531v1>|æ— |
|ğŸ“ æ›´æ–°|Simulated Ensemble Attack: Transferring Jailbreaks Across Fine-tuned Vision-Language Models|[ç¿»è¯‘å¤±è´¥] Simulated Ensemble Attack: Transferring Jailbreaks Across Fine-tuned Vision-Language Models|Ruofan Wang, Xin Wang, Yang Yao, Juncheng Li, Xuan Tong, Xingjun Ma|<https://arxiv.org/pdf/2508.01741v3>|åˆ†æå¤±è´¥|


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Know Yourself Better: Diverse Object-Related Features Improve Open Set Recognition|Know Yourself Better: å¤šæ ·åŒ–çš„ Object-Related Features æå‡ Open Set Recognition|Jiawen Xu, Margret Keuper|<https://arxiv.org/pdf/2404.10370v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Hidden Monotonicity: Explaining Deep Neural Networks via their DC Decomposition|Hidden Monotonicity: é€šè¿‡ DC åˆ†è§£è§£é‡Š Deep Neural Networks|Jakob Paul Zimmermann, Georg Loho|<https://arxiv.org/pdf/2601.07700v2>|æ— |
|ğŸ†• å‘å¸ƒ|PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized GUI Agent with Long-Term User-Centric Records|PersonalAlignï¼šåŸºäºé•¿æœŸç”¨æˆ·ä¸­å¿ƒè®°å½•çš„ä¸ªæ€§åŒ–GUI Agentåˆ†å±‚éšå¼æ„å›¾å¯¹é½|Yibo Lyu, Gongwei Chen, Rui Shao, Weili Guan, Liqiang Nie|<https://arxiv.org/pdf/2601.09636v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Multimodal Signal Processing For Thermo-Visible-Lidar Fusion In Real-time 3D Semantic Mapping|ç”¨äºå®æ—¶3Dè¯­ä¹‰æ˜ å°„ä¸­çƒ­æˆåƒ-å¯è§å…‰-Lidarèåˆçš„å¤šæ¨¡æ€ä¿¡å·å¤„ç†|Jiajun Sun, Yangyi Ou, Haoyuan Zheng, Chao yang, Yue Ma|<https://arxiv.org/pdf/2601.09578v1>|åˆ†æå¤±è´¥|

