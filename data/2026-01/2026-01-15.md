## [UPDATED!] **2026-01-15** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Medical SAM3: A Foundation Model for Universal Prompt-Driven Medical Image Segmentation|Medical SAM3: ä¸€ç§é€šç”¨æç¤ºé©±åŠ¨çš„åŒ»å­¦å›¾åƒåˆ†å‰²åŸºç¡€æ¨¡å‹|Chongcong Jiang, Tianxingjian Ding, Chuhan Song, Jiachen Tu, Ziyang Yan, Yihua Shao, Zhenyi Wang, Yuzhang Shang .etc.|<https://arxiv.org/pdf/2601.10880v1>|[ä»£ç ](https://github.com/AIM-Research-Lab/Medical-SAM3.)|
|ğŸ“ æ›´æ–°|Zero-Shot Transfer Capabilities of the Sundial Foundation Model for Leaf Area Index Forecasting|Sundial åŸºç¡€æ¨¡å‹åœ¨å¶é¢ç§¯æŒ‡æ•°é¢„æµ‹ä¸­çš„ Zero-Shot è¿ç§»èƒ½åŠ›|Peining Zhang, Hongchen Qin, Haochen Zhang, Ziqi Guo, Guiling Wang, Jinbo Bi|<https://arxiv.org/pdf/2511.20004v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Evaluating Foundation Models' 3D Understanding Through Multi-View Correspondence Analysis|é€šè¿‡å¤šè§†è§’å¯¹åº”åˆ†æè¯„ä¼°åŸºç¡€æ¨¡å‹çš„3Dç†è§£èƒ½åŠ›|Valentina Lilova, Toyesh Chakravorty, Julian I. Bibo, Emma Boccaletti, Brandon Li, LÃ­via BaxovÃ¡, Cees G. M. Snoek, Mohammadreza Salehi|<https://arxiv.org/pdf/2512.11574v2>|[ä»£ç ](https://github.com/ToyeshC/open-hummingbird-3d-eval.)|
|ğŸ†• å‘å¸ƒ|See Less, Drive Better: Generalizable End-to-End Autonomous Driving via Foundation Models Stochastic Patch Selection|çœ‹å¾—æ›´å°‘ï¼Œå¼€å¾—æ›´å¥½ï¼šé€šè¿‡ Foundation Models éšæœº Patch Selection å®ç°å¯æ³›åŒ–çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶|Amir Mallak, Erfan Aasi, Shiva Sreeram, Tsun-Hsuan Wang, Daniela Rus, Alaa Maalouf|<https://arxiv.org/pdf/2601.10707v1>|æ— |
|ğŸ†• å‘å¸ƒ|Action100M: A Large-scale Video Action Dataset|Action100M: ä¸€ä¸ªå¤§è§„æ¨¡è§†é¢‘åŠ¨ä½œæ•°æ®é›†|Delong Chen, Tejaswi Kasarla, Yejin Bang, Mustafa Shukor, Willy Chung, Jade Yu, Allen Bolourchi, Theo Moutakanni .etc.|<https://arxiv.org/pdf/2601.10592v1>|æ— |
|ğŸ“ æ›´æ–°|Cross-Modal Fine-Tuning of 3D Convolutional Foundation Models for ADHD Classification with Low-Rank Adaptation|åŸºäºLow-Rank Adaptationçš„3Då·ç§¯åŸºç¡€æ¨¡å‹è·¨æ¨¡æ€å¾®è°ƒç”¨äºADHDåˆ†ç±»|Jyun-Ping Kao, Shinyeong Rho, Shahar Lazarev, Hyun-Hae Cho, Fangxu Xing, Taehoon Shin, C. -C. Jay Kuo, Jonghye Woo|<https://arxiv.org/pdf/2511.06163v2>|æ— |
|ğŸ†• å‘å¸ƒ|DR$^2$Seg: Decomposed Two-Stage Rollouts for Efficient Reasoning Segmentation in Multimodal Large Language Models|DR$^2$Seg: ç”¨äºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹é«˜æ•ˆæ¨ç†åˆ†å‰²çš„åˆ†è§£å¼ä¸¤é˜¶æ®µRollouts|Yulin He, Wei Chen, Zhikang Jian, Tianhang Guo, Wenjuan Zhou, Minglong Li|<https://arxiv.org/pdf/2601.09981v1>|æ— |


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|STEP3-VL-10B Technical Report|STEP3-VL-10B æŠ€æœ¯æŠ¥å‘Š|Ailin Huang, Chengyuan Yao, Chunrui Han, Fanqi Wan, Hangyu Guo, Haoran Lv, Hongyu Zhou, Jia Wang .etc.|<https://arxiv.org/pdf/2601.09668v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Handling Missing Modalities in Multimodal Survival Prediction for Non-Small Cell Lung Cancer|å¤„ç†éå°ç»†èƒè‚ºç™Œå¤šæ¨¡æ€ç”Ÿå­˜é¢„æµ‹ä¸­çš„ç¼ºå¤±æ¨¡æ€|Filippo Ruffini, Camillo Maria Caruso, Claudia Tacconi, Lorenzo Nibid, Francesca Miccolis, Marta Lovino, Carlo Greco, Edy Ippolito .etc.|<https://arxiv.org/pdf/2601.10386v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|VQ-Seg: Vector-Quantized Token Perturbation for Semi-Supervised Medical Image Segmentation|VQ-Seg: ç”¨äºåŠç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²çš„å‘é‡é‡åŒ–Tokenæ‰°åŠ¨|Sicheng Yang, Zhaohu Xing, Lei Zhu|<https://arxiv.org/pdf/2601.10124v1>|[ä»£ç ](https://github.com/script-Yang/VQ-Seg.)|
|ğŸ†• å‘å¸ƒ|V-Zero: Self-Improving Multimodal Reasoning with Zero Annotation|VV-Zero: é›¶æ ‡æ³¨ä¸‹çš„è‡ªæ”¹è¿›å¤šæ¨¡æ€æ¨ç†|Han Wang, Yi Yang, Jingyuan Hu, Minfeng Zhu, Wei Chen|<https://arxiv.org/pdf/2601.10094v1>|[ä»£ç ](https://github.com/SatonoDia/V-Zero); åˆ†æå¤±è´¥|


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Decorrelation Speeds Up Vision Transformers|å»ç›¸å…³åŠ é€Ÿ Vision Transformers|Kieran Carrigg, Rob van Gastel, Melda Yeghaian, Sander Dalm, Faysal Boughorbel, Marcel van Gerven|<https://arxiv.org/pdf/2510.14657v3>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|AgriFM: A Multi-source Temporal Remote Sensing Foundation Model for Agriculture Mapping|AgriFMï¼šç”¨äºå†œä¸šåˆ¶å›¾çš„å¤šæºæ—¶åºé¥æ„ŸåŸºç¡€æ¨¡å‹|Wenyuan Li, Shunlin Liang, Keyan Chen, Yongzhe Chen, Han Ma, Jianglei Xu, Yichuan Ma, Shikang Guan .etc.|<https://arxiv.org/pdf/2505.21357v3>|[ä»£ç ](https://github.com/flyakon/AgriFM.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Smooth Operator: Smooth Verifiable Reward Activates Spatial Reasoning Ability of Vision-Language Model|Smooth Operatorï¼šSmooth Verifiable Reward æ¿€æ´» Vision-Language Model çš„ç©ºé—´æ¨ç†èƒ½åŠ›|Siwen Jiao, Tianxiong Lv, Kangan Qian, Chenxu Zhao, Xiuyuan Zhu, Tianlun Li, Xiaolong Cheng, Jinyu Li .etc.|<https://arxiv.org/pdf/2601.07695v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|EfficientFSL: Enhancing Few-Shot Classification via Query-Only Tuning in Vision Transformers|EfficientFSL: é€šè¿‡ Vision Transformers ä¸­çš„ Query-Only Tuning å¢å¼º Few-Shot Classification|Wenwen Liao, Hang Ruan, Jianbo Yu, Bing Song, YuansongWang, Xiaofeng Yang|<https://arxiv.org/pdf/2601.08499v2>|æ— |


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|MINGLE: VLMs for Semantically Complex Region Detection in Urban Scenes|MINGLEï¼šç”¨äºåŸå¸‚åœºæ™¯ä¸­è¯­ä¹‰å¤æ‚åŒºåŸŸæ£€æµ‹çš„VLMs|Liu Liu, Alexandra Kudaeva, Marco Cipriano, Fatimeh Al Ghannam, Freya Tan, Gerard de Melo, Andres Sevtsuk|<https://arxiv.org/pdf/2509.13484v3>|æ— |
|ğŸ“ æ›´æ–°|Encoder-Only Image Registration|ä»…ç¼–ç å™¨çš„å›¾åƒé…å‡†|Xiang Chen, Renjiu Hu, Jinwei Zhang, Yuxi Zhang, Xinyao Yu, Min Liu, Yaonan Wang, Hang Zhang|<https://arxiv.org/pdf/2509.00451v3>|[ä»£ç ](https://github.com/XiangChen1994/EOIR.)|
|ğŸ“ æ›´æ–°|Instance-level quantitative saliency in multiple sclerosis lesion segmentation|å¤šå‘æ€§ç¡¬åŒ–ç—‡ç—…ç¶åˆ†å‰²ä¸­çš„å®ä¾‹çº§å®šé‡æ˜¾è‘—æ€§|Federico Spagnolo, Nataliia Molchanova, Meritxell Bach Cuadra, Mario Ocampo Pineda, Lester Melie-Garcia, Cristina Granziera, Vincent Andrearczyk, Adrien Depeursinge|<https://arxiv.org/pdf/2406.09335v3>|æ— |
|ğŸ†• å‘å¸ƒ|From Physical Degradation Models to Task-Aware All-in-One Image Restoration|ä»ç‰©ç†é€€åŒ–æ¨¡å‹åˆ°ä»»åŠ¡æ„ŸçŸ¥çš„ä¸€ä½“åŒ–å›¾åƒæ¢å¤|Hu Gao, Xiaoning Lei, Xichen Xu, Xingjian Wang, Lizhuang Ma|<https://arxiv.org/pdf/2601.10192v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|JOGS: Joint Optimization of Pose Estimation and 3D Gaussian Splatting|JOGSï¼šå§¿æ€ä¼°è®¡ä¸3D Gaussian Splattingçš„è”åˆä¼˜åŒ–|Xianben Yang, Yuxuan Li, Tao Wang, Tao Wang, Yi Jin, Yidong Li, Haibin Ling|<https://arxiv.org/pdf/2510.26117v2>|æ— |
|ğŸ“ æ›´æ–°|Human-inspired Global-to-Parallel Multi-scale Encoding for Lightweight Vision Models|å—äººç±»å¯å‘çš„å…¨å±€åˆ°å¹¶è¡Œå¤šå°ºåº¦ç¼–ç ï¼Œç”¨äºè½»é‡çº§è§†è§‰æ¨¡å‹|Wei Xu|<https://arxiv.org/pdf/2601.08190v2>|æ— |


### å›¾åƒåˆ†ç±»ä¸è¯†åˆ« (Image Classification & Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ICONIC-444: A 3.1-Million-Image Dataset for OOD Detection Research|ICONIC-444ï¼šä¸€ä¸ªç”¨äº OOD æ£€æµ‹ç ”ç©¶çš„ 310 ä¸‡å›¾åƒæ•°æ®é›†|Gerhard Krumpl, Henning Avenhaus, Horst Possegger|<https://arxiv.org/pdf/2601.10802v1>|æ— |
|ğŸ“ æ›´æ–°|Towards Understanding Deep Learning Model in Image Recognition via Coverage Test|[ç¿»è¯‘å¤±è´¥] Towards Understanding Deep Learning Model in Image Recognition via Coverage Test|Wenkai Li, Xiaoqi Li, Yingjie Mao, Yishun Wang|<https://arxiv.org/pdf/2505.08814v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Granular Ball Guided Masking: Structure-aware Data Augmentation|[ç¿»è¯‘å¤±è´¥] Granular Ball Guided Masking: Structure-aware Data Augmentation|Shuyin Xia, Fan Chen, Dawei Dai, Meng Yang, Junwei Han, Xinbo Gao, Guoyin Wang|<https://arxiv.org/pdf/2512.21011v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Graph Algorithm Unrolling with Douglas-Rachford Iterations for Image Interpolation with Guaranteed Initialization|åŸºäºDouglas-Rachfordè¿­ä»£çš„å›¾ç®—æ³•å±•å¼€ç”¨äºå…·æœ‰ä¿è¯åˆå§‹åŒ–çš„å›¾åƒæ’å€¼|Xue Zhang, Bingshuo Hu, Gene Cheung|<https://arxiv.org/pdf/2509.11926v3>|åˆ†æå¤±è´¥|


### è¯­ä¹‰/å®ä¾‹åˆ†å‰² (Semantic/Instance Segmentation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Urban Socio-Semantic Segmentation with Vision-Language Reasoning|åŸºäº Vision-Language Reasoning çš„åŸå¸‚ç¤¾ä¼šè¯­ä¹‰åˆ†å‰²|Yu Wang, Yi Wang, Rui Dai, Yujie Wang, Kaikui Liu, Xiangxiang Chu, Yansheng Li|<https://arxiv.org/pdf/2601.10477v1>|[ä»£ç ](https://github.com/AMAP-ML/SocioReasoner.)|


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|A Safety Report on GPT-5.2, Gemini 3 Pro, Qwen3-VL, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5|å…³äº GPT-5.2ã€Gemini 3 Proã€Qwen3-VLã€Grok 4.1 Fastã€Nano Banana Pro å’Œ Seedream 4.5 çš„å®‰å…¨æŠ¥å‘Š|Xingjun Ma, Yixu Wang, Hengyuan Xu, Yutao Wu, Yifan Ding, Yunhan Zhao, Zilong Wang, Jiabin Hua .etc.|<https://arxiv.org/pdf/2601.10527v2>|æ— |
|ğŸ†• å‘å¸ƒ|FrankenMotion: Part-level Human Motion Generation and Composition|FrankenMotion: éƒ¨ä»¶çº§äººä½“è¿åŠ¨ç”Ÿæˆä¸ç»„åˆ|Chuqiao Li, Xianghui Xie, Yong Cao, Andreas Geiger, Gerard Pons-Moll|<https://arxiv.org/pdf/2601.10909v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Image2Garment: Simulation-ready Garment Generation from a Single Image|Image2Garment: ä»å•å¼ å›¾åƒç”Ÿæˆå¯ç”¨äºä»¿çœŸçš„æœè£…|Selim Emir Can, Jan Ackermann, Kiyohiro Nakayama, Ruofan Liu, Tong Wu, Yang Zheng, Hugo Bertiche, Menglei Chai .etc.|<https://arxiv.org/pdf/2601.09658v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|CoMoVi: Co-Generation of 3D Human Motions and Realistic Videos|CoMoViï¼š3Däººä½“åŠ¨ä½œä¸é€¼çœŸè§†é¢‘çš„ååŒç”Ÿæˆ|Chengfeng Zhao, Jiazhi Shu, Yubo Zhao, Tianyu Huang, Jiahao Lu, Zekai Gu, Chengwei Ren, Zhiyang Dou .etc.|<https://arxiv.org/pdf/2601.10632v1>|æ— |
|ğŸ†• å‘å¸ƒ|Alterbute: Editing Intrinsic Attributes of Objects in Images|[ç¿»è¯‘å¤±è´¥] Alterbute: Editing Intrinsic Attributes of Objects in Images|Tal Reiss, Daniel Winter, Matan Cohen, Alex Rav-Acha, Yael Pritch, Ariel Shamir, Yedid Hoshen|<https://arxiv.org/pdf/2601.10714v1>|æ— |
|ğŸ†• å‘å¸ƒ|Future Optical Flow Prediction Improves Robot Control & Video Generation|[ç¿»è¯‘å¤±è´¥] Future Optical Flow Prediction Improves Robot Control & Video Generation|Kanchana Ranasinghe, Honglu Zhou, Yu Fang, Luyu Yang, Le Xue, Ran Xu, Caiming Xiong, Silvio Savarese .etc.|<https://arxiv.org/pdf/2601.10781v1>|æ— |
|ğŸ†• å‘å¸ƒ|RSATalker: Realistic Socially-Aware Talking Head Generation for Multi-Turn Conversation|RSATalker: é¢å‘å¤šè½®å¯¹è¯çš„çœŸå®æ„Ÿç¤¾äº¤æ„ŸçŸ¥ Talking Head ç”Ÿæˆ|Peng Chen, Xiaobao Wei, Yi Yang, Naiming Yao, Hui Chen, Feng Tian|<https://arxiv.org/pdf/2601.10606v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Subjective evaluation of UHD video coded using VVC with LCEVC and ML-VVC|ä½¿ç”¨ VVC ç»“åˆ LCEVC å’Œ ML-VVC ç¼–ç çš„ UHD è§†é¢‘ä¸»è§‚è¯„ä»·|Naeem Ramzan, Muhammad Tufail Khan|<https://arxiv.org/pdf/2601.10448v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Global Context Compression with Interleaved Vision-Text Transformation|åŸºäºäº¤é”™è§†è§‰-æ–‡æœ¬å˜æ¢çš„å…¨å±€ä¸Šä¸‹æ–‡å‹ç¼©|Dian Jiao, Jiaxin Duan, Shuai Zhao, Jiabing Leng, Yiran Zhang, Feng Huang|<https://arxiv.org/pdf/2601.10378v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|SPATIALGEN: Layout-guided 3D Indoor Scene Generation|[ç¿»è¯‘å¤±è´¥] SPATIALGEN: Layout-guided 3D Indoor Scene Generation|Chuan Fang, Heng Li, Yixun Liang, Jia Zheng, Yongsen Mao, Yuan Liu, Rui Tang, Zihan Zhou .etc.|<https://arxiv.org/pdf/2509.14981v4>|æ— |
|ğŸ†• å‘å¸ƒ|Fine-Grained Human Pose Editing Assessment via Layer-Selective MLLMs|é€šè¿‡åˆ†å±‚é€‰æ‹©æ€§MLLMè¿›è¡Œç»†ç²’åº¦äººä½“å§¿æ€ç¼–è¾‘è¯„ä¼°|Ningyu Sun, Zhaolin Cai, Zitong Xu, Peihang Chen, Huiyu Duan, Yichao Yan, Xiongkuo Min, Xiaokang Yang|<https://arxiv.org/pdf/2601.10369v1>|æ— |
|ğŸ†• å‘å¸ƒ|Think-Then-Generate: Reasoning-Aware Text-to-Image Diffusion with LLM Encoders|Think-Then-Generate: å…·æœ‰æ¨ç†æ„ŸçŸ¥çš„åŸºäº LLM Encoders çš„ Text-to-Image Diffusion|Siqi Kou, Jiachun Jin, Zetong Zhou, Ye Ma, Yugang Wang, Quan Chen, Peng Jiang, Xiao Yang .etc.|<https://arxiv.org/pdf/2601.10332v1>|æ— |
|ğŸ†• å‘å¸ƒ|ROMA: Real-time Omni-Multimodal Assistant with Interactive Streaming Understanding|ROMA: å…·æœ‰äº¤äº’å¼æµå¼ç†è§£çš„å®æ—¶å…¨æ¨¡æ€åŠ©æ‰‹|Xueyun Tian, Wei Li, Bingbing Xu, Heng Dong, Yuanzhuo Wang, Huawei Shen|<https://arxiv.org/pdf/2601.10323v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|GANeXt: A Fully ConvNeXt-Enhanced Generative Adversarial Network for MRI- and CBCT-to-CT Synthesis|GANeXt: ä¸€ç§ç”¨äºMRIå’ŒCBCTåˆ°CTåˆæˆçš„å®Œå…¨ConvNeXtå¢å¼ºç”Ÿæˆå¯¹æŠ—ç½‘ç»œ|Siyuan Mei, Yan Xia, Fuxin Fan, Andreas Maier|<https://arxiv.org/pdf/2512.19336v2>|æ— |
|ğŸ†• å‘å¸ƒ|Beyond Inpainting: Unleash 3D Understanding for Precise Camera-Controlled Video Generation|è¶…è¶Šå›¾åƒä¿®å¤ï¼šé‡Šæ”¾ 3D ç†è§£èƒ½åŠ›ä»¥å®ç°ç²¾ç¡®çš„ç›¸æœºæ§åˆ¶è§†é¢‘ç”Ÿæˆ|Dong-Yu Chen, Yixin Guo, Shuojin Yang, Tai-Jiang Mu, Shi-Min Hu|<https://arxiv.org/pdf/2601.10214v1>|æ— |
|ğŸ“ æ›´æ–°|FastMesh: Efficient Artistic Mesh Generation via Component Decoupling|FastMesh: é€šè¿‡ç»„ä»¶è§£è€¦å®ç°é«˜æ•ˆè‰ºæœ¯ç½‘æ ¼ç”Ÿæˆ|Jeonghwan Kim, Yushi Lan, Armando Fortes, Yongwei Chen, Xingang Pan|<https://arxiv.org/pdf/2508.19188v3>|æ— |
|ğŸ†• å‘å¸ƒ|RAG-3DSG: Enhancing 3D Scene Graphs with Re-Shot Guided Retrieval-Augmented Generation|RAG-3DSG: åˆ©ç”¨é‡æ‹å¼•å¯¼çš„æ£€ç´¢å¢å¼ºç”Ÿæˆå¢å¼º3Dåœºæ™¯å›¾|Yue Chang, Rufeng Chen, Zhaofan Zhang, Yi Chen, Sihong Xie|<https://arxiv.org/pdf/2601.10168v1>|æ— |
|ğŸ†• å‘å¸ƒ|LaViT: Aligning Latent Visual Thoughts for Multi-modal Reasoning|LaViT: å¯¹é½æ½œåœ¨è§†è§‰æ€ç»´ä»¥è¿›è¡Œå¤šæ¨¡æ€æ¨ç†|Linquan Wu, Tianxiang Jiang, Yifei Dong, Haoyu Yang, Fengji Zhang, Shichaang Meng, Ai Xuan, Linqi Song .etc.|<https://arxiv.org/pdf/2601.10129v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|RealCamo: Boosting Real Camouflage Synthesis with Layout Controls and Textual-Visual Guidance|RealCamoï¼šåˆ©ç”¨å¸ƒå±€æ§åˆ¶å’Œæ–‡æœ¬-è§†è§‰æŒ‡å¯¼æå‡çœŸå®ä¼ªè£…åˆæˆ|Chunyuan Chen, Yunuo Cai, Shujuan Li, Weiyun Liang, Bin Wang, Jing Xu|<https://arxiv.org/pdf/2512.22974v3>|æ— |
|ğŸ“ æ›´æ–°|Generative Adversarial Gumbel MCTS for Abstract Visual Composition Generation|ç”¨äºæŠ½è±¡è§†è§‰æ„å›¾ç”Ÿæˆçš„ç”Ÿæˆå¯¹æŠ— Gumbel MCTS|Zirui Zhao, Boye Niu, David Hsu, Wee Sun Lee|<https://arxiv.org/pdf/2512.01242v2>|æ— |
|ğŸ†• å‘å¸ƒ|FlowAct-R1: Towards Interactive Humanoid Video Generation|FlowAct-R1: è¿ˆå‘äº¤äº’å¼äººå½¢æœºå™¨äººè§†é¢‘ç”Ÿæˆ|Lizhen Wang, Yongming Zhu, Zhipeng Ge, Youwei Zheng, Longhao Zhang, Tianshu Hu, Shiyang Qin, Mingshuang Luo .etc.|<https://arxiv.org/pdf/2601.10103v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|InfoSculpt: Sculpting the Latent Space for Generalized Category Discovery|InfoSculpt: é›•åˆ»æ½œåœ¨ç©ºé—´ä»¥å®ç°å¹¿ä¹‰ç±»åˆ«å‘ç°|Wenwen Liao, Hang Ruan, Jianbo Yu, Yuansong Wang, Qingchao Jiang, Xiaofeng Yang|<https://arxiv.org/pdf/2601.10098v1>|æ— |
|ğŸ†• å‘å¸ƒ|MathDoc: Benchmarking Structured Extraction and Active Refusal on Noisy Mathematics Exam Papers|MathDoc: åœ¨å™ªå£°æ•°å­¦è¯•å·ä¸Šå¯¹ç»“æ„åŒ–æå–å’Œä¸»åŠ¨æ‹’ç»è¿›è¡ŒåŸºå‡†æµ‹è¯•|Chenyue Zhou, Jiayi Tuo, Shitong Qin, Wei Dai, Mingxuan Wang, Ziwei Zhao, Duoyang Li, Shiyang Su .etc.|<https://arxiv.org/pdf/2601.10104v1>|[ä»£ç ](https://github.com/winnk123/papers); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|CoF-T2I: Video Models as Pure Visual Reasoners for Text-to-Image Generation|CoF-T2I: å°†è§†é¢‘æ¨¡å‹ä½œä¸º Text-to-Image ç”Ÿæˆä¸­çš„çº¯è§†è§‰æ¨ç†å™¨|Chengzhuo Tong, Mingkun Chang, Shenglong Zhang, Yuran Wang, Cheng Liang, Zhizheng Zhao, Ruichuan An, Bohan Zeng .etc.|<https://arxiv.org/pdf/2601.10061v1>|æ— |
|ğŸ“ æ›´æ–°|AITTI: Learning Adaptive Inclusive Token for Text-to-Image Generation|AITTIï¼šå­¦ä¹ è‡ªé€‚åº”åŒ…å®¹Tokenç”¨äºText-to-Image Generation|Xinyu Hou, Xiaoming Li, Chen Change Loy|<https://arxiv.org/pdf/2406.12805v3>|[ä»£ç ](https://github.com/itsmag11/AITTI.)|
|ğŸ†• å‘å¸ƒ|EditEmoTalk: Controllable Speech-Driven 3D Facial Animation with Continuous Expression Editing|EditEmoTalk: å…·æœ‰è¿ç»­è¡¨æƒ…ç¼–è¾‘çš„å¯æ§è¯­éŸ³é©±åŠ¨ 3D é¢éƒ¨åŠ¨ç”»|Diqiong Jiang, Kai Zhu, Dan Song, Jian Chang, Chenglizhao Chen, Zhenyu Wu|<https://arxiv.org/pdf/2601.10000v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|High-Quality 3D Head Reconstruction from Any Single Portrait Image|ä»ä»»æ„å•å¼ è‚–åƒå›¾åƒè¿›è¡Œé«˜è´¨é‡3Då¤´éƒ¨é‡å»º|Jianfu Zhang, Yujie Gao, Jiahui Zhan, Wentao Wang, Yiyi Zhang, Haohua Zhao, Liqing Zhang|<https://arxiv.org/pdf/2503.08516v3>|åˆ†æå¤±è´¥|


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|ViSTA: Visual Storytelling using Multi-modal Adapters for Text-to-Image Diffusion Models|ViSTA: ä½¿ç”¨å¤šæ¨¡æ€é€‚é…å™¨è¿›è¡Œæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„è§†è§‰å™äº‹|Sibo Dong, Ismail Shaheen, Maggie Shen, Rupayan Mallick, Sarah Adel Bargal|<https://arxiv.org/pdf/2506.12198v3>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|3D latent diffusion models for parameterizing and history matching multiscenario facies systems|ç”¨äºå‚æ•°åŒ–å’Œå†å²åŒ¹é…å¤šåœºæ™¯ç›¸ç³»ç»Ÿçš„3D latent diffusion models|Guido Di Federico, Louis J. Durlofsky|<https://arxiv.org/pdf/2508.16621v2>|æ— |
|ğŸ“ æ›´æ–°|Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning|SciCap çš„äº”å¹´ï¼šæˆ‘ä»¬åœ¨ç§‘å­¦å›¾åƒè¯´æ˜ä¸­å­¦åˆ°çš„ç»éªŒä¸æœªæ¥æ–¹å‘|Ting-Hao 'Kenneth' Huang, Ryan A. Rossi, Sungchul Kim, Tong Yu, Ting-Yao E. Hsu, Ho Yin, Ng, C. Lee Giles|<https://arxiv.org/pdf/2512.21789v2>|æ— |
|ğŸ“ æ›´æ–°|Zoom-IQA: Image Quality Assessment with Reliable Region-Aware Reasoning|Zoom-IQA: åŸºäºå¯é åŒºåŸŸæ„ŸçŸ¥æ¨ç†çš„å›¾åƒè´¨é‡è¯„ä¼°|Guoqiang Liang, Jianyi Wang, Zhonghua Wu, Shangchen Zhou|<https://arxiv.org/pdf/2601.02918v2>|æ— |
|ğŸ†• å‘å¸ƒ|Towards Efficient Low-rate Image Compression with Frequency-aware Diffusion Prior Refinement|é¢å‘é«˜æ•ˆä½ç ç‡å›¾åƒå‹ç¼©çš„Frequency-aware Diffusion Prior Refinement|Yichong Xia, Yimin Zhou, Jinpeng Wang, Bin Chen|<https://arxiv.org/pdf/2601.10373v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|A Geometric Unification of Generative AI with Manifold-Probabilistic Projection Models|ç”Ÿæˆå¼ AI ä¸æµå½¢æ¦‚ç‡æŠ•å½±æ¨¡å‹çš„å‡ ä½•ç»Ÿä¸€|Leah Bar, Liron Mor Yosef, Shai Zucker, Neta Shoham, Inbar Seroussi, Nir Sochen|<https://arxiv.org/pdf/2510.00666v2>|æ— |
|ğŸ“ æ›´æ–°|3D Wavelet-Based Structural Priors for Controlled Diffusion in Whole-Body Low-Dose PET Denoising|åŸºäº 3D å°æ³¢çš„ç»“æ„å…ˆéªŒç”¨äºå…¨èº«ä½å‰‚é‡ PET å»å™ªä¸­çš„å¯æ§æ‰©æ•£|Peiyuan Jing, Yue Tang, Chun-Wun Cheng, Zhenxuan Zhang, Liutao Yang, Thiago V. Lima, Klaus Strobel, Antoine Leimgruber .etc.|<https://arxiv.org/pdf/2601.07093v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Beyond Single Prompts: Synergistic Fusion and Arrangement for VICL|è¶…è¶Šå•ä¸€æç¤ºï¼šVICL çš„ååŒèåˆä¸æ’åˆ—|Wenwen Liao, Jianbo Yu, Yuansong Wang, Shifu Yan, Xiaofeng Yang|<https://arxiv.org/pdf/2601.10117v1>|æ— |
|ğŸ“ æ›´æ–°|Learning Physics-Informed Noise Models from Dark Frames for Low-Light Raw Image Denoising|ä»æš—å¸§ä¸­å­¦ä¹ ç‰©ç†ä¿¡æ¯å™ªå£°æ¨¡å‹ç”¨äºä½å…‰ Raw å›¾åƒå»å™ª|Hansen Feng, Lizhi Wang, Yiqi Huang, Yuzhi Wang, Lin Zhu, Hua Huang|<https://arxiv.org/pdf/2310.09126v3>|æ— |
|ğŸ†• å‘å¸ƒ|Disentangled Concept Representation for Text-to-image Person Re-identification|[ç¿»è¯‘å¤±è´¥] Disentangled Concept Representation for Text-to-image Person Re-identification|Giyeol Kim, Chanho Eom|<https://arxiv.org/pdf/2601.10053v1>|æ— |
|ğŸ“ æ›´æ–°|End-to-End PET Image Reconstruction via a Posterior-Mean Diffusion Model|åŸºäºåéªŒå‡å€¼æ‰©æ•£æ¨¡å‹çš„ç«¯åˆ°ç«¯ PET å›¾åƒé‡å»º|Yiran Sun, Osama Mawlawi|<https://arxiv.org/pdf/2503.08546v2>|æ— |


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Inference-time Physics Alignment of Video Generative Models with Latent World Models|è§†é¢‘ç”Ÿæˆæ¨¡å‹æ¨ç†é˜¶æ®µçš„ç‰©ç†å¯¹é½ä¸æ½œåœ¨ä¸–ç•Œæ¨¡å‹|Jianhao Yuan, Xiaofeng Zhang, Felix Friedrich, Nicolas Beltran-Velez, Melissa Hall, Reyhane Askari-Hemmat, Xiaochuang Han, Nicolas Ballas .etc.|<https://arxiv.org/pdf/2601.10553v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Tuning-Free Adaptive Style Incorporation for Structure-Consistent Text-Driven Style Transfer|æ— éœ€è°ƒå‚çš„è‡ªé€‚åº”é£æ ¼èå…¥ç”¨äºç»“æ„ä¸€è‡´çš„æ–‡æœ¬é©±åŠ¨é£æ ¼è¿ç§»|Yanqi Ge, Jiaqi Liu, Qingnan Fan, Xi Jiang, Ye Huang, Shuai Qin, Hong Gu, Wen Li .etc.|<https://arxiv.org/pdf/2404.06835v2>|æ— |
|ğŸ“ æ›´æ–°|Beautiful Images, Toxic Words: Understanding and Addressing Offensive Text in Generated Images|Beautiful Images, Toxic Words: ç†è§£å¹¶è§£å†³ç”Ÿæˆå›¾åƒä¸­çš„å†’çŠ¯æ€§æ–‡æœ¬|Aditya Kumar, Tom Blanchard, Adam Dziedzic, Franziska Boenisch|<https://arxiv.org/pdf/2502.05066v4>|æ— |


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Spatial As Deep: Spatial CNN for Traffic Scene Understanding|[ç¿»è¯‘å¤±è´¥] Spatial As Deep: Spatial CNN for Traffic Scene Understanding|Xingang Pan, Xiaohang Zhan, Jianping Shi, Ping Luo, Xiaogang Wang, Xiaoou Tang|<https://arxiv.org/pdf/1712.06080v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|RTV-Bench: Benchmarking MLLM Continuous Perception, Understanding and Reasoning through Real-Time Video|RTV-Bench: é€šè¿‡å®æ—¶è§†é¢‘å¯¹ MLLM çš„è¿ç»­æ„ŸçŸ¥ã€ç†è§£å’Œæ¨ç†è¿›è¡ŒåŸºå‡†æµ‹è¯•|Shuhang Xun, Sicheng Tao, Jungang Li, Yibo Shi, Zhixin Lin, Zhanhui Zhu, Yibo Yan, Hanqian Li .etc.|<https://arxiv.org/pdf/2505.02064v4>|æ— |
|ğŸ“ æ›´æ–°|The Hatching-Box: A Novel System for Automated Monitoring and Quantification of Drosophila melanogaster Developmental Behavior|The Hatching-Boxï¼šä¸€ç§ç”¨äºè‡ªåŠ¨ç›‘æµ‹å’Œé‡åŒ–é»‘è…¹æœè‡å‘è‚²è¡Œä¸ºçš„æ–°å‹ç³»ç»Ÿ|Julian Bigge, Maite Ogueta, Luis Garcia, Benjamin Risse|<https://arxiv.org/pdf/2411.15390v4>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|ELITE: Efficient Gaussian Head Avatar from a Monocular Video via Learned Initialization and TEst-time Generative Adaptation|ELITE: é€šè¿‡å­¦ä¹ åˆå§‹åŒ–å’Œæµ‹è¯•æ—¶ç”Ÿæˆé€‚åº”ä»å•ç›®è§†é¢‘ä¸­é«˜æ•ˆæ„å»º Gaussian Head Avatar|Kim Youwang, Lee Hyoseok, Subin Park, Gerard Pons-Moll, Tae-Hyun Oh|<https://arxiv.org/pdf/2601.10200v1>|æ— |
|ğŸ“ æ›´æ–°|TeleMem: Building Long-Term and Multimodal Memory for Agentic AI|TeleMem: ä¸º Agentic AI æ„å»ºé•¿æœŸå’Œå¤šæ¨¡æ€è®°å¿†|Chunliang Chen, Ming Guan, Xiao Lin, Jiaxu Li, Luxi Lin, Qiyi Wang, Xiangyu Chen, Jixiang Luo .etc.|<https://arxiv.org/pdf/2601.06037v3>|åˆ†æå¤±è´¥|


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### è§†è§‰å®šä½ä¸æ˜ å°„ (Visual Localization & Mapping)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization|RGS-SLAM: å…·æœ‰å•æ¬¡ç¨ å¯†åˆå§‹åŒ–çš„é²æ£’ Gaussian Splatting SLAM|Wei-Tse Cheng, Yen-Jen Chiou, Yuan-Fu Yang|<https://arxiv.org/pdf/2601.00705v3>|[ä»£ç ](https://breeze1124.github.io/rgs-slam-project-page); åˆ†æå¤±è´¥|


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Unleashing Semantic and Geometric Priors for 3D Scene Completion|é‡Šæ”¾è¯­ä¹‰ä¸å‡ ä½•å…ˆéªŒç”¨äº 3D åœºæ™¯è¡¥å…¨|Shiyuan Chen, Wei Sui, Bohao Zhang, Zeyd Boukhers, John See, Cong Yang|<https://arxiv.org/pdf/2508.13601v2>|æ— |
|ğŸ“ æ›´æ–°|SPARK: Scalable Real-Time Point Cloud Aggregation with Multi-View Self-Calibration|SPARKï¼šå…·æœ‰å¤šè§†å›¾è‡ªæ ¡å‡†çš„å¯æ‰©å±•å®æ—¶ç‚¹äº‘èšåˆ|Chentian Sun|<https://arxiv.org/pdf/2601.08414v2>|åˆ†æå¤±è´¥|


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Bayesian Monocular Depth Refinement via Neural Radiance Fields|åŸºäºNeRFçš„è´å¶æ–¯å•ç›®æ·±åº¦ç»†åŒ–|Arun Muthukkumar|<https://arxiv.org/pdf/2601.03869v2>|æå‡ºMDENeRFæ¡†æ¶ï¼Œåˆ©ç”¨NeRFæ·±åº¦ä¿¡æ¯ç»†åŒ–å•ç›®æ·±åº¦ä¼°è®¡|


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Effects of Different Attention Mechanisms Applied on 3D Models in Video Classification|åº”ç”¨äº3Dæ¨¡å‹çš„ä¸åŒæ³¨æ„åŠ›æœºåˆ¶åœ¨è§†é¢‘åˆ†ç±»ä¸­çš„æ•ˆæœ|Mohammad Rasras, Iuliana Marin, Serban Radu, Irina Mocanu|<https://arxiv.org/pdf/2601.10854v1>|æ— |
|ğŸ†• å‘å¸ƒ|CURVE: A Benchmark for Cultural and Multilingual Long Video Reasoning|CURUBE: ä¸€ä¸ªæ–‡åŒ–ä¸å¤šè¯­è¨€é•¿è§†é¢‘æ¨ç†åŸºå‡†|Darshan Singh, Arsha Nagrani, Kawshik Manikantan, Harman Singh, Dinesh Tewari, Tobias Weyand, Cordelia Schmid, Anelia Angelova .etc.|<https://arxiv.org/pdf/2601.10649v1>|[ä»£ç ](https://github.com/google-deepmind/neptune)|
|ğŸ“ æ›´æ–°|Explicit Abstention Knobs for Predictable Reliability in Video Question Answering|ç”¨äº Video Question Answering ä¸­å¯é¢„æµ‹å¯é æ€§çš„æ˜¾å¼æ‹’ç»è°ƒèŠ‚æ—‹é’®|Jorge Ortiz|<https://arxiv.org/pdf/2601.00138v2>|æ— |
|ğŸ†• å‘å¸ƒ|UEOF: A Benchmark Dataset for Underwater Event-Based Optical Flow|UEOF: ä¸€ä¸ªç”¨äºæ°´ä¸‹äº‹ä»¶å…‰æµçš„åŸºå‡†æ•°æ®é›†|Nick Truong, Pritam P. Karmokar, William J. Beksi|<https://arxiv.org/pdf/2601.10054v1>|[ä»£ç ](https://robotic-vision-lab.github.io/ueof.)|


### åŠ¨ä½œè¯†åˆ«ä¸ç†è§£ (Action Recognition & Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Can Vision-Language Models Understand Construction Workers? An Exploratory Study|Vision-Language Models èƒ½ç†è§£å»ºç­‘å·¥äººå—ï¼Ÿä¸€é¡¹æ¢ç´¢æ€§ç ”ç©¶|Hieu Bui, Nathaniel E. Chodosh, Arash Tavakoli|<https://arxiv.org/pdf/2601.10835v1>|æ— |
|ğŸ†• å‘å¸ƒ|BikeActions: An Open Platform and Benchmark for Cyclist-Centric VRU Action Recognition|BikeActions: ä¸€ä¸ªä»¥éª‘è¡Œè€…ä¸ºä¸­å¿ƒçš„VRUåŠ¨ä½œè¯†åˆ«å¼€æ”¾å¹³å°ä¸åŸºå‡†|Max A. Buettner, Kanak Mazumder, Luca Koecher, Mario Finkbeiner, Sebastian Niebler, Fabian B. Flohr|<https://arxiv.org/pdf/2601.10521v1>|æ— |
|ğŸ“ æ›´æ–°|Lifelong Domain Adaptive 3D Human Pose Estimation|[ç¿»è¯‘å¤±è´¥] Lifelong Domain Adaptive 3D Human Pose Estimation|Qucheng Peng, Hongfei Xue, Pu Wang, Chen Chen|<https://arxiv.org/pdf/2512.23860v2>|æ— |


### è§†é¢‘ç›®æ ‡è·Ÿè¸ª (Video Object Tracking)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Molmo2: Open Weights and Data for Vision-Language Models with Video Understanding and Grounding|Molmo2ï¼šå…·å¤‡è§†é¢‘ç†è§£å’Œå®šä½èƒ½åŠ›çš„ Vision-Language Models çš„å¼€æ”¾æƒé‡ä¸æ•°æ®|Christopher Clark, Jieyu Zhang, Zixian Ma, Jae Sung Park, Mohammadreza Salehi, Rohun Tripathi, Sangho Lee, Zhongzheng Ren .etc.|<https://arxiv.org/pdf/2601.10611v1>|æ— |
|ğŸ†• å‘å¸ƒ|Cell Behavior Video Classification Challenge, a benchmark for computer vision methods in time-lapse microscopy|Cell Behavior Video Classification Challengeï¼Œä¸€ä¸ªç”¨äºå»¶æ—¶æ˜¾å¾®é•œä¸­è®¡ç®—æœºè§†è§‰æ–¹æ³•çš„åŸºå‡†|Raffaella Fiamma Cabini, Deborah Barkauskas, Guangyu Chen, Zhi-Qi Cheng, David E Cicchetti, Judith Drazba, Rodrigo Fernandez-Gonzalez, Raymond Hawkins .etc.|<https://arxiv.org/pdf/2601.10250v1>|æ— |
|ğŸ“ æ›´æ–°|Data-Driven Feature Tracking for Event Cameras With and Without Frames|åŸºäºæ•°æ®é©±åŠ¨çš„æœ‰å¸§å’Œæ— å¸§ Event Camera ç‰¹å¾è·Ÿè¸ª|Nico Messikommer, Carter Fang, Mathias Gehrig, Giovanni Cioffi, Davide Scaramuzza|<https://arxiv.org/pdf/2211.12826v4>|æ— |
|ğŸ†• å‘å¸ƒ|VERHallu: Evaluating and Mitigating Event Relation Hallucination in Video Large Language Models|VERHallu: è¯„ä¼°å’Œç¼“è§£ Video Large Language Models ä¸­çš„ Event Relation Hallucination|Zefan Zhang, Kehua Zhu, Shijie Jiang, Hongyuan Lu, Shengkai Sun, Tian Bai|<https://arxiv.org/pdf/2601.10010v1>|æ— |


## è‡ªç›‘ç£ä¸è¡¨å¾å­¦ä¹  (Self-supervised & Representation Learning)


### è¡¨å¾çŸ¥è¯†è¿ç§» (Representation Knowledge Transfer)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Thinking Like Van Gogh: Structure-Aware Style Transfer via Flow-Guided 3D Gaussian Splatting|[ç¿»è¯‘å¤±è´¥] Thinking Like Van Gogh: Structure-Aware Style Transfer via Flow-Guided 3D Gaussian Splatting|Zhendong Wang, Lebin Zhou, Jingchuan Xiao, Rongduo Han, Nam Ling, Cihan Ruan|<https://arxiv.org/pdf/2601.10075v1>|åˆ†æå¤±è´¥|


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ChartComplete: A Taxonomy-based Inclusive Chart Dataset|ChartComplete: ä¸€ä¸ªåŸºäºåˆ†ç±»å­¦çš„åŒ…å®¹æ€§å›¾è¡¨æ•°æ®é›†|Ahmad Mustapha, Charbel Toumieh, Mariette Awad|<https://arxiv.org/pdf/2601.10462v2>|æ— |
|ğŸ†• å‘å¸ƒ|Multi-Temporal Frames Projection for Dynamic Processes Fusion in Fluorescence Microscopy|[ç¿»è¯‘å¤±è´¥] Multi-Temporal Frames Projection for Dynamic Processes Fusion in Fluorescence Microscopy|Hassan Eshkiki, Sarah Costa, Mostafa Mohammadpour, Farinaz Tanhaei, Christopher H. George, Fabio Caraffini|<https://arxiv.org/pdf/2601.10392v1>|æ— |
|ğŸ†• å‘å¸ƒ|Attend to what I say: Highlighting relevant content on slides|å…³æ³¨æˆ‘æ‰€è¯´çš„å†…å®¹ï¼šçªå‡ºå¹»ç¯ç‰‡ä¸Šçš„ç›¸å…³å†…å®¹|Megha Mariam K M, C. V. Jawahar|<https://arxiv.org/pdf/2601.10244v1>|[ä»£ç ](https://github.com/meghamariamkm2002/Slide_Highlight)|


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|WildRayZer: Self-supervised Large View Synthesis in Dynamic Environments|WildRayZer: åŠ¨æ€ç¯å¢ƒä¸­çš„è‡ªç›‘ç£å¤§è§†è§’åˆæˆ|Xuweiyi Chen, Wentao Zhou, Zezhou Cheng|<https://arxiv.org/pdf/2601.10716v1>|æ— |
|ğŸ“ æ›´æ–°|Moonworks Lunara Aesthetic Dataset|Moonworks Lunara ç¾å­¦æ•°æ®é›†|Yan Wang, M M Sayeef Abdullah, Partho Hassan, Sabit Hassan|<https://arxiv.org/pdf/2601.07941v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Process-Guided Concept Bottleneck Model|[ç¿»è¯‘å¤±è´¥] Process-Guided Concept Bottleneck Model|Reza M. Asiyabi, SEOSAW Partnership, Steven Hancock, Casey Ryan|<https://arxiv.org/pdf/2601.10562v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|SERA-H: Beyond Native Sentinel Spatial Limits for High-Resolution Canopy Height Mapping|SERA-Hï¼šè¶…è¶ŠåŸç”ŸSentinelç©ºé—´é™åˆ¶çš„é«˜åˆ†è¾¨ç‡å† å±‚é«˜åº¦åˆ¶å›¾|Thomas Boudras, Martin Schwartz, Rasmus Fensholt, Martin Brandt, Ibrahim Fayad, Jean-Pierre Wigneron, Gabriel Belouze, Fajwel Fogel .etc.|<https://arxiv.org/pdf/2512.18128v2>|æ— |
|ğŸ“ æ›´æ–°|Debiased Orthogonal Boundary-Driven Efficient Noise Mitigation|å»åæ­£äº¤è¾¹ç•Œé©±åŠ¨çš„é«˜æ•ˆå™ªå£°ç¼“è§£|Hao Li, Jiayang Gu, Jingkuan Song, An Zhang, Lianli Gao|<https://arxiv.org/pdf/2410.01944v2>|[ä»£ç ](https://github.com/leolee99/OSA.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Fusionista2.0: Efficiency Retrieval System for Large-Scale Datasets|Fusionista2.0: é¢å‘å¤§è§„æ¨¡æ•°æ®é›†çš„é«˜æ•ˆæ£€ç´¢ç³»ç»Ÿ|Huy M. Le, Dat Tien Nguyen, Phuc Binh Nguyen, Gia Bao Le Tran, Phu Truong Thien, Cuong Dinh, Minh Nguyen, Nga Nguyen .etc.|<https://arxiv.org/pdf/2511.12255v2>|æ— |
|ğŸ†• å‘å¸ƒ|Difficulty-guided Sampling: Bridging the Target Gap between Dataset Distillation and Downstream Tasks|Difficultyåº¦å¼•å¯¼é‡‡æ ·ï¼šå¼¥åˆæ•°æ®é›†è’¸é¦ä¸ä¸‹æ¸¸ä»»åŠ¡ä¹‹é—´çš„ç›®æ ‡å·®è·|Mingzhuo Li, Guang Li, Linfeng Ye, Jiafeng Mao, Takahiro Ogawa, Konstantinos N. Plataniotis, Miki Haseyama|<https://arxiv.org/pdf/2601.10090v1>|æ— |
|ğŸ“ æ›´æ–°|Modality-Balanced Collaborative Distillation for Multi-Modal Domain Generalization|[ç¿»è¯‘å¤±è´¥] Modality-Balanced Collaborative Distillation for Multi-Modal Domain Generalization|Xiaohan Wang, Zhangtao Cheng, Ting Zhong, Leiting Chen, Fan Zhou|<https://arxiv.org/pdf/2511.20258v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Comparative Evaluation of Deep Learning-Based and WHO-Informed Approaches for Sperm Morphology Assessment|åŸºäºDeep Learningçš„æ–¹æ³•ä¸åŸºäºWHOçš„æ–¹æ³•åœ¨ç²¾å­å½¢æ€è¯„ä¼°ä¸­çš„æ¯”è¾ƒè¯„ä¼°|Mohammad Abbadi|<https://arxiv.org/pdf/2601.10070v1>|æ— |
|ğŸ“ æ›´æ–°|Jump-teaching: Combating Sample Selection Bias via Temporal Disagreement|Jump-teaching: é€šè¿‡æ—¶é—´å·®å¼‚å¯¹æŠ—æ ·æœ¬é€‰æ‹©åå·®|Kangye Ji, Fei Cheng, Zeqing Wang, Qichang Zhang, Bohu Huang|<https://arxiv.org/pdf/2405.17137v5>|åˆ†æå¤±è´¥|


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|From One-to-One to Many-to-Many: Dynamic Cross-Layer Injection for Deep Vision-Language Fusion|ä»ä»ä¸€å¯¹ä¸€åˆ°å¤šå¯¹å¤šï¼šç”¨äºæ·±åº¦è§†è§‰-è¯­è¨€èåˆçš„åŠ¨æ€è·¨å±‚æ³¨å…¥|Cheng Chen, Yuyu Guo, Pengpeng Zeng, Jingkuan Song, Peng Di, Hang Yu, Lianli Gao|<https://arxiv.org/pdf/2601.10710v1>|æ— |
|ğŸ†• å‘å¸ƒ|Multi-Objective Pareto-Front Optimization for Efficient Adaptive VVC Streaming|é¢å‘é«˜æ•ˆè‡ªé€‚åº”VVCæµä¼ è¾“çš„å¤šç›®æ ‡Paretoå‰æ²¿ä¼˜åŒ–|Angeliki Katsenou, Vignesh V. Menon, Guoda Laurinaviciute, Benjamin Bross, Detlev Marpe|<https://arxiv.org/pdf/2601.10607v1>|æ— |
|ğŸ“ æ›´æ–°|Semi-Tensor-Product Based Convolutional Neural Networks|åŸºäºåŠå¼ é‡ç§¯çš„å·ç§¯ç¥ç»ç½‘ç»œ|Daizhan Cheng, Xiao Zhang|<https://arxiv.org/pdf/2506.10407v3>|æ— |
|ğŸ“ æ›´æ–°|Symmetrization Weighted Binary Cross-Entropy: Modeling Perceptual Asymmetry for Human-Consistent Neural Edge Detection|å¯¹ç§°åŒ–åŠ æƒäºŒå…ƒäº¤å‰ç†µï¼šä¸ºäººç±»ä¸€è‡´çš„ç¥ç»è¾¹ç¼˜æ£€æµ‹å»ºæ¨¡æ„ŸçŸ¥ä¸å¯¹ç§°æ€§|Hao Shu|<https://arxiv.org/pdf/2501.13365v3>|æ— |


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### åˆ†å¸ƒå¤–æ³›åŒ– (Out-of-distribution Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|One Model, Many Behaviors: Training-Induced Effects on Out-of-Distribution Detection|One Model, Many Behaviorsï¼šè®­ç»ƒå¯¹ Out-of-Distribution Detection çš„å½±å“|Gerhard Krumpl, Henning Avenhaus, Horst Possegger|<https://arxiv.org/pdf/2601.10836v1>|æ— |
|ğŸ†• å‘å¸ƒ|A Unified 3D Object Perception Framework for Real-Time Outside-In Multi-Camera Systems|é¢å‘å®æ—¶ Outside-In å¤šç›¸æœºç³»ç»Ÿçš„ç»Ÿä¸€ 3D Object Perception æ¡†æ¶|Yizhou Wang, Sameer Pusegaonkar, Yuxing Wang, Anqi Li, Vishal Kumar, Chetan Sethi, Ganapathy Aiyer, Yun He .etc.|<https://arxiv.org/pdf/2601.10819v1>|æ— |
|ğŸ†• å‘å¸ƒ|An analytic theory of convolutional neural network inverse problems solvers|å·ç§¯ç¥ç»ç½‘ç»œé€†é—®é¢˜æ±‚è§£å™¨çš„è§£æç†è®º|Minh Hai Nguyen, Quoc Bao Do, Edouard Pauwels, Pierre Weiss|<https://arxiv.org/pdf/2601.10334v1>|æ— |
|ğŸ†• å‘å¸ƒ|OT-Drive: Out-of-Distribution Off-Road Traversable Area Segmentation via Optimal Transport|OT-Drive: åŸºäºæœ€ä¼˜ä¼ è¾“çš„åˆ†å¸ƒå¤–è¶Šé‡å¯é€šè¡ŒåŒºåŸŸåˆ†å‰²|Zhihua Zhao, Guoqiang Li, Chen Min, Kangping Lu|<https://arxiv.org/pdf/2601.09952v1>|æ— |


### å¯¹æŠ—é²æ£’æ€§ (Adversarial Robustness)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Adversarial Evasion Attacks on Computer Vision using SHAP Values|åˆ©ç”¨ SHAP Values å¯¹è®¡ç®—æœºè§†è§‰çš„å¯¹æŠ—æ€§é€ƒé¿æ”»å‡»|Frank Mollard, Marcus Becker, Florian Roehrbein|<https://arxiv.org/pdf/2601.10587v1>|æ— |
|ğŸ†• å‘å¸ƒ|SRAW-Attack: Space-Reweighted Adversarial Warping Attack for SAR Target Recognition|SRAW-Attack: ç”¨äºSARç›®æ ‡è¯†åˆ«çš„ç©ºé—´é‡åŠ æƒå¯¹æŠ—æ‰­æ›²æ”»å‡»|Yiming Zhang, Weibo Qin, Yuntian Liu, Feng Wang|<https://arxiv.org/pdf/2601.10324v1>|[ä»£ç ](https://github.com/boremycin/SAR-ATR-TransAttack.)|
|ğŸ“ æ›´æ–°|GreedyPixel: Fine-Grained Black-Box Adversarial Attack Via Greedy Algorithm|GreedyPixel: é€šè¿‡è´ªå©ªç®—æ³•è¿›è¡Œç»†ç²’åº¦é»‘ç›’å¯¹æŠ—æ”»å‡»|Hanrui Wang, Ching-Chun Chang, Chun-Shien Lu, Christopher Leckie, Isao Echizen|<https://arxiv.org/pdf/2501.14230v4>|[ä»£ç ](https://github.com/azrealwang/greedypixel.)|


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### é›¶/å°‘æ ·æœ¬æ³›åŒ– (Zero/Few-shot Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MERGETUNE: Continued fine-tuning of vision-language models|MERGETUNE: è§†è§‰-è¯­è¨€æ¨¡å‹çš„æŒç»­å¾®è°ƒ|Wenqing Wang, Da Li, Xiatian Zhu, Josef Kittler|<https://arxiv.org/pdf/2601.10497v2>|[ä»£ç ](https://github.com/Surrey-UP-Lab/MERGETUNE.)|


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Power to the Clients: Federated Learning in a Dictatorship Setting|[ç¿»è¯‘å¤±è´¥] Power to the Clients: Federated Learning in a Dictatorship Setting|Mohammadsajad Alipour, Mohammad Mohammadi Amiri|<https://arxiv.org/pdf/2510.22149v2>|æ— |
|ğŸ†• å‘å¸ƒ|Enhancing the quality of gauge images captured in smoke and haze scenes through deep learning|é€šè¿‡æ·±åº¦å­¦ä¹ æå‡çƒŸé›¾å’Œé›¾å¤©åœºæ™¯ä¸­ä»ªè¡¨å›¾åƒçš„è´¨é‡|Oscar H. RamÃ­rez-Agudelo, Akshay N. Shewatkar, Edoardo Milana, Roland C. Aydin, Kai Franke|<https://arxiv.org/pdf/2601.10537v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Lunar-G2R: Geometry-to-Reflectance Learning for High-Fidelity Lunar BRDF Estimation|[ç¿»è¯‘å¤±è´¥] Lunar-G2R: Geometry-to-Reflectance Learning for High-Fidelity Lunar BRDF Estimation|Clementine Grethen, Nicolas Menga, Roland Brochard, Geraldine Morin, Simone Gasparini, Jeremy Lebreton, Manuel Sanchez Gestido|<https://arxiv.org/pdf/2601.10449v1>|æ— |
|ğŸ†• å‘å¸ƒ|ReaMIL: Reasoning- and Evidence-Aware Multiple Instance Learning for Whole-Slide Histopathology|ReaMIL: ç”¨äºå…¨åˆ‡ç‰‡ç—…ç†å­¦çš„æ¨ç†ä¸è¯æ®æ„ŸçŸ¥å¤šå®ä¾‹å­¦ä¹ |Hyun Do Jung, Jungwon Choi, Hwiyoung Kim|<https://arxiv.org/pdf/2601.10073v1>|åˆ†æå¤±è´¥|


## å…·èº«æ™ºèƒ½ä¸äº¤äº’è§†è§‰ (Embodied Intelligence & Interactive Vision)


### è§†è§‰å¯¼èˆªä¸è·¯å¾„è§„åˆ’ (Visual Navigation & Path Planning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|UrbanNav: Learning Language-Guided Urban Navigation from Web-Scale Human Trajectories|UrbanNav: ä»Webè§„æ¨¡çš„äººç±»è½¨è¿¹ä¸­å­¦ä¹ è¯­è¨€å¼•å¯¼çš„åŸå¸‚å¯¼èˆª|Yanghong Mei, Yirong Yang, Longteng Guo, Qunbo Wang, Ming-Ming Yu, Xingjian He, Wenjun Wu, Jing Liu|<https://arxiv.org/pdf/2512.09607v2>|åˆ†æå¤±è´¥|


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|BBQ-V: Benchmarking Visual Stereotype Bias in Large Multimodal Models|BBQ-Vï¼šè¯„ä¼°å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ä¸­çš„è§†è§‰åˆ»æ¿å°è±¡åè§|Vishal Narnaware, Ashmal Vayani, Rohit Gupta, Sirnam Swetha, Mubarak Shah|<https://arxiv.org/pdf/2502.08779v3>|æ— |
|ğŸ“ æ›´æ–°|Hot-Start from Pixels: Low-Resolution Visual Tokens for Chinese Language Modeling|Hot-Start from Pixels: ç”¨äºä¸­æ–‡è¯­è¨€å»ºæ¨¡çš„ä½åˆ†è¾¨ç‡ Visual Tokens|Shuyang Xiang, Hao Guan|<https://arxiv.org/pdf/2601.09566v2>|æ— |
|ğŸ“ æ›´æ–°|A Study of Commonsense Reasoning over Visual Object Properties|å…³äºè§†è§‰å¯¹è±¡å±æ€§çš„å¸¸è¯†æ¨ç†ç ”ç©¶|Abhishek Kolari, Mohammadhossein Khojasteh, Yifan Jiang, Floris den Hengst, Filip Ilievski|<https://arxiv.org/pdf/2508.10956v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Advancing Adaptive Multi-Stage Video Anomaly Reasoning: A Benchmark Dataset and Method|æ¨è¿›è‡ªé€‚åº”å¤šé˜¶æ®µè§†é¢‘å¼‚å¸¸æ¨ç†ï¼šä¸€ä¸ªåŸºå‡†æ•°æ®é›†ä¸æ–¹æ³•|Chao Huang, Benfeng Wang, Wei Wang, Jie Wen, Li Shen, Wenqi Ren, Yong Xu, Xiaochun Cao|<https://arxiv.org/pdf/2601.10165v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Enhancing Visual In-Context Learning by Multi-Faceted Fusion|é€šè¿‡å¤šæ–¹é¢èåˆå¢å¼ºè§†è§‰ä¸Šä¸‹æ–‡å­¦ä¹ |Wenwen Liao, Jianbo Yu, Yuansong Wang, Qingchao Jiang, Xiaofeng Yang|<https://arxiv.org/pdf/2601.10107v1>|æ— |
|ğŸ“ æ›´æ–°|Unveiling and Bridging the Functional Perception Gap in MLLMs: Atomic Visual Alignment and Hierarchical Evaluation via PET-Bench|æ­ç¤ºå¹¶å¼¥åˆ MLLMs ä¸­çš„åŠŸèƒ½æ„ŸçŸ¥å·®è·ï¼šé€šè¿‡ PET-Bench å®ç°åŸå­è§†è§‰å¯¹é½ä¸å±‚æ¬¡åŒ–è¯„ä¼°|Zanting Ye, Xiaolong Niu, Xuanbin Wu, Xu Han, Shengyuan Liu, Jing Hao, Zhihao Peng, Hao Sun .etc.|<https://arxiv.org/pdf/2601.02737v2>|[ä»£ç ](https://github.com/yezanting/PET-Bench.)|
|ğŸ†• å‘å¸ƒ|The Spatial Blindspot of Vision-Language Models|Vision-Language Models çš„ç©ºé—´ç›²åŒº|Nahid Alam, Leema Krishna Murali, Siddhant Bharadwaj, Patrick Liu, Timothy Chung, Drishti Sharma, Akshata A, Kranthi Kiran .etc.|<https://arxiv.org/pdf/2601.09954v1>|æ— |


### è·¨æ¨¡æ€æ£€ç´¢ä¸åŒ¹é… (Cross-modal Retrieval & Matching)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Image Complexity-Aware Adaptive Retrieval for Efficient Vision-Language Models|[ç¿»è¯‘å¤±è´¥] Image Complexity-Aware Adaptive Retrieval for Efficient Vision-Language Models|Mikel Williams-Lekuona, Georgina Cosma|<https://arxiv.org/pdf/2512.15372v2>|æ— |
|ğŸ†• å‘å¸ƒ|SVII-3D: Advancing Roadside Infrastructure Inventory with Decimeter-level 3D Localization and Comprehension from Sparse Street Imagery|SVII-3Dï¼šåˆ©ç”¨ç¨€ç–è¡—æ™¯å›¾åƒçš„ decimeter çº§ 3D å®šä½ä¸ç†è§£æ¨è¿›è·¯ä¾§åŸºç¡€è®¾æ–½æ¸…å•|Chong Liu, Luxuan Fu, Yang Jia, Zhen Dong, Bisheng Yang|<https://arxiv.org/pdf/2601.10535v1>|æ— |
|ğŸ†• å‘å¸ƒ|DanQing: An Up-to-Date Large-Scale Chinese Vision-Language Pre-training Dataset|DanQing: ä¸€ä¸ªæœ€æ–°çš„ä¸­æ–‡è§†è§‰-è¯­è¨€é¢„è®­ç»ƒå¤§è§„æ¨¡æ•°æ®é›†|Hengyu Shen, Tiancheng Gu, Bin Qin, Lan Wu, Yuling Wu, Shuo Tan, Zelong Sun, Jun Wang .etc.|<https://arxiv.org/pdf/2601.10305v1>|åˆ†æå¤±è´¥|


### å¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿ (Multimodal Dialogue Systems)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Hierarchical Refinement of Universal Multimodal Attacks on Vision-Language Models|é€šç”¨å¤šæ¨¡æ€æ”»å‡»å¯¹ Vision-Language Models çš„åˆ†å±‚ç»†åŒ–|Peng-Fei Zhang, Zi Huang|<https://arxiv.org/pdf/2601.10313v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Optimizing Multimodal LLMs for Egocentric Video Understanding: A Solution for the HD-EPIC VQA Challenge|é’ˆå¯¹ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒè§†é¢‘ç†è§£çš„å¤šæ¨¡æ€LLMä¼˜åŒ–ï¼šHD-EPIC VQAæŒ‘æˆ˜èµ›çš„è§£å†³æ–¹æ¡ˆ|Sicheng Yang, Yukai Huang, Shitong Sun, Weitong Cai, Jiankang Deng, Jifei Song, Zhensong Zhang|<https://arxiv.org/pdf/2601.10228v1>|[ä»£ç ](https://github.com/YoungSeng/Egocentric-Co-Pilot.)|


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### å·¥ä¸šè§†è§‰æ£€æµ‹ (Industrial Visual Inspection)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Semantic Misalignment in Vision-Language Models under Perceptual Degradation|Perceptual Degradation ä¸‹ Vision-Language Models ä¸­çš„ Semantic Misalignment|Guo Cheng|<https://arxiv.org/pdf/2601.08355v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Wavelet-based Multi-View Fusion of 4D Radar Tensor and Camera for Robust 3D Object Detection|åŸºäºå°æ³¢çš„4D Radar Tensorä¸ç›¸æœºå¤šè§†å›¾èåˆç”¨äºé²æ£’3Dç›®æ ‡æ£€æµ‹|Runwei Guan, Jianan Liu, Shaofeng Liang, Fangqiang Ding, Shanliang Yao, Xiaokai Bai, Daizong Liu, Tao Huang .etc.|<https://arxiv.org/pdf/2512.22972v2>|æ— |


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Jordan-Segmentable Masks: A Topology-Aware definition for characterizing Binary Image Segmentation|Jordan-Segmentable Masksï¼šä¸€ç§ç”¨äºè¡¨å¾ Binary Image Segmentation çš„ Topology-Aware å®šä¹‰|Serena Grazia De Benedictis, Amedeo Altavilla, Nicoletta Del Buono|<https://arxiv.org/pdf/2601.10577v1>|æ— |
|ğŸ†• å‘å¸ƒ|DeepUrban: Interaction-Aware Trajectory Prediction and Planning for Automated Driving by Aerial Imagery|DeepUrbanï¼šåŸºäºAerial Imageryçš„è‡ªåŠ¨é©¾é©¶äº¤äº’æ„ŸçŸ¥è½¨è¿¹é¢„æµ‹ä¸è§„åˆ’|Constantin Selzer, Fabian B. Flohr|<https://arxiv.org/pdf/2601.10554v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|A large-scale heterogeneous 3D magnetic resonance brain imaging dataset for self-supervised learning|é¢å‘è‡ªç›‘ç£å­¦ä¹ çš„å¤§è§„æ¨¡å¼‚æ„3Dç£å…±æŒ¯è„‘æˆåƒæ•°æ®é›†|Stefano Cerri, AsbjÃ¸rn Munk, Jakob Ambsdorf, Julia Machnio, Sebastian NÃ¸rgaard Llambias, Vardan Nersesjan, Christian Hedeager Krag, Peirong Liu .etc.|<https://arxiv.org/pdf/2506.14432v2>|æ— |
|ğŸ†• å‘å¸ƒ|SatMap: Revisiting Satellite Maps as Prior for Online HD Map Construction|SatMapï¼šé‡æ–°å®¡è§†å«æ˜Ÿåœ°å›¾ä½œä¸ºåœ¨çº¿ HD Map Construction çš„å…ˆéªŒ|Kanak Mazumder, Fabian B. Flohr|<https://arxiv.org/pdf/2601.10512v1>|æ— |
|ğŸ“ æ›´æ–°|Mamba Goes HoME: Hierarchical Soft Mixture-of-Experts for 3D Medical Image Segmentation|Mamba Goes HoME: ç”¨äº 3D åŒ»å­¦å›¾åƒåˆ†å‰²çš„åˆ†å±‚è½¯æ··åˆä¸“å®¶æ¨¡å‹|Szymon PÅ‚otka, Gizem Mert, Maciej Chrabaszcz, Ewa Szczurek, Arkadiusz Sitek|<https://arxiv.org/pdf/2507.06363v3>|[ä»£ç ](https://github.com/gmum/MambaHoME.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Deep learning-based ecological analysis of camera trap images is impacted by training data quality and quantity|åŸºäºæ·±åº¦å­¦ä¹ çš„ç›¸æœºé™·é˜±å›¾åƒç”Ÿæ€åˆ†æå—è®­ç»ƒæ•°æ®è´¨é‡å’Œæ•°é‡çš„å½±å“|Peggy A. Bevan, Omiros Pantazis, Holly Pringle, Guilherme Braga Ferreira, Daniel J. Ingram, Emily Madsen, Liam Thomas, Dol Raj Thanet .etc.|<https://arxiv.org/pdf/2408.14348v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|MHub.ai: A Simple, Standardized, and Reproducible Platform for AI Models in Medical Imaging|MHub.ai: ä¸€ä¸ªç”¨äºåŒ»å­¦å½±åƒ AI æ¨¡å‹çš„ç®€å•ã€æ ‡å‡†åŒ–ä¸”å¯å¤ç°çš„å¹³å°|Leonard NÃ¼rnberg, Dennis Bontempi, Suraj Pai, Curtis Lisle, Steve Pieper, Ron Kikinis, Sil van de Leemput, Rahul Soni .etc.|<https://arxiv.org/pdf/2601.10154v1>|æ— |


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|RS2-SAM2: Customized SAM2 for Referring Remote Sensing Image Segmentation|RS2-SAM2: ç”¨äºæŒ‡ä»£é¥æ„Ÿå›¾åƒåˆ†å‰²çš„å®šåˆ¶åŒ–SAM2|Fu Rong, Meng Lan, Qian Zhang, Lefei Zhang|<https://arxiv.org/pdf/2503.07266v4>|æ— |
|ğŸ“ æ›´æ–°|DFIR-DETR: Frequency Domain Enhancement and Dynamic Feature Aggregation for Cross-Scene Small Object Detection|DFIR-DETRï¼šç”¨äºè·¨åœºæ™¯å°ç›®æ ‡æ£€æµ‹çš„é¢‘åŸŸå¢å¼ºä¸åŠ¨æ€ç‰¹å¾èšåˆ|Bo Gao, Jingcheng Tong, Xingsheng Chen, Han Yu, Zichen Li|<https://arxiv.org/pdf/2512.07078v2>|åˆ†æå¤±è´¥|


### åˆ›æ„åª’ä½“ç”Ÿæˆ (Creative Media Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|DW-DGAT: Dynamically Weighted Dual Graph Attention Network for Neurodegenerative Disease Diagnosis|DW-DGATï¼šç”¨äºç¥ç»é€€è¡Œæ€§ç–¾ç—…è¯Šæ–­çš„åŠ¨æ€åŠ æƒåŒå›¾æ³¨æ„åŠ›ç½‘ç»œ|Chengjia Liang, Zhenjiong Wang, Chao Chen, Ruizhi Zhang, Songxi Liang, Hai Xie, Haijun Lei, Zhongwei Huang|<https://arxiv.org/pdf/2601.10001v1>|æ— |


## æ–°å…´ç†è®ºä¸è·¨å­¦ç§‘æ–¹å‘ (Emerging Theory & Interdisciplinary Directions)


### å¯è§£é‡Šè§†è§‰æ™ºèƒ½ (Explainable Visual Intelligence)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Unleashing the Capabilities of Large Vision-Language Models for Intelligent Perception of Roadside Infrastructure|é‡Šæ”¾ Large Vision-Language Models åœ¨è·¯ä¾§åŸºç¡€è®¾æ–½æ™ºèƒ½æ„ŸçŸ¥ä¸­çš„æ½œåŠ›|Luxuan Fu, Chong Liu, Bisheng Yang, Zhen Dong|<https://arxiv.org/pdf/2601.10551v1>|æ— |


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|TBC: A Target-Background Contrast Metric for Low-Altitude Infrared and Visible Image Fusion|TBCï¼šä¸€ç§ç”¨äºä½ç©ºçº¢å¤–ä¸å¯è§å…‰å›¾åƒèåˆçš„ç›®æ ‡-èƒŒæ™¯å¯¹æ¯”åº¦åº¦é‡|Yufeng Xie, Cong Wang|<https://arxiv.org/pdf/2512.15211v2>|åˆ†æå¤±è´¥|

