## [UPDATED!] **2026-01-16** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MHA2MLA-VLM: Enabling DeepSeek's Economical Multi-Head Latent Attention across Vision-Language Models|MHA2MLA-VLM: åœ¨ Vision-Language Models ä¸­å¯ç”¨ DeepSeek çš„ç»æµå‹ Multi-Head Latent Attention|Xiaoran Fan, Zhichao Sun, Tao Ji, Lixing Shen, Tao Gui|<https://arxiv.org/pdf/2601.11464v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Wetland mapping from sparse annotations with satellite image time series and temporal-aware segment anything model|åŸºäºå«æ˜Ÿå›¾åƒæ—¶é—´åºåˆ—å’Œæ—¶åºæ„ŸçŸ¥ Segment Anything Model çš„ç¨€ç–æ ‡æ³¨æ¹¿åœ°åˆ¶å›¾|Shuai Yuan, Tianwu Lin, Shuang Chen, Yu Xia, Peng Qin, Xiangyu Liu, Xiaoqing Xu, Nan Xu .etc.|<https://arxiv.org/pdf/2601.11400v1>|æ— |
|ğŸ“ æ›´æ–°|NanoSD: Edge Efficient Foundation Model for Real Time Image Restoration|NanoSD: è¾¹ç¼˜é«˜æ•ˆå®æ—¶å›¾åƒå¤åŸåŸºç¡€æ¨¡å‹|Subhajit Sanyal, Srinivas Soumitri Miriyala, Akshay Janardan Bankar, Manjunath Arveti, Sowmya Vajrala, Shreyas Pandith, Sravanth Kodavanti, Abhishek Ameta .etc.|<https://arxiv.org/pdf/2601.09823v2>|æ— |
|ğŸ“ æ›´æ–°|FiCo-ITR: bridging fine-grained and coarse-grained image-text retrieval for comparative performance analysis|[ç¿»è¯‘å¤±è´¥] FiCo-ITR: bridging fine-grained and coarse-grained image-text retrieval for comparative performance analysis|Mikel Williams-Lekuona, Georgina Cosma|<https://arxiv.org/pdf/2407.20114v3>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|AviationLMM: A Large Multimodal Foundation Model for Civil Aviation|AviationLMM: æ°‘ç”¨èˆªç©ºå¤§å‹å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹|Wenbin Li, Jingling Wu, Xiaoyong Lin. Jing Chen, Cong Chen|<https://arxiv.org/pdf/2601.09105v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Sparse Data Tree Canopy Segmentation: Fine-Tuning Leading Pretrained Models on Only 150 Images|ç¨€ç–æ•°æ®æ ‘å† åˆ†å‰²ï¼šä»…åœ¨150å¼ å›¾åƒä¸Šå¾®è°ƒé¢†å…ˆçš„é¢„è®­ç»ƒæ¨¡å‹|David Szczecina, Hudson Sun, Anthony Bertnyk, Niloofar Azad, Kyle Gao, Lincoln Linlin Xu|<https://arxiv.org/pdf/2601.10931v1>|åˆ†æå¤±è´¥|


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Assessing Building Heat Resilience Using UAV and Street-View Imagery with Coupled Global Context Vision Transformer|ä½¿ç”¨UAVå’Œè¡—æ™¯å›¾åƒç»“åˆè€¦åˆå…¨å±€ä¸Šä¸‹æ–‡Vision Transformerè¯„ä¼°å»ºç­‘çƒ­éŸ§æ€§|Steffen Knoblauch, Ram Kumar Muthusamy, Hao Li, Iddy Chazua, Benedcto Adamu, Innocent Maholi, Alexander Zipf|<https://arxiv.org/pdf/2601.11357v1>|æ— |
|ğŸ†• å‘å¸ƒ|X-Distill: Cross-Architecture Vision Distillation for Visuomotor Learning|X-Distill: ç”¨äº Visuomotor Learning çš„è·¨æ¶æ„è§†è§‰è’¸é¦|Maanping Shao, Feihong Zhang, Gu Zhang, Baiye Cheng, Zhengrong Xue, Huazhe Xu|<https://arxiv.org/pdf/2601.11269v1>|æ— |
|ğŸ“ æ›´æ–°|VINO: A Unified Visual Generator with Interleaved OmniModal Context|VINO: å…·æœ‰äº¤é”™å…¨æ¨¡æ€ä¸Šä¸‹æ–‡çš„ç»Ÿä¸€è§†è§‰ç”Ÿæˆå™¨|Junyi Chen, Tong He, Zhoujie Fu, Pengfei Wan, Kun Gai, Weicai Ye|<https://arxiv.org/pdf/2601.02358v2>|æ— |
|ğŸ“ æ›´æ–°|Multi-Receptive Field Ensemble with Cross-Entropy Masking for Class Imbalance in Remote Sensing Change Detection|Multi-Receptive Field Ensemble with Cross-Entropy Masking for Remote Sensing Change Detectionä¸­çš„Class Imbalance|Humza Naveed, Xina Zeng, Mitch Bryson, Nagita Mehrseresht|<https://arxiv.org/pdf/2508.10568v2>|[ä»£ç ](https://github.com/humza909/SAM-ECEM)|
|ğŸ†• å‘å¸ƒ|Vision-as-Inverse-Graphics Agent via Interleaved Multimodal Reasoning|åŸºäºäº¤é”™å¤šæ¨¡æ€æ¨ç†çš„è§†è§‰å³é€†å‘å›¾å½¢å­¦Agent|Shaofeng Yin, Jiaxin Ge, Zora Zhiruo Wang, Xiuyu Li, Michael J. Black, Trevor Darrell, Angjoo Kanazawa, Haiwen Feng|<https://arxiv.org/pdf/2601.11109v1>|åˆ†æå¤±è´¥|


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Collaborative Representation Learning for Alignment of Tactile, Language, and Vision Modalities|ç”¨äºè§¦è§‰ã€è¯­è¨€å’Œè§†è§‰æ¨¡æ€å¯¹é½çš„åä½œè¡¨ç¤ºå­¦ä¹ |Yiyun Zhou, Mingjing Xu, Jingwei Shi, Quanjiang Li, Jingyuan Chen|<https://arxiv.org/pdf/2511.11512v4>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|ProSGNeRF: Progressive Dynamic Neural Scene Graph with Frequency Modulated Foundation Model in Urban Scenes|ProSGNeRFï¼šåŸå¸‚åœºæ™¯ä¸­åŸºäºé¢‘ç‡è°ƒåˆ¶åŸºç¡€æ¨¡å‹çš„æ¸è¿›å¼åŠ¨æ€ç¥ç»åœºæ™¯å›¾|Tianchen Deng, Yanbo Wang, Yejia Liu, Chenpeng Su, Jingchuan Wang, Danwei Wang, Shao-Yuan Lo, Weidong Chen|<https://arxiv.org/pdf/2312.09076v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|MMedExpert-R1: Strengthening Multimodal Medical Reasoning via Domain-Specific Adaptation and Clinical Guideline Reinforcement|MMedExpert-R1: é€šè¿‡é¢†åŸŸç‰¹å®šé€‚åº”å’Œä¸´åºŠæŒ‡å—å¼ºåŒ–å¢å¼ºå¤šæ¨¡æ€åŒ»å­¦æ¨ç†|Meidan Ding, Jipeng Zhang, Wenxuan Wang, Haiqin Zhong, Xiaoling Luo, Wenting Chen, Linlin Shen|<https://arxiv.org/pdf/2601.10949v1>|æ— |
|ğŸ“ æ›´æ–°|MoLAN: A Unified Modality-Aware Noise Dynamic Editing Framework for Multimodal Sentiment Analysis|MoLAN: ä¸€ä¸ªç”¨äºå¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æçš„ç»Ÿä¸€æ¨¡æ€æ„ŸçŸ¥å™ªå£°åŠ¨æ€ç¼–è¾‘æ¡†æ¶|Xingle Xu, Yongkang Liu, Dexian Cai, Shi Feng, Xiaocui Yang, Daling Wang, Yifei Zhang|<https://arxiv.org/pdf/2508.09145v2>|[ä»£ç ](https://github.com/betterfly123/MoLAN-Framework.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Self-learned representation-guided latent diffusion model for breast cancer classification in deep ultraviolet whole surface images|[ç¿»è¯‘å¤±è´¥] Self-learned representation-guided latent diffusion model for breast cancer classification in deep ultraviolet whole surface images|Pouya Afshin, David Helminiak, Tianling Niu, Julie M. Jorns, Tina Yen, Bing Yu, Dong Hye Ye|<https://arxiv.org/pdf/2601.10917v1>|æ— |


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### è¯­ä¹‰/å®ä¾‹åˆ†å‰² (Semantic/Instance Segmentation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ReScene4D: Temporally Consistent Semantic Instance Segmentation of Evolving Indoor 3D Scenes|ReScene4Dï¼šæ¼”åŒ–çš„å®¤å†…3Dåœºæ™¯çš„æ—¶é—´ä¸€è‡´æ€§è¯­ä¹‰å®ä¾‹åˆ†å‰²|Emily Steiner, Jianhao Zheng, Henry Howard-Jenkins, Chris Xie, Iro Armeni|<https://arxiv.org/pdf/2601.11508v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Topology-Guaranteed Image Segmentation: Enforcing Connectivity, Genus, and Width Constraints|[ç¿»è¯‘å¤±è´¥] Topology-Guaranteed Image Segmentation: Enforcing Connectivity, Genus, and Width Constraints|Wenxiao Li, Xue-Cheng Tai, Jun Liu|<https://arxiv.org/pdf/2601.11409v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Context-Aware Semantic Segmentation via Stage-Wise Attention|[ç¿»è¯‘å¤±è´¥] Context-Aware Semantic Segmentation via Stage-Wise Attention|Antoine Carreaud, Elias Naha, Arthur Chansel, Nina Lahellec, Jan Skaloud, Adrien Gressin|<https://arxiv.org/pdf/2601.11310v1>|æ— |


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|A Single-Parameter Factor-Graph Image Prior|[ç¿»è¯‘å¤±è´¥] A Single-Parameter Factor-Graph Image Prior|Tianyang Wang, Ender Konukoglu, Hans-Andrea Loeliger|<https://arxiv.org/pdf/2601.08749v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|SAM-pose2seg: Pose-Guided Human Instance Segmentation in Crowds|SAM-pose2seg: å§¿æ€å¼•å¯¼çš„æ‹¥æŒ¤åœºæ™¯äººä½“å®ä¾‹åˆ†å‰²|Constantin Kolomiiets, Miroslav Purkrabek, Jiri Matas|<https://arxiv.org/pdf/2601.08982v2>|[ä»£ç ](https://mirapurkrabek.github.io/BBox-Mask-Pose)|


### å›¾åƒåˆ†ç±»ä¸è¯†åˆ« (Image Classification & Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Towards Implicit Aggregation: Robust Image Representation for Place Recognition in the Transformer Era|[ç¿»è¯‘å¤±è´¥] Towards Implicit Aggregation: Robust Image Representation for Place Recognition in the Transformer Era|Feng Lu, Tong Jin, Canming Ye, Yunpeng Liu, Xiangyuan Lan, Chun Yuan|<https://arxiv.org/pdf/2511.06024v2>|[ä»£ç ](https://github.com/lu-feng/image.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Classification of Chest XRay Diseases through image processing and analysis techniques|é€šè¿‡å›¾åƒå¤„ç†å’Œåˆ†ææŠ€æœ¯çš„èƒ¸éƒ¨Xå…‰ç–¾ç—…åˆ†ç±»|Santiago MartÃ­nez Novoa, MarÃ­a Catalina IbÃ¡Ã±ez, Lina GÃ³mez Mesa, Jeremias Kramer|<https://arxiv.org/pdf/2601.10913v1>|[ä»£ç ](https://github.com/AML4206-MINE20242/Proyecto_AML); åˆ†æå¤±è´¥|


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ShapeR: Robust Conditional 3D Shape Generation from Casual Captures|ShapeR: ä»éšæ„æ‹æ‘„ä¸­è¿›è¡Œé²æ£’çš„æ¡ä»¶3Då½¢çŠ¶ç”Ÿæˆ|Yawar Siddiqui, Duncan Frost, Samir Aroudj, Armen Avetisyan, Henry Howard-Jenkins, Daniel DeTone, Pierre Moulon, Qirui Wu .etc.|<https://arxiv.org/pdf/2601.11514v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|CTest-Metric: A Unified Framework to Assess Clinical Validity of Metrics for CT Report Generation|CTest-Metricï¼šä¸€ä¸ªè¯„ä¼° CT æŠ¥å‘Šç”ŸæˆæŒ‡æ ‡ä¸´åºŠæœ‰æ•ˆæ€§çš„ç»Ÿä¸€æ¡†æ¶|Vanshali Sharma, Andrea Mia Bejar, Gorkem Durak, Ulas Bagci|<https://arxiv.org/pdf/2601.11488v1>|æ— |
|ğŸ†• å‘å¸ƒ|UniX: Unifying Autoregression and Diffusion for Chest X-Ray Understanding and Generation|UniX: ç»Ÿä¸€è‡ªå›å½’å’Œæ‰©æ•£ç”¨äºèƒ¸éƒ¨ X-Ray ç†è§£ä¸ç”Ÿæˆ|Ruiheng Zhang, Jingfeng Yao, Huangxuan Zhao, Hao Yan, Xiao He, Lei Chen, Zhou Wei, Yong Luo .etc.|<https://arxiv.org/pdf/2601.11522v1>|[ä»£ç ](https://github.com/ZrH42/UniX.)|
|ğŸ“ æ›´æ–°|A Safety Report on GPT-5.2, Gemini 3 Pro, Qwen3-VL, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5|å…³äº GPT-5.2ã€Gemini 3 Proã€Qwen3-VLã€Grok 4.1 Fastã€Nano Banana Pro å’Œ Seedream 4.5 çš„å®‰å…¨æŠ¥å‘Š|Xingjun Ma, Yixu Wang, Hengyuan Xu, Yutao Wu, Yifan Ding, Yunhan Zhao, Zilong Wang, Jiabin Hua .etc.|<https://arxiv.org/pdf/2601.10527v2>|æ— |
|ğŸ†• å‘å¸ƒ|SAMannot: A Memory-Efficient, Local, Open-source Framework for Interactive Video Instance Segmentation based on SAM2|SAMannotï¼šä¸€ç§åŸºäºSAM2çš„å†…å­˜é«˜æ•ˆã€æœ¬åœ°åŒ–ã€å¼€æºçš„äº¤äº’å¼è§†é¢‘å®ä¾‹åˆ†å‰²æ¡†æ¶|Gergely Dinya, AndrÃ¡s GelencsÃ©r, Krisztina KupÃ¡n, Clemens KÃ¼pper, KristÃ³f Karacs, Anna GelencsÃ©r-HorvÃ¡th|<https://arxiv.org/pdf/2601.11301v1>|æ— |
|ğŸ†• å‘å¸ƒ|ATATA: One Algorithm to Align Them All|ATATAï¼šä¸€ç§å¯¹é½æ‰€æœ‰æ•°æ®çš„ç®—æ³•|Boyi Pang, Savva Ignatyev, Vladimir Ippolitov, Ramil Khafizov, Yurii Melnik, Oleg Voynov, Maksim Nakhodnov, Aibek Alanov .etc.|<https://arxiv.org/pdf/2601.11194v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|VidLeaks: Membership Inference Attacks Against Text-to-Video Models|VidLeaks: é’ˆå¯¹Text-to-Videoæ¨¡å‹çš„æˆå‘˜æ¨æ–­æ”»å‡»|Li Wang, Wenyu Chen, Ning Yu, Zheng Li, Shanqing Guo|<https://arxiv.org/pdf/2601.11210v1>|æ— |
|ğŸ†• å‘å¸ƒ|CoDance: An Unbind-Rebind Paradigm for Robust Multi-Subject Animation|CoDanceï¼šä¸€ç§ç”¨äºé²æ£’å¤šä¸»ä½“åŠ¨ç”»çš„è§£ç»‘-é‡ç»‘èŒƒå¼|Shuai Tan, Biao Gong, Ke Ma, Yutong Feng, Qiyuan Zhang, Yan Wang, Yujun Shen, Hengshuang Zhao|<https://arxiv.org/pdf/2601.11096v1>|æ— |
|ğŸ†• å‘å¸ƒ|PhysRVG: Physics-Aware Unified Reinforcement Learning for Video Generative Models|PhysRVGï¼šé¢å‘è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„ç‰©ç†æ„ŸçŸ¥ç»Ÿä¸€å¼ºåŒ–å­¦ä¹ |Qiyuan Zhang, Biao Gong, Shuai Tan, Zheng Zhang, Yujun Shen, Xing Zhu, Yuyuan Li, Kelu Yao .etc.|<https://arxiv.org/pdf/2601.11087v1>|æ— |
|ğŸ†• å‘å¸ƒ|Generation of Chest CT pulmonary Nodule Images by Latent Diffusion Models using the LIDC-IDRI Dataset|åŸºäºLIDC-IDRIæ•°æ®é›†åˆ©ç”¨Latent Diffusion Modelsç”Ÿæˆèƒ¸éƒ¨CTè‚ºç»“èŠ‚å›¾åƒ|Kaito Urata, Maiko Nagao, Atsushi Teramoto, Kazuyoshi Imaizumi, Masashi Kondo, Hiroshi Fujita|<https://arxiv.org/pdf/2601.11085v1>|æ— |
|ğŸ†• å‘å¸ƒ|Visual question answering-based image-finding generation for pulmonary nodules on chest CT from structured annotations|åŸºäºç»“æ„åŒ–æ ‡æ³¨çš„èƒ¸éƒ¨CTè‚ºç»“èŠ‚è§†è§‰é—®ç­”å›¾åƒæ£€ç´¢ç”Ÿæˆ|Maiko Nagao, Kaito Urata, Atsushi Teramoto, Kazuyoshi Imaizumi, Masashi Kondo, Hiroshi Fujita|<https://arxiv.org/pdf/2601.11075v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|H-AIM: Orchestrating LLMs, PDDL, and Behavior Trees for Hierarchical Multi-Robot Planning|H-AIMï¼šåè°ƒ LLMsã€PDDL å’Œ Behavior Trees è¿›è¡Œåˆ†å±‚å¤šæœºå™¨äººè§„åˆ’|Haishan Zeng, Peng Li|<https://arxiv.org/pdf/2601.11063v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Your One-Stop Solution for AI-Generated Video Detection|AIç”Ÿæˆè§†é¢‘æ£€æµ‹çš„ä¸€ç«™å¼è§£å†³æ–¹æ¡ˆ|Long Ma, Zihao Xue, Yan Wang, Zhiyuan Yan, Jin Xu, Xiaorui Jiang, Haiyang Yu, Yong Liao .etc.|<https://arxiv.org/pdf/2601.11035v1>|[ä»£ç ](https://github.com/LongMa-2025/AIGVDBench.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|FFP-300K: Scaling First-Frame Propagation for Generalizable Video Editing|FFP-300K: æ‰©å±•é¦–å¸§ä¼ æ’­ä»¥å®ç°å¯æ³›åŒ–çš„è§†é¢‘ç¼–è¾‘|Xijie Huang, Chengming Xu, Donghao Luo, Xiaobin Hu, Peng Tang, Xu Peng, Jiangning Zhang, Chengjie Wang .etc.|<https://arxiv.org/pdf/2601.01720v3>|æ— |
|ğŸ“ æ›´æ–°|Controllable Video Generation: A Survey|[ç¿»è¯‘å¤±è´¥] Controllable Video Generation: A Survey|Yue Ma, Kunyu Feng, Zhongyuan Hu, Xinyu Wang, Yucheng Wang, Mingzhe Zheng, Xuanhua He, Chenyang Zhu .etc.|<https://arxiv.org/pdf/2507.16869v2>|[ä»£ç ](https://github.com/mayuelala/Awesome-Controllable-Video-Generation.); åˆ†æå¤±è´¥|


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|When Are Two Scores Better Than One? Investigating Ensembles of Diffusion Models|å½“ä¸¤ä¸ªåˆ†æ•°ä¼˜äºä¸€ä¸ªæ—¶ï¼Ÿç ”ç©¶ Diffusion Models çš„é›†æˆ|RaphaÃ«l Razafindralambo, RÃ©my Sun, FrÃ©dÃ©ric Precioso, Damien Garreau, Pierre-Alexandre Mattei|<https://arxiv.org/pdf/2601.11444v1>|æ— |
|ğŸ†• å‘å¸ƒ|Simple Models, Rich Representations: Visual Decoding from Primate Intracortical Neural Signals|[ç¿»è¯‘å¤±è´¥] Simple Models, Rich Representations: Visual Decoding from Primate Intracortical Neural Signals|Matteo Ciferri, Matteo Ferrante, Nicola Toschi|<https://arxiv.org/pdf/2601.11108v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|M3DDM+: An improved video outpainting by a modified masking strategy|M3DDM+: é€šè¿‡æ”¹è¿›çš„æ©ç ç­–ç•¥å®ç°æ›´å¥½çš„è§†é¢‘å¤–ç»˜|Takuya Murakawa, Takumi Fukuzawa, Ning Ding, Toru Tamaki|<https://arxiv.org/pdf/2601.11048v1>|[ä»£ç ](https://github.com/tamaki-lab/M3DDM-Plus.)|


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Image-Text Knowledge Modeling for Unsupervised Multi-Scenario Person Re-Identification|[ç¿»è¯‘å¤±è´¥] Image-Text Knowledge Modeling for Unsupervised Multi-Scenario Person Re-Identification|Zhiqi Pang, Lingling Zhao, Yang Liu, Chunyu Wang, Gaurav Sharma|<https://arxiv.org/pdf/2601.11243v1>|æ— |
|ğŸ“ æ›´æ–°|SceneFoundry: Generating Interactive Infinite 3D Worlds|SceneFoundryï¼šç”Ÿæˆå¯äº¤äº’çš„æ— é™3Dä¸–ç•Œ|ChunTeng Chen, YiChen Hsu, YiWen Liu, WeiFang Sun, TsaiChing Ni, ChunYi Lee, Min Sun, YuanFu Yang|<https://arxiv.org/pdf/2601.05810v2>|[ä»£ç ](https://anc891203.github.io/SceneFoundry-Demo); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Beyond Known Fakes: Generalized Detection of AI-Generated Images via Post-hoc Distribution Alignment|è¶…è¶Šå·²çŸ¥ä¼ªé€ ï¼šé€šè¿‡äº‹ååˆ†å¸ƒå¯¹é½å®ç° AI ç”Ÿæˆå›¾åƒçš„å¹¿ä¹‰æ£€æµ‹|Li Wang, Wenyu Chen, Xiangtao Meng, Zheng Li, Shanqing Guo|<https://arxiv.org/pdf/2502.10803v2>|åˆ†æå¤±è´¥|


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Beyond Feature Mapping GAP: Integrating Real HDRTV Priors for Superior SDRTV-to-HDRTV Conversion|è¶…è¶Šç‰¹å¾æ˜ å°„GAPï¼šé›†æˆçœŸå®HDRTVå…ˆéªŒä»¥å®ç°æ›´ä¼˜çš„SDRTV-to-HDRTVè½¬æ¢|Gang He, Kepeng Xu, Li Xu, Siqi Wang, Wenxin Yu, Xianyun Wu|<https://arxiv.org/pdf/2411.10775v3>|åˆ†æå¤±è´¥|


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Beer-Lambert Autoencoder for Unsupervised Stain Representation Learning and Deconvolution in Multi-immunohistochemical Brightfield Histology Images|ç”¨äºå¤šé‡å…ç–«ç»„åŒ–æ˜åœºç»„ç»‡ç—…ç†å›¾åƒçš„æ— ç›‘ç£æŸ“è‰²è¡¨ç¤ºå­¦ä¹ ä¸è§£å·ç§¯çš„ Beer-Lambert è‡ªç¼–ç å™¨|Mark Eastwood, Thomas McKee, Zedong Hu, Sabine Tejpar, Fayyaz Minhas|<https://arxiv.org/pdf/2601.11336v1>|[ä»£ç ](https://github.com/measty/StainQuant.git.)|
|ğŸ†• å‘å¸ƒ|IDDR-NGP: Incorporating Detectors for Distractor Removal with Instant Neural Radiance Field|IDDR-NGP: ç»“åˆæ£€æµ‹å™¨ä¸Instant Neural Radiance Fieldè¿›è¡Œå¹²æ‰°ç‰©å»é™¤|Xianliang Huang, Jiajie Gou, Shuhang Chen, Zhizhou Zhong, Jihong Guan, Shuigeng Zhou|<https://arxiv.org/pdf/2601.11030v1>|æ— |
|ğŸ“ æ›´æ–°|FOF-X: Towards Real-time Detailed Human Reconstruction from a Single Image|[ç¿»è¯‘å¤±è´¥] FOF-X: Towards Real-time Detailed Human Reconstruction from a Single Image|Qiao Feng, Yuanwang Yang, Yebin Liu, Yu-Kun Lai, Jingyu Yang, Kun Li|<https://arxiv.org/pdf/2412.05961v4>|åˆ†æå¤±è´¥|


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|UIKA: Fast Universal Head Avatar from Pose-Free Images|UIKA: æ¥è‡ªæ— å§¿æ€å›¾åƒçš„å¿«é€Ÿé€šç”¨å¤´éƒ¨å¤´åƒ|Zijian Wu, Boyao Zhou, Liangxiao Hu, Hongyu Liu, Yuan Sun, Xuan Wang, Xun Cao, Yujun Shen .etc.|<https://arxiv.org/pdf/2601.07603v2>|[ä»£ç ](https://zijian-wu.github.io/uika-page); åˆ†æå¤±è´¥|


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Think-Clip-Sample: Slow-Fast Frame Selection for Video Understanding|Think-Clip-Sample: ç”¨äºè§†é¢‘ç†è§£çš„ Slow-Fast å¸§é€‰æ‹©|Wenhui Tan, Ruihua Song, Jiaze Li, Jianzhong Ju, Zhenbo Luo|<https://arxiv.org/pdf/2601.11359v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Efficient On-Board Processing of Oblique UAV Video for Rapid Flood Extent Mapping|ç”¨äºå¿«é€Ÿæ´ªæ°´èŒƒå›´æµ‹ç»˜çš„å€¾æ–œ UAV è§†é¢‘é«˜æ•ˆ On-Board å¤„ç†|Vishisht Sharma, Sam Leroux, Lisa Landuyt, Nick Witvrouwen, Pieter Simoens|<https://arxiv.org/pdf/2601.11290v1>|æ— |
|ğŸ“ æ›´æ–°|Video-Browser: Towards Agentic Open-web Video Browsing|Video-Browser: é¢å‘ Agentic å¼€æ”¾ç½‘ç»œè§†é¢‘æµè§ˆ|Zhengyang Liang, Yan Shu, Xiangrui Liu, Minghao Qin, Kaixin Liang, Nicu Sebe, Zheng Liu, Lizi Liao|<https://arxiv.org/pdf/2512.23044v2>|[ä»£ç ](https://github.com/chrisx599/Video-Browser)|
|ğŸ†• å‘å¸ƒ|Convolutions Need Registers Too: HVS-Inspired Dynamic Attention for Video Quality Assessment|å·ç§¯ä¹Ÿéœ€è¦å¯„å­˜å™¨ï¼šå—HVSå¯å‘çš„è§†é¢‘è´¨é‡è¯„ä¼°åŠ¨æ€æ³¨æ„åŠ›|Mayesha Maliha R. Mithila, Mylene C. Q. Farias|<https://arxiv.org/pdf/2601.11045v1>|åˆ†æå¤±è´¥|


### æ—¶åºå»ºæ¨¡ä¸é¢„æµ‹ (Temporal Modeling & Prediction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|FTDMamba: Frequency-Assisted Temporal Dilation Mamba for Unmanned Aerial Vehicle Video Anomaly Detection|[ç¿»è¯‘å¤±è´¥] FTDMamba: Frequency-Assisted Temporal Dilation Mamba for Unmanned Aerial Vehicle Video Anomaly Detection|Cheng-Zhuang Liu, Si-Bao Chen, Qing-Ling Shu, Chris Ding, Jin Tang, Bin Luo|<https://arxiv.org/pdf/2601.11254v1>|[ä»£ç ](https://github.com/uavano/FTDMamba.)|


## è‡ªç›‘ç£ä¸è¡¨å¾å­¦ä¹  (Self-supervised & Representation Learning)


### è·¨æ¨¡æ€ä¸€è‡´æ€§å­¦ä¹  (Cross-modal Consistency Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|InfoAffect: Affective Annotations of Infographics in Information Spread|InfoAffectï¼šä¿¡æ¯ä¼ æ’­ä¸­ä¿¡æ¯å›¾è¡¨çš„æƒ…æ„Ÿæ ‡æ³¨|Zihang Fu, Yunchao Wang, Chenyu Huang, Guodao Sun, Ronghua Liang|<https://arxiv.org/pdf/2511.06404v2>|[ä»£ç ](https://github.com/bulichuchu/InfoAffect-dataset.); åˆ†æå¤±è´¥|


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Meta-Learning Guided Pruning for Few-Shot Plant Pathology on Edge Devices|Meta-Learning Guided Pruning for Edge Devicesä¸Šçš„Few-Shot Plant Pathology|Shahnawaz Alam, Mohammed Mudassir Uddin, Mohammed Kaif Pasha|<https://arxiv.org/pdf/2601.02353v2>|æ— |
|ğŸ†• å‘å¸ƒ|PubMed-OCR: PMC Open Access OCR Annotations|[ç¿»è¯‘å¤±è´¥] PubMed-OCR: PMC Open Access OCR Annotations|Hunter Heidenreich, Yosheb Getachew, Olivia Dinica, Ben Elliott|<https://arxiv.org/pdf/2601.11425v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Democratizing planetary-scale analysis: An ultra-lightweight Earth embedding database for accurate and flexible global land monitoring|æ™®åŠè¡Œæ˜Ÿå°ºåº¦åˆ†æï¼šç”¨äºå‡†ç¡®å’Œçµæ´»å…¨çƒåœŸåœ°ç›‘æµ‹çš„è¶…è½»é‡çº§ Earth embedding æ•°æ®åº“|Shuang Chen, Jie Wang, Shuai Yuan, Jiayang Li, Yu Xia, Yuanhong Liao, Junbo Wei, Jincheng Yuan .etc.|<https://arxiv.org/pdf/2601.11183v1>|æ— |
|ğŸ†• å‘å¸ƒ|GMM-COMET: Continual Source-Free Universal Domain Adaptation via a Mean Teacher and Gaussian Mixture Model-Based Pseudo-Labeling|GMM-COMET: åŸºäºMean Teacherå’ŒGaussian Mixture Modelä¼ªæ ‡ç­¾çš„æŒç»­æ— æºé€šç”¨åŸŸé€‚åº”|Pascal Schlachter, Bin Yang|<https://arxiv.org/pdf/2601.11161v1>|[ä»£ç ](https://github.com/pascalschlachter/GMM-COMET.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|KOCOBrain: Kuramoto-Guided Graph Network for Uncovering Structure-Function Coupling in Adolescent Prenatal Drug Exposure|[ç¿»è¯‘å¤±è´¥] KOCOBrain: Kuramoto-Guided Graph Network for Uncovering Structure-Function Coupling in Adolescent Prenatal Drug Exposure|Badhan Mazumder, Lei Wu, Sir-Lord Wiafe, Vince D. Calhoun, Dong Hye Ye|<https://arxiv.org/pdf/2601.11018v1>|åˆ†æå¤±è´¥|


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|SENSE: Self-Supervised Neural Embeddings for Spatial Ensembles|SENSE: ç”¨äºç©ºé—´é›†æˆçš„è‡ªç›‘ç£ç¥ç»åµŒå…¥|Hamid Gadirov, Lennard Manuel, Steffen Frey|<https://arxiv.org/pdf/2512.11145v2>|åˆ†æå¤±è´¥|


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|ChartComplete: A Taxonomy-based Inclusive Chart Dataset|ChartComplete: ä¸€ä¸ªåŸºäºåˆ†ç±»å­¦çš„åŒ…å®¹æ€§å›¾è¡¨æ•°æ®é›†|Ahmad Mustapha, Charbel Toumieh, Mariette Awad|<https://arxiv.org/pdf/2601.10462v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Attention Debiasing for Token Pruning in Vision Language Models|Vision Language Models ä¸­ Token Pruning çš„ Attention Debiasing|Kai Zhao, Wubang Yuan, Yuchen Lin, Liting Ruan, Xiaofeng Lu, Deng-Ping Fan, Ming-Ming Cheng, Dan Zeng|<https://arxiv.org/pdf/2508.17807v2>|[ä»£ç ](https://github.com/intcomp/attention-bias.)|


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### åˆ†å¸ƒå¤–æ³›åŒ– (Out-of-distribution Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Matching High-Dimensional Geometric Quantiles for Test-Time Adaptation of Transformers and Convolutional Networks Alike|[ç¿»è¯‘å¤±è´¥] Matching High-Dimensional Geometric Quantiles for Test-Time Adaptation of Transformers and Convolutional Networks Alike|Sravan Danda, Aditya Challa, Shlok Mehendale, Snehanshu Saha|<https://arxiv.org/pdf/2601.11022v1>|åˆ†æå¤±è´¥|


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SUG-Occ: An Explicit Semantics and Uncertainty Guided Sparse Learning Framework for Real-Time 3D Occupancy Prediction|SUG-Occ: ä¸€ç§æ˜¾å¼è¯­ä¹‰ä¸ä¸ç¡®å®šæ€§å¼•å¯¼çš„ç¨€ç–å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºå®æ—¶ 3D å æ®é¢„æµ‹|Hanlin Wu, Pengfei Lin, Ehsan Javanmardi, Nanren Bao, Bo Qian, Hao Si, Manabu Tsukada|<https://arxiv.org/pdf/2601.11396v1>|æ— |
|ğŸ†• å‘å¸ƒ|Heterogeneous Uncertainty-Guided Composed Image Retrieval with Fine-Grained Probabilistic Learning|åŸºäºç»†ç²’åº¦æ¦‚ç‡å­¦ä¹ çš„å¼‚æ„ä¸ç¡®å®šæ€§å¼•å¯¼ç»„åˆå›¾åƒæ£€ç´¢|Haomiao Tang, Jinpeng Wang, Minyi Zhao, Guanghao Meng, Ruisheng Luo, Long Chen, Shu-Tao Xia|<https://arxiv.org/pdf/2601.11393v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Graph Smoothing for Enhanced Local Geometry Learning in Point Cloud Analysis|ç”¨äºç‚¹äº‘åˆ†æä¸­å¢å¼ºå±€éƒ¨å‡ ä½•å­¦ä¹ çš„Graph Smoothing|Shangbo Yuan, Jie Xu, Ping Hu, Xiaofeng Zhu, Na Zhao|<https://arxiv.org/pdf/2601.11102v1>|æ— |
|ğŸ†• å‘å¸ƒ|RobuMTL: Enhancing Multi-Task Learning Robustness Against Weather Conditions|RobuMTL: å¢å¼ºå¤šä»»åŠ¡å­¦ä¹ å¯¹å¤©æ°”æ¡ä»¶çš„é²æ£’æ€§|Tasneem Shaffee, Sherief Reda|<https://arxiv.org/pdf/2601.10921v1>|åˆ†æå¤±è´¥|


### é›¶/å°‘æ ·æœ¬æ³›åŒ– (Zero/Few-shot Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|MERGETUNE: Continued fine-tuning of vision-language models|MERGETUNE: è§†è§‰-è¯­è¨€æ¨¡å‹çš„æŒç»­å¾®è°ƒ|Wenqing Wang, Da Li, Xiatian Zhu, Josef Kittler|<https://arxiv.org/pdf/2601.10497v2>|[ä»£ç ](https://github.com/Surrey-UP-Lab/MERGETUNE.); åˆ†æå¤±è´¥|


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è·¨æ¨¡æ€æ£€ç´¢ä¸åŒ¹é… (Cross-modal Retrieval & Matching)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Language-Agnostic Visual Embeddings for Cross-Script Handwriting Retrieval|[ç¿»è¯‘å¤±è´¥] Language-Agnostic Visual Embeddings for Cross-Script Handwriting Retrieval|Fangke Chen, Tianhao Dong, Sirry Chen, Guobin Zhang, Yishu Zhang, Yining Chen|<https://arxiv.org/pdf/2601.11248v1>|æ— |


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Better Language Models Exhibit Higher Visual Alignment|æ›´å¥½çš„è¯­è¨€æ¨¡å‹è¡¨ç°å‡ºæ›´é«˜çš„è§†è§‰å¯¹é½|Jona Ruthardt, Gertjan J. Burghouts, Serge Belongie, Yuki M. Asano|<https://arxiv.org/pdf/2410.07173v3>|æ— |


### å¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿ (Multimodal Dialogue Systems)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Cascading multi-agent anomaly detection in surveillance systems via vision-language models and embedding-based classification|åŸºäºvision-language modelså’Œembedding-based classificationçš„ç›‘æ§ç³»ç»Ÿä¸­çº§è”å¤šagentå¼‚å¸¸æ£€æµ‹|Tayyab Rehman, Giovanni De Gasperis, Aly Shmahell|<https://arxiv.org/pdf/2601.06204v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|PatientVLM Meets DocVLM: Pre-Consultation Dialogue Between Vision-Language Models for Efficient Diagnosis|PatientVLM é‡è§ DocVLMï¼šç”¨äºé«˜æ•ˆè¯Šæ–­çš„ Vision-Language Models ä¹‹é—´çš„é¢„è¯Šå¯¹è¯|K Lokesh, Abhirama Subramanyam Penamakuri, Uday Agarwal, Apoorva Challa, Shreya K Gowda, Somesh Gupta, Anand Mishra|<https://arxiv.org/pdf/2601.10945v1>|åˆ†æå¤±è´¥|


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Generative Scenario Rollouts for End-to-End Autonomous Driving|ç”¨äºç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶çš„ç”Ÿæˆå¼åœºæ™¯æ¨æ¼”|Rajeev Yasarla, Deepti Hegde, Shizhong Han, Hsin-Pai Cheng, Yunxiao Shi, Meysam Sadeghigooghari, Shweta Mahajan, Apratim Bhattacharyya .etc.|<https://arxiv.org/pdf/2601.11475v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Causal-SAM-LLM: Large Language Models as Causal Reasoners for Robust Medical Segmentation|Causal-SAM-LLM: ä½œä¸ºå› æœæ¨ç†å™¨çš„ Large Language Models ç”¨äºé²æ£’åŒ»å­¦åˆ†å‰²|Tao Tang, Shijie Xu, Jionglong Su, Zhixiang Lu|<https://arxiv.org/pdf/2507.03585v2>|æ— |
|ğŸ“ æ›´æ–°|Exploring the Challenge and Value of Deep Learning in Automated Skin Disease Diagnosis|æ¢ç´¢Deep Learningåœ¨è‡ªåŠ¨åŒ–çš®è‚¤ç—…è¯Šæ–­ä¸­çš„æŒ‘æˆ˜ä¸ä»·å€¼|Runhao Liu, Ziming Chen, Guangzhen Yao, Peng Zhang|<https://arxiv.org/pdf/2510.03869v2>|æ— |
|ğŸ“ æ›´æ–°|A Classification-Aware Super-Resolution Framework for Ship Targets in SAR Imagery|ä¸€ç§é¢å‘SARå›¾åƒä¸­èˆ¹èˆ¶ç›®æ ‡çš„åˆ†ç±»æ„ŸçŸ¥è¶…åˆ†è¾¨ç‡æ¡†æ¶|Ch Muhammad Awais, Marco Reggiannini, Davide Moroni, Oktay Karakus|<https://arxiv.org/pdf/2508.06407v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Bio-inspired fine-tuning for selective transfer learning in image classification|å—ç”Ÿç‰©å¯å‘çš„å›¾åƒåˆ†ç±»é€‰æ‹©æ€§è¿ç§»å­¦ä¹ å¾®è°ƒ|Ana Davila, Jacinto Colan, Yasuhisa Hasegawa|<https://arxiv.org/pdf/2601.11235v1>|[ä»£ç ](https://github.com/davilac/BioTune.)|
|ğŸ“ æ›´æ–°|V2X-Radar: A Multi-modal Dataset with 4D Radar for Cooperative Perception|V2X-Radar: ä¸€ä¸ªç”¨äºååŒæ„ŸçŸ¥çš„åŒ…å«4D Radarçš„å¤šæ¨¡æ€æ•°æ®é›†|Lei Yang, Xinyu Zhang, Jun Li, Chen Wang, Jiaqi Ma, Zhiying Song, Tong Zhao, Ziying Song .etc.|<https://arxiv.org/pdf/2411.10962v5>|[ä»£ç ](https://github.com/yanglei18/V2X-Radar.); åˆ†æå¤±è´¥|


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|PRISM-CAFO: Prior-conditioned Remote-sensing Infrastructure Segmentation and Mapping for CAFOs|PRISM-CAFO: åŸºäºå…ˆéªŒæ¡ä»¶çš„CAFOé¥æ„ŸåŸºç¡€è®¾æ–½åˆ†å‰²ä¸åˆ¶å›¾|Oishee Bintey Hoque, Nibir Chandra Mandal, Kyle Luong, Amanda Wilson, Samarth Swarup, Madhav Marathe, Abhijin Adiga|<https://arxiv.org/pdf/2601.11451v1>|æ— |
|ğŸ†• å‘å¸ƒ|SME-YOLO: A Real-Time Detector for Tiny Defect Detection on PCB Surfaces|SME-YOLO: ä¸€ç§ç”¨äºPCBè¡¨é¢å¾®å°ç¼ºé™·æ£€æµ‹çš„å®æ—¶æ£€æµ‹å™¨|Meng Han|<https://arxiv.org/pdf/2601.11402v1>|æ— |
|ğŸ“ æ›´æ–°|A Synthetic Benchmark for Collaborative 3D Semantic Occupancy Prediction in V2X-Enabled Autonomous Driving|é¢å‘V2Xè‡ªåŠ¨é©¾é©¶çš„ååŒ3Dè¯­ä¹‰å ç”¨é¢„æµ‹åˆæˆåŸºå‡†|Hanlin Wu, Pengfei Lin, Ehsan Javanmardi, Naren Bao, Bo Qian, Hao Si, Manabu Tsukada|<https://arxiv.org/pdf/2506.17004v3>|[ä»£ç ](https://github.com/tlab-wide/Co3SOP)|
|ğŸ“ æ›´æ–°|TriDF: Triplane-Accelerated Density Fields for Few-Shot Remote Sensing Novel View Synthesis|TriDFï¼šç”¨äºå°‘æ ·æœ¬é¥æ„Ÿæ–°è§†å›¾åˆæˆçš„TriplaneåŠ é€Ÿå¯†åº¦åœº|Jiaming Kang, Keyan Chen, Zhengxia Zou, Zhenwei Shi|<https://arxiv.org/pdf/2503.13347v3>|[ä»£ç ](https://github.com/kanehub/TriDF)|


## æ–°å…´ç†è®ºä¸è·¨å­¦ç§‘æ–¹å‘ (Emerging Theory & Interdisciplinary Directions)


### è§†è§‰è®¤çŸ¥è®¡ç®— (Visual Cognitive Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Map2Thought: Explicit 3D Spatial Reasoning via Metric Cognitive Maps|Map2Thought: é€šè¿‡åº¦é‡è®¤çŸ¥åœ°å›¾è¿›è¡Œæ˜¾å¼3Dç©ºé—´æ¨ç†|Xiangjun Gao, Zhensong Zhang, Dave Zhenyu Chen, Songcen Xu, Long Quan, Eduardo PÃ©rez-Pellitero, Youngkyoon Jang|<https://arxiv.org/pdf/2601.11442v1>|åˆ†æå¤±è´¥|


### ç¥ç»-ç¬¦å·è§†è§‰ (Neuro-symbolic Vision)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Enhancing Vision Language Models with Logic Reasoning for Situational Awareness|åˆ©ç”¨é€»è¾‘æ¨ç†å¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹ä»¥å®ç°æ€åŠ¿æ„ŸçŸ¥|Pavana Pradeep, Krishna Kant, Suya Yu|<https://arxiv.org/pdf/2601.11322v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|SoLA-Vision: Fine-grained Layer-wise Linear Softmax Hybrid Attention|SoLA-Vision: ç»†ç²’åº¦é€å±‚çº¿æ€§ Softmax æ··åˆæ³¨æ„åŠ›|Ruibang Li, Guan Luo, Yiwei Zhang, Jin Gao, Bing Li, Weiming Hu|<https://arxiv.org/pdf/2601.11164v1>|åˆ†æå¤±è´¥|

