## [UPDATED!] **2026-01-18** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Improved cystic hygroma detection from prenatal imaging using ultrasound-specific self-supervised representation learning|åˆ©ç”¨è¶…å£°ç‰¹å®šè‡ªç›‘ç£è¡¨å¾å­¦ä¹ æ”¹è¿›äº§å‰å½±åƒä¸­çš„å›Šæ€§æ°´ç˜¤æ£€æµ‹|Youssef Megahed, Robin Ducharme, Inok Lee, Inbal Willner, Adrian D. C. Chan, Mark Walker, Steven Hawken|<https://arxiv.org/pdf/2512.22730v2>|æ— |
|ğŸ†• å‘å¸ƒ|MMDeepResearch-Bench: A Benchmark for Multimodal Deep Research Agents|MMDeepResearch-Bench: å¤šæ¨¡æ€æ·±åº¦ç ”ç©¶AgentåŸºå‡†|Peizhou Huang, Zixuan Zhong, Zhongwei Wan, Donghao Zhou, Samiul Alam, Xin Wang, Zexin Li, Zhihao Dou .etc.|<https://arxiv.org/pdf/2601.12346v1>|æ— |
|ğŸ“ æ›´æ–°|SLIM-Brain: A Data- and Training-Efficient Foundation Model for fMRI Data Analysis|SLIM-Brainï¼šä¸€ç§ç”¨äº fMRI æ•°æ®åˆ†æçš„æ•°æ®å’Œè®­ç»ƒé«˜æ•ˆçš„åŸºç¡€æ¨¡å‹|Mo Wang, Junfeng Xia, Wenhao Ye, Enyu Liu, Kaining Peng, Jianfeng Feng, Quanying Liu, Hongkai Wen|<https://arxiv.org/pdf/2512.21881v2>|æ— |
|ğŸ†• å‘å¸ƒ|Concepts from Representations: Post-hoc Concept Bottleneck Models via Sparse Decomposition of Visual Representations|Concepts from Representations: é€šè¿‡è§†è§‰è¡¨ç¤ºçš„ç¨€ç–åˆ†è§£è¿›è¡Œäº‹å Concept Bottleneck Models|Shizhan Gong, Xiaofan Zhang, Qi Dou|<https://arxiv.org/pdf/2601.12303v1>|æ— |
|ğŸ“ æ›´æ–°|Improved cystic hygroma detection from prenatal imaging using ultrasound-specific self-supervised representation learning|åˆ©ç”¨è¶…å£°ç‰¹å®šè‡ªç›‘ç£è¡¨å¾å­¦ä¹ æ”¹è¿›äº§å‰å½±åƒä¸­çš„å›Šæ€§æ°´ç˜¤æ£€æµ‹|Youssef Megahed, Robin Ducharme, Inok Lee, Inbal Willner, Adrian D. C. Chan, Mark Walker, Steven Hawken|<https://arxiv.org/pdf/2512.22730v2>|æ— |
|ğŸ†• å‘å¸ƒ|MMDeepResearch-Bench: A Benchmark for Multimodal Deep Research Agents|MMDeepResearch-Bench: å¤šæ¨¡æ€æ·±åº¦ç ”ç©¶AgentåŸºå‡†|Peizhou Huang, Zixuan Zhong, Zhongwei Wan, Donghao Zhou, Samiul Alam, Xin Wang, Zexin Li, Zhihao Dou .etc.|<https://arxiv.org/pdf/2601.12346v1>|æ— |
|ğŸ“ æ›´æ–°|SLIM-Brain: A Data- and Training-Efficient Foundation Model for fMRI Data Analysis|SLIM-Brainï¼šä¸€ç§ç”¨äºfMRIæ•°æ®åˆ†æçš„æ•°æ®å’Œè®­ç»ƒé«˜æ•ˆçš„åŸºç¡€æ¨¡å‹|Mo Wang, Junfeng Xia, Wenhao Ye, Enyu Liu, Kaining Peng, Jianfeng Feng, Quanying Liu, Hongkai Wen|<https://arxiv.org/pdf/2512.21881v2>|æ— |
|ğŸ†• å‘å¸ƒ|Concepts from Representations: Post-hoc Concept Bottleneck Models via Sparse Decomposition of Visual Representations|Concepts from Representations: é€šè¿‡è§†è§‰è¡¨ç¤ºçš„ç¨€ç–åˆ†è§£è¿›è¡Œäº‹å Concept Bottleneck Models|Shizhan Gong, Xiaofan Zhang, Qi Dou|<https://arxiv.org/pdf/2601.12303v1>|æ— |


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|A Hierarchical Benchmark of Foundation Models for Dermatology|çš®è‚¤ç§‘åŸºç¡€æ¨¡å‹çš„åˆ†å±‚åŸºå‡†|Furkan Yuceyalcin, Abdurrahim Yilmaz, Burak Temelkuran|<https://arxiv.org/pdf/2601.12382v1>|æ— |
|ğŸ†• å‘å¸ƒ|DepthCropSeg++: Scaling a Crop Segmentation Foundation Model With Depth-Labeled Data|DepthCropSeg++: åˆ©ç”¨Depth-Labeled Dataæ‰©å±•Crop Segmentation Foundation Model|Jiafei Zhang, Songliang Cao, Binghui Xu, Yanan Li, Weiwei Jia, Tingting Wu, Hao Lu, Weijuan Hu .etc.|<https://arxiv.org/pdf/2601.12366v1>|æ— |
|ğŸ“ æ›´æ–°|TennisTV: Do Multimodal Large Language Models Understand Tennis Rallies?|TennisTV: å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç†è§£ç½‘çƒå¯¹æ‹‰å—ï¼Ÿ|Zhongyuan Bao, Lejun Zhang|<https://arxiv.org/pdf/2509.15602v3>|æ— |
|ğŸ†• å‘å¸ƒ|A Hierarchical Benchmark of Foundation Models for Dermatology|çš®è‚¤ç§‘åŸºç¡€æ¨¡å‹çš„åˆ†å±‚åŸºå‡†|Furkan Yuceyalcin, Abdurrahim Yilmaz, Burak Temelkuran|<https://arxiv.org/pdf/2601.12382v1>|æ— |
|ğŸ†• å‘å¸ƒ|DepthCropSeg++: Scaling a Crop Segmentation Foundation Model With Depth-Labeled Data|DepthCropSeg++: åˆ©ç”¨Depth-Labeled Dataæ‰©å±•Crop Segmentation Foundation Model|Jiafei Zhang, Songliang Cao, Binghui Xu, Yanan Li, Weiwei Jia, Tingting Wu, Hao Lu, Weijuan Hu .etc.|<https://arxiv.org/pdf/2601.12366v1>|æ— |
|ğŸ“ æ›´æ–°|TennisTV: Do Multimodal Large Language Models Understand Tennis Rallies?|TennisTVï¼šå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç†è§£ç½‘çƒå¯¹æ‹‰å—ï¼Ÿ|Zhongyuan Bao, Lejun Zhang|<https://arxiv.org/pdf/2509.15602v3>|æ— |


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|AgenticPruner: MAC-Constrained Neural Network Compression via LLM-Driven Strategy Search|AgenticPruner: é€šè¿‡ LLM é©±åŠ¨çš„ç­–ç•¥æœç´¢å®ç° MAC çº¦æŸçš„ç¥ç»ç½‘ç»œå‹ç¼©|Shahrzad Esmat, Mahdi Banisharif, Ali Jannesari|<https://arxiv.org/pdf/2601.12272v1>|æ— |
|ğŸ†• å‘å¸ƒ|AgenticPruner: MAC-Constrained Neural Network Compression via LLM-Driven Strategy Search|AgenticPruner: é€šè¿‡ LLM é©±åŠ¨çš„ç­–ç•¥æœç´¢å®ç° MAC çº¦æŸçš„ç¥ç»ç½‘ç»œå‹ç¼©|Shahrzad Esmat, Mahdi Banisharif, Ali Jannesari|<https://arxiv.org/pdf/2601.12272v1>|æ— |
|ğŸ†• å‘å¸ƒ|An Innovative Framework for Breast Cancer Detection Using Pyramid Adaptive Atrous Convolution, Transformer Integration, and Multi-Scale Feature Fusion|ä¸€ç§ä½¿ç”¨Pyramid Adaptive Atrous Convolutionã€Transformer Integrationå’ŒMulti-Scale Feature Fusionè¿›è¡Œä¹³è…ºç™Œæ£€æµ‹çš„åˆ›æ–°æ¡†æ¶|Ehsan Sadeghi Pour, Mahdi Esmaeili, Morteza Romoozi|<https://arxiv.org/pdf/2601.12249v1>|æ— |


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### å›¾åƒåˆ†ç±»ä¸è¯†åˆ« (Image Classification & Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Normalized Conditional Mutual Information Surrogate Loss for Deep Neural Classifiers|[ç¿»è¯‘å¤±è´¥] Normalized Conditional Mutual Information Surrogate Loss for Deep Neural Classifiers|Linfeng Ye, Zhixiang Chi, Konstantinos N. Plataniotis, En-hui Yang|<https://arxiv.org/pdf/2601.02543v3>|æ— |
|ğŸ“ æ›´æ–°|Normalized Conditional Mutual Information Surrogate Loss for Deep Neural Classifiers|[ç¿»è¯‘å¤±è´¥] Normalized Conditional Mutual Information Surrogate Loss for Deep Neural Classifiers|Linfeng Ye, Zhixiang Chi, Konstantinos N. Plataniotis, En-hui Yang|<https://arxiv.org/pdf/2601.02543v3>|æ— |


### è¯­ä¹‰/å®ä¾‹åˆ†å‰² (Semantic/Instance Segmentation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Large-scale EM Benchmark for Multi-Organelle Instance Segmentation in the Wild|é¢å‘é‡å¤–å¤šç»†èƒå™¨å®ä¾‹åˆ†å‰²çš„å¤§è§„æ¨¡EM Benchmark|Yanrui Lu, Danyang Chen, Haowen Xiao, Jiarui Zhu, Fukang Ge, Binqian Zou, Jiali Guan, Jiayin Liang .etc.|<https://arxiv.org/pdf/2601.12464v1>|æ— |
|ğŸ†• å‘å¸ƒ|Large-scale EM Benchmark for Multi-Organelle Instance Segmentation in the Wild|é¢å‘é‡å¤–å¤šç»†èƒå™¨å®ä¾‹åˆ†å‰²çš„å¤§è§„æ¨¡EMåŸºå‡†|Yanrui Lu, Danyang Chen, Haowen Xiao, Jiarui Zhu, Fukang Ge, Binqian Zou, Jiali Guan, Jiayin Liang .etc.|<https://arxiv.org/pdf/2601.12464v1>|æ— |


### ç›®æ ‡æ£€æµ‹ä¸å®šä½ (Object Detection & Localization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|CD-TWINSAFE: A ROS-enabled Digital Twin for Scene Understanding and Safety Emerging V2I Technology|CD-TWINSAFE: ä¸€ç§æ”¯æŒROSçš„ç”¨äºåœºæ™¯ç†è§£å’Œå®‰å…¨æ–°å…´V2IæŠ€æœ¯çš„æ•°å­—å­ªç”Ÿ|Amro Khaled, Farah Khaled, Omar Riad, Catherine M. Elias|<https://arxiv.org/pdf/2601.12373v1>|æ— |
|ğŸ†• å‘å¸ƒ|CD-TWINSAFE: A ROS-enabled Digital Twin for Scene Understanding and Safety Emerging V2I Technology|CD-TWINSAFE: ä¸€ç§æ”¯æŒROSçš„ç”¨äºåœºæ™¯ç†è§£å’Œå®‰å…¨æ–°å…´V2IæŠ€æœ¯çš„æ•°å­—å­ªç”Ÿ|Amro Khaled, Farah Khaled, Omar Riad, Catherine M. Elias|<https://arxiv.org/pdf/2601.12373v1>|æ— |


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Turbo-GoDec: Exploiting the Cluster Sparsity Prior for Hyperspectral Anomaly Detection|Turbo-GoDec: åˆ©ç”¨èšç±»ç¨€ç–å…ˆéªŒè¿›è¡Œé«˜å…‰è°±å¼‚å¸¸æ£€æµ‹|Jiahui Sheng, Xiaorun Li, Shuhan Chen|<https://arxiv.org/pdf/2601.12337v1>|[ä»£ç ](https://github.com/jiahuisheng/Turbo-GoDec.)|
|ğŸ†• å‘å¸ƒ|GazeFormer-MoE: Context-Aware Gaze Estimation via CLIP and MoE Transformer|GazeFormer-MoE: åŸºäº CLIP å’Œ MoE Transformer çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥è§†çº¿ä¼°è®¡|Xinyuan Zhao, Xianrui Chen, Ahmad Chaddad|<https://arxiv.org/pdf/2601.12316v1>|æ— |
|ğŸ†• å‘å¸ƒ|Turbo-GoDec: Exploiting the Cluster Sparsity Prior for Hyperspectral Anomaly Detection|Turbo-GoDec: åˆ©ç”¨èšç±»ç¨€ç–å…ˆéªŒè¿›è¡Œé«˜å…‰è°±å¼‚å¸¸æ£€æµ‹|Jiahui Sheng, Xiaorun Li, Shuhan Chen|<https://arxiv.org/pdf/2601.12337v1>|[ä»£ç ](https://github.com/jiahuisheng/Turbo-GoDec.)|
|ğŸ†• å‘å¸ƒ|GazeFormer-MoE: Context-Aware Gaze Estimation via CLIP and MoE Transformer|GazeFormer-MoE: åŸºäº CLIP å’Œ MoE Transformer çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥è§†çº¿ä¼°è®¡|Xinyuan Zhao, Xianrui Chen, Ahmad Chaddad|<https://arxiv.org/pdf/2601.12316v1>|æ— |
|ğŸ†• å‘å¸ƒ|Breaking Coordinate Overfitting: Geometry-Aware WiFi Sensing for Cross-Layout 3D Pose Estimation|æ‰“ç ´åæ ‡è¿‡æ‹Ÿåˆï¼šç”¨äºè·¨å¸ƒå±€ 3D å§¿æ€ä¼°è®¡çš„å‡ ä½•æ„ŸçŸ¥ WiFi æ„ŸçŸ¥|Songming Jia, Yan Lu, Bin Liu, Xiang Zhang, Peng Zhao, Xinmeng Tang, Yelin Wei, Jinyang Huang .etc.|<https://arxiv.org/pdf/2601.12252v1>|æ— |


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Knot So Simple: A Minimalistic Environment for Spatial Reasoning|Knot So Simple: ä¸€ä¸ªç”¨äºç©ºé—´æ¨ç†çš„æç®€ç¯å¢ƒ|Zizhao Chen, Yoav Artzi|<https://arxiv.org/pdf/2505.18028v3>|[ä»£ç ](https://github.com/lil-lab/knotgym.)|
|ğŸ†• å‘å¸ƒ|ReWorld: Multi-Dimensional Reward Modeling for Embodied World Models|ReWorld: ç”¨äºå…·èº«ä¸–ç•Œæ¨¡å‹çš„å¤šç»´å¥–åŠ±å»ºæ¨¡|Baorui Peng, Wenyao Zhang, Liang Xu, Zekun Qi, Jiazhao Zhang, Hongsi Liu, Wenjun Zeng, Xin Jin|<https://arxiv.org/pdf/2601.12428v1>|æ— |
|ğŸ†• å‘å¸ƒ|Utilizing the Score of Data Distribution for Hyperspectral Anomaly Detection|åˆ©ç”¨æ•°æ®åˆ†å¸ƒçš„åˆ†æ•°è¿›è¡Œé«˜å…‰è°±å¼‚å¸¸æ£€æµ‹|Jiahui Sheng, Yidan Shi, Shu Xiang, Xiaorun Li, Shuhan Chen|<https://arxiv.org/pdf/2601.12379v1>|[ä»£ç ](https://github.com/jiahuisheng/ScoreAD.)|
|ğŸ“ æ›´æ–°|Generative Diffusion Contrastive Network for Multi-View Clustering|ç”¨äºå¤šè§†å›¾èšç±»çš„ç”Ÿæˆæ‰©æ•£å¯¹æ¯”ç½‘ç»œ|Jian Zhu, Xin Zou, Xi Wang, Lei Liu, Chang Tang, Li-Rong Dai|<https://arxiv.org/pdf/2509.09527v2>|[ä»£ç ](https://github.com/HackerHyper/GDCN.)|
|ğŸ“ æ›´æ–°|A new baseline for edge detection: Make Encoder-Decoder great again|è¾¹ç¼˜æ£€æµ‹çš„æ–°åŸºå‡†ï¼šè®© Encoder-Decoder å†æ¬¡ä¼Ÿå¤§|Yachuan Li, Xavier Soria Pomab, Yongke Xi, Guanlin Li, Chaozhi Yang, Qian Xiao, Yun Bai, Zongmin LI|<https://arxiv.org/pdf/2409.14976v3>|[ä»£ç ](https://github.com/Li-yachuan/NBED.)|
|ğŸ†• å‘å¸ƒ|S^2F-Net:A Robust Spatial-Spectral Fusion Framework for Cross-Model AIGC Detection|S^2F-Net: ä¸€ç§ç”¨äºè·¨æ¨¡æ€ AIGC æ£€æµ‹çš„é²æ£’ç©ºé—´-å…‰è°±èåˆæ¡†æ¶|Xiangyu Hu, Yicheng Hong, Hongchuang Zheng, Wenjun Zeng, Bingyao Liu|<https://arxiv.org/pdf/2601.12313v1>|æ— |
|ğŸ†• å‘å¸ƒ|LegacyAvatars: Volumetric Face Avatars For Traditional Graphics Pipelines|LegacyAvatars: ç”¨äºä¼ ç»Ÿå›¾å½¢æµæ°´çº¿çš„ä½“ç§¯äººè„¸ Avatar|Safa C. Medin, Gengyan Li, Ziqian Bai, Ruofei Du, Leonhard Helminger, Yinda Zhang, Stephan J. Garbin, Philip L. Davidson .etc.|<https://arxiv.org/pdf/2601.12285v1>|æ— |
|ğŸ†• å‘å¸ƒ|SDiT: Semantic Region-Adaptive for Diffusion Transformers|SDiT: é¢å‘ Diffusion Transformers çš„è¯­ä¹‰åŒºåŸŸè‡ªé€‚åº”|Bowen Lin, Fanjiang Ye, Yihua Liu, Zhenghui Guo, Boyuan Zhang, Weijian Zheng, Yufan Xu, Tiancheng Xing .etc.|<https://arxiv.org/pdf/2601.12283v1>|æ— |
|ğŸ“ æ›´æ–°|Knot So Simple: A Minimalistic Environment for Spatial Reasoning|Knot So Simple: ä¸€ä¸ªç”¨äºç©ºé—´æ¨ç†çš„æç®€ç¯å¢ƒ|Zizhao Chen, Yoav Artzi|<https://arxiv.org/pdf/2505.18028v3>|[ä»£ç ](https://github.com/lil-lab/knotgym.)|
|ğŸ†• å‘å¸ƒ|ReWorld: Multi-Dimensional Reward Modeling for Embodied World Models|ReWorld: ç”¨äºå…·èº«ä¸–ç•Œæ¨¡å‹çš„å¤šç»´å¥–åŠ±å»ºæ¨¡|Baorui Peng, Wenyao Zhang, Liang Xu, Zekun Qi, Jiazhao Zhang, Hongsi Liu, Wenjun Zeng, Xin Jin|<https://arxiv.org/pdf/2601.12428v1>|æ— |
|ğŸ†• å‘å¸ƒ|Utilizing the Score of Data Distribution for Hyperspectral Anomaly Detection|åˆ©ç”¨æ•°æ®åˆ†å¸ƒçš„åˆ†æ•°è¿›è¡Œé«˜å…‰è°±å¼‚å¸¸æ£€æµ‹|Jiahui Sheng, Yidan Shi, Shu Xiang, Xiaorun Li, Shuhan Chen|<https://arxiv.org/pdf/2601.12379v1>|[ä»£ç ](https://github.com/jiahuisheng/ScoreAD.)|
|ğŸ“ æ›´æ–°|Generative Diffusion Contrastive Network for Multi-View Clustering|ç”¨äºå¤šè§†å›¾èšç±»çš„ç”Ÿæˆæ‰©æ•£å¯¹æ¯”ç½‘ç»œ|Jian Zhu, Xin Zou, Xi Wang, Lei Liu, Chang Tang, Li-Rong Dai|<https://arxiv.org/pdf/2509.09527v2>|[ä»£ç ](https://github.com/HackerHyper/GDCN.)|
|ğŸ“ æ›´æ–°|A new baseline for edge detection: Make Encoder-Decoder great again|è¾¹ç¼˜æ£€æµ‹çš„æ–°åŸºå‡†ï¼šè®© Encoder-Decoder å†æ¬¡ä¼Ÿå¤§|Yachuan Li, Xavier Soria Pomab, Yongke Xi, Guanlin Li, Chaozhi Yang, Qian Xiao, Yun Bai, Zongmin LI|<https://arxiv.org/pdf/2409.14976v3>|[ä»£ç ](https://github.com/Li-yachuan/NBED.)|
|ğŸ†• å‘å¸ƒ|S^2F-Net:A Robust Spatial-Spectral Fusion Framework for Cross-Model AIGC Detection|S^2F-Netï¼šä¸€ç§ç”¨äºè·¨æ¨¡æ€AIGCæ£€æµ‹çš„é²æ£’ç©ºé—´-å…‰è°±èåˆæ¡†æ¶|Xiangyu Hu, Yicheng Hong, Hongchuang Zheng, Wenjun Zeng, Bingyao Liu|<https://arxiv.org/pdf/2601.12313v1>|æ— |
|ğŸ†• å‘å¸ƒ|LegacyAvatars: Volumetric Face Avatars For Traditional Graphics Pipelines|LegacyAvatars: ç”¨äºä¼ ç»Ÿå›¾å½¢æµæ°´çº¿çš„ä½“ç§¯äººè„¸åŒ–èº«|Safa C. Medin, Gengyan Li, Ziqian Bai, Ruofei Du, Leonhard Helminger, Yinda Zhang, Stephan J. Garbin, Philip L. Davidson .etc.|<https://arxiv.org/pdf/2601.12285v1>|æ— |
|ğŸ†• å‘å¸ƒ|SDiT: Semantic Region-Adaptive for Diffusion Transformers|SDiT: é¢å‘ Diffusion Transformers çš„è¯­ä¹‰åŒºåŸŸè‡ªé€‚åº”|Bowen Lin, Fanjiang Ye, Yihua Liu, Zhenghui Guo, Boyuan Zhang, Weijian Zheng, Yufan Xu, Tiancheng Xing .etc.|<https://arxiv.org/pdf/2601.12283v1>|æ— |
|ğŸ†• å‘å¸ƒ|Soft Shadow Diffusion (SSD): Physics-inspired Learning for 3D Computational Periscopy|Soft Shadow Diffusion (SSD): å—ç‰©ç†å¯å‘çš„3Dè®¡ç®—æ½œæœ›é•œå­¦ä¹ |Fadlullah Raji, John Murray-Bruce|<https://arxiv.org/pdf/2601.12257v1>|åˆ†æå¤±è´¥|


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Class-Partitioned VQ-VAE and Latent Flow Matching for Point Cloud Scene Generation|Class-Partitioned VQ-VAE å’Œ Latent Flow Matching ç”¨äºç‚¹äº‘åœºæ™¯ç”Ÿæˆ|Dasith de Silva Edirimuni, Ajmal Saeed Mian|<https://arxiv.org/pdf/2601.12391v1>|æ— |
|ğŸ†• å‘å¸ƒ|From Prompts to Pavement: LMMs-based Agentic Behavior-Tree Generation Framework for Autonomous Vehicles|ä»æç¤ºè¯åˆ°è·¯é¢ï¼šåŸºäºLMMsçš„è‡ªåŠ¨é©¾é©¶æ±½è½¦æ™ºèƒ½ä½“è¡Œä¸ºæ ‘ç”Ÿæˆæ¡†æ¶|Omar Y. Goba, Ahmed Y. Gado, Catherine M. Elias, Ahmed Hussein|<https://arxiv.org/pdf/2601.12358v1>|æ— |
|ğŸ“ æ›´æ–°|CymbaDiff: Structured Spatial Diffusion for Sketch-based 3D Semantic Urban Scene Generation|CymbaDiff: ç”¨äºåŸºäºè‰å›¾çš„3Dè¯­ä¹‰åŸå¸‚åœºæ™¯ç”Ÿæˆçš„ç»“æ„åŒ–ç©ºé—´æ‰©æ•£|Li Liang, Bo Miao, Xinyu Wang, Naveed Akhtar, Jordan Vice, Ajmal Mian|<https://arxiv.org/pdf/2510.13245v3>|[ä»£ç ](https://github.com/Lillian-research-hub/CymbaDiff); æå‡ºé¦–ä¸ªè‰å›¾ç”Ÿæˆ3Dè¯­ä¹‰åœºæ™¯æ•°æ®é›†SketchSem3DåŠç»“æ„åŒ–ç©ºé—´æ‰©æ•£æ¨¡å‹CymbaDiffã€‚|
|ğŸ†• å‘å¸ƒ|Multi-Sensor Matching with HyperNetworks|[ç¿»è¯‘å¤±è´¥] Multi-Sensor Matching with HyperNetworks|Eli Passov, Nathan S. Netanyahu, Yosi Keller|<https://arxiv.org/pdf/2601.12325v1>|æ— |
|ğŸ“ æ›´æ–°|UDPNet: Unleashing Depth-based Priors for Robust Image Dehazing|[ç¿»è¯‘å¤±è´¥] UDPNet: Unleashing Depth-based Priors for Robust Image Dehazing|Zengyuan Zuo, Junjun Jiang, Gang Wu, Xianming Liu|<https://arxiv.org/pdf/2601.06909v2>|[ä»£ç ](https://github.com/Harbinzzy/UDPNet.)|
|ğŸ†• å‘å¸ƒ|Class-Partitioned VQ-VAE and Latent Flow Matching for Point Cloud Scene Generation|Class-Partitioned VQ-VAE å’Œ Latent Flow Matching ç”¨äºç‚¹äº‘åœºæ™¯ç”Ÿæˆ|Dasith de Silva Edirimuni, Ajmal Saeed Mian|<https://arxiv.org/pdf/2601.12391v1>|æ— |
|ğŸ†• å‘å¸ƒ|From Prompts to Pavement: LMMs-based Agentic Behavior-Tree Generation Framework for Autonomous Vehicles|ä»æç¤ºè¯åˆ°è·¯é¢ï¼šåŸºäºLMMsçš„è‡ªåŠ¨é©¾é©¶è½¦è¾†æ™ºèƒ½ä½“è¡Œä¸ºæ ‘ç”Ÿæˆæ¡†æ¶|Omar Y. Goba, Ahmed Y. Gado, Catherine M. Elias, Ahmed Hussein|<https://arxiv.org/pdf/2601.12358v1>|æ— |
|ğŸ“ æ›´æ–°|CymbaDiff: Structured Spatial Diffusion for Sketch-based 3D Semantic Urban Scene Generation|CymbaDiff: ç”¨äºåŸºäºè‰å›¾çš„3Dè¯­ä¹‰åŸå¸‚åœºæ™¯ç”Ÿæˆçš„ç»“æ„åŒ–ç©ºé—´æ‰©æ•£|Li Liang, Bo Miao, Xinyu Wang, Naveed Akhtar, Jordan Vice, Ajmal Mian|<https://arxiv.org/pdf/2510.13245v3>|[ä»£ç ](https://github.com/Lillian-research-hub/CymbaDiff)|
|ğŸ†• å‘å¸ƒ|Multi-Sensor Matching with HyperNetworks|[ç¿»è¯‘å¤±è´¥] Multi-Sensor Matching with HyperNetworks|Eli Passov, Nathan S. Netanyahu, Yosi Keller|<https://arxiv.org/pdf/2601.12325v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|UDPNet: Unleashing Depth-based Priors for Robust Image Dehazing|[ç¿»è¯‘å¤±è´¥] UDPNet: Unleashing Depth-based Priors for Robust Image Dehazing|Zengyuan Zuo, Junjun Jiang, Gang Wu, Xianming Liu|<https://arxiv.org/pdf/2601.06909v2>|[ä»£ç ](https://github.com/Harbinzzy/UDPNet.)|
|ğŸ“ æ›´æ–°|LAMP: Data-Efficient Linear Affine Weight-Space Models for Parameter-Controlled 3D Shape Generation and Extrapolation|LAMPï¼šç”¨äºå‚æ•°æ§åˆ¶ 3D å½¢çŠ¶ç”Ÿæˆä¸å¤–æ¨çš„æ•°æ®é«˜æ•ˆçº¿æ€§ä»¿å°„æƒé‡ç©ºé—´æ¨¡å‹|Ghadi Nehme, Yanxia Zhang, Dule Shu, Matt Klenk, Faez Ahmed|<https://arxiv.org/pdf/2510.22491v2>|æ— |
|ğŸ†• å‘å¸ƒ|Proc3D: Procedural 3D Generation and Parametric Editing of 3D Shapes with Large Language Models|Proc3Dï¼šåŸºäº Large Language Models çš„ 3D å½¢çŠ¶ç¨‹åºåŒ–ç”Ÿæˆä¸å‚æ•°åŒ–ç¼–è¾‘|Fadlullah Raji, Stefano Petrangeli, Matheus Gadelha, Yu Shen, Uttaran Bhattacharya, Gang Wu|<https://arxiv.org/pdf/2601.12234v1>|æ— |


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|EmoKGEdit: Training-free Affective Injection via Visual Cue Transformation|EmoKGEdit: é€šè¿‡è§†è§‰æç¤ºå˜æ¢å®ç°å…è®­ç»ƒçš„æƒ…æ„Ÿæ³¨å…¥|Jing Zhang, Bingjie Fan|<https://arxiv.org/pdf/2601.12326v1>|æ— |
|ğŸ†• å‘å¸ƒ|EmoKGEdit: Training-free Affective Injection via Visual Cue Transformation|EmoKGEdit: é€šè¿‡è§†è§‰æç¤ºå˜æ¢å®ç°å…è®­ç»ƒçš„æƒ…æ„Ÿæ³¨å…¥|Jing Zhang, Bingjie Fan|<https://arxiv.org/pdf/2601.12326v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Less is More: Label-Guided Summarization of Procedural and Instructional Videos|å°‘å³æ˜¯å¤šï¼šLabel-Guided çš„ç¨‹åºæ€§ä¸æ•™å­¦è§†é¢‘æ‘˜è¦|Shreya Rajpal, Michal Golovanesky, Carsten Eickhoff|<https://arxiv.org/pdf/2601.12243v1>|æ— |
|ğŸ†• å‘å¸ƒ|Where It Moves, It Matters: Referring Surgical Instrument Segmentation via Motion|WhereåŠ¨ä¹‹å¤„ï¼Œè‡³å…³é‡è¦ï¼šåŸºäºè¿åŠ¨çš„æŒ‡ä»£æ‰‹æœ¯å™¨æ¢°åˆ†å‰²|Meng Wei, Kun Yuan, Shi Li, Yue Zhou, Long Bai, Nassir Navab, Hongliang Ren, Hong Joo Lee .etc.|<https://arxiv.org/pdf/2601.12224v1>|æ— |


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Wukong Framework for Not Safe For Work Detection in Text-to-Image systems|ç”¨äº Text-to-Image ç³»ç»Ÿä¸­ Not Safe For Work æ£€æµ‹çš„ Wukong Framework|Mingrui Liu, Sixiao Zhang, Cheng Long|<https://arxiv.org/pdf/2508.00591v2>|æ— |
|ğŸ“ æ›´æ–°|Wukong Framework for Not Safe For Work Detection in Text-to-Image systems|ç”¨äº Text-to-Image ç³»ç»Ÿä¸­ Not Safe For Work æ£€æµ‹çš„ Wukong Framework|Mingrui Liu, Sixiao Zhang, Cheng Long|<https://arxiv.org/pdf/2508.00591v2>|æ— |


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Encoding Emotion Through Self-Supervised Eye Movement Reconstruction|é€šè¿‡è‡ªç›‘ç£çœ¼åŠ¨é‡å»ºç¼–ç æƒ…æ„Ÿ|Marcus Ma, Jordan Prescott, Emily Zhou, Tiantian Feng, Kleanthis Avramidis, Gabor Mihaly Toth, Shrikanth Narayanan|<https://arxiv.org/pdf/2601.12534v2>|æ— |
|ğŸ†• å‘å¸ƒ|XRefine: Attention-Guided Keypoint Match Refinement|XRefine: æ³¨æ„åŠ›å¼•å¯¼çš„å…³é”®ç‚¹åŒ¹é…ä¼˜åŒ–|Jan Fabian Schmid, Annika Hagemann|<https://arxiv.org/pdf/2601.12530v1>|[ä»£ç ](https://github.com/boschresearch/xrefine.)|
|ğŸ†• å‘å¸ƒ|NeuralFur: Animal Fur Reconstruction From Multi-View Images|NeuralFur: ä»å¤šè§†å›¾å›¾åƒè¿›è¡ŒåŠ¨ç‰©æ¯›å‘é‡å»º|Vanessa Sklyarova, Berna Kabadayi, Anastasios Yiannakidis, Giorgio Becherini, Michael J. Black, Justus Thies|<https://arxiv.org/pdf/2601.12481v1>|æ— |
|ğŸ†• å‘å¸ƒ|XRefine: Attention-Guided Keypoint Match Refinement|[ç¿»è¯‘å¤±è´¥] XRefine: Attention-Guided Keypoint Match Refinement|Jan Fabian Schmid, Annika Hagemann|<https://arxiv.org/pdf/2601.12530v1>|[ä»£ç ](https://github.com/boschresearch/xrefine.)|
|ğŸ†• å‘å¸ƒ|NeuralFur: Animal Fur Reconstruction From Multi-View Images|[ç¿»è¯‘å¤±è´¥] NeuralFur: Animal Fur Reconstruction From Multi-View Images|Vanessa Sklyarova, Berna Kabadayi, Anastasios Yiannakidis, Giorgio Becherini, Michael J. Black, Justus Thies|<https://arxiv.org/pdf/2601.12481v1>|æ— |


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Exploring the Potentials of Spiking Neural Networks for Image Deraining|æ¢ç´¢ Spiking Neural Networks åœ¨å›¾åƒå»é›¨ä¸­çš„æ½œåŠ›|Shuang Chen, Tomas Krajnik, Farshad Arvin, Amir Atapour-Abarghouei|<https://arxiv.org/pdf/2512.02258v3>|æ— |
|ğŸ†• å‘å¸ƒ|Deep Feature Deformation Weights|[ç¿»è¯‘å¤±è´¥] Deep Feature Deformation Weights|Richard Liu, Itai Lang, Rana Hanocka|<https://arxiv.org/pdf/2601.12527v1>|æ— |
|ğŸ“ æ›´æ–°|Exploring the Potentials of Spiking Neural Networks for Image Deraining|æ¢ç´¢ Spiking Neural Networks åœ¨å›¾åƒå»é›¨ä¸­çš„æ½œåŠ›|Shuang Chen, Tomas Krajnik, Farshad Arvin, Amir Atapour-Abarghouei|<https://arxiv.org/pdf/2512.02258v3>|æ— |
|ğŸ†• å‘å¸ƒ|Deep Feature Deformation Weights|[ç¿»è¯‘å¤±è´¥] Deep Feature Deformation Weights|Richard Liu, Itai Lang, Rana Hanocka|<https://arxiv.org/pdf/2601.12527v1>|æ— |


### è§†è§‰å®šä½ä¸æ˜ å°„ (Visual Localization & Mapping)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|OpenNavMap: Structure-Free Topometric Mapping via Large-Scale Collaborative Localization|OpenNavMap: é€šè¿‡å¤§è§„æ¨¡ååŒå®šä½å®ç°æ— ç»“æ„æ‹“æ‰‘åº¦é‡åœ°å›¾æ„å»º|Jianhao Jiao, Changkun Liu, Jingwen Yu, Boyi Liu, Qianyi Zhang, Yue Wang, Dimitrios Kanoulas|<https://arxiv.org/pdf/2601.12291v1>|[ä»£ç ](https://rpl-cs-ucl.github.io/OpenNavMap_page.)|
|ğŸ†• å‘å¸ƒ|OpenNavMap: Structure-Free Topometric Mapping via Large-Scale Collaborative Localization|OpenNavMap: é€šè¿‡å¤§è§„æ¨¡ååŒå®šä½å®ç°æ— ç»“æ„æ‹“æ‰‘åº¦é‡åœ°å›¾æ„å»º|Jianhao Jiao, Changkun Liu, Jingwen Yu, Boyi Liu, Qianyi Zhang, Yue Wang, Dimitrios Kanoulas|<https://arxiv.org/pdf/2601.12291v1>|[ä»£ç ](https://rpl-cs-ucl.github.io/OpenNavMap_page.)|


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|SiLVR: A Simple Language-based Video Reasoning Framework|SiLVR: ä¸€ä¸ªç®€å•çš„åŸºäºè¯­è¨€çš„è§†é¢‘æ¨ç†æ¡†æ¶|Ce Zhang, Yan-Bo Lin, Ziyang Wang, Mohit Bansal, Gedas Bertasius|<https://arxiv.org/pdf/2505.24869v2>|æ— |
|ğŸ†• å‘å¸ƒ|Video Individual Counting and Tracking from Moving Drones: A Benchmark and Methods|ç§»åŠ¨æ— äººæœºè§†é¢‘ä¸ªä½“è®¡æ•°ä¸è·Ÿè¸ªï¼šåŸºå‡†ä¸æ–¹æ³•|Yaowu Fan, Jia Wan, Tao Han, Andy J. Ma, Antoni B. Chan|<https://arxiv.org/pdf/2601.12500v1>|æ— |
|ğŸ“ æ›´æ–°|BenchSeg: A Large-Scale Dataset and Benchmark for Multi-View Food Video Segmentation|BenchSegï¼šä¸€ä¸ªç”¨äºå¤šè§†è§’é£Ÿç‰©è§†é¢‘åˆ†å‰²çš„å¤§è§„æ¨¡æ•°æ®é›†å’ŒåŸºå‡†|Ahmad AlMughrabi, Guillermo Rivo, Carlos JimÃ©nez-FarfÃ¡n, Umair Haroon, Farid Al-Areqi, Hyunjun Jung, Benjamin Busam, Ricardo Marques .etc.|<https://arxiv.org/pdf/2601.07581v2>|[ä»£ç ](https://amughrabi.github.io/benchseg.)|
|ğŸ“ æ›´æ–°|SiLVR: A Simple Language-based Video Reasoning Framework|SiLVR: ä¸€ä¸ªç®€å•çš„åŸºäºè¯­è¨€çš„è§†é¢‘æ¨ç†æ¡†æ¶|Ce Zhang, Yan-Bo Lin, Ziyang Wang, Mohit Bansal, Gedas Bertasius|<https://arxiv.org/pdf/2505.24869v2>|æ— |
|ğŸ†• å‘å¸ƒ|Video Individual Counting and Tracking from Moving Drones: A Benchmark and Methods|æ¥è‡ªç§»åŠ¨æ— äººæœºçš„è§†é¢‘ä¸ªä½“è®¡æ•°ä¸è·Ÿè¸ªï¼šåŸºå‡†ä¸æ–¹æ³•|Yaowu Fan, Jia Wan, Tao Han, Andy J. Ma, Antoni B. Chan|<https://arxiv.org/pdf/2601.12500v1>|æ— |
|ğŸ“ æ›´æ–°|BenchSeg: A Large-Scale Dataset and Benchmark for Multi-View Food Video Segmentation|BenchSeg: ä¸€ä¸ªç”¨äºå¤šè§†è§’é£Ÿç‰©è§†é¢‘åˆ†å‰²çš„å¤§è§„æ¨¡æ•°æ®é›†å’ŒåŸºå‡†|Ahmad AlMughrabi, Guillermo Rivo, Carlos JimÃ©nez-FarfÃ¡n, Umair Haroon, Farid Al-Areqi, Hyunjun Jung, Benjamin Busam, Ricardo Marques .etc.|<https://arxiv.org/pdf/2601.07581v2>|[ä»£ç ](https://amughrabi.github.io/benchseg.)|


### åŠ¨ä½œè¯†åˆ«ä¸ç†è§£ (Action Recognition & Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SkeFi: Cross-Modal Knowledge Transfer for Wireless Skeleton-Based Action Recognition|SkeFi: ç”¨äºåŸºäºæ— çº¿éª¨æ¶çš„åŠ¨ä½œè¯†åˆ«çš„è·¨æ¨¡æ€çŸ¥è¯†è¿ç§»|Shunyu Huang, Yunjiao Zhou, Jianfei Yang|<https://arxiv.org/pdf/2601.12432v1>|[ä»£ç ](https://github.com/Huang0035/Skefi.)|
|ğŸ†• å‘å¸ƒ|Weaknesses of Facial Emotion Recognition Systems|Facial Emotion Recognition Systems çš„å¼±ç‚¹|Aleksandra JamrÃ³z, Patrycja Wysocka, Piotr Garbat|<https://arxiv.org/pdf/2601.12402v1>|æ— |
|ğŸ†• å‘å¸ƒ|CurConMix+: A Unified Spatio-Temporal Framework for Hierarchical Surgical Workflow Understanding|CurConMix+: ç”¨äºåˆ†å±‚æ‰‹æœ¯æµç¨‹ç†è§£çš„ç»Ÿä¸€æ—¶ç©ºæ¡†æ¶|Yongjun Jeon, Jongmin Shin, Kanggil Park, Seonmin Park, Soyoung Lim, Jung Yong Kim, Jinsoo Rhu, Jongman Kim .etc.|<https://arxiv.org/pdf/2601.12312v1>|æ— |
|ğŸ†• å‘å¸ƒ|SkeFi: Cross-Modal Knowledge Transfer for Wireless Skeleton-Based Action Recognition|SkeFi: ç”¨äºåŸºäºæ— çº¿éª¨æ¶çš„åŠ¨ä½œè¯†åˆ«çš„è·¨æ¨¡æ€çŸ¥è¯†è¿ç§»|Shunyu Huang, Yunjiao Zhou, Jianfei Yang|<https://arxiv.org/pdf/2601.12432v1>|[ä»£ç ](https://github.com/Huang0035/Skefi.)|
|ğŸ†• å‘å¸ƒ|Weaknesses of Facial Emotion Recognition Systems|Facial Emotion Recognition Systems çš„å¼±ç‚¹|Aleksandra JamrÃ³z, Patrycja Wysocka, Piotr Garbat|<https://arxiv.org/pdf/2601.12402v1>|æ— |
|ğŸ†• å‘å¸ƒ|CurConMix+: A Unified Spatio-Temporal Framework for Hierarchical Surgical Workflow Understanding|CurConMix+: ç”¨äºåˆ†å±‚æ‰‹æœ¯æµç¨‹ç†è§£çš„ç»Ÿä¸€æ—¶ç©ºæ¡†æ¶|Yongjun Jeon, Jongmin Shin, Kanggil Park, Seonmin Park, Soyoung Lim, Jung Yong Kim, Jinsoo Rhu, Jongman Kim .etc.|<https://arxiv.org/pdf/2601.12312v1>|æ— |


### è§†é¢‘ç›®æ ‡è·Ÿè¸ª (Video Object Tracking)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|3AM: 3egment Anything with Geometric Consistency in Videos|3AMï¼šåœ¨è§†é¢‘ä¸­åˆ©ç”¨å‡ ä½•ä¸€è‡´æ€§å®ç° 3egment Anything|Yang-Che Sun, Cheng Sun, Chin-Yang Lin, Fu-En Yang, Min-Hung Chen, Yen-Yu Lin, Yu-Lun Liu|<https://arxiv.org/pdf/2601.08831v2>|[ä»£ç ](https://jayisaking.github.io/3AM-Page)|
|ğŸ“ æ›´æ–°|3AM: 3egment Anything with Geometric Consistency in Videos|3AMï¼šåœ¨è§†é¢‘ä¸­åˆ©ç”¨å‡ ä½•ä¸€è‡´æ€§å®ç° 3egment Anything|Yang-Che Sun, Cheng Sun, Chin-Yang Lin, Fu-En Yang, Min-Hung Chen, Yen-Yu Lin, Yu-Lun Liu|<https://arxiv.org/pdf/2601.08831v2>|[ä»£ç ](https://jayisaking.github.io/3AM-Page)|


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Towards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach|[ç¿»è¯‘å¤±è´¥] Towards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach|Shiqi Wang, Mahdi Khosravy, Neeraj Gupta, Olaf Witkowski|<https://arxiv.org/pdf/2601.12624v1>|æ— |
|ğŸ†• å‘å¸ƒ|Camera Pose Revisited|[ç¿»è¯‘å¤±è´¥] Camera Pose Revisited|WÅ‚adysÅ‚aw Skarbek, MichaÅ‚ Salomonowicz, MichaÅ‚ KrÃ³l|<https://arxiv.org/pdf/2601.12567v1>|æ— |
|ğŸ†• å‘å¸ƒ|Life, Machine Learning, and the Search for Habitability: Predicting Biosignature Fluxes for the Habitable Worlds Observatory|ç”Ÿå‘½ã€æœºå™¨å­¦ä¹ ä¸å®œå±…æ€§æ¢ç´¢ï¼šä¸ºå®œå±…ä¸–ç•Œå¤©æ–‡å°é¢„æµ‹ç”Ÿç‰©ç‰¹å¾é€šé‡|Mark Moussa, Amber V. Young, Brianna Isola, Vasuda Trehan, Michael D. Himes, Nicholas Wogan, Giada Arney|<https://arxiv.org/pdf/2601.12557v1>|æ— |
|ğŸ†• å‘å¸ƒ|Towards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach|[ç¿»è¯‘å¤±è´¥] Towards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach|Shiqi Wang, Mahdi Khosravy, Neeraj Gupta, Olaf Witkowski|<https://arxiv.org/pdf/2601.12624v1>|æ— |
|ğŸ†• å‘å¸ƒ|Camera Pose Revisited|[ç¿»è¯‘å¤±è´¥] Camera Pose Revisited|WÅ‚adysÅ‚aw Skarbek, MichaÅ‚ Salomonowicz, MichaÅ‚ KrÃ³l|<https://arxiv.org/pdf/2601.12567v1>|æ— |
|ğŸ†• å‘å¸ƒ|Life, Machine Learning, and the Search for Habitability: Predicting Biosignature Fluxes for the Habitable Worlds Observatory|ç”Ÿå‘½ã€æœºå™¨å­¦ä¹ ä¸å®œå±…æ€§æœç´¢ï¼šé¢„æµ‹å®œå±…ä¸–ç•Œå¤©æ–‡å°çš„ç”Ÿç‰©ç‰¹å¾é€šé‡|Mark Moussa, Amber V. Young, Brianna Isola, Vasuda Trehan, Michael D. Himes, Nicholas Wogan, Giada Arney|<https://arxiv.org/pdf/2601.12557v1>|æ— |


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Real-Time Reconstruction of 3D Bone Models via Very-Low-Dose Protocols|åŸºäºæä½å‰‚é‡åè®®çš„3Déª¨éª¼æ¨¡å‹å®æ—¶é‡å»º|Yiqun Lin, Haoran Sun, Yongqing Li, Rabia Aslam, Lung Fung Tse, Tiange Cheng, Chun Sing Chui, Wing Fung Yau .etc.|<https://arxiv.org/pdf/2508.13947v2>|æ— |
|ğŸ†• å‘å¸ƒ|DALD-PCAC: Density-Adaptive Learning Descriptor for Point Cloud Lossless Attribute Compression|DALD-PCAC: ç”¨äºç‚¹äº‘æ— æŸå±æ€§å‹ç¼©çš„å¯†åº¦è‡ªé€‚åº”å­¦ä¹ æè¿°ç¬¦|Chunyang Fu, Ge Li, Wei Gao, Shiqi Wang, Zhu Li, Shan Liu|<https://arxiv.org/pdf/2601.12261v1>|[ä»£ç ](https://github.com/zb12138/DALD_PCAC.)|
|ğŸ“ æ›´æ–°|Real-Time Reconstruction of 3D Bone Models via Very-Low-Dose Protocols|åŸºäºæä½å‰‚é‡åè®®çš„3Déª¨éª¼æ¨¡å‹å®æ—¶é‡å»º|Yiqun Lin, Haoran Sun, Yongqing Li, Rabia Aslam, Lung Fung Tse, Tiange Cheng, Chun Sing Chui, Wing Fung Yau .etc.|<https://arxiv.org/pdf/2508.13947v2>|æ— |
|ğŸ†• å‘å¸ƒ|DALD-PCAC: Density-Adaptive Learning Descriptor for Point Cloud Lossless Attribute Compression|DALD-PCAC: ç”¨äºç‚¹äº‘æ— æŸå±æ€§å‹ç¼©çš„å¯†åº¦è‡ªé€‚åº”å­¦ä¹ æè¿°ç¬¦|Chunyang Fu, Ge Li, Wei Gao, Shiqi Wang, Zhu Li, Shan Liu|<https://arxiv.org/pdf/2601.12261v1>|[ä»£ç ](https://github.com/zb12138/DALD_PCAC.)|


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### å¯¹æŠ—é²æ£’æ€§ (Adversarial Robustness)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Histopath-C: Towards Realistic Domain Shifts for Histopathology Vision-Language Adaptation|Histopath-Cï¼šé¢å‘Histopathology Vision-Language Adaptationçš„çœŸå®åŸŸåç§»|Mehrdad Noori, Gustavo Adolfo Vargas Hakim, David Osowiechi, Fereshteh Shakeri, Ali Bahri, Moslem Yazdanpanah, Sahar Dastani, Ismail Ben Ayed .etc.|<https://arxiv.org/pdf/2601.12493v1>|[ä»£ç ](https://github.com/Mehrdad-Noori/Histopath-C.)|
|ğŸ†• å‘å¸ƒ|Adversarial Defense in Vision-Language Models: An Overview|Vision-Language Modelsä¸­çš„å¯¹æŠ—é˜²å¾¡ï¼šç»¼è¿°|Xiaowei Fu, Lei Zhang|<https://arxiv.org/pdf/2601.12443v1>|æ— |
|ğŸ†• å‘å¸ƒ|A Two-Stage Globally-Diverse Adversarial Attack for Vision-Language Pre-training Models|é’ˆå¯¹ Vision-Language Pre-training Models çš„ä¸¤é˜¶æ®µå…¨å±€å¤šæ ·åŒ–å¯¹æŠ—æ”»å‡»|Wutao Chen, Huaqin Zou, Chen Wan, Lifeng Huang|<https://arxiv.org/pdf/2601.12304v1>|æ— |
|ğŸ“ æ›´æ–°|SRAW-Attack: Space-Reweighted Adversarial Warping Attack for SAR Target Recognition|SRAW-Attack: ç”¨äºSARç›®æ ‡è¯†åˆ«çš„ç©ºé—´é‡åŠ æƒå¯¹æŠ—å½¢å˜æ”»å‡»|Yiming Zhang, Weibo Qin, Yuntian Liu, Feng Wang|<https://arxiv.org/pdf/2601.10324v2>|[ä»£ç ](https://github.com/boremycin/SAR-ATR-TransAttack.)|
|ğŸ†• å‘å¸ƒ|Histopath-C: Towards Realistic Domain Shifts for Histopathology Vision-Language Adaptation|Histopath-Cï¼šé¢å‘Histopathology Vision-Language Adaptationçš„çœŸå®åŸŸåç§»|Mehrdad Noori, Gustavo Adolfo Vargas Hakim, David Osowiechi, Fereshteh Shakeri, Ali Bahri, Moslem Yazdanpanah, Sahar Dastani, Ismail Ben Ayed .etc.|<https://arxiv.org/pdf/2601.12493v1>|[ä»£ç ](https://github.com/Mehrdad-Noori/Histopath-C.)|
|ğŸ†• å‘å¸ƒ|Adversarial Defense in Vision-Language Models: An Overview|Vision-Language Modelsä¸­çš„å¯¹æŠ—é˜²å¾¡ï¼šç»¼è¿°|Xiaowei Fu, Lei Zhang|<https://arxiv.org/pdf/2601.12443v1>|æ— |
|ğŸ†• å‘å¸ƒ|A Two-Stage Globally-Diverse Adversarial Attack for Vision-Language Pre-training Models|é’ˆå¯¹ Vision-Language Pre-training Models çš„ä¸¤é˜¶æ®µå…¨å±€å¤šæ ·åŒ–å¯¹æŠ—æ”»å‡»|Wutao Chen, Huaqin Zou, Chen Wan, Lifeng Huang|<https://arxiv.org/pdf/2601.12304v1>|æ— |
|ğŸ“ æ›´æ–°|SRAW-Attack: Space-Reweighted Adversarial Warping Attack for SAR Target Recognition|SRAW-Attack: ç”¨äºSARç›®æ ‡è¯†åˆ«çš„ç©ºé—´é‡åŠ æƒå¯¹æŠ—æ‰­æ›²æ”»å‡»|Yiming Zhang, Weibo Qin, Yuntian Liu, Feng Wang|<https://arxiv.org/pdf/2601.10324v2>|[ä»£ç ](https://github.com/boremycin/SAR-ATR-TransAttack.)|


### åˆ†å¸ƒå¤–æ³›åŒ– (Out-of-distribution Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|DCAC: Dynamic Class-Aware Cache Creates Stronger Out-of-Distribution Detectors|DCAC: åŠ¨æ€ç±»åˆ«æ„ŸçŸ¥ç¼“å­˜æ„å»ºæ›´å¼ºçš„åˆ†å¸ƒå¤–æ£€æµ‹å™¨|Yanqi Wu, Qichao Chen, Runhe Lai, Xinhua Lu, Jia-Xin Zhuang, Zhilin Zhao, Wei-Shi Zheng, Ruixuan Wang|<https://arxiv.org/pdf/2601.12468v1>|æ— |
|ğŸ“ æ›´æ–°|SA-ResGS: Self-Augmented Residual 3D Gaussian Splatting for Next Best View Selection|SA-ResGS: ç”¨äº Next Best View Selection çš„ Self-Augmented Residual 3D Gaussian Splatting|Kim Jun-Seong, Tae-Hyun Oh, Eduardo PÃ©rez-Pellitero, Youngkyoon Jang|<https://arxiv.org/pdf/2601.03024v2>|æ— |
|ğŸ†• å‘å¸ƒ|DCAC: Dynamic Class-Aware Cache Creates Stronger Out-of-Distribution Detectors|DCAC: åŠ¨æ€ç±»åˆ«æ„ŸçŸ¥ç¼“å­˜æ„å»ºæ›´å¼ºçš„åˆ†å¸ƒå¤–æ£€æµ‹å™¨|Yanqi Wu, Qichao Chen, Runhe Lai, Xinhua Lu, Jia-Xin Zhuang, Zhilin Zhao, Wei-Shi Zheng, Ruixuan Wang|<https://arxiv.org/pdf/2601.12468v1>|æ— |
|ğŸ“ æ›´æ–°|SA-ResGS: Self-Augmented Residual 3D Gaussian Splatting for Next Best View Selection|SA-ResGS: ç”¨äºNext Best View Selectionçš„è‡ªå¢å¼ºæ®‹å·®3D Gaussian Splatting|Kim Jun-Seong, Tae-Hyun Oh, Eduardo PÃ©rez-Pellitero, Youngkyoon Jang|<https://arxiv.org/pdf/2601.03024v2>|æ— |


### ä¸ç¡®å®šæ€§é‡åŒ– (Uncertainty Quantification)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Constraint-Aware Neurosymbolic Uncertainty Quantification with Bayesian Deep Learning for Scientific Discovery|é¢å‘ç§‘å­¦å‘ç°çš„åŸºäºBayesian Deep Learningçš„Constraint-Aware Neurosymbolic Uncertainty Quantification|Shahnawaz Alam, Mohammed Mudassir Uddin, Mohammed Kaif Pasha|<https://arxiv.org/pdf/2601.12442v1>|æ— |
|ğŸ†• å‘å¸ƒ|Constraint-Aware Neurosymbolic Uncertainty Quantification with Bayesian Deep Learning for Scientific Discovery|é¢å‘ç§‘å­¦å‘ç°çš„åŸºäºBayesian Deep Learningçš„Constraint-Aware Neurosymbolic Uncertainty Quantification|Shahnawaz Alam, Mohammed Mudassir Uddin, Mohammed Kaif Pasha|<https://arxiv.org/pdf/2601.12442v1>|æ— |


### è§†è§‰å®‰å…¨ä¸éšç§ (Visual Security & Privacy)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Privacy-Preserving Federated Learning with Verifiable Fairness Guarantees|å…·æœ‰å¯éªŒè¯å…¬å¹³æ€§ä¿è¯çš„éšç§ä¿æŠ¤è”é‚¦å­¦ä¹ |Mohammed Himayath Ali, Mohammed Aqib Abdullah, Syed Muneer Hussin, Mohammed Mudassir Uddin, Shahnawaz Alam|<https://arxiv.org/pdf/2601.12447v1>|æ— |
|ğŸ†• å‘å¸ƒ|Privacy-Preserving Federated Learning with Verifiable Fairness Guarantees|å…·æœ‰å¯éªŒè¯å…¬å¹³æ€§ä¿è¯çš„éšç§ä¿æŠ¤è”é‚¦å­¦ä¹ |Mohammed Himayath Ali, Mohammed Aqib Abdullah, Syed Muneer Hussin, Mohammed Mudassir Uddin, Shahnawaz Alam|<https://arxiv.org/pdf/2601.12447v1>|æ— |


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|DeepRAHT: Learning Predictive RAHT for Point Cloud Attribute Compression|DeepRAHT: å­¦ä¹ ç”¨äºç‚¹äº‘å±æ€§å‹ç¼©çš„é¢„æµ‹æ€§RAHT|Chunyang Fu, Tai Qin, Shiqi Wang, Zhu Li|<https://arxiv.org/pdf/2601.12255v1>|[ä»£ç ](https://github.com/zb12138/DeepRAHT.)|
|ğŸ†• å‘å¸ƒ|Federated Joint Learning for Domain and Class Generalization|[ç¿»è¯‘å¤±è´¥] Federated Joint Learning for Domain and Class Generalization|Haoran Xu, Jiaze Li, Jianzhong Ju, Zhenbo Luo|<https://arxiv.org/pdf/2601.12253v1>|æ— |


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|vSTMD: Visual Motion Detection for Extremely Tiny Target at Various Velocities|vSTMD: é’ˆå¯¹å„ç§é€Ÿåº¦æå¾®å°ç›®æ ‡çš„è§†è§‰è¿åŠ¨æ£€æµ‹|Mingshuo Xu, Hao Luan, Zhou Daniel Hao, Jigen Peng, Shigang Yue|<https://arxiv.org/pdf/2501.13054v2>|[ä»£ç ](https://github.com/MingshuoXu/vSTMD.)|
|ğŸ“ æ›´æ–°|vSTMD: Visual Motion Detection for Extremely Tiny Target at Various Velocities|vSTMDï¼šé’ˆå¯¹å„ç§é€Ÿåº¦æå°ç›®æ ‡çš„è§†è§‰è¿åŠ¨æ£€æµ‹|Mingshuo Xu, Hao Luan, Zhou Daniel Hao, Jigen Peng, Shigang Yue|<https://arxiv.org/pdf/2501.13054v2>|[ä»£ç ](https://github.com/MingshuoXu/vSTMD.)|


### è·¨æ¨¡æ€æ£€ç´¢ä¸åŒ¹é… (Cross-modal Retrieval & Matching)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|FlowIID: Single-Step Intrinsic Image Decomposition via Latent Flow Matching|FlowIID: é€šè¿‡ Latent Flow Matching å®ç°å•æ­¥æœ¬å¾å›¾åƒåˆ†è§£|Mithlesh Singla, Seema Kumari, Shanmuganathan Raman|<https://arxiv.org/pdf/2601.12329v1>|æ— |
|ğŸ†• å‘å¸ƒ|CytoCLIP: Learning Cytoarchitectural Characteristics in Developing Human Brain Using Contrastive Language Image Pre-Training|CytoCLIPï¼šåˆ©ç”¨å¯¹æ¯”è¯­è¨€å›¾åƒé¢„è®­ç»ƒå­¦ä¹ å‘è‚²ä¸­äººè„‘çš„ç»†èƒæ„ç­‘ç‰¹å¾|Pralaypati Ta, Sriram Venkatesaperumal, Keerthi Ram, Mohanasankar Sivaprakasam|<https://arxiv.org/pdf/2601.12282v1>|æ— |
|ğŸ†• å‘å¸ƒ|FlowIID: Single-Step Intrinsic Image Decomposition via Latent Flow Matching|FlowIID: é€šè¿‡ Latent Flow Matching å®ç°å•æ­¥æœ¬å¾å›¾åƒåˆ†è§£|Mithlesh Singla, Seema Kumari, Shanmuganathan Raman|<https://arxiv.org/pdf/2601.12329v1>|æ— |
|ğŸ†• å‘å¸ƒ|CytoCLIP: Learning Cytoarchitectural Characteristics in Developing Human Brain Using Contrastive Language Image Pre-Training|CytoCLIPï¼šåˆ©ç”¨å¯¹æ¯”è¯­è¨€å›¾åƒé¢„è®­ç»ƒå­¦ä¹ å‘è‚²ä¸­äººç±»å¤§è„‘çš„ç»†èƒæ„ç­‘ç‰¹å¾|Pralaypati Ta, Sriram Venkatesaperumal, Keerthi Ram, Mohanasankar Sivaprakasam|<https://arxiv.org/pdf/2601.12282v1>|æ— |


### å¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿ (Multimodal Dialogue Systems)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|REF-VLM: Triplet-Based Referring Paradigm for Unified Visual Decoding|REF-VLM: åŸºäºä¸‰å…ƒç»„çš„æŒ‡ä»£èŒƒå¼ç”¨äºç»Ÿä¸€è§†è§‰è§£ç |Yan Tai, Luhao Zhu, Yunan Ding, Yiying Dong, Guangtao Zhai, Xiaohong Liu, Guodong Guo|<https://arxiv.org/pdf/2503.07413v2>|æ— |
|ğŸ“ æ›´æ–°|REF-VLM: Triplet-Based Referring Paradigm for Unified Visual Decoding|REF-VLM: åŸºäºä¸‰å…ƒç»„çš„æŒ‡ä»£èŒƒå¼ç”¨äºç»Ÿä¸€è§†è§‰è§£ç |Yan Tai, Luhao Zhu, Yunan Ding, Yiying Dong, Guangtao Zhai, Xiaohong Liu, Guodong Guo|<https://arxiv.org/pdf/2503.07413v2>|æ— |


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Fine-Tuning Cycle-GAN for Domain Adaptation of MRI Images|Fine-Tuning Cycle-GAN for MRI Imagesçš„Domain Adaptation|Mohd Usama, Belal Ahmad, Faleh Menawer R Althiyabi|<https://arxiv.org/pdf/2601.12512v1>|æ— |
|ğŸ†• å‘å¸ƒ|HOT-POT: Optimal Transport for Sparse Stereo Matching|HOT-POT: ç”¨äºç¨€ç–ç«‹ä½“åŒ¹é…çš„æœ€ä¼˜ä¼ è¾“|Antonin Clerc, Michael Quellmalz, Moritz Piening, Philipp Flotho, Gregor Kornhardt, Gabriele Steidl|<https://arxiv.org/pdf/2601.12423v1>|æ— |
|ğŸ†• å‘å¸ƒ|Fine-Tuning Cycle-GAN for Domain Adaptation of MRI Images|Fine-Tuning Cycle-GAN for MRI Imagesçš„Domain Adaptation|Mohd Usama, Belal Ahmad, Faleh Menawer R Althiyabi|<https://arxiv.org/pdf/2601.12512v1>|æ— |
|ğŸ†• å‘å¸ƒ|HOT-POT: Optimal Transport for Sparse Stereo Matching|HOT-POT: ç”¨äºç¨€ç–ç«‹ä½“åŒ¹é…çš„æœ€ä¼˜ä¼ è¾“|Antonin Clerc, Michael Quellmalz, Moritz Piening, Philipp Flotho, Gregor Kornhardt, Gabriele Steidl|<https://arxiv.org/pdf/2601.12423v1>|æ— |
|ğŸ†• å‘å¸ƒ|DiffusionQC: Artifact Detection in Histopathology via Diffusion Model|DiffusionQC: é€šè¿‡ Diffusion Model è¿›è¡Œç»„ç»‡ç—…ç†å­¦ä¸­çš„ä¼ªå½±æ£€æµ‹|Zhenzhen Wang, Zhongliang Zhou, Zhuoyu Wen, Jeong Hwan Kook, John B Wojcik, John Kang|<https://arxiv.org/pdf/2601.12233v1>|æ— |


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SDCoNet: Saliency-Driven Multi-Task Collaborative Network for Remote Sensing Object Detection|[ç¿»è¯‘å¤±è´¥] SDCoNet: Saliency-Driven Multi-Task Collaborative Network for Remote Sensing Object Detection|Ruo Qi, Linhui Dai, Yusong Qin, Chaolei Yang, Yanshan Li|<https://arxiv.org/pdf/2601.12507v1>|[ä»£ç ](https://github.com/qiruo-ya/SDCoNet.)|
|ğŸ“ æ›´æ–°|RemoteDet-Mamba: A Hybrid Mamba-CNN Network for Multi-modal Object Detection in Remote Sensing Images|RemoteDet-Mamba: ç”¨äºé¥æ„Ÿå›¾åƒå¤šæ¨¡æ€ç›®æ ‡æ£€æµ‹çš„æ··åˆ Mamba-CNN ç½‘ç»œ|Kejun Ren, Xin Wu, Lianming Xu, Li Wang|<https://arxiv.org/pdf/2410.13532v2>|æ— |
|ğŸ†• å‘å¸ƒ|Adaptive Multi-Scale Correlation Meta-Network for Few-Shot Remote Sensing Image Classification|è‡ªé€‚åº”å¤šå°ºåº¦ç›¸å…³æ€§å…ƒç½‘ç»œç”¨äºFew-Shoté¥æ„Ÿå›¾åƒåˆ†ç±»|Anurag Kaushish, Ayan Sar, Sampurna Roy, Sudeshna Chakraborty, Prashant Trivedi, Tanupriya Choudhury, Kanav Gupta|<https://arxiv.org/pdf/2601.12308v1>|æ— |
|ğŸ†• å‘å¸ƒ|SDCoNet: Saliency-Driven Multi-Task Collaborative Network for Remote Sensing Object Detection|[ç¿»è¯‘å¤±è´¥] SDCoNet: Saliency-Driven Multi-Task Collaborative Network for Remote Sensing Object Detection|Ruo Qi, Linhui Dai, Yusong Qin, Chaolei Yang, Yanshan Li|<https://arxiv.org/pdf/2601.12507v1>|[ä»£ç ](https://github.com/qiruo-ya/SDCoNet.)|
|ğŸ“ æ›´æ–°|RemoteDet-Mamba: A Hybrid Mamba-CNN Network for Multi-modal Object Detection in Remote Sensing Images|RemoteDet-Mamba: ç”¨äºé¥æ„Ÿå›¾åƒå¤šæ¨¡æ€ç›®æ ‡æ£€æµ‹çš„æ··åˆ Mamba-CNN ç½‘ç»œ|Kejun Ren, Xin Wu, Lianming Xu, Li Wang|<https://arxiv.org/pdf/2410.13532v2>|æ— |
|ğŸ†• å‘å¸ƒ|Adaptive Multi-Scale Correlation Meta-Network for Few-Shot Remote Sensing Image Classification|ç”¨äºFew-Shoté¥æ„Ÿå›¾åƒåˆ†ç±»çš„è‡ªé€‚åº”å¤šå°ºåº¦ç›¸å…³æ€§Meta-Network|Anurag Kaushish, Ayan Sar, Sampurna Roy, Sudeshna Chakraborty, Prashant Trivedi, Tanupriya Choudhury, Kanav Gupta|<https://arxiv.org/pdf/2601.12308v1>|æ— |


## æ–°å…´ç†è®ºä¸è·¨å­¦ç§‘æ–¹å‘ (Emerging Theory & Interdisciplinary Directions)


### å¯è§£é‡Šè§†è§‰æ™ºèƒ½ (Explainable Visual Intelligence)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Linear Mechanisms for Spatiotemporal Reasoning in Vision Language Models|Vision Language Models ä¸­æ—¶ç©ºæ¨ç†çš„çº¿æ€§æœºåˆ¶|Raphi Kang, Hongqiao Chen, Georgia Gkioxari, Pietro Perona|<https://arxiv.org/pdf/2601.12626v1>|[ä»£ç ](https://github.com/Raphoo/linear-mech-vlms.)|
|ğŸ†• å‘å¸ƒ|Linear Mechanisms for Spatiotemporal Reasoning in Vision Language Models|Vision Language Models ä¸­æ—¶ç©ºæ¨ç†çš„çº¿æ€§æœºåˆ¶|Raphi Kang, Hongqiao Chen, Georgia Gkioxari, Pietro Perona|<https://arxiv.org/pdf/2601.12626v1>|[ä»£ç ](https://github.com/Raphoo/linear-mech-vlms.)|


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|PISE: Physics-Anchored Semantically-Enhanced Deep Computational Ghost Imaging for Robust Low-Bandwidth Machine Perception|PISEï¼šåŸºäºç‰©ç†é”šå®šä¸è¯­ä¹‰å¢å¼ºçš„é²æ£’ä½å¸¦å®½æœºå™¨æ„ŸçŸ¥æ·±åº¦è®¡ç®—é¬¼æˆåƒ|Tong Wu|<https://arxiv.org/pdf/2601.12551v1>|æ— |
|ğŸ“ æ›´æ–°|ProFuse: Efficient Cross-View Context Fusion for Open-Vocabulary 3D Gaussian Splatting|ProFuseï¼šé¢å‘ Open-Vocabulary 3D Gaussian Splatting çš„é«˜æ•ˆè·¨è§†å›¾ä¸Šä¸‹æ–‡èåˆ|Yen-Jen Chiou, Wei-Tse Cheng, Yuan-Fu Yang|<https://arxiv.org/pdf/2601.04754v2>|[ä»£ç ](https://chiou1203.github.io/ProFuse)|
|ğŸ†• å‘å¸ƒ|SimpleMatch: A Simple and Strong Baseline for Semantic Correspondence|SimpleMatch: è¯­ä¹‰å¯¹åº”çš„ä¸€ä¸ªç®€å•ä¸”å¼ºå¤§çš„åŸºçº¿|Hailing Jin, Huiying Li|<https://arxiv.org/pdf/2601.12357v1>|[ä»£ç ](https://github.com/hailong23-jin/SimpleMatch.)|
|ğŸ†• å‘å¸ƒ|PISE: Physics-Anchored Semantically-Enhanced Deep Computational Ghost Imaging for Robust Low-Bandwidth Machine Perception|PISEï¼šåŸºäºç‰©ç†é”šå®šä¸è¯­ä¹‰å¢å¼ºçš„é²æ£’ä½å¸¦å®½æœºå™¨æ„ŸçŸ¥æ·±åº¦è®¡ç®—é¬¼æˆåƒ|Tong Wu|<https://arxiv.org/pdf/2601.12551v1>|æ— |
|ğŸ“ æ›´æ–°|ProFuse: Efficient Cross-View Context Fusion for Open-Vocabulary 3D Gaussian Splatting|ProFuse: é¢å‘ Open-Vocabulary 3D Gaussian Splatting çš„é«˜æ•ˆè·¨è§†å›¾ä¸Šä¸‹æ–‡èåˆ|Yen-Jen Chiou, Wei-Tse Cheng, Yuan-Fu Yang|<https://arxiv.org/pdf/2601.04754v2>|[ä»£ç ](https://chiou1203.github.io/ProFuse)|
|ğŸ†• å‘å¸ƒ|SimpleMatch: A Simple and Strong Baseline for Semantic Correspondence|SimpleMatch: è¯­ä¹‰å¯¹åº”çš„ä¸€ä¸ªç®€å•ä¸”å¼ºå¤§çš„åŸºçº¿|Hailing Jin, Huiying Li|<https://arxiv.org/pdf/2601.12357v1>|[ä»£ç ](https://github.com/hailong23-jin/SimpleMatch.)|
|ğŸ†• å‘å¸ƒ|BirdsEye-RU: A Dataset For Detecting Faces from Overhead Images|BirdsEye-RU: ä¸€ä¸ªç”¨äºä»ä¿¯è§†å›¾åƒä¸­æ£€æµ‹äººè„¸çš„æ•°æ®é›†|Md. Ahanaf Arif Khan, Ariful Islam, Sangeeta Biswas, Md. Iqbal Aziz Khan, Subrata Pramanik, Sanjoy Kumar Chakravarty, Bimal Kumar Pramanik|<https://arxiv.org/pdf/2601.12533v2>|æ— |
|ğŸ“ æ›´æ–°|UM3: Unsupervised Map to Map Matching|UM3: æ— ç›‘ç£ Map to Map åŒ¹é…|Chaolong Ying, Yinan Zhang, Lei Zhang, Jiazhuang Wang, Shujun Jia, Tianshu Yu|<https://arxiv.org/pdf/2508.16874v2>|æ— |
|ğŸ“ æ›´æ–°|UM3: Unsupervised Map to Map Matching|UM3: æ— ç›‘ç£ Map åˆ° Map åŒ¹é…|Chaolong Ying, Yinan Zhang, Lei Zhang, Jiazhuang Wang, Shujun Jia, Tianshu Yu|<https://arxiv.org/pdf/2508.16874v2>|æ— |

