## [UPDATED!] **2026-01-19** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Calibration Attention: Learning Reliability-Aware Representations for Vision Transformers|Calibration Attention: ä¸º Vision Transformers å­¦ä¹ å¯é æ€§æ„ŸçŸ¥è¡¨ç¤º|Wenhao Liang, Wei Emma Zhang, Lin Yue, Miao Xu, Mingyu Guo, Olaf Maennel, Weitong Chen|<https://arxiv.org/pdf/2508.08547v2>|[ä»£ç ](https://github.com/EagleAdelaide/CalibrationAttention-CalAttn-); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|From 100,000+ images to winning the first brain MRI foundation model challenges: Sharing lessons and models|ä» 100,000+ å¼ å›¾åƒåˆ°èµ¢å¾—é¦–ä¸ªè„‘éƒ¨ MRI åŸºç¡€æ¨¡å‹æŒ‘æˆ˜èµ›ï¼šåˆ†äº«ç»éªŒä¸æ¨¡å‹|Pedro M. Gordaliza, Jaume Banus, BenoÃ®t GÃ©rin, Maxence Wynen, Nataliia Molchanova, Jonas Richiardi, Meritxell Bach Cuadra|<https://arxiv.org/pdf/2601.13166v1>|[ä»£ç ](https://github.com/jbanusco/BrainFM4Challenges.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Early Prediction of Type 2 Diabetes Using Multimodal data and Tabular Transformers|åˆ©ç”¨å¤šæ¨¡æ€æ•°æ®å’Œè¡¨æ ¼ Transformers è¿›è¡Œ 2 å‹ç³–å°¿ç—…çš„æ—©æœŸé¢„æµ‹|Sulaiman Khan, Md. Rafiul Biswas, Zubair Shah|<https://arxiv.org/pdf/2601.12981v1>|åˆ†æå¤±è´¥|


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MultiST: A Cross-Attention-Based Multimodal Model for Spatial Transcriptomic|MultiST: ä¸€ç§åŸºäºCross-Attentionçš„ç©ºé—´è½¬å½•ç»„å­¦å¤šæ¨¡æ€æ¨¡å‹|Wei Wang, Quoc-Toan Ly, Chong Yu, Jun Bai|<https://arxiv.org/pdf/2601.13331v1>|[ä»£ç ](https://github.com/LabJunBMI/MultiST.git.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Earth Embeddings as Products: Taxonomy, Ecosystem, and Standardized Access|Earth Embeddings as Productsï¼šåˆ†ç±»ã€ç”Ÿæ€ç³»ç»Ÿä¸æ ‡å‡†åŒ–è®¿é—®|Heng Fang, Adam J. Stewart, Isaac Corley, Xiao Xiang Zhu, Hossein Azizpour|<https://arxiv.org/pdf/2601.13134v1>|æ— |
|ğŸ“ æ›´æ–°|Image-to-Video Transfer Learning based on Image-Language Foundation Models: A Comprehensive Survey|åŸºäºImage-Language Foundation Modelsçš„Image-to-Video Transfer Learningï¼šç»¼è¿°|Jinxuan Li, Chaolei Tan, Haoxuan Chen, Jianxin Ma, Jian-Fang Hu, Jianhuang Lai, Wei-Shi Zheng|<https://arxiv.org/pdf/2510.10671v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|A Generalist Foundation Model for Total-body PET/CT Enables Diagnostic Reporting and System-wide Metabolic Profiling|ä¸€ç§ç”¨äºå…¨èº« PET/CT çš„é€šç”¨åŸºç¡€æ¨¡å‹å®ç°è¯Šæ–­æŠ¥å‘Šå’Œå…¨èº«ä»£è°¢åˆ†æ|Wei Chen, Liang Wu, Shuyi Lu, Yuanyuan Sun, Wenkai Bi, Zilong Yuan, Yaoyao He, Feng Wang .etc.|<https://arxiv.org/pdf/2601.12820v1>|æ— |
|ğŸ“ æ›´æ–°|MMedExpert-R1: Strengthening Multimodal Medical Reasoning via Domain-Specific Adaptation and Clinical Guideline Reinforcement|MMedExpert-R1ï¼šé€šè¿‡é¢†åŸŸç‰¹å®šé€‚åº”å’Œä¸´åºŠæŒ‡å—å¼ºåŒ–å¢å¼ºå¤šæ¨¡æ€åŒ»å­¦æ¨ç†|Meidan Ding, Jipeng Zhang, Wenxuan Wang, Haiqin Zhong, Xiaoling Luo, Wenting Chen, Linlin Shen|<https://arxiv.org/pdf/2601.10949v2>|åˆ†æå¤±è´¥|


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Scaling Laws for Geospatial Foundation Models: A case study on PhilEO Bench|Geospatial Foundation Models çš„æ‰©å±•å®šå¾‹ï¼šPhilEO Bench æ¡ˆä¾‹ç ”ç©¶|Nikolaos Dionelis, Riccardo Musto, Jente Bosmans, Simone Sarti, Giancarlo Paoletti, Peter Naylor, Valerio Marsocci, SÃ©bastien LefÃ¨vre .etc.|<https://arxiv.org/pdf/2506.14765v5>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|TVWorld: Foundations for Remote-Control TV Agents|TVWorld: é¥æ§ TV Agent çš„åŸºç¡€|Zhantao Ma, Quanfeng Lu, Shuai Zhong, Dahai Yu, Ping Luo, Michael K. Ng|<https://arxiv.org/pdf/2601.13142v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Towards Unbiased Source-Free Object Detection via Vision Foundation Models|[ç¿»è¯‘å¤±è´¥] Towards Unbiased Source-Free Object Detection via Vision Foundation Models|Zhi Cai, Yingjie Gao, Yanan Zhang, Xinzhu Ma, Di Huang|<https://arxiv.org/pdf/2601.12765v1>|åˆ†æå¤±è´¥|


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Event-based Heterogeneous Information Processing for Online Vision-based Obstacle Detection and Localization|åŸºäºEventçš„å¼‚æ„ä¿¡æ¯å¤„ç†ç”¨äºåœ¨çº¿è§†è§‰éšœç¢ç‰©æ£€æµ‹ä¸å®šä½|Reza Ahmadvand, Sarah Safura Sharif, Yaser Mike Banad|<https://arxiv.org/pdf/2601.13451v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|A Lightweight Model-Driven 4D Radar Framework for Pervasive Human Detection in Harsh Conditions|ä¸€ç§è½»é‡çº§æ¨¡å‹é©±åŠ¨çš„4Dé›·è¾¾æ¡†æ¶ï¼Œç”¨äºæ¶åŠ£æ¡ä»¶ä¸‹çš„æ™®é€‚äººä½“æ£€æµ‹|Zhenan Liu, Amir Khajepour, George Shaker|<https://arxiv.org/pdf/2601.13373v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Deep Image Prior with L0 Gradient Regularizer for Image Smoothing|[ç¿»è¯‘å¤±è´¥] Deep Image Prior with L0 Gradient Regularizer for Image Smoothing|Nhat Thanh Tran, Kevin Bui, Jack Xin|<https://arxiv.org/pdf/2601.13400v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Fine-grained spatial-temporal perception for gas leak segmentation|[ç¿»è¯‘å¤±è´¥] Fine-grained spatial-temporal perception for gas leak segmentation|Xinlong Zhao, Shan Du|<https://arxiv.org/pdf/2505.00295v2>|æ— |
|ğŸ†• å‘å¸ƒ|FGTBT: Frequency-Guided Task-Balancing Transformer for Unified Facial Landmark Detection|FGTBT: ç”¨äºç»Ÿä¸€äººè„¸å…³é”®ç‚¹æ£€æµ‹çš„é¢‘åŸŸå¼•å¯¼ä»»åŠ¡å¹³è¡¡ Transformer|Jun Wan, Xinyu Xiong, Ning Chen, Zhihui Lai, Jie Zhou, Wenwen Min|<https://arxiv.org/pdf/2601.12863v1>|[ä»£ç ](https://github.com/Xi0ngxinyu/FGTBT.)|
|ğŸ“ æ›´æ–°|Part-Aware Bottom-Up Group Reasoning for Fine-Grained Social Interaction Detection|é¢å‘ç»†ç²’åº¦ç¤¾äº¤äº¤äº’æ£€æµ‹çš„éƒ¨ä»¶æ„ŸçŸ¥è‡ªåº•å‘ä¸Šåˆ†ç»„æ¨ç†|Dongkeun Kim, Minsu Cho, Suha Kwak|<https://arxiv.org/pdf/2511.03666v2>|æ— |
|ğŸ†• å‘å¸ƒ|Fusion-Restoration Image Processing Algorithm to Improve the High-Temperature Deformation Measurement|Fusion-Restoration å›¾åƒå¤„ç†ç®—æ³•ä»¥æé«˜é«˜æ¸©å˜å½¢æµ‹é‡|Banglei Guan, Dongcai Tan, Jing Tao, Ang Su, Yang Shang, Qifeng Yu|<https://arxiv.org/pdf/2601.12682v1>|æ— |


### ç›®æ ‡æ£€æµ‹ä¸å®šä½ (Object Detection & Localization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Leveraging Transformer Decoder for Automotive Radar Object Detection|åˆ©ç”¨ Transformer Decoder è¿›è¡Œæ±½è½¦é›·è¾¾ç›®æ ‡æ£€æµ‹|Changxu Zhang, Zhaoze Wang, Tai Fei, Christopher Grimm, Yi Jin, Claas Tebruegge, Ernst Warsitz, Markus Gardill|<https://arxiv.org/pdf/2601.13386v1>|æ— |
|ğŸ†• å‘å¸ƒ|Practical Insights into Semi-Supervised Object Detection Approaches|åŠç›‘ç£ç›®æ ‡æ£€æµ‹æ–¹æ³•çš„å®è·µè§è§£|Chaoxin Wang, Bharaneeshwar Balasubramaniyam, Anurag Sangem, Nicolais Guevara, Doina Caragea|<https://arxiv.org/pdf/2601.13380v1>|æ— |
|ğŸ†• å‘å¸ƒ|Real-Time 4D Radar Perception for Robust Human Detection in Harsh Enclosed Environments|æ¶åŠ£å°é—­ç¯å¢ƒä¸­ç”¨äºé²æ£’äººä½“æ£€æµ‹çš„å®æ—¶4D Radaræ„ŸçŸ¥|Zhenan Liu, Yaodong Cui, Amir Khajepour, George Shaker|<https://arxiv.org/pdf/2601.13364v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Infrared Object Detection with Ultra Small ConvNets: Is ImageNet Pretraining Still Useful?|åŸºäºè¶…å°ConvNetsçš„çº¢å¤–ç›®æ ‡æ£€æµ‹ï¼šImageNeté¢„è®­ç»ƒä»ç„¶æœ‰ç”¨å—ï¼Ÿ|Srikanth Muralidharan, Heitor R. Medeiros, Masih Aminbeidokhti, Eric Granger, Marco Pedersoli|<https://arxiv.org/pdf/2508.02927v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|A Streamlined Attention-Based Network for Descriptor Extraction|ä¸€ç§åŸºäºç²¾ç®€æ³¨æ„åŠ›çš„æè¿°ç¬¦æå–ç½‘ç»œ|Mattia D'Urso, Emanuele Santellani, Christian Sormann, Mattia Rossi, Andreas Kuhn, Friedrich Fraundorfer|<https://arxiv.org/pdf/2601.13126v1>|æ— |
|ğŸ†• å‘å¸ƒ|RSOD: Reliability-Guided Sonar Image Object Detection with Extremely Limited Labels|RSOD: åŸºäºå¯é æ€§å¼•å¯¼çš„æä½æ ‡ç­¾å£°çº³å›¾åƒç›®æ ‡æ£€æµ‹|Chengzhou Li, Ping Guo, Guanchen Meng, Qi Jia, Jinyuan Liu, Zhu Liu, Xiaokang Liu, Yu Liu .etc.|<https://arxiv.org/pdf/2601.12715v1>|æ— |
|ğŸ†• å‘å¸ƒ|Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT|ç”¨äºåŸºäº TensorRT çš„é«˜æ•ˆ 3D ç›®æ ‡æ£€æµ‹çš„æ··åˆç²¾åº¦ PointPillars|Ninnart Fuengfusin, Keisuke Yoneda, Naoki Suganuma|<https://arxiv.org/pdf/2601.12638v1>|æ— |


### è¯­ä¹‰/å®ä¾‹åˆ†å‰² (Semantic/Instance Segmentation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Deep Learning for Semantic Segmentation of 3D Ultrasound Data|Deep Learning for 3D Ultrasound Data çš„ Semantic Segmentation|Chenyu Liu, Marco Cecotti, Harikrishnan Vijayakumar, Patrick Robinson, James Barson, Mihai Caleap|<https://arxiv.org/pdf/2601.13263v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|RIS-FUSION: Rethinking Text-Driven Infrared and Visible Image Fusion from the Perspective of Referring Image Segmentation|RIS-FUSION: ä»Referring Image Segmentationè§†è§’é‡æ–°å®¡è§†Text-Driven Infrared and Visible Image Fusion|Siju Ma, Changsiyu Gong, Xiaofeng Fan, Yong Ma, Chengjie Jiang|<https://arxiv.org/pdf/2509.12710v2>|[ä»£ç ](https://github.com/SijuMa2003/RIS-FUSION.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|GaussianTrimmer: Online Trimming Boundaries for 3DGS Segmentation|GaussianTrimmer: ç”¨äº3DGSåˆ†å‰²çš„åœ¨çº¿ä¿®å‰ªè¾¹ç•Œ|Liwei Liao, Ronggang Wang|<https://arxiv.org/pdf/2601.12683v1>|æ— |


### å›¾åƒåˆ†ç±»ä¸è¯†åˆ« (Image Classification & Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|GridNet-HD: A High-Resolution Multi-Modal Dataset for LiDAR-Image Fusion on Power Line Infrastructure|GridNet-HD: ä¸€ä¸ªç”¨äºç”µåŠ›çº¿åŸºç¡€è®¾æ–½ LiDAR-Image èåˆçš„é«˜åˆ†è¾¨ç‡å¤šæ¨¡æ€æ•°æ®é›†|Antoine Carreaud, Shanci Li, Malo De Lacour, Digre Frinde, Jan Skaloud, Adrien Gressin|<https://arxiv.org/pdf/2601.13052v1>|æ— |
|ğŸ†• å‘å¸ƒ|Membership Inference Test: Auditing Training Data in Object Classification Models|Membership Inference Test: å®¡è®¡ Object Classification Models ä¸­çš„è®­ç»ƒæ•°æ®|Gonzalo Mancera, Daniel DeAlcala, Aythami Morales, Ruben Tolosana, Julian Fierrez|<https://arxiv.org/pdf/2601.12929v1>|æ— |
|ğŸ†• å‘å¸ƒ|Open Vocabulary Panoptic Segmentation With Retrieval Augmentation|åŸºäºæ£€ç´¢å¢å¼ºçš„å¼€æ”¾è¯æ±‡å…¨æ™¯åˆ†å‰²|Nafis Sadeq, Qingfeng Liu, Mostafa El-Khamy|<https://arxiv.org/pdf/2601.12779v1>|æ— |


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|A Large-scale Benchmark on Geological Fault Delineation Models: Domain Shift, Training Dynamics, Generalizability, Evaluation and Inferential Behavior|åœ°è´¨æ–­å±‚æç»˜æ¨¡å‹çš„å¤§è§„æ¨¡åŸºå‡†ï¼šDomain Shiftã€Training Dynamicsã€Generalizabilityã€Evaluation å’Œ Inferential Behavior|Jorge Quesada, Chen Zhou, Prithwijit Chowdhury, Mohammad Alotaibi, Ahmad Mustafa, Yusufjon Kumakov, Mohit Prabhushankar, Ghassan AlRegib|<https://arxiv.org/pdf/2505.08585v4>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Single-Step Reconstruction-Free Anomaly Detection and Segmentation via Diffusion Models|åŸºäº Diffusion Models çš„å•æ­¥æ— é‡å»ºå¼‚å¸¸æ£€æµ‹ä¸åˆ†å‰²|Mehrdad Moradi, Marco Grasso, Bianca Maria Colosimo, Kamran Paynabar|<https://arxiv.org/pdf/2508.04818v2>|[ä»£ç ](https://github.com/mehrdadmoradi124/RADAR)|
|ğŸ“ æ›´æ–°|Combining Shape Completion and Grasp Prediction for Fast and Versatile Grasping with a Multi-Fingered Hand|ç»“åˆå½¢çŠ¶è¡¥å…¨ä¸æŠ“å–é¢„æµ‹ä»¥å®ç°å¤šæŒ‡æ‰‹å¿«é€Ÿä¸”é€šç”¨çš„æŠ“å–|Matthias Humt, Dominik Winkelbauer, Ulrich Hillenbrand, Berthold BÃ¤uml|<https://arxiv.org/pdf/2310.20350v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|A Semantic Decoupling-Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision-Language Models|åŸºäºè¯­ä¹‰è§£è€¦çš„ä¸¤é˜¶æ®µé›¨å¤©æ”»å‡»ï¼šæ­ç¤ºVision-Language Modelsçš„å¤©æ°”é²æ£’æ€§ç¼ºé™·|Chengyin Hu, Xiang Chen, Zhe Jia, Weiwen Shi, Fengyu Zhang, Jiujiang Guo, Yiwei Wei|<https://arxiv.org/pdf/2601.13238v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Shape Completion with Prediction of Uncertain Regions|[ç¿»è¯‘å¤±è´¥] Shape Completion with Prediction of Uncertain Regions|Matthias Humt, Dominik Winkelbauer, Ulrich Hillenbrand|<https://arxiv.org/pdf/2308.00377v2>|æ— |
|ğŸ†• å‘å¸ƒ|ICo3D: An Interactive Conversational 3D Virtual Human|ICo3D: ä¸€ä¸ªäº¤äº’å¼å¯¹è¯3Dè™šæ‹Ÿäºº|Richard Shaw, Youngkyoon Jang, Athanasios Papaioannou, Arthur Moreau, Helisa Dhamo, Zhensong Zhang, Eduardo PÃ©rez-Pellitero|<https://arxiv.org/pdf/2601.13148v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|GaussExplorer: 3D Gaussian Splatting for Embodied Exploration and Reasoning|GaussExplorer: ç”¨äºå…·èº«æ¢ç´¢ä¸æ¨ç†çš„ 3D Gaussian Splatting|Kim Yu-Ji, Dahye Lee, Kim Jun-Seong, GeonU Kim, Nam Hyeon-Woo, Yongjin Kwon, Yu-Chiang Frank Wang, Jaesung Choe .etc.|<https://arxiv.org/pdf/2601.13132v1>|æ— |
|ğŸ†• å‘å¸ƒ|GazeD: Context-Aware Diffusion for Accurate 3D Gaze Estimation|GazeDï¼šç”¨äºç²¾ç¡®3D Gaze Estimationçš„Context-Aware Diffusion|Riccardo Catalini, Davide Di Nucci, Guido Borghi, Davide Davoli, Lorenzo Garattoni, Giampiero Francesca, Yuki Kawana, Roberto Vezzani|<https://arxiv.org/pdf/2601.12948v1>|æ— |
|ğŸ“ æ›´æ–°|PositionIC: Unified Position and Identity Consistency for Image Customization|PositionICï¼šç”¨äºå›¾åƒå®šåˆ¶çš„ç»Ÿä¸€ä½ç½®ä¸èº«ä»½ä¸€è‡´æ€§|Junjie Hu, Tianyang Han, Kai Ma, Jialin Gao, Song Yang, Xianhua He, Junfeng Luo, Xiaoming Wei .etc.|<https://arxiv.org/pdf/2507.13861v6>|[ä»£ç ](https://github.com/MeiGen-AI/PositionIC.)|
|ğŸ“ æ›´æ–°|A Survey on Vision-Language-Action Models for Embodied AI|é¢å‘å…·èº«æ™ºèƒ½çš„Vision-Language-Actionæ¨¡å‹ç»¼è¿°|Yueen Ma, Zixing Song, Yuzheng Zhuang, Jianye Hao, Irwin King|<https://arxiv.org/pdf/2405.14093v6>|[ä»£ç ](https://github.com/yueen-ma/Awesome-VLA.)|
|ğŸ†• å‘å¸ƒ|Moaw: Unleashing Motion Awareness for Video Diffusion Models|Moaw: é‡Šæ”¾ Video Diffusion Models çš„è¿åŠ¨æ„ŸçŸ¥èƒ½åŠ›|Tianqi Zhang, Ziyi Wang, Wenzhao Zheng, Weiliang Chen, Yuanhui Huang, Zhengyang Huang, Jie Zhou, Jiwen Lu|<https://arxiv.org/pdf/2601.12761v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Towards Temporal Fusion Beyond the Field of View for Camera-based Semantic Scene Completion|Towardsè¶…è¶Šè§†åœºçš„æ—¶é—´èåˆç”¨äºåŸºäºæ‘„åƒå¤´çš„è¯­ä¹‰åœºæ™¯å®Œæˆ|Jongseong Bae, Junwoo Ha, Jinnyeong Heo, Yeongin Lee, Ha Young Kim|<https://arxiv.org/pdf/2511.12498v2>|æ— |
|ğŸ“ æ›´æ–°|Synthetic Geology: Structural Geology Meets Deep Learning|[ç¿»è¯‘å¤±è´¥] Synthetic Geology: Structural Geology Meets Deep Learning|Simon Ghyselincks, Valeriia Okhmak, Stefano Zampini, George Turkiyyah, David Keyes, Eldad Haber|<https://arxiv.org/pdf/2506.11164v3>|åˆ†æå¤±è´¥|


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Spherical Geometry Diffusion: Generating High-quality 3D Face Geometry via Sphere-anchored Representations|Spherical Geometry Diffusionï¼šé€šè¿‡ Sphere-anchored Representations ç”Ÿæˆé«˜è´¨é‡ 3D äººè„¸å‡ ä½•|Junyi Zhang, Yiming Wang, Yunhong Lu, Qichao Wang, Wenzhe Qian, Xiaoyin Xu, David Gu, Min Zhang|<https://arxiv.org/pdf/2601.13371v1>|æ— |
|ğŸ“ æ›´æ–°|A Text-to-3D Framework for Joint Generation of CG-Ready Humans and Compatible Garments|ä¸€ä¸ªç”¨äºè”åˆç”ŸæˆCGå°±ç»ªäººç‰©å’Œå…¼å®¹æœè£…çš„Text-to-3Dæ¡†æ¶|Zhiyao Sun, Yu-Hui Wen, Ho-Jui Fang, Sheng Ye, Matthieu Lin, Tian Lv, Yong-Jin Liu|<https://arxiv.org/pdf/2503.12052v3>|æ— |
|ğŸ“ æ›´æ–°|SAMannot: A Memory-Efficient, Local, Open-source Framework for Interactive Video Instance Segmentation based on SAM2|SAMannotï¼šä¸€ç§åŸºäºSAM2çš„å†…å­˜é«˜æ•ˆã€æœ¬åœ°åŒ–ã€å¼€æºçš„äº¤äº’å¼è§†é¢‘å®ä¾‹åˆ†å‰²æ¡†æ¶|Gergely Dinya, AndrÃ¡s GelencsÃ©r, Krisztina KupÃ¡n, Clemens KÃ¼pper, KristÃ³f Karacs, Anna GelencsÃ©r-HorvÃ¡th|<https://arxiv.org/pdf/2601.11301v2>|æ— |
|ğŸ†• å‘å¸ƒ|PhaseMark: A Post-hoc, Optimization-Free Watermarking of AI-generated Images in the Latent Frequency Domain|PhasePhaseMarkï¼šæ½œåœ¨é¢‘ç‡åŸŸä¸­AIç”Ÿæˆå›¾åƒçš„äº‹åã€å…ä¼˜åŒ–æ°´å°|Sung Ju Lee, Nam Ik Cho|<https://arxiv.org/pdf/2601.13128v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Evaluating Latent Generative Paradigms for High-Fidelity 3D Shape Completion from a Single Depth Image|è¯„ä¼°åŸºäºå•å¼ æ·±åº¦å›¾åƒçš„é«˜ä¿çœŸ3Då½¢çŠ¶è¡¥å…¨çš„æ½œåœ¨ç”ŸæˆèŒƒå¼|Matthias Humt, Ulrich Hillenbrand, Rudolph Triebel|<https://arxiv.org/pdf/2511.11074v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Prototype Learning-Based Few-Shot Segmentation for Low-Light Crack on Concrete Structures|åŸºäºåŸå‹å­¦ä¹ çš„æ··å‡åœŸç»“æ„ä½å…‰ç…§è£‚ç¼å°‘æ ·æœ¬åˆ†å‰²|Yulun Guo|<https://arxiv.org/pdf/2601.13059v1>|[ä»£ç ](https://github.com/YulunGuo/CrackFSS.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Fine-Grained Human Pose Editing Assessment via Layer-Selective MLLMs|é€šè¿‡é€šè¿‡Layer-Selective MLLMsè¿›è¡Œç»†ç²’åº¦äººä½“å§¿æ€ç¼–è¾‘è¯„ä¼°|Ningyu Sun, Zhaolin Cai, Zitong Xu, Peihang Chen, Huiyu Duan, Yichao Yan, Xiongkuo Min, Xiaokang Yang|<https://arxiv.org/pdf/2601.10369v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Dual-Stream Collaborative Transformer for Image Captioning|[ç¿»è¯‘å¤±è´¥] Dual-Stream Collaborative Transformer for Image Captioning|Jun Wan, Jun Liu, Zhihui lai, Jie Zhou|<https://arxiv.org/pdf/2601.12926v1>|æ— |
|ğŸ†• å‘å¸ƒ|Sparse ActionGen: Accelerating Diffusion Policy with Real-time Pruning|Sparse ActionGen: é€šè¿‡å®æ—¶å‰ªæåŠ é€Ÿ Diffusion Policy|Kangye Ji, Yuan Meng, Zhou Jianbo, Ye Li, Hanyun Cui, Zhi Wang|<https://arxiv.org/pdf/2601.12894v1>|[ä»£ç ](https://sparse-actiongen.github.io/.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Exploring Talking Head Models With Adjacent Frame Prior for Speech-Preserving Facial Expression Manipulation|æ¢ç´¢åˆ©ç”¨ç›¸é‚»å¸§å…ˆéªŒçš„Talking Headæ¨¡å‹ç”¨äºè¯­éŸ³ä¿æŒçš„é¢éƒ¨è¡¨æƒ…æ“æ§|Zhenxuan Lu, Zhihua Xu, Zhijing Yang, Feng Gao, Yongyi Lu, Keze Wang, Tianshui Chen|<https://arxiv.org/pdf/2601.12876v1>|æ— |
|ğŸ†• å‘å¸ƒ|Accurate Simulation Pipeline for Passive Single-Photon Imaging|ç”¨äºè¢«åŠ¨å•å…‰å­æˆåƒçš„ç²¾ç¡®ä»¿çœŸæµç¨‹|Aleksi Suonsivu, Lauri Salmela, Leevi Uosukainen, Edoardo Peretti, Radu Ciprian Bilcu, Giacomo Boracchi|<https://arxiv.org/pdf/2601.12850v1>|æ— |
|ğŸ“ æ›´æ–°|Lightning Fast Caching-based Parallel Denoising Prediction for Accelerating Talking Head Generation|åŸºäºç¼“å­˜çš„æé€Ÿå¹¶è¡Œå»å™ªé¢„æµ‹ä»¥åŠ é€Ÿ Talking Head Generation|Jianzhi Long, Wenhao Sun, Rongcheng Tu, Dacheng Tao|<https://arxiv.org/pdf/2509.00052v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|FRoM-W1: Towards General Humanoid Whole-Body Control with Language Instructions|FRFRoM-W1: åŸºäºè¯­è¨€æŒ‡ä»¤çš„é€šç”¨ä»¿äººæœºå™¨äººå…¨èº«æ§åˆ¶|Peng Li, Zihan Zhuang, Yangfan Gao, Yi Dong, Sixian Li, Changhao Jiang, Shihan Dou, Zhiheng Xi .etc.|<https://arxiv.org/pdf/2601.12799v1>|æ— |
|ğŸ†• å‘å¸ƒ|Joint Source-Channel-Generation Coding: From Distortion-oriented Reconstruction to Semantic-consistent Generation|è”åˆä¿¡æº-ä¿¡é“-ç”Ÿæˆç¼–ç ï¼šä»é¢å‘å¤±çœŸçš„é‡å»ºåˆ°è¯­ä¹‰ä¸€è‡´çš„ç”Ÿæˆ|Tong Wu, Zhiyong Chen, Guo Lu, Li Song, Feng Yang, Meixia Tao, Wenjun Zhang|<https://arxiv.org/pdf/2601.12808v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Beyond the Safety Tax: Mitigating Unsafe Text-to-Image Generation via External Safety Rectification|è¶…è¶Šå®‰å…¨ç¨ï¼šé€šè¿‡å¤–éƒ¨å®‰å…¨ä¿®æ­£ç¼“è§£ä¸å®‰å…¨çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ|Xiangtao Meng, Yingkai Dong, Ning Yu, Li Wang, Zheng Li, Shanqing Guo|<https://arxiv.org/pdf/2508.21099v3>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|InstructMoLE: Instruction-Guided Mixture of Low-rank Experts for Multi-Conditional Image Generation|InstructMoLE: æŒ‡ä»¤å¼•å¯¼çš„ä½ç§©ä¸“å®¶æ··åˆç”¨äºå¤šæ¡ä»¶å›¾åƒç”Ÿæˆ|Jinqi Xiao, Qing Yan, Liming Jiang, Zichuan Liu, Hao Kang, Shen Sang, Tiancheng Zhi, Jing Liu .etc.|<https://arxiv.org/pdf/2512.21788v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Multimodal RewardBench 2: Evaluating Omni Reward Models for Interleaved Text and Image|Multimodal RewardBench 2ï¼šè¯„ä¼°ç”¨äºäº¤é”™æ–‡æœ¬å’Œå›¾åƒçš„Omni Reward Models|Yushi Hu, Reyhane Askari-Hemmat, Melissa Hall, Emily Dinan, Luke Zettlemoyer, Marjan Ghazvininejad|<https://arxiv.org/pdf/2512.16899v3>|æ— |
|ğŸ†• å‘å¸ƒ|S2DiT: Sandwich Diffusion Transformer for Mobile Streaming Video Generation|S2DiT: ç”¨äºç§»åŠ¨æµå¼è§†é¢‘ç”Ÿæˆçš„ Sandwich Diffusion Transformer|Lin Zhao, Yushu Wu, Aleksei Lebedev, Dishani Lahiri, Meng Dong, Arpit Sahni, Michael Vasilkovsky, Hao Chen .etc.|<https://arxiv.org/pdf/2601.12719v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Controllable Video Generation: A Survey|[ç¿»è¯‘å¤±è´¥] Controllable Video Generation: A Survey|Yue Ma, Kunyu Feng, Zhongyuan Hu, Xinyu Wang, Yucheng Wang, Mingzhe Zheng, Bingyuan Wang, Qinghe Wang .etc.|<https://arxiv.org/pdf/2507.16869v3>|[ä»£ç ](https://github.com/mayuelala/Awesome-Controllable-Video-Generation.)|


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|StyMam: A Mamba-Based Generator for Artistic Style Transfer|StyMam: åŸºäº Mamba çš„è‰ºæœ¯é£æ ¼è¿ç§»ç”Ÿæˆå™¨|Zhou Hong, Rongsheng Hu, Yicheng Di, Xiaolong Xu, Ning Dong, Yihua Shao, Run Ling, Yun Wang .etc.|<https://arxiv.org/pdf/2601.12954v1>|æ— |
|ğŸ“ æ›´æ–°|ManipShield: A Unified Framework for Image Manipulation Detection, Localization and Explanation|ManipShield: ä¸€ä¸ªç”¨äºå›¾åƒç¯¡æ”¹æ£€æµ‹ã€å®šä½ä¸è§£é‡Šçš„ç»Ÿä¸€æ¡†æ¶|Zitong Xu, Huiyu Duan, Xiaoyu Wang, Zhaolin Cai, Kaiwei Zhang, Qiang Hu, Jing Liu, Xiongkuo Min .etc.|<https://arxiv.org/pdf/2511.14259v3>|æ— |
|ğŸ“ æ›´æ–°|Integrating Reinforcement Learning with Visual Generative Models: Foundations and Advances|å°†å¼ºåŒ–å­¦ä¹ ä¸è§†è§‰ç”Ÿæˆæ¨¡å‹ç›¸ç»“åˆï¼šåŸºç¡€ä¸è¿›å±•|Yuanzhi Liang, Yijie Fang, Ke Hao, Rui Li, Ziqi Ni, Ruijie Su, Chi Zhang|<https://arxiv.org/pdf/2508.10316v3>|åˆ†æå¤±è´¥|


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Generalizable and Animatable 3D Full-Head Gaussian Avatar from a Single Image|å¯æ³›åŒ–ä¸”å¯åŠ¨ç”»çš„å•å¼ å›¾åƒ3Då…¨å¤´Gaussian Avatar|Shuling Zhao, Dan Xu|<https://arxiv.org/pdf/2601.12770v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|STRIDE-QA: Visual Question Answering Dataset for Spatiotemporal Reasoning in Urban Driving Scenes|STRIDE-QA: é¢å‘åŸå¸‚åœºæ™¯æ—¶ç©ºæ¨ç†çš„è§†è§‰é—®ç­”æ•°æ®é›†|Keishi Ishihara, Kento Sasaki, Tsubasa Takahashi, Daiki Shiono, Yu Yamaguchi|<https://arxiv.org/pdf/2508.10427v3>|æ— |


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Diffusion Representations for Fine-Grained Image Classification: A Marine Plankton Case Study|ç”¨äºç»†ç²’åº¦å›¾åƒåˆ†ç±»çš„Diffusion Representationsï¼šä»¥æµ·æ´‹æµ®æ¸¸ç”Ÿç‰©ä¸ºä¾‹|A. Nieto Juscafresa, Ã. MazcuÃ±Ã¡n Herreros, J. Sullivan|<https://arxiv.org/pdf/2601.13416v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Shared representations in brains and models reveal a two-route cortical organization during scene perception|å¤§è„‘å’Œæ¨¡å‹ä¸­çš„å…±äº«è¡¨å¾æ­ç¤ºäº†åœºæ™¯æ„ŸçŸ¥æœŸé—´çš„åŒé€šè·¯çš®å±‚ç»„ç»‡|Pablo Marcos-ManchÃ³n, LluÃ­s Fuentemilla|<https://arxiv.org/pdf/2507.13941v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|TreeDGS: Aerial Gaussian Splatting for Distant DBH Measurement|TreeDGSï¼šç”¨äºè¿œè·ç¦»DBHæµ‹é‡çš„èˆªç©ºGaussian Splatting|Belal Shaheen, Minh-Hieu Nguyen, Bach-Thuan Bui, Shubham, Tim Wu, Michael Fairley, Matthew David Zane, Michael Wu .etc.|<https://arxiv.org/pdf/2601.12823v1>|åˆ†æå¤±è´¥|


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|OceanSplat: Object-aware Gaussian Splatting with Trinocular View Consistency for Underwater Scene Reconstruction|OceanSplatï¼šåŸºäºä¸‰ç›®è§†å›¾ä¸€è‡´æ€§çš„ç‰©ä½“æ„ŸçŸ¥é«˜æ–¯æ³¼æº…ç”¨äºæ°´ä¸‹åœºæ™¯é‡å»º|Minseong Kweon, Jinsun Park|<https://arxiv.org/pdf/2601.04984v2>|æ— |
|ğŸ†• å‘å¸ƒ|Think3D: Thinking with Space for Spatial Reasoning|Think3D: åˆ©ç”¨ç©ºé—´è¿›è¡Œç©ºé—´æ¨ç†|Zaibin Zhang, Yuhan Wu, Lianjie Jia, Yifan Wang, Zhongbo Zhang, Yijiang Li, Binghao Ran, Fuxi Zhang .etc.|<https://arxiv.org/pdf/2601.13029v1>|[ä»£ç ](https://github.com/zhangzaibin/spagent.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|DeepDetect: Learning All-in-One Dense Keypoints|DeepDetect: å­¦ä¹ ä¸€ä½“åŒ–å¯†é›†å…³é”®ç‚¹|Shaharyar Ahmed Khan Tareen, Filza Khan Tareen, Xiaojing Yuan|<https://arxiv.org/pdf/2510.17422v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|KaoLRM: Repurposing Pre-trained Large Reconstruction Models for Parametric 3D Face Reconstruction|KaoLRMï¼šå¤ç”¨é¢„è®­ç»ƒå¤§é‡å»ºæ¨¡å‹è¿›è¡Œå‚æ•°åŒ–3Däººè„¸é‡å»º|Qingtian Zhu, Xu Cao, Zhixiang Wang, Yinqiang Zheng, Takafumi Taketomi|<https://arxiv.org/pdf/2601.12736v1>|[ä»£ç ](https://github.com/CyberAgentAILab/KaoLRM.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Fusing in 3D: Free-Viewpoint Fusion Rendering with a 3D Infrared-Visible Scene Representation|Fusing in 3D: åŸºäºInfrared-Visible 3Dåœºæ™¯è¡¨ç¤ºçš„è‡ªç”±è§†ç‚¹èåˆæ¸²æŸ“|Chao Yang, Deshui Miao, Chao Tian, Guoqing Zhu, Yameng Gu, Zhenyu He|<https://arxiv.org/pdf/2601.12697v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|SM3D: Mitigating Spectral Bias and Semantic Dilution in Point Cloud State Space Models|SM3Dï¼šç¼“è§£ç‚¹äº‘çŠ¶æ€ç©ºé—´æ¨¡å‹ä¸­çš„é¢‘è°±åå·®å’Œè¯­ä¹‰ç¨€é‡Š|Bin Liu, Chunyang Wang, Xuelian Liu|<https://arxiv.org/pdf/2505.11099v3>|[ä»£ç ](https://github.com/L1277471578/SM3D); åˆ†æå¤±è´¥|


### è§†è§‰å®šä½ä¸æ˜ å°„ (Visual Localization & Mapping)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|PERSEUS: Perception with Semantic Endoscopic Understanding and SLAM|PERSEUSï¼šåŸºäºè¯­ä¹‰å†…çª¥é•œç†è§£ä¸SLAMçš„æ„ŸçŸ¥|Ayberk Acar, Fangjie Li, Susheela Sharma Stern, Lidia Al-Zogbi, Hao Li, Kanyifeechukwu Jane Oguine, Dilara Isik, Brendan Burkhart .etc.|<https://arxiv.org/pdf/2509.13541v2>|åˆ†æå¤±è´¥|


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### æ—¶åºå»ºæ¨¡ä¸é¢„æµ‹ (Temporal Modeling & Prediction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|GTPred: Benchmarking MLLMs for Interpretable Geo-localization and Time-of-capture Prediction|GTPred: MLLMså¯è§£é‡Šåœ°ç†å®šä½ä¸æ‹æ‘„æ—¶é—´é¢„æµ‹çš„åŸºå‡†æµ‹è¯•|Jinnao Li, Zijian Chen, Tingzhu Chen, Changbo Wang|<https://arxiv.org/pdf/2601.13207v1>|æ— |


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Perception, Understanding and Reasoning, A Multimodal Benchmark for Video Fake News Detection|Perception, Understanding and Reasoningï¼šè§†é¢‘å‡æ–°é—»æ£€æµ‹çš„å¤šæ¨¡æ€åŸºå‡†|Cui Yakun, Peng Qi, Fushuo Huo, Hang Du, Weijie Shi, Juntao Dai, Zhenghao Zhu, Sirui Han .etc.|<https://arxiv.org/pdf/2510.24816v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|WVSC: Wireless Video Semantic Communication with Multi-frame Compensation|WVSC: åŸºäºå¤šå¸§è¡¥å¿çš„æ— çº¿è§†é¢‘è¯­ä¹‰é€šä¿¡|Bingyan Xie, Yongpeng Wu, Yuxuan Shi, Biqian Feng, Wenjun Zhang, Jihong Park, Tony Q. S. Quek|<https://arxiv.org/pdf/2503.21197v2>|æ— |


## è‡ªç›‘ç£ä¸è¡¨å¾å­¦ä¹  (Self-supervised & Representation Learning)


### è·¨æ¨¡æ€ä¸€è‡´æ€§å­¦ä¹  (Cross-modal Consistency Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|From Bands to Depth: Understanding Bathymetry Decisions on Sentinel-2|ä»æ³¢æ®µåˆ°æ·±åº¦ï¼šç†è§£ Sentinel-2 çš„æ°´æ·±æµ‹é‡å†³ç­–|Satyaki Roy Chowdhury, Aswathnarayan Radhakrishnan, Hsiao Jou Hsu, Hari Subramoni, Joachim Moortgat|<https://arxiv.org/pdf/2601.12636v1>|åˆ†æå¤±è´¥|


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|WEEP: A Differentiable Nonconvex Sparse Regularizer via Weakly-Convex Envelope|WEEPï¼šä¸€ç§åŸºäºå¼±å‡¸åŒ…ç»œçš„å¯å¾®éå‡¸ç¨€ç–æ­£åˆ™åŒ–å™¨|Takanobu Furuhashi, Hidekata Hontani, Qibin Zhao, Tatsuya Yokota|<https://arxiv.org/pdf/2507.20447v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Using deep learning for predicting cleansing quality of colon capsule endoscopy images|[ç¿»è¯‘å¤±è´¥] Using deep learning for predicting cleansing quality of colon capsule endoscopy images|Puneet Sharma, Kristian DalsbÃ¸ Hindberg, Benedicte Schelde-Olesen, Ulrik Deding, Esmaeil S. Nadimi, Jan-Matthias Braun|<https://arxiv.org/pdf/2601.13412v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Aligning Agentic World Models via Knowledgeable Experience Learning|é€šè¿‡çŸ¥è¯†ç»éªŒå­¦ä¹ å¯¹é½æ™ºèƒ½ä½“ä¸–ç•Œæ¨¡å‹|Baochang Ren, Yunzhi Yao, Rui Sun, Shuofei Qiao, Ningyu Zhang, Huajun Chen|<https://arxiv.org/pdf/2601.13247v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Crafting Adversarial Inputs for Large Vision-Language Models Using Black-Box Optimization|åˆ©ç”¨é»‘ç›’ä¼˜åŒ–ä¸ºå¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹åˆ¶ä½œå¯¹æŠ—è¾“å…¥|Jiwei Guan, Haibo Jin, Haohan Wang|<https://arxiv.org/pdf/2601.01747v3>|æ— |
|ğŸ†• å‘å¸ƒ|CSGaussian: Progressive Rate-Distortion Compression and Segmentation for 3D Gaussian Splatting|CSGaussian: 3D Gaussian Splatting çš„æ¸è¿›ç‡å¤±çœŸå‹ç¼©ä¸åˆ†å‰²|Yu-Jen Tseng, Chia-Hao Kao, Jing-Zhong Chen, Alessandro Gnutti, Shao-Yuan Lo, Yen-Yu Lin, Wen-Hsiao Peng|<https://arxiv.org/pdf/2601.12814v1>|æ— |


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics|å…·æœ‰åƒç´ çº§ç²¾åº¦çš„æ¨ç†ï¼šç”¨äºå®šé‡åœ°ç†ç©ºé—´åˆ†æçš„ QVLM æ¶æ„ä¸ SQuID æ•°æ®é›†|Peter A. Massih, Eric Cosatto|<https://arxiv.org/pdf/2601.13401v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Rethinking Skip Connections: Additive U-Net for Robust and Interpretable Denoising|é‡æ–°æ€è€ƒè·³è·ƒè¿æ¥ï¼šç”¨äºé²æ£’ä¸”å¯è§£é‡Šå»å™ªçš„åŠ æ€§ U-Net|Vikram R Lakkavalli|<https://arxiv.org/pdf/2601.13208v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|ConvMambaNet: A Hybrid CNN-Mamba State Space Architecture for Accurate and Real-Time EEG Seizure Detection|ConvMambaNet: ä¸€ç§ç”¨äºç²¾ç¡®å’Œå®æ—¶EEGç™«ç—«æ£€æµ‹çš„æ··åˆCNN-MambaçŠ¶æ€ç©ºé—´æ¶æ„|Md. Nishan Khan, Kazi Shahriar Sanjid, Md. Tanzim Hossain, Asib Mostakim Fony, Istiak Ahmed, M. Monir Uddin|<https://arxiv.org/pdf/2601.13234v1>|æ— |
|ğŸ†• å‘å¸ƒ|TwoHead-SwinFPN: A Unified DL Architecture for Synthetic Manipulation, Detection and Localization in Identity Documents|TwoHead-SwinFPN: ä¸€ç§ç”¨äºèº«ä»½è¯ä»¶åˆæˆç¯¡æ”¹ã€æ£€æµ‹å’Œå®šä½çš„ç»Ÿä¸€DLæ¶æ„|Chan Naseeb, Adeel Ashraf Cheema, Hassan Sami, Tayyab Afzal, Muhammad Omair, Usman Habib|<https://arxiv.org/pdf/2601.12895v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|SKANet: A Cognitive Dual-Stream Framework with Adaptive Modality Fusion for Robust Compound GNSS Interference Classification|SKANet: ä¸€ç§å…·æœ‰è‡ªé€‚åº”æ¨¡æ€èåˆçš„è®¤çŸ¥åŒæµæ¡†æ¶ï¼Œç”¨äºé²æ£’çš„å¤åˆGNSSå¹²æ‰°åˆ†ç±»|Zhihan Zeng, Yang Zhao, Kaihe Wang, Dusit Niyato, Hongyuan Shu, Junchu Zhao, Yanjun Huang, Yue Xiu .etc.|<https://arxiv.org/pdf/2601.12791v1>|æ— |
|ğŸ†• å‘å¸ƒ|PhyG-MoE: A Physics-Guided Mixture-of-Experts Framework for Energy-Efficient GNSS Interference Recognition|PhyG-MoE: ä¸€ç§é¢å‘èŠ‚èƒ½GNSSå¹²æ‰°è¯†åˆ«çš„ç‰©ç†å¼•å¯¼æ··åˆä¸“å®¶æ¡†æ¶|Zhihan Zeng, Yang Zhao, Kaihe Wang, Dusit Niyato, Yue Xiu, Lu Chen, Zhongpei Zhang, Ning Wei|<https://arxiv.org/pdf/2601.12798v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images|Non-IID ç™Œç—‡å›¾åƒä¸Š Federated Learning çš„å¯æ³›åŒ– Hyperparameter Optimization|Elisa GonÃ§alves Ribeiro, Rodrigo Moreira, Larissa Ferreira Rodrigues Moreira, AndrÃ© Ricardo Backes|<https://arxiv.org/pdf/2601.12664v1>|åˆ†æå¤±è´¥|


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|LLM-VLM Fusion Framework for Autonomous Maritime Port Inspection using a Heterogeneous UAV-USV System|ç”¨äºå¼‚æ„ UAV-USV ç³»ç»Ÿè‡ªä¸»æµ·äº‹æ¸¯å£æ£€æŸ¥çš„ LLM-VLM èåˆæ¡†æ¶|Muhayy Ud Din, Waseem Akram, Ahsan B. Bakht, Irfan Hussain|<https://arxiv.org/pdf/2601.13096v1>|[ä»£ç ](https://github.com/Muhayyuddin/llm-vlm-fusion-port-inspection)|
|ğŸ“ æ›´æ–°|ChartComplete: A Taxonomy-based Inclusive Chart Dataset|ChartComplete: åŸºäºåˆ†ç±»å­¦çš„å…¨é¢å›¾è¡¨æ•°æ®é›†|Ahmad Mustapha, Charbel Toumieh, Mariette Awad|<https://arxiv.org/pdf/2601.10462v3>|æ— |


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### å¯¹æŠ—é²æ£’æ€§ (Adversarial Robustness)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Sy-FAR: Symmetry-based Fair Adversarial Robustness|Sy-FAR: åŸºäºå¯¹ç§°æ€§çš„å…¬å¹³å¯¹æŠ—é²æ£’æ€§|Haneen Najjar, Eyal Ronen, Mahmood Sharif|<https://arxiv.org/pdf/2509.12939v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Proxy Robustness in Vision Language Models is Effortlessly Transferable|Vision Language Models ä¸­çš„ Proxy Robustness å¯è½»æ¾è¿ç§»|Xiaowei Fu, Fuxiang Huang, Lei Zhang|<https://arxiv.org/pdf/2601.12865v1>|[ä»£ç ](https://github.com/fxw13/HPT-GPD.)|
|ğŸ†• å‘å¸ƒ|Combating Noisy Labels through Fostering Self- and Neighbor-Consistency|é€šè¿‡ä¿ƒè¿›è‡ªèº«å’Œé‚»å±…ä¸€è‡´æ€§æ¥å¯¹æŠ—å™ªå£°æ ‡ç­¾|Zeren Sun, Yazhou Yao, Tongliang Liu, Zechao Li, Fumin Shen, Jinhui Tang|<https://arxiv.org/pdf/2601.12795v1>|åˆ†æå¤±è´¥|


### åˆ†å¸ƒå¤–æ³›åŒ– (Out-of-distribution Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Simple Yet Effective Selective Imputation for Incomplete Multi-view Clustering|[ç¿»è¯‘å¤±è´¥] Simple Yet Effective Selective Imputation for Incomplete Multi-view Clustering|Cai Xu, Jinlong Liu, Yilin Zhang, Ziyu Guan, Wei Zhao, Xiaofei He|<https://arxiv.org/pdf/2512.10327v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Unified Source-Free Domain Adaptation|[ç¿»è¯‘å¤±è´¥] Unified Source-Free Domain Adaptation|Song Tang, Wenxin Su, Mao Ye, Boyu Wang, Xiatian Zhu|<https://arxiv.org/pdf/2403.07601v4>|[ä»£ç ](https://github.com/tntek/CausalDA.); åˆ†æå¤±è´¥|


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### å°æ ·æœ¬å­¦ä¹  (Few-shot Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Organ-Aware Attention Improves CT Triage and Classification|Organ-Aware Attention æ”¹è¿› CT åˆ†è¯Šä¸åˆ†ç±»|Lavsen Dahal, Yubraj Bhandari, Geoffrey D. Rubin, Joseph Y. Lo|<https://arxiv.org/pdf/2601.13385v1>|[ä»£ç ](https://github.com/lavsendahal/oracle-ct.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Near-Light Color Photometric Stereo for mono-Chromaticity non-lambertian surface|[ç¿»è¯‘å¤±è´¥] Near-Light Color Photometric Stereo for mono-Chromaticity non-lambertian surface|Zonglin Li, Jieji Ren, Shuangfan Zhou, Heng Guo, Jinnuo Zhang, Jiang Zhou, Boxin Shi, Zhanyu Ma .etc.|<https://arxiv.org/pdf/2601.12666v1>|åˆ†æå¤±è´¥|


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|QASA: Quality-Guided K-Adaptive Slot Attention for Unsupervised Object-Centric Learning|QASAï¼šç”¨äºæ— ç›‘ç£ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒå­¦ä¹ çš„è´¨é‡å¼•å¯¼Kè‡ªé€‚åº”Slot Attention|Tianran Ouyang, Xingping Dong, Jing Zhang, Mang Ye, Jun Chen, Bo Du|<https://arxiv.org/pdf/2601.12936v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Supervision-by-Hallucination-and-Transfer: A Weakly-Supervised Approach for Robust and Precise Facial Landmark Detection|Supervision-by-Hallucination-and-Transfer: ä¸€ç§ç”¨äºé²æ£’ä¸”ç²¾ç¡® Facial Landmark Detection çš„ Weakly-Supervised æ–¹æ³•|Jun Wan, Yuanzhi Yao, Zhihui Lai, Jie Zhou, Xianxu Hou, Wenwen Min|<https://arxiv.org/pdf/2601.12919v1>|æ— |
|ğŸ†• å‘å¸ƒ|Data-Consistent Learning of Inverse Problems|Inverse Problems çš„ Data-Consistent Learning|Markus Haltmeier, Gyeongha Hwang|<https://arxiv.org/pdf/2601.12831v1>|æ— |
|ğŸ†• å‘å¸ƒ|P2L-CA: An Effective Parameter Tuning Framework for Rehearsal-Free Multi-Label Class-Incremental Learning|P2L-CA: ä¸€ç§ç”¨äºå…æ’ç»ƒå¤šæ ‡ç­¾ç±»å¢é‡å­¦ä¹ çš„æœ‰æ•ˆå‚æ•°è°ƒä¼˜æ¡†æ¶|Songlin Dong, Jiangyang Li, Chenhao Ding, Zhiheng Ma, Haoyu Luo, Yuhang He, Yihong Gong|<https://arxiv.org/pdf/2601.12714v1>|æ— |


### é›¶/å°‘æ ·æœ¬æ³›åŒ– (Zero/Few-shot Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension|VIROï¼šåŸºäºéªŒè¯çš„é²æ£’é«˜æ•ˆç¥ç»ç¬¦å·æ¨ç†ç”¨äºæŒ‡ä»£è¡¨è¾¾ç†è§£|Hyejin Park, Junhyuk Kwon, Suha Kwak, Jungseul Ok|<https://arxiv.org/pdf/2601.12781v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Spatial-VLN: Zero-Shot Vision-and-Language Navigation With Explicit Spatial Perception and Exploration|Spatial-VLN: å…·æœ‰æ˜¾å¼ç©ºé—´æ„ŸçŸ¥ä¸æ¢ç´¢çš„ Zero-Shot Vision-and-Language Navigation|Lu Yue, Yue Fan, Shiwei Lian, Yu Zhao, Jiaxin Yu, Liang Xie, Feitian Zhang|<https://arxiv.org/pdf/2601.12766v1>|[ä»£ç ](https://yueluhhxx.github.io/Spatial-VLN-web); åˆ†æå¤±è´¥|


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è·¨æ¨¡æ€æ£€ç´¢ä¸åŒ¹é… (Cross-modal Retrieval & Matching)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Enginuity: Building an Open Multi-Domain Dataset of Complex Engineering Diagrams|Enginuityï¼šæ„å»ºä¸€ä¸ªå¤æ‚å·¥ç¨‹å›¾è¡¨çš„å¼€æ”¾å¤šåŸŸæ•°æ®é›†|Ethan Seefried, Prahitha Movva, Naga Harshita Marupaka, Tilak Kasturi, Tirthankar Ghosal|<https://arxiv.org/pdf/2601.13299v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Delving Deeper: Hierarchical Visual Perception for Robust Video-Text Retrieval|Delving Deeper: ç”¨äºé²æ£’ Video-Text Retrieval çš„åˆ†å±‚è§†è§‰æ„ŸçŸ¥|Zequn Xie, Boyun Zhang, Yuxiao Lin, Tao Jin|<https://arxiv.org/pdf/2601.12768v1>|[ä»£ç ](https://github.com/boyun-zhang/HVP-Net.); åˆ†æå¤±è´¥|


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|CausalSpatial: A Benchmark for Object-Centric Causal Spatial Reasoning|CausalSpatial: ä¸€ä¸ªä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„å› æœç©ºé—´æ¨ç†åŸºå‡†|Wenxin Ma, Chenlong Wang, Ruisheng Yuan, Hao Chen, Nanru Dai, S. Kevin Zhou, Yijun Yang, Alan Yuille .etc.|<https://arxiv.org/pdf/2601.13304v1>|[ä»£ç ](https://github.com/CausalSpatial/CausalSpatial); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|ObjectVisA-120: Object-based Visual Attention Prediction in Interactive Street-crossing Environments|ObjectVisA-120ï¼šInteractive Street-crossing Environments ä¸­åŸºäº Object çš„ Visual Attention Prediction|Igor Vozniak, Philipp Mueller, Nils Lipp, Janis Sprenger, Konstantin Poddubnyy, Davit Hovhannisyan, Christian Mueller, Andreas Bulling .etc.|<https://arxiv.org/pdf/2601.13218v1>|æ— |
|ğŸ“ æ›´æ–°|Visual Hand Gesture Recognition with Deep Learning: A Comprehensive Review of Methods, Datasets, Challenges and Future Research Directions|åŸºäºæ·±åº¦å­¦ä¹ çš„è§†è§‰æ‰‹åŠ¿è¯†åˆ«ï¼šæ–¹æ³•ã€æ•°æ®é›†ã€æŒ‘æˆ˜ä¸æœªæ¥ç ”ç©¶æ–¹å‘ç»¼è¿°|Konstantinos Foteinos, Manousos Linardakis, Panagiotis Radoglou-Grammatikis, Vasileios Argyriou, Panagiotis Sarigiannidis, Iraklis Varlamis, Georgios Th. Papadopoulos|<https://arxiv.org/pdf/2507.04465v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|CLIP-Guided Adaptable Self-Supervised Learning for Human-Centric Visual Tasks|CLIPå¼•å¯¼çš„ä»¥äººä¸ºä¸­å¿ƒçš„è§†è§‰ä»»åŠ¡è‡ªé€‚åº”è‡ªç›‘ç£å­¦ä¹ |Mingshuang Luo, Ruibing Hou, Bo Chao, Hong Chang, Zimo Liu, Yaowei Wang, Shiguang Shan|<https://arxiv.org/pdf/2601.13133v1>|æ— |
|ğŸ†• å‘å¸ƒ|DC-VLAQ: Query-Residual Aggregation for Robust Visual Place Recognition|DC-VLAQ: ç”¨äºé²æ£’è§†è§‰åœ°ç‚¹è¯†åˆ«çš„ Query-Residual èšåˆ|Hanyu Zhu, Zhihao Zhan, Yuhang Ming, Liang Li, Dibo Hou, Javier Civera, Wanzeng Kong|<https://arxiv.org/pdf/2601.12729v1>|åˆ†æå¤±è´¥|


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|AI-generated data contamination erodes pathological variability and diagnostic reliability|[ç¿»è¯‘å¤±è´¥] AI-generated data contamination erodes pathological variability and diagnostic reliability|Hongyu He, Shaowen Xiang, Ye Zhang, Yingtao Zhu, Jin Zhang, Hao Deng, Emily Alsentzer, Qingyu Chen .etc.|<https://arxiv.org/pdf/2601.12946v2>|æ— |
|ğŸ†• å‘å¸ƒ|SGW-GAN: Sliced Gromov-Wasserstein Guided GANs for Retinal Fundus Image Enhancement|[ç¿»è¯‘å¤±è´¥] SGW-GAN: Sliced Gromov-Wasserstein Guided GANs for Retinal Fundus Image Enhancement|Yujian Xiong, Xuanzhao Dong, Wenhui Zhu, Xin Li, Oana Dumitrascu, Yalin Wang|<https://arxiv.org/pdf/2601.13417v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Beyond Knowledge Silos: Task Fingerprinting for Democratization of Medical Imaging AI|æ‰“ç ´çŸ¥è¯†å­¤å²›ï¼šç”¨äºåŒ»å­¦å½±åƒ AI æ°‘ä¸»åŒ–çš„ Task Fingerprinting|Patrick Godau, Akriti Srivastava, Constantin Ulrich, Tim Adler, Klaus Maier-Hein, Lena Maier-Hein|<https://arxiv.org/pdf/2412.08763v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Patient-Conditioned Adaptive Offsets for Reliable Diagnosis across Subgroups|Patient-Conditioned è‡ªé€‚åº”åç§»ç”¨äºè·¨å­ç»„çš„å¯é è¯Šæ–­|Gelei Xu, Yuying Duan, Jun Xia, Ruining Deng, Wei Jin, Yiyu Shi|<https://arxiv.org/pdf/2601.13094v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Comparative validation of surgical phase recognition, instrument keypoint estimation, and instrument instance segmentation in endoscopy: Results of the PhaKIR 2024 challenge|å†…çª¥é•œæ‰‹æœ¯é˜¶æ®µè¯†åˆ«ã€å™¨æ¢°å…³é”®ç‚¹ä¼°è®¡å’Œå™¨æ¢°å®ä¾‹åˆ†å‰²çš„æ¯”è¾ƒéªŒè¯ï¼šPhaKIR 2024æŒ‘æˆ˜èµ›ç»“æœ|Tobias Rueckert, David Rauber, Raphaela Maerkl, Leonard Klausmann, Suemeyye R. Yildiran, Max Gutbrod, Danilo Weber Nunes, Alvaro Fernandez Moreno .etc.|<https://arxiv.org/pdf/2507.16559v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Cross-Scale Pretraining: Enhancing Self-Supervised Learning for Low-Resolution Satellite Imagery for Semantic Segmentation|è·¨å°ºåº¦é¢„è®­ç»ƒï¼šå¢å¼ºç”¨äºè¯­ä¹‰åˆ†å‰²çš„ä½åˆ†è¾¨ç‡å«æ˜Ÿå›¾åƒçš„è‡ªç›‘ç£å­¦ä¹ |John Waithaka, Gustave Bwirayesu, Moise Busogi|<https://arxiv.org/pdf/2601.12964v1>|æ— |
|ğŸ“ æ›´æ–°|Jordan-Segmentable Masks: A Topology-Aware definition for characterizing Binary Image Segmentation|Jordan-Segmentable Masksï¼šä¸€ç§ç”¨äºè¡¨å¾ Binary Image Segmentation çš„ Topology-Aware å®šä¹‰|Serena Grazia De Benedictis, Amedeo Altavilla, Nicoletta Del Buono|<https://arxiv.org/pdf/2601.10577v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|YOLO26: An Analysis of NMS-Free End to End Framework for Real-Time Object Detection|YOLO26ï¼šä¸€ç§ç”¨äºå®æ—¶ç›®æ ‡æ£€æµ‹çš„æ— NMSç«¯åˆ°ç«¯æ¡†æ¶åˆ†æ|Sudip Chakrabarty|<https://arxiv.org/pdf/2601.12882v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Seeing Isn't Always Believing: Analysis of Grad-CAM Faithfulness and Localization Reliability in Lung Cancer CT Classification|[ç¿»è¯‘å¤±è´¥] Seeing Isn't Always Believing: Analysis of Grad-CAM Faithfulness and Localization Reliability in Lung Cancer CT Classification|Teerapong Panboonyuen|<https://arxiv.org/pdf/2601.12826v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|SSPFormer: Self-Supervised Pretrained Transformer for MRI Images|SSPFormer: ç”¨äºMRIå›¾åƒçš„è‡ªç›‘ç£é¢„è®­ç»ƒTransformer|Jingkai Li, Xiaoze Tian, Yuhang Shen, Jia Wang, Dianjie Lu, Guijuan Zhang, Zhuoran Zheng|<https://arxiv.org/pdf/2601.12747v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification|åˆ©ç”¨ Test-Time Augmentation æå‡è”é‚¦å­¦ä¹ ä¸­çš„è„‘è‚¿ç˜¤ MRI åˆ†ç±»|Thamara Leandra de Deus Melo, Rodrigo Moreira, Larissa Ferreira Rodrigues Moreira, AndrÃ© Ricardo Backes|<https://arxiv.org/pdf/2601.12671v1>|æ— |
|ğŸ“ æ›´æ–°|PraNet-V2: Dual-Supervised Reverse Attention for Medical Image Segmentation|PraNet-V2: ç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²çš„åŒé‡ç›‘ç£åå‘æ³¨æ„åŠ›|Bo-Cheng Hu, Ge-Peng Ji, Dian Shao, Deng-Ping Fan|<https://arxiv.org/pdf/2504.10986v2>|[ä»£ç ](https://github.com/ai4colonoscopy/PraNet-V2); åˆ†æå¤±è´¥|


### å·¥ä¸šè§†è§‰æ£€æµ‹ (Industrial Visual Inspection)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Analyzing VLM-Based Approaches for Anomaly Classification and Segmentation|åŸºäºVLMçš„æ–¹æ³•ç”¨äºå¼‚å¸¸åˆ†ç±»ä¸åˆ†å‰²çš„åˆ†æ|Mohit Kakda, Mirudula Shri Muthukumaran, Uttapreksha Patel, Lawrence Swaminathan Xavier Prince|<https://arxiv.org/pdf/2601.13440v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Simultaneous Detection of LSD and FMD in Cattle Using Ensemble Deep Learning|åŸºäºé›†æˆæ·±åº¦å­¦ä¹ çš„ç‰› LSD å’Œ FMD åŒæ—¶æ£€æµ‹|Nazibul Basar Ayon, Abdul Hasib, Md. Faishal Ahmed, Md. Sadiqur Rahman, Kamrul Islam, T. M. Mehrab Hasan, A. S. M. Ahsanul Sarkar Akib|<https://arxiv.org/pdf/2601.12889v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|SSVP: Synergistic Semantic-Visual Prompting for Industrial Zero-Shot Anomaly Detection|SSVP: ç”¨äºå·¥ä¸šé›¶æ ·æœ¬å¼‚å¸¸æ£€æµ‹çš„ååŒè¯­ä¹‰-è§†è§‰æç¤º|Chenhao Fu, Han Fang, Xiuzheng Zheng, Wenbo Wei, Yonghua Li, Hao Sun, Xuelong Li|<https://arxiv.org/pdf/2601.09147v2>|æ— |


### åˆ›æ„åª’ä½“ç”Ÿæˆ (Creative Media Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|AsyncBEV: Cross-modal Flow Alignment in Asynchronous 3D Object Detection|AsyncBEVï¼šå¼‚æ­¥3Dç›®æ ‡æ£€æµ‹ä¸­çš„è·¨æ¨¡æ€æµå¯¹é½|Shiming Wang, Holger Caesar, Liangliang Nan, Julian F. P. Kooij|<https://arxiv.org/pdf/2601.12994v1>|åˆ†æå¤±è´¥|


### æ™ºèƒ½äº¤é€šè§†è§‰ (Intelligent Transportation Vision)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|VILTA: A VLM-in-the-Loop Adversary for Enhancing Driving Policy Robustness|[ç¿»è¯‘å¤±è´¥] VILTA: A VLM-in-the-Loop Adversary for Enhancing Driving Policy Robustness|Qimao Chen, Fang Li, Shaoqing Xu, Zhiyi Lai, Zixun Xie, Yuechen Luo, Shengyin Jiang, Hanbing Li .etc.|<https://arxiv.org/pdf/2601.12672v1>|æ— |


## æ–°å…´ç†è®ºä¸è·¨å­¦ç§‘æ–¹å‘ (Emerging Theory & Interdisciplinary Directions)


### ç¥ç»-ç¬¦å·è§†è§‰ (Neuro-symbolic Vision)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Local-to-Global Logical Explanations for Deep Vision Models|[ç¿»è¯‘å¤±è´¥] Local-to-Global Logical Explanations for Deep Vision Models|Bhavan Vasu, Giuseppe Raffa, Prasad Tadepalli|<https://arxiv.org/pdf/2601.13404v1>|æ— |
|ğŸ†• å‘å¸ƒ|Left-Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data|åŸºäºåˆæˆç©ºé—´å…³ç³»æ•°æ®è®­ç»ƒçš„ CLIP é£æ ¼è§†è§‰-è¯­è¨€æ¨¡å‹ä¸­çš„å·¦å³å¯¹ç§°æ€§ç ´ç¼º|Takaki Yamamoto, Chihiro Noguchi, Toshihiro Tanizawa|<https://arxiv.org/pdf/2601.12809v1>|æ— |


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Not all Blends are Equal: The BLEMORE Dataset of Blended Emotion Expressions with Relative Salience Annotations|[ç¿»è¯‘å¤±è´¥] Not all Blends are Equal: The BLEMORE Dataset of Blended Emotion Expressions with Relative Salience Annotations|Tim Lachmann, Alexandra Israelsson, Christina Tornberg, Teimuraz Saghinadze, Michal Balazia, Philipp MÃ¼ller, Petri Laukka|<https://arxiv.org/pdf/2601.13225v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Event2Audio: Event-Based Optical Vibration Sensing|Event2Audio: åŸºäºEventçš„å…‰å­¦æŒ¯åŠ¨æ„ŸçŸ¥|Mingxuan Cai, Dekel Galor, Amit Pal Singh Kohli, Jacob L. Yates, Laura Waller|<https://arxiv.org/pdf/2507.03273v2>|æ— |

