## [UPDATED!] **2026-01-20** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|VIAFormer: Voxel-Image Alignment Transformer for High-Fidelity Voxel Refinement|VIAFormer: ç”¨äºé«˜ä¿çœŸ Voxel ç»†åŒ–çš„ Voxel-Image Alignment Transformer|Tiancheng Fang, Bowen Pan, Lingxi Chen, Jiangjing Lyu, Chengfei Lyu, Chaoyue Niu, Fan Wu|<https://arxiv.org/pdf/2601.13664v2>|æ— |
|ğŸ†• å‘å¸ƒ|HiT: History-Injection Transformers for Onboard Continuous Flood Change Detection|HiTï¼šç”¨äºæ˜Ÿè½½è¿ç»­æ´ªæ°´å˜åŒ–æ£€æµ‹çš„ History-Injection Transformers|Daniel Kyselica, JonÃ¡Å¡ Herec, Oliver Kutis, Rado PitoÅˆÃ¡k|<https://arxiv.org/pdf/2601.13751v2>|[ä»£ç ](https://github.com/zaitra/HiT-change-detection)|
|ğŸ†• å‘å¸ƒ|LLMOrbit: A Circular Taxonomy of Large Language Models -From Scaling Walls to Agentic AI Systems|LLMOrbit: å¤§è¯­è¨€æ¨¡å‹çš„å¾ªç¯åˆ†ç±»æ³•â€”â€”ä»æ‰©å±•å¢™åˆ° Agentic AI ç³»ç»Ÿ|Badri N. Patro, Vijay S. Agneeswaran|<https://arxiv.org/pdf/2601.14053v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Multimodal Emotion Recognition using Audio-Video Transformer Fusion with Cross Attention|ä½¿ç”¨ Cross Attention çš„ Audio-Video Transformer Fusion è¿›è¡Œå¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«|Joe Dhanith P R, Shravan Venkatraman, Vigya Sharma, Santhosh Malarvannan|<https://arxiv.org/pdf/2407.18552v4>|[ä»£ç ](https://github.com/shravan-18/AVTCA.); åˆ†æå¤±è´¥|


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection|è¶…è¶Šè¾¹ç•Œï¼šåˆ©ç”¨Vision Foundation Modelsè¿›è¡ŒSource-Free Object Detection|Huizai Yao, Sicheng Zhao, Pengteng Li, Yi Cui, Shuo Lu, Weiyu Guo, Yunfan Lu, Yijie Xu .etc.|<https://arxiv.org/pdf/2511.07301v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR|LightOnOCRï¼šä¸€ä¸ªç”¨äº State-of-the-Art OCR çš„ 1B ç«¯åˆ°ç«¯å¤šè¯­è¨€ Vision-Language Model|Said Taghadouini, Adrien CavaillÃ¨s, Baptiste Aubertin|<https://arxiv.org/pdf/2601.14251v1>|æ— |
|ğŸ†• å‘å¸ƒ|Vision Also You Need: Navigating Out-of-Distribution Detection with Multimodal Large Language Model|Vision Also You Need: åˆ©ç”¨ Multimodal Large Language Model å¯¼èˆª Out-of-Distribution Detection|Haoran Xu, Yanlin Liu, Zizhao Tong, Jiaze Li, Kexue Fu, Yuyang Zhang, Longxiang Gao, Shuaiguang Li .etc.|<https://arxiv.org/pdf/2601.14052v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|OCCAM: Class-Agnostic, Training-Free, Prior-Free and Multi-Class Object Counting|[ç¿»è¯‘å¤±è´¥] OCCAM: Class-Agnostic, Training-Free, Prior-Free and Multi-Class Object Counting|Michail Spanakis, Iason Oikonomidis, Antonis Argyros|<https://arxiv.org/pdf/2601.13871v1>|[ä»£ç ](https://mikespanak.github.io/OCCAM_counter.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|CARI4D: Category Agnostic 4D Reconstruction of Human-Object Interaction|CARI4D: ç±»åˆ«æ— å…³çš„äººç‰©äº¤äº’4Dé‡å»º|Xianghui Xie, Bowen Wen, Yan Chang, Hesam Rabeti, Jiefeng Li, Ye Yuan, Gerard Pons-Moll, Stan Birchfield|<https://arxiv.org/pdf/2512.11988v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Vidi2.5: Large Multimodal Models for Video Understanding and Creation|Vidi2.5: ç”¨äºè§†é¢‘ç†è§£å’Œåˆ›ä½œçš„å¤§å‹å¤šæ¨¡æ€æ¨¡å‹|Vidi Team, Chia-Wen Kuo, Chuang Huang, Dawei Du, Fan Chen, Fanding Lei, Feng Gao, Guang Chen .etc.|<https://arxiv.org/pdf/2511.19529v2>|åˆ†æå¤±è´¥|


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery|LLMå¢å¼ºçš„å¯å¹²é¢„å¤šæ¨¡æ€é€‚é…å™¨ç”¨äºè‚ºç™Œæ‰‹æœ¯æœ¯åå¹¶å‘ç—‡é¢„æµ‹|Shubham Pandey, Bhavin Jawade, Srirangaraj Setlur, Venu Govindaraju, Kenneth Seastedt|<https://arxiv.org/pdf/2601.14154v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Weather-R1: Logically Consistent Reinforcement Fine-Tuning for Multimodal Reasoning in Meteorology|Weather-R1ï¼šæ°”è±¡å­¦å¤šæ¨¡æ€æ¨ç†çš„é€»è¾‘ä¸€è‡´æ€§å¼ºåŒ–å¾®è°ƒ|Kaiyu Wu, Pucheng Han, Hualong Zhang, Naigeng Wu, Keze Wang|<https://arxiv.org/pdf/2601.14044v1>|[ä»£ç ](https://github.com/Marcowky/Weather-R1.)|
|ğŸ†• å‘å¸ƒ|FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation|FantasyVLNï¼šç”¨äº Vision-Language Navigation çš„ç»Ÿä¸€å¤šæ¨¡æ€ Chain-of-Thought æ¨ç†|Jing Zuo, Lingzhou Mu, Fan Jiang, Chengcheng Ma, Mu Xu, Yonggang Qi|<https://arxiv.org/pdf/2601.13976v1>|æ— |
|ğŸ†• å‘å¸ƒ|FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs|FutureOmniï¼šè¯„ä¼°å¤šæ¨¡æ€LLMåŸºäºå…¨æ¨¡æ€ä¸Šä¸‹æ–‡çš„æœªæ¥é¢„æµ‹|Qian Chen, Jinlan Fu, Changsong Li, See-Kiong Ng, Xipeng Qiu|<https://arxiv.org/pdf/2601.13836v1>|[ä»£ç ](https://github.com/OpenMOSS/FutureOmni); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|GeoSurDepth: Harnessing Foundation Model for Spatial Geometry Consistency-Oriented Self-Supervised Surround-View Depth Estimation|GeoSurDepth: åˆ©ç”¨Foundation Modelå®ç°é¢å‘ç©ºé—´å‡ ä½•ä¸€è‡´æ€§çš„è‡ªç›‘ç£ç¯è§†æ·±åº¦ä¼°è®¡|Weimin Liu, Wenjun Wang, Joshua H. Meng|<https://arxiv.org/pdf/2601.05839v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Face-Voice Association with Inductive Bias for Maximum Class Separation|åŸºäºå½’çº³åå·®ä»¥å®ç°æœ€å¤§ç±»åˆ«åˆ†ç¦»çš„Face-Voice Association|Marta Moscati, Oleksandr Kats, Mubashir Noman, Muhammad Zaigham Zaheer, Yufang Hou, Markus Schedl, Shah Nawaz|<https://arxiv.org/pdf/2601.13651v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|CARPE: Context-Aware Image Representation Prioritization via Ensemble for Large Vision-Language Models|CARPEï¼šåŸºäºé›†æˆçš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥å›¾åƒè¡¨ç¤ºä¼˜å…ˆçº§æ’åºï¼Œç”¨äºå¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹|Donghee Lee, Rui Cai, Zhe Zhao|<https://arxiv.org/pdf/2601.13622v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Hierarchy-Aware Multimodal Unlearning for Medical AI|[ç¿»è¯‘å¤±è´¥] Hierarchy-Aware Multimodal Unlearning for Medical AI|Fengli Wu, Vaidehi Patil, Jaehong Yoon, Yue Zhang, Mohit Bansal|<https://arxiv.org/pdf/2512.09867v2>|åˆ†æå¤±è´¥|


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Gaussian Based Adaptive Multi-Modal 3D Semantic Occupancy Prediction|åŸºäº Gaussian çš„è‡ªé€‚åº”å¤šæ¨¡æ€ 3D è¯­ä¹‰å æ®é¢„æµ‹|A. Enes Doruk|<https://arxiv.org/pdf/2601.14448v1>|æ— |
|ğŸ†• å‘å¸ƒ|GIC-DLC: Differentiable Logic Circuits for Hardware-Friendly Grayscale Image Compression|GIC-DLC: é¢å‘ç¡¬ä»¶å‹å¥½çš„ç°åº¦å›¾åƒå‹ç¼©çš„å¯å¾®åˆ†é€»è¾‘ç”µè·¯|Till Aczel, David F. Jenny, Simon BÃ¼hrer, Andreas Plesner, Antonio Di Maio, Roger Wattenhofer|<https://arxiv.org/pdf/2601.14130v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|FlyPose: Towards Robust Human Pose Estimation From Aerial Views|FlyPose: é¢å‘é²æ£’èˆªæ‹è§†è§’äººä½“å§¿æ€ä¼°è®¡|Hassaan Farooq, Marvin Brenner, Peter StÃ¼tz|<https://arxiv.org/pdf/2601.05747v2>|[ä»£ç ](https://github.com/farooqhassaan/FlyPose.)|
|ğŸ†• å‘å¸ƒ|On the Role of Rotation Equivariance in Monocular 3D Human Pose Estimation|è®ºæ—‹è½¬ç­‰å˜æ€§åœ¨å•ç›®3Däººä½“å§¿æ€ä¼°è®¡ä¸­çš„ä½œç”¨|Pavlo Melnyk, Cuong Le, Urs Waldmann, Per-Erik ForssÃ©n, Bastian Wandt|<https://arxiv.org/pdf/2601.13913v1>|æ— |
|ğŸ†• å‘å¸ƒ|Transformer based Multi-task Fusion Network for Food Spoilage Detection and Shelf life Forecasting|åŸºäº Transformer çš„å¤šä»»åŠ¡èåˆç½‘ç»œç”¨äºé£Ÿå“è…è´¥æ£€æµ‹ä¸ä¿è´¨æœŸé¢„æµ‹|Mounika Kanulla, Rajasree Dadigi, Sailaja Thota, Vivek Yelleti|<https://arxiv.org/pdf/2601.13665v1>|æ— |
|ğŸ†• å‘å¸ƒ|Learning Fine-Grained Correspondence with Cross-Perspective Perception for Open-Vocabulary 6D Object Pose Estimation|åˆ©ç”¨è·¨è§†è§’æ„ŸçŸ¥å­¦ä¹ ç»†ç²’åº¦å¯¹åº”å…³ç³»ä»¥å®ç°å¼€æ”¾è¯æ±‡6Dç‰©ä½“å§¿æ€ä¼°è®¡|Yu Qin, Shimeng Fan, Fan Yang, Zixuan Xue, Zijie Mai, Wenrui Chen, Kailun Yang, Zhiyong Li|<https://arxiv.org/pdf/2601.13565v1>|[ä»£ç ](https://github.com/zjjqinyu/FiCoP.)|


### è¯­ä¹‰/å®ä¾‹åˆ†å‰² (Semantic/Instance Segmentation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|SuperGSeg: Open-Vocabulary 3D Segmentation with Structured Super-Gaussians|SuperGSeg: åŸºäºç»“æ„åŒ–è¶…é«˜æ–¯çš„å¼€æ”¾è¯æ±‡ 3D åˆ†å‰²|Siyun Liang, Sen Wang, Kunyi Li, Michael Niemeyer, Stefano Gasperini, Hendrik P. A. Lensch, Nassir Navab, Federico Tombari|<https://arxiv.org/pdf/2412.10231v3>|æ— |
|ğŸ“ æ›´æ–°|Federated Unsupervised Semantic Segmentation|è”é‚¦æ— ç›‘ç£è¯­ä¹‰åˆ†å‰²|Evangelos Charalampakis, Vasileios Mygdalis, Ioannis Pitas|<https://arxiv.org/pdf/2505.23292v2>|[ä»£ç ](https://github.com/evanchar/FUSS); åˆ†æå¤±è´¥|


### å›¾åƒåˆ†ç±»ä¸è¯†åˆ« (Image Classification & Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MooneyMaker: A Python package to create ambiguous two-tone images|MooneyMakerï¼šç”¨äºåˆ›å»ºæ¨¡ç³ŠåŒè‰²å›¾åƒçš„ Python åŒ…|Lars C. Reining, Thabo Matthies, Luisa Haussner, Rabea Turon, Thomas S. A. Wallis|<https://arxiv.org/pdf/2601.14077v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Insight: Interpretable Semantic Hierarchies in Vision-Language Encoders|Insightï¼šVision-Language Encoder ä¸­çš„å¯è§£é‡Šè¯­ä¹‰å±‚æ¬¡|Kai Wittenmayer, Sukrut Rao, Amin Parchami-Araghi, Bernt Schiele, Jonas Fischer|<https://arxiv.org/pdf/2601.13798v1>|[ä»£ç ](https://github.com/kawi19/Insight.); åˆ†æå¤±è´¥|


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Coding the Visual World: From Image to Simulation Using Vision Language Models|ç¼–ç è§†è§‰ä¸–ç•Œï¼šåˆ©ç”¨ Vision Language Models ä»å›¾åƒåˆ°ä»¿çœŸ|Sagi Eppel|<https://arxiv.org/pdf/2601.05344v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|DiffRatio: Training One-Step Diffusion Models Without Teacher Supervision|DiffRatio: æ— æ•™å¸ˆç›‘ç£çš„å•æ­¥æ‰©æ•£æ¨¡å‹è®­ç»ƒ|Wenlin Chen, Mingtian Zhang, Jiajun He, Zijing Ou, JosÃ© Miguel HernÃ¡ndez-Lobato, Bernhard SchÃ¶lkopf, David Barber|<https://arxiv.org/pdf/2502.08005v4>|æ— |
|ğŸ†• å‘å¸ƒ|Diffusion-Guided Backdoor Attacks in Real-World Reinforcement Learning|[ç¿»è¯‘å¤±è´¥] Diffusion-Guided Backdoor Attacks in Real-World Reinforcement Learning|Tairan Huang, Qingqing Ye, Yulin Jin, Jiawei Lian, Yi Wang, Haibo Hu|<https://arxiv.org/pdf/2601.14104v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|ESPLoRA: Enhanced Spatial Precision with Low-Rank Adaption in Text-to-Image Diffusion Models for High-Definition Synthesis|ESPLoRAï¼šText-to-Image Diffusion Models ä¸­åˆ©ç”¨ Low-Rank Adaption æå‡ç©ºé—´ç²¾åº¦ä»¥å®ç° High-Definition Synthesis|Andrea Rigo, Luca Stornaiuolo, Mauro Martino, Bruno Lepri, Nicu Sebe|<https://arxiv.org/pdf/2504.13745v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Likelihood-Separable Diffusion Inference for Multi-Image MRI Super-Resolution|[ç¿»è¯‘å¤±è´¥] Likelihood-Separable Diffusion Inference for Multi-Image MRI Super-Resolution|Samuel W. Remedios, Zhangxing Bian, Shuwen Wei, Aaron Carass, Jerry L. Prince, Blake E. Dewey|<https://arxiv.org/pdf/2601.14030v1>|æ— |
|ğŸ†• å‘å¸ƒ|Self-Supervised Score-Based Despeckling for SAR Imagery via Log-Domain Transformation|åŸºäºåŸŸå˜æ¢ä¸‹çš„SARå›¾åƒè‡ªç›‘ç£åŸºäºå»æ–‘ç®—æ³•|Junhyuk Heo|<https://arxiv.org/pdf/2601.14334v1>|æ— |
|ğŸ“ æ›´æ–°|Controllable Localized Face Anonymization Via Diffusion Inpainting|åŸºäº Diffusion Inpainting çš„å¯æ§å±€éƒ¨äººè„¸åŒ¿ååŒ–|Ali Salar, Qing Liu, Guoying Zhao|<https://arxiv.org/pdf/2509.14866v2>|æ— |
|ğŸ†• å‘å¸ƒ|LURE: Latent Space Unblocking for Multi-Concept Reawakening in Diffusion Models|LUREï¼šDiffusion Models ä¸­å¤šæ¦‚å¿µå”¤é†’çš„ Latent Space Unblocking|Mengyu Sun, Ziyuan Yang, Andrew Beng Jin Teoh, Junxu Liu, Haibo Hu, Yi Zhang|<https://arxiv.org/pdf/2601.14330v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Comparison of Generative Learning Methods for Turbulence Surrogates|ç”¨äºæ¹æµæ›¿ä»£æ¨¡å‹çš„ç”Ÿæˆå¼å­¦ä¹ æ–¹æ³•æ¯”è¾ƒ|Claudia Drygala, Edmund Ross, Mohammad Sharifi Ghazijahani, Christian Cierpka, Francesca di Mare, Hanno Gottschalk|<https://arxiv.org/pdf/2411.16417v4>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Comparative Study of UNet-based Architectures for Liver Tumor Segmentation in Multi-Phase Contrast-Enhanced Computed Tomography|åŸºäºUNetçš„æ¶æ„åœ¨å¤šæœŸå¯¹æ¯”å¢å¼ºComputed Tomographyè‚è„è‚¿ç˜¤åˆ†å‰²ä¸­çš„æ¯”è¾ƒç ”ç©¶|Doan-Van-Anh Ly, Thanh-Hai Le, Thi-Thu-Hien Pham|<https://arxiv.org/pdf/2510.25522v5>|æ— |
|ğŸ“ æ›´æ–°|Context-measure: Contextualizing Metric for Camouflage|Context-measureï¼šç”¨äºä¼ªè£…çš„ä¸Šä¸‹æ–‡åº¦é‡|Chen-Yang Wang, Gepeng Ji, Song Shao, Ming-Ming Cheng, Deng-Ping Fan|<https://arxiv.org/pdf/2512.07076v2>|[ä»£ç ](https://github.com/pursuitxi/Context-measure.)|
|ğŸ†• å‘å¸ƒ|GO-MLVTON: Garment Occlusion-Aware Multi-Layer Virtual Try-On with Diffusion Models|GO-MLVTONï¼šåŸºäº Diffusion Models çš„æœè£…é®æŒ¡æ„ŸçŸ¥å¤šå±‚è™šæ‹Ÿè¯•ç©¿|Yang Yu, Yunze Deng, Yige Zhang, Yanjie Xiao, Youkun Ou, Wenhao Hu, Mingchao Li, Bin Feng .etc.|<https://arxiv.org/pdf/2601.13524v1>|[ä»£ç ](https://upyuyang.github.io/go-mlvton); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models|SlimDiffï¼šæ— éœ€è®­ç»ƒã€æ¿€æ´»å¼•å¯¼çš„å…æ‰‹æ‰©æ•£æ¨¡å‹ç˜¦èº«|Arani Roy, Shristi Das Biswas, Kaushik Roy|<https://arxiv.org/pdf/2509.21498v2>|æ— |


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis|Motion 3-to-4ï¼šç”¨äº4Dåˆæˆçš„3Dè¿åŠ¨é‡å»º|Hongyuan Chen, Xingyu Chen, Youjia Zhang, Zexiang Xu, Anpei Chen|<https://arxiv.org/pdf/2601.14253v1>|[ä»£ç ](https://motion3-to-4.github.io/.)|
|ğŸ†• å‘å¸ƒ|VideoMaMa: Mask-Guided Video Matting via Generative Prior|VideoMaMa: åŸºäºç”Ÿæˆå…ˆéªŒçš„æ©ç å¼•å¯¼è§†é¢‘æŠ å›¾|Sangbeom Lim, Seoung Wug Oh, Jiahui Huang, Heeji Yoon, Seungryong Kim, Joon-Young Lee|<https://arxiv.org/pdf/2601.14255v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|FastGHA: Generalized Few-Shot 3D Gaussian Head Avatars with Real-Time Animation|FastGHAï¼šå…·æœ‰å®æ—¶åŠ¨ç”»çš„å¹¿ä¹‰å°‘æ ·æœ¬3D Gaussian Head Avatars|Xinya Ji, Sebastian Weiss, Manuel Kansy, Jacek Naruniec, Xun Cao, Barbara Solenthaler, Derek Bradley|<https://arxiv.org/pdf/2601.13837v1>|æ— |
|ğŸ†• å‘å¸ƒ|Discriminant Learning-based Colorspace for Blade Segmentation|åŸºäºåˆ¤åˆ«å¼å­¦ä¹ çš„å¶ç‰‡åˆ†å‰²è‰²å½©ç©ºé—´|RaÃ¼l PÃ©rez-Gonzalo, Andreas Espersen, Antonio Agudo|<https://arxiv.org/pdf/2601.13816v1>|æ— |
|ğŸ†• å‘å¸ƒ|Facial Spatiotemporal Graphs: Leveraging the 3D Facial Surface for Remote Physiological Measurement|é¢éƒ¨æ—¶ç©ºå›¾ï¼šåˆ©ç”¨3Dé¢éƒ¨è¡¨é¢è¿›è¡Œè¿œç¨‹ç”Ÿç†æµ‹é‡|Sam Cantrill, David Ahmedt-Aristizabal, Lars Petersson, Hanna Suominen, Mohammad Ali Armin|<https://arxiv.org/pdf/2601.13724v1>|[ä»£ç ](https://samcantrill.github.io/facial-stgraph-rppg); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and Agentic Search|åŸºäºè§†å¬å®ä½“å‡èšå’Œæ™ºèƒ½æœç´¢çš„åˆ†å±‚é•¿è§†é¢‘ç†è§£|Xinlei Yin, Xiulian Peng, Xiao Li, Zhiwei Xiong, Yan Lu|<https://arxiv.org/pdf/2601.13719v1>|æ— |


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|OmniTransfer: All-in-one Framework for Spatio-temporal Video Transfer|OmniTransferï¼šæ—¶ç©ºè§†é¢‘è¿ç§»çš„ä¸€ä½“åŒ–æ¡†æ¶|Pengze Zhang, Yanze Wu, Mengtian Li, Xu Bai, Songtao Zhao, Fulong Ye, Chong Mou, Xinghui Li .etc.|<https://arxiv.org/pdf/2601.14250v1>|æ— |
|ğŸ†• å‘å¸ƒ|KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning|KAGE-Bench: ç”¨äº Reinforcement Learning çš„å¿«é€Ÿ Known-Axis è§†è§‰æ³›åŒ–è¯„ä¼°|Egor Cherepanov, Daniil Zelezetsky, Alexey K. Kovalev, Aleksandr I. Panov|<https://arxiv.org/pdf/2601.14232v1>|[ä»£ç ](https://avanturist322.github.io/KAGEBench); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|One-Shot Refiner: Boosting Feed-forward Novel View Synthesis via One-Step Diffusion|One-Shot Refinerï¼šé€šè¿‡å•æ­¥æ‰©æ•£æå‡å‰å‘ Novel View Synthesis|Yitong Dong, Qi Zhang, Minchao Jiang, Zhiqiang Wu, Qingnan Fan, Ying Feng, Huaqi Zhang, Hujun Bao .etc.|<https://arxiv.org/pdf/2601.14161v1>|æ— |
|ğŸ†• å‘å¸ƒ|TwinBrainVLA: Unleashing the Potential of Generalist VLMs for Embodied Tasks via Asymmetric Mixture-of-Transformers|TwinBrainVLAï¼šé€šè¿‡éå¯¹ç§° Mixture-of-Transformers é‡Šæ”¾é€šç”¨ VLM åœ¨å…·èº«ä»»åŠ¡ä¸­çš„æ½œåŠ›|Bin Yu, Shijie Lian, Xiaopeng Lin, Yuliang Wei, Zhaolong Shen, Changti Wu, Yuzhuo Miao, Xinming Wang .etc.|<https://arxiv.org/pdf/2601.14133v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|GalaxyEdit: Large-Scale Image Editing Dataset with Enhanced Diffusion Adapter|GalaxyEdit: å¸¦æœ‰å¢å¼º Diffusion Adapter çš„å¤§è§„æ¨¡å›¾åƒç¼–è¾‘æ•°æ®é›†|Aniruddha Bala, Rohan Jaiswal, Siddharth Roheda, Rohit Chowdhury, Loay Rashid|<https://arxiv.org/pdf/2411.13794v2>|æ— |
|ğŸ†• å‘å¸ƒ|The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning|èªæ˜çš„å‰¯ä½œç”¨ï¼šMLLMså¤šå›¾åƒæ¨ç†ä¸­çš„å®‰å…¨é£é™©|Renmiao Chen, Yida Lu, Shiyao Cui, Xuan Ouyang, Victor Shea-Jay Huang, Shumin Zhang, Chengwei Pan, Han Qiu .etc.|<https://arxiv.org/pdf/2601.14127v1>|[ä»£ç ](https://github.com/thu-coai/MIR-SafetyBench.)|
|ğŸ†• å‘å¸ƒ|Interp3D: Correspondence-aware Interpolation for Generative Textured 3D Morphing|Interp3Dï¼šç”¨äºç”Ÿæˆå¼çº¹ç†3Då˜å½¢çš„å¯¹åº”æ„ŸçŸ¥æ’å€¼|Xiaolu Liu, Yicong Li, Qiyuan He, Jiayin Zhu, Wei Ji, Angela Yao, Jianke Zhu|<https://arxiv.org/pdf/2601.14103v1>|[ä»£ç ](https://github.com/xiaolul2/Interp3D.)|
|ğŸ†• å‘å¸ƒ|Fine-Grained Zero-Shot Composed Image Retrieval with Complementary Visual-Semantic Integration|ç»†ç²’åº¦Zero-Shotç»„åˆå›¾åƒæ£€ç´¢ä¸äº’è¡¥è§†è§‰è¯­ä¹‰é›†æˆ|Yongcong Ye, Kai Zhang, Yanghai Zhang, Enhong Chen, Longfei Li, Jun Zhou|<https://arxiv.org/pdf/2601.14060v1>|[ä»£ç ](https://github.com/yyc6631/CVSI.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion|POCI-Diff: ä½¿ç”¨ 3D-Layout å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹ä¸€è‡´ä¸”äº¤äº’åœ°å®šä½ç‰©ä½“|Andrea Rigo, Luca Stornaiuolo, Weijie Wang, Mauro Martino, Bruno Lepri, Nicu Sebe|<https://arxiv.org/pdf/2601.14056v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|TrackletGPT: A Language-like GPT Framework for White Matter Tract Segmentation|TrackletGPT: ä¸€ç§ç”¨äºç™½è´¨çº¤ç»´æŸåˆ†å‰²çš„ç±»è¯­è¨€ GPT æ¡†æ¶|Anoushkrit Goel, Simroop Singh, Ankita Joshi, Ranjeet Ranjan Jha, Chirag Ahuja, Aditya Nigam, Arnav Bhavsar|<https://arxiv.org/pdf/2601.13935v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|The 4D Human Embryonic Brain Atlas: spatiotemporal atlas generation for rapid anatomical changes|4Däººç±»èƒšèƒè„‘å›¾è°±ï¼šé’ˆå¯¹å¿«é€Ÿè§£å‰–å˜åŒ–çš„æ—¶ç©ºå›¾è°±ç”Ÿæˆ|Wietske A. P. Bastiaansen, Melek Rousian, Anton H. J. Koning, Wiro J. Niessen, Bernadette S. de Bakker, RÃ©gine P. M. Steegers-Theunissen, Stefan Klein|<https://arxiv.org/pdf/2503.07177v2>|æ— |
|ğŸ“ æ›´æ–°|Paired Image Generation with Diffusion-Guided Diffusion Models|Diffusion-Guided Diffusion Models çš„æˆå¯¹å›¾åƒç”Ÿæˆ|Haoxuan Zhang, Wenju Cui, Yuzhu Cao, Tao Tan, Jie Liu, Yunsong Peng, Jian Zheng|<https://arxiv.org/pdf/2507.14833v2>|[ä»£ç ](https://github.com/zhanghx1320/PIG.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|PREGEN: Uncovering Latent Thoughts in Composed Video Retrieval|PREGEN: æ­ç¤ºç»„åˆè§†é¢‘æ£€ç´¢ä¸­çš„æ½œåœ¨æ€ç»´|Gabriele Serussi, David Vainshtein, Jonathan Kouchly, Dotan Di Castro, Chaim Baskin|<https://arxiv.org/pdf/2601.13797v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Dynamic Differential Linear Attention: Enhancing Linear Diffusion Transformer for High-Quality Image Generation|Dynamic Differential Linear Attentionï¼šå¢å¼º Linear Diffusion Transformer ä»¥å®ç°é«˜è´¨é‡å›¾åƒç”Ÿæˆ|Boyuan Cao, Xingbo Yao, Chenhui Wang, Jiaxin Ye, Yujie Wei, Hongming Shan|<https://arxiv.org/pdf/2601.13683v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Edit2Restore:Few-Shot Image Restoration via Parameter-Efficient Adaptation of Pre-trained Editing Models|Edit2Restore: é€šè¿‡é¢„è®­ç»ƒç¼–è¾‘æ¨¡å‹çš„å‚æ•°é«˜æ•ˆé€‚åº”è¿›è¡Œå°‘æ ·æœ¬å›¾åƒä¿®å¤|M. AkÄ±n YÄ±lmaz, Ahmet Bilican, Burak Can Biner, A. Murat Tekalp|<https://arxiv.org/pdf/2601.03391v2>|[ä»£ç ](https://github.com/makinyilmaz/Edit2Restore)|
|ğŸ†• å‘å¸ƒ|ChartVerse: Scaling Chart Reasoning via Reliable Programmatic Synthesis from Scratch|ChartVerse: é€šè¿‡ä»é›¶å¼€å§‹çš„å¯é ç¨‹åºåˆæˆæ‰©å±•å›¾è¡¨æ¨ç†|Zheng Liu, Honglin Lin, Chonghan Qin, Xiaoyang Wang, Xin Gao, Yu Li, Mengzhang Cai, Yun Zhu .etc.|<https://arxiv.org/pdf/2601.13606v1>|åˆ†æå¤±è´¥|


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|DiffusionAgent: Navigating Expert Models for Agentic Image Generation|DiffusionAgent: å¯¼èˆªä¸“å®¶æ¨¡å‹ä»¥å®ç°æ™ºèƒ½ä½“å›¾åƒç”Ÿæˆ|Jie Qin, Jie Wu, Weifeng Chen, Yueming Lyu|<https://arxiv.org/pdf/2401.10061v2>|[ä»£ç ](https://github.com/DiffusionAgent/DiffusionAgent)|
|ğŸ†• å‘å¸ƒ|VTONGuard: Automatic Detection and Authentication of AI-Generated Virtual Try-On Content|VTONGuardï¼šAIç”Ÿæˆè™šæ‹Ÿè¯•ç©¿å†…å®¹çš„è‡ªåŠ¨æ£€æµ‹ä¸è®¤è¯|Shengyi Wu, Yan Hong, Shengyao Chen, Zheng Wang, Xianbing Sun, Jiahui Zhan, Jun Lan, Jianfu Zhang|<https://arxiv.org/pdf/2601.13951v1>|æ— |
|ğŸ“ æ›´æ–°|DocReward: A Document Reward Model for Structuring and Stylizing|DocReward: ç”¨äºç»“æ„å’Œæ ·å¼åŒ–çš„æ–‡æ¡£å¥–åŠ±æ¨¡å‹|Junpeng Liu, Yuzhong Zhao, Bowen Cao, Jiayu Ding, Yilin Jia, Tengchao Lv, Yupan Huang, Shaohan Huang .etc.|<https://arxiv.org/pdf/2510.11391v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Light4GS: Lightweight Compact 4D Gaussian Splatting Generation via Context Model|Light4GSï¼šé€šè¿‡Context Modelå®ç°çš„è½»é‡çº§ç´§å‡‘4D Gaussian Splattingç”Ÿæˆ|Mufan Liu, Qi Yang, He Huang, Wenjie Huang, Zhenlong Yuan, Zhu Li, Yiling Xu|<https://arxiv.org/pdf/2503.13948v2>|åˆ†æå¤±è´¥|


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|PAS-Mamba: Phase-Amplitude-Spatial State Space Model for MRI Reconstruction|PAS-Mamba: MRIé‡å»ºçš„ç›¸ä½-å¹…åº¦-ç©ºé—´çŠ¶æ€ç©ºé—´æ¨¡å‹|Xiaoyan Kui, Zijie Fan, Zexin Ji, Qinsong Li, Hao Xu, Weixin Si, Haodong Xu, Beiji Zou|<https://arxiv.org/pdf/2601.14530v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Rig-Aware 3D Reconstruction of Vehicle Undercarriages using Gaussian Splatting|åŸºäº Gaussian Splatting çš„ Rig æ„ŸçŸ¥è½¦è¾†åº•ç›˜ 3D é‡å»º|Nitin Kulkarni, Akhil Devarashetti, Charlie Cluss, Livio Forte, Dan Buckmaster, Philip Schneider, Chunming Qiao, Alina Vereshchaka|<https://arxiv.org/pdf/2601.14208v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|GeLoc3r: Enhancing Relative Camera Pose Regression with Geometric Consistency Regularization|GeLoc3r: åˆ©ç”¨å‡ ä½•ä¸€è‡´æ€§æ­£åˆ™åŒ–å¢å¼ºç›¸å¯¹ç›¸æœºä½å§¿å›å½’|Jingxing Li, Yongjae Lee, Deliang Fan|<https://arxiv.org/pdf/2509.23038v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|IDESplat: Iterative Depth Probability Estimation for Generalizable 3D Gaussian Splatting|IDESplat: ç”¨äºå¯æ³›åŒ–3D Gaussian Splattingçš„è¿­ä»£æ·±åº¦æ¦‚ç‡ä¼°è®¡|Wei Long, Haifeng Wu, Shiyin Jiang, Jinhua Zhang, Xinchun Ji, Shuhang Gu|<https://arxiv.org/pdf/2601.03824v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|ParkingTwin: Training-Free Streaming 3D Reconstruction for Parking-Lot Digital Twins|ParkingTwinï¼šé¢å‘åœè½¦åœºæ•°å­—å­ªç”Ÿçš„å…è®­ç»ƒæµå¼3Dé‡å»º|Xinhao Liu, Yu Wang, Xiansheng Guo, Gordon Owusu Boateng, Yu Cao, Haonan Si, Xingchen Guo, Nirwan Ansari|<https://arxiv.org/pdf/2601.13706v1>|[ä»£ç ](https://mihoutao-liu.github.io/ParkingTwin); åˆ†æå¤±è´¥|


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Implicit Neural Representation Facilitates Unified Universal Vision Encoding|Implicit Neural Representation ä¿ƒè¿›ç»Ÿä¸€çš„é€šç”¨è§†è§‰ç¼–ç |Matthew Gwilliam, Xiao Wang, Xuefeng Hu, Zhenheng Yang|<https://arxiv.org/pdf/2601.14256v1>|[ä»£ç ](https://github.com/tiktok/huvr.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Deblur4DGS: 4D Gaussian Splatting from Blurry Monocular Video|Deblur4DGSï¼šæ¥è‡ªæ¨¡ç³Šå•ç›®è§†é¢‘çš„4D Gaussian Splatting|Renlong Wu, Zhilu Zhang, Mingyang Chen, Zifei Yan, Wangmeng Zuo|<https://arxiv.org/pdf/2412.06424v3>|[ä»£ç ](https://github.com/ZcsrenlongZ/Deblur4DGS.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Optical Linear Systems Framework for Event Sensing and Computational Neuromorphic Imaging|ç”¨äºäº‹ä»¶æ„ŸçŸ¥ä¸è®¡ç®—ç¥ç»å½¢æ€æˆåƒçš„å…‰å­¦çº¿æ€§ç³»ç»Ÿæ¡†æ¶|Nimrod Kruger, Nicholas Owen Ralph, Gregory Cohen, Paul Hurley|<https://arxiv.org/pdf/2601.13498v1>|æ— |


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### åŠ¨ä½œè¯†åˆ«ä¸ç†è§£ (Action Recognition & Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Curriculum-Based Strategies for Efficient Cross-Domain Action Recognition|åŸºäºè¯¾ç¨‹å­¦ä¹ ç­–ç•¥çš„é«˜æ•ˆè·¨åŸŸåŠ¨ä½œè¯†åˆ«|Emily Kim, Allen Wu, Jessica Hodgins|<https://arxiv.org/pdf/2601.14101v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Two-Stream temporal transformer for video action classification|[ç¿»è¯‘å¤±è´¥] Two-Stream temporal transformer for video action classification|Nattapong Kurpukdee, Adrian G. Bors|<https://arxiv.org/pdf/2601.14086v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|BikeActions: An Open Platform and Benchmark for Cyclist-Centric VRU Action Recognition|BikeActions: ä¸€ä¸ªä»¥éª‘è¡Œè€…ä¸ºä¸­å¿ƒçš„VRUåŠ¨ä½œè¯†åˆ«å¼€æ”¾å¹³å°ä¸åŸºå‡†|Max A. Buettner, Kanak Mazumder, Luca Koecher, Mario Finkbeiner, Sebastian Niebler, Fabian B. Flohr|<https://arxiv.org/pdf/2601.10521v2>|æ— |


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Unsupervised Video Class-Incremental Learning via Deep Embedded Clustering Management|æ— ç›‘ç£è§†é¢‘ç±»å¢é‡å­¦ä¹ é€šè¿‡æ·±åº¦åµŒå…¥èšç±»ç®¡ç†|Nattapong Kurpukdee, Adrian G. Bors|<https://arxiv.org/pdf/2601.14069v1>|åˆ†æå¤±è´¥|


### æ—¶åºå»ºæ¨¡ä¸é¢„æµ‹ (Temporal Modeling & Prediction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|STEC: A Reference-Free Spatio-Temporal Entropy Coverage Metric for Evaluating Sampled Video Frames|STECï¼šä¸€ç§ç”¨äºè¯„ä¼°é‡‡æ ·è§†é¢‘å¸§çš„æ— å‚è€ƒæ—¶ç©ºç†µè¦†ç›–åº¦é‡|Shih-Yao Lin|<https://arxiv.org/pdf/2601.13974v1>|æ— |
|ğŸ“ æ›´æ–°|ActAvatar: Temporally-Aware Precise Action Control for Talking Avatars|ActAvatar: é¢å‘Talking Avatarçš„æ—¶é—´æ„ŸçŸ¥ç²¾ç¡®åŠ¨ä½œæ§åˆ¶|Ziqiao Peng, Yi Chen, Yifeng Ma, Guozhen Zhang, Zhiyao Sun, Zixiang Zhou, Youliang Zhang, Zhengguang Zhou .etc.|<https://arxiv.org/pdf/2512.19546v2>|æ— |


### è§†é¢‘ç›®æ ‡è·Ÿè¸ª (Video Object Tracking)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MVGD-Net: A Novel Motion-aware Video Glass Surface Detection Network|MVGD-Net: ä¸€ç§æ–°é¢–çš„è¿åŠ¨æ„ŸçŸ¥è§†é¢‘ç»ç’ƒè¡¨é¢æ£€æµ‹ç½‘ç»œ|Yiwei Lu, Hao Huang, Tao Yan|<https://arxiv.org/pdf/2601.13715v1>|åˆ†æå¤±è´¥|


## è‡ªç›‘ç£ä¸è¡¨å¾å­¦ä¹  (Self-supervised & Representation Learning)


### è¡¨å¾çŸ¥è¯†è¿ç§» (Representation Knowledge Transfer)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|UniHash: Unifying Pointwise and Pairwise Hashing Paradigms for Seen and Unseen Category Retrieval|UniHash: ç»Ÿä¸€ç‚¹å¯¹å’Œæˆå¯¹å“ˆå¸ŒèŒƒå¼ç”¨äºå¯è§å’Œä¸å¯è§ç±»åˆ«æ£€ç´¢|Xiaoxu Ma, Runhao Li, Xiangbo Zhang, Zhenyu Weng|<https://arxiv.org/pdf/2601.09828v2>|åˆ†æå¤±è´¥|


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ASBA: A-line State Space Model and B-line Attention for Sparse Optical Doppler Tomography Reconstruction|ASBAï¼šç”¨äºç¨€ç–å…‰å­¦å¤šæ™®å‹’å±‚æé‡å»ºçš„A-lineçŠ¶æ€ç©ºé—´æ¨¡å‹ä¸B-lineæ³¨æ„åŠ›|Zhenghong Li, Wensheng Cheng, Congwu Du, Yingtian Pan, Zhaozheng Yin, Haibin Ling|<https://arxiv.org/pdf/2601.14165v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|HCF: Hierarchical Cascade Framework for Distributed Multi-Stage Image Compression|HCF: ç”¨äºåˆ†å¸ƒå¼å¤šé˜¶æ®µå›¾åƒå‹ç¼©çš„çº§è”æ¡†æ¶|Junhao Cai, Taegun An, Chengjun Jin, Sung Il Choi, Juhyun Park, Changhee Joo|<https://arxiv.org/pdf/2508.02051v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|VENI: Variational Encoder for Natural Illumination|VENI: ç”¨äºè‡ªç„¶å…‰ç…§çš„å˜åˆ†ç¼–ç å™¨|Paul Walker, James A. D. Gardner, Andreea Ardelean, William A. P. Smith, Bernhard Egger|<https://arxiv.org/pdf/2601.14079v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Learning Latent Action World Models In The Wild|[ç¿»è¯‘å¤±è´¥] Learning Latent Action World Models In The Wild|Quentin Garrido, Tushar Nagarajan, Basile Terver, Nicolas Ballas, Yann LeCun, Michael Rabbat|<https://arxiv.org/pdf/2601.05230v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|SoK: On the Survivability of Backdoor Attacks on Unconstrained Face Recognition Systems|SoK: å…³äºæ— çº¦æŸäººè„¸è¯†åˆ«ç³»ç»Ÿä¸­åé—¨æ”»å‡»çš„ç”Ÿå­˜èƒ½åŠ›|Quentin Le Roux, Yannick Teglia, Teddy Furon, Philippe Loubet-Moundi, Eric Bourbao|<https://arxiv.org/pdf/2507.01607v5>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|FG-OrIU: Towards Better Forgetting via Feature-Gradient Orthogonality for Incremental Unlearning|FG-OrIU: é€šè¿‡ç‰¹å¾-æ¢¯åº¦æ­£äº¤æ€§å®ç°æ›´å¥½çš„å¢é‡é—å¿˜|Qian Feng, JiaHang Tu, Mintong Kang, Hanbin Zhao, Chao Zhang, Hui Qian|<https://arxiv.org/pdf/2601.13578v1>|æ— |


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Harmonizing the Deep: A Unified Information Pipeline for Robust Marine Biodiversity Assessment Across Heterogeneous Domains|Harmonizing the Deepï¼šç”¨äºè·¨å¼‚æ„åŸŸé²æ£’æµ·æ´‹ç”Ÿç‰©å¤šæ ·æ€§è¯„ä¼°çš„ç»Ÿä¸€ä¿¡æ¯ç®¡é“|Marco Piccolo, Qiwei Han, Astrid van Toor, Joachim Vanneste|<https://arxiv.org/pdf/2601.13975v1>|æ— |
|ğŸ†• å‘å¸ƒ|Attention-space Contrastive Guidance for Efficient Hallucination Mitigation in LVLMs|Attention-space å¯¹æ¯”å¼•å¯¼ç”¨äº LVLMs ä¸­çš„é«˜æ•ˆå¹»è§‰ç¼“è§£|Yujin Jo, Sangyoon Bae, Taesup Kim|<https://arxiv.org/pdf/2601.13707v1>|åˆ†æå¤±è´¥|


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Manipulating Feature Visualizations with Gradient Slingshots|åˆ©ç”¨ Gradient Slingshots æ“çºµç‰¹å¾å¯è§†åŒ–|Dilyara Bareeva, Marina M. -C. HÃ¶hne, Alexander Warnecke, Lukas Pirch, Klaus-Robert MÃ¼ller, Konrad Rieck, Sebastian Lapuschkin, Kirill Bykov|<https://arxiv.org/pdf/2401.06122v4>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Probabilistic Deep Discriminant Analysis for Wind Blade Segmentation|[ç¿»è¯‘å¤±è´¥] Probabilistic Deep Discriminant Analysis for Wind Blade Segmentation|RaÃ¼l PÃ©rez-Gonzalo, Andreas Espersen, Antonio Agudo|<https://arxiv.org/pdf/2601.13852v1>|åˆ†æå¤±è´¥|


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### å¯¹æŠ—é²æ£’æ€§ (Adversarial Robustness)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Quadratic Upper Bound for Boosting Robustness|Boosting é²æ£’æ€§çš„äºŒæ¬¡ä¸Šç•Œ|Euijin You, Hyang-Won Lee|<https://arxiv.org/pdf/2601.13645v1>|æ— |


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|XD-MAP: Cross-Modal Domain Adaptation using Semantic Parametric Mapping|XD-MAP: ä½¿ç”¨è¯­ä¹‰å‚æ•°æ˜ å°„çš„è·¨æ¨¡æ€åŸŸé€‚åº”|Frank Bieder, Hendrik KÃ¶nigshof, Haohao Hu, Fabian Immel, Yinzhe Shen, Jan-Hendrik Pauls, Christoph Stiller|<https://arxiv.org/pdf/2601.14477v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Progressive self-supervised blind-spot denoising method for LDCT denoising|ç”¨äºLDCTå»å™ªçš„æ¸è¿›å¼è‡ªç›‘ç£ç›²ç‚¹å»å™ªæ–¹æ³•|Yichao Liu, Yueyang Teng, Junwen Guo|<https://arxiv.org/pdf/2601.14180v1>|æ— |
|ğŸ†• å‘å¸ƒ|IIR-VLM: In-Context Instance-level Recognition for Large Vision-Language Models|IIR-VLM: å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å®ä¾‹çº§è¯†åˆ«|Liang Shi, Wei Li, Kevin M Beussman, Lin Chen, Yun Fu|<https://arxiv.org/pdf/2601.14188v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|PMCE: Probabilistic Multi-Granularity Semantics with Caption-Guided Enhancement for Few-Shot Learning|PMCEï¼šåŸºäºCaption-Guided Enhancementçš„Probabilistic Multi-Granularity Semanticsç”¨äºFew-Shot Learning|Jiaying Wu, Can Gao, Jinglu Hu, Hui Li, Xiaofeng Cao, Jingcai Guo|<https://arxiv.org/pdf/2601.14111v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Federated Balanced Learning|Fè”é‚¦å¹³è¡¡å­¦ä¹ |Jiaze Li, Haoran Xu, Wanyi Wu, Changwei Wang, Shuaiguang Li, Jianzhong Ju, Zhenbo Luo, Jian Luan .etc.|<https://arxiv.org/pdf/2601.14042v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Equivariant Learning for Unsupervised Image Dehazing|[ç¿»è¯‘å¤±è´¥] Equivariant Learning for Unsupervised Image Dehazing|Zhang Wen, Jiangwei Xie, Dongdong Chen|<https://arxiv.org/pdf/2601.13986v1>|æ— |
|ğŸ†• å‘å¸ƒ|Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning|Glance-or-Gazeï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ æ¿€åŠ± LMMs è‡ªé€‚åº”åœ°èšç„¦æœç´¢|Hongbo Bai, Yujin Zhou, Yile Wu, Chi-Min Chan, Pengcheng Wen, Kunhao Pan, Sirui Han, Yike Guo|<https://arxiv.org/pdf/2601.13942v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Object-Centric Latent Action Learning|ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„æ½œåœ¨åŠ¨ä½œå­¦ä¹ |Albina Klepach, Alexander Nikulin, Ilya Zisman, Denis Tarasov, Alexander Derevyagin, Andrei Polubarov, Nikita Lyubaykin, Igor Kiselev .etc.|<https://arxiv.org/pdf/2502.09680v3>|æ— |
|ğŸ“ æ›´æ–°|GenView++: Unifying Adaptive Generative Augmentation and Quality-Driven Supervision for Contrastive Representation Learning|GenView++ï¼šç»Ÿä¸€è‡ªé€‚åº”ç”Ÿæˆå¢å¼ºä¸è´¨é‡é©±åŠ¨ç›‘ç£çš„å¯¹æ¯”è¡¨ç¤ºå­¦ä¹ |Xiaojie Li, Bei Wang, Wei Liu, Jianlong Wu, Yue Yu, Liqiang Nie, Min Zhang|<https://arxiv.org/pdf/2509.23770v3>|åˆ†æå¤±è´¥|


### å°æ ·æœ¬å­¦ä¹  (Few-shot Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Copy-Trasform-Paste: Zero-Shot Object-Object Alignment Guided by Vision-Language and Geometric Constraints|Copy-Transform-Pasteï¼šç”± Vision-Language å’Œå‡ ä½•çº¦æŸå¼•å¯¼çš„ Zero-Shot ç‰©ä½“å¯¹é½|Rotem Gatenyo, Ohad Fried|<https://arxiv.org/pdf/2601.14207v1>|åˆ†æå¤±è´¥|


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Chain-of-Thought Compression Should Not Be Blind: V-Skip for Efficient Multimodal Reasoning via Dual-Path Anchoring|Chain-of-Thoughtå‹ç¼©ä¸åº”ç›²ç›®ï¼šV-Skipé€šè¿‡åŒè·¯å¾„é”šå®šå®ç°é«˜æ•ˆå¤šæ¨¡æ€æ¨ç†|Dongxu Zhang, Yiding Sun, Cheng Tan, Wenbiao Yan, Ning Yang, Jihua Zhu, Haijun Zhang|<https://arxiv.org/pdf/2601.13879v2>|æ— |
|ğŸ†• å‘å¸ƒ|Soft Tail-dropping for Adaptive Visual Tokenization|[ç¿»è¯‘å¤±è´¥] Soft Tail-dropping for Adaptive Visual Tokenization|Zeyuan Chen, Kai Zhang, Zhuowen Tu, Yuanjun Xiong|<https://arxiv.org/pdf/2601.14246v1>|æ— |
|ğŸ†• å‘å¸ƒ|DermaBench: A Clinician-Annotated Benchmark Dataset for Dermatology Visual Question Answering and Reasoning|DermaBench: ä¸€ä¸ªä¸´åºŠåŒ»ç”Ÿæ ‡æ³¨çš„çš®è‚¤ç§‘è§†è§‰é—®ç­”ä¸æ¨ç†åŸºå‡†æ•°æ®é›†|Abdurrahim Yilmaz, Ozan Erdem, Ece Gokyayla, Ayda Acar, Burc Bugra Dagtas, Dilara Ilhan Erdil, Gulsum Gencoglan, Burak Temelkuran|<https://arxiv.org/pdf/2601.14084v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|CityCube: Benchmarking Cross-view Spatial Reasoning on Vision-Language Models in Urban Environments|CityCubeï¼šåœ¨åŸå¸‚ç¯å¢ƒä¸­å¯¹ Vision-Language Models çš„è·¨è§†å›¾ç©ºé—´æ¨ç†è¿›è¡ŒåŸºå‡†æµ‹è¯•|Haotian Xu, Yue Hu, Zhengqiu Zhu, Chen Gao, Ziyou Wang, Junreng Rao, Wenhao Lu, Weishi Li .etc.|<https://arxiv.org/pdf/2601.14339v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Revisiting Multi-Task Visual Representation Learning|[ç¿»è¯‘å¤±è´¥] Revisiting Multi-Task Visual Representation Learning|Shangzhe Di, Zhonghua Zhai, Weidi Xie|<https://arxiv.org/pdf/2601.13886v1>|æ— |
|ğŸ†• å‘å¸ƒ|DisasterVQA: A Visual Question Answering Benchmark Dataset for Disaster Scenes|[ç¿»è¯‘å¤±è´¥] DisasterVQA: A Visual Question Answering Benchmark Dataset for Disaster Scenes|Aisha Al-Mohannadi, Ayisha Firoz, Yin Yang, Muhammad Imran, Ferda Ofli|<https://arxiv.org/pdf/2601.13839v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|RxnBench: A Multimodal Benchmark for Evaluating Large Language Models on Chemical Reaction Understanding from Scientific Literature|RxnBench: ä¸€ä¸ªç”¨äºè¯„ä¼° Large Language Models åœ¨ç§‘å­¦æ–‡çŒ®ä¸­åŒ–å­¦ååº”ç†è§£èƒ½åŠ›çš„ Multimodal Benchmark|Hanzheng Li, Xi Fang, Yixuan Li, Chaozheng Huang, Junjie Wang, Xi Wang, Hongzhe Bai, Bojun Hao .etc.|<https://arxiv.org/pdf/2512.23565v4>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Reasoning or Pattern Matching? Probing Large Vision-Language Models with Visual Puzzles|[ç¿»è¯‘å¤±è´¥] Reasoning or Pattern Matching? Probing Large Vision-Language Models with Visual Puzzles|Maria Lymperaiou, Vasileios Karampinis, Giorgos Filandrianos, Angelos Vlachos, Chrysoula Zerva, Athanasios Voulodimos|<https://arxiv.org/pdf/2601.13705v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Scaling Test-time Inference for Visual Grounding|Visual Grounding çš„æµ‹è¯•æ—¶æ¨ç†æ‰©å±•|Guanqi Zhan, Changye Li, Zhijian Liu, Yao Lu, Yi Wu, Song Han, Ligeng Zhu|<https://arxiv.org/pdf/2601.13633v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Reasoning is a Modality|[ç¿»è¯‘å¤±è´¥] Reasoning is a Modality|Zhiguang Liu, Yi Shang|<https://arxiv.org/pdf/2601.13562v1>|æ— |


### å¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿ (Multimodal Dialogue Systems)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Hummus: A Dataset of Humorous Multimodal Metaphor Use|Hummus: ä¸€ä¸ªå¹½é»˜å¤šæ¨¡æ€éšå–»ä½¿ç”¨çš„æ•°æ®é›†|Xiaoyu Tong, Zhi Zhang, Pia Sommerauer, Martha Lewis, Ekaterina Shutova|<https://arxiv.org/pdf/2504.02983v2>|[ä»£ç ](https://github.com/xiaoyuisrain/humorous-multimodal-metaphor-use.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Disc3D: Automatic Curation of High-Quality 3D Dialog Data via Discriminative Object Referring|Disc3Dï¼šé€šè¿‡åˆ¤åˆ«æ€§å¯¹è±¡æŒ‡ä»£è‡ªåŠ¨ç²¾é€‰é«˜è´¨é‡3Då¯¹è¯æ•°æ®|Siyuan Wei, Chunjie Wang, Xiao Liu, Xiaosheng Yan, Zhishan Zhou, Rui Huang|<https://arxiv.org/pdf/2511.18817v3>|åˆ†æå¤±è´¥|


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### å·¥ä¸šè§†è§‰æ£€æµ‹ (Industrial Visual Inspection)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Image class translation: visual inspection of class-specific hypotheticals and classification based on translation distance|å›¾åƒç±»åˆ«ç¿»è¯‘ï¼šç±»åˆ«ç‰¹å®šå‡è®¾çš„è§†è§‰æ£€æŸ¥ä¸åŸºäºç¿»è¯‘è·ç¦»çš„åˆ†ç±»|Mikyla K. Bowen, Jesse W. Wilson|<https://arxiv.org/pdf/2408.08973v2>|åˆ†æå¤±è´¥|


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Weakly-supervised segmentation using inherently-explainable classification models and their application to brain tumour classification|ä½¿ç”¨ inherently-explainable åˆ†ç±»æ¨¡å‹çš„å¼±ç›‘ç£åˆ†å‰²åŠå…¶åœ¨è„‘è‚¿ç˜¤åˆ†ç±»ä¸­çš„åº”ç”¨|Soumick Chatterjee, Hadya Yassin, Florian Dubost, Andreas NÃ¼rnberger, Oliver Speck|<https://arxiv.org/pdf/2206.05148v3>|[ä»£ç ](https://github.com/soumickmj/GPModels); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Real-Time Wildfire Localization on the NASA Autonomous Modular Sensor using Deep Learning|ä½¿ç”¨ Deep Learning åœ¨ NASA Autonomous Modular Sensor ä¸Šè¿›è¡Œå®æ—¶é‡ç«å®šä½|Yajvan Ravan, Aref Malek, Chester Dolph, Nikhil Behari|<https://arxiv.org/pdf/2601.14475v1>|[ä»£ç ](https://github.com/nasa/Autonomous-Modular-Sensor-Wildfire-Segmentation); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Vision-Based Natural Language Scene Understanding for Autonomous Driving: An Extended Dataset and a New Model for Traffic Scene Description Generation|åŸºäºè§†è§‰çš„è‡ªåŠ¨é©¾é©¶è‡ªç„¶è¯­è¨€åœºæ™¯ç†è§£ï¼šæ‰©å±•æ•°æ®é›†ä¸äº¤é€šåœºæ™¯æè¿°ç”Ÿæˆæ–°æ¨¡å‹|Danial Sadrian Zadeh, Otman A. Basir, Behzad Moshiri|<https://arxiv.org/pdf/2601.14438v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Large-Scale Label Quality Assessment for Medical Segmentation via a Vision-Language Judge and Synthetic Data|é€šè¿‡ Vision-Language Judge å’Œåˆæˆæ•°æ®è¿›è¡ŒåŒ»å­¦åˆ†å‰²çš„å¤§è§„æ¨¡æ ‡ç­¾è´¨é‡è¯„ä¼°|Yixiong Chen, Zongwei Zhou, Wenxuan Li, Alan Yuille|<https://arxiv.org/pdf/2601.14406v1>|[ä»£ç ](https://github.com/Schuture/SegAE.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI|æ— è§£ç å™¨çš„è¶…ä½“ç´ GNNç”¨äºå¤šæ¨¡æ€MRIä¸­çš„ç²¾å‡†è„‘è‚¿ç˜¤å®šä½|Andrea Protani, Marc Molina Van Den Bosch, Lorenzo Giusti, Heloisa Barbosa Da Silva, Paolo Cacace, Albert Sund Aillet, Miguel Angel Gonzalez Ballester, Friedhelm Hummel .etc.|<https://arxiv.org/pdf/2601.14055v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation|[ç¿»è¯‘å¤±è´¥] Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation|Wesam Moustafa, Hossam Elsafty, Helen Schneider, Lorenz Sparrenberg, Rafet Sifa|<https://arxiv.org/pdf/2601.14039v1>|[ä»£ç ](https://github.com/wemous/abstention-for-segmentation.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|DExTeR: Weakly Semi-Supervised Object Detection with Class and Instance Experts for Medical Imaging|DExTeR: åŸºäºç±»åˆ«å’Œå®ä¾‹ä¸“å®¶çš„å¼±åŠç›‘ç£åŒ»å­¦å›¾åƒç›®æ ‡æ£€æµ‹|Adrien Meyer, Didier Mutter, Nicolas Padoy|<https://arxiv.org/pdf/2601.13954v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Unsupervised Deformable Image Registration with Local-Global Attention and Image Decomposition|æ— ç›‘ç£å¯å˜å½¢å›¾åƒé…å‡†ï¼šåŸºäºLocal-Global Attentionä¸Image Decomposition|Zhengyong Huang, Xingwen Sun, Xuting Chang, Ning Jiang, Yao Wang, Jianfei Sun, Hongbin Han, Yao Sui|<https://arxiv.org/pdf/2601.14337v1>|[ä»£ç ](https://github.com/huangzyong/LGANet-Registration.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Partial Decoder Attention Network with Contour-weighted Loss Function for Data-Imbalance Medical Image Segmentation|[ç¿»è¯‘å¤±è´¥] Partial Decoder Attention Network with Contour-weighted Loss Function for Data-Imbalance Medical Image Segmentation|Zhengyong Huang, Ning Jiang, Xingwen Sun, Lihua Zhang, Peng Chen, Jens Domke, Yao Sui|<https://arxiv.org/pdf/2601.14338v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Learning Domain-Invariant Representations for Cross-Domain Image Registration via Scene-Appearance Disentanglement|é€šè¿‡åœºæ™¯-å¤–è§‚è§£è€¦å­¦ä¹ ç”¨äºè·¨åŸŸå›¾åƒé…å‡†çš„åŸŸä¸å˜è¡¨ç¤º|Jiahao Qin, Yiwen Wang|<https://arxiv.org/pdf/2601.08875v2>|[ä»£ç ](https://github.com/D-ST-Sword/SAR-NET); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|SatMap: Revisiting Satellite Maps as Prior for Online HD Map Construction|SatMapï¼šé‡æ–°å®¡è§†å«æ˜Ÿåœ°å›¾ä½œä¸ºåœ¨çº¿HD Map Constructionçš„å…ˆéªŒ|Kanak Mazumder, Fabian B. Flohr|<https://arxiv.org/pdf/2601.10512v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|HyperWalker: Dynamic Hypergraph-Based Deep Diagnosis for Multi-Hop Clinical Modeling across EHR and X-Ray in Medical VLMs|HyperWalkerï¼šåŸºäºåŠ¨æ€è¶…å›¾çš„æ·±åº¦è¯Šæ–­ï¼Œç”¨äºåŒ»ç–—VLMä¸­è·¨EHRå’ŒX-Rayçš„å¤šè·³ä¸´åºŠå»ºæ¨¡|Yuezhe Yang, Hao Wang, Yige Peng, Jinman Kim, Lei Bi|<https://arxiv.org/pdf/2601.13919v1>|[ä»£ç ](https://github.com/Bean-Young/HyperWalker)|
|ğŸ†• å‘å¸ƒ|Towards Visually Explaining Statistical Tests with Applications in Biomedical Imaging|[ç¿»è¯‘å¤±è´¥] Towards Visually Explaining Statistical Tests with Applications in Biomedical Imaging|Masoumeh Javanbakhat, Piotr Komorowski, Dilyara Bareeva, Wei-Chang Lai, Wojciech Samek, Christoph Lippert|<https://arxiv.org/pdf/2601.13899v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Doracamom: Joint 3D Detection and Occupancy Prediction with Multi-view 4D Radars and Cameras for Omnidirectional Perception|Doracamomï¼šåŸºäºå¤šè§†è§’ 4D é›·è¾¾å’Œç›¸æœºçš„è”åˆ 3D æ£€æµ‹ä¸å æ®é¢„æµ‹ï¼Œç”¨äºå…¨æ–¹ä½æ„ŸçŸ¥|Lianqing Zheng, Jianan Liu, Runwei Guan, Long Yang, Shouyi Lu, Yuanzhe Li, Xiaokai Bai, Jie Bai .etc.|<https://arxiv.org/pdf/2501.15394v3>|æ— |
|ğŸ†• å‘å¸ƒ|Finally Outshining the Random Baseline: A Simple and Effective Solution for Active Learning in 3D Biomedical Imaging|ç»ˆäºè¶…è¶ŠéšæœºåŸºçº¿ï¼š3D Biomedical Imaging ä¸­ Active Learning çš„ç®€å•æœ‰æ•ˆè§£å†³æ–¹æ¡ˆ|Carsten T. LÃ¼th, Jeremias Traub, Kim-Celine Kahl, Till J. Bungert, Lukas Klein, Lars KrÃ¤mer, Paul F. JÃ¤ger, Klaus Maier-Hein .etc.|<https://arxiv.org/pdf/2601.13677v1>|[ä»£ç ](https://github.com/MIC-DKFZ/nnActive.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|DiffFace-Edit: A Diffusion-Based Facial Dataset for Forgery-Semantic Driven Deepfake Detection Analysis|DiffFace-Edit: ä¸€ä¸ªåŸºäºDiffusionçš„ç”¨äºä¼ªé€ è¯­ä¹‰é©±åŠ¨çš„Deepfakeæ£€æµ‹åˆ†æçš„äººè„¸æ•°æ®é›†|Feng Ding, Wenhui Yi, Xinan He, Mengyao Xiao, Jianfeng Xu, Jianqiang Du|<https://arxiv.org/pdf/2601.13551v1>|[ä»£ç ](https://github.com/ywh1093/DiffFace-Edit.)|


### åˆ›æ„åª’ä½“ç”Ÿæˆ (Creative Media Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|TalkingHeadBench: A Multi-Modal Benchmark & Analysis of Talking-Head DeepFake Detection|TalkingHeadBenchï¼šä¸€ç§ç”¨äºTalking-Head DeepFakeæ£€æµ‹çš„å¤šæ¨¡æ€åŸºå‡†ä¸åˆ†æ|Xinqi Xiong, Prakrut Patel, Qingyuan Fan, Amisha Wadhwa, Sarathy Selvam, Xiao Guo, Luchao Qi, Xiaoming Liu .etc.|<https://arxiv.org/pdf/2505.24866v3>|åˆ†æå¤±è´¥|


### æ™ºèƒ½äº¤é€šè§†è§‰ (Intelligent Transportation Vision)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Tube-Based Robust Control Strategy for Vision-Guided Autonomous Vehicles|åŸºäºTubeçš„è§†è§‰å¼•å¯¼è‡ªåŠ¨é©¾é©¶è½¦è¾†é²æ£’æ§åˆ¶ç­–ç•¥|Der-Hau Lee|<https://arxiv.org/pdf/2503.18752v2>|æ— |
|ğŸ“ æ›´æ–°|Back2Color: Domain-Adaptive Synthetic-to-Real Monocular Depth Estimation for Dynamic Traffic Scenes|Back2Colorï¼šé¢å‘åŠ¨æ€äº¤é€šåœºæ™¯çš„åŸŸè‡ªé€‚åº”åˆæˆåˆ°çœŸå®å•ç›®æ·±åº¦ä¼°è®¡|Yufan Zhu, Chongzhi Ran, Mingtao Feng, Le Dong, Weisheng Dong, Antonio M. LÃ³pez|<https://arxiv.org/pdf/2406.07741v7>|åˆ†æå¤±è´¥|


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Correcting and Quantifying Systematic Errors in 3D Box Annotations for Autonomous Driving|çº æ­£å¹¶é‡åŒ–è‡ªåŠ¨é©¾é©¶ä¸­3D Boxæ ‡æ³¨çš„ç³»ç»Ÿè¯¯å·®|Alexandre Justo Miro, Ludvig af Klinteberg, Bogdan Timus, Aron Asefaw, Ajinkya Khoche, Thomas Gustafsson, Sina Sharif Mansouri, Masoud Daneshtalab|<https://arxiv.org/pdf/2601.14038v1>|[ä»£ç ](https://github.com/alexandre-justo-miro/annotation-correction-3D-boxes.)|
|ğŸ“ æ›´æ–°|Balanced Diffusion-Guided Fusion for Multimodal Remote Sensing Classification|[ç¿»è¯‘å¤±è´¥] Balanced Diffusion-Guided Fusion for Multimodal Remote Sensing Classification|Hao Liu, Yongjie Zheng, Yuhan Kang, Mingyang Zhang, Maoguo Gong, Lorenzo Bruzzone|<https://arxiv.org/pdf/2509.23310v2>|[ä»£ç ](https://github.com/HaoLiu-XDU/BDGF.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3|OmniOVCDï¼šåˆ©ç”¨ SAM 3 ç®€åŒ–å¼€æ”¾è¯æ±‡å˜åŒ–æ£€æµ‹|Xu Zhang, Danyang Li, Yingjie Xia, Xiaohang Dong, Hualong Yu, Jianye Wang, Qicheng Li|<https://arxiv.org/pdf/2601.13895v1>|æ— |
|ğŸ†• å‘å¸ƒ|DIS2: Disentanglement Meets Distillation with Classwise Attention for Robust Remote Sensing Segmentation under Missing Modalities|DIS2ï¼šè§£è€¦ä¸è’¸é¦ç»“åˆç±»åˆ«æ³¨æ„åŠ›ç”¨äºç¼ºå¤±æ¨¡æ€ä¸‹çš„é²æ£’é¥æ„Ÿåˆ†å‰²|Nhi Kieu, Kien Nguyen, Arnold Wiliem, Clinton Fookes, Sridha Sridharan|<https://arxiv.org/pdf/2601.13502v1>|æ— |


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Intrinsic Dimensionality as a Model-Free Measure of Class Imbalance|Intrinsic Dimensionality ä½œä¸ºä¸€ç§æ— æ¨¡å‹çš„ç±»åˆ«ä¸å¹³è¡¡åº¦é‡|Ã‡aÄŸrÄ± Eser, Zeynep Sonat BaltacÄ±, Emre AkbaÅŸ, Sinan Kalkan|<https://arxiv.org/pdf/2511.10475v2>|[ä»£ç ](https://github.com/cagries/IDIM.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Radially Distorted Homographies, Revisited|[ç¿»è¯‘å¤±è´¥] Radially Distorted Homographies, Revisited|MÃ¥rten WadenbÃ¤ck, Marcus Valtonen Ã–rnhag, Johan Edstedt|<https://arxiv.org/pdf/2508.21190v2>|[ä»£ç ](https://github.com/marcusvaltonen/HomLib); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|VERIDAH: Solving Enumeration Anomaly Aware Vertebra Labeling across Imaging Sequences|VERIDAH: è·¨æˆåƒåºåˆ—çš„è§£å†³æšä¸¾å¼‚å¸¸æ„ŸçŸ¥æ¤éª¨æ ‡æ³¨|Hendrik MÃ¶ller, Hanna Schoen, Robert Graf, Matan Atad, Nathan Molinier, Anjany Sekuboyina, Bettina K. Budai, Fabian Bamberg .etc.|<https://arxiv.org/pdf/2601.14066v1>|[ä»£ç ](https://github.com/Hendrik-code/spineps.)|
|ğŸ†• å‘å¸ƒ|SHARE: A Fully Unsupervised Framework for Single Hyperspectral Image Restoration|SHAREï¼šå•å¹…é«˜å…‰è°±å›¾åƒæ¢å¤çš„å®Œå…¨æ— ç›‘ç£æ¡†æ¶|Jiangwei Xie, Zhang Wen, Mike Davies, Dongdong Chen|<https://arxiv.org/pdf/2601.13987v1>|[ä»£ç ](https://github.com/xuwayyy/SHARE.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|GutenOCR: A Grounded Vision-Language Front-End for Documents|GutenOCRï¼šä¸€ç§ç”¨äºæ–‡æ¡£çš„Grounded Vision-Languageå‰ç«¯|Hunter Heidenreich, Ben Elliott, Olivia Dinica, Yosheb Getachew|<https://arxiv.org/pdf/2601.14490v1>|æ— |
|ğŸ“ æ›´æ–°|Registration-Free Monitoring of Unstructured Point Cloud Data via Intrinsic Geometrical Properties|åŸºäºå†…åœ¨å‡ ä½•ç‰¹æ€§çš„éç»“æ„åŒ–ç‚¹äº‘æ•°æ®æ— é…å‡†ç›‘æµ‹|Mariafrancesca Patalano, Giovanna Capizzi, Kamran Paynabar|<https://arxiv.org/pdf/2511.05623v2>|æ— |
|ğŸ“ æ›´æ–°|WaveletInception Networks for on-board Vibration-Based Infrastructure Health Monitoring|[ç¿»è¯‘å¤±è´¥] WaveletInception Networks for on-board Vibration-Based Infrastructure Health Monitoring|Reza Riahi Samani, Alfredo Nunez, Bart De Schutter|<https://arxiv.org/pdf/2507.12969v2>|åˆ†æå¤±è´¥|

