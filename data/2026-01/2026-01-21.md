## [UPDATED!] **2026-01-21** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Rethinking Video Generation Model for the Embodied World|é‡æ–°æ€è€ƒé¢å‘å…·èº«ä¸–ç•Œçš„è§†é¢‘ç”Ÿæˆæ¨¡å‹|Yufan Deng, Zilin Pan, Hongyu Zhang, Xiaojie Li, Ruoqing Hu, Yufei Ding, Yiming Zou, Yan Zeng .etc.|<https://arxiv.org/pdf/2601.15282v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|DrivIng: A Large-Scale Multimodal Driving Dataset with Full Digital Twin Integration|DrivIngï¼šä¸€ä¸ªå…·æœ‰å…¨æ•°å­—å­ªç”Ÿé›†æˆçš„å¤§è§„æ¨¡å¤šæ¨¡æ€é©¾é©¶æ•°æ®é›†|Dominik RÃ¶ÃŸle, Xujun Xie, Adithya Mohan, Venkatesh Thirugnana Sambandham, Daniel Cremers, Torsten SchÃ¶n|<https://arxiv.org/pdf/2601.15260v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Symmetry Informative and Agnostic Feature Disentanglement for 3D Shapes|3Då½¢çŠ¶çš„å¯¹ç§°ä¿¡æ¯ä¸æ— å…³ç‰¹å¾è§£è€¦|Tobias WeiÃŸberg, Weikang Wang, Paul Roetzer, Nafie El Amrani, Florian Bernard|<https://arxiv.org/pdf/2601.14804v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|FunCineForge: A Unified Dataset Toolkit and Model for Zero-Shot Movie Dubbing in Diverse Cinematic Scenes|FunCineForgeï¼šé¢å‘å¤šæ ·åŒ–ç”µå½±åœºæ™¯ä¸­ Zero-Shot é…éŸ³çš„ç»Ÿä¸€æ•°æ®é›†å·¥å…·åŒ…ä¸æ¨¡å‹|Jiaxuan Liu, Yang Xiang, Han Zhao, Xiangang Li, Zhenhua Ling|<https://arxiv.org/pdf/2601.14777v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|A Training-Free Guess What Vision Language Model from Snippets to Open-Vocabulary Object Detection|ä¸€ç§æ— éœ€è®­ç»ƒçš„Guess Whatè§†è§‰è¯­è¨€æ¨¡å‹ï¼šä»ç‰‡æ®µåˆ°å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹|Guiying Zhu, Bowen Yang, Yin Zhuang, Tong Zhang, Guanqun Wang, Zhihao Che, He Chen, Lianlin Li|<https://arxiv.org/pdf/2601.11910v2>|æ— |


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Towards Understanding Best Practices for Quantization of Vision-Language Models|[ç¿»è¯‘å¤±è´¥] Towards Understanding Best Practices for Quantization of Vision-Language Models|Gautom Das, Vincent La, Ethan Lau, Abhinav Shrivastava, Matthew Gwilliam|<https://arxiv.org/pdf/2601.15287v1>|[ä»£ç ](https://github.com/gautomdas/mmq.)|
|ğŸ†• å‘å¸ƒ|A Computer Vision Hybrid Approach: CNN and Transformer Models for Accurate Alzheimer's Detection from Brain MRI Scans|ä¸€ç§è®¡ç®—æœºè§†è§‰æ··åˆæ–¹æ³•ï¼šç”¨äºä»è„‘éƒ¨MRIæ‰«æä¸­å‡†ç¡®æ£€æµ‹é˜¿å°”èŒ¨æµ·é»˜ç—…çš„CNNå’ŒTransformeræ¨¡å‹|Md Mahmudul Hoque, Shuvo Karmaker, Md. Hadi Al-Amin, Md Modabberul Islam, Jisun Junayed, Farha Ulfat Mahi|<https://arxiv.org/pdf/2601.15202v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Does Object Binding Naturally Emerge in Large Pretrained Vision Transformers?|Object Binding æ˜¯å¦åœ¨å¤§è§„æ¨¡é¢„è®­ç»ƒ Vision Transformers ä¸­è‡ªç„¶æ¶Œç°ï¼Ÿ|Yihao Li, Saeed Salehi, Lyle Ungar, Konrad P. Kording|<https://arxiv.org/pdf/2510.24709v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|VIAFormer: Voxel-Image Alignment Transformer for High-Fidelity Voxel Refinement|VIAFormer: ç”¨äºé«˜ä¿çœŸ Voxel ç»†åŒ–çš„ Voxel-Image Alignment Transformer|Tiancheng Fang, Bowen Pan, Lingxi Chen, Jiangjing Lyu, Chengfei Lyu, Chaoyue Niu, Fan Wu|<https://arxiv.org/pdf/2601.13664v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|HiT: History-Injection Transformers for Onboard Continuous Flood Change Detection|HiTï¼šç”¨äºæ˜Ÿè½½è¿ç»­æ´ªæ°´å˜åŒ–æ£€æµ‹çš„ History-Injection Transformers|Daniel Kyselica, JonÃ¡Å¡ Herec, Oliver Kutis, Rado PitoÅˆÃ¡k|<https://arxiv.org/pdf/2601.13751v2>|[ä»£ç ](https://github.com/zaitra/HiT-change-detection); åˆ†æå¤±è´¥|


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Hyperphantasia: A Benchmark for Evaluating the Mental Visualization Capabilities of Multimodal LLMs|Hyperphantasiaï¼šä¸€ä¸ªè¯„ä¼°å¤šæ¨¡æ€LLMå¿ƒç†å¯è§†åŒ–èƒ½åŠ›çš„åŸºå‡†|Mohammad Shahab Sepehri, Berk Tinaz, Zalan Fabian, Mahdi Soltanolkotabi|<https://arxiv.org/pdf/2507.11932v2>|æ— |
|ğŸ†• å‘å¸ƒ|Large-Scale Multidimensional Knowledge Profiling of Scientific Literature|ç§‘å­¦æ–‡çŒ®çš„å¤§è§„æ¨¡å¤šç»´çŸ¥è¯†ç”»åƒ|Zhucun Xue, Jiangning Zhang, Juntao Jiang, Jinzhuo Liu, Haoyang He, Teng Hu, Xiaobin Hu, Guangming Yao .etc.|<https://arxiv.org/pdf/2601.15170v1>|[ä»£ç ](https://github.com/xzc-zju/Profiling_Scientific_Literature); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Omni-AVSR: Towards Unified Multimodal Speech Recognition with Large Language Models|Omni-AVSR: åŸºäºLarge Language Modelsçš„ç»Ÿä¸€Multimodal Speech Recognition|Umberto Cappellazzo, Xubo Liu, Pingchuan Ma, Stavros Petridis, Maja Pantic|<https://arxiv.org/pdf/2511.07253v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|A Multi-Stage Augmented Multimodal Interaction Network for Quantifying Fish Feeding Intensity Using Feeding Image, Audio and Water Wave|ä¸€ç§åŸºäºæŠ•å–‚å›¾åƒã€éŸ³é¢‘å’Œæ°´æ³¢é‡åŒ–é±¼ç±»æ‘„é£Ÿå¼ºåº¦çš„å¤šé˜¶æ®µå¢å¼ºå¤šæ¨¡æ€äº¤äº’ç½‘ç»œ|Shulong Zhang, Mingyuan Yao, Jiayin Zhao, Daoliang Li, Yingyi Chen, Haihua Wang|<https://arxiv.org/pdf/2506.14170v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Multimodal system for skin cancer detection|ç”¨äºçš®è‚¤ç™Œæ£€æµ‹çš„å¤šæ¨¡æ€ç³»ç»Ÿ|Volodymyr Sydorskyi, Igor Krashenyi, Oleksii Yakubenko|<https://arxiv.org/pdf/2601.14822v1>|åˆ†æå¤±è´¥|


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### ç›®æ ‡æ£€æµ‹ä¸å®šä½ (Object Detection & Localization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ZENITH: Automated Gradient Norm Informed Stochastic Optimization|[ç¿»è¯‘å¤±è´¥] ZENITH: Automated Gradient Norm Informed Stochastic Optimization|Dhrubo Saha|<https://arxiv.org/pdf/2601.15212v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Debate-Enhanced Pseudo Labeling and Frequency-Aware Progressive Debiasing for Weakly-Supervised Camouflaged Object Detection with Scribble Annotations|åŸºäºæ¶‚é¸¦æ ‡æ³¨çš„å¼±ç›‘ç£ä¼ªè£…ç›®æ ‡æ£€æµ‹çš„è¾©è®ºå¢å¼ºä¼ªæ ‡ç­¾ä¸é¢‘ç‡æ„ŸçŸ¥æ¸è¿›å»å|Jiawei Ge, Jiuxin Cao, Xinyi Li, Xuelin Zhu, Chang Liu, Bo Liu, Chen Feng, Ioannis Patras|<https://arxiv.org/pdf/2512.20260v4>|æ— |
|ğŸ“ æ›´æ–°|Training-Free In-Context Forensic Chain for Image Manipulation Detection and Localization|[ç¿»è¯‘å¤±è´¥] Training-Free In-Context Forensic Chain for Image Manipulation Detection and Localization|Rui Chen, Bin Liu, Changtao Miao, Xinghao Wang, Yi Li, Tao Gong, Qi Chu, Nenghai Yu|<https://arxiv.org/pdf/2510.10111v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|M2I2HA: A Multi-modal Object Detection Method Based on Intra- and Inter-Modal Hypergraph Attention|M2I2HA: ä¸€ç§åŸºäºæ¨¡æ€å†…å’Œæ¨¡æ€é—´è¶…å›¾æ³¨æ„åŠ›çš„å¤šæ¨¡æ€ç›®æ ‡æ£€æµ‹æ–¹æ³•|Xiaofan Yang, Yubin Liu, Wei Pan, Guoqing Chu, Junming Zhang, Jie Zhao, Zhuoqi Man, Xuanming Cao|<https://arxiv.org/pdf/2601.14776v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|SimD3: A Synthetic drone Dataset with Payload and Bird Distractor Modeling for Robust Detection|SimD3: ä¸€ä¸ªå¸¦æœ‰è½½è·å’Œé¸Ÿç±»å¹²æ‰°å»ºæ¨¡çš„åˆæˆæ— äººæœºæ•°æ®é›†ï¼Œç”¨äºé²æ£’æ£€æµ‹|Ami Pandat, Kanyala Muvva, Punna Rajasekhar, Gopika Vinod, Rohit Shukla|<https://arxiv.org/pdf/2601.14742v1>|æ— |


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|BBoxMaskPose v2: Expanding Mutual Conditioning to 3D|BBoxMaskPose v2: å°†ç›¸äº’æ¡ä»¶æ‰©å±•åˆ° 3D|Miroslav Purkrabek, Constantin Kolomiiets, Jiri Matas|<https://arxiv.org/pdf/2601.15200v1>|[ä»£ç ](https://MiraPurkrabek.github.io/BBox-Mask-Pose); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Enhancing Few-Shot Out-of-Distribution Detection via the Refinement of Foreground and Background|[ç¿»è¯‘å¤±è´¥] Enhancing Few-Shot Out-of-Distribution Detection via the Refinement of Foreground and Background|Tianyu Li, Songyue Cai, Zongqian Wu, Ping Hu, Xiaofeng Zhu|<https://arxiv.org/pdf/2601.15065v1>|[ä»£ç ](https://github.com/lounwb/FoBoR.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Difference Decomposition Networks for Infrared Small Target Detection|[ç¿»è¯‘å¤±è´¥] Difference Decomposition Networks for Infrared Small Target Detection|Chen Hu, Mingyu Zhou, Shuai Yuan, Hongbo Hu, Zhenming Peng, Tian Pu, Xiyin Li|<https://arxiv.org/pdf/2512.03470v3>|[ä»£ç ](https://github.com/greekinRoma/IRSTD_HC_Platform.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|FeedbackSTS-Det: Sparse Frames-Based Spatio-Temporal Semantic Feedback Network for Infrared Small Target Detection|FeedbackSTS-Det: åŸºäºç¨€ç–å¸§çš„æ—¶ç©ºè¯­ä¹‰åé¦ˆç½‘ç»œç”¨äºçº¢å¤–å°ç›®æ ‡æ£€æµ‹|Yian Huang, Qing Qin, Aji Mao, Xiangyu Qiu, Liang Xu, Xian Zhang, Zhenming Peng|<https://arxiv.org/pdf/2601.14690v1>|[ä»£ç ](https://github.com/IDIP-Lab/FeedbackSTS-Det.)|
|ğŸ†• å‘å¸ƒ|READ-Net: Clarifying Emotional Ambiguity via Adaptive Feature Recalibration for Audio-Visual Depression Detection|READ-Net: é€šè¿‡è‡ªé€‚åº”ç‰¹å¾é‡æ ¡å‡†æ¶ˆé™¤æƒ…æ„Ÿæ¨¡ç³Šä»¥è¿›è¡Œ Audio-Visual Depression Detection|Chenglizhao Chen, Boze Li, Mengke Song, Dehao Feng, Xinyu Liu, Shanchen Pang, Jufeng Yang, Hui Yu|<https://arxiv.org/pdf/2601.14651v1>|åˆ†æå¤±è´¥|


### å›¾åƒåˆ†ç±»ä¸è¯†åˆ« (Image Classification & Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Graph Recognition via Subgraph Prediction|[ç¿»è¯‘å¤±è´¥] Graph Recognition via Subgraph Prediction|AndrÃ© Eberhard, Gerhard Neumann, Pascal Friederich|<https://arxiv.org/pdf/2601.15133v1>|åˆ†æå¤±è´¥|


### è¯­ä¹‰/å®ä¾‹åˆ†å‰² (Semantic/Instance Segmentation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Erosion Attack for Adversarial Training to Enhance Semantic Segmentation Robustness|[ç¿»è¯‘å¤±è´¥] Erosion Attack for Adversarial Training to Enhance Semantic Segmentation Robustness|Yufei Song, Ziqi Zhou, Menghao Deng, Yifan Hu, Shengshan Hu, Minghui Li, Leo Yu Zhang|<https://arxiv.org/pdf/2601.14950v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Context Patch Fusion With Class Token Enhancement for Weakly Supervised Semantic Segmentation|[ç¿»è¯‘å¤±è´¥] Context Patch Fusion With Class Token Enhancement for Weakly Supervised Semantic Segmentation|Yiyang Fu, Hui Li, Wangyu Wu|<https://arxiv.org/pdf/2601.14718v1>|åˆ†æå¤±è´¥|


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Walk through Paintings: Egocentric World Models from Internet Priors|Walk through Paintings: æ¥è‡ª Internet Priors çš„ Egocentric World Models|Anurag Bagchi, Zhipeng Bao, Homanga Bharadhwaj, Yu-Xiong Wang, Pavel Tokmakov, Martial Hebert|<https://arxiv.org/pdf/2601.15284v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Iterative Refinement Improves Compositional Image Generation|[ç¿»è¯‘å¤±è´¥] Iterative Refinement Improves Compositional Image Generation|Shantanu Jaiswal, Mihir Prabhudesai, Nikash Bhardwaj, Zheyang Qin, Amir Zadeh, Chuan Li, Katerina Fragkiadaki, Deepak Pathak|<https://arxiv.org/pdf/2601.15286v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|LuxRemix: Lighting Decomposition and Remixing for Indoor Scenes|LuxRemixï¼šå®¤å†…åœºæ™¯çš„å…‰ç…§åˆ†è§£ä¸é‡æ··|Ruofan Liang, Norman MÃ¼ller, Ethan Weber, Duncan Zauss, Nandita Vijaykumar, Peter Kontschieder, Christian Richardt|<https://arxiv.org/pdf/2601.15283v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|StableWorld: Towards Stable and Consistent Long Interactive Video Generation|StableWorld: è¿ˆå‘ç¨³å®šä¸”ä¸€è‡´çš„é•¿äº¤äº’è§†é¢‘ç”Ÿæˆ|Ying Yang, Zhengyao Lv, Tianlin Pan, Haofan Wang, Binxin Yang, Hubery Yin, Chen Li, Ziwei Liu .etc.|<https://arxiv.org/pdf/2601.15281v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|FlowSSC: Universal Generative Monocular Semantic Scene Completion via One-Step Latent Diffusion|FlowSSC: åŸºäºä¸€æ­¥æ½œåœ¨æ‰©æ•£çš„é€šç”¨ç”Ÿæˆå¼å•ç›®è¯­ä¹‰åœºæ™¯è¡¥å…¨|Zichen Xi, Hao-Xiang Chen, Nan Xue, Hongyu Yan, Qi-Yuan Feng, Levent Burak Kara, Joaquim Jorge, Qun-Ce Xu|<https://arxiv.org/pdf/2601.15250v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|ScenDi: 3D-to-2D Scene Diffusion Cascades for Urban Generation|ScenDiï¼šç”¨äºåŸå¸‚ç”Ÿæˆçš„3D-to-2Dåœºæ™¯æ‰©æ•£çº§è”|Hanlei Guo, Jiahao Shao, Xinya Chen, Xiyang Tan, Sheng Miao, Yujun Shen, Yiyi Liao|<https://arxiv.org/pdf/2601.15221v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|CRAFT: Continuous Reasoning and Agentic Feedback Tuning for Multimodal Text-to-Image Generation|CRAFTï¼šç”¨äºå¤šæ¨¡æ€æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„è¿ç»­æ¨ç†ä¸æ™ºèƒ½ä½“åé¦ˆè°ƒä¼˜|V. Kovalev, A. Kuvshinov, A. Buzovkin, D. Pokidov, D. Timonin|<https://arxiv.org/pdf/2512.20362v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Sora as a World Model? A Complete Survey on Text-to-Video Generation|Sora ä½œä¸ºä¸–ç•Œæ¨¡å‹ï¼Ÿå…³äº Text-to-Video Generation çš„å…¨é¢ç»¼è¿°|Fachrina Dewi Puspitasari, Chaoning Zhang, Joseph Cho, Adnan Haider, Noor Ul Eman, Omer Amin, Alexis Mankowski, Muhammad Umair .etc.|<https://arxiv.org/pdf/2403.05131v3>|æ— |
|ğŸ†• å‘å¸ƒ|Differential Privacy Image Generation with Reconstruction Loss and Noise Injection Using an Error Feedback SGD|åŸºäºè¯¯å·®åé¦ˆ SGD çš„é‡æ„æŸå¤±ä¸å™ªå£°æ³¨å…¥å·®åˆ†éšç§å›¾åƒç”Ÿæˆ|Qiwei Ma, Jun Zhang|<https://arxiv.org/pdf/2601.15061v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|SpatialV2A: Visual-Guided High-fidelity Spatial Audio Generation|[ç¿»è¯‘å¤±è´¥] SpatialV2A: Visual-Guided High-fidelity Spatial Audio Generation|Yanan Wang, Linjie Ren, Zihao Li, Junyi Wang, Tian Gan|<https://arxiv.org/pdf/2601.15017v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|TempViz: On the Evaluation of Temporal Knowledge in Text-to-Image Models|TempViz: å…³äº Text-to-Image æ¨¡å‹ä¸­æ—¶åºçŸ¥è¯†çš„è¯„ä¼°|Carolin Holtermann, Nina Krebs, Anne Lauscher|<https://arxiv.org/pdf/2601.14951v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|A Constraint Programming Model for the Super-Agile Earth Observation Satellite Imaging Scheduling Problem|[ç¿»è¯‘å¤±è´¥] A Constraint Programming Model for the Super-Agile Earth Observation Satellite Imaging Scheduling Problem|Margarida Caleiras, Samuel Moniz, Paulo Jorge Nascimento|<https://arxiv.org/pdf/2601.11967v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|MTFlow: Time-Conditioned Flow Matching for Microtubule Segmentation in Noisy Microscopy Images|MTFlow: ç”¨äºå™ªå£°æ˜¾å¾®é•œå›¾åƒä¸­å¾®ç®¡åˆ†å‰²çš„æ—¶é—´æ¡ä»¶æµåŒ¹é…|Sidi Mohamed Sid El Moctar, Achraf Ait Laydi, Yousef El Mourabit, HÃ©lÃ¨ne Bouvrais|<https://arxiv.org/pdf/2601.14841v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Reconstruction-Anchored Diffusion Model for Text-to-Motion Generation|åŸºäºé‡å»ºé”šå®šçš„æ–‡æœ¬åˆ°åŠ¨ä½œç”Ÿæˆæ‰©æ•£æ¨¡å‹|Yifei Liu, Changxing Ding, Ling Guo, Huaiguang Jiang, Qiong Cao|<https://arxiv.org/pdf/2601.14788v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Human detectors are surprisingly powerful reward models|Human detectors æ˜¯ä»¤äººæƒŠè®¶çš„å¼ºå¤§çš„ reward models|Kumar Ashutosh, XuDong Wang, Xi Yin, Kristen Grauman, Adam Polyak, Ishan Misra, Rohit Girdhar|<https://arxiv.org/pdf/2601.14037v2>|æ— |
|ğŸ“ æ›´æ–°|Can Synthetic Images Serve as Effective and Efficient Class Prototypes?|åˆæˆå›¾åƒèƒ½å¦ä½œä¸ºæœ‰æ•ˆä¸”é«˜æ•ˆçš„ç±»åˆ«åŸå‹ï¼Ÿ|Dianxing Shi, Dingjie Fu, Yuqiao Liu, Jun Wang|<https://arxiv.org/pdf/2512.17160v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|T2T-VICL: Unlocking the Boundaries of Cross-Task Visual In-Context Learning via Implicit Text-Driven VLMs|T2T-VICL: é€šè¿‡éšå¼æ–‡æœ¬é©±åŠ¨çš„VLMsè§£é”è·¨ä»»åŠ¡è§†è§‰ä¸Šä¸‹æ–‡å­¦ä¹ çš„è¾¹ç•Œ|Shao-Jun Xia, Huixin Zhang, Zhengzhong Tu|<https://arxiv.org/pdf/2511.16107v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Unified Text-Image Generation with Weakness-Targeted Post-Training|é¢å‘å¼±ç‚¹å®šä½çš„åè®­ç»ƒç»Ÿä¸€ Text-Image ç”Ÿæˆ|Jiahui Chen, Philippe Hansen-Estruch, Xiaochuang Han, Yushi Hu, Emily Dinan, Amita Kamath, Michal Drozdzal, Reyhane Askari-Hemmat .etc.|<https://arxiv.org/pdf/2601.04339v2>|æ— |
|ğŸ†• å‘å¸ƒ|LaVR: Scene Latent Conditioned Generative Video Trajectory Re-Rendering using Large 4D Reconstruction Models|LaVRï¼šåˆ©ç”¨å¤§å‹4Dé‡å»ºæ¨¡å‹è¿›è¡Œåœºæ™¯æ½œåœ¨æ¡ä»¶ç”Ÿæˆå¼è§†é¢‘è½¨è¿¹é‡æ¸²æŸ“|Mingyang Xie, Numair Khan, Tianfu Wang, Naina Dhingra, Seonghyeon Nam, Haitao Yang, Zhuo Hui, Christopher Metzler .etc.|<https://arxiv.org/pdf/2601.14674v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Interleaved Latent Visual Reasoning with Selective Perceptual Modeling|å…·æœ‰é€‰æ‹©æ€§æ„ŸçŸ¥å»ºæ¨¡çš„äº¤é”™æ½œåœ¨è§†è§‰æ¨ç†|Shuai Dong, Siyuan Wang, Xingyu Liu, Chenglin Li, Haowen Hou, Zhongyu Wei|<https://arxiv.org/pdf/2512.05665v3>|[ä»£ç ](https://github.com/XD111ds/ILVR.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Mirai: Autoregressive Visual Generation Needs Foresight|Miraiï¼šè‡ªå›å½’è§†è§‰ç”Ÿæˆéœ€è¦ Foresight|Yonghao Yu, Lang Huang, Zerun Wang, Runyi Li, Toshihiko Yamasaki|<https://arxiv.org/pdf/2601.14671v1>|æ— |
|ğŸ†• å‘å¸ƒ|3D Space as a Scratchpad for Editable Text-to-Image Generation|[ç¿»è¯‘å¤±è´¥] 3D Space as a Scratchpad for Editable Text-to-Image Generation|Oindrila Saha, Vojtech Krs, Radomir Mech, Subhransu Maji, Matheus Gadelha, Kevin Blackburn-Matzen|<https://arxiv.org/pdf/2601.14602v1>|[ä»£ç ](https://oindrilasaha.github.io/3DScratchpad)|


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries|BayesianVLA: é€šè¿‡Latent Action Querieså¯¹Vision Language Action Modelsè¿›è¡Œè´å¶æ–¯åˆ†è§£|Shijie Lian, Bin Yu, Xiaopeng Lin, Laurence T. Yang, Zhaolong Shen, Changti Wu, Yuzhuo Miao, Cong Huang .etc.|<https://arxiv.org/pdf/2601.15197v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Pb4U-GNet: Resolution-Adaptive Garment Simulation via Propagation-before-Update Graph Network|Pb4U-GNet: é€šè¿‡ Propagation-before-Update Graph Network å®ç°åˆ†è¾¨ç‡è‡ªé€‚åº”çš„æœè£…ä»¿çœŸ|Aoran Liu, Kun Hu, Clinton Ansun Mo, Qiuxia Wu, Wenxiong Kang, Zhiyong Wang|<https://arxiv.org/pdf/2601.15110v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|The Pictorial Cortex: Zero-Shot Cross-Subject fMRI-to-Image Reconstruction via Compositional Latent Modeling|[ç¿»è¯‘å¤±è´¥] The Pictorial Cortex: Zero-Shot Cross-Subject fMRI-to-Image Reconstruction via Compositional Latent Modeling|Jingyang Huo, Yikai Wang, Yanwei Fu, Jianfeng Feng|<https://arxiv.org/pdf/2601.15071v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|When Are Two Scores Better Than One? Investigating Ensembles of Diffusion Models|[ç¿»è¯‘å¤±è´¥] When Are Two Scores Better Than One? Investigating Ensembles of Diffusion Models|RaphaÃ«l Razafindralambo, RÃ©my Sun, FrÃ©dÃ©ric Precioso, Damien Garreau, Pierre-Alexandre Mattei|<https://arxiv.org/pdf/2601.11444v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Towards Holistic Modeling for Video Frame Interpolation with Auto-regressive Diffusion Transformers|[ç¿»è¯‘å¤±è´¥] Towards Holistic Modeling for Video Frame Interpolation with Auto-regressive Diffusion Transformers|Xinyu Peng, Han Li, Yuyang Huang, Ziyang Zheng, Yaoming Wang, Xin Chen, Wenrui Dai, Chenglin Li .etc.|<https://arxiv.org/pdf/2601.14959v1>|[ä»£ç ](https://github.com/xypeng9903/LDF-VFI.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Semantic Image Synthesis via Diffusion Models|[ç¿»è¯‘å¤±è´¥] Semantic Image Synthesis via Diffusion Models|Wengang Zhou, Weilun Wang, Jianmin Bao, Dongdong Chen, Dong Chen, Lu Yuan, Houqiang Li|<https://arxiv.org/pdf/2207.00050v4>|[ä»£ç ](https://github.com/WeilunWang/semantic-diffusion-model.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Trustworthy Longitudinal Brain MRI Completion: A Deformation-Based Approach with KAN-Enhanced Diffusion Model|[ç¿»è¯‘å¤±è´¥] Trustworthy Longitudinal Brain MRI Completion: A Deformation-Based Approach with KAN-Enhanced Diffusion Model|Tianli Tao, Ziyang Wang, Delong Yang, Han Zhang, Le Zhang|<https://arxiv.org/pdf/2601.09572v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|UBATrack: Spatio-Temporal State Space Model for General Multi-Modal Tracking|UBATrack: ç”¨äºé€šç”¨å¤šæ¨¡æ€è·Ÿè¸ªçš„æ—¶ç©ºçŠ¶æ€ç©ºé—´æ¨¡å‹|Qihua Liang, Liang Chen, Yaozong Zheng, Jian Nong, Zhiyi Mo, Bineng Zhong|<https://arxiv.org/pdf/2601.14799v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Safeguarding Facial Identity against Diffusion-based Face Swapping via Cascading Pathway Disruption|é€šè¿‡çº§è”è·¯å¾„é˜»æ–­é˜²èŒƒåŸºäºDiffusionçš„äººè„¸äº¤æ¢ä»¥ä¿æŠ¤é¢éƒ¨èº«ä»½|Liqin Wang, Qianyue Hu, Wei Lu, Xiangyang Luo|<https://arxiv.org/pdf/2601.14738v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Extendable Generalization Self-Supervised Diffusion for Low-Dose CT Reconstruction|å¯æ‰©å±•æ³›åŒ–è‡ªç›‘ç£æ‰©æ•£ç”¨äºä½å‰‚é‡CTé‡å»º|Guoquan Wei, Liu Shi, Zekun Zhou, Mohan Li, Cunfeng Wei, Wenzhe Shan, Qiegen Liu|<https://arxiv.org/pdf/2509.23885v3>|æ— |
|ğŸ†• å‘å¸ƒ|LookBench: A Live and Holistic Open Benchmark for Fashion Image Retrieval|LookBench: ä¸€ä¸ªé¢å‘æ—¶å°šå›¾åƒæ£€ç´¢çš„å®æ—¶ä¸”å…¨é¢çš„å¼€æ”¾åŸºå‡†|Chao Gao, Siqiao Xue, Yimin Peng, Jiwen Fu, Tingyi Gu, Shanshan Li, Fan Zhou|<https://arxiv.org/pdf/2601.14706v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Smudged Fingerprints: A Systematic Evaluation of the Robustness of AI Image Fingerprints|Smudged Fingerprints: AI Image Fingerprints é²æ£’æ€§çš„ç³»ç»Ÿæ€§è¯„ä¼°|Kai Yao, Marc Juarez|<https://arxiv.org/pdf/2512.11771v2>|[ä»£ç ](https://github.com/kaikaiyao/SmudgedFingerprints.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|A comprehensive overview of deep learning models for object detection from videos/images|[ç¿»è¯‘å¤±è´¥] A comprehensive overview of deep learning models for object detection from videos/images|Sukana Zulfqar, Sadia Saeed, M. Azam Zia, Anjum Ali, Faisal Mehmood, Abid Ali|<https://arxiv.org/pdf/2601.14677v1>|æ— |
|ğŸ“ æ›´æ–°|$\mathrm{D}^\mathrm{3}$-Predictor: Noise-Free Deterministic Diffusion for Dense Prediction|$\mathrm{D}^\mathrm{3}$-Predictor: ç”¨äº Dense Prediction çš„æ— å™ªç¡®å®šæ€§ Diffusion|Changliang Xia, Chengyou Jia, Minnan Luo, Zhuohang Dang, Xin Shen, Bowen Ping|<https://arxiv.org/pdf/2512.07062v4>|[ä»£ç ](https://x-gengroup.github.io/HomePage_D3-Predictor)|
|ğŸ†• å‘å¸ƒ|Diffusion Epistemic Uncertainty with Asymmetric Learning for Diffusion-Generated Image Detection|Diffusion è®¤çŸ¥ä¸ç¡®å®šæ€§ä¸éå¯¹ç§°å­¦ä¹ åœ¨ Diffusion ç”Ÿæˆå›¾åƒæ£€æµ‹ä¸­çš„åº”ç”¨|Yingsong Huang, Hui Guo, Jing Huang, Bing Bai, Qi Xiong|<https://arxiv.org/pdf/2601.14625v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|RI3D: Few-Shot Gaussian Splatting With Repair and Inpainting Diffusion Priors|RI3D: åŸºäºä¿®å¤å’Œä¿®å¤æ‰©æ•£å…ˆéªŒçš„å°‘æ ·æœ¬é«˜æ–¯æ³¼æº…|Avinash Paliwal, Xilong Zhou, Wei Ye, Jinhui Xiong, Rakesh Ranjan, Nima Khademi Kalantari|<https://arxiv.org/pdf/2503.10860v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Anatomically Guided Latent Diffusion for Brain MRI Progression Modeling|[ç¿»è¯‘å¤±è´¥] Anatomically Guided Latent Diffusion for Brain MRI Progression Modeling|Cheng Wan, Bahram Jafrasteh, Ehsan Adeli, Miaomiao Zhang, Qingyu Zhao|<https://arxiv.org/pdf/2601.14584v1>|åˆ†æå¤±è´¥|


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Unlocking Generalization in Polyp Segmentation with DINO Self-Attention "keys"|åˆ©ç”¨ DINO Self-Attention "keys" è§£é”æ¯è‚‰åˆ†å‰²çš„æ³›åŒ–èƒ½åŠ›|Carla Monteiro, Valentina Corbetta, Regina Beets-Tan, LuÃ­s F. Teixeira, Wilson Silva|<https://arxiv.org/pdf/2512.13376v2>|æ— |
|ğŸ“ æ›´æ–°|PanoDreamer: Optimization-Based Single Image to 360 3D Scene With Diffusion|PanoDreamer: åŸºäºä¼˜åŒ–çš„å•å›¾åƒåˆ° 360 3D åœºæ™¯ç”Ÿæˆæ–¹æ³•ï¼Œç»“åˆ Diffusion|Avinash Paliwal, Xilong Zhou, Andrii Tsarov, Nima Khademi Kalantari|<https://arxiv.org/pdf/2412.04827v3>|æ— |


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Enhancing Text-to-Image Generation via End-Edge Collaborative Hybrid Super-Resolution|é€šè¿‡ç«¯è¾¹ååŒæ··åˆè¶…åˆ†è¾¨ç‡å¢å¼ºText-to-Imageç”Ÿæˆ|Chongbin Yi, Yuxin Liang, Ziqi Zhou, Peng Yang|<https://arxiv.org/pdf/2601.14741v1>|åˆ†æå¤±è´¥|


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|RayRoPE: Projective Ray Positional Encoding for Multi-view Attention|RayRoPE: ç”¨äºå¤šè§†å›¾æ³¨æ„åŠ›çš„æŠ•å½±å°„çº¿ä½ç½®ç¼–ç |Yu Wu, Minsik Jeon, Jen-Hao Rick Chang, Oncel Tuzel, Shubham Tulsiani|<https://arxiv.org/pdf/2601.15275v1>|æ— |
|ğŸ“ æ›´æ–°|ConeGS: Error-Guided Densification Using Pixel Cones for Improved Reconstruction With Fewer Primitives|ConeGSï¼šåˆ©ç”¨åƒç´ é”¥è¿›è¡Œè¯¯å·®å¼•å¯¼çš„è‡´å¯†åŒ–ï¼Œä»¥æ›´å°‘çš„å›¾å…ƒå®ç°æ”¹è¿›çš„é‡å»º|BartÅ‚omiej Baranowski, Stefano Esposito, Patricia GschoÃŸmann, Anpei Chen, Andreas Geiger|<https://arxiv.org/pdf/2511.06810v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Encoding Emotion Through Self-Supervised Eye Movement Reconstruction|é€šè¿‡è‡ªç›‘ç£çœ¼åŠ¨é‡å»ºç¼–ç æƒ…æ„Ÿ|Marcus Ma, Jordan Prescott, Emily Zhou, Tiantian Feng, Kleanthis Avramidis, Gabor Mihaly Toth, Shrikanth Narayanan|<https://arxiv.org/pdf/2601.12534v2>|åˆ†æå¤±è´¥|


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|GAT-NeRF: Geometry-Aware-Transformer Enhanced Neural Radiance Fields for High-Fidelity 4D Facial Avatars|[ç¿»è¯‘å¤±è´¥] GAT-NeRF: Geometry-Aware-Transformer Enhanced Neural Radiance Fields for High-Fidelity 4D Facial Avatars|Zhe Chang, Haodong Jin, Ying Sun, Yan Song, Hui Yu|<https://arxiv.org/pdf/2601.14875v1>|æ— |
|ğŸ†• å‘å¸ƒ|POTR: Post-Training 3DGS Compression|POTR: è®­ç»ƒå 3DGS å‹ç¼©|Bert Ramlot, Martijn Courteaux, Peter Lambert, Glenn Van Wallendael|<https://arxiv.org/pdf/2601.14821v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|NumGrad-Pull: Numerical Gradient Guided Tri-plane Representation for Surface Reconstruction from Point Clouds|NumGrad-Pull: æ•°å€¼æ¢¯åº¦å¼•å¯¼çš„Tri-planeè¡¨ç¤ºç”¨äºç‚¹äº‘è¡¨é¢é‡å»º|Ruikai Cui, Binzhu Xie, Shi Qiu, Jiawei Liu, Saeed Anwar, Nick Barnes|<https://arxiv.org/pdf/2411.17392v2>|[ä»£ç ](https://github.com/CuiRuikai/NumGrad-Pull); åˆ†æå¤±è´¥|


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Training-Free and Interpretable Hateful Video Detection via Multi-stage Adversarial Reasoning|[ç¿»è¯‘å¤±è´¥] Training-Free and Interpretable Hateful Video Detection via Multi-stage Adversarial Reasoning|Shuonan Yang, Yuchen Zhang, Zeyu Fu|<https://arxiv.org/pdf/2601.15115v1>|[ä»£ç ](https://github.com/Multimodal-Intelligence-Lab-MIL/MARS.)|
|ğŸ†• å‘å¸ƒ|LiViBench: An Omnimodal Benchmark for Interactive Livestream Video Understanding|[ç¿»è¯‘å¤±è´¥] LiViBench: An Omnimodal Benchmark for Interactive Livestream Video Understanding|Xiaodong Wang, Langling Huang, Zhirong Wu, Xu Zhao, Teng Xu, Xuhong Xia, Peixi Peng|<https://arxiv.org/pdf/2601.15016v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|HERMES: KV Cache as Hierarchical Memory for Efficient Streaming Video Understanding|HERMES: å°† KV Cache ä½œä¸ºåˆ†å±‚è®°å¿†ä»¥å®ç°é«˜æ•ˆçš„æµå¼è§†é¢‘ç†è§£|Haowei Zhang, Shudong Yang, Jinlan Fu, See-Kiong Ng, Xipeng Qiu|<https://arxiv.org/pdf/2601.14724v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|RiskCueBench: Benchmarking Anticipatory Reasoning from Early Risk Cues in Video-Language Models|RiskCueBench: åœ¨ Video-Language Models ä¸­åŸºäºæ—©æœŸé£é™©çº¿ç´¢çš„é¢„åˆ¤æ¨ç†åŸºå‡†æµ‹è¯•|Sha Luo, Yogesh Prabhu, Timothy Ossowski, Kaiping Chen, Junjie Hu|<https://arxiv.org/pdf/2601.03369v2>|æ— |
|ğŸ†• å‘å¸ƒ|LFS: Learnable Frame Selector for Event-Aware and Temporally Diverse Video Captioning|LFSï¼šç”¨äºEvent-Awareå’ŒTemporally Diverse Video Captioningçš„å¯å­¦ä¹ å¸§é€‰æ‹©å™¨|Lianying Chao, Linfeng Yin, Peiyu Ren, Yifan Jiang, Qiaoyu Ren, Dingcheng Shan, Jing-cheng Pang, Sijie Wu .etc.|<https://arxiv.org/pdf/2601.14594v1>|æ— |
|ğŸ†• å‘å¸ƒ|Breaking the accuracy-resource dilemma: a lightweight adaptive video inference enhancement|æ‰“ç ´å‡†ç¡®ç‡ä¸èµ„æºçš„ä¸¤éš¾å›°å¢ƒï¼šä¸€ç§è½»é‡çº§è‡ªé€‚åº”è§†é¢‘æ¨ç†å¢å¼ºæ–¹æ³•|Wei Ma, Shaowu Chen, Junjie Ye, Peichang Zhang, Lei Huang|<https://arxiv.org/pdf/2601.14568v1>|åˆ†æå¤±è´¥|


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|APPLE: Attribute-Preserving Pseudo-Labeling for Diffusion-Based Face Swapping|APPLE: ç”¨äºåŸºäºDiffusionçš„äººè„¸äº¤æ¢çš„å±æ€§ä¿æŒä¼ªæ ‡ç­¾|Jiwon Kang, Yeji Choi, JoungBin Lee, Wooseok Jang, Jinhyeok Choi, Taekeun Kang, Yongjae Park, Myungin Kim .etc.|<https://arxiv.org/pdf/2601.15288v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|PROGRESSLM: Towards Progress Reasoning in Vision-Language Models|[ç¿»è¯‘å¤±è´¥] PROGRESSLM: Towards Progress Reasoning in Vision-Language Models|Jianshu Zhang, Chengxuan Qian, Haosen Sun, Haoran Lu, Dingcheng Wang, Letian Xue, Han Liu|<https://arxiv.org/pdf/2601.15224v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Tracing 3D Anatomy in 2D Strokes: A Multi-Stage Projection Driven Approach to Cervical Spine Fracture Identification|[ç¿»è¯‘å¤±è´¥] Tracing 3D Anatomy in 2D Strokes: A Multi-Stage Projection Driven Approach to Cervical Spine Fracture Identification|Fabi Nahian Madhurja, Rusab Sarmun, Muhammad E. H. Chowdhury, Adam Mushtak, Israa Al-Hashimi, Sohaib Bassam Zoghoul|<https://arxiv.org/pdf/2601.15235v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Synthetic Data Augmentation for Multi-Task Chinese Porcelain Classification: A Stable Diffusion Approach|ç”¨äºå¤šä»»åŠ¡ä¸­å›½ç“·å™¨åˆ†ç±»çš„åˆæˆæ•°æ®å¢å¼ºï¼šä¸€ç§Stable Diffusionæ–¹æ³•|Ziyao Ling, Silvia Mirri, Paola Salomoni, Giovanni Delnevo|<https://arxiv.org/pdf/2601.14791v1>|åˆ†æå¤±è´¥|


### æ¨ç†ä¼˜åŒ– (Inference Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|A Dynamic Prognostic Prediction Method for Colorectal Cancer Liver Metastasis|ä¸€ç§ç”¨äºç»“ç›´è‚ ç™Œè‚è½¬ç§»çš„åŠ¨æ€é¢„åé¢„æµ‹æ–¹æ³•|Wei Yang, Yiran Zhu, Yan su, Zesheng Li, Chengchang Pan, Honggang Qi|<https://arxiv.org/pdf/2505.03123v2>|åˆ†æå¤±è´¥|


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|OSMa-Bench: Evaluating Open Semantic Mapping Under Varying Lighting Conditions|OSMa-Bench: åœ¨ä¸åŒå…‰ç…§æ¡ä»¶ä¸‹è¯„ä¼°å¼€æ”¾è¯­ä¹‰æ˜ å°„|Maxim Popov, Regina Kurkova, Mikhail Iumanov, Jaafar Mahmoud, Sergey Kolyubin|<https://arxiv.org/pdf/2503.10331v3>|[ä»£ç ](https://be2rlab.github.io/OSMa-Bench)|
|ğŸ†• å‘å¸ƒ|Filtered 2D Contour-Based Reconstruction of 3D STL Model from CT-DICOM Images|åŸºäºCT-DICOMå›¾åƒçš„3D STLæ¨¡å‹è¿‡æ»¤2Dè½®å»“é‡å»º|K. Punnam Chandar, Y. Ravi Kumar|<https://arxiv.org/pdf/2601.14997v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Karhunen-LoÃ¨ve Expansion-Based Residual Anomaly Map for Resource-Efficient Glioma MRI Segmentation|åŸºäºKarhunen-LoÃ¨veå±•å¼€çš„æ®‹å·®å¼‚å¸¸å›¾ç”¨äºèµ„æºé«˜æ•ˆçš„èƒ¶è´¨ç˜¤MRIåˆ†å‰²|Anthony Hur|<https://arxiv.org/pdf/2601.11833v2>|åˆ†æå¤±è´¥|


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|DeepFedNAS: A Unified Framework for Principled, Hardware-Aware, and Predictor-Free Federated Neural Architecture Search|DeepFedNASï¼šä¸€ä¸ªåŸºäºåŸåˆ™ã€ç¡¬ä»¶æ„ŸçŸ¥ä¸”æ— é¢„æµ‹å™¨çš„è”é‚¦ç¥ç»æ¶æ„æœç´¢ç»Ÿä¸€æ¡†æ¶|Bostan Khan, Masoud Daneshtalab|<https://arxiv.org/pdf/2601.15127v1>|[ä»£ç ](https://github.com/bostankhan6/DeepFedNAS); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|ExPrIS: Knowledge-Level Expectations as Priors for Object Interpretation from Sensor Data|ExPrIS: çŸ¥è¯†çº§æœŸæœ›ä½œä¸ºä»ä¼ æ„Ÿå™¨æ•°æ®ä¸­è¿›è¡Œç‰©ä½“è§£é‡Šçš„å…ˆéªŒ|Marian Renz, Martin GÃ¼nther, Felix Igelbrink, Oscar Lima, Martin Atzmueller|<https://arxiv.org/pdf/2601.15025v1>|æ— |
|ğŸ†• å‘å¸ƒ|Federated Transformer-GNN for Privacy-Preserving Brain Tumor Localization with Modality-Level Explainability|ç”¨äºä¿æŠ¤éšç§çš„è„‘è‚¿ç˜¤å®šä½çš„è”é‚¦ Transformer-GNNï¼Œå…·æœ‰æ¨¡æ€çº§å¯è§£é‡Šæ€§|Andrea Protani, Riccardo Taiello, Marc Molina Van Den Bosch, Luigi Serio|<https://arxiv.org/pdf/2601.15042v1>|æ— |
|ğŸ†• å‘å¸ƒ|Mixture-of-Experts Models in Vision: Routing, Optimization, and Generalization|è§†è§‰ä¸­çš„æ··åˆä¸“å®¶æ¨¡å‹ï¼šè·¯ç”±ã€ä¼˜åŒ–ä¸æ³›åŒ–|Adam Rokah, Daniel Veress, Caleb Caulk, Sourav Sharan|<https://arxiv.org/pdf/2601.15021v1>|åˆ†æå¤±è´¥|


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### åˆ†å¸ƒå¤–æ³›åŒ– (Out-of-distribution Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Deep Leakage with Generative Flow Matching Denoiser|[ç¿»è¯‘å¤±è´¥] Deep Leakage with Generative Flow Matching Denoiser|Isaac Baglin, Xiatian Zhu, Simon Hadfield|<https://arxiv.org/pdf/2601.15049v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Unified Multi-Dataset Training for TBPS|[ç¿»è¯‘å¤±è´¥] Unified Multi-Dataset Training for TBPS|Nilanjana Chatterjee, Sidharatha Garg, A V Subramanyam, Brejesh Lall|<https://arxiv.org/pdf/2601.14978v1>|åˆ†æå¤±è´¥|


### å¯¹æŠ—é²æ£’æ€§ (Adversarial Robustness)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Transfer Learning from One Cancer to Another via Deep Learning Domain Adaptation|[ç¿»è¯‘å¤±è´¥] Transfer Learning from One Cancer to Another via Deep Learning Domain Adaptation|Justin Cheung, Samuel Savine, Calvin Nguyen, Lin Lu, Alhassan S. Yasin|<https://arxiv.org/pdf/2601.14678v1>|åˆ†æå¤±è´¥|


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SpooFL: Spoofing Federated Learning|[ç¿»è¯‘å¤±è´¥] SpooFL: Spoofing Federated Learning|Isaac Baglin, Xiatian Zhu, Simon Hadfield|<https://arxiv.org/pdf/2601.15055v1>|æ— |
|ğŸ“ æ›´æ–°|SUG-Occ: An Explicit Semantics and Uncertainty Guided Sparse Learning Framework for Real-Time 3D Occupancy Prediction|SUG-Occ: ä¸€ç§æ˜¾å¼è¯­ä¹‰å’Œä¸ç¡®å®šæ€§å¼•å¯¼çš„ç¨€ç–å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºå®æ—¶ 3D å æ®é¢„æµ‹|Hanlin Wu, Pengfei Lin, Ehsan Javanmardi, Nanren Bao, Bo Qian, Hao Si, Manabu Tsukada|<https://arxiv.org/pdf/2601.11396v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Learning Consistent Taxonomic Classification through Hierarchical Reasoning|é€šè¿‡å±‚æ¬¡æ¨ç†å­¦ä¹ ä¸€è‡´çš„åˆ†ç±»å­¦åˆ†ç±»|Zhenghong Li, Kecheng Zheng, Haibin Ling|<https://arxiv.org/pdf/2601.14610v1>|æ— |


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|RealX3D: A Physically-Degraded 3D Benchmark for Multi-view Visual Restoration and Reconstruction|RealX3D: ä¸€ä¸ªé¢å‘å¤šè§†è§’è§†è§‰æ¢å¤ä¸é‡å»ºçš„ç‰©ç†é€€åŒ–3DåŸºå‡†|Shuhong Liu, Chenyu Bao, Ziteng Cui, Yun Liu, Xuangeng Chu, Lin Gu, Marcos V. Conde, Ryo Umagami .etc.|<https://arxiv.org/pdf/2512.23437v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|ReinPath: A Multimodal Reinforcement Learning Approach for Pathology|ReinPath: ä¸€ç§ç”¨äºç—…ç†å­¦çš„å¤šæ¨¡æ€å¼ºåŒ–å­¦ä¹ æ–¹æ³•|Kangcheng Zhou, Jun Jiang, Qing Zhang, Shuang Zheng, Qingli Li, Shugong Xu|<https://arxiv.org/pdf/2601.14757v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning|Render-of-Thoughtï¼šå°†æ–‡æœ¬ Chain-of-Thought æ¸²æŸ“ä¸ºå›¾åƒä»¥è¿›è¡Œ Visual Latent Reasoning|Yifan Wang, Shiyu Li, Peiming Li, Xiaochen Yang, Yang Tang, Zheng Wei|<https://arxiv.org/pdf/2601.14750v1>|[ä»£ç ](https://github.com/TencentBAC/RoT); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|KBE-DME: Dynamic Multimodal Evaluation via Knowledge Enhanced Benchmark Evolution|KBE-DME: é€šè¿‡çŸ¥è¯†å¢å¼ºåŸºå‡†æ¼”è¿›çš„åŠ¨æ€å¤šæ¨¡æ€è¯„ä¼°|Junzhe Zhang, Huixuan Zhang, Xiaojun Wan|<https://arxiv.org/pdf/2510.21182v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Chain-of-Thought Compression Should Not Be Blind: V-Skip for Efficient Multimodal Reasoning via Dual-Path Anchoring|Chain-of-Thoughtå‹ç¼©ä¸åº”ç›²ç›®ï¼šé€šè¿‡åŒè·¯å¾„é”šå®šå®ç°é«˜æ•ˆå¤šæ¨¡æ€æ¨ç†çš„V-Skip|Dongxu Zhang, Yiding Sun, Cheng Tan, Wenbiao Yan, Ning Yang, Jihua Zhu, Haijun Zhang|<https://arxiv.org/pdf/2601.13879v2>|åˆ†æå¤±è´¥|


### è·¨æ¨¡æ€æ£€ç´¢ä¸åŒ¹é… (Cross-modal Retrieval & Matching)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SpatialMem: Unified 3D Memory with Metric Anchoring and Fast Retrieval|SpatialMem: å¸¦æœ‰åº¦é‡é”šå®šå’Œå¿«é€Ÿæ£€ç´¢çš„ç»Ÿä¸€ 3D Memory|Xinyi Zheng, Yunze Liu, Chi-Hao Wu, Fan Zhang, Hao Zheng, Wenqi Zhou, Walterio W. Mayol-Cuevas, Junxiao Shen|<https://arxiv.org/pdf/2601.14895v1>|æ— |


### è§†è§‰å†…å®¹æè¿° (Visual Content Description)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|DeepMoLM: Leveraging Visual and Geometric Structural Information for Molecule-Text Modeling|DeepMoLMï¼šåˆ©ç”¨è§†è§‰å’Œå‡ ä½•ç»“æ„ä¿¡æ¯è¿›è¡Œåˆ†å­-æ–‡æœ¬å»ºæ¨¡|Jing Lan, Hexiao Ding, Hongzhao Chen, Yufeng Jiang, Nga-Chun Ng, Gwing Kei Yip, Gerald W. Y. Cheng, Yunlin Mao .etc.|<https://arxiv.org/pdf/2601.14732v1>|[ä»£ç ](https://github.com/1anj/DeepMoLM.); åˆ†æå¤±è´¥|


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|BREPS: Bounding-Box Robustness Evaluation of Promptable Segmentation|BREPS: å¯æç¤ºåˆ†å‰²çš„è¾¹ç•Œæ¡†é²æ£’æ€§è¯„ä¼°|Andrey Moskalenko, Danil Kuznetsov, Irina Dudko, Anastasiia Iasakova, Nikita Boldyrev, Denis Shepelev, Andrei Spiridonov, Andrey Kuznetsov .etc.|<https://arxiv.org/pdf/2601.15123v1>|[ä»£ç ](https://github.com/emb-ai/BREPS.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Vision Models for Medical Imaging: A Hybrid Approach for PCOS Detection from Ultrasound Scans|ç”¨äºåŒ»å­¦æˆåƒçš„Vision Modelsï¼šä¸€ç§åŸºäºè¶…å£°æ‰«æçš„PCOSæ£€æµ‹æ··åˆæ–¹æ³•|Md Mahmudul Hoque, Md Mehedi Hassain, Muntakimur Rahaman, Md. Towhidul Islam, Shaista Rani, Md Sharif Mollah|<https://arxiv.org/pdf/2601.15119v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Benchmarking the Influence of Pre-training on Explanation Performance in MR Image Classification|è¯„ä¼°é¢„è®­ç»ƒå¯¹ MR å›¾åƒåˆ†ç±»ä¸­è§£é‡Šæ€§èƒ½çš„å½±å“|Marta Oliveira, Rick Wilming, Benedict Clark, CÃ©line Budding, Fabian Eitel, Kerstin Ritter, Stefan Haufe|<https://arxiv.org/pdf/2306.12150v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|AI-generated data contamination erodes pathological variability and diagnostic reliability|[ç¿»è¯‘å¤±è´¥] AI-generated data contamination erodes pathological variability and diagnostic reliability|Hongyu He, Shaowen Xiang, Ye Zhang, Yingtao Zhu, Jin Zhang, Hao Deng, Emily Alsentzer, Qingyu Chen .etc.|<https://arxiv.org/pdf/2601.12946v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|LocBAM: Advancing 3D Patch-Based Image Segmentation by Integrating Location Contex|LocBAMï¼šé€šè¿‡æ•´åˆä½ç½®ä¸Šä¸‹æ–‡æ¨è¿›åŸºäº3D Patchçš„å›¾åƒåˆ†å‰²|Donnate Hooft, Stefan M. Fischer, Cosmin Bercea, Jan C. Peeken, Julia A. Schnabel|<https://arxiv.org/pdf/2601.14802v1>|[ä»£ç ](https://github.com/compai-lab/2026-ISBI-hooft)|
|ğŸ†• å‘å¸ƒ|Using Multi-Instance Learning to Identify Unique Polyps in Colon Capsule Endoscopy Images|ä½¿ç”¨ Multi-Instance Learning è¯†åˆ«ç»“è‚ èƒ¶å›Šå†…é•œå›¾åƒä¸­çš„ç‹¬ç‰¹æ¯è‚‰|Puneet Sharma, Kristian DalsbÃ¸ Hindberg, Eibe Frank, Benedicte Schelde-Olesen, Ulrik Deding|<https://arxiv.org/pdf/2601.14771v1>|æ— |
|ğŸ†• å‘å¸ƒ|Does medical specialization of VLMs enhance discriminative power?: A comprehensive investigation through feature distribution analysis|VLMçš„åŒ»å­¦ä¸“ä¸šåŒ–æ˜¯å¦å¢å¼ºåˆ¤åˆ«èƒ½åŠ›ï¼Ÿï¼šé€šè¿‡ç‰¹å¾åˆ†å¸ƒåˆ†æçš„å…¨é¢è°ƒæŸ¥|Keita Takeda, Tomoya Sakai|<https://arxiv.org/pdf/2601.14774v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|LRR-Bench: Left, Right or Rotate? Vision-Language models Still Struggle With Spatial Understanding Tasks|LRR-Benchï¼šå·¦ã€å³è¿˜æ˜¯æ—‹è½¬ï¼ŸVision-Languageæ¨¡å‹ä»åœ¨ç©ºé—´ç†è§£ä»»åŠ¡ä¸­é¢ä¸´å›°éš¾|Fei Kong|<https://arxiv.org/pdf/2507.20174v2>|[ä»£ç ](https://github.com/kong13661/LRR-Bench.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Improving Artifact Robustness for CT Deep Learning Models Without Labeled Artifact Images via Domain Adaptation|é€šè¿‡åŸŸé€‚åº”æå‡CTæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨æ— æ ‡æ³¨ä¼ªå½±å›¾åƒä¸‹çš„ä¼ªå½±é²æ£’æ€§|Justin Cheung, Samuel Savine, Calvin Nguyen, Lin Lu, Alhassan S. Yasin|<https://arxiv.org/pdf/2510.06584v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Forest-Chat: Adapting Vision-Language Agents for Interactive Forest Change Analysis|Forest-Chatï¼šä½¿ Vision-Language Agents é€‚åº”äº¤äº’å¼æ£®æ—å˜åŒ–åˆ†æ|James Brock, Ce Zhang, Nantheera Anantrasirichai|<https://arxiv.org/pdf/2601.14637v1>|æ— |
|ğŸ†• å‘å¸ƒ|U-Harmony: Enhancing Joint Training for Segmentation Models with Universal Harmonization|U-Harmonyï¼šé€šè¿‡Universal Harmonizationå¢å¼ºåˆ†å‰²æ¨¡å‹çš„è”åˆè®­ç»ƒ|Weiwei Ma, Xiaobing Yu, Peijie Qiu, Jin Yang, Pan Xiao, Xiaoqi Zhao, Xiaofeng Liu, Tomo Miyazaki .etc.|<https://arxiv.org/pdf/2601.14605v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|From Volumes to Slices: Computationally Efficient Contrastive Learning for Sequential Abdominal CT Analysis|ä» Volumes åˆ° Slicesï¼šç”¨äº Sequential Abdominal CT Analysis çš„è®¡ç®—é«˜æ•ˆ Contrastive Learning|Po-Kai Chiu, Hung-Hsuan Chen|<https://arxiv.org/pdf/2601.14593v1>|[ä»£ç ](https://github.com/tkz05/2D-VoCo-CT-Classifier); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Scribble-Supervised Medical Image Segmentation with Dynamic Teacher Switching and Hierarchical Consistency|åŸºäºåŠ¨æ€æ•™å¸ˆåˆ‡æ¢å’Œå±‚æ¬¡ä¸€è‡´æ€§çš„æ¶‚é¸¦ç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²|Thanh-Huy Nguyen, Hoang-Loc Cao, Dat T. Chung, Mai-Anh Vu, Thanh-Minh Nguyen, Minh Le, Phat K. Huynh, Ulas Bagci|<https://arxiv.org/pdf/2601.14563v1>|æ— |


### å·¥ä¸šè§†è§‰æ£€æµ‹ (Industrial Visual Inspection)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Three-dimensional visualization of X-ray micro-CT with large-scale datasets: Efficiency and accuracy for real-time interaction|X-ray micro-CTåœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸‹çš„ä¸‰ç»´å¯è§†åŒ–ï¼šå®æ—¶äº¤äº’çš„æ•ˆç‡ä¸å‡†ç¡®æ€§|Yipeng Yin, Rao Yao, Qingying Li, Dazhong Wang, Hong Zhou, Zhijun Fang, Jianing Chen, Longjie Qian .etc.|<https://arxiv.org/pdf/2601.15098v1>|æ— |


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|GAIA: A Global, Multi-modal, Multi-scale Vision-Language Dataset for Remote Sensing Image Analysis|GAIA: ä¸€ä¸ªç”¨äºé¥æ„Ÿå›¾åƒåˆ†æçš„å…¨çƒã€å¤šæ¨¡æ€ã€å¤šå°ºåº¦ Vision-Language æ•°æ®é›†|Angelos Zavras, Dimitrios Michail, Xiao Xiang Zhu, BegÃ¼m Demir, Ioannis Papoutsis|<https://arxiv.org/pdf/2502.09598v2>|[ä»£ç ](https://github.com/Orion-AI-Lab/GAIA.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|UniRoute: Unified Routing Mixture-of-Experts for Modality-Adaptive Remote Sensing Change Detection|UniRouteï¼šç”¨äºæ¨¡æ€è‡ªé€‚åº”é¥æ„Ÿå˜åŒ–æ£€æµ‹çš„ç»Ÿä¸€è·¯ç”±æ··åˆä¸“å®¶|Qingling Shu, Sibao Chen, Wei Lu, Zhihui You, Chengzhuang Liu|<https://arxiv.org/pdf/2601.14797v1>|åˆ†æå¤±è´¥|


### æ™ºèƒ½äº¤é€šè§†è§‰ (Intelligent Transportation Vision)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|AutoDriDM: An Explainable Benchmark for Decision-Making of Vision-Language Models in Autonomous Driving|AutoDriDMï¼šä¸€ä¸ªç”¨äºè‡ªåŠ¨é©¾é©¶ä¸­ Vision-Language Models å†³ç­–çš„å¯è§£é‡ŠåŸºå‡†|Zecong Tang, Zixu Wang, Yifei Wang, Weitong Lian, Tianjian Gao, Haoran Li, Tengju Ru, Lingyi Meng .etc.|<https://arxiv.org/pdf/2601.14702v1>|åˆ†æå¤±è´¥|


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|RegFreeNet: A Registration-Free Network for CBCT-based 3D Dental Implant Planning|RegFreeNet: ä¸€ç§ç”¨äºåŸºäºCBCTçš„3Dç‰™ç§‘ç§æ¤è§„åˆ’çš„å…é…å‡†ç½‘ç»œ|Xinquan Yang, Xuguang Li, Mianjie Zheng, Xuefen Liu, Kun Tang, Kian Ming Lim, He Meng, Jianfeng Ren .etc.|<https://arxiv.org/pdf/2601.14703v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Geo-Registration of Terrestrial LiDAR Point Clouds with Satellite Images without GNSS|æ— GNSSæ¡ä»¶ä¸‹åœ°é¢LiDARç‚¹äº‘ä¸å«æ˜Ÿå›¾åƒçš„åœ°ç†é…å‡†|Xinyu Wang, Muhammad Ibrahim, Haitian Wang, Atif Mansoor, Xiuping Jia, Ajmal Mian|<https://arxiv.org/pdf/2507.05999v4>|æ— |
|ğŸ“ æ›´æ–°|BirdsEye-RU: A Dataset For Detecting Faces from Overhead Images|BirdsEye-RU: ä¸€ä¸ªç”¨äºä»ä¿¯è§†å›¾åƒä¸­æ£€æµ‹äººè„¸çš„æ•°æ®é›†|Md. Ahanaf Arif Khan, Ariful Islam, Sangeeta Biswas, Md. Iqbal Aziz Khan, Subrata Pramanik, Sanjoy Kumar Chakravarty, Bimal Kumar Pramanik|<https://arxiv.org/pdf/2601.12533v2>|æ— |

