## [UPDATED!] **2026-01-22** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders|åˆ©ç”¨è¡¨ç¤ºè‡ªç¼–ç å™¨æ‰©å±• Text-to-Image Diffusion Transformers|Shengbang Tong, Boyang Zheng, Ziteng Wang, Bingda Tang, Nanye Ma, Ellis Brown, Jihan Yang, Rob Fergus .etc.|<https://arxiv.org/pdf/2601.16208v1>|æ— |
|ğŸ“ æ›´æ–°|Vision-as-Inverse-Graphics Agent via Interleaved Multimodal Reasoning|åŸºäºäº¤é”™å¤šæ¨¡æ€æ¨ç†çš„Vision-as-Inverse-Graphics Agent|Shaofeng Yin, Jiaxin Ge, Zora Zhiruo Wang, Xiuyu Li, Michael J. Black, Trevor Darrell, Angjoo Kanazawa, Haiwen Feng|<https://arxiv.org/pdf/2601.11109v2>|æ— |


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|DSFedMed: Dual-Scale Federated Medical Image Segmentation via Mutual Distillation Between Foundation and Lightweight Models|DSFedMed: é€šè¿‡Foundationæ¨¡å‹ä¸è½»é‡çº§æ¨¡å‹ä¹‹é—´çš„ç›¸äº’è’¸é¦å®ç°åŒå°ºåº¦è”é‚¦åŒ»å­¦å›¾åƒåˆ†å‰²|Hanwen Zhang, Qiaojin Shen, Yuxi Liu, Yuesheng Zhu, Guibo Luo|<https://arxiv.org/pdf/2601.16073v1>|æ— |
|ğŸ“ æ›´æ–°|OccLE: Label-Efficient 3D Semantic Occupancy Prediction|OccLE: æ ‡ç­¾é«˜æ•ˆçš„ 3D è¯­ä¹‰å æ®é¢„æµ‹|Naiyu Fang, Zheyuan Zhou, Fayao Liu, Xulei Yang, Jiacheng Wei, Lemiao Qiu, Hongsheng Li, Guosheng Lin|<https://arxiv.org/pdf/2505.20617v4>|[ä»£ç ](https://github.com/NerdFNY/OccLE)|
|ğŸ†• å‘å¸ƒ|Opening the Black Box: Preliminary Insights into Affective Modeling in Multimodal Foundation Models|æ‰“å¼€é»‘ç›’ï¼šå…³äºå¤šæ¨¡æ€åŸºç¡€æ¨¡å‹ä¸­æƒ…æ„Ÿå»ºæ¨¡çš„åˆæ­¥è§è§£|Zhen Zhang, Runhao Zeng, Sicheng Zhao, Xiping Hu|<https://arxiv.org/pdf/2601.15906v1>|æ— |
|ğŸ†• å‘å¸ƒ|Understanding the Transfer Limits of Vision Foundation Models|ç†è§£ Vision Foundation Models çš„è¿ç§»æé™|Shiqi Huang, Yipei Wang, Natasha Thorley, Alexander Ng, Shaheer Saeed, Mark Emberton, Shonit Punwani, Veeru Kasivisvanathan .etc.|<https://arxiv.org/pdf/2601.15888v1>|æ— |
|ğŸ†• å‘å¸ƒ|Atlas-Assisted Segment Anything Model for Fetal Brain MRI (FeTal-SAM)|[ç¿»è¯‘å¤±è´¥] Atlas-Assisted Segment Anything Model for Fetal Brain MRI (FeTal-SAM)|Qi Zeng, Weide Liu, Bo Li, Ryne Didier, P. Ellen Grant, Davood Karimi|<https://arxiv.org/pdf/2601.15759v1>|æ— |
|ğŸ“ æ›´æ–°|Boosting Generative Image Modeling via Joint Image-Feature Synthesis|é€šè¿‡è”åˆå›¾åƒ-ç‰¹å¾åˆæˆæå‡ç”Ÿæˆå¼å›¾åƒå»ºæ¨¡|Theodoros Kouzelis, Efstathios Karypidis, Ioannis Kakogeorgiou, Spyros Gidaris, Nikos Komodakis|<https://arxiv.org/pdf/2504.16064v3>|æ— |
|ğŸ†• å‘å¸ƒ|Sub-Region-Aware Modality Fusion and Adaptive Prompting for Multi-Modal Brain Tumor Segmentation|[ç¿»è¯‘å¤±è´¥] Sub-Region-Aware Modality Fusion and Adaptive Prompting for Multi-Modal Brain Tumor Segmentation|Shadi Alijani, Fereshteh Aghaee Meibodi, Homayoun Najjaran|<https://arxiv.org/pdf/2601.15734v1>|æ— |
|ğŸ“ æ›´æ–°|Skywork UniPic 2.0: Building Kontext Model with Online RL for Unified Multimodal Model|Skywork UniPic 2.0ï¼šåˆ©ç”¨ Online RL æ„å»º Kontext Model ä»¥å®ç°ç»Ÿä¸€ Multimodal Model|Hongyang Wei, Baixin Xu, Hongbo Liu, Size Wu, Jie Liu, Yi Peng, Peiyu Wang, Zexiang Liu .etc.|<https://arxiv.org/pdf/2509.04548v2>|æ— |
|ğŸ“ æ›´æ–°|Efficient Multimodal Large Language Models: A Survey|é«˜æ•ˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼šç»¼è¿°|Yizhang Jin, Jian Li, Yexin Liu, Tianjun Gu, Kai Wu, Zhengkai Jiang, Muyang He, Bo Zhao .etc.|<https://arxiv.org/pdf/2405.10739v3>|[ä»£ç ](https://github.com/lijiannuist/Efficient-Multimodal-LLMs-Survey.)|


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|The Percept-V Challenge: Can Multimodal LLMs Crack Simple Perception Problems?|[ç¿»è¯‘å¤±è´¥] The Percept-V Challenge: Can Multimodal LLMs Crack Simple Perception Problems?|Samrajnee Ghosh, Naman Agarwal, Hemanshu Garg, Chinmay Mittal, Mausam, Parag Singla|<https://arxiv.org/pdf/2508.21143v3>|æ— |
|ğŸ“ æ›´æ–°|Multi-event Video-Text Retrieval|[ç¿»è¯‘å¤±è´¥] Multi-event Video-Text Retrieval|Gengyuan Zhang, Jisen Ren, Jindong Gu, Volker Tresp|<https://arxiv.org/pdf/2308.11551v3>|[ä»£ç ](https://github.com/gengyuanmax/MeVTR.)|


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### ç›®æ ‡æ£€æµ‹ä¸å®šä½ (Object Detection & Localization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Is this chart lying to me? Automating the detection of misleading visualizations|è¿™å¼ å›¾è¡¨åœ¨æ¬ºéª—æˆ‘å—ï¼Ÿè¯¯å¯¼æ€§å¯è§†åŒ–çš„è‡ªåŠ¨æ£€æµ‹|Jonathan Tonglet, Jan Zimny, Tinne Tuytelaars, Iryna Gurevych|<https://arxiv.org/pdf/2508.21675v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection|YOLO é‡è§ Mixture-of-Expertsï¼šç”¨äºé²æ£’ç›®æ ‡æ£€æµ‹çš„è‡ªé€‚åº”ä¸“å®¶è·¯ç”±|Ori Meiraz, Sharon Shalev, Avishai Weizman|<https://arxiv.org/pdf/2511.13344v4>|æ— |
|ğŸ†• å‘å¸ƒ|Enhanced LULC Segmentation via Lightweight Model Refinements on ALOS-2 SAR Data|é€šè¿‡ ALOS-2 SAR æ•°æ®ä¸Šçš„è½»é‡çº§æ¨¡å‹æ”¹è¿›å¢å¼º LULC åˆ†å‰²|Ali Caglayan, Nevrez Imamoglu, Toru Kouyama|<https://arxiv.org/pdf/2601.15705v1>|æ— |
|ğŸ“ æ›´æ–°|Real-Time Object Detection Meets DINOv3|å®æ—¶å®æ—¶ç›®æ ‡æ£€æµ‹é‡ä¸Š DINOv3|Shihua Huang, Yongjie Hou, Longfei Liu, Xuanlong Yu, Xi Shen|<https://arxiv.org/pdf/2509.20787v3>|[ä»£ç ](https://github.com/Intellindust-AI-Lab/DEIMv2)|


### å›¾åƒåˆ†ç±»ä¸è¯†åˆ« (Image Classification & Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Clustering-Guided Spatial-Spectral Mamba for Hyperspectral Image Classification|[ç¿»è¯‘å¤±è´¥] Clustering-Guided Spatial-Spectral Mamba for Hyperspectral Image Classification|Zack Dewis, Yimin Zhu, Zhengsen Xu, Mabel Heffring, Saeid Taleghanidoozdoozan, Quinn Ledingham, Lincoln Linlin Xu|<https://arxiv.org/pdf/2601.16098v1>|æ— |
|ğŸ†• å‘å¸ƒ|RadJEPA: Radiology Encoder for Chest X-Rays via Joint Embedding Predictive Architecture|RadJEPAï¼šåŸºäºJoint Embedding Predictive Architectureçš„èƒ¸éƒ¨Xå…‰æ”¾å°„å­¦ç¼–ç å™¨|Anas Anwarul Haq Khan, Mariam Husain, Kshitij Jadhav|<https://arxiv.org/pdf/2601.15891v1>|æ— |
|ğŸ†• å‘å¸ƒ|White-Box mHC: Electromagnetic Spectrum-Aware and Interpretable Stream Interactions for Hyperspectral Image Classification|White-Box mHCï¼šç”µç£è°±æ„ŸçŸ¥ä¸”å¯è§£é‡Šçš„æµäº¤äº’ç”¨äºé«˜å…‰è°±å›¾åƒåˆ†ç±»|Yimin Zhu, Lincoln Linlin Xu, Zhengsen Xu, Zack Dewis, Mabel Heffring, Saeid Taleghanidoozdoozan, Motasem Alkayid, Quinn Ledingham .etc.|<https://arxiv.org/pdf/2601.15757v1>|æ— |


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|A Multi-View Pipeline and Benchmark Dataset for 3D Hand Pose Estimation in Surgery|ç”¨äºæ‰‹æœ¯ä¸­3Dæ‰‹éƒ¨å§¿æ€ä¼°è®¡çš„å¤šè§†è§’Pipelineå’ŒåŸºå‡†æ•°æ®é›†|Valery Fischer, Alan Magdaleno, Anna-Katharina Calek, Nicola Cavalcanti, Nathan Hoffman, Christoph Germann, Joschua WÃ¼thrich, Max KrÃ¤henmann .etc.|<https://arxiv.org/pdf/2601.15918v1>|æ— |
|ğŸ†• å‘å¸ƒ|Out-of-Distribution Detection Based on Total Variation Estimation|åŸºäº Total Variation Estimation çš„ Out-of-Distribution æ£€æµ‹|Dabiao Ma, Zhiba Su, Jian Yang, Haojun Fei|<https://arxiv.org/pdf/2601.15867v1>|æ— |
|ğŸ“ æ›´æ–°|Multi-View Projection for Unsupervised Domain Adaptation in 3D Semantic Segmentation|ç”¨äº3Dè¯­ä¹‰åˆ†å‰²æ— ç›‘ç£åŸŸé€‚åº”çš„å¤šè§†å›¾æŠ•å½±|Andrew Caunes, Thierry Chateau, Vincent Fremont|<https://arxiv.org/pdf/2505.15545v3>|æ— |
|ğŸ†• å‘å¸ƒ|Breaking the Resolution Barrier: Arbitrary-resolution Deep Image Steganography Framework|[ç¿»è¯‘å¤±è´¥] Breaking the Resolution Barrier: Arbitrary-resolution Deep Image Steganography Framework|Xinjue Hu, Chi Wang, Boyu Wang, Xiang Zhang, Zhenshan Tan, Zhangjie Fu|<https://arxiv.org/pdf/2601.15739v1>|æ— |
|ğŸ“ æ›´æ–°|DF-LLaVA: Unlocking MLLM's potential for Synthetic Image Detection via Prompt-Guided Knowledge Injection|DF-LLaVA: é€šè¿‡ Prompt-Guided Knowledge Injection é‡Šæ”¾ MLLM åœ¨ Synthetic Image Detection ä¸­çš„æ½œåŠ›|Zhuokang Shen, Kaisen Zhang, Bohan Jia, Heming Jia, Yuan Fang, Zhou Yu, Shaohui Lin|<https://arxiv.org/pdf/2509.14957v2>|[ä»£ç ](https://github.com/Eliot-Shen/DF-LLaVA.)|
|ğŸ†• å‘å¸ƒ|Performance-guided Reinforced Active Learning for Object Detection|[ç¿»è¯‘å¤±è´¥] Performance-guided Reinforced Active Learning for Object Detection|Zhixuan Liang, Xingyu Zeng, Rui Zhao, Ping Luo|<https://arxiv.org/pdf/2601.15688v1>|æ— |


### è¯­ä¹‰/å®ä¾‹åˆ†å‰² (Semantic/Instance Segmentation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Divide, Conquer and Unite: Hierarchical Style-Recalibrated Prototype Alignment for Federated Medical Segmentation|åˆ†æ²»ä¸ç»Ÿä¸€ï¼šç”¨äºè”é‚¦åŒ»å­¦åˆ†å‰²çš„åˆ†å±‚é£æ ¼é‡æ ¡å‡†åŸå‹å¯¹é½|Xingyue Zhao, Wenke Huang, Xingguang Wang, Haoyu Zhao, Linghao Zhuang, Anwen Jiang, Guancheng Wan, Mang Ye|<https://arxiv.org/pdf/2511.10945v2>|æ— |


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|CamPilot: Improving Camera Control in Video Diffusion Model with Efficient Camera Reward Feedback|CamPilotï¼šé€šè¿‡é«˜æ•ˆCamera Reward Feedbackæ”¹è¿›Video Diffusion Modelä¸­çš„Camera Control|Wenhang Ge, Guibao Shen, Jiawei Feng, Luozhou Wang, Hao Lu, Xingye Tian, Xin Tao, Ying-Cong Chen|<https://arxiv.org/pdf/2601.16214v1>|[ä»£ç ](https://a-bigbao.github.io/CamPilot)|
|ğŸ†• å‘å¸ƒ|Learning to Watermark in the Latent Space of Generative Models|[ç¿»è¯‘å¤±è´¥] Learning to Watermark in the Latent Space of Generative Models|Sylvestre-Alvise Rebuffi, Tuan Tran, Valeriu Lacatusu, Pierre Fernandez, TomÃ¡Å¡ SouÄek, Nikola JovanoviÄ‡, Tom Sander, Hady Elsahar .etc.|<https://arxiv.org/pdf/2601.16140v1>|æ— |
|ğŸ“ æ›´æ–°|BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries|BayesianVLA: é€šè¿‡Latent Action Querieså¯¹Vision Language Action Modelsè¿›è¡ŒBayesianåˆ†è§£|Shijie Lian, Bin Yu, Xiaopeng Lin, Laurence T. Yang, Zhaolong Shen, Changti Wu, Yuzhuo Miao, Cong Huang .etc.|<https://arxiv.org/pdf/2601.15197v2>|æ— |
|ğŸ“ æ›´æ–°|Yesnt: Are Diffusion Relighting Models Ready for Capture Stage Compositing? A Hybrid Alternative to Bridge the Gap|Yesnt: Diffusion Relighting æ¨¡å‹å·²å‡†å¤‡å¥½ç”¨äºæ‹æ‘„é˜¶æ®µåˆæˆäº†å—ï¼Ÿä¸€ç§å¼¥åˆå·®è·çš„æ··åˆæ›¿ä»£æ–¹æ¡ˆ|Elisabeth JÃ¼ttner, Janelle Pfeifer, Leona Krath, Stefan Korfhage, Hannah DrÃ¶ge, Matthias B. Hullin, Markus Plack|<https://arxiv.org/pdf/2510.23494v2>|æ— |
|ğŸ†• å‘å¸ƒ|HyperAlign: Hypernetwork for Efficient Test-Time Alignment of Diffusion Models|HyperAlign: ç”¨äº Diffusion Models é«˜æ•ˆ Test-Time Alignment çš„ Hypernetwork|Xin Xie, Jiaxian Guo, Dong Gong|<https://arxiv.org/pdf/2601.15968v1>|æ— |
|ğŸ†• å‘å¸ƒ|Diffusion Model-Based Data Augmentation for Enhanced Neuron Segmentation|åŸºäºDiffusion Modelçš„æ•°æ®å¢å¼ºä»¥å¢å¼ºNeuron Segmentation|Liuyun Jiang, Yanchao Zhang, Jinyue Guo, Yizhuo Lu, Ruining Zhou, Hua Han|<https://arxiv.org/pdf/2601.15779v1>|[ä»£ç ](https://github.com/HeadLiuYun/NeuroDiff.)|
|ğŸ“ æ›´æ–°|GO-MLVTON: Garment Occlusion-Aware Multi-Layer Virtual Try-On with Diffusion Models|GO-MLVTONï¼šåŸºäº Diffusion Models çš„æœè£…é®æŒ¡æ„ŸçŸ¥å¤šå±‚è™šæ‹Ÿè¯•ç©¿|Yang Yu, Yunze Deng, Yige Zhang, Yanjie Xiao, Youkun Ou, Wenhao Hu, Mingchao Li, Bin Feng .etc.|<https://arxiv.org/pdf/2601.13524v2>|[ä»£ç ](https://upyuyang.github.io/go-mlvton)|
|ğŸ“ æ›´æ–°|Simulating Dual-Pixel Images From Ray Tracing For Depth Estimation|ä»å…‰çº¿è¿½è¸ªæ¨¡æ‹ŸåŒåƒç´ å›¾åƒç”¨äºæ·±åº¦ä¼°è®¡|Fengchen He, Dayang Zhao, Hao Xu, Tingwei Quan, Shaoqun Zeng|<https://arxiv.org/pdf/2503.11213v2>|[ä»£ç ](https://github.com/LinYark/Sdirt)|
|ğŸ†• å‘å¸ƒ|VIOLA: Towards Video In-Context Learning with Minimal Annotations|VIOLA: åŸºäºæœ€å°‘æ ‡æ³¨çš„è§†é¢‘ä¸Šä¸‹æ–‡å­¦ä¹ |Ryo Fujii, Hideo Saito, Ryo Hachiuma|<https://arxiv.org/pdf/2601.15549v1>|æ— |


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|PyraTok: Language-Aligned Pyramidal Tokenizer for Video Understanding and Generation|PyraTok: ç”¨äºè§†é¢‘ç†è§£å’Œç”Ÿæˆçš„è¯­è¨€å¯¹é½é‡‘å­—å¡” Tokenizer|Onkar Susladkar, Tushar Prakash, Adheesh Juvekar, Kiet A. Nguyen, Dong-Hwan Jang, Inderjit S Dhillon, Ismini Lourentzou|<https://arxiv.org/pdf/2601.16210v1>|æ— |
|ğŸ†• å‘å¸ƒ|360Anything: Geometry-Free Lifting of Images and Videos to 360Â°|360Anything: å›¾åƒå’Œè§†é¢‘åˆ° 360Â° çš„æ— å‡ ä½•æå‡|Ziyi Wu, Daniel Watson, Andrea Tagliasacchi, David J. Fleet, Marcus A. Brubaker, Saurabh Saxena|<https://arxiv.org/pdf/2601.16192v1>|[ä»£ç ](https://360anything.github.io/.)|
|ğŸ†• å‘å¸ƒ|ActionMesh: Animated 3D Mesh Generation with Temporal 3D Diffusion|ActionMesh: åŸºäºTemporal 3D Diffusionçš„åŠ¨ç”»3D Meshç”Ÿæˆ|Remy Sabathier, David Novotny, Niloy J. Mitra, Tom Monnier|<https://arxiv.org/pdf/2601.16148v1>|æ— |
|ğŸ“ æ›´æ–°|CGS-GAN: 3D Consistent Gaussian Splatting GANs for High Resolution Human Head Synthesis|[ç¿»è¯‘å¤±è´¥] CGS-GAN: 3D Consistent Gaussian Splatting GANs for High Resolution Human Head Synthesis|Florian Barthel, Wieland Morgenstern, Paul Hinzer, Anna Hilsmann, Peter Eisert|<https://arxiv.org/pdf/2505.17590v3>|[ä»£ç ](https://fraunhoferhhi.github.io/cgs-gan)|
|ğŸ†• å‘å¸ƒ|DextER: Language-driven Dexterous Grasp Generation with Embodied Reasoning|DextER: åŸºäºå…·èº«æ¨ç†çš„è¯­è¨€é©±åŠ¨çµå·§æŠ“å–ç”Ÿæˆ|Junha Lee, Eunha Park, Minsu Cho|<https://arxiv.org/pdf/2601.16046v1>|æ— |
|ğŸ†• å‘å¸ƒ|PAINT: Pathology-Aware Integrated Next-Scale Transformation for Virtual Immunohistochemistry|PAINTï¼šç”¨äºè™šæ‹Ÿå…ç–«ç»„åŒ–çš„Pathology-Aware Integrated Next-Scale Transformation|Rongze Ma, Mengkang Lu, Zhenyu Xiang, Yongsheng Pan, Yicheng Wu, Qingjie Zeng, Yong Xia|<https://arxiv.org/pdf/2601.16024v1>|æ— |
|ğŸ†• å‘å¸ƒ|PhysicsMind: Sim and Real Mechanics Benchmarking for Physical Reasoning and Prediction in Foundational VLMs and World Models|PhysicsMind: ç”¨äºåŸºç¡€ VLM å’Œä¸–ç•Œæ¨¡å‹ä¸­ç‰©ç†æ¨ç†ä¸é¢„æµ‹çš„ä»¿çœŸä¸çœŸå®åŠ›å­¦åŸºå‡†æµ‹è¯•|Chak-Wing Mak, Guanyu Zhu, Boyi Zhang, Hongji Li, Xiaowei Chi, Kevin Zhang, Yichen Wu, Yangfan He .etc.|<https://arxiv.org/pdf/2601.16007v1>|æ— |
|ğŸ†• å‘å¸ƒ|PF-D2M: A Pose-free Diffusion Model for Universal Dance-to-Music Generation|[ç¿»è¯‘å¤±è´¥] PF-D2M: A Pose-free Diffusion Model for Universal Dance-to-Music Generation|Jaekwon Im, Natalia Polouliakh, Taketo Akama|<https://arxiv.org/pdf/2601.15872v1>|æ— |
|ğŸ†• å‘å¸ƒ|Uncertainty-guided Generation of Dark-field Radiographs|Uncertainty-guided æš—åœº X å°„çº¿å›¾åƒç”Ÿæˆ|Lina Felsner, Henriette Bast, Tina Dorosti, Florian Schaff, Franz Pfeiffer, Daniela Pfeiffer, Julia Schnabel|<https://arxiv.org/pdf/2601.15859v1>|æ— |
|ğŸ†• å‘å¸ƒ|LL-GaussianMap: Zero-shot Low-Light Image Enhancement via 2D Gaussian Splatting Guided Gain Maps|LL-GaussianMap: é€šè¿‡ 2D Gaussian Splatting å¼•å¯¼çš„å¢ç›Šå›¾å®ç° Zero-shot ä½å…‰ç…§å›¾åƒå¢å¼º|Yuhan Chen, Ying Fang, Guofa Li, Wenxuan Yu, Yicui Shi, Jingrui Zhang, Kefei Qian, Wenbo Chu .etc.|<https://arxiv.org/pdf/2601.15766v1>|æ— |
|ğŸ“ æ›´æ–°|A Segmentation-driven Editing Method for Bolt Defect Augmentation and Detection|ä¸€ç§åŸºäºSegmentationçš„Bolt Defectå¢å¼ºä¸æ£€æµ‹Editingæ–¹æ³•|Yangjie Xiao, Ke Zhang, Jiacun Wang, Xin Sheng, Yurong Guo, Meijuan Chen, Zehua Ren, Zhaoye Zheng .etc.|<https://arxiv.org/pdf/2508.10509v3>|[ä»£ç ](https://github.com/Jay-xyj/SBDE.)|
|ğŸ“ æ›´æ–°|MultiHuman-Testbench: Benchmarking Image Generation for Multiple Humans|MultiHuman-Testbench: å¤šäººå›¾åƒç”Ÿæˆçš„åŸºå‡†æµ‹è¯•|Shubhankar Borse, Seokeon Choi, Sunghyun Park, Jeongho Kim, Shreya Kadambi, Risheek Garrepalli, Sungrack Yun, Munawar Hayat .etc.|<https://arxiv.org/pdf/2506.20879v4>|[ä»£ç ](https://github.com/Qualcomm-AI-research/MultiHuman-Testbench.)|
|ğŸ†• å‘å¸ƒ|Beyond Visual Safety: Jailbreaking Multimodal Large Language Models for Harmful Image Generation via Semantic-Agnostic Inputs|è¶…è¶Šè§†è§‰å®‰å…¨æ€§ï¼šé€šè¿‡è¯­ä¹‰æ— å…³è¾“å…¥è¶Šç‹±å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä»¥ç”Ÿæˆæœ‰å®³å›¾åƒ|Mingyu Yu, Lana Liu, Zhehao Zhao, Wei Wang, Sujuan Qin|<https://arxiv.org/pdf/2601.15698v1>|æ— |
|ğŸ†• å‘å¸ƒ|Skywork UniPic 3.0: Unified Multi-Image Composition via Sequence Modeling|Skywork UniPic 3.0ï¼šé€šè¿‡åºåˆ—å»ºæ¨¡å®ç°ç»Ÿä¸€çš„å¤šå›¾åƒåˆæˆ|Hongyang Wei, Hongbo Liu, Zidong Wang, Yi Peng, Baixin Xu, Size Wu, Xuying Zhang, Xianglong He .etc.|<https://arxiv.org/pdf/2601.15664v1>|æ— |
|ğŸ“ æ›´æ–°|SURE-Med: Systematic Uncertainty Reduction for Enhanced Reliability in Medical Report Generation|SURE-Med: åŒ»å­¦æŠ¥å‘Šç”Ÿæˆä¸­ç”¨äºå¢å¼ºå¯é æ€§çš„ç³»ç»Ÿæ€§ä¸ç¡®å®šæ€§é™ä½|Yuhang Gu, Xingyu Hu, Yuyu Fan, Xulin Yan, Longhuan Xu, Peng peng|<https://arxiv.org/pdf/2508.01693v2>|æ— |
|ğŸ†• å‘å¸ƒ|Explainable Deepfake Detection with RL Enhanced Self-Blended Images|åŸºäºRLå¢å¼ºè‡ªæ··åˆå›¾åƒçš„å¯è§£é‡ŠDeepfakeæ£€æµ‹|Ning Jiang, Dingheng Zeng, Yanhong Liu, Haiyang Yi, Shijie Yu, Minghe Weng, Haifeng Shen, Ying Li|<https://arxiv.org/pdf/2601.15624v1>|[ä»£ç ](https://github.com/deon1219/rlsbi.)|
|ğŸ†• å‘å¸ƒ|Relative Classification Accuracy: A Calibrated Metric for Identity Consistency in Fine-Grained K-pop Face Generation|ç›¸å¯¹åˆ†ç±»å‡†ç¡®ç‡ï¼šç»†ç²’åº¦ K-pop äººè„¸ç”Ÿæˆä¸­èº«ä»½ä¸€è‡´æ€§çš„æ ¡å‡†æŒ‡æ ‡|Sylvey Lin, Eranki Vasistha|<https://arxiv.org/pdf/2601.15560v1>|æ— |


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Rethinking Composed Image Retrieval Evaluation: A Fine-Grained Benchmark from Image Editing|é‡æ–°æ€è€ƒç»„åˆå›¾åƒæ£€ç´¢è¯„ä¼°ï¼šæ¥è‡ªå›¾åƒç¼–è¾‘çš„ç»†ç²’åº¦åŸºå‡†|Tingyu Song, Yanzhao Zhang, Mingxin Li, Zhuoning Guo, Dingkun Long, Pengjun Xie, Siyue Zhang, Yilun Zhao .etc.|<https://arxiv.org/pdf/2601.16125v1>|æ— |
|ğŸ“ æ›´æ–°|StyMam: A Mamba-Based Generator for Artistic Style Transfer|StyMam: åŸºäº Mamba çš„è‰ºæœ¯é£æ ¼è¿ç§»ç”Ÿæˆå™¨|Zhou Hong, Rongsheng Hu, Yicheng Di, Xiaolong Xu, Ning Dong, Yihua Shao, Run Ling, Yun Wang .etc.|<https://arxiv.org/pdf/2601.12954v2>|æ— |


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|No Mesh, No Problem: Estimating Coral Volume and Surface from Sparse Multi-View Images|No Mesh, No Problem: ä»ç¨€ç–å¤šè§†è§’å›¾åƒä¼°è®¡çŠç‘šä½“ç§¯å’Œè¡¨é¢|Diego Eustachio Farchione, Ramzi Idoughi, Peter Wonka|<https://arxiv.org/pdf/2509.11164v3>|æ— |
|ğŸ“ æ›´æ–°|TeleMem: Building Long-Term and Multimodal Memory for Agentic AI|TeleMem: ä¸º Agentic AI æ„å»ºé•¿æœŸå¤šæ¨¡æ€è®°å¿†|Chunliang Chen, Ming Guan, Xiao Lin, Jiaxu Li, Luxi Lin, Qiyi Wang, Xiangyu Chen, Jixiang Luo .etc.|<https://arxiv.org/pdf/2601.06037v4>|æ— |
|ğŸ†• å‘å¸ƒ|Event-VStream: Event-Driven Real-Time Understanding for Long Video Streams|Event-VStream: é¢å‘é•¿è§†é¢‘æµçš„ Event-Driven å®æ—¶ç†è§£|Zhenghui Guo, Yuanbin Man, Junyuan Sheng, Bowen Lin, Ahmed Ahmed, Bo Jiang, Boyuan Zhang, Miao Yin .etc.|<https://arxiv.org/pdf/2601.15655v1>|æ— |


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|CropCraft: Complete Structural Characterization of Crop Plants From Images|CropCraft: ä»å›¾åƒè¿›è¡Œä½œç‰©çš„å®Œæ•´ç»“æ„è¡¨å¾|Albert J. Zhai, Xinlei Wang, Kaiyuan Li, Zhao Jiang, Junxiong Zhou, Sheng Wang, Zhenong Jin, Kaiyu Guan .etc.|<https://arxiv.org/pdf/2411.09693v2>|æ— |
|ğŸ“ æ›´æ–°|Auditing and Mitigating Bias in Gender Classification Algorithms: A Data-Centric Approach|å®¡è®¡å’Œç¼“è§£æ€§åˆ«åˆ†ç±»ç®—æ³•ä¸­çš„åè§ï¼šä¸€ç§ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„æ–¹æ³•|Tadesse K Bahiru, Natnael Tilahun Sinshaw, Teshager Hailemariam Moges, Dheeraj Kumar Singh|<https://arxiv.org/pdf/2510.17873v2>|æ— |
|ğŸ†• å‘å¸ƒ|EVolSplat4D: Efficient Volume-based Gaussian Splatting for 4D Urban Scene Synthesis|EVolSplat4D: ç”¨äº4DåŸå¸‚åœºæ™¯åˆæˆçš„åŸºäºä½“é‡çš„é«˜æ•ˆé«˜æ–¯æ³¼æº…|Sheng Miao, Sijin Li, Pan Wang, Dongfeng Bai, Bingbing Liu, Yue Wang, Andreas Geiger, Yiyi Liao|<https://arxiv.org/pdf/2601.15951v1>|æ— |
|ğŸ“ æ›´æ–°|Rasterizing Wireless Radiance Field via Deformable 2D Gaussian Splatting|é€šè¿‡å¯å˜å½¢ 2D Gaussian Splatting å…‰æ …åŒ–æ— çº¿è¾å°„åœº|Mufan Liu, Cixiao Zhang, Qi Yang, Yujie Cao, Yiling Xu, Yin Xu, Shu Sun, Mingzeng Dai .etc.|<https://arxiv.org/pdf/2506.12787v3>|[ä»£ç ](https://evan-sudo.github.io/swiftwrf)|
|ğŸ†• å‘å¸ƒ|LL-GaussianImage: Efficient Image Representation for Zero-shot Low-Light Enhancement with 2D Gaussian Splatting|LL-GaussianImage: åŸºäº2D Gaussian Splattingçš„é«˜æ•ˆå›¾åƒè¡¨ç¤ºç”¨äºZero-shot Low-Light Enhancement|Yuhan Chen, Wenxuan Yu, Guofa Li, Yijun Xu, Ying Fang, Yicui Shi, Long Cao, Wenbo Chu .etc.|<https://arxiv.org/pdf/2601.15772v1>|æ— |


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Masked Modeling for Human Motion Recovery Under Occlusions|é®æŒ¡ä¸‹äººä½“è¿åŠ¨æ¢å¤çš„Masked Modeling|Zhiyin Qian, Siwei Zhang, Bharat Lal Bhatnagar, Federica Bogo, Siyu Tang|<https://arxiv.org/pdf/2601.16079v1>|æ— |
|ğŸ†• å‘å¸ƒ|ThermoSplat: Cross-Modal 3D Gaussian Splatting with Feature Modulation and Geometry Decoupling|ThermoSplat: åŸºäºç‰¹å¾è°ƒåˆ¶ä¸å‡ ä½•è§£è€¦çš„è·¨æ¨¡æ€ 3D Gaussian Splatting|Zhaoqi Su, Shihai Chen, Xinyan Lin, Liqin Huang, Zhipeng Su, Xiaoqiang Lu|<https://arxiv.org/pdf/2601.15897v1>|æ— |


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### åŠ¨ä½œè¯†åˆ«ä¸ç†è§£ (Action Recognition & Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Why Can't I Open My Drawer? Mitigating Object-Driven Shortcuts in Zero-Shot Compositional Action Recognition|ä¸ºä»€ä¹ˆæˆ‘æ‰“ä¸å¼€æŠ½å±‰ï¼Ÿç¼“è§£ Zero-Shot Compositional Action Recognition ä¸­çš„ Object-Driven Shortcuts|Geo Ahn, Inwoong Lee, Taeoh Kim, Minho Shim, Dongyoon Wee, Jinwoo Choi|<https://arxiv.org/pdf/2601.16211v1>|æ— |
|ğŸ“ æ›´æ–°|BAH Dataset for Ambivalence/Hesitancy Recognition in Videos for Digital Behavioural Change|ç”¨äºæ•°å­—è¡Œä¸ºæ”¹å˜çš„è§†é¢‘ä¸­çŸ›ç›¾/çŠ¹è±«è¯†åˆ«çš„BAHæ•°æ®é›†|Manuela GonzÃ¡lez-GonzÃ¡lez, Soufiane Belharbi, Muhammad Osama Zeeshan, Masoumeh Sharafi, Muhammad Haseeb Aslam, Marco Pedersoli, Alessandro Lameiras Koerich, Simon L Bacon .etc.|<https://arxiv.org/pdf/2505.19328v3>|æ— |


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|HVD: Human Vision-Driven Video Representation Learning for Text-Video Retrieval|[ç¿»è¯‘å¤±è´¥] HVD: Human Vision-Driven Video Representation Learning for Text-Video Retrieval|Zequn Xie, Xin Liu, Boyun Zhang, Yuxiao Lin, Sihang Cai, Tao Jin|<https://arxiv.org/pdf/2601.16155v1>|æ— |
|ğŸ“ æ›´æ–°|An Efficient Quality Metric for Video Frame Interpolation Based on Motion-Field Divergence|åŸºäºè¿åŠ¨åœºæ•£åº¦çš„è§†é¢‘å¸§æ’å€¼é«˜æ•ˆè´¨é‡è¯„ä¼°æŒ‡æ ‡|Conall Daly, Darren Ramsook, Anil Kokaram|<https://arxiv.org/pdf/2510.01361v2>|[ä»£ç ](https://github.com/conalld/psnr-div.)|
|ğŸ†• å‘å¸ƒ|Assessing Situational and Spatial Awareness of VLMs with Synthetically Generated Video|è¯„ä¼° VLMs åœ¨åˆæˆç”Ÿæˆè§†é¢‘ä¸­çš„æƒ…å¢ƒæ„ŸçŸ¥å’Œç©ºé—´æ„ŸçŸ¥èƒ½åŠ›|Pascal Benschop, Justin Dauwels, Jan van Gemert|<https://arxiv.org/pdf/2601.15780v1>|æ— |
|ğŸ†• å‘å¸ƒ|VideoThinker: Building Agentic VideoLLMs with LLM-Guided Tool Reasoning|VideoThinker: åˆ©ç”¨ LLM-Guided Tool Reasoning æ„å»º Agentic VideoLLMs|Chenglin Li, Qianglong Chen, Feng Han, Yikun Wang, Xingxi Yin, Yan Gong, Ruilin Li, Yin Zhang .etc.|<https://arxiv.org/pdf/2601.15724v1>|æ— |


### è§†é¢‘ç›®æ ‡è·Ÿè¸ª (Video Object Tracking)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Dynamic Exploration on Segment-Proposal Graphs for Tubular Centerline Tracking|åŸºäºSegment-Proposalå›¾çš„åŠ¨æ€æ¢ç´¢ç”¨äºç®¡çŠ¶ä¸­å¿ƒçº¿è¿½è¸ª|Chong Di, Jinglin Zhang, Zhenjiang Li, Jean-Marie Mirebeau, Da Chen, Laurent D. Cohen|<https://arxiv.org/pdf/2506.18930v2>|æ— |


### æ—¶åºå»ºæ¨¡ä¸é¢„æµ‹ (Temporal Modeling & Prediction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SuperOcc: Toward Cohesive Temporal Modeling for Superquadric-based Occupancy Prediction|SuperOcc: åŸºäºSuperquadricçš„Occupancy Predictionçš„è¿è´¯æ—¶åºå»ºæ¨¡|Zichen Yu, Quanli Liu, Wei Wang, Liyong Zhang, Xiaoguang Zhao|<https://arxiv.org/pdf/2601.15644v1>|[ä»£ç ](https://github.com/Yzichen/SuperOcc.)|
|ğŸ†• å‘å¸ƒ|Region-aware Spatiotemporal Modeling with Collaborative Domain Generalization for Cross-Subject EEG Emotion Recognition|åŸºäºåŒºåŸŸæ„ŸçŸ¥æ—¶ç©ºå»ºæ¨¡ä¸åä½œåŸŸæ³›åŒ–çš„è·¨è¢«è¯•EEGæƒ…ç»ªè¯†åˆ«|Weiwei Wu, Yueyang Li, Yuhu Shi, Weiming Zeng, Lang Qin, Yang Yang, Ke Zhou, Zhiguo Zhang .etc.|<https://arxiv.org/pdf/2601.15615v1>|[ä»£ç ](https://github.com/RyanLi-X/RSM-CoDG.)|


## è‡ªç›‘ç£ä¸è¡¨å¾å­¦ä¹  (Self-supervised & Representation Learning)


### è·¨æ¨¡æ€ä¸€è‡´æ€§å­¦ä¹  (Cross-modal Consistency Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Radiation-Preserving Selective Imaging for Pediatric Hip Dysplasia: A Cross-Modal Ultrasound-Xray Policy with Limited Labels|ç”¨äºå„¿ç«¥é«‹å…³èŠ‚å‘è‚²ä¸è‰¯çš„è¾å°„ä¿æŒé€‰æ‹©æ€§æˆåƒï¼šåŸºäºæœ‰é™æ ‡ç­¾çš„è·¨æ¨¡æ€ Ultrasound-Xray ç­–ç•¥|Duncan Stothers, Ben Stothers, Emily Schaeffer, Kishore Mulpuri|<https://arxiv.org/pdf/2511.18457v2>|æ— |


### å¯¹æ¯”å­¦ä¹ æ–¹æ³• (Contrastive Learning Methods)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Decoupling Multi-Contrast Super-Resolution: Self-Supervised Implicit Re-Representation for Unpaired Cross-Modal Synthesis|è§£è€¦å¤šå¯¹æ¯”åº¦è¶…åˆ†è¾¨ç‡ï¼šç”¨äºéé…å¯¹è·¨æ¨¡æ€åˆæˆçš„è‡ªç›‘ç£éšå¼é‡è¡¨ç¤º|Yinzhe Wu, Hongyu Rui, Fanwen Wang, Jiahao Huang, Zhenxuan Zhang, Haosen Zhang, Zi Wang, Guang Yang|<https://arxiv.org/pdf/2505.05855v2>|æ— |
|ğŸ†• å‘å¸ƒ|Evolving Without Ending: Unifying Multimodal Incremental Learning for Continual Panoptic Perception|Evolving Without Ending: ç»Ÿä¸€å¤šæ¨¡æ€å¢é‡å­¦ä¹ ä»¥å®ç°æŒç»­å…¨æ™¯æ„ŸçŸ¥|Bo Yuan, Danpei Zhao, Wentao Li, Tian Li, Zhiguo Jiang|<https://arxiv.org/pdf/2601.15643v1>|æ— |


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Distillation-based Layer Dropping (DLD) Effective End-to-end Framework for Dynamic Speech Networks|åŸºäºè’¸é¦çš„å±‚ä¸¢å¼ƒ (DLD)ï¼šåŠ¨æ€è¯­éŸ³ç½‘ç»œçš„é«˜æ•ˆç«¯åˆ°ç«¯æ¡†æ¶|Abdul Hannan, Daniele Falavigna, Shah Nawaz, Mubashir Noman, Markus Schedl, Alessio Brutti|<https://arxiv.org/pdf/2601.16117v1>|æ— |
|ğŸ†• å‘å¸ƒ|Neural Particle Automata: Learning Self-Organizing Particle Dynamics|Neural Particle Automata: å­¦ä¹ è‡ªç»„ç»‡ç²’å­åŠ¨åŠ›å­¦|Hyunsoo Kim, Ehsan Pajouheshgar, Sabine SÃ¼sstrunk, Wenzel Jakob, Jinah Park|<https://arxiv.org/pdf/2601.16096v1>|æ— |
|ğŸ†• å‘å¸ƒ|DTP: A Simple yet Effective Distracting Token Pruning Framework for Vision-Language Action Models|DTPï¼šä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„ Vision-Language Action Models å¹²æ‰° Token å‰ªææ¡†æ¶|Chenyang Li, Jieyuan Liu, Bin Li, Bo Gao, Yilin Yuan, Yangfan He, Yuchen Li, Jingqun Tang|<https://arxiv.org/pdf/2601.16065v1>|æ— |
|ğŸ†• å‘å¸ƒ|A Mobile Application for Flower Recognition System Based on Convolutional Neural Networks|åŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„é²œèŠ±è¯†åˆ«ç³»ç»Ÿç§»åŠ¨åº”ç”¨ç¨‹åº|Mustafa Yurdakul, Enes Ayan, Fahrettin Horasan, Sakir Tasdemir|<https://arxiv.org/pdf/2601.15810v1>|æ— |


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SAMTok: Representing Any Mask with Two Words|SAMTok: ç”¨ä¸¤ä¸ªè¯è¡¨ç¤ºä»»æ„ Mask|Yikang Zhou, Tao Zhang, Dengxian Gong, Yuanzheng Wu, Ye Tian, Haochen Wang, Haobo Yuan, Jiacong Wang .etc.|<https://arxiv.org/pdf/2601.16093v1>|æ— |
|ğŸ†• å‘å¸ƒ|TinySense: Effective CSI Compression for Scalable and Accurate Wi-Fi Sensing|TinySenseï¼šç”¨äºå¯æ‰©å±•ä¸”ç²¾ç¡® Wi-Fi æ„ŸçŸ¥çš„é«˜æ•ˆ CSI å‹ç¼©|Toan Gian, Dung T. Tran, Viet Quoc Pham, Francesco Restuccia, Van-Dinh Nguyen|<https://arxiv.org/pdf/2601.15838v1>|æ— |
|ğŸ“ æ›´æ–°|Crafting Adversarial Inputs for Large Vision-Language Models Using Black-Box Optimization|åˆ©ç”¨é»‘ç›’ä¼˜åŒ–ä¸ºå¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹åˆ¶ä½œå¯¹æŠ—è¾“å…¥|Jiwei Guan, Haibo Jin, Haohan Wang|<https://arxiv.org/pdf/2601.01747v4>|æ— |


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|PlantTraitNet: An Uncertainty-Aware Multimodal Framework for Global-Scale Plant Trait Inference from Citizen Science Data|PlantTraitNet: ä¸€ä¸ªç”¨äºä»å…¬æ°‘ç§‘å­¦æ•°æ®ä¸­è¿›è¡Œå…¨çƒå°ºåº¦æ¤ç‰©æ€§çŠ¶æ¨æ–­çš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥å¤šæ¨¡æ€æ¡†æ¶|Ayushi Sharma, Johanna Trost, Daniel Lusk, Johannes Dollinger, Julian Schrader, Christian Rossi, Javier Lopatin, Etienne LalibertÃ© .etc.|<https://arxiv.org/pdf/2511.06943v2>|æ— |
|ğŸ†• å‘å¸ƒ|An IoT-Based Smart Plant Monitoring and Irrigation System with Real-Time Environmental Sensing, Automated Alerts, and Cloud Analytics|åŸºäº IoT çš„æ™ºèƒ½æ¤ç‰©ç›‘æµ‹ä¸çŒæº‰ç³»ç»Ÿï¼Œå…·å¤‡å®æ—¶ç¯å¢ƒæ„ŸçŸ¥ã€è‡ªåŠ¨æŠ¥è­¦å’Œ Cloud Analytics|Abdul Hasib, A. S. M. Ahsanul Sarkar Akib|<https://arxiv.org/pdf/2601.15830v1>|æ— |


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### å¯¹æŠ—é²æ£’æ€§ (Adversarial Robustness)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Provable Robustness in Multimodal Large Language Models via Feature Space Smoothing|é€šè¿‡ç‰¹å¾ç©ºé—´å¹³æ»‘åœ¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸­å®ç°å¯è¯æ˜çš„é²æ£’æ€§|Song Xia, Meiwen Ding, Chenqi Kong, Wenhan Yang, Xudong Jiang|<https://arxiv.org/pdf/2601.16200v1>|æ— |


### åˆ†å¸ƒå¤–æ³›åŒ– (Out-of-distribution Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|synthocr-gen: A synthetic ocr dataset generator for low-resource languages- breaking the data barrier|synthocr-gen: é¢å‘ä½èµ„æºè¯­è¨€çš„åˆæˆ OCR æ•°æ®é›†ç”Ÿæˆå™¨â€”â€”æ‰“ç ´æ•°æ®å£å’|Haq Nawaz Malik, Kh Mohmad Shafi, Tanveer Ahmad Reshi|<https://arxiv.org/pdf/2601.16113v1>|æ— |


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|The Latency Wall: Benchmarking Off-the-Shelf Emotion Recognition for Real-Time Virtual Avatars|å»¶è¿Ÿå¢™ï¼šé¢å‘å®æ—¶è™šæ‹Ÿå¤´åƒçš„ç°æˆæƒ…æ„Ÿè¯†åˆ«åŸºå‡†æµ‹è¯•|Yarin Benyamin|<https://arxiv.org/pdf/2601.15914v1>|æ— |
|ğŸ†• å‘å¸ƒ|Transfer Learning from ImageNet for MEG-Based Decoding of Imagined Speech|åŸºäº ImageNet è¿ç§»å­¦ä¹ ç”¨äº MEG æƒ³è±¡è¯­éŸ³è§£ç |Soufiane Jhilal, StÃ©phanie Martin, Anne-Lise Giraud|<https://arxiv.org/pdf/2601.15909v1>|æ— |
|ğŸ†• å‘å¸ƒ|Class Confidence Aware Reweighting for Long Tailed Learning|[ç¿»è¯‘å¤±è´¥] Class Confidence Aware Reweighting for Long Tailed Learning|Brainard Philemon Jagati, Jitendra Tembhurne, Harsh Goud, Rudra Pratap Singh, Chandrashekhar Meshram|<https://arxiv.org/pdf/2601.15924v1>|æ— |
|ğŸ“ æ›´æ–°|Heterogeneous Uncertainty-Guided Composed Image Retrieval with Fine-Grained Probabilistic Learning|åŸºäºç»†ç²’åº¦æ¦‚ç‡å­¦ä¹ çš„å¼‚æ„ä¸ç¡®å®šæ€§å¼•å¯¼ç»„åˆå›¾åƒæ£€ç´¢|Haomiao Tang, Jinpeng Wang, Minyi Zhao, Guanghao Meng, Ruisheng Luo, Long Chen, Shu-Tao Xia|<https://arxiv.org/pdf/2601.11393v2>|æ— |
|ğŸ“ æ›´æ–°|SUG-Occ: An Explicit Semantics and Uncertainty Guided Sparse Learning Framework for Real-Time 3D Occupancy Prediction|SUG-Occ: ä¸€ç§æ˜¾å¼è¯­ä¹‰å’Œä¸ç¡®å®šæ€§å¼•å¯¼çš„ç¨€ç–å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºå®æ—¶3D Occupancy Prediction|Hanlin Wu, Pengfei Lin, Ehsan Javanmardi, Naren Bao, Bo Qian, Hao Si, Manabu Tsukada|<https://arxiv.org/pdf/2601.11396v3>|æ— |
|ğŸ†• å‘å¸ƒ|Beyond Off-the-Shelf Models: A Lightweight and Accessible Machine Learning Pipeline for Ecologists Working with Image Data|è¶…è¶Šç°æˆæ¨¡å‹ï¼šé¢å‘ä½¿ç”¨å›¾åƒæ•°æ®çš„ç”Ÿæ€å­¦å®¶çš„è½»é‡çº§ä¸”æ˜“ç”¨çš„æœºå™¨å­¦ä¹ æµç¨‹|Clare Chemery, Hendrik Edelhoff, Ludwig Bothmann|<https://arxiv.org/pdf/2601.15813v1>|æ— |
|ğŸ“ æ›´æ–°|Skin Lesion Phenotyping via Nested Multi-modal Contrastive Learning|[ç¿»è¯‘å¤±è´¥] Skin Lesion Phenotyping via Nested Multi-modal Contrastive Learning|Dionysis Christopoulos, Sotiris Spanos, Eirini Baltzi, Valsamis Ntouskos, Konstantinos Karantzalos|<https://arxiv.org/pdf/2505.23709v2>|æ— |
|ğŸ“ æ›´æ–°|TUN: Detecting Significant Points in Persistence Diagrams with Deep Learning|TUNï¼šä½¿ç”¨æ·±åº¦å­¦ä¹ æ£€æµ‹æŒä¹…å›¾ä¸­çš„æ˜¾è‘—ç‚¹|Yu Chen, Hongwei Lin|<https://arxiv.org/pdf/2512.14274v2>|æ— |
|ğŸ†• å‘å¸ƒ|Consistency-Regularized GAN for Few-Shot SAR Target Recognition|Consä¸€è‡´æ€§æ­£åˆ™åŒ– GAN ç”¨äº Few-Shot SAR ç›®æ ‡è¯†åˆ«|Yikui Zhai, Shikuang Liu, Wenlve Zhou, Hongsheng Zhang, Zhiheng Zhou, Xiaolin Tian, C. L. Philip Chen|<https://arxiv.org/pdf/2601.15681v1>|[ä»£ç ](https://github.com/yikuizhai/Cr-GAN.)|
|ğŸ†• å‘å¸ƒ|FUGC: Benchmarking Semi-Supervised Learning Methods for Cervical Segmentation|FUGC: å®«é¢ˆåˆ†å‰²åŠç›‘ç£å­¦ä¹ æ–¹æ³•åŸºå‡†æµ‹è¯•|Jieyun Bai, Yitong Tang, Zihao Zhou, Mahdi Islam, Musarrat Tabassum, Enrique Almar-Munoz, Hongyu Liu, Hui Meng .etc.|<https://arxiv.org/pdf/2601.15572v1>|æ— |


### å°æ ·æœ¬å­¦ä¹  (Few-shot Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Zero-Shot Product Attribute Labeling with Vision-Language Models: A Three-Tier Evaluation Framework|Zero-Shotäº§å“å±æ€§æ ‡æ³¨ï¼šåŸºäºVision-Language Modelsçš„ä¸‰å±‚è¯„ä¼°æ¡†æ¶|Shubham Shukla, Kunal Sonalkar|<https://arxiv.org/pdf/2601.15711v1>|æ— |


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Keyframe-Based Feed-Forward Visual Odometry|åŸºäºå…³é”®å¸§çš„å‰é¦ˆè§†è§‰é‡Œç¨‹è®¡|Weichen Dai, Wenhan Su, Da Kong, Yuhang Ming, Wanzeng Kong|<https://arxiv.org/pdf/2601.16020v1>|æ— |
|ğŸ†• å‘å¸ƒ|NeuroMamba: Multi-Perspective Feature Interaction with Visual Mamba for Neuron Segmentation|NeuroMamba: åŸºäº Visual Mamba çš„å¤šè§†è§’ç‰¹å¾äº¤äº’ç”¨äºç¥ç»å…ƒåˆ†å‰²|Liuyun Jiang, Yizhuo Lu, Yanchao Zhang, Jiazheng Liu, Hua Han|<https://arxiv.org/pdf/2601.15929v1>|æ— |
|ğŸ“ æ›´æ–°|Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning|Render-of-Thoughtï¼šå°†æ–‡æœ¬ Chain-of-Thought æ¸²æŸ“ä¸ºå›¾åƒä»¥è¿›è¡Œ Visual Latent Reasoning|Yifan Wang, Shiyu Li, Peiming Li, Xiaochen Yang, Yang Tang, Zheng Wei|<https://arxiv.org/pdf/2601.14750v2>|[ä»£ç ](https://github.com/TencentBAC/RoT)|
|ğŸ“ æ›´æ–°|VideoPro: Adaptive Program Reasoning for Long Video Understanding|VideoProï¼šé¢å‘é•¿è§†é¢‘ç†è§£çš„è‡ªé€‚åº”ç¨‹åºæ¨ç†|Chenglin Li, Feng Han, Yikun Wang, Ruilin Li, Shuai Dong, Haowen Hou, Haitao Li, Qianglong Chen .etc.|<https://arxiv.org/pdf/2509.17743v3>|æ— |
|ğŸ“ æ›´æ–°|VIKI-R: Coordinating Embodied Multi-Agent Cooperation via Reinforcement Learning|VIKI-R: é€šè¿‡ Reinforcement Learning åè°ƒ Embodied Multi-Agent Cooperation|Li Kang, Xiufeng Song, Heng Zhou, Yiran Qin, Jie Yang, Xiaohong Liu, Philip Torr, Lei Bai .etc.|<https://arxiv.org/pdf/2506.09049v3>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|PatchEAD: Unifying Industrial Visual Prompting Frameworks for Patch-Exclusive Anomaly Detection|PatchEAD: ç»Ÿä¸€ç”¨äºPatch-Exclusiveå¼‚å¸¸æ£€æµ‹çš„å·¥ä¸šè§†è§‰æç¤ºæ¡†æ¶|Po-Han Huang, Jeng-Lin Li, Po-Hsuan Huang, Ming-Ching Chang, Wei-Chao Chen|<https://arxiv.org/pdf/2509.25856v2>|æ— |


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Phi-SegNet: Phase-Integrated Supervision for Medical Image Segmentation|Phi-SegNet: ç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²çš„ç›¸ä½é›†æˆç›‘ç£|Shams Nafisa Ali, Taufiq Hasan|<https://arxiv.org/pdf/2601.16064v1>|æ— |
|ğŸ†• å‘å¸ƒ|ProGiDiff: Prompt-Guided Diffusion-Based Medical Image Segmentation|[ç¿»è¯‘å¤±è´¥] ProGiDiff: Prompt-Guided Diffusion-Based Medical Image Segmentation|Yuan Lin, Murong Xu, Marc HÃ¶lle, Chinmay Prabhakar, Andreas Maier, Vasileios Belagiannis, Bjoern Menze, Suprosanna Shit|<https://arxiv.org/pdf/2601.16060v1>|æ— |
|ğŸ“ æ›´æ–°|MetaDCSeg: Robust Medical Image Segmentation via Meta Dynamic Center Weighting|MetaDCSeg: é€šè¿‡Meta Dynamic Center Weightingå®ç°é²æ£’çš„åŒ»å­¦å›¾åƒåˆ†å‰²|Chenyu Mu, Guihai Chen, Xun Yang, Erkun Yang, Cheng Deng|<https://arxiv.org/pdf/2511.18894v2>|æ— |
|ğŸ“ æ›´æ–°|Language-guided Medical Image Segmentation with Target-informed Multi-level Contrastive Alignments|[ç¿»è¯‘å¤±è´¥] Language-guided Medical Image Segmentation with Target-informed Multi-level Contrastive Alignments|Mingjian Li, Mingyuan Meng, Shuchang Ye, Michael Fulham, Lei Bi, Jinman Kim|<https://arxiv.org/pdf/2412.13533v3>|æ— |
|ğŸ†• å‘å¸ƒ|PMPBench: A Paired Multi-Modal Pan-Cancer Benchmark for Medical Image Synthesis|PMPBench: ä¸€ä¸ªç”¨äºåŒ»å­¦å›¾åƒåˆæˆçš„é…å¯¹å¤šæ¨¡æ€æ³›ç™ŒåŸºå‡†|Yifan Chen, Fei Yin, Hao Chen, Jia Wu, Chao Li|<https://arxiv.org/pdf/2601.15884v1>|[ä»£ç ](https://github.com/YifanChen02/PMPBench.)|
|ğŸ†• å‘å¸ƒ|A Lightweight Brain-Inspired Machine Learning Framework for Coronary Angiography: Hybrid Neural Representation and Robust Learning Strategies|ä¸€ç§ç”¨äºå† çŠ¶åŠ¨è„‰é€ å½±çš„è½»é‡çº§è„‘å¯å‘çš„æœºå™¨å­¦ä¹ æ¡†æ¶ï¼šæ··åˆç¥ç»è¡¨ç¤ºä¸é²æ£’å­¦ä¹ ç­–ç•¥|Jingsong Xia, Siqi Wang|<https://arxiv.org/pdf/2601.15865v1>|æ— |
|ğŸ“ æ›´æ–°|Scribble-Supervised Medical Image Segmentation with Dynamic Teacher Switching and Hierarchical Consistency|åŸºäºåŠ¨æ€æ•™å¸ˆåˆ‡æ¢å’Œå±‚æ¬¡ä¸€è‡´æ€§çš„æ¶‚é¸¦ç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²|Thanh-Huy Nguyen, Hoang-Loc Cao, Dat T. Chung, Mai-Anh Vu, Thanh-Minh Nguyen, Minh Le, Phat K. Huynh, Ulas Bagci|<https://arxiv.org/pdf/2601.14563v2>|æ— |


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Towards Realistic Remote Sensing Dataset Distillation with Discriminative Prototype-guided Diffusion|[ç¿»è¯‘å¤±è´¥] Towards Realistic Remote Sensing Dataset Distillation with Discriminative Prototype-guided Diffusion|Yonghao Xu, Pedram Ghamisi, Qihao Weng|<https://arxiv.org/pdf/2601.15829v1>|[ä»£ç ](https://github.com/YonghaoXu/DPD)|


### å·¥ä¸šè§†è§‰æ£€æµ‹ (Industrial Visual Inspection)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|DECOR: Deep Embedding Clustering with Orientation Robustness|DECOR: å…·æœ‰æ–¹å‘é²æ£’æ€§çš„æ·±åº¦åµŒå…¥èšç±»|Fiona Victoria Stanley Jothiraj, Arunaggiri Pandian Karunanidhi, Seth A. Eichmeyer|<https://arxiv.org/pdf/2510.03328v2>|æ— |


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Find the Leak, Fix the Split: Cluster-Based Method to Prevent Leakage in Video-Derived Datasets|Find the Leak, Fix the Split: åŸºäº Cluster çš„æ–¹æ³•é˜²æ­¢ Video-Derived Datasets ä¸­çš„ Leakage|Noam Glazner, Noam Tsfaty, Sharon Shalev, Avishai Weizman|<https://arxiv.org/pdf/2511.13944v2>|æ— |
|ğŸ†• å‘å¸ƒ|FAIR-ESI: Feature Adaptive Importance Refinement for Electrophysiological Source Imaging|FAIR-ESI: ç”¨äºç”µç”Ÿç†æºæˆåƒçš„ç‰¹å¾è‡ªé€‚åº”é‡è¦æ€§ç»†åŒ–|Linyong Zou, Liang Zhang, Xiongfei Wang, Jia-Hong Gao, Yi Sun, Shurong Sheng, Kuntao Xiao, Wanli Yang .etc.|<https://arxiv.org/pdf/2601.15731v1>|æ— |
|ğŸ“ æ›´æ–°|From Text to Image: Exploring GPT-4Vision's Potential in Advanced Radiological Analysis across Subspecialties|ä»æ–‡æœ¬åˆ°å›¾åƒï¼šæ¢ç´¢ GPT-4Vision åœ¨å„äºšä¸“ç§‘é«˜çº§æ”¾å°„å­¦åˆ†æä¸­çš„æ½œåŠ›|Felix Busch, Tianyu Han, Marcus Makowski, Daniel Truhn, Keno Bressem, Lisa Adams|<https://arxiv.org/pdf/2311.14777v2>|æ— |
|ğŸ“ æ›´æ–°|GutenOCR: A Grounded Vision-Language Front-End for Documents|GutenOCR: ä¸€ä¸ªç”¨äºæ–‡æ¡£çš„Grounded Vision-Languageå‰ç«¯|Hunter Heidenreich, Ben Elliott, Olivia Dinica, Yosheb Getachew|<https://arxiv.org/pdf/2601.14490v2>|æ— |

