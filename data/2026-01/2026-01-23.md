## [UPDATED!] **2026-01-23** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Beyond the LUMIR challenge: The pathway to foundational registration models|[ç¿»è¯‘å¤±è´¥] Beyond the LUMIR challenge: The pathway to foundational registration models|Junyu Chen, Shuwen Wei, Joel Honkamaa, Pekka Marttinen, Hang Zhang, Min Liu, Yichao Zhou, Zuopeng Tan .etc.|<https://arxiv.org/pdf/2505.24160v2>|æ— |
|ğŸ†• å‘å¸ƒ|Embedding -based Crop Type Classification in the Groundnut Basin of Senegal|åŸºäº Embedding çš„å¡å†…åŠ å°” Groundnut Basin ä½œç‰©ç±»å‹åˆ†ç±»|Madeline C. Lisaius, Srinivasan Keshav, Andrew Blake, Clement Atzberger|<https://arxiv.org/pdf/2601.16900v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Incorporating Eye-Tracking Signals Into Multimodal Deep Visual Models For Predicting User Aesthetic Experience In Residential Interiors|å°†çœ¼åŠ¨è¿½è¸ªä¿¡å·èå…¥å¤šæ¨¡æ€æ·±åº¦è§†è§‰æ¨¡å‹ä»¥é¢„æµ‹ä½å®…å®¤å†…ç”¨æˆ·å®¡ç¾ä½“éªŒ|Chen-Ying Chien, Po-Chih Kuo|<https://arxiv.org/pdf/2601.16811v1>|æ— |
|ğŸ“ æ›´æ–°|A Multi-Stage Hybrid Framework for Automated Interpretation of Multi-View Engineering Drawings Using Vision Language Model|[ç¿»è¯‘å¤±è´¥] A Multi-Stage Hybrid Framework for Automated Interpretation of Multi-View Engineering Drawings Using Vision Language Model|Muhammad Tayyab Khan, Zane Yong, Lequn Chen, Wenhe Feng, Nicholas Yew Jin Tan, Seung Ki Moon|<https://arxiv.org/pdf/2510.21862v2>|æ— |
|ğŸ“ æ›´æ–°|SAMRI: Segment Anything Model for MRI|SAMRIï¼šç”¨äº MRI çš„ Segment Anything Model|Zhao Wang, Wei Dai, Thuy Thanh Dao, Steffen Bollmann, Hongfu Sun, Craig Engstrom, Shekhar S. Chandra|<https://arxiv.org/pdf/2510.26635v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|OnlineSI: Taming Large Language Model for Online 3D Understanding and Grounding|OnlineSI: é©¯æœ Large Language Model ç”¨äºåœ¨çº¿ 3D ç†è§£å’Œå®šä½|Zixian Liu, Zhaoxi Chen, Liang Pan, Ziwei Liu|<https://arxiv.org/pdf/2601.16538v1>|æ— |
|ğŸ†• å‘å¸ƒ|VISTA-PATH: An interactive foundation model for pathology image segmentation and quantitative analysis in computational pathology|[ç¿»è¯‘å¤±è´¥] VISTA-PATH: An interactive foundation model for pathology image segmentation and quantitative analysis in computational pathology|Peixian Liang, Songhao Li, Shunsuke Koga, Yutong Li, Zahra Alipour, Yucheng Tang, Daguang Xu, Zhi Huang|<https://arxiv.org/pdf/2601.16451v1>|[ä»£ç ](https://github.com/zhihuanglab/VISTA-PATH.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|On Computational Limits of FlowAR Models: Expressivity and Efficiency|è®º FlowAR æ¨¡å‹çš„è®¡ç®—æé™ï¼šè¡¨è¾¾èƒ½åŠ›ä¸æ•ˆç‡|Yang Cao, Chengyue Gong, Yekun Ke, Xiaoyu Li, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song|<https://arxiv.org/pdf/2502.16490v2>|åˆ†æå¤±è´¥|


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|FUSAR-KLIP: Towards Multimodal Foundation Models for Remote Sensing|FUSAR-KLIP: é¢å‘é¥æ„Ÿçš„å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹|Yi Yang, Xiaokun Zhang, Qingchen Fang, Jing Liu, Ziqi Ye, Rui Li, Li Liu, Haipeng Wang|<https://arxiv.org/pdf/2509.23927v4>|æ— |
|ğŸ“ æ›´æ–°|UniFGVC: Universal Training-Free Few-Shot Fine-Grained Vision Classification via Attribute-Aware Multimodal Retrieval|UniFGVC: é€šè¿‡å±æ€§æ„ŸçŸ¥å¤šæ¨¡æ€æ£€ç´¢å®ç°çš„é€šç”¨å…è®­ç»ƒå°‘æ ·æœ¬ç»†ç²’åº¦è§†è§‰åˆ†ç±»|Hongyu Guo, Xiangzhao Hao, Jiarui Guo, Haiyun Guo, Jinqiao Wang, Tat-Seng Chua|<https://arxiv.org/pdf/2508.04136v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation|FantasyVLNï¼šç”¨äºVision-Language Navigationçš„ç»Ÿä¸€å¤šæ¨¡æ€Chain-of-Thoughtæ¨ç†|Jing Zuo, Lingzhou Mu, Fan Jiang, Chengcheng Ma, Mu Xu, Yonggang Qi|<https://arxiv.org/pdf/2601.13976v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Beyond Superficial Unlearning: Sharpness-Aware Robust Erasure of Hallucinations in Multimodal LLMs|[ç¿»è¯‘å¤±è´¥] Beyond Superficial Unlearning: Sharpness-Aware Robust Erasure of Hallucinations in Multimodal LLMs|Xianya Fang, Feiyang Ren, Xiang Chen, Yu Tian, Zhen Bi, Haiyang Yu, Sheng-Jun Huang|<https://arxiv.org/pdf/2601.16527v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Emotion-LLaMAv2 and MMEVerse: A New Framework and Benchmark for Multimodal Emotion Understanding|Emotion-LLaMAv2 å’Œ MMEVerseï¼šå¤šæ¨¡æ€æƒ…æ„Ÿç†è§£çš„æ–°æ¡†æ¶ä¸åŸºå‡†|Xiaojiang Peng, Jingyi Chen, Zebang Cheng, Bao Peng, Fengyi Wu, Yifei Dong, Shuyuan Tu, Qiyu Hu .etc.|<https://arxiv.org/pdf/2601.16449v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Hierarchy-Aware Multimodal Unlearning for Medical AI|[ç¿»è¯‘å¤±è´¥] Hierarchy-Aware Multimodal Unlearning for Medical AI|Fengli Wu, Vaidehi Patil, Jaehong Yoon, Yue Zhang, Mohit Bansal|<https://arxiv.org/pdf/2512.09867v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Cognitively-Inspired Tokens Overcome Egocentric Bias in Multimodal Models|å—è®¤çŸ¥å¯å‘çš„ Tokens å…‹æœå¤šæ¨¡æ€æ¨¡å‹ä¸­çš„è‡ªæˆ‘ä¸­å¿ƒåå·®|Bridget Leonard, Scott O. Murray|<https://arxiv.org/pdf/2601.16378v1>|æ— |


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|PanopMamba: Vision State Space Modeling for Nuclei Panoptic Segmentation|PanopMamba: ç”¨äº Nuclei Panoptic Segmentation çš„ Vision State Space Modeling|Ming Kang, Fung Fung Ting, RaphaÃ«l C. -W. Phan, Zongyuan Ge, Chee-Ming Ting|<https://arxiv.org/pdf/2601.16631v1>|[ä»£ç ](https://github.com/mkang315/PanopMamba.)|
|ğŸ“ æ›´æ–°|CardioMOD-Net: A Modal Decomposition-Neural Network Framework for Diagnosis and Prognosis of HFpEF from Echocardiography Cine Loops|CardioMOD-Net: ä¸€ç§ç”¨äºä»è¶…å£°å¿ƒåŠ¨å›¾ç”µå½±å¾ªç¯è¯Šæ–­å’Œé¢„åHFpEFçš„æ¨¡æ€åˆ†è§£-ç¥ç»ç½‘ç»œæ¡†æ¶|AndrÃ©s Bell-Navas, JesÃºs Garicano-Mena, Antonella Ausiello, Soledad Le Clainche, MarÃ­a Villalba-Orero, Enrique Lara-Pezzi|<https://arxiv.org/pdf/2601.01176v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|PanoNormal: Monocular Indoor 360Â° Surface Normal Estimation|PanoNormal: å•ç›®å®¤å†… 360Â° è¡¨é¢æ³•å‘é‡ä¼°è®¡|Kun Huang, Fanglue Zhang, Neil Dodgson|<https://arxiv.org/pdf/2405.18745v2>|[ä»£ç ](https://github.com/huangkun101230/PanoNormal.); åˆ†æå¤±è´¥|


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Intelligent Systems in Neuroimaging: Pioneering AI Techniques for Brain Tumor Detection|ç¥ç»å½±åƒä¸­çš„æ™ºèƒ½ç³»ç»Ÿï¼šç”¨äºè„‘è‚¿ç˜¤æ£€æµ‹çš„å…ˆé©±AIæŠ€æœ¯|Md. Mohaiminul Islam, Md. Mofazzal Hossen, Maher Ali Rusho, Nahiyan Nazah Ridita, Zarin Tasnia Shanta, Md. Simanto Haider, Ahmed Faizul Haque Dhrubo, Md. Khurshid Jahan .etc.|<https://arxiv.org/pdf/2511.17655v2>|æ— |
|ğŸ†• å‘å¸ƒ|SLD: Segmentation-Based Landmark Detection for Spinal Ligaments|SLD: åŸºäºåˆ†å‰²çš„è„ŠæŸ±éŸ§å¸¦å…³é”®ç‚¹æ£€æµ‹|Lara Blomenkamp, Ivanna Kramer, Sabine Bauer, Theresa SchÃ¶che|<https://arxiv.org/pdf/2601.16782v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|From Neck to Head: Bio-Impedance Sensing for Head Pose Estimation|ä»é¢ˆéƒ¨åˆ°å¤´éƒ¨ï¼šç”¨äº Head Pose Estimation çš„ Bio-Impedance Sensing|Mengxi Liu, Lala Shakti Swarup Ray, Sizhen Bian, Ko Watanabe, Ankur Bhatt, Joanna Sorysz, Russel Torah, Bo Zhou .etc.|<https://arxiv.org/pdf/2507.12884v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Reliable Brain Tumor Segmentation Based on Spiking Neural Networks with Efficient Training|åŸºäºé«˜æ•ˆè®­ç»ƒçš„ Spiking Neural Networks çš„å¯é è„‘è‚¿ç˜¤åˆ†å‰²|Aurora Pia Ghiardelli, Guangzhi Tang, Tao Sun|<https://arxiv.org/pdf/2601.16652v1>|æå‡ºåŸºäºSNNçš„å¯é èŠ‚èƒ½3Dè„‘è‚¿ç˜¤åˆ†å‰²æ¡†æ¶ï¼Œåˆ©ç”¨å¤šè§†å›¾é›†æˆå¢å¼ºé²æ£’æ€§ï¼Œå¹¶é‡‡ç”¨FPTTé«˜æ•ˆè®­ç»ƒã€‚|
|ğŸ†• å‘å¸ƒ|MDAFNet: Multiscale Differential Edge and Adaptive Frequency Guided Network for Infrared Small Target Detection|[ç¿»è¯‘å¤±è´¥] MDAFNet: Multiscale Differential Edge and Adaptive Frequency Guided Network for Infrared Small Target Detection|Shuying Li, Qiang Ma, San Zhang, Wuwei Wang, Chuang Yang|<https://arxiv.org/pdf/2601.16434v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|LAKAN: Landmark-assisted Adaptive Kolmogorov-Arnold Network for Face Forgery Detection|LAKANï¼šç”¨äºäººè„¸ä¼ªé€ æ£€æµ‹çš„Landmarkè¾…åŠ©è‡ªé€‚åº”Kolmogorov-Arnold Network|Jiayao Jiang, Siran Peng, Bin Liu, Qi Chu, Nenghai Yu|<https://arxiv.org/pdf/2510.00634v2>|åˆ†æå¤±è´¥|


### è¯­ä¹‰/å®ä¾‹åˆ†å‰² (Semantic/Instance Segmentation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|REL-SF4PASS: Panoramic Semantic Segmentation with REL Depth Representation and Spherical Fusion|REL-SF4PASS: åŸºäº REL Depth Representation å’Œ Spherical Fusion çš„å…¨æ™¯è¯­ä¹‰åˆ†å‰²|Xuewei Li, Xinghan Bao, Zhimin Chen, Xi Li|<https://arxiv.org/pdf/2601.16788v1>|æ— |


### ç›®æ ‡æ£€æµ‹ä¸å®šä½ (Object Detection & Localization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|UltraFlwr -- An Efficient Federated Surgical Object Detection Framework|UltraFlwr -- ä¸€ç§é«˜æ•ˆçš„è”é‚¦æ‰‹æœ¯ç›®æ ‡æ£€æµ‹æ¡†æ¶|Yang Li, Soumya Snigdha Kundu, Maxence Boels, Toktam Mahmoodi, Sebastien Ourselin, Tom Vercauteren, Prokar Dasgupta, Jonathan Shapey .etc.|<https://arxiv.org/pdf/2503.15161v2>|[ä»£ç ](https://github.com/KCL-BMEIS/UltraFlwr.)|
|ğŸ†• å‘å¸ƒ|Boundary and Position Information Mining for Aerial Small Object Detection|[ç¿»è¯‘å¤±è´¥] Boundary and Position Information Mining for Aerial Small Object Detection|Rongxin Huang, Guangfeng Lin, Wenbo Zhou, Zhirong Li, Wenhuan Wu|<https://arxiv.org/pdf/2601.16617v1>|åˆ†æå¤±è´¥|


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SyncLight: Controllable and Consistent Multi-View Relighting|SyncLight: å¯æ§ä¸”ä¸€è‡´çš„å¤šè§†è§’é‡å…‰ç…§|David Serrano-Lozano, Anand Bhattad, Luis Herranz, Jean-FranÃ§ois Lalonde, Javier Vazquez-Corral|<https://arxiv.org/pdf/2601.16981v1>|æ— |
|ğŸ†• å‘å¸ƒ|AnyView: Synthesizing Any Novel View in Dynamic Scenes|AnyView: åœ¨åŠ¨æ€åœºæ™¯ä¸­åˆæˆä»»æ„æ–°è§†è§’|Basile Van Hoorick, Dian Chen, Shun Iwase, Pavel Tokmakov, Muhammad Zubair Irshad, Igor Vasiljevic, Swati Gupta, Fangzhou Cheng .etc.|<https://arxiv.org/pdf/2601.16982v1>|[ä»£ç ](https://tri-ml.github.io/AnyView)|
|ğŸ†• å‘å¸ƒ|Reward-Forcing: Autoregressive Video Generation with Reward Feedback|Reward-Forcing: åŸºäºReward Feedbackçš„è‡ªå›å½’è§†é¢‘ç”Ÿæˆ|Jingran Zhang, Ning Li, Yuanhao Ban, Andrew Bai, Justin Cui|<https://arxiv.org/pdf/2601.16933v1>|æ— |
|ğŸ†• å‘å¸ƒ|AutoRegressive Generation with B-rep Holistic Token Sequence Representation|åŸºäº B-rep æ•´ä½“ Token åºåˆ—è¡¨ç¤ºçš„è‡ªå›å½’ç”Ÿæˆ|Jiahao Li, Yunpeng Bai, Yongkang Dai, Hao Guo, Hongping Gan, Yilei Shi|<https://arxiv.org/pdf/2601.16771v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|SCHIGAND: A Synthetic Facial Generation Mode Pipeline|[ç¿»è¯‘å¤±è´¥] SCHIGAND: A Synthetic Facial Generation Mode Pipeline|Ananya Kadali, Sunnie Jehan-Morrison, Orasiki Wellington, Barney Evans, Precious Durojaiye, Richard Guest|<https://arxiv.org/pdf/2601.16627v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|AnchoredDream: Zero-Shot 360Â° Indoor Scene Generation from a Single View via Geometric Grounding|AnchoredDreamï¼šé€šè¿‡å‡ ä½•åŸºç¡€ä»å•è§†å›¾è¿›è¡Œé›¶æ ·æœ¬ 360Â° å®¤å†…åœºæ™¯ç”Ÿæˆ|Runmao Yao, Junsheng Zhou, Zhen Dong, Yu-Shen Liu|<https://arxiv.org/pdf/2601.16532v1>|æ— |
|ğŸ†• å‘å¸ƒ|SALAD: Achieve High-Sparsity Attention via Efficient Linear Attention Tuning for Video Diffusion Transformer|SALAD: é€šè¿‡é«˜æ•ˆçš„ Linear Attention Tuning ä¸º Video Diffusion Transformer å®ç°é«˜ç¨€ç– Attention|Tongcheng Fang, Hanling Zhang, Ruiqi Xie, Zhuo Han, Xin Tao, Tianchen Zhao, Pengfei Wan, Wenbo Ding .etc.|<https://arxiv.org/pdf/2601.16515v1>|æ— |
|ğŸ“ æ›´æ–°|ToonifyGB: StyleGAN-based Gaussian Blendshapes for 3D Stylized Head Avatars|[ç¿»è¯‘å¤±è´¥] ToonifyGB: StyleGAN-based Gaussian Blendshapes for 3D Stylized Head Avatars|Rui-Yang Ju, Sheng-Yen Huang, Yi-Ping Hung|<https://arxiv.org/pdf/2505.10072v3>|åˆ†æå¤±è´¥|


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|T-LoRA: Single Image Diffusion Model Customization Without Overfitting|T-LoRA: å•å›¾åƒ Diffusion Model å®šåˆ¶åŒ– Without Overfitting|Vera Soboleva, Aibek Alanov, Andrey Kuznetsov, Konstantin Sobolev|<https://arxiv.org/pdf/2507.05964v2>|[ä»£ç ](https://controlgenai.github.io/T-LoRA)|
|ğŸ†• å‘å¸ƒ|ColorConceptBench: A Benchmark for Probabilistic Color-Concept Understanding in Text-to-Image Models|ColorConceptBenchï¼šText-to-Image Modelsä¸­æ¦‚ç‡æ€§é¢œè‰²-æ¦‚å¿µç†è§£çš„åŸºå‡†|Chenxi Ruan, Yu Xiao, Yihan Hou, Guosheng Hu, Wei Zeng|<https://arxiv.org/pdf/2601.16836v1>|æ— |
|ğŸ†• å‘å¸ƒ|Fast, faithful and photorealistic diffusion-based image super-resolution with enhanced Flow Map models|åŸºäºå¢å¼º Flow Map æ¨¡å‹çš„å¿«é€Ÿã€ä¿çœŸä¸”é€¼çœŸçš„æ‰©æ•£å‹å›¾åƒè¶…åˆ†è¾¨ç‡|Maxence Noble, Gonzalo IÃ±aki Quintana, Benjamin Aubin, ClÃ©ment Chadebec|<https://arxiv.org/pdf/2601.16660v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Edge-Aware Image Manipulation via Diffusion Models with a Novel Structure-Preservation Loss|åŸºäºæ‰©æ•£æ¨¡å‹ä¸æ–°å‹ç»“æ„ä¿æŒæŸå¤±çš„è¾¹ç¼˜æ„ŸçŸ¥å›¾åƒæ“ä½œ|Minsu Gong, Nuri Ryu, Jungseul Ok, Sunghyun Cho|<https://arxiv.org/pdf/2601.16645v1>|[ä»£ç ](https://github.com/gongms00/SPL.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|GazeD: Context-Aware Diffusion for Accurate 3D Gaze Estimation|GazeDï¼šç”¨äºç²¾ç¡®3D Gaze Estimationçš„Context-Aware Diffusion|Riccardo Catalini, Davide Di Nucci, Guido Borghi, Davide Davoli, Lorenzo Garattoni, Gianpiero Francesca, Yuki Kawana, Roberto Vezzani|<https://arxiv.org/pdf/2601.12948v2>|æ— |
|ğŸ“ æ›´æ–°|Text-to-Image Diffusion Models Cannot Count, and Prompt Refinement Cannot Help|Text-to-Image Diffusion Models æ— æ³•è®¡æ•°ï¼ŒPrompt Refinement ä¹Ÿæ— æµäºäº‹|Xuyang Guo, Jiayan Huo, Yingyu Liang, Zhenmei Shi, Zhao Song, Jiahao Zhang, Zhen Zhuang|<https://arxiv.org/pdf/2503.06884v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Markovian Reeb Graphs for Simulating Spatiotemporal Patterns of Life|Markovian Reeb Graphs ç”¨äºæ¨¡æ‹Ÿç”Ÿå‘½æ—¶ç©ºæ¨¡å¼|Anantajit Subrahmanya, Chandrakanth Gudavalli, Connor Levenson, B. S. Manjunath|<https://arxiv.org/pdf/2510.03152v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|CoreEditor: Consistent 3D Editing via Correspondence-constrained Diffusion|CoreEditor: é€šè¿‡å¯¹åº”çº¦æŸæ‰©æ•£å®ç°ä¸€è‡´çš„3Dç¼–è¾‘|Zhe Zhu, Honghua Chen, Peng Li, Mingqiang Wei|<https://arxiv.org/pdf/2508.11603v2>|åˆ†æå¤±è´¥|


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|LoL: Longer than Longer, Scaling Video Generation to Hour|LoL: Longer than Longer, å°†è§†é¢‘ç”Ÿæˆæ‰©å±•åˆ°å°æ—¶çº§|Justin Cui, Jie Wu, Ming Li, Tao Yang, Xiaojie Li, Rui Wang, Andrew Bai, Yuanhao Ban .etc.|<https://arxiv.org/pdf/2601.16914v1>|æ— |
|ğŸ†• å‘å¸ƒ|CER-HV: A CER-Based Human-in-the-Loop Framework for Cleaning Datasets Applied to Arabic-Script HTR|CER-HV: ä¸€ç§åŸºäºCERçš„ç”¨äºæ¸…æ´—åº”ç”¨äºé˜¿æ‹‰ä¼¯æ–‡HTRæ•°æ®é›†çš„äººæœºååŒæ¡†æ¶|Sana Al-azzawi, Elisa Barney, Marcus Liwicki|<https://arxiv.org/pdf/2601.16713v1>|æ— |


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|MoE-Enhanced Multi-Domain Feature Selection and Fusion for Fast Map-Free Trajectory Prediction|MoEå¢å¼ºçš„å¤šåŸŸç‰¹å¾é€‰æ‹©ä¸èåˆç”¨äºå¿«é€Ÿæ— åœ°å›¾è½¨è¿¹é¢„æµ‹|Wenyi Xiong, Jian Chen, Ziheng Qi, Wenhua Chen|<https://arxiv.org/pdf/2512.02368v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|FoldNet: Learning Generalizable Closed-Loop Policy for Garment Folding via Keypoint-Driven Asset and Demonstration Synthesis|FoldNet: é€šè¿‡Keypoint-Driven Asset and Demonstration Synthesiså­¦ä¹ å¯æ³›åŒ–çš„æœè£…æŠ˜å é—­ç¯ç­–ç•¥|Yuxing Chen, Bowen Xiao, He Wang|<https://arxiv.org/pdf/2505.09109v4>|åˆ†æå¤±è´¥|


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|MapAnything: Universal Feed-Forward Metric 3D Reconstruction|MapAnything: é€šç”¨å‰å‘åº¦é‡3Dé‡å»º|Nikhil Keetha, Norman MÃ¼ller, Johannes SchÃ¶nberger, Lorenzo Porzi, Yuchen Zhang, Tobias Fischer, Arno Knapitsch, Duncan Zauss .etc.|<https://arxiv.org/pdf/2509.13414v3>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Masked Modeling for Human Motion Recovery Under Occlusions|é®æŒ¡ä¸‹äººä½“è¿åŠ¨æ¢å¤çš„Masked Modeling|Zhiyin Qian, Siwei Zhang, Bharat Lal Bhatnagar, Federica Bogo, Siyu Tang|<https://arxiv.org/pdf/2601.16079v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|ReWeaver: Towards Simulation-Ready and Topology-Accurate Garment Reconstruction|ReWeaver: é¢å‘ä»¿çœŸå°±ç»ªä¸”æ‹“æ‰‘å‡†ç¡®çš„æœè£…é‡å»º|Ming Li, Hui Shan, Kai Zheng, Chentao Shen, Siyu Liu, Yanwei Fu, Zhen Chen, Xiangru Huang|<https://arxiv.org/pdf/2601.16672v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Understanding and Improving UMAP with Geometric and Topological Priors: The JORC-UMAP Algorithm|ç†è§£å¹¶åˆ©ç”¨å‡ ä½•ä¸æ‹“æ‰‘å…ˆéªŒæ”¹è¿›UMAPï¼šJORC-UMAPç®—æ³•|Xiaobin Li, Run Zhang|<https://arxiv.org/pdf/2601.16552v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|AlphaFace: High Fidelity and Real-time Face Swapper Robust to Facial Pose|AlphaFaceï¼šé«˜ä¿çœŸä¸”å®æ—¶çš„é¢éƒ¨å§¿æ€é²æ£’ Face Swapper|Jongmin Yu, Hyeontaek Oh, Zhongtian Sun, Angelica I Aviles-Rivero, Moongu Jeon, Jinhong Yang|<https://arxiv.org/pdf/2601.16429v1>|[ä»£ç ](https://github.com/andrewyu90/Alphaface_Official.git); åˆ†æå¤±è´¥|


### è§†è§‰å®šä½ä¸æ˜ å°„ (Visual Localization & Mapping)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|GPA-VGGT:Adapting VGGT to Large scale Localization by self-Supervised learning with Geometry and Physics Aware loss|GPA-VGGT: é€šè¿‡å…·æœ‰å‡ ä½•å’Œç‰©ç†æ„ŸçŸ¥æŸå¤±çš„è‡ªç›‘ç£å­¦ä¹ å°†VGGTé€‚åº”äºå¤§è§„æ¨¡å®šä½|Yangfan Xu, Lilian Zhang, Xiaofeng He, Pengdong Wu, Wenqi Wu, Jun Mao|<https://arxiv.org/pdf/2601.16885v1>|[ä»£ç ](https://github.com/X-yangfan/GPA-VGGT.)|


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Language-Guided and Motion-Aware Gait Representation for Generalizable Recognition|[ç¿»è¯‘å¤±è´¥] Language-Guided and Motion-Aware Gait Representation for Generalizable Recognition|Zhengxian Wu, Chuanrui Zhang, Shenao Jiang, Hangrui Xu, Zirui Liao, Luyuan Zhang, Huaqiu Li, Peng Jiao .etc.|<https://arxiv.org/pdf/2601.11931v2>|[ä»£ç ](https://dingwu1021.github.io/LMGait); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Multi-View Consistent Wound Segmentation With Neural Fields|[ç¿»è¯‘å¤±è´¥] Multi-View Consistent Wound Segmentation With Neural Fields|Remi Chierchia, LÃ©o Lebrat, David Ahmedt-Aristizabal, Yulia Arzhaeva, Olivier Salvado, Clinton Fookes, Rodrigo Santa Cruz|<https://arxiv.org/pdf/2601.16487v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|The Prism Hypothesis: Harmonizing Semantic and Pixel Representations via Unified Autoencoding|The Prism Hypothesisï¼šé€šè¿‡ Unified Autoencoding åè°ƒ Semantic å’Œ Pixel Representations|Weichen Fan, Haiwen Diao, Quan Wang, Dahua Lin, Ziwei Liu|<https://arxiv.org/pdf/2512.19693v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|NFL-BA: Near-Field Light Bundle Adjustment for SLAM in Dynamic Lighting|NFL-BA: ç”¨äºåŠ¨æ€å…‰ç…§ä¸‹ SLAM çš„è¿‘åœºå…‰æŸå¹³å·®æ³•|Andrea Dunn Beltran, Daniel Rho, Marc Niethammer, Roni Sengupta|<https://arxiv.org/pdf/2412.13176v4>|[ä»£ç ](https://asdunnbe.github.io/NFL-BA); åˆ†æå¤±è´¥|


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|PocketDVDNet: Realtime Video Denoising for Real Camera Noise|PocketDVDNet: é¢å‘çœŸå®ç›¸æœºå™ªå£°çš„å®æ—¶è§†é¢‘å»å™ª|Crispian Morris, Imogen Dexter, Fan Zhang, David R. Bull, Nantheera Anantrasirichai|<https://arxiv.org/pdf/2601.16780v1>|æ— |
|ğŸ“ æ›´æ–°|Self-supervised Learning of Echocardiographic Video Representations via Online Cluster Distillation|é€šè¿‡åœ¨çº¿èšç±»è’¸é¦è¿›è¡Œè¶…å£°å¿ƒåŠ¨å›¾è§†é¢‘è¡¨ç¤ºçš„è‡ªç›‘ç£å­¦ä¹ |Divyanshu Mishra, Mohammadreza Salehi, Pramit Saha, Olga Patey, Aris T. Papageorghiou, Yuki M. Asano, J. Alison Noble|<https://arxiv.org/pdf/2506.11777v3>|[ä»£ç ](https://github.com/mdivyanshu97/DISCOVR)|


### åŠ¨ä½œè¯†åˆ«ä¸ç†è§£ (Action Recognition & Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Affinity Contrastive Learning for Skeleton-based Human Activity Understanding|åŸºäºéª¨æ¶çš„äººç±»æ´»åŠ¨ç†è§£çš„äº²å’ŒåŠ›å¯¹æ¯”å­¦ä¹ |Hongda Liu, Yunfan Liu, Min Ren, Lin Sui, Yunlong Wang, Zhenan Sun|<https://arxiv.org/pdf/2601.16694v1>|[ä»£ç ](https://github.com/firework8/ACLNet.)|
|ğŸ“ æ›´æ–°|A Novel Deep Hybrid Framework with Ensemble-Based Feature Optimization for Robust Real-Time Human Activity Recognition|ä¸€ç§åŸºäºé›†æˆç‰¹å¾ä¼˜åŒ–çš„æ–°å‹æ·±åº¦æ··åˆæ¡†æ¶ï¼Œç”¨äºé²æ£’å®æ—¶äººç±»æ´»åŠ¨è¯†åˆ«|Wasi Ullah, Yasir Noman Khalid, Saddam Hussain Khan|<https://arxiv.org/pdf/2508.18695v3>|åˆ†æå¤±è´¥|


## è‡ªç›‘ç£ä¸è¡¨å¾å­¦ä¹  (Self-supervised & Representation Learning)


### å¯¹æ¯”å­¦ä¹ æ–¹æ³• (Contrastive Learning Methods)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Decoupling Multi-Contrast Super-Resolution: Self-Supervised Implicit Re-Representation for Unpaired Cross-Modal Synthesis|è§£è€¦å¤šå¯¹æ¯”åº¦è¶…åˆ†è¾¨ç‡ï¼šç”¨äºéé…å¯¹è·¨æ¨¡æ€åˆæˆçš„è‡ªç›‘ç£éšå¼é‡è¡¨ç¤º|Yinzhe Wu, Hongyu Rui, Fanwen Wang, Jiahao Huang, Zhenxuan Zhang, Haosen Zhang, Zi Wang, Guang Yang|<https://arxiv.org/pdf/2505.05855v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|CASP: Few-Shot Class-Incremental Learning with CLS Token Attention Steering Prompts|CASP: åŸºäº CLS Token Attention Steering Prompts çš„å°‘æ ·æœ¬ç±»å¢é‡å­¦ä¹ |Shuai Huang, Xuhan Lin, Yuwu Lu|<https://arxiv.org/pdf/2601.16773v1>|åˆ†æå¤±è´¥|


### æ©ç è‡ªç¼–ç  (Masked Autoencoding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Masked Face Recognition under Different Backbones|ä¸åŒBackboneä¸‹çš„Masked Face Recognition|Bo Zhang, Ming Zhang, Kun Wu, Lei Bian, Yi Lin|<https://arxiv.org/pdf/2601.16440v1>|æ— |


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Pretraining Frame Preservation in Autoregressive Video Memory Compression|è‡ªå›å½’è§†é¢‘å†…å­˜å‹ç¼©ä¸­çš„å¸§ä¿ç•™é¢„è®­ç»ƒ|Lvmin Zhang, Shengqu Cai, Muyang Li, Chong Zeng, Beijia Lu, Anyi Rao, Song Han, Gordon Wetzstein .etc.|<https://arxiv.org/pdf/2512.23851v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|No Validation, No Problem: Predicting Model Performance from a Single Gradient|No Validation, No Problem: ä»å•ä¸ªæ¢¯åº¦é¢„æµ‹æ¨¡å‹æ€§èƒ½|Fangzheng Wu, Brian Summa|<https://arxiv.org/pdf/2601.16874v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|UrbanIng-V2X: A Large-Scale Multi-Vehicle, Multi-Infrastructure Dataset Across Multiple Intersections for Cooperative Perception|UrbanIng-V2X: ä¸€ç§ç”¨äºååŒæ„ŸçŸ¥çš„è·¨å¤šä¸ªè·¯å£çš„å¤§è§„æ¨¡å¤šè½¦ã€å¤šåŸºç¡€è®¾æ–½æ•°æ®é›†|Karthikeyan Chandra Sekaran, Markus Geisler, Dominik RÃ¶ÃŸle, Adithya Mohan, Daniel Cremers, Wolfgang Utschick, Michael Botsch, Werner Huber .etc.|<https://arxiv.org/pdf/2510.23478v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|GAMMA: Generalizable Alignment via Multi-task and Manipulation-Augmented Training for AI-Generated Image Detection|GAMMAï¼šé€šè¿‡å¤šä»»åŠ¡å’Œæ“ä½œå¢å¼ºè®­ç»ƒå®ç°å¯æ³›åŒ–å¯¹é½çš„AIç”Ÿæˆå›¾åƒæ£€æµ‹|Haozhen Yan, Yan Hong, Suning Lang, Jiahui Zhan, Yikun Ji, Yujie Gao, Huijia Zhu, Jun Lan .etc.|<https://arxiv.org/pdf/2509.10250v2>|åˆ†æå¤±è´¥|


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|A Step to Decouple Optimization in 3DGS|è¿ˆå‘è§£è€¦ 3DGS ä¼˜åŒ–çš„ä¸€æ­¥|Renjie Ding, Yaonan Wang, Min Liu, Jialin Zhu, Jiazheng Wang, Jiahao Zhao, Wenting Shen, Feixiang He .etc.|<https://arxiv.org/pdf/2601.16736v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|AR-LIF: Adaptive reset leaky integrate-and-fire neuron for spiking neural networks|AR-LIF: ç”¨äº Spiking Neural Networks çš„è‡ªé€‚åº”å¤ä½ Leaky Integrate-and-Fire ç¥ç»å…ƒ|Zeyu Huang, Wei Meng, Quan Liu, Kun Chen, Li Ma|<https://arxiv.org/pdf/2507.20746v3>|[ä»£ç ](https://github.com/2ephyrus/AR-LIF.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|A Cosine Network for Image Super-Resolution|ç”¨äºå›¾åƒè¶…åˆ†è¾¨ç‡çš„ Cosine Network|Chunwei Tian, Chengyuan Zhang, Bob Zhang, Zhiwu Li, C. L. Philip Chen, David Zhang|<https://arxiv.org/pdf/2601.16413v1>|åˆ†æå¤±è´¥|


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|DeMark: A Query-Free Black-Box Attack on Deepfake Watermarking Defenses|[ç¿»è¯‘å¤±è´¥] DeMark: A Query-Free Black-Box Attack on Deepfake Watermarking Defenses|Wei Song, Zhenchang Xing, Liming Zhu, Yulei Sui, Jingling Xue|<https://arxiv.org/pdf/2601.16473v1>|åˆ†æå¤±è´¥|


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### åˆ†å¸ƒå¤–æ³›åŒ– (Out-of-distribution Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Flow Matching for Probabilistic Monocular 3D Human Pose Estimation|Flow Matching ç”¨äºæ¦‚ç‡æ€§å•ç›® 3D äººä½“å§¿æ€ä¼°è®¡|Cuong Le, PavlÃ³ Melnyk, Bastian Wandt, MÃ¥rten WadenbÃ¤ck|<https://arxiv.org/pdf/2601.16763v1>|æ— |
|ğŸ“ æ›´æ–°|ProSub: Probabilistic Open-Set Semi-Supervised Learning with Subspace-Based Out-of-Distribution Detection|ProSubï¼šåŸºäºå­ç©ºé—´ Out-of-Distribution æ£€æµ‹çš„æ¦‚ç‡æ€§å¼€é›†åŠç›‘ç£å­¦ä¹ |Erik Wallin, Lennart Svensson, Fredrik Kahl, Lars Hammarstrand|<https://arxiv.org/pdf/2407.11735v2>|[ä»£ç ](https://github.com/walline/prosub.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Towards contrast- and pathology-agnostic clinical fetal brain MRI segmentation using SynthSeg|Towards contrast- and pathology-agnostic clinicalèƒå„¿è„‘MRIåˆ†å‰²ä½¿ç”¨SynthSeg|Ziyao Shang, Misha Kaandorp, Kelly Payette, Marina Fernandez Garcia, Roxane Licandro, Georg Langs, Jordina Aviles Verdera, Jana Hutter .etc.|<https://arxiv.org/pdf/2504.10244v2>|åˆ†æå¤±è´¥|


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### é›¶/å°‘æ ·æœ¬æ³›åŒ– (Zero/Few-shot Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Evaluating Large Vision-language Models for Surgical Tool Detection|è¯„ä¼°ç”¨äºæ‰‹æœ¯å™¨æ¢°æ£€æµ‹çš„å¤§è§„æ¨¡è§†è§‰-è¯­è¨€æ¨¡å‹|Nakul Poudel, Richard Simon, Cristian A. Linte|<https://arxiv.org/pdf/2601.16895v1>|æ— |


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Calibrated Probabilistic Interpolation for GEDI Biomass|GEDI Biomass çš„æ ¡å‡†æ¦‚ç‡æ’å€¼|Robin Young, Srinivasan Keshav|<https://arxiv.org/pdf/2601.16834v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Revisiting the Ordering of Channel and Spatial Attention: A Comprehensive Study on Sequential and Parallel Designs|é‡æ–°å®¡è§†é€šé“æ³¨æ„åŠ›å’Œç©ºé—´æ³¨æ„åŠ›çš„é¡ºåºï¼šå…³äºé¡ºåºå’Œå¹¶è¡Œè®¾è®¡çš„å…¨é¢ç ”ç©¶|Zhongming Liu, Bingbing Jiang|<https://arxiv.org/pdf/2601.07310v2>|æ— |
|ğŸ†• å‘å¸ƒ|Expert Knowledge-Guided Decision Calibration for Accurate Fine-Grained Tree Species Classification|[ç¿»è¯‘å¤±è´¥] Expert Knowledge-Guided Decision Calibration for Accurate Fine-Grained Tree Species Classification|Chen Long, Dian Chen, Ruifei Ding, Zhe Chen, Zhen Dong, Bisheng Yang|<https://arxiv.org/pdf/2601.16498v1>|[ä»£ç ](https://github.com/WHU-USI3DV/TreeCLS.); åˆ†æå¤±è´¥|


## å…·èº«æ™ºèƒ½ä¸äº¤äº’è§†è§‰ (Embodied Intelligence & Interactive Vision)


### è§†è§‰å¯¼èˆªä¸è·¯å¾„è§„åˆ’ (Visual Navigation & Path Planning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|VisGym: Diverse, Customizable, Scalable Environments for Multimodal Agents|VisGym: é¢å‘å¤šæ¨¡æ€ Agent çš„å¤šæ ·åŒ–ã€å¯å®šåˆ¶ã€å¯æ‰©å±•ç¯å¢ƒ|Zirui Wang, Junyi Zhang, Jiaxin Ge, Long Lian, Letian Fu, Lisa Dunlap, Ken Goldberg, XuDong Wang .etc.|<https://arxiv.org/pdf/2601.16973v1>|[ä»£ç ](https://visgym.github.io/.); åˆ†æå¤±è´¥|


### è§†è§‰æ“ä½œä¸æ§åˆ¶ (Visual Manipulation & Control)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ReViP: Reducing False Completion in Vision-Language-Action Models with Vision-Proprioception Rebalance|ReViP: é€šè¿‡è§†è§‰-æœ¬ä½“æ„Ÿè§‰å†å¹³è¡¡å‡å°‘è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ä¸­çš„é”™è¯¯è¡¥å…¨|Zhuohao Li, Yinghao Li, Jian-Jian Jiang, Lang Zhou, Tianyu Zhang, Wei-Shi Zheng|<https://arxiv.org/pdf/2601.16667v1>|åˆ†æå¤±è´¥|


### ç›®æ ‡å¯¼å‘è§†è§‰å†³ç­– (Goal-oriented Visual Decision Making)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Coupled Physics-Gated Adaptation: Spatially Decoding Volumetric Photochemical Conversion in Complex 3D-Printed Objects|è€¦åˆç‰©ç†é—¨æ§è‡ªé€‚åº”ï¼šç©ºé—´è§£ç å¤æ‚3Dæ‰“å°ç‰©ä½“ä¸­çš„ä½“ç§¯å…‰åŒ–å­¦è½¬æ¢|Maryam Eftekharifar, Churun Zhang, Jialiang Wei, Xudong Cao, Hossein Heidari|<https://arxiv.org/pdf/2511.19913v2>|æ— |


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|IBISAgent: Reinforcing Pixel-Level Visual Reasoning in MLLMs for Universal Biomedical Object Referring and Segmentation|IBISAgent: åœ¨MLLMsä¸­å¼ºåŒ–åƒç´ çº§è§†è§‰æ¨ç†ä»¥å®ç°é€šç”¨ç”Ÿç‰©åŒ»å­¦å¯¹è±¡æŒ‡ä»£ä¸åˆ†å‰²|Yankai Jiang, Qiaoru Li, Binlu Xu, Haoran Sun, Chao Ding, Junting Dong, Yuxiang Cai, Xuhong Zhang .etc.|<https://arxiv.org/pdf/2601.03054v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|EMemBench: Interactive Benchmarking of Episodic Memory for VLM Agents|[ç¿»è¯‘å¤±è´¥] EMemBench: Interactive Benchmarking of Episodic Memory for VLM Agents|Xinze Li, Ziyue Zhu, Siyuan Liu, Yubo Ma, Yuhang Zang, Yixin Cao, Aixin Sun|<https://arxiv.org/pdf/2601.16690v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|TangramPuzzle: Evaluating Multimodal Large Language Models with Compositional Spatial Reasoning|TangramPuzzle: ä½¿ç”¨ç»„åˆç©ºé—´æ¨ç†è¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹|Daixian Liu, Jiayi Kuang, Yinghui Li, Yangning Li, Di Yin, Haoyu Cao, Xing Sun, Ying Shen .etc.|<https://arxiv.org/pdf/2601.16520v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Are We Using the Right Benchmark: An Evaluation Framework for Visual Token Compression Methods|[ç¿»è¯‘å¤±è´¥] Are We Using the Right Benchmark: An Evaluation Framework for Visual Token Compression Methods|Chenfei Liao, Wensong Wang, Zichen Wen, Xu Zheng, Yiyu Wang, Haocong He, Yuanhuiyi Lyu, Lutao Jiang .etc.|<https://arxiv.org/pdf/2510.07143v2>|æ— |
|ğŸ“ æ›´æ–°|Visual Autoregressive Transformers Must Use $Î©(n^2 d)$ Memory|Visual Autoregressive Transformers å¿…é¡»ä½¿ç”¨ $Î©(n^2 d)$ å†…å­˜|Yang Cao, Xiaoyu Li, Yekun Ke, Yingyu Liang, Zhenmei Shi, Zhao Song|<https://arxiv.org/pdf/2503.14881v2>|æ— |
|ğŸ†• å‘å¸ƒ|Order from Chaos: Physical World Understanding from Glitchy Gameplay Videos|Order from Chaos: ä» Glitchy Gameplay Videos ä¸­ç†è§£ Physical World|Meng Cao, Haoran Tang, Haoze Zhao, Mingfei Han, Ruyang Liu, Qiang Sun, Xiaojun Chang, Ian Reid .etc.|<https://arxiv.org/pdf/2601.16471v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|ResAgent: Entropy-based Prior Point Discovery and Visual Reasoning for Referring Expression Segmentation|ResAgent: åŸºäºç†µçš„å…ˆéªŒç‚¹å‘ç°ä¸è§†è§‰æ¨ç†ç”¨äºæŒ‡ä»£è¡¨è¾¾åˆ†å‰²|Yihao Wang, Jusheng Zhang, Ziyi Tang, Keze Wang, Meng Yang|<https://arxiv.org/pdf/2601.16394v1>|åˆ†æå¤±è´¥|


### è·¨æ¨¡æ€æ£€ç´¢ä¸åŒ¹é… (Cross-modal Retrieval & Matching)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|X-Aligner: Composed Visual Retrieval without the Bells and Whistles|[ç¿»è¯‘å¤±è´¥] X-Aligner: Composed Visual Retrieval without the Bells and Whistles|Yuqian Zheng, Mariana-Iuliana Georgescu|<https://arxiv.org/pdf/2601.16582v1>|æ— |


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Scribble-Supervised Medical Image Segmentation with Dynamic Teacher Switching and Hierarchical Consistency|åŸºäºåŠ¨æ€æ•™å¸ˆåˆ‡æ¢ä¸å±‚æ¬¡ä¸€è‡´æ€§çš„æ¶‚é¸¦ç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²|Thanh-Huy Nguyen, Hoang-Loc Cao, Dat T. Chung, Mai-Anh Vu, Thanh-Minh Nguyen, Minh Le, Phat K. Huynh, Ulas Bagci|<https://arxiv.org/pdf/2601.14563v3>|æ— |
|ğŸ†• å‘å¸ƒ|Domain-invariant Mixed-domain Semi-supervised Medical Image Segmentation with Clustered Maximum Mean Discrepancy Alignment|åŸºäºèšç±»æœ€å¤§å‡å€¼å·®å¼‚å¯¹é½çš„åŸŸä¸å˜æ··åˆåŸŸåŠç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²|Ba-Thinh Lam, Thanh-Huy Nguyen, Hoang-Thien Nguyen, Quang-Khai Bui-Tran, Nguyen Lan Vi Vu, Phat K. Huynh, Ulas Bagci, Min Xu|<https://arxiv.org/pdf/2601.16954v1>|æ— |
|ğŸ“ æ›´æ–°|DeepShield: Fortifying Deepfake Video Detection with Local and Global Forgery Analysis|DeepShield: åˆ©ç”¨å±€éƒ¨å’Œå…¨å±€ä¼ªé€ åˆ†æå¼ºåŒ– Deepfake è§†é¢‘æ£€æµ‹|Yinqi Cai, Jichang Li, Zhaolun Li, Weikai Chen, Rushi Lan, Xi Xie, Xiaonan Luo, Guanbin Li|<https://arxiv.org/pdf/2510.25237v2>|[ä»£ç ](https://github.com/lijichang/DeepShield.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Using Shadows in Circular Synthetic Aperture Sonar Imaging for Target Analysis|åˆ©ç”¨åœ†å½¢åˆæˆå­”å¾„å£°çº³æˆåƒä¸­çš„é˜´å½±è¿›è¡Œç›®æ ‡åˆ†æ|Yann Le Gall, Nicolas Burlet, Mathieu Simon, Fabien Novella, Samantha Dugelay, Jean-Philippe Malkasse|<https://arxiv.org/pdf/2601.16733v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|A Lightweight Medical Image Classification Framework via Self-Supervised Contrastive Learning and Quantum-Enhanced Feature Modeling|ä¸€ç§åŸºäºè‡ªç›‘ç£å¯¹æ¯”å­¦ä¹ å’Œé‡å­å¢å¼ºç‰¹å¾å»ºæ¨¡çš„è½»é‡çº§åŒ»å­¦å›¾åƒåˆ†ç±»æ¡†æ¶|Jingsong Xia, Siqi Wang|<https://arxiv.org/pdf/2601.16608v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Efficient Multi-scale Masked Autoencoders with Hybrid-Attention Mechanism for Breast Lesion Classification|åŸºäºæ··åˆæ³¨æ„åŠ›æœºåˆ¶çš„é«˜æ•ˆå¤šå°ºåº¦æ©ç è‡ªç¼–ç å™¨ç”¨äºä¹³è…ºç—…ç¶åˆ†ç±»|Hung Q. Vo, Pengyu Yuan, Zheng Yin, Kelvin K. Wong, Chika F. Ezeana, Son T. Ly, Hien V. Nguyen, Stephen T. C. Wong|<https://arxiv.org/pdf/2503.07157v4>|æ— |
|ğŸ†• å‘å¸ƒ|On The Robustness of Foundational 3D Medical Image Segmentation Models Against Imprecise Visual Prompts|è®ºåŸºç¡€3DåŒ»å­¦å›¾åƒåˆ†å‰²æ¨¡å‹å¯¹ä¸ç²¾ç¡®è§†è§‰æç¤ºçš„é²æ£’æ€§|Soumitri Chattopadhyay, Basar Demir, Marc Niethammer|<https://arxiv.org/pdf/2601.16383v1>|[ä»£ç ](https://github.com/ucsdbiag/Prompt-Robustness-MedSegFMs)|


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|VALISENS: A Validated Innovative Multi-Sensor System for Cooperative Automated Driving|VALISENS: ä¸€ç§ç”¨äºååŒè‡ªåŠ¨é©¾é©¶çš„ç»è¿‡éªŒè¯çš„åˆ›æ–°å‹å¤šä¼ æ„Ÿå™¨ç³»ç»Ÿ|Lei Wan, Prabesh Gupta, Andreas Eich, Marcel Kettelgerdes, Hannan Ejaz Keen, Michael KlÃ¶ppel-Gersdorf, Alexey Vinel|<https://arxiv.org/pdf/2505.06980v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|HA2F: Dual-module Collaboration-Guided Hierarchical Adaptive Aggregation Framework for Remote Sensing Change Detection|HA2F: ç”¨äºé¥æ„Ÿå˜åŒ–æ£€æµ‹çš„åŒæ¨¡å—ååŒå¼•å¯¼åˆ†å±‚è‡ªé€‚åº”èšåˆæ¡†æ¶|Shuying Li, Yuchen Wang, San Zhang, Chuang Yang|<https://arxiv.org/pdf/2601.16573v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|DCCS-Det: Directional Context and Cross-Scale-Aware Detector for Infrared Small Target|DCCS-Det: ç”¨äºçº¢å¤–å°ç›®æ ‡çš„æ–¹å‘ä¸Šä¸‹æ–‡ä¸è·¨å°ºåº¦æ„ŸçŸ¥æ£€æµ‹å™¨|Shuying Li, Qiang Ma, San Zhang, Chuang Yang|<https://arxiv.org/pdf/2601.16428v1>|æ— |
|ğŸ†• å‘å¸ƒ|Learning Domain Knowledge in Multimodal Large Language Models through Reinforcement Fine-Tuning|é€šè¿‡å¼ºåŒ–å¾®è°ƒåœ¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸­å­¦ä¹ é¢†åŸŸçŸ¥è¯†|Qinglong Cao, Yuntian Chen, Chao Ma, Xiaokang Yang|<https://arxiv.org/pdf/2601.16419v1>|æ— |


### å·¥ä¸šè§†è§‰æ£€æµ‹ (Industrial Visual Inspection)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|VTFusion: A Vision-Text Multimodal Fusion Network for Few-Shot Anomaly Detection|[ç¿»è¯‘å¤±è´¥] VTFusion: A Vision-Text Multimodal Fusion Network for Few-Shot Anomaly Detection|Yuxin Jiang, Yunkang Cao, Yuqi Cheng, Yiheng Zhang, Weiming Shen|<https://arxiv.org/pdf/2601.16381v1>|æ— |


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Curated endoscopic retrograde cholangiopancreatography images dataset|ç²¾é€‰çš„ç»å†…é•œé€†è¡Œèƒ°èƒ†ç®¡é€ å½±æœ¯å›¾åƒæ•°æ®é›†|Alda JoÃ£o Andrade, MÃ³nica Martins, AndrÃ© Ferreira, TarcÃ­sio AraÃºjo, LuÃ­s Lopes, Victor Alves|<https://arxiv.org/pdf/2601.16759v1>|æ— |
|ğŸ†• å‘å¸ƒ|Semi-Supervised Hierarchical Open-Set Classification|[ç¿»è¯‘å¤±è´¥] Semi-Supervised Hierarchical Open-Set Classification|Erik Wallin, Fredrik Kahl, Lars Hammarstrand|<https://arxiv.org/pdf/2601.16541v1>|[ä»£ç ](https://github.com/walline/semihoc.); åˆ†æå¤±è´¥|

