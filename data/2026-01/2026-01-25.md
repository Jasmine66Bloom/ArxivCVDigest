## [UPDATED!] **2026-01-25** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Inconsistency Masks: Harnessing Model Disagreement for Stable Semi-Supervised Segmentation|Inconsistency Masksï¼šåˆ©ç”¨æ¨¡å‹åˆ†æ­§å®ç°ç¨³å®šçš„åŠç›‘ç£åˆ†å‰²|Michael R. H. Vorndran, Bernhard F. Roeck|<https://arxiv.org/pdf/2401.14387v3>|[ä»£ç ](https://github.com/MichaelVorndran/InconsistencyMasks)|
|ğŸ“ æ›´æ–°|Motion Focus Recognition in Fast-Moving Egocentric Video|Fast-Moving Egocentric Video ä¸­çš„ Motion Focus Recognition|Si-En Hong, James Tribble, Alexander Lake, Hao Wang, Chaoyi Zhou, Ashish Bastola, Siyu Huang, Eisa Chaudhary .etc.|<https://arxiv.org/pdf/2601.07154v2>|æ— |


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|EEG Foundation Models: Progresses, Benchmarking, and Open Problems|EEG Foundation Modelsï¼šè¿›å±•ã€åŸºå‡†æµ‹è¯•ä¸å¼€æ”¾é—®é¢˜|Dingkun Liu, Yuheng Chen, Zhu Chen, Zhenyao Cui, Yaozhi Wen, Jiayu An, Jingwei Luo, Dongrui Wu|<https://arxiv.org/pdf/2601.17883v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Quran-MD: A Fine-Grained Multilingual Multimodal Dataset of the Quran|Quran-MD: ä¸€ä¸ªç»†ç²’åº¦çš„å¤šè¯­è¨€å¤šæ¨¡æ€å¤å…°ç»æ•°æ®é›†|Muhammad Umar Salman, Mohammad Areeb Qazi, Mohammed Talha Alam|<https://arxiv.org/pdf/2601.17880v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|PVLM: Parsing-Aware Vision Language Model with Dynamic Contrastive Learning for Zero-Shot Deepfake Attribution|PVLM: åŸºäºåŠ¨æ€å¯¹æ¯”å­¦ä¹ çš„è§£ææ„ŸçŸ¥è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œç”¨äºZero-Shot Deepfake Attribution|Yaning Zhang, Jiahe Zhang, Chunjie Ma, Weili Guan, Tian Gan, Zan Gao|<https://arxiv.org/pdf/2504.14129v3>|æ— |
|ğŸ†• å‘å¸ƒ|AVMeme Exam: A Multimodal Multilingual Multicultural Benchmark for LLMs' Contextual and Cultural Knowledge and Thinking|AVMeme Examï¼šç”¨äºLLMä¸Šä¸‹æ–‡ä¸æ–‡åŒ–çŸ¥è¯†åŠæ€ç»´çš„å¤šæ¨¡æ€å¤šè¯­è¨€å¤šæ–‡åŒ–åŸºå‡†|Xilin Jiang, Qiaolin Wang, Junkai Wu, Xiaomin He, Zhongweiyang Xu, Yinghao Ma, Minshuo Piao, Kaiyi Yang .etc.|<https://arxiv.org/pdf/2601.17645v1>|åˆ†æå¤±è´¥|


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|BeetleVerse: A Study on Taxonomic Classification of Ground Beetles|BeetleVerse: å…³äºGround Beetlesåˆ†ç±»å­¦åˆ†ç±»çš„ç ”ç©¶|S M Rayeed, Alyson East, Samuel Stevens, Sydne Record, Charles V Stewart|<https://arxiv.org/pdf/2504.13393v3>|æ— |


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### ç›®æ ‡æ£€æµ‹ä¸å®šä½ (Object Detection & Localization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Cross-Level Sensor Fusion with Object Lists via Transformer for 3D Object Detection|åŸºäºTransformerçš„è·¨å±‚çº§ä¼ æ„Ÿå™¨åˆ—è¡¨èåˆç”¨äº3Dç›®æ ‡æ£€æµ‹|Xiangzhong Liu, Jiajie Zhang, Hao Shen|<https://arxiv.org/pdf/2512.12884v2>|åˆ†æå¤±è´¥|


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Strip-Fusion: Spatiotemporal Fusion for Multispectral Pedestrian Detection|Strip-Fusion: ç”¨äºå¤šå…‰è°±è¡Œäººæ£€æµ‹çš„æ—¶ç©ºèåˆ|Asiegbu Miracle Kanu-Asiegbu, Nitin Jotwani, Xiaoxiao Du|<https://arxiv.org/pdf/2601.18008v1>|åˆ†æå¤±è´¥|


### å›¾åƒåˆ†ç±»ä¸è¯†åˆ« (Image Classification & Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Demographic-aware fine-grained classification of pediatric wrist fractures|Demographic-awareçš„å„¿ç«¥æ‰‹è…•éª¨æŠ˜ç»†ç²’åº¦åˆ†ç±»|Ammar Ahmed, Ali Shariq Imran, Zenun Kastrati, Sher Muhammad Daudpota|<https://arxiv.org/pdf/2507.12964v6>|åˆ†æå¤±è´¥|


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MV-S2V: Multi-View Subject-Consistent Video Generation|[ç¿»è¯‘å¤±è´¥] MV-S2V: Multi-View Subject-Consistent Video Generation|Ziyang Song, Xinyu Gong, Bangya Liu, Zelin Zhao|<https://arxiv.org/pdf/2601.17756v2>|[ä»£ç ](https://szy-young.github.io/mv-s2v)|
|ğŸ“ æ›´æ–°|Mitigating the Modality Gap: Few-Shot Out-of-Distribution Detection with Multi-modal Prototypes and Image Bias Estimation|ç¼“è§£æ¨¡æ€å·®è·ï¼šåŸºäºå¤šæ¨¡æ€åŸå‹å’Œå›¾åƒåå·®ä¼°è®¡çš„å°‘æ ·æœ¬åˆ†å¸ƒå¤–æ£€æµ‹|Yimu Wang, Evelien Riddell, Adrian Chow, Sean Sedwards, Krzysztof Czarnecki|<https://arxiv.org/pdf/2502.00662v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|RemEdit: Efficient Diffusion Editing with Riemannian Geometry|RemEdit: åŸºäº Riemannian Geometry çš„é«˜æ•ˆ Diffusion Editing|Eashan Adhikarla, Brian D. Davison|<https://arxiv.org/pdf/2601.17927v1>|[ä»£ç ](https://github.com/eashanadhikarla/RemEdit.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Photography Perspective Composition: Towards Aesthetic Perspective Recommendation|æ‘„å½±è§†è§’æ„å›¾ï¼šè¿ˆå‘ç¾å­¦è§†è§’æ¨è|Lujian Yao, Siming Zheng, Xinbin Yuan, Zhuoxuan Cai, Pu Wu, Jinwei Chen, Bo Li, Peng-Tao Jiang|<https://arxiv.org/pdf/2505.20655v5>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Unified-EGformer: Exposure Guided Lightweight Transformer for Mixed-Exposure Image Enhancement|Unified-EGformer: æ›å…‰å¼•å¯¼çš„è½»é‡çº§Transformerç”¨äºæ··åˆæ›å…‰å›¾åƒå¢å¼º|Eashan Adhikarla, Kai Zhang, Rosaura G. VidalMata, Manjushree Aithal, Nikhil Ambha Madhusudhana, John Nicholson, Lichao Sun, Brian D. Davison|<https://arxiv.org/pdf/2407.13170v2>|æ— |
|ğŸ“ æ›´æ–°|Image2Garment: Simulation-ready Garment Generation from a Single Image|Image2Garment: ä»å•å¼ å›¾åƒç”Ÿæˆå¯ç”¨äºä»¿çœŸçš„æœè£…|Selim Emir Can, Jan Ackermann, Kiyohiro Nakayama, Ruofan Liu, Tong Wu, Yang Zheng, Hugo Bertiche, Menglei Chai .etc.|<https://arxiv.org/pdf/2601.09658v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Flatten The Complex: Joint B-Rep Generation via Compositional $k$-Cell Particles|Flatten The Complex: é€šè¿‡ç»„åˆå¼ $k$-Cell Particles çš„è”åˆ B-Rep ç”Ÿæˆ|Junran Lu, Yuanqi Li, Hengji Li, Jie Guo, Yanwen Guo|<https://arxiv.org/pdf/2601.17733v1>|æ— |
|ğŸ“ æ›´æ–°|GeneMAN: Generalizable Single-Image 3D Human Reconstruction from Multi-Source Human Data|GeneMAN: åŸºäºå¤šæºäººä½“æ•°æ®çš„å¯æ³›åŒ–å•å›¾åƒ3Däººä½“é‡å»º|Wentao Wang, Hang Ye, Fangzhou Hong, Xue Yang, Jianfu Zhang, Yizhou Wang, Ziwei Liu, Liang Pan|<https://arxiv.org/pdf/2411.18624v3>|æ— |
|ğŸ“ æ›´æ–°|DragNeXt: Rethinking Drag-Based Image Editing|DragNeXt: é‡æ–°æ€è€ƒåŸºäºæ‹–æ‹½çš„å›¾åƒç¼–è¾‘|Yuan Zhou, Junbao Zhou, Qingshan Xu, Kesen Zhao, Yuxuan Wang, Hao Fei, Richang Hong, Hanwang Zhang|<https://arxiv.org/pdf/2506.07611v2>|æ— |
|ğŸ†• å‘å¸ƒ|Training-Free Text-to-Image Compositional Food Generation via Prompt Grafting|é€šè¿‡Prompt Graftingå®ç°å…è®­ç»ƒçš„Text-to-Imageç»„åˆé£Ÿç‰©ç”Ÿæˆ|Xinyue Pan, Yuhao Chen, Fengqing Zhu|<https://arxiv.org/pdf/2601.17666v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|SPACE-CLIP: Spatial Perception via Adaptive CLIP Embeddings for Monocular Depth Estimation|SPACE-CLIP: åŸºäºè‡ªé€‚åº” CLIP åµŒå…¥çš„ç©ºé—´æ„ŸçŸ¥ç”¨äºå•ç›®æ·±åº¦ä¼°è®¡|Taewan Cho, Taeryang Kim, Andrew Jaeyong Choi|<https://arxiv.org/pdf/2601.17657v1>|[ä»£ç ](https://github.com/taewan2002/space-clip); åˆ†æå¤±è´¥|


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Streaming-dLLM: Accelerating Diffusion LLMs via Suffix Pruning and Dynamic Decoding|Streaming-dLLMï¼šé€šè¿‡åç¼€å‰ªæå’ŒåŠ¨æ€è§£ç åŠ é€Ÿæ‰©æ•£ LLM|Zhongyu Xiao, Zhiwei Hao, Jianyuan Guo, Yong Luo, Jia Liu, Jie Xu, Han Hu|<https://arxiv.org/pdf/2601.17917v2>|[ä»£ç ](https://github.com/xiaoshideta/Streaming-dLLM.)|
|ğŸ†• å‘å¸ƒ|VidLaDA: Bidirectional Diffusion Large Language Models for Efficient Video Understanding|VidLaDA: ç”¨äºé«˜æ•ˆè§†é¢‘ç†è§£çš„åŒå‘æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹|Zhihao He, Tieyuan Chen, Kangyu Wang, Ziran Qin, Yang Shao, Chaofan Gan, Shijie Li, Zuxuan Wu .etc.|<https://arxiv.org/pdf/2601.17868v1>|[ä»£ç ](https://github.com/ziHoHe/VidLaDA.)|
|ğŸ†• å‘å¸ƒ|SynMind: Reducing Semantic Hallucination in fMRI-Based Image Reconstruction|SynMind: å‡å°‘åŸºäºfMRIçš„å›¾åƒé‡å»ºä¸­çš„è¯­ä¹‰å¹»è§‰|Lan Yang, Minghan Yang, Ke Li, Honggang Zhang, Kaiyue Pang, Yi-Zhe Song|<https://arxiv.org/pdf/2601.17857v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|VAE-REPA: Variational Autoencoder Representation Alignment for Efficient Diffusion Training|VAE-REPA: ç”¨äºé«˜æ•ˆæ‰©æ•£è®­ç»ƒçš„å˜åˆ†è‡ªç¼–ç å™¨è¡¨ç¤ºå¯¹é½|Mengmeng Wang, Dengyang Jiang, Liuzhuozheng Li, Yucheng Lin, Guojiang Shen, Xiangjie Kong, Yong Liu, Guang Dai .etc.|<https://arxiv.org/pdf/2601.17830v1>|æ— |
|ğŸ†• å‘å¸ƒ|ViTCoP: Accelerating Large Vision-Language Models via Visual and Textual Semantic Collaborative Pruning|ViTCoPï¼šé€šè¿‡è§†è§‰å’Œæ–‡æœ¬è¯­ä¹‰ååŒå‰ªæåŠ é€Ÿå¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹|Wen Luo, Peng Chen, Xiaotao Huang, LiQun Huang|<https://arxiv.org/pdf/2601.17818v1>|æ— |
|ğŸ“ æ›´æ–°|Communicate Less, Synthesize the Rest: Latency-aware Intent-based Generative Semantic Multicasting with Diffusion Models|å°‘é€šä¿¡ï¼Œå…¶ä½™åˆæˆï¼šåŸºäº Diffusion Models çš„æ—¶å»¶æ„ŸçŸ¥æ„å›¾å¼ç”Ÿæˆè¯­ä¹‰å¤šæ’­|Xinkai Liu, Mahdi Boloursaz Mashhadi, Li Qiao, Yi Ma, Rahim Tafazolli, Mehdi Bennis|<https://arxiv.org/pdf/2411.02334v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|A Computational Approach to Visual Metonymy|ä¸€ç§è§†è§‰è½¬å–»çš„è®¡ç®—æ–¹æ³•|Saptarshi Ghosh, Linfeng Liu, Tianyu Jiang|<https://arxiv.org/pdf/2601.17706v1>|[ä»£ç ](https://github.com/cincynlp/ViMET.); åˆ†æå¤±è´¥|


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|The Script is All You Need: An Agentic Framework for Long-Horizon Dialogue-to-Cinematic Video Generation|[ç¿»è¯‘å¤±è´¥] The Script is All You Need: An Agentic Framework for Long-Horizon Dialogue-to-Cinematic Video Generation|Chenyu Mu, Xin He, Qu Yang, Wanshun Chen, Jiadi Yao, Huang Liu, Zihao Yi, Bo Zhao .etc.|<https://arxiv.org/pdf/2601.17737v2>|æ— |
|ğŸ†• å‘å¸ƒ|From Specialist to Generalist: Unlocking SAM's Learning Potential on Unlabeled Medical Images|ä»ä¸“å®¶åˆ°é€šæ‰ï¼šè§£é” SAM åœ¨æœªæ ‡æ³¨åŒ»å­¦å›¾åƒä¸Šçš„å­¦ä¹ æ½œåŠ›|Vi Vu, Thanh-Huy Nguyen, Tien-Thinh Nguyen, Ba-Thinh Lam, Hoang-Thien Nguyen, Tianyang Wang, Xingjian Li, Min Xu|<https://arxiv.org/pdf/2601.17934v1>|[ä»£ç ](https://github.com/vnlvi2k3/SC-SAM.)|


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|StyMam: A Mamba-Based Generator for Artistic Style Transfer|StyMam: åŸºäº Mamba çš„è‰ºæœ¯é£æ ¼è¿ç§»ç”Ÿæˆå™¨|Zhou Hong, Ning Dong, Yicheng Di, Xiaolong Xu, Rongsheng Hu, Yihua Shao, Run Ling, Yun Wang .etc.|<https://arxiv.org/pdf/2601.12954v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|StyleDecoupler: Generalizable Artistic Style Disentanglement|StyleDecoupler: å¯æ³›åŒ–çš„è‰ºæœ¯é£æ ¼è§£è€¦|Zexi Jia, Jinchao Zhang, Jie Zhou|<https://arxiv.org/pdf/2601.17697v1>|æ— |


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Geometry-Grounded Gaussian Splatting|[ç¿»è¯‘å¤±è´¥] Geometry-Grounded Gaussian Splatting|Baowen Zhang, Chenxing Jiang, Heng Li, Shaojie Shen, Ping Tan|<https://arxiv.org/pdf/2601.17835v2>|æ— |
|ğŸ“ æ›´æ–°|FLARE: Feed-forward Geometry, Appearance and Camera Estimation from Uncalibrated Sparse Views|FLARE: æ¥è‡ªæœªæ ‡å®šç¨€ç–è§†è§’çš„å‰é¦ˆå‡ ä½•ã€å¤–è§‚å’Œç›¸æœºä¼°è®¡|Shangzhan Zhang, Jianyuan Wang, Yinghao Xu, Nan Xue, Christian Rupprecht, Xiaowei Zhou, Yujun Shen, Gordon Wetzstein|<https://arxiv.org/pdf/2502.12138v7>|[ä»£ç ](https://zhanghe3z.github.io/FLARE)|
|ğŸ†• å‘å¸ƒ|PEAfowl: Perception-Enhanced Multi-View Vision-Language-Action for Bimanual Manipulation|[ç¿»è¯‘å¤±è´¥] PEAfowl: Perception-Enhanced Multi-View Vision-Language-Action for Bimanual Manipulation|Qingyu Fan, Zhaoxiang Li, Yi Lu, Wang Chen, Qiu Shen, Xiao-xiao Long, Yinghao Cai, Tao Lu .etc.|<https://arxiv.org/pdf/2601.17885v1>|[ä»£ç ](https://peafowlvla.github.io/.)|
|ğŸ†• å‘å¸ƒ|MV-SAM: Multi-view Promptable Segmentation using Pointmap Guidance|MV-SAM: ä½¿ç”¨ Pointmap Guidance çš„ Multi-view Promptable Segmentation|Yoonwoo Jeong, Cheng Sun, Yu-Chiang Frank Wang, Minsu Cho, Jaesung Choe|<https://arxiv.org/pdf/2601.17866v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Agreement-Driven Multi-View 3D Reconstruction for Live Cattle Weight Estimation|åŸºäºä¸€è‡´æ€§é©±åŠ¨çš„å¤šè§†è§’ 3D é‡å»ºç”¨äºæ´»ç‰›ä½“é‡ä¼°è®¡|Rabin Dulal, Wenfeng Jia, Lihong Zheng, Jane Quinn|<https://arxiv.org/pdf/2601.17791v1>|åˆ†æå¤±è´¥|


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|MorphiNet: A Graph Subdivision Network for Adaptive Bi-ventricle Surface Reconstruction|MorphiNet: ç”¨äºè‡ªé€‚åº”åŒå¿ƒå®¤è¡¨é¢é‡å»ºçš„å›¾ç»†åˆ†ç½‘ç»œ|Yu Deng, Yiyang Xu, Linglong Qian, CharlÃ¨ne Mauger, Anastasia Nasopoulou, Steven Williams, Michelle Williams, Steven Niederer .etc.|<https://arxiv.org/pdf/2412.10985v2>|æ— |
|ğŸ†• å‘å¸ƒ|Video Compression with Hierarchical Temporal Neural Representation|åŸºäºåˆ†å±‚æ—¶åºç¥ç»è¡¨ç¤ºçš„è§†é¢‘å‹ç¼©|Jun Zhu, Xinfeng Zhang, Lv Tang, Junhao Jiang, Gai Zhang, Jia Wang|<https://arxiv.org/pdf/2601.17743v1>|æ— |
|ğŸ†• å‘å¸ƒ|Frequency-aware Neural Representation for Videos|[ç¿»è¯‘å¤±è´¥] Frequency-aware Neural Representation for Videos|Jun Zhu, Xinfeng Zhang, Lv Tang, Junhao Jiang, Gai Zhang, Jia Wang|<https://arxiv.org/pdf/2601.17741v1>|æ— |
|ğŸ†• å‘å¸ƒ|Implicit Neural Representation-Based Continuous Single Image Super Resolution: An Empirical Study|åŸºäºImplicit Neural Representationçš„è¿ç»­å•å›¾åƒè¶…åˆ†è¾¨ç‡ï¼šä¸€é¡¹å®è¯ç ”ç©¶|Tayyab Nasir, Daochang Liu, Ajmal Mian|<https://arxiv.org/pdf/2601.17723v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Advancing Structured Priors for Sparse-Voxel Surface Reconstruction|æ¨è¿›ç¨€ç–ä½“ç´ è¡¨é¢é‡å»ºçš„ç»“æ„åŒ–å…ˆéªŒ|Ting-Hsun Chi, Chu-Rong Chen, Chi-Tun Hsu, Hsuan-Ting Lin, Sheng-Yu Huang, Cheng Sun, Yu-Chiang Frank Wang|<https://arxiv.org/pdf/2601.17720v1>|æ— |
|ğŸ“ æ›´æ–°|TreeDGS: Aerial Gaussian Splatting for Distant DBH Measurement|TreeDGS: ç”¨äºè¿œç«¯ DBH æµ‹é‡çš„èˆªç©º Gaussian Splatting|Belal Shaheen, Minh-Hieu Nguyen, Bach-Thuan Bui, Shubham, Tim Wu, Michael Fairley, Matthew David Zane, Michael Wu .etc.|<https://arxiv.org/pdf/2601.12823v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Unified Cross-Modal Attention-Mixer Based Structural-Functional Connectomics Fusion for Neuropsychiatric Disorder Diagnosis|åŸºäºç»Ÿä¸€è·¨æ¨¡æ€ Attention-Mixer çš„ç»“æ„-åŠŸèƒ½è¿æ¥ç»„å­¦èåˆç”¨äºç¥ç»ç²¾ç¥ç–¾ç—…è¯Šæ–­|Badhan Mazumder, Lei Wu, Vince D. Calhoun, Dong Hye Ye|<https://arxiv.org/pdf/2505.15139v2>|æ— |


## è‡ªç›‘ç£ä¸è¡¨å¾å­¦ä¹  (Self-supervised & Representation Learning)


### å¯¹æ¯”å­¦ä¹ æ–¹æ³• (Contrastive Learning Methods)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Cross-domain EEG-based Emotion Recognition with Contrastive Learning|åŸºäºå¯¹æ¯”å­¦ä¹ çš„è·¨åŸŸ EEG æƒ…æ„Ÿè¯†åˆ«|Rui Yan, Yibo Li, Han Ding, Fei Wang|<https://arxiv.org/pdf/2511.05293v2>|[ä»£ç ](https://github.com/Departure2021/EmotionCLIP.)|


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MorphXAI: An Explainable Framework for Morphological Analysis of Parasites in Blood Smear Images|MorphXAIï¼šè¡€æ¶‚ç‰‡å›¾åƒä¸­å¯„ç”Ÿè™«å½¢æ€åˆ†æçš„å¯è§£é‡Šæ¡†æ¶|Aqsa Yousaf, Sint Sint Win, Megan Coffee, Habeeb Olufowobi|<https://arxiv.org/pdf/2601.18001v1>|æ— |
|ğŸ“ æ›´æ–°|Vision-Proprioception Fusion with Mamba2 in End-to-End Reinforcement Learning for Motion Control|åŸºäºMamba2çš„è§†è§‰-æœ¬ä½“æ„ŸçŸ¥èåˆåœ¨ç”¨äºè¿åŠ¨æ§åˆ¶çš„ç«¯åˆ°ç«¯å¼ºåŒ–å­¦ä¹ ä¸­çš„åº”ç”¨|Xiaowen Tao, Yinuo Wang, Jinzhao Zhou|<https://arxiv.org/pdf/2509.07593v2>|åˆ†æå¤±è´¥|


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Systematic Characterization of Minimal Deep Learning Architectures: A Unified Analysis of Convergence, Pruning, and Quantization|æœ€å°æ·±åº¦å­¦ä¹ æ¶æ„çš„ç³»ç»Ÿæ€§è¡¨å¾ï¼šæ”¶æ•›ã€å‰ªæä¸é‡åŒ–çš„ç»Ÿä¸€åˆ†æ|Ziwei Zheng, Huizhi Liang, Vaclav Snasel, Vito Latora, Panos Pardalos, Giuseppe Nicosia, Varun Ojha|<https://arxiv.org/pdf/2601.17987v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|UPLiFT: Efficient Pixel-Dense Feature Upsampling with Local Attenders|UPLiFT: ä½¿ç”¨ Local Attenders çš„é«˜æ•ˆåƒç´ å¯†é›†ç‰¹å¾ä¸Šé‡‡æ ·|Matthew Walmer, Saksham Suri, Anirud Aggarwal, Abhinav Shrivastava|<https://arxiv.org/pdf/2601.17950v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|BanglaRobustNet: A Hybrid Denoising-Attention Architecture for Robust Bangla Speech Recognition|BanglaRobustNet: ä¸€ç§ç”¨äºé²æ£’Banglaè¯­éŸ³è¯†åˆ«çš„æ··åˆå»å™ªæ³¨æ„åŠ›æ¶æ„|Md Sazzadul Islam Ridoy, Mubaswira Ibnat Zidney, Sumi Akter, Md. Aminur Rahman|<https://arxiv.org/pdf/2601.17679v1>|æ— |
|ğŸ“ æ›´æ–°|Physics-Guided Multi-View Graph Neural Network for Schizophrenia Classification via Structural-Functional Coupling|åŸºäºç»“æ„-åŠŸèƒ½è€¦åˆçš„ç²¾ç¥åˆ†è£‚ç—‡åˆ†ç±»çš„ç‰©ç†å¼•å¯¼å¤šè§†å›¾å›¾ç¥ç»ç½‘ç»œ|Badhan Mazumder, Ayush Kanyal, Lei Wu, Vince D. Calhoun, Dong Hye Ye|<https://arxiv.org/pdf/2505.15135v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|NeuroKoop: Neural Koopman Fusion of Structural-Functional Connectomes for Identifying Prenatal Drug Exposure in Adolescents|NeuroKoopï¼šç”¨äºè¯†åˆ«é’å°‘å¹´äº§å‰è¯ç‰©æš´éœ²çš„ç»“æ„-åŠŸèƒ½è¿æ¥ä½“çš„Neural Koopmanèåˆ|Badhan Mazumder, Aline Kotoski, Vince D. Calhoun, Dong Hye Ye|<https://arxiv.org/pdf/2508.16414v2>|åˆ†æå¤±è´¥|


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|FlowMorph: Physics-Consistent Self-Supervision for Label-Free Single-Cell Mechanics in Microfluidic Videos|FlowMorphï¼šç”¨äºå¾®æµæ§è§†é¢‘ä¸­æ— æ ‡è®°å•ç»†èƒåŠ›å­¦çš„ç‰©ç†ä¸€è‡´æ€§è‡ªç›‘ç£|Bora Yimenicioglu, Vishal Manikanden|<https://arxiv.org/pdf/2601.17947v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Dissipative Learning: A Framework for Viable Adaptive Systems|[ç¿»è¯‘å¤±è´¥] Dissipative Learning: A Framework for Viable Adaptive Systems|Laurent Caraffa|<https://arxiv.org/pdf/2601.17933v1>|æ— |
|ğŸ“ æ›´æ–°|MoE3D: A Mixture-of-Experts Module for 3D Reconstruction|MoE3D: ç”¨äº3D Reconstructionçš„Mixture-of-Expertsæ¨¡å—|Zichen Wang, Ang Cao, Liam J. Wang, Jeong Joon Park|<https://arxiv.org/pdf/2601.05208v3>|æ— |
|ğŸ“ æ›´æ–°|PyMAF-X: Towards Well-aligned Full-body Model Regression from Monocular Images|[ç¿»è¯‘å¤±è´¥] PyMAF-X: Towards Well-aligned Full-body Model Regression from Monocular Images|Hongwen Zhang, Yating Tian, Yuxiang Zhang, Mengcheng Li, Liang An, Zhenan Sun, Yebin Liu|<https://arxiv.org/pdf/2207.06400v4>|æ— |
|ğŸ†• å‘å¸ƒ|An AI-enabled tool for quantifying overlapping red blood cell sickling dynamics in microfluidic assays|ä¸€ç§ç”¨äºé‡åŒ–å¾®æµæ§å®éªŒä¸­é‡å çº¢ç»†èƒé•°çŠ¶åŒ–åŠ¨æ€çš„AIå·¥å…·|Nikhil Kadivar, Guansheng Li, Jianlu Zheng, John M. Higgins, Ming Dao, George Em Karniadakis, Mengjia Xu|<https://arxiv.org/pdf/2601.17703v1>|æ— |
|ğŸ“ æ›´æ–°|DeepInsert: Early Layer Bypass for Efficient and Performant Multimodal Understanding|DeepDeepInsertï¼šç”¨äºé«˜æ•ˆé«˜æ€§èƒ½å¤šæ¨¡æ€ç†è§£çš„æ—©æœŸå±‚æ—è·¯|Moulik Choraria, Xinbo Wu, Akhil Bhimaraju, Nitesh Sekhar, Yue Wu, Xu Zhang, Prateek Singhal, Lav R. Varshney|<https://arxiv.org/pdf/2504.19327v3>|åˆ†æå¤±è´¥|


### æ¨ç†ä¼˜åŒ– (Inference Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|SceneSplat++: A Large Dataset and Comprehensive Benchmark for Language Gaussian Splatting|SceneSplat++ï¼šç”¨äºè¯­è¨€ Gaussian Splatting çš„å¤§è§„æ¨¡æ•°æ®é›†ä¸ç»¼åˆåŸºå‡†|Mengjiao Ma, Qi Ma, Yue Li, Jiahuan Cheng, Runyi Yang, Bin Ren, Nikola Popovic, Mingqiang Wei .etc.|<https://arxiv.org/pdf/2506.08710v4>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Matrix-free Second-order Optimization of Gaussian Splats with Residual Sampling|Gaussian Splats çš„æ— çŸ©é˜µäºŒé˜¶ä¼˜åŒ–ä¸æ®‹å·®é‡‡æ ·|Hamza Pehlivan, Andrea Boscolo Camiletto, Lin Geng Foo, Marc Habermann, Christian Theobalt|<https://arxiv.org/pdf/2504.12905v3>|æ— |


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### åˆ†å¸ƒå¤–æ³›åŒ– (Out-of-distribution Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Feature-Space Generative Models for One-Shot Class-Incremental Learning|Feature-Space ç”Ÿæˆæ¨¡å‹ç”¨äº One-Shot ç±»å¢é‡å­¦ä¹ |Jack Foster, Kirill Paramonov, Mete Ozay, Umberto Michieli|<https://arxiv.org/pdf/2601.17905v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Revisiting 3D Reconstruction Kernels as Low-Pass Filters|é‡æ–°å®¡è§†ä½œä¸ºä½é€šæ»¤æ³¢å™¨çš„ 3D Reconstruction Kernels|Shengjun Zhang, Min Chen, Yibo Wei, Mingyu Dong, Yueqi Duan|<https://arxiv.org/pdf/2601.17900v1>|åˆ†æå¤±è´¥|


### å¯¹æŠ—é²æ£’æ€§ (Adversarial Robustness)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Degradation-Agnostic Statistical Facial Feature Transformation for Blind Face Restoration in Adverse Weather Conditions|Degradation-Agnostic ç»Ÿè®¡é¢éƒ¨ç‰¹å¾å˜æ¢ç”¨äºæ¶åŠ£å¤©æ°”æ¡ä»¶ä¸‹çš„ç›²äººè„¸å¤åŸ|Chang-Hwan Son, Cheol-Hwan Kim|<https://arxiv.org/pdf/2507.07464v4>|åˆ†æå¤±è´¥|


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Domain-Expert-Guided Hybrid Mixture-of-Experts for Medical AI: Integrating Data-Driven Learning with Clinical Priors|é¢†åŸŸä¸“å®¶å¼•å¯¼çš„æ··åˆMixture-of-Expertsç”¨äºåŒ»ç–—AIï¼šèåˆæ•°æ®é©±åŠ¨å­¦ä¹ ä¸ä¸´åºŠå…ˆéªŒ|Jinchen Gu, Nan Zhao, Lei Qiu, Lu Zhang|<https://arxiv.org/pdf/2601.17977v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Learning Sewing Patterns via Latent Flow Matching of Implicit Fields|é€šè¿‡éšå¼åœºçš„Latent Flow Matchingå­¦ä¹ ç¼çº«å›¾æ¡ˆ|Cong Cao, Ren Li, Corentin Dumery, Hao Li|<https://arxiv.org/pdf/2601.17740v1>|æ— |


### å°æ ·æœ¬å­¦ä¹  (Few-shot Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|BigTokDetect: A Clinically-Informed Vision-Language Modeling Framework for Detecting Pro-Bigorexia Videos on TikTok|BigTokDetectï¼šä¸€ç§ç”¨äºæ£€æµ‹TikTokä¸Šå€¾å‘å¥ç¾å¼ºè¿«ç—‡è§†é¢‘çš„ä¸´åºŠçŸ¥æƒ…Vision-Languageå»ºæ¨¡æ¡†æ¶|Minh Duc Chu, Kshitij Pawar, Zihao He, Roxanna Sharifi, Ross Sonnenblick, Magdalayna Curry, Laura D'Adamo, Lindsay Young .etc.|<https://arxiv.org/pdf/2508.06515v3>|æ— |


## å…·èº«æ™ºèƒ½ä¸äº¤äº’è§†è§‰ (Embodied Intelligence & Interactive Vision)


### è§†è§‰æ“ä½œä¸æ§åˆ¶ (Visual Manipulation & Control)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Masked Depth Modeling for Spatial Perception|[ç¿»è¯‘å¤±è´¥] Masked Depth Modeling for Spatial Perception|Bin Tan, Changjiang Sun, Xiage Qin, Hanat Adai, Zelin Fu, Tianxiang Zhou, Han Zhang, Yinghao Xu .etc.|<https://arxiv.org/pdf/2601.17895v1>|æ— |


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|CARE Transformer: Mobile-Friendly Linear Visual Transformer via Decoupled Dual Interaction|CARE Transformer: é€šè¿‡è§£è€¦åŒé‡äº¤äº’å®ç°çš„ç§»åŠ¨å‹å¥½å‹çº¿æ€§ Visual Transformer|Yuan Zhou, Qingshan Xu, Jiequan Cui, Junbao Zhou, Jing Zhang, Richang Hong, Hanwang Zhang|<https://arxiv.org/pdf/2411.16170v2>|[ä»£ç ](https://github.com/zhouyuan888888/CARE-Transformer)|
|ğŸ†• å‘å¸ƒ|Benchmarking Direct Preference Optimization for Medical Large Vision-Language Models|åŸºå‡†æµ‹è¯•ç”¨äºåŒ»å­¦ Large Vision-Language Models çš„ Direct Preference Optimization|Dain Kim, Jiwoo Lee, Jaehoon Yun, Yong Hoe Koo, Qingyu Chen, Hyunjae Kim, Jaewoo Kang|<https://arxiv.org/pdf/2601.17918v1>|[ä»£ç ](https://github.com/dmis-lab/med-vlm-dpo.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Towards Robust Evaluation of Visual Activity Recognition: Resolving Verb Ambiguity with Sense Clustering|[ç¿»è¯‘å¤±è´¥] Towards Robust Evaluation of Visual Activity Recognition: Resolving Verb Ambiguity with Sense Clustering|Louie Hong Yao, Nicholas Jarvis, Tianyu Jiang|<https://arxiv.org/pdf/2508.04945v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|SenseNova-MARS: Empowering Multimodal Agentic Reasoning and Search via Reinforcement Learning|SenseNova-MARSï¼šé€šè¿‡ Reinforcement Learning èµ‹èƒ½ Multimodal Agentic Reasoning and Search|Yong Xien Chng, Tao Hu, Wenwen Tong, Xueheng Li, Jiandong Chen, Haojia Yu, Jiefan Lu, Hewei Guo .etc.|<https://arxiv.org/pdf/2512.24330v2>|åˆ†æå¤±è´¥|


### å¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿ (Multimodal Dialogue Systems)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|RotBench: Evaluating Multimodal Large Language Models on Identifying Image Rotation|RotBenchï¼šè¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨è¯†åˆ«å›¾åƒæ—‹è½¬æ–¹é¢çš„æ€§èƒ½|Tianyi Niu, Jaemin Cho, Elias Stengel-Eskin, Mohit Bansal|<https://arxiv.org/pdf/2508.13968v3>|åˆ†æå¤±è´¥|


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Leveraging Persistence Image to Enhance Robustness and Performance in Curvilinear Structure Segmentation|åˆ©ç”¨ Persistence Image å¢å¼ºæ›²çº¿ç»“æ„åˆ†å‰²çš„é²æ£’æ€§å’Œæ€§èƒ½|Zhuangzhi Gao, Feixiang Zhou, He Zhao, Xiuju Chen, Xiaoxin Li, Qinkai Yu, Yitian Zhao, Alena Shantsila .etc.|<https://arxiv.org/pdf/2601.18045v1>|æ— |
|ğŸ†• å‘å¸ƒ|DTC: A Deformable Transposed Convolution Module for Medical Image Segmentation|DTCï¼šä¸€ç§ç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²çš„å¯å˜å½¢è½¬ç½®å·ç§¯æ¨¡å—|Chengkun Sun, Jinqian Pan, Renjie Liang, Zhengkang Fan, Xin Miao, Jiang Bian, Jie Xu|<https://arxiv.org/pdf/2601.17939v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Domain Generalization with Quantum Enhancement for Medical Image Classification: A Lightweight Approach for Cross-Center Deployment|åˆ©ç”¨é‡å­å¢å¼ºçš„åŸŸæ³›åŒ–è¿›è¡ŒåŒ»å­¦å›¾åƒåˆ†ç±»ï¼šä¸€ç§ç”¨äºè·¨ä¸­å¿ƒéƒ¨ç½²çš„è½»é‡çº§æ–¹æ³•|Jingsong Xia, Siqi Wang|<https://arxiv.org/pdf/2601.17862v1>|æ— |


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Bridging Supervision Gaps: A Unified Framework for Remote Sensing Change Detection|å¼¥åˆç›‘ç£å·®è·ï¼šé¥æ„Ÿå˜åŒ–æ£€æµ‹ç»Ÿä¸€æ¡†æ¶|Kaixuan Jiang, Chen Wu, Zhenghui Zhao, Chengxi Han|<https://arxiv.org/pdf/2601.17747v1>|æ— |
|ğŸ†• å‘å¸ƒ|Uni-RS: A Spatially Faithful Unified Understanding and Generation Model for Remote Sensing|Uni-RS: ä¸€ä¸ªç©ºé—´ä¿çœŸçš„é¥æ„Ÿç»Ÿä¸€ç†è§£ä¸ç”Ÿæˆæ¨¡å‹|Weiyu Zhang, Yuan Hu, Yong Li, Yu Liu|<https://arxiv.org/pdf/2601.17673v1>|åˆ†æå¤±è´¥|


## æ–°å…´ç†è®ºä¸è·¨å­¦ç§‘æ–¹å‘ (Emerging Theory & Interdisciplinary Directions)


### ç¥ç»-ç¬¦å·è§†è§‰ (Neuro-symbolic Vision)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|From Darkness to Detail: Frequency-Aware SSMs for Low-Light Vision|ä»é»‘æš—åˆ°ç»†èŠ‚ï¼šé¢å‘ä½å…‰è§†è§‰çš„é¢‘ç‡æ„ŸçŸ¥ SSMs|Eashan Adhikarla, Kai Zhang, Gong Chen, John Nicholson, Brian D. Davison|<https://arxiv.org/pdf/2408.09650v2>|[ä»£ç ](https://github.com/eashanadhikarla/ExpoMamba.); åˆ†æå¤±è´¥|


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|CloSET: Modeling Clothed Humans on Continuous Surface with Explicit Template Decomposition|CloSET: åŸºäºæ˜¾å¼æ¨¡æ¿åˆ†è§£çš„è¿ç»­è¡¨é¢ç€è£…äººä½“å»ºæ¨¡|Hongwen Zhang, Siyou Lin, Ruizhi Shao, Yuxiang Zhang, Zerong Zheng, Han Huang, Yandong Guo, Yebin Liu|<https://arxiv.org/pdf/2304.03167v2>|æ— |

