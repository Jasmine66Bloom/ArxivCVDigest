## [UPDATED!] **2026-01-26** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|MindCine: Multimodal EEG-to-Video Reconstruction with Large-Scale Pretrained Models|MindCineï¼šåŸºäºå¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹çš„å¤šæ¨¡æ€ EEG åˆ°è§†é¢‘é‡å»º|Tian-Yi Zhou, Xuan-Hao Liu, Bao-Liang Lu, Wei-Long Zheng|<https://arxiv.org/pdf/2601.18192v2>|æ— |
|ğŸ“ æ›´æ–°|Beyond Memorization: Selective Learning for Copyright-Safe Diffusion Model Training|è¶…è¶Šè®°å¿†ï¼šç”¨äºç‰ˆæƒå®‰å…¨çš„ Diffusion æ¨¡å‹è®­ç»ƒçš„é€‰æ‹©æ€§å­¦ä¹ |Divya Kothandaraman, Jaclyn Pytlarz|<https://arxiv.org/pdf/2512.11194v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Anatomically-aware conformal prediction for medical image segmentation with random walks|é¢å‘åŒ»å­¦å›¾åƒåˆ†å‰²çš„è§£å‰–æ„ŸçŸ¥ä¿å½¢é¢„æµ‹ï¼šåŸºäºéšæœºæ¸¸èµ°çš„æ–¹æ³•|MÃ©lanie Gaillochet, Christian Desrosiers, HervÃ© Lombaert|<https://arxiv.org/pdf/2601.18997v1>|æ— |
|ğŸ“ æ›´æ–°|Decoding Visual Experience and Mapping Semantics through Whole-Brain Analysis Using fMRI Foundation Models|é€šè¿‡ä½¿ç”¨ fMRI Foundation Models è¿›è¡Œå…¨è„‘åˆ†ææ¥è§£ç è§†è§‰ä½“éªŒå¹¶æ˜ å°„è¯­ä¹‰|Yanchen Wang, Adam Turnbull, Tiange Xiang, Yunlong Xu, Sa Zhou, Adnan Masoud, Shekoofeh Azizi, Feng Vankee Lin .etc.|<https://arxiv.org/pdf/2411.07121v3>|æ— |
|ğŸ†• å‘å¸ƒ|A Pragmatic VLA Foundation Model|ä¸€ä¸ªå®ç”¨çš„ VLA åŸºç¡€æ¨¡å‹|Wei Wu, Fan Lu, Yunnan Wang, Shuai Yang, Shi Liu, Fangjing Wang, Qian Zhu, He Sun .etc.|<https://arxiv.org/pdf/2601.18692v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Whole Slide Concepts: A Supervised Foundation Model For Pathological Images|Whole Slide Conceptsï¼šä¸€ç§ç”¨äºç—…ç†å›¾åƒçš„ç›‘ç£åŸºç¡€æ¨¡å‹|Till Nicke, Daniela Schacherer, Jan Raphael SchÃ¤fer, Natalia Artysh, Antje Prasse, AndrÃ© Homeyer, Andrea Schenk, Henning HÃ¶fener .etc.|<https://arxiv.org/pdf/2507.05742v3>|[ä»£ç ](https://github.com/FraunhoferMEVIS/MedicalMultitaskModeling.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Q-Bench-Portrait: Benchmarking Multimodal Large Language Models on Portrait Image Quality Perception|Q-Bench-Portraitï¼šåœ¨è‚–åƒå›¾åƒè´¨é‡æ„ŸçŸ¥æ–¹é¢è¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹|Sijing Wu, Yunhao Li, Zicheng Zhang, Qi Jia, Xinyue Li, Huiyu Duan, Xiongkuo Min, Guangtao Zhai|<https://arxiv.org/pdf/2601.18346v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|MangaVQA and MangaLMM: A Benchmark and Specialized Model for Multimodal Manga Understanding|MangaVQA å’Œ MangaLMMï¼šç”¨äºå¤šæ¨¡æ€æ¼«ç”»ç†è§£çš„åŸºå‡†å’Œä¸“ç”¨æ¨¡å‹|Jeonghun Baek, Kazuki Egashira, Shota Onohara, Atsuyuki Miyai, Yuki Imajuku, Hikaru Ikuta, Kiyoharu Aizawa|<https://arxiv.org/pdf/2505.20298v3>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities|ç»Ÿä¸€å¤šæ¨¡æ€ç†è§£ä¸ç”Ÿæˆæ¨¡å‹ï¼šè¿›å±•ã€æŒ‘æˆ˜ä¸æœºé‡|Shanshan Zhao, Xinjie Zhang, Jintao Guo, Jiakui Hu, Lunhao Duan, Minghao Fu, Yong Xien Chng, Guo-Hua Wang .etc.|<https://arxiv.org/pdf/2505.02567v6>|[ä»£ç ](https://github.com/AIDC-AI/Awesome-Unified-Multimodal-Models)|


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Scaling Foundation Models for Radar Scene Understanding|[ç¿»è¯‘å¤±è´¥] Scaling Foundation Models for Radar Scene Understanding|Pushkal Mishra, Kshitiz Bansal, Dinesh Bharadia|<https://arxiv.org/pdf/2511.21105v2>|æ— |
|ğŸ“ æ›´æ–°|Omni-AVSR: Towards Unified Multimodal Speech Recognition with Large Language Models|Omni-AVSR: åŸºäºLarge Language Modelsçš„ç»Ÿä¸€å¤šæ¨¡æ€è¯­éŸ³è¯†åˆ«|Umberto Cappellazzo, Xubo Liu, Pingchuan Ma, Stavros Petridis, Maja Pantic|<https://arxiv.org/pdf/2511.07253v3>|æ— |
|ğŸ†• å‘å¸ƒ|DeFM: Learning Foundation Representations from Depth for Robotics|DeFM: ä»æ·±åº¦æ•°æ®å­¦ä¹ åŸºç¡€è¡¨ç¤ºä»¥ç”¨äºæœºå™¨äººæŠ€æœ¯|Manthan Patel, Jonas Frey, Mayank Mittal, Fan Yang, Alexander Hansson, Amir Bar, Cesar Cadena, Marco Hutter|<https://arxiv.org/pdf/2601.18923v1>|æ— |
|ğŸ†• å‘å¸ƒ|Multimodal Privacy-Preserving Entity Resolution with Fully Homomorphic Encryption|åŸºäºå…¨åŒæ€åŠ å¯†çš„å¤šæ¨¡æ€éšç§ä¿æŠ¤å®ä½“è§£æ|Susim Roy, Nalini Ratha|<https://arxiv.org/pdf/2601.18612v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Fair-Eye Net: A Fair, Trustworthy, Multimodal Integrated Glaucoma Full Chain AI System|Fair-Eye Netï¼šä¸€ä¸ªå…¬å¹³ã€å¯ä¿¡ã€å¤šæ¨¡æ€é›†æˆçš„é’å…‰çœ¼å…¨é“¾è·¯ AI ç³»ç»Ÿ|Wenbin Wei, Suyuan Yao, Cheng Huang, Xiangyu Gao|<https://arxiv.org/pdf/2601.18464v1>|æ— |
|ğŸ†• å‘å¸ƒ|A Tumor Aware DenseNet Swin Hybrid Learning with Boosted and Hierarchical Feature Spaces for Large-Scale Brain MRI Classification|ä¸€ç§å…·æœ‰å¢å¼ºå’Œåˆ†å±‚ç‰¹å¾ç©ºé—´çš„è‚¿ç˜¤æ„ŸçŸ¥ DenseNet Swin æ··åˆå­¦ä¹ ï¼Œç”¨äºå¤§è§„æ¨¡è„‘éƒ¨ MRI åˆ†ç±»|Muhammad Ali Shah, Muhammad Mansoor Alam, Saddam Hussain Khan|<https://arxiv.org/pdf/2601.18330v1>|æ— |
|ğŸ†• å‘å¸ƒ|Integrating Fine-Grained Audio-Visual Evidence for Robust Multimodal Emotion Reasoning|æ•´åˆç»†ç²’åº¦è§†å¬è¯æ®ä»¥å®ç°é²æ£’çš„å¤šæ¨¡æ€æƒ…æ„Ÿæ¨ç†|Zhixian Zhao, Wenjie Tian, Xiaohai Tian, Jun Zhang, Lei Xie|<https://arxiv.org/pdf/2601.18321v1>|[ä»£ç ](https://github.com/zxzhao0/SABER-LLM.)|
|ğŸ†• å‘å¸ƒ|A multimodal vision foundation model for generalizable knee pathology|ä¸€ç§ç”¨äºå¯æ³›åŒ–è†å…³èŠ‚ç—…ç†å­¦çš„å¤šæ¨¡æ€è§†è§‰åŸºç¡€æ¨¡å‹|Kang Yu, Dingyu Wang, Zimu Yuan, Nan Zhou, Jiajun Liu, Jiaxin Liu, Shanggui Liu, Yaoyan Zheng .etc.|<https://arxiv.org/pdf/2601.18250v1>|æ— |


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|On the Role of Depth in Surgical Vision Foundation Models: An Empirical Study of RGB-D Pre-training|è®ºæ·±åº¦åœ¨æ‰‹æœ¯è§†è§‰åŸºç¡€æ¨¡å‹ä¸­çš„ä½œç”¨ï¼šRGB-Dé¢„è®­ç»ƒçš„å®è¯ç ”ç©¶|John J. Han, Adam Schmidt, Muhammad Abdullah Jamal, Chinedu Nwoye, Anita Rau, Jie Ying Wu, Omid Mohareri|<https://arxiv.org/pdf/2601.18929v1>|æ— |
|ğŸ†• å‘å¸ƒ|Efficient Complex-Valued Vision Transformers for MRI Classification Directly from k-Space|ç”¨äºç›´æ¥ä» k-Space è¿›è¡Œ MRI åˆ†ç±»çš„é«˜æ•ˆå¤å€¼ Vision Transformers|Moritz Rempe, Lukas T. Rotkopf, Marco Schlimbach, Helmut Becker, Fabian HÃ¶rst, Johannes Haubold, Philipp Dammann, Kevin KrÃ¶ninger .etc.|<https://arxiv.org/pdf/2601.18392v1>|æ— |


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SeNeDiF-OOD: Semantic Nested Dichotomy Fusion for Out-of-Distribution Detection Methodology in Open-World Classification. A Case Study on Monument Style Classification|SeNeDiF-OODï¼šç”¨äºå¼€æ”¾ä¸–ç•Œåˆ†ç±»ä¸­åˆ†å¸ƒå¤–æ£€æµ‹æ–¹æ³•çš„è¯­ä¹‰åµŒå¥—äºŒåˆ†æ³•èåˆã€‚ä»¥çºªå¿µç¢‘é£æ ¼åˆ†ç±»ä¸ºä¾‹|Ignacio Antequera-SÃ¡nchez, Juan Luis SuÃ¡rez-DÃ­az, Rosana Montes, Francisco Herrera|<https://arxiv.org/pdf/2601.18739v2>|æ— |
|ğŸ“ æ›´æ–°|DeltaDorsal: Enhancing Hand Pose Estimation with Dorsal Features in Egocentric Views|DeltaDorsalï¼šåœ¨ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†è§’ä¸­åˆ©ç”¨èƒŒéƒ¨ç‰¹å¾å¢å¼ºæ‰‹éƒ¨å§¿æ€ä¼°è®¡|William Huang, Siyou Pei, Leyi Zou, Eric J. Gonzalez, Ishan Chatterjee, Yang Zhang|<https://arxiv.org/pdf/2601.15516v2>|æ— |
|ğŸ†• å‘å¸ƒ|Weakly supervised framework for wildlife detection and counting in challenging Arctic environments: a case study on caribou (Rangifer tarandus)|é’ˆå¯¹å…·æœ‰æŒ‘æˆ˜æ€§çš„åŒ—æç¯å¢ƒä¸­é‡ç”ŸåŠ¨ç‰©æ£€æµ‹å’Œè®¡æ•°çš„å¼±ç›‘ç£æ¡†æ¶ï¼šä»¥é©¯é¹¿ä¸ºä¾‹|Ghazaleh Serati, Samuel Foucher, Jerome Theau|<https://arxiv.org/pdf/2601.18891v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|DGFusion: Depth-Guided Sensor Fusion for Robust Semantic Perception|[ç¿»è¯‘å¤±è´¥] DGFusion: Depth-Guided Sensor Fusion for Robust Semantic Perception|Tim Broedermannn, Christos Sakaridis, Luigi Piccinelli, Wim Abbeloos, Luc Van Gool|<https://arxiv.org/pdf/2509.09828v3>|[ä»£ç ](https://github.com/timbroed/DGFusion); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Dynamic Mask-Based Backdoor Attack Against Vision AI Models: A Case Study on Mushroom Detection|åŸºäºåŠ¨æ€æ©ç çš„é’ˆå¯¹Vision AIæ¨¡å‹çš„åé—¨æ”»å‡»ï¼šä»¥è˜‘è‡æ£€æµ‹ä¸ºä¾‹|Zeineb Dridi, Jihen Bennaceur, Amine Ben Hassouna|<https://arxiv.org/pdf/2601.18845v1>|åˆ†æå¤±è´¥|


### è¯­ä¹‰/å®ä¾‹åˆ†å‰² (Semantic/Instance Segmentation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Smart Split-Federated Learning over Noisy Channels for Embryo Image Segmentation|[ç¿»è¯‘å¤±è´¥] Smart Split-Federated Learning over Noisy Channels for Embryo Image Segmentation|Zahra Hafezi Kafshgari, Ivan V. Bajic, Parvaneh Saeedi|<https://arxiv.org/pdf/2601.18948v1>|æ— |


### ç›®æ ‡æ£€æµ‹ä¸å®šä½ (Object Detection & Localization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|EFSI-DETR: Efficient Frequency-Semantic Integration for Real-Time Small Object Detection in UAV Imagery|EFSI-DETR: ç”¨äºUAVå›¾åƒä¸­å®æ—¶å°ç›®æ ‡æ£€æµ‹çš„é«˜æ•ˆé¢‘ç‡-è¯­ä¹‰é›†æˆ|Yu Xia, Chang Liu, Tianqi Xiang, Zhigang Tu|<https://arxiv.org/pdf/2601.18597v1>|æ— |
|ğŸ†• å‘å¸ƒ|Automated Landmark Detection for assessing hip conditions: A Cross-Modality Validation of MRI versus X-ray|ç”¨äºè¯„ä¼°é«‹éƒ¨çŠ¶å†µçš„è‡ªåŠ¨Landmarkæ£€æµ‹ï¼šMRIä¸X-rayçš„Cross-ModalityéªŒè¯|Roberto Di Via, Vito Paolo Pastore, Francesca Odone, SiÃ´n Glyn-Jones, Irina Voiculescu|<https://arxiv.org/pdf/2601.18555v1>|[ä»£ç ](https://github.com/Malga-Vision/Landmarks-Hip-Conditions); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Real-Time Object Detection Meets DINOv3|å®æ—¶ç›®æ ‡æ£€æµ‹é‡ä¸Š DINOv3|Shihua Huang, Yongjie Hou, Longfei Liu, Xuanlong Yu, Xi Shen|<https://arxiv.org/pdf/2509.20787v4>|[ä»£ç ](https://github.com/Intellindust-AI-Lab/DEIMv2)|
|ğŸ†• å‘å¸ƒ|YOLO-DS: Fine-Grained Feature Decoupling via Dual-Statistic Synergy Operator for Object Detection|YOLO-DS: åŸºäºDual-Statistic Synergy Operatorçš„ç»†ç²’åº¦ç‰¹å¾è§£è€¦ç”¨äºç›®æ ‡æ£€æµ‹|Lin Huang, Yujuan Tan, Weisheng Li, Shitai Shan, Liu Liu, Bo Liu, Linlin Shen, Jing Yu .etc.|<https://arxiv.org/pdf/2601.18172v1>|æ— |


### å›¾åƒåˆ†ç±»ä¸è¯†åˆ« (Image Classification & Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Revisiting Aerial Scene Classification on the AID Benchmark|[ç¿»è¯‘å¤±è´¥] Revisiting Aerial Scene Classification on the AID Benchmark|Subhajeet Das, Susmita Ghosh, Abhiroop Chatterjee|<https://arxiv.org/pdf/2601.18263v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Cross-Domain Transfer with Self-Supervised Spectral-Spatial Modeling for Hyperspectral Image Classification|è·¨åŸŸè¿ç§»ä¸è‡ªç›‘ç£å…‰è°±-ç©ºé—´å»ºæ¨¡ç”¨äºé«˜å…‰è°±å›¾åƒåˆ†ç±»|Jianshu Chao, Tianhua Lv, Qiqiong Ma, Yunfei Qiu, Li Fang, Huifang Shen, Wei Yao|<https://arxiv.org/pdf/2601.18088v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Semi-Supervised Hyperspectral Image Classification with Edge-Aware Superpixel Label Propagation and Adaptive Pseudo-Labeling|åŸºäºè¾¹ç¼˜æ„ŸçŸ¥è¶…åƒç´ æ ‡ç­¾ä¼ æ’­å’Œè‡ªé€‚åº”ä¼ªæ ‡ç­¾çš„åŠç›‘ç£é«˜å…‰è°±å›¾åƒåˆ†ç±»|Yunfei Qiu, Qiqiong Ma, Tianhua Lv, Li Fang, Shudong Zhou, Wei Yao|<https://arxiv.org/pdf/2601.18049v1>|æ— |


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Non-Invasive 3D Wound Measurement with RGB-D Imaging|åŸºäºRGB-Dæˆåƒçš„æ— åˆ›3Dä¼¤å£æµ‹é‡|Lena HarkÃ¤mper, Leo Lebrat, David Ahmedt-Aristizabal, Olivier Salvado, Mattias Heinrich, Rodrigo Santa Cruz|<https://arxiv.org/pdf/2601.19014v1>|æ— |
|ğŸ†• å‘å¸ƒ|Self-Refining Video Sampling|è‡ªä¼˜åŒ–è§†é¢‘é‡‡æ ·|Sangwon Jang, Taekyung Ki, Jaehyeong Jo, Saining Xie, Jaehong Yoon, Sung Ju Hwang|<https://arxiv.org/pdf/2601.18577v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Closing the Modality Gap Aligns Group-Wise Semantics|[ç¿»è¯‘å¤±è´¥] Closing the Modality Gap Aligns Group-Wise Semantics|Eleonora Grassucci, Giordano Cicchetti, Emanuele Frasca, Aurelio Uncini, Danilo Comminiello|<https://arxiv.org/pdf/2601.18525v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|3DGesPolicy: Phoneme-Aware Holistic Co-Speech Gesture Generation Based on Action Control|3DGesPolicy: åŸºäºåŠ¨ä½œæ§åˆ¶çš„éŸ³ç´ æ„ŸçŸ¥æ•´ä½“ååŒè¯­éŸ³æ‰‹åŠ¿ç”Ÿæˆ|Xuanmeng Sha, Liyun Zhang, Tomohiro Mashita, Naoya Chiba, Yuki Uranishi|<https://arxiv.org/pdf/2601.18451v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Beyond Rigid: Benchmarking Non-Rigid Video Editing|[ç¿»è¯‘å¤±è´¥] Beyond Rigid: Benchmarking Non-Rigid Video Editing|Bingzheng Qu, Kehai Chen, Xuefeng Bai, Jun Yu, Min Zhang|<https://arxiv.org/pdf/2601.18340v1>|æ— |
|ğŸ†• å‘å¸ƒ|Agentic Very Long Video Understanding|[ç¿»è¯‘å¤±è´¥] Agentic Very Long Video Understanding|Aniket Rege, Arka Sadhu, Yuliang Li, Kejie Li, Ramya Korlakai Vinayak, Yuning Chai, Yong Jae Lee, Hyo Jin Kim|<https://arxiv.org/pdf/2601.18157v1>|æ— |


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Purrception: Variational Flow Matching for Vector-Quantized Image Generation|Purrceptionï¼šç”¨äºVector-Quantizedå›¾åƒç”Ÿæˆçš„Variational Flow Matching|RÄƒzvan-Andrei MatiÅŸan, Vincent Tao Hu, Grigory Bartosh, BjÃ¶rn Ommer, Cees G. M. Snoek, Max Welling, Jan-Willem van de Meent, Mohammad Mahdi Derakhshani .etc.|<https://arxiv.org/pdf/2510.01478v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction|FreeOrbit4Dï¼šé€šè¿‡å‡ ä½•å®Œå¤‡çš„4Dé‡å»ºå®ç°å•ç›®è§†é¢‘å…è®­ç»ƒä»»æ„ç›¸æœºé‡å®šå‘|Wei Cao, Hao Zhang, Fengrui Tian, Yulun Wu, Yingying Li, Shenlong Wang, Ning Yu, Yaoyao Liu|<https://arxiv.org/pdf/2601.18993v1>|æ— |
|ğŸ“ æ›´æ–°|Learning Video Generation for Robotic Manipulation with Collaborative Trajectory Control|é¢å‘æœºå™¨äººæ“çºµçš„åä½œè½¨è¿¹æ§åˆ¶è§†é¢‘ç”Ÿæˆå­¦ä¹ |Xiao Fu, Xintao Wang, Xian Liu, Jianhong Bai, Runsen Xu, Pengfei Wan, Di Zhang, Dahua Lin|<https://arxiv.org/pdf/2506.01943v3>|[ä»£ç ](https://fuxiao0719.github.io/projects); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Joint Diffusion for Universal Hand-Object Grasp Generation|ç”¨äºé€šç”¨æ‰‹-ç‰©ä½“æŠ“å–ç”Ÿæˆçš„è”åˆ Diffusion|Jinkun Cao, Jingyuan Liu, Kris Kitani, Yi Zhou|<https://arxiv.org/pdf/2409.04560v2>|æ— |
|ğŸ“ æ›´æ–°|ResMatching: Noise-Resilient Computational Super-Resolution via Guided Conditional Flow Matching|ResMatchingï¼šé€šè¿‡å¼•å¯¼æ¡ä»¶æµåŒ¹é…å®ç°æŠ—å™ªè®¡ç®—è¶…åˆ†è¾¨ç‡|Anirban Ray, Vera Galinova, Florian Jug|<https://arxiv.org/pdf/2510.26601v3>|æ— |
|ğŸ“ æ›´æ–°|Physiology-Informed Generative Multi-Task Network for Contrast-Free CT Perfusion|åŸºäºç”Ÿç†ä¿¡æ¯çš„ç”Ÿæˆå¼å¤šä»»åŠ¡ç½‘ç»œç”¨äºæ— å¯¹æ¯”å‰‚CTçŒæ³¨|Wasif Khan, John Rees, Kyle B. See, Simon Kato, Ziqian Huang, Amy Lazarte, Kyle Douglas, Xiangyang Lou .etc.|<https://arxiv.org/pdf/2505.22673v2>|æ— |
|ğŸ†• å‘å¸ƒ|Are Video Generation Models Geographically Fair? An Attraction-Centric Evaluation of Global Visual Knowledge|è§†é¢‘ç”Ÿæˆæ¨¡å‹åœ¨åœ°ç†ä¸Šæ˜¯å¦å…¬å¹³ï¼ŸåŸºäºå¸å¼•åŠ›çš„å…¨çƒè§†è§‰çŸ¥è¯†è¯„ä¼°|Xiao Liu, Jiawei Zhang|<https://arxiv.org/pdf/2601.18698v1>|æ— |
|ğŸ“ æ›´æ–°|GHOST: Hallucination-Inducing Image Generation for Multimodal LLMs|GHOSTï¼šé¢å‘å¤šæ¨¡æ€ LLMs çš„è¯±å¯¼å¹»è§‰å›¾åƒç”Ÿæˆ|Aryan Yazdan Parast, Parsa Hosseini, Hesam Asadollahzadeh, Arshia Soltani Moakhar, Basim Azam, Soheil Feizi, Naveed Akhtar|<https://arxiv.org/pdf/2509.25178v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|HeadLighter: Disentangling Illumination in Generative 3D Gaussian Heads via Lightstage Captures|HeadLighterï¼šé€šè¿‡ Lightstage é‡‡é›†è§£è€¦ç”Ÿæˆå¼ 3D Gaussian Heads ä¸­çš„å…‰ç…§|Yating Wang, Yuan Sun, Xuan Wang, Ran Yi, Boyao Zhou, Yipengjing Sun, Hongyu Liu, Yinuo Wang .etc.|<https://arxiv.org/pdf/2601.02103v2>|æ— |
|ğŸ†• å‘å¸ƒ|Splat-Portrait: Generalizing Talking Heads with Gaussian Splatting|Splat-Portrait: åˆ©ç”¨ Gaussian Splatting æ³›åŒ– Talking Heads|Tong Shi, Melonie de Almeida, Daniela Ivanova, Nicolas Pugeault, Paul Henderson|<https://arxiv.org/pdf/2601.18633v1>|[ä»£ç ](https://github.com/stonewalking/Splat-portrait.)|
|ğŸ“ æ›´æ–°|SMooGPT: Stylized Motion Generation using Large Language Models|SMooGPT: ä½¿ç”¨ Large Language Models çš„é£æ ¼åŒ–è¿åŠ¨ç”Ÿæˆ|Lei Zhong, Yi Yang, Changjian Li|<https://arxiv.org/pdf/2509.04058v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|GimmBO: Interactive Generative Image Model Merging via Bayesian Optimization|GimmBOï¼šé€šè¿‡ Bayesian Optimization å®ç°äº¤äº’å¼ç”Ÿæˆå›¾åƒæ¨¡å‹åˆå¹¶|Chenxi Liu, Selena Ling, Alec Jacobson|<https://arxiv.org/pdf/2601.18585v1>|æ— |
|ğŸ†• å‘å¸ƒ|GenAgent: Scaling Text-to-Image Generation via Agentic Multimodal Reasoning|GenAgent: é€šè¿‡ Agentic Multimodal Reasoning æ‰©å±• Text-to-Image Generation|Kaixun Jiang, Yuzheng Wang, Junjie Zhou, Pandeng Li, Zhihang Liu, Chen-Wei Xie, Zhaoyu Chen, Yun Zheng .etc.|<https://arxiv.org/pdf/2601.18543v1>|[ä»£ç ](https://github.com/deep-kaixun/GenAgent)|
|ğŸ†• å‘å¸ƒ|SelfieAvatar: Real-time Head Avatar reenactment from a Selfie Video|SelfieAvatar: ä»è‡ªæ‹è§†é¢‘è¿›è¡Œå®æ—¶å¤´éƒ¨Avataré‡æ¼”|Wei Liang, Hui Yu, Derui Ding, Rachael E. Jack, Philippe G. Schyns|<https://arxiv.org/pdf/2601.18851v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Audio-Driven Talking Face Generation with Blink Embedding and Hash Grid Landmarks Encoding|åŸºäºBlink Embeddingå’ŒHash Grid Landmarks Encodingçš„Audio-Driven Talking Face Generation|Yuhui Zhang, Hui Yu, Wei Liang, Sunjie Zhang|<https://arxiv.org/pdf/2601.18849v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Adams Bashforth Moulton Solver for Inversion and Editing in Rectified Flow|ç”¨äº Rectified Flow ä¸­åæ¼”ä¸ç¼–è¾‘çš„ Adams Bashforth Moulton æ±‚è§£å™¨|Yongjia Ma, Donglin Di, Xuan Liu, Xiaokai Chen, Lei Fan, Tonghua Su, Yue Gao|<https://arxiv.org/pdf/2503.16522v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|AnchoredDream: Zero-Shot 360Â° Indoor Scene Generation from a Single View via Geometric Grounding|AnchoredDreamï¼šé€šè¿‡å‡ ä½•åŸºç¡€ä»å•è§†å›¾è¿›è¡Œé›¶æ ·æœ¬ 360Â° å®¤å†…åœºæ™¯ç”Ÿæˆ|Runmao Yao, Junsheng Zhou, Zhen Dong, Yu-Shen Liu|<https://arxiv.org/pdf/2601.16532v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|TechING: Towards Real World Technical Image Understanding via VLMs|TechING: é€šè¿‡ VLMs è¿ˆå‘çœŸå®ä¸–ç•ŒæŠ€æœ¯å›¾åƒç†è§£|Tafazzul Nadeem, Bhavik Shangari, Manish Rai, Gagan Raj Gupta, Ashutosh Modi|<https://arxiv.org/pdf/2601.18238v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|QualiRAG: Retrieval-Augmented Generation for Visual Quality Understanding|QualiRAGï¼šç”¨äºè§†è§‰è´¨é‡ç†è§£çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ|Linhan Cao, Wei Sun, Weixia Zhang, Xiangyang Zhu, Kaiwei Zhang, Jun Jia, Dandan Zhu, Guangtao Zhai .etc.|<https://arxiv.org/pdf/2601.18195v1>|[ä»£ç ](https://github.com/clh124/QualiRAG.)|
|ğŸ†• å‘å¸ƒ|Spatial-Conditioned Reasoning in Long-Egocentric Videos|é•¿Egocentricè§†é¢‘ä¸­çš„ç©ºé—´æ¡ä»¶æ¨ç†|James Tribble, Hao Wang, Si-En Hong, Chaoyi Zhou, Ashish Bastola, Siyu Huang, Abolfazl Razi|<https://arxiv.org/pdf/2601.18100v1>|ç ”ç©¶æ˜¾å¼ç©ºé—´ä¿¡å·å¦‚ä½•æå‡VLMåœ¨é•¿è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘ä¸­çš„ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚|


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|RealStats: A Rigorous Real-Only Statistical Framework for Fake Image Detection|RealStats: ä¸€ä¸ªä¸¥è°¨çš„ä»…çœŸå®å›¾åƒç»Ÿè®¡æ¡†æ¶ç”¨äºå‡å›¾åƒæ£€æµ‹|Haim Zisman, Uri Shaham|<https://arxiv.org/pdf/2601.18900v1>|æ— |
|ğŸ“ æ›´æ–°|HiCache: A Plug-in Scaled-Hermite Upgrade for Taylor-Style Cache-then-Forecast Diffusion Acceleration|HiCacheï¼šä¸€ç§ç”¨äº Taylor-Style Cache-then-Forecast æ‰©æ•£åŠ é€Ÿçš„æ’ä»¶å¼ Scaled-Hermite å‡çº§æ–¹æ¡ˆ|Liang Feng, Shikang Zheng, Jiacheng Liu, Yuqi Lin, Qinming Zhou, Peiliang Cai, Xinyu Wang, Junjie Chen .etc.|<https://arxiv.org/pdf/2508.16984v2>|[ä»£ç ](https://github.com/fenglang918/HiCache)|
|ğŸ“ æ›´æ–°|LLMPopcorn: Exploring LLMs as Assistants for Popular Micro-video Generation|LLMPopcornï¼šæ¢ç´¢ LLM ä½œä¸ºæµè¡ŒçŸ­è§†é¢‘ç”Ÿæˆçš„åŠ©æ‰‹|Junchen Fu, Xuri Ge, Kaiwen Zheng, Alexandros Karatzoglou, Ioannis Arapakis, Xin Xin, Yongxin Ni, Joemon M. Jose|<https://arxiv.org/pdf/2502.12945v3>|[ä»£ç ](https://github.com/GAIR-Lab/LLMPopcorn.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Localizing Knowledge in Diffusion Transformers|å®šä½ Diffusion Transformers ä¸­çš„çŸ¥è¯†|Arman Zarei, Samyadeep Basu, Keivan Rezaei, Zihao Lin, Sayan Nag, Soheil Feizi|<https://arxiv.org/pdf/2505.18832v3>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Too Many Frames, Not All Useful: Efficient Strategies for Long-Form Video QA|[ç¿»è¯‘å¤±è´¥] Too Many Frames, Not All Useful: Efficient Strategies for Long-Form Video QA|Jongwoo Park, Kanchana Ranasinghe, Kumara Kahatapitiya, Wonjeong Ryu, Donghyun Kim, Michael S. Ryoo|<https://arxiv.org/pdf/2406.09396v6>|[ä»£ç ](https://github.com/jongwoopark7978/LVNet); åˆ†æå¤±è´¥|


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SMART: Scalable Mesh-free Aerodynamic Simulations from Raw Geometries using a Transformer-based Surrogate Model|SMARTï¼šåŸºäº Transformer ä»£ç†æ¨¡å‹ä»åŸå§‹å‡ ä½•å½¢çŠ¶è¿›è¡Œå¯æ‰©å±•æ— ç½‘æ ¼ç©ºæ°”åŠ¨åŠ›å­¦æ¨¡æ‹Ÿ|Jan Hagnberger, Mathias Niepert|<https://arxiv.org/pdf/2601.18707v1>|æ— |
|ğŸ“ æ›´æ–°|No Other Representation Component Is Needed: Diffusion Transformers Can Provide Representation Guidance by Themselves|æ— éœ€å…¶ä»–è¡¨ç¤ºç»„ä»¶ï¼šDiffusion Transformers å¯è‡ªè¡Œæä¾›è¡¨ç¤ºæŒ‡å¯¼|Dengyang Jiang, Mengmeng Wang, Liuzhuozheng Li, Lei Zhang, Haoyu Wang, Wei Wei, Guang Dai, Yanning Zhang .etc.|<https://arxiv.org/pdf/2505.02831v5>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|DVD-Quant: Data-free Video Diffusion Transformers Quantization|[ç¿»è¯‘å¤±è´¥] DVD-Quant: Data-free Video Diffusion Transformers Quantization|Zhiteng Li, Hanxuan Li, Junyi Wu, Kai Liu, Haotong Qin, Linghe Kong, Guihai Chen, Yulun Zhang .etc.|<https://arxiv.org/pdf/2505.18663v3>|[ä»£ç ](https://github.com/lhxcs/DVD-Quant.)|
|ğŸ“ æ›´æ–°|Cross-Platform Scaling of Vision-Language-Action Models from Edge to Cloud GPUs|ä»è¾¹ç¼˜åˆ°äº‘ç«¯ GPU çš„ Vision-Language-Action æ¨¡å‹è·¨å¹³å°æ‰©å±•|Amir Taherin, Juyi Lin, Arash Akbari, Arman Akbari, Pu Zhao, Weiwei Chen, David Kaeli, Yanzhi Wang|<https://arxiv.org/pdf/2509.11480v2>|æ— |
|ğŸ“ æ›´æ–°|BADiff: Bandwidth Adaptive Diffusion Model|BADiff: å¸¦å®½è‡ªé€‚åº”æ‰©æ•£æ¨¡å‹|Xi Zhang, Hanwei Zhu, Yan Zhong, Jiamang Wang, Weisi Lin|<https://arxiv.org/pdf/2510.21366v2>|[ä»£ç ](https://github.com/xzhang9308/BADiff.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|ELIP: Efficient Discriminative Language-Image Pre-training with Fewer Vision Tokens|ELIP: ä½¿ç”¨æ›´å°‘ Vision Tokens çš„é«˜æ•ˆåˆ¤åˆ«å¼ Language-Image Pre-training|Yangyang Guo, Haoyu Zhang, Yongkang Wong, Liqiang Nie, Mohan Kankanhalli|<https://arxiv.org/pdf/2309.16738v3>|æ— |
|ğŸ“ æ›´æ–°|Coding the Visual World: From Image to Simulation Using Vision Language Models|ç¼–ç è§†è§‰ä¸–ç•Œï¼šåˆ©ç”¨ Vision Language Models ä»å›¾åƒåˆ°ä»¿çœŸ|Sagi Eppel|<https://arxiv.org/pdf/2601.05344v3>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Context-measure: Contextualizing Metric for Camouflage|Context-measureï¼šç”¨äºä¼ªè£…çš„ä¸Šä¸‹æ–‡åº¦é‡|Chen-Yang Wang, Gepeng Ji, Song Shao, Ming-Ming Cheng, Deng-Ping Fan|<https://arxiv.org/pdf/2512.07076v3>|[ä»£ç ](https://github.com/pursuitxi/Context-measure.)|
|ğŸ“ æ›´æ–°|Multimodal Evaluation of Russian-language Architectures|ä¿„è¯­æ¶æ„çš„å¤šæ¨¡æ€è¯„ä¼°|Artem Chervyakov, Ulyana Isaeva, Anton Emelyanov, Artem Safin, Maria Tikhonova, Alexander Kharitonov, Yulia Lyakh, Petr Surovtsev .etc.|<https://arxiv.org/pdf/2511.15552v3>|æ— |
|ğŸ†• å‘å¸ƒ|TempDiffReg: Temporal Diffusion Model for Non-Rigid 2D-3D Vascular Registration|TempDiffRegï¼šç”¨äºéåˆšæ€§2D-3Dè¡€ç®¡é…å‡†çš„æ—¶é—´æ‰©æ•£æ¨¡å‹|Zehua Liu, Shihao Zou, Jincai Huang, Yanfang Zhang, Chao Tong, Weixin Si|<https://arxiv.org/pdf/2601.18168v1>|[ä»£ç ](https://github.com/LZH970328/TempDiffReg.git)|
|ğŸ†• å‘å¸ƒ|Forward Consistency Learning with Gated Context Aggregation for Video Anomaly Detection|åŸºäºé—¨æ§ä¸Šä¸‹æ–‡èšåˆçš„å‰å‘ä¸€è‡´æ€§å­¦ä¹ ç”¨äºè§†é¢‘å¼‚å¸¸æ£€æµ‹|Jiahao Lyu, Minghua Zhao, Xuewen Huang, Yifei Chen, Shuangli Du, Jing Hu, Cheng Shi, Zhiyong Lv|<https://arxiv.org/pdf/2601.18135v1>|æ— |


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|CONQUER: Context-Aware Representation with Query Enhancement for Text-Based Person Search|CONQUER: åŸºäºQueryå¢å¼ºçš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥è¡¨ç¤ºç”¨äºText-Based Person Search|Zequn Xie|<https://arxiv.org/pdf/2601.18625v1>|[ä»£ç ](https://github.com/zqxie77/CONQUER.)|
|ğŸ“ æ›´æ–°|Radiance Fields from Photons|[ç¿»è¯‘å¤±è´¥] Radiance Fields from Photons|Sacha Jungerman, Aryan Garg, Mohit Gupta|<https://arxiv.org/pdf/2407.09386v3>|æ— |
|ğŸ†• å‘å¸ƒ|PPISP: Physically-Plausible Compensation and Control of Photometric Variations in Radiance Field Reconstruction|PPISP: Radiance Fieldé‡å»ºä¸­å…‰åº¦å˜åŒ–çš„ç‰©ç†åˆç†è¡¥å¿ä¸æ§åˆ¶|Isaac Deutsch, Nicolas MoÃ«nne-Loccoz, Gavriel State, Zan Gojcic|<https://arxiv.org/pdf/2601.18336v1>|[ä»£ç ](https://github.com/nv-tlabs/ppisp)|
|ğŸ†• å‘å¸ƒ|Contextual Range-View Projection for 3D LiDAR Point Clouds|[ç¿»è¯‘å¤±è´¥] Contextual Range-View Projection for 3D LiDAR Point Clouds|Seyedali Mousavi, Seyedhamidreza Mousavi, Masoud Daneshtalab|<https://arxiv.org/pdf/2601.18301v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|HomoFM: Deep Homography Estimation with Flow Matching|HomoFM: åŸºäºFlow Matchingçš„æ·±åº¦å•åº”æ€§ä¼°è®¡|Mengfan He, Liangzheng Sun, Chunyu Li, Ziyang Meng|<https://arxiv.org/pdf/2601.18222v1>|[ä»£ç ](https://github.com/hmf21/HomoFM.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|LungCRCT: Causal Representation based Lung CT Processing for Lung Cancer Treatment|LungCRCT: åŸºäºå› æœè¡¨ç¤ºçš„ç”¨äºè‚ºç™Œæ²»ç–—çš„è‚ºéƒ¨CTå¤„ç†|Daeyoung Kim|<https://arxiv.org/pdf/2601.18118v1>|åˆ†æå¤±è´¥|


### è§†è§‰å®šä½ä¸æ˜ å°„ (Visual Localization & Mapping)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|GPA-VGGT:Adapting VGGT to Large Scale Localization by Self-Supervised Learning with Geometry and Physics Aware Loss|GPA-VGGTï¼šé€šè¿‡å…·æœ‰å‡ ä½•å’Œç‰©ç†æ„ŸçŸ¥æŸå¤±çš„è‡ªç›‘ç£å­¦ä¹ å°†VGGTé€‚åº”äºå¤§è§„æ¨¡å®šä½|Yangfan Xu, Lilian Zhang, Xiaofeng He, Pengdong Wu, Wenqi Wu, Jun Mao|<https://arxiv.org/pdf/2601.16885v2>|[ä»£ç ](https://github.com/X-yangfan/GPA-VGGT.)|
|ğŸ†• å‘å¸ƒ|Co-PLNet: A Collaborative Point-Line Network for Prompt-Guided Wireframe Parsing|Co-PLNet: ä¸€ç§ç”¨äºPrompt-Guided Wireframe Parsingçš„ååŒç‚¹çº¿ç½‘ç»œ|Chao Wang, Xuanying Li, Cheng Dai, Jinglei Feng, Yuxiang Luo, Yuqi Ouyang, Hao Qin|<https://arxiv.org/pdf/2601.18252v1>|åˆ†æå¤±è´¥|


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Grasp-and-Lift: Executable 3D Hand-Object Interaction Reconstruction via Physics-in-the-Loop Optimization|Grasp-and-Lift: é€šè¿‡ç‰©ç†é—­ç¯ä¼˜åŒ–å®ç°å¯æ‰§è¡Œçš„3Dæ‰‹-ç‰©äº¤äº’é‡å»º|Byeonggyeol Choi, Woojin Oh, Jongwoo Lim|<https://arxiv.org/pdf/2601.18121v1>|åˆ†æå¤±è´¥|


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### åŠ¨ä½œè¯†åˆ«ä¸ç†è§£ (Action Recognition & Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|BAH Dataset for Ambivalence/Hesitancy Recognition in Videos for Digital Behavioural Change|ç”¨äºæ•°å­—è¡Œä¸ºæ”¹å˜çš„è§†é¢‘ä¸­çŸ›ç›¾/çŠ¹è±«è¯†åˆ«çš„BAHæ•°æ®é›†|Manuela GonzÃ¡lez-GonzÃ¡lez, Soufiane Belharbi, Muhammad Osama Zeeshan, Masoumeh Sharafi, Muhammad Haseeb Aslam, Marco Pedersoli, Alessandro Lameiras Koerich, Simon L Bacon .etc.|<https://arxiv.org/pdf/2505.19328v4>|æ— |
|ğŸ“ æ›´æ–°|Kinetic Mining in Context: Few-Shot Action Synthesis via Text-to-Motion Distillation|ä¸Šä¸‹æ–‡ä¸­çš„åŠ¨æ€æŒ–æ˜ï¼šé€šè¿‡ Text-to-Motion è’¸é¦å®ç° Few-Shot åŠ¨ä½œåˆæˆ|Luca Cazzola, Ahed Alboody|<https://arxiv.org/pdf/2512.11654v2>|[ä»£ç ](https://lucazzola.github.io/publications)|


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|MARC: Memory-Augmented RL Token Compression for Efficient Video Understanding|MARC: ç”¨äºé«˜æ•ˆè§†é¢‘ç†è§£çš„Memory-Augmented RL Tokenå‹ç¼©|Peiran Wu, Zhuorui Yu, Yunze Liu, Chi-Hao Wu, Enmin Zhou, Junxiao Shen|<https://arxiv.org/pdf/2510.07915v2>|æ— |
|ğŸ“ æ›´æ–°|HERMES: KV Cache as Hierarchical Memory for Efficient Streaming Video Understanding|HERMES: å°† KV Cache ä½œä¸ºåˆ†å±‚è®°å¿†ä»¥å®ç°é«˜æ•ˆçš„æµå¼è§†é¢‘ç†è§£|Haowei Zhang, Shudong Yang, Jinlan Fu, See-Kiong Ng, Xipeng Qiu|<https://arxiv.org/pdf/2601.14724v2>|æ— |
|ğŸ†• å‘å¸ƒ|LoD-Structured 3D Gaussian Splatting for Streaming Video Reconstruction|LoD-Structured 3D Gaussian Splatting ç”¨äºæµå¼è§†é¢‘é‡å»º|Xinhui Liu, Can Wang, Lei Liu, Zhenghao Chen, Wei Jiang, Wei Wang, Dong Xu|<https://arxiv.org/pdf/2601.18475v1>|åˆ†æå¤±è´¥|


### è§†é¢‘ç›®æ ‡è·Ÿè¸ª (Video Object Tracking)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|MultiHateLoc: Towards Temporal Localisation of Multimodal Hate Content in Online Videos|MultiHateLoc: åœ¨çº¿è§†é¢‘ä¸­å¤šæ¨¡æ€ä»‡æ¨å†…å®¹çš„æ—¶é—´å®šä½|Qiyue Sun, Tailin Chen, Yinghui Zhang, Yuchen Zhang, Jiangbei Yue, Jianbo Jiao, Zeyu Fu|<https://arxiv.org/pdf/2512.10408v2>|æ— |


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|NC-Reg : Neural Cortical Maps for Rigid Registration|NC-Regï¼šç”¨äºåˆšæ€§é…å‡†çš„ç¥ç»çš®å±‚å›¾è°±|Ines Vati, Pierrick Bourgeat, Rodrigo Santa Cruz, Vincent Dore, Olivier Salvado, Clinton Fookes, LÃ©o Lebrat|<https://arxiv.org/pdf/2601.19042v1>|æ— |
|ğŸ“ æ›´æ–°|An Efficient and Explainable KAN Framework for Wireless Radiation Field Prediction|ä¸€ç§é«˜æ•ˆä¸”å¯è§£é‡Šçš„ KAN æ¡†æ¶ï¼Œç”¨äºæ— çº¿è¾å°„åœºé¢„æµ‹|Jingzhou Shen, Xuyu Wang|<https://arxiv.org/pdf/2601.11656v2>|æ— |
|ğŸ“ æ›´æ–°|GaNI: Global and Near Field Illumination Aware Neural Inverse Rendering|GaNI: å…¨å±€å’Œè¿‘åœºå…‰ç…§æ„ŸçŸ¥ç¥ç»é€†å‘æ¸²æŸ“|Jiaye Wu, Saeed Hadadan, Geng Lin, Matthias Zwicker, David Jacobs, Roni Sengupta|<https://arxiv.org/pdf/2403.15651v4>|æ— |
|ğŸ“ æ›´æ–°|Practical insights on the effect of different encodings, ansÃ¤tze and measurements in quantum and hybrid convolutional neural networks|å…³äºé‡å­å’Œæ··åˆå·ç§¯ç¥ç»ç½‘ç»œä¸­ä¸åŒç¼–ç ã€ansÃ¤tze å’Œæµ‹é‡æ–¹æ³•çš„å®é™…è§è§£|JesÃºs Lozano-Cruz, Albert Nieto-Morales, Oriol BallÃ³-Gimbernat, Adan Garriga, AntÃ³n RodrÃ­guez-Otero, Alejandro Borrallo-Rentero|<https://arxiv.org/pdf/2506.20355v2>|æ— |
|ğŸ†• å‘å¸ƒ|Larger than memory image processing|è¶…è¶Šå†…å­˜çš„å›¾åƒå¤„ç†|Jon Sporring, David Stansby|<https://arxiv.org/pdf/2601.18407v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Depth to Anatomy: Learning Internal Organ Locations from Surface Depth Images|Depth to Anatomy: ä» Surface Depth Images å­¦ä¹  Internal Organ Locations|Eytan Kats, Kai Geissler, Daniel Mensing, Jochen G. Hirsch, Stefan Heldman, Mattias P. Heinrich|<https://arxiv.org/pdf/2601.18260v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Differentiable Architecture Search for Adversarially Robust Quantum Computer Vision|é¢å‘å¯¹æŠ—é²æ£’é‡å­è®¡ç®—æœºè§†è§‰çš„å¯å¾®åˆ†æ¶æ„æœç´¢|Mohamed Afane, Quanjiang Long, Haoting Shen, Ying Mao, Junaid Farooq, Ying Wang, Juntao Chen|<https://arxiv.org/pdf/2601.18058v1>|æ— |
|ğŸ“ æ›´æ–°|A Step to Decouple Optimization in 3DGS|è¿ˆå‘è§£è€¦ 3DGS ä¼˜åŒ–çš„ä¸€æ­¥|Renjie Ding, Yaonan Wang, Min Liu, Jialin Zhu, Jiazheng Wang, Jiahao Zhao, Wenting Shen, Feixiang He .etc.|<https://arxiv.org/pdf/2601.16736v2>|æ— |


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Moonworks Lunara Aesthetic Dataset|Moonworks Lunara ç¾å­¦æ•°æ®é›†|Yan Wang, M M Sayeef Abdullah, Partho Hassan, Sabit Hassan|<https://arxiv.org/pdf/2601.07941v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Counterfactual Explanations on Robust Perceptual Geodesics|é²æ£’æ„ŸçŸ¥æµ‹åœ°çº¿ä¸Šçš„åäº‹å®è§£é‡Š|Eslam Zaher, Maciej Trzaskowski, Quan Nguyen, Fred Roosta|<https://arxiv.org/pdf/2601.18678v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|REMAC: Reference-Based Martian Asymmetrical Image Compression|REMAC: åŸºäºå‚è€ƒçš„ç«æ˜Ÿéå¯¹ç§°å›¾åƒå‹ç¼©|Qing Ding, Mai Xu, Shengxi Li, Xin Deng, Xin Zou|<https://arxiv.org/pdf/2601.18547v1>|æ— |
|ğŸ†• å‘å¸ƒ|AgentDoG: A Diagnostic Guardrail Framework for AI Agent Safety and Security|AgentDoGï¼šé¢å‘ AI Agent å®‰å…¨ä¸å®‰å…¨çš„è¯Šæ–­æŠ¤æ æ¡†æ¶|Dongrui Liu, Qihan Ren, Chen Qian, Shuai Shao, Yuejin Xie, Yu Li, Zhonghao Yang, Haoyu Luo .etc.|<https://arxiv.org/pdf/2601.18491v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Seeing Beyond the Image: ECG and Anatomical Knowledge-Guided Myocardial Scar Segmentation from Late Gadolinium-Enhanced Images|è¶…è¶Šå›¾åƒï¼šECGå’Œè§£å‰–çŸ¥è¯†å¼•å¯¼çš„Late Gadolinium-Enhanced Imageså¿ƒè‚Œç˜¢ç—•åˆ†å‰²|Farheen Ramzan, Yusuf Kiberu, Nikesh Jathanna, Meryem Jabrane, Vicente Grau, Shahnaz Jamil-Copley, Richard H. Clayton, Chen .etc.|<https://arxiv.org/pdf/2511.14702v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Vision-Language-Model-Guided Differentiable Ray Tracing for Fast and Accurate Multi-Material RF Parameter Estimation|[ç¿»è¯‘å¤±è´¥] Vision-Language-Model-Guided Differentiable Ray Tracing for Fast and Accurate Multi-Material RF Parameter Estimation|Zerui Kang, Yishen Lim, Zhouyou Gu, Seung-Woo Ko, Tony Q. S. Quek, Jihong Park|<https://arxiv.org/pdf/2601.18242v1>|æ— |
|ğŸ†• å‘å¸ƒ|Facial Emotion Recognition on FER-2013 using an EfficientNetB2-Based Approach|åŸºäºEfficientNetB2çš„æ–¹æ³•åœ¨FER-2013ä¸Šçš„é¢éƒ¨æƒ…æ„Ÿè¯†åˆ«|Sahil Naik, Soham Bagayatkar, Pavankumar Singh|<https://arxiv.org/pdf/2601.18228v1>|åˆ†æå¤±è´¥|


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|AI-enabled Satellite Edge Computing: A Single-Pixel Feature based Shallow Classification Model for Hyperspectral Imaging|[ç¿»è¯‘å¤±è´¥] AI-enabled Satellite Edge Computing: A Single-Pixel Feature based Shallow Classification Model for Hyperspectral Imaging|Li Fang, Tianyu Li, Yanghong Lin, Shudong Zhou, Wei Yao|<https://arxiv.org/pdf/2601.18560v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|\textsc{NaVIDA}: Vision-Language Navigation with Inverse Dynamics Augmentation|\textsc{NaVIDA}: åŸºäºé€†åŠ¨åŠ›å­¦å¢å¼ºçš„è§†è§‰è¯­è¨€å¯¼èˆª|Weiye Zhu, Zekai Zhang, Xiangchen Wang, Hewei Pan, Teng Wang, Tiantian Geng, Rongtao Xu, Feng Zheng|<https://arxiv.org/pdf/2601.18188v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Text-Pass Filter: An Efficient Scene Text Detector|Text-Pass Filter: ä¸€ç§é«˜æ•ˆçš„åœºæ™¯æ–‡æœ¬æ£€æµ‹å™¨|Chuang Yang, Haozhao Ma, Xu Han, Yuan Yuan, Qi Wang|<https://arxiv.org/pdf/2601.18098v1>|æ— |


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### å¯¹æŠ—é²æ£’æ€§ (Adversarial Robustness)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ARMOR: Agentic Reasoning for Methods Orchestration and Reparameterization for Robust Adversarial Attacks|ARMOR: ç”¨äºé²æ£’å¯¹æŠ—æ”»å‡»çš„æ™ºèƒ½ä½“æ¨ç†ã€æ–¹æ³•ç¼–æ’ä¸é‡å‚æ•°åŒ–|Gabriel Lee Jun Rong, Christos Korgialas, Dion Jia Xu Ho, Pai Chet Ng, Xiaoxiao Miao, Konstantinos N. Plataniotis|<https://arxiv.org/pdf/2601.18386v1>|åˆ†æå¤±è´¥|


### ä¸ç¡®å®šæ€§é‡åŒ– (Uncertainty Quantification)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Automated HER2 scoring with uncertainty quantification using lensfree holography and deep learning|åŸºäºæ— é€é•œå…¨æ¯å’Œæ·±åº¦å­¦ä¹ è¿›è¡ŒHER2è‡ªåŠ¨è¯„åˆ†åŠä¸ç¡®å®šæ€§é‡åŒ–|Che-Yung Shen, Xilin Yang, Yuzhu Li, Leon Lenk, Aydogan Ozcan|<https://arxiv.org/pdf/2601.18219v1>|æ— |
|ğŸ“ æ›´æ–°|The Art of Saying "Maybe": A Conformal Lens for Uncertainty Benchmarking in VLMs|è¯´â€œä¹Ÿè®¸â€çš„è‰ºæœ¯ï¼šç”¨äº VLMs ä¸ç¡®å®šæ€§åŸºå‡†æµ‹è¯•çš„ Conformal Lens|Asif Azad, Mohammad Sadat Hossain, MD Sadik Hossain Shanto, M Saifur Rahman, Md Rizwan Parvez|<https://arxiv.org/pdf/2509.13379v3>|æ— |


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Synthetic Object Compositions for Scalable and Accurate Learning in Detection, Segmentation, and Grounding|ç”¨äºæ£€æµ‹ã€åˆ†å‰²å’Œå®šä½ä¸­å¯æ‰©å±•ä¸”å‡†ç¡®å­¦ä¹ çš„åˆæˆå¯¹è±¡ç»„åˆ|Weikai Huang, Jieyu Zhang, Taoyang Jia, Chenhao Zheng, Ziqi Gao, Jae Sung Park, Winson Han, Ranjay Krishna|<https://arxiv.org/pdf/2510.09110v4>|æ— |
|ğŸ†• å‘å¸ƒ|Pay Attention to Where You Look|[ç¿»è¯‘å¤±è´¥] Pay Attention to Where You Look|Alex Beriand, JhihYang Wu, Daniel Brignac, Natnael Daba, Abhijit Mahalanobis|<https://arxiv.org/pdf/2601.18970v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Low Cost, High Efficiency: LiDAR Place Recognition in Vineyards with Matryoshka Representation Learning|ä½æˆæœ¬ï¼Œé«˜æ•ˆç‡ï¼šåŸºäºMatryoshka Representation Learningçš„è‘¡è„å›­LiDARåœºæ™¯è¯†åˆ«|Judith Vilella-Cantos, Mauro Martini, Marcello Chiaberge, MÃ³nica Ballesta, David Valiente|<https://arxiv.org/pdf/2601.18714v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Scale-Aware Self-Supervised Learning for Segmentation of Small and Sparse Structures|Scale-Awareè‡ªç›‘ç£å­¦ä¹ ç”¨äºå°è€Œç¨€ç–ç»“æ„çš„åˆ†å‰²|Jorge Quesada, Ghassan AlRegib|<https://arxiv.org/pdf/2601.18619v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|On Procrustes Contamination in Machine Learning Applications of Geometric Morphometrics|å‡ ä½•å½¢æ€æµ‹é‡å­¦æœºå™¨å­¦ä¹ åº”ç”¨ä¸­çš„Procrustesæ±¡æŸ“é—®é¢˜|Lloyd Austin Courtenay|<https://arxiv.org/pdf/2601.18448v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Comparative Evaluation of Machine Learning Algorithms for Affective State Recognition from Children's Drawings|ç”¨äºä»å„¿ç«¥ç»˜ç”»ä¸­è¯†åˆ«æƒ…æ„ŸçŠ¶æ€çš„æœºå™¨å­¦ä¹ ç®—æ³•çš„æ¯”è¾ƒè¯„ä¼°|Aura Loredana Dan|<https://arxiv.org/pdf/2601.18414v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Exploiting Minority Pseudo-Labels for Semi-Supervised Fine-grained Road Scene Understanding|åˆ©ç”¨å°‘æ•°ä¼ªæ ‡ç­¾è¿›è¡ŒåŠç›‘ç£ç»†ç²’åº¦é“è·¯åœºæ™¯ç†è§£|Yuting Hong, Yongkang Wu, Hui Xiao, Huazheng Hao, Xiaojie Qiu, Baochen Yao, Chengbin Peng|<https://arxiv.org/pdf/2409.12680v3>|æ— |


### é›¶/å°‘æ ·æœ¬æ³›åŒ– (Zero/Few-shot Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|CMOOD: Concept-based Multi-label OOD Detection|CMOOD: åŸºäºæ¦‚å¿µçš„å¤šæ ‡ç­¾ OOD æ£€æµ‹|Zhendong Liu, Yi Nian, Yuehan Qin, Henry Peng Zou, Li Li, Xiyang Hu, Yue Zhao|<https://arxiv.org/pdf/2411.13578v2>|æ— |
|ğŸ†• å‘å¸ƒ|GUIGuard: Toward a General Framework for Privacy-Preserving GUI Agents|GUIGuardï¼šé¢å‘éšç§ä¿æŠ¤ GUI Agents çš„é€šç”¨æ¡†æ¶|Yanxi Wang, Zhiling Zhang, Wenbo Zhou, Weiming Zhang, Jie Zhang, Qiannan Zhu, Yu Shi, Shuxin Zheng .etc.|<https://arxiv.org/pdf/2601.18842v1>|[ä»£ç ](https://futuresis.github.io/GUIGuard-page); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|CellStyle: Improved Zero-Shot Cell Segmentation via Style Transfer|CellStyle: é€šè¿‡é£æ ¼è¿ç§»æ”¹è¿› Zero-Shot ç»†èƒåˆ†å‰²|RÃ¼veyda Yilmaz, Zhu Chen, Yuli Wu, Johannes Stegmaier|<https://arxiv.org/pdf/2503.08603v2>|æ— |


### å°æ ·æœ¬å­¦ä¹  (Few-shot Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|A-TPT: Angular Diversity Calibration Properties for Test-Time Prompt Tuning of Vision-Language Models|AA-TPT: ç”¨äºVision-Language Models Test-Time Prompt Tuningçš„è§’åº¦å¤šæ ·æ€§æ ¡å‡†å±æ€§|Shihab Aaqil Ahamed, Udaya S. K. P. Miriya Thanthrige, Ranga Rodrigo, Muhammad Haris Khan|<https://arxiv.org/pdf/2510.26441v2>|æ— |
|ğŸ“ æ›´æ–°|GlobalGeoTree: A Multi-Granular Vision-Language Dataset for Global Tree Species Classification|GlobalGeoTree: ä¸€ä¸ªç”¨äºå…¨çƒæ ‘ç§åˆ†ç±»çš„å¤šç²’åº¦è§†è§‰è¯­è¨€æ•°æ®é›†|Yang Mu, Zhitong Xiong, Yi Wang, Muhammad Shahzad, Franz Essl, Holger Kreft, Mark van Kleunen, Xiao Xiang Zhu|<https://arxiv.org/pdf/2505.12513v3>|æ— |


## å…·èº«æ™ºèƒ½ä¸äº¤äº’è§†è§‰ (Embodied Intelligence & Interactive Vision)


### è§†è§‰æ“ä½œä¸æ§åˆ¶ (Visual Manipulation & Control)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Advances and Innovations in the Multi-Agent Robotic System (MARS) Challenge|Multi-Agent Robotic System (MARS) æŒ‘æˆ˜èµ›çš„è¿›å±•ä¸åˆ›æ–°|Li Kang, Heng Zhou, Xiufeng Song, Rui Li, Bruno N. Y. Chen, Ziye Wang, Ximeng Meng, Stone Tao .etc.|<https://arxiv.org/pdf/2601.18733v1>|æ— |


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|ViSIL: Unified Evaluation of Information Loss in Multimodal Video Captioning|ViSILï¼šå¤šæ¨¡æ€è§†é¢‘æè¿°ä¸­ä¿¡æ¯ä¸¢å¤±çš„ç»Ÿä¸€è¯„ä¼°|Po-han Li, Shenghui Chen, Ufuk Topcu, Sandeep Chinchali|<https://arxiv.org/pdf/2601.09851v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|MMedAgent-RL: Optimizing Multi-Agent Collaboration for Multimodal Medical Reasoning|MMedAgent-RLï¼šä¼˜åŒ–å¤šæ¨¡æ€åŒ»å­¦æ¨ç†çš„å¤šæ™ºèƒ½ä½“åä½œ|Peng Xia, Jinglu Wang, Yibo Peng, Kaide Zeng, Zihan Dong, Xian Wu, Xiangru Tang, Hongtu Zhu .etc.|<https://arxiv.org/pdf/2506.00555v3>|æ— |
|ğŸ†• å‘å¸ƒ|AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning|AdaReasoner: ç”¨äºè¿­ä»£è§†è§‰æ¨ç†çš„åŠ¨æ€å·¥å…·ç¼–æ’|Mingyang Song, Haoyu Sun, Jiawei Gu, Linjie Li, Luxin Xu, Ranjay Krishna, Yu Cheng|<https://arxiv.org/pdf/2601.18631v1>|æ— |
|ğŸ“ æ›´æ–°|CLIP's Visual Embedding Projector is a Few-shot Cornucopia|CLIPçš„Visual Embedding Projectoræ˜¯Few-shot Cornucopia|Mohammad Fahes, Tuan-Hung Vu, Andrei Bursuc, Patrick PÃ©rez, Raoul de Charette|<https://arxiv.org/pdf/2410.05270v4>|[ä»£ç ](https://github.com/astra-vision/ProLIP); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Ask Me Again Differently: GRAS for Measuring Bias in Vision Language Models on Gender, Race, Age, and Skin Tone|è¯·æ¢ç§æ–¹å¼é—®æˆ‘ï¼šç”¨äºè¡¡é‡ Vision Language Models åœ¨æ€§åˆ«ã€ç§æ—ã€å¹´é¾„å’Œè‚¤è‰²æ–¹é¢åå·®çš„ GRAS|Shaivi Malik, Hasnat Md Abdullah, Sriparna Saha, Amit Sheth|<https://arxiv.org/pdf/2508.18989v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Noise-Robust AV-ASR Using Visual Features Both in the Whisper Encoder and Decoder|åˆ©ç”¨ Whisper ç¼–ç å™¨å’Œè§£ç å™¨ä¸­çš„è§†è§‰ç‰¹å¾å®ç°æŠ—å™ª AV-ASR|Zhengyang Li, Thomas Graave, BjÃ¶rn MÃ¶ller, Zehang Wu, Matthias Franz, Tim Fingscheidt|<https://arxiv.org/pdf/2601.18396v1>|[ä»£ç ](https://github.com/ifnspaml/Dual-Use-AVASR)|
|ğŸ†• å‘å¸ƒ|Gaze Prediction in Virtual Reality Without Eye Tracking Using Visual and Head Motion Cues|ä¸ä½¿ç”¨çœ¼åŠ¨è¿½è¸ªï¼Œåˆ©ç”¨è§†è§‰å’Œå¤´éƒ¨è¿åŠ¨çº¿ç´¢åœ¨ Virtual Reality ä¸­è¿›è¡Œ Gaze Prediction|Christos Petrou, Harris Partaourides, Athanasios Balomenos, Yannis Kopsinis, Sotirios Chatzis|<https://arxiv.org/pdf/2601.18372v1>|æ— |
|ğŸ“ æ›´æ–°|GeoVLMath: Enhancing Geometry Reasoning in Vision-Language Models via Cross-Modal Reward for Auxiliary Line Creation|GeoVLMathï¼šé€šè¿‡è¾…åŠ©çº¿åˆ›å»ºçš„è·¨æ¨¡æ€å¥–åŠ±å¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹çš„å‡ ä½•æ¨ç†èƒ½åŠ›|Shasha Guo, Liang Pang, Xi Wang, Yanling Wang, Huawei Shen, Jing Zhang|<https://arxiv.org/pdf/2510.11020v2>|æ— |
|ğŸ“ æ›´æ–°|VideoPro: Adaptive Program Reasoning for Long Video Understanding|VideoProï¼šç”¨äºé•¿è§†é¢‘ç†è§£çš„è‡ªé€‚åº”ç¨‹åºæ¨ç†|Chenglin Li, Feng Han, Yikun Wang, Ruilin Li, Shuai Dong, Haowen Hou, Haitao Li, Qianglong Chen .etc.|<https://arxiv.org/pdf/2509.17743v4>|æ— |


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|When Swin Transformer Meets KANs: An Improved Transformer Architecture for Medical Image Segmentation|å½“ Swin Transformer é‡è§ KANsï¼šä¸€ç§ç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²çš„æ”¹è¿› Transformer æ¶æ„|Nishchal Sapkota, Haoyan Shi, Yejia Zhang, Xianshi Ma, Bofang Zheng, Fabian Vazquez, Pengfei Gu, Danny Z. Chen|<https://arxiv.org/pdf/2511.04084v2>|[ä»£ç ](https://github.com/nsapkota417/UKAST); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation|Diffusion Models ä¸­ç”¨äº Cross-Modality Image Translation çš„ Adaptive Domain Shift|Zihao Wang, Yuzhou Chen, Shaogang Ren|<https://arxiv.org/pdf/2601.18623v1>|æ— |
|ğŸ†• å‘å¸ƒ|Generative Diffusion Augmentation with Quantum-Enhanced Discrimination for Medical Image Diagnosis|åŸºäºé‡å­å¢å¼ºåˆ¤åˆ«çš„ç”Ÿæˆæ‰©æ•£å¢å¼ºç”¨äºåŒ»å­¦å›¾åƒè¯Šæ–­|Jingsong Xia, Siqi Wang|<https://arxiv.org/pdf/2601.18556v1>|æ— |
|ğŸ†• å‘å¸ƒ|From Cold Start to Active Learning: Embedding-Based Scan Selection for Medical Image Segmentation|ä»å†·å¯åŠ¨åˆ°ä¸»åŠ¨å­¦ä¹ ï¼šç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²çš„åŸºäºåµŒå…¥çš„æ‰«æé€‰æ‹©|Devon Levy, Bar Assayag, Laura Gaspar, Ilan Shimshoni, Bella Specktor-Fadida|<https://arxiv.org/pdf/2601.18532v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|PCICF: A Pedestrian Crossing Identification and Classification Framework|PCICFï¼šä¸€ç§è¡Œäººè¿‡è¡—è¯†åˆ«ä¸åˆ†ç±»æ¡†æ¶|Junyi Gu, Beatriz Cabrero-Daniel, Ali Nouri, Lydia Armini, Christian Berger|<https://arxiv.org/pdf/2509.24386v2>|[ä»£ç ](https://github.com/Claud1234/PCICF)|
|ğŸ†• å‘å¸ƒ|DisasterInsight: A Multimodal Benchmark for Function-Aware and Grounded Disaster Assessment|DisasterInsight: ä¸€ä¸ªé¢å‘åŠŸèƒ½æ„ŸçŸ¥å’ŒåŸºç¡€ç¾å®³è¯„ä¼°çš„å¤šæ¨¡æ€åŸºå‡†|Sara Tehrani, Yonghao Xu, Leif Haglund, Amanda Berg, Michael Felsberg|<https://arxiv.org/pdf/2601.18493v1>|æ— |
|ğŸ“ æ›´æ–°|From Filters to VLMs: Benchmarking Defogging Methods through Object Detection and Segmentation Performance|ä» Filters åˆ° VLMsï¼šé€šè¿‡ç›®æ ‡æ£€æµ‹å’Œåˆ†å‰²æ€§èƒ½è¯„ä¼°å»é›¾æ–¹æ³•|Ardalan Aryashad, Parsa Razmara, Amin Mahjoub, Seyedarmin Azizi, Mahdi Salmani, Arad Firouzkouhi|<https://arxiv.org/pdf/2510.03906v2>|[ä»£ç ](https://aradfir.github.io/filters-to-vlms-defogging-page)|
|ğŸ“ æ›´æ–°|A Style-Based Profiling Framework for Quantifying the Synthetic-to-Real Gap in Autonomous Driving Datasets|ä¸€ç§åŸºäºé£æ ¼çš„æ¡†æ¶ï¼Œç”¨äºé‡åŒ–è‡ªåŠ¨é©¾é©¶æ•°æ®é›†ä¸­çš„åˆæˆåˆ°çœŸå®å·®è·|Dingyi Yao, Xinyao Han, Ruibo Ming, Zhihang Song, Lihui Peng, Jianming Hu, Danya Yao, Yi Zhang|<https://arxiv.org/pdf/2510.10203v3>|æ— |
|ğŸ“ æ›´æ–°|Not All Pixels Are Equal: Pixel-wise Meta-Learning for Medical Segmentation with Noisy Labels|[ç¿»è¯‘å¤±è´¥] Not All Pixels Are Equal: Pixel-wise Meta-Learning for Medical Segmentation with Noisy Labels|Chenyu Mu, Guihai Chen, Xun Yang, Erkun Yang, Cheng Deng|<https://arxiv.org/pdf/2511.18894v3>|æ— |


### å·¥ä¸šè§†è§‰æ£€æµ‹ (Industrial Visual Inspection)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|V-Loop: Visual Logical Loop Verification for Hallucination Detection in Medical Visual Question Answering|V-Loop: ç”¨äºMedical Visual Question Answeringä¸­å¹»è§‰æ£€æµ‹çš„Visual Logical Loop Verification|Mengyuan Jin, Zehui Liao, Yong Xia|<https://arxiv.org/pdf/2601.18240v1>|åˆ†æå¤±è´¥|


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Multi-Perspective Subimage CLIP with Keyword Guidance for Remote Sensing Image-Text Retrieval|åŸºäºå…³é”®è¯å¼•å¯¼çš„å¤šè§†è§’å­å›¾CLIPç”¨äºé¥æ„Ÿå›¾åƒ-æ–‡æœ¬æ£€ç´¢|Yifan Li, Shiying Wang, Jianqiang Huang|<https://arxiv.org/pdf/2601.18190v1>|[ä»£ç ](https://github.com/Lcrucial1f/MPS-CLIP.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|PRISM-CAFO: Prior-conditioned Remote-sensing Infrastructure Segmentation and Mapping for CAFOs|PRISM-CAFO: åŸºäºå…ˆéªŒæ¡ä»¶çš„CAFOé¥æ„ŸåŸºç¡€è®¾æ–½åˆ†å‰²ä¸åˆ¶å›¾|Oishee Bintey Hoque, Nibir Chandra Mandal, Kyle Luong, Amanda Wilson, Samarth Swarup, Madhav Marathe, Abhijin Adiga|<https://arxiv.org/pdf/2601.11451v2>|[ä»£ç ](https://github.com/Nibir088/PRISM-CAFO.); åˆ†æå¤±è´¥|


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Equi-RO: A 4D mmWave Radar Odometry via Equivariant Networks|Equi-RO: åŸºäºEquivariant Networksçš„4D mmWave Radar Odometry|Zeyu Han, Shuocheng Yang, Minghan Zhu, Fang Zhang, Shaobing Xu, Maani Ghaffari, Jianqiang Wang|<https://arxiv.org/pdf/2509.20674v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|An Unsupervised Tensor-Based Domain Alignment|ä¸€ç§åŸºäºæ— ç›‘ç£å¼ é‡çš„åŸŸå¯¹é½|Chong Hyun Lee, Kibae Lee, Hyun Hee Yim|<https://arxiv.org/pdf/2601.18564v1>|æ— |
|ğŸ†• å‘å¸ƒ|OREHAS: A fully automated deep-learning pipeline for volumetric endolymphatic hydrops quantification in MRI|OREHASï¼šä¸€ç§ç”¨äºMRIä¸­å†…æ·‹å·´ç§¯æ°´ä½“ç§¯å®šé‡çš„å…¨è‡ªåŠ¨æ·±åº¦å­¦ä¹ æµæ°´çº¿|Caterina Fuster-BarcelÃ³, Claudia CastrillÃ³n, Laura Rodrigo-MuÃ±oz, Victor Manuel Vega-SuÃ¡rez, NicolÃ¡s PÃ©rez-FernÃ¡ndez, Gorka Bastarrika, Arrate MuÃ±oz-Barrutia|<https://arxiv.org/pdf/2601.18368v1>|æ— |
|ğŸ†• å‘å¸ƒ|SwipeGen: Bridging the Execution Gap in GUI Agents via Human-like Swipe Synthesis|SwipeGen: é€šè¿‡ç±»äººæ»‘åŠ¨åˆæˆå¼¥åˆ GUI Agents çš„æ‰§è¡Œå·®è·|Xuan Wang, Siyuan Su, Quantong Fu, Yongxiang Hu, Yangfan Zhou|<https://arxiv.org/pdf/2601.18305v1>|æ— |
|ğŸ†• å‘å¸ƒ|AGSP-DSA: An Adaptive Graph Signal Processing Framework for Robust Multimodal Fusion with Dynamic Semantic Alignment|AGSP-DSA: ä¸€ç§åŸºäºåŠ¨æ€è¯­ä¹‰å¯¹é½çš„é²æ£’å¤šæ¨¡æ€èåˆè‡ªé€‚åº”å›¾ä¿¡å·å¤„ç†æ¡†æ¶|KV Karthikeya, Ashok Kumar Das, Shantanu Pal, Vivekananda Bhat K, Arun Sekar Rajasekaran|<https://arxiv.org/pdf/2601.18589v1>|æ— |
|ğŸ†• å‘å¸ƒ|Estimation of geometric transformation matrices using grid-shaped pilot signals|ä½¿ç”¨ç½‘æ ¼çŠ¶å¯¼é¢‘ä¿¡å·ä¼°è®¡å‡ ä½•å˜æ¢çŸ©é˜µ|Rinka Kawano, Masaki Kawamura|<https://arxiv.org/pdf/2601.18385v1>|æ— |
|ğŸ†• å‘å¸ƒ|Computational Framework for Estimating Relative Gaussian Blur Kernels between Image Pairs|ç”¨äºä¼°è®¡å›¾åƒå¯¹ä¹‹é—´ç›¸å¯¹ Gaussian æ¨¡ç³Šæ ¸çš„è®¡ç®—æ¡†æ¶|Akbar Saadat|<https://arxiv.org/pdf/2601.18099v1>|åˆ†æå¤±è´¥|

