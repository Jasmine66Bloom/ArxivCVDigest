## [UPDATED!] **2026-01-27** (Update Time)


## è§†è§‰è¡¨å¾ä¸åŸºç¡€æ¨¡å‹ (Visual Representation & Foundation Models)


### è§†è§‰Transformeræ¶æ„ (Vision Transformer Architectures)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|HexFormer: Hyperbolic Vision Transformer with Exponential Map Aggregation|HexFormer: å¸¦æœ‰æŒ‡æ•°æ˜ å°„èšåˆçš„åŒæ›²è§†è§‰ Transformer|Haya Alyoussef, Ahmad Bdeir, Diego Coello de Portugal Mecke, Tom Hanika, Niels Landwehr, Lars Schmidt-Thieme|<https://arxiv.org/pdf/2601.19849v1>|æ— |
|ğŸ†• å‘å¸ƒ|PaW-ViT: A Patch-based Warping Vision Transformer for Robust Ear Verification|PaW-ViT: ä¸€ç§åŸºäº Patch Warping çš„ Vision Transformerï¼Œç”¨äºé²æ£’çš„äººè€³éªŒè¯|Deeksha Arun, Kevin W. Bowyer, Patrick Flynn|<https://arxiv.org/pdf/2601.19771v1>|æ— |
|ğŸ†• å‘å¸ƒ|Diffusion for De-Occlusion: Accessory-Aware Diffusion Inpainting for Robust Ear Biometric Recognition|[ç¿»è¯‘å¤±è´¥] Diffusion for De-Occlusion: Accessory-Aware Diffusion Inpainting for Robust Ear Biometric Recognition|Deeksha Arun, Kevin W. Bowyer, Patrick Flynn|<https://arxiv.org/pdf/2601.19795v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|DSTCS: Dual-Student Teacher Framework with Segment Anything Model for Semi-Supervised Pubic Symphysis Fetal Head Segmentation|DSTCSï¼šç»“åˆSegment Anything Modelçš„åŒå­¦ç”Ÿæ•™å¸ˆæ¡†æ¶ç”¨äºåŠç›‘ç£è€»éª¨è”åˆèƒå¤´åˆ†å‰²|Yalin Luo, Shun Long, Huijin Wang, Jieyun Bai|<https://arxiv.org/pdf/2601.19446v1>|æ— |
|ğŸ“ æ›´æ–°|MGPC: Multimodal Network for Generalizable Point Cloud Completion With Modality Dropout and Progressive Decoding|MGPC: åŸºäºæ¨¡æ€ä¸¢å¼ƒå’Œæ¸è¿›è§£ç çš„å¯æ³›åŒ–ç‚¹äº‘è¡¥å…¨å¤šæ¨¡æ€ç½‘ç»œ|Jiangyuan Liu, Yuhao Zhao, Hongxuan Ma, Zhe Liu, Jian Wang, Wei Zou|<https://arxiv.org/pdf/2601.03660v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|PyCAT4: A Hierarchical Vision Transformer-based Framework for 3D Human Pose Estimation|PyCAT4: ä¸€ç§åŸºäºHierarchical Vision Transformerçš„3D Human Pose Estimationæ¡†æ¶|Zongyou Yang, Jonathan Loo, Yinghan Hou|<https://arxiv.org/pdf/2508.02806v2>|åˆ†æå¤±è´¥|


### å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ (Large-scale Pretrained Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Benchmarking Multimodal Large Language Models for Missing Modality Completion in Product Catalogues|Benchmarking å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç”¨äºäº§å“ç›®å½•ä¸­çš„ç¼ºå¤±æ¨¡æ€è¡¥å…¨|Junchen Fu, Wenhao Deng, Kaiwen Zheng, Alexandros Karatzoglou, Ioannis Arapakis, Yu Ye, Yongxin Ni, Joemon M. Jose .etc.|<https://arxiv.org/pdf/2601.19750v1>|æ— |
|ğŸ†• å‘å¸ƒ|GMS-CAVP: Improving Audio-Video Correspondence with Multi-Scale Contrastive and Generative Pretraining|GMS-CAVP: åˆ©ç”¨å¤šå°ºåº¦å¯¹æ¯”å’Œç”Ÿæˆé¢„è®­ç»ƒæ”¹è¿›éŸ³è§†é¢‘å¯¹åº”å…³ç³»|Shentong Mo, Zehua Chen, Jun Zhu|<https://arxiv.org/pdf/2601.19606v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Innovator-VL: A Multimodal Large Language Model for Scientific Discovery|Innovator-VL: ç”¨äºç§‘å­¦å‘ç°çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹|Zichen Wen, Boxue Yang, Shuang Chen, Yaojie Zhang, Yuhang Han, Junlong Ke, Cong Wang, Yicheng Fu .etc.|<https://arxiv.org/pdf/2601.19325v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Enhancing Descriptive Captions with Visual Attributes for Multimodal Perception|åˆ©ç”¨è§†è§‰å±æ€§å¢å¼ºæè¿°æ€§å­—å¹•ä»¥å®ç°å¤šæ¨¡æ€æ„ŸçŸ¥|Yanpeng Sun, Jing Hao, Ke Zhu, Jiang-Jiang Liu, Yuxiang Zhao, Xiaofan Li, Na Zhao, Zechao Li .etc.|<https://arxiv.org/pdf/2412.14233v3>|[ä»£ç ](https://github.com/syp2ysy/DCE.)|
|ğŸ“ æ›´æ–°|Knowledge-enhanced Pretraining for Vision-language Pathology Foundation Model on Cancer Diagnosis|ç”¨äºç™Œç—‡è¯Šæ–­çš„è§†è§‰è¯­è¨€ç—…ç†åŸºç¡€æ¨¡å‹çš„çŸ¥è¯†å¢å¼ºé¢„è®­ç»ƒ|Xiao Zhou, Luoyi Sun, Dexuan He, Wenbin Guan, Ge Wang, Ruifen Wang, Lifeng Wang, Xiaojun Yuan .etc.|<https://arxiv.org/pdf/2412.13126v2>|æ— |
|ğŸ“ æ›´æ–°|Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning|Vlaser: å…·æœ‰ååŒå…·èº«æ¨ç†çš„ Vision-Language-Action æ¨¡å‹|Ganlin Yang, Tianyi Zhang, Haoran Hao, Weiyun Wang, Yibin Liu, Dehui Wang, Guanzhou Chen, Zijian Cai .etc.|<https://arxiv.org/pdf/2510.11027v2>|æ— |
|ğŸ“ æ›´æ–°|MindCine: Multimodal EEG-to-Video Reconstruction with Large-Scale Pretrained Models|MindCineï¼šåŸºäºå¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹çš„å¤šæ¨¡æ€ EEG åˆ°è§†é¢‘é‡å»º|Tian-Yi Zhou, Xuan-Hao Liu, Bao-Liang Lu, Wei-Long Zheng|<https://arxiv.org/pdf/2601.18192v2>|æ— |
|ğŸ“ æ›´æ–°|Epistemic-aware Vision-Language Foundation Model for Fetal Ultrasound Interpretation|[ç¿»è¯‘å¤±è´¥] Epistemic-aware Vision-Language Foundation Model for Fetal Ultrasound Interpretation|Xiao He, Huangxuan Zhao, Guojia Wan, Wei Zhou, Yanxing Liu, Juhua Liu, Yongchao Xu, Yong Luo .etc.|<https://arxiv.org/pdf/2510.12953v3>|[ä»£ç ](https://hexiao0275.github.io/FetalMind.)|
|ğŸ†• å‘å¸ƒ|Pixel-Grounded Retrieval for Knowledgeable Large Multimodal Models|[ç¿»è¯‘å¤±è´¥] Pixel-Grounded Retrieval for Knowledgeable Large Multimodal Models|Jeonghwan Kim, Renjie Tao, Sanat Sharma, Jiaqi Wang, Kai Sun, Zhaojiang Lin, Seungwhan Moon, Lambert Mathias .etc.|<https://arxiv.org/pdf/2601.19060v1>|æ— |


### å¤šæ¨¡æ€è¡¨å¾å­¦ä¹  (Multimodal Representation Learning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Self-Supervised Weight Templates for Scalable Vision Model Initialization|è‡ªç›‘ç£æƒé‡æ¨¡æ¿ç”¨äºå¯æ‰©å±•è§†è§‰æ¨¡å‹åˆå§‹åŒ–|Yucheng Xie, Fu Feng, Ruixiao Shi, Jing Wang, Yong Rui, Xin Geng|<https://arxiv.org/pdf/2601.19694v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Towards Governance-Oriented Low-Altitude Intelligence: A Management-Centric Multi-Modal Benchmark With Implicitly Coordinated Vision-Language Reasoning Framework|é¢å‘æ²»ç†çš„ä½ç©ºæ™ºèƒ½ï¼šä»¥ç®¡ç†ä¸ºä¸­å¿ƒçš„å¤šæ¨¡æ€åŸºå‡†ä¸éšå¼åè°ƒçš„è§†è§‰è¯­è¨€æ¨ç†æ¡†æ¶|Hao Chang, Zhihui Wang, Lingxiang Wu, Peijin Wang, Wenhui Diao, Jinqiao Wang|<https://arxiv.org/pdf/2601.19640v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Adaptive Multimodal Person Recognition: A Robust Framework for Handling Missing Modalities|è‡ªé€‚åº”å¤šæ¨¡æ€äººå‘˜è¯†åˆ«ï¼šä¸€ç§å¤„ç†ç¼ºå¤±æ¨¡æ€çš„é²æ£’æ¡†æ¶|Aref Farhadipour, Teodora Vukovic, Volker Dellwo, Petr Motlicek, Srikanth Madikeri|<https://arxiv.org/pdf/2512.14961v3>|æ— |
|ğŸ“ æ›´æ–°|A Genealogy of Foundation Models in Remote Sensing|é¥æ„Ÿé¢†åŸŸ Foundation Models çš„è°±ç³»|Kevin Lane, Morteza Karimzadeh|<https://arxiv.org/pdf/2504.17177v3>|æ— |


## è§†è§‰è¯†åˆ«ä¸ç†è§£ (Visual Recognition & Understanding)


### å…³é”®ç‚¹å®šä½ä¸å§¿æ€ä¼°è®¡ (Keypoint Detection & Pose Estimation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Atomic Depth Estimation From Noisy Electron Microscopy Data Via Deep Learning|åŸºäºæ·±åº¦å­¦ä¹ çš„å™ªå£°ç”µå­æ˜¾å¾®é•œæ•°æ®åŸå­æ·±åº¦ä¼°è®¡|Matan Leibovich, Mai Tan, Ramon Manzorro-Ureba, Adria Marcos-Morales, Sreyas Mohan, Peter A. Crozier, Carlos Fernandez-Granda|<https://arxiv.org/pdf/2601.17046v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|A new Image Similarity Metric for a Perceptual and Transparent Geometric and Chromatic Assessment|ä¸€ç§æ–°çš„ç”¨äºæ„ŸçŸ¥å’Œé€æ˜å‡ ä½•ä¸è‰²å½©è¯„ä¼°çš„å›¾åƒç›¸ä¼¼æ€§åº¦é‡|Antonio Di Marino, Vincenzo Bevilacqua, Emanuel Di Nardo, Angelo Ciaramella, Ivanoe De Falco, Giovanna Sannino|<https://arxiv.org/pdf/2601.19680v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|SeNeDiF-OOD: Semantic Nested Dichotomy Fusion for Out-of-Distribution Detection Methodology in Open-World Classification. A Case Study on Monument Style Classification|SeNeDiF-OODï¼šç”¨äºå¼€æ”¾ä¸–ç•Œåˆ†ç±»ä¸­åˆ†å¸ƒå¤–æ£€æµ‹æ–¹æ³•çš„è¯­ä¹‰åµŒå¥—äºŒåˆ†æ³•èåˆã€‚ä»¥çºªå¿µç¢‘é£æ ¼åˆ†ç±»ä¸ºä¾‹|Ignacio Antequera-SÃ¡nchez, Juan Luis SuÃ¡rez-DÃ­az, Rosana Montes, Francisco Herrera|<https://arxiv.org/pdf/2601.18739v2>|æ— |
|ğŸ†• å‘å¸ƒ|Learned split-spectrum metalens for obstruction-free broadband imaging in the visible|ç”¨äºå¯è§å…‰æ³¢æ®µæ— é®æŒ¡å®½å¸¦æˆåƒçš„ Learned split-spectrum metalens|Seungwoo Yoon, Dohyun Kang, Eunsue Choi, Sohyun Lee, Seoyeon Kim, Minho Choi, Hyeonsu Heo, Dong-ha Shin .etc.|<https://arxiv.org/pdf/2601.19403v1>|æ— |
|ğŸ“ æ›´æ–°|Probing Deep into Temporal Profile Makes the Infrared Small Target Detector Much Better|æ·±å…¥æ¢ç©¶æ—¶åºè½®å»“ä½¿çº¢å¤–å°ç›®æ ‡æ£€æµ‹å™¨æ€§èƒ½æ˜¾è‘—æå‡|Ruojing Li, Wei An, Yingqian Wang, Xinyi Ying, Yimian Dai, Longguang Wang, Miao Li, Yulan Guo .etc.|<https://arxiv.org/pdf/2506.12766v4>|[ä»£ç ](https://github.com/TinaLRJ/DeepPro.); åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Perception-to-Pursuit: Track-Centric Temporal Reasoning for Open-World Drone Detection and Autonomous Chasing|Perception-to-Pursuitï¼šé¢å‘å¼€æ”¾ä¸–ç•Œæ— äººæœºæ£€æµ‹ä¸è‡ªä¸»è¿½é€çš„ä»¥è½¨è¿¹ä¸ºä¸­å¿ƒçš„æ—¶åºæ¨ç†|Venkatakrishna Reddy Oruganti|<https://arxiv.org/pdf/2601.19318v1>|æ— |


### è¯­ä¹‰/å®ä¾‹åˆ†å‰² (Semantic/Instance Segmentation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|MSCloudCAM: Multi-Scale Context Adaptation with Convolutional Cross-Attention for Multispectral Cloud Segmentation|MSCloudCAM: åŸºäºå·ç§¯äº¤å‰æ³¨æ„åŠ›çš„å¤šå°ºåº¦ä¸Šä¸‹æ–‡è‡ªé€‚åº”å¤šå…‰è°±äº‘åˆ†å‰²|Md Abdullah Al Mazid, Liangdong Deng, Naphtali Rishe|<https://arxiv.org/pdf/2510.10802v4>|æ— |
|ğŸ†• å‘å¸ƒ|AMGFormer: Adaptive Multi-Granular Transformer for Brain Tumor Segmentation with Missing Modalities|AMGFormer: ç”¨äºç¼ºå¤±æ¨¡æ€è„‘è‚¿ç˜¤åˆ†å‰²çš„è‡ªé€‚åº”å¤šç²’åº¦Transformer|Chengxiang Guo, Jian Wang, Junhua Fei, Xiao Li, Chunling Chen, Yun Jin|<https://arxiv.org/pdf/2601.19349v1>|[ä»£ç ](https://github.com/guochengxiangives/AMGFormer.)|
|ğŸ†• å‘å¸ƒ|TFFM: Topology-Aware Feature Fusion Module via Latent Graph Reasoning for Retinal Vessel Segmentation|TFFMï¼šåŸºäºæ½œåœ¨å›¾æ¨ç†çš„æ‹“æ‰‘æ„ŸçŸ¥ç‰¹å¾èåˆæ¨¡å—ç”¨äºè§†ç½‘è†œè¡€ç®¡åˆ†å‰²|Iftekhar Ahmed, Shakib Absar, Aftar Ahmad Sami, Shadman Sakib, Debojyoti Biswas, Seraj Al Mahmud Mostafa|<https://arxiv.org/pdf/2601.19136v1>|[ä»£ç ](https://tffm-module.github.io/.); åˆ†æå¤±è´¥|


### ç›®æ ‡æ£€æµ‹ä¸å®šä½ (Object Detection & Localization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Unveiling Perceptual Artifacts: A Fine-Grained Benchmark for Interpretable AI-Generated Image Detection|æ­ç¤ºæ„ŸçŸ¥ä¼ªå½±ï¼šç”¨äºå¯è§£é‡Š AI ç”Ÿæˆå›¾åƒæ£€æµ‹çš„ç»†ç²’åº¦åŸºå‡†|Yao Xiao, Weiyan Chen, Jiahao Chen, Zijie Cao, Weijian Deng, Binbin Yang, Ziyi Dong, Xiangyang Ji .etc.|<https://arxiv.org/pdf/2601.19430v1>|[ä»£ç ](https://github.com/Coxy7/X-AIGD.)|
|ğŸ†• å‘å¸ƒ|Implicit Non-Causal Factors are Out via Dataset Splitting for Domain Generalization Object Detection|é€šè¿‡æ•°æ®é›†å‰”é™¤éšå¼éå› æœå› ç´ ä»¥å®ç°åŸŸæ³›åŒ–ç›®æ ‡æ£€æµ‹|Zhilong Zhang, Lei Zhang, Qing He, Shuyin Xia, Guoyin Wang, Fuxiang Huang|<https://arxiv.org/pdf/2601.19127v1>|æ— |
|ğŸ“ æ›´æ–°|Panoramic Distortion-Aware Tokenization for Person Detection and Localization in Overhead Fisheye Images|Overhead Fisheye å›¾åƒä¸­äººå‘˜æ£€æµ‹ä¸å®šä½çš„å…¨æ™¯ç•¸å˜æ„ŸçŸ¥ Tokenization|Nobuhiko Wakai, Satoshi Sato, Yasunori Ishii, Takayoshi Yamashita|<https://arxiv.org/pdf/2503.14228v4>|æ— |


### å›¾åƒåˆ†ç±»ä¸è¯†åˆ« (Image Classification & Recognition)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Establishing dermatopathology encyclopedia DermpathNet with Artificial Intelligence-Based Workflow|å»ºç«‹åŸºäºäººå·¥æ™ºèƒ½å·¥ä½œæµç¨‹çš„çš®è‚¤ç—…ç†å­¦ç™¾ç§‘å…¨ä¹¦ DermpathNet|Ziyang Xu, Mingquan Lin, Yiliang Zhou, Zihan Xu, Seth J. Orlow, Zihan Xu, Shane A. Meehan, Alexandra Flamm .etc.|<https://arxiv.org/pdf/2601.19378v1>|æ— |


## ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ (Generative Visual Modeling)


### æ¡ä»¶å¼ç”Ÿæˆä¸ç¼–è¾‘ (Conditional Generation & Editing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Parameter-Efficient MoE LoRA for Few-Shot Multi-Style Editing|é¢å‘å°‘æ ·æœ¬å¤šé£æ ¼ç¼–è¾‘çš„å‚æ•°é«˜æ•ˆ MoE LoRA|Cong Cao, Yujie Xu, Xiaodong Xu|<https://arxiv.org/pdf/2511.11236v3>|[ä»£ç ](https://github.com/cao-cong/FSMSE.)|
|ğŸ“ æ›´æ–°|SCoPE VLM: Selective Context Processing for Efficient Document Navigation in Vision-Language Models|SCoPE VLM: Vision-Language Models ä¸­ç”¨äºé«˜æ•ˆæ–‡æ¡£å¯¼èˆªçš„é€‰æ‹©æ€§ä¸Šä¸‹æ–‡å¤„ç†|Gyubeum Lim, Yemo Koo, Vijay Krishna Madisetti|<https://arxiv.org/pdf/2510.21850v2>|æ— |
|ğŸ“ æ›´æ–°|Bounding Box-Guided Diffusion for Synthesizing Industrial Images and Segmentation Map|[ç¿»è¯‘å¤±è´¥] Bounding Box-Guided Diffusion for Synthesizing Industrial Images and Segmentation Map|Emanuele Caruso, Alessandro Simoni, Francesco Pelosin|<https://arxiv.org/pdf/2505.03623v2>|[ä»£ç ](https://github.com/covisionlab/diffusion_labeling.)|
|ğŸ“ æ›´æ–°|JointDiff: Bridging Continuous and Discrete in Multi-Agent Trajectory Generation|JointDiff: åœ¨ Multi-Agent è½¨è¿¹ç”Ÿæˆä¸­è¿æ¥è¿ç»­ä¸ç¦»æ•£|Guillem Capellera, Luis Ferraz, Antonio Rubio, Alexandre Alahi, Antonio Agudo|<https://arxiv.org/pdf/2509.22522v2>|æ— |
|ğŸ†• å‘å¸ƒ|Localized Latent Editing for Dose-Response Modeling in Botulinum Toxin Injection Planning|ç”¨äºè‚‰æ¯’æ¯’ç´ æ³¨å°„è§„åˆ’ä¸­å‰‚é‡-å“åº”å»ºæ¨¡çš„å±€éƒ¨æ½œåœ¨ç¼–è¾‘|EstÃ¨phe Arnaud, Mohamed Daoudi, Pierre Guerreschi|<https://arxiv.org/pdf/2601.19593v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|iFSQ: Improving FSQ for Image Generation with 1 Line of Code|iFSQï¼šç”¨1è¡Œä»£ç æ”¹è¿›FSQä»¥è¿›è¡Œå›¾åƒç”Ÿæˆ|Bin Lin, Zongjian Li, Yuwei Niu, Kaixiong Gong, Yunyang Ge, Yunlong Lin, Mingzhe Zheng, JianWei Zhang .etc.|<https://arxiv.org/pdf/2601.17124v2>|[ä»£ç ](https://github.com/Tencent-Hunyuan/iFSQ)|
|ğŸ†• å‘å¸ƒ|MaDiS: Taming Masked Diffusion Language Models for Sign Language Generation|MaDiS: é©¯æœ Masked Diffusion Language Models ç”¨äºæ‰‹è¯­ç”Ÿæˆ|Ronglai Zuo, Rolandos Alexandros Potamias, Qi Sun, Evangelos Ververas, Jiankang Deng, Stefanos Zafeiriou|<https://arxiv.org/pdf/2601.19577v1>|æ— |
|ğŸ“ æ›´æ–°|MV-S2V: Multi-View Subject-Consistent Video Generation|[ç¿»è¯‘å¤±è´¥] MV-S2V: Multi-View Subject-Consistent Video Generation|Ziyang Song, Xinyu Gong, Bangya Liu, Zelin Zhao|<https://arxiv.org/pdf/2601.17756v2>|[ä»£ç ](https://szy-young.github.io/mv-s2v)|
|ğŸ†• å‘å¸ƒ|Bridging Information Asymmetry: A Hierarchical Framework for Deterministic Blind Face Restoration|å¼¥åˆä¿¡æ¯ä¸å¯¹ç§°ï¼šç¡®å®šæ€§ç›²äººè„¸å¤åŸçš„åˆ†å±‚æ¡†æ¶|Zhengjian Yao, Jiakui Hu, Kaiwen Li, Hangzhou He, Xinliang Zhang, Shuang Zeng, Lei Zhu, Yanye Lu|<https://arxiv.org/pdf/2601.19506v1>|æ— |
|ğŸ†• å‘å¸ƒ|Cortex-Grounded Diffusion Models for Brain Image Generation|åŸºäºCortexçš„æ‰©æ•£æ¨¡å‹ç”¨äºè„‘å›¾åƒç”Ÿæˆ|Fabian Bongratz, Yitong Li, Sama Elbaroudy, Christian Wachinger|<https://arxiv.org/pdf/2601.19498v1>|æ— |
|ğŸ†• å‘å¸ƒ|Dynamic Worlds, Dynamic Humans: Generating Virtual Human-Scene Interaction Motion in Dynamic Scenes|Dynamic Worlds, Dynamic Humans: åœ¨Dynamic Scenesä¸­ç”ŸæˆVirtual Human-Scene Interaction Motion|Yin Wang, Zhiying Leng, Haitian Liu, Frederick W. B. Li, Mu Li, Xiaohui Liang|<https://arxiv.org/pdf/2601.19484v1>|æ— |
|ğŸ†• å‘å¸ƒ|Entropy-Guided k-Guard Sampling for Long-Horizon Autoregressive Video Generation|[ç¿»è¯‘å¤±è´¥] Entropy-Guided k-Guard Sampling for Long-Horizon Autoregressive Video Generation|Yizhao Han, Tianxing Shi, Zhao Wang, Zifan Xu, Zhiyuan Pu, Mingxiao Li, Qian Zhang, Wei Yin .etc.|<https://arxiv.org/pdf/2601.19488v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|LL-GaussianMap: Zero-shot Low-Light Image Enhancement via 2D Gaussian Splatting Guided Gain Maps|LL-GaussianMap: é€šè¿‡ 2D Gaussian Splatting å¼•å¯¼çš„å¢ç›Šå›¾å®ç° Zero-shot ä½å…‰ç…§å›¾åƒå¢å¼º|Yuhan Chen, Ying Fang, Guofa Li, Wenxuan Yu, Yicui Shi, Jingrui Zhang, Kefei Qian, Wenbo Chu .etc.|<https://arxiv.org/pdf/2601.15766v2>|æ— |
|ğŸ“ æ›´æ–°|DiffInk: Glyph- and Style-Aware Latent Diffusion Transformer for Text to Online Handwriting Generation|DiffInkï¼šé¢å‘æ–‡æœ¬åˆ°åœ¨çº¿æ‰‹å†™ç”Ÿæˆçš„å­—å½¢ä¸é£æ ¼æ„ŸçŸ¥æ½œåœ¨æ‰©æ•£ Transformer|Wei Pan, Huiguo He, Hiuyi Cheng, Yilin Shi, Lianwen Jin|<https://arxiv.org/pdf/2509.23624v2>|æ— |
|ğŸ“ æ›´æ–°|R-Meshfusion: Reinforcement Learning Powered Sparse-View Mesh Reconstruction with Diffusion Priors|R-Meshfusion: åŸºäºReinforcement Learningå’ŒDiffusion Priorsçš„ç¨€ç–è§†è§’Mesh Reconstruction|Haoyang Wang, Liming Liu, Peiheng Wang, Junlin Hao, Jiangkai Wu, Xinggong Zhang|<https://arxiv.org/pdf/2504.11946v2>|æ— |
|ğŸ“ æ›´æ–°|Astra: General Interactive World Model with Autoregressive Denoising|Astraï¼šåŸºäºè‡ªå›å½’å»å™ªçš„é€šç”¨äº¤äº’å¼ä¸–ç•Œæ¨¡å‹|Yixuan Zhu, Jiaqi Feng, Wenzhao Zheng, Yuan Gao, Xin Tao, Pengfei Wan, Jie Zhou, Jiwen Lu|<https://arxiv.org/pdf/2512.08931v3>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|VC-Bench: Pioneering the Video Connecting Benchmark with a Dataset and Evaluation Metrics|VC-Bench: é€šè¿‡æ•°æ®é›†å’Œè¯„ä¼°æŒ‡æ ‡å¼€åˆ›è§†é¢‘è¿æ¥åŸºå‡†|Zhiyu Yin, Zhipeng Liu, Kehai Chen, Lemao Liu, Jin Liu, Hong-Dong Li, Yang Xiang, Min Zhang|<https://arxiv.org/pdf/2601.19236v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Towards Pixel-Level VLM Perception via Simple Points Prediction|[ç¿»è¯‘å¤±è´¥] Towards Pixel-Level VLM Perception via Simple Points Prediction|Tianhui Song, Haoyu Lu, Hao Yang, Lin Sui, Haoning Wu, Zaida Zhou, Zhiqi Huang, Yiping Bao .etc.|<https://arxiv.org/pdf/2601.19228v1>|æ— |
|ğŸ†• å‘å¸ƒ|SNR-Edit: Structure-Aware Noise Rectification for Inversion-Free Flow-Based Editing|SNR-Edit: ç”¨äºå…åæ¼”åŸºäºæµç¼–è¾‘çš„ç»“æ„æ„ŸçŸ¥å™ªå£°æ ¡æ­£|Lifan Jiang, Boxi Wu, Yuhang Pei, Tianrun Wu, Yongyuan Chen, Yan Zhao, Shiyu Yu, Deng Cai|<https://arxiv.org/pdf/2601.19180v1>|æ— |
|ğŸ†• å‘å¸ƒ|CLIP-Guided Unsupervised Semantic-Aware Exposure Correction|CLIP-Guided æ— ç›‘ç£è¯­ä¹‰æ„ŸçŸ¥æ›å…‰æ ¡æ­£|Puzhen Wu, Han Weng, Quan Zheng, Yi Zhan, Hewei Wang, Yiming Li, Jiahui Han, Rui Xu|<https://arxiv.org/pdf/2601.19129v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Generation then Reconstruction: Accelerating Masked Autoregressive Models via Two-Stage Sampling|[ç¿»è¯‘å¤±è´¥] Generation then Reconstruction: Accelerating Masked Autoregressive Models via Two-Stage Sampling|Feihong Yan, Peiru Wang, Yao Zhu, Kaiyu Pang, Qingyan Wei, Huiqi Li, Linfeng Zhang|<https://arxiv.org/pdf/2510.17171v2>|[ä»£ç ](https://github.com/feihongyan1/GtR.)|
|ğŸ†• å‘å¸ƒ|NuiWorld: Exploring a Scalable Framework for End-to-End Controllable World Generation|NuiWorldï¼šæ¢ç´¢ä¸€ç§ç«¯åˆ°ç«¯å¯æ§ä¸–ç•Œç”Ÿæˆçš„å¯æ‰©å±•æ¡†æ¶|Han-Hung Lee, Cheng-Yu Yang, Yu-Lun Liu, Angel X. Chang|<https://arxiv.org/pdf/2601.19048v1>|æ— |


### ä¸‰ç»´å†…å®¹ç”Ÿæˆ (3D Content Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|GeoDiff3D: Self-Supervised 3D Scene Generation with Geometry-Constrained 2D Diffusion Guidance|GeoDiff3D: åŸºäºå‡ ä½•çº¦æŸ 2D Diffusion æŒ‡å¯¼çš„è‡ªç›‘ç£ 3D åœºæ™¯ç”Ÿæˆ|Haozhi Zhu, Miaomiao Zhao, Dingyao Liu, Runze Tian, Yan Zhang, Jie Guo, Fenggen Yu|<https://arxiv.org/pdf/2601.19785v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Video-KTR: Reinforcing Video Reasoning via Key Token Attribution|Video-KTR: é€šè¿‡å…³é”® Token å½’å› å¢å¼ºè§†é¢‘æ¨ç†|Ziyue Wang, Sheng Jin, Zhongrong Zuo, Jiawei Wu, Han Qiu, Qi She, Hao Zhang, Xudong Jiang|<https://arxiv.org/pdf/2601.19686v1>|[ä»£ç ](https://github.com/zywang0104/Video-KTR.)|
|ğŸ†• å‘å¸ƒ|RoamScene3D: Immersive Text-to-3D Scene Generation via Adaptive Object-aware Roaming|RoamScene3Dï¼šé€šè¿‡è‡ªé€‚åº”å¯¹è±¡æ„ŸçŸ¥æ¼«æ¸¸å®ç°æ²‰æµ¸å¼Text-to-3Dåœºæ™¯ç”Ÿæˆ|Jisheng Chu, Wenrui Li, Rui Zhao, Wangmeng Zuo, Shifeng Chen, Xiaopeng Fan|<https://arxiv.org/pdf/2601.19433v1>|[ä»£ç ](https://github.com/JS-CHU/RoamScene3D.)|
|ğŸ†• å‘å¸ƒ|Handcrafted Feature Fusion for Reliable Detection of AI-Generated Images|Handcrafted Feature Fusion for AIç”Ÿæˆå›¾åƒçš„å¯é æ£€æµ‹|Syed Mehedi Hasan Nirob, Moqsadur Rahman, Shamim Ehsan, Summit Haque|<https://arxiv.org/pdf/2601.19262v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|LocationAgent: A Hierarchical Agent for Image Geolocation via Decoupling Strategy and Evidence from Parametric Knowledge|LocationAgent: ä¸€ç§åŸºäºè§£è€¦ç­–ç•¥å’Œå‚æ•°åŒ–çŸ¥è¯†è¯æ®çš„å›¾åƒåœ°ç†å®šä½åˆ†å±‚Agent|Qiujun Li, Zijin Xiao, Xulin Wang, Zhidan Ma, Cheng Yang, Haifeng Li|<https://arxiv.org/pdf/2601.19155v1>|æ— |
|ğŸ†• å‘å¸ƒ|FBSDiff++: Improved Frequency Band Substitution of Diffusion Features for Efficient and Highly Controllable Text-Driven Image-to-Image Translation|FBSDiff++ï¼šæ”¹è¿›çš„æ‰©æ•£ç‰¹å¾é¢‘å¸¦æ›¿æ¢ï¼Œç”¨äºé«˜æ•ˆä¸”é«˜åº¦å¯æ§çš„æ–‡æœ¬é©±åŠ¨å›¾åƒåˆ°å›¾åƒç¿»è¯‘|Xiang Gao, Yunpeng Jia|<https://arxiv.org/pdf/2601.19115v1>|æ— |
|ğŸ“ æ›´æ–°|Watermark-based Attribution of AI-Generated Content|åŸºäºæ°´å°çš„AIç”Ÿæˆå†…å®¹å½’å› |Zhengyuan Jiang, Moyang Guo, Yuepeng Hu, Yupu Wang, Neil Zhenqiang Gong|<https://arxiv.org/pdf/2404.04254v4>|æ— |


### æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (Diffusion Probabilistic Models)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|LangForce: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries|LangForce: é€šè¿‡Latent Action Querieså¯¹Vision Language Action Modelsè¿›è¡Œè´å¶æ–¯åˆ†è§£|Shijie Lian, Bin Yu, Xiaopeng Lin, Laurence T. Yang, Zhaolong Shen, Changti Wu, Yuzhuo Miao, Cong Huang .etc.|<https://arxiv.org/pdf/2601.15197v4>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|SWA-LDM: Toward Stealthy Watermarks for Latent Diffusion Models|SWA-LDM: é¢å‘ Latent Diffusion Models çš„éšè”½æ°´å°|Zhonghao Yang, Linye Lyu, Xuanhang Chang, Daojing He, YU LI|<https://arxiv.org/pdf/2502.10495v2>|æ— |
|ğŸ“ æ›´æ–°|There and Back Again: On the relation between Noise and Image Inversions in Diffusion Models|There and Back Again: è®º Diffusion Models ä¸­ Noise å’Œ Image Inversions ä¹‹é—´çš„å…³ç³»|Åukasz Staniszewski, Åukasz KuciÅ„ski, Kamil Deja|<https://arxiv.org/pdf/2410.23530v5>|[ä»£ç ](https://github.com/luk-st/taba.)|
|ğŸ“ æ›´æ–°|Self-Evolving Vision-Language Models for Image Quality Assessment via Voting and Ranking|åŸºäºæŠ•ç¥¨å’Œæ’åºçš„è‡ªæ¼”è¿›è§†è§‰-è¯­è¨€æ¨¡å‹ç”¨äºå›¾åƒè´¨é‡è¯„ä¼°|Wen Wen, Tianwu Zhi, Kanglong Fan, Yang Li, Xinge Peng, Yabin Zhang, Yiting Liao, Junlin Li .etc.|<https://arxiv.org/pdf/2509.25787v4>|æ— |
|ğŸ“ æ›´æ–°|Diffusion models for multivariate subsurface generation and efficient probabilistic inversion|[ç¿»è¯‘å¤±è´¥] Diffusion models for multivariate subsurface generation and efficient probabilistic inversion|Roberto Miele, Niklas Linde|<https://arxiv.org/pdf/2507.15809v4>|æ— |
|ğŸ“ æ›´æ–°|Universal Multi-Domain Translation via Diffusion Routers|é€šè¿‡ Diffusion Routers å®ç°é€šç”¨å¤šåŸŸç¿»è¯‘|Duc Kieu, Kien Do, Tuan Hoang, Thao Minh Le, Tung Kieu, Dang Nguyen, Thin Nguyen|<https://arxiv.org/pdf/2510.03252v3>|æ— |
|ğŸ“ æ›´æ–°|Revealing Subtle Phenotypes in Small Microscopy Datasets Using Latent Diffusion Models|åˆ©ç”¨ Latent Diffusion Models æ­ç¤ºå°è§„æ¨¡æ˜¾å¾®é•œæ•°æ®é›†ä¸­çš„ç»†å¾®è¡¨å‹|Anis Bourou, Biel CastaÃ±o Segade, Thomas Boyer, ValÃ©rie Mezger, Auguste Genovesio|<https://arxiv.org/pdf/2502.09665v2>|æ— |
|ğŸ“ æ›´æ–°|Token Caching for Diffusion Transformer Acceleration|ç”¨äº Diffusion Transformer åŠ é€Ÿçš„ Token Caching|Jinming Lou, Wenyang Luo, Yufan Liu, Bing Li, Xinmiao Ding, Weiming Hu, Yuming Li, Chenguang Ma|<https://arxiv.org/pdf/2409.18523v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|ProMist-5K: A Comprehensive Dataset for Digital Emulation of Cinematic Pro-Mist Filter Effects|ProMist-5Kï¼šç”¨äºç”µå½±çº§ Pro-Mist æ»¤é•œæ•ˆæœæ•°å­—ä»¿çœŸçš„ç»¼åˆæ•°æ®é›†|Yingtie Lei, Zimeng Li, Chi-Man Pun, Wangyu Wu, Junke Yang, Xuhang Chen|<https://arxiv.org/pdf/2601.19295v1>|æ— |
|ğŸ“ æ›´æ–°|ForensicHub: A Unified Benchmark & Codebase for All-Domain Fake Image Detection and Localization|ForensicHubï¼šé¢å‘å…¨åŸŸå‡å›¾åƒæ£€æµ‹ä¸å®šä½çš„ç»Ÿä¸€åŸºå‡†ä¸ä»£ç åº“|Bo Du, Xuekang Zhu, Xiaochen Ma, Chenfan Qu, Kaiwen Feng, Zhe Yang, Chi-Man Pun, Jian Liu .etc.|<https://arxiv.org/pdf/2505.11003v3>|æ— |
|ğŸ“ æ›´æ–°|Image deblurring based on lightweight multi-information fusion network|åŸºäºè½»é‡çº§å¤šä¿¡æ¯èåˆç½‘ç»œçš„å›¾åƒå»æ¨¡ç³Š|Yanni Zhang, Yiming Liu, Qiang Li, Miao Qi, Dahong Xu, Jun Kong, Jianzhong Wang|<https://arxiv.org/pdf/2101.05403v2>|æ— |
|ğŸ“ æ›´æ–°|Streaming-dLLM: Accelerating Diffusion LLMs via Suffix Pruning and Dynamic Decoding|Streaming-dLLMï¼šé€šè¿‡åç¼€å‰ªæå’ŒåŠ¨æ€è§£ç åŠ é€Ÿæ‰©æ•£ LLM|Zhongyu Xiao, Zhiwei Hao, Jianyuan Guo, Yong Luo, Jia Liu, Jie Xu, Han Hu|<https://arxiv.org/pdf/2601.17917v2>|[ä»£ç ](https://github.com/xiaoshideta/Streaming-dLLM.)|
|ğŸ†• å‘å¸ƒ|Privacy-Preserving Model Transcription with Differentially Private Synthetic Distillation|åŸºäºå·®åˆ†éšç§åˆæˆè’¸é¦çš„éšç§ä¿æŠ¤æ¨¡å‹è½¬å½•|Bochao Liu, Shiming Ge, Pengju Wang, Shikun Li, Tongliang Liu|<https://arxiv.org/pdf/2601.19090v1>|æ— |


### æ—¶ç©ºä¸€è‡´æ€§ç”Ÿæˆ (Spatiotemporal Coherent Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Mocap Anywhere: Towards Pairwise-Distance based Motion Capture in the Wild (for the Wild)|Mocap Anywhere: åŸºäºæˆå¯¹è·ç¦»çš„é‡å¤–è¿åŠ¨æ•æ‰ (for the Wild) è¿ˆå‘|Ofir Abramovich, Ariel Shamir, Andreas Aristidou|<https://arxiv.org/pdf/2601.19519v1>|æ— |
|ğŸ“ æ›´æ–°|SVBench: Evaluation of Video Generation Models on Social Reasoning|SVBench: è§†é¢‘ç”Ÿæˆæ¨¡å‹åœ¨ç¤¾äº¤æ¨ç†ä¸Šçš„è¯„ä¼°|Wenshuo Peng, Gongxuan Wang, Tianmeng Yang, Chuanhao Li, Xiaojie Xu, Hui He, Kaipeng Zhang|<https://arxiv.org/pdf/2512.21507v2>|æ— |
|ğŸ“ æ›´æ–°|The Script is All You Need: An Agentic Framework for Long-Horizon Dialogue-to-Cinematic Video Generation|[ç¿»è¯‘å¤±è´¥] The Script is All You Need: An Agentic Framework for Long-Horizon Dialogue-to-Cinematic Video Generation|Chenyu Mu, Xin He, Qu Yang, Wanshun Chen, Jiadi Yao, Huang Liu, Zihao Yi, Bo Zhao .etc.|<https://arxiv.org/pdf/2601.17737v2>|åˆ†æå¤±è´¥|


## ä¸‰ç»´è§†è§‰ä¸å‡ ä½•æ¨ç† (3D Vision & Geometric Reasoning)


### å¤šè§†å›¾å‡ ä½•é‡å»º (Multi-view Geometric Reconstruction)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|VGGT-SLAM 2.0: Real time Dense Feed-forward Scene Reconstruction|VGGT-SLAM 2.0: å®æ—¶å¯†é›†å‰é¦ˆåœºæ™¯é‡å»º|Dominic Maggio, Luca Carlone|<https://arxiv.org/pdf/2601.19887v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Geometry-Grounded Gaussian Splatting|[ç¿»è¯‘å¤±è´¥] Geometry-Grounded Gaussian Splatting|Baowen Zhang, Chenxing Jiang, Heng Li, Shaojie Shen, Ping Tan|<https://arxiv.org/pdf/2601.17835v2>|æ— |
|ğŸ†• å‘å¸ƒ|Fast Converging 3D Gaussian Splatting for 1-Minute Reconstruction|å¿«é€Ÿæ”¶æ•›çš„ 3D Gaussian Splatting ç”¨äº 1 åˆ†é’Ÿé‡å»º|Ziyu Zhang, Tianle Liu, Diantao Tu, Shuhan Shen|<https://arxiv.org/pdf/2601.19489v1>|æ— |
|ğŸ“ æ›´æ–°|Gradient-Direction-Aware Density Control for 3D Gaussian Splatting|é¢å‘æ¢¯åº¦æ–¹å‘çš„3D Gaussian Splattingå¯†åº¦æ§åˆ¶|Zheng Zhou, Yu-Jie Xiong, Jia-Chen Zhang, Chun-Ming Xia, Xihe Qiu, Hongjian Zhan|<https://arxiv.org/pdf/2508.09239v2>|æ— |
|ğŸ†• å‘å¸ƒ|m2sv: A Scalable Benchmark for Map-to-Street-View Spatial Reasoning|m2sv: ä¸€ä¸ªç”¨äºåœ°å›¾åˆ°è¡—æ™¯ç©ºé—´æ¨ç†çš„å¯æ‰©å±•åŸºå‡†|Yosub Shin, Michael Buriek, Igor Molybog|<https://arxiv.org/pdf/2601.19099v1>|åˆ†æå¤±è´¥|


### ç¥ç»è¾å°„åœºè¡¨ç¤º (Neural Radiance Field Representation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|WaterClear-GS: Optical-Aware Gaussian Splatting for Underwater Reconstruction and Restoration|WaterClear-GS: ç”¨äºæ°´ä¸‹é‡å»ºä¸æ¢å¤çš„å…‰æ„ŸçŸ¥ Gaussian Splatting|Xinrui Zhang, Yufeng Wang, Shuangkang Fang, Zesheng Wang, Dacheng Qi, Wenrui Ding|<https://arxiv.org/pdf/2601.19753v1>|[ä»£ç ](https://buaaxrzhang.github.io/WaterClear-GS)|
|ğŸ“ æ›´æ–°|NegoCollab: A Common Representation Negotiation Approach for Heterogeneous Collaborative Perception|NegoCollabï¼šä¸€ç§ç”¨äºå¼‚æ„ååŒæ„ŸçŸ¥çš„é€šç”¨è¡¨ç¤ºåå•†æ–¹æ³•|Congzhang Shao, Quan Yuan, Guiyang Luo, Yue Hu, Danni Wang, Yilin Liu, Rui Pan, Bo Chen .etc.|<https://arxiv.org/pdf/2510.27647v2>|æ— |
|ğŸ“ æ›´æ–°|Universal Beta Splatting|é€šç”¨ Beta Splatting|Rong Liu, Zhongpai Gao, Benjamin Planche, Meida Chen, Van Nguyen Nguyen, Meng Zheng, Anwesa Choudhuri, Terrence Chen .etc.|<https://arxiv.org/pdf/2510.03312v2>|[ä»£ç ](https://rongliu-leo.github.io/universal-beta-splatting)|
|ğŸ†• å‘å¸ƒ|QA-ReID: Quality-Aware Query-Adaptive Convolution Leveraging Fused Global and Structural Cues for Clothes-Changing ReID|QA-ReID: Quality-Aware Query-Adaptive Convolution åˆ©ç”¨èåˆçš„å…¨å±€å’Œç»“æ„çº¿ç´¢ç”¨äºæ¢è¡£ ReID|Yuxiang Wang, Kunming Jiang, Tianxiang Zhang, Ke Tian, Gaozhe Jiang|<https://arxiv.org/pdf/2601.19133v1>|æ— |


### è§†è§‰å®šä½ä¸æ˜ å°„ (Visual Localization & Mapping)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|The S3LI Vulcano Dataset: A Dataset for Multi-Modal SLAM in Unstructured Planetary Environments|S3LI Vulcanoæ•°æ®é›†ï¼šç”¨äºéç»“æ„åŒ–è¡Œæ˜Ÿç¯å¢ƒå¤šæ¨¡æ€SLAMçš„æ•°æ®é›†|Riccardo Giubilato, Marcus Gerhard MÃ¼ller, Marco Sewtz, Laura Alejandra Encinar Gonzalez, John Folkesson, Rudolph Triebel|<https://arxiv.org/pdf/2601.19557v1>|[ä»£ç ](https://github.com/DLR-RM/s3li-toolkit)|


## æ—¶åºè§†è§‰åˆ†æ (Temporal Visual Analysis)


### é•¿æ—¶åºè§†é¢‘ç†è§£ (Long-term Video Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|MLVTG: Mamba-Based Feature Alignment and LLM-Driven Purification for Multi-Modal Video Temporal Grounding|MLVTG: åŸºäº Mamba çš„ç‰¹å¾å¯¹é½ä¸ LLM é©±åŠ¨çš„å‡€åŒ–ç”¨äºå¤šæ¨¡æ€è§†é¢‘æ—¶åºå®šä½|Zhiyi Zhu, Xiaoyu Wu, Zihao Liu, Linlin Yang|<https://arxiv.org/pdf/2506.08512v2>|æ— |


### åŠ¨ä½œè¯†åˆ«ä¸ç†è§£ (Action Recognition & Understanding)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Mitigating Attention Sinks and Massive Activations in Audio-Visual Speech Recognition with LLMs|åˆ©ç”¨ LLM ç¼“è§£è§†å¬è¯­éŸ³è¯†åˆ«ä¸­çš„ Attention Sinks å’Œ Massive Activations|Anand, Umberto Cappellazzo, Stavros Petridis, Maja Pantic|<https://arxiv.org/pdf/2510.22603v3>|åˆ†æå¤±è´¥|


## è‡ªç›‘ç£ä¸è¡¨å¾å­¦ä¹  (Self-supervised & Representation Learning)


### å¯¹æ¯”å­¦ä¹ æ–¹æ³• (Contrastive Learning Methods)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|EgoHandICL: Egocentric 3D Hand Reconstruction with In-Context Learning|EgoHandICL: åŸºäºIn-Context Learningçš„Egocentric 3D Hand Reconstruction|Binzhu Xie, Shi Qiu, Sicheng Zhang, Yinqiao Wang, Hao Xu, Muzammal Naseer, Chi-Wing Fu, Pheng-Ann Heng|<https://arxiv.org/pdf/2601.19850v1>|[ä»£ç ](https://github.com/Nicous20/EgoHandICL)|


## è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹ä¼˜åŒ– (Computational Efficiency & Model Optimization)


### ç¥ç»æ¶æ„ä¼˜åŒ– (Neural Architecture Optimization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|SONIC: Spectral Oriented Neural Invariant Convolutions|[ç¿»è¯‘å¤±è´¥] SONIC: Spectral Oriented Neural Invariant Convolutions|Gijs Joppe Moens, Regina Beets-Tan, Eduardo H. P. Pooch|<https://arxiv.org/pdf/2601.19884v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|SharpNet: Enhancing MLPs to Represent Functions with Controlled Non-differentiability|SharpNet: å¢å¼º MLP ä»¥è¡¨ç¤ºå…·æœ‰å—æ§ä¸å¯å¾®æ€§çš„å‡½æ•°|Hanting Niu, Junkai Deng, Fei Hou, Wencheng Wang, Ying He|<https://arxiv.org/pdf/2601.19683v1>|æ— |
|ğŸ“ æ›´æ–°|Distillation-based Layer Dropping (DLD): Effective End-to-end Framework for Dynamic Speech Networks|åŸºäºè’¸é¦çš„å±‚ä¸¢å¼ƒ (DLD)ï¼šåŠ¨æ€è¯­éŸ³ç½‘ç»œçš„é«˜æ•ˆç«¯åˆ°ç«¯æ¡†æ¶|Abdul Hannan, Daniele Falavigna, Shah Nawaz, Mubashir Noman, Markus Schedl, Alessio Brutti|<https://arxiv.org/pdf/2601.16117v2>|æ— |
|ğŸ†• å‘å¸ƒ|Resolving Primitive-Sharing Ambiguity in Long-Tailed Industrial Point Cloud Segmentation via Spatial Context Constraints|é€šè¿‡ç©ºé—´ä¸Šä¸‹æ–‡çº¦æŸè§£å†³é•¿å°¾å·¥ä¸šç‚¹äº‘åˆ†å‰²ä¸­çš„åŸºå…ƒå…±äº«æ­§ä¹‰|Chao Yin, Qing Han, Zhiwei Hou, Yue Liu, Anjin Dai, Hongda Hu, Ji Yang, Wei Yao|<https://arxiv.org/pdf/2601.19128v1>|åˆ†æå¤±è´¥|


### èµ„æºå—é™è§†è§‰è®¡ç®— (Resource-constrained Visual Computing)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|DiffStyle3D: Consistent 3D Gaussian Stylization via Attention Optimization|DiffStyle3D: é€šè¿‡æ³¨æ„åŠ›ä¼˜åŒ–çš„ä¸€è‡´æ€§3Dé«˜æ–¯é£æ ¼åŒ–|Yitong Yang, Xuexin Liu, Yinglin Wang, Jing Wang, Hao Dou, Changshuo Wang, Shuting He|<https://arxiv.org/pdf/2601.19717v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|A Non-Invasive 3D Gait Analysis Framework for Quantifying Psychomotor Retardation in Major Depressive Disorder|ä¸€ç§ç”¨äºé‡åŒ–é‡åº¦ç²¾ç¥éšœç¢ä¸­ç²¾ç¥è¿åŠ¨è¿Ÿæ»çš„æ— åˆ› 3D æ­¥æ€åˆ†ææ¡†æ¶|Fouad Boutaleb, Emery Pierson, Mohamed Daoudi, ClÃ©mence Nineuil, Ali Amad, Fabien D'Hondt|<https://arxiv.org/pdf/2601.19526v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Contrastive Spectral Rectification: Test-Time Defense towards Zero-shot Adversarial Robustness of CLIP|å¯¹æ¯”å…‰è°±ä¿®æ­£ï¼šé¢å‘ CLIP é›¶æ ·æœ¬å¯¹æŠ—é²æ£’æ€§çš„æµ‹è¯•æ—¶é˜²å¾¡|Sen Nie, Jie Zhang, Zhuo Wang, Shiguang Shan, Xilin Chen|<https://arxiv.org/pdf/2601.19210v1>|[ä»£ç ](https://github.com/Summu77/CSR.)|
|ğŸ†• å‘å¸ƒ|Optimized $k$-means color quantization of digital images in machine-based and human perception-based colorspaces|åŸºäºæœºå™¨æ„ŸçŸ¥å’Œäººç±»æ„ŸçŸ¥é¢œè‰²ç©ºé—´çš„æ•°å­—å›¾åƒä¼˜åŒ– $k$-means é¢œè‰²é‡åŒ–|Ranjan Maitra|<https://arxiv.org/pdf/2601.19117v1>|æ— |


### æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ (Model Compression & Acceleration)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|QuaMo: Quaternion Motions for Vision-based 3D Human Kinematics Capture|QuaMo: ç”¨äºåŸºäºè§†è§‰çš„ 3D äººä½“è¿åŠ¨å­¦æ•æ‰çš„ Quaternion Motions|Cuong Le, Pavlo Melnyk, Urs Waldmann, MÃ¥rten WadenbÃ¤ck, Bastian Wandt|<https://arxiv.org/pdf/2601.19580v1>|[ä»£ç ](https://github.com/cuongle1206/QuaMo)|
|ğŸ“ æ›´æ–°|Deep Ensembling with No Overhead for either Training or Testing: The All-Round Blessings of Dynamic Sparsity|è®­ç»ƒæˆ–æµ‹è¯•é›¶å¼€é”€çš„æ·±åº¦é›†æˆï¼šåŠ¨æ€ç¨€ç–æ€§çš„å…¨æ–¹ä½ä¼˜åŠ¿|Shiwei Liu, Tianlong Chen, Zahra Atashgahi, Xiaohan Chen, Ghada Sokar, Elena Mocanu, Mykola Pechenizkiy, Zhangyang Wang .etc.|<https://arxiv.org/pdf/2106.14568v5>|[ä»£ç ](https://github.com/VITA-Group/FreeTickets.)|
|ğŸ“ æ›´æ–°|KOCOBrain: Kuramoto-Guided Graph Network for Uncovering Structure-Function Coupling in Adolescent Prenatal Drug Exposure|KOCOBrainï¼šç”¨äºæ­ç¤ºé’å°‘å¹´äº§å‰è¯ç‰©æš´éœ²ä¸­ç»“æ„-åŠŸèƒ½è€¦åˆçš„Kuramotoå¼•å¯¼å›¾ç½‘ç»œ|Badhan Mazumder, Lei Wu, Sir-Lord Wiafe, Vince D. Calhoun, Dong Hye Ye|<https://arxiv.org/pdf/2601.11018v2>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Supervising 3D Talking Head Avatars with Analysis-by-Audio-Synthesis|åˆ©ç”¨ Analysis-by-Audio-Synthesis ç›‘ç£ 3D è¯´è¯å¤´åƒ|Radek DanÄ›Äek, Carolin Schmitt, Senya Polikovsky, Michael J. Black|<https://arxiv.org/pdf/2504.13386v4>|æ— |
|ğŸ“ æ›´æ–°|Task-Specific Directions: Definition, Exploration, and Utilization in Parameter Efficient Fine-Tuning|Task-Specific Directionsï¼šåœ¨å‚æ•°é«˜æ•ˆå¾®è°ƒä¸­çš„å®šä¹‰ã€æ¢ç´¢ä¸åˆ©ç”¨|Chongjie Si, Zhiyi Shi, Shifan Zhang, Xiaokang Yang, Hanspeter Pfister, Wei Shen|<https://arxiv.org/pdf/2409.01035v5>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Magnetic Resonance Simulation of Effective Transverse Relaxation (T2*)|æœ‰æ•ˆæ¨ªå‘å¼›è±« (T2*) çš„ç£å…±æŒ¯æ¨¡æ‹Ÿ|Hidenori Takeshima|<https://arxiv.org/pdf/2601.19246v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|Reg-TTR, Test-Time Refinement for Fast, Robust and Accurate Image Registration|Reg-TTRï¼Œç”¨äºå¿«é€Ÿã€é²æ£’ä¸”ç²¾ç¡®å›¾åƒé…å‡†çš„æµ‹è¯•æ—¶ä¼˜åŒ–|Lin Chen, Yue He, Fengting Zhang, Yaonan Wang, Fengming Lin, Xiang Chen, Min Liu|<https://arxiv.org/pdf/2601.19114v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|EPAS: Efficient Training with Progressive Activation Sharing|EPAS: åˆ©ç”¨æ¸è¿›å¼æ¿€æ´»å…±äº«çš„é«˜æ•ˆè®­ç»ƒ|Rezaul Karim, Maryam Dialameh, Yang Liu, Boxing Chen, Walid Ahmed|<https://arxiv.org/pdf/2601.19089v1>|åˆ†æå¤±è´¥|


## é²æ£’æ€§ä¸å¯é æ€§ (Robustness & Reliability)


### åˆ†å¸ƒå¤–æ³›åŒ– (Out-of-distribution Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|DisCoPatch: Taming Adversarially-driven Batch Statistics for Improved Out-of-Distribution Detection|DisCoPatch: é©¯æœå¯¹æŠ—é©±åŠ¨çš„ Batch Statistics ä»¥æ”¹è¿› Out-of-Distribution Detection|Francisco Caetano, Christiaan Viviers, Luis A. Zavala-MondragÃ³n, Peter H. N. de With, Fons van der Sommen|<https://arxiv.org/pdf/2501.08005v7>|æ— |
|ğŸ“ æ›´æ–°|Activation Function Design Sustains Plasticity in Continual Learning|[ç¿»è¯‘å¤±è´¥] Activation Function Design Sustains Plasticity in Continual Learning|Lute Lillo, Nick Cheney|<https://arxiv.org/pdf/2509.22562v2>|æ— |


## ä½èµ„æºä¸é«˜æ•ˆå­¦ä¹  (Low-resource & Efficient Learning)


### é›¶/å°‘æ ·æœ¬æ³›åŒ– (Zero/Few-shot Generalization)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Will It Zero-Shot?: Predicting Zero-Shot Classification Performance For Arbitrary Queries|Will It Zero-Shot?: é¢„æµ‹ä»»æ„ Queries çš„ Zero-Shot åˆ†ç±»æ€§èƒ½|Kevin Robbins, Xiaotong Liu, Yu Wu, Le Sun, Grady McPeak, Abby Stylianou, Robert Pless|<https://arxiv.org/pdf/2601.17535v2>|æ— |
|ğŸ†• å‘å¸ƒ|Towards Gold-Standard Depth Estimation for Tree Branches in UAV Forestry: Benchmarking Deep Stereo Matching Methods|[ç¿»è¯‘å¤±è´¥] Towards Gold-Standard Depth Estimation for Tree Branches in UAV Forestry: Benchmarking Deep Stereo Matching Methods|Yida Lin, Bing Xue, Mengjie Zhang, Sam Schofield, Richard Green|<https://arxiv.org/pdf/2601.19461v1>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|TIGaussian: Disentangle Gaussians for Spatial-Awared Text-Image-3D Alignment|TIGaussian: è§£è€¦é«˜æ–¯ä»¥å®ç°ç©ºé—´æ„ŸçŸ¥çš„ Text-Image-3D å¯¹é½|Jiarun Liu, Qifeng Chen, Yiru Zhao, Minghua Liu, Baorui Ma, Sheng Yang|<https://arxiv.org/pdf/2601.19247v1>|æ— |


### ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ (Active Learning Strategies)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|KeepLoRA: Continual Learning with Residual Gradient Adaptation|KeepLoRA: åŸºäºæ®‹å·®æ¢¯åº¦é€‚é…çš„æŒç»­å­¦ä¹ |Mao-Lin Luo, Zi-Hao Zhou, Yi-Lin Zhang, Yuanyu Wan, Tong Wei, Min-Ling Zhang|<https://arxiv.org/pdf/2601.19659v1>|[ä»£ç ](https://github.com/MaolinLuo/KeepLoRA.)|
|ğŸ“ æ›´æ–°|Learning to Detect Unseen Jailbreak Attacks in Large Vision-Language Models|å­¦ä¹ æ£€æµ‹ Large Vision-Language Models ä¸­æœªè§è¿‡çš„è¶Šç‹±æ”»å‡»|Shuang Liang, Zhihao Xu, Jiaqi Weng, Jialing Tao, Hui Xue, Xiting Wang|<https://arxiv.org/pdf/2508.09201v4>|æ— |
|ğŸ“ æ›´æ–°|Federated Joint Learning for Domain and Class Generalization|[ç¿»è¯‘å¤±è´¥] Federated Joint Learning for Domain and Class Generalization|Haoran Xu, Jiaze Li, Jianzhong Ju, Zhenbo Luo|<https://arxiv.org/pdf/2601.12253v2>|æ— |
|ğŸ†• å‘å¸ƒ|A Multi-View Consistency Framework with Semi-Supervised Domain Adaptation|ä¸€ç§å…·æœ‰åŠç›‘ç£åŸŸé€‚åº”çš„å¤šè§†å›¾ä¸€è‡´æ€§æ¡†æ¶|Yuting Hong, Li Dong, Xiaojie Qiu, Hui Xiao, Baochen Yao, Siming Zheng, Chengbin Peng|<https://arxiv.org/pdf/2601.19266v1>|æ— |
|ğŸ“ æ›´æ–°|Deeply Learned Robust Matrix Completion for Large-scale Low-rank Data Recovery|[ç¿»è¯‘å¤±è´¥] Deeply Learned Robust Matrix Completion for Large-scale Low-rank Data Recovery|HanQin Cai, Chandra Kundu, Jialin Liu, Wotao Yin|<https://arxiv.org/pdf/2501.00677v2>|æ— |


## è§†è§‰-è¯­è¨€ååŒç†è§£ (Vision-Language Joint Understanding)


### å¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿ (Multimodal Dialogue Systems)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|DuwatBench: Bridging Language and Visual Heritage through an Arabic Calligraphy Benchmark for Multimodal Understanding|DuwatBenchï¼šé€šè¿‡ç”¨äºå¤šæ¨¡æ€ç†è§£çš„é˜¿æ‹‰ä¼¯ä¹¦æ³•åŸºå‡†è¿æ¥è¯­è¨€ä¸è§†è§‰é—äº§|Shubham Patle, Sara Ghaboura, Hania Tariq, Mohammad Usman Khan, Omkar Thawakar, Rao Muhammad Anwer, Salman Khan|<https://arxiv.org/pdf/2601.19898v1>|[ä»£ç ](https://github.com/mbzuai-oryx/DuwatBench)|


### è§†è§‰é—®ç­”ä¸æ¨ç† (Visual Question Answering & Reasoning)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Query-Guided Spatial-Temporal-Frequency Interaction for Music Audio-Visual Question Answering|[ç¿»è¯‘å¤±è´¥] Query-Guided Spatial-Temporal-Frequency Interaction for Music Audio-Visual Question Answering|Kun Li, Michael Ying Yang, Sami Sebastian Brandt|<https://arxiv.org/pdf/2601.19821v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|ReVision: A Dataset and Baseline VLM for Privacy-Preserving Task-Oriented Visual Instruction Rewriting|ReVision: ä¸€ä¸ªé¢å‘éšç§ä¿æŠ¤ä»»åŠ¡å‹è§†è§‰æŒ‡ä»¤é‡å†™çš„æ•°æ®é›†ä¸åŸºçº¿ VLM|Abhijit Mishra, Mingda Li, Hsiang Fu, Richard Noh, Minji Kim|<https://arxiv.org/pdf/2502.14780v3>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|Human Cognitive Benchmarks Reveal Foundational Visual Gaps in MLLMs|Human Cognitive Benchmarks æ­ç¤º MLLMs çš„åŸºç¡€è§†è§‰å·®è·|Jen-Tse Huang, Dasen Dai, Jen-Yuan Huang, Youliang Yuan, Xiaoyuan Liu, Wenxuan Wang, Wenxiang Jiao, Pinjia He .etc.|<https://arxiv.org/pdf/2502.16435v3>|æ— |
|ğŸ†• å‘å¸ƒ|Bridging Visual and Wireless Sensing: A Unified Radiation Field for 3D Radio Map Construction|è¿æ¥è§†è§‰ä¸æ— çº¿æ„ŸçŸ¥ï¼šç”¨äº3D Radio Mapæ„å»ºçš„ç»Ÿä¸€è¾å°„åœº|Chaozheng Wen, Jingwen Tong, Zehong Lin, Chenghong Bian, Jun Zhang|<https://arxiv.org/pdf/2601.19216v1>|æ— |
|ğŸ†• å‘å¸ƒ|MATA: A Trainable Hierarchical Automaton System for Multi-Agent Visual Reasoning|[ç¿»è¯‘å¤±è´¥] MATA: A Trainable Hierarchical Automaton System for Multi-Agent Visual Reasoning|Zhixi Cai, Fucai Ke, Kevin Leo, Sukai Huang, Maria Garcia de la Banda, Peter J. Stuckey, Hamid Rezatofighi|<https://arxiv.org/pdf/2601.19204v1>|[ä»£ç ](https://github.com/ControlNet/MATA.)|
|ğŸ“ æ›´æ–°|DiVE-k: Differential Visual Reasoning for Fine-grained Image Recognition|DiVE-kï¼šé¢å‘ç»†ç²’åº¦å›¾åƒè¯†åˆ«çš„å·®åˆ†è§†è§‰æ¨ç†|Raja Kumar, Arka Sadhu, Ram Nevatia|<https://arxiv.org/pdf/2511.18305v2>|[ä»£ç ](https://github.com/raja-kumar/DiVE-k)|


### è§†è§‰å†…å®¹æè¿° (Visual Content Description)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Youtu-VL: Unleashing Visual Potential via Unified Vision-Language Supervision|Youtu-VL: é€šè¿‡ç»Ÿä¸€è§†è§‰-è¯­è¨€ç›‘ç£é‡Šæ”¾è§†è§‰æ½œåŠ›|Zhixiang Wei, Yi Li, Zhehan Kan, Xinghua Jiang, Zuwei Long, Shifeng Liu, Hongze Shen, Wei Liu .etc.|<https://arxiv.org/pdf/2601.19798v1>|åˆ†æå¤±è´¥|


## é¢†åŸŸç‰¹å®šè§†è§‰åº”ç”¨ (Domain-specific Visual Applications)


### é¥æ„Ÿä¸åœ°ç†ä¿¡æ¯ (Remote Sensing & Geospatial Information)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ“ æ›´æ–°|Assessing the Effectiveness of Deep Embeddings for Tree Species Classification in the Dutch Forest Inventory|è¯„ä¼°Deep Embeddingsåœ¨è·å…°æ£®æ—æ¸…æŸ¥æ ‘ç§åˆ†ç±»ä¸­çš„æœ‰æ•ˆæ€§|Takayuki Ishikawa, Carmelo Bonannella, Bas J. W. Lerink, Marc RuÃŸwurm|<https://arxiv.org/pdf/2508.18829v2>|æ— |
|ğŸ“ æ›´æ–°|Leveraging Convolutional and Graph Networks for an Unsupervised Remote Sensing Labelling Tool|åˆ©ç”¨å·ç§¯å’Œå›¾ç½‘ç»œçš„æ— ç›‘ç£é¥æ„Ÿæ ‡æ³¨å·¥å…·|Tulsi Patel, Mark W. Jones, Thomas Redfern|<https://arxiv.org/pdf/2508.00506v2>|æ— |
|ğŸ“ æ›´æ–°|A Gift from the Integration of Discriminative and Diffusion-based Generative Learning: Boundary Refinement Remote Sensing Semantic Segmentation|åˆ¤åˆ«å¼ä¸åŸºäºæ‰©æ•£çš„ç”Ÿæˆå­¦ä¹ èåˆçš„é¦ˆèµ ï¼šè¾¹ç•Œç»†åŒ–é¥æ„Ÿè¯­ä¹‰åˆ†å‰²|Hao Wang, Keyan Hu, Xin Guo, Haifeng Li, Chao Tao|<https://arxiv.org/pdf/2507.01573v2>|æ— |
|ğŸ“ æ›´æ–°|Uni-PrevPredMap: Extending PrevPredMap to a Unified Framework of Prior-Informed Modeling for Online Vectorized HD Map Construction|Uni-PrevPredMapï¼šå°†PrevPredMapæ‰©å±•ä¸ºåœ¨çº¿çŸ¢é‡åŒ–HDåœ°å›¾æ„å»ºçš„å…ˆéªŒä¿¡æ¯å»ºæ¨¡ç»Ÿä¸€æ¡†æ¶|Nan Peng, Xun Zhou, Mingming Wang, Guisong Chen, Wenqi Xu|<https://arxiv.org/pdf/2504.06647v3>|[ä»£ç ](https://github.com/pnnnnnnn/Uni-PrevPredMap.); åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|BTCChat: Advancing Remote Sensing Bi-temporal Change Captioning with Multimodal Large Language Model|BTCChat: åˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ¨è¿›é¥æ„ŸåŒæ—¶ç›¸å˜åŒ–æè¿°|Yujie Li, Wenjia Xu, Yuanben Zhang, Zhiwei Wei, Mugen Peng|<https://arxiv.org/pdf/2509.05895v2>|[ä»£ç ](https://github.com/IntelliSensing/BTCChat)|


### åŒ»å­¦å½±åƒåˆ†æ (Medical Image Analysis)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Interpretable and backpropagation-free Green Learning for efficient multi-task echocardiographic segmentation and classification|å¯è§£é‡Šä¸”æ— éœ€åå‘ä¼ æ’­çš„Green Learningç”¨äºé«˜æ•ˆçš„å¤šä»»åŠ¡è¶…å£°å¿ƒåŠ¨å›¾åˆ†å‰²ä¸åˆ†ç±»|Jyun-Ping Kao, Jiaxing Yang, C. -C. Jay Kuo, Jonghye Woo|<https://arxiv.org/pdf/2601.19743v1>|æ— |
|ğŸ†• å‘å¸ƒ|DSVM-UNet : Enhancing VM-UNet with Dual Self-distillation for Medical Image Segmentation|DSVM-UNetï¼šé€šè¿‡åŒé‡è‡ªè’¸é¦å¢å¼ºVM-UNetç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²|Renrong Shao, Dongyang Li, Dong Xia, Lin Shao, Jiangdong Lu, Fen Zheng, Lulu Zhang|<https://arxiv.org/pdf/2601.19690v1>|[ä»£ç ](https://github.com/RoryShao/DSVM-UNet.git.)|
|ğŸ“ æ›´æ–°|Semantic-aware Random Convolution and Source Matching for Domain Generalization in Medical Image Segmentation|é¢å‘åŒ»å­¦å›¾åƒåˆ†å‰²åŸŸæ³›åŒ–çš„è¯­ä¹‰æ„ŸçŸ¥éšæœºå·ç§¯ä¸æºåŸŸåŒ¹é…|Franz Thaler, Martin Urschler, Mateusz Kozinski, Matthias AF Gsell, Gernot Plank, Darko Stern|<https://arxiv.org/pdf/2512.01510v2>|åˆ†æå¤±è´¥|
|ğŸ†• å‘å¸ƒ|The role of self-supervised pretraining in differentially private medical image analysis|è‡ªç›‘ç£é¢„è®­ç»ƒåœ¨å·®åˆ†éšç§åŒ»å­¦å›¾åƒåˆ†æä¸­çš„ä½œç”¨|Soroosh Tayebi Arasteh, Mina Farajiamiri, Mahshad Lotfinia, Behrus Hinrichs-Puladi, Jonas Bienzeisler, Mohamed Alhaskir, Mirabela Rusu, Christiane Kuhl .etc.|<https://arxiv.org/pdf/2601.19618v1>|åˆ†æå¤±è´¥|
|ğŸ“ æ›´æ–°|AI-generated data contamination erodes pathological variability and diagnostic reliability|[ç¿»è¯‘å¤±è´¥] AI-generated data contamination erodes pathological variability and diagnostic reliability|Hongyu He, Shaowen Xiang, Ye Zhang, Yingtao Zhu, Jin Zhang, Hao Deng, Emily Alsentzer, Qingyu Chen .etc.|<https://arxiv.org/pdf/2601.12946v3>|æ— |
|ğŸ†• å‘å¸ƒ|Pareto-Guided Optimization for Uncertainty-Aware Medical Image Segmentation|[ç¿»è¯‘å¤±è´¥] Pareto-Guided Optimization for Uncertainty-Aware Medical Image Segmentation|Jinming Zhang, Xi Yang, Youpeng Yang, Haosen Shi, Yuyao Yan, Qiufeng Wang, Guangliang Cheng, Kaizhu Huang|<https://arxiv.org/pdf/2601.19365v1>|æ— |


### æ™ºèƒ½äº¤é€šè§†è§‰ (Intelligent Transportation Vision)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|ScenePilot-Bench: A Large-Scale Dataset and Benchmark for Evaluation of Vision-Language Models in Autonomous Driving|ScenePilot-Benchï¼šç”¨äºè¯„ä¼°è‡ªåŠ¨é©¾é©¶ä¸­Vision-Language Modelsçš„å¤§è§„æ¨¡æ•°æ®é›†å’ŒåŸºå‡†|Yujin Wang, Yutong Zheng, Wenxian Fan, Tianyi Wang, Hongqing Chu, Daxin Tian, Bingzhao Gao, Jianqiang Wang .etc.|<https://arxiv.org/pdf/2601.19582v1>|æ— |


### åˆ›æ„åª’ä½“ç”Ÿæˆ (Creative Media Generation)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Instance-Guided Radar Depth Estimation for 3D Object Detection|[ç¿»è¯‘å¤±è´¥] Instance-Guided Radar Depth Estimation for 3D Object Detection|Chen-Chou Lo, Patrick Vandewalle|<https://arxiv.org/pdf/2601.19314v1>|åˆ†æå¤±è´¥|


### å·¥ä¸šè§†è§‰æ£€æµ‹ (Industrial Visual Inspection)

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|UniPCB: A Unified Vision-Language Benchmark for Open-Ended PCB Quality Inspection|UniPCB: ä¸€ä¸ªç”¨äºå¼€æ”¾å¼PCBè´¨é‡æ£€æµ‹çš„ç»Ÿä¸€è§†è§‰-è¯­è¨€åŸºå‡†|Fuxiang Sun, Xi Jiang, Jiansheng Wu, Haigang Zhang, Feng Zheng, Jinfeng Yang|<https://arxiv.org/pdf/2601.19222v1>|æ— |


## å…¶ä»– (Others)


### æœªåˆ†ç±»

|çŠ¶æ€|è‹±æ–‡æ ‡é¢˜|ä¸­æ–‡æ ‡é¢˜|ä½œè€…|PDFé“¾æ¥|ä»£ç /è´¡çŒ®|
|---|---|---|---|---|---|
|ğŸ†• å‘å¸ƒ|Tri-Reader: An Open-Access, Multi-Stage AI Pipeline for First-Pass Lung Nodule Annotation in Screening CT|Tri-Readerï¼šä¸€ç§ç”¨äºç­›æŸ¥ CT ä¸­é¦–è½®è‚ºç»“èŠ‚æ ‡æ³¨çš„å¼€æ”¾è·å–ã€å¤šé˜¶æ®µ AI æµæ°´çº¿|Fakrul Islam Tushar, Joseph Y. Lo|<https://arxiv.org/pdf/2601.19380v1>|æ— |
|ğŸ†• å‘å¸ƒ|Beyond Shadows: A Large-Scale Benchmark and Multi-Stage Framework for High-Fidelity Facial Shadow Removal|è¶…è¶Šé˜´å½±ï¼šç”¨äºé«˜ä¿çœŸé¢éƒ¨é˜´å½±å»é™¤çš„å¤§è§„æ¨¡åŸºå‡†ä¸å¤šé˜¶æ®µæ¡†æ¶|Tailong Luo, Jiesong Bai, Jinyang Huang, Junyu Xia, Wangyu Wu, Xuhang Chen|<https://arxiv.org/pdf/2601.19309v1>|æ— |
|ğŸ†• å‘å¸ƒ|Glance and Focus Reinforcement for Pan-cancer Screening|[ç¿»è¯‘å¤±è´¥] Glance and Focus Reinforcement for Pan-cancer Screening|Linshan Wu, Jiaxin Zhuang, Hao Chen|<https://arxiv.org/pdf/2601.19103v1>|æ— |
|ğŸ†• å‘å¸ƒ|GTFMN: Guided Texture and Feature Modulation Network for Low-Light Image Enhancement and Super-Resolution|GTFMN: ç”¨äºä½å…‰ç…§å›¾åƒå¢å¼ºä¸è¶…åˆ†è¾¨ç‡çš„å¼•å¯¼çº¹ç†å’Œç‰¹å¾è°ƒåˆ¶ç½‘ç»œ|Yongsong Huang, Tzu-Hsuan Peng, Tomo Miyazaki, Xiaofeng Liu, Chun-Ting Chou, Ai-Chun Pang, Shinichiro Omachi|<https://arxiv.org/pdf/2601.19157v1>|æ— |
|ğŸ“ æ›´æ–°|Extensions on Low-complexity DCT Approximations for Larger Blocklengths Based on Minimal Angle Similarity|åŸºäºæœ€å°è§’åº¦ç›¸ä¼¼åº¦çš„æ›´å¤§å—é•¿ä½å¤æ‚åº¦ DCT è¿‘ä¼¼æ‰©å±•|A. P. RadÃ¼nz, L. Portella, R. S. Oliveira, F. M. Bayer, R. J. Cintra|<https://arxiv.org/pdf/2410.15244v2>|æå‡ºåŸºäºæœ€å°è§’åº¦ç›¸ä¼¼åº¦çš„16ã€32ã€64ç‚¹ä½å¤æ‚åº¦DCTè¿‘ä¼¼æ–¹æ³•ã€‚|

