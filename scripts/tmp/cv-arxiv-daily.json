{"\u751f\u6210\u6a21\u578b": {}, "\u591a\u6a21\u6001": {}, "Nerf": {}, "3DGS": {}, "\u6a21\u578b\u538b\u7f29/\u4f18\u5316": {}, "\u5206\u7c7b/\u68c0\u6d4b/\u8bc6\u522b/\u5206\u5272/...": {"2403.01362": "|**2024-03-03**|**Enhancing Retinal Vascular Structure Segmentation in Images With a Novel Design Two-Path Interactive Fusion Module Model**|\u901a\u8fc7\u65b0\u9896\u8bbe\u8ba1\u7684\u4e24\u8def\u4ea4\u4e92\u5f0f\u878d\u5408\u6a21\u5757\u6a21\u578b\u589e\u5f3a\u56fe\u50cf\u4e2d\u7684\u89c6\u7f51\u819c\u8840\u7ba1\u7ed3\u6784\u5206\u5272|Rui Yang, Shunpu Zhang|Precision in identifying and differentiating micro and macro blood vessels in the retina is crucial for the diagnosis of retinal diseases, although it poses a significant challenge. Current autoencoding-based segmentation approaches encounter limitations as they are constrained by the encoder and undergo a reduction in resolution during the encoding stage. The inability to recover lost information in the decoding phase further impedes these approaches. Consequently, their capacity to extract the retinal microvascular structure is restricted. To address this issue, we introduce Swin-Res-Net, a specialized module designed to enhance the precision of retinal vessel segmentation. Swin-Res-Net utilizes the Swin transformer which uses shifted windows with displacement for partitioning, to reduce network complexity and accelerate model convergence. Additionally, the model incorporates interactive fusion with a functional module in the Res2Net architecture. The Res2Net leverages multi-scale techniques to enlarge the receptive field of the convolutional kernel, enabling the extraction of additional semantic information from the image. This combination creates a new module that enhances the localization and separation of micro vessels in the retina. To improve the efficiency of processing vascular information, we've added a module to eliminate redundant information between the encoding and decoding steps.   Our proposed architecture produces outstanding results, either meeting or surpassing those of other published models. The AUC reflects significant enhancements, achieving values of 0.9956, 0.9931, and 0.9946 in pixel-wise segmentation of retinal vessels across three widely utilized datasets: CHASE-DB1, DRIVE, and STARE, respectively. Moreover, Swin-Res-Net outperforms alternative architectures, demonstrating superior performance in both IOU and F1 measure metrics.|\u7cbe\u786e\u8bc6\u522b\u548c\u533a\u5206\u89c6\u7f51\u819c\u4e2d\u7684\u5fae\u89c2\u548c\u5b8f\u89c2\u8840\u7ba1\u5bf9\u4e8e\u89c6\u7f51\u819c\u75be\u75c5\u7684\u8bca\u65ad\u81f3\u5173\u91cd\u8981\uff0c\u5c3d\u7ba1\u5b83\u63d0\u51fa\u4e86\u91cd\u5927\u6311\u6218\u3002\u5f53\u524d\u57fa\u4e8e\u81ea\u52a8\u7f16\u7801\u7684\u5206\u5272\u65b9\u6cd5\u9047\u5230\u9650\u5236\uff0c\u56e0\u4e3a\u5b83\u4eec\u53d7\u5230\u7f16\u7801\u5668\u7684\u7ea6\u675f\u5e76\u4e14\u5728\u7f16\u7801\u9636\u6bb5\u7ecf\u5386\u5206\u8fa8\u7387\u7684\u964d\u4f4e\u3002\u65e0\u6cd5\u5728\u89e3\u7801\u9636\u6bb5\u6062\u590d\u4e22\u5931\u7684\u4fe1\u606f\u8fdb\u4e00\u6b65\u963b\u788d\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u3002\u56e0\u6b64\uff0c\u5b83\u4eec\u63d0\u53d6\u89c6\u7f51\u819c\u5fae\u8840\u7ba1\u7ed3\u6784\u7684\u80fd\u529b\u53d7\u5230\u9650\u5236\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u5f15\u5165\u4e86 Swin-Res-Net\uff0c\u8fd9\u662f\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8e\u63d0\u9ad8\u89c6\u7f51\u819c\u8840\u7ba1\u5206\u5272\u7cbe\u5ea6\u7684\u6a21\u5757\u3002 Swin-Res-Net \u5229\u7528 Swin \u53d8\u538b\u5668\uff0c\u4f7f\u7528\u5e26\u6709\u4f4d\u79fb\u7684\u79fb\u4f4d\u7a97\u53e3\u8fdb\u884c\u5206\u533a\uff0c\u4ee5\u964d\u4f4e\u7f51\u7edc\u590d\u6742\u6027\u5e76\u52a0\u901f\u6a21\u578b\u6536\u655b\u3002\u6b64\u5916\uff0c\u8be5\u6a21\u578b\u5c06\u4ea4\u4e92\u5f0f\u878d\u5408\u4e0e Res2Net \u67b6\u6784\u4e2d\u7684\u529f\u80fd\u6a21\u5757\u76f8\u7ed3\u5408\u3002 Res2Net \u5229\u7528\u591a\u5c3a\u5ea6\u6280\u672f\u6765\u6269\u5927\u5377\u79ef\u6838\u7684\u611f\u53d7\u91ce\uff0c\u4ece\u800c\u80fd\u591f\u4ece\u56fe\u50cf\u4e2d\u63d0\u53d6\u989d\u5916\u7684\u8bed\u4e49\u4fe1\u606f\u3002\u8fd9\u79cd\u7ec4\u5408\u521b\u5efa\u4e86\u4e00\u4e2a\u65b0\u6a21\u5757\uff0c\u53ef\u4ee5\u589e\u5f3a\u89c6\u7f51\u819c\u4e2d\u5fae\u8840\u7ba1\u7684\u5b9a\u4f4d\u548c\u5206\u79bb\u3002\u4e3a\u4e86\u63d0\u9ad8\u5904\u7406\u8840\u7ba1\u4fe1\u606f\u7684\u6548\u7387\uff0c\u6211\u4eec\u6dfb\u52a0\u4e86\u4e00\u4e2a\u6a21\u5757\u6765\u6d88\u9664\u7f16\u7801\u548c\u89e3\u7801\u6b65\u9aa4\u4e4b\u95f4\u7684\u5197\u4f59\u4fe1\u606f\u3002\u6211\u4eec\u63d0\u51fa\u7684\u67b6\u6784\u4ea7\u751f\u4e86\u51fa\u8272\u7684\u7ed3\u679c\uff0c\u8fbe\u5230\u6216\u8d85\u8fc7\u4e86\u5176\u4ed6\u5df2\u53d1\u5e03\u6a21\u578b\u7684\u7ed3\u679c\u3002 AUC \u53cd\u6620\u4e86\u663e\u7740\u7684\u589e\u5f3a\uff0c\u5728\u4e09\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u6570\u636e\u96c6\uff08CHASE-DB1\u3001DRIVE \u548c STARE\uff09\u4e2d\u7684\u89c6\u7f51\u819c\u8840\u7ba1\u50cf\u7d20\u7ea7\u5206\u5272\u4e2d\u5206\u522b\u5b9e\u73b0\u4e86 0.9956\u30010.9931 \u548c 0.9946 \u7684\u503c\u3002\u6b64\u5916\uff0cSwin-Res-Net \u7684\u6027\u80fd\u4f18\u4e8e\u66ff\u4ee3\u67b6\u6784\uff0c\u5728 IOU \u548c F1 \u6d4b\u91cf\u6307\u6807\u4e0a\u90fd\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u6027\u80fd\u3002|[2403.01362v1](http://arxiv.org/pdf/2403.01362v1)|null|\n"}, "OCR": {}, "GNN": {}, "\u56fe\u50cf\u7406\u89e3": {}, "LLM": {}, "Transformer": {}, "3D/CG": {}, "\u5404\u7c7b\u5b66\u4e60\u65b9\u5f0f": {}, "\u5176\u4ed6": {}}